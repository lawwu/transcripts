
[00:00:00.000 --> 00:00:05.360]   if say, like a chat GPT and chatbots hadn't got the kind of got the interest they'd ended up
[00:00:05.360 --> 00:00:09.040]   getting, which I think was quite surprising to everyone that people were ready to use these
[00:00:09.040 --> 00:00:13.280]   things, even though they were lacking in certain directions, right? Impressive though they are.
[00:00:13.280 --> 00:00:18.480]   Then we would have produced more specialized systems, I think, built off of the main track
[00:00:18.480 --> 00:00:24.400]   like AlphaFolds and AlphaGoes and so on and our scientific work. So that's created a different
[00:00:24.400 --> 00:00:31.840]   type of environment that we're now all operating in as a field. And it's a little bit more chaotic
[00:00:31.840 --> 00:00:36.720]   because there's so many more things going on and there's so much VC money going into it and
[00:00:36.720 --> 00:00:42.800]   everyone's sort of almost losing their minds over it, I think. And the thing I worry about is I want
[00:00:42.800 --> 00:00:49.040]   to make sure that as a field we act responsibly and thoughtfully and scientifically about this
[00:00:49.040 --> 00:00:54.880]   and use the scientific method to approach this in a, as I said, an optimistic but careful way.
[00:00:54.880 --> 00:00:59.840]   And I think that's the, I've always believed that's the right approach for something like AI
[00:00:59.840 --> 00:01:05.760]   and I just hope that doesn't get lost in this huge rush. I'm obviously a huge techno-optimist,
[00:01:05.760 --> 00:01:10.960]   but I want us to be cautious with that given the transformative power of what we're bringing
[00:01:10.960 --> 00:01:15.520]   into the world, you know, collectively. And I think it's going to be one of the most important
[00:01:15.520 --> 00:01:20.880]   technologies humanity will ever invent. So we've got to put all our efforts into getting this right
[00:01:20.880 --> 00:01:26.720]   and to be thoughtful and sort of also humble about what we know and don't know about the
[00:01:26.720 --> 00:01:31.440]   systems that are coming and the uncertainties around that. And in my view, the only sensible
[00:01:31.440 --> 00:01:36.240]   approach when you have huge uncertainty is to be sort of cautiously optimistic and use the
[00:01:36.240 --> 00:01:40.800]   scientific method to try and have as much foresight and understanding about what's coming down the
[00:01:40.800 --> 00:01:44.640]   line and the consequences of that before it happens. You know, you don't want to be live
[00:01:44.640 --> 00:01:49.840]   A/B testing out in the world with these very consequential systems because unintended consequences
[00:01:49.840 --> 00:01:56.880]   may be quite severe. So, you know, I want us to move away as a field from sort of move fast and
[00:01:56.880 --> 00:02:00.640]   break things attitude, which is, you know, maybe served the valley very well in the past and
[00:02:00.640 --> 00:02:07.040]   obviously created important innovations. But I think in this case, you know, we want to be
[00:02:08.080 --> 00:02:12.400]   bold with the with the positive things that it can do and make sure we realize things like
[00:02:12.400 --> 00:02:18.160]   medicine and science and advancing all of those things whilst being, you know, responsible and
[00:02:18.160 --> 00:02:24.160]   thoughtful with as far as possible with mitigating the risks. When you extrapolate all this out
[00:02:24.160 --> 00:02:27.600]   forward and you think about superhuman intelligence, what does that landscape look like to
[00:02:27.600 --> 00:02:31.440]   you? Is it like still controlled by a private company? Like what should the governance of that
[00:02:31.440 --> 00:02:38.720]   look like concretely? Yeah, look, I would love, you know, I think that this has to be this is so
[00:02:38.720 --> 00:02:44.880]   consequential, this technology. I think it's much bigger than any one company or or even industry
[00:02:44.880 --> 00:02:51.040]   in general. I think it has to be a big collaboration with many stakeholders from civil society,
[00:02:51.040 --> 00:02:55.600]   academia, government. And the good news is, I think with the popularity of the recent chat bot
[00:02:55.600 --> 00:03:00.960]   systems and so on, I think that has woken up many of these other parts of society that this is
[00:03:00.960 --> 00:03:05.360]   coming and what it will be like to interact with these systems. And that's great. So it's opened
[00:03:05.360 --> 00:03:10.640]   up lots of doors for very good conversations. I mean, example of that was the safety summit at in
[00:03:10.640 --> 00:03:15.200]   the UK hosted a few months ago, which I thought was a big success to start getting this international
[00:03:15.200 --> 00:03:19.920]   dialogue going. And, and, and, you know, I think the whole of society needs to be involved in
[00:03:19.920 --> 00:03:24.080]   deciding what do we want to deploy these models for? How do we want to use them? What do we not
[00:03:24.080 --> 00:03:27.840]   want to use them for? You know, I think we've got to try and get some international consensus
[00:03:27.840 --> 00:03:33.120]   around that, you know, sort of almost like the UN level if possible. And then also making sure that
[00:03:33.120 --> 00:03:38.320]   the benefits of these systems benefit everyone, you know, for the good of everyone in society in
[00:03:38.320 --> 00:03:43.680]   general. And that's why I push so hard things like AI for science. And, and I hope that, you know,
[00:03:43.680 --> 00:03:47.680]   with things like our spin out isomorphic, we're going to start curing diseases, you know, terrible
[00:03:47.680 --> 00:03:53.120]   diseases with AI and accelerate drug discovery, big challenges that face us and face humanity,
[00:03:54.000 --> 00:03:59.200]   massive challenges, actually, which I'm optimistic we can solve, because we've got this incredibly
[00:03:59.200 --> 00:04:05.120]   powerful tool coming along down the line of AI that we can apply, and I think help us solve many

