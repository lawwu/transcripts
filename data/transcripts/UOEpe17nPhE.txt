
[00:00:00.000 --> 00:00:05.520]   The following is a conversation with Ryan Schiller, creator of Librex, an anonymous
[00:00:05.520 --> 00:00:11.440]   discussion feed for college communities starting at first with Yale, then the Ivy Leagues, and now
[00:00:11.440 --> 00:00:18.560]   adding Stanford and MIT. Their mission is to give students a place to explore ideas and issues
[00:00:18.560 --> 00:00:24.880]   in a positive way, but with much more personal and intellectual freedom than has defined college
[00:00:24.880 --> 00:00:31.760]   campuses in recent history. I think this is a very difficult but worthy project. Quick thank you to
[00:00:31.760 --> 00:00:39.360]   our sponsors, Allform, Magic Spoon, BetterHelp, and Brave. Click their links to support this podcast.
[00:00:39.360 --> 00:00:46.560]   As a side note, let me say that Ryan is a young entrepreneur and genuine human being who quickly
[00:00:46.560 --> 00:00:52.800]   won me over. He's inspiring in many ways, both in the struggle he had to overcome in his personal
[00:00:52.800 --> 00:00:59.440]   life, but also in the fact that he did not know how to code, but saw a problem in this world,
[00:00:59.440 --> 00:01:05.600]   in his community, that he cared about. And for that, he learned to code and built a solution
[00:01:05.600 --> 00:01:11.840]   in the best way he knew how. That's an important reminder for us humans. Let us not only complain
[00:01:11.840 --> 00:01:18.160]   about the problems in the world, let us fix them. I also have to say that there's passion in Ryan's
[00:01:18.160 --> 00:01:24.400]   eyes for really wanting to make a difference in the world. His story, his effort gives me hope for
[00:01:24.400 --> 00:01:30.400]   the future. There is hate in this world, but I believe there's much more love. And I believe
[00:01:30.400 --> 00:01:36.400]   it's possible to build online platforms that connect us through our common humanity as we
[00:01:36.400 --> 00:01:44.320]   explore difficult, personal, even painful ideas together. This is the Lex Friedman Podcast,
[00:01:44.320 --> 00:01:51.040]   and here is my conversation with Ryan Schiller. Let's start with the basics. What is Librex?
[00:01:51.040 --> 00:01:57.200]   What are its founding story and founding principles? And looking to the future,
[00:01:57.200 --> 00:02:01.920]   what do you hope to achieve with Librex? - Sure, let me break that down. So what is Librex?
[00:02:01.920 --> 00:02:07.440]   Librex is an anonymous discussion feed for college campuses. It's a place where people
[00:02:07.440 --> 00:02:13.440]   can have important and unfettered discussions and open discourse about topics they care about,
[00:02:13.440 --> 00:02:18.320]   ideas that matter. And they can do all of that completely anonymously with verified members of
[00:02:18.320 --> 00:02:25.520]   their college community. And we exist both on each Ivy League campus and we have an inter-Ivy
[00:02:25.520 --> 00:02:33.040]   community. And actually this week we just opened to MIT and Stanford. - No, really? MIT? Yes.
[00:02:33.040 --> 00:02:37.600]   - And Stanford. So we have MIT and Stanford communities, and I expect you to sign up for
[00:02:37.600 --> 00:02:43.680]   your MIT account and start posting. - What are, for people who are not familiar like me actually,
[00:02:43.680 --> 00:02:48.240]   which are the Ivy Leagues? - Sure. So we started at Yale, which is my,
[00:02:48.240 --> 00:02:52.480]   I don't know, can you call it alma mater? Because I haven't technically graduated.
[00:02:52.480 --> 00:02:57.040]   - Yeah. What's that called when you're actually still there? My university.
[00:02:57.040 --> 00:03:00.240]   - Yeah, I guess we'll just call it home. That's my home.
[00:03:00.240 --> 00:03:03.280]   - Educational home. - Started at my educational home of Yale,
[00:03:03.280 --> 00:03:08.880]   and then we moved to, and we could get into the story of this eventually if you'd like.
[00:03:08.880 --> 00:03:15.200]   And then we went to Dartmouth and then quarantine hit. We opened to the rest of the Ivy League.
[00:03:15.200 --> 00:03:21.920]   And now we have, and the Ivy League for those who don't know is Harvard, Yale, Princeton, Dartmouth,
[00:03:21.920 --> 00:03:28.240]   Columbia, Cornell, Brown, and Penn. I got it all in one breath. - What's the youngest Ivy League,
[00:03:28.240 --> 00:03:32.720]   Penn? No, Columbia. - I can't say it on camera.
[00:03:32.720 --> 00:03:37.200]   - We'll edit it in post. I don't know. - I'll just say each of all eight of them,
[00:03:37.200 --> 00:03:40.320]   and then you can just like get it in. - Yeah.
[00:03:40.320 --> 00:03:42.960]   - Like Penn, Harvard. - There's actually a really nice
[00:03:42.960 --> 00:03:47.840]   software that people should check out, like a service, it's using machine learning really nicely
[00:03:47.840 --> 00:03:56.880]   for podcast editing, where you can, it learns the voice of the speaker and it can change the words
[00:03:56.880 --> 00:03:58.560]   you said. - It's like some deep fake stuff.
[00:03:58.560 --> 00:04:03.200]   - It's deep fake, but for positive applications. It's very interesting. It's like the only deep
[00:04:03.200 --> 00:04:06.000]   fake positive applications I see. - I have a friend who's obsessed with
[00:04:06.000 --> 00:04:11.440]   deep fakes. What's great about, I think, deep fakes is that it's gonna do the opposite of sort
[00:04:11.440 --> 00:04:15.120]   of what's happening with our culture, where everyone will have plausible deniability.
[00:04:15.120 --> 00:04:21.760]   - Yeah, exactly. I mean, that's the hope for me is there's so many fake things out there
[00:04:22.320 --> 00:04:29.040]   that we're going to actually be much more skeptical and think and take in multiple sources
[00:04:29.040 --> 00:04:35.360]   and actually like reason, like use common sense and use deep thinking to understand what is true
[00:04:35.360 --> 00:04:41.200]   and what is not. Because we used to have traditional sources like the New York Times
[00:04:41.200 --> 00:04:46.000]   and all these kinds of publications that had a reputation, there are these institutions,
[00:04:46.000 --> 00:04:50.960]   and they're the source of truth. And when you no longer can trust anything as a source of truth,
[00:04:50.960 --> 00:04:56.240]   you start to think on your own. That gets part of the individual. That takes us way back to
[00:04:56.240 --> 00:05:00.720]   where I came from, the Soviet Union, where you can't really trust any one source of news.
[00:05:00.720 --> 00:05:03.360]   You have to think on your own. You have to talk to your friends.
[00:05:03.360 --> 00:05:08.080]   - Tremendous amount of intellectual autonomy, don't you think? Think about the societal
[00:05:08.080 --> 00:05:09.920]   consequences. - Absolutely. I mean,
[00:05:09.920 --> 00:05:16.480]   we see so much decentralization in all aspects of our digital lives now, but this is like
[00:05:16.480 --> 00:05:24.240]   the decentralization of thought. You could say it's sadly, or I don't think it's sad,
[00:05:24.240 --> 00:05:31.520]   is decentralization of truth, where truth is a clustering thing, where you have this point cloud
[00:05:31.520 --> 00:05:38.720]   of people just swimming around, like billions of them, and they all have certain ideas. And what's
[00:05:38.720 --> 00:05:44.000]   thought of as truth is almost like a clustering algorithm when you just get a bunch of people
[00:05:44.000 --> 00:05:48.640]   that believe the same thing, that's truth. But there's also another truth, and there may be
[00:05:48.640 --> 00:05:55.440]   multiple truths, and it's almost, it would be like a battle of truths. Maybe even the idea of truth
[00:05:55.440 --> 00:06:02.320]   will lessen its power in society, that there is such a thing as a truth. 'Cause the downside of
[00:06:02.320 --> 00:06:09.360]   saying something is true is, it's almost the downside of what people, religious people,
[00:06:09.360 --> 00:06:16.480]   call scientism, which is like, once science has declared something as true, you can't no longer
[00:06:16.480 --> 00:06:21.840]   question it. But the reality is, science is a moving mechanism. You're constantly questioning,
[00:06:21.840 --> 00:06:31.200]   you're constantly questioning, and maybe truth should be renamed as a process, not a final
[00:06:31.200 --> 00:06:35.440]   destination. The whole point is to keep questioning, keep questioning, keep discovering.
[00:06:35.440 --> 00:06:42.240]   >> Kind of like we're going backwards in time to back when people were sort of
[00:06:42.240 --> 00:06:47.840]   finding their identities and we were less globalized, right? People would get together,
[00:06:47.840 --> 00:06:52.240]   and they'd get together around a common value system, common morals, and a common place.
[00:06:52.240 --> 00:06:57.200]   And those would be sort of these clusters of their truth, right? And so we have all these different
[00:06:57.200 --> 00:07:03.040]   civilizations and societies across the world that created their own truths. We talk about the Jews
[00:07:03.040 --> 00:07:08.080]   and the Talmud and Torah, we can look at Buddhist texts, we can look at all sorts of different
[00:07:08.080 --> 00:07:12.640]   truths and how many of them get at the same things, but many of them have different ideas
[00:07:12.640 --> 00:07:18.240]   or different articulations. >> Yeah, Harari and Sapiens rewinds that even farther back into like
[00:07:18.240 --> 00:07:23.200]   caveman times. That's the thing that made us humans special, is we can develop these clusters
[00:07:23.200 --> 00:07:28.480]   of ideas, hold them in our minds through stories, pass them on to each other, and it grows and grows,
[00:07:28.480 --> 00:07:38.240]   and finally we have Bitcoin. Which money is another belief system that has power only because
[00:07:38.240 --> 00:07:45.280]   we believe in it. And is that truth? I don't know, but it has power. It's carried in the minds of
[00:07:45.280 --> 00:07:53.680]   millions and thereby has power. But back to Librex. So what's the founding story, what's the
[00:07:53.680 --> 00:08:00.000]   founding principles of Librex? >> Sure. So I was on campus as a freshman and I was talking to my
[00:08:00.000 --> 00:08:06.320]   friends. Many of them felt like it was hard to raise your hand in class to ask a question. They
[00:08:06.320 --> 00:08:10.160]   really felt like even outside the classroom it was hard to be vulnerable. And the thing you have to
[00:08:10.160 --> 00:08:15.600]   understand about Yale is it's not that big a place. Everyone knows someone who knows someone who knows
[00:08:15.600 --> 00:08:21.760]   you basically. And people come to these schools, first of all, they're home for people and they
[00:08:21.760 --> 00:08:24.640]   want to be themselves. They want to feel like they can be authentic. They want to make real
[00:08:24.640 --> 00:08:29.520]   friendships. And second of all, it's a place where people go for intellectual vitality to
[00:08:29.520 --> 00:08:37.280]   explore important ideas and to grow as thinkers. And fortunately due to the culture, my friends
[00:08:37.280 --> 00:08:42.320]   expressed that it was very difficult to do that and I felt it too. And then I go and talk to my
[00:08:42.320 --> 00:08:48.160]   professors and I remember I talked to one specific global affairs professor and I was taking his
[00:08:48.160 --> 00:08:53.200]   class and his area of expertise was in the Middle Eastern conflict. And I went to him and I said,
[00:08:53.200 --> 00:08:59.440]   "Professor, we're almost finished this class and we haven't even gotten to sort of... The reason I
[00:08:59.440 --> 00:09:02.880]   originally wanted to take the class was to hear about your perspective on the Middle Eastern
[00:09:02.880 --> 00:09:07.360]   conflict." Because something I'd learned at Yale, and this is maybe a sort of a tangent, but I'll
[00:09:07.360 --> 00:09:12.000]   flesh it out a bit. Something I'd learned at Yale is that you can learn all sorts of things from a
[00:09:12.000 --> 00:09:17.920]   textbook and what you kind of go to Yale to do is to get the opinions of the experts that go
[00:09:17.920 --> 00:09:22.320]   beyond the textbook and to have those more in-depth conversations. And so that's sort of
[00:09:22.320 --> 00:09:26.560]   the added value of going to a place like Yale and taking a course there as opposed to just reading
[00:09:26.560 --> 00:09:31.200]   a textbook. - But also interact with that opinion. - Exactly. - In person, yeah. - To interact with
[00:09:31.200 --> 00:09:37.440]   that opinion, to hear it, to respond to it, to push back on it and to have that with some great
[00:09:37.440 --> 00:09:42.880]   minds. And there really are great minds at Yale, don't get me wrong. It's still a place of tremendous
[00:09:42.880 --> 00:09:48.240]   brilliance. So I'm talking to this professor, right? And I'm like, "I haven't heard your area
[00:09:48.240 --> 00:09:53.760]   of expertise." And I'm like, "Are we going to get to it? What's the deal?" And this is during office
[00:09:53.760 --> 00:09:59.440]   hours, mind you. So we're one-on-one. He says, "Ryan, to be honest, I used to teach this area
[00:09:59.440 --> 00:10:03.840]   every single year. In fact, I would do a section on it, which is like a small seminar, like break
[00:10:03.840 --> 00:10:10.000]   away from the class where he would talk to the students in small groups and explain his perspective,
[00:10:10.000 --> 00:10:15.680]   his research, and have a real debate about it, like around a Harkness table." And he said, "I
[00:10:15.680 --> 00:10:22.800]   used to do this. And then about two years ago, a student reported me to the school and I realized
[00:10:22.800 --> 00:10:28.400]   my job was at risk. And I realized the best course of action was basically just not to broach the
[00:10:28.400 --> 00:10:34.880]   topic. And so now I just don't even mention it." And he's like, "You can say whatever you want, but
[00:10:35.760 --> 00:10:40.880]   I'm not going to be a part of it." And it's a real shame. It's a real loss to all of the students
[00:10:40.880 --> 00:10:48.560]   who I think came to the school to learn from these brilliant professors. - In that context of these
[00:10:48.560 --> 00:10:56.480]   world experts, the problem seems to be that reporting mechanism where there's a disproportionate
[00:10:56.480 --> 00:11:04.640]   power to a complaint of a young student, a complaint that an idea is painful or an idea
[00:11:04.640 --> 00:11:13.200]   is disrespectful to, or ideas creating an unsafe space. And the conclusion of that, I mean, I'm not
[00:11:13.200 --> 00:11:20.400]   sure what to do with that because it's a single reporting, maybe a couple, but that has more power
[00:11:20.400 --> 00:11:27.120]   than the idea itself. And that's strange. I don't know how to fix that in the administration,
[00:11:27.120 --> 00:11:33.520]   except to fire everybody. So this is to push back against this storyline that academia is
[00:11:33.520 --> 00:11:37.680]   somehow fundamentally broken. I think we have to separate a lot of things out.
[00:11:37.680 --> 00:11:43.840]   Like one is you have to look at faculty and you have to look at the administration.
[00:11:43.840 --> 00:11:54.400]   And like at MIT, for example, the administration tries to do well, but they're the ones that often
[00:11:54.400 --> 00:12:00.640]   lack courage. They're often the ones who are the source of the problem. When people criticize
[00:12:00.640 --> 00:12:08.160]   academia, and I'll just speak to myself, I'm willing to take heat for this, is they really
[00:12:08.160 --> 00:12:14.560]   are criticizing the administration, not the faculty, because the faculty oftentimes are the
[00:12:14.560 --> 00:12:22.160]   most brilliant, the boldest thinkers that you think. Whenever you talk about, we need the truth
[00:12:22.160 --> 00:12:27.600]   to be spoken, the faculty are often the ones who are in the possession of the deepest truths in
[00:12:27.600 --> 00:12:32.960]   their mind. And in that sense, and they also have the capacity to truly educate in the way that
[00:12:32.960 --> 00:12:41.040]   you're saying. And so it's not broken fundamentally, but there's stuff that's not
[00:12:41.040 --> 00:12:44.560]   working that well and needs to be fixed. - You kind of took my words. That's what I
[00:12:44.560 --> 00:12:48.080]   thought you were gonna ask me if I think the Ivy League is broken. That's totally,
[00:12:48.080 --> 00:12:50.400]   that's exactly it. - So you don't think, yeah. So on the
[00:12:50.400 --> 00:12:55.680]   question, do you think the Ivy League is broken, how do you think about it? The academia in general,
[00:12:55.680 --> 00:13:00.720]   I suppose, but Ivy League still, I think it represents some of the best qualities of academia.
[00:13:00.720 --> 00:13:04.800]   - Yeah, what more is there to say there? I think the Ivy League is producing tremendous
[00:13:04.800 --> 00:13:11.040]   thinkers to this day. I think the culture has a lot that can be improved, but I have a lot of
[00:13:11.040 --> 00:13:15.600]   faith in the people who are in these institutions. I think, like you said, the administration,
[00:13:15.600 --> 00:13:22.000]   and I have to be a little careful because I've been in some of these committees and I have talked
[00:13:22.000 --> 00:13:26.240]   to the administration about these sorts of things. I think they have a lot of stakeholders,
[00:13:26.240 --> 00:13:32.560]   and unfortunately it makes it difficult for them to always serve these brilliant faculty and the
[00:13:32.560 --> 00:13:37.520]   students in the way that they would probably like to. - Yeah, okay, so this is me speaking,
[00:13:37.520 --> 00:13:42.960]   right? The administration, I know the people, and they're oftentimes the faculty holding positions
[00:13:42.960 --> 00:13:44.400]   in these committees, right? - Yes.
[00:13:44.400 --> 00:13:53.760]   - But it's in the role of quote-unquote service, they're trying to do well. They're trying to do
[00:13:53.760 --> 00:14:02.000]   good, but I think you could say the mechanism is not working, but I could also say my personal
[00:14:02.000 --> 00:14:15.280]   opinion is they lack courage, and one, courage, and two, grace when they walk through the fire.
[00:14:15.280 --> 00:14:24.080]   So courage is stepping into the fire, and grace when you walk through the fire is like maintaining
[00:14:24.080 --> 00:14:32.880]   that, as opposed to being rude and insensitive to the lived quote-unquote experience of others,
[00:14:32.880 --> 00:14:40.240]   or just not eloquent at all, as you step in and take the courageous step of saying the difficult
[00:14:40.240 --> 00:14:45.920]   thing, doing it well, doing it skillfully. So both of those are important, the courage and the skill
[00:14:45.920 --> 00:14:51.120]   to communicate difficult ideas, and they often lack them because they weren't trained for it,
[00:14:51.120 --> 00:14:58.640]   I think. So you can blame the mechanisms that allow 19, 20-year-old students to have more power
[00:14:58.640 --> 00:15:04.560]   than the entire faculty, or you could just say that the faculty need to step up and grow some guts
[00:15:04.560 --> 00:15:08.000]   and skill of graceful communication. - And really administration.
[00:15:08.000 --> 00:15:13.040]   - Well, yeah, and the administration, that's right, that's the administration.
[00:15:13.040 --> 00:15:17.200]   - 'Cause the faculty are sometimes some of the most brave, outspoken people
[00:15:18.000 --> 00:15:26.960]   within the bounds of their career. - Yeah, so that's like the founding
[00:15:26.960 --> 00:15:33.440]   kind of spark of a fire that led you to then say, "Okay, so how can I help?"
[00:15:33.440 --> 00:15:39.200]   - Yeah, and I explored a lot, I explored a lot of options. I wrote many articles to my friends,
[00:15:39.200 --> 00:15:43.440]   talked to them, and I realized it sort of needed to be a cultural change, sort of needed to be
[00:15:43.440 --> 00:15:51.440]   bottom-up, grassroots, something. I knew the energy was there because you just look at the
[00:15:51.440 --> 00:15:56.960]   most recent institutional assessment from Yale, this was basically the number one thing that
[00:15:56.960 --> 00:16:02.560]   students, faculty, and alumni all pointed to, to the administration, was cultivating more
[00:16:02.560 --> 00:16:07.360]   conversations on campus and more difficult conversations on campus. So the people on
[00:16:07.360 --> 00:16:17.760]   campus know it. And you look at a Gallup poll, 61% of students on Ivy League campuses are afraid to
[00:16:17.760 --> 00:16:25.520]   speak their minds because of the campus culture. The campus culture is causing a sort of freezing
[00:16:25.520 --> 00:16:27.920]   effect on discourse. - Can you pause on that again?
[00:16:27.920 --> 00:16:31.360]   So what percentage of students feel afraid to speak their mind?
[00:16:31.360 --> 00:16:39.040]   - 61% nationally. And you're talking about places, nothing like the Ivy League, where I'd say,
[00:16:39.040 --> 00:16:45.920]   I'd imagine it would be even worse because of just the way that these communities kind of come
[00:16:45.920 --> 00:16:50.880]   about and the sorts of people who are attracted or are invited to these sorts of communities.
[00:16:50.880 --> 00:16:56.800]   That's nationwide, that college students, and it's going up, that college students are afraid to
[00:16:57.680 --> 00:17:03.360]   say what they believe because of their campus climate. So it's a majority. It's not a conservative
[00:17:03.360 --> 00:17:07.840]   thing, it's not a liberal thing, it's a group thing. We're all feeling it. The majority of
[00:17:07.840 --> 00:17:08.960]   us are feeling it. - And basically,
[00:17:08.960 --> 00:17:16.400]   you don't even necessarily need to have anything to say, you just have a fear.
[00:17:16.400 --> 00:17:19.200]   - That's right. - So when you're teaching,
[00:17:19.200 --> 00:17:26.320]   metaphor is a really powerful thing to explain. And there's just the caution that you feel that's
[00:17:26.320 --> 00:17:32.000]   just horrible for humor. Now, comedians have the freedom to just talk shit, which is why I really
[00:17:32.000 --> 00:17:39.760]   appreciate somebody who's been a friend recently, Tim Dillon, who gives zero, pardon my French,
[00:17:39.760 --> 00:17:46.000]   fucks about anything, which is very liberating, very important person to just tear down the
[00:17:46.000 --> 00:17:53.600]   powerful. But inside the academia, as an educator, as a teacher, as a professor, you don't have the
[00:17:53.600 --> 00:17:59.360]   same freedom. So that fear is felt, I guess, by a majority of students. - And you were getting
[00:17:59.360 --> 00:18:04.960]   at something there too, which is that if you're afraid to speak metaphorically, if you're afraid
[00:18:04.960 --> 00:18:10.800]   to speak imprecisely, it can be very difficult to actually think at all and to think to the
[00:18:10.800 --> 00:18:15.600]   extremities of what you're capable of. Because these are the mechanisms we use when we don't
[00:18:15.600 --> 00:18:20.160]   have quite the precise mathematical language to quite pinpoint what we're talking about yet.
[00:18:20.160 --> 00:18:25.440]   This is the beginning. This is the creative step that leads to new knowledge. And so that really
[00:18:25.440 --> 00:18:31.040]   scares me is that if I'm not allowed to sort of excavate these things, these ideas with people
[00:18:31.040 --> 00:18:34.720]   in the sort of messy, sloppy way that we do as humans when we're first being creative,
[00:18:34.720 --> 00:18:39.600]   are we going to be able to continue to innovate? Are we going to continue to be able to learn?
[00:18:39.600 --> 00:18:44.960]   That's what really starts to scare me. - So you've explored a bunch of different ideas. You
[00:18:44.960 --> 00:18:51.920]   wrote a bunch of different stuff. How did Librex come about? - Basically, it came to me that it had
[00:18:51.920 --> 00:18:56.400]   to be kind of a grassroots movement and it had to be something that changed culturally. And it had
[00:18:56.400 --> 00:19:02.880]   to be relatively personal. People meeting people. People finding out that, "No, I'm not the only one
[00:19:02.880 --> 00:19:08.640]   on campus who feels this way. I feel alone, and there are a lot of other people who feel alone.
[00:19:08.640 --> 00:19:16.320]   I believe this thing, and it's not as unpopular as I thought." Basically creating heterodoxy of
[00:19:16.320 --> 00:19:22.800]   thought. And it's creating that moment where you realize that your politics are personal and that
[00:19:22.800 --> 00:19:29.280]   your politics are shared by a lot of people on campus. And so I just started coding it. I didn't
[00:19:29.280 --> 00:19:37.040]   have much coding experience, but went head first in and figured how hard could it be? - I mean,
[00:19:37.040 --> 00:19:42.000]   this is really fascinating. So I talked to a lot of software engineers, AI people. Obviously,
[00:19:42.000 --> 00:19:49.200]   that's where my passion, my interests are. My focus has been throughout my life. The fascinating
[00:19:49.200 --> 00:19:55.760]   thing about your story, I think it should be truly inspiring to people that want to change the world,
[00:19:55.760 --> 00:20:01.520]   is that you don't have a background in programming. You don't have even maybe a technical
[00:20:01.520 --> 00:20:10.400]   background. So you saw a problem, you explored different ideas, and then you just decided you're
[00:20:10.400 --> 00:20:16.720]   going to learn how to build an app without a technical background. You didn't try to...
[00:20:16.720 --> 00:20:25.680]   That's so bold. That is so beautiful, man. Can you take me through the journey of deciding to
[00:20:25.680 --> 00:20:31.120]   do that, of learning to program without a programming background, and building the app?
[00:20:31.120 --> 00:20:38.560]   Detail, what do you actually... How do you start? - Sure. I mean, you want to buy a Mac. I learned
[00:20:38.560 --> 00:20:42.720]   you had to buy a Mac. I'm just going to go step by step, right? I'll be as dumb as possible.
[00:20:42.720 --> 00:20:50.800]   It was truly leading by your feet. - So you needed a computer for this. - Oh yeah, I had a PC at the
[00:20:50.800 --> 00:20:56.320]   time, and I was Android at the time. And I realized it should be like an iOS app. And so
[00:20:56.320 --> 00:21:02.720]   that was a decision. But I knew kids these days, they're always on their phone. And I wanted you
[00:21:02.720 --> 00:21:08.400]   to be able to say a passing thought in class, make a passing... You're walking around and you have a
[00:21:08.400 --> 00:21:12.000]   thought and you can express it. Or you're in the dining hall and you have your phone out, you can
[00:21:12.000 --> 00:21:16.720]   express it. So it was clear to me it should be an iOS app. - By the way, Android is great.
[00:21:17.520 --> 00:21:20.880]   Definitely check that out. - We also are now available on Android, but we'll get there
[00:21:20.880 --> 00:21:27.920]   for the Android users from MIT, Stanford, or the Ivy League. So back to how it happened. So I
[00:21:27.920 --> 00:21:34.400]   realized I needed a Mac. So went out and got a Mac. And I realized I needed an iPhone for testing
[00:21:34.400 --> 00:21:41.520]   eventually. Got an iPhone. So those were the real robot blocks to start with. From there, I mean,
[00:21:41.520 --> 00:21:45.520]   there's almost too much information out there about programming. The question is like, where do
[00:21:45.520 --> 00:21:52.640]   you start and what's going to be useful to you? And my first thought was I should look at some
[00:21:52.640 --> 00:21:56.640]   Yale classes, but it became very clear very quickly that that was not the right place to start.
[00:21:56.640 --> 00:22:02.320]   That would probably be the right place to start if I wanted to get a job at Amazon, but my goal
[00:22:02.320 --> 00:22:08.480]   was slightly different. And I definitely had it in mind that what I was trying to make was I'm
[00:22:08.480 --> 00:22:12.480]   trying to prove out an idea. I'm not trying to make a finished product. I'm just trying to get
[00:22:12.480 --> 00:22:20.400]   to the first step. Because I figured if I keep getting to the next step, at least I won't die
[00:22:20.400 --> 00:22:25.440]   now. At least things will move forward. I'll learn new things. Maybe I'll meet new people.
[00:22:25.440 --> 00:22:30.240]   I'll show a degree of seriousness about what I'm doing, and things will come together. And that is,
[00:22:30.240 --> 00:22:36.560]   as you'll see, what ends up happening. So I start with Swift, right? And I find this video from the
[00:22:36.560 --> 00:22:41.840]   Stanford professor that had a million views that was like, how to make basically Swift apps perfect.
[00:22:41.840 --> 00:22:48.400]   - And you just like, so you got this Mac and you went like, go to google.com and you type in--
[00:22:48.400 --> 00:22:49.200]   - Download Xcode.
[00:22:49.200 --> 00:22:50.160]   - Xcode.
[00:22:50.160 --> 00:22:58.080]   - Yeah, and then I type it on YouTube like, Stanford iOS Swift, enter. First YouTube video
[00:22:58.080 --> 00:23:01.520]   has a million views. I'm like, it has to be good at Stanford, has a million views.
[00:23:01.520 --> 00:23:06.000]   I got lucky. I mean, that turned out to be a very good video.
[00:23:06.000 --> 00:23:08.880]   - And it's basically like introductory course to Swift.
[00:23:08.880 --> 00:23:12.640]   - Yeah, I mean, you say introductory. I think most of the people in that class
[00:23:12.640 --> 00:23:15.600]   probably had a much better background than I did.
[00:23:15.600 --> 00:23:18.480]   - They're software developers probably. They're computer scientists.
[00:23:18.480 --> 00:23:24.000]   - And it was slow for me. I don't think I realized it fully at the time, just how far behind I was
[00:23:24.000 --> 00:23:27.520]   from the rest of the class. 'Cause I was like, wow, it seems like people are picking this up
[00:23:27.520 --> 00:23:33.600]   really quickly. So it took a little longer and a lot of time on Stack Overflow. But eventually I
[00:23:33.600 --> 00:23:40.400]   made a truly minimal viable product. The most minimal, like we're talking, put text on screen,
[00:23:40.400 --> 00:23:49.120]   add text to screen, comment on top of text, make a post, make a response. And anyone with a Yale
[00:23:49.120 --> 00:23:58.400]   email can do this. And you plug it into a cloud server and you verify people's accounts and you're
[00:23:58.400 --> 00:23:58.880]   off. You have--
[00:23:59.040 --> 00:24:04.400]   - You have to figure out how to, like the whole idea of like having an account. So there's a
[00:24:04.400 --> 00:24:07.920]   permanence, like you can create an account with an email.
[00:24:07.920 --> 00:24:08.800]   - Verify it.
[00:24:08.800 --> 00:24:12.160]   - Verify it. Okay. So that's not, you know--
[00:24:12.160 --> 00:24:15.520]   - And that's literally how I thought about it, right? Like, so what do I need to do? And I'm
[00:24:15.520 --> 00:24:21.120]   like, well, first thing I need is a login page. And I'm like, how to make a login page in Swift?
[00:24:21.120 --> 00:24:24.560]   I mean, it's that easy. If someone, this has been done before, of course--
[00:24:24.560 --> 00:24:28.000]   - And then the first page that pops up was probably a pretty damn good page when you--
[00:24:28.000 --> 00:24:32.560]   - It wasn't that bad. It wasn't perfect, but like maybe it got me 80% of the way there.
[00:24:32.560 --> 00:24:32.880]   - Yeah.
[00:24:32.880 --> 00:24:37.360]   - And then I came into some bugs and then, you know, I asked Stack Overflow a few questions
[00:24:37.360 --> 00:24:41.680]   and then I got a little further and then I found some more bugs. And then I'm like,
[00:24:41.680 --> 00:24:45.280]   maybe this isn't the right way to do it. Maybe I should do it this way. And I'm sure my code
[00:24:45.280 --> 00:24:49.440]   isn't great, but the goal isn't to make great code. The goal wasn't to make scalable code.
[00:24:49.440 --> 00:24:54.560]   It was to understand, is this something my friends will use? Like, what is the reaction
[00:24:54.560 --> 00:24:58.240]   going to be if I put it in their hands? And am I capable of making this thing?
[00:24:58.240 --> 00:25:03.760]   - That's awesome. And so you're just focusing on the experience, like actually just really
[00:25:03.760 --> 00:25:08.240]   driving towards that first step, figuring out the first step and really driving towards it.
[00:25:08.240 --> 00:25:13.360]   Of course, you have to also figure out like this concept of like storage, like database.
[00:25:13.360 --> 00:25:14.480]   - You know something funny?
[00:25:14.480 --> 00:25:15.040]   - What's that?
[00:25:15.040 --> 00:25:19.280]   - I just made the database structure with no knowledge of databases whatsoever.
[00:25:19.280 --> 00:25:23.360]   And I start showing it to my friends who have an experience in CS and they're like,
[00:25:23.360 --> 00:25:28.320]   you used a heap, that's so interesting. You're like, why did you decide to store it in this way?
[00:25:28.320 --> 00:25:34.880]   I'm like, bro, I don't even know what a heap is. I just did it 'cause it works. Like,
[00:25:34.880 --> 00:25:38.000]   I'm trying to make calls and stuff. And they're like, yeah, they're like,
[00:25:38.000 --> 00:25:40.000]   the hierarchy is really like, and I'm like, what?
[00:25:40.000 --> 00:25:44.880]   - Well, there's a deep, profound lesson in there that I don't know how much you've interacted
[00:25:44.880 --> 00:25:49.760]   with computer science people since, but they tend to optimize and have these kinds of discussions.
[00:25:49.760 --> 00:25:55.600]   And what results is over-optimization. It's like worrying, is this really the right way to do it?
[00:25:55.600 --> 00:26:00.640]   And then you go, as opposed to doing the first thing on Stack Overflow, you go down this like
[00:26:00.640 --> 00:26:06.960]   rabbit hole of what's the actual proper way to do it. And then you're like, you wake up five years
[00:26:06.960 --> 00:26:13.120]   later working on Amazon because you've never finished the login page. Like, it's kind of
[00:26:13.120 --> 00:26:20.880]   hilarious, but that's a really deep lesson. Like, just get it done. And there's like, what's a heap,
[00:26:20.880 --> 00:26:27.520]   bro? Is the right, that should be a T-shirt. That's really the right approach to building
[00:26:27.520 --> 00:26:34.880]   something that ultimately creates an experience. And then you iterate eventually. That's how some
[00:26:34.880 --> 00:26:39.920]   of the greatest software products in this world have been built, is you create it quickly and
[00:26:39.920 --> 00:26:45.360]   then just iterate. What was, by the way, in your mind, the thing that you were chasing as a
[00:26:45.360 --> 00:26:52.000]   prototype? Like, what was the first step that it feels like something is working?
[00:26:52.000 --> 00:26:58.720]   Like, is it you interacting with another friend? - Yeah, I think the first step was like,
[00:26:58.720 --> 00:27:03.600]   it's one thing to tell someone about an idea, but it's another thing to put in their hands and kind
[00:27:03.600 --> 00:27:12.000]   of see the way their eyes kind of look. And when I'd go, I'd walk around cross campus, which is
[00:27:12.000 --> 00:27:15.840]   part of Yale, and I'd literally just go up to people and run up to them and be like, try this,
[00:27:15.840 --> 00:27:18.800]   try this, you gotta try this. This is pre-quarantine, by the way, of course. This would
[00:27:18.800 --> 00:27:22.560]   never be the same post-quarantine, but like, you gotta try this, you gotta try this. Like, what is
[00:27:22.560 --> 00:27:26.640]   it? And I'd be like, and I'd explain, it's like an anonymous discussion feed for our Yale campus.
[00:27:26.640 --> 00:27:32.640]   And you'd see their gears turning and they just, some people would be like, not interested. I'm
[00:27:32.640 --> 00:27:37.440]   like, fine, not your target demographic, I get it, you'll come eventually. But some people,
[00:27:37.440 --> 00:27:44.160]   like, you could see it, they got it. They're like, yes. And that's when I was like, okay, okay,
[00:27:44.160 --> 00:27:51.040]   there is, and you don't need, I mean, you don't need 50% of people to like it. You need what,
[00:27:51.040 --> 00:27:57.280]   5%, 10% to love it, and then they'll tell 5%, 10%. - Yeah, word of mouth, yeah. - And you're good.
[00:27:59.360 --> 00:28:03.920]   Of course, the first version was very, very crappy, but seeing people trying, despite all
[00:28:03.920 --> 00:28:09.920]   the crappiness, it was sort of enough to be the first step. And since then, all of my code's been
[00:28:09.920 --> 00:28:16.000]   stripped out. I now have friends who basically have told me, don't bother with the coding part,
[00:28:16.000 --> 00:28:20.320]   you do the rest, you just make sure that we can code, because they wanna code. Great. I mean,
[00:28:20.320 --> 00:28:23.760]   I'm not an engineer. I never intended to be an engineer, and there's a lot to do that's
[00:28:23.760 --> 00:28:31.120]   not engineering. But the point was just to validate the idea, so to speak. - When was the moment that
[00:28:31.120 --> 00:28:38.800]   you felt like, we've created something special? Maybe a moment where you're proud of that this is,
[00:28:38.800 --> 00:28:48.160]   this has the potential to actually be the very implementation of the idea that I initially had.
[00:28:48.160 --> 00:28:55.680]   - There's so many little moments. And I bet there'll still be moments in the future that make
[00:28:55.680 --> 00:29:00.880]   it hard to totally say. - Yeah, we should say this is still
[00:29:00.880 --> 00:29:05.280]   the very early days of LibreX. - Yeah. It's literally been a year.
[00:29:05.280 --> 00:29:07.200]   - It's only been a year? - Since we've had actual,
[00:29:07.200 --> 00:29:10.080]   a lot of people on the app, yeah, about a year. - Oh, wow, okay.
[00:29:10.080 --> 00:29:15.280]   - I mean, there's some crazy moments. I could talk about going to Dartmouth, 'cause it's one thing to
[00:29:15.280 --> 00:29:22.240]   get some traction at your school. People know you, and it's your school. It's another thing to go to
[00:29:22.240 --> 00:29:27.120]   another school where no one knows you and sign up 90% of the campus overnight.
[00:29:27.120 --> 00:29:31.520]   - Wow, so tell me that story. You're invading another territory.
[00:29:31.520 --> 00:29:35.520]   - It was literally like that. - Did you buy a Dartmouth sweatshirt?
[00:29:35.520 --> 00:29:42.000]   - Purposely, I didn't want to fraud anyone, but I was purposefully non-descript in my clothing.
[00:29:42.000 --> 00:29:49.680]   Yeah, no Yale stuff, no Dartmouth stuff, just blended. I'll go back there. So what happened was
[00:29:49.680 --> 00:29:59.600]   this was like March of last year, so almost a year ago today. And I really wanted to see if we could
[00:29:59.600 --> 00:30:06.720]   go from sort of one campus to two campuses. So I didn't know anyone at Dartmouth's campus, but I
[00:30:07.280 --> 00:30:15.680]   kind of had some cold emails, some warm-ish emails. And I went to people and I was like,
[00:30:15.680 --> 00:30:20.560]   basically, can I sleep on your floor for two days during finals period? I had a lot of people who
[00:30:20.560 --> 00:30:25.360]   said, this is crazy, like no one wants to download an app during finals period, a social app during
[00:30:25.360 --> 00:30:31.760]   finals period. But I emailed a few people, I was like, can I sleep on your floor? And one of them
[00:30:31.760 --> 00:30:38.880]   was crazy enough to say, sure, come to my dorm, I have a nice floor. And he ended up, today he's
[00:30:38.880 --> 00:30:44.240]   still really close, he's a really close friend. But anyway, I take a train knowing nothing about
[00:30:44.240 --> 00:30:52.480]   this guy besides his first and last name. And I arrive and Dartmouth is really, really remote,
[00:30:52.480 --> 00:30:58.560]   way more remote than you think to the point where I'm like, he's like, he warned me, he's a really
[00:30:58.560 --> 00:31:02.560]   hospitable guy. He warned me like, it's gonna be hard to get to campus from the train station
[00:31:02.560 --> 00:31:06.800]   because it's really remote. And I'm like, I'm sure it's fine, I'll just get an Uber. There are no
[00:31:06.800 --> 00:31:13.520]   Ubers in Hanover. What do you think this is? - It's New Hampshire. So Connecticut, I mean,
[00:31:13.520 --> 00:31:18.000]   Yale is pretty remote as well, no? - Yeah, Yale is, well, I mean,
[00:31:18.000 --> 00:31:23.120]   Yale's in New Haven, which is a real city. It has Ubers, it has food, it has culture,
[00:31:23.120 --> 00:31:27.360]   it has a nightclub even. Like we're talking about a real city, like it's not New York,
[00:31:27.360 --> 00:31:33.200]   it's not Philadelphia where I'm from, but it's a city. New Hampshire is something very different.
[00:31:33.200 --> 00:31:37.440]   - Yeah, beautiful campus, I'm sure. - Beautiful, oh my gosh, I could talk
[00:31:37.440 --> 00:31:42.880]   so much about, I was blown away by Dartmouth. I started wondering like why I didn't apply
[00:31:42.880 --> 00:31:50.800]   legitimately. Between the people and the culture, it was a beautiful vacation. So I arrived there,
[00:31:50.800 --> 00:31:55.520]   no Uber, but eventually I call this guy who's like the only guy who can get you to Dartmouth
[00:31:55.520 --> 00:32:00.720]   and it takes a couple hours, but we get there. I sleep on this guy's floor, I wake up, I ask him
[00:32:00.720 --> 00:32:04.400]   if there's any printing. He's like, "Oh, Dartmouth happens to have free printing in the copy room."
[00:32:04.400 --> 00:32:11.040]   I print out like 2000 posters until the guy in the copy room literally goes to me, he's like,
[00:32:11.040 --> 00:32:15.200]   "Kid, I don't know what you're doing, but you need to get out of here." I'm like, "All right,
[00:32:15.200 --> 00:32:17.600]   I'm going, I'm going." - You found the limits.
[00:32:17.600 --> 00:32:21.920]   - I know, yeah, I found the limit. And I think a lot of startups is about finding the limits.
[00:32:22.480 --> 00:32:27.280]   Maybe that's a little piece of advice socially. He's like, "You gotta get out of here." And I
[00:32:27.280 --> 00:32:34.960]   then go to every single dorm door, I put a poster under every single dorm door advertising the app
[00:32:34.960 --> 00:32:41.760]   with a QR code. I walk around campus saying hi to everyone and telling them about the app. I go from
[00:32:41.760 --> 00:32:46.240]   table to table in the cafeteria, introduce myself, say hi, and tell them to download the app.
[00:32:46.240 --> 00:32:52.080]   It's exhausting, there's so many steps, so many crotching down to slip the poster under the dorm
[00:32:52.080 --> 00:33:01.040]   door, my legs were burning. But by the end of it, 24 hours later, I'm sitting in a bus and I'm just
[00:33:01.040 --> 00:33:05.680]   pressing the refresh button on the account creation panel. It's like going up by hundreds.
[00:33:05.680 --> 00:33:10.720]   And I'm like, "Oh my gosh." - The word of mouth is working in a sense.
[00:33:10.720 --> 00:33:15.040]   I mean, certainly your initial seed is powerful. - Just a piece.
[00:33:15.040 --> 00:33:20.320]   - Yeah, but then the word of mouth is what carries it forward. And what was the explanation you gave
[00:33:20.320 --> 00:33:28.080]   to the app? Is anonymity a fundamental part of it? Like saying, "This is a chance for you to speak
[00:33:28.080 --> 00:33:36.000]   your mind about your experiences on campus." - Yeah, I think people get it. What I've realized
[00:33:36.000 --> 00:33:41.920]   is you don't need to tell people why to try it, they know. - There's a hunger for this.
[00:33:41.920 --> 00:33:48.720]   - Exactly. So all I do is I'm very factual, I said, and this is where I kind of ended up coining the
[00:33:49.360 --> 00:33:55.360]   kind of the line that I now use to say it because I said it so many times in those 24 hours. I just
[00:33:55.360 --> 00:33:59.760]   said it's an anonymous discussion feed for Dartmouth. And they're like, "Yes."
[00:33:59.760 --> 00:34:06.320]   Like they've been waiting for it. Some people are more skeptical, but a lot of people were like,
[00:34:06.320 --> 00:34:12.240]   "Great, I'm excited to try this. I'm excited to meet people and connect." And I mean, the way
[00:34:12.240 --> 00:34:18.640]   Dartmouth's taken to it is incredible. Everything from professors writing poems during finals period
[00:34:18.640 --> 00:34:23.520]   to be like, "Good luck in finals period, you're gonna rise like a phoenix," or whatever,
[00:34:23.520 --> 00:34:30.480]   to like, "Yeah, it's crazy." I heard about two women meeting on Librex and starting a finance
[00:34:30.480 --> 00:34:38.720]   club at Dartmouth, two significant others meeting. There was an article recently written up at Yale
[00:34:38.720 --> 00:34:43.520]   as well about two queer women who met on Librex and started a relationship, which was pretty,
[00:34:43.520 --> 00:34:49.040]   it was pretty interesting to see people throwing parties pre-COVID. Yeah, it was just amazing to
[00:34:49.040 --> 00:34:54.000]   see how when you allow people to be vulnerable and social, they connect. People have this natural
[00:34:54.000 --> 00:34:58.960]   desire to connect. - Yeah, when you have, when they have a natural desire to have a voice,
[00:34:58.960 --> 00:35:07.840]   and then when that voice is paired with freedom, then you could truly express yourself. And there's
[00:35:07.840 --> 00:35:14.240]   something liberating about that. And in that sense, you're connecting as your true self,
[00:35:14.240 --> 00:35:18.720]   whatever that is. What are the most powerful conversation you've seen on the app? You
[00:35:18.720 --> 00:35:24.480]   mentioned people connecting. - The hard part about that is the sorting, figuring out which one am I
[00:35:24.480 --> 00:35:28.400]   gonna put at the top. - Mental sorting. Just something that stands out to you. Sorry, I don't
[00:35:28.400 --> 00:35:33.920]   mean to do the top 10 conversations ever of all time, ever on the app. I just mean stuff that you
[00:35:33.920 --> 00:35:39.200]   remember that stands out to you. - I remember this one really amazing comment from this,
[00:35:39.200 --> 00:35:48.160]   he was a Mexican international student who spoke out, and this post was super edgy,
[00:35:48.160 --> 00:35:53.600]   but yet it got hundreds and hundreds of upvotes within the Yale community. It was a Yale community
[00:35:53.600 --> 00:35:58.080]   specific post. And we should point out that there's a school specific community now, and
[00:35:58.080 --> 00:36:02.960]   there's an all Ivy community. So this was specifically in the Yale community. And this
[00:36:02.960 --> 00:36:09.840]   was a little while ago, but it stuck with me. This Mexican international student comes to Yale,
[00:36:09.840 --> 00:36:16.960]   and he starts talking about his experience in the La Casa, which is the Mexican Latinx,
[00:36:16.960 --> 00:36:22.880]   as they would say, cultural center at Yale, and how he doesn't feel welcome there because he's
[00:36:22.880 --> 00:36:29.120]   Roman Catholic, basically, and international, and how he doesn't feel like he fits with their
[00:36:29.120 --> 00:36:34.240]   agenda. And as a result, this place that's supposed to be home for him, he feels outcasted
[00:36:34.240 --> 00:36:39.360]   and feels more alone than he does anywhere else on campus. - That's powerful. - That was powerful
[00:36:39.360 --> 00:36:45.600]   to me. Yeah. Hearing someone who should be feeling supported by this culture say,
[00:36:45.600 --> 00:36:53.920]   "Actually, this is not doing anything for me. This is not helping me. This is not where I feel
[00:36:53.920 --> 00:37:02.640]   at home." - So what do you make of anonymity? Because it seems to be a fundamental aspect
[00:37:02.640 --> 00:37:08.400]   of the power of the app, right? But at the same time, anonymity on the internet,
[00:37:08.400 --> 00:37:15.840]   so it protects us, right? It gives us freedom to have a voice, but it can also bring out the
[00:37:15.840 --> 00:37:22.240]   dark sides of human nature, like trolls or people who want to be malicious, want to hurt others
[00:37:22.800 --> 00:37:30.400]   purely for the joy of hurting others, being cruel for fun, and going to the dark places. So
[00:37:30.400 --> 00:37:35.040]   what do you make of anonymity as a fundamental feature of social interaction,
[00:37:35.040 --> 00:37:40.160]   like the pros and the cons? - Yeah, just to break that down a bit, I would say a lot of those same
[00:37:40.160 --> 00:37:46.000]   things about a place like Twitter, where people are very unanonymous. Having said that, of course,
[00:37:46.000 --> 00:37:52.000]   there's a different sort of capacity people have when they're anonymous, right? In all different
[00:37:52.000 --> 00:37:57.040]   sorts of ways. So what do I make of anonymity? I think it can be incredibly liberating and allow
[00:37:57.040 --> 00:38:02.000]   people to be incredibly vulnerable and to connect in different ways, both on politics, and there was
[00:38:02.000 --> 00:38:08.400]   a lot to talk about this year regarding politics, and personally, being vulnerable, talking about
[00:38:08.400 --> 00:38:13.760]   relationships and mental health. I think it allows people to have a community that's not performative.
[00:38:13.760 --> 00:38:21.440]   And of course, there's this other side where people can sometimes break rules or say things
[00:38:21.440 --> 00:38:25.200]   that they wouldn't otherwise say that people don't always agree with, or that people might
[00:38:25.200 --> 00:38:31.600]   find repugnant. And to an extent, these can facilitate great conversations. And on the other
[00:38:31.600 --> 00:38:36.000]   hand, we have to have moderation in place, and we have to have community guidelines to make sure
[00:38:36.000 --> 00:38:42.480]   that the anonymity doesn't overwhelm the purpose, which is that anonymity, first of all, anonymity
[00:38:42.480 --> 00:38:48.560]   is a tool in LibreX. It was not the purpose of LibreX. It is a way that we get towards these
[00:38:48.560 --> 00:38:55.600]   authentic conversations given our campus climate. And second of all, I would say it's a spectrum.
[00:38:55.600 --> 00:39:05.200]   It's not just LibreX is anonymous, right? Because LibreX isn't totally anonymous. Everyone's a
[00:39:05.200 --> 00:39:10.400]   verified Ivy League student. You know exactly what school everyone goes to. You only have
[00:39:10.400 --> 00:39:18.240]   one account per person at Yale, meaning that, I mean, what that amounts to is people have more
[00:39:18.240 --> 00:39:21.200]   of an ownership in the community, and people know that they're connected and they have a
[00:39:21.200 --> 00:39:27.120]   common vernacular. So the anonymity is a scale and it's a tool. - But you can also trust, I mean,
[00:39:27.120 --> 00:39:32.480]   this is the difference between Reddit anonymity, where you can easily create multiple accounts.
[00:39:32.480 --> 00:39:39.760]   When you have only one account per person, or at least it's very difficult to create multiple
[00:39:39.760 --> 00:39:45.120]   accounts, then you can trust that the anonymous person you're talking to is a human being.
[00:39:45.120 --> 00:39:48.080]   - Not a bot. - I try to be completely
[00:39:48.080 --> 00:39:54.640]   unanonymous now in my public interactions. I try to be as real in every way possible,
[00:39:54.640 --> 00:40:01.280]   like zero gap between private me and public me. - Why exactly did you, it seems like this is an
[00:40:01.280 --> 00:40:06.800]   intentional mission. What made you want to sort of bridge that gap between the private sphere and
[00:40:06.800 --> 00:40:11.920]   public sphere? 'Cause that's unique. I know a lot of intellectuals who would make a different
[00:40:11.920 --> 00:40:18.000]   decision. - Yeah, interesting. I had a discussion about with Naval about this, actually, with a few
[00:40:18.000 --> 00:40:24.960]   others that have a very clear distinction between public and private. - Something I'm struggling
[00:40:24.960 --> 00:40:36.320]   with, by the way, personally, and thinking about. - So one on the very basic surface level is if you
[00:40:36.320 --> 00:40:49.600]   carry with yourself lies, small lies or big lies, it's extramental effort to remember what you're
[00:40:49.600 --> 00:40:55.760]   supposed to say and not supposed to say. So that's on a very surface level of like, it's just easier
[00:40:55.760 --> 00:41:00.480]   to live life when you have the smaller of the gap between the private you and the public you.
[00:41:02.320 --> 00:41:08.240]   The second is, I think for me, from an engineering perspective,
[00:41:08.240 --> 00:41:15.840]   like if I'm dishonest with others, I will too quickly become dishonest with myself.
[00:41:15.840 --> 00:41:22.240]   And in so doing, I will not truly be able to think deeply about the world and come up and
[00:41:22.240 --> 00:41:27.840]   build revolutionary ideas. There's something about honesty that feels like it's that first
[00:41:27.840 --> 00:41:33.280]   principles thinking that's almost like overused as a term, but it feels like that requires radical
[00:41:33.280 --> 00:41:39.360]   honesty, not radical asshole and lichness, but radical honesty with yourself, with yourself.
[00:41:39.360 --> 00:41:46.320]   And it feels like it's difficult to be radically honest with yourself when you're being dishonest
[00:41:46.320 --> 00:41:53.680]   with the public. And also I have a nice feature, honestly, that in this current social context,
[00:41:53.680 --> 00:42:00.320]   so we can talk about race and gender and what are the other topics that are touchy?
[00:42:00.320 --> 00:42:03.520]   - Ethnicity and nationality.
[00:42:03.520 --> 00:42:05.040]   - All those things. I mean like...
[00:42:05.040 --> 00:42:06.240]   - Family structure.
[00:42:06.240 --> 00:42:12.320]   - Maybe I'm ineloquent in the way I speak about them, but I honestly, when I look in the mirror,
[00:42:12.320 --> 00:42:19.920]   like I'm not deeply hateful of a particular race or even just hateful of a particular race.
[00:42:20.720 --> 00:42:25.680]   I'm sure I'm biased and I've tried to think about those biases and so on. And also I don't have any
[00:42:25.680 --> 00:42:35.120]   creepy shit in my closet about women. It seems like a lot of people did a lot of creepy stuff
[00:42:35.120 --> 00:42:42.720]   in their life. And I just feel like that's really nice and deliberating. And especially now,
[00:42:42.720 --> 00:42:47.840]   it's funny because I've gotten a bit of a platform and I think it all started when I went,
[00:42:47.840 --> 00:42:56.480]   this is a female comedian, Whitney Cummings. And I've gotten a lot of amazing women writing me
[00:42:56.480 --> 00:43:02.720]   throughout, but when I went on Whitney, it was like the number of DMs I get on Instagram
[00:43:02.720 --> 00:43:10.720]   from women is just ridiculous. And I think that was a really important moment for me is like,
[00:43:11.600 --> 00:43:18.080]   I speak and I feel, I really value love, long-term monogamy with one person.
[00:43:18.080 --> 00:43:26.640]   And it's like, I could see where a lot of guys would now continue that message in public and
[00:43:26.640 --> 00:43:31.440]   in private, just start sleeping around. And so that's an important statement for me mentally.
[00:43:31.440 --> 00:43:33.840]   It's like, nope. - Straight and narrow.
[00:43:33.840 --> 00:43:37.600]   - It just goes straight and narrow. And not out of fear, but out of principle and just
[00:43:38.880 --> 00:43:47.200]   live life honestly. And I feel like that's truly liberating as a human being. Forget public,
[00:43:47.200 --> 00:43:51.280]   all that, because then I feel like I'm on sturdy ground when I say
[00:43:51.280 --> 00:43:57.280]   difficult things. And at the same time, sorry, I'm ranting on this, I apologize.
[00:43:57.280 --> 00:44:05.040]   - I'm interested personally, so keep going. - I honestly believe in the internet,
[00:44:07.040 --> 00:44:12.880]   in people on the internet, that when they hear me speak, they can see if I'm full of shit or not.
[00:44:12.880 --> 00:44:23.920]   I won't be able to fake it. They'll see it through. Yeah. So I feel like if you're not
[00:44:23.920 --> 00:44:30.400]   lying about stuff, you have the freedom to truly be yourself and the internet will figure it out.
[00:44:30.400 --> 00:44:33.840]   Will figure who you are. - People have a natural
[00:44:33.840 --> 00:44:37.280]   tendency to be able to tell bullshit. And it makes sense from an evolutionary standpoint.
[00:44:37.280 --> 00:44:39.840]   - Exactly. - Why wouldn't, why,
[00:44:39.840 --> 00:44:47.680]   of all the things that we could evolve to be good at, being able to detect honesty seems like one
[00:44:47.680 --> 00:44:51.760]   that would be particularly valuable, especially in the sorts of societies we developed into.
[00:44:51.760 --> 00:44:57.440]   - And then also from a selfish perspective, like a success perspective, I think there's a lot of
[00:44:57.440 --> 00:45:06.080]   folks that have inspired me, like Elon is one of them, that shows that there's a hunger for genuineness.
[00:45:06.080 --> 00:45:14.240]   Like you can build a business as a CEO and be genuine and like real and do stupid shit every
[00:45:14.240 --> 00:45:18.240]   once in a while, as long as it's coming from the same place of who you truly are.
[00:45:18.240 --> 00:45:22.240]   Like Elon's inspirational with that. And then there's a lot of other people I admire
[00:45:23.120 --> 00:45:31.120]   that are counter-inspirations in the sense like they're very formal, they hold back a lot of
[00:45:31.120 --> 00:45:35.920]   themselves. And it's like, I know how brilliant those people are and I think they're not being
[00:45:35.920 --> 00:45:42.640]   as effective of leaders, public faces of companies as they could be. I mean, to be honest, like,
[00:45:42.640 --> 00:45:48.080]   not to throw shade, but I will, is like Mark Zuckerberg is an example of that.
[00:45:49.440 --> 00:45:54.400]   Jack Dorsey's also a bit of an example of that. I like Jack a lot. I've talked to him a lot.
[00:45:54.400 --> 00:46:02.400]   I will talk to him more. I think he's a much more amazing person than he conveys through his public
[00:46:02.400 --> 00:46:08.320]   presentation. I think a lot of that has to do with PR and marketing people having an effect.
[00:46:08.320 --> 00:46:11.840]   Listen, it's difficult. I think it's really difficult. It's probably many of the same
[00:46:11.840 --> 00:46:19.120]   difficulties you will face is the pressures, but it's hard to know what to do. But I think
[00:46:19.120 --> 00:46:25.840]   as much as possible as an individual, you should try to be honest in the face of the world and the
[00:46:25.840 --> 00:46:32.240]   company that wants you to be more polished. And that being more polished turns you into a
[00:46:32.240 --> 00:46:38.000]   politician and politician eventually turns into being dishonest. Dishonest with the world and
[00:46:38.000 --> 00:46:42.000]   dishonest with yourself. - Something I noticed, which was the people, of the people you mentioned,
[00:46:42.000 --> 00:46:48.480]   those things have had ramifications in terms of letting things go too far, get out of hand. And
[00:46:48.480 --> 00:46:55.920]   you wonder, it's an aspect of lying, right? You say one lie goes to another lie, you push it down,
[00:46:55.920 --> 00:47:00.320]   it doesn't matter. You can figure it out later. You can figure out later. Pretty soon,
[00:47:00.320 --> 00:47:06.480]   you've dug a pretty big hole. And I think if we look at Twitter and we look at Facebook,
[00:47:06.480 --> 00:47:12.720]   I think it goes without saying what sorts of holes have been dug, perhaps because of a lack
[00:47:12.720 --> 00:47:17.280]   of honesty that goes all the way up to the leaders. - So yeah, there's two problems within
[00:47:17.280 --> 00:47:24.000]   the company. It doesn't make you as effective of a leader, I think. That's one. And two,
[00:47:24.000 --> 00:47:30.160]   for social media companies, I think people need to trust, like, it doesn't have to be the CEO,
[00:47:30.160 --> 00:47:36.000]   but it has to be, like, this is how humans work. We want to look to somebody where like,
[00:47:36.000 --> 00:47:44.000]   I trust you. If you're going to use a social media platform, I think you have to trust
[00:47:44.960 --> 00:47:50.560]   the set of individuals working at the top of that social. - Something I realized really quickly,
[00:47:50.560 --> 00:47:56.480]   one of the lessons throughout the startup was that people don't totally connect to products as
[00:47:56.480 --> 00:48:03.920]   much as they connect to people. And I mean, I don't know how much you've spent on Librex,
[00:48:03.920 --> 00:48:09.680]   you've only been here the last couple of weeks, like last week, but I mean, I love the product.
[00:48:09.680 --> 00:48:14.640]   And one of the aspects of me loving the product is that I'm super active and I've been super
[00:48:14.640 --> 00:48:20.560]   active throughout the entire time. And the amount of support I've received has made that very easy
[00:48:20.560 --> 00:48:26.320]   to do from the community and the fact that I could, I mean, so I came to Boston for this interview,
[00:48:26.320 --> 00:48:34.560]   right? I came to Boston, I got off the train, it was around 5.30 PM, I checked Librex, someone
[00:48:34.560 --> 00:48:38.720]   is writing, "Hey, I'm in Boston, does anyone want to get dinner?" 30 minutes later, I'm getting
[00:48:38.720 --> 00:48:45.440]   dinner with them. - That's amazing. - And I mean, it's incredible. First of all, as an entrepreneur,
[00:48:45.440 --> 00:48:52.000]   the amount of stuff I learn from these people and when they reiterate and I hear that they got the
[00:48:52.000 --> 00:48:57.120]   message through the product, I mean, that's incredibly validating. But also, I mean, I think
[00:48:57.120 --> 00:49:01.840]   it's just important to be able to put a face to a brand and especially a brand that's built on trust.
[00:49:02.960 --> 00:49:09.440]   Because fundamentally, the users are trusting us with some really important discussions and some
[00:49:09.440 --> 00:49:14.800]   really, and a movement to some degree. It's a community and a movement. - I'll tell you actually
[00:49:14.800 --> 00:49:22.240]   why I didn't use the app very much so far is there's something really powerful about the way
[00:49:22.240 --> 00:49:28.480]   it's constructed, which I felt like a bit of an outsider 'cause I don't know the communities. It
[00:49:28.480 --> 00:49:35.520]   felt like it's a really strong community around each of these places. And so I felt like I was,
[00:49:35.520 --> 00:49:41.840]   it made me really wish there was an MIT one. And so there's both discussions about the deep
[00:49:41.840 --> 00:49:50.640]   like community issues within Columbia or Yale or so on, Dartmouth. And there's also the broader
[00:49:50.640 --> 00:49:54.880]   community of the Ivy Leagues that people are discussing. But I could see that actually
[00:49:54.880 --> 00:50:01.200]   expanding more and more and more, but which is a powerful coupling, which is the feeling of like
[00:50:01.200 --> 00:50:06.560]   this little village, this little community we're building together, but also the broader issues.
[00:50:06.560 --> 00:50:08.320]   - Yeah. - So you can do both
[00:50:08.320 --> 00:50:10.720]   discussions. - One thing that was important to me is
[00:50:10.720 --> 00:50:19.200]   talking about social media as a concept, right? I think the way people socialize is very much
[00:50:19.200 --> 00:50:25.520]   context dependent. So we're talking about people understanding each other through language,
[00:50:25.520 --> 00:50:32.880]   through English. And these languages are constructed in a very nuanced way, in a very
[00:50:32.880 --> 00:50:39.920]   sort of temperamental way, right? And you kind of need a similar context to be able to have
[00:50:39.920 --> 00:50:46.560]   productive conversations. So to me, it's really important that these groups, they share something
[00:50:46.560 --> 00:50:52.880]   in common, a really big lived experience, the Ivy League or their school community. And they have a
[00:50:52.880 --> 00:50:57.120]   similar vocabulary, they have a similar background, they know what's happening in their community.
[00:50:57.120 --> 00:51:02.800]   And so having social media that is community connected to me was fundamental. Like you talk
[00:51:02.800 --> 00:51:08.480]   about anonymity, to me, community is the thing that when I think about Librex, I think what
[00:51:08.480 --> 00:51:14.160]   makes it different. It's the fact that everyone knows what's going on. Everyone comes from a
[00:51:14.160 --> 00:51:20.320]   similar context and people can socialize in a way where they understand each other because they've
[00:51:20.320 --> 00:51:24.240]   been through, you used the word lived experience, they've been through so many of the same lived
[00:51:24.240 --> 00:51:33.600]   experiences. - One clarification, is there an easy way, if you choose, to then connect and meet space
[00:51:33.600 --> 00:51:41.440]   and physical space? - So I guess the sort of magic of it, and I was talking to a bunch of Harvard
[00:51:41.440 --> 00:51:46.800]   Librexers who I met off the app while I was in Boston. And every time they told me, this is my
[00:51:46.800 --> 00:51:50.320]   favorite part of the app, this is what I love about the app. We have this matching system,
[00:51:50.320 --> 00:51:57.120]   which is an anonymous direct message that you can send to any poster. So I was talking to this guy
[00:51:57.120 --> 00:52:04.560]   who, he was really into coin collection, and he met other people who were really into coin
[00:52:04.560 --> 00:52:09.920]   collection through a post and he would make a post about coin collection. And then someone would come
[00:52:09.920 --> 00:52:14.400]   to him and they'd be like, and they could direct message him anonymously and it would just show
[00:52:14.400 --> 00:52:19.040]   them that his, it would just show him their school. And then they could just text chat,
[00:52:19.040 --> 00:52:24.080]   totally anonymously, direct message if he accepted the anonymous request. - Do they see the usernames?
[00:52:24.080 --> 00:52:31.200]   - There are no usernames on Librex. It's all just schools names. So he made this post about coin
[00:52:31.200 --> 00:52:39.760]   collection and you got a direct message. - Yeah, I guess so, right? - No usernames. - Because I was just looking
[00:52:39.760 --> 00:52:44.960]   at the text. - Yeah. - That's interesting, that's right. - And I can tell you, I can go into why.
[00:52:44.960 --> 00:52:51.120]   - That's really interesting. - Yeah, I can go into it. - So it truly is anonymous. - It's, well, I mean,
[00:52:51.120 --> 00:52:56.720]   - It depends on what you mean by anonymous. - Exactly. - It's a very different kind of anonymous. - And the reason
[00:52:56.720 --> 00:53:01.760]   that we made that decision is because we wanted people to connect to ideas.
[00:53:01.760 --> 00:53:05.520]   We wanted people to connect to things in the moment. We don't want people to go,
[00:53:06.160 --> 00:53:10.800]   "Oh, I know this guy. He said this other thing." And we didn't want people to feel like they were
[00:53:10.800 --> 00:53:15.360]   at risk of being doxed. So it's just, these are small communities, right? - Yeah. - We talked about this.
[00:53:15.360 --> 00:53:22.560]   Everyone knows someone who knows you. - Yeah. - And in 2021, it would not take much to be able to figure
[00:53:22.560 --> 00:53:28.880]   out who someone might be just through a couple of posts. So it's both safety and about the ideas
[00:53:28.880 --> 00:53:34.160]   in terms of not adding usernames. Anyway, we have this anonymous direct message system where you can
[00:53:34.160 --> 00:53:41.680]   direct message the original poster of any post, the OP, if you're a Redditor, of any post. And that
[00:53:41.680 --> 00:53:46.640]   makes it really easy to meet up because once you guys are one-on-one, you can exchange a number,
[00:53:46.640 --> 00:53:53.440]   you can exchange a Snapchat, you can exchange an email. Probably not very often, but you could.
[00:53:53.440 --> 00:53:58.240]   And then that's how people meet up, matching. - And then a lot of people connect in this way.
[00:53:58.240 --> 00:54:03.280]   Let me just take a small step into the technical. I read somewhere, I don't know if it's true,
[00:54:03.840 --> 00:54:08.720]   that one of the reasons you were rejected from YC, Y Combinator, in the final rounds
[00:54:08.720 --> 00:54:16.080]   is because one of the principles is to refuse to sell user data. Can you speak to that?
[00:54:16.080 --> 00:54:26.640]   Why do you think it's important not to sell user data? And sort of, which draws a clear contrast
[00:54:26.640 --> 00:54:33.840]   between other, basically any other service on the internet? - I mean, to be honest, it's quite
[00:54:33.840 --> 00:54:39.120]   simple. I mean, we talk about this platform, people are talking about their most intimate
[00:54:39.120 --> 00:54:45.520]   secrets, their political opinions. How are they feeling about what's going on in their city
[00:54:45.520 --> 00:54:54.800]   during the summer? How are they feeling about the political cycle and also their mental health,
[00:54:54.800 --> 00:55:00.480]   their relationships? These are some of the most intimate thoughts that people were having.
[00:55:00.480 --> 00:55:08.800]   Point blank, I don't think it was ethical to pawn them off for a profit. I didn't think it was
[00:55:08.800 --> 00:55:13.040]   moral. I don't think I could sleep at night if that was what I was doing, is turning these people's
[00:55:13.040 --> 00:55:21.680]   most intimate beliefs and secrets into a currency that I bought and sold. There's something very
[00:55:21.680 --> 00:55:29.520]   off about that. - I tend to believe that there is some room, so like Facebook would just take that
[00:55:29.520 --> 00:55:35.600]   data and sell it, right? But there's some room in transparency and giving people the choice on
[00:55:35.600 --> 00:55:42.240]   which parts they can, I wouldn't even see it as sell, but like share with advertisers. - Are you
[00:55:42.240 --> 00:55:46.960]   gonna give them a profit? - So right, you have to monetize, you have to create an entire system,
[00:55:46.960 --> 00:55:53.600]   you have to rethink this whole thing, right? But as long as you give people control and are
[00:55:53.600 --> 00:55:58.000]   transparent and make it easy, like I think it's really difficult to delete a Facebook account,
[00:55:58.000 --> 00:56:01.520]   or like delete all your data, or to download-- - I've tried, it's very difficult.
[00:56:01.520 --> 00:56:08.560]   - So like just make it easy and trust in that if you create a great product, people are not going
[00:56:08.560 --> 00:56:14.320]   to do it. And if they do it, then they're not actually a deep loving member of the community,
[00:56:14.320 --> 00:56:22.800]   what's that? - So we very quickly realized that user privacy was something that was not only a
[00:56:22.800 --> 00:56:28.160]   core value, but was something that users really cared about. And we added this functionality,
[00:56:28.160 --> 00:56:34.720]   it's just a button that says forget me. You press it, like two clicks, it's not that hard,
[00:56:34.720 --> 00:56:42.480]   we just remove your email from the database. You're good. - Beautiful, I think Facebook should
[00:56:42.480 --> 00:56:50.320]   have that. I honestly, so call me crazy, but maybe you can actually speak to this, but I don't think
[00:56:50.320 --> 00:56:55.440]   Facebook, well now they would, but if they did it earlier, they would lose that much money.
[00:56:55.440 --> 00:57:02.800]   If they allow, like transparently tell people you could just delete everything. They also explain
[00:57:02.800 --> 00:57:11.200]   that like in ways that's going to potentially like lessen your experience in the short term,
[00:57:11.200 --> 00:57:18.560]   like explain that. But then there shouldn't be like multiple clicks of a button that don't make
[00:57:18.560 --> 00:57:25.440]   any sense. I'm trying to hold back from ranting about Instagram, because let me just say real
[00:57:25.440 --> 00:57:30.960]   quick, 'cause I've been locked out of Instagram for a month. And there's a whole group inside
[00:57:30.960 --> 00:57:38.080]   Facebook that are like supporters of like Lex, help Lex. - Free Lex? - Free Lex. I wasn't blocked,
[00:57:38.080 --> 00:57:42.880]   it was just like a bug in the system. Somebody was hammering the API with my account. And so
[00:57:42.880 --> 00:57:47.920]   they kept thinking I'm a bot. Anyway, it's a bug, it happens to a lot of people. But like,
[00:57:47.920 --> 00:57:51.840]   first of all, I appreciate the love from all the amazing engineers in Instagram and Facebook.
[00:57:51.840 --> 00:57:58.320]   Love those folks. The entire mechanism though is somehow broken. I mean, I put that on the
[00:57:58.320 --> 00:58:03.360]   leadership, but it's also difficult to operate a large company once it scales, all those kinds of
[00:58:03.360 --> 00:58:12.080]   things. But it should not be that difficult to do some basic things that you want to do, which is,
[00:58:12.080 --> 00:58:20.400]   in the case of Facebook, that's verify your identity to the app. And also in the case of
[00:58:20.400 --> 00:58:30.320]   Facebook, in the case of LibreX, like disappear, if you choose. There's downsides to disappearing,
[00:58:30.320 --> 00:58:37.360]   but it should not be a difficult process. And yeah, I think people are waking up to that.
[00:58:37.360 --> 00:58:46.320]   I think there's a lot of room for an app like LibreX with its foundational ideas to redefine
[00:58:46.320 --> 00:58:51.520]   what social media should look like. And like you said, I think beautifully, anonymity is not the
[00:58:51.520 --> 00:58:59.520]   core value. It's just the tool you use. And who knows, maybe anonymity will not always be the tool
[00:58:59.520 --> 00:59:04.880]   we use. Like if you give people the choice, who knows what this evolves from the login page you
[00:59:04.880 --> 00:59:10.000]   initially created. The key thing is the founding principles. And again, who knows if you give
[00:59:10.000 --> 00:59:15.280]   people a really nice way to monetize their data, maybe there'll no longer be a thing that you say,
[00:59:15.280 --> 00:59:20.720]   do not sell user data. Yeah, all those kinds of things. But the basic principles should be there.
[00:59:20.720 --> 00:59:30.080]   And also a good, simple interface design goes a really long way, like simplicity and elegance,
[00:59:30.080 --> 00:59:34.240]   which LibreX currently is. Clubhouse is another- - It's gotten a lot better, by the way.
[00:59:34.240 --> 00:59:41.120]   I don't mean to go too deep into the history, but the- - It was bad? I didn't look at the early
[00:59:41.120 --> 00:59:47.440]   pictures. - Oh, thank goodness. - I read somewhere that it was like a white screen, like with black,
[00:59:48.640 --> 00:59:56.800]   HTML basic. - The upvote and downvote buttons were like these big, freaking boxes. And I could go on,
[00:59:56.800 --> 01:00:04.960]   but it was my genius design skills. I almost failed art class when I was in first grade,
[01:00:04.960 --> 01:00:09.920]   and I think I still have similar skills to my first grade self. But it's gotten a lot better,
[01:00:09.920 --> 01:00:15.200]   and thanks to a lot of my friends who have sort of chipped in here and there. - Oh, I love the idea
[01:00:15.200 --> 01:00:22.880]   of a button that just, like, forget me. I don't know, that's really moving, actually. That's
[01:00:22.880 --> 01:00:30.480]   actually all people want, is they want, I think, okay, I'll speak to my experience. I would give
[01:00:30.480 --> 01:00:38.240]   so much more if I could just disappear if I needed to. And I trusted the community, I trusted
[01:00:39.280 --> 01:00:46.160]   the founders and the principals. That's really powerful, man, the trust and ease of escape.
[01:00:46.160 --> 01:00:54.640]   Yeah. You've also kind of mentioned moderation, which is really interesting. So with this anonymity
[01:00:54.640 --> 01:01:00.480]   and this community, I don't know if you've heard of the internet, but there's trolls on the
[01:01:00.480 --> 01:01:08.240]   internet. - So I've heard. - And even if they go to Yale and Dartmouth, there's still people that
[01:01:08.240 --> 01:01:17.920]   probably enjoy the sort of being the guerrilla warfare, counter-revolutionary, and just, like,
[01:01:17.920 --> 01:01:27.120]   creating chaos in a place of love. So how do you prevent chaos and hatred breaking out in Librex?
[01:01:27.120 --> 01:01:34.080]   So the way I think about it is, we have these principals. They're pretty simple,
[01:01:34.080 --> 01:01:39.520]   and they're pretty easy to enforce. And then beyond the principals, we have a set of moderators,
[01:01:39.520 --> 01:01:43.680]   moderators from every single Ivy League school, a team of diverse moderators who enforce these
[01:01:43.680 --> 01:01:48.320]   principals, but not only enforce the principals, but kind of clue us in to what's happening in
[01:01:48.320 --> 01:01:54.080]   their community and how the real life context of their community translates to the Librex context
[01:01:54.080 --> 01:02:01.360]   of their community. And beyond that, we have conversation with them about the standards of
[01:02:01.360 --> 01:02:06.000]   the community, and we're constantly talking about what needs to be further elucidated and what needs
[01:02:06.000 --> 01:02:11.760]   to be tweaked, and we're in constant communication with the community. Now, if you want me to get
[01:02:11.760 --> 01:02:16.080]   into the principals that underlie Librex's moderation policy. - Yeah, please. Maybe you
[01:02:16.080 --> 01:02:20.080]   can explain that there's moderators. What does that mean? How are they chosen, and what are
[01:02:20.080 --> 01:02:25.200]   the principals under which they operate? - Sure. So how are the moderators chosen?
[01:02:25.200 --> 01:02:32.000]   The moderators are all volunteers. They're Librexers who reach out to me and respond to
[01:02:32.000 --> 01:02:38.640]   the opportunity to become moderator. And the way they're chosen is basically we want to make sure
[01:02:38.640 --> 01:02:42.560]   that they're in tune with their community. We want to make sure they come from diverse backgrounds,
[01:02:42.560 --> 01:02:46.640]   and we want to make sure that they sort of understand what the community is about. And then
[01:02:46.640 --> 01:02:52.640]   we ask them some questions about how they would deal with certain scenarios, ones that we've had
[01:02:52.640 --> 01:02:56.640]   in the past and we feel strongly about, and then also ones that are a little more murky, where we
[01:02:56.640 --> 01:03:02.480]   want to see that they're sort of thinking about these things in a critical way. And from there,
[01:03:02.480 --> 01:03:10.000]   we choose a set, and they have the power to take down posts. Of course, everything at the end of
[01:03:10.000 --> 01:03:15.680]   the day depends on my review, but they can take them down, and we can reinstate them if it's a
[01:03:15.680 --> 01:03:21.440]   problem. But they can take down posts, and they can advocate for different moderation standards
[01:03:21.440 --> 01:03:26.320]   and different moderation policies. - So for now, you're the Linus Torvald of this community.
[01:03:26.320 --> 01:03:34.880]   So meaning like, you're able to, like people are actually able to email you or like-
[01:03:34.880 --> 01:03:38.960]   - Text me. - Text you, contact you, and get a response.
[01:03:38.960 --> 01:03:45.840]   Like you respond to basically everybody. And then you're like really, you know, you're living that
[01:03:45.840 --> 01:03:51.840]   live on people's floor life currently. That's not necessarily, this is the early days, folks.
[01:03:51.840 --> 01:03:59.360]   I knew Ryan before he was a billionaire and he was cool. And then he was in a mansion making
[01:03:59.360 --> 01:04:06.960]   meats on his barbecue. No, okay. But you know, how does it scale? Like what,
[01:04:06.960 --> 01:04:15.200]   I suppose how does it scale is the question. I mean, with Linus, I don't know if you're
[01:04:15.200 --> 01:04:19.760]   familiar with the Linux open source community, but he still stayed at the top for a while. It was
[01:04:19.760 --> 01:04:24.480]   really important, like leadership there was really important to drive that large scale,
[01:04:24.480 --> 01:04:32.480]   really productive open source community. What do you see your role as LibreX grows? And in general,
[01:04:32.480 --> 01:04:37.920]   what are the mechanisms of scaling here for moderation? - The way I see it, open discourse
[01:04:37.920 --> 01:04:45.200]   is fundamental to the purpose of the app, right? So as the, I guess you could say founder, CEO,
[01:04:45.200 --> 01:04:52.640]   what have you, part of my purpose has to be to enforce the vision, right? And part of the vision
[01:04:52.640 --> 01:04:58.640]   is open discourse. And that does come down in part to reasonable moderation and community-guided
[01:04:58.640 --> 01:05:03.760]   reasonable moderation. So I imagine that will always be something that I'm intimately involved
[01:05:03.760 --> 01:05:11.920]   with to some degree. Now the degree to which the way in which that manifests, I imagine will have
[01:05:11.920 --> 01:05:19.360]   to change, right? And hopefully I'll be able to, just like you can hire a CTO, hopefully I'll be
[01:05:19.360 --> 01:05:27.600]   able to be integrated in hiring people who understand the way that we are sort of operating
[01:05:27.600 --> 01:05:32.800]   and the reasonable standards of moderation. And there can be a sort of hierarchical structure,
[01:05:33.520 --> 01:05:39.760]   but I think when you have a product whose key purpose is to allow people to have these difficult
[01:05:39.760 --> 01:05:44.000]   conversations on campus that need to be had. - Yeah, that moderation is core to that.
[01:05:44.000 --> 01:05:50.560]   - I can never fully, I don't think I can fully ever abdicate that responsibility. I think that
[01:05:50.560 --> 01:05:57.200]   would be like, I mean, that would be like Bezos abdicating e-commerce, right? Like that's part
[01:05:57.200 --> 01:06:02.000]   of the job. - Yeah. Of course you can run companies in different ways. I think that,
[01:06:02.000 --> 01:06:06.400]   'cause he might've abdicated quite a bit of the details there. - It's hard for me to say.
[01:06:06.400 --> 01:06:10.880]   - Because Amazon does so many things. I think probably the better examples like Elon with
[01:06:10.880 --> 01:06:13.920]   rockets, he's still at the core. - Of the engineering.
[01:06:13.920 --> 01:06:17.680]   - He's at the core of the engineering. There's some fundamental questions of what,
[01:06:17.680 --> 01:06:22.800]   he probably does way too much of the engineering. Like he's like the lowest level detail,
[01:06:22.800 --> 01:06:29.520]   but you're saying like the core things that make the app work is the moderation of difficult
[01:06:29.520 --> 01:06:33.280]   conversations. - And by the way, I'm 21 years old. Let's
[01:06:33.280 --> 01:06:41.600]   remind us, everyone of that. If this thing does scale and if this thing continues to be a positive
[01:06:41.600 --> 01:06:47.360]   force in a lot of people's lives, who knows what will happen in the next, what I'll learn.
[01:06:47.360 --> 01:06:53.120]   I'm still growing, definitely as a leader, still growing as a thinker, still growing as a person.
[01:06:53.920 --> 01:07:02.640]   I can't pretend that I know how to run a business that is worth up to $1 billion, whatever. I can't
[01:07:02.640 --> 01:07:07.120]   pretend I know how to run a business that's going to have millions and millions of users. I expect
[01:07:07.120 --> 01:07:11.920]   that there are going to be a lot of amazing people who will teach me and a lot of people who have
[01:07:11.920 --> 01:07:18.160]   already kind of stepped into my life and helped me out and taught me things. And I imagine that I'll
[01:07:18.160 --> 01:07:23.840]   learn so much more. I just know that moderation is always going to be important to me because I
[01:07:23.840 --> 01:07:30.480]   don't think LibreX is LibreX unless we have open discourse and moderation, reasonable, open,
[01:07:30.480 --> 01:07:34.800]   light touch moderation is at the heart of creating that, right?
[01:07:34.800 --> 01:07:40.720]   - So as a creator of this kind of community in place with anonymity and difficult conversations,
[01:07:42.720 --> 01:07:48.240]   what do you think about this touchy three words that people have been tossing around and
[01:07:48.240 --> 01:07:52.240]   politicizing, I would say, but is at the core of the founding of this country, which is the
[01:07:52.240 --> 01:07:59.760]   freedom of speech. How do you think about the freedom of speech, this particular kind of freedom
[01:07:59.760 --> 01:08:06.800]   of expression? And do you think it's a fundamental human right? How do you define it to yourself when
[01:08:06.800 --> 01:08:12.480]   you're thinking about it? I went down, especially preparing for this conversation down a rabbit
[01:08:12.480 --> 01:08:19.280]   hole of like just how unclear it is, philosophically, what is meant by this kind of freedom.
[01:08:19.280 --> 01:08:26.400]   It's not as easy as people think, but it's interesting, pragmatically speaking,
[01:08:26.400 --> 01:08:30.000]   to hear how you think about it in the context of LibreX.
[01:08:30.000 --> 01:08:37.120]   - Yeah, it's a tough one, right? There's a lot there. So I come from the background of being a
[01:08:37.120 --> 01:08:44.320]   math major. Maybe it's important to start with that. And I found myself in the middle of this
[01:08:44.320 --> 01:08:50.800]   question of freedom of speech. One of the wonderful things is that the LibreX community is filled with
[01:08:50.800 --> 01:08:57.840]   PhDs and governance majors who have taught me a ton about this sort of thing. And I'm still
[01:08:57.840 --> 01:09:04.240]   learning. I'm still growing. I'm still probably going to modify my perspective to some degree,
[01:09:04.240 --> 01:09:09.760]   hopefully. Don't worry. I imagine I'll always support free discourse.
[01:09:09.760 --> 01:09:16.560]   - Learning how to speak about stuff is critical here because it's like,
[01:09:16.560 --> 01:09:23.120]   I'm learning that this is like a minefield of conversations. Because the moment you say like,
[01:09:23.120 --> 01:09:30.640]   even saying freedom of speech is a complicated concept, people will be like, "Oh, we spotted
[01:09:30.640 --> 01:09:35.920]   a communist." They'll say, "There's nothing complicated about freedom. Freedom is freedom,
[01:09:35.920 --> 01:09:42.320]   bro." It is complicated. First of all, if you talk about, there's different definitions of
[01:09:42.320 --> 01:09:46.960]   freedom of speech. If you want to go constitution, if you want to talk about the United States
[01:09:46.960 --> 01:09:53.760]   specifically and what's legal, it's actually not as exciting and not as beautiful as people think
[01:09:53.760 --> 01:09:54.800]   of. - Complicated.
[01:09:54.800 --> 01:10:01.120]   - It's complicated. I think there's ideals behind it that we want to see. What does that actually
[01:10:01.120 --> 01:10:09.360]   materialize itself in the digital world where we're trying to communicate in ways that allows
[01:10:09.360 --> 01:10:16.800]   for difficult conversations and also at the same time doesn't result in the silencing of voices,
[01:10:18.320 --> 01:10:23.760]   not through censorship, but through just assholes being rude.
[01:10:23.760 --> 01:10:26.960]   - Spam. - Spam. So it could be just bots.
[01:10:26.960 --> 01:10:29.120]   - Racism. - Racism.
[01:10:29.120 --> 01:10:32.800]   - Going back to the name of the app, LibreX. - Yes.
[01:10:32.800 --> 01:10:40.640]   - Libre, free. X was support Montu for free exchange. And the free exchange of what?
[01:10:40.640 --> 01:10:45.680]   My purpose was to create as much intercommunication of ideas,
[01:10:46.480 --> 01:10:52.720]   be them repugnant or otherwise as possible. And of course to do that within legal bounds
[01:10:52.720 --> 01:10:58.800]   and to do that without causing anyone to be harassed or doxxed. So to keep things focused
[01:10:58.800 --> 01:11:09.280]   on the ideas, not the people. And then no BS crap stuff. And so to me, the easiest way to
[01:11:09.280 --> 01:11:14.560]   moderate around that, because as you said, figuring out what is hateful and what is hate speech is
[01:11:14.560 --> 01:11:21.760]   really hard, was to say no sweeping statements against core identity groups. And that seems to
[01:11:21.760 --> 01:11:26.960]   work on the whole pretty well to be pretty light touch. - It's hard to do though.
[01:11:26.960 --> 01:11:29.200]   - It's difficult. - Because we like to generalize.
[01:11:29.200 --> 01:11:31.040]   We humans. - It's difficult, but
[01:11:31.040 --> 01:11:37.760]   what it comes down to is be specific. And when you think about what are sweeping statements against
[01:11:37.760 --> 01:11:42.960]   core identity groups, oftentimes these are sort of hackneyed subjects. These are things that have
[01:11:42.960 --> 01:11:49.840]   been broached and we've heard them before. They don't really lead anywhere productive. So it goes
[01:11:49.840 --> 01:11:55.520]   under this principle of be specific in the ideas you're discussing. - So even for like positive
[01:11:55.520 --> 01:12:00.240]   and humorous stuff, you try to avoid generalizations. - Against core identity groups.
[01:12:00.240 --> 01:12:05.680]   - Core identity groups. Sorry, what are core identity groups? - We're talking race, religion.
[01:12:05.680 --> 01:12:13.120]   - Okay. Got it. Even positive stuff? - Well, against, negative.
[01:12:13.120 --> 01:12:19.360]   - Against, sorry, against, against. Okay. - Very, very, we've learned to be very specific.
[01:12:19.360 --> 01:12:25.040]   Very few words, but the community gets it. - Yeah, they get it. I mean, this is the thing,
[01:12:25.040 --> 01:12:33.520]   the trouble with rules is as the community grows, they'll figure out ways to manipulate the rules.
[01:12:33.520 --> 01:12:36.480]   - Absolutely. It's human nature. It's creativity. - Yeah.
[01:12:36.480 --> 01:12:41.760]   - Something beautiful about it, of course. Unlike in- - From an evolutionary perspective, yes.
[01:12:41.760 --> 01:12:47.440]   - Yeah. The fact that people are so creative and so looking to, and because people are genuinely
[01:12:47.440 --> 01:12:53.120]   interested in figuring out these things about social media. And so they'll 100% like see like,
[01:12:53.120 --> 01:12:57.600]   where's the edge? And I mean, part of that's maintaining some level of vagueness in your rule
[01:12:57.600 --> 01:13:02.880]   set, which has its own set of questions and something we could think about. And I'm not
[01:13:02.880 --> 01:13:06.480]   implying I have all the answers, but there is something really interesting about people being
[01:13:06.480 --> 01:13:11.600]   so engaged that they're looking to figure out where are those edges and what does that mean?
[01:13:11.600 --> 01:13:15.680]   What does that edge mean? - Well, so one of the things I'm kind of
[01:13:15.680 --> 01:13:22.000]   thinking about, like from an individual user of Librex or an individual user of the internet,
[01:13:22.000 --> 01:13:28.240]   I think about like that one person that is on Reddit saying hateful stuff or positive stuff,
[01:13:28.240 --> 01:13:33.680]   doesn't matter, or funny stuff. One of the things I think about is the trajectory of that
[01:13:33.680 --> 01:13:40.720]   individual through life and how social media can help that person become the best version of
[01:13:40.720 --> 01:13:47.120]   themselves. I don't mean from like an Orwellian sense, like educate them properly or something.
[01:13:47.120 --> 01:13:54.480]   I just mean like, we're all, I believe we're all fundamentally good. And I also believe we all have
[01:13:55.040 --> 01:14:03.600]   the capacity to do, to create some amazing stuff in this world, whether that's ideas or art or
[01:14:03.600 --> 01:14:09.280]   engineering, all those kinds of things, just to be amazing people. And I kind of think about like,
[01:14:09.280 --> 01:14:15.680]   you know, a lot of social media mechanisms bring out the worst in us. And I try to think like,
[01:14:15.680 --> 01:14:24.640]   in the longterm, how can the social media or how can a website, how can a tool that you create
[01:14:24.640 --> 01:14:29.360]   can make the best, like you take a trajectory that makes you a better, better and better,
[01:14:29.360 --> 01:14:32.960]   and like the best version of yourself. So I think about that, because like,
[01:14:32.960 --> 01:14:39.360]   you know, Twitter can really take you down some dark trajectories. I've seen people just not being
[01:14:39.360 --> 01:14:43.360]   the best version of themselves. Forget the cancel culture and all that kind of stuff. It's just like,
[01:14:43.360 --> 01:14:49.040]   they're not developing intellectually in the way that's going to make the best version of themselves.
[01:14:49.040 --> 01:14:55.760]   I think Reddit, I'm not sure what I think about Reddit yet. Because one positive side is all the
[01:14:55.760 --> 01:15:02.160]   shitposting on Reddit could be just like a release valve for some stress in life. And you almost have
[01:15:02.160 --> 01:15:08.000]   like a parallel life where in your in meat space, you might be actually becoming successful and so
[01:15:08.000 --> 01:15:13.600]   on and growing and so on. But you just need sometimes to be angry at somebody. But I tend to
[01:15:13.600 --> 01:15:20.400]   not think that's possible. I think if you're shitposting, you're probably not spending your
[01:15:20.400 --> 01:15:26.960]   time the best way you could. I don't know. I'm torn on that. But do you think about that with
[01:15:26.960 --> 01:15:33.760]   Librex of creating a trajectory for the Yale, for the Dartmouth, the students to where they grow
[01:15:33.760 --> 01:15:40.320]   intellectually? - One thing that I think about a lot is how do you incentivize positive content
[01:15:40.320 --> 01:15:46.960]   creation? How do you incentivize really intellectual content creation? It's something that,
[01:15:46.960 --> 01:15:54.640]   frankly, I think about every single day. And I think there are ways that,
[01:15:54.640 --> 01:16:00.800]   I mean, one thing that's great about humans is that they can be incentivized. And I think there
[01:16:00.800 --> 01:16:05.840]   are ways that you can incentivize people to make the right kind of content if that's your goal.
[01:16:05.840 --> 01:16:10.000]   - So you think such mechanisms exist for such incentivization?
[01:16:10.000 --> 01:16:13.680]   - I do. I don't want to let the cat out of the bag, so to speak.
[01:16:13.680 --> 01:16:16.400]   - So you have already concrete ideas in your mind?
[01:16:16.400 --> 01:16:20.560]   - I have about three concrete ideas that I'm very, very optimistic about.
[01:16:20.560 --> 01:16:26.960]   - You don't even need to share them. I understand totally. But the fact that you have them,
[01:16:26.960 --> 01:16:34.000]   that's really good. Because I feel like sometimes the downfall of the social media is that there's
[01:16:34.000 --> 01:16:42.720]   literally not even a thinking or a discussion about the incentivization of positive long-term
[01:16:42.720 --> 01:16:48.320]   content creation. I mean, Twitter, I really was excited about this when they said, like,
[01:16:48.320 --> 01:16:52.000]   when Jack has talked about creating healthy conversations.
[01:16:52.000 --> 01:16:57.680]   - Yeah, he does seem to care. I've listened to him. I mean, he has a very particular way of
[01:16:57.680 --> 01:17:02.000]   saying things. But you get the impression that he's someone who actually cares about these things
[01:17:02.000 --> 01:17:05.200]   within the limits of his power. - Yeah. And that's the question,
[01:17:05.200 --> 01:17:12.720]   the limits of the power. LibreX is growing not just in the number of communities, but also in
[01:17:12.720 --> 01:17:19.520]   the way you're incentivizing positive conversations, like coupled with the moderation and
[01:17:19.520 --> 01:17:22.480]   so on. So you think there's a lot of innovation to be had in that area?
[01:17:22.480 --> 01:17:27.280]   - I think there's a tremendous amount. I think when you think about the reasons people post,
[01:17:27.920 --> 01:17:34.480]   fundamentally, people want to make a positive impact on their community to some degree. Now,
[01:17:34.480 --> 01:17:39.600]   there will always be bad actors. And part of the benefit of our moderation structure is that we can
[01:17:39.600 --> 01:17:47.280]   limit some of those bad actors, no body counts, no brigading. At the same time, the more you
[01:17:47.280 --> 01:17:53.120]   incentivize a certain type of behavior, the better it's going to be. And we don't see it as our role
[01:17:53.120 --> 01:17:59.840]   as the platform to force the community in a direction. And frankly, I don't think it would
[01:17:59.840 --> 01:18:04.800]   be good for anyone, the community or the conversations, if we forced a specific type of
[01:18:04.800 --> 01:18:10.800]   conversations, conversation. We just need to make the tools to allow people to be good and to
[01:18:10.800 --> 01:18:18.480]   incentivize good behavior. - Yeah, I believe that. You will not need to censor if you allow people
[01:18:18.480 --> 01:18:24.880]   at scale to be good. The good will overpower the assholes. - That's my fundamental belief. I'm
[01:18:24.880 --> 01:18:32.000]   very optimistic about that. - But currently LibreX is small in the sense that it's a small
[01:18:32.000 --> 01:18:37.200]   set of communities that I believe. And you mentioned to me offline that by design, you're
[01:18:37.200 --> 01:18:46.960]   scaling slowly and carefully. So how does LibreX scale? Is it possible? Facebook also started with
[01:18:46.960 --> 01:18:54.480]   a small set of communities that were schools and then now grew to be basically the, if not one of
[01:18:54.480 --> 01:19:00.640]   the largest social networks in the world. Do you see LibreX as potentially scaling to be
[01:19:00.640 --> 01:19:09.120]   beyond even college campuses, but encompassing the whole world? - It's a long timeline.
[01:19:11.120 --> 01:19:18.240]   I'll say this, this gets back to where did Facebook go wrong? Because clearly they did a
[01:19:18.240 --> 01:19:25.840]   lot right. And we can only speculate about what the objectives were of the founders of Facebook.
[01:19:25.840 --> 01:19:34.160]   I'm sure they've said some things, but it's always interesting to know what the mythology is versus
[01:19:34.160 --> 01:19:40.720]   what the truth is of the matter. So perhaps they've been very successful. I mean, they've
[01:19:40.720 --> 01:19:47.600]   taken over the world to some extent. At the same time, the goals of LibreX are to create these
[01:19:47.600 --> 01:19:53.520]   positive communities and these open conversations where people can have real conversation and
[01:19:53.520 --> 01:19:59.200]   connection in their communities in a vulnerable and authentic way. And so to that end, which
[01:19:59.200 --> 01:20:06.160]   I imagine might be different than the goals of a Facebook, for example, one thing that we want to
[01:20:06.160 --> 01:20:13.760]   do is keep things intimate and community-based. So each school is its own community. And perhaps
[01:20:13.760 --> 01:20:19.040]   you could have a slightly broader community. Maybe you could have a, I know the California
[01:20:19.040 --> 01:20:23.520]   system is an obvious one, Pac-10 might be an obvious one, and we can think about that.
[01:20:23.520 --> 01:20:33.200]   But fundamentally the unit of community is your school or your school community. So that's one
[01:20:33.200 --> 01:20:38.240]   difference that I think will help us. The other thing is that we're scaling intentionally,
[01:20:38.240 --> 01:20:43.600]   meaning that when we expand to a school, we have moderators in place. We have moderators who
[01:20:43.600 --> 01:20:49.600]   understand that school's environment in a very personal level, and we're growing responsibly.
[01:20:49.600 --> 01:20:53.200]   We're growing as we're ready, both technologically, but also socially,
[01:20:53.200 --> 01:21:00.960]   as we think we have the tools to preserve the community and to encourage the community to
[01:21:00.960 --> 01:21:06.960]   create the sort of content that we want them to create. - And there's a lot of ways to define
[01:21:06.960 --> 01:21:12.720]   community. So first of all, there's geographic community as well. But the way you're kind of
[01:21:12.720 --> 01:21:18.880]   defining community with Yale and Dartmouth is the email, right? That's what gives you,
[01:21:18.880 --> 01:21:26.880]   there's a power to the email in the sense that that's how you can verify, efficiently verify
[01:21:26.880 --> 01:21:34.400]   yourself with being a single individual in the university. In that same way, you can verify your
[01:21:34.400 --> 01:21:41.360]   employment at a company, for example, like Google, Microsoft, Facebook. Do you see your
[01:21:41.360 --> 01:21:48.320]   potentially taking on those communities? That'd be fascinating, getting like anonymous community
[01:21:48.320 --> 01:21:55.040]   conversations inside Google. - 100% crossed my mind. To some extent, this is something where
[01:21:56.400 --> 01:22:02.720]   I understand the college experience. I understand the need. And I've never worked at Google.
[01:22:02.720 --> 01:22:07.760]   I don't know if they would hire me. Hopefully, maybe as a product manager.
[01:22:07.760 --> 01:22:17.280]   I think if there's a community that needs this product and has that will, which I think,
[01:22:17.280 --> 01:22:23.200]   especially as LibreX continues to grow and expand and change and learn,
[01:22:24.080 --> 01:22:27.120]   because that's what we're doing is we're learning, right? With each community,
[01:22:27.120 --> 01:22:33.680]   it's not just about growing. It's about learning from each of these communities and iterating.
[01:22:33.680 --> 01:22:39.600]   I think it's quite likely there are going to be all sorts of communities that could use this tool
[01:22:39.600 --> 01:22:47.440]   to improve their culture, so to speak. - So forgive me, I'm not actually that knowledgeable
[01:22:47.440 --> 01:22:52.640]   about the history of attempts of building social networks to solve the problem that you're solving.
[01:22:53.520 --> 01:23:00.560]   But I was made aware that there was an app or at least a social network called Yik Yak
[01:23:00.560 --> 01:23:12.480]   that had a similar kind of focus. I think the thing you've spoken about that differs between
[01:23:12.480 --> 01:23:18.640]   LibreX and Yik Yak is that Yik Yak was defined, am I pronouncing it right even? - You're good.
[01:23:18.640 --> 01:23:21.440]   - I'm good. - I met the founder, so I can confirm.
[01:23:21.440 --> 01:23:28.640]   - Okay, you can confirm, cool. That it was constrained to a geographical area versus
[01:23:28.640 --> 01:23:36.800]   like to the actual community and that somehow had fundamental like actual differences in
[01:23:36.800 --> 01:23:42.960]   social dynamics that resulted. But can you speak to the history of Yik Yak? How does LibreX differ?
[01:23:42.960 --> 01:23:48.400]   What lessons have you learned from that? Oh, and I should say that I guess there was controversial
[01:23:49.200 --> 01:23:52.640]   I don't know, I didn't look at the details, but I'm guessing there's a bunch of racism and hate
[01:23:52.640 --> 01:23:55.760]   speech and all that kind of stuff that emerged on Yik Yak. - Absolutely there was.
[01:23:55.760 --> 01:24:02.880]   - Okay, so that's an example of like, okay, here's how it goes wrong when you have anonymity
[01:24:02.880 --> 01:24:10.800]   on college campuses. So how does LibreX going to do better? - Yeah, Yik Yak had a lot of problems,
[01:24:10.800 --> 01:24:15.040]   content problems, but the content problems go deeper than maybe what the press would reveal.
[01:24:16.400 --> 01:24:21.920]   There's a lot to say and part of it is parsing exactly what to talk about when it comes to Yik
[01:24:21.920 --> 01:24:26.240]   Yak. And when you talk about startups, I mean, you know this, you know startups,
[01:24:26.240 --> 01:24:32.640]   and you look at the postmortem, it's almost never what people think it is. And oftentimes these
[01:24:32.640 --> 01:24:38.640]   things are somewhat unknowable. And the degree to which people seeking confirmation bias to
[01:24:38.640 --> 01:24:43.360]   somebody who's seeking closure, look to find a singular attribute that caused the failure.
[01:24:43.360 --> 01:24:46.640]   - It feels like the little details often make all the difference.
[01:24:46.640 --> 01:24:53.920]   - Yes. And I think the details are so little that as humans, we are not capable of parsing
[01:24:53.920 --> 01:24:59.920]   even what they are, but I'll tell you my perspective on it, knowing that I'm also
[01:24:59.920 --> 01:25:09.360]   a human with biases, in this particular case, very significant biases. So I started building
[01:25:09.360 --> 01:25:15.600]   Librex for its own merits. At first I wasn't aware of Yik Yak, but as I started to talk to people
[01:25:15.600 --> 01:25:22.080]   about this platform I was building, I was made aware of Yik Yak and I built it from day one with
[01:25:22.080 --> 01:25:29.200]   a lot of the issues Yik Yak had in mind. So as you said, the one difference between Yik Yak is
[01:25:29.200 --> 01:25:36.160]   the geographical versus community-based aspect. Going along with that, one thing I realized by
[01:25:36.160 --> 01:25:41.840]   researching social media sites is that the majority of the negative content, the content
[01:25:41.840 --> 01:25:49.440]   that's terrible and breaking all the rules is created by really, and the people who are not
[01:25:49.440 --> 01:25:57.280]   reformable, so to speak, the people who are not showing the best part of the human experience.
[01:25:57.280 --> 01:26:04.240]   It's a really small minority, right? I remember I was listening to the founder of 4chan, Moot,
[01:26:04.240 --> 01:26:12.960]   talk about this, how one guy was able to basically destroy large swaths of his community.
[01:26:12.960 --> 01:26:19.760]   That's part of what makes it exciting for that minority is how much power they can have. So if
[01:26:19.760 --> 01:26:25.440]   you're predisposed to think in this way, it's exciting that you can walk into, like I mentioned
[01:26:25.440 --> 01:26:32.080]   the party before, you have a party of a lot of positive people and it feels, especially if you
[01:26:33.680 --> 01:26:41.760]   don't have much power in this world, it feels exceptionally empowering to destroy
[01:26:41.760 --> 01:26:50.880]   the lives of many. And if you think this way, it's a problem. But I'm hopeful that you're right,
[01:26:50.880 --> 01:26:55.920]   that in most cases it's going to be a minority of people. - I think it is, and that's what the
[01:26:55.920 --> 01:27:03.520]   research has showed. And one really powerful thing is that we can really actively control
[01:27:03.520 --> 01:27:08.320]   who comes in and out of our community based on the .edu verification. And we can also control
[01:27:08.320 --> 01:27:13.840]   who's not in our community because we have that lever where each account is associated with .edu.
[01:27:13.840 --> 01:27:21.760]   So that's the first point I would put out there. Second point is controlled expansion, meaning that
[01:27:21.760 --> 01:27:27.920]   we have community moderation. We have this panel that allows the moderators to see all of the
[01:27:27.920 --> 01:27:33.360]   highly downvoted content, all of the reported content, all the flagged content and look through
[01:27:33.360 --> 01:27:40.720]   it and decide what they like and what's appropriate and what's not appropriate. And we ping every
[01:27:40.720 --> 01:27:45.920]   moderator when there's a report. So things are taken down pretty quickly. And we have our
[01:27:45.920 --> 01:27:51.600]   standards and we have, I think above all of that, we have a mission and it's a community-based
[01:27:51.600 --> 01:27:56.800]   mission. Yik Yak was more of a fun app and by its own admission, it was a place where people
[01:27:56.800 --> 01:28:03.040]   could enjoy themselves and could sort of yak. - Yak, yeah. - Yik Yak, you know, chit chat.
[01:28:03.040 --> 01:28:09.920]   We have a bigger purpose than that, frankly. And I think that shows in the people who self-select
[01:28:09.920 --> 01:28:15.440]   to be on that app, to be on LibreX and to be on Yik Yak, respectively. The last thing I'll say is,
[01:28:15.440 --> 01:28:21.520]   Yik Yak was very few characters. It was a Twitter-esque platform. And that doesn't allow
[01:28:21.520 --> 01:28:24.880]   for a tremendous amount of nuance. It doesn't allow for a tremendous amount of conversation.
[01:28:24.880 --> 01:28:33.600]   LibreX is much more long form. And so the kind of posts that you'll get on LibreX can spam pages.
[01:28:33.600 --> 01:28:39.760]   What people are starting to realize is that they can reach a lot more people at a lot more
[01:28:39.760 --> 01:28:46.240]   pertinent of a time, a lot more quickly by posting their thoughts on LibreX than if they
[01:28:46.240 --> 01:28:51.600]   went to their school newspaper. And I think the school newspapers might be a little worried about
[01:28:51.600 --> 01:28:55.360]   that, but more importantly, we're connecting people in this way where long form communication
[01:28:55.360 --> 01:29:00.080]   with nuance that takes into account everything that's happening in the community temporally
[01:29:00.080 --> 01:29:09.520]   is really available at LibreX and, you know, not really communicable in 240 or 480 or whatever
[01:29:09.520 --> 01:29:15.440]   the number of characters the acts were bound to. And then, you know, I could talk about the history
[01:29:15.440 --> 01:29:20.640]   of Yik Yak if you want me to go further. They started, I think they were at 12 schools.
[01:29:20.640 --> 01:29:27.680]   And then spring break hit, people told their friends, look at this app, a thousand schools
[01:29:27.680 --> 01:29:32.400]   signed up and had active communities. They had a problem on their hands. And then the high schools
[01:29:32.400 --> 01:29:38.000]   come on board. - Yeah. I think a lot of the things you said ring true to me, but especially the
[01:29:38.000 --> 01:29:44.480]   vision one, which I do think having a vision in the leadership, having a mission makes all the
[01:29:44.480 --> 01:29:50.240]   difference in the world. That's both for the engineers that are building, like the team that's
[01:29:50.240 --> 01:29:56.400]   building the app, the moderation and users, 'cause they kinda, the mission carries itself
[01:29:56.400 --> 01:30:02.480]   through the behavior of the people on the social network.
[01:30:04.560 --> 01:30:10.320]   As a small tangent, let me ask you something about Parler, but it's less about Parler and more
[01:30:10.320 --> 01:30:16.880]   about AWS. So AWS removed Parler from its platform, you know, for whatever reasons,
[01:30:16.880 --> 01:30:23.680]   doesn't really matter. But the fact that AWS would do this was really, really bothered me
[01:30:23.680 --> 01:30:31.520]   personally, because I saw AWS as the computing infrastructure. And I always thought that part
[01:30:32.320 --> 01:30:37.040]   could not put a finger on its scale. And I don't know what your thoughts are, like,
[01:30:37.040 --> 01:30:43.600]   were you bothered by Parler being removed from AWS? And how does that affect how you think about
[01:30:43.600 --> 01:30:51.120]   the computing infrastructure on which Lubrix is based? - I was bothered not so much by Parler
[01:30:51.120 --> 01:30:57.840]   specifically being taken out of AWS, but more the fact that something that's like a highway,
[01:30:58.720 --> 01:31:04.240]   something that people rely on, that people build on top of, that people assume is gonna be somewhat
[01:31:04.240 --> 01:31:12.960]   position agnostic, like a road that people drive on, is becoming ideologically sort of discriminatory.
[01:31:12.960 --> 01:31:18.480]   I just, and of course, mind you, Amazon can do what it wants, it's a private company,
[01:31:18.480 --> 01:31:23.920]   and I support the rights of private companies. I just, on an ethical and sort of a deep moral level,
[01:31:23.920 --> 01:31:33.360]   I wonder, like, at what point should a company sort of be agnostic in that regard and let
[01:31:33.360 --> 01:31:39.520]   developers build on top of their infrastructure? And where does that responsibility hold?
[01:31:39.520 --> 01:31:45.920]   - Yes, it makes you hope that there's going to be, from a capitalistic sense,
[01:31:45.920 --> 01:31:50.480]   competitors to AWS who say, like, we're not going to put our finger on the scale.
[01:31:50.480 --> 01:31:57.280]   I mean, on the highway is a good sort of example. It's like if a privately owned highway said,
[01:31:57.280 --> 01:32:03.680]   you know, we're no longer going to allow, we're only going to allow electric vehicles.
[01:32:03.680 --> 01:32:10.000]   And a bunch of people in this world would be like, yes, because electric is good for the environment.
[01:32:10.000 --> 01:32:20.080]   And, you know, yes, but then you have to consider the, like, the slippery slope nature of it,
[01:32:20.080 --> 01:32:25.440]   but also, like, the negative impact on the lives of many others and what that means for innovation
[01:32:25.440 --> 01:32:30.560]   and for, like, competition, again, in a capitalistic sense. So there's some nature,
[01:32:30.560 --> 01:32:38.960]   there's some level to this hierarchy of our existence that we should not allow to manipulate
[01:32:38.960 --> 01:32:43.280]   what's built on top of it. It should be truly infrastructure. And it feels like compute
[01:32:44.400 --> 01:32:52.000]   is storage and compute is that layer, like it shouldn't be messed with. I haven't seen anybody
[01:32:52.000 --> 01:32:56.160]   really complain about it, like in terms of government. And I'm not even sure government
[01:32:56.160 --> 01:33:01.520]   is the right mechanism through policy and regulation to step in. Because again, they do
[01:33:01.520 --> 01:33:09.200]   a messy job of fixing things. But I do hope there's competitors to AWS that make AWS and step up.
[01:33:09.200 --> 01:33:12.560]   Because I do think, you know, I'm a fan of AWS, except this.
[01:33:12.560 --> 01:33:13.200]   - Good service.
[01:33:13.200 --> 01:33:15.600]   - It's a good service until this.
[01:33:15.600 --> 01:33:18.960]   - Until, yeah, until they rip out the rug.
[01:33:18.960 --> 01:33:26.160]   - And the point is, it's not that necessarily their decision was a bad one with Parler
[01:33:26.160 --> 01:33:35.280]   in particular. It's that, like, the slippery slope nature of it, but also, it takes the good actors
[01:33:35.920 --> 01:33:40.480]   that are creating amazing products and makes them more fearful. And when you're more fearful,
[01:33:40.480 --> 01:33:44.880]   it's the same reason that anonymity is a tool that you don't create the best thing you could
[01:33:44.880 --> 01:33:51.200]   possibly create. When you're fearful, you don't create. I think we kind of talked about it a
[01:33:51.200 --> 01:33:57.360]   little bit, but I wonder if we can kind of revisit it a little bit. I talked to a guy named Ronald
[01:33:57.360 --> 01:34:05.200]   Sullivan, who's a faculty at Harvard law professor. He was on the legal defense team. He was the
[01:34:05.200 --> 01:34:11.840]   lawyer for Harvey Weinstein and Aaron Hernandez for the double murder case. So he takes on these
[01:34:11.840 --> 01:34:18.080]   really difficult cases of unpopular figures because he believes, like, that's the way you test,
[01:34:18.080 --> 01:34:25.920]   that we believe in the rule of law. But he was, there's a big protest in Harvard
[01:34:25.920 --> 01:34:33.120]   to get him, basically censor him and to get him to no longer be faculty dean,
[01:34:34.000 --> 01:34:40.400]   all those kinds of things. And it was by a minority of students, but, and there was a huge
[01:34:40.400 --> 01:34:46.240]   blowback, obviously, in the public, but also inside Harvard, like, that's not okay. He stands
[01:34:46.240 --> 01:34:50.560]   for the very principles at the founding of Harvard and at the principles of the founding of this
[01:34:50.560 --> 01:34:59.680]   country and the law and so on. But the basic argument is that, was about safe spaces, that
[01:34:59.680 --> 01:35:07.840]   it's unsafe to have somebody who is basically supporting Harvey Weinstein, right? What do you
[01:35:07.840 --> 01:35:14.400]   think about this whole idea of safe spaces on college campuses? Because it feels like
[01:35:14.400 --> 01:35:20.000]   the mission of Librex is pushing back against the idea of safe spaces.
[01:35:20.000 --> 01:35:25.920]   I think safe spaces are fine when they're within people's private lives, within their homes,
[01:35:26.640 --> 01:35:31.520]   within their religious organizations. I think the problem becomes when the institution starts
[01:35:31.520 --> 01:35:43.040]   encouraging or backing safe spaces, because what are people being safe from? And oftentimes it
[01:35:43.040 --> 01:35:50.800]   seems like there's this idea that the harm that's being attempted to be mitigated is the harm of
[01:35:50.800 --> 01:35:56.400]   confronting opinions you disagree with, opinions you might find repugnant. And if this is
[01:35:56.400 --> 01:36:02.560]   conflated with a need for safety, then that's where the idea of liberal arts education sort of dies.
[01:36:02.560 --> 01:36:08.800]   Of course, it's complicated and we still want to have safe intellectual environments.
[01:36:08.800 --> 01:36:16.400]   But the way that I hear the term safe space used today, I think it doesn't really have a place
[01:36:16.400 --> 01:36:24.160]   within the intellectual context. - Yeah, it's funny. I mean, this is why Librex is really
[01:36:24.160 --> 01:36:27.600]   exciting, is it's pushing those difficult conversations. And I'd love to see,
[01:36:27.600 --> 01:36:37.600]   ultimately, there does seem to be an asymmetry of power that results in the concept of safe spaces
[01:36:37.600 --> 01:36:43.760]   and hate speech being redefined in the slippery slope kind of way, where it means basically
[01:36:43.760 --> 01:36:50.720]   anything you want it to mean. And it basically is used to silence people. To silence people,
[01:36:50.720 --> 01:36:56.640]   they're like good, thoughtful experts. - Also, yeah, on that, I would say it has
[01:36:56.640 --> 01:37:02.080]   not just a pragmatic purpose, which is the silencing, but also sort of an ideological
[01:37:02.080 --> 01:37:09.600]   purpose, which is, and a linguistic purpose, which is to conflate words with unsafety and harm and
[01:37:09.600 --> 01:37:16.080]   violence, which is what you kind of see on a cultural linguistic level is happening
[01:37:16.720 --> 01:37:22.160]   all around us right now, is that this idea that words are harm, it's a very dangerous and slippery
[01:37:22.160 --> 01:37:27.360]   concept. I mean, you don't have to slip that far to see why that's a problem. Once we start
[01:37:27.360 --> 01:37:31.920]   making words into violence and we start criminalizing words, we get into some really
[01:37:31.920 --> 01:37:38.560]   authoritarian territory. Things that I think, I mean, myself and my background, I don't know how
[01:37:38.560 --> 01:37:43.200]   much we have to go into it, but things that my ancestors certainly would be worried about.
[01:37:43.200 --> 01:37:48.240]   - What's your background? - I'm a child of Holocaust
[01:37:48.240 --> 01:37:53.760]   survivors and pro-Grom survivors. - Yeah, I mean, me as well,
[01:37:53.760 --> 01:37:59.920]   from different directions. I come from the Soviet Union. So there's, well, like in most of us,
[01:37:59.920 --> 01:38:06.160]   hate and love runs through our blood from our history. You mentioned MIT is being added to
[01:38:06.160 --> 01:38:09.840]   Librex. Has it already been added? - Yes, it was added today.
[01:38:09.840 --> 01:38:16.960]   - Today, okay. So let me ask you, this is exciting because I don't know what your thoughts are about
[01:38:16.960 --> 01:38:22.320]   this, but I'll tell you from my perspective, if you're, and a lot of MIT folks listen to this,
[01:38:22.320 --> 01:38:28.480]   I would love it if you joined Librex. It'd be interesting to explore conversations
[01:38:28.480 --> 01:38:38.480]   on several topics inside MIT, but one of the most moving that hasn't been discussed at all
[01:38:38.560 --> 01:38:45.440]   except in little flourishes here and there is the topic of Jeffrey Epstein.
[01:38:45.440 --> 01:38:56.400]   Now there's been a huge amount of like impact that the connections of various faculty to Jeffrey
[01:38:56.400 --> 01:39:03.920]   Epstein and the various things that have been said had on MIT, but it feels like the difficult
[01:39:03.920 --> 01:39:10.160]   conversation haven't had been had. It's the administration trying to clean up and give a
[01:39:10.160 --> 01:39:16.400]   bunch of BS to try to pretend like, let's just hide this part. Like nothing is broken, nothing
[01:39:16.400 --> 01:39:24.240]   to see here. Here's a bad dude that did some bad things and some faculty that kind of misbehaved a
[01:39:24.240 --> 01:39:29.520]   little bit because they're a little bit clueless. Let's all look the other way. Harvard did this
[01:39:29.520 --> 01:39:37.360]   much better, by the way. They completely, it's almost like people pretend like Harvard didn't
[01:39:37.360 --> 01:39:44.560]   have anything to do with Jeffrey Epstein. But I think I'd be curious to hear what those
[01:39:44.560 --> 01:39:53.520]   conversations are because there's conversations on the topic of like, well, obviously sort of
[01:39:53.520 --> 01:39:59.680]   sexual assault and disrespecting women on any kind of level within academia, but just women
[01:39:59.680 --> 01:40:06.000]   in general. That's an important topic to talk about various, many sets of difficult conversations.
[01:40:06.000 --> 01:40:16.640]   And the other topic is funding for research. Like what are we okay taking money from and what are
[01:40:16.640 --> 01:40:21.840]   we not okay taking money from? There's a lot of just interesting, difficult conversations to be
[01:40:21.840 --> 01:40:30.240]   had. I've worked with people who refuse to take money from DOD, Department of Defense, for example,
[01:40:30.240 --> 01:40:35.920]   because in some indirect or direct way, you're funding military, industrial complex, all those
[01:40:35.920 --> 01:40:42.000]   kinds of things. I think with Jeffrey Epstein, it's even more stark, this contrast of like, well,
[01:40:42.000 --> 01:40:49.200]   what is and isn't ethical to take money from? And I just think, forget academia, I think there's just
[01:40:49.200 --> 01:40:54.960]   a lot of interesting, deep human discussions to be had and they haven't been. And there's been
[01:40:54.960 --> 01:41:01.200]   somebody, I don't know if you're familiar with Eric Weinstein, who has been outraged by the fact
[01:41:01.200 --> 01:41:06.240]   that nobody's talking about Jeffrey Epstein. Nobody's having these difficult conversations.
[01:41:06.240 --> 01:41:15.840]   And Eric himself has had a sort of complicated journey through academia in the sense that he's
[01:41:15.840 --> 01:41:20.080]   a really kind of renegade thinker in many kinds of ways. I'm not sure if you know who Eric is
[01:41:20.080 --> 01:41:21.280]   by any chance. - Heard the name.
[01:41:21.280 --> 01:41:22.400]   - Okay. - I actually
[01:41:22.400 --> 01:41:24.000]   checked out Zev. - Zev.
[01:41:24.000 --> 01:41:29.040]   - It was heartening for me to see that I was not the youngest person on this podcast.
[01:41:29.040 --> 01:41:31.360]   - You're the second youngest. - Second youngest.
[01:41:31.360 --> 01:41:45.520]   - That's hilarious. But Eric, he's kind of a renegade thinker. He's a mathematical physicist.
[01:41:46.480 --> 01:41:52.800]   With I believe a PhD at Harvard and he spent some time at MIT and so on. But he speaks to the fact
[01:41:52.800 --> 01:41:57.840]   that sort of there's a culture of conformity and so on. And if you're somebody who's a bit
[01:41:57.840 --> 01:42:02.000]   outside the box, a bit weird in whatever dimension of weird, that makes you actually
[01:42:02.000 --> 01:42:07.840]   kind of interesting that the system kind of wants to make you an outcast, wants to throw you out.
[01:42:07.840 --> 01:42:13.840]   And so he kind of opposes that whole idea. He's the perfect person to have conversations with
[01:42:13.840 --> 01:42:21.040]   in this kind of Librax kind of context of anonymity. Because I'll tell you the few
[01:42:21.040 --> 01:42:27.520]   conversations that came across and they were very quickly silenced. And I'm troubled by it.
[01:42:27.520 --> 01:42:35.520]   I'm not sure what to think of it. There's a few threads inside MIT, like on a mailing list,
[01:42:35.520 --> 01:42:41.680]   discussing Marvin Minsky. I don't know if you know who that is. He's an AI researcher. He's
[01:42:41.680 --> 01:42:47.280]   a seminal figure in AI before your time, but one of the most important people in art, in the history
[01:42:47.280 --> 01:42:55.440]   of artificial intelligence. And there was a discussion on a thread that involved
[01:42:55.440 --> 01:43:03.600]   the interaction between Marvin Minsky and Jeffrey Epstein. That conversation was quickly shut down.
[01:43:03.600 --> 01:43:09.360]   One person was pushed out of MIT, Richard Stallman, who's one of the key figures in the,
[01:43:09.360 --> 01:43:17.040]   because of that, because he wanted some clarity about the situation, but he also miss, he spoke
[01:43:17.040 --> 01:43:23.760]   like we mentioned earlier without grace, right? But he was quickly punished by the administration
[01:43:23.760 --> 01:43:27.920]   because of a few people protesting. And just that conversation,
[01:43:27.920 --> 01:43:37.280]   I guess what bothered me most is it didn't continue. It didn't expand. There was no like
[01:43:37.280 --> 01:43:44.560]   complexity. And there was a hunger that was clear behind that conversation, especially
[01:43:44.560 --> 01:43:49.840]   sort of for me, I'd like to understand Marvin Minsky was one of the reasons I wanted to come
[01:43:49.840 --> 01:43:56.400]   to MIT. He's passed away, but he's one of the key figures in the field that I deeply care about,
[01:43:56.400 --> 01:44:03.840]   artificial intelligence. And I thought that his name was dragged through the mud,
[01:44:04.480 --> 01:44:11.280]   through that situation and without ever being like resolved. And so it's unclear to me, like,
[01:44:11.280 --> 01:44:18.400]   what am I supposed to think about all this? And the only way to come to a conclusion there is to
[01:44:18.400 --> 01:44:22.880]   keep talking. It's like the thing we started this conversation with about truth is like,
[01:44:22.880 --> 01:44:30.480]   it's conversation. So in that sense, I'd love if people on Librex, perhaps in other places,
[01:44:30.480 --> 01:44:36.800]   but it seems like Librex is a nice platform to discuss Marvin Minsky, to discuss Jeffrey Epstein,
[01:44:36.800 --> 01:44:42.880]   to learn from it, to grow from it, to see how we can make MIT better. As I'm still one of the
[01:44:42.880 --> 01:44:49.120]   people, I've always dreamed of being at MIT. It was a dream come true in many ways. And I still
[01:44:49.120 --> 01:44:54.400]   believe that MIT is one of the most special places in this world, like many other universities,
[01:44:54.400 --> 01:45:00.160]   universities in general is truly special, man. It hurts my heart when people speak
[01:45:00.160 --> 01:45:06.160]   poorly of academia. I understand what they mean. They're very correct, but there is much more,
[01:45:06.160 --> 01:45:12.240]   in my opinion, that's beautiful about academia and that's broken. I mean, I don't know if you
[01:45:12.240 --> 01:45:17.200]   have something to comment. It doesn't necessarily need to be about Jeffrey Epstein, but there's
[01:45:17.200 --> 01:45:25.120]   these difficult things that come up that test the academic community, right? That it feels like
[01:45:25.120 --> 01:45:31.760]   conversation is the only way to resolve it. - I think people have a natural need for closure.
[01:45:31.760 --> 01:45:37.520]   And it's not just, I'm not as plugged into what academics are talking about as you would be, Lex,
[01:45:37.520 --> 01:45:41.440]   but I even- - Kids these days, no respect for Minsky.
[01:45:41.440 --> 01:45:48.000]   - Exactly. I mean, especially in the AI community, I'm not necessarily a programmer,
[01:45:48.000 --> 01:45:55.920]   but what I will say is that people come to LibreX and we always see a huge spike in users whenever
[01:45:55.920 --> 01:46:02.400]   there's a tragedy on campus or something where people need closure. Recently, there was a suicide
[01:46:02.400 --> 01:46:09.760]   just the other day on Yale's campus and people were just coming to pay respects and to say,
[01:46:09.760 --> 01:46:17.680]   "Rest in peace," and speak also about what might've led to an environment where people
[01:46:17.680 --> 01:46:27.360]   are drawn to these terrible results. - So just having a conversation is important there.
[01:46:27.360 --> 01:46:30.400]   'Cause it brings closure. - People need the space,
[01:46:30.400 --> 01:46:37.760]   especially when no one wants to go out and put their head above, be the longest blade of grass
[01:46:37.760 --> 01:46:42.080]   on that one because of the stigma. People need to be able to speak.
[01:46:42.080 --> 01:46:47.280]   - Yeah, that fear really bothers me, the fear that silences people,
[01:46:47.280 --> 01:46:57.040]   like where they self-censor, where they self-silence. Well, you've created an amazing
[01:46:57.040 --> 01:47:02.880]   place. I'm kind of interested in your struggle and your journey of creating positive
[01:47:05.840 --> 01:47:11.440]   incentives because it's a problem in a very different domain that I'm also interested in.
[01:47:11.440 --> 01:47:20.720]   So I love robotics, I love human-robot interaction. And so I believe that most people are good and we
[01:47:20.720 --> 01:47:25.760]   can bring out the best in human nature. Social networks is a very tricky space to do that in.
[01:47:25.760 --> 01:47:29.200]   So I'm glad you're taking on the problem and I'm glad you have the mission that you do.
[01:47:29.760 --> 01:47:36.240]   I hope you succeed. But you mentioned offline that you used to be into chess.
[01:47:36.240 --> 01:47:40.960]   Tell me about your journey through chess. - Sure. I was a very competitive tournament
[01:47:40.960 --> 01:47:45.360]   player growing up till about like 13. For the chess fans, I got to around 2000
[01:47:45.360 --> 01:47:53.440]   USCF. So I was a competitive player, especially my age group. And that actually led me to poker.
[01:47:55.840 --> 01:47:59.680]   I was playing a tournament and what happens is when you're like a very strong 13-year-old and
[01:47:59.680 --> 01:48:03.440]   you're playing locally, if you want a good match, you're going to end up playing a lot of adults.
[01:48:03.440 --> 01:48:10.480]   And I ended up playing this mid-40s guy who we played a really strong game. He actually beat me.
[01:48:10.480 --> 01:48:14.400]   I still remember the game and think, "Oh, I could have actually played that move instead of that
[01:48:14.400 --> 01:48:19.600]   one." But after the game, we had a post-mortem. It was this me, I think I was 13 at the time,
[01:48:19.600 --> 01:48:25.600]   and this 40-year-old hanging over this chess board and looking over the moves. And even at my age,
[01:48:25.600 --> 01:48:31.280]   it occurred to me that this guy was absolutely brilliant. And after the post-mortem, not only
[01:48:31.280 --> 01:48:35.120]   by the way in chess, but just in the way he articulates his thoughts as some people are,
[01:48:35.120 --> 01:48:39.600]   after the post-mortem, I went and looked him up online and I found out that he was a World Series
[01:48:39.600 --> 01:48:45.440]   of Poker champion. - Who is it? - His name is Bill Chen. - Oh, wow. - And I haven't really kept up
[01:48:45.440 --> 01:48:52.240]   with him except one time there was another chess tournament when I was around 14. And I followed
[01:48:52.240 --> 01:48:56.560]   him into an elevator as he was leaving the chess hall, pretending that I was going to go up just
[01:48:56.560 --> 01:49:02.080]   because I just wanted to talk to him. And I suggested a sequel or some changes that I thought
[01:49:02.080 --> 01:49:05.680]   he should make for his book. And he was like, "Actually, I was thinking of doing the same thing,"
[01:49:05.680 --> 01:49:11.200]   which was incredibly validating to my 14-year-old or 15-year-old self. But I really haven't kept up
[01:49:11.200 --> 01:49:16.400]   with him. So it's a shout out to him. And then he wrote a book called "The Mathematics of Poker"
[01:49:16.400 --> 01:49:22.080]   that I started reading. And that, first of all, kickstarted my interest in game theory. And second
[01:49:22.080 --> 01:49:28.960]   of all, in poker. So I started from chess and then poker. And I started with Bitcoin poker and
[01:49:28.960 --> 01:49:35.920]   had a lot of success with that. Met a lot of amazing friends. Learned a ton about, I mean,
[01:49:35.920 --> 01:49:41.120]   I think about entrepreneurship as well as taking risks, reasonable risks, positive expected value
[01:49:41.120 --> 01:49:49.360]   risks. And also just growing as a person and mathematician. - Did you say Bitcoin poker?
[01:49:49.360 --> 01:49:51.120]   - Yeah. - What's Bitcoin poker?
[01:49:51.120 --> 01:49:53.520]   - So you have to understand I was 14 years old, right? - Yes.
[01:49:53.520 --> 01:49:58.960]   - So how is a 14-year-old with wonderful parents who care about him and probably don't want him
[01:49:58.960 --> 01:50:05.600]   playing poker going to start playing poker? Because I wanted the challenge. I love the
[01:50:05.600 --> 01:50:10.080]   challenge. I love the competition. And I realized the answer is probably Bitcoin,
[01:50:10.080 --> 01:50:17.040]   because the implications of that. And they had these free roll tournaments, which for those
[01:50:17.040 --> 01:50:20.320]   of you who don't know what free rolls are, there's these promotional tournaments that
[01:50:20.320 --> 01:50:25.760]   sites put on where they'll put like a few dollars in and then thousands of people sign up and the
[01:50:25.760 --> 01:50:31.280]   winners get like a dollar. And I started there and I worked my way up. - That's amazing. What's
[01:50:31.280 --> 01:50:38.080]   your sense about from that time to today of the growth of the cryptocurrency community? I'm
[01:50:38.080 --> 01:50:46.160]   actually having like four or five conversation with Bitcoin proponents, Bitcoin maximists,
[01:50:46.160 --> 01:50:50.240]   and like all these, I'm just having all these cryptocurrency conversations currently,
[01:50:50.240 --> 01:50:55.680]   because there's so many brilliant, like technically brilliant, but also financially
[01:50:55.680 --> 01:51:00.480]   and philosophically brilliant people in those communities. It's fascinating with the explosion
[01:51:00.480 --> 01:51:05.760]   of impact. And also if you look into the future, the possible revolutionary impact
[01:51:05.760 --> 01:51:10.320]   on society in general. But what's your sense about this whole growth of Bitcoin?
[01:51:10.320 --> 01:51:16.560]   - I'm definitely less knowledgeable on the currency. Again, like programming, it was a means
[01:51:16.560 --> 01:51:18.080]   to an end. - Yes, got it.
[01:51:18.080 --> 01:51:23.360]   - What I will say is that there was this amazing community that grew out of it, and you'd have
[01:51:23.360 --> 01:51:30.960]   people who were willing to stake me or have me be their horse and they're my backer for having
[01:51:30.960 --> 01:51:37.680]   never met me for literally full Bitcoin tournaments, like full Bitcoin entry fee tournaments.
[01:51:38.240 --> 01:51:42.640]   And I get a percentage of the profits and they get a percentage. And to have that level of community
[01:51:42.640 --> 01:51:49.280]   for that degree of money, I mean, it gives you hope about the potential for humans to
[01:51:49.280 --> 01:51:53.760]   act in mutual best interest with a degree of trust.
[01:51:53.760 --> 01:51:59.200]   - Yeah, there's a really fascinating, strong community there. But speaking of like bringing
[01:51:59.200 --> 01:52:03.760]   out the best of human nature, it's a community that's currently struggling a little bit
[01:52:05.280 --> 01:52:11.840]   in terms of their ability to communicate in a positive, inspiring way. Like the Bitcoin folks,
[01:52:11.840 --> 01:52:20.640]   and we talk about this a lot, I honestly think they have a lot of love in their hearts and minds,
[01:52:20.640 --> 01:52:30.480]   but they just kind of naturally, because the world has been like institutions and the centralized
[01:52:30.480 --> 01:52:37.600]   powers have been sort of mocking and fighting them for many years that they've become sort of
[01:52:37.600 --> 01:52:42.800]   worn down and cynical. And so they tend to be a little bit more aggressive and negative on the
[01:52:42.800 --> 01:52:48.320]   internet in the way they communicate, especially on Twitter. And it's just created this whole
[01:52:48.320 --> 01:52:55.520]   community of basically being derisive and mocking and trolling and all this kind of stuff. But
[01:52:55.520 --> 01:53:00.560]   people are trying to, as the Bitcoin community grows, as the cryptocurrency community grows,
[01:53:00.560 --> 01:53:05.920]   they're trying to revolutionize that aspect too. So they're trying to find the positive core and
[01:53:05.920 --> 01:53:13.280]   grow in that way. So it's fascinating, 'cause I think all of us are trying to find the positive
[01:53:13.280 --> 01:53:19.040]   aspects of ourselves and trying to learn how to communicate in a positive way online. It's like
[01:53:19.040 --> 01:53:22.800]   the internet hasn't been around, social networks haven't been around that long. We're trying to
[01:53:23.680 --> 01:53:28.320]   figure this thing out. Let me ask you the ridiculous question. I don't know if you have an
[01:53:28.320 --> 01:53:34.000]   answer, but who is the greatest chess player of all time in your view? So since you like chess,
[01:53:34.000 --> 01:53:35.520]   you talk about- - That's on how you
[01:53:35.520 --> 01:53:40.720]   define it. But if you're talking about raw skill, like if you put everyone across time into a
[01:53:40.720 --> 01:53:45.120]   tournament together, Carlson would win. I don't think that's particularly controversial.
[01:53:45.120 --> 01:53:47.520]   - Oh, you mean like with the same exact skill level?
[01:53:47.520 --> 01:53:49.280]   - Exactly. - Magnus Carlson, okay.
[01:53:50.240 --> 01:53:57.760]   - Now, if you talk about political importance, I think Bobby Fischer is, he's the only one that
[01:53:57.760 --> 01:54:02.160]   people still, you go to someone on the street, they know Bobby Fischer because of what he
[01:54:02.160 --> 01:54:04.320]   represented, right? - Who do you think is more famous
[01:54:04.320 --> 01:54:09.920]   on the street, Garry Kasparov or Bobby Fischer? - Bobby, in America, Bobby Fischer.
[01:54:09.920 --> 01:54:11.360]   - You think so? - Yes.
[01:54:11.360 --> 01:54:14.160]   - That's interesting. I think we're gonna have to put that to the test.
[01:54:14.160 --> 01:54:18.240]   - Yeah, maybe it's more reflective of the community that I was a part of, but yeah.
[01:54:18.240 --> 01:54:23.440]   - Oh, so in the community you were part of, like, Young Minds, playing chess, Bobby Fischer
[01:54:23.440 --> 01:54:27.520]   was a superstar in terms of the roots. - Yeah, I think so, because he's American
[01:54:27.520 --> 01:54:36.400]   and he stood up against the big bad Russians at the time and unfortunately he had a very bad
[01:54:36.400 --> 01:54:44.320]   downfall. But for our geopolitical situation, he meant a lot. And then if you talk about,
[01:54:44.320 --> 01:54:49.920]   compared to contemporaries, actually, I would say Paul Morphy was a bit of a throwback.
[01:54:49.920 --> 01:54:55.040]   He's one of those geniuses that was just head and shoulders above everyone else.
[01:54:55.040 --> 01:54:59.920]   - Is there somebody that inspired your own play, like, as a Young Mind?
[01:54:59.920 --> 01:55:04.320]   - Yeah, I really liked Mikhail Tal. - So, like, you see, you were,
[01:55:04.320 --> 01:55:06.800]   I think he was very aggressive, right? - Yeah, very tactical.
[01:55:06.800 --> 01:55:12.720]   Which is funny, 'cause I found that I was better at, like, sort of slow methodical play
[01:55:12.720 --> 01:55:17.280]   than quick tactics. But I just, I mean, there's something beautiful about the creativity.
[01:55:17.280 --> 01:55:21.440]   And that's something I always latched onto, was being a creative player, being a creative person.
[01:55:21.440 --> 01:55:26.080]   I mean, chess doesn't really reward creativity as much as a lot of other things, especially
[01:55:26.080 --> 01:55:32.800]   entrepreneurial pursuits. Which I think is part of the reason why I sort of grew out of it. But
[01:55:32.800 --> 01:55:36.720]   I always was attracted to the creativity that I did see in chess.
[01:55:36.720 --> 01:55:42.560]   - So let me ask the flip, the other, 'cause you said poker, is there somebody that stands
[01:55:42.560 --> 01:55:50.160]   out to you as could be the greatest poker player of all time? Like, who do you admire in that role?
[01:55:50.160 --> 01:55:55.760]   - That's a more controversial one, because these chess players are such, like, first of all,
[01:55:55.760 --> 01:56:00.160]   there's more of an objective standard. And second of all, there's, like, they're, like, almost,
[01:56:00.160 --> 01:56:06.000]   like, cultural figures to me. Whereas poker players are more, like, live, living. They feel
[01:56:06.000 --> 01:56:10.560]   more, like, they feel more accessible. - But they also have, like, personalities.
[01:56:10.560 --> 01:56:12.400]   - Yeah. - Like, poker have, like, Phil Ivey
[01:56:12.400 --> 01:56:13.840]   as a personality. - They have vices.
[01:56:13.840 --> 01:56:19.760]   - They have vices, they have quirks, they have humor. Like, I guess we've seen videos of them.
[01:56:19.760 --> 01:56:21.840]   - Yeah. - Because it's such a recent
[01:56:21.840 --> 01:56:23.760]   development. - I'll say one person who I
[01:56:23.760 --> 01:56:29.680]   admire so much, and, like, if I could, like, have a dinner list of people that I want to have dinner
[01:56:29.680 --> 01:56:32.800]   with, like, maybe it'll happen now, actually. (both laugh)
[01:56:32.800 --> 01:56:35.920]   I would love to have dinner with him. Phil Galfond.
[01:56:35.920 --> 01:56:38.240]   - Oh, wow. - Who I don't, most people
[01:56:38.240 --> 01:56:39.440]   probably won't know. - Yeah.
[01:56:39.440 --> 01:56:47.280]   - But, on this podcast, but the way, first of all, he democratized poker learning in, like,
[01:56:47.280 --> 01:56:53.200]   the mathematical nitty-gritty, how do you get good at poker type sense, to the entire world,
[01:56:53.200 --> 01:56:59.200]   in, like, an unprecedented way. He was, he gave, he had this gift that he had learned and distilled
[01:56:59.200 --> 01:57:04.720]   by working with some of the greatest poker minds, and he just democratized it through his website.
[01:57:04.720 --> 01:57:11.840]   And I learned a ton from him. And not only that, but you just listen to him think, and it's almost
[01:57:11.840 --> 01:57:16.640]   like a philosophical meditation, the way that he breaks things down and thinks about these different
[01:57:16.640 --> 01:57:23.280]   elements and has such a holistic thought process. It's like watching a genius work. And, you know,
[01:57:23.280 --> 01:57:29.200]   he's also just a nice, fun, sociable guy that, like, you can imagine being at your dinner table.
[01:57:29.200 --> 01:57:30.960]   - Yeah. - So, all that combined.
[01:57:30.960 --> 01:57:34.720]   - Which is not true for a lot of poker players, right? A lot of them are dark souls.
[01:57:34.720 --> 01:57:40.000]   - To say the least, yes. - I really like the, what is he, Canadian,
[01:57:40.000 --> 01:57:42.320]   Daniel Negrano. - He's also a nice guy.
[01:57:42.320 --> 01:57:47.600]   - He's also a nice guy, but he's also somebody who's able to express his thoughts about poker
[01:57:47.600 --> 01:57:52.320]   really well, but also in an entertaining way. He seems to be able to predict cards
[01:57:52.320 --> 01:57:56.080]   better than anybody I've ever seen. Like, what-- - Did you watch the challenge?
[01:57:56.080 --> 01:57:59.440]   - Which challenge? - He lost, like, a million dollars
[01:57:59.440 --> 01:58:05.440]   recently to Doug Polk. He lost a million dollars to Doug Polk, Heads Up Online. It's really
[01:58:05.440 --> 01:58:09.280]   interesting. - Yeah, it's awesome to watch these guys
[01:58:09.280 --> 01:58:14.320]   work. So, I know you're 21? - 21.
[01:58:14.320 --> 01:58:23.840]   - 21. So, asking you for advice is a little bit funny, but at the same time, not, because you've
[01:58:23.840 --> 01:58:29.840]   created a social network. You've created a startup from nothing. As we talked about earlier,
[01:58:29.840 --> 01:58:33.840]   like, without knowing how to program, you've programmed. I mean, you've taken this whole
[01:58:33.840 --> 01:58:39.920]   journey that a lot of people, I think, would be really inspired by. So, given that, and given
[01:58:39.920 --> 01:58:43.280]   the fact that 20 years from now, you'll probably laugh at the advice you're gonna give now.
[01:58:43.280 --> 01:58:48.400]   - Absolutely, I hope so. If I don't laugh at the advice I give now, something went desperately
[01:58:48.400 --> 01:58:52.400]   wrong, right? - Yeah. So, do you have advice for people
[01:58:53.360 --> 01:58:59.600]   that wanna follow in your footsteps and create a startup, whether it's in the software app
[01:58:59.600 --> 01:59:04.720]   domain or whether it's anything else? - So, I'll speak specifically about social
[01:59:04.720 --> 01:59:06.240]   media apps. - Yes.
[01:59:06.240 --> 01:59:10.720]   - Try to keep it as narrow as possible so I can laugh as little as possible when I'm 41.
[01:59:10.720 --> 01:59:18.800]   And what I would say is that if you're like a 21, 22-year-old who's looking at me and being like,
[01:59:19.680 --> 01:59:25.360]   "I wanna do something like this," what I would say is you probably know better than just about
[01:59:25.360 --> 01:59:31.840]   anyone. And if you have a feeling in yourself that this is something that I have to do,
[01:59:31.840 --> 01:59:35.760]   and this is something I could imagine myself doing for the next 10 years, because if you're
[01:59:35.760 --> 01:59:40.960]   successful, you are gonna have to do it for the next 10 years. And through the ups and the downs,
[01:59:40.960 --> 01:59:46.000]   through the amazing interviews with Lex and through the not-so-amazing articles you might
[01:59:46.000 --> 01:59:51.920]   have with other people, right? And you're gonna have to ride those highs and lows, and you have
[01:59:51.920 --> 01:59:56.880]   to believe in what you're doing. But if you have that feeling, what I would say is listen to as
[01:59:56.880 --> 02:00:04.080]   few people as possible, because people are experts in domains, but when it comes to what's hot and
[02:00:04.080 --> 02:00:11.760]   what makes sense in a social context, you are the authority as a young person who's going through
[02:00:11.760 --> 02:00:21.440]   these things and living in your milieu. And I've talked to, at this point, so many experts,
[02:00:21.440 --> 02:00:30.080]   experts, so many investors, VCs. You'd be amazed at the advice I've gotten.
[02:00:30.080 --> 02:00:33.760]   >> So there's a minefield of bad advice?
[02:00:33.760 --> 02:00:37.920]   >> That's the hardest part, I think, for young people. And it's the thing,
[02:00:38.560 --> 02:00:44.720]   when people, like, I help Yellies all the time who ask, like, I never turn down when a founder
[02:00:44.720 --> 02:00:50.400]   asks me to have a conversation, I never turn it down. I'm always there for them. And the number
[02:00:50.400 --> 02:00:57.280]   one thing I worry about is that at Yale, we're taught implicitly and explicitly that you listen
[02:00:57.280 --> 02:01:04.560]   to the adult in the room, you listen to the person with the highest pay grade. And it's devastating,
[02:01:04.560 --> 02:01:07.040]   'cause that's how innovation dies. And, you know...
[02:01:07.040 --> 02:01:13.440]   >> Yeah, it's intimidating, too. You talk to VC who probably made--
[02:01:13.440 --> 02:01:14.560]   >> Is worth a billion dollars.
[02:01:14.560 --> 02:01:20.720]   >> Yeah, billion dollars, and they're going to tell you, you know, all the successful startups
[02:01:20.720 --> 02:01:26.560]   they helped fund, or even just a successful business owner is going to tell you some advice.
[02:01:26.560 --> 02:01:33.600]   And it's hard psychologically to think that they might be wrong. Yeah, but you're saying that's
[02:01:33.600 --> 02:01:34.720]   the only way you succeed is just listen to yourself.
[02:01:34.720 --> 02:01:37.360]   >> It's the only way you can succeed, 'cause if they knew what they were doing,
[02:01:37.360 --> 02:01:44.160]   they would have built it themselves. And what's especially hard is people go, "Oh, of course,
[02:01:44.160 --> 02:01:48.400]   you know, I'll listen to people's, I'll listen to their advice, but I'll know why it's wrong.
[02:01:48.400 --> 02:01:53.680]   And then I'll do my own thing." And that sounds greatly abstract, but sometimes you can't always
[02:01:53.680 --> 02:01:58.960]   even put your finger on why they're wrong. And I think to have the conviction to say,
[02:01:59.680 --> 02:02:05.280]   "You're wrong, and I can't tell you why, but I still think I'm right." It's a rare thing,
[02:02:05.280 --> 02:02:11.280]   especially at like, it's very counterintuitive. And you might even say it's hubris or arrogant,
[02:02:11.280 --> 02:02:16.160]   but I think it's necessary, 'cause a lot of these things are, they're not things that you can really
[02:02:16.160 --> 02:02:22.720]   put into words until you see them in action. Like a lot of them are kind of happy accidents.
[02:02:22.720 --> 02:02:30.400]   >> Yeah, it's been tough for me, like as a person who, like I'm very empathetic, so when people
[02:02:30.400 --> 02:02:38.400]   tell me stuff, I kind of want to understand them. And it's been a painful process, especially people
[02:02:38.400 --> 02:02:45.120]   close to me. Basically everything I've done, especially in the recent few years, a lot of
[02:02:45.120 --> 02:02:54.800]   people close to me said not to do. And like my parents too, that's been a hard one, is to basically
[02:02:54.800 --> 02:03:04.640]   acknowledge to myself that you don't know, like you don't, that everything you're going to say
[02:03:04.640 --> 02:03:09.680]   by way of advice for me is not going to be helpful. Like I love my parents very much,
[02:03:10.640 --> 02:03:17.600]   but like, they're just like, they don't get it. And as you put it beautifully,
[02:03:17.600 --> 02:03:26.480]   it's very difficult to put your finger on exactly why, because a lot of advice sounds reasonable.
[02:03:26.480 --> 02:03:35.760]   >> That's the worst kind. If it sounds really good, that just means it's an earworm. Like that's like
[02:03:35.760 --> 02:03:40.160]   a song that you hear on the radio and then you're like, you're humming it in the car and it's like,
[02:03:40.160 --> 02:03:44.640]   it's the same thing. The better it sounds, the more skeptical.
[02:03:44.640 --> 02:03:50.480]   >> Yeah. Reason is a bad drug. Like you should be very careful, because like,
[02:03:50.480 --> 02:03:57.520]   you know, the things that seem impossible, every major innovation, every major business
[02:03:57.520 --> 02:04:03.280]   seems impossible at birth. But even not just the impossible things, I think, you know,
[02:04:03.280 --> 02:04:11.280]   you look at like love, for example, it's very easy to give advice to sort of point out all the ways
[02:04:11.280 --> 02:04:17.040]   it can go wrong, or marriage, all the divorces that people go through, all the pain of years
[02:04:17.040 --> 02:04:22.960]   that you go through, the divorce, like the system of marriage, the marriage industrial complex,
[02:04:22.960 --> 02:04:28.160]   all the money that's wasted, all those kinds of things. But that advice is useless when you're
[02:04:28.160 --> 02:04:35.280]   in love. The point is to just pat the person on the back and say, go get them kid. Like,
[02:04:35.280 --> 02:04:38.320]   what is it? Good Will Hunting, I went to see about a girl.
[02:04:38.320 --> 02:04:39.600]   >> Oh, yeah.
[02:04:39.600 --> 02:04:42.080]   >> That's a good movie.
[02:04:42.080 --> 02:04:42.800]   >> I love that movie.
[02:04:42.800 --> 02:04:50.400]   >> But yeah, that's, that took me a long time to figure out. I'm still trying to fight through it,
[02:04:50.400 --> 02:04:59.360]   but especially when you're young, that's hard. But nothing in life is worth accomplishing is easy.
[02:04:59.360 --> 02:05:03.440]   >> But I think it's really interesting you make that connection between like startup advice
[02:05:03.440 --> 02:05:09.120]   and like your parents, because it's the exact same sort of mechanism, where when you're young,
[02:05:09.120 --> 02:05:14.560]   your parents are usually like, right, right? And the experts are usually right. And you know,
[02:05:14.560 --> 02:05:18.800]   if you listen to them, and you follow their orders, you're going to go to a school like Yale.
[02:05:18.800 --> 02:05:19.360]   >> Yeah.
[02:05:19.360 --> 02:05:26.240]   >> And at a certain point, stops making sense. I've seen my friends at Yale go down paths,
[02:05:26.240 --> 02:05:31.440]   because they just continued listening to their parents that I know in their heart of hearts
[02:05:31.440 --> 02:05:32.960]   is not the right path for them.
[02:05:32.960 --> 02:05:41.760]   >> Yeah, you know what? That's how I see the education system. The whole point is to guide
[02:05:41.760 --> 02:05:50.160]   you to a certain point in your life, and everybody's point is different. And your task is
[02:05:50.160 --> 02:05:55.760]   to at that point, to have a personal revolution and create your own path.
[02:05:55.760 --> 02:05:56.800]   >> But no one tells you that.
[02:05:56.800 --> 02:06:01.360]   >> Nobody tells you that, because they want you to keep following the same path as they're leading
[02:06:01.360 --> 02:06:05.920]   you towards. Like they're not going to say your whole job is to eventually rebel.
[02:06:05.920 --> 02:06:06.640]   >> Yeah.
[02:06:07.360 --> 02:06:12.800]   >> That's how rebellion works. You're not supposed to be told, but that is the task.
[02:06:12.800 --> 02:06:17.920]   They can take you just like you said, and depending who you are, they can take you really
[02:06:17.920 --> 02:06:22.960]   far. But at a certain point, you have to rebel. That could be getting a PhD, that could be in
[02:06:22.960 --> 02:06:24.400]   your undergrad, that could be high school.
[02:06:24.400 --> 02:06:29.120]   >> Yeah, it could be any point. One thing that I think played a pretty pivotal role,
[02:06:29.120 --> 02:06:34.240]   and I've never really mentioned this, he might not even know the person about to tell you about,
[02:06:35.280 --> 02:06:39.680]   in sort of me actually going out and making Librex, was that I was taking this graduate
[02:06:39.680 --> 02:06:48.880]   level math class, I think my sophomore year. And I met this PhD student who was also in it,
[02:06:48.880 --> 02:06:54.880]   and had considerable citations and also startup experience. And I think he actually ended up
[02:06:54.880 --> 02:07:00.640]   being the CTO of a unicorn later on. I've sort of lost touch with him, but we're still Facebook
[02:07:00.640 --> 02:07:08.720]   friends, as it is in the 21st century. And I was in a class and I was telling him, "I really want
[02:07:08.720 --> 02:07:15.600]   to make this thing, but I have no technical background." And this guy's a computer genius,
[02:07:15.600 --> 02:07:21.680]   he worked under Dan Spielman at Yale. So he's a good guy, right? And we were doing some math
[02:07:21.680 --> 02:07:27.120]   together. We were doing something on discrepancy, for those of you who really care about math,
[02:07:27.120 --> 02:07:33.600]   so combinatorics. And he just turns to me, he's like, "I think you could do it." I'm like,
[02:07:33.600 --> 02:07:37.920]   "What do you mean, you think I could do it?" He's like, "I think you could do it." And I was like,
[02:07:37.920 --> 02:07:44.320]   "Really?" But I respected this guy so much. His name was Young Duck. Shout out to Young Duck.
[02:07:44.320 --> 02:07:48.720]   I respected this guy so much that I was like, "If Young Duck says I can do it, and Young Duck is a
[02:07:48.720 --> 02:07:54.080]   legit genius, and he knows, and he knows me." Because we were in two classes together, and we'd
[02:07:54.080 --> 02:07:59.200]   spend a lot of time together. If he thinks I can do it, then who am I to say I can't do it?
[02:07:59.200 --> 02:08:02.400]   Yeah, that's a lesson for mentorship.
[02:08:02.400 --> 02:08:05.360]   By the way, he has no idea, probably.
[02:08:05.360 --> 02:08:10.720]   Well, and he might not even remember that interaction, which is funny. But the point is
[02:08:10.720 --> 02:08:19.760]   that when a crazy young kid comes up to you with a crazy dream, every once in a while,
[02:08:19.760 --> 02:08:25.760]   you should just pat him on the back and say, "I believe in you." You can do it. If they look up to
[02:08:25.760 --> 02:08:35.840]   you, that means your words have power. And if you say, "No, no, come on, be reasonable. Finish your
[02:08:35.840 --> 02:08:41.040]   schoolwork," kind of thing, that's unreasonable to take that leap. "No, just finish your education,"
[02:08:41.040 --> 02:08:47.120]   blah, blah, blah. Whatever the reasonable advice is, every once in a while, maybe often as a
[02:08:47.120 --> 02:08:53.680]   mentor, you should say, "Go see about a girl in California," or whatever the equivalent is.
[02:08:53.680 --> 02:08:56.720]   That was my moment. That was my Goodwill Hunting moment.
[02:08:56.720 --> 02:09:02.080]   That's your Goodwill Hunting moment. Man, I miss Robin Williams. That was a special guy.
[02:09:02.080 --> 02:09:08.640]   People love it when I ask about book recommendations in general. Of course,
[02:09:08.640 --> 02:09:12.080]   your journey is just beginning, but is there something that jumps out to you,
[02:09:12.080 --> 02:09:18.240]   technical, fiction, philosophical, sci-fi, coloring books, blog posts you read somewhere
[02:09:18.240 --> 02:09:20.880]   that had an impact on your life?
[02:09:20.880 --> 02:09:22.320]   Video games.
[02:09:22.320 --> 02:09:27.120]   Video games that you recommend to others. Minecraft, manual.
[02:09:27.120 --> 02:09:28.500]   Manga.
[02:09:28.500 --> 02:09:33.360]   I mean, yeah, video. You could mention video games too, if there's something that jumps out to you
[02:09:33.360 --> 02:09:35.040]   that just had an impact.
[02:09:36.800 --> 02:09:43.440]   I guess I'll say I really like the book The War of Art, which is a book about creative resistance
[02:09:43.440 --> 02:09:50.000]   and the creative struggle and what it means to be creative. Part of what I see in this conversation
[02:09:50.000 --> 02:09:56.000]   and what you're doing, Lex, is so much of The War of Art's idea is that you just keep writing
[02:09:56.000 --> 02:10:04.160]   and writing and writing until you get to the new crap. You just roll with it, right? That's sort
[02:10:04.160 --> 02:10:08.720]   of what happens when you have three-hour conversations with people is you can only have
[02:10:08.720 --> 02:10:14.320]   so much scripted or societally constructed stuff until you get to the real you.
[02:10:14.320 --> 02:10:19.040]   And you have to show up. I mean, that book is kind of painful.
[02:10:19.040 --> 02:10:22.560]   It's really painful. And it's not something I would recommend for every part of it,
[02:10:22.560 --> 02:10:27.280]   but for what it did in my life at the time. It also kind of normalized, I don't know,
[02:10:29.040 --> 02:10:35.360]   part of my coming-of-age story is part of it's about realizing that I'm a creative person
[02:10:35.360 --> 02:10:41.840]   and person who needs to create. That's sort of a God-given thing, I think, for a lot of people,
[02:10:41.840 --> 02:10:46.240]   but it's something that I don't really feel like I can live without. And part of it was realizing
[02:10:46.240 --> 02:10:50.160]   that even within some of these more rigid structures, it's okay that I don't sort of
[02:10:50.160 --> 02:10:55.840]   fit in with them. And to hear about the struggles of other creatives was something for my own
[02:10:55.840 --> 02:11:01.360]   self-esteem and my own growing up that was really important to me. So I don't think the book itself
[02:11:01.360 --> 02:11:06.160]   might be perfect, but for what it did for my life, it was really impactful.
[02:11:06.160 --> 02:11:13.440]   Yeah, I think exactly. The words may not be exactly right by way of advice, but I think
[02:11:13.440 --> 02:11:20.880]   the journey that a lot of creatives take by reading that book is kind of profound. He also
[02:11:20.880 --> 02:11:27.520]   has another one called "Turning Pro," I think. I mean, he in general espouses taking it seriously.
[02:11:27.520 --> 02:11:32.240]   If you have a creative mind and you want to create something special in this world,
[02:11:32.240 --> 02:11:38.320]   go do it. Don't show up and look at the blank page.
[02:11:38.320 --> 02:11:45.680]   And so many people would tell me, would encourage me either blatantly or through implicit means
[02:11:45.680 --> 02:11:50.880]   to basically take the Apolesis seriously. It's a good signal, by the way.
[02:11:50.880 --> 02:11:57.440]   It's a good signal because my really close friends, the ones who have always supported me,
[02:11:57.440 --> 02:12:02.160]   they never said that because they got it. They understood that that was my path. And they might
[02:12:02.160 --> 02:12:07.840]   be skeptical. They might be like, I mean, one of my friends I remember told me, "I was always
[02:12:07.840 --> 02:12:12.720]   taken aback about why you were so certain this would work out." And he's like, "I finally got
[02:12:12.720 --> 02:12:18.160]   it once I saw it popping off, but before that I just didn't get it." But he still supported me.
[02:12:18.160 --> 02:12:24.400]   And I think it's a really good signal. And actually, just the fact of going through this
[02:12:24.400 --> 02:12:29.920]   process has made me socially feel so much more connected. And I've somewhat consolidated my
[02:12:29.920 --> 02:12:34.640]   social life to some degree, but it's so much more vulnerable connected. And that's part of
[02:12:34.640 --> 02:12:40.480]   the creative process. I have to thank for that, I think. There's something that's unstoppable about
[02:12:40.480 --> 02:12:48.000]   the creative mind. It's right there, that fire. And I guess part of the thing that you're supposed
[02:12:48.000 --> 02:12:51.760]   to do is let that fire burn in whichever direction. - And it's gonna hurt.
[02:12:51.760 --> 02:12:57.520]   - It's gonna hurt. Fire will hurt. But on the topic of video games, you mentioned Stanley
[02:12:57.520 --> 02:13:04.000]   Parable offline. You said you play some video games. Is there a video game that you especially
[02:13:04.000 --> 02:13:09.600]   love that you recommend I play, for example? - Yeah, I'll mention it's actually freely
[02:13:09.600 --> 02:13:14.880]   in keeping with what we've been talking about. It's The Beginner's Guide, which is what I...
[02:13:14.880 --> 02:13:19.760]   It was made by the same guy, Davey Rendon, who made The Stanley Parable, which I briefly saw
[02:13:19.760 --> 02:13:26.640]   you... I just clicked the video and then I went to sleep. It was like 2 a.m. But I briefly saw
[02:13:26.640 --> 02:13:33.840]   that you were looking at. And it's a game that is better treated as art. And I think...
[02:13:37.440 --> 02:13:40.800]   I won't claim to understand the creator, 'cause that would be a cardinal sin
[02:13:40.800 --> 02:13:49.040]   to me as a creative person. But it gets to the heart of a lot of the things that we've been
[02:13:49.040 --> 02:13:55.200]   talking about, which is the creative mind. The game can be interpreted in a lot of ways,
[02:13:55.200 --> 02:14:00.880]   in a feminist way. It could be interpreted as a story of friends. It could be interpreted
[02:14:01.440 --> 02:14:07.440]   as the story of critics versus a creative. The way I like to interpret it, and I don't want to
[02:14:07.440 --> 02:14:16.160]   give away too much, is the story of the creative part of your mind that creates just for the sake
[02:14:16.160 --> 02:14:23.600]   of creating. Meaning the part that creates for no rhyme or reason or clear meaning. It's almost
[02:14:24.560 --> 02:14:32.080]   ethereal. Versus the part that's... You could call it the editor. You could call it the pragmatist.
[02:14:32.080 --> 02:14:38.640]   You could call it the necessary force of ego in our lives. We can't totally be egoless, right?
[02:14:38.640 --> 02:14:45.200]   But we need to be egoless to be creative. And how that sort of internal censure... What role does
[02:14:45.200 --> 02:14:50.160]   it play? And how do we allow our creative minds to be creative? And yet, how do we still become
[02:14:50.160 --> 02:14:55.840]   useful? Because... And it's funny that a video game could have this in.
[02:14:55.840 --> 02:15:02.480]   It's a fascinating tension, which reminds me about the ridiculous question I every once in a while
[02:15:02.480 --> 02:15:11.280]   ask about meaning and death. So this whole ride ends. You're at the beginning of the ride,
[02:15:11.280 --> 02:15:17.360]   but it could end any day, actually. That's kind of the way human life works. You could die today,
[02:15:17.360 --> 02:15:22.000]   you can die tomorrow. Do you think about your own mortality? Do you think about death?
[02:15:22.000 --> 02:15:30.560]   Do you meditate on it? And in that context, as the creative, but a pragmatist too,
[02:15:30.560 --> 02:15:34.720]   as running a startup, what do you think is the meaning of this whole thing?
[02:15:34.720 --> 02:15:44.720]   Yeah, so, on mortality, right? About three years ago, four years ago now,
[02:15:45.440 --> 02:15:53.040]   I was excited to go to Yale. I was playing six hours of squash a day, which squash is a sport I
[02:15:53.040 --> 02:15:58.160]   love so much. And I was really getting a lot better. And I was even thinking I could maybe
[02:15:58.160 --> 02:16:11.280]   walk onto the Yale team. And I woke up one day, I felt really, really sick. I went and I decided
[02:16:11.280 --> 02:16:18.560]   not to go to squash that day. And I know, I wanted to, I almost did. And you'll see how this story
[02:16:18.560 --> 02:16:22.800]   turns out. You'll decide if I made the right choice. I decided not to go to squash today.
[02:16:22.800 --> 02:16:27.040]   And I decided to get my driver's license, or I had to get my driver's license, because I wanted to
[02:16:27.040 --> 02:16:31.600]   get a driver's license before I, it's just how young I am, before I went off to college, because
[02:16:31.600 --> 02:16:36.640]   otherwise I might never get it. And I'm going back and I successfully got my driver's license,
[02:16:36.640 --> 02:16:44.960]   brahsham. And I go back to my house and I decided I don't want to drive back because I just feel so
[02:16:44.960 --> 02:16:50.720]   sick. Things are spinning. I have the worst headache. I come home, I run back right into my
[02:16:50.720 --> 02:16:56.640]   bed and feeling really sick to the point where I even asked my mom, who is a doctor, I'm like,
[02:16:56.640 --> 02:17:01.120]   should I go to the hospital? And she's like, you can just wait it out. I'm sure it'll get better.
[02:17:01.120 --> 02:17:02.960]   - I like your mom.
[02:17:02.960 --> 02:17:08.320]   - Yeah. And then, you know, and then at one point I look at my arms and they're like
[02:17:08.320 --> 02:17:14.080]   covered in this like red splotchy stuff. Yeah. And I'm like, well, I think, and she's like,
[02:17:14.080 --> 02:17:19.200]   yeah, we have to go. And so I go there and they're like, you have scarlet fever. And
[02:17:19.200 --> 02:17:23.120]   they're like, there's nothing we can do. You should probably just go back home. So I go back home,
[02:17:23.120 --> 02:17:30.160]   six hours later, I wake up in the morning. They'd let me out at like 3 AM. They let me,
[02:17:30.160 --> 02:17:34.080]   I come home in the morning and I feel this, like a spear through my chest.
[02:17:34.080 --> 02:17:39.680]   And I never felt anything like it. And I was, it was very disconcerting when you have a,
[02:17:39.680 --> 02:17:43.600]   cause we're all used to different sorts of pain. Right. And that was the sort of pain I never felt
[02:17:43.600 --> 02:17:49.680]   before. I suppose as an athlete, you're used to like, you know, pain. So I told my parents and
[02:17:49.680 --> 02:17:53.440]   immediately we hopped back in the car, we'd go up to the same hospital I was at six hours ago.
[02:17:53.440 --> 02:17:57.040]   And they initially didn't want to let me in. And I was like, I have chest pain. They're like, oh,
[02:17:57.040 --> 02:18:00.560]   come in. Cause they're like, you're a healthy guy. Wait your turn. And I'm like, no, you don't
[02:18:00.560 --> 02:18:05.680]   understand. I have like a pain in my chest. And then they let me in. They start doing tests on me.
[02:18:05.680 --> 02:18:11.440]   They like put something like in my back, which is really scary. It's a huge needle. And I'm smiling
[02:18:11.440 --> 02:18:16.240]   because it's like one of the ways I reduce stress, I guess, or deal with this sort of thing and make
[02:18:16.240 --> 02:18:22.560]   light of it. But like, no, that, you know, it's definitely very scary in the moment, shocking and
[02:18:22.560 --> 02:18:29.200]   scary. And they go and they do a bunch of tests and they determined that a virus like attacked my
[02:18:29.200 --> 02:18:36.320]   heart and I had myocarditis and pericarditis. And they said I had maybe 25 to 35% chance at
[02:18:36.320 --> 02:18:45.280]   one point of dying. And so I'm sitting in my, they admit me into the hospital. I'm in my bed for about
[02:18:45.280 --> 02:18:54.320]   three weeks. And I'm just, I'm just standing there. And I had this moment also that I remember
[02:18:54.320 --> 02:19:03.840]   very specifically where I was in so much pain that like I was crying, not out of like emotional
[02:19:03.840 --> 02:19:09.680]   standpoint, but actually just purely out of the pain itself. Like I could feel my heart in my
[02:19:09.680 --> 02:19:14.640]   chest. And when I leaned back, I felt it touch my rib cage and feel horrible. So I couldn't go to
[02:19:14.640 --> 02:19:19.920]   sleep and lean back. I had to lean forward all throughout the night. Right. And I'm feeling my,
[02:19:19.920 --> 02:19:23.680]   and I'm feeling my chest. I'm feeling this terrible pain in my chest. I'm crying
[02:19:23.680 --> 02:19:29.680]   unstoppably. And I mean, also, maybe I should mention that at the time I was someone who'd like
[02:19:29.680 --> 02:19:35.280]   refused to take in anything into my body that wasn't natural. And so a lot of the time I tried
[02:19:35.280 --> 02:19:41.440]   to be unmedicated. Eventually I didn't allow them to add a little medication to my body,
[02:19:41.440 --> 02:19:47.600]   but there's just so much uncertainty and pain. And the first time I had to come to terms with
[02:19:47.600 --> 02:19:53.520]   mortality. First of all, I think you still should have gone play squash. I mean, come on. I mean,
[02:19:53.520 --> 02:19:59.680]   yeah. I thought you were serious about this. You still carry that with you sort of.
[02:19:59.680 --> 02:20:09.920]   There is power to realizing the ride can end. Right. Very suddenly. Very suddenly. Yeah.
[02:20:10.640 --> 02:20:18.640]   And painfully. And, you know, it has pragmatic application to like what you,
[02:20:18.640 --> 02:20:25.200]   to trajectories you take through life. Right. Something else that is worth noting is that I,
[02:20:25.200 --> 02:20:32.400]   for the next year, couldn't walk to my classes. So I get to Yale, they put me in a medical single
[02:20:32.400 --> 02:20:38.800]   alone, and I have to get shuttled to all my classes. I have to ask, I had to ask a few
[02:20:38.800 --> 02:20:44.640]   professors to even move classes so I could actually get there. I can't move my book. I
[02:20:44.640 --> 02:20:52.800]   can't lift my book bags. I can't, I can't walk upstairs. I spent like 12 hours a day in my dorm
[02:20:52.800 --> 02:21:00.480]   room, just like staring at the walls and more so, and more than that, all this, like you, I got to
[02:21:00.480 --> 02:21:08.960]   watch my body, like deteriorate and like the muscle like fall off of it. Cause I was, I was
[02:21:08.960 --> 02:21:16.080]   taking these pills and they're kind of catabolic. And for an 18 year old, I mean, I think every 18
[02:21:16.080 --> 02:21:22.240]   year old has feelings about their body, man or woman. And, you know, just seeing this, it's like
[02:21:22.240 --> 02:21:27.840]   you're watching sort of death transpire. And you're also very fatigued because your heart's not at
[02:21:28.640 --> 02:21:33.120]   peak condition and you're thinking about the future. And a lot of the things you enjoy have
[02:21:33.120 --> 02:21:41.040]   kind of been stripped away from you. And I took up a meditation practice, like started with like
[02:21:41.040 --> 02:21:47.120]   five minutes a day. At my peak, I was at like 40 minutes a day, kept it up consistently for about
[02:21:47.120 --> 02:21:54.080]   two years. And I started thinking about like, what do I want to do? And like, what do I care about?
[02:21:56.480 --> 02:22:02.400]   And to get to your point, I think you're asking like, how does this carry forward, right? I think
[02:22:02.400 --> 02:22:08.560]   I realized that, you know, there's an end and I realized that there are things I believe
[02:22:08.560 --> 02:22:14.640]   and things that I believe that might not be so overtly popular, but that I truly think make
[02:22:14.640 --> 02:22:21.520]   the world a better place. And in spite of, and in basically if my conditions provided,
[02:22:21.520 --> 02:22:27.360]   I wanted to make something that, I wanted to do something that would make me feel sort of
[02:22:27.360 --> 02:22:32.000]   whole in that way. - Yeah. I mean, that's an amazing journey to take that time and to come
[02:22:32.000 --> 02:22:38.400]   out on the other end. Now, man, that's amazing. I did not realize like that there was a long-term
[02:22:38.400 --> 02:22:47.520]   struggle. I think that's in the end, if you do succeed, we'll have a profound positive impact
[02:22:47.520 --> 02:22:55.440]   because struggle is ultimately like humbling, but also empowering. So I'm glad to see that.
[02:22:55.440 --> 02:22:59.840]   But from the perspective of the creative, the other ridiculous question about meaning,
[02:22:59.840 --> 02:23:10.320]   do you think about this kind of stuff? Is that the meaning of life for you, the meaning of life for
[02:23:10.320 --> 02:23:16.480]   us descendants of apes in general? - The first thing I'd like to say is that I think part of
[02:23:16.480 --> 02:23:20.640]   like when we talk about the meaning of life, part of it is the fact that we get to struggle with
[02:23:20.640 --> 02:23:28.800]   this question and we get to do it together for a long time. And sometimes I think it's accepting
[02:23:28.800 --> 02:23:33.760]   that there's no meaning at all. And sometimes I think it's accepting that, or even just parsing
[02:23:33.760 --> 02:23:38.080]   the phrase and thinking about the meaning of life. I sometimes, I'm look, I'm very young.
[02:23:38.080 --> 02:23:45.680]   Again, I hope that anything I say now is going to be very different in the future because I think
[02:23:45.680 --> 02:23:52.560]   meaning, life has so many meanings that it'll be crazy to see what I think in 20 years about
[02:23:52.560 --> 02:23:59.200]   the meaning of life. - Yeah, rise from the future, cut them some slack. - Please do. Perspective,
[02:23:59.200 --> 02:24:05.760]   perspective, perspective. Having said that, I think part of what brings meaning to my life
[02:24:05.760 --> 02:24:10.560]   is things like this, where we think about these things with people who are really, really,
[02:24:10.560 --> 02:24:15.600]   really on the ball and we get to connect with these people. That certainly brings meaning to
[02:24:15.600 --> 02:24:22.880]   my life, human connection. - Yeah, this conversation is just another like echo of the thing you're
[02:24:22.880 --> 02:24:29.600]   trying to create in the digital space, right? - Yes. - That's the same kind of magic. From what
[02:24:29.600 --> 02:24:34.080]   I understand about what you're trying to create is the same reason I fell in love with the long
[02:24:34.080 --> 02:24:39.760]   form podcast thing, like as a fan, that's why I listen to long form podcasts, is there's something
[02:24:39.760 --> 02:24:48.320]   deeply human and genuine about the interchange through the voice. But I do think that connection
[02:24:48.320 --> 02:24:54.960]   through text can be even more powerful. Like I think about letters, I still write letters to
[02:24:54.960 --> 02:25:04.240]   Russia, there's something powerful in letters. When you put a lot of yourself in the words you say,
[02:25:04.240 --> 02:25:11.280]   in the words you write, that's powerful. You can really communicate, not just the actual semantic
[02:25:11.280 --> 02:25:18.960]   meaning of the words, but like a lot of who you are through those words and create real connections.
[02:25:18.960 --> 02:25:27.680]   So I hope you succeed there. And listen, Ryan, I think this was an incredible conversation. I'm
[02:25:27.680 --> 02:25:34.560]   glad that people like you are fighting the good fight for bringing out the best in human nature
[02:25:34.560 --> 02:25:41.600]   in the digital space. I think that's a battleground where the good will win, like love will win. And
[02:25:41.600 --> 02:25:46.640]   I'm glad you're creating technology that does just that. So thank you so much for wasting all your
[02:25:46.640 --> 02:25:51.280]   time, for coming down. I can't wait to see what you do in the future. Thanks for talking today.
[02:25:51.280 --> 02:25:52.640]   - Thank you for having me. - Bam.
[02:25:52.640 --> 02:25:57.200]   - How many finger guns have you gotten at the end of the podcast?
[02:25:57.200 --> 02:25:59.360]   - Zero. - Two now.
[02:25:59.360 --> 02:26:06.320]   - Thanks for listening to this conversation with Ryan Schiller, and thank you to all our sponsors,
[02:26:06.320 --> 02:26:12.640]   Allform, Magic Spoon, BetterHelp, and Brave. Click their links to support this podcast.
[02:26:12.640 --> 02:26:20.960]   And now let me leave you with some words from George Washington on March 15th, 1783.
[02:26:21.760 --> 02:26:28.640]   "If freedom of speech is taken away, then dumb and silent we may be led, like sheep to the slaughter."
[02:26:28.640 --> 02:26:32.960]   Thank you for listening, and hope to see you next time.
[02:26:33.840 --> 02:26:33.920]   [END]
[02:26:34.560 --> 02:26:36.560]   George Washington, "Freedom of Speech" - March 15, 1783.
[02:26:36.560 --> 02:26:46.560]   [BLANK_AUDIO]

