
[00:00:00.000 --> 00:00:09.320]   The focus, as I see it in the industry, has shifted from sometimes making the models into
[00:00:09.320 --> 00:00:15.920]   make them work well in the real world and be able to be flexible enough and adapt changes.
[00:00:15.920 --> 00:00:21.660]   So that's, I guess I can say that many times maintaining the model and make it good and
[00:00:21.660 --> 00:00:27.600]   reliable out there is sometimes much harder than actually developing it.
[00:00:27.600 --> 00:00:31.960]   You're listening to Gradient Dissent, a show about machine learning in the real world,
[00:00:31.960 --> 00:00:34.440]   and I'm your host, Lukas Biewald.
[00:00:34.440 --> 00:00:41.800]   Nimrod is a senior computer vision algorithms developer at Nanit and the father of two children.
[00:00:41.800 --> 00:00:45.720]   Nanit develops smart baby monitoring systems and it's a product that I happen to use every
[00:00:45.720 --> 00:00:46.720]   day.
[00:00:46.720 --> 00:00:50.000]   So I'm extra excited to talk to him.
[00:00:50.000 --> 00:00:55.240]   So Nimrod, I'm super excited to talk to you about the article you wrote on ML in production,
[00:00:55.240 --> 00:01:00.160]   but I'd say I'm especially excited to talk to you because you make maybe the app that
[00:01:00.160 --> 00:01:02.360]   I use the most these days, the Nanit app.
[00:01:02.360 --> 00:01:07.360]   So my daughter actually turned one today and we've been using it for the last year.
[00:01:07.360 --> 00:01:11.720]   And basically every morning, my mother-in-law and my wife kind of discussed the stats from
[00:01:11.720 --> 00:01:13.760]   the previous night's sleep.
[00:01:13.760 --> 00:01:15.560]   So I really, really love your app.
[00:01:15.560 --> 00:01:16.560]   I can say that honestly.
[00:01:16.560 --> 00:01:20.320]   And I was proud to discover that you were customers of Weights and Biases.
[00:01:20.320 --> 00:01:23.440]   But I was wondering if you could start by maybe talking about what your app does and
[00:01:23.440 --> 00:01:26.120]   what the history of the company is and how you think about that.
[00:01:26.120 --> 00:01:27.120]   Yeah, sure.
[00:01:27.120 --> 00:01:28.800]   So first, I'm happy to be here.
[00:01:28.800 --> 00:01:33.800]   And the whole company started by an idea of one of the staff, one of the founders that
[00:01:33.800 --> 00:01:40.800]   actually wanted to monitor his son's sleep during the night since he came from the whole
[00:01:40.800 --> 00:01:45.040]   world of processes and monitoring using cameras.
[00:01:45.040 --> 00:01:48.640]   And he wanted to take that to his son.
[00:01:48.640 --> 00:01:54.600]   And it started as a project when he was at Cornell University and everything just rolled
[00:01:54.600 --> 00:01:56.560]   from there, actually.
[00:01:56.560 --> 00:02:01.320]   And since we have a camera and he's from the field of computer vision, we started the company,
[00:02:01.320 --> 00:02:06.240]   started doing a smart baby monitor using computer vision algorithms that can attract, as you
[00:02:06.240 --> 00:02:13.400]   know, sleep, also the breathing motion and let you celebrate the milestones of your baby.
[00:02:13.400 --> 00:02:18.240]   For example, you know, falling asleep for the first time on his own and sleeping through
[00:02:18.240 --> 00:02:23.400]   the night without any visits from the parents, which is great for us, the parents, of course.
[00:02:23.400 --> 00:02:28.640]   And they're giving you a specific sleep tips in order to improve your baby's sleep.
[00:02:28.640 --> 00:02:35.640]   And actually the key, or I can say what guides the company is what value can we extract from
[00:02:35.640 --> 00:02:38.760]   visual data that the camera collects?
[00:02:38.760 --> 00:02:45.080]   So it's kind of obvious on sleep and of course on breathing for young babies.
[00:02:45.080 --> 00:02:48.960]   But also this is the guidelines that guide us for the next products and features, how
[00:02:48.960 --> 00:02:54.800]   to give value in terms of wealth and wellness to our customers.
[00:02:54.800 --> 00:02:59.400]   And it's also really unique since also this product has two hats, basically.
[00:02:59.400 --> 00:03:04.760]   We can have the hat of a consumer electronic product as you use it.
[00:03:04.760 --> 00:03:10.560]   And it's also a research tool, which started to being used more and more recently.
[00:03:10.560 --> 00:03:12.380]   Researchers are doing the home sleep research.
[00:03:12.380 --> 00:03:17.100]   So it's pretty cool that science and technology are working together and we get to deliver
[00:03:17.100 --> 00:03:20.240]   a really interesting product.
[00:03:20.240 --> 00:03:21.240]   That is really cool.
[00:03:21.240 --> 00:03:26.980]   And I think folks who are listening to this who haven't had children yet might not realize
[00:03:26.980 --> 00:03:33.820]   how essential sleep is for your sanity as a parent and also how important sleep is for
[00:03:33.820 --> 00:03:35.780]   the sanity of your child.
[00:03:35.780 --> 00:03:40.360]   So I've definitely thought much more about sleep in the last year than I ever thought
[00:03:40.360 --> 00:03:42.140]   about before.
[00:03:42.140 --> 00:03:48.340]   One of the key advantages of the product is as parents, you get up at night for your children
[00:03:48.340 --> 00:03:52.500]   and you're drowsy and you don't remember exactly, did I get up like two times?
[00:03:52.500 --> 00:03:53.860]   It was at 3 a.m.
[00:03:53.860 --> 00:03:56.460]   Maybe it was five, I don't remember.
[00:03:56.460 --> 00:04:03.220]   And NANI just collects you the data and serves to you clearly in order to make useful summary
[00:04:03.220 --> 00:04:05.100]   of the night.
[00:04:05.100 --> 00:04:09.860]   And you can also make data-driven decisions if you want and not by beliefs because this
[00:04:09.860 --> 00:04:14.040]   whole field of baby's sleep is full with beliefs.
[00:04:14.040 --> 00:04:17.380]   Some say that this method works better, some say the other.
[00:04:17.380 --> 00:04:19.780]   And here you get the facts, you get the data.
[00:04:19.780 --> 00:04:25.620]   The baby slept well, the baby slept better, the baby didn't sleep that good this night.
[00:04:25.620 --> 00:04:30.860]   And we also see that since parents are more focusing on the baby's sleep, also babies
[00:04:30.860 --> 00:04:32.420]   with NANI sleep better.
[00:04:32.420 --> 00:04:38.140]   They sleep longer, their sleep quality is better because everyone is in this process
[00:04:38.140 --> 00:04:39.340]   and they're focusing.
[00:04:39.340 --> 00:04:41.600]   So it's pretty amazing, I must say.
[00:04:41.600 --> 00:04:42.600]   That's really amazing.
[00:04:42.600 --> 00:04:46.380]   How do you know that babies that use NANI sleep better?
[00:04:46.380 --> 00:04:54.420]   So we have a large user base and we often send service to our customers and they actually
[00:04:54.420 --> 00:04:55.420]   respond to that.
[00:04:55.420 --> 00:04:59.980]   And we see in the statistics and what they are telling that just babies with NANI can
[00:04:59.980 --> 00:05:04.820]   sleep better because you are more aware of that and actually the tips are useful.
[00:05:04.820 --> 00:05:09.100]   So you're in a mindset of improving and how sleep is important.
[00:05:09.100 --> 00:05:10.100]   So I guess that's it.
[00:05:10.100 --> 00:05:11.100]   That's very cool.
[00:05:11.100 --> 00:05:14.860]   So can you break down what the...
[00:05:14.860 --> 00:05:19.020]   This is supposed to be an ML podcast, although parenting has been coming up an awful lot
[00:05:19.020 --> 00:05:20.740]   lately with people we've been talking to.
[00:05:20.740 --> 00:05:25.940]   Can you kind of break down the pieces that are kind of ML problems or computer vision
[00:05:25.940 --> 00:05:29.460]   problems that you need to solve to make the app work?
[00:05:29.460 --> 00:05:30.460]   Yeah.
[00:05:30.460 --> 00:05:37.100]   So we use all sorts of computer vision algorithm in order to get a good understanding of the
[00:05:37.100 --> 00:05:38.100]   scene.
[00:05:38.100 --> 00:05:43.940]   So for example, when the baby is falling asleep on his own and whether a parent comes to visit
[00:05:43.940 --> 00:05:49.460]   or not, all those are actually computer vision problems that we need to solve.
[00:05:49.460 --> 00:05:53.940]   And we actually serve multiple models during the night in order to get the whole scene
[00:05:53.940 --> 00:05:59.960]   understanding and on top of that, we take those outputs from the models and serve you
[00:05:59.960 --> 00:06:01.980]   the data much more clearly.
[00:06:01.980 --> 00:06:05.780]   So there's been a lot going on during the night.
[00:06:05.780 --> 00:06:09.780]   And so do you run the models on the phone or do you run them in the cloud?
[00:06:09.780 --> 00:06:10.780]   How does that work?
[00:06:10.780 --> 00:06:12.740]   Mostly in the cloud.
[00:06:12.740 --> 00:06:19.500]   We do have some algorithms that are running on the camera as well, but mostly on the cloud.
[00:06:19.500 --> 00:06:23.020]   And can you give me some sense of what the scale of this is?
[00:06:23.020 --> 00:06:27.500]   How much data your models are handling or how many streams of video you get in a typical
[00:06:27.500 --> 00:06:28.500]   night?
[00:06:28.500 --> 00:06:29.500]   Yeah.
[00:06:29.500 --> 00:06:32.060]   So let's take a short example.
[00:06:32.060 --> 00:06:39.980]   We have more than a hundred thousand users and we have a full night, which basically
[00:06:39.980 --> 00:06:47.380]   means that if we serve, for example, every 10 minutes or so, we get into a few tens of
[00:06:47.380 --> 00:06:52.660]   millions of calls for models per night.
[00:06:52.660 --> 00:06:53.940]   So it's a nice scale.
[00:06:53.940 --> 00:07:01.180]   I mean, we get to serve over tens of millions of requests per night to all our users.
[00:07:01.180 --> 00:07:03.740]   And these are pretty sensitive models.
[00:07:03.740 --> 00:07:05.700]   And I've noticed that you've never gone down.
[00:07:05.700 --> 00:07:10.380]   I mean, at least in my experience, it seems like you do a really good job with reliability.
[00:07:10.380 --> 00:07:15.020]   And I would think you'd have maybe a higher reliability bar than some other applications
[00:07:15.020 --> 00:07:16.340]   of folks you've talked to.
[00:07:16.340 --> 00:07:17.340]   Yeah.
[00:07:17.340 --> 00:07:18.340]   Well, you're right.
[00:07:18.340 --> 00:07:21.780]   Since babies are actually the most important things to the parents, we try to be as reliable
[00:07:21.780 --> 00:07:26.380]   as possible in terms of robustness of the models and accuracy of the models, and also
[00:07:26.380 --> 00:07:30.700]   in terms of runtime and to reduce downtime as much as possible.
[00:07:30.700 --> 00:07:35.340]   Because again, as everyone expects, our algorithms to work all the time and give them the data,
[00:07:35.340 --> 00:07:37.900]   especially when it comes to babies.
[00:07:37.900 --> 00:07:42.660]   So we're putting a lot of effort on that as well.
[00:07:42.660 --> 00:07:47.780]   And I guess the sleeping model is important, but the one that seems must be kind of anxiety
[00:07:47.780 --> 00:07:48.780]   producing.
[00:07:48.780 --> 00:07:52.700]   I mean, just talking about it, it's giving me anxiety, but the breathing motion monitoring,
[00:07:52.700 --> 00:07:56.140]   is that also an ML model that checks for that?
[00:07:56.140 --> 00:07:59.460]   Well, we use multiple models there.
[00:07:59.460 --> 00:08:03.380]   So there are some models that are more of a machine learning, deep learning base, and
[00:08:03.380 --> 00:08:06.420]   there are some computer vision classics models as well.
[00:08:06.420 --> 00:08:09.780]   There are all sorts of models.
[00:08:09.780 --> 00:08:12.900]   And why do you use multiple models for a single application?
[00:08:12.900 --> 00:08:19.820]   Well, we have many tasks that we need to solve in order to get this product to be reliable
[00:08:19.820 --> 00:08:24.380]   and robust enough, especially when we're talking about breathing motion.
[00:08:24.380 --> 00:08:30.740]   So I guess when you look at handling millions of requests per night, I guess, what are some
[00:08:30.740 --> 00:08:34.700]   things that you do to make sure that this is reliable and make sure that your compute
[00:08:34.700 --> 00:08:36.540]   spend is sane?
[00:08:36.540 --> 00:08:41.300]   How do you think about model architecture and how do you deploy your models and what
[00:08:41.300 --> 00:08:44.060]   frameworks and tools do you use?
[00:08:44.060 --> 00:08:45.540]   So it's pretty interesting.
[00:08:45.540 --> 00:08:49.780]   At our team, we're actually responsible for the whole flow, end to end.
[00:08:49.780 --> 00:08:56.660]   I mean, from developing and defining the task, all the research, selecting the model architecture,
[00:08:56.660 --> 00:08:59.260]   even conducting a proof of concept.
[00:08:59.260 --> 00:09:04.620]   Many times we'll probably elaborate on that later because I think it's really important
[00:09:04.620 --> 00:09:08.020]   nowadays for practitioners in the industry.
[00:09:08.020 --> 00:09:12.420]   Also the whole training process, of course, where you come in the picture with some great
[00:09:12.420 --> 00:09:17.100]   tools helping us find which models and experiments are better.
[00:09:17.100 --> 00:09:21.700]   Evaluating, which is actually pretty interesting because we try to conduct an evaluation metrics
[00:09:21.700 --> 00:09:25.340]   that also holds the product objectives inside as well.
[00:09:25.340 --> 00:09:28.460]   Because we're not building models in vacuum.
[00:09:28.460 --> 00:09:31.380]   We're all tied up to a product and a value to give to our customers.
[00:09:31.380 --> 00:09:34.100]   So it's not always that straightforward.
[00:09:34.100 --> 00:09:39.060]   And until deploying to production, including building monitoring systems, which should
[00:09:39.060 --> 00:09:44.040]   be our eyes out there eventually, and runtime optimization, as you said, not to spend so
[00:09:44.040 --> 00:09:45.360]   much on compute.
[00:09:45.360 --> 00:09:51.020]   So it's pretty complicated flow, but over the last few projects, we actually formed
[00:09:51.020 --> 00:09:58.740]   a nice formula for it, which I posted on Medium blog post as a guidelines, which proven to
[00:09:58.740 --> 00:10:01.540]   be successful in the first few times.
[00:10:01.540 --> 00:10:05.860]   And it's actually in the trend, at least as I see it now.
[00:10:05.860 --> 00:10:11.180]   I mean, every time I read on Twitter or on LinkedIn or whatever about people that are
[00:10:11.180 --> 00:10:18.340]   talking how to maintain and deploy and make good models in production, because there isn't
[00:10:18.340 --> 00:10:20.740]   any silver bullet there.
[00:10:20.740 --> 00:10:25.740]   And there are companies that are always trying to solve the whole pipeline, some part of
[00:10:25.740 --> 00:10:26.740]   it.
[00:10:26.740 --> 00:10:27.740]   So it's pretty interesting.
[00:10:27.740 --> 00:10:33.980]   I mean, the focus as I see it in the industry is shifted from sometimes making the models
[00:10:33.980 --> 00:10:39.980]   into make them work well in the real world and be able to be flexible enough and adapt
[00:10:39.980 --> 00:10:40.980]   changes.
[00:10:40.980 --> 00:10:47.180]   I guess I can say that many times maintaining the model and make it good and reliable out
[00:10:47.180 --> 00:10:53.060]   there is sometimes much harder than actually developing it, which is kind of amazing.
[00:10:53.060 --> 00:10:57.500]   If you think of it, I guess that wasn't exactly the focus like a few years ago, but kind of
[00:10:57.500 --> 00:10:58.980]   like get there.
[00:10:58.980 --> 00:11:02.700]   Tell me some stories about some stuff that you've run into and tell me, if you could
[00:11:02.700 --> 00:11:07.380]   tell me specifically, maybe pick a model and what it does and kind of what were the issues
[00:11:07.380 --> 00:11:11.780]   that you ran into in the process of getting it deployed and running?
[00:11:11.780 --> 00:11:14.340]   Yeah, we can take object detectors as example.
[00:11:14.340 --> 00:11:17.460]   We use them, of course, in our product.
[00:11:17.460 --> 00:11:21.460]   And in this case, an object detector would be like a baby detector or like a parent detector?
[00:11:21.460 --> 00:11:22.460]   Is that...
[00:11:22.460 --> 00:11:28.980]   For example, yeah, it can be, let's say for example, yeah, a baby detector.
[00:11:28.980 --> 00:11:34.580]   And so when you take a baby detector and you actually want to start building it, you must
[00:11:34.580 --> 00:11:39.940]   be aware of, for example, the evaluation on how you're going to be performed.
[00:11:39.940 --> 00:11:42.940]   That's a common pitfall.
[00:11:42.940 --> 00:11:43.940]   People can...
[00:11:43.940 --> 00:11:46.500]   Choosing the right evaluation metrics is pretty tricky.
[00:11:46.500 --> 00:11:52.460]   I know that I can say for myself, I have to recover from some bad decisions.
[00:11:52.460 --> 00:11:55.820]   And it's actually how you look on the model.
[00:11:55.820 --> 00:12:01.300]   If you could break that down, what would be a bad evaluation metric from a baby detector?
[00:12:01.300 --> 00:12:05.620]   Because I can think probably some people are listening to this and thinking, "Okay, accuracy
[00:12:05.620 --> 00:12:07.540]   sounds like a pretty good metric."
[00:12:07.540 --> 00:12:13.140]   But what would be a metric that might lead you astray with the baby detection model?
[00:12:13.140 --> 00:12:18.260]   So okay, let's take just a toy example about it.
[00:12:18.260 --> 00:12:23.660]   And let's say we have a baby detector and its accuracy is, let's say it's pretty good,
[00:12:23.660 --> 00:12:28.380]   but we care more about, eventually in the product, we care more about the false positive
[00:12:28.380 --> 00:12:30.900]   than the false negative, for example.
[00:12:30.900 --> 00:12:35.740]   And how you look on the evaluation metrics can really affect that.
[00:12:35.740 --> 00:12:41.580]   So if I'll give a little bit more weight to the false positive, we saw, for example, a
[00:12:41.580 --> 00:12:47.660]   decrease in accuracy on some metrics that actually average everything.
[00:12:47.660 --> 00:12:51.700]   But eventually this is the right metric and we get a much higher performance.
[00:12:51.700 --> 00:12:53.380]   Or also the other way around.
[00:12:53.380 --> 00:12:59.460]   We have a model that has very high accuracy, but eventually since the product was aimed
[00:12:59.460 --> 00:13:05.540]   to try to decrease false positives, the product metric was way lower.
[00:13:05.540 --> 00:13:07.020]   So it's really how you look at it.
[00:13:07.020 --> 00:13:08.940]   And that's the tricky part, I think.
[00:13:08.940 --> 00:13:13.460]   So I guess what metric then could you move to and then what would you do to improve that
[00:13:13.460 --> 00:13:14.460]   metric?
[00:13:14.460 --> 00:13:22.260]   So once you define the metric, you can always try and see where the weak cases and maybe
[00:13:22.260 --> 00:13:26.780]   how you can strengthen them, even if it's more data or even if it's a special kind of
[00:13:26.780 --> 00:13:27.780]   augmentation.
[00:13:27.780 --> 00:13:35.220]   But again, those things can be under the radar if you don't give them enough weight.
[00:13:35.220 --> 00:13:39.140]   I mean, that's a common failure case that actually happened in the past.
[00:13:39.140 --> 00:13:44.140]   Wait, so can you explain one more time what happens there in this failure case?
[00:13:44.140 --> 00:13:45.140]   Yeah.
[00:13:45.140 --> 00:13:50.460]   So let's say, for example, we took an accuracy overall measure for a baby detector, but we
[00:13:50.460 --> 00:13:55.660]   misdetect the baby when it wasn't there, but we had the high recall, which compensates
[00:13:55.660 --> 00:13:56.660]   that.
[00:13:56.660 --> 00:13:58.380]   So naturally we got to very high accuracy.
[00:13:58.380 --> 00:14:02.900]   But for example, for other product purposes, the precision needed to be higher in order
[00:14:02.900 --> 00:14:04.980]   to give enough value to the product.
[00:14:04.980 --> 00:14:09.260]   And so it's actually another way of looking at it is looking over the precision as the
[00:14:09.260 --> 00:14:11.060]   biggest parameter for us.
[00:14:11.060 --> 00:14:16.940]   And so once we changed to look at that, we could clearly see the problem and fix that.
[00:14:16.940 --> 00:14:19.460]   And how do you fix a problem like that?
[00:14:19.460 --> 00:14:26.220]   So collecting the data, I assume in a much dedicated way to your problem, maybe see whether
[00:14:26.220 --> 00:14:33.060]   you're actually collecting the right data and not just maybe random sample the data
[00:14:33.060 --> 00:14:38.300]   at some point, but actually direct yourself to the places that the model will look when
[00:14:38.300 --> 00:14:39.300]   it's in production.
[00:14:39.300 --> 00:14:44.660]   And so you want to try to imitate that and collect data from those parts in order to
[00:14:44.660 --> 00:14:49.900]   make your model trained on what it's actually going to see and not on what's easy to collect.
[00:14:49.900 --> 00:14:52.300]   That's one of probably the best solutions.
[00:14:52.300 --> 00:14:57.340]   So collecting data of the cases where you think your model is struggling and adding
[00:14:57.340 --> 00:14:59.500]   that as opposed to random sampling.
[00:14:59.500 --> 00:15:03.420]   For example, or maybe collecting the right data to your problem.
[00:15:03.420 --> 00:15:09.260]   I mean, you can collect data in many ways and collecting the data that suits your problem
[00:15:09.260 --> 00:15:15.020]   is the first thing actually I think you need to do and put a lot of thought about it.
[00:15:15.020 --> 00:15:17.740]   It's actually my first bullet on the guidelines.
[00:15:17.740 --> 00:15:21.140]   Start by defining what's the right data for you.
[00:15:21.140 --> 00:15:25.380]   Don't just collect data and start working on the model because you're going to waste
[00:15:25.380 --> 00:15:27.500]   time.
[00:15:27.500 --> 00:15:35.200]   And do you have ways of explaining to a business person how to justify the cost of data collection
[00:15:35.200 --> 00:15:38.780]   in terms of some metric that they care about?
[00:15:38.780 --> 00:15:41.220]   Is that an important thing to you?
[00:15:41.220 --> 00:15:48.460]   We try to keep a close connection between the product and the algorithm performances
[00:15:48.460 --> 00:15:57.220]   because data collection is very expensive and our time and our resources are very expensive.
[00:15:57.220 --> 00:16:02.380]   So we try not to make perfect models that will have no effect on the product.
[00:16:02.380 --> 00:16:07.900]   So yeah, I guess this process is pretty easy for us because this is one of the first priorities
[00:16:07.900 --> 00:16:10.220]   when we start a project.
[00:16:10.220 --> 00:16:14.500]   And are you also in parallel experimenting with different kinds of algorithms or doing
[00:16:14.500 --> 00:16:15.500]   hyper parameter searches?
[00:16:15.540 --> 00:16:18.540]   Is that important to you at all or is it really just the data collection?
[00:16:18.540 --> 00:16:21.860]   No, no, no, no.
[00:16:21.860 --> 00:16:28.100]   Data collection is good, but we're doing all sorts of hyper parameter tuning and choosing
[00:16:28.100 --> 00:16:32.380]   models and we have really organized mythology about what to do first.
[00:16:32.380 --> 00:16:34.380]   Can you tell me your methodology?
[00:16:34.380 --> 00:16:40.020]   Well, not in particular, but we start, I guess a good thing to do is maybe start with trying
[00:16:40.020 --> 00:16:45.220]   to get the best model you can get and trying to get an upper bound of performance and ignore
[00:16:45.220 --> 00:16:49.820]   speed in ignore runtime, for example, just to see what you're up about from the program.
[00:16:49.820 --> 00:16:56.860]   Because in many cases, the algorithms are working on public data sets and everyone,
[00:16:56.860 --> 00:17:03.380]   you know, detectors work on MS COCO and classification, for example, on ImageNet, but not in all cases,
[00:17:03.380 --> 00:17:05.860]   it's a good proxy to your problem.
[00:17:05.860 --> 00:17:12.580]   Medical images have their own data sets, but some other parts, the data is not always natural
[00:17:12.580 --> 00:17:13.660]   image style.
[00:17:13.660 --> 00:17:18.580]   So you got to try models and many hyper parameter tuning.
[00:17:18.580 --> 00:17:20.420]   It's most of the work from training.
[00:17:20.420 --> 00:17:25.540]   I mean, it's not actual work, but it takes a lot of time.
[00:17:25.540 --> 00:17:28.580]   And then once the model is deployed, do you stop there?
[00:17:28.580 --> 00:17:32.060]   I would imagine you'd have a pretty, you'd have kind of new problems that would come
[00:17:32.060 --> 00:17:33.060]   up.
[00:17:33.060 --> 00:17:37.940]   Like, do you see like data drift as an issue for you or like, how do you think about production
[00:17:37.940 --> 00:17:39.620]   monitoring?
[00:17:39.620 --> 00:17:42.340]   So we put a lot of effort in production monitoring.
[00:17:42.340 --> 00:17:43.820]   I think it's really important.
[00:17:43.820 --> 00:17:49.180]   And people sometimes underestimate that because once you deploy a model, I guess nothing,
[00:17:49.180 --> 00:17:50.820]   it's not ending.
[00:17:50.820 --> 00:17:56.460]   It's actually the beginning because it's much harder and you need to invest a real good
[00:17:56.460 --> 00:18:01.820]   planning and making your monitoring systems to be reliable enough and give you enough
[00:18:01.820 --> 00:18:06.140]   confidence because once you deploy the model, that's the only thing you can see.
[00:18:06.140 --> 00:18:11.540]   And the performance on the test that you get before you deploy the model is just a single
[00:18:11.540 --> 00:18:12.540]   time.
[00:18:12.540 --> 00:18:17.380]   And after that, you'll get many timeframes with performance decision and you need your
[00:18:17.380 --> 00:18:23.100]   monitoring to be reliable enough to spot some shifts and maybe sudden drops and try to understand
[00:18:23.100 --> 00:18:24.660]   what happened.
[00:18:24.660 --> 00:18:29.620]   So I guess I can say that we never stop with the models.
[00:18:29.620 --> 00:18:36.820]   We always look on the monitoring and see where we can see any problems and what it's connected
[00:18:36.820 --> 00:18:37.820]   to.
[00:18:37.820 --> 00:18:40.740]   I think one of the issues is you don't really have ground truth in production.
[00:18:40.740 --> 00:18:43.100]   So how do you know if there's a problem?
[00:18:43.100 --> 00:18:44.100]   It's true.
[00:18:44.100 --> 00:18:45.100]   It's pretty complicated.
[00:18:45.100 --> 00:18:49.660]   So we always consider prediction distributions and common stuff like that.
[00:18:49.660 --> 00:18:55.260]   We also use other routes as well, for example, user satisfactions and maybe tickets they
[00:18:55.260 --> 00:19:01.340]   open so we can spot some maybe problems there that we didn't caught up in our monitors.
[00:19:01.340 --> 00:19:06.100]   So we try to find a source whenever we can, usually from other parts of the company as
[00:19:06.100 --> 00:19:07.100]   well.
[00:19:07.100 --> 00:19:08.100]   Interesting.
[00:19:08.100 --> 00:19:09.900]   I always wonder how people do...
[00:19:09.900 --> 00:19:14.740]   I've heard different variants, but will you actually file a ticket against the ML team
[00:19:14.740 --> 00:19:16.260]   if you find a bad prediction?
[00:19:16.260 --> 00:19:19.220]   And then what do you do with a ticket like that?
[00:19:19.220 --> 00:19:24.620]   Well, they don't file it specifically to the ML team, but yeah, people file tickets for
[00:19:24.620 --> 00:19:29.180]   bad predictions because everything is actually based on that.
[00:19:29.180 --> 00:19:36.180]   So you can get wrong statistics and bad results and you're a parent, you want to get the data
[00:19:36.180 --> 00:19:40.660]   for your child, you pay for this product and you want answers.
[00:19:40.660 --> 00:19:44.220]   It's actually quite a challenge.
[00:19:44.220 --> 00:19:49.300]   Since we have so many users and we need to keep our models in a very high performance
[00:19:49.300 --> 00:19:55.980]   level in order not to make so many tickets for us and also make the experience for our
[00:19:55.980 --> 00:19:58.980]   users much, much better.
[00:19:58.980 --> 00:19:59.980]   So it's a challenge.
[00:19:59.980 --> 00:20:06.740]   And one thing you talked about in your paper or your Medium post was preparations before
[00:20:06.740 --> 00:20:08.660]   deploying a model to production.
[00:20:08.660 --> 00:20:10.940]   Can you talk about how that works?
[00:20:10.940 --> 00:20:11.940]   Yeah.
[00:20:11.940 --> 00:20:17.340]   We try to simulate as much as possible how everything will be in production.
[00:20:17.340 --> 00:20:25.540]   For example, we actually create a production-like environment and we also get some of the users
[00:20:25.540 --> 00:20:30.980]   to use that, of course, they're supportive and they're aware that there are going to
[00:20:30.980 --> 00:20:32.340]   be changes.
[00:20:32.340 --> 00:20:37.420]   And we try to monitor everything we can there in order to see that our model formed the
[00:20:37.420 --> 00:20:40.780]   way we expect, that we don't see any issues.
[00:20:40.780 --> 00:20:46.180]   And that's of course, in parallel, we also do all those end-to-end tests of all of our
[00:20:46.180 --> 00:20:51.180]   algorithms together to see that the new model behaves as it should be and it doesn't rise
[00:20:51.180 --> 00:20:56.340]   any special problems from entering a new block or maybe improving them.
[00:20:56.340 --> 00:20:59.940]   That's most of the work that's done there.
[00:20:59.940 --> 00:21:00.940]   Got it.
[00:21:00.940 --> 00:21:01.940]   Got it.
[00:21:01.940 --> 00:21:06.420]   Could you tell me a little bit about how Weights & Biases fits into your workflow and how you
[00:21:06.420 --> 00:21:08.380]   use the Weights & Biases tool?
[00:21:08.380 --> 00:21:09.380]   Yeah.
[00:21:09.380 --> 00:21:14.300]   So with Weights & Biases, we manage all of our experiments, which is great.
[00:21:14.300 --> 00:21:21.060]   We also use your visualization tools in order to compare between experiments.
[00:21:21.060 --> 00:21:27.620]   And since you have everything so shiny and dynamic, we can also try different parameters
[00:21:27.620 --> 00:21:33.900]   and see what could have been and without running all the model over and over again, which saves
[00:21:33.900 --> 00:21:34.900]   time.
[00:21:34.900 --> 00:21:40.860]   I'm a pretty huge fan of the reports that you can do, because as I said before, we are
[00:21:40.860 --> 00:21:44.020]   really tied up with the product team about the algorithms we do.
[00:21:44.020 --> 00:21:53.700]   So it actually makes us a way to show them what we do and visualize on real time how
[00:21:53.700 --> 00:21:56.580]   each parameter affects the results.
[00:21:56.580 --> 00:22:01.180]   And we talk about what should be better for the product and the algorithm team together.
[00:22:01.180 --> 00:22:03.100]   So yeah, we use it quite a lot.
[00:22:03.100 --> 00:22:07.140]   So you actually use reports to share results with the product team?
[00:22:07.140 --> 00:22:08.140]   Yeah.
[00:22:08.260 --> 00:22:13.380]   We also use reports to summarize and share with product teams, show them some maybe model
[00:22:13.380 --> 00:22:18.620]   weaknesses, whether we want to deal with this now or maybe deal with this later.
[00:22:18.620 --> 00:22:23.020]   And for example, how changing parameters can help.
[00:22:23.020 --> 00:22:28.020]   It also, it's better for mutual work and transparency, because sometimes you're trying to be a little
[00:22:28.020 --> 00:22:30.380]   bit suspicious from things you don't understand.
[00:22:30.380 --> 00:22:34.620]   And once we understand their job and they understand our job, I think the mutual job
[00:22:34.620 --> 00:22:35.620]   is much better.
[00:22:35.620 --> 00:22:39.900]   We've seen that once you talk about it and you explain and they can understand your world
[00:22:39.900 --> 00:22:44.340]   and you can understand theirs, we can make decisions which are much more good for the
[00:22:44.340 --> 00:22:46.260]   company.
[00:22:46.260 --> 00:22:49.220]   So it's actually pretty useful for us.
[00:22:49.220 --> 00:22:53.860]   Do you often go down paths where there's a product feature you might want to make, but
[00:22:53.860 --> 00:22:58.780]   you're not sure if you're going to be able to make the machine learning algorithm accurate
[00:22:58.780 --> 00:23:01.820]   enough or powerful enough to actually make the feature possible?
[00:23:01.820 --> 00:23:03.820]   Do you ever get in situations like that?
[00:23:03.820 --> 00:23:04.820]   All the time.
[00:23:04.820 --> 00:23:10.100]   This is one of the main challenges we have when working with this scale and working on
[00:23:10.100 --> 00:23:11.300]   such sensitive data.
[00:23:11.300 --> 00:23:17.580]   I mean, we get so many cool ideas and papers and works, and it's really hard to get them
[00:23:17.580 --> 00:23:18.580]   into production.
[00:23:18.580 --> 00:23:20.540]   This gap is sometimes pretty big.
[00:23:20.540 --> 00:23:25.460]   I can just name one example that pops into my head.
[00:23:25.460 --> 00:23:29.780]   GANs, for example, are pretty, they're amazing example for that.
[00:23:29.780 --> 00:23:35.380]   They do marvelous things, but it's really hard to get them into production.
[00:23:35.380 --> 00:23:41.180]   They often tend not to converge and it's worked well on this dataset, but not in this dataset
[00:23:41.180 --> 00:23:43.140]   and this dataset's worked not good enough.
[00:23:43.140 --> 00:23:50.500]   So it's a pretty big challenge how to be innovative and giving good and valuable features, but
[00:23:50.500 --> 00:23:53.680]   also reliable and accurate, which is-
[00:23:53.680 --> 00:23:54.680]   What might you do with a GAN?
[00:23:54.680 --> 00:23:55.680]   I'm trying to picture that.
[00:23:55.680 --> 00:23:58.660]   I don't want any deep fakes of my baby.
[00:23:58.660 --> 00:24:07.180]   No, no, no, not deep fakes, but there are many other uses of GAN that we can use maybe
[00:24:07.180 --> 00:24:14.940]   for enhanced images and make your nice fun features that you can celebrate your baby
[00:24:14.940 --> 00:24:17.700]   with a different background and stuff like that.
[00:24:17.700 --> 00:24:21.820]   So there's all sorts of stuff that GANs can be really useful.
[00:24:21.820 --> 00:24:28.580]   But again, there's a big gap between an experiment and a paper and actually getting into production.
[00:24:28.580 --> 00:24:34.100]   I know that in the last couple of years, there's been a lot of advances, almost like a tsunami
[00:24:34.100 --> 00:24:36.780]   of advances in computer vision.
[00:24:36.780 --> 00:24:38.220]   Have any of them been relevant to you?
[00:24:38.220 --> 00:24:44.540]   Do you take recent stuff and get them in production or is that stuff too theoretical to really
[00:24:44.540 --> 00:24:47.300]   matter for the practical stuff you're doing?
[00:24:47.300 --> 00:24:52.900]   We always try to take state of the art and trying to adapt them to our domain.
[00:24:52.900 --> 00:24:57.380]   There are fields which is easier, maybe mainly object detection.
[00:24:57.380 --> 00:25:03.740]   We talked about it, so it's since tasks are pretty much solved, let's say, or pretty much
[00:25:03.740 --> 00:25:05.700]   comfortable to get them into production.
[00:25:05.700 --> 00:25:10.500]   So yeah, it's much easier, but there are other fields that we try.
[00:25:10.500 --> 00:25:13.340]   I honestly say we try all the time.
[00:25:13.340 --> 00:25:17.820]   Sometimes it's really hard to bridge this gap, but it's definitely something that keeps
[00:25:17.820 --> 00:25:19.940]   us motivated and try to do it all the time.
[00:25:19.940 --> 00:25:25.100]   I mean, if you stay behind in this field, you probably won't exist that long.
[00:25:25.100 --> 00:25:26.100]   This is what I believe.
[00:25:26.100 --> 00:25:27.100]   Sure, yeah.
[00:25:27.100 --> 00:25:30.500]   Is there any, I guess, any paper or line of research that you can talk about as being
[00:25:30.500 --> 00:25:32.420]   especially relevant to the work you're doing?
[00:25:32.420 --> 00:25:38.660]   I can talk about some nice researches we did, lastly, and all of them are actually somehow
[00:25:38.660 --> 00:25:39.660]   related.
[00:25:39.660 --> 00:25:43.580]   I mean, they're all using the sleep metrics that we have, which have the algorithms at
[00:25:43.580 --> 00:25:44.580]   the back.
[00:25:44.580 --> 00:25:49.020]   So during, for example, during the pandemic, during COVID, I actually, NANIT helped to
[00:25:49.020 --> 00:25:51.780]   kept families together.
[00:25:51.780 --> 00:25:57.860]   For example, when the grandparents can't see their grandchildren and NANIT allows that.
[00:25:57.860 --> 00:26:03.420]   And we also checked during COVID, what are the effects on babies.
[00:26:03.420 --> 00:26:08.060]   And we actually tried to study the difference between children that their parents were essential
[00:26:08.060 --> 00:26:12.900]   and went to work as usual and parents that stayed at home.
[00:26:12.900 --> 00:26:19.620]   And we actually saw that at the first few weeks, from the end of March, let's say for
[00:26:19.620 --> 00:26:26.060]   the first few weeks, we saw that the sleep of the babies actually got worse.
[00:26:26.060 --> 00:26:33.500]   But yeah, but it was actually improved after a couple of months, we saw that the sleep
[00:26:33.500 --> 00:26:38.380]   of the babies that their parents stayed at home actually got back to normal, which is
[00:26:38.380 --> 00:26:39.380]   pretty amazing.
[00:26:39.380 --> 00:26:46.220]   It actually means that babies are resilient to the change and they adapt back, which is
[00:26:46.220 --> 00:26:49.180]   kind of cool.
[00:26:49.180 --> 00:26:55.260]   Can I ask you, so this is, I think for a lot of parents, the most drama filled topic is
[00:26:55.260 --> 00:26:59.540]   kind of sleep training the baby, where you leave the baby and let them cry at various
[00:26:59.540 --> 00:27:04.420]   lengths and kind of teach them to go to sleep on their own instead of with you holding them.
[00:27:04.420 --> 00:27:06.220]   Do you have an opinion on that?
[00:27:06.220 --> 00:27:12.460]   Well, since I'm not a sleep expert, I can only say from my experience, it's important
[00:27:12.460 --> 00:27:14.740]   to let the baby sleep on their own.
[00:27:14.740 --> 00:27:16.220]   I guess not in any cost, but-
[00:27:16.220 --> 00:27:17.940]   Do you have any data on that?
[00:27:17.940 --> 00:27:20.820]   I guess you do sort of track when the baby falls asleep on their own.
[00:27:20.820 --> 00:27:22.340]   Yeah, yeah, we do.
[00:27:22.340 --> 00:27:28.620]   I'm not sure if I have any relevant research done in this field, but again, this is the
[00:27:28.620 --> 00:27:30.300]   beauty of Nanny.
[00:27:30.300 --> 00:27:36.180]   You can actually test your assumptions, I would say, because if you believe in that,
[00:27:36.180 --> 00:27:40.180]   and then the objective data tells you that it's right, so that's good.
[00:27:40.180 --> 00:27:44.580]   And if not, so you might want to reconsider, but that's up to you.
[00:27:44.580 --> 00:27:47.100]   You got the data, you can decide.
[00:27:47.100 --> 00:27:51.260]   Do you publish aggregate statistics like that on different things that help babies sleep?
[00:27:51.260 --> 00:27:54.300]   We do have researches that we publish.
[00:27:54.300 --> 00:27:58.420]   I'm not sure regarding those, what helps and what doesn't specifically.
[00:27:58.420 --> 00:28:04.780]   We did publish research about screen time and how it affects babies and young children.
[00:28:04.780 --> 00:28:06.220]   And it's actually pretty amazing.
[00:28:06.220 --> 00:28:13.300]   We found out that, for example, touchscreens have a bigger effect on the sleep of babies
[00:28:13.300 --> 00:28:15.020]   as opposed to, for example, television.
[00:28:15.020 --> 00:28:18.860]   I mean, television has less effect, which has pretty amazed me.
[00:28:18.860 --> 00:28:25.180]   We saw that touchscreens are causing fragmented sleep and less sleep time overall, which is
[00:28:25.180 --> 00:28:26.180]   pretty...
[00:28:26.180 --> 00:28:27.780]   I mean, it's really amazing.
[00:28:27.780 --> 00:28:31.820]   You can conduct a research and see it quickly because we have large user base and engage
[00:28:31.820 --> 00:28:37.300]   users that can allow us and answer questions.
[00:28:37.300 --> 00:28:39.540]   This is also a good research tool.
[00:28:39.540 --> 00:28:41.260]   That really is amazing, yeah.
[00:28:41.260 --> 00:28:45.940]   It seems like, I guess, from your app, I feel like your benchmarks of sleep are actually
[00:28:45.940 --> 00:28:50.140]   a little less sleep than I see in the parenting books that I read.
[00:28:50.140 --> 00:28:54.460]   Do you think because you're actually monitoring it instead of getting self-reported data,
[00:28:54.460 --> 00:28:58.900]   do you see systematic bias in the self-reported sleep data?
[00:28:58.900 --> 00:29:04.460]   It'll tell me how my daughter is doing compared to averages.
[00:29:04.460 --> 00:29:08.840]   And it's funny because the app is telling me she's doing pretty good.
[00:29:08.840 --> 00:29:12.540]   But then when I compare it to books that I'm reading, it seems like she's sleeping a little
[00:29:12.540 --> 00:29:14.060]   less than average.
[00:29:14.060 --> 00:29:17.560]   So maybe you're just trying to be positive and helpful.
[00:29:17.560 --> 00:29:22.020]   But I also wonder because we try to write down every time she wakes up and when she
[00:29:22.020 --> 00:29:23.660]   goes to sleep and when she gets up.
[00:29:23.660 --> 00:29:29.460]   I always feel like our written notes imply a little more sleep than the data actually
[00:29:29.460 --> 00:29:31.180]   shows us that she got.
[00:29:31.180 --> 00:29:36.500]   So I wonder if previous studies relying on parents' memories end up making us think that
[00:29:36.500 --> 00:29:39.300]   babies are sleeping more than they're actually sleeping.
[00:29:39.300 --> 00:29:42.700]   So what I can say about it, so I guess that's sometimes true.
[00:29:42.700 --> 00:29:47.900]   Also I guess getting data for babies for sleep, especially from babies, is pretty expensive.
[00:29:47.900 --> 00:29:55.380]   I mean, I'm not sure researchers can do thousands of babies and then record their sleep, but
[00:29:55.380 --> 00:29:56.660]   nannies actually can do.
[00:29:56.660 --> 00:30:01.660]   So maybe there's some small portion, this is why you see some big variance between studies
[00:30:01.660 --> 00:30:02.660]   about sleep, I guess.
[00:30:02.660 --> 00:30:04.660]   So I guess that would be the reason.
[00:30:04.660 --> 00:30:10.860]   I guess, is there any other takeaways besides avoiding touchscreens to help a baby sleep?
[00:30:10.860 --> 00:30:17.700]   Any conclusions you've come to with your large scale data collection?
[00:30:17.700 --> 00:30:23.360]   So most of actually the significant tips that we see are actually incorporated in the app.
[00:30:23.360 --> 00:30:28.020]   So helping baby fall asleep on his own is of course a remarkable sign for that because
[00:30:28.020 --> 00:30:31.900]   once he wakes up during the night, he can come back to bed.
[00:30:31.900 --> 00:30:39.300]   And so I guess what we see and what we're trying to translate it and validate it, of
[00:30:39.300 --> 00:30:43.540]   course, and send it as tips if possible.
[00:30:43.540 --> 00:30:44.540]   Cool.
[00:30:44.540 --> 00:30:49.900]   Well, I guess we always end with two questions and I want to make sure we have a little time
[00:30:49.900 --> 00:30:50.900]   for that.
[00:30:50.900 --> 00:30:55.660]   So the second to last question is, what is one underrated aspect of machine learning
[00:30:55.660 --> 00:30:58.580]   that you think people should pay more attention to than they do?
[00:30:58.580 --> 00:31:03.820]   I would say building a good process for deploying the models.
[00:31:03.820 --> 00:31:08.220]   I mean, making something that is worse as a system and it's not occasionally working
[00:31:08.220 --> 00:31:13.340]   not because sometimes people tend to, yeah, okay, let's take the data, let's train it.
[00:31:13.340 --> 00:31:14.340]   Okay.
[00:31:14.340 --> 00:31:15.340]   It's very good on accuracy.
[00:31:15.340 --> 00:31:16.340]   Okay.
[00:31:16.340 --> 00:31:17.340]   We can deploy it.
[00:31:17.340 --> 00:31:22.380]   And then the performance are bad and now the model is in the air and it's much harder to
[00:31:22.380 --> 00:31:23.500]   fix it.
[00:31:23.500 --> 00:31:29.340]   So I'd say conducting this methodology, this pipeline of how to work better is something
[00:31:29.340 --> 00:31:31.460]   that people should pay more attention.
[00:31:31.460 --> 00:31:35.620]   And I think that's what we see, at least what I read on Twitter and LinkedIn and stuff like
[00:31:35.620 --> 00:31:38.420]   that, people are paying more and more attention to that.
[00:31:38.420 --> 00:31:41.780]   And I think that's important for the industry.
[00:31:41.780 --> 00:31:45.860]   And are there tools that you use to help with that?
[00:31:45.860 --> 00:31:48.220]   In building those pipelines.
[00:31:48.220 --> 00:31:55.080]   So we use whatever, for example, managing experiments and showing the report and see
[00:31:55.080 --> 00:31:59.820]   everything really helps us to get understanding on how it's exactly done.
[00:31:59.820 --> 00:32:03.220]   Try and simulate the production like this is what works for us.
[00:32:03.220 --> 00:32:06.420]   But I know there are several companies and there are several products out there that
[00:32:06.420 --> 00:32:07.960]   can do many things.
[00:32:07.960 --> 00:32:12.980]   And this is why I wrote it as guidelines because probably some of the tips there could be useful
[00:32:12.980 --> 00:32:14.860]   for many people.
[00:32:14.860 --> 00:32:16.540]   Some of them are not.
[00:32:16.540 --> 00:32:17.540]   Totally.
[00:32:17.540 --> 00:32:20.940]   And then I guess maybe you answered my last question, but I'll ask it anyway.
[00:32:20.940 --> 00:32:24.700]   So when you look at machine learning in general and making it work in a production, what do
[00:32:24.700 --> 00:32:31.020]   you see as the biggest challenge from going from research to deployed model working for
[00:32:31.020 --> 00:32:32.020]   customers?
[00:32:32.020 --> 00:32:37.300]   So, yeah, as I said, I think this gap is sometimes really big.
[00:32:37.300 --> 00:32:45.780]   In fact, maybe the ability to understand which paper is nice, but will it hold in production?
[00:32:45.780 --> 00:32:47.780]   That's a pretty big problem.
[00:32:47.780 --> 00:32:48.780]   You need to foresee it.
[00:32:48.780 --> 00:32:56.820]   And we've tried a lot of cool features that we saw in conferences and papers, but it didn't
[00:32:56.820 --> 00:33:00.300]   hold on our data or maybe they weren't good enough.
[00:33:00.300 --> 00:33:01.700]   So we had to drop them.
[00:33:01.700 --> 00:33:06.420]   Well, I really appreciate you being kind of public about your work and willing to do case
[00:33:06.420 --> 00:33:07.420]   studies and things like that.
[00:33:07.420 --> 00:33:11.500]   I think it really helps a lot of people learn best practices as they try to get models in
[00:33:11.500 --> 00:33:12.500]   production.
[00:33:12.500 --> 00:33:15.940]   We'll put some links to some of the work that you've put out, but I would say, please keep
[00:33:15.940 --> 00:33:17.620]   doing it if you're open to it.
[00:33:17.620 --> 00:33:19.180]   It's super helpful for our community.
[00:33:19.180 --> 00:33:21.140]   Yeah, I totally agree.
[00:33:21.140 --> 00:33:23.860]   This is how we learned and this is how we can share the knowledge.
[00:33:23.860 --> 00:33:27.540]   And I think as much as people will share the knowledge, it will be better and everyone
[00:33:27.540 --> 00:33:31.100]   could have great productivity, which I think is important.
[00:33:31.100 --> 00:33:32.100]   Totally.
[00:33:32.100 --> 00:33:34.100]   Thanks Nimrod, really appreciate it.
[00:33:34.100 --> 00:33:36.540]   Thank you so much.
[00:33:36.540 --> 00:33:39.780]   Thanks for listening to another episode of Gradient Dissent.
[00:33:39.780 --> 00:33:44.100]   Doing these interviews are a lot of fun and it's especially fun for me when I can actually
[00:33:44.100 --> 00:33:46.860]   hear from the people that are listening to these episodes.
[00:33:46.860 --> 00:33:51.740]   So if you wouldn't mind leaving a comment and telling me what you think or starting a
[00:33:51.740 --> 00:33:54.860]   conversation, that would make me inspired to do more of these episodes.
[00:33:54.860 --> 00:33:58.420]   And also if you wouldn't mind liking and subscribing, I'd appreciate that a lot.

