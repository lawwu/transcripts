
[00:00:00.000 --> 00:00:08.640]   Welcome, everyone. We're so excited to welcome you to the official kickoff for our very first
[00:00:08.640 --> 00:00:15.120]   machine learning focused hackathon. And this hackathon is co-sponsored with Weights & Biases.
[00:00:15.120 --> 00:00:20.040]   Thanks so much for being here with us today. I'm Ornella from the community team, and I
[00:00:20.040 --> 00:00:24.760]   have some awesome guests from Weights & Biases with me today. So I will let them introduce
[00:00:24.760 --> 00:00:25.760]   themselves.
[00:00:25.760 --> 00:00:32.280]   Brilliant. Thanks a million, Ornella. So hey, everyone. Super excited to be hacking with
[00:00:32.280 --> 00:00:38.440]   you the next week. I'm Morgan. I work on the growth ML team in Weights & Biases. So I've
[00:00:38.440 --> 00:00:42.200]   been in Weights & Biases about two years as a machine learning engineer and then managing
[00:00:42.200 --> 00:00:48.280]   a team here. And yeah, I've had a lot of fun in the past few weeks working with Ornella
[00:00:48.280 --> 00:00:53.680]   and the team at Ruplet. And yeah, looking forward to seeing some cool projects by this
[00:00:53.680 --> 00:00:56.320]   time next week. And let me hand it over to Corey.
[00:00:56.320 --> 00:01:00.680]   Hey, everyone. My name's Corey. I've only been working at Weights & Biases for about
[00:01:00.680 --> 00:01:04.720]   a month now, but I'm the community manager there. So I know you guys have a fantastic
[00:01:04.720 --> 00:01:09.360]   community at Ruplet, and we have a fantastic community at Weights & Biases. So really happy
[00:01:09.360 --> 00:01:15.000]   to kind of be able to join forces here for this first ML hackathon. And also really appreciate
[00:01:15.000 --> 00:01:21.040]   you for joining us on a Saturday. I know that's never easy to do. So we're happy to help support
[00:01:21.040 --> 00:01:25.360]   you and look forward to all the great things that you create.
[00:01:25.360 --> 00:01:31.680]   Amazing. We're so happy to have Morgan and Corey here with us. So I wanted to walk through
[00:01:31.680 --> 00:01:37.520]   some logistics first, just for the hackathon kickoff. And I first wanted to say that if
[00:01:37.520 --> 00:01:42.240]   today is your first time hearing about the hackathon, don't worry. It's not too late
[00:01:42.240 --> 00:01:50.440]   to sign up. So the waitlist application form on the hackathon website will be open until
[00:01:50.440 --> 00:01:56.800]   Wednesday. We'll be accepting new people every day and granting cycles for GPU access every
[00:01:56.800 --> 00:02:01.760]   day. So it's really not too late to sign up, and you still have time to build out an awesome
[00:02:01.760 --> 00:02:07.800]   project as long as you sign up by Wednesday. We also just opened up the Machine Learning
[00:02:07.800 --> 00:02:12.720]   Hackathon channel on our Discord. So we'll put the link in the chat. And starting on
[00:02:12.720 --> 00:02:18.120]   Monday morning, we'll have machine learning engineers from Weights & Biases helping people
[00:02:18.120 --> 00:02:25.440]   out with their project and providing support. We'll also have a live Replet 101 this week
[00:02:25.440 --> 00:02:31.640]   with David Morgan. So you can pop in live and ask questions during his live office hour.
[00:02:31.640 --> 00:02:37.360]   That'll be awesome. So we'll post all the support links in the chat as well. And really
[00:02:37.360 --> 00:02:42.760]   the most important thing for this hackathon is that you have to use both Weights & Biases
[00:02:42.760 --> 00:02:48.360]   and Replet in your project. And when you get the acceptance email into the hackathon, you'll
[00:02:48.360 --> 00:02:54.400]   get a bunch of resources for how to do that. So if it's your first time using Weights & Biases
[00:02:54.400 --> 00:03:01.160]   or if it's your first time using Replet, don't worry, we have you covered on both fronts.
[00:03:01.160 --> 00:03:06.920]   And just for prize eligibility, I wanted to mention that the grand prize and honorable
[00:03:06.920 --> 00:03:12.640]   mention all projects that use Replet and Weights & Biases will be eligible for both, but you'll
[00:03:12.640 --> 00:03:18.160]   have to choose whether you're submitting a Repl or Weights & Biases report, and then
[00:03:18.160 --> 00:03:23.720]   you'll be eligible for either Best Repl or Best Weights & Biases report. And that'll
[00:03:23.720 --> 00:03:30.400]   all be clear on the submission form, which I'll talk about at the end of this session.
[00:03:30.400 --> 00:03:36.000]   So the bulk of the session today, Morgan's going to run us through an awesome example
[00:03:36.000 --> 00:03:41.360]   of using Replet and Weights & Biases together. This is going to be a quick start for anyone
[00:03:41.360 --> 00:03:47.480]   who is just wondering where to get started for the hackathon. So I'll take Corey and
[00:03:47.480 --> 00:03:52.040]   myself off the screen and we'll let Morgan take it away.
[00:03:52.040 --> 00:04:06.240]   Perfect. Thanks, Aniela. Okay, let me share my screen here. And there we go. Okay. So
[00:04:06.240 --> 00:04:15.920]   yeah, Weights & Biases and Replet. So I'll give for the Replet folks on the call, give
[00:04:15.920 --> 00:04:20.960]   folks a quick idea of what Weights & Biases is and how it's useful in the machine learning
[00:04:20.960 --> 00:04:26.680]   world and then take a quick tour through a few Repls we've put together to get people
[00:04:26.680 --> 00:04:32.600]   started and to show how Weights & Biases fits into the picture when things come to ML. And
[00:04:32.600 --> 00:04:39.040]   so what we're looking at here is Weights & Biases workspace. Before getting into that,
[00:04:39.040 --> 00:04:45.520]   I can give a little context around why a tool like Weights & Biases is useful when it comes
[00:04:45.520 --> 00:04:53.600]   to machine learning. And so unlike traditional software engineering, machine learning can
[00:04:53.600 --> 00:04:59.640]   be much more experimental. You're running a lot of different trials, you're trying a
[00:04:59.640 --> 00:05:06.480]   lot of different parameters. And so there's a lot more accumulation of artifacts and learnings
[00:05:06.480 --> 00:05:12.520]   and notes of all the things you've done to try and get the best out of your model. And
[00:05:12.520 --> 00:05:19.320]   so having one place to store all of those results is pretty important. And again, for
[00:05:19.320 --> 00:05:25.400]   example, in machine learning, another difference between software engineering is you can actually
[00:05:25.400 --> 00:05:33.480]   have a machine learning model that looks like it's working well and giving reasonable predictions
[00:05:33.480 --> 00:05:41.760]   and has reasonable accuracy metrics, but you might actually have a bug in there. So compared
[00:05:41.760 --> 00:05:47.440]   to software where if you have a bug in your program, it's going to fail or it's going
[00:05:47.440 --> 00:05:53.760]   to be very obvious. In machine learning, you can have these little silent bugs. And so
[00:05:53.760 --> 00:05:59.960]   it can be tricky and gnarly to track down. And so again, with tools like Weights & Biases,
[00:05:59.960 --> 00:06:05.360]   you're able to look back over all of the settings of your experiment, and maybe you forgot to
[00:06:05.360 --> 00:06:10.840]   set something on or off, or some value was set at 10 times higher than it should have
[00:06:10.840 --> 00:06:17.400]   been. That doesn't cause the model to fail, but causes it to perform worse than it would
[00:06:17.400 --> 00:06:23.560]   have. So being able to go back and track down those issues is crucial to getting the most
[00:06:23.560 --> 00:06:27.640]   out of your machine learning. And especially when you're running a lot of experiments on
[00:06:27.640 --> 00:06:36.240]   a lot of GPUs, it can save you a lot of time and sometimes a lot of money too. But let
[00:06:36.240 --> 00:06:41.160]   me give a quick tour of Weights & Biases and how it's going to be useful to folks this
[00:06:41.160 --> 00:06:48.760]   week. And so what we're looking at here is the workspace for Weights & Biases. And see
[00:06:48.760 --> 00:06:53.400]   here on the left of the screen, we have all of our experiments. And you can see down here
[00:06:53.400 --> 00:07:00.560]   we have about 100 experiments in this workspace. We're not going to look through all of these
[00:07:00.560 --> 00:07:07.200]   experiments, but here we can see an aggregation of what are some of the top performing experiments
[00:07:07.200 --> 00:07:13.840]   that we have. And so some of these top panels just give us the scores for some of the experiments
[00:07:13.840 --> 00:07:19.720]   that work the best. And so for example, here, let's try this one, for example. So this is
[00:07:19.720 --> 00:07:27.000]   our accuracy score and we can see this experiment, which has this lovely name, Rosie Sweep. These
[00:07:27.000 --> 00:07:32.200]   are random names that Weights & Biases gives your experiments. We can actually click into
[00:07:32.200 --> 00:07:40.320]   Rosie Sweep and see in more detail how this experiment ran. And so again, we have the
[00:07:40.320 --> 00:07:46.360]   results that we have there. We also have a lot of system metrics in terms of your disk
[00:07:46.360 --> 00:07:53.480]   utilization, CPU utilization. If you're using a GPU, you can also see your GPU use here.
[00:07:53.480 --> 00:07:59.160]   And so the nice thing with Weights & Biases is that it keeps track of a lot of this information
[00:07:59.160 --> 00:08:05.160]   automatically. And so for example, if you're running this within a Git folder, it'll also
[00:08:05.160 --> 00:08:12.320]   take note of the state of that Git repository at that time. So you'll be able to roll back
[00:08:12.320 --> 00:08:19.240]   that repository and run the exact same experiment if you ever need to. We've also here logged
[00:08:19.240 --> 00:08:24.720]   a huge amount of information about the settings that we used both in our model and in our
[00:08:24.720 --> 00:08:30.200]   training pipeline. So again, if we need to replicate this, if this is the magic model
[00:08:30.200 --> 00:08:34.960]   and the magic experiment that has the best run, we can go back and replicate exactly
[00:08:34.960 --> 00:08:43.720]   that before we go and deploy it in a cool little replica. Another handy feature that's
[00:08:43.720 --> 00:08:50.120]   off by default, but you can turn it on, is the code saving. And so again, if you run
[00:08:50.120 --> 00:08:57.160]   Weights & Biases and you turn this on in your user settings, it'll also take a snapshot
[00:08:57.160 --> 00:09:02.840]   of the script or the notebook or the REPL that you're running Weights & Biases in. So
[00:09:02.840 --> 00:09:08.840]   again, in terms of being able to understand exactly what code you used to get this result,
[00:09:08.840 --> 00:09:15.680]   it's all here for you in Weights & Biases. And so that's for a single experiment. But
[00:09:15.680 --> 00:09:21.600]   often, like you saw earlier, we're running tens or a hundred experiments. And so we want
[00:09:21.600 --> 00:09:28.160]   to understand exactly what are the main or the most important settings or hyperparameters,
[00:09:28.160 --> 00:09:33.440]   as they're known in machine learning, to get the most out of your model. And so here, we
[00:09:33.440 --> 00:09:40.200]   have charts like this, which is called a parallel coordinates plot. And in this case, it looks
[00:09:40.200 --> 00:09:47.080]   a bit gnarly. You can't really glean too many insights from this. So here, we're looking
[00:09:47.080 --> 00:09:54.760]   at four different hyperparameters or different training settings and different values for
[00:09:54.760 --> 00:09:59.880]   each. And then on the last column over here, we have the metric that we care about. In
[00:09:59.880 --> 00:10:05.800]   this case, the metric is called AUC and a higher AUC is better. And so we want to understand,
[00:10:05.800 --> 00:10:10.160]   okay, for all of these different experiments with all these different settings, which resulted
[00:10:10.160 --> 00:10:17.320]   in the highest AUC. And so here, we can just click and drag in this workspace, a filter.
[00:10:17.320 --> 00:10:22.640]   And now we have a much clearer idea of what are some of the better settings that we should
[00:10:22.640 --> 00:10:28.040]   consider when training our models. And so you can see, for example, some settings, say
[00:10:28.040 --> 00:10:33.920]   in this column here, which is the learning rate, which is kind of like, think of it as
[00:10:33.920 --> 00:10:42.600]   how quickly the model updates itself after each sample of data that it sees while it's
[00:10:42.600 --> 00:10:49.960]   training. And so here, you can see this model in this pipeline is fairly sensitive to learning
[00:10:49.960 --> 00:10:56.880]   rates between 0.8 and 0.85 here. Whereas other hyperparameters, maybe it's not so sensitive.
[00:10:56.880 --> 00:11:01.840]   We have anything from this hyperparameter, which is the mil and child weight. And this
[00:11:01.840 --> 00:11:08.760]   is anywhere from 120 down to 20. And again, gamma somewhere in the middle, there's 0.5
[00:11:08.760 --> 00:11:14.320]   to 0.7, looks like a promising range. And again, for early stopping rounds, doesn't
[00:11:14.320 --> 00:11:20.080]   look to be so sensitive. We can have decent results across a wide range of early stopping
[00:11:20.080 --> 00:11:25.360]   rounds. And so with charts like this, you can, after running a large amount of experiments,
[00:11:25.360 --> 00:11:32.840]   or even five or 10, you can develop a bit of an intuition of what are the ranges that
[00:11:32.840 --> 00:11:38.400]   your models tend to perform well in. And that's quite important when training, especially
[00:11:38.400 --> 00:11:45.280]   in machine learning. Some of it is almost, can be at times more of an art than a science.
[00:11:45.280 --> 00:11:51.040]   And so doing a lot of experimentation and understanding how your model responds to different
[00:11:51.040 --> 00:11:58.240]   settings helps you build up an intuition of how to get the best out of your models. And
[00:11:58.240 --> 00:12:04.240]   so these are some of the panels that we get in Weights and Biases. To create any one of
[00:12:04.240 --> 00:12:11.640]   these panels, you can just click on these add panel buttons. And so we can replicate
[00:12:11.640 --> 00:12:18.280]   that chart, the parallel coordinates chart again, for example. And so here we have all
[00:12:18.280 --> 00:12:24.560]   the options that we have. And so we can click on that. And so we need to add our columns.
[00:12:24.560 --> 00:12:30.120]   And so we'll start with the metric that we care about. And in this case, we can go for
[00:12:30.120 --> 00:12:38.120]   accuracy. And we'll do, let's see, we'll do this one. Yep. And now we're going to add
[00:12:38.120 --> 00:12:44.800]   the hyperparameters that we're interested in. And so we can do like learning rate again.
[00:12:44.800 --> 00:12:57.880]   And we can do one more. Let's go with the max child rate. No, child rate. Yes. Let's
[00:12:57.880 --> 00:13:08.240]   try that. Just take a second to load up. And okay. And it looks like this metric, accuracy
[00:13:08.240 --> 00:13:19.520]   metric actually wasn't populating. So let's swap that out for another one. No, let's go
[00:13:19.520 --> 00:13:30.320]   with AUC score. We'll keep it simple, right? This one. Great. And we can get rid of this
[00:13:30.320 --> 00:13:40.280]   accuracy. Cool. And that's it. There you can click okay. We can click and drag this. And
[00:13:40.280 --> 00:13:45.800]   now we've recreated this parallel coordinates plot. And so creating plots like this in your
[00:13:45.800 --> 00:13:51.480]   workspace is like super straightforward, really, really easy to do. You'll also notice when
[00:13:51.480 --> 00:13:59.240]   I filtered the plot down here, it's actually filtered across my entire workspace. And so
[00:13:59.240 --> 00:14:04.400]   if you keep an eye on these little eyelids on the left for each of our experiments, when
[00:14:04.400 --> 00:14:11.360]   I close that, it actually displays every run, not only in this chart, but across all of
[00:14:11.360 --> 00:14:18.320]   the other charts in our workspace. So it's also a useful way to filter your entire workspace
[00:14:18.320 --> 00:14:25.600]   by filtering single charts. The other useful thing I wanted to show was our run comparison
[00:14:25.600 --> 00:14:33.800]   chart. And so I can again click on add panel. And so again, when you're running a lot of
[00:14:33.800 --> 00:14:39.920]   experiments, it can be difficult to keep track of all of the changes you are making between
[00:14:39.920 --> 00:14:46.240]   them. So for example, here you see for configs, there's a lot to keep track of here and then
[00:14:46.240 --> 00:14:51.760]   like a whole bunch of runs to keep an eye on. But if we toggle this little diff only
[00:14:51.760 --> 00:14:59.400]   switch here, we can filter this down to only the settings that have changed between each
[00:14:59.400 --> 00:15:05.480]   one. And so we only care about say the configs that we've changed. And so now you can see,
[00:15:05.480 --> 00:15:10.560]   okay, exactly for each one of these runs, what were the different settings that we've
[00:15:10.560 --> 00:15:15.400]   picked for them. And again, that can be useful, especially if you have it narrowed it down
[00:15:15.400 --> 00:15:21.760]   to maybe only if we hide all of these, you've only narrowed it down to like three or four
[00:15:21.760 --> 00:15:26.920]   candidates runs, then you can like zoom in and say, okay, like what are the most interesting
[00:15:26.920 --> 00:15:33.200]   or what were the differences between all of these runs here and get a like more fine grained
[00:15:33.200 --> 00:15:45.000]   idea of an understanding of how this model trains. Super. And so once you have finished
[00:15:45.000 --> 00:15:53.400]   or you have identified some interesting results, you might want to keep a note of those results,
[00:15:53.400 --> 00:15:59.400]   even for either for yourself in terms of like a little kind of training journal, or as a
[00:15:59.400 --> 00:16:06.160]   more polished piece of analysis that you might want to share with a friend or a supervisor
[00:16:06.160 --> 00:16:14.280]   or a manager. And so for those bits of work, we have a tool called reports. And here we
[00:16:14.280 --> 00:16:24.800]   can see some of our favorite Weights and Biases reports. And reports are basically like word
[00:16:24.800 --> 00:16:30.880]   editors with Weights and Biases charts built into it. So you get the advantage of all of
[00:16:30.880 --> 00:16:38.040]   the functionality that you would expect from a word editor, but with the addition of interactive
[00:16:38.040 --> 00:16:42.800]   Weights and Biases charts. And so we can see a few in this example report here that kind
[00:16:42.800 --> 00:16:49.960]   of shows a quick outline of all of the different features. And so this is obviously a little
[00:16:49.960 --> 00:16:54.760]   exaggerated, but if you didn't have embedded Weights and Biases charts, you might be sharing
[00:16:54.760 --> 00:17:00.200]   something like this, which are like screenshots and maybe like low fidelity screenshots, like
[00:17:00.200 --> 00:17:05.880]   dropped into like a Slack or a Discord or like passed around in emails. But the alternative
[00:17:05.880 --> 00:17:11.920]   is that you can embed these like rich Weights and Biases plots. And anyone visiting these
[00:17:11.920 --> 00:17:17.160]   plots can kind of take a look at them, zoom in if they're like interested in a particular
[00:17:17.160 --> 00:17:35.720]   run, they can like click into that run. And using Weights and Biases reports. And so like
[00:17:35.720 --> 00:17:40.560]   we saw in our workspace, an HR you can have in your workspace, you can also have in your
[00:17:40.560 --> 00:17:50.600]   report. Here below, we can see all of the runs in this experiment. And we can, if we,
[00:17:50.600 --> 00:17:56.960]   yeah, I think we can open some of those. I know this one particular one is locked. And
[00:17:56.960 --> 00:18:03.480]   then the other nice feature that we have as like a visualization tool are Weights and
[00:18:03.480 --> 00:18:08.960]   Biases tables. And so here, it's for those of you familiar with like data frames, you
[00:18:08.960 --> 00:18:13.720]   can think of it like as a data frame, but where you can also visualize rich media. So
[00:18:13.720 --> 00:18:20.160]   that could be images, that could be video, that could be audio, you know, HTML, point
[00:18:20.160 --> 00:18:25.560]   clouds, like a huge range of like media formats. And so here you can do a little bit more exploration
[00:18:25.560 --> 00:18:31.040]   of like how your model is training, or even just like see what your predictions look like.
[00:18:31.040 --> 00:18:37.040]   And so in this case, we're simply this is the data set called Fashion MNIST, where the
[00:18:37.040 --> 00:18:42.400]   idea is to predict the model has to learn, you know, what class of what type of clothes
[00:18:42.400 --> 00:18:46.920]   is in the image. And so here in this column, you can see these are the predictions from
[00:18:46.920 --> 00:18:55.000]   the model. And then here is the is the ground truth. So with tables, you know, you can get
[00:18:55.000 --> 00:18:59.560]   all of the like basic functionality you'd expect in the table, like, you know, being
[00:18:59.560 --> 00:19:07.840]   able to like sort columns, but you can also do some interesting actions like grouping
[00:19:07.840 --> 00:19:16.480]   the ground truth. Now, we will see every for every class of clothing, you know, starting
[00:19:16.480 --> 00:19:22.440]   with addresses here, for example, you can explore all of the different samples that
[00:19:22.440 --> 00:19:28.840]   were in our evaluation data set. And you can, you know, browse through and see, well, is
[00:19:28.840 --> 00:19:34.200]   everything like labeled correctly? You know, are there like maybe borderline cases, for
[00:19:34.200 --> 00:19:40.120]   example, here where the model might think it's could also be like a t shirt, as opposed
[00:19:40.120 --> 00:19:45.240]   to like a dress, and kind of understand a little bit more how your how your model is
[00:19:45.240 --> 00:19:51.960]   doing. And so when you group by one column, all of the other columns get grouped to and
[00:19:51.960 --> 00:19:58.560]   so we can then see in these columns here, these are this is the distribution of the
[00:19:58.560 --> 00:20:03.960]   scores for each one of the categories that our model is given. And so the higher the
[00:20:03.960 --> 00:20:10.040]   score, the more likely it's going to predict that category. So here for the dress category,
[00:20:10.040 --> 00:20:15.400]   as you'd expect in a good model, most of the predictions are on the higher end, you know,
[00:20:15.400 --> 00:20:19.800]   somewhere between point nine, and one. And so it's like predicting correctly, that it's
[00:20:19.800 --> 00:20:27.160]   a dress. And you know, for like, to contrast that, we can see, okay, like pullover is for
[00:20:27.160 --> 00:20:32.880]   the ground truth of a pullover, you know, predictions of dress are close to zero there.
[00:20:32.880 --> 00:20:39.400]   And so that's like one useful way to to explore your models, we can also verify, you know,
[00:20:39.400 --> 00:20:45.000]   was my theory that the model might be confused between dresses and shirts, you know, possibly
[00:20:45.000 --> 00:20:50.640]   correct. And we can see here, probably not most of the the when it comes to like the
[00:20:50.640 --> 00:20:55.800]   shirt class, and for samples like this, most of the predictions were close to zero. And
[00:20:55.800 --> 00:21:00.480]   so our model is doing a good job, you know, differentiating between what is a dress and
[00:21:00.480 --> 00:21:07.880]   what is a shirt. And so that's one useful way to use tables. And I'll come back to one
[00:21:07.880 --> 00:21:12.200]   or two other like interesting use cases that I think will be helpful for this hackathon
[00:21:12.200 --> 00:21:20.360]   in a minute. And so in reports, as well as being able to embed all of our charts, you
[00:21:20.360 --> 00:21:26.800]   know, it has all of the expected formatting that you would have in any kind of modern
[00:21:26.800 --> 00:21:33.960]   word editor. And so you have code blocks, latex, checklists, obviously supporting GIFs
[00:21:33.960 --> 00:21:40.840]   is crucial, YouTube embeds, linking to other reports, Weights and Bars reports shows up
[00:21:40.840 --> 00:21:46.800]   nicely like this. And it also it's not here. But you know, we also support like, Spotify
[00:21:46.800 --> 00:21:55.080]   embeds, SoundCloud embeds and Twitter embeds. So there's a whole bunch of content you can
[00:21:55.080 --> 00:22:02.560]   put into a report to like really tell a nice, like engaging story about your work. And so
[00:22:02.560 --> 00:22:13.520]   one useful case for tables is actually exploring your predictions when it comes to playing
[00:22:13.520 --> 00:22:18.920]   around with some text to image models. For example, if you're using them stable diffusion,
[00:22:18.920 --> 00:22:23.560]   like maybe you want to call the API during this hack and create do some like interesting
[00:22:23.560 --> 00:22:31.160]   like image generation as part of your project. And so it's really important when you're training
[00:22:31.160 --> 00:22:34.400]   or fine tuning or even just like predicting with these models to like be able to keep
[00:22:34.400 --> 00:22:38.800]   track of like how your prompts are changing to understand how to get the most out of your
[00:22:38.800 --> 00:22:44.520]   model. And so here I am, this is an example of what you might do for a training journal,
[00:22:44.520 --> 00:22:50.200]   where you know, for over like a few days, over the Christmas break, I was just like
[00:22:50.200 --> 00:22:54.400]   doing some different experiments, taking quick notes of what the results were, and just like
[00:22:54.400 --> 00:22:59.280]   dumping them all into a report like this, which was like, really handy in retrospect,
[00:22:59.280 --> 00:23:03.640]   to be able to look back and see what worked and what didn't work here. And so here, for
[00:23:03.640 --> 00:23:11.040]   example, is just a table. And so this task that I was trying to do was to fine tune a
[00:23:11.040 --> 00:23:16.440]   stable diffusion model on tortas. And so a torta, if you don't know, is a delicious type
[00:23:16.440 --> 00:23:23.680]   of Mexico sandwich. I was in Mexico for Christmas. So this was top of mind. And so here are the,
[00:23:23.680 --> 00:23:29.560]   here's my training data set. And so examples of tortas that I, you know, just pulled off
[00:23:29.560 --> 00:23:35.240]   some Google reviews and wanted to visualize to make sure that they all kind of looked
[00:23:35.240 --> 00:23:40.800]   okay. And so there's like a nice diversity of, you know, shapes and sizes of tortas here.
[00:23:40.800 --> 00:23:47.400]   And so we're looking good from like the data set point of view. And then so to log to a
[00:23:47.400 --> 00:23:51.880]   table, I don't want to spend too much time looking at code, but we'll go quickly just
[00:23:51.880 --> 00:23:59.760]   through this one little bit. To log to a table, you first call 1db.init. And so to start any
[00:23:59.760 --> 00:24:05.600]   Weights and Biases experiment, this is your, you know, the first port of call. Well, obviously
[00:24:05.600 --> 00:24:14.400]   after importing our library 1db. And so once you have imported the library, you call 1db.init.
[00:24:14.400 --> 00:24:19.440]   And this started, starts a Weights and Biases run. And so once you have started that run,
[00:24:19.440 --> 00:24:25.200]   you know, you can log anything to it, you know, be it your images or data sets or model
[00:24:25.200 --> 00:24:30.680]   files or metrics like we saw earlier. And so in this case, we're going to log a table
[00:24:30.680 --> 00:24:36.200]   to this run. And so once we've set it up and passing our Weights and Biases username to
[00:24:36.200 --> 00:24:41.960]   the entity and given our project a name and optionally passing us some of the like config
[00:24:41.960 --> 00:24:48.280]   values that we, that we care about, we create a table. And so this is how you first instantiate
[00:24:48.280 --> 00:24:53.480]   a table and we give the column names. The column in this case are the concept, which
[00:24:53.480 --> 00:24:58.600]   in this particular example is our tortoise. We give it the prompt and the, so this is,
[00:24:58.600 --> 00:25:02.920]   you know, what we're asking stable diffusion to create. And then this is a guidance scale.
[00:25:02.920 --> 00:25:10.080]   This is a setting on how much or little the model should pay attention to your prompt.
[00:25:10.080 --> 00:25:14.440]   And so once we have that all set up, essentially we're looping through a whole bunch of guidance
[00:25:14.440 --> 00:25:19.400]   settings here to understand the impact of different guidance scales. We're generating
[00:25:19.400 --> 00:25:28.000]   five images, I think, for each one of those settings. And then we're adding that data
[00:25:28.000 --> 00:25:35.560]   to a table row by row. And so that's how you append data to a table, row by row by row.
[00:25:35.560 --> 00:25:40.880]   And so we have the name, the prompt, the guidance scale, and then we log all of our images here.
[00:25:40.880 --> 00:25:47.240]   And we actually, I was wrong, we have six images. And so this is a image tensor here
[00:25:47.240 --> 00:25:52.320]   and we just wrap it in 1db.image to be able to, for weights and biases, to be able to
[00:25:52.320 --> 00:25:56.520]   visualize it correctly. And so we do that for each one of the guidance scales that we
[00:25:56.520 --> 00:26:03.760]   have. And then when we're ready with our table, we just call 1db.log and we pass it a dictionary,
[00:26:03.760 --> 00:26:08.960]   which in this case is a dictionary of the name of our table and the table object itself.
[00:26:08.960 --> 00:26:15.520]   And so 1db.log is what you use to log anything to weights and biases, be it a table, be it
[00:26:15.520 --> 00:26:23.160]   your metrics, or be it data sets or model files. And then finally we call 1db.finish
[00:26:23.160 --> 00:26:28.600]   to finish our weights and biases run. And so we can quickly see the result of logging
[00:26:28.600 --> 00:26:33.360]   to a table like this. And so this is like an early version where I was more exploring
[00:26:33.360 --> 00:26:39.480]   just the different guidance scales while keeping the same prompt. And so here you can see our
[00:26:39.480 --> 00:26:47.400]   guidance scales running from seven to 12. And as these images come back to me, you can
[00:26:47.400 --> 00:26:55.120]   kind of get a feel of like, if this guidance scale is having like a massive impact on the
[00:26:55.120 --> 00:27:00.800]   generated outputs. And this is TBD, it's not entirely clear that guidance scale in this
[00:27:00.800 --> 00:27:05.680]   particular example is making a huge amount of difference, which is a good learning in
[00:27:05.680 --> 00:27:12.200]   itself. And so later we tried to explore like, okay, different prompts with the same fixed
[00:27:12.200 --> 00:27:16.080]   guidance scale we set at nine in this case. And we say, okay, guidance scale at nine seemed
[00:27:16.080 --> 00:27:20.400]   reasonable. Let's see how it goes with a few different examples. And so in this case, in
[00:27:20.400 --> 00:27:24.840]   case you can't read, we have a photo of lots of tortoise in a green field, looking pretty
[00:27:24.840 --> 00:27:30.000]   good. A sketch drawing of a tortoise floating through space, again, looking pretty good.
[00:27:30.000 --> 00:27:35.880]   A tortoise being eaten by a sheep by Claude Monet, not great here. And so there's probably
[00:27:35.880 --> 00:27:42.760]   something we can do to like, with this prompt, to try and make it more specific or more descriptive
[00:27:42.760 --> 00:27:49.160]   and try again. And so being able to keep track of like all of these learnings as you go is
[00:27:49.160 --> 00:27:53.360]   with two like weights and biases tables is like super useful. And so I've got a whole
[00:27:53.360 --> 00:27:59.480]   bunch of tables here. This is going to be linked in one of the docs we're going to share.
[00:27:59.480 --> 00:28:05.160]   And yeah, you can, you feel free to browse in your own time. The last thing. And so this
[00:28:05.160 --> 00:28:12.180]   is a doc that we're going to share to everyone participating. And this is just a few basics
[00:28:12.180 --> 00:28:16.720]   here in terms of what is weights and biases. I link to our quick start guide and like how
[00:28:16.720 --> 00:28:22.400]   to sign up for a free account. And I should say weights and biases is completely free
[00:28:22.400 --> 00:28:29.260]   for personal use. So you can just feel free to sign up. The one thing you need to do when
[00:28:29.260 --> 00:28:35.380]   you start a weights and biases run, you'll be asked for your API key. And so you'll find
[00:28:35.380 --> 00:28:41.960]   it at this link here. The prompt in the code will also like give you this link as well
[00:28:41.960 --> 00:28:46.680]   every time. So you don't have to know this today. And then you, so you go to this link,
[00:28:46.680 --> 00:28:53.240]   you pass it your API key, and then you can log to weights and biases as normal. We recommend
[00:28:53.240 --> 00:28:57.360]   for this hack and you know, when using weights and biases with Repl.it, it's a good idea
[00:28:57.360 --> 00:29:03.440]   to save your one API key to your Repl.it secrets. And so that way, you know, you can just save
[00:29:03.440 --> 00:29:11.040]   it there once and then you, you know, that'll be available to your Repl.it in the environment
[00:29:11.040 --> 00:29:16.640]   and you won't have to think about logging this again. As an alternative, but be careful
[00:29:16.640 --> 00:29:22.520]   when you're sharing public Repl.its, you could also, you know, specifically add it to your
[00:29:22.520 --> 00:29:28.560]   script setting the environment variable in Python here by passing your API key like that.
[00:29:28.560 --> 00:29:33.960]   But again, highly recommend you use Repl.it secrets for your weights and biases API key
[00:29:33.960 --> 00:29:40.360]   and any of the API keys that you might be using during the hackathon, such as GPT-3
[00:29:40.360 --> 00:29:48.400]   or Stable Fusion API keys. So here, like I said, we have a bunch of examples of reports
[00:29:48.400 --> 00:29:54.760]   for yourselves, as well as a link to the report I just showed you. I wanted to mention one
[00:29:54.760 --> 00:30:03.440]   thing. And so when it comes to GPUs on Repl.it, and so Repl.it have currently have K80s available,
[00:30:03.440 --> 00:30:09.940]   which is a GPU from NVIDIA. And so I've had fun playing around with these the last few
[00:30:09.940 --> 00:30:14.960]   weeks and kind of wanted to point out a few things to people when they're using them.
[00:30:14.960 --> 00:30:21.480]   And so right now, the disk storage on Repl.it is limited to a gigabyte. And so it's worth
[00:30:21.480 --> 00:30:26.120]   keeping an eye on your disk usage and maybe considering deleting any like model files
[00:30:26.120 --> 00:30:31.920]   or data sets that you're not using. It's also worth considering before downloading a data
[00:30:31.920 --> 00:30:38.120]   or a model, or for example, like a large pre-trained model, checking actually the file size there
[00:30:38.120 --> 00:30:43.760]   because you don't want to download a model so big that you won't be able to run it. So
[00:30:43.760 --> 00:30:49.880]   again, worth bearing in mind there. And the other thing is just to keep an eye on the
[00:30:49.880 --> 00:31:00.560]   memory usage of your GPU. And so you can easily see that just by running NVIDIA SMI in your
[00:31:00.560 --> 00:31:06.760]   shell and you'll get all of the stats from your GPU there. And at times, it might be
[00:31:06.760 --> 00:31:14.480]   worth clearing your GPU cache to be able to free up some memory to do more training. Weights
[00:31:14.480 --> 00:31:20.560]   and biases in the system metrics, like I mentioned, also keeps track of your GPU utilization.
[00:31:20.560 --> 00:31:25.640]   So on the flip side, you want to make sure that you're using as much of your GPU as you
[00:31:25.640 --> 00:31:30.920]   can. And so in weights and biases, it gives you a percent from like zero to 100% of how
[00:31:30.920 --> 00:31:38.040]   much of your GPU memory you're using. And you want to get that up 80, 90, 95% to make
[00:31:38.040 --> 00:31:43.320]   sure you're training as fast as possible. What else in this doc? Finally, yeah, in this
[00:31:43.320 --> 00:31:49.520]   doc, there's a bunch of links to a bunch of resources here, our docs, the community Discord,
[00:31:49.520 --> 00:31:53.880]   and a few other replit examples. And we'll be adding a few more links to this doc as
[00:31:53.880 --> 00:32:00.880]   we go during the week. Great. Okay. How are we doing on time? A few more minutes, I think.
[00:32:00.880 --> 00:32:11.200]   Cool. So I wanted to just point out some of the repls that are on the weights and biases
[00:32:11.200 --> 00:32:19.480]   replit page. So when you go to replit.com/@wandb, you'll be able to see all of our pinned repls,
[00:32:19.480 --> 00:32:24.760]   including this one. And so this is our quick start. And this is just the basics of logging
[00:32:24.760 --> 00:32:31.760]   with weights and biases. And we can take a look into the code here. And so one thing
[00:32:31.760 --> 00:32:38.120]   you need to do when you're using weights and biases with replit, because it's a newer environment
[00:32:38.120 --> 00:32:44.880]   for us, you need to call this or set this environment variable, wandb_console, you set
[00:32:44.880 --> 00:32:49.880]   it to wrap, and then you're good to go to do your weights and biases login. And so once
[00:32:49.880 --> 00:32:59.720]   you've installed your library and you've imported wandb, like I mentioned before, you call wandb.init
[00:32:59.720 --> 00:33:06.560]   to start a run. And so this is where you, like you saw before, you can pass your entity.
[00:33:06.560 --> 00:33:12.520]   In this case, I haven't passed the entity because it defaults to your personal user.
[00:33:12.520 --> 00:33:17.000]   You can set your project name, you can set the name of your run. So if you don't love
[00:33:17.000 --> 00:33:22.200]   the random names that weights and biases is given your runs, or you want to like put some
[00:33:22.200 --> 00:33:26.680]   hint in the name of like what you're doing in this experiment, you can change the name.
[00:33:26.680 --> 00:33:31.800]   And then finally, you can add any relevant configs here that you want to like make sure
[00:33:31.800 --> 00:33:39.400]   to keep track of later. So I really encourage you to, when you're log, log more than you
[00:33:39.400 --> 00:33:44.240]   think you need to the config, because you never know after a few days of a week of doing
[00:33:44.240 --> 00:33:49.600]   experiments, actually what was that setting that you actually turned out to make a big
[00:33:49.600 --> 00:33:53.560]   difference. And so it's always better to be safe than sorry, and log as much as you can
[00:33:53.560 --> 00:33:58.960]   to your config so that you have like the full picture of how you train the model in a few
[00:33:58.960 --> 00:34:04.080]   days or a few weeks. And so in this case, we've started the weights and biases run,
[00:34:04.080 --> 00:34:10.480]   it's running. This is just, you know, a simple like dummy example of like some of the, in
[00:34:10.480 --> 00:34:14.640]   a training loop, some of the metrics you might be logging. And so here, you know, we're just
[00:34:14.640 --> 00:34:21.120]   calculating the kind of like random, but ascending accuracy and a loss that's like slowly descending.
[00:34:21.120 --> 00:34:24.840]   And then once you have those metrics, like I said, you saw before with the table, we
[00:34:24.840 --> 00:34:33.120]   just called one DB dot log. And so here you pass your metrics in as a dictionary. And
[00:34:33.120 --> 00:34:40.960]   this, you know, accepts ints or scalars or floats, not focusing on the data type here.
[00:34:40.960 --> 00:34:44.880]   And so this is just simulating a training run. Once you're finished your run, like I
[00:34:44.880 --> 00:34:51.800]   saw before, you just call one DB dot finish. And that'll be your metrics logged to weights
[00:34:51.800 --> 00:34:58.520]   and biases. Here, you know, we have an actual like bit more of a, like a real example. And
[00:34:58.520 --> 00:35:04.120]   so here, you know, we're actually doing a small example, a small experiment on a real,
[00:35:04.120 --> 00:35:09.880]   you know, mini model and varying parameter, which is called a dropout. And so dropout
[00:35:09.880 --> 00:35:18.580]   in machine learning is in, especially in neural networks is when you deliberately randomly
[00:35:18.580 --> 00:35:27.840]   set some of the weights in your model to zero. And it's useful to regularize your model or
[00:35:27.840 --> 00:35:31.840]   in other words, you know, it prevents it from just memorizing your training data, but instead
[00:35:31.840 --> 00:35:38.080]   helps it learn general concepts. And so here, this is just a quick experiment where we're
[00:35:38.080 --> 00:35:46.040]   setting a random value for our dropout, which has then been passed to our model in the step
[00:35:46.040 --> 00:35:54.200]   here. And then we're looking at the impact of how that random change impacts your metrics
[00:35:54.200 --> 00:35:59.840]   here. In this case, our training loss and later on our validation loss here. And so
[00:35:59.840 --> 00:36:07.840]   here is another example of logging to weights and biases run. So this is like the kind of
[00:36:07.840 --> 00:36:15.640]   one-on-one of logging to weights and biases. And this runs nicely in a REPL. For something
[00:36:15.640 --> 00:36:23.200]   more advanced, we also have this example. So here we're training a vision model with
[00:36:23.200 --> 00:36:27.120]   Hugging Face Transformers, which is a popular machine learning library, but for text and
[00:36:27.120 --> 00:36:34.880]   image training. And so here you can take, if I reload this, you can take a browse through
[00:36:34.880 --> 00:36:39.960]   the code here. In this case, we're actually using a inbuilt integration that we have in
[00:36:39.960 --> 00:36:46.280]   Hugging Face Transformers in their trainer. And so here there's actually less weights
[00:36:46.280 --> 00:36:56.400]   and biases codes that you need to run, which is cool. You can simply set a parameter in
[00:36:56.400 --> 00:37:04.680]   the trainer and then that will automatically kick off weights and biases logging and yeah,
[00:37:04.680 --> 00:37:10.720]   start training your vision model and sending metrics back to weights and biases. And so
[00:37:10.720 --> 00:37:16.560]   you can take a browse through the code here. I'll just get down to where you're sending
[00:37:16.560 --> 00:37:25.280]   weights and biases. And so here Hugging Face's trainer takes these training arguments. And
[00:37:25.280 --> 00:37:32.360]   so this is how you turn on weights and biases logging. You just simply set report to 1DB
[00:37:32.360 --> 00:37:37.880]   and then you're good to go. You can see those training arguments being passed here to the
[00:37:37.880 --> 00:37:46.400]   trainer. But once this trainer gets instantiated and report to 1DB is running, you'll be then
[00:37:46.400 --> 00:37:52.280]   prompted for your API key, unless it's already in your secrets. And then your model will
[00:37:52.280 --> 00:37:58.120]   start training and your metrics start getting pushed to weights and biases. The last example
[00:37:58.120 --> 00:38:04.800]   I wanted to quickly run through was this example of nano-GPT. So I think probably most, if
[00:38:04.800 --> 00:38:11.440]   not everyone on this call has heard of chat-GPT at this point and also GPT-3, these super
[00:38:11.440 --> 00:38:20.480]   powerful models from open AI. And so Andrew Karpathy, well-known machine learning professor
[00:38:20.480 --> 00:38:26.360]   at Stanford and also the ex-head of autonomy at Tesla has this wonderful little library
[00:38:26.360 --> 00:38:35.600]   called nano-GPT. And so this is an example of this library or this model being trained
[00:38:35.600 --> 00:38:42.720]   in Replicant. And so he's written this, he's really boiled down the training code and the
[00:38:42.720 --> 00:38:48.960]   model code to train one of these GPT models to its like bare, bare bones. And so if you're
[00:38:48.960 --> 00:38:54.760]   interested in how all these like crazy big models are trained, this is a really good
[00:38:54.760 --> 00:39:00.360]   place to start. He also has an accompanying couple of YouTube videos that we can like
[00:39:00.360 --> 00:39:07.680]   put into the resources we'll be sending folks as well. And again, he actually just started
[00:39:07.680 --> 00:39:12.880]   using weights and biases for this project, which was a pretty cool thing to see. And
[00:39:12.880 --> 00:39:21.520]   so this is a slightly modified version of his, one of his scripts. And yeah, I would
[00:39:21.520 --> 00:39:26.120]   say we don't need to run through this code. We don't need to watch this replica load on
[00:39:26.120 --> 00:39:31.320]   my slow internet right now. But yeah, that's more or less, I think everything I wanted
[00:39:31.320 --> 00:39:40.280]   to run you through today. Like Arnella said, we'll be in the Replit discord in the machine
[00:39:40.280 --> 00:39:47.080]   learning hackathon channel all week. Myself, Corey, the ML engineer in my team are there
[00:39:47.080 --> 00:39:51.160]   to give you a hand, make sure you're getting set up and make sure all your weights and
[00:39:51.160 --> 00:39:56.640]   biases is logging is running well, answer any of your machine learning questions and
[00:39:56.640 --> 00:40:01.720]   yeah, happy to pass it back to Arnella.
[00:40:01.720 --> 00:40:10.280]   Hello, thanks Morgan. That was amazing. I feel like I learned so much just watching
[00:40:10.280 --> 00:40:17.440]   that. Also now I really want a torta. Thanks for that. But yeah, I just wanted to pop back
[00:40:17.440 --> 00:40:24.120]   in to explain the submission rules and walk through the prizes again, because we know
[00:40:24.120 --> 00:40:36.640]   that's why you're all here. So let's do that quickly. So this is the hackathon website
[00:40:36.640 --> 00:40:43.640]   that I'm sure many of you have seen already. And it's also where you can still apply to
[00:40:43.640 --> 00:40:48.600]   participate in the hackathon. Like we said, you can apply until Wednesday and we'll accept
[00:40:48.600 --> 00:40:56.560]   new people every day. So it's not too late. I wanted to go over the rules once again.
[00:40:56.560 --> 00:41:03.040]   So the main thing is that you have to have both a Replit account and a weights and biases
[00:41:03.040 --> 00:41:10.480]   account and you have to use both technologies in your project. So that's going to be the
[00:41:10.480 --> 00:41:19.920]   really important thing. And the last date for valid entries is 1159 PM next Saturday.
[00:41:19.920 --> 00:41:25.080]   And this is Pacific time. So just be mindful of that. The form will not accept submissions
[00:41:25.080 --> 00:41:32.480]   after that point. And the actual submission form will be sent to your emails also this
[00:41:32.480 --> 00:41:38.320]   Wednesday. So stay tuned for that. You know, if you're really, really fast and you finish
[00:41:38.320 --> 00:41:43.040]   your project before then, that's awesome. Make sure you submit it on Wednesday. But
[00:41:43.040 --> 00:41:49.920]   we think, you know, it might take people a little bit of time to get going. So the next
[00:41:49.920 --> 00:41:56.240]   thing that I want to talk about is teams briefly. So it's totally okay to participate in a team
[00:41:56.240 --> 00:42:03.480]   and you can just let us know who's a part of your team when you submit your project.
[00:42:03.480 --> 00:42:07.280]   But the important thing to consider is that you're going to want to make sure that the
[00:42:07.280 --> 00:42:12.680]   submission, the account that you use for the submission is the same Replet account that
[00:42:12.680 --> 00:42:19.280]   was accepted to the hackathon and also is the one that got the cycles for GPUs. So we
[00:42:19.280 --> 00:42:25.480]   won't be granting cycles to everyone in your team. It'll just be the account that was accepted
[00:42:25.480 --> 00:42:34.840]   to the hackathon and receive that email. And the prizes to go over one more time. So like
[00:42:34.840 --> 00:42:39.000]   I mentioned earlier, everyone is eligible for the grand prize as well as the honorable
[00:42:39.000 --> 00:42:44.000]   mention and then on the submission form, you will choose whether you want to be eligible
[00:42:44.000 --> 00:42:50.160]   for the best weights and biases report or the best Replet project. So the grand prize
[00:42:50.160 --> 00:42:55.960]   300,000 cycles, which is amazing. Think about all of the community Repls you can tip with
[00:42:55.960 --> 00:43:02.620]   that or all the bounties you can post with that. We've got 100,000 cycles for best weights
[00:43:02.620 --> 00:43:09.600]   and biases report as well as best Replet project and then for honorable mention, 50,000 cycles.
[00:43:09.600 --> 00:43:15.120]   Also for best Replet project, make sure you share your work to community using the 1B
[00:43:15.120 --> 00:43:23.680]   tag so that we can see all of your wonderful projects. And Morgan and his team at weights
[00:43:23.680 --> 00:43:28.920]   and biases will choose the winners. So those are the folks that you want to impress with
[00:43:28.920 --> 00:43:34.880]   all of your projects. And yeah, just wanted to say a really big thank you to our guests.
[00:43:34.880 --> 00:43:43.560]   I'll pull you all back in really briefly. Thanks so much for being here on a Saturday.
[00:43:43.560 --> 00:43:49.080]   We really appreciate your time and we'll see everyone at the closing ceremony on the 15th.
[00:43:49.080 --> 00:43:54.120]   Brilliant. Yeah. I'm looking forward to chatting with everyone during the week and the discord
[00:43:54.120 --> 00:43:59.120]   as well. I think we'll try and maybe have some daily updates and showcase any early
[00:43:59.120 --> 00:44:04.800]   cool projects. We also actually have one cool example coming maybe on Monday where you've
[00:44:04.800 --> 00:44:10.460]   probably seen examples online where people are trying to replicate chat GPT using the
[00:44:10.460 --> 00:44:15.480]   open AI and using external knowledge bases. And so we have a cool example like that coming,
[00:44:15.480 --> 00:44:20.000]   which I think works really nicely in Replet and weights and biases too. So yeah, looking
[00:44:20.000 --> 00:44:24.200]   forward to hanging out with everyone for a week.
[00:44:24.200 --> 00:44:29.760]   We have one question in the chat. How many people can there be in a group? I would say
[00:44:29.760 --> 00:44:34.120]   that Morgan, I defer to you on that.
[00:44:34.120 --> 00:44:41.400]   Yeah. No, no strong opinion there. Machine learning projects tend to be tricky to manage
[00:44:41.400 --> 00:44:46.880]   when you've got more than like two to three people, I think. But yeah, I guess there's
[00:44:46.880 --> 00:44:53.680]   no hard limit on the amount of people in your team. Bear in mind, I think it's only going
[00:44:53.680 --> 00:44:58.440]   to be one account that the cycles are going to be credited to if you do win. Correct?
[00:44:58.440 --> 00:45:07.840]   Yeah. So just be mindful of that and do whatever you wish within those bounds, I guess.
[00:45:07.840 --> 00:45:13.480]   Amazing. If anyone has any other questions throughout the week or today, please post
[00:45:13.480 --> 00:45:18.460]   in the Discord channel and we'll get back to you. But otherwise, look for communications
[00:45:18.460 --> 00:45:26.480]   from us via email and also in the announcements in the Discord channel. Thanks so much for
[00:45:26.480 --> 00:45:27.480]   joining us today.
[00:45:27.480 --> 00:45:30.480]   Brilliant. Thanks everyone. See you soon.
[00:45:30.480 --> 00:45:31.680]   Bye.
[00:45:31.680 --> 00:45:41.680]   [BLANK_AUDIO]

