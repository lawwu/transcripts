
[00:00:00.000 --> 00:00:04.560]   The following is a conversation with Michael Malice, his second time on the podcast.
[00:00:04.560 --> 00:00:09.560]   He's an anarchist, political thinker, podcaster and author.
[00:00:09.560 --> 00:00:15.440]   He wrote Dear Reader, which is a book on North Korea, and The New Right,
[00:00:15.440 --> 00:00:20.360]   a book on the various ideological movements at the fringe of American politics.
[00:00:20.360 --> 00:00:25.560]   He hosts the podcast called You're Welcome, spelled Y-O-U-R.
[00:00:25.560 --> 00:00:28.720]   And in general, there's a lot of live shows on YouTube
[00:00:29.080 --> 00:00:34.920]   that are at times profoundly absurd and at other times absurdly profound
[00:00:34.920 --> 00:00:37.800]   and always full of humor and wisdom.
[00:00:37.800 --> 00:00:43.040]   He is the Joker to my Batman and the caviar to my vodka.
[00:00:43.040 --> 00:00:49.560]   His masterful dance between dark humor and difficult, even dangerous ideas
[00:00:49.560 --> 00:00:52.240]   challenges me to think deeply about this world.
[00:00:52.240 --> 00:00:57.520]   And when that fails, at least smile and have a good laugh at the absurdity of it all.
[00:00:58.400 --> 00:01:00.200]   This episode has much of that.
[00:01:00.200 --> 00:01:05.720]   His outfit, for example, the exact inverse of mine
[00:01:05.720 --> 00:01:12.120]   with a white suit and a black shirt is just one example of that,
[00:01:12.120 --> 00:01:17.200]   of the humor, trolling and brilliance that is Michael Malice.
[00:01:17.200 --> 00:01:23.640]   Quick mention of our sponsors, NetSuite, business management software,
[00:01:24.120 --> 00:01:31.360]   Athletic Greens, all in one nutrition drink, Sun Basket, meal delivery service and Cash App.
[00:01:31.360 --> 00:01:37.720]   So the choice is success, health, food or money.
[00:01:37.720 --> 00:01:39.760]   Choose wisely, my friends.
[00:01:39.760 --> 00:01:45.080]   And if you wish, click the sponsor links below to get a discount and to support this podcast.
[00:01:45.080 --> 00:01:51.520]   As a side note, let me say that Michael is in many ways a man of radical ideas,
[00:01:52.000 --> 00:01:54.600]   but also a man with kindness in his heart.
[00:01:54.600 --> 00:01:59.200]   Those two things are great ingredients for a fascinating conversation.
[00:01:59.200 --> 00:02:03.120]   I hope to have several such people on this podcast this upcoming year
[00:02:03.120 --> 00:02:08.760]   who also have radical ideas about politics, science, technology and life.
[00:02:08.760 --> 00:02:14.200]   At times, often perhaps, I might fail at asking the challenging questions
[00:02:14.200 --> 00:02:17.400]   that should be asked, but I will try my best to do so
[00:02:17.400 --> 00:02:20.400]   and hope to keep improving every time.
[00:02:20.400 --> 00:02:24.760]   Mostly, I come to these conversations with an open mind and with love.
[00:02:24.760 --> 00:02:28.760]   Unfortunately, that kind of approach can be taken advantage of in many ways.
[00:02:28.760 --> 00:02:34.520]   It can be used by reporters or just people online later to highlight how or why
[00:02:34.520 --> 00:02:38.960]   I'm ignorant or worse, I'm generally not a good human being.
[00:02:38.960 --> 00:02:41.720]   In the context of this, I have two options.
[00:02:41.720 --> 00:02:47.840]   I could either be cautious and afraid or second, be kind, thoughtful and fearless.
[00:02:48.440 --> 00:02:53.480]   I choose the latter, hopefully while still being open, fragile and empathetic.
[00:02:53.480 --> 00:02:58.480]   Again, I strive to be like the main character of The Idiot by Dostoevsky.
[00:02:58.480 --> 00:03:01.280]   That's my New Year's resolution.
[00:03:01.280 --> 00:03:05.080]   Be kind and do difficult things, difficult conversations,
[00:03:05.080 --> 00:03:09.800]   difficult research projects and difficult entrepreneurial adventures.
[00:03:09.800 --> 00:03:14.400]   If you enjoy this thing, subscribe on YouTube, review it on Apple Podcasts,
[00:03:14.680 --> 00:03:19.920]   follow on Spotify, support it on Patreon or connect with me on Twitter @LexFriedman.
[00:03:19.920 --> 00:03:24.160]   And now here's my conversation with Michael Malice.
[00:03:24.160 --> 00:03:26.000]   Knock, knock.
[00:03:26.000 --> 00:03:28.880]   You're stealing my bed?
[00:03:28.880 --> 00:03:30.000]   I'll kill your family.
[00:03:30.000 --> 00:03:34.480]   That's not how a knock-knock joke works.
[00:03:34.480 --> 00:03:35.920]   Knock, knock, Michael.
[00:03:35.920 --> 00:03:37.800]   You don't do knock-knock jokes with Russians.
[00:03:37.800 --> 00:03:39.640]   Because if we have to knock at the door,
[00:03:39.640 --> 00:03:43.680]   turn down the TV, you got to sit quiet.
[00:03:44.040 --> 00:03:45.320]   We hope they go away.
[00:03:45.320 --> 00:03:48.120]   You don't do that back in the Netherlands.
[00:03:48.120 --> 00:03:48.960]   You know this.
[00:03:48.960 --> 00:03:49.560]   It's triggering.
[00:03:49.560 --> 00:03:50.160]   Who's there?
[00:03:50.160 --> 00:03:52.920]   I can't even do it now.
[00:03:52.920 --> 00:03:54.440]   Knock, knock.
[00:03:54.440 --> 00:03:55.320]   Who's there?
[00:03:55.320 --> 00:03:56.920]   Leon.
[00:03:56.920 --> 00:03:58.000]   Leon who?
[00:03:58.000 --> 00:04:00.520]   Leon me when you're not strong, Michael.
[00:04:00.520 --> 00:04:02.440]   Well, that will never happen.
[00:04:02.440 --> 00:04:07.280]   I stole elegantly, eloquently that joke from you.
[00:04:07.280 --> 00:04:09.200]   The lie detector term.
[00:04:09.200 --> 00:04:10.040]   That was a lie.
[00:04:10.040 --> 00:04:11.320]   Elegantly and eloquently.
[00:04:11.320 --> 00:04:11.840]   Well.
[00:04:11.840 --> 00:04:17.200]   Yeah, you crossed it on a sheet of paper.
[00:04:17.200 --> 00:04:18.480]   That means it's real.
[00:04:18.480 --> 00:04:21.560]   The reason I bring it up is because you had the guts,
[00:04:21.560 --> 00:04:25.240]   the brilliance to do a knock-knock joke.
[00:04:25.240 --> 00:04:28.160]   Not once, but three times with Alex Jones.
[00:04:28.160 --> 00:04:29.160]   I think it was like six.
[00:04:29.160 --> 00:04:29.880]   I had a runner.
[00:04:29.880 --> 00:04:30.880]   OK.
[00:04:30.880 --> 00:04:35.000]   Maybe they started to sort of melt together in this beautiful
[00:04:35.000 --> 00:04:38.680]   art form that you've created, which is like these kind,
[00:04:38.680 --> 00:04:40.760]   loving knock-knock jokes with Alex Jones.
[00:04:41.120 --> 00:04:44.440]   So you got a chance to meet him and talk to them twice with
[00:04:44.440 --> 00:04:45.280]   Tim Pool.
[00:04:45.280 --> 00:04:45.720]   Yeah.
[00:04:45.720 --> 00:04:48.400]   In a long form conversation.
[00:04:48.400 --> 00:04:54.560]   What was it like talking to Alex Jones, both on the deep
[00:04:54.560 --> 00:05:00.160]   philosophical, intellectual level and staring the man in his eyes
[00:05:00.160 --> 00:05:04.000]   and doing a knock-knock joke about Olive.
[00:05:04.000 --> 00:05:04.720]   Knock, knock.
[00:05:04.720 --> 00:05:05.320]   Who's there?
[00:05:05.320 --> 00:05:05.880]   Olive.
[00:05:05.880 --> 00:05:07.040]   I love you, Alex.
[00:05:07.040 --> 00:05:10.840]   Well, there's a lot to explain.
[00:05:10.880 --> 00:05:12.160]   Where do you start?
[00:05:12.160 --> 00:05:15.240]   I've been on his show, InfoWars, a few times when I was
[00:05:15.240 --> 00:05:16.920]   researching my book, Then You Write.
[00:05:16.920 --> 00:05:20.000]   So I had had conversations with him before.
[00:05:20.000 --> 00:05:23.480]   One of the things that I appreciate about Alex is he is a
[00:05:23.480 --> 00:05:27.040]   lot more self-aware than people think and has a good sense of
[00:05:27.040 --> 00:05:27.440]   humor.
[00:05:27.440 --> 00:05:31.640]   And I also like a good twist ending.
[00:05:31.640 --> 00:05:35.680]   So if you set people up and all these jokes are these kind of
[00:05:35.680 --> 00:05:38.960]   vapid, you know, all of you jokes, and the last one's about
[00:05:38.960 --> 00:05:42.120]   building seven, they're not going to see that one coming, nor
[00:05:42.120 --> 00:05:43.320]   will he see that one coming.
[00:05:43.320 --> 00:05:45.800]   I even had another one about Sandy Hook, which I didn't do on
[00:05:45.800 --> 00:05:48.240]   the air because he was being like a good sport.
[00:05:48.240 --> 00:05:51.000]   So I didn't, but that was the dagger that was kind of behind
[00:05:51.000 --> 00:05:52.160]   my back if necessary.
[00:05:52.160 --> 00:05:56.200]   But it was a good mechanism toward, I like it when things
[00:05:56.200 --> 00:05:57.160]   work on several levels.
[00:05:57.160 --> 00:06:01.840]   It was also a good mechanism to keep kind of the conversation
[00:06:01.840 --> 00:06:02.480]   guarded.
[00:06:02.480 --> 00:06:05.040]   And this every so often, this is kind of hitting the control,
[00:06:05.040 --> 00:06:10.800]   delete and bring it down to a certain point of calmness.
[00:06:10.800 --> 00:06:12.200]   What about the love thing?
[00:06:12.200 --> 00:06:16.200]   I mean, you're saying that that was a buildup to the dagger,
[00:06:16.200 --> 00:06:21.480]   but it was also somehow really refreshing to get that little
[00:06:21.480 --> 00:06:23.440]   jolt, like that pause.
[00:06:23.440 --> 00:06:25.520]   You don't get that in conversations often.
[00:06:25.520 --> 00:06:28.560]   Like I'm a huge fan of Rogan and he'll have a three hour
[00:06:28.560 --> 00:06:34.320]   conversation, but at some point just pause and be like, I love
[00:06:34.320 --> 00:06:34.840]   you, man.
[00:06:35.480 --> 00:06:39.960]   Like it's in the cheesiest way possible because that seems
[00:06:39.960 --> 00:06:42.880]   to be, it somehow hits the hardest then.
[00:06:42.880 --> 00:06:43.680]   I don't know.
[00:06:43.680 --> 00:06:46.400]   I don't know you didn't intend it that way, but with Alex
[00:06:46.400 --> 00:06:49.720]   Jones to sit there and to say, I love you.
[00:06:49.720 --> 00:06:52.280]   That was like that.
[00:06:52.280 --> 00:06:54.640]   I just haven't never heard that before.
[00:06:54.640 --> 00:06:57.960]   And so it struck me as like, not just funny for what you're
[00:06:57.960 --> 00:07:02.440]   doing, but just like, whoa, we just took, because conversations
[00:07:02.440 --> 00:07:05.000]   are all about like this ranting, especially with Alex Jones,
[00:07:05.000 --> 00:07:08.240]   just like ranting about this or that, this part of the world.
[00:07:08.240 --> 00:07:09.400]   Like, can you believe this shit?
[00:07:09.400 --> 00:07:10.080]   That kind of thing.
[00:07:10.080 --> 00:07:12.840]   But like to pause and be like, this is awesome.
[00:07:12.840 --> 00:07:14.800]   I don't know if you felt that way, but.
[00:07:14.800 --> 00:07:16.160]   Oh, I definitely felt that way.
[00:07:16.160 --> 00:07:17.040]   So it was actually very fun.
[00:07:17.040 --> 00:07:18.760]   I'll give you the backstory of how that happened.
[00:07:18.760 --> 00:07:24.400]   It was, it was, it was silly because Tim calls me up and
[00:07:24.400 --> 00:07:27.080]   there's this expression in marketing, don't go past the sale.
[00:07:27.080 --> 00:07:27.400]   Right.
[00:07:27.400 --> 00:07:29.960]   So if you're trying to sell someone a car and you're like,
[00:07:29.960 --> 00:07:31.920]   it's got this feature, this feature, that feature.
[00:07:32.160 --> 00:07:33.040]   And they're like, you know what?
[00:07:33.040 --> 00:07:34.040]   I'm going to buy the car.
[00:07:34.040 --> 00:07:37.800]   If you keep talking, you can only make them lose the sale.
[00:07:37.800 --> 00:07:40.280]   You just get them to sign and get, get out of Dodge.
[00:07:40.280 --> 00:07:46.000]   So Tim calls me up and he goes, okay, uh, here's what we're thinking.
[00:07:46.000 --> 00:07:47.960]   This is top secret.
[00:07:47.960 --> 00:07:49.520]   Alex is going to be on the show.
[00:07:49.520 --> 00:07:51.080]   We want you on as well.
[00:07:51.080 --> 00:07:53.680]   And I've never said yes to anything as quickly in my life.
[00:07:53.680 --> 00:07:57.520]   Um, and then he keeps talking and I'm like, Tim, this, you
[00:07:57.520 --> 00:07:58.160]   don't have to sell it.
[00:07:58.160 --> 00:07:58.960]   I interrupted him.
[00:07:58.960 --> 00:07:59.960]   I go, you don't have to sell it.
[00:07:59.960 --> 00:08:00.960]   Why are you by the way?
[00:08:01.520 --> 00:08:08.800]   I think because, um, I am kind of an agent of chaos and Alex is in his own way, an
[00:08:08.800 --> 00:08:14.240]   agent of chaos and what is provides an opportunity in this kind of news media
[00:08:14.240 --> 00:08:15.640]   space that you and I travel in.
[00:08:15.640 --> 00:08:20.000]   It's the kind of things where none of us three, you know, as we said on the
[00:08:20.000 --> 00:08:21.880]   show, knew what it would be like.
[00:08:21.880 --> 00:08:27.080]   If you, you know, to certain within certain parameters, what, you know,
[00:08:27.080 --> 00:08:31.240]   Megan Kelly or Wolf Blitzer or any of these corporate figures are going to be
[00:08:31.240 --> 00:08:35.920]   like in a conversation to some extent, none of us had any idea that I knew they
[00:08:35.920 --> 00:08:37.800]   didn't know I was bringing knock knock jokes.
[00:08:37.800 --> 00:08:38.200]   Yeah.
[00:08:38.200 --> 00:08:42.440]   Um, so that was kind of what was so excited.
[00:08:42.440 --> 00:08:46.720]   I said at one point, I'm kind of envious of the audience because this is, there's
[00:08:46.720 --> 00:08:51.200]   so many exciting things that are happening and that the internet and podcasting
[00:08:51.200 --> 00:08:53.160]   provides people an opportunity to do that.
[00:08:53.160 --> 00:08:55.000]   It was great.
[00:08:55.000 --> 00:08:55.520]   Yeah.
[00:08:55.520 --> 00:08:58.280]   That, that was the greatest pairing.
[00:08:59.160 --> 00:09:01.920]   With Alex Jones that I've ever seen by far.
[00:09:01.920 --> 00:09:08.040]   So like, so I immediately knew now this isn't a knock on Tim, but I don't
[00:09:08.040 --> 00:09:09.840]   even know if Tim was prepared.
[00:09:09.840 --> 00:09:11.720]   Tim was not prepared for this.
[00:09:11.720 --> 00:09:12.800]   How could he be prepared?
[00:09:12.800 --> 00:09:16.360]   Well, so I mean, I don't know if Tim is used to that.
[00:09:16.360 --> 00:09:20.560]   I think Joe Rogan is more equipped, prepared for the chaos, just
[00:09:20.560 --> 00:09:21.840]   the years he's been in it.
[00:09:21.840 --> 00:09:26.440]   Like I immediately thought this is the right pairing for Joe Rogan.
[00:09:26.440 --> 00:09:30.880]   Cause Alex Jones has been on Joe Rogan a few times, three times.
[00:09:30.880 --> 00:09:33.440]   My favorite so far was with Tim Dillon.
[00:09:33.440 --> 00:09:33.600]   Right.
[00:09:33.600 --> 00:09:34.520]   For Jan, yeah.
[00:09:34.520 --> 00:09:43.040]   But Tim was clearly, uh, Tim Dillon was also kind of, uh, uh, a genius in his own
[00:09:43.040 --> 00:09:47.440]   right, but he was kind of a fan and he was back and he was stepping away.
[00:09:47.440 --> 00:09:56.240]   He was almost like in awe of Alex Jones where, uh, you were both, you were
[00:09:56.280 --> 00:10:00.760]   in awe of the experience that's being created and at the same time,
[00:10:00.760 --> 00:10:03.600]   fearlessly just trolling the situation.
[00:10:03.600 --> 00:10:07.480]   I mean, to do a knock knock joke to stop me, that just shows that
[00:10:07.480 --> 00:10:09.160]   you're in control of the experience.
[00:10:09.160 --> 00:10:10.960]   No, you're like riding the experience.
[00:10:10.960 --> 00:10:14.280]   That immediately was like, this needs to be on Rogan.
[00:10:14.280 --> 00:10:17.800]   So I hope that happens as well.
[00:10:17.800 --> 00:10:22.160]   You're on your own, of course, on Rogan, but just you, that's an experience.
[00:10:22.160 --> 00:10:24.600]   That's the, whatever, this gotta be a good name for it.
[00:10:24.600 --> 00:10:27.400]   Like Jimi Hendrix experience, there's no Michael and Alex.
[00:10:27.400 --> 00:10:29.480]   It's taken.
[00:10:29.480 --> 00:10:34.240]   Well, I don't know how many years you can, you can restart the experience.
[00:10:34.240 --> 00:10:36.680]   Because I feel, sorry to interrupt you.
[00:10:36.680 --> 00:10:44.800]   I feel a very big responsibility, especially in 2020 to provide fun and
[00:10:44.800 --> 00:10:50.200]   something cool and something unique that hasn't been done before for the audience.
[00:10:50.480 --> 00:10:55.120]   I think this has been a very rough year on our audiences psychologically
[00:10:55.120 --> 00:10:56.800]   and in other aspects of their lives.
[00:10:56.800 --> 00:11:02.560]   So I feel if I'm going to be there, I'm going to put on a show and it's also
[00:11:02.560 --> 00:11:05.480]   going to be great because it also alienates the people you don't want.
[00:11:05.480 --> 00:11:06.000]   Right.
[00:11:06.000 --> 00:11:08.680]   So there's a lot of people who sit there and be like, oh, he's telling
[00:11:08.680 --> 00:11:10.680]   knock people who are too cool for school.
[00:11:10.680 --> 00:11:13.480]   Uh, where they're like, oh, he's telling knock, knock jokes.
[00:11:13.480 --> 00:11:14.120]   This is stupid.
[00:11:14.120 --> 00:11:14.680]   I'm like, good.
[00:11:15.040 --> 00:11:22.480]   If you have an issue with having eaten cotton candy or doing a puzzle with a
[00:11:22.480 --> 00:11:27.040]   kid or with, without, you know, by yourself, that's on you and it's something
[00:11:27.040 --> 00:11:31.240]   very, something I think is the enemy of cynicism and this idea that like, oh,
[00:11:31.240 --> 00:11:33.280]   this is too silly and amethyst.
[00:11:33.280 --> 00:11:36.440]   Like we need that kind of childlike aspect in our lives.
[00:11:36.440 --> 00:11:37.920]   I think it's something we could use more of.
[00:11:37.920 --> 00:11:41.560]   It's very much an aspect of our media culture that to kind of have
[00:11:41.720 --> 00:11:45.880]   be condemnatory about that or to do it in a certain very corporate fake way.
[00:11:45.880 --> 00:11:50.000]   So it is something I encourage a lot, something I enjoy doing.
[00:11:50.000 --> 00:11:55.440]   Um, and again, I like with the first time I was on Tim, I had a propeller
[00:11:55.440 --> 00:11:59.360]   beanie on, you know, with the motorized and a lot of people were like, I can't
[00:11:59.360 --> 00:12:01.320]   take anyone seriously who dresses like this.
[00:12:01.320 --> 00:12:01.880]   I go good.
[00:12:01.880 --> 00:12:07.440]   If you judge someone's ideas by how they appear instead of the ideas themselves,
[00:12:07.440 --> 00:12:10.040]   you're not someone I want on my team.
[00:12:10.200 --> 00:12:14.600]   Are we going to address the outfit you're wearing?
[00:12:14.600 --> 00:12:15.680]   We can address it.
[00:12:15.680 --> 00:12:15.960]   Sure.
[00:12:15.960 --> 00:12:22.720]   You know, for those who are colorblind, Michael's wearing the, or just listening
[00:12:22.720 --> 00:12:29.520]   to this, Michael's wearing the exact opposite, the inverse from, uh, from
[00:12:29.520 --> 00:12:33.280]   another dimension outfit, which is a white suit and black shirt.
[00:12:33.280 --> 00:12:34.840]   Uh, so genius.
[00:12:34.840 --> 00:12:35.120]   Okay.
[00:12:35.120 --> 00:12:37.880]   So, uh, you just see the next two looks I've planned.
[00:12:37.880 --> 00:12:39.040]   Oh no.
[00:12:39.040 --> 00:12:39.240]   Yeah.
[00:12:39.240 --> 00:12:39.720]   They're great.
[00:12:40.720 --> 00:12:42.400]   Well, obviously this relationship is going to end today.
[00:12:42.400 --> 00:12:44.560]   So it's over.
[00:12:44.560 --> 00:12:47.560]   Okay.
[00:12:47.560 --> 00:12:52.360]   Is there some deep philosophy to the humor is, uh, this
[00:12:52.360 --> 00:12:53.960]   goes to our trolling discussion.
[00:12:53.960 --> 00:13:01.080]   Is there some, is there like chapters to this genius or is this just, uh,
[00:13:01.080 --> 00:13:02.880]   what makes you smile in the morning?
[00:13:02.880 --> 00:13:06.200]   Well, I mean, I think you're honestly, in this case, using
[00:13:06.200 --> 00:13:07.440]   the word genius a little loosely.
[00:13:07.520 --> 00:13:11.360]   I don't think this is particularly genius, but I do think it is fun.
[00:13:11.360 --> 00:13:13.040]   It is exuberant.
[00:13:13.040 --> 00:13:14.160]   It is joyous.
[00:13:14.160 --> 00:13:21.200]   Um, I think the, the bigger my audience has gotten, um, and the more I actually
[00:13:21.200 --> 00:13:27.400]   communicate with, you know, fans, I do feel it kind of kicks in these paternal,
[00:13:27.400 --> 00:13:28.320]   maternal instincts.
[00:13:28.320 --> 00:13:29.800]   It's, which is very, very odd.
[00:13:29.800 --> 00:13:30.760]   I did not expect to have them.
[00:13:30.760 --> 00:13:31.200]   What do you mean?
[00:13:31.200 --> 00:13:32.480]   Who's the dad?
[00:13:32.480 --> 00:13:33.680]   I'm the dad and the mom.
[00:13:33.680 --> 00:13:36.040]   I remember, and it may have been similar for you.
[00:13:36.040 --> 00:13:41.600]   I'm curious to hear it for young, smart, like, um, ambitious men, like 24 to 27
[00:13:41.600 --> 00:13:45.320]   for me was a very rough period because that's the window where a lot of people
[00:13:45.320 --> 00:13:47.000]   get married and they kind of check out.
[00:13:47.000 --> 00:13:52.120]   And if you're very much kind of finding your own road, um, you don't know what's
[00:13:52.120 --> 00:13:52.520]   happening.
[00:13:52.520 --> 00:13:55.040]   No, one's in a position to really guide you or help you.
[00:13:55.040 --> 00:13:56.440]   And it's, it's, it's tough.
[00:13:56.440 --> 00:13:57.840]   It's a very tough window.
[00:13:57.840 --> 00:14:04.680]   And what I'm finding now is having these kids who are in that position, but now
[00:14:04.680 --> 00:14:08.160]   instead of them stumbling along for some of them, I'm the one who could be like,
[00:14:08.160 --> 00:14:08.880]   no, no, no, no.
[00:14:08.880 --> 00:14:09.960]   It's not you.
[00:14:09.960 --> 00:14:11.080]   It's everybody else.
[00:14:11.080 --> 00:14:17.280]   And to be able to give them that semblance of feeling seen to use a
[00:14:17.280 --> 00:14:21.560]   cliched expression, to feel normal and that no, no, you're the, you're the,
[00:14:21.560 --> 00:14:22.800]   you're the heroes here.
[00:14:22.800 --> 00:14:24.400]   They're the background noise.
[00:14:24.400 --> 00:14:30.120]   Um, it's just really very, uh, flattering and humbling to be in that position.
[00:14:30.120 --> 00:14:31.560]   You have many minds, right?
[00:14:31.800 --> 00:14:33.840]   There's the thoughtful kind.
[00:14:33.840 --> 00:14:38.560]   Uh, Michael, there's like, I'm going to burn down the powerful.
[00:14:38.560 --> 00:14:38.960]   Yeah.
[00:14:38.960 --> 00:14:39.520]   Michael.
[00:14:39.520 --> 00:14:46.760]   And then there's like, I'm going to have this just lighthearted trolling of the
[00:14:46.760 --> 00:14:54.960]   world, which, and which of those are most important to the 24 to the 27 demographic.
[00:14:54.960 --> 00:14:56.960]   I think it's, it is the combination.
[00:14:57.280 --> 00:15:02.600]   You know, it's like if you're making a meal, you know, chicken Kiev, you need the
[00:15:02.600 --> 00:15:05.960]   chicken, you need the ham, you need the butter sauce.
[00:15:05.960 --> 00:15:12.400]   Um, because I think people, when you're young, you need to see someone who's
[00:15:12.400 --> 00:15:15.160]   fought the fight for you and who's won.
[00:15:15.160 --> 00:15:18.320]   So it's very easy to be defeatist.
[00:15:18.320 --> 00:15:20.480]   So this is what winning looks like.
[00:15:20.480 --> 00:15:26.240]   No, this is not, this is most assuredly what winning does not look like, but in
[00:15:26.240 --> 00:15:28.840]   my normal clothes, a little bit more.
[00:15:28.840 --> 00:15:32.960]   Uh, this is a good time to mention that clothes wise you're, you're wearing
[00:15:32.960 --> 00:15:38.400]   sheath underwear and people should buy sheath underwear, use code malice20.
[00:15:38.400 --> 00:15:41.520]   If you go to sheathunderwear.com use promo code malice20.
[00:15:41.520 --> 00:15:45.240]   What I love about the, why I'm glad to promote the product and wear it.
[00:15:45.240 --> 00:15:47.480]   It's the most comfortable underwear I've ever worn.
[00:15:47.480 --> 00:15:50.440]   And you have a separate pouch for both parts of your genitals.
[00:15:50.440 --> 00:15:53.960]   That's, that's what you, I thought there was like a punchline coming.
[00:15:53.960 --> 00:15:56.120]   No, it's a very nice aspect of the product.
[00:15:56.160 --> 00:15:56.480]   Yeah.
[00:15:56.480 --> 00:15:59.280]   But I think what, here's something else just as it goes back to, we're just
[00:15:59.280 --> 00:16:02.280]   talking about, there are so many, and this is going to segue into this.
[00:16:02.280 --> 00:16:06.800]   There are so many small companies who've been devastated this year.
[00:16:06.800 --> 00:16:10.680]   We have not seen a sustained attack on mom and pop shops.
[00:16:10.680 --> 00:16:16.520]   Uh, like we've seen in 2020 who are innovators and making something happen.
[00:16:16.520 --> 00:16:20.920]   And when you're just like one dude, who's producing a product,
[00:16:20.920 --> 00:16:22.720]   they're a sponsor of mine.
[00:16:22.720 --> 00:16:25.600]   I'm happy to, first of all, it's funny that I'm pitching underwear,
[00:16:25.600 --> 00:16:27.680]   but pitching, but it's also.
[00:16:27.680 --> 00:16:28.960]   Something I enjoy.
[00:16:28.960 --> 00:16:30.080]   She says small business.
[00:16:30.080 --> 00:16:30.520]   Yeah.
[00:16:30.520 --> 00:16:30.760]   Yeah.
[00:16:30.760 --> 00:16:32.440]   It's microscopic like a thimble.
[00:16:32.440 --> 00:16:35.720]   So this isn't a sponsor of mine, but this is a good segue.
[00:16:35.720 --> 00:16:37.320]   So this is Russians.
[00:16:37.320 --> 00:16:38.320]   We celebrate new years.
[00:16:38.320 --> 00:16:38.520]   Yeah.
[00:16:38.520 --> 00:16:38.960]   It's November.
[00:16:38.960 --> 00:16:42.760]   We have dead motor was, he comes down, puts a present under your pillow.
[00:16:42.760 --> 00:16:45.200]   So this is a company called JL Lawson.
[00:16:45.200 --> 00:16:46.560]   He's a fan of yours.
[00:16:46.560 --> 00:16:47.520]   He's a metal worker.
[00:16:47.520 --> 00:16:50.520]   And he said, can I give you something to give to Lex?
[00:16:50.520 --> 00:16:52.520]   I have one of his worry coins.
[00:16:52.520 --> 00:16:53.560]   I'll tell you what it is.
[00:16:53.560 --> 00:16:54.600]   He's not a sponsor.
[00:16:54.600 --> 00:16:56.120]   This is not, I'm not getting paid for this.
[00:16:56.120 --> 00:16:58.640]   So what a worry coin is, I carry around in my butt.
[00:16:58.640 --> 00:16:59.920]   If you have raw denim, it's great.
[00:16:59.920 --> 00:17:00.920]   Cause it brings you fades.
[00:17:00.920 --> 00:17:02.880]   So you carry it around with you all the time.
[00:17:02.880 --> 00:17:04.440]   It says worrying.
[00:17:04.440 --> 00:17:05.680]   It's like paying a debt.
[00:17:05.680 --> 00:17:06.520]   You don't owe.
[00:17:06.520 --> 00:17:07.920]   Right.
[00:17:07.920 --> 00:17:11.920]   And I carry this around and for now, it's been like a year.
[00:17:11.920 --> 00:17:13.920]   Next time you're worrying, and this is good advice.
[00:17:13.920 --> 00:17:17.720]   If you don't have a worry coin, go think about 10 years ago.
[00:17:17.720 --> 00:17:18.280]   Yes.
[00:17:18.280 --> 00:17:19.760]   And what you were worried about then.
[00:17:19.760 --> 00:17:22.600]   And then think about, did any of those things pan out?
[00:17:22.840 --> 00:17:25.200]   And some of them did, but you were able to handle it.
[00:17:25.200 --> 00:17:28.440]   And that's a good way to maintain perspective.
[00:17:28.440 --> 00:17:29.920]   So JL Lawson's the company.
[00:17:29.920 --> 00:17:31.280]   He sent me this present.
[00:17:31.280 --> 00:17:32.720]   I said, let me give it to Lex on air.
[00:17:32.720 --> 00:17:34.680]   So enjoy.
[00:17:34.680 --> 00:17:36.400]   So I also open it up.
[00:17:36.400 --> 00:17:36.720]   Yeah.
[00:17:36.720 --> 00:17:40.840]   JL Lawson and co to Lex from Anthony.
[00:17:40.840 --> 00:17:41.320]   Yeah.
[00:17:41.320 --> 00:17:43.400]   And I said, make something mathematical for Lex.
[00:17:43.400 --> 00:17:44.360]   I don't even know what's in there.
[00:17:44.360 --> 00:17:45.360]   You don't know what's in there.
[00:17:45.360 --> 00:17:45.640]   No.
[00:17:45.640 --> 00:17:47.240]   And it got through a TSA.
[00:17:47.240 --> 00:17:48.720]   Could be a bomb.
[00:17:48.720 --> 00:17:51.240]   It could be just like this episode.
[00:17:52.240 --> 00:17:54.680]   Make sure you unwrap it close to the mic because it drives you for crazy.
[00:17:54.680 --> 00:17:56.240]   That's really the best part.
[00:17:56.240 --> 00:18:02.240]   Or is this what unboxing video looks like?
[00:18:02.240 --> 00:18:07.240]   This conversation is going to be a big hit on the internet.
[00:18:07.240 --> 00:18:08.480]   With the unboxing community.
[00:18:08.480 --> 00:18:13.480]   I need to have an excited look on my face to make sure that the reaction
[00:18:13.480 --> 00:18:16.240]   video is be an unboxing and a reaction video.
[00:18:16.240 --> 00:18:17.440]   Lex screaming reacts.
[00:18:18.440 --> 00:18:19.760]   and a reaction video.
[00:18:19.760 --> 00:18:21.080]   - Like screaming react.
[00:18:21.080 --> 00:18:23.320]   It's another box.
[00:18:23.320 --> 00:18:25.560]   It's just a series of boxes.
[00:18:25.560 --> 00:18:30.240]   - Lex, big fan since hearing you on Rogan months ago.
[00:18:30.240 --> 00:18:32.360]   Most of your guests are over my head,
[00:18:32.360 --> 00:18:33.760]   but still enjoyable.
[00:18:33.760 --> 00:18:34.720]   - Aw.
[00:18:34.720 --> 00:18:37.760]   - Like this episode, Michael was kind enough
[00:18:37.760 --> 00:18:40.280]   to want to share my work with you.
[00:18:40.280 --> 00:18:41.620]   Keep doing what you do.
[00:18:41.620 --> 00:18:43.300]   Anthony Lawson.
[00:18:43.300 --> 00:18:45.320]   Thanks Anthony.
[00:18:45.320 --> 00:18:47.520]   - There's a lot in there.
[00:18:47.520 --> 00:18:48.340]   - What is in there?
[00:18:48.340 --> 00:18:49.180]   - I'll open some.
[00:18:49.180 --> 00:18:50.000]   - Okay.
[00:18:50.000 --> 00:18:50.840]   - All right.
[00:18:50.840 --> 00:18:52.640]   (speaking in foreign language)
[00:18:52.640 --> 00:18:53.720]   - Show it to the camera
[00:18:53.720 --> 00:18:56.680]   and then make sure you look excited or not or disappointed.
[00:18:56.680 --> 00:18:57.520]   - No, this is cool.
[00:18:57.520 --> 00:18:59.200]   This is a worry coin like I was showing you.
[00:18:59.200 --> 00:19:00.040]   - Oh, nice.
[00:19:00.040 --> 00:19:00.860]   - So you hold it in your hand
[00:19:00.860 --> 00:19:02.480]   and when you can do this with your thumb,
[00:19:02.480 --> 00:19:05.000]   if people have anxiety or whatever.
[00:19:05.000 --> 00:19:06.480]   - Oh, there's a lot of cool stuff in here.
[00:19:06.480 --> 00:19:08.080]   Fibonacci coin.
[00:19:08.080 --> 00:19:10.080]   - Oh, see, yeah, that's the math stuff.
[00:19:10.080 --> 00:19:11.640]   - That's really awesome.
[00:19:11.640 --> 00:19:13.120]   This is really cool.
[00:19:13.120 --> 00:19:15.080]   - Wait, you got a big one in there too.
[00:19:15.080 --> 00:19:17.520]   - That's what she said.
[00:19:18.460 --> 00:19:19.540]   (laughing)
[00:19:19.540 --> 00:19:20.620]   - I'm telling you,
[00:19:20.620 --> 00:19:23.700]   last time you offended me saying I don't have humor.
[00:19:23.700 --> 00:19:24.540]   - So I...
[00:19:24.540 --> 00:19:26.780]   (laughing)
[00:19:26.780 --> 00:19:33.260]   - The spin tray, micro brass and copper bronze.
[00:19:33.260 --> 00:19:35.300]   By the way, the packaging is epic.
[00:19:35.300 --> 00:19:37.380]   - I think that's his top.
[00:19:37.380 --> 00:19:38.600]   He makes tops.
[00:19:38.600 --> 00:19:41.420]   - Cool.
[00:19:41.420 --> 00:19:44.820]   - Yeah, you spin it in there.
[00:19:44.840 --> 00:19:47.680]   - It's the two different bronze and copper.
[00:19:47.680 --> 00:19:53.320]   - I think he's the only one who makes these machined tops.
[00:19:53.320 --> 00:19:55.280]   - And then he's sitting here, I guess.
[00:19:55.280 --> 00:19:58.160]   - Yeah, but you could spin him in that section.
[00:19:58.160 --> 00:19:59.000]   - Got it, cool.
[00:19:59.000 --> 00:20:02.760]   Where's the worry thing?
[00:20:02.760 --> 00:20:04.280]   - Here's the worry coin.
[00:20:04.280 --> 00:20:05.240]   - Anyway, I wasn't listening.
[00:20:05.240 --> 00:20:07.280]   What were you worried about 10 years ago?
[00:20:07.280 --> 00:20:09.720]   - 10 years ago, 2010.
[00:20:09.720 --> 00:20:11.280]   What would I have been worried about then?
[00:20:11.280 --> 00:20:12.360]   - The government?
[00:20:12.360 --> 00:20:13.920]   - No, that's not a worry.
[00:20:13.920 --> 00:20:17.060]   - What was the North Korea book?
[00:20:17.060 --> 00:20:19.820]   - That came out in 2014.
[00:20:19.820 --> 00:20:22.580]   I went there in 2012.
[00:20:22.580 --> 00:20:24.700]   Came out in January 2014.
[00:20:24.700 --> 00:20:28.220]   It still pays my rent with the royalties.
[00:20:28.220 --> 00:20:29.060]   - The North Korea book?
[00:20:29.060 --> 00:20:30.020]   - Yeah.
[00:20:30.020 --> 00:20:31.740]   This is why it's so much better.
[00:20:31.740 --> 00:20:34.300]   - I gotta talk to you about self-publishing
[00:20:34.300 --> 00:20:36.380]   'cause you brought that up.
[00:20:36.380 --> 00:20:39.260]   - I'm doing the next book's also gonna be self-published.
[00:20:39.260 --> 00:20:40.700]   - Can we talk about self-publishing?
[00:20:40.700 --> 00:20:45.160]   - What's the whole idea of publishing,
[00:20:45.160 --> 00:20:47.600]   like having a publisher and an agent?
[00:20:47.600 --> 00:20:48.600]   'Cause there's a bunch of people
[00:20:48.600 --> 00:20:49.880]   who've been reaching out to me
[00:20:49.880 --> 00:20:52.240]   trying to get me to write a book, which is ridiculous.
[00:20:52.240 --> 00:20:53.160]   - Why?
[00:20:53.160 --> 00:20:56.100]   - There's people who are brilliant folks like you,
[00:20:56.100 --> 00:20:59.320]   like Jordan Peterson, that I think have a lot of knowledge
[00:20:59.320 --> 00:21:00.860]   to share with the world.
[00:21:00.860 --> 00:21:04.520]   I think what I feel I can contribute to the world
[00:21:04.520 --> 00:21:08.440]   in terms of impact is to build something.
[00:21:10.140 --> 00:21:12.000]   Meaning like engineering stuff.
[00:21:12.000 --> 00:21:12.840]   - Okay.
[00:21:12.840 --> 00:21:13.680]   - Like a book.
[00:21:13.680 --> 00:21:14.760]   - A book has to be engineered,
[00:21:14.760 --> 00:21:16.320]   and I'm not using it loosely.
[00:21:16.320 --> 00:21:17.720]   You have to engineer a book.
[00:21:17.720 --> 00:21:18.560]   - No, for sure.
[00:21:18.560 --> 00:21:20.400]   What I mean is like literally a product
[00:21:20.400 --> 00:21:23.000]   with programming and artificial intelligence.
[00:21:23.000 --> 00:21:25.080]   I wanna build a company, I want to,
[00:21:25.080 --> 00:21:28.640]   'cause I have a few ideas that I feel I'm equipped.
[00:21:28.640 --> 00:21:31.680]   And it has to do with your intuition
[00:21:31.680 --> 00:21:35.320]   about the way you can build a better world, you individually.
[00:21:35.320 --> 00:21:38.480]   Like what can you add to the world that's a positive thing?
[00:21:38.480 --> 00:21:42.380]   And for me, I feel like the maximal thing
[00:21:42.380 --> 00:21:45.460]   I can add to the world is at least to attempt
[00:21:45.460 --> 00:21:49.420]   to build products that would add more love in the world.
[00:21:49.420 --> 00:21:50.860]   And like, so I wanna focus on that.
[00:21:50.860 --> 00:21:55.460]   The danger of the book for me, or any kind of writing,
[00:21:55.460 --> 00:21:57.980]   and even this podcast is a little bit dangerous for me,
[00:21:57.980 --> 00:21:59.420]   is like, it's fun.
[00:21:59.420 --> 00:22:00.260]   - That's for sure.
[00:22:00.260 --> 00:22:03.100]   (laughing)
[00:22:03.100 --> 00:22:03.920]   - It's fun.
[00:22:03.920 --> 00:22:05.500]   It's like it takes you into this place
[00:22:05.500 --> 00:22:06.980]   where you start thinking about the world,
[00:22:06.980 --> 00:22:08.980]   you start enjoying and playing with ideas,
[00:22:08.980 --> 00:22:12.700]   you start, and like just your book on,
[00:22:12.700 --> 00:22:16.420]   Hey Dear Reader, but also the new right,
[00:22:16.420 --> 00:22:19.900]   like clearly you and I probably think similarly
[00:22:19.900 --> 00:22:22.940]   in the sense that you did a lot of work.
[00:22:22.940 --> 00:22:25.580]   - Yes, this next book is killing me.
[00:22:25.580 --> 00:22:27.580]   - Yeah, as you mentioned often,
[00:22:27.580 --> 00:22:32.020]   it's clear like on your YouTube channel,
[00:22:32.020 --> 00:22:35.180]   which I'm a fan of, you often, it just comes out like,
[00:22:35.180 --> 00:22:37.580]   you mentioned all of these books that you're reading,
[00:22:37.580 --> 00:22:40.860]   it just comes through you, that you're suffering
[00:22:40.860 --> 00:22:43.580]   through this and it changes you.
[00:22:43.580 --> 00:22:47.580]   And it's clear that you're thinking deeply
[00:22:47.580 --> 00:22:48.980]   about the world because of this book.
[00:22:48.980 --> 00:22:51.720]   And I feel like if you do that, that's like,
[00:22:51.720 --> 00:22:54.820]   when I first came to this country,
[00:22:54.820 --> 00:22:57.500]   I read the book, The Giver, I need to read it again.
[00:22:57.500 --> 00:23:02.060]   It's like, the red pill thing, it changes you
[00:23:02.060 --> 00:23:04.820]   in where you can never be the same person again.
[00:23:04.820 --> 00:23:07.700]   And I feel about a book in that same way.
[00:23:07.700 --> 00:23:09.700]   The moment you write a book,
[00:23:09.700 --> 00:23:11.060]   of course it depends on the book.
[00:23:11.060 --> 00:23:14.540]   I could also just write like in my field,
[00:23:14.540 --> 00:23:15.940]   a very technical book.
[00:23:15.940 --> 00:23:17.940]   - No, that's a terrible idea.
[00:23:17.940 --> 00:23:20.540]   - Yes, but that's okay, that doesn't really change you.
[00:23:20.540 --> 00:23:22.460]   That's just like sharing information.
[00:23:22.460 --> 00:23:24.460]   But like something where you're like,
[00:23:24.460 --> 00:23:26.680]   how do I think about this world?
[00:23:26.680 --> 00:23:28.700]   Can you just leave that behind you?
[00:23:28.700 --> 00:23:31.060]   - I get it, dude, it's being pregnant.
[00:23:31.060 --> 00:23:33.140]   It never escapes your brain, I'm telling you.
[00:23:33.140 --> 00:23:34.180]   You're absolutely right.
[00:23:34.180 --> 00:23:35.020]   - Yeah, I don't know.
[00:23:35.020 --> 00:23:36.740]   It does seem to change you.
[00:23:36.740 --> 00:23:37.860]   But the reason I bring that up
[00:23:37.860 --> 00:23:41.380]   is 'cause there's this whole industry of people
[00:23:41.380 --> 00:23:44.460]   that seem to not really contribute much
[00:23:44.460 --> 00:23:46.300]   to the publication process,
[00:23:46.300 --> 00:23:49.140]   but they make themselves seem necessary
[00:23:49.140 --> 00:23:51.620]   for like if you wanna be in the New York Times
[00:23:51.620 --> 00:23:53.380]   bestseller list kind of thing.
[00:23:53.380 --> 00:23:57.220]   But also just being like reputable,
[00:23:57.220 --> 00:23:59.500]   which I'm allergic to that whole concept.
[00:23:59.500 --> 00:24:02.060]   But do you think it's possible to be
[00:24:02.060 --> 00:24:04.140]   on the New York Times bestseller list
[00:24:04.140 --> 00:24:09.140]   and be a reputable author and still be self-published?
[00:24:09.140 --> 00:24:11.060]   - Not what you would wanna do.
[00:24:11.060 --> 00:24:12.820]   Like people like Mark Sisson, I think is his name.
[00:24:12.820 --> 00:24:14.060]   He wrote like "The Primal Blueprint."
[00:24:14.060 --> 00:24:16.500]   So like if I'm getting the names correct,
[00:24:16.500 --> 00:24:18.100]   he's the first paleo guy, right?
[00:24:18.100 --> 00:24:21.780]   So he self-published it, it sold gangbusters,
[00:24:21.780 --> 00:24:23.620]   but that would be on their health chart, I believe.
[00:24:23.620 --> 00:24:27.460]   And it's a little bit of a different situation.
[00:24:27.460 --> 00:24:30.660]   You would be reaching much more for the mainstream.
[00:24:30.660 --> 00:24:34.380]   You'd be giving up a lot if you go through a publisher,
[00:24:34.380 --> 00:24:35.940]   especially financially.
[00:24:35.940 --> 00:24:38.740]   But yeah, you are not going to have the cred
[00:24:38.740 --> 00:24:41.820]   because the publishing is a cartel.
[00:24:41.820 --> 00:24:43.980]   The New York Times is part of this cartel.
[00:24:43.980 --> 00:24:47.940]   And if you don't publish within this cartel,
[00:24:47.940 --> 00:24:51.820]   they will do what they can, as any cartel has to,
[00:24:51.820 --> 00:24:55.680]   by necessity of being cartel, to pretend you don't exist.
[00:24:55.680 --> 00:24:58.420]   So they will, I was, I think, the first one
[00:24:58.420 --> 00:25:01.060]   to have an hour on Book TV for Dear Reader,
[00:25:01.060 --> 00:25:03.460]   'cause that was a Kickstarter book.
[00:25:03.460 --> 00:25:05.460]   But this is something that people--
[00:25:05.460 --> 00:25:06.780]   - Dear Reader was a Kickstarter book.
[00:25:06.780 --> 00:25:08.340]   - Yeah.
[00:25:08.340 --> 00:25:12.220]   This is something people would have to be aware of.
[00:25:12.220 --> 00:25:14.380]   So you would be giving up a lot,
[00:25:14.380 --> 00:25:17.500]   but you'd also be giving a lot to work with a publisher
[00:25:17.500 --> 00:25:19.980]   'cause you're losing like a year and a half of your life
[00:25:19.980 --> 00:25:21.940]   because they're glacial and they don't care.
[00:25:21.940 --> 00:25:23.900]   - Well, that's my problem, it's not the money.
[00:25:23.900 --> 00:25:25.900]   I mean, the money is whatever percent they take,
[00:25:25.900 --> 00:25:27.900]   10, 20, 30, 50%--
[00:25:27.900 --> 00:25:29.820]   - They're taking a huge chunk.
[00:25:29.820 --> 00:25:33.740]   So if I sell a book through St. Martin's, it's a dollar.
[00:25:33.740 --> 00:25:36.140]   If I sell a book through Amazon, which is Dear Reader,
[00:25:36.140 --> 00:25:37.380]   that's $6.
[00:25:37.380 --> 00:25:40.020]   So that's what, 87%, it's something crazy.
[00:25:40.020 --> 00:25:43.580]   - But for me, what bothers me isn't the money,
[00:25:43.580 --> 00:25:47.940]   for me personally, for me, what bothers me is incompetence.
[00:25:47.940 --> 00:25:50.260]   Like whenever I go to the DMV or something like that--
[00:25:50.260 --> 00:25:51.100]   - Can I interrupt you?
[00:25:51.100 --> 00:25:51.920]   - Yeah.
[00:25:51.920 --> 00:25:52.760]   - Let's talk incompetence.
[00:25:52.760 --> 00:25:54.020]   - Yeah.
[00:25:54.020 --> 00:25:55.700]   - New Right comes out last year.
[00:25:55.700 --> 00:25:56.540]   - Yes.
[00:25:56.540 --> 00:25:59.220]   - I get on Rogan, get on Rubin,
[00:25:59.220 --> 00:26:04.500]   I call them and I said, "I got on these shows,
[00:26:04.500 --> 00:26:06.720]   "is there money in the budget for travel?"
[00:26:06.720 --> 00:26:10.900]   And they say, "We don't have that budget."
[00:26:10.900 --> 00:26:11.740]   Fine.
[00:26:11.740 --> 00:26:14.780]   - By the way, you got on those shows with no help from them.
[00:26:14.780 --> 00:26:17.060]   - Correct, oh yeah, that's not even a question.
[00:26:17.060 --> 00:26:18.580]   The reason they would want you to do a book
[00:26:18.580 --> 00:26:19.860]   is 'cause they know you could get,
[00:26:19.860 --> 00:26:23.380]   the only reason people get book deals nowadays, literally,
[00:26:23.380 --> 00:26:25.460]   is 'cause they know that person can market their own book.
[00:26:25.460 --> 00:26:27.100]   That's the only way.
[00:26:27.100 --> 00:26:29.420]   And I got on Rubin, I got on Rogan,
[00:26:29.420 --> 00:26:31.380]   and they go, "We don't have the money for travel,"
[00:26:31.380 --> 00:26:33.420]   which is fair, "they can do Skype."
[00:26:33.420 --> 00:26:36.420]   They told me this in writing.
[00:26:36.420 --> 00:26:37.980]   And I'm like, "Okay."
[00:26:37.980 --> 00:26:40.260]   - They can financially cover Skype?
[00:26:40.260 --> 00:26:41.220]   (laughs)
[00:26:41.220 --> 00:26:43.740]   - No, but it's like, "Hey, Joe, yeah,
[00:26:43.740 --> 00:26:45.500]   "we don't have the budget, but you're gonna do Skype,
[00:26:45.500 --> 00:26:46.980]   "hello, hello?"
[00:26:46.980 --> 00:26:48.060]   (laughs)
[00:26:48.060 --> 00:26:51.860]   So there is, another friend of mine
[00:26:51.860 --> 00:26:55.580]   was on a show on CNBC with Nassim Taleb.
[00:26:55.580 --> 00:26:59.660]   And they said, "Nassim wants a copy of the book."
[00:26:59.660 --> 00:27:03.620]   And they're like, "Oh yeah, it's like four o'clock on Friday,
[00:27:03.620 --> 00:27:05.740]   "so we're closed, so."
[00:27:05.740 --> 00:27:08.740]   And he's like, he went there, picked it up,
[00:27:08.740 --> 00:27:10.740]   and walked it the two blocks.
[00:27:10.740 --> 00:27:14.420]   So there is, it's almost cartoonish.
[00:27:14.420 --> 00:27:20.060]   And it's not incompetence, it's past that.
[00:27:20.060 --> 00:27:23.740]   It's something almost, you can't really believe it.
[00:27:23.740 --> 00:27:25.260]   I've had two friends who have been
[00:27:25.260 --> 00:27:26.860]   literally rendered suicidal
[00:27:26.860 --> 00:27:30.780]   because this was such a huge opportunity for them.
[00:27:30.780 --> 00:27:32.380]   And it was like watching their kid
[00:27:32.380 --> 00:27:33.660]   get beaten in front of them.
[00:27:33.660 --> 00:27:35.020]   And I had to talk them off the ledge.
[00:27:35.020 --> 00:27:38.420]   So it's, people do not appreciate how bad,
[00:27:38.420 --> 00:27:39.340]   here's another example.
[00:27:39.340 --> 00:27:42.020]   - The apathy of bureaucracy, something like that.
[00:27:42.020 --> 00:27:44.460]   - I did this book, "Concierge Confidential."
[00:27:44.460 --> 00:27:46.180]   There's a typo in the first chapter,
[00:27:46.180 --> 00:27:49.620]   it ends with, "I'm about to, T-O-O."
[00:27:49.620 --> 00:27:52.260]   They didn't fix it for the paperback.
[00:27:52.260 --> 00:27:53.100]   Who cared?
[00:27:53.100 --> 00:27:54.300]   It's just like, well, okay.
[00:27:54.300 --> 00:27:56.740]   Yeah, great book, by the way.
[00:27:56.740 --> 00:27:59.340]   It got NPR, gave it one of the books of the year.
[00:27:59.340 --> 00:28:00.660]   So that was cool.
[00:28:00.660 --> 00:28:03.300]   - So why participate in this?
[00:28:03.300 --> 00:28:04.860]   - Because otherwise, New York Times
[00:28:04.860 --> 00:28:07.300]   is gonna pretend you don't exist.
[00:28:07.300 --> 00:28:10.740]   Getting booked on some shows might be more difficult,
[00:28:10.740 --> 00:28:13.340]   although I think that's collapsing in real time.
[00:28:13.340 --> 00:28:17.940]   You're not gonna get reviewed necessarily
[00:28:17.940 --> 00:28:21.260]   on places like PW or some others.
[00:28:21.260 --> 00:28:23.820]   - So the new book you're working on,
[00:28:23.820 --> 00:28:24.660]   do you have a title yet or no?
[00:28:24.660 --> 00:28:25.500]   - "The White Pill."
[00:28:25.500 --> 00:28:26.320]   - "The White Pill."
[00:28:26.320 --> 00:28:29.700]   Are you self-publishing that?
[00:28:29.700 --> 00:28:31.060]   - Oh yeah, for sure.
[00:28:31.060 --> 00:28:32.980]   - And what's the thinking behind that?
[00:28:32.980 --> 00:28:35.100]   Just because you already have a huge following
[00:28:35.100 --> 00:28:36.780]   and a big platform and--
[00:28:36.780 --> 00:28:38.220]   - It's six times the cash.
[00:28:38.220 --> 00:28:41.620]   If I finish the book in December,
[00:28:41.620 --> 00:28:43.620]   I could have it out in February.
[00:28:43.620 --> 00:28:45.740]   If I finish the book in December with a publisher,
[00:28:45.740 --> 00:28:50.220]   it's gonna be out in December at the earliest, 2021.
[00:28:50.220 --> 00:28:52.500]   Why am I giving up 10 months of my life?
[00:28:52.500 --> 00:28:53.340]   - Well, this is the big one.
[00:28:53.340 --> 00:28:55.260]   Do you have any leverage?
[00:28:55.260 --> 00:28:58.700]   Do authors have leverage to say, "F you"?
[00:28:58.700 --> 00:29:00.820]   Can you just say, "Can you?"
[00:29:00.820 --> 00:29:01.740]   - What do you mean?
[00:29:01.740 --> 00:29:06.420]   - Meaning like, "I wanna release this book in two months."
[00:29:06.420 --> 00:29:07.300]   - Oh, no, no.
[00:29:07.300 --> 00:29:08.540]   I mean, you'll have a contract
[00:29:08.540 --> 00:29:09.660]   and then your agent can fight it,
[00:29:09.660 --> 00:29:13.140]   but they don't have the capacity to rush things through.
[00:29:14.580 --> 00:29:18.380]   - Yeah, I guess if the, 'cause I've heard big authors,
[00:29:18.380 --> 00:29:20.260]   I don't know, Sam Harris, all those folks,
[00:29:20.260 --> 00:29:23.640]   talk about like, they've accepted it, actually.
[00:29:23.640 --> 00:29:24.660]   They've accepted, they're like,
[00:29:24.660 --> 00:29:26.060]   "Yeah, it takes a long time to--"
[00:29:26.060 --> 00:29:27.220]   - I'm not accepting it.
[00:29:27.220 --> 00:29:30.180]   - But you're kind of implying
[00:29:30.180 --> 00:29:32.860]   that a human being like me should.
[00:29:32.860 --> 00:29:36.140]   - I'm saying these are your options.
[00:29:36.140 --> 00:29:36.980]   - Right.
[00:29:36.980 --> 00:29:37.980]   - So--
[00:29:37.980 --> 00:29:38.820]   - I just hate it.
[00:29:38.820 --> 00:29:41.660]   I hate the waiting because it's incompetence.
[00:29:41.660 --> 00:29:44.580]   It's not necessarily the wait.
[00:29:44.580 --> 00:29:47.340]   If I knew it wasn't, you know,
[00:29:47.340 --> 00:29:51.540]   if it was the kind of people that are up at 2 a.m. at night
[00:29:51.540 --> 00:29:54.540]   on a Friday and they love what you're doing
[00:29:54.540 --> 00:29:56.860]   and they're helping create something special,
[00:29:56.860 --> 00:29:59.060]   that's the sense I get with some of the Netflix folks,
[00:29:59.060 --> 00:30:01.860]   for example, that work with people.
[00:30:01.860 --> 00:30:03.420]   I just, I don't know anything about this world,
[00:30:03.420 --> 00:30:08.380]   but you get like Netflix folks who help with shows.
[00:30:08.380 --> 00:30:10.940]   You could tell that they're obsessed with those shows.
[00:30:10.940 --> 00:30:12.980]   - Yeah, you're not gonna get that publishing.
[00:30:12.980 --> 00:30:14.940]   If you hand, like I handed the book in,
[00:30:14.940 --> 00:30:16.140]   I think it was July.
[00:30:16.140 --> 00:30:20.220]   I didn't hear anything from my editor until December.
[00:30:20.220 --> 00:30:24.500]   - Well, can we actually talk about the suffering?
[00:30:24.500 --> 00:30:25.340]   - Sure.
[00:30:25.340 --> 00:30:27.620]   - The darkest parts of writing a book.
[00:30:27.620 --> 00:30:32.020]   So let's go to the full Michael Malice, Stephen King mode
[00:30:32.020 --> 00:30:35.420]   of what are the darkest moments of writing this book?
[00:30:35.420 --> 00:30:38.240]   And what is it, maybe start with the white pill.
[00:30:38.240 --> 00:30:40.580]   What's the idea, what's the hope,
[00:30:40.580 --> 00:30:43.100]   and what are your darkest moments around writing this book?
[00:30:43.100 --> 00:30:46.700]   - So people are familiar with the red pill and the blue pill,
[00:30:46.700 --> 00:30:48.580]   the red, therefore the matrix.
[00:30:48.580 --> 00:30:52.500]   The red pill is the idea that what is presented as fact
[00:30:52.500 --> 00:30:54.780]   by the corporate press entertainment industry
[00:30:54.780 --> 00:30:56.540]   is in fact a carefully constructed narrative
[00:30:56.540 --> 00:30:58.860]   designed to keep some very unpleasant people in power
[00:30:58.860 --> 00:31:01.220]   and everyone else under control.
[00:31:01.220 --> 00:31:04.300]   And I guess one of my expressions is you take one red pill,
[00:31:04.300 --> 00:31:05.860]   not the whole bottle.
[00:31:05.860 --> 00:31:07.780]   Because at a certain point you think everything's a lie
[00:31:07.780 --> 00:31:11.580]   and you're kind of no capacity for distinguishing truths.
[00:31:11.580 --> 00:31:13.180]   - You're full of good one-liners.
[00:31:13.180 --> 00:31:14.340]   - Well, thank you.
[00:31:14.340 --> 00:31:16.500]   I'm full of something, that's for sure.
[00:31:16.500 --> 00:31:20.460]   And what I saw in this space
[00:31:20.460 --> 00:31:22.700]   is a lot of these red-pilled people
[00:31:22.700 --> 00:31:27.060]   got very disheartened and cynical.
[00:31:27.060 --> 00:31:29.860]   And one of my big heroes is Albert Camus,
[00:31:29.860 --> 00:31:32.980]   and he said the worst thing is cynicism.
[00:31:32.980 --> 00:31:35.500]   And that's something called the black pill,
[00:31:35.500 --> 00:31:39.420]   which is the idea that it's just,
[00:31:39.420 --> 00:31:42.580]   we're waiting for the end, it's hopeless.
[00:31:42.580 --> 00:31:46.820]   And I don't see it that way at all.
[00:31:46.820 --> 00:31:50.980]   And I'm like, all right, I have to address this
[00:31:50.980 --> 00:31:53.300]   and not just with some kind of cheerleading,
[00:31:53.300 --> 00:31:54.860]   everything's gonna be great, guys.
[00:31:54.860 --> 00:31:58.820]   Here is why I am positive.
[00:31:58.820 --> 00:32:02.140]   And not that I'm positive the good guys are gonna win,
[00:32:02.140 --> 00:32:05.340]   but I'm positive the good guys can win.
[00:32:05.340 --> 00:32:06.660]   And that's all you need,
[00:32:06.660 --> 00:32:10.960]   because if your, God forbid, kid is kidnapped,
[00:32:10.960 --> 00:32:14.340]   and there's a 10% chance that you can save them,
[00:32:14.340 --> 00:32:17.900]   you're not gonna be like, well, I don't like those odds.
[00:32:17.900 --> 00:32:20.380]   This is your country, this is your values,
[00:32:20.380 --> 00:32:22.340]   this is your family.
[00:32:22.340 --> 00:32:24.340]   I don't think it's much more than 10%.
[00:32:24.340 --> 00:32:28.220]   And even if you lose, you will take pride
[00:32:28.220 --> 00:32:31.940]   in that you did everything in your power to win.
[00:32:31.940 --> 00:32:34.020]   - Is there a good definition of good guys
[00:32:35.040 --> 00:32:37.340]   in the sense that-- - The ones who wear white.
[00:32:37.340 --> 00:32:39.940]   - There's layers to this.
[00:32:39.940 --> 00:32:41.880]   You're like modern day Shakespeare.
[00:32:41.880 --> 00:32:48.300]   Is there a danger in thinking Adolf Hitler
[00:32:48.300 --> 00:32:52.020]   was probably pretty confident
[00:32:52.020 --> 00:32:54.380]   that he led a group of good guys?
[00:32:54.380 --> 00:32:57.220]   - Listen, if Hitler did anything wrong, why isn't he in jail?
[00:32:57.220 --> 00:33:02.540]   My Czech friend thought of that joke.
[00:33:02.540 --> 00:33:04.260]   Actually, he says it in his accent, he goes,
[00:33:04.260 --> 00:33:06.540]   if Hitler's so bad, why isn't he in the jail?
[00:33:06.540 --> 00:33:09.720]   - That's a good point.
[00:33:09.720 --> 00:33:11.140]   He's probably still alive, right?
[00:33:11.140 --> 00:33:13.620]   - And look, yeah, hopefully.
[00:33:13.620 --> 00:33:18.200]   - Oh boy, two of the three people listening to this
[00:33:18.200 --> 00:33:19.500]   are very upset right now.
[00:33:19.500 --> 00:33:22.860]   What were you even talking about?
[00:33:22.860 --> 00:33:26.020]   Oh, how do you know what is good?
[00:33:26.020 --> 00:33:27.660]   - There's lots of standards of good.
[00:33:27.660 --> 00:33:31.640]   But if you're, for me, to be a good guy is
[00:33:31.640 --> 00:33:33.680]   if you want to leave the world
[00:33:33.680 --> 00:33:35.680]   a little bit better than you found it.
[00:33:35.680 --> 00:33:38.320]   That, to me, is the definition of a good guy.
[00:33:38.320 --> 00:33:41.040]   And I think there are many people
[00:33:41.040 --> 00:33:43.720]   that that's not their motivation at all.
[00:33:43.720 --> 00:33:45.320]   - It's about your motivation.
[00:33:45.320 --> 00:33:47.060]   - Well, it's also about if your motivation
[00:33:47.060 --> 00:33:49.920]   is at all correlated to reality.
[00:33:49.920 --> 00:33:53.360]   No one thinks we're the bad guys, that's correct.
[00:33:53.360 --> 00:33:57.680]   But are you taking steps to check your motivations
[00:33:57.680 --> 00:34:00.680]   and also take a certain amount of humility?
[00:34:00.680 --> 00:34:01.960]   Because if you're going to start
[00:34:01.960 --> 00:34:03.600]   interfering with other people's lives,
[00:34:03.600 --> 00:34:06.440]   you really better be sure you know
[00:34:06.440 --> 00:34:08.480]   what you're talking about.
[00:34:08.480 --> 00:34:10.600]   - The control of others,
[00:34:10.600 --> 00:34:12.480]   if you do have centralized control
[00:34:12.480 --> 00:34:16.840]   or then you kind of, you become a leader of a group,
[00:34:16.840 --> 00:34:21.520]   you better know, you better do so humbly and cautiously.
[00:34:21.520 --> 00:34:25.080]   - And also have steam valves, right?
[00:34:25.080 --> 00:34:28.440]   So in case things go wrong, let's have,
[00:34:28.440 --> 00:34:29.960]   I'm sure this is a lot happening with AI,
[00:34:29.960 --> 00:34:31.480]   or whatever, or computers.
[00:34:31.480 --> 00:34:33.040]   Like, okay, if something goes wrong here,
[00:34:33.040 --> 00:34:35.320]   how do we have a workaround
[00:34:35.320 --> 00:34:37.480]   to make sure it doesn't cause everything to collapse?
[00:34:37.480 --> 00:34:39.200]   - Yeah, the going wrong thing,
[00:34:39.200 --> 00:34:42.240]   I mean, the whole, the feedback mechanism.
[00:34:42.240 --> 00:34:46.240]   Like, I wonder if people in Congress
[00:34:46.240 --> 00:34:50.040]   think that things are really wrong.
[00:34:50.040 --> 00:34:51.480]   - It's working for them.
[00:34:51.480 --> 00:34:53.320]   - Are you sure?
[00:34:53.320 --> 00:34:54.520]   Because-- - No, I'm not sure.
[00:34:54.520 --> 00:34:59.280]   - Because I'd like to believe that the people
[00:34:59.280 --> 00:35:02.680]   that at least when they got into politics
[00:35:02.680 --> 00:35:04.480]   actually wanted, some of it is ego,
[00:35:04.480 --> 00:35:08.560]   but some of it is wanting to be the kind of person
[00:35:08.560 --> 00:35:09.880]   that builds a better world.
[00:35:09.880 --> 00:35:12.440]   - Sure, I also think it's diverse.
[00:35:12.440 --> 00:35:15.520]   Some are gonna have different motivations than others.
[00:35:15.520 --> 00:35:18.240]   - But once you're in the system
[00:35:18.240 --> 00:35:20.280]   and trying to build a better world,
[00:35:20.280 --> 00:35:22.640]   how do you know that it's not working?
[00:35:22.640 --> 00:35:26.360]   How do you take the basic feedback mechanisms
[00:35:28.280 --> 00:35:30.680]   and actually productively change?
[00:35:30.680 --> 00:35:32.120]   I mean, that's what it means to be a good guy,
[00:35:32.120 --> 00:35:34.280]   is like, hmm, something is wrong here.
[00:35:34.280 --> 00:35:36.160]   And that's why I like the Elon Musk,
[00:35:36.160 --> 00:35:38.120]   think from first principles.
[00:35:38.120 --> 00:35:39.920]   Like, wait, wait, wait, okay.
[00:35:39.920 --> 00:35:41.960]   Let's ask the big question.
[00:35:41.960 --> 00:35:45.120]   Can this be, one, is this working at all?
[00:35:45.120 --> 00:35:47.400]   Like, the way we're solving this particular problem
[00:35:47.400 --> 00:35:50.080]   of government, is this working at all?
[00:35:50.080 --> 00:35:52.720]   And then stepping away and saying,
[00:35:52.720 --> 00:35:55.800]   as opposed to modifying this bill or that bill
[00:35:55.800 --> 00:35:59.120]   or this little strategy, like increase the tax by this much
[00:35:59.120 --> 00:36:00.840]   or decrease the tax by this much,
[00:36:00.840 --> 00:36:05.840]   why do we have a democracy at all?
[00:36:05.840 --> 00:36:10.840]   Or why do we have any kind of representative democracy?
[00:36:10.840 --> 00:36:13.040]   Shouldn't it be a pure democracy?
[00:36:13.040 --> 00:36:16.520]   Or why do we have states,
[00:36:16.520 --> 00:36:19.800]   like representation of states and federal government
[00:36:19.800 --> 00:36:20.640]   and so on?
[00:36:20.640 --> 00:36:23.040]   Why do we have this kind of separation of powers?
[00:36:23.040 --> 00:36:23.880]   Is this different?
[00:36:23.920 --> 00:36:26.200]   Why do we have term limits or not?
[00:36:26.200 --> 00:36:28.440]   Like big things.
[00:36:28.440 --> 00:36:31.280]   Like, how do you actually make that happen?
[00:36:31.280 --> 00:36:33.480]   And is that what it means to be a good guy?
[00:36:33.480 --> 00:36:38.200]   It's like taking big revolutionary steps
[00:36:38.200 --> 00:36:39.800]   as opposed to incremental steps.
[00:36:39.800 --> 00:36:41.400]   - Well, I don't know that you could be a politician
[00:36:41.400 --> 00:36:42.840]   to be a good guy, to be honest.
[00:36:42.840 --> 00:36:44.280]   And let me give you a counterexample,
[00:36:44.280 --> 00:36:47.080]   someone who you could tell is not being a good guy.
[00:36:47.080 --> 00:36:48.400]   Joe Biden said he was,
[00:36:48.400 --> 00:36:50.720]   he regards the Iraq war as a mistake, okay?
[00:36:50.720 --> 00:36:52.960]   You and I have made mistakes in our lives, I'm sure.
[00:36:52.960 --> 00:36:54.200]   None of our mistakes have caused
[00:36:54.200 --> 00:36:56.720]   tens of thousands of people to die.
[00:36:56.720 --> 00:36:58.520]   If, let's suppose I'm, for yourself.
[00:36:58.520 --> 00:37:00.920]   That's fair, okay, I'll take that.
[00:37:00.920 --> 00:37:02.560]   I don't build the kill bots.
[00:37:02.560 --> 00:37:08.120]   If I were a chef, let's take it out of politics,
[00:37:08.120 --> 00:37:10.960]   and in my restaurant, somehow, accidentally,
[00:37:10.960 --> 00:37:12.840]   someone ate something and they died.
[00:37:12.840 --> 00:37:15.560]   A, I would feel horrible.
[00:37:15.560 --> 00:37:18.240]   But more importantly, I would be like,
[00:37:18.240 --> 00:37:20.600]   we need to look through this system
[00:37:20.600 --> 00:37:22.640]   and figure out how it got to the point
[00:37:22.640 --> 00:37:24.160]   where someone lost their life,
[00:37:24.160 --> 00:37:26.200]   because that can never happen again.
[00:37:26.200 --> 00:37:28.960]   And we need to figure out step by step.
[00:37:28.960 --> 00:37:33.160]   I'm not a gun person, but there's this checklist
[00:37:33.160 --> 00:37:35.560]   of if you're holding a gun, there's five things to do.
[00:37:35.560 --> 00:37:37.360]   And if you get too wrong, you're gonna be,
[00:37:37.360 --> 00:37:39.280]   it's like, assume every gun is loaded,
[00:37:39.280 --> 00:37:42.440]   only point it at something that you wanna kill,
[00:37:42.440 --> 00:37:43.840]   and there's three other things.
[00:37:43.840 --> 00:37:48.000]   And it's to make sure that nothing goes wrong.
[00:37:48.000 --> 00:37:51.600]   So if I made, if I'm that chef,
[00:37:51.600 --> 00:37:54.080]   and I would have to not only feel guilt,
[00:37:54.080 --> 00:37:56.680]   but take preventative action to make sure,
[00:37:56.680 --> 00:38:00.520]   this has no possibility of happening again.
[00:38:00.520 --> 00:38:03.060]   If you look at the staff he's putting in,
[00:38:03.060 --> 00:38:06.240]   it's the same warmongers that would have advised him
[00:38:06.240 --> 00:38:09.680]   to get into the Iraq War on the first time.
[00:38:09.680 --> 00:38:12.400]   That is, to me, is not a good guy.
[00:38:12.400 --> 00:38:15.040]   That, to me, is someone who does not feel remorse
[00:38:15.040 --> 00:38:18.540]   for their responsibility in killing not only many Americans,
[00:38:18.540 --> 00:38:21.160]   but some of us think that dead Iraqis
[00:38:21.160 --> 00:38:22.760]   isn't necessarily ideal either.
[00:38:22.760 --> 00:38:27.040]   - Okay, let's talk a bit about war.
[00:38:27.040 --> 00:38:29.560]   Maybe you can also correct me on something.
[00:38:29.560 --> 00:38:34.560]   The first time I found myself into Barack Obama
[00:38:34.560 --> 00:38:37.860]   was, I don't know how many years ago this was,
[00:38:37.860 --> 00:38:42.200]   but when I maybe heard a speech of his
[00:38:42.200 --> 00:38:44.960]   about him speaking out against the war.
[00:38:44.960 --> 00:38:45.800]   - Yeah.
[00:38:45.800 --> 00:38:48.960]   - And him, I think it's on record
[00:38:48.960 --> 00:38:51.040]   saying he was against the war,
[00:38:51.040 --> 00:38:52.640]   before it was happening.
[00:38:52.640 --> 00:38:54.240]   - But he wasn't in Senate at the time,
[00:38:54.240 --> 00:38:55.600]   so it was very easy for him to say this.
[00:38:55.600 --> 00:38:57.520]   - But see, people say that.
[00:38:57.520 --> 00:38:58.720]   People say that.
[00:38:58.720 --> 00:39:00.720]   People say it was easy,
[00:39:00.720 --> 00:39:04.800]   and some people say it's strategically the wise thing to do,
[00:39:04.800 --> 00:39:07.200]   given some kind of calculus, whatever.
[00:39:07.200 --> 00:39:10.100]   But I, to this day, give him,
[00:39:10.100 --> 00:39:12.800]   that's the reason I've always given him props,
[00:39:12.800 --> 00:39:15.600]   in my mind, this is a man of character.
[00:39:15.600 --> 00:39:19.840]   I also personally really value great speeches.
[00:39:19.840 --> 00:39:22.320]   I think speeches are really important for leaders,
[00:39:22.320 --> 00:39:23.520]   'cause they inspire the world.
[00:39:23.520 --> 00:39:25.240]   It's like, one of the most,
[00:39:25.240 --> 00:39:27.840]   best things you can contribute to the world is great,
[00:39:27.840 --> 00:39:31.180]   like, through intellect,
[00:39:31.180 --> 00:39:33.480]   mold ideas in a way that's communicable
[00:39:33.480 --> 00:39:34.920]   to a huge number of people.
[00:39:34.920 --> 00:39:36.680]   - Yeah, it's better to persuade than to force,
[00:39:36.680 --> 00:39:37.680]   in every instance.
[00:39:37.680 --> 00:39:39.280]   - That's where I disagree with Chomsky.
[00:39:39.280 --> 00:39:41.120]   He said, if you're,
[00:39:41.120 --> 00:39:42.880]   Chomsky's whole idea was that,
[00:39:42.880 --> 00:39:45.440]   if you're a really eloquent speaker,
[00:39:45.440 --> 00:39:48.160]   that means your ideas aren't that good.
[00:39:48.160 --> 00:39:49.000]   - That's nonsense.
[00:39:49.000 --> 00:39:52.160]   - Yeah, so, I think that's a way for him to describe,
[00:39:52.160 --> 00:39:55.000]   like, I speak in a very boring way.
[00:39:55.000 --> 00:39:56.880]   Maybe that's the pitch for this podcast.
[00:39:56.880 --> 00:40:00.800]   I speak boring so that the ideas are the things you value,
[00:40:00.800 --> 00:40:02.400]   and it's also useful to go to sleep.
[00:40:02.400 --> 00:40:06.560]   But the, that's why I really liked Obama
[00:40:06.560 --> 00:40:09.520]   throughout his life, and still do.
[00:40:09.520 --> 00:40:11.960]   But when I first, like, saw this as,
[00:40:11.960 --> 00:40:13.840]   for some reason, you can disagree,
[00:40:13.840 --> 00:40:15.320]   I thought he's a man of character,
[00:40:15.320 --> 00:40:18.340]   is to, when most politicians,
[00:40:18.340 --> 00:40:21.800]   most people who are trying to calculate and rise in power,
[00:40:21.800 --> 00:40:23.280]   I think were for the war,
[00:40:23.280 --> 00:40:25.440]   or too afraid to be against the war.
[00:40:25.440 --> 00:40:28.920]   That's why I liked Bernie Sanders,
[00:40:28.920 --> 00:40:32.360]   and that's why I liked, like, in the early days,
[00:40:32.360 --> 00:40:34.880]   Obama, for speaking out against the war.
[00:40:34.880 --> 00:40:37.040]   And not, like, in this weird activist way,
[00:40:37.040 --> 00:40:40.520]   not weird, but not saying I'm an activist,
[00:40:40.520 --> 00:40:44.440]   this is, but, like, just saying the common sense thing,
[00:40:44.440 --> 00:40:46.920]   and being brave enough to say the common sense thing,
[00:40:46.920 --> 00:40:49.620]   without, like, having a big sign,
[00:40:49.620 --> 00:40:52.020]   and saying I'm going to be the anti-war candidate,
[00:40:52.020 --> 00:40:52.900]   or something like that.
[00:40:52.900 --> 00:40:56.100]   But just saying this is not a good idea.
[00:40:56.100 --> 00:40:58.780]   - Yeah, and I think it's, for those of us
[00:40:58.780 --> 00:40:59.740]   who are old enough to remember,
[00:40:59.740 --> 00:41:04.260]   it's pretty despicable what happened with Tulsi in 2020.
[00:41:04.260 --> 00:41:06.700]   She was the biggest anti-war candidate,
[00:41:06.700 --> 00:41:09.320]   and she was marginalized within her own party,
[00:41:09.320 --> 00:41:10.460]   which I guess you can make sense,
[00:41:10.460 --> 00:41:12.540]   she's just a congresswoman from Hawaii.
[00:41:12.540 --> 00:41:16.140]   But the corporate press did everything in their power
[00:41:16.140 --> 00:41:19.220]   to diminish her and pretend she didn't existed.
[00:41:19.220 --> 00:41:23.220]   And for those of us who remember where 12 years prior,
[00:41:23.220 --> 00:41:25.660]   when George W. Bush had
[00:41:25.660 --> 00:41:27.220]   the Republican National Convention in New York,
[00:41:27.220 --> 00:41:29.420]   and it was, like, the biggest protest in history,
[00:41:29.420 --> 00:41:34.100]   and the Iraq War led to democratic landslides
[00:41:34.100 --> 00:41:37.340]   in 2006 and 2008, to have that completely not part
[00:41:37.340 --> 00:41:39.900]   of the Democratic Party in 2020
[00:41:39.900 --> 00:41:42.200]   is both shocking and reprehensible.
[00:41:42.200 --> 00:41:44.980]   - Hey, Michael.
[00:41:45.820 --> 00:41:46.660]   - Is it?
[00:41:46.660 --> 00:41:48.140]   (laughing)
[00:41:48.140 --> 00:41:49.300]   You don't have to say, "Hey, Michael,"
[00:41:49.300 --> 00:41:50.500]   you just say, "Knock, knock."
[00:41:50.500 --> 00:41:51.700]   - No, it's not a knock-knock joke.
[00:41:51.700 --> 00:41:52.900]   - Oh, okay, hey, Lusha.
[00:41:52.900 --> 00:41:54.500]   (laughing)
[00:41:54.500 --> 00:41:57.820]   - What did the volcano say to its true love?
[00:41:57.820 --> 00:41:59.260]   - What?
[00:41:59.260 --> 00:42:00.220]   - I love you.
[00:42:00.220 --> 00:42:04.100]   (laughing)
[00:42:04.100 --> 00:42:06.780]   - These jokes work better
[00:42:06.780 --> 00:42:08.660]   when you know how to speak English.
[00:42:08.660 --> 00:42:11.700]   - It was actually in Russian, I did Google Translate.
[00:42:11.700 --> 00:42:13.260]   Okay.
[00:42:13.260 --> 00:42:15.180]   Back to your book, "In the Suffering."
[00:42:15.180 --> 00:42:18.380]   You somehow turned it positive,
[00:42:18.380 --> 00:42:20.980]   and as one who's wearing,
[00:42:20.980 --> 00:42:22.540]   who's the representative of the black pill
[00:42:22.540 --> 00:42:25.580]   in this conversation, what are some of the darker moments,
[00:42:25.580 --> 00:42:27.220]   what are some of the hardest challenges
[00:42:27.220 --> 00:42:30.580]   of putting together this book, the white pill?
[00:42:30.580 --> 00:42:32.660]   - Content, content, content.
[00:42:32.660 --> 00:42:37.660]   So if I'm having a page about Reagan taking on Gerald Ford
[00:42:37.660 --> 00:42:41.300]   in the 1976 presidential primaries,
[00:42:41.300 --> 00:42:43.540]   I'm gonna have to read, like, 20.
[00:42:43.540 --> 00:42:45.460]   So, and it's the thing, like,
[00:42:45.460 --> 00:42:48.500]   if there'll be sometimes I'll remember some quote somewhere,
[00:42:48.500 --> 00:42:51.060]   and then I have to spend an hour trying to find it,
[00:42:51.060 --> 00:42:53.060]   because I want it to be as dense
[00:42:53.060 --> 00:42:56.100]   with information as possible.
[00:42:56.100 --> 00:42:57.460]   - Like, how do you structure
[00:42:57.460 --> 00:43:01.780]   the main philosophical ideas you wanna convey?
[00:43:01.780 --> 00:43:03.140]   Is that already planned out?
[00:43:03.140 --> 00:43:06.500]   - No, the book changed entirely from its conception.
[00:43:06.500 --> 00:43:10.020]   So my buddy Ryan Holiday had a series of books,
[00:43:10.020 --> 00:43:13.060]   still does, where he takes the ideas of the Stoics,
[00:43:13.060 --> 00:43:16.100]   and he applies them to contemporary terms.
[00:43:16.100 --> 00:43:17.380]   He has this whole cottage industry
[00:43:17.380 --> 00:43:18.700]   that he's doing very well with.
[00:43:18.700 --> 00:43:21.860]   And I'd asked him years ago if I could do that with Camus,
[00:43:21.860 --> 00:43:23.420]   and he's like, "Sure, go for it."
[00:43:23.420 --> 00:43:27.700]   And I was going to rework Camus' "The Myth of Sisyphus,"
[00:43:27.700 --> 00:43:30.620]   and I read it recently, I reread it,
[00:43:30.620 --> 00:43:32.780]   and this wasn't the book I remembered at all.
[00:43:32.780 --> 00:43:34.220]   And I'm like, okay, I'm gonna write the book
[00:43:34.220 --> 00:43:35.660]   that I remembered.
[00:43:35.660 --> 00:43:38.740]   But the more I was writing it,
[00:43:38.740 --> 00:43:41.140]   one of the things I always yell at conservatives about,
[00:43:41.140 --> 00:43:44.900]   there's a long list, is they don't talk about
[00:43:44.900 --> 00:43:47.220]   the great victory of conservatism,
[00:43:47.220 --> 00:43:50.820]   which was the winning of the Cold War without firing a shot.
[00:43:50.820 --> 00:43:52.340]   And I said, "You can't expect the New York Times
[00:43:52.340 --> 00:43:55.220]   "to tell this story because the blood is on their hands."
[00:43:55.220 --> 00:43:58.820]   And I'm like, "Well, Michael,
[00:43:58.820 --> 00:44:01.340]   "instead of complaining about it, why don't you do it?
[00:44:01.340 --> 00:44:02.220]   "Why don't you talk?"
[00:44:02.220 --> 00:44:03.940]   That is a great example of the good guys
[00:44:03.940 --> 00:44:05.500]   winning over the bad guys.
[00:44:05.500 --> 00:44:10.500]   And that's become, A, the victory is beautiful,
[00:44:11.140 --> 00:44:12.540]   but also pointing out to people,
[00:44:12.540 --> 00:44:13.740]   when people are like, "Oh, things are worse
[00:44:13.740 --> 00:44:15.260]   "than they've ever been,"
[00:44:15.260 --> 00:44:18.420]   they don't appreciate how bad things were in the '30s,
[00:44:18.420 --> 00:44:20.860]   what Stalin was doing overseas,
[00:44:20.860 --> 00:44:23.420]   and how people in the West were advocating
[00:44:23.420 --> 00:44:24.800]   to bring that here.
[00:44:24.800 --> 00:44:29.100]   So that's kind of pointing out how bad things were
[00:44:29.100 --> 00:44:30.700]   and how good they became.
[00:44:30.700 --> 00:44:34.000]   And you don't have to be a Republican or conservative
[00:44:34.000 --> 00:44:37.300]   to be delighted at the collapse of totalitarianism
[00:44:37.300 --> 00:44:39.140]   and the peaceful liberation of half the world.
[00:44:39.140 --> 00:44:40.940]   - So that's a picture of the good guys winning.
[00:44:40.940 --> 00:44:41.780]   - Oh, yeah.
[00:44:41.780 --> 00:44:42.900]   - Well, how does that connect to Sisyphus?
[00:44:42.900 --> 00:44:47.900]   And maybe to speak deeper to life
[00:44:47.900 --> 00:44:51.460]   and whatever the hell this thing is,
[00:44:51.460 --> 00:44:55.440]   which is what I remember the myth of Sisyphus being about.
[00:44:55.440 --> 00:44:58.860]   So where does the threat of Camus
[00:44:58.860 --> 00:45:02.300]   sort of lie in the work that you're doing?
[00:45:02.300 --> 00:45:04.980]   - So the myth of Sisyphus,
[00:45:04.980 --> 00:45:06.300]   which I had remembered incorrectly,
[00:45:06.300 --> 00:45:11.300]   is actually just a five to seven page coda
[00:45:11.300 --> 00:45:12.580]   to the whole book at the very end.
[00:45:12.580 --> 00:45:14.060]   Like you only need to read that little essay
[00:45:14.060 --> 00:45:15.340]   called "The Myth of Sisyphus."
[00:45:15.340 --> 00:45:19.060]   The broader work is about Camus' concept of the absurd
[00:45:19.060 --> 00:45:20.860]   and the absurd man within literature.
[00:45:20.860 --> 00:45:22.780]   And it's just like, I don't really care
[00:45:22.780 --> 00:45:24.460]   about this character in Dostoevsky
[00:45:24.460 --> 00:45:25.620]   and all this other stuff that you're talking about.
[00:45:25.620 --> 00:45:27.220]   It's of no relevance.
[00:45:27.220 --> 00:45:30.700]   But the myth of Sisyphus, the myth itself, not the book,
[00:45:30.700 --> 00:45:34.260]   or the essay of his, is this Greek character,
[00:45:34.260 --> 00:45:39.260]   and Sisyphus is forced in hell to roll a rock up a hill.
[00:45:39.260 --> 00:45:42.620]   For eternity, at the very last moment, the rock falls away.
[00:45:42.620 --> 00:45:44.780]   And Camus' takeaway from the story
[00:45:44.780 --> 00:45:48.420]   is that we must imagine Sisyphus happy.
[00:45:48.420 --> 00:45:50.180]   And there's several interpretations of this,
[00:45:50.180 --> 00:45:52.260]   but one is once you accept
[00:45:52.260 --> 00:45:56.780]   that you are living an absurdist existence,
[00:45:56.780 --> 00:46:01.780]   once you own your reality, it loses its bite.
[00:46:02.320 --> 00:46:06.880]   And you can start with that as your kind of baseline.
[00:46:06.880 --> 00:46:08.800]   - And bite is suffering.
[00:46:08.800 --> 00:46:11.160]   - And hopelessness.
[00:46:11.160 --> 00:46:16.160]   So I think when people look at how much ridiculousness
[00:46:16.160 --> 00:46:19.520]   is happening in America and it's escalating,
[00:46:19.520 --> 00:46:22.240]   you can either think, oh, all is lost,
[00:46:22.240 --> 00:46:24.320]   or you can, and I think you and I
[00:46:24.320 --> 00:46:25.520]   have lived our lives like this,
[00:46:25.520 --> 00:46:27.680]   you can live life more like a surfer,
[00:46:27.680 --> 00:46:30.360]   whereas you're never gonna control the ocean.
[00:46:30.360 --> 00:46:33.440]   But you can sure enjoy that ride and stop,
[00:46:33.440 --> 00:46:36.740]   if you're trying to control the waves, yeah, you're done.
[00:46:36.740 --> 00:46:39.200]   But if you're like, all right, I've got my board,
[00:46:39.200 --> 00:46:41.080]   I'm gonna see where this takes me,
[00:46:41.080 --> 00:46:44.240]   surfing, from what I understand, is a pretty fun activity.
[00:46:44.240 --> 00:46:45.920]   And also sometimes dangerous,
[00:46:45.920 --> 00:46:48.280]   but you'd have to ask Tulsi about that.
[00:46:48.280 --> 00:46:53.280]   - So we were offline talking about Stalin
[00:46:53.280 --> 00:46:57.400]   and the evils of the Soviet regime.
[00:46:57.400 --> 00:46:58.800]   - Yeah.
[00:46:58.800 --> 00:47:00.040]   - One of the things I mentioned,
[00:47:00.040 --> 00:47:02.700]   I watched the movie "Mr. Jones,"
[00:47:02.700 --> 00:47:06.480]   but it's about the 1930s, called the more,
[00:47:06.480 --> 00:47:11.320]   what would you say, the torture of the Ukrainian people
[00:47:11.320 --> 00:47:13.140]   by Stalin.
[00:47:13.140 --> 00:47:15.280]   One interesting thing to me,
[00:47:15.280 --> 00:47:17.560]   that I'd love to hear your opinion about,
[00:47:17.560 --> 00:47:20.040]   is the role of journalism in all of this.
[00:47:20.040 --> 00:47:25.580]   And also about 1930s Germany.
[00:47:25.580 --> 00:47:30.580]   So what's the role of journalists and intellectuals
[00:47:30.580 --> 00:47:34.340]   in a time when trouble is brewing,
[00:47:34.340 --> 00:47:39.340]   but it requires a really sort of brave and deep thinking
[00:47:39.340 --> 00:47:43.060]   to understand that trouble is brewing.
[00:47:43.060 --> 00:47:44.660]   Like if you were a journalist,
[00:47:44.660 --> 00:47:47.700]   or if you were just like an intellectual, a thinker,
[00:47:47.700 --> 00:47:52.380]   but also a voice in the space of public discourse,
[00:47:52.380 --> 00:47:57.380]   what would you do in 1930s about Stalin, about Haldemar?
[00:47:57.380 --> 00:48:02.580]   And what would you do about Nazi Germany in 1937, 1938?
[00:48:02.580 --> 00:48:05.120]   - So that's really funny that you asked that,
[00:48:05.120 --> 00:48:07.580]   because currently how the book is structured,
[00:48:07.580 --> 00:48:10.980]   it's like, books often follow three act structure, right?
[00:48:10.980 --> 00:48:14.660]   So act three is the 80s, act one is the 30s,
[00:48:14.660 --> 00:48:16.620]   and act two is gonna be like,
[00:48:16.620 --> 00:48:18.980]   all right, let's suppose you were in the 30s.
[00:48:18.980 --> 00:48:20.180]   Are you just gonna give up?
[00:48:20.180 --> 00:48:21.340]   Like, are you just gonna be like,
[00:48:21.340 --> 00:48:23.580]   well, we're screwed, and you'd be right to say,
[00:48:23.580 --> 00:48:25.620]   things are gonna be very bad for a long time.
[00:48:25.620 --> 00:48:28.780]   Or are you going to be one of those few who are like,
[00:48:28.780 --> 00:48:30.220]   we're gonna do something about this,
[00:48:30.220 --> 00:48:32.140]   and we're gonna go down swinging.
[00:48:32.140 --> 00:48:33.660]   There are two books I can recommend,
[00:48:33.660 --> 00:48:38.660]   which are just masterpieces that are written by women,
[00:48:38.660 --> 00:48:41.120]   that just are historians that are just superb.
[00:48:41.120 --> 00:48:43.380]   There's a book called "Beyond Belief" by Deborah Lippstadt.
[00:48:43.380 --> 00:48:45.640]   She talks about the rise of Nazi Germany
[00:48:45.640 --> 00:48:47.520]   as seen through the press.
[00:48:47.520 --> 00:48:49.140]   And what was amazing,
[00:48:49.140 --> 00:48:51.580]   and she does a great job empathizing with the press
[00:48:51.580 --> 00:48:53.360]   and understand their perspective,
[00:48:53.360 --> 00:48:55.740]   is we remember, and Chamberlain gets a bad rap,
[00:48:55.740 --> 00:48:58.240]   Neville Chamberlain, for kind of appeasing Hitler,
[00:48:58.240 --> 00:49:00.760]   because not that long ago, they had the Great War.
[00:49:00.760 --> 00:49:02.440]   They had World War I,
[00:49:02.440 --> 00:49:04.680]   and they had the carnage
[00:49:04.680 --> 00:49:06.740]   that the earth had never seen before.
[00:49:06.740 --> 00:49:08.740]   And when you had people made out of meat,
[00:49:08.740 --> 00:49:09.980]   meeting industrial machines,
[00:49:09.980 --> 00:49:12.580]   and plastic surgery was invented as a consequence of this,
[00:49:12.580 --> 00:49:16.000]   they're coming back mangled and disfigured, and for what?
[00:49:16.000 --> 00:49:18.620]   And this was a world where the Kaiser
[00:49:18.620 --> 00:49:20.660]   was the most evil person who ever lived.
[00:49:20.660 --> 00:49:23.580]   And we all had the Western propaganda about the Han,
[00:49:23.580 --> 00:49:25.840]   and all the rapes, and all this barbarism,
[00:49:25.840 --> 00:49:27.140]   and blah, blah, blah.
[00:49:27.140 --> 00:49:30.100]   So not that long later,
[00:49:30.100 --> 00:49:32.300]   when you're hearing all this propaganda,
[00:49:32.300 --> 00:49:34.180]   which was factual, about Hitler,
[00:49:34.180 --> 00:49:36.020]   it's like, we heard this.
[00:49:36.020 --> 00:49:37.800]   We heard this 20 years ago.
[00:49:37.800 --> 00:49:39.620]   This was all lies.
[00:49:39.620 --> 00:49:41.660]   Give us a break.
[00:49:41.660 --> 00:49:46.540]   And she has all the quotes from the different agencies
[00:49:46.540 --> 00:49:47.540]   and how they addressed it.
[00:49:47.540 --> 00:49:49.140]   Plus, they had very limited information.
[00:49:49.140 --> 00:49:51.780]   It's not like Nazi Germany was an open society
[00:49:51.780 --> 00:49:53.020]   where reporters can walk around,
[00:49:53.020 --> 00:49:55.780]   and they were under a lot of pressure as well
[00:49:55.780 --> 00:49:56.700]   in those areas.
[00:49:56.700 --> 00:49:59.860]   - And Hitler himself was pretty good at,
[00:49:59.860 --> 00:50:01.180]   he let some stuff slip,
[00:50:01.180 --> 00:50:04.580]   but usually he made it seem like he wants peace.
[00:50:04.580 --> 00:50:05.620]   He wants world peace.
[00:50:05.620 --> 00:50:06.540]   - This was amazing.
[00:50:06.540 --> 00:50:07.980]   They were making the argument that
[00:50:07.980 --> 00:50:11.260]   because all these Jews were being beaten up on the street,
[00:50:11.260 --> 00:50:13.900]   this proved, this was the hot take of the day,
[00:50:13.900 --> 00:50:15.980]   that Hitler was weak,
[00:50:15.980 --> 00:50:18.020]   because since Hitler's a statesman,
[00:50:18.020 --> 00:50:20.080]   and he can't control these hooligans,
[00:50:20.080 --> 00:50:22.940]   that shows his control and power is tenuous,
[00:50:22.940 --> 00:50:24.340]   and this is all gonna go away.
[00:50:24.340 --> 00:50:26.860]   - By the way, I mean, Hitler thought that too.
[00:50:26.860 --> 00:50:29.780]   He was kind of afraid of the branchers, whatever.
[00:50:29.780 --> 00:50:32.380]   He was afraid of these hooligans a little bit.
[00:50:32.380 --> 00:50:34.140]   They were useful to him,
[00:50:34.140 --> 00:50:37.840]   but at a certain point, yeah, they can get in the way.
[00:50:37.840 --> 00:50:40.260]   That's why he wanted to get control of the military,
[00:50:40.260 --> 00:50:42.100]   the army, their regiment.
[00:50:42.100 --> 00:50:43.500]   If you wanna take over the world,
[00:50:43.500 --> 00:50:45.200]   you can't do it with hooligans.
[00:50:45.200 --> 00:50:47.100]   You have to do it with an actual army.
[00:50:47.100 --> 00:50:48.460]   - And then you had Kristallnacht,
[00:50:48.460 --> 00:50:50.540]   which was a nationwide pogrom,
[00:50:50.540 --> 00:50:54.860]   and then all the news agencies universally were like,
[00:50:54.860 --> 00:50:57.340]   "Oh, crap, we got this wrong,"
[00:50:57.340 --> 00:50:59.220]   and the condemnation was universal.
[00:50:59.220 --> 00:51:02.500]   So that book traces the West's reaction
[00:51:02.500 --> 00:51:03.700]   to what's going on there,
[00:51:03.700 --> 00:51:08.100]   and including the reaction to the incipient Holocaust,
[00:51:08.100 --> 00:51:10.380]   as people being, you know, what they knew,
[00:51:10.380 --> 00:51:11.620]   when did they know.
[00:51:11.620 --> 00:51:14.780]   There was not ambiguity about people.
[00:51:14.780 --> 00:51:17.960]   I think there's this myth that she dispels
[00:51:17.960 --> 00:51:20.760]   that they didn't know the Holocaust was happening
[00:51:20.760 --> 00:51:22.000]   or they didn't care.
[00:51:22.000 --> 00:51:23.400]   They were aware,
[00:51:23.400 --> 00:51:25.160]   but they were already at war with Nazi Germany.
[00:51:25.160 --> 00:51:29.040]   Like, literally, what else could they do at that point,
[00:51:29.040 --> 00:51:31.280]   you know, to rescue all these Jews?
[00:51:31.280 --> 00:51:34.360]   So that's a superb book, and Ann Appelbaum,
[00:51:34.360 --> 00:51:36.360]   I think the book is called "Red Famine,"
[00:51:36.360 --> 00:51:41.360]   came out fairly recently, and she brings the receipts.
[00:51:41.720 --> 00:51:44.940]   And she's a, you know, this is something I really hate
[00:51:44.940 --> 00:51:47.500]   with the binary thinkers, where people think,
[00:51:47.500 --> 00:51:48.740]   "Oh, you know, if you're a Democrat,
[00:51:48.740 --> 00:51:49.860]   "you're basically a communist."
[00:51:49.860 --> 00:51:51.180]   They call Joe Biden a Marxist.
[00:51:51.180 --> 00:51:53.060]   It's just like, you know, she's a hard lefty.
[00:51:53.060 --> 00:51:57.300]   She has TDS, but this book just systemically
[00:51:57.300 --> 00:51:59.380]   lays out what Stalin did.
[00:51:59.380 --> 00:52:01.700]   - By the way, I'm triggered by the binary thinkers,
[00:52:01.700 --> 00:52:02.900]   and for those who don't know,
[00:52:02.900 --> 00:52:06.620]   TDS0011 is Trump Derangement Syndrome.
[00:52:06.620 --> 00:52:10.500]   - Yes, so they, you know, forced the starvation
[00:52:10.500 --> 00:52:15.020]   of this entire population, and they, it's not only that,
[00:52:15.020 --> 00:52:18.400]   it's like they knew if you weren't starving
[00:52:18.400 --> 00:52:21.460]   by looking at you, that you were hiding food.
[00:52:21.460 --> 00:52:23.220]   So they'd come back to your house at night
[00:52:23.220 --> 00:52:25.180]   and break your fingers in the door,
[00:52:25.180 --> 00:52:26.900]   or take, burn down your house,
[00:52:26.900 --> 00:52:28.400]   and now you're on the street without food,
[00:52:28.400 --> 00:52:30.780]   because you lied, 'cause this is the people's food.
[00:52:30.780 --> 00:52:32.260]   You're a kulak, you're a landowner.
[00:52:32.260 --> 00:52:33.860]   And very quickly, a kulak, which meant, like,
[00:52:33.860 --> 00:52:37.560]   peasant landowner, became anyone who had a piece of bread.
[00:52:37.560 --> 00:52:40.380]   And it was systemic and ongoing,
[00:52:40.380 --> 00:52:45.260]   and many people in the press did not believe it.
[00:52:45.260 --> 00:52:47.700]   There was a British journalist, I believe,
[00:52:47.700 --> 00:52:50.260]   who got out of the train, Ukraine,
[00:52:50.260 --> 00:52:51.820]   like one town earlier, and walked,
[00:52:51.820 --> 00:52:55.700]   and he described all this, and he was mocked and derided,
[00:52:55.700 --> 00:52:58.060]   and this is just anti-Russian propaganda,
[00:52:58.060 --> 00:52:59.540]   because at the time, in the '30s,
[00:52:59.540 --> 00:53:02.080]   this was, socialism had come to fruition.
[00:53:02.080 --> 00:53:03.460]   This was a noble experiment.
[00:53:03.460 --> 00:53:04.900]   I'd seen the future, and it works,
[00:53:04.900 --> 00:53:08.220]   as I think Sidney Webb was the guy who said that.
[00:53:08.220 --> 00:53:11.940]   And the premise was, let's see what happens.
[00:53:11.940 --> 00:53:13.700]   We've never tried something like that.
[00:53:13.700 --> 00:53:15.820]   And they were perfectly happy
[00:53:15.820 --> 00:53:17.900]   to have this experiment happen overseas
[00:53:17.900 --> 00:53:19.920]   at the price of the Russian people,
[00:53:19.920 --> 00:53:21.140]   because it's like, you know what?
[00:53:21.140 --> 00:53:23.140]   Maybe this'll be paradise on Earth.
[00:53:23.140 --> 00:53:26.660]   And there's a, I address this in my book as well,
[00:53:26.660 --> 00:53:30.060]   there's a superb essay, I think, by Eugene Genovese,
[00:53:30.060 --> 00:53:32.060]   and he talks about the question,
[00:53:32.060 --> 00:53:34.820]   the question being, what did you know,
[00:53:34.820 --> 00:53:36.220]   and when did you know it?
[00:53:36.220 --> 00:53:38.140]   What did you know about the concentration camps?
[00:53:38.140 --> 00:53:39.800]   What did you know about the starvation?
[00:53:39.800 --> 00:53:41.860]   What did you know about children being taught at school
[00:53:41.860 --> 00:53:45.060]   to turn in their parents for having some extra bread?
[00:53:45.060 --> 00:53:47.540]   And his conclusion is, we all knew,
[00:53:47.540 --> 00:53:49.780]   and we all knew from the beginning, every bit of it,
[00:53:49.780 --> 00:53:52.380]   and we didn't care, because we were more interested
[00:53:52.380 --> 00:53:54.120]   in promoting this ideology.
[00:53:54.120 --> 00:53:56.900]   So when people are kind of thinking
[00:53:56.900 --> 00:54:00.300]   the worst thing on Earth is like Robert E. Lee's statue
[00:54:00.300 --> 00:54:02.520]   being taken down to Washington, D.C.,
[00:54:02.520 --> 00:54:04.580]   we were being told,
[00:54:05.140 --> 00:54:09.300]   and especially in a much more limited news information world
[00:54:09.300 --> 00:54:11.740]   where now you have literally anyone can have a Twitter,
[00:54:11.740 --> 00:54:13.500]   but how many outlets were there,
[00:54:13.500 --> 00:54:16.940]   that this is, we're backwards, they're the future,
[00:54:16.940 --> 00:54:19.620]   they're scientific, we have the vagaries of the market,
[00:54:19.620 --> 00:54:21.340]   which led to the Great Depression,
[00:54:21.340 --> 00:54:24.020]   and when you see what was being put over
[00:54:24.020 --> 00:54:26.220]   on the American public at the time,
[00:54:26.220 --> 00:54:28.820]   anyone who thinks things are as bad now
[00:54:28.820 --> 00:54:31.860]   as they've ever been is simply delusional or ignorant.
[00:54:31.860 --> 00:54:35.140]   - Yeah, I would say just as a small aside,
[00:54:35.140 --> 00:54:37.380]   that's why reading, as I'm almost done
[00:54:37.380 --> 00:54:39.940]   with "The Rise and Fall of the Third Reich,"
[00:54:39.940 --> 00:54:40.780]   - Oh, yeah.
[00:54:40.780 --> 00:54:45.780]   - Is, it's a, refreshes, resets the palette
[00:54:45.780 --> 00:54:49.340]   of your understanding of what is good and evil in the world
[00:54:49.340 --> 00:54:52.900]   that I think is really useful now.
[00:54:52.900 --> 00:54:56.900]   Like, you know, what helps me be really positive
[00:54:56.900 --> 00:55:01.340]   and almost naive on Twitter and in the world
[00:55:01.340 --> 00:55:03.620]   is by just studying history.
[00:55:03.620 --> 00:55:04.460]   - Yeah.
[00:55:04.460 --> 00:55:09.460]   - And comparing it to how amazing things are today,
[00:55:09.460 --> 00:55:15.100]   but in that time, what would you do?
[00:55:15.100 --> 00:55:21.060]   What does a brave mind do?
[00:55:21.060 --> 00:55:26.060]   And not just acts of bravery,
[00:55:26.060 --> 00:55:30.020]   but how do you be effective in that?
[00:55:30.020 --> 00:55:31.300]   And that's something I often think about.
[00:55:31.300 --> 00:55:33.540]   It's sometimes easy to be an activist
[00:55:33.540 --> 00:55:37.260]   in terms of just saying stuff.
[00:55:37.260 --> 00:55:40.380]   It's hard to be effective at your activism.
[00:55:40.380 --> 00:55:43.660]   - One of the big questions historians have constantly
[00:55:43.660 --> 00:55:45.260]   is how did this happen?
[00:55:45.260 --> 00:55:46.700]   A, is to make sure it doesn't happen again,
[00:55:46.700 --> 00:55:48.060]   but this is Germany.
[00:55:48.060 --> 00:55:51.540]   This is not some kind of weirdo cult nation.
[00:55:51.540 --> 00:55:53.580]   They're very advanced, very,
[00:55:53.580 --> 00:55:55.660]   in the land of poets and philosophers.
[00:55:55.660 --> 00:55:57.620]   How did it get to that point
[00:55:57.620 --> 00:56:00.220]   that they're just shooting children
[00:56:00.220 --> 00:56:02.060]   and everyone's cheering for this?
[00:56:02.060 --> 00:56:04.620]   - Specifically on the antisemitism and the Holocaust.
[00:56:04.620 --> 00:56:07.060]   - No, totalitarianism, the cult of Hitler
[00:56:07.060 --> 00:56:09.020]   and just this whole kind of thing.
[00:56:09.020 --> 00:56:11.700]   - Sorry to interrupt, but there's two sides.
[00:56:11.700 --> 00:56:13.100]   I don't know if you want to separate them.
[00:56:13.100 --> 00:56:17.500]   One is the totalitarianism and the entirety
[00:56:17.500 --> 00:56:20.300]   of the Nazi regime, and then there's the Holocaust,
[00:56:20.300 --> 00:56:24.620]   which is like, you know, going, I would say,
[00:56:25.740 --> 00:56:30.740]   like very specifically, as I think you're about to describe,
[00:56:30.740 --> 00:56:34.860]   is like, you know, targeting Jews very much so.
[00:56:34.860 --> 00:56:36.780]   I don't know if you see those as two separate things.
[00:56:36.780 --> 00:56:37.940]   - I think they're very interconnected,
[00:56:37.940 --> 00:56:40.900]   but I think if you look at it,
[00:56:40.900 --> 00:56:44.980]   everyone thinks that they'd be the ones putting up Anne Frank,
[00:56:44.980 --> 00:56:46.020]   but if you look at the numbers,
[00:56:46.020 --> 00:56:48.860]   they'd be the ones calling the Stasi on her
[00:56:48.860 --> 00:56:50.660]   or whoever the people were at the time,
[00:56:50.660 --> 00:56:52.540]   and not the Stasi, obviously,
[00:56:52.540 --> 00:56:54.460]   and patting themselves on the back for it.
[00:56:54.460 --> 00:56:55.300]   - So sorry to pause on that.
[00:56:55.300 --> 00:56:57.060]   That's a really important thing.
[00:56:57.060 --> 00:56:58.660]   If you're listening to this,
[00:56:58.660 --> 00:57:03.940]   that, and you were in Germany at the time,
[00:57:03.940 --> 00:57:07.740]   you would have likely been willing to commit
[00:57:07.740 --> 00:57:10.620]   or at least keep a blind eye to the violence against Jews.
[00:57:10.620 --> 00:57:14.020]   Like, you have to really sit with that idea,
[00:57:14.020 --> 00:57:17.700]   that it would have been somebody who just sees this
[00:57:17.700 --> 00:57:19.300]   and is not bothered by it,
[00:57:19.300 --> 00:57:22.700]   and also very likely kind of understand this
[00:57:22.700 --> 00:57:26.620]   as a necessary evil or even a necessary good.
[00:57:26.620 --> 00:57:30.020]   - Yeah, and I think people think
[00:57:30.020 --> 00:57:32.780]   that they would be the abolitionists marching on Selma.
[00:57:32.780 --> 00:57:36.100]   The numbers don't add up to that at all,
[00:57:36.100 --> 00:57:37.660]   and I think the question would be,
[00:57:37.660 --> 00:57:40.820]   what social, my friend was on Tinder, my friend Matt,
[00:57:40.820 --> 00:57:43.860]   who's a great dude, and the question was,
[00:57:43.860 --> 00:57:46.260]   what's the most controversial opinion you have?
[00:57:46.260 --> 00:57:49.100]   This is in New York, and the girl wrote, "I hate Trump."
[00:57:49.980 --> 00:57:52.140]   And what people perceive themselves
[00:57:52.140 --> 00:57:55.340]   as being courageous in saying and doing,
[00:57:55.340 --> 00:57:58.220]   and what is the actual social costs of you saying
[00:57:58.220 --> 00:58:00.900]   or doing this are two very disconnected things.
[00:58:00.900 --> 00:58:04.300]   And we're also trained by corporate media
[00:58:04.300 --> 00:58:09.300]   to have completely vapid, uninteresting, banal ideas,
[00:58:09.300 --> 00:58:11.940]   and yet regard ourselves as revolutionaries.
[00:58:11.940 --> 00:58:16.380]   There are people who still in New York will take pride
[00:58:16.380 --> 00:58:18.220]   'cause they have a gay friend.
[00:58:18.220 --> 00:58:21.700]   And it's like, first of all, who cares?
[00:58:21.700 --> 00:58:23.900]   But second of all, you are not a hero.
[00:58:23.900 --> 00:58:26.780]   And that person's not your prop, by the way.
[00:58:26.780 --> 00:58:28.140]   That's another big problem.
[00:58:28.140 --> 00:58:30.820]   - Which is why I'd like to give Richard Wolff a shout out
[00:58:30.820 --> 00:58:34.460]   for being an intellectual who talks about communism.
[00:58:34.460 --> 00:58:38.300]   I think it takes kind of a heroic intellectual right now
[00:58:38.300 --> 00:58:41.620]   to speak about communism seriously.
[00:58:41.620 --> 00:58:45.700]   There's difficult waters to tread, is that the expression?
[00:58:45.700 --> 00:58:47.340]   There's difficult paths to walk.
[00:58:47.340 --> 00:58:49.460]   I love watching a robot try to use idiom
[00:58:49.460 --> 00:58:50.300]   in a language he doesn't know.
[00:58:50.300 --> 00:58:52.860]   - Zero, zero, one, one.
[00:58:52.860 --> 00:58:57.340]   I'm quite deeply hurt by the binary comment.
[00:58:57.340 --> 00:58:58.220]   - Are you?
[00:58:58.220 --> 00:59:00.220]   Your feeling has gone from one to zero.
[00:59:00.220 --> 00:59:02.420]   (laughing)
[00:59:02.420 --> 00:59:03.260]   - Yeah.
[00:59:03.260 --> 00:59:04.100]   - What is love?
[00:59:04.100 --> 00:59:05.700]   - My buffers have overflown.
[00:59:05.700 --> 00:59:10.500]   No, but there's difficult, I feel like communism
[00:59:10.500 --> 00:59:14.340]   is universally seen as a bad thing currently
[00:59:14.340 --> 00:59:15.420]   in intellectual circles.
[00:59:15.420 --> 00:59:16.260]   - Yes.
[00:59:16.260 --> 00:59:17.820]   - And I think maybe some people disagree with that.
[00:59:17.820 --> 00:59:21.980]   People say like far left people are trying to,
[00:59:21.980 --> 00:59:25.540]   there's some people who argue the BLM movement
[00:59:25.540 --> 00:59:28.260]   is some kind of harm of a Marxist.
[00:59:28.260 --> 00:59:31.860]   I mean, I don't really follow the deep logic in that,
[00:59:31.860 --> 00:59:34.500]   whatever, but it's just--
[00:59:34.500 --> 00:59:35.860]   - Well, they said they were formed by Marxism,
[00:59:35.860 --> 00:59:37.180]   the founder, co-founder.
[00:59:37.180 --> 00:59:41.180]   - Yeah, but stating that is different than--
[00:59:41.180 --> 00:59:43.500]   - There's Marx the totalitarian,
[00:59:43.500 --> 00:59:44.740]   there's also Marx the revolutionary.
[00:59:44.740 --> 00:59:47.020]   I think they're talking more like we're revolutionaries,
[00:59:47.020 --> 00:59:48.540]   we're gonna overthrow the status quo.
[00:59:48.540 --> 00:59:51.620]   - Yeah, right, but we can have that further discussion,
[00:59:51.620 --> 00:59:54.060]   but I just don't think they speak deeply
[00:59:54.060 --> 00:59:57.460]   about political systems and saying communism
[00:59:57.460 --> 01:00:01.340]   is going to be the righteous system.
[01:00:01.340 --> 01:00:03.740]   There's not a deep intellectual discourse, what I mean.
[01:00:03.740 --> 01:00:05.980]   But if you were to try to be on stage
[01:00:05.980 --> 01:00:07.380]   with the Jordan Peterson,
[01:00:07.380 --> 01:00:10.540]   like to me the brave thing now,
[01:00:10.540 --> 01:00:13.620]   it would be to argue for communism.
[01:00:13.620 --> 01:00:16.900]   It'd be interesting to see, not many people do it.
[01:00:16.900 --> 01:00:18.300]   I certainly wouldn't be willing to do it.
[01:00:18.300 --> 01:00:20.780]   I don't have enough, first of all, I don't believe it,
[01:00:20.780 --> 01:00:23.740]   but second of all, it's a very difficult argument to make
[01:00:23.740 --> 01:00:25.580]   because you would get so much fire,
[01:00:25.580 --> 01:00:27.180]   which is why I like Richard Wolff,
[01:00:27.180 --> 01:00:31.300]   he's one of the people who is quite rigorously showing
[01:00:31.300 --> 01:00:35.140]   that there's some good ideas within the system of communism,
[01:00:35.140 --> 01:00:38.540]   specifically saying that attacking more
[01:00:38.540 --> 01:00:42.260]   the negative sides of capitalism.
[01:00:42.260 --> 01:00:43.860]   So saying that there is,
[01:00:43.860 --> 01:00:48.020]   that capitalism potentially is more dangerous than communism.
[01:00:48.020 --> 01:00:51.060]   I mean, I disagree with that, but I think it's a--
[01:00:51.060 --> 01:00:52.380]   - I love how something is like,
[01:00:52.380 --> 01:00:54.740]   we've got a body count of 60 million,
[01:00:54.740 --> 01:00:57.540]   but this, everything is, and potentially,
[01:00:57.540 --> 01:00:59.700]   like water can drown everyone on earth.
[01:00:59.700 --> 01:01:01.260]   So this is incoherent.
[01:01:01.260 --> 01:01:03.340]   - Well, I think nuclear weapons are bad,
[01:01:03.340 --> 01:01:04.980]   but nuclear energy is good.
[01:01:04.980 --> 01:01:07.580]   - Sure, well, nuclear weapons also can be good.
[01:01:07.580 --> 01:01:08.820]   You can easily make the argument,
[01:01:08.820 --> 01:01:10.580]   which I don't know that I subscribe to,
[01:01:10.580 --> 01:01:15.580]   that nuclear weapons prevented boots on the ground war,
[01:01:15.580 --> 01:01:17.380]   and it would cause them to be much more contained.
[01:01:17.380 --> 01:01:19.300]   - And they're also quite effective
[01:01:19.300 --> 01:01:21.580]   at changing the direction of an asteroid
[01:01:21.580 --> 01:01:22.900]   that's about to hit earth,
[01:01:22.900 --> 01:01:24.740]   as I've learned from a movie. - Armageddon.
[01:01:24.740 --> 01:01:25.900]   - Yeah, Armageddon.
[01:01:25.900 --> 01:01:28.620]   And they're actually useful, as Elon Musk has claimed
[01:01:28.620 --> 01:01:33.620]   for application for, prior to colonizing Mars,
[01:01:33.620 --> 01:01:35.380]   making it more habitable.
[01:01:35.380 --> 01:01:36.340]   - Oh, okay.
[01:01:36.340 --> 01:01:38.260]   - So it should change. - Gotta do something.
[01:01:38.260 --> 01:01:40.300]   (both laughing)
[01:01:40.300 --> 01:01:43.860]   - But, but, but, yes, but I guess what I'm saying
[01:01:43.860 --> 01:01:46.380]   is there's place for nuance,
[01:01:46.380 --> 01:01:49.540]   and there's some topics so hot, like communism,
[01:01:49.540 --> 01:01:53.100]   where nuance is very difficult to have.
[01:01:53.100 --> 01:01:55.980]   And I feel like with Nazi Germany,
[01:01:55.980 --> 01:01:59.060]   it was a similar thing at the time.
[01:01:59.060 --> 01:02:01.660]   - Let me tell, you wanna talk about Jeanette Rankin,
[01:02:01.660 --> 01:02:03.380]   who was one of my favorite people?
[01:02:03.380 --> 01:02:06.220]   So Jeanette Rankin was the first woman elected to Congress.
[01:02:06.220 --> 01:02:08.740]   She was elected before women's suffrage
[01:02:08.740 --> 01:02:12.100]   was passed the constitutional amendment for Montana.
[01:02:12.100 --> 01:02:15.580]   She was elected in 1916.
[01:02:15.580 --> 01:02:18.940]   She was one of a handful of people
[01:02:18.940 --> 01:02:21.900]   to vote against the US going into the Great War,
[01:02:21.900 --> 01:02:23.420]   which was the right call at the time.
[01:02:23.420 --> 01:02:26.780]   She was a pacifist, Republican as well, coincidentally.
[01:02:26.780 --> 01:02:31.780]   She lost her seat, ran again in, was it 1940?
[01:02:31.780 --> 01:02:36.460]   Got the seat again, and was the only person to vote
[01:02:36.460 --> 01:02:38.600]   against getting into World War II.
[01:02:38.600 --> 01:02:40.740]   It was not a unanimous choice.
[01:02:40.740 --> 01:02:42.340]   Jeanette Rankin was the one person,
[01:02:42.340 --> 01:02:44.260]   and she said, "You can no more win a war
[01:02:44.260 --> 01:02:46.220]   "than you can win a hurricane."
[01:02:46.220 --> 01:02:50.300]   So she's one of these interesting, and talk about bravery.
[01:02:50.300 --> 01:02:54.500]   You're the one vote after Pearl Harbor to say,
[01:02:54.500 --> 01:02:55.700]   "We're not doing this."
[01:02:55.700 --> 01:02:58.820]   And I mean, the pressure she must've been under at the time
[01:02:58.820 --> 01:03:01.580]   is, and of course, many people are not interested
[01:03:01.580 --> 01:03:02.460]   in hearing her perspective.
[01:03:02.460 --> 01:03:03.940]   She's crazy, she's evil, blah, blah, blah.
[01:03:03.940 --> 01:03:05.580]   It's also funny, someone on my Twitter,
[01:03:05.580 --> 01:03:06.620]   when I talked about her, goes,
[01:03:06.620 --> 01:03:08.140]   "Maybe she had Hitler's sympathies."
[01:03:08.140 --> 01:03:12.160]   Like, yeah, Ms. Rankin was a big fan of Hitler.
[01:03:12.160 --> 01:03:14.120]   That's, you figured it out, guys.
[01:03:14.120 --> 01:03:16.520]   - Do you think there's an argument to be made
[01:03:16.520 --> 01:03:19.360]   that United States should not have gotten involved
[01:03:19.360 --> 01:03:20.280]   in World War II?
[01:03:20.280 --> 01:03:21.700]   - Oh, easy, an easy argument.
[01:03:21.700 --> 01:03:24.980]   The argument, there's, I talk about this in The New Right.
[01:03:24.980 --> 01:03:27.660]   So on internet circles, there's something called
[01:03:27.660 --> 01:03:30.000]   Godwin's Law, which means the longer
[01:03:30.000 --> 01:03:32.720]   an internet conversation goes on,
[01:03:32.720 --> 01:03:35.720]   the probability someone gets compared to Hitler becomes one.
[01:03:37.520 --> 01:03:40.080]   In certain New Right circles,
[01:03:40.080 --> 01:03:41.920]   the longer the conversation goes on,
[01:03:41.920 --> 01:03:43.720]   the more likelihood that the argument will become,
[01:03:43.720 --> 01:03:45.960]   we should have been in World War II also becomes one.
[01:03:45.960 --> 01:03:48.160]   And the argument is, at the very least,
[01:03:48.160 --> 01:03:52.600]   stay back, let Hitler and Stalin kill each other off,
[01:03:52.600 --> 01:03:54.780]   and then go in and knock off the weaker one.
[01:03:54.780 --> 01:03:59.120]   And you're gonna be saving, destroying two nightmare systems.
[01:03:59.120 --> 01:04:00.760]   And I think that's an easy argument to make.
[01:04:00.760 --> 01:04:02.840]   Now, it's hard to pull off after Pearl Harbor,
[01:04:02.840 --> 01:04:07.320]   but in terms of strategy, I don't think that's a tough sell.
[01:04:07.320 --> 01:04:08.960]   - What about after Pearl Harbor?
[01:04:08.960 --> 01:04:10.480]   - I mean, that's what I'm saying, after Pearl Harbor,
[01:04:10.480 --> 01:04:11.920]   how are you gonna sell that to the people?
[01:04:11.920 --> 01:04:13.600]   The argument is blah, blah, the Holocaust.
[01:04:13.600 --> 01:04:15.280]   The Holocaust, there's no scenario
[01:04:15.280 --> 01:04:16.800]   where that doesn't happen, really,
[01:04:16.800 --> 01:04:19.560]   if you're, unless you're going in way earlier.
[01:04:19.560 --> 01:04:21.040]   But even so, Hitler had said,
[01:04:21.040 --> 01:04:23.480]   if the Jews launch another war,
[01:04:23.480 --> 01:04:24.760]   we're gonna wipe them from the face of the earth.
[01:04:24.760 --> 01:04:26.600]   So the Jews are being held hostage by Hitler
[01:04:26.600 --> 01:04:27.640]   as an argument for this.
[01:04:27.640 --> 01:04:31.560]   Another thing he did, which was diabolical,
[01:04:31.560 --> 01:04:35.080]   is in order to make it that people could not accept Jews
[01:04:35.080 --> 01:04:37.680]   as refugees, if they were gonna leave Germany,
[01:04:37.680 --> 01:04:39.560]   they had to be penniless.
[01:04:39.560 --> 01:04:41.400]   So now you have, it's not like they're coming over
[01:04:41.400 --> 01:04:43.300]   with money and they can take care of themselves.
[01:04:43.300 --> 01:04:45.560]   No, no, they're gonna be completely destitute.
[01:04:45.560 --> 01:04:47.040]   - Makes it harder to accept them, yeah.
[01:04:47.040 --> 01:04:49.040]   - Millions of destitute people who don't speak the language,
[01:04:49.040 --> 01:04:50.680]   it's a tough sell.
[01:04:50.680 --> 01:04:53.200]   - So speaking of Goodwin's Law,
[01:04:53.200 --> 01:04:56.060]   what do you make of this condition,
[01:04:56.060 --> 01:04:58.920]   Trump derangement syndrome?
[01:04:58.920 --> 01:04:59.760]   - Yeah.
[01:04:59.760 --> 01:05:04.760]   - And the idea of comparing Trump to Hitler?
[01:05:05.000 --> 01:05:06.800]   - I think it's despicable.
[01:05:06.800 --> 01:05:08.920]   And I'll give you an example, something parallel
[01:05:08.920 --> 01:05:12.080]   that I think more people should be regarding as despicable.
[01:05:12.080 --> 01:05:15.680]   Earlier in 2020, we were all told
[01:05:15.680 --> 01:05:18.560]   that unless we were in Syria immediately,
[01:05:18.560 --> 01:05:20.860]   the Kurds were gonna be exterminated.
[01:05:20.860 --> 01:05:22.560]   They invoked the Holocaust.
[01:05:22.560 --> 01:05:24.680]   This is gonna be another genocide.
[01:05:24.680 --> 01:05:26.560]   And if you're not for this, you should,
[01:05:26.560 --> 01:05:29.600]   you're basically forcing another Holocaust.
[01:05:29.600 --> 01:05:31.880]   None of the people who use this argument,
[01:05:31.880 --> 01:05:33.960]   we didn't go to Syria, the Kurds were not exterminated,
[01:05:33.960 --> 01:05:36.800]   just vanished from the news, had any consequences
[01:05:36.800 --> 01:05:39.660]   for using this kind of a comparison.
[01:05:39.660 --> 01:05:44.520]   So I think it's really kind of fatuous.
[01:05:44.520 --> 01:05:46.880]   And I think it's amazing that people think Hitler's
[01:05:46.880 --> 01:05:49.200]   the only tyrant who ever lived.
[01:05:49.200 --> 01:05:52.220]   Like everyone who's bad is specifically Hitler.
[01:05:52.220 --> 01:05:54.060]   You know how you know he's not Hitler?
[01:05:54.060 --> 01:05:56.160]   Because you can tweet at him,
[01:05:56.160 --> 01:05:58.520]   and no one comes to your house to kill your family.
[01:05:58.520 --> 01:06:00.960]   Like that's kind of a big difference.
[01:06:00.960 --> 01:06:04.080]   Also the difference between Trump and many of his critics
[01:06:04.080 --> 01:06:06.680]   is that his grandchildren will be raised as Jews.
[01:06:06.680 --> 01:06:08.800]   So that's also kind of a,
[01:06:08.800 --> 01:06:11.520]   and Deborah Lipschitz talks about this a lot.
[01:06:11.520 --> 01:06:13.160]   The New York Times at the time,
[01:06:13.160 --> 01:06:16.440]   there's another book called "Buried by the Times"
[01:06:16.440 --> 01:06:18.680]   which talks about the New York Times in the World War II.
[01:06:18.680 --> 01:06:23.680]   Because the idea that Jews weren't white was a Hitler idea.
[01:06:23.680 --> 01:06:26.340]   The New York Times at the time,
[01:06:26.340 --> 01:06:30.600]   Salzburger, wanted to be against this idea.
[01:06:30.600 --> 01:06:34.440]   So they specifically downplayed the antisemitism
[01:06:34.440 --> 01:06:37.240]   as opposed to the Nazis are being oppressive.
[01:06:37.240 --> 01:06:40.600]   So the argument that you can separate Nazism
[01:06:40.600 --> 01:06:43.920]   from antisemitism is a historical debate people have.
[01:06:43.920 --> 01:06:46.560]   And my perspective is, I think it's,
[01:06:46.560 --> 01:06:51.160]   I do not find it convincing that you can separate those two.
[01:06:51.160 --> 01:06:54.320]   I think antisemitism was essential to Nazism.
[01:06:54.320 --> 01:06:57.040]   I think Nazism and Mussolini's fascism
[01:06:57.040 --> 01:06:58.520]   have very big differences.
[01:06:59.880 --> 01:07:03.040]   - Do you think antisemitism is fundamental
[01:07:03.040 --> 01:07:04.520]   to who Hitler was?
[01:07:04.520 --> 01:07:05.720]   Or was it just the,
[01:07:05.720 --> 01:07:07.520]   so this is the interesting thing is like,
[01:07:07.520 --> 01:07:12.520]   it was a tool that he saw as being effective?
[01:07:12.520 --> 01:07:13.840]   - No, he believed it.
[01:07:13.840 --> 01:07:17.680]   - So why do you see those as intricately connected?
[01:07:17.680 --> 01:07:21.240]   Could Hitler have accomplished the same amount
[01:07:21.240 --> 01:07:23.680]   or more without the Holocaust?
[01:07:23.680 --> 01:07:25.320]   - Yeah, 'cause think about how many resources
[01:07:25.320 --> 01:07:27.280]   you got to divert at a time
[01:07:27.280 --> 01:07:29.400]   where you have Operation Barbarossa with Stalin.
[01:07:29.400 --> 01:07:32.200]   So why are they so connected?
[01:07:32.200 --> 01:07:36.200]   Is it because Hitler was insane?
[01:07:36.200 --> 01:07:38.040]   Or was he a bad strategist?
[01:07:38.040 --> 01:07:39.480]   - He was obviously a bad strategist.
[01:07:39.480 --> 01:07:42.280]   He took, he had no need to open a second front.
[01:07:42.280 --> 01:07:45.320]   His generals, my understanding, told him this is crazy.
[01:07:45.320 --> 01:07:47.240]   It didn't work out for him at all.
[01:07:47.240 --> 01:07:52.240]   I mean, to draw Russia and her resources into that war,
[01:07:52.240 --> 01:07:55.060]   it makes absolutely no sense in retrospect.
[01:07:55.060 --> 01:07:56.560]   There's a book about, I forget what it's called,
[01:07:56.560 --> 01:07:57.960]   where it talked about him at that point
[01:07:57.960 --> 01:08:00.000]   was just high all the time on amphetamines
[01:08:00.000 --> 01:08:01.480]   and that could have affected his thinking.
[01:08:01.480 --> 01:08:03.280]   - Yeah, there's a really good book on drugs.
[01:08:03.280 --> 01:08:05.160]   I mean, I forget what it's called,
[01:08:05.160 --> 01:08:06.840]   but yeah, it's a really good one.
[01:08:06.840 --> 01:08:11.840]   - But it was, I mean, scapegoating is a big part and parcel
[01:08:11.840 --> 01:08:15.400]   of the Nazi mythology.
[01:08:15.400 --> 01:08:17.480]   And this kind of one universal figure
[01:08:17.480 --> 01:08:20.640]   to explain this kind of skeleton key.
[01:08:20.640 --> 01:08:22.120]   - But it could have been the communists.
[01:08:22.120 --> 01:08:24.400]   I mean, that could have been the source of the hatred.
[01:08:24.400 --> 01:08:25.320]   So like-- - But the communists
[01:08:25.320 --> 01:08:26.980]   didn't get Germany into World War I,
[01:08:26.980 --> 01:08:28.600]   like he said the Jews did.
[01:08:28.600 --> 01:08:33.600]   - It seems to me that the atrocity of the Holocaust
[01:08:33.600 --> 01:08:37.040]   is the reason we see Hitler as evil.
[01:08:37.040 --> 01:08:38.440]   - No, the reason we see Hitler as evil
[01:08:38.440 --> 01:08:40.420]   is 'cause of World War II propaganda still.
[01:08:40.420 --> 01:08:42.160]   Because we don't see Stalin as evil.
[01:08:42.160 --> 01:08:44.020]   - Right, that's my main point. - We don't see Mao as evil
[01:08:44.020 --> 01:08:45.520]   to that extent.
[01:08:45.520 --> 01:08:46.760]   I think that-- - Why?
[01:08:46.760 --> 01:08:47.600]   Like, why would you say that?
[01:08:47.600 --> 01:08:48.760]   - You know why? - The nature
[01:08:48.760 --> 01:08:49.840]   of that propaganda.
[01:08:49.840 --> 01:08:51.920]   - Because I think a lot of the problem
[01:08:51.920 --> 01:08:53.920]   for the certain type of mentality
[01:08:53.920 --> 01:08:56.400]   is Hitler didn't mass murder equally.
[01:08:56.400 --> 01:08:58.780]   So as long as you're killing just one group,
[01:08:58.780 --> 01:08:59.620]   it's a problem.
[01:08:59.620 --> 01:09:00.800]   But if you're murdering everyone equally,
[01:09:00.800 --> 01:09:02.880]   all of a sudden it's like, eh, what are you gonna do?
[01:09:02.880 --> 01:09:04.200]   So the fact, like you were saying,
[01:09:04.200 --> 01:09:06.200]   the Haldimard is not common knowledge,
[01:09:06.200 --> 01:09:09.520]   the fact that Mao's 50 million dead
[01:09:09.520 --> 01:09:10.500]   are not common knowledge,
[01:09:10.500 --> 01:09:14.200]   and Richard Nixon can be raising a glass to him in China,
[01:09:14.200 --> 01:09:16.000]   these are things that I think the West
[01:09:16.000 --> 01:09:18.020]   has not done a good job reconciling.
[01:09:18.020 --> 01:09:21.400]   - Knock, knock. - Who's there?
[01:09:21.400 --> 01:09:23.480]   - Frank. - Frank who?
[01:09:23.480 --> 01:09:26.440]   - Frank, you for being my friend, Michael.
[01:09:26.440 --> 01:09:28.120]   - And the heart attacks will say,
[01:09:28.120 --> 01:09:29.680]   Frank, you for being my friend.
[01:09:29.680 --> 01:09:31.880]   - Is it, is it, is it?
[01:09:31.880 --> 01:09:32.880]   - You gotta do it like this.
[01:09:32.880 --> 01:09:34.480]   - Okay, all right. - Yeah.
[01:09:34.480 --> 01:09:35.320]   - Okay.
[01:09:35.320 --> 01:09:38.680]   Now back to Hitler.
[01:09:38.680 --> 01:09:40.920]   (laughing)
[01:09:40.920 --> 01:09:45.920]   Do you think Hitler could have been stopped?
[01:09:45.920 --> 01:09:48.960]   We kind of talked about it a little bit
[01:09:48.960 --> 01:09:52.560]   in terms of how to, what is the brave thing to do
[01:09:52.560 --> 01:09:56.240]   in the time of Nazi Germany, but do you think,
[01:09:56.240 --> 01:09:58.000]   I mean, I'm not even gonna ask about Stalin
[01:09:58.000 --> 01:10:00.080]   in terms of could Stalin have been stopped,
[01:10:00.080 --> 01:10:02.440]   'cause probably the answer is there's no,
[01:10:02.440 --> 01:10:05.480]   but on the Hitler side, could Hitler have been stopped?
[01:10:05.480 --> 01:10:07.520]   - I think a lot of these things,
[01:10:07.520 --> 01:10:09.160]   a lot of luck has to play with it.
[01:10:09.160 --> 01:10:10.600]   He was almost assassinated.
[01:10:10.600 --> 01:10:14.480]   If you mean by like the West, it's very hard.
[01:10:14.480 --> 01:10:16.160]   I mean, yeah.
[01:10:16.160 --> 01:10:18.480]   - By the German people too, I mean, could,
[01:10:18.480 --> 01:10:23.240]   like if politically speaking, there was a rise to power
[01:10:23.240 --> 01:10:25.960]   through the '30s, through the '20s really,
[01:10:25.960 --> 01:10:28.960]   I mean, like can whoever, it's not about Hitler,
[01:10:28.960 --> 01:10:32.880]   it's about that kind of way of thinking,
[01:10:32.880 --> 01:10:37.760]   that totalitarian control that always leads to trouble,
[01:10:37.760 --> 01:10:40.000]   and sometimes on a mass scale,
[01:10:40.000 --> 01:10:41.760]   could that have been stopped in Germany
[01:10:41.760 --> 01:10:44.200]   or maybe in the Soviet Union?
[01:10:44.200 --> 01:10:46.160]   - Well, I think this is one of the best arguments
[01:10:46.160 --> 01:10:48.120]   against radicalization in the States,
[01:10:48.120 --> 01:10:52.600]   which is how do you engage when you have like 30%
[01:10:52.600 --> 01:10:55.760]   of the population who are members of a party,
[01:10:55.760 --> 01:10:59.040]   which is dedicated to systemically overthrowing
[01:10:59.040 --> 01:11:00.480]   the existing democracy?
[01:11:00.480 --> 01:11:04.800]   Stalin gave orders that the communists
[01:11:04.800 --> 01:11:09.160]   who had a pretty sizable population, the Reichstag,
[01:11:09.160 --> 01:11:11.160]   that their target shouldn't be the Nazis,
[01:11:11.160 --> 01:11:14.200]   but the liberals and the social Democrats,
[01:11:14.200 --> 01:11:16.680]   and they invented the term social fascist for them.
[01:11:16.680 --> 01:11:19.360]   So instead of, they're just like jihadis,
[01:11:19.360 --> 01:11:21.800]   instead of taking their sights on Nazism,
[01:11:21.800 --> 01:11:24.000]   they set their sights on the moderates,
[01:11:24.000 --> 01:11:27.360]   because they figured the choice between Hitler and us,
[01:11:27.360 --> 01:11:29.840]   we're gonna win, and this was a huge gamble,
[01:11:29.840 --> 01:11:32.400]   and they were all killed or had to flee,
[01:11:32.400 --> 01:11:34.760]   and the ones who fled were killed also by Stalin,
[01:11:34.760 --> 01:11:36.040]   so that's my understanding.
[01:11:36.040 --> 01:11:39.720]   So this is an easy way where he could have been
[01:11:39.720 --> 01:11:41.000]   certainly heavily mitigated.
[01:11:41.000 --> 01:11:43.360]   - What about France and England,
[01:11:43.360 --> 01:11:45.920]   that it was obvious that Hitler was lying,
[01:11:45.920 --> 01:11:48.880]   and they wanted peace so bad
[01:11:48.880 --> 01:11:50.960]   that they were willing to put up with it,
[01:11:50.960 --> 01:11:52.480]   even after Czechoslovakia?
[01:11:52.480 --> 01:11:58.080]   This is the anti-pacifist argument,
[01:11:58.080 --> 01:12:01.000]   which is like they should have
[01:12:01.000 --> 01:12:04.720]   threatened military force more.
[01:12:04.720 --> 01:12:07.520]   - But then the other anti-pacifist argument is,
[01:12:07.520 --> 01:12:11.280]   if you're gonna, remember Barack Obama had the red line,
[01:12:11.280 --> 01:12:13.720]   if you cross this red line in Syria, we're gonna go in,
[01:12:13.720 --> 01:12:15.520]   and Assad or whatever's like, yeah, cool,
[01:12:15.520 --> 01:12:17.880]   and he's like, oh, okay, well, sorry.
[01:12:17.880 --> 01:12:20.200]   So if you're a threatening force,
[01:12:20.200 --> 01:12:21.640]   there's the great song lyric,
[01:12:21.640 --> 01:12:25.640]   don't show your guns unless you intend to fight, right?
[01:12:25.640 --> 01:12:29.600]   So it's very clear with free countries
[01:12:29.600 --> 01:12:31.040]   through what's in the press,
[01:12:31.040 --> 01:12:33.240]   whether the institutional will is there
[01:12:33.240 --> 01:12:35.240]   to follow through on these threats,
[01:12:35.240 --> 01:12:38.760]   so I think it would have been very hard for Chamberlain
[01:12:38.760 --> 01:12:42.400]   to rally the British people to take on Hitler
[01:12:42.400 --> 01:12:44.160]   just after the great, I mean,
[01:12:44.160 --> 01:12:46.840]   the suffering that Britons took on the Great War,
[01:12:46.840 --> 01:12:49.040]   they still, obviously, it means so much more to them
[01:12:49.040 --> 01:12:50.600]   than it does to us in the West.
[01:12:50.600 --> 01:12:52.960]   - What about, what do you make of Churchill then?
[01:12:52.960 --> 01:12:56.760]   Like why was Churchill able to rally the British people?
[01:12:56.760 --> 01:13:01.680]   Why was he, like, do you give much credit to Churchill
[01:13:01.680 --> 01:13:06.240]   for being one of the great forces
[01:13:06.240 --> 01:13:08.280]   in stopping Hitler in World War II?
[01:13:08.280 --> 01:13:10.560]   - I don't think that's really in dispute.
[01:13:10.560 --> 01:13:12.640]   I think he was very much regarded
[01:13:12.640 --> 01:13:15.840]   as this kind of the right man at the right time,
[01:13:15.840 --> 01:13:19.160]   and I think Chamberlain took a gamble.
[01:13:19.160 --> 01:13:23.440]   The expression peace in our time was Neville Chamberlain
[01:13:23.440 --> 01:13:25.360]   when he signed the appeasement with Hitler,
[01:13:25.360 --> 01:13:27.520]   and he goes, "We now have peace in our time,
[01:13:27.520 --> 01:13:29.200]   "now go home and get a good night's sleep."
[01:13:29.200 --> 01:13:30.800]   That's what he said, 'cause he's like,
[01:13:30.800 --> 01:13:33.520]   "All right, he's gonna stop here."
[01:13:33.520 --> 01:13:37.840]   And it's not impossible that if you just gave,
[01:13:37.840 --> 01:13:40.280]   like if you gave Saddam Hussein Kuwait,
[01:13:40.280 --> 01:13:44.080]   it's not impossible that he's not gonna invade Saudi Arabia
[01:13:44.080 --> 01:13:45.080]   next, something like that.
[01:13:45.080 --> 01:13:48.440]   - Let's see, okay, but everything I've read,
[01:13:48.440 --> 01:13:54.280]   it's like, of course, there's, it's not impossible,
[01:13:54.280 --> 01:13:58.920]   but when you're in the room with Hitler,
[01:13:58.920 --> 01:14:01.480]   you should be able to see like man to man,
[01:14:01.480 --> 01:14:06.600]   like to me, a great leader should be able to see
[01:14:06.600 --> 01:14:10.680]   past the facade and see like, yes,
[01:14:10.680 --> 01:14:12.560]   everything in life is a risk,
[01:14:12.560 --> 01:14:15.280]   but it seems like the right risk to take with Hitler.
[01:14:15.280 --> 01:14:19.440]   Like it's surprising to me, I know there's charisma,
[01:14:19.440 --> 01:14:21.720]   but it's surprising to me people did not see
[01:14:21.720 --> 01:14:23.360]   through this facade.
[01:14:23.360 --> 01:14:26.080]   - I really hate the idea of hindsight
[01:14:26.080 --> 01:14:27.720]   in everything being 2020,
[01:14:27.720 --> 01:14:30.240]   and I think it's a very good idea generally,
[01:14:30.240 --> 01:14:32.800]   not most thinking generally, not in this specific instance,
[01:14:32.800 --> 01:14:34.880]   to give our ancestors more credit
[01:14:34.880 --> 01:14:37.080]   than we tend to give them,
[01:14:37.080 --> 01:14:39.120]   'cause people often, here's a great example
[01:14:39.120 --> 01:14:42.040]   from another context, which is lightning rods.
[01:14:42.040 --> 01:14:44.120]   People always talk about religious people being stupid
[01:14:44.120 --> 01:14:46.800]   and superstitious, and they weren't,
[01:14:46.800 --> 01:14:48.920]   they often were very well reasoned.
[01:14:48.920 --> 01:14:50.600]   An example of this is lightning rods,
[01:14:50.600 --> 01:14:54.280]   which is every year, whatever town,
[01:14:54.280 --> 01:14:56.160]   the church was the tallest building,
[01:14:56.160 --> 01:14:57.960]   and that's the one that always got hit by lightning
[01:14:57.960 --> 01:14:59.520]   and got caught on fire.
[01:14:59.520 --> 01:15:04.120]   Now, what, it's a coincidence that it's always the church?
[01:15:04.120 --> 01:15:06.320]   Like that makes logical sense.
[01:15:06.320 --> 01:15:09.360]   Now, they didn't realize, well, it's because it's the tallest
[01:15:09.360 --> 01:15:11.320]   and therefore that attracts the electricity,
[01:15:11.320 --> 01:15:13.120]   and in fact, when they invented lighting rods,
[01:15:13.120 --> 01:15:14.840]   this was a controversy 'cause it's like,
[01:15:14.840 --> 01:15:17.800]   well, how is God going to show his displeasure
[01:15:17.800 --> 01:15:19.120]   if now it's striking this lightning rod
[01:15:19.120 --> 01:15:20.400]   and not burning down the church?
[01:15:20.400 --> 01:15:24.680]   So a lot of times, things are a lot more coherent
[01:15:24.680 --> 01:15:26.600]   than we give them credit for,
[01:15:26.600 --> 01:15:30.720]   and again, Chamberlain, he's the head of a parliamentary
[01:15:30.720 --> 01:15:34.880]   party, so he does not have the freedom, in a sense,
[01:15:34.880 --> 01:15:36.880]   that a Hitler would to be like, all right,
[01:15:36.880 --> 01:15:38.760]   we're doing this again, boys.
[01:15:38.760 --> 01:15:40.360]   We don't know what it's like in the room with Hitler.
[01:15:40.360 --> 01:15:43.400]   Come on, that's, we really have no idea.
[01:15:43.400 --> 01:15:45.160]   - But I think you have to think about that, right?
[01:15:45.160 --> 01:15:49.240]   - Yeah, but you can, I can very easily see him in the room
[01:15:49.240 --> 01:15:52.440]   being very calm and charming, and then you think,
[01:15:52.440 --> 01:15:55.320]   okay, the guy with the speeches is the act,
[01:15:55.320 --> 01:15:57.520]   and he's putting on a show for his people,
[01:15:57.520 --> 01:15:59.360]   and this is the real one.
[01:15:59.360 --> 01:16:02.800]   - Okay, so let's take somebody as an example.
[01:16:02.800 --> 01:16:06.560]   Let's take our mutual friend, Vladimir Putin.
[01:16:06.560 --> 01:16:07.400]   - Yes.
[01:16:07.400 --> 01:16:08.240]   - Okay.
[01:16:08.240 --> 01:16:11.720]   I don't know why saying his name makes my voice crack.
[01:16:11.720 --> 01:16:12.560]   (both laugh)
[01:16:12.560 --> 01:16:14.120]   - 'Cause you're scared he could hear you.
[01:16:14.120 --> 01:16:15.200]   It's like Beetlejuice.
[01:16:15.200 --> 01:16:17.040]   Vlad, yeah.
[01:16:17.040 --> 01:16:21.760]   - So there's a lot of people that--
[01:16:21.760 --> 01:16:23.080]   - Was he the one who built you?
[01:16:23.080 --> 01:16:24.680]   (both laugh)
[01:16:24.680 --> 01:16:26.980]   - No, that was a collaboration.
[01:16:29.100 --> 01:16:33.280]   What's, it's a double-blind engineering effort
[01:16:33.280 --> 01:16:39.600]   where I was not told of who my maker was.
[01:16:39.600 --> 01:16:41.880]   There's a backstory, but--
[01:16:41.880 --> 01:16:45.680]   - There's a talking cricket, Pinocchio.
[01:16:45.680 --> 01:16:50.240]   You'll be a real voice.
[01:16:50.240 --> 01:16:54.720]   - I talk about him quite a bit
[01:16:54.720 --> 01:16:57.960]   because I find him fascinating.
[01:16:57.960 --> 01:17:01.660]   Now, there's a really important line that people say,
[01:17:01.660 --> 01:17:05.140]   like, why does Lex admire Putin?
[01:17:05.140 --> 01:17:07.340]   I do not admire Putin.
[01:17:07.340 --> 01:17:08.860]   I find the man fascinating.
[01:17:08.860 --> 01:17:10.940]   I find Hitler fascinating.
[01:17:10.940 --> 01:17:14.220]   I find a lot of figures in history fascinating,
[01:17:14.220 --> 01:17:16.880]   both good and bad.
[01:17:16.880 --> 01:17:20.420]   And the figures, just as you said,
[01:17:20.420 --> 01:17:22.940]   that are with us today, like Vladimir Putin,
[01:17:22.940 --> 01:17:25.660]   like Donald Trump, like Barack Obama,
[01:17:25.660 --> 01:17:26.900]   it's difficult to place them
[01:17:26.900 --> 01:17:28.600]   on the spectrum of good and evil
[01:17:28.600 --> 01:17:30.720]   because that's only really applies
[01:17:30.720 --> 01:17:33.560]   to when you see the consequences of their action
[01:17:33.560 --> 01:17:35.460]   in a historical context.
[01:17:35.460 --> 01:17:39.900]   So there's some people who say that Vladimir Putin is evil.
[01:17:39.900 --> 01:17:45.120]   And based on our discussion about Hitler,
[01:17:45.120 --> 01:17:46.560]   that's something I think about a lot,
[01:17:46.560 --> 01:17:49.640]   which is in the room with Putin,
[01:17:49.640 --> 01:17:52.720]   and there's also a lot of historical descriptions
[01:17:52.720 --> 01:17:55.180]   of what it's like to be in the room
[01:17:55.180 --> 01:17:57.120]   with Hitler in the 1930s.
[01:17:57.120 --> 01:17:58.860]   There is a lot of charisma.
[01:17:58.860 --> 01:18:03.860]   In the same way, I find Putin to be very charismatic
[01:18:03.860 --> 01:18:05.680]   in his own way.
[01:18:05.680 --> 01:18:07.560]   The humor, the wit, the brilliance,
[01:18:07.560 --> 01:18:14.460]   there's a simplicity of the way he thinks
[01:18:14.460 --> 01:18:19.240]   that really, if taken at face value,
[01:18:19.240 --> 01:18:22.680]   looks like a very intelligent, honest man,
[01:18:24.120 --> 01:18:29.120]   thinking practically about how to build a better Russia,
[01:18:29.120 --> 01:18:33.360]   constantly, almost like an executive.
[01:18:33.360 --> 01:18:39.060]   He looks like a man who loves his job
[01:18:39.060 --> 01:18:42.280]   in a way that Trump, for example, doesn't,
[01:18:42.280 --> 01:18:46.060]   meaning he loves laws and rules and how to--
[01:18:46.060 --> 01:18:48.940]   - He has no adversarial press, so that's gonna help.
[01:18:48.940 --> 01:18:49.780]   - Yes.
[01:18:49.780 --> 01:18:50.600]   - And he's popular with his people.
[01:18:50.600 --> 01:18:51.980]   That's also gonna help enormously.
[01:18:51.980 --> 01:18:55.560]   - I'm talking about strictly the man,
[01:18:55.560 --> 01:18:57.880]   directly the words coming out of his mouth.
[01:18:57.880 --> 01:19:00.260]   Like all the videos and interviews I watch,
[01:19:00.260 --> 01:19:02.920]   based on that, not the press, not the reporting.
[01:19:02.920 --> 01:19:05.280]   You can just see that here's a man
[01:19:05.280 --> 01:19:10.280]   who's able to display a charisma that's not,
[01:19:10.280 --> 01:19:12.680]   like I can see, that's why I love Joe Rogan,
[01:19:12.680 --> 01:19:17.180]   is like you could tell the guy is genuine
[01:19:17.180 --> 01:19:18.480]   and is a good person.
[01:19:18.480 --> 01:19:20.920]   And you could tell immediately that
[01:19:20.920 --> 01:19:23.520]   once you meet Joe that he's going to be offline,
[01:19:23.520 --> 01:19:24.500]   also a good person.
[01:19:24.500 --> 01:19:26.980]   You could tell there's like signals that we send
[01:19:26.980 --> 01:19:29.120]   that are like difficult to kind of describe.
[01:19:29.120 --> 01:19:33.680]   In the same way, you could tell Putin is like,
[01:19:33.680 --> 01:19:36.620]   he genuinely loves his job
[01:19:36.620 --> 01:19:37.960]   and wants to build a better Russia.
[01:19:37.960 --> 01:19:42.040]   There's the argument that he is actually
[01:19:42.040 --> 01:19:44.480]   an evil man behind that charisma,
[01:19:44.480 --> 01:19:48.680]   or is able to assassinate people,
[01:19:50.800 --> 01:19:53.040]   limit free press, all those kinds of things.
[01:19:53.040 --> 01:19:59.480]   Like that's, what do we do with that?
[01:19:59.480 --> 01:20:03.280]   So what do human beings like journalists
[01:20:03.280 --> 01:20:05.880]   or what do other leaders,
[01:20:05.880 --> 01:20:07.560]   when they're in the room with Putin,
[01:20:07.560 --> 01:20:09.200]   do with those kinds of notions
[01:20:09.200 --> 01:20:13.220]   in deciding how to act in this world,
[01:20:13.220 --> 01:20:15.200]   in deciding what policy to enact,
[01:20:15.200 --> 01:20:16.040]   all those kinds of things.
[01:20:16.040 --> 01:20:17.200]   Just like with Hitler,
[01:20:17.200 --> 01:20:19.920]   when Chairman is in the room with Hitler,
[01:20:19.920 --> 01:20:23.000]   how does he decide how to act?
[01:20:23.000 --> 01:20:25.520]   - Well, let's go back to like my wheelhouse,
[01:20:25.520 --> 01:20:27.200]   which is North Korea, right?
[01:20:27.200 --> 01:20:32.200]   So when your entire world is based on being against Trump
[01:20:32.200 --> 01:20:35.120]   and everything Trump does is buffoonery
[01:20:35.120 --> 01:20:36.980]   or kind of productive,
[01:20:36.980 --> 01:20:38.640]   the conclusion of your reporting
[01:20:38.640 --> 01:20:41.160]   is gonna be pretty much given.
[01:20:41.160 --> 01:20:44.160]   I was very hopeful that there would be
[01:20:44.160 --> 01:20:46.560]   some positive outlooks or outcomes rather
[01:20:46.560 --> 01:20:48.520]   of Trump's meeting with Kim Jong-un.
[01:20:49.760 --> 01:20:51.240]   It looked like there was a space
[01:20:51.240 --> 01:20:53.160]   for things to go a bit better.
[01:20:53.160 --> 01:20:54.960]   I talked about it a lot at the time.
[01:20:54.960 --> 01:21:01.840]   And Trump was under no illusions
[01:21:01.840 --> 01:21:03.920]   about who he was dealing with.
[01:21:03.920 --> 01:21:08.520]   People pretend that, oh, he was kind of naive.
[01:21:08.520 --> 01:21:10.960]   He had one of the refugees at his State of the Union,
[01:21:10.960 --> 01:21:13.040]   you know, lifting up his crutch.
[01:21:13.040 --> 01:21:16.200]   The first thing he sat down and talked to Xi Jinping about
[01:21:16.200 --> 01:21:18.340]   in Mar-a-Lago right after he became inaugurated
[01:21:18.340 --> 01:21:19.480]   was North Korea.
[01:21:19.480 --> 01:21:22.640]   Barack Obama said that when he sat down Trump
[01:21:22.640 --> 01:21:24.840]   in the White House during the transfer of power,
[01:21:24.840 --> 01:21:26.960]   he said North Korea is the biggest issue.
[01:21:26.960 --> 01:21:30.580]   So I think a good leader,
[01:21:30.580 --> 01:21:32.920]   whether or not you consider Trump a good leader,
[01:21:32.920 --> 01:21:34.940]   has to be aware of, all right,
[01:21:34.940 --> 01:21:39.400]   I'm gonna have to have relationships of some kind,
[01:21:39.400 --> 01:21:41.400]   even if it's adversarial,
[01:21:41.400 --> 01:21:45.320]   with some really evil, evil, horrible people,
[01:21:45.320 --> 01:21:47.800]   which Kim Jong-un clearly is.
[01:21:47.800 --> 01:21:50.160]   - Well, I don't think there's anybody
[01:21:50.160 --> 01:21:53.240]   that has a perspective that North Korean,
[01:21:53.240 --> 01:21:57.560]   Kim Jong-un or Il are not evil, right?
[01:21:57.560 --> 01:21:58.400]   - Correct.
[01:21:58.400 --> 01:22:03.800]   - But with, in 1930s Germany,
[01:22:03.800 --> 01:22:06.240]   isn't it a little bit more nuanced?
[01:22:06.240 --> 01:22:07.920]   - Yeah, because Hitler hasn't done anything yet,
[01:22:07.920 --> 01:22:11.320]   and he's just a blowhard, and he's an anti-Semite, sure.
[01:22:11.320 --> 01:22:12.760]   But he's-- - What about, like,
[01:22:12.760 --> 01:22:15.000]   before the war breaks out,
[01:22:15.000 --> 01:22:20.000]   like, what about the basic, actionable anti-Semitism
[01:22:20.000 --> 01:22:23.040]   when you're, like, just attacking, hurting--
[01:22:23.040 --> 01:22:23.960]   - We're talking Kristallnacht,
[01:22:23.960 --> 01:22:26.040]   or we're talking about the Night of Long Knives?
[01:22:26.040 --> 01:22:28.520]   - Kristallnacht, so it's the Night of the Broken Glass.
[01:22:28.520 --> 01:22:30.360]   - Yeah, yeah, no, Long Knives is when he assassinated
[01:22:30.360 --> 01:22:32.840]   a bunch of his people, that was something different.
[01:22:32.840 --> 01:22:36.440]   - Yeah, so like, when you're actually attacking
[01:22:36.440 --> 01:22:37.680]   your own citizenry.
[01:22:37.680 --> 01:22:41.200]   - Yeah, that was universally condemned, Kristallnacht,
[01:22:41.200 --> 01:22:45.400]   and that was very shocking, its level of barbarism
[01:22:45.400 --> 01:22:51.560]   to the West, because I think we still want to believe,
[01:22:51.560 --> 01:22:57.200]   understandably, that things aren't as bad as they seem.
[01:22:57.200 --> 01:23:00.360]   We would rather, this is why, you know,
[01:23:00.360 --> 01:23:02.520]   the North Korea book I did, "Dear Reader,"
[01:23:02.520 --> 01:23:06.680]   is used in a humorous framework,
[01:23:06.680 --> 01:23:09.520]   because if you have to look, it's like looking to the sun.
[01:23:09.520 --> 01:23:12.520]   If you stare at it straight on, it's very hard to do,
[01:23:12.520 --> 01:23:14.840]   so you have to kind of look at it obliquely,
[01:23:14.840 --> 01:23:17.720]   and then you're kind of realizing
[01:23:17.720 --> 01:23:19.560]   the enormity of the depravity.
[01:23:19.560 --> 01:23:24.240]   And again, pogroms in Russia had been a thing
[01:23:24.240 --> 01:23:27.760]   for a very long time, and there's a difference between,
[01:23:27.760 --> 01:23:30.320]   okay, you know, we're gonna sack these villages
[01:23:30.320 --> 01:23:33.240]   and persecute people, and we're gonna systematically
[01:23:33.240 --> 01:23:36.400]   exterminate them, there's still levels
[01:23:36.400 --> 01:23:38.640]   of evil and depravity.
[01:23:38.640 --> 01:23:40.480]   - So you did write the book, "Dear Reader,"
[01:23:40.480 --> 01:23:43.200]   on Kim Jong-il, "Dear Reader,"
[01:23:43.200 --> 01:23:48.200]   the unauthorized autobiography of Kim Jong-il.
[01:23:48.200 --> 01:23:50.880]   So that's the previous leader of North Korea,
[01:23:50.880 --> 01:23:53.720]   current one is the un-- - Jong-un.
[01:23:53.720 --> 01:23:56.320]   - No creativity on the naming.
[01:23:56.320 --> 01:23:57.840]   - Well, no, this is intentional,
[01:23:57.840 --> 01:24:01.840]   'cause it's a throwback to the dad.
[01:24:01.840 --> 01:24:06.000]   - So there's been only three leaders in North Korea?
[01:24:06.000 --> 01:24:08.400]   So we've talked about the history of Hitler and Stalin,
[01:24:08.400 --> 01:24:10.520]   and unlike these, I think it's important to understand
[01:24:10.520 --> 01:24:13.320]   that the history of those kinds of humans,
[01:24:13.320 --> 01:24:17.240]   the history of North Korea is not well written about
[01:24:17.240 --> 01:24:18.760]   or understood, which is why your book
[01:24:18.760 --> 01:24:21.120]   is exceptionally powerful and important.
[01:24:21.120 --> 01:24:26.000]   So maybe in a big, broad way,
[01:24:26.000 --> 01:24:31.000]   can you say who was, who is Kim Jong-il
[01:24:31.000 --> 01:24:36.720]   as a man, as a leader, as a historical figure
[01:24:36.720 --> 01:24:39.000]   that we should understand and why should we understand them?
[01:24:39.000 --> 01:24:41.720]   - So I wrote "Dear Reader" by going to North Korea
[01:24:41.720 --> 01:24:44.120]   and getting all their propaganda,
[01:24:44.120 --> 01:24:45.840]   which is translated into several languages,
[01:24:45.840 --> 01:24:47.200]   'cause the conceit is everyone on Earth
[01:24:47.200 --> 01:24:51.200]   is interested in them and wants to mirror their ideology.
[01:24:51.200 --> 01:24:53.280]   - And he died in 2011. - 2011, yeah.
[01:24:53.280 --> 01:24:55.640]   - And you wrote the book in 2012.
[01:24:55.640 --> 01:24:58.520]   - I went there in 2012, I wrote the book, came out in 2014.
[01:24:58.520 --> 01:25:02.480]   So Kim Jong-il is, though not an intellect,
[01:25:02.480 --> 01:25:04.600]   North Korea's version of Forrest Gump,
[01:25:04.600 --> 01:25:05.840]   in that when they write their history,
[01:25:05.840 --> 01:25:08.520]   whenever something happens, he's there.
[01:25:08.520 --> 01:25:12.280]   And by telling his life story, it's in the first person,
[01:25:12.280 --> 01:25:14.400]   he's telling the history of North Korea.
[01:25:14.400 --> 01:25:18.320]   So I wanted to write the kind of book where in one book,
[01:25:18.320 --> 01:25:19.520]   and it's the kind of reading you could do
[01:25:19.520 --> 01:25:21.080]   in the beach or the bathroom,
[01:25:21.080 --> 01:25:22.320]   you're gonna get the entire history
[01:25:22.320 --> 01:25:23.800]   and know everything you need to know about North Korea
[01:25:23.800 --> 01:25:26.280]   in one accessible outlet.
[01:25:26.280 --> 01:25:30.880]   And it's, what people don't appreciate about North Korea,
[01:25:30.880 --> 01:25:33.320]   there's several things, how bad it is.
[01:25:33.320 --> 01:25:35.260]   And this didn't happen overnight.
[01:25:35.260 --> 01:25:37.080]   This was very systemic,
[01:25:37.080 --> 01:25:39.320]   that what this family did to that country,
[01:25:39.320 --> 01:25:43.000]   where piece by piece, they did everything in their power
[01:25:43.000 --> 01:25:46.200]   to hermetically seal it from the rest of the world,
[01:25:46.200 --> 01:25:50.360]   ramp up the oppression, keep any information from coming in.
[01:25:50.360 --> 01:25:54.120]   And they're very creative and innovative
[01:25:54.120 --> 01:25:58.820]   in their style of manipulation and control.
[01:25:58.820 --> 01:26:03.080]   So there is a farcical element.
[01:26:03.080 --> 01:26:04.120]   Let me give you an example.
[01:26:04.120 --> 01:26:05.740]   So people in the West kind of get it wrong.
[01:26:05.740 --> 01:26:08.560]   They talk about, oh, they talk about when Kim Jong-il
[01:26:08.560 --> 01:26:11.580]   played golf for the first time, he gets 17 holes in one.
[01:26:11.580 --> 01:26:15.620]   There's this one story about Kim Jong-il shrinking time.
[01:26:15.620 --> 01:26:20.220]   And this is a story, it sounds supernatural, but it's not.
[01:26:20.220 --> 01:26:23.380]   So Kim Jong-il is at a conference, the Dear Leader,
[01:26:23.380 --> 01:26:25.220]   and someone is giving a talk.
[01:26:25.220 --> 01:26:27.340]   And while that person is giving a talk,
[01:26:27.340 --> 01:26:31.100]   Kim Jong-il is taking notes and working on his work.
[01:26:31.100 --> 01:26:32.700]   And he has an aide who keeps interrupting him
[01:26:32.700 --> 01:26:35.000]   with questions and the speaker keeps stopping.
[01:26:35.000 --> 01:26:37.880]   And Kim Jong-il says, "Why are you stopping?"
[01:26:37.880 --> 01:26:39.760]   Goes, "I see you're doing these other things."
[01:26:39.760 --> 01:26:42.400]   And he goes, "No, no, I can do all these things at once."
[01:26:42.400 --> 01:26:43.800]   Everyone's shocked.
[01:26:43.800 --> 01:26:47.120]   And they said, "This is why Kim Jong-il looks at time
[01:26:47.120 --> 01:26:51.520]   "not like a plane, but like a cube, and he can shrink time."
[01:26:51.520 --> 01:26:54.440]   And my friend goes, "Do they mean multitasking?"
[01:26:54.440 --> 01:26:57.520]   And yes, Kim Jong-il is the only person in North Korea
[01:26:57.520 --> 01:26:59.940]   who's capable of multitasking.
[01:26:59.940 --> 01:27:02.720]   So in order to elevate him,
[01:27:02.720 --> 01:27:05.360]   they basically make everyone else in North Korea
[01:27:05.360 --> 01:27:07.880]   completely incompetent.
[01:27:07.880 --> 01:27:14.320]   And that has a purpose because should the leader go away,
[01:27:14.320 --> 01:27:16.560]   this country is gonna collapse overnight.
[01:27:16.560 --> 01:27:19.080]   So they laugh in the West
[01:27:19.080 --> 01:27:22.320]   about all these newspapers show him at the factory
[01:27:22.320 --> 01:27:24.960]   and he's at the fish hatchery, at the paper plant.
[01:27:24.960 --> 01:27:27.620]   They say the difference in North Korea
[01:27:27.620 --> 01:27:29.840]   is that the leader goes among the people
[01:27:29.840 --> 01:27:31.820]   and does what he calls field guidance.
[01:27:31.820 --> 01:27:33.460]   So he will go in that farm and be like,
[01:27:33.460 --> 01:27:34.380]   "This is what you need to do."
[01:27:34.380 --> 01:27:37.740]   And he'll go here and he's so smart, he's good at everything
[01:27:37.740 --> 01:27:39.840]   and thanks to him for sharing his wisdom with us.
[01:27:39.840 --> 01:27:42.080]   And he's not removed from the people
[01:27:42.080 --> 01:27:43.620]   like in every other country.
[01:27:43.620 --> 01:27:47.760]   - Why does that seem to go wrong with humans, do you think?
[01:27:47.760 --> 01:27:50.120]   That this kind of, the structure
[01:27:50.120 --> 01:27:53.520]   where there's this one figure, this authoritarian,
[01:27:53.520 --> 01:27:58.380]   this totalitarian structure where there's one figure
[01:27:58.380 --> 01:28:00.500]   that's a source of comfort and knowledge.
[01:28:00.500 --> 01:28:03.100]   - Kim Jong-il is not good at farming.
[01:28:03.100 --> 01:28:05.960]   Kim Jong-il is not good at the machinery.
[01:28:05.960 --> 01:28:07.680]   It's all a complete lie.
[01:28:07.680 --> 01:28:08.760]   Or the things he'll point out
[01:28:08.760 --> 01:28:10.020]   will be things that are completely obvious.
[01:28:10.020 --> 01:28:12.840]   So here's another example that they use.
[01:28:12.840 --> 01:28:14.300]   In North Korea, they have something called
[01:28:14.300 --> 01:28:16.660]   the Tower of the Juche Idea, which is an obelisk,
[01:28:16.660 --> 01:28:18.340]   which looks like the Washington Monument,
[01:28:18.340 --> 01:28:19.780]   but it's completely different
[01:28:19.780 --> 01:28:22.900]   'cause it's got this like plastic torch at the top.
[01:28:22.900 --> 01:28:25.420]   And they talk about in their propaganda
[01:28:25.420 --> 01:28:29.920]   how all the architects got together and they said,
[01:28:29.920 --> 01:28:33.920]   "Oh, we should make this the second tallest
[01:28:33.920 --> 01:28:35.380]   "stone obelisk in the world."
[01:28:35.380 --> 01:28:39.260]   And Kim Jong-il says, "No, let's make it the tallest."
[01:28:39.260 --> 01:28:41.560]   They're like, "Oh, we never thought of this before."
[01:28:41.560 --> 01:28:43.540]   And the way it's presented as it,
[01:28:43.540 --> 01:28:45.980]   and like he's the first person to think of this,
[01:28:45.980 --> 01:28:48.420]   like these architects are having a brainstorming session
[01:28:48.420 --> 01:28:49.460]   at the Tower of the Juche Idea.
[01:28:49.460 --> 01:28:52.360]   They're like, "All right, we gotta do something innovative
[01:28:52.360 --> 01:28:53.540]   "to put North Korea on the map.
[01:28:53.540 --> 01:28:54.620]   "What can we do?
[01:28:54.620 --> 01:28:56.380]   "How about second biggest?"
[01:28:56.380 --> 01:28:58.100]   He's gonna go for this.
[01:28:58.100 --> 01:28:59.940]   And then he's like, "Oh, we never thought of this."
[01:28:59.940 --> 01:29:04.780]   It's so, because I present it at face value,
[01:29:04.780 --> 01:29:06.700]   people sometimes say the book's a satire.
[01:29:06.700 --> 01:29:07.560]   It's not a satire.
[01:29:07.560 --> 01:29:09.340]   I downplayed all this stuff.
[01:29:09.340 --> 01:29:10.180]   It's a farce.
[01:29:10.180 --> 01:29:11.240]   Here's another example.
[01:29:11.240 --> 01:29:12.580]   North Korea is very big,
[01:29:12.580 --> 01:29:14.220]   and I think Russia is to some extent too,
[01:29:14.220 --> 01:29:16.100]   on amusement parks, fun fairs, they call them,
[01:29:16.100 --> 01:29:17.700]   in the British style,
[01:29:17.700 --> 01:29:19.260]   because this is a chance for the people
[01:29:19.260 --> 01:29:20.820]   to all get together.
[01:29:20.820 --> 01:29:22.780]   And there was this amusement park.
[01:29:22.780 --> 01:29:24.980]   It's almost like South Park, Cartman,
[01:29:24.980 --> 01:29:27.660]   where there's all these rides.
[01:29:27.660 --> 01:29:32.380]   And Kim Jong-il's like, "I'm not gonna let any elderly
[01:29:32.380 --> 01:29:34.380]   "or children take these rides
[01:29:34.380 --> 01:29:39.380]   "until I put myself in danger and ride them myself."
[01:29:39.380 --> 01:29:42.700]   And they go, "But dear leader, it's drizzling."
[01:29:42.700 --> 01:29:46.480]   And he goes, "No, I have to make sure these rides
[01:29:46.480 --> 01:29:47.980]   "are gonna be safe for everyone,
[01:29:47.980 --> 01:29:49.260]   "even during the light rain."
[01:29:49.260 --> 01:29:51.140]   They go, "Well, can we go on these rides with you?"
[01:29:51.140 --> 01:29:54.300]   "No, no, no, I have to be the courageous one."
[01:29:54.300 --> 01:29:55.500]   And he's riding all the rides,
[01:29:55.500 --> 01:29:58.020]   and they're standing there crying at his courage.
[01:29:58.020 --> 01:29:58.980]   But that's what's,
[01:29:58.980 --> 01:30:00.880]   and you ask all the thing in one power,
[01:30:00.880 --> 01:30:02.940]   it's like, listen, I'm quite confident
[01:30:02.940 --> 01:30:06.200]   that those fun fair engineers are in a position
[01:30:06.200 --> 01:30:09.180]   to ride Modest Mouse, whatever it's called, by themselves,
[01:30:09.180 --> 01:30:12.100]   and be like, "Yeah, okay, this is good for the kids."
[01:30:12.100 --> 01:30:14.380]   Although to be fair, some of those amusement parks
[01:30:14.380 --> 01:30:16.420]   are pretty rusty and dangerous.
[01:30:16.420 --> 01:30:18.960]   - Yeah, but that kind of propaganda,
[01:30:19.780 --> 01:30:22.220]   I guess what I'm playing a devil's advocate,
[01:30:22.220 --> 01:30:25.260]   is like, it's comforting and it's useful,
[01:30:25.260 --> 01:30:28.740]   but it does seem that that naturally leads
[01:30:28.740 --> 01:30:32.060]   to an abuse of power.
[01:30:32.060 --> 01:30:34.180]   - No, it's not, how can it be used correctly?
[01:30:34.180 --> 01:30:37.620]   No one person has the intellect or the mind
[01:30:37.620 --> 01:30:40.700]   to understand the entirety of an economy,
[01:30:40.700 --> 01:30:43.420]   let alone every individual field of interest.
[01:30:43.420 --> 01:30:44.240]   - Well, for example,
[01:30:44.240 --> 01:30:45.860]   you can have an artificial intelligence system
[01:30:45.860 --> 01:30:48.540]   that understands the entirety of it.
[01:30:48.540 --> 01:30:50.500]   - Did your affect just completely change?
[01:30:50.500 --> 01:30:52.180]   The mask slipped?
[01:30:52.180 --> 01:30:54.100]   I guess you could have an artificial intelligence system.
[01:30:54.100 --> 01:30:55.580]   (both laughing)
[01:30:55.580 --> 01:31:00.180]   - But the question is, can that,
[01:31:00.180 --> 01:31:03.340]   I mean, the human version of that is like,
[01:31:03.340 --> 01:31:05.180]   you can hire a lot of experts, right?
[01:31:05.180 --> 01:31:07.380]   You can be an extremely good manager.
[01:31:07.380 --> 01:31:09.780]   - Yeah, and since everything's dynamic,
[01:31:09.780 --> 01:31:13.500]   they're not gonna have the data to kind of manage it well.
[01:31:13.500 --> 01:31:14.700]   - It seems that there's a,
[01:31:14.700 --> 01:31:17.900]   like what George Washington allegedly did,
[01:31:17.900 --> 01:31:21.380]   it seems like most humans are not able to fire themselves.
[01:31:21.380 --> 01:31:23.900]   You're not able to like,
[01:31:23.900 --> 01:31:24.740]   - Yeah, you're right.
[01:31:24.740 --> 01:31:25.940]   - Ultimately be a check on your own power,
[01:31:25.940 --> 01:31:28.460]   but that's not, if I was like,
[01:31:28.460 --> 01:31:30.020]   if I was creating a human,
[01:31:30.020 --> 01:31:34.980]   it's like, that's not an obvious bug of the system
[01:31:34.980 --> 01:31:39.980]   that we would not be able to fire ourselves
[01:31:39.980 --> 01:31:42.700]   to know when we have,
[01:31:42.700 --> 01:31:44.140]   I mean, it seems like that's something
[01:31:44.140 --> 01:31:45.420]   you have to know always.
[01:31:45.420 --> 01:31:47.780]   Like that's something I often wonder is like,
[01:31:47.780 --> 01:31:49.500]   am I wrong about this?
[01:31:49.500 --> 01:31:50.900]   - Well, this is what we talked about earlier.
[01:31:50.900 --> 01:31:54.140]   What are the safety valves to make sure that, okay,
[01:31:54.140 --> 01:31:57.420]   if I am incorrect or my knowledge is finite,
[01:31:57.420 --> 01:31:59.220]   Plato's cave kind of thing,
[01:31:59.220 --> 01:32:02.140]   what mechanisms are in place that my mistake
[01:32:02.140 --> 01:32:04.420]   or limited information isn't gonna have
[01:32:04.420 --> 01:32:06.660]   deleterious consequences?
[01:32:06.660 --> 01:32:07.940]   And North Korea does not really have that.
[01:32:07.940 --> 01:32:10.580]   And as a result, they had polio in the '90s.
[01:32:10.580 --> 01:32:14.780]   - So there is a, you write about it straight,
[01:32:14.780 --> 01:32:16.180]   but there's a humor to it
[01:32:16.180 --> 01:32:20.380]   because it's an absurdly evil place, I suppose.
[01:32:20.380 --> 01:32:21.940]   - Yeah.
[01:32:21.940 --> 01:32:25.700]   - A bunch of people, I asked,
[01:32:25.700 --> 01:32:27.020]   I said that I'm talking to you
[01:32:27.020 --> 01:32:28.820]   and a bunch of people asked questions.
[01:32:28.820 --> 01:32:31.340]   - Oh, I gotta hear from the plebs.
[01:32:31.340 --> 01:32:32.820]   You asked me before we started recording,
[01:32:32.820 --> 01:32:35.060]   I specifically said no, it was in my contract.
[01:32:35.060 --> 01:32:39.460]   - Yeah, and I gave you all the pink Skittles or whatever.
[01:32:39.460 --> 01:32:41.100]   But they--
[01:32:41.100 --> 01:32:43.580]   - So pink, you don't think.
[01:32:43.580 --> 01:32:44.540]   - I'm trolling, Michael.
[01:32:44.540 --> 01:32:46.460]   Let me explain to you how that works.
[01:32:46.460 --> 01:32:50.860]   If people should go at malice.locals.com
[01:32:50.860 --> 01:32:53.940]   and sign up and pay,
[01:32:53.940 --> 01:32:56.180]   I think the membership fee is several thousand dollars.
[01:32:56.180 --> 01:32:58.660]   It's very, it's not--
[01:32:58.660 --> 01:32:59.860]   - It's not for the layman.
[01:32:59.860 --> 01:33:02.300]   - Yeah, but the service is excellent.
[01:33:02.300 --> 01:33:05.300]   You get a coat with it.
[01:33:05.300 --> 01:33:06.620]   But yeah, I went there,
[01:33:06.620 --> 01:33:08.580]   posted a lot of really brilliant people there.
[01:33:08.580 --> 01:33:10.460]   People should join that community
[01:33:10.460 --> 01:33:13.420]   if you find Michael interesting
[01:33:13.420 --> 01:33:14.940]   or if you just wanna go and say,
[01:33:14.940 --> 01:33:17.340]   well, he's wrong, it's a great place to have that--
[01:33:17.340 --> 01:33:19.740]   - It's not a great place for that, I assure you.
[01:33:19.740 --> 01:33:23.060]   - Yeah, a lot of really kind people.
[01:33:23.060 --> 01:33:26.460]   So anyway, there's a bunch of people
[01:33:26.460 --> 01:33:28.500]   asked that we should talk about humor.
[01:33:28.500 --> 01:33:29.780]   - Okay.
[01:33:29.780 --> 01:33:32.180]   - So pretend, hypothetically speaking,
[01:33:32.180 --> 01:33:33.220]   that I'm a robot
[01:33:33.220 --> 01:33:38.220]   asking you to explain humor to me.
[01:33:38.220 --> 01:33:42.820]   So dear reader, I mean, there's a humor,
[01:33:42.820 --> 01:33:47.060]   there's just so wonderfully dance
[01:33:47.060 --> 01:33:49.980]   between serious dark topics
[01:33:49.980 --> 01:33:54.940]   and then seriously dark humor.
[01:33:54.940 --> 01:33:59.420]   Can you try to, if you were to write like a,
[01:33:59.420 --> 01:34:00.740]   I don't know, a Wikipedia article,
[01:34:00.740 --> 01:34:03.540]   maybe a book about your philosophy of humor,
[01:34:03.540 --> 01:34:05.660]   what do you think is the role of humor in all of this?
[01:34:05.660 --> 01:34:06.900]   - A joke is like a baby.
[01:34:06.900 --> 01:34:09.500]   You can't dissect it and then put it back together
[01:34:09.500 --> 01:34:10.660]   and expect it to work.
[01:34:10.660 --> 01:34:12.060]   Trust me on this one.
[01:34:12.060 --> 01:34:14.980]   Despite, no matter how you carve that thing up,
[01:34:14.980 --> 01:34:17.900]   it's not gonna be working the next day
[01:34:17.900 --> 01:34:20.180]   and you need it to sew those little sneakers
[01:34:20.180 --> 01:34:21.020]   with those hands.
[01:34:21.020 --> 01:34:22.340]   - Oh.
[01:34:22.340 --> 01:34:24.540]   - I don't know that humor is something
[01:34:24.540 --> 01:34:26.180]   that is very explainable.
[01:34:26.180 --> 01:34:28.420]   People, there's something called claptor
[01:34:28.420 --> 01:34:30.540]   where this is like the worst kind of humor
[01:34:30.540 --> 01:34:32.340]   where people applaud 'cause they agree
[01:34:32.340 --> 01:34:35.180]   with what you're saying as opposed to laptor.
[01:34:35.180 --> 01:34:37.020]   Well, that's the kind of--
[01:34:37.020 --> 01:34:37.900]   - That's the poetry reading?
[01:34:37.900 --> 01:34:40.220]   - Yeah, and the drag queens do that too.
[01:34:41.340 --> 01:34:43.540]   I think 'cause they have the nails.
[01:34:43.540 --> 01:34:45.860]   This, you laugh, it's a visceral reaction.
[01:34:45.860 --> 01:34:48.060]   When someone on Twitter is insisting,
[01:34:48.060 --> 01:34:49.660]   you know, that's not funny,
[01:34:49.660 --> 01:34:52.300]   you're not in a position to make that claim.
[01:34:52.300 --> 01:34:54.900]   And let's go back to North Korea.
[01:34:54.900 --> 01:34:59.420]   I had a refugee I knew and he went to high school here
[01:34:59.420 --> 01:35:02.000]   and he was talking to his buddies and they said,
[01:35:02.000 --> 01:35:05.260]   "Hey, remember when we were kids, we had Pokemon?"
[01:35:05.260 --> 01:35:06.860]   And he goes, "Oh yeah, except instead of Pokemon,
[01:35:06.860 --> 01:35:09.580]   "I watched my dad starve to death," which is the truth.
[01:35:09.580 --> 01:35:14.580]   Now, who are any of us to tell him not to make that joke?
[01:35:14.580 --> 01:35:17.100]   I don't know what it's like watching anyone,
[01:35:17.100 --> 01:35:19.300]   including my dad, starve to death.
[01:35:19.300 --> 01:35:22.400]   And my dad's fatty so he's not going hungry anytime soon.
[01:35:22.400 --> 01:35:27.940]   So it's very bizarre to me
[01:35:27.940 --> 01:35:32.060]   when people feel comfortable precluding others
[01:35:32.060 --> 01:35:35.220]   from making jokes, especially,
[01:35:35.220 --> 01:35:36.440]   and I think this is a very Jewish thing,
[01:35:36.440 --> 01:35:38.300]   like this kind of gallows humor,
[01:35:38.300 --> 01:35:42.580]   especially when it's laughing about a personal loss
[01:35:42.580 --> 01:35:44.100]   or experience that they've had.
[01:35:44.100 --> 01:35:49.100]   Humor is a great way to mitigate pain and suffering.
[01:35:49.100 --> 01:35:52.700]   But it's also, I think this is why it's a Jewish thing,
[01:35:52.700 --> 01:35:53.660]   it's a black thing,
[01:35:53.660 --> 01:35:56.920]   when you are a marginalized community or poorer, it's free.
[01:35:56.920 --> 01:36:01.220]   Telling stories, telling jokes or songs,
[01:36:01.220 --> 01:36:03.140]   you don't have to have money,
[01:36:03.140 --> 01:36:05.600]   but you can have joy and happiness.
[01:36:05.600 --> 01:36:07.680]   And I think that's why you find it so much more
[01:36:07.680 --> 01:36:09.960]   in kind of lower status communities
[01:36:09.960 --> 01:36:14.180]   than you find in wasps who are notoriously humorless.
[01:36:14.180 --> 01:36:16.480]   - Which is strange because people pay you a lot of money
[01:36:16.480 --> 01:36:20.340]   for the jokes you do, so it's not really free.
[01:36:20.340 --> 01:36:22.420]   - Yeah, well, no, they don't have to pay me.
[01:36:22.420 --> 01:36:25.900]   It's appreciated but not expected.
[01:36:25.900 --> 01:36:27.460]   - I find my voice cracking every time
[01:36:27.460 --> 01:36:28.300]   I try to make a joke.
[01:36:28.300 --> 01:36:30.360]   Like I fail miserably at this.
[01:36:30.360 --> 01:36:32.660]   Some people--
[01:36:32.660 --> 01:36:34.740]   - You're still in beta, that's why.
[01:36:34.740 --> 01:36:35.580]   - Alpha.
[01:36:35.580 --> 01:36:36.780]   - Sure.
[01:36:36.780 --> 01:36:38.140]   - Being an alpha's like being a lady.
[01:36:38.140 --> 01:36:40.220]   If you have to tell people you are, you aren't.
[01:36:40.220 --> 01:36:42.740]   - No, I meant alpha version, not alpha male.
[01:36:42.740 --> 01:36:43.580]   - Okay.
[01:36:43.580 --> 01:36:46.460]   I don't know if you're a robot gobbledygook.
[01:36:46.460 --> 01:36:49.220]   - I'm not going there, okay.
[01:36:49.220 --> 01:36:51.260]   - Who are you talking to?
[01:36:51.260 --> 01:36:54.360]   - In my own head, I'm talking to myself in my own head.
[01:36:54.360 --> 01:36:56.500]   Okay, speaking of North Korea,
[01:36:56.500 --> 01:37:00.800]   some people say that, you know,
[01:37:00.800 --> 01:37:05.180]   I've read that comedy is about timing.
[01:37:05.180 --> 01:37:06.540]   Well, first of all, do you agree?
[01:37:06.540 --> 01:37:07.780]   And second of all--
[01:37:07.780 --> 01:37:08.980]   (laughing)
[01:37:08.980 --> 01:37:09.820]   - No, I'm serious.
[01:37:09.820 --> 01:37:10.660]   It's very much about timing.
[01:37:10.660 --> 01:37:13.260]   - You're saying yes, that timing, yeah, it's funny.
[01:37:13.260 --> 01:37:14.100]   Okay.
[01:37:14.100 --> 01:37:16.060]   - Isn't it comedy is tragedy plus timing?
[01:37:16.060 --> 01:37:18.260]   Isn't that the full reference?
[01:37:18.260 --> 01:37:20.720]   - What is it, the interrupting cow knock-knock joke?
[01:37:20.720 --> 01:37:22.420]   I'm not gonna do it, but--
[01:37:22.420 --> 01:37:23.780]   - That's not a timing thing.
[01:37:23.780 --> 01:37:27.580]   It's more of a repetition and then the twist ending.
[01:37:27.580 --> 01:37:28.420]   - No, the moo.
[01:37:28.420 --> 01:37:29.740]   - Oh, the moo, yeah, yeah, yeah.
[01:37:29.740 --> 01:37:30.780]   - Interrupting cow.
[01:37:30.780 --> 01:37:33.260]   You're thinking of the banana one.
[01:37:33.260 --> 01:37:37.060]   - Anyway, I'm not going there.
[01:37:37.060 --> 01:37:37.900]   Yet, you're--
[01:37:37.900 --> 01:37:39.460]   - Who are you talking to?
[01:37:39.460 --> 01:37:40.300]   - In my own head.
[01:37:40.300 --> 01:37:41.580]   - You have a thick floor.
[01:37:41.580 --> 01:37:42.780]   Do you have any earpiece?
[01:37:42.780 --> 01:37:43.780]   Are you small wonder?
[01:37:43.780 --> 01:37:46.100]   Do you stand sleeping in a wardrobe?
[01:37:46.100 --> 01:37:49.360]   - Yeah, God, that's so British.
[01:37:49.360 --> 01:37:51.180]   But yet, you're very--
[01:37:51.180 --> 01:37:52.740]   - I don't wanna say in a closet
[01:37:52.740 --> 01:37:54.260]   'cause that has connotations.
[01:37:54.260 --> 01:37:57.580]   - Let's both come out of the closet for a second.
[01:37:57.580 --> 01:37:58.900]   - I love you. - And let's talk about--
[01:37:58.900 --> 01:38:01.100]   - I love you, Lex.
[01:38:01.100 --> 01:38:02.820]   I wasn't saying I love you, Alex.
[01:38:02.820 --> 01:38:04.860]   I was saying I love you, Lex.
[01:38:04.860 --> 01:38:06.020]   - Oh, you're talking to me.
[01:38:06.020 --> 01:38:07.820]   - Yes, through the screen.
[01:38:07.820 --> 01:38:11.740]   - So, you think about me when you're with another man.
[01:38:11.740 --> 01:38:13.500]   - I watch you when you're sleeping.
[01:38:13.500 --> 01:38:15.540]   - Okay, so you're--
[01:38:15.540 --> 01:38:16.380]   - Like the Vengal song, "Eternal Flame."
[01:38:16.380 --> 01:38:18.300]   - You're really active on Twitter.
[01:38:18.300 --> 01:38:19.380]   - Yeah.
[01:38:19.380 --> 01:38:21.020]   - And somebody else asked
[01:38:21.020 --> 01:38:24.080]   on your overly expensive membership site.
[01:38:24.080 --> 01:38:27.100]   - My grift site.
[01:38:28.300 --> 01:38:33.300]   - How do you find humor different in writing on Twitter
[01:38:33.300 --> 01:38:34.700]   versus spoken humor?
[01:38:34.700 --> 01:38:36.260]   So, if-- - Oh, that's a great question.
[01:38:36.260 --> 01:38:38.100]   - If humor is about timing,
[01:38:38.100 --> 01:38:41.180]   how do you capture the timing and the brilliance
[01:38:41.180 --> 01:38:44.060]   of the whatever is underlying humor
[01:38:44.060 --> 01:38:45.260]   in a context of Twitter?
[01:38:45.260 --> 01:38:47.640]   Like, another way to say it is,
[01:38:47.640 --> 01:38:53.540]   how do you be funny and yet thoughtful on Twitter?
[01:38:53.540 --> 01:38:57.780]   - So, with Twitter, you have to be the first one
[01:38:57.780 --> 01:38:58.740]   to the punchline.
[01:38:58.740 --> 01:39:00.380]   So, when Ron Paul had his stroke,
[01:39:00.380 --> 01:39:01.780]   I was immediately being like,
[01:39:01.780 --> 01:39:03.700]   he's still the most articulate libertarian.
[01:39:03.700 --> 01:39:06.020]   He's doing a great Joe Biden impression right now.
[01:39:06.020 --> 01:39:08.300]   All the libertarians got ass-mad.
[01:39:08.300 --> 01:39:10.200]   And people are like, too soon.
[01:39:10.200 --> 01:39:12.480]   Or like when someone dies, you're making the jokes about them.
[01:39:12.480 --> 01:39:14.780]   It's like, when do you wanna make the jokes
[01:39:14.780 --> 01:39:16.020]   about someone just died a week later?
[01:39:16.020 --> 01:39:16.920]   It doesn't make any sense.
[01:39:16.920 --> 01:39:17.760]   Now, you might--
[01:39:17.760 --> 01:39:18.780]   - Too soon is perfect timing.
[01:39:18.780 --> 01:39:21.260]   - Or you could say, it's not appropriate ever.
[01:39:21.260 --> 01:39:24.900]   But too soon does not make sense in this context.
[01:39:24.900 --> 01:39:28.460]   So, that is something that I enjoy doing.
[01:39:28.460 --> 01:39:31.100]   It's also fun ruffling people's feathers,
[01:39:31.100 --> 01:39:32.580]   which is something I enjoy doing.
[01:39:32.580 --> 01:39:37.580]   I think spoken versus writing is very different
[01:39:37.580 --> 01:39:41.760]   because when you are having good banter with someone,
[01:39:41.760 --> 01:39:47.620]   for me as the audience, knowing that it is on the spot
[01:39:47.620 --> 01:39:50.220]   really adds an element of humor
[01:39:50.220 --> 01:39:51.800]   'cause then it's like, wow, this is fun.
[01:39:51.800 --> 01:39:54.060]   It's like a ping pong match or something.
[01:39:54.060 --> 01:39:57.900]   Whereas in writing, you're losing the tone,
[01:39:57.900 --> 01:40:02.660]   you're losing the relationship of a dynamic conversation.
[01:40:02.660 --> 01:40:05.500]   And a lot of times the joke
[01:40:05.500 --> 01:40:07.660]   is just gonna be a different type of joke.
[01:40:07.660 --> 01:40:10.580]   - Well, it's funny, but Twitter, there's a sense,
[01:40:10.580 --> 01:40:15.580]   especially your Twitter, that you just thought of that
[01:40:15.580 --> 01:40:16.900]   and you just wrote it.
[01:40:16.900 --> 01:40:17.740]   - Yes.
[01:40:17.740 --> 01:40:22.300]   - Like there's a feeling like it's literally you talking
[01:40:22.300 --> 01:40:26.460]   as opposed to what I imagine is there's some editing
[01:40:26.460 --> 01:40:27.940]   or it doesn't look like it.
[01:40:27.940 --> 01:40:29.900]   Whoever your editor is should be fired.
[01:40:29.900 --> 01:40:32.340]   (laughing)
[01:40:32.340 --> 01:40:33.940]   There's an interesting effect actually.
[01:40:33.940 --> 01:40:36.940]   If I want to say something, I don't know,
[01:40:36.940 --> 01:40:41.740]   about something that's bothering me
[01:40:41.740 --> 01:40:44.380]   about the presidential election or something like that.
[01:40:44.380 --> 01:40:47.260]   Like what is the actual central idea
[01:40:47.260 --> 01:40:48.780]   that I'm trying to convey to myself?
[01:40:48.780 --> 01:40:51.220]   Like if say I was having a hypothetical conversation
[01:40:51.220 --> 01:40:52.060]   with myself.
[01:40:52.060 --> 01:40:52.900]   - Okay.
[01:40:52.900 --> 01:40:53.720]   - What?
[01:40:53.720 --> 01:40:54.560]   No, not going there.
[01:40:54.560 --> 01:40:55.540]   (laughing)
[01:40:55.540 --> 01:40:57.460]   Why am I putting my pants back on?
[01:40:57.460 --> 01:40:58.980]   I'm more comfortable this way.
[01:40:58.980 --> 01:41:04.340]   Promo code malice20, sheathunderwear.com.
[01:41:04.340 --> 01:41:05.180]   Okay.
[01:41:05.180 --> 01:41:07.420]   (laughing)
[01:41:07.420 --> 01:41:12.580]   - That's sheath, what's the website?
[01:41:12.580 --> 01:41:13.620]   - Sheathunderwear.com.
[01:41:13.620 --> 01:41:17.420]   - Sheathunderwear.com, promo code malice20.
[01:41:17.420 --> 01:41:19.780]   And I forgot, why is that underwear really nice?
[01:41:19.780 --> 01:41:21.980]   - Because it has a dual pouch technology
[01:41:21.980 --> 01:41:23.300]   to keep your man parts separate.
[01:41:23.300 --> 01:41:24.500]   They've also got woman stuff,
[01:41:24.500 --> 01:41:25.540]   but I don't know how that works.
[01:41:25.540 --> 01:41:27.500]   There's a thing going somewhere.
[01:41:27.500 --> 01:41:29.100]   - And the material's really refreshing.
[01:41:29.100 --> 01:41:29.940]   I mean, it's really a good--
[01:41:29.940 --> 01:41:31.780]   - And it makes your ass look good.
[01:41:31.780 --> 01:41:35.380]   - That's promo code malice20.
[01:41:35.380 --> 01:41:39.220]   - And it's made by a former vet 'cause he was in Iraq.
[01:41:39.220 --> 01:41:40.780]   So that's why I like promoting it.
[01:41:40.780 --> 01:41:41.620]   - Yeah.
[01:41:41.620 --> 01:41:44.220]   But when I'm writing the tweet,
[01:41:44.220 --> 01:41:49.540]   it forces me to think deeply about the core of the message.
[01:41:49.540 --> 01:41:50.380]   - Okay.
[01:41:50.380 --> 01:41:52.900]   - But what I found, this really interesting effect,
[01:41:52.900 --> 01:41:55.020]   I don't really do much editing on the tweet.
[01:41:55.020 --> 01:41:57.860]   I'll just think and then I'll write it.
[01:41:57.860 --> 01:42:01.340]   And then when I post it, like submit,
[01:42:01.340 --> 01:42:04.920]   I immediately see the tweet very differently
[01:42:04.920 --> 01:42:06.620]   than it was in my mind.
[01:42:06.620 --> 01:42:08.820]   I often delete, I delete, I don't know,
[01:42:08.820 --> 01:42:13.380]   some percentage of tweets about two, five seconds after.
[01:42:13.380 --> 01:42:14.220]   - Wow.
[01:42:14.220 --> 01:42:17.020]   - I don't know, it's something, once you send it,
[01:42:17.020 --> 01:42:19.140]   it's why the Gmail send features,
[01:42:19.140 --> 01:42:21.400]   undo send features really nice.
[01:42:21.400 --> 01:42:24.200]   It's like, it just changes the way I see the thing.
[01:42:24.200 --> 01:42:25.040]   So--
[01:42:25.040 --> 01:42:26.300]   - That's very interesting.
[01:42:26.300 --> 01:42:28.260]   - But I really love it that you can delete it
[01:42:28.260 --> 01:42:32.900]   because when I say stuff out in the wild,
[01:42:32.900 --> 01:42:35.020]   like to other humans, like--
[01:42:35.020 --> 01:42:35.860]   - Other humans.
[01:42:35.860 --> 01:42:40.740]   - Spoken word is like, you can't delete what you just said.
[01:42:40.740 --> 01:42:44.900]   And I often regret the things I say, like on the spot.
[01:42:44.900 --> 01:42:46.220]   Like I shouldn't have said that.
[01:42:46.220 --> 01:42:47.060]   - Really?
[01:42:47.060 --> 01:42:47.880]   - Yeah.
[01:42:47.880 --> 01:42:48.720]   - I don't have that.
[01:42:48.720 --> 01:42:49.660]   (laughing)
[01:42:49.660 --> 01:42:52.820]   - Well, again, whoever your editor is,
[01:42:52.820 --> 01:42:55.540]   what is it, Edith Piaf,
[01:42:55.540 --> 01:42:58.460]   Jean-Eric A. Han.
[01:42:58.460 --> 01:43:01.420]   - Wow, your French is as bad as your English.
[01:43:01.420 --> 01:43:04.740]   I don't have any tweets I regret
[01:43:04.740 --> 01:43:08.980]   because if I sent a tweet that I regretted,
[01:43:08.980 --> 01:43:11.220]   I would make amends.
[01:43:11.220 --> 01:43:14.820]   I would make it a point if I was needlessly offensive
[01:43:14.820 --> 01:43:17.900]   to somebody or hurtful or accidentally,
[01:43:17.900 --> 01:43:21.980]   I would make sure to fix it and go out of my way
[01:43:21.980 --> 01:43:24.860]   to make sure that person feels vindicated
[01:43:24.860 --> 01:43:27.140]   and validated by accepting my apology.
[01:43:27.140 --> 01:43:30.100]   That has never happened, had to happen, thankfully.
[01:43:30.100 --> 01:43:35.100]   I'm also someone who is not big on taking the bait.
[01:43:35.100 --> 01:43:40.660]   Recently, some people have come after me pretty hard.
[01:43:40.660 --> 01:43:44.500]   And my perspective is that it's not really about me.
[01:43:44.500 --> 01:43:46.900]   It's either I represent something to them.
[01:43:46.900 --> 01:43:49.460]   I'm just some jackass with a Twitter.
[01:43:49.460 --> 01:43:51.880]   So if you're getting this riled up over me,
[01:43:51.880 --> 01:43:53.020]   it's not really about me.
[01:43:53.020 --> 01:43:55.460]   Maybe I'm delusional, but that's how I look at it.
[01:43:55.460 --> 01:43:57.100]   So if they are trying to provoke me
[01:43:57.100 --> 01:44:01.660]   into this kind of heated exchange, I will never do it
[01:44:01.660 --> 01:44:03.300]   because I'm not interested in it.
[01:44:03.300 --> 01:44:04.740]   And I don't think there's gonna be any,
[01:44:04.740 --> 01:44:08.220]   it's like Jeanette Rankin, you can't win.
[01:44:08.220 --> 01:44:10.580]   It's just gonna be like trying to win a hurricane.
[01:44:10.580 --> 01:44:12.300]   There's no hero here.
[01:44:12.300 --> 01:44:13.460]   - Well, let me ask you about this
[01:44:13.460 --> 01:44:14.820]   'cause somebody also asked it
[01:44:14.820 --> 01:44:17.580]   on your overly expensive membership site
[01:44:17.580 --> 01:44:20.580]   that they were saying that they're an academic.
[01:44:20.580 --> 01:44:22.540]   They wonder 'cause I'm an, quote unquote,
[01:44:22.540 --> 01:44:23.560]   I'm not an academic,
[01:44:23.560 --> 01:44:26.020]   but I do still have an affiliation with MIT.
[01:44:26.020 --> 01:44:28.580]   The word academic is just dirty.
[01:44:28.580 --> 01:44:30.400]   It's like-- - It is.
[01:44:30.400 --> 01:44:32.460]   - Which is a problem that needs to change.
[01:44:32.460 --> 01:44:34.820]   Just like the word nerd is dirty.
[01:44:34.820 --> 01:44:37.540]   - No, academic needs, is gonna be the next front to open
[01:44:37.540 --> 01:44:39.060]   and they're gonna be very vilified.
[01:44:39.060 --> 01:44:41.980]   We're coming for them and it's gonna be very, very ugly.
[01:44:41.980 --> 01:44:43.420]   And I cannot wait.
[01:44:43.420 --> 01:44:45.500]   - No, but there needs to be a place,
[01:44:45.500 --> 01:44:50.140]   a different term for people who love research
[01:44:50.140 --> 01:44:51.900]   and knowledge and-- - Oh, that's true.
[01:44:51.900 --> 01:44:53.740]   - Like you have to-- - No, you're right, 100%.
[01:44:53.740 --> 01:44:54.580]   - You're right.
[01:44:54.580 --> 01:44:58.040]   So like you have to clarify what you mean by academic.
[01:44:58.040 --> 01:45:00.660]   And right now the word academic means a very,
[01:45:00.660 --> 01:45:04.280]   in the intellectual public discourse, it means the enemy.
[01:45:04.280 --> 01:45:07.380]   And there's a lot of people that perhaps deserve
[01:45:07.380 --> 01:45:12.380]   that targeted vilification, but like a lot that don't.
[01:45:12.380 --> 01:45:13.780]   They're just curious people.
[01:45:13.780 --> 01:45:15.020]   - Yeah, no, you're absolutely right.
[01:45:15.020 --> 01:45:18.380]   - Building robots that will one day destroy you.
[01:45:18.380 --> 01:45:20.300]   Voice cracks every time I make a joke.
[01:45:20.300 --> 01:45:21.220]   - You're not, 'cause it's just--
[01:45:21.220 --> 01:45:22.060]   - I can't do this. - 'Cause you're not
[01:45:22.060 --> 01:45:24.820]   making a joke, it's you're telling a joke.
[01:45:24.820 --> 01:45:26.420]   - I'm editing.
[01:45:26.420 --> 01:45:28.340]   Can I delete that joke?
[01:45:28.340 --> 01:45:30.380]   Okay, it's not even a joke.
[01:45:30.380 --> 01:45:34.060]   Building robots that will one day kill us.
[01:45:34.060 --> 01:45:36.660]   Humans-- - Oh, God willing.
[01:45:36.660 --> 01:45:38.580]   - God willing, humans are the joke.
[01:45:38.580 --> 01:45:40.020]   That's why I'm cracking.
[01:45:40.020 --> 01:45:41.220]   My voice is cracking.
[01:45:42.060 --> 01:45:42.900]   (laughing)
[01:45:42.900 --> 01:45:45.700]   - What were even, what was I even fucking saying?
[01:45:45.700 --> 01:45:46.540]   Academics.
[01:45:46.540 --> 01:45:48.260]   But why--
[01:45:48.260 --> 01:45:50.300]   - My local, someone had a question, they're an academic.
[01:45:50.300 --> 01:45:51.500]   - Right, they're an academic.
[01:45:51.500 --> 01:45:55.340]   They're saying like, are you worried that, you know,
[01:45:55.340 --> 01:46:00.340]   in academia, associating yourself with a sort of somebody
[01:46:00.340 --> 01:46:05.260]   who has, who can be misconstrued to have radical ideas,
[01:46:05.260 --> 01:46:06.640]   like the two examples they gave
[01:46:06.640 --> 01:46:08.420]   is Michael Malice and Joe Rogan.
[01:46:09.940 --> 01:46:11.700]   Does Joe have any radical,
[01:46:11.700 --> 01:46:13.260]   I wouldn't consider him radical at all.
[01:46:13.260 --> 01:46:15.220]   - Well, we can talk about it.
[01:46:15.220 --> 01:46:17.140]   - But Joe is, I think, a bad example.
[01:46:17.140 --> 01:46:19.620]   He's quite centrist to me.
[01:46:19.620 --> 01:46:22.060]   - Well, he could have, for example,
[01:46:22.060 --> 01:46:24.420]   like what has Joe been attacked on?
[01:46:24.420 --> 01:46:27.860]   Is, for example, on the topic of like transgender,
[01:46:27.860 --> 01:46:32.300]   - Athletes and sports. - Athletes and sports.
[01:46:32.300 --> 01:46:34.580]   There's, what else?
[01:46:34.580 --> 01:46:37.620]   I mean, he's been pro Bernie Sanders and--
[01:46:37.620 --> 01:46:38.820]   - That's hardly radical.
[01:46:38.820 --> 01:46:43.300]   - Pro Trump or like giving Trump a pass.
[01:46:43.300 --> 01:46:44.620]   - Yeah, not anti-Trump.
[01:46:44.620 --> 01:46:46.020]   - Not anti-Trump. - Yeah.
[01:46:46.020 --> 01:46:48.300]   - What else?
[01:46:48.300 --> 01:46:49.460]   Just--
[01:46:49.460 --> 01:46:50.700]   - But none of these are radical.
[01:46:50.700 --> 01:46:55.260]   - Meat, meat stuff being pro meat versus anti-vegan.
[01:46:55.260 --> 01:46:56.220]   - Yeah.
[01:46:56.220 --> 01:46:57.340]   - You know, all those kinds of things.
[01:46:57.340 --> 01:47:00.640]   But you can be misconstrued and saying,
[01:47:00.640 --> 01:47:01.700]   there's, I think, a highlight,
[01:47:01.700 --> 01:47:03.580]   and my mom actually wrote to me about this,
[01:47:03.580 --> 01:47:05.060]   which is hilarious. - Yoshika.
[01:47:05.060 --> 01:47:07.100]   - Yoshika, thank you.
[01:47:07.100 --> 01:47:08.700]   I like how you jotted it down.
[01:47:08.700 --> 01:47:09.860]   That's when it's important.
[01:47:09.860 --> 01:47:11.580]   - Well, let me see, your mom wrote to you, Yoshika.
[01:47:11.580 --> 01:47:13.620]   - That's a sign, my voice cracks,
[01:47:13.620 --> 01:47:16.460]   a sign when Michael Malice makes a funny joke
[01:47:16.460 --> 01:47:18.020]   is when you jot something down.
[01:47:18.020 --> 01:47:19.060]   (laughing)
[01:47:19.060 --> 01:47:19.900]   - Yoshika.
[01:47:19.900 --> 01:47:23.060]   (speaking in foreign language)
[01:47:23.060 --> 01:47:25.940]   - He writes it, and then the next time he just crosses it out.
[01:47:25.940 --> 01:47:27.100]   (laughing)
[01:47:27.100 --> 01:47:28.700]   It's a good point, yeah.
[01:47:28.700 --> 01:47:30.820]   It's like Joe Biden, the debates.
[01:47:30.820 --> 01:47:31.660]   Okay.
[01:47:31.660 --> 01:47:34.180]   - I did also just crap my pants.
[01:47:34.180 --> 01:47:36.580]   (laughing)
[01:47:36.580 --> 01:47:37.420]   - So--
[01:47:37.420 --> 01:47:39.300]   - It's like a mud slide down here.
[01:47:39.300 --> 01:47:42.380]   - There is a, I mean, he's a comedian.
[01:47:42.380 --> 01:47:44.580]   You have a comedian side to you, right?
[01:47:44.580 --> 01:47:46.540]   I mean, you've talked a lot. - Humorist, yeah.
[01:47:46.540 --> 01:47:48.780]   - Humorist side, yeah, humorist.
[01:47:48.780 --> 01:47:51.060]   So you can misconstrue Joe as being
[01:47:51.060 --> 01:47:52.420]   somehow a radical thinker,
[01:47:52.420 --> 01:47:54.500]   and the same one could be done with you.
[01:47:54.500 --> 01:47:55.900]   And his question was,
[01:47:55.900 --> 01:47:58.940]   are you worried about associating yourself
[01:47:58.940 --> 01:48:00.300]   with folks like that?
[01:48:00.300 --> 01:48:01.220]   - Am I, or are you?
[01:48:01.220 --> 01:48:02.300]   - Me, me.
[01:48:02.300 --> 01:48:03.620]   - Yeah, that's my question.
[01:48:03.620 --> 01:48:06.160]   - And is that something,
[01:48:06.160 --> 01:48:09.700]   do you see yourself as somebody
[01:48:09.700 --> 01:48:14.260]   who's dangerous that I shouldn't be talking to?
[01:48:14.260 --> 01:48:15.880]   And in the same way,
[01:48:15.880 --> 01:48:22.620]   do you ever think about guests on your podcast
[01:48:22.620 --> 01:48:24.700]   or people you talk to publicly,
[01:48:24.700 --> 01:48:26.540]   associate yourself with publicly,
[01:48:26.540 --> 01:48:31.060]   and think that there is somebody that crosses that line
[01:48:31.060 --> 01:48:31.900]   that you shouldn't talk to?
[01:48:31.900 --> 01:48:35.020]   - Yes, so I interviewed, in the new ride,
[01:48:35.020 --> 01:48:36.880]   I interviewed up to full-blown Nazis
[01:48:36.880 --> 01:48:38.560]   in the last chapters of Chris Cantwell,
[01:48:38.560 --> 01:48:40.800]   but that was in the context of that book, right?
[01:48:40.800 --> 01:48:42.920]   So there's lots of people who,
[01:48:42.920 --> 01:48:44.880]   people want me to have on my show,
[01:48:44.880 --> 01:48:46.840]   and the way I look at it is like
[01:48:46.840 --> 01:48:48.520]   you have a table and tablecloth, right?
[01:48:48.520 --> 01:48:52.120]   And let's suppose the table is three feet wide,
[01:48:52.120 --> 01:48:54.480]   the tablecloth is two feet wide.
[01:48:54.480 --> 01:48:56.800]   So if I move the tablecloth to the right,
[01:48:56.800 --> 01:48:58.320]   I'm gonna lose people on the left.
[01:48:58.320 --> 01:49:00.120]   I can only cover so much space.
[01:49:00.120 --> 01:49:02.740]   And the further you go on the fringe in one direction,
[01:49:02.740 --> 01:49:04.640]   the more mainstream you're going to lose
[01:49:04.640 --> 01:49:05.680]   in the other direction.
[01:49:05.680 --> 01:49:08.560]   So I'm very much making a conscious choice
[01:49:08.560 --> 01:49:12.620]   not to talk to, being, people will say I'm cowardly,
[01:49:12.620 --> 01:49:15.200]   and that's absolutely true, I'm being fearful here.
[01:49:15.200 --> 01:49:19.180]   I would prefer not to talk to some of those
[01:49:19.180 --> 01:49:22.720]   who would alienate some of the more mainstream people.
[01:49:22.720 --> 01:49:25.200]   And here's a perfect example of why.
[01:49:25.200 --> 01:49:26.440]   On my birthday last year,
[01:49:26.440 --> 01:49:29.080]   I woke up seven o'clock in the morning to go pee,
[01:49:29.080 --> 01:49:31.280]   and I checked Twitter, it's whatever,
[01:49:31.280 --> 01:49:33.340]   and Jeb Bush had followed me, Jeb.
[01:49:34.300 --> 01:49:37.880]   And I, it's 7 a.m., you're not really awake,
[01:49:37.880 --> 01:49:38.720]   you're like, wait, what?
[01:49:38.720 --> 01:49:40.080]   And then I thought maybe it was a fake account,
[01:49:40.080 --> 01:49:41.280]   but it's in the verified tab.
[01:49:41.280 --> 01:49:42.120]   Oh, you don't have this,
[01:49:42.120 --> 01:49:44.200]   'cause you're not verified on Twitter, that's a shame.
[01:49:44.200 --> 01:49:45.600]   So people who are mad around Twitter.
[01:49:45.600 --> 01:49:48.560]   - Twitter does not respect robots.
[01:49:48.560 --> 01:49:49.400]   (Lex laughing)
[01:49:49.400 --> 01:49:51.600]   - They ban bots, you're lucky you haven't been banned.
[01:49:51.600 --> 01:49:52.920]   - Zero, one.
[01:49:52.920 --> 01:49:55.960]   - Zero, zero, it's zero, zero, zero.
[01:49:55.960 --> 01:49:57.080]   - Those are my pronouns.
[01:49:57.080 --> 01:50:00.240]   (Lex laughing)
[01:50:00.240 --> 01:50:03.560]   - So it was Jeb, Jeb, Governor Bush,
[01:50:03.560 --> 01:50:05.580]   and I corresponded with him,
[01:50:05.580 --> 01:50:07.080]   and I asked him on the show,
[01:50:07.080 --> 01:50:09.360]   and he decided not to for various reasons.
[01:50:09.360 --> 01:50:11.560]   Very politely, he's like, just politics is so bad right now,
[01:50:11.560 --> 01:50:12.800]   I don't wanna talk about it.
[01:50:12.800 --> 01:50:14.640]   I respect that for him.
[01:50:14.640 --> 01:50:18.960]   If I am in a, if I'm creating my show
[01:50:18.960 --> 01:50:20.880]   where he's going to get heat,
[01:50:20.880 --> 01:50:24.000]   for who, and get canceled,
[01:50:24.000 --> 01:50:26.240]   oh, you can't be on the show, he has these other guests,
[01:50:26.240 --> 01:50:27.640]   I don't wanna lose that opportunity,
[01:50:27.640 --> 01:50:29.420]   because, as we were talking about earlier,
[01:50:29.420 --> 01:50:31.240]   me and Alex Jones and Tim Pool,
[01:50:31.240 --> 01:50:34.320]   I think a lot of people would be very excited
[01:50:34.320 --> 01:50:36.120]   to see me sit down with Jeb Bush.
[01:50:36.120 --> 01:50:38.360]   And I told him in writing, and I meant this,
[01:50:38.360 --> 01:50:41.760]   I wouldn't be clowning him, I wouldn't be disrespectful,
[01:50:41.760 --> 01:50:43.160]   it would be a lot of fun.
[01:50:43.160 --> 01:50:45.600]   There's a goofball side to him that comes out sometimes,
[01:50:45.600 --> 01:50:47.360]   and I would do my best to bring that out,
[01:50:47.360 --> 01:50:49.240]   and talk about what it's like being a blue blood,
[01:50:49.240 --> 01:50:50.600]   to be born into his grandfather,
[01:50:50.600 --> 01:50:53.360]   Prescott Bush was a senator from Connecticut,
[01:50:53.360 --> 01:50:55.840]   marrying a woman who didn't speak English,
[01:50:55.840 --> 01:50:57.480]   how does that work when your family's royalty,
[01:50:57.480 --> 01:50:58.320]   and things like that.
[01:50:58.320 --> 01:51:00.120]   So I had a lot of fun questions for him,
[01:51:00.120 --> 01:51:01.400]   and that's kinda, you're gonna have to choose
[01:51:01.400 --> 01:51:02.440]   one or the other.
[01:51:02.440 --> 01:51:04.360]   - Well, you do a really good job with that,
[01:51:04.360 --> 01:51:06.240]   like Ben Shapiro does a good job with that too,
[01:51:06.240 --> 01:51:10.840]   which is, you can have a trolly side,
[01:51:10.840 --> 01:51:12.640]   a humor side, where you tear down
[01:51:12.640 --> 01:51:14.480]   the power structures and so on,
[01:51:14.480 --> 01:51:16.360]   but you can also have a serious side,
[01:51:16.360 --> 01:51:18.480]   and it's a safe space for people
[01:51:18.480 --> 01:51:20.040]   from all walks of life to walk in,
[01:51:20.040 --> 01:51:22.640]   and you're not adversarial.
[01:51:22.640 --> 01:51:25.920]   - Never, I take the word guests seriously.
[01:51:25.920 --> 01:51:27.640]   If they're gonna be on my show,
[01:51:27.640 --> 01:51:30.840]   I'm not going to have them have negative consequences
[01:51:30.840 --> 01:51:32.720]   as a result of being on my show.
[01:51:32.720 --> 01:51:36.080]   - That said, I mean, maybe in my case,
[01:51:36.080 --> 01:51:41.080]   I'll be honest and say that I find Alex Jones
[01:51:41.080 --> 01:51:43.040]   outside of the conspiracy stuff,
[01:51:43.040 --> 01:51:44.920]   for some reason, maybe you can explain,
[01:51:44.920 --> 01:51:46.280]   maybe you can psychoanalyze me,
[01:51:46.280 --> 01:51:49.280]   but I find him hilarious to listen to.
[01:51:49.280 --> 01:51:51.360]   - He's a performer, he's very performative.
[01:51:51.360 --> 01:51:53.280]   - But there's a lot of people that don't see
[01:51:53.280 --> 01:51:56.760]   the humor of it, and they see the serious consequences
[01:51:56.760 --> 01:52:00.400]   of spreading conspiracy theories of different kinds,
[01:52:00.400 --> 01:52:04.840]   and they see the danger of it.
[01:52:04.840 --> 01:52:10.760]   And I personally, I'm often tempted to talk to Alex
[01:52:10.760 --> 01:52:15.920]   in a podcast format, but I think I'm trying
[01:52:15.920 --> 01:52:18.960]   to convince myself that I never will.
[01:52:18.960 --> 01:52:22.040]   For me, I feel unsafe talking to Alex
[01:52:22.040 --> 01:52:26.640]   because I can't truly be myself, which is like--
[01:52:26.640 --> 01:52:27.560]   - Yeah, you'd have to be on.
[01:52:27.560 --> 01:52:29.520]   - Naive and honest.
[01:52:29.520 --> 01:52:34.520]   And actually, generally, when I talk to humans,
[01:52:34.520 --> 01:52:36.440]   I want to see the best in them.
[01:52:36.440 --> 01:52:40.280]   And I think that's, I often think about
[01:52:40.280 --> 01:52:44.680]   if I talked to Hitler in 1935, 1938--
[01:52:44.680 --> 01:52:46.640]   - You got a list of names to give him?
[01:52:46.640 --> 01:52:47.680]   (laughs)
[01:52:47.680 --> 01:52:50.640]   - Well, yeah, I mean, that's how you get the interview.
[01:52:50.640 --> 01:52:51.880]   Come on, let's be honest.
[01:52:51.880 --> 01:52:54.300]   Who are we kidding?
[01:52:56.200 --> 01:52:58.560]   I would, you have to give away one of your,
[01:52:58.560 --> 01:53:00.400]   I would probably give away my brother, so--
[01:53:00.400 --> 01:53:01.600]   - How many brothers do you have?
[01:53:01.600 --> 01:53:02.440]   - Well, just one.
[01:53:02.440 --> 01:53:03.260]   - Okay.
[01:53:03.260 --> 01:53:04.100]   - Too many.
[01:53:04.100 --> 01:53:05.880]   - What, I wanna be an only child.
[01:53:05.880 --> 01:53:09.760]   - He's the older brother, he used to pick on me, payback.
[01:53:09.760 --> 01:53:11.360]   You know, it's only, he had a good life.
[01:53:11.360 --> 01:53:12.640]   - You should think of it more as Stalin,
[01:53:12.640 --> 01:53:15.020]   I so interrupt you, because Hitler, you're Jewish,
[01:53:15.020 --> 01:53:17.800]   so you're already gonna have very adversarial,
[01:53:17.800 --> 01:53:19.480]   it's not gonna be a normal, he's not gonna perceive you
[01:53:19.480 --> 01:53:21.280]   as a human in a sense, right?
[01:53:21.280 --> 01:53:22.920]   - Right, Stalin, you're right.
[01:53:22.920 --> 01:53:24.240]   - Yeah, that would be much easier,
[01:53:24.240 --> 01:53:26.480]   or Kim Jong-un, or something like that.
[01:53:26.480 --> 01:53:28.000]   - Like, you have to think, like how,
[01:53:28.000 --> 01:53:29.600]   okay, this is a good question, is,
[01:53:29.600 --> 01:53:33.080]   in that spirit, why don't you jot something down?
[01:53:33.080 --> 01:53:35.160]   (laughing)
[01:53:35.160 --> 01:53:36.000]   If you--
[01:53:36.000 --> 01:53:37.680]   - Lutz loves Hitler.
[01:53:37.680 --> 01:53:39.560]   (laughing)
[01:53:39.560 --> 01:53:41.760]   - All right, we'll cross it out in a second.
[01:53:41.760 --> 01:53:43.480]   - Approve.
[01:53:43.480 --> 01:53:45.760]   - I think this is a really good example
[01:53:45.760 --> 01:53:49.040]   of a difficult figure that's controversial
[01:53:49.040 --> 01:53:50.600]   that people bring up to me a lot,
[01:53:50.600 --> 01:53:53.920]   and you've interviewed twice, which is Curtis Yarvin.
[01:53:53.920 --> 01:53:54.840]   - Yeah, Manches Mall Blok.
[01:53:54.840 --> 01:53:57.040]   - Manches Mall, AKA Manches Mall Blok,
[01:53:57.040 --> 01:54:01.160]   which is his pseudonym that he goes by in his blog.
[01:54:01.160 --> 01:54:03.640]   Can you tell me about who he is?
[01:54:03.640 --> 01:54:04.480]   - Sure.
[01:54:04.480 --> 01:54:06.760]   - Why is he interesting, what of his ideas are interesting?
[01:54:06.760 --> 01:54:10.240]   - Well, briefly, he invented the concept of the red pill.
[01:54:10.240 --> 01:54:13.520]   So, Curtis, Manches Mall Blok had a blog
[01:54:13.520 --> 01:54:14.920]   called Unqualified Reservations,
[01:54:14.920 --> 01:54:16.880]   you can still find it online.
[01:54:16.880 --> 01:54:21.200]   It's very verbose, he writes at length, very, very bright.
[01:54:22.540 --> 01:54:25.980]   His perspective is very heretical.
[01:54:25.980 --> 01:54:28.660]   So a lot of things that we take for granted
[01:54:28.660 --> 01:54:32.620]   in our liberal democracy, he regards as not only incorrect,
[01:54:32.620 --> 01:54:36.180]   which is downright absurd, and he does not take
[01:54:36.180 --> 01:54:40.300]   what many people view as the basis of American political
[01:54:40.300 --> 01:54:43.600]   discourse as the basis for his thought.
[01:54:43.600 --> 01:54:48.140]   So, when you're starting with someone
[01:54:48.140 --> 01:54:52.980]   who is basically repudiating kind of the Western worldview,
[01:54:52.980 --> 01:54:55.620]   or not the Western worldview, like the American milieu,
[01:54:55.620 --> 01:54:57.900]   a lot of people are gonna, of course,
[01:54:57.900 --> 01:55:02.420]   regard him as dangerous or someone who is verboten.
[01:55:02.420 --> 01:55:04.880]   He's a very bright person.
[01:55:04.880 --> 01:55:08.060]   - Why is he such a toxic figure?
[01:55:08.060 --> 01:55:10.760]   - Because if you are blue-pilled,
[01:55:10.760 --> 01:55:15.760]   if you are the guardians of what is acceptable discourse,
[01:55:17.020 --> 01:55:20.580]   then you have to make sure your forts are secured,
[01:55:20.580 --> 01:55:23.940]   and that any figure outside of this acceptable discourse
[01:55:23.940 --> 01:55:26.460]   has to be marginalized and regarded
[01:55:26.460 --> 01:55:28.380]   as radioactive as possible.
[01:55:28.380 --> 01:55:32.820]   You don't want to let in these kind of ideas
[01:55:32.820 --> 01:55:34.580]   that would be destructive to your hegemony.
[01:55:34.580 --> 01:55:36.540]   - Well, so, let's dig into it.
[01:55:36.540 --> 01:55:39.980]   So, like, he, I've read a few things by him,
[01:55:39.980 --> 01:55:43.980]   but then I hear that, in a bunch of places,
[01:55:43.980 --> 01:55:47.020]   him being called a racist, a white supremacist,
[01:55:47.020 --> 01:55:49.240]   neo-fascist, so on.
[01:55:49.240 --> 01:55:52.180]   I go to his Wikipedia.
[01:55:52.180 --> 01:55:53.020]   - Yeah.
[01:55:53.020 --> 01:55:54.700]   - There's a view on race section.
[01:55:54.700 --> 01:55:57.100]   Let me read it.
[01:55:57.100 --> 01:55:57.920]   - Okay.
[01:55:57.920 --> 01:56:00.380]   - "Yarvin's opinions have been described as racist,
[01:56:00.380 --> 01:56:03.480]   "with his writings interpreted as supportive of slavery,
[01:56:03.480 --> 01:56:06.180]   "including the belief that whites have higher IQs
[01:56:06.180 --> 01:56:08.600]   "than blacks for genetic reasons.
[01:56:08.600 --> 01:56:11.720]   "Yarvin himself maintains that he's not a racist
[01:56:11.720 --> 01:56:14.100]   "because while he doubts that, quote,
[01:56:14.100 --> 01:56:17.680]   "all races are equally smart, the notion, quote,
[01:56:17.680 --> 01:56:19.800]   "that people who score higher on IQ tests
[01:56:19.800 --> 01:56:23.760]   "are in some sense superior human beings is, quote, creepy.
[01:56:23.760 --> 01:56:27.900]   "He also disputes being an outspoken advocate for slavery,
[01:56:27.900 --> 01:56:30.340]   "though he has argued that some races
[01:56:30.340 --> 01:56:33.440]   "are more suited for slavery than others, quote,
[01:56:33.440 --> 01:56:34.620]   "it should be obvious that,
[01:56:34.620 --> 01:56:37.720]   "although I'm not a white nationalist,
[01:56:37.720 --> 01:56:40.400]   "I am not exactly allergic to the stuff.
[01:56:40.400 --> 01:56:44.080]   "Yarvin wrote in a post that linked approvingly of,"
[01:56:44.080 --> 01:56:45.920]   I don't know these people, "Steve Saylor."
[01:56:45.920 --> 01:56:46.880]   - Steve Saylor, yeah, he's from--
[01:56:46.880 --> 01:56:49.600]   - "Jerry Taylor and other racialists."
[01:56:49.600 --> 01:56:50.660]   - Yeah, so--
[01:56:50.660 --> 01:56:53.120]   - Okay, so one of my questions is--
[01:56:53.120 --> 01:56:56.560]   - Let me just say one sentence.
[01:56:56.560 --> 01:56:59.760]   In the same way that you mentioned that guy earlier
[01:56:59.760 --> 01:57:02.340]   who was defending some aspects of communism,
[01:57:02.340 --> 01:57:05.080]   and that is, in some context, acceptable,
[01:57:05.080 --> 01:57:06.320]   when you think about it, it's like,
[01:57:06.320 --> 01:57:07.800]   this should be radioactive.
[01:57:07.800 --> 01:57:08.640]   - Right.
[01:57:08.640 --> 01:57:11.120]   - The fact that he is engaging with these ideas
[01:57:11.120 --> 01:57:15.400]   in anything other than this has to be reputed at all costs
[01:57:15.400 --> 01:57:18.240]   is what renders him, to a large extent, a racist.
[01:57:18.240 --> 01:57:19.080]   - That's really interesting.
[01:57:19.080 --> 01:57:21.800]   So there are some topics you can be--
[01:57:21.800 --> 01:57:22.640]   - Nuanced.
[01:57:22.640 --> 01:57:24.200]   - Nuanced, and some not.
[01:57:24.200 --> 01:57:28.360]   And communism is still a topic that you can be nuanced about.
[01:57:28.360 --> 01:57:29.200]   - Right.
[01:57:29.200 --> 01:57:31.160]   - It's difficult, but you can be.
[01:57:31.160 --> 01:57:33.720]   Race, and this, like, talking about slavery
[01:57:33.720 --> 01:57:36.640]   and IQ differences based on race
[01:57:36.640 --> 01:57:40.400]   is a topic that, I guess, is radioactive
[01:57:40.400 --> 01:57:43.240]   to a degree where you can't even say anything,
[01:57:43.240 --> 01:57:46.400]   even if it's, like, nuanced,
[01:57:46.400 --> 01:57:49.080]   or not even, like, making a point,
[01:57:49.080 --> 01:57:52.040]   it's like touching it as you make another point.
[01:57:52.040 --> 01:57:54.480]   - And understandably, you can understand that.
[01:57:54.480 --> 01:57:56.680]   I'm gonna steel man their point,
[01:57:56.680 --> 01:57:57.920]   'cause you can understand the point.
[01:57:57.920 --> 01:57:59.440]   It's like, you're just talking about Hitler.
[01:57:59.440 --> 01:58:01.240]   Once this foot gets in the door
[01:58:01.240 --> 01:58:03.960]   that some people are inherently slaves,
[01:58:03.960 --> 01:58:05.980]   or some people are inherently better than others,
[01:58:05.980 --> 01:58:08.360]   it really quickly, you know, collapses.
[01:58:08.360 --> 01:58:09.480]   So that would be their perspective.
[01:58:09.480 --> 01:58:10.360]   - But that's what, like,
[01:58:10.360 --> 01:58:12.640]   if I were to give criticism of his--
[01:58:12.640 --> 01:58:13.840]   - But let me just say one more thing.
[01:58:13.840 --> 01:58:16.800]   Racist is also used to describe Alex Jones.
[01:58:16.800 --> 01:58:18.800]   Alex doesn't talk about race.
[01:58:18.800 --> 01:58:20.760]   Racist is a shorthand
[01:58:20.760 --> 01:58:23.400]   for a certain percentage of the population
[01:58:23.400 --> 01:58:26.880]   to let you know, do not bother investing
[01:58:26.880 --> 01:58:28.320]   in this person any further.
[01:58:28.320 --> 01:58:29.560]   They are off limits.
[01:58:29.560 --> 01:58:31.560]   - Definitely, racism and sexism is a thing
[01:58:31.560 --> 01:58:33.680]   that's now used to shut down conversation
[01:58:33.680 --> 01:58:36.500]   that's quite absurd by a small percent of the population.
[01:58:36.500 --> 01:58:38.100]   - But Jared Taylor and Steve Saylor,
[01:58:38.100 --> 01:58:39.940]   Jared Taylor interviewed him for my book,
[01:58:39.940 --> 01:58:43.300]   he would be regarded in any sense as a racist.
[01:58:43.300 --> 01:58:45.620]   - What's the difference between racist and racialist?
[01:58:45.620 --> 01:58:48.340]   - So racialists, I mean, this is splitting hairs,
[01:58:48.340 --> 01:58:50.380]   and now I'm gonna be all radioactive.
[01:58:50.380 --> 01:58:52.500]   Jared Taylor runs something called Amren,
[01:58:52.500 --> 01:58:54.980]   and this is, I mean, his perspective
[01:58:54.980 --> 01:58:57.260]   is that there are inherent differences to the races,
[01:58:57.260 --> 01:59:01.060]   and you cannot live side by side well.
[01:59:01.060 --> 01:59:03.060]   Whites and blacks should not be living side by side.
[01:59:03.060 --> 01:59:04.620]   - By the way, for people who don't know,
[01:59:04.620 --> 01:59:06.620]   this is out of context,
[01:59:06.620 --> 01:59:08.700]   you have written a great book
[01:59:08.700 --> 01:59:11.020]   that includes some of these concepts called The New Right,
[01:59:11.020 --> 01:59:12.540]   which not includes these concepts,
[01:59:12.540 --> 01:59:13.660]   but talks about-- - Doesn't, yeah.
[01:59:13.660 --> 01:59:17.340]   - Well, it's more about the growth of the community
[01:59:17.340 --> 01:59:22.340]   around the alt-right and all those kinds of world.
[01:59:22.340 --> 01:59:25.900]   - Right, so, and his point about IQ,
[01:59:25.900 --> 01:59:29.420]   it's like if you had a population, the Dutch, right?
[01:59:29.420 --> 01:59:31.460]   I think they're the tallest people on the Earth.
[01:59:31.460 --> 01:59:33.060]   And if you said, well,
[01:59:33.060 --> 01:59:35.060]   the Dutch are the best people on Earth, why?
[01:59:35.060 --> 01:59:37.980]   'Cause they're the tallest, it's like you're a crazy person.
[01:59:37.980 --> 01:59:39.740]   So if someone is scoring low,
[01:59:39.740 --> 01:59:41.660]   an individual on an IQ test,
[01:59:41.660 --> 01:59:44.380]   that means they're somehow a lower quality person.
[01:59:44.380 --> 01:59:46.380]   Well, maybe in one very specific aspect,
[01:59:46.380 --> 01:59:48.620]   but I mean, if they're a good human being,
[01:59:48.620 --> 01:59:49.820]   I've got friends who are low IQ,
[01:59:49.820 --> 01:59:51.980]   all my friends are low IQ, frankly, compared to me.
[01:59:51.980 --> 01:59:52.820]   Sounded like Trump there for a second.
[01:59:52.820 --> 01:59:53.900]   - That's how you choose friends.
[01:59:53.900 --> 01:59:55.100]   (both laughing)
[01:59:55.100 --> 01:59:56.180]   - Well, I don't have any other choices.
[01:59:56.180 --> 01:59:57.500]   No one's gonna be at my level.
[01:59:57.500 --> 02:00:00.380]   - You're the smartest person since Abraham Lincoln
[02:00:00.380 --> 02:00:02.100]   that I've ever seen.
[02:00:02.100 --> 02:00:03.940]   - Unlike him, I actually am honest.
[02:00:03.940 --> 02:00:08.940]   So he is someone who very much swims in heretical ideas.
[02:00:08.940 --> 02:00:12.620]   Here's another thing.
[02:00:12.620 --> 02:00:15.220]   Like if you bring up that Aristotle said
[02:00:15.220 --> 02:00:17.060]   that some people are born to be slaves,
[02:00:17.060 --> 02:00:18.140]   he wasn't speaking about race,
[02:00:18.140 --> 02:00:20.100]   he just meant people's souls.
[02:00:20.100 --> 02:00:22.460]   H.L. Mencken, who's a great heretic
[02:00:22.460 --> 02:00:26.500]   and early to 20th century figure,
[02:00:26.500 --> 02:00:28.340]   one of his quotes that I say all the time,
[02:00:28.340 --> 02:00:30.500]   which people have seen a lot in this past year,
[02:00:30.500 --> 02:00:32.300]   that the average man does not want to be free,
[02:00:32.300 --> 02:00:34.180]   he merely wants to be safe.
[02:00:34.180 --> 02:00:36.260]   That I think is, I don't know,
[02:00:36.260 --> 02:00:40.380]   I am not familiar with what Moldau saying about slavery
[02:00:40.380 --> 02:00:42.060]   'cause his writing is ponderous,
[02:00:42.060 --> 02:00:45.000]   but that certainly is something I think that is undeniable,
[02:00:45.000 --> 02:00:46.300]   that I think more people are realizing
[02:00:46.300 --> 02:00:48.160]   there's a large percent of the population
[02:00:48.160 --> 02:00:50.420]   that is actively disinterested in freedom
[02:00:50.420 --> 02:00:52.780]   and the moral responsibilities it entails.
[02:00:52.780 --> 02:00:55.820]   - Well, I mean, really just the word slavery,
[02:00:55.820 --> 02:00:57.700]   if you wanna make some kind of point
[02:00:57.700 --> 02:01:02.100]   or even think about the topic outside the context
[02:01:02.100 --> 02:01:03.820]   of this is a horrible thing that happened
[02:01:03.820 --> 02:01:05.220]   in the United States history.
[02:01:05.220 --> 02:01:06.220]   - And other countries' histories,
[02:01:06.220 --> 02:01:07.500]   it's not unique to us, let's be clear.
[02:01:07.500 --> 02:01:08.980]   - This is, I mean, very important
[02:01:08.980 --> 02:01:10.300]   and there's slavery going on today
[02:01:10.300 --> 02:01:13.900]   and a lot of people argue that sex trafficking
[02:01:13.900 --> 02:01:14.740]   and all those kinds of things,
[02:01:14.740 --> 02:01:17.300]   I mean, there's atrocities going on today
[02:01:17.300 --> 02:01:22.300]   that talking about it in a way
[02:01:22.300 --> 02:01:24.500]   that's not immediately saying
[02:01:24.500 --> 02:01:27.260]   this is the most horrible thing that happened ever.
[02:01:27.260 --> 02:01:31.580]   It's something I think about a lot
[02:01:31.580 --> 02:01:34.060]   is like if I wanna say something controversial,
[02:01:34.060 --> 02:01:38.860]   I should do so with skill, with care
[02:01:38.860 --> 02:01:40.780]   and only about things I care about.
[02:01:40.780 --> 02:01:43.260]   - Well, here's where I would disagree.
[02:01:43.260 --> 02:01:46.300]   When I say things, I often say things that are controversial
[02:01:46.300 --> 02:01:48.660]   or I will say uncontroversial things
[02:01:48.660 --> 02:01:50.340]   in a controversial way
[02:01:50.340 --> 02:01:53.380]   because it's a useful mechanism to alienate people
[02:01:53.380 --> 02:01:55.020]   you don't want around you
[02:01:55.020 --> 02:01:58.520]   because if there are people who are going to be shocked
[02:01:58.520 --> 02:02:01.840]   by certain topics, like we should have ended World War II,
[02:02:01.840 --> 02:02:04.060]   like even as a hypothesis, they just clutch their pearls,
[02:02:04.060 --> 02:02:06.340]   they're like, oh, you want the Holocaust to happen,
[02:02:06.340 --> 02:02:08.520]   I can't discuss most things with you
[02:02:08.520 --> 02:02:10.740]   because you're not interested in having a conversation,
[02:02:10.740 --> 02:02:12.100]   you're interested in your emotional response.
[02:02:12.100 --> 02:02:13.460]   - Yeah, I think I see things differently.
[02:02:13.460 --> 02:02:15.420]   Maybe this is a bit of a devil's advocate,
[02:02:15.420 --> 02:02:18.260]   but what in at least the modern discourse
[02:02:18.260 --> 02:02:20.860]   of like Twitter and social media and so on,
[02:02:20.860 --> 02:02:22.820]   I find that if you do that,
[02:02:22.820 --> 02:02:26.700]   you're not actually removing the people
[02:02:26.700 --> 02:02:29.460]   that are not thoughtful and kind and so on,
[02:02:29.460 --> 02:02:31.860]   you're actually attracting loud people.
[02:02:31.860 --> 02:02:33.220]   Like a small number of them,
[02:02:33.220 --> 02:02:35.380]   they come over and start yelling at you,
[02:02:35.380 --> 02:02:39.260]   start yelling, they're basically ruin the party
[02:02:39.260 --> 02:02:42.260]   by showing up and just screaming
[02:02:42.260 --> 02:02:43.940]   and so all the thoughtful people leave.
[02:02:43.940 --> 02:02:46.980]   - Well, that's why you have to be a very heavy blocker.
[02:02:46.980 --> 02:02:48.180]   You have to block people on Twitter
[02:02:48.180 --> 02:02:50.000]   'cause you have to cultivate your audience
[02:02:50.000 --> 02:02:51.920]   and have them, like a lot of times people come at me,
[02:02:51.920 --> 02:02:54.140]   I don't care, then they'll start attacking
[02:02:54.140 --> 02:02:55.420]   members of my audience and then I'm like,
[02:02:55.420 --> 02:02:57.700]   dang, I gotta block them because they've won this one
[02:02:57.700 --> 02:02:58.960]   'cause I can't have that.
[02:02:58.960 --> 02:03:02.980]   - Yeah, I don't know.
[02:03:02.980 --> 02:03:07.700]   Unnecessarily provoking people feels...
[02:03:07.700 --> 02:03:12.640]   - This is beta testing.
[02:03:12.640 --> 02:03:14.540]   You try to break the system and see what works.
[02:03:14.540 --> 02:03:17.340]   You put up as much pressure as possible.
[02:03:17.340 --> 02:03:19.220]   This is very much computer stuff
[02:03:19.220 --> 02:03:21.060]   that you should be able to appreciate.
[02:03:21.060 --> 02:03:22.600]   - The point being when you have a program,
[02:03:22.600 --> 02:03:24.160]   you're trying to intentionally sit there
[02:03:24.160 --> 02:03:26.800]   and do as many mistakes to see what go wrong, right?
[02:03:26.800 --> 02:03:28.800]   Is that not common practice?
[02:03:28.800 --> 02:03:29.640]   - Yeah, exactly.
[02:03:29.640 --> 02:03:33.480]   So you're saying that's a way to see
[02:03:33.480 --> 02:03:34.760]   communication with the world
[02:03:34.760 --> 02:03:37.480]   is you say something uncontroversial
[02:03:37.480 --> 02:03:40.920]   in a controversial way and that blocks people.
[02:03:40.920 --> 02:03:42.000]   - Or does it trigger them?
[02:03:42.000 --> 02:03:43.160]   Do they roll their eyes?
[02:03:43.160 --> 02:03:45.580]   What is gonna be their emotional response?
[02:03:45.580 --> 02:03:46.840]   Are they gonna start yelling?
[02:03:46.840 --> 02:03:50.440]   - The problem is the reason I can't think like this
[02:03:50.440 --> 02:03:52.720]   or I can't because I'm not sure
[02:03:52.720 --> 02:03:56.600]   about the points I'm trying to make always.
[02:03:56.600 --> 02:03:59.160]   I'm not always 100% sure that I'm right about things.
[02:03:59.160 --> 02:04:04.160]   So in being thoughtful, I'm afraid that I'll turn off
[02:04:04.160 --> 02:04:10.560]   with an ineloquently phrased or even incorrect statement,
[02:04:10.560 --> 02:04:13.120]   I will do damage that can't be undone
[02:04:13.120 --> 02:04:17.320]   in terms of having a good conversation about a topic.
[02:04:17.320 --> 02:04:21.040]   So I wanna be very careful about,
[02:04:21.040 --> 02:04:24.640]   I'm not saying afraid, fear is not what I'm talking about.
[02:04:24.640 --> 02:04:29.640]   I think fear is like not saying something out of fears
[02:04:29.640 --> 02:04:33.120]   at the core of many of the problems of the world today.
[02:04:33.120 --> 02:04:36.360]   But I'm just saying say stuff with care.
[02:04:36.360 --> 02:04:39.200]   If I'm going to touch race as a topic,
[02:04:39.200 --> 02:04:43.120]   it feels like you really should be deeply,
[02:04:43.120 --> 02:04:45.240]   first have a point to make.
[02:04:45.240 --> 02:04:47.840]   Like you really care about a point you wanna make.
[02:04:47.840 --> 02:04:51.320]   And second, think deeply about how to say that point
[02:04:51.320 --> 02:04:54.000]   in a way that communicates it the best.
[02:04:54.000 --> 02:04:59.000]   And touching, I would say, listen,
[02:04:59.000 --> 02:05:03.360]   I've, on your show, which is great,
[02:05:03.360 --> 02:05:07.320]   I'd like to say thank you for having Mencious Molebug.
[02:05:07.320 --> 02:05:08.360]   - You are welcome.
[02:05:08.360 --> 02:05:13.800]   - That's the name of the show.
[02:05:13.800 --> 02:05:15.640]   - Thank you for having me a couple of times.
[02:05:15.640 --> 02:05:18.800]   It's great to sort of get him to, in this loose way,
[02:05:18.800 --> 02:05:20.720]   to talk about different kinds of stuff.
[02:05:20.720 --> 02:05:22.040]   - I don't think we talked about race at all.
[02:05:22.040 --> 02:05:22.880]   - No, no, no, no.
[02:05:22.880 --> 02:05:25.280]   - No, but I'm just bringing it back to what you were asking,
[02:05:25.280 --> 02:05:27.440]   which is if you read the Wikipedia,
[02:05:27.440 --> 02:05:28.600]   the perspective is gonna be
[02:05:28.600 --> 02:05:31.000]   this guy talks about slavery constantly,
[02:05:31.000 --> 02:05:33.360]   where it's completely disproportionate to his work.
[02:05:33.360 --> 02:05:35.040]   - But even on your show, you can tell,
[02:05:35.040 --> 02:05:36.600]   even outside of the race stuff,
[02:05:36.600 --> 02:05:40.760]   that he's not ultra careful about, he's not--
[02:05:42.640 --> 02:05:43.800]   - Nuanced.
[02:05:43.800 --> 02:05:46.840]   - Yeah, he's not afraid to say something just like,
[02:05:46.840 --> 02:05:48.920]   I would say, let me just criticize him,
[02:05:48.920 --> 02:05:50.760]   my face is not you, this is me,
[02:05:50.760 --> 02:05:53.260]   carelessly say something controversial.
[02:05:53.260 --> 02:05:54.100]   - Right.
[02:05:54.100 --> 02:05:57.320]   - I'm not saying, he doesn't go,
[02:05:57.320 --> 02:05:59.360]   that makes him, it's a very different thing
[02:05:59.360 --> 02:06:03.080]   than somebody who on purpose says
[02:06:03.080 --> 02:06:07.440]   something controversial stuff, like Milo Anopoulos,
[02:06:07.440 --> 02:06:09.600]   sorry, I forgot Milo, whatever his name is.
[02:06:09.600 --> 02:06:10.440]   - Anopoulos, yeah.
[02:06:10.440 --> 02:06:12.080]   - Yeah, which is really nice to see
[02:06:12.080 --> 02:06:13.800]   that he's a genuine person who's thoughtful,
[02:06:13.800 --> 02:06:17.560]   he doesn't mean to, but he just carelessly
[02:06:17.560 --> 02:06:21.600]   seems to say things that I feel like
[02:06:21.600 --> 02:06:24.360]   damage the rest of his body of work.
[02:06:24.360 --> 02:06:25.640]   - I can't really speak for him,
[02:06:25.640 --> 02:06:27.840]   but I would guess his point is,
[02:06:27.840 --> 02:06:31.200]   once you're swimming in this kind of worldview,
[02:06:31.200 --> 02:06:34.480]   you're going to be anathema already,
[02:06:34.480 --> 02:06:35.960]   so there's no pleasing these people,
[02:06:35.960 --> 02:06:37.040]   so why bother trying?
[02:06:37.040 --> 02:06:38.600]   - Yeah, I think that's a deeply,
[02:06:38.600 --> 02:06:41.080]   that's a black pill way of seeing the world.
[02:06:41.080 --> 02:06:42.200]   - It's not a black pill at all.
[02:06:42.200 --> 02:06:44.840]   - Because it's a cynical way, like these people,
[02:06:44.840 --> 02:06:49.320]   so it's saying that you're,
[02:06:49.320 --> 02:06:51.360]   it's a very kind of way of thinking,
[02:06:51.360 --> 02:06:53.000]   like I'll say whatever I want,
[02:06:53.000 --> 02:06:54.360]   whoever comes along with me.
[02:06:54.360 --> 02:06:55.960]   - No, you just earlier said yourself
[02:06:55.960 --> 02:06:58.600]   that racism has been weaponized
[02:06:58.600 --> 02:07:00.680]   as a way to shut down conversation,
[02:07:00.680 --> 02:07:03.040]   so I think his perspective would be,
[02:07:03.040 --> 02:07:06.580]   I am so outside the mainstream in my worldview
[02:07:06.580 --> 02:07:09.800]   that I know I'm going to be called racist,
[02:07:09.800 --> 02:07:12.480]   so there's no point in trying to be nuanced
[02:07:12.480 --> 02:07:14.560]   because I'm already going to get the scarlet letter.
[02:07:14.560 --> 02:07:15.960]   - Yeah, I just disagree with that
[02:07:15.960 --> 02:07:19.680]   because, for example, I am one person
[02:07:19.680 --> 02:07:22.560]   that he turned off by his carelessness,
[02:07:22.560 --> 02:07:25.160]   and I think I should be a good target,
[02:07:25.160 --> 02:07:26.800]   I should be somebody-- - I think that's fair.
[02:07:26.800 --> 02:07:31.280]   - And I'm just, like, it's very convenient
[02:07:31.280 --> 02:07:33.320]   to think that there's ridiculous people out there,
[02:07:33.320 --> 02:07:35.640]   which there are, who call everybody racist
[02:07:35.640 --> 02:07:39.040]   and sexist currently, and then you can't please them,
[02:07:39.040 --> 02:07:41.160]   so I'm not even gonna try.
[02:07:41.160 --> 02:07:44.040]   No, but there's this gray area of people
[02:07:44.040 --> 02:07:47.080]   that I don't listen to the outrage culture, whatever.
[02:07:47.080 --> 02:07:49.360]   This Wikipedia article means nothing to me.
[02:07:49.360 --> 02:07:52.280]   Like, I'm not going to-- - Right, I got you.
[02:07:52.280 --> 02:07:55.280]   - What I'm more, I'm just seeing this careless person,
[02:07:55.280 --> 02:08:00.280]   and if he's going to be careless about race like this,
[02:08:00.280 --> 02:08:03.840]   I feel like if I walk along with him long enough,
[02:08:03.840 --> 02:08:06.880]   I'm going to catch the carelessness.
[02:08:06.880 --> 02:08:09.520]   I'm going to lose, like--
[02:08:09.520 --> 02:08:11.600]   - I'll defend your perspective better than you can.
[02:08:11.600 --> 02:08:13.600]   - Yeah, this is good.
[02:08:13.600 --> 02:08:14.680]   I'm taking notes.
[02:08:14.680 --> 02:08:15.800]   - I talked to Eric Weinstein
[02:08:15.800 --> 02:08:17.600]   after you guys talked about me on your show.
[02:08:17.600 --> 02:08:18.600]   - Reynolds Weinstein.
[02:08:18.600 --> 02:08:19.880]   - We had a good conversation.
[02:08:19.880 --> 02:08:21.000]   He invited me on his show.
[02:08:21.000 --> 02:08:22.440]   - That would be an amazing conversation.
[02:08:22.440 --> 02:08:26.360]   - And we got on the phone, and his concern, fairly,
[02:08:26.360 --> 02:08:28.360]   he goes, "I don't want you to come on my show
[02:08:28.360 --> 02:08:30.640]   "for the purposes of clowning me,"
[02:08:30.640 --> 02:08:32.960]   and I would never do that.
[02:08:32.960 --> 02:08:36.480]   - He might not be aware of who you, of--
[02:08:36.480 --> 02:08:37.680]   - That's why he wanted to feel me out.
[02:08:37.680 --> 02:08:39.160]   He's like, when he hears troll,
[02:08:39.160 --> 02:08:40.400]   it can mean a lot of different things,
[02:08:40.400 --> 02:08:42.120]   and we had a very good conversation.
[02:08:42.120 --> 02:08:43.600]   It very much was very clear
[02:08:43.600 --> 02:08:45.600]   that's not where the conversation would go,
[02:08:45.600 --> 02:08:48.840]   but I think when you are going to be on someone's show,
[02:08:48.840 --> 02:08:51.080]   there is a responsibility
[02:08:51.080 --> 02:08:53.560]   that they're not going to have to pay a cost
[02:08:53.560 --> 02:08:54.840]   for having you as their guest,
[02:08:54.840 --> 02:08:58.080]   so if you were put off by how he was
[02:08:58.080 --> 02:09:00.080]   in that live stream or two I did,
[02:09:00.080 --> 02:09:01.720]   I understand where you're coming from.
[02:09:01.720 --> 02:09:03.360]   I think he's very, very bright,
[02:09:03.360 --> 02:09:06.080]   but you have a different audience than I do
[02:09:06.080 --> 02:09:07.800]   and you're going for something different than I am.
[02:09:07.800 --> 02:09:11.760]   - No, no, no, in my sense of--
[02:09:11.760 --> 02:09:12.800]   - You wouldn't feel safe with him.
[02:09:12.800 --> 02:09:14.040]   - Yeah, I wouldn't feel safe with him,
[02:09:14.040 --> 02:09:15.520]   but he's borderline for me.
[02:09:15.520 --> 02:09:19.200]   I would like to actually talk to him one day.
[02:09:19.200 --> 02:09:22.120]   Alex Jones has crossed the other line for me.
[02:09:22.120 --> 02:09:24.000]   - Well, you could do what you could do with me,
[02:09:24.000 --> 02:09:26.160]   tape the episode and then never release it.
[02:09:26.160 --> 02:09:31.160]   - No, it's one of those things where it'll be,
[02:09:31.160 --> 02:09:32.500]   when there's finally,
[02:09:32.500 --> 02:09:36.000]   they'll make a History Channel documentary
[02:09:36.000 --> 02:09:38.280]   about you and I and how it all went wrong,
[02:09:38.280 --> 02:09:39.880]   like the cult that we started
[02:09:39.880 --> 02:09:42.040]   and everybody killed themselves.
[02:09:42.040 --> 02:09:46.800]   And we'll release it then
[02:09:46.800 --> 02:09:49.280]   because it'll be like unseen footage.
[02:09:49.280 --> 02:09:51.440]   This is how it started.
[02:09:51.440 --> 02:09:52.800]   It'll be black and white
[02:09:52.800 --> 02:09:56.360]   in a basement somewhere in New York.
[02:09:56.360 --> 02:09:58.240]   - Yeah, my mother's basement.
[02:09:58.240 --> 02:10:01.440]   - This explains so much.
[02:10:01.440 --> 02:10:04.760]   Okay, so I spoke to Yaron Brook
[02:10:05.720 --> 02:10:09.900]   about objectivism and Ayn Rand,
[02:10:09.900 --> 02:10:12.880]   he kind of argued,
[02:10:12.880 --> 02:10:14.960]   he highlighted the difference between capitalism
[02:10:14.960 --> 02:10:19.720]   and anarchism as around the topic of violence
[02:10:19.720 --> 02:10:24.720]   and that having government
[02:10:24.720 --> 02:10:28.000]   be the sort of,
[02:10:28.000 --> 02:10:31.200]   the negative way to say it is like
[02:10:31.200 --> 02:10:33.360]   having a monopoly on violence,
[02:10:33.360 --> 02:10:36.000]   but basically being the arbiter of,
[02:10:36.000 --> 02:10:39.280]   or the people that making sure
[02:10:39.280 --> 02:10:41.840]   that violence doesn't get out of hand,
[02:10:41.840 --> 02:10:42.680]   that would--
[02:10:42.680 --> 02:10:44.440]   - Yeah, 2020 showed that, yep.
[02:10:44.440 --> 02:10:46.080]   Government's great at that, yep.
[02:10:46.080 --> 02:10:49.760]   - Well, what's, okay, without--
[02:10:49.760 --> 02:10:51.000]   - This is the same with the straight face,
[02:10:51.000 --> 02:10:51.840]   making that argument.
[02:10:51.840 --> 02:10:52.680]   Good work, Yaron.
[02:10:52.680 --> 02:10:56.280]   - All right, well, can you with a straight face argue
[02:10:56.280 --> 02:11:02.080]   for the idea that in anarchism,
[02:11:02.080 --> 02:11:04.440]   violence would not get out of hand?
[02:11:04.440 --> 02:11:06.320]   - Sure, for one thing,
[02:11:06.320 --> 02:11:08.560]   if your worst argument against,
[02:11:08.560 --> 02:11:10.040]   one of my little quotes is,
[02:11:10.040 --> 02:11:12.000]   "What are presented as the strongest arguments
[02:11:12.000 --> 02:11:14.040]   "against anarchism are inevitably descriptions
[02:11:14.040 --> 02:11:15.280]   "of the status quo."
[02:11:15.280 --> 02:11:17.800]   So the argument is under anarchism,
[02:11:17.800 --> 02:11:21.080]   you'd have warlords killing people
[02:11:21.080 --> 02:11:24.040]   and then you'd have whoever's strongest
[02:11:24.040 --> 02:11:25.680]   gets to just take over a neighborhood.
[02:11:25.680 --> 02:11:27.360]   Well, we have that now.
[02:11:27.360 --> 02:11:31.160]   We saw that the police are perfectly comfortable
[02:11:31.160 --> 02:11:33.200]   disarming the population
[02:11:33.200 --> 02:11:36.400]   and then when they try to protect themselves are punished,
[02:11:36.400 --> 02:11:38.000]   we're happy to stand down.
[02:11:38.000 --> 02:11:42.160]   You can only have that happen if you have a monopoly.
[02:11:42.160 --> 02:11:44.040]   If they're, like, let's suppose you had
[02:11:44.040 --> 02:11:45.640]   television stations, right?
[02:11:45.640 --> 02:11:47.640]   And CBS said, "You know what?
[02:11:47.640 --> 02:11:49.240]   "We're not gonna broadcast."
[02:11:49.240 --> 02:11:51.400]   Cool, you don't broadcast,
[02:11:51.400 --> 02:11:53.080]   we're gonna watch any of these other channels.
[02:11:53.080 --> 02:11:55.080]   So the problem with having a monopoly
[02:11:55.080 --> 02:11:57.680]   is everyone has to be dependent on this issue.
[02:11:57.680 --> 02:12:00.360]   What's amazing about minarchism, which objectivists are,
[02:12:00.360 --> 02:12:04.680]   is they will argue that government is really, really bad
[02:12:04.680 --> 02:12:06.920]   at everything it does and it touches.
[02:12:06.920 --> 02:12:09.720]   Therefore, it has to be in charge
[02:12:09.720 --> 02:12:11.000]   of the most important stuff.
[02:12:11.000 --> 02:12:13.040]   - Well, that's not therefore, but,
[02:12:13.040 --> 02:12:16.640]   but there is a thing that's fundamentally different
[02:12:16.640 --> 02:12:17.480]   than all the other things that--
[02:12:17.480 --> 02:12:22.080]   - But Yaron Brook also said that no government has,
[02:12:22.080 --> 02:12:23.480]   this is on your show,
[02:12:23.480 --> 02:12:26.120]   has ever worked in the way he's proposing.
[02:12:26.120 --> 02:12:29.240]   Now, objectivism, Ayn Rand's philosophy,
[02:12:29.240 --> 02:12:31.480]   is based on objective reality.
[02:12:31.480 --> 02:12:33.600]   And what she posited is,
[02:12:33.600 --> 02:12:35.720]   you look and study the facts of nature,
[02:12:35.720 --> 02:12:36.880]   study the facts of reality,
[02:12:36.880 --> 02:12:38.840]   and deduce things accordingly.
[02:12:38.840 --> 02:12:41.080]   And she very much regards herself
[02:12:41.080 --> 02:12:43.520]   as part of the Aristotelian tradition,
[02:12:43.520 --> 02:12:45.760]   as opposed to the Platonist tradition,
[02:12:45.760 --> 02:12:47.840]   where the idea precedes reality,
[02:12:47.840 --> 02:12:50.640]   and the idea is more real than what we see around us.
[02:12:50.640 --> 02:12:55.520]   So what he's saying is, all the data, according to him,
[02:12:55.520 --> 02:12:58.200]   contradicts his argument,
[02:12:58.200 --> 02:13:01.200]   but still, he's going to make this imaginary government
[02:13:01.200 --> 02:13:02.680]   that has never existed,
[02:13:02.680 --> 02:13:06.200]   and there's no evidence that it can exist.
[02:13:06.200 --> 02:13:09.000]   Let's talk about objective law.
[02:13:09.000 --> 02:13:11.120]   To have access to the legal system,
[02:13:11.120 --> 02:13:13.000]   which is something we want,
[02:13:13.000 --> 02:13:14.880]   even just in terms of selling disputes,
[02:13:14.880 --> 02:13:16.720]   when you have a government monopoly,
[02:13:16.720 --> 02:13:18.960]   it's going to be more expensive,
[02:13:18.960 --> 02:13:20.640]   more difficult for poor people.
[02:13:20.640 --> 02:13:22.800]   The cost of hiring a lawyer is more expensive
[02:13:22.800 --> 02:13:24.100]   than hiring a surgeon.
[02:13:24.100 --> 02:13:25.800]   You can't say with a straight face,
[02:13:25.800 --> 02:13:28.060]   this is the only way or the best way.
[02:13:28.060 --> 02:13:31.680]   Okay, so, and the other thing is,
[02:13:31.680 --> 02:13:32.960]   the argument for objectivism,
[02:13:32.960 --> 02:13:35.760]   they have this, against anarchism,
[02:13:35.760 --> 02:13:37.720]   they have this stupid claim, it's like,
[02:13:37.720 --> 02:13:41.880]   what if, you know, you're a member of one security company,
[02:13:41.880 --> 02:13:43.360]   and I'm a member of another,
[02:13:43.360 --> 02:13:45.520]   and we have a dispute, and one shows up the door,
[02:13:45.520 --> 02:13:47.040]   what happens now?
[02:13:47.040 --> 02:13:49.160]   As if this is some insuperable argument.
[02:13:49.160 --> 02:13:51.120]   Well, we have that on Earth.
[02:13:51.120 --> 02:13:53.000]   Every country is in a state of anarchism
[02:13:53.000 --> 02:13:54.200]   regarding every other country.
[02:13:54.200 --> 02:13:55.520]   We don't have a world government.
[02:13:55.520 --> 02:14:00.520]   So what happens if a Canadian kills an American in Mexico?
[02:14:00.520 --> 02:14:01.500]   I have no idea.
[02:14:01.500 --> 02:14:02.960]   I bet you don't have an idea.
[02:14:02.960 --> 02:14:06.680]   What I'm sure of is that system has been worked out
[02:14:06.680 --> 02:14:08.940]   ahead of time between the three countries,
[02:14:08.940 --> 02:14:11.200]   and it's been worked out in such a way
[02:14:11.200 --> 02:14:13.300]   that you and I don't have to reinvent the wheel.
[02:14:13.300 --> 02:14:15.160]   Same thing with cell phone companies.
[02:14:15.160 --> 02:14:17.480]   If I'm on Sprint, you're on Metro PCS,
[02:14:17.480 --> 02:14:19.360]   and I call you, who pays?
[02:14:19.360 --> 02:14:20.840]   Does Sprint pay you?
[02:14:20.840 --> 02:14:22.300]   Do they split the difference?
[02:14:22.300 --> 02:14:23.500]   First of all, there's no objective way
[02:14:23.500 --> 02:14:25.800]   that one has to work, but the thing is,
[02:14:25.800 --> 02:14:29.580]   companies who have auto accidents,
[02:14:29.580 --> 02:14:30.780]   they have arbitrage all the time.
[02:14:30.780 --> 02:14:33.220]   Like if I run into you, they work it out,
[02:14:33.220 --> 02:14:36.280]   and it never reaches our desk.
[02:14:36.280 --> 02:14:39.600]   So the only thing that cops are good at
[02:14:39.600 --> 02:14:42.000]   is keeping people, at any government monopoly,
[02:14:42.000 --> 02:14:43.760]   is forcing people to be their customers
[02:14:43.760 --> 02:14:45.400]   by keeping them unsafe.
[02:14:45.400 --> 02:14:49.180]   - Okay, there's a few things I'd like to say there
[02:14:49.180 --> 02:14:51.520]   that just explore some of these ideas.
[02:14:51.520 --> 02:14:55.120]   So one, in terms of Canadian and Mexico and so on,
[02:14:55.120 --> 02:14:58.800]   that it does, something has been worked out, perhaps.
[02:14:58.800 --> 02:15:00.400]   - Not perhaps, don't say perhaps.
[02:15:00.400 --> 02:15:02.920]   You know for sure that if you--
[02:15:02.920 --> 02:15:03.960]   - There's a point I'm trying to make.
[02:15:03.960 --> 02:15:06.460]   So let's say for sure it's been worked out.
[02:15:06.460 --> 02:15:10.200]   There was a point in history where it wasn't worked out.
[02:15:10.200 --> 02:15:15.000]   To work, to come to a place of stability,
[02:15:15.000 --> 02:15:16.960]   there has to first be some instability.
[02:15:16.960 --> 02:15:20.500]   So when you first, like for every kind of situation,
[02:15:21.260 --> 02:15:23.900]   it's like dispute over space.
[02:15:23.900 --> 02:15:26.420]   Like who gets to own Mars, that kind of thing.
[02:15:26.420 --> 02:15:29.540]   There's a first for it, and then these different
[02:15:29.540 --> 02:15:33.580]   competing institutions will have to figure it out.
[02:15:33.580 --> 02:15:36.420]   And so there's the concern with anarchism, I think,
[02:15:36.420 --> 02:15:38.580]   or with any kind of interaction.
[02:15:38.580 --> 02:15:41.820]   You said brilliantly that there's an anarchism
[02:15:41.820 --> 02:15:44.300]   relative to the, there's no one world government.
[02:15:44.300 --> 02:15:45.140]   - Right.
[02:15:45.140 --> 02:15:47.700]   - Alex Jones enters the chat, but.
[02:15:47.700 --> 02:15:49.820]   (laughing)
[02:15:49.820 --> 02:15:54.220]   - The, there's, the fear is that there's going to be
[02:15:54.220 --> 02:15:57.260]   an instability that doesn't converge
[02:15:57.260 --> 02:15:58.700]   towards some stable place.
[02:15:58.700 --> 02:16:00.940]   - That is not the fear, that is the goal
[02:16:00.940 --> 02:16:03.060]   under Ayn Rand's philosophy.
[02:16:03.060 --> 02:16:06.100]   Markets have something that they always talk about
[02:16:06.100 --> 02:16:07.980]   as being creatively destructive.
[02:16:07.980 --> 02:16:10.580]   Which means you look at something that's been happening
[02:16:10.580 --> 02:16:14.580]   for a very long time, every generation, every innovator
[02:16:14.580 --> 02:16:17.440]   starts chipping away at it, he finds better ways,
[02:16:17.440 --> 02:16:19.740]   marginal improvement, or it doesn't work,
[02:16:19.740 --> 02:16:20.900]   and he goes broke.
[02:16:20.900 --> 02:16:23.580]   When government tries to implement improvement,
[02:16:23.580 --> 02:16:25.500]   we all have to suffer the consequences.
[02:16:25.500 --> 02:16:28.100]   When an innovator does, it's a huge asymmetry.
[02:16:28.100 --> 02:16:30.000]   If it hurts, it only hurts him.
[02:16:30.000 --> 02:16:32.120]   If it succeeds, he becomes rich,
[02:16:32.120 --> 02:16:34.420]   and we all profit as a consequence.
[02:16:34.420 --> 02:16:35.900]   - But the fear of anarchism, I think,
[02:16:35.900 --> 02:16:39.740]   is that it will be non-creative destruction,
[02:16:39.740 --> 02:16:41.060]   it'll be just destruction.
[02:16:41.060 --> 02:16:45.500]   Right, it's not like the instability.
[02:16:45.500 --> 02:16:48.220]   - Let's give you, there's no, stability is one
[02:16:48.220 --> 02:16:50.020]   of these words that sounds objective
[02:16:50.020 --> 02:16:51.500]   but has no real meaning.
[02:16:51.500 --> 02:16:54.460]   What field has stability?
[02:16:54.460 --> 02:16:56.300]   If you had, let's suppose you want stability--
[02:16:56.300 --> 02:16:57.620]   - Relationships.
[02:16:57.620 --> 02:16:58.860]   - Let's talk about medicine.
[02:16:58.860 --> 02:17:01.100]   Stability means we're not gonna invent new diseases
[02:17:01.100 --> 02:17:02.620]   or new treatments, right?
[02:17:02.620 --> 02:17:06.780]   If you mean stability in terms of a baseline of security,
[02:17:06.780 --> 02:17:08.260]   we have that already.
[02:17:08.260 --> 02:17:11.360]   Very few relationships turn violent.
[02:17:11.360 --> 02:17:13.980]   Under an anarchist system, look at it right now,
[02:17:14.860 --> 02:17:18.780]   if you look at a bar full of drunken young males
[02:17:18.780 --> 02:17:22.360]   full of testosterone, if you look at a hotel
[02:17:22.360 --> 02:17:25.540]   where everyone is not native to the area,
[02:17:25.540 --> 02:17:29.140]   those are both far safer than the places
[02:17:29.140 --> 02:17:32.320]   that the government has taken upon itself to protect you.
[02:17:32.320 --> 02:17:36.320]   The parks, the alleyways, the streets, the subways.
[02:17:36.320 --> 02:17:39.620]   We have right now a comparison of which is better
[02:17:39.620 --> 02:17:42.840]   at keeping people safe, and it's very obvious
[02:17:42.840 --> 02:17:46.240]   that when something is private and under someone's control,
[02:17:46.240 --> 02:17:48.280]   and there would be layers of, there'd be more police,
[02:17:48.280 --> 02:17:50.400]   but they wouldn't be a government monopoly.
[02:17:50.400 --> 02:17:53.120]   The store would have someone, the street would have someone,
[02:17:53.120 --> 02:17:54.700]   and you'd have your own personal security
[02:17:54.700 --> 02:17:56.240]   that would be attached to your phone.
[02:17:56.240 --> 02:17:59.720]   Having security as a function of geography
[02:17:59.720 --> 02:18:02.460]   as opposed to a function of you as an individual
[02:18:02.460 --> 02:18:05.640]   is a landline technology in a post-cellphone world.
[02:18:05.640 --> 02:18:07.720]   - So you think it's possible to have,
[02:18:07.720 --> 02:18:10.520]   psychologically speaking, as an individual
[02:18:10.520 --> 02:18:13.360]   among the masses, to have a sense of security
[02:18:13.360 --> 02:18:16.960]   even though there's not a centralized thing
[02:18:16.960 --> 02:18:18.120]   at the bottom of the whole thing.
[02:18:18.120 --> 02:18:21.920]   So there's not a set of laws
[02:18:21.920 --> 02:18:23.840]   that are enforced based on geography,
[02:18:23.840 --> 02:18:24.880]   like we have nations now.
[02:18:24.880 --> 02:18:27.000]   You can have a set of laws that are enforced
[02:18:27.000 --> 02:18:30.180]   in some kind of emergent, agreed-upon way.
[02:18:30.180 --> 02:18:32.760]   So basically, I wanna go to a hotel
[02:18:32.760 --> 02:18:35.160]   and trust that I'll be able to get a room,
[02:18:35.160 --> 02:18:36.920]   and nobody's gonna break down the door,
[02:18:36.920 --> 02:18:40.480]   and I don't know, take all my vodka.
[02:18:40.480 --> 02:18:42.440]   - Let's take it a different way.
[02:18:42.440 --> 02:18:45.380]   If you were worried about a hotel having bedbugs,
[02:18:45.380 --> 02:18:47.320]   that's not something that government's involved in,
[02:18:47.320 --> 02:18:50.620]   what mechanism, and that's not an unrealistic concern,
[02:18:50.620 --> 02:18:53.240]   are there mechanisms right now that you can undertake
[02:18:53.240 --> 02:18:54.680]   to make sure that's not the case?
[02:18:54.680 --> 02:18:55.520]   - Yes.
[02:18:55.520 --> 02:18:57.080]   - So it would be the same thing with,
[02:18:57.080 --> 02:19:01.480]   I want to make sure I go to a hotel that has security.
[02:19:01.480 --> 02:19:03.080]   It would be exactly the same thing.
[02:19:03.080 --> 02:19:05.320]   And here's another example, kosher food.
[02:19:05.320 --> 02:19:08.300]   People who keep kosher, Jews who keep kosher,
[02:19:08.300 --> 02:19:10.320]   their food has to be prepared in a certain way.
[02:19:10.320 --> 02:19:12.960]   It has to meet higher rabbinical standards, right?
[02:19:12.960 --> 02:19:16.360]   If you look at food, it will have that certification,
[02:19:16.360 --> 02:19:18.400]   the K, and there's even competition there.
[02:19:18.400 --> 02:19:20.560]   There's the K, and there's the stricter U letter.
[02:19:20.560 --> 02:19:22.480]   People don't notice it 'cause they're not looking for it.
[02:19:22.480 --> 02:19:26.880]   You would have companies certifying different locales
[02:19:26.880 --> 02:19:28.240]   for their level of security,
[02:19:28.240 --> 02:19:32.600]   and it would take an hour to have an app
[02:19:32.600 --> 02:19:34.360]   just like when you have toll roads, right?
[02:19:34.360 --> 02:19:37.280]   That would tell you you're approaching an unsafe area,
[02:19:37.280 --> 02:19:38.800]   you're not gonna be covered by us,
[02:19:38.800 --> 02:19:41.880]   and you could have it color-coded very easily.
[02:19:41.880 --> 02:19:43.800]   We could do this today.
[02:19:43.800 --> 02:19:46.100]   - But the thing is, you're exactly correct,
[02:19:46.100 --> 02:19:49.520]   but there's an assumption of you're already in a,
[02:19:49.520 --> 02:19:51.400]   okay, you can give me a different word than stability,
[02:19:51.400 --> 02:19:54.840]   but you're already in a place where the forces
[02:19:54.840 --> 02:19:57.840]   of the market or whatever can operate.
[02:19:57.840 --> 02:20:00.900]   The worry is like, initially,
[02:20:00.900 --> 02:20:04.620]   you might not have enough stability
[02:20:04.620 --> 02:20:07.800]   to where you can choose one place over the other
[02:20:07.800 --> 02:20:10.120]   based on the security that they provide.
[02:20:10.120 --> 02:20:12.800]   - We already have different types of security here
[02:20:12.800 --> 02:20:14.320]   because we have federal government,
[02:20:14.320 --> 02:20:17.840]   we have state governments, and we have local governments,
[02:20:17.840 --> 02:20:20.460]   and these often contradict each other.
[02:20:20.460 --> 02:20:22.400]   So the idea of the implausibility
[02:20:22.400 --> 02:20:24.920]   of having different security companies
[02:20:24.920 --> 02:20:27.480]   and having it be unstable or impossible,
[02:20:27.480 --> 02:20:30.400]   we already have a very rough example
[02:20:30.400 --> 02:20:31.640]   of it happening in real life.
[02:20:31.640 --> 02:20:33.080]   - But all of it started,
[02:20:35.000 --> 02:20:38.160]   the idea of, especially with Yaron,
[02:20:38.160 --> 02:20:42.640]   is it all started with government monopoly of violence
[02:20:42.640 --> 02:20:47.120]   saying, "No, kids, don't let violence get out of hand."
[02:20:47.120 --> 02:20:49.280]   So how do-- - We had a civil war
[02:20:49.280 --> 02:20:51.600]   where half the country was slaughtered.
[02:20:51.600 --> 02:20:53.840]   - That's a display of the government
[02:20:53.840 --> 02:20:56.640]   not having a monopoly on the violence, right?
[02:20:56.640 --> 02:20:58.240]   It's like, that's the split.
[02:20:58.240 --> 02:21:00.440]   - It had such a monopoly on the violence in the North
[02:21:00.440 --> 02:21:03.040]   that it could draft people to fight others
[02:21:03.040 --> 02:21:03.880]   that they didn't even care about.
[02:21:03.880 --> 02:21:08.880]   - There's a South, so it's the government splitting.
[02:21:08.880 --> 02:21:13.080]   It's like a giant iceberg splitting.
[02:21:13.080 --> 02:21:16.720]   The argument is that you would have something
[02:21:16.720 --> 02:21:19.740]   like a civil war much more often under anarchism.
[02:21:19.740 --> 02:21:25.040]   - First of all, if you had a civil war much more often,
[02:21:25.040 --> 02:21:27.600]   we don't have that with car companies, right?
[02:21:27.600 --> 02:21:28.880]   There's no car company that says,
[02:21:28.880 --> 02:21:32.060]   "I refuse to pay you," or whatever.
[02:21:32.060 --> 02:21:34.580]   - That's not violence, sorry to interrupt.
[02:21:34.580 --> 02:21:36.460]   And I'm playing-- - Hold on, let me finish.
[02:21:36.460 --> 02:21:38.960]   It is violence because if I'm a company
[02:21:38.960 --> 02:21:42.880]   and I'm saying that my cars can run over yours
[02:21:42.880 --> 02:21:45.600]   with no consequences, this is a rough analog,
[02:21:45.600 --> 02:21:48.080]   why has that not happened?
[02:21:48.080 --> 02:21:50.980]   Now, in terms of having security system,
[02:21:50.980 --> 02:21:53.940]   if I am free, just like switching cell phone
[02:21:53.940 --> 02:21:56.100]   to go from one provider to another,
[02:21:56.100 --> 02:21:58.140]   and this one company as part of its payment
[02:21:58.140 --> 02:22:00.700]   doesn't want $50 a month, $100 a month,
[02:22:00.700 --> 02:22:03.820]   wants my son, I'm not going to be a member
[02:22:03.820 --> 02:22:07.100]   of this security company unless, in that case,
[02:22:07.100 --> 02:22:08.800]   we're dealing with something like a Pearl Harbor
[02:22:08.800 --> 02:22:12.020]   or foreign invasion where it's all hands on deck.
[02:22:12.020 --> 02:22:13.660]   - Let's go by evidence.
[02:22:13.660 --> 02:22:15.780]   How many places do we have evidence of
[02:22:15.780 --> 02:22:18.040]   that you can have at a large scale?
[02:22:18.040 --> 02:22:20.940]   - Why is that at a large scale?
[02:22:20.940 --> 02:22:24.260]   - Because it feels like once you don't know the person.
[02:22:24.260 --> 02:22:25.480]   - What about eBay?
[02:22:25.480 --> 02:22:27.580]   eBay is an example of anarchist in practice.
[02:22:27.580 --> 02:22:29.480]   I am selling something to someone whose name
[02:22:29.480 --> 02:22:31.200]   I don't even know in a country that is
[02:22:31.200 --> 02:22:34.460]   nowhere approximate to me, and eBay acts as the arbiter.
[02:22:34.460 --> 02:22:36.780]   Sometimes I don't get the money after I get screwed over,
[02:22:36.780 --> 02:22:38.800]   but that's far less than the taxation
[02:22:38.800 --> 02:22:40.520]   that I have to give to the federal government.
[02:22:40.520 --> 02:22:43.580]   - It's a great point, but it's in the space of finance.
[02:22:43.580 --> 02:22:48.580]   If I could, if on eBay, you could also commit violence.
[02:22:48.580 --> 02:22:50.620]   - Theft is violence.
[02:22:50.620 --> 02:22:51.860]   - No.
[02:22:51.860 --> 02:22:54.940]   - Yeah, if you give me 10 grand for a car
[02:22:54.940 --> 02:22:56.100]   and I don't deliver anything,
[02:22:56.100 --> 02:22:57.420]   you've stolen 10 grand from me.
[02:22:57.420 --> 02:23:02.420]   - Yes, but there's something uniquely problematic
[02:23:02.420 --> 02:23:06.200]   to being stabbed or shot.
[02:23:06.200 --> 02:23:08.600]   - The reason you're stabbed or shot is because
[02:23:08.600 --> 02:23:10.960]   the government, despite its contract,
[02:23:10.960 --> 02:23:13.960]   is refusing to allow Second Amendment rights
[02:23:13.960 --> 02:23:16.120]   to be implemented among the citizenry,
[02:23:16.120 --> 02:23:20.040]   and the people who are making that the case are the cops.
[02:23:20.040 --> 02:23:22.480]   They are the ones who are the traitors to the Constitution
[02:23:22.480 --> 02:23:24.240]   and should be regarded as such,
[02:23:24.240 --> 02:23:27.700]   whereas private companies are far more amenable
[02:23:27.700 --> 02:23:29.860]   to market pressures than the state is.
[02:23:29.860 --> 02:23:32.140]   - It's a strong argument,
[02:23:32.140 --> 02:23:37.140]   but let's actually just briefly mention the scale thing.
[02:23:37.140 --> 02:23:40.500]   Why don't you think we should talk about scale?
[02:23:40.500 --> 02:23:42.780]   - Because if you had anarchism just in Vermont
[02:23:42.780 --> 02:23:45.460]   or just in Brooklyn, fine.
[02:23:45.460 --> 02:23:47.060]   The people make the argument you need anarchism
[02:23:47.060 --> 02:23:48.660]   or else China's gonna invade,
[02:23:48.660 --> 02:23:50.580]   but that's like saying, what,
[02:23:50.580 --> 02:23:52.060]   do these little countries don't exist?
[02:23:52.060 --> 02:23:53.460]   Does San Salvador not exist?
[02:23:53.460 --> 02:23:55.140]   Some of them are violent, some of them are not,
[02:23:55.140 --> 02:23:57.380]   but the point is they're not all,
[02:23:57.380 --> 02:23:59.380]   at a moment's notice, about to be invaded.
[02:23:59.380 --> 02:24:00.820]   Kuwait's an example of this.
[02:24:00.820 --> 02:24:02.500]   Kuwait was invaded by Iraq,
[02:24:02.500 --> 02:24:04.660]   and very quickly all the big countries
[02:24:04.660 --> 02:24:08.620]   who were interested in having your stability, safe space,
[02:24:08.620 --> 02:24:11.180]   got involved and kicked them out of Kuwait.
[02:24:11.180 --> 02:24:13.740]   If you had this company
[02:24:13.740 --> 02:24:15.700]   that was waging war on the population,
[02:24:15.700 --> 02:24:18.180]   it seems quite likely that the other organization
[02:24:18.180 --> 02:24:19.860]   would get together and put a stop to this
[02:24:19.860 --> 02:24:21.020]   because they're not in a position
[02:24:21.020 --> 02:24:23.580]   to provide this service of security to their customers.
[02:24:23.580 --> 02:24:25.300]   - Okay, all this is brilliant,
[02:24:25.300 --> 02:24:28.700]   but didn't you just say that we are actually
[02:24:28.700 --> 02:24:32.260]   in a state of anarchism relative to other countries?
[02:24:32.260 --> 02:24:33.100]   - Yes.
[02:24:33.100 --> 02:24:35.260]   - So isn't this what emerges?
[02:24:35.260 --> 02:24:38.080]   This is what, aren't we actually living
[02:24:38.080 --> 02:24:41.900]   in a state of anarchism where we all have agreed?
[02:24:41.900 --> 02:24:43.020]   - I haven't agreed to anything.
[02:24:43.020 --> 02:24:45.740]   - So the basic criticism you have is
[02:24:45.740 --> 02:24:48.500]   you're born on a geographical land,
[02:24:49.500 --> 02:24:52.700]   a geographical area, and you're forced
[02:24:52.700 --> 02:24:55.940]   to have signed a bunch of stuff just by being born
[02:24:55.940 --> 02:24:57.380]   in a particular place.
[02:24:57.380 --> 02:25:02.380]   So really, if you could just much easier choose
[02:25:02.380 --> 02:25:08.620]   which space of ideas you are associated with,
[02:25:08.620 --> 02:25:10.740]   that would be actually a state of anarchism.
[02:25:10.740 --> 02:25:11.580]   - Yes.
[02:25:11.580 --> 02:25:16.620]   - And you could have a military that you sign up with.
[02:25:16.620 --> 02:25:17.460]   - Sure.
[02:25:18.260 --> 02:25:20.180]   - And you're certainly not putting people in prison
[02:25:20.180 --> 02:25:22.780]   to get raped because they're selling drugs.
[02:25:22.780 --> 02:25:23.620]   - Yeah.
[02:25:23.620 --> 02:25:27.940]   - And you're certainly not allowing everyone else
[02:25:27.940 --> 02:25:30.300]   on the street who wants to be there.
[02:25:30.300 --> 02:25:32.620]   - Can we say something nice about Ayn Rand?
[02:25:32.620 --> 02:25:34.740]   - I can talk about nice things about her all day.
[02:25:34.740 --> 02:25:36.420]   I own her copy of The Fountainhead, you know.
[02:25:36.420 --> 02:25:40.380]   - What to you is Ayn Rand's best idea,
[02:25:40.380 --> 02:25:43.820]   one that you find impactful, insightful, useful
[02:25:43.820 --> 02:25:46.700]   for us in modern society that you think about?
[02:25:46.700 --> 02:25:51.700]   - That your life has meaning and productive work
[02:25:51.700 --> 02:25:56.860]   is your highest value, and that you shouldn't apologize,
[02:25:56.860 --> 02:25:58.860]   and this is something I despise,
[02:25:58.860 --> 02:26:00.940]   you shouldn't apologize for saying,
[02:26:00.940 --> 02:26:05.640]   I want to be happy and I'm going to work toward that.
[02:26:05.640 --> 02:26:08.980]   And that, as a few others, that you owe nobody else,
[02:26:08.980 --> 02:26:12.540]   some random stranger, a second of your time.
[02:26:12.540 --> 02:26:14.940]   You see this a lot on Twitter and social media,
[02:26:14.940 --> 02:26:17.660]   people demanding a debate, or demanding you act
[02:26:17.660 --> 02:26:19.740]   a certain way, and engage with them.
[02:26:19.740 --> 02:26:21.940]   You don't owe them anything.
[02:26:21.940 --> 02:26:26.140]   So I think those are some of her best ideas.
[02:26:26.140 --> 02:26:27.260]   And she teaches you how to think.
[02:26:27.260 --> 02:26:28.500]   Ayn Rand does not have all the answers,
[02:26:28.500 --> 02:26:29.820]   but she has all the questions.
[02:26:29.820 --> 02:26:31.020]   - Do you think, what do you think
[02:26:31.020 --> 02:26:32.300]   about the whole selfishness thing?
[02:26:32.300 --> 02:26:37.300]   I mean, are you triggered by the word selfishness?
[02:26:37.300 --> 02:26:39.180]   - It's really unfortunate what she does,
[02:26:39.180 --> 02:26:40.540]   because you were just talking earlier
[02:26:40.540 --> 02:26:43.140]   about mold bug being carelessly.
[02:26:43.140 --> 02:26:47.380]   She, this is indefensible in my opinion.
[02:26:47.380 --> 02:26:50.500]   So she talks about the virtue of selfishness,
[02:26:50.500 --> 02:26:54.420]   and she claims that when people talk about selfishness,
[02:26:54.420 --> 02:26:57.420]   they mean concern primarily with the self.
[02:26:57.420 --> 02:26:58.260]   They don't.
[02:26:58.260 --> 02:26:59.500]   When people talk about selfishness,
[02:26:59.500 --> 02:27:01.340]   they mean in a sociopathic way,
[02:27:01.340 --> 02:27:03.620]   concern exclusively with oneself, right?
[02:27:03.620 --> 02:27:06.940]   They mean like, oh, if someone is dying on the street,
[02:27:06.940 --> 02:27:10.180]   I'm not gonna even waste a second saving them,
[02:27:10.180 --> 02:27:11.340]   because I'm selfish.
[02:27:11.380 --> 02:27:14.460]   So she sets up this complete caricature of the term.
[02:27:14.460 --> 02:27:19.220]   When she's attacking selflessness in her best sense
[02:27:19.220 --> 02:27:22.660]   is when there are people who have no sense of self.
[02:27:22.660 --> 02:27:25.180]   They have no values of their own.
[02:27:25.180 --> 02:27:26.940]   They have no goals of their own.
[02:27:26.940 --> 02:27:29.460]   Everything that's in their mind is gotten secondhand
[02:27:29.460 --> 02:27:30.860]   from the culture at large,
[02:27:30.860 --> 02:27:33.700]   and there's nothing unique or special
[02:27:33.700 --> 02:27:36.460]   from their perspective worth fighting for.
[02:27:36.460 --> 02:27:40.940]   So when she attacks, when she advocates for the self,
[02:27:40.940 --> 02:27:42.940]   she basically means self-development,
[02:27:42.940 --> 02:27:44.860]   self-improvement, and achievement.
[02:27:44.860 --> 02:27:48.860]   So I think that word choice is really false
[02:27:48.860 --> 02:27:52.260]   and needlessly off-putting.
[02:27:52.260 --> 02:27:53.580]   - Yeah.
[02:27:53.580 --> 02:27:55.260]   Controversial, perhaps for the purpose
[02:27:55.260 --> 02:27:56.780]   of being controversial, I don't know.
[02:27:56.780 --> 02:27:59.220]   - But it's just, it's not accurate.
[02:27:59.220 --> 02:28:01.660]   That's not what people mean by selfishness.
[02:28:01.660 --> 02:28:04.580]   - Yeah, I would say it's one of the reasons
[02:28:04.580 --> 02:28:09.340]   probably her philosophy is not as much adopted
[02:28:09.340 --> 02:28:11.500]   or thought about is like, it's funny,
[02:28:11.500 --> 02:28:13.420]   like the use of words means something.
[02:28:13.420 --> 02:28:15.660]   Exactly as you said, that's my criticism,
[02:28:15.660 --> 02:28:18.180]   that's just my bug, which could be incorrect criticism,
[02:28:18.180 --> 02:28:20.280]   by the way, so I'm not exactly sure.
[02:28:20.280 --> 02:28:26.420]   Can we talk about some modern day chaos and politics?
[02:28:26.420 --> 02:28:29.840]   - Yes, please, I hate chaos.
[02:28:29.840 --> 02:28:32.500]   - Speaking of your hatred for chaos,
[02:28:32.500 --> 02:28:34.060]   let's talk about secession.
[02:28:34.060 --> 02:28:36.340]   - Oh yeah, I was the first one on this trip.
[02:28:36.340 --> 02:28:39.260]   - Yeah, you were, well, the Civil War beat you to it,
[02:28:39.260 --> 02:28:40.540]   but-- - Sure,
[02:28:40.540 --> 02:28:41.660]   in contemporary times.
[02:28:41.660 --> 02:28:45.380]   - In contemporary times, you were on this.
[02:28:45.380 --> 02:28:49.440]   Can you talk about what is the idea of secession?
[02:28:49.440 --> 02:28:52.580]   What are the odds that it might happen?
[02:28:52.580 --> 02:28:56.100]   What does it mean for the United States
[02:28:56.100 --> 02:28:58.460]   in some way for different states to secede?
[02:28:58.460 --> 02:29:00.060]   - Sure, America's been one country
[02:29:00.060 --> 02:29:02.620]   with several cultures since the beginning.
[02:29:02.620 --> 02:29:05.380]   There's absolutely no reason for someone,
[02:29:05.380 --> 02:29:07.220]   this goes back to the anarchist idea,
[02:29:07.220 --> 02:29:10.380]   if you despise Donald Trump, which is your prerogative,
[02:29:10.380 --> 02:29:13.660]   if you think Joe Biden is a clown, which is your prerogative,
[02:29:13.660 --> 02:29:16.940]   there's absolutely no reason for you to be governed
[02:29:16.940 --> 02:29:18.780]   by someone you disapprove of.
[02:29:18.780 --> 02:29:21.340]   This is an incoherent, nonsensical concept.
[02:29:21.340 --> 02:29:23.860]   The only reason we even take it as a hypothesis
[02:29:23.860 --> 02:29:27.020]   is that we're trained to the contrary since kindergarten.
[02:29:27.020 --> 02:29:30.180]   A secession, I don't know along what lines,
[02:29:30.180 --> 02:29:33.980]   but increasingly, it's becoming harder and harder
[02:29:33.980 --> 02:29:36.060]   for people to have conversations.
[02:29:36.060 --> 02:29:38.380]   I think social media, and this is something people
[02:29:38.380 --> 02:29:40.420]   despise social media for, I think this is something
[02:29:40.420 --> 02:29:43.660]   that social media has done well, which I'm advocating for,
[02:29:43.660 --> 02:29:47.300]   is it tends to kind of run through ideas
[02:29:47.300 --> 02:29:48.740]   through like an evolutionary process
[02:29:48.740 --> 02:29:51.060]   and drive them to the logical conclusion.
[02:29:51.060 --> 02:29:52.640]   So it's very hard to be a moderate online
[02:29:52.640 --> 02:29:55.340]   'cause there's gonna be people pushing through your ideas
[02:29:55.340 --> 02:29:56.980]   through several cycles, and then you're gonna end up
[02:29:56.980 --> 02:29:58.680]   at some kind of more pure,
[02:29:58.680 --> 02:30:01.760]   or if you wanna dislike it, extreme perspective.
[02:30:01.760 --> 02:30:03.660]   Having these different pockets,
[02:30:04.740 --> 02:30:07.420]   it's not really governable 'cause people fundamentally
[02:30:07.420 --> 02:30:08.980]   have different worldviews.
[02:30:08.980 --> 02:30:11.180]   So I don't know what secession would look like.
[02:30:11.180 --> 02:30:15.580]   I think the number is really increasing
[02:30:15.580 --> 02:30:17.380]   at an exponential rate.
[02:30:17.380 --> 02:30:19.300]   I do not think-- - The number of supporters.
[02:30:19.300 --> 02:30:20.380]   - Of supporters.
[02:30:20.380 --> 02:30:22.740]   I think the claim that this can only be accomplished
[02:30:22.740 --> 02:30:25.900]   through violence is false, it's a lie.
[02:30:25.900 --> 02:30:28.020]   Just like any divorce doesn't have to involve
[02:30:28.020 --> 02:30:30.060]   beating your ex-husband or ex-wife.
[02:30:30.060 --> 02:30:34.060]   So, and I'm very much looking forward to this
[02:30:34.060 --> 02:30:38.700]   becoming a reality far quicker than I ever expected.
[02:30:38.700 --> 02:30:40.460]   - Well, do you think there's a value
[02:30:40.460 --> 02:30:45.460]   of competing worldviews being forced
[02:30:45.460 --> 02:30:52.140]   to be in the same space? - Yes, but within a context.
[02:30:52.140 --> 02:30:56.700]   So we can agree, if group one thinks A, B, and C
[02:30:56.700 --> 02:30:59.180]   are the fundamental aspects of their worldview
[02:30:59.180 --> 02:31:03.220]   and argue within that, and group two thinks D, E, and F
[02:31:03.220 --> 02:31:05.380]   and argue within that, so you're gonna have
[02:31:05.380 --> 02:31:06.980]   a lot of argument within those space.
[02:31:06.980 --> 02:31:09.880]   But if there's fundamental differences in worldview,
[02:31:09.880 --> 02:31:13.620]   there's no reason to be, especially when each views
[02:31:13.620 --> 02:31:15.540]   the other as completely incoherent and unreasonable.
[02:31:15.540 --> 02:31:20.500]   - Do you think there's a line of fundamentally different
[02:31:20.500 --> 02:31:25.500]   worldviews that, along which a secession will happen
[02:31:25.500 --> 02:31:27.420]   in the United States?
[02:31:27.420 --> 02:31:29.100]   Like is there something that emerges to you
[02:31:29.100 --> 02:31:34.100]   as a set of ideas that are like, what do you call that?
[02:31:34.100 --> 02:31:39.500]   Like you can't come to an agreement over.
[02:31:39.500 --> 02:31:40.780]   - Yeah, I think that's already happening.
[02:31:40.780 --> 02:31:44.100]   Like with the masks, I think there's just two
[02:31:44.100 --> 02:31:46.820]   fundamental perspective, and each one thinks
[02:31:46.820 --> 02:31:51.680]   the other is insane and also deadly and destructive.
[02:31:51.680 --> 02:31:56.460]   And I don't see how there's any discourse on this topic.
[02:31:56.460 --> 02:31:58.300]   - So on the left--
[02:31:58.300 --> 02:31:59.540]   - I wouldn't say it's left versus right.
[02:31:59.540 --> 02:32:02.300]   I think it's people who are pro-risk
[02:32:02.300 --> 02:32:04.000]   versus people who are risk-averse.
[02:32:04.000 --> 02:32:10.340]   - Yeah, so risk-averse, and then there's like a hope
[02:32:10.340 --> 02:32:15.340]   for the comfort of the sort of centralized science,
[02:32:15.340 --> 02:32:21.580]   giving the truth, and then everybody must follow the truth
[02:32:21.580 --> 02:32:23.100]   of the proper way to behave.
[02:32:23.100 --> 02:32:27.100]   And then there's, on the other side, a distrust
[02:32:27.100 --> 02:32:29.740]   of any kind of centralized institutions,
[02:32:29.740 --> 02:32:34.740]   of anybody who might use control to try to gain
[02:32:34.740 --> 02:32:38.660]   greater and greater power, and masks are a symbol of that.
[02:32:38.660 --> 02:32:42.580]   And even if masks are or are not a--
[02:32:42.580 --> 02:32:43.420]   - Efficacious, yeah.
[02:32:43.420 --> 02:32:48.140]   - Yeah, effective way of stopping the virus,
[02:32:48.140 --> 02:32:51.100]   which is really unfortunate to me from a perspective.
[02:32:51.100 --> 02:32:53.460]   I happen to be on a survey paper about masks.
[02:32:53.460 --> 02:32:56.380]   Like people don't seem to care about the data or so on.
[02:32:56.380 --> 02:32:57.740]   - Correct.
[02:32:57.740 --> 02:33:01.460]   - This has become just a nice point on which
[02:33:01.460 --> 02:33:05.940]   to then highlight the difference between the two sides.
[02:33:05.940 --> 02:33:10.900]   Yeah, it's really, I mean, it sounds kind of on the face,
[02:33:10.900 --> 02:33:12.500]   kind of ridiculous that the secession
[02:33:12.500 --> 02:33:13.580]   would occur over a mask.
[02:33:13.580 --> 02:33:15.500]   - It wouldn't, but I'm saying this is an example
[02:33:15.500 --> 02:33:16.700]   of something where there's a clean break.
[02:33:16.700 --> 02:33:17.700]   - Yes.
[02:33:17.700 --> 02:33:22.700]   - And risk-averse versus someone who's risk-seeking,
[02:33:22.700 --> 02:33:25.460]   these are just two fundamentally different perspectives.
[02:33:25.460 --> 02:33:26.860]   Do you want to have an NHS,
[02:33:26.860 --> 02:33:29.780]   or do you have one of a market-based healthcare system?
[02:33:29.780 --> 02:33:32.220]   You can make very valid arguments for both.
[02:33:32.220 --> 02:33:34.420]   There's no reason for everyone to be under one.
[02:33:34.420 --> 02:33:36.800]   - But you think that's not something that's,
[02:33:36.800 --> 02:33:40.420]   you think that's irreconcilable, if that's the word,
[02:33:40.420 --> 02:33:41.260]   - Yeah.
[02:33:41.260 --> 02:33:44.460]   - That that's not in the space of ideas
[02:33:44.460 --> 02:33:46.220]   that you can have in the same room together,
[02:33:46.220 --> 02:33:49.260]   and they fight at each other and ultimately make progress.
[02:33:49.260 --> 02:33:51.700]   That secession is the more effective way
[02:33:51.700 --> 02:33:52.780]   to proceed forward.
[02:33:52.780 --> 02:33:53.620]   - Yes.
[02:33:54.140 --> 02:33:59.140]   - Well, do you see a possible world
[02:33:59.140 --> 02:34:01.380]   where no is the answer?
[02:34:01.380 --> 02:34:04.060]   Meaning, I know you say yes,
[02:34:04.060 --> 02:34:06.420]   because you kind of lean on the side of freedom
[02:34:06.420 --> 02:34:08.020]   and anarchism.
[02:34:08.020 --> 02:34:08.900]   - Yes.
[02:34:08.900 --> 02:34:10.600]   - Like you make, you want to make,
[02:34:10.600 --> 02:34:14.980]   let me make an argument in terms of divorce,
[02:34:14.980 --> 02:34:19.020]   which is in your worldview or your intuition
[02:34:19.020 --> 02:34:22.700]   is you want to make secession as frictionless as possible.
[02:34:22.700 --> 02:34:23.540]   - Of course.
[02:34:23.540 --> 02:34:25.740]   - Along all lines, not just like states or whatever,
[02:34:25.740 --> 02:34:29.140]   just like you want to choose, you want to be free.
[02:34:29.140 --> 02:34:30.580]   - Yeah, and peaceful.
[02:34:30.580 --> 02:34:34.420]   - Let me make my authoritarian Russian,
[02:34:34.420 --> 02:34:35.700]   - Okay, Papa Stalin.
[02:34:35.700 --> 02:34:39.460]   - Papa Stalin argument in terms of relationships.
[02:34:39.460 --> 02:34:42.900]   Like when shit goes wrong in a relationship,
[02:34:42.900 --> 02:34:44.000]   - Watch your language.
[02:34:44.000 --> 02:34:50.620]   - Okay, there's only a place for one Stalin at this table.
[02:34:50.620 --> 02:34:51.460]   Okay?
[02:34:51.460 --> 02:34:52.980]   - Okay, I'll get to be Lenin.
[02:34:52.980 --> 02:34:55.060]   - No, you get to be like Merkel
[02:34:55.060 --> 02:34:57.060]   as our previous discussion with Putin.
[02:34:57.060 --> 02:34:59.480]   Okay, don't let me unleash the hounds.
[02:34:59.480 --> 02:35:04.500]   You know, you want to work through some of the troubles
[02:35:04.500 --> 02:35:05.620]   before you get divorced.
[02:35:05.620 --> 02:35:07.740]   Like you want to do the work in relationships sometimes.
[02:35:07.740 --> 02:35:09.020]   Like it goes up and down.
[02:35:09.020 --> 02:35:11.380]   - It's been 200 plus years.
[02:35:11.380 --> 02:35:13.180]   It's done.
[02:35:13.180 --> 02:35:16.400]   - But in the, listen, okay, so it's not a one night stand,
[02:35:16.400 --> 02:35:17.340]   but you know.
[02:35:17.340 --> 02:35:20.740]   - Look at Trump, this, I don't see the middle ground.
[02:35:20.740 --> 02:35:24.100]   He's either a complete calamity buffoon
[02:35:24.100 --> 02:35:26.740]   or he's been the first great president we've had
[02:35:26.740 --> 02:35:29.140]   in like many, many years.
[02:35:29.140 --> 02:35:31.960]   - So you think that there's something different now
[02:35:31.960 --> 02:35:33.300]   than it was 20 years ago?
[02:35:33.300 --> 02:35:36.040]   - Yes, social media and access to information.
[02:35:36.040 --> 02:35:39.380]   - And the division will only increase, you think?
[02:35:39.380 --> 02:35:40.220]   - Oh, yes.
[02:35:40.220 --> 02:35:42.820]   - So Trump is not an accident of history.
[02:35:42.820 --> 02:35:46.540]   - So they thought Trump was the river, but he was the dam.
[02:35:46.540 --> 02:35:47.960]   Trump was the dam.
[02:35:47.960 --> 02:35:50.860]   They thought he was the river.
[02:35:50.860 --> 02:35:55.700]   So in that analogy, Trump being gone makes things worse.
[02:35:55.700 --> 02:35:57.300]   - Yes, for that perspective.
[02:35:57.300 --> 02:35:59.960]   Because now things are really gonna hit the fan.
[02:35:59.960 --> 02:36:04.620]   - So what are the odds of secession?
[02:36:04.620 --> 02:36:05.460]   - I don't know.
[02:36:05.460 --> 02:36:10.260]   And my desperate hope is that it's peaceful.
[02:36:10.260 --> 02:36:12.860]   But I think the number of people who are becoming
[02:36:12.860 --> 02:36:14.660]   very comfortable with the violence
[02:36:14.660 --> 02:36:16.300]   is making me very unsettled.
[02:36:17.220 --> 02:36:20.820]   - Well, I see words as violence and your Twitter.
[02:36:20.820 --> 02:36:24.020]   - It's like Hiroshima, times a million.
[02:36:24.020 --> 02:36:28.700]   - Sometimes I curl up in the corner crying
[02:36:28.700 --> 02:36:30.340]   after I check your Twitter feed.
[02:36:30.340 --> 02:36:37.740]   But in all seriousness, you think it's possible
[02:36:37.740 --> 02:36:39.740]   to do nonviolent secession?
[02:36:39.740 --> 02:36:41.780]   - It's a good check of Slovakia.
[02:36:41.780 --> 02:36:43.120]   Look at Brexit.
[02:36:43.120 --> 02:36:44.460]   Brexit was a secession.
[02:36:46.120 --> 02:36:47.500]   - Right, right.
[02:36:47.500 --> 02:36:48.820]   So you can have--
[02:36:48.820 --> 02:36:50.680]   - Civil War did not need to be fought.
[02:36:50.680 --> 02:36:52.580]   That would have been a nonviolent secession.
[02:36:52.580 --> 02:36:54.020]   And if you worry about slavery,
[02:36:54.020 --> 02:36:55.420]   you could have bought off all the slaves,
[02:36:55.420 --> 02:36:56.860]   import them to the North.
[02:36:56.860 --> 02:36:58.740]   It still would have been cheaper and less loss of life
[02:36:58.740 --> 02:37:01.220]   and probably better for race relations.
[02:37:01.220 --> 02:37:03.940]   - Yeah, I don't know enough history to wonder about
[02:37:03.940 --> 02:37:05.980]   how the Civil War could have been avoided.
[02:37:05.980 --> 02:37:07.700]   - Well, that's how.
[02:37:07.700 --> 02:37:10.060]   - Is, well, conversation?
[02:37:10.060 --> 02:37:11.740]   So like--
[02:37:11.740 --> 02:37:12.820]   - No, no, if they want to secede,
[02:37:12.820 --> 02:37:14.460]   say, look, here's what we're gonna do.
[02:37:14.460 --> 02:37:16.080]   We're gonna let you secede,
[02:37:16.080 --> 02:37:18.080]   but you have to end slavery.
[02:37:18.080 --> 02:37:19.240]   They seceded because of slavery.
[02:37:19.240 --> 02:37:20.080]   Here's the other thing.
[02:37:20.080 --> 02:37:21.580]   There's like this, some circles of conservatism
[02:37:21.580 --> 02:37:23.320]   have this myth that, oh, it wasn't about slavery,
[02:37:23.320 --> 02:37:24.440]   it was about states' rights.
[02:37:24.440 --> 02:37:26.240]   Well, if you go back, every state,
[02:37:26.240 --> 02:37:28.400]   when they seceded, released a press release,
[02:37:28.400 --> 02:37:30.840]   and they said explicitly, we're doing this 'cause of slavery.
[02:37:30.840 --> 02:37:33.960]   So that is an abomination that needs to be taken care of.
[02:37:33.960 --> 02:37:37.800]   But the way, other countries have ended slavery peacefully.
[02:37:37.800 --> 02:37:41.000]   One of the ways to do it is pay them by all,
[02:37:41.000 --> 02:37:42.400]   and we end up doing this after the war.
[02:37:42.400 --> 02:37:45.200]   I think the South people got reparations,
[02:37:45.200 --> 02:37:47.440]   the slave owners, it was just insane.
[02:37:47.440 --> 02:37:50.160]   Bring them North, wanna go to Canada, whatever,
[02:37:50.160 --> 02:37:52.360]   and you agree, and that's our peace treaty.
[02:37:52.360 --> 02:37:56.160]   Because the people who died weren't the slave owners.
[02:37:56.160 --> 02:37:57.780]   It was white trash.
[02:37:57.780 --> 02:37:59.920]   And it was, that's who always,
[02:37:59.920 --> 02:38:01.200]   and I hate that that's the term.
[02:38:01.200 --> 02:38:02.360]   I can't think of a better one.
[02:38:02.360 --> 02:38:04.240]   But that's who always ends up fighting these wars often,
[02:38:04.240 --> 02:38:07.320]   disproportionately, it's poor people and uneducated people.
[02:38:07.320 --> 02:38:09.760]   And I do not regard them as cannon fodder.
[02:38:09.760 --> 02:38:10.920]   I think it's horrible.
[02:38:11.760 --> 02:38:14.160]   - So what would it look like?
[02:38:14.160 --> 02:38:16.480]   There'll be two founding documents?
[02:38:16.480 --> 02:38:18.320]   - Yeah, they had their constitution.
[02:38:18.320 --> 02:38:20.640]   - Which I don't know the history of that.
[02:38:20.640 --> 02:38:21.760]   - Yeah, they had a constitution,
[02:38:21.760 --> 02:38:23.520]   but it was much more decentralized.
[02:38:23.520 --> 02:38:26.520]   - If secession doesn't happen.
[02:38:26.520 --> 02:38:27.340]   - Yeah.
[02:38:27.340 --> 02:38:33.440]   - You said that Donald Trump was the dam, not the river.
[02:38:33.440 --> 02:38:34.280]   - Yeah.
[02:38:34.280 --> 02:38:37.800]   - That sounds like Walt Whitman or something.
[02:38:37.800 --> 02:38:40.040]   It's poetry, okay.
[02:38:40.040 --> 02:38:41.440]   - Are you flirting with me?
[02:38:41.440 --> 02:38:45.880]   - You know us, we don't flirt.
[02:38:45.880 --> 02:38:50.440]   We just club and drag you to the cave.
[02:38:50.440 --> 02:38:51.640]   - We hammer and sickle.
[02:38:51.640 --> 02:38:54.560]   - And you don't wanna know about the sickle.
[02:38:54.560 --> 02:38:56.600]   It's not good cop, bad cop.
[02:38:56.600 --> 02:38:57.700]   - Bad cop, worse cop.
[02:38:57.700 --> 02:39:04.240]   - Yeah, what do you think 2024 looks like
[02:39:04.240 --> 02:39:07.400]   in terms of the candidates?
[02:39:07.400 --> 02:39:08.880]   - It's gonna be Kamala Harris
[02:39:08.880 --> 02:39:11.400]   as the Democratic candidate.
[02:39:11.400 --> 02:39:14.640]   I'm really looking forward to Ted Cruz versus Mike Pence,
[02:39:14.640 --> 02:39:17.160]   'cause they're both very good at debate.
[02:39:17.160 --> 02:39:18.000]   That would be interesting to see
[02:39:18.000 --> 02:39:19.160]   how they differentiate themselves.
[02:39:19.160 --> 02:39:22.760]   But honestly, I mean,
[02:39:22.760 --> 02:39:24.560]   things are gonna get really ugly really soon.
[02:39:24.560 --> 02:39:26.080]   - What about Donald Trump coming back?
[02:39:26.080 --> 02:39:27.280]   - He's not gonna do it.
[02:39:27.280 --> 02:39:30.200]   So things, in my opinion,
[02:39:30.200 --> 02:39:33.200]   I think things are gonna be really, really crazy in 2021.
[02:39:33.200 --> 02:39:34.920]   And talking about the dam being gone.
[02:39:34.920 --> 02:39:37.480]   - 2021, so this year coming up?
[02:39:37.480 --> 02:39:40.000]   - Oh yeah, it's gonna be complete mayhem.
[02:39:40.000 --> 02:39:43.720]   - What do you think, prediction-wise,
[02:39:43.720 --> 02:39:45.280]   and this is empirical,
[02:39:45.280 --> 02:39:48.960]   what do you think Donald Trump's Twitter feed
[02:39:48.960 --> 02:39:52.120]   looks like in 2021?
[02:39:52.120 --> 02:39:54.320]   At the end of 2021, we'll look back
[02:39:54.320 --> 02:39:59.320]   and see what was the Obamagate exclamation points,
[02:39:59.320 --> 02:40:01.800]   or we won.
[02:40:01.800 --> 02:40:05.700]   - He is going to be, for the first time in history,
[02:40:05.700 --> 02:40:09.860]   holding the Republican Party accountable to the base.
[02:40:09.860 --> 02:40:11.640]   We've never had that happen before.
[02:40:11.640 --> 02:40:15.440]   I think he's going to be holding their feet to the fire,
[02:40:15.440 --> 02:40:17.240]   radicalizing them.
[02:40:17.240 --> 02:40:19.480]   And given that they have the Senate,
[02:40:19.480 --> 02:40:20.940]   where it's gonna be 50/50,
[02:40:20.940 --> 02:40:24.000]   the Democrats have a three-seat majority in the House.
[02:40:24.000 --> 02:40:26.800]   This is not a governing coalition for either.
[02:40:26.800 --> 02:40:28.160]   It's going to be complete mayhem.
[02:40:28.160 --> 02:40:29.320]   - What does that actually look like?
[02:40:29.320 --> 02:40:31.320]   So what are the key values you think
[02:40:31.320 --> 02:40:34.040]   that he's gonna try to push?
[02:40:34.040 --> 02:40:36.540]   - I think it's just gonna be very contrarian.
[02:40:36.540 --> 02:40:38.100]   He's gonna be holding them accountable
[02:40:38.100 --> 02:40:38.940]   in terms of budgeting,
[02:40:38.940 --> 02:40:41.140]   even though he never did that as president.
[02:40:41.140 --> 02:40:44.020]   I think in terms of some kind of nominations.
[02:40:44.020 --> 02:40:47.020]   Here's the thing, this is the first time since Nixon,
[02:40:47.020 --> 02:40:53.780]   50 years, and things weren't as politicized then,
[02:40:53.780 --> 02:40:54.980]   where an incoming president
[02:40:54.980 --> 02:40:57.060]   doesn't have control of the Senate.
[02:40:57.060 --> 02:41:01.060]   The Senate has the vote over cabinet positions.
[02:41:01.060 --> 02:41:05.360]   I do not see a possibility of them not trying to pick a fight
[02:41:05.360 --> 02:41:07.920]   on one or two of these nominations.
[02:41:07.920 --> 02:41:10.600]   And that's gonna, and especially as revenge for Kavanaugh,
[02:41:10.600 --> 02:41:12.680]   this is gonna get very bloody very quickly.
[02:41:12.680 --> 02:41:14.560]   And I think Mitch McConnell,
[02:41:14.560 --> 02:41:16.040]   there's a sadistic side to him.
[02:41:16.040 --> 02:41:19.160]   He revels in being the brakes on the car.
[02:41:19.160 --> 02:41:21.800]   And I think the base, it's just gonna be throwing just,
[02:41:21.800 --> 02:41:22.960]   they're gonna want some bone.
[02:41:22.960 --> 02:41:25.780]   It's like, oh yeah, we eliminated this one person.
[02:41:25.780 --> 02:41:28.120]   So that's gonna get really ugly really quickly.
[02:41:28.120 --> 02:41:31.040]   - You see it being quite divisive.
[02:41:31.040 --> 02:41:32.300]   - Oh yeah. - A division increasing,
[02:41:32.300 --> 02:41:35.540]   not stabilizing or decreasing.
[02:41:35.540 --> 02:41:37.380]   - And I'll be doing my part.
[02:41:37.380 --> 02:41:38.880]   - I know you'll be doing my part,
[02:41:38.880 --> 02:41:40.040]   but I'm trying to do my part.
[02:41:40.040 --> 02:41:43.400]   And like trying to be, like to me,
[02:41:43.400 --> 02:41:48.400]   the division is shouting over people like Elon Musk,
[02:41:48.400 --> 02:41:51.380]   people who are actually building stuff
[02:41:51.380 --> 02:41:53.060]   and like accomplishing things in this world
[02:41:53.060 --> 02:41:53.900]   in terms of like--
[02:41:53.900 --> 02:41:55.440]   - Elon said he took the red pill.
[02:41:55.440 --> 02:41:59.180]   - No, see, you're talking about the,
[02:41:59.180 --> 02:42:00.700]   I'm talking about, forget Elon.
[02:42:00.700 --> 02:42:03.820]   SpaceX and Tesla and actually the good sides
[02:42:03.820 --> 02:42:06.320]   of like some of the things that Google is doing,
[02:42:06.320 --> 02:42:09.420]   like actually building things,
[02:42:09.420 --> 02:42:11.580]   like making the world's information searchable,
[02:42:11.580 --> 02:42:12.660]   all that kind of stuff.
[02:42:12.660 --> 02:42:14.220]   Like all the stuff, you know,
[02:42:14.220 --> 02:42:18.260]   making actually the world a better place.
[02:42:18.260 --> 02:42:19.400]   There's a bunch of technologies
[02:42:19.400 --> 02:42:20.880]   that are increasing our quality of life,
[02:42:20.880 --> 02:42:22.720]   all that kind of stuff.
[02:42:22.720 --> 02:42:25.380]   I feel like they get like not much credit
[02:42:25.380 --> 02:42:29.540]   or in our public discourse because of the division.
[02:42:29.540 --> 02:42:30.880]   The division is just like,
[02:42:30.880 --> 02:42:34.940]   it's clouding our ability to concentrate
[02:42:34.940 --> 02:42:36.860]   on what's awesome about this world.
[02:42:36.860 --> 02:42:39.860]   - Well, you know what would eliminate the division, right?
[02:42:39.860 --> 02:42:40.700]   - Secession?
[02:42:40.700 --> 02:42:41.660]   - Yeah.
[02:42:41.660 --> 02:42:42.480]   - See, I don't,
[02:42:42.480 --> 02:42:46.280]   it's hard for me to disagree.
[02:42:46.280 --> 02:42:50.660]   It's hard for me to disagree because,
[02:42:50.660 --> 02:42:53.680]   but at the same time, secession,
[02:42:53.680 --> 02:42:57.980]   I'm a romantic at heart
[02:42:57.980 --> 02:42:59.580]   and to me, divorce breaks my heart.
[02:42:59.580 --> 02:43:01.580]   - Cool, but do you wanna live in a country--
[02:43:01.580 --> 02:43:02.420]   - Cool story, bro.
[02:43:02.420 --> 02:43:03.980]   - Yeah, but do you wanna live in a country
[02:43:03.980 --> 02:43:07.100]   where Joe Rogan is regarded as an example
[02:43:07.100 --> 02:43:09.260]   of someone who's spreading white supremacy?
[02:43:09.260 --> 02:43:10.100]   I don't.
[02:43:10.100 --> 02:43:13.220]   - Well, but see, I feel like that's not the country
[02:43:13.220 --> 02:43:14.980]   we live in, that's just--
[02:43:14.980 --> 02:43:16.380]   - The New York Times did it.
[02:43:16.380 --> 02:43:19.140]   The cathedral does it on a regular basis.
[02:43:19.140 --> 02:43:21.580]   - Well, the cathedral is, okay.
[02:43:21.580 --> 02:43:24.940]   The cathedral, I guess you can maybe define the cathedral,
[02:43:24.940 --> 02:43:27.160]   but it's like the centralized institutions
[02:43:27.160 --> 02:43:29.540]   that have a story that they're trying to sell and so on.
[02:43:29.540 --> 02:43:30.580]   - Yeah, this is Moldvick's concept,
[02:43:30.580 --> 02:43:32.620]   but yeah, they basically set the limits
[02:43:32.620 --> 02:43:34.460]   of permissible discourse and create a narrative
[02:43:34.460 --> 02:43:36.020]   for the population to follow.
[02:43:36.020 --> 02:43:37.940]   - But to me, that's a minority of people.
[02:43:37.940 --> 02:43:39.940]   - Yeah, minority's always controlling everything
[02:43:39.940 --> 02:43:40.780]   in any country.
[02:43:40.780 --> 02:43:42.820]   The vast majority of the masses have no thought.
[02:43:42.820 --> 02:43:44.940]   - Yeah, but minorities can be overthrown.
[02:43:44.940 --> 02:43:46.500]   - Sure, the circulation of the elites, yeah.
[02:43:46.500 --> 02:43:48.060]   - The way the, no, no, no, no,
[02:43:48.060 --> 02:43:50.820]   and that's what progress looks like
[02:43:50.820 --> 02:43:53.140]   is ridiculous people take power
[02:43:53.140 --> 02:43:57.160]   and then they get annoying and new ridiculous people
[02:43:57.160 --> 02:43:59.820]   that are a little bit better overthrow the previous--
[02:43:59.820 --> 02:44:01.840]   - No, I think progress happens
[02:44:01.840 --> 02:44:04.560]   despite the people who are in power, not because of them.
[02:44:04.560 --> 02:44:06.620]   - Right, and so why is this a secession?
[02:44:06.620 --> 02:44:11.440]   So is it always about overthrowing the powerful?
[02:44:11.440 --> 02:44:12.760]   Is that how progress happens?
[02:44:12.760 --> 02:44:14.760]   - No, I think progress happens despite the powerful.
[02:44:14.760 --> 02:44:17.120]   The powerful are gonna do what's in their power
[02:44:17.120 --> 02:44:19.720]   to maintain their power and they're gonna fight innovation
[02:44:19.720 --> 02:44:21.840]   because it's a threat to their control.
[02:44:21.840 --> 02:44:24.360]   - There's always gonna be the New York Times of the world.
[02:44:24.360 --> 02:44:25.800]   There's always gonna be those--
[02:44:25.800 --> 02:44:28.000]   - Sure, and let them have their own country.
[02:44:28.000 --> 02:44:29.940]   - So it's two countries.
[02:44:29.940 --> 02:44:32.960]   One has Joe Rogan, the other one has the New York Times?
[02:44:32.960 --> 02:44:34.640]   - That's basically what's happening right now.
[02:44:34.640 --> 02:44:37.920]   It's just geographically doesn't map out very well,
[02:44:37.920 --> 02:44:39.080]   but culturally, yes.
[02:44:39.080 --> 02:44:41.680]   - But that's just cultural stuff.
[02:44:41.680 --> 02:44:43.760]   There's a layer of public discourse.
[02:44:43.760 --> 02:44:44.600]   - Okay.
[02:44:44.600 --> 02:44:46.960]   - I don't mean, that's what we're operating under now.
[02:44:46.960 --> 02:44:48.600]   But there's actually progress being made,
[02:44:48.600 --> 02:44:52.200]   like roads being built, hospitals being run,
[02:44:52.200 --> 02:44:55.120]   all those kinds of things, different innovations.
[02:44:55.120 --> 02:44:59.080]   That seems like secession is counterproductive to that.
[02:44:59.080 --> 02:45:00.760]   - Right, 'cause one country would have all the roads
[02:45:00.760 --> 02:45:02.080]   and the other would have all the hospitals.
[02:45:02.080 --> 02:45:03.560]   That's a great point.
[02:45:03.560 --> 02:45:05.400]   - No, that's not the point I'm trying to make.
[02:45:05.400 --> 02:45:08.720]   It's just like, it just feels like the division
[02:45:08.720 --> 02:45:11.800]   that we're experiencing in the space of ideas
[02:45:11.800 --> 02:45:14.440]   could be constructive and productive
[02:45:14.440 --> 02:45:17.480]   for building better roads and better hospitals
[02:45:17.480 --> 02:45:20.440]   as opposed to using that division
[02:45:20.440 --> 02:45:21.360]   to separate the countries.
[02:45:21.360 --> 02:45:23.640]   They're all gonna have to solve the same problems,
[02:45:23.640 --> 02:45:24.480]   it feels like.
[02:45:24.480 --> 02:45:27.560]   - Sure, but they can solve them differently
[02:45:27.560 --> 02:45:28.800]   and compete that way.
[02:45:28.800 --> 02:45:31.040]   Mass is a great example, yeah.
[02:45:31.040 --> 02:45:31.880]   We're seeing that right now.
[02:45:31.880 --> 02:45:33.320]   Different countries have different mass mandates
[02:45:33.320 --> 02:45:34.320]   and things like this.
[02:45:34.320 --> 02:45:37.800]   - And the competition within the same structure,
[02:45:37.800 --> 02:45:40.600]   within the same founding documents and same institutions
[02:45:40.600 --> 02:45:43.560]   is not effective, you think, as effective as separating?
[02:45:43.560 --> 02:45:45.840]   - It is effective, but there is a certain point,
[02:45:45.840 --> 02:45:47.840]   which I think we have long passed,
[02:45:47.840 --> 02:45:50.680]   where there is not a governing consensus
[02:45:50.680 --> 02:45:52.320]   ideologically or culturally.
[02:45:52.320 --> 02:45:54.000]   - Let me ask you a fun question, okay?
[02:45:54.000 --> 02:45:56.000]   - Knock, knock. (laughs)
[02:45:56.000 --> 02:45:56.840]   - Who's there?
[02:45:56.840 --> 02:46:00.000]   Mars.
[02:46:00.000 --> 02:46:02.480]   - God of war.
[02:46:02.480 --> 02:46:04.240]   - The other one.
[02:46:04.240 --> 02:46:06.840]   The planet.
[02:46:06.840 --> 02:46:13.640]   So there is a kind of captivating notion that we might,
[02:46:14.680 --> 02:46:19.400]   I'm excited by it, the human being stepping foot on Mars.
[02:46:19.400 --> 02:46:24.120]   That to me is, it's like one of those things that feels
[02:46:24.120 --> 02:46:30.360]   like it's, why do we want to engage in space exploration?
[02:46:30.360 --> 02:46:35.740]   But I'm a bit with Elon Musk on this, which is,
[02:46:35.740 --> 02:46:42.120]   it's obvious that eventually, if human species is to survive,
[02:46:42.120 --> 02:46:45.120]   it's going to have to innovate in ways
[02:46:45.120 --> 02:46:46.860]   that includes the space.
[02:46:46.860 --> 02:46:50.640]   Like there's a lot of things we're not able to predict yet
[02:46:50.640 --> 02:46:54.880]   that if we push ourselves to the limits of space,
[02:46:54.880 --> 02:46:58.080]   like new ideas will come that'll be obvious
[02:46:58.080 --> 02:46:59.120]   a hundred years from now,
[02:46:59.120 --> 02:47:01.360]   and then we're not even imagining now.
[02:47:01.360 --> 02:47:05.040]   And colonizing Mars, that idea that seems ridiculous,
[02:47:05.040 --> 02:47:08.960]   exceptionally difficult, impossibly expensive,
[02:47:08.960 --> 02:47:12.040]   is something that is actually going to be seen
[02:47:12.040 --> 02:47:15.040]   as obvious in retrospect, and that we should engage in.
[02:47:15.040 --> 02:47:18.400]   Okay, that's just to contextualize things.
[02:47:18.400 --> 02:47:22.320]   The fun idea and experiment from a philosophical
[02:47:22.320 --> 02:47:27.200]   and political sense is, what kind of government,
[02:47:27.200 --> 02:47:31.440]   how do you orchestrate a government when you go to Mars?
[02:47:31.440 --> 02:47:33.240]   We don't get too many chances like this,
[02:47:33.240 --> 02:47:38.240]   but how do you build new systems, not in place of old ones,
[02:47:38.580 --> 02:47:41.760]   but in a place where no system previous have existed?
[02:47:41.760 --> 02:47:42.880]   - I think organically.
[02:47:42.880 --> 02:47:45.400]   I hate that word, but that's the correct word.
[02:47:45.400 --> 02:47:46.960]   You would have to figure out,
[02:47:46.960 --> 02:47:48.520]   I mean, that's how America was built.
[02:47:48.520 --> 02:47:49.920]   You had, it was a Jamestown colony,
[02:47:49.920 --> 02:47:51.580]   and they tried to do communism here,
[02:47:51.580 --> 02:47:52.680]   and it completely failed,
[02:47:52.680 --> 02:47:54.240]   and they went to a more free market system
[02:47:54.240 --> 02:47:57.280]   with the second wave of colonists, is my understanding.
[02:47:57.280 --> 02:47:59.720]   For Mars, I mean, it depends on the population,
[02:47:59.720 --> 02:48:02.080]   who the population was, the number of people.
[02:48:02.080 --> 02:48:07.680]   I don't know, these are all kind of hypotheticals
[02:48:07.680 --> 02:48:10.860]   that I don't really have any good insight in whatsoever.
[02:48:10.860 --> 02:48:12.100]   I'm not a space person.
[02:48:12.100 --> 02:48:14.600]   I hate astronomy, like I hate it.
[02:48:14.600 --> 02:48:16.280]   - So a lot of people look up to the stars,
[02:48:16.280 --> 02:48:17.740]   and they're filled with awe and wonder
[02:48:17.740 --> 02:48:19.220]   about the mystery of the universe,
[02:48:19.220 --> 02:48:22.680]   and you look up to the stars, and you feel what?
[02:48:22.680 --> 02:48:23.560]   - I'm not looking up.
[02:48:23.560 --> 02:48:24.800]   I'm looking at the Earth.
[02:48:24.800 --> 02:48:28.460]   If you look at what's, I'd much rather,
[02:48:28.460 --> 02:48:32.860]   given a choice between Mars and the deep sea,
[02:48:32.860 --> 02:48:34.780]   I'd much rather spend a week at the deep sea
[02:48:34.780 --> 02:48:36.540]   and all the life forms that are down there,
[02:48:36.540 --> 02:48:38.420]   'cause they're literal aliens.
[02:48:38.420 --> 02:48:39.500]   It's like things that are not literal,
[02:48:39.500 --> 02:48:42.820]   but they're unimaginable to us, some of the things down there.
[02:48:42.820 --> 02:48:43.740]   - Yeah, that's true.
[02:48:43.740 --> 02:48:45.580]   To me, it's an interesting thought experiment
[02:48:45.580 --> 02:48:49.420]   to see when you have 10 people, when you have 100 people,
[02:48:49.420 --> 02:48:51.980]   how do you build an effective,
[02:48:51.980 --> 02:48:54.260]   this is actually really useful for a company, right?
[02:48:54.260 --> 02:48:57.820]   How do you build an effective company that does things?
[02:48:57.820 --> 02:49:00.580]   It's not an obvious, despite everybody being
[02:49:00.580 --> 02:49:03.700]   really certain about everything in this modern world,
[02:49:03.700 --> 02:49:06.500]   to me, it's not obvious, like how do you run successfully
[02:49:06.500 --> 02:49:07.780]   as a group of people?
[02:49:07.780 --> 02:49:10.860]   - That's what I'm saying.
[02:49:10.860 --> 02:49:13.260]   Organic means you have to look at who the people are
[02:49:13.260 --> 02:49:15.780]   and tailor the organization to them,
[02:49:15.780 --> 02:49:17.940]   as opposed to try to impose something.
[02:49:17.940 --> 02:49:19.580]   - But you get to also select people.
[02:49:19.580 --> 02:49:23.060]   - Right, 'cause it's not gonna be open borders on Mars.
[02:49:23.060 --> 02:49:23.900]   - Oh, right.
[02:49:23.900 --> 02:49:26.300]   I was gonna say, when you have one country,
[02:49:26.300 --> 02:49:27.260]   it's all open borders.
[02:49:27.260 --> 02:49:29.420]   Yeah, you're right, from outer space.
[02:49:29.420 --> 02:49:30.260]   - Right.
[02:49:30.260 --> 02:49:33.620]   - Some say they're aliens already there,
[02:49:33.620 --> 02:49:35.180]   so you're gonna have to negotiate that.
[02:49:35.180 --> 02:49:37.060]   - Sure, we're aliens, so.
[02:49:37.060 --> 02:49:38.780]   - We're aliens to somebody.
[02:49:38.780 --> 02:49:40.100]   - We're legal aliens.
[02:49:40.100 --> 02:49:42.300]   - Do you think there's alien civilizations out there?
[02:49:42.300 --> 02:49:44.540]   - Yes, of course.
[02:49:44.540 --> 02:49:46.780]   - What do you think is their system of government?
[02:49:46.780 --> 02:49:48.980]   - Anarchism, 'cause they're advanced.
[02:49:48.980 --> 02:49:51.980]   - Do you honestly think there's
[02:49:51.980 --> 02:49:53.220]   intelligent life forms out there?
[02:49:53.220 --> 02:49:55.820]   - Of course, just the math, it's impossible that there isn't.
[02:49:55.820 --> 02:50:00.020]   - So what do you make of all the stories
[02:50:00.020 --> 02:50:02.940]   of UFO sightings, all that kind of stuff?
[02:50:02.940 --> 02:50:04.700]   Do you think they've visited Earth?
[02:50:05.300 --> 02:50:08.540]   - Yes, my grandfather was an air traffic controller
[02:50:08.540 --> 02:50:11.180]   in the Soviet Union, and he said they would often
[02:50:11.180 --> 02:50:15.020]   see these things that were not operating
[02:50:15.020 --> 02:50:16.940]   the way we knew vehicles operate.
[02:50:16.940 --> 02:50:18.660]   So that's good enough for me.
[02:50:18.660 --> 02:50:20.340]   - So, I mean, do you think government
[02:50:20.340 --> 02:50:23.020]   is in possession of some, like,
[02:50:23.020 --> 02:50:24.300]   what do you think government is doing
[02:50:24.300 --> 02:50:25.900]   with this kind of information?
[02:50:25.900 --> 02:50:29.060]   Do you think somebody has any understanding
[02:50:29.060 --> 02:50:34.060]   of UFO sightings or any kind of information
[02:50:35.060 --> 02:50:39.220]   about extraterrestrial life forms
[02:50:39.220 --> 02:50:41.580]   that are not known to the public?
[02:50:41.580 --> 02:50:43.260]   - Yes, that's indisputably true.
[02:50:43.260 --> 02:50:45.500]   I think the fact that so many of these sightings
[02:50:45.500 --> 02:50:48.220]   are from aerodynamic professionals,
[02:50:48.220 --> 02:50:50.460]   like pilots and things of that nature,
[02:50:50.460 --> 02:50:53.020]   they are people who've seen it all, who are reputable.
[02:50:53.020 --> 02:50:54.820]   If they are on record saying,
[02:50:54.820 --> 02:50:57.520]   "I've seen things that don't make sense,"
[02:50:57.520 --> 02:50:59.420]   and both the Russians and the Americans
[02:50:59.420 --> 02:51:02.960]   thought it was the other one, that says something.
[02:51:02.960 --> 02:51:04.700]   - Shouldn't that be a bigger problem?
[02:51:04.700 --> 02:51:07.460]   Shouldn't that be bigger news and a bigger problem
[02:51:07.460 --> 02:51:09.620]   if government is, in fact, hiding it?
[02:51:09.620 --> 02:51:11.220]   - I guess, but what are they gonna do
[02:51:11.220 --> 02:51:13.100]   with that information?
[02:51:13.100 --> 02:51:14.380]   - It's a good question.
[02:51:14.380 --> 02:51:19.380]   If a UFO, if an extraterrestrial spacecraft,
[02:51:19.380 --> 02:51:22.780]   which most likely would be a crappy space,
[02:51:22.780 --> 02:51:24.860]   it wouldn't be the actual aliens,
[02:51:24.860 --> 02:51:28.140]   it would be some drone probe ship.
[02:51:28.140 --> 02:51:29.900]   - AI. - Yeah, AI, yeah.
[02:51:29.900 --> 02:51:33.200]   So what would you do with that information
[02:51:33.200 --> 02:51:35.600]   as somebody that's in charge of,
[02:51:35.600 --> 02:51:40.600]   you see how badly WHO fumbled the discussion of masks.
[02:51:40.600 --> 02:51:44.640]   Masks, yeah, masks is one of them,
[02:51:44.640 --> 02:51:47.080]   but everything really in terms of communicating
[02:51:47.080 --> 02:51:49.000]   with the public honestly about what they know,
[02:51:49.000 --> 02:51:52.640]   what they don't know, and that's a trivial one.
[02:51:52.640 --> 02:51:53.480]   - Right.
[02:51:56.540 --> 02:51:59.940]   - I don't know, they certainly feel incompetent
[02:51:59.940 --> 02:52:03.640]   at being able to communicate effectively with the public
[02:52:03.640 --> 02:52:06.140]   about something much more difficult,
[02:52:06.140 --> 02:52:09.380]   much more full of mystery, like a UFO.
[02:52:09.380 --> 02:52:13.820]   A thing, a piece of material that's out of this Earth,
[02:52:13.820 --> 02:52:18.820]   forget organic material, I don't know.
[02:52:18.820 --> 02:52:21.620]   To me, from a scientist's perspective,
[02:52:21.620 --> 02:52:23.940]   it would be beautiful, it would be inspiring
[02:52:23.940 --> 02:52:25.380]   to reveal this to the world.
[02:52:25.380 --> 02:52:28.740]   Here's a mystery, and make it completely public.
[02:52:28.740 --> 02:52:30.480]   Share it with China, share it with everybody.
[02:52:30.480 --> 02:52:33.540]   - I think there is a domino effect
[02:52:33.540 --> 02:52:35.940]   where the concern would be what else are you hiding from us?
[02:52:35.940 --> 02:52:36.980]   And at that point, if you said,
[02:52:36.980 --> 02:52:38.420]   no, no, no, this is everything,
[02:52:38.420 --> 02:52:39.460]   people wouldn't believe you,
[02:52:39.460 --> 02:52:42.020]   and you can't blame them for not believing them.
[02:52:42.020 --> 02:52:44.380]   - Ah, yeah.
[02:52:44.380 --> 02:52:46.980]   - And then it'd be like, show us the aliens,
[02:52:46.980 --> 02:52:47.820]   they'd be like, we don't have them,
[02:52:47.820 --> 02:52:49.620]   we just have the craft, you're lying.
[02:52:50.620 --> 02:52:55.620]   - Speaking of aliens, offline, you mentioned elves.
[02:52:55.620 --> 02:52:56.860]   - Yeah.
[02:52:56.860 --> 02:52:58.860]   - And psychedelics. - Yeah.
[02:52:58.860 --> 02:53:01.740]   - What do you think about psychedelics
[02:53:01.740 --> 02:53:07.980]   in terms of the kind of places that can take your mind,
[02:53:07.980 --> 02:53:11.500]   the kind of journey it can take you on?
[02:53:11.500 --> 02:53:14.400]   Like, what do you think, what is,
[02:53:14.400 --> 02:53:17.820]   what do you think the psychedelics do to the human mind,
[02:53:17.820 --> 02:53:20.020]   and what does that say about the capacity
[02:53:20.020 --> 02:53:21.980]   of the human mind, and just in general,
[02:53:21.980 --> 02:53:23.540]   like the mysteries of all that's out there?
[02:53:23.540 --> 02:53:26.300]   - I don't know that we understand what they do.
[02:53:26.300 --> 02:53:28.740]   The way I heard it explained to me
[02:53:28.740 --> 02:53:30.780]   is that much of the human mind
[02:53:30.780 --> 02:53:33.460]   isn't about receiving information,
[02:53:33.460 --> 02:53:35.820]   but blocking information, right?
[02:53:35.820 --> 02:53:38.380]   Because there's so much data coming in any moment
[02:53:38.380 --> 02:53:39.960]   that you basically have to train yourself
[02:53:39.960 --> 02:53:42.740]   to see and to hear only what you want to see and to hear.
[02:53:42.740 --> 02:53:45.360]   And that what psychedelics do is they tear that away,
[02:53:45.360 --> 02:53:47.180]   and suddenly you're much more aware of what's out there,
[02:53:47.180 --> 02:53:48.660]   and also you're gonna be noticing patterns
[02:53:48.660 --> 02:53:49.940]   that you hadn't noticed before.
[02:53:49.940 --> 02:53:51.540]   I know you had that researcher on the show,
[02:53:51.540 --> 02:53:53.940]   and he kind of discussed this at some length.
[02:53:53.940 --> 02:53:58.540]   I mean, Rogan is probably the person
[02:53:58.540 --> 02:54:00.260]   who popularized DMT more than,
[02:54:00.260 --> 02:54:01.260]   well, he's obviously the person
[02:54:01.260 --> 02:54:03.860]   who's popularized DMT more than anything.
[02:54:03.860 --> 02:54:07.140]   I don't know anyone who has, even researchers,
[02:54:07.140 --> 02:54:10.300]   who have anything close to a coherent explanation
[02:54:10.300 --> 02:54:13.860]   of why this drug, which exists everywhere,
[02:54:13.860 --> 02:54:16.900]   would have this very specific, very extreme effect
[02:54:16.900 --> 02:54:19.780]   on so many people who are going to be experiencing
[02:54:19.780 --> 02:54:23.020]   such bizarre consequences as a result of it.
[02:54:23.020 --> 02:54:25.020]   I think it's very interesting that,
[02:54:25.020 --> 02:54:26.500]   this is talking about the government,
[02:54:26.500 --> 02:54:29.780]   the CIA started experimenting with LSD.
[02:54:29.780 --> 02:54:33.100]   They killed one of their own people, drove them to suicide.
[02:54:33.100 --> 02:54:35.780]   And there was a lot of research into,
[02:54:35.780 --> 02:54:39.580]   Terrence McKenna talks about this, into this field.
[02:54:39.580 --> 02:54:42.140]   And then very quickly, once it got into the mainstream,
[02:54:42.140 --> 02:54:44.780]   they shut it down, even though it's not addictive,
[02:54:44.780 --> 02:54:46.980]   it doesn't cause you to go crazy or anything like that.
[02:54:46.980 --> 02:54:49.820]   And there was a lot of propaganda against its use,
[02:54:49.820 --> 02:54:52.620]   which I think, thankfully, is now somewhat receding.
[02:54:52.620 --> 02:54:54.540]   I think in Colorado, just legalized mushrooms,
[02:54:54.540 --> 02:54:55.660]   something like that.
[02:54:55.660 --> 02:54:57.460]   And I think it'll be very interesting to see what happens
[02:54:57.460 --> 02:54:58.700]   as a result of this.
[02:54:58.700 --> 02:55:00.580]   - Yeah, and the interesting thing is,
[02:55:00.580 --> 02:55:03.460]   there doesn't seem to be, for certain psychedelics,
[02:55:03.460 --> 02:55:05.660]   like psilocybin, like mushrooms,
[02:55:05.660 --> 02:55:08.140]   there doesn't seem to be a lethal dose,
[02:55:08.140 --> 02:55:09.860]   which is fascinating.
[02:55:09.860 --> 02:55:13.740]   Like Matthew Johnson, the Hopkins professor
[02:55:13.740 --> 02:55:17.420]   that you mentioned, I'm definitely gonna do
[02:55:17.420 --> 02:55:18.900]   one of his studies.
[02:55:18.900 --> 02:55:23.900]   It's a really cool way to do what he calls a heroic dose.
[02:55:23.900 --> 02:55:26.660]   - Oh, I wanna do it.
[02:55:26.660 --> 02:55:27.500]   What do I have to do?
[02:55:27.500 --> 02:55:28.340]   Let's do it. - I'll let you know.
[02:55:28.340 --> 02:55:30.340]   So he is--
[02:55:30.340 --> 02:55:32.060]   - A heroic dose, holy crap.
[02:55:32.060 --> 02:55:35.020]   - Yeah, but it's safe.
[02:55:35.020 --> 02:55:37.940]   - What's a, how many grams are we talking?
[02:55:37.940 --> 02:55:40.860]   - I don't know, but it's just, it's big.
[02:55:40.860 --> 02:55:42.780]   He says that--
[02:55:42.780 --> 02:55:44.380]   - He's gonna have a kick.
[02:55:44.380 --> 02:55:48.300]   - Yeah, so he says that, I mean, he also studies cocaine,
[02:55:48.300 --> 02:55:49.940]   he studies all kinds of drugs,
[02:55:49.940 --> 02:55:53.100]   and he's like, the psilocybin is--
[02:55:53.100 --> 02:55:55.100]   - Heroic dose of cocaine kills you.
[02:55:55.100 --> 02:55:58.780]   - Well, you can't, so you can't even come close.
[02:55:58.780 --> 02:56:01.220]   So he says like, the problem with studying cocaine
[02:56:01.220 --> 02:56:05.060]   is you have like people who are addicted to cocaine,
[02:56:05.060 --> 02:56:08.620]   or war, or so on, you give 'em the kind of doses
[02:56:08.620 --> 02:56:10.140]   that we can in part of the study,
[02:56:10.140 --> 02:56:13.260]   it's like, it's nothing to them.
[02:56:13.260 --> 02:56:14.100]   - Right, yeah, yeah.
[02:56:14.100 --> 02:56:16.020]   - Psilocybin is the only one where like,
[02:56:16.020 --> 02:56:20.540]   even like daily users, or like regular users,
[02:56:20.540 --> 02:56:23.500]   like are blown away by the dose they give them.
[02:56:23.500 --> 02:56:24.340]   - Oh, fuck.
[02:56:24.340 --> 02:56:25.180]   (Lex laughing)
[02:56:25.180 --> 02:56:26.000]   - So.
[02:56:26.000 --> 02:56:26.840]   (Lex laughing)
[02:56:26.840 --> 02:56:28.100]   - Okay, well, we're going back to Russia.
[02:56:28.100 --> 02:56:29.340]   (Lex laughing)
[02:56:29.340 --> 02:56:30.940]   - You can go to Russia in your mind.
[02:56:30.940 --> 02:56:32.100]   - Yeah.
[02:56:32.100 --> 02:56:34.540]   - You can go to outer space, maybe.
[02:56:34.540 --> 02:56:36.100]   Maybe you'll become an astronaut,
[02:56:36.100 --> 02:56:39.140]   or astronomer after all.
[02:56:39.140 --> 02:56:40.500]   - Maybe I'll be Baba Yaga.
[02:56:40.500 --> 02:56:42.660]   (Lex laughing)
[02:56:42.660 --> 02:56:44.420]   - I'll let people look that one up.
[02:56:44.420 --> 02:56:45.480]   - Holy crap, wow.
[02:56:45.480 --> 02:56:48.580]   - What is love?
[02:56:48.580 --> 02:56:52.180]   What do you think this thing is?
[02:56:52.180 --> 02:56:55.960]   Like our attachment to other human beings?
[02:56:55.960 --> 02:56:58.820]   And is it something that we should give
[02:56:58.820 --> 02:57:00.060]   to just a few people?
[02:57:00.060 --> 02:57:01.860]   - Yes, that's for sure.
[02:57:01.860 --> 02:57:04.700]   When I was working with D.L. Hughley in his book,
[02:57:04.700 --> 02:57:07.520]   he didn't use the term, but he was describing
[02:57:07.520 --> 02:57:09.900]   like low-key depression.
[02:57:09.900 --> 02:57:12.940]   And he talked about how he was in the airport,
[02:57:12.940 --> 02:57:15.060]   and he noticed a girl had a red dress,
[02:57:15.060 --> 02:57:16.220]   and he went up and thanked her,
[02:57:16.220 --> 02:57:17.620]   and she was like, "What are you thanking for?"
[02:57:17.620 --> 02:57:20.640]   And he had realized he hadn't registered color in weeks.
[02:57:20.640 --> 02:57:24.260]   And I think love is like that.
[02:57:24.260 --> 02:57:27.340]   When you see someone, and you just like,
[02:57:27.340 --> 02:57:29.400]   "Oh, like your eyes are open.
[02:57:29.400 --> 02:57:32.320]   "Like this is something I've never seen before.
[02:57:32.320 --> 02:57:34.340]   "I want more of this," that kind of thing.
[02:57:34.340 --> 02:57:39.340]   It really disorients and reorients your thinking.
[02:57:39.340 --> 02:57:45.320]   - Don't you find that the world is full of that nonstop?
[02:57:45.320 --> 02:57:47.120]   It's not just like a person either.
[02:57:47.120 --> 02:57:50.280]   - Yes, but when it's in a person,
[02:57:50.280 --> 02:57:52.480]   it's a whole other level, 'cause it's like,
[02:57:52.480 --> 02:57:54.960]   I could have, this is gonna be great for years.
[02:57:54.960 --> 02:57:57.680]   It's like, every day it's something new.
[02:57:57.680 --> 02:58:00.520]   I mean, and that is rare.
[02:58:00.520 --> 02:58:01.760]   - You think it's rare?
[02:58:01.980 --> 02:58:04.780]   Find someone who you could talk to them for years
[02:58:04.780 --> 02:58:06.100]   and not run out of things to talk to.
[02:58:06.100 --> 02:58:07.740]   - Oh, that's true, for years, yes, yes.
[02:58:07.740 --> 02:58:09.260]   - That's rare.
[02:58:09.260 --> 02:58:12.140]   And know that they really, if you leave the room,
[02:58:12.140 --> 02:58:14.100]   they will do right by you.
[02:58:14.100 --> 02:58:15.540]   That's really rare.
[02:58:15.540 --> 02:58:19.580]   - Well, from a Russian perspective,
[02:58:19.580 --> 02:58:21.580]   you just don't give them another choice.
[02:58:21.580 --> 02:58:24.160]   (Lex laughing)
[02:58:24.160 --> 02:58:28.860]   This is (speaking in foreign language)
[02:58:28.860 --> 02:58:30.800]   New Year, New Year's Eve.
[02:58:31.460 --> 02:58:32.300]   - Yeah.
[02:58:32.300 --> 02:58:36.420]   - So you've talked about secession
[02:58:36.420 --> 02:58:37.660]   and the world burning down,
[02:58:37.660 --> 02:58:41.940]   and you holding the match at the end,
[02:58:41.940 --> 02:58:43.980]   standing with a big smile on your face.
[02:58:43.980 --> 02:58:45.900]   - Yes, why so serious?
[02:58:45.900 --> 02:58:49.100]   - But let me ask you,
[02:58:49.100 --> 02:58:53.940]   if it doesn't include flame and secession and destruction
[02:58:53.940 --> 02:58:57.500]   and laughing malice and makeup and a white suit at the end,
[02:58:59.540 --> 02:59:03.360]   how do we bring more kindness and love to the world in 2021?
[02:59:03.360 --> 02:59:04.880]   - Oh, easy.
[02:59:04.880 --> 02:59:09.320]   Be comfortable saying, "I want to be happy."
[02:59:09.320 --> 02:59:11.720]   And if there's someone who interjects
[02:59:11.720 --> 02:59:15.680]   and gives you attitude, arms lengthen.
[02:59:15.680 --> 02:59:19.360]   Surround yourself with people who also want to be happy.
[02:59:19.360 --> 02:59:20.840]   Here's a great example.
[02:59:20.840 --> 02:59:22.800]   My buddy, Chris Williamson, who I've mentioned before,
[02:59:22.800 --> 02:59:25.200]   he's a podcaster, does Modern Wisdom.
[02:59:25.200 --> 02:59:28.040]   He's an awesome dude, and we became friends,
[02:59:28.040 --> 02:59:30.120]   very close friends this past year.
[02:59:30.120 --> 02:59:31.800]   And he was in Dubai recently,
[02:59:31.800 --> 02:59:35.560]   and he sent me pics from Dubai by the pool, just loving life.
[02:59:35.560 --> 02:59:39.100]   And it took me a week, and then it clicked in my head.
[02:59:39.100 --> 02:59:40.640]   And I'm like, "You know what?
[02:59:40.640 --> 02:59:43.620]   "For some other people,
[02:59:43.620 --> 02:59:47.460]   "if they saw him, underwear model, at the pool,
[02:59:47.460 --> 02:59:50.680]   "they would think this is him bragging or humble bragging."
[02:59:50.680 --> 02:59:51.920]   And that never entered my head.
[02:59:51.920 --> 02:59:54.580]   I'm like, "Oh man, I'm so glad my boy
[02:59:54.580 --> 02:59:59.580]   "can be having a good time and is sharing his joy with me."
[02:59:59.580 --> 03:00:02.140]   That's the kind of people you need to surround yourself with
[03:00:02.140 --> 03:00:05.140]   where it never enters their head to be resentful
[03:00:05.140 --> 03:00:09.500]   or anything other than sharing in your bounty.
[03:00:09.500 --> 03:00:12.000]   - What makes you happy?
[03:00:12.000 --> 03:00:15.060]   - I'm happy all the time.
[03:00:15.060 --> 03:00:17.700]   And one of the points I made in my life is,
[03:00:17.700 --> 03:00:20.740]   I really hated, I really did not like to give advice
[03:00:20.740 --> 03:00:22.220]   because I feel, don't give advice
[03:00:22.220 --> 03:00:24.260]   until you know what you're talking about.
[03:00:24.260 --> 03:00:27.620]   And to me, what makes me happy is being self-actualized.
[03:00:27.620 --> 03:00:30.620]   I am in a position with my career
[03:00:30.620 --> 03:00:33.460]   where I could be myself 24/7,
[03:00:33.460 --> 03:00:36.180]   where I never have to engage in small talk,
[03:00:36.180 --> 03:00:39.100]   where I never have to interact with someone I don't want to.
[03:00:39.100 --> 03:00:41.260]   And I'm very blessed to have that.
[03:00:41.260 --> 03:00:42.780]   Very few people have that.
[03:00:42.780 --> 03:00:45.520]   And to have that be not only,
[03:00:45.520 --> 03:00:49.220]   to have that be rewarded,
[03:00:49.220 --> 03:00:52.980]   and having people find that something of value to them
[03:00:52.980 --> 03:00:55.140]   makes me very, very happy.
[03:00:55.140 --> 03:00:57.260]   But also being an uncle.
[03:00:57.260 --> 03:00:58.540]   I have two little nephews.
[03:00:58.540 --> 03:01:00.220]   They make me very, very happy.
[03:01:00.220 --> 03:01:02.780]   Sure, my sister's raised in the Russian
[03:01:02.780 --> 03:01:05.100]   so they talk like immigrants, but that's okay.
[03:01:05.100 --> 03:01:06.860]   We're gonna change that.
[03:01:06.860 --> 03:01:08.800]   We have to dismember her, that's fine.
[03:01:08.800 --> 03:01:09.980]   That makes me happy.
[03:01:09.980 --> 03:01:14.460]   And to be able to finish this book
[03:01:14.460 --> 03:01:17.060]   and know it's gonna give people a sense of hope,
[03:01:17.060 --> 03:01:18.700]   that's really validating.
[03:01:20.020 --> 03:01:23.660]   - What are you most grateful for for our conversation today?
[03:01:23.660 --> 03:01:27.620]   - (laughs) You're stealing my bit.
[03:01:27.620 --> 03:01:29.900]   What am I most grateful for?
[03:01:29.900 --> 03:01:34.900]   I am very grateful that I can come in here
[03:01:34.900 --> 03:01:38.340]   not knowing what we're gonna talk about
[03:01:38.340 --> 03:01:41.060]   and know it's not gonna be something
[03:01:41.060 --> 03:01:43.220]   I have to be on guard about,
[03:01:43.220 --> 03:01:45.500]   or I have to watch my words,
[03:01:45.500 --> 03:01:47.460]   and that neither you or your audience
[03:01:47.460 --> 03:01:51.940]   is going to be responding derisively.
[03:01:51.940 --> 03:01:55.140]   I feel safe here.
[03:01:55.140 --> 03:01:55.980]   - You're welcome.
[03:01:55.980 --> 03:01:57.460]   (laughs)
[03:01:57.460 --> 03:01:58.300]   - Spasibo.
[03:01:58.300 --> 03:01:59.380]   - Thanks for talking to me, Michael.
[03:01:59.380 --> 03:02:00.220]   It was awesome.
[03:02:00.220 --> 03:02:03.020]   Thank you for listening to this conversation
[03:02:03.020 --> 03:02:05.980]   with Michael Malice, and thank you to our sponsors.
[03:02:05.980 --> 03:02:08.860]   NetSuite Business Management Software,
[03:02:08.860 --> 03:02:11.520]   Athletic Greens All-in-One Nutrition Drink,
[03:02:11.520 --> 03:02:16.100]   Sun Basket Meal Delivery Service, and Cash App.
[03:02:16.100 --> 03:02:21.100]   So the choice is success, health, food, or money.
[03:02:21.100 --> 03:02:23.140]   Choose wisely, my friends.
[03:02:23.140 --> 03:02:26.100]   And if you wish, click the sponsor links below
[03:02:26.100 --> 03:02:29.020]   to get a discount to support this podcast.
[03:02:29.020 --> 03:02:31.180]   And now, let me leave you with some words
[03:02:31.180 --> 03:02:34.340]   from Emma Goldman on anarchism.
[03:02:34.340 --> 03:02:36.500]   People have only as much liberty
[03:02:36.500 --> 03:02:38.860]   as they have the intelligence to want
[03:02:38.860 --> 03:02:41.140]   and the courage to take.
[03:02:41.140 --> 03:02:43.900]   Thank you for listening, and hope to see you next time.
[03:02:43.900 --> 03:02:46.480]   (upbeat music)
[03:02:46.480 --> 03:02:49.060]   (upbeat music)
[03:02:49.060 --> 03:02:59.060]   [BLANK_AUDIO]

