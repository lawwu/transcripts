
[00:00:00.000 --> 00:00:04.880]   Hello again! Let's take care of the original task, improving the model performance.
[00:00:04.880 --> 00:00:08.560]   How can we make the model better and increase the intersection of a union metric?
[00:00:08.560 --> 00:00:12.560]   In our previous video, we refactored the baseline notebook.
[00:00:12.560 --> 00:00:16.800]   Now, we will want to export everything to a train.py script file.
[00:00:16.800 --> 00:00:22.400]   There are multiple ways of doing this. You can export every single cell by hand,
[00:00:22.400 --> 00:00:28.560]   copy-pasting them on the train.py file, or you can use a semi-automatic way like nbdev or nbconvert.
[00:00:28.880 --> 00:00:34.320]   To keep it simple, I went the manual way. I merge every single cell and copy-paste them
[00:00:34.320 --> 00:00:40.400]   on the train.py file. At the end of the file, you have the train function that depends on the config.
[00:00:40.400 --> 00:00:45.520]   The only thing I have added is the parse_args functionality.
[00:00:45.520 --> 00:00:48.640]   This enables you to overwrite arguments on the fly.
[00:00:48.640 --> 00:00:53.520]   It converts your Python program into an interactive command-line interface.
[00:00:54.480 --> 00:01:00.240]   There are multiple tools to add this functionality. I'm using default Python arg parse.
[00:01:00.240 --> 00:01:06.800]   As we are using Fast.ai, you can use the built-in call parse decorator to transform your script
[00:01:06.800 --> 00:01:12.640]   into a command-line interface. Inside the environment, you just call this file with Python,
[00:01:12.640 --> 00:01:18.800]   python train.py. This way, we will run the file in the same way as it was presented on the notebook.
[00:01:20.320 --> 00:01:25.440]   This is not very interesting as it will run with default args, and we already have a bunch of runs
[00:01:25.440 --> 00:01:33.440]   like that. Let's just cancel the run using ctrl+c.
[00:01:33.440 --> 00:01:41.040]   Let's go to the workspace and see the new run that we logged. There it is!
[00:01:41.040 --> 00:01:45.760]   We can delete this partial run by clicking on the three dots.
[00:01:47.680 --> 00:01:52.880]   As we said before, we have an interactive Python program now, so let's make use of that.
[00:01:52.880 --> 00:01:58.080]   You can access the help menu by calling python train -help, and it will print you out all the
[00:01:58.080 --> 00:02:04.160]   parameters you are capable of overwriting. Or with a different batch size. Let's try batch size 16 for
[00:02:04.160 --> 00:02:12.960]   a change. You can overwrite batch size by passing the argument name and the argument name.
[00:02:12.960 --> 00:02:20.160]   You can override batch size by passing the argument name and the new value. This will create a new run
[00:02:20.160 --> 00:02:27.760]   with batch size equals 16, overwriting the default 8. Let's confirm this on the workspace. There it is!
[00:02:27.760 --> 00:02:34.000]   Let's click on the run and on the overview tab, and scroll down to the config. We can confirm
[00:02:34.000 --> 00:02:46.400]   that the batch size is 16 now. Let's also kill this run. What we actually want to do is explore
[00:02:46.400 --> 00:02:52.400]   the hyperparameter space, but we don't want to do it manually like that. We want to define a way to
[00:02:52.400 --> 00:02:59.440]   orchestrate our hyperparameter optimization. Here comes Weights & Biases Sweeps, our hyperparameter
[00:02:59.440 --> 00:03:05.520]   optimization tool. With just a few lines of code and our already instrumented training script,
[00:03:05.520 --> 00:03:11.520]   you will be running massive hyperparameter tuning in no time. But how do we actually do this?
[00:03:11.520 --> 00:03:17.600]   How do we tell Weights & Biases to run this code automatically? This is done through a yaml
[00:03:17.600 --> 00:03:24.000]   configuration file. First, you define what script you want to run, in our case train.py. Second,
[00:03:24.000 --> 00:03:29.760]   you have to define a method of exploration of the hyperparameter space. We provide grid, random,
[00:03:29.760 --> 00:03:34.720]   and biasion optimization search. You can refer to the Weights & Biases Sweeps documentation to get
[00:03:34.720 --> 00:03:39.840]   more information about the algorithms. Then, you have to define which project your sweep will live
[00:03:39.840 --> 00:03:44.880]   in. Sometimes you want to use a different project to put your sweeps in, to not pollute your main
[00:03:44.880 --> 00:03:50.160]   workspace. In our case, we will use the same project as before. Then, you define a metric
[00:03:50.160 --> 00:03:54.320]   to monitor. In our case, we want to maximize mean intersection over union.
[00:03:54.320 --> 00:04:00.160]   And finally, you want to define your hyperparameter space.
[00:04:00.160 --> 00:04:09.840]   You can use this to override default arguments, like log predictions. This is equivalent to
[00:04:09.840 --> 00:04:14.480]   changing the default values on the train.py file. You can use a distribution to sample
[00:04:14.480 --> 00:04:21.200]   continuous parameters. In our case, we'll sample the learning rate between the log of the mean and
[00:04:21.200 --> 00:04:27.120]   max values. You can also pass a list of values for discrete parameters. We'll try a smaller batch
[00:04:27.120 --> 00:04:32.880]   size, so we get more optimizer updates, as our dataset is really small. I had good results in
[00:04:32.880 --> 00:04:38.000]   the past using this trick with small datasets. We'll also increase the image size a little bit.
[00:04:38.000 --> 00:04:42.320]   This should improve the model performance on segmentation of small objects. Finally,
[00:04:42.320 --> 00:04:47.200]   we'll try different image backbones. These are my four favorite backbones from TorchVision.
[00:04:47.200 --> 00:04:52.480]   Feel free to go to TorchVision models and try other backbones. There are plenty of them.
[00:04:52.480 --> 00:04:57.520]   Depending on your task and your dataset, you may want to try bigger models. TorchVision models are
[00:04:57.520 --> 00:05:03.200]   trained regularly, with state-of-the-art techniques. Our sweep configuration file is ready.
[00:05:03.200 --> 00:05:08.720]   Let's switch to a terminal now and start the sweep. You can launch the sweep using 1db,
[00:05:08.720 --> 00:05:14.320]   sweep, and the sweep configuration file. The sweep has been created. You can click the link,
[00:05:14.320 --> 00:05:19.360]   and you will be redirected to the sweep workspace. It's still empty, but you can click on the
[00:05:19.360 --> 00:05:24.640]   overview tab and see the configuration file that was used to create the sweep. You see the proposed
[00:05:24.640 --> 00:05:29.520]   sweep command to launch an agent. This is the same command suggested on the terminal.
[00:05:29.520 --> 00:05:37.440]   Let's run this command. Before doing that, let's check the options available for the 1db agent.
[00:05:38.080 --> 00:05:43.520]   We see that we have a count parameter, so we can limit the max number of runs per agent.
[00:05:43.520 --> 00:05:48.480]   As we are doing random search, if you don't pass any count parameter, it will run forever,
[00:05:48.480 --> 00:05:53.360]   so you will have to kill it manually. Let's start by 50 runs. Running this command will
[00:05:53.360 --> 00:05:57.120]   launch the agent, and you will start populating your sweep workspace with runs.
[00:05:57.120 --> 00:06:02.480]   You can see the selected hyperparameters at the beginning of the script.
[00:06:06.160 --> 00:06:09.920]   Now we can switch to the workspace, and we should see the incoming run.
[00:06:09.920 --> 00:06:16.720]   There it is. You will see the plot updating automatically as more runs come in.
[00:06:16.720 --> 00:06:22.960]   But I have an extra surprise for you. I have switch machines. I'm not using the same machine
[00:06:22.960 --> 00:06:28.320]   as we were using before. This machine is equipped with two GPUs. You can check the available GPUs
[00:06:28.320 --> 00:06:33.600]   on your machine using the nvidia-smi command. We see that the first GPU is being used,
[00:06:33.600 --> 00:06:39.040]   and the second one is just sitting idle. Let's fix that. Let's open a new terminal.
[00:06:39.040 --> 00:06:45.440]   We can override the CUDA visible device environment variable, and force the code to run on the second
[00:06:45.440 --> 00:06:53.040]   GPU. This command will create a new agent. On the second GPU, we will also pass a quota of 50 runs.
[00:06:53.040 --> 00:06:58.640]   This is really powerful when you have access to large compute centers, like a cluster,
[00:06:58.640 --> 00:07:04.560]   or machines equipped with multiple GPUs. As you expect, you can launch agents in parallel,
[00:07:04.560 --> 00:07:07.840]   and greatly reduce the time spent performing the sweep.
[00:07:07.840 --> 00:07:13.280]   As we go to the workspace, we see that two runs are coming in parallel.
[00:07:13.280 --> 00:07:18.880]   Great! Now we have two agents contributing in parallel to finish the sweep.
[00:07:18.880 --> 00:07:24.240]   This should reduce in half the time needed to complete our hyperparameter exploration.
[00:07:24.240 --> 00:07:27.760]   In the next video, we'll explore the results of the finished sweep.
[00:07:28.640 --> 00:07:29.220]   Thanks for watching!
[00:07:29.780 --> 00:07:29.860]   you
[00:07:30.660 --> 00:07:30.740]   you
[00:07:30.740 --> 00:07:30.820]   you
[00:07:31.780 --> 00:07:31.860]   you
[00:07:31.860 --> 00:07:31.940]   you
[00:07:31.940 --> 00:07:32.020]   you
[00:07:32.980 --> 00:07:33.060]   you
[00:07:33.060 --> 00:07:33.140]   you
[00:07:33.140 --> 00:07:33.220]   you
[00:07:33.220 --> 00:07:33.300]   you
[00:07:33.300 --> 00:07:33.380]   you
[00:07:33.380 --> 00:07:33.460]   you
[00:07:33.460 --> 00:07:33.540]   you
[00:07:33.540 --> 00:07:33.620]   you
[00:07:33.620 --> 00:07:33.700]   you
[00:07:34.660 --> 00:07:34.740]   you
[00:07:34.740 --> 00:07:34.820]   you
[00:07:35.620 --> 00:07:35.700]   you
[00:07:35.700 --> 00:07:45.700]   [BLANK_AUDIO]

