
[00:00:00.000 --> 00:00:03.000]   Welcome back for the third week.
[00:00:03.000 --> 00:00:05.760]   And I'm really excited to have you back come again
[00:00:05.760 --> 00:00:07.600]   and for this week as well.
[00:00:07.600 --> 00:00:09.360]   And this week we're going to be looking
[00:00:09.360 --> 00:00:12.860]   into deep learning models in production.
[00:00:12.860 --> 00:00:15.960]   So last week when we started, we kind of,
[00:00:15.960 --> 00:00:18.760]   last week when we finished,
[00:00:18.760 --> 00:00:22.080]   we finished at the point where we were at that point
[00:00:22.080 --> 00:00:24.120]   where we could get our data sets ready.
[00:00:24.120 --> 00:00:25.880]   And this week, what we're gonna do
[00:00:25.880 --> 00:00:27.760]   is we're gonna build on top of that.
[00:00:27.760 --> 00:00:29.660]   We're gonna have our data sets ready
[00:00:29.660 --> 00:00:32.320]   and on top of that, we're gonna also learn
[00:00:32.320 --> 00:00:34.840]   how to create a deep learning model.
[00:00:34.840 --> 00:00:36.560]   And more specifically, we're gonna learn
[00:00:36.560 --> 00:00:38.220]   how to put that model in production.
[00:00:38.220 --> 00:00:40.100]   So we're gonna create an application
[00:00:40.100 --> 00:00:42.120]   that you and everybody else can then share
[00:00:42.120 --> 00:00:45.340]   with your friends and you can share what work you've done.
[00:00:45.340 --> 00:00:48.980]   And then we really wanna, at that point,
[00:00:48.980 --> 00:00:51.880]   we really wanna start sharing our work
[00:00:51.880 --> 00:00:53.760]   'cause that's something that's really helpful.
[00:00:53.760 --> 00:00:57.160]   And you wanna start sort of writing blog about it
[00:00:57.160 --> 00:01:01.180]   or sort of sharing that on social media.
[00:01:01.180 --> 00:01:06.180]   But we'll talk more about the benefits of each in a while.
[00:01:06.180 --> 00:01:11.540]   But then again, a lot has happened this week.
[00:01:11.540 --> 00:01:15.000]   So Ravi Chandra, he's also written a blog just this week.
[00:01:15.000 --> 00:01:17.140]   So thanks Ravi for sharing all the learnings
[00:01:17.140 --> 00:01:20.440]   and sort of summarizing everything that you've learned.
[00:01:20.440 --> 00:01:21.280]   It's really good.
[00:01:21.280 --> 00:01:23.140]   And I really did kind of notice your profile
[00:01:23.140 --> 00:01:25.240]   just because of that you've been sharing
[00:01:25.240 --> 00:01:27.100]   this week after week.
[00:01:27.100 --> 00:01:28.580]   It's really exciting to see
[00:01:28.580 --> 00:01:30.020]   that you're working as software engineer,
[00:01:30.020 --> 00:01:32.060]   but yet your interest in deep learning
[00:01:32.060 --> 00:01:34.260]   seems to be quite a bit.
[00:01:34.260 --> 00:01:37.860]   Same for Korean, he's come back again for the second week
[00:01:37.860 --> 00:01:40.220]   and he's again written another blog,
[00:01:40.220 --> 00:01:44.500]   which is more about a summary of what he learned last week.
[00:01:44.500 --> 00:01:45.460]   It's really helpful.
[00:01:45.460 --> 00:01:48.700]   And I think this is something that I believe both you,
[00:01:48.700 --> 00:01:52.620]   Korean and Ravi, you both would have learned a lot
[00:01:52.620 --> 00:01:56.900]   by writing just by sort of summarizing and writing.
[00:01:56.900 --> 00:01:59.260]   Everything and summarizing what you've learned.
[00:01:59.260 --> 00:02:04.980]   Exciting news, next week we're gonna have Parul joining us.
[00:02:04.980 --> 00:02:06.940]   She will be sharing exactly about this.
[00:02:06.940 --> 00:02:11.060]   She will be sharing about how to share your work publicly.
[00:02:11.060 --> 00:02:15.940]   So if you don't know about who Parul is, let me show you.
[00:02:15.940 --> 00:02:18.940]   (keyboard clacking)
[00:02:18.940 --> 00:02:34.140]   So Parul is a competition, sorry, a notebooks grandmaster.
[00:02:34.140 --> 00:02:36.060]   And at the moment she's ranked 16th.
[00:02:36.060 --> 00:02:38.180]   So we've all benefited in the Kaggle community
[00:02:38.180 --> 00:02:39.000]   from Parul's work.
[00:02:39.000 --> 00:02:41.540]   She's got really interesting notebooks
[00:02:41.540 --> 00:02:43.900]   and she's been sharing her learnings with everybody
[00:02:43.900 --> 00:02:44.980]   for quite some time now.
[00:02:44.980 --> 00:02:49.220]   And I've heard her name on many social media platforms
[00:02:49.220 --> 00:02:51.900]   and got to know her personally as well.
[00:02:51.900 --> 00:02:55.540]   And she's also got this really nice personal blog,
[00:02:55.540 --> 00:02:57.180]   which is called Breaking the Jargons.
[00:02:57.180 --> 00:02:59.340]   I really like the name and she's got everything here.
[00:02:59.340 --> 00:03:00.660]   She's got her own article,
[00:03:00.660 --> 00:03:04.140]   she's got her own Kaggle profile that takes it to,
[00:03:04.140 --> 00:03:07.380]   the Kaggle link that takes to the Kaggle profile.
[00:03:07.380 --> 00:03:08.980]   And she'll be joining us next week.
[00:03:08.980 --> 00:03:12.220]   So last week we had a guest lecture from Tanishq,
[00:03:12.220 --> 00:03:14.020]   but Parul will be coming back next week
[00:03:14.020 --> 00:03:16.740]   and she will be sharing just her journey
[00:03:16.740 --> 00:03:21.180]   on how sharing work publicly has been really helpful.
[00:03:21.180 --> 00:03:27.500]   And then there's been some sort of bugs.
[00:03:27.500 --> 00:03:28.940]   So there's been some sort of questions
[00:03:28.940 --> 00:03:30.540]   that have come up from you guys.
[00:03:30.540 --> 00:03:33.140]   One of the most common one that I've seen
[00:03:33.140 --> 00:03:35.900]   and everybody sort of asked me about it is this one.
[00:03:35.900 --> 00:03:38.380]   The search images, Dr. Goh is not working
[00:03:38.380 --> 00:03:40.820]   or the search images Bing is not working.
[00:03:40.820 --> 00:03:44.260]   So on Slack yesterday, let me bring up Slack.
[00:03:44.260 --> 00:03:50.900]   On Slack, I did share with everybody on,
[00:03:50.900 --> 00:03:53.740]   I did share this link,
[00:03:53.740 --> 00:04:00.060]   which basically tells you like what needs to be done.
[00:04:00.060 --> 00:04:02.740]   Just use this function instead, just use this.
[00:04:02.740 --> 00:04:03.580]   Sorry, it's this one.
[00:04:03.580 --> 00:04:06.420]   Just use the search images EDG corrected.
[00:04:06.420 --> 00:04:08.900]   We can go into the details on what exactly is going on,
[00:04:08.900 --> 00:04:11.740]   but I've already provided in this thread,
[00:04:11.740 --> 00:04:15.220]   the whole sort of summary and background on what's going on.
[00:04:15.220 --> 00:04:19.740]   So there was exactly a commit that changed this.
[00:04:19.740 --> 00:04:22.420]   So that commit is pretty much here.
[00:04:22.420 --> 00:04:25.780]   So this commit ID kind of changed the default parameter
[00:04:25.780 --> 00:04:28.740]   that due to which this bug is,
[00:04:28.740 --> 00:04:31.140]   or due to which there's this error that's coming up.
[00:04:31.140 --> 00:04:34.780]   So if you remove the dot decode method
[00:04:34.780 --> 00:04:35.980]   and that should just work.
[00:04:35.980 --> 00:04:39.540]   So you can see the difference in DDG corrected
[00:04:39.540 --> 00:04:43.220]   and the difference in DDG is just this line of code.
[00:04:43.220 --> 00:04:46.900]   So you have a dot decode over here in result.
[00:04:46.900 --> 00:04:49.100]   You don't have that here because this URL read
[00:04:49.100 --> 00:04:53.580]   now already returns a decoded version of your data.
[00:04:53.580 --> 00:04:56.500]   So you don't really need to call decode on it specifically,
[00:04:56.500 --> 00:04:58.260]   but we'll go into this, we'll create our own data set.
[00:04:58.260 --> 00:05:00.500]   So today we're gonna do a lot more coding
[00:05:00.500 --> 00:05:03.620]   and we're going to dig a lot deeper
[00:05:03.620 --> 00:05:06.980]   into the source code of FastAI.
[00:05:06.980 --> 00:05:09.740]   Something I did wanna mention,
[00:05:09.740 --> 00:05:11.780]   I'm a bit disappointed about this is,
[00:05:11.780 --> 00:05:13.540]   and it's not to point to Grijesh,
[00:05:13.540 --> 00:05:17.660]   he's been, but I feel that Grijesh is the only person
[00:05:17.660 --> 00:05:21.020]   who's come back and he's discussed the questionnaire
[00:05:21.020 --> 00:05:22.900]   at the end of chapter one.
[00:05:22.900 --> 00:05:24.980]   So at the last session,
[00:05:24.980 --> 00:05:27.940]   I showed you towards the end of chapter one.
[00:05:27.940 --> 00:05:30.700]   (mouse clicking)
[00:05:30.700 --> 00:05:36.300]   There is this questionnaire,
[00:05:36.300 --> 00:05:39.500]   which has about 33 questions
[00:05:39.500 --> 00:05:40.940]   and these questions shouldn't take long.
[00:05:40.940 --> 00:05:43.620]   It should be like five, 10 seconds per question,
[00:05:43.620 --> 00:05:45.340]   but I've only seen Grijesh come back
[00:05:45.340 --> 00:05:48.180]   and he's the only person who's been asking questions
[00:05:48.180 --> 00:05:50.740]   about this questionnaire.
[00:05:50.740 --> 00:05:53.820]   It sort of makes me feel sad that not everybody's doing it,
[00:05:53.820 --> 00:05:56.060]   but I want you guys to do it
[00:05:56.060 --> 00:05:58.460]   because it will help you.
[00:05:58.460 --> 00:06:00.180]   It will really help your understanding.
[00:06:00.180 --> 00:06:02.460]   So if you go back and you read the chapter,
[00:06:02.460 --> 00:06:04.380]   we want you to do these questions.
[00:06:04.380 --> 00:06:07.220]   And we want to discuss these questions
[00:06:07.220 --> 00:06:09.140]   throughout the week between ourselves.
[00:06:09.140 --> 00:06:11.420]   And you wanna make sure that you understand
[00:06:11.420 --> 00:06:13.620]   and have answers to each of these questions.
[00:06:13.620 --> 00:06:19.460]   We've seen, and I'll be going through the questions today.
[00:06:19.460 --> 00:06:23.100]   So we have lots more time today than last week.
[00:06:23.100 --> 00:06:26.100]   Another thing is, Ravi has brought up,
[00:06:26.100 --> 00:06:27.660]   he said he was setting up this EC2
[00:06:27.660 --> 00:06:30.460]   and he mentioned that a minimum number of CPUs
[00:06:30.460 --> 00:06:33.740]   that he needs to sort of run is four virtual CPUs.
[00:06:33.740 --> 00:06:36.220]   So he was trying to start with one virtual CPU.
[00:06:36.220 --> 00:06:37.940]   That's okay.
[00:06:37.940 --> 00:06:39.340]   I think that's just an AWS requirement.
[00:06:39.340 --> 00:06:41.180]   There's also more things on the web.
[00:06:41.180 --> 00:06:44.820]   If you have only the one virtual CPU,
[00:06:44.820 --> 00:06:47.420]   so what happens in a deep learning world,
[00:06:47.420 --> 00:06:49.180]   or basically when you're using a GPU,
[00:06:49.780 --> 00:06:53.180]   your CPU does a majority of the data processing,
[00:06:53.180 --> 00:06:56.660]   and then it feeds that data to the GPU.
[00:06:56.660 --> 00:06:58.580]   If you only have one CPU,
[00:06:58.580 --> 00:07:03.180]   then it's not gonna be able to feed data to the GPU
[00:07:03.180 --> 00:07:05.940]   fast enough to keep it utilized very well.
[00:07:05.940 --> 00:07:08.300]   So it's actually under utilizing your GPUs.
[00:07:08.300 --> 00:07:10.780]   What you need is you need at least four virtual CPUs.
[00:07:10.780 --> 00:07:13.380]   I usually go with eight or 16,
[00:07:13.380 --> 00:07:15.740]   but even four should be fine to start with.
[00:07:18.380 --> 00:07:19.860]   And then the last thing I wanna discuss
[00:07:19.860 --> 00:07:21.660]   is there's been some confusion
[00:07:21.660 --> 00:07:24.820]   about whether we wanna use Fast.ai forums,
[00:07:24.820 --> 00:07:27.980]   whether we wanna use Weights & Biases forums,
[00:07:27.980 --> 00:07:29.820]   and where we're using Slack for.
[00:07:29.820 --> 00:07:33.300]   It's like, what's the difference in the three?
[00:07:33.300 --> 00:07:34.740]   When should we use Fast.ai forums?
[00:07:34.740 --> 00:07:37.220]   When should we use Weights & Biases forums?
[00:07:37.220 --> 00:07:38.820]   And when Slack forums?
[00:07:38.820 --> 00:07:41.020]   To me, it's really fine.
[00:07:41.020 --> 00:07:43.580]   I mean, whatever we wanna use, I will share.
[00:07:43.580 --> 00:07:47.740]   Towards the end of today, there will be time.
[00:07:47.740 --> 00:07:50.020]   So once we've finished chapter two,
[00:07:50.020 --> 00:07:52.700]   which will be creating a model in production,
[00:07:52.700 --> 00:07:55.060]   then I will go into this Fast.ai forums
[00:07:55.060 --> 00:07:57.940]   and I'll kind of share with you what the differences are,
[00:07:57.940 --> 00:08:01.580]   what the benefits are from each.
[00:08:01.580 --> 00:08:03.020]   And then I'll let you guys decide.
[00:08:03.020 --> 00:08:05.580]   I mean, we can do the comments as last time,
[00:08:05.580 --> 00:08:07.700]   like whether we should go from 60 to 90 minutes.
[00:08:07.700 --> 00:08:09.780]   And then there was these huge amount of comments
[00:08:09.780 --> 00:08:10.620]   on which one to use.
[00:08:10.620 --> 00:08:12.740]   So let's sort of do like a popular vote.
[00:08:12.740 --> 00:08:17.020]   And we're gonna be using this 1db.me/fastbook3.
[00:08:17.020 --> 00:08:18.340]   So let me post that here.
[00:08:18.340 --> 00:08:26.500]   So 1db.me/fastbook3 will take you,
[00:08:26.500 --> 00:08:29.420]   again, just as last time, it will take you to,
[00:08:29.420 --> 00:08:41.620]   it will take you to this Fast.ai reading group week three,
[00:08:41.620 --> 00:08:42.580]   which is today.
[00:08:42.580 --> 00:08:44.620]   And then we're gonna be asking all the,
[00:08:44.620 --> 00:08:47.180]   we're gonna be discussing everything as part of comments.
[00:08:47.180 --> 00:08:48.700]   So that's something that's not gonna change.
[00:08:48.700 --> 00:08:49.900]   We're gonna continue doing this
[00:08:49.900 --> 00:08:51.780]   'cause I find it really easy
[00:08:51.780 --> 00:08:53.740]   instead of having to look at the Zoom chat
[00:08:53.740 --> 00:08:56.660]   or having to look at YouTube chat.
[00:08:56.660 --> 00:08:58.540]   It's just easy to have it all in one place
[00:08:58.540 --> 00:09:00.580]   and still continue having comments.
[00:09:00.580 --> 00:09:02.020]   So thanks, Sanyam, for posting this.
[00:09:02.020 --> 00:09:06.580]   And we will get, we'll share with everybody
[00:09:06.580 --> 00:09:09.940]   on what the benefits are of sharing your WeTube projects
[00:09:09.940 --> 00:09:12.140]   in forums at Fast.ai.
[00:09:12.140 --> 00:09:15.340]   So with that being said, let's quickly get started
[00:09:15.340 --> 00:09:17.300]   with what we are going to cover today.
[00:09:17.300 --> 00:09:39.220]   So we're gonna cover all of this today.
[00:09:40.260 --> 00:09:45.180]   The last place where we stopped was here.
[00:09:45.180 --> 00:09:50.060]   So we're having a look at basically,
[00:09:50.060 --> 00:09:53.940]   I showed you how you can create your own dataset basically.
[00:09:53.940 --> 00:09:58.940]   And the way to do it is to use this download image
[00:09:58.940 --> 00:10:02.580]   and to use this search images Bing option.
[00:10:02.580 --> 00:10:03.820]   So one second, please.
[00:10:03.820 --> 00:10:09.300]   Is to use this search images Bing, which is right here.
[00:10:09.300 --> 00:10:11.380]   So this was where we stopped last time.
[00:10:11.380 --> 00:10:13.820]   So we're gonna go ahead from here.
[00:10:13.820 --> 00:10:17.140]   And today what we're gonna do is we're gonna just
[00:10:17.140 --> 00:10:18.100]   build on top of this.
[00:10:18.100 --> 00:10:22.340]   So by this time, I hope that everybody is able to create
[00:10:22.340 --> 00:10:25.260]   their, basically everybody is able to
[00:10:25.260 --> 00:10:27.660]   create their own datasets.
[00:10:27.660 --> 00:10:29.580]   And this week you should have pretty much
[00:10:29.580 --> 00:10:30.900]   created your own datasets.
[00:10:30.900 --> 00:10:36.380]   We looked at a simple way to look at the source code
[00:10:36.380 --> 00:10:39.020]   of things is just to put question mark, question mark.
[00:10:39.020 --> 00:10:40.780]   So last time I didn't touch,
[00:10:40.780 --> 00:10:43.500]   I didn't go into the coding side of things a lot,
[00:10:43.500 --> 00:10:44.900]   but that's gonna change this week.
[00:10:44.900 --> 00:10:48.820]   So let's just quickly go into chapter two production.
[00:10:48.820 --> 00:10:51.300]   So I have my thing set up on GCP.
[00:10:51.300 --> 00:10:53.620]   So if I import everything that works.
[00:10:53.620 --> 00:10:58.460]   So this was the sort of the search images Bing
[00:10:58.460 --> 00:10:59.300]   was the one thing.
[00:10:59.300 --> 00:11:00.740]   So you need a zero key for that.
[00:11:00.740 --> 00:11:03.860]   And then you need to pass that key in here.
[00:11:03.860 --> 00:11:06.380]   And then you need to say, well, pretty much anything
[00:11:06.380 --> 00:11:07.260]   that you wanna search for.
[00:11:07.260 --> 00:11:11.700]   You could say grizzly bear, right?
[00:11:11.700 --> 00:11:16.820]   But what has been noticed is that this is something
[00:11:16.820 --> 00:11:19.380]   that wasn't working very well.
[00:11:19.380 --> 00:11:21.700]   So there's a substitute for it,
[00:11:21.700 --> 00:11:23.860]   which is called search images, duck, duck, go.
[00:11:23.860 --> 00:11:25.460]   So let me just, I'm going to Slack.
[00:11:25.460 --> 00:11:29.740]   I'm just gonna copy this function and let me paste it here.
[00:11:29.740 --> 00:11:31.500]   Define search images.
[00:11:31.500 --> 00:11:34.860]   So it just defines a function and I can just say URLs
[00:11:34.860 --> 00:11:39.860]   equals search images, duck, duck, go instead.
[00:11:39.860 --> 00:11:43.740]   And I can say grizzly bear, right?
[00:11:43.740 --> 00:11:51.860]   And that, and I can just say, okay,
[00:11:51.860 --> 00:11:55.220]   return the max number of images as a hundred.
[00:11:55.220 --> 00:12:01.260]   And there it is, that returns a number of URLs.
[00:12:01.260 --> 00:12:03.860]   So just to be sure that this is working,
[00:12:03.860 --> 00:12:06.900]   I can go into the first URL, which is this one,
[00:12:06.900 --> 00:12:10.380]   and I can go and let me just copy paste just to make sure.
[00:12:10.380 --> 00:12:12.500]   And there it is, that's a picture of a grizzly bear
[00:12:12.500 --> 00:12:16.500]   sleeping on a wooden log, which is funny.
[00:12:16.500 --> 00:12:20.700]   So cool, so instead of using search images Bing,
[00:12:20.700 --> 00:12:23.660]   you can just use this search images, duck, duck, go.
[00:12:23.660 --> 00:12:26.460]   And then you no longer need to do results.at robots.
[00:12:26.460 --> 00:12:29.980]   You can just replace that, replace that.
[00:12:29.980 --> 00:12:33.820]   And instead of doing something like this,
[00:12:33.820 --> 00:12:36.780]   just delete that line, which was in the notebook.
[00:12:36.780 --> 00:12:41.700]   So you'll have search images, duck, duck, go.
[00:12:41.700 --> 00:12:43.220]   You don't need to pass in a key.
[00:12:43.220 --> 00:12:45.980]   You can just say grizzly bear and that's it.
[00:12:45.980 --> 00:12:47.700]   And that will return your results.
[00:12:47.700 --> 00:12:52.140]   So it returns 279 images for grizzly bears.
[00:12:52.140 --> 00:12:55.540]   Cool, then I can just open my,
[00:12:55.540 --> 00:13:01.180]   I can just open my thumbnail.
[00:13:01.180 --> 00:13:02.620]   So the next thing you wanna do is,
[00:13:02.620 --> 00:13:05.100]   if you really wanna create your dataset,
[00:13:05.100 --> 00:13:06.660]   then the next thing you wanna do is,
[00:13:06.660 --> 00:13:09.460]   instead of using this search images Bing,
[00:13:09.460 --> 00:13:10.860]   'cause we're not using this,
[00:13:10.860 --> 00:13:14.220]   we wanna replace this with search images, duck, duck, go.
[00:13:14.220 --> 00:13:17.420]   And what this search images, duck, duck, go needs
[00:13:17.420 --> 00:13:18.460]   is just the term.
[00:13:18.460 --> 00:13:20.700]   So there's no need to pass in a key, right?
[00:13:20.700 --> 00:13:25.140]   So we take away the key and we just say max images,
[00:13:25.140 --> 00:13:28.380]   maybe a hundred.
[00:13:28.380 --> 00:13:31.740]   And then you no longer, 'cause this output
[00:13:31.740 --> 00:13:33.820]   will get stored in results.
[00:13:33.820 --> 00:13:36.500]   Then you no longer need to do results.attr.
[00:13:36.500 --> 00:13:38.460]   You can just say something like that.
[00:13:38.460 --> 00:13:40.540]   And then that will go on.
[00:13:40.540 --> 00:13:42.100]   Sorry, there's a path that exists.
[00:13:42.100 --> 00:13:46.260]   So let me go rm, rfbears.
[00:13:46.260 --> 00:13:48.100]   So basically what I'm trying to say is,
[00:13:48.100 --> 00:13:51.620]   there's already a path called beers at this.
[00:13:51.620 --> 00:13:54.460]   And it says, unless the path exists,
[00:13:54.460 --> 00:13:56.980]   you only run this when the path doesn't exist.
[00:13:56.980 --> 00:13:59.140]   So that's why this code never got run.
[00:14:00.380 --> 00:14:03.260]   So let me just delete that folder.
[00:14:03.260 --> 00:14:05.180]   Cool.
[00:14:05.180 --> 00:14:08.820]   Now, if I have a look, there's no such thing as beers.
[00:14:08.820 --> 00:14:12.420]   By the way, having an exclamation mark
[00:14:12.420 --> 00:14:14.140]   just means that you're running bash commands
[00:14:14.140 --> 00:14:16.340]   or something that you'd rather run in a terminal,
[00:14:16.340 --> 00:14:18.140]   but Jupyter lets you run these things.
[00:14:18.140 --> 00:14:21.500]   It's not a Python, it's not something for Jupyter either.
[00:14:21.500 --> 00:14:24.460]   So now I can just say,
[00:14:24.460 --> 00:14:27.140]   let me add something called a tqdm,
[00:14:27.140 --> 00:14:29.900]   which is just a convenience.
[00:14:29.900 --> 00:14:35.300]   And here we go.
[00:14:35.300 --> 00:14:37.060]   It's downloading the images.
[00:14:37.060 --> 00:14:44.540]   So if you really wanna see,
[00:14:44.540 --> 00:14:47.420]   it's doing something.
[00:14:47.420 --> 00:14:56.860]   I can just do edge top and my CPU is busy.
[00:14:56.860 --> 00:15:00.660]   So that means the images are being downloaded
[00:15:00.660 --> 00:15:02.780]   and we're done with 33%.
[00:15:02.780 --> 00:15:05.740]   So this is just something I wanted to show you
[00:15:05.740 --> 00:15:07.900]   on how you can create your own dataset.
[00:15:07.900 --> 00:15:10.140]   So I could have just gone in
[00:15:10.140 --> 00:15:12.460]   and I could have also passed in,
[00:15:12.460 --> 00:15:15.460]   instead of doing grizzly bear, black bear, teddy bear,
[00:15:15.460 --> 00:15:20.140]   we can also download any sort of images that we want.
[00:15:20.140 --> 00:15:20.980]   So you could actually,
[00:15:20.980 --> 00:15:22.500]   if I wanted to create like a tennis ball
[00:15:22.500 --> 00:15:24.220]   versus a cricket ball classifier,
[00:15:24.220 --> 00:15:25.060]   or I don't know,
[00:15:25.060 --> 00:15:26.060]   if you wanna go into sport
[00:15:26.260 --> 00:15:30.460]   or you wanna have anything else, you can do it.
[00:15:30.460 --> 00:15:32.500]   So just instead of beotypes,
[00:15:32.500 --> 00:15:37.500]   just say classifying or classes
[00:15:37.500 --> 00:15:39.940]   and just call them something like this,
[00:15:39.940 --> 00:15:41.860]   something like a tennis ball.
[00:15:41.860 --> 00:15:45.860]   And I don't know if it'll be a difference.
[00:15:45.860 --> 00:15:47.180]   I haven't tried this,
[00:15:47.180 --> 00:15:49.460]   but you could just say this and that should download.
[00:15:49.460 --> 00:15:51.140]   And then you just replace that with this.
[00:15:51.140 --> 00:15:52.660]   So that will go,
[00:15:52.660 --> 00:15:54.900]   that will go and it will download the images
[00:15:54.900 --> 00:15:57.620]   for a tennis ball and cricket ball pretty much.
[00:15:57.620 --> 00:15:59.940]   And then something you might be wondering
[00:15:59.940 --> 00:16:02.180]   on what TKDM does.
[00:16:02.180 --> 00:16:03.540]   So unless you had a TKDM,
[00:16:03.540 --> 00:16:04.820]   it won't show something like this.
[00:16:04.820 --> 00:16:06.140]   Like now it's showing progress.
[00:16:06.140 --> 00:16:07.940]   It was actually showing me,
[00:16:07.940 --> 00:16:09.420]   okay, we were done with 33%,
[00:16:09.420 --> 00:16:10.380]   we were done with 66.
[00:16:10.380 --> 00:16:13.700]   So that's the main benefit of having TKDM here.
[00:16:13.700 --> 00:16:16.340]   Cool, so then at that particular path,
[00:16:16.340 --> 00:16:17.700]   if I go to this path,
[00:16:23.500 --> 00:16:24.940]   so if I go to the beers path,
[00:16:24.940 --> 00:16:26.460]   now I have three folders,
[00:16:26.460 --> 00:16:28.580]   black, grizzly and teddy.
[00:16:28.580 --> 00:16:29.580]   If I go into black,
[00:16:29.580 --> 00:16:31.300]   I have all these images
[00:16:31.300 --> 00:16:33.020]   that have been downloaded for black beers.
[00:16:33.020 --> 00:16:34.060]   If I click on one,
[00:16:34.060 --> 00:16:35.260]   that's a black beer.
[00:16:35.260 --> 00:16:41.860]   If I click on a teddy bear,
[00:16:41.860 --> 00:16:44.300]   the image, then that's a teddy bear.
[00:16:44.300 --> 00:16:45.140]   There it is.
[00:16:45.140 --> 00:16:46.460]   That's an image of teddy bear.
[00:16:46.460 --> 00:16:47.300]   I'm so cool.
[00:16:47.300 --> 00:16:48.820]   So then this way we have been able
[00:16:48.820 --> 00:16:51.740]   to then download images using DuckDuckGo.
[00:16:53.300 --> 00:16:55.060]   Then what get image files will do,
[00:16:55.060 --> 00:16:56.660]   I'm just passing in this path.
[00:16:56.660 --> 00:17:00.900]   So this path is just a path to the folder beers.
[00:17:00.900 --> 00:17:03.860]   So we're running this in Jupyter Notebook.
[00:17:03.860 --> 00:17:06.020]   And then what it does is it points
[00:17:06.020 --> 00:17:08.660]   to this path with three folders.
[00:17:08.660 --> 00:17:11.540]   And we're calling a fast AI function
[00:17:11.540 --> 00:17:13.460]   called get image files.
[00:17:13.460 --> 00:17:16.140]   So I can show you on what get image files is,
[00:17:16.140 --> 00:17:19.060]   but if you wanna know what get image files is,
[00:17:19.060 --> 00:17:21.980]   you can just do a question mark, question mark.
[00:17:21.980 --> 00:17:24.580]   And then it will show you, okay,
[00:17:24.580 --> 00:17:26.900]   all it does is what this get image files does
[00:17:26.900 --> 00:17:29.060]   is it calls something called get files
[00:17:29.060 --> 00:17:32.820]   and it passes in extensions called image extensions.
[00:17:32.820 --> 00:17:35.620]   So what is get files doing?
[00:17:35.620 --> 00:17:37.820]   So I can just go and say, okay,
[00:17:37.820 --> 00:17:40.780]   please tell me what's get files doing.
[00:17:40.780 --> 00:17:43.740]   What get files does is it gets all the files
[00:17:43.740 --> 00:17:45.380]   in part with extensions.
[00:17:45.380 --> 00:17:49.620]   So because we only looking at image files,
[00:17:49.620 --> 00:17:52.980]   then these extensions could be JPEG, PNG.
[00:17:52.980 --> 00:17:56.580]   So pretty much if I go and have a look at image extensions,
[00:17:56.580 --> 00:18:00.020]   then you can see how there's a list of all these extensions,
[00:18:00.020 --> 00:18:05.460]   pretty much everything that's related to an image.
[00:18:05.460 --> 00:18:10.460]   And internally, fast AI is using something called MIME types.
[00:18:10.460 --> 00:18:14.860]   So MIME types is what will return
[00:18:14.860 --> 00:18:16.460]   just all these extensions.
[00:18:16.460 --> 00:18:18.660]   Just in case, that's just an extra thing.
[00:18:18.660 --> 00:18:20.220]   So cool, so then get files,
[00:18:20.220 --> 00:18:24.220]   all that does is get files will go to this path.
[00:18:24.220 --> 00:18:28.300]   It will find a path of all of these files in that folder,
[00:18:28.300 --> 00:18:30.860]   only if the extension of that file
[00:18:30.860 --> 00:18:33.740]   is belonging to one of those image extensions.
[00:18:33.740 --> 00:18:35.140]   So if there's like a TXT
[00:18:35.140 --> 00:18:38.300]   or a PowerPoint presentation in there or a PDF,
[00:18:38.300 --> 00:18:40.580]   it won't return a path to that.
[00:18:40.580 --> 00:18:42.620]   As an example, let me show you.
[00:18:42.620 --> 00:18:47.620]   So I'm just gonna create a file called cat.txt.
[00:18:48.540 --> 00:18:50.020]   And then I can just say,
[00:18:50.020 --> 00:18:56.100]   get image files in my current directory.
[00:18:56.100 --> 00:18:58.940]   And then it's only returning the paths to images.
[00:18:58.940 --> 00:19:01.620]   This cat.txt never gets returned.
[00:19:01.620 --> 00:19:06.940]   Cool, so then I can go in and I can pass,
[00:19:06.940 --> 00:19:08.320]   I can then pass in this,
[00:19:08.320 --> 00:19:12.100]   I can then pass in the path to this BS folder.
[00:19:12.100 --> 00:19:13.120]   And I can say,
[00:19:15.300 --> 00:19:18.100]   please get all the image related files
[00:19:18.100 --> 00:19:19.580]   that are inside this folder
[00:19:19.580 --> 00:19:22.140]   or on all the sub folders that are there.
[00:19:22.140 --> 00:19:24.180]   So I can just say that and it will return.
[00:19:24.180 --> 00:19:27.100]   It will say, okay, there's 259 files.
[00:19:27.100 --> 00:19:30.400]   The first one is under beer grizzly.
[00:19:30.400 --> 00:19:33.380]   Then there's pretty much, if I can just go,
[00:19:33.380 --> 00:19:35.500]   if I have a look at the last 10 files,
[00:19:35.500 --> 00:19:37.020]   then they're just beers and black.
[00:19:37.020 --> 00:19:39.020]   So it's pretty much gone in
[00:19:39.020 --> 00:19:42.880]   into the all three of the folders, black, grizzly and teddy.
[00:19:42.880 --> 00:19:45.180]   And then it's returned all of those.
[00:19:45.180 --> 00:19:47.440]   It's returned the path to all of those files.
[00:19:47.440 --> 00:19:52.220]   Then the next thing is just something called verify images.
[00:19:52.220 --> 00:19:55.420]   So see how I'm putting question mark, question mark,
[00:19:55.420 --> 00:19:57.500]   just to have a look at the source code.
[00:19:57.500 --> 00:19:59.880]   There's another way to do it, which is,
[00:19:59.880 --> 00:20:01.140]   you could actually use,
[00:20:01.140 --> 00:20:05.300]   you could actually use VS code to go through the,
[00:20:05.300 --> 00:20:07.220]   to actually go through the source code.
[00:20:07.220 --> 00:20:08.780]   I will show you each of that today.
[00:20:08.780 --> 00:20:11.820]   So that today is more practical side of things
[00:20:11.820 --> 00:20:14.320]   and less on the theoretical side of things.
[00:20:14.320 --> 00:20:15.820]   But I will show you, but right now,
[00:20:15.820 --> 00:20:18.320]   'cause most of you are gonna be running this
[00:20:18.320 --> 00:20:20.060]   and in Google Colab,
[00:20:20.060 --> 00:20:22.320]   then the easiest way is just to put a question mark,
[00:20:22.320 --> 00:20:23.160]   question mark.
[00:20:23.160 --> 00:20:24.660]   And if you put a single question mark,
[00:20:24.660 --> 00:20:26.660]   it will just return the doc string.
[00:20:26.660 --> 00:20:30.220]   So it will just say, okay, verify images just does this.
[00:20:30.220 --> 00:20:33.340]   It will find images in all the file names
[00:20:33.340 --> 00:20:34.800]   that can't be opened.
[00:20:34.800 --> 00:20:35.640]   So that's it.
[00:20:35.640 --> 00:20:41.980]   And the last one that I showed you last time is this one.
[00:20:41.980 --> 00:20:45.880]   So if you, in Fast.ai, there's this option to click doc.
[00:20:45.880 --> 00:20:47.480]   So verify images, question mark,
[00:20:47.480 --> 00:20:50.120]   or question mark, question mark is Jupyter specific.
[00:20:50.120 --> 00:20:52.200]   Doc is Fast.ai specific.
[00:20:52.200 --> 00:20:54.680]   So it will open up this really nice sort of UI,
[00:20:54.680 --> 00:20:56.040]   and then you can click on source,
[00:20:56.040 --> 00:20:59.080]   and it will also take you to the source of verify images
[00:20:59.080 --> 00:21:01.440]   inside the Fast.ai repo.
[00:21:01.440 --> 00:21:03.400]   So that's the three ways of doing this.
[00:21:03.400 --> 00:21:05.240]   Cool.
[00:21:05.240 --> 00:21:07.960]   And then I can just remove a list of files,
[00:21:07.960 --> 00:21:10.640]   'cause then what this does is it will say,
[00:21:10.640 --> 00:21:13.380]   these are the six parts that can't be opened.
[00:21:13.380 --> 00:21:16.060]   So inside this, I can't open this file.
[00:21:16.060 --> 00:21:17.300]   These could be corrupt files,
[00:21:17.300 --> 00:21:20.540]   or yeah, pretty much they just can't be opened.
[00:21:20.540 --> 00:21:25.540]   It could be text files with a JPG sort of extension,
[00:21:25.540 --> 00:21:28.020]   but this function is just saying
[00:21:28.020 --> 00:21:30.340]   that these are the files that can't be opened.
[00:21:30.340 --> 00:21:31.520]   And then the last thing we wanna do
[00:21:31.520 --> 00:21:34.140]   is we just wanna remove them from our part, and that's it.
[00:21:34.140 --> 00:21:36.220]   And now we have a dataset ready,
[00:21:36.220 --> 00:21:38.380]   and we've sort of cleaned it.
[00:21:38.380 --> 00:21:39.780]   So yeah, so this is how you can go back,
[00:21:39.780 --> 00:21:41.980]   and you can create your own datasets.
[00:21:41.980 --> 00:21:48.440]   We will have lots more time for questions today.
[00:21:48.440 --> 00:21:50.160]   I'm not going into questions right now,
[00:21:50.160 --> 00:21:54.040]   but as we go through chapter two,
[00:21:54.040 --> 00:21:56.480]   something I wanna say is we're not going to be
[00:21:56.480 --> 00:21:57.960]   going into chapter three today.
[00:21:57.960 --> 00:22:00.880]   I've made a change, a last minute change,
[00:22:00.880 --> 00:22:03.520]   which is going to be, we're going to wrap up chapter two.
[00:22:03.520 --> 00:22:05.400]   I'm going to show you each of the steps
[00:22:05.400 --> 00:22:06.440]   that I mentioned in the book,
[00:22:06.440 --> 00:22:08.220]   and sort of show you how I can,
[00:22:08.220 --> 00:22:10.200]   how we can do it in Jupyter Notebook.
[00:22:10.200 --> 00:22:12.240]   And then I'm going to go deeper and deeper
[00:22:12.240 --> 00:22:13.800]   into the source code of some of the things
[00:22:13.800 --> 00:22:17.160]   so you can go back and experiment with these things
[00:22:17.160 --> 00:22:18.440]   on your own this week.
[00:22:18.440 --> 00:22:23.440]   Okay, so this is where we were.
[00:22:23.440 --> 00:22:26.920]   We pretty much left off at this point.
[00:22:26.920 --> 00:22:31.920]   So until now, what I've shown you is just a way
[00:22:31.920 --> 00:22:35.320]   on how you can create your own datasets.
[00:22:35.320 --> 00:22:38.580]   Then from this point on, let's go deeper
[00:22:38.580 --> 00:22:40.660]   into what some of these things mean.
[00:22:40.660 --> 00:22:45.380]   So something in fast AI or basically in deep learning,
[00:22:45.380 --> 00:22:48.780]   you will see being talked a lot about is a data loader.
[00:22:48.780 --> 00:22:51.460]   So what is a data loader?
[00:22:51.460 --> 00:22:55.180]   So you know how I told you we have,
[00:22:55.180 --> 00:23:01.060]   say our dataset consists of 100 items.
[00:23:01.060 --> 00:23:04.580]   Then you put them in batches.
[00:23:04.580 --> 00:23:06.100]   So you say you have 10 batches,
[00:23:06.100 --> 00:23:08.460]   batch one, batch two, batch three,
[00:23:08.460 --> 00:23:11.220]   and each one of them has 10 items.
[00:23:11.220 --> 00:23:17.060]   Then there's a, you have your GPU here,
[00:23:17.060 --> 00:23:22.280]   and the model is sort of training at this point.
[00:23:22.280 --> 00:23:25.540]   Then something is going to pass each of these batches
[00:23:25.540 --> 00:23:27.580]   one by one to the GPU.
[00:23:27.580 --> 00:23:31.940]   This something that passes these batches one by one
[00:23:31.940 --> 00:23:34.640]   to the GPU is called a data loader.
[00:23:34.640 --> 00:23:36.820]   Okay.
[00:23:36.820 --> 00:23:40.460]   We're going to look a lot more deeply
[00:23:40.460 --> 00:23:44.020]   into what exactly a data loader is or what exactly it does.
[00:23:44.020 --> 00:23:50.380]   But in fast AI, you have a class called data loaders.
[00:23:50.380 --> 00:23:57.100]   In fast AI, you have a class called data loaders,
[00:23:57.100 --> 00:24:00.900]   which pretty much has a train and validation data loaders.
[00:24:00.900 --> 00:24:02.580]   That's the, in summary,
[00:24:02.580 --> 00:24:06.100]   this is how the source code of this data loaders class
[00:24:06.100 --> 00:24:10.260]   looks like, but a data loader class is just nothing,
[00:24:10.260 --> 00:24:14.060]   but a fast AI clause that stores multiple data loaders,
[00:24:14.060 --> 00:24:15.700]   objects that you pass to it.
[00:24:15.700 --> 00:24:19.940]   So this is a data loader object that will get the batches
[00:24:19.940 --> 00:24:22.820]   and it will feed the batches to the GPU.
[00:24:22.820 --> 00:24:24.940]   You can have multiple of these,
[00:24:24.940 --> 00:24:26.180]   'cause if you think of it,
[00:24:26.180 --> 00:24:28.580]   remember we have a training set.
[00:24:28.580 --> 00:24:32.980]   We have a training and we have a validation set.
[00:24:32.980 --> 00:24:36.780]   So typically what you want to do is you want to have
[00:24:36.780 --> 00:24:40.020]   a data loader for training data,
[00:24:40.020 --> 00:24:43.180]   and then you want to have a data loader for validation data.
[00:24:43.180 --> 00:24:45.780]   So when we had a hundred items,
[00:24:45.780 --> 00:24:50.100]   we split it into 80 and 20 by 20% split.
[00:24:50.100 --> 00:24:54.100]   So then this 80% would be fed by training data loader.
[00:24:54.100 --> 00:24:58.140]   And this 20% would be fed by using a validation data loader.
[00:24:58.140 --> 00:25:01.180]   But what this fast AI data loaders class does
[00:25:01.180 --> 00:25:02.820]   is that it brings them together.
[00:25:02.820 --> 00:25:06.180]   So this has two loaders.
[00:25:06.180 --> 00:25:09.220]   The first one is called the train loader,
[00:25:09.220 --> 00:25:10.660]   which returns this.
[00:25:10.660 --> 00:25:13.580]   And the second one is called a validation loader
[00:25:13.580 --> 00:25:15.980]   or a val loader.
[00:25:15.980 --> 00:25:17.380]   But you can have as many as you like.
[00:25:17.380 --> 00:25:19.980]   Don't think that the fast AI data loaders class
[00:25:19.980 --> 00:25:20.820]   can only have two.
[00:25:20.820 --> 00:25:23.980]   It can have as many loaders as you want.
[00:25:23.980 --> 00:25:26.740]   (mouse clicking)
[00:25:26.740 --> 00:25:31.420]   Okay.
[00:25:31.420 --> 00:25:33.740]   So then in fast AI right now,
[00:25:33.740 --> 00:25:37.620]   when we did something like get image files,
[00:25:37.620 --> 00:25:42.460]   all that it did was it returned a list of parts.
[00:25:42.460 --> 00:25:43.420]   So let me show you.
[00:25:43.420 --> 00:25:47.260]   So when I did this, get image files,
[00:25:47.260 --> 00:25:50.580]   all that this FNs or this file names
[00:25:50.580 --> 00:25:52.420]   was just a list of parts.
[00:25:52.420 --> 00:25:56.580]   So the first item was grizzly.jpg,
[00:25:56.580 --> 00:25:58.900]   B is grizzly, then 0083.jpg,
[00:25:58.900 --> 00:26:03.540]   which is just the parts to these particular files.
[00:26:03.540 --> 00:26:06.220]   Then the question is,
[00:26:06.220 --> 00:26:09.100]   how do you turn your downloaded data into a data loader?
[00:26:09.100 --> 00:26:12.500]   'Cause if you wanna train your deep learning model,
[00:26:12.500 --> 00:26:16.500]   then what you need is you need to convert your,
[00:26:16.500 --> 00:26:18.860]   you need to be able to convert these parts
[00:26:18.860 --> 00:26:21.860]   into a way that can then be fed to your GPU.
[00:26:21.860 --> 00:26:24.300]   So for that, what fast AI basically needs
[00:26:24.300 --> 00:26:26.380]   is what kind of data we're working with.
[00:26:26.380 --> 00:26:28.460]   Is it images or text?
[00:26:28.460 --> 00:26:29.940]   How do you get the list of items?
[00:26:29.940 --> 00:26:32.460]   So right now we can get the list of items
[00:26:32.460 --> 00:26:34.700]   by using something called get image files.
[00:26:34.700 --> 00:26:39.700]   So this is returning my 250 something list of items.
[00:26:39.700 --> 00:26:42.180]   The next thing you wanna know is how do you label
[00:26:42.180 --> 00:26:44.900]   these items and then how do you create the validation set?
[00:26:44.900 --> 00:26:48.140]   So as long as you have the answer to these,
[00:26:49.260 --> 00:26:52.300]   as long as you have the answer to these four questions,
[00:26:52.300 --> 00:26:54.980]   then you can actually pretty much,
[00:26:54.980 --> 00:26:56.860]   then you're sorted to create,
[00:26:56.860 --> 00:26:59.260]   convert your downloaded data into a data loader.
[00:26:59.260 --> 00:27:04.420]   So in fast AI, there's two things
[00:27:04.420 --> 00:27:06.540]   that you'll come across mostly.
[00:27:06.540 --> 00:27:08.500]   The first one is a data block.
[00:27:08.500 --> 00:27:13.460]   So we can create our bears data block
[00:27:13.460 --> 00:27:16.700]   by telling fast AI that there's two blocks.
[00:27:16.700 --> 00:27:19.700]   One is an image block, second is a category block.
[00:27:19.700 --> 00:27:23.420]   Then you tell fast AI on how you can get all of these items.
[00:27:23.420 --> 00:27:34.740]   Then you tell fast AI on how to get all of these items.
[00:27:34.740 --> 00:27:37.340]   So the way to get these items is to use this function,
[00:27:37.340 --> 00:27:41.380]   get image files, which will return that list of parts.
[00:27:41.380 --> 00:27:44.700]   Then the final thing you tell is how do you split your data
[00:27:44.700 --> 00:27:46.780]   into a training and validation?
[00:27:46.780 --> 00:27:50.820]   And then finally, what this get y is,
[00:27:50.820 --> 00:27:55.260]   from those list of items, how do you get your y labels?
[00:27:55.260 --> 00:27:57.740]   And then this is the transforms.
[00:27:57.740 --> 00:28:00.980]   So we looked into these six, sorry.
[00:28:00.980 --> 00:28:02.540]   We looked into these six,
[00:28:02.540 --> 00:28:05.700]   we looked into these six or five lines of code previously,
[00:28:05.700 --> 00:28:09.020]   but let me again go into them a little bit more deeply.
[00:28:10.500 --> 00:28:15.460]   So get image files has say about 250 parts.
[00:28:15.460 --> 00:28:19.620]   So this is my part one, part two, part three,
[00:28:19.620 --> 00:28:20.820]   part four, and so on.
[00:28:20.820 --> 00:28:26.660]   And this part is something like ./images/001.jpg.
[00:28:26.660 --> 00:28:34.820]   And this part is something like images/0083.jpg.
[00:28:34.820 --> 00:28:37.820]   So something like that.
[00:28:39.180 --> 00:28:41.100]   Then what you wanna do is,
[00:28:41.100 --> 00:28:51.420]   then what you wanna do is from this part,
[00:28:51.420 --> 00:28:56.020]   from just this one part object, you need to get two things.
[00:28:56.020 --> 00:29:03.180]   One is your image, second is your label.
[00:29:04.940 --> 00:29:08.820]   So what this image block,
[00:29:08.820 --> 00:29:12.220]   what these image block and category block are doing,
[00:29:12.220 --> 00:29:13.220]   they're telling you,
[00:29:13.220 --> 00:29:19.220]   if you wanna convert this part into an image,
[00:29:19.220 --> 00:29:24.020]   use something called an image block over here.
[00:29:24.020 --> 00:29:26.500]   And if you're gonna convert this part to a label,
[00:29:26.500 --> 00:29:28.580]   use something called a category block.
[00:29:28.580 --> 00:29:33.020]   So I'll show you on what exactly that means
[00:29:33.020 --> 00:29:35.580]   when we look into the code and we look into it more deeply,
[00:29:35.580 --> 00:29:38.180]   then I'll exactly show you what's happening.
[00:29:38.180 --> 00:29:40.060]   So that's the first thing.
[00:29:40.060 --> 00:29:43.260]   So that's why you have two blocks.
[00:29:43.260 --> 00:29:47.660]   The first block is for your dependent variable,
[00:29:47.660 --> 00:29:49.940]   and the second block is for your independent variable.
[00:29:49.940 --> 00:29:53.420]   So when you're predicting something,
[00:29:53.420 --> 00:29:55.900]   you have your X and your Y.
[00:29:55.900 --> 00:29:58.940]   So for example, when we have images of these images
[00:29:58.940 --> 00:30:03.940]   as .001, oh, sorry, like /images001.jpg,
[00:30:03.940 --> 00:30:11.820]   you have your images as 001.jpg, 002.jpg,
[00:30:11.820 --> 00:30:15.900]   so on, 008.jpg.
[00:30:15.900 --> 00:30:17.380]   Then you have your categories,
[00:30:17.380 --> 00:30:19.500]   'cause each of these images belongs to categories.
[00:30:19.500 --> 00:30:23.300]   So you could have a black bear, grizzly bear,
[00:30:23.300 --> 00:30:27.860]   and you could also have teddy bear.
[00:30:28.780 --> 00:30:31.100]   So then these things on the right,
[00:30:31.100 --> 00:30:36.580]   they call it dependent 'cause they depend on X.
[00:30:36.580 --> 00:30:38.500]   So X is your independent variable,
[00:30:38.500 --> 00:30:41.420]   'cause you kind of predict the Y from X.
[00:30:41.420 --> 00:30:43.700]   So the prediction of Y depends on X.
[00:30:43.700 --> 00:30:47.180]   So that's just another term of saying independent
[00:30:47.180 --> 00:30:48.380]   and dependent variables.
[00:30:48.380 --> 00:30:53.980]   So then the next thing that we wanna look at,
[00:30:53.980 --> 00:30:55.660]   and we can all go deeper and deeper
[00:30:55.780 --> 00:31:00.100]   into how exactly this data block is structured in Fast.ai,
[00:31:00.100 --> 00:31:02.380]   or we can look at the source code of everything,
[00:31:02.380 --> 00:31:05.020]   which we will do over time.
[00:31:05.020 --> 00:31:07.460]   But the next thing is, how do you get your items?
[00:31:07.460 --> 00:31:10.420]   So you use this something called get image files.
[00:31:10.420 --> 00:31:14.820]   So when you say get, let me show you.
[00:31:14.820 --> 00:31:17.140]   So this is exactly what it is.
[00:31:17.140 --> 00:31:20.140]   In get image files, when you pass a path,
[00:31:20.140 --> 00:31:24.140]   then from that path, it's extracting all the items.
[00:31:25.140 --> 00:31:26.300]   So that's what this is.
[00:31:26.300 --> 00:31:29.540]   So you can get your items by passing in this function
[00:31:29.540 --> 00:31:31.020]   called get image files.
[00:31:31.020 --> 00:31:37.380]   Then the third line of code, which is this splitter,
[00:31:37.380 --> 00:31:38.860]   is a random splitter.
[00:31:38.860 --> 00:31:39.940]   What that means,
[00:31:39.940 --> 00:31:45.500]   what that means is,
[00:31:45.500 --> 00:31:48.140]   remember how you have these,
[00:31:48.140 --> 00:31:52.420]   you have like these 250 paths, so P250,
[00:31:52.420 --> 00:31:54.700]   then you wanna be able to split these paths
[00:31:54.700 --> 00:31:56.340]   into train and validation.
[00:31:56.340 --> 00:31:57.860]   'Cause you want your model to learn
[00:31:57.860 --> 00:32:00.500]   from a certain number of images,
[00:32:00.500 --> 00:32:03.940]   and then you want to test the performance of your model
[00:32:03.940 --> 00:32:05.740]   on the validation set.
[00:32:05.740 --> 00:32:08.500]   So what this random splitter will do,
[00:32:08.500 --> 00:32:10.260]   is it will randomly pick,
[00:32:10.260 --> 00:32:13.940]   it will randomly pick 200 images,
[00:32:13.940 --> 00:32:17.820]   or it will randomly pick basically 80% of the images,
[00:32:17.820 --> 00:32:19.820]   and it will call it training data.
[00:32:21.740 --> 00:32:24.900]   And then it will put 20% and it will call it validation.
[00:32:24.900 --> 00:32:26.900]   So that's how this random splitter,
[00:32:26.900 --> 00:32:29.060]   that's what this random splitter is doing.
[00:32:29.060 --> 00:32:31.780]   So if you have,
[00:32:31.780 --> 00:32:36.300]   so if you have some, just five numbers,
[00:32:36.300 --> 00:32:39.100]   like one, two, three, four, five,
[00:32:39.100 --> 00:32:40.940]   then what this random splitter will do,
[00:32:40.940 --> 00:32:44.260]   is it will pick one, three, five in your training set,
[00:32:44.260 --> 00:32:47.060]   and then two and four in your validation set,
[00:32:47.060 --> 00:32:49.540]   if the validation set is 40%.
[00:32:50.220 --> 00:32:51.220]   So then the question is,
[00:32:51.220 --> 00:32:54.020]   something that gets passed to this,
[00:32:54.020 --> 00:32:56.500]   something that gets passed to this random splitter,
[00:32:56.500 --> 00:32:58.340]   is this something called a seed?
[00:32:58.340 --> 00:33:00.500]   So what this seed does,
[00:33:00.500 --> 00:33:03.340]   is that this seed, every time you pass in a random seed,
[00:33:03.340 --> 00:33:05.700]   if you pass in a random seed called 42,
[00:33:05.700 --> 00:33:08.460]   and you give it a list of five,
[00:33:08.460 --> 00:33:09.820]   basically five items,
[00:33:09.820 --> 00:33:11.940]   then what this random splitter will do,
[00:33:11.940 --> 00:33:15.220]   is that every time you'll end up with the same,
[00:33:15.220 --> 00:33:16.940]   one, three, five in your training set,
[00:33:16.940 --> 00:33:18.860]   and two and four in your validation set,
[00:33:18.860 --> 00:33:21.060]   so let me show you on what I mean by that.
[00:33:21.060 --> 00:33:26.300]   So let's say I have just the first five parts,
[00:33:26.300 --> 00:33:28.020]   these are my first five parts,
[00:33:28.020 --> 00:33:34.860]   and I wanna call random splitter,
[00:33:34.860 --> 00:33:37.060]   and I pass in a seed,
[00:33:37.060 --> 00:33:38.740]   I don't pass in a seed right now.
[00:33:38.740 --> 00:33:41.580]   So let's say these are my items,
[00:33:41.580 --> 00:33:44.260]   my items are just the first five parts,
[00:33:44.260 --> 00:33:47.820]   which look like this.
[00:33:48.380 --> 00:33:50.860]   Which look like this, right?
[00:33:50.860 --> 00:33:54.140]   Then I wanna split these items,
[00:33:54.140 --> 00:33:55.620]   so these are just my,
[00:33:55.620 --> 00:33:56.860]   this is my whole data set,
[00:33:56.860 --> 00:33:58.140]   and I wanna split these items
[00:33:58.140 --> 00:34:00.860]   into training and validation set,
[00:34:00.860 --> 00:34:04.260]   then you can just pass in random splitter.
[00:34:04.260 --> 00:34:08.220]   So you can see how the fourth, third, the zeroth,
[00:34:08.220 --> 00:34:11.100]   and the first item ended up in the training set,
[00:34:11.100 --> 00:34:14.260]   and the second item ended up in the validation set.
[00:34:14.260 --> 00:34:16.860]   So that's just the first part of this,
[00:34:16.860 --> 00:34:18.820]   which is this,
[00:34:18.820 --> 00:34:21.940]   it's just the indexes for the items in your training set,
[00:34:21.940 --> 00:34:23.980]   and then this is just the index of the items
[00:34:23.980 --> 00:34:25.580]   in your validation set.
[00:34:25.580 --> 00:34:28.540]   But if I run this again,
[00:34:28.540 --> 00:34:31.060]   then you can see how it's different,
[00:34:31.060 --> 00:34:34.180]   like the last time item two was in validation,
[00:34:34.180 --> 00:34:36.620]   but this time, these are the items in training.
[00:34:36.620 --> 00:34:37.700]   And then if I run this again,
[00:34:37.700 --> 00:34:40.300]   then you can see how it keeps on changing.
[00:34:40.300 --> 00:34:41.820]   So say if you,
[00:34:41.820 --> 00:34:44.780]   the problem with that is if you share this notebook
[00:34:44.780 --> 00:34:46.460]   with somebody else,
[00:34:46.460 --> 00:34:49.660]   then what will happen is when they're trying to split
[00:34:49.660 --> 00:34:52.580]   the items into a training and a validation set,
[00:34:52.580 --> 00:34:55.660]   what will happen is their validation set
[00:34:55.660 --> 00:34:58.460]   will be very different from your validation set.
[00:34:58.460 --> 00:35:01.140]   And a way to avoid that
[00:35:01.140 --> 00:35:03.660]   is to pass in something called a seed.
[00:35:03.660 --> 00:35:06.420]   So if I pass in a seed, every time I run this,
[00:35:06.420 --> 00:35:11.420]   it's going to select the same item as a validation set.
[00:35:11.420 --> 00:35:13.500]   It's basically a seed,
[00:35:13.500 --> 00:35:17.340]   it's just a way of like, it's not random anymore.
[00:35:17.340 --> 00:35:18.260]   I mean, it's,
[00:35:18.260 --> 00:35:21.820]   okay, I would be digressing if I explained
[00:35:21.820 --> 00:35:23.020]   what exactly a seed does,
[00:35:23.020 --> 00:35:24.460]   but for now, just understand,
[00:35:24.460 --> 00:35:27.000]   every time you have a seed,
[00:35:27.000 --> 00:35:34.060]   so if you have your five items as one, two, three, four,
[00:35:34.060 --> 00:35:36.880]   five, if you don't have a seed,
[00:35:36.880 --> 00:35:39.380]   then your validation item could be two,
[00:35:39.380 --> 00:35:41.940]   it could be four, it could be five, or it could be any.
[00:35:41.940 --> 00:35:43.780]   But as long as you pass in a seed,
[00:35:43.780 --> 00:35:45.100]   it's only going to select,
[00:35:45.100 --> 00:35:48.260]   it's going to split the data always the same time,
[00:35:48.260 --> 00:35:51.060]   so you end up with the same item in your validation set.
[00:35:51.060 --> 00:35:54.700]   So that's the next thing.
[00:35:54.700 --> 00:35:58.500]   So that's what this random splitter does.
[00:35:58.500 --> 00:36:03.220]   Then the next thing you have in your data blocks
[00:36:03.220 --> 00:36:05.620]   is your getY as a parent label.
[00:36:05.620 --> 00:36:07.180]   So what is a parent label?
[00:36:07.180 --> 00:36:09.620]   So these are things that I want you to,
[00:36:09.620 --> 00:36:13.220]   so exactly how I'm showing you right now,
[00:36:13.220 --> 00:36:16.380]   this is exactly how I want you to go back
[00:36:16.380 --> 00:36:20.200]   and I want you to experiment with these notebooks.
[00:36:20.200 --> 00:36:22.100]   So next thing you want to do is you want to check,
[00:36:22.100 --> 00:36:23.420]   okay, what's a parent label?
[00:36:23.420 --> 00:36:26.220]   Let me check the doc of the parent label.
[00:36:26.220 --> 00:36:27.580]   It just returns,
[00:36:27.580 --> 00:36:29.860]   it labels the item with the parent folder name.
[00:36:29.860 --> 00:36:31.540]   Okay, so if my,
[00:36:31.540 --> 00:36:36.960]   so my item, sorry, my zeroth item is a path.
[00:36:38.060 --> 00:36:40.580]   If I pass in that,
[00:36:40.580 --> 00:36:44.700]   so then it labels it as the parent folder.
[00:36:44.700 --> 00:36:46.400]   So if you can see, so if you understand this,
[00:36:46.400 --> 00:36:48.560]   I think this is crucial to understand.
[00:36:48.560 --> 00:36:58.660]   So I had my, so this is,
[00:36:58.660 --> 00:37:00.820]   I'm just trying to show you
[00:37:00.820 --> 00:37:03.960]   what's going on behind the scenes in Fast.ai.
[00:37:03.960 --> 00:37:05.360]   So if you have your five items,
[00:37:05.360 --> 00:37:07.660]   which are all paths like bears, grizzly,
[00:37:07.660 --> 00:37:11.940]   and then you have the image name,
[00:37:11.940 --> 00:37:14.760]   and then, so let me randomize it actually.
[00:37:14.760 --> 00:37:17.460]   It's fine.
[00:37:17.460 --> 00:37:20.860]   Then what this parent label is doing,
[00:37:20.860 --> 00:37:23.960]   it's 'cause this file,
[00:37:23.960 --> 00:37:28.960]   00090.jpg, it's in the folder grizzly.
[00:37:28.960 --> 00:37:31.180]   And this file is again in the folder grizzly.
[00:37:31.180 --> 00:37:32.500]   So what this parent label is doing
[00:37:32.500 --> 00:37:34.740]   is just finding the parent folder,
[00:37:34.740 --> 00:37:36.560]   and then it's returning that.
[00:37:36.560 --> 00:37:39.860]   So all of these images are in the folder grizzly.
[00:37:39.860 --> 00:37:42.320]   But if they were in a black bear,
[00:37:42.320 --> 00:37:45.060]   or they were in basically any other folder,
[00:37:45.060 --> 00:37:47.300]   then it would return that label.
[00:37:47.300 --> 00:37:48.540]   So let me show you again.
[00:37:48.540 --> 00:37:50.620]   (typing)
[00:37:50.620 --> 00:38:08.700]   Interesting.
[00:38:08.700 --> 00:38:11.160]   I'm trying to find np, one second please.
[00:38:11.160 --> 00:38:13.240]   (typing)
[00:38:13.240 --> 00:38:35.960]   Okay, that's more like it.
[00:38:35.960 --> 00:38:38.720]   So all I did by using this function
[00:38:38.720 --> 00:38:41.520]   and np.random.permutation,
[00:38:41.520 --> 00:38:46.520]   if I have, so if I have a list of five items like this,
[00:38:46.520 --> 00:38:52.480]   then what this np.random.permutation does
[00:38:52.480 --> 00:38:53.760]   is it just shuffles it.
[00:38:53.760 --> 00:38:56.240]   It just shuffles basically that.
[00:38:56.240 --> 00:38:58.160]   So I just shuffled my list of paths,
[00:38:58.160 --> 00:39:01.160]   and I just selected the top five paths in this line of code.
[00:39:01.160 --> 00:39:04.360]   So right now, my first item is a teddy bear.
[00:39:04.360 --> 00:39:06.520]   My second item is in a teddy.
[00:39:06.520 --> 00:39:08.680]   My third item is a black bear.
[00:39:08.680 --> 00:39:10.840]   So if I go and do this again.
[00:39:10.840 --> 00:39:28.400]   I see.
[00:39:28.400 --> 00:39:30.480]   (typing)
[00:39:30.480 --> 00:39:48.920]   Ah, it's 'cause it's an np array.
[00:39:48.920 --> 00:39:49.760]   Nevermind for now.
[00:39:49.760 --> 00:39:51.880]   All I'm trying to do is I'm just trying to show you,
[00:39:51.880 --> 00:39:55.960]   if I parent label,
[00:39:58.280 --> 00:39:59.120]   map.
[00:39:59.120 --> 00:40:07.920]   Yeah, there we go.
[00:40:07.920 --> 00:40:10.080]   So all I'm trying to show you is basically,
[00:40:10.080 --> 00:40:13.800]   all I did was I had all my file names,
[00:40:13.800 --> 00:40:17.040]   and I just sort of, I just shuffled the file names,
[00:40:17.040 --> 00:40:18.960]   and I selected the top five.
[00:40:18.960 --> 00:40:22.840]   Then the next thing I did was I just found the parent label
[00:40:22.840 --> 00:40:23.920]   for each of these.
[00:40:23.920 --> 00:40:26.400]   So this is what FastCI is doing internally
[00:40:26.400 --> 00:40:29.080]   is that for this file name, it's saying,
[00:40:29.080 --> 00:40:30.840]   okay, this is a grizzly bear.
[00:40:30.840 --> 00:40:33.440]   This is how it's, the label for this path
[00:40:33.440 --> 00:40:35.040]   is going to be grizzly.
[00:40:35.040 --> 00:40:37.360]   The label for this path is going to be teddy,
[00:40:37.360 --> 00:40:40.440]   and the label for the last path is going to be black.
[00:40:40.440 --> 00:40:42.440]   So this is what I wanted to show you.
[00:40:42.440 --> 00:40:44.160]   So see how I told you when,
[00:40:44.160 --> 00:40:47.520]   when you have a path like this,
[00:40:47.520 --> 00:40:49.400]   so you have a path like this,
[00:40:49.400 --> 00:40:51.720]   then there's a way to actually convert this path
[00:40:51.720 --> 00:40:53.640]   into an image and a label.
[00:40:53.640 --> 00:40:56.120]   So we're converting this path to a label
[00:40:56.120 --> 00:41:00.760]   by using something which is called a parent label function.
[00:41:00.760 --> 00:41:03.280]   This parent label just returns like a grizzly,
[00:41:03.280 --> 00:41:07.240]   black, or teddy category.
[00:41:07.240 --> 00:41:10.200]   And then if you want to convert this path into an image,
[00:41:10.200 --> 00:41:13.440]   you just open the image using something called a PIL,
[00:41:13.440 --> 00:41:14.720]   but that's okay.
[00:41:14.720 --> 00:41:19.400]   So that's the basic idea of what exactly is happening
[00:41:19.400 --> 00:41:22.040]   in all of these lines of code.
[00:41:22.040 --> 00:41:24.480]   The last thing you have is you have something called
[00:41:24.480 --> 00:41:25.760]   an item transforms,
[00:41:25.760 --> 00:41:28.680]   which is just something that does a resize.
[00:41:28.680 --> 00:41:30.720]   So right now, this is something we've touched
[00:41:30.720 --> 00:41:32.000]   based on before as well.
[00:41:32.000 --> 00:41:33.720]   So you have your five, or I don't know,
[00:41:33.720 --> 00:41:35.240]   you have your 250 paths,
[00:41:35.240 --> 00:41:37.320]   but let's say you have just the five paths
[00:41:37.320 --> 00:41:38.760]   of images right now.
[00:41:38.760 --> 00:41:41.640]   Now, each image is going to be a different size.
[00:41:41.640 --> 00:41:46.640]   So this image could be something like a 1080 by 1280,
[00:41:46.640 --> 00:41:50.320]   and this image could be a 128 by 128.
[00:41:50.320 --> 00:41:52.120]   That's not gonna work.
[00:41:52.120 --> 00:41:55.180]   So if you want to convert these images into a batch,
[00:41:55.180 --> 00:41:57.160]   we want them to be the same size.
[00:41:57.160 --> 00:42:00.960]   So that's what this resize 128 will do.
[00:42:00.960 --> 00:42:03.400]   It will just make sure that each of these
[00:42:03.400 --> 00:42:08.400]   are 128 by 128 size, each of the images.
[00:42:08.400 --> 00:42:12.080]   And then finally, when you do something like this,
[00:42:12.080 --> 00:42:16.960]   you say, so when we did, the beers was just a data block.
[00:42:16.960 --> 00:42:18.920]   When we call this line of code,
[00:42:18.920 --> 00:42:23.360]   which is beers.dataloaders, and we pass in a path,
[00:42:23.360 --> 00:42:25.880]   it converts these into these data loader objects.
[00:42:25.880 --> 00:42:29.680]   So as I showed you, what we want to be doing is
[00:42:29.680 --> 00:42:32.400]   we want to be able to convert these list of items
[00:42:32.400 --> 00:42:34.300]   into something called a data loader
[00:42:34.300 --> 00:42:37.460]   that then feeds the batches to the GPU.
[00:42:37.460 --> 00:42:43.000]   So this is what this line of code is doing over here,
[00:42:43.000 --> 00:42:44.480]   the beers data loader.
[00:42:46.900 --> 00:42:50.880]   It's converting basically your list of items
[00:42:50.880 --> 00:42:54.040]   into your data loader objects, your train data loader
[00:42:54.040 --> 00:42:55.920]   and your validation data loader.
[00:42:55.920 --> 00:42:58.440]   So you can actually see the batch.
[00:42:58.440 --> 00:43:00.100]   So if you have a look at the batch,
[00:43:00.100 --> 00:43:02.560]   if I'm having a look at the valid data loader,
[00:43:02.560 --> 00:43:04.320]   then you can see how there's like four images.
[00:43:04.320 --> 00:43:09.320]   So your path, so you had your path P1, P2, P3, or whatever.
[00:43:09.320 --> 00:43:13.040]   Each of those paths have been converted first into an image.
[00:43:13.040 --> 00:43:16.280]   And then that path has also been converted into a label.
[00:43:16.280 --> 00:43:19.100]   So that's exactly sort of what's going on
[00:43:19.100 --> 00:43:21.420]   underneath in Fast.ai.
[00:43:21.420 --> 00:43:23.460]   So this, as already mentioned,
[00:43:23.460 --> 00:43:27.240]   this label is coming from this parent label function.
[00:43:27.240 --> 00:43:31.580]   Before going down into showing you
[00:43:31.580 --> 00:43:34.340]   the various resize methods of what's exactly going on
[00:43:34.340 --> 00:43:36.500]   in this part of the book,
[00:43:36.500 --> 00:43:38.620]   let me have a look at the questions.
[00:43:38.620 --> 00:43:40.780]   So we're gonna take eight minutes break.
[00:43:45.580 --> 00:43:49.500]   So any questions so far about what a data block is,
[00:43:49.500 --> 00:43:51.140]   what's a parent label doing,
[00:43:51.140 --> 00:43:54.280]   what exactly is happening in all of these lines of code?
[00:43:54.280 --> 00:44:07.700]   Yeah, Kevin, one nice thing about the search images,
[00:44:07.700 --> 00:44:09.180]   Dr. Go is that you don't need a key.
[00:44:09.180 --> 00:44:10.780]   Exactly, so it's free to use
[00:44:10.780 --> 00:44:14.620]   and you pretty much can then just go in
[00:44:14.620 --> 00:44:17.100]   and you can just call this function
[00:44:17.100 --> 00:44:18.460]   without having an SEO key.
[00:44:18.460 --> 00:44:23.140]   There's also an package to download images from Google,
[00:44:23.140 --> 00:44:24.460]   which is similar to Dr. Go.
[00:44:24.460 --> 00:44:25.620]   Okay, I didn't know about this.
[00:44:25.620 --> 00:44:28.580]   So yeah, feel free to use any of the packages.
[00:44:28.580 --> 00:44:33.580]   There's no expectation to use either one.
[00:44:33.580 --> 00:44:37.860]   TIL about TKDM, super neat utility.
[00:44:37.860 --> 00:44:39.260]   Thanks for showing us.
[00:44:39.260 --> 00:44:40.100]   No problem.
[00:44:40.100 --> 00:44:42.520]   If using code, this is a great extension.
[00:44:43.480 --> 00:44:44.320]   Yeah.
[00:44:44.320 --> 00:44:51.260]   Can you explain what getAtra class exactly does
[00:44:51.260 --> 00:44:55.000]   and how is it advantageous to implement data loaders
[00:44:55.000 --> 00:44:57.560]   with getAtra at props rather than just applying
[00:44:57.560 --> 00:44:59.780]   train test loaders in the constructor?
[00:44:59.780 --> 00:45:03.080]   Yes, I think it's not very relevant
[00:45:03.080 --> 00:45:07.640]   for this particular time.
[00:45:07.640 --> 00:45:10.120]   I mean, we're just sort of, as a group,
[00:45:10.120 --> 00:45:12.840]   we're just learning on what data loaders are.
[00:45:12.840 --> 00:45:15.600]   We don't really, we haven't really seen what getAtra is.
[00:45:15.600 --> 00:45:17.320]   We haven't really seen what at props is.
[00:45:17.320 --> 00:45:19.880]   So I think this question is a bit far ahead
[00:45:19.880 --> 00:45:21.160]   than where we are right now.
[00:45:21.160 --> 00:45:23.760]   So we will come back to this question later though.
[00:45:23.760 --> 00:45:26.360]   Is it possible to add a data loader
[00:45:26.360 --> 00:45:27.560]   for testing data as well?
[00:45:27.560 --> 00:45:30.440]   Well, you pretty much, when you're saying in fast AI,
[00:45:30.440 --> 00:45:32.480]   when you're passing in data loaders,
[00:45:32.480 --> 00:45:34.360]   so see how you're passing data loader,
[00:45:34.360 --> 00:45:36.960]   you can pass in three data loaders.
[00:45:36.960 --> 00:45:39.180]   So then the first one becomes your training.
[00:45:39.180 --> 00:45:40.640]   The second one becomes validation
[00:45:40.640 --> 00:45:42.840]   and the third one becomes your test.
[00:45:42.840 --> 00:45:45.880]   There's also an option to say data loaders.test,
[00:45:45.880 --> 00:45:47.280]   which will then also create a data.
[00:45:47.280 --> 00:45:48.920]   But this is again, this is again,
[00:45:48.920 --> 00:45:51.620]   something that's a bit ahead of where we are right now.
[00:45:51.620 --> 00:45:57.800]   What if the random splitter splitting the data
[00:45:57.800 --> 00:46:00.080]   does not include images from one category?
[00:46:00.080 --> 00:46:02.600]   Okay, that's a really, really good question.
[00:46:02.600 --> 00:46:06.240]   So what if, so what if I have,
[00:46:06.240 --> 00:46:09.840]   so right now in my five images,
[00:46:09.840 --> 00:46:12.920]   five items that I had, I had all the three categories.
[00:46:12.920 --> 00:46:15.160]   I had grizzly, teddy, black and black.
[00:46:15.160 --> 00:46:17.120]   But what if there was only,
[00:46:17.120 --> 00:46:19.080]   what if I selected only four items?
[00:46:19.080 --> 00:46:24.800]   And then I check my parent labels.
[00:46:24.800 --> 00:46:29.280]   In that case, I do not have a black category here.
[00:46:29.280 --> 00:46:33.120]   In that case, then what you wanna do is instead of,
[00:46:33.120 --> 00:46:35.420]   and this usually happens when one of the classes
[00:46:35.420 --> 00:46:38.320]   has very few labels compared to the other classes,
[00:46:38.320 --> 00:46:41.360]   and sometimes that class doesn't even make it
[00:46:41.360 --> 00:46:42.920]   to the validation set.
[00:46:42.920 --> 00:46:44.280]   In that case, then what you wanna do
[00:46:44.280 --> 00:46:48.360]   is there's something called like a KNN, basically,
[00:46:48.360 --> 00:46:50.600]   oh, sorry, not a KNN, a stratified K-fold
[00:46:50.600 --> 00:46:52.200]   is what you wanna have a look at.
[00:46:52.200 --> 00:46:55.040]   So I'll just, I'm sure that's been answered though.
[00:46:55.040 --> 00:47:03.200]   This video by Vishnu is a great resource to understand.
[00:47:03.200 --> 00:47:04.560]   Yes, I've seen this video.
[00:47:04.560 --> 00:47:06.320]   Thank you, Harish, for sharing this.
[00:47:06.320 --> 00:47:07.160]   It's really a good video.
[00:47:07.160 --> 00:47:10.240]   So let me post this on ClassDI,
[00:47:10.240 --> 00:47:12.240]   oh, sorry, on the Zoom chat.
[00:47:12.240 --> 00:47:18.920]   Difference between data loader and data block
[00:47:18.920 --> 00:47:19.760]   is not clear to me.
[00:47:19.760 --> 00:47:22.280]   Okay, I will explain that right now.
[00:47:22.280 --> 00:47:24.840]   Can you explain what a splitter is used again?
[00:47:24.840 --> 00:47:29.160]   Okay, I will explain splitters.
[00:47:29.160 --> 00:47:31.440]   If we have a train and validation set,
[00:47:31.440 --> 00:47:33.320]   how can we address it in data block?
[00:47:33.320 --> 00:47:36.040]   There's something called like a grandparent splitter,
[00:47:36.040 --> 00:47:38.400]   or there's basically ways to do it.
[00:47:38.400 --> 00:47:40.320]   Like if you have your folder structure,
[00:47:40.320 --> 00:47:44.040]   this is a very easy thing to solve this question,
[00:47:44.040 --> 00:47:47.640]   but we will look at an instance of this very, very soon.
[00:47:47.640 --> 00:47:48.960]   So I won't touch on this right now,
[00:47:48.960 --> 00:47:52.240]   but typically you wanna look at something called
[00:47:52.240 --> 00:47:53.720]   a grandparent splitter.
[00:47:53.720 --> 00:48:02.200]   Okay, so then the last two questions,
[00:48:02.200 --> 00:48:04.000]   what is the difference between a data block
[00:48:04.000 --> 00:48:06.440]   and a data loader?
[00:48:06.440 --> 00:48:07.440]   Let's touch on that.
[00:48:07.440 --> 00:48:19.960]   So this is what the data block is doing basically.
[00:48:19.960 --> 00:48:22.240]   All you're saying to the data block is,
[00:48:22.240 --> 00:48:26.880]   all you're saying to the data block
[00:48:26.880 --> 00:48:28.360]   is you're passing in some things,
[00:48:28.360 --> 00:48:30.440]   you're passing in the two blocks,
[00:48:30.440 --> 00:48:32.640]   you're passing in a way to get items,
[00:48:32.640 --> 00:48:35.120]   you're passing in what splitter you're gonna use,
[00:48:35.120 --> 00:48:37.760]   you're passing in on how you're gonna get your categories,
[00:48:37.760 --> 00:48:40.160]   and then you're passing in what your item transforms
[00:48:40.160 --> 00:48:41.320]   are gonna be.
[00:48:41.320 --> 00:48:44.440]   Right now, you're not actually doing any of the computation.
[00:48:44.440 --> 00:48:47.480]   Okay, it's just, think of it this way.
[00:48:47.480 --> 00:48:49.600]   A data block is just a map.
[00:48:49.600 --> 00:48:54.280]   So if I wanna go from A to B,
[00:48:54.280 --> 00:48:57.720]   where A is my list of items,
[00:48:57.720 --> 00:49:01.200]   so this is my list of items,
[00:49:01.200 --> 00:49:03.240]   and I wanna create my data loader,
[00:49:03.240 --> 00:49:08.840]   then the data block, this thing, is just a map.
[00:49:08.840 --> 00:49:11.040]   So it's just a map.
[00:49:11.040 --> 00:49:12.560]   So it's a map that's showing you
[00:49:12.560 --> 00:49:14.440]   how you can go from here to here.
[00:49:14.440 --> 00:49:16.800]   So you haven't really created your data loader.
[00:49:16.800 --> 00:49:19.360]   A data block is just telling you that,
[00:49:19.360 --> 00:49:21.480]   okay, for this kind of dataset,
[00:49:21.480 --> 00:49:24.960]   for this kind of beers classifier,
[00:49:24.960 --> 00:49:28.000]   these are the kind of things that you would need
[00:49:28.000 --> 00:49:30.320]   to be able to create your data loader.
[00:49:30.320 --> 00:49:33.640]   That's exactly, so it's just a map, it's just a template.
[00:49:33.640 --> 00:49:38.920]   But the actual creation of the data loader happens here.
[00:49:38.920 --> 00:49:41.680]   So when you say, so this beers is a data block,
[00:49:41.680 --> 00:49:42.640]   remember that.
[00:49:42.640 --> 00:49:45.080]   So this beers is a D block.
[00:49:45.080 --> 00:49:49.120]   You're creating your data loaders basically
[00:49:49.120 --> 00:49:51.800]   by saying data block dot data loaders,
[00:49:51.800 --> 00:49:53.320]   and then you're passing the path.
[00:49:53.320 --> 00:49:56.400]   That's when these data loaders sort of get returned.
[00:49:56.400 --> 00:49:58.440]   So this is something that you should remember
[00:49:58.440 --> 00:50:01.880]   is a data block is just a map or a template
[00:50:01.880 --> 00:50:03.880]   from point A to point B,
[00:50:03.880 --> 00:50:05.880]   point A being your list of items
[00:50:05.880 --> 00:50:08.600]   and point B being your data loaders.
[00:50:08.600 --> 00:50:11.920]   Then when you call data loaders on it,
[00:50:11.920 --> 00:50:14.040]   that's when the actual thing gets called.
[00:50:14.040 --> 00:50:18.640]   Cool.
[00:50:18.640 --> 00:50:20.160]   That's time.
[00:50:20.160 --> 00:50:21.000]   Let's move on.
[00:50:21.000 --> 00:50:23.280]   I think that was most of the questions.
[00:50:23.280 --> 00:50:24.960]   We'll cover the other ones after.
[00:50:24.960 --> 00:50:27.800]   Oh, sorry, I missed this one.
[00:50:27.800 --> 00:50:29.840]   What is splitter used for again?
[00:50:29.840 --> 00:50:33.680]   So Kareem, if you remember what we had to do last time
[00:50:33.680 --> 00:50:35.600]   is we wanna be able to split our data
[00:50:35.600 --> 00:50:39.040]   into a training and validation set.
[00:50:39.040 --> 00:50:43.280]   So in a model, you wanna train your model on a training data
[00:50:43.280 --> 00:50:45.560]   and then you wanna test the performance of that model
[00:50:45.560 --> 00:50:47.520]   on a validation data set.
[00:50:47.520 --> 00:50:49.440]   So what this splitter is going to do
[00:50:49.440 --> 00:50:53.360]   is it's a way to split your list of items
[00:50:53.360 --> 00:50:55.160]   into training and validation.
[00:50:55.160 --> 00:50:59.080]   So what that means is, one last time,
[00:50:59.080 --> 00:51:00.280]   what that means is,
[00:51:00.280 --> 00:51:13.040]   if you have like a list of items, say 100,
[00:51:13.040 --> 00:51:15.400]   right now the data block doesn't know
[00:51:15.400 --> 00:51:18.880]   on which of these should go in the training set
[00:51:18.880 --> 00:51:21.680]   and which of these should go in the validation set.
[00:51:21.680 --> 00:51:26.680]   What that, the splitter is what will tell you.
[00:51:26.680 --> 00:51:30.200]   The splitter will tell you, okay, out of these 100 items,
[00:51:30.200 --> 00:51:34.440]   given that you wanna have 20% of the items
[00:51:34.440 --> 00:51:36.880]   in your validation set, out of these 100 items,
[00:51:36.880 --> 00:51:39.080]   this item, this item, this item, this item,
[00:51:39.080 --> 00:51:41.800]   and then whatever the 20 items are,
[00:51:41.800 --> 00:51:46.800]   these randomly selected 20 items are going here
[00:51:46.800 --> 00:51:49.960]   and then the 80 items are going here.
[00:51:49.960 --> 00:51:52.520]   That's if you have a random splitter.
[00:51:52.520 --> 00:51:54.880]   But if you have any other type of splitter,
[00:51:54.880 --> 00:51:57.840]   there's like different types of splitters in fast.ai,
[00:51:57.840 --> 00:51:59.360]   but right now all we need to worry about
[00:51:59.360 --> 00:52:01.120]   is this random splitter.
[00:52:01.120 --> 00:52:03.240]   Then all it's doing is it's just splitting your data
[00:52:03.240 --> 00:52:05.960]   into training and validation sets.
[00:52:05.960 --> 00:52:08.120]   So that's exactly what you need to know.
[00:52:08.120 --> 00:52:09.160]   I hope that helps.
[00:52:09.160 --> 00:52:12.480]   Okay.
[00:52:12.480 --> 00:52:19.040]   So right now, what we had a look at
[00:52:19.040 --> 00:52:22.800]   was this resize 128 being parsed.
[00:52:22.800 --> 00:52:25.000]   But if I go into...
[00:52:25.000 --> 00:52:27.760]   (mouse clicking)
[00:52:27.760 --> 00:52:30.520]   (mouse clicking)
[00:52:30.520 --> 00:52:33.280]   (mouse clicking)
[00:52:33.280 --> 00:52:36.040]   (mouse clicking)
[00:52:36.040 --> 00:53:01.960]   I see.
[00:53:01.960 --> 00:53:04.720]   (mouse clicking)
[00:53:04.720 --> 00:53:20.480]   So my first, basically my first...
[00:53:20.480 --> 00:53:25.000]   So this is, I showed you how we wanna be able
[00:53:25.000 --> 00:53:28.720]   to convert this part into then an image
[00:53:28.720 --> 00:53:32.200]   that you wanna use to train your model, right?
[00:53:32.200 --> 00:53:37.200]   So this is a library called PIL image in Python.
[00:53:37.200 --> 00:53:40.360]   That can then open these images.
[00:53:40.360 --> 00:53:43.480]   So if my image looks something like this,
[00:53:43.480 --> 00:53:46.800]   it's a really big size, right?
[00:53:46.800 --> 00:53:50.560]   So if that's my image,
[00:53:50.560 --> 00:53:55.560]   then the size of this image is 1920 by 128.
[00:53:55.680 --> 00:53:59.600]   But remember, what we want to do is for each of these items
[00:53:59.600 --> 00:54:01.000]   or for each of these images,
[00:54:01.000 --> 00:54:04.000]   we wanna resize them to a particular size.
[00:54:04.000 --> 00:54:06.440]   So there's a function called resize.
[00:54:06.440 --> 00:54:11.840]   And I can just say resize to size 128
[00:54:11.840 --> 00:54:13.520]   and I can pass in the image.
[00:54:13.520 --> 00:54:16.280]   (mouse clicking)
[00:54:16.280 --> 00:54:29.480]   This seems to be a small problem here.
[00:54:29.480 --> 00:54:31.480]   This should work.
[00:54:31.480 --> 00:54:32.320]   That's okay.
[00:54:32.320 --> 00:54:36.520]   I will skip this point for now and show you exactly
[00:54:36.520 --> 00:54:39.480]   through the examples that I have already.
[00:54:41.240 --> 00:54:44.280]   So when you have this resize 128,
[00:54:44.280 --> 00:54:47.480]   what this is doing is it's taking all of those sort
[00:54:47.480 --> 00:54:51.160]   of grizzly and teddy bear images that are of really big size
[00:54:51.160 --> 00:54:53.360]   as I've shown you here.
[00:54:53.360 --> 00:54:56.520]   So if I go and have a look at this image
[00:54:56.520 --> 00:55:00.680]   and each different part would have a different image size.
[00:55:00.680 --> 00:55:02.520]   So this is a really big image.
[00:55:02.520 --> 00:55:05.440]   And what this resize is trying to do is it's trying
[00:55:05.440 --> 00:55:09.520]   to resize it to a particular size of 128 by 128.
[00:55:09.520 --> 00:55:12.400]   There's different methods on how you can resize.
[00:55:12.400 --> 00:55:15.040]   So look, imagine this, right?
[00:55:15.040 --> 00:55:18.360]   If your image is that big,
[00:55:18.360 --> 00:55:21.800]   if this is my teddy bear image,
[00:55:21.800 --> 00:55:26.080]   1280 by 1920,
[00:55:26.080 --> 00:55:29.000]   and I wanna be able to resize it to a square.
[00:55:29.000 --> 00:55:30.760]   So this is not a square.
[00:55:30.760 --> 00:55:35.760]   One of the sides is much bigger
[00:55:37.040 --> 00:55:41.320]   and I wanna resize it to a square of 128 by 128.
[00:55:41.320 --> 00:55:44.200]   Then one way is I can squish it, right?
[00:55:44.200 --> 00:55:47.720]   I can squish it, which then looks like this.
[00:55:47.720 --> 00:55:50.400]   So you can see how in this case
[00:55:50.400 --> 00:55:52.760]   that grizzly bear has been stretched.
[00:55:52.760 --> 00:55:56.880]   So you can see from this image that this looks a bit weird.
[00:55:56.880 --> 00:56:00.400]   Like, I mean, there's something that we're missing out on.
[00:56:00.400 --> 00:56:03.600]   Like the objects are now warped
[00:56:03.600 --> 00:56:05.360]   or the objects now look different
[00:56:05.360 --> 00:56:06.840]   than what they actually are.
[00:56:06.840 --> 00:56:12.000]   So that's the first way of resizing.
[00:56:12.000 --> 00:56:14.840]   The second one is you can pad an image.
[00:56:14.840 --> 00:56:19.720]   So say if you wanna resize this to 128 by 128,
[00:56:19.720 --> 00:56:24.720]   then what you can do is you can pad your image
[00:56:24.720 --> 00:56:27.600]   on these sides.
[00:56:27.600 --> 00:56:31.240]   So this is also 1920, right?
[00:56:31.240 --> 00:56:36.240]   'Cause you can add a bunch of just black border on this side.
[00:56:36.240 --> 00:56:39.320]   So then this becomes a square of 1920 by 1920,
[00:56:39.320 --> 00:56:42.320]   and then that can be resized to 128.
[00:56:42.320 --> 00:56:46.240]   But you can see how now adding these black borders.
[00:56:46.240 --> 00:56:49.800]   So when you're gonna pass this image to your model,
[00:56:49.800 --> 00:56:52.200]   what's gonna happen is that model is gonna think
[00:56:52.200 --> 00:56:55.640]   of these black borders as information.
[00:56:55.640 --> 00:56:57.480]   And if it's gonna think of these black borders
[00:56:57.480 --> 00:57:00.560]   as information, then it's gonna lose accuracy
[00:57:00.560 --> 00:57:03.520]   'cause you're actually not passing in your image,
[00:57:03.520 --> 00:57:05.000]   but there's actually all these borders
[00:57:05.000 --> 00:57:06.360]   that are being passed.
[00:57:06.360 --> 00:57:11.920]   So those are the two methods that are there.
[00:57:11.920 --> 00:57:15.040]   But again, these are both methods aren't the best.
[00:57:15.040 --> 00:57:17.680]   These are good to create model baselines,
[00:57:17.680 --> 00:57:19.480]   but they're not the best because why?
[00:57:19.480 --> 00:57:21.680]   If we squish or stretch the images,
[00:57:21.680 --> 00:57:23.760]   they end up as in unrealistic shapes.
[00:57:23.760 --> 00:57:25.600]   For example, we saw this bear.
[00:57:25.600 --> 00:57:26.840]   That's an unrealistic shape.
[00:57:26.840 --> 00:57:28.680]   That's not how a bear looks like.
[00:57:28.680 --> 00:57:30.160]   Or it can be like even this one,
[00:57:30.160 --> 00:57:33.000]   it looks a bit stretched horizontally.
[00:57:33.000 --> 00:57:35.960]   So that's an unrealistic shape.
[00:57:35.960 --> 00:57:37.320]   Or if we add borders,
[00:57:37.320 --> 00:57:39.600]   then we're adding this extra information.
[00:57:39.600 --> 00:57:41.600]   So both of these are suboptimal.
[00:57:41.600 --> 00:57:43.400]   They're not the best way to do this.
[00:57:43.400 --> 00:57:47.960]   The next thing you could have done, right?
[00:57:47.960 --> 00:57:49.920]   The next possible thing that could have been done
[00:57:49.920 --> 00:57:52.920]   is if I have my image like this,
[00:57:54.760 --> 00:57:58.920]   as already said, if this is 1280, this is 1920,
[00:57:58.920 --> 00:58:02.480]   then what I could have done is I could have found
[00:58:02.480 --> 00:58:05.240]   a square inside this image like this.
[00:58:05.240 --> 00:58:08.880]   And we get rid of all the other image.
[00:58:08.880 --> 00:58:12.240]   This is called as cropping, right?
[00:58:12.240 --> 00:58:13.080]   Image cropping.
[00:58:13.080 --> 00:58:14.760]   We do this anyway in our phones,
[00:58:14.760 --> 00:58:16.560]   or that's just image cropping.
[00:58:16.560 --> 00:58:20.880]   But the problem with this is you're actually missing out
[00:58:20.880 --> 00:58:23.080]   on a lot of other data.
[00:58:23.080 --> 00:58:26.320]   So what if the bear was like this,
[00:58:26.320 --> 00:58:28.000]   but you only have the lower body
[00:58:28.000 --> 00:58:30.000]   and not the upper body of the bear?
[00:58:30.000 --> 00:58:34.360]   But this thing is called as a random crop.
[00:58:34.360 --> 00:58:37.160]   So it's just a way of cropping.
[00:58:37.160 --> 00:58:40.440]   But in practice, what we actually do in deep learning
[00:58:40.440 --> 00:58:42.400]   is when you're training your models,
[00:58:42.400 --> 00:58:44.320]   what we do is we call something,
[00:58:44.320 --> 00:58:47.560]   we do something which is called a random resized crop.
[00:58:47.560 --> 00:58:52.560]   So say you wanna train your model for 10 epochs, right?
[00:58:52.600 --> 00:58:55.560]   In the first epoch, you find this crop,
[00:58:55.560 --> 00:58:57.240]   which is the size.
[00:58:57.240 --> 00:59:01.120]   So even if your bear looks like this,
[00:59:01.120 --> 00:59:05.000]   in the first pass, the model gets to see
[00:59:05.000 --> 00:59:06.240]   the head and the body.
[00:59:06.240 --> 00:59:09.120]   When you're doing the second pass,
[00:59:09.120 --> 00:59:10.800]   your crop comes from here.
[00:59:10.800 --> 00:59:13.520]   So now the model already knows what a head looks like,
[00:59:13.520 --> 00:59:14.840]   and then it gets extra information
[00:59:14.840 --> 00:59:16.560]   about the feet of the bear.
[00:59:16.560 --> 00:59:18.720]   And then finally, you have, say,
[00:59:18.720 --> 00:59:21.360]   your third pass looks like this.
[00:59:21.360 --> 00:59:26.040]   In that case, now the model has this extra information
[00:59:26.040 --> 00:59:29.120]   about how the hand sort of looks like on the,
[00:59:29.120 --> 00:59:31.840]   how particular this side of the bear looks like.
[00:59:31.840 --> 00:59:32.920]   So this is something that,
[00:59:32.920 --> 00:59:36.320]   this is how a lot of the models are trained
[00:59:36.320 --> 00:59:38.920]   in deep learning in practice today,
[00:59:38.920 --> 00:59:42.120]   is that you have something called a random resized crop.
[00:59:42.120 --> 00:59:44.960]   The benefit of this approach is,
[00:59:44.960 --> 00:59:48.720]   A, your images, they don't either become
[00:59:48.720 --> 00:59:53.160]   too sort of stretched or they don't sort of become too small.
[00:59:53.160 --> 00:59:55.000]   You're not always cropping the same side,
[00:59:55.000 --> 00:59:57.960]   so you're not always losing out information.
[00:59:57.960 --> 01:00:02.680]   And then over time, as you go over and over these images
[01:00:02.680 --> 01:00:05.360]   and you do multiple data passes,
[01:00:05.360 --> 01:00:08.240]   then what you see is the model will actually see
[01:00:08.240 --> 01:00:10.960]   each part of the image every time.
[01:00:10.960 --> 01:00:13.280]   So say in 10 epochs,
[01:00:13.280 --> 01:00:15.040]   the model would have seen each part of the image.
[01:00:15.040 --> 01:00:17.880]   So it still sees the full image,
[01:00:17.880 --> 01:00:20.240]   but just in parts.
[01:00:20.240 --> 01:00:22.880]   And this is what random resized crop looks like.
[01:00:22.880 --> 01:00:25.080]   So if you have an image of a teddy bear,
[01:00:25.080 --> 01:00:28.720]   so say the first crop gets this image.
[01:00:28.720 --> 01:00:30.760]   So right now we're missing, say,
[01:00:30.760 --> 01:00:34.360]   we're missing some context on the upper side.
[01:00:34.360 --> 01:00:37.400]   But then the second random resized crop looks like this,
[01:00:37.400 --> 01:00:38.400]   the third one looks like this,
[01:00:38.400 --> 01:00:39.800]   and now you get the feet.
[01:00:39.800 --> 01:00:41.680]   And then in this one, you get the feet and the hand
[01:00:41.680 --> 01:00:44.000]   and you sort of miss the head.
[01:00:44.000 --> 01:00:47.120]   So this is like just a way or an example
[01:00:47.120 --> 01:00:49.400]   of what random resized crop looks like.
[01:00:49.400 --> 01:01:00.000]   So that was just what all these five lines of code
[01:01:00.000 --> 01:01:04.080]   basically mean in Data Loader.
[01:01:04.080 --> 01:01:06.360]   And then what there's different ways
[01:01:06.360 --> 01:01:08.640]   of sort of resizing and resized cropping.
[01:01:08.640 --> 01:01:12.880]   The next thing I wanna touch on is data augmentation.
[01:01:12.880 --> 01:01:15.560]   Okay, and this is important.
[01:01:15.560 --> 01:01:19.040]   I think this is something you would have heard everywhere
[01:01:19.040 --> 01:01:21.680]   in deep learning is data augmentation.
[01:01:21.680 --> 01:01:24.040]   So what data augmentation basically does
[01:01:24.040 --> 01:01:30.600]   is you have an image and say this image looks like this.
[01:01:30.600 --> 01:01:34.000]   Then when you're in a real world
[01:01:34.000 --> 01:01:36.560]   and you're trying to train your deep learning model,
[01:01:36.560 --> 01:01:38.960]   it's not always gonna get this same image.
[01:01:38.960 --> 01:01:42.040]   This image, when you see it in real world,
[01:01:42.040 --> 01:01:44.440]   this image could be rotated like this.
[01:01:44.440 --> 01:01:48.080]   It could be, I mean, it could be horizontal.
[01:01:48.080 --> 01:01:50.120]   It could be vertically flipped.
[01:01:50.120 --> 01:01:52.280]   Like you'll see, this is just a bad example,
[01:01:52.280 --> 01:01:56.200]   but say if it's an example of a basketball line here, right?
[01:01:56.200 --> 01:01:58.000]   Then you can have like all these different images
[01:01:58.000 --> 01:01:58.920]   or all these different ways.
[01:01:58.920 --> 01:02:00.400]   Like it depends on the camera person
[01:02:00.400 --> 01:02:03.680]   and how the camera person takes the picture.
[01:02:03.680 --> 01:02:04.640]   It could be blurry.
[01:02:04.640 --> 01:02:06.560]   It could be different contrast.
[01:02:06.560 --> 01:02:08.160]   It could be different image.
[01:02:08.160 --> 01:02:11.720]   So then this process of creating these multiple
[01:02:11.720 --> 01:02:16.480]   sort of images from the same one image
[01:02:16.480 --> 01:02:18.200]   is called a state augmentation.
[01:02:18.200 --> 01:02:21.320]   So you see, you have a teddy bear
[01:02:21.320 --> 01:02:23.720]   and the typical data augmentations that you have
[01:02:23.720 --> 01:02:26.040]   are something like rotation, flipping.
[01:02:26.040 --> 01:02:27.960]   So flipping is just, if your image is like this,
[01:02:27.960 --> 01:02:30.160]   you just flip it to your right or you flip it vertically.
[01:02:30.160 --> 01:02:31.880]   So it's reverted.
[01:02:31.880 --> 01:02:34.520]   Warping, which is just, if the image looks like this,
[01:02:34.520 --> 01:02:36.520]   then you either go like that or you go like that.
[01:02:36.520 --> 01:02:39.600]   So it's just like sort of a different angle.
[01:02:39.600 --> 01:02:42.920]   So this is a warped image of a teddy bear.
[01:02:42.920 --> 01:02:44.120]   And then you can change the brightness.
[01:02:44.120 --> 01:02:45.760]   You can change the contrast.
[01:02:45.760 --> 01:02:47.680]   So this is helpful.
[01:02:47.680 --> 01:02:51.280]   How is data augmentation helpful to deep learning models
[01:02:51.280 --> 01:02:55.000]   is, you know, we talked about overfitting last time.
[01:02:55.000 --> 01:02:59.840]   So overfitting can only happen if you see the same image
[01:02:59.840 --> 01:03:02.080]   again and again and again, multiple times.
[01:03:02.080 --> 01:03:05.760]   That's when the model can learn, okay, a teddy bear,
[01:03:05.760 --> 01:03:08.040]   a yellow teddy bear looks exactly like this.
[01:03:08.040 --> 01:03:11.920]   Like if I feed this image to the model 10 times,
[01:03:11.920 --> 01:03:14.880]   then the model is bound to overfit on this particular image
[01:03:14.880 --> 01:03:17.360]   and it won't be able to generalize better.
[01:03:17.360 --> 01:03:21.240]   But when we add data augmentation, then in the first epoch,
[01:03:21.240 --> 01:03:23.880]   the first time the model will see something like this,
[01:03:23.880 --> 01:03:27.240]   say the second time the model will see something like this,
[01:03:27.240 --> 01:03:29.680]   the third time model sees something like this.
[01:03:29.680 --> 01:03:33.400]   So every time the color, even though it's the same image,
[01:03:33.400 --> 01:03:36.400]   we can create multiple of these images.
[01:03:36.400 --> 01:03:40.520]   And this idea is called data augmentation.
[01:03:40.520 --> 01:03:46.080]   Okay, we are towards the end.
[01:03:46.080 --> 01:03:48.440]   There's not much left now.
[01:03:48.440 --> 01:03:52.200]   Now we, so this idea of data augmentation,
[01:03:52.200 --> 01:03:54.600]   that's the main covered thing.
[01:03:54.600 --> 01:03:58.080]   So we can now pass in as a batch transform
[01:03:58.080 --> 01:04:00.720]   to your data loader, basically.
[01:04:00.720 --> 01:04:01.720]   What does that mean?
[01:04:01.720 --> 01:04:04.200]   Why are we passing this as a batch loader?
[01:04:05.720 --> 01:04:09.000]   Typically, so you had your,
[01:04:09.000 --> 01:04:11.400]   say you had your list of 100 items here,
[01:04:11.400 --> 01:04:14.760]   then you create your batches of 10.
[01:04:14.760 --> 01:04:18.000]   Then you wanna do all these rotation,
[01:04:18.000 --> 01:04:22.120]   all these sort of flipping off in batches.
[01:04:22.120 --> 01:04:24.400]   It's just a way to save computation
[01:04:24.400 --> 01:04:26.720]   and it's just computationally better
[01:04:26.720 --> 01:04:28.560]   rather than doing it on each image
[01:04:28.560 --> 01:04:30.400]   and then you create your batches.
[01:04:30.400 --> 01:04:33.200]   It's just a better way of doing it on the batches first.
[01:04:35.600 --> 01:04:40.600]   Great, so then I can just create my base data loader
[01:04:40.600 --> 01:04:44.080]   passing in these augmentation transforms.
[01:04:44.080 --> 01:04:48.040]   So remember, anything that changes the original image
[01:04:48.040 --> 01:04:49.520]   is called a transform.
[01:04:49.520 --> 01:04:51.360]   So I can pass in these org transforms,
[01:04:51.360 --> 01:04:54.280]   which just says, okay, my data loader now
[01:04:54.280 --> 01:04:56.280]   has data augmentation in it.
[01:04:56.280 --> 01:04:59.160]   And then the next thing that we do is,
[01:04:59.160 --> 01:05:01.320]   this is something you've all seen before,
[01:05:01.320 --> 01:05:02.760]   is we just create a learner.
[01:05:02.760 --> 01:05:06.200]   We say, I wanna create my convolutional neural network.
[01:05:06.200 --> 01:05:08.560]   The model architecture is called ResNet-18
[01:05:08.560 --> 01:05:11.840]   and I wanna metric, my metric is error rate.
[01:05:11.840 --> 01:05:14.120]   So I wanna monitor my error rate.
[01:05:14.120 --> 01:05:16.920]   So when I fine tune my model,
[01:05:16.920 --> 01:05:18.680]   so let me show you in the notebook.
[01:05:18.680 --> 01:05:32.080]   So I'm just running all those lines of code again.
[01:05:32.080 --> 01:05:34.840]   (mouse clicking)
[01:05:34.840 --> 01:05:39.880]   Okay, this is the point where the model is training.
[01:05:39.880 --> 01:05:58.360]   So meanwhile, that's running, let's continue forward.
[01:05:58.360 --> 01:06:02.120]   So something that we have is called a confusion matrix.
[01:06:02.120 --> 01:06:06.120]   So in a way, once your model has sort of trained
[01:06:06.120 --> 01:06:10.120]   and sort of learned how these different beers look like,
[01:06:10.120 --> 01:06:12.560]   then what you wanna be able to do is,
[01:06:12.560 --> 01:06:17.200]   you wanna be able to tell where did my model go wrong?
[01:06:17.200 --> 01:06:19.720]   So that's something is called a confusion matrix.
[01:06:19.720 --> 01:06:21.080]   A confusion matrix will tell you
[01:06:21.080 --> 01:06:22.800]   where did the model go wrong?
[01:06:22.800 --> 01:06:24.600]   So the best way to interpret this
[01:06:24.600 --> 01:06:29.200]   is you want all your items to be on the diagonal, okay?
[01:06:29.200 --> 01:06:31.360]   So if there's 41 here,
[01:06:31.360 --> 01:06:35.160]   that means that there's actually 41 beers
[01:06:35.160 --> 01:06:37.000]   and the model has also predicted.
[01:06:37.000 --> 01:06:40.000]   So there's 41 images that were actually beers
[01:06:40.000 --> 01:06:42.680]   and the model predicted them as black.
[01:06:42.680 --> 01:06:44.000]   But if I look at this one,
[01:06:44.000 --> 01:06:46.840]   this means it actually was a grizzly,
[01:06:46.840 --> 01:06:48.760]   but the model predicted as a black.
[01:06:48.760 --> 01:06:52.280]   So this is something that we, this is how we can see.
[01:06:52.280 --> 01:06:53.840]   And it's helpful for us to know
[01:06:53.840 --> 01:06:55.920]   when we put the models in production,
[01:06:55.920 --> 01:06:58.960]   this is helpful for us to know that this is where,
[01:06:58.960 --> 01:07:03.840]   so this is where the deep learning model got it wrong,
[01:07:03.840 --> 01:07:07.440]   or even here that it actually was a black one,
[01:07:07.440 --> 01:07:10.400]   a black bear, but the model predicted this as a grizzly.
[01:07:10.400 --> 01:07:15.040]   And going back to, going back to this,
[01:07:15.040 --> 01:07:18.120]   when I was showing you this learn equals CNN learner,
[01:07:18.120 --> 01:07:21.200]   passing in the model and the matrix equals error rate.
[01:07:21.200 --> 01:07:22.920]   So when you pass in an error rate,
[01:07:22.920 --> 01:07:25.240]   then you can see how in the first epoch,
[01:07:25.240 --> 01:07:28.600]   it says that my error rate is 18%
[01:07:28.600 --> 01:07:31.320]   and the error rate goes down and down and down
[01:07:31.320 --> 01:07:32.520]   until it is 0%.
[01:07:32.520 --> 01:07:36.240]   This model particularly is able to classify
[01:07:36.240 --> 01:07:40.720]   all of my images perfectly.
[01:07:40.720 --> 01:07:44.360]   20, so it has 20 images which are black
[01:07:44.360 --> 01:07:46.760]   and it also predicts them as black bears.
[01:07:46.760 --> 01:07:48.440]   There's 18 images which are grizzly bears
[01:07:48.440 --> 01:07:50.440]   and it predicts them as grizzly bears.
[01:07:50.440 --> 01:07:52.120]   There's 12 images which are teddies
[01:07:52.120 --> 01:07:53.720]   and it predicts them as teddies.
[01:07:53.720 --> 01:07:57.440]   So that's the main sort of thing
[01:07:57.440 --> 01:08:01.560]   on how you can then create your model.
[01:08:01.560 --> 01:08:03.600]   But the next thing you wanna do is,
[01:08:03.600 --> 01:08:06.840]   you can actually use a model to check,
[01:08:06.840 --> 01:08:08.480]   you wanna check your model on,
[01:08:08.480 --> 01:08:12.240]   okay, where did the model go the most wrong, right?
[01:08:12.240 --> 01:08:14.720]   So when you, Fast.ai has something called
[01:08:14.720 --> 01:08:17.720]   as an interpretation plot top losses.
[01:08:17.720 --> 01:08:19.320]   What this top losses does,
[01:08:20.160 --> 01:08:23.640]   a loss, remember, a loss is something that will be high
[01:08:23.640 --> 01:08:26.960]   when your model is wrong.
[01:08:26.960 --> 01:08:29.600]   So that's when the loss will be high.
[01:08:29.600 --> 01:08:31.840]   So when you have your loss as something like,
[01:08:31.840 --> 01:08:36.640]   so these four labels are just the actual class,
[01:08:36.640 --> 01:08:39.640]   the predicted class, and then, oh, sorry.
[01:08:39.640 --> 01:08:49.760]   I think the first one is not the actual class,
[01:08:49.760 --> 01:08:52.840]   the first one is the predicted class.
[01:08:52.840 --> 01:08:54.840]   So the first one is predicted,
[01:08:54.840 --> 01:08:57.080]   the second one is the actual class,
[01:08:57.080 --> 01:08:59.720]   then this is your loss, 1.37,
[01:08:59.720 --> 01:09:02.000]   and this is the probability that the model says
[01:09:02.000 --> 01:09:02.920]   it's a grizzly.
[01:09:02.920 --> 01:09:04.520]   So the model is 70,
[01:09:04.520 --> 01:09:06.800]   it's saying with a probability of 0.74
[01:09:06.800 --> 01:09:08.400]   that this image is a grizzly.
[01:09:08.400 --> 01:09:11.960]   Now, actually, if we have a look at this image,
[01:09:11.960 --> 01:09:14.560]   so remember from the classification matrix,
[01:09:14.560 --> 01:09:17.800]   there was one image that the model got wrong.
[01:09:17.800 --> 01:09:19.640]   If we actually have a look at this,
[01:09:19.640 --> 01:09:21.920]   this image is actually that of a grizzly bear,
[01:09:21.920 --> 01:09:23.480]   so it's not even a black bear.
[01:09:23.480 --> 01:09:25.160]   So the label is incorrect.
[01:09:25.160 --> 01:09:30.160]   So this way, we can actually do a lot of data cleaning,
[01:09:30.160 --> 01:09:34.960]   'cause then you can compare the predictions of the model
[01:09:34.960 --> 01:09:36.880]   to the actual labels.
[01:09:36.880 --> 01:09:39.160]   And then you can see, okay, in this case,
[01:09:39.160 --> 01:09:40.560]   it's the label that's incorrect.
[01:09:40.560 --> 01:09:42.680]   And in a real-world case scenario,
[01:09:42.680 --> 01:09:44.240]   you have lots of these places
[01:09:44.240 --> 01:09:46.480]   where the labels could be incorrect,
[01:09:46.480 --> 01:09:49.040]   and this is a good way of making sure
[01:09:49.040 --> 01:09:52.680]   that you can clean your data using this method,
[01:09:52.680 --> 01:09:55.120]   using this interpretation plot top losses.
[01:09:55.120 --> 01:10:00.680]   So yeah, so the intuitive approach to do data cleaning
[01:10:00.680 --> 01:10:02.880]   is to do it before you train a model.
[01:10:02.880 --> 01:10:05.160]   But Fast.ai and Jeremy and Sylvain,
[01:10:05.160 --> 01:10:07.240]   sort of in this book have shown us
[01:10:07.240 --> 01:10:09.640]   that how it can be really helpful
[01:10:09.640 --> 01:10:11.320]   to do the actual cleaning
[01:10:11.320 --> 01:10:15.640]   after you've sort of trained your model,
[01:10:15.640 --> 01:10:17.560]   and then you compare the predictions of the model
[01:10:17.560 --> 01:10:18.760]   with the actual labels.
[01:10:19.760 --> 01:10:24.200]   So this is just going into data cleaning from here on.
[01:10:24.200 --> 01:10:27.160]   So if you see in data cleaning,
[01:10:27.160 --> 01:10:30.760]   Fast.ai has something called an image classifier cleaner.
[01:10:30.760 --> 01:10:32.520]   So if I go in my notebook,
[01:10:32.520 --> 01:10:35.800]   so this is how this cleaner looks like.
[01:10:35.800 --> 01:10:37.720]   What you can do is in this cleaner,
[01:10:37.720 --> 01:10:39.640]   it will show you all these different images.
[01:10:39.640 --> 01:10:43.800]   So in this example, it's actually showing you an image
[01:10:43.800 --> 01:10:47.000]   that is both a grizzly and a black bear,
[01:10:47.000 --> 01:10:49.560]   but in the dataset that we've downloaded ourselves
[01:10:49.560 --> 01:10:53.400]   using this DuckDuckGo, there's no dirty images as such.
[01:10:53.400 --> 01:10:56.680]   Like this even, the second image,
[01:10:56.680 --> 01:10:59.920]   that of a grizzly has two grizzly bears, so it's fine.
[01:10:59.920 --> 01:11:01.360]   But in this particular dataset
[01:11:01.360 --> 01:11:04.400]   that Jeremy and Sylvain were working with,
[01:11:04.400 --> 01:11:05.800]   there was this particular image
[01:11:05.800 --> 01:11:09.480]   with a grizzly bear and a black bear.
[01:11:09.480 --> 01:11:11.520]   So what you could have done is you could have just gone here
[01:11:11.520 --> 01:11:12.960]   and you could have said, delete it,
[01:11:12.960 --> 01:11:16.160]   or you could have changed the label of this image
[01:11:16.160 --> 01:11:18.840]   to say it's a black, basically black image.
[01:11:18.840 --> 01:11:23.840]   So this is how this sort of image cleaner
[01:11:23.840 --> 01:11:26.400]   or image classifier cleaner will work.
[01:11:26.400 --> 01:11:29.280]   It's using the trained model predictions
[01:11:29.280 --> 01:11:32.760]   and it's sort of can be then used to clean your dataset.
[01:11:32.760 --> 01:11:37.680]   So when you're creating your dataset using the DuckDuckGo,
[01:11:37.680 --> 01:11:39.880]   please don't forget to use this cleaner
[01:11:39.880 --> 01:11:44.640]   and don't forget to interpret the interpreters plot
[01:11:44.640 --> 01:11:47.960]   to stop losses method to then see losses
[01:11:47.960 --> 01:11:51.480]   and then pretty much see the actual model predictions.
[01:11:51.480 --> 01:11:55.480]   So that's the main sort of things that I did wanna cover.
[01:11:55.480 --> 01:11:58.800]   So that's how, I know we've covered a lot today.
[01:11:58.800 --> 01:12:00.240]   There's a lot that's been covered
[01:12:00.240 --> 01:12:04.680]   and there's a lot of information that's been dumped on you,
[01:12:04.680 --> 01:12:06.400]   but that's okay.
[01:12:06.400 --> 01:12:11.400]   When you go back, just read this whole chapter slowly
[01:12:11.760 --> 01:12:14.880]   and steadily, and then all of this will make sense.
[01:12:14.880 --> 01:12:18.680]   But before, now the only thing that we left with today
[01:12:18.680 --> 01:12:22.320]   is just how to turn this trained model that we have
[01:12:22.320 --> 01:12:25.000]   that can tell grizzly bears from black bears,
[01:12:25.000 --> 01:12:28.000]   how do we convert this into an online application?
[01:12:28.000 --> 01:12:30.200]   So this is something that we're gonna do now,
[01:12:30.200 --> 01:12:32.680]   but I'm gonna take four minutes of questions
[01:12:32.680 --> 01:12:35.480]   if there are any.
[01:12:35.480 --> 01:12:37.640]   (silence)
[01:12:37.640 --> 01:12:56.040]   How can we create a stratified validation
[01:12:56.040 --> 01:12:58.280]   in case we have a class imbalance?
[01:12:58.280 --> 01:13:01.440]   Well, this sklearn has stratified splitters,
[01:13:01.440 --> 01:13:04.240]   fastai has a stratified splitter as well,
[01:13:04.240 --> 01:13:05.760]   as far as I remember.
[01:13:05.760 --> 01:13:07.840]   So the best way would be you search something
[01:13:07.840 --> 01:13:12.840]   like stratified split, stratified split,
[01:13:12.840 --> 01:13:15.160]   and you just say fastai.
[01:13:15.160 --> 01:13:17.680]   So see how this is, forums,
[01:13:17.680 --> 01:13:18.920]   it'll take you to the fastai forums
[01:13:18.920 --> 01:13:22.760]   and we'll show you how you can do stratified labels sampling.
[01:13:22.760 --> 01:13:33.880]   If fastai library does have equal replacement
[01:13:33.880 --> 01:13:36.240]   for k-fold for dealing with class imbalance,
[01:13:36.240 --> 01:13:37.560]   I'm sure there is.
[01:13:37.560 --> 01:13:40.960]   Yes, it's been answered in the forums again.
[01:13:40.960 --> 01:13:44.360]   So yeah, before asking, just have a look in the forums.
[01:13:44.360 --> 01:13:45.760]   Most of the questions you'll find
[01:13:45.760 --> 01:13:47.520]   have answers to that already.
[01:13:47.520 --> 01:13:51.760]   When do I get tensors out of the data loader?
[01:13:51.760 --> 01:13:54.240]   Okay, again, we are,
[01:13:54.240 --> 01:14:00.720]   so what happens is you have your items, right?
[01:14:01.960 --> 01:14:06.840]   These items are being resized.
[01:14:06.840 --> 01:14:11.840]   So all of them are now 128, 128, 128.
[01:14:11.840 --> 01:14:13.960]   Then they get converted to tensors.
[01:14:13.960 --> 01:14:16.240]   So each of these get converted to tensors.
[01:14:16.240 --> 01:14:20.120]   And then that's when they get stacked.
[01:14:20.120 --> 01:14:23.600]   So you have a tensor of four by 128 by 128.
[01:14:23.600 --> 01:14:26.440]   So then your data loader,
[01:14:26.440 --> 01:14:28.160]   so this becomes your first batch.
[01:14:28.160 --> 01:14:29.760]   The same thing happens for the next four.
[01:14:29.760 --> 01:14:33.280]   So you have your another four by 128 by 128 tensor.
[01:14:33.280 --> 01:14:40.360]   So when do I get the tensors out of the data loader?
[01:14:40.360 --> 01:14:43.160]   Pretty much every time the data loader is returning tensors,
[01:14:43.160 --> 01:14:45.840]   but there's a point where each item,
[01:14:45.840 --> 01:14:48.520]   after being resized to a specific size,
[01:14:48.520 --> 01:14:50.720]   that's when it gets converted into a tensor.
[01:14:50.720 --> 01:14:56.400]   What will happen if the image does not belong to the sample?
[01:14:56.400 --> 01:14:57.680]   Okay, that's called outer sampling.
[01:14:57.680 --> 01:14:59.400]   We're gonna cover that next.
[01:14:59.800 --> 01:15:01.320]   That's a really good question.
[01:15:01.320 --> 01:15:04.520]   Is random splitter needed
[01:15:04.520 --> 01:15:06.520]   when you have both training and validation folders?
[01:15:06.520 --> 01:15:07.360]   No.
[01:15:07.360 --> 01:15:10.440]   Again, you wanna use a grandparent splitter
[01:15:10.440 --> 01:15:12.360]   or you wanna use like a folder splitter
[01:15:12.360 --> 01:15:14.880]   that you wanna split your dataset based on folders.
[01:15:14.880 --> 01:15:18.880]   So the question for context for everybody,
[01:15:18.880 --> 01:15:21.280]   the question that's being asked
[01:15:21.280 --> 01:15:23.680]   about the folder structure, it's just this.
[01:15:23.680 --> 01:15:27.840]   So instead of having all my items in a specific,
[01:15:27.840 --> 01:15:30.560]   in a particular folder, in which case it's called beers,
[01:15:30.560 --> 01:15:34.400]   what if I have beers and then I have two folders,
[01:15:34.400 --> 01:15:38.560]   train and val, and then train has all these
[01:15:38.560 --> 01:15:42.640]   sort of hundred images and val has say 20 images.
[01:15:42.640 --> 01:15:44.840]   In that case, how do I do this splitting?
[01:15:44.840 --> 01:15:49.200]   So then how do I split based on these folders?
[01:15:49.200 --> 01:15:50.560]   I think it's called a grandparent splitter,
[01:15:50.560 --> 01:15:52.320]   but yeah, that's the one I can get back to you
[01:15:52.320 --> 01:15:54.200]   on what exactly it's called in Fast.ai.
[01:15:54.200 --> 01:15:56.440]   But I'm sure there's a way, like you can just have a look.
[01:15:56.440 --> 01:15:58.440]   Yeah, there it is, grandparent splitter.
[01:15:58.440 --> 01:16:07.240]   Okay, you can't use a grandparent splitter
[01:16:07.240 --> 01:16:09.560]   on like indexes one, two, three, four, five.
[01:16:09.560 --> 01:16:14.240]   So I've got to explain what a grandparent splitter does.
[01:16:14.240 --> 01:16:19.440]   I'm confusing myself with a grandparent splitter,
[01:16:19.440 --> 01:16:21.280]   but don't worry about the grandparent splitter for now.
[01:16:21.280 --> 01:16:24.040]   I think I've said, I will give you context
[01:16:24.040 --> 01:16:26.080]   on where each of these splitters gets used,
[01:16:26.080 --> 01:16:27.960]   but give me a day and I'll get back to you
[01:16:27.960 --> 01:16:31.000]   with which splitter will get used at which point
[01:16:31.000 --> 01:16:34.900]   and how you can do this splitting based on the folders.
[01:16:34.900 --> 01:16:41.480]   Oh, what is the difference between splitter
[01:16:41.480 --> 01:16:44.240]   and valid percentage when we were using this?
[01:16:44.240 --> 01:16:45.760]   Well, internally, when you were calling
[01:16:45.760 --> 01:16:47.720]   imageDataLoaders.fromName function,
[01:16:47.720 --> 01:16:50.360]   Fast.ai was creating a splitter for you
[01:16:50.360 --> 01:16:52.240]   for that particular valid percentage.
[01:16:52.240 --> 01:16:55.920]   So in that case, you didn't just have to specify a splitter,
[01:16:55.920 --> 01:16:57.800]   but because now we want to show you
[01:16:57.800 --> 01:16:59.960]   on what exactly is going on step-by-step,
[01:16:59.960 --> 01:17:02.240]   that's why we have a look at what splitter is.
[01:17:02.240 --> 01:17:09.800]   Will it matter if at test time, the images are resized?
[01:17:09.800 --> 01:17:13.120]   No, it doesn't matter if they're resized
[01:17:13.120 --> 01:17:15.280]   using the same method as training,
[01:17:15.280 --> 01:17:18.360]   but it is recommended that that's what the case is.
[01:17:18.360 --> 01:17:20.880]   Again, this is something that we are skipping ahead
[01:17:20.880 --> 01:17:23.960]   a little bit, so I will answer that in my own time
[01:17:23.960 --> 01:17:26.280]   afterwards, it's not relevant right now.
[01:17:26.280 --> 01:17:32.680]   How will random resize crop make sure
[01:17:32.680 --> 01:17:34.160]   that the entire image is seen by the model?
[01:17:34.160 --> 01:17:36.400]   So as I said, 'cause you're going,
[01:17:36.400 --> 01:17:39.240]   you're making multiple passes over that image,
[01:17:39.240 --> 01:17:44.240]   so that's why it's seen by the model,
[01:17:44.240 --> 01:17:46.480]   the whole image is seen by the model.
[01:17:46.480 --> 01:17:52.320]   So for example here, when you have this whole image,
[01:17:52.320 --> 01:17:54.680]   the first crop is here, the second crop is here,
[01:17:54.680 --> 01:17:57.160]   the third crop is here, and then the fourth crop is here.
[01:17:57.160 --> 01:17:59.600]   So every time, 'cause you have a different crop,
[01:17:59.600 --> 01:18:02.320]   the model actually ends up seeing the whole image.
[01:18:02.320 --> 01:18:08.360]   I think that's been asked before.
[01:18:08.360 --> 01:18:10.520]   (silence)
[01:18:10.520 --> 01:18:34.440]   So the question is, when we're passing batch transforms
[01:18:34.440 --> 01:18:37.480]   in Fast.ai, then is the same type of augmentation
[01:18:37.480 --> 01:18:39.000]   being applied to all images?
[01:18:39.000 --> 01:18:41.080]   I would say so, but I'll have to double check,
[01:18:41.080 --> 01:18:42.800]   'cause there's no way to have,
[01:18:42.800 --> 01:18:45.040]   if you're in a particular batch, then yes,
[01:18:45.040 --> 01:18:47.880]   there's in a way the rotations,
[01:18:47.880 --> 01:18:49.880]   but I'll have to go double check if Fast.ai
[01:18:49.880 --> 01:18:53.240]   does something more interesting,
[01:18:53.240 --> 01:18:54.680]   but my answer would be yes for now,
[01:18:54.680 --> 01:18:56.440]   but I'll get back to that question.
[01:18:56.440 --> 01:19:03.120]   I'm skipping this one for now,
[01:19:03.120 --> 01:19:05.040]   'cause we already looked at fine tuning,
[01:19:05.040 --> 01:19:08.240]   but we will look into model training a lot more.
[01:19:08.240 --> 01:19:12.440]   Would it make sense to add borders to images
[01:19:12.440 --> 01:19:14.560]   during item transforming training?
[01:19:14.560 --> 01:19:17.280]   Okay, these are all really good questions.
[01:19:17.280 --> 01:19:21.560]   I was just thinking if there's anything that's so far,
[01:19:21.560 --> 01:19:23.720]   these are all questions that build on top
[01:19:23.720 --> 01:19:25.640]   of what we've looked at today,
[01:19:25.640 --> 01:19:27.840]   but I was just more looking at questions on,
[01:19:27.840 --> 01:19:29.440]   okay, I didn't understand this part
[01:19:29.440 --> 01:19:30.680]   of what we looked at so far,
[01:19:30.680 --> 01:19:32.200]   or I didn't understand this part
[01:19:32.200 --> 01:19:33.800]   of what we looked at so far,
[01:19:33.800 --> 01:19:36.440]   but it looks like everybody's understood
[01:19:36.440 --> 01:19:38.040]   what we've looked at so far,
[01:19:38.040 --> 01:19:40.080]   'cause nobody's asked me to explain
[01:19:40.080 --> 01:19:42.080]   a particular step again, so that's good.
[01:19:42.080 --> 01:19:47.840]   Okay, so then the next thing,
[01:19:47.840 --> 01:19:51.520]   and the last thing that we're gonna do today is called,
[01:19:51.520 --> 01:19:55.320]   we wanna use, we wanna turn this trained model
[01:19:55.320 --> 01:19:57.320]   into an online application,
[01:19:57.320 --> 01:19:59.520]   and this is something you're all gonna do this week,
[01:19:59.520 --> 01:20:01.960]   so we're gonna spend time on this right now,
[01:20:01.960 --> 01:20:04.640]   and we're gonna use this model for inference.
[01:20:04.640 --> 01:20:10.640]   So let me show you on how that can be done in code,
[01:20:10.640 --> 01:20:12.880]   instead of reading the book.
[01:20:12.880 --> 01:20:18.480]   So the first thing, so by now, when we have this,
[01:20:18.480 --> 01:20:21.800]   we have our learn as a CNN learner, right?
[01:20:21.800 --> 01:20:24.120]   And this learner has been trained,
[01:20:24.120 --> 01:20:26.120]   so remember how model,
[01:20:31.680 --> 01:20:36.440]   so if we have a model, it gets inputs,
[01:20:36.440 --> 01:20:38.440]   and a model has weights.
[01:20:38.440 --> 01:20:40.720]   So when a model has been trained,
[01:20:40.720 --> 01:20:43.800]   these weights are what we wanna store for the model.
[01:20:43.800 --> 01:20:48.600]   So in this case, when you have a 0% error rate,
[01:20:48.600 --> 01:20:49.840]   this model has been trained,
[01:20:49.840 --> 01:20:52.760]   and it already has these sort of weights
[01:20:52.760 --> 01:20:54.840]   that are the best weights for this model.
[01:20:54.840 --> 01:20:56.600]   So what we do is then,
[01:20:56.600 --> 01:20:59.720]   when we say something like learn.export,
[01:21:00.600 --> 01:21:02.160]   then in my current path,
[01:21:02.160 --> 01:21:05.560]   it creates a file called export.pkl.
[01:21:05.560 --> 01:21:09.280]   So basically what this function has done
[01:21:09.280 --> 01:21:11.160]   is that it's taken the learner,
[01:21:11.160 --> 01:21:12.800]   it's taken those weights,
[01:21:12.800 --> 01:21:15.640]   and it's dumped all of it in a file.
[01:21:15.640 --> 01:21:20.040]   So then you can actually share this file now with anybody.
[01:21:20.040 --> 01:21:23.400]   I could share this export.pkl file with you,
[01:21:23.400 --> 01:21:25.880]   and you could call load learner
[01:21:25.880 --> 01:21:29.600]   for this export.pkl file,
[01:21:29.600 --> 01:21:34.120]   and it will create my learner object again,
[01:21:34.120 --> 01:21:37.920]   and it will be using the same weights that we have so far.
[01:21:37.920 --> 01:21:44.520]   So this is how you can actually convert your model
[01:21:44.520 --> 01:21:48.920]   into a file that can then be shared with a lot of people.
[01:21:48.920 --> 01:21:51.120]   And then I can finally call predict,
[01:21:51.120 --> 01:21:53.040]   and you can see how the learner
[01:21:53.040 --> 01:21:57.120]   still can predict this image of a grizzly,
[01:21:57.120 --> 01:21:58.960]   and it still has the same vocab,
[01:21:58.960 --> 01:22:00.760]   which is black grizzly and teddy.
[01:22:00.760 --> 01:22:04.480]   So what we're doing, let me explain what we're doing.
[01:22:04.480 --> 01:22:11.280]   So first we had a learner,
[01:22:11.280 --> 01:22:12.880]   then we put it in a file.
[01:22:12.880 --> 01:22:16.400]   So I'm gonna call it export.pkl.
[01:22:16.400 --> 01:22:18.080]   So I trained my model,
[01:22:18.080 --> 01:22:21.480]   and I stored everything that I needed in this file.
[01:22:21.480 --> 01:22:25.200]   Now, this is the file that I can share with a lot of people,
[01:22:25.200 --> 01:22:27.840]   or I can share with multiple people,
[01:22:27.840 --> 01:22:30.880]   or I can then, when I wanna call inference,
[01:22:30.880 --> 01:22:33.280]   I actually wanna make the predictions,
[01:22:33.280 --> 01:22:35.800]   then what I can do is I can say load learner,
[01:22:35.800 --> 01:22:38.000]   and I can pass in the path to this file,
[01:22:38.000 --> 01:22:40.200]   which will create this learner object.
[01:22:40.200 --> 01:22:44.680]   And then I can then call prediction, learn.predict,
[01:22:44.680 --> 01:22:48.040]   just as this model was trained just now,
[01:22:48.040 --> 01:22:50.360]   and it still keeps the best weights,
[01:22:50.360 --> 01:22:51.960]   and then I can then call predictions.
[01:22:51.960 --> 01:22:54.000]   So look at this sort of scenario
[01:22:54.000 --> 01:22:56.640]   that I created to help explain what's happening.
[01:22:57.520 --> 01:22:58.360]   I don't know about,
[01:22:58.360 --> 01:23:00.360]   well, different companies have it differently,
[01:23:00.360 --> 01:23:02.120]   but just as an example,
[01:23:02.120 --> 01:23:05.920]   say I'm a data scientist or an ML or an AI scientist,
[01:23:05.920 --> 01:23:07.480]   it's like different names for these things
[01:23:07.480 --> 01:23:10.600]   in different companies.
[01:23:10.600 --> 01:23:13.000]   So I'm sitting here and I trained my model.
[01:23:13.000 --> 01:23:17.200]   So I wanted to create this Bayes classifier.
[01:23:17.200 --> 01:23:18.840]   So I trained my model,
[01:23:18.840 --> 01:23:21.240]   and then I dumped it into this artifact
[01:23:21.240 --> 01:23:24.400]   called model.pkl or something.
[01:23:24.400 --> 01:23:25.800]   It's just the file name.
[01:23:25.800 --> 01:23:28.280]   Then what I did, my model is ready.
[01:23:28.280 --> 01:23:29.240]   I'm a data scientist.
[01:23:29.240 --> 01:23:31.080]   I've done my model training.
[01:23:31.080 --> 01:23:34.880]   Then typically what I do is I will take this file
[01:23:34.880 --> 01:23:36.680]   and I will give it to somebody
[01:23:36.680 --> 01:23:39.280]   who's responsible for putting this model
[01:23:39.280 --> 01:23:41.760]   towards the customers.
[01:23:41.760 --> 01:23:45.280]   So then if there's like all these customers here,
[01:23:45.280 --> 01:23:48.400]   they should be able to interact with this model, right?
[01:23:48.400 --> 01:23:50.520]   That's someone like a data engineer
[01:23:50.520 --> 01:23:54.120]   or someone who's responsible for making sure
[01:23:54.120 --> 01:23:58.280]   that this model can then call predictions on,
[01:23:58.280 --> 01:24:02.320]   basically the users can use it to call predictions.
[01:24:02.320 --> 01:24:06.400]   What they do is they will keep this file in an environment
[01:24:06.400 --> 01:24:08.040]   that has all the dependencies.
[01:24:08.040 --> 01:24:10.280]   By dependencies, I mean, this environment,
[01:24:10.280 --> 01:24:13.400]   it has all the libraries, like it has Torch,
[01:24:13.400 --> 01:24:16.880]   it has Fast.ai or basically everything that you need
[01:24:16.880 --> 01:24:18.960]   to be able to load the learner.
[01:24:18.960 --> 01:24:23.120]   And then a user could pass an input image,
[01:24:23.120 --> 01:24:26.360]   which could be an image of a teddy bear.
[01:24:26.360 --> 01:24:29.760]   It could pass an image to this,
[01:24:29.760 --> 01:24:32.120]   particularly file or this learner,
[01:24:32.120 --> 01:24:35.440]   and then it will return predictions as usual.
[01:24:35.440 --> 01:24:40.440]   So this is the sort of the way things get done
[01:24:40.440 --> 01:24:42.760]   in most companies.
[01:24:42.760 --> 01:24:45.320]   And usually this person could be the same
[01:24:45.320 --> 01:24:46.920]   who's responsible for training
[01:24:46.920 --> 01:24:49.200]   and then also putting the model in production.
[01:24:49.200 --> 01:24:51.400]   But basically putting a model in production
[01:24:51.400 --> 01:24:53.880]   in simple terms means that then the users
[01:24:53.880 --> 01:24:56.000]   can use this model to call predictions.
[01:24:56.000 --> 01:24:59.680]   So what's the difference in training?
[01:24:59.680 --> 01:25:02.800]   So what's the difference in training and inference?
[01:25:02.800 --> 01:25:05.440]   Inference just basically means
[01:25:05.440 --> 01:25:07.480]   when you're not training your model anymore
[01:25:07.480 --> 01:25:09.600]   and you're just calling predictions on it.
[01:25:09.600 --> 01:25:15.720]   So we're gonna be converting this model
[01:25:15.720 --> 01:25:18.400]   and we're gonna convert this into an app.
[01:25:18.400 --> 01:25:21.680]   So the first thing that we need to do that,
[01:25:21.680 --> 01:25:25.400]   there's something called IPyWidgets.
[01:25:25.400 --> 01:25:28.800]   What is it called?
[01:25:28.800 --> 01:25:31.800]   Yeah, it's called IPyWidgets.
[01:25:31.800 --> 01:25:33.760]   So there's something called IPyWidgets.
[01:25:33.760 --> 01:25:38.600]   So this IPyWidgets has been imported here.
[01:25:38.600 --> 01:25:42.080]   From those widgets, I can create all these different buttons.
[01:25:42.080 --> 01:25:44.080]   So I can create my upload button.
[01:25:44.200 --> 01:25:49.200]   And then right now, I just pass an image path
[01:25:49.200 --> 01:25:51.520]   to this basically button.
[01:25:51.520 --> 01:25:53.920]   I just said that the image that I've uploaded
[01:25:53.920 --> 01:25:55.000]   is this particular image,
[01:25:55.000 --> 01:25:57.800]   this grizzly image that looks like this.
[01:25:57.800 --> 01:26:02.280]   Then on my learner, I can call predict passing in this image.
[01:26:02.280 --> 01:26:04.000]   So what that will do,
[01:26:04.000 --> 01:26:08.120]   I see how it returns the prediction.
[01:26:08.120 --> 01:26:10.560]   It returns that the prediction is that of a,
[01:26:10.560 --> 01:26:11.560]   like this image,
[01:26:11.560 --> 01:26:13.800]   has been predicted as a grizzly bear.
[01:26:13.800 --> 01:26:17.240]   And the probability of prediction is 0.999.
[01:26:17.240 --> 01:26:19.280]   So the model is really, really confident
[01:26:19.280 --> 01:26:21.000]   that this is a grizzly bear.
[01:26:21.000 --> 01:26:21.840]   And then finally,
[01:26:21.840 --> 01:26:25.520]   I can just convert this process that I did manually
[01:26:25.520 --> 01:26:29.040]   of passing in an image and then the model calls predict.
[01:26:29.040 --> 01:26:34.040]   I can then convert this into a button called classify.
[01:26:34.040 --> 01:26:36.200]   And on this button, I can say,
[01:26:36.200 --> 01:26:37.920]   if I click this button,
[01:26:37.920 --> 01:26:39.480]   then call this button,
[01:26:39.480 --> 01:26:40.840]   click this button,
[01:26:40.840 --> 01:26:42.520]   then call this function.
[01:26:42.520 --> 01:26:44.000]   What this function will do
[01:26:44.000 --> 01:26:48.160]   is whatever image I've uploaded to my upload button,
[01:26:48.160 --> 01:26:52.080]   it will convert that into an image that looks like this.
[01:26:52.080 --> 01:26:57.080]   So this image, it'll convert it into an image.
[01:26:57.080 --> 01:26:59.520]   Then it will clear any output that there is,
[01:26:59.520 --> 01:27:01.840]   and it will display that image.
[01:27:01.840 --> 01:27:04.240]   And finally, it will call prediction
[01:27:04.240 --> 01:27:06.640]   on this particular image that I've uploaded.
[01:27:06.640 --> 01:27:08.200]   And then it will say, okay,
[01:27:09.320 --> 01:27:10.840]   as a label, show this.
[01:27:10.840 --> 01:27:12.000]   Like, this is my prediction,
[01:27:12.000 --> 01:27:13.120]   this is my probability.
[01:27:13.120 --> 01:27:14.720]   So let me show you what I mean.
[01:27:14.720 --> 01:27:17.760]   So see that?
[01:27:17.760 --> 01:27:18.920]   That's what it's done.
[01:27:18.920 --> 01:27:22.480]   It's converted this whole thing into an app.
[01:27:22.480 --> 01:27:24.040]   Like, you can just use Jupyter
[01:27:24.040 --> 01:27:25.960]   to create this really small app.
[01:27:25.960 --> 01:27:27.640]   And this is something I want you guys
[01:27:27.640 --> 01:27:31.680]   to go back and do all of this in this week
[01:27:31.680 --> 01:27:34.200]   is all of you should have a single app
[01:27:34.200 --> 01:27:37.880]   that you're proud of that looks something like this.
[01:27:37.880 --> 01:27:40.320]   And then I can just go in
[01:27:40.320 --> 01:27:42.960]   and I can upload an image of,
[01:27:42.960 --> 01:27:49.960]   I can just go in and I can upload an image
[01:27:49.960 --> 01:27:51.320]   of a grizzly bear,
[01:27:51.320 --> 01:27:54.800]   and I can click on classify and see what it does.
[01:27:54.800 --> 01:27:57.400]   It says, okay, that's a prediction is grizzly,
[01:27:57.400 --> 01:27:59.040]   and the probability is 100%.
[01:27:59.040 --> 01:28:01.680]   I'm 100% confident that this is a grizzly bear.
[01:28:01.680 --> 01:28:06.080]   But this is again in a Jupyter notebook right now.
[01:28:06.080 --> 01:28:09.880]   So what you wanna do is you can't really share
[01:28:09.880 --> 01:28:11.800]   this Jupyter notebook with customers, right?
[01:28:11.800 --> 01:28:16.000]   You wanna be able to convert this into a real app.
[01:28:16.000 --> 01:28:17.320]   For that, there's two libraries.
[01:28:17.320 --> 01:28:20.000]   One of them is called, well, the boiler
[01:28:20.000 --> 01:28:22.400]   is a library that does this.
[01:28:22.400 --> 01:28:25.560]   And then if you just call these two lines of code,
[01:28:25.560 --> 01:28:27.800]   it will convert this into an app.
[01:28:27.800 --> 01:28:28.760]   So let me show you.
[01:28:28.760 --> 01:28:35.720]   So all I did, I copied all of the stuff that I had.
[01:28:35.720 --> 01:28:40.320]   Basically just from here all the way to here,
[01:28:40.320 --> 01:28:43.240]   I just copied all of this stuff into a new notebook,
[01:28:43.240 --> 01:28:45.000]   and I'm just running this again.
[01:28:45.000 --> 01:28:50.880]   It's the same thing, right?
[01:28:50.880 --> 01:28:53.320]   And this is my output.
[01:28:53.320 --> 01:28:54.480]   So if I click on that,
[01:28:54.480 --> 01:28:57.320]   when I installed that boiler application,
[01:28:57.320 --> 01:28:58.560]   then I can click on this.
[01:28:58.560 --> 01:29:04.000]   And what that will do is it will convert this thing
[01:29:04.000 --> 01:29:06.000]   into an application.
[01:29:06.000 --> 01:29:11.880]   So now I can share this,
[01:29:11.880 --> 01:29:14.120]   'cause right now I'm running this on my local host.
[01:29:14.120 --> 01:29:19.120]   If this was online on like say 192.168 or some HTTP URL,
[01:29:19.120 --> 01:29:22.320]   then what you can do is now you can share your app
[01:29:22.320 --> 01:29:24.440]   with friends and they can all come in
[01:29:24.440 --> 01:29:25.960]   and they can all upload their own images.
[01:29:25.960 --> 01:29:28.520]   If I go in and upload another image of Grizzly
[01:29:28.520 --> 01:29:30.840]   and I click classify, well, it works.
[01:29:30.840 --> 01:29:33.200]   So I can download another teddy bear image
[01:29:33.200 --> 01:29:34.200]   or I can upload that.
[01:29:34.200 --> 01:29:38.040]   So now I've sort of converted this model
[01:29:38.040 --> 01:29:42.080]   that I had of a Grizzly and a teddy bear classifier.
[01:29:42.080 --> 01:29:45.360]   And I've converted that model into this nice looking app,
[01:29:45.360 --> 01:29:47.560]   into a very basic nice looking app that looks like this.
[01:29:47.560 --> 01:29:49.040]   It just has like four or five,
[01:29:49.040 --> 01:29:52.040]   it has some buttons that iPad widgets we used to do.
[01:29:52.040 --> 01:29:54.680]   And then it uses this boiler to convert this
[01:29:54.680 --> 01:29:57.760]   Jupyter notebook and it serves it
[01:29:57.760 --> 01:29:59.880]   at this URL boiler window.
[01:30:01.440 --> 01:30:06.080]   So then homework for this week would be
[01:30:06.080 --> 01:30:08.520]   taking this sort of exercise
[01:30:08.520 --> 01:30:11.880]   and then going back and converting everything.
[01:30:11.880 --> 01:30:13.360]   Like you could have your own data sets.
[01:30:13.360 --> 01:30:15.640]   Say you're interested about a guitar
[01:30:15.640 --> 01:30:18.920]   or you're interested about, I don't know,
[01:30:18.920 --> 01:30:20.760]   you're interested about music.
[01:30:20.760 --> 01:30:23.760]   So then you could have all these musical instruments
[01:30:23.760 --> 01:30:25.360]   and you could have an app
[01:30:25.360 --> 01:30:28.200]   that does a music instrument classifier.
[01:30:28.200 --> 01:30:29.960]   And then you could also have an app
[01:30:29.960 --> 01:30:33.760]   that somebody in a fast AI student,
[01:30:33.760 --> 01:30:35.720]   previously what they did was
[01:30:35.720 --> 01:30:39.960]   they uploaded 10 images each of their cousins.
[01:30:39.960 --> 01:30:42.120]   So he had like 16 cousins.
[01:30:42.120 --> 01:30:45.000]   So he uploaded 10 or 15 images each of the cousins
[01:30:45.000 --> 01:30:48.440]   and he created an app that was called a cousin classifier
[01:30:48.440 --> 01:30:51.080]   that then his partner could use
[01:30:51.080 --> 01:30:53.120]   to classify which cousin is,
[01:30:53.120 --> 01:30:54.520]   like what's the name of which cousin.
[01:30:54.520 --> 01:30:55.960]   So she could just take a picture,
[01:30:55.960 --> 01:30:59.000]   upload that image of that cousin
[01:30:59.000 --> 01:31:01.400]   and then it will tell you the name of that cousin.
[01:31:01.400 --> 01:31:02.920]   So there's like all these different things
[01:31:02.920 --> 01:31:04.160]   that you can now build.
[01:31:04.160 --> 01:31:07.040]   And this week, don't come back next week
[01:31:07.040 --> 01:31:10.160]   if you haven't built an app like this.
[01:31:10.160 --> 01:31:12.760]   So then the next thing that comes,
[01:31:12.760 --> 01:31:15.080]   and I'm gonna go over, I'm gonna go 10 minutes over
[01:31:15.080 --> 01:31:17.680]   'cause there's more stuff that I wanna cover today
[01:31:17.680 --> 01:31:18.600]   and I'm not done yet.
[01:31:18.600 --> 01:31:20.640]   So it's better if we cover this today
[01:31:20.640 --> 01:31:22.840]   rather than leaving it next week.
[01:31:22.840 --> 01:31:28.520]   So right now we've converted things into an app already.
[01:31:28.520 --> 01:31:33.520]   So this is done.
[01:31:33.520 --> 01:31:38.200]   Then the next thing is deploying your app.
[01:31:38.200 --> 01:31:40.560]   What deploying your app means is,
[01:31:40.560 --> 01:31:44.520]   say you don't wanna use a GCP instance,
[01:31:44.520 --> 01:31:48.880]   then what Fastly I suggest is there's an app called Binder.
[01:31:48.880 --> 01:31:50.440]   So let me see if I can find it.
[01:31:56.800 --> 01:32:01.800]   So there's this app called, which is in the notebook.
[01:32:01.800 --> 01:32:04.960]   You can go to this URL called Binder,
[01:32:04.960 --> 01:32:08.520]   then just go create a GitHub repository.
[01:32:08.520 --> 01:32:11.200]   So you'll have to check what GitHub is.
[01:32:11.200 --> 01:32:13.200]   And then if you go create a GitHub repository,
[01:32:13.200 --> 01:32:16.040]   I created a recent GitHub repository called
[01:32:16.040 --> 01:32:20.400]   Beoclassifier.
[01:32:20.400 --> 01:32:23.400]   And then I uploaded this exact,
[01:32:23.400 --> 01:32:27.080]   basically I uploaded this exact Jupyter notebook over here.
[01:32:27.080 --> 01:32:28.520]   So this is the same notebook.
[01:32:28.520 --> 01:32:30.520]   And then I can pass in the URL
[01:32:30.520 --> 01:32:32.600]   of this GitHub repository over here.
[01:32:32.600 --> 01:32:34.720]   And then the next step that's mentioned
[01:32:34.720 --> 01:32:38.800]   is you just change the URL to open to this boiler,
[01:32:38.800 --> 01:32:41.400]   render, and then the name of the,
[01:32:41.400 --> 01:32:45.880]   so I can just say beard.ipinb, and I can click on launch.
[01:32:45.880 --> 01:32:51.800]   So that will then launch this into an app classifier.
[01:32:51.800 --> 01:32:53.080]   It'll give me this URL.
[01:32:53.080 --> 01:32:55.720]   So if I go to this URL, I can share this URL.
[01:32:55.720 --> 01:32:59.000]   It doesn't want to do it for me right now.
[01:32:59.000 --> 01:33:01.320]   That's okay.
[01:33:01.320 --> 01:33:03.560]   It's just a small bug that I'll have to fix later.
[01:33:03.560 --> 01:33:06.440]   But basically then what it will do is it will convert this
[01:33:06.440 --> 01:33:10.040]   into an boiler app that will look something like this.
[01:33:10.040 --> 01:33:12.480]   And then you can share this with anybody in your family,
[01:33:12.480 --> 01:33:15.120]   or you can even go to this URL from your phones
[01:33:15.120 --> 01:33:18.480]   and you can upload images and can classify those images.
[01:33:18.480 --> 01:33:20.400]   So this is something you want to do this week
[01:33:20.400 --> 01:33:23.320]   is you want to create your own datasets.
[01:33:23.320 --> 01:33:27.520]   You want to use the Fast.ai cleaner to clean the datasets.
[01:33:27.520 --> 01:33:30.600]   And then you want to be able to deploy this app to Binder.
[01:33:30.600 --> 01:33:33.800]   So that's the most of it.
[01:33:33.800 --> 01:33:37.360]   That's pretty much the most of it.
[01:33:37.360 --> 01:33:41.080]   I do want you to go back and read the 2.4.
[01:33:41.080 --> 01:33:42.960]   So we've covered so far.
[01:33:42.960 --> 01:33:47.240]   We won't be coming back to chapter two, but have a look.
[01:33:47.240 --> 01:33:50.320]   The rest of the chapter two, there's mostly theory
[01:33:50.320 --> 01:33:52.240]   and there's mostly interesting patterns.
[01:33:52.240 --> 01:33:55.480]   Like I've shown you the major bulk of what there is
[01:33:55.480 --> 01:33:57.240]   in chapter two.
[01:33:57.240 --> 01:33:59.800]   I've shown you exactly how you can convert things to an app.
[01:33:59.800 --> 01:34:03.160]   And what I want you to do is then go back
[01:34:03.160 --> 01:34:07.600]   and read all of this, all the titles and everything,
[01:34:07.600 --> 01:34:09.640]   especially things like how to avoid a disaster.
[01:34:09.640 --> 01:34:11.600]   'Cause when you deploy your app,
[01:34:11.600 --> 01:34:13.520]   you need to be able to make sure
[01:34:13.520 --> 01:34:15.920]   that it can still classify things.
[01:34:15.920 --> 01:34:17.640]   There's some things that you really need
[01:34:17.640 --> 01:34:20.240]   to be able to think about.
[01:34:20.240 --> 01:34:23.480]   And this, go back and have a look at this part
[01:34:23.480 --> 01:34:25.880]   and then answer the question there.
[01:34:25.880 --> 01:34:27.920]   So there's like these 27 questions.
[01:34:27.920 --> 01:34:30.120]   You should be able to answer the 32 questions
[01:34:30.120 --> 01:34:31.320]   from the first chapter.
[01:34:31.320 --> 01:34:34.240]   And then you should be able to answer the 27 questions.
[01:34:34.240 --> 01:34:40.440]   Okay, then last thing I want to discuss
[01:34:40.440 --> 01:34:42.520]   is now that we're all doing projects
[01:34:42.520 --> 01:34:45.400]   and we're all doing, sorry, I'll go to questions first.
[01:34:45.400 --> 01:34:47.160]   We're just going to have a look at
[01:34:47.160 --> 01:34:50.600]   if there's any questions so far about what we've discussed.
[01:34:50.600 --> 01:35:06.840]   As I showed you, Mohit, you can pretty much say doc
[01:35:06.840 --> 01:35:09.320]   or you can say question mark, question mark
[01:35:09.320 --> 01:35:10.720]   in Jupyter Notebook.
[01:35:10.720 --> 01:35:12.880]   But if you want to do it in Visual Studio Code,
[01:35:12.880 --> 01:35:14.760]   I don't have it connected, but let me do it now.
[01:35:14.760 --> 01:35:17.320]   I'll show you how you can do it in Visual Studio Code.
[01:35:17.320 --> 01:35:18.160]   One second.
[01:35:18.160 --> 01:35:25.560]   The easiest way is, say you want to learn about,
[01:35:25.560 --> 01:35:30.480]   say you want to learn about this load learner function
[01:35:30.480 --> 01:35:33.360]   called doc, pass in the function name
[01:35:33.360 --> 01:35:37.040]   that will tell you what exactly this function does.
[01:35:37.040 --> 01:35:38.960]   You can click on show in docs.
[01:35:38.960 --> 01:35:40.920]   So it will take you to the Fast.ai documentation.
[01:35:40.920 --> 01:35:43.560]   Fast.ai has really wonderful documentation.
[01:35:43.560 --> 01:35:46.480]   It will show you exactly, it will show you,
[01:35:46.480 --> 01:35:50.920]   it will give you what all the other basically functions are
[01:35:50.920 --> 01:35:52.080]   that get called.
[01:35:52.080 --> 01:35:53.680]   And then you can also have a look
[01:35:53.680 --> 01:35:55.840]   at the source code from here.
[01:35:55.840 --> 01:35:57.640]   But something I like to do is,
[01:35:57.640 --> 01:36:07.080]   I like to connect to this using VS Code
[01:36:07.080 --> 01:36:08.400]   'cause I'm on GCP.
[01:36:08.400 --> 01:36:11.160]   And then I can open my folder.
[01:36:11.160 --> 01:36:16.160]   So then I can open the Fast.ai repository.
[01:36:16.160 --> 01:36:23.600]   I don't read much of the documentation anymore,
[01:36:23.600 --> 01:36:25.680]   but when I do, I do use the doc.
[01:36:25.680 --> 01:36:28.560]   But say I want to look at this load learner function,
[01:36:28.560 --> 01:36:31.360]   something I do, I just search for this load learner.
[01:36:31.360 --> 01:36:37.280]   And then that takes me directly to this,
[01:36:37.280 --> 01:36:39.760]   that takes me directly to this function.
[01:36:39.760 --> 01:36:42.120]   So then I can have a look at what exactly is happening.
[01:36:42.120 --> 01:36:44.240]   So for example, one thing I did do today
[01:36:44.240 --> 01:36:48.560]   is I was having a look at this verify images function.
[01:36:48.560 --> 01:36:51.160]   So when I went into verify images function like this,
[01:36:51.160 --> 01:36:52.800]   I can see that all it's doing
[01:36:52.800 --> 01:36:56.080]   is it's calling the verify image function parallelly.
[01:36:56.080 --> 01:36:58.600]   So I can click on this and then I can see, okay,
[01:36:58.600 --> 01:37:00.920]   all it's doing that it's trying to,
[01:37:00.920 --> 01:37:04.040]   there's a path to it and it's trying to open that path
[01:37:04.040 --> 01:37:05.280]   in a particular mode.
[01:37:05.280 --> 01:37:06.120]   And that's it.
[01:37:06.120 --> 01:37:08.520]   It can see if it can load it and can open it,
[01:37:08.520 --> 01:37:10.320]   that's it, it turns true.
[01:37:10.320 --> 01:37:12.920]   So that's just how easy things get
[01:37:12.920 --> 01:37:15.240]   when you're using Visual Studio Code
[01:37:15.240 --> 01:37:17.640]   or any other editor of your choice.
[01:37:17.640 --> 01:37:27.880]   Assume the total number of items is 105
[01:37:27.880 --> 01:37:29.520]   and the bat size is 10.
[01:37:29.520 --> 01:37:31.760]   How will the, take care of the last five items?
[01:37:31.760 --> 01:37:34.200]   So there's an option, either you can do drop last,
[01:37:34.200 --> 01:37:36.880]   which will then, the last bat size will be five.
[01:37:36.880 --> 01:37:37.720]   That's okay.
[01:37:37.720 --> 01:37:40.440]   It's just the GPU will get five items.
[01:37:40.440 --> 01:37:42.920]   Or the second option is you don't drop the last item.
[01:37:42.920 --> 01:37:46.080]   So in that case, we'll pick the five items randomly
[01:37:46.080 --> 01:37:47.440]   from the remaining hundred.
[01:37:47.440 --> 01:37:51.240]   I think there's like a circle loop as well.
[01:37:51.240 --> 01:37:53.200]   Like you can have the first five items.
[01:37:53.200 --> 01:37:55.800]   So that's just a basic answer.
[01:37:55.800 --> 01:38:00.160]   In GitHub, we need to have model and requirements
[01:38:00.160 --> 01:38:01.760]   to deploy it via binder, right?
[01:38:01.760 --> 01:38:04.360]   I'm not sure, something was failing on my end
[01:38:04.360 --> 01:38:07.160]   when I tried to, but I'm having a look at,
[01:38:07.760 --> 01:38:12.760]   so Fast.ai has beer boiler app.
[01:38:12.760 --> 01:38:18.440]   So Fast.ai has this beer boiler app.
[01:38:18.440 --> 01:38:20.080]   So if I click on this binder,
[01:38:20.080 --> 01:38:26.560]   it has this export PKL, which is the,
[01:38:26.560 --> 01:38:29.480]   that thing and has a requirements of TXT.
[01:38:29.480 --> 01:38:30.400]   So it does seem right.
[01:38:30.400 --> 01:38:34.720]   You do need the requirements, the TXT and a model.pkl.
[01:38:34.720 --> 01:38:36.400]   I think I made a mess of it,
[01:38:36.400 --> 01:38:41.400]   but then you can see how it's now creating this app.
[01:38:41.400 --> 01:38:44.720]   So it'll take a few minutes, but have a look at this repo.
[01:38:44.720 --> 01:38:46.480]   Let me share this here.
[01:38:46.480 --> 01:38:49.760]   Have a look at this repo.
[01:38:49.760 --> 01:38:52.080]   It's the template that is used
[01:38:52.080 --> 01:38:54.400]   to create this binder, Grizzly app.
[01:38:54.400 --> 01:38:57.920]   But I'll also post this in discussions going forward.
[01:38:57.920 --> 01:38:59.520]   How do you search for functions in VS Code?
[01:38:59.520 --> 01:39:01.720]   There's a shortcut called Control + T.
[01:39:04.880 --> 01:39:06.680]   You can view the Fast.ai source code directly
[01:39:06.680 --> 01:39:08.920]   in VS Code in your, yes, thank you.
[01:39:08.920 --> 01:39:11.120]   That's a good point.
[01:39:11.120 --> 01:39:14.200]   This of course works well for other repositories as well.
[01:39:14.200 --> 01:39:15.200]   Yes, that's a good point.
[01:39:15.200 --> 01:39:18.400]   There's also, is this opening code spaces, I believe?
[01:39:18.400 --> 01:39:19.240]   Let's see.
[01:39:19.240 --> 01:39:26.240]   Yeah, this is actually quite handy.
[01:39:26.240 --> 01:39:29.760]   There's also a GitHub code spaces that you can do
[01:39:29.760 --> 01:39:31.360]   that'll open it in the browser.
[01:39:33.680 --> 01:39:35.880]   Thanks for sharing this, Ravi.
[01:39:35.880 --> 01:39:39.680]   Do you recommend setting up environment using Conda
[01:39:39.680 --> 01:39:41.360]   or use of notebooks so that web applications
[01:39:41.360 --> 01:39:42.720]   can be made for deployment?
[01:39:42.720 --> 01:39:45.800]   What's the question again?
[01:39:45.800 --> 01:39:47.280]   So do you recommend setting up environments
[01:39:47.280 --> 01:39:49.400]   using Conda or use of notebooks?
[01:39:49.400 --> 01:39:51.600]   For the notebooks, you'll need an environment anyway,
[01:39:51.600 --> 01:39:54.880]   unless you mean like deployment.
[01:39:54.880 --> 01:39:58.560]   For the test or for the small applications
[01:39:58.560 --> 01:40:00.640]   that we're gonna be building this week,
[01:40:00.640 --> 01:40:01.960]   notebooks are completely fine
[01:40:02.040 --> 01:40:04.400]   and capable of taking care of all your needs.
[01:40:04.400 --> 01:40:08.760]   Okay, so then this brings us to the last thing.
[01:40:08.760 --> 01:40:11.960]   The last thing that we wanna discuss,
[01:40:11.960 --> 01:40:14.960]   I will post it here and you can start commenting.
[01:40:14.960 --> 01:40:23.440]   Where do we host our discussions if not on Slack?
[01:40:23.440 --> 01:40:30.720]   Okay, the options are basically Weights and Biases,
[01:40:30.720 --> 01:40:33.080]   Forums or Fast.ai Forums.
[01:40:33.080 --> 01:40:36.400]   So now what will happen is you will go back this week
[01:40:36.400 --> 01:40:41.400]   and you would have created your own sort of application
[01:40:41.400 --> 01:40:44.440]   that could be any classifier that you're interested in,
[01:40:44.440 --> 01:40:46.200]   you would have created your own dataset.
[01:40:46.200 --> 01:40:48.640]   And this is a really good time to start blogging.
[01:40:48.640 --> 01:40:49.720]   If you're not blogging yet,
[01:40:49.720 --> 01:40:51.400]   this is a really good time to start blogging
[01:40:51.400 --> 01:40:52.840]   and Parul's gonna come next week
[01:40:52.840 --> 01:40:55.000]   and she's gonna share all her experiences
[01:40:55.000 --> 01:40:56.640]   on why you should blog.
[01:40:56.640 --> 01:40:58.360]   But basically then there's two options.
[01:40:58.440 --> 01:41:03.040]   You can continue sharing your work on Slack,
[01:41:03.040 --> 01:41:06.560]   but the problem with Slack is it has like this 10,000 limit
[01:41:06.560 --> 01:41:10.240]   of, and I say 10,000 limit of messages.
[01:41:10.240 --> 01:41:12.520]   And what's gonna happen is that then those messages
[01:41:12.520 --> 01:41:13.880]   will get lost over time.
[01:41:13.880 --> 01:41:17.240]   So if somebody is coming back and they're doing this,
[01:41:17.240 --> 01:41:21.320]   they're doing this fast book lecture videos,
[01:41:21.320 --> 01:41:23.840]   six months after they won't be able to have a history
[01:41:23.840 --> 01:41:25.240]   of these messages and they won't know
[01:41:25.240 --> 01:41:26.480]   what we are referring to.
[01:41:27.440 --> 01:41:30.840]   So the easiest way, there's this two options then,
[01:41:30.840 --> 01:41:34.040]   and I've been sort of considering which one to go for.
[01:41:34.040 --> 01:41:36.160]   There's pros and cons for both.
[01:41:36.160 --> 01:41:41.280]   I mean, being a part of the Fast AI Forum is really handy,
[01:41:41.280 --> 01:41:44.800]   but then the question is, where do we get the fast books?
[01:41:44.800 --> 01:41:46.320]   If we go to part one,
[01:41:46.320 --> 01:41:52.400]   if we go to part one, then the options here,
[01:41:52.400 --> 01:41:55.680]   I see there's all these things that you have a BA classifier
[01:41:55.680 --> 01:41:59.200]   but then there's this category called study groups.
[01:41:59.200 --> 01:42:01.640]   So I could create a new topic over here
[01:42:01.640 --> 01:42:04.280]   called a fast book study group,
[01:42:04.280 --> 01:42:08.240]   but then we would be,
[01:42:08.240 --> 01:42:11.000]   or we could go in this deep learning category
[01:42:11.000 --> 01:42:14.000]   and we could go, deep learning only has latest.
[01:42:14.000 --> 01:42:17.880]   Okay, so deep learning does not have study groups category.
[01:42:17.880 --> 01:42:20.600]   So we will have to go into part one 2020,
[01:42:20.600 --> 01:42:22.280]   then we will have to go into study groups
[01:42:22.280 --> 01:42:24.160]   and then we'll have to create a new topic.
[01:42:24.160 --> 01:42:26.840]   And then that's where all our discussions would be.
[01:42:26.840 --> 01:42:28.640]   So we will be sharing the space
[01:42:28.640 --> 01:42:31.160]   with a lot many other people,
[01:42:31.160 --> 01:42:32.800]   with a lot many other study groups
[01:42:32.800 --> 01:42:35.360]   and a lot many other people,
[01:42:35.360 --> 01:42:38.520]   which has a lot of advantages.
[01:42:38.520 --> 01:42:41.120]   The advantages are, I mean,
[01:42:41.120 --> 01:42:44.280]   the advantages are that you get this community
[01:42:44.280 --> 01:42:45.960]   and this environment of other people
[01:42:45.960 --> 01:42:49.080]   who are doing the same things as we are.
[01:42:49.080 --> 01:42:53.120]   But there's a disadvantage that things would be
[01:42:53.120 --> 01:42:56.160]   a little bit inside the forums.
[01:42:56.160 --> 01:42:57.960]   Like they're not,
[01:42:57.960 --> 01:43:01.080]   like you're not gonna be the exclusive 70 people
[01:43:01.080 --> 01:43:02.800]   or a hundred people who are sharing your work
[01:43:02.800 --> 01:43:05.760]   and then it automatically gets highlighted.
[01:43:05.760 --> 01:43:08.080]   So then the other option is,
[01:43:08.080 --> 01:43:09.920]   we go to the Weights and Biases forums,
[01:43:09.920 --> 01:43:10.800]   which is this place.
[01:43:10.800 --> 01:43:15.800]   So if you go, 1db.ai/fc.
[01:43:15.800 --> 01:43:17.560]   And if we go into these forums,
[01:43:17.560 --> 01:43:19.320]   then we can have,
[01:43:19.320 --> 01:43:23.200]   I can start a discussion called Share Your Work here.
[01:43:23.200 --> 01:43:25.680]   So, sorry, one thing I should have mentioned is
[01:43:25.680 --> 01:43:28.360]   there's another Share Your Work.
[01:43:28.360 --> 01:43:32.600]   It should be somewhere in forums.
[01:43:32.600 --> 01:43:33.440]   Let me Google it.
[01:43:33.440 --> 01:43:35.200]   Let me check for it, sorry.
[01:43:35.200 --> 01:43:36.520]   Share Your Work.
[01:43:36.520 --> 01:43:43.280]   So there's a multiple categories of Share Your Work.
[01:43:43.280 --> 01:43:44.160]   So that's what I'm talking like.
[01:43:44.160 --> 01:43:45.240]   If we go into the forums,
[01:43:45.240 --> 01:43:47.480]   there's so many categories of different things
[01:43:48.760 --> 01:43:51.160]   that there's a lot of other people have shared that work
[01:43:51.160 --> 01:43:53.360]   and you can go in and you can share your work
[01:43:53.360 --> 01:43:55.600]   or on Weights and Biases forums,
[01:43:55.600 --> 01:43:58.880]   then it's gonna be highly exclusive to us.
[01:43:58.880 --> 01:44:00.400]   So we could have,
[01:44:00.400 --> 01:44:02.080]   you could have in and you could have a discussion
[01:44:02.080 --> 01:44:03.280]   and you could have Share Your Work
[01:44:03.280 --> 01:44:05.120]   that I can then easily look at.
[01:44:05.120 --> 01:44:09.320]   'Cause if we all go into the forums and things would be,
[01:44:09.320 --> 01:44:11.480]   I would imagine things would be,
[01:44:11.480 --> 01:44:13.400]   small things would be at different places.
[01:44:13.400 --> 01:44:15.040]   Whereas in Weights and Biases forums,
[01:44:15.040 --> 01:44:15.880]   if we go here,
[01:44:15.880 --> 01:44:19.320]   then it's just exclusive for the group for us.
[01:44:19.320 --> 01:44:21.800]   And personally, I'm more inclined.
[01:44:21.800 --> 01:44:24.840]   Actually, I'm not inclined.
[01:44:24.840 --> 01:44:26.160]   I'm thinking,
[01:44:26.160 --> 01:44:28.680]   I can't come up with an answer on which way to go.
[01:44:28.680 --> 01:44:31.920]   But I think having that exclusivity,
[01:44:31.920 --> 01:44:33.160]   personally, I would have preferred that.
[01:44:33.160 --> 01:44:37.120]   But to me, it really doesn't make any difference
[01:44:37.120 --> 01:44:38.880]   in the sense of where we should go.
[01:44:38.880 --> 01:44:42.520]   So if you guys can come in and you can answer,
[01:44:42.520 --> 01:44:45.800]   you can come in and you can answer to this thread
[01:44:45.800 --> 01:44:47.720]   that would really be helpful.
[01:44:47.720 --> 01:44:50.360]   So then I can find and I'll know
[01:44:50.360 --> 01:44:53.240]   like where does everybody want to go.
[01:44:53.240 --> 01:44:56.760]   Are you guys there?
[01:44:56.760 --> 01:44:59.520]   (mouse clicking)
[01:44:59.520 --> 01:45:02.280]   (mouse clicking)
[01:45:02.280 --> 01:45:07.280]  , could you please post a really, really quick question?
[01:45:07.280 --> 01:45:10.040]   (mouse clicking)
[01:45:10.040 --> 01:45:32.480]   Could you please post a really, really request
[01:45:32.480 --> 01:45:34.680]   if there's like 60 of us right now in the call,
[01:45:34.680 --> 01:45:39.200]   can we please all post where we want to move ahead
[01:45:39.200 --> 01:45:40.040]   with our journeys?
[01:45:40.040 --> 01:45:42.240]   And that doesn't mean that if we're in 1 DB,
[01:45:42.240 --> 01:45:44.640]   that doesn't mean we can't be in fast.ai.
[01:45:44.640 --> 01:45:45.880]   We can be in bit of both,
[01:45:45.880 --> 01:45:48.560]   but then that's again the same problem.
[01:45:48.560 --> 01:45:51.160]   So we need to be at the one place, whichever it is.
[01:45:51.160 --> 01:46:01.160]   Okay, there's a split so far.
[01:46:01.160 --> 01:46:02.520]   That's not what I expected.
[01:46:02.520 --> 01:46:05.280]   (mouse clicking)
[01:46:05.280 --> 01:46:08.280]   Yeah, there's also fast.ai discord.
[01:46:08.280 --> 01:46:10.280]   So for those of you that don't know,
[01:46:10.280 --> 01:46:13.240]   there's a fast.ai discord.
[01:46:13.240 --> 01:46:16.080]   So let me show you fast.ai discord.
[01:46:16.080 --> 01:46:21.880]   But fast.ai discord is not so much for sharing work.
[01:46:21.880 --> 01:46:23.960]   It's more for chit chat and it's more for,
[01:46:23.960 --> 01:46:28.640]   so if I go in fast.ai and then there's chit chat
[01:46:28.640 --> 01:46:30.840]   and there's stuff about fast.ai work.
[01:46:31.480 --> 01:46:35.080]   So you can see Jeremy's there by the way.
[01:46:35.080 --> 01:46:36.640]   Jeremy's there on the forums as well.
[01:46:36.640 --> 01:46:38.680]   But there's fast.ai is more about development.
[01:46:38.680 --> 01:46:41.800]   It's more about, it's more about live coding sessions
[01:46:41.800 --> 01:46:43.840]   and it's more about the general things
[01:46:43.840 --> 01:46:45.080]   that are related to fast.ai,
[01:46:45.080 --> 01:46:46.880]   not so much about the projects.
[01:46:46.880 --> 01:46:48.680]   So forums are a better place for.
[01:46:48.680 --> 01:46:51.440]   (mouse clicking)
[01:46:51.440 --> 01:47:09.440]   Okay, it looks like 1DB is the preferred option so far.
[01:47:09.440 --> 01:47:11.760]   That doesn't mean and,
[01:47:11.760 --> 01:47:15.440]   that doesn't mean you shouldn't post in the fast.ai forums,
[01:47:15.440 --> 01:47:17.120]   but let's make a discussion.
[01:47:17.120 --> 01:47:22.120]   Let's go fast.ai, sorry, let's go 1DB forums from here on.
[01:47:22.120 --> 01:47:24.800]   And we are gonna move away from Slack.
[01:47:24.800 --> 01:47:27.000]   So something that you're all gonna do,
[01:47:27.000 --> 01:47:31.000]   I'm gonna create a discussion post here
[01:47:31.000 --> 01:47:32.320]   and I'm just gonna say,
[01:47:32.320 --> 01:47:35.920]   actually I'm not gonna create a discussion post.
[01:47:35.920 --> 01:47:37.080]   All we're gonna do is,
[01:47:37.080 --> 01:47:44.640]   all we're gonna do from this point on is when you come here,
[01:47:44.640 --> 01:47:48.280]   when you come to the forums, instead of commenting or,
[01:47:48.280 --> 01:47:51.160]   'cause if you comment, I get notified, so that's also fine.
[01:47:51.160 --> 01:47:53.080]   But then if you have any question
[01:47:53.080 --> 01:47:55.760]   that's related to the fast book,
[01:47:55.760 --> 01:47:57.280]   come here and start a discussion.
[01:47:57.280 --> 01:47:58.520]   So anything that's related.
[01:47:58.520 --> 01:48:01.520]   So instead of asking on Slack, if you do ask on Slack,
[01:48:01.520 --> 01:48:04.240]   I will ask you to repost on the forums,
[01:48:04.240 --> 01:48:07.000]   just for, we wanna keep it long-term.
[01:48:07.000 --> 01:48:08.800]   And then if there's projects that you're sharing,
[01:48:08.800 --> 01:48:10.840]   if there's work or projects that you're sharing,
[01:48:10.840 --> 01:48:13.880]   there's experiments that you're sharing or all that stuff,
[01:48:13.880 --> 01:48:16.960]   we can discuss it on the Weights & Biases forums,
[01:48:16.960 --> 01:48:20.040]   but then also let's tweet about it, let's blog about it.
[01:48:20.040 --> 01:48:22.280]   And then it's also shared on the Fast.ai forums.
[01:48:22.280 --> 01:48:24.480]   So let's do a bit of both,
[01:48:24.480 --> 01:48:26.280]   but let's keep the Weights & Biases forums
[01:48:26.280 --> 01:48:30.200]   more exclusive for us, between us as a group,
[01:48:30.200 --> 01:48:33.280]   'cause we're gonna be going forward for the next 15 weeks.
[01:48:33.280 --> 01:48:35.560]   So let's keep it more exclusive between us
[01:48:35.560 --> 01:48:37.640]   and we answer and ask questions
[01:48:37.640 --> 01:48:41.000]   and have all these discussions at this one place.
[01:48:41.000 --> 01:48:43.360]   And then I'm gonna be using this one place
[01:48:43.360 --> 01:48:46.040]   to highlight your work, to find your work,
[01:48:46.040 --> 01:48:48.840]   but feel free to also post it once things are ready,
[01:48:48.840 --> 01:48:50.960]   post them in the Fast.ai forums on,
[01:48:50.960 --> 01:48:52.960]   okay, look at this is what I did.
[01:48:52.960 --> 01:48:56.160]   So anything that's Fast.ai specific,
[01:48:56.160 --> 01:48:59.960]   library specific things, we will take it to the forums.
[01:48:59.960 --> 01:49:00.800]   So I think that's,
[01:49:00.800 --> 01:49:05.960]   I think that's the,
[01:49:05.960 --> 01:49:09.280]   yeah, everybody's saying Weights & Biases.
[01:49:09.280 --> 01:49:10.840]   Okay, so thanks for that, guys.
[01:49:10.840 --> 01:49:12.280]   I think this is it for today.
[01:49:13.280 --> 01:49:15.720]   We will, I will announce it next week
[01:49:15.720 --> 01:49:17.720]   on what's happening and these changes
[01:49:17.720 --> 01:49:20.240]   on how we're gonna be using the forums only
[01:49:20.240 --> 01:49:22.360]   for these discussions.
[01:49:22.360 --> 01:49:24.240]   But going forward, that's what we're gonna do.
[01:49:24.240 --> 01:49:25.400]   So if you do post in Slack,
[01:49:25.400 --> 01:49:28.360]   I will ask you to repost on forums.
[01:49:28.360 --> 01:49:29.200]   So thanks for today.
[01:49:29.200 --> 01:49:30.440]   Thanks for joining.
[01:49:30.440 --> 01:49:33.560]   As usual, feel free to ask me questions.
[01:49:33.560 --> 01:49:35.760]   I'll be there throughout the week,
[01:49:35.760 --> 01:49:38.440]   answering all your questions that you might have.
[01:49:38.440 --> 01:49:40.480]   The second thing is, unfortunately,
[01:49:40.480 --> 01:49:42.880]   I won't be around for the informal catch up today.
[01:49:42.880 --> 01:49:44.880]   I've gotta be somewhere.
[01:49:44.880 --> 01:49:47.760]   So if you do wanna just post in Slack
[01:49:47.760 --> 01:49:49.000]   and I will still create the meeting
[01:49:49.000 --> 01:49:51.520]   so you guys can talk to each other.
[01:49:51.520 --> 01:49:53.920]   But thanks for today and see you guys next week.
[01:49:53.920 --> 01:49:54.760]   Bye.
[01:49:54.760 --> 01:50:02.160]   [BLANK_AUDIO]

