
[00:00:00.000 --> 00:00:18.160]   Hello, everyone. Who's excited to chat about MCP today?
[00:00:18.160 --> 00:00:23.340]   Okay, we can work on that. We can get it a little bit better by the end of this talk.
[00:00:24.340 --> 00:00:35.340]   But I'm Theo. I am a product manager at Anthropic, work on MCP. Prior to this, was also a startup founder, working in the AI space.
[00:00:35.340 --> 00:00:48.680]   Couple fun facts about me, because everyone says make yourself a little bit more personable, is I like playing poker, mostly losing money at poker, not making money at poker, and I also really like coffee.
[00:00:48.680 --> 00:00:56.680]   If you're a huge coffee fan and want to talk about the best coffee in San Francisco, hit me up after the talk.
[00:00:56.680 --> 00:01:04.680]   But you didn't come here to talk about me. You came here to learn about MCP. So let's talk about MCP.
[00:01:04.680 --> 00:01:15.680]   I was told not to say MCP is the best thing since sliced bread, which I won't say, but mostly because I don't actually think it's the best thing since sliced bread.
[00:01:15.680 --> 00:01:28.680]   My goal here today is to really walk you through the origin story of MCP, why we launched it, give you a better sense of where it can actually help you in your workflow,
[00:01:28.680 --> 00:01:37.680]   And then ultimately give you a sense of the types of questions that I'm frequently hearing, where I think there's a lot of value to build in the ecosystem.
[00:01:37.680 --> 00:01:44.680]   And let you decide for yourself whether or not it is actually the best thing since sliced bread.
[00:01:44.680 --> 00:01:53.680]   So scrolling all the way back to mid last year, the co-creators of MCP, David and Justin, had this idea.
[00:01:53.680 --> 00:01:58.680]   They were seeing that, you know, classic two engineers in a garage style.
[00:01:58.680 --> 00:02:06.680]   They were seeing that they were constantly copying and pasting context from outside of the context window into the context window.
[00:02:06.680 --> 00:02:15.680]   So you're doing your workflow and suddenly you're remembering that there was a Slack message that was really important that had a lot of context that you could just copy in.
[00:02:15.680 --> 00:02:18.680]   So you're constantly kind of copying things back and forth from Slack.
[00:02:18.680 --> 00:02:22.680]   Maybe you're copying things in from Sentry, your error logs.
[00:02:22.680 --> 00:02:33.680]   But they were kind of realizing, hey, it would be so great if Claude or any LLM could just kind of climb out of its box, reach out into the real world,
[00:02:33.680 --> 00:02:37.680]   and bring that context and those actions to the model.
[00:02:37.680 --> 00:02:46.680]   And so the genesis of MCP was really around this big question of not just context but model agency.
[00:02:46.680 --> 00:02:52.680]   How do you actually give the model the ability to interact with the outside world?
[00:02:52.680 --> 00:03:01.680]   And so as they started thinking about this, they came to the conclusion that it had to be an open source standardized protocol
[00:03:01.680 --> 00:03:05.680]   in order for this to make sense at scale.
[00:03:05.680 --> 00:03:20.680]   And the reason is, of course, as you all know, if you want to build an integration and the actor or the client in this case that has to leverage that integration is using a closed source ecosystem,
[00:03:20.680 --> 00:03:28.680]   then you need maybe a BD or partnerships angle with that client to actually get access to the team, to integrate with them.
[00:03:28.680 --> 00:03:34.680]   You then have to align on the right interface, and then you get to actually build the thing itself.
[00:03:34.680 --> 00:03:45.680]   And so the idea here was that model agency was the biggest thing that was stopping LLMs from actually reaching the next stage of usefulness and intelligence,
[00:03:45.680 --> 00:03:52.680]   as we saw that reasoning models were becoming more and more the future, that tool calling was getting better.
[00:03:52.680 --> 00:04:04.680]   We really wanted to make sure that we were making it possible for everyone to get involved in that ecosystem and actually allow the models to, again, have agency.
[00:04:04.680 --> 00:04:15.680]   So they form a small tiger team internally, work on this protocol, and launch it at our company Hack Week in November of last year.
[00:04:15.680 --> 00:04:18.680]   And this was really the first turning point of MCP.
[00:04:18.680 --> 00:04:20.680]   It went viral, as you can imagine.
[00:04:20.680 --> 00:04:26.680]   Engineers from various teams were working on building MCPs to automate their own workflows.
[00:04:26.680 --> 00:04:30.680]   They were working on MCPs to automate other teams' workflows.
[00:04:30.680 --> 00:04:36.680]   This was really kind of a cool moment to see how it went from, again, like two engineers in a garage,
[00:04:36.680 --> 00:04:45.680]   all the way to this is a major moment and turning point where we think we actually unlocked some true value for other people.
[00:04:45.680 --> 00:04:50.680]   And so we ultimately ended up open sourcing MCP in November of last year,
[00:04:50.680 --> 00:04:53.680]   and that's when we introduced it to the rest of the world.
[00:04:53.680 --> 00:04:59.680]   But as most builders know, when you build something zero to one,
[00:04:59.680 --> 00:05:02.680]   you think the launch moment is going to be really impactful.
[00:05:02.680 --> 00:05:05.680]   But it actually usually is not.
[00:05:05.680 --> 00:05:10.680]   At launch, most people were saying things like, what's MCP?
[00:05:10.680 --> 00:05:14.680]   Or even worse, or maybe, you know, rightfully so, what's MPC?
[00:05:14.680 --> 00:05:18.680]   And more often than not, we got this question of,
[00:05:18.680 --> 00:05:21.680]   I don't really understand why you need a new protocol.
[00:05:21.680 --> 00:05:24.680]   I don't really understand why it has to be open source.
[00:05:24.680 --> 00:05:27.680]   Can't models call tools already?
[00:05:27.680 --> 00:05:35.680]   This was the slew of questions that kind of came again and again for probably from the era of November,
[00:05:35.680 --> 00:05:39.680]   all the way even to early this year.
[00:05:39.680 --> 00:05:53.680]   And it really took making it possible for builders to kind of get their hands dirty with building MCPs to automate their own workflow for this to take off.
[00:05:53.680 --> 00:05:59.680]   And so the next turning point, as Henry alluded to, was when Cursor kind of adopted MCP.
[00:05:59.680 --> 00:06:03.680]   And after that, a lot of other coding tools also adopted MCP.
[00:06:03.680 --> 00:06:08.680]   VS Code, Source Graph, et cetera.
[00:06:08.680 --> 00:06:12.680]   We had a lot of coding IDEs start adopting MCP.
[00:06:12.680 --> 00:06:23.680]   And that's really where that next stage of momentum came in where agency was given to builders to actually build MCPs for themselves.
[00:06:23.680 --> 00:06:33.680]   And more recently, we've seen kind of another turning point where Google, Microsoft, OpenAI, and many others have also adopted MCP.
[00:06:33.680 --> 00:06:37.680]   So we're really excited to see this kind of become more and more the standard.
[00:06:37.680 --> 00:06:44.680]   But ultimately, standards become standards because they are actually useful to builders.
[00:06:44.680 --> 00:06:49.680]   And so I kind of want to ask all of you to keep us honest.
[00:06:49.680 --> 00:06:56.680]   Contribute when you see issues with the way that the protocol is built today.
[00:06:56.680 --> 00:07:05.680]   Or if you even want to take that one step further and submit a PR directly to the GitHub repo and fix the issue, that would be even better.
[00:07:05.680 --> 00:07:12.680]   But our goal here is really to make it maximally useful for you all and for model providers.
[00:07:12.680 --> 00:07:21.680]   So thank you for your help in even getting us to the point where I can be speaking on stage about this less than one year later.
[00:07:22.680 --> 00:07:34.680]   So just to get a little bit deeper into what we were solving for at the start of building MCP is, again, this kind of idea of model agency.
[00:07:34.680 --> 00:07:40.680]   And part of that means agents is kind of the direction that we think is going to be the future.
[00:07:40.680 --> 00:07:42.680]   That's no surprise to anyone in this room.
[00:07:42.680 --> 00:07:49.680]   You are probably going to hear the word agents said in every talk, if not almost every talk.
[00:07:49.680 --> 00:08:02.680]   But the way that we think about agents is that you are giving the model, or you're rather depending on the model's intelligence to choose actions and decide what to do.
[00:08:02.680 --> 00:08:17.680]   In the same way that, you know, maybe when you talk to a human and you ask them for a response, you don't know exactly what the response is, but based on your understanding of maybe the task that you've given them, your hope is that they are going to give you the right response.
[00:08:17.680 --> 00:08:26.680]   And we want to kind of enable that world where you're depending on the model's intelligence scaling over time.
[00:08:26.680 --> 00:08:33.680]   So that leads to principles in how we actually build the protocol itself.
[00:08:33.680 --> 00:08:41.680]   Recently, we launched the support for Streamable HTTP, which changes the transport from SSE.
[00:08:41.680 --> 00:08:48.680]   And as you all might know, Streamable HTTP enables more bidirectionality.
[00:08:48.680 --> 00:08:52.680]   And so that was a very controversial decision, actually.
[00:08:52.680 --> 00:09:00.680]   But if you're keeping agents in mind as the future, it makes a lot of sense because you want to make sure that agents can kind of communicate with each other.
[00:09:00.680 --> 00:09:07.680]   The other thing that we believe is that there will be a lot more servers than there are clients.
[00:09:07.680 --> 00:09:09.680]   We could be totally wrong on this.
[00:09:09.680 --> 00:09:12.680]   I would love to see where the future plays out.
[00:09:12.680 --> 00:09:24.680]   But because we think that there will be a lot more servers than there are clients, we optimized for server simplicity and for the server builders to have better tooling.
[00:09:24.680 --> 00:09:33.680]   And that does mean when we have to make a trade-off between client complexity or server complexity, we tend to optimize for pushing the complexity down to the client.
[00:09:33.680 --> 00:09:38.680]   So I apologize in advance to client builders, but it was an intentional decision.
[00:09:38.680 --> 00:09:46.680]   Again, I would be curious to see if this plays out the way that we thought it would.
[00:09:46.680 --> 00:09:53.680]   So I'm going to speed run through some project updates, mostly because other talks are going to go much more in detail here.
[00:09:53.680 --> 00:10:00.680]   But last six months, we launched ability for folks to build remote MCPs.
[00:10:00.680 --> 00:10:04.680]   We fixed auth, which we got wrong initially.
[00:10:04.680 --> 00:10:05.680]   Thank you.
[00:10:05.680 --> 00:10:11.680]   So I know that was a huge, huge thing that we got wrong initially, but it is now fixed in the draft spec.
[00:10:11.680 --> 00:10:20.680]   And so we'd love folks to continue helping to push on these things that they see don't match their mental model.
[00:10:20.680 --> 00:10:32.680]   This was actually fixed via a series of people from the community jumping in to work on saying, hey, this is how auth works with identity providers,
[00:10:32.680 --> 00:10:34.680]   and here's how we can update the protocol.
[00:10:34.680 --> 00:10:38.680]   So very much a community effort.
[00:10:38.680 --> 00:10:42.680]   Again, launched renewable HTTP as the primary transport.
[00:10:42.680 --> 00:10:56.680]   And lastly, made a couple of updates to the developer experience by updating our SDKs and also making updates to inspector, which if you aren't familiar with, is a really good debugging tool for your server.
[00:10:56.680 --> 00:11:01.680]   I think it is probably our most underutilized tool.
[00:11:01.680 --> 00:11:06.680]   Looking forward, we're going to be focusing a lot more on that agent experience.
[00:11:06.680 --> 00:11:11.680]   So we just added elicitation to the draft spec.
[00:11:11.680 --> 00:11:17.680]   This allows servers to ask for more information from end users.
[00:11:17.680 --> 00:11:28.680]   So you can imagine you're building a-- maybe you're building a flight booking tool, and the end user says, hey, book me the best flight to Atlanta.
[00:11:28.680 --> 00:11:33.680]   And so as the server, you have a question, which is what does best mean to you?
[00:11:33.680 --> 00:11:35.680]   Is it cheapest or is it fastest?
[00:11:35.680 --> 00:11:39.680]   So you ask the end user, and now you can pass through that elicitation.
[00:11:39.680 --> 00:11:43.680]   The end user can respond and have that response ultimately sent back to the server.
[00:11:43.680 --> 00:11:55.680]   We are also making progress on the registry API, which would make it a lot easier for models to actually find MCPs that weren't already given to them upfront.
[00:11:55.680 --> 00:11:59.680]   So this is, again, kind of on that theme of model agency.
[00:11:59.680 --> 00:12:03.680]   We're really betting on the intelligence of models going up over time.
[00:12:03.680 --> 00:12:17.680]   Again, working on developer experience, we've heard often from you all that there are-- that, you know, you'd love to understand what kind of the best patterns are in the ecosystem or what the standards are.
[00:12:17.680 --> 00:12:27.680]   And so we want to make sure that there are open source examples that both we've contributed to and also the community can contribute to to kind of help build those standards and patterns together.
[00:12:27.680 --> 00:12:40.680]   And lastly, we're making sure that MCP stays open forever, and we are investing heavily in thinking about the next phase of governance.
[00:12:40.680 --> 00:12:43.680]   So there will be more updates on that soon.
[00:12:43.680 --> 00:12:55.680]   And just to do a quick call-out to the graphic in the bottom, so a lot of people have asked us what it looks like to actually build an agent with MCP.
[00:12:55.680 --> 00:13:08.680]   So our take is that an agent really is just a server acting as a client and vice versa, where you can then kind of chat back and forth with other agents, other servers, other clients.
[00:13:08.680 --> 00:13:10.680]   So I won't go into too much detail there.
[00:13:10.680 --> 00:13:21.680]   I know a lot of other people are going to be talking about agents in more detail, but I just wanted to make sure that I call that out here.
[00:13:21.680 --> 00:13:34.680]   So the thing that everyone has probably been waiting for and that I've been told over and over again when I talk to founders, what they're asking me about is what should I build in this space?
[00:13:34.680 --> 00:13:40.680]   If MCP becomes a standard, where are the interesting opportunities?
[00:13:40.680 --> 00:13:47.680]   So before jumping into this, the first thing I'll say is that we are really early right now.
[00:13:47.680 --> 00:13:52.680]   And that means that even if the standard exists, we still need the ecosystem to be filled out.
[00:13:52.680 --> 00:13:56.680]   And I would urge you to build more and more and more servers.
[00:13:56.680 --> 00:14:05.680]   If I had to put a weighting on these three bullet points, I would put 80% on the first one, 10% on the second one, and 10% on the third one.
[00:14:05.680 --> 00:14:14.680]   So we have a lot of opportunity to build a lot more servers that are higher quality and for different verticals.
[00:14:14.680 --> 00:14:27.680]   And just to touch quickly on what I mean by higher quality, a lot of people, you know, maybe hot take, but I think a lot of people are wrapping their API endpoints one-to-one and just exposing that as tools.
[00:14:27.680 --> 00:14:30.680]   So I don't think that's the right way to build an MCP server.
[00:14:30.680 --> 00:14:33.680]   That in and of itself could probably be a 20-minute talk.
[00:14:33.680 --> 00:14:38.680]   But what you really have to remember when you're building a server is that you have three users.
[00:14:38.680 --> 00:14:42.680]   You have the end user, the client developer, and the model.
[00:14:42.680 --> 00:14:45.680]   So a lot of people forget that the model is a user here as well.
[00:14:45.680 --> 00:14:51.680]   You want to, just as you would for API design, you want to think about what are the use cases that your end users are going to have?
[00:14:51.680 --> 00:14:56.680]   What are the prompts that they might actually be putting into the model?
[00:14:56.680 --> 00:15:04.680]   And ultimately, what are the tools that you then need to expose to the model to enable the model to respond correctly to those prompts?
[00:15:04.680 --> 00:15:10.680]   So higher quality servers and also servers for different verticals.
[00:15:10.680 --> 00:15:14.680]   A lot of the servers today have been for DevTools.
[00:15:14.680 --> 00:15:25.680]   We would love to see this expand to be useful beyond engineers into verticals like sales, finance, legal, education, pick your poison, whatever you know best.
[00:15:25.680 --> 00:15:29.680]   We would just love to see more servers.
[00:15:29.680 --> 00:15:33.680]   The next piece is on simplifying server building.
[00:15:33.680 --> 00:15:40.680]   So again, as I mentioned, we believe strongly that servers are going to be the vast majority of the ecosystem.
[00:15:40.680 --> 00:15:49.680]   There will, of course, be a lot of clients as well, but we think the order of magnitude of servers is going to outweigh the order of magnitude of clients.
[00:15:49.680 --> 00:16:07.680]   And so we would love to see a lot more tooling to actually make it easier and easier to build servers, both for enterprises that are deploying MCPs internally as interfaces between teams and for indie hackers and everything in between that are building MCPs for external users.
[00:16:07.680 --> 00:16:15.680]   So anything from hosting tooling, testing tooling, evals, deployment, et cetera.
[00:16:15.680 --> 00:16:26.680]   And then I snuck a bullet in here that's maybe a little bit more of a moonshot and a bet on the future, but there's a bullet for automated MCP server generation.
[00:16:26.680 --> 00:16:46.680]   And again, if you kind of think back to our bet on model intelligence and model agency for the future, at some point models will be so good writing code and interacting with the external world that they will actually be able to write their own MCPs on the fly in real time.
[00:16:46.680 --> 00:16:59.680]   And so this might be a little early for where we are today, but I do think that there will be an opportunity for automated MCP generation as models get smarter and smarter.
[00:16:59.680 --> 00:17:09.680]   And last but not least, I wanted to do a quick call out for any tooling around AI security, observability, auditing, et cetera.
[00:17:09.680 --> 00:17:12.680]   I don't think this is actually specific to MCP.
[00:17:12.680 --> 00:17:26.680]   This is true for any AI application, but I think the more that you enable those applications to have access to the outside world, to start playing with real data, of course, the security and privacy, et cetera, implications also go up.
[00:17:26.680 --> 00:17:34.680]   And so I think if you're going to build a startup in that space, now is the time.
[00:17:34.680 --> 00:17:36.680]   So with that, happy MCP-ing.
[00:17:36.680 --> 00:17:37.680]   Thank you.
[00:17:37.680 --> 00:17:44.680]   Thank you.

