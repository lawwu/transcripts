
[00:00:00.000 --> 00:00:06.040]   And so now you have this really rich record of everything in the PR that's associated
[00:00:06.040 --> 00:00:07.040]   with that PR.
[00:00:07.040 --> 00:00:14.640]   And it's getting closer to proper software engineering practices where you have the test
[00:00:14.640 --> 00:00:20.440]   as automatically conducted from the PR itself and you have all the documentation there.
[00:00:20.440 --> 00:00:24.280]   You're listening to Gradient Dissent, a show where we learn about making machine learning
[00:00:24.280 --> 00:00:25.940]   models work in the real world.
[00:00:25.940 --> 00:00:28.040]   I'm your host, Lukas Biewald.
[00:00:28.040 --> 00:00:32.640]   I love talking to Hamel Hussain because he likes making tools for machine learning practitioners
[00:00:32.640 --> 00:00:34.840]   the same way I do.
[00:00:34.840 --> 00:00:39.320]   He's currently working at GitHub, but before that he's built large data science teams at
[00:00:39.320 --> 00:00:43.680]   Airbnb, DataRobot, and a whole bunch of other really successful companies.
[00:00:43.680 --> 00:00:45.080]   I can't wait to talk to him.
[00:00:45.080 --> 00:00:48.160]   So Hamel, thanks so much for taking the time to talk today.
[00:00:48.160 --> 00:00:51.680]   You're one of the first guests that we've had that I've actually worked with before.
[00:00:51.680 --> 00:00:53.220]   So we have a lot to talk about.
[00:00:53.220 --> 00:00:56.400]   And I thought, you know, the cool thing that we worked on, which I'd just love for you
[00:00:56.400 --> 00:01:01.240]   to describe is the CodeSearchNet project that you spearheaded.
[00:01:01.240 --> 00:01:05.520]   Can you just describe for somebody who doesn't know what it is, what it is and what the goals
[00:01:05.520 --> 00:01:06.520]   are?
[00:01:06.520 --> 00:01:07.520]   Yeah.
[00:01:07.520 --> 00:01:13.040]   So GitHub has a large corpus of code, as you might imagine.
[00:01:13.040 --> 00:01:19.040]   You know, there's all these open source repositories and many different languages.
[00:01:19.040 --> 00:01:26.200]   And in the machine learning community, natural language processing is a really exciting space,
[00:01:26.200 --> 00:01:28.240]   especially with deep learning.
[00:01:28.240 --> 00:01:36.200]   And you know, there's a lot of there's a few data sets that people really like for that.
[00:01:36.200 --> 00:01:45.080]   But one that sort of hasn't been paid attention to much is perhaps, you know, large corpus
[00:01:45.080 --> 00:01:46.880]   of GitHub data.
[00:01:46.880 --> 00:01:50.680]   And the thing is, like, that data is open, is already open.
[00:01:50.680 --> 00:01:51.680]   It's already open source.
[00:01:51.680 --> 00:01:56.320]   But it can the barrier to entry is kind of high, especially when you're talking about
[00:01:56.320 --> 00:02:02.440]   code to tokenize code or parse code is very complicated, especially when a strip out comments
[00:02:02.440 --> 00:02:05.040]   or do something like that.
[00:02:05.040 --> 00:02:11.160]   So internally, I get hoping at a project where we wanted to explore representation learning
[00:02:11.160 --> 00:02:19.640]   of code and kind of explore the possibilities to see if we could represent, learn a representation
[00:02:19.640 --> 00:02:20.640]   of code.
[00:02:20.640 --> 00:02:24.040]   And what exactly, sorry, what do you mean by like a representation of the code, like
[00:02:24.040 --> 00:02:25.040]   some abstract representation?
[00:02:25.040 --> 00:02:27.080]   Or how do you think about that?
[00:02:27.080 --> 00:02:28.080]   Oh, yeah, sorry.
[00:02:28.080 --> 00:02:35.720]   I mean, in a very canonical machine learning sense, like learning and embedding of code.
[00:02:35.720 --> 00:02:37.640]   So that aligns with natural language.
[00:02:37.640 --> 00:02:43.120]   That was one of the experiments that we wanted to try to then see if we could use that to
[00:02:43.120 --> 00:02:44.640]   boost search results.
[00:02:44.640 --> 00:02:50.200]   So someone types in a query, you know, a lot of people don't like GitHub search, understandably.
[00:02:50.200 --> 00:02:55.480]   And, you know, if you're trying to search for code, you have to right now you it's keyword
[00:02:55.480 --> 00:02:56.480]   search.
[00:02:56.480 --> 00:03:00.720]   So you have to have a good idea of what the syntax is, or what keywords may be in the
[00:03:00.720 --> 00:03:03.040]   code that you're trying to find.
[00:03:03.040 --> 00:03:06.400]   But what if, what if you don't know that?
[00:03:06.400 --> 00:03:10.400]   What if you're trying to search for some kind of concept in a code?
[00:03:10.400 --> 00:03:12.240]   You know, is that possible?
[00:03:12.240 --> 00:03:20.600]   And so we started exploring that to see if it would be possible, perhaps to use machine
[00:03:20.600 --> 00:03:27.760]   learning to, to learn some, you know, an embedding of code to then, you know, do some kind of
[00:03:27.760 --> 00:03:30.160]   semantic search.
[00:03:30.160 --> 00:03:38.080]   So one of the one of the interesting parts about that is, you might wonder, how would
[00:03:38.080 --> 00:03:39.360]   you go about doing that?
[00:03:39.360 --> 00:03:43.280]   How would you go about learning some embeddings of code?
[00:03:43.280 --> 00:03:50.440]   And so kind of stealing a lot of ideas from natural language processing, you know, that
[00:03:50.440 --> 00:03:56.120]   so it's useful natural language processing, if you have parallel corpus of, you know,
[00:03:56.120 --> 00:04:01.280]   let's say one language to another language, like a language translation.
[00:04:01.280 --> 00:04:06.520]   So so we thought about that and said, that's interesting.
[00:04:06.520 --> 00:04:11.360]   I wonder if we could do that with code, since there is a lot of natural language happens
[00:04:11.360 --> 00:04:16.680]   to be inside code and specifically comments of code, where people naturally are sort of
[00:04:16.680 --> 00:04:19.040]   labeling what code does.
[00:04:19.040 --> 00:04:25.000]   And so now this is a tough problem, because, you know, comments can be everywhere.
[00:04:25.000 --> 00:04:26.960]   They're not necessarily in the same place.
[00:04:26.960 --> 00:04:32.400]   They're not necessarily at the same level of granularity, or in the same format.
[00:04:32.400 --> 00:04:37.760]   And so what we did is, we kind of scoped down the problem to methods and functions in various
[00:04:37.760 --> 00:04:44.300]   languages and looked at sort of the doc strings or what what is equivalent to a doc string
[00:04:44.300 --> 00:04:51.080]   in Python, which is some comment that documents what that function is doing.
[00:04:51.080 --> 00:04:56.160]   So we constructed a large parallel corpus of all of these things.
[00:04:56.160 --> 00:04:57.960]   And we did some experimentation.
[00:04:57.960 --> 00:05:01.480]   And it was a really exciting project.
[00:05:01.480 --> 00:05:06.920]   It kind of, we had to kind of stop in the middle.
[00:05:06.920 --> 00:05:12.160]   For various reasons, as sometimes happens with machine learning projects that, you know,
[00:05:12.160 --> 00:05:14.760]   are ambitious like this.
[00:05:14.760 --> 00:05:22.080]   But in doing so, we thought, we should open source the data, and we should kind of present
[00:05:22.080 --> 00:05:27.200]   the results we have and give it to the community so they can take it forward from there.
[00:05:27.200 --> 00:05:33.840]   So the CodeSearchNet challenge is a large corpus, this large parallel corpus of code
[00:05:33.840 --> 00:05:36.120]   in natural language.
[00:05:36.120 --> 00:05:44.360]   And it's benchmarks of our attempt at doing information retrieval.
[00:05:44.360 --> 00:05:49.320]   So given a query of some kind, can you identify the piece of code that goes with that?
[00:05:49.320 --> 00:05:55.320]   So in this case, given a doc string, can you find the code that is paired with that originally?
[00:05:55.320 --> 00:06:00.560]   So the benchmark is an information retrieval task.
[00:06:00.560 --> 00:06:06.360]   And so we thought, okay, even though we're pausing on this for a moment, we know that
[00:06:06.360 --> 00:06:09.760]   everybody is interested in this.
[00:06:09.760 --> 00:06:13.520]   Not everybody, but a lot of people may be interested in this.
[00:06:13.520 --> 00:06:20.440]   We saw people, various research labs, kind of doing, exploring similar problems.
[00:06:20.440 --> 00:06:26.120]   So we thought, okay, we should get in the mix being GitHub.
[00:06:26.120 --> 00:06:31.200]   And so that was kind of the impetus to release this dataset.
[00:06:31.200 --> 00:06:43.120]   And of course, we had a wonderful partnership with Weights and Biases who hosts the benchmarks,
[00:06:43.120 --> 00:06:50.400]   the leaderboard of the different submissions that people have and improvements to the model.
[00:06:50.400 --> 00:06:54.680]   And the thing that I really, really like about Weights and Biases is the transparency.
[00:06:54.680 --> 00:07:01.720]   So in Kaggle competitions, you only really get to see what is behind the scenes if the
[00:07:01.720 --> 00:07:03.360]   author chooses to release the code.
[00:07:03.360 --> 00:07:05.600]   But Weights and Biases, you can see all kinds of detail.
[00:07:05.600 --> 00:07:08.320]   It's very transparent.
[00:07:08.320 --> 00:07:11.440]   And you get very rich logs of what happened during the training process.
[00:07:11.440 --> 00:07:13.080]   So that's really helpful.
[00:07:13.080 --> 00:07:15.960]   And I think the whole community can see that.
[00:07:15.960 --> 00:07:19.320]   And I think that helps drive that forward.
[00:07:19.320 --> 00:07:25.560]   So just to clarify, so the challenge is to sort of find the code that best matches the
[00:07:25.560 --> 00:07:26.560]   docstring?
[00:07:26.560 --> 00:07:27.560]   Yeah.
[00:07:27.560 --> 00:07:29.320]   So there's a couple of different tasks.
[00:07:29.320 --> 00:07:31.240]   So there's one task.
[00:07:31.240 --> 00:07:37.520]   So matching a docstring to code is sort of a proxy for what...
[00:07:37.520 --> 00:07:42.320]   So like a search query may not look like a docstring.
[00:07:42.320 --> 00:07:43.320]   Probably doesn't.
[00:07:43.320 --> 00:07:44.320]   Totally.
[00:07:44.320 --> 00:07:50.960]   And so that task is pairing the docstring with the original code is a proxy for search.
[00:07:50.960 --> 00:07:57.400]   So we also have some actual search queries that people have done against Bing.
[00:07:57.400 --> 00:08:00.920]   Since we're in Microsoft, we could pull that.
[00:08:00.920 --> 00:08:07.640]   And we have some ways of finding out what page they landed on.
[00:08:07.640 --> 00:08:12.480]   And if that was kind of inferred, that was the thing they were looking for.
[00:08:12.480 --> 00:08:17.840]   So we have another test set that is actual queries from a search engine.
[00:08:17.840 --> 00:08:25.560]   Even that is not perfect because the task that we would want to simulate is a more scoped
[00:08:25.560 --> 00:08:31.160]   search of code, not a global search like on Google or Bing of how to do something.
[00:08:31.160 --> 00:08:32.800]   I think that's a solved problem.
[00:08:32.800 --> 00:08:35.600]   That works really well, at least for me.
[00:08:35.600 --> 00:08:39.840]   So I would say the task isn't perfect.
[00:08:39.840 --> 00:08:43.000]   But we sort of did whatever we could in the time we had.
[00:08:43.000 --> 00:08:45.360]   I think it's awesome that you released the data.
[00:08:45.360 --> 00:08:49.840]   But the idea is, since we worked together, I think I kind of understand it.
[00:08:49.840 --> 00:08:58.840]   It's like, I searched for some algorithm, maybe like insertion sort, and then I mapped
[00:08:58.840 --> 00:09:00.840]   that to code that actually does insertion sort.
[00:09:00.840 --> 00:09:06.120]   So maybe there's some embedding space that's like the sort of embedding of insertion sort.
[00:09:06.120 --> 00:09:07.120]   Right?
[00:09:07.120 --> 00:09:08.120]   Yeah, absolutely.
[00:09:08.120 --> 00:09:12.680]   So even if it doesn't contain the word insertion or sort, you can still find that code.
[00:09:12.680 --> 00:09:13.680]   Because it does that.
[00:09:13.680 --> 00:09:16.320]   Yeah, because it does that.
[00:09:16.320 --> 00:09:22.840]   And that's the idea, is to enhance discoverability of code to do various things.
[00:09:22.840 --> 00:09:23.840]   So it's super cool.
[00:09:23.840 --> 00:09:30.080]   We'll put a link to some materials so folks can find that, that are more interested.
[00:09:30.080 --> 00:09:35.680]   Hi, we'd love to take a moment to tell you guys about Weights and Biases.
[00:09:35.680 --> 00:09:41.200]   Weights and Biases is a tool that helps you track and visualize every detail of your machine
[00:09:41.200 --> 00:09:42.200]   learning models.
[00:09:42.200 --> 00:09:48.160]   We help you debug your machine learning models in real time, collaborate easily, and advance
[00:09:48.160 --> 00:09:51.240]   the state of the art in machine learning.
[00:09:51.240 --> 00:09:56.440]   You can integrate Weights and Biases into your models with just a few lines of code.
[00:09:56.440 --> 00:10:01.200]   With hyperparameter sweeps, you can find the best set of hyperparameters for your models
[00:10:01.200 --> 00:10:03.120]   automatically.
[00:10:03.120 --> 00:10:08.520]   You can also track and compare how many GPU resources your models are using.
[00:10:08.520 --> 00:10:14.560]   With one line of code, you can visualize model predictions in the form of images, videos,
[00:10:14.560 --> 00:10:20.960]   audio, plotly charts, molecular data, segmentation maps, and 3D point clouds.
[00:10:20.960 --> 00:10:26.800]   You can save everything you need to reproduce your models days, weeks, or even months after
[00:10:26.800 --> 00:10:27.800]   training.
[00:10:27.800 --> 00:10:32.920]   Finally, with reports, you can make your models come alive.
[00:10:32.920 --> 00:10:37.920]   Reports are like blog posts in which your readers can interact with your model metrics
[00:10:37.920 --> 00:10:39.720]   and predictions.
[00:10:39.720 --> 00:10:45.960]   Reports serve as a centralized repository of metrics, predictions, hyperparameter stride,
[00:10:45.960 --> 00:10:47.680]   and accompanying notes.
[00:10:47.680 --> 00:10:53.360]   All of this together gives you a bird's eye view of your machine learning workflow.
[00:10:53.360 --> 00:10:58.860]   You can use reports to share your model insights, keep your team on the same page, and collaborate
[00:10:58.860 --> 00:11:00.920]   effectively remotely.
[00:11:00.920 --> 00:11:05.000]   I'll leave a link in the show notes below to help you get started.
[00:11:05.000 --> 00:11:07.600]   And now let's get back to the episode.
[00:11:07.600 --> 00:11:11.280]   So we actually haven't talked about this, but I was kind of looking at your background
[00:11:11.280 --> 00:11:16.800]   and I was seeing that you worked at DataRobot and you wrote about AutoML.
[00:11:16.800 --> 00:11:18.680]   This is another question we get all the time.
[00:11:18.680 --> 00:11:21.640]   What do you sort of think is the state of AutoML?
[00:11:21.640 --> 00:11:23.680]   Is it something you use in practice?
[00:11:23.680 --> 00:11:25.880]   Would you recommend it to people?
[00:11:25.880 --> 00:11:26.880]   When is it useful?
[00:11:26.880 --> 00:11:27.880]   When is it not useful?
[00:11:27.880 --> 00:11:28.880]   What do you think?
[00:11:28.880 --> 00:11:33.980]   I think AutoML is really misunderstood a lot of times.
[00:11:33.980 --> 00:11:37.960]   Maybe define it first because we might be talking about different things.
[00:11:37.960 --> 00:11:40.920]   I think we're talking about the same thing, but I'll define it just for clarity.
[00:11:40.920 --> 00:11:48.480]   So I would say AutoML are tools that help you automate your machine learning pipeline
[00:11:48.480 --> 00:11:49.880]   as much as possible.
[00:11:49.880 --> 00:11:52.080]   And that can mean various different things.
[00:11:52.080 --> 00:11:55.280]   And obviously that definition has a very large scope.
[00:11:55.280 --> 00:11:58.800]   Of course, you can automate some parts of your machine learning pipeline.
[00:11:58.800 --> 00:12:02.080]   You can try to automate the whole machine learning pipeline.
[00:12:02.080 --> 00:12:04.840]   What part are you automating exactly?
[00:12:04.840 --> 00:12:06.920]   That kind of gets into the weeds.
[00:12:06.920 --> 00:12:17.120]   But I would say something that sufficiently automates a lot of it, you can kind of bucket
[00:12:17.120 --> 00:12:18.480]   that into AutoML.
[00:12:18.480 --> 00:12:24.680]   But even that is, I don't know if there's like an official, there's an organization
[00:12:24.680 --> 00:12:26.240]   that has a definition.
[00:12:26.240 --> 00:12:33.240]   I don't remember it off the top of my head, but that's the way I would define it personally.
[00:12:33.240 --> 00:12:34.920]   So you're right.
[00:12:34.920 --> 00:12:43.000]   I did work at DataRobot, who is a company that has a piece of software, software as
[00:12:43.000 --> 00:12:44.000]   a service.
[00:12:44.000 --> 00:12:51.760]   And they're one of the first kind of folks to really kind of put AutoML out there.
[00:12:51.760 --> 00:12:59.760]   I would say before DataRobot, tools that you may have seen are, I think it was called Weka
[00:12:59.760 --> 00:13:01.600]   or AutoWeka, Weka.
[00:13:01.600 --> 00:13:04.800]   And then maybe RapidMiner was one that was popular.
[00:13:04.800 --> 00:13:11.200]   Things that sort of automate the machine learning pipeline.
[00:13:11.200 --> 00:13:18.840]   So kind of to drill in a little bit more, what DataRobot does is, you feed it a prepared
[00:13:18.840 --> 00:13:21.040]   set of data.
[00:13:21.040 --> 00:13:26.080]   And so you've already done tons of work before getting to this process.
[00:13:26.080 --> 00:13:30.400]   And you have a target variable and all these features.
[00:13:30.400 --> 00:13:37.600]   And so what DataRobot does is it tries a lot of feature engineering steps, kind of like
[00:13:37.600 --> 00:13:43.200]   almost problem agnostic feature engineering steps.
[00:13:43.200 --> 00:13:47.920]   And it tries many different algorithms, all from open source, and it benchmarks them against
[00:13:47.920 --> 00:13:48.920]   each other.
[00:13:48.920 --> 00:13:54.200]   And it does lots of diagnostics, like an incredible amount of diagnostics on your data.
[00:13:54.200 --> 00:13:58.320]   And then kind of gives you a leaderboard of all these different models.
[00:13:58.320 --> 00:14:02.800]   Again, they're all open, like from open source.
[00:14:02.800 --> 00:14:05.960]   And that's like one flavor of that.
[00:14:05.960 --> 00:14:06.960]   There's other people that do this.
[00:14:06.960 --> 00:14:15.040]   So like H2O has product where they have, I think they call it AutoML, or self-driving
[00:14:15.040 --> 00:14:16.120]   ML or something like that.
[00:14:16.120 --> 00:14:18.200]   I don't know what it's exactly.
[00:14:18.200 --> 00:14:21.320]   But they do something like this.
[00:14:21.320 --> 00:14:28.600]   And so when people, the reason why AutoML is misunderstood is people say, people think
[00:14:28.600 --> 00:14:35.860]   of it in a certain, kind of put it in a box and they say, you know, this can't replace
[00:14:35.860 --> 00:14:37.400]   a data scientist.
[00:14:37.400 --> 00:14:42.840]   Or the objection is, you know, why would I, you know, I can beat this thing.
[00:14:42.840 --> 00:14:44.760]   I have domain knowledge.
[00:14:44.760 --> 00:14:51.960]   Why would I want to use an AutoML system when, you know, I can build a model with my domain
[00:14:51.960 --> 00:14:55.880]   understanding kind of to fit the needs better.
[00:14:55.880 --> 00:15:00.160]   But what is, why would someone want to use AutoML?
[00:15:00.160 --> 00:15:02.760]   And so that's the common misunderstanding.
[00:15:02.760 --> 00:15:09.660]   And so I wrote about this when I was at Airbnb, the blog you're referencing.
[00:15:09.660 --> 00:15:14.760]   And I think the way that it's used most effectively is to really augment a data scientist.
[00:15:14.760 --> 00:15:19.920]   You might not use any of the models produced from the AutoML system, which kind of sounds
[00:15:19.920 --> 00:15:21.240]   ironic.
[00:15:21.240 --> 00:15:25.660]   But really, the AutoML system gives you a lot of information at the very beginning.
[00:15:25.660 --> 00:15:29.300]   So I think it's really important to have a baseline.
[00:15:29.300 --> 00:15:34.040]   And the better your baseline, like the more, the better off you are.
[00:15:34.040 --> 00:15:40.560]   And so you can use AutoML system to give you a pretty competitive baseline to begin with.
[00:15:40.560 --> 00:15:44.620]   The reason that a lot of people use, you know, linear regression or something or some simple
[00:15:44.620 --> 00:15:49.780]   model or just the average as, you know, baseline or whatever it might be, is, you know, that's
[00:15:49.780 --> 00:15:52.880]   easy to do and you need a baseline to compare what's going on.
[00:15:52.880 --> 00:15:54.060]   So that's helpful.
[00:15:54.060 --> 00:15:58.780]   And then also you get a lot of diagnostics, you get a lot of things, you know, something
[00:15:58.780 --> 00:16:01.700]   that automatically explores your data set and you can read.
[00:16:01.700 --> 00:16:07.180]   You're just getting more information about the task at hand.
[00:16:07.180 --> 00:16:13.060]   And if you do that, you can use that information really effectively to go and build your own
[00:16:13.060 --> 00:16:18.860]   custom model and kind of start with some more hypotheses about, you know, what might work
[00:16:18.860 --> 00:16:22.300]   or what might not work or invalidate some hypotheses.
[00:16:22.300 --> 00:16:28.220]   I mean, it's not uncommon to hear, I hear this all the time, you know, data scientists
[00:16:28.220 --> 00:16:32.420]   will say, you know what, random forest, they don't really work on this model or on this
[00:16:32.420 --> 00:16:37.940]   data set or, you know, whatever neural nets, they don't work.
[00:16:37.940 --> 00:16:43.660]   But you know, what if the AutoML system, like, has much better results than you did and uses
[00:16:43.660 --> 00:16:44.820]   that model?
[00:16:44.820 --> 00:16:45.820]   That's really interesting.
[00:16:45.820 --> 00:16:46.820]   Like, why did that happen?
[00:16:46.820 --> 00:16:49.700]   That happens like, fair amount, a number of times.
[00:16:49.700 --> 00:16:54.980]   Like when I was at Airbnb, which is, you know, has a lot of talented people, you know, it's
[00:16:54.980 --> 00:17:02.260]   really interesting, like sometimes AutoML system would give you some result that was
[00:17:02.260 --> 00:17:05.340]   kind of something you didn't expect.
[00:17:05.340 --> 00:17:09.420]   And so I think that it's just really interesting.
[00:17:09.420 --> 00:17:12.500]   It's a way of using AutoML.
[00:17:12.500 --> 00:17:18.500]   I don't really see AutoML replacing data scientists, but I see it's like an incredibly useful tool.
[00:17:18.500 --> 00:17:24.580]   I mean, just even in doing lots of exploratory data analysis, I know that sounds trivial
[00:17:24.580 --> 00:17:30.420]   or easy, but just to have something that does that really nicely for you and gives you all
[00:17:30.420 --> 00:17:36.540]   kinds of statistics and metrics and like all kinds of graphs just for free is just a head
[00:17:36.540 --> 00:17:37.540]   start.
[00:17:37.540 --> 00:17:40.020]   So that's kind of my spiel on AutoML.
[00:17:40.020 --> 00:17:41.020]   It's kind of interesting.
[00:17:41.020 --> 00:17:47.380]   Do you make a distinction between AutoML and hyperparameter optimization?
[00:17:47.380 --> 00:17:52.540]   I think hyperparameter optimization is part of AutoML.
[00:17:52.540 --> 00:17:57.700]   Like if something is really AutoML, it should also be doing hyperparameter optimization
[00:17:57.700 --> 00:18:01.700]   and that's what a lot of these AutoML frameworks do.
[00:18:01.700 --> 00:18:11.140]   And so, yeah, I mean, but I wouldn't say hyperparameter tuning on its own is what I would just call
[00:18:11.140 --> 00:18:12.140]   AutoML.
[00:18:12.140 --> 00:18:17.100]   I mean, this word AutoML is, like I said, very hard to define.
[00:18:17.100 --> 00:18:22.020]   But it's definitely something that should be included in there.
[00:18:22.020 --> 00:18:24.300]   But what extra stuff does it do?
[00:18:24.300 --> 00:18:25.660]   Try different algorithms, you mean?
[00:18:25.660 --> 00:18:28.060]   Or what does it do on top of that?
[00:18:28.060 --> 00:18:29.060]   Yeah.
[00:18:29.060 --> 00:18:32.820]   So a lot of the magic of, let's say, for example, DataRobot, because I'm really familiar with
[00:18:32.820 --> 00:18:35.460]   that product.
[00:18:35.460 --> 00:18:38.200]   It does a lot of feature engineering.
[00:18:38.200 --> 00:18:42.700]   So it's built by people that are grandmasters at Kaggle.
[00:18:42.700 --> 00:18:49.300]   They have like three or four, or actually more, former grandmasters and then a lot more
[00:18:49.300 --> 00:18:52.340]   people close to that.
[00:18:52.340 --> 00:19:00.820]   And they've taken all their experience of winning these competitions and put a lot of
[00:19:00.820 --> 00:19:02.260]   recipes in there.
[00:19:02.260 --> 00:19:10.300]   So things like, OK, if you're using a tree-based model, here are some feature engineering steps
[00:19:10.300 --> 00:19:11.300]   to try.
[00:19:11.300 --> 00:19:15.780]   If your data contains text, let's try these feature engineering steps.
[00:19:15.780 --> 00:19:19.820]   If your data looks like this, let's try something else.
[00:19:19.820 --> 00:19:26.380]   It's like a lot of these rules built in, but also it's a lot of different recipes.
[00:19:26.380 --> 00:19:33.700]   Includes things like model stacking, model ensembling models.
[00:19:33.700 --> 00:19:37.180]   Includes hyperparameter tuning.
[00:19:37.180 --> 00:19:41.300]   And so it's an incredible amount of diagnostics.
[00:19:41.300 --> 00:19:49.740]   So you get feature importance type of stuff in many different ways.
[00:19:49.740 --> 00:19:55.260]   You get a lot of model explainability stuff.
[00:19:55.260 --> 00:19:59.340]   And so all that information is pretty useful, regardless of what model you're going to go
[00:19:59.340 --> 00:20:04.820]   with to understand something really fast.
[00:20:04.820 --> 00:20:05.820]   And so, yeah.
[00:20:05.820 --> 00:20:11.260]   It's kind of interesting because I feel like a lot of people think of AutoML as a way to
[00:20:11.260 --> 00:20:15.180]   just sort of get the best model.
[00:20:15.180 --> 00:20:16.180]   And yeah, it's funny.
[00:20:16.180 --> 00:20:22.300]   I sort of tell people that I also share your view that it's a good way to do exploration,
[00:20:22.300 --> 00:20:25.260]   or at least hyperparameter search, I think is a great way to sort of understand the domain
[00:20:25.260 --> 00:20:26.260]   you're in.
[00:20:26.260 --> 00:20:30.780]   But I guess, you know, maybe it's because Google has that AutoML product where you actually
[00:20:30.780 --> 00:20:31.780]   don't get a lot of data.
[00:20:31.780 --> 00:20:37.220]   I think you just get the best model out of it.
[00:20:37.220 --> 00:20:42.020]   Sometimes I think of AutoML specifically as just a way to find the best model.
[00:20:42.020 --> 00:20:47.380]   But of course, if you get to see all the different runs and how they did, that would be incredibly
[00:20:47.380 --> 00:20:49.820]   useful to learn about your dataset.
[00:20:49.820 --> 00:20:51.140]   Yeah, I agree.
[00:20:51.140 --> 00:20:56.180]   And yeah, some products, I think they actually kind of think of, maybe they've designed it
[00:20:56.180 --> 00:21:00.060]   in such a way where they think of it as a black box and just give you the best model.
[00:21:00.060 --> 00:21:03.340]   I don't really think that's that incredibly useful.
[00:21:03.340 --> 00:21:04.340]   Why isn't that useful though?
[00:21:04.340 --> 00:21:09.060]   I mean, because, you know, I think a lot of, you know, from like a business owner's perspective,
[00:21:09.060 --> 00:21:12.900]   they might be like, awesome, like it's a pain in the ass to make models.
[00:21:12.900 --> 00:21:14.740]   Let me just get it done with this.
[00:21:14.740 --> 00:21:16.700]   Well, I would say it is still useful.
[00:21:16.700 --> 00:21:19.340]   I agree with you, but it's not as useful.
[00:21:19.340 --> 00:21:24.260]   I mean, I would say being able to see everything and learn from it is kind of a lot of value
[00:21:24.260 --> 00:21:25.260]   added.
[00:21:25.260 --> 00:21:31.020]   I mean, you can still build it and not look at it, all that stuff if you want to.
[00:21:31.020 --> 00:21:33.140]   But I find it to be useful as a data scientist.
[00:21:33.140 --> 00:21:41.460]   I've found that it makes me a lot better and kind of helps to check some stuff.
[00:21:41.460 --> 00:21:47.740]   When you were working at DataRobot, do you think most teams were using DataRobot more
[00:21:47.740 --> 00:21:53.100]   for an exploratory use case or for like an optimization purpose?
[00:21:53.100 --> 00:21:55.900]   It was pretty mixed.
[00:21:55.900 --> 00:22:01.900]   So I worked with a lot of customers there and people were using it to sort of, so a
[00:22:01.900 --> 00:22:07.060]   lot of people already had a model in production of some kind and, you know, they just wanted
[00:22:07.060 --> 00:22:09.500]   to, and that was a really excellent use case.
[00:22:09.500 --> 00:22:14.500]   I mean, just plug that data in DataRobot and see, you know, what's going on.
[00:22:14.500 --> 00:22:16.060]   And that was a really popular use case.
[00:22:16.060 --> 00:22:20.580]   Another one was, okay, you don't know how to get started.
[00:22:20.580 --> 00:22:25.060]   You're kind of taking a long time to build a model, you want to use this.
[00:22:25.060 --> 00:22:30.620]   And people use that, a lot of people actually use the product to learn about, help learn
[00:22:30.620 --> 00:22:31.620]   about data science.
[00:22:31.620 --> 00:22:38.900]   Like, because it was so transparent, you know, they could see like all the steps, what you
[00:22:38.900 --> 00:22:44.060]   did, you know, and, you know, they would learn about like, kind of like the workflow.
[00:22:44.060 --> 00:22:50.980]   But yeah, I think, you know, there was a mix between sort of taking something you already
[00:22:50.980 --> 00:22:56.580]   have, putting it there and exploring.
[00:22:56.580 --> 00:23:01.480]   I would say people that already had data scientists, like experienced ones, they found it really
[00:23:01.480 --> 00:23:06.020]   useful to get new ideas that like they didn't consider before.
[00:23:06.020 --> 00:23:07.020]   Makes sense.
[00:23:07.020 --> 00:23:08.020]   All right.
[00:23:08.020 --> 00:23:10.220]   So, so what are you, what are you working on now?
[00:23:10.220 --> 00:23:12.380]   It's a, what's your day like?
[00:23:12.380 --> 00:23:14.340]   Can I guess, I'm just following your Twitter.
[00:23:14.340 --> 00:23:15.900]   I haven't talked to you in a while.
[00:23:15.900 --> 00:23:19.940]   It seems like you are really into GitHub Actions that I don't totally understand, but I want
[00:23:19.940 --> 00:23:20.940]   to learn.
[00:23:20.940 --> 00:23:24.940]   Oh yeah, that's a great question.
[00:23:24.940 --> 00:23:28.300]   I mean, I didn't try to be, but it kind of just worked out that way.
[00:23:28.300 --> 00:23:30.660]   So you're absolutely right.
[00:23:30.660 --> 00:23:36.300]   Kind of become the GitHub Actions person for data science by accident, I think.
[00:23:36.300 --> 00:23:44.140]   So yeah, to answer your question, I'm really interested in tools that can help data scientists
[00:23:44.140 --> 00:23:45.140]   building those.
[00:23:45.140 --> 00:23:51.020]   That's why I like talking to you so much, because you're also interested in that.
[00:23:51.020 --> 00:23:57.860]   And so some of the things, so, I mean, that's kind of what, what I was doing, or why I was
[00:23:57.860 --> 00:23:59.380]   interested in working at DataRobot.
[00:23:59.380 --> 00:24:02.500]   And I did a lot of that at Airbnb.
[00:24:02.500 --> 00:24:07.600]   And then at GitHub, I'm doing that also.
[00:24:07.600 --> 00:24:15.220]   And so one of the things that I've tried to do is use, to find ways, kind of in the short
[00:24:15.220 --> 00:24:21.140]   term, there's some long-term things I'm working on, which, you know, we're exploring, but
[00:24:21.140 --> 00:24:25.260]   kind of in the short term, like what can I do right now with the products that GitHub
[00:24:25.260 --> 00:24:31.100]   already has to make data science easier?
[00:24:31.100 --> 00:24:34.400]   And so it's being creative and trying to figure out what I can provide.
[00:24:34.400 --> 00:24:37.000]   So like, there's a couple examples of that.
[00:24:37.000 --> 00:24:47.060]   One is CI/CD, continuous integration and delivery for machine learning workflows.
[00:24:47.060 --> 00:24:50.860]   So GitHub launched Actions, as you alluded to.
[00:24:50.860 --> 00:24:59.420]   And so, you know, when I saw that launch, I realized that there's an opportunity to
[00:24:59.420 --> 00:25:06.420]   construct a CI/CD sort of plugins that will allow people to have machine learning workflows
[00:25:06.420 --> 00:25:11.100]   that kind of, or that have CI/CD workflows for machine learning.
[00:25:11.100 --> 00:25:18.540]   And you just, just because I think a lot of people might not know, including kind of myself,
[00:25:18.540 --> 00:25:22.460]   what is a GitHub Action and why is it useful for this?
[00:25:22.460 --> 00:25:25.020]   Yeah, that's a good question.
[00:25:25.020 --> 00:25:33.700]   So GitHub Action, on the surface, GitHub Actions look like another CI/CD system like Travis
[00:25:33.700 --> 00:25:42.420]   or CircleCI or something like that, you know, compute that you can run, triggered by some
[00:25:42.420 --> 00:25:44.420]   GitHub event.
[00:25:44.420 --> 00:25:45.740]   And this runs on GitHub?
[00:25:45.740 --> 00:25:47.700]   Yeah, this runs on GitHub.
[00:25:47.700 --> 00:25:52.920]   So but the way that it's differentiated is in a couple of ways.
[00:25:52.920 --> 00:26:01.540]   One is, so you can fire a GitHub Action to run on any event, almost any event, like,
[00:26:01.540 --> 00:26:07.540]   so an event means opening an issue, commenting on issue, opening a PR, labeling a PR, just
[00:26:07.540 --> 00:26:12.560]   think like almost anything that you can let happens on GitHub, you can trigger Actions
[00:26:12.560 --> 00:26:16.300]   to run arbitrary code based on that event.
[00:26:16.300 --> 00:26:22.340]   And then the reason why Actions is special is for like two primary reasons.
[00:26:22.340 --> 00:26:31.020]   One is all the metadata associated with like the event that triggered the Action is hydrated
[00:26:31.020 --> 00:26:33.500]   into the Actions environment.
[00:26:33.500 --> 00:26:37.420]   So like, if you want to know who commented on that PR, or whatever, that's super easy
[00:26:37.420 --> 00:26:41.340]   to do because it's available inside the environment.
[00:26:41.340 --> 00:26:49.700]   Secondly, is, let's say that you create a workflow that is super useful, something like,
[00:26:49.700 --> 00:26:57.660]   I'm going to run machine learning workflow, log my metrics to weights and biases.
[00:26:57.660 --> 00:27:04.060]   And then you report the metrics back into the PR in GitHub.
[00:27:04.060 --> 00:27:05.820]   So that's pretty, that's pretty useful.
[00:27:05.820 --> 00:27:09.740]   And so if you want to, you can kind of package it up a little bit.
[00:27:09.740 --> 00:27:16.700]   And you can say, okay, I have this workflow, it expects, it expects this input, like it
[00:27:16.700 --> 00:27:21.140]   inspects, it expects a run ID.
[00:27:21.140 --> 00:27:28.620]   And as an output, you know, it will, it will comment on the issue with this formatted table
[00:27:28.620 --> 00:27:30.180]   or something like that.
[00:27:30.180 --> 00:27:33.980]   I'm simplifying it, what really I mean, there's a really, we can talk about that.
[00:27:33.980 --> 00:27:37.700]   But and then I can just use your workflow, I don't have to know anything about how you
[00:27:37.700 --> 00:27:39.160]   did that.
[00:27:39.160 --> 00:27:42.260]   I can just say, hey, this action, this workflow is pretty cool.
[00:27:42.260 --> 00:27:47.260]   I just have to feed it a run ID and some like, you know, then it will do the same thing on
[00:27:47.260 --> 00:27:48.260]   my repo.
[00:27:48.260 --> 00:27:54.940]   So I can just reference your kind of packaged workflow from your repo.
[00:27:54.940 --> 00:27:57.100]   I don't have to install anything or do anything.
[00:27:57.100 --> 00:28:03.660]   And I can, so I can compose many different workflows together that do very modular things.
[00:28:03.660 --> 00:28:04.740]   Sorry, dumb question.
[00:28:04.740 --> 00:28:07.420]   So how do I, how would I pass in the run ID?
[00:28:07.420 --> 00:28:10.100]   Like where would that happen?
[00:28:10.100 --> 00:28:11.180]   Yeah.
[00:28:11.180 --> 00:28:21.220]   So with every step in an actions workflow, if you're using a packaged action, that, you
[00:28:21.220 --> 00:28:23.420]   know, you can, you can, there's inputs.
[00:28:23.420 --> 00:28:29.380]   So you can say, so that inputs can come from anywhere, you can hard code a string, or you
[00:28:29.380 --> 00:28:32.540]   can say that input can come from another step in the workflow.
[00:28:32.540 --> 00:28:33.540]   I see.
[00:28:33.540 --> 00:28:38.620]   And then so like for specifically for weights and biases, I happen to have, because I love
[00:28:38.620 --> 00:28:41.940]   weights and biases so much, I made an action that does this.
[00:28:41.940 --> 00:28:48.820]   So what happens is I actually logged the SHA, the commit SHA that ran that is associated
[00:28:48.820 --> 00:28:53.340]   with a machine learning workflow, and two weights and biases.
[00:28:53.340 --> 00:28:58.300]   And then when the, when the model is finished training, it takes that SHA and it pulls it
[00:28:58.300 --> 00:28:59.840]   from weights and biases.
[00:28:59.840 --> 00:29:02.340]   So that kind of becomes the input.
[00:29:02.340 --> 00:29:04.700]   And so that's one way of doing it.
[00:29:04.700 --> 00:29:08.460]   And then another thing I do is like when I deploy a model.
[00:29:08.460 --> 00:29:11.140]   So weights and biases puts a comment in my PR.
[00:29:11.140 --> 00:29:16.780]   It's a table of all the different runs and the run IDs from weights and biases.
[00:29:16.780 --> 00:29:23.180]   And then I just have a chat command, I say, you know, backslash deploy run ID.
[00:29:23.180 --> 00:29:27.180]   And then in actions, you know, I parse that command and I say, okay, like, give me the
[00:29:27.180 --> 00:29:33.540]   run ID and I pass it into another like action that then takes that run ID as an input.
[00:29:33.540 --> 00:29:39.300]   And then it goes out to weights and biases, downloads the model and it pushes it to my
[00:29:39.300 --> 00:29:40.300]   serving infrastructure.
[00:29:40.300 --> 00:29:41.900]   Well, I didn't know you did that.
[00:29:41.900 --> 00:29:43.900]   Can we give this to other customers?
[00:29:43.900 --> 00:29:46.900]   Yeah, I really would like to.
[00:29:46.900 --> 00:29:49.140]   I think it's super cool.
[00:29:49.140 --> 00:29:50.140]   Yeah, super cool.
[00:29:50.140 --> 00:29:52.900]   Like I think it's something I'm really excited about, actually.
[00:29:52.900 --> 00:29:53.900]   Nice.
[00:29:53.900 --> 00:29:54.900]   Well, you send me a link.
[00:29:54.900 --> 00:29:56.900]   I would love to play with it.
[00:29:56.900 --> 00:29:57.900]   Yeah.
[00:29:57.900 --> 00:29:58.900]   Sweet.
[00:29:58.900 --> 00:30:06.060]   So basically, GitHub Actions kind of lets you build developer workflows and you're using
[00:30:06.060 --> 00:30:09.620]   it to do essentially CI/CD for ML.
[00:30:09.620 --> 00:30:10.620]   Yeah.
[00:30:10.620 --> 00:30:12.740]   So let me kind of paint a more clear picture.
[00:30:12.740 --> 00:30:13.740]   Okay.
[00:30:13.740 --> 00:30:14.740]   Yeah, totally.
[00:30:14.740 --> 00:30:18.740]   And so imagine the scenario, like you may see it all the time.
[00:30:18.740 --> 00:30:22.700]   So you open a PR, you want to make a change to a model of some kind.
[00:30:22.700 --> 00:30:24.580]   Happens all the time.
[00:30:24.580 --> 00:30:30.100]   And you want a way to be able to see if this model is better than the baseline or whatever
[00:30:30.100 --> 00:30:32.460]   you might have in production.
[00:30:32.460 --> 00:30:34.500]   Now how do people do that today?
[00:30:34.500 --> 00:30:38.980]   Even if you have something really cool like weights and biases, that's still a separate
[00:30:38.980 --> 00:30:40.740]   system than GitHub.
[00:30:40.740 --> 00:30:44.420]   And you might have to go out to weights and biases and copy and paste the link into the
[00:30:44.420 --> 00:30:47.700]   PR, say, "Hey, I ran this code in there."
[00:30:47.700 --> 00:30:50.340]   But that's kind of prone to error.
[00:30:50.340 --> 00:30:52.100]   Like that might be a stale run.
[00:30:52.100 --> 00:30:53.860]   You might have changed the code since then.
[00:30:53.860 --> 00:30:54.860]   You never know.
[00:30:54.860 --> 00:30:55.860]   And it's all in different places.
[00:30:55.860 --> 00:31:00.500]   You want to go back to the PR, you know, depending, you know, that's like a manual process.
[00:31:00.500 --> 00:31:02.300]   It's not a good practice.
[00:31:02.300 --> 00:31:07.420]   So in machine learning, workflows can take a long time to run.
[00:31:07.420 --> 00:31:11.940]   It can take like, you know, a day, a week, whatever it might be.
[00:31:11.940 --> 00:31:16.460]   But sometimes you might want to do a full run before you merge some code.
[00:31:16.460 --> 00:31:22.960]   And so with GitHub Actions, what you can do is you can say, in your PR, I'm ready to test
[00:31:22.960 --> 00:31:25.340]   a full run of this model.
[00:31:25.340 --> 00:31:30.860]   And then you can issue a chat ops command, say run full test.
[00:31:30.860 --> 00:31:35.600]   And then your model runs on your infrastructure of your choice, logs to the experiment tracking
[00:31:35.600 --> 00:31:37.700]   system of your choice.
[00:31:37.700 --> 00:31:43.140]   And then it dumps metadata into the PR in form of comments and other things, where you
[00:31:43.140 --> 00:31:48.340]   can see all the results of the diagnostics of this model that you want.
[00:31:48.340 --> 00:31:53.060]   And then finally, you can decide to deploy this model or do anything else using another
[00:31:53.060 --> 00:31:55.700]   chat command, and then deploy it.
[00:31:55.700 --> 00:31:59.620]   And so now you have this really rich record of everything in the PR that's associated
[00:31:59.620 --> 00:32:00.620]   with that PR.
[00:32:00.620 --> 00:32:06.820]   And it's getting closer to proper software engineering practices, where you have like
[00:32:06.820 --> 00:32:12.980]   the test that's like automatically conducted from the PR itself, and you have all the documentation
[00:32:12.980 --> 00:32:13.980]   there.
[00:32:13.980 --> 00:32:17.660]   I've even talked to some Waste and Biases customers, what they do is they have Jupyter
[00:32:17.660 --> 00:32:22.380]   notebooks on the side and they copy and paste those Jupyter notebooks into the PRs.
[00:32:22.380 --> 00:32:24.100]   And this is to avoid all that stuff.
[00:32:24.100 --> 00:32:25.500]   So it just happens automatically.
[00:32:25.500 --> 00:32:26.940]   So I hope that helps.
[00:32:26.940 --> 00:32:27.940]   That was great.
[00:32:27.940 --> 00:32:28.940]   That was educational.
[00:32:28.940 --> 00:32:34.580]   And I think we should try to package up what you did and offer it to our customers.
[00:32:34.580 --> 00:32:35.580]   I think they would like it.
[00:32:35.580 --> 00:32:36.580]   Yeah.
[00:32:36.580 --> 00:32:37.580]   All right.
[00:32:37.580 --> 00:32:42.340]   Well, we've been talking for like half an hour, so we probably should wrap up with some
[00:32:42.340 --> 00:32:46.260]   final questions that we've been asking everybody and getting really interesting answers.
[00:32:46.260 --> 00:32:50.740]   So what is one underrated aspect of machine learning that you think people should pay
[00:32:50.740 --> 00:32:52.020]   more attention to?
[00:32:52.020 --> 00:32:58.100]   I actually think one of the highest impact areas you can try to work on as a data scientist
[00:32:58.100 --> 00:33:03.620]   or machine learning engineer is to build tools for other data scientists.
[00:33:03.620 --> 00:33:08.100]   And sometimes the tools, they don't have to be sexy.
[00:33:08.100 --> 00:33:12.340]   So there's another thing that I built called Fast Pages, which helps people share information
[00:33:12.340 --> 00:33:17.940]   and write blogs, which is like, sounds really unsexy and it really is very unsexy.
[00:33:17.940 --> 00:33:20.900]   But I think that kind of stuff is very useful.
[00:33:20.900 --> 00:33:25.940]   So thinking of things that you can do to automate your own workflow and then share that and
[00:33:25.940 --> 00:33:28.980]   make it into tools, I think that's very underrated.
[00:33:28.980 --> 00:33:29.980]   Nice.
[00:33:29.980 --> 00:33:35.660]   Well, from one toolmaker to another, I have a lot of respect for that.
[00:33:35.660 --> 00:33:36.660]   That's awesome.
[00:33:36.660 --> 00:33:38.740]   We'll put a link to Fast Pages.
[00:33:38.740 --> 00:33:40.740]   I think it's super cool.
[00:33:40.740 --> 00:33:41.820]   All right.
[00:33:41.820 --> 00:33:46.300]   Next question is, what's the biggest challenge of making machine learning actually work in
[00:33:46.300 --> 00:33:49.060]   the real world, in your experience?
[00:33:49.060 --> 00:33:57.300]   Yeah, I think that there is a gap between software engineering and machine learning
[00:33:57.300 --> 00:34:03.860]   and kind of different disciplines that need to work together to a lot of times pull off
[00:34:03.860 --> 00:34:06.900]   a successful deployment of machine learning.
[00:34:06.900 --> 00:34:13.020]   And I think part of it is organizational and part of it is tooling.
[00:34:13.020 --> 00:34:16.220]   I don't think tooling can get you all the way there.
[00:34:16.220 --> 00:34:24.740]   I think machine learning is a team sport and requires people from design, UX, of course,
[00:34:24.740 --> 00:34:30.820]   ML folks, infrastructure people, DevOps, all kinds of people to pull something off.
[00:34:30.820 --> 00:34:35.940]   And so I think that can be a challenge to kind of get those people together in a lot
[00:34:35.940 --> 00:34:39.060]   of organizations to do what you want.
[00:34:39.060 --> 00:34:43.260]   Have there been any particular dysfunctional patterns that you've seen over and over with
[00:34:43.260 --> 00:34:44.260]   that or miscommunications?
[00:34:44.260 --> 00:34:45.260]   Oh, yeah.
[00:34:45.260 --> 00:34:52.220]   I mean, I think the main pattern that I continue to see over and over again is, "Oh, my business
[00:34:52.220 --> 00:34:53.980]   is in trouble.
[00:34:53.980 --> 00:34:56.540]   Let's sprinkle some data scientists on it."
[00:34:56.540 --> 00:34:59.460]   You don't just hire a data scientist to solve a machine learning problem.
[00:34:59.460 --> 00:35:03.020]   You need to think about it as a holistic product.
[00:35:03.020 --> 00:35:07.260]   And I think that pattern keeps repeating itself over and over again.
[00:35:07.260 --> 00:35:10.620]   While you're still seeing that, it reminds me of my first job.
[00:35:10.620 --> 00:35:16.340]   Yeah, it may have not changed much.
[00:35:16.340 --> 00:35:17.340]   I don't know.
[00:35:17.340 --> 00:35:21.100]   I mean, hopefully the industry is getting a little bit better.
[00:35:21.100 --> 00:35:22.100]   All right.
[00:35:22.100 --> 00:35:26.900]   So final question is, if people want to learn more about what you're working on, get in
[00:35:26.900 --> 00:35:29.940]   touch with you, what's the best way for people to find you online?
[00:35:29.940 --> 00:35:34.460]   Yeah, I mean, there's a lot of ways you could find me on Twitter.
[00:35:34.460 --> 00:35:39.540]   I have a website that I haven't updated in a while, but you can do that.
[00:35:39.540 --> 00:35:40.540]   You can just Google me.
[00:35:40.540 --> 00:35:41.540]   There's a lot of stuff.
[00:35:41.540 --> 00:35:42.540]   Nice.
[00:35:42.540 --> 00:35:43.540]   Yeah.
[00:35:43.540 --> 00:35:44.540]   All right.
[00:35:44.540 --> 00:35:49.540]   We'll put a bunch of links for people to come use your tools.
[00:35:49.540 --> 00:35:50.540]   Yeah.
[00:35:50.540 --> 00:35:51.540]   Thanks so much for chatting.
[00:35:51.540 --> 00:35:52.540]   This was really fun.
[00:35:52.540 --> 00:35:53.540]   Yeah.
[00:35:53.540 --> 00:35:54.540]   Thank you.
[00:35:54.540 --> 00:35:55.540]   Appreciate it.
[00:35:55.540 --> 00:35:55.540]   Cheers.
[00:35:55.540 --> 00:35:56.040]   Cheers.
[00:35:56.040 --> 00:36:01.040]   Cheers.
[00:36:01.040 --> 00:36:04.400]   [MUSIC PLAYING]

