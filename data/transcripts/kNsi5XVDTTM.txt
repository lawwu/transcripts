
[00:00:00.000 --> 00:00:01.280]   AI might just upend all that.
[00:00:01.280 --> 00:00:03.480]   Future apps might just be much more of a dialogue
[00:00:03.480 --> 00:00:04.640]   between computer and machine.
[00:00:04.640 --> 00:00:06.000]   The very fundamental assumptions
[00:00:06.000 --> 00:00:08.360]   about how software gets built might just completely change.
[00:00:08.360 --> 00:00:09.560]   We work with a lot of great founders.
[00:00:09.560 --> 00:00:13.400]   We also work with Elon, and like, he's still special.
[00:00:13.400 --> 00:00:15.440]   I think the incumbent education system
[00:00:15.440 --> 00:00:16.800]   is trying to destroy itself.
[00:00:16.800 --> 00:00:18.000]   I don't think there's any prospect
[00:00:18.000 --> 00:00:19.840]   of nuclear fusion being legal in the US.
[00:00:19.840 --> 00:00:21.880]   Things that are basically the equivalent of,
[00:00:21.880 --> 00:00:22.800]   I don't know, baseball cards,
[00:00:22.800 --> 00:00:25.160]   where there's no real good or service that's being created.
[00:00:25.160 --> 00:00:27.520]   I would entirely disagree with the premise of that question.
[00:00:27.520 --> 00:00:28.800]   Different religions and cultures,
[00:00:28.800 --> 00:00:31.080]   they all tend to have some underlying unease
[00:00:31.080 --> 00:00:33.000]   with the concept of money, the concept of trade,
[00:00:33.000 --> 00:00:34.200]   the concept of interest.
[00:00:34.200 --> 00:00:36.360]   It's like superstition, it's like resentment,
[00:00:36.360 --> 00:00:39.200]   but those things are the things that make economies work.
[00:00:39.200 --> 00:00:40.560]   If venture capital ever gets snuffed
[00:00:40.560 --> 00:00:42.280]   and there's no more tech startups or whatever,
[00:00:42.280 --> 00:00:43.120]   like, then at that point,
[00:00:43.120 --> 00:00:44.920]   the economy is gonna be 100% managerial,
[00:00:44.920 --> 00:00:47.360]   and at that point, there will be no innovation forever.
[00:00:47.360 --> 00:00:50.800]   - Okay, today, I have the great pleasure
[00:00:50.800 --> 00:00:52.760]   of speaking with Marc Andreessen,
[00:00:52.760 --> 00:00:54.840]   which means for the first time on the podcast,
[00:00:54.840 --> 00:00:58.240]   the guest and the host playback speed will actually match.
[00:00:58.240 --> 00:01:01.040]   So Marc, welcome to the Lunar Society.
[00:01:01.040 --> 00:01:02.680]   - Good morning, and thank you for having me.
[00:01:02.680 --> 00:01:04.080]   It's great to be here.
[00:01:04.080 --> 00:01:04.920]   - My pleasure.
[00:01:04.920 --> 00:01:08.320]   So have you been tempted anytime in the last 14 years
[00:01:08.320 --> 00:01:11.840]   to start a company, not A16Z, but another company?
[00:01:11.840 --> 00:01:14.920]   - No, it's, I mean, we have.
[00:01:14.920 --> 00:01:16.480]   I mean, so the short answer is we did.
[00:01:16.480 --> 00:01:19.160]   So we started our venture firm in 2009,
[00:01:19.160 --> 00:01:21.720]   and so it's sort of given my partner, Ben and I,
[00:01:21.720 --> 00:01:23.120]   a chance to kind of fully exercise
[00:01:23.120 --> 00:01:25.960]   our entrepreneurial ambitions and energies
[00:01:25.960 --> 00:01:26.800]   to build this firm.
[00:01:26.800 --> 00:01:28.560]   We're over 500 people now at the firm,
[00:01:28.560 --> 00:01:31.400]   which is small for a tech company,
[00:01:31.400 --> 00:01:33.320]   but it's big for a venture capital firm.
[00:01:33.320 --> 00:01:37.880]   And so it's let us kind of fully get all those urges out.
[00:01:37.880 --> 00:01:39.640]   - But there's no product where you think,
[00:01:39.640 --> 00:01:40.760]   oh God, this needs to exist,
[00:01:40.760 --> 00:01:42.680]   and I should be the one to make it happen?
[00:01:42.680 --> 00:01:43.840]   - You know, I think a lot, I mean,
[00:01:43.840 --> 00:01:45.440]   we look at this kind of through the lens of like,
[00:01:45.440 --> 00:01:47.600]   what would I do if I were 23 again?
[00:01:47.600 --> 00:01:50.000]   And so I always have those ideas,
[00:01:50.000 --> 00:01:53.200]   but starting a company is really,
[00:01:53.200 --> 00:01:55.160]   look, starting a company is like a real commitment.
[00:01:55.160 --> 00:01:57.600]   Like, it really changes your life.
[00:01:57.600 --> 00:01:58.920]   You know, my favorite all-time quote
[00:01:58.920 --> 00:02:01.040]   on being a startup founder is from Sean Parker,
[00:02:01.040 --> 00:02:04.480]   who says, "Starting a company is like chewing glass.
[00:02:04.480 --> 00:02:07.160]   "Eventually you start to like the taste of your own blood."
[00:02:07.160 --> 00:02:08.680]   (laughing)
[00:02:08.680 --> 00:02:10.720]   That quote always gives people like this.
[00:02:10.720 --> 00:02:12.080]   I always get this queasy look, you know,
[00:02:12.080 --> 00:02:13.440]   on the face of people I'm talking to,
[00:02:13.440 --> 00:02:14.280]   and I roll that quote out.
[00:02:14.280 --> 00:02:17.360]   But like, it really is, I mean, it's really intense.
[00:02:17.360 --> 00:02:19.200]   And so I always tell people, you know,
[00:02:19.200 --> 00:02:20.760]   whenever anybody asks me if they should start a company,
[00:02:20.760 --> 00:02:22.960]   you know, the answer is always no,
[00:02:22.960 --> 00:02:25.960]   because it's such a just like gigantic,
[00:02:25.960 --> 00:02:28.760]   like emotional, irrational, you know, kind of thing to do.
[00:02:28.760 --> 00:02:30.880]   Like the implications of that decision are so profound
[00:02:30.880 --> 00:02:34.120]   in terms of how you live your life that I,
[00:02:34.120 --> 00:02:35.800]   yeah, I mean, look, there are plenty of great ideas
[00:02:35.800 --> 00:02:37.200]   and plenty of interesting things to do,
[00:02:37.200 --> 00:02:39.760]   but the actual process is so difficult.
[00:02:39.760 --> 00:02:43.040]   It gets romanticized a lot, and it's not romantic.
[00:02:43.040 --> 00:02:44.840]   It's a very difficult thing to do.
[00:02:44.840 --> 00:02:47.840]   And so, and I, you know, I did it multiple times before.
[00:02:47.840 --> 00:02:51.200]   So at least for now, I don't revisit that.
[00:02:51.200 --> 00:02:53.080]   - But being a venture capitalist is not like that.
[00:02:53.080 --> 00:02:54.840]   When you're in the 30th pitch of the day,
[00:02:54.840 --> 00:02:56.400]   you're not wondering if chewing glass
[00:02:56.400 --> 00:02:58.160]   might not be more comfortable?
[00:02:58.160 --> 00:02:59.000]   - No, it's different.
[00:02:59.000 --> 00:03:00.000]   Well, so it's different.
[00:03:00.000 --> 00:03:01.840]   Well, I'll just, I'll tell you how I experienced it.
[00:03:01.840 --> 00:03:04.000]   You know, people are wired to respond to stress
[00:03:04.000 --> 00:03:04.840]   in different ways.
[00:03:04.840 --> 00:03:06.400]   And I think there are people who are wired to be,
[00:03:06.400 --> 00:03:08.200]   you know, extremely productive and extreme,
[00:03:08.200 --> 00:03:09.040]   you know, actually get,
[00:03:09.040 --> 00:03:11.840]   who get like very happy under extreme levels of stress.
[00:03:11.840 --> 00:03:14.560]   I have a different, like, I'm fine with stress.
[00:03:14.560 --> 00:03:16.600]   I'm, in fact, I inclined towards it.
[00:03:16.600 --> 00:03:18.840]   And I, you know, if I don't have any, I seek it out.
[00:03:18.840 --> 00:03:20.840]   But like, I don't, past a certain level,
[00:03:20.840 --> 00:03:21.760]   I don't really enjoy it.
[00:03:21.760 --> 00:03:24.480]   Like it doesn't, it degrades the quality of my life,
[00:03:24.480 --> 00:03:25.520]   not improves it.
[00:03:25.520 --> 00:03:28.440]   Maybe I have an affinity for self-torture.
[00:03:28.440 --> 00:03:32.200]   But, and so it's the, there's, I mean, look,
[00:03:32.200 --> 00:03:33.760]   there's stress in everything, you know,
[00:03:33.760 --> 00:03:35.480]   and there's stress in every profession.
[00:03:35.480 --> 00:03:37.160]   And there's certainly stress in being an investor,
[00:03:37.160 --> 00:03:39.800]   but it's a completely different kind of stress.
[00:03:39.800 --> 00:03:41.440]   Because when you're a startup founder,
[00:03:41.440 --> 00:03:43.360]   like it's all on you, right?
[00:03:43.360 --> 00:03:45.560]   It's like everything that happens is on you.
[00:03:45.560 --> 00:03:47.360]   Everything that goes wrong is on you.
[00:03:47.360 --> 00:03:49.440]   Like when there's an issue in the company,
[00:03:49.440 --> 00:03:51.280]   a crisis in the company, like it's on you to fix it.
[00:03:51.280 --> 00:03:53.520]   Like you're, you know, you're up at four in the morning,
[00:03:53.520 --> 00:03:55.680]   like all the time, like worrying about things.
[00:03:55.680 --> 00:03:58.920]   And just investors, there's just a layer of buffer.
[00:03:58.920 --> 00:04:01.760]   You know, we have, you know, we have no end of problems.
[00:04:01.760 --> 00:04:03.960]   And, you know, we have, we help our portfolio companies
[00:04:03.960 --> 00:04:05.680]   as best we can with all kinds of issues.
[00:04:05.680 --> 00:04:07.880]   But like, you know, some crisis inside a company,
[00:04:07.880 --> 00:04:10.320]   like it's not my company, like it's not.
[00:04:10.320 --> 00:04:12.320]   Not everything is my fault.
[00:04:12.320 --> 00:04:17.920]   And so it's a more diffuse kind of stress.
[00:04:17.920 --> 00:04:20.400]   And honestly, it's easier to deal with.
[00:04:20.400 --> 00:04:21.840]   - Got it, that makes sense.
[00:04:21.840 --> 00:04:23.120]   But why did you stop your blog?
[00:04:23.120 --> 00:04:24.720]   Would you ever start it again?
[00:04:24.720 --> 00:04:27.080]   - Hmm, so I write intermittently.
[00:04:27.080 --> 00:04:28.920]   You know, I just, I mean, I stopped.
[00:04:28.920 --> 00:04:32.080]   The original blog was like, what, 2007 to 2009,
[00:04:32.080 --> 00:04:33.880]   you know, kind of thing.
[00:04:33.880 --> 00:04:36.400]   And then we started the firm and then that kind of,
[00:04:36.400 --> 00:04:37.360]   you know, it was like having a new baby
[00:04:37.360 --> 00:04:38.760]   that kind of soaked up all my time.
[00:04:38.760 --> 00:04:39.600]   - Yeah.
[00:04:39.600 --> 00:04:40.800]   - And then I, you know, I write intermittently
[00:04:40.800 --> 00:04:41.760]   and then I do, you know, I'm doing,
[00:04:41.760 --> 00:04:43.080]   I do social media intermittently.
[00:04:43.080 --> 00:04:45.080]   And, you know, basically it's just, you know,
[00:04:45.080 --> 00:04:47.600]   part of it is I, you know, I have a lot to say
[00:04:47.600 --> 00:04:48.600]   and a lot that I'm interested in,
[00:04:48.600 --> 00:04:50.880]   but also I, you know, I like to experiment
[00:04:50.880 --> 00:04:53.400]   with the new formats and I like to, you know,
[00:04:53.400 --> 00:04:54.960]   kind of, you know, like, you know,
[00:04:54.960 --> 00:04:56.520]   we do live in a fundamentally different world
[00:04:56.520 --> 00:04:58.280]   as a result of social media and the internet
[00:04:58.280 --> 00:04:59.960]   and blogging and Twitter and all the rest of it.
[00:04:59.960 --> 00:05:02.080]   So I try to keep my hand in it and experiment,
[00:05:02.080 --> 00:05:03.720]   but, you know, I kind of rotate.
[00:05:03.720 --> 00:05:05.720]   I rotate both how I spend my time and rotate,
[00:05:05.720 --> 00:05:07.280]   but I think, you know, it makes sense.
[00:05:07.280 --> 00:05:11.400]   - Mm-hmm, now before AWS, deploying applications
[00:05:11.400 --> 00:05:13.560]   was probably the bottleneck on your software.
[00:05:13.560 --> 00:05:15.040]   What is the biggest bottleneck today?
[00:05:15.040 --> 00:05:17.800]   At what layer of abstraction do we need new tools?
[00:05:17.800 --> 00:05:19.600]   - Yeah, so I think literally sitting here today,
[00:05:19.600 --> 00:05:21.920]   I think overwhelmingly it's the impact AI
[00:05:21.920 --> 00:05:23.480]   is having on coding, right?
[00:05:23.480 --> 00:05:26.160]   So like, I think there's a real possibility
[00:05:26.160 --> 00:05:28.480]   that basically, I think there's a possibility
[00:05:28.480 --> 00:05:29.960]   that basically every application category
[00:05:29.960 --> 00:05:32.120]   gets upended in the next five years.
[00:05:32.120 --> 00:05:34.720]   Like, I think the whole model of how applications
[00:05:34.720 --> 00:05:36.400]   get built across every domain,
[00:05:36.400 --> 00:05:37.800]   I think it might just completely change.
[00:05:37.800 --> 00:05:40.480]   'Cause I think, you know, the old model without AI,
[00:05:40.480 --> 00:05:42.640]   you know, you typically have like some sort of database,
[00:05:42.640 --> 00:05:44.520]   you have some sort of front end of the database,
[00:05:44.520 --> 00:05:46.520]   you have forms, right?
[00:05:46.520 --> 00:05:47.880]   You had, you know, these sort of known
[00:05:47.880 --> 00:05:51.000]   user interaction models, mobile apps and so forth.
[00:05:51.000 --> 00:05:53.520]   You know, we kind of got to a pretty good
[00:05:53.520 --> 00:05:55.200]   kind of shared understanding of how humans
[00:05:55.200 --> 00:05:58.040]   and machines communicate, kind of in the windowing era
[00:05:58.040 --> 00:06:00.240]   and then in the mobile era, in the web era.
[00:06:00.240 --> 00:06:03.440]   You know, I think AI might just upend all that.
[00:06:03.440 --> 00:06:05.920]   And I think the future apps might just be much more
[00:06:05.920 --> 00:06:08.240]   of a dialogue between computer and machine.
[00:06:08.240 --> 00:06:10.240]   You know, this either a text-written dialogue
[00:06:10.240 --> 00:06:12.280]   or a spoken dialogue or some other form of dialogue.
[00:06:12.280 --> 00:06:14.480]   And, you know, the human is guiding the machine
[00:06:14.480 --> 00:06:17.000]   in what to do and receiving real-time feedback.
[00:06:17.000 --> 00:06:18.920]   And there's a loop and then the machine
[00:06:18.920 --> 00:06:21.120]   just does what it does and it gives you the results.
[00:06:21.120 --> 00:06:22.360]   I, you know, I think we're potentially
[00:06:22.360 --> 00:06:23.200]   on the front end of that.
[00:06:23.200 --> 00:06:25.040]   I think that all might change.
[00:06:25.040 --> 00:06:27.920]   So the very fundamental assumptions
[00:06:27.920 --> 00:06:29.160]   about how software gets built,
[00:06:29.160 --> 00:06:31.080]   I think might just completely change.
[00:06:31.080 --> 00:06:33.480]   And so the, yeah, the tools on that
[00:06:33.480 --> 00:06:35.520]   are at the very front end.
[00:06:35.520 --> 00:06:36.960]   Like there's an entirely new stack
[00:06:36.960 --> 00:06:38.440]   that needs to get built to do that.
[00:06:38.440 --> 00:06:41.800]   So that's, yeah, that's probably the big thing.
[00:06:41.800 --> 00:06:42.960]   - Is there a reason, though,
[00:06:42.960 --> 00:06:44.480]   AI is not one of your focus areas?
[00:06:44.480 --> 00:06:46.800]   Or as far as I know, you guys don't have an AI fund
[00:06:46.800 --> 00:06:49.320]   dedicated to the technology specifically?
[00:06:49.320 --> 00:06:50.440]   - Yeah, so basically what we look at
[00:06:50.440 --> 00:06:51.720]   is it's all of software, right?
[00:06:51.720 --> 00:06:54.080]   And so we look at it as like it is the core business.
[00:06:54.080 --> 00:06:56.200]   So software is the core of the firm.
[00:06:56.200 --> 00:06:59.120]   You know, we've been public on that for a long time.
[00:06:59.120 --> 00:07:00.880]   You know, the core fund, the core venture fund
[00:07:00.880 --> 00:07:02.720]   is the kind of core software fund.
[00:07:02.720 --> 00:07:06.040]   And then AI basically is the next turn on software.
[00:07:06.040 --> 00:07:08.120]   And so it's, I view it kind of as the opposite
[00:07:08.120 --> 00:07:08.960]   of what you said.
[00:07:08.960 --> 00:07:10.400]   It's sort of, it is like the most integral thing
[00:07:10.400 --> 00:07:12.160]   that we're doing.
[00:07:12.160 --> 00:07:14.240]   The separate funds get created for the new areas,
[00:07:14.240 --> 00:07:17.000]   like for the new areas that are like structurally different
[00:07:17.000 --> 00:07:19.760]   in terms of like how industries work, right.
[00:07:19.760 --> 00:07:23.520]   And so, you know, but like AI is basically
[00:07:23.520 --> 00:07:24.360]   the future of software.
[00:07:24.360 --> 00:07:26.780]   And so it's the future of the core of the firm.
[00:07:26.780 --> 00:07:28.400]   - Got it, got it.
[00:07:28.400 --> 00:07:30.000]   Now let's talk a little bit about your past.
[00:07:30.000 --> 00:07:32.960]   So you sold Netscape for $10 billion.
[00:07:32.960 --> 00:07:35.280]   But today Chrome has what, like 2.7 billion users
[00:07:35.280 --> 00:07:36.200]   or something.
[00:07:36.200 --> 00:07:38.880]   And then Opsware was sold for like $1.7 billion.
[00:07:39.920 --> 00:07:42.320]   AWS is gonna probably make close to 100 billion
[00:07:42.320 --> 00:07:43.400]   in revenue yearly.
[00:07:43.400 --> 00:07:46.200]   In retrospect, do you think if these companies
[00:07:46.200 --> 00:07:47.680]   had remained startups,
[00:07:47.680 --> 00:07:50.480]   they would have ended up dominating these large markets?
[00:07:50.480 --> 00:07:53.240]   - Yeah, so I spent like virtually no time on the past.
[00:07:53.240 --> 00:07:56.800]   The one thing I know about the past is I can't change it.
[00:07:56.800 --> 00:07:57.640]   - Yeah.
[00:07:57.640 --> 00:07:59.960]   - So I spent virtually no time
[00:07:59.960 --> 00:08:01.800]   kind of revisiting old decisions.
[00:08:01.800 --> 00:08:04.240]   I, you know, people I know who spent a lot of time
[00:08:04.240 --> 00:08:06.280]   revisiting old decisions, like are less effective
[00:08:06.280 --> 00:08:09.280]   'cause they mired themselves in what-ifs and counterfactuals.
[00:08:10.160 --> 00:08:12.840]   So, yeah, I really don't spend any time on it.
[00:08:12.840 --> 00:08:14.980]   I really don't even really have theories on it.
[00:08:14.980 --> 00:08:16.800]   I guess the big thing I would just say
[00:08:16.800 --> 00:08:20.120]   is reality plays out in really complicated ways.
[00:08:20.120 --> 00:08:21.680]   Like, you know, everything on paper is straightforward.
[00:08:21.680 --> 00:08:23.480]   Reality is very complicated and messy.
[00:08:23.480 --> 00:08:25.440]   The technical way that I think about it
[00:08:25.440 --> 00:08:27.320]   is basically every startup is charting
[00:08:27.320 --> 00:08:31.080]   a path-dependent course through a complex adaptive system.
[00:08:31.080 --> 00:08:34.760]   And because of that, like, you know,
[00:08:34.760 --> 00:08:36.840]   it's sort of this, if you remember,
[00:08:36.840 --> 00:08:38.440]   if you've ever read about this in the old days,
[00:08:38.440 --> 00:08:39.680]   people had this obsession a while back
[00:08:39.680 --> 00:08:41.640]   with what's called, you know, chaos theory.
[00:08:41.640 --> 00:08:43.400]   It's sort of this thing of like, okay,
[00:08:43.400 --> 00:08:44.960]   we're used to thinking about like systems
[00:08:44.960 --> 00:08:46.400]   as if they're like deterministic, you know,
[00:08:46.400 --> 00:08:48.080]   so you start at point A, you end up at point B,
[00:08:48.080 --> 00:08:49.660]   and you can do that over and over again, right?
[00:08:49.660 --> 00:08:51.160]   Like, you know, what happens when you drop an apple
[00:08:51.160 --> 00:08:53.480]   out of a tree or whatever?
[00:08:53.480 --> 00:08:56.080]   You know, in the real world, like in the world of humans
[00:08:56.080 --> 00:08:58.120]   and, you know, 8 billion people interacting
[00:08:58.120 --> 00:08:59.280]   and then trying to start companies
[00:08:59.280 --> 00:09:00.360]   that intersect in these markets
[00:09:00.360 --> 00:09:01.580]   and do all these complicated things
[00:09:01.580 --> 00:09:03.120]   and have all these employees,
[00:09:03.120 --> 00:09:06.040]   it's just there's like random elements all over the place.
[00:09:06.040 --> 00:09:07.720]   There's path dependence as a consequence.
[00:09:07.720 --> 00:09:09.880]   You run the same scenario, start at point A,
[00:09:09.880 --> 00:09:12.640]   one time you end up point B, one time you end up point Z.
[00:09:12.640 --> 00:09:14.200]   You know, there's a million reasons
[00:09:14.200 --> 00:09:16.720]   why the sort of, you know, fork's branch,
[00:09:16.720 --> 00:09:21.720]   or the branch's fork, and so you just can't, like, yeah.
[00:09:21.720 --> 00:09:24.360]   I mean, this is my advice to every founder
[00:09:24.360 --> 00:09:26.640]   who wants to revisit old decisions.
[00:09:26.640 --> 00:09:28.400]   It's just like, it's not a useful
[00:09:28.400 --> 00:09:29.520]   and productive thing to do.
[00:09:29.520 --> 00:09:31.360]   The world is too complicated and messy.
[00:09:31.360 --> 00:09:33.200]   So you just, you know, you take whatever you,
[00:09:33.200 --> 00:09:34.600]   you know, you take whatever skills you think you have
[00:09:34.600 --> 00:09:36.560]   and you just do something new.
[00:09:36.560 --> 00:09:37.920]   - Makes sense.
[00:09:37.920 --> 00:09:40.560]   Aren't venture capitalists part of the managerial elite?
[00:09:40.560 --> 00:09:42.880]   So Burnham says that the rise of the finance capitalist
[00:09:42.880 --> 00:09:45.720]   is a decisive phase in the managerial revolution.
[00:09:45.720 --> 00:09:48.380]   What would he think about venture capitalists?
[00:09:48.380 --> 00:09:51.720]   - Yeah, so this I actually think about a lot.
[00:09:51.720 --> 00:09:54.120]   So, and I know you said everybody can Google it,
[00:09:54.120 --> 00:09:56.240]   but I'll just, I just wanna, I will provide this
[00:09:56.240 --> 00:09:57.680]   just so this makes sense.
[00:09:57.680 --> 00:09:59.840]   So James Burnham basically famously said
[00:09:59.840 --> 00:10:01.320]   there's basically two kinds of capitalism,
[00:10:01.320 --> 00:10:02.720]   and we call them both capitalism,
[00:10:02.720 --> 00:10:04.920]   but they're actually very different how they operate.
[00:10:04.920 --> 00:10:06.360]   There's the old model of capitalism,
[00:10:06.360 --> 00:10:07.680]   which is bourgeois capitalism.
[00:10:07.680 --> 00:10:09.840]   And bourgeois capitalism was the classic model
[00:10:09.840 --> 00:10:11.760]   where the owner of the business, right,
[00:10:11.760 --> 00:10:13.840]   there was a person who, by the way,
[00:10:13.840 --> 00:10:15.520]   often put their name on the door, right?
[00:10:15.520 --> 00:10:17.640]   Ford Motor Company, right?
[00:10:17.640 --> 00:10:18.460]   - Andrews and Horowitz.
[00:10:18.460 --> 00:10:19.600]   - Disney company, right?
[00:10:19.600 --> 00:10:21.200]   Andrews and Horowitz, right?
[00:10:21.200 --> 00:10:25.020]   And then that person owned the business, right?
[00:10:25.020 --> 00:10:26.720]   Often 100% of the business.
[00:10:26.720 --> 00:10:29.040]   And then that person ran the business, right?
[00:10:29.040 --> 00:10:30.800]   And so this is sort of the classic, you know,
[00:10:30.800 --> 00:10:32.560]   this is, these are the people the communists hated, right?
[00:10:32.560 --> 00:10:35.760]   This is like the bourgeois capitalist company owner,
[00:10:35.760 --> 00:10:39.400]   builder, CEO, right, as sort of one person.
[00:10:39.400 --> 00:10:42.320]   With, it's very key with like a direct link, right,
[00:10:42.320 --> 00:10:43.920]   between ownership and control, right?
[00:10:43.920 --> 00:10:45.240]   The person who owns it controls it,
[00:10:45.240 --> 00:10:46.520]   the person who controls it runs it.
[00:10:46.520 --> 00:10:48.320]   Like, it's just a thing.
[00:10:48.320 --> 00:10:50.560]   There's a proprietor of the business.
[00:10:50.560 --> 00:10:52.560]   So that's the old model.
[00:10:52.560 --> 00:10:53.800]   And then what he said basically is
[00:10:53.800 --> 00:10:55.600]   as of the middle of the 20th century,
[00:10:55.600 --> 00:10:57.360]   most of the economy was transitioning.
[00:10:57.360 --> 00:10:58.880]   And I think that transition has happened
[00:10:58.880 --> 00:11:01.400]   and has, you know, is basically now complete.
[00:11:01.400 --> 00:11:02.940]   Most of the economy transitions
[00:11:02.940 --> 00:11:04.120]   to a different mode of operating,
[00:11:04.120 --> 00:11:06.920]   a different kind of capitalism called managerial capitalism.
[00:11:06.920 --> 00:11:08.960]   In managerial capitalism, you basically,
[00:11:08.960 --> 00:11:11.320]   you have a separation of ownership and management.
[00:11:11.320 --> 00:11:13.840]   So you have one set of, you know, think public company.
[00:11:13.840 --> 00:11:15.240]   You have one set of owners, you know,
[00:11:15.240 --> 00:11:16.560]   who are like dispersed shareholders.
[00:11:16.560 --> 00:11:18.240]   And there's like a million of them for a big company
[00:11:18.240 --> 00:11:19.080]   and who knows where they are
[00:11:19.080 --> 00:11:20.240]   and they're not paying any attention to the company
[00:11:20.240 --> 00:11:23.240]   and they have no ability to run the company and like whatever.
[00:11:23.240 --> 00:11:25.120]   And then you've got a professional manager class
[00:11:25.120 --> 00:11:27.620]   and they step in and they run the company.
[00:11:27.620 --> 00:11:29.960]   And then what he said basically is as a consequence of that,
[00:11:29.960 --> 00:11:31.460]   that the managers end up in control.
[00:11:31.460 --> 00:11:33.820]   Even though the managers don't own the company, right?
[00:11:33.820 --> 00:11:35.080]   Even though their ownership's taken, you know,
[00:11:35.080 --> 00:11:36.000]   a lot of public companies,
[00:11:36.000 --> 00:11:38.360]   the managers might own like 1% of the company,
[00:11:38.360 --> 00:11:39.520]   but they end up in total control
[00:11:39.520 --> 00:11:41.260]   and then they can do whatever they want.
[00:11:41.260 --> 00:11:43.960]   And he actually said, look, it doesn't even matter
[00:11:43.960 --> 00:11:45.400]   if you think this is good or bad or whatever,
[00:11:45.400 --> 00:11:46.240]   it's just inevitable.
[00:11:46.240 --> 00:11:49.240]   And it's inevitable because of scale and complexity, right?
[00:11:49.240 --> 00:11:51.080]   And so the modern industrial
[00:11:51.080 --> 00:11:52.440]   and post-industrial organizations
[00:11:52.440 --> 00:11:54.440]   are gonna end up being so big and so complex
[00:11:54.440 --> 00:11:56.160]   and so technical that you're gonna need
[00:11:56.160 --> 00:11:57.840]   this professional managerial class to run them.
[00:11:57.840 --> 00:11:59.040]   And it's just an inevitability.
[00:11:59.040 --> 00:12:00.480]   This is how it's gonna go.
[00:12:00.480 --> 00:12:03.680]   And so I really think this is exactly what's played out.
[00:12:03.680 --> 00:12:08.180]   A consequence of that that I think is pretty obvious
[00:12:08.180 --> 00:12:10.420]   is that managerial capitalism has a big advantage
[00:12:10.420 --> 00:12:11.300]   that Burnham identified,
[00:12:11.300 --> 00:12:12.860]   which is the managers are often very good
[00:12:12.860 --> 00:12:14.020]   at running things at scale.
[00:12:14.020 --> 00:12:15.820]   And we have these, you know, giant, you know,
[00:12:15.820 --> 00:12:18.060]   industries and sectors of the economy and healthcare
[00:12:18.060 --> 00:12:19.720]   and education, all these things that are running at like,
[00:12:19.720 --> 00:12:22.620]   you know, giant levels of scale, you know,
[00:12:22.620 --> 00:12:24.860]   which was new in the 20th century.
[00:12:24.860 --> 00:12:28.260]   But there's sort of a consequence of that,
[00:12:28.260 --> 00:12:31.060]   which is managers don't build new things, right?
[00:12:31.060 --> 00:12:32.800]   They just, they're not trained to do it.
[00:12:32.800 --> 00:12:33.820]   They don't have the background to do it.
[00:12:33.820 --> 00:12:35.000]   They don't have the personality to do it.
[00:12:35.000 --> 00:12:36.060]   They don't have the temperament to do it.
[00:12:36.060 --> 00:12:37.980]   And they don't have the incentives to do it
[00:12:37.980 --> 00:12:39.740]   because they basically, the number one job
[00:12:39.740 --> 00:12:42.660]   if you're a manager is not to upset the apple cart, right?
[00:12:42.660 --> 00:12:44.940]   You want to like stay in that job for as long as possible.
[00:12:44.940 --> 00:12:46.220]   You want to get paid your annual comp
[00:12:46.220 --> 00:12:47.060]   for as long as possible.
[00:12:47.060 --> 00:12:49.380]   And you don't want to do anything that would introduce risk.
[00:12:49.380 --> 00:12:52.960]   And so managers can't and won't build new things.
[00:12:52.960 --> 00:12:55.260]   And so specifically to your question,
[00:12:55.260 --> 00:12:57.940]   the role of startups,
[00:12:57.940 --> 00:13:00.220]   like the role of entrepreneurial capitalism, right?
[00:13:00.220 --> 00:13:02.160]   Is to basically bring back
[00:13:02.160 --> 00:13:05.880]   the old bourgeois capitalist model enough, right?
[00:13:05.880 --> 00:13:07.720]   Now, it's a rump effort
[00:13:07.720 --> 00:13:09.040]   'cause it's not most of the economy today,
[00:13:09.040 --> 00:13:11.920]   but bring back the older model of bourgeois capitalism
[00:13:11.920 --> 00:13:13.260]   or what we call entrepreneurial capitalism,
[00:13:13.260 --> 00:13:14.160]   like bring it back enough
[00:13:14.160 --> 00:13:17.040]   to at least be able to build the new things, right?
[00:13:17.040 --> 00:13:18.960]   And so basically what we do is,
[00:13:18.960 --> 00:13:20.040]   what we do basically is like,
[00:13:20.040 --> 00:13:21.720]   we fund the new bourgeois capitalists
[00:13:21.720 --> 00:13:23.480]   who we call tech founders.
[00:13:23.480 --> 00:13:26.100]   And then there's basically two layers of finance
[00:13:26.100 --> 00:13:28.800]   that basically enable basically bourgeois capitalism
[00:13:28.800 --> 00:13:30.360]   to at least resurface a little bit
[00:13:30.360 --> 00:13:32.000]   within this managerial system.
[00:13:32.000 --> 00:13:33.780]   Venture capital does that at the point of inception
[00:13:33.780 --> 00:13:35.200]   and then private equity does that at a point
[00:13:35.200 --> 00:13:37.840]   when a company needs to actually transform.
[00:13:37.840 --> 00:13:40.680]   And so I view it as like we're an enabling agent
[00:13:40.680 --> 00:13:42.960]   for at least enough of a resumption of bourgeois capitalism
[00:13:42.960 --> 00:13:44.640]   to be able to get new things built,
[00:13:44.640 --> 00:13:46.480]   even if most of the companies that we built
[00:13:46.480 --> 00:13:48.720]   ultimately themselves end up being run
[00:13:48.720 --> 00:13:49.980]   in the managerial model.
[00:13:49.980 --> 00:13:51.840]   And as Brennan would say,
[00:13:51.840 --> 00:13:53.320]   like that's just the way of the modern world.
[00:13:53.320 --> 00:13:55.140]   Like that's just how it's gonna work.
[00:13:55.140 --> 00:13:57.400]   - But you guys get like preferred shares and board seats
[00:13:57.400 --> 00:13:58.520]   and rightfully so.
[00:13:58.520 --> 00:14:00.160]   But wouldn't Burnham look at this and say,
[00:14:00.160 --> 00:14:02.600]   you guys are all like, you're not the owners
[00:14:02.600 --> 00:14:05.360]   and you do have some amount of control over your companies.
[00:14:05.360 --> 00:14:06.200]   - Yeah, so he would say,
[00:14:06.200 --> 00:14:07.760]   I think he would say that we're like a hybrid.
[00:14:07.760 --> 00:14:10.200]   We're like a managerial entity that is in the business
[00:14:10.200 --> 00:14:13.320]   of catalyzing and supporting bourgeois companies,
[00:14:13.320 --> 00:14:14.440]   bourgeois capitalist companies.
[00:14:14.440 --> 00:14:16.920]   Like I think he would clearly identify the startups
[00:14:16.920 --> 00:14:17.760]   that we fund.
[00:14:17.760 --> 00:14:20.040]   I think he would be like, oh yeah, that's the old model.
[00:14:20.040 --> 00:14:21.760]   Like that's the old model of like Thomas Edison
[00:14:21.760 --> 00:14:23.960]   or Henry Ford or one of these guys.
[00:14:23.960 --> 00:14:25.560]   You could just draw like a straight line
[00:14:25.560 --> 00:14:27.280]   from Thomas Edison and Henry Ford to like,
[00:14:27.280 --> 00:14:29.200]   Steve Jobs and Larry Page and Mark Zuckerberg.
[00:14:29.200 --> 00:14:31.360]   Like, that's that model.
[00:14:31.360 --> 00:14:33.360]   That's, it's a founder, it's a CEO.
[00:14:33.360 --> 00:14:36.840]   It's at least, when they start out owning 100%,
[00:14:36.840 --> 00:14:38.240]   they do have to raise money most of the time,
[00:14:38.240 --> 00:14:40.620]   but like, they're throwbacks.
[00:14:40.620 --> 00:14:42.440]   Like the modern tech founders are throwbacks
[00:14:42.440 --> 00:14:44.760]   to this older model of bourgeois capitalism.
[00:14:44.760 --> 00:14:46.520]   And I think, so I think you're right
[00:14:46.520 --> 00:14:48.920]   in that he would view us as a managerial entity,
[00:14:48.920 --> 00:14:50.460]   but he would view us as a managerial entity
[00:14:50.460 --> 00:14:52.200]   that is in the business of causing
[00:14:52.200 --> 00:14:53.760]   new bourgeois capitalist institutions
[00:14:53.760 --> 00:14:55.360]   to at least be created.
[00:14:55.360 --> 00:14:57.280]   And I think he would credit us with that.
[00:14:57.280 --> 00:14:59.120]   And then I think he would say, what I also said,
[00:14:59.120 --> 00:15:00.480]   I think he would say is, however,
[00:15:00.480 --> 00:15:03.880]   our fate is that most of the companies that we fund
[00:15:03.880 --> 00:15:06.040]   and most of the founders that we back
[00:15:06.040 --> 00:15:09.520]   end up over time handing off control of their companies
[00:15:09.520 --> 00:15:11.520]   to a managerial class.
[00:15:11.520 --> 00:15:14.920]   And so our companies, the companies we fund,
[00:15:14.920 --> 00:15:17.080]   when they get to scale, they tend to get pulled
[00:15:17.080 --> 00:15:19.000]   into the managerial orbit, right?
[00:15:19.000 --> 00:15:21.380]   They tend to get pulled into the managerial matrix,
[00:15:21.380 --> 00:15:23.500]   which by the way, is when they stop being able
[00:15:23.500 --> 00:15:25.400]   to build new things, right?
[00:15:25.400 --> 00:15:27.440]   Which is what causes the smart and aggressive people
[00:15:27.440 --> 00:15:29.840]   at those companies to leave and then come back to us
[00:15:29.840 --> 00:15:32.880]   and raise money and start a new bourgeois capitalist company.
[00:15:32.880 --> 00:15:35.040]   Right, and so basically, like I view it as like,
[00:15:35.040 --> 00:15:37.160]   I don't know, the economy is like 99% managerial.
[00:15:37.160 --> 00:15:40.120]   And if we can just keep the 1% of the old model alive,
[00:15:40.120 --> 00:15:41.520]   we'll keep getting new things.
[00:15:41.520 --> 00:15:43.400]   If the 1%, by the way, if we get snuffed,
[00:15:43.400 --> 00:15:44.880]   like if venture capital ever gets snuffed,
[00:15:44.880 --> 00:15:48.280]   it's outlawed or whatever, it just fails, right?
[00:15:48.280 --> 00:15:50.080]   You know, and there is no more venture capital,
[00:15:50.080 --> 00:15:51.720]   there's no more tech startups or whatever,
[00:15:51.720 --> 00:15:53.800]   like then at that point, the economy is gonna be
[00:15:53.800 --> 00:15:55.400]   100% managerial, and at that point,
[00:15:55.400 --> 00:15:57.880]   there will be no innovation forever.
[00:15:57.880 --> 00:15:59.280]   I think people might think they want that,
[00:15:59.280 --> 00:16:00.520]   I don't think they actually want that.
[00:16:00.520 --> 00:16:03.120]   I don't think we wanna live in that world.
[00:16:03.120 --> 00:16:05.380]   - Now, will this trend towards managerialism
[00:16:05.380 --> 00:16:08.760]   also happen to A16Z as it scales, or will it be immune?
[00:16:08.760 --> 00:16:10.960]   Like what happens to A16Z in five decades?
[00:16:10.960 --> 00:16:13.920]   - Yeah, so this becomes, you know, at a certain point,
[00:16:13.920 --> 00:16:15.680]   this becomes the succession problem, right?
[00:16:15.680 --> 00:16:17.280]   So as long as Ben and I are running it,
[00:16:17.280 --> 00:16:19.080]   like our determination is to kind of keep it
[00:16:19.080 --> 00:16:20.560]   as much in the bourgeois model as possible.
[00:16:20.560 --> 00:16:22.040]   And as you pointed out, like literally,
[00:16:22.040 --> 00:16:23.520]   it's like our name's on the door.
[00:16:23.520 --> 00:16:25.720]   You know, like Ben and I control the firm,
[00:16:25.720 --> 00:16:28.160]   like, you know, there's no board,
[00:16:28.160 --> 00:16:29.480]   like the firm doesn't have a board of directors,
[00:16:29.480 --> 00:16:31.600]   like it's just Ben and me running it.
[00:16:31.600 --> 00:16:32.880]   You know, it's a private entity,
[00:16:32.880 --> 00:16:35.080]   there are no outside shareholders.
[00:16:35.080 --> 00:16:36.480]   And so as long as Ben and I are running it
[00:16:36.480 --> 00:16:38.080]   and we're running it in the way that we're running it,
[00:16:38.080 --> 00:16:40.880]   it will be as bourgeois, it will be in the bourgeois model
[00:16:40.880 --> 00:16:44.720]   as much as any investment firm could be.
[00:16:44.720 --> 00:16:47.760]   You know, someday, you know,
[00:16:47.760 --> 00:16:50.480]   there's the succession challenge.
[00:16:50.480 --> 00:16:53.360]   And I bring that up because like the succession challenge
[00:16:53.360 --> 00:16:56.840]   is basically, you know, for tech companies,
[00:16:56.840 --> 00:16:58.520]   the succession point is usually sort of
[00:16:58.520 --> 00:17:00.240]   when that transformation happens, right?
[00:17:00.240 --> 00:17:01.960]   When it goes from being in the bourgeois model
[00:17:01.960 --> 00:17:04.280]   to being in the managerial model.
[00:17:04.280 --> 00:17:06.120]   And then this gets to sort of the philosophy
[00:17:06.120 --> 00:17:07.840]   of succession in tech companies.
[00:17:07.840 --> 00:17:10.400]   And the general thing that happens there is that,
[00:17:10.400 --> 00:17:12.360]   you know, the great, and you see this over and over again
[00:17:12.360 --> 00:17:14.280]   with like the great founder CEOs,
[00:17:14.280 --> 00:17:15.400]   and when it comes time to hand it off,
[00:17:15.400 --> 00:17:16.640]   there's basically two kinds of people
[00:17:16.640 --> 00:17:18.080]   that they could hand it off to.
[00:17:18.080 --> 00:17:20.480]   You know, they could hand it off to somebody like them,
[00:17:20.480 --> 00:17:23.240]   right, who's like a mercurial, you know, idiosyncratic,
[00:17:23.240 --> 00:17:26.320]   you know, high disagreeableness, you know, ornery,
[00:17:26.320 --> 00:17:28.120]   you know, sort of, you know,
[00:17:28.120 --> 00:17:30.840]   entrepreneurial kind of personality, right?
[00:17:30.840 --> 00:17:31.720]   You know, somebody in their mold,
[00:17:31.720 --> 00:17:33.080]   or they could hand it off to somebody
[00:17:33.080 --> 00:17:35.240]   who knows how to run things at scale.
[00:17:35.240 --> 00:17:37.680]   Almost always what they do is they hand it off
[00:17:37.680 --> 00:17:39.440]   to somebody who can run it at scale.
[00:17:39.440 --> 00:17:42.080]   The reason they do that is actually two reasons.
[00:17:42.080 --> 00:17:43.600]   There's the theoretical reason they do that,
[00:17:43.600 --> 00:17:45.680]   which is it is at scale at that point,
[00:17:45.680 --> 00:17:47.840]   and somebody does need to run it at scale.
[00:17:47.840 --> 00:17:49.920]   And then the other is they often have
[00:17:49.920 --> 00:17:52.640]   what I call the long-suffering number two.
[00:17:52.640 --> 00:17:54.000]   So they've got like, you know,
[00:17:54.000 --> 00:17:56.200]   you've had like, you know, whatever, you know,
[00:17:56.200 --> 00:17:58.160]   you've had like this like high-octane, you know,
[00:17:58.160 --> 00:18:00.000]   kind of founder CEO who like breaks a lot of glass.
[00:18:00.000 --> 00:18:01.360]   And then there's often like the number two,
[00:18:01.360 --> 00:18:03.000]   there's like the chief operating officer or something,
[00:18:03.000 --> 00:18:04.360]   who's like the person who like fundamentally
[00:18:04.360 --> 00:18:05.640]   keeps the trains running on time
[00:18:05.640 --> 00:18:07.760]   and keeps everybody from quitting.
[00:18:07.760 --> 00:18:09.000]   And that long-suffering number two
[00:18:09.000 --> 00:18:11.320]   has often been in that job for 10 or 15 years at that point,
[00:18:11.320 --> 00:18:13.400]   and is literally the long, you know, is long-suffering,
[00:18:13.400 --> 00:18:14.760]   like they've always been the underling.
[00:18:14.760 --> 00:18:16.560]   And then it's like, okay, you know, they've quote unquote,
[00:18:16.560 --> 00:18:18.640]   they now deserve the chance to run the company themselves.
[00:18:18.640 --> 00:18:19.480]   And that's the handover.
[00:18:19.480 --> 00:18:22.120]   Now, those founders often end up regretting that decision.
[00:18:22.120 --> 00:18:23.600]   And in later years, they will tell you, boy,
[00:18:23.600 --> 00:18:25.680]   I wish I had handed it off to this other person
[00:18:25.680 --> 00:18:27.760]   who was, you know, maybe deeper in the organization,
[00:18:27.760 --> 00:18:29.600]   who was maybe younger, who was more like I am,
[00:18:29.600 --> 00:18:30.720]   and maybe would have built new products,
[00:18:30.720 --> 00:18:31.800]   and maybe that was a mistake.
[00:18:31.800 --> 00:18:34.440]   But the fact that they do this over and over again,
[00:18:34.440 --> 00:18:37.280]   to me illustrates why the Burnham theory is correct,
[00:18:37.280 --> 00:18:39.240]   which is large complex organizations
[00:18:39.240 --> 00:18:40.840]   ultimately do end up getting run by managers
[00:18:40.840 --> 00:18:41.840]   in almost all cases.
[00:18:41.840 --> 00:18:46.160]   Again, the only sort of upside, the only sort of good,
[00:18:46.160 --> 00:18:47.000]   you know, I don't know, good news.
[00:18:47.000 --> 00:18:49.400]   The only optimistic kind of, you know, view on that
[00:18:49.400 --> 00:18:52.280]   is that it's the transition from these companies
[00:18:52.280 --> 00:18:55.200]   being in the bourgeois capitalist model
[00:18:55.200 --> 00:18:56.960]   to the managerial model that creates the opportunity
[00:18:56.960 --> 00:18:58.560]   for the new generation of startups, right?
[00:18:58.560 --> 00:19:00.760]   Like, right, because in the counterfactual,
[00:19:00.760 --> 00:19:03.480]   like if these companies remain bourgeois capitalist companies
[00:19:03.480 --> 00:19:04.320]   for a hundred years,
[00:19:04.320 --> 00:19:05.360]   then they would be the companies
[00:19:05.360 --> 00:19:06.280]   to create all the new products.
[00:19:06.280 --> 00:19:08.640]   And then, you know, we wouldn't necessarily need to exist
[00:19:08.640 --> 00:19:10.160]   because those companies would just like,
[00:19:10.160 --> 00:19:11.160]   do what the startups do.
[00:19:11.160 --> 00:19:12.800]   They would just build all the new stuff.
[00:19:12.800 --> 00:19:15.320]   But because they won't do that in that model,
[00:19:15.320 --> 00:19:17.320]   they won't do that and they don't do that
[00:19:17.320 --> 00:19:18.680]   almost without exception, you know,
[00:19:18.680 --> 00:19:20.320]   therefore there's always the opportunity
[00:19:20.320 --> 00:19:21.160]   for the next new startup.
[00:19:21.160 --> 00:19:22.840]   And I think that's good.
[00:19:22.840 --> 00:19:24.400]   Like, I think that, you know,
[00:19:24.400 --> 00:19:25.920]   that keeps the economy, you know, vital,
[00:19:25.920 --> 00:19:27.680]   even in the face of this overwhelming, you know,
[00:19:27.680 --> 00:19:29.320]   trend towards managerialism.
[00:19:29.320 --> 00:19:33.440]   - Now, if you had a fund with a hundred year lock-in,
[00:19:33.440 --> 00:19:34.880]   what would you be able to invest in
[00:19:34.880 --> 00:19:37.240]   that you can't invest in right now?
[00:19:37.240 --> 00:19:39.040]   - Yeah, so the thing with a longer, you know,
[00:19:39.040 --> 00:19:41.000]   so our lock-up now, you know,
[00:19:41.000 --> 00:19:42.800]   the base lock-up for venture is like 10 years.
[00:19:42.800 --> 00:19:44.440]   And then we have the ability to kind of push that out.
[00:19:44.440 --> 00:19:45.840]   You know, we can kind of push that to 15.
[00:19:45.840 --> 00:19:47.120]   And then, you know, I think if we, you know,
[00:19:47.120 --> 00:19:48.240]   for really high quality companies,
[00:19:48.240 --> 00:19:49.400]   we can push that to 20.
[00:19:49.400 --> 00:19:51.320]   You know, we haven't, you know,
[00:19:51.320 --> 00:19:52.320]   we haven't been in business long enough
[00:19:52.320 --> 00:19:54.000]   to try to push it beyond that.
[00:19:54.000 --> 00:19:55.520]   So, you know, we'll see.
[00:19:55.520 --> 00:19:57.920]   You know, the question,
[00:19:57.920 --> 00:19:59.680]   if you could push it to a hundred years,
[00:19:59.680 --> 00:20:00.600]   you know, the question is like,
[00:20:00.600 --> 00:20:03.440]   is it really time that's the bottleneck, right?
[00:20:03.440 --> 00:20:04.560]   Like, are there, in other words,
[00:20:04.560 --> 00:20:05.880]   like the implication of the question would be like,
[00:20:05.880 --> 00:20:09.280]   are there more ambitious projects that would take longer
[00:20:09.280 --> 00:20:10.600]   that you would fund that you're not funding?
[00:20:10.600 --> 00:20:11.640]   'Cause the timeframe's too short.
[00:20:11.720 --> 00:20:13.760]   And the problem with a hundred,
[00:20:13.760 --> 00:20:14.960]   the problem with a hundred year timeframe,
[00:20:14.960 --> 00:20:15.960]   or even a 50 year timeframe,
[00:20:15.960 --> 00:20:18.120]   or even a 20 year timeframe is that
[00:20:18.120 --> 00:20:21.040]   new things don't tend to,
[00:20:21.040 --> 00:20:22.400]   they don't tend to like go through
[00:20:22.400 --> 00:20:24.440]   a 20 year incubation phase in business
[00:20:24.440 --> 00:20:26.280]   and then come out the other end and be good.
[00:20:26.280 --> 00:20:29.040]   Like, basically what seems to happen
[00:20:29.040 --> 00:20:30.240]   is they need milestones.
[00:20:30.240 --> 00:20:33.800]   Like, you know, they need points of contact with reality.
[00:20:33.800 --> 00:20:35.960]   Every once in a while, there will be a company,
[00:20:35.960 --> 00:20:37.440]   a very special company will get funded
[00:20:37.440 --> 00:20:38.280]   with a founder who's like,
[00:20:38.280 --> 00:20:39.360]   "Look, I'm gonna do the long-term thing."
[00:20:39.360 --> 00:20:41.160]   And then they kind of go into a tunnel,
[00:20:41.160 --> 00:20:42.320]   you know, for 10 or 15 years
[00:20:42.320 --> 00:20:43.160]   where they're building something.
[00:20:43.160 --> 00:20:44.840]   And the theory is they're gonna come out the other side.
[00:20:44.840 --> 00:20:47.920]   Like these have existed and these do get funded.
[00:20:47.920 --> 00:20:49.560]   You know, generally they never come out with anything.
[00:20:49.560 --> 00:20:51.640]   Like they just, they end up going,
[00:20:51.640 --> 00:20:52.760]   they end up in their own private,
[00:20:52.760 --> 00:20:54.400]   we call it, they end up in their own private Idaho.
[00:20:54.400 --> 00:20:56.560]   Like they end up in their own internal world.
[00:20:56.560 --> 00:20:58.600]   They don't have contact with reality.
[00:20:58.600 --> 00:21:00.000]   They're not ever in the market.
[00:21:00.000 --> 00:21:01.760]   They're not working with customers.
[00:21:01.760 --> 00:21:03.320]   You know, they just, they start to become
[00:21:03.320 --> 00:21:06.920]   like basically bubbles of their own reality.
[00:21:06.920 --> 00:21:09.480]   And then, you know, they don't like,
[00:21:09.480 --> 00:21:10.960]   look, contact with the real world,
[00:21:10.960 --> 00:21:13.120]   like contact with the real world is difficult.
[00:21:13.120 --> 00:21:13.960]   Like every single time,
[00:21:13.960 --> 00:21:16.320]   like the real world is a pain in the butt.
[00:21:16.320 --> 00:21:20.080]   And, you know, to like mark to market your views
[00:21:20.080 --> 00:21:21.760]   of like what you're doing with the reality
[00:21:21.760 --> 00:21:24.120]   of what like anybody's actually gonna wanna pay for,
[00:21:24.120 --> 00:21:26.360]   like requires you to go expose yourself to that.
[00:21:26.360 --> 00:21:28.920]   Like it's really hard to do that in the abstract
[00:21:28.920 --> 00:21:31.440]   or to build a product that anybody's gonna wanna use.
[00:21:31.440 --> 00:21:33.760]   And so this thing where people go in a tunnel
[00:21:33.760 --> 00:21:36.360]   for 10 or 15 or 20 years, like it doesn't go well.
[00:21:36.360 --> 00:21:37.440]   I think a hundred years would be
[00:21:37.440 --> 00:21:39.200]   an even more degenerate version of that.
[00:21:39.200 --> 00:21:40.680]   Like, I just think they'd end up,
[00:21:40.680 --> 00:21:41.960]   it would just, it would end up, you know,
[00:21:41.960 --> 00:21:44.440]   kind of best case is kind of this unbounded research lab
[00:21:44.440 --> 00:21:45.520]   that maybe would write papers.
[00:21:45.520 --> 00:21:47.000]   And I don't know, you know,
[00:21:47.000 --> 00:21:48.920]   something maybe comes out the other end of the far future
[00:21:48.920 --> 00:21:51.040]   in the form of some open source thing or something,
[00:21:51.040 --> 00:21:54.200]   but like, they're not gonna build an enterprise that way.
[00:21:54.200 --> 00:21:56.920]   And so I think having some level of contact
[00:21:56.920 --> 00:21:58.440]   with reality over the course of for sure,
[00:21:58.440 --> 00:22:01.280]   the first like five to seven years is pretty important.
[00:22:01.280 --> 00:22:03.560]   The other question that I would ask, you know,
[00:22:03.560 --> 00:22:07.440]   the other way to get a kind of your underlying question,
[00:22:07.440 --> 00:22:08.280]   the other thing would just be like,
[00:22:08.280 --> 00:22:10.360]   what if you just had more zeros on the amount of money?
[00:22:10.360 --> 00:22:12.360]   Right, and so what if instead of funding companies
[00:22:12.360 --> 00:22:14.480]   for $20 million, you could fund them for $2 billion
[00:22:14.480 --> 00:22:16.560]   or $20 billion, right?
[00:22:16.560 --> 00:22:17.400]   In other words, you know,
[00:22:17.400 --> 00:22:18.800]   maybe they would operate on the timeframe
[00:22:18.800 --> 00:22:19.640]   of today's companies.
[00:22:19.640 --> 00:22:21.760]   They'd operate on like whatever five or 10 year timeframe,
[00:22:21.760 --> 00:22:23.520]   but you know, you could fund them with 20 billion
[00:22:23.520 --> 00:22:26.480]   of venture financing instead of 20 million.
[00:22:26.480 --> 00:22:29.400]   You know, I think that's a more interesting question.
[00:22:29.400 --> 00:22:31.560]   I think it's possible that there are, you know,
[00:22:31.560 --> 00:22:33.760]   pretty big, you know, fundamental things
[00:22:33.760 --> 00:22:35.720]   that could be built with larger amounts of money
[00:22:35.720 --> 00:22:38.000]   in this kind of entrepreneurial model.
[00:22:38.000 --> 00:22:39.920]   You know, everyone, I mean, look, you get, you know,
[00:22:39.920 --> 00:22:41.440]   every once in a while, you do see, you know,
[00:22:41.440 --> 00:22:42.840]   you do see these like giant, you know,
[00:22:42.840 --> 00:22:44.840]   Tesla and SpaceX is two obvious examples.
[00:22:44.840 --> 00:22:47.640]   Like, you know, of these like world changing things
[00:22:47.640 --> 00:22:48.840]   that just, you know, took a lot of money
[00:22:48.840 --> 00:22:51.080]   and then had really big impact.
[00:22:51.080 --> 00:22:53.000]   And so maybe there's something there
[00:22:53.000 --> 00:22:55.200]   and maybe that's something that the venture ecosystem
[00:22:55.200 --> 00:22:57.480]   should experiment with in the years ahead.
[00:22:57.480 --> 00:22:59.600]   So I would be more focused on that
[00:22:59.600 --> 00:23:01.880]   as opposed to elongating the time.
[00:23:01.880 --> 00:23:03.680]   - But like, what about basic research, right?
[00:23:03.680 --> 00:23:06.800]   So I think you've spoken about the dysfunctions
[00:23:06.800 --> 00:23:09.720]   of the academic government research complex,
[00:23:09.720 --> 00:23:11.120]   but like within the next internet,
[00:23:11.120 --> 00:23:13.520]   the next thing that Andreessen from 10 years from now
[00:23:13.520 --> 00:23:14.720]   is building on top of,
[00:23:14.720 --> 00:23:16.720]   maybe there needs to be some sort of,
[00:23:16.720 --> 00:23:18.440]   if the government effort is broken,
[00:23:18.440 --> 00:23:20.200]   maybe you just need to bootstrap something yourself
[00:23:20.200 --> 00:23:21.760]   or have you considered that?
[00:23:21.760 --> 00:23:24.400]   - Yeah, so the strong version of this argument
[00:23:24.400 --> 00:23:26.680]   is from a guy named Bill Janeway
[00:23:26.680 --> 00:23:28.600]   and he's a legendary VC.
[00:23:28.600 --> 00:23:29.960]   Actually Janeway is a great, a great, a great,
[00:23:29.960 --> 00:23:31.480]   a wonderful guy if people haven't heard of him.
[00:23:31.480 --> 00:23:33.880]   He's a, he was actually, was it a,
[00:23:33.880 --> 00:23:36.160]   he was a, he was, he's a PhD in economics.
[00:23:36.160 --> 00:23:39.840]   I think he's a student of a student of John Maynard Keynes.
[00:23:39.840 --> 00:23:41.520]   So he kind of comes from like a highly pedigreed,
[00:23:41.520 --> 00:23:42.960]   like economic theory background.
[00:23:42.960 --> 00:23:43.800]   And then he was a,
[00:23:43.800 --> 00:23:45.960]   himself a legendary venture capitalist in his career.
[00:23:45.960 --> 00:23:48.600]   He became a Hanson investor at the firm Warburg Pincus
[00:23:48.600 --> 00:23:50.720]   and funded some really interesting companies.
[00:23:50.720 --> 00:23:52.720]   And so he's one of these rare people
[00:23:52.720 --> 00:23:54.640]   who's both theoretical and practical
[00:23:54.640 --> 00:23:56.400]   on this kind of question.
[00:23:56.400 --> 00:23:57.760]   And he wrote this book,
[00:23:57.760 --> 00:24:00.080]   which is, I really recommend,
[00:24:00.080 --> 00:24:02.560]   it's called "Doing Capitalism"
[00:24:02.560 --> 00:24:05.160]   and where he kind of goes through this question.
[00:24:05.160 --> 00:24:07.160]   And so the argument that he makes,
[00:24:07.160 --> 00:24:08.200]   along the lines of what you're saying,
[00:24:08.200 --> 00:24:09.960]   the argument that he makes is basically,
[00:24:09.960 --> 00:24:11.520]   and it's a little bit of a, I don't know,
[00:24:11.520 --> 00:24:12.720]   it's a little bit of a pessimistic argument.
[00:24:12.720 --> 00:24:14.680]   The argument he makes basically is,
[00:24:14.680 --> 00:24:15.680]   if you look at the entire,
[00:24:15.680 --> 00:24:16.920]   if you look at basically the history
[00:24:16.920 --> 00:24:18.080]   of professional venture capital,
[00:24:18.080 --> 00:24:21.560]   which is now like a 60 year journey, basically,
[00:24:21.560 --> 00:24:22.720]   or maybe even 50 years,
[00:24:22.720 --> 00:24:24.560]   it's basically from the late '60s, early '70s
[00:24:24.560 --> 00:24:26.800]   and kind of modern form.
[00:24:26.800 --> 00:24:30.240]   He said, basically the big category that's worked
[00:24:30.240 --> 00:24:32.520]   is computer science.
[00:24:32.520 --> 00:24:34.920]   And then he said, there's the second category
[00:24:34.920 --> 00:24:36.440]   that's worked is biotech.
[00:24:36.440 --> 00:24:38.960]   And then he said, at least at the time of writing,
[00:24:38.960 --> 00:24:40.440]   he said everything else didn't work.
[00:24:40.440 --> 00:24:43.320]   And so all the money that people poured into cleantech
[00:24:43.320 --> 00:24:44.680]   and da, da, da, da, da,
[00:24:44.680 --> 00:24:47.240]   like all these other areas
[00:24:47.240 --> 00:24:49.240]   that venture capitalists tried to fund,
[00:24:49.240 --> 00:24:51.720]   they basically, from a return standpoint,
[00:24:51.720 --> 00:24:52.560]   they just didn't work.
[00:24:52.560 --> 00:24:55.240]   They just, you just wash the, you just burn the capital.
[00:24:55.240 --> 00:24:56.560]   And then what he says is,
[00:24:56.560 --> 00:24:58.480]   and then he says is, it's like the number,
[00:24:58.480 --> 00:25:00.000]   when he wrote the book, he ran the numbers
[00:25:00.000 --> 00:25:01.200]   and it's like, basically computer science
[00:25:01.200 --> 00:25:02.440]   has worked twice as well as biotech
[00:25:02.440 --> 00:25:04.480]   or something like that.
[00:25:04.480 --> 00:25:05.400]   And then what he said is,
[00:25:05.400 --> 00:25:07.120]   what he said is, this is a direct result
[00:25:07.120 --> 00:25:08.440]   of basically federal research funding
[00:25:08.440 --> 00:25:10.440]   over the previous 50 years.
[00:25:10.440 --> 00:25:13.760]   And so he said, basically what computer science-based
[00:25:13.760 --> 00:25:14.760]   venture capital is able to do
[00:25:14.760 --> 00:25:17.680]   is it was able to productize 50 prior years
[00:25:17.680 --> 00:25:20.160]   of basic research in computer science,
[00:25:20.160 --> 00:25:21.800]   information science, information theory,
[00:25:21.800 --> 00:25:24.760]   communications theory, algorithms,
[00:25:24.760 --> 00:25:27.400]   all the stuff that was done in engineering schools,
[00:25:27.400 --> 00:25:32.120]   basically from 1940 through like 1990, right?
[00:25:32.120 --> 00:25:35.680]   And so he said, basically, we are productizing that.
[00:25:35.680 --> 00:25:37.040]   That's been the big thing, right?
[00:25:37.040 --> 00:25:39.840]   And then he said, biotech where,
[00:25:39.840 --> 00:25:41.400]   that sector we're productizing,
[00:25:41.400 --> 00:25:43.920]   basically the work that NIH, right?
[00:25:43.920 --> 00:25:45.520]   And others put into basic research
[00:25:45.520 --> 00:25:46.720]   in the biological sciences.
[00:25:46.720 --> 00:25:49.680]   And he said, that was about half as much money
[00:25:49.680 --> 00:25:51.760]   and maybe about like half as much time,
[00:25:51.760 --> 00:25:53.600]   like that work really started kicking in
[00:25:53.600 --> 00:25:55.640]   in the '60s and '70s, a little bit later.
[00:25:56.640 --> 00:25:57.480]   And then he said, look, he said,
[00:25:57.480 --> 00:25:59.040]   the problem is there aren't other sectors
[00:25:59.040 --> 00:26:01.480]   that have had these huge investments in basic research.
[00:26:01.480 --> 00:26:04.000]   Like they just, there has been no basic,
[00:26:04.000 --> 00:26:05.680]   there's just not this huge backlog
[00:26:05.680 --> 00:26:07.560]   of like basic research into like climate science
[00:26:07.560 --> 00:26:10.160]   or into, take your pick of, I don't know,
[00:26:10.160 --> 00:26:13.040]   online content or like whatever the other sectors are
[00:26:13.040 --> 00:26:15.360]   where people burn a lot of money.
[00:26:15.360 --> 00:26:16.360]   And so he says, look, he says,
[00:26:16.360 --> 00:26:18.040]   if you wanna predict the future of venture capital,
[00:26:18.040 --> 00:26:19.560]   you basically just look at where,
[00:26:19.560 --> 00:26:22.400]   the previous 50 years of where research R&D,
[00:26:22.400 --> 00:26:23.600]   basic research has happened,
[00:26:23.600 --> 00:26:25.760]   federal research funding has happened.
[00:26:25.760 --> 00:26:28.720]   And he said, and again, his strong form of it is,
[00:26:28.720 --> 00:26:30.800]   it's like, there's no shortcuts on this, right?
[00:26:30.800 --> 00:26:32.600]   And so if you're trying to do venture capital
[00:26:32.600 --> 00:26:34.120]   in a sector that doesn't have this big,
[00:26:34.120 --> 00:26:37.440]   basically, kind of install base of basic research
[00:26:37.440 --> 00:26:38.280]   that's already happened,
[00:26:38.280 --> 00:26:40.080]   like you're basically just building up windmills.
[00:26:40.080 --> 00:26:41.400]   I think there's a lot to his argument.
[00:26:41.400 --> 00:26:42.640]   I'm a little more optimistic
[00:26:42.640 --> 00:26:45.000]   about a broader spread of categories.
[00:26:45.000 --> 00:26:46.800]   A big reason I'm more optimistic
[00:26:46.800 --> 00:26:48.000]   about a broader set of categories
[00:26:48.000 --> 00:26:49.520]   is because I think computer science, right,
[00:26:49.520 --> 00:26:52.680]   in particular now applies across more categories, right?
[00:26:52.680 --> 00:26:55.160]   So this was sort of the underlying point
[00:26:55.160 --> 00:26:56.440]   of the software eats the world thesis,
[00:26:56.440 --> 00:26:58.840]   which is computer science used to be,
[00:26:58.840 --> 00:27:00.480]   computers used to be just like an industry,
[00:27:00.480 --> 00:27:02.440]   where just like people made and sold computers,
[00:27:02.440 --> 00:27:04.120]   but now you can apply computer science
[00:27:04.120 --> 00:27:07.480]   into many other markets, financial services and healthcare,
[00:27:07.480 --> 00:27:08.560]   and many, many others,
[00:27:08.560 --> 00:27:10.440]   where it can be a disruptive force.
[00:27:10.440 --> 00:27:13.200]   And so I think there's a payoff to computer science
[00:27:13.200 --> 00:27:15.960]   and software for sure, that can apply in a sectors.
[00:27:15.960 --> 00:27:18.120]   I think maybe some of the biological sciences
[00:27:18.120 --> 00:27:21.240]   can be stretched into other sectors.
[00:27:21.240 --> 00:27:22.080]   You know, and then look,
[00:27:22.080 --> 00:27:23.760]   there's a lot of smart people in the world,
[00:27:23.760 --> 00:27:25.640]   there's niche research efforts all over the place
[00:27:25.640 --> 00:27:28.320]   in many fields that are doing interesting work.
[00:27:28.320 --> 00:27:30.560]   Maybe you don't get a giant industry
[00:27:30.560 --> 00:27:32.400]   out the other end in some new sector,
[00:27:32.400 --> 00:27:34.080]   but maybe you get some very special companies,
[00:27:34.080 --> 00:27:34.920]   you know, doing special.
[00:27:34.920 --> 00:27:36.600]   I mean, look, SpaceX, like, you know,
[00:27:36.600 --> 00:27:38.640]   SpaceX is like a massive advance in aeronautics.
[00:27:38.640 --> 00:27:41.520]   It took advantage of a lot of aeronautics R&D.
[00:27:41.520 --> 00:27:44.000]   It's not like there's some huge aeronautics venture industry,
[00:27:44.000 --> 00:27:46.280]   but yeah, you know, there is a big winner,
[00:27:46.280 --> 00:27:48.840]   you know, at least one, and I think more to come.
[00:27:48.840 --> 00:27:51.640]   And so I'm a little bit more optimistic and open-minded.
[00:27:51.640 --> 00:27:53.920]   You know, I think Bill would probably say that I'm naive.
[00:27:53.920 --> 00:27:54.880]   - Mm-hmm.
[00:27:54.880 --> 00:27:56.200]   No, but you mentioned earlier,
[00:27:56.200 --> 00:27:58.360]   being able to write potentially nine or 10 figure checks
[00:27:58.360 --> 00:28:00.960]   to these companies like SpaceX or Tesla,
[00:28:00.960 --> 00:28:03.360]   who might require the capital to do something grand.
[00:28:03.360 --> 00:28:04.200]   Last I checked,
[00:28:04.200 --> 00:28:07.080]   you guys have 35 billion or something under management.
[00:28:07.080 --> 00:28:09.240]   Do we need to add a few more zeros to that as well?
[00:28:09.240 --> 00:28:11.840]   Is that, will A16Z's assets under management
[00:28:11.840 --> 00:28:14.360]   just keep growing, or will you cap it at some point?
[00:28:14.360 --> 00:28:18.120]   - So we cap, so we cap it, you know, as best we can, right?
[00:28:18.120 --> 00:28:20.320]   We basically cap it to the opportunity set, right?
[00:28:20.320 --> 00:28:23.200]   And so basically our entire model, right?
[00:28:23.200 --> 00:28:25.280]   And it's not a single, you know, it's maybe obvious,
[00:28:25.280 --> 00:28:26.360]   but it's not a single chunk of money.
[00:28:26.360 --> 00:28:27.920]   Like, it's broken into various strategies,
[00:28:27.920 --> 00:28:29.800]   and we apply different strategies in different sectors
[00:28:29.800 --> 00:28:32.000]   at different stages, you know, so it's decomposed.
[00:28:32.000 --> 00:28:32.960]   You know, we have like six, you know,
[00:28:32.960 --> 00:28:34.160]   primary investment groups internally,
[00:28:34.160 --> 00:28:35.440]   so in the different stages,
[00:28:35.440 --> 00:28:36.840]   and so that money's broken out in different ways.
[00:28:36.840 --> 00:28:40.600]   But yeah, I mean, look, you know,
[00:28:40.600 --> 00:28:43.000]   we cap it as best we can to the opportunity set.
[00:28:43.000 --> 00:28:44.400]   We always tell LPs the same thing,
[00:28:44.400 --> 00:28:46.800]   which is we're not trying to grow assets under management.
[00:28:46.800 --> 00:28:47.720]   Like, that's not a goal.
[00:28:47.720 --> 00:28:49.800]   Like, to the best of our ability,
[00:28:49.800 --> 00:28:51.440]   we're trying to maintain whatever return level
[00:28:51.440 --> 00:28:52.760]   we're maintaining.
[00:28:52.760 --> 00:28:54.320]   You know, we are trying to eat market share.
[00:28:54.320 --> 00:28:56.280]   Like, we'd like to eat as much market share as possible,
[00:28:56.280 --> 00:28:57.840]   and then we would like to go fully exploit
[00:28:57.840 --> 00:28:58.960]   the available opportunities.
[00:28:58.960 --> 00:29:00.160]   We'd like to fund all the, you know,
[00:29:00.160 --> 00:29:01.560]   we'd like to fund all the really good founders.
[00:29:01.560 --> 00:29:02.680]   We'd like to back, you know,
[00:29:02.680 --> 00:29:04.840]   all the interesting new spaces.
[00:29:04.840 --> 00:29:05.680]   You know, but we're not,
[00:29:05.680 --> 00:29:06.960]   what we wouldn't want to do
[00:29:06.960 --> 00:29:09.080]   is double assets under management in return for,
[00:29:09.080 --> 00:29:11.480]   you know, 5% lower returns or something like that.
[00:29:11.480 --> 00:29:13.440]   Like, that would be a bad trade for us.
[00:29:13.440 --> 00:29:16.560]   So to put another zero on that,
[00:29:16.560 --> 00:29:18.920]   I think what we would need would be a theory.
[00:29:18.920 --> 00:29:20.600]   As I said, I think we would need a theory
[00:29:20.600 --> 00:29:22.600]   on a different kind of venture capital model,
[00:29:22.600 --> 00:29:24.400]   which would be basically trying to back
[00:29:24.400 --> 00:29:26.320]   much larger scale projects.
[00:29:26.320 --> 00:29:29.560]   And again, I think there's a really big argument
[00:29:29.560 --> 00:29:30.760]   you could make that that's precisely
[00:29:30.760 --> 00:29:31.920]   what firms like ours should be doing.
[00:29:31.920 --> 00:29:33.560]   Like, there are these really big problems in the world,
[00:29:33.560 --> 00:29:35.960]   and maybe we just need to be, like, much more aggressive
[00:29:35.960 --> 00:29:37.040]   about how we go at it.
[00:29:37.040 --> 00:29:37.960]   And we just need, you know,
[00:29:37.960 --> 00:29:39.240]   and we need founders who are more aggressive,
[00:29:39.240 --> 00:29:41.760]   and then we need to back them with more money.
[00:29:41.760 --> 00:29:43.480]   Look, I think you can also argue, like,
[00:29:43.480 --> 00:29:45.120]   either that wouldn't work or we don't need it.
[00:29:45.120 --> 00:29:46.400]   You know, the counter-argument
[00:29:46.400 --> 00:29:48.280]   on the Tesla and SpaceX examples that I gave
[00:29:48.280 --> 00:29:49.520]   is that they didn't need it, right?
[00:29:49.520 --> 00:29:52.560]   They raised money the old fashioned way, right?
[00:29:52.560 --> 00:29:54.360]   They raised money round by round
[00:29:54.360 --> 00:29:56.440]   in the existing venture ecosystem.
[00:29:56.440 --> 00:29:58.440]   And so, you know, for whatever limitations
[00:29:58.440 --> 00:30:00.040]   you think the existing ecosystem has,
[00:30:00.040 --> 00:30:01.840]   and maybe it's not ambitious enough or whatever,
[00:30:01.840 --> 00:30:04.160]   like, it did fund Tesla and SpaceX.
[00:30:04.160 --> 00:30:07.600]   And so, you know, maybe it works.
[00:30:07.600 --> 00:30:09.840]   And then this goes to this underlying question, right?
[00:30:09.840 --> 00:30:11.680]   So the underlying question underneath all this basically
[00:30:11.680 --> 00:30:12.520]   is not the money part.
[00:30:12.520 --> 00:30:13.440]   The underlying question is, like,
[00:30:13.440 --> 00:30:15.760]   how many great entrepreneurs are there, right?
[00:30:15.760 --> 00:30:17.520]   And then how many really big ideas are there
[00:30:17.520 --> 00:30:19.640]   for those entrepreneurs to go after, right?
[00:30:19.640 --> 00:30:21.760]   And then that goes, you know, one level deeper,
[00:30:21.760 --> 00:30:22.600]   which is, okay, well, like,
[00:30:22.600 --> 00:30:23.800]   what makes a great entrepreneur?
[00:30:23.800 --> 00:30:27.040]   Are they born, like, are they trained, right?
[00:30:27.040 --> 00:30:29.800]   Like, what, you know, what made Elon, Elon?
[00:30:29.800 --> 00:30:31.840]   What would you need to do to get 10 more Elons?
[00:30:31.840 --> 00:30:33.640]   What would you need to do to get a hundred more Elons?
[00:30:33.640 --> 00:30:35.840]   What would you need to do to make a thousand more Elons,
[00:30:35.840 --> 00:30:36.680]   right?
[00:30:36.680 --> 00:30:37.520]   Are they already out there
[00:30:37.520 --> 00:30:38.680]   and we just haven't found them yet?
[00:30:38.680 --> 00:30:40.120]   Could we grow them some, you know,
[00:30:40.120 --> 00:30:43.240]   could we grow them in tanks, you know?
[00:30:43.240 --> 00:30:45.440]   - Just like testosterone to the water supply.
[00:30:45.440 --> 00:30:46.480]   - Yeah, like, yeah.
[00:30:46.480 --> 00:30:47.640]   I mean, like, yeah, yeah.
[00:30:47.640 --> 00:30:49.440]   Or do we need, by the way,
[00:30:49.440 --> 00:30:51.120]   do we need a different kind of training program, right?
[00:30:51.120 --> 00:30:52.000]   Do we need, I don't know,
[00:30:52.000 --> 00:30:53.440]   does there need to be a new kind of entrepreneurial
[00:30:53.440 --> 00:30:55.520]   university that trains entrepreneurs, right?
[00:30:55.520 --> 00:30:57.240]   Like, that's just like a totally different thing.
[00:30:57.240 --> 00:30:59.400]   Like, those are the underlying questions, right?
[00:30:59.400 --> 00:31:01.760]   Like, I think if you show me 10 more Elons,
[00:31:01.760 --> 00:31:03.480]   I'll figure out how to fund their companies.
[00:31:03.480 --> 00:31:06.760]   I can tell you, like, we work with a lot of great founders
[00:31:06.760 --> 00:31:10.960]   and we also work with Elon and like, he's still special.
[00:31:10.960 --> 00:31:13.400]   Like, he's still highly, he's still highly,
[00:31:13.400 --> 00:31:14.600]   he's still highly unusual,
[00:31:14.600 --> 00:31:16.560]   even relative to the other great entrepreneurs.
[00:31:16.560 --> 00:31:17.400]   - Yeah, yeah, yeah.
[00:31:17.400 --> 00:31:19.040]   (laughs)
[00:31:19.040 --> 00:31:20.680]   Let's talk about crypto for a second.
[00:31:20.680 --> 00:31:22.720]   When you're investing in crypto projects,
[00:31:22.720 --> 00:31:24.920]   how do you distinguish cases where
[00:31:24.920 --> 00:31:27.200]   there's some real new good or service
[00:31:27.200 --> 00:31:29.040]   that a new technology is enabling
[00:31:29.040 --> 00:31:32.280]   and cases where it's just speculation of some kind?
[00:31:32.280 --> 00:31:34.280]   - Yeah, so what we definitely don't do
[00:31:34.280 --> 00:31:35.360]   is the speculation side.
[00:31:35.360 --> 00:31:36.760]   Like, we just don't do that.
[00:31:36.760 --> 00:31:38.480]   And I mean that very specifically,
[00:31:38.480 --> 00:31:39.640]   which is like, we're not like,
[00:31:39.640 --> 00:31:40.800]   we're not running a hedge fund.
[00:31:40.800 --> 00:31:42.400]   So what we do is we apply
[00:31:42.400 --> 00:31:45.080]   the classic venture capital 101 playbook to crypto.
[00:31:45.080 --> 00:31:47.080]   And we do that the exact same way that we do that
[00:31:47.080 --> 00:31:49.800]   with every other venture sector that we invest in.
[00:31:49.800 --> 00:31:51.880]   Which is to say, we're trying to back basically,
[00:31:51.880 --> 00:31:53.320]   you know, new ventures.
[00:31:53.320 --> 00:31:55.600]   By the way, in crypto, that venture might be a new company
[00:31:55.600 --> 00:31:56.880]   or it might be a new network, right?
[00:31:56.880 --> 00:31:58.840]   Or it might be actually, you know, a hybrid of the two.
[00:31:58.840 --> 00:32:01.960]   And we're completely agnostic as to which way that goes.
[00:32:01.960 --> 00:32:03.840]   We actually write our crypto term sheets
[00:32:03.840 --> 00:32:05.960]   where even when we're backing like a crypto C-Corp,
[00:32:05.960 --> 00:32:07.520]   we always write in the term sheets
[00:32:07.520 --> 00:32:09.880]   that they can flip it into being a tokenized network
[00:32:09.880 --> 00:32:11.320]   anytime they want to, right?
[00:32:11.320 --> 00:32:15.640]   And so we don't distinguish between companies and networks.
[00:32:15.640 --> 00:32:18.320]   But we approach it with the venture capital 101 playbook,
[00:32:18.320 --> 00:32:19.160]   which is like, look,
[00:32:19.160 --> 00:32:21.520]   we're looking for basically really sharp founders
[00:32:21.520 --> 00:32:24.960]   who have a vision and the determination to go after it.
[00:32:24.960 --> 00:32:26.880]   That basically where there's some reason to believe
[00:32:26.880 --> 00:32:28.200]   that there's some sort of deep level
[00:32:28.200 --> 00:32:30.400]   of technological economic change happening,
[00:32:30.400 --> 00:32:31.680]   which is what you need basically
[00:32:31.680 --> 00:32:34.040]   for a new startup to wedge into a market.
[00:32:34.040 --> 00:32:35.200]   And then that there, yeah,
[00:32:35.200 --> 00:32:36.800]   that there's a reason for it to exist.
[00:32:36.800 --> 00:32:38.360]   Like there's a market for what they're building
[00:32:38.360 --> 00:32:39.840]   and they're gonna build a product
[00:32:39.840 --> 00:32:41.440]   and there's gonna be an intersection between product
[00:32:41.440 --> 00:32:43.000]   and market, and there's gonna be a way to make money
[00:32:43.000 --> 00:32:45.960]   and kind of the core playbook.
[00:32:45.960 --> 00:32:48.480]   We go into every venture, every crypto investment
[00:32:48.480 --> 00:32:50.200]   with the same timeframe we go into venture investing.
[00:32:50.200 --> 00:32:52.800]   So we go in with at least a five to 10 year timeframe,
[00:32:52.800 --> 00:32:54.600]   if not a 15 to 20 year timeframe.
[00:32:54.600 --> 00:32:56.680]   And so that's what we do.
[00:32:56.680 --> 00:32:58.960]   The reason that's not necessarily the norm of crypto,
[00:32:58.960 --> 00:33:01.720]   I think is basically an artifact of the fact that,
[00:33:01.720 --> 00:33:04.240]   you know, especially anything with crypto tokens,
[00:33:04.240 --> 00:33:05.960]   like there is this thing where they do tend
[00:33:05.960 --> 00:33:07.360]   to publicly float like a lot sooner
[00:33:07.360 --> 00:33:08.720]   than startup equity floats.
[00:33:08.720 --> 00:33:11.200]   And so, you know, these,
[00:33:11.200 --> 00:33:12.760]   let's say we're backing a new crypto network,
[00:33:12.760 --> 00:33:14.280]   it goes ahead and like floats a token,
[00:33:14.280 --> 00:33:15.760]   you know, as sort of one of the first steps
[00:33:15.760 --> 00:33:16.840]   of what it does.
[00:33:16.840 --> 00:33:19.160]   You know, it has a liquid, you know, thing,
[00:33:19.160 --> 00:33:21.400]   you know, years in advance of when a corresponding,
[00:33:21.400 --> 00:33:22.840]   you know, normal C corp would.
[00:33:22.840 --> 00:33:24.080]   There's a weird thing in behavioral economics
[00:33:24.080 --> 00:33:25.840]   where when something has a daily price signal
[00:33:25.840 --> 00:33:27.440]   and where you can trade it,
[00:33:27.440 --> 00:33:29.240]   people tend to obsess on the daily price signal
[00:33:29.240 --> 00:33:32.120]   and they tend to trade it too much, right?
[00:33:32.120 --> 00:33:33.720]   And there's all this literature on this
[00:33:33.720 --> 00:33:34.920]   that kind of shows how this happens.
[00:33:34.920 --> 00:33:36.280]   Like it's part of the human experience.
[00:33:36.280 --> 00:33:37.120]   Like we can't help ourselves.
[00:33:37.120 --> 00:33:38.200]   Like it's like moss to a flame.
[00:33:38.200 --> 00:33:39.960]   We can't, like, if I can trade the stock every day,
[00:33:39.960 --> 00:33:41.040]   I trade the stock every day, right?
[00:33:41.040 --> 00:33:43.000]   Like, like almost all, almost every investor
[00:33:43.000 --> 00:33:45.080]   in almost every asset class trades too often
[00:33:45.080 --> 00:33:47.560]   in a way that damages their returns.
[00:33:47.560 --> 00:33:49.120]   And so, and then as a consequence of that,
[00:33:49.120 --> 00:33:52.240]   what's happened is a lot of the investment firms
[00:33:52.240 --> 00:33:55.040]   that invest in crypto startups are actually hedge funds,
[00:33:55.040 --> 00:33:55.880]   right?
[00:33:55.880 --> 00:33:57.320]   They're structured as hedge funds, right?
[00:33:57.320 --> 00:33:58.960]   They trade, they have trading desks,
[00:33:58.960 --> 00:34:00.560]   they trade frequently, you know,
[00:34:00.560 --> 00:34:02.400]   they have the equivalent of what's called
[00:34:02.400 --> 00:34:03.640]   a public book in hedge fund land.
[00:34:03.640 --> 00:34:04.480]   They've got like, you know,
[00:34:04.480 --> 00:34:06.440]   these crypto assets they're trading frequently
[00:34:06.440 --> 00:34:07.280]   and then they'll back a startup
[00:34:07.280 --> 00:34:09.040]   and then they'll trade that startup's token
[00:34:09.040 --> 00:34:11.480]   just like they trade Bitcoin or Ethereum or whatever.
[00:34:11.480 --> 00:34:13.000]   But in our view, like that's the wrong way.
[00:34:13.000 --> 00:34:15.480]   And then by the way, there's an incentive issue,
[00:34:15.480 --> 00:34:16.640]   which is then they pay, you know,
[00:34:16.640 --> 00:34:18.080]   they pay themselves on a hedge fund model.
[00:34:18.080 --> 00:34:19.840]   They pay themselves annually, right?
[00:34:19.840 --> 00:34:21.360]   And so they're paying themselves annually
[00:34:21.360 --> 00:34:22.560]   based on the markup of projects
[00:34:22.560 --> 00:34:24.080]   that might still be years away from, you know,
[00:34:24.080 --> 00:34:26.760]   realization of ultimate underlying value.
[00:34:26.760 --> 00:34:28.400]   And then you, and then there's this big issue,
[00:34:28.400 --> 00:34:31.160]   you know, of misalignment between them and their OPs.
[00:34:31.160 --> 00:34:32.760]   And so, so that, so anyway,
[00:34:32.760 --> 00:34:34.320]   so that's all led to this thing
[00:34:34.320 --> 00:34:36.200]   where it basically just these new crypto projects,
[00:34:36.200 --> 00:34:38.400]   the tokens are traded too aggressively.
[00:34:38.400 --> 00:34:41.040]   They just, in our model, they just shouldn't be,
[00:34:41.040 --> 00:34:42.440]   they're not ready for that yet.
[00:34:42.440 --> 00:34:45.440]   And so we anchor hard on the venture capital model.
[00:34:45.440 --> 00:34:47.200]   We treat these investments the exact same way
[00:34:47.200 --> 00:34:49.200]   as if we're investing in venture capital equity,
[00:34:49.200 --> 00:34:50.760]   we basically buy and hold, you know,
[00:34:50.760 --> 00:34:51.960]   for as long as we can.
[00:34:51.960 --> 00:34:55.600]   And, you know, and try to get to the, you know,
[00:34:55.600 --> 00:34:57.720]   have a real focus on the underlying intrinsic value
[00:34:57.720 --> 00:34:59.680]   of the product and technology that's being developed.
[00:34:59.680 --> 00:35:01.720]   So in other words, like, yeah, basically no speculation,
[00:35:01.720 --> 00:35:05.480]   like no, if by speculation you mean like daily trading
[00:35:05.480 --> 00:35:07.120]   or whatever, trying to look at prices and charts
[00:35:07.120 --> 00:35:09.400]   and all that stuff, like we don't, that we don't do.
[00:35:09.400 --> 00:35:11.800]   - Or separately, another category would be things
[00:35:11.800 --> 00:35:13.800]   that are basically the equivalent of, I don't know,
[00:35:13.800 --> 00:35:17.320]   baseball cards where there's no real good or service
[00:35:17.320 --> 00:35:18.160]   that's being created.
[00:35:18.160 --> 00:35:19.520]   It is something that, you know,
[00:35:19.520 --> 00:35:21.480]   you might think might be valuable in the future,
[00:35:21.480 --> 00:35:24.200]   but not because like the GDP has gone up.
[00:35:24.200 --> 00:35:26.880]   - Oh, baseball cards are a totally valid good and service.
[00:35:26.880 --> 00:35:27.720]   That's a misnomer.
[00:35:27.720 --> 00:35:31.360]   Like that's not, yeah, that I think is a,
[00:35:31.360 --> 00:35:33.960]   I would entirely disagree with the premise of that question.
[00:35:33.960 --> 00:35:35.560]   - But are they going to raise median incomes
[00:35:35.560 --> 00:35:37.720]   or even slightly?
[00:35:37.720 --> 00:35:38.800]   - Yeah, yeah, there are people who make, yeah,
[00:35:38.800 --> 00:35:41.040]   there are people who make their living on baseball cards.
[00:35:41.040 --> 00:35:42.360]   - Right, right, right.
[00:35:42.360 --> 00:35:44.600]   - Collect, look, art, art is a, art is,
[00:35:44.600 --> 00:35:47.800]   art has been a part of the economy for thousands of,
[00:35:47.800 --> 00:35:49.920]   I mean, art, art's one of the original things
[00:35:49.920 --> 00:35:51.120]   that people bought and sold, right?
[00:35:51.120 --> 00:35:54.000]   Like it's, it's, art is, art is fundamental
[00:35:54.000 --> 00:35:56.480]   to any, I mean, any, any kind of, I mean,
[00:35:56.480 --> 00:35:57.800]   would you really want to be part of an economy
[00:35:57.800 --> 00:35:59.200]   where they didn't value art?
[00:35:59.200 --> 00:36:02.360]   But like, that would be depressing.
[00:36:02.360 --> 00:36:04.440]   - Yeah, yeah, or like, but there's a question of like,
[00:36:04.440 --> 00:36:06.440]   do they value art versus are they speculating on art?
[00:36:06.440 --> 00:36:09.000]   And then how much of the effort is being spent
[00:36:09.000 --> 00:36:12.000]   on speculating on the art versus creating the art?
[00:36:12.000 --> 00:36:15.200]   - Well, so this gets into this old kind of taboo, right?
[00:36:15.200 --> 00:36:16.800]   Cultural taboo, you know, this, again,
[00:36:16.800 --> 00:36:18.400]   this depends what you mean by speculation.
[00:36:18.400 --> 00:36:20.600]   Like if, if what you mean by speculation
[00:36:20.600 --> 00:36:22.720]   is like obsessing on like daily price signals
[00:36:22.720 --> 00:36:25.520]   and like buying and selling and churning a portfolio, right?
[00:36:25.520 --> 00:36:26.680]   Being like a day trader, right?
[00:36:26.680 --> 00:36:28.520]   Like that kind of speculation, that, that, that,
[00:36:28.520 --> 00:36:30.320]   that's what I think of speculation is.
[00:36:30.320 --> 00:36:32.880]   Like that's, let's say that's the bad form of speculation.
[00:36:32.880 --> 00:36:34.880]   Like that's the non-productive form.
[00:36:34.880 --> 00:36:37.720]   If by speculation, on the other hand, you know,
[00:36:37.720 --> 00:36:40.200]   you mean, look, there, there are different kinds of things
[00:36:40.200 --> 00:36:42.880]   in the world that have different possible future values.
[00:36:42.880 --> 00:36:44.400]   And, you know, people are trying to estimate
[00:36:44.400 --> 00:36:46.360]   those future values and people are trying to figure out,
[00:36:46.360 --> 00:36:47.800]   you know, utility and they're trying to figure out
[00:36:47.800 --> 00:36:49.120]   aesthetic value, right?
[00:36:49.120 --> 00:36:50.120]   I mean, look, you just look at how the,
[00:36:50.120 --> 00:36:51.920]   look at how the traditional art market works, right?
[00:36:51.920 --> 00:36:54.080]   Like is somebody supporting a new contemporary artist
[00:36:54.080 --> 00:36:55.840]   speculating or not?
[00:36:55.840 --> 00:36:57.400]   It's like, you know, yes, maybe, you know,
[00:36:57.400 --> 00:36:58.640]   from, from one lens they are,
[00:36:58.640 --> 00:37:00.040]   and maybe they're buying and selling paintings
[00:37:00.040 --> 00:37:01.760]   and maybe they're, you know, maybe they, they buy in
[00:37:01.760 --> 00:37:03.400]   and if it doesn't start going up in price,
[00:37:03.400 --> 00:37:04.400]   they flip it and buy something else.
[00:37:04.400 --> 00:37:06.560]   Maybe the speculation, but also maybe they're supporting
[00:37:06.560 --> 00:37:08.280]   a new young artist, right?
[00:37:08.280 --> 00:37:10.920]   And maybe they build a portfolio of, of new, you know,
[00:37:10.920 --> 00:37:13.320]   a speculative portfolio of new young artists.
[00:37:13.320 --> 00:37:15.280]   And as a consequence, those artists can then afford,
[00:37:15.280 --> 00:37:16.280]   you know, they can get, and get paid
[00:37:16.280 --> 00:37:17.520]   and they can afford to be full-time artists.
[00:37:17.520 --> 00:37:18.960]   And then it turns out, you know, they're the next,
[00:37:18.960 --> 00:37:20.120]   you know, next Picasso.
[00:37:20.120 --> 00:37:23.320]   And so that kind of speculation I think is,
[00:37:23.320 --> 00:37:24.280]   is good and healthy.
[00:37:24.280 --> 00:37:27.520]   And I think it's, it's core to everything.
[00:37:27.520 --> 00:37:29.320]   Like, I'd also say this, like,
[00:37:29.320 --> 00:37:30.680]   I don't know that there's,
[00:37:30.680 --> 00:37:32.200]   I don't know that there's actually a dividing line
[00:37:32.200 --> 00:37:33.520]   between that form of speculation,
[00:37:33.520 --> 00:37:35.600]   speculation of what people call investments.
[00:37:35.600 --> 00:37:37.040]   'Cause even when people make investments,
[00:37:37.040 --> 00:37:38.520]   I mean, you just look at the bond,
[00:37:38.520 --> 00:37:40.040]   even just the institutional bond market.
[00:37:40.040 --> 00:37:43.080]   I mean, look, US government debt, right?
[00:37:43.080 --> 00:37:44.640]   Like people are today in the bond market
[00:37:44.640 --> 00:37:46.120]   trying to figure out what that's worth, right?
[00:37:46.120 --> 00:37:46.960]   'Cause like, as you know,
[00:37:46.960 --> 00:37:48.120]   is the debt ceiling gonna get raised?
[00:37:48.120 --> 00:37:49.280]   Like, you know, they're,
[00:37:49.280 --> 00:37:51.400]   like even that's up for grabs, right?
[00:37:51.400 --> 00:37:53.480]   And so, and that's, and that's the, that's not,
[00:37:53.480 --> 00:37:55.000]   to me, that's not speculation in the bad sense.
[00:37:55.000 --> 00:37:56.480]   That's a market working properly.
[00:37:56.480 --> 00:37:58.160]   Like people are trying to estimate, you know, people,
[00:37:58.160 --> 00:38:00.120]   you know, Ben Graham said, right?
[00:38:00.120 --> 00:38:01.600]   Financial markets are both a voting machine
[00:38:01.600 --> 00:38:02.640]   and a weighing machine, right?
[00:38:02.640 --> 00:38:04.360]   And in the short term, they tend to be a voting machine.
[00:38:04.360 --> 00:38:06.800]   In the long run, they tend to be a weighing machine.
[00:38:06.800 --> 00:38:08.480]   What's the difference between a voting machine
[00:38:08.480 --> 00:38:09.320]   and a weighing machine?
[00:38:09.320 --> 00:38:10.160]   I mean, I don't know.
[00:38:10.160 --> 00:38:11.480]   Some people would say they're very different.
[00:38:11.480 --> 00:38:13.240]   Maybe it's actually the same thing.
[00:38:13.240 --> 00:38:14.920]   Why do prices go up, right?
[00:38:14.920 --> 00:38:16.120]   'Cause there are more buyers than sellers.
[00:38:16.120 --> 00:38:16.960]   Why do prices go down?
[00:38:16.960 --> 00:38:18.960]   There are more sellers than buyers.
[00:38:18.960 --> 00:38:21.680]   Like the way markets work is you get individuals,
[00:38:21.680 --> 00:38:23.400]   you know, basically trying to make these estimations
[00:38:23.400 --> 00:38:24.560]   and then you get the collective effect.
[00:38:24.560 --> 00:38:26.240]   And I just, there's this,
[00:38:26.240 --> 00:38:29.080]   there's this dirty interpretation of any kind of trading
[00:38:29.080 --> 00:38:31.520]   or any kind of basically people trying to, you know,
[00:38:31.520 --> 00:38:33.720]   do the voting and weighing process that I just, you know,
[00:38:33.720 --> 00:38:36.600]   I just think it's this historical ancient taboo
[00:38:36.600 --> 00:38:38.880]   against like money, you know, it's like in the Bible,
[00:38:38.880 --> 00:38:39.720]   like it's like, you know,
[00:38:39.720 --> 00:38:41.680]   Jesus kicking the money changers out of the temple, right?
[00:38:41.680 --> 00:38:43.360]   It's this, you know, this old taboo
[00:38:43.360 --> 00:38:45.800]   against like charging interest on debt, right?
[00:38:45.800 --> 00:38:46.720]   We just have, right?
[00:38:46.720 --> 00:38:48.080]   We just have this fundamental, you know,
[00:38:48.080 --> 00:38:49.680]   different religions and cultures tend to have,
[00:38:49.680 --> 00:38:52.400]   they all tend to have like some underlying unease, right?
[00:38:52.400 --> 00:38:54.280]   With the concept of money, the concept of trade,
[00:38:54.280 --> 00:38:56.080]   the concept of interest, right?
[00:38:56.080 --> 00:38:58.120]   And I just think it's like, it's like superstition.
[00:38:58.120 --> 00:39:00.240]   It's like resentment, you know, it's like, you know,
[00:39:00.240 --> 00:39:01.360]   fear of the unknown,
[00:39:01.360 --> 00:39:05.200]   but those things are the things that make economies work.
[00:39:05.200 --> 00:39:07.040]   And so I'm all in favor.
[00:39:07.040 --> 00:39:08.600]   - I don't mean to get hung up on this,
[00:39:08.600 --> 00:39:10.160]   but if you think of like something like the stock market
[00:39:10.160 --> 00:39:11.800]   or the bond market, I mean, fundamentally,
[00:39:11.800 --> 00:39:14.280]   you can tell a story there where basically the reason what
[00:39:14.280 --> 00:39:17.720]   these, you know, stockbrokers or these hedge fund managers
[00:39:17.720 --> 00:39:19.680]   are doing is valuable is because they're basically deciding
[00:39:19.680 --> 00:39:20.520]   where capital should go.
[00:39:20.520 --> 00:39:22.040]   Should we build a factory in Milwaukee?
[00:39:22.040 --> 00:39:23.120]   Should we build it in Toronto?
[00:39:23.120 --> 00:39:24.280]   Like where should it, like fundamentally,
[00:39:24.280 --> 00:39:25.320]   where should capital go?
[00:39:25.320 --> 00:39:26.880]   Whereas what is the story there for like,
[00:39:26.880 --> 00:39:30.240]   what is the NFT helping allocate the capital towards?
[00:39:30.240 --> 00:39:31.840]   Like, why is it, why does it matter
[00:39:31.840 --> 00:39:33.600]   if the price is efficient there?
[00:39:33.600 --> 00:39:34.440]   - Oh, 'cause it's art.
[00:39:34.440 --> 00:39:36.480]   I mean, I mean, let's just take the pure,
[00:39:36.480 --> 00:39:38.560]   and look, NFT is a very general concept, right?
[00:39:38.560 --> 00:39:41.360]   NFT is basically just like a form of digital ownership.
[00:39:41.360 --> 00:39:42.360]   There are many kinds,
[00:39:42.360 --> 00:39:44.040]   there will be many kinds of NFTs in the future.
[00:39:44.040 --> 00:39:45.000]   Many of them will, for example,
[00:39:45.000 --> 00:39:47.440]   represent claims on real underlying property, right?
[00:39:47.440 --> 00:39:48.480]   Like I think a lot of real assets
[00:39:48.480 --> 00:39:49.320]   are gonna get wrapped in NFTs.
[00:39:49.320 --> 00:39:52.680]   And so like NFT is a very broad technological mechanism,
[00:39:52.680 --> 00:39:54.960]   but let's specifically take the form of NFT
[00:39:54.960 --> 00:39:56.120]   that everybody likes to criticize,
[00:39:56.120 --> 00:39:57.960]   which is like NFT is like a creative,
[00:39:57.960 --> 00:40:00.040]   basically a creative project, a creative,
[00:40:00.040 --> 00:40:02.800]   an image or a character in a fictional universe
[00:40:02.800 --> 00:40:03.640]   or something like that.
[00:40:03.640 --> 00:40:06.240]   Like the part that people like to beat on.
[00:40:06.240 --> 00:40:07.960]   And I'm just saying like, they're just art.
[00:40:07.960 --> 00:40:09.560]   Like that's just digital art, right?
[00:40:09.560 --> 00:40:11.440]   And so every criticism people make of that
[00:40:11.440 --> 00:40:12.720]   is the same criticism you would make
[00:40:12.720 --> 00:40:14.080]   of buying and selling paintings.
[00:40:14.080 --> 00:40:17.000]   It would be the same buying and selling photographs, right?
[00:40:17.000 --> 00:40:19.160]   Of buying and selling sculpture, right?
[00:40:19.160 --> 00:40:22.760]   Like, I mean, I always like to really push this.
[00:40:22.760 --> 00:40:23.600]   I always like to push this.
[00:40:23.600 --> 00:40:26.080]   Like, what's the Mona Lisa worth?
[00:40:26.080 --> 00:40:27.040]   I don't wanna spoil the movie,
[00:40:27.040 --> 00:40:28.480]   but you know, the new "Knives Out" movie,
[00:40:28.480 --> 00:40:31.920]   let's just say the Mona Lisa plays a role in the movie.
[00:40:31.920 --> 00:40:34.040]   What's the Mona Lisa worth, right?
[00:40:34.040 --> 00:40:36.200]   And so one way of looking at the Mona Lisa
[00:40:36.200 --> 00:40:38.920]   is that it's worth the cost of producing it, right?
[00:40:38.920 --> 00:40:41.520]   It's worth the canvas and the paint, right?
[00:40:41.520 --> 00:40:44.520]   And you can create a completely identical reproduction
[00:40:44.520 --> 00:40:47.080]   of the Mona Lisa with like 25 bucks of canvas and paint.
[00:40:47.080 --> 00:40:49.360]   So the Mona Lisa is worth 25 bucks.
[00:40:49.360 --> 00:40:52.040]   Or you could say the Mona Lisa is like a cultural artifact.
[00:40:52.040 --> 00:40:53.600]   And as a cultural artifact, it's worth, you know,
[00:40:53.600 --> 00:40:55.880]   probably a billion dollars or $10 billion, right?
[00:40:55.880 --> 00:40:58.800]   And so, and like, I bring this up specifically
[00:40:58.800 --> 00:41:00.440]   on your question of like, okay, what's the spread?
[00:41:00.440 --> 00:41:02.400]   Like, what explains the spread between $25
[00:41:02.400 --> 00:41:04.200]   and like the $10 billion or whatever
[00:41:04.200 --> 00:41:06.560]   that it would go at if it ever hit the market?
[00:41:06.560 --> 00:41:08.560]   It's like, because people care, right?
[00:41:08.560 --> 00:41:10.280]   Because it's art, because it's aesthetic,
[00:41:10.280 --> 00:41:11.520]   because it's cultural, right?
[00:41:11.520 --> 00:41:13.800]   Because it's part of what we've decided
[00:41:13.800 --> 00:41:15.680]   is the cultural heritage of humanity.
[00:41:15.680 --> 00:41:17.320]   The thing that makes like life worth living
[00:41:17.320 --> 00:41:19.880]   is that it's not just about like subsistence, right?
[00:41:19.880 --> 00:41:21.400]   Is that we're gonna have higher values
[00:41:21.400 --> 00:41:23.200]   and we're gonna value aesthetics, right?
[00:41:23.200 --> 00:41:25.120]   - Do you see a difference between, you know,
[00:41:25.120 --> 00:41:28.480]   the funding the flying cars and the SpaceXs and Teslas
[00:41:28.480 --> 00:41:30.560]   versus, but sure, maybe it like improves
[00:41:30.560 --> 00:41:32.360]   the aesthetic heritage of humanity,
[00:41:32.360 --> 00:41:34.800]   but does one of them seem a different category
[00:41:34.800 --> 00:41:35.960]   than the other to you?
[00:41:35.960 --> 00:41:37.720]   Or is it basically, is that all included
[00:41:37.720 --> 00:41:39.160]   in the venture stuff you're interested in?
[00:41:39.160 --> 00:41:40.520]   - I mean, it's a little bit like saying, you know,
[00:41:40.520 --> 00:41:42.960]   should we fund a Thomas Edison or Beethoven, right?
[00:41:42.960 --> 00:41:45.600]   Like, like if push comes to shove
[00:41:45.600 --> 00:41:46.480]   and we can only fund one of them,
[00:41:46.480 --> 00:41:48.480]   we probably should fund Edison and not Beethoven, right?
[00:41:48.480 --> 00:41:50.240]   Like indoor lighting is probably more important
[00:41:50.240 --> 00:41:53.480]   than like music, but like,
[00:41:53.480 --> 00:41:55.240]   I don't wanna live without Beethoven, right?
[00:41:55.240 --> 00:41:58.480]   Like, and I don't want the world to like,
[00:41:58.480 --> 00:42:00.280]   the point of the world,
[00:42:00.280 --> 00:42:01.920]   this actually I think is a very important point.
[00:42:01.920 --> 00:42:03.200]   The point of the world, right?
[00:42:03.200 --> 00:42:05.120]   The point of human, like people have lots
[00:42:05.120 --> 00:42:06.320]   and lots of views on human existence.
[00:42:06.320 --> 00:42:07.840]   There's lots and lots of people trying to figure out
[00:42:07.840 --> 00:42:09.320]   the point of human existence, you know,
[00:42:09.320 --> 00:42:10.800]   religions and philosophies and so forth,
[00:42:10.800 --> 00:42:13.120]   but kind of what they all have in common is, right?
[00:42:13.120 --> 00:42:15.800]   Other than maybe Marxism, what they all have in common is
[00:42:15.800 --> 00:42:17.800]   we're not just here to like get up in the morning,
[00:42:17.800 --> 00:42:19.600]   work in a factory all day, go home at night,
[00:42:19.600 --> 00:42:21.880]   like, you know, be depressed and sad, go to bed.
[00:42:21.880 --> 00:42:23.680]   Like we're not, it's not, we don't,
[00:42:23.680 --> 00:42:25.280]   we're not just material, right?
[00:42:25.280 --> 00:42:26.800]   Like whatever this is all about,
[00:42:26.800 --> 00:42:29.000]   like it's not just about materiality.
[00:42:29.000 --> 00:42:31.160]   There are higher aspirations and higher goals, right?
[00:42:31.160 --> 00:42:32.680]   And we create art, we create literature,
[00:42:32.680 --> 00:42:34.080]   we create paintings, we create sculptures,
[00:42:34.080 --> 00:42:36.920]   we create like aesthetics, like we create fashion, right?
[00:42:36.920 --> 00:42:38.640]   We create music, we create, you know,
[00:42:38.640 --> 00:42:41.560]   like all of these things and, you know, fiction, fiction,
[00:42:41.560 --> 00:42:43.120]   like why does fiction exist?
[00:42:43.120 --> 00:42:45.360]   Like, why is a fake story worth anything?
[00:42:45.360 --> 00:42:47.240]   Well, 'cause people, it enhances your life
[00:42:47.240 --> 00:42:49.040]   to get like wrapped up in a fake story, right?
[00:42:49.040 --> 00:42:50.920]   It like makes your life better that these things exist.
[00:42:50.920 --> 00:42:52.320]   Like, and you wouldn't want to live in a world, you know,
[00:42:52.320 --> 00:42:53.840]   imagine living in a world where there's no fiction
[00:42:53.840 --> 00:42:55.280]   'cause everybody's like, you know,
[00:42:55.280 --> 00:42:57.120]   the grinds are all like, oh, fiction's not useful.
[00:42:57.120 --> 00:42:59.200]   Like, it's not real, right?
[00:42:59.200 --> 00:43:01.120]   It's like, no, like it's great.
[00:43:01.120 --> 00:43:02.640]   Like, I want to live in a world where there's fiction.
[00:43:02.640 --> 00:43:04.320]   Like, I like nothing more at the end of the day
[00:43:04.320 --> 00:43:06.000]   than having a couple hours to be able to get outside
[00:43:06.000 --> 00:43:07.400]   of my own head and like watch a really good movie.
[00:43:07.400 --> 00:43:08.440]   And like, I don't want to live in a world
[00:43:08.440 --> 00:43:09.600]   where that doesn't happen.
[00:43:09.600 --> 00:43:11.520]   As a consequence, funding movies, right,
[00:43:11.520 --> 00:43:13.040]   as another example of what you're talking about
[00:43:13.040 --> 00:43:15.680]   is I think a thing that like really makes the world better.
[00:43:15.680 --> 00:43:18.440]   So, and then, look, here's the other thing.
[00:43:18.440 --> 00:43:20.680]   The world we live in actually is the opposite,
[00:43:20.680 --> 00:43:22.440]   I think, of the world you're alluding to.
[00:43:22.440 --> 00:43:23.960]   The world we live in is not a world
[00:43:23.960 --> 00:43:26.000]   in which we have to choose between funding flying cars
[00:43:26.000 --> 00:43:27.480]   and funding NFTs, right?
[00:43:27.480 --> 00:43:28.320]   Or like in my example,
[00:43:28.320 --> 00:43:29.680]   funding Edison versus funding Beethoven.
[00:43:29.680 --> 00:43:31.520]   The world we live in is actually the opposite of that
[00:43:31.520 --> 00:43:33.520]   where we have a massive oversupply of capital
[00:43:33.520 --> 00:43:35.960]   and not nearly enough things to fund, right?
[00:43:35.960 --> 00:43:38.320]   Just broadly in the world,
[00:43:38.320 --> 00:43:39.440]   the nature of the modern economy
[00:43:39.440 --> 00:43:40.800]   is we have what Ben Bernanke called
[00:43:40.800 --> 00:43:42.320]   the global savings glut.
[00:43:42.320 --> 00:43:44.960]   We've just got this like massive oversupply of capital
[00:43:44.960 --> 00:43:46.600]   that was generated by the last 200 years
[00:43:46.600 --> 00:43:47.560]   of economic activity.
[00:43:47.560 --> 00:43:50.080]   And there is just, and then there's only one Elon.
[00:43:50.080 --> 00:43:53.760]   Like there's just this massive supply demand imbalance
[00:43:53.760 --> 00:43:54.760]   between the amount of capital
[00:43:54.760 --> 00:43:56.800]   that basically needs to generate a return
[00:43:56.800 --> 00:43:58.520]   and then the actual number of like viable,
[00:43:58.520 --> 00:44:00.120]   investable projects and great entrepreneurs
[00:44:00.120 --> 00:44:01.320]   to actually create those projects.
[00:44:01.320 --> 00:44:03.480]   And so, like if anything, we don't,
[00:44:03.480 --> 00:44:04.800]   I mean, as you kind of say,
[00:44:04.800 --> 00:44:07.160]   we don't, we certainly don't have enough flying car startups.
[00:44:07.160 --> 00:44:08.440]   We also don't have enough art startups.
[00:44:08.440 --> 00:44:11.120]   Like we need more of all of this, right?
[00:44:11.120 --> 00:44:12.920]   And so that, I don't think there's a trade-off.
[00:44:12.920 --> 00:44:15.960]   I think it's actually, we need more of all of it.
[00:44:15.960 --> 00:44:17.600]   - Have you reached the end of history
[00:44:17.600 --> 00:44:19.360]   when it comes to how venture capital works?
[00:44:19.360 --> 00:44:21.560]   So, you know, for decades, there's like the,
[00:44:21.560 --> 00:44:23.600]   you basically get equity in these early stage companies.
[00:44:23.600 --> 00:44:26.120]   You invest more of a round, there's a two 20 structure.
[00:44:26.120 --> 00:44:27.520]   Is that basically what venture is gonna look like
[00:44:27.520 --> 00:44:30.160]   in 50 years or what's gonna change?
[00:44:30.160 --> 00:44:32.040]   - So I think the details will change
[00:44:32.040 --> 00:44:33.360]   and the details have changed a lot.
[00:44:33.360 --> 00:44:34.880]   And the details will change a lot.
[00:44:34.880 --> 00:44:36.840]   And if you go back to the late 60s, early 70s,
[00:44:36.840 --> 00:44:38.880]   it's like the details were different then.
[00:44:38.880 --> 00:44:41.160]   And then, you know, the details were different 20 years ago.
[00:44:41.160 --> 00:44:43.200]   By the way, they're changing again right now
[00:44:43.200 --> 00:44:44.680]   in a bunch of ways.
[00:44:44.680 --> 00:44:47.320]   And so the details will change.
[00:44:47.320 --> 00:44:50.120]   Having said that, I think there's a core kind of,
[00:44:50.120 --> 00:44:53.600]   I don't know, there's a core activity that is,
[00:44:53.600 --> 00:44:56.160]   there's a core activity that seems very fundamental.
[00:44:56.160 --> 00:45:00.000]   And the term I use, I borrowed from Tyler Cohen,
[00:45:00.000 --> 00:45:03.040]   who's talked about this, he calls it project picking.
[00:45:03.040 --> 00:45:05.240]   When you're doing new things, right?
[00:45:05.240 --> 00:45:07.080]   And by the way, new things, new tech startups,
[00:45:07.080 --> 00:45:10.040]   by the way, making new movies, publishing new books,
[00:45:10.880 --> 00:45:13.080]   you know, creating new art, right?
[00:45:13.080 --> 00:45:14.880]   When you're doing something new,
[00:45:14.880 --> 00:45:17.480]   there's this pattern that just repeats over and over again.
[00:45:17.480 --> 00:45:18.520]   If you look back in history,
[00:45:18.520 --> 00:45:20.080]   it's basically been the pattern for, you know,
[00:45:20.080 --> 00:45:21.160]   hundreds or thousands of years.
[00:45:21.160 --> 00:45:22.440]   And it seems like it's still a pattern,
[00:45:22.440 --> 00:45:24.480]   which is you're gonna do something new.
[00:45:24.480 --> 00:45:25.560]   It's gonna be very risky.
[00:45:25.560 --> 00:45:28.320]   It's gonna be a very complex undertaking, right?
[00:45:28.320 --> 00:45:29.160]   Like I said earlier,
[00:45:29.160 --> 00:45:31.520]   it's gonna be some very complicated effort
[00:45:31.520 --> 00:45:34.040]   that's gonna involve a path-dependent kind of journey
[00:45:34.040 --> 00:45:35.320]   through a complex adaptive system.
[00:45:35.320 --> 00:45:37.760]   Reality is gonna be very fuzzy and messy.
[00:45:38.760 --> 00:45:42.480]   And you're gonna have a very idiosyncratic set of people
[00:45:42.480 --> 00:45:44.920]   who, you know, start and run that project.
[00:45:44.920 --> 00:45:47.000]   They're gonna be highly disagreeable, you know,
[00:45:47.000 --> 00:45:48.560]   ornery people,
[00:45:48.560 --> 00:45:50.840]   'cause that's the kind of people who do new things.
[00:45:50.840 --> 00:45:52.680]   They're going to need to build something
[00:45:52.680 --> 00:45:53.920]   bigger than themselves, right?
[00:45:53.920 --> 00:45:55.280]   They're gonna need to like assemble a team
[00:45:55.280 --> 00:45:56.520]   and like a whole effort.
[00:45:56.520 --> 00:45:58.360]   They're gonna run into all kinds of problems
[00:45:58.360 --> 00:46:00.400]   and issues along the way.
[00:46:00.400 --> 00:46:01.960]   And then there's just this role.
[00:46:01.960 --> 00:46:03.600]   Every time you see that pattern,
[00:46:03.600 --> 00:46:05.560]   there's just this role where there's somebody
[00:46:05.560 --> 00:46:06.640]   in the background who's like,
[00:46:06.640 --> 00:46:09.400]   "Okay, this one, not that one.
[00:46:09.400 --> 00:46:11.000]   "This founder, not that founder.
[00:46:11.000 --> 00:46:12.840]   "This expedition, not that expedition.
[00:46:12.840 --> 00:46:14.960]   "This movie, not that movie."
[00:46:14.960 --> 00:46:15.800]   Right?
[00:46:15.800 --> 00:46:19.480]   And those people kind of play a judgment and taste role.
[00:46:19.480 --> 00:46:22.440]   They play an endorsement branding marketing role.
[00:46:22.440 --> 00:46:24.960]   And then they often play a financing role, right?
[00:46:24.960 --> 00:46:26.680]   And then by the way, they often are very hands-on
[00:46:26.680 --> 00:46:29.800]   and they try to contribute to the success of the project.
[00:46:29.800 --> 00:46:32.040]   The historical example of this I always use
[00:46:32.040 --> 00:46:33.480]   is that the current model of venture capital
[00:46:33.480 --> 00:46:35.560]   is actually very similar to how whaling expeditions
[00:46:35.560 --> 00:46:38.160]   got funded 400 years ago, right?
[00:46:38.160 --> 00:46:40.680]   To the point of like the term that we actually have,
[00:46:40.680 --> 00:46:42.120]   which is carried interest or carry,
[00:46:42.120 --> 00:46:43.600]   which is sort of the profit sharing
[00:46:43.600 --> 00:46:46.080]   that the VCs get on a successful startup.
[00:46:46.080 --> 00:46:48.400]   That term actually goes back to the whaling industry
[00:46:48.400 --> 00:46:52.200]   400 years ago, where the financiers of whaling journeys,
[00:46:52.200 --> 00:46:54.360]   like literally like out of like Moby Dick,
[00:46:54.360 --> 00:46:56.240]   they go like hunt a whale and bring it's,
[00:46:56.240 --> 00:46:57.920]   you know, it's basically it's carcass back,
[00:46:57.920 --> 00:46:58.840]   you know, to land.
[00:46:58.840 --> 00:47:02.120]   The carry was literally the percentage
[00:47:02.120 --> 00:47:05.040]   of the carried amount of whale that the investors got.
[00:47:05.040 --> 00:47:06.240]   It was called carry 'cause it was literally
[00:47:06.240 --> 00:47:08.880]   the amount of whale that the ship could carry back.
[00:47:08.880 --> 00:47:11.200]   And so if you go back to how the whaling journeys
[00:47:11.200 --> 00:47:13.640]   off like the coast of Maine in like the 1600s were funded,
[00:47:13.640 --> 00:47:14.920]   there were a group of what we, you know,
[00:47:14.920 --> 00:47:16.720]   they didn't call themselves venture capitals at that time,
[00:47:16.720 --> 00:47:19.960]   but there were a group of basically, you know, capitalists.
[00:47:19.960 --> 00:47:22.400]   And they would sit, you know, in a tavern or something
[00:47:22.400 --> 00:47:24.880]   and they would, you know, get pitches by whaling captains,
[00:47:24.880 --> 00:47:26.000]   you know, about, you know,
[00:47:26.000 --> 00:47:27.440]   and you can imagine the whaling captains, right?
[00:47:27.440 --> 00:47:30.000]   Like, I mean, like whaling, right?
[00:47:30.000 --> 00:47:31.760]   Whaling, like a third of the whaling journeys
[00:47:31.760 --> 00:47:32.960]   never came back, right?
[00:47:32.960 --> 00:47:35.040]   Like a third of the time the boats got destroyed
[00:47:35.040 --> 00:47:36.160]   and everybody drowned, right?
[00:47:36.160 --> 00:47:38.560]   And so it's like, okay, I'm the captain
[00:47:38.560 --> 00:47:40.840]   who's gonna be able to like, not only go get the whale,
[00:47:40.840 --> 00:47:42.600]   but like, I'm gonna be able to keep my crew alive.
[00:47:42.600 --> 00:47:44.400]   And by the way, I have a strategy and a theory
[00:47:44.400 --> 00:47:46.120]   for where the whale is, right?
[00:47:46.120 --> 00:47:47.520]   And maybe one guy's like, look,
[00:47:47.520 --> 00:47:49.280]   I'm gonna go where everybody knows there are whales
[00:47:49.280 --> 00:47:50.120]   and other guy's gonna be like,
[00:47:50.120 --> 00:47:51.320]   no, that place is over fished.
[00:47:51.320 --> 00:47:52.280]   I'm gonna go to some other place
[00:47:52.280 --> 00:47:54.600]   where nobody thinks there's a whale, but I think there is.
[00:47:54.600 --> 00:47:55.960]   And then one guy's gonna say,
[00:47:55.960 --> 00:47:57.720]   I'm better at assembling a crew than the other.
[00:47:57.720 --> 00:47:58.680]   And the other one's like, well, no,
[00:47:58.680 --> 00:47:59.560]   I don't even need the crew.
[00:47:59.560 --> 00:48:01.560]   I just need like a bunch of like, whatever grunts to like,
[00:48:01.560 --> 00:48:03.840]   and I'm gonna do all the work.
[00:48:03.840 --> 00:48:05.120]   And then another guy might say, you know,
[00:48:05.120 --> 00:48:06.160]   I want a small fast boat.
[00:48:06.160 --> 00:48:09.240]   Another guy might say, I want a, you know, a big slow boat.
[00:48:09.240 --> 00:48:11.160]   Right, and so there's a set of people,
[00:48:11.160 --> 00:48:13.440]   like imagine in the tavern at candlelight, like at night,
[00:48:13.440 --> 00:48:14.760]   like debating all this back and forth saying,
[00:48:14.760 --> 00:48:16.200]   okay, this captain on this journey,
[00:48:16.200 --> 00:48:17.760]   not that captain on that journey.
[00:48:17.760 --> 00:48:19.400]   And then putting the money behind it, right?
[00:48:19.400 --> 00:48:20.280]   To finance the thing.
[00:48:20.280 --> 00:48:22.400]   And like, that's what they did then.
[00:48:22.400 --> 00:48:23.880]   That's still what we do, right?
[00:48:23.880 --> 00:48:26.920]   And so what I'm pretty confident about
[00:48:26.920 --> 00:48:29.560]   is there will be somebody like us
[00:48:29.560 --> 00:48:32.000]   who's doing that in 50 years, 100 years, 200 years.
[00:48:32.000 --> 00:48:34.280]   It will be something like that.
[00:48:34.280 --> 00:48:35.480]   Will it be called venture capital?
[00:48:35.480 --> 00:48:36.560]   That I don't know.
[00:48:36.560 --> 00:48:38.440]   You know, will it be, you know, I don't know.
[00:48:38.440 --> 00:48:39.880]   You know, where will it be happening?
[00:48:39.880 --> 00:48:40.720]   I don't know.
[00:48:40.720 --> 00:48:43.000]   But that seems like a very fundamental role.
[00:48:43.000 --> 00:48:43.840]   - Yep, yep.
[00:48:43.840 --> 00:48:45.960]   But will the public private distinction that exists now,
[00:48:45.960 --> 00:48:47.560]   will that exist in 50 years?
[00:48:47.560 --> 00:48:49.840]   - That's really public and private market,
[00:48:49.840 --> 00:48:51.320]   like companies, right?
[00:48:51.320 --> 00:48:53.040]   You mean like companies going public?
[00:48:53.040 --> 00:48:53.880]   - Yeah, yeah, yeah.
[00:48:53.880 --> 00:48:55.240]   And just like the fact like there's different rules
[00:48:55.240 --> 00:48:57.080]   for investing in both and, you know,
[00:48:57.080 --> 00:49:00.120]   just kind of a separate category, is that gonna exist?
[00:49:00.120 --> 00:49:03.000]   - Yeah, so that's already, there's already shades of gray.
[00:49:03.000 --> 00:49:05.400]   So I would say that's already dissolving.
[00:49:05.400 --> 00:49:06.760]   You know, there's very formal, you know,
[00:49:06.760 --> 00:49:08.400]   there's very formal kind of rules here,
[00:49:08.400 --> 00:49:11.480]   but, you know, there's already shading
[00:49:11.480 --> 00:49:12.600]   that's taking place, right?
[00:49:12.600 --> 00:49:14.080]   And so in the last 20 years,
[00:49:14.080 --> 00:49:15.280]   it's become much more common
[00:49:15.280 --> 00:49:16.920]   for especially later stage private companies
[00:49:16.920 --> 00:49:18.960]   to have their stocks actually trade, right?
[00:49:18.960 --> 00:49:21.080]   Actually be, you know, let's say semi-liquid, right?
[00:49:21.080 --> 00:49:22.920]   And trading either through secondary exchanges
[00:49:22.920 --> 00:49:24.920]   or, you know, tender offers or whatever.
[00:49:24.920 --> 00:49:27.040]   And so like that didn't used to happen, right?
[00:49:27.040 --> 00:49:29.040]   That didn't happen really in the 1990s
[00:49:29.040 --> 00:49:31.080]   and then it started happening in the late 2000s.
[00:49:31.080 --> 00:49:31.920]   And then you've got, you know,
[00:49:31.920 --> 00:49:33.560]   lots of people with different kinds of approaches
[00:49:33.560 --> 00:49:34.840]   to have different kinds of private markets
[00:49:34.840 --> 00:49:36.640]   and new kinds of private liquidity.
[00:49:36.640 --> 00:49:38.520]   And then, look, you've got these new mechanisms,
[00:49:38.520 --> 00:49:39.540]   you've got crypto tokens, right?
[00:49:39.540 --> 00:49:41.280]   You've got entirely new mechanisms as well,
[00:49:41.280 --> 00:49:42.480]   you know, kind of popping up,
[00:49:42.480 --> 00:49:45.000]   representing, you know, kind of underlying value.
[00:49:45.000 --> 00:49:47.120]   And then, you know, you have big, you know,
[00:49:47.120 --> 00:49:48.600]   arguments and debates all the time in public
[00:49:48.600 --> 00:49:49.920]   and with regulators and in the newspapers
[00:49:49.920 --> 00:49:52.080]   about what counts as, you know, this, you know,
[00:49:52.080 --> 00:49:54.520]   who can invest and, you know, you know,
[00:49:54.520 --> 00:49:55.960]   this whole accredited investor thing, right?
[00:49:55.960 --> 00:49:57.200]   A lot of this is around, quote unquote,
[00:49:57.200 --> 00:49:58.960]   protecting investors and then there's this concept
[00:49:58.960 --> 00:50:00.440]   of like high net worth investors
[00:50:00.440 --> 00:50:01.720]   should be allowed to take more risk
[00:50:01.720 --> 00:50:03.720]   'cause they can kind of bear, you know, the losses,
[00:50:03.720 --> 00:50:04.800]   whereas kind of normal investors
[00:50:04.800 --> 00:50:06.960]   should not be allowed to invest in private companies.
[00:50:06.960 --> 00:50:08.740]   But then there's a counter argument that says,
[00:50:08.740 --> 00:50:10.520]   then you're cutting off growth,
[00:50:10.520 --> 00:50:12.440]   investing as an opportunity for normal investors
[00:50:12.440 --> 00:50:14.680]   and you're making, you know, wealth inequality worse.
[00:50:14.680 --> 00:50:17.720]   And so, you know, that debate will keep playing out.
[00:50:17.720 --> 00:50:19.320]   You know, it'll kind of fuzz a bit,
[00:50:19.320 --> 00:50:20.880]   like I'd expect probably both sides
[00:50:20.880 --> 00:50:23.600]   will moderate a little bit, you know?
[00:50:23.600 --> 00:50:24.440]   So in other words,
[00:50:24.440 --> 00:50:27.160]   public companies will get to be a little bit more,
[00:50:27.160 --> 00:50:28.640]   you know, they'll probably get a little more liquid
[00:50:28.640 --> 00:50:29.480]   over time.
[00:50:29.480 --> 00:50:31.360]   The definition of what it means to be public
[00:50:31.360 --> 00:50:32.800]   will probably broaden out.
[00:50:32.800 --> 00:50:35.160]   You know, the regulators will probably expect,
[00:50:35.160 --> 00:50:36.040]   well, I'll give you an example.
[00:50:36.040 --> 00:50:37.320]   Here's an interesting thing.
[00:50:37.320 --> 00:50:39.760]   So you can have this interesting case
[00:50:39.760 --> 00:50:41.320]   where you can take a company private,
[00:50:41.320 --> 00:50:42.880]   but yet it's still effectively public
[00:50:42.880 --> 00:50:45.660]   'cause it has publicly traded bonds.
[00:50:45.660 --> 00:50:48.600]   And then it ends up with like publicly filed financials
[00:50:48.600 --> 00:50:50.960]   on the bond side, even though its stock is private, right?
[00:50:50.960 --> 00:50:54.360]   And so it's effectively still public
[00:50:54.360 --> 00:50:55.800]   because of information disclosure.
[00:50:55.800 --> 00:50:56.640]   And then the argument is like,
[00:50:56.640 --> 00:50:58.840]   well, if you already have full information disclosure
[00:50:58.840 --> 00:51:00.280]   as a result of the bonds trading,
[00:51:00.280 --> 00:51:01.800]   you might as well take the stock public again
[00:51:01.800 --> 00:51:03.280]   'cause you're not losing, you know.
[00:51:03.280 --> 00:51:05.800]   So anyway, it'll fuzz out somewhere in there.
[00:51:05.800 --> 00:51:09.560]   - Okay, so there's a clear pipeline of successful founders
[00:51:09.560 --> 00:51:10.920]   who then become venture capitalists,
[00:51:10.920 --> 00:51:12.680]   like yourself, obviously.
[00:51:12.680 --> 00:51:15.600]   But I'm curious why the opposite is not more true, right?
[00:51:15.600 --> 00:51:16.880]   So if you're a venture capitalist,
[00:51:16.880 --> 00:51:18.360]   you've seen dozens of companies
[00:51:18.360 --> 00:51:20.120]   go through hundreds of different problems.
[00:51:20.120 --> 00:51:21.200]   And you would think that this puts you
[00:51:21.200 --> 00:51:25.280]   in a perfect position to kind of be a great entrepreneur.
[00:51:25.280 --> 00:51:28.240]   So why don't more venture capitalists become entrepreneurs?
[00:51:28.240 --> 00:51:29.280]   - Yeah, so I think the answer,
[00:51:29.280 --> 00:51:30.480]   I think one is it's just harder.
[00:51:30.480 --> 00:51:32.960]   Like it's just, it is harder to build a company.
[00:51:32.960 --> 00:51:34.040]   Like it just, it flat out is.
[00:51:34.040 --> 00:51:35.080]   Like it's not easy to be a VC,
[00:51:35.080 --> 00:51:37.020]   but it's harder to build a company.
[00:51:37.020 --> 00:51:39.840]   And it requires a level of personal commitment.
[00:51:39.840 --> 00:51:42.000]   Like people get to a point,
[00:51:42.000 --> 00:51:43.160]   like successful venture capitalists
[00:51:43.160 --> 00:51:44.000]   do get to a point in life
[00:51:44.000 --> 00:51:46.080]   where they start to become pretty comfortable.
[00:51:46.080 --> 00:51:47.280]   You know, they make money and like, you know,
[00:51:47.280 --> 00:51:48.720]   they have like, you know,
[00:51:48.720 --> 00:51:51.040]   they start to kind of settle into a sort of fairly nice way
[00:51:51.040 --> 00:51:52.480]   of living at some point in a lot of cases.
[00:51:52.480 --> 00:51:56.320]   And so going back to the, you know, 2 a.m. chewing glass,
[00:51:56.320 --> 00:51:58.040]   you know, kind of thing, you know,
[00:51:58.040 --> 00:51:59.440]   is maybe a little bit of a stretch
[00:51:59.440 --> 00:52:02.040]   for how they want to spend their time.
[00:52:02.040 --> 00:52:02.880]   So that's part of it.
[00:52:02.880 --> 00:52:03.920]   I think the other part of it is, look,
[00:52:03.920 --> 00:52:05.960]   the activities are pretty different.
[00:52:05.960 --> 00:52:08.960]   You know, the way I describe it is actually starting
[00:52:08.960 --> 00:52:12.280]   and running a company is it's a full-on contact sport.
[00:52:12.280 --> 00:52:14.480]   You know, it's a hundred decisions a day.
[00:52:14.480 --> 00:52:16.880]   It's like, I'll give you an example, bias to action.
[00:52:16.880 --> 00:52:19.080]   Like anybody who's running a company,
[00:52:19.080 --> 00:52:20.880]   like you have to have a bias to action.
[00:52:20.880 --> 00:52:23.160]   Like you're faced with a hundred decisions a day.
[00:52:23.160 --> 00:52:24.920]   You don't have definitive answers on any of them.
[00:52:24.920 --> 00:52:27.120]   And you have to make this, you have to actually act anyway.
[00:52:27.120 --> 00:52:28.760]   'Cause if you sit and analyze, you know,
[00:52:28.760 --> 00:52:30.240]   the world will pass you by, right?
[00:52:30.240 --> 00:52:31.360]   And so it's like, what is it?
[00:52:31.360 --> 00:52:32.920]   A good plan executed violently
[00:52:32.920 --> 00:52:35.200]   is much better than a great plan executed later.
[00:52:35.200 --> 00:52:37.640]   Right, and so it's just, it's a mode of operating
[00:52:37.640 --> 00:52:40.440]   that basically like rewards like aggression,
[00:52:40.440 --> 00:52:43.760]   contact with reality, constantly testing hypotheses,
[00:52:43.760 --> 00:52:46.920]   screwing up a lot, changing your mind a lot,
[00:52:46.920 --> 00:52:49.960]   you know, revisiting things, you know,
[00:52:49.960 --> 00:52:52.480]   just like it's, you know, it's, you know,
[00:52:52.480 --> 00:52:54.760]   thousands and thousands of like crazy real world variables
[00:52:54.760 --> 00:52:55.600]   all intersecting.
[00:52:55.600 --> 00:52:58.240]   Being an investor is different.
[00:52:58.240 --> 00:53:02.920]   It's much more analytical, clinical, outside in,
[00:53:02.920 --> 00:53:06.400]   like the decision cycles are much longer.
[00:53:06.400 --> 00:53:07.800]   You get a much longer period of time
[00:53:07.800 --> 00:53:09.080]   to think about what you should invest in.
[00:53:09.080 --> 00:53:10.640]   You get a much longer period of time to figure out
[00:53:10.640 --> 00:53:12.360]   when you should sell.
[00:53:12.360 --> 00:53:13.880]   You know, like I said, you generally don't wanna
[00:53:13.880 --> 00:53:14.720]   trade frequently.
[00:53:14.720 --> 00:53:16.040]   Like I think if you're doing your job right.
[00:53:16.040 --> 00:53:17.600]   So you actually wanna take a long time
[00:53:17.600 --> 00:53:19.360]   to like really make the investment decisions
[00:53:19.360 --> 00:53:21.520]   and then make the ultimate sale decisions.
[00:53:21.520 --> 00:53:25.840]   You know, VCs, we help along the way, you know,
[00:53:25.840 --> 00:53:27.280]   when companies have, you know,
[00:53:27.280 --> 00:53:28.880]   kind of issues that they're in the middle of,
[00:53:28.880 --> 00:53:30.360]   but like, you know, fundamentally,
[00:53:30.360 --> 00:53:33.000]   there's like a much bigger level of watching, observing,
[00:53:33.000 --> 00:53:37.760]   learning, thinking, arguing in the abstract
[00:53:37.760 --> 00:53:40.640]   as opposed to day-to-day, just like bloody combat.
[00:53:41.760 --> 00:53:43.680]   And so it's a different, I don't know.
[00:53:43.680 --> 00:53:46.640]   It's like, you know, honestly, it's a little bit like,
[00:53:46.640 --> 00:53:50.640]   why don't the great football broadcasters, right?
[00:53:50.640 --> 00:53:53.440]   You know, go get on the field, right?
[00:53:53.440 --> 00:53:55.720]   And try being, you know, running back for a season.
[00:53:55.720 --> 00:53:56.560]   - Yeah.
[00:53:56.560 --> 00:53:58.680]   - It's a little bit like that, to be totally honest.
[00:53:58.680 --> 00:54:00.280]   - Yeah, yeah, yeah, got it.
[00:54:00.280 --> 00:54:02.960]   How soon can you tell whether somebody will make
[00:54:02.960 --> 00:54:05.320]   for a good CEO of a large company specifically?
[00:54:05.320 --> 00:54:07.000]   So can you tell as soon as, you know,
[00:54:07.000 --> 00:54:08.280]   that they've got like a new startup
[00:54:08.280 --> 00:54:09.120]   that they're pitching you?
[00:54:09.120 --> 00:54:10.960]   Or does it become more clear over time
[00:54:10.960 --> 00:54:13.040]   as they get more and more employees?
[00:54:13.040 --> 00:54:14.760]   - Yeah, well, look, sometimes they've done it before, right?
[00:54:14.760 --> 00:54:16.920]   And so, well, okay, so I guess I'd say this.
[00:54:16.920 --> 00:54:19.120]   The big thing with like being able to run things at scale,
[00:54:19.120 --> 00:54:20.280]   there's actually a very big breakthrough
[00:54:20.280 --> 00:54:22.160]   that people either make or they don't make.
[00:54:22.160 --> 00:54:23.480]   And the very big breakthrough
[00:54:23.480 --> 00:54:26.400]   is whether they know how to manage managers, right?
[00:54:26.400 --> 00:54:27.960]   And so, because the reason for that
[00:54:27.960 --> 00:54:30.120]   is like running a big company, you don't have,
[00:54:30.120 --> 00:54:32.160]   say you're running a company with 100,000 employees.
[00:54:32.160 --> 00:54:34.560]   You don't have 100,000 direct reports, right?
[00:54:34.560 --> 00:54:37.120]   You still only have like eight or 10 direct reports.
[00:54:37.120 --> 00:54:39.120]   And then each of them have eight or 10 direct reports.
[00:54:39.120 --> 00:54:40.560]   Then each of them have eight or 10 direct reports.
[00:54:40.560 --> 00:54:42.520]   And so, even the CEOs of really big companies,
[00:54:42.520 --> 00:54:44.200]   they're only really dealing with like eight or 10
[00:54:44.200 --> 00:54:46.040]   or 12 people on a daily basis.
[00:54:46.040 --> 00:54:49.520]   Like, and so the key breakthrough, right?
[00:54:49.520 --> 00:54:51.520]   And then how do you become trained as a manager?
[00:54:51.520 --> 00:54:53.120]   The way you become trained as a manager initially
[00:54:53.120 --> 00:54:55.320]   is you manage a team of individual contributors, right?
[00:54:55.320 --> 00:54:57.080]   So I'm an engineering manager.
[00:54:57.080 --> 00:55:00.040]   I have eight or 10 coders working for me.
[00:55:00.040 --> 00:55:01.360]   And then the breakthrough is,
[00:55:01.360 --> 00:55:04.360]   can I, am I trained on how to become a manager of managers?
[00:55:04.360 --> 00:55:06.800]   Right, and so if I'm early in my career,
[00:55:06.800 --> 00:55:07.640]   the way I think about that
[00:55:07.640 --> 00:55:09.080]   is I start out as an individual contributor,
[00:55:09.080 --> 00:55:10.360]   let's say an engineer.
[00:55:10.360 --> 00:55:11.840]   I get trained on how to be a manager
[00:55:11.840 --> 00:55:13.120]   of individual contributors.
[00:55:13.120 --> 00:55:15.120]   That makes me an engineering manager.
[00:55:15.120 --> 00:55:16.160]   And then if I get promoted to
[00:55:16.160 --> 00:55:17.440]   what they call engineering director,
[00:55:17.440 --> 00:55:18.640]   which is one level up,
[00:55:18.640 --> 00:55:21.920]   now I'm a director and now I'm managing a team of managers.
[00:55:21.920 --> 00:55:23.760]   Anybody who can make that jump
[00:55:23.760 --> 00:55:25.560]   now has a generalizable skill
[00:55:25.560 --> 00:55:26.800]   of being able to manage managers.
[00:55:26.800 --> 00:55:29.200]   And then what makes that skill so great
[00:55:29.200 --> 00:55:30.720]   is that skill can scale, right?
[00:55:30.720 --> 00:55:33.200]   Because then you can get promoted to be VP of engineering.
[00:55:33.200 --> 00:55:34.400]   Now you have a team of directors
[00:55:34.400 --> 00:55:35.400]   who have teams of managers,
[00:55:35.400 --> 00:55:37.000]   who have teams of ICs, right?
[00:55:37.000 --> 00:55:37.840]   And so forth.
[00:55:37.840 --> 00:55:39.560]   And then at some point, if you keep climbing that ladder,
[00:55:39.560 --> 00:55:41.520]   at some point you get promoted to CEO,
[00:55:41.520 --> 00:55:43.040]   and then you have a team of managers
[00:55:43.040 --> 00:55:44.160]   who are the executives of the company,
[00:55:44.160 --> 00:55:45.960]   and then everything stands out from there.
[00:55:45.960 --> 00:55:47.920]   And so if you can manage managers,
[00:55:47.920 --> 00:55:48.920]   like at least in theory,
[00:55:48.920 --> 00:55:50.800]   you have the basic skill and temperament
[00:55:50.800 --> 00:55:53.520]   required to be able to scale all the way up.
[00:55:53.520 --> 00:55:55.040]   You know, then it becomes a question of like,
[00:55:55.040 --> 00:55:56.720]   how much complexity can you deal with?
[00:55:56.720 --> 00:55:59.320]   Like, can you learn enough about all the different domains
[00:55:59.320 --> 00:56:01.080]   of what it means to run a business?
[00:56:01.080 --> 00:56:03.080]   You know, are you gonna enjoy being in the job
[00:56:03.080 --> 00:56:04.080]   and being on the hot seat?
[00:56:04.080 --> 00:56:06.560]   Like, you know, all kinds of those questions.
[00:56:07.720 --> 00:56:09.280]   I think most of the people we back,
[00:56:09.280 --> 00:56:10.120]   let's put it this way.
[00:56:10.120 --> 00:56:11.160]   I think 100% of the people we back
[00:56:11.160 --> 00:56:13.360]   have the intelligence to do it.
[00:56:13.360 --> 00:56:16.640]   I think maybe half of them have the temperament to do it.
[00:56:16.640 --> 00:56:19.280]   And then maybe half of those have the intelligence
[00:56:19.280 --> 00:56:21.680]   and the temperament, and they really want to do it.
[00:56:21.680 --> 00:56:23.960]   And by that, by wanna do it, I mean 20 years from now,
[00:56:23.960 --> 00:56:25.400]   they still wanna be running their company.
[00:56:25.400 --> 00:56:26.360]   - Right.
[00:56:26.360 --> 00:56:28.400]   - And so, you know, enough of them
[00:56:28.400 --> 00:56:29.560]   where we get the success cases,
[00:56:29.560 --> 00:56:32.320]   but having said that, like, look, as an entrepreneur,
[00:56:32.320 --> 00:56:33.200]   you have to really want that.
[00:56:33.200 --> 00:56:34.600]   Like, you have to be smart enough,
[00:56:34.600 --> 00:56:35.560]   and you have to have the temperament,
[00:56:35.560 --> 00:56:37.600]   and you have to actually want to learn the skills.
[00:56:37.600 --> 00:56:40.320]   And not everybody is able to line those up.
[00:56:40.320 --> 00:56:41.160]   - Got it, got it.
[00:56:41.160 --> 00:56:43.080]   Managing the managerial revolution.
[00:56:43.080 --> 00:56:44.640]   - Yes, exactly.
[00:56:44.640 --> 00:56:45.840]   Well, that's the thing, right?
[00:56:45.840 --> 00:56:47.160]   Well, actually, that's exactly right.
[00:56:47.160 --> 00:56:49.480]   So, right, the best case scenario
[00:56:49.480 --> 00:56:52.840]   is a bourgeois capitalist entrepreneurial CEO
[00:56:52.840 --> 00:56:54.600]   managing a team of managers
[00:56:54.600 --> 00:56:56.840]   who are doing all the managerial stuff required at scale.
[00:56:56.840 --> 00:56:58.960]   Right, like, that's the best case scenario
[00:56:58.960 --> 00:57:00.680]   for a large modern organization, right?
[00:57:00.680 --> 00:57:02.880]   Which is they're able to, best of both worlds.
[00:57:02.880 --> 00:57:04.480]   They're able to harness the benefits of scale,
[00:57:04.480 --> 00:57:07.000]   and they're able to still build new things.
[00:57:07.000 --> 00:57:09.120]   You know, the degenerate version of that, right,
[00:57:09.120 --> 00:57:12.280]   is a manager running a company, right,
[00:57:12.280 --> 00:57:16.080]   of basically, you know, in theory,
[00:57:16.080 --> 00:57:17.160]   people who can build new products.
[00:57:17.160 --> 00:57:19.800]   But if the manager, in the Burnham sense,
[00:57:19.800 --> 00:57:21.760]   if the CEO is manager in the Burnham sense
[00:57:21.760 --> 00:57:24.000]   is running a team of people who want to build new products,
[00:57:24.000 --> 00:57:26.000]   that company probably will not actually build new products.
[00:57:26.000 --> 00:57:27.200]   Those people will probably all leave
[00:57:27.200 --> 00:57:28.320]   and start their own companies.
[00:57:28.320 --> 00:57:30.520]   - Mm-hmm, yeah, yeah.
[00:57:30.520 --> 00:57:32.600]   Now, as unlikely as this may be,
[00:57:32.600 --> 00:57:34.320]   just humor the hypothetical,
[00:57:34.320 --> 00:57:38.120]   let's say A16Z for the next 10 to 20 years
[00:57:38.120 --> 00:57:39.600]   has mediocre returns.
[00:57:39.600 --> 00:57:40.880]   If you had to guess, looking back,
[00:57:40.880 --> 00:57:42.840]   what would be the most likely reason this might happen?
[00:57:42.840 --> 00:57:44.400]   Would it have to be some sort of macro headwind?
[00:57:44.400 --> 00:57:46.880]   Would it have to be betting on the wrong tech sectors?
[00:57:46.880 --> 00:57:48.680]   What would it have to be?
[00:57:48.680 --> 00:57:50.920]   - So 20 years is a long enough time
[00:57:50.920 --> 00:57:54.160]   where it's probably not just a macroeconomic thing, right,
[00:57:54.160 --> 00:57:56.120]   in that, you know, the cycles play out,
[00:57:56.120 --> 00:57:57.920]   you know, the big macro cycles seem to play out
[00:57:57.920 --> 00:57:59.320]   over like seven to 10 year periods.
[00:57:59.320 --> 00:58:01.120]   And so over 20 years, you'd expect to kind of get
[00:58:01.120 --> 00:58:02.920]   two or three big cycles through that.
[00:58:02.920 --> 00:58:04.640]   And so you'd expect to get, you know,
[00:58:04.640 --> 00:58:05.680]   at least some chance to, you know,
[00:58:05.680 --> 00:58:08.560]   make money and harvest profits.
[00:58:08.560 --> 00:58:10.880]   So probably it wouldn't be a macro problem.
[00:58:10.880 --> 00:58:12.280]   I mean, you can look, you can imagine it.
[00:58:12.280 --> 00:58:13.480]   Like if we have like, you know,
[00:58:13.480 --> 00:58:14.920]   if the Black Plague return, you know,
[00:58:14.920 --> 00:58:17.760]   it's like a real pandemic happens, right?
[00:58:17.760 --> 00:58:19.600]   By the way, I'm now gonna get you demonetized on Google
[00:58:19.600 --> 00:58:21.440]   'cause I'm gonna reference pandemics, but.
[00:58:21.440 --> 00:58:23.000]   - Don't worry, I didn't have enough views
[00:58:23.000 --> 00:58:24.320]   to be monetized anyway, so.
[00:58:24.320 --> 00:58:27.800]   - If there's a, you know, I don't know.
[00:58:27.800 --> 00:58:29.600]   If there's, you know, if something horrible happens,
[00:58:29.600 --> 00:58:31.840]   then you could be in a ditch for 20 years, you know.
[00:58:31.840 --> 00:58:34.960]   But if things continue kind of the way that they have
[00:58:34.960 --> 00:58:36.880]   for the last, you know, 50 years or 80 years,
[00:58:36.880 --> 00:58:38.360]   like there'll be multiple cycles
[00:58:38.360 --> 00:58:39.560]   and there'll be a chance to make money
[00:58:39.560 --> 00:58:42.200]   for people who make good investments.
[00:58:42.200 --> 00:58:43.960]   So it's probably not that.
[00:58:43.960 --> 00:58:46.160]   And then there's like the micro,
[00:58:46.160 --> 00:58:47.360]   there'll be the micro explanation,
[00:58:47.360 --> 00:58:48.800]   which is we just make bad investments.
[00:58:48.800 --> 00:58:50.120]   Like we invest the money,
[00:58:50.120 --> 00:58:53.320]   but we just invest in the wrong companies and we screw up.
[00:58:53.320 --> 00:58:55.240]   And that's, of course, always a possibility
[00:58:55.240 --> 00:58:56.480]   and probably the, you know, the most,
[00:58:56.480 --> 00:58:59.240]   always the kind of most likely downside case.
[00:58:59.240 --> 00:59:01.440]   The other downside case is I would,
[00:59:01.440 --> 00:59:03.280]   it would build basically on what I was mentioning earlier
[00:59:03.280 --> 00:59:04.120]   from Bill Janeway.
[00:59:04.120 --> 00:59:07.280]   The other downside case would just be like, you know,
[00:59:07.280 --> 00:59:10.440]   there's just not enough technological change happening.
[00:59:10.440 --> 00:59:13.840]   Right, there's just, like there wasn't enough, you know,
[00:59:13.840 --> 00:59:16.120]   investment in basic research in the preceding 50 years
[00:59:16.120 --> 00:59:18.400]   in areas that actually paid off.
[00:59:18.400 --> 00:59:19.680]   There wasn't enough sort of
[00:59:19.680 --> 00:59:21.240]   therefore underlying technological change
[00:59:21.240 --> 00:59:23.760]   to provide an opportunity for new entrepreneurial,
[00:59:23.760 --> 00:59:25.480]   you know, innovation.
[00:59:25.480 --> 00:59:27.000]   And, you know, the entrepreneurs, you know,
[00:59:27.000 --> 00:59:28.800]   started the companies and they tried to build products
[00:59:28.800 --> 00:59:29.640]   and we funded them.
[00:59:29.640 --> 00:59:31.000]   And like, it just, for whatever reason,
[00:59:31.000 --> 00:59:33.000]   like the sectors in which everybody was operating
[00:59:33.000 --> 00:59:35.040]   just like didn't pay off.
[00:59:35.040 --> 00:59:36.320]   You know, I'd say if we hit like, I don't know,
[00:59:36.320 --> 00:59:38.320]   five clean tech sectors in a row or something like that,
[00:59:38.320 --> 00:59:40.680]   you know, then the whole thing just doesn't work.
[00:59:40.680 --> 00:59:43.800]   Yeah, I think that would be, that's the biggest,
[00:59:43.800 --> 00:59:45.560]   that in a sense, that's the scariest one.
[00:59:45.560 --> 00:59:47.520]   'Cause that's the one that's most out of our control.
[00:59:47.520 --> 00:59:49.760]   You know, that's like purely, you know, exogenous, right?
[00:59:49.760 --> 00:59:51.160]   Like if we, you know,
[00:59:51.160 --> 00:59:53.240]   we can't wish new science into existence.
[00:59:53.240 --> 00:59:55.920]   And so that would be the scary one.
[00:59:55.920 --> 00:59:57.480]   I don't think that's the case.
[00:59:57.480 --> 00:59:58.800]   And in fact, I think quite possibly
[00:59:58.800 --> 00:59:59.640]   the opposite is happening,
[00:59:59.640 --> 01:00:01.800]   but that would be the downside scenario.
[01:00:01.800 --> 01:00:06.240]   How vulnerable is A16Z to any given single tech sector
[01:00:06.240 --> 01:00:07.080]   not working out?
[01:00:07.080 --> 01:00:09.600]   Whether it's because of technical immaturity
[01:00:09.600 --> 01:00:11.320]   or whether regulation or anything else.
[01:00:11.320 --> 01:00:14.200]   But like if one, if like your top sector doesn't work out,
[01:00:14.200 --> 01:00:15.480]   how vulnerable is the whole firm?
[01:00:15.480 --> 01:00:17.840]   It's innovation could just be outlawed, right?
[01:00:17.840 --> 01:00:20.480]   And that's a real risk because innovation is outlawed
[01:00:20.480 --> 01:00:22.000]   in big and important areas, right?
[01:00:22.000 --> 01:00:24.760]   Like, so, you know, nuclear there's, you know,
[01:00:24.760 --> 01:00:26.760]   I always love meeting with new nuclear entrepreneurs
[01:00:26.760 --> 01:00:28.200]   because it's just like so obvious that they're,
[01:00:28.200 --> 01:00:29.520]   you know, we should have this big, you know,
[01:00:29.520 --> 01:00:30.560]   investment in nuclear energy.
[01:00:30.560 --> 01:00:32.040]   And there's all these new designs,
[01:00:32.040 --> 01:00:33.360]   but the Nuclear Regulatory Commission
[01:00:33.360 --> 01:00:35.000]   has not authorized a new nuclear design
[01:00:35.000 --> 01:00:37.400]   since its inception nearly 50 years ago.
[01:00:37.400 --> 01:00:39.120]   And so it's just illegal to build new nuclear,
[01:00:39.120 --> 01:00:41.080]   right, in the US.
[01:00:41.080 --> 01:00:42.640]   By the way, there's all these fusion entrepreneurs
[01:00:42.640 --> 01:00:43.960]   that again, they're like super geniuses.
[01:00:43.960 --> 01:00:44.800]   The products are great.
[01:00:44.800 --> 01:00:45.920]   It looks fantastic.
[01:00:45.920 --> 01:00:47.800]   I don't think there's any prospect of nuclear fusion
[01:00:47.800 --> 01:00:49.640]   being legal in the US, right?
[01:00:49.640 --> 01:00:51.280]   I just don't think, I think it's just impossible.
[01:00:51.280 --> 01:00:52.560]   It can't be done.
[01:00:52.560 --> 01:00:55.840]   And so, you know, maybe it's just all outlawed.
[01:00:56.760 --> 01:00:57.600]   You know, in which case, look,
[01:00:57.600 --> 01:00:59.400]   at a societal level, we'll deserve the result,
[01:00:59.400 --> 01:01:01.680]   but that would be a bummer for us.
[01:01:01.680 --> 01:01:03.640]   - And then like, so, yeah, well, I don't know.
[01:01:03.640 --> 01:01:04.840]   Let's say crypto gets regulated
[01:01:04.840 --> 01:01:06.440]   or it's like just not ready yet or something.
[01:01:06.440 --> 01:01:07.480]   Like what happens to,
[01:01:07.480 --> 01:01:08.520]   it doesn't have to be crypto in specific,
[01:01:08.520 --> 01:01:10.480]   but like what happens to A16Z as a whole?
[01:01:10.480 --> 01:01:13.760]   I mean, does the whole firm carry on or?
[01:01:13.760 --> 01:01:15.880]   - Yeah, you know, I mean, look, it's up to our LPs, right?
[01:01:15.880 --> 01:01:17.920]   So it's, you know, we raise money on a cycle.
[01:01:17.920 --> 01:01:20.040]   So it's, you know, our LPs have an option every cycle
[01:01:20.040 --> 01:01:22.120]   to not continue to invest.
[01:01:22.120 --> 01:01:24.760]   You know, I just logically, I think, you know,
[01:01:24.760 --> 01:01:26.680]   the firm is somewhat diversified now.
[01:01:26.680 --> 01:01:30.080]   Like as I said, we have like six primary investment domains.
[01:01:30.080 --> 01:01:31.320]   Now, and so at least in theory,
[01:01:31.320 --> 01:01:34.360]   we have some diversification across categories.
[01:01:34.360 --> 01:01:36.360]   You know, and so at least in theory,
[01:01:36.360 --> 01:01:37.800]   we could like lose a category or two.
[01:01:37.800 --> 01:01:38.840]   And like the firm, you know,
[01:01:38.840 --> 01:01:40.240]   the investment returns could still be good
[01:01:40.240 --> 01:01:43.000]   and the investors would still fund us.
[01:01:43.000 --> 01:01:44.640]   You know, the downside case from there would be
[01:01:44.640 --> 01:01:47.280]   that those categories are actually more correlated,
[01:01:47.280 --> 01:01:50.680]   you know, than we would want them to be.
[01:01:50.680 --> 01:01:52.360]   You know, as a firm, we have a big focus on software.
[01:01:52.360 --> 01:01:54.040]   Like we think software is a wedge across, you know,
[01:01:54.040 --> 01:01:55.880]   each of those verticals.
[01:01:55.880 --> 01:01:57.000]   You know, maybe software, you know, look,
[01:01:57.000 --> 01:01:59.520]   maybe AI turns out whatever reason not to work
[01:01:59.520 --> 01:02:02.080]   or gets outlawed or something, you know, happens.
[01:02:02.080 --> 01:02:03.920]   Or just like fundamentally makes economics worse
[01:02:03.920 --> 01:02:05.680]   or something, you know,
[01:02:05.680 --> 01:02:07.640]   then you can imagine that hitting multiple sectors.
[01:02:07.640 --> 01:02:09.720]   Again, I don't think that's going to happen,
[01:02:09.720 --> 01:02:11.360]   but I guess it's a possibility.
[01:02:11.360 --> 01:02:12.400]   - Yeah, yeah, yeah.
[01:02:12.400 --> 01:02:14.480]   What did the old management of Twitter fail to see
[01:02:14.480 --> 01:02:16.040]   about the potential of the platform?
[01:02:16.040 --> 01:02:17.520]   - You know, so first, I guess I'd say it's,
[01:02:17.520 --> 01:02:20.480]   I have a very hard time second guessing management teams.
[01:02:20.480 --> 01:02:23.000]   'Cause like I said, my belief is that,
[01:02:23.000 --> 01:02:25.520]   like it's so easy to criticize companies
[01:02:25.520 --> 01:02:26.560]   and teams from the outside.
[01:02:26.560 --> 01:02:28.080]   It's so hard to run these companies.
[01:02:28.080 --> 01:02:29.920]   There are always a thousand factors
[01:02:29.920 --> 01:02:32.640]   that are invisible from the outside
[01:02:32.640 --> 01:02:35.320]   that make it really hard to make decisions internally.
[01:02:35.320 --> 01:02:37.000]   But by the way, the histories and all this stuff
[01:02:37.000 --> 01:02:39.320]   are really always screwed up because, you know,
[01:02:39.320 --> 01:02:40.960]   what you almost always find, right,
[01:02:40.960 --> 01:02:42.520]   is that in the histories of the great companies,
[01:02:42.520 --> 01:02:44.440]   you almost always find that there were moments early on
[01:02:44.440 --> 01:02:45.360]   where it was really tenuous
[01:02:45.360 --> 01:02:46.680]   and it could have easily gone the other way.
[01:02:46.680 --> 01:02:47.520]   And like, you know,
[01:02:47.520 --> 01:02:49.600]   Netflix could have sold out to Blockbuster early on
[01:02:49.600 --> 01:02:50.920]   and Google could have sold out to Yahoo.
[01:02:50.920 --> 01:02:52.040]   And we, you know, never would have even heard
[01:02:52.040 --> 01:02:53.880]   of those companies, right?
[01:02:53.880 --> 01:02:58.120]   And so, you know, it's really, really hard to second guess.
[01:02:58.120 --> 01:02:59.680]   I guess I just put it this way.
[01:02:59.680 --> 01:03:01.960]   I've just, I've always, I've always believed,
[01:03:01.960 --> 01:03:03.320]   and I was an angel investor on Twitter
[01:03:03.320 --> 01:03:05.120]   back when it first got started.
[01:03:05.120 --> 01:03:07.640]   I just, I've always believed the public graph
[01:03:07.640 --> 01:03:09.920]   is something that should just be like,
[01:03:09.920 --> 01:03:12.160]   just titanically valuable in the world, right?
[01:03:12.160 --> 01:03:15.160]   Like the public follow graph, you know,
[01:03:15.160 --> 01:03:16.480]   so in the computer science terms,
[01:03:16.480 --> 01:03:19.440]   Twitter is what's called publish, subscribe.
[01:03:19.440 --> 01:03:22.240]   So the idea of a one-way public follow graph,
[01:03:22.240 --> 01:03:23.680]   like that ought to be just like
[01:03:23.680 --> 01:03:24.960]   absolutely titanically valuable.
[01:03:24.960 --> 01:03:26.320]   Like that ought to be like the most valuable,
[01:03:26.320 --> 01:03:28.840]   like intent, you know, loyalty brand signal in the world.
[01:03:28.840 --> 01:03:29.840]   That ought to be like, you know,
[01:03:29.840 --> 01:03:31.000]   the most complete expression
[01:03:31.000 --> 01:03:32.320]   of what people care about in the world.
[01:03:32.320 --> 01:03:33.360]   That ought to be the primary way
[01:03:33.360 --> 01:03:35.200]   that every creator of everything, you know,
[01:03:35.200 --> 01:03:38.000]   interacts with their customers and their audience.
[01:03:38.000 --> 01:03:39.920]   You know, this ought to be where all the politics,
[01:03:39.920 --> 01:03:40.760]   you know, operates.
[01:03:40.760 --> 01:03:42.120]   This ought to be where all of, you know,
[01:03:42.120 --> 01:03:43.960]   basically every creative profession operates.
[01:03:43.960 --> 01:03:44.960]   This ought to be where, you know,
[01:03:44.960 --> 01:03:47.240]   a huge amount of the economy operates.
[01:03:47.240 --> 01:03:48.760]   That's just such a, like,
[01:03:48.760 --> 01:03:50.720]   they were always onto such a big idea.
[01:03:50.720 --> 01:03:52.800]   And then, yeah, and then, you know,
[01:03:52.800 --> 01:03:54.840]   like with everything, it's not a question of like, okay,
[01:03:54.840 --> 01:03:56.400]   like what does that mean in terms of like
[01:03:56.400 --> 01:03:57.880]   what kind of product you can build around that?
[01:03:57.880 --> 01:03:59.440]   And then, you know, how big ultimately, you know,
[01:03:59.440 --> 01:04:01.280]   can you get people to pay for it?
[01:04:01.280 --> 01:04:03.280]   But yeah, I've always viewed that like
[01:04:03.280 --> 01:04:05.400]   the economic opportunity around that core innovation
[01:04:05.400 --> 01:04:06.920]   that they had is just much, much larger
[01:04:06.920 --> 01:04:08.320]   than anybody has seen so far.
[01:04:08.320 --> 01:04:10.520]   - But how specifically do you monetize that graph?
[01:04:10.520 --> 01:04:11.840]   - Oh, I mean, there's a gazillion ways.
[01:04:11.840 --> 01:04:14.120]   I mean, there's tons and tons of ways.
[01:04:14.120 --> 01:04:16.160]   I would just, Elon has talked about this publicly,
[01:04:16.160 --> 01:04:19.200]   so it's not spoiling anything, but like, look, like,
[01:04:19.200 --> 01:04:21.200]   Twitter is a promotional vehicle, right,
[01:04:21.200 --> 01:04:22.760]   for a lot of people who then, like,
[01:04:22.760 --> 01:04:25.680]   will provide you stuff on other, you know,
[01:04:25.680 --> 01:04:26.960]   I'm just taking an obvious example.
[01:04:26.960 --> 01:04:29.520]   He's talked about his video, right?
[01:04:29.520 --> 01:04:31.800]   People create video, they market it on Twitter,
[01:04:31.800 --> 01:04:33.880]   and then they monetize it on YouTube, right?
[01:04:33.880 --> 01:04:35.920]   Like, what, why, right?
[01:04:35.920 --> 01:04:38.240]   Like, why, like, why is that not happening?
[01:04:38.240 --> 01:04:40.040]   You know, musicians, you know, will have followings of,
[01:04:40.040 --> 01:04:41.480]   you know, five, 10 million people on Twitter.
[01:04:41.480 --> 01:04:42.600]   They aren't selling concert tickets.
[01:04:42.600 --> 01:04:44.240]   You know, they ought to sell out concerts.
[01:04:44.240 --> 01:04:46.480]   I actually first noticed this with,
[01:04:46.480 --> 01:04:48.080]   I'm sure this was happening before,
[01:04:48.080 --> 01:04:49.600]   but where it first came to mind was,
[01:04:49.600 --> 01:04:50.760]   I don't know if you remember,
[01:04:50.760 --> 01:04:53.040]   Conan O'Brien, when he got famously fired
[01:04:53.040 --> 01:04:55.720]   from "The Tonight Show," he did this tour,
[01:04:55.720 --> 01:04:58.520]   and I was a fan of his, so I was following him at the time,
[01:04:58.520 --> 01:05:01.640]   and so he did a live, he did his first live tour,
[01:05:01.640 --> 01:05:03.760]   his live kind of comedy music tour,
[01:05:03.760 --> 01:05:05.600]   and he sold out the tour across,
[01:05:05.600 --> 01:05:06.640]   I don't know, whatever, 40 cities.
[01:05:06.640 --> 01:05:08.880]   He sold out the tour in, like, two hours.
[01:05:08.880 --> 01:05:09.720]   How did he do it?
[01:05:09.720 --> 01:05:11.160]   Well, he just, like, put up on his Twitter account.
[01:05:11.160 --> 01:05:12.960]   He said, you know, "I'm going on the road.
[01:05:12.960 --> 01:05:15.280]   "Here are the dates, like, click here to buy tickets."
[01:05:15.280 --> 01:05:16.120]   Boom, they all sold out.
[01:05:16.120 --> 01:05:17.400]   Now, "click here to buy tickets"
[01:05:17.400 --> 01:05:19.920]   was not "click here to buy tickets" on Twitter, right?
[01:05:19.920 --> 01:05:21.720]   It was "click here to buy tickets" somewhere else,
[01:05:21.720 --> 01:05:24.160]   but, like, why isn't every concert in the world,
[01:05:24.160 --> 01:05:26.760]   why isn't every live event getting booked on Twitter?
[01:05:26.760 --> 01:05:29.200]   It's just, you know, it just, like,
[01:05:29.200 --> 01:05:31.560]   there's a lot of this kind of thing that just,
[01:05:31.560 --> 01:05:34.280]   as Elon's fond of saying, it's not rocket science.
[01:05:34.280 --> 01:05:35.120]   - Yeah, yeah.
[01:05:35.120 --> 01:05:37.000]   It's funny that a few revolutions in the Middle East
[01:05:37.000 --> 01:05:38.400]   were organized in the same way
[01:05:38.400 --> 01:05:40.000]   that Conan O'Brien organized his tour,
[01:05:40.000 --> 01:05:41.760]   just by posting it on Twitter.
[01:05:41.760 --> 01:05:44.640]   - So this is the thing that got me so convinced
[01:05:44.640 --> 01:05:46.360]   on social media, I think, relatively early.
[01:05:46.360 --> 01:05:48.680]   So even before the Arab Spring.
[01:05:48.680 --> 01:05:50.880]   So I don't know if you remember, you might be too young,
[01:05:50.880 --> 01:05:51.720]   but I don't know if you remember
[01:05:51.720 --> 01:05:54.640]   that there was this overwhelming critique of social media
[01:05:54.640 --> 01:05:57.240]   between, like, inception in, like, 2001
[01:05:57.240 --> 01:05:59.640]   to basically mainstreaming in, like, 2011, 2012.
[01:05:59.640 --> 01:06:00.600]   There was, like, a decade
[01:06:00.600 --> 01:06:02.680]   where there was just this overwhelming critique
[01:06:02.680 --> 01:06:05.560]   from all the smart people, as I like to say,
[01:06:05.560 --> 01:06:07.360]   that was basically, this thing is useless.
[01:06:07.360 --> 01:06:08.520]   Like, this thing is useless.
[01:06:08.520 --> 01:06:10.360]   This is narcissism, right?
[01:06:10.360 --> 01:06:13.120]   This is just, like, pointless, you know, self-ego stroking,
[01:06:13.120 --> 01:06:15.040]   like, narcissism, nobody cares.
[01:06:15.040 --> 01:06:16.960]   You know, the cliche always was Twitter is where you go
[01:06:16.960 --> 01:06:19.200]   to learn what somebody's cat had for breakfast,
[01:06:19.200 --> 01:06:20.960]   who cares what your cat had for breakfast.
[01:06:20.960 --> 01:06:23.800]   Like, nothing will ever come from any of this, right?
[01:06:23.800 --> 01:06:25.480]   And then I remember, like, reading,
[01:06:25.480 --> 01:06:27.000]   and you could pick up any newspaper
[01:06:27.000 --> 01:06:28.760]   at any given day, kind of, through that period,
[01:06:28.760 --> 01:06:29.880]   and you could read something like this.
[01:06:29.880 --> 01:06:31.720]   And then I remember Erdogan,
[01:06:31.720 --> 01:06:34.960]   when Erdogan was consolidating control of Turkey,
[01:06:34.960 --> 01:06:36.760]   Erdogan came out, and he said,
[01:06:36.760 --> 01:06:39.560]   "I think Twitter is the primary challenge
[01:06:39.560 --> 01:06:42.160]   "to the survival of any political regime
[01:06:42.160 --> 01:06:43.440]   "in the modern world."
[01:06:43.440 --> 01:06:46.560]   And I was like, "Okay, all the smart analysts
[01:06:46.560 --> 01:06:47.840]   "all think this is worthless."
[01:06:47.840 --> 01:06:50.400]   And then a guy who's actually trying to, like,
[01:06:50.400 --> 01:06:51.760]   keep control of a country is like,
[01:06:51.760 --> 01:06:53.320]   "This is my number one threat."
[01:06:53.320 --> 01:06:58.800]   I mean, like, just the spread, right, of what that meant,
[01:06:58.800 --> 01:07:00.120]   right, of what the outcomes were,
[01:07:00.120 --> 01:07:01.400]   I was just like, "Oh, my God."
[01:07:01.400 --> 01:07:03.640]   Like, and of course, you know, my conclusion was,
[01:07:03.640 --> 01:07:05.200]   Erdogan is right, you know,
[01:07:05.200 --> 01:07:07.280]   and all the smart Westerners are wrong.
[01:07:07.280 --> 01:07:08.960]   And, you know, and by the way, you know,
[01:07:08.960 --> 01:07:10.240]   quite honestly, that's played out.
[01:07:10.240 --> 01:07:12.000]   By the way, quite honestly, I think it's still early on.
[01:07:12.000 --> 01:07:13.920]   Like, I think we're still pretty early
[01:07:13.920 --> 01:07:15.640]   in the long arc of social media.
[01:07:15.640 --> 01:07:20.040]   Like, we're new, I mean, the high-level thing here
[01:07:20.040 --> 01:07:23.280]   would be just like, we're new, you know,
[01:07:23.280 --> 01:07:25.960]   the world in which 5 billion people are on the internet,
[01:07:25.960 --> 01:07:28.960]   right, is still only a decade or so old, right?
[01:07:28.960 --> 01:07:31.200]   So that's still really early, right?
[01:07:31.200 --> 01:07:33.320]   And then the world in which, like, 5 billion people
[01:07:33.320 --> 01:07:36.440]   are on social networks is, like, five years old, right?
[01:07:36.440 --> 01:07:39.200]   It's still, like, super early, right?
[01:07:39.200 --> 01:07:40.360]   And if you just look at the history
[01:07:40.360 --> 01:07:41.440]   of these transitions in the past,
[01:07:41.440 --> 01:07:42.880]   like, if you just look at, like, the printing press
[01:07:42.880 --> 01:07:45.920]   as sort of an, as a precedent example,
[01:07:45.920 --> 01:07:48.200]   like, it took 200 years, right,
[01:07:48.200 --> 01:07:50.600]   to fully play out the consequences of the printing press.
[01:07:50.600 --> 01:07:52.760]   Like, we're still in the very early stages
[01:07:52.760 --> 01:07:53.720]   with these things.
[01:07:53.720 --> 01:07:54.560]   - Yep, yep, yep.
[01:07:54.560 --> 01:07:56.120]   I was, like, 10 in 2011,
[01:07:56.120 --> 01:07:57.320]   so I don't know if I would have personally,
[01:07:57.320 --> 01:07:59.240]   I would like to think that I would have caught on
[01:07:59.240 --> 01:08:00.920]   if I was older, but maybe not.
[01:08:00.920 --> 01:08:01.840]   It's hard to know.
[01:08:01.840 --> 01:08:04.440]   But, you know, it is kind of interesting.
[01:08:04.440 --> 01:08:05.880]   You are basically personally invested
[01:08:05.880 --> 01:08:08.600]   in, I think, every single major social media company,
[01:08:08.600 --> 01:08:09.960]   but it's interesting to get your thoughts
[01:08:09.960 --> 01:08:11.800]   on where that sector might go.
[01:08:11.800 --> 01:08:13.640]   Do you think the next 10 years
[01:08:13.640 --> 01:08:16.200]   will look like the last 10 years when it comes to big tech?
[01:08:16.200 --> 01:08:19.440]   Does it just keep becoming a bigger fraction of GDP?
[01:08:19.440 --> 01:08:21.320]   Like, will that ever stop?
[01:08:21.320 --> 01:08:24.160]   - Yeah, so as a fraction of GDP, it's only gonna go up.
[01:08:24.160 --> 01:08:25.920]   And, yeah, and it's just, it's literally,
[01:08:25.920 --> 01:08:26.760]   it is the process.
[01:08:26.760 --> 01:08:29.080]   It is the process of sort of tech,
[01:08:29.080 --> 01:08:31.800]   tech infusing itself into every sector.
[01:08:31.800 --> 01:08:34.000]   And I think that's just, like, an overwhelming trend
[01:08:34.000 --> 01:08:36.440]   because it just, there are better ways to do things.
[01:08:36.440 --> 01:08:37.960]   There are things that are possible today
[01:08:37.960 --> 01:08:39.600]   that were not possible 10 years ago.
[01:08:39.600 --> 01:08:41.440]   There are things that will be possible five years from now
[01:08:41.440 --> 01:08:43.280]   that are possible today.
[01:08:43.280 --> 01:08:45.600]   And so, from a sector standpoint,
[01:08:45.600 --> 01:08:49.120]   the sector will certainly rise as a percent.
[01:08:49.120 --> 01:08:52.760]   You know, look, I'm putting my money where my mouth is
[01:08:52.760 --> 01:08:53.600]   in the following statement.
[01:08:53.600 --> 01:08:55.400]   Like, entrepreneurial capitalism
[01:08:55.400 --> 01:08:57.280]   will deliver most of that, right?
[01:08:57.280 --> 01:08:58.960]   A lot of that gain will be companies
[01:08:58.960 --> 01:09:01.360]   that were funded in the kind of venture capital,
[01:09:01.360 --> 01:09:03.120]   you know, kind of Silicon Valley kind of model.
[01:09:03.120 --> 01:09:04.560]   For the basic reason we discussed,
[01:09:04.560 --> 01:09:06.840]   which is, you know, that you do need to have
[01:09:06.840 --> 01:09:09.960]   that kind of throwback kind of bourgeois capitalist models
[01:09:09.960 --> 01:09:10.880]   to do new things.
[01:09:10.880 --> 01:09:14.080]   You know, incumbents generally are still very poor
[01:09:14.080 --> 01:09:16.480]   at changing themselves in response to new technology
[01:09:16.480 --> 01:09:18.720]   for the reasons we've discussed.
[01:09:18.720 --> 01:09:21.680]   So I think that process will continue to play out.
[01:09:21.680 --> 01:09:23.600]   Another thing I would just highlight is
[01:09:23.600 --> 01:09:26.320]   the opportunity set for tech is, I think,
[01:09:26.320 --> 01:09:29.320]   changing over time in another interesting way,
[01:09:29.320 --> 01:09:32.440]   which is, I think, we've been good at going after
[01:09:32.440 --> 01:09:35.640]   the very dynamic but small slices of GDP
[01:09:35.640 --> 01:09:36.560]   in the last 50 years.
[01:09:36.560 --> 01:09:38.520]   And I think more and more now we're gonna be going after
[01:09:38.520 --> 01:09:41.880]   the less dynamic but much larger sectors of GDP.
[01:09:41.880 --> 01:09:44.280]   So I think, you know, education, healthcare,
[01:09:44.280 --> 01:09:48.160]   you know, real estate, finance, you know, law, government,
[01:09:48.160 --> 01:09:50.800]   right, are really starting to come up for grabs.
[01:09:50.800 --> 01:09:52.120]   They're very complicated markets
[01:09:52.120 --> 01:09:52.960]   and they're hard to function in.
[01:09:52.960 --> 01:09:54.960]   And the startups, it's harder to build the companies,
[01:09:54.960 --> 01:09:57.600]   but the payoff is potentially much bigger
[01:09:57.600 --> 01:10:00.200]   because those are such huge slices of GDP.
[01:10:00.200 --> 01:10:04.000]   So the shape of the industry will change a bit over time.
[01:10:04.000 --> 01:10:07.000]   But, you know, look like, you know,
[01:10:07.000 --> 01:10:09.880]   this is very basic, like what is technology?
[01:10:09.880 --> 01:10:11.240]   Technology is a better way of doing things.
[01:10:11.240 --> 01:10:13.240]   Like at some point, the better way of doing things
[01:10:13.240 --> 01:10:15.360]   is the way that people do things.
[01:10:15.360 --> 01:10:17.240]   At some point, that does shift market share
[01:10:17.240 --> 01:10:18.200]   from people doing things the old way
[01:10:18.200 --> 01:10:20.120]   to people doing things the new way.
[01:10:20.120 --> 01:10:20.960]   - Right.
[01:10:20.960 --> 01:10:23.120]   But so if like you, let's say you build
[01:10:23.120 --> 01:10:24.960]   like a better education system somehow,
[01:10:24.960 --> 01:10:26.400]   the government is still gonna be dumping
[01:10:26.400 --> 01:10:28.360]   trillions of dollars into the old education system
[01:10:28.360 --> 01:10:29.560]   or the old healthcare system.
[01:10:29.560 --> 01:10:31.680]   Do you just kind of accept this as a lost cause
[01:10:31.680 --> 01:10:34.280]   that basically like 50% of GDP will just be wasted,
[01:10:34.280 --> 01:10:35.720]   but we'll make the other 50% really good?
[01:10:35.720 --> 01:10:39.360]   Or like, when you build the alternatives,
[01:10:39.360 --> 01:10:43.200]   could you just accept the loss of the existing system?
[01:10:43.200 --> 01:10:45.720]   - Yeah, so look, let's take education as a great example.
[01:10:45.720 --> 01:10:48.240]   Like I think the incumbent education system
[01:10:48.240 --> 01:10:49.840]   is trying to destroy itself, right?
[01:10:49.840 --> 01:10:53.280]   Like I think it is, I think it and the people running it
[01:10:53.280 --> 01:10:55.560]   and the people funding it are trying to kill it, right?
[01:10:55.560 --> 01:10:56.600]   And they're kind of doing that
[01:10:56.600 --> 01:10:57.960]   every possible way they can, right?
[01:10:58.560 --> 01:10:59.400]   So for K through 12,
[01:10:59.400 --> 01:11:01.680]   they're prioritizing the teachers over the students, right?
[01:11:01.680 --> 01:11:02.760]   Which is just like the opposite
[01:11:02.760 --> 01:11:05.600]   of what any like properly run company would do, right?
[01:11:05.600 --> 01:11:09.280]   At the university level, like they are,
[01:11:09.280 --> 01:11:11.160]   the problems in the modern university
[01:11:11.160 --> 01:11:13.120]   have been well covered by other people.
[01:11:13.120 --> 01:11:17.360]   They have become a cartel, the student loan,
[01:11:17.360 --> 01:11:19.280]   what is it?
[01:11:19.280 --> 01:11:20.960]   Was it Stanford now has more admin,
[01:11:20.960 --> 01:11:22.240]   Stanford now has more administrators
[01:11:22.240 --> 01:11:24.400]   than they have students, right?
[01:11:24.400 --> 01:11:25.720]   Again, it's like you wouldn't,
[01:11:25.720 --> 01:11:27.760]   no company would run that way.
[01:11:27.760 --> 01:11:29.280]   - I mean, there's like a positive vision
[01:11:29.280 --> 01:11:30.680]   where you could turn that into the bloom,
[01:11:30.680 --> 01:11:33.440]   two sigma is a single student for single administrator,
[01:11:33.440 --> 01:11:35.440]   but I don't think that's what's happening.
[01:11:35.440 --> 01:11:37.040]   - Yes, yes, that's correct.
[01:11:37.040 --> 01:11:39.240]   You could, you could and they're not.
[01:11:39.240 --> 01:11:40.920]   That's right, that's exactly right.
[01:11:40.920 --> 01:11:42.360]   And then look, it's like, you know, look,
[01:11:42.360 --> 01:11:43.720]   you see the federal student loan, you know,
[01:11:43.720 --> 01:11:44.560]   kind of crazy thing.
[01:11:44.560 --> 01:11:45.400]   And by the way, you know,
[01:11:45.400 --> 01:11:47.040]   the universities are voluntarily shutting down
[01:11:47.040 --> 01:11:48.360]   use of admissions testing, right?
[01:11:48.360 --> 01:11:50.800]   They're shutting down SAT, ACT, GRE.
[01:11:50.800 --> 01:11:52.120]   They're very deliberately eliminating
[01:11:52.120 --> 01:11:53.360]   the intelligence signal, right?
[01:11:53.360 --> 01:11:54.480]   Which is like a big part of the signal
[01:11:54.480 --> 01:11:57.160]   that employers kind of piggyback on top of.
[01:11:57.160 --> 01:12:00.560]   You know, they become intensely politicized.
[01:12:00.560 --> 01:12:01.800]   You know, we now know, by the way,
[01:12:01.800 --> 01:12:03.520]   the replication crisis, most of the research
[01:12:03.520 --> 01:12:05.720]   that happens at these universities is fake, right?
[01:12:05.720 --> 01:12:07.920]   Most of it's not real, generating real research results.
[01:12:07.920 --> 01:12:10.480]   We know that 'cause it won't replicate.
[01:12:10.480 --> 01:12:12.240]   You know, it's just like, you've got these,
[01:12:12.240 --> 01:12:13.560]   you know, you've just got these,
[01:12:13.560 --> 01:12:15.760]   you've just got these kind of increasingly disconnected,
[01:12:15.760 --> 01:12:16.800]   you know, kind of mentalities.
[01:12:16.800 --> 01:12:18.760]   And, you know, there's some set of people obviously
[01:12:18.760 --> 01:12:19.960]   who are gonna keep going to these schools,
[01:12:19.960 --> 01:12:24.080]   but you know, like a degree from a,
[01:12:24.080 --> 01:12:25.720]   and then you just look at cost, right?
[01:12:25.720 --> 01:12:28.720]   So like a degree from a, you know,
[01:12:28.720 --> 01:12:30.680]   mainstream university that costs, you know,
[01:12:30.680 --> 01:12:33.880]   in 10 years, a half million to a million dollars, right?
[01:12:33.880 --> 01:12:36.480]   That has no intelligence signal attached to it anymore,
[01:12:36.480 --> 01:12:39.440]   right, where like most of the like classes are fake.
[01:12:39.440 --> 01:12:41.000]   Most of the degrees are fake.
[01:12:41.000 --> 01:12:43.800]   Most of the research is fake, right?
[01:12:43.800 --> 01:12:44.920]   Where they're like, you know,
[01:12:44.920 --> 01:12:46.480]   wrapped up in these political obsessions.
[01:12:46.480 --> 01:12:51.040]   Like that's probably not the future
[01:12:51.040 --> 01:12:53.680]   of how employers are going to staff.
[01:12:53.680 --> 01:12:54.960]   That's probably not where people
[01:12:54.960 --> 01:12:57.480]   are actually going to learn valuable marketable skills.
[01:12:57.480 --> 01:12:59.240]   Right, like that's like the last thing that they want
[01:12:59.240 --> 01:13:01.160]   is to like actually teach somebody like a marketable skill.
[01:13:01.160 --> 01:13:03.880]   Like that's so, like teaching somebody a marketable skill
[01:13:03.880 --> 01:13:05.360]   is so far down on the list of priorities
[01:13:05.360 --> 01:13:08.040]   at a university now, it's like not even in the top 20.
[01:13:08.040 --> 01:13:11.800]   And so, you know, a lot of it is just they're a cartel.
[01:13:11.800 --> 01:13:14.000]   Like they operate as a cartel, they run as a cartel.
[01:13:14.000 --> 01:13:16.520]   It's a literal cartel, like they run as a cartel
[01:13:16.520 --> 01:13:19.520]   because, and the cartels administered through the agencies,
[01:13:19.520 --> 01:13:21.080]   the sort of quasi governmental bodies
[01:13:21.080 --> 01:13:22.040]   that determine who gets access
[01:13:22.040 --> 01:13:23.600]   to federal student loan funding.
[01:13:23.600 --> 01:13:25.200]   And those bodies are staffed
[01:13:25.200 --> 01:13:27.320]   by the current university administrators, right?
[01:13:27.320 --> 01:13:29.680]   And so it's a self-governing cartel.
[01:13:29.680 --> 01:13:32.240]   It does exactly what cartels do.
[01:13:32.240 --> 01:13:34.560]   It's stagnating in going crazy
[01:13:34.560 --> 01:13:36.120]   in a kind of in spectacular ways.
[01:13:36.120 --> 01:13:38.760]   And so there is clearly going to,
[01:13:38.760 --> 01:13:40.280]   there is going to be an education revolution.
[01:13:40.280 --> 01:13:41.840]   Like, does that happen by the way?
[01:13:41.840 --> 01:13:43.360]   Does that happen today or five years or 10 years?
[01:13:43.360 --> 01:13:44.480]   I don't know, right?
[01:13:44.480 --> 01:13:46.360]   Does it happen in the form of new in-person institutions
[01:13:46.360 --> 01:13:47.400]   versus internet based?
[01:13:47.400 --> 01:13:48.840]   I don't know.
[01:13:48.840 --> 01:13:51.360]   Is it driven by, you know, new, is it driven by us
[01:13:51.360 --> 01:13:53.320]   or is it driven by employers who just get fed up
[01:13:53.320 --> 01:13:54.440]   and they're like, you know, screw it.
[01:13:54.440 --> 01:13:55.840]   Like, we're not going to live like this anymore.
[01:13:55.840 --> 01:13:56.680]   And we're just going to hire people
[01:13:56.680 --> 01:13:58.000]   in a totally different way.
[01:13:58.000 --> 01:13:58.840]   That I don't know.
[01:13:58.840 --> 01:13:59.760]   Like, there's lots and lots of questions
[01:13:59.760 --> 01:14:01.000]   about what's going to happen from here.
[01:14:01.000 --> 01:14:03.000]   But like the system is breaking,
[01:14:03.000 --> 01:14:05.400]   like in really kind of fundamental and obvious ways.
[01:14:05.400 --> 01:14:07.840]   And then, you know, healthcare, same thing, right?
[01:14:07.840 --> 01:14:10.680]   Healthcare is just like, healthcare is just very broadly,
[01:14:10.680 --> 01:14:13.400]   like just outcomes on healthcare.
[01:14:13.400 --> 01:14:18.200]   Like it's almost, it's extraordinarily difficult to find any,
[01:14:18.200 --> 01:14:19.440]   it's extraordinarily difficult
[01:14:19.440 --> 01:14:21.480]   to find positive outcomes in healthcare.
[01:14:21.480 --> 01:14:23.200]   Positive outcomes.
[01:14:23.200 --> 01:14:25.840]   Like, in other words, like there's lots of activity
[01:14:25.840 --> 01:14:26.680]   in healthcare.
[01:14:26.680 --> 01:14:28.920]   It's very hard to find anything that causes people
[01:14:28.920 --> 01:14:30.480]   to like live longer, right?
[01:14:30.480 --> 01:14:31.720]   Or to like be healthier longer.
[01:14:31.720 --> 01:14:32.880]   And then, you know, every once in a while,
[01:14:32.880 --> 01:14:34.600]   there's like a successful form of cancer treatment
[01:14:34.600 --> 01:14:35.440]   or something.
[01:14:35.440 --> 01:14:36.720]   But like, there are all these analyses
[01:14:36.720 --> 01:14:38.480]   that show like massive investment in like, you know,
[01:14:38.480 --> 01:14:40.320]   public support for health insurance and all these things.
[01:14:40.320 --> 01:14:41.520]   And then it's just like health outcomes
[01:14:41.520 --> 01:14:42.360]   basically don't move.
[01:14:42.360 --> 01:14:43.560]   - Right.
[01:14:43.560 --> 01:14:46.000]   - And so there's just like,
[01:14:46.000 --> 01:14:47.720]   to the extent that people care at all
[01:14:47.720 --> 01:14:49.840]   about the reality of like their health,
[01:14:49.840 --> 01:14:51.760]   then they're gonna have to be new ways of doing things.
[01:14:51.760 --> 01:14:53.120]   And tech is gonna be the wedge into the market
[01:14:53.120 --> 01:14:54.760]   for people who have those new ideas.
[01:14:54.760 --> 01:14:55.600]   - Yeah, yeah.
[01:14:55.600 --> 01:14:56.920]   Hopefully these revolutions in education and healthcare
[01:14:56.920 --> 01:14:58.320]   are not like healthcare itself,
[01:14:58.320 --> 01:15:00.800]   where we're always 20 years away from a cure to cancer.
[01:15:00.800 --> 01:15:02.200]   And we're always, you know, 20 years away
[01:15:02.200 --> 01:15:05.080]   from making educational technological.
[01:15:05.080 --> 01:15:09.120]   You've talked about how big tech is two to four X overstaffed
[01:15:09.120 --> 01:15:10.080]   in the best case.
[01:15:10.080 --> 01:15:12.680]   I'm curious how overstaffed do you think venture capital is?
[01:15:12.680 --> 01:15:15.120]   How many partners and associates could we get let go?
[01:15:15.120 --> 01:15:16.400]   And there really wouldn't be a difference
[01:15:16.400 --> 01:15:18.360]   in the performance of venture capital.
[01:15:18.360 --> 01:15:20.040]   - So Andy, my friend, Andy Rocklef,
[01:15:20.040 --> 01:15:21.080]   who was a founder of Benchmark
[01:15:21.080 --> 01:15:23.720]   and teaches venture capital at Stanford,
[01:15:23.720 --> 01:15:26.040]   his description of this is I think correct,
[01:15:26.040 --> 01:15:28.280]   which he says, "Venture capital is always overstaffed
[01:15:28.280 --> 01:15:29.440]   and overfunded."
[01:15:29.440 --> 01:15:31.080]   And his estimate is it's like,
[01:15:31.080 --> 01:15:33.240]   it's like overstaffed and overfunded by like,
[01:15:33.240 --> 01:15:35.880]   at least 80% of it is over what it's,
[01:15:35.880 --> 01:15:38.800]   it's like overfunded by like a factor of five.
[01:15:38.800 --> 01:15:39.640]   It should probably be,
[01:15:39.640 --> 01:15:42.120]   in other words, it's probably 20% of the size that it is.
[01:15:42.120 --> 01:15:43.520]   But it should be 20% of the number of people,
[01:15:43.520 --> 01:15:44.840]   there should be 20% of the number of funds,
[01:15:44.840 --> 01:15:48.720]   there should be 20% the number of, the amount of money.
[01:15:48.720 --> 01:15:51.120]   And his conclusion after watching this for a long time
[01:15:51.120 --> 01:15:51.960]   and analyzing it was,
[01:15:51.960 --> 01:15:55.360]   it's basically a permanent like 5X overfunding, overstaffing.
[01:15:55.360 --> 01:15:57.160]   And it goes to what I referenced earlier,
[01:15:57.160 --> 01:15:59.960]   which is the world we live in just has this massive imbalance
[01:15:59.960 --> 01:16:03.000]   of too much money chasing too few opportunities
[01:16:03.000 --> 01:16:05.040]   to invest the money productively.
[01:16:05.040 --> 01:16:07.000]   And so there's just too much money
[01:16:07.000 --> 01:16:09.760]   that needs long run returns that looks to venture
[01:16:09.760 --> 01:16:11.400]   as part of their asset allocation
[01:16:11.400 --> 01:16:14.040]   in the way that modern investors do asset allocation.
[01:16:14.040 --> 01:16:16.760]   And it's, and so the full version of this,
[01:16:16.760 --> 01:16:17.720]   he describes it as basically,
[01:16:17.720 --> 01:16:20.040]   there's only ever been two models
[01:16:20.040 --> 01:16:21.400]   of institutional investment.
[01:16:21.400 --> 01:16:22.920]   There's the old model of institutional investment,
[01:16:22.920 --> 01:16:24.480]   which is 60, 40 stocks and bonds
[01:16:24.480 --> 01:16:26.040]   that kind of dominated the 20th century
[01:16:26.040 --> 01:16:27.160]   up until the 1970s.
[01:16:27.160 --> 01:16:29.040]   And then there's what's called the Swenson model,
[01:16:29.040 --> 01:16:29.920]   named after Dave Swenson,
[01:16:29.920 --> 01:16:31.920]   who created the Yale endowment in its modern form.
[01:16:31.920 --> 01:16:33.880]   And that's the model that all the endowments
[01:16:33.880 --> 01:16:35.080]   and foundations have today.
[01:16:35.080 --> 01:16:36.480]   And increasingly the sovereign wealth funds
[01:16:36.480 --> 01:16:38.560]   where they invest in alternative assets,
[01:16:38.560 --> 01:16:41.520]   which means, hedge funds, venture capital, real estate,
[01:16:41.520 --> 01:16:44.680]   right, and things that aren't stocks and bonds.
[01:16:44.680 --> 01:16:47.080]   And so anybody following the Swenson model
[01:16:47.080 --> 01:16:49.200]   has an allocation of venture capital,
[01:16:49.200 --> 01:16:51.280]   on average, maybe that's 4% of their assets,
[01:16:51.280 --> 01:16:53.800]   but 4% of the entire global asset base
[01:16:53.800 --> 01:16:55.920]   is just a gigantic number.
[01:16:55.920 --> 01:16:58.880]   And so, and then hope, it's like somebody once said,
[01:16:58.880 --> 01:17:00.600]   it's like having a sixth marriage, right?
[01:17:00.600 --> 01:17:02.960]   It's like, hope triumphing over experience.
[01:17:02.960 --> 01:17:05.880]   You know, the thing you'll hear from LPs
[01:17:05.880 --> 01:17:07.160]   is every LP says they only invest
[01:17:07.160 --> 01:17:08.560]   in the top 10 venture capital funds,
[01:17:08.560 --> 01:17:11.040]   and then every LP has a different list of who that is.
[01:17:11.920 --> 01:17:14.720]   Right, and so it's sort of this thing of like,
[01:17:14.720 --> 01:17:16.680]   you know, everybody, and they all kind of know
[01:17:16.680 --> 01:17:17.920]   that the whole sector is overfunded,
[01:17:17.920 --> 01:17:19.640]   but they all kind of know that they suffer
[01:17:19.640 --> 01:17:22.800]   from a real, a lack of, you know,
[01:17:22.800 --> 01:17:24.640]   where else is the money going to go?
[01:17:24.640 --> 01:17:25.480]   - Yeah, yeah.
[01:17:25.480 --> 01:17:28.720]   - And then, yeah, and then look, it's always possible,
[01:17:28.720 --> 01:17:30.360]   like you never know, like it's always possible
[01:17:30.360 --> 01:17:31.920]   that you'll have some great new fund
[01:17:31.920 --> 01:17:33.040]   that's gonna do spectacularly well,
[01:17:33.040 --> 01:17:35.000]   there's some great new sector that'll open up.
[01:17:35.000 --> 01:17:37.600]   You know, a huge advantage that venture capital has,
[01:17:37.600 --> 01:17:40.000]   right, is that the long dated part of it, right,
[01:17:40.000 --> 01:17:42.240]   means that you don't suffer the consequences
[01:17:42.240 --> 01:17:45.200]   of a bad venture capital investment, like up front, right?
[01:17:45.200 --> 01:17:47.680]   Like, so you get like a 10 year lease on life
[01:17:47.680 --> 01:17:49.000]   when you make a venture capital investment,
[01:17:49.000 --> 01:17:51.320]   like you're not gonna get judged for a long time.
[01:17:51.320 --> 01:17:52.160]   - Yeah. - Yeah.
[01:17:52.160 --> 01:17:53.560]   - And so I think that causes people probably
[01:17:53.560 --> 01:17:55.440]   to invest more in the sector probably than they should.
[01:17:55.440 --> 01:17:57.320]   - Is Vinner's Curse also a big component here,
[01:17:57.320 --> 01:17:58.680]   where the guy who bids the most
[01:17:58.680 --> 01:18:00.480]   is the one who sets the price?
[01:18:00.480 --> 01:18:02.000]   - That can happen.
[01:18:02.000 --> 01:18:05.640]   At the early stages, the best companies tend to raise
[01:18:05.640 --> 01:18:09.040]   at less than the optimal price because they wanna,
[01:18:09.040 --> 01:18:11.320]   because the signal of who invests is more important
[01:18:11.320 --> 01:18:12.840]   than the absolute price.
[01:18:12.840 --> 01:18:15.040]   And so almost every investment that we fund,
[01:18:15.040 --> 01:18:17.760]   like at the series A stage, they could raise money,
[01:18:17.760 --> 01:18:21.360]   I think, at two to four times the price they raise from us,
[01:18:21.360 --> 01:18:22.320]   but they value the signal.
[01:18:22.320 --> 01:18:24.920]   And I think that's also true of the seed landscape,
[01:18:24.920 --> 01:18:26.760]   and I think it's also still true in a lot of cases
[01:18:26.760 --> 01:18:28.520]   at the series B level.
[01:18:28.520 --> 01:18:29.560]   Series C and beyond,
[01:18:29.560 --> 01:18:31.560]   it becomes much more of an efficient market.
[01:18:31.560 --> 01:18:32.800]   Again, it's not a full auction.
[01:18:32.800 --> 01:18:33.920]   It's a little bit like your earlier question.
[01:18:33.920 --> 01:18:36.520]   It's not just money.
[01:18:36.520 --> 01:18:39.080]   It's not, well, at least here's the theory.
[01:18:39.080 --> 01:18:40.040]   It's not just money, right?
[01:18:40.040 --> 01:18:41.400]   It's not just a liquid,
[01:18:41.400 --> 01:18:43.400]   it's not just a straight up liquid financial market.
[01:18:43.400 --> 01:18:46.320]   Like these are whaling journeys, right?
[01:18:46.320 --> 01:18:47.960]   And so, and by the way,
[01:18:47.960 --> 01:18:50.040]   like there's a much blunter answer to this question,
[01:18:50.040 --> 01:18:53.080]   which is people who raise seed money and series A money
[01:18:53.080 --> 01:18:56.040]   from the high bidder often end up really regretting it
[01:18:56.040 --> 01:18:57.520]   because they end up raising from people
[01:18:57.520 --> 01:18:58.840]   who don't actually understand the nature
[01:18:58.840 --> 01:19:01.040]   of a whaling journey or a tech startup.
[01:19:01.040 --> 01:19:05.440]   And then they panic at the wrong times and they freak out.
[01:19:05.440 --> 01:19:07.800]   And the wrong investors can really screw up a company.
[01:19:07.800 --> 01:19:09.440]   And so at least historically,
[01:19:09.440 --> 01:19:11.320]   there's a self-correcting equilibrium
[01:19:11.320 --> 01:19:12.160]   that comes out of that
[01:19:12.160 --> 01:19:13.520]   where the best entrepreneurs understand
[01:19:13.520 --> 01:19:14.440]   that they want people on their team
[01:19:14.440 --> 01:19:15.280]   who really know what they're doing
[01:19:15.280 --> 01:19:16.240]   and they don't wanna take chances
[01:19:16.240 --> 01:19:17.400]   that somebody is gonna like freak out
[01:19:17.400 --> 01:19:18.640]   and try to shut the company down
[01:19:18.640 --> 01:19:20.160]   the first time something goes wrong.
[01:19:20.160 --> 01:19:21.000]   - Got it, got it.
[01:19:21.000 --> 01:19:21.840]   - But we'll see.
[01:19:21.840 --> 01:19:24.240]   - Hey everybody.
[01:19:24.240 --> 01:19:26.320]   I hope you enjoyed that episode.
[01:19:26.320 --> 01:19:29.680]   Just wanted to let you know that in order to help pay
[01:19:29.680 --> 01:19:33.040]   for the bills associated with this podcast,
[01:19:33.040 --> 01:19:35.160]   I'm turning on paid subscriptions
[01:19:35.160 --> 01:19:39.480]   on my SEP stack at varkashpatel.com.
[01:19:39.480 --> 01:19:43.600]   No important content on this podcast will ever be paywalled.
[01:19:43.600 --> 01:19:46.320]   So please don't donate if you have to think twice
[01:19:46.320 --> 01:19:48.060]   before buying a cup of coffee.
[01:19:48.060 --> 01:19:49.560]   But if you have the means
[01:19:49.560 --> 01:19:51.240]   and you've enjoyed this podcast
[01:19:51.240 --> 01:19:52.960]   or gotten some kind of value out of it,
[01:19:52.960 --> 01:19:54.820]   I would really appreciate your support.
[01:19:54.820 --> 01:19:57.040]   As always, the most helpful thing you can do
[01:19:57.040 --> 01:19:58.800]   is to share the podcast.
[01:19:58.800 --> 01:20:00.520]   Send it to people you think might enjoy it,
[01:20:00.520 --> 01:20:02.640]   put it in Twitter, your group chats, et cetera.
[01:20:02.640 --> 01:20:04.520]   Just splits the world.
[01:20:04.520 --> 01:20:05.760]   Appreciate your listening.
[01:20:05.760 --> 01:20:06.920]   I'll see you next time.
[01:20:06.920 --> 01:20:07.760]   Cheers.
[01:20:08.200 --> 01:20:10.780]   (upbeat music)
[01:20:10.820 --> 01:20:13.400]   (upbeat music)
[01:20:13.400 --> 01:20:17.400]   [music]

