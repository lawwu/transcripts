
[00:00:00.000 --> 00:00:02.880]   The following is a conversation with Dmitry Korkin,
[00:00:02.880 --> 00:00:04.860]   his second time in the podcast.
[00:00:04.860 --> 00:00:06.980]   He's a professor of bioinformatics
[00:00:06.980 --> 00:00:09.740]   and computational biology at WPI,
[00:00:09.740 --> 00:00:13.540]   where he specializes in bioinformatics of complex disease,
[00:00:13.540 --> 00:00:16.300]   computational genomics, systems biology,
[00:00:16.300 --> 00:00:18.580]   and biomedical data analytics.
[00:00:18.580 --> 00:00:22.060]   He loves biology, he loves computing,
[00:00:22.060 --> 00:00:26.140]   plus he is Russian and recites a poem in Russian
[00:00:26.140 --> 00:00:27.780]   at the end of the podcast.
[00:00:27.780 --> 00:00:31.100]   What else could you possibly ask for in this world?
[00:00:31.100 --> 00:00:32.960]   Quick mention of our sponsors,
[00:00:32.960 --> 00:00:37.760]   Brave Browser, NetSuite Business Management Software,
[00:00:37.760 --> 00:00:40.300]   Magic Spoon Low Carb Cereal,
[00:00:40.300 --> 00:00:42.920]   and Eight Sleep Self-Cooling Mattress.
[00:00:42.920 --> 00:00:46.380]   So the choice is browsing privacy, business success,
[00:00:46.380 --> 00:00:49.180]   healthy diet, or comfortable sleep.
[00:00:49.180 --> 00:00:50.660]   Choose wisely, my friends.
[00:00:50.660 --> 00:00:53.640]   And if you wish, click the sponsor links below
[00:00:53.640 --> 00:00:56.460]   to get a discount and to support this podcast.
[00:00:56.460 --> 00:00:58.620]   As a side note, let me say that to me,
[00:00:58.620 --> 00:01:01.540]   the scientists that did the best apolitical,
[00:01:01.540 --> 00:01:04.020]   impactful, brilliant work of 2020
[00:01:04.020 --> 00:01:09.020]   are the biologists who study viruses without an agenda,
[00:01:09.020 --> 00:01:11.820]   without much sleep, to be honest,
[00:01:11.820 --> 00:01:14.500]   just a pure passion for scientific discovery
[00:01:14.500 --> 00:01:18.440]   and exploration of the mysteries within viruses.
[00:01:18.440 --> 00:01:21.380]   Viruses are both terrifying and beautiful.
[00:01:21.380 --> 00:01:22.980]   Terrifying because they can threaten
[00:01:22.980 --> 00:01:25.180]   the fabric of human civilization,
[00:01:25.180 --> 00:01:27.860]   both biological and psychological.
[00:01:27.860 --> 00:01:30.500]   Beautiful because they give us insights
[00:01:30.500 --> 00:01:32.980]   into the nature of life on Earth
[00:01:32.980 --> 00:01:35.940]   and perhaps even extraterrestrial life
[00:01:35.940 --> 00:01:38.020]   of the not-so-intelligent variety
[00:01:38.020 --> 00:01:39.580]   that might meet us one day
[00:01:39.580 --> 00:01:41.540]   as we explore the habitable planets
[00:01:41.540 --> 00:01:43.780]   and moons in our universe.
[00:01:43.780 --> 00:01:45.820]   If you enjoy this thing, subscribe on YouTube,
[00:01:45.820 --> 00:01:49.080]   review it on Apple Podcasts, follow on Spotify,
[00:01:49.080 --> 00:01:50.940]   support on Patreon, or connect with me
[00:01:50.940 --> 00:01:53.220]   on Twitter @LexFriedman.
[00:01:53.220 --> 00:01:56.960]   And now, here's my conversation with Dmitry Korkin.
[00:01:56.960 --> 00:02:00.720]   It's often said that proteins
[00:02:00.720 --> 00:02:04.260]   and the amino acid residues that make them up
[00:02:04.260 --> 00:02:06.460]   are the building blocks of life.
[00:02:06.460 --> 00:02:08.060]   Do you think of proteins in this way
[00:02:08.060 --> 00:02:11.200]   as the basic building blocks of life?
[00:02:11.200 --> 00:02:12.240]   - Yes and no.
[00:02:12.240 --> 00:02:16.340]   So the proteins indeed is the basic unit,
[00:02:16.340 --> 00:02:20.500]   biological unit, that carries out
[00:02:20.500 --> 00:02:22.860]   important function of the cell.
[00:02:22.860 --> 00:02:25.820]   However, through studying the proteins
[00:02:25.820 --> 00:02:29.340]   and comparing the proteins across different species,
[00:02:29.340 --> 00:02:31.420]   across different kingdoms,
[00:02:31.420 --> 00:02:34.620]   you realize that proteins are actually
[00:02:34.620 --> 00:02:36.740]   much more complicated.
[00:02:36.740 --> 00:02:41.740]   So they have so-called modular complexity.
[00:02:41.740 --> 00:02:47.300]   And so what I mean by that is an average protein
[00:02:47.880 --> 00:02:52.880]   consists of several structural units.
[00:02:52.880 --> 00:02:57.480]   So we call them protein domains.
[00:02:57.480 --> 00:03:02.480]   And so you can imagine a protein as a string of beads,
[00:03:02.480 --> 00:03:04.860]   where each bead is a protein domain.
[00:03:04.860 --> 00:03:10.240]   And in the past 20 years,
[00:03:10.240 --> 00:03:13.600]   scientists have been studying the nature
[00:03:13.600 --> 00:03:15.040]   of the protein domains.
[00:03:15.040 --> 00:03:19.480]   Because we realized that it's the unit.
[00:03:19.480 --> 00:03:22.120]   Because if you look at the functions, right?
[00:03:22.120 --> 00:03:25.880]   So many proteins have more than one function.
[00:03:25.880 --> 00:03:29.440]   And those protein functions are often carried out
[00:03:29.440 --> 00:03:31.560]   by those protein domains.
[00:03:31.560 --> 00:03:36.560]   So we also see that in the evolution,
[00:03:36.560 --> 00:03:40.160]   those proteins domains get shuffled.
[00:03:40.160 --> 00:03:43.460]   So they act actually as a unit.
[00:03:43.460 --> 00:03:45.280]   Also from the structural perspective, right?
[00:03:45.280 --> 00:03:50.280]   So some people think of a protein
[00:03:50.280 --> 00:03:55.320]   as a sort of a globular molecule.
[00:03:55.320 --> 00:03:56.800]   But as a matter of fact,
[00:03:56.800 --> 00:04:01.800]   is the globular part of this protein is a protein domain.
[00:04:01.800 --> 00:04:06.000]   So we often have this, again,
[00:04:06.000 --> 00:04:09.640]   the collection of this protein domains
[00:04:10.580 --> 00:04:14.600]   align on a string as beads.
[00:04:14.600 --> 00:04:17.880]   - And the protein domains are made up of amino acid residues.
[00:04:17.880 --> 00:04:18.720]   - Yes.
[00:04:18.720 --> 00:04:19.560]   - So we're talking--
[00:04:19.560 --> 00:04:20.380]   - So it's--
[00:04:20.380 --> 00:04:21.220]   - So this is the basic,
[00:04:21.220 --> 00:04:22.560]   so you're saying the protein domain
[00:04:22.560 --> 00:04:25.600]   is the basic building block of the function
[00:04:25.600 --> 00:04:28.300]   that we think about proteins doing.
[00:04:28.300 --> 00:04:30.360]   So of course, you can always talk about
[00:04:30.360 --> 00:04:31.480]   different building blocks.
[00:04:31.480 --> 00:04:32.840]   It's turtles all the way down.
[00:04:32.840 --> 00:04:35.320]   But there's a point where there is,
[00:04:35.320 --> 00:04:37.640]   at the point of the hierarchy,
[00:04:37.640 --> 00:04:42.040]   where it's the most, the cleanest element block
[00:04:42.040 --> 00:04:46.220]   based on which you can put them together
[00:04:46.220 --> 00:04:49.200]   in different kinds of ways to form complex function.
[00:04:49.200 --> 00:04:50.880]   And you're saying protein domains,
[00:04:50.880 --> 00:04:55.160]   why is that not talked about as often in popular culture?
[00:04:55.160 --> 00:04:58.240]   - Well, there are several perspectives on this.
[00:04:58.240 --> 00:05:03.200]   And one, of course, is the historical perspective, right?
[00:05:03.200 --> 00:05:07.760]   So historically, scientists have been able
[00:05:07.760 --> 00:05:12.400]   to structurally resolve to obtain the 3D coordinates
[00:05:12.400 --> 00:05:17.400]   of a protein for smaller proteins.
[00:05:17.400 --> 00:05:21.000]   And smaller proteins tend to be a single domain protein.
[00:05:21.000 --> 00:05:24.000]   So we have a protein equal to a protein domain.
[00:05:24.000 --> 00:05:27.080]   And so because of that, the initial suspicion
[00:05:27.080 --> 00:05:31.720]   was that the proteins, they have globular shapes,
[00:05:31.720 --> 00:05:36.720]   and the more of smaller proteins you obtain structurally,
[00:05:36.720 --> 00:05:41.720]   the more you became convinced that that's the case.
[00:05:41.720 --> 00:05:45.720]   And only later when we started having
[00:05:45.720 --> 00:05:52.920]   alternative approaches, so the traditional ones
[00:05:52.920 --> 00:05:57.320]   are X-ray crystallography and NMR spectroscopy.
[00:05:57.320 --> 00:06:02.000]   So these are sort of the two main techniques
[00:06:02.000 --> 00:06:04.440]   that give us the 3D coordinates.
[00:06:04.440 --> 00:06:07.760]   But nowadays, there is huge breakthrough
[00:06:07.760 --> 00:06:10.460]   in cryo-electron microscopy.
[00:06:10.460 --> 00:06:13.600]   So the more advanced methods that allow us
[00:06:13.600 --> 00:06:20.440]   to get into the 3D shapes of much larger molecules,
[00:06:20.440 --> 00:06:24.920]   molecular complexes, just to give you
[00:06:24.920 --> 00:06:29.200]   one of the common examples for this year.
[00:06:29.200 --> 00:06:32.760]   Right, so the first experimental structure
[00:06:32.760 --> 00:06:37.760]   of a SARS-CoV-2 protein was the cryo-EM structure
[00:06:37.760 --> 00:06:41.960]   of the S protein, so the spike protein.
[00:06:41.960 --> 00:06:46.320]   And so it was solved very quickly.
[00:06:46.320 --> 00:06:49.480]   And the reason for that is the advancement
[00:06:49.480 --> 00:06:53.960]   of this technology is pretty spectacular.
[00:06:53.960 --> 00:06:57.480]   - How many domains is the, is it more than one domain?
[00:06:57.480 --> 00:07:01.320]   - Oh yes, oh yes, I mean, so it's a very complex structure.
[00:07:01.320 --> 00:07:03.040]   - It's complex.
[00:07:03.040 --> 00:07:06.480]   - We, you know, on top of the complexity
[00:07:06.480 --> 00:07:11.160]   of a single protein, right, so this structure
[00:07:11.160 --> 00:07:13.720]   is actually, is a complex, is a trimer.
[00:07:13.720 --> 00:07:17.640]   So it needs to form a trimer in order to function properly.
[00:07:17.640 --> 00:07:18.720]   - What's a complex?
[00:07:18.720 --> 00:07:22.880]   - So a complex is agglomeration of multiple proteins.
[00:07:22.880 --> 00:07:27.880]   And so we can have the same protein copied in multiple,
[00:07:27.880 --> 00:07:32.120]   you know, made up in multiple copies
[00:07:32.120 --> 00:07:36.160]   and forming something that we called a homo-oligomer.
[00:07:36.160 --> 00:07:38.120]   Homo means the same, right?
[00:07:38.120 --> 00:07:43.120]   So in this case, so the spike protein is an example
[00:07:43.120 --> 00:07:46.720]   of a homotetrimer, homotrimer, sorry.
[00:07:46.720 --> 00:07:48.080]   - So it needs three copies of a--
[00:07:48.080 --> 00:07:50.040]   - Three copies, exactly. - In order to.
[00:07:50.040 --> 00:07:50.880]   - Exactly.
[00:07:50.880 --> 00:07:55.000]   - We have these three chains, the three molecular chains
[00:07:55.000 --> 00:07:58.480]   coupled together and performing the function.
[00:07:58.480 --> 00:08:02.380]   That's what, when you look at this protein from the top,
[00:08:02.380 --> 00:08:03.920]   you see a perfect triangle.
[00:08:03.920 --> 00:08:04.760]   - Yeah.
[00:08:04.760 --> 00:08:08.280]   - So, but other, you know, so other complexes
[00:08:08.280 --> 00:08:12.160]   are made up of, you know, different proteins.
[00:08:12.160 --> 00:08:15.400]   Some of them are completely different,
[00:08:15.400 --> 00:08:16.920]   some of them are similar.
[00:08:16.920 --> 00:08:20.160]   The hemoglobin molecule, right, so it's actually,
[00:08:20.160 --> 00:08:21.880]   it's a protein complex.
[00:08:21.880 --> 00:08:25.760]   It's made of four basic subunits.
[00:08:25.760 --> 00:08:29.040]   Two of them are identical to each other,
[00:08:29.040 --> 00:08:30.800]   two other identical to each other,
[00:08:30.800 --> 00:08:32.820]   but they are also similar to each other,
[00:08:32.820 --> 00:08:36.000]   which sort of gives us some ideas
[00:08:36.000 --> 00:08:40.640]   about the evolution of this, you know, of this molecule.
[00:08:40.640 --> 00:08:43.980]   And perhaps, so one of the hypothesis is that, you know,
[00:08:43.980 --> 00:08:48.280]   in the past, it was just a homotetrimer, right?
[00:08:48.280 --> 00:08:53.160]   So four identical copies, and then it became, you know,
[00:08:53.160 --> 00:08:58.160]   sort of modified, it became mutated over the time
[00:08:58.160 --> 00:09:00.200]   and became more specialized.
[00:09:00.200 --> 00:09:02.600]   - Can we linger on the spike protein for a little bit?
[00:09:02.600 --> 00:09:04.980]   Is there something interesting
[00:09:04.980 --> 00:09:07.000]   or like beautiful you find about it?
[00:09:07.000 --> 00:09:07.920]   - I mean, first of all,
[00:09:07.920 --> 00:09:11.000]   it's an incredibly challenging protein.
[00:09:11.000 --> 00:09:16.000]   And so we, as a part of our sort of research
[00:09:16.160 --> 00:09:20.200]   to understand the structural basis of this virus
[00:09:20.200 --> 00:09:22.760]   to sort of decode, structurally decode
[00:09:22.760 --> 00:09:27.600]   every single protein in its proteome,
[00:09:27.600 --> 00:09:31.800]   we've been working on the spike protein.
[00:09:31.800 --> 00:09:34.480]   And one of the main challenges was that
[00:09:34.480 --> 00:09:40.680]   the cryo-EM data allows us to reconstruct
[00:09:40.680 --> 00:09:44.680]   or to obtain the 3D coordinates
[00:09:44.680 --> 00:09:48.080]   of roughly 2/3 of the protein.
[00:09:48.080 --> 00:09:51.960]   The rest of the 1/3 of this protein,
[00:09:51.960 --> 00:09:56.960]   it's a part that is buried into the membrane of the virus
[00:09:56.960 --> 00:10:01.600]   and of the viral envelope.
[00:10:01.600 --> 00:10:06.600]   And it also has a lot of unstable structures around it.
[00:10:06.600 --> 00:10:08.680]   - So it's chemically interacting somehow
[00:10:08.680 --> 00:10:10.200]   with whatever the heck it's connecting to.
[00:10:10.200 --> 00:10:12.840]   - Yeah, so people are still trying to understand.
[00:10:12.840 --> 00:10:17.840]   So the nature of and the role of this 1/3,
[00:10:17.840 --> 00:10:20.180]   'cause the top part,
[00:10:20.180 --> 00:10:25.240]   the primary function is to get attached
[00:10:25.240 --> 00:10:29.560]   to the ACE2 receptor, human receptor.
[00:10:29.560 --> 00:10:33.880]   There is also beautiful mechanics
[00:10:33.880 --> 00:10:36.080]   of how this thing happens, right?
[00:10:36.080 --> 00:10:40.560]   So because there are three different copies of this chains,
[00:10:41.960 --> 00:10:44.840]   there are three different domains, right?
[00:10:44.840 --> 00:10:46.080]   So we're talking about domains.
[00:10:46.080 --> 00:10:49.240]   So this is the receptor binding domains, RBDs,
[00:10:49.240 --> 00:10:52.960]   that gets untangled and get ready
[00:10:52.960 --> 00:10:56.840]   to get attached to the receptor.
[00:10:56.840 --> 00:11:01.840]   And now they are not necessarily going in a sync mode.
[00:11:01.840 --> 00:11:05.360]   As a matter of fact--
[00:11:05.360 --> 00:11:06.640]   - It's asynchronous?
[00:11:06.640 --> 00:11:11.640]   - So yes, and this is where another level
[00:11:11.680 --> 00:11:13.600]   of complexity comes into play,
[00:11:13.600 --> 00:11:17.160]   because right now what we see is,
[00:11:17.160 --> 00:11:21.840]   we typically see just one of the arms going out
[00:11:21.840 --> 00:11:26.840]   and getting ready to be attached to the ACE2 receptors.
[00:11:26.840 --> 00:11:30.360]   However, there was a recent mutation
[00:11:30.360 --> 00:11:35.080]   that people studied in that spike protein.
[00:11:35.080 --> 00:11:40.080]   And very recently, a group from Umayyad,
[00:11:40.080 --> 00:11:43.560]   a group from Umayyad Medical School,
[00:11:43.560 --> 00:11:45.280]   we happened to collaborate with groups.
[00:11:45.280 --> 00:11:47.240]   So this is a group of Jeremy Luban
[00:11:47.240 --> 00:11:50.640]   and a number of other faculty.
[00:11:50.640 --> 00:11:56.560]   They actually solved the mutated structure of the spike.
[00:11:56.560 --> 00:12:03.000]   And they showed that actually, because of these mutations,
[00:12:03.000 --> 00:12:08.000]   you have more than one arms opening up.
[00:12:08.860 --> 00:12:13.860]   And so now, so the frequency of two arms going up
[00:12:13.860 --> 00:12:18.120]   increased quite drastically.
[00:12:18.120 --> 00:12:18.960]   - Oh, interesting.
[00:12:18.960 --> 00:12:21.120]   Does that change the dynamics somehow?
[00:12:21.120 --> 00:12:24.320]   - It potentially can change the dynamics of,
[00:12:24.320 --> 00:12:28.420]   because now you have two possible opportunities
[00:12:28.420 --> 00:12:31.140]   to get attached to the ACE2 receptor.
[00:12:31.140 --> 00:12:35.280]   It's a very complex molecular process, mechanistic process.
[00:12:35.280 --> 00:12:37.420]   But the first step of this process
[00:12:37.420 --> 00:12:41.500]   is the attachment of this spike protein,
[00:12:41.500 --> 00:12:46.500]   of the spike trimer, to the human ACE2 receptor.
[00:12:46.500 --> 00:12:48.900]   So this is a molecule that sits
[00:12:48.900 --> 00:12:51.940]   on the surface of the human cell.
[00:12:51.940 --> 00:12:54.720]   And that's essentially what initiates,
[00:12:54.720 --> 00:12:58.880]   what triggers the whole process of encapsulation.
[00:12:58.880 --> 00:13:01.440]   - If this was dating, this would be the first date.
[00:13:01.440 --> 00:13:02.280]   So this is the--
[00:13:02.280 --> 00:13:03.120]   (laughing)
[00:13:03.120 --> 00:13:04.740]   - In a way, yes.
[00:13:05.660 --> 00:13:07.940]   - So is it possible to have the spike protein
[00:13:07.940 --> 00:13:10.620]   just floating about on its own?
[00:13:10.620 --> 00:13:14.660]   Or does it need that interactability with the membrane?
[00:13:14.660 --> 00:13:16.920]   - Yeah, so it needs to be attached,
[00:13:16.920 --> 00:13:19.020]   at least as far as I know.
[00:13:19.020 --> 00:13:23.300]   But when you get this thing attached on the surface,
[00:13:23.300 --> 00:13:25.140]   there is also a lot of dynamics
[00:13:25.140 --> 00:13:28.200]   on how it sits on the surface.
[00:13:28.200 --> 00:13:32.220]   So for example, there was a recent work in,
[00:13:32.220 --> 00:13:35.780]   again, where people use the cryo-lactone microscopy
[00:13:35.780 --> 00:13:38.940]   to get the first glimpse of the overall structure.
[00:13:38.940 --> 00:13:40.180]   It's a very low res,
[00:13:40.180 --> 00:13:43.820]   but you still get some interesting details
[00:13:43.820 --> 00:13:47.040]   about the surface, about what is happening inside,
[00:13:47.040 --> 00:13:50.740]   because we have literally no clue until recent work
[00:13:50.740 --> 00:13:54.540]   about how the capsid is organized.
[00:13:54.540 --> 00:13:55.380]   - What's a capsid?
[00:13:55.380 --> 00:13:56.740]   - So a capsid is essentially,
[00:13:56.740 --> 00:14:01.020]   it's the inner core of the viral particle
[00:14:01.020 --> 00:14:05.020]   where there is the RNA of the virus,
[00:14:05.020 --> 00:14:09.200]   and it's protected by another protein, N-protein,
[00:14:09.200 --> 00:14:13.460]   that essentially acts as a shield.
[00:14:13.460 --> 00:14:16.580]   But now we are learning more and more,
[00:14:16.580 --> 00:14:18.660]   so it's actually, it's not just this shield.
[00:14:18.660 --> 00:14:21.840]   It potentially is used for the stability
[00:14:21.840 --> 00:14:25.100]   of the outer shell of the virus.
[00:14:25.100 --> 00:14:27.860]   So it's pretty complicated.
[00:14:27.860 --> 00:14:29.780]   - And I mean, understanding all of this
[00:14:29.780 --> 00:14:31.660]   is really useful for trying to figure out
[00:14:31.660 --> 00:14:34.140]   like developing a vaccine or some kind of drug
[00:14:34.140 --> 00:14:36.080]   to attack any aspects of this, right?
[00:14:36.080 --> 00:14:39.420]   - So, I mean, there are many different implications to that.
[00:14:39.420 --> 00:14:41.100]   I mean, first of all,
[00:14:41.100 --> 00:14:44.620]   it's important to understand the virus itself, right?
[00:14:44.620 --> 00:14:49.620]   So in order to understand how it acts,
[00:14:49.620 --> 00:14:56.540]   what is the overall mechanistic process of this virus,
[00:14:56.540 --> 00:15:00.580]   replication of this virus, proliferation to the cell, right?
[00:15:00.580 --> 00:15:03.020]   So that's one aspect.
[00:15:03.020 --> 00:15:06.500]   The other aspect is designing new treatments, right?
[00:15:06.500 --> 00:15:09.060]   So one of the possible treatments
[00:15:09.060 --> 00:15:12.500]   is designing nanoparticles.
[00:15:12.500 --> 00:15:17.220]   And so some nanoparticles that will resemble the viral shape
[00:15:17.220 --> 00:15:19.540]   that would have the spike integrated,
[00:15:19.540 --> 00:15:23.700]   and essentially would act as a competitor to the real virus
[00:15:23.700 --> 00:15:26.700]   by blocking the ACE2 receptors
[00:15:26.700 --> 00:15:30.400]   and thus preventing the real virus entering the cell.
[00:15:30.400 --> 00:15:33.940]   Now, there are also, you know,
[00:15:33.940 --> 00:15:36.700]   there is a very interesting direction
[00:15:36.700 --> 00:15:39.420]   in looking at the membrane,
[00:15:39.420 --> 00:15:42.020]   at the envelope portion of the protein
[00:15:42.020 --> 00:15:45.980]   and attacking its M protein.
[00:15:45.980 --> 00:15:49.460]   So there are, you know, to give you a, you know,
[00:15:49.460 --> 00:15:51.200]   sort of a brief overview,
[00:15:51.200 --> 00:15:53.500]   there are four structural proteins.
[00:15:53.500 --> 00:15:55.780]   These are the proteins that made up
[00:15:55.780 --> 00:15:59.340]   a structure of the virus.
[00:15:59.340 --> 00:16:04.060]   So spike, S protein, that acts as a trimer,
[00:16:04.060 --> 00:16:05.900]   so it needs three copies.
[00:16:05.900 --> 00:16:10.820]   E, envelope protein, that acts as a pentamer,
[00:16:10.820 --> 00:16:14.420]   so it needs five copies to act properly.
[00:16:14.420 --> 00:16:17.940]   M is a membrane protein.
[00:16:17.940 --> 00:16:21.700]   It forms dimers, and actually it forms beautiful lattice.
[00:16:21.700 --> 00:16:23.540]   And this is something that we've been studying
[00:16:23.540 --> 00:16:25.700]   and we are seeing it in simulations.
[00:16:25.700 --> 00:16:29.660]   It actually forms a very nice grid or, you know,
[00:16:29.660 --> 00:16:33.740]   threads, you know, of different dimers
[00:16:33.740 --> 00:16:34.580]   attached next to each other.
[00:16:34.580 --> 00:16:36.260]   - Just a bunch of copies of each other,
[00:16:36.260 --> 00:16:38.300]   and they naturally, when you have a bunch of copies
[00:16:38.300 --> 00:16:40.220]   of each other, they form an interesting lattice.
[00:16:40.220 --> 00:16:41.060]   - Exactly.
[00:16:41.060 --> 00:16:43.540]   And, you know, if you think about this, right,
[00:16:43.540 --> 00:16:48.540]   so this complex, you know, the viral shape
[00:16:49.500 --> 00:16:53.060]   needs to be organized somehow, self-organized somehow.
[00:16:53.060 --> 00:16:53.900]   Right?
[00:16:53.900 --> 00:16:57.940]   So, you know, if it was a completely random process,
[00:16:57.940 --> 00:17:02.100]   you know, you probably wouldn't have the envelope shell
[00:17:02.100 --> 00:17:03.740]   of the ellipsoid shape.
[00:17:03.740 --> 00:17:05.900]   You know, you would have something, you know,
[00:17:05.900 --> 00:17:07.620]   pre-random, right, shape.
[00:17:07.620 --> 00:17:10.580]   So there is some, you know, regularity
[00:17:10.580 --> 00:17:15.580]   in how this, you know, how these dimers
[00:17:16.740 --> 00:17:20.540]   get attached to each other in a very specific, directed way.
[00:17:20.540 --> 00:17:21.940]   - Is that understood at all?
[00:17:21.940 --> 00:17:24.300]   - It's not understood.
[00:17:24.300 --> 00:17:28.420]   We are now, we've been working in the past six months
[00:17:28.420 --> 00:17:29.860]   since, you know, we met.
[00:17:29.860 --> 00:17:32.140]   Actually, this is where we started working
[00:17:32.140 --> 00:17:35.020]   on trying to understand the overall structure
[00:17:35.020 --> 00:17:38.180]   of the envelope and the key components
[00:17:38.180 --> 00:17:41.100]   that made up this, you know, structure.
[00:17:41.100 --> 00:17:42.300]   - Wait, does the envelope also have
[00:17:42.300 --> 00:17:43.580]   the lattice structure or no?
[00:17:43.580 --> 00:17:47.380]   - So the envelope is essentially is the outer shell
[00:17:47.380 --> 00:17:48.820]   of the viral particle.
[00:17:48.820 --> 00:17:51.620]   The N, the nucleocapsid protein,
[00:17:51.620 --> 00:17:54.020]   is something that is inside.
[00:17:54.020 --> 00:17:54.860]   - Got it.
[00:17:54.860 --> 00:17:59.500]   - But get that, the N is likely to interact with M.
[00:17:59.500 --> 00:18:01.460]   - Does it go M and E?
[00:18:01.460 --> 00:18:02.620]   Like, where's the E in--
[00:18:02.620 --> 00:18:05.660]   - So E, those different proteins,
[00:18:05.660 --> 00:18:10.660]   they occur in different copies on the viral particle.
[00:18:10.820 --> 00:18:13.980]   So E, this pentamer complex,
[00:18:13.980 --> 00:18:18.980]   we only have two or three maybe per each particle.
[00:18:18.980 --> 00:18:20.020]   - Mm-hmm. - Okay?
[00:18:20.020 --> 00:18:24.540]   We have thousand or so of M dimers
[00:18:24.540 --> 00:18:26.580]   that essentially made up,
[00:18:26.580 --> 00:18:30.940]   that makes up the entire, you know, outer shell.
[00:18:30.940 --> 00:18:33.700]   - So most of the outer shell is the M--
[00:18:33.700 --> 00:18:34.540]   - M dimer.
[00:18:34.540 --> 00:18:35.640]   - It's the M protein. - And lipids.
[00:18:35.640 --> 00:18:38.180]   - When you say particle, that's the viron,
[00:18:38.180 --> 00:18:40.100]   the virates, the individual virus.
[00:18:40.100 --> 00:18:41.020]   - The single, yes.
[00:18:41.020 --> 00:18:43.620]   - Single element of the virus, single virus.
[00:18:43.620 --> 00:18:45.100]   - Single virus, right.
[00:18:45.100 --> 00:18:47.100]   And we have about, you know,
[00:18:47.100 --> 00:18:51.100]   roughly 50 to 90 spike trimers, right?
[00:18:51.100 --> 00:18:53.460]   So when you, you know, when you show a--
[00:18:53.460 --> 00:18:55.020]   - Per virus particle.
[00:18:55.020 --> 00:18:56.540]   - Per virus particle.
[00:18:56.540 --> 00:18:58.660]   - Sorry, what did you say, 50 to 90?
[00:18:58.660 --> 00:19:00.700]   - 50 to 90, right? - Cool.
[00:19:00.700 --> 00:19:03.980]   - So this is how this thing is organized.
[00:19:03.980 --> 00:19:06.380]   And so now, typically, right,
[00:19:06.380 --> 00:19:11.380]   so you see these, the antibodies that target,
[00:19:11.380 --> 00:19:15.180]   you know, spike protein, certain parts of the spike protein,
[00:19:15.180 --> 00:19:17.940]   but there could be some, also some treatments, right?
[00:19:17.940 --> 00:19:21.980]   So these are, you know, these are small molecules
[00:19:21.980 --> 00:19:26.980]   that bind strategic parts of these proteins,
[00:19:26.980 --> 00:19:29.660]   disrupting its functioning.
[00:19:29.660 --> 00:19:34.060]   So one of the promising directions,
[00:19:34.060 --> 00:19:35.620]   it's one of the newest directions,
[00:19:35.620 --> 00:19:40.620]   is actually targeting the M-dimer of the protein,
[00:19:40.620 --> 00:19:44.260]   targeting the proteins that make up this outer shell.
[00:19:44.260 --> 00:19:47.740]   Because if you're able to destroy the outer shell,
[00:19:47.740 --> 00:19:52.260]   you're essentially destroying the viral particle itself.
[00:19:52.260 --> 00:19:56.820]   So preventing it from, you know, functioning at all.
[00:19:56.820 --> 00:19:59.260]   - So that's, you think, is,
[00:19:59.260 --> 00:20:01.540]   from a sort of cybersecurity perspective,
[00:20:01.540 --> 00:20:03.060]   virus security perspective,
[00:20:03.060 --> 00:20:05.260]   that's the best attack vector?
[00:20:05.260 --> 00:20:08.540]   Is, or like, that's a promising attack vector?
[00:20:08.540 --> 00:20:09.380]   - I would say, yeah.
[00:20:09.380 --> 00:20:12.700]   So I mean, there's still tons of research needs to be,
[00:20:12.700 --> 00:20:14.020]   you know, to be done.
[00:20:14.020 --> 00:20:16.580]   But yes, I think, you know, so--
[00:20:16.580 --> 00:20:18.900]   - There's more attack surface, I guess.
[00:20:18.900 --> 00:20:20.460]   - More attack surface, but, you know,
[00:20:20.460 --> 00:20:24.180]   from our analysis, from other evolutionary analysis,
[00:20:24.180 --> 00:20:27.980]   this protein is evolutionarily more stable
[00:20:27.980 --> 00:20:31.220]   compared to the, say, to the spike protein.
[00:20:31.220 --> 00:20:35.500]   - Oh, and stable means a more static target?
[00:20:35.500 --> 00:20:36.340]   - Well, yeah.
[00:20:36.340 --> 00:20:39.980]   So it doesn't change, it doesn't evolve
[00:20:39.980 --> 00:20:43.460]   from the evolutionary perspective so drastically
[00:20:43.460 --> 00:20:46.020]   as, for example, the spike protein.
[00:20:46.020 --> 00:20:47.940]   - There's a bunch of stuff in the news
[00:20:47.940 --> 00:20:51.420]   about mutations of the virus in the United Kingdom.
[00:20:51.420 --> 00:20:54.180]   I also saw in South Africa something,
[00:20:54.180 --> 00:20:55.460]   maybe that was yesterday.
[00:20:55.460 --> 00:21:00.180]   You just kind of mentioned about stability and so on.
[00:21:00.180 --> 00:21:02.780]   Which aspects of this are mutatable
[00:21:02.780 --> 00:21:07.580]   and which aspects, if mutated, become more dangerous?
[00:21:07.580 --> 00:21:09.260]   And maybe even zooming out,
[00:21:09.260 --> 00:21:12.060]   what are your thoughts and knowledge and ideas
[00:21:12.060 --> 00:21:13.660]   about the way it's mutated,
[00:21:13.660 --> 00:21:15.340]   all the news that we've been hearing?
[00:21:15.340 --> 00:21:18.460]   Are you worried about it from a biological perspective?
[00:21:18.460 --> 00:21:21.260]   Are you worried about it from a human perspective?
[00:21:21.260 --> 00:21:26.260]   - So I mean, you know, mutations are sort of a general way
[00:21:26.260 --> 00:21:28.620]   for these viruses to evolve, right?
[00:21:28.620 --> 00:21:33.620]   So it's essentially, this is the way they evolve.
[00:21:33.620 --> 00:21:38.660]   This is the way they were able to jump
[00:21:38.660 --> 00:21:42.060]   from one species to another.
[00:21:42.060 --> 00:21:46.780]   We also see some recent jumps.
[00:21:46.780 --> 00:21:49.540]   There were some incidents of this virus
[00:21:49.540 --> 00:21:51.860]   jumping from human to dogs.
[00:21:51.860 --> 00:21:55.860]   So there is some danger in those jumps
[00:21:55.860 --> 00:21:59.460]   because every time it jumps, it also mutates, right?
[00:21:59.460 --> 00:22:04.460]   So when it jumps to the species and jumps back,
[00:22:04.460 --> 00:22:09.940]   so it acquires some mutations that are sort of driven
[00:22:09.940 --> 00:22:16.300]   by the environment of a new host, right?
[00:22:16.300 --> 00:22:19.220]   And it's different from the human environment.
[00:22:19.220 --> 00:22:21.420]   And so we don't know whether the mutations
[00:22:21.420 --> 00:22:26.180]   that are acquired in the new species are neutral
[00:22:26.180 --> 00:22:31.180]   with respect to the human host or maybe damaging.
[00:22:31.180 --> 00:22:33.620]   - Yeah, change is always scary.
[00:22:33.620 --> 00:22:37.460]   But so are you worried about, I mean, it seems like
[00:22:37.460 --> 00:22:40.380]   because the spread is during winter now
[00:22:40.380 --> 00:22:42.280]   seems to be exceptionally high,
[00:22:42.280 --> 00:22:46.780]   and especially with a vaccine just around the corner
[00:22:46.780 --> 00:22:49.140]   already being actually deployed,
[00:22:49.140 --> 00:22:53.020]   is there some worry that this puts evolutionary pressure,
[00:22:53.020 --> 00:22:58.020]   selective pressure on the virus for it to mutate?
[00:22:58.020 --> 00:23:00.420]   Is that a source of worry? - Yes.
[00:23:00.420 --> 00:23:02.660]   Well, I mean, there is always this thought
[00:23:02.660 --> 00:23:07.660]   in the scientist's mind, what will happen, right?
[00:23:07.660 --> 00:23:12.500]   So I know there've been discussions
[00:23:12.500 --> 00:23:17.500]   about sort of the arms race between the ability
[00:23:17.580 --> 00:23:22.580]   of the humanity to get vaccinated faster
[00:23:22.580 --> 00:23:30.940]   than the virus essentially becomes resistant to the vaccine.
[00:23:30.940 --> 00:23:41.740]   I mean, I don't worry that much
[00:23:41.740 --> 00:23:46.740]   simply because there is not that much evidence to that.
[00:23:47.500 --> 00:23:50.020]   - To aggressive mutation around a vaccine.
[00:23:50.020 --> 00:23:51.140]   - Exactly.
[00:23:51.140 --> 00:23:54.860]   Obviously there are mutations around the vaccine.
[00:23:54.860 --> 00:23:59.860]   So the reason we get vaccinated every year
[00:23:59.860 --> 00:24:02.740]   against the season of flu. - Because there's mutations.
[00:24:02.740 --> 00:24:08.860]   - But I think it's important to study it, no doubts.
[00:24:08.860 --> 00:24:14.660]   So I think one of the, to me, and again, I might be biased
[00:24:15.220 --> 00:24:20.220]   because we've been trying to do that as well.
[00:24:20.220 --> 00:24:22.900]   But one of the critical directions
[00:24:22.900 --> 00:24:26.580]   in understanding the virus is to understand its evolution
[00:24:26.580 --> 00:24:30.220]   in order to sort of understand the mechanisms,
[00:24:30.220 --> 00:24:34.140]   the key mechanisms that lead the virus to jump,
[00:24:34.140 --> 00:24:38.660]   the Nordic viruses to jump from species to another,
[00:24:38.660 --> 00:24:41.700]   that the mechanisms that lead the virus
[00:24:41.700 --> 00:24:46.700]   to become resistant to vaccines, also to treatments.
[00:24:46.700 --> 00:24:47.780]   Right?
[00:24:47.780 --> 00:24:51.500]   And hopefully that knowledge will enable us
[00:24:51.500 --> 00:24:55.500]   to sort of forecast the evolutionary traces,
[00:24:55.500 --> 00:24:58.100]   the future evolutionary traces of this virus.
[00:24:58.100 --> 00:25:00.980]   - I mean, what, from a biological perspective,
[00:25:00.980 --> 00:25:02.180]   this might be a dumb question,
[00:25:02.180 --> 00:25:07.180]   but is there parts of the virus that if souped up
[00:25:07.940 --> 00:25:11.780]   through mutation could make it more effective
[00:25:11.780 --> 00:25:12.620]   at doing its job?
[00:25:12.620 --> 00:25:15.700]   We're talking about this specific coronavirus.
[00:25:15.700 --> 00:25:16.860]   'Cause we were talking about the different,
[00:25:16.860 --> 00:25:20.900]   like the membrane, the M protein, the E protein,
[00:25:20.900 --> 00:25:25.540]   the N and the S, the spike.
[00:25:25.540 --> 00:25:28.940]   Is there some-- - And 20 or so more
[00:25:28.940 --> 00:25:30.260]   in addition to that.
[00:25:30.260 --> 00:25:32.300]   - But is that a dumb way to look at it?
[00:25:32.300 --> 00:25:37.300]   Like which of these, if mutated, could,
[00:25:38.140 --> 00:25:42.020]   have the greatest impact, potentially damaging impact
[00:25:42.020 --> 00:25:43.460]   on the effectiveness of the virus?
[00:25:43.460 --> 00:25:46.580]   - So it's actually, it's a very good question.
[00:25:46.580 --> 00:25:50.140]   Because, and the short answer is we don't know yet.
[00:25:50.140 --> 00:25:53.500]   But of course there is capacity of this virus
[00:25:53.500 --> 00:25:55.560]   to become more efficient.
[00:25:55.560 --> 00:25:58.700]   The reason for that is, you know,
[00:25:58.700 --> 00:26:01.820]   so if you look at the virus, I mean, it's a machine, right?
[00:26:01.820 --> 00:26:05.500]   So it's a machine that does a lot of different functions.
[00:26:05.500 --> 00:26:08.500]   And many of these functions are sort of nearly perfect,
[00:26:08.500 --> 00:26:09.820]   but they are not perfect.
[00:26:09.820 --> 00:26:14.100]   And those mutations can make those functions more perfect.
[00:26:14.100 --> 00:26:18.220]   For example, the attachment to ACE2 receptor, right?
[00:26:18.220 --> 00:26:19.380]   Of the spike, right?
[00:26:19.380 --> 00:26:23.540]   So, you know, is it,
[00:26:23.540 --> 00:26:28.340]   has this virus reached the efficiency
[00:26:28.340 --> 00:26:31.540]   in which the attachment is carried out?
[00:26:31.540 --> 00:26:33.340]   Or there are some mutations that,
[00:26:34.140 --> 00:26:36.300]   that still to be discovered, right?
[00:26:36.300 --> 00:26:41.300]   That will make this attachment sort of stronger,
[00:26:41.300 --> 00:26:46.900]   or, you know, something more, in a way more efficient
[00:26:46.900 --> 00:26:51.880]   from the point of view of this virus functioning.
[00:26:51.880 --> 00:26:54.660]   That's sort of the obvious example.
[00:26:54.660 --> 00:26:57.500]   But if you look at each of these proteins,
[00:26:57.500 --> 00:26:58.820]   I mean, it's there for a reason.
[00:26:58.820 --> 00:27:00.780]   It performs certain function.
[00:27:00.780 --> 00:27:05.580]   And it could be that certain mutations
[00:27:05.580 --> 00:27:08.500]   will, you know, enhance this function.
[00:27:08.500 --> 00:27:09.900]   It could be that some mutations
[00:27:09.900 --> 00:27:13.700]   will make this function much less efficient.
[00:27:13.700 --> 00:27:15.360]   So that's also the case.
[00:27:15.360 --> 00:27:17.820]   - Let's, since we're talking about
[00:27:17.820 --> 00:27:20.420]   the evolutionary history of a virus,
[00:27:20.420 --> 00:27:25.220]   let's zoom back out and look at the evolution of proteins.
[00:27:25.220 --> 00:27:29.980]   I glanced at this 2010 Nature paper
[00:27:29.980 --> 00:27:34.340]   on the, quote, "Ongoing expansion of the protein universe."
[00:27:34.340 --> 00:27:37.380]   And then, you know, it kind of implies
[00:27:37.380 --> 00:27:41.340]   and talks about that proteins started
[00:27:41.340 --> 00:27:43.600]   with a common ancestor, which is, you know,
[00:27:43.600 --> 00:27:44.700]   kind of interesting.
[00:27:44.700 --> 00:27:45.940]   It's interesting to think about, like,
[00:27:45.940 --> 00:27:49.740]   even just like the first organic thing
[00:27:49.740 --> 00:27:51.860]   that started life on Earth.
[00:27:51.860 --> 00:27:55.980]   And from that, there's now, you know, what is it?
[00:27:55.980 --> 00:27:59.900]   3.5 billion years later, there's now millions of proteins.
[00:27:59.900 --> 00:28:01.300]   And they're still evolving.
[00:28:01.300 --> 00:28:02.980]   And that's, you know, in part,
[00:28:02.980 --> 00:28:04.980]   one of the things that you're researching.
[00:28:04.980 --> 00:28:06.820]   Is there something interesting to you
[00:28:06.820 --> 00:28:09.880]   about the evolution of proteins
[00:28:09.880 --> 00:28:14.620]   from this initial ancestor to today?
[00:28:14.620 --> 00:28:15.660]   Is there something beautiful,
[00:28:15.660 --> 00:28:18.120]   insightful about this long story?
[00:28:18.120 --> 00:28:23.120]   - So I think, you know, if I were to pick a single keyword
[00:28:23.120 --> 00:28:29.100]   about protein evolution, I would pick modularity,
[00:28:29.340 --> 00:28:32.940]   something that we talked about in the beginning.
[00:28:32.940 --> 00:28:36.260]   And that's the fact that the proteins
[00:28:36.260 --> 00:28:39.260]   are no longer considered as, you know,
[00:28:39.260 --> 00:28:41.480]   as a sequence of letters.
[00:28:41.480 --> 00:28:46.060]   There are hierarchical complexities
[00:28:46.060 --> 00:28:48.420]   in the way these proteins are organized.
[00:28:48.420 --> 00:28:51.940]   And these complexities are actually going
[00:28:51.940 --> 00:28:54.140]   beyond the protein sequence.
[00:28:54.140 --> 00:28:57.940]   It's actually going all the way back to the gene,
[00:28:57.940 --> 00:29:00.180]   to the nucleotide sequence.
[00:29:00.180 --> 00:29:05.040]   And so, you know, again, these protein domains,
[00:29:05.040 --> 00:29:08.060]   they are not only functional building blocks.
[00:29:08.060 --> 00:29:10.140]   They're also evolutionary building blocks.
[00:29:10.140 --> 00:29:12.780]   And so what we see in the sort of,
[00:29:12.780 --> 00:29:15.300]   in the later stages of evolution,
[00:29:15.300 --> 00:29:18.940]   I mean, once this stable, structurally
[00:29:18.940 --> 00:29:22.220]   and functionally building blocks were discovered,
[00:29:22.220 --> 00:29:27.220]   they essentially, they stay, those domains stay as such.
[00:29:28.220 --> 00:29:31.760]   So that's why if you start comparing different proteins,
[00:29:31.760 --> 00:29:36.760]   you will see that many of them will have similar fragments.
[00:29:36.760 --> 00:29:39.820]   And those fragments will correspond to something
[00:29:39.820 --> 00:29:42.460]   that we call protein domain families.
[00:29:42.460 --> 00:29:44.220]   And so they are still different
[00:29:44.220 --> 00:29:48.220]   because you still have mutations and, you know,
[00:29:48.220 --> 00:29:54.460]   different mutations are attributed to, you know,
[00:29:54.460 --> 00:29:57.820]   diversification of the function of this, you know,
[00:29:57.820 --> 00:29:59.020]   protein domains.
[00:29:59.020 --> 00:30:03.700]   However, you don't, you very rarely see, you know,
[00:30:03.700 --> 00:30:07.980]   the evolutionary events that would split
[00:30:07.980 --> 00:30:12.160]   this domain into fragments because, and it's, you know,
[00:30:12.160 --> 00:30:18.180]   once you have the domain split, you actually,
[00:30:18.180 --> 00:30:23.220]   you know, you can completely cancel out its function
[00:30:23.980 --> 00:30:26.580]   or at the very least you can reduce it.
[00:30:26.580 --> 00:30:29.620]   And that's not, you know, efficient from the point of view
[00:30:29.620 --> 00:30:32.860]   of the, you know, of the cell functioning.
[00:30:32.860 --> 00:30:37.860]   So the protein domain level is a very important one.
[00:30:37.860 --> 00:30:42.020]   Now, on top of that, right?
[00:30:42.020 --> 00:30:44.100]   So if you look at the proteins, right?
[00:30:44.100 --> 00:30:46.340]   So you have this structural units
[00:30:46.340 --> 00:30:48.200]   and they carry out the function.
[00:30:48.200 --> 00:30:51.880]   But then much less is known about things
[00:30:51.880 --> 00:30:54.400]   that connect this protein domains.
[00:30:54.400 --> 00:30:56.380]   Something that we call linkers.
[00:30:56.380 --> 00:31:00.780]   And those linkers are completely flexible, you know,
[00:31:00.780 --> 00:31:03.540]   parts of the protein that nevertheless
[00:31:03.540 --> 00:31:06.380]   carry out a lot of function.
[00:31:06.380 --> 00:31:08.060]   - It's like little tails, little heads.
[00:31:08.060 --> 00:31:11.100]   - So we do have tails, so they're called termini,
[00:31:11.100 --> 00:31:12.340]   C and N termini.
[00:31:12.340 --> 00:31:14.060]   So these are things right on the,
[00:31:14.060 --> 00:31:19.060]   on one and another ends of the protein sequence.
[00:31:20.060 --> 00:31:22.560]   So they are also very important.
[00:31:22.560 --> 00:31:26.320]   So they attributed to very specific interactions
[00:31:26.320 --> 00:31:27.720]   between the proteins.
[00:31:27.720 --> 00:31:28.560]   So-
[00:31:28.560 --> 00:31:30.800]   - But you're referring to the links between domains.
[00:31:30.800 --> 00:31:32.600]   - That connect the domains.
[00:31:32.600 --> 00:31:35.120]   And, you know, apart from the,
[00:31:35.120 --> 00:31:38.440]   just the simple perspective,
[00:31:38.440 --> 00:31:41.200]   if you have, you know, a very short domain,
[00:31:41.200 --> 00:31:43.720]   you have, sorry, a very short linker,
[00:31:43.720 --> 00:31:45.880]   you have two domains next to each other.
[00:31:45.880 --> 00:31:47.560]   They are forced to be next to each other.
[00:31:47.560 --> 00:31:49.060]   If you have a very long one,
[00:31:49.060 --> 00:31:52.080]   you have the domains that are extremely flexible
[00:31:52.080 --> 00:31:54.320]   and they carry out a lot of sort of
[00:31:54.320 --> 00:31:56.880]   spatial reorganization, right?
[00:31:56.880 --> 00:31:58.120]   - That's awesome.
[00:31:58.120 --> 00:31:59.640]   - But on top of that, right,
[00:31:59.640 --> 00:32:03.760]   just this linker itself, because it's so flexible,
[00:32:03.760 --> 00:32:07.480]   it actually can adapt to a lot of different shapes.
[00:32:07.480 --> 00:32:11.080]   And therefore it's a very good interactor
[00:32:11.080 --> 00:32:13.180]   when it comes to interaction between
[00:32:13.180 --> 00:32:15.520]   this protein and other protein.
[00:32:15.520 --> 00:32:18.920]   All right, so these things also evolve, you know,
[00:32:18.920 --> 00:32:23.920]   and they in a way have different sort of laws of,
[00:32:23.920 --> 00:32:30.500]   the driving laws that underlie the evolution,
[00:32:30.500 --> 00:32:35.580]   because they no longer need to preserve certain structure,
[00:32:35.580 --> 00:32:38.860]   right, unlike protein domains.
[00:32:38.860 --> 00:32:41.500]   And so on top of that,
[00:32:41.500 --> 00:32:45.860]   you have something that is even less studied.
[00:32:45.860 --> 00:32:49.360]   And this is something that attribute
[00:32:49.360 --> 00:32:53.260]   to the concept of alternative splicing.
[00:32:53.260 --> 00:32:56.940]   So alternative splicing, so it's a very cool concept.
[00:32:56.940 --> 00:33:00.400]   It's something that we've been fascinated about
[00:33:00.400 --> 00:33:03.520]   for over a decade in my lab
[00:33:03.520 --> 00:33:05.520]   and trying to do research with that.
[00:33:05.520 --> 00:33:08.100]   But so, you know, so typically, you know,
[00:33:08.100 --> 00:33:11.600]   a simplistic perspective is that
[00:33:11.600 --> 00:33:15.840]   one gene is equal one protein product.
[00:33:15.840 --> 00:33:18.340]   Right, so you have a gene, you know,
[00:33:18.340 --> 00:33:21.140]   you transcribe it and translate it,
[00:33:21.140 --> 00:33:22.900]   and it becomes a protein.
[00:33:22.900 --> 00:33:28.380]   In reality, when we talk about eukaryotes,
[00:33:28.380 --> 00:33:32.320]   especially sort of more recent eukaryotes
[00:33:32.320 --> 00:33:33.820]   that are very complex,
[00:33:33.820 --> 00:33:39.900]   the gene is no longer equal to one protein.
[00:33:41.100 --> 00:33:46.100]   It actually can produce multiple
[00:33:46.100 --> 00:33:51.220]   functionally, you know, active protein products.
[00:33:51.220 --> 00:33:53.480]   And each of them is, you know,
[00:33:53.480 --> 00:33:57.920]   is called an alternatively spliced product.
[00:33:57.920 --> 00:34:01.840]   The reason it happens is that if you look at the gene,
[00:34:01.840 --> 00:34:05.580]   it actually has, it has also blocks.
[00:34:05.580 --> 00:34:08.300]   And the blocks, some of which,
[00:34:08.300 --> 00:34:10.680]   and it's essentially, it goes like this.
[00:34:10.680 --> 00:34:13.860]   So we have a block that will later be translated,
[00:34:13.860 --> 00:34:15.060]   we call it exon.
[00:34:15.060 --> 00:34:19.220]   Then we'll have a block that is not translated, cut out.
[00:34:19.220 --> 00:34:20.400]   We call it intron.
[00:34:20.400 --> 00:34:22.840]   So we have exon, intron, exon, intron,
[00:34:22.840 --> 00:34:24.140]   et cetera, et cetera, et cetera, right?
[00:34:24.140 --> 00:34:26.900]   So sometimes you can have, you know,
[00:34:26.900 --> 00:34:29.860]   dozens of these exons and introns.
[00:34:29.860 --> 00:34:32.660]   So what happens is during the process
[00:34:32.660 --> 00:34:35.780]   when the gene is converted to RNA,
[00:34:37.320 --> 00:34:41.260]   we have things that are cut out,
[00:34:41.260 --> 00:34:43.220]   the introns that cut out,
[00:34:43.220 --> 00:34:47.180]   and exons that now get assembled together.
[00:34:47.180 --> 00:34:51.400]   And sometimes we will throw out some of the exons.
[00:34:51.400 --> 00:34:54.620]   And the remaining protein product will become--
[00:34:54.620 --> 00:34:55.620]   - Still be the same.
[00:34:55.620 --> 00:34:56.540]   - Different. - Oh, different.
[00:34:56.540 --> 00:34:59.980]   - Right, so now you have fragments of the protein
[00:34:59.980 --> 00:35:01.360]   that no longer there.
[00:35:01.360 --> 00:35:03.820]   They were cut out with the introns.
[00:35:03.820 --> 00:35:07.560]   Sometimes you will essentially take one exon
[00:35:07.560 --> 00:35:09.840]   and replace it with another one, right?
[00:35:09.840 --> 00:35:12.640]   - So there's some flexibility in this process.
[00:35:12.640 --> 00:35:17.200]   - So that creates a whole new level of complexity.
[00:35:17.200 --> 00:35:18.680]   'Cause now-- - Is this random though?
[00:35:18.680 --> 00:35:19.680]   Is it random?
[00:35:19.680 --> 00:35:20.880]   - It's not random.
[00:35:20.880 --> 00:35:24.520]   We, and this is where I think now the appearance
[00:35:24.520 --> 00:35:27.380]   of this modern single cell,
[00:35:27.380 --> 00:35:31.280]   and before that tissue level sequencing,
[00:35:31.280 --> 00:35:34.300]   next generation sequencing techniques such as RNA-Seq,
[00:35:34.300 --> 00:35:38.220]   allows us to see that these are the events
[00:35:38.220 --> 00:35:41.300]   that often happen in response.
[00:35:41.300 --> 00:35:45.680]   It's a dynamic event that happens in response to disease,
[00:35:45.680 --> 00:35:51.980]   or in response to certain developmental stage of a cell.
[00:35:51.980 --> 00:35:56.820]   And this is an incredibly complex layer
[00:35:56.820 --> 00:35:59.820]   that also undergoes, I mean,
[00:35:59.820 --> 00:36:01.560]   because it's at the gene level, right?
[00:36:01.560 --> 00:36:05.420]   So it undergoes certain evolution, right?
[00:36:05.420 --> 00:36:10.060]   And now we have this interplay between what happening,
[00:36:10.060 --> 00:36:12.740]   what is happening in the protein world,
[00:36:12.740 --> 00:36:17.740]   and what is happening in the gene and RNA world.
[00:36:17.740 --> 00:36:22.720]   And for example, it's often that we see
[00:36:22.720 --> 00:36:26.420]   that the boundaries of these exons
[00:36:27.600 --> 00:36:30.360]   coincide with the boundaries of the protein domains.
[00:36:30.360 --> 00:36:36.520]   Right, so there is this close interplay to that.
[00:36:36.520 --> 00:36:37.960]   It's not always, I mean,
[00:36:37.960 --> 00:36:39.800]   otherwise it would be too simple, right?
[00:36:39.800 --> 00:36:41.880]   But we do see the connection
[00:36:41.880 --> 00:36:45.000]   between those sort of machineries.
[00:36:45.000 --> 00:36:49.760]   And obviously the evolution will pick up this complexity
[00:36:49.760 --> 00:36:52.880]   and-- - Select for whatever
[00:36:52.880 --> 00:36:55.040]   is successful, whatever is functioning.
[00:36:55.040 --> 00:36:57.560]   - We see that complexity in play.
[00:36:57.560 --> 00:37:02.280]   And makes this question more complex, but more exciting.
[00:37:02.280 --> 00:37:05.200]   - As a small detour, I don't know if you think about this
[00:37:05.200 --> 00:37:07.520]   in into the world of computer science,
[00:37:07.520 --> 00:37:11.240]   there's a Douglas Hostetter, I think,
[00:37:11.240 --> 00:37:14.360]   came up with a name of Quine,
[00:37:14.360 --> 00:37:16.740]   which are, I don't know if you're familiar with these things,
[00:37:16.740 --> 00:37:20.240]   but it's computer programs that have,
[00:37:20.240 --> 00:37:23.300]   I guess, exon and intron, and they copy,
[00:37:23.300 --> 00:37:26.240]   the whole purpose of the program is to copy itself.
[00:37:26.240 --> 00:37:28.480]   So it prints copies of itself,
[00:37:28.480 --> 00:37:31.000]   but can also carry information inside of it.
[00:37:31.000 --> 00:37:35.440]   That's a very kind of crude, fun exercise of,
[00:37:35.440 --> 00:37:40.000]   can we sort of replicate these ideas from cells,
[00:37:40.000 --> 00:37:42.960]   can we have a computer program that when you run it,
[00:37:42.960 --> 00:37:47.080]   just prints itself, the entirety of itself,
[00:37:47.080 --> 00:37:50.040]   and does it in different programming languages and so on.
[00:37:50.040 --> 00:37:51.960]   I've been playing around and writing them.
[00:37:51.960 --> 00:37:53.720]   It's a kind of fun little exercise.
[00:37:53.720 --> 00:37:54.920]   - You know, when I was a kid,
[00:37:54.920 --> 00:37:59.920]   so it was essentially one of the sort of main stages
[00:37:59.920 --> 00:38:07.880]   in informatics Olympiads that you have to reach
[00:38:07.880 --> 00:38:10.880]   in order to be any so good,
[00:38:10.880 --> 00:38:14.400]   is you should be able to write a program
[00:38:14.400 --> 00:38:16.680]   that replicates itself.
[00:38:16.680 --> 00:38:20.920]   And so the task then becomes even sort of more complicated.
[00:38:20.920 --> 00:38:24.040]   So what is the shortest program?
[00:38:24.040 --> 00:38:27.480]   And of course it's a function of a programming language,
[00:38:27.480 --> 00:38:30.920]   but yeah, I remember a long, long, long time ago
[00:38:30.920 --> 00:38:34.840]   when we tried to make it short and short
[00:38:34.840 --> 00:38:36.560]   and find the shortcuts.
[00:38:36.560 --> 00:38:38.640]   - There's actually on Stack Exchange,
[00:38:38.640 --> 00:38:43.640]   there's an entire site called Code Golf, I think,
[00:38:43.640 --> 00:38:46.520]   where the entirety is just the competition.
[00:38:46.520 --> 00:38:48.680]   People just come up with whatever task.
[00:38:48.680 --> 00:38:51.680]   I don't know, like write code
[00:38:51.680 --> 00:38:54.640]   that reports the weather today.
[00:38:54.640 --> 00:38:57.280]   And the competition is about,
[00:38:57.280 --> 00:38:58.640]   in whatever programming language,
[00:38:58.640 --> 00:39:00.440]   what is the shortest program?
[00:39:00.440 --> 00:39:02.240]   And it makes you actually, people should check it out
[00:39:02.240 --> 00:39:03.600]   because it makes you realize
[00:39:03.600 --> 00:39:07.160]   there's some weird programming languages out there.
[00:39:07.160 --> 00:39:11.720]   But just to dig on that a little deeper,
[00:39:11.720 --> 00:39:16.080]   do you think, in computer science,
[00:39:16.080 --> 00:39:19.280]   we don't often think about programs.
[00:39:19.280 --> 00:39:21.320]   Just like the machine learning world now,
[00:39:21.320 --> 00:39:26.320]   that's still kind of basic programs.
[00:39:26.320 --> 00:39:29.640]   And then there's humans that replicate themselves, right?
[00:39:29.640 --> 00:39:31.560]   And there's these mutations and so on.
[00:39:31.560 --> 00:39:34.520]   Do you think we'll ever have a world
[00:39:34.520 --> 00:39:36.360]   where there's programs that kind of
[00:39:36.360 --> 00:39:40.680]   have an evolutionary process?
[00:39:40.680 --> 00:39:42.680]   So I'm not talking about evolutionary algorithms,
[00:39:42.680 --> 00:39:43.760]   but I'm talking about programs
[00:39:43.760 --> 00:39:46.520]   that kind of mate with each other and evolve
[00:39:46.520 --> 00:39:49.600]   and on their own replicate themselves.
[00:39:49.600 --> 00:39:54.600]   So this is kind of, the idea here is,
[00:39:54.600 --> 00:39:57.120]   that's how you can have a runaway thing.
[00:39:57.120 --> 00:39:59.240]   So we think about machine learning as a system
[00:39:59.240 --> 00:40:01.440]   that gets smarter and smarter and smarter and smarter.
[00:40:01.440 --> 00:40:05.640]   At least the machine learning systems of today are like,
[00:40:05.640 --> 00:40:09.120]   it's a program that you can turn off,
[00:40:09.120 --> 00:40:12.800]   as opposed to throwing a bunch of little programs out there
[00:40:12.800 --> 00:40:16.400]   and letting them multiply and mate and evolve
[00:40:16.400 --> 00:40:17.480]   and replicate.
[00:40:17.480 --> 00:40:20.560]   Do you ever think about that kind of world
[00:40:20.560 --> 00:40:23.440]   when we jump from the biological systems
[00:40:23.440 --> 00:40:27.280]   that you're looking at to artificial ones?
[00:40:27.280 --> 00:40:31.000]   - I mean, it's almost like you take
[00:40:31.000 --> 00:40:34.480]   the sort of the area of intelligent agents, right?
[00:40:34.480 --> 00:40:38.720]   Which are essentially the independent sort of codes
[00:40:38.720 --> 00:40:42.560]   that run and interact and exchange the information, right?
[00:40:42.560 --> 00:40:45.200]   So I don't see why not.
[00:40:45.200 --> 00:40:48.840]   I mean, it could be sort of a natural evolution
[00:40:48.840 --> 00:40:53.000]   in this area of computer science.
[00:40:53.000 --> 00:40:54.720]   - I think it's kind of an interesting possibility.
[00:40:54.720 --> 00:40:56.000]   It's terrifying too,
[00:40:56.000 --> 00:40:58.360]   but I think it's a really powerful tool.
[00:40:58.360 --> 00:41:00.680]   Like to have agents that,
[00:41:00.680 --> 00:41:02.800]   we have social networks with millions of people
[00:41:02.800 --> 00:41:03.840]   and they interact.
[00:41:03.840 --> 00:41:05.720]   I think it's interesting to inject into that,
[00:41:05.720 --> 00:41:08.400]   there's already injecting into that bots, right?
[00:41:08.400 --> 00:41:10.040]   But those bots are pretty dumb.
[00:41:12.520 --> 00:41:14.720]   They're probably pretty dumb algorithms.
[00:41:14.720 --> 00:41:18.640]   It's interesting to think that there might be bots
[00:41:18.640 --> 00:41:20.480]   that evolve together with humans.
[00:41:20.480 --> 00:41:23.960]   And there's the sea of humans and robots
[00:41:23.960 --> 00:41:26.520]   that are operating first in the digital space.
[00:41:26.520 --> 00:41:27.960]   And then you can also think,
[00:41:27.960 --> 00:41:29.760]   I love the idea, some people worked,
[00:41:29.760 --> 00:41:32.600]   I think at Harvard, at Penn,
[00:41:32.600 --> 00:41:37.600]   there's robotics labs that take as a fundamental task
[00:41:38.960 --> 00:41:42.360]   to build a robot that given extra resources
[00:41:42.360 --> 00:41:44.840]   can build another copy of itself,
[00:41:44.840 --> 00:41:46.520]   like in the physical space,
[00:41:46.520 --> 00:41:49.360]   which is super difficult to do,
[00:41:49.360 --> 00:41:50.840]   but super interesting.
[00:41:50.840 --> 00:41:54.000]   I remember there's like research on robots
[00:41:54.000 --> 00:41:55.200]   that can build a bridge.
[00:41:55.200 --> 00:41:56.840]   So they make a copy of themselves
[00:41:56.840 --> 00:41:57.960]   and they connect themselves.
[00:41:57.960 --> 00:42:00.520]   And so there's like self-building bridge
[00:42:00.520 --> 00:42:02.320]   based on building blocks.
[00:42:02.320 --> 00:42:05.600]   You can imagine like a building that self assembles.
[00:42:05.600 --> 00:42:07.560]   So it's basically self-assembling structures
[00:42:07.560 --> 00:42:10.640]   from robotic parts.
[00:42:10.640 --> 00:42:13.880]   But it's interesting to, within that robot,
[00:42:13.880 --> 00:42:15.480]   add the ability to mutate
[00:42:15.480 --> 00:42:21.320]   and do all the interesting little things
[00:42:21.320 --> 00:42:23.200]   that you're referring to in evolution
[00:42:23.200 --> 00:42:26.320]   to go from a single origin protein building block
[00:42:26.320 --> 00:42:28.920]   to like this weird complex--
[00:42:28.920 --> 00:42:30.320]   - And if you think about this,
[00:42:30.320 --> 00:42:34.600]   I mean, the bits and pieces are there.
[00:42:34.600 --> 00:42:37.280]   So you mentioned the evolutionary algorithm, right?
[00:42:37.280 --> 00:42:38.520]   So this is sort of,
[00:42:38.520 --> 00:42:43.520]   and maybe sort of the goal is in a way different, right?
[00:42:43.520 --> 00:42:49.840]   So the goal is to essentially to optimize your search.
[00:42:49.840 --> 00:42:53.040]   So, but sort of the ideas are there.
[00:42:53.040 --> 00:42:58.040]   So people recognize that the recombination events
[00:42:58.040 --> 00:43:03.280]   lead to global changes in the search trajectories,
[00:43:03.280 --> 00:43:08.280]   the mutations event is a more refined step in the search.
[00:43:08.280 --> 00:43:15.040]   Then you have other sort of nature inspired algorithm, right?
[00:43:15.040 --> 00:43:21.480]   So one of the reason that I think it's one of the funnest one
[00:43:21.480 --> 00:43:24.840]   is the slime based algorithm, right?
[00:43:24.840 --> 00:43:29.840]   So I think the first was introduced by the Japanese group
[00:43:30.200 --> 00:43:35.200]   where it was able to solve some pretty complex problems.
[00:43:35.200 --> 00:43:41.840]   So that's, and then I think there are still a lot of things
[00:43:41.840 --> 00:43:48.320]   we've yet to borrow from the nature, right?
[00:43:48.320 --> 00:43:52.000]   So there are a lot of sort of ideas
[00:43:52.000 --> 00:43:56.000]   that nature gets to offer us
[00:43:56.000 --> 00:43:58.360]   that it's up to us to grab it
[00:43:58.360 --> 00:44:02.160]   and to get the best use of it.
[00:44:02.160 --> 00:44:04.160]   - Including neural networks,
[00:44:04.160 --> 00:44:07.040]   that we have a very crude inspiration
[00:44:07.040 --> 00:44:08.280]   from nature on neural networks.
[00:44:08.280 --> 00:44:10.920]   Maybe there's other inspirations to be discovered
[00:44:10.920 --> 00:44:15.920]   in the brain or other aspects of the various systems,
[00:44:15.920 --> 00:44:20.160]   even like the immune system, the way it interplays.
[00:44:20.160 --> 00:44:23.560]   I recently started to understand that the immune system
[00:44:23.560 --> 00:44:26.040]   has something to do with the way the brain operates.
[00:44:26.040 --> 00:44:28.360]   Like there's multiple things going on in there,
[00:44:28.360 --> 00:44:30.520]   which all of which are not modeled
[00:44:30.520 --> 00:44:32.120]   in artificial neural networks.
[00:44:32.120 --> 00:44:33.960]   And maybe if you throw a little bit
[00:44:33.960 --> 00:44:36.240]   of that biological spice in there,
[00:44:36.240 --> 00:44:38.980]   you'll come up with something cool.
[00:44:38.980 --> 00:44:43.720]   I'm not sure if you're familiar with the Drake equation
[00:44:43.720 --> 00:44:46.720]   that estimate, I just did a video on it yesterday
[00:44:46.720 --> 00:44:49.280]   'cause I wanted to give my own estimate of it.
[00:44:49.280 --> 00:44:52.360]   It's an equation that combines a bunch of factors
[00:44:52.360 --> 00:44:55.960]   to estimate how many alien civilizations are.
[00:44:55.960 --> 00:44:58.520]   - Oh yeah, I've heard about it, yes.
[00:44:58.520 --> 00:45:01.160]   - So one of the interesting parameters,
[00:45:01.160 --> 00:45:06.000]   you know, it's like how many stars are born every year,
[00:45:06.000 --> 00:45:10.720]   how many planets are on average per star,
[00:45:10.720 --> 00:45:14.280]   for this, how many habitable planets are there.
[00:45:14.280 --> 00:45:17.560]   And then the one that starts being really interesting
[00:45:17.560 --> 00:45:23.560]   is the probability that life emerges on a habitable planet.
[00:45:24.740 --> 00:45:27.920]   So like, I don't know if you think about,
[00:45:27.920 --> 00:45:29.720]   you certainly think a lot about evolution,
[00:45:29.720 --> 00:45:31.080]   but do you think about the thing
[00:45:31.080 --> 00:45:32.520]   which evolution doesn't describe,
[00:45:32.520 --> 00:45:34.920]   which is like the beginning of evolution,
[00:45:34.920 --> 00:45:36.640]   the origin of life?
[00:45:36.640 --> 00:45:38.800]   I think I put the probability of life
[00:45:38.800 --> 00:45:41.800]   developing in a habitable planet at 1%.
[00:45:41.800 --> 00:45:44.440]   This is very scientifically rigorous.
[00:45:44.440 --> 00:45:48.760]   Okay, first at a high level for the Drake equation,
[00:45:48.760 --> 00:45:51.680]   what would you put that percent at on earth?
[00:45:51.680 --> 00:45:55.060]   And in general, do you have something,
[00:45:55.060 --> 00:45:58.180]   do you have thoughts about how life might have started?
[00:45:58.180 --> 00:46:00.660]   You know, like the proteins being the first,
[00:46:00.660 --> 00:46:02.900]   kind of one of the early jumping points?
[00:46:02.900 --> 00:46:07.460]   - Yeah, so I think back in 2018,
[00:46:07.460 --> 00:46:10.420]   there was a very exciting paper published in Nature
[00:46:10.420 --> 00:46:15.420]   where they found one of the simplest amino acids,
[00:46:18.260 --> 00:46:23.260]   glycine, in a comet dust.
[00:46:23.260 --> 00:46:28.540]   So this is, and I apologize if I don't pronounce,
[00:46:28.540 --> 00:46:32.080]   it's a Russian-named comet,
[00:46:32.080 --> 00:46:34.760]   I think Chugryumov-Gerasimenko.
[00:46:34.760 --> 00:46:39.760]   This is the comet where, and there was this mission
[00:46:39.760 --> 00:46:44.000]   to get close to this comet
[00:46:44.000 --> 00:46:48.160]   and get the star dust from its tail.
[00:46:48.160 --> 00:46:50.640]   And when scientists analyzed it,
[00:46:50.640 --> 00:46:53.640]   they actually found traces of glycine,
[00:46:53.640 --> 00:47:01.640]   which makes up, it's one of the 20 basic amino acids
[00:47:01.640 --> 00:47:06.020]   that makes up proteins.
[00:47:06.020 --> 00:47:10.960]   So that was kind of very exciting.
[00:47:10.960 --> 00:47:14.240]   But the question is very interesting.
[00:47:14.240 --> 00:47:18.560]   So what, if there is some alien life,
[00:47:18.560 --> 00:47:22.920]   is it gonna be made of proteins, right?
[00:47:22.920 --> 00:47:24.360]   There may be RNAs, right?
[00:47:24.360 --> 00:47:28.920]   So we see that the RNA viruses are certainly
[00:47:28.920 --> 00:47:35.400]   very well-established sort of group of molecular machines.
[00:47:35.400 --> 00:47:42.120]   Right, so yeah, it's a very interesting question.
[00:47:42.120 --> 00:47:43.580]   - What probability would you put,
[00:47:43.580 --> 00:47:45.280]   like how hard is this,
[00:47:45.280 --> 00:47:48.760]   like how unlikely just on Earth do you think
[00:47:48.760 --> 00:47:51.600]   this whole thing is that we got going?
[00:47:51.600 --> 00:47:54.640]   Like are we really lucky or is it inevitable?
[00:47:54.640 --> 00:47:56.240]   Like what's your sense when you sit back
[00:47:56.240 --> 00:47:58.840]   and think about life on Earth?
[00:47:58.840 --> 00:48:01.000]   Is it higher or lower than 1%?
[00:48:01.000 --> 00:48:02.320]   Well, 'cause 1% is pretty low,
[00:48:02.320 --> 00:48:05.060]   but it's still like, damn, that's a pretty good chance.
[00:48:05.060 --> 00:48:06.600]   - Yes, it's a pretty good chance.
[00:48:06.600 --> 00:48:09.260]   I mean, I would personally, but again,
[00:48:10.560 --> 00:48:15.560]   I'm probably not the best person to do such estimations,
[00:48:15.560 --> 00:48:21.660]   but I would, intuitively, I would probably put it lower.
[00:48:21.660 --> 00:48:23.940]   But still, I mean--
[00:48:23.940 --> 00:48:26.560]   - So we're really lucky here on Earth?
[00:48:26.560 --> 00:48:28.860]   - I mean--
[00:48:28.860 --> 00:48:30.500]   - Or the conditions are really good.
[00:48:30.500 --> 00:48:35.500]   - It's, I think that everything was right in a way, right?
[00:48:35.500 --> 00:48:39.740]   So still, it's not, the conditions were not like ideal
[00:48:39.740 --> 00:48:44.740]   if you try to look at what was several billions years ago
[00:48:44.740 --> 00:48:48.340]   when the life emerged.
[00:48:48.340 --> 00:48:52.060]   - So there is something called the rare Earth hypothesis
[00:48:52.060 --> 00:48:56.180]   that in counter to the Drake equation says that
[00:48:56.180 --> 00:49:00.260]   the conditions of Earth,
[00:49:00.260 --> 00:49:03.300]   if you actually were to describe Earth,
[00:49:03.300 --> 00:49:08.060]   it's quite a special place, so special it might be unique
[00:49:08.060 --> 00:49:11.780]   in our galaxy and potentially close to unique
[00:49:11.780 --> 00:49:12.860]   in the entire universe.
[00:49:12.860 --> 00:49:14.700]   Like it's very difficult to reconstruct
[00:49:14.700 --> 00:49:16.340]   those same conditions.
[00:49:16.340 --> 00:49:19.540]   And what the rare Earth hypothesis argues
[00:49:19.540 --> 00:49:23.060]   is all those different conditions are essential for life.
[00:49:23.060 --> 00:49:26.140]   And so that's sort of the counter,
[00:49:26.140 --> 00:49:27.420]   like all the things we,
[00:49:27.420 --> 00:49:31.700]   thinking that Earth is pretty average,
[00:49:31.700 --> 00:49:33.260]   I mean, I can't really,
[00:49:33.260 --> 00:49:35.380]   I'm trying to remember to go through all of them,
[00:49:35.380 --> 00:49:38.900]   but just the fact that it is shielded
[00:49:38.900 --> 00:49:41.860]   from a lot of asteroids,
[00:49:41.860 --> 00:49:43.800]   obviously the distance to the sun,
[00:49:43.800 --> 00:49:48.220]   but also the fact that it's like a perfect balance
[00:49:48.220 --> 00:49:52.180]   between the amount of water and land
[00:49:52.180 --> 00:49:53.660]   and all those kinds of things.
[00:49:53.660 --> 00:49:55.180]   I don't know, there's a bunch of different factors
[00:49:55.180 --> 00:49:57.540]   that I don't remember, there's a long list.
[00:49:57.540 --> 00:49:59.140]   But it's fascinating to think about
[00:49:59.140 --> 00:50:03.620]   if in order for something like proteins
[00:50:03.620 --> 00:50:06.580]   and then the DNA and RNA to emerge,
[00:50:06.580 --> 00:50:10.500]   you need, and basic living organisms,
[00:50:10.500 --> 00:50:14.960]   you need to be very close to an Earth-like planet,
[00:50:14.960 --> 00:50:16.600]   which would be sad.
[00:50:16.600 --> 00:50:19.740]   Or exciting, I don't know.
[00:50:19.740 --> 00:50:23.220]   - If you ask me, in a way I put a parallel
[00:50:23.220 --> 00:50:28.220]   between our own research
[00:50:28.220 --> 00:50:33.400]   and from the intuitive perspective.
[00:50:34.040 --> 00:50:36.680]   You have those two extremes,
[00:50:36.680 --> 00:50:40.400]   and the reality is never, very rarely,
[00:50:40.400 --> 00:50:41.920]   falls into the extremes.
[00:50:41.920 --> 00:50:46.160]   It's always, the optimums always reach somewhere in between.
[00:50:46.160 --> 00:50:50.040]   And that's what I tend to think.
[00:50:50.040 --> 00:50:54.040]   I think that we're probably somewhere in between,
[00:50:54.040 --> 00:50:57.000]   so they were not unique-unique,
[00:50:57.000 --> 00:51:01.960]   but again, the chances are reasonably small.
[00:51:01.960 --> 00:51:05.240]   The problem is we don't know the other extremes.
[00:51:05.240 --> 00:51:08.040]   I tend to think that we don't actually understand
[00:51:08.040 --> 00:51:13.040]   the basic mechanisms of what this is all originated from.
[00:51:13.040 --> 00:51:16.160]   It seems like we think of life as this distinct thing,
[00:51:16.160 --> 00:51:18.520]   maybe intelligence as a distinct thing,
[00:51:18.520 --> 00:51:23.120]   maybe the physics from which planets and suns are born
[00:51:23.120 --> 00:51:25.920]   is a distinct thing, but that could be a very,
[00:51:25.920 --> 00:51:28.280]   it's like the Stephen Wolfram thing.
[00:51:28.280 --> 00:51:31.020]   From simple rules emerges greater and greater complexity.
[00:51:31.020 --> 00:51:34.940]   So I tend to believe that just life finds a way.
[00:51:34.940 --> 00:51:39.560]   We don't know the extreme of how common life is,
[00:51:39.560 --> 00:51:43.660]   'cause it could be life is like everywhere.
[00:51:43.660 --> 00:51:49.440]   Like so everywhere that it's almost like laughable,
[00:51:49.440 --> 00:51:52.120]   like that we're such idiots to think we're,
[00:51:52.120 --> 00:51:56.280]   like it's ridiculous to even think,
[00:51:56.280 --> 00:51:59.460]   it's like ants thinking that their little colony
[00:51:59.460 --> 00:52:03.200]   is the unique thing and everything else doesn't exist.
[00:52:03.200 --> 00:52:07.520]   I mean, it's also very possible that that's the extreme,
[00:52:07.520 --> 00:52:09.880]   and we're just not able to maybe comprehend
[00:52:09.880 --> 00:52:12.860]   the nature of that life.
[00:52:12.860 --> 00:52:16.560]   Just to stick on alien life for just a brief moment more,
[00:52:16.560 --> 00:52:21.560]   there is some signs of life on Venus in gaseous form.
[00:52:21.560 --> 00:52:27.240]   There's hope for life on Mars, probably extinct.
[00:52:28.140 --> 00:52:30.860]   We're not talking about intelligent life.
[00:52:30.860 --> 00:52:33.820]   Although that has been in the news recently.
[00:52:33.820 --> 00:52:36.900]   We're talking about basic like bacteria.
[00:52:36.900 --> 00:52:37.740]   - Plural bacteria.
[00:52:37.740 --> 00:52:42.180]   - Yeah, and then also I guess, there's a couple moons.
[00:52:42.180 --> 00:52:43.020]   - Europa.
[00:52:43.020 --> 00:52:46.020]   - Yeah, Europa, which is Jupiter's moon.
[00:52:46.020 --> 00:52:47.460]   I think there's another one.
[00:52:47.460 --> 00:52:51.240]   Are you, is that exciting or is it terrifying to you
[00:52:51.240 --> 00:52:52.980]   that we might find life?
[00:52:52.980 --> 00:52:54.460]   Do you hope we find life?
[00:52:54.460 --> 00:52:56.800]   - I certainly do hope that we find life.
[00:52:57.940 --> 00:53:02.100]   I mean, it was very exciting to hear about this news
[00:53:02.100 --> 00:53:09.260]   about the possible life on Venus.
[00:53:09.260 --> 00:53:11.620]   - It'd be nice to have hard evidence of something
[00:53:11.620 --> 00:53:17.140]   which is what the hope is for Mars and Europa.
[00:53:17.140 --> 00:53:18.420]   But do you think those organisms
[00:53:18.420 --> 00:53:20.820]   would be similar biologically,
[00:53:20.820 --> 00:53:23.980]   or would they even be sort of carbon-based
[00:53:23.980 --> 00:53:25.760]   if we do find them?
[00:53:25.760 --> 00:53:28.940]   - I would say they would be carbon-based.
[00:53:28.940 --> 00:53:31.820]   How similar, it's a big question, right?
[00:53:31.820 --> 00:53:36.820]   So it's, the moment we discover things outside Earth,
[00:53:36.820 --> 00:53:42.400]   even if it's a tiny little single cell,
[00:53:42.400 --> 00:53:45.380]   I mean, there is so much.
[00:53:45.380 --> 00:53:47.620]   - Just imagine that, that would be so.
[00:53:47.620 --> 00:53:50.460]   - I think that that would be another turning point
[00:53:50.460 --> 00:53:52.060]   for the science.
[00:53:52.060 --> 00:53:56.200]   And if, especially if it's different in some very new way,
[00:53:56.200 --> 00:53:58.200]   that's exciting, 'cause that says,
[00:53:58.200 --> 00:54:00.480]   that's a definitive statement, not a definitive,
[00:54:00.480 --> 00:54:01.760]   but a pretty strong statement
[00:54:01.760 --> 00:54:05.440]   that life is everywhere in the universe.
[00:54:05.440 --> 00:54:07.720]   To me, at least, that's really exciting.
[00:54:07.720 --> 00:54:13.480]   You brought up Joshua Lederberg in an offline conversation.
[00:54:13.480 --> 00:54:15.800]   I think I'd love to talk to you about AlphaFold,
[00:54:15.800 --> 00:54:17.220]   and this might be an interesting way
[00:54:17.220 --> 00:54:20.400]   to enter that conversation, because,
[00:54:20.400 --> 00:54:24.520]   so he won the 1958 Nobel Prize in Physiology and Medicine
[00:54:24.520 --> 00:54:29.000]   for discovering that bacteria can mate and exchange genes,
[00:54:29.000 --> 00:54:32.200]   but he also did a ton of other stuff,
[00:54:32.200 --> 00:54:37.200]   like we mentioned, helping NASA find life on Mars,
[00:54:37.200 --> 00:54:41.840]   and the-- - Dendro.
[00:54:41.840 --> 00:54:45.260]   - Dendro, the chemical expert system,
[00:54:45.260 --> 00:54:46.900]   expert systems, remember those?
[00:54:47.920 --> 00:54:51.400]   Do you, what do you find interesting about this guy
[00:54:51.400 --> 00:54:55.000]   and his ideas about artificial intelligence in general?
[00:54:55.000 --> 00:55:00.000]   - So I have a kind of personal story to share.
[00:55:00.000 --> 00:55:05.160]   So I started my PhD in Canada back in 2000,
[00:55:05.160 --> 00:55:07.760]   and so essentially my PhD was,
[00:55:07.760 --> 00:55:10.120]   so we were developing sort of a new language
[00:55:10.120 --> 00:55:12.560]   for symbolic machine learning,
[00:55:12.560 --> 00:55:15.120]   so it's different from the feature-based machine learning,
[00:55:15.120 --> 00:55:19.840]   and one of the sort of cleanest applications
[00:55:19.840 --> 00:55:24.000]   of this approach, of this formalism,
[00:55:24.000 --> 00:55:28.600]   was to cheminformatics and computer-aided drug design.
[00:55:28.600 --> 00:55:31.360]   Right, so essentially we were,
[00:55:31.360 --> 00:55:35.680]   as a part of my research, I developed a system
[00:55:35.680 --> 00:55:40.200]   that essentially looked at chemical compounds
[00:55:40.200 --> 00:55:42.840]   of, say, the same therapeutic category,
[00:55:44.680 --> 00:55:48.600]   male hormones, right, and tried to figure out
[00:55:48.600 --> 00:55:53.160]   the structural fragments that are,
[00:55:53.160 --> 00:55:56.480]   the structural building blocks that are important,
[00:55:56.480 --> 00:55:58.840]   that define this class,
[00:55:58.840 --> 00:56:00.480]   versus structural building blocks
[00:56:00.480 --> 00:56:03.400]   that are there just because, you know,
[00:56:03.400 --> 00:56:04.960]   to complete the structure,
[00:56:04.960 --> 00:56:06.760]   but they are not essentially the ones
[00:56:06.760 --> 00:56:10.760]   that make up the key chemical properties
[00:56:10.760 --> 00:56:13.520]   of this therapeutic category.
[00:56:13.520 --> 00:56:17.520]   And, you know, for me it was something new.
[00:56:17.520 --> 00:56:20.560]   I was trained as an applied mathematician,
[00:56:20.560 --> 00:56:23.720]   you know, with some machine learning background,
[00:56:23.720 --> 00:56:25.800]   but, you know, computer-aided drug design
[00:56:25.800 --> 00:56:28.400]   was a completely new territory.
[00:56:28.400 --> 00:56:32.200]   So because of that, I often find myself
[00:56:32.200 --> 00:56:35.280]   asking lots of questions on one of the sort of
[00:56:35.280 --> 00:56:37.640]   central forums.
[00:56:37.640 --> 00:56:39.400]   Back then there were, you know,
[00:56:39.400 --> 00:56:41.080]   no Facebooks or stuff like that,
[00:56:41.080 --> 00:56:42.480]   there was-- - What's a forum?
[00:56:42.480 --> 00:56:44.400]   - It's a, you know, it's a forum,
[00:56:44.400 --> 00:56:46.360]   it's essentially it's like a bulletin board.
[00:56:46.360 --> 00:56:49.680]   - Yeah, on the internet. - Yeah, so you essentially,
[00:56:49.680 --> 00:56:52.440]   you have a bunch of people and you post a question
[00:56:52.440 --> 00:56:54.560]   and you get, you know, an answer from,
[00:56:54.560 --> 00:56:56.000]   you know, different people.
[00:56:56.000 --> 00:57:01.000]   And back then, one of the most popular forums was CCL.
[00:57:01.000 --> 00:57:05.440]   Think Computational Chemistry Library,
[00:57:05.440 --> 00:57:07.080]   not library, but something like that,
[00:57:07.080 --> 00:57:09.840]   but CCL, that was the forum.
[00:57:09.840 --> 00:57:12.800]   And there I, you know, I--
[00:57:12.800 --> 00:57:14.040]   - Asked a lot of dumb questions.
[00:57:14.040 --> 00:57:17.960]   - Yes, I asked questions, also shared some, you know,
[00:57:17.960 --> 00:57:20.600]   some information about our formalism,
[00:57:20.600 --> 00:57:25.080]   how we do and whether whatever we do makes sense.
[00:57:25.080 --> 00:57:29.160]   And so, you know, and I remember that one of these posts,
[00:57:29.160 --> 00:57:31.400]   I mean, I still remember, you know,
[00:57:31.400 --> 00:57:36.400]   I would call it desperately looking for a chemist's advice,
[00:57:39.200 --> 00:57:40.720]   something like that, right?
[00:57:40.720 --> 00:57:43.960]   And so I post my question, I explained, you know,
[00:57:43.960 --> 00:57:48.960]   how our formalism is, what it does,
[00:57:48.960 --> 00:57:53.160]   and what kind of applications I'm planning to do.
[00:57:53.160 --> 00:57:55.000]   And, you know, and it was, you know,
[00:57:55.000 --> 00:57:56.880]   in the middle of the night and, you know,
[00:57:56.880 --> 00:58:01.880]   I went back to bed and next morning
[00:58:01.880 --> 00:58:04.760]   have a phone call from my advisor
[00:58:04.760 --> 00:58:06.880]   who also looked at this forum.
[00:58:06.880 --> 00:58:11.040]   He's like, "You won't believe who replied to you."
[00:58:11.040 --> 00:58:13.880]   And it's like, "Who?"
[00:58:13.880 --> 00:58:16.440]   He said, "Well, you know, there is a message to you
[00:58:16.440 --> 00:58:18.040]   "from Joshua Lederberg."
[00:58:18.040 --> 00:58:22.800]   And my reaction was like, "Who is Joshua Lederberg?"
[00:58:22.800 --> 00:58:24.840]   (laughing)
[00:58:24.840 --> 00:58:26.000]   - Your advisor hung up.
[00:58:26.000 --> 00:58:29.720]   - So, and essentially, you know,
[00:58:29.720 --> 00:58:34.120]   Joshua wrote me that we had conceptually similar ideas
[00:58:34.120 --> 00:58:36.680]   in the Dendrel project.
[00:58:36.680 --> 00:58:38.240]   You may wanna look it up.
[00:58:38.240 --> 00:58:40.160]   And, you know--
[00:58:40.160 --> 00:58:42.640]   - And we should also, sorry, and this is a side comment,
[00:58:42.640 --> 00:58:45.960]   say that even though he won the Nobel Prize
[00:58:45.960 --> 00:58:49.320]   at a really young age, in '58, but so--
[00:58:49.320 --> 00:58:52.400]   - He was, I think, he was, what, 33.
[00:58:52.400 --> 00:58:54.000]   - Yeah, it's just crazy.
[00:58:54.000 --> 00:58:57.640]   So anyway, so that's, so hence in the '90s,
[00:58:57.640 --> 00:59:02.120]   responding to young whippersnappers on the CCL forum.
[00:59:02.120 --> 00:59:02.960]   Okay, so--
[00:59:02.960 --> 00:59:05.840]   - And so back then he was already very senior.
[00:59:05.840 --> 00:59:09.600]   I mean, he unfortunately passed away back in 2008.
[00:59:09.600 --> 00:59:12.560]   But, you know, back in 2001, he was, I mean,
[00:59:12.560 --> 00:59:15.960]   he was a professor emeritus at Rockefeller University.
[00:59:15.960 --> 00:59:17.720]   And, you know, that was actually,
[00:59:17.720 --> 00:59:22.720]   believe it or not, one of the reasons
[00:59:22.720 --> 00:59:26.800]   I decided to join, you know, as a postdoc,
[00:59:26.800 --> 00:59:28.160]   the group of Andrei Saleh,
[00:59:28.160 --> 00:59:30.800]   who was at Rockefeller University,
[00:59:30.800 --> 00:59:33.440]   with the hope that, you know, that I could actually,
[00:59:33.440 --> 00:59:38.080]   you know, have a chance to meet Joshua in person.
[00:59:38.080 --> 00:59:40.880]   And I met him very briefly, right?
[00:59:40.880 --> 00:59:45.400]   Just because he was walking, you know,
[00:59:45.400 --> 00:59:47.600]   there's a little bridge that connects
[00:59:47.600 --> 00:59:50.040]   the sort of the research campus
[00:59:50.040 --> 00:59:55.040]   with the sort of sky scrapper that Rockefeller owns,
[00:59:55.040 --> 00:59:58.760]   the way, you know, postdocs and faculty
[00:59:58.760 --> 01:00:00.520]   and graduate students live.
[01:00:00.520 --> 01:00:02.440]   And so I met him, you know,
[01:00:02.440 --> 01:00:06.320]   and had a very short conversation, you know.
[01:00:06.320 --> 01:00:10.360]   But so I started, you know, reading about Dendral,
[01:00:10.360 --> 01:00:12.680]   and I was amazed, you know, it's,
[01:00:12.680 --> 01:00:16.080]   we're talking about 1960, right?
[01:00:16.080 --> 01:00:19.280]   The ideas were so profound.
[01:00:19.280 --> 01:00:21.120]   - Well, what's the fundamental ideas of it?
[01:00:21.120 --> 01:00:25.000]   - The reason to make this is even crazier.
[01:00:25.000 --> 01:00:29.840]   So Lederberg wanted to make a system
[01:00:29.840 --> 01:00:33.440]   that would help him study
[01:00:33.440 --> 01:00:38.440]   the extraterrestrial molecules, right?
[01:00:38.440 --> 01:00:40.960]   So the idea was that, you know,
[01:00:40.960 --> 01:00:43.400]   the way you study the extraterrestrial molecules
[01:00:43.400 --> 01:00:46.560]   is you do the mass spec analysis, right?
[01:00:46.560 --> 01:00:49.680]   And so the mass spec gives you sort of bits,
[01:00:49.680 --> 01:00:51.680]   numbers about essentially,
[01:00:51.680 --> 01:00:54.760]   gives you the ideas about the possible fragments,
[01:00:54.760 --> 01:00:57.440]   or, you know, atoms, you know,
[01:00:57.440 --> 01:00:59.800]   and maybe a little fragments,
[01:00:59.800 --> 01:01:03.600]   pieces of this molecule that make up the molecule, right?
[01:01:03.600 --> 01:01:06.080]   So now you need to sort of,
[01:01:06.080 --> 01:01:09.200]   to decompose this information
[01:01:09.200 --> 01:01:12.440]   and to figure out what was the whole
[01:01:12.440 --> 01:01:17.440]   before, you know, became fragments, bits and pieces, right?
[01:01:17.440 --> 01:01:20.840]   So in order to make this, you know,
[01:01:20.840 --> 01:01:22.680]   to have this tool,
[01:01:24.360 --> 01:01:28.640]   the idea of Lederberg was to connect chemistry,
[01:01:28.640 --> 01:01:31.080]   computer science,
[01:01:31.080 --> 01:01:36.080]   and to design this so-called expert system
[01:01:36.080 --> 01:01:38.200]   that looks, that takes into account,
[01:01:38.200 --> 01:01:42.160]   that takes as an input, the mass spec data,
[01:01:42.160 --> 01:01:47.160]   the possible database of possible molecules,
[01:01:47.160 --> 01:01:52.640]   and essentially try to sort of induce the molecule
[01:01:52.640 --> 01:01:55.600]   that would correspond to this spectra.
[01:01:55.600 --> 01:01:57.760]   Or, you know, essentially,
[01:01:57.760 --> 01:02:01.520]   what this project ended up being
[01:02:01.520 --> 01:02:07.080]   was that, you know, it would provide a list of candidates
[01:02:07.080 --> 01:02:09.760]   that then a chemist would look at
[01:02:09.760 --> 01:02:12.560]   and make final decision, so.
[01:02:12.560 --> 01:02:13.960]   - But the original idea, I suppose,
[01:02:13.960 --> 01:02:16.840]   is to solve the entirety of this problem automatically.
[01:02:16.840 --> 01:02:17.680]   - Yes, yes.
[01:02:17.680 --> 01:02:19.600]   So he, you know,
[01:02:20.520 --> 01:02:24.000]   so he, back then, he--
[01:02:24.000 --> 01:02:26.280]   - '60s. - Approached, yes.
[01:02:26.280 --> 01:02:27.120]   Believe that.
[01:02:27.120 --> 01:02:28.960]   You know, it's amazing.
[01:02:28.960 --> 01:02:31.080]   I mean, it still blows my mind, you know,
[01:02:31.080 --> 01:02:32.800]   that it's, that's,
[01:02:32.800 --> 01:02:37.400]   and this was essentially the origin
[01:02:37.400 --> 01:02:41.120]   of the modern bioinformatics, cheminformatics,
[01:02:41.120 --> 01:02:42.800]   you know, back in '60s.
[01:02:42.800 --> 01:02:44.000]   So that's, you know,
[01:02:44.000 --> 01:02:48.960]   so every time you deal with projects like this,
[01:02:48.960 --> 01:02:51.360]   with the, you know, research like this,
[01:02:51.360 --> 01:02:52.560]   it just, you know,
[01:02:52.560 --> 01:02:56.360]   so the power of the, you know,
[01:02:56.360 --> 01:02:58.960]   intelligence of these people
[01:02:58.960 --> 01:03:01.720]   is just, you know, overwhelming.
[01:03:01.720 --> 01:03:04.200]   - Do you think about expert systems?
[01:03:04.200 --> 01:03:09.200]   Is there, and why they kind of didn't become successful?
[01:03:09.200 --> 01:03:12.520]   Especially in the space of bioinformatics,
[01:03:12.520 --> 01:03:15.400]   where it does seem like there is a lot of expertise
[01:03:15.400 --> 01:03:18.280]   in humans, and, you know,
[01:03:18.280 --> 01:03:21.360]   is it possible to see that a system like this
[01:03:21.360 --> 01:03:23.600]   could be made very useful?
[01:03:23.600 --> 01:03:24.440]   - Right. - And be built up?
[01:03:24.440 --> 01:03:26.920]   - So it's actually, it's a great question,
[01:03:26.920 --> 01:03:28.480]   and this is something, so, you know,
[01:03:28.480 --> 01:03:31.480]   so, you know, at my university,
[01:03:31.480 --> 01:03:33.920]   I teach artificial intelligence,
[01:03:33.920 --> 01:03:36.440]   and, you know, we start,
[01:03:36.440 --> 01:03:40.120]   my first two lectures are on the history of AI.
[01:03:40.120 --> 01:03:44.360]   And there we, you know, we try to, you know,
[01:03:44.360 --> 01:03:48.200]   go through the main stages of AI,
[01:03:48.200 --> 01:03:53.080]   and so, you know, the question of why expert systems
[01:03:53.080 --> 01:03:57.120]   failed or became obsolete,
[01:03:57.120 --> 01:03:58.520]   it's actually a very interesting one.
[01:03:58.520 --> 01:04:01.680]   And there are, you know, if you try to read the,
[01:04:01.680 --> 01:04:03.320]   you know, the historical perspectives,
[01:04:03.320 --> 01:04:05.520]   there are actually two lines of thoughts.
[01:04:05.520 --> 01:04:10.520]   One is that they were essentially
[01:04:10.520 --> 01:04:14.840]   not up to the expectations,
[01:04:14.840 --> 01:04:18.040]   and so therefore they were replaced, you know,
[01:04:18.040 --> 01:04:21.160]   by other things, right?
[01:04:21.160 --> 01:04:25.320]   The other one was that completely opposite one,
[01:04:25.320 --> 01:04:28.160]   that they were too good.
[01:04:28.160 --> 01:04:31.440]   And as a result, they essentially
[01:04:31.440 --> 01:04:33.180]   became sort of a household name,
[01:04:33.180 --> 01:04:37.120]   and then essentially they got transformed.
[01:04:37.120 --> 01:04:40.680]   I mean, in both cases, sort of the outcome was the same.
[01:04:40.680 --> 01:04:42.400]   They evolved into something.
[01:04:42.400 --> 01:04:43.760]   - Yeah. - Right?
[01:04:43.760 --> 01:04:46.040]   And that's what I, you know, if--
[01:04:46.040 --> 01:04:47.680]   - That's interesting. - If I look at this, right?
[01:04:47.680 --> 01:04:50.200]   So the modern machine learning, right?
[01:04:50.200 --> 01:04:52.000]   So-- - So there's echoes
[01:04:52.000 --> 01:04:53.240]   in the modern machine learning to that.
[01:04:53.240 --> 01:04:55.320]   - I think so, I think so, because, you know,
[01:04:55.320 --> 01:04:57.200]   if you think about this, you know,
[01:04:57.200 --> 01:04:59.640]   and how we design, you know,
[01:04:59.640 --> 01:05:02.480]   the most successful algorithms,
[01:05:02.480 --> 01:05:04.120]   including AlphaFold, right?
[01:05:04.120 --> 01:05:08.040]   You built in the knowledge about the domain
[01:05:08.040 --> 01:05:09.920]   that you study, right?
[01:05:09.920 --> 01:05:12.860]   So you built in your expertise.
[01:05:12.860 --> 01:05:16.520]   - So speaking of AlphaFold, so DeepMind's AlphaFold2
[01:05:16.520 --> 01:05:18.920]   recently was announced to have,
[01:05:18.920 --> 01:05:21.400]   quote unquote, "solved protein folding."
[01:05:21.400 --> 01:05:24.160]   How exciting is this to you?
[01:05:24.160 --> 01:05:28.280]   It seems to be one of the exciting things
[01:05:28.280 --> 01:05:29.640]   that have happened in 2020.
[01:05:29.640 --> 01:05:32.280]   It's an incredible accomplishment from the looks of it.
[01:05:32.280 --> 01:05:33.840]   What part of it is amazing to you?
[01:05:33.840 --> 01:05:36.280]   What part would you say is overhyped
[01:05:36.280 --> 01:05:39.000]   or maybe misunderstood?
[01:05:39.000 --> 01:05:41.880]   - It's definitely a very exciting achievement.
[01:05:41.880 --> 01:05:43.760]   To give you a little bit of perspective, right?
[01:05:43.760 --> 01:05:48.760]   So in bioinformatics, we have several competitions.
[01:05:48.760 --> 01:05:53.000]   And so the way, you know, you often hear
[01:05:53.000 --> 01:05:56.160]   how those competitions have been explained
[01:05:56.160 --> 01:05:59.560]   to sort of to non-bioinformaticians is that,
[01:05:59.560 --> 01:06:01.800]   you know, they call it bioinformatics Olympic games.
[01:06:01.800 --> 01:06:03.600]   And there are several disciplines, right?
[01:06:03.600 --> 01:06:07.040]   So the historical one of the first one
[01:06:07.040 --> 01:06:10.280]   was the discipline in predicting the protein structure,
[01:06:10.280 --> 01:06:12.560]   predicting the 3D coordinates of the protein.
[01:06:12.560 --> 01:06:13.600]   But there are some others.
[01:06:13.600 --> 01:06:16.760]   So the predicting protein functions,
[01:06:16.760 --> 01:06:21.480]   predicting effects of mutations on protein functions,
[01:06:21.480 --> 01:06:24.920]   then predicting protein-protein interactions.
[01:06:24.920 --> 01:06:28.080]   So the original one was CASP
[01:06:28.080 --> 01:06:31.520]   or a critical assessment of protein structure.
[01:06:31.520 --> 01:06:38.160]   And the, you know, typically what happens
[01:06:40.000 --> 01:06:43.960]   during these competitions is, you know, scientists,
[01:06:43.960 --> 01:06:48.360]   experimental scientists solve the structures,
[01:06:48.360 --> 01:06:51.680]   but don't put them into the protein databank,
[01:06:51.680 --> 01:06:53.720]   which is the centralized database
[01:06:53.720 --> 01:06:57.240]   that contains all the 3D coordinates.
[01:06:57.240 --> 01:07:02.240]   Instead, they hold it and release protein sequences.
[01:07:02.240 --> 01:07:05.400]   And now the challenge of the community
[01:07:05.400 --> 01:07:10.160]   is to predict the 3D structures of these proteins,
[01:07:10.160 --> 01:07:12.920]   and then use the experimentally solved structures
[01:07:12.920 --> 01:07:16.600]   to assess which one is the closest one, right?
[01:07:16.600 --> 01:07:17.760]   - And this competition, by the way,
[01:07:17.760 --> 01:07:19.520]   just a bunch of different tangents.
[01:07:19.520 --> 01:07:22.840]   And maybe you can also say, what is protein folding?
[01:07:22.840 --> 01:07:25.000]   Then this competition, CASP competition,
[01:07:25.000 --> 01:07:27.440]   has become the gold standard,
[01:07:27.440 --> 01:07:29.500]   and that's what was used to say
[01:07:29.500 --> 01:07:32.440]   that protein folding was solved.
[01:07:32.440 --> 01:07:35.320]   So I just added a little, yeah, just a bunch.
[01:07:35.320 --> 01:07:37.680]   - So if you can, whenever you say stuff,
[01:07:37.680 --> 01:07:39.400]   maybe throw in some of the basics
[01:07:39.400 --> 01:07:41.560]   for the folks that might be outside of the field.
[01:07:41.560 --> 01:07:42.400]   Anyway, sorry.
[01:07:42.400 --> 01:07:45.920]   - So, yeah, so, you know, so the reason it's, you know,
[01:07:45.920 --> 01:07:50.280]   it's relevant to our understanding of protein folding
[01:07:50.280 --> 01:07:54.160]   is because, you know, we've yet to learn
[01:07:54.160 --> 01:07:58.140]   how the folding mechanistically works, right?
[01:07:58.140 --> 01:08:00.740]   So there are different hypotheses
[01:08:00.740 --> 01:08:02.800]   what happens to this fold.
[01:08:02.800 --> 01:08:05.960]   For example, there is a hypothesis
[01:08:05.960 --> 01:08:09.780]   that the folding happens by, you know,
[01:08:09.780 --> 01:08:12.640]   also in the modular fashion, right?
[01:08:12.640 --> 01:08:16.220]   So that, you know, we have protein domains
[01:08:16.220 --> 01:08:17.920]   that get folded independently
[01:08:17.920 --> 01:08:19.720]   because their structure is stable,
[01:08:19.720 --> 01:08:23.360]   and then the whole protein structure gets formed.
[01:08:23.360 --> 01:08:25.360]   But, you know, within those domains,
[01:08:25.360 --> 01:08:27.460]   we also have so-called secondary structure,
[01:08:27.460 --> 01:08:29.800]   the small alpha helices, beta sheets.
[01:08:29.800 --> 01:08:34.320]   So these are, you know, elements that are structurally stable.
[01:08:34.320 --> 01:08:37.800]   And so, and the question is, you know,
[01:08:37.800 --> 01:08:40.320]   when do they get formed?
[01:08:40.320 --> 01:08:42.560]   Because some of the secondary structure elements,
[01:08:42.560 --> 01:08:46.480]   you have to have, you know, a fragment in the beginning
[01:08:46.480 --> 01:08:49.400]   and say the fragment in the middle, right?
[01:08:49.400 --> 01:08:52.840]   So you cannot potentially start
[01:08:52.840 --> 01:08:57.120]   having the full fold from the get-go, right?
[01:08:57.120 --> 01:09:00.320]   So it's still, you know, it's still a big enigma,
[01:09:00.320 --> 01:09:01.440]   what happens.
[01:09:01.440 --> 01:09:04.260]   We know that it's an extremely efficient
[01:09:04.260 --> 01:09:05.680]   and stable process, right?
[01:09:05.680 --> 01:09:07.640]   - So there's this long sequence,
[01:09:07.640 --> 01:09:09.520]   and the fold happens really quickly.
[01:09:09.520 --> 01:09:10.360]   - Exactly.
[01:09:10.360 --> 01:09:11.200]   - So that's really weird, right?
[01:09:11.200 --> 01:09:15.120]   And it happens like the same way almost every time.
[01:09:15.120 --> 01:09:16.600]   - Exactly, exactly, right?
[01:09:16.600 --> 01:09:17.880]   - That's really weird.
[01:09:17.880 --> 01:09:19.080]   That's freaking weird.
[01:09:19.080 --> 01:09:22.920]   - It's, yeah, that's why it's such an amazing thing.
[01:09:22.920 --> 01:09:24.960]   But most importantly, right, so it's, you know,
[01:09:24.960 --> 01:09:29.240]   so when you see the translation process, right,
[01:09:29.240 --> 01:09:34.240]   so when you don't have the whole protein translated, right,
[01:09:34.240 --> 01:09:39.200]   it's still being translated, you know,
[01:09:39.200 --> 01:09:41.200]   getting out from the ribosome,
[01:09:41.200 --> 01:09:45.760]   you already see some structural, you know, fragmentation.
[01:09:45.760 --> 01:09:49.280]   So folding starts happening
[01:09:49.280 --> 01:09:53.040]   before the whole protein gets produced, right?
[01:09:53.040 --> 01:09:55.080]   And so this is obviously, you know,
[01:09:55.080 --> 01:09:59.240]   one of the biggest questions in, you know,
[01:09:59.240 --> 01:10:00.960]   in modern molecular biologies.
[01:10:00.960 --> 01:10:04.160]   - Not like maybe what happens,
[01:10:04.160 --> 01:10:07.880]   like that's not, that's bigger than the question of folding.
[01:10:07.880 --> 01:10:09.560]   That's the question of like,
[01:10:09.560 --> 01:10:12.440]   so like deeper fundamental idea of folding.
[01:10:12.440 --> 01:10:13.400]   - Yes. - Behind folding.
[01:10:13.400 --> 01:10:14.640]   - Exactly, exactly.
[01:10:14.640 --> 01:10:19.640]   So, you know, so obviously if we are able to predict
[01:10:21.320 --> 01:10:24.040]   the end product of protein folding,
[01:10:24.040 --> 01:10:27.640]   we are one step closer to understanding
[01:10:27.640 --> 01:10:30.200]   sort of the mechanistics of the protein folding.
[01:10:30.200 --> 01:10:34.680]   Because we can then potentially look and start probing
[01:10:34.680 --> 01:10:38.200]   what are the critical parts of this process
[01:10:38.200 --> 01:10:41.200]   and what are not so critical parts of this process.
[01:10:41.200 --> 01:10:44.440]   So we can start decomposing this, you know,
[01:10:44.440 --> 01:10:49.440]   so in a way, this protein structure prediction algorithm
[01:10:50.120 --> 01:10:53.720]   can be used as a tool, right?
[01:10:53.720 --> 01:10:58.720]   So you change the, you know, you modify the protein,
[01:10:58.720 --> 01:11:02.400]   you get back to this tool, it predicts,
[01:11:02.400 --> 01:11:05.000]   okay, it's completely unstable.
[01:11:05.000 --> 01:11:07.840]   - Yeah, which aspects of the input
[01:11:07.840 --> 01:11:09.880]   will have a big impact on the output.
[01:11:09.880 --> 01:11:11.200]   - Exactly, exactly.
[01:11:11.200 --> 01:11:13.360]   So what happens is, you know,
[01:11:13.360 --> 01:11:18.360]   we typically have some sort of incremental advancement.
[01:11:18.720 --> 01:11:22.600]   You know, each stage of this CASP competition,
[01:11:22.600 --> 01:11:25.320]   you have groups with incremental advancement.
[01:11:25.320 --> 01:11:29.840]   And, you know, historically, the top performing groups
[01:11:29.840 --> 01:11:34.400]   were, you know, they were not using machine learning.
[01:11:34.400 --> 01:11:37.720]   They were using very advanced biophysics
[01:11:37.720 --> 01:11:39.600]   combined with bioinformatics,
[01:11:39.600 --> 01:11:43.220]   combined with, you know, the data mining.
[01:11:43.220 --> 01:11:47.360]   And that was, you know, that would enable them
[01:11:47.360 --> 01:11:52.360]   to obtain protein structures of those proteins
[01:11:52.360 --> 01:11:57.520]   that don't have any structurally solved relatives.
[01:11:57.520 --> 01:12:01.860]   Because, you know, if we have another protein,
[01:12:01.860 --> 01:12:05.640]   say the same protein, but coming from a different species,
[01:12:05.640 --> 01:12:10.440]   we could potentially derive some ideas,
[01:12:10.440 --> 01:12:13.200]   and that's so-called homology or comparative modeling,
[01:12:13.200 --> 01:12:15.280]   where we'll derive some ideas
[01:12:15.280 --> 01:12:17.360]   from the previously known structures.
[01:12:17.360 --> 01:12:21.440]   And that would help us tremendously in, you know,
[01:12:21.440 --> 01:12:25.400]   in reconstructing the 3D structure overall.
[01:12:25.400 --> 01:12:27.900]   But what happens when we don't have these relatives?
[01:12:27.900 --> 01:12:31.200]   This is when it becomes really, really hard, right?
[01:12:31.200 --> 01:12:35.240]   So that's so-called de novo, you know,
[01:12:35.240 --> 01:12:37.560]   de novo protein structure prediction.
[01:12:37.560 --> 01:12:39.040]   And in this case,
[01:12:39.040 --> 01:12:43.040]   those methods were traditionally very good.
[01:12:43.040 --> 01:12:46.280]   But what happened in the last year,
[01:12:46.280 --> 01:12:49.540]   the original alpha fold came into,
[01:12:49.540 --> 01:12:55.640]   and all of a sudden, it's much better than everyone else.
[01:12:55.640 --> 01:12:57.920]   - This is 2018.
[01:12:57.920 --> 01:12:58.760]   - Yeah.
[01:12:58.760 --> 01:13:02.160]   - Oh, and the competition is only every two years, I think.
[01:13:02.160 --> 01:13:06.600]   - And then, so, you know, it was sort of
[01:13:06.600 --> 01:13:10.160]   kind of of a shockwave to the bioinformatics community
[01:13:10.160 --> 01:13:15.160]   that we have like a state-of-the-art machine learning system
[01:13:15.160 --> 01:13:18.440]   that does structure prediction.
[01:13:18.440 --> 01:13:20.760]   And essentially what it does, you know,
[01:13:20.760 --> 01:13:25.760]   so if you look at this, it actually predicts the context.
[01:13:25.760 --> 01:13:29.480]   So, you know, so the process of reconstructing
[01:13:29.480 --> 01:13:34.480]   the 3D structure starts by predicting the context
[01:13:34.480 --> 01:13:38.880]   between the different parts of the protein.
[01:13:38.880 --> 01:13:40.960]   And the context is essentially the part of the proteins
[01:13:40.960 --> 01:13:43.240]   that are in the close proximity to each other.
[01:13:43.240 --> 01:13:44.680]   - Right, so it's actually,
[01:13:44.680 --> 01:13:47.800]   the machine learning part seems to be estimating,
[01:13:47.800 --> 01:13:51.080]   you can correct me if I'm wrong here,
[01:13:51.080 --> 01:13:53.200]   but it seems to be estimating the distance matrix,
[01:13:53.200 --> 01:13:55.880]   which is like the distance between the different parts.
[01:13:55.880 --> 01:13:58.080]   - Yeah, so we call it a contact map.
[01:13:58.080 --> 01:13:58.920]   - Contact map.
[01:13:58.920 --> 01:14:00.600]   - Right, so once you have the contact map,
[01:14:00.600 --> 01:14:03.920]   the reconstruction is becoming more straightforward.
[01:14:03.920 --> 01:14:04.760]   - Yeah.
[01:14:04.760 --> 01:14:06.800]   - Right, but so the contact map is the key.
[01:14:06.800 --> 01:14:11.280]   And so, you know, so that what happened.
[01:14:11.280 --> 01:14:16.000]   And now we started seeing in this current stage, right,
[01:14:16.000 --> 01:14:18.480]   where in the most recent one,
[01:14:18.480 --> 01:14:22.040]   we started seeing the emergence of these ideas
[01:14:22.040 --> 01:14:25.080]   in other people works, right?
[01:14:25.080 --> 01:14:29.520]   But yet here's, you know, AlphaFold2,
[01:14:29.520 --> 01:14:33.400]   that again outperforms everyone else.
[01:14:33.400 --> 01:14:35.800]   And also by introducing yet another wave
[01:14:35.800 --> 01:14:38.640]   of the machine learning ideas.
[01:14:38.640 --> 01:14:41.280]   - Yeah, there does seem to be also an incorporation.
[01:14:41.280 --> 01:14:43.040]   First of all, the paper's not out yet,
[01:14:43.040 --> 01:14:44.880]   but there's a bunch of ideas already out.
[01:14:44.880 --> 01:14:48.120]   There does seem to be an incorporation of this other thing.
[01:14:48.120 --> 01:14:50.160]   I don't know if it's something that you could speak to,
[01:14:50.160 --> 01:14:55.160]   which is like the incorporation of like other structures,
[01:14:55.160 --> 01:15:01.720]   like evolutionary similar structures
[01:15:01.720 --> 01:15:03.840]   that are used to kind of give you hints.
[01:15:03.840 --> 01:15:08.360]   - Yes, so evolutionary similarity is something
[01:15:08.360 --> 01:15:10.760]   that we can detect at different levels, right?
[01:15:10.760 --> 01:15:15.760]   So we know, for example, that the structure of proteins
[01:15:15.760 --> 01:15:20.520]   is more conserved than the sequence.
[01:15:20.520 --> 01:15:22.320]   The sequence could be very different,
[01:15:22.320 --> 01:15:26.320]   but the structural shape is actually still very conserved.
[01:15:26.320 --> 01:15:28.880]   So that's sort of the intrinsic property that, you know,
[01:15:28.880 --> 01:15:31.720]   in a way related to protein folds, you know,
[01:15:31.720 --> 01:15:35.400]   to the evolution of the protein,
[01:15:35.400 --> 01:15:37.800]   of proteins and protein domains, et cetera.
[01:15:37.800 --> 01:15:41.040]   But we know that, I mean, there've been multiple studies.
[01:15:41.040 --> 01:15:45.320]   And, you know, ideally if you have structures,
[01:15:45.320 --> 01:15:48.560]   you know, you should use that information.
[01:15:48.560 --> 01:15:51.200]   However, sometimes we don't have this information.
[01:15:51.200 --> 01:15:53.200]   Instead, we have a bunch of sequences.
[01:15:53.200 --> 01:15:54.880]   Sequences we have a lot, right?
[01:15:54.880 --> 01:15:59.880]   So we have, you know, hundreds, thousands of, you know,
[01:15:59.880 --> 01:16:02.680]   different organisms sequenced, right?
[01:16:02.680 --> 01:16:05.680]   And by taking the same protein,
[01:16:05.680 --> 01:16:09.800]   but in different organisms and aligning it,
[01:16:09.800 --> 01:16:12.200]   so making it, you know,
[01:16:12.200 --> 01:16:15.360]   making the corresponding positions aligned,
[01:16:15.360 --> 01:16:20.360]   we can actually say a lot about sort of what is conserved
[01:16:20.360 --> 01:16:24.040]   in this protein and therefore, you know,
[01:16:24.040 --> 01:16:27.240]   structure more stable, what is diverse in this protein.
[01:16:27.240 --> 01:16:30.880]   So on top of that, we could provide sort of the information
[01:16:30.880 --> 01:16:34.320]   about the sort of the secondary structure of this protein,
[01:16:34.320 --> 01:16:35.160]   et cetera, et cetera.
[01:16:35.160 --> 01:16:37.560]   So this information is extremely useful
[01:16:37.560 --> 01:16:39.880]   and it's already there.
[01:16:39.880 --> 01:16:42.840]   So while it's tempting to, you know,
[01:16:42.840 --> 01:16:44.760]   to do a complete ab initio,
[01:16:44.760 --> 01:16:48.200]   so you just have a protein sequence and nothing else,
[01:16:48.200 --> 01:16:52.880]   the reality is such that we are overwhelmed with this data.
[01:16:52.880 --> 01:16:54.200]   So why not use it?
[01:16:55.200 --> 01:16:56.520]   - Mm-hmm.
[01:16:56.520 --> 01:16:59.240]   - And so, yeah, so I'm looking forward
[01:16:59.240 --> 01:17:01.480]   to reading this paper.
[01:17:01.480 --> 01:17:03.440]   - It does seem to, like they've,
[01:17:03.440 --> 01:17:05.920]   in the previous version of AlphaFold, they didn't,
[01:17:05.920 --> 01:17:09.760]   for this evolutionary similarity thing,
[01:17:09.760 --> 01:17:12.020]   they didn't use machine learning for that.
[01:17:12.020 --> 01:17:15.600]   Or rather, they used it as like the input
[01:17:15.600 --> 01:17:17.880]   to the entirety of the neural net,
[01:17:17.880 --> 01:17:22.000]   like the features derived from the similarity.
[01:17:22.000 --> 01:17:24.640]   It seems like there's some kind of, quote unquote,
[01:17:24.640 --> 01:17:29.640]   iterative thing where it seems to be part of the learning
[01:17:29.640 --> 01:17:34.240]   process is the incorporation of this evolutionary similarity.
[01:17:34.240 --> 01:17:36.920]   - Yeah, I don't think there is a bioarchive paper, right?
[01:17:36.920 --> 01:17:38.520]   - There's nothing. - No, nothing.
[01:17:38.520 --> 01:17:40.680]   - There's a blog post that's written
[01:17:40.680 --> 01:17:42.320]   by a marketing team, essentially.
[01:17:42.320 --> 01:17:43.640]   - Yeah. - Which, you know,
[01:17:43.640 --> 01:17:48.640]   it has some scientific similarity probably
[01:17:48.640 --> 01:17:51.760]   to the actual methodology used,
[01:17:51.800 --> 01:17:55.240]   but it could be, it's like interpreting scripture.
[01:17:55.240 --> 01:17:58.800]   It could be just poetic interpretations
[01:17:58.800 --> 01:18:00.040]   of the actual work as opposed
[01:18:00.040 --> 01:18:01.920]   to direct connection to the work.
[01:18:01.920 --> 01:18:04.280]   - So now, speaking about protein folding, right?
[01:18:04.280 --> 01:18:06.800]   So, you know, in order to answer the question
[01:18:06.800 --> 01:18:09.440]   whether or not we have solved this, right?
[01:18:09.440 --> 01:18:13.280]   So we need to go back to the beginning of our conversation,
[01:18:13.280 --> 01:18:15.000]   you know, with the realization that, you know,
[01:18:15.000 --> 01:18:20.000]   an average protein is that typically what the cusp
[01:18:21.040 --> 01:18:24.080]   has been focusing on is, you know,
[01:18:24.080 --> 01:18:27.200]   this competition has been focusing on the single,
[01:18:27.200 --> 01:18:31.000]   maybe two domain proteins that are still very compact.
[01:18:31.000 --> 01:18:34.860]   And even those ones are extremely challenging to solve,
[01:18:34.860 --> 01:18:37.640]   right, but now we talk about, you know,
[01:18:37.640 --> 01:18:42.400]   an average protein that has two, three protein domains.
[01:18:42.400 --> 01:18:47.400]   If you look at the proteins that are in charge of the,
[01:18:47.480 --> 01:18:51.500]   you know, of the process with the neural system, right,
[01:18:51.500 --> 01:18:57.720]   perhaps one of the most recently evolved sort of systems
[01:18:57.720 --> 01:19:04.120]   in the organism, right?
[01:19:04.120 --> 01:19:06.320]   All of them, well, the majority of them
[01:19:06.320 --> 01:19:09.000]   are highly multi-domain proteins.
[01:19:09.000 --> 01:19:13.520]   So they are, you know, some of them have five, six, seven,
[01:19:13.520 --> 01:19:16.840]   you know, and more domains, right?
[01:19:16.840 --> 01:19:20.720]   And, you know, we are very far away from understanding
[01:19:20.720 --> 01:19:22.400]   how these proteins are folded.
[01:19:22.400 --> 01:19:24.440]   - So the complexity of the protein matters here,
[01:19:24.440 --> 01:19:27.960]   the complexity of the protein modules
[01:19:27.960 --> 01:19:30.240]   or the protein domains.
[01:19:30.240 --> 01:19:36.000]   So you're saying solved, so the definition of solved here
[01:19:36.000 --> 01:19:38.640]   is particularly the cast competition,
[01:19:38.640 --> 01:19:41.760]   achieving human level, not human level,
[01:19:41.760 --> 01:19:45.640]   achieving experimental level performance
[01:19:45.640 --> 01:19:48.520]   on these particular sets of proteins
[01:19:48.520 --> 01:19:50.280]   that have been used in these competitions.
[01:19:50.280 --> 01:19:54.680]   - Well, I mean, you know, I do think that, you know,
[01:19:54.680 --> 01:19:57.760]   especially with regards to the alpha fold, you know,
[01:19:57.760 --> 01:20:02.760]   it is able to, you know, to solve, you know,
[01:20:02.760 --> 01:20:07.360]   at the near experimental level,
[01:20:07.360 --> 01:20:14.000]   pretty big majority of the more compact proteins,
[01:20:15.000 --> 01:20:17.480]   like, or protein domains, because, again,
[01:20:17.480 --> 01:20:21.200]   in order to understand how the overall protein,
[01:20:21.200 --> 01:20:24.640]   you know, multi-domain protein fold,
[01:20:24.640 --> 01:20:26.840]   we do need to understand the structure
[01:20:26.840 --> 01:20:28.760]   of its individual domains.
[01:20:28.760 --> 01:20:31.120]   - I mean, unlike if you look at alpha zero
[01:20:31.120 --> 01:20:36.120]   or like mu zero, if you look at that work,
[01:20:36.120 --> 01:20:39.520]   you know, it's nice, reinforcement learning,
[01:20:39.520 --> 01:20:41.120]   self-playing mechanisms are nice
[01:20:41.120 --> 01:20:42.400]   'cause it's all in simulation,
[01:20:42.400 --> 01:20:45.920]   so you can learn from just huge amounts.
[01:20:45.920 --> 01:20:47.360]   Like, you don't need data.
[01:20:47.360 --> 01:20:49.760]   It was like the problem with proteins,
[01:20:49.760 --> 01:20:54.560]   like the size, I forget how many 3D structures
[01:20:54.560 --> 01:20:56.960]   have been mapped, but the training data is very small,
[01:20:56.960 --> 01:20:59.040]   no matter what, it's like millions,
[01:20:59.040 --> 01:21:01.400]   maybe a one or two million, something like that,
[01:21:01.400 --> 01:21:02.920]   but it's some very small number,
[01:21:02.920 --> 01:21:06.000]   but like, it doesn't seem like that's scalable.
[01:21:06.000 --> 01:21:09.360]   There has to be, I don't know,
[01:21:09.360 --> 01:21:13.120]   it feels like you want to somehow 10X the data
[01:21:13.120 --> 01:21:15.720]   or 100X the data somehow.
[01:21:15.720 --> 01:21:18.720]   - Yes, but we also can take advantage
[01:21:18.720 --> 01:21:23.080]   of homology models, right?
[01:21:23.080 --> 01:21:26.760]   So the models that are of very good quality
[01:21:26.760 --> 01:21:30.680]   because they are essentially obtained
[01:21:30.680 --> 01:21:33.760]   based on the evolutionary information, right?
[01:21:33.760 --> 01:21:38.560]   So you can, there is a potential to enhance this information
[01:21:38.560 --> 01:21:43.560]   and use it again to empower the training set.
[01:21:43.560 --> 01:21:53.600]   And it's, I think, I am actually very optimistic.
[01:21:53.600 --> 01:21:58.760]   I think it's been one of these sort of, you know,
[01:21:58.760 --> 01:22:07.160]   churning events where you have a system
[01:22:07.160 --> 01:22:11.320]   that is, you know, a machine learning system
[01:22:11.320 --> 01:22:15.760]   that is truly better than the sort of the more conventional
[01:22:15.760 --> 01:22:17.960]   biophysics-based methods.
[01:22:17.960 --> 01:22:19.400]   - That's a huge leap.
[01:22:19.400 --> 01:22:21.320]   This is one of those fun questions,
[01:22:21.320 --> 01:22:26.320]   but where would you put it in the ranking
[01:22:26.320 --> 01:22:28.560]   of the greatest breakthroughs
[01:22:28.560 --> 01:22:30.500]   in artificial intelligence history?
[01:22:30.500 --> 01:22:34.980]   So like, okay, so let's see who's in the running.
[01:22:34.980 --> 01:22:35.880]   Maybe you can correct me.
[01:22:35.880 --> 01:22:39.960]   So you got like AlphaZero and AlphaGo
[01:22:39.960 --> 01:22:44.520]   beating the world champion at the game of Go.
[01:22:44.520 --> 01:22:48.240]   Thought to be impossible like 20 years ago,
[01:22:48.240 --> 01:22:51.380]   or at least the AI community was highly skeptical.
[01:22:51.380 --> 01:22:55.120]   Then you got like also Deep Blue original Kasparov.
[01:22:55.120 --> 01:22:56.960]   You have deep learning itself, like the,
[01:22:56.960 --> 01:23:01.000]   maybe what would you say, the AlexNet image in that moment.
[01:23:01.000 --> 01:23:02.120]   So the first, you know,
[01:23:02.120 --> 01:23:04.840]   network achieving human level performance,
[01:23:04.840 --> 01:23:07.880]   super not, that's not true.
[01:23:07.880 --> 01:23:11.040]   Achieving like a big leap in performance
[01:23:11.040 --> 01:23:12.760]   on the computer vision problem.
[01:23:12.760 --> 01:23:19.000]   There is OpenAI, the whole like GPT-3,
[01:23:19.000 --> 01:23:23.060]   that whole space of transformers and language models,
[01:23:23.060 --> 01:23:27.160]   just achieving this incredible performance
[01:23:27.160 --> 01:23:30.240]   of application of neural networks to language models.
[01:23:30.240 --> 01:23:33.560]   Boston Dynamics, pretty cool.
[01:23:33.560 --> 01:23:35.960]   Like robotics, even though people are like,
[01:23:35.960 --> 01:23:38.760]   there's no AI, no, no, no.
[01:23:38.760 --> 01:23:41.560]   There's no machine learning currently,
[01:23:41.560 --> 01:23:44.560]   but AI is much bigger than machine learning.
[01:23:44.560 --> 01:23:48.920]   So that just the engineering aspect,
[01:23:48.920 --> 01:23:50.840]   I would say it's one of the greatest accomplishments
[01:23:50.840 --> 01:23:53.920]   in engineering side, engineering meaning
[01:23:53.920 --> 01:23:58.040]   like mechanical engineering of robotics ever.
[01:23:58.040 --> 01:23:59.560]   Then of course, autonomous vehicles,
[01:23:59.560 --> 01:24:01.320]   you can argue for Waymo,
[01:24:01.320 --> 01:24:03.600]   which is like the Google self-driving car,
[01:24:03.600 --> 01:24:05.480]   or you can argue for Tesla,
[01:24:05.480 --> 01:24:07.920]   which is like actually being used
[01:24:07.920 --> 01:24:09.880]   by hundreds of thousands of people
[01:24:09.880 --> 01:24:12.040]   on the road today, machine learning system.
[01:24:12.040 --> 01:24:17.600]   And I don't know if you can, what else is there?
[01:24:17.600 --> 01:24:18.440]   But I think that's it.
[01:24:18.440 --> 01:24:20.960]   So, and then AlphaFold, many people are saying
[01:24:20.960 --> 01:24:23.360]   is up there, potentially number one.
[01:24:23.360 --> 01:24:24.860]   Would you put them at number one?
[01:24:24.860 --> 01:24:29.860]   - Well, in terms of the impact on the science
[01:24:30.200 --> 01:24:34.080]   and on the society beyond, it's definitely,
[01:24:34.080 --> 01:24:35.840]   to me would be one of the--
[01:24:35.840 --> 01:24:38.480]   - Top three?
[01:24:38.480 --> 01:24:44.640]   - I mean, I'm probably not the best person to answer that.
[01:24:44.640 --> 01:24:50.480]   But I do have, I remember my,
[01:24:50.480 --> 01:24:56.400]   back in, I think 1997, when Deep Blue,
[01:24:56.400 --> 01:25:01.400]   but Kasparov, it was, I mean, it was a shock.
[01:25:01.400 --> 01:25:04.280]   I mean, it was, and I think for the,
[01:25:04.280 --> 01:25:13.000]   for the pretty substantial part of the world,
[01:25:13.000 --> 01:25:18.240]   that especially people who have some experience
[01:25:18.240 --> 01:25:25.080]   with chess, right, and realizing how incredibly human
[01:25:25.080 --> 01:25:30.080]   this game, how much of a brain power you need
[01:25:30.080 --> 01:25:35.800]   to reach those levels of grandmasters, right, level.
[01:25:35.800 --> 01:25:37.920]   - Yeah, and it's probably one of the first time,
[01:25:37.920 --> 01:25:39.760]   and how good Kasparov was.
[01:25:39.760 --> 01:25:42.280]   - And again, yeah, so Kasparov's arguably
[01:25:42.280 --> 01:25:45.560]   one of the best ever, right?
[01:25:45.560 --> 01:25:48.080]   And you get a machine that beats him, right?
[01:25:48.080 --> 01:25:48.920]   So it's--
[01:25:48.920 --> 01:25:50.760]   - First time a machine probably beat a human
[01:25:50.760 --> 01:25:53.720]   at that scale of a thing, of anything.
[01:25:53.720 --> 01:25:56.480]   - Yes, yes, so that was, to me, that was like,
[01:25:56.480 --> 01:25:59.400]   you know, one of the groundbreaking events
[01:25:59.400 --> 01:26:00.600]   in the history of AI.
[01:26:00.600 --> 01:26:01.920]   - Yeah, it's probably number one.
[01:26:01.920 --> 01:26:05.440]   - As probably, like, we don't, it's hard to remember.
[01:26:05.440 --> 01:26:08.120]   It's like Muhammad Ali versus, I don't know,
[01:26:08.120 --> 01:26:09.880]   any other, Mike Tyson, something like that.
[01:26:09.880 --> 01:26:12.760]   It's like, nah, you gotta put Muhammad Ali at number one.
[01:26:12.760 --> 01:26:16.240]   Same with Deep Blue, even though
[01:26:16.240 --> 01:26:17.980]   it's not machine learning based.
[01:26:17.980 --> 01:26:21.520]   Still, it uses advanced search,
[01:26:21.520 --> 01:26:24.080]   and search is the integral part of AI, right?
[01:26:24.080 --> 01:26:25.400]   So as you said, it's--
[01:26:25.400 --> 01:26:27.640]   - People don't think of it that way at this moment.
[01:26:27.640 --> 01:26:30.880]   In Vogue, currently, search is not seen
[01:26:30.880 --> 01:26:34.240]   as a fundamental aspect of intelligence,
[01:26:34.240 --> 01:26:37.680]   but it very well, it very likely is.
[01:26:37.680 --> 01:26:39.640]   In fact, I mean, that's what neural networks are,
[01:26:39.640 --> 01:26:41.240]   is they're just performing search
[01:26:41.240 --> 01:26:42.880]   on the space of parameters.
[01:26:42.880 --> 01:26:45.520]   And it's all search. (laughs)
[01:26:45.520 --> 01:26:47.760]   All of intelligence is some form of search,
[01:26:47.760 --> 01:26:49.640]   and you just have to become clever and clever
[01:26:49.640 --> 01:26:50.920]   at that search problem.
[01:26:50.920 --> 01:26:54.000]   - And I also have another one that you didn't mention
[01:26:54.000 --> 01:26:57.440]   that's one of my favorite ones.
[01:26:57.440 --> 01:27:00.880]   So you probably heard of this.
[01:27:00.880 --> 01:27:03.440]   I think it's called Deep Rembrandt.
[01:27:03.440 --> 01:27:06.600]   It's the project where they trained,
[01:27:06.600 --> 01:27:08.840]   I think there was a collaboration between
[01:27:08.840 --> 01:27:15.280]   the experts in Rembrandt painting in Netherlands,
[01:27:15.280 --> 01:27:18.320]   and a group, an artificial intelligence group,
[01:27:18.320 --> 01:27:20.200]   where they train an algorithm
[01:27:20.200 --> 01:27:23.000]   to replicate the style of the Rembrandt,
[01:27:23.000 --> 01:27:27.000]   and they actually printed a portrait
[01:27:27.000 --> 01:27:31.160]   that never existed before in the style of Rembrandt.
[01:27:31.160 --> 01:27:36.760]   I think they printed it on a sort of,
[01:27:36.760 --> 01:27:40.000]   on the canvas that, using pretty much
[01:27:40.000 --> 01:27:42.560]   same types of paints and stuff.
[01:27:42.560 --> 01:27:44.080]   To me, it was mind-blowing.
[01:27:44.080 --> 01:27:44.920]   - Yeah.
[01:27:44.920 --> 01:27:45.740]   - It's--
[01:27:45.740 --> 01:27:46.880]   - In the space of art, that's interesting.
[01:27:46.880 --> 01:27:50.080]   There hasn't been, maybe that's it,
[01:27:50.080 --> 01:27:53.600]   but I think there hasn't been an image
[01:27:53.600 --> 01:27:55.840]   in that moment yet in the space of art.
[01:27:55.840 --> 01:27:59.600]   You haven't been able to achieve superhuman level
[01:27:59.600 --> 01:28:01.420]   performance in the space of art,
[01:28:01.420 --> 01:28:04.660]   even though there was this big famous thing
[01:28:04.660 --> 01:28:07.680]   where a piece of art was purchased,
[01:28:07.680 --> 01:28:08.680]   I guess, for a lot of money.
[01:28:08.680 --> 01:28:09.520]   - Yes.
[01:28:09.520 --> 01:28:12.360]   - Yeah, but it's still, people are like,
[01:28:12.360 --> 01:28:14.020]   in the space of music at least,
[01:28:15.600 --> 01:28:19.720]   that's, it's clear that human-created pieces
[01:28:19.720 --> 01:28:21.680]   are much more popular.
[01:28:21.680 --> 01:28:24.400]   So there hasn't been a moment where it's like,
[01:28:24.400 --> 01:28:28.760]   oh, this is, we're now, I would say in the space of music,
[01:28:28.760 --> 01:28:32.080]   what makes a lot of money, we're talking about serious money,
[01:28:32.080 --> 01:28:35.280]   it's music and movies, or like shows and so on,
[01:28:35.280 --> 01:28:36.600]   and entertainment.
[01:28:36.600 --> 01:28:40.000]   There hasn't been a moment where AI created,
[01:28:40.000 --> 01:28:44.440]   AI was able to create a piece of music
[01:28:44.440 --> 01:28:49.440]   or a piece of cinema, like Netflix show,
[01:28:49.440 --> 01:28:54.840]   that is, that's sufficiently popular to make a ton of money.
[01:28:54.840 --> 01:28:56.120]   - Yeah.
[01:28:56.120 --> 01:28:58.960]   - And that moment would be very, very powerful,
[01:28:58.960 --> 01:29:01.560]   'cause that's like, that's an AI system
[01:29:01.560 --> 01:29:03.040]   being used to make a lot of money.
[01:29:03.040 --> 01:29:05.480]   And like direct, of course, AI tools,
[01:29:05.480 --> 01:29:07.920]   like even Premiere, audio editing, all the editing,
[01:29:07.920 --> 01:29:09.760]   everything I do, to edit this podcast,
[01:29:09.760 --> 01:29:11.640]   there's a lot of AI involved.
[01:29:11.640 --> 01:29:13.280]   Actually, there's this program,
[01:29:13.280 --> 01:29:15.560]   I wanna talk to those folks just 'cause I wanna nerd out,
[01:29:15.560 --> 01:29:18.080]   it's called iZotope, I don't know if you're familiar with it.
[01:29:18.080 --> 01:29:20.160]   They have a bunch of tools of audio processing,
[01:29:20.160 --> 01:29:23.080]   and they have, I think they're Boston-based.
[01:29:23.080 --> 01:29:26.360]   Just, it's so exciting to me to use it,
[01:29:26.360 --> 01:29:30.360]   like on the audio here, 'cause it's all machine learning.
[01:29:30.360 --> 01:29:35.360]   It's not, 'cause most audio production stuff
[01:29:35.360 --> 01:29:37.520]   is like any kind of processing you do,
[01:29:37.520 --> 01:29:39.520]   it's very basic signal processing.
[01:29:39.520 --> 01:29:41.960]   And you're tuning knobs and so on.
[01:29:41.960 --> 01:29:43.560]   They have all of that, of course,
[01:29:43.560 --> 01:29:46.000]   but they also have all of this machine learning stuff,
[01:29:46.000 --> 01:29:48.520]   like where you actually give it training data.
[01:29:48.520 --> 01:29:51.440]   You select parts of the audio you train on,
[01:29:51.440 --> 01:29:56.360]   you train on it, and it figures stuff out.
[01:29:56.360 --> 01:29:58.080]   It's great, it's able to detect,
[01:29:58.080 --> 01:30:03.320]   like the ability of it to be able to separate voice
[01:30:03.320 --> 01:30:07.240]   and music, for example, or voice in anything, is incredible.
[01:30:07.240 --> 01:30:11.160]   Like it just, it's clearly exceptionally good
[01:30:11.160 --> 01:30:14.920]   at applying these different neural networks models
[01:30:14.920 --> 01:30:18.920]   to separate the different kinds of signals from the audio.
[01:30:18.920 --> 01:30:22.280]   Okay, so that's really exciting.
[01:30:22.280 --> 01:30:24.600]   Photoshop, Adobe people also use it.
[01:30:24.600 --> 01:30:28.280]   But to generate a piece of music
[01:30:28.280 --> 01:30:31.960]   that will sell millions, a piece of art, yeah.
[01:30:31.960 --> 01:30:35.360]   - No, I agree, and that's,
[01:30:38.640 --> 01:30:41.160]   as I mentioned, I offer my AI class,
[01:30:41.160 --> 01:30:44.640]   and an integral part of this is the project, right?
[01:30:44.640 --> 01:30:47.320]   So it's my favorite, ultimate favorite part,
[01:30:47.320 --> 01:30:51.360]   because typically we have these project presentations
[01:30:51.360 --> 01:30:53.480]   the last two weeks of the class,
[01:30:53.480 --> 01:30:56.160]   it's right before the Christmas break,
[01:30:56.160 --> 01:31:00.320]   and it's sort of, it adds this cool excitement.
[01:31:00.320 --> 01:31:05.320]   And every time, I'm amazed with some projects
[01:31:05.520 --> 01:31:08.720]   that people come up with.
[01:31:08.720 --> 01:31:13.120]   And so, and quite a few of them are actually,
[01:31:13.120 --> 01:31:17.760]   they have some link to arts.
[01:31:17.760 --> 01:31:22.160]   I mean, I think last year, we had a group
[01:31:22.160 --> 01:31:27.160]   who designed an AI producing hokus, Japanese poems.
[01:31:27.160 --> 01:31:29.400]   - Oh, wow.
[01:31:29.400 --> 01:31:33.600]   - And some of them, so it got trained
[01:31:34.120 --> 01:31:35.680]   on the English base. - Hokus?
[01:31:35.680 --> 01:31:37.280]   - Hokus, hokus, right?
[01:31:37.280 --> 01:31:42.280]   So, and some of them, they get to present
[01:31:42.280 --> 01:31:44.240]   like the top selection.
[01:31:44.240 --> 01:31:45.160]   They were pretty good.
[01:31:45.160 --> 01:31:47.840]   I mean, of course, I'm not a specialist,
[01:31:47.840 --> 01:31:50.280]   but you read them, and you see--
[01:31:50.280 --> 01:31:51.440]   - It seems profound.
[01:31:51.440 --> 01:31:54.920]   - Yes, yeah, it seems reason, so it's kind of cool.
[01:31:54.920 --> 01:31:57.840]   We also had a couple of projects
[01:31:57.840 --> 01:32:02.840]   where people tried to teach AI how to play like rock music,
[01:32:03.520 --> 01:32:08.400]   classical music, I think, and popular music.
[01:32:08.400 --> 01:32:14.240]   Interestingly enough, classical music
[01:32:14.240 --> 01:32:16.600]   was among the most difficult ones.
[01:32:16.600 --> 01:32:25.160]   Of course, if you look at the grandmasters of music,
[01:32:25.160 --> 01:32:31.080]   like Bach, right?
[01:32:31.080 --> 01:32:34.840]   So, there is a lot of almost math.
[01:32:34.840 --> 01:32:36.600]   - Yeah, well, he's very mathematical.
[01:32:36.600 --> 01:32:39.040]   - Exactly, so this is, I would imagine
[01:32:39.040 --> 01:32:43.800]   that at least some style of this music could be picked up,
[01:32:43.800 --> 01:32:46.960]   but then you have this completely different spectrum
[01:32:46.960 --> 01:32:51.960]   of classical composers, and so it's almost like,
[01:32:51.960 --> 01:32:56.800]   you don't have to sort of look at the data.
[01:32:56.800 --> 01:33:00.560]   You just listen to it, and say, "Nah, that's not it,
[01:33:00.560 --> 01:33:01.600]   "not yet." - That's not it.
[01:33:01.600 --> 01:33:03.360]   Yeah, that's how I feel, too.
[01:33:03.360 --> 01:33:05.840]   There's OpenAI has, I think, OpenMuse
[01:33:05.840 --> 01:33:07.560]   or something like that, the system.
[01:33:07.560 --> 01:33:09.760]   It's cool, but it's like, eh,
[01:33:09.760 --> 01:33:12.080]   it's not compelling for some reason.
[01:33:12.080 --> 01:33:14.200]   It could be a psychological reason, too.
[01:33:14.200 --> 01:33:17.560]   Maybe we need to have a human being,
[01:33:17.560 --> 01:33:20.680]   a tortured soul behind the music, I don't know.
[01:33:20.680 --> 01:33:23.940]   - Yeah, no, absolutely, I completely agree.
[01:33:23.940 --> 01:33:26.560]   But yeah, whether or not we'll have,
[01:33:26.560 --> 01:33:31.560]   one day we'll have a song written by an AI engine
[01:33:31.560 --> 01:33:37.960]   to be in top charts, musical charts,
[01:33:37.960 --> 01:33:39.300]   I wouldn't be surprised.
[01:33:39.300 --> 01:33:41.720]   I wouldn't be surprised.
[01:33:41.720 --> 01:33:44.720]   - I wonder if we already have one,
[01:33:44.720 --> 01:33:46.400]   and it just hasn't been announced.
[01:33:46.400 --> 01:33:48.000]   (both laugh)
[01:33:48.000 --> 01:33:49.960]   We wouldn't know.
[01:33:49.960 --> 01:33:53.920]   How hard is the multi-protein folding problem?
[01:33:53.920 --> 01:33:57.080]   Is that something you've already mentioned,
[01:33:57.080 --> 01:33:58.720]   which is baked into this idea
[01:33:58.720 --> 01:34:01.160]   of greater and greater complexity of proteins?
[01:34:01.160 --> 01:34:03.280]   Like multi-domain proteins,
[01:34:03.280 --> 01:34:08.280]   is that basically become multi-protein complexes?
[01:34:08.280 --> 01:34:10.640]   - Yes, you got it right.
[01:34:10.640 --> 01:34:15.640]   So it has the components of both,
[01:34:15.640 --> 01:34:21.600]   of protein folding and protein-protein interactions.
[01:34:22.560 --> 01:34:24.480]   Because in order for these domains,
[01:34:24.480 --> 01:34:26.520]   I mean, many of these proteins,
[01:34:26.520 --> 01:34:30.140]   actually, they never form a stable structure.
[01:34:30.140 --> 01:34:33.080]   One of my favorite proteins,
[01:34:33.080 --> 01:34:37.760]   and pretty much everyone who works in the,
[01:34:37.760 --> 01:34:41.800]   I know, whom I know who works with proteins,
[01:34:41.800 --> 01:34:44.720]   they always have their favorite proteins.
[01:34:44.720 --> 01:34:47.720]   Right, so one of my favorite proteins,
[01:34:47.720 --> 01:34:49.200]   probably my favorite protein,
[01:34:49.200 --> 01:34:51.500]   the one that I worked when I was a postdoc,
[01:34:51.500 --> 01:34:56.240]   is so-called post-synaptic density 95, PSD95 protein.
[01:34:56.240 --> 01:35:00.520]   So it's one of the key actors
[01:35:00.520 --> 01:35:03.820]   in the majority of neurological processes
[01:35:03.820 --> 01:35:04.880]   at the molecular level.
[01:35:04.880 --> 01:35:10.000]   And essentially, it's a key player
[01:35:10.000 --> 01:35:13.520]   in the post-synaptic density.
[01:35:13.520 --> 01:35:17.200]   So this is the crucial part of the synapse,
[01:35:17.200 --> 01:35:21.400]   where a lot of these chemological processes
[01:35:21.400 --> 01:35:22.480]   are happening.
[01:35:22.480 --> 01:35:26.280]   So it has five domains, right?
[01:35:26.280 --> 01:35:27.480]   So five protein domains.
[01:35:27.480 --> 01:35:30.920]   It's a pretty large proteins,
[01:35:30.920 --> 01:35:33.920]   I think 600 something, I mean,
[01:35:33.920 --> 01:35:40.740]   but the way it's organized itself, it's flexible, right?
[01:35:40.740 --> 01:35:43.900]   So it acts as a scaffold.
[01:35:43.900 --> 01:35:48.900]   So it is used to bring in other proteins.
[01:35:49.340 --> 01:35:54.340]   So they start acting in the orchestrated manner, right?
[01:35:54.340 --> 01:35:58.860]   So, and the type of the shape of this protein,
[01:35:58.860 --> 01:36:02.580]   it's in a way, there are some stable parts of this protein,
[01:36:02.580 --> 01:36:04.540]   but there are some flexible.
[01:36:04.540 --> 01:36:07.740]   And this flexibility is built in,
[01:36:07.740 --> 01:36:09.580]   into the protein in order to become
[01:36:09.580 --> 01:36:13.180]   sort of this multifunctional machine.
[01:36:13.180 --> 01:36:16.540]   - So do you think that kind of thing is also learnable
[01:36:16.540 --> 01:36:19.400]   through the AlphaFold2 kind of approach?
[01:36:19.400 --> 01:36:22.420]   - I mean, the time will tell.
[01:36:22.420 --> 01:36:24.500]   - Is it another level of complexity?
[01:36:24.500 --> 01:36:27.340]   Is it, like how big of a jump in complexity
[01:36:27.340 --> 01:36:28.180]   is that whole thing?
[01:36:28.180 --> 01:36:31.380]   - To me, it's yet another level of complexity,
[01:36:31.380 --> 01:36:35.180]   because when we talk about protein-protein interactions,
[01:36:35.180 --> 01:36:38.860]   and there is actually a different challenge for this,
[01:36:38.860 --> 01:36:40.020]   called CAPRI.
[01:36:40.020 --> 01:36:43.420]   And so this, that is focused specifically
[01:36:43.420 --> 01:36:45.700]   on macromolecular interactions.
[01:36:45.700 --> 01:36:48.560]   Protein-protein, protein-DNA, et cetera.
[01:36:48.560 --> 01:36:53.560]   So, but it's, you know, there are different mechanisms
[01:36:53.560 --> 01:36:58.760]   that govern molecular interactions,
[01:36:58.760 --> 01:37:00.740]   and that need to be picked up,
[01:37:00.740 --> 01:37:03.660]   say by a machine learning algorithm.
[01:37:03.660 --> 01:37:06.540]   Interestingly enough, we actually,
[01:37:06.540 --> 01:37:11.540]   we participated for a few years in this competition.
[01:37:11.540 --> 01:37:14.900]   We typically don't participate in competitions,
[01:37:14.900 --> 01:37:19.220]   I don't know, don't have enough time,
[01:37:19.220 --> 01:37:21.100]   you know, 'cause it's very intensive.
[01:37:21.100 --> 01:37:23.700]   It's a very intensive process.
[01:37:23.700 --> 01:37:28.180]   But we participated back in, you know,
[01:37:28.180 --> 01:37:30.580]   about 10 years ago or so.
[01:37:30.580 --> 01:37:32.660]   And the way we entered this competition,
[01:37:32.660 --> 01:37:35.420]   so we design a scoring function, right?
[01:37:35.420 --> 01:37:38.100]   So the function that evaluates whether or not
[01:37:38.100 --> 01:37:41.900]   your protein-protein interaction is supposed to look like
[01:37:41.900 --> 01:37:43.340]   experimentally solved, right?
[01:37:43.340 --> 01:37:45.900]   So the scoring function is very critical part
[01:37:45.900 --> 01:37:49.820]   of the model prediction.
[01:37:49.820 --> 01:37:52.700]   So we design it to be a machine learning one.
[01:37:52.700 --> 01:37:55.820]   And so it was one of the first
[01:37:55.820 --> 01:37:59.980]   machine learning-based scoring function used in CAPRI.
[01:37:59.980 --> 01:38:03.900]   And, you know, we essentially, you know,
[01:38:03.900 --> 01:38:06.580]   learned what should contribute,
[01:38:06.580 --> 01:38:08.860]   what are the critical components contributing
[01:38:08.860 --> 01:38:10.540]   into the protein-protein interaction.
[01:38:10.540 --> 01:38:13.340]   - So this could be converted into a learning problem
[01:38:13.340 --> 01:38:15.580]   and thereby it could be learned.
[01:38:15.580 --> 01:38:17.020]   - I believe so, yes.
[01:38:17.020 --> 01:38:20.460]   - Do you think AlphaFold2 or something similar to it
[01:38:20.460 --> 01:38:24.300]   from DeepMind or somebody else will be,
[01:38:24.300 --> 01:38:28.660]   will result in a Nobel Prize or multiple Nobel Prizes?
[01:38:28.660 --> 01:38:33.300]   So like, you know, obviously, maybe not so obviously,
[01:38:33.300 --> 01:38:38.020]   you can't give a Nobel Prize to a computer program.
[01:38:38.020 --> 01:38:40.980]   You, at least for now, give it to the designers
[01:38:40.980 --> 01:38:42.140]   of that program.
[01:38:42.140 --> 01:38:46.060]   But do you see one or multiple Nobel Prizes
[01:38:46.060 --> 01:38:51.060]   where AlphaFold2 is like a large percentage
[01:38:51.060 --> 01:38:54.880]   of what that prize is given for?
[01:38:54.880 --> 01:38:58.940]   Would it lead to discoveries at the level of Nobel Prizes?
[01:38:58.940 --> 01:39:05.380]   - I mean, I think we are definitely destined
[01:39:05.380 --> 01:39:08.700]   to see the Nobel Prize becoming sort of,
[01:39:08.700 --> 01:39:12.300]   to be evolving with the evolution of science.
[01:39:12.300 --> 01:39:14.500]   And the evolution of science is such
[01:39:14.500 --> 01:39:17.820]   that it now becomes like really multifaceted, right?
[01:39:17.820 --> 01:39:21.300]   So where you don't really have like a unique discipline,
[01:39:21.300 --> 01:39:25.660]   you have sort of the, a lot of cross-disciplinary talks
[01:39:25.660 --> 01:39:28.460]   in order to achieve sort of, you know,
[01:39:28.460 --> 01:39:32.380]   really big advancements, you know.
[01:39:32.380 --> 01:39:37.380]   So I think, you know, the computational methods
[01:39:37.380 --> 01:39:42.500]   will be acknowledged in one way or another.
[01:39:42.500 --> 01:39:46.860]   And as a matter of fact, you know,
[01:39:46.860 --> 01:39:50.580]   they were first acknowledged back in 2013, right?
[01:39:50.580 --> 01:39:55.580]   Where, you know, the first three people were, you know,
[01:39:55.580 --> 01:39:59.140]   awarded the Nobel Prize for the,
[01:39:59.140 --> 01:40:01.460]   for study of the protein folding, right, the principle.
[01:40:01.460 --> 01:40:03.820]   And, you know, I think all three of them
[01:40:03.820 --> 01:40:06.940]   are computational biophysicists, right?
[01:40:06.940 --> 01:40:11.940]   So, you know, that I think is unavoidable, you know.
[01:40:11.940 --> 01:40:16.560]   It will come with the time.
[01:40:16.560 --> 01:40:23.460]   The fact that, you know, alpha fold and, you know,
[01:40:23.460 --> 01:40:26.340]   similar approaches, 'cause again, it's a matter of time
[01:40:26.340 --> 01:40:31.340]   that people will embrace this, you know, principle.
[01:40:31.700 --> 01:40:34.940]   And we'll see more and more such, you know,
[01:40:34.940 --> 01:40:36.940]   such tools coming into play.
[01:40:36.940 --> 01:40:41.940]   But, you know, these methods will be critical
[01:40:41.940 --> 01:40:47.380]   in a scientific discovery, no doubts about it.
[01:40:47.380 --> 01:40:51.460]   - On the engineering side, maybe a dark question,
[01:40:51.460 --> 01:40:53.380]   but do you think it's possible
[01:40:53.380 --> 01:40:55.140]   to use these machine learning methods
[01:40:55.140 --> 01:40:59.000]   to start to engineer proteins?
[01:40:59.000 --> 01:41:04.000]   And the next question is something quite a few biologists
[01:41:04.000 --> 01:41:07.280]   are against, some are for, for study purposes,
[01:41:07.280 --> 01:41:09.620]   is to engineer viruses.
[01:41:09.620 --> 01:41:11.860]   Do you think machine learning, like something
[01:41:11.860 --> 01:41:14.780]   like alpha fold could be used to engineer viruses?
[01:41:14.780 --> 01:41:16.980]   - So to answering the first question, you know,
[01:41:16.980 --> 01:41:21.660]   it has been, you know, a part of the research
[01:41:21.660 --> 01:41:22.700]   in the protein science.
[01:41:22.700 --> 01:41:25.500]   The protein design is, you know,
[01:41:25.500 --> 01:41:29.160]   is a very prominent areas of research.
[01:41:29.160 --> 01:41:32.000]   Of course, you know, one of the pioneers is David Baker
[01:41:32.000 --> 01:41:34.900]   and Rosetta algorithm that, you know,
[01:41:34.900 --> 01:41:38.220]   essentially was doing the de novo design
[01:41:38.220 --> 01:41:41.540]   and was used to design new proteins, you know.
[01:41:41.540 --> 01:41:44.200]   - And design of proteins means design of function.
[01:41:44.200 --> 01:41:47.320]   So like when you design a protein, you can control,
[01:41:47.320 --> 01:41:49.080]   I mean, the whole point of a protein,
[01:41:49.080 --> 01:41:52.200]   with the protein structure comes a function,
[01:41:52.200 --> 01:41:53.720]   like it's doing something.
[01:41:53.720 --> 01:41:54.560]   - Correct, correct.
[01:41:54.560 --> 01:41:56.240]   - Or design different things.
[01:41:56.240 --> 01:41:58.160]   - So you can, yeah, so you can, well,
[01:41:58.160 --> 01:42:00.680]   you can look at the proteins from the functional perspective,
[01:42:00.680 --> 01:42:02.720]   you can also look at the proteins
[01:42:02.720 --> 01:42:04.200]   from the structural perspective, right?
[01:42:04.200 --> 01:42:05.700]   So the structural building blocks.
[01:42:05.700 --> 01:42:08.880]   So if you want to have a building block of a certain shape,
[01:42:08.880 --> 01:42:11.160]   you can try to achieve it by, you know,
[01:42:11.160 --> 01:42:13.160]   introducing a new protein sequence
[01:42:13.160 --> 01:42:17.240]   and predicting, you know, how it will fold.
[01:42:17.240 --> 01:42:22.040]   So with that, I mean, it's a natural,
[01:42:22.040 --> 01:42:27.040]   one of the natural applications of these algorithms.
[01:42:27.040 --> 01:42:32.480]   Now, talking about engineering a virus.
[01:42:32.480 --> 01:42:35.120]   - With machine learning.
[01:42:35.120 --> 01:42:36.360]   - With machine learning, right?
[01:42:36.360 --> 01:42:41.360]   So, well, you know, so luckily for us,
[01:42:41.360 --> 01:42:46.680]   I mean, we don't have that much data, right?
[01:42:46.680 --> 01:42:50.120]   We actually, right now, one of the projects
[01:42:50.120 --> 01:42:53.680]   that we are carrying on in the lab
[01:42:53.680 --> 01:42:56.960]   is we're trying to develop a machine learning algorithm
[01:42:56.960 --> 01:43:00.040]   that determines whether or not
[01:43:00.040 --> 01:43:02.680]   the current strain is pathogenic.
[01:43:02.680 --> 01:43:03.760]   And-- - The current strain
[01:43:03.760 --> 01:43:04.600]   of the coronavirus.
[01:43:04.600 --> 01:43:07.720]   - Of the virus, I mean, so there are applications
[01:43:07.720 --> 01:43:11.440]   to coronaviruses because we have strains of SARS-CoV-2,
[01:43:11.440 --> 01:43:14.600]   also SARS-CoV, MERS, that are pathogenic,
[01:43:14.600 --> 01:43:17.640]   but we also have strains of other coronaviruses
[01:43:17.640 --> 01:43:20.440]   that are not pathogenic, I mean,
[01:43:20.440 --> 01:43:25.440]   the common cold viruses and some other ones, right?
[01:43:25.440 --> 01:43:29.000]   So-- - Pathogenic meaning spreading.
[01:43:29.000 --> 01:43:33.760]   - Pathogenic meaning it's actually inflicting damage.
[01:43:33.760 --> 01:43:35.320]   Correct.
[01:43:35.320 --> 01:43:39.720]   There are also some seasonal versus pandemic strains
[01:43:39.720 --> 01:43:41.760]   of influenza, right?
[01:43:41.760 --> 01:43:45.520]   And determining what are the molecular determinant, right,
[01:43:45.520 --> 01:43:48.320]   so that are built in into the protein sequence,
[01:43:48.320 --> 01:43:50.720]   into the gene sequence, right?
[01:43:50.720 --> 01:43:53.000]   So, and whether or not the machine learning
[01:43:53.000 --> 01:43:58.000]   can determine those components, right?
[01:43:58.000 --> 01:44:00.680]   - Oh, interesting, so like using machine learning,
[01:44:00.680 --> 01:44:03.400]   that's really interesting, to given,
[01:44:03.400 --> 01:44:06.800]   the input is like, what, the entire--
[01:44:06.800 --> 01:44:07.640]   - Protein sequence.
[01:44:07.640 --> 01:44:09.760]   - The protein sequence, and then determine
[01:44:09.760 --> 01:44:12.360]   if this thing is gonna be able to do damage
[01:44:12.360 --> 01:44:14.640]   to a biological system.
[01:44:14.640 --> 01:44:15.920]   - Yeah.
[01:44:15.920 --> 01:44:17.480]   So, I mean-- - It's good machine learning,
[01:44:17.480 --> 01:44:19.720]   you're saying we don't have enough data for that?
[01:44:19.720 --> 01:44:22.640]   - I mean, for this specific one, we do.
[01:44:22.640 --> 01:44:25.560]   We might actually have to back up on this,
[01:44:25.560 --> 01:44:27.240]   'cause we're still in the process.
[01:44:27.240 --> 01:44:31.680]   There was one work that appeared in bio-archive
[01:44:31.680 --> 01:44:35.480]   by Eugene Kunin, who is one of these pioneers
[01:44:35.480 --> 01:44:40.480]   in evolutionary genomics, and they tried to look at this,
[01:44:41.760 --> 01:44:45.080]   but the methods were sort of standard,
[01:44:45.080 --> 01:44:50.200]   supervised learning methods, and now the question is,
[01:44:50.200 --> 01:44:56.320]   can you advance it further by using not so standard methods?
[01:44:56.320 --> 01:45:02.680]   So, there's obviously a lot of hope in transfer learning,
[01:45:02.680 --> 01:45:06.200]   where you can actually try to transfer the information
[01:45:06.200 --> 01:45:07.680]   that the machine learning learns
[01:45:07.680 --> 01:45:11.320]   about the proper protein sequences, right?
[01:45:11.320 --> 01:45:16.320]   And so, there is some promise in going this direction,
[01:45:16.320 --> 01:45:20.440]   but if we have this, it would be extremely useful,
[01:45:20.440 --> 01:45:22.960]   because then we could essentially forecast
[01:45:22.960 --> 01:45:26.280]   the potential mutations that would make a current strain
[01:45:26.280 --> 01:45:27.560]   more or less pathogenic.
[01:45:27.560 --> 01:45:31.120]   - Anticipate them from a vaccine development,
[01:45:31.120 --> 01:45:34.520]   for the treatment, antiviral drug development.
[01:45:34.520 --> 01:45:36.840]   - That would be a very crucial task.
[01:45:36.840 --> 01:45:41.840]   - But you could also use that system to then say,
[01:45:41.840 --> 01:45:45.240]   how would we potentially modify this virus
[01:45:45.240 --> 01:45:47.160]   to make it more pathogenic?
[01:45:47.160 --> 01:45:50.240]   - That's true, that's true.
[01:45:50.240 --> 01:45:55.240]   I mean, you know, again, the hope is, well, several things.
[01:45:55.240 --> 01:46:04.320]   So, one is that, even if you design a sequence, right?
[01:46:06.760 --> 01:46:11.760]   So, to carry out the actual experimental biology,
[01:46:11.760 --> 01:46:16.000]   to ensure that all the components working,
[01:46:16.000 --> 01:46:19.080]   you know, is a completely different matter.
[01:46:19.080 --> 01:46:19.920]   - Difficult process.
[01:46:19.920 --> 01:46:24.400]   - Yes, then we've seen in the past,
[01:46:24.400 --> 01:46:27.680]   there could be some regulation of the moment
[01:46:27.680 --> 01:46:30.440]   the scientific community recognizes
[01:46:30.440 --> 01:46:34.600]   that it's now becoming no longer a sort of a fun puzzle
[01:46:34.600 --> 01:46:36.640]   for machine learning.
[01:46:36.640 --> 01:46:37.840]   - Could be a weapon.
[01:46:37.840 --> 01:46:40.440]   - Yeah, so then there might be some regulation.
[01:46:40.440 --> 01:46:44.760]   So, I think back in, what, 2015,
[01:46:44.760 --> 01:46:49.520]   there was an issue on regulating the research
[01:46:49.520 --> 01:46:52.480]   on influenza strains, right?
[01:46:52.480 --> 01:46:57.480]   So, there were several groups use sort of mutation analysis
[01:46:57.480 --> 01:47:01.820]   to determine whether or not this strain will jump
[01:47:01.820 --> 01:47:03.280]   from one species to another.
[01:47:03.280 --> 01:47:06.520]   And I think there was like a half a year moratorium
[01:47:06.520 --> 01:47:09.760]   on the research, on the paper published,
[01:47:09.760 --> 01:47:13.600]   until scientists analyzed it
[01:47:13.600 --> 01:47:16.440]   and decided that it's actually safe.
[01:47:16.440 --> 01:47:17.600]   - I forgot what that's called,
[01:47:17.600 --> 01:47:20.040]   something of function, test of function.
[01:47:20.040 --> 01:47:21.280]   - Gain of function, loss of function.
[01:47:21.280 --> 01:47:23.040]   - Gain of function, yeah, gain of function,
[01:47:23.040 --> 01:47:24.980]   loss of function, that's right, sorry.
[01:47:24.980 --> 01:47:29.640]   It's like, let's watch this thing mutate for a while
[01:47:29.640 --> 01:47:33.760]   to see what kind of things we can observe.
[01:47:33.760 --> 01:47:37.240]   I guess, I'm not so much worried about that kind of research
[01:47:37.240 --> 01:47:38.600]   if there's a lot of regulation
[01:47:38.600 --> 01:47:40.160]   and if it's done very well
[01:47:40.160 --> 01:47:42.760]   and with competence and seriously.
[01:47:42.760 --> 01:47:45.680]   I am more worried about kind of this,
[01:47:45.680 --> 01:47:49.600]   the underlying aspect of this question
[01:47:49.600 --> 01:47:51.280]   is more like 50 years from now.
[01:47:51.280 --> 01:47:54.940]   Speaking to the Drake equation,
[01:47:54.940 --> 01:47:57.280]   one of the parameters in the Drake equation
[01:47:57.280 --> 01:47:59.840]   is how long civilizations last.
[01:47:59.840 --> 01:48:03.880]   And that seems to be the most important value, actually,
[01:48:03.880 --> 01:48:06.160]   for calculating if there's other alien
[01:48:06.160 --> 01:48:08.080]   intelligent civilizations out there.
[01:48:08.080 --> 01:48:11.000]   That's where there's most variability.
[01:48:11.000 --> 01:48:15.120]   Assuming, like if life, if that percentage
[01:48:15.120 --> 01:48:19.400]   that life can emerge is like not zero,
[01:48:19.400 --> 01:48:21.280]   like if we're super unique,
[01:48:21.280 --> 01:48:23.980]   then it's the how long we last
[01:48:23.980 --> 01:48:26.200]   is basically the most important thing.
[01:48:26.200 --> 01:48:29.000]   So from a selfish perspective,
[01:48:29.000 --> 01:48:32.040]   but also from a Drake equation perspective,
[01:48:32.040 --> 01:48:35.040]   I'm worried about our civilization lasting.
[01:48:35.040 --> 01:48:37.640]   And you kind of think about all the ways
[01:48:37.640 --> 01:48:39.120]   in which machine learning can be used
[01:48:39.120 --> 01:48:44.120]   to design greater weapons of destruction.
[01:48:44.120 --> 01:48:48.600]   And I mean, one way to ask that,
[01:48:48.600 --> 01:48:50.560]   if you look sort of 50 years from now,
[01:48:50.560 --> 01:48:51.680]   100 years from now,
[01:48:51.680 --> 01:48:55.800]   would you be more worried about natural pandemics
[01:48:55.800 --> 01:48:57.560]   or engineered pandemics?
[01:48:57.560 --> 01:49:02.640]   Like who is the better designer of viruses,
[01:49:02.640 --> 01:49:05.980]   nature or humans, if we look down the line?
[01:49:05.980 --> 01:49:08.840]   - I think, in my view,
[01:49:08.840 --> 01:49:12.680]   I would still be worried about the natural pandemics,
[01:49:12.680 --> 01:49:15.600]   simply because, I mean, the capacity
[01:49:15.600 --> 01:49:20.720]   of the nature producing this.
[01:49:20.720 --> 01:49:22.720]   - It does a pretty good job, right?
[01:49:22.720 --> 01:49:23.560]   - Yes.
[01:49:23.560 --> 01:49:25.320]   - The motivation for using virus,
[01:49:25.320 --> 01:49:29.060]   engineering viruses as a weapon is a weird one,
[01:49:29.060 --> 01:49:31.520]   because maybe you can correct me on this,
[01:49:31.520 --> 01:49:35.640]   but it seems very difficult to target a virus, right?
[01:49:35.640 --> 01:49:38.440]   The whole point of a weapon, the way a rocket works,
[01:49:38.440 --> 01:49:40.120]   if a starting point, you have an end point,
[01:49:40.120 --> 01:49:42.360]   and you're trying to hit a target,
[01:49:42.360 --> 01:49:44.680]   to hit a target with a virus is very difficult.
[01:49:44.680 --> 01:49:47.040]   It's basically just, right?
[01:49:47.040 --> 01:49:50.100]   It's the target would be the human species.
[01:49:50.100 --> 01:49:52.920]   Oh man.
[01:49:52.920 --> 01:49:54.800]   - Yeah, I have a hope in us,
[01:49:54.800 --> 01:49:58.240]   I'm forever optimistic that we will not,
[01:49:58.240 --> 01:50:02.120]   there's insufficient evil in the world
[01:50:02.120 --> 01:50:04.560]   to lead to that kind of destruction.
[01:50:04.560 --> 01:50:07.760]   - Well, I also hope that, I mean, that's what we see.
[01:50:07.760 --> 01:50:11.760]   I mean, with the way we are getting connected,
[01:50:11.760 --> 01:50:14.440]   the world is getting connected,
[01:50:14.440 --> 01:50:19.440]   I think it helps for the world to become more transparent.
[01:50:19.440 --> 01:50:22.560]   - Yeah.
[01:50:22.560 --> 01:50:27.120]   - So the information spread is,
[01:50:27.120 --> 01:50:31.640]   I think it's one of the key things for the society
[01:50:31.640 --> 01:50:35.600]   to become more balanced.
[01:50:35.600 --> 01:50:36.440]   - Yeah. - One way or another.
[01:50:36.440 --> 01:50:38.360]   - This is something that people disagree with me on,
[01:50:38.360 --> 01:50:41.920]   but I do think that the kind of secrecy
[01:50:41.920 --> 01:50:43.480]   that governments have,
[01:50:43.480 --> 01:50:47.060]   so you're kind of speaking more to the other aspects,
[01:50:47.060 --> 01:50:49.700]   like research community being more open,
[01:50:49.700 --> 01:50:52.160]   companies are being more open,
[01:50:52.160 --> 01:50:53.920]   government is still like,
[01:50:53.920 --> 01:50:57.880]   we're talking about like military secrets.
[01:50:57.880 --> 01:51:01.440]   I think military secrets of the kind
[01:51:01.440 --> 01:51:03.760]   that could destroy the world
[01:51:03.760 --> 01:51:07.320]   will become also a thing of the 20th century.
[01:51:07.320 --> 01:51:09.360]   It'll become more and more open.
[01:51:09.360 --> 01:51:10.200]   - Yeah.
[01:51:10.200 --> 01:51:13.240]   - I think nations will lose power in the 21st century,
[01:51:13.240 --> 01:51:16.000]   like lose sufficient power towards secrecies.
[01:51:16.000 --> 01:51:18.900]   Transparency is more beneficial than secrecy,
[01:51:18.900 --> 01:51:21.200]   but of course it's not obvious.
[01:51:21.200 --> 01:51:23.400]   Let's hope so, let's hope so,
[01:51:23.400 --> 01:51:28.400]   that the governments will become more transparent.
[01:51:28.400 --> 01:51:35.280]   - So we last talked, I think, in March or April.
[01:51:35.280 --> 01:51:36.760]   What have you learned?
[01:51:36.760 --> 01:51:40.480]   How has your philosophical, psychological,
[01:51:40.480 --> 01:51:43.800]   biological worldview changed since then?
[01:51:43.800 --> 01:51:46.120]   Or you've been studying it nonstop
[01:51:46.120 --> 01:51:48.900]   from a computational biology perspective.
[01:51:48.900 --> 01:51:50.420]   How has your understanding and thoughts
[01:51:50.420 --> 01:51:53.000]   about this virus changed over those months,
[01:51:53.000 --> 01:51:54.440]   from the beginning to today?
[01:51:54.440 --> 01:51:58.160]   - One thing that I was really amazed
[01:51:58.160 --> 01:52:03.120]   at how efficient the scientific community was.
[01:52:03.120 --> 01:52:08.120]   I mean, and even just judging on this very narrow domain
[01:52:08.120 --> 01:52:12.520]   of protein structure,
[01:52:12.520 --> 01:52:16.600]   understanding the structural characterization
[01:52:16.600 --> 01:52:19.880]   of this virus from the components point of view,
[01:52:19.880 --> 01:52:21.480]   whole virus point of view.
[01:52:21.480 --> 01:52:26.040]   If you look at SARS, right,
[01:52:26.040 --> 01:52:28.620]   the something that happened, you know,
[01:52:28.620 --> 01:52:34.040]   less than 20, but close enough, 20 years ago.
[01:52:34.040 --> 01:52:38.500]   And you see what, when it happened,
[01:52:38.500 --> 01:52:42.460]   what was sort of the response by the scientific community.
[01:52:42.460 --> 01:52:47.100]   You see that the structural characterizations did occur,
[01:52:47.100 --> 01:52:51.640]   but it took several years, right?
[01:52:51.640 --> 01:52:54.920]   Now, the things that took several years,
[01:52:54.920 --> 01:52:56.880]   it's a matter of months, right?
[01:52:56.880 --> 01:53:01.620]   So we see that, you know, the research pop up.
[01:53:01.620 --> 01:53:03.960]   We are at the unprecedented level
[01:53:03.960 --> 01:53:06.000]   in terms of the sequencing, right?
[01:53:06.000 --> 01:53:11.000]   Never before we had a single virus sequenced so many times.
[01:53:11.000 --> 01:53:17.040]   You know, so which allows us to actually,
[01:53:17.040 --> 01:53:22.040]   to trace very precisely the sort of the evolutionary nature
[01:53:22.040 --> 01:53:25.780]   of this virus, what happens.
[01:53:25.780 --> 01:53:28.200]   And it's not just the, you know,
[01:53:28.200 --> 01:53:31.780]   this virus independently of everything.
[01:53:31.780 --> 01:53:34.240]   It's, you know, it's the, you know,
[01:53:34.240 --> 01:53:36.520]   the sequence of this virus linked,
[01:53:36.520 --> 01:53:39.940]   anchored to the specific geographic place,
[01:53:39.940 --> 01:53:42.160]   to specific people, because, you know,
[01:53:42.160 --> 01:53:47.160]   our genotype influences also, you know,
[01:53:47.160 --> 01:53:48.900]   the evolution of this, you know,
[01:53:48.900 --> 01:53:53.900]   it's always a host pathogen co-evolution that, you know,
[01:53:53.900 --> 01:53:55.400]   occurs.
[01:53:55.400 --> 01:53:58.960]   - It'd be cool if we also had a lot more data about,
[01:53:58.960 --> 01:54:01.280]   sort of, the spread of this virus.
[01:54:01.280 --> 01:54:05.120]   Not maybe, well, it'd be nice if we had it
[01:54:05.120 --> 01:54:08.120]   for like contact tracing purposes for this virus,
[01:54:08.120 --> 01:54:09.700]   but it'd be also nice if we had it
[01:54:09.700 --> 01:54:11.960]   for the study for future viruses,
[01:54:11.960 --> 01:54:13.600]   to be able to respond and so on.
[01:54:13.600 --> 01:54:16.040]   But it's already nice that we have geographical data
[01:54:16.040 --> 01:54:18.240]   and the basic data from individual humans.
[01:54:18.240 --> 01:54:19.080]   - Exactly.
[01:54:19.080 --> 01:54:24.080]   No, I think contact tracing is obviously a key component
[01:54:24.080 --> 01:54:28.020]   in understanding the spread of this virus.
[01:54:28.020 --> 01:54:31.720]   There is also, there is a number of challenges, right?
[01:54:31.720 --> 01:54:33.760]   So XPRICE is one of them.
[01:54:33.760 --> 01:54:38.760]   We, you know, just recently, you know,
[01:54:38.760 --> 01:54:40.880]   took a part of this competition.
[01:54:40.880 --> 01:54:45.880]   It's the prediction of the number of infections
[01:54:45.880 --> 01:54:47.880]   in different regions.
[01:54:47.880 --> 01:54:53.880]   So, and, you know, obviously the AI is the main topic
[01:54:53.880 --> 01:54:56.280]   in those predictions.
[01:54:56.280 --> 01:54:58.840]   - Yeah, but it's still the data.
[01:54:58.840 --> 01:55:00.320]   I mean, that's a competition,
[01:55:00.320 --> 01:55:05.320]   but the data is weak on the training.
[01:55:05.320 --> 01:55:07.620]   Like, it's great.
[01:55:07.620 --> 01:55:09.320]   It's much more than probably before,
[01:55:09.320 --> 01:55:12.840]   but like, it would be nice if it was like really rich.
[01:55:12.840 --> 01:55:16.760]   Like I talked to Michael Mina from Harvard.
[01:55:16.760 --> 01:55:19.000]   I mean, he dreams that the community comes together
[01:55:19.000 --> 01:55:22.960]   with like a weather map to where a viruses, right?
[01:55:22.960 --> 01:55:27.840]   Like really high resolution sensors on like how,
[01:55:27.840 --> 01:55:29.880]   from person to person, the viruses that travel,
[01:55:29.880 --> 01:55:32.000]   all the different kinds of viruses, right?
[01:55:32.000 --> 01:55:34.620]   Because there's a ton of them.
[01:55:34.620 --> 01:55:36.800]   And then you'd be able to tell the story
[01:55:36.800 --> 01:55:41.200]   that you've spoken about of the evolution of these viruses,
[01:55:41.200 --> 01:55:44.800]   like day-to-day mutations that are occurring.
[01:55:44.800 --> 01:55:46.040]   I mean, that'd be fascinating,
[01:55:46.040 --> 01:55:48.680]   just from a perspective of study
[01:55:48.680 --> 01:55:50.680]   and from the perspective of being able to respond
[01:55:50.680 --> 01:55:51.640]   to future pandemics.
[01:55:51.640 --> 01:55:53.940]   That's ultimately what I'm worried about.
[01:55:53.940 --> 01:55:56.440]   People love books.
[01:55:56.440 --> 01:56:01.160]   Is there some three or whatever number of books,
[01:56:01.160 --> 01:56:02.960]   technical fiction, philosophical,
[01:56:02.960 --> 01:56:06.240]   that brought you joy in life,
[01:56:06.240 --> 01:56:07.760]   had an impact on your life,
[01:56:07.760 --> 01:56:11.360]   and maybe some that you would recommend others?
[01:56:11.360 --> 01:56:13.640]   - So I'll give you three very different books,
[01:56:13.640 --> 01:56:15.840]   and I also have a special runner-up.
[01:56:15.840 --> 01:56:18.160]   - Honorable mention.
[01:56:18.160 --> 01:56:22.000]   - I mean, it's an audio book,
[01:56:22.000 --> 01:56:25.520]   and there's some specific reason behind it.
[01:56:25.520 --> 01:56:28.360]   So the first book is something
[01:56:28.360 --> 01:56:32.480]   that sort of impacted my earlier stage of life,
[01:56:32.480 --> 01:56:36.240]   and I'm probably not gonna be very original here.
[01:56:36.240 --> 01:56:39.120]   It's "Bulgakov's Master and Margarita."
[01:56:39.120 --> 01:56:41.280]   So that's probably, you know.
[01:56:41.280 --> 01:56:43.880]   - Well, not for a Russian, maybe it's not super original,
[01:56:43.880 --> 01:56:47.640]   but it's a really powerful book for even in English.
[01:56:47.640 --> 01:56:49.160]   So I read it in English, so.
[01:56:49.160 --> 01:56:51.440]   - It is incredibly powerful,
[01:56:51.440 --> 01:56:55.440]   and I mean, it's the way it ends, right?
[01:56:55.440 --> 01:56:58.640]   So I still have goosebumps
[01:56:58.640 --> 01:57:01.520]   when I read the very last sort of,
[01:57:01.520 --> 01:57:03.120]   it's called prologue,
[01:57:03.120 --> 01:57:05.800]   where it's just so powerful.
[01:57:05.800 --> 01:57:07.320]   - What impact did it have on you?
[01:57:07.320 --> 01:57:09.280]   What ideas, what insights did you get from it?
[01:57:09.280 --> 01:57:12.200]   - I was just taken by, you know,
[01:57:12.200 --> 01:57:17.200]   by the fact that you have those parallel lives
[01:57:17.200 --> 01:57:23.160]   apart from many centuries, right?
[01:57:23.160 --> 01:57:26.880]   And somehow they got sort of intertwined
[01:57:26.880 --> 01:57:28.960]   into one story.
[01:57:28.960 --> 01:57:33.840]   And that, to me, was fascinating.
[01:57:33.840 --> 01:57:38.840]   And, you know, of course, the romantic part of this book
[01:57:38.840 --> 01:57:41.760]   is like, it's not just romance,
[01:57:41.760 --> 01:57:45.840]   it's like the romance empowered by sort of magic, right?
[01:57:45.840 --> 01:57:50.840]   And maybe on top of that, you have some irony,
[01:57:50.840 --> 01:57:53.400]   which is unavoidable, right?
[01:57:53.400 --> 01:57:56.440]   Because it was that, you know, the Soviet time.
[01:57:56.440 --> 01:57:58.560]   - But it's very, it's deeply Russian.
[01:57:58.560 --> 01:58:03.560]   So that's the wit, the humor, the pain, the love,
[01:58:03.560 --> 01:58:06.200]   all of that is one of the books
[01:58:06.200 --> 01:58:10.280]   that kind of captures something about Russian culture
[01:58:10.280 --> 01:58:12.560]   that people outside of Russia should probably read.
[01:58:12.560 --> 01:58:13.400]   - I agree.
[01:58:13.400 --> 01:58:14.240]   - What's the second one?
[01:58:14.240 --> 01:58:18.240]   - So the second one is, again, another one that,
[01:58:18.240 --> 01:58:21.880]   it happened, I read it later in my life.
[01:58:21.880 --> 01:58:25.600]   I think I read it first time when I was a,
[01:58:26.600 --> 01:58:27.760]   a graduate student.
[01:58:27.760 --> 01:58:30.880]   And that's the Solzhenitsyn's "Cancer Ward."
[01:58:30.880 --> 01:58:36.440]   That is amazingly powerful book.
[01:58:36.440 --> 01:58:37.640]   It's-- - What is it about?
[01:58:37.640 --> 01:58:41.640]   - It's about, I mean, essentially based on,
[01:58:41.640 --> 01:58:44.760]   you know, Solzhenitsyn was diagnosed with cancer
[01:58:44.760 --> 01:58:49.480]   when he was reasonably young and he made a full recovery.
[01:58:49.480 --> 01:58:54.480]   But, you know, so this is about a person
[01:58:54.480 --> 01:58:59.360]   who was sentenced for life in one of these, you know, camps.
[01:58:59.360 --> 01:59:03.680]   And he had some cancer.
[01:59:03.680 --> 01:59:06.840]   So he was, you know, transported back
[01:59:06.840 --> 01:59:10.000]   to one of these Soviet republics,
[01:59:10.000 --> 01:59:13.480]   I think, you know, South Asian republics.
[01:59:13.480 --> 01:59:18.480]   And the book is about, you know,
[01:59:19.820 --> 01:59:24.820]   his experience being a prisoner,
[01:59:24.820 --> 01:59:29.820]   being a, you know, a patient in the cancer clinic,
[01:59:29.820 --> 01:59:32.380]   in a cancer ward, surrounded by people,
[01:59:32.380 --> 01:59:35.340]   many of which die, right?
[01:59:35.340 --> 01:59:41.580]   But in the way, you know, the way it reads,
[01:59:41.580 --> 01:59:43.140]   I mean, first of all, later on,
[01:59:43.140 --> 01:59:47.580]   I read the accounts of the doctors
[01:59:47.580 --> 01:59:51.780]   who described these, you know, the experiences,
[01:59:51.780 --> 01:59:58.740]   in the book, by the patient as incredibly accurate, right?
[01:59:58.740 --> 02:00:03.340]   So, you know, I read that there was some doctors saying
[02:00:03.340 --> 02:00:07.140]   that, you know, every single doctor should read this book
[02:00:07.140 --> 02:00:10.660]   to understand what the patient feels.
[02:00:10.660 --> 02:00:15.660]   But, you know, again, as many of the Solzhenitsyn's books,
[02:00:17.060 --> 02:00:19.540]   it has multiple levels of complexity.
[02:00:19.540 --> 02:00:24.540]   And obviously, you know, if you look above the cancer
[02:00:24.540 --> 02:00:29.820]   and the patient, I mean, the tumor that was growing
[02:00:29.820 --> 02:00:35.340]   and then disappeared in his body with some consequences,
[02:00:35.340 --> 02:00:42.700]   I mean, this is, you know, allegorically the Soviet,
[02:00:45.300 --> 02:00:48.020]   and, you know, and he actually, he agreed,
[02:00:48.020 --> 02:00:51.020]   you know, when he was asked, he said that this is
[02:00:51.020 --> 02:00:53.940]   what made him think about this, you know,
[02:00:53.940 --> 02:00:56.140]   how to combine these experiences.
[02:00:56.140 --> 02:01:00.140]   Him being a part of the, you know, of the Soviet regime,
[02:01:00.140 --> 02:01:04.020]   also being a part of the, you know,
[02:01:04.020 --> 02:01:08.020]   of someone sent to the Gulag camp, right?
[02:01:08.020 --> 02:01:12.700]   And also someone who experienced cancer in his life.
[02:01:12.700 --> 02:01:16.580]   You know, the Gulag Archipelago and this book,
[02:01:16.580 --> 02:01:20.300]   these are the works that actually made him,
[02:01:20.300 --> 02:01:22.860]   you know, receive a Nobel Prize.
[02:01:22.860 --> 02:01:25.940]   But, you know, to me, I've, you know,
[02:01:25.940 --> 02:01:30.940]   I've read other, you know, books by Solzhenitsyn.
[02:01:30.940 --> 02:01:34.780]   This one is, to me, is the most powerful one.
[02:01:34.780 --> 02:01:37.100]   - And by the way, both this one and the previous one,
[02:01:37.100 --> 02:01:38.700]   you read in Russian?
[02:01:38.700 --> 02:01:40.280]   - Yes, yes.
[02:01:40.280 --> 02:01:44.460]   So now there is, the third book is an English book,
[02:01:44.460 --> 02:01:45.700]   and it's completely different.
[02:01:45.700 --> 02:01:48.760]   So, you know, we're switching the gears completely.
[02:01:48.760 --> 02:01:52.260]   So this is the book, which it's not even a book,
[02:01:52.260 --> 02:01:56.940]   it's an essay by Jonathan Neumann.
[02:01:56.940 --> 02:01:57.780]   - Oh, wow.
[02:01:57.780 --> 02:01:59.660]   - Called "The Computer and the Brain."
[02:01:59.660 --> 02:02:03.980]   And that was the book he was writing,
[02:02:03.980 --> 02:02:07.760]   knowing that he was dying of cancer.
[02:02:07.760 --> 02:02:09.860]   So the book was released back,
[02:02:09.860 --> 02:02:12.340]   it's a very thin book, right?
[02:02:12.340 --> 02:02:17.340]   But the power, the intellectual power
[02:02:17.340 --> 02:02:21.320]   in this book, in this essay is incredible.
[02:02:21.320 --> 02:02:24.320]   I mean, you probably know that von Neumann
[02:02:24.320 --> 02:02:28.680]   is considered to be one of the biggest thinkers, right?
[02:02:28.680 --> 02:02:32.500]   So his intellectual power was incredible, right?
[02:02:32.500 --> 02:02:36.500]   And you can actually feel this power in this book
[02:02:36.500 --> 02:02:38.220]   where, you know, the person is writing
[02:02:38.220 --> 02:02:41.340]   knowing that he will be, you know, he will die.
[02:02:41.340 --> 02:02:44.260]   The book actually got published only after his death,
[02:02:44.260 --> 02:02:48.220]   back in 1958, he died in 1957.
[02:02:48.220 --> 02:02:53.060]   And, but, so he tried to put as many ideas
[02:02:53.060 --> 02:02:58.060]   that, you know, he still, you know, hadn't realized.
[02:02:58.060 --> 02:03:04.620]   And, you know, so this book is very difficult to read
[02:03:04.780 --> 02:03:09.780]   because, you know, every single paragraph is just compact.
[02:03:09.780 --> 02:03:13.620]   You know, it's filled with these ideas
[02:03:13.620 --> 02:03:15.960]   and, you know, the ideas are incredible.
[02:03:15.960 --> 02:03:19.900]   You know, nowadays, you know, so he tried
[02:03:19.900 --> 02:03:24.900]   to put the parallels between the brain computing power,
[02:03:24.900 --> 02:03:28.740]   the neural system, and the computers, you know,
[02:03:28.740 --> 02:03:29.580]   as they were understood.
[02:03:29.580 --> 02:03:31.380]   - Do you remember what year he was working on this?
[02:03:31.380 --> 02:03:32.420]   Like approximately?
[02:03:32.420 --> 02:03:33.720]   - '57. - '57.
[02:03:33.720 --> 02:03:36.420]   - So that was right during his, you know,
[02:03:36.420 --> 02:03:39.780]   when he was diagnosed with cancer and he was essentially.
[02:03:39.780 --> 02:03:42.740]   - Yeah, he's one of those, there's a few folks
[02:03:42.740 --> 02:03:45.540]   people mention, I think Ed Witten is another,
[02:03:45.540 --> 02:03:49.080]   that like, everyone that meets them,
[02:03:49.080 --> 02:03:51.820]   they say he's just an intellectual powerhouse.
[02:03:51.820 --> 02:03:52.640]   - Yes.
[02:03:52.640 --> 02:03:54.340]   - Okay, so who's the honorable mention?
[02:03:54.340 --> 02:03:56.620]   - So, so, so, and this is, I mean,
[02:03:56.620 --> 02:03:59.500]   the reason I put it sort of in this separate section
[02:03:59.500 --> 02:04:04.500]   because this is a book that I recently listened to.
[02:04:04.500 --> 02:04:09.240]   So it's an audio book, and this is a book
[02:04:09.240 --> 02:04:12.560]   called Lab Girl by Hope Jarren.
[02:04:12.560 --> 02:04:16.480]   So Hope Jarren, she is a scientist,
[02:04:16.480 --> 02:04:20.440]   she's a geochemist that essentially studies
[02:04:20.440 --> 02:04:27.040]   the fossil plants and so she uses the fossil plants,
[02:04:29.000 --> 02:04:33.560]   the chemical analysis to understand what was the climate
[02:04:33.560 --> 02:04:38.320]   back in, you know, in thousand years,
[02:04:38.320 --> 02:04:40.280]   hundreds of thousands of years ago.
[02:04:40.280 --> 02:04:45.280]   And so something that incredibly touched me by this book,
[02:04:45.280 --> 02:04:48.400]   it was narrated by the author.
[02:04:48.400 --> 02:04:51.680]   - Nice, excellent. - And it's an incredibly
[02:04:51.680 --> 02:04:54.080]   personal story, incredibly.
[02:04:54.080 --> 02:04:58.720]   So certain parts of the book you could actually
[02:04:58.720 --> 02:05:00.100]   hear the author crying.
[02:05:00.100 --> 02:05:03.920]   And that, to me, I mean, I never experienced
[02:05:03.920 --> 02:05:06.400]   anything like this, you know, reading the book.
[02:05:06.400 --> 02:05:10.200]   But it was like, you know, the connection
[02:05:10.200 --> 02:05:12.720]   between you and the author.
[02:05:12.720 --> 02:05:17.240]   And I think this is, you know, this is really a must read,
[02:05:17.240 --> 02:05:22.240]   but even better, a must listen to audio book
[02:05:22.240 --> 02:05:26.880]   for anyone who wants to learn about sort of, you know,
[02:05:26.880 --> 02:05:30.920]   academia, science, research in general.
[02:05:30.920 --> 02:05:32.960]   Because it's a very personal account
[02:05:32.960 --> 02:05:36.760]   about her becoming a scientist.
[02:05:36.760 --> 02:05:42.980]   - So we're just before New Year's, you know,
[02:05:42.980 --> 02:05:46.560]   we talked a lot about some difficult topics,
[02:05:46.560 --> 02:05:48.120]   the viruses and so on.
[02:05:48.120 --> 02:05:51.840]   Do you have some exciting things you're looking forward
[02:05:51.840 --> 02:05:56.120]   to in 2021, some New Year's resolutions,
[02:05:56.120 --> 02:06:01.120]   maybe silly or fun, or something very important
[02:06:01.120 --> 02:06:04.720]   and fundamental to the world of science
[02:06:04.720 --> 02:06:06.680]   or something completely unimportant?
[02:06:06.680 --> 02:06:11.160]   - Well, I'm definitely looking forward
[02:06:11.160 --> 02:06:15.640]   towards, you know, things becoming normal, right?
[02:06:15.640 --> 02:06:19.840]   So yes, so I really miss traveling.
[02:06:19.840 --> 02:06:25.900]   Every summer I go to a international city,
[02:06:25.900 --> 02:06:27.340]   international summer school,
[02:06:27.340 --> 02:06:30.380]   it's called the School for Molecular and Theoretical Biology.
[02:06:30.380 --> 02:06:31.820]   It's held in Europe,
[02:06:31.820 --> 02:06:34.380]   it's organized by very good friends of mine.
[02:06:34.380 --> 02:06:37.860]   And this is the school for gifted kids
[02:06:37.860 --> 02:06:41.020]   from all over the world, and they're incredibly bright.
[02:06:41.020 --> 02:06:43.940]   It's like, every time I go there, it's like, you know,
[02:06:43.940 --> 02:06:46.580]   it's the highlight of the year.
[02:06:46.580 --> 02:06:50.980]   And we couldn't make it this August,
[02:06:50.980 --> 02:06:55.460]   so we did this school remotely, but it's different.
[02:06:55.460 --> 02:06:58.780]   So I am definitely looking forward
[02:06:58.780 --> 02:07:01.140]   to next August coming there.
[02:07:01.140 --> 02:07:05.900]   I also, I mean, you know, one of my personal resolutions,
[02:07:05.900 --> 02:07:10.900]   I realized that being in-house and working from home,
[02:07:10.900 --> 02:07:15.500]   you know, I realized that actually,
[02:07:15.500 --> 02:07:20.460]   I apparently missed a lot, you know,
[02:07:20.460 --> 02:07:24.420]   spending time with my family, believe it or not.
[02:07:24.420 --> 02:07:28.300]   So you typically, you know, with all the research
[02:07:28.300 --> 02:07:33.300]   and teaching and everything related to the academic life,
[02:07:33.300 --> 02:07:38.280]   I mean, you get distracted.
[02:07:38.280 --> 02:07:43.280]   And so, you know, you don't feel that, you know,
[02:07:43.280 --> 02:07:46.700]   the fact that you are away from your family
[02:07:46.700 --> 02:07:48.660]   doesn't affect you because you're, you know,
[02:07:48.660 --> 02:07:50.860]   naturally distracted by other things.
[02:07:50.860 --> 02:07:55.140]   And, you know, this time I realized that, you know,
[02:07:55.140 --> 02:07:58.180]   that that's so important, right?
[02:07:58.180 --> 02:08:01.940]   Spending your time with the family, with your kids.
[02:08:01.940 --> 02:08:05.420]   And so that would be my new year resolution
[02:08:05.420 --> 02:08:09.900]   in actually trying to spend as much time as possible.
[02:08:09.900 --> 02:08:11.300]   - Even when the world opens up.
[02:08:11.300 --> 02:08:13.900]   Yeah, that's a beautiful message.
[02:08:13.900 --> 02:08:15.660]   That's a beautiful reminder.
[02:08:15.660 --> 02:08:20.660]   I asked you if there's a Russian poem you could read
[02:08:20.780 --> 02:08:22.060]   that I could force you to read.
[02:08:22.060 --> 02:08:23.960]   And you said, okay, fine, sure.
[02:08:23.960 --> 02:08:27.700]   Do you mind reading?
[02:08:27.700 --> 02:08:30.700]   And you said that no paper needed, so.
[02:08:30.700 --> 02:08:31.540]   - Nope.
[02:08:31.540 --> 02:08:35.580]   So yeah, so this poem was written by my namesake,
[02:08:35.580 --> 02:08:38.060]   another Dmitry, Dmitry Kemmerfeld.
[02:08:38.060 --> 02:08:42.380]   And it's a recent poem,
[02:08:42.380 --> 02:08:47.380]   and it's called "Sorceress", "Vedma" in Russian.
[02:08:50.220 --> 02:08:52.940]   Or actually, "Kaldunya".
[02:08:52.940 --> 02:08:57.940]   So that's sort of another connotation of sorceress or witch.
[02:08:57.940 --> 02:08:59.740]   And I really like it.
[02:08:59.740 --> 02:09:02.740]   And it's one of just a handful poems
[02:09:02.740 --> 02:09:05.460]   I actually can recall by heart.
[02:09:05.460 --> 02:09:08.660]   I also have a very strong association
[02:09:08.660 --> 02:09:12.540]   when I read this poem with Master Margarita,
[02:09:12.540 --> 02:09:16.800]   the main female character, Margarita.
[02:09:18.260 --> 02:09:23.220]   And also it's happening about the same time
[02:09:23.220 --> 02:09:28.220]   we are talking now, so around New Year, around Christmas.
[02:09:28.220 --> 02:09:31.980]   - Do you mind reading it in Russian?
[02:09:31.980 --> 02:09:34.140]   - I'll give it a try.
[02:09:34.140 --> 02:09:39.700]   (speaking in foreign language)
[02:09:39.700 --> 02:09:43.620]   (speaking in foreign language)
[02:09:43.620 --> 02:09:47.540]   (speaking in foreign language)
[02:09:47.540 --> 02:09:51.460]   (speaking in foreign language)
[02:09:51.940 --> 02:09:55.860]   (speaking in foreign language)
[02:09:55.860 --> 02:09:59.780]   (speaking in foreign language)
[02:09:59.780 --> 02:10:03.700]   (speaking in foreign language)
[02:10:03.700 --> 02:10:07.620]   (speaking in foreign language)
[02:10:08.140 --> 02:10:12.060]   (speaking in foreign language)
[02:10:12.060 --> 02:10:15.980]   (speaking in foreign language)
[02:10:15.980 --> 02:10:41.340]   - That's beautiful.
[02:10:41.340 --> 02:10:44.820]   I love how it captures a moment of longing
[02:10:44.820 --> 02:10:49.740]   and maybe love even.
[02:10:49.740 --> 02:10:50.660]   - Yes.
[02:10:50.660 --> 02:10:55.340]   To me, it has a lot of meaning about this,
[02:10:55.340 --> 02:10:59.940]   something that is happening, something that is far away,
[02:10:59.940 --> 02:11:02.260]   but still very close to you.
[02:11:02.260 --> 02:11:06.180]   And yes, it's the winter.
[02:11:06.180 --> 02:11:08.580]   - There's something magical about winter, isn't it?
[02:11:08.580 --> 02:11:10.420]   What is the, well, I don't know.
[02:11:10.420 --> 02:11:11.900]   I don't know how to translate it,
[02:11:11.900 --> 02:11:14.980]   but a kiss in winter is interesting.
[02:11:14.980 --> 02:11:17.580]   Lips in winter and all that kind of stuff.
[02:11:17.580 --> 02:11:20.260]   It's beautifully, I mean, Russian has a way.
[02:11:20.260 --> 02:11:22.620]   As a reason, Russian poetry is just,
[02:11:22.620 --> 02:11:24.540]   I'm a fan of poetry in both languages,
[02:11:24.540 --> 02:11:28.220]   but English doesn't capture some of the magic
[02:11:28.220 --> 02:11:31.620]   that Russian seems to, so thank you for doing that.
[02:11:31.620 --> 02:11:32.660]   That was awesome.
[02:11:32.660 --> 02:11:35.560]   Dmitry, it's great to talk to you again.
[02:11:35.560 --> 02:11:39.260]   It's contagious how much you love what you do,
[02:11:39.260 --> 02:11:40.780]   how much you love life.
[02:11:40.780 --> 02:11:44.020]   So I really appreciate you taking the time to talk today.
[02:11:44.020 --> 02:11:46.340]   - And thank you for having me.
[02:11:46.340 --> 02:11:47.820]   - Thanks for listening to this conversation
[02:11:47.820 --> 02:11:50.740]   with Dmitry Korkin, and thank you to our sponsors,
[02:11:50.740 --> 02:11:54.940]   Brave Browser, NetSuite Business Management Software,
[02:11:54.940 --> 02:11:56.940]   Magic Spoon Low Carb Cereal,
[02:11:56.940 --> 02:12:00.220]   and Asleep Self-Cooling Mattress.
[02:12:00.220 --> 02:12:04.100]   So the choice is browsing privacy, business success,
[02:12:04.100 --> 02:12:06.940]   healthy diet, a comfortable sleep.
[02:12:06.940 --> 02:12:08.580]   Choose wisely, my friends.
[02:12:08.580 --> 02:12:11.140]   And if you wish, click the sponsor links below
[02:12:11.140 --> 02:12:14.220]   to get a discount and to support this podcast.
[02:12:14.220 --> 02:12:16.620]   Now, let me leave you with some words
[02:12:16.620 --> 02:12:19.100]   from Jeffrey Eugenides.
[02:12:19.100 --> 02:12:21.500]   Biology gives you a brain.
[02:12:21.500 --> 02:12:24.100]   Life turns it into a mind.
[02:12:24.100 --> 02:12:27.780]   Thank you for listening, and hope to see you next time.
[02:12:27.780 --> 02:12:30.360]   (upbeat music)
[02:12:30.360 --> 02:12:32.940]   (upbeat music)
[02:12:32.940 --> 02:12:42.940]   [BLANK_AUDIO]

