
[00:00:00.000 --> 00:00:06.600]   We make these devices called microfluidic devices that are kind of like, you can sort
[00:00:06.600 --> 00:00:11.880]   of picture the way integrated circuits made it possible to do a lot of electronic computations
[00:00:11.880 --> 00:00:14.400]   and have very small footprint.
[00:00:14.400 --> 00:00:19.940]   And that kind of led to this revolution in computer science hardware.
[00:00:19.940 --> 00:00:25.520]   We make these microfluidic devices that allow us to do like fluidic computations in high
[00:00:25.520 --> 00:00:28.760]   throughput in very small footprints.
[00:00:28.760 --> 00:00:33.120]   You're listening to Gradient Dissent, a show about machine learning in the real world.
[00:00:33.120 --> 00:00:35.880]   And I'm your host, Lukas Biewald.
[00:00:35.880 --> 00:00:40.640]   Polly is an assistant professor of genetics and bioengineering at Stanford.
[00:00:40.640 --> 00:00:45.880]   Her lab's main focus is on developing and applying new microfluidic platforms to create
[00:00:45.880 --> 00:00:51.520]   high throughput data, which is crucial to making machine learning work in biology and
[00:00:51.520 --> 00:00:52.520]   genetics.
[00:00:52.520 --> 00:00:55.680]   I'm super excited to talk to her today.
[00:00:55.680 --> 00:00:57.640]   Thank you so much for agreeing to this interview.
[00:00:57.640 --> 00:01:02.160]   People have been asking us to get more kind of content on the intersection of biology
[00:01:02.160 --> 00:01:03.680]   and machine learning.
[00:01:03.680 --> 00:01:07.840]   And it's kind of funny, I'll just say, you told me that you didn't know anything about
[00:01:07.840 --> 00:01:11.600]   machine learning, but as we've kind of gone around, we've realized that you're well respected
[00:01:11.600 --> 00:01:14.960]   as someone in biology that knows a lot about machine learning.
[00:01:14.960 --> 00:01:18.760]   So I don't know if I can trust your self-assessment here.
[00:01:18.760 --> 00:01:20.400]   That's really nice to hear.
[00:01:20.400 --> 00:01:25.500]   I feel like we don't know very much about machine learning, but we have been collaborating
[00:01:25.500 --> 00:01:27.560]   more and more with experts in machine learning.
[00:01:27.560 --> 00:01:29.880]   So we're trying to learn as we go.
[00:01:29.880 --> 00:01:34.600]   Well, it's funny, I've discovered kind of with our pharma customers, and we've been
[00:01:34.600 --> 00:01:37.680]   getting a lot of those lately, I started to realize dropping your name actually gives
[00:01:37.680 --> 00:01:39.680]   me a ton of street cred.
[00:01:39.680 --> 00:01:40.680]   That's awesome.
[00:01:40.680 --> 00:01:41.680]   Yeah, that's great to hear.
[00:01:41.680 --> 00:01:49.760]   I guess I should say, I feel like I was friends with you from undergrad, so it's a little
[00:01:49.760 --> 00:01:50.760]   funny.
[00:01:50.760 --> 00:01:54.880]   I mean, it's awesome to watch your career trajectory and it's exciting to hear you talk
[00:01:54.880 --> 00:01:55.880]   about your work.
[00:01:55.880 --> 00:01:57.360]   Same on my part, right?
[00:01:57.360 --> 00:02:02.960]   If I tell any of my students that I know you instantly, it's like I'm a Silicon Valley
[00:02:02.960 --> 00:02:03.960]   celebrity, right?
[00:02:03.960 --> 00:02:10.120]   So I'm like at least in close proximity to it, so it goes both ways.
[00:02:10.120 --> 00:02:11.120]   Nice.
[00:02:11.120 --> 00:02:12.120]   All right.
[00:02:12.120 --> 00:02:15.960]   Well, maybe you could explain kind of at a high level what your research interests are.
[00:02:15.960 --> 00:02:20.120]   You kind of laid it out in the notes and I tried to do some background research, like
[00:02:20.120 --> 00:02:24.240]   reading your papers like I normally do with the machine learning guests, but I found your
[00:02:24.240 --> 00:02:26.240]   academic work pretty impenetrable.
[00:02:26.240 --> 00:02:30.840]   So can you take a big step back with me and sort of explain what you're doing and why
[00:02:30.840 --> 00:02:31.840]   it's important?
[00:02:31.840 --> 00:02:33.880]   Yeah, it's really technical.
[00:02:33.880 --> 00:02:41.120]   So I guess I would say a couple examples of the things that I'm interested in are the
[00:02:41.120 --> 00:02:45.560]   promise of the Human Genome Project a long time ago was this idea that we were going
[00:02:45.560 --> 00:02:51.080]   to be able to sequence everybody's genomes and then we would look at the difference in
[00:02:51.080 --> 00:02:56.040]   the sequences of those genomes and we would instantly be able to say whether a particular
[00:02:56.040 --> 00:03:00.800]   mutation in the genome meant that somebody was going to have a particular disease or
[00:03:00.800 --> 00:03:04.700]   maybe they would respond to a particular treatment.
[00:03:04.700 --> 00:03:10.340]   And I think the challenge is that the amount of possible variation is really huge.
[00:03:10.340 --> 00:03:17.200]   So there are so many different variants that we discover and we still don't really know
[00:03:17.200 --> 00:03:21.720]   for the vast majority of variants, three quarters of variants that we found, we have no idea
[00:03:21.720 --> 00:03:24.240]   whether they're likely to have a functional effect.
[00:03:24.240 --> 00:03:28.080]   I'm sorry, I'm just going to start the dumb questions early.
[00:03:28.080 --> 00:03:32.200]   So you mean variants of genes, like different DNA, is that right?
[00:03:32.200 --> 00:03:35.800]   Yeah, I mean like different letters in the genome, different letters in the genome.
[00:03:35.800 --> 00:03:37.240]   Different letters in the DNA.
[00:03:37.240 --> 00:03:38.240]   Okay, got it.
[00:03:38.240 --> 00:03:39.600]   Yeah, different letters in the DNA.
[00:03:39.600 --> 00:03:43.920]   And so probably the main thing that my lab is really interested in is trying to figure
[00:03:43.920 --> 00:03:51.680]   out maybe from high school biology, everybody kind of remembers that DNA makes RNA, makes
[00:03:51.680 --> 00:03:52.680]   protein.
[00:03:52.680 --> 00:03:57.760]   And we're pretty good for portions of the genome, the parts of the genome that say what
[00:03:57.760 --> 00:03:59.320]   proteins to make.
[00:03:59.320 --> 00:04:05.480]   We have a pretty good sense of what RNAs are made and what proteins they make kind of,
[00:04:05.480 --> 00:04:09.360]   but then what we really don't know is how to predict what those proteins do from the
[00:04:09.360 --> 00:04:10.360]   sequence.
[00:04:10.360 --> 00:04:15.960]   So it's like we have parts of the program, but we just don't really know how to predict
[00:04:15.960 --> 00:04:18.600]   what the functional effects are going to be when we make changes.
[00:04:18.600 --> 00:04:19.600]   Right.
[00:04:19.600 --> 00:04:21.760]   So, I mean, isn't it like kind of deterministic?
[00:04:21.760 --> 00:04:25.320]   Like don't you actually know from the DNA what RNA might make?
[00:04:25.320 --> 00:04:28.840]   I guess in biology, anywhere you pull out a thread, it gets more complicated than you
[00:04:28.840 --> 00:04:29.840]   think, right?
[00:04:29.840 --> 00:04:36.560]   Yeah, it's pretty interesting in that we have a sense of, I guess I would say, so we know
[00:04:36.560 --> 00:04:42.720]   for the parts of the genome that actually code for proteins, which is a tiny amount
[00:04:42.720 --> 00:04:49.280]   of the genome, like a really small fraction, we have a sense of what RNAs are made, but
[00:04:49.280 --> 00:04:52.120]   there's way more regulation after that.
[00:04:52.120 --> 00:04:58.760]   So first, just for the RNA, the RNA kind of will loop around and cut itself up to make
[00:04:58.760 --> 00:05:00.920]   kind of different variants.
[00:05:00.920 --> 00:05:05.320]   And then when we make proteins from that, I think one of the big challenges is figuring
[00:05:05.320 --> 00:05:11.680]   out a protein is like a linear sequence that has to fold into a three-dimensional structure
[00:05:11.680 --> 00:05:14.720]   and that three-dimensional structure does something.
[00:05:14.720 --> 00:05:19.320]   And I think a great example of where machine learning has had a real impact in biology
[00:05:19.320 --> 00:05:26.640]   is AlphaFold2, is a great example where there's been this problem for a long time, what three-dimensional
[00:05:26.640 --> 00:05:29.560]   structure do linear protein sequences make?
[00:05:29.560 --> 00:05:34.160]   And here, machine learning algorithms have improved our ability to predict that, but
[00:05:34.160 --> 00:05:38.960]   we still don't know what those proteins do when they're folded or whether they just fold
[00:05:38.960 --> 00:05:41.120]   into one confirmation or multiple confirmations.
[00:05:41.120 --> 00:05:44.160]   So I think there's a lot more questions like that.
[00:05:44.160 --> 00:05:47.000]   Could you give me an example of one that you do know?
[00:05:47.000 --> 00:05:49.040]   Because we know some, right?
[00:05:49.040 --> 00:05:51.280]   There's some mechanisms that we understand, right?
[00:05:51.280 --> 00:05:52.280]   Yeah.
[00:05:52.280 --> 00:05:56.760]   I mean, there's some in terms of protein folding or in terms of-
[00:05:56.760 --> 00:05:58.320]   I guess just in terms of the whole sequence.
[00:05:58.320 --> 00:05:59.880]   So you have a different...
[00:05:59.880 --> 00:06:04.000]   What's the sort of canonical example from high school biology of you have some different
[00:06:04.000 --> 00:06:07.560]   letters so then you're missing a protein and then you have some disease, right?
[00:06:07.560 --> 00:06:09.880]   That's sort of kind of my mental model.
[00:06:09.880 --> 00:06:10.880]   Is that even right?
[00:06:10.880 --> 00:06:11.880]   Yeah.
[00:06:11.880 --> 00:06:14.640]   There are a small number of...
[00:06:14.640 --> 00:06:17.520]   I guess initially it's like Mendel with the peas, right?
[00:06:17.520 --> 00:06:21.480]   You learn about Mendel with the peas in high school and it's like, "Oh."
[00:06:21.480 --> 00:06:25.640]   Depending on what the sequence is, it's either going to be pink flowers or white flowers.
[00:06:25.640 --> 00:06:29.400]   And I think people thought that was going to be the case for genes.
[00:06:29.400 --> 00:06:34.240]   And there are a small number of genes like sickle cell anemia is a great example of a
[00:06:34.240 --> 00:06:39.440]   gene where we know that this gene, if you have this variant, you're going to have sickle
[00:06:39.440 --> 00:06:40.440]   cell anemia.
[00:06:40.440 --> 00:06:43.240]   If you don't, you won't.
[00:06:43.240 --> 00:06:52.560]   But most traits, whether it's height or autism or diabetes or whatever, are actually...
[00:06:52.560 --> 00:06:57.920]   It's sort of like there's a whole collection of thousands of genes that determine whether
[00:06:57.920 --> 00:07:04.200]   or not you're going to get a particular disease and how you have a distribution of genes that
[00:07:04.200 --> 00:07:06.680]   mean you're more or less likely to have a disease.
[00:07:06.680 --> 00:07:10.800]   And then that distribution interacts with your environment and what you're exposed to.
[00:07:10.800 --> 00:07:14.040]   So yeah, it's more complicated than Mendel.
[00:07:14.040 --> 00:07:20.880]   So your research is on the actual kind of physical mechanism that goes from you have
[00:07:20.880 --> 00:07:23.760]   more of some kind of protein and then something happens.
[00:07:23.760 --> 00:07:24.760]   Is that right?
[00:07:24.880 --> 00:07:27.880]   I guess my research...
[00:07:27.880 --> 00:07:31.480]   And again, it's so technical.
[00:07:31.480 --> 00:07:36.400]   There's a few different things that I would say my research focuses on.
[00:07:36.400 --> 00:07:43.320]   At a basic level, one of the questions that I'm interested in is when you have changes
[00:07:43.320 --> 00:07:48.520]   in the sequence of a protein or changes in the part of the genome that tell you when
[00:07:48.520 --> 00:07:54.280]   and how much to make of that protein, how do those changes alter function?
[00:07:54.280 --> 00:07:57.760]   So I guess I was initially...
[00:07:57.760 --> 00:07:58.760]   I was a physicist.
[00:07:58.760 --> 00:08:01.840]   My PhD is in physics.
[00:08:01.840 --> 00:08:08.240]   And one of the things that I think is really interesting is that these sequences code for
[00:08:08.240 --> 00:08:11.960]   molecules, three-dimensional molecules.
[00:08:11.960 --> 00:08:17.920]   And a change in the sequence of that molecule changes the physical forces that it uses to
[00:08:17.920 --> 00:08:20.300]   interact with other molecules.
[00:08:20.300 --> 00:08:26.480]   So that can affect whether a cell lives or dies, whether a fetus lives or dies.
[00:08:26.480 --> 00:08:30.840]   It's sort of this interaction at the scale where a change at the level of a molecule
[00:08:30.840 --> 00:08:34.920]   can have profound influences for a fetus or a cell.
[00:08:34.920 --> 00:08:42.080]   So my lab is really interested in how changes in the sequence of a molecule affect its structure
[00:08:42.080 --> 00:08:43.080]   and function.
[00:08:43.080 --> 00:08:46.640]   I'm not sure if that's specific enough.
[00:08:46.640 --> 00:08:48.920]   No, totally.
[00:08:48.920 --> 00:08:52.240]   Let me see if I can repeat this back.
[00:08:52.240 --> 00:08:54.480]   So it sounds like you're interested in...
[00:08:54.480 --> 00:08:58.560]   So the DNA makes RNA and there's probably some asterisk there.
[00:08:58.560 --> 00:09:02.000]   And then the RNA kind of makes a linear sequence of a protein.
[00:09:02.000 --> 00:09:09.200]   And it sounds like you're sort of interested in how the changes in the composition, I guess,
[00:09:09.200 --> 00:09:15.120]   of that protein sort of change something that happens beyond that.
[00:09:15.120 --> 00:09:16.120]   Yeah.
[00:09:16.120 --> 00:09:19.480]   So DNA makes RNA makes protein.
[00:09:19.480 --> 00:09:24.480]   Proteins then fold into a three-dimensional structure and they do things in the cell.
[00:09:24.480 --> 00:09:29.520]   So sometimes they bind RNA to tell the cell when it should make other genes.
[00:09:29.520 --> 00:09:33.960]   They bind other proteins to transmit signals.
[00:09:33.960 --> 00:09:39.640]   Proteins are kind of like the functional workhorse of what makes stuff happen in your cells.
[00:09:39.640 --> 00:09:47.240]   And my lab is really interested in how do changes in those sequences alter the structure
[00:09:47.240 --> 00:09:49.680]   and function of the molecules.
[00:09:49.680 --> 00:09:54.080]   And I guess I would say sort of two more things.
[00:09:54.080 --> 00:10:01.160]   One of the things, our approach is it's a problem of staggering complexity.
[00:10:01.160 --> 00:10:07.360]   The number of possible amino acid combinations for an average size protein is larger than
[00:10:07.360 --> 00:10:09.800]   the number of atoms in the universe.
[00:10:09.800 --> 00:10:14.560]   So we're never going to be able to test all possible variants and see what they do.
[00:10:14.560 --> 00:10:16.360]   That's just impossible.
[00:10:16.360 --> 00:10:22.400]   So we're really interested in trying to figure out, can we create libraries in which we systematically
[00:10:22.400 --> 00:10:28.920]   vary sequence, it varies these physical properties, and we assess the effect on function so that
[00:10:28.920 --> 00:10:34.800]   we can kind of learn not just a black box relationship between sequence and function,
[00:10:34.800 --> 00:10:39.460]   but we can ultimately develop quantitative and predictive models that would allow us
[00:10:39.460 --> 00:10:44.400]   to predict not just for the molecules we study, but for all molecules, how sequence changes
[00:10:44.400 --> 00:10:45.400]   alter function.
[00:10:45.400 --> 00:10:46.400]   I see.
[00:10:46.400 --> 00:10:50.880]   But through kind of a physical understanding versus like...
[00:10:50.880 --> 00:10:54.360]   I feel like the machine learning perspective might be to sort of like, "Hey, let's treat
[00:10:54.360 --> 00:10:59.600]   this as a black box possibly, and let's sort of look for patterns here," versus trying
[00:10:59.600 --> 00:11:02.880]   to understand the actual physics of what's happening.
[00:11:02.880 --> 00:11:03.880]   Exactly.
[00:11:03.880 --> 00:11:04.880]   So what I think...
[00:11:04.880 --> 00:11:05.880]   Interesting.
[00:11:05.880 --> 00:11:11.440]   Where I think that us and where we've really loved collaborating with machine learning
[00:11:11.440 --> 00:11:18.440]   specialists is our approach is we develop these tools, we make these devices called
[00:11:18.440 --> 00:11:21.560]   microfluidic devices that are kind of like...
[00:11:21.560 --> 00:11:26.320]   You can sort of picture the way integrated circuits made it possible to do a lot of electronic
[00:11:26.320 --> 00:11:32.680]   computations in a very small footprint, and that kind of led to this revolution in computer
[00:11:32.680 --> 00:11:34.820]   science hardware.
[00:11:34.820 --> 00:11:42.880]   For us, what we do is we make these microfluidic devices that allow us to do fluidic computations
[00:11:42.880 --> 00:11:45.680]   in high throughput in very small footprints.
[00:11:45.680 --> 00:11:47.800]   So now what we can do is we can do...
[00:11:47.800 --> 00:11:49.800]   So, a fluidic computation.
[00:11:49.800 --> 00:11:50.800]   Right.
[00:11:50.800 --> 00:11:57.640]   So normally, if you were going to do an experiment in biology, you sort of picture test tubes
[00:11:57.640 --> 00:12:02.080]   and Petri dishes and big things.
[00:12:02.080 --> 00:12:09.680]   And if you wanted to do a thousand reactions, you need these giant expensive robots.
[00:12:09.680 --> 00:12:14.040]   And so what we've been doing is we've been using this approach where we can create these
[00:12:14.040 --> 00:12:21.000]   tiny devices that instead of using five milliliters of fluid for each reaction, we use about a
[00:12:21.000 --> 00:12:22.080]   nanoliter.
[00:12:22.080 --> 00:12:27.740]   And these devices make it possible to use fewer reagents, so everything is low cost.
[00:12:27.740 --> 00:12:32.340]   We can automate things on these devices without the use of expensive robots.
[00:12:32.340 --> 00:12:38.360]   And now the main power of these technologies is that they allow us to make a thousand measurements
[00:12:38.360 --> 00:12:43.200]   in the amount of time and cost that it used to take to make one in biology.
[00:12:43.200 --> 00:12:50.900]   And now I think that that means that we can generate data at a scale that allows us to
[00:12:50.900 --> 00:12:56.520]   quantitatively test predictions from our colleagues in ML.
[00:12:56.520 --> 00:12:59.160]   So you all need ground truth.
[00:12:59.160 --> 00:13:02.720]   You need some ground truth measurement to assess what's going on.
[00:13:02.720 --> 00:13:04.220]   And you can't just have one or two.
[00:13:04.220 --> 00:13:09.620]   You need enough that you can do some sort of regression to figure out where is your
[00:13:09.620 --> 00:13:13.160]   model successful and where is it failing.
[00:13:13.160 --> 00:13:19.780]   And so our job is to make measurements of a thousand things really quantitatively where
[00:13:19.780 --> 00:13:25.200]   we can interface back and forth with ML people to test those predictions, revise and refine
[00:13:25.200 --> 00:13:33.360]   those models, and hopefully try and use some of these ML predictions to learn new physics.
[00:13:33.360 --> 00:13:37.160]   That's what we want to do.
[00:13:37.160 --> 00:13:38.160]   That's so cool.
[00:13:38.160 --> 00:13:42.120]   So what would be something that would happen at that tiny scale?
[00:13:42.120 --> 00:13:48.280]   Are you literally putting a protein in there and watching what happens?
[00:13:48.280 --> 00:13:49.280]   Yeah.
[00:13:49.280 --> 00:13:51.280]   Can you explain exactly what goes into that?
[00:13:51.280 --> 00:13:52.280]   Yeah, exactly.
[00:13:52.280 --> 00:13:56.560]   So, okay, here's two examples of some platforms we've developed.
[00:13:56.560 --> 00:14:02.840]   So we've been working really closely with Dan Herschlag and he's an enzymologist.
[00:14:02.840 --> 00:14:07.920]   And so one type of protein that we're interested in is enzymes.
[00:14:07.920 --> 00:14:13.080]   And enzymes, they underpin all of our metabolism.
[00:14:13.080 --> 00:14:17.440]   They make it possible to do chemical reactions that would never happen in the absence of
[00:14:17.440 --> 00:14:18.440]   an enzyme.
[00:14:18.440 --> 00:14:24.440]   So they're important, both for ourselves, they're the tools people use in modern molecular
[00:14:24.440 --> 00:14:25.440]   biology.
[00:14:25.440 --> 00:14:28.120]   You use them to make libraries for sequencing.
[00:14:28.120 --> 00:14:31.760]   People use them in, you use them when you do your laundry, right?
[00:14:31.760 --> 00:14:35.400]   Enzymes are the things that bust up stains on your clothes.
[00:14:35.400 --> 00:14:40.320]   And we still don't really know how the sequence of an enzyme specifies its function.
[00:14:40.320 --> 00:14:47.160]   So one thing that we can do now is just like sort of a, I guess, DNA, like the Moderna
[00:14:47.160 --> 00:14:48.160]   vaccine, right?
[00:14:48.160 --> 00:14:52.640]   We sort of heard now we can make this mRNA vaccine and we can program it to make something
[00:14:52.640 --> 00:14:54.040]   that we want.
[00:14:54.040 --> 00:15:00.360]   We can create little pieces of DNA, each of which specifies a protein we want to make.
[00:15:00.360 --> 00:15:05.760]   We can use a robot so that we spot bits of this DNA in an array.
[00:15:05.760 --> 00:15:11.800]   So we have like a thousand little spots and we know the program encoded by the DNA in
[00:15:11.800 --> 00:15:13.600]   each spot.
[00:15:13.600 --> 00:15:19.280]   We can take one of these devices that we make that has little chambers and align them to
[00:15:19.280 --> 00:15:21.200]   the spots.
[00:15:21.200 --> 00:15:26.880]   And then there's sort of this magical mixture of like all of the stuff that you need to
[00:15:26.880 --> 00:15:29.800]   turn DNA into RNA and protein.
[00:15:29.800 --> 00:15:34.880]   The companies sell, it's like you just buy this little tube that has the polymerase you
[00:15:34.880 --> 00:15:39.840]   learned about in high school biology, the ribosome that makes the protein, all that
[00:15:39.840 --> 00:15:40.840]   stuff.
[00:15:40.840 --> 00:15:41.840]   We push it into these little chambers.
[00:15:41.840 --> 00:15:42.840]   It fits in a nanoliter?
[00:15:42.840 --> 00:15:43.840]   Yeah.
[00:15:43.840 --> 00:15:47.840]   So the nanoliter is not too, it all fits?
[00:15:47.840 --> 00:15:48.840]   Yeah.
[00:15:48.840 --> 00:15:55.320]   A nanoliter is like, okay, your hair, a hair strand is like a hundred microns.
[00:15:55.320 --> 00:16:01.960]   Each of the chambers in these devices is about the diameter of your hair and the height of
[00:16:01.960 --> 00:16:03.880]   a tenth of your hair.
[00:16:03.880 --> 00:16:10.320]   So we use a lot of the machinery that people use for lithography to make these integrated
[00:16:10.320 --> 00:16:11.320]   circuits.
[00:16:11.320 --> 00:16:16.880]   We use all the same equipment to make these tiny devices.
[00:16:16.880 --> 00:16:17.880]   And now we can make a little bit-
[00:16:17.880 --> 00:16:20.920]   I guess I see the integrated circuit analogy.
[00:16:20.920 --> 00:16:22.760]   Yeah, exactly.
[00:16:22.760 --> 00:16:29.960]   So we really do use a lot of the same equipment, except for now, instead of pushing electrons
[00:16:29.960 --> 00:16:36.160]   around, we're actually pushing fluid that contains molecules in different ways within
[00:16:36.160 --> 00:16:37.300]   these devices.
[00:16:37.300 --> 00:16:43.280]   So we can make each one of these enzyme variants in each chamber.
[00:16:43.280 --> 00:16:47.580]   And now we can quantitatively ask, when you make this mutation, how does it affect the
[00:16:47.580 --> 00:16:54.300]   ability of this enzyme to catalyze the reaction it's supposed to catalyze?
[00:16:54.300 --> 00:16:57.900]   So that's an example of one of the things that we do.
[00:16:57.900 --> 00:17:04.020]   And the reason why you would want to do it is this might help us classify variants in
[00:17:04.020 --> 00:17:09.220]   the human population for whether or not they're likely to compromise function and cause disease.
[00:17:09.220 --> 00:17:15.220]   It could also maybe help us generate new enzymes that eat up environmental waste or design
[00:17:15.220 --> 00:17:18.140]   new enzymes to do things that we want to do.
[00:17:18.140 --> 00:17:22.900]   One other example, I guess, of something that we do is historically, when you've looked
[00:17:22.900 --> 00:17:30.660]   at a population of cells, let's say from a tumor, we've ground up all those cells and
[00:17:30.660 --> 00:17:36.100]   we've asked, what's the behavior of that population of cells?
[00:17:36.100 --> 00:17:42.180]   Within all of those cells, maybe there's one or two rare cells that's resistant to a drug.
[00:17:42.180 --> 00:17:47.700]   And when we treat a patient with that drug, those one or two cells are going to proliferate
[00:17:47.700 --> 00:17:50.900]   and drive treatment failures.
[00:17:50.900 --> 00:17:56.700]   So we need a way where instead of looking at all of the cells mashed up together, we
[00:17:56.700 --> 00:18:00.940]   want to be able to profile the cells one by one.
[00:18:00.940 --> 00:18:08.100]   So another technology that we're using that this field, microfluidics, allows you to do
[00:18:08.100 --> 00:18:15.820]   is we can actually put every cell in a tiny droplet, like basically a little water and
[00:18:15.820 --> 00:18:23.300]   oil droplet that serves as a tiny compartment where we can interrogate that cell by itself
[00:18:23.300 --> 00:18:26.380]   without looking at all of its neighbors at the same time.
[00:18:26.380 --> 00:18:30.340]   And so again, those droplets are like a nanoliter.
[00:18:30.340 --> 00:18:39.580]   And we can look at a million cells individually at once in their own little nanoliter compartments.
[00:18:39.580 --> 00:18:42.380]   So how do you break up all the cells?
[00:18:42.380 --> 00:18:43.940]   Yeah.
[00:18:43.940 --> 00:18:47.820]   Some cells just grow, like blood cells grow by themselves.
[00:18:47.820 --> 00:18:51.620]   For solid cells, this is something that actually our collaborators do.
[00:18:51.620 --> 00:18:55.900]   I never actually, I never really know how to do this, but you can treat them with enzymes
[00:18:55.900 --> 00:18:59.700]   that chew up the stuff that connects them so that they separate.
[00:18:59.700 --> 00:19:04.100]   If they grow on a surface, you treat them with this enzyme and then they separate from
[00:19:04.100 --> 00:19:05.700]   each other and come into the solution.
[00:19:05.700 --> 00:19:10.460]   And then we put them in the bubbles, in the droplets.
[00:19:10.460 --> 00:19:12.380]   It's some automated way, I assume.
[00:19:12.380 --> 00:19:13.380]   Yeah.
[00:19:13.380 --> 00:19:16.140]   I wish I could show you the videos.
[00:19:16.140 --> 00:19:17.140]   I could send you some.
[00:19:17.140 --> 00:19:18.140]   I know.
[00:19:18.140 --> 00:19:19.140]   Send me some videos.
[00:19:19.140 --> 00:19:20.140]   Yeah.
[00:19:20.140 --> 00:19:21.140]   We'll put some links to them.
[00:19:21.140 --> 00:19:22.140]   That would be awesome.
[00:19:22.140 --> 00:19:23.140]   I'll send you videos of both.
[00:19:23.140 --> 00:19:24.140]   Yeah.
[00:19:24.140 --> 00:19:25.140]   Cool.
[00:19:25.140 --> 00:19:32.620]   So I guess it's funny, a really dumb question that I keep being afraid to ask, but I think
[00:19:32.620 --> 00:19:37.900]   other people might be feeling is, everyone saw in machine learning the protein folding
[00:19:37.900 --> 00:19:42.940]   thing and everybody knows that protein folding is this interesting, big problem that a lot
[00:19:42.940 --> 00:19:44.300]   of ML people have worked on.
[00:19:44.300 --> 00:19:49.820]   But I've always kind of, I guess, here, I'll ask the question.
[00:19:49.820 --> 00:19:51.260]   Why is protein folding so important?
[00:19:51.260 --> 00:19:53.460]   It seems like it would be really critical to your work.
[00:19:53.460 --> 00:19:59.020]   But can't you also just look at the proteins and see what shape they have?
[00:19:59.020 --> 00:20:00.500]   Aren't they literally just there?
[00:20:00.500 --> 00:20:01.860]   It's such a good question.
[00:20:01.860 --> 00:20:02.860]   These questions are awesome.
[00:20:02.860 --> 00:20:03.860]   Yeah.
[00:20:03.860 --> 00:20:04.860]   So they're tiny, right?
[00:20:04.860 --> 00:20:06.180]   They're really tiny.
[00:20:06.180 --> 00:20:12.540]   And so to see the structure of a protein, you have a few options.
[00:20:12.540 --> 00:20:16.940]   Historically, people have tried to crystallize them.
[00:20:16.940 --> 00:20:22.540]   So they've tried to get them to basically form a three-dimensional crystal where they're
[00:20:22.540 --> 00:20:25.100]   all in the same shape.
[00:20:25.100 --> 00:20:30.780]   And then they've taken them to a giant x-ray beam, like the Stanford linear accelerator
[00:20:30.780 --> 00:20:32.500]   or other places like this.
[00:20:32.500 --> 00:20:34.580]   They've shot x-rays through them.
[00:20:34.580 --> 00:20:38.580]   They've looked at the diffraction pattern that they make.
[00:20:38.580 --> 00:20:45.380]   And then they apply a bunch of super fancy Fourier transforms, essentially, to take the
[00:20:45.380 --> 00:20:51.180]   diffraction pattern and turn it back into a picture of what the protein looks like in
[00:20:51.180 --> 00:20:52.180]   3D.
[00:20:52.180 --> 00:20:53.180]   And it's really hard.
[00:20:53.180 --> 00:20:58.020]   You go to talks all the time where a graduate student is like, "I spent five years trying
[00:20:58.020 --> 00:21:00.460]   to crystallize this one protein."
[00:21:00.460 --> 00:21:03.100]   A lot of proteins don't crystallize.
[00:21:03.100 --> 00:21:04.780]   And it's slow.
[00:21:04.780 --> 00:21:08.820]   And the other thing is most proteins don't exist as a single static structure.
[00:21:08.820 --> 00:21:10.780]   They're wiggling around all the time.
[00:21:10.780 --> 00:21:16.140]   And that wiggling is really important for how they do their function.
[00:21:16.140 --> 00:21:24.580]   More recently, people have started using cryo-electron microscopy as another way to look at proteins
[00:21:24.580 --> 00:21:28.780]   where you freeze proteins down on these metal grids.
[00:21:28.780 --> 00:21:35.820]   And then you use these super fancy $10 million microscopes to look at the individual particles.
[00:21:35.820 --> 00:21:40.780]   And there's been a real revolution in this in the last several years, basically because
[00:21:40.780 --> 00:21:47.800]   of the image processing algorithms have made it possible to align many different particles
[00:21:47.800 --> 00:21:50.220]   and reconstruct what things look like.
[00:21:50.220 --> 00:21:53.540]   But that's only suitable for big proteins.
[00:21:53.540 --> 00:21:55.300]   You can't really do it for small proteins.
[00:21:55.300 --> 00:22:01.980]   So the vast majority of proteins don't have crystal structures or these cryo-EM structures.
[00:22:01.980 --> 00:22:05.180]   So we just don't know what they look like.
[00:22:05.180 --> 00:22:11.100]   And we've really looked at some of them fold into these three-dimensional structures.
[00:22:11.100 --> 00:22:13.340]   A lot of them are kind of unfolded.
[00:22:13.340 --> 00:22:17.940]   And we have very few pictures of what they're doing.
[00:22:17.940 --> 00:22:24.460]   So trying to predict the number of structures we have is just tiny compared to the number
[00:22:24.460 --> 00:22:27.220]   of proteins we know about.
[00:22:27.220 --> 00:22:30.580]   And the structures are often a static picture.
[00:22:30.580 --> 00:22:35.980]   So that's one reason why it's a hard problem.
[00:22:35.980 --> 00:22:40.340]   And the reason why you want to know is let's say you want to design a new drug to target
[00:22:40.340 --> 00:22:41.340]   a protein.
[00:22:41.340 --> 00:22:47.300]   You kind of need to know that 3D shape so you can figure out where would you put a drug
[00:22:47.300 --> 00:22:55.500]   and what kind of drug is likely to fit in there and alter the function of that protein.
[00:22:55.500 --> 00:22:56.500]   I'm not sure if that makes sense.
[00:22:56.500 --> 00:22:57.500]   Yeah, that makes sense.
[00:22:57.500 --> 00:22:58.500]   I guess that's incredibly...
[00:22:58.500 --> 00:22:59.500]   No, I don't know.
[00:22:59.500 --> 00:23:00.780]   That was really helpful.
[00:23:00.780 --> 00:23:01.780]   Thank you.
[00:23:01.780 --> 00:23:06.580]   And I saw this amazing blog post that I think was from more of a computer science perspective
[00:23:06.580 --> 00:23:11.740]   on how the Moderna drug works, which is super helpful for me to understand why you would
[00:23:11.740 --> 00:23:12.740]   kind of care about...
[00:23:12.740 --> 00:23:15.740]   I think Drew Ford did that to me.
[00:23:15.740 --> 00:23:16.740]   Yeah.
[00:23:16.740 --> 00:23:17.740]   Oh, cool.
[00:23:17.740 --> 00:23:18.740]   Drew Ford did that to me.
[00:23:18.740 --> 00:23:19.740]   Yeah.
[00:23:19.740 --> 00:23:23.980]   I was like, "Wow, this is so amazing that people could figure this stuff out and then
[00:23:23.980 --> 00:23:25.380]   make a certain shape."
[00:23:25.380 --> 00:23:28.980]   And then it seemed like they modified it a little bit from the natural one to kind of
[00:23:28.980 --> 00:23:29.980]   make the shape better.
[00:23:29.980 --> 00:23:33.300]   And I can't believe they figured that.
[00:23:33.300 --> 00:23:36.060]   They figured that, but it sounds like they figured it out in days.
[00:23:36.060 --> 00:23:38.780]   So is that kind of the excitement?
[00:23:38.780 --> 00:23:39.780]   Yeah.
[00:23:39.780 --> 00:23:43.100]   What was really interesting was, yeah, Drew was like, "The people who figured this out
[00:23:43.100 --> 00:23:47.620]   should get some huge prize."
[00:23:47.620 --> 00:23:53.860]   And I think what's really interesting is that it's been tens of thousands of people over
[00:23:53.860 --> 00:23:57.220]   decades who have made it possible.
[00:23:57.220 --> 00:24:06.500]   So I think for this particular vaccine, there are people that sort of specialized in mRNA
[00:24:06.500 --> 00:24:08.980]   vaccine production that have been critical.
[00:24:08.980 --> 00:24:16.060]   There's people that specialize in coronavirus in general and spike protein, which is like
[00:24:16.060 --> 00:24:19.820]   the protein on the surface that we're trying to mimic with these vaccines.
[00:24:19.820 --> 00:24:27.380]   But it's really kind of a beautiful example of so many different fields of biology have
[00:24:27.380 --> 00:24:35.780]   contributed to that in terms of thinking about the folding and the structure of RNA to figure
[00:24:35.780 --> 00:24:36.780]   out...
[00:24:36.780 --> 00:24:41.020]   I mean, both in terms of immunology, what parts of the protein should we be targeting?
[00:24:41.020 --> 00:24:47.020]   In terms of thinking about nucleic acid biology, how do we make an mRNA that's going to be
[00:24:47.020 --> 00:24:52.400]   pretty stable, which some of the modifications that you're talking about made it more stable.
[00:24:52.400 --> 00:24:58.100]   Thinking about delivery, how do we wrap it so that it can go into your body and isn't
[00:24:58.100 --> 00:25:02.080]   just instantly chewed up by all of the enzymes in your body that are looking for foreign
[00:25:02.080 --> 00:25:04.140]   invaders and want to chew them up all the time.
[00:25:04.140 --> 00:25:10.140]   So it's an amazing triumph of the scientific community and scientists from so many different
[00:25:10.140 --> 00:25:11.140]   fields.
[00:25:11.140 --> 00:25:12.140]   Yeah.
[00:25:12.140 --> 00:25:13.140]   It's really exciting, I guess.
[00:25:13.140 --> 00:25:14.140]   Yeah, it seems cool.
[00:25:14.140 --> 00:25:15.140]   Yeah.
[00:25:15.780 --> 00:25:22.740]   So I guess I'm kind of curious your experience collaborating with machine learning practitioners.
[00:25:22.740 --> 00:25:25.580]   Can you maybe describe what that's been like?
[00:25:25.580 --> 00:25:32.560]   I mean, I remember when I first started working with people in medicine with my last company,
[00:25:32.560 --> 00:25:34.540]   it was such a funny kind of cultural mismatch.
[00:25:34.540 --> 00:25:37.980]   I remember them telling me, they were doing microscopy and they were like, "We have so
[00:25:37.980 --> 00:25:38.980]   much data.
[00:25:38.980 --> 00:25:45.020]   We have like 500 people's tumors that have been sliced and stained or something."
[00:25:45.020 --> 00:25:46.020]   And I was just like, "Wait a minute.
[00:25:46.020 --> 00:25:47.020]   I'm not sure anything would work with that."
[00:25:47.020 --> 00:25:56.820]   They're big files, I guess, but I think I need more than a big file.
[00:25:56.820 --> 00:25:57.820]   Yeah.
[00:25:57.820 --> 00:26:00.580]   I mean, I love it.
[00:26:00.580 --> 00:26:03.340]   I think it's so pleasurable.
[00:26:03.340 --> 00:26:10.660]   Yeah, I love working with practitioners of machine learning, both because as a field,
[00:26:10.660 --> 00:26:13.180]   it's moving so fast.
[00:26:13.180 --> 00:26:18.220]   So the things that are possible this year are different than what was possible six months
[00:26:18.220 --> 00:26:19.580]   ago, a year ago.
[00:26:19.580 --> 00:26:25.300]   It's interesting to think about all of the ways in which algorithms that are developed
[00:26:25.300 --> 00:26:33.860]   for figuring out whose face is in a photo can instantly be ported to biology.
[00:26:33.860 --> 00:26:40.100]   So you can leverage all of the commercial interest in developing something like that
[00:26:40.100 --> 00:26:46.060]   towards problems like what we study that are never going to be as commercially viable or
[00:26:46.060 --> 00:26:47.340]   interesting.
[00:26:47.340 --> 00:26:49.260]   So that's really exciting.
[00:26:49.260 --> 00:26:55.620]   In terms of the culture mismatch, what's funny I think is I'm on thesis committees for a
[00:26:55.620 --> 00:26:58.260]   lot of ML students now.
[00:26:58.260 --> 00:27:05.260]   And for ML students, what they want is they want their algorithm to have the best AUC
[00:27:05.260 --> 00:27:06.940]   by two percent.
[00:27:06.940 --> 00:27:11.100]   Even an incremental benefit is good, right?
[00:27:11.100 --> 00:27:12.780]   Because it could potentially scale.
[00:27:12.780 --> 00:27:18.900]   But for them, any points that are unexplained are like a failure.
[00:27:18.900 --> 00:27:23.180]   Whereas for us, that's the most interesting part, right?
[00:27:23.180 --> 00:27:26.500]   What do those points that are not explained by the algorithm have in common?
[00:27:26.500 --> 00:27:32.300]   And are we discovering new biology or new physics that we hadn't thought about before?
[00:27:32.300 --> 00:27:41.780]   So and it's cool in that, you know, trying like the mathematical facility that ML practitioners
[00:27:41.780 --> 00:27:44.920]   have is astounding.
[00:27:44.920 --> 00:27:50.220]   And so it's fun where some of the questions, you know, people are like, I'm sorry, just
[00:27:50.220 --> 00:27:51.780]   what is a protein?
[00:27:51.780 --> 00:27:54.860]   Where we're like, oh, okay, yeah, we can answer that.
[00:27:54.860 --> 00:28:00.380]   And then at the same time, I'm like, you know, I'm looking at that image everybody shows
[00:28:00.380 --> 00:28:03.220]   of their neural net with like the, you know, all the layers.
[00:28:03.220 --> 00:28:06.260]   And I have no idea how you would actually implement that.
[00:28:06.260 --> 00:28:07.260]   Like I've seen the picture.
[00:28:07.260 --> 00:28:09.260]   I have the picture in my papers, right?
[00:28:09.260 --> 00:28:13.180]   But I would never be able to actually do, I don't even know the first thing about how
[00:28:13.180 --> 00:28:15.140]   to set it up, you know?
[00:28:15.140 --> 00:28:16.140]   Yeah.
[00:28:16.140 --> 00:28:22.380]   So I think that's what's sort of fun about it is that there's this natural complementarity,
[00:28:22.380 --> 00:28:29.420]   but there's so much for each side to learn that it's always really intellectually engaging.
[00:28:29.420 --> 00:28:36.940]   Do you feel like coming from like kind of a physics background, is it maybe like disappointing
[00:28:36.940 --> 00:28:42.040]   that I mean, do you worry at all that maybe the only way to explain some of these systems
[00:28:42.040 --> 00:28:44.780]   is through kind of a black box technique?
[00:28:44.780 --> 00:28:48.860]   I feel like the protein folding thing, it seems like for a long time, I knew that people
[00:28:48.860 --> 00:28:52.940]   were, it seemed like they were really trying to just simulate what would happen to the
[00:28:52.940 --> 00:28:53.940]   proteins.
[00:28:53.940 --> 00:28:58.360]   And I'm not totally up on the latest stuff, but it seemed to me like the approach that
[00:28:58.360 --> 00:29:02.380]   worked really well with the alpha fold was sort of less physics simulation and more just
[00:29:02.380 --> 00:29:03.380]   kind of like observing.
[00:29:03.380 --> 00:29:07.460]   I guess, where do you think that goes?
[00:29:07.460 --> 00:29:12.380]   So for me, what I really think about is, and this is sort of the heart of some of the stuff
[00:29:12.380 --> 00:29:20.980]   that we've been doing with Anshul Kondaji's lab, is what I think is, so here's my motivation
[00:29:20.980 --> 00:29:25.420]   for why I think we need to eventually know the physical principles.
[00:29:25.420 --> 00:29:33.100]   Let's say we were wanting to learn how to create a new ballistic or fly a new thing.
[00:29:33.100 --> 00:29:37.220]   If we just wanted to take this black box approach, it would be like, okay, each time we want
[00:29:37.220 --> 00:29:42.180]   to fly a new thing or make a new ballistic, we're just going to make a thousand ballistics
[00:29:42.180 --> 00:29:48.620]   and then we're going to shoot them and we're going to collect the data and then we'll hold
[00:29:48.620 --> 00:29:52.180]   out some of the data and we'll train a neural net and now we're going to be able to predict
[00:29:52.180 --> 00:29:55.180]   it for that system.
[00:29:55.180 --> 00:30:00.420]   The fact that we know the laws of gravity means that we're not restricted to just now
[00:30:00.420 --> 00:30:04.880]   working with that system that we've tested a thousand times.
[00:30:04.880 --> 00:30:09.860]   We can work with all kinds of systems because we have this generalizable physical model.
[00:30:09.860 --> 00:30:15.300]   I don't think it's necessarily at odds with machine learning approaches.
[00:30:15.300 --> 00:30:21.540]   One thing that we think is really exciting is, let's say you're able to train a neural
[00:30:21.540 --> 00:30:28.040]   net on a given dataset where you have a physical hypothesis about what's going on.
[00:30:28.040 --> 00:30:29.880]   We can do a lot of experiments.
[00:30:29.880 --> 00:30:33.820]   We can do a thousand experiments, a thousand measurements in parallel each time we run
[00:30:33.820 --> 00:30:39.860]   an assay, but that's often not enough to fully characterize a system.
[00:30:39.860 --> 00:30:45.580]   If you have a neural net that can predict behaviors, now we can feed it in things where
[00:30:45.580 --> 00:30:52.660]   we're systematically varying particular physical parameters to ask what it thinks.
[00:30:52.660 --> 00:30:59.220]   I think sometimes you can use these black box models as a way to do in silico experiments
[00:30:59.220 --> 00:31:05.260]   at a scale far beyond what you could reach with even the highest throughput.
[00:31:05.260 --> 00:31:06.260]   You can.
[00:31:06.260 --> 00:31:12.240]   In silico experiments, you can do millions or billions of in silico experiments, choose
[00:31:12.240 --> 00:31:19.820]   a thousand that you then go back and test with some of our experimental techniques to
[00:31:19.820 --> 00:31:22.540]   see what's going on.
[00:31:22.540 --> 00:31:29.260]   I think rather than just thinking of neural network predictions as an endpoint, like I'm
[00:31:29.260 --> 00:31:33.740]   going to train on this system and I'm going to predict for this system, can we use them
[00:31:33.740 --> 00:31:38.940]   as a tool to uncover generalizable physical principles?
[00:31:38.940 --> 00:31:44.620]   To me, that's a really interesting and complimentary way to think about those problems.
[00:31:44.620 --> 00:31:46.520]   Yeah, that makes sense.
[00:31:46.520 --> 00:31:50.340]   Another question, and I guess I'm just asking the dumb questions that maybe I'm afraid to
[00:31:50.340 --> 00:31:51.340]   ask other people.
[00:31:51.340 --> 00:31:52.340]   Do it.
[00:31:52.340 --> 00:31:53.340]   Yeah.
[00:31:53.340 --> 00:31:54.340]   I was going to ask, does it get image recognition?
[00:31:54.340 --> 00:31:59.940]   I feel like I've been working on image recognition for two decades, so I've seen it go from totally
[00:31:59.940 --> 00:32:05.940]   not working to working maybe better than humans in a lot of controlled cases.
[00:32:05.940 --> 00:32:09.420]   Yeah, particularly in clinical cases.
[00:32:09.420 --> 00:32:12.700]   There's a lot of clinical evidence that it can work better than people.
[00:32:12.700 --> 00:32:13.700]   Yeah.
[00:32:13.700 --> 00:32:14.700]   Yeah.
[00:32:14.700 --> 00:32:19.300]   You talked about how it's mostly trained off of images online.
[00:32:19.300 --> 00:32:26.100]   Really ImageNet was this moment where it started working where people decided to collect a
[00:32:26.100 --> 00:32:28.100]   huge set of data.
[00:32:28.100 --> 00:32:32.940]   And then there was this thing called transfer learning that's become mainstream where people
[00:32:32.940 --> 00:32:38.460]   take something trained on a big set of data and then they fine tune it on a smaller set
[00:32:38.460 --> 00:32:40.140]   of data.
[00:32:40.140 --> 00:32:43.180]   Do you feel like that is working in biology?
[00:32:43.180 --> 00:32:46.780]   Is there an analogy to that where there's some big data set that you could train on
[00:32:46.780 --> 00:32:51.860]   and then modify the models to work on smaller data sets?
[00:32:51.860 --> 00:32:55.500]   It just seems so clear that's what happened in images.
[00:32:55.500 --> 00:32:58.860]   I don't really know the biology analogies to that.
[00:32:58.860 --> 00:32:59.860]   Yeah.
[00:32:59.860 --> 00:33:01.500]   I think that's definitely...
[00:33:01.500 --> 00:33:06.980]   When I go to talks right now, everybody's always using transfer learning.
[00:33:06.980 --> 00:33:10.940]   It's because of the fact that it's hard to make measurements.
[00:33:10.940 --> 00:33:14.740]   Maybe you have one system and you've characterized it to death and now you want to know the other
[00:33:14.740 --> 00:33:15.740]   system.
[00:33:15.740 --> 00:33:19.180]   So the ability to train on the system that you've really characterized well and then
[00:33:19.180 --> 00:33:24.580]   predict in a different system, that's hugely valuable.
[00:33:24.580 --> 00:33:26.060]   That's hugely valuable.
[00:33:26.060 --> 00:33:29.220]   I think it's seeing applications all the time in biology.
[00:33:29.220 --> 00:33:32.740]   Maybe people have characterized one cell type really, really well.
[00:33:32.740 --> 00:33:38.060]   Now there's another cell type, but it costs so much money to characterize a cell type
[00:33:38.060 --> 00:33:42.620]   at that depth that now if they can use transfer learning to predict behavior for this novel
[00:33:42.620 --> 00:33:46.540]   cell type that hasn't been as well characterized, that's super valuable.
[00:33:46.540 --> 00:33:52.580]   Well, it seems like maybe one difference is that there's a lot of commercial interest
[00:33:52.580 --> 00:33:53.580]   in...
[00:33:53.580 --> 00:33:56.940]   I guess there's a lot of commercial interest in biology too, but maybe it's cheaper to
[00:33:56.940 --> 00:33:58.940]   classify images.
[00:33:58.940 --> 00:34:03.820]   It was interesting that one very motivated professor, Fei-Fei at Stanford, could make
[00:34:03.820 --> 00:34:07.580]   this amazing data set that changed the whole field.
[00:34:07.580 --> 00:34:11.600]   I sort of imagine that the same type of thing in biology would be expensive enough to make
[00:34:11.600 --> 00:34:17.020]   it complicated and hard and maybe no one's really motivated to do this as a general works
[00:34:17.020 --> 00:34:19.300]   project.
[00:34:19.300 --> 00:34:27.100]   I guess another thing is the ability to crowdsource measurements.
[00:34:27.100 --> 00:34:31.420]   People are generating images all day long and uploading them and making them publicly
[00:34:31.420 --> 00:34:32.420]   available.
[00:34:32.420 --> 00:34:35.900]   I think the closest you come to that would be sequencing.
[00:34:35.900 --> 00:34:44.120]   People are sequencing and people are willingly sharing all of their genomic data with 23andMe
[00:34:44.120 --> 00:34:46.880]   and Ancestry.com and all of these places.
[00:34:46.880 --> 00:34:51.200]   That has sort of seen crowdsourced growth.
[00:34:51.200 --> 00:34:55.120]   Still not on the scale of images, but a huge amount of data.
[00:34:55.120 --> 00:35:00.600]   But I think what's really lacking is we're getting more and more sequences and that's
[00:35:00.600 --> 00:35:01.600]   great.
[00:35:01.600 --> 00:35:05.980]   But in the same way that for the images, you not only needed the images, but you needed
[00:35:05.980 --> 00:35:11.640]   initially to know, is this a dog or a cat or an arm or a barbell or what is this?
[00:35:11.640 --> 00:35:14.480]   That's what I think we don't have as much in biology right now.
[00:35:14.480 --> 00:35:20.740]   We have all the sequence, but we don't have the functional annotation that goes with it
[00:35:20.740 --> 00:35:24.900]   that allows us to make that same sort of progress.
[00:35:24.900 --> 00:35:28.380]   I think to me, that's the bottleneck.
[00:35:28.380 --> 00:35:30.380]   That's the thing that we're trying to solve.
[00:35:30.380 --> 00:35:34.140]   Yeah, I actually didn't really realize what your work was on.
[00:35:34.140 --> 00:35:36.180]   It's so cool that you're...
[00:35:36.180 --> 00:35:40.940]   It seems like actually collecting data at a far bigger scale would be the perfect thing
[00:35:40.940 --> 00:35:43.940]   to make the mathematical models work better.
[00:35:43.940 --> 00:35:45.860]   It seems pretty cool.
[00:35:45.860 --> 00:35:48.820]   Yeah, I've been obsessed with...
[00:35:48.820 --> 00:35:54.580]   Marcus Covert told me about this book, The Weathermakers, that he said was really great.
[00:35:54.580 --> 00:35:57.580]   So I read it.
[00:35:57.580 --> 00:36:02.020]   We both took different things away from it, but part of the book is sort of talking about
[00:36:02.020 --> 00:36:08.100]   100 years ago, people had these kind of primitive atmospheric models where you could have a
[00:36:08.100 --> 00:36:12.220]   room full of people all doing calculations in parallel.
[00:36:12.220 --> 00:36:13.220]   And at the end of...
[00:36:13.220 --> 00:36:19.340]   They would start calculating and at the end of 24 hours, they had the ability to predict
[00:36:19.340 --> 00:36:22.100]   what the weather was going to be 24 hours in the future.
[00:36:22.100 --> 00:36:28.060]   So it was like all of these people calculating could basically just keep pace with time and
[00:36:28.060 --> 00:36:31.020]   it didn't really give you any predictive power.
[00:36:31.020 --> 00:36:36.060]   Now, we have these weather models that allow...
[00:36:36.060 --> 00:36:39.460]   You can look 10 days out and have a pretty good sense of if it's going to rain, if it's
[00:36:39.460 --> 00:36:42.580]   going to snow, what's going to happen with the weather.
[00:36:42.580 --> 00:36:48.180]   What Marcus took away from it is that you really need to look at an entire system, so
[00:36:48.180 --> 00:36:54.740]   like a cell in its entirety in order to really be able to model and understand the behavior.
[00:36:54.740 --> 00:37:01.900]   What I took away from it was this progress was really only enabled by the fact that we
[00:37:01.900 --> 00:37:08.780]   had weather stations around the world that were recording huge amounts of data, not in
[00:37:08.780 --> 00:37:15.420]   relative terms like, "Oh, it's 10% hotter today than it was yesterday," or "It's going
[00:37:15.420 --> 00:37:20.060]   to rain twice as much today as yesterday," but they were recording all of these data
[00:37:20.060 --> 00:37:28.100]   in terms of physical constants like temperature and precipitation, humidity, and that allowed
[00:37:28.100 --> 00:37:34.940]   us to develop these atmospheric models and to test the predictions of physical models
[00:37:34.940 --> 00:37:36.900]   and to develop this predictive power.
[00:37:36.900 --> 00:37:43.420]   So our big push, using these technologies, using these microfluidic technologies that
[00:37:43.420 --> 00:37:49.340]   make it possible to shrink biology and make measurements at a much more rapid pace, we're
[00:37:49.340 --> 00:37:53.340]   really interested in trying to say, "Can we do this for biological systems, but can we
[00:37:53.340 --> 00:37:57.420]   also always do it in the language of physical constants?"
[00:37:57.420 --> 00:38:03.740]   There's quantities like energies that reflect how much energy it takes to fold something
[00:38:03.740 --> 00:38:07.180]   and what the energy is when two different molecules come together.
[00:38:07.180 --> 00:38:10.580]   And so those are the kinds of quantities we're trying to measure.
[00:38:10.580 --> 00:38:16.740]   And I think that ultimately those types of measurements in concert with huge amounts
[00:38:16.740 --> 00:38:23.900]   of sequence data and ML algorithms that are seeking to predict the function of different
[00:38:23.900 --> 00:38:30.540]   sequences and how changes to the sequences alter function, those kinds of physical constants
[00:38:30.540 --> 00:38:35.700]   can be integrated with all of that other stuff to eventually attack these problems that seem
[00:38:35.700 --> 00:38:42.980]   intractable now, but so did weather prediction 100 years ago.
[00:38:42.980 --> 00:38:47.180]   So I feel like scientists always hate to answer this question, but I'm sure everybody's thinking
[00:38:47.180 --> 00:38:49.380]   it when you use that analogy.
[00:38:49.380 --> 00:38:59.020]   When you roll this kind of work forward 10 or 20 years or more, how would it affect my
[00:38:59.020 --> 00:39:00.020]   day-to-day life?
[00:39:00.020 --> 00:39:05.340]   Is it a lot of diseases get cured?
[00:39:05.340 --> 00:39:08.660]   What is the ultimate impact of this stuff?
[00:39:08.660 --> 00:39:09.660]   Yeah.
[00:39:09.660 --> 00:39:16.180]   So a lot of our science is pretty basic to be unashamed about it.
[00:39:16.180 --> 00:39:24.140]   So a defense of that is CRISPR has been this amazing tool and it came from people studying
[00:39:24.140 --> 00:39:26.540]   the mechanisms of bacterial immunity.
[00:39:26.540 --> 00:39:31.660]   Everybody was looking for things that were necessarily going to transform our ability
[00:39:31.660 --> 00:39:37.540]   to engineer genomes, but that's what we found in the course of doing basic scientific research.
[00:39:37.540 --> 00:39:43.660]   For me, what would be tangible things that I would hope could come out of some of our
[00:39:43.660 --> 00:39:52.060]   research are, I hope that we can characterize functional variants across some of these proteins
[00:39:52.060 --> 00:39:58.380]   so that clinicians can tell their patients this mutation that you have, like the measurements
[00:39:58.380 --> 00:40:03.140]   we make could improve the algorithms that would allow a clinician to say to a patient,
[00:40:03.140 --> 00:40:07.580]   you have this mutation and I think it means that we should treat you with this drug.
[00:40:07.580 --> 00:40:14.140]   So sort of closing the loop on precision medicine beyond the most common variants to more rare
[00:40:14.140 --> 00:40:17.740]   variants that people have to provide clinically actionable information.
[00:40:17.740 --> 00:40:24.140]   For precision medicine, some of the things that we're doing where we're looking at these
[00:40:24.140 --> 00:40:30.060]   individual cells, we have these droplet platforms as well as some other platforms.
[00:40:30.060 --> 00:40:36.140]   I'd like those to become something where we could work with actual clinical samples to
[00:40:36.140 --> 00:40:43.420]   say we looked at the cells from your tumor and we're able to say that a small fraction
[00:40:43.420 --> 00:40:51.060]   of them carry this particular resistance marker, or we tested the drug sensitivity profile
[00:40:51.060 --> 00:40:55.500]   of the cells from your tumor and so we're recommending this course of action.
[00:40:55.500 --> 00:41:05.460]   And then beyond medicine, I think the ability to say, we've got to design enzymes with particular
[00:41:05.460 --> 00:41:10.780]   functions, the ability to say, okay, we've got this toxic chemical that has leaked out
[00:41:10.780 --> 00:41:14.500]   of this mine, how are we going to clean it up?
[00:41:14.500 --> 00:41:19.260]   What if in the same way that you can write a program to do certain things, what if we
[00:41:19.260 --> 00:41:25.380]   could now specify the DNA that makes the protein that would have the capability of breaking
[00:41:25.380 --> 00:41:28.580]   down that compound to be non-toxic?
[00:41:28.580 --> 00:41:31.660]   To me, those are all the dreams of...
[00:41:31.660 --> 00:41:33.580]   Those are the three dreams of the research we're doing.
[00:41:33.580 --> 00:41:41.260]   And then I would say the last thing is, as a faculty at a university, my biggest impact
[00:41:41.260 --> 00:41:47.500]   will probably not even come from my own work, but I'm training all of these incredibly talented
[00:41:47.500 --> 00:41:49.660]   graduate students and postdocs.
[00:41:49.660 --> 00:41:57.260]   And so if one of them acquires the skills that allows them to go off and solve some
[00:41:57.260 --> 00:42:03.740]   of these problems or run things, then your function is fulfilled.
[00:42:03.740 --> 00:42:09.340]   So you're not only trying to do research and take grant money that the public gave you
[00:42:09.340 --> 00:42:17.100]   reluctantly and turn it into papers and knowledge, you're also trying to be a mentor that allows
[00:42:17.100 --> 00:42:21.220]   people to come through your lab to gain the skills that they need to be successful in
[00:42:21.220 --> 00:42:26.560]   the future in industry or in research or as public communicators or whatever they decide
[00:42:26.560 --> 00:42:27.560]   to do.
[00:42:27.560 --> 00:42:28.560]   Wow.
[00:42:28.560 --> 00:42:33.500]   I wish I could go back to grad school and work in the Fortis lab.
[00:42:33.500 --> 00:42:34.500]   That's pretty awesome.
[00:42:34.500 --> 00:42:35.500]   I love my lab.
[00:42:35.500 --> 00:42:36.500]   My lab is amazing.
[00:42:36.500 --> 00:42:37.500]   Yeah.
[00:42:37.500 --> 00:42:38.500]   They're great.
[00:42:38.500 --> 00:42:39.500]   Yeah.
[00:42:39.500 --> 00:42:47.380]   I guess one final question, because I know we have so many students that watch this.
[00:42:47.380 --> 00:42:52.900]   If you were starting your career, or I guess how would you guide an ML-oriented person
[00:42:52.900 --> 00:42:57.980]   early in their career who's really interested in the biological applications, where would
[00:42:57.980 --> 00:43:05.220]   you guide them to look for having a successful career for the next few decades?
[00:43:05.220 --> 00:43:09.820]   I guess are they going to school or are they not going to school?
[00:43:09.820 --> 00:43:10.820]   Going to school.
[00:43:10.820 --> 00:43:11.820]   Yeah.
[00:43:11.820 --> 00:43:15.820]   I guess I would encourage...
[00:43:15.820 --> 00:43:23.460]   I think the most...to me, the people that have the most impact and a lot of my collaborators,
[00:43:23.460 --> 00:43:31.700]   my ML collaborators that I'm most always in awe of, I think what they're able to do is
[00:43:31.700 --> 00:43:38.820]   not only are they incredibly proficient at developing novel algorithms, I think that's
[00:43:38.820 --> 00:43:41.620]   hard, but there's a lot of people that are good at that.
[00:43:41.620 --> 00:43:47.460]   That's very competitive to be the absolute best at just straight up algorithm development.
[00:43:47.460 --> 00:43:53.740]   I think the ones that really try and engage with the biology, so ask all the stupid questions,
[00:43:53.740 --> 00:43:59.660]   starting with the very first thing that they don't understand, ask questions all the time,
[00:43:59.660 --> 00:44:04.780]   try and get references about the biology literature or the physics literature.
[00:44:04.780 --> 00:44:11.780]   I really think that there's so many things in common between machine learning and the
[00:44:11.780 --> 00:44:16.380]   way in which it works and statistical mechanics and thermodynamics and just the mathematical
[00:44:16.380 --> 00:44:18.820]   frameworks of both are really very similar.
[00:44:18.820 --> 00:44:26.280]   I think becoming conversant in both of those really positions you where I think it's easier
[00:44:26.280 --> 00:44:31.180]   to leverage these really powerful algorithms you're developing to make the most progress
[00:44:31.180 --> 00:44:34.980]   in the field that you're trying to attack.
[00:44:34.980 --> 00:44:35.980]   Awesome.
[00:44:35.980 --> 00:44:36.980]   That makes total sense.
[00:44:36.980 --> 00:44:38.620]   The stupid question thing, I really mean it.
[00:44:38.620 --> 00:44:46.460]   When I started my postdoc, I had been trained in physics and I asked questions where my
[00:44:46.460 --> 00:44:51.660]   advisor literally put his head in his hands because he couldn't believe that anybody didn't
[00:44:51.660 --> 00:44:52.660]   know this.
[00:44:52.660 --> 00:44:55.940]   The students that were training me would be like, "Can you go run this on a gel?"
[00:44:55.940 --> 00:44:59.140]   I was like, "No, because I do not know how to run gels."
[00:44:59.140 --> 00:45:03.860]   Which is something that every biologist knows.
[00:45:03.860 --> 00:45:04.860]   It was painful.
[00:45:04.860 --> 00:45:11.500]   I cried that first six months because I felt so stupid all the time.
[00:45:11.500 --> 00:45:18.020]   But I think being willing to ask those incredibly stupid questions over and over and over again,
[00:45:18.020 --> 00:45:20.260]   it makes that learning curve steep.
[00:45:20.260 --> 00:45:22.380]   It's painful, but it makes the learning curve steep.
[00:45:22.380 --> 00:45:25.380]   I think it's the thing to do.
[00:45:25.380 --> 00:45:26.380]   Awesome.
[00:45:26.380 --> 00:45:27.380]   Well, thanks for answering my stupid questions.
[00:45:27.380 --> 00:45:28.380]   That was a lot of fun.
[00:45:28.380 --> 00:45:29.380]   They weren't stupid at all.
[00:45:29.380 --> 00:45:30.380]   They were really good.
[00:45:30.380 --> 00:45:31.380]   Yeah.
[00:45:31.380 --> 00:45:35.660]   Thanks for listening to another episode of Gradient Dissent.
[00:45:35.660 --> 00:45:39.940]   Doing these interviews are a lot of fun and it's especially fun for me when I can actually
[00:45:39.940 --> 00:45:43.380]   hear from the people that are listening to these episodes.
[00:45:43.380 --> 00:45:48.100]   If you wouldn't mind leaving a comment and telling me what you think or starting a conversation,
[00:45:48.100 --> 00:45:50.740]   that would make me inspired to do more of these episodes.
[00:45:50.740 --> 00:45:54.300]   And also, if you wouldn't mind liking and subscribing, I'd appreciate that a lot.

