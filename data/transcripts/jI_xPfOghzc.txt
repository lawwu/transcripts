
[00:00:00.000 --> 00:00:10.000]   [BLANK_AUDIO]
[00:00:10.000 --> 00:00:38.000]   Hey everybody, and welcome back to week 11 of Fast Book Reading Group.
[00:00:38.000 --> 00:00:42.640]   It's been an exciting week as well, the past week.
[00:00:42.640 --> 00:00:47.280]   And this week, we'll be finishing up what we left last week,
[00:00:47.280 --> 00:00:51.240]   which was about looking at movie recommendation using Fast AI.
[00:00:51.240 --> 00:00:53.720]   So what we're gonna do this week is that was chapter eight.
[00:00:53.720 --> 00:00:55.160]   So we will wrap up chapter eight.
[00:00:55.160 --> 00:00:57.440]   And instead of going to chapter nine, ten, eleven, so
[00:00:57.440 --> 00:01:00.280]   let me just show you how fast it looks like.
[00:01:00.280 --> 00:01:03.240]   So if I go to Fast Book, I have it open here.
[00:01:03.240 --> 00:01:07.120]   So as you can see, chapter nine is tabular, ten is NLP,
[00:01:07.120 --> 00:01:09.200]   mid-level data, and then NLP dive.
[00:01:09.200 --> 00:01:12.680]   So I thought, we've been doing computer vision for a while, and
[00:01:12.680 --> 00:01:17.840]   it's completely okay to come back to some specific chapters after some time.
[00:01:17.840 --> 00:01:23.400]   So what we're gonna do is, we're going to wrap up chapter eight.
[00:01:23.400 --> 00:01:28.080]   And then I'm gonna have Zach Mueller, I reached out to him and
[00:01:28.080 --> 00:01:30.960]   I asked for his help on like with tabular.
[00:01:30.960 --> 00:01:33.480]   So he's probably gonna come in and present about tabular,
[00:01:33.480 --> 00:01:35.680]   show some of his really cool projects.
[00:01:35.680 --> 00:01:37.920]   And that's when we'll get started with tabular.
[00:01:37.920 --> 00:01:42.560]   But in the meantime, we will do chapter eight and move on to convolutions.
[00:01:42.560 --> 00:01:43.840]   So that's the idea for today.
[00:01:43.840 --> 00:01:50.280]   So as you can see, if you go to that link, 1db.me/fastbook11,
[00:01:50.280 --> 00:01:54.040]   this is a really, really exciting time for me.
[00:01:54.040 --> 00:01:57.960]   If you go to that link, 1db.me/fastbook11,
[00:01:57.960 --> 00:02:01.280]   instead of this taking you to the usual place,
[00:02:01.280 --> 00:02:05.440]   it will take you to Weights and Biases forums, hooray.
[00:02:05.440 --> 00:02:10.320]   So something that's changed this week from all the other past weeks is that
[00:02:10.320 --> 00:02:16.600]   we are really excited to announce that Weights and Biases has its own forums now.
[00:02:16.600 --> 00:02:21.200]   And what this does is, it just adds a lot more structure to a lot of things.
[00:02:21.200 --> 00:02:24.440]   So if you're doing fastbook, you can see this like this community events,
[00:02:24.440 --> 00:02:25.960]   we can go into community events and
[00:02:25.960 --> 00:02:28.800]   you can see there's so many other community events that are on.
[00:02:28.800 --> 00:02:31.960]   So you can see this fastbook, this Chai Time Kaggle.
[00:02:31.960 --> 00:02:36.120]   Some of these are a little bit private because this is still in the very beta
[00:02:36.120 --> 00:02:39.560]   version right now and Angelica, who is behind it,
[00:02:39.560 --> 00:02:44.320]   is actually working nonstop to add new and new things to the forums.
[00:02:44.320 --> 00:02:48.160]   So this is still in beta, but it's going to change a little bit.
[00:02:48.160 --> 00:02:50.160]   Actually, it's going to change quite a bit.
[00:02:50.160 --> 00:02:53.560]   But for now, if we go to this fastbook reading group,
[00:02:53.560 --> 00:02:56.200]   you can see there's a week 11 discussion thread.
[00:02:56.200 --> 00:03:00.640]   So our discussion is going to happen here and this is exactly the same as last,
[00:03:00.640 --> 00:03:04.880]   as pretty much the Weights and Biases fully connected forums that you're used to.
[00:03:04.880 --> 00:03:08.040]   So if you go here and you can just say reply.
[00:03:08.040 --> 00:03:10.360]   So anytime you have a question, you just say reply.
[00:03:10.360 --> 00:03:13.200]   I'm just going to put comment here and I'm just going to say reply.
[00:03:13.200 --> 00:03:15.520]   Oh, it says post must be at least 20 characters.
[00:03:15.520 --> 00:03:19.840]   So if your characters are less than 20, just do something like that.
[00:03:19.840 --> 00:03:21.440]   And that should be fine.
[00:03:21.440 --> 00:03:23.440]   So let's just say...
[00:03:23.440 --> 00:03:25.520]   Test body is too short. It's not letting me do it.
[00:03:25.520 --> 00:03:31.040]   Okay. I'm going to make sure that I write 20 characters.
[00:03:31.040 --> 00:03:33.680]   How about that? And now I can say test.
[00:03:33.680 --> 00:03:37.120]   So I just did that and then that will let me post and it's still very live.
[00:03:37.120 --> 00:03:41.600]   So while I'm doing the session and we're going through the fastbook week 11,
[00:03:41.600 --> 00:03:45.040]   you can post your questions here and I'll come back time to time
[00:03:45.040 --> 00:03:47.120]   and keep checking your questions.
[00:03:47.120 --> 00:03:50.320]   And then the nice thing about the forums,
[00:03:50.320 --> 00:03:53.120]   if you haven't used the Discourse forums before,
[00:03:53.120 --> 00:03:58.880]   is that if you go to forums.fast.ai, these are again Discourse forums.
[00:03:58.880 --> 00:04:05.200]   So it's just going to be much easier for you to go into now the Fast.ai community
[00:04:05.200 --> 00:04:08.160]   once you're used to it, once you get used to the forums.
[00:04:08.160 --> 00:04:12.880]   And there's also a lot of other things that are happening at these forums.
[00:04:12.880 --> 00:04:16.320]   So eventually what we're going to do is we're going to slowly...
[00:04:16.320 --> 00:04:18.560]   We've already started shifting towards the forums
[00:04:18.560 --> 00:04:22.000]   and that's something that we're going to do week after week in the coming times.
[00:04:22.320 --> 00:04:28.800]   And so that being said, so if you go to that link,
[00:04:28.800 --> 00:04:31.840]   please make sure that you're able to log into forums and test.
[00:04:31.840 --> 00:04:34.640]   And if you're not, please feel free to chat,
[00:04:34.640 --> 00:04:40.000]   post a chat in Zoom and Angelica maybe can help you out.
[00:04:40.000 --> 00:04:41.200]   So that's that.
[00:04:41.200 --> 00:04:45.440]   So this week, I only saw the one really nice...
[00:04:45.440 --> 00:04:49.040]   I only saw the one really nice blog post from Vinayak
[00:04:49.040 --> 00:04:50.880]   and I really, really like this post.
[00:04:50.880 --> 00:04:54.560]   It uses Microsoft Excel to explain pretty much spreadsheets
[00:04:54.560 --> 00:04:56.720]   to explain multi-label classification.
[00:04:56.720 --> 00:04:59.040]   And thanks Vinayak for coming week after week
[00:04:59.040 --> 00:05:02.880]   and then sharing all of these really wonderful blog posts with us.
[00:05:02.880 --> 00:05:06.400]   So you can see if you have logits, you can do a sigmoid operation
[00:05:06.400 --> 00:05:09.040]   and then you can see in front of you what those values are going to be.
[00:05:09.040 --> 00:05:11.760]   And instead of like using sigmoid, if you did a softmax,
[00:05:11.760 --> 00:05:13.280]   what those values are going to be.
[00:05:13.280 --> 00:05:15.760]   And then you can compare and look at all these
[00:05:15.760 --> 00:05:17.760]   interesting, interesting things in this blog post.
[00:05:17.760 --> 00:05:18.960]   So I really, really like it.
[00:05:20.320 --> 00:05:25.440]   Having said that, I'm really sorry if I missed anybody's blog post.
[00:05:25.440 --> 00:05:29.760]   So if in case I did, please feel free to post in chat or on the forums
[00:05:29.760 --> 00:05:31.360]   and I will make sure.
[00:05:31.360 --> 00:05:33.760]   But this is the only one I could find for this week.
[00:05:33.760 --> 00:05:38.160]   Okay. So let's get started with Colab.
[00:05:38.160 --> 00:05:47.920]   When that loads.
[00:05:49.840 --> 00:05:55.360]   So I'm going to zoom out a little bit because I think that's quite zoomed in.
[00:05:55.360 --> 00:05:57.600]   Let me know if that's fine.
[00:05:57.600 --> 00:06:02.000]   And in case it isn't, just feel free to post again on the forums
[00:06:02.000 --> 00:06:03.440]   or just in the chat for now.
[00:06:03.440 --> 00:06:09.760]   So we last time where we left this was creating our own embeddings.
[00:06:09.760 --> 00:06:13.840]   So we looked at what embeddings are and we looked at basically
[00:06:13.840 --> 00:06:17.280]   we created our own model called dot product bias.
[00:06:17.280 --> 00:06:20.720]   And in that we saw like in PyTorch, if you want to create parameters
[00:06:20.720 --> 00:06:26.480]   that can be learned, we saw that you have to wrap things inside an nn.parameter.
[00:06:26.480 --> 00:06:28.160]   So let's see where that is.
[00:06:28.160 --> 00:06:28.800]   So here it is.
[00:06:28.800 --> 00:06:32.480]   First, we use the nn.embeddings and we created that.
[00:06:32.480 --> 00:06:35.840]   So which basically means it's just like a matrix, but it will be learned.
[00:06:35.840 --> 00:06:39.040]   And you can index into these embedding matrices.
[00:06:39.040 --> 00:06:43.520]   And then the next thing was we saw create params, which is here.
[00:06:43.520 --> 00:06:47.120]   So we created this small function and we looked at this small function
[00:06:47.120 --> 00:06:48.320]   called create params.
[00:06:48.320 --> 00:06:52.560]   And in that, what we did is if you provide a size, a size could maybe be like
[00:06:52.560 --> 00:06:56.560]   20 by 30 or some size like that.
[00:06:56.560 --> 00:07:00.160]   Then if you provide a size like that, then pretty much it will create
[00:07:00.160 --> 00:07:03.440]   an nn.parameter of that shape.
[00:07:03.440 --> 00:07:07.440]   And that then becomes a trainable parameter in your model.
[00:07:07.440 --> 00:07:08.880]   So we just use this function.
[00:07:08.880 --> 00:07:13.760]   Sorry, give me one sec.
[00:07:13.760 --> 00:07:16.080]   Something's running and it's taking a little bit of time.
[00:07:16.080 --> 00:07:17.200]   Oh, there it is.
[00:07:17.200 --> 00:07:17.840]   It's that one.
[00:07:17.840 --> 00:07:22.080]   So let's that run and then I can actually just stop it.
[00:07:22.080 --> 00:07:23.120]   Cool.
[00:07:23.120 --> 00:07:28.320]   Now I'll just go back to, so we saw this model, we saw weight decay.
[00:07:28.320 --> 00:07:36.240]   And we finally wrapped up creating our own matrices, all of that.
[00:07:36.240 --> 00:07:40.400]   And we're back to now and we're at that point of like interpreting, embedding and biases.
[00:07:41.920 --> 00:07:46.880]   So one thing, if you remember last week, as I said, what exactly are embedding matrices?
[00:07:46.880 --> 00:07:50.640]   If you remember that these are basically latent factors.
[00:07:50.640 --> 00:07:57.440]   So like a movie has latent factors, like how old it is, or it has latent factors,
[00:07:57.440 --> 00:07:59.280]   like how much action is there in the movie?
[00:07:59.280 --> 00:08:01.840]   Or it has latent factors, like, is it a musical?
[00:08:01.840 --> 00:08:06.240]   Or like, these are some properties of movie that we can say latent factors.
[00:08:06.240 --> 00:08:08.960]   And instead of just having like five latent factors for a movie,
[00:08:08.960 --> 00:08:15.440]   it is completely possible to have like 256 or like 50 in our case, when we saw in this example.
[00:08:15.440 --> 00:08:18.400]   Oh, it's training again.
[00:08:18.400 --> 00:08:19.280]   Sorry, one sec.
[00:08:19.280 --> 00:08:20.880]   Let me just stop that from training.
[00:08:20.880 --> 00:08:24.320]   Any training over here?
[00:08:24.320 --> 00:08:24.880]   No training.
[00:08:24.880 --> 00:08:25.520]   Oh, there it is.
[00:08:25.520 --> 00:08:26.640]   That's the last one.
[00:08:26.640 --> 00:08:29.120]   So anyways, now let this model train.
[00:08:29.120 --> 00:08:32.560]   So we're going to see how, let me just wrap this up.
[00:08:32.560 --> 00:08:35.840]   But in this time, then what we're going to do today is we're going to see how you can
[00:08:35.840 --> 00:08:37.520]   now interpret those embeddings.
[00:08:37.520 --> 00:08:44.800]   So what's actually going to happen is that for every movie, the model is going to learn
[00:08:44.800 --> 00:08:48.960]   some characteristics that are relevant to the movie.
[00:08:48.960 --> 00:08:58.800]   So if I go to my one node, if I have one, two, let's say three movies,
[00:08:58.800 --> 00:09:04.960]   and each movie is represented by a 50 long vector, right?
[00:09:04.960 --> 00:09:07.440]   So this is 50.
[00:09:07.440 --> 00:09:09.920]   This is also 50.
[00:09:09.920 --> 00:09:13.520]   This is also 50 and so on.
[00:09:13.520 --> 00:09:17.440]   And this is say my movie one.
[00:09:17.440 --> 00:09:19.360]   This is my movie two.
[00:09:19.360 --> 00:09:20.880]   This is my movie three.
[00:09:20.880 --> 00:09:24.240]   And the next thing we also looked at was bias last time.
[00:09:24.240 --> 00:09:31.360]   So you saw that to make our model better, we also added like this single term,
[00:09:31.360 --> 00:09:32.800]   which is what you called bias.
[00:09:32.960 --> 00:09:38.400]   Just give me one sec.
[00:09:38.400 --> 00:09:43.600]   So we added this, let's say B1 for bias for movie one, B2, and B3.
[00:09:43.600 --> 00:09:48.800]   And we call the orange parts as embeddings, right?
[00:09:48.800 --> 00:09:54.480]   So these are embedding.
[00:09:54.480 --> 00:10:00.000]   So now the thing is that each movie, for each movie, we learn something
[00:10:00.560 --> 00:10:03.840]   that's like 50 properties that are relevant to that movie.
[00:10:03.840 --> 00:10:06.160]   And then we do the same thing for users as well.
[00:10:06.160 --> 00:10:10.880]   So you can represent your users like user one, user two,
[00:10:10.880 --> 00:10:14.880]   and you could also represent your user three.
[00:10:14.880 --> 00:10:22.640]   And we do the exact same process, like the exact same thing as above for users.
[00:10:22.640 --> 00:10:25.360]   So now by the time the model has finished training,
[00:10:25.360 --> 00:10:29.040]   what has exactly happened is that a model has learned
[00:10:29.040 --> 00:10:33.040]   to identify a movie by its characteristics or latent factors.
[00:10:33.040 --> 00:10:37.440]   And similarly, a model has learned to classify or not exactly classify,
[00:10:37.440 --> 00:10:39.520]   but it's learned some things about the user.
[00:10:39.520 --> 00:10:42.400]   So if I'm a user, it's learned things about me.
[00:10:42.400 --> 00:10:46.080]   Let's say I'm this person. Let's say I am you one or user one.
[00:10:46.080 --> 00:10:49.120]   And now what the model has done that when I finish this training
[00:10:49.120 --> 00:10:52.480]   or when the model has finished training, it has learned some things about me.
[00:10:52.480 --> 00:10:55.840]   It has learned like things like if I like new movies
[00:10:55.840 --> 00:10:58.640]   or do I like old movies, that is classicals.
[00:10:58.640 --> 00:11:01.040]   It has learned if I like action movies.
[00:11:01.040 --> 00:11:02.800]   It has learned if I like musical movies,
[00:11:02.800 --> 00:11:04.880]   or there's just these characteristics that it has learned.
[00:11:04.880 --> 00:11:08.720]   And similarly, it has learned characteristics about movies.
[00:11:08.720 --> 00:11:11.440]   So the characteristics that it has learned about movies are,
[00:11:11.440 --> 00:11:14.800]   is it an old movie or a new movie?
[00:11:14.800 --> 00:11:18.800]   Or is it a musical? Or is it like how much action it is?
[00:11:18.800 --> 00:11:24.080]   So now what the model can do, so let's say if the model is sitting
[00:11:24.080 --> 00:11:28.480]   in the center somewhere here, let's say this is my model.
[00:11:28.480 --> 00:11:32.000]   I'm just kind of showing an example. So let's say this is my model.
[00:11:32.000 --> 00:11:37.680]   So what the model can do is it can match the user who it understands.
[00:11:37.680 --> 00:11:42.240]   The model understands the user by now, and it can match the user to some movie
[00:11:42.240 --> 00:11:46.640]   that the model thinks that the latent factors match with each other.
[00:11:46.640 --> 00:11:50.880]   So if this person, you one, likes a movie that's full of action,
[00:11:50.880 --> 00:11:54.080]   and M3 is a movie that has a lot of action,
[00:11:54.080 --> 00:11:58.960]   then it's possible that you one or the user one is going to like movie three.
[00:11:58.960 --> 00:12:01.200]   So that's how these recommendation systems work.
[00:12:01.200 --> 00:12:05.040]   So that's the basic idea that we wrapped up last time.
[00:12:05.040 --> 00:12:10.880]   And now what we're going to do is like what the model,
[00:12:10.880 --> 00:12:14.720]   so what's happened by now, one second, let me just make this a little bit bigger.
[00:12:14.720 --> 00:12:18.320]   So now we already know that the model has learned things about the movies,
[00:12:18.320 --> 00:12:21.600]   and it has learned things about the users as well, right?
[00:12:21.600 --> 00:12:24.960]   So this is the user embedding, and then this is,
[00:12:24.960 --> 00:12:31.120]   let me just also draw the user bias. So this is user bias.
[00:12:31.120 --> 00:12:38.160]   So let's just call it B1 dash, B2 dash, and let's call it embedding two dash,
[00:12:38.160 --> 00:12:44.000]   embedding three dash. And this is embedding three, embedding two, embedding one.
[00:12:44.000 --> 00:12:47.600]   And now when the model has finished training is that it has learned these embeddings.
[00:12:47.600 --> 00:12:49.280]   And what are these embeddings?
[00:12:49.280 --> 00:12:55.440]   These embeddings are some things or some features or some latent factors
[00:12:55.440 --> 00:12:59.760]   that the model has learned about the movies and the users, right?
[00:12:59.760 --> 00:13:02.320]   That's how it is able to match a user to a movie.
[00:13:02.320 --> 00:13:07.680]   So then what we want to do, don't you think it would make really good sense
[00:13:07.680 --> 00:13:12.000]   to now be able to interpret those embeddings?
[00:13:12.000 --> 00:13:16.400]   So like we can, what if we were able to plot these embeddings, right?
[00:13:16.400 --> 00:13:22.160]   What if the model can characterize these, what if the model can characterize these embeddings,
[00:13:22.160 --> 00:13:23.680]   these movies based on these embeddings?
[00:13:23.680 --> 00:13:28.560]   So like things like, oh, the model already knows that movie one is full of action.
[00:13:28.560 --> 00:13:31.280]   The model already knows that movie two is full of action.
[00:13:31.280 --> 00:13:34.480]   And the model already knows that movie three is, let's say, full of,
[00:13:34.480 --> 00:13:40.320]   let's say it's full of, it's a very new movie, or let's say it's full of musical.
[00:13:40.320 --> 00:13:42.880]   There's very less action in movie three.
[00:13:42.880 --> 00:13:46.000]   Then what the model can do is like based on these embedding matrices,
[00:13:46.000 --> 00:13:51.120]   if we start to plot them, you will see that the model will bring M1 and M2 together
[00:13:51.120 --> 00:13:55.040]   because it thinks that they are similar based on what it has learned about these movies.
[00:13:55.040 --> 00:13:58.960]   And you will see that it will take M3 further away.
[00:13:58.960 --> 00:14:02.800]   So we need to be able to now be able to interpret these embeddings and biases.
[00:14:02.800 --> 00:14:04.480]   And that's what we're going to do in this section.
[00:14:04.480 --> 00:14:10.400]   So let's grab, this is learn.model is now my learned model,
[00:14:10.400 --> 00:14:12.720]   or the model that has learned and finished training.
[00:14:12.720 --> 00:14:16.400]   And it has learned things about my movies and the users.
[00:14:16.400 --> 00:14:19.680]   And now let's just grab the movie biases from it.
[00:14:19.680 --> 00:14:22.800]   Okay. So let's see what the shape of this movie bias is.
[00:14:22.800 --> 00:14:25.360]   What do you think is the shape going to be?
[00:14:25.360 --> 00:14:31.280]   Is one thing before I print, how about let's just think what the shape is going to be.
[00:14:31.280 --> 00:14:33.920]   So let's say how many, how many movies did we have?
[00:14:33.920 --> 00:14:37.680]   Is there something called n movies in this?
[00:14:37.680 --> 00:14:40.640]   I think there was something called n movies, right?
[00:14:40.640 --> 00:14:41.440]   There it is.
[00:14:41.440 --> 00:14:44.480]   So we had 1665 movies, right?
[00:14:44.480 --> 00:14:51.280]   And if I tell you each movie has a bias, then the shape of this should be around 1665.
[00:14:51.280 --> 00:14:54.000]   That's my prediction.
[00:14:54.000 --> 00:14:58.560]   And it is 1665 because each movie gets one bias, right?
[00:14:58.560 --> 00:15:03.520]   And what this bias was, just to recap what this bias was,
[00:15:03.520 --> 00:15:07.280]   this bias was a thing like about the movie that
[00:15:07.280 --> 00:15:10.400]   we're actually going to interpret these things.
[00:15:10.400 --> 00:15:12.160]   And we're going to learn what they are.
[00:15:12.160 --> 00:15:15.120]   But to give you an intuition about what these biases are,
[00:15:15.120 --> 00:15:18.640]   so these embeddings are characteristics about these movies and users.
[00:15:18.640 --> 00:15:21.280]   And what biases are, biases are things like,
[00:15:21.280 --> 00:15:24.960]   oh, you know, you know how we say in proper English, like my opinion is biased.
[00:15:24.960 --> 00:15:30.080]   So in this sense as well, bias has the same meaning.
[00:15:30.080 --> 00:15:37.760]   A bias is just like, it's like a, it's more like, even if the movie matches,
[00:15:37.760 --> 00:15:42.640]   like even if the movie is full of action and a user likes a lot of action movies,
[00:15:42.640 --> 00:15:46.560]   then it is possible that this movie would still be a bad movie.
[00:15:46.560 --> 00:15:51.360]   Or like for this user, when this, you know how some people are,
[00:15:51.360 --> 00:15:55.280]   like they don't like to give good ratings to movies and they're like very negative.
[00:15:55.280 --> 00:15:57.520]   That's just their bias, right?
[00:15:57.520 --> 00:15:58.480]   That's just who they are.
[00:15:58.480 --> 00:16:04.560]   That's just like their characteristic, but that's just like how their nature is.
[00:16:04.560 --> 00:16:08.000]   So that's the bias about the users, okay?
[00:16:08.000 --> 00:16:12.880]   And when, even if this user says, oh, I like action movies
[00:16:12.880 --> 00:16:16.080]   and the model presents something like M3 to it,
[00:16:16.080 --> 00:16:19.440]   it's very much possible that the user will still not like the movie
[00:16:19.440 --> 00:16:21.200]   because that's just the bias of that user.
[00:16:21.200 --> 00:16:23.360]   This user doesn't really like anything.
[00:16:23.360 --> 00:16:28.880]   So it's just very possible that these are biases about movies and users.
[00:16:28.880 --> 00:16:33.040]   So let's see how we can interpret these biases.
[00:16:33.440 --> 00:16:37.520]   Did somebody raise their hand?
[00:16:37.520 --> 00:16:38.720]   Rinder, did you raise your hand?
[00:16:38.720 --> 00:16:40.080]   Do you really want to say something?
[00:16:40.080 --> 00:16:42.400]   I can just say allow to talk.
[00:16:42.400 --> 00:16:43.840]   So if you want to post on the...
[00:16:43.840 --> 00:16:47.440]   Let me go to the forums just in case you posted something.
[00:16:47.440 --> 00:17:00.960]   Okay. Looks like there's no question so far.
[00:17:00.960 --> 00:17:02.560]   So maybe that was my mistake.
[00:17:03.280 --> 00:17:04.160]   All right. Let's keep going.
[00:17:04.160 --> 00:17:10.880]   So what we want to do now is we want to be able to interpret these biases, right?
[00:17:10.880 --> 00:17:17.920]   So let's just grab the top five movies that have the lowest biases.
[00:17:17.920 --> 00:17:25.440]   So let's see the indexes of those movies out of my 1665 on that.
[00:17:25.440 --> 00:17:27.520]   And now let's just check what these movies are.
[00:17:27.520 --> 00:17:31.920]   So these movies are children of the con or like Robocop or Mortal Kombat.
[00:17:31.920 --> 00:17:34.080]   And what exactly does this mean?
[00:17:34.080 --> 00:17:36.720]   Like having a low bias for a movie?
[00:17:36.720 --> 00:17:44.000]   That just means even if the model matches a user that likes action movies
[00:17:44.000 --> 00:17:47.840]   and it matches a movie that has action in it,
[00:17:47.840 --> 00:17:50.720]   but if the movie has low bias, then what it means is that
[00:17:50.720 --> 00:17:55.520]   it is still not going to be liked by the people because it just has a low bias.
[00:17:55.520 --> 00:17:56.560]   It's just that bias.
[00:17:56.560 --> 00:17:59.440]   So it's just that the nature of that movie that even if it has action,
[00:17:59.440 --> 00:18:03.760]   even if you know how some movies have action, they have musical and they are new,
[00:18:03.760 --> 00:18:05.840]   but it's still they're like really bad movies.
[00:18:05.840 --> 00:18:08.160]   That's the bias about the movie.
[00:18:08.160 --> 00:18:11.680]   So when we have like these really,
[00:18:11.680 --> 00:18:15.360]   when we try and interpret these biases about the movies,
[00:18:15.360 --> 00:18:19.040]   we can see like these are movies that probably aren't going to be liked
[00:18:19.040 --> 00:18:20.800]   even if you match them to a user.
[00:18:20.800 --> 00:18:26.080]   So that's just this understanding of how you interpret bias for movies.
[00:18:26.080 --> 00:18:29.840]   And then similarly, if I interpret, if I get the,
[00:18:29.840 --> 00:18:33.360]   if I put descending equal to true, which means a really high bias,
[00:18:33.360 --> 00:18:37.440]   which means that these movies have really high likability factor.
[00:18:37.440 --> 00:18:43.680]   Like even if you match a user who probably hasn't seen like prison break movies,
[00:18:43.680 --> 00:18:46.800]   like Shawshank Redemption, which was related to that,
[00:18:46.800 --> 00:18:49.040]   even if a user hasn't seen movies like that,
[00:18:49.040 --> 00:18:54.480]   if you match Shawshank Redemption and you make that person see that movie,
[00:18:54.480 --> 00:18:58.080]   then they're probably going to like it because this movie is so well made.
[00:18:58.080 --> 00:18:59.920]   So that's the bias about this movie.
[00:18:59.920 --> 00:19:03.360]   The bias about this movie is that it's really nice and it's really well made.
[00:19:03.360 --> 00:19:05.440]   It's really well directed. It's really well produced.
[00:19:05.440 --> 00:19:08.080]   And it is very much possible that the user,
[00:19:08.080 --> 00:19:11.120]   even if they don't match with the latent factors with each other,
[00:19:11.120 --> 00:19:13.440]   it's very much possible that they're still going to like this movie.
[00:19:13.440 --> 00:19:16.080]   So that's the biases.
[00:19:16.080 --> 00:19:20.400]   And similarly, if you were to ask me like how to interpret the biases for users,
[00:19:20.400 --> 00:19:27.440]   I could say, oh, really high biased users are ones who really like watching movies.
[00:19:27.440 --> 00:19:30.480]   And then the ones with really low biases are the users that
[00:19:30.480 --> 00:19:32.640]   are the ones that really don't like watching movies,
[00:19:32.640 --> 00:19:35.680]   or they are the ones that don't really like any movie at all.
[00:19:35.680 --> 00:19:38.400]   So that's how you would interpret these biases.
[00:19:38.400 --> 00:19:44.000]   I'm saying, anyways, that's just the way I would see this.
[00:19:44.000 --> 00:19:48.320]   And now if I'm to plot, so see how, so for now,
[00:19:48.320 --> 00:19:52.400]   what we have done is we've interpreted these biases that are in purple.
[00:19:52.400 --> 00:19:55.280]   So let's now get to the point where we try and,
[00:19:55.280 --> 00:19:59.120]   we try and interpret the embeddings that are in orange.
[00:19:59.120 --> 00:20:03.920]   And because these embeddings are in like latent space,
[00:20:03.920 --> 00:20:07.600]   which is like 50 dimensions, because it's like 50 vector long.
[00:20:07.600 --> 00:20:09.440]   How do you plot something that has like,
[00:20:09.440 --> 00:20:12.960]   you know, if you're plotting something on a 2D chart,
[00:20:12.960 --> 00:20:15.360]   all you need is X and Y, right?
[00:20:15.360 --> 00:20:19.360]   So you have a vector with two dimensions, your X value and the Y value,
[00:20:19.360 --> 00:20:23.760]   or even on a 3D space, what you have is your X, Y and width at the back.
[00:20:23.760 --> 00:20:30.400]   So how do you plot something that has like 50 dimensions or like the,
[00:20:30.400 --> 00:20:33.680]   yeah, which has like 50 latent factors, so it has 50 dimensions.
[00:20:33.680 --> 00:20:36.640]   So what you can do, there's this technique called PCA.
[00:20:36.640 --> 00:20:42.880]   I remember from memory, I think Kevin Bird, I think he asked the question about
[00:20:42.880 --> 00:20:46.080]   when are we going to do PCA or if we're going to do PCA at all.
[00:20:46.080 --> 00:20:50.960]   Kevin, if you're here today, well, this is the answer that we do PCA to interpret embeddings.
[00:20:50.960 --> 00:20:59.600]   And the idea is that you reduce a 50 length vector into a three or like a two length vector
[00:20:59.600 --> 00:21:05.440]   into a tiny version of this vector while retaining most of the information that's still in that.
[00:21:05.440 --> 00:21:12.480]   So what you can do is like, you can apply for this, this, and these three vectors.
[00:21:12.480 --> 00:21:16.720]   You can apply something called PCA, just principal component analysis.
[00:21:16.720 --> 00:21:20.960]   We won't go into the details of it, but the basic idea is
[00:21:20.960 --> 00:21:24.880]   you can reduce these vectors into smaller versions of themselves.
[00:21:24.880 --> 00:21:31.600]   So this still becomes, this is my embedding one, embedding two, embedding three,
[00:21:31.600 --> 00:21:35.920]   but they're smaller versions of themselves while retaining most of the information
[00:21:35.920 --> 00:21:39.280]   that's already present in the bigger version of the vectors.
[00:21:39.280 --> 00:21:41.600]   And now what I can do is I can plot them.
[00:21:41.600 --> 00:21:43.360]   So that's exactly what's happening over here.
[00:21:43.360 --> 00:21:47.680]   You can see how I do PCA and I just say three.
[00:21:47.680 --> 00:21:49.920]   So now I can plot them.
[00:21:49.920 --> 00:21:53.840]   And in over here, you can see like now you can really interpret movies and you can see
[00:21:53.840 --> 00:21:57.440]   like it's putting some classicals like Godfather and Shawshank Redemption,
[00:21:57.440 --> 00:22:02.720]   which are really high bias, which are movies like superbly good movies as together.
[00:22:02.720 --> 00:22:08.000]   It's kind of putting like Terminator and Terminator 2 together, very close to each other.
[00:22:08.000 --> 00:22:09.600]   And the ones that are far away.
[00:22:09.600 --> 00:22:15.520]   So I'm not a very big movie person and I don't, but if you are one, you can probably see like,
[00:22:15.520 --> 00:22:19.760]   I would imagine that English Patient and Terminator are like very different movies.
[00:22:19.760 --> 00:22:21.200]   So let's actually see that.
[00:22:21.200 --> 00:22:24.480]   English Patient 1996.
[00:22:24.480 --> 00:22:26.880]   What's this movie about? I have no idea.
[00:22:26.880 --> 00:22:32.640]   So it's a nurse tends to a plane crash victim who is on his deathbed.
[00:22:32.640 --> 00:22:35.920]   So yeah, so that kind of movie is like very different from Terminator,
[00:22:35.920 --> 00:22:38.640]   which is more like a sci-fi, I think.
[00:22:38.640 --> 00:22:39.600]   So Terminator.
[00:22:39.600 --> 00:22:44.880]   Exactly. So that's a sci-fi action movie.
[00:22:44.880 --> 00:22:45.760]   So that's a very different.
[00:22:45.760 --> 00:22:50.000]   So you can see how the English Patient and the Terminator are like far away from each other.
[00:22:50.000 --> 00:22:52.240]   So that's how you can interpret biases.
[00:22:52.240 --> 00:22:58.160]   And like what you could have done is like one idea that I feel is a good idea is like
[00:22:58.160 --> 00:23:00.400]   when you're doing movie recommendations or you're doing,
[00:23:00.400 --> 00:23:06.640]   you're doing like any tasks, if you're in a product company and you're trying to do
[00:23:06.640 --> 00:23:09.680]   these product kinds of things, or if you work for Amazon and you're trying to match
[00:23:09.680 --> 00:23:14.160]   user to the products that they like, when you do this, the model has now,
[00:23:14.160 --> 00:23:20.880]   when you finish training, the model has learned things about A, the product and B, the users.
[00:23:20.880 --> 00:23:28.560]   So maybe what you could do is you could plot the users on an embedding matrix chart.
[00:23:28.560 --> 00:23:34.240]   Because what it will do is it will bring together the users that are very similar to each other.
[00:23:34.880 --> 00:23:37.600]   And it will, it will like form clusters.
[00:23:37.600 --> 00:23:41.040]   So it will bring the users that are very similar to each other together.
[00:23:41.040 --> 00:23:43.760]   And then maybe you could use marketing to like,
[00:23:43.760 --> 00:23:50.560]   oh, let's just target these kind of people who really like these kind of products.
[00:23:50.560 --> 00:23:56.560]   So like by this way, you actually gain more insights about your users, about your products.
[00:23:56.560 --> 00:24:01.440]   And like all of these ways that you can use deep learning to your benefit,
[00:24:01.440 --> 00:24:10.320]   if you're, if you ever work in like a product or a product or a user base kind of industry.
[00:24:10.320 --> 00:24:14.480]   So I think that's really helpful to see that deep learning is not just something that
[00:24:14.480 --> 00:24:20.960]   is used like for computer vision or NLP as we see it, but it's also really,
[00:24:20.960 --> 00:24:25.120]   really helpful when people say like deep learning is not interpretable or like,
[00:24:25.120 --> 00:24:28.560]   like deep learning is like this black box.
[00:24:28.560 --> 00:24:31.760]   I kind of disagree because we have this example right in front of us.
[00:24:31.760 --> 00:24:35.360]   Deep learning is actually helping us learn more about the users.
[00:24:35.360 --> 00:24:38.480]   And it's helping us learn more about these movies.
[00:24:38.480 --> 00:24:43.280]   And like, even for someone like me who hadn't seen Terminator and who hasn't seen English patient,
[00:24:43.280 --> 00:24:46.800]   I could maybe still make a guess that these two movies are different from each other.
[00:24:46.800 --> 00:24:51.760]   And by a simple Google, it did, Google search, it did turn out to be the case.
[00:24:51.760 --> 00:24:56.160]   Like this was sci-fi and this was about a plane crash, which is like a slightly different genre.
[00:24:57.040 --> 00:25:02.080]   So anyway, so that's just the thing I want to say about embeddings and like how you can use them
[00:25:02.080 --> 00:25:09.760]   to interpret them. One last one, another thing I want to bring up is this.
[00:25:09.760 --> 00:25:18.320]   I think it's this, if you haven't heard of Jay Allama, you should hear of him.
[00:25:18.320 --> 00:25:20.080]   And sorry, you should check him out.
[00:25:21.120 --> 00:25:28.560]   And the one blog that I'm really interested, which will be is called Understanding.
[00:25:28.560 --> 00:25:30.960]   I think it's called What are Embeddings, really?
[00:25:30.960 --> 00:25:35.680]   I think that's one post. Illustrate word to word.
[00:25:35.680 --> 00:25:39.600]   Maybe it's this one.
[00:25:39.600 --> 00:25:46.720]   For Standard Embeddings. Yeah, there we go.
[00:25:46.720 --> 00:25:50.640]   So that's just putting embedding, embedding, embedding, word embeddings.
[00:25:50.640 --> 00:25:54.000]   Oh yeah, this is the one. King, man, woman, and then you bring them together.
[00:25:54.000 --> 00:25:58.240]   Okay. So I'm gonna post this link in Zoom chat.
[00:25:58.240 --> 00:26:00.240]   Actually, let me just post this on the forum.
[00:26:00.240 --> 00:26:06.320]   So, oh, Kevin getting some likes. Nice.
[00:26:06.320 --> 00:26:18.240]   So that's the post by Jay Allama on embeddings.
[00:26:18.240 --> 00:26:22.560]   Have I spelled his name correctly? Yeah, I think I did.
[00:26:22.560 --> 00:26:26.560]   So that's that.
[00:26:26.560 --> 00:26:30.480]   So what I want you to do is like, when you go back from today,
[00:26:30.480 --> 00:26:32.160]   just have a look at this post.
[00:26:32.160 --> 00:26:36.320]   And this is, just have a look at this post.
[00:26:36.320 --> 00:26:40.800]   And these are basically, this will give you a good understanding of embeddings, right?
[00:26:40.800 --> 00:26:44.720]   So right now, what I told you, or what we've looked at is that
[00:26:44.720 --> 00:26:48.880]   we have movies and we have users and movies and users are,
[00:26:48.880 --> 00:26:53.760]   so basically embeddings are like these things we learn about movies or users
[00:26:53.760 --> 00:26:56.480]   or like the problem that we're interested in.
[00:26:56.480 --> 00:26:59.600]   So embeddings are just characteristics that you learn about things, right?
[00:26:59.600 --> 00:27:07.120]   It's not, embeddings are things that are not just used in the collaborative filtering world.
[00:27:07.120 --> 00:27:10.800]   Embeddings are actually things that are also used in NLP a lot.
[00:27:10.800 --> 00:27:15.200]   So when you see in NLP, when you see a transformer model or like this,
[00:27:15.200 --> 00:27:18.640]   all of these things in NLP, so deep learning is something that
[00:27:18.640 --> 00:27:22.080]   as you get the basics more and more, you'll see, oh, in NLP,
[00:27:22.080 --> 00:27:25.600]   we're actually doing the same or similar thing that we did for collaborative filtering.
[00:27:25.600 --> 00:27:29.920]   Or we're kind of doing the similar, it's like the similar concept of like,
[00:27:29.920 --> 00:27:34.320]   you let the model learn things and then you have some objectives that you're trying to solve.
[00:27:34.320 --> 00:27:39.680]   Right? So the question, or like the thing I'm going to say right now is,
[00:27:40.320 --> 00:27:45.520]   what if each word had an embedding, right?
[00:27:45.520 --> 00:27:51.680]   So what if each word was represented by an embedding or like some latent factors
[00:27:51.680 --> 00:27:57.040]   and you train the model to then on some specific task,
[00:27:57.040 --> 00:28:01.520]   like maybe sentence classification or named entity recognition,
[00:28:01.520 --> 00:28:04.080]   on just some tasks, don't worry about what these tasks are.
[00:28:04.080 --> 00:28:07.520]   You don't need to have that kind of knowledge about NLP.
[00:28:07.520 --> 00:28:15.760]   But let me just say, what if a model then was able to learn these embeddings about words, right?
[00:28:15.760 --> 00:28:19.680]   What's going to happen when this trained model,
[00:28:19.680 --> 00:28:24.400]   when this model has finally finished training, what's going to happen is that
[00:28:24.400 --> 00:28:28.000]   the model will learn these characteristics about words, right?
[00:28:28.000 --> 00:28:33.440]   In a way, what's happening is that the model is learning these things about,
[00:28:33.440 --> 00:28:36.800]   it's like, it's learning these characteristics about words.
[00:28:36.800 --> 00:28:40.880]   So in a way, this model is actually learning the whole language by itself, right?
[00:28:40.880 --> 00:28:44.640]   Because as humans, when we say basic, or when we say advanced,
[00:28:44.640 --> 00:28:47.840]   there's still, what's different in them?
[00:28:47.840 --> 00:28:49.280]   Like, how do we interpret that?
[00:28:49.280 --> 00:28:53.040]   We also interpret those things as like, oh, basic and advanced is like,
[00:28:53.040 --> 00:28:57.840]   basic is just something that's advanced, like further off,
[00:28:57.840 --> 00:28:59.600]   and basic is just right at the beginning.
[00:28:59.600 --> 00:29:01.040]   So like a baseline.
[00:29:01.040 --> 00:29:03.360]   And like, if the model can learn these embeddings,
[00:29:03.360 --> 00:29:07.760]   then it can actually be used to do natural language processing,
[00:29:07.760 --> 00:29:11.440]   because it will then learn the words, it will then learn things about language.
[00:29:11.440 --> 00:29:15.520]   So I'm sorry I digressed a little bit, like I went away from collaborative filtering,
[00:29:15.520 --> 00:29:17.920]   and I went away from movie recommendation,
[00:29:17.920 --> 00:29:23.200]   but I felt like this was a really good point to introduce embeddings as a more general concept.
[00:29:23.200 --> 00:29:25.920]   And what this post by Jay Alamar will do,
[00:29:25.920 --> 00:29:32.480]   I've just introduced embeddings from like a collaborative filtering perspective,
[00:29:32.480 --> 00:29:35.360]   but if you read this post, you learn about embeddings
[00:29:35.360 --> 00:29:38.000]   from a natural language processing perspective,
[00:29:38.000 --> 00:29:41.520]   and then that way you realize, oh, embeddings is like a general concept
[00:29:41.520 --> 00:29:44.160]   that can be used for multiple things.
[00:29:44.160 --> 00:29:48.800]   So I guess that's my goal.
[00:29:48.800 --> 00:29:54.480]   It's like, I want you to have that understanding of embeddings on a general basis.
[00:29:54.480 --> 00:29:55.920]   So that's that.
[00:29:55.920 --> 00:29:57.440]   So what's next?
[00:29:57.440 --> 00:29:58.640]   So we've just finished this.
[00:29:59.200 --> 00:30:02.400]   Before going on to the next one, I saw Girijesh.
[00:30:02.400 --> 00:30:10.000]   I saw Girijesh ask, is this collaborative filtering we are discussing?
[00:30:10.000 --> 00:30:10.640]   Yes, it is.
[00:30:10.640 --> 00:30:18.640]   And I took a digression up to NLP and posted this link about the illustrated word2vec.
[00:30:18.640 --> 00:30:24.880]   Hi, everyone.
[00:30:24.880 --> 00:30:26.880]   Here we are, explicit gratings on a scale of...
[00:30:28.560 --> 00:30:32.640]   Here we are, having explicit gratings on a scale of 1 to 5 or 1 to 10.
[00:30:32.640 --> 00:30:37.840]   How can we build Clab Learner, a recommendation system,
[00:30:37.840 --> 00:30:40.800]   where we don't have explicit gratings,
[00:30:40.800 --> 00:30:46.560]   but some implicit feedback like the number of likes or the number of car ads
[00:30:46.560 --> 00:30:47.200]   or the number...
[00:30:47.200 --> 00:30:48.560]   Oh, that's a really good question.
[00:30:48.560 --> 00:30:53.280]   But when I think of it, you already know of sigmoid.
[00:30:53.280 --> 00:30:58.320]   You already know of scaled sigmoid, right?
[00:30:58.480 --> 00:31:03.760]   So again, this is not something I've worked on or this is not something...
[00:31:03.760 --> 00:31:08.480]   I'm just coming up with like a solution that I think might work.
[00:31:08.480 --> 00:31:11.440]   So if it doesn't work, please, yeah,
[00:31:11.440 --> 00:31:13.280]   please take this solution with a grain of salt.
[00:31:13.280 --> 00:31:16.880]   But what Vinayak is saying is like you have like say image 1.
[00:31:16.880 --> 00:31:19.840]   So I'm just going to say image 1, image 2,
[00:31:19.840 --> 00:31:22.320]   and I'm just going to say image 3 as examples, right?
[00:31:22.320 --> 00:31:25.520]   So let's say you get 109 likes on this.
[00:31:25.520 --> 00:31:29.600]   You get 5 likes on this and you get 50 likes on this.
[00:31:29.600 --> 00:31:33.840]   So how do you build a recommendation system or like this kind of system?
[00:31:33.840 --> 00:31:36.560]   Like how do you convert these to between 1 and 5?
[00:31:36.560 --> 00:31:39.840]   Well, what you could do, Fast.ai has this function
[00:31:39.840 --> 00:31:42.000]   that you already know of and you've already seen.
[00:31:42.000 --> 00:31:44.640]   I think it's called scaled sigmoid.
[00:31:44.640 --> 00:31:47.120]   You could apply that to these things
[00:31:47.120 --> 00:31:50.720]   and then that will convert everything to be between 1 and 5.
[00:31:50.720 --> 00:31:53.040]   And then you could do the same thing as you are right now.
[00:31:53.760 --> 00:31:55.760]   So I think maybe try that.
[00:31:55.760 --> 00:31:56.960]   That's something that might work.
[00:31:56.960 --> 00:32:01.280]   The blog article wasn't completely tied to Fastbook,
[00:32:01.280 --> 00:32:04.880]   but it's spawned from the normalization discussion from last week.
[00:32:04.880 --> 00:32:06.320]   Oh, thanks for sharing.
[00:32:06.320 --> 00:32:07.600]   Let me just bring that up.
[00:32:07.600 --> 00:32:12.720]   Normalizing Fast.ai tabular inputs.
[00:32:12.720 --> 00:32:14.000]   Okay, thanks, Kevin.
[00:32:14.000 --> 00:32:14.880]   Thanks, Kevin, for sharing.
[00:32:14.880 --> 00:32:18.080]   Oh, by the way, Kevin has this wonderful blog as well.
[00:32:18.080 --> 00:32:22.480]   Do you not, Kevin?
[00:32:22.880 --> 00:32:26.800]   I think you do.
[00:32:26.800 --> 00:32:28.160]   Oh, there it is.
[00:32:28.160 --> 00:32:29.920]   I'm certainly post that.
[00:32:29.920 --> 00:32:43.360]   So I'm just going to edit my past post so everything remains in one place.
[00:32:43.360 --> 00:32:46.640]   There we go.
[00:32:46.640 --> 00:32:50.560]   No, I don't need spawn text.
[00:32:50.560 --> 00:32:52.240]   I'm so sad.
[00:32:52.560 --> 00:32:52.960]   All right.
[00:32:52.960 --> 00:32:54.960]   So let's move on.
[00:32:54.960 --> 00:32:58.320]   So now, I guess what we could have done is like
[00:32:58.320 --> 00:33:00.640]   instead of building a learner ourselves,
[00:33:00.640 --> 00:33:02.800]   Fast.ai has something called a Colab Learner.
[00:33:02.800 --> 00:33:03.760]   So we can use that.
[00:33:03.760 --> 00:33:08.240]   We can say change everything to be between 0 and 5.5.
[00:33:08.240 --> 00:33:09.920]   And I could say fit one cycle.
[00:33:09.920 --> 00:33:11.680]   I'm not going to do it for 5.
[00:33:11.680 --> 00:33:12.800]   Let me just say 1.
[00:33:12.800 --> 00:33:15.680]   And then you can see like I can check the model.
[00:33:15.680 --> 00:33:20.160]   It is embedding.bias, which is the same model as ours.
[00:33:20.160 --> 00:33:25.120]   So actually, let me just see if I can open that up and show it to you.
[00:33:25.120 --> 00:33:30.720]   So if I go git repos, if I go Fast.ai, and I say enter.
[00:33:30.720 --> 00:33:34.320]   So by this time, I also want to teach you like
[00:33:34.320 --> 00:33:37.600]   or show you like these skills of searching through source code.
[00:33:37.600 --> 00:33:40.320]   So if you want to search through this embedding.bias source code,
[00:33:40.320 --> 00:33:42.400]   you could either press question mark, question mark here.
[00:33:42.400 --> 00:33:44.240]   You could either use WIM.
[00:33:44.240 --> 00:33:49.040]   So I could go in my terminal and I could go cd git repos.
[00:33:49.680 --> 00:33:51.680]   I could go Fast.ai.
[00:33:51.680 --> 00:33:56.080]   And I don't have tags.
[00:33:56.080 --> 00:33:57.680]   Let me see if I have ctags set up.
[00:33:57.680 --> 00:34:01.360]   So I could say ctags are dot ignoring.
[00:34:01.360 --> 00:34:01.760]   Cool.
[00:34:01.760 --> 00:34:05.840]   And I could say WIM and I could say tag Colab Learner.
[00:34:05.840 --> 00:34:06.880]   Is that how it works?
[00:34:06.880 --> 00:34:08.080]   Colab Data Loader.
[00:34:08.080 --> 00:34:10.160]   Okay. So I need Colab Learner.
[00:34:10.160 --> 00:34:12.480]   What's a Colab Learner called?
[00:34:12.480 --> 00:34:16.080]   Oh, it's in small. That's why.
[00:34:16.880 --> 00:34:19.360]   So I could just say tag Colab Learner.
[00:34:19.360 --> 00:34:20.720]   So that's one way of looking at it.
[00:34:20.720 --> 00:34:23.840]   Like I could have just used WIM to do all of this.
[00:34:23.840 --> 00:34:26.480]   Or the other way or the easier way could be
[00:34:26.480 --> 00:34:30.640]   if you haven't used WIM before, I could just go into VS Code.
[00:34:30.640 --> 00:34:36.720]   I could open the repository and then I could press control T on my keyboard
[00:34:36.720 --> 00:34:38.720]   and I could say Colab Learner.
[00:34:38.720 --> 00:34:41.440]   And then that takes me to the source code of Colab Learner.
[00:34:41.440 --> 00:34:44.480]   And then finally, I'm not done yet.
[00:34:44.480 --> 00:34:49.520]   The last thing you could do is you could go to GitHub FastAI.
[00:34:49.520 --> 00:34:53.440]   So I go here.
[00:34:53.440 --> 00:34:56.160]   I go to the FastAI library.
[00:34:56.160 --> 00:35:01.600]   And now that I'm on the library, GitHub has released this really cool thing.
[00:35:01.600 --> 00:35:06.160]   If I press dot on this repository, it will set up a web editor,
[00:35:06.160 --> 00:35:08.400]   which is VS Code running over here.
[00:35:08.400 --> 00:35:10.640]   And then I could press control shift F
[00:35:10.640 --> 00:35:13.760]   or like I could do anything that I do with VS Code just over here.
[00:35:13.760 --> 00:35:17.760]   So I could maybe search control shift F and I could say Colab Learner.
[00:35:17.760 --> 00:35:21.600]   Or I could press control T like I did in VS Code.
[00:35:21.600 --> 00:35:23.360]   So let's just do-- I think I changed the--
[00:35:23.360 --> 00:35:28.400]   So anyway, so there's like these multiple ways of doing--
[00:35:28.400 --> 00:35:29.520]   or looking at source code.
[00:35:29.520 --> 00:35:30.240]   So take your pick.
[00:35:30.240 --> 00:35:31.680]   If you like WIM, do it this way.
[00:35:31.680 --> 00:35:33.760]   If you like VS Code, do it this way.
[00:35:33.760 --> 00:35:34.800]   Or you could just do it in the--
[00:35:34.800 --> 00:35:36.320]   Or you could do it in the--
[00:35:36.320 --> 00:35:39.680]   You could do it in the Jupyter Notebook as well.
[00:35:39.680 --> 00:35:40.880]   So I just want to show you the--
[00:35:41.440 --> 00:35:42.160]   Let's just see.
[00:35:42.160 --> 00:35:46.960]   The model we're creating is called embedding.bias in Colab Learner.
[00:35:46.960 --> 00:35:48.480]   So what exactly is happening?
[00:35:48.480 --> 00:35:50.400]   We get our embedding sizes.
[00:35:50.400 --> 00:35:54.400]   If we haven't provided the loss function, it sets a loss function for us.
[00:35:54.400 --> 00:35:57.360]   It sets a config for us.
[00:35:57.360 --> 00:36:02.240]   It sets a Y range for us, which is between 0 and 5.5.
[00:36:02.240 --> 00:36:05.520]   Then if I'm using a neural network,
[00:36:05.520 --> 00:36:07.920]   remember how we created two different approaches?
[00:36:07.920 --> 00:36:10.720]   So if I'm using a neural network, use embedding nn.
[00:36:10.720 --> 00:36:11.680]   Otherwise, use this--
[00:36:11.680 --> 00:36:15.520]   If I'm not using nn, then use this embedding.bias.
[00:36:15.520 --> 00:36:18.080]   So if I press Control and I go to that--
[00:36:18.080 --> 00:36:23.360]   I hover over that thing, I can go to the source code of embedding.bias.
[00:36:23.360 --> 00:36:26.000]   And you can see now what exactly is happening over here
[00:36:26.000 --> 00:36:28.000]   is that you create--
[00:36:28.000 --> 00:36:33.200]   You set the self.y range, which we passed between 0 and 5.5.
[00:36:33.200 --> 00:36:36.800]   And then what you can do next is that you can set your user's weight,
[00:36:37.520 --> 00:36:41.440]   movie's weight, user bias, or item bias, which is called--
[00:36:41.440 --> 00:36:43.040]   It's I stands for item.
[00:36:43.040 --> 00:36:45.600]   And you could then just use a list comprehension.
[00:36:45.600 --> 00:36:48.240]   You pass in your different shapes.
[00:36:48.240 --> 00:36:52.480]   So if your user weight, remember, if we look at the model above,
[00:36:52.480 --> 00:36:54.320]   where is the model?
[00:36:54.320 --> 00:36:55.040]   Here it is.
[00:36:55.040 --> 00:36:57.760]   So my user factors, remember, they were from n users
[00:36:57.760 --> 00:37:00.960]   or the number of users to my dimensions of the factors.
[00:37:00.960 --> 00:37:04.320]   Similarly, as you can see, my user weight is from number of users
[00:37:04.320 --> 00:37:05.840]   to the number of factors that I have.
[00:37:06.880 --> 00:37:10.400]   I weight, which is the item weight, in our case, the item is movie.
[00:37:10.400 --> 00:37:12.800]   So it goes from n movies to n factors.
[00:37:12.800 --> 00:37:15.120]   So I can just go from number of items that I have,
[00:37:15.120 --> 00:37:18.320]   which is going to be n movies, and it goes to n factors.
[00:37:18.320 --> 00:37:20.880]   And similarly, I set my bias.
[00:37:20.880 --> 00:37:23.600]   So bias is just the number of users or the number of items.
[00:37:23.600 --> 00:37:27.280]   So you just say number of users and 1, so just the one column.
[00:37:27.280 --> 00:37:29.680]   And when you're doing the forward in PyTorch,
[00:37:29.680 --> 00:37:32.800]   you grab your users, you grab your items,
[00:37:32.800 --> 00:37:34.320]   you do the dot product between them,
[00:37:34.320 --> 00:37:36.960]   which will multiply the embedding matrices.
[00:37:36.960 --> 00:37:38.960]   So you see how similar they are.
[00:37:38.960 --> 00:37:41.200]   And then you can get the result like this.
[00:37:41.200 --> 00:37:44.000]   You add the bias to your result this time.
[00:37:44.000 --> 00:37:47.840]   Sorry, you add your biases to your dot product
[00:37:47.840 --> 00:37:50.240]   because that's the user bias and the movie bias.
[00:37:50.240 --> 00:37:53.920]   And then if y range is none, you just return that.
[00:37:53.920 --> 00:37:56.080]   Otherwise, you apply the sigmoid to make sure
[00:37:56.080 --> 00:37:58.800]   that your outputs are between that range that you passed.
[00:37:58.800 --> 00:38:00.160]   So I think this will really help you.
[00:38:01.840 --> 00:38:05.120]   This is now a good time to actually start looking at source code.
[00:38:05.120 --> 00:38:07.520]   This is now a good time to start thinking about,
[00:38:07.520 --> 00:38:10.640]   oh, how is this really working or how is that really working?
[00:38:10.640 --> 00:38:12.240]   We've been in this journey long enough.
[00:38:12.240 --> 00:38:14.080]   Like this is the 11th week,
[00:38:14.080 --> 00:38:16.800]   and you've been coming back week after week.
[00:38:16.800 --> 00:38:19.200]   So this is now a really, really good time
[00:38:19.200 --> 00:38:22.640]   to expand on the knowledge that you have.
[00:38:22.640 --> 00:38:25.280]   And these are the little things that you should do
[00:38:25.280 --> 00:38:26.880]   when you go back in the week.
[00:38:26.880 --> 00:38:28.640]   So let's keep going.
[00:38:29.600 --> 00:38:31.840]   I'm sorry. I know I'm taking a lot of digressions today.
[00:38:31.840 --> 00:38:34.400]   So if that's unhelpful, let me know.
[00:38:34.400 --> 00:38:39.200]   All right. So we can create a Colab Learner like this,
[00:38:39.200 --> 00:38:41.200]   which I just showed you the source code of.
[00:38:41.200 --> 00:38:42.800]   And then I can fit my cycle.
[00:38:42.800 --> 00:38:44.960]   Oh, I shouldn't have done that.
[00:38:44.960 --> 00:38:46.720]   Anyway, and I can fit with this.
[00:38:46.720 --> 00:38:48.880]   I can pass my learning rate as 5e neg 3.
[00:38:48.880 --> 00:38:50.320]   I can pass my weight decay.
[00:38:50.320 --> 00:38:54.080]   Similarly, I can now grab my movie bias.
[00:38:54.080 --> 00:38:58.000]   I can grab the indexes which are the top biases.
[00:38:58.000 --> 00:38:59.920]   And you can see like you can still get the same
[00:38:59.920 --> 00:39:04.160]   really top rated movies, which are Titanic, Shawshank Redemption.
[00:39:04.160 --> 00:39:05.280]   So we've already looked at that.
[00:39:05.280 --> 00:39:08.160]   Now, another thing that you want to know
[00:39:08.160 --> 00:39:10.640]   is like this thing called embedding distance.
[00:39:10.640 --> 00:39:13.600]   So what does that embedding distance stand for?
[00:39:13.600 --> 00:39:14.720]   Or why is it relevant?
[00:39:14.720 --> 00:39:19.760]   It's like by this time, the model has learned
[00:39:19.760 --> 00:39:21.920]   things about the movies.
[00:39:21.920 --> 00:39:24.320]   It has learned these things about the users, right?
[00:39:25.120 --> 00:39:30.240]   So if you want to know if movie one is similar to movie two, right?
[00:39:30.240 --> 00:39:34.000]   So there's these 50 categories about movies.
[00:39:34.000 --> 00:39:37.200]   So let's say the first category is action.
[00:39:37.200 --> 00:39:41.120]   The second category is like how new it is.
[00:39:41.120 --> 00:39:44.000]   The third category is like musical.
[00:39:44.000 --> 00:39:46.480]   And of course, there's no way to know
[00:39:46.480 --> 00:39:48.720]   what these categories actually mean.
[00:39:48.720 --> 00:39:54.480]   I'm just taking examples to show you
[00:39:54.480 --> 00:39:57.520]   or like to give you an intuition about what these categories could mean.
[00:39:57.520 --> 00:40:00.480]   But the model, because it learns these categories on its own,
[00:40:00.480 --> 00:40:03.840]   these are just latent categories for the models.
[00:40:03.840 --> 00:40:07.280]   Like the model just learns 50 things about something, right?
[00:40:07.280 --> 00:40:10.160]   And then it learns about 50 things about the next thing
[00:40:10.160 --> 00:40:11.600]   and 50 things about the third thing.
[00:40:11.600 --> 00:40:14.320]   Like what these are is up to interpretation.
[00:40:14.320 --> 00:40:16.560]   And these could be anything.
[00:40:16.560 --> 00:40:21.920]   But anyway, if we want to see if movie one is similar to movie two,
[00:40:22.480 --> 00:40:26.640]   what we could do is we could check the distance between these points, right?
[00:40:26.640 --> 00:40:29.840]   So like if this is a number which is 1.7
[00:40:29.840 --> 00:40:32.000]   and this is a number which is 1.6,
[00:40:32.000 --> 00:40:35.200]   it just means that both movies have similar kind of action in them.
[00:40:35.200 --> 00:40:38.000]   If this is a number that's 0.1
[00:40:38.000 --> 00:40:40.000]   and this is a number that's 0.1,
[00:40:40.000 --> 00:40:42.560]   then it just means that both movies are kind of old
[00:40:42.560 --> 00:40:45.680]   because the new factor is not very high.
[00:40:45.680 --> 00:40:47.920]   If this is a number that's -1.9
[00:40:47.920 --> 00:40:50.240]   and this is a number that's -1.8,
[00:40:50.240 --> 00:40:53.520]   then this just means that the two movies aren't really musical,
[00:40:53.520 --> 00:40:55.120]   that there's not a lot of music in them.
[00:40:55.120 --> 00:41:00.480]   So by this way, I could take the difference
[00:41:00.480 --> 00:41:04.400]   between this item and this item,
[00:41:04.400 --> 00:41:08.800]   the second and the second, the third and the third, and so on.
[00:41:08.800 --> 00:41:13.360]   And what that will do is that will give me a way to see similarity between things.
[00:41:13.360 --> 00:41:16.880]   So one way to check distance is just to use the Pythagoras theorem
[00:41:16.880 --> 00:41:19.840]   or like x squared plus y squared under root.
[00:41:19.840 --> 00:41:23.280]   So that's just called cosine similarity.
[00:41:23.280 --> 00:41:25.440]   So that this is something you can do.
[00:41:25.440 --> 00:41:30.800]   And then that's the way how you can check the embedding distance.
[00:41:30.800 --> 00:41:34.160]   So I'm not sure exactly where this nn.cosine similarity comes from.
[00:41:34.160 --> 00:41:36.480]   So let me just see the source code of it actually.
[00:41:36.480 --> 00:41:40.960]   On a two-dimensional map,
[00:41:40.960 --> 00:41:43.600]   we can calculate the distance between two coordinates.
[00:41:43.600 --> 00:41:48.560]   For a 50-dimensional embedding, we can do exactly the same thing
[00:41:48.560 --> 00:41:51.760]   except that we add up the squares of all 50 coordinate distances.
[00:41:51.760 --> 00:41:52.400]   That is correct.
[00:41:52.400 --> 00:41:55.600]   If there are two movies that are nearly identical,
[00:41:55.600 --> 00:41:59.600]   then the embedding vectors would also be nearly identical,
[00:41:59.600 --> 00:42:01.600]   which is exactly what I've just said right now.
[00:42:01.600 --> 00:42:06.160]   There is a more general idea here.
[00:42:06.160 --> 00:42:10.400]   Movie similarity can be identified by the similarity of uses the Pythagoras.
[00:42:10.400 --> 00:42:11.920]   That's fine. And we can find that.
[00:42:11.920 --> 00:42:17.360]   Okay, so maybe in Pythagoras, just the way to do this is called nn.cosine similarity.
[00:42:17.360 --> 00:42:23.440]   So if I were you and I don't understand how nn.cosine similarity works,
[00:42:23.440 --> 00:42:26.800]   I will just copy paste that and then I will go into PyTorch.
[00:42:26.800 --> 00:42:31.520]   And then I will try and see, oh, okay, it's just like a dot product
[00:42:31.520 --> 00:42:33.520]   and then you divide by the absolute value.
[00:42:33.520 --> 00:42:35.360]   So that's just like the similarity.
[00:42:35.360 --> 00:42:37.760]   So I could check the source code of this and all that stuff
[00:42:37.760 --> 00:42:40.000]   just to see exactly what's happening.
[00:42:40.000 --> 00:42:42.480]   So it's calling the functional form of this and so on.
[00:42:44.240 --> 00:42:48.240]   All right, so now we're at the last part of this,
[00:42:48.240 --> 00:42:51.120]   which is called bootstrapping a collaborative filtering model.
[00:42:51.120 --> 00:42:55.280]   But before we move on to 1.6, let me just see if there's any questions.
[00:42:55.280 --> 00:43:02.400]   I think using a sigmoid to convert this implicit feedback into some range
[00:43:02.400 --> 00:43:03.920]   could be a good rating measure.
[00:43:03.920 --> 00:43:07.920]   Yes, exactly. This is to answer with Gnag.
[00:43:07.920 --> 00:43:08.640]   Yes, I agree.
[00:43:08.640 --> 00:43:13.280]   All right, I'm just going to skip on that question.
[00:43:13.280 --> 00:43:15.280]   Keep that discussion going, guys.
[00:43:15.280 --> 00:43:16.640]   Really happy to see that happening.
[00:43:16.640 --> 00:43:20.000]   But I will come back and answer those questions afterwards.
[00:43:20.000 --> 00:43:27.200]   Okay, so now we are on to this bootstrapping collaborative filtering model topic.
[00:43:27.200 --> 00:43:28.000]   And what does that mean?
[00:43:28.000 --> 00:43:33.040]   That basically means like if you're a big company
[00:43:33.040 --> 00:43:40.080]   and you don't have any users and you don't have any movies
[00:43:40.080 --> 00:43:45.040]   or like you just have a bunch of movies, but you don't really have users
[00:43:45.040 --> 00:43:46.400]   and like you're just starting out.
[00:43:46.400 --> 00:43:49.200]   So how do you deal with that?
[00:43:49.200 --> 00:43:52.880]   Like how do you even recommend?
[00:43:52.880 --> 00:43:54.400]   What do you recommend to the first user?
[00:43:54.400 --> 00:43:57.680]   Like what are the movies that you recommend to your first user?
[00:43:57.680 --> 00:44:03.840]   Or like how does these things work for new movies or like for new users?
[00:44:03.840 --> 00:44:07.920]   Just give me a sec.
[00:44:08.880 --> 00:44:12.320]   So how do these things work?
[00:44:12.320 --> 00:44:14.240]   Like if it's a new movie or it's a new user.
[00:44:14.240 --> 00:44:18.720]   And the answer is there is no straight answer.
[00:44:18.720 --> 00:44:21.680]   There's like these different things that you can do.
[00:44:21.680 --> 00:44:26.880]   So maybe one thing that you could do is...
[00:44:26.880 --> 00:44:32.880]   So I am this massive organization.
[00:44:32.880 --> 00:44:37.280]   I have so many movies, which I'll say 10,000.
[00:44:37.280 --> 00:44:38.640]   So 10K movies.
[00:44:38.640 --> 00:44:40.400]   And then I get my first user.
[00:44:40.400 --> 00:44:43.920]   So which out of these movies do I recommend to this user?
[00:44:43.920 --> 00:44:45.840]   And that's the question.
[00:44:45.840 --> 00:44:50.320]   So like what I could do is because I have 10,000 movies,
[00:44:50.320 --> 00:44:52.560]   maybe I know about these movies already.
[00:44:52.560 --> 00:44:55.680]   Like I know how much the model already knows about these movies.
[00:44:55.680 --> 00:45:01.760]   And then what I could do is I could ask this user a bunch of questions.
[00:45:01.760 --> 00:45:03.920]   It's like, do you like action movies?
[00:45:03.920 --> 00:45:04.960]   Yes or no.
[00:45:04.960 --> 00:45:08.560]   Do you like or like rate between one and five,
[00:45:08.560 --> 00:45:10.480]   how much do you like action movies?
[00:45:10.480 --> 00:45:13.200]   Rate between one and five, how much do you like musicals?
[00:45:13.200 --> 00:45:19.120]   Rate between one and five, how much or how new you want your movies to be?
[00:45:19.120 --> 00:45:20.400]   So like how many new?
[00:45:20.400 --> 00:45:23.680]   And then based on that, based on these answers,
[00:45:23.680 --> 00:45:27.200]   you could then create an embedding matrix for this user.
[00:45:27.200 --> 00:45:29.920]   And then based on that, you can match the movies.
[00:45:29.920 --> 00:45:34.560]   So that's like the way these things get solved.
[00:45:34.560 --> 00:45:36.800]   So when you join a new company and you get a questionnaire
[00:45:36.800 --> 00:45:40.320]   about like when you join Netflix and it makes you like
[00:45:40.320 --> 00:45:44.080]   or it will give you a list or like, especially when I joined Reddit,
[00:45:44.080 --> 00:45:52.480]   it did ask me on Reddit is like, oh, can you like some topics that you're interested in?
[00:45:52.480 --> 00:45:55.600]   So if I go to Reddit and let's say if I say sign up,
[00:45:55.600 --> 00:46:00.960]   oh, it will make me enter all these emails.
[00:46:00.960 --> 00:46:05.520]   Anyway, what Reddit does is like it will say this, this.
[00:46:05.520 --> 00:46:09.200]   What Reddit will do is like it will give you 50 different topics
[00:46:09.200 --> 00:46:11.040]   and will say, please select five.
[00:46:11.040 --> 00:46:13.520]   Or the same thing happens if you join a newspaper.
[00:46:13.520 --> 00:46:17.120]   So if you join a new newspaper, the newspaper will say,
[00:46:17.120 --> 00:46:20.720]   oh, please select the top three kinds of news that you're interested in.
[00:46:20.720 --> 00:46:24.640]   Is it sport or is it more national news or international news?
[00:46:24.640 --> 00:46:28.400]   And then based on that, it recommends you the news articles
[00:46:28.400 --> 00:46:31.600]   or like all of that stuff happens based on the recommendation engine.
[00:46:31.600 --> 00:46:36.000]   Or even for Netflix and it will say, oh, please like 10 movies out of this big sample set.
[00:46:36.000 --> 00:46:40.400]   So that's the way how this bootstrapping of collaborative filtering model works.
[00:46:40.400 --> 00:46:46.880]   Or the next thing that could be is like, what if you have,
[00:46:46.880 --> 00:46:49.760]   so that's just one problem.
[00:46:50.320 --> 00:47:00.160]   The second thing could be you have this really big company,
[00:47:00.160 --> 00:47:06.800]   you have 10K movies and you have 10K users and now a new user joins.
[00:47:06.800 --> 00:47:08.560]   So what do you give to this new user?
[00:47:08.560 --> 00:47:13.200]   What do you make, like what recommendations do you give to this new user?
[00:47:13.200 --> 00:47:18.880]   Well, what you could do at this point is like you could take the average
[00:47:18.880 --> 00:47:23.280]   of the embedding matrices of all the 10,000 users
[00:47:23.280 --> 00:47:26.560]   and then that becomes like your ideal new user.
[00:47:26.560 --> 00:47:30.000]   Because now you have a massive, or like not massive, like 10,000 is not massive,
[00:47:30.000 --> 00:47:36.240]   but let's just say you have a decent enough size of like a sample set of 10,000 users.
[00:47:36.240 --> 00:47:41.040]   Then what you could do is like, you know, like the first user doesn't like action movies,
[00:47:41.040 --> 00:47:44.560]   the second user doesn't, likes action movies or like something like that.
[00:47:44.560 --> 00:47:46.960]   Then what you could do is like you could take the average
[00:47:46.960 --> 00:47:52.320]   and then what that will give you is like, oh, on average, a user likes action movies.
[00:47:52.320 --> 00:47:57.120]   On average, a user really likes newer movies as compared to older movies.
[00:47:57.120 --> 00:48:00.960]   On average, a user doesn't like musicals or like these things like that.
[00:48:00.960 --> 00:48:02.640]   So you get like these average factors.
[00:48:02.640 --> 00:48:06.320]   And what you could do is like based on these average factors,
[00:48:06.320 --> 00:48:08.960]   then you start recommending those movies to the new user.
[00:48:08.960 --> 00:48:14.240]   So anyway, so that's just the two problems that you will or might face
[00:48:14.240 --> 00:48:17.680]   if you end up working in collaborative filtering.
[00:48:17.680 --> 00:48:23.200]   And that's it. That's all there is about collaborative filtering.
[00:48:23.200 --> 00:48:26.960]   This just is like a neural network way of doing things.
[00:48:26.960 --> 00:48:29.440]   It's just using an end-of-sequential.
[00:48:29.440 --> 00:48:32.320]   So to turn our architecture into a deep learning model,
[00:48:32.320 --> 00:48:35.120]   the first step is to take the results of the embedding lookup
[00:48:35.120 --> 00:48:37.360]   and concatenate those activations together.
[00:48:37.360 --> 00:48:39.680]   So there's not really a lot that's going on in this.
[00:48:39.680 --> 00:48:41.360]   So I will skip through this part.
[00:48:41.360 --> 00:48:43.360]   It's like literally just a code convenience
[00:48:43.360 --> 00:48:45.520]   or like just something small that's really happening.
[00:48:45.520 --> 00:48:48.160]   So it just does this torch.cat over here,
[00:48:48.160 --> 00:48:49.920]   which is just concatenating the embeddings.
[00:48:49.920 --> 00:48:53.120]   So have a look at this. Have a read of this bit.
[00:48:53.120 --> 00:48:56.320]   And it's literally five or six lines of code.
[00:48:56.320 --> 00:48:57.280]   Have a read of this thing.
[00:48:57.280 --> 00:49:01.600]   And if you still have questions, come back to the forums and ask me about it.
[00:49:01.600 --> 00:49:04.160]   Or I can cover them next week if you have questions.
[00:49:04.160 --> 00:49:10.160]   But by this time, I hope that I've been able to explain
[00:49:10.720 --> 00:49:12.240]   embeddings, what embeddings are.
[00:49:12.240 --> 00:49:16.640]   And I hope I've been able to explain how these movie recommendation system works
[00:49:16.640 --> 00:49:21.040]   and how, yeah, and how like when you have a new user,
[00:49:21.040 --> 00:49:22.960]   what kind of things you have to be worried about.
[00:49:22.960 --> 00:49:26.160]   So that's that. That's just the conclusion.
[00:49:26.160 --> 00:49:27.920]   And that's where we finish this chapter.
[00:49:27.920 --> 00:49:31.200]   Please, please, please do have a look at the questionnaire.
[00:49:31.200 --> 00:49:36.960]   So I am planning to have like an informal catch-up this Saturday
[00:49:36.960 --> 00:49:38.480]   or maybe this weekend.
[00:49:38.480 --> 00:49:42.880]   And in that, what I do plan to do is pretty much going to be stuff like,
[00:49:42.880 --> 00:49:46.000]   oh, how do we like we can go through the questionnaires
[00:49:46.000 --> 00:49:47.760]   or you can come to me with your questions
[00:49:47.760 --> 00:49:50.720]   and we can have a discussion about the various questionnaires
[00:49:50.720 --> 00:49:52.560]   from each of these different chapters.
[00:49:52.560 --> 00:49:55.040]   So that's something that I do think would be a good idea
[00:49:55.040 --> 00:49:58.320]   because we've been skipping over the questionnaire week after week.
[00:49:58.320 --> 00:50:03.760]   So like, what is the use of bias in a dot product model?
[00:50:03.760 --> 00:50:05.600]   So like, we know now what bias is.
[00:50:05.600 --> 00:50:07.600]   Like, we can't get rid of bias.
[00:50:07.600 --> 00:50:12.400]   It's just something that tells us about a natural characteristic of somebody.
[00:50:12.400 --> 00:50:16.640]   So if a movie has high bias, it means it's really likable.
[00:50:16.640 --> 00:50:21.040]   So even if you match a movie with high bias to a user
[00:50:21.040 --> 00:50:26.560]   that doesn't really have that perfect match between latent factors,
[00:50:26.560 --> 00:50:30.320]   then even then we know that that is a high rate,
[00:50:30.320 --> 00:50:32.320]   that user is going to rate that movie highly.
[00:50:32.320 --> 00:50:35.360]   So there's all these things that have a look.
[00:50:35.360 --> 00:50:37.600]   Like, what does ArcSort do in PyTorch?
[00:50:37.600 --> 00:50:40.800]   So these are really good questions that I hope
[00:50:40.800 --> 00:50:45.280]   for the first seven chapters you have looked into.
[00:50:45.280 --> 00:50:49.440]   But in case you haven't, let's have a meeting,
[00:50:49.440 --> 00:50:51.920]   informal meeting sometime this Saturday and Sunday.
[00:50:51.920 --> 00:50:54.800]   And I will post the details of that meeting over here,
[00:50:54.800 --> 00:51:00.080]   basically in the week 11 discussion thread or just on the forums.
[00:51:00.080 --> 00:51:01.120]   And I'll tweet about it.
[00:51:01.120 --> 00:51:03.120]   So that's that.
[00:51:03.120 --> 00:51:06.320]   So let's just wrap up collaborative filtering.
[00:51:06.320 --> 00:51:10.560]   Does anybody have questions about collaborative filtering?
[00:51:10.560 --> 00:51:13.920]   Otherwise, we will move on to convolutions.
[00:51:13.920 --> 00:51:29.920]   I was checking on ways to address the call site, look on who initiated.
[00:51:29.920 --> 00:51:30.720]   Oh, Kevin Bird.
[00:51:31.360 --> 00:51:37.680]   Of course, Kevin has been part of Fast.ai for many, many years that I know.
[00:51:37.680 --> 00:51:38.960]   So this is November 18.
[00:51:38.960 --> 00:51:42.980]   All right.
[00:51:42.980 --> 00:51:49.040]   That being said, then let's just move on to the--
[00:51:49.040 --> 00:51:51.280]   let's just move on to convolutions.
[00:51:57.440 --> 00:52:05.360]   OK, so this is when we kind of just--
[00:52:05.360 --> 00:52:09.360]   this is like the shift of, oh, so far we've been learning embeddings.
[00:52:09.360 --> 00:52:15.680]   And this is when now we just start working on a completely different topic,
[00:52:15.680 --> 00:52:17.200]   which is convolutional neural networks.
[00:52:17.200 --> 00:52:20.880]   So forget everything that I've told you so far.
[00:52:20.880 --> 00:52:25.440]   And let's just start fresh on this really new topic.
[00:52:26.320 --> 00:52:27.600]   So convolutional neural networks.
[00:52:27.600 --> 00:52:33.920]   We have seen, or you would have seen convolutional neural networks being there in the wild.
[00:52:33.920 --> 00:52:39.520]   CNNs are just like this really, really common word or phrase in deep learning
[00:52:39.520 --> 00:52:41.440]   that you would see almost everywhere.
[00:52:41.440 --> 00:52:45.600]   But as part of this, and as part of-- so what the plan is now for me is like,
[00:52:45.600 --> 00:52:46.960]   we're going to do 13.
[00:52:46.960 --> 00:52:48.640]   We're going to do chapter 14.
[00:52:48.640 --> 00:52:53.040]   We're going to do chapter 15, 16, 17, 18, 19, if 20 maybe.
[00:52:53.680 --> 00:52:56.960]   And then we're probably going to come back to the NLP and Tabular.
[00:52:56.960 --> 00:52:58.240]   So I'm not going to touch Tabular.
[00:52:58.240 --> 00:53:00.560]   Tabular is something that I've asked Zach.
[00:53:00.560 --> 00:53:03.840]   So I think Zach will come in and he will explain Tabular.
[00:53:03.840 --> 00:53:07.120]   So I think-- and that would be really helpful,
[00:53:07.120 --> 00:53:10.720]   because I think Zach's been involved in the Tabular field a lot more than I have.
[00:53:10.720 --> 00:53:15.200]   So I think Zach was also working on--
[00:53:15.200 --> 00:53:19.600]   so that's Zach, by the way.
[00:53:19.600 --> 00:53:22.080]   When I keep saying Zach, that's Zachary Muller.
[00:53:22.080 --> 00:53:23.520]   And he's also on Twitter.
[00:53:23.520 --> 00:53:25.520]   So have a look.
[00:53:25.520 --> 00:53:27.840]   And yeah.
[00:53:27.840 --> 00:53:35.600]   Then what's going to happen now is that in terms of how the outline looks for Fastbook
[00:53:35.600 --> 00:53:38.800]   is that we're going to look at these chapters 13 and so on.
[00:53:38.800 --> 00:53:41.360]   And then we're going to come back to Tabular and we're going to do NLP.
[00:53:41.360 --> 00:53:45.520]   So what are convolutions exactly?
[00:53:45.520 --> 00:53:50.320]   And what really happens when we say, oh, we've created a convolutional network?
[00:53:50.320 --> 00:53:55.600]   So in this part, we're just going to build on top of what we've learned.
[00:53:55.600 --> 00:53:57.200]   So we're not going to learn a new skill.
[00:53:57.200 --> 00:53:59.760]   Like we already know how to build image classifiers.
[00:53:59.760 --> 00:54:02.320]   We already know how to do multi-level classification.
[00:54:02.320 --> 00:54:04.800]   We already know those sort of things.
[00:54:04.800 --> 00:54:07.360]   So what's going to happen from this chapter onwards
[00:54:07.360 --> 00:54:09.920]   is that we're going to learn about, oh, okay.
[00:54:09.920 --> 00:54:13.680]   I know how to build an image classifier.
[00:54:13.680 --> 00:54:16.720]   From this chapter onwards, I'm going to learn,
[00:54:16.720 --> 00:54:20.160]   oh, what exactly goes on when I build an image classifier?
[00:54:20.560 --> 00:54:24.720]   This is when we start going into the details of the things that we've been doing so far.
[00:54:24.720 --> 00:54:26.000]   All right.
[00:54:26.000 --> 00:54:27.280]   So I just make my imports.
[00:54:27.280 --> 00:54:29.600]   Let me restart this notebook.
[00:54:29.600 --> 00:54:31.520]   So convolutional networks.
[00:54:31.520 --> 00:54:34.960]   So in chapter MNIST Basics, which was the very first chapter,
[00:54:34.960 --> 00:54:37.840]   we were able to do like threes and sevens classification.
[00:54:37.840 --> 00:54:39.840]   We've also built pets classifier in the past.
[00:54:39.840 --> 00:54:43.120]   So now what's this magic of convolutions?
[00:54:43.120 --> 00:54:45.520]   And what exactly are convolutions?
[00:54:45.520 --> 00:54:47.840]   So let's see what convolutions are.
[00:54:48.240 --> 00:55:02.800]   So basically, for an image can be represented like this, right?
[00:55:02.800 --> 00:55:05.520]   On your left, this is how an image can be represented.
[00:55:05.520 --> 00:55:11.920]   As we already know, an image is just a bunch of numbers inside the,
[00:55:11.920 --> 00:55:13.440]   it's just like a matrix, right?
[00:55:13.440 --> 00:55:21.440]   So if we have a 28 by 28 image, then that's just a 28 by 28 rectangle, right?
[00:55:21.440 --> 00:55:28.480]   And if we say, we already know, like if we have a 3 by 28 by 28, which is an RGB image,
[00:55:28.480 --> 00:55:32.400]   then the 3 stands for the 3 colors, RGB.
[00:55:32.400 --> 00:55:33.920]   So that just becomes your 3 channels.
[00:55:33.920 --> 00:55:38.000]   Let me actually put them here.
[00:55:42.560 --> 00:55:49.200]   So remember how a single channel image between 3s and 7s,
[00:55:49.200 --> 00:55:53.600]   when you're looking at 3s and 7s, let me close this bit.
[00:55:53.600 --> 00:55:54.160]   One second.
[00:55:54.160 --> 00:55:59.040]   So when I go to 3s and 7s, remember how we were,
[00:55:59.040 --> 00:56:02.400]   when we were highlighting these things in the MNIST Basics
[00:56:02.400 --> 00:56:04.640]   and we looked at what an image actually looks like
[00:56:04.640 --> 00:56:08.160]   and we saw that an image inside is just a bunch of numbers, right?
[00:56:08.960 --> 00:56:13.440]   And for, so this is like the number 3 and then these becomes just numbers.
[00:56:13.440 --> 00:56:14.640]   This could be 244.
[00:56:14.640 --> 00:56:19.280]   And we had this discussion about, is black a higher number or is white a smaller number?
[00:56:19.280 --> 00:56:26.480]   Let's not go into the details of that because I think that's just slightly...
[00:56:26.480 --> 00:56:33.920]   Sorry, one sec.
[00:56:33.920 --> 00:56:39.440]   So red, green, and blue.
[00:56:39.440 --> 00:56:42.800]   And so then a 3D image looks like this.
[00:56:42.800 --> 00:56:46.640]   So I was just going to say, let's not go into the details of whether black is a higher number
[00:56:46.640 --> 00:56:49.520]   or how exactly these images are represented in the computer
[00:56:49.520 --> 00:56:51.280]   because that could be a bit digressing.
[00:56:51.280 --> 00:56:55.360]   But let's just focus on the main idea or the main concept,
[00:56:55.360 --> 00:56:57.920]   which is like if it's a 3-channel image,
[00:56:57.920 --> 00:57:01.920]   then I have these 3 matrices which kind of stack together,
[00:57:01.920 --> 00:57:06.640]   which represents the red, green, and blue, how much of a red is in the image,
[00:57:06.640 --> 00:57:08.720]   how much of a green is in the particular pixel.
[00:57:08.720 --> 00:57:12.400]   So if I'm looking at this pixel, then I'm looking at the blue pixel,
[00:57:12.400 --> 00:57:15.040]   I'm looking at the red pixel, and I'm looking at the green pixel.
[00:57:15.040 --> 00:57:17.120]   That's how this kind of works.
[00:57:17.120 --> 00:57:23.120]   So an image is just basically numbers underneath.
[00:57:23.120 --> 00:57:29.040]   And what we do when we have convolution is we just do matrix multiplication.
[00:57:30.000 --> 00:57:36.880]   So on your right, what this is, it's called a convolution kernel.
[00:57:36.880 --> 00:57:42.000]   And what you do is you take if your convolution kernel is of size 3x3,
[00:57:42.000 --> 00:57:52.560]   then if this is then all I do is on my image, I take a 3x3 block,
[00:57:52.560 --> 00:57:58.400]   I take my 3x3 kernel, and I multiply this number with this number,
[00:57:58.400 --> 00:58:03.600]   the second element with the second one, the third one with the third one, and so on.
[00:58:03.600 --> 00:58:07.600]   So you can see how I'm doing that here and you get some number or some output.
[00:58:07.600 --> 00:58:11.520]   This is exactly what's going on in a convolution operation.
[00:58:11.520 --> 00:58:17.840]   You basically have the image on your left, which is just a bunch of numbers,
[00:58:17.840 --> 00:58:22.320]   and then you have a convolution kernel, which could be a smaller size or a bigger size.
[00:58:22.320 --> 00:58:26.640]   So when you say 3x3 convolution, that just means that your convolution kernel
[00:58:26.640 --> 00:58:31.840]   is width 3 and height 3. So that's just this basic idea.
[00:58:31.840 --> 00:58:39.360]   And if you're trying to say, if you want to build an edge detector using convolutions,
[00:58:39.360 --> 00:58:44.560]   which is like when we were doing classification of digit 3 from digit 7.
[00:58:44.560 --> 00:58:51.040]   So what was the difference when we were doing digit 3 versus digit 7?
[00:58:51.040 --> 00:58:56.000]   Well, the one difference was in digit 7, you have a top edge over here.
[00:58:56.000 --> 00:58:59.520]   You have an edge over here. In 3, you have an edge over here,
[00:58:59.520 --> 00:59:02.720]   slight edge over here, a diagonal here, a diagonal here, and so on.
[00:59:02.720 --> 00:59:07.760]   So these are the things that a convolution kernel learns,
[00:59:07.760 --> 00:59:14.480]   or sorry, the convolution neural network learns, and it does so with the help of convolution kernels.
[00:59:14.480 --> 00:59:18.080]   And one such kernel is this top edge detector.
[00:59:18.080 --> 00:59:25.680]   So these nine numbers represent a kernel, and a convolution kernel, what it does is,
[00:59:25.680 --> 00:59:32.880]   it has the ability to learn these top edges. So how does it do that?
[00:59:32.880 --> 00:59:39.840]   Well, let's just say my top edge looks like I just have,
[00:59:39.840 --> 00:59:44.640]   because you know how I have 3x3 numbers, let's say these three numbers are minus 1,
[00:59:44.640 --> 00:59:49.440]   minus 1 at the top, 0 in the middle, and then 1 at the bottom, right?
[00:59:50.480 --> 00:59:57.600]   And then because my image looks like this. So let me just paste that.
[00:59:57.600 --> 01:00:14.480]   So because my image looks like this, and my kernel, my 3x3 kernel is minus 1, minus 1, minus 1,
[01:00:14.480 --> 01:00:20.160]   000111. So as I've said, a convolution operation
[01:00:20.160 --> 01:00:29.840]   is just like picking a 3x3 and multiplying it.
[01:00:29.840 --> 01:00:35.360]   And then what's going to happen is that if you multiply this section with this kernel,
[01:00:35.360 --> 01:00:38.720]   well, this is all going to be zeros, so nothing goes here.
[01:00:38.720 --> 01:00:42.880]   This is going to give a higher number. So when you multiply these by 1 and 1,
[01:00:42.880 --> 01:00:49.840]   so it's just going to be 155 plus 246 plus 182, whatever that number is.
[01:00:49.840 --> 01:00:58.560]   It's just going to give me a big or higher number. So that's exactly what this operation can be done
[01:00:58.560 --> 01:01:04.240]   then in using PyTorch. And what you do is, let's say I grab some
[01:01:04.240 --> 01:01:09.360]   section from this image. So I grab my rows-- oh, sorry, that's not defined.
[01:01:11.360 --> 01:01:17.200]   So I grab my rows 8, 9, and-- basically, I grab my rows 8, 9, and 10.
[01:01:17.200 --> 01:01:23.920]   So-- and I grab the columns 18, 19, 20. So 18, 19, let's see what those values are.
[01:01:23.920 --> 01:01:30.560]   So these are the values, 254, 75, 254, 153. And then if I multiply that with top edge,
[01:01:30.560 --> 01:01:36.960]   it gives me some random value. Not some random value, but it just gives me a lower value.
[01:01:36.960 --> 01:01:40.480]   Sorry, I didn't mean to say random. I just meant to say some lower value.
[01:01:40.480 --> 01:01:46.880]   But what if-- because this-- because remember, like the-- like this section of the image,
[01:01:46.880 --> 01:01:54.400]   7 to 10th row, 7-- basically, 8, 9, and 10th row, and column 18, 19, 20 is going to be somewhere
[01:01:54.400 --> 01:02:00.320]   here, right? That is not a top edge. So you want the kernel to give a high value when it sees the
[01:02:00.320 --> 01:02:05.200]   top edge, and you want the kernel to give a low value when there is no top edge. So because in
[01:02:05.200 --> 01:02:11.280]   this region, there is no top edge, it gives me a lower value. But what about the region between
[01:02:11.280 --> 01:02:21.520]   rows 5, 6, 7? So 5, this one, 6, 7, and then 7, 8, 9 columns. So 7, 8, 9. So that's just--
[01:02:21.520 --> 01:02:32.480]   let's see what the exact values are, which are-- oh, sorry. Am I doing this wrong? Is 4 to 7 is
[01:02:32.480 --> 01:02:40.800]   that-- that's row 4, 5, 6, not the-- OK, so 7 is out. Sorry, I just did a mistake when I was
[01:02:40.800 --> 01:02:46.720]   explaining indexing. I just thought this is rows 5, 6, 7. It's actually rows 4, 5, 6, and this is
[01:02:46.720 --> 01:02:54.960]   actually rows 6, 7, 8. Sorry. So 4, 5, 6, and 6, 7, 8. So 4, 5, 6, and 6, 7, 8. So it's going to be
[01:02:54.960 --> 01:03:06.160]   0, 0, 0, 142, 155, 256, 254, 254, 254. Now at this point, I want my top edge detector to give me a
[01:03:06.160 --> 01:03:11.760]   high value, right? So let's see. If I multiply that element by element and I check the sum,
[01:03:11.760 --> 01:03:18.960]   well, it is actually a high value. So our top edge detector is working. But how exactly is it working?
[01:03:21.440 --> 01:03:28.000]   So we are going from rows-- what is it? 4, 5, 6, which is like these three rows, and 6, 7, 8.
[01:03:28.000 --> 01:03:38.160]   These are the three numbers we had. So what exactly happens is at this point, because there's
[01:03:38.160 --> 01:03:44.160]   values at the bottom and no values at the top, the top values get multiplied by minus 1, minus 1,
[01:03:44.160 --> 01:03:49.600]   minus 1, which gives me 0. All of these become 0. And then you multiply with these, which becomes
[01:03:49.600 --> 01:03:55.600]   a higher value. So what was the value you were getting? 762. So that's how-- it's just through
[01:03:55.600 --> 01:04:00.640]   a little bit of math and just through a little bit of multiplication. In an image, when there's
[01:04:00.640 --> 01:04:07.200]   dark values at the bottom, which is in this case, and there's light values at the top,
[01:04:07.200 --> 01:04:13.040]   then that's your top edge, right? If you think of it from an intuition perspective,
[01:04:13.040 --> 01:04:19.040]   what is a top edge? What exactly is a top edge in an image? So if I have an image like this,
[01:04:19.040 --> 01:04:25.520]   which is 7, what exactly is a top edge? A top edge is something like I'm going from a region of
[01:04:25.520 --> 01:04:31.920]   white to suddenly a region where I hit some black. So I'm going from a region where the pixel values
[01:04:31.920 --> 01:04:37.440]   are really low or small at the top, but then suddenly I hit a point where there's some higher
[01:04:37.440 --> 01:04:43.440]   pixel values. So this is exactly what's happening when I was doing this multiplication. So if I
[01:04:43.440 --> 01:04:49.120]   went from rows 4, 5, 6, and let's just say I went to this region, I'm going from a region where
[01:04:49.120 --> 01:04:54.960]   there's all these light pixel values at the top, and suddenly I start hitting dark pixels. So this
[01:04:54.960 --> 01:05:03.120]   is why when I multiply this with minus 1, minus 1, 0, 0, 0, and 1, 1, 1, it just gives me a higher
[01:05:03.120 --> 01:05:09.600]   value because the bottom ones get multiplied by positive numbers. So that's this idea of top edge
[01:05:09.600 --> 01:05:17.280]   detector. And what if I wanted to detect a vertical edge? I could do something like minus 1, minus 1,
[01:05:17.280 --> 01:05:25.120]   0, 0, 0, 1, 1, 1. So what's this kernel going to do? It's going to represent I'm coming from light
[01:05:25.120 --> 01:05:29.680]   values on the left, and then suddenly I have dark values on the right. So it's going to
[01:05:29.680 --> 01:05:36.560]   look at basically the edges, the vertical edges. It's going to look at the vertical
[01:05:36.560 --> 01:05:42.160]   edge like this one because I'm coming from zeros, which will give me negative or zero values here,
[01:05:42.160 --> 01:05:46.800]   but suddenly for this rows, it gives me higher values because this is what gets multiplied by 1,
[01:05:46.800 --> 01:05:53.840]   1, and 1. So this is how these convolution kernels are. You don't have to define convolution kernels
[01:05:53.840 --> 01:05:59.280]   in a convolution neural network by yourself. These are kernels or these things, the
[01:06:00.320 --> 01:06:07.120]   convolution kernel learns on its own, but it is helpful to know how can these kernels detect top
[01:06:07.120 --> 01:06:14.320]   edges or how they can detect these bottom edges or left edges. So let's see what happens. So this is
[01:06:14.320 --> 01:06:20.080]   just explaining the math, how you go minus and then you have plus at the bottom. So we can create
[01:06:20.080 --> 01:06:27.200]   this small function, which can apply this kernel to basically my image. And then I can say, oh,
[01:06:27.200 --> 01:06:31.600]   please apply from row five and then to column seven. And then you can see the value that you
[01:06:31.600 --> 01:06:39.040]   get is 762. I will kind of stop here when it comes to convolution kernels. And just this,
[01:06:39.040 --> 01:06:46.320]   all I wanted to do is like just give a very basic introduction about like what kernels are and like
[01:06:46.320 --> 01:06:52.320]   how you can detect top edges and how you can detect bottom edges or left edges. What I want you to do,
[01:06:52.320 --> 01:06:57.760]   or would be really nice for this week would be if you can have a look at the collaborative
[01:06:57.760 --> 01:07:02.400]   filtering, you can read, and if you can read JLM's blog about embeddings and he gets some
[01:07:02.400 --> 01:07:06.000]   understanding about embeddings, then maybe that's something that you could write about, which is
[01:07:06.000 --> 01:07:10.640]   about this idea of like building movie recommendation systems and what exactly goes on and
[01:07:10.640 --> 01:07:15.760]   plotting and plotting embeddings and all that stuff. But it would also be really helpful if
[01:07:15.760 --> 01:07:25.440]   you come back next week and you read this chapter until 1.2. So I've given you a basic understanding
[01:07:25.440 --> 01:07:31.200]   of what exactly convolution kernels are, like how do they detect top edges and how do they detect
[01:07:31.200 --> 01:07:37.600]   these, what exactly these kernels stand for. In the rest of the sections, it's just showing how
[01:07:37.600 --> 01:07:43.680]   to do convolutions in PyTorch in 1.1.2. In 1.1.3, it's just introducing two new concepts, which are
[01:07:43.680 --> 01:07:48.640]   really small concepts, strides and padding. And then you can see like how convolution is just like
[01:07:48.640 --> 01:07:56.960]   a matrix multiplication in 1.1.4. So just come next week reading these four sections by yourself.
[01:07:56.960 --> 01:08:02.000]   And then we will continue and we will wrap up this chapter next week. So next week,
[01:08:02.000 --> 01:08:07.440]   we're going to wrap up chapter 13. But this is where I'll end and stop today in terms of like
[01:08:07.440 --> 01:08:13.520]   the explanations. So let me see if there's any questions. Are kernels randomly chosen?
[01:08:13.840 --> 01:08:18.720]   Or are they chosen from a limited set that they are known to perform, that are known to perform?
[01:08:18.720 --> 01:08:26.080]   So when the features were many, many years ago, when features were manually crafted,
[01:08:26.080 --> 01:08:32.800]   you had hand-designed kernels. But now you don't even define a kernel. Like when you say
[01:08:32.800 --> 01:08:41.760]   in, when you say something like nn.conv2d, or, and you define, say, my in channels are three,
[01:08:41.760 --> 01:08:46.320]   my out channels are three, and my kernel size is three. When you do something like that,
[01:08:46.320 --> 01:08:52.640]   the convolution is defining the kernels on its own. Like it's learning these weights. So what
[01:08:52.640 --> 01:08:59.040]   happens in convolution, or like when you build these things in PyTorch, is that it starts with,
[01:08:59.040 --> 01:09:02.880]   instead of like, we started with minus one, minus one, zero, zero, zero, one, one, one.
[01:09:02.880 --> 01:09:09.360]   What exactly happens is that it starts with some random values. But as you're doing training of
[01:09:09.360 --> 01:09:16.480]   the model, it starts to learn kernels that helps define, that helps to, that helps the model to
[01:09:16.480 --> 01:09:22.080]   classify things. So we don't really have to define anything. It's just, and these are things that we
[01:09:22.080 --> 01:09:28.240]   will actually touch a lot into in the next one. Oh, thank you. Kernels are typically initialized
[01:09:28.240 --> 01:09:37.040]   with random values. And pros and cons will become clear as we, thanks for the answer.
[01:09:38.240 --> 01:09:42.240]   I like this blog post, which allows me to play around with, absolutely, I know this one. This
[01:09:42.240 --> 01:09:48.320]   is really nice. So I have a look at this. This one just explains like, actually, let me post this.
[01:09:48.320 --> 01:09:53.520]   Let me, let's just add it to the, Angelica, I think you and I have got some work after this.
[01:09:53.520 --> 01:10:00.880]   We will just add all of these sections, convolution, and we will just add it to the
[01:10:00.880 --> 01:10:07.600]   thread at the top or pin this. So you can see now in this one, you'll be able to like play around
[01:10:07.600 --> 01:10:14.000]   with convolution kernels. So you can see if I have like, if these are the values in this image,
[01:10:14.000 --> 01:10:17.680]   what happens when I multiply kernels, you have like multiple kernels that you can select.
[01:10:17.680 --> 01:10:24.560]   If I select a left sub L or like, if I select, let's just say I select blur. So in a blur,
[01:10:24.560 --> 01:10:30.880]   all you have to do is like, you want to make the pixel values lower, right? That's what will blur
[01:10:30.880 --> 01:10:36.240]   the image. So that becomes my blur kernel, because all it is doing is like, it's multiplying by a
[01:10:36.240 --> 01:10:41.120]   lower value. If you multiply something by 0.06, it's going to be, the value is going to be reduced.
[01:10:41.120 --> 01:10:48.240]   So you just see, and you have like the, the center pixel has a higher weight. And then every pixel
[01:10:48.240 --> 01:10:52.640]   around it has like really small weights, which means that you're actually going to blur the
[01:10:52.640 --> 01:10:58.720]   image around the central pixel. So this is how like this, this, this thing works. And you can
[01:10:58.720 --> 01:11:04.480]   see like, oh, at this point, the values are 92 or like, whatever. So have a play around with this.
[01:11:04.640 --> 01:11:17.520]   I thought some of the image processing ones could be chosen.
[01:11:17.520 --> 01:11:24.800]   I think this used to be before. This is edge detection, box blur.
[01:11:28.240 --> 01:11:35.920]   I mean, I'm talking from a, I think the blurring or the edge, not exactly the blurring,
[01:11:35.920 --> 01:11:40.960]   but the blurring or sharpen, they're like augmentations or like you can, you can use
[01:11:40.960 --> 01:11:44.960]   blur as an augmentation. Then you know, what's going to happen in that augmentation. But I'm
[01:11:44.960 --> 01:11:50.400]   talking more from a perspective of like, when you build a, when you build a convolution neural
[01:11:50.400 --> 01:11:56.400]   network, like do we learn those kernels or do we have to like sharpen the image first and then blur
[01:11:56.400 --> 01:12:01.680]   the image or like all that stuff? So I think when we, when we are doing it from a perspective of
[01:12:01.680 --> 01:12:06.800]   like learning the model or learning the convolution neural network, like then that's when these things
[01:12:06.800 --> 01:12:12.000]   get started randomly. But anyway, we'll, we'll touch a lot on that. What does the negative
[01:12:12.000 --> 01:12:18.560]   values imply after doing the conv operation on an image? Sorry. What if the values are negative
[01:12:18.560 --> 01:12:24.000]   after doing a conv operation? How to handle this? Well, the values are always going to be like,
[01:12:24.000 --> 01:12:28.560]   they're not only going to be between zero and 255. Like they're going to be, it is very much
[01:12:28.560 --> 01:12:33.920]   possible. So if you have negative values, then that just means like your white gets shifted
[01:12:33.920 --> 01:12:38.800]   towards that negative minus 20. So this is something we will actually, this is, this has
[01:12:38.800 --> 01:12:46.160]   been explained in a section. I think it is section 1.1.2, where you do the blurring and you show the
[01:12:46.160 --> 01:12:51.200]   image. So anyway, just have a look and have a read of this section. All it does is it just shifts
[01:12:51.200 --> 01:12:56.960]   your, like instead of like zero being white, it just means like minus 20 is white. So just have
[01:12:56.960 --> 01:13:03.040]   a read. Gray becomes zero in that case. So just have a read and you will see what I mean. So just
[01:13:03.040 --> 01:13:09.280]   have a read of these four, four sections. Cool. So let's just stop there. Thanks everybody. And
[01:13:09.280 --> 01:13:13.440]   I will see you guys next week.
[01:13:13.760 --> 01:13:13.840]   Bye.
[01:13:14.800 --> 01:13:14.880]   [END]
[01:13:15.840 --> 01:13:15.920]   you
[01:13:15.920 --> 01:13:26.000]   [END]

