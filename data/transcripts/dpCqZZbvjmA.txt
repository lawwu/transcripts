
[00:00:00.000 --> 00:00:02.100]   All little chips began as big chips.
[00:00:02.100 --> 00:00:05.640]   The chips are made by dicing a wafer.
[00:00:05.640 --> 00:00:10.300]   And the wafer is for most of the chips you and I deal with, begin
[00:00:10.300 --> 00:00:12.000]   at 300 millimeter in diameter.
[00:00:12.000 --> 00:00:15.520]   And the chips are sort of punched out like your, your mother would
[00:00:15.520 --> 00:00:17.540]   punch out cookies from cookie dough.
[00:00:17.540 --> 00:00:21.760]   What's interesting is that for large AI work, we have to try and
[00:00:21.760 --> 00:00:23.160]   stitch them back together again.
[00:00:23.160 --> 00:00:23.720]   Right?
[00:00:23.720 --> 00:00:25.020]   One chip isn't enough.
[00:00:25.020 --> 00:00:31.020]   And so we then expend tremendous effort trying to tie these chips that earlier
[00:00:31.020 --> 00:00:34.960]   in the manufacturing process, we cut up in discrete elements, we try to
[00:00:34.960 --> 00:00:37.160]   reassemble them in the form of a cluster.
[00:00:37.160 --> 00:00:39.520]   And it turns out that's rather bad strategy.
[00:00:39.520 --> 00:00:43.120]   So if you can keep the traffic on your chip, you're thousands of
[00:00:43.120 --> 00:00:45.880]   times faster at a thousandth of the power.
[00:00:45.880 --> 00:00:50.440]   And so by building a big chip, we were able to keep a huge amount of the work
[00:00:50.440 --> 00:00:54.880]   that usually leaves chip boundaries and slows down training, we're able
[00:00:54.880 --> 00:00:59.920]   to keep it on the chip and do work much faster at much lower power.

