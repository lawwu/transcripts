
[00:00:00.000 --> 00:00:04.000]   sacks, how are you doing with your Tucker afterglow? Amazing
[00:00:04.000 --> 00:00:07.680]   episode, the feedback is the number one episode of the year
[00:00:07.680 --> 00:00:11.560]   after the vape, I think in trending to be maybe a million
[00:00:11.560 --> 00:00:14.680]   views on YouTube. So how's the afterglow?
[00:00:14.680 --> 00:00:17.640]   Yeah, I did notice there's one particular clip that's going
[00:00:17.640 --> 00:00:19.560]   viral where he calls you stupid.
[00:00:19.560 --> 00:00:20.720]   Yes, there's that.
[00:00:20.720 --> 00:00:26.200]   I thought Tucker was incredible. I found him so intellectually
[00:00:26.200 --> 00:00:31.240]   interesting. And it's not always the case that great moderators
[00:00:31.240 --> 00:00:34.400]   and interviewers make great guests, but he is so
[00:00:34.400 --> 00:00:38.440]   intellectually curious and has unique points of view that you
[00:00:38.440 --> 00:00:42.800]   want to hear them out. And his style of talking I find also,
[00:00:42.800 --> 00:00:46.440]   like very easy to listen to. I thought he was really impressive,
[00:00:46.440 --> 00:00:48.600]   really, really impressive. You don't have to agree with
[00:00:48.600 --> 00:00:51.800]   everything he says quite honestly. And some people
[00:00:51.800 --> 00:00:55.440]   probably won't. But I found it really compelling. I don't agree
[00:00:55.440 --> 00:00:59.400]   with half of stuff he said or maybe a third. But I too enjoyed
[00:00:59.400 --> 00:01:02.960]   it very much. I thought he was great sacks. I got you know, as
[00:01:02.960 --> 00:01:06.320]   the person people believe has Trump derangement syndrome,
[00:01:06.320 --> 00:01:09.240]   thank you for your trade. You know, or the person people
[00:01:09.240 --> 00:01:11.360]   consider like the far left, they're like, why aren't you
[00:01:11.360 --> 00:01:13.920]   pushing back? Why aren't you pushing back and this has
[00:01:13.920 --> 00:01:16.480]   become a MAGA takeover. You had Jared Kushner, he didn't get
[00:01:16.480 --> 00:01:19.040]   pushed back, you didn't get pushed back to Tucker. You know,
[00:01:19.040 --> 00:01:21.000]   one of the things we're trying to do here, I'm speaking for
[00:01:21.000 --> 00:01:24.360]   myself, is to let people talk, let them put out their position.
[00:01:24.840 --> 00:01:27.480]   And if you do that, and we did that with the presidential
[00:01:27.480 --> 00:01:31.200]   candidates, exceptionally, I think, then you can decide for
[00:01:31.200 --> 00:01:34.520]   yourself. And yes, we'll ask a hard question here or there, or
[00:01:34.520 --> 00:01:37.160]   maybe, you know, push them a little bit. But we don't want to
[00:01:37.160 --> 00:01:40.680]   make it uncomfortable to come here and make it like they come
[00:01:40.680 --> 00:01:43.600]   here and we take the 10 worst things about the person or the
[00:01:43.600 --> 00:01:46.240]   10 criticisms and run through them. You can get that on cable
[00:01:46.240 --> 00:01:49.000]   news, you can get that on either side of the aisle. What I want
[00:01:49.000 --> 00:01:52.440]   to do is let them talk. And then actually interesting things come
[00:01:52.440 --> 00:01:52.600]   up.
[00:01:52.640 --> 00:01:54.560]   Why do you always get this feedback?
[00:01:54.560 --> 00:01:57.280]   Because people perceive me because you say I have Trump
[00:01:57.280 --> 00:01:59.960]   derangement syndrome as the token left guy. That's all. And
[00:01:59.960 --> 00:02:02.080]   I'm a moderate and I try to keep saying that but people keep
[00:02:02.080 --> 00:02:04.720]   wanting to say I'm like, for our left, I just want folks to
[00:02:04.720 --> 00:02:08.080]   realize that we're going to go and have more guests, especially
[00:02:08.080 --> 00:02:11.040]   if we can learn from those folks. And especially if hearing
[00:02:11.040 --> 00:02:14.680]   them out can expand how we think about what's going on in the
[00:02:14.680 --> 00:02:19.040]   world. So get over it. And it's about learning and being
[00:02:19.040 --> 00:02:22.400]   curious. Hard conversations will be the norm here on the pod.
[00:02:23.280 --> 00:02:26.840]   We're going to have any guests we damn well, please. And some
[00:02:26.840 --> 00:02:29.040]   people will choose to not ask hard questions. I will choose to
[00:02:29.040 --> 00:02:32.400]   ask hard questions, but I won't hijack the show. And so please
[00:02:32.400 --> 00:02:35.320]   don't email me and tell me I didn't do my job fighting for
[00:02:35.320 --> 00:02:37.920]   the left or whatever. That's not my job. I'm going to ask a hard
[00:02:37.920 --> 00:02:40.520]   question when I want to on the show. But I'm not going to
[00:02:40.520 --> 00:02:41.640]   hijack the show with 20.
[00:02:41.640 --> 00:02:44.960]   Bravo to you. I suspect you're getting a lot of pressure from
[00:02:44.960 --> 00:02:46.040]   the private equity wives.
[00:02:46.040 --> 00:02:47.120]   Yes.
[00:02:47.120 --> 00:02:50.920]   What a great moment. What a great moment.
[00:02:50.960 --> 00:02:54.400]   People on SSRIs Jason are blowing up your inbox.
[00:02:54.400 --> 00:03:14.080]   Well, the conversation that everybody's going wild with so
[00:03:14.080 --> 00:03:17.160]   let's just get into it is these college anti semitism hearings.
[00:03:17.160 --> 00:03:20.480]   On Tuesday, the House Education Committee spoke with the
[00:03:20.480 --> 00:03:25.680]   presidents of Harvard, Penn, MIT. And they faced a lot of
[00:03:25.680 --> 00:03:30.520]   tough questions. Many of the videos went viral. And I guess
[00:03:30.520 --> 00:03:35.760]   the part that specifically went most viral was the presidents of
[00:03:35.760 --> 00:03:40.040]   these organizations refusing to specify whether or not the calls
[00:03:40.040 --> 00:03:44.840]   for mass murder of a particular group genocide of students were
[00:03:44.840 --> 00:03:48.040]   or were not against the codes of conduct against bullying and
[00:03:48.040 --> 00:03:50.080]   harassment at places like Harvard, Claudia and gay
[00:03:50.080 --> 00:03:53.920]   specifically, was asked over and over again, whether chance of
[00:03:53.920 --> 00:03:57.960]   intifada were violations of Harvard's code of conduct. She
[00:03:57.960 --> 00:04:01.160]   didn't give a great answer. I'm just curious, sacks. Obviously,
[00:04:01.160 --> 00:04:03.680]   you're Jewish, you went to the Ivy League, passionate about
[00:04:03.680 --> 00:04:10.160]   free speech. And you've talked about surplus politics. He is.
[00:04:10.160 --> 00:04:13.760]   What's your take here? Should students be allowed to march
[00:04:13.760 --> 00:04:19.320]   around campus, chanting from the river to the sea, intifada,
[00:04:19.320 --> 00:04:24.440]   etc. Because of free speech? Or, you know, did these code of
[00:04:24.440 --> 00:04:26.360]   conducts come into play? And what was your reaction when you
[00:04:26.360 --> 00:04:28.720]   saw their answers? Because obviously, there's a nuanced
[00:04:28.720 --> 00:04:29.040]   issue?
[00:04:29.040 --> 00:04:32.320]   Well, look, I mean, I have a very high bar for free speech. So
[00:04:32.320 --> 00:04:36.520]   I would allow, you know, almost everything. The problem that
[00:04:36.520 --> 00:04:39.160]   these university presidents have is that's not their position.
[00:04:39.160 --> 00:04:40.880]   They're trying to wrap themselves in the cloak of
[00:04:40.880 --> 00:04:43.920]   freedom of speech and academic freedom. But that has not been
[00:04:43.920 --> 00:04:47.600]   their practice on campus for many years. On a previous
[00:04:47.600 --> 00:04:51.120]   program, we talked about that fire survey, which polled
[00:04:51.120 --> 00:04:54.960]   students about how free they feel to express opinions on
[00:04:54.960 --> 00:04:58.600]   campus. The results were dismal for the Ivy League, the Ivy
[00:04:58.600 --> 00:05:02.000]   League scored way worse than state schools. And in fact,
[00:05:02.000 --> 00:05:06.160]   remember that Harvard got the blue Tarski is 0.0.
[00:05:08.560 --> 00:05:09.960]   Their last place,
[00:05:09.960 --> 00:05:13.600]   students there reported that speakers were shouted down,
[00:05:13.600 --> 00:05:16.920]   they weren't even invited, they weren't allowed to, to continue
[00:05:16.920 --> 00:05:20.760]   and finish their speeches. So Harvard has an abysmal record on
[00:05:20.760 --> 00:05:24.160]   freedom of speech. So it's hard to believe the president of
[00:05:24.160 --> 00:05:27.480]   Harvard when she claims that she's standing up for freedom of
[00:05:27.480 --> 00:05:31.520]   speech. And in fact, if you were to apply that same standard to
[00:05:31.520 --> 00:05:35.080]   other groups, do you really believe I mean, imagine if the
[00:05:35.080 --> 00:05:38.040]   representatives at that hearing had said to the president of
[00:05:38.040 --> 00:05:42.920]   Harvard, you know, are you allowed to advocate for
[00:05:42.920 --> 00:05:48.360]   genocide of black people or trans people? I mean, would the
[00:05:48.360 --> 00:05:50.880]   answer have been the same? I don't think so. I agree. I
[00:05:50.880 --> 00:05:55.920]   think absolutely not. So the question is, why are Jews being
[00:05:55.920 --> 00:05:58.680]   treated differently than these other groups? And I think this
[00:05:58.680 --> 00:06:04.000]   all goes back to kind of woke identity politics, where in the
[00:06:04.000 --> 00:06:07.560]   woke ideology, there are certain groups that are victim groups.
[00:06:07.960 --> 00:06:10.960]   And there are certain groups that are oppressor groups. And
[00:06:10.960 --> 00:06:14.600]   if you're in a victim group, then you get special
[00:06:14.600 --> 00:06:18.200]   protections. And if you're in an oppressor group, then it's just
[00:06:18.200 --> 00:06:21.880]   assumed that you can't really suffer discrimination or, you
[00:06:21.880 --> 00:06:28.440]   know, injustice in that same way. And I think that Jews have
[00:06:28.440 --> 00:06:32.120]   basically been put in an oppressor group, they basically
[00:06:32.120 --> 00:06:35.600]   are being put in the same group as, as all white people. And I
[00:06:35.600 --> 00:06:39.480]   think this has come as a great surprise to a lot of donors to
[00:06:39.480 --> 00:06:44.120]   these university campuses, who I think, were okay with woke
[00:06:44.120 --> 00:06:48.600]   identity politics to some degree when they believed that Jewish
[00:06:48.600 --> 00:06:53.680]   people were a potential victim group, and that anti semitism
[00:06:53.680 --> 00:06:57.680]   was being treated as real. And lo and behold, they have found
[00:06:57.680 --> 00:07:00.560]   out that no, they're an oppressor group, and they're not
[00:07:00.560 --> 00:07:04.880]   protected. And even very explicit cases of anti
[00:07:04.880 --> 00:07:07.840]   semitism are not being recognized by these universities
[00:07:07.840 --> 00:07:12.880]   because, again, it doesn't match up with this woke ideology. I
[00:07:12.880 --> 00:07:15.760]   think it would have been a lot better for a lot of these
[00:07:15.760 --> 00:07:20.200]   donors to realize that woke identity politics was a
[00:07:20.200 --> 00:07:23.240]   cul-de-sac. It was something that they should not have wanted
[00:07:23.240 --> 00:07:27.720]   to participate in. But I think they're now waking up to the
[00:07:27.720 --> 00:07:34.720]   realization that in this, again, oppressor, oppressed dichotomy,
[00:07:34.720 --> 00:07:35.840]   they're on the wrong side of that.
[00:07:35.840 --> 00:07:38.800]   I think you're exactly they don't like that realization.
[00:07:38.800 --> 00:07:41.720]   Exactly correct. Identity politics road to nowhere.
[00:07:41.720 --> 00:07:45.000]   Freeberg, you gave a passionate speech here about being forced
[00:07:45.000 --> 00:07:48.480]   to pick a side when we're talking about the conflict in
[00:07:48.480 --> 00:07:52.080]   the Middle East. And I guess there's underpinnings here of
[00:07:52.080 --> 00:07:57.700]   your discussion, anti Zionism, anti semitism, and where's the
[00:07:57.700 --> 00:08:01.720]   line between is just caring about humans and children being
[00:08:01.720 --> 00:08:08.400]   killed versus maybe harassment, etc. I'm curious when you saw
[00:08:08.400 --> 00:08:12.040]   these answers, what was your reaction? And yeah, how do you
[00:08:12.040 --> 00:08:12.520]   feel about it?
[00:08:12.520 --> 00:08:20.520]   I was surprised that the Congress people didn't ask the
[00:08:20.520 --> 00:08:26.380]   university presidents, what would your reaction be? If they
[00:08:26.380 --> 00:08:33.880]   started to burn crosses, and say something about white
[00:08:33.880 --> 00:08:40.540]   supremacy, black people don't belong in the US immigrants
[00:08:40.540 --> 00:08:45.160]   don't belong in the US if you picked another ethnic group and
[00:08:45.160 --> 00:08:48.840]   made statements that have traditionally been deemed
[00:08:48.840 --> 00:08:53.640]   threatening and harassing? Would they have made a difference of
[00:08:53.640 --> 00:08:57.620]   judgment? And if so, what's the difference between what's gone
[00:08:57.620 --> 00:09:03.240]   on this week, or in recent weeks, and what's gone on in
[00:09:03.240 --> 00:09:07.920]   other civil rights actions that have taken place in educational
[00:09:07.920 --> 00:09:11.260]   institutions. And I think that would have been like a really
[00:09:11.260 --> 00:09:15.700]   kind of telling understanding of the discernment that's that's
[00:09:15.700 --> 00:09:21.300]   being made on campus today, versus in the past. It is
[00:09:21.320 --> 00:09:25.540]   interesting to see that there's clearly a sense of being torn
[00:09:25.540 --> 00:09:31.400]   with respect to allowing the freedom of expression about
[00:09:31.400 --> 00:09:36.140]   groups that feel oppressed to be allowed to happen on campus,
[00:09:36.140 --> 00:09:41.660]   because that is probably a majority opinion. And that's why
[00:09:41.660 --> 00:09:44.860]   I think this is particularly difficult for these presidents
[00:09:44.860 --> 00:09:48.460]   to handle the situation. And I'm not excusing their behavior or
[00:09:48.460 --> 00:09:53.200]   their actions or their comments yesterday. But there's clearly
[00:09:53.200 --> 00:09:56.140]   something underlying this that I think we need to just
[00:09:56.140 --> 00:09:59.660]   acknowledge, which is that there is a large number of people,
[00:09:59.660 --> 00:10:03.340]   perhaps the majority of people that feel that there is some
[00:10:03.340 --> 00:10:06.900]   oppression going on, and that that oppression has a right to
[00:10:06.900 --> 00:10:10.380]   be spoken for, and that this behavior is the only way the
[00:10:10.380 --> 00:10:14.380]   Boston Tea Party did not follow convention, the Boston Tea Party
[00:10:14.380 --> 00:10:18.220]   was a rebellion against an institution that was oppressive
[00:10:19.180 --> 00:10:22.260]   and the Boston Tea Party was the only action that was going to
[00:10:22.260 --> 00:10:26.460]   make a change that could have driven a change and rebellion
[00:10:26.460 --> 00:10:30.140]   against an institution or an establishment that causes
[00:10:30.140 --> 00:10:36.540]   oppression isn't supposed to have rules. It isn't supposed to
[00:10:36.540 --> 00:10:39.220]   follow convention, it isn't supposed to be a discourse. And
[00:10:39.220 --> 00:10:43.700]   so I think that that sentiment is where a lot of this conflict
[00:10:43.700 --> 00:10:45.740]   is coming from for the presidents in making these
[00:10:45.740 --> 00:10:48.300]   decisions that they see that the majority of people truly
[00:10:48.300 --> 00:10:51.860]   believe that there's oppression that this is the course to speak
[00:10:51.860 --> 00:10:55.100]   up for that oppression, and that they can't step on that because
[00:10:55.100 --> 00:10:58.140]   if they did, they would be causing more disruption to more
[00:10:58.140 --> 00:11:02.020]   people than allowing it and it's a very difficult situation that
[00:11:02.020 --> 00:11:04.660]   they find themselves in. So I'm not excusing it, but I'm trying
[00:11:04.660 --> 00:11:05.820]   to frame up why I think
[00:11:05.820 --> 00:11:10.540]   smart people might be acting this way. Frankly, I think it's
[00:11:10.540 --> 00:11:14.900]   worth asking what would be the case if this were other ethnic
[00:11:14.900 --> 00:11:19.380]   groups or other people that were being kind of, you know, told,
[00:11:19.380 --> 00:11:23.220]   hey, we're gonna have an intifada against x or y or z,
[00:11:23.220 --> 00:11:24.620]   where the actions have been the same.
[00:11:24.620 --> 00:11:28.420]   Chabot, if they were asked that same question, is calling for
[00:11:28.420 --> 00:11:33.340]   the genocide of black Americans, Asian Americans, Indian
[00:11:33.340 --> 00:11:39.180]   Americans, trans Americans, harassment or bullying? What do
[00:11:39.180 --> 00:11:41.060]   you think their answers would have been? And then where do you
[00:11:41.060 --> 00:11:41.740]   think this has gone?
[00:11:41.740 --> 00:11:44.100]   I don't know what their answers would have been. But obviously,
[00:11:44.100 --> 00:11:48.220]   it's morally unacceptable. As best as I can tell, they were
[00:11:48.220 --> 00:11:52.460]   coached by lawyers before they appeared in front of Congress.
[00:11:52.460 --> 00:11:59.540]   And they found some verbal gymnastics, maybe to try to
[00:11:59.540 --> 00:12:04.220]   defend their point of view. And in it, they lost all moral
[00:12:04.220 --> 00:12:07.340]   clarity. Because to your point, Jason, if and to Friedberg's
[00:12:07.340 --> 00:12:11.740]   point, if you just replaced the Jewish people with any other
[00:12:12.700 --> 00:12:15.940]   people, maybe in this moment, it was harder to see. But it's
[00:12:15.940 --> 00:12:18.660]   like, these should not be debatable, difficult moral
[00:12:18.660 --> 00:12:26.380]   questions. So how did we get here? I think that over the last
[00:12:26.380 --> 00:12:31.020]   40 years, and to be honest, it started when the US News and
[00:12:31.020 --> 00:12:41.540]   World Report started to rank universities. They gamified the
[00:12:41.540 --> 00:12:44.660]   desire for these universities to get at the top of the list,
[00:12:44.660 --> 00:12:47.500]   which allowed them to theoretically get better
[00:12:47.500 --> 00:12:50.460]   recruits. But really, what it did was allow them to build
[00:12:50.460 --> 00:12:55.300]   massive asset management businesses that ultimately
[00:12:55.300 --> 00:13:00.660]   consume these schools. And now what you find is that the
[00:13:00.660 --> 00:13:04.020]   learning process has gotten totally perverted, because it
[00:13:04.020 --> 00:13:10.500]   became a second order priority to being able to raise money and
[00:13:10.500 --> 00:13:13.300]   to manage assets. I think Harvard Management Company at
[00:13:13.300 --> 00:13:18.140]   one point was one of the largest owners of forestry in America,
[00:13:18.140 --> 00:13:21.620]   you know, the other large owner was john Malone, a rapacious
[00:13:21.620 --> 00:13:26.060]   capitalist. So what this shows you is that the mission of these
[00:13:26.060 --> 00:13:30.500]   universities, which is to actually celebrate free speech
[00:13:30.500 --> 00:13:34.420]   and to teach kids to think critically has been lost. And I
[00:13:34.420 --> 00:13:39.780]   think that this was a very simple way of seeing it. And it
[00:13:39.780 --> 00:13:44.580]   should be disturbing to people that this happened, that the
[00:13:44.580 --> 00:13:50.220]   places where you send our 18 and 19 and 20 year old kids cannot
[00:13:50.220 --> 00:13:53.140]   at a very simple level, teach the moral clarity to say
[00:13:53.140 --> 00:13:57.900]   teaching or supporting even the concept of genocide should is
[00:13:57.900 --> 00:14:02.140]   wrong. Can you teach it in a historical context, obviously,
[00:14:02.140 --> 00:14:05.580]   but that's not what they even said there. Right. So they got
[00:14:05.580 --> 00:14:07.940]   into a level of verbal gymnastics, which I think is
[00:14:07.940 --> 00:14:10.540]   really, it should be viewed by everybody is pretty morally
[00:14:10.540 --> 00:14:11.220]   unacceptable.
[00:14:11.220 --> 00:14:14.660]   I think it's well said, and it's clearly bullying or harassment,
[00:14:14.660 --> 00:14:18.900]   if you're going to chase Jewish students around campus. And I
[00:14:18.900 --> 00:14:23.380]   think that's what we saw. Now, if you were to come off or sacks,
[00:14:23.380 --> 00:14:26.540]   or maybe sacks best since you're super, you have a super high
[00:14:26.540 --> 00:14:30.460]   benchmark freedom of speech. If these were students in a debate
[00:14:30.460 --> 00:14:34.740]   club, or in a lecture hall, giving their position taking
[00:14:34.740 --> 00:14:37.740]   hard questions, people opting into it, wouldn't feel like
[00:14:37.740 --> 00:14:43.020]   bullying harassment. Yet, the hypocrisy is so thick that the
[00:14:43.020 --> 00:14:46.540]   you know, they chase people like Ben Shapiro, off campus, etc.
[00:14:46.540 --> 00:14:49.860]   When they had something controversial to say at many of
[00:14:49.860 --> 00:14:54.140]   these schools. But I think we can all agree, chanting about
[00:14:54.140 --> 00:14:57.180]   genocide, and chasing students around campus and disrupting the
[00:14:57.180 --> 00:15:00.580]   campus. That feels like bullying harassment. I don't know that
[00:15:00.580 --> 00:15:02.700]   and I agree with you, Chamath this mental gymnastics that they
[00:15:02.700 --> 00:15:05.500]   went through. But the statements, it's just very easy
[00:15:05.500 --> 00:15:08.380]   to say, yes, that's harassment. Yes, that's bullying. Now, if
[00:15:08.380 --> 00:15:11.940]   you did it in a lecture hall, and you or you wrote a paper,
[00:15:11.940 --> 00:15:15.300]   sacks, maybe doesn't feel like bullying harassment feels like
[00:15:15.300 --> 00:15:16.060]   freedom of speech. Yeah.
[00:15:16.060 --> 00:15:22.500]   Yeah, look, I mean, we can, you can always debate the hard cases
[00:15:22.500 --> 00:15:26.220]   and in free speech and where the lines should be. And again, I
[00:15:26.220 --> 00:15:30.060]   would draw the lines in a way that makes most speech
[00:15:30.060 --> 00:15:33.220]   permissible. But when you're talking about chasing students
[00:15:33.220 --> 00:15:36.140]   around campus to yell in their face, that clearly is bullying
[00:15:36.140 --> 00:15:39.700]   or harassment. And there's no reason to ever allow something
[00:15:39.700 --> 00:15:42.300]   like that. But again, the point I would make is that what you're
[00:15:42.300 --> 00:15:48.300]   gonna see in the wake of this is that a lot of Jewish people are
[00:15:48.300 --> 00:15:52.260]   realizing that they don't have a home on the left anymore. And I
[00:15:52.260 --> 00:15:55.980]   expect that many Jews are going to start shifting right and into
[00:15:55.980 --> 00:16:00.500]   the Republican Party to a place where I've been for a while. And
[00:16:00.540 --> 00:16:03.260]   and I think this goes back a long way. So if you go all the
[00:16:03.260 --> 00:16:06.260]   way back to the original civil rights movement, the 1960s, I
[00:16:06.260 --> 00:16:09.860]   think that many Jews were an integral part of that movement.
[00:16:09.860 --> 00:16:13.580]   And they felt a great solidarity with the original civil rights
[00:16:13.580 --> 00:16:16.780]   movement, civil rights leaders, because they felt like they had
[00:16:16.780 --> 00:16:21.220]   a shared history of persecution that blacks in America had
[00:16:21.220 --> 00:16:24.060]   suffered from racism. Jews around the world felt like that
[00:16:24.060 --> 00:16:27.620]   stuff from anti semitism. And they basically believe that all
[00:16:27.620 --> 00:16:30.220]   people should be treated equally that we should have individual
[00:16:30.220 --> 00:16:34.100]   rights. And basically, they were advocating for a colorblind
[00:16:34.100 --> 00:16:37.540]   standard, right, a colorblind treatment of all people. And so
[00:16:37.540 --> 00:16:41.460]   I think that Jews historically have wanted to be on the left
[00:16:41.460 --> 00:16:44.380]   for that reason. But I think what's happened over the last
[00:16:44.380 --> 00:16:48.260]   few decades is that the civil rights movement, in particular,
[00:16:48.260 --> 00:16:51.940]   and the left have moved to this woke ideology where it's no
[00:16:51.940 --> 00:16:56.100]   longer about colorblindness. It's more about identity groups.
[00:16:56.380 --> 00:17:01.700]   And instead of trying to get past racial differences, it's
[00:17:01.700 --> 00:17:04.460]   been about accentuating them. And so we've had this whole
[00:17:04.460 --> 00:17:09.220]   equity agenda, which is really defined as redistribution from
[00:17:09.220 --> 00:17:12.780]   one racial group to another racial group. I think that for
[00:17:12.780 --> 00:17:15.500]   whatever reason, a lot of Jews just hadn't confronted the
[00:17:15.500 --> 00:17:19.940]   reality that the left had really changed in this way. And again,
[00:17:19.940 --> 00:17:22.540]   I think it goes back to the fact that they thought that, oh, well,
[00:17:22.540 --> 00:17:26.580]   if we're going to be defining identity groups in this, you
[00:17:26.580 --> 00:17:29.380]   know, woke way, you know, Jews obviously should be one of these
[00:17:29.380 --> 00:17:32.820]   victim groups, but they're waking up to the fact that Jews
[00:17:32.820 --> 00:17:36.700]   are not, you know, Jews are just in the minds of kind of woke
[00:17:36.700 --> 00:17:40.260]   ideology. Jews are just white people. Okay, successful white
[00:17:40.260 --> 00:17:44.540]   people with two white people with a Jewish background. And as
[00:17:44.540 --> 00:17:48.420]   a result, they're part of an oppressor class. And I think
[00:17:48.420 --> 00:17:51.580]   that for a lot of Jewish people who are waking up to this are
[00:17:51.580 --> 00:17:54.260]   realizing, wait a second, this is actually a very destructive
[00:17:54.260 --> 00:18:00.420]   ideology. And it makes us the bad guys. And so I would expect
[00:18:00.420 --> 00:18:04.580]   that, again, a lot of Jewish people are waking up to the ways
[00:18:04.580 --> 00:18:08.820]   in which the left has changed. And they're realizing that that
[00:18:08.820 --> 00:18:12.100]   is not a hospitable place in the political spectrum for them to
[00:18:12.100 --> 00:18:18.500]   be. And I would expect there to be kind of a pilgrimage now, of
[00:18:18.500 --> 00:18:21.940]   more Jews in America towards the right, as opposed to remaining
[00:18:21.940 --> 00:18:23.140]   on the left where they've always been.
[00:18:23.140 --> 00:18:26.980]   Yeah, the left needs to remember, people should be
[00:18:26.980 --> 00:18:29.860]   judged, not by the color of their skin or their ethnicity,
[00:18:29.860 --> 00:18:35.700]   but the content of their character. It's a quoting MLK
[00:18:35.700 --> 00:18:39.100]   can get you canceled right now, I think, to actually say that
[00:18:39.100 --> 00:18:41.780]   people should be judged by their color blindness is considered.
[00:18:41.780 --> 00:18:44.980]   You know, a lot of people call that racism. Now that's like,
[00:18:45.780 --> 00:18:49.740]   by the way, that that is the mainstream conservative view on
[00:18:49.740 --> 00:18:52.420]   civil rights related issues is that colorblindness should be
[00:18:52.420 --> 00:18:54.380]   the standard, right? I want to treat everyone used to be the
[00:18:54.380 --> 00:18:57.700]   same as individuals. Yes, exactly. But that was the
[00:18:57.700 --> 00:19:00.180]   liberal point of view. This was the civil rights movements.
[00:19:00.180 --> 00:19:04.740]   Basic tenant. Yeah, we've lost it all. By the way, I think
[00:19:04.740 --> 00:19:07.180]   there is just one other caveat we have to say about this whole
[00:19:07.180 --> 00:19:12.220]   issue, which is that it should be possible to criticize the
[00:19:12.220 --> 00:19:15.340]   State of Israel or Netanyahu, whose government or the bombing
[00:19:15.340 --> 00:19:19.260]   campaign they're conducting in Gaza, or the actions that led up
[00:19:19.260 --> 00:19:23.380]   to this event, there should be room to criticize Israel without
[00:19:23.380 --> 00:19:25.860]   being called an anti Semite. I want to be like really clear
[00:19:25.860 --> 00:19:30.700]   about that. And there needs to be a pretty wide latitude to
[00:19:30.700 --> 00:19:35.140]   have that conversation. And I do think that one of the mistakes
[00:19:35.140 --> 00:19:40.900]   that's happened for a while now is that Jewish groups have been
[00:19:40.900 --> 00:19:43.940]   a little too quick on the trigger to call people anti
[00:19:43.940 --> 00:19:47.860]   Semites for criticizing the policies of the Israeli
[00:19:47.860 --> 00:19:50.980]   government. And again, I think there needs to be wide latitude
[00:19:50.980 --> 00:19:54.180]   to do that. However, I don't think that's the type of speech
[00:19:54.180 --> 00:19:56.980]   that we're talking about here, Jason, I think you framed it up
[00:19:56.980 --> 00:20:02.300]   pretty well. This is people who have veered off of legitimate
[00:20:02.300 --> 00:20:05.420]   criticism, whether you agree with or not the legitimate
[00:20:05.420 --> 00:20:09.180]   criticism about the Israeli government's action into this
[00:20:09.180 --> 00:20:12.740]   sort of genocidal rhetoric. And that's what we're talking about
[00:20:12.740 --> 00:20:15.540]   here. Absolutely. Any final thoughts from the rest of the
[00:20:15.540 --> 00:20:17.700]   panelists before we move on to business?
[00:20:17.700 --> 00:20:19.900]   You guys think that they're going to get fired? Or what do
[00:20:19.900 --> 00:20:21.500]   you think is the right consequence for this?
[00:20:21.500 --> 00:20:25.380]   I think they're getting fired. I think the money, as you pointed
[00:20:25.380 --> 00:20:28.140]   out in your tweets, or is going to cause that they're going to
[00:20:28.140 --> 00:20:29.180]   lose a lot of donations.
[00:20:29.180 --> 00:20:32.700]   What do you think? I'm not tied into these like donor groups.
[00:20:32.700 --> 00:20:34.660]   It's the donor groups that are going to drive the decision
[00:20:34.660 --> 00:20:37.500]   because they're going to call the boards. And so I think it's
[00:20:37.500 --> 00:20:40.500]   really board dependent. Obviously, Ackman is a big donor
[00:20:40.500 --> 00:20:44.100]   at Harvard, and he's been very vocal about what he wants to see
[00:20:44.100 --> 00:20:50.740]   Harvard's board do. I think this is going to drive a big change.
[00:20:50.740 --> 00:20:55.140]   Whether individuals get fired. I really don't know. I think of
[00:20:55.140 --> 00:20:58.180]   the four, if I were to just have to make a bet, I'd say probably
[00:20:58.180 --> 00:21:01.740]   at least one of them is getting fired. It's like, but it's
[00:21:01.740 --> 00:21:02.700]   certainly going to change a lot.
[00:21:02.700 --> 00:21:04.540]   Matthew, you think they're gonna get fired? What do you think as
[00:21:04.540 --> 00:21:05.860]   you wrap final alert tomorrow?
[00:21:05.860 --> 00:21:07.900]   Yeah, I think I think free burgers, right, you have to
[00:21:07.900 --> 00:21:10.340]   follow the money. And I think the money has been very clear
[00:21:10.340 --> 00:21:12.940]   that this can't stand. And I think that that's good, because
[00:21:12.940 --> 00:21:17.100]   I think the people who've been donating have enough moral
[00:21:17.100 --> 00:21:20.380]   clarity on these kinds of topics to say this is unacceptable. So
[00:21:20.380 --> 00:21:22.980]   how long will it take to filter through the decision making? I
[00:21:22.980 --> 00:21:25.660]   don't know, because I also don't know how this machinery works.
[00:21:25.660 --> 00:21:29.900]   But I think what people have to decide immediately right now is
[00:21:29.900 --> 00:21:33.700]   all the kids that are applying for early access and early
[00:21:33.700 --> 00:21:38.620]   decision. Do you really want to go to these schools? And the
[00:21:38.620 --> 00:21:42.700]   parents? Do you want your kids to be going to these schools? So
[00:21:42.700 --> 00:21:45.700]   I think that's that's a kind of a decision that can probably
[00:21:45.700 --> 00:21:49.820]   happen right now or needs to happen right now. While all of
[00:21:49.820 --> 00:21:53.540]   this other kind of like donation driven asset manager driven
[00:21:53.540 --> 00:21:55.500]   decision making, take shape.
[00:21:55.500 --> 00:21:59.060]   All right, let's get into the state of the economy. It's a
[00:21:59.060 --> 00:22:01.420]   really interesting story I sent to the group chat from the
[00:22:01.420 --> 00:22:06.420]   Financial Times about tribalism now impacting how people view
[00:22:06.460 --> 00:22:09.580]   the economy. It's called expressive responding,
[00:22:09.580 --> 00:22:12.780]   basically, how you feel about the economy is based on which
[00:22:12.780 --> 00:22:17.380]   tribe you're in. Here's a quick snapshot of what's going on. If
[00:22:17.380 --> 00:22:21.460]   you're a Republican, and you were doing really well under
[00:22:21.460 --> 00:22:23.380]   Biden, you're going to say things are terrible in the
[00:22:23.380 --> 00:22:26.300]   economy during Trump, Dems were doing awesome, like everybody
[00:22:26.300 --> 00:22:28.500]   else. But because they hated Trump, they said the economy was
[00:22:28.500 --> 00:22:33.420]   trash. Here's the chart that explains that. And then I'll
[00:22:33.420 --> 00:22:35.380]   give you a couple quick bullet points of where the economy is.
[00:22:35.380 --> 00:22:40.100]   But you see the divergent there in the charts and based on the
[00:22:40.100 --> 00:22:43.300]   different administrations being in power. And if you look at the
[00:22:43.300 --> 00:22:46.340]   second chart, it's pretty telling this isn't happening.
[00:22:46.340 --> 00:22:48.900]   This tribalism is not happening in other countries, you can see
[00:22:48.900 --> 00:22:53.500]   France, Germany, UK, people feel about the economy, how the
[00:22:53.500 --> 00:22:57.860]   economy is actually doing pretty wild data. And I'll let you
[00:22:57.860 --> 00:22:59.900]   respond to that in just a second. I'm just gonna give you
[00:22:59.900 --> 00:23:03.580]   eight quick hits on what's going on the economy credit card debt
[00:23:03.620 --> 00:23:06.660]   is reaching all time highs. We surpassed 1 trillion back in
[00:23:06.660 --> 00:23:10.140]   July keeps rising. People are taking money out of their 401k
[00:23:10.140 --> 00:23:14.340]   is hardship distributions increased 13% between q2 and q3
[00:23:14.340 --> 00:23:17.540]   super spending just collapsed in October growing only point 2%
[00:23:17.540 --> 00:23:21.980]   last month versus 7% in September, but November year
[00:23:21.980 --> 00:23:25.380]   over year increases in Black Friday and Cyber Monday spending.
[00:23:25.380 --> 00:23:27.900]   So maybe that's a head fake. I don't know maybe people are
[00:23:27.900 --> 00:23:32.180]   bargain hunting, hunting consumer prices rose just 3.2%
[00:23:32.180 --> 00:23:37.340]   year over year in October versus 9.1% in June of 2022. Home
[00:23:37.340 --> 00:23:41.820]   sell 13 year low in October. Most folks are betting interest
[00:23:41.820 --> 00:23:45.220]   rate increases are over and summer betting interest rate
[00:23:45.220 --> 00:23:48.580]   cuts will start as early as q1 call she's forecast say we
[00:23:48.580 --> 00:23:51.740]   should expect to see and that's a prediction market to quarter
[00:23:51.740 --> 00:23:56.820]   point cuts by July sacks. We've been bearish on consumers. And
[00:23:56.820 --> 00:24:01.540]   all this crazy debt. Is this the beginning of the end? Is this
[00:24:01.540 --> 00:24:04.940]   the end? Where are we at in the consumer spending cycle?
[00:24:04.940 --> 00:24:07.940]   It's hard to know because there's so many mixed signals.
[00:24:07.940 --> 00:24:12.820]   Kobayashi letter had a great tweet on this. There's a lot of
[00:24:12.820 --> 00:24:16.060]   mixed economic data right now. But I mean, the economy seems to
[00:24:16.060 --> 00:24:20.060]   be doing fairly well, but the electorate doesn't feel it. And
[00:24:20.060 --> 00:24:24.300]   you're seeing in recent weeks, you're seeing a lot of
[00:24:24.300 --> 00:24:28.900]   commentary by pundits trying to convince the American people
[00:24:28.940 --> 00:24:32.940]   that the economy is better than people evidently feel that it
[00:24:32.940 --> 00:24:40.100]   is. And I think that one of the big reasons for this gap is
[00:24:40.100 --> 00:24:43.940]   that over the last few years, we've had a lot of inflation.
[00:24:43.940 --> 00:24:49.260]   And the rise in price levels has not been matched by the rise in
[00:24:49.260 --> 00:24:53.300]   people's incomes. So people simply feel worse off because
[00:24:53.300 --> 00:24:57.380]   their spending powers diminish. Now, it's true that the current
[00:24:57.380 --> 00:25:01.660]   inflation rate is going down. But all that means is that the
[00:25:01.660 --> 00:25:05.980]   price level now is growing at, call it 3% issue year, it's
[00:25:05.980 --> 00:25:08.940]   still growing. It's not like prices have come down. They're
[00:25:08.940 --> 00:25:13.740]   just rising at a slower rate. So you know, last year, we had a 9%
[00:25:13.740 --> 00:25:18.020]   in inflation. And inflation has been high the last couple of
[00:25:18.020 --> 00:25:21.140]   years, the rate of increase is slowing down. But people's
[00:25:21.140 --> 00:25:26.180]   wages, if you're working class have simply not kept up with
[00:25:26.180 --> 00:25:31.140]   the price of goods and services. And so I think people feel worse
[00:25:31.140 --> 00:25:35.340]   off than they did a few years ago. And you can try to convince
[00:25:35.340 --> 00:25:38.740]   them till you're blue in the face that actually, the economic
[00:25:38.740 --> 00:25:42.580]   data is great. But if you're somebody whose wages have not
[00:25:42.580 --> 00:25:45.180]   kept pace with price levels, you're not going to feel better
[00:25:45.180 --> 00:25:45.620]   off.
[00:25:45.620 --> 00:25:51.780]   Jamal, on your first point, I think that there is this thing
[00:25:51.780 --> 00:25:58.020]   that we've grown accustomed to, which is how you feel about
[00:25:58.020 --> 00:26:01.860]   what's happening versus what the data may say. And I think that
[00:26:01.860 --> 00:26:09.580]   the press and journalists in a pretty untrustworthy way, amplify
[00:26:09.580 --> 00:26:14.940]   this separation. So we hear about the economy doing well,
[00:26:14.940 --> 00:26:17.620]   maybe it's not doing well, we hear how the economy is not
[00:26:17.620 --> 00:26:21.140]   doing well, and it actually is doing well. Nobody wants to
[00:26:21.140 --> 00:26:23.260]   write about the data, people want to write about their
[00:26:23.260 --> 00:26:27.100]   feelings. And their feelings largely are more defined by the
[00:26:27.100 --> 00:26:30.540]   people around them and what they feel. So simple example, Nick,
[00:26:30.540 --> 00:26:32.580]   if you just want to throw this up, but there was a this is the
[00:26:32.580 --> 00:26:35.540]   Federal Reserve's data, this is not anybody else's data. But you
[00:26:35.540 --> 00:26:39.820]   would think that the wealth gap is being exacerbated. And you
[00:26:39.820 --> 00:26:42.980]   would think that wealth gains are going to a few. And again,
[00:26:42.980 --> 00:26:46.380]   without having an opinion, the data shows something truly
[00:26:46.380 --> 00:26:50.060]   incredible, which is that the American dream is not hanging on
[00:26:50.060 --> 00:26:54.980]   by a lifeline. But more and more American families are achieving
[00:26:54.980 --> 00:26:58.820]   it. You know, 12% of American families are now considered
[00:26:58.820 --> 00:27:01.900]   millionaire households, 8% are considered multi millionaire
[00:27:01.900 --> 00:27:05.180]   households. That's incredible. But what's even more impressive
[00:27:05.180 --> 00:27:09.980]   is that even as they do well, the cohort underneath them, the
[00:27:09.980 --> 00:27:14.980]   folks that make 150 to 250 k a year are the ones that are
[00:27:14.980 --> 00:27:19.740]   absolutely crushing, and they're making more than the top 10% of
[00:27:19.740 --> 00:27:24.340]   all families. So I think Jason, the the broader economic
[00:27:24.340 --> 00:27:27.460]   takeaway I have is unless you're willing to look at the raw data,
[00:27:27.460 --> 00:27:35.700]   the risk is high, that you will be fed an emotional perspective
[00:27:35.700 --> 00:27:40.140]   that amplifies your bias, or causes you to reject that view,
[00:27:40.140 --> 00:27:42.340]   because it just seems so untrustworthy. And it doesn't
[00:27:42.340 --> 00:27:45.060]   map to what you're seeing. It's very, very hard to tell the
[00:27:45.060 --> 00:27:48.060]   truth. That is Federal Reserve data that tells the truth about
[00:27:48.060 --> 00:27:51.220]   the US economy. And it turns out that, you know, the economy is
[00:27:51.220 --> 00:27:54.580]   pretty good and doing a lot for a lot of people.
[00:27:54.580 --> 00:27:59.020]   Freiburg, where do you sit, you've brought up the issue of
[00:27:59.020 --> 00:28:02.220]   credit card debt as a leading indicator, it's continues to
[00:28:02.220 --> 00:28:06.740]   surge. But there is some inkling that consumers may be tapped out
[00:28:06.740 --> 00:28:11.660]   IE tapping their 401ks. So what's your take on the consumer
[00:28:11.660 --> 00:28:15.780]   and this tribalism that we're seeing in the interpretation of
[00:28:15.780 --> 00:28:17.540]   data and how people feel about the economy?
[00:28:17.780 --> 00:28:20.620]   No, I mean, I think if people don't feel like they're
[00:28:20.620 --> 00:28:27.020]   progressing on the order of 10% a year, in terms of income
[00:28:27.020 --> 00:28:31.180]   adjusted for purchasing power, they're generally going to be
[00:28:31.180 --> 00:28:33.340]   unhappy, and they're going to project that as a general
[00:28:33.340 --> 00:28:37.380]   statement about quote, the economy. And so the more people
[00:28:37.380 --> 00:28:40.220]   that that's the case, the more you see that happening. And so
[00:28:40.220 --> 00:28:43.740]   while there may be, you know, a minority of people that are
[00:28:43.740 --> 00:28:48.580]   seeing great economic mobility, if a large enough percentage of
[00:28:48.580 --> 00:28:52.100]   people I don't see it, roughly call it 10% increase in
[00:28:52.100 --> 00:28:57.740]   lifestyle ability year to year. That's going to, you know, catch
[00:28:57.740 --> 00:29:00.820]   up to these overall scores of consumer sentiment. I think the
[00:29:00.820 --> 00:29:03.180]   way that economists measure the economy is a lot different than
[00:29:03.180 --> 00:29:05.300]   the average person measures the economy, which is really their
[00:29:05.300 --> 00:29:07.780]   own, you know, purchasing power and income.
[00:29:07.780 --> 00:29:08.660]   Saks your thoughts.
[00:29:08.660 --> 00:29:12.460]   Look, at the end of the day, the question that people ask
[00:29:12.460 --> 00:29:14.900]   themselves, which is the question that Ronald Reagan as
[00:29:14.900 --> 00:29:17.300]   voters in 1980 is, are you better off than you were four
[00:29:17.300 --> 00:29:20.340]   years ago. And I think that a lot of people, particularly
[00:29:20.340 --> 00:29:23.940]   working class people don't feel better off, because mainly their
[00:29:23.940 --> 00:29:29.180]   wages have not kept pace with the overall inflation level, not
[00:29:29.180 --> 00:29:32.540]   just measured on a one year basis, but over a four year
[00:29:32.540 --> 00:29:35.860]   basis. And I do think this could explain some of the tribalism
[00:29:35.860 --> 00:29:39.140]   Jason is that we've talked about this before that the biggest gap
[00:29:39.140 --> 00:29:42.300]   in the electorate is between professional class and working
[00:29:42.300 --> 00:29:45.380]   class. If you're a professional class, meaning you have a at
[00:29:45.380 --> 00:29:49.020]   least one college degree, by more than 30 points, you're
[00:29:49.020 --> 00:29:52.620]   likely to be a democrat. And if you're working class, which just
[00:29:52.620 --> 00:29:55.260]   means, you know, no college degree, let's say high school
[00:29:55.260 --> 00:29:57.900]   educated, you're much more likely to be a Republican, the
[00:29:57.900 --> 00:29:59.940]   parties have sort of flipped, the Republican Party is now a
[00:29:59.940 --> 00:30:02.100]   working class party, I think a lot of people find that very
[00:30:02.100 --> 00:30:05.660]   surprising. It's not the party of, you know, fat cat bankers
[00:30:05.660 --> 00:30:09.060]   anymore. And you know, the fortune 500. So the parties have
[00:30:09.060 --> 00:30:13.420]   really flipped. And I do think that working class people are
[00:30:13.420 --> 00:30:19.060]   most impacted by inflation. If you're kind of in lower to mid
[00:30:19.060 --> 00:30:22.980]   income, and your wages, the wages of labor have not gone up
[00:30:22.980 --> 00:30:26.220]   and prices have then you're going to be worse off. I do
[00:30:26.220 --> 00:30:29.380]   think that is a big part of it. And I think the media is sort of
[00:30:29.380 --> 00:30:32.500]   working on overdrive right now to convince people that they
[00:30:32.500 --> 00:30:34.940]   should think that their circumstances are better than
[00:30:34.940 --> 00:30:40.140]   they actually are. And, and maybe look, maybe the overall
[00:30:40.140 --> 00:30:44.220]   economic data right now is mixed to positive. I'll certainly
[00:30:44.220 --> 00:30:47.700]   concede that. But I think for the average person, what they
[00:30:47.700 --> 00:30:50.300]   care about their pocketbook, and it's far from clear that they're
[00:30:50.300 --> 00:30:52.900]   better off now than they were four years ago. Jason, what do
[00:30:52.900 --> 00:30:53.220]   you think,
[00:30:53.220 --> 00:30:56.540]   I think is a very important segment, because you're correct.
[00:30:56.540 --> 00:30:59.900]   sacks in a very nuanced point, multiple things true at once
[00:30:59.900 --> 00:31:03.300]   here, there is still sticker shock from inflation. I went to
[00:31:03.300 --> 00:31:07.220]   buy birthday cake, $47 for a cake. I was shocked. How does
[00:31:07.220 --> 00:31:11.260]   perfect it goes for you? So now is it made of cocaine? No, no, I
[00:31:11.260 --> 00:31:13.940]   just put the cocaine all over the top. But yeah, that's, you
[00:31:13.940 --> 00:31:16.740]   know, I got truffle shaved on it. I really felt like it was a
[00:31:16.740 --> 00:31:19.860]   white truffle cake. And this was a small cake. It was nuts.
[00:31:19.860 --> 00:31:24.140]   Anyway, there is sticker shock. The truth is, though, wages are
[00:31:24.140 --> 00:31:27.940]   very strong right now. And wages are slightly outpacing inflation.
[00:31:27.940 --> 00:31:30.780]   But that is a new phenomenon. Correct sacks. That is a new
[00:31:30.780 --> 00:31:34.180]   phenomenon. So people are still feeling the sticker shock. But
[00:31:34.180 --> 00:31:38.740]   at the same time, unemployment and wages drive how people feel
[00:31:38.740 --> 00:31:42.140]   and people are feeling obviously very confident as you see in the
[00:31:42.140 --> 00:31:45.380]   credit card debt when you're confident to trumat point about
[00:31:45.380 --> 00:31:47.860]   just follow the money and look at the actual numbers. People
[00:31:47.860 --> 00:31:49.980]   would not be taking out credit card debt, they wouldn't tap the
[00:31:49.980 --> 00:31:53.700]   401k if they felt they've got great job prospects. They have
[00:31:53.700 --> 00:31:57.340]   options for jobs. It's a 50 year low in unemployment, which is
[00:31:57.380 --> 00:32:00.540]   unbelievable that that's continued. And wages are
[00:32:00.540 --> 00:32:05.100]   increasing. Uber drivers are now making 30 for $36. And listen,
[00:32:05.100 --> 00:32:07.180]   I've been tracking how much they think from the beginning, it was
[00:32:07.180 --> 00:32:13.100]   $15, then $20 and $25. So wages are increasing massively, the
[00:32:13.100 --> 00:32:16.140]   GDP is 5%, or something like that. And unemployment is low.
[00:32:16.140 --> 00:32:19.740]   So the economy is actually doing extraordinary. That's just the
[00:32:19.740 --> 00:32:23.500]   fact but the sticker shock is very, very real. So I think we
[00:32:23.500 --> 00:32:25.900]   can wrap it there unless anybody wants to add
[00:32:25.900 --> 00:32:29.860]   well, by the way, just over the last month, there's been a huge
[00:32:29.860 --> 00:32:32.620]   rally in stocks, especially growth stocks, Bitcoin is now
[00:32:32.620 --> 00:32:38.260]   rallied to 44,000. What? Yeah, that's nuts. A firm is up like
[00:32:38.260 --> 00:32:41.980]   20% today. That's you know, the buy now pay later company
[00:32:41.980 --> 00:32:44.740]   because on strong Christmas spending, like you're saying
[00:32:44.740 --> 00:32:48.340]   all the stocks, sacks that bottomed because of interest
[00:32:48.340 --> 00:32:52.580]   rates have now just started to massively rally, massively. So
[00:32:52.580 --> 00:32:53.460]   all the secular
[00:32:53.500 --> 00:32:56.300]   this is all based on expectations of rate cuts
[00:32:56.300 --> 00:32:58.980]   coming sooner than people thought. And I think Bill
[00:32:58.980 --> 00:33:02.260]   Ackman has really led this trade and he timed it perfectly
[00:33:02.260 --> 00:33:07.740]   apparently, by basically going long the bottom market like a
[00:33:07.740 --> 00:33:13.260]   month ago, 10 years at 417 411. Sorry. We're off like, you know,
[00:33:13.260 --> 00:33:16.060]   80 basis points in like a couple months. It's not
[00:33:16.060 --> 00:33:19.980]   right. But all this euphoria, we've gone from fear to greed.
[00:33:19.980 --> 00:33:23.460]   And, you know, really in one or two months, it's all driven by
[00:33:23.460 --> 00:33:27.740]   rate expectations that people are expecting a rate cut in q1.
[00:33:27.740 --> 00:33:32.260]   And so far, that's not really justified by the feds. hawkish
[00:33:32.260 --> 00:33:34.500]   rhetoric, but people nevertheless seem to think it's
[00:33:34.500 --> 00:33:38.660]   coming. I think that this could be a do I put on my tinfoil?
[00:33:38.660 --> 00:33:42.220]   conspiracy.
[00:33:42.220 --> 00:33:50.380]   I think there will be a rate cut in q1. And I think this is the
[00:33:50.380 --> 00:33:53.980]   Biden bailout. Let's I think this is I think this is a Biden
[00:33:53.980 --> 00:33:58.740]   bailout by the Fed. Because if they cut rates in q1, that's
[00:33:58.740 --> 00:34:00.860]   going to make everyone feel really flush. It takes about six
[00:34:00.860 --> 00:34:03.620]   months to work its way into the system. But that's going to give
[00:34:03.620 --> 00:34:05.700]   a big boost to the Biden campaign.
[00:34:05.700 --> 00:34:11.220]   If you see a quarter point rate cut in q1. A trillion of the 5.7
[00:34:11.220 --> 00:34:13.500]   trillion in money market accounts will rip into the
[00:34:13.500 --> 00:34:13.980]   market.
[00:34:13.980 --> 00:34:17.420]   Oh, wow, that'll be nuts.
[00:34:17.580 --> 00:34:20.500]   Just people knowing that they're on the way down that they peeked
[00:34:20.500 --> 00:34:22.860]   in on the way down is gonna unlock a lot of capital.
[00:34:22.860 --> 00:34:25.940]   It's gonna unlock a lot of capital. And to be clear, it's a
[00:34:25.940 --> 00:34:28.020]   small group of people who believe it's coming in the first
[00:34:28.020 --> 00:34:31.700]   quarter, Bill Ackman and David Sachs. The majority according to
[00:34:31.700 --> 00:34:34.660]   prediction markets think we'll have two of them, you know, by
[00:34:34.660 --> 00:34:35.260]   the summer,
[00:34:35.260 --> 00:34:38.020]   without debating whether it happens in first quarter or
[00:34:38.020 --> 00:34:40.700]   second quarter. The more fundamental thing is, if you
[00:34:40.700 --> 00:34:45.900]   look two years out, you probably see rates around two and a half
[00:34:45.900 --> 00:34:50.820]   percent. And that's 160 basis points from here. That's the
[00:34:50.820 --> 00:34:54.220]   big, big change that I think helps all of us quite honestly.
[00:34:54.220 --> 00:34:58.660]   Yeah. And let's segue here. Great segment, by the way,
[00:34:58.660 --> 00:35:02.620]   gentlemen. Because in our backyard, what we do every day
[00:35:02.620 --> 00:35:06.140]   in terms of capital allocation and building companies, the
[00:35:06.140 --> 00:35:09.740]   cleanup work continues. It was a rager folks, people partied
[00:35:09.740 --> 00:35:13.300]   well into the next day. And we're still seeing seeing the
[00:35:13.300 --> 00:35:16.980]   cleanup Carta has some great data. And this is data amongst
[00:35:16.980 --> 00:35:21.220]   Carter users, which is a subset of users willing to pay an
[00:35:21.220 --> 00:35:24.540]   expensive price to manage their cap tables, the number of
[00:35:24.540 --> 00:35:27.660]   companies that shut down after raising 10 million, which is a
[00:35:27.660 --> 00:35:34.340]   very high benchmark that's up 238% in 2023. From 47 companies
[00:35:34.340 --> 00:35:38.900]   last year to 112 this year, also VC firms, and I'm seeing this
[00:35:38.900 --> 00:35:42.060]   very quietly happening. This isn't reported on VC firms are
[00:35:42.060 --> 00:35:45.820]   very opaque about laying people off or reshuffling the deck, but
[00:35:45.820 --> 00:35:50.260]   a firm called Openview out of Boston just abruptly shut down
[00:35:50.260 --> 00:35:54.380]   they had 70 plus employees, they just raised about 600 million of
[00:35:54.380 --> 00:35:58.420]   an $800 million target for their fund. There were reports about
[00:35:58.420 --> 00:36:01.220]   great cost, not hitting their target and reshuffling a bit
[00:36:01.220 --> 00:36:04.580]   that might have been overstated to be honest. But on the bright
[00:36:04.580 --> 00:36:08.700]   side, we're seeing some rebounding in a RR of the public
[00:36:08.700 --> 00:36:11.700]   SAS companies that started to rebound in q3. Here's the chart
[00:36:11.700 --> 00:36:17.020]   from altimeter. Looks like we hit bottom in q1 of 2023.
[00:36:17.020 --> 00:36:20.860]   Another bright spot public firms that are continuing to downsize
[00:36:20.860 --> 00:36:24.260]   are getting rewarded by the public market Spotify just did a
[00:36:24.260 --> 00:36:29.900]   third layoff 17% throughout 1500 employees. So I guess sacks
[00:36:29.900 --> 00:36:33.900]   everybody was thinking SAS was over it was the end of days we
[00:36:33.900 --> 00:36:38.420]   talked about not a recession SAS but a depression and I think
[00:36:38.420 --> 00:36:41.500]   that was accurate. How are you feeling about the private
[00:36:41.500 --> 00:36:44.740]   company market and maybe stabilization or the return of
[00:36:44.740 --> 00:36:46.660]   growth in SAS companies?
[00:36:46.660 --> 00:36:51.340]   Well, what I've been saying for the past year, year and a half
[00:36:51.340 --> 00:36:54.580]   is that we've been in a software recession, the overall economy
[00:36:54.580 --> 00:36:58.420]   may not have been in a recession because the consumer has stayed
[00:36:58.420 --> 00:37:01.380]   strong, as you said, consumer spending has stayed strong. So
[00:37:01.380 --> 00:37:06.260]   the BTC part has held up the economy. But I think in B2B, and
[00:37:06.260 --> 00:37:09.380]   particularly in software, there has absolutely been a recession.
[00:37:09.380 --> 00:37:13.900]   It started in the first half of 2022. With rate hikes, there was
[00:37:13.900 --> 00:37:20.540]   a huge revaluation of growth stocks. And you saw multiples
[00:37:20.540 --> 00:37:24.900]   come down on SAS valuations from in the public markets as high as
[00:37:24.900 --> 00:37:29.700]   35 down to seven or eight, something like that. In private
[00:37:29.700 --> 00:37:35.060]   VC world, we saw valuations go from called 100 times ARR to
[00:37:35.060 --> 00:37:38.620]   something more like 30 times ARR. So the first half of 2022,
[00:37:38.620 --> 00:37:42.900]   we saw a valuation correction. But then around mid 2022, what I
[00:37:42.900 --> 00:37:45.900]   started seeing in all my board meetings was every startup
[00:37:45.900 --> 00:37:48.420]   started missing its sales forecast, and they started
[00:37:48.420 --> 00:37:51.980]   reforecasting down. And that process really continued for a
[00:37:51.980 --> 00:37:55.700]   year. And we saw the exact same thing in the public markets in
[00:37:55.700 --> 00:37:59.540]   public SAS companies as well. And it's really remarkable how
[00:37:59.540 --> 00:38:04.660]   the data from the public stocks that our friend Jammin' Ball
[00:38:04.660 --> 00:38:09.420]   from Altimeter has been publishing, you know, regularly,
[00:38:09.420 --> 00:38:12.780]   how that has matched up with what I've seen kind of
[00:38:12.780 --> 00:38:17.260]   anecdotally, in board meetings, and you know, in conversations
[00:38:17.260 --> 00:38:22.020]   super healthy, correct, that the, the CEOs and the boards
[00:38:22.020 --> 00:38:24.900]   understand, hey, these private market valuations have to in
[00:38:24.900 --> 00:38:28.220]   some way, be informed by public, this is a very short because the
[00:38:28.220 --> 00:38:32.100]   public stocks are the exit comps. Right. So you know, if
[00:38:32.100 --> 00:38:35.580]   the public stocks are worth, I don't know, a third of what they
[00:38:35.580 --> 00:38:38.620]   used to be, then private valuations have to reflect that.
[00:38:38.620 --> 00:38:40.780]   But in any event, I want to go beyond just talking about
[00:38:40.780 --> 00:38:44.460]   valuations here, I want to talk about the business results. And
[00:38:44.460 --> 00:38:51.140]   again, for this time period from call it mid 2022, to mid 2023,
[00:38:51.140 --> 00:38:54.740]   there was a software session, software companies were cutting
[00:38:54.740 --> 00:38:58.180]   jobs, they were reforecasting down, they were growing slower,
[00:38:58.180 --> 00:39:00.740]   and many cases, they're actually shrinking. I mean, some
[00:39:00.740 --> 00:39:06.340]   companies lost AR are because of churn, you know, a lot of their
[00:39:06.340 --> 00:39:09.540]   customers were shutting down, or sharpening their pencils, they
[00:39:09.540 --> 00:39:13.340]   were consolidating vendors. The last year has been a really,
[00:39:13.340 --> 00:39:16.100]   really tough time in the software space. But I think now
[00:39:16.100 --> 00:39:19.820]   we've turned a corner I started seeing in the last couple of
[00:39:19.820 --> 00:39:22.760]   months, I started seeing green shoots, and some my board
[00:39:22.760 --> 00:39:25.780]   meetings. And now here we have this chart from jamming that can
[00:39:25.780 --> 00:39:29.100]   you just put this on the screen again, where we saw that finally
[00:39:29.100 --> 00:39:34.740]   in q3, we went from four quarters of negative growth in
[00:39:34.740 --> 00:39:38.500]   net new AR are to finally a quarter of positive growth. Now,
[00:39:38.500 --> 00:39:43.340]   2% is not a great number, but at least we are finally positive, as
[00:39:43.340 --> 00:39:46.780]   opposed to negative, which means that net new AR was shrinking. I
[00:39:46.780 --> 00:39:50.060]   think again, the the software session, I'm calling an end to
[00:39:50.060 --> 00:39:51.220]   the software recession.
[00:39:51.220 --> 00:39:55.420]   And is it an official breaking breaking news? SACS has called
[00:39:55.420 --> 00:39:59.580]   an end. So let's let the party begin, I think software revenues
[00:39:59.580 --> 00:40:03.220]   are going to rebound. I think the open question that's
[00:40:03.220 --> 00:40:06.780]   remaining then is will valuations rebound? Or will you
[00:40:06.780 --> 00:40:10.980]   have to grow into the last valuation or some truncated
[00:40:10.980 --> 00:40:15.420]   valuation? And this is where, you know, even if rates go to 2%
[00:40:15.420 --> 00:40:19.860]   are people going to be as excited again, to bring the
[00:40:19.860 --> 00:40:24.820]   public markets back to 15 and 20 times forward ARR. And that's an
[00:40:24.820 --> 00:40:28.260]   open question. I think the market says no, which means that
[00:40:28.260 --> 00:40:32.460]   even as growth comes back, you still have a valuation reset,
[00:40:32.460 --> 00:40:37.060]   that may actually explain why startups are shutting down. Why
[00:40:37.060 --> 00:40:40.460]   venture firms that you know, if you looked at that firm in
[00:40:40.460 --> 00:40:43.060]   Boston that shut down, they had some seemingly very good
[00:40:43.060 --> 00:40:45.500]   companies in their portfolio. So there should be nothing stopping
[00:40:45.500 --> 00:40:49.380]   them from continuing to raise capital and invest. But I just
[00:40:49.380 --> 00:40:53.260]   suspect the the end market that they operate in is going to be
[00:40:53.260 --> 00:40:57.580]   value constrained if they pay top dollar for things that are
[00:40:57.580 --> 00:41:01.220]   now just worth a lot less, even if they double revenue. I'll
[00:41:01.220 --> 00:41:03.500]   give you an example. We talked to the private equity guys a lot
[00:41:03.500 --> 00:41:06.580]   just because we try to understand where they are buyers,
[00:41:06.580 --> 00:41:09.300]   right? Why is that important? explain why private equity
[00:41:09.300 --> 00:41:11.860]   versus public markets and how they think about businesses?
[00:41:11.860 --> 00:41:13.540]   Because I think it's a very important point that you've made
[00:41:13.540 --> 00:41:17.940]   to me privately. I think that when you look at the ecosystem,
[00:41:18.140 --> 00:41:24.060]   the ecosystem doesn't work. If you never get liquidity to your
[00:41:24.060 --> 00:41:28.220]   employees and to your shareholders. So liquidity
[00:41:28.220 --> 00:41:32.900]   happens in one of two ways. It can go in the public markets, or
[00:41:32.900 --> 00:41:35.900]   you can transact to private equity. Why? Because they have
[00:41:35.900 --> 00:41:39.420]   almost as much money and frankly, more in many cases to
[00:41:39.420 --> 00:41:44.140]   pay than a public market can give you via a traditional IPO.
[00:41:44.700 --> 00:41:48.020]   So I think that they are a pretty rational buyer. And they
[00:41:48.020 --> 00:41:52.820]   do a very good job. Because they are a concentrated buyer of
[00:41:52.820 --> 00:41:55.980]   finding a very fair price, what is the real honest market
[00:41:55.980 --> 00:41:59.060]   clearing price. And so if you don't want to look at the market
[00:41:59.060 --> 00:42:03.220]   through rose colored glasses, and you want sobriety, ask a
[00:42:03.220 --> 00:42:05.460]   private equity investor what they would buy your position
[00:42:05.460 --> 00:42:08.460]   for. That's why I spend a lot of time talking to them because I
[00:42:08.460 --> 00:42:11.860]   want to know what this stuff is really worth. And what I would
[00:42:11.860 --> 00:42:14.100]   tell you is that even for companies that are in the
[00:42:14.100 --> 00:42:19.140]   hundreds of millions of ARR, the premiums that they're willing to
[00:42:19.140 --> 00:42:24.140]   pay are between three and five times ARR at the high end. And
[00:42:24.140 --> 00:42:26.700]   that a lot of deals get transacted between one and three
[00:42:26.700 --> 00:42:30.060]   times ARR. That may not be what people want to hear. But that's
[00:42:30.060 --> 00:42:32.500]   because when you look at the underlying ability to generate
[00:42:32.500 --> 00:42:36.020]   cash flow, many of these businesses haven't proved it
[00:42:36.020 --> 00:42:40.260]   yet. And so they want to buy things in a margin of safety
[00:42:40.260 --> 00:42:44.660]   where they can come in and cut certain expenses, while still
[00:42:44.660 --> 00:42:49.940]   helping to grow in certain markets. All of that used to be
[00:42:49.940 --> 00:42:52.860]   a 10x multiple in the public markets. So private equities
[00:42:52.860 --> 00:42:55.660]   buying for three to five times and really one to three times.
[00:42:55.660 --> 00:43:00.580]   It's going to be hard for the public market buyer to be paying
[00:43:00.580 --> 00:43:01.420]   a lot more than that.
[00:43:01.420 --> 00:43:03.740]   Got it. Can I build on that? This is a chart that was
[00:43:03.740 --> 00:43:08.820]   published on December 1 by jamming at altimeter. And I do
[00:43:08.820 --> 00:43:13.660]   think it speaks to the valuation question quite well. You can
[00:43:13.660 --> 00:43:19.740]   see here that there's this line at 7.8 times, which I think
[00:43:19.740 --> 00:43:24.700]   refers to 7.8 times next 12 months revenue. That is the
[00:43:24.700 --> 00:43:28.540]   long term pre COVID average. So that is where the average SAS
[00:43:28.540 --> 00:43:32.100]   stock has traded over a long period of time.
[00:43:32.100 --> 00:43:32.620]   Eight years.
[00:43:32.620 --> 00:43:35.820]   Currently, as of December 1, we're at 5.8. I think it's
[00:43:35.820 --> 00:43:38.380]   probably a little higher now because the markets pretty much
[00:43:38.380 --> 00:43:42.300]   rallied over the last five days. But you can see that we're still
[00:43:42.300 --> 00:43:47.580]   trading below the long term average in terms of multiples.
[00:43:47.580 --> 00:43:51.500]   And part of that is because interest the 10 year is still at
[00:43:51.500 --> 00:43:55.100]   4.3%. Although it's come down quite a bit, you can see a peak
[00:43:55.100 --> 00:44:01.300]   there around 5%. Now it's at 4.3. If you believe that the 10
[00:44:01.300 --> 00:44:03.940]   year is going to go back down to I don't know this two and a half
[00:44:03.940 --> 00:44:09.140]   3% range. And if you believe that growth is re accelerating,
[00:44:09.140 --> 00:44:15.380]   then I think there is room, you know, for this number, the 5.8
[00:44:15.380 --> 00:44:21.660]   number to at least grow into the long term average, which is 7.8.
[00:44:21.660 --> 00:44:26.300]   So there there is room there, I think that as the stocks are
[00:44:26.300 --> 00:44:30.860]   priced today, it doesn't feel like they're overpriced. Let's
[00:44:30.860 --> 00:44:33.900]   put it that way. And I never want to tell anyone what to
[00:44:33.900 --> 00:44:36.980]   buy. But you can see here that we are still trending below the
[00:44:36.980 --> 00:44:37.900]   long term average,
[00:44:37.900 --> 00:44:41.820]   he should pull this number back to 2010. Interesting. So at the
[00:44:41.820 --> 00:44:45.340]   start of the super cycle, after the Great Recession, yeah, not a
[00:44:45.340 --> 00:44:47.700]   bad point, but and probably pull it back, frankly, all the way to
[00:44:47.700 --> 00:44:51.740]   2005 2006. Because you had enough companies there that were
[00:44:51.740 --> 00:44:55.140]   public that were sassy software companies, including Salesforce
[00:44:55.140 --> 00:44:57.860]   might be a six instead of 7.8. And we might be at the 20 year
[00:44:57.860 --> 00:44:59.780]   average is a really good point. I'll ask Brad to do that
[00:44:59.780 --> 00:45:04.540]   freeberg. Switching to you, you have been a capital allocator
[00:45:04.540 --> 00:45:09.060]   and company formation, executive for the last close, getting
[00:45:09.060 --> 00:45:13.180]   close to a decade. And you made big news this week, instead of
[00:45:13.180 --> 00:45:15.820]   doing more funds, which I know you had a lot of people
[00:45:15.820 --> 00:45:18.980]   interested in backing your funds, you decided you're going
[00:45:18.980 --> 00:45:23.180]   all in, and that you are choosing to take the highest
[00:45:23.180 --> 00:45:26.540]   performer most promising company in your portfolio and become CEO
[00:45:26.540 --> 00:45:29.340]   of that company explain your decision because I think it does
[00:45:29.340 --> 00:45:32.860]   relate exactly because you're got skin in the game here the
[00:45:32.860 --> 00:45:35.820]   most skin possible, which is your time. You've decided to go
[00:45:35.820 --> 00:45:38.060]   the CEO route put all your eggs in one basket explain your
[00:45:38.060 --> 00:45:38.380]   thinking.
[00:45:38.380 --> 00:45:41.500]   We started a business at the production board, which is my
[00:45:41.500 --> 00:45:47.740]   firm. Four years ago with Judd Ward, who's the CTO and co
[00:45:47.740 --> 00:45:51.300]   founder of this business who came up with some pretty novel
[00:45:51.300 --> 00:45:55.540]   ideas on how we could use gene editing to make incredible
[00:45:55.540 --> 00:45:58.820]   transformations in agriculture reality. The conversation
[00:45:58.820 --> 00:46:02.820]   originally started from a paper I read. In January of 2019, I
[00:46:02.820 --> 00:46:05.060]   reached out to Judd and said, Hey, we should talk about this
[00:46:05.060 --> 00:46:08.220]   paper. And we started brainstorming and Judd came up
[00:46:08.220 --> 00:46:11.860]   with this concept for this business. And it was really a,
[00:46:11.860 --> 00:46:16.700]   you know, call it a moonshot that they undertook, and we've
[00:46:16.700 --> 00:46:20.180]   put 10s of millions of dollars of capital into this project
[00:46:20.180 --> 00:46:23.220]   over the last four years and been operating in stealth. And
[00:46:23.220 --> 00:46:25.740]   the team had some pretty significant breakthroughs this
[00:46:25.740 --> 00:46:28.580]   year that make the whole thing a reality. Now, the potential of
[00:46:28.580 --> 00:46:32.980]   the business is so significant, that I really don't have a
[00:46:32.980 --> 00:46:37.260]   choice. But to go all in on this, it's a no brainer, as, as
[00:46:37.260 --> 00:46:40.340]   I said, in the tweet, I put out, I could spend a bunch of my time
[00:46:40.340 --> 00:46:43.180]   as you said, like, starting other businesses or making
[00:46:43.180 --> 00:46:49.100]   investments, but at the end of the day, you know, investing a
[00:46:49.100 --> 00:46:52.980]   cruise to a power law, where if you have something that's going
[00:46:52.980 --> 00:46:57.860]   to be transformative, it could be many multiples on all the
[00:46:57.860 --> 00:47:00.660]   other stuff you do. And so it only made sense for me to say,
[00:47:00.660 --> 00:47:04.060]   Look, I've, I've got to dedicate my time, attention and energy to
[00:47:04.060 --> 00:47:07.100]   making sure that this business realize its potential, I'm going
[00:47:07.100 --> 00:47:10.620]   to go in full time as CEO. So it's pretty exciting, you know,
[00:47:10.620 --> 00:47:12.820]   gene editing, I'll talk a little bit about it. But I can't share
[00:47:12.820 --> 00:47:17.580]   too many details. gene editing, as you guys know, was discovered
[00:47:17.580 --> 00:47:20.180]   it's controversial whether it was discovered first by George
[00:47:20.180 --> 00:47:23.420]   church and the group at the at the Broad in Harvard, or Jennifer
[00:47:23.420 --> 00:47:28.260]   Doudna and her group at Berkeley. But CRISPR cast nine
[00:47:28.260 --> 00:47:32.820]   is the system that allowed us for the first time ever to go in
[00:47:32.820 --> 00:47:37.180]   and make specific edits to DNA. Historically, any work we've
[00:47:37.180 --> 00:47:42.580]   done in the genome has been, you know, very ad hoc haphazard,
[00:47:42.580 --> 00:47:46.220]   throwing large amounts of DNA into a cell to try and get that
[00:47:46.220 --> 00:47:49.860]   cell to do something. But CRISPR really unlocked this call it
[00:47:49.900 --> 00:47:55.340]   search and replace function in DNA. And that capability has
[00:47:55.340 --> 00:47:58.460]   allowed researchers to make novel therapeutics to create
[00:47:58.460 --> 00:48:01.940]   have new discoveries in biology, and it's really unlocked an
[00:48:01.940 --> 00:48:06.660]   entirely new era in biology. One application of gene editing is
[00:48:06.660 --> 00:48:10.220]   in agriculture, where we can look specifically at the genes
[00:48:10.220 --> 00:48:14.180]   and plants and what they do to the plant. And if we can make
[00:48:14.180 --> 00:48:18.020]   specific changes that you would otherwise see in nature, through
[00:48:18.020 --> 00:48:21.140]   traditional plant breeding and mutations happen over time
[00:48:21.140 --> 00:48:24.100]   through plant breeding, can you accelerate those changes? And
[00:48:24.100 --> 00:48:27.140]   can you make a set of changes? Rather than spend millennia
[00:48:27.140 --> 00:48:30.140]   breeding plants, can you make a specific set of changes that
[00:48:30.140 --> 00:48:33.220]   will cause the plant to do something very novel, and as a
[00:48:33.220 --> 00:48:36.820]   result, get the plant to be more successful. And by editing the
[00:48:36.820 --> 00:48:39.620]   DNA of the plant to make it more successful, its yield goes up,
[00:48:39.620 --> 00:48:42.980]   it can generate more food with less water, more food with less
[00:48:42.980 --> 00:48:47.620]   land, more food with less labor, etc, etc. That's the general
[00:48:47.620 --> 00:48:51.300]   premise on how we can use gene editing to drive productivity in
[00:48:51.300 --> 00:48:52.060]   agriculture.
[00:48:52.060 --> 00:48:55.980]   Amazing. And you could, I assume, make the strawberries
[00:48:55.980 --> 00:48:59.740]   taste more delicious, like those ones from Hokkaido in Japan, as
[00:48:59.740 --> 00:49:03.140]   opposed to just making them giant flavorless softballs.
[00:49:03.140 --> 00:49:05.900]   The way gene editing has been thought about in agriculture
[00:49:05.900 --> 00:49:08.980]   over the last decade has been exactly what you're saying,
[00:49:08.980 --> 00:49:12.620]   which is to make a specific trait edit, which is one edit in
[00:49:12.620 --> 00:49:16.660]   one gene that does one specific thing to the plant. And what
[00:49:16.660 --> 00:49:19.380]   Judd and the team came up with was starting with the problem
[00:49:19.380 --> 00:49:22.420]   rather than starting with this, you know, kind of very specific
[00:49:22.420 --> 00:49:25.780]   thing that we could do. And they said, how do we get yield to go
[00:49:25.780 --> 00:49:29.180]   up significantly in plants. And they came up with this creative
[00:49:29.180 --> 00:49:32.420]   idea, which is doing a series of edits, which is called
[00:49:32.420 --> 00:49:35.460]   multiplex editing, multiple edits across multiple genes,
[00:49:35.460 --> 00:49:38.500]   that would actually change the biology of a plant in a
[00:49:38.500 --> 00:49:42.060]   fundamentally understandable way. But that would ultimately
[00:49:42.060 --> 00:49:46.140]   drive such a transformative increase in yield, it would open
[00:49:46.140 --> 00:49:49.500]   up entirely new opportunities in agriculture. And so that was the
[00:49:49.500 --> 00:49:53.180]   moonshot was the series of edits that could, you know, change how
[00:49:53.180 --> 00:49:56.860]   plants, you know, do a specific set of things that makes their
[00:49:56.860 --> 00:49:59.700]   yield go up significantly. And we weren't sure if it would work.
[00:49:59.700 --> 00:50:01.900]   First of all, we weren't sure if it was possible to do the edits.
[00:50:01.900 --> 00:50:06.860]   Editing plants is very hard, the cell wall of plants has to be
[00:50:06.860 --> 00:50:09.500]   dissolved, then you have to get the editing machinery into the
[00:50:09.500 --> 00:50:12.420]   plant into the cell. And then you have to get that cell to
[00:50:12.420 --> 00:50:15.060]   edit the right gene and not have other edits. And then you have
[00:50:15.060 --> 00:50:17.540]   to get the cell to grow back into a plant. There's so many
[00:50:17.540 --> 00:50:20.260]   complicated, difficult steps, you have to get all of them to
[00:50:20.260 --> 00:50:23.180]   work. And then we weren't even sure if making all those edits
[00:50:23.180 --> 00:50:25.780]   would cause the outcome that we expected. And it turns out that
[00:50:25.780 --> 00:50:28.660]   that it does. And that happened as of a few weeks ago, this
[00:50:28.660 --> 00:50:30.980]   company. And that's why I decided to step in because
[00:50:30.980 --> 00:50:34.180]   suddenly, it's like, oh my gosh, the moonshot is working. We put
[00:50:34.180 --> 00:50:37.460]   in a lot of capital, we spent years funding the exercise, it's
[00:50:37.460 --> 00:50:40.540]   real. And now we're going to take off. And that's why I'm
[00:50:40.540 --> 00:50:43.540]   going on this. So I'm being a little cagey with respect to the
[00:50:43.540 --> 00:50:46.700]   details. As I understand, it's top secret stuff. That's fine. I
[00:50:46.700 --> 00:50:49.140]   definitely want to talk more specifically about what the
[00:50:49.140 --> 00:50:51.940]   team's done and what we're going to do with the business, which I
[00:50:51.940 --> 00:50:55.060]   will happily do in a few months when some some things become
[00:50:55.060 --> 00:50:58.300]   public. But in the meantime, I'm excited to do it. I got to tell
[00:50:58.300 --> 00:51:01.260]   you, the last set, it's been seven years since I've been an
[00:51:01.260 --> 00:51:06.180]   operating CEO. And, you know, to some degree, there's always
[00:51:06.180 --> 00:51:09.620]   been a piece missing for me and what I do every day, that I
[00:51:09.620 --> 00:51:12.460]   haven't felt like I've had the ability to have the influence
[00:51:12.900 --> 00:51:15.220]   and make the decisions that I think need to be made. You're
[00:51:15.220 --> 00:51:17.900]   advising the CEO, you're sitting in a board seat, kind of
[00:51:17.900 --> 00:51:21.260]   encouraging them to do certain things. But then sometimes they
[00:51:21.260 --> 00:51:24.180]   listen, and sometimes they don't. So to actually be in the
[00:51:24.180 --> 00:51:27.180]   seat feels to me like the right place. It's the right place
[00:51:27.180 --> 00:51:30.100]   where I can have the influence and drive the change that I want
[00:51:30.100 --> 00:51:33.620]   to see. And I haven't done that in a very long time. And so it's
[00:51:33.620 --> 00:51:36.700]   also personally, I think the right decision for me to find,
[00:51:36.700 --> 00:51:38.740]   you know, satisfaction in the work I'm doing, not to mention
[00:51:38.740 --> 00:51:39.940]   the excitement I get out of the business.
[00:51:40.140 --> 00:51:43.220]   And you and I have talked about this privately, you know, the
[00:51:43.220 --> 00:51:46.300]   world has too much capital, there's just tons of money,
[00:51:46.300 --> 00:51:49.740]   there's too many problems to be solved. The real issue,
[00:51:49.740 --> 00:51:54.460]   especially when you're running an incubator, or a studio, you
[00:51:54.460 --> 00:51:57.420]   know, a startup studio, like some of the startup studios, is
[00:51:57.420 --> 00:52:03.860]   who is going to pilot this very fast jet fighter and the number
[00:52:03.860 --> 00:52:08.180]   of people who are ambitious, and technically know how to fly one
[00:52:08.180 --> 00:52:11.260]   of these planes, and do it at high speed, and you know, want
[00:52:11.260 --> 00:52:14.780]   to take on that dangerous cockpit is very low. And so I
[00:52:14.780 --> 00:52:16.820]   think it's very courageous of you to jump on and do this. So
[00:52:16.820 --> 00:52:17.580]   congratulations.
[00:52:17.580 --> 00:52:19.820]   The point you're making is a really good one worth talking
[00:52:19.820 --> 00:52:23.140]   about just for a second. There's been this criticism in Silicon
[00:52:23.140 --> 00:52:27.020]   Valley. And I'd love your guys's point of view on this to
[00:52:27.020 --> 00:52:30.060]   Chamath and sacks, but like, and Jacob, but like, there's been
[00:52:30.060 --> 00:52:32.500]   this criticism in Silicon Valley, which is that, you know,
[00:52:32.500 --> 00:52:36.260]   we do too much of the easy stuff. And to all the capital
[00:52:36.260 --> 00:52:38.540]   goes into the apps and stuff, you know, things that are the
[00:52:38.540 --> 00:52:41.740]   path of least resistance to making money, not into the hard
[00:52:41.740 --> 00:52:44.180]   things that are low probability require a lot of capital. It's
[00:52:44.180 --> 00:52:47.540]   not universally true, but it's generally true with respect to
[00:52:47.540 --> 00:52:51.100]   how capital is allocated. And, you know, I was kind of talking
[00:52:51.100 --> 00:52:55.220]   with a bunch of people last week about this. And I kind of
[00:52:55.220 --> 00:52:58.740]   realized that, like, there's only if you're going to do a
[00:52:58.740 --> 00:53:01.820]   difficult project that requires a lot of capital, you're going
[00:53:01.820 --> 00:53:05.220]   to want to entrust that capital to someone that has proven
[00:53:05.220 --> 00:53:09.820]   themselves. Someone who's proven themselves is generally going to
[00:53:09.820 --> 00:53:11.740]   have the choice of things they're going to want to do with
[00:53:11.740 --> 00:53:14.340]   their life. And if they've proven themselves, it usually
[00:53:14.340 --> 00:53:16.700]   means they've had some exit event or some liquidity event
[00:53:16.700 --> 00:53:20.260]   that discourages them from doing a very difficult thing and
[00:53:20.260 --> 00:53:22.500]   taking on a lot of risk and burning themselves to death
[00:53:22.500 --> 00:53:25.580]   again, when they've already made it. And the people that have
[00:53:25.580 --> 00:53:27.940]   made it usually make it in software the first time around
[00:53:27.940 --> 00:53:30.860]   because software creates a path of least resistance to
[00:53:31.380 --> 00:53:35.980]   generating returns. And then the challenging question for them is
[00:53:35.980 --> 00:53:39.380]   do you do it again, and you make easy money, you know how to do
[00:53:39.380 --> 00:53:44.340]   it? Or do you take a 5% shot or 2% shot of success 98% chance of
[00:53:44.340 --> 00:53:47.660]   failure, going after a very hard project that takes a very long
[00:53:47.660 --> 00:53:51.700]   period of time. So I think that the challenge with difficult
[00:53:51.700 --> 00:53:56.820]   technology being developed in Silicon Valley is less about a
[00:53:56.820 --> 00:53:59.780]   dearth of capital or dearth of ideas or dearth of opportunities.
[00:53:59.780 --> 00:54:02.740]   It's more about a dearth of talent, that finding the right
[00:54:02.740 --> 00:54:07.460]   folks who have the capabilities and have done this before, to
[00:54:07.460 --> 00:54:10.340]   want to step back into the saddle and take on a very large
[00:54:10.340 --> 00:54:14.340]   low probability problem is really the challenge that I see
[00:54:14.340 --> 00:54:17.460]   a lot of in getting a lot of these things kind of going and
[00:54:17.460 --> 00:54:20.740]   funded hard to get people to be in the arena. Yes, Chima, you've
[00:54:20.740 --> 00:54:21.940]   seen this in your portfolio,
[00:54:21.940 --> 00:54:24.860]   a hard problem is what I'm saying, like a 2% chance of
[00:54:24.860 --> 00:54:27.460]   success kind of problem. Like, why would I do that? When I can
[00:54:27.460 --> 00:54:30.340]   go do something that's I'm 60% likely to succeed at and do
[00:54:30.340 --> 00:54:31.180]   really well doing it.
[00:54:31.180 --> 00:54:37.860]   I find that most companies are very under managed and under
[00:54:37.860 --> 00:54:42.060]   experienced. And it's surprising for me, it lacks a level of
[00:54:42.060 --> 00:54:45.780]   sophistication that I just assumed existed. And I guess
[00:54:45.780 --> 00:54:48.620]   that's because my last experience was when I was
[00:54:48.620 --> 00:54:52.140]   helping to build a company that frankly, coming out of the great
[00:54:52.140 --> 00:54:55.500]   financial crisis, we were recruiting people at Facebook
[00:54:55.500 --> 00:54:59.540]   from Google for the most part, and then building an entire core
[00:54:59.540 --> 00:55:04.300]   of young people and grooming from within. It was, we had a
[00:55:04.300 --> 00:55:09.260]   pretty good go of it. Fast forward to 2023. And I must
[00:55:09.260 --> 00:55:12.220]   admit that the companies that I interact with when I get into
[00:55:12.220 --> 00:55:16.900]   the weeds, I think the real talent to Friedberg's point is
[00:55:16.900 --> 00:55:20.980]   spread too thin across too many businesses. And so there are
[00:55:20.980 --> 00:55:24.860]   pockets of greatness in every company, but there's no real
[00:55:24.940 --> 00:55:27.540]   gravitational pull for any of them as a result of that.
[00:55:27.540 --> 00:55:30.220]   This is an excellent point as well. When we had a SERP
[00:55:30.220 --> 00:55:36.020]   environment, so many companies got funded, an amazing CMO, CTO,
[00:55:36.020 --> 00:55:40.300]   VP of Ops, started their own company. And they were just
[00:55:40.300 --> 00:55:42.940]   their natural position was the sixth man on the bench, you
[00:55:42.940 --> 00:55:45.780]   know, on the Knicks or the Warriors, not the primary
[00:55:45.780 --> 00:55:48.180]   scorer, they weren't Steph Curry, they shouldn't be in that
[00:55:48.180 --> 00:55:50.420]   position, they should be coming off the bench and being an
[00:55:50.420 --> 00:55:53.460]   amazing contributor. This is I've concluded the best time in
[00:55:53.460 --> 00:55:58.260]   the world to start a new company. I am absolutely amazed
[00:55:58.260 --> 00:56:01.220]   by the companies coming in applying for funding for us.
[00:56:01.220 --> 00:56:03.500]   I understand because that's your business model. But what about
[00:56:03.500 --> 00:56:05.980]   encouraging people to actually join a good company and learn
[00:56:05.980 --> 00:56:07.100]   how to be a good manager?
[00:56:07.100 --> 00:56:10.860]   Absolutely. These are two, the two best options, I think, if
[00:56:10.860 --> 00:56:14.420]   you have two or three really great builders, you actually
[00:56:14.420 --> 00:56:17.020]   know how to build into two or three, you have a great idea,
[00:56:17.020 --> 00:56:19.260]   and you want to do it, I encourage you to start a
[00:56:19.260 --> 00:56:21.420]   startup. If you don't have a great idea, you don't have two
[00:56:21.420 --> 00:56:24.060]   or three co founders, you don't want to leave the thing. Find
[00:56:24.060 --> 00:56:27.220]   somebody who's just getting onto the launchpad or just getting a
[00:56:27.220 --> 00:56:30.340]   little escape velocity in their rocket, which would be defined
[00:56:30.340 --> 00:56:35.820]   as 10 to 30 employees, maybe having raised two to $20
[00:56:35.820 --> 00:56:40.100]   million, that's an ideal time to get on the rocket. And just any
[00:56:40.100 --> 00:56:44.060]   seat you can get. As Sheryl Sandberg said, famously, any
[00:56:44.060 --> 00:56:46.460]   seat on the rocket ship is a seat on the rocket ship, you
[00:56:46.460 --> 00:56:47.860]   just want to get on board. Yeah,
[00:56:47.860 --> 00:56:51.340]   I disagree with the first part of what you said. Oh, okay.
[00:56:51.380 --> 00:56:51.980]   Explain why.
[00:56:51.980 --> 00:56:57.180]   I run into two and three person teams every day that I think are
[00:56:57.180 --> 00:57:00.540]   exceptionally talented, who should be inside of a company.
[00:57:00.540 --> 00:57:03.220]   And instead, they found somebody to give them money. And so
[00:57:03.220 --> 00:57:04.820]   instead, they're starting something and they're just
[00:57:04.820 --> 00:57:08.260]   meandering. And the problem with these two and three person teams
[00:57:08.260 --> 00:57:12.460]   is that even now, if you stick the right label on it, like AI,
[00:57:12.460 --> 00:57:17.740]   you'll find five or six or $7 million of money, it won't be
[00:57:17.740 --> 00:57:22.180]   led by any single investor. So it's all done in a safe. None of
[00:57:22.180 --> 00:57:25.420]   these folks have boards. And so they come in and check in with
[00:57:25.420 --> 00:57:28.020]   me time to time. And I asked him about their progress, and it's a
[00:57:28.020 --> 00:57:31.940]   mess. And I'm shocked. And I'm like, why are you guys wasting
[00:57:31.940 --> 00:57:35.220]   your time, like you should be at a startup that's winning. And
[00:57:35.220 --> 00:57:37.460]   part of it is that they think it's the right thing to do. And
[00:57:37.460 --> 00:57:41.500]   I don't think there's any valor in being a founder. I think
[00:57:41.500 --> 00:57:44.340]   there's a lot of valor in building something that's really
[00:57:44.340 --> 00:57:46.980]   valuable for people. And if that means being a director of
[00:57:46.980 --> 00:57:48.460]   marketing, go do that instead.
[00:57:48.460 --> 00:57:53.100]   It's a valid point. I think your most valid point in that is that
[00:57:53.100 --> 00:57:57.260]   there is not governance and mentorship for during the peak
[00:57:57.260 --> 00:58:01.500]   Zerp era. We created something called founder university to
[00:58:01.500 --> 00:58:03.580]   kind of sit well, of course, where we teach people how to do
[00:58:03.580 --> 00:58:06.180]   this stuff. And then we wind up investing in about 10% of those
[00:58:06.180 --> 00:58:10.740]   companies. And it's nuts how many people are applying. And we
[00:58:10.740 --> 00:58:15.420]   tell people when you hit $255,000 in revenue, we'll start
[00:58:15.420 --> 00:58:18.820]   doing quarterly board meetings with you. And they don't even
[00:58:18.820 --> 00:58:20.660]   have to be officially board meetings, or just mentoring
[00:58:20.660 --> 00:58:24.020]   sessions for one hour where you present as if it's a board. And
[00:58:24.020 --> 00:58:27.980]   so I agree, largely the passing of the hat and doing a party
[00:58:27.980 --> 00:58:32.420]   round. And having no mentorship is a weakness in the system in
[00:58:32.420 --> 00:58:34.500]   our firm. We fixed it. We found a university
[00:58:34.500 --> 00:58:36.740]   Yeah, but isn't dropping a slightly different point?
[00:58:36.740 --> 00:58:42.060]   Jason's with respect? Well, I think that when you have bubbly
[00:58:42.060 --> 00:58:45.260]   funding conditions, it leads to an over fragmentation of
[00:58:45.260 --> 00:58:49.260]   talent. Sure. I mean, isn't that the point? Yes. I mean, it takes
[00:58:49.260 --> 00:58:54.100]   a certain concentration of outstanding people, not just
[00:58:54.100 --> 00:58:56.780]   founders, but also like early employees to create a great
[00:58:56.780 --> 00:58:57.620]   company. And
[00:58:57.620 --> 00:58:59.260]   now with PayPal, right? I mean, that was the greatest
[00:58:59.260 --> 00:59:00.140]   concentration of
[00:59:00.140 --> 00:59:02.780]   news in history with talent, right? You have like
[00:59:02.780 --> 00:59:04.740]   that in Google would be the two best examples. Yeah.
[00:59:04.740 --> 00:59:09.620]   Yeah. So one of the reasons why you can end up with again, an
[00:59:09.620 --> 00:59:12.260]   over fragmentation is if there is too much funding in the
[00:59:12.260 --> 00:59:17.180]   system, and everybody's getting funded for really, you know, mid
[00:59:17.180 --> 00:59:22.860]   ideas. And it prevents a congealing of great talent to
[00:59:22.860 --> 00:59:26.140]   come together at companies where to have a really big idea. If
[00:59:26.140 --> 00:59:30.340]   you believe that the startup ecosystem was overfunded during
[00:59:30.340 --> 00:59:33.380]   the ZURP bubble, which it clearly was, I mean, you don't
[00:59:33.380 --> 00:59:36.900]   just get bubbly valuations, you also get bubbly funding
[00:59:36.900 --> 00:59:40.500]   conditions, then by definition, there are companies at the
[00:59:40.500 --> 00:59:42.900]   margins, they're getting funded, that shouldn't get funded. And
[00:59:42.900 --> 00:59:45.460]   that leads to an over fragmentation of talent.
[00:59:45.460 --> 00:59:49.780]   Here's what's happening on the ground. We used to see a lot of
[00:59:49.780 --> 00:59:52.820]   solo founders outsourcing their tech, what we're seeing now is
[00:59:52.820 --> 00:59:55.220]   usually two, three, four founders getting together to do
[00:59:55.220 --> 01:00:01.100]   a company. And one of the counter prevailing forces here
[01:00:01.100 --> 01:00:03.900]   is what we saw with Spotify, just laying off 1700 people
[01:00:03.900 --> 01:00:07.580]   Google laying off 20,000 Facebook laying off, I think 25
[01:00:07.580 --> 01:00:11.420]   or 30,000, Microsoft, Uber, all these companies have laid off so
[01:00:11.420 --> 01:00:14.460]   massively, they're all on hiring freezes. So then what happens is
[01:00:14.460 --> 01:00:17.500]   there's massive amounts of talent at reasonable prices
[01:00:17.500 --> 01:00:20.940]   joining together after having worked at those companies. And
[01:00:20.940 --> 01:00:23.820]   so I would say the companies were funding at this early stage,
[01:00:23.820 --> 01:00:27.340]   we're never doing solo founders, I mean, unless it's a serial
[01:00:27.340 --> 01:00:29.380]   entrepreneur, and we're seeing two or three people who worked
[01:00:29.380 --> 01:00:33.740]   at Uber or Google or Airbnb, you know, who have like this really
[01:00:33.740 --> 01:00:36.900]   great product velocity coming together, and they have to be
[01:00:36.900 --> 01:00:40.020]   builders. So I think it's two things are true at once that the
[01:00:40.020 --> 01:00:43.220]   number of companies being funded has plummeted, I think about 75%
[01:00:43.220 --> 01:00:46.940]   sacks. But the quality and the amount of concentration of
[01:00:46.940 --> 01:00:50.420]   talent, even in those startup cohorts is really high. And they
[01:00:50.420 --> 01:00:53.460]   don't have for job offers from big tech, they're not having
[01:00:53.460 --> 01:00:57.980]   like a Salesforce $300,000 offer coming in or a Google $400,000
[01:00:57.980 --> 01:01:00.500]   offer coming in. So I think this is going to be the best vintage
[01:01:00.500 --> 01:01:03.380]   of venture in our lifetimes. That's my personal belief. I
[01:01:03.380 --> 01:01:07.700]   invested in 100 companies this year. But I could be wrong, we
[01:01:07.700 --> 01:01:11.620]   should talk about the Google Gemini launch, Google just
[01:01:11.620 --> 01:01:15.140]   dropped their chat GPT killer. And from my perspective, it's
[01:01:15.140 --> 01:01:20.220]   often awesome. Just two quick videos here. It does have very
[01:01:20.220 --> 01:01:23.300]   strong multimodal mode, if you don't know what that is, just
[01:01:23.300 --> 01:01:26.540]   means you can use images, videos, text input and output.
[01:01:26.540 --> 01:01:29.220]   In this demo that you're seeing on the screen, if you're
[01:01:29.220 --> 01:01:33.060]   watching the show, they take a picture of a physics test that
[01:01:33.060 --> 01:01:35.900]   somebody took in handwriting, they find which answers are
[01:01:35.900 --> 01:01:39.820]   wrong, they explain it lots of reasoning going on in here. And
[01:01:39.820 --> 01:01:42.500]   obviously, the multimodal means you're seeing an image and
[01:01:42.500 --> 01:01:46.660]   you're getting text back. Second video they showed in the in the
[01:01:46.660 --> 01:01:49.260]   they launched a lot of stuff today with this Gemini brand.
[01:01:49.260 --> 01:01:54.180]   They're using the classic example of doing a party,
[01:01:54.180 --> 01:01:55.220]   planning a party.
[01:01:55.220 --> 01:01:57.300]   They use my likeness in the Google video. Wait, what's
[01:01:57.300 --> 01:02:00.180]   going here? It is there's there's a chubby chema. Sorry,
[01:02:00.540 --> 01:02:03.980]   can't body shape people. Sorry, folks. There's chubby chema.
[01:02:03.980 --> 01:02:06.700]   Please strike that. Oh my god, I shouldn't have said that.
[01:02:06.700 --> 01:02:08.700]   I thought Vinnie Lingham was fat chamath.
[01:02:08.700 --> 01:02:11.460]   Vinnie Lingham has claimed fat chamath. That was that's why I
[01:02:11.460 --> 01:02:15.020]   went for chubby. I didn't want to infringe on his IP. But
[01:02:15.020 --> 01:02:19.900]   anyway, no, I'm gonna get canceled. So in this video, the
[01:02:19.900 --> 01:02:22.340]   person asked to do a kid's party, what's very unique here
[01:02:22.340 --> 01:02:24.740]   is that it does the follow up questions, which is, you know,
[01:02:24.740 --> 01:02:26.300]   really interesting and understands reasoning and
[01:02:26.300 --> 01:02:30.900]   context, but it built a dynamic interface for this use case. And
[01:02:30.900 --> 01:02:36.300]   it did like a pinboard and a kind of Google s, task lists and
[01:02:36.300 --> 01:02:39.620]   KPIs and all this other nonsense. But behind all of
[01:02:39.620 --> 01:02:43.220]   this, in the Gemini exceptionalism, I think is that
[01:02:43.220 --> 01:02:46.380]   they did all these benchmarks against a bunch of, there's a
[01:02:46.380 --> 01:02:50.260]   bunch of tests and batteries of tests that language models use
[01:02:50.260 --> 01:02:53.900]   to prove how strong they are. And Google says Gemini beat GPT
[01:02:53.900 --> 01:02:58.020]   for the latest from open AI in 30 out of 32 benchmarks, this is
[01:02:58.020 --> 01:03:01.420]   going to come in three flavors, ultra pro and nano. That's
[01:03:01.420 --> 01:03:04.860]   basically cost and strength. And there's a lot more behind this.
[01:03:04.860 --> 01:03:07.620]   But based on what I'm seeing, in my opinion, I've been looking at
[01:03:07.620 --> 01:03:12.860]   this stuff every week with Cindy and looking at all of the
[01:03:12.860 --> 01:03:18.380]   latest and greatest, this feels like it is a leapfrog by about
[01:03:18.380 --> 01:03:21.700]   20 or 30%. If this is true, but freeberg, you looked at the
[01:03:21.700 --> 01:03:24.460]   original papers, what are your thoughts on the underpinnings? I
[01:03:24.460 --> 01:03:26.660]   talked about the UX and some of the reasoning, what are you
[01:03:26.660 --> 01:03:31.340]   seeing? And we'll consider this a flash on the fly science
[01:03:31.340 --> 01:03:33.780]   corner for all those Friedberg stands out there.
[01:03:33.780 --> 01:03:39.740]   I haven't read the whole 60 pages, but I looked at the
[01:03:39.740 --> 01:03:43.300]   performance charts, and it's pretty damn impressive. I feel I
[01:03:43.300 --> 01:03:47.340]   use the demo that I feel like you're interacting with data
[01:03:47.340 --> 01:03:49.420]   from Star Trek. Do you guys ever watch Star Trek?
[01:03:50.180 --> 01:03:53.700]   On your face? Your dream has come true from your child. I
[01:03:53.700 --> 01:03:55.700]   mean, I was like, this is a lifelong dream. I can finally
[01:03:55.700 --> 01:03:59.140]   have a chat with data. It's like conversational. It's
[01:03:59.140 --> 01:04:03.820]   predictable, in the sense that it kind of predicts the details
[01:04:03.820 --> 01:04:07.340]   that I might ask or might otherwise forget to ask fills
[01:04:07.340 --> 01:04:12.060]   them in. There's some, I think, really smart features of it. And
[01:04:12.060 --> 01:04:17.420]   I think it says a lot that Google truly does have the
[01:04:17.420 --> 01:04:22.940]   muscle to compete. And now is showing the way of us to do so
[01:04:22.940 --> 01:04:25.660]   that they're actually putting this out there, that they're
[01:04:25.660 --> 01:04:29.060]   willing to disrupt themselves cannibalize their own search
[01:04:29.060 --> 01:04:33.580]   business potentially, in a way that everyone's been worried
[01:04:33.580 --> 01:04:37.140]   they wouldn't be willing or able to do, they'll figure out a way
[01:04:37.140 --> 01:04:39.340]   to monetize it later. But they really are showing that they're
[01:04:39.340 --> 01:04:43.380]   willing to try and make the best product for users, which has
[01:04:43.380 --> 01:04:47.180]   always been a core mantra for Google from the origins of the
[01:04:47.180 --> 01:04:50.700]   business, focus on the user and all else will follow. And
[01:04:50.700 --> 01:04:52.620]   everyone's been saying the last couple years, they're too
[01:04:52.620 --> 01:04:55.420]   focused on profit, they're squeezing every nickel and dime
[01:04:55.420 --> 01:04:58.900]   out of every click, and showing that they're willing to put this
[01:04:58.900 --> 01:05:01.660]   out there says a lot about the strategic imperative of the
[01:05:01.660 --> 01:05:04.420]   board and the leadership there. So that makes a big difference.
[01:05:04.420 --> 01:05:06.780]   The product seems really good. The scoring data seems
[01:05:06.780 --> 01:05:10.500]   incredible against GPT for, which is I think the key
[01:05:10.500 --> 01:05:13.020]   benchmark, as we know, open AI has some new models that are
[01:05:13.020 --> 01:05:16.420]   coming to market. Here, let's pull up the table of results.
[01:05:16.700 --> 01:05:19.820]   But this shows Gemini's performance against GPT for
[01:05:19.820 --> 01:05:24.060]   using a number of well known metrics. I'll say that there is
[01:05:24.060 --> 01:05:29.020]   no business on earth that has more data than Google. YouTube
[01:05:29.020 --> 01:05:32.940]   is the richest data repository, digital data repository on
[01:05:32.940 --> 01:05:36.860]   earth. The YouTube data set gives Google an extraordinary
[01:05:36.860 --> 01:05:39.820]   advantage in training. And clearly, we're seeing that the
[01:05:39.820 --> 01:05:42.940]   results are getting on imaging and video here. So you know,
[01:05:42.940 --> 01:05:45.300]   big, big, big announcement for Google, I think it's definitely
[01:05:45.300 --> 01:05:48.700]   on earth, saying that they're in the game. And it's going to be
[01:05:48.700 --> 01:05:50.780]   pretty powerful to watch pretty, I think pretty important to
[01:05:50.780 --> 01:05:51.020]   watch.
[01:05:51.020 --> 01:05:55.980]   Saksis freebird said the cojones are on the table now Sundar has
[01:05:55.980 --> 01:05:58.300]   dropped the wave us. What's your take?
[01:05:58.300 --> 01:06:01.180]   I think it's pretty clear that Google's gonna be a major player
[01:06:01.180 --> 01:06:05.260]   in AI. But the question is, are they going to be dominant in AI?
[01:06:05.260 --> 01:06:07.620]   And I think one of the points that our friend backers are
[01:06:07.620 --> 01:06:11.260]   makes that's well taken about Google's market position is that
[01:06:11.260 --> 01:06:14.380]   if you look at their position and search, which is gradually
[01:06:14.380 --> 01:06:18.780]   being replaced by AI, they're absolutely dominant in search.
[01:06:18.780 --> 01:06:24.340]   So even if they turn out to be good or great, in AI, their AI
[01:06:24.340 --> 01:06:28.020]   franchises is never going to be as dominant as their search
[01:06:28.020 --> 01:06:32.100]   franchise was in that market. And so to the extent that AI is
[01:06:32.100 --> 01:06:35.780]   replacing search, and I think we're seeing that more and more
[01:06:35.780 --> 01:06:38.540]   right, if you can get the AI just to give you the answer,
[01:06:38.540 --> 01:06:41.620]   instead of a list of 10 blue links, that's a better user
[01:06:41.620 --> 01:06:44.860]   experience. So I think as more and more searches get replaced
[01:06:44.860 --> 01:06:47.940]   with AI, it's just impossible that they're going to maintain
[01:06:47.940 --> 01:06:52.580]   that same dominant share. Moreover, it's really unclear how
[01:06:52.580 --> 01:06:56.620]   you monetize those, let's call them AI searches, where it just
[01:06:56.620 --> 01:07:00.660]   gives you the answer, because nobody wants to get three ad
[01:07:00.660 --> 01:07:03.300]   links up at the top of their answer, no one's going to click
[01:07:03.300 --> 01:07:05.940]   on those. So I think look, Google is gonna be a player in
[01:07:05.940 --> 01:07:10.260]   AI. But as AI displaces search, it's going to be a real
[01:07:10.260 --> 01:07:11.780]   challenge for them as a company, I think,
[01:07:11.780 --> 01:07:15.380]   I have the opposite position, I'll explain sex. While I do
[01:07:15.380 --> 01:07:18.460]   think you're right, their dominance won't be the same.
[01:07:18.460 --> 01:07:24.340]   Having used the Google flights, AI integration, Google shopping
[01:07:24.340 --> 01:07:27.020]   and integration that's in bar right now, which is very like
[01:07:27.020 --> 01:07:31.300]   1.0, or even point one, I think the number of searches or the
[01:07:31.300 --> 01:07:33.740]   number of interactions, the number of queries, let's call
[01:07:33.740 --> 01:07:38.380]   them questions asked, is going to go like 10 2050 100x, I think
[01:07:38.380 --> 01:07:41.260]   they're all going to be talking to their eyes all day long. And
[01:07:41.260 --> 01:07:43.900]   where I think you might be wrong is I think actually, the clicks
[01:07:43.900 --> 01:07:47.220]   are going to fit in certain categories perfectly into the
[01:07:47.220 --> 01:07:50.740]   response. So in this birthday one, if you had a bunch of
[01:07:50.740 --> 01:07:54.420]   ideas of what you could click on to purchase, if it said, Hey,
[01:07:54.420 --> 01:07:57.020]   great idea for the birthday, did you think about these hats? Did
[01:07:57.020 --> 01:07:59.260]   you think about these pinatas? Did you think about these places
[01:07:59.260 --> 01:08:02.820]   to get cake, and those were all paid and AI inform them because
[01:08:02.820 --> 01:08:05.940]   you want to do an animal based jungle party, and it showed you
[01:08:05.940 --> 01:08:12.260]   it's going to make unbelievable ad targeting that is right into
[01:08:12.260 --> 01:08:15.060]   your planning, hey, get these hats here, get this, get this
[01:08:15.060 --> 01:08:17.820]   flight here, book this restaurant, I think it could be a
[01:08:17.820 --> 01:08:22.140]   goldmine. And I think the the clickstream and the ad network
[01:08:22.140 --> 01:08:25.660]   is going to fit perfectly into it. Same thing with those
[01:08:25.660 --> 01:08:29.660]   questions being asked, you know, hey, do you want to get a math
[01:08:29.660 --> 01:08:33.340]   tutor? Do you want to buy this book, etc. So I am going to take
[01:08:33.340 --> 01:08:35.460]   the other side of it. Chamath, where do you land? Are you
[01:08:35.460 --> 01:08:38.540]   short, long or neutral Google based on this?
[01:08:38.540 --> 01:08:43.940]   I think that there's two important things to notice about
[01:08:43.940 --> 01:08:48.780]   this. The first is who is in charge of this project. And this
[01:08:48.780 --> 01:08:52.260]   is I think, after they did that reorg, the most important person
[01:08:52.260 --> 01:08:57.860]   in all of this is Jeff Dean, who, if you look back, is the
[01:08:57.860 --> 01:09:00.340]   one of the most preeminent technical lights, frankly, of
[01:09:00.340 --> 01:09:05.300]   the internet, but within Google is just a giant, right? So
[01:09:05.300 --> 01:09:09.140]   TensorFlow, MapReduce, BigTable, Spanner, the guy is just an
[01:09:09.140 --> 01:09:13.380]   absolute animal. He's proven an ability to not just
[01:09:13.380 --> 01:09:16.820]   conceptualize big ideas, but then get them to market in a way
[01:09:16.820 --> 01:09:19.900]   that can work at scale. Right? That's the first thing. The
[01:09:19.900 --> 01:09:22.820]   second thing is that this Gemini is a collaboration between
[01:09:22.820 --> 01:09:25.700]   DeepMind for the first time and Google Research and a bunch of
[01:09:25.700 --> 01:09:28.180]   other people at Google. So I think Friedberg mentioned this
[01:09:28.180 --> 01:09:32.060]   before, the test for Google is not their technical capacity,
[01:09:32.060 --> 01:09:35.540]   but their ability to organize everybody and get them to row in
[01:09:35.540 --> 01:09:41.100]   the same direction. So I think that that's, that's really
[01:09:41.100 --> 01:09:46.740]   important. My takeaway is what I kind of put out on Twitter,
[01:09:46.740 --> 01:09:51.700]   which is that I think all of this is one more brick in the
[01:09:51.700 --> 01:09:57.420]   wall on this theme of commoditization. So we have all
[01:09:57.420 --> 01:09:59.820]   of these really interesting foundational models. If you just
[01:09:59.820 --> 01:10:03.420]   look back a little bit, Llama 2's advances have been pretty
[01:10:03.420 --> 01:10:09.820]   amazing. Out of the UAE, Abu Dhabi, the government showed
[01:10:09.820 --> 01:10:13.420]   some Falcon, which showed some really interesting promise.
[01:10:13.420 --> 01:10:18.820]   Obviously, OpenAI is doing some great work with GPT-4 and GPT-5.
[01:10:18.820 --> 01:10:23.860]   Now you see Gemini and the results that they're generating.
[01:10:25.100 --> 01:10:27.260]   There's going to be a proliferation of foundational
[01:10:27.260 --> 01:10:33.540]   models, the cost of those models will go to zero. And so why is
[01:10:33.540 --> 01:10:36.060]   why is that an important thing? Well, one, it's good for the
[01:10:36.060 --> 01:10:42.060]   ecosystem. Two, it's really good for developers. And three, it
[01:10:42.060 --> 01:10:44.500]   allows us to then figure out where the real value is going to
[01:10:44.500 --> 01:10:47.740]   be made. And I think the value is in taking these models and
[01:10:47.740 --> 01:10:51.580]   wrapping them with cheap, abstracted hardware, right? You
[01:10:51.580 --> 01:10:56.340]   can't have an economy get built in AI when you have year long
[01:10:56.340 --> 01:11:00.220]   waiting lists for H100s and A100s from NVIDIA. That's not
[01:11:00.220 --> 01:11:04.420]   possible. So that entire layer as well will get commoditized. So
[01:11:04.420 --> 01:11:08.100]   the folks that are the AWSs, the Azures and the GCPs of the world
[01:11:08.100 --> 01:11:13.060]   or these next generation entrants, who are building AI
[01:11:13.060 --> 01:11:16.300]   clouds, those folks, I think will make money and then the
[01:11:16.300 --> 01:11:20.180]   apps will make money. So I think it's a very good thing. I think
[01:11:20.180 --> 01:11:23.300]   that you don't want a lot of the lock in that NVIDIA was trying
[01:11:23.300 --> 01:11:25.380]   to create, they were trying to create essentially a walled
[01:11:25.380 --> 01:11:28.460]   garden where you have to use CUDA in order to basically
[01:11:28.460 --> 01:11:32.660]   compile to these, these miles to their chips. It's going to break
[01:11:32.660 --> 01:11:35.860]   all of that. So I'm generally quite constructive. I think that
[01:11:35.860 --> 01:11:40.380]   this is a really good step in democratizing this whole thing,
[01:11:40.380 --> 01:11:45.260]   and letting the value agreed to the ends. It's a barbell,
[01:11:45.260 --> 01:11:48.220]   infrastructure providers and app builders. That's my best guess
[01:11:48.220 --> 01:11:49.820]   of where money gets made here.
[01:11:49.820 --> 01:11:54.300]   All right, Adobe's $20 billion acquisition of Figma is stalled
[01:11:54.300 --> 01:11:58.820]   right now. UK CMA stands for competition and markets
[01:11:58.820 --> 01:12:03.540]   authority. It's effectively blocked this acquisition for a
[01:12:03.540 --> 01:12:07.980]   couple of obvious reasons. One reduces innovation to it
[01:12:07.980 --> 01:12:10.740]   eliminates competition between two top competitors and product
[01:12:10.740 --> 01:12:14.140]   design. And three removes Figma as a threat to Adobe's
[01:12:14.140 --> 01:12:19.940]   Photoshop in Illustrator products. CMI a mentioned some
[01:12:19.940 --> 01:12:23.620]   potential remedies divesting of overlapping operations in each
[01:12:23.620 --> 01:12:28.340]   market where the deal could cause less competition, or just
[01:12:28.340 --> 01:12:32.460]   prohibiting the merger entirely feels like that's what's going
[01:12:32.460 --> 01:12:37.060]   to happen. And also actually, I have to take a sharp right,
[01:12:37.060 --> 01:12:38.180]   there was a peak Zerp deal.
[01:12:38.180 --> 01:12:41.860]   I have to take issue with you said that they are doing this
[01:12:41.860 --> 01:12:45.780]   for obvious reasons. I don't think these reasons are obvious
[01:12:45.780 --> 01:12:47.660]   in the sense that I don't think I don't think they speak for
[01:12:47.660 --> 01:12:51.620]   themselves. I think they have to be defended. And I don't think
[01:12:51.620 --> 01:12:52.660]   these are good reasons.
[01:12:52.660 --> 01:12:57.020]   Oh, yeah, no, I, the I'm when I say obvious reasons, I'm not
[01:12:57.020 --> 01:13:00.700]   endorsing them. I'm just saying the standard reasons of lack of
[01:13:00.700 --> 01:13:05.860]   competition, and consolidation of competitors. So but yeah,
[01:13:05.860 --> 01:13:10.740]   expand on your point, and you think it should not be stopped
[01:13:10.780 --> 01:13:15.260]   this merger? Well, first of all, this merger was originally
[01:13:15.260 --> 01:13:19.460]   announced, I think back on September 15 of 2022. Over a
[01:13:19.460 --> 01:13:25.020]   year ago, what is that? That's almost 15 months ago. Yeah. So
[01:13:25.020 --> 01:13:28.420]   this is a ridiculous amount of time for regulators to take to
[01:13:28.420 --> 01:13:30.420]   figure out whether they're going to approve the deal. That's no
[01:13:30.420 --> 01:13:33.540]   good for anybody. I think businesses, whether you're
[01:13:33.540 --> 01:13:36.780]   Adobe, whether you're Figma have a right to have these questions
[01:13:36.780 --> 01:13:40.060]   answered much more quickly. So what are the regulators doing?
[01:13:40.100 --> 01:13:43.900]   So that's point number one. Point number two is that it's
[01:13:43.900 --> 01:13:47.300]   mostly the UK regulator, which is called the CMA or competition
[01:13:47.300 --> 01:13:51.180]   and markets authority. They're the ones who are dragging their
[01:13:51.180 --> 01:13:55.180]   feet and holding this up. So figment Adobe have to get the
[01:13:55.180 --> 01:13:58.820]   approval of three different regulatory bodies, they have to
[01:13:58.820 --> 01:14:02.060]   get approval in the United States, from I think the DOJ,
[01:14:02.060 --> 01:14:06.460]   they have to get approval from the EU with Brussels. And now
[01:14:06.460 --> 01:14:10.140]   because of thanks to Brexit, they also have to get approved
[01:14:10.140 --> 01:14:15.700]   by the UK. And to me, it's a little crazy that one country's,
[01:14:15.700 --> 01:14:18.940]   you know, competition authority, the UK, which is not in the
[01:14:18.940 --> 01:14:22.620]   grand scheme of things, that big a market can hold up this entire
[01:14:22.620 --> 01:14:25.780]   deal. You know, it should be faster, of course, right? They
[01:14:25.780 --> 01:14:29.020]   should not just start number I question whether like one
[01:14:29.020 --> 01:14:32.860]   country, the UK should be able to hold up a deal if the US and
[01:14:32.860 --> 01:14:36.300]   the EU approve it. And one thing I would say to startups is,
[01:14:36.580 --> 01:14:41.180]   if the CMA is going to start holding up deals for a bunch of
[01:14:41.180 --> 01:14:44.540]   novel reasons, meaning, you know, reasons that haven't
[01:14:44.540 --> 01:14:47.700]   previously been articulated before in an antitrust law, why
[01:14:47.700 --> 01:14:50.860]   in the world do you would you want to create nexus with the UK?
[01:14:50.860 --> 01:14:53.780]   I think this pertains to all the startup ecosystem because look,
[01:14:53.780 --> 01:14:56.540]   I remember when I was doing Yammer, we decided to open an
[01:14:56.540 --> 01:14:59.900]   office in Europe, and we decided to settle in London, and we
[01:14:59.900 --> 01:15:02.980]   created a pretty big office in London, we thought that was the
[01:15:02.980 --> 01:15:06.820]   best place for a startup to locate. If you had told me at
[01:15:06.820 --> 01:15:11.460]   the time, that that was subject our acquisition by Microsoft to
[01:15:11.460 --> 01:15:14.740]   the CMA over there, and that they would take some novel
[01:15:14.740 --> 01:15:17.980]   interpretation and hold up my deal. There's no way I would
[01:15:17.980 --> 01:15:21.580]   have wanted to open an office in the UK. So let's be clear about
[01:15:21.580 --> 01:15:25.060]   that. Now, I want to move on just quickly to the argument,
[01:15:25.060 --> 01:15:29.020]   the CMA is making and I do think it's a novel argument. They're
[01:15:29.020 --> 01:15:33.940]   not saying that Adobe and Figma are competitive today. And
[01:15:33.940 --> 01:15:36.300]   actually, I think they are operating in different markets.
[01:15:36.300 --> 01:15:41.860]   Figma is a product for web designers, and web developers.
[01:15:41.860 --> 01:15:46.140]   And the end state of a figment design is code. If you look at
[01:15:46.140 --> 01:15:49.700]   Adobe's products like Photoshop, the end state is marketing
[01:15:49.700 --> 01:15:53.340]   collateral. It's it's a marketing design product. Nobody
[01:15:53.340 --> 01:15:58.980]   uses Figma to create marketing collateral, they use Photoshop
[01:15:59.260 --> 01:16:04.900]   and nobody who's using Photoshop is using that to build websites.
[01:16:04.900 --> 01:16:09.260]   Okay, these are in practice pretty distinct markets. And I
[01:16:09.260 --> 01:16:13.420]   think the CMA has conceded that they're distinct and separate
[01:16:13.420 --> 01:16:17.260]   markets. But what the CMA is trying to say is that at some
[01:16:17.260 --> 01:16:21.980]   point in the future, if we block this deal, Figma might compete,
[01:16:21.980 --> 01:16:27.140]   might compete with Adobe, they might create a competitor to
[01:16:27.140 --> 01:16:31.260]   Photoshop. And that is a bogus rationale for blocking a deal.
[01:16:31.260 --> 01:16:34.540]   Because first of all, I think we all know that Figma has no
[01:16:34.540 --> 01:16:37.500]   interest in competing with Photoshop, they're not going to
[01:16:37.500 --> 01:16:40.700]   compete, they're much more interested in AI, they're much
[01:16:40.700 --> 01:16:44.060]   more interested in doing things like prompt to design to code,
[01:16:44.060 --> 01:16:47.780]   they're not interested in building, you know, a Photoshop
[01:16:47.780 --> 01:16:50.100]   competitor. And there's no reason to believe that they
[01:16:50.100 --> 01:16:53.340]   would do that. Moreover, that is not an objective standard.
[01:16:53.340 --> 01:16:56.660]   Think about it. If you can block a deal on the grounds that
[01:16:56.660 --> 01:16:59.940]   these two companies don't compete today, but might one day
[01:16:59.940 --> 01:17:03.660]   compete in the future, it gives the regulators a veto over any
[01:17:03.660 --> 01:17:06.420]   deal. And that is not the way antitrust is supposed to work.
[01:17:06.420 --> 01:17:09.460]   The way that antitrust is historically worked is you
[01:17:09.460 --> 01:17:13.740]   define what market these companies are in, and you add
[01:17:13.740 --> 01:17:17.060]   their market share together, if they're both in the same market
[01:17:17.060 --> 01:17:22.020]   to see if it would create an undue monopoly or oligopoly
[01:17:22.020 --> 01:17:25.260]   something some dynamic like that it was a market share test,
[01:17:25.260 --> 01:17:29.340]   which is an objective test. This is not an objective test. This
[01:17:29.340 --> 01:17:31.900]   is a regular saying, Hmm, you know, we know you don't compete
[01:17:31.900 --> 01:17:34.980]   today, but like one day in the future, you might, that is
[01:17:34.980 --> 01:17:38.380]   bogus. So if you allow the CMA to block this deal on that
[01:17:38.380 --> 01:17:41.420]   ground, they can block any deal for any reason. And then on top
[01:17:41.420 --> 01:17:45.180]   of it, they've taken 15 months to come down with this opinion.
[01:17:45.180 --> 01:17:48.460]   I think this is gonna have a very chilling effect on M&A
[01:17:48.460 --> 01:17:52.260]   activity for for not a good reason, for not a good reason.
[01:17:52.260 --> 01:17:54.620]   And that is the last thing the startup ecosystem needs right
[01:17:54.620 --> 01:17:55.140]   now.
[01:17:55.140 --> 01:18:02.300]   I'm going to agree about the time, I'm going to agree that we
[01:18:02.300 --> 01:18:05.660]   should let a little more M&A happen. I'll disagree. Adobe has
[01:18:05.660 --> 01:18:09.060]   a product XD competes directly with Figma. And then I've gotten
[01:18:09.060 --> 01:18:13.620]   multiple designers who have included me in Figma designs for
[01:18:13.620 --> 01:18:16.500]   things that are other than interfaces. They're using it for
[01:18:16.500 --> 01:18:19.980]   decks, they're using it for marketing collateral. And if you
[01:18:19.980 --> 01:18:23.540]   go look at figmas templates offering, they are all
[01:18:23.540 --> 01:18:26.900]   Photoshop, Illustrator key functions. So in the market,
[01:18:26.900 --> 01:18:29.220]   even though the products were not designed as competitors,
[01:18:29.220 --> 01:18:32.460]   designers are starting with Figma for many design projects
[01:18:32.460 --> 01:18:35.260]   in my direct experience and by looking at the templates. So
[01:18:35.260 --> 01:18:36.460]   I'll disagree on that third point.
[01:18:36.460 --> 01:18:40.420]   Well, hold on, I gotta do a fact check on one thing. You're right
[01:18:40.420 --> 01:18:43.540]   that Adobe had a competitive product to Figma called XD, they
[01:18:43.540 --> 01:18:48.220]   shut it down. They shut it down. Yeah, it was a failure. So they
[01:18:48.220 --> 01:18:52.900]   are out of the market for a web design tool. They're out. So
[01:18:52.900 --> 01:18:55.540]   that argument no longer exists. And I don't know if they shut it
[01:18:55.540 --> 01:18:58.060]   down because of this deal or because it was failing anyway.
[01:18:58.060 --> 01:19:02.780]   But they solve that problem. Now with respect to these use cases
[01:19:02.780 --> 01:19:06.460]   where Okay, yeah, you're talking anecdotally, Jason about, you've
[01:19:06.460 --> 01:19:11.300]   seen some web designer, no, I'm talking, go look at the
[01:19:11.300 --> 01:19:13.820]   templates. I just put the link in there. It's still anecdotal.
[01:19:13.820 --> 01:19:16.300]   It's not based on a market share test. If you want to make this
[01:19:16.300 --> 01:19:20.380]   argument that Figma and Photoshop are competitive
[01:19:20.380 --> 01:19:23.340]   products, break it down in terms of market share. That's my
[01:19:23.340 --> 01:19:26.300]   point, add up figmas market share in the market for
[01:19:26.300 --> 01:19:29.180]   marketing collateral, and see if that would create undue
[01:19:29.180 --> 01:19:32.300]   concentration. Fair enough. My objection is that they're not
[01:19:32.300 --> 01:19:36.260]   basing this decision. If it can even be called a decision, I
[01:19:36.260 --> 01:19:38.900]   think it's more like just concerns and dragging their
[01:19:38.900 --> 01:19:43.620]   feet. But they are basing their concerns on something that's
[01:19:43.620 --> 01:19:47.300]   unquantifiable. And I do think that anti stress decisions
[01:19:47.300 --> 01:19:51.460]   should be quantifiable. The concerning thing here is that
[01:19:51.460 --> 01:19:54.580]   this is on the heels of Activision and Microsoft, which
[01:19:54.580 --> 01:19:58.020]   was equally protracted and drawn out. I don't I think it's bad
[01:19:58.020 --> 01:20:03.260]   for capital markets, when deals that are offered up just linger
[01:20:03.260 --> 01:20:08.740]   for 1518 months. I don't think that that's healthy. It causes a
[01:20:08.740 --> 01:20:13.820]   lot of pause amongst investors. And it probably freezes both
[01:20:13.820 --> 01:20:18.580]   Adobe and Figma from investing the way that they would if they
[01:20:18.580 --> 01:20:20.900]   knew that this thing was voted up or down in three months or
[01:20:20.900 --> 01:20:24.780]   whatever. So I think that I totally agree with you that
[01:20:24.780 --> 01:20:28.900]   there needs to be an SLA around these things. And you can't take
[01:20:28.900 --> 01:20:34.980]   this much time. I breezed through the CMA report. My gosh,
[01:20:34.980 --> 01:20:39.220]   it's 400 pages, which is like, that's insane. A 400 page
[01:20:39.220 --> 01:20:42.380]   document is like it's a little outlandish. But I wanted to call
[01:20:42.380 --> 01:20:47.100]   out two parts of that document. One is in support, sacks of what
[01:20:47.100 --> 01:20:50.100]   you said, Nick, you can just throw it up here. What they said
[01:20:50.100 --> 01:20:52.460]   was that in assessing the competitive effects of the
[01:20:52.460 --> 01:20:56.100]   merger, we must decide whether there is an expectation, i.e.
[01:20:56.100 --> 01:20:59.460]   more than 50% chance that the merger will result in diminished
[01:20:59.460 --> 01:21:03.460]   competition. Now, that's like a little nuts, because David, as
[01:21:03.460 --> 01:21:06.420]   you said, it's like, we're going to take an expected probability
[01:21:06.420 --> 01:21:09.700]   and a guess into the future about what we think will happen.
[01:21:09.740 --> 01:21:13.900]   And I think that that's not a fair way of doing business. I
[01:21:13.900 --> 01:21:16.220]   think that you have to look at what will happen when this
[01:21:16.220 --> 01:21:20.500]   happens. And judge on its face. You can't say, well, also, by
[01:21:20.500 --> 01:21:23.620]   the way, I expect that you guys will be intelligent and really
[01:21:23.620 --> 01:21:25.980]   execute. So that'll just increase the odds. That's not
[01:21:25.980 --> 01:21:29.620]   right. That's, that's what business is. So if I had to
[01:21:29.620 --> 01:21:31.780]   steel man, the pro figma side, I would say that that's
[01:21:31.780 --> 01:21:34.940]   unreasonable. The second side on the pro figma side is there's
[01:21:34.940 --> 01:21:38.460]   this long point here, I think it's like number 27 or 28 in
[01:21:38.460 --> 01:21:41.580]   this document. And this is what's crazy. It's it basically
[01:21:41.580 --> 01:21:45.860]   says, like, hey, we went through document discovery, we found
[01:21:45.860 --> 01:21:50.700]   some emails that basically said, by Adobe, that said, we did
[01:21:50.700 --> 01:21:55.020]   market analyses, we didn't think we were doing very well. And I
[01:21:55.020 --> 01:21:59.140]   think it's important to note for the CMA that this is what 100
[01:21:59.140 --> 01:22:03.060]   years of MBA classes have taught people to do. I mean, you teach
[01:22:03.060 --> 01:22:07.220]   executives that go work at companies to do what's called a
[01:22:07.220 --> 01:22:10.500]   SWOT analysis to figure out what are the risks and opportunities
[01:22:10.500 --> 01:22:14.980]   for your business and then to go and invest to fix them. That's
[01:22:14.980 --> 01:22:18.540]   capitalism. And that's business theory. And we've taught
[01:22:18.540 --> 01:22:22.340]   executives at every single company to do this. That can't
[01:22:22.340 --> 01:22:25.740]   be illegal. Meaning to use your brain inside of a business to
[01:22:25.740 --> 01:22:28.740]   realize that what you did isn't working. So that would that's
[01:22:28.740 --> 01:22:31.340]   also I would say, sacks in support of what you're saying,
[01:22:31.340 --> 01:22:36.060]   which is, it's taking too long. It's speculative. And you're
[01:22:36.060 --> 01:22:38.220]   punishing people for actually being good business people. And
[01:22:38.220 --> 01:22:40.860]   I don't think that makes sense. What's the number six months,
[01:22:40.860 --> 01:22:45.540]   just to add to that, you know, again, like an important overlay
[01:22:45.540 --> 01:22:50.820]   here is that the CMA is the UK regulator, and they're the
[01:22:50.820 --> 01:22:55.020]   smallest market, the GDP of the UK is 3 trillion, the GDP of the
[01:22:55.020 --> 01:22:59.100]   US 16 trillion, the GDP of the US is, I forget, it's in the
[01:22:59.100 --> 01:23:04.300]   2025 trillion range. So you've got the toughest regulator, who
[01:23:04.300 --> 01:23:06.340]   is coming up with no novel legal theory,
[01:23:06.340 --> 01:23:10.620]   I think it's worth exploring that these regulators, I think,
[01:23:10.620 --> 01:23:15.500]   are working in conjunction. And those fingerprints looked a
[01:23:15.500 --> 01:23:18.020]   little bit more obvious. I'm not playing conspiracy theorists,
[01:23:18.020 --> 01:23:24.260]   but it looks like the EU, the FTC, and the CMA did work
[01:23:24.260 --> 01:23:27.540]   together. I don't know how officially or not in Microsoft
[01:23:27.540 --> 01:23:31.860]   Activision, it looked relatively coordinated. I suspect that it
[01:23:31.860 --> 01:23:34.180]   stands to reason that they're in touch. And they talk about
[01:23:34.180 --> 01:23:37.340]   these deals and their combined perspectives. I don't know how
[01:23:37.340 --> 01:23:39.780]   else you just generate a 400 page report with this kind of
[01:23:39.780 --> 01:23:43.020]   specificity, unless there's some amount of collaboration and,
[01:23:43.020 --> 01:23:45.780]   and sharing, which, by the way, I think does make sense. I think
[01:23:45.780 --> 01:23:49.900]   it does make sense to coordinate your point of view. But I think
[01:23:49.900 --> 01:23:51.220]   I agree with you, David, that
[01:23:51.220 --> 01:23:55.020]   we don't know that for sure. I mean, like, all I know is that
[01:23:55.020 --> 01:23:58.380]   in the press reports, it's been about the CMA, it's possible
[01:23:58.380 --> 01:24:01.980]   that the EU or I don't think us will do this, because that would
[01:24:01.980 --> 01:24:04.980]   just be like inventing a wholly new antitrust law, right? Where
[01:24:04.980 --> 01:24:09.060]   I understand, I'm just saying that my point of view is that as
[01:24:09.060 --> 01:24:12.700]   a business owner, my response to this would be to gatekeep the
[01:24:12.700 --> 01:24:16.620]   app in these geographies, so that I don't create a nexus if I
[01:24:16.620 --> 01:24:18.940]   ever get bought. Bingo. That's my point. That's exactly my
[01:24:18.940 --> 01:24:22.140]   point is that the smallest market is creating the most
[01:24:22.140 --> 01:24:26.780]   problems for this merger. So assuming they're kind of on
[01:24:26.780 --> 01:24:29.700]   their own in this, and the EU doesn't just copy it, if you if
[01:24:29.700 --> 01:24:32.420]   you're right, if they copy it, then figment Adobe have a bigger
[01:24:32.420 --> 01:24:35.420]   problem. But I think that's what's going to happen. Right?
[01:24:35.420 --> 01:24:39.220]   Then maybe the EU does copy. But right now, the CMA is way ahead
[01:24:39.220 --> 01:24:42.740]   of any other regulator in terms of a novel theory. So So what
[01:24:42.740 --> 01:24:44.820]   I'm saying is, if you're a company, why would you subject
[01:24:44.820 --> 01:24:47.500]   yourself to green when it's so easy to avoid their market? I
[01:24:47.500 --> 01:24:51.260]   think I think it fundamentally hurts UK productivity over the
[01:24:51.260 --> 01:24:55.300]   long run, because I don't see how companies if they can't a get a
[01:24:55.300 --> 01:25:00.340]   reasonable SLA for a response, and then be get a reasonable
[01:25:00.340 --> 01:25:04.300]   document, that's not going to require $50 million of, of
[01:25:04.300 --> 01:25:08.020]   lawyers and consultants to read. To do business in a country
[01:25:08.020 --> 01:25:11.660]   just goes down the incentives to do business. So now if you
[01:25:11.660 --> 01:25:16.000]   steelman, the other side, I actually think it's very
[01:25:16.000 --> 01:25:19.420]   difficult to steel man, why this is bad for competition. I think
[01:25:19.420 --> 01:25:22.180]   the only steel man is more from the economic shareholder
[01:25:22.180 --> 01:25:24.300]   perspective of Adobe, which is good, they have paid a different
[01:25:24.300 --> 01:25:27.300]   price. What does that because I think it's a mixture of cash and
[01:25:27.300 --> 01:25:30.780]   stock. So that's changed because Adobe's rallied a lot. And is
[01:25:30.780 --> 01:25:34.580]   that price worth it? But that's, again, not a reason to use a
[01:25:34.580 --> 01:25:40.060]   regulator to run a deal to the ground, right? Adobe should just
[01:25:40.060 --> 01:25:42.700]   man up and talk to Dylan and say, here's the new price.
[01:25:42.700 --> 01:25:44.100]   Otherwise, here's a billion dollars.
[01:25:44.100 --> 01:25:47.260]   I don't think Adobe is driving in that way. I mean, by all
[01:25:47.260 --> 01:25:50.060]   accounts, Sigma as a business is still doing very well, even if
[01:25:50.060 --> 01:25:53.620]   they paid too high a price 15 months ago, they've grown,
[01:25:53.660 --> 01:25:56.420]   they've partially grown into that valuation already. I don't
[01:25:56.420 --> 01:25:59.540]   think Adobe is driving this. I really think that the CMA is
[01:25:59.540 --> 01:26:02.460]   driving this. I think there's a regulator who wants to pioneer a
[01:26:02.460 --> 01:26:06.420]   novel legal theory. And in a weird way, I mean, it's not. Have
[01:26:06.420 --> 01:26:08.780]   you ever seen like a pack of dogs where you've got like a
[01:26:08.780 --> 01:26:12.740]   Great Dane and a Doberman and then a Chihuahua and the Chihuahua
[01:26:12.740 --> 01:26:17.140]   is trying to leave the pack. The CMA is like the dog and it's
[01:26:17.140 --> 01:26:19.780]   like barking the loudest and trying to shepherd all the other
[01:26:19.780 --> 01:26:24.940]   dogs. You got a yappy little Chihuahua here. The issue that
[01:26:24.940 --> 01:26:28.980]   you bring up is a great day and then the EU is a is a is a big
[01:26:28.980 --> 01:26:34.620]   dog. And yeah, but if the EU and the United States follow suit,
[01:26:34.620 --> 01:26:38.340]   it will, it's just death by 1000 cuts, meaning it will require a
[01:26:38.340 --> 01:26:44.060]   Brad Smith like character inside of this company, who can go and
[01:26:44.060 --> 01:26:47.660]   work with regulators to really get it done. And this is the
[01:26:47.660 --> 01:26:52.900]   brilliance of of him at Microsoft is it when you look at
[01:26:52.900 --> 01:26:57.220]   the track record of his ability post this consent decree to get
[01:26:57.220 --> 01:27:01.420]   deals done inside of Microsoft. It's truly incredible. There is
[01:27:01.420 --> 01:27:03.900]   nothing that they've really tried to buy, whether it's
[01:27:03.900 --> 01:27:09.260]   nuance or whether it's Mojang, or whether it's GitHub.
[01:27:09.260 --> 01:27:15.020]   Activision, they've linked in, they've got around the table,
[01:27:15.060 --> 01:27:18.740]   do we really want to create an economic system where whether a
[01:27:18.740 --> 01:27:21.220]   deal gets through is completely arbitrary, because there's no
[01:27:21.220 --> 01:27:23.980]   longer a quantitative test, the regulators can just pause it,
[01:27:23.980 --> 01:27:26.020]   that at some point in the future, these companies may be
[01:27:26.020 --> 01:27:29.220]   competitive. No, the and it takes and furthermore, in order
[01:27:29.220 --> 01:27:33.660]   to get past the regulators who have a completely subjective
[01:27:33.660 --> 01:27:36.620]   standard, you need like a political genius like a Brad
[01:27:36.620 --> 01:27:41.100]   Smith. I mean, that is like the definition of crony capitalism,
[01:27:41.100 --> 01:27:44.340]   right is that you get your deal done if you got a Brad Smith,
[01:27:44.540 --> 01:27:47.300]   and you don't get it done. If you're a startup like Figma,
[01:27:47.300 --> 01:27:49.020]   that's not the system we want to be in.
[01:27:49.020 --> 01:27:53.380]   Absolutely not. Three important things. One future competition
[01:27:53.380 --> 01:27:57.220]   is a stupid test. Number two, just put six months on it. It's
[01:27:57.220 --> 01:28:00.380]   not even future. It's their assessment of the probability of
[01:28:00.380 --> 01:28:04.540]   future competition, which is just dumb. It's this is pre cogs in
[01:28:04.540 --> 01:28:05.500]   minority report,
[01:28:05.500 --> 01:28:10.860]   Figma could sign an affidavit today, saying that we're not
[01:28:10.860 --> 01:28:13.500]   making a list. We're not building it. Yeah, it's not. It's
[01:28:13.500 --> 01:28:16.260]   not our roadmap. It's not even an affidavit. It's you could go
[01:28:16.260 --> 01:28:20.740]   through, you could conduct discovery on the question of
[01:28:20.740 --> 01:28:24.020]   whether Figma has ever even discussed internally, whether
[01:28:24.020 --> 01:28:26.140]   they should compete with Photoshop, right? Because you
[01:28:26.140 --> 01:28:28.780]   don't just launch a Photoshop competitor out of the blue, you
[01:28:28.780 --> 01:28:32.100]   probably discuss it for a while. So they could conduct discovery
[01:28:32.100 --> 01:28:36.140]   on that question. I guarantee you Figma does not have robust
[01:28:36.140 --> 01:28:39.340]   conversations in discovery about competing with Photoshop. That's
[01:28:39.340 --> 01:28:40.620]   not where their interest is.
[01:28:41.460 --> 01:28:44.260]   And then also, they should be just have a six, they should
[01:28:44.260 --> 01:28:48.500]   have a six month clock to do this. And then if I'm Adobe and
[01:28:48.500 --> 01:28:52.620]   Figma, I would say, I would pull a Zuck when they came out Zuck
[01:28:52.620 --> 01:28:54.980]   and said, you have to pay for news in Australia, you have to
[01:28:54.980 --> 01:28:58.180]   pay for news in Canada. Remember these two government
[01:28:58.180 --> 01:29:01.260]   overreaches, that you can even put a link to a news story.
[01:29:01.260 --> 01:29:03.300]   He's like, okay, fine, we're just going to not include links
[01:29:03.300 --> 01:29:06.060]   to the New York Times and feeds that's not allowed. They should
[01:29:06.060 --> 01:29:10.260]   just say anybody who's in the UK, you can no longer we're
[01:29:10.260 --> 01:29:11.700]   going to look at your IP addresses, we're going to look
[01:29:11.700 --> 01:29:14.380]   at your address, you can't buy Figma, you can't buy Adobe,
[01:29:14.380 --> 01:29:16.980]   we're going through with this. So if you don't want consumers
[01:29:16.980 --> 01:29:19.140]   to have this product, you don't have to have it. And then people
[01:29:19.140 --> 01:29:21.620]   have to get a VPN to use these products, like I would call
[01:29:21.620 --> 01:29:25.420]   their bluff on it. Kind of overreaching. I agree. Okay.
[01:29:25.420 --> 01:29:28.260]   Freeberg, any last thoughts as we wrap up?
[01:29:28.260 --> 01:29:31.060]   Jake out in order to have a healthy startup ecosystem, we
[01:29:31.060 --> 01:29:35.220]   need exits. That's the big picture. Yes. When you put this
[01:29:35.220 --> 01:29:38.460]   kind of chilling effect on M&A, because think about it. If
[01:29:38.460 --> 01:29:41.060]   you're either an acquirer, or your target, you're thinking
[01:29:41.060 --> 01:29:44.700]   about doing a deal, and you know, that it will take you at
[01:29:44.700 --> 01:29:48.540]   least or it could take you 15 months to get it's not worth it.
[01:29:48.540 --> 01:29:51.140]   You children and the standard for whether it gets approved is
[01:29:51.140 --> 01:29:54.260]   completely arbitrary. That's going to have a dampening or
[01:29:54.260 --> 01:29:57.500]   chilling effect on M&A activity, which means fewer good exits for
[01:29:57.500 --> 01:30:00.900]   the ecosystem, which means that less risk capital will want to
[01:30:00.900 --> 01:30:03.220]   go into the ecosystem to begin with.
[01:30:03.220 --> 01:30:05.780]   And a fair thing. I'll run this up the flagpole. So you think
[01:30:05.780 --> 01:30:08.160]   sex? Why don't they say if they're really concerned about
[01:30:08.160 --> 01:30:11.280]   the top 10 companies, hey, the top 10 companies, the trillion
[01:30:11.280 --> 01:30:14.700]   dollar crowd, right, the Microsoft, the Google, etc,
[01:30:14.700 --> 01:30:18.120]   Apple, they have a different standard than the mid market. So
[01:30:18.120 --> 01:30:20.740]   if you really were concerned about consolidation in the in
[01:30:20.740 --> 01:30:24.340]   the top 10 companies, just say they're not allowed to buy these
[01:30:24.340 --> 01:30:26.860]   companies without going through the scrutiny. But anybody under
[01:30:26.860 --> 01:30:30.900]   250 billion dollars, they can merge, they can buy each other,
[01:30:30.900 --> 01:30:33.740]   they can do whatever they want. They're exempt from this kind of
[01:30:33.740 --> 01:30:36.060]   review and just let the free market decide because then that
[01:30:36.060 --> 01:30:37.720]   would build up the mid market, right sex,
[01:30:37.720 --> 01:30:42.120]   I'm concerned about the power of big tech companies. Okay, but I
[01:30:42.120 --> 01:30:44.940]   would deal with that by targeting anti competitive
[01:30:44.940 --> 01:30:48.800]   tactics, interoperability. Yeah, require interoperability, don't
[01:30:48.800 --> 01:30:52.980]   let them bundle things like that. Don't invent some wholly
[01:30:52.980 --> 01:30:56.400]   new arbitrary subjective tests for whether a company can be
[01:30:56.400 --> 01:30:59.520]   acquired. We have a good standard around that, which has
[01:30:59.520 --> 01:31:00.520]   to do with market share.
[01:31:00.520 --> 01:31:03.280]   Hey, shout out Lena Khan come on the pod anytime. All right,
[01:31:03.280 --> 01:31:07.520]   everybody. This has been an and sincerely Lena Khan come on the
[01:31:07.520 --> 01:31:09.920]   pod. Let's talk about this has been another amazing episode of
[01:31:09.920 --> 01:31:13.960]   the all in podcast for the dictator. Chama polyhypertia. The
[01:31:13.960 --> 01:31:19.540]   rain man, David Sachs, and El Capitan, the pilot, Sultan of
[01:31:19.540 --> 01:31:23.520]   science and CEO, David Freeberg. I am the world's greatest
[01:31:23.520 --> 01:31:26.680]   moderator. Love you besties. We'll see you next time.
[01:31:26.680 --> 01:31:27.400]   Back at you.
[01:31:30.240 --> 01:31:31.520]   Let your winners ride.
[01:31:31.520 --> 01:31:34.360]   Rain Man David Sachs.
[01:31:34.360 --> 01:31:40.760]   We open source it to the fans and they've just gone crazy.
[01:31:40.760 --> 01:31:41.760]   Love you.
[01:31:41.760 --> 01:31:50.960]   Besties are
[01:31:50.960 --> 01:31:55.000]   dog taking a notice your driveway.
[01:31:58.800 --> 01:32:03.120]   My avatar should all just get a room and just have one big huge
[01:32:03.120 --> 01:32:06.280]   orgy because they're all like this like sexual tension that
[01:32:06.280 --> 01:32:07.200]   they just need to release.
[01:32:07.200 --> 01:32:10.320]   You're about to be
[01:32:10.320 --> 01:32:14.720]   waiting to get
[01:32:15.320 --> 01:32:15.560]   our
[01:32:15.560 --> 01:32:25.280]   going all in. All in.
[01:32:25.280 --> 01:32:31.280]   [Music]

