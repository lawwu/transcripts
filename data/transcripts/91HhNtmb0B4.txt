
[00:00:00.000 --> 00:00:06.920]   Today, I'm going to give you a quick walkthrough of getting started with weights and biases.
[00:00:06.920 --> 00:00:09.640]   So our tool is focused around machine learning.
[00:00:09.640 --> 00:00:13.280]   If you're doing a machine learning project and you want to track all of your results
[00:00:13.280 --> 00:00:18.040]   in one place, visualize things, and share your results with collaborators, this is a
[00:00:18.040 --> 00:00:20.120]   great tool for you.
[00:00:20.120 --> 00:00:24.320]   Here's a featured gallery of some reports that people have made inside our app.
[00:00:24.320 --> 00:00:30.840]   So this allows folks to log metrics directly to weights and biases, and then visualize
[00:00:30.840 --> 00:00:33.240]   and describe their results in the UI.
[00:00:33.240 --> 00:00:34.240]   So here's an example.
[00:00:34.240 --> 00:00:39.540]   One of our customers at Latent Space is creating GANs, and they're able to visualize metrics
[00:00:39.540 --> 00:00:45.400]   over time, compare against baselines, and then visualize the results of their models.
[00:00:45.400 --> 00:00:49.440]   This is crucial in terms of collaborating around a machine learning project, because
[00:00:49.440 --> 00:00:55.320]   they're able to have a centralized dashboard where they can show and explain their results.
[00:00:55.320 --> 00:00:58.600]   So let's get started by signing up for an account.
[00:00:58.600 --> 00:01:03.240]   So now on the homepage, you'll be able to go through this quick checklist to get started
[00:01:03.240 --> 00:01:04.240]   with weights and biases.
[00:01:04.240 --> 00:01:08.360]   First, you'll want to try out the logging and see how it works.
[00:01:08.360 --> 00:01:13.920]   So I've created this live example for you that you can follow along with really quickly.
[00:01:13.920 --> 00:01:23.960]   So what you'll want to do is copy these commands into your terminal.
[00:01:23.960 --> 00:01:30.080]   That's cloning the tutorial project, which is a quick Keras model, and then authenticating.
[00:01:30.080 --> 00:01:35.180]   So that's you putting your API key into your local machine.
[00:01:35.180 --> 00:01:42.800]   Now I'm running Python tutorial.py, and that will start this model training.
[00:01:42.800 --> 00:01:52.160]   So as you can see, this link is printed out on the command line.
[00:01:52.160 --> 00:01:55.140]   So opening up that link, you get the project page.
[00:01:55.140 --> 00:01:58.480]   This page has a couple of key features I'd like to share with you.
[00:01:58.480 --> 00:02:02.480]   Here's the sidebar where you can see each row is a single run.
[00:02:02.480 --> 00:02:05.480]   So it's a single experiment that you ran in your script.
[00:02:05.480 --> 00:02:11.600]   Each time you call WMB init, a new run and a new line in this table get added.
[00:02:11.600 --> 00:02:13.280]   Now you can filter these.
[00:02:13.280 --> 00:02:19.920]   So if you have, say, a certain number of epochs on a set of runs that you want to compare,
[00:02:19.920 --> 00:02:21.420]   you can filter by that.
[00:02:21.420 --> 00:02:24.420]   You can group by any column you're logging in here.
[00:02:24.420 --> 00:02:26.240]   And you can also sort by different values.
[00:02:26.240 --> 00:02:30.160]   Right now, it's the latest run at the top.
[00:02:30.160 --> 00:02:33.840]   So each of these columns is just something that I'm logging from my script.
[00:02:33.840 --> 00:02:40.160]   And that makes it easy to compare things like dropout or hidden layer sizes across my models.
[00:02:40.160 --> 00:02:43.600]   To configure the columns, I can click over here and add and remove columns.
[00:02:43.600 --> 00:02:48.440]   Since I'm the only user, I'm going to hide that column.
[00:02:48.440 --> 00:02:53.220]   Now another cool feature that I'd love for you to try is you can add notes.
[00:02:53.220 --> 00:02:59.000]   So if you have a little note to yourself that you'd like to remember about that run, you
[00:02:59.000 --> 00:03:00.560]   can add that here.
[00:03:00.560 --> 00:03:04.840]   And when you click on the run, that note will be available here in the overview tab of the
[00:03:04.840 --> 00:03:11.720]   run, along with the config and summary and things like the git repo and the latest git
[00:03:11.720 --> 00:03:14.160]   commit before you ran the run.
[00:03:14.160 --> 00:03:20.480]   So these are background pieces of information that might be useful for you as you're comparing
[00:03:20.480 --> 00:03:21.640]   runs.
[00:03:21.640 --> 00:03:27.560]   Another thing that we pick up if you're using-- if you're logging the media, we offer a feature
[00:03:27.560 --> 00:03:32.580]   where you can visualize different images from your runs in the UI.
[00:03:32.580 --> 00:03:37.720]   You can also do this with point clouds and audio and a lot of different rich media types.
[00:03:37.720 --> 00:03:41.120]   We even support molecules, which is pretty cool.
[00:03:41.120 --> 00:03:48.160]   So to learn about those particular features, you can go to docs.wmb.com.
[00:03:48.160 --> 00:03:51.760]   And that's all listed here in our Python library.
[00:03:51.760 --> 00:03:55.000]   So wmb_init is what launches a new run.
[00:03:55.000 --> 00:04:01.000]   wmb_config is where I save hyperparameters, maybe the dataset name or model type.
[00:04:01.000 --> 00:04:03.800]   And I feed that into init.
[00:04:03.800 --> 00:04:06.240]   And then log is what I call overtime.
[00:04:06.240 --> 00:04:12.680]   So inside my training loop, I just pass in a dictionary of what I want to see on those
[00:04:12.680 --> 00:04:13.680]   graphs.
[00:04:13.680 --> 00:04:19.880]   And if I have a custom x-axis, I can also set that here and then select a custom x-axis
[00:04:19.880 --> 00:04:21.880]   here in the UI.
[00:04:21.880 --> 00:04:22.880]   Great.
[00:04:22.880 --> 00:04:25.480]   So that's the run page.
[00:04:25.480 --> 00:04:28.240]   A couple of tabs that are cool.
[00:04:28.240 --> 00:04:30.040]   We get the system metrics.
[00:04:30.040 --> 00:04:32.280]   So this run didn't run for very long.
[00:04:32.280 --> 00:04:34.680]   The CPU utilization was pretty low.
[00:04:34.680 --> 00:04:38.880]   But these get logged about every 30 seconds.
[00:04:38.880 --> 00:04:42.760]   And they're useful for identifying bottlenecks in your models.
[00:04:42.760 --> 00:04:44.400]   We also pick up the graph.
[00:04:44.400 --> 00:04:50.760]   So if you want to look at the shape of your model, you can check that on the model tab.
[00:04:50.760 --> 00:04:56.200]   We get the standard out and standard error and show that here in the logs tab.
[00:04:56.200 --> 00:05:00.260]   And then we also save any files that you put in the WMB directory.
[00:05:00.260 --> 00:05:06.000]   So in this case, I saved the best model at the end of training.
[00:05:06.000 --> 00:05:09.240]   And that happens automatically with the Keras callback.
[00:05:09.240 --> 00:05:13.160]   You can also see any images that I uploaded.
[00:05:13.160 --> 00:05:19.240]   In this case, I'm looking at fashion MNIST, which is black and white images of different
[00:05:19.240 --> 00:05:21.560]   pieces of clothing.
[00:05:21.560 --> 00:05:25.760]   So now back to the project page.
[00:05:25.760 --> 00:05:28.760]   You can see here, by default, this project is private.
[00:05:28.760 --> 00:05:33.520]   But I'm going to make it public so that you guys can come and check out this URL if you
[00:05:33.520 --> 00:05:35.520]   like.
[00:05:35.520 --> 00:05:40.480]   So looking at the tabs available here, you can leave a description on your project if
[00:05:40.480 --> 00:05:45.160]   you'd like other folks to be able to understand what you're trying to do here.
[00:05:45.160 --> 00:05:52.120]   So in this case, I'll do WMB/tutorial.
[00:05:52.120 --> 00:05:58.640]   And I'll just grab this link and paste that in so that other folks who come to my project
[00:05:58.640 --> 00:06:02.360]   can see the repo that I was using.
[00:06:02.360 --> 00:06:07.600]   Now it looks like I could probably improve some of these values.
[00:06:07.600 --> 00:06:10.880]   So I'm going to go back to the terminal.
[00:06:10.880 --> 00:06:24.800]   And I'm going to edit the script and rerun.
[00:06:24.800 --> 00:06:27.960]   So as this is running, it prints out again that link.
[00:06:27.960 --> 00:06:32.420]   And you'll see that run appear live here in the dashboard.
[00:06:32.420 --> 00:06:36.120]   Now looking at the dashboard, I can actually configure these graphs.
[00:06:36.120 --> 00:06:38.600]   So epic isn't that useful to me.
[00:06:38.600 --> 00:06:40.960]   I'll delete that panel.
[00:06:40.960 --> 00:06:46.880]   Now I can resize these to take up more space.
[00:06:46.880 --> 00:06:54.040]   As you can see, the new run is being drawn live.
[00:06:54.040 --> 00:06:56.880]   So it looks like those changes weren't very effective.
[00:06:56.880 --> 00:07:02.200]   Even though it trained for longer, it never achieved the same level of accuracy.
[00:07:02.200 --> 00:07:04.960]   That's a bummer.
[00:07:04.960 --> 00:07:09.280]   But it's useful to be able to see that live because I can actually stop the run early
[00:07:09.280 --> 00:07:14.220]   if it's running for a very long time and try a different combination of hyperparameters.
[00:07:14.220 --> 00:07:20.200]   So again, you can compare those here in the table.
[00:07:20.200 --> 00:07:25.680]   You can also use the magic wand to only show columns that are different.
[00:07:25.680 --> 00:07:30.360]   So in this case, I only changed epic, learning rate, and momentum.
[00:07:30.360 --> 00:07:34.400]   So it hides all the other columns that aren't necessary.
[00:07:34.400 --> 00:07:35.400]   Great.
[00:07:35.400 --> 00:07:41.440]   Now I'm going to show you a nifty feature for describing your results.
[00:07:41.440 --> 00:07:44.800]   So I'm going to create a new report.
[00:07:44.800 --> 00:07:51.240]   And this report feature is a way that you can create and save dashboards and then share
[00:07:51.240 --> 00:07:56.560]   those dashboards with your collaborators or keep track of different stages of the process
[00:07:56.560 --> 00:07:58.840]   as you're building out your project.
[00:07:58.840 --> 00:08:05.560]   So each section has a set of different panels and then a run set that controls the data
[00:08:05.560 --> 00:08:07.400]   visible in this section.
[00:08:07.400 --> 00:08:10.260]   So here I've just added a markdown panel.
[00:08:10.260 --> 00:08:13.480]   And I can describe what I'm working on.
[00:08:13.480 --> 00:08:17.660]   I can rename the section.
[00:08:17.660 --> 00:08:22.160]   And then I can also add a bunch of different types of plots.
[00:08:22.160 --> 00:08:29.040]   So I could put accuracy and validation accuracy on the same graph to compare them across runs.
[00:08:29.040 --> 00:08:35.320]   As you can see, the first run in blue, the second run in red.
[00:08:35.320 --> 00:08:38.080]   In this project, I have a lot more runs.
[00:08:38.080 --> 00:08:45.120]   And that means that I can compare across many, many different combinations of hyperparameters.
[00:08:45.120 --> 00:08:54.880]   So as you can see, there are a lot of variations across my 180 runs in here.
[00:08:54.880 --> 00:08:57.740]   And that's because I ran a hyperparameter sweep.
[00:08:57.740 --> 00:09:01.400]   And now we can talk about that more together in a follow-up video.
[00:09:01.400 --> 00:09:04.280]   I'll put a link in the description here.
[00:09:04.280 --> 00:09:06.260]   So back to the workspace.
[00:09:06.260 --> 00:09:11.200]   I can export these graphs to a report and show you what a report looks like with some
[00:09:11.200 --> 00:09:14.360]   more data in it.
[00:09:14.360 --> 00:09:18.920]   So here, that saves the state of the graphs that I had in this section, as well as the
[00:09:18.920 --> 00:09:20.840]   visible run sets.
[00:09:20.840 --> 00:09:25.100]   So say I just wanted to talk about one of the sweeps that I'm doing.
[00:09:25.100 --> 00:09:30.560]   I can select the sweep and then pick which one I want to show here.
[00:09:30.560 --> 00:09:35.520]   And that filters down these graphs in the section to just the sweeps selected in this
[00:09:35.520 --> 00:09:37.200]   table.
[00:09:37.200 --> 00:09:45.200]   Now if I want to filter even more, I could do something like choose a particular batch
[00:09:45.200 --> 00:09:55.640]   size threshold and say it has to be greater than maybe 150.
[00:09:55.640 --> 00:09:59.940]   And that filters down my table even more.
[00:09:59.940 --> 00:10:05.800]   So any changes you make in the table on a given section will be reflected above.
[00:10:05.800 --> 00:10:10.000]   Another thing you can do is you can group the different sections and then visualize
[00:10:10.000 --> 00:10:11.560]   those groups.
[00:10:11.560 --> 00:10:17.280]   So imagine I have two different sweeps and I want to see which one performed better.
[00:10:17.280 --> 00:10:23.960]   I can set up two different run sets here, one for the first sweep and one for the second
[00:10:23.960 --> 00:10:24.960]   sweep.
[00:10:24.960 --> 00:10:32.160]   So here I'm filtering down to the second sweep.
[00:10:32.160 --> 00:10:34.600]   And I'm visualizing all of those runs.
[00:10:34.600 --> 00:10:37.800]   And then I'm going to group by all.
[00:10:37.800 --> 00:10:42.520]   That means that I'm putting them all in one big group.
[00:10:42.520 --> 00:10:52.320]   So now if I group by all here, I'll be able to see those grouped runs up here on the graphs.
[00:10:52.320 --> 00:10:55.640]   So once that's saved, I'll be able to share this link.
[00:10:55.640 --> 00:10:57.880]   The way I do that is here.
[00:10:57.880 --> 00:11:04.000]   I can copy the link and if I want to give other folks who are members of my team or
[00:11:04.000 --> 00:11:08.480]   who I give access to the project, I can turn this on so that they can actually come in
[00:11:08.480 --> 00:11:10.760]   and edit the same report.
[00:11:10.760 --> 00:11:13.960]   So we do support collaborative reports.
[00:11:13.960 --> 00:11:19.920]   If you like a report that you see and you want to copy the layout and try your own runs
[00:11:19.920 --> 00:11:26.480]   in it, you can clone a collaborator's report in the same project and then edit it in a
[00:11:26.480 --> 00:11:27.480]   new copy.
[00:11:27.480 --> 00:11:28.480]   Great.
[00:11:28.480 --> 00:11:33.440]   So now I'm going to show you a few of my personal favorite features.
[00:11:33.440 --> 00:11:39.760]   I'm going to create a new section below and then show you what some of these other visualizations
[00:11:39.760 --> 00:11:40.760]   look like.
[00:11:40.760 --> 00:11:43.080]   So we've looked at the line plot.
[00:11:43.080 --> 00:11:50.040]   That allows you to pick multiple Y metrics and show them on the same graph.
[00:11:50.040 --> 00:11:54.440]   You can group, change the chart style.
[00:11:54.440 --> 00:11:57.700]   You can also change the titles and the legend.
[00:11:57.700 --> 00:12:01.640]   So say I want to see the batch size in the legend.
[00:12:01.640 --> 00:12:03.720]   I can show that here.
[00:12:03.720 --> 00:12:13.720]   And I can even say batch size in the legend itself so that it's visible up here.
[00:12:13.720 --> 00:12:17.080]   So now I have quite a few runs visualized, which is a bit messy.
[00:12:17.080 --> 00:12:27.480]   I'm going to click this eye button and select visualize none and then just pick one run
[00:12:27.480 --> 00:12:29.800]   that logged these metrics.
[00:12:29.800 --> 00:12:34.200]   And I'll be able to see those three different metrics on here on the graph.
[00:12:34.200 --> 00:12:39.020]   Now if I want to, I can actually make those lines different colors by editing the line
[00:12:39.020 --> 00:12:40.760]   styles down here.
[00:12:40.760 --> 00:12:44.600]   So I can pick three colors to differentiate them more.
[00:12:44.600 --> 00:12:50.560]   I can also change the line style if I want them to all be solid.
[00:12:50.560 --> 00:12:54.280]   So this is totally up to you, very configurable.
[00:12:54.280 --> 00:12:55.600]   And then expressions.
[00:12:55.600 --> 00:13:03.080]   So I can actually set up an expression to use all three of these metrics at once.
[00:13:03.080 --> 00:13:06.920]   For other types of plots, we've got bar charts.
[00:13:06.920 --> 00:13:11.840]   And this will take the final value that was logged for a given metric.
[00:13:11.840 --> 00:13:16.320]   You can change this in your script if you want to set the summary to a different value,
[00:13:16.320 --> 00:13:20.320]   like best accuracy instead of final accuracy.
[00:13:20.320 --> 00:13:25.240]   Now you can also add a scatter plot.
[00:13:25.240 --> 00:13:26.240]   And there you go.
[00:13:26.240 --> 00:13:27.400]   You can mouse over these guys.
[00:13:27.400 --> 00:13:29.320]   You can select a region.
[00:13:29.320 --> 00:13:36.280]   And that will actually zoom in on the other charts on just the runs that you've selected.
[00:13:36.280 --> 00:13:39.760]   Another chart that behaves that way that I think you'll like is called the parallel coordinates
[00:13:39.760 --> 00:13:41.200]   chart.
[00:13:41.200 --> 00:13:46.400]   Now the idea here is I can see the relationships between my hyperparameter choices and my output
[00:13:46.400 --> 00:13:48.960]   metrics.
[00:13:48.960 --> 00:13:54.940]   So let's look at something like accuracy.
[00:13:54.940 --> 00:13:59.800]   So I have a couple of runs that crashed and never logged accuracy.
[00:13:59.800 --> 00:14:07.660]   To get rid of those, I'm going to select on this axis and then press the filter button.
[00:14:07.660 --> 00:14:10.600]   And that will actually add a filter to the run set.
[00:14:10.600 --> 00:14:17.740]   So now if I go out here, I'll see that a new filter has been added to restrict the accuracy
[00:14:17.740 --> 00:14:20.960]   to just the values I care about.
[00:14:20.960 --> 00:14:27.440]   Now if I zoom in on the axis here, you'll see that's actually zooming in on the other
[00:14:27.440 --> 00:14:29.200]   graphs as well.
[00:14:29.200 --> 00:14:34.100]   So you can slice and dice your results dynamically and compare things.
[00:14:34.100 --> 00:14:39.800]   Now the next type of panel I want to show you is called the run compare.
[00:14:39.800 --> 00:14:46.020]   And this is a table that takes the config and summary metrics from your runs and shows
[00:14:46.020 --> 00:14:49.160]   you the difference across runs.
[00:14:49.160 --> 00:14:55.320]   So now you can imagine if I'm keeping a few of my hyperparameters the same and then just
[00:14:55.320 --> 00:15:00.120]   varying a couple of things, I probably don't care about all of the hyperparameters that
[00:15:00.120 --> 00:15:01.520]   are the same on every run.
[00:15:01.520 --> 00:15:08.080]   So you can use the diff only feature to hide any rows that are the same across all runs.
[00:15:08.080 --> 00:15:11.760]   And this guy again is controlled by the run set down here.
[00:15:11.760 --> 00:15:17.220]   So if I wanted to just compare a couple of different runs, I could do that by selecting
[00:15:17.220 --> 00:15:21.960]   them here in the table and seeing them appear here on this.
[00:15:21.960 --> 00:15:28.780]   Now you can imagine wanting to show a zoom in on just a couple of runs, but keep showing
[00:15:28.780 --> 00:15:31.780]   all of the rest of the runs up here.
[00:15:31.780 --> 00:15:35.280]   So the way I'd recommend doing that is just creating a new section.
[00:15:35.280 --> 00:15:40.680]   That gives you access to a new run set and a new area to fill in visualizations.
[00:15:40.680 --> 00:15:46.400]   So here I'll create that run compare to zoom in on just a couple of runs.
[00:15:46.400 --> 00:15:51.840]   Starting from visualize none and selecting just a couple.
[00:15:51.840 --> 00:15:55.460]   Great.
[00:15:55.460 --> 00:15:58.440]   Next up is the code comparer.
[00:15:58.440 --> 00:16:04.480]   So this will take code from across your runs and show you the diff in the UI.
[00:16:04.480 --> 00:16:07.160]   Now by default, we have this turned off.
[00:16:07.160 --> 00:16:11.800]   So in your settings page, you'll be able to go to your project defaults.
[00:16:11.800 --> 00:16:17.360]   As you can see, my projects are private by default, and now I've enabled code saving.
[00:16:17.360 --> 00:16:23.600]   So that means any new runs that I run, I'll be able to save and compare the code in this
[00:16:23.600 --> 00:16:24.600]   UI.
[00:16:24.600 --> 00:16:32.320]   You can learn more about that here in our docs if you look for code comparer.
[00:16:32.320 --> 00:16:34.660]   And so here's an example of what that looks like.
[00:16:34.660 --> 00:16:37.560]   So here's a diff in the UI.
[00:16:37.560 --> 00:16:41.800]   And you can also, if you're using Jupyter, get the session history.
[00:16:41.800 --> 00:16:47.640]   So that allows you to see exactly the cells that were run during your run.
[00:16:47.640 --> 00:16:52.840]   Next up, we've got the parameter importance panel.
[00:16:52.840 --> 00:16:53.840]   I love this panel.
[00:16:53.840 --> 00:16:54.840]   I think it's really cool.
[00:16:54.840 --> 00:17:00.000]   So the way this one works is it takes all of the runs that you have visualized, and
[00:17:00.000 --> 00:17:05.000]   it runs a quick random forest based on the metric that you've selected here.
[00:17:05.000 --> 00:17:10.760]   So I want to see what different config values most affect the accuracy.
[00:17:10.760 --> 00:17:14.200]   It looks like learning rate is really important.
[00:17:14.200 --> 00:17:19.200]   So if you're interested in logging something like a segmentation mask, you can actually
[00:17:19.200 --> 00:17:26.680]   dynamically visualize different pieces of the mask at different opacities in the UI.
[00:17:26.680 --> 00:17:28.280]   You can also log audio, video.
[00:17:28.280 --> 00:17:29.280]   We have histograms.
[00:17:29.280 --> 00:17:32.720]   We have this cool molecule feature.
[00:17:32.720 --> 00:17:34.600]   And I'm starting to add some live example links.
[00:17:34.600 --> 00:17:39.560]   So if you go to the docs, you can actually open up a page where you can see this feature
[00:17:39.560 --> 00:17:42.280]   live in the UI.
[00:17:42.280 --> 00:17:48.720]   So here's an example of a cool molecule that I can actually open up and zoom around to
[00:17:48.720 --> 00:17:51.360]   look at.
[00:17:51.360 --> 00:17:55.040]   So this is the kind of thing that you can log and visualize.
[00:17:55.040 --> 00:17:56.680]   We're constantly adding new features.
[00:17:56.680 --> 00:18:01.420]   We've got RSC and PR curves, confusion matrices, and heat maps.
[00:18:01.420 --> 00:18:07.080]   You can also, if you'd like to log something from matplotlib, we'll host it and show it
[00:18:07.080 --> 00:18:09.640]   in the UI as plotly.
[00:18:09.640 --> 00:18:16.640]   So that gives you a chance to log really custom graphs and then have them be interactive.
[00:18:16.640 --> 00:18:21.440]   Now if you have any other features that you'd like to see in here, I'd love to hear about
[00:18:21.440 --> 00:18:22.440]   it.
[00:18:22.440 --> 00:18:26.920]   We're constantly making this better, adding different framework integrations.
[00:18:26.920 --> 00:18:32.080]   And we're also really interested in hearing what kinds of projects you're working on.
[00:18:32.080 --> 00:18:37.480]   If you click on your profile image, you'll see the gallery page.
[00:18:37.480 --> 00:18:43.520]   And this gallery is a curated list of the cool reports that we talked about at the beginning
[00:18:43.520 --> 00:18:44.520]   of this video.
[00:18:44.520 --> 00:18:51.600]   So you can email us, contact@wmb.com, and share your work to be featured here.
[00:18:51.600 --> 00:18:52.600]   Great.
[00:18:52.600 --> 00:18:55.380]   Well, this has been fun, you guys.
[00:18:55.380 --> 00:19:01.760]   I hope that as you start running more runs, you reach out to us with any questions or
[00:19:01.760 --> 00:19:03.440]   suggestions.
[00:19:03.440 --> 00:19:07.920]   And I hope this video was useful to help you get started.
[00:19:07.920 --> 00:19:08.480]   Thanks, you guys.
[00:19:08.480 --> 00:19:18.480]   [BLANK_AUDIO]

