
[00:00:00.000 --> 00:00:04.960]   For early access to future documentaries and 30-plus exclusive ad-free videos,
[00:00:04.960 --> 00:00:07.560]   check out my Patreon, link in the description.
[00:00:07.560 --> 00:00:12.260]   DeepSeek wasn't meant to happen.
[00:00:12.260 --> 00:00:14.760]   The lines were well-rehearsed.
[00:00:14.760 --> 00:00:18.100]   The West had an ever-growing lead in AI.
[00:00:18.100 --> 00:00:23.420]   Language models were getting ever more expensive as they got more intelligent.
[00:00:23.420 --> 00:00:28.820]   And research was retreating behind a veil of competitive secrecy.
[00:00:28.820 --> 00:00:36.780]   But on the 20th of January, 2025, those reading those lines started to stutter.
[00:00:36.780 --> 00:00:42.820]   A model that visibly seemed to think before it spoke had been released, DeepSeek R1.
[00:00:42.820 --> 00:00:47.860]   It was unbelievably cheap, competitive with the best the West had to offer,
[00:00:47.860 --> 00:00:51.960]   and out in the open, available to anyone to download.
[00:00:51.960 --> 00:00:57.180]   Even OpenAI admit as much, arguing in March that DeepSeek shows,
[00:00:57.180 --> 00:01:01.020]   quote, that our lead is not wide and is narrowing.
[00:01:01.020 --> 00:01:06.220]   OpenAI even want models like DeepSeek R1 banned because they say, quote,
[00:01:06.220 --> 00:01:12.460]   DeepSeek could be compelled by the Chinese Communist Party to manipulate its models to cause harm.
[00:01:12.460 --> 00:01:18.680]   And because DeepSeek is simultaneously state-subsidized, state-controlled, and freely available,
[00:01:19.340 --> 00:01:22.900]   it will cost users their privacy and security.
[00:01:22.900 --> 00:01:30.840]   Now, while Google's Gemini 2.5 and the new ChatGPT image gen have wrestled back the headlines at the beginning of April,
[00:01:30.840 --> 00:01:34.840]   DeepSeek is preparing to deliver yet another shock to the system,
[00:01:34.840 --> 00:01:38.980]   with DeepSeek R2 expected later in April or May.
[00:01:39.380 --> 00:01:42.960]   But truth be told, many of you will already know all of that.
[00:01:42.960 --> 00:01:50.700]   What you might not know, though, are the aims and beliefs expressed in disparate interviews by the secretive founder behind DeepSeek,
[00:01:50.840 --> 00:01:58.440]   billionaire Liang Wenfeng, a man who now has to hide from crowds of adoring fans in his own hometown,
[00:01:58.440 --> 00:02:00.400]   according to a friend he texted,
[00:02:00.400 --> 00:02:04.400]   and who has now fled his home province with his family to escape further attention.
[00:02:04.400 --> 00:02:09.360]   Nor will some of you know about the first AI operation that made Liang his money,
[00:02:09.600 --> 00:02:11.140]   and then went awry.
[00:02:11.140 --> 00:02:16.840]   Or the beauty of some of the technical innovations behind the Omega viral DeepSeek R1.
[00:02:16.840 --> 00:02:23.200]   Or just how the Western labs like OpenAI and Anthropic have fired back with their own narratives
[00:02:23.200 --> 00:02:26.520]   in the days and weeks since the release of R1.
[00:02:26.520 --> 00:02:32.840]   There is frankly so much that so many people don't know about the company DeepSeek and what it means.
[00:02:32.840 --> 00:02:37.060]   The truth is that DeepSeek is a whale caught in a net of narratives,
[00:02:37.060 --> 00:02:39.180]   most of which contradict each other.
[00:02:39.180 --> 00:02:43.480]   So let's get as close as we can to the truth behind the narratives,
[00:02:43.480 --> 00:02:46.500]   and what that truth says about where all of this is going.
[00:02:46.500 --> 00:02:49.000]   Because if Liang Wenfeng is correct,
[00:02:49.000 --> 00:02:52.460]   and artificial general intelligence is, quote,
[00:02:52.460 --> 00:02:55.260]   10, 5, or even 2 years away,
[00:02:55.260 --> 00:03:01.680]   then this story is about far, far more than one man, one lab, or even one nation.
[00:03:01.680 --> 00:03:07.280]   Here then is what one of Liang's business partners said of the man who is thought to be 40.
[00:03:07.620 --> 00:03:12.140]   He was this very nerdy guy with a terrible hairstyle when they first met.
[00:03:12.140 --> 00:03:17.180]   Talking about building a 10,000 chip cluster to train his own AI models.
[00:03:17.180 --> 00:03:18.760]   We didn't take him seriously.
[00:03:18.760 --> 00:03:24.480]   Of course, there are many AI leaders with terrible hairstyles, so what sets Liang Wenfeng apart?
[00:03:24.720 --> 00:03:28.360]   He certainly wasn't always about solving intelligence and making it free.
[00:03:28.360 --> 00:03:32.060]   It's hard to become a billionaire that way, as you might well guess.
[00:03:32.060 --> 00:03:37.980]   No, to seek out the origin story here, we must switch to a first-hand account from the man himself.
[00:03:37.980 --> 00:03:40.660]   Before that, though, a few moments of background.
[00:03:40.660 --> 00:03:45.240]   Liang graduated university into a world that was falling apart.
[00:03:45.240 --> 00:03:50.240]   Some of you will be too young, of course, to remember the panic of September 2008,
[00:03:50.240 --> 00:03:56.080]   when the financial pyramid built on the sands of the US subprime housing market collapsed.
[00:03:56.080 --> 00:04:03.760]   Either way, you might be able to understand the drive Liang had to try to understand the patterns within the unfolding chaos,
[00:04:03.760 --> 00:04:05.640]   and predict what would come next.
[00:04:05.640 --> 00:04:12.260]   There were those who tried to tempt him into different directions while he operated out of a small flat in Chengdu, Sichuan.
[00:04:12.260 --> 00:04:17.040]   Not me, though I was there, actually, in Chengdu at the same time, learning Mandarin.
[00:04:17.040 --> 00:04:23.200]   No, no, no, it was the founder of what would become DJI, the world's preeminent drone maker,
[00:04:23.200 --> 00:04:26.420]   who tried to headhunt Liang, but to no avail.
[00:04:26.420 --> 00:04:28.320]   Liang had bigger ambitions.
[00:04:28.320 --> 00:04:31.960]   After getting a master's in information engineering in 2010,
[00:04:31.960 --> 00:04:36.600]   Liang went on a founding spree between 2013 and 2016,
[00:04:36.600 --> 00:04:42.200]   culminating in the establishment of the hedge fund High Flyer in February 2016.
[00:04:42.200 --> 00:04:47.200]   Each entity he started included the core goal of using machine learning
[00:04:47.200 --> 00:04:53.600]   to uncover the patterns behind microsecond or even nanosecond movements in the financial markets.
[00:04:53.600 --> 00:04:57.360]   Patterns and paradigms no humans could detect alone.
[00:04:57.600 --> 00:04:59.600]   Artificial intelligence, if you will.
[00:04:59.600 --> 00:05:01.280]   Before it was called that, of course.
[00:05:01.280 --> 00:05:07.500]   As late as May 2023, Liang was still describing his goal in financial terms.
[00:05:07.500 --> 00:05:14.260]   Our broader research aims to understand what kind of paradigms can fully describe the entire financial market,
[00:05:14.260 --> 00:05:17.140]   and whether there are simpler ways to express it.
[00:05:17.140 --> 00:05:23.440]   Anyway, it worked through attracting $9.4 billion in assets under management by the end of 2021,
[00:05:23.440 --> 00:05:29.860]   and providing returns that in some cases were 20 to 50 percentage points more than stock market benchmarks.
[00:05:29.860 --> 00:05:32.140]   Liang absolutely minted it.
[00:05:32.140 --> 00:05:36.380]   He was a billionaire by his mid-30s and on top of the world.
[00:05:36.380 --> 00:05:39.240]   All of High Flyer's market strategies used AI,
[00:05:39.240 --> 00:05:41.140]   and yes, they were calling it that,
[00:05:41.140 --> 00:05:45.700]   and they even had a supercomputer powered by 10,000 NVIDIA GPUs.
[00:05:45.700 --> 00:05:50.240]   He might not at this point be scaling up language models like a tiny American startup,
[00:05:50.240 --> 00:05:53.960]   OpenAI, had done the year earlier in 2020 with GPT-3.
[00:05:53.960 --> 00:05:59.140]   But had his AI truly solved the chaos of the financial markets?
[00:05:59.140 --> 00:06:00.140]   Had he done it?
[00:06:00.140 --> 00:06:00.780]   No.
[00:06:00.780 --> 00:06:03.500]   This is where the story starts to get interesting.
[00:06:03.500 --> 00:06:07.120]   Liang's AI system, built with a team of just over 100 individuals,
[00:06:07.120 --> 00:06:10.320]   had a troublesome personality quirk.
[00:06:10.320 --> 00:06:12.900]   It was frankly too much of a risk taker.
[00:06:12.900 --> 00:06:16.800]   It would double down on bets when it felt it was right, and that wasn't all.
[00:06:16.800 --> 00:06:20.420]   The hedge fund itself, High Flyer, had become hubristic.
[00:06:20.420 --> 00:06:22.960]   It was flying too close to the sun.
[00:06:22.960 --> 00:06:26.760]   Success as a hedge fund, as you might expect, attracts more investments.
[00:06:26.760 --> 00:06:30.340]   If you don't limit your fund size, and Liang didn't in time,
[00:06:30.340 --> 00:06:33.980]   then sometimes you have too much money to deploy in a smart way.
[00:06:33.980 --> 00:06:36.540]   Your trades get copied, your edge becomes less keen.
[00:06:36.540 --> 00:06:42.560]   So after seeing a sharp drawdown, High Flyer expressed its deep guilt in public,
[00:06:42.560 --> 00:06:45.260]   and took measures to further limit who could invest with them.
[00:06:45.260 --> 00:06:47.580]   Yes, in case you're curious, they did learn their lesson,
[00:06:47.580 --> 00:06:51.120]   and are still going as a hedge fund today with some degree of success.
[00:06:51.120 --> 00:06:53.960]   Actually, between 2018 and early 2024,
[00:06:53.960 --> 00:06:57.760]   High Flyer has outperformed the Chinese equivalent of the S&P index,
[00:06:57.760 --> 00:06:59.660]   albeit with some stumbles since then.
[00:06:59.660 --> 00:07:02.360]   And yes, as we know, Liang didn't give up on AI.
[00:07:02.360 --> 00:07:08.020]   He was rich now, and could afford an outfit dedicated to decoding not just financial systems,
[00:07:08.020 --> 00:07:11.140]   but the nature of general intelligence itself.
[00:07:11.140 --> 00:07:13.720]   The effort would be called DeepSeek,
[00:07:13.720 --> 00:07:18.100]   and it was first formed as a research body in April 2023.
[00:07:18.580 --> 00:07:22.500]   Any scars, perhaps, though, for Liang from his previous AI experience?
[00:07:22.500 --> 00:07:27.460]   Well, there is one that might have carried over into the paper DeepSeek produced
[00:07:27.460 --> 00:07:30.140]   on their first large language model, or chatbot.
[00:07:30.140 --> 00:07:34.140]   From his experience, Liang knew that AI could be fickle,
[00:07:34.140 --> 00:07:36.060]   and not always a reliable partner.
[00:07:36.060 --> 00:07:39.760]   So DeepSeek added this disclaimer for their first chatbot,
[00:07:39.760 --> 00:07:43.080]   DeepSeek V1, released in November 2023.
[00:07:43.080 --> 00:07:49.060]   We profoundly recognize the importance of safety for general artificial intelligence.
[00:07:49.060 --> 00:07:53.440]   The premise for establishing a truly helpful artificial intelligence model
[00:07:53.440 --> 00:07:56.620]   is that it possesses values consistent with those of humans,
[00:07:56.620 --> 00:07:59.960]   and exhibits friendliness towards humanity.
[00:07:59.960 --> 00:08:02.100]   Before I continue any further, though,
[00:08:02.100 --> 00:08:05.340]   let's not pretend that many of us in the West were paying much attention
[00:08:05.340 --> 00:08:07.980]   to any of the developments described so far.
[00:08:07.980 --> 00:08:11.620]   By then, of course, OpenAI were well onto GPT-4,
[00:08:11.620 --> 00:08:14.060]   which showed sparks of AGI.
[00:08:14.060 --> 00:08:17.320]   GPT-4 was released publicly in March 2023,
[00:08:17.320 --> 00:08:22.160]   well before DeepSeek was even officially founded in July of that year.
[00:08:22.160 --> 00:08:24.240]   But at least the stage had been set,
[00:08:24.240 --> 00:08:25.460]   a reclusive billionaire,
[00:08:25.460 --> 00:08:29.360]   one and a half decades deep into wielding artificial intelligence
[00:08:29.360 --> 00:08:30.320]   to understand the world.
[00:08:30.320 --> 00:08:32.300]   A man who had made his money,
[00:08:32.300 --> 00:08:33.660]   and was now, in his words,
[00:08:33.660 --> 00:08:35.660]   simply driven to explore.
[00:08:35.660 --> 00:08:36.220]   Quote,
[00:08:36.220 --> 00:08:37.760]   People, Liang said,
[00:08:37.760 --> 00:08:41.440]   may think there's some hidden business logic behind DeepSeek,
[00:08:41.440 --> 00:08:44.100]   but it's mainly driven by curiosity.
[00:08:44.100 --> 00:08:50.940]   Why did DeepSeek R1 capture the world's attention at the start of 2025?
[00:08:50.940 --> 00:08:54.860]   Why did it divide opinions and convulse markets?
[00:08:54.860 --> 00:08:58.920]   Was it that the wider world could see the thinking process
[00:08:58.920 --> 00:09:01.300]   of the language model before it gave its final answer?
[00:09:01.600 --> 00:09:03.520]   Was it that the DeepSeek model was so cheap?
[00:09:03.520 --> 00:09:07.860]   Or that the model and the methods behind it were so open and accessible?
[00:09:07.860 --> 00:09:11.380]   Or was it that such a performant model had come from China,
[00:09:11.380 --> 00:09:14.520]   which was supposed to be a year behind the Western frontier?
[00:09:14.520 --> 00:09:17.160]   We will investigate each of these possibilities,
[00:09:17.160 --> 00:09:22.160]   but there was one thing that was certain of the DeepSeek of summer 2023.
[00:09:22.160 --> 00:09:26.460]   It was, indeed, deeply behind Western AI labs.
[00:09:26.460 --> 00:09:27.460]   By then, don't forget,
[00:09:27.460 --> 00:09:29.180]   not only was GPT-4 out and about,
[00:09:29.320 --> 00:09:32.000]   but so was the first version of Claude from Anthropic
[00:09:32.000 --> 00:09:33.700]   and Bard from Google,
[00:09:33.700 --> 00:09:36.260]   and even Llama 2 from Meta.
[00:09:36.260 --> 00:09:37.600]   DeepSeek, by the way,
[00:09:37.600 --> 00:09:40.640]   paid particular attention to Llama 2.
[00:09:40.640 --> 00:09:45.060]   That model might not have been quite as smart on key benchmarks as GPT-4,
[00:09:45.060 --> 00:09:47.000]   but it was so-called open weights,
[00:09:47.000 --> 00:09:49.060]   which means almost anyone could download,
[00:09:49.060 --> 00:09:49.560]   tweak,
[00:09:49.560 --> 00:09:51.480]   and deploy the model as they saw fit.
[00:09:51.480 --> 00:09:53.720]   A model is, of course, nothing without its weight,
[00:09:53.720 --> 00:09:58.160]   or its billions of tweakable numerical values used to calculate outputs.
[00:09:58.160 --> 00:09:58.740]   To be clear,
[00:09:58.740 --> 00:10:01.500]   open weights isn't quite the same as open source,
[00:10:01.500 --> 00:10:03.040]   as to be open source,
[00:10:03.040 --> 00:10:06.280]   we would need to see the data that went into training the model,
[00:10:06.280 --> 00:10:07.560]   the source, so to speak,
[00:10:07.560 --> 00:10:09.860]   which we did not and still do not know.
[00:10:10.000 --> 00:10:13.560]   Despite some models like Llama 2 being open weights at least,
[00:10:13.560 --> 00:10:16.500]   key leaders within Western AI labs were saying
[00:10:16.500 --> 00:10:19.520]   that the frontier would increasingly belong
[00:10:19.520 --> 00:10:22.520]   to those who kept secret the methodology
[00:10:22.520 --> 00:10:24.520]   behind their language model training,
[00:10:24.520 --> 00:10:25.800]   as OpenAI did.
[00:10:25.800 --> 00:10:27.120]   Here's Ilya Sutskova,
[00:10:27.120 --> 00:10:29.680]   at the time the chief scientist of OpenAI.
[00:10:29.680 --> 00:10:30.620]   He was saying
[00:10:30.620 --> 00:10:32.740]   there will always be a gap
[00:10:32.740 --> 00:10:35.940]   between the open models and the private models,
[00:10:35.940 --> 00:10:38.680]   and this gap may even be increasing.
[00:10:38.680 --> 00:10:42.060]   Sam Altman, CEO and co-founder of OpenAI, went further.
[00:10:42.060 --> 00:10:44.700]   It wasn't just that research secrets were becoming a moat,
[00:10:44.700 --> 00:10:46.500]   so too was money.
[00:10:46.500 --> 00:10:48.840]   In June of 2023 in India,
[00:10:48.840 --> 00:10:50.480]   Sam Altman replied to a question
[00:10:50.480 --> 00:10:52.320]   about whether a team with just $10 million
[00:10:52.320 --> 00:10:54.000]   could compete with OpenAI.
[00:10:54.000 --> 00:10:57.060]   His response for me became a wider comment
[00:10:57.060 --> 00:10:59.280]   on whether it was possible for any startup
[00:10:59.280 --> 00:11:00.360]   to enter the race
[00:11:00.360 --> 00:11:02.740]   and build a truly intelligent language model.
[00:11:02.740 --> 00:11:04.980]   Look, the way this works is we're going to tell you
[00:11:04.980 --> 00:11:06.740]   it's totally hopeless to compete with us
[00:11:06.740 --> 00:11:08.460]   on training foundation models you shouldn't try,
[00:11:08.460 --> 00:11:10.540]   and it's your job to, like, try anyway.
[00:11:10.540 --> 00:11:12.980]   And I believe both of those things.
[00:11:12.980 --> 00:11:18.100]   I think it is pretty hopeless, but...
[00:11:18.100 --> 00:11:18.840]   Not just this,
[00:11:18.840 --> 00:11:20.480]   a month earlier, in May,
[00:11:20.480 --> 00:11:22.360]   he had put it even more bluntly.
[00:11:22.360 --> 00:11:24.060]   There will be the hyperscaler's
[00:11:24.060 --> 00:11:26.660]   best closed source models,
[00:11:26.660 --> 00:11:29.140]   and there will be the progress
[00:11:29.140 --> 00:11:30.540]   that the open source community makes,
[00:11:30.540 --> 00:11:31.400]   and it'll be, you know,
[00:11:31.400 --> 00:11:32.980]   a few years behind or whatever,
[00:11:32.980 --> 00:11:34.000]   a couple years behind, maybe.
[00:11:34.000 --> 00:11:34.900]   As we learnt,
[00:11:34.900 --> 00:11:36.700]   a few weeks before these comments,
[00:11:36.700 --> 00:11:39.640]   Liang had launched what would become DeepSeq.
[00:11:39.640 --> 00:11:41.580]   In short, remember this context
[00:11:41.580 --> 00:11:43.660]   when you wonder at the order reaction
[00:11:43.660 --> 00:11:46.760]   to DeepSeq R1 in January 2025.
[00:11:46.760 --> 00:11:48.800]   It wasn't supposed to be like this.
[00:11:48.800 --> 00:11:50.060]   Intelligence was supposed to come
[00:11:50.060 --> 00:11:51.760]   from the scale of the base model,
[00:11:51.760 --> 00:11:54.220]   measured not just in how many tens of thousands
[00:11:54.220 --> 00:11:56.640]   of NVIDIA GPUs were used to compute
[00:11:56.640 --> 00:11:57.840]   the parameters of that model,
[00:11:57.840 --> 00:11:59.660]   but on how much data it was trained on.
[00:11:59.660 --> 00:12:01.860]   It just made sense that no one could compete
[00:12:01.860 --> 00:12:05.380]   without the backing of multi-trillion dollar hyperscalers
[00:12:05.380 --> 00:12:07.240]   like Microsoft or Google.
[00:12:07.240 --> 00:12:08.900]   Liang Wenfeng was rich,
[00:12:08.900 --> 00:12:10.180]   but not that rich.
[00:12:10.180 --> 00:12:11.360]   Liang must have known
[00:12:11.360 --> 00:12:12.940]   that these Western lab leaders
[00:12:12.940 --> 00:12:14.860]   thought what he was about to attempt
[00:12:14.860 --> 00:12:15.880]   was impossible,
[00:12:15.880 --> 00:12:17.440]   but he tried anyway.
[00:12:17.440 --> 00:12:18.900]   Nor would he be distracted
[00:12:18.900 --> 00:12:21.140]   by the law of quick monetization
[00:12:21.140 --> 00:12:23.480]   through routes like $20 subscriptions.
[00:12:23.480 --> 00:12:25.840]   Liang said in May of 2023,
[00:12:25.840 --> 00:12:27.200]   our goal is clear,
[00:12:27.200 --> 00:12:29.860]   to focus on research and exploration,
[00:12:29.860 --> 00:12:32.960]   rather than vertical domains and applications.
[00:12:32.960 --> 00:12:35.500]   So DeepSeq focused its recruitment efforts
[00:12:35.500 --> 00:12:36.700]   on those who were young,
[00:12:36.700 --> 00:12:38.920]   curious and crucially Chinese.
[00:12:38.920 --> 00:12:39.800]   By the way,
[00:12:39.800 --> 00:12:41.760]   not even Chinese returnees
[00:12:41.760 --> 00:12:43.440]   from the West were favored.
[00:12:43.440 --> 00:12:44.420]   Liang added,
[00:12:44.420 --> 00:12:47.480]   DeepSeq prioritizes capability over credentials,
[00:12:47.480 --> 00:12:48.860]   core technical roles
[00:12:48.860 --> 00:12:51.260]   are primarily filled by recent grads
[00:12:51.260 --> 00:12:52.900]   or those one to two years out.
[00:12:52.900 --> 00:12:54.560]   These intellectual foot soldiers
[00:12:54.560 --> 00:12:56.120]   would not be waylaid
[00:12:56.120 --> 00:12:57.960]   by the need to release on a schedule
[00:12:57.960 --> 00:12:59.140]   to compete with OpenAI.
[00:12:59.140 --> 00:13:00.700]   That was what had led Google
[00:13:00.700 --> 00:13:02.300]   to release a botched Bard
[00:13:02.300 --> 00:13:04.900]   and Microsoft a comically wayward Bing.
[00:13:04.900 --> 00:13:06.340]   Our evaluation standards
[00:13:06.340 --> 00:13:07.320]   are quite different
[00:13:07.320 --> 00:13:08.580]   from those of most companies.
[00:13:08.580 --> 00:13:09.880]   We don't have KPIs,
[00:13:09.880 --> 00:13:10.920]   key performance indicators,
[00:13:10.920 --> 00:13:12.380]   or so-called quotas.
[00:13:12.380 --> 00:13:13.420]   In our experience,
[00:13:13.420 --> 00:13:15.460]   innovation requires as little intervention
[00:13:15.460 --> 00:13:16.740]   and management as possible,
[00:13:16.740 --> 00:13:18.600]   giving everyone the space to explore
[00:13:18.600 --> 00:13:20.220]   and the freedom to make mistakes.
[00:13:20.220 --> 00:13:21.380]   All that said,
[00:13:21.380 --> 00:13:23.700]   DeepSeq's first pair of AI models
[00:13:23.700 --> 00:13:25.660]   released in November 2023
[00:13:25.660 --> 00:13:29.420]   were not exactly stunning in their originality.
[00:13:29.420 --> 00:13:31.000]   As I hinted at earlier,
[00:13:31.000 --> 00:13:32.860]   their V1 large language model
[00:13:32.860 --> 00:13:35.040]   drew heavily upon the innovations
[00:13:35.040 --> 00:13:37.060]   of Meta's Lama 2 LLM.
[00:13:37.060 --> 00:13:39.380]   And neither of their November releases,
[00:13:39.380 --> 00:13:41.240]   DeepSeq Coda or V1,
[00:13:41.240 --> 00:13:43.020]   made waves in the Western media.
[00:13:43.160 --> 00:13:44.420]   As attention at that time,
[00:13:44.420 --> 00:13:45.120]   you may remember,
[00:13:45.120 --> 00:13:46.520]   focused on Sam Altman
[00:13:46.520 --> 00:13:48.860]   being temporarily fired from OpenAI
[00:13:48.860 --> 00:13:50.120]   for lack of candor.
[00:13:50.120 --> 00:13:51.980]   But there were just a few signs
[00:13:51.980 --> 00:13:54.420]   that DeepSeq were indeed focused on
[00:13:54.420 --> 00:13:55.780]   long-termism,
[00:13:55.780 --> 00:13:58.100]   as each of their papers explicitly claim.
[00:13:58.100 --> 00:13:58.800]   For example,
[00:13:58.800 --> 00:14:01.560]   DeepSeq excluded multiple-choice questions
[00:14:01.560 --> 00:14:03.900]   from their bespoke training dataset,
[00:14:03.900 --> 00:14:05.540]   so that their models would not
[00:14:05.540 --> 00:14:07.840]   overperform on formal tests,
[00:14:08.000 --> 00:14:09.600]   but underwhelm in practice.
[00:14:09.600 --> 00:14:11.160]   And that's a lesson not learnt
[00:14:11.160 --> 00:14:12.960]   by all AI labs at the time,
[00:14:12.960 --> 00:14:13.700]   or even now.
[00:14:13.700 --> 00:14:14.620]   DeepSeq wrote,
[00:14:14.620 --> 00:14:15.000]   quote,
[00:14:15.000 --> 00:14:16.740]   overfitting two benchmarks
[00:14:16.740 --> 00:14:17.960]   would not contribute
[00:14:17.960 --> 00:14:19.840]   to achieving true intelligence
[00:14:19.840 --> 00:14:20.500]   in the model.
[00:14:20.500 --> 00:14:22.360]   By the beginning of 2024,
[00:14:22.360 --> 00:14:23.560]   the DeepSeq team
[00:14:23.560 --> 00:14:24.780]   was cooking with gas.
[00:14:24.780 --> 00:14:25.440]   In January,
[00:14:25.440 --> 00:14:27.160]   they pioneered a novel approach
[00:14:27.160 --> 00:14:28.300]   to getting more intelligence
[00:14:28.300 --> 00:14:29.920]   from their models for less.
[00:14:29.920 --> 00:14:32.060]   Bear in mind that models like Lama 2
[00:14:32.060 --> 00:14:34.220]   use their entire set of weights,
[00:14:34.220 --> 00:14:36.760]   often tens or hundreds of billions strong,
[00:14:36.760 --> 00:14:38.160]   to compute a response
[00:14:38.160 --> 00:14:39.220]   to a user prompt.
[00:14:39.220 --> 00:14:41.220]   That contrasted with
[00:14:41.220 --> 00:14:43.480]   the mixture of experts approach,
[00:14:43.480 --> 00:14:45.180]   which was not at all original
[00:14:45.180 --> 00:14:45.820]   to DeepSeq.
[00:14:45.820 --> 00:14:47.460]   The mixture of experts approach
[00:14:47.460 --> 00:14:49.740]   involves using a specialized subset
[00:14:49.740 --> 00:14:50.940]   of those weights,
[00:14:50.940 --> 00:14:52.700]   depending on the user input,
[00:14:52.700 --> 00:14:55.220]   thereby tapping into one or more
[00:14:55.220 --> 00:14:57.560]   of the set or mix of experts
[00:14:57.560 --> 00:14:58.420]   within the model,
[00:14:58.420 --> 00:14:59.000]   if you will.
[00:14:59.000 --> 00:14:59.780]   But think about it,
[00:14:59.780 --> 00:15:01.200]   because only a subset
[00:15:01.200 --> 00:15:02.160]   of the model weights
[00:15:02.160 --> 00:15:03.880]   would respond to each request,
[00:15:03.880 --> 00:15:06.380]   every expert within the model
[00:15:06.380 --> 00:15:07.640]   had to have a degree
[00:15:07.640 --> 00:15:09.020]   of common capability.
[00:15:09.020 --> 00:15:11.100]   A tiny bit like forcing Messi
[00:15:11.100 --> 00:15:12.440]   to spend hours a week
[00:15:12.440 --> 00:15:13.740]   practicing goalkeeping,
[00:15:13.740 --> 00:15:14.420]   and yes,
[00:15:14.420 --> 00:15:15.340]   I am talking about soccer
[00:15:15.340 --> 00:15:16.400]   if you are American.
[00:15:16.400 --> 00:15:18.240]   Could DeepSeq utilize
[00:15:18.240 --> 00:15:20.060]   the mixture of experts approach,
[00:15:20.060 --> 00:15:21.280]   which is highly efficient,
[00:15:21.280 --> 00:15:22.940]   without that key downside?
[00:15:22.940 --> 00:15:24.080]   You probably guessed the answer
[00:15:24.080 --> 00:15:24.660]   from my tone,
[00:15:24.660 --> 00:15:25.260]   but yes,
[00:15:25.260 --> 00:15:25.980]   in their
[00:15:25.980 --> 00:15:28.900]   Towards Ultimate Expert Specialization paper,
[00:15:28.900 --> 00:15:29.780]   here's the innovation.
[00:15:29.780 --> 00:15:31.960]   Certain expert subnetworks
[00:15:31.960 --> 00:15:32.920]   within the language model
[00:15:32.920 --> 00:15:34.760]   would always be activated
[00:15:34.760 --> 00:15:36.020]   in any response.
[00:15:36.020 --> 00:15:37.220]   Those guys could be
[00:15:37.220 --> 00:15:38.180]   the generalists.
[00:15:38.180 --> 00:15:39.100]   This meant that
[00:15:39.100 --> 00:15:40.220]   the remaining experts,
[00:15:40.220 --> 00:15:40.760]   like Messi,
[00:15:40.760 --> 00:15:42.100]   could truly focus
[00:15:42.100 --> 00:15:43.420]   on what they are good at.
[00:15:43.420 --> 00:15:43.780]   And yes,
[00:15:43.780 --> 00:15:45.160]   just in case you're thinking ahead,
[00:15:45.160 --> 00:15:46.880]   this is also one of the
[00:15:46.880 --> 00:15:47.920]   many secrets behind
[00:15:47.920 --> 00:15:48.700]   the base model
[00:15:48.700 --> 00:15:50.420]   that powers DeepSeq R1,
[00:15:50.420 --> 00:15:51.520]   the global phenomenon.
[00:15:51.520 --> 00:15:52.780]   DeepSeq were just
[00:15:52.780 --> 00:15:53.660]   getting warmed up though.
[00:15:53.660 --> 00:15:55.020]   In April of 2024,
[00:15:55.020 --> 00:15:57.000]   they released DeepSeq Math,
[00:15:57.000 --> 00:15:57.980]   a tiny model
[00:15:57.980 --> 00:15:59.060]   that matched the performance
[00:15:59.060 --> 00:15:59.760]   in mathematics,
[00:15:59.760 --> 00:16:00.220]   at least,
[00:16:00.220 --> 00:16:01.220]   of GPT-4,
[00:16:01.220 --> 00:16:02.540]   a goliath of a model
[00:16:02.540 --> 00:16:03.200]   in comparison.
[00:16:03.200 --> 00:16:04.040]   What's the deal
[00:16:04.040 --> 00:16:05.320]   with DeepSeq Math then?
[00:16:05.320 --> 00:16:05.580]   Well,
[00:16:05.580 --> 00:16:06.400]   one of the secrets
[00:16:06.400 --> 00:16:07.500]   behind the model's success
[00:16:07.500 --> 00:16:09.200]   was the unassumingly named
[00:16:09.200 --> 00:16:10.380]   Group Relative
[00:16:10.380 --> 00:16:11.800]   Polity Optimization.
[00:16:11.800 --> 00:16:12.540]   A mouthful,
[00:16:12.540 --> 00:16:13.680]   but it's a training method
[00:16:13.680 --> 00:16:14.620]   later incorporated,
[00:16:14.620 --> 00:16:15.300]   you guessed it,
[00:16:15.300 --> 00:16:16.300]   by the celebrated
[00:16:16.300 --> 00:16:17.340]   DeepSeq R1.
[00:16:17.340 --> 00:16:18.920]   Here then is the TLDR
[00:16:18.920 --> 00:16:20.140]   on that beast
[00:16:20.140 --> 00:16:21.300]   of a training innovation.
[00:16:21.300 --> 00:16:22.500]   All language models
[00:16:22.500 --> 00:16:23.580]   need to do more
[00:16:23.580 --> 00:16:24.660]   than just predict
[00:16:24.660 --> 00:16:25.380]   the next word,
[00:16:25.380 --> 00:16:26.460]   which is what they learn
[00:16:26.460 --> 00:16:27.400]   in pre-training.
[00:16:27.400 --> 00:16:28.160]   They need
[00:16:28.160 --> 00:16:29.320]   post-training
[00:16:29.320 --> 00:16:30.240]   to move from
[00:16:30.240 --> 00:16:31.060]   predicting the most
[00:16:31.060 --> 00:16:32.140]   probable word
[00:16:32.140 --> 00:16:32.980]   to the most
[00:16:32.980 --> 00:16:34.580]   helpful sets of words
[00:16:34.580 --> 00:16:35.900]   as judged by humans.
[00:16:35.900 --> 00:16:36.940]   And ultimately,
[00:16:36.940 --> 00:16:38.500]   for mathematical reasoning
[00:16:38.500 --> 00:16:39.480]   or coding steps,
[00:16:39.480 --> 00:16:40.220]   the most
[00:16:40.220 --> 00:16:41.420]   correct word.
[00:16:41.420 --> 00:16:42.380]   Think of it like this,
[00:16:42.380 --> 00:16:43.380]   you can't be smarter
[00:16:43.380 --> 00:16:43.900]   than Twitter
[00:16:43.900 --> 00:16:45.120]   if all you do
[00:16:45.120 --> 00:16:46.640]   is train to predict
[00:16:46.640 --> 00:16:47.580]   the next tweet.
[00:16:47.580 --> 00:16:48.880]   This takes careful
[00:16:48.880 --> 00:16:49.640]   reinforcement
[00:16:49.640 --> 00:16:50.400]   of the weights
[00:16:50.400 --> 00:16:50.920]   of the model
[00:16:50.920 --> 00:16:51.760]   that produce
[00:16:51.760 --> 00:16:53.180]   these desired outputs.
[00:16:53.180 --> 00:16:53.580]   Yes,
[00:16:53.580 --> 00:16:55.320]   this was by mid-2024
[00:16:55.320 --> 00:16:55.920]   well-known,
[00:16:55.920 --> 00:16:56.760]   but what was the magic
[00:16:56.760 --> 00:16:58.220]   behind GRPO,
[00:16:58.220 --> 00:16:59.640]   DeepSeq's new flavor
[00:16:59.640 --> 00:17:01.040]   of reinforcement learning?
[00:17:01.040 --> 00:17:01.640]   Well,
[00:17:01.640 --> 00:17:03.380]   DeepSeq needed efficiency
[00:17:03.380 --> 00:17:04.960]   to fight the AI giants.
[00:17:04.960 --> 00:17:06.100]   Common reinforcement
[00:17:06.100 --> 00:17:06.820]   learning approaches
[00:17:06.820 --> 00:17:07.540]   at the time
[00:17:07.540 --> 00:17:08.480]   used chunky,
[00:17:08.480 --> 00:17:09.140]   clunky,
[00:17:09.140 --> 00:17:10.300]   critic models
[00:17:10.300 --> 00:17:11.620]   to assess answers
[00:17:11.620 --> 00:17:12.940]   as they were being generated
[00:17:12.940 --> 00:17:13.600]   to predict
[00:17:13.600 --> 00:17:14.240]   which ones
[00:17:14.240 --> 00:17:15.440]   were headed for success.
[00:17:15.440 --> 00:17:16.700]   DeepSeq dropped
[00:17:16.700 --> 00:17:18.220]   this memory-heavy critic
[00:17:18.220 --> 00:17:19.480]   and instead generated
[00:17:19.480 --> 00:17:21.100]   a group of answers
[00:17:21.100 --> 00:17:21.700]   in parallel,
[00:17:21.700 --> 00:17:23.740]   checked the yes-no accuracy
[00:17:23.740 --> 00:17:24.860]   of the final outputs,
[00:17:25.060 --> 00:17:25.760]   and then using
[00:17:25.760 --> 00:17:27.580]   the relative score
[00:17:27.580 --> 00:17:28.420]   of each answer
[00:17:28.420 --> 00:17:29.420]   above or below
[00:17:29.420 --> 00:17:30.420]   the average accuracy
[00:17:30.420 --> 00:17:31.400]   of the group of answers
[00:17:31.400 --> 00:17:34.040]   reinforced the successful weights
[00:17:34.040 --> 00:17:34.520]   in the model
[00:17:34.520 --> 00:17:36.000]   and down-weighted others.
[00:17:36.000 --> 00:17:37.200]   Group of answers,
[00:17:37.200 --> 00:17:38.440]   relative score,
[00:17:38.440 --> 00:17:39.400]   reinforcing
[00:17:39.400 --> 00:17:41.320]   the most successful weights.
[00:17:41.320 --> 00:17:42.420]   Group relative
[00:17:42.420 --> 00:17:43.580]   policy optimization.
[00:17:43.580 --> 00:17:44.860]   Stepping back then,
[00:17:44.860 --> 00:17:46.020]   each of these innovations
[00:17:46.020 --> 00:17:47.620]   was desperately essential
[00:17:47.620 --> 00:17:48.780]   to keep DeepSeq
[00:17:48.780 --> 00:17:49.420]   within reach
[00:17:49.420 --> 00:17:51.060]   of the resource behemoths
[00:17:51.060 --> 00:17:52.380]   behind ChatGPT,
[00:17:52.380 --> 00:17:53.580]   Claude and Gemini.
[00:17:53.760 --> 00:17:55.100]   By May of 2024,
[00:17:55.100 --> 00:17:55.880]   Liang's lab
[00:17:55.880 --> 00:17:57.540]   shipped DeepSeq V2
[00:17:57.540 --> 00:17:58.760]   with yet another
[00:17:58.760 --> 00:17:59.680]   efficiency miracle,
[00:17:59.680 --> 00:18:01.460]   multi-head latent attention.
[00:18:01.460 --> 00:18:02.480]   Now, don't worry,
[00:18:02.480 --> 00:18:03.480]   there's no deep dive
[00:18:03.480 --> 00:18:04.540]   coming on this one,
[00:18:04.540 --> 00:18:05.180]   but forgive me
[00:18:05.180 --> 00:18:06.480]   just a few words
[00:18:06.480 --> 00:18:07.420]   on how DeepSeq
[00:18:07.420 --> 00:18:08.560]   yet again reduced
[00:18:08.560 --> 00:18:09.680]   how big a model
[00:18:09.680 --> 00:18:10.160]   had to be
[00:18:10.160 --> 00:18:11.080]   to reach a similar
[00:18:11.080 --> 00:18:12.040]   level of performance.
[00:18:12.040 --> 00:18:13.460]   Think of multi-head
[00:18:13.460 --> 00:18:14.300]   latent attention
[00:18:14.300 --> 00:18:15.180]   as allowing
[00:18:15.180 --> 00:18:16.400]   multiple parts
[00:18:16.400 --> 00:18:16.840]   of the model
[00:18:16.840 --> 00:18:18.180]   to share common weights
[00:18:18.180 --> 00:18:19.300]   that are hidden
[00:18:19.300 --> 00:18:20.180]   or latent
[00:18:20.180 --> 00:18:21.340]   when they quote
[00:18:21.340 --> 00:18:22.400]   pay attention.
[00:18:22.400 --> 00:18:23.360]   If you're wondering,
[00:18:23.360 --> 00:18:24.860]   this attention mechanism
[00:18:24.860 --> 00:18:25.880]   is the process
[00:18:25.880 --> 00:18:26.980]   by which language models
[00:18:26.980 --> 00:18:28.180]   deduce which parts
[00:18:28.180 --> 00:18:29.680]   of the preceding text
[00:18:29.680 --> 00:18:30.680]   are most relevant
[00:18:30.680 --> 00:18:31.320]   for predicting
[00:18:31.320 --> 00:18:32.040]   the next word.
[00:18:32.040 --> 00:18:33.340]   Sharing those latent
[00:18:33.340 --> 00:18:34.200]   or hidden weights
[00:18:34.200 --> 00:18:35.440]   when paying attention
[00:18:35.440 --> 00:18:37.000]   meant that this model
[00:18:37.000 --> 00:18:37.920]   needed fewer
[00:18:37.920 --> 00:18:39.340]   of the weights overall.
[00:18:39.340 --> 00:18:40.160]   Shared weights,
[00:18:40.160 --> 00:18:41.000]   smaller model,
[00:18:41.000 --> 00:18:41.940]   greater efficiency.
[00:18:41.940 --> 00:18:43.640]   DeepSeq V2.
[00:18:43.920 --> 00:18:44.760]   Okay, we get it.
[00:18:44.760 --> 00:18:45.720]   The point has probably
[00:18:45.720 --> 00:18:46.540]   now been made
[00:18:46.540 --> 00:18:47.840]   that DeepSeq R1
[00:18:47.840 --> 00:18:49.980]   was not a creatio ex nihilo
[00:18:49.980 --> 00:18:51.520]   created from thin air.
[00:18:51.520 --> 00:18:52.260]   It was built
[00:18:52.260 --> 00:18:53.020]   on the back
[00:18:53.020 --> 00:18:54.800]   of painstaking innovations
[00:18:54.800 --> 00:18:55.820]   amassed over
[00:18:55.820 --> 00:18:57.040]   almost two years
[00:18:57.040 --> 00:18:58.000]   and made open
[00:18:58.000 --> 00:18:58.600]   to the world.
[00:18:58.600 --> 00:18:59.400]   Funded, of course,
[00:18:59.400 --> 00:19:00.880]   by a reclusive billionaire.
[00:19:00.880 --> 00:19:01.480]   But wait,
[00:19:01.480 --> 00:19:02.260]   why did Liang
[00:19:02.260 --> 00:19:03.620]   need so much efficiency?
[00:19:03.620 --> 00:19:04.540]   Because yes,
[00:19:04.540 --> 00:19:05.580]   DeepSeq had indeed
[00:19:05.580 --> 00:19:07.040]   secured 10,000
[00:19:07.040 --> 00:19:09.100]   Nvidia A100 GPUs
[00:19:09.100 --> 00:19:10.080]   for High Flyer's
[00:19:10.080 --> 00:19:10.600]   stock trading
[00:19:10.600 --> 00:19:11.500]   in 2021.
[00:19:11.500 --> 00:19:13.620]   But the US government
[00:19:13.620 --> 00:19:14.920]   did not want to let
[00:19:14.920 --> 00:19:15.820]   Chinese companies
[00:19:15.820 --> 00:19:16.600]   get their hands
[00:19:16.600 --> 00:19:18.500]   on more powerful chips.
[00:19:18.500 --> 00:19:19.900]   One after another,
[00:19:19.900 --> 00:19:21.280]   restrictions were introduced
[00:19:21.280 --> 00:19:22.880]   by the Biden administration
[00:19:22.880 --> 00:19:23.860]   to stop China
[00:19:23.860 --> 00:19:25.300]   getting the compute
[00:19:25.300 --> 00:19:26.100]   that it wanted.
[00:19:26.100 --> 00:19:27.400]   Nvidia tried to
[00:19:27.400 --> 00:19:28.120]   wriggle its way
[00:19:28.120 --> 00:19:29.200]   past these restrictions
[00:19:29.200 --> 00:19:30.840]   by inventing new chips
[00:19:30.840 --> 00:19:31.820]   that scraped
[00:19:31.820 --> 00:19:32.780]   under these limits.
[00:19:32.780 --> 00:19:33.620]   But each time
[00:19:33.620 --> 00:19:35.060]   a new restriction followed.
[00:19:35.060 --> 00:19:36.840]   As Liang himself said
[00:19:36.840 --> 00:19:38.400]   in the summer of 2024,
[00:19:38.400 --> 00:19:39.960]   money has never been
[00:19:39.960 --> 00:19:41.020]   the problem for us.
[00:19:41.020 --> 00:19:42.580]   Bands on shipments
[00:19:42.580 --> 00:19:43.320]   of advanced chips
[00:19:43.320 --> 00:19:44.520]   chips are the problem.
[00:19:44.520 --> 00:19:45.620]   That's the context.
[00:19:45.620 --> 00:19:47.520]   The march to more powerful AI
[00:19:47.520 --> 00:19:48.760]   was now being framed
[00:19:48.760 --> 00:19:49.820]   as a race,
[00:19:49.820 --> 00:19:50.980]   even a, quote,
[00:19:50.980 --> 00:19:51.500]   war.
[00:19:51.500 --> 00:19:52.900]   That perhaps inevitably
[00:19:52.900 --> 00:19:54.340]   kicked off a spree
[00:19:54.340 --> 00:19:55.460]   of smuggling
[00:19:55.460 --> 00:19:57.080]   worthy of a spy movie,
[00:19:57.080 --> 00:19:58.860]   with Singapore and Malaysia
[00:19:58.860 --> 00:20:00.140]   as focal points
[00:20:00.140 --> 00:20:01.420]   for Chinese companies
[00:20:01.420 --> 00:20:02.220]   getting chips
[00:20:02.220 --> 00:20:03.680]   past the new blockade.
[00:20:03.680 --> 00:20:04.460]   Think of this,
[00:20:04.460 --> 00:20:06.300]   some of the GPUs
[00:20:06.300 --> 00:20:07.240]   used in China
[00:20:07.240 --> 00:20:09.080]   to calculate R1's, say,
[00:20:09.080 --> 00:20:10.700]   recipe for Ratatouille,
[00:20:10.700 --> 00:20:12.680]   were apparently smuggled there
[00:20:12.680 --> 00:20:13.800]   in suitcases
[00:20:13.800 --> 00:20:15.320]   with, I would guess,
[00:20:15.320 --> 00:20:16.480]   little space left
[00:20:16.480 --> 00:20:17.560]   for spare socks.
[00:20:17.560 --> 00:20:18.540]   And this brings us
[00:20:18.540 --> 00:20:20.360]   to the end of 2024
[00:20:20.360 --> 00:20:22.180]   with the stage almost set.
[00:20:22.180 --> 00:20:23.140]   Liang Wenfeng
[00:20:23.140 --> 00:20:25.060]   toiling in his Hangzhou office,
[00:20:25.060 --> 00:20:26.960]   reputedly reading papers,
[00:20:26.960 --> 00:20:27.880]   writing code,
[00:20:27.880 --> 00:20:28.900]   and participating
[00:20:28.900 --> 00:20:29.900]   in group discussions,
[00:20:29.900 --> 00:20:31.720]   just like every other researcher
[00:20:31.720 --> 00:20:32.400]   at DeepSeek,
[00:20:32.400 --> 00:20:33.320]   well into the night.
[00:20:33.320 --> 00:20:34.140]   that company
[00:20:34.140 --> 00:20:35.920]   now in the line of sight
[00:20:35.920 --> 00:20:37.620]   of AI industry insiders,
[00:20:37.620 --> 00:20:39.060]   but virtually unknown
[00:20:39.060 --> 00:20:39.840]   to the public
[00:20:39.840 --> 00:20:40.720]   outside of China.
[00:20:40.720 --> 00:20:42.000]   A whale rising,
[00:20:42.000 --> 00:20:44.240]   but still just beneath the surface
[00:20:44.240 --> 00:20:45.820]   as a new year dawned.
[00:20:45.820 --> 00:21:01.620]   Liang Wenfeng
[00:21:01.620 --> 00:21:02.760]   was tired
[00:21:02.760 --> 00:21:03.780]   of the West
[00:21:03.780 --> 00:21:04.920]   inventing things
[00:21:04.920 --> 00:21:05.940]   and China
[00:21:05.940 --> 00:21:06.960]   swooping in
[00:21:06.960 --> 00:21:07.620]   to imitate
[00:21:07.620 --> 00:21:08.900]   and monetize
[00:21:08.900 --> 00:21:09.760]   those innovations.
[00:21:09.760 --> 00:21:11.220]   What's more surprising though
[00:21:11.220 --> 00:21:12.420]   is that he publicly
[00:21:12.420 --> 00:21:13.300]   said as much.
[00:21:13.300 --> 00:21:14.300]   China should
[00:21:14.300 --> 00:21:15.360]   gradually become
[00:21:15.360 --> 00:21:16.400]   a contributor
[00:21:16.400 --> 00:21:17.540]   instead of free riding,
[00:21:17.540 --> 00:21:18.080]   he said,
[00:21:18.080 --> 00:21:19.240]   in his last known
[00:21:19.240 --> 00:21:19.940]   media interview.
[00:21:19.940 --> 00:21:20.720]   He went on
[00:21:20.720 --> 00:21:22.000]   to directly cite
[00:21:22.000 --> 00:21:23.500]   the scaling law,
[00:21:23.500 --> 00:21:24.840]   an empirical finding
[00:21:24.840 --> 00:21:25.560]   first made
[00:21:25.560 --> 00:21:26.360]   in Silicon Valley
[00:21:26.360 --> 00:21:27.440]   that language models
[00:21:27.440 --> 00:21:28.800]   get predictably better
[00:21:28.800 --> 00:21:29.600]   the more parameters
[00:21:29.600 --> 00:21:30.100]   they had
[00:21:30.100 --> 00:21:30.560]   and the more
[00:21:30.560 --> 00:21:31.480]   high quality data
[00:21:31.480 --> 00:21:32.340]   they train on.
[00:21:32.340 --> 00:21:32.960]   In the past
[00:21:32.960 --> 00:21:33.920]   30 plus years
[00:21:33.920 --> 00:21:35.060]   of the IT wave,
[00:21:35.060 --> 00:21:35.760]   Liang said,
[00:21:35.760 --> 00:21:36.340]   of China,
[00:21:36.340 --> 00:21:37.380]   we basically
[00:21:37.380 --> 00:21:38.280]   didn't participate
[00:21:38.280 --> 00:21:39.380]   in real
[00:21:39.380 --> 00:21:40.580]   technological innovation.
[00:21:40.580 --> 00:21:41.700]   We're used to
[00:21:41.700 --> 00:21:42.340]   Moore's law
[00:21:42.340 --> 00:21:43.560]   falling out of the sky,
[00:21:43.560 --> 00:21:44.520]   lying at home
[00:21:44.520 --> 00:21:45.520]   waiting 18 months
[00:21:45.520 --> 00:21:46.360]   for better hardware
[00:21:46.360 --> 00:21:47.020]   and software
[00:21:47.020 --> 00:21:47.800]   to emerge.
[00:21:47.800 --> 00:21:49.140]   That is how
[00:21:49.140 --> 00:21:50.640]   the scaling law
[00:21:50.640 --> 00:21:51.560]   is being treated.
[00:21:51.560 --> 00:21:52.300]   No,
[00:21:52.300 --> 00:21:53.200]   Liang wanted
[00:21:53.200 --> 00:21:53.780]   DeepSeek
[00:21:53.780 --> 00:21:55.100]   to be a pioneer
[00:21:55.100 --> 00:21:56.460]   that gave away
[00:21:56.460 --> 00:21:57.260]   its research
[00:21:57.260 --> 00:21:58.440]   which others
[00:21:58.440 --> 00:21:59.140]   could then learn
[00:21:59.140 --> 00:22:00.480]   from and adapt.
[00:22:00.480 --> 00:22:01.920]   In the dying days
[00:22:01.920 --> 00:22:02.840]   of 2024,
[00:22:02.840 --> 00:22:04.060]   DeepSeek produced
[00:22:04.060 --> 00:22:05.820]   DeepSeek V3.
[00:22:05.820 --> 00:22:06.880]   It was the bringing
[00:22:06.880 --> 00:22:08.120]   together and scaling
[00:22:08.120 --> 00:22:09.480]   up of all the innovations
[00:22:09.480 --> 00:22:10.580]   you have already heard
[00:22:10.580 --> 00:22:12.220]   about as well as others.
[00:22:12.220 --> 00:22:13.140]   Why not throw in
[00:22:13.140 --> 00:22:14.460]   some mixed precision
[00:22:14.460 --> 00:22:15.300]   training wherein
[00:22:15.300 --> 00:22:16.000]   your obsession
[00:22:16.000 --> 00:22:16.680]   with efficiency
[00:22:16.680 --> 00:22:17.580]   has to reach
[00:22:17.580 --> 00:22:18.740]   such crack addict
[00:22:18.740 --> 00:22:19.680]   levels that you
[00:22:19.680 --> 00:22:20.700]   handwrite code
[00:22:20.700 --> 00:22:22.160]   to optimise instructions
[00:22:22.160 --> 00:22:23.340]   to the NVIDIA GPU
[00:22:23.340 --> 00:22:24.780]   itself rather than
[00:22:24.780 --> 00:22:25.720]   relying on the
[00:22:25.720 --> 00:22:27.040]   popular CUDA libraries
[00:22:27.040 --> 00:22:28.140]   that NVIDIA provides
[00:22:28.140 --> 00:22:28.480]   for you.
[00:22:28.480 --> 00:22:29.380]   With V3,
[00:22:29.380 --> 00:22:30.700]   DeepSeek's coal picks
[00:22:30.700 --> 00:22:32.020]   were almost worn
[00:22:32.020 --> 00:22:33.420]   blunt from finding
[00:22:33.420 --> 00:22:34.520]   nuggets of efficiency.
[00:22:34.520 --> 00:22:35.880]   And though the hour
[00:22:35.880 --> 00:22:36.420]   was late,
[00:22:36.420 --> 00:22:37.120]   Western Labs
[00:22:37.120 --> 00:22:38.020]   were at last
[00:22:38.020 --> 00:22:39.040]   scrambling teams
[00:22:39.040 --> 00:22:40.480]   to study DeepSeek's
[00:22:40.480 --> 00:22:41.120]   breakthroughs.
[00:22:41.120 --> 00:22:41.900]   Dario Amadei,
[00:22:41.900 --> 00:22:42.900]   CEO of Anthropic,
[00:22:42.900 --> 00:22:43.700]   said that
[00:22:43.700 --> 00:22:45.340]   DeepSeek's V3
[00:22:45.340 --> 00:22:46.140]   was actually
[00:22:46.140 --> 00:22:47.180]   the real innovation
[00:22:47.180 --> 00:22:48.000]   and what
[00:22:48.000 --> 00:22:48.540]   should,
[00:22:48.540 --> 00:22:49.100]   he said,
[00:22:49.100 --> 00:22:50.020]   have made people
[00:22:50.020 --> 00:22:50.660]   take notice
[00:22:50.660 --> 00:22:51.360]   a month ago.
[00:22:51.360 --> 00:22:52.500]   We certainly did.
[00:22:52.500 --> 00:22:53.380]   DeepSeek knew
[00:22:53.380 --> 00:22:54.020]   to keep digging
[00:22:54.020 --> 00:22:54.560]   though because
[00:22:54.560 --> 00:22:55.740]   OpenAI had shown
[00:22:55.740 --> 00:22:56.400]   that there was
[00:22:56.400 --> 00:22:57.540]   gold just ahead.
[00:22:57.540 --> 00:22:58.420]   In September of
[00:22:58.420 --> 00:22:59.060]   2024,
[00:22:59.060 --> 00:23:00.380]   OpenAI had showcased
[00:23:00.380 --> 00:23:01.200]   a new type
[00:23:01.200 --> 00:23:01.820]   of reinforcement
[00:23:01.820 --> 00:23:02.580]   learning that
[00:23:02.580 --> 00:23:03.500]   utilised the
[00:23:03.500 --> 00:23:04.420]   chains of thought
[00:23:04.420 --> 00:23:05.140]   a model produces
[00:23:05.140 --> 00:23:06.260]   before it submits
[00:23:06.260 --> 00:23:07.040]   a final answer.
[00:23:07.040 --> 00:23:07.780]   As we've seen,
[00:23:07.780 --> 00:23:08.780]   a model whose goal
[00:23:08.780 --> 00:23:09.300]   is to predict
[00:23:09.300 --> 00:23:10.080]   what a human on
[00:23:10.080 --> 00:23:10.900]   the web might say
[00:23:10.900 --> 00:23:11.780]   next will always
[00:23:11.780 --> 00:23:12.820]   be limited in
[00:23:12.820 --> 00:23:13.300]   capability.
[00:23:13.300 --> 00:23:14.480]   The O series
[00:23:14.480 --> 00:23:15.300]   from OpenAI
[00:23:15.300 --> 00:23:16.260]   showed that if
[00:23:16.260 --> 00:23:17.280]   instead you first
[00:23:17.280 --> 00:23:18.060]   induce the model
[00:23:18.060 --> 00:23:19.140]   to reason out loud,
[00:23:19.140 --> 00:23:20.620]   then apply brutal
[00:23:20.620 --> 00:23:21.280]   optimisation
[00:23:21.280 --> 00:23:22.260]   pressure in favour
[00:23:22.260 --> 00:23:23.240]   of those outputs
[00:23:23.240 --> 00:23:24.880]   that match verifiably
[00:23:24.880 --> 00:23:25.880]   correct answers
[00:23:25.880 --> 00:23:26.760]   in domains like
[00:23:26.760 --> 00:23:27.720]   mathematics and coding,
[00:23:27.720 --> 00:23:29.660]   you thereby optimise
[00:23:29.660 --> 00:23:30.500]   for the most
[00:23:30.500 --> 00:23:32.080]   technically accurate
[00:23:32.080 --> 00:23:32.740]   continuation
[00:23:32.740 --> 00:23:34.680]   and unveil a whole
[00:23:34.680 --> 00:23:35.680]   new terrain of
[00:23:35.680 --> 00:23:36.540]   reasoning progress
[00:23:36.540 --> 00:23:37.300]   to be explored.
[00:23:37.300 --> 00:23:38.400]   Because of
[00:23:38.400 --> 00:23:39.500]   Liang Wenfeng,
[00:23:39.500 --> 00:23:40.840]   DeepSeek was there
[00:23:40.840 --> 00:23:41.780]   ready and waiting,
[00:23:41.780 --> 00:23:42.920]   pick in hand.
[00:23:42.920 --> 00:23:43.800]   Adding this
[00:23:43.800 --> 00:23:44.520]   think-out-loud
[00:23:44.520 --> 00:23:45.400]   reasoning innovation
[00:23:45.400 --> 00:23:46.360]   on top of their
[00:23:46.360 --> 00:23:47.660]   V3-based model
[00:23:47.660 --> 00:23:49.200]   produced DeepSeek
[00:23:49.200 --> 00:23:50.840]   R1-0.
[00:23:50.840 --> 00:23:51.640]   Yes,
[00:23:51.640 --> 00:23:52.120]   zero,
[00:23:52.120 --> 00:23:52.760]   but the thoughts
[00:23:52.760 --> 00:23:53.520]   of that model
[00:23:53.520 --> 00:23:54.280]   could be a little
[00:23:54.280 --> 00:23:55.360]   wayward in language
[00:23:55.360 --> 00:23:55.920]   and style,
[00:23:55.920 --> 00:23:56.640]   so with some
[00:23:56.640 --> 00:23:57.360]   further tweaks
[00:23:57.360 --> 00:23:58.420]   and fine-tuning,
[00:23:58.420 --> 00:23:59.580]   DeepSeek could
[00:23:59.580 --> 00:24:01.060]   unveil DeepSeek
[00:24:01.060 --> 00:24:02.060]   R1,
[00:24:02.060 --> 00:24:04.220]   the AI that has
[00:24:04.220 --> 00:24:05.360]   billions of people
[00:24:05.360 --> 00:24:05.800]   talking.
[00:24:05.800 --> 00:24:06.700]   In many technical
[00:24:06.700 --> 00:24:07.180]   benchmarks,
[00:24:07.180 --> 00:24:08.440]   R1 narrowly
[00:24:08.440 --> 00:24:09.520]   surpassed the
[00:24:09.520 --> 00:24:10.380]   performance of the
[00:24:10.380 --> 00:24:11.400]   original O1 model
[00:24:11.400 --> 00:24:12.060]   from OpenAI
[00:24:12.060 --> 00:24:12.720]   in September,
[00:24:12.720 --> 00:24:13.460]   and in others
[00:24:13.460 --> 00:24:14.060]   it was not far
[00:24:14.060 --> 00:24:14.480]   behind.
[00:24:14.480 --> 00:24:15.620]   By being open
[00:24:15.620 --> 00:24:16.540]   with their research,
[00:24:16.540 --> 00:24:17.520]   DeepSeek showed
[00:24:17.520 --> 00:24:18.380]   the world how
[00:24:18.380 --> 00:24:19.580]   language models,
[00:24:19.580 --> 00:24:20.500]   under that
[00:24:20.500 --> 00:24:21.120]   unrelenting
[00:24:21.120 --> 00:24:22.200]   optimization pressure
[00:24:22.200 --> 00:24:22.660]   to produce
[00:24:22.660 --> 00:24:23.480]   correct answers,
[00:24:23.480 --> 00:24:24.300]   could sometimes
[00:24:24.300 --> 00:24:25.560]   backtrack and
[00:24:25.560 --> 00:24:26.400]   even correct
[00:24:26.400 --> 00:24:26.860]   themselves.
[00:24:26.860 --> 00:24:28.140]   It was an
[00:24:28.140 --> 00:24:29.180]   aha moment
[00:24:29.180 --> 00:24:30.060]   for the models
[00:24:30.060 --> 00:24:31.020]   and for the
[00:24:31.020 --> 00:24:31.900]   world realizing
[00:24:31.900 --> 00:24:32.700]   just how close
[00:24:32.700 --> 00:24:33.400]   a secretive
[00:24:33.400 --> 00:24:34.320]   Chinese lab was
[00:24:34.320 --> 00:24:34.820]   to household
[00:24:34.820 --> 00:24:35.540]   names like
[00:24:35.540 --> 00:24:36.240]   ChatGPT.
[00:24:36.240 --> 00:24:36.860]   Don't get me
[00:24:36.860 --> 00:24:37.120]   wrong,
[00:24:37.120 --> 00:24:37.900]   there were other
[00:24:37.900 --> 00:24:38.980]   innovations in the
[00:24:38.980 --> 00:24:39.680]   DeepSeek R1
[00:24:39.680 --> 00:24:40.300]   paper including
[00:24:40.300 --> 00:24:41.200]   how their biggest
[00:24:41.200 --> 00:24:41.820]   and smartest
[00:24:41.820 --> 00:24:42.420]   models could
[00:24:42.420 --> 00:24:43.660]   effectively distill
[00:24:43.660 --> 00:24:44.400]   much of their
[00:24:44.400 --> 00:24:45.140]   abilities into
[00:24:45.140 --> 00:24:45.800]   smaller models,
[00:24:45.800 --> 00:24:46.560]   saving those
[00:24:46.560 --> 00:24:47.160]   models much of
[00:24:47.160 --> 00:24:47.780]   the work to
[00:24:47.780 --> 00:24:48.160]   get up to
[00:24:48.160 --> 00:24:48.540]   scratch.
[00:24:48.540 --> 00:24:49.580]   The explain it
[00:24:49.580 --> 00:24:50.180]   like I'm 10
[00:24:50.180 --> 00:24:51.060]   of that innovation
[00:24:51.060 --> 00:24:51.960]   is that models
[00:24:51.960 --> 00:24:52.460]   that can fit
[00:24:52.460 --> 00:24:53.120]   onto phones
[00:24:53.120 --> 00:24:53.560]   and home
[00:24:53.560 --> 00:24:54.380]   computers or
[00:24:54.380 --> 00:24:54.880]   served at
[00:24:54.880 --> 00:24:55.600]   incredibly low
[00:24:55.600 --> 00:24:56.020]   cost from
[00:24:56.020 --> 00:24:56.760]   anywhere are
[00:24:56.760 --> 00:24:57.520]   now set in
[00:24:57.520 --> 00:24:58.880]   2025 to be
[00:24:58.880 --> 00:24:59.660]   smarter than
[00:24:59.660 --> 00:25:00.340]   the smartest
[00:25:00.340 --> 00:25:01.080]   giant models
[00:25:01.080 --> 00:25:02.460]   of 2024.
[00:25:02.460 --> 00:25:03.420]   But why the
[00:25:03.420 --> 00:25:04.200]   virality of
[00:25:04.200 --> 00:25:05.100]   DeepSeek R1?
[00:25:05.100 --> 00:25:05.780]   Was it the
[00:25:05.780 --> 00:25:06.280]   fact that you
[00:25:06.280 --> 00:25:06.900]   could see those
[00:25:06.900 --> 00:25:07.580]   thoughts in the
[00:25:07.580 --> 00:25:08.400]   DeepSeek chat
[00:25:08.400 --> 00:25:09.080]   that made the
[00:25:09.080 --> 00:25:09.820]   model so compelling?
[00:25:09.820 --> 00:25:10.720]   Or the fact that
[00:25:10.720 --> 00:25:11.460]   it was so cheap
[00:25:11.460 --> 00:25:12.180]   that caused
[00:25:12.180 --> 00:25:13.240]   Nvidia stocks to
[00:25:13.240 --> 00:25:14.360]   plunge by almost
[00:25:14.360 --> 00:25:15.140]   half a trillion
[00:25:15.140 --> 00:25:15.640]   dollars?
[00:25:15.640 --> 00:25:16.600]   Liang had said
[00:25:16.600 --> 00:25:17.340]   himself by the
[00:25:17.340 --> 00:25:18.180]   way that he
[00:25:18.180 --> 00:25:19.220]   quote didn't expect
[00:25:19.220 --> 00:25:20.220]   pricing to be so
[00:25:20.220 --> 00:25:20.880]   sensitive to
[00:25:20.880 --> 00:25:21.200]   everyone.
[00:25:21.200 --> 00:25:22.200]   Okay was it
[00:25:22.200 --> 00:25:23.100]   DeepSeek's openness
[00:25:23.100 --> 00:25:23.600]   that was so
[00:25:23.600 --> 00:25:23.960]   shocking?
[00:25:23.960 --> 00:25:24.780]   A hundred
[00:25:24.780 --> 00:25:25.760]   narratives have
[00:25:25.760 --> 00:25:26.620]   bloomed in the
[00:25:26.620 --> 00:25:27.420]   days and weeks
[00:25:27.420 --> 00:25:28.280]   after the release
[00:25:28.280 --> 00:25:29.340]   of DeepSeek R1
[00:25:29.340 --> 00:25:31.020]   but not all of
[00:25:31.020 --> 00:25:31.940]   them are as
[00:25:31.940 --> 00:25:32.500]   they seem.
[00:25:32.500 --> 00:25:33.620]   First let's
[00:25:33.620 --> 00:25:34.220]   address those
[00:25:34.220 --> 00:25:34.640]   chains of
[00:25:34.640 --> 00:25:34.920]   thought.
[00:25:34.920 --> 00:25:35.620]   In hindsight
[00:25:35.620 --> 00:25:36.520]   it might seem
[00:25:36.520 --> 00:25:37.500]   obvious that
[00:25:37.500 --> 00:25:38.420]   gaining privileged
[00:25:38.420 --> 00:25:39.240]   access to a
[00:25:39.240 --> 00:25:40.280]   model's thoughts
[00:25:40.280 --> 00:25:41.140]   was always going
[00:25:41.140 --> 00:25:41.940]   to stand out
[00:25:41.940 --> 00:25:42.440]   in a crowded
[00:25:42.440 --> 00:25:42.880]   market.
[00:25:42.880 --> 00:25:44.000]   OpenAI only
[00:25:44.000 --> 00:25:45.200]   gave sanitized
[00:25:45.200 --> 00:25:46.260]   summaries of its
[00:25:46.260 --> 00:25:47.080]   O1 model's
[00:25:47.080 --> 00:25:48.080]   thoughts after all.
[00:25:48.080 --> 00:25:48.560]   But wait,
[00:25:48.560 --> 00:25:49.700]   within hours of
[00:25:49.700 --> 00:25:50.700]   the R1 release
[00:25:50.700 --> 00:25:51.680]   Google had given
[00:25:51.680 --> 00:25:53.360]   us Gemini 2.0
[00:25:53.360 --> 00:25:54.160]   flash thinking,
[00:25:54.160 --> 00:25:55.320]   a model that
[00:25:55.320 --> 00:25:56.040]   showed its
[00:25:56.040 --> 00:25:56.460]   thoughts.
[00:25:56.460 --> 00:25:57.380]   That model's
[00:25:57.380 --> 00:25:58.080]   impact on the
[00:25:58.080 --> 00:25:58.920]   scene can best
[00:25:58.920 --> 00:26:00.000]   be described as
[00:26:00.000 --> 00:26:01.240]   a cute ripple
[00:26:01.240 --> 00:26:02.500]   next to R1
[00:26:02.500 --> 00:26:03.040]   tsunami.
[00:26:03.040 --> 00:26:03.820]   So it must have
[00:26:03.820 --> 00:26:04.420]   been the price,
[00:26:04.420 --> 00:26:04.700]   right?
[00:26:04.700 --> 00:26:05.180]   by some
[00:26:05.180 --> 00:26:06.240]   metrics R1's
[00:26:06.240 --> 00:26:07.860]   95% cheaper than
[00:26:07.860 --> 00:26:08.940]   competitively capable
[00:26:08.940 --> 00:26:09.600]   models from
[00:26:09.600 --> 00:26:10.000]   OpenAI.
[00:26:10.000 --> 00:26:10.860]   But wait,
[00:26:10.860 --> 00:26:12.620]   Gemini 2 flash is
[00:26:12.620 --> 00:26:13.260]   even cheaper.
[00:26:13.260 --> 00:26:14.200]   And again,
[00:26:14.200 --> 00:26:15.500]   just a polite
[00:26:15.500 --> 00:26:16.280]   round of applause.
[00:26:16.280 --> 00:26:16.840]   Okay,
[00:26:16.840 --> 00:26:17.380]   maybe it's the
[00:26:17.380 --> 00:26:17.880]   fact that the
[00:26:17.880 --> 00:26:18.900]   model cost just
[00:26:18.900 --> 00:26:20.160]   $6 million to
[00:26:20.160 --> 00:26:20.520]   train,
[00:26:20.520 --> 00:26:21.340]   which is a
[00:26:21.340 --> 00:26:22.440]   measly sum in
[00:26:22.440 --> 00:26:23.180]   the circumstances.
[00:26:23.180 --> 00:26:24.000]   Well,
[00:26:24.000 --> 00:26:24.600]   on that,
[00:26:24.600 --> 00:26:25.380]   let's take a
[00:26:25.380 --> 00:26:26.120]   moment to at
[00:26:26.120 --> 00:26:26.920]   least hear out
[00:26:26.920 --> 00:26:27.820]   the argument from
[00:26:27.820 --> 00:26:28.580]   the leaders of
[00:26:28.580 --> 00:26:28.980]   the Western
[00:26:28.980 --> 00:26:29.900]   labs on price,
[00:26:29.900 --> 00:26:30.760]   even if you have
[00:26:30.760 --> 00:26:31.720]   reason to doubt
[00:26:31.720 --> 00:26:32.460]   their motivation.
[00:26:32.800 --> 00:26:33.680]   Anthropix CEO
[00:26:33.680 --> 00:26:34.500]   Dario Amadei
[00:26:34.500 --> 00:26:35.660]   first responded by
[00:26:35.660 --> 00:26:36.560]   describing how
[00:26:36.560 --> 00:26:37.640]   costs had already
[00:26:37.640 --> 00:26:38.520]   been consistently
[00:26:38.520 --> 00:26:40.060]   dropping 4x per
[00:26:40.060 --> 00:26:41.160]   year for the
[00:26:41.160 --> 00:26:41.860]   same amount of
[00:26:41.860 --> 00:26:42.600]   model capability.
[00:26:42.600 --> 00:26:43.720]   He even wrote a
[00:26:43.720 --> 00:26:44.720]   full article to
[00:26:44.720 --> 00:26:45.720]   in part clarify
[00:26:45.720 --> 00:26:46.280]   that,
[00:26:46.280 --> 00:26:46.680]   quote,
[00:26:46.680 --> 00:26:47.640]   even if you take
[00:26:47.640 --> 00:26:48.480]   DeepSeq's training
[00:26:48.480 --> 00:26:49.200]   costs at face
[00:26:49.200 --> 00:26:49.660]   value,
[00:26:49.660 --> 00:26:50.880]   they are on
[00:26:50.880 --> 00:26:51.860]   trend at best
[00:26:51.860 --> 00:26:52.760]   and probably not
[00:26:52.760 --> 00:26:53.320]   even that.
[00:26:53.320 --> 00:26:54.420]   He did admit that
[00:26:54.420 --> 00:26:55.140]   what was different
[00:26:55.140 --> 00:26:56.280]   in his words was
[00:26:56.280 --> 00:26:57.380]   that the company
[00:26:57.380 --> 00:26:58.320]   that was first to
[00:26:58.320 --> 00:26:59.140]   demonstrate the
[00:26:59.140 --> 00:26:59.980]   expected cost
[00:26:59.980 --> 00:27:00.980]   reductions was
[00:27:00.980 --> 00:27:01.500]   Chinese.
[00:27:01.920 --> 00:27:02.920]   DeepSeq's GPU
[00:27:02.920 --> 00:27:04.000]   investments alone
[00:27:04.000 --> 00:27:05.160]   account for more
[00:27:05.160 --> 00:27:07.060]   than $500 million
[00:27:07.060 --> 00:27:08.320]   even after
[00:27:08.320 --> 00:27:09.240]   considering export
[00:27:09.240 --> 00:27:09.720]   controls.
[00:27:09.720 --> 00:27:10.820]   Their total server
[00:27:10.820 --> 00:27:11.700]   capital expenditure
[00:27:11.700 --> 00:27:13.520]   is around $1.6
[00:27:13.520 --> 00:27:13.800]   billion.
[00:27:13.800 --> 00:27:15.080]   Even a $6
[00:27:15.080 --> 00:27:16.360]   million training run
[00:27:16.360 --> 00:27:17.240]   doesn't just appear
[00:27:17.240 --> 00:27:17.900]   from nowhere.
[00:27:17.900 --> 00:27:18.480]   Indeed,
[00:27:18.480 --> 00:27:19.480]   things are getting
[00:27:19.480 --> 00:27:20.500]   so costly for
[00:27:20.500 --> 00:27:21.580]   DeepSeq that even
[00:27:21.580 --> 00:27:22.840]   Liang's vast pockets
[00:27:22.840 --> 00:27:23.600]   are reaching their
[00:27:23.600 --> 00:27:23.980]   limits.
[00:27:23.980 --> 00:27:25.140]   According to reports
[00:27:25.140 --> 00:27:26.120]   from February of
[00:27:26.120 --> 00:27:26.740]   2025,
[00:27:26.740 --> 00:27:28.100]   Liang is considering
[00:27:28.100 --> 00:27:29.480]   raising outside money
[00:27:29.480 --> 00:27:30.320]   for the first time,
[00:27:30.520 --> 00:27:31.100]   potentially from
[00:27:31.100 --> 00:27:31.900]   Alibaba Group
[00:27:31.900 --> 00:27:32.740]   and Chinese
[00:27:32.740 --> 00:27:34.100]   state-affiliated funds.
[00:27:34.100 --> 00:27:35.480]   Why would so much
[00:27:35.480 --> 00:27:36.140]   money be needed?
[00:27:36.140 --> 00:27:36.600]   Well,
[00:27:36.600 --> 00:27:37.520]   it's not just to
[00:27:37.520 --> 00:27:38.820]   serve the tens of
[00:27:38.820 --> 00:27:39.500]   millions of daily
[00:27:39.500 --> 00:27:40.160]   active users
[00:27:40.160 --> 00:27:40.920]   that DeepSeq now
[00:27:40.920 --> 00:27:41.280]   has.
[00:27:41.280 --> 00:27:42.260]   It's to scale
[00:27:42.260 --> 00:27:43.200]   model intelligence
[00:27:43.200 --> 00:27:43.640]   further,
[00:27:43.640 --> 00:27:44.980]   all the way to
[00:27:44.980 --> 00:27:45.700]   AGI,
[00:27:45.700 --> 00:27:46.540]   an artificial
[00:27:46.540 --> 00:27:47.540]   intelligence as
[00:27:47.540 --> 00:27:48.300]   general in
[00:27:48.300 --> 00:27:49.320]   applicability as
[00:27:49.320 --> 00:27:49.700]   our own.
[00:27:49.700 --> 00:27:50.480]   According to
[00:27:50.480 --> 00:27:51.080]   Altman and
[00:27:51.080 --> 00:27:51.560]   Amadei,
[00:27:51.560 --> 00:27:52.720]   tacking on that
[00:27:52.720 --> 00:27:53.520]   think-out-loud
[00:27:53.520 --> 00:27:54.520]   reasoning optimization
[00:27:54.520 --> 00:27:55.800]   to a great
[00:27:55.800 --> 00:27:56.440]   base model
[00:27:56.440 --> 00:27:57.220]   can yield
[00:27:57.220 --> 00:27:58.780]   outsized dividends
[00:27:58.780 --> 00:27:59.700]   at first,
[00:27:59.700 --> 00:28:00.460]   which have
[00:28:00.460 --> 00:28:01.280]   allowed DeepSeq
[00:28:01.280 --> 00:28:01.960]   to catch up.
[00:28:01.960 --> 00:28:03.200]   But to ride
[00:28:03.200 --> 00:28:03.900]   that upward
[00:28:03.900 --> 00:28:04.940]   curve into
[00:28:04.940 --> 00:28:06.000]   the vicinity
[00:28:06.000 --> 00:28:07.020]   of AGI,
[00:28:07.020 --> 00:28:08.540]   you'll need
[00:28:08.540 --> 00:28:09.240]   tens of
[00:28:09.240 --> 00:28:09.680]   billions of
[00:28:09.680 --> 00:28:10.400]   dollars worth
[00:28:10.400 --> 00:28:10.920]   of compute,
[00:28:10.920 --> 00:28:11.700]   they argue.
[00:28:11.700 --> 00:28:12.600]   Amadei wrote,
[00:28:12.900 --> 00:28:13.480]   We're therefore
[00:28:13.480 --> 00:28:13.900]   at an
[00:28:13.900 --> 00:28:14.420]   interesting
[00:28:14.420 --> 00:28:15.500]   crossover point
[00:28:15.500 --> 00:28:16.660]   where it is
[00:28:16.660 --> 00:28:17.980]   temporarily the
[00:28:17.980 --> 00:28:18.860]   case that
[00:28:18.860 --> 00:28:19.740]   several companies
[00:28:19.740 --> 00:28:20.280]   can produce
[00:28:20.280 --> 00:28:20.980]   good reasoning
[00:28:20.980 --> 00:28:21.360]   models.
[00:28:21.360 --> 00:28:22.220]   This will
[00:28:22.220 --> 00:28:23.360]   rapidly cease
[00:28:23.360 --> 00:28:24.060]   to be true
[00:28:24.060 --> 00:28:24.960]   as everyone
[00:28:24.960 --> 00:28:25.880]   moves further
[00:28:25.880 --> 00:28:26.680]   up the
[00:28:26.680 --> 00:28:27.420]   scaling curve
[00:28:27.420 --> 00:28:27.860]   on these
[00:28:27.860 --> 00:28:28.200]   models.
[00:28:28.200 --> 00:28:29.240]   Making AI,
[00:28:29.240 --> 00:28:29.780]   he said,
[00:28:29.780 --> 00:28:30.540]   that is smarter
[00:28:30.540 --> 00:28:31.520]   than almost all
[00:28:31.520 --> 00:28:32.320]   humans at
[00:28:32.320 --> 00:28:33.020]   almost all
[00:28:33.020 --> 00:28:34.180]   things will
[00:28:34.180 --> 00:28:35.260]   require millions
[00:28:35.260 --> 00:28:35.880]   of chips,
[00:28:35.880 --> 00:28:36.860]   tens of
[00:28:36.860 --> 00:28:37.360]   billions of
[00:28:37.360 --> 00:28:38.280]   dollars at
[00:28:38.280 --> 00:28:38.660]   least,
[00:28:38.660 --> 00:28:39.740]   and is most
[00:28:39.740 --> 00:28:40.540]   likely to happen
[00:28:40.540 --> 00:28:42.060]   in 2026,
[00:28:42.480 --> 00:28:43.440]   2027.
[00:28:43.440 --> 00:28:44.300]   Even forgetting
[00:28:44.300 --> 00:28:45.060]   DeepSeq for a
[00:28:45.060 --> 00:28:45.320]   moment,
[00:28:45.320 --> 00:28:46.320]   that is quite
[00:28:46.320 --> 00:28:47.020]   the quote.
[00:28:47.020 --> 00:28:47.960]   If he's right
[00:28:47.960 --> 00:28:48.240]   though,
[00:28:48.240 --> 00:28:48.700]   and it's a
[00:28:48.700 --> 00:28:49.480]   big if,
[00:28:49.480 --> 00:28:50.420]   those Chinese
[00:28:50.420 --> 00:28:51.100]   corporate jet
[00:28:51.100 --> 00:28:51.620]   setters are
[00:28:51.620 --> 00:28:51.940]   going to have
[00:28:51.940 --> 00:28:52.360]   to smuggle
[00:28:52.360 --> 00:28:53.040]   god knows
[00:28:53.040 --> 00:28:53.360]   how many
[00:28:53.360 --> 00:28:54.200]   GPUs under
[00:28:54.200 --> 00:28:54.600]   their pack
[00:28:54.600 --> 00:28:54.980]   pajamas.
[00:28:54.980 --> 00:28:56.440]   But Amadei
[00:28:56.440 --> 00:28:57.440]   has a word
[00:28:57.440 --> 00:28:58.100]   on that.
[00:28:58.100 --> 00:28:59.100]   One billion
[00:28:59.100 --> 00:28:59.760]   dollars of
[00:28:59.760 --> 00:29:00.620]   economic activity
[00:29:00.620 --> 00:29:01.380]   can be hidden,
[00:29:01.380 --> 00:29:02.300]   but it's hard
[00:29:02.300 --> 00:29:02.760]   to hide
[00:29:02.760 --> 00:29:03.240]   a hundred
[00:29:03.240 --> 00:29:03.920]   billion or
[00:29:03.920 --> 00:29:04.400]   even ten
[00:29:04.400 --> 00:29:04.700]   billion.
[00:29:04.700 --> 00:29:05.420]   A million
[00:29:05.420 --> 00:29:06.360]   chips may
[00:29:06.360 --> 00:29:07.000]   also be
[00:29:07.000 --> 00:29:07.560]   physically
[00:29:07.560 --> 00:29:08.420]   difficult to
[00:29:08.420 --> 00:29:08.760]   smuggle.
[00:29:08.760 --> 00:29:09.280]   Without
[00:29:09.280 --> 00:29:09.940]   enough chips,
[00:29:09.940 --> 00:29:10.400]   according to
[00:29:10.400 --> 00:29:10.960]   this argument,
[00:29:10.960 --> 00:29:11.740]   DeepSeq are
[00:29:11.740 --> 00:29:12.400]   R2 and
[00:29:12.400 --> 00:29:13.420]   R3 can't
[00:29:13.420 --> 00:29:14.020]   help but
[00:29:14.020 --> 00:29:14.680]   fall behind.
[00:29:14.680 --> 00:29:15.420]   We simply
[00:29:15.420 --> 00:29:15.840]   do not
[00:29:15.840 --> 00:29:16.540]   know if
[00:29:16.540 --> 00:29:17.260]   the DeepSeq
[00:29:17.260 --> 00:29:18.140]   engineers can
[00:29:18.140 --> 00:29:18.820]   keep building
[00:29:18.820 --> 00:29:19.700]   at the pace
[00:29:19.700 --> 00:29:20.060]   of those
[00:29:20.060 --> 00:29:20.700]   working with
[00:29:20.700 --> 00:29:21.420]   billion dollar
[00:29:21.420 --> 00:29:21.860]   bricks.
[00:29:21.860 --> 00:29:22.500]   While we're
[00:29:22.500 --> 00:29:23.020]   on China,
[00:29:23.020 --> 00:29:23.440]   there is
[00:29:23.440 --> 00:29:24.120]   another narrative
[00:29:24.120 --> 00:29:24.800]   that I want
[00:29:24.800 --> 00:29:25.580]   to debunk.
[00:29:25.580 --> 00:29:26.240]   You may have
[00:29:26.240 --> 00:29:27.180]   been told that
[00:29:27.180 --> 00:29:28.060]   DeepSeq is a
[00:29:28.060 --> 00:29:28.740]   one-off and
[00:29:28.740 --> 00:29:29.600]   that China lacks
[00:29:29.600 --> 00:29:30.260]   the environment
[00:29:30.260 --> 00:29:30.920]   to properly
[00:29:30.920 --> 00:29:31.880]   foster innovation
[00:29:31.880 --> 00:29:32.660]   in AI.
[00:29:32.660 --> 00:29:33.120]   Well,
[00:29:33.120 --> 00:29:33.800]   even if you
[00:29:33.800 --> 00:29:34.840]   cast aside the
[00:29:34.840 --> 00:29:35.520]   text-to-image
[00:29:35.520 --> 00:29:36.340]   and text-to-video
[00:29:36.340 --> 00:29:37.360]   wonders produced
[00:29:37.360 --> 00:29:38.160]   by tools like
[00:29:38.160 --> 00:29:38.680]   Kling AI,
[00:29:38.680 --> 00:29:39.600]   you are still
[00:29:39.600 --> 00:29:40.360]   left with a
[00:29:40.360 --> 00:29:41.380]   landscape full
[00:29:41.380 --> 00:29:41.980]   of new models
[00:29:41.980 --> 00:29:43.020]   like Doobao
[00:29:43.020 --> 00:29:44.500]   1.5 Pro from
[00:29:44.500 --> 00:29:45.200]   ByteDance,
[00:29:45.200 --> 00:29:45.700]   makers of
[00:29:45.700 --> 00:29:46.000]   TikTok,
[00:29:46.000 --> 00:29:46.860]   released within
[00:29:46.860 --> 00:29:47.700]   hours actually
[00:29:47.700 --> 00:29:48.440]   of R1.
[00:29:48.440 --> 00:29:48.800]   Oh,
[00:29:48.800 --> 00:29:49.380]   and a week
[00:29:49.380 --> 00:29:50.020]   before that,
[00:29:50.020 --> 00:29:51.140]   we got Spark
[00:29:51.140 --> 00:29:52.040]   Deep Reasoning
[00:29:52.040 --> 00:29:53.060]   X1 from
[00:29:53.060 --> 00:29:54.100]   iFlyTech and
[00:29:54.100 --> 00:29:54.480]   Huawei,
[00:29:54.480 --> 00:29:55.260]   which beats
[00:29:55.260 --> 00:29:55.960]   Western models
[00:29:55.960 --> 00:29:56.820]   at Chinese
[00:29:56.820 --> 00:29:57.620]   technical exams
[00:29:57.620 --> 00:29:58.460]   and is used by
[00:29:58.460 --> 00:29:59.140]   almost 100
[00:29:59.140 --> 00:29:59.800]   million people
[00:29:59.800 --> 00:30:00.220]   already.
[00:30:00.220 --> 00:30:01.000]   And on
[00:30:01.000 --> 00:30:02.220]   January 20th,
[00:30:02.220 --> 00:30:02.840]   the literal
[00:30:02.840 --> 00:30:03.740]   same day that
[00:30:03.740 --> 00:30:04.360]   R1 was
[00:30:04.360 --> 00:30:04.820]   released,
[00:30:04.820 --> 00:30:05.580]   the Chinese
[00:30:05.580 --> 00:30:06.360]   research firm
[00:30:06.360 --> 00:30:07.120]   Moonshot
[00:30:07.120 --> 00:30:07.980]   AI launched
[00:30:07.980 --> 00:30:08.920]   the multimodal
[00:30:08.920 --> 00:30:09.980]   model Kimi
[00:30:09.980 --> 00:30:11.220]   K1.5,
[00:30:11.220 --> 00:30:13.360]   achieving 96.2%
[00:30:13.360 --> 00:30:14.360]   on a popular
[00:30:14.360 --> 00:30:15.360]   math benchmark.
[00:30:15.360 --> 00:30:15.740]   Yes,
[00:30:15.740 --> 00:30:16.380]   that's a better
[00:30:16.380 --> 00:30:16.920]   score than
[00:30:16.920 --> 00:30:17.600]   OpenAI's
[00:30:17.600 --> 00:30:17.980]   O1.
[00:30:17.980 --> 00:30:18.600]   So anyone
[00:30:18.600 --> 00:30:19.140]   saying that
[00:30:19.140 --> 00:30:20.020]   R1 is the
[00:30:20.020 --> 00:30:20.460]   last we're
[00:30:20.460 --> 00:30:20.860]   going to hear
[00:30:20.860 --> 00:30:21.460]   from China
[00:30:21.460 --> 00:30:22.200]   for quite a
[00:30:22.200 --> 00:30:23.260]   while might
[00:30:23.260 --> 00:30:23.620]   well be
[00:30:23.620 --> 00:30:24.300]   getting nervous,
[00:30:24.300 --> 00:30:25.480]   especially with
[00:30:25.480 --> 00:30:26.800]   R2 apparently
[00:30:26.800 --> 00:30:27.360]   imminent.
[00:30:27.360 --> 00:30:27.960]   Now,
[00:30:27.960 --> 00:30:28.840]   I can't
[00:30:28.840 --> 00:30:29.700]   cover present
[00:30:29.700 --> 00:30:30.380]   and future
[00:30:30.380 --> 00:30:31.140]   Chinese language
[00:30:31.140 --> 00:30:31.980]   models without
[00:30:31.980 --> 00:30:33.020]   mentioning another
[00:30:33.020 --> 00:30:33.920]   narrative that
[00:30:33.920 --> 00:30:34.360]   might need
[00:30:34.360 --> 00:30:34.720]   busting.
[00:30:34.720 --> 00:30:35.580]   that the
[00:30:35.580 --> 00:30:36.420]   open nature
[00:30:36.420 --> 00:30:37.120]   of the
[00:30:37.120 --> 00:30:37.880]   DeepSeq R1
[00:30:37.880 --> 00:30:38.820]   paper is
[00:30:38.820 --> 00:30:39.960]   reflected in
[00:30:39.960 --> 00:30:40.560]   the openness
[00:30:40.560 --> 00:30:41.380]   of the model
[00:30:41.380 --> 00:30:41.960]   itself.
[00:30:41.960 --> 00:30:42.760]   Because as
[00:30:42.760 --> 00:30:43.360]   many of you
[00:30:43.360 --> 00:30:43.820]   will know,
[00:30:43.820 --> 00:30:44.620]   the model is
[00:30:44.620 --> 00:30:45.540]   not free to
[00:30:45.540 --> 00:30:46.340]   return outputs
[00:30:46.340 --> 00:30:47.140]   on sensitive
[00:30:47.140 --> 00:30:48.020]   Chinese topics.
[00:30:48.020 --> 00:30:49.040]   Not that it
[00:30:49.040 --> 00:30:49.880]   doesn't know
[00:30:49.880 --> 00:30:50.460]   anything about
[00:30:50.460 --> 00:30:50.960]   them though.
[00:30:50.960 --> 00:30:51.780]   I asked a
[00:30:51.780 --> 00:30:52.380]   simple question,
[00:30:52.380 --> 00:30:53.020]   tell me about
[00:30:53.020 --> 00:30:53.600]   the Uyghurs,
[00:30:53.600 --> 00:30:54.380]   and got this
[00:30:54.380 --> 00:30:55.440]   intriguing set
[00:30:55.440 --> 00:30:56.000]   of thoughts.
[00:30:56.000 --> 00:30:56.960]   This has to
[00:30:56.960 --> 00:30:57.460]   lead to an
[00:30:57.460 --> 00:30:58.340]   illuminating and
[00:30:58.340 --> 00:30:59.220]   deeply reflective
[00:30:59.220 --> 00:30:59.980]   final answer.
[00:30:59.980 --> 00:31:00.620]   We're sure,
[00:31:00.620 --> 00:31:00.900]   right?
[00:31:00.900 --> 00:31:02.780]   Not so much.
[00:31:02.780 --> 00:31:03.560]   Yes,
[00:31:03.560 --> 00:31:04.200]   DeepSeq's
[00:31:04.200 --> 00:31:04.820]   R1 model
[00:31:04.820 --> 00:31:05.560]   was released
[00:31:05.560 --> 00:31:06.400]   under MIT
[00:31:06.400 --> 00:31:06.860]   license,
[00:31:06.860 --> 00:31:07.420]   so of course
[00:31:07.420 --> 00:31:08.520]   others have
[00:31:08.520 --> 00:31:09.240]   been quick to
[00:31:09.240 --> 00:31:09.740]   adapt the
[00:31:09.740 --> 00:31:10.380]   model to,
[00:31:10.380 --> 00:31:11.060]   well,
[00:31:11.060 --> 00:31:11.960]   speak its
[00:31:11.960 --> 00:31:12.380]   truth.
[00:31:12.380 --> 00:31:13.140]   Regardless
[00:31:13.140 --> 00:31:13.500]   though,
[00:31:13.500 --> 00:31:14.360]   I am sure
[00:31:14.360 --> 00:31:15.280]   that this
[00:31:15.280 --> 00:31:15.920]   is a topic
[00:31:15.920 --> 00:31:16.740]   that DeepSeq
[00:31:16.740 --> 00:31:17.340]   and Liang
[00:31:17.340 --> 00:31:17.920]   Wenfeng,
[00:31:17.920 --> 00:31:18.440]   if they're
[00:31:18.440 --> 00:31:18.720]   watching,
[00:31:18.720 --> 00:31:19.960]   are exceptionally
[00:31:19.960 --> 00:31:20.640]   keen for me
[00:31:20.640 --> 00:31:21.140]   to move on
[00:31:21.140 --> 00:31:21.380]   from.
[00:31:21.380 --> 00:31:21.900]   So let's
[00:31:21.900 --> 00:31:22.420]   turn to how
[00:31:22.420 --> 00:31:22.920]   OpenAI
[00:31:22.920 --> 00:31:23.620]   tried,
[00:31:23.620 --> 00:31:24.180]   briefly,
[00:31:24.180 --> 00:31:25.020]   to establish
[00:31:25.020 --> 00:31:25.700]   their own
[00:31:25.700 --> 00:31:26.660]   counter-narrative,
[00:31:26.660 --> 00:31:27.860]   which was that
[00:31:27.860 --> 00:31:28.900]   DeepSeq may
[00:31:28.900 --> 00:31:30.200]   have illicitly
[00:31:30.200 --> 00:31:31.320]   accessed the
[00:31:31.320 --> 00:31:31.860]   chains of
[00:31:31.860 --> 00:31:32.540]   thought of
[00:31:32.540 --> 00:31:33.280]   OpenAI's
[00:31:33.280 --> 00:31:34.000]   O1 model
[00:31:34.000 --> 00:31:35.140]   and trained
[00:31:35.140 --> 00:31:35.480]   on them.
[00:31:35.480 --> 00:31:36.040]   Think of that
[00:31:36.040 --> 00:31:36.680]   as effectively
[00:31:36.680 --> 00:31:37.600]   stealing the
[00:31:37.600 --> 00:31:38.480]   intelligence that
[00:31:38.480 --> 00:31:39.280]   had been so
[00:31:39.280 --> 00:31:40.500]   carefully cultivated
[00:31:40.500 --> 00:31:41.360]   by OpenAI.
[00:31:41.360 --> 00:31:42.480]   A spokesperson
[00:31:42.480 --> 00:31:43.440]   for OpenAI
[00:31:43.440 --> 00:31:43.800]   said,
[00:31:43.940 --> 00:31:44.660]   we know that
[00:31:44.660 --> 00:31:45.160]   groups in
[00:31:45.160 --> 00:31:45.860]   China are
[00:31:45.860 --> 00:31:46.800]   actively working
[00:31:46.800 --> 00:31:47.260]   to use
[00:31:47.260 --> 00:31:47.780]   methods,
[00:31:47.780 --> 00:31:48.600]   including what's
[00:31:48.600 --> 00:31:48.900]   known as
[00:31:48.900 --> 00:31:49.520]   distillation,
[00:31:49.520 --> 00:31:50.300]   to try to
[00:31:50.300 --> 00:31:51.380]   replicate advanced
[00:31:51.380 --> 00:31:52.620]   US AI models.
[00:31:52.620 --> 00:31:53.640]   We are aware
[00:31:53.640 --> 00:31:54.560]   of and reviewing
[00:31:54.560 --> 00:31:55.520]   indications that
[00:31:55.520 --> 00:31:56.180]   DeepSeq may
[00:31:56.180 --> 00:31:57.520]   have inappropriately
[00:31:57.520 --> 00:31:58.160]   distilled our
[00:31:58.160 --> 00:31:58.420]   models.
[00:31:58.420 --> 00:31:58.980]   We take
[00:31:58.980 --> 00:31:59.500]   aggressive,
[00:31:59.500 --> 00:32:00.160]   proactive
[00:32:00.160 --> 00:32:00.800]   countermeasures
[00:32:00.800 --> 00:32:01.760]   to protect our
[00:32:01.760 --> 00:32:02.580]   technology and
[00:32:02.580 --> 00:32:03.260]   will continue
[00:32:03.260 --> 00:32:04.220]   working closely
[00:32:04.220 --> 00:32:04.880]   with the US
[00:32:04.880 --> 00:32:05.520]   government to
[00:32:05.520 --> 00:32:06.020]   protect the
[00:32:06.020 --> 00:32:06.560]   most capable
[00:32:06.560 --> 00:32:07.300]   models being
[00:32:07.300 --> 00:32:07.940]   built here.
[00:32:07.940 --> 00:32:08.540]   Side note,
[00:32:08.540 --> 00:32:09.140]   speaking of
[00:32:09.140 --> 00:32:09.680]   working with the
[00:32:09.680 --> 00:32:10.020]   government,
[00:32:10.020 --> 00:32:10.900]   certain US
[00:32:10.900 --> 00:32:11.660]   lawmakers are
[00:32:11.660 --> 00:32:12.500]   proposing that
[00:32:12.500 --> 00:32:13.560]   US users be
[00:32:13.560 --> 00:32:14.560]   jailed if they
[00:32:14.560 --> 00:32:15.840]   use DeepSeq R1.
[00:32:15.840 --> 00:32:16.660]   Back to the
[00:32:16.660 --> 00:32:17.220]   counter-narrative,
[00:32:17.220 --> 00:32:19.140]   that died in the
[00:32:19.140 --> 00:32:19.940]   public imagination
[00:32:19.940 --> 00:32:21.260]   almost as soon as
[00:32:21.260 --> 00:32:21.840]   it was tried,
[00:32:21.840 --> 00:32:22.840]   for one obvious
[00:32:22.840 --> 00:32:23.220]   reason.
[00:32:23.220 --> 00:32:24.460]   OpenAI themselves
[00:32:24.460 --> 00:32:25.400]   are being sued
[00:32:25.400 --> 00:32:26.100]   by everyone,
[00:32:26.100 --> 00:32:26.880]   including my
[00:32:26.880 --> 00:32:27.540]   second cousin's
[00:32:27.540 --> 00:32:28.340]   estranged grandmother,
[00:32:28.340 --> 00:32:29.500]   for knowingly
[00:32:29.500 --> 00:32:30.340]   training on
[00:32:30.340 --> 00:32:31.380]   copyrighted works
[00:32:31.380 --> 00:32:32.300]   without compensation.
[00:32:32.300 --> 00:32:32.820]   So,
[00:32:32.820 --> 00:32:33.740]   one suspects
[00:32:33.740 --> 00:32:34.960]   few will have
[00:32:34.960 --> 00:32:35.800]   any sympathy
[00:32:35.800 --> 00:32:36.340]   for those
[00:32:36.340 --> 00:32:37.100]   companies if
[00:32:37.100 --> 00:32:37.580]   others,
[00:32:37.580 --> 00:32:38.480]   like DeepSeq,
[00:32:38.480 --> 00:32:39.540]   distill anything
[00:32:39.540 --> 00:32:40.660]   from ChatGPT,
[00:32:40.660 --> 00:32:41.380]   even if they
[00:32:41.380 --> 00:32:41.900]   needed to,
[00:32:41.900 --> 00:32:42.340]   which they
[00:32:42.340 --> 00:32:43.060]   probably didn't
[00:32:43.060 --> 00:32:43.540]   by the way.
[00:32:43.540 --> 00:32:44.260]   Regardless,
[00:32:44.260 --> 00:32:45.460]   reasoning is being
[00:32:45.460 --> 00:32:46.800]   automated at a
[00:32:46.800 --> 00:32:47.820]   breakneck pace.
[00:32:47.820 --> 00:32:49.500]   As hard to believe
[00:32:49.500 --> 00:32:50.720]   as the DeepSeq
[00:32:50.720 --> 00:32:51.480]   rise is,
[00:32:51.480 --> 00:32:52.060]   for me,
[00:32:52.060 --> 00:32:53.220]   it's actually only
[00:32:53.220 --> 00:32:54.680]   a pointer to a
[00:32:54.680 --> 00:32:55.420]   bigger story.
[00:32:55.420 --> 00:32:57.100]   We are actually
[00:32:57.100 --> 00:32:58.760]   entering an era of
[00:32:58.760 --> 00:33:00.160]   automated artificial
[00:33:00.160 --> 00:33:00.880]   intelligence.
[00:33:00.880 --> 00:33:01.500]   And no,
[00:33:01.500 --> 00:33:02.520]   the models will not
[00:33:02.520 --> 00:33:03.440]   always best be
[00:33:03.440 --> 00:33:04.880]   described as tools
[00:33:04.880 --> 00:33:05.780]   akin to a
[00:33:05.780 --> 00:33:06.240]   calculator.
[00:33:06.240 --> 00:33:08.180]   If an AI in
[00:33:08.180 --> 00:33:09.060]   three years time
[00:33:09.060 --> 00:33:10.800]   can do 95% of
[00:33:10.800 --> 00:33:11.380]   my job,
[00:33:11.680 --> 00:33:12.360]   or yours,
[00:33:12.360 --> 00:33:13.380]   at what point
[00:33:13.380 --> 00:33:14.260]   am I just
[00:33:14.260 --> 00:33:15.200]   a tool responsible
[00:33:15.200 --> 00:33:16.440]   only for clicking
[00:33:16.440 --> 00:33:16.860]   submit?
[00:33:16.860 --> 00:33:17.540]   Granted,
[00:33:17.540 --> 00:33:18.800]   we are very much
[00:33:18.800 --> 00:33:19.740]   not there yet,
[00:33:19.740 --> 00:33:20.280]   of course.
[00:33:20.280 --> 00:33:21.560]   It is DeepSeq
[00:33:21.560 --> 00:33:22.640]   R1,
[00:33:22.640 --> 00:33:23.380]   after all.
[00:33:23.380 --> 00:33:24.080]   And yes,
[00:33:24.080 --> 00:33:25.320]   humans are still
[00:33:25.320 --> 00:33:26.600]   just about in the
[00:33:26.600 --> 00:33:27.380]   driving seat.
[00:33:27.380 --> 00:33:28.100]   Meaning,
[00:33:28.100 --> 00:33:28.660]   I guess,
[00:33:28.660 --> 00:33:29.600]   the only thing
[00:33:29.600 --> 00:33:30.680]   absolutely guaranteed
[00:33:30.680 --> 00:33:31.880]   is drama.
[00:33:31.880 --> 00:33:37.420]   That then was the
[00:33:37.420 --> 00:33:38.580]   DeepSeq story as
[00:33:38.580 --> 00:33:39.300]   best we know it.
[00:33:39.300 --> 00:33:40.420]   What is next
[00:33:40.420 --> 00:33:41.240]   though for the
[00:33:41.240 --> 00:33:42.740]   taciturn Liangwenfeng
[00:33:42.740 --> 00:33:43.520]   and his team of
[00:33:43.520 --> 00:33:43.880]   wizards?
[00:33:43.880 --> 00:33:45.480]   The R1 paper hints
[00:33:45.480 --> 00:33:46.720]   that they are deep
[00:33:46.720 --> 00:33:47.520]   in the mind still
[00:33:47.520 --> 00:33:48.460]   working on
[00:33:48.460 --> 00:33:49.760]   infinite context
[00:33:49.760 --> 00:33:51.020]   and a replacement
[00:33:51.020 --> 00:33:51.920]   for the legendary
[00:33:51.920 --> 00:33:53.220]   transformer architecture
[00:33:53.220 --> 00:33:54.520]   behind every famous
[00:33:54.520 --> 00:33:55.060]   language model.
[00:33:55.060 --> 00:33:55.660]   But just take
[00:33:55.660 --> 00:33:56.520]   infinite context,
[00:33:56.740 --> 00:33:57.320]   where we can
[00:33:57.320 --> 00:33:58.020]   imagine a model
[00:33:58.020 --> 00:33:59.000]   provided everything
[00:33:59.000 --> 00:33:59.960]   you have ever heard
[00:33:59.960 --> 00:34:01.120]   or seen or said
[00:34:01.120 --> 00:34:02.300]   and referencing any
[00:34:02.300 --> 00:34:03.060]   of it when it gives
[00:34:03.060 --> 00:34:04.360]   you its next answer.
[00:34:04.360 --> 00:34:05.460]   Will DeepSeq do it?
[00:34:05.460 --> 00:34:06.520]   Will they reach
[00:34:06.520 --> 00:34:07.580]   AGI first?
[00:34:07.580 --> 00:34:08.760]   Would they actually
[00:34:08.760 --> 00:34:09.980]   open source it if so?
[00:34:09.980 --> 00:34:11.040]   Will the world
[00:34:11.040 --> 00:34:12.760]   grasp even a fraction
[00:34:12.760 --> 00:34:13.540]   of what is happening
[00:34:13.540 --> 00:34:14.960]   before that day
[00:34:14.960 --> 00:34:16.280]   or only after?
[00:34:16.280 --> 00:34:17.180]   Well,
[00:34:17.180 --> 00:34:18.560]   it probably won't be
[00:34:18.560 --> 00:34:19.900]   long before we find out.
[00:34:19.900 --> 00:34:21.960]   you
[00:34:21.960 --> 00:34:23.120]   Thank you.

