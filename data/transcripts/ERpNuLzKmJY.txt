
[00:00:00.000 --> 00:00:01.920]   You led the creation of ChatGBT.
[00:00:01.920 --> 00:00:04.160]   At what point did you realize, first of all,
[00:00:04.160 --> 00:00:07.920]   these LLMs are the path to go and then a chatbot would be,
[00:00:07.920 --> 00:00:10.160]   or some way to instruct them would be a useful thing to do?
[00:00:10.160 --> 00:00:13.800]   Before ChatGBT, OpenAI had these instruction following models.
[00:00:13.800 --> 00:00:18.920]   And the idea there was we had base models
[00:00:18.920 --> 00:00:21.920]   and people can prompt them in elaborate ways.
[00:00:21.920 --> 00:00:24.280]   But they're also kind of hard to prompt.
[00:00:24.280 --> 00:00:27.320]   You had to basically do autocomplete.
[00:00:27.320 --> 00:00:30.480]   So you have to set up a very good prompt with some examples.
[00:00:30.480 --> 00:00:36.080]   So people at OpenAI were working on just taking the base models
[00:00:36.080 --> 00:00:38.080]   and making them easier to prompt so that if you just
[00:00:38.080 --> 00:00:40.360]   wrote a question, it would answer the question instead
[00:00:40.360 --> 00:00:43.640]   of giving you more questions or something.
[00:00:43.640 --> 00:00:45.480]   So we had these instruction following models,
[00:00:45.480 --> 00:00:46.980]   which were kind of like base models,
[00:00:46.980 --> 00:00:49.640]   but a little easier to use.
[00:00:49.640 --> 00:00:52.480]   And those are the original ones deployed in the API.
[00:00:52.480 --> 00:00:57.720]   Or after GPT-3, those were the next generation of models.
[00:00:57.720 --> 00:01:00.480]   Then at the same time, there were definitely a lot of people
[00:01:00.480 --> 00:01:03.960]   thinking about chat.
[00:01:03.960 --> 00:01:06.120]   So Google had some papers.
[00:01:06.120 --> 00:01:10.200]   They had Lambda and earlier Mina.
[00:01:10.200 --> 00:01:11.520]   So they had these chatbots.
[00:01:11.520 --> 00:01:16.240]   And it was more like a base model
[00:01:16.240 --> 00:01:19.400]   that was really specialized to the task of chat,
[00:01:19.400 --> 00:01:20.400]   really good at chat.
[00:01:20.400 --> 00:01:24.960]   And I think at least looking at the examples from the paper,
[00:01:24.960 --> 00:01:28.120]   it was more used for fun applications,
[00:01:28.120 --> 00:01:31.880]   like where the model would take on some persona
[00:01:31.880 --> 00:01:33.120]   and pretend to be that persona.
[00:01:33.120 --> 00:01:39.200]   It was not so functional, like help me refactor my code.
[00:01:39.200 --> 00:01:42.000]   So yeah, there are definitely people thinking about chat.
[00:01:42.000 --> 00:01:45.880]   I had worked on a project before looking
[00:01:45.880 --> 00:01:49.160]   at chat called WebGPT, which is more
[00:01:49.160 --> 00:01:52.840]   about doing question answering with the help of web browsing
[00:01:52.840 --> 00:01:53.840]   and retrieval.
[00:01:53.840 --> 00:01:58.000]   And well, when you do question answering,
[00:01:58.000 --> 00:02:02.520]   it really wants to be in a chat, because you always
[00:02:02.520 --> 00:02:04.280]   want to ask follow-up questions.
[00:02:04.280 --> 00:02:07.720]   Or sometimes the model should ask a clarifying question,
[00:02:07.720 --> 00:02:09.320]   because the question is ambiguous.
[00:02:09.320 --> 00:02:11.840]   So it was kind of clear after we did the first version of that
[00:02:11.840 --> 00:02:14.760]   that the next version should be conversational.
[00:02:14.760 --> 00:02:19.560]   So anyway, we started working on a conversational chat
[00:02:19.560 --> 00:02:21.640]   assistant.
[00:02:21.640 --> 00:02:27.680]   And this was built on top of GPD 3.5,
[00:02:27.680 --> 00:02:30.760]   which was done training at the beginning of 2022.
[00:02:30.760 --> 00:02:33.320]   And that model was quite good at language and code.
[00:02:33.320 --> 00:02:35.960]   So we quickly realized that it was actually
[00:02:35.960 --> 00:02:37.120]   quite good at coding help.
[00:02:37.120 --> 00:02:40.440]   And that was one of the things we were excited about.
[00:02:40.440 --> 00:02:45.880]   So yeah, we worked on that for most of the year.
[00:02:45.880 --> 00:02:49.680]   And we had browsing as another feature in it,
[00:02:49.680 --> 00:02:53.000]   though we ended up deemphasizing that later on,
[00:02:53.000 --> 00:02:56.320]   because the model's internal knowledge was so good
[00:02:56.320 --> 00:02:59.360]   that the browsing wasn't the most interesting thing
[00:02:59.360 --> 00:03:00.760]   about it.
[00:03:00.760 --> 00:03:03.440]   And then we were thinking about--
[00:03:03.440 --> 00:03:06.680]   we had it out for beta testing to friends and family
[00:03:06.680 --> 00:03:07.640]   for a while.
[00:03:07.640 --> 00:03:10.920]   And we were thinking about doing a public release.
[00:03:10.920 --> 00:03:14.280]   But at that time, actually, GPD 4
[00:03:14.280 --> 00:03:18.240]   finished training in August or--
[00:03:18.240 --> 00:03:20.280]   yeah, in August that year.
[00:03:20.280 --> 00:03:25.960]   And actually, the flagship RL effort at OpenAI
[00:03:25.960 --> 00:03:27.520]   was the instruction following effort,
[00:03:27.520 --> 00:03:29.880]   because that was the models that were being
[00:03:29.880 --> 00:03:31.360]   deployed into production.
[00:03:31.360 --> 00:03:36.840]   So the first fine tunes of GPD 4 used that whole stack.
[00:03:36.840 --> 00:03:40.680]   And that was-- yeah, those models were really good.
[00:03:40.680 --> 00:03:42.440]   And everyone got really excited about that
[00:03:42.440 --> 00:03:46.440]   after seeing the Instruct fine tune GPD 4s.
[00:03:46.440 --> 00:03:48.320]   But so they were really, really good.
[00:03:48.320 --> 00:03:50.360]   They would occasionally give you amazing outputs.
[00:03:50.360 --> 00:03:52.560]   But they were also a little bit--
[00:03:52.560 --> 00:03:55.400]   the model was clearly pretty unreliable.
[00:03:55.400 --> 00:03:57.360]   It would sometimes hallucinate a lot.
[00:03:57.360 --> 00:03:58.560]   And it was pretty--
[00:03:58.560 --> 00:04:01.040]   it would sometimes give you pretty unhinged outputs.
[00:04:01.040 --> 00:04:03.400]   So it was clearly not quite ready for prime time.
[00:04:03.400 --> 00:04:06.360]   But it was obviously very good.
[00:04:06.360 --> 00:04:09.560]   And yeah, so I guess that--
[00:04:09.560 --> 00:04:12.240]   people forgot about chat for a little while
[00:04:12.240 --> 00:04:16.200]   after that about this alternative branch.
[00:04:16.200 --> 00:04:18.120]   But then we ended up--
[00:04:18.120 --> 00:04:19.000]   we pushed it further.
[00:04:19.000 --> 00:04:21.120]   And we ended up mixing together all the data
[00:04:21.120 --> 00:04:23.320]   sets, like the Instruct and the chat data,
[00:04:23.320 --> 00:04:26.280]   and to try to get something that was the best of both worlds.
[00:04:26.280 --> 00:04:28.720]   And I think the models we--
[00:04:28.720 --> 00:04:34.800]   the chat models were clearly more--
[00:04:34.800 --> 00:04:36.440]   it was easier to use.
[00:04:36.440 --> 00:04:38.400]   It was sort of more--
[00:04:38.400 --> 00:04:41.880]   it sort of automatically had much more sensible behavior
[00:04:41.880 --> 00:04:44.800]   in terms of the model knowing its own limitations.
[00:04:44.800 --> 00:04:46.840]   The other thing about chat was that when
[00:04:46.840 --> 00:04:49.400]   we had these Instruct models, the task
[00:04:49.400 --> 00:04:53.280]   of complete this text, but in a nice way or in a helpful way,
[00:04:53.280 --> 00:04:55.360]   that's a pretty poorly defined task.
[00:04:55.360 --> 00:04:59.000]   So I think that task is both confusing for the model
[00:04:59.000 --> 00:05:01.720]   and for the human who's supposed to do the data labeling.
[00:05:01.760 --> 00:05:06.280]   Whereas for chat, I think people had an intuitive sense of what
[00:05:06.280 --> 00:05:07.960]   a helpful robot should be like.
[00:05:07.960 --> 00:05:10.800]   So I think it was just much easier to tell people--
[00:05:10.800 --> 00:05:17.000]   for people to get the idea of what the model was supposed
[00:05:17.000 --> 00:05:18.560]   to do.
[00:05:18.560 --> 00:05:23.720]   And so as a result, I think the model had a much more coherent
[00:05:23.720 --> 00:05:24.560]   personality.
[00:05:24.560 --> 00:05:31.480]   And it was much easier to get pretty sensible behavior
[00:05:31.480 --> 00:05:32.280]   robustly.
[00:05:32.280 --> 00:05:34.160]   Is it the case that anybody could
[00:05:34.160 --> 00:05:38.200]   have made chat GBT using your publicly available fine tuning
[00:05:38.200 --> 00:05:39.000]   API?
[00:05:39.000 --> 00:05:40.000]   Not exactly.
[00:05:40.000 --> 00:05:43.600]   I mean, they could have--
[00:05:43.600 --> 00:05:45.440]   I don't remember the status of which models
[00:05:45.440 --> 00:05:49.840]   were available for fine tuning.
[00:05:49.840 --> 00:05:53.320]   Assuming we had 3.5 available for fine tuning at the time,
[00:05:53.320 --> 00:05:56.360]   you could have made something pretty decently close.
[00:05:56.360 --> 00:05:58.600]   But I'm not sure you would have--
[00:05:58.600 --> 00:05:59.960]   I don't think you would have been
[00:05:59.960 --> 00:06:02.040]   able to do just one iteration of fine tuning
[00:06:02.040 --> 00:06:05.280]   where you have purely human written data
[00:06:05.280 --> 00:06:06.360]   and you fine tune on that.
[00:06:06.360 --> 00:06:09.640]   I think you would want to do several iterations.
[00:06:09.640 --> 00:06:15.120]   If you're not going to do RL, which we did,
[00:06:15.120 --> 00:06:17.800]   you'd want to do some kind of iterative supervised fine
[00:06:17.800 --> 00:06:20.360]   tuning where you have humans edit the model generated
[00:06:20.360 --> 00:06:21.280]   outputs.
[00:06:21.280 --> 00:06:24.080]   Because it's really hard to get people to--
[00:06:24.080 --> 00:06:26.120]   if you train on human generated data,
[00:06:26.120 --> 00:06:27.520]   even if it's really high quality,
[00:06:27.520 --> 00:06:30.640]   it's just hard for a model to fit that data perfectly.
[00:06:30.640 --> 00:06:33.640]   Because it might not be something
[00:06:33.640 --> 00:06:36.360]   a model is capable of outputting.
[00:06:36.360 --> 00:06:39.360]   So you need to do something iterative that looks
[00:06:39.360 --> 00:06:42.160]   a little bit more like RL.
[00:06:42.160 --> 00:06:44.000]   So I think if you had done that, you
[00:06:44.000 --> 00:06:45.720]   could have gotten something pretty close.
[00:06:45.720 --> 00:06:47.640]   But that would have been kind of non-trivial.
[00:06:47.640 --> 00:06:53.480]   But we also had another instruction following model
[00:06:53.480 --> 00:06:56.200]   trained with RL that was released a little before chat
[00:06:56.200 --> 00:06:56.680]   GBT.
[00:06:56.680 --> 00:07:00.200]   So I think if you put a chat wrapper on that,
[00:07:00.200 --> 00:07:02.120]   you would get something decently close.
[00:07:02.120 --> 00:07:08.920]   But that model, if you just prompted it with chat.
[00:07:08.920 --> 00:07:13.920]   But that model had some differences in strengths.
[00:07:13.920 --> 00:07:16.600]   That model was pretty good at writing and poetry and so forth.
[00:07:16.600 --> 00:07:21.160]   But it wasn't as good at knowing its limitations
[00:07:21.160 --> 00:07:24.680]   and at factuality and so forth.
[00:07:24.680 --> 00:07:34.680]   [BLANK_AUDIO]

