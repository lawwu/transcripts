
[00:00:00.000 --> 00:00:03.600]   anything and everything. All the standard applications that you see of a GPT model,
[00:00:03.600 --> 00:00:07.840]   as applied to whatever their scenario is inside their company. It's the same applications,
[00:00:07.840 --> 00:00:11.920]   but with the benefit of having your data imbued into this model. One thing that we always think
[00:00:11.920 --> 00:00:17.040]   about, or one paradigm that I'm thinking about a lot these days is the idea that these large
[00:00:17.040 --> 00:00:22.240]   language models are really databases. I think of every relational database out there as an exact
[00:00:22.240 --> 00:00:25.760]   version of a database. You have a schema, you have a way of querying data. These large language
[00:00:25.760 --> 00:00:30.080]   models are in some sense soft databases. You can ask them natural language questions. They can find
[00:00:30.080 --> 00:00:35.040]   relationships between data that aren't expressed in a relational database, but might be expressed
[00:00:35.040 --> 00:00:39.200]   if you give it enough data and teach it what text looks like or what language looks like.
[00:00:39.200 --> 00:00:42.960]   And you can query these things like databases or even connect them to databases as well. For me,
[00:00:42.960 --> 00:00:47.760]   I see that as an emerging application area. Just thinking of these not as models, but as these soft
[00:00:47.760 --> 00:00:51.440]   databases that give you the ability to make connections that you could never do if you had
[00:00:51.440 --> 00:00:56.080]   an exact relational databases or fuzzy databases or approximate databases. I'm sure someone will
[00:00:56.080 --> 00:00:57.440]   coin a much cleverer term than that.

