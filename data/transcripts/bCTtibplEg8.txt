
[00:00:00.000 --> 00:00:07.200]   When we designed Vigilite, we built it not just as a language that can be authored by
[00:00:07.200 --> 00:00:13.680]   people, but actually as a language where we can automatically generate visualizations.
[00:00:13.680 --> 00:00:20.480]   And I think that's also what distinguishes it from other languages such as D3 or ggplot.nr.
[00:00:20.480 --> 00:00:27.640]   Because we're in JSON, it is very easy to programmatically generate visualizations.
[00:00:27.640 --> 00:00:30.160]   You're listening to Gradient Dissent.
[00:00:30.160 --> 00:00:34.720]   Today we have Lavanya with us, who's been watching all the interviews in the background,
[00:00:34.720 --> 00:00:38.520]   but we wanted to get her in there asking questions.
[00:00:38.520 --> 00:00:43.160]   And we're talking to Dominique, who's one of the authors of Vigilite.
[00:00:43.160 --> 00:00:47.080]   And we got excited to talk to him because we've been using Vega in our product and we
[00:00:47.080 --> 00:00:51.960]   recently released it, but it solves this huge problem for us where we want to let our users
[00:00:51.960 --> 00:00:57.320]   have complete control over the graphs in a language that makes sense.
[00:00:57.320 --> 00:01:00.920]   And then we discovered Vega and it was a perfect solution to the problem that we had.
[00:01:00.920 --> 00:01:05.480]   And then we talked to Dominique and he had so many interesting ideas about the way machine
[00:01:05.480 --> 00:01:06.880]   learning should be visualized.
[00:01:06.880 --> 00:01:10.360]   And we didn't even realize he came from a visualization background.
[00:01:10.360 --> 00:01:13.080]   So we have a ton of questions to ask him today.
[00:01:13.080 --> 00:01:14.080]   Super excited.
[00:01:14.080 --> 00:01:15.080]   Can't wait.
[00:01:15.080 --> 00:01:20.840]   I think the main thing, or you've done a bunch of impressive stuff, but the thing that is
[00:01:20.840 --> 00:01:24.520]   most exciting for us is that we were one of the authors of Vigilite.
[00:01:24.520 --> 00:01:29.360]   And so I kind of thought maybe the best place to start for some people who don't know even
[00:01:29.360 --> 00:01:33.480]   what Vega is, is just sort of describe what Vega is and what the goals are and then how
[00:01:33.480 --> 00:01:37.080]   Vigilite works within that context.
[00:01:37.080 --> 00:01:38.840]   Yeah.
[00:01:38.840 --> 00:01:44.560]   So the way Vega came to be is that my advisor, Jeff Heer, so Jeff, together with his graduate
[00:01:44.560 --> 00:01:51.640]   students Arvind and Ham, created a declarative way to describe interactions, building on
[00:01:51.640 --> 00:01:58.200]   ideas from functional reactive programming, which is a concept that's been around for
[00:01:58.200 --> 00:01:59.200]   quite a while.
[00:01:59.200 --> 00:02:04.960]   And so they adopted this concept for visualizations to describe not just the visual encodings,
[00:02:04.960 --> 00:02:07.640]   but also the interactions fully declaratively.
[00:02:07.640 --> 00:02:14.720]   And so that then became, I think that was Vega version two at that point.
[00:02:14.720 --> 00:02:20.240]   Vega at that point was still fairly low level in that you had to describe all the details
[00:02:20.240 --> 00:02:28.280]   of the visual encoding, as well as the axes and legends and potential other configuration.
[00:02:28.280 --> 00:02:33.680]   So around the same time, my colleague Ham, who also worked on the first version of Vega,
[00:02:33.680 --> 00:02:39.280]   on this reactive version of Vega, he was working on a visualization recommendation browser
[00:02:39.280 --> 00:02:41.000]   at that point that was called Voyager.
[00:02:41.000 --> 00:02:46.680]   And I helped him with it and we needed a visualization language to do recommendation in.
[00:02:46.680 --> 00:02:52.640]   And so Ham and Jeff talked about the need for a high level visualization language that
[00:02:52.640 --> 00:02:55.760]   you can do a recommendation where you don't have to specify all the details, but really
[00:02:55.760 --> 00:03:00.320]   only what's essential, which is this mapping from data to visual properties.
[00:03:00.320 --> 00:03:05.160]   So I think they talked at the Viz conference in Paris and on the flight back, Jeff hacked
[00:03:05.160 --> 00:03:09.960]   the first version of it, which then I think the code is still where we're building on
[00:03:09.960 --> 00:03:10.960]   today.
[00:03:10.960 --> 00:03:11.960]   That's awesome.
[00:03:11.960 --> 00:03:16.680]   Sorry, before you go too far down this path, I'm going to ask all the dumb questions that
[00:03:16.680 --> 00:03:17.680]   I feel embarrassed to ask.
[00:03:17.680 --> 00:03:24.080]   I mean, I feel like I've heard declarative language for visualization many, many times
[00:03:24.080 --> 00:03:28.400]   and I always kind of nod, but what does declarative really mean?
[00:03:28.400 --> 00:03:35.920]   What would be another way that would be a non-declarative way to describe a visualization?
[00:03:35.920 --> 00:03:40.920]   The biggest distinction between declarative and on the other side is imperative, is that
[00:03:40.920 --> 00:03:47.160]   in a declarative language, you describe what you want, not how you want an algorithm to
[00:03:47.160 --> 00:03:49.080]   execute steps to get to where you want to go.
[00:03:49.080 --> 00:03:54.920]   Good examples of that are HTML and CSS, where you describe what the layout of the page should
[00:03:54.920 --> 00:04:01.480]   be, but you don't tell the layout engine to move something by a couple of pixels and then
[00:04:01.480 --> 00:04:03.200]   move again by a couple of pixels.
[00:04:03.200 --> 00:04:11.680]   Another good example of a declarative language is SQL, or SQL, which is the database query
[00:04:11.680 --> 00:04:17.840]   language that people use to query databases for both analytics or for, let's say, a banking
[00:04:17.840 --> 00:04:19.600]   system, for instance.
[00:04:19.600 --> 00:04:23.320]   And in these declarative queries, you describe what you want the result to be.
[00:04:23.320 --> 00:04:29.440]   So you say, "I want from this table, the tuples or the rows that have these properties."
[00:04:29.440 --> 00:04:32.080]   And you don't describe how you're going to get that.
[00:04:32.080 --> 00:04:36.920]   And that's as opposed to an imperative algorithm where you would have to write the search,
[00:04:36.920 --> 00:04:41.440]   you would know how the data is stored, in what format, whether it's maybe even distributed
[00:04:41.440 --> 00:04:43.160]   on multiple machines or not.
[00:04:43.160 --> 00:04:45.640]   In a declarative language, you only describe what you want.
[00:04:45.640 --> 00:04:51.360]   And then that could run on a small database that's embedded, or it could run on a cluster
[00:04:51.360 --> 00:04:54.240]   of a thousand machines, and you shouldn't have to worry.
[00:04:54.240 --> 00:04:58.680]   And so for visualization, that means you shouldn't have to worry about how the visualization
[00:04:58.680 --> 00:05:03.120]   is drawn, how you draw a pixel here, a rectangle here, or a line there.
[00:05:03.120 --> 00:05:07.360]   No, you just want to say, "I make a chart that encodes these variables."
[00:05:07.360 --> 00:05:10.920]   So I guess how declarative is it?
[00:05:10.920 --> 00:05:14.860]   And I have used VEGA a fair amount, but I think people that are listening or watching
[00:05:14.860 --> 00:05:15.860]   may not have.
[00:05:15.860 --> 00:05:21.000]   So I suppose the most declarative thing might be, "Give me an insight about these variables,"
[00:05:21.000 --> 00:05:23.160]   or "Just compare these variables."
[00:05:23.160 --> 00:05:25.880]   But that might be unsatisfying.
[00:05:25.880 --> 00:05:31.280]   What level are we describing the semantics of what we're doing versus saying, "Hey, give
[00:05:31.280 --> 00:05:32.800]   me these three pixels here."
[00:05:32.800 --> 00:05:36.680]   Do you say exactly the type of plot that you want, or is that inferred?
[00:05:36.680 --> 00:05:39.640]   How do you think about all of that?
[00:05:39.640 --> 00:05:43.240]   The way, what we built on is this concept called the grammar of graphics.
[00:05:43.240 --> 00:05:49.280]   And that is a really cool concept that a lot of languages, even D3, have built on.
[00:05:49.280 --> 00:05:53.480]   And the core idea is that a visualization is not just a particular type, so it's not
[00:05:53.480 --> 00:05:59.520]   just a horizontal bar chart or a bubble chart or a radar plot.
[00:05:59.520 --> 00:06:04.600]   But instead, a visualization is described as a combination of basic building blocks.
[00:06:04.600 --> 00:06:10.300]   Kind of like in language, we have words that we combine using rules, which is a grammar.
[00:06:10.300 --> 00:06:15.960]   And so the words in the grammar of graphics are two things.
[00:06:15.960 --> 00:06:20.560]   One is marks, and the other one is visual encodings.
[00:06:20.560 --> 00:06:27.040]   So a mark is, for instance, a bar or a line or a point.
[00:06:27.040 --> 00:06:34.980]   An encoding is a mapping from data properties to visual properties of that mark.
[00:06:34.980 --> 00:06:42.480]   So for instance, a bar chart is a bar mark that maps some category to X and some continuous
[00:06:42.480 --> 00:06:44.680]   variable to Y.
[00:06:44.680 --> 00:06:46.860]   And that's how you describe a bar chart.
[00:06:46.860 --> 00:06:51.600]   And now I think what's cool about this is, if you want to change from a horizontal to
[00:06:51.600 --> 00:06:57.600]   a vertical bar chart, or some call it a column or a row chart, you don't have to change the
[00:06:57.600 --> 00:06:58.600]   type.
[00:06:58.600 --> 00:07:01.440]   You just swap the channels in the encoding.
[00:07:01.440 --> 00:07:03.120]   I have a question.
[00:07:03.120 --> 00:07:08.080]   So we see so many really messed up charts that people make because people get too excited,
[00:07:08.080 --> 00:07:11.320]   especially when they work with a really powerful visualization tool.
[00:07:11.320 --> 00:07:15.640]   And I feel like you've spent so much of your life designing really good grammar visualizations
[00:07:15.640 --> 00:07:17.520]   and designing a lot of really cool plots.
[00:07:17.520 --> 00:07:23.160]   So what's your recommendation for people, for best practices for designing these visualizations?
[00:07:23.160 --> 00:07:25.420]   I think it is actually making mistakes.
[00:07:25.420 --> 00:07:31.280]   It is trying it out and seeing how difficult is it or how easy is it to read data in a
[00:07:31.280 --> 00:07:32.360]   particular chart.
[00:07:32.360 --> 00:07:36.200]   But before you actually go out and publish that chart and show it to the world, maybe
[00:07:36.200 --> 00:07:39.240]   think about what can I remove from this chart?
[00:07:39.240 --> 00:07:45.600]   I think a visualization is really showing what you want to show when it's showing the
[00:07:45.600 --> 00:07:47.040]   essential of the data.
[00:07:47.040 --> 00:07:50.480]   Very important in any visualization design is following two basic principles.
[00:07:50.480 --> 00:07:54.280]   And these are often called effectiveness and expressiveness.
[00:07:54.280 --> 00:07:56.640]   This goes back to some work from Jacques McKinlay.
[00:07:56.640 --> 00:08:00.080]   He developed actually an automated system to follow these rules.
[00:08:00.080 --> 00:08:04.840]   So these two rules, they're kind of oddly named, but essentially what they boil down
[00:08:04.840 --> 00:08:13.360]   to is first expressiveness means that a visualization should show all the facts in the data, but
[00:08:13.360 --> 00:08:15.960]   not more than that.
[00:08:15.960 --> 00:08:20.920]   So what that means is that a visualization shouldn't imply something about the data that
[00:08:20.920 --> 00:08:22.120]   doesn't exist in the data.
[00:08:22.120 --> 00:08:26.720]   And then effectiveness means make a visualization that's as easily perceivable as possible.
[00:08:26.720 --> 00:08:34.960]   And one rule that you can apply there is to use the most effective channels first.
[00:08:34.960 --> 00:08:40.680]   And the most effective channels are X and Y, or there are like length and positions.
[00:08:40.680 --> 00:08:42.840]   They're the best.
[00:08:42.840 --> 00:08:45.800]   And then afterwards it's like color and size and some other things.
[00:08:45.800 --> 00:08:51.400]   So that's why bar charts, scatter plots, line charts are so popular, or it's so effective
[00:08:51.400 --> 00:08:54.100]   because they are using those very effective channels first.
[00:08:54.100 --> 00:08:57.000]   But there's also, sometimes you have to go beyond effectiveness.
[00:08:57.000 --> 00:09:07.920]   I always wonder, is there any room for fun or novelty in a good visualization?
[00:09:07.920 --> 00:09:12.040]   Yeah, that's a good question.
[00:09:12.040 --> 00:09:16.880]   I like to actually think back to a paper from Tukey and Wilk there.
[00:09:16.880 --> 00:09:22.680]   They've written in the '60s, this one of the famous papers about exploratory analysis and
[00:09:22.680 --> 00:09:23.680]   statistics.
[00:09:23.680 --> 00:09:26.960]   And they talked about the relationship of statistics to visualizations.
[00:09:26.960 --> 00:09:31.640]   And one, so the paper is full of amazing, amazing quotes.
[00:09:31.640 --> 00:09:35.120]   And it's kind of amazing to read this today because almost everything is still true today.
[00:09:35.120 --> 00:09:41.040]   But one of the things they say there is that it's not necessarily important to invent new
[00:09:41.040 --> 00:09:45.520]   visualizations, but think about how we can take the visualizations that we have, or the
[00:09:45.520 --> 00:09:52.560]   essential of the visualizations, and combine them in new ways to fit new opportunities.
[00:09:52.560 --> 00:09:56.320]   And so I think there's a lot of creativity in making visualizations, even the simple
[00:09:56.320 --> 00:10:00.360]   ones, parches, lines, or scatter plots, but combine them in meaningful ways.
[00:10:00.360 --> 00:10:02.520]   Also pre-transforming the data in meaningful ways.
[00:10:02.520 --> 00:10:06.120]   And so there can be a lot of creativity in there.
[00:10:06.120 --> 00:10:11.880]   Do you have a favorite visualization that you think is maybe underused or that you'd
[00:10:11.880 --> 00:10:13.120]   like to see more of?
[00:10:13.120 --> 00:10:16.640]   I think slope charts are kind of amazing.
[00:10:16.640 --> 00:10:17.640]   What's a slope chart?
[00:10:17.640 --> 00:10:18.640]   What's a slope chart?
[00:10:18.640 --> 00:10:20.640]   So naming charts, by the way, is an interesting concept.
[00:10:20.640 --> 00:10:26.800]   If you think about the grammar, then the concept of naming charts is kind of odd.
[00:10:26.800 --> 00:10:30.400]   I'm going to reveal a secret, but at some point I'm going to write a system that automatically
[00:10:30.400 --> 00:10:31.400]   names a chart.
[00:10:31.400 --> 00:10:36.680]   Or the other way around, give it a name and it tells you what the specification is.
[00:10:36.680 --> 00:10:42.640]   But going back to slope charts, a slope chart is, imagine you have two categorical variables,
[00:10:42.640 --> 00:10:48.340]   let's say two years, and you have data for those years.
[00:10:48.340 --> 00:10:51.560]   And now what you could do is plot that as a scatter plot.
[00:10:51.560 --> 00:10:57.640]   So on X you have the years and on Y you have some numerical measure.
[00:10:57.640 --> 00:11:04.560]   You should then draw different categories that exist in both years as colored points.
[00:11:04.560 --> 00:11:08.940]   It's hard to see actually trends between those things, between those different years.
[00:11:08.940 --> 00:11:16.840]   But if instead you just draw a line between them, trends or changes, they just jump out
[00:11:16.840 --> 00:11:17.840]   to you.
[00:11:17.840 --> 00:11:19.020]   And I think it's great.
[00:11:19.020 --> 00:11:25.220]   So wherever you have categorical data and this bipartite graph, and just drawing a line
[00:11:25.220 --> 00:11:28.160]   instead of drawing points is great.
[00:11:28.160 --> 00:11:30.160]   It's called a slope chart?
[00:11:30.160 --> 00:11:31.160]   That's one name.
[00:11:31.160 --> 00:11:32.160]   Cool.
[00:11:32.160 --> 00:11:33.160]   One in the VegaLite gallery.
[00:11:33.160 --> 00:11:36.680]   Yeah, we'll have to link to that.
[00:11:36.680 --> 00:11:44.440]   So I guess, where do you think about the line between VegaLite and Vega?
[00:11:44.440 --> 00:11:47.880]   Is it always super clear what belongs where?
[00:11:47.880 --> 00:11:52.500]   Because I would think a declarative, I mean, they're both in a sense, a declarative language
[00:11:52.500 --> 00:11:53.500]   for charts.
[00:11:53.500 --> 00:11:55.840]   One's just higher level and one's lower level.
[00:11:55.840 --> 00:11:59.240]   So where do you draw the line?
[00:11:59.240 --> 00:12:03.600]   So maybe before we go there, one important thing to keep in mind is that Vega and VegaLite
[00:12:03.600 --> 00:12:05.920]   added something to the ground of graphics.
[00:12:05.920 --> 00:12:10.400]   VegaLite in particular added, for instance, support for interactions.
[00:12:10.400 --> 00:12:13.840]   So something that my colleague Hammond Arbind and I worked together on.
[00:12:13.840 --> 00:12:20.440]   Where we added some other kind of words or language constructs that you can add to make
[00:12:20.440 --> 00:12:21.440]   charts interactive.
[00:12:21.440 --> 00:12:22.440]   And we also add composition.
[00:12:22.440 --> 00:12:27.440]   And so these are high level concepts, which then actually compile from VegaLite to the
[00:12:27.440 --> 00:12:34.360]   lower level Vega into, in this case, layouts and signals, which are these functional reactive
[00:12:34.360 --> 00:12:35.600]   concepts that Vega has.
[00:12:35.600 --> 00:12:39.340]   And so I think that helps me also a little bit understand the difference of where does
[00:12:39.340 --> 00:12:40.420]   what go.
[00:12:40.420 --> 00:12:43.560]   And what is, sorry, composition before I drop that?
[00:12:43.560 --> 00:12:48.280]   Composition is being able to layer charts or concatenate charts.
[00:12:48.280 --> 00:12:53.680]   And we also have a concept called repeat, which is a convenient concatenation.
[00:12:53.680 --> 00:12:54.680]   And then faceting.
[00:12:54.680 --> 00:12:58.320]   Faceting is another word for it is trellis.
[00:12:58.320 --> 00:13:02.540]   It's a way to break down a chart by a categorical variable.
[00:13:02.540 --> 00:13:07.080]   So for instance, if you have data for different countries, you can then draw one histogram
[00:13:07.080 --> 00:13:10.520]   for each country or one scatterplot for each country.
[00:13:10.520 --> 00:13:11.520]   Faceted charts are also great.
[00:13:11.520 --> 00:13:15.760]   And often faceting is a very powerful way if you have an additional categorical variable
[00:13:15.760 --> 00:13:16.760]   to show your data.
[00:13:16.760 --> 00:13:22.680]   So is this where you make, sorry, a whole array or a matrix of charts?
[00:13:22.680 --> 00:13:25.040]   That's what I'm picturing with a faceted chart?
[00:13:25.040 --> 00:13:26.040]   Yeah.
[00:13:26.040 --> 00:13:27.040]   So if you- Like a grid of charts?
[00:13:27.040 --> 00:13:28.040]   Yeah.
[00:13:28.040 --> 00:13:29.040]   I see.
[00:13:29.040 --> 00:13:30.040]   Okay.
[00:13:30.040 --> 00:13:31.040]   Yeah.
[00:13:31.040 --> 00:13:32.040]   Cool.
[00:13:32.040 --> 00:13:33.040]   Cool.
[00:13:33.040 --> 00:13:34.040]   Yeah.
[00:13:34.040 --> 00:13:35.040]   So that's faceting.
[00:13:35.040 --> 00:13:36.040]   Okay.
[00:13:36.040 --> 00:13:37.040]   So that's composition.
[00:13:37.040 --> 00:13:38.040]   And then we talked about, oh, Vega, VegaLite.
[00:13:38.040 --> 00:13:39.040]   Yeah.
[00:13:39.040 --> 00:13:44.160]   So the difference, I think, really between Vega and VegaLite is the abstraction level.
[00:13:44.160 --> 00:13:45.840]   VegaLite compiles to Vega.
[00:13:45.840 --> 00:13:50.600]   So anything that's possible in VegaLite is also possible in Vega because of that.
[00:13:50.600 --> 00:13:54.520]   But it requires about one or two orders of magnitude more code in most cases.
[00:13:54.520 --> 00:13:55.960]   So that's one big difference.
[00:13:55.960 --> 00:13:57.320]   And how do we achieve that?
[00:13:57.320 --> 00:14:02.240]   Well, one, we have higher level mark types in VegaLite.
[00:14:02.240 --> 00:14:06.880]   So for instance, Vega only has a rectangle.
[00:14:06.880 --> 00:14:07.880]   And it has some more.
[00:14:07.880 --> 00:14:09.280]   Vega has rectangles.
[00:14:09.280 --> 00:14:13.720]   VegaLite actually has bars as a concept.
[00:14:13.720 --> 00:14:18.400]   And so if you have that, you can have some defaults associated with that high level mark
[00:14:18.400 --> 00:14:22.640]   type, which you then don't have to manually specify in Vega.
[00:14:22.640 --> 00:14:27.280]   In VegaLite, you don't have to specify it because it gets instantiated in Vega automatically.
[00:14:27.280 --> 00:14:30.840]   And then the other is sensible defaults or smart defaults.
[00:14:30.840 --> 00:14:34.400]   Essentially, you don't have to specify an axis.
[00:14:34.400 --> 00:14:35.800]   We'll make one for you.
[00:14:35.800 --> 00:14:37.000]   If you use the XL1 coding.
[00:14:37.000 --> 00:14:39.040]   If you use color, we'll make a legend for you.
[00:14:39.040 --> 00:14:41.880]   If you use size, we'll make a legend for you.
[00:14:41.880 --> 00:14:44.280]   If you use faceting, we'll make a header for you.
[00:14:44.280 --> 00:14:47.000]   Just kind of like an axis.
[00:14:47.000 --> 00:14:51.640]   In Vega, you have to specify all the details of those marks or of those elements, those
[00:14:51.640 --> 00:14:52.640]   chart elements.
[00:14:52.640 --> 00:14:57.800]   You can still override the defaults in VegaLite, but by default, we will do something.
[00:14:57.800 --> 00:14:59.840]   And that's really what VegaLite is.
[00:14:59.840 --> 00:15:05.560]   It's a high level language and a compiler that compiles from higher level specification
[00:15:05.560 --> 00:15:08.320]   to lower level Vega specification.
[00:15:08.320 --> 00:15:14.680]   Right now, we don't have a way to easily extend the high level concepts we have in Vega.
[00:15:14.680 --> 00:15:16.040]   Sorry, in VegaLite.
[00:15:16.040 --> 00:15:21.280]   We do have a little bit of an extension mechanism where you can add more macros.
[00:15:21.280 --> 00:15:27.960]   So for instance, box plots in VegaLite are just a macro, which actually compiles to a
[00:15:27.960 --> 00:15:31.560]   rectangle, the line and the little ticks at the end.
[00:15:31.560 --> 00:15:34.180]   And there's a bunch of other things that are just macros.
[00:15:34.180 --> 00:15:38.320]   And so one could actually build a language on top of VegaLite.
[00:15:38.320 --> 00:15:39.320]   And people have done that.
[00:15:39.320 --> 00:15:46.120]   Altair, for instance, is a Python wrapper or Python syntax, Python API for generating
[00:15:46.120 --> 00:15:50.480]   VegaLite JSON specifications.
[00:15:50.480 --> 00:15:55.200]   And there's other ones in Elm and in R and somebody made one in Rust and there's one
[00:15:55.200 --> 00:15:56.200]   in JavaScript.
[00:15:56.200 --> 00:15:57.200]   Oh, and Julia.
[00:15:57.200 --> 00:16:00.200]   Yes, there's one in Julia as well.
[00:16:00.200 --> 00:16:03.520]   It's actually a good one.
[00:16:03.520 --> 00:16:07.720]   I guess our comment made me wonder if you have any comments on ggplot.
[00:16:07.720 --> 00:16:11.440]   I feel like that's often a beloved plotting library.
[00:16:11.440 --> 00:16:16.480]   Was that an inspiration for Vega at all or did you have reactions to it?
[00:16:16.480 --> 00:16:21.720]   So ggplot came out a long time before Vega and VegaLite.
[00:16:21.720 --> 00:16:24.200]   And it also builds on the grammar of graphics.
[00:16:24.200 --> 00:16:28.640]   At the time, really was the prime example for an implementation of the grammar of graphics
[00:16:28.640 --> 00:16:31.760]   in any programming language, really.
[00:16:31.760 --> 00:16:35.280]   It uses slightly different terminology from Vega and VegaLite.
[00:16:35.280 --> 00:16:37.880]   ggplot has definitely been a great inspiration.
[00:16:37.880 --> 00:16:44.600]   And we like when I say we, so Pam, Arvind, Jeff and I have talked to Hedley Wickham before.
[00:16:44.600 --> 00:16:46.120]   Yeah, big fans of it.
[00:16:46.120 --> 00:16:51.080]   We actually considered using it for Voyager, but because Voyager was easier built as a
[00:16:51.080 --> 00:16:57.400]   web application, interfacing from a web application to R would have been a lot more overhead than
[00:16:57.400 --> 00:17:00.280]   building our own visualization library.
[00:17:00.280 --> 00:17:02.040]   Totally.
[00:17:02.040 --> 00:17:03.520]   Maybe switching gears a little bit.
[00:17:03.520 --> 00:17:07.280]   One thing I thought was interesting about your background and interest is it's also
[00:17:07.280 --> 00:17:08.280]   machine learning.
[00:17:08.280 --> 00:17:11.240]   And I thought that was pretty interesting and cool.
[00:17:11.240 --> 00:17:15.560]   I wonder if machine learning has informed your thoughts about, well, first, if it's
[00:17:15.560 --> 00:17:18.320]   informed your thoughts about visualizations at all.
[00:17:18.320 --> 00:17:21.440]   And then I'd love to hear about if you have suggestions of visualizations that you think
[00:17:21.440 --> 00:17:24.960]   are helpful in the machine learning process.
[00:17:24.960 --> 00:17:31.040]   Yeah, I think visualization and machine learning are really good fits for each other.
[00:17:31.040 --> 00:17:35.800]   And so I can think of two things that we can talk about, both where visualization is useful
[00:17:35.800 --> 00:17:39.040]   for machine learning and where machine learning is useful for visualization.
[00:17:39.040 --> 00:17:40.040]   Totally, yeah.
[00:17:40.040 --> 00:17:43.240]   Maybe let's start with why visualization for machine learning.
[00:17:43.240 --> 00:17:46.480]   I think one of the most, you can disagree with me there if you want to, one of the most
[00:17:46.480 --> 00:17:50.160]   important things in machine learning is data.
[00:17:50.160 --> 00:17:51.320]   It's not the most important thing.
[00:17:51.320 --> 00:17:53.600]   I think few people would disagree.
[00:17:53.600 --> 00:17:54.600]   Okay.
[00:17:54.600 --> 00:18:00.280]   So because data is so, okay, we can agree that data is essential to machine learning.
[00:18:00.280 --> 00:18:04.520]   If you have bad data, your model is not going to do anything good.
[00:18:04.520 --> 00:18:08.400]   You can still create a bad model with good data, but good data is essential for a good
[00:18:08.400 --> 00:18:09.660]   model.
[00:18:09.660 --> 00:18:15.920]   And so understanding that data that becomes part of your model or gets used to train the
[00:18:15.920 --> 00:18:17.680]   model is really essential.
[00:18:17.680 --> 00:18:22.480]   And I think visualization is a really powerful way there to understand what's in your data
[00:18:22.480 --> 00:18:26.320]   and what's happening there, especially in conjunction with more formal statistics.
[00:18:26.320 --> 00:18:30.920]   But formal statistics are only good when you know what you're really looking for.
[00:18:30.920 --> 00:18:34.640]   When you're still trying to look around, what's in this data, what might be problems with
[00:18:34.640 --> 00:18:39.920]   the data, that's when visualization really, really shines.
[00:18:39.920 --> 00:18:43.880]   And you actually built a library to help with the exploration of data, right?
[00:18:43.880 --> 00:18:44.880]   Yeah.
[00:18:44.880 --> 00:18:52.200]   So Voyager and then Voyager 2 and some other follow-up work from there is a visualization
[00:18:52.200 --> 00:18:54.160]   recommendation browser.
[00:18:54.160 --> 00:18:59.280]   So the idea there is that rather than having to manually create all the visualizations
[00:18:59.280 --> 00:19:04.240]   and go still through this process of deciding which encoding do I want to use and which
[00:19:04.240 --> 00:19:09.480]   mark type do I want to use, just let you browse recommendations and still be able to steer
[00:19:09.480 --> 00:19:10.560]   the recommendations.
[00:19:10.560 --> 00:19:13.960]   So the recommendations shouldn't go too far from where you are.
[00:19:13.960 --> 00:19:18.880]   They should still be close to what you've looked at before, but they should take away
[00:19:18.880 --> 00:19:22.640]   some of that tedium of having to manually specify all the charts.
[00:19:22.640 --> 00:19:25.240]   And the recommendation is great for two things.
[00:19:25.240 --> 00:19:31.760]   One is, yeah, because it makes visualizations less tedious and also it can encourage best
[00:19:31.760 --> 00:19:32.760]   practices.
[00:19:32.760 --> 00:19:37.640]   For instance, a good statistical practice, a good practice, data analysis practice, is
[00:19:37.640 --> 00:19:42.180]   to look at the univariate summaries when you start looking at a dataset.
[00:19:42.180 --> 00:19:47.320]   So what are the distributions of each of my fields, each of my dimensions?
[00:19:47.320 --> 00:19:51.120]   And doing that before looking into correlations between dimensions.
[00:19:51.120 --> 00:19:56.200]   And this is often difficult if you start looking at one field and you're like, "Ah, there's
[00:19:56.200 --> 00:19:57.200]   something interesting here.
[00:19:57.200 --> 00:19:59.320]   Now I wonder how this correlates with this other dataset."
[00:19:59.320 --> 00:20:03.440]   And then you're off on attention.
[00:20:03.440 --> 00:20:12.560]   So by forcing you or by offering you a gallery of all the dimensions and all the univariate
[00:20:12.560 --> 00:20:17.080]   summaries at first, it makes it a lot easier to follow that best practice of looking at
[00:20:17.080 --> 00:20:20.320]   all the univariate summaries first.
[00:20:20.320 --> 00:20:21.720]   Can you do this at scale?
[00:20:21.720 --> 00:20:24.280]   Will it scale to millions of rows?
[00:20:24.280 --> 00:20:28.760]   And how do you even begin if your dataset is that big to find patterns in it?
[00:20:28.760 --> 00:20:31.040]   And how does the software scale to?
[00:20:31.040 --> 00:20:37.920]   Yeah, so the software is built as a research prototype that is built as a browser application
[00:20:37.920 --> 00:20:39.880]   where all the data has to fit into the browser.
[00:20:39.880 --> 00:20:41.280]   So it currently does not scale.
[00:20:41.280 --> 00:20:44.360]   But the interesting thing about it is that the number of rows shouldn't really matter
[00:20:44.360 --> 00:20:47.480]   too much as long as we can visualize it.
[00:20:47.480 --> 00:20:50.600]   We could probably have a whole episode about that.
[00:20:50.600 --> 00:20:54.000]   Wait, wait, the number of rows shouldn't matter in what sense?
[00:20:54.000 --> 00:20:57.240]   It seems like it would make it more complicated to visualize.
[00:20:57.240 --> 00:21:03.760]   I mean, it doesn't make the visualization necessarily itself harder, but it seems like
[00:21:03.760 --> 00:21:08.000]   actually scanning through all of them might start to get impractical.
[00:21:08.000 --> 00:21:10.600]   Yeah, I guess there's two issues.
[00:21:10.600 --> 00:21:14.360]   One is a computational issue of just transforming the data and then rendering it.
[00:21:14.360 --> 00:21:18.200]   And then the other is can I represent the data in a way that is not overwhelming to
[00:21:18.200 --> 00:21:21.000]   the viewer?
[00:21:21.000 --> 00:21:25.600]   But assuming we can do that for a couple of thousands of data points or tens of thousands
[00:21:25.600 --> 00:21:30.120]   or hundreds of thousands of data points, if you have many dimensions, the recommendation
[00:21:30.120 --> 00:21:35.360]   aspect gets a lot more difficult because now you have to think about, okay, how do I represent
[00:21:35.360 --> 00:21:36.360]   all these dimensions?
[00:21:36.360 --> 00:21:38.400]   Let's use this, browse them.
[00:21:38.400 --> 00:21:40.800]   How do I show correlations between dimensions?
[00:21:40.800 --> 00:21:41.800]   There's a lot more.
[00:21:41.800 --> 00:21:49.080]   If I showed all correlations between three dimensions, it gets impractical very quickly.
[00:21:49.080 --> 00:21:50.080]   Totally.
[00:21:50.080 --> 00:21:51.080]   Yeah.
[00:21:51.080 --> 00:21:54.920]   So that's, I guess, visualization for machine learning.
[00:21:54.920 --> 00:21:58.440]   And then going the other way around, machine learning for visualization is something that
[00:21:58.440 --> 00:21:59.880]   I've become pretty interested in.
[00:21:59.880 --> 00:22:05.000]   When we designed FigureLight, we built it not just as a language that can be authored by
[00:22:05.000 --> 00:22:11.480]   people, but actually as a language where we can automatically generate visualizations.
[00:22:11.480 --> 00:22:18.280]   And I think that's also what distinguishes it from other languages such as D3 or ggplot.nr.
[00:22:18.280 --> 00:22:25.040]   Because we're in JSON, it is very easy to programmatically generate visualizations.
[00:22:25.040 --> 00:22:27.380]   Then we built a recommendation system on top of it.
[00:22:27.380 --> 00:22:32.960]   So when we have a visualization language that is declarative and in a language that is easily
[00:22:32.960 --> 00:22:38.240]   operatable, we could think about ways to automatically generate visualizations from programs or from
[00:22:38.240 --> 00:22:39.240]   models.
[00:22:39.240 --> 00:22:44.800]   And so one of those models is a model called Draco, my colleagues and I have been working
[00:22:44.800 --> 00:22:51.160]   on together, where we encoded design best practices as a formal model.
[00:22:51.160 --> 00:22:56.280]   And then we can automatically apply those best practices to recommend visualizations.
[00:22:56.280 --> 00:22:59.960]   And so that can go beyond what I've talked about in Voyager, where we recommend this
[00:22:59.960 --> 00:23:01.960]   gallery of visualizations.
[00:23:01.960 --> 00:23:09.000]   Because you can consider a lot more aspects of both the data or the visualization, or
[00:23:09.000 --> 00:23:13.040]   the task that the user wants to do, or the context that they're in, or the device that
[00:23:13.040 --> 00:23:14.040]   they're looking at it on.
[00:23:14.040 --> 00:23:20.080]   It's funny, I keep wanting to ask actually, I don't know how to fit this into the flow,
[00:23:20.080 --> 00:23:25.360]   but I think one of the issues with visualizing data and machine learning, especially with
[00:23:25.360 --> 00:23:30.840]   a lot of the deep learning folks that we work with, is that the data often has...
[00:23:30.840 --> 00:23:35.720]   It's not the three independent variables and a dependent variable in the stats class.
[00:23:35.720 --> 00:23:40.800]   It's more like the data is like an image, or the data is like an audio file.
[00:23:40.800 --> 00:23:45.680]   And so I feel like just even visualizing the distributions gets unwieldy, and it's also
[00:23:45.680 --> 00:23:48.280]   a little unclear what you would do with that.
[00:23:48.280 --> 00:23:53.960]   So do you have thoughts about visualizing things where there's a higher order structure,
[00:23:53.960 --> 00:23:58.960]   like an image or a video or audio file or something like that?
[00:23:58.960 --> 00:24:05.920]   I guess it's tricky because a visualization is two dimensional, two point something dimensional.
[00:24:05.920 --> 00:24:10.080]   Maybe you can use color and size and every encoding channel essentially can represent
[00:24:10.080 --> 00:24:15.600]   another dimension, but after four or five or so, it really becomes overwhelming.
[00:24:15.600 --> 00:24:21.240]   So if you have a dataset with thousands of dimensions, I think the way to do it now is
[00:24:21.240 --> 00:24:24.080]   to use dimensionality reduction methods.
[00:24:24.080 --> 00:24:33.280]   So t-SNE, UMAP, TCA, to reduce the numbers of dimensions to the essential, in some way,
[00:24:33.280 --> 00:24:35.120]   dimensions.
[00:24:35.120 --> 00:24:38.760]   Or create some kind of domain specific visualization.
[00:24:38.760 --> 00:24:45.980]   So in a way, an image is a domain specific visualization that maps your long vectors
[00:24:45.980 --> 00:24:51.640]   of numbers to a matrix of color encoding.
[00:24:51.640 --> 00:24:55.320]   So what do you think about, all of my Twitter feed is talking about model explainability
[00:24:55.320 --> 00:24:57.840]   and how that's still a very unsolved problem.
[00:24:57.840 --> 00:25:02.680]   So what do you think are techniques that everyone should know about and how do you think the
[00:25:02.680 --> 00:25:03.680]   field is progressing?
[00:25:03.680 --> 00:25:09.720]   Do you think we're going to have interpretable models in five years, anytime soon, or are
[00:25:09.720 --> 00:25:14.480]   neural networks never going to be explainable?
[00:25:14.480 --> 00:25:15.480]   I don't know.
[00:25:15.480 --> 00:25:16.480]   That's a good question.
[00:25:16.480 --> 00:25:18.320]   I think many people are trying to answer.
[00:25:18.320 --> 00:25:24.640]   There's been a trade off where people often made simpler models because they are more
[00:25:24.640 --> 00:25:28.840]   explainable and the more complex the model gets, the harder they get to explain.
[00:25:28.840 --> 00:25:33.800]   So sometimes there's methods similar to dimensionality reduction, I guess, to reduce your complex
[00:25:33.800 --> 00:25:36.400]   model to a simpler model, which you can then explain.
[00:25:36.400 --> 00:25:39.860]   But none of those methods are fully, really, really satisfying.
[00:25:39.860 --> 00:25:44.880]   Some of the techniques I've seen is use more inherently explainable models that are still
[00:25:44.880 --> 00:25:45.880]   complex.
[00:25:45.880 --> 00:25:51.520]   So for instance, a good example of that is our GAMS, general additive models, which
[00:25:51.520 --> 00:25:57.280]   are linear models of functions applied to every dimension.
[00:25:57.280 --> 00:26:00.480]   Well, why is that more explainable?
[00:26:00.480 --> 00:26:01.700]   Why is it more explainable?
[00:26:01.700 --> 00:26:06.760]   Because you can apply some techniques where you can understand, for instance, the function
[00:26:06.760 --> 00:26:11.860]   that gets applied to every dimension individually, or you can also then look at how do those
[00:26:11.860 --> 00:26:17.560]   dimensions or the functions applied to those dimensions, how do those get combined in just
[00:26:17.560 --> 00:26:24.680]   a linear function, which is a lot easier to understand than some nonlinear combination
[00:26:24.680 --> 00:26:30.080]   of many, many dimensions.
[00:26:30.080 --> 00:26:34.120]   But wouldn't you want to have the different dimensions interact with each other or allow
[00:26:34.120 --> 00:26:35.120]   for that?
[00:26:35.120 --> 00:26:39.320]   I guess maybe taking a step back, can you make this a little more concrete for someone
[00:26:39.320 --> 00:26:41.000]   who hasn't seen this before?
[00:26:41.000 --> 00:26:46.740]   What would be, what kind of functions would you be imagining and how would they be applied?
[00:26:46.740 --> 00:26:53.040]   For instance, if you want to predict the quantity of variable, like some number, let's say,
[00:26:53.040 --> 00:26:56.320]   use the standard example, the housing price, the price of a house, you want to do that
[00:26:56.320 --> 00:26:59.800]   based on the dimensions, the available dimensions.
[00:26:59.800 --> 00:27:04.800]   Let's say the size of the square feet, the number of bathrooms, the number of bedrooms,
[00:27:04.800 --> 00:27:07.800]   or the number of floors.
[00:27:07.800 --> 00:27:17.440]   And so now what you can do is do a linear combination of the dimensions to get the price.
[00:27:17.440 --> 00:27:23.320]   So if you just take a linear combination, I could say multiply the square feet by, I
[00:27:23.320 --> 00:27:29.240]   don't know, 10, the number of floors by 20, the plot size by five, and then get a number
[00:27:29.240 --> 00:27:30.640]   out that is the housing price.
[00:27:30.640 --> 00:27:35.840]   So that would be a simple linear model where you essentially apply a weight to every, every
[00:27:35.840 --> 00:27:37.600]   individual dimension.
[00:27:37.600 --> 00:27:44.920]   So now what a general, these additive models do is that they apply a non-linear function
[00:27:44.920 --> 00:27:46.520]   to each dimension individually.
[00:27:46.520 --> 00:27:51.760]   So it can be like a log function or any other complex, can be as complex as we want.
[00:27:51.760 --> 00:27:57.280]   But because it's a function, you can actually visualize it very easily just by looking at
[00:27:57.280 --> 00:28:05.720]   the value on the X axis and the value after applying the function on the Y axis.
[00:28:05.720 --> 00:28:09.480]   And so if you then want to know what is the price of a particular house or the predicted
[00:28:09.480 --> 00:28:16.360]   price of a house, in each of these charts per dimension, you just look up for my value,
[00:28:16.360 --> 00:28:20.640]   what's the corresponding value that goes into the sum, and then you just sum them up.
[00:28:20.640 --> 00:28:21.640]   I see.
[00:28:21.640 --> 00:28:26.320]   So you could see exactly how much each thing contributed to your final score or your final
[00:28:26.320 --> 00:28:27.320]   prediction.
[00:28:27.320 --> 00:28:28.320]   Yeah.
[00:28:28.320 --> 00:28:32.160]   And a very good example of, if you want to actually play with that and try it out is
[00:28:32.160 --> 00:28:37.240]   at this system called Gamit, which is a research project at Microsoft Research, where they
[00:28:37.240 --> 00:28:44.640]   built a system for doing exactly, exactly this task of understanding a model that is
[00:28:44.640 --> 00:28:51.200]   a general, one of those Gam models, and both being able to, for instance, compare two predictions
[00:28:51.200 --> 00:28:57.560]   between, for two houses, understanding how much each dimension contributes to the predicted
[00:28:57.560 --> 00:29:02.600]   price and also make it very easy to compare or to look at the general model, the whole
[00:29:02.600 --> 00:29:05.560]   model in just one view.
[00:29:05.560 --> 00:29:11.160]   And yes, you don't have the ability to have multiple dimensions affect your output, but
[00:29:11.160 --> 00:29:17.000]   still, these models work fairly well and are a lot more interpretable than a model that
[00:29:17.000 --> 00:29:22.920]   computes many, many dimensions or incorporates many dimensions in every single point.
[00:29:22.920 --> 00:29:28.480]   Do you have thoughts on visualizations to help with understanding what's going on in
[00:29:28.480 --> 00:29:34.040]   a much more complicated models, like say, a convolutional network or a fancier type
[00:29:34.040 --> 00:29:35.040]   of network?
[00:29:35.040 --> 00:29:38.920]   Yeah, I think visualizations can actually help at different points.
[00:29:38.920 --> 00:29:45.880]   And I think visualizations are only as powerful or only as useful as the task that you designed
[00:29:45.880 --> 00:29:46.880]   them for.
[00:29:46.880 --> 00:29:51.160]   So I think in general saying, "Oh, can you visualize this thing?" is impossible without
[00:29:51.160 --> 00:29:52.160]   a task.
[00:29:52.160 --> 00:29:54.040]   So can you visualize X for Y?
[00:29:54.040 --> 00:29:59.960]   So for instance, I can, one could visualize a model for the purpose of understanding
[00:29:59.960 --> 00:30:02.880]   the architecture.
[00:30:02.880 --> 00:30:08.760]   And so when you, for instance, have a complex neural network with many layers and many different
[00:30:08.760 --> 00:30:13.520]   complex functions at every, in every layer, you might want to visualize it to see what
[00:30:13.520 --> 00:30:20.200]   functions are being applied, what parameters are being used and how big is each layer.
[00:30:20.200 --> 00:30:21.720]   And so there's a couple of visualizations.
[00:30:21.720 --> 00:30:25.800]   I think the one of the most popular ones is probably the one in TensorBoard, which actually
[00:30:25.800 --> 00:30:29.000]   my colleague Ham started when he was interning at Google.
[00:30:29.000 --> 00:30:31.200]   So that's one.
[00:30:31.200 --> 00:30:33.880]   Did you mean the parallel coordinates plot maybe?
[00:30:33.880 --> 00:30:37.400]   Or which visualization in TensorBoard?
[00:30:37.400 --> 00:30:45.040]   In TensorBoard, it's the visualization of the graph, the data flow graph.
[00:30:45.040 --> 00:30:49.440]   It's this, there's kind of two views in TensorBoard.
[00:30:49.440 --> 00:30:54.160]   There's the one where you look at your model outputs or your metrics.
[00:30:54.160 --> 00:30:56.200]   And there's the one where you look at the model architecture.
[00:30:56.200 --> 00:30:59.120]   And I'm talking about the model architecture one.
[00:30:59.120 --> 00:31:03.240]   So that can help you to, for instance, debug what's happening, but it might not, it doesn't
[00:31:03.240 --> 00:31:07.480]   help you at all to explain a particular prediction, for instance.
[00:31:07.480 --> 00:31:12.440]   So for that, you might use a different visualization that does like feature visualizations or lets
[00:31:12.440 --> 00:31:18.240]   you inspect different layers and what's the attribution of in different layers.
[00:31:18.240 --> 00:31:19.520]   Cool.
[00:31:19.520 --> 00:31:20.920]   We always end with two questions.
[00:31:20.920 --> 00:31:22.720]   I want to make sure we have time for it.
[00:31:22.720 --> 00:31:25.840]   And I think we maybe should modify them slightly to focus on visualization.
[00:31:25.840 --> 00:31:32.960]   So normally we ask what's a subfield of machine learning that people should pay more attention
[00:31:32.960 --> 00:31:38.800]   to, which I'm curious your thoughts on, but maybe I'd also ask a sort of subfield of visualization
[00:31:38.800 --> 00:31:43.160]   that you think doesn't get as much attention as it deserves.
[00:31:43.160 --> 00:31:49.400]   I think for machine learning, I'm very excited that there's a lot more attention on understanding
[00:31:49.400 --> 00:31:50.880]   what's happening in these models.
[00:31:50.880 --> 00:31:57.200]   I'm also a huge fan of more classical AI methods, which I guess is not machine learning anymore.
[00:31:57.200 --> 00:32:00.240]   But yeah, I'm very excited about constraint solvers and-
[00:32:00.240 --> 00:32:03.720]   Whoa, man, we have not had that answer.
[00:32:03.720 --> 00:32:04.720]   Constraints?
[00:32:04.720 --> 00:32:07.160]   I thought you were going to say SVNs or something with constraint solvers.
[00:32:07.160 --> 00:32:10.920]   No, no, classical AI, not even learned, right?
[00:32:10.920 --> 00:32:15.720]   I thought they used ML to do constraint satisfaction these days.
[00:32:15.720 --> 00:32:16.720]   I guess.
[00:32:16.720 --> 00:32:17.720]   I don't know.
[00:32:17.720 --> 00:32:23.640]   Well, you can use ML now for learning indexes and databases.
[00:32:23.640 --> 00:32:24.640]   Cool.
[00:32:24.640 --> 00:32:31.560]   And I think these classical AI methods are exciting because they allow you to describe
[00:32:31.560 --> 00:32:38.800]   a model, a way, a concept, a theory in a very formal way and then automatically apply it.
[00:32:38.800 --> 00:32:44.080]   Very declarative, very declarative problem solving and describing problems and solving
[00:32:44.080 --> 00:32:45.080]   them.
[00:32:45.080 --> 00:32:46.920]   And these solvers are amazingly fast today.
[00:32:46.920 --> 00:32:48.400]   Pretty excited about it.
[00:32:48.400 --> 00:32:52.760]   In visualization, because it's a science, we're trying to explain what makes a visualization
[00:32:52.760 --> 00:32:54.480]   good.
[00:32:54.480 --> 00:33:01.080]   And there's been a lot of work on high level design of good visualizations.
[00:33:01.080 --> 00:33:07.040]   So I talked about these principles of effectiveness and expressiveness earlier.
[00:33:07.040 --> 00:33:09.280]   And there's no systems to automatically apply them.
[00:33:09.280 --> 00:33:13.600]   There's design best practices and there's books and people are teaching those in classes
[00:33:13.600 --> 00:33:15.160]   and so on.
[00:33:15.160 --> 00:33:24.360]   And then on a very low level, perceptual level, there's some understanding of how do we perceive
[00:33:24.360 --> 00:33:29.480]   colors and shapes and gestalt of shapes.
[00:33:29.480 --> 00:33:32.560]   And how do we see patterns?
[00:33:32.560 --> 00:33:38.560]   But we don't have a good understanding of how those low level insights on perception
[00:33:38.560 --> 00:33:44.840]   actually translate to those higher level design practices.
[00:33:44.840 --> 00:33:51.800]   And I think the two sides slowly are inching towards each other, but they're not this,
[00:33:51.800 --> 00:33:55.760]   they're like this far from each other right now and kind of slowly inching towards each
[00:33:55.760 --> 00:33:56.760]   other.
[00:33:56.760 --> 00:34:03.400]   And what I'm really excited for is kind of like the general relativity theory of how
[00:34:03.400 --> 00:34:04.880]   do these two actually combine?
[00:34:04.880 --> 00:34:10.200]   We need a unifying theory there of how do these two things relate?
[00:34:10.200 --> 00:34:14.280]   It's like we know it's high level, it's kind of like relativity.
[00:34:14.280 --> 00:34:18.360]   We know this small like quirks things.
[00:34:18.360 --> 00:34:19.840]   We don't know how they relate to each other.
[00:34:19.840 --> 00:34:21.280]   We know how the universe behaves.
[00:34:21.280 --> 00:34:23.960]   We know how little particles behave.
[00:34:23.960 --> 00:34:25.720]   But when you combine it, it doesn't work.
[00:34:25.720 --> 00:34:31.040]   So we have kind of this crisis that physics has had for a while as well in visualization.
[00:34:31.040 --> 00:34:33.000]   Well, what a great answer.
[00:34:33.000 --> 00:34:34.000]   That's so evocative.
[00:34:34.000 --> 00:34:38.320]   I want to talk about that for another hour.
[00:34:38.320 --> 00:34:43.440]   Normally we end with asking people really on behalf of our audience, kind of what the
[00:34:43.440 --> 00:34:51.840]   biggest challenges are that you see in taking ML projects from sort of conception to deployed.
[00:34:51.840 --> 00:34:53.280]   Do you have thoughts there?
[00:34:53.280 --> 00:35:00.840]   I think one of the trickiest thing in deploying machine learning are metrics.
[00:35:00.840 --> 00:35:05.440]   Coming up with good, meaningful metrics that you're optimizing.
[00:35:05.440 --> 00:35:07.240]   To me, machine learning is optimizing a function.
[00:35:07.240 --> 00:35:08.720]   But what is that function?
[00:35:08.720 --> 00:35:12.000]   And how do I make sure that that's actually a meaningful function?
[00:35:12.000 --> 00:35:14.600]   And also that it's going to be meaningful in the future?
[00:35:14.600 --> 00:35:19.720]   Because we know from many examples that if you're over-optimizing a metric, that metric
[00:35:19.720 --> 00:35:21.960]   becomes meaningless.
[00:35:21.960 --> 00:35:28.080]   So how do you ensure that a metric is meaningful right now and will be meaningful in the future?
[00:35:28.080 --> 00:35:29.680]   And it's actually tracking what you care about.
[00:35:29.680 --> 00:35:31.120]   It's a difficult question.
[00:35:31.120 --> 00:35:33.400]   And I don't know whether there's going to be one answer.
[00:35:33.400 --> 00:35:34.400]   I don't think so.
[00:35:34.400 --> 00:35:39.760]   Train a model on a bunch of different optimization functions and figure out which one makes sense
[00:35:39.760 --> 00:35:40.760]   or something.
[00:35:40.760 --> 00:35:41.760]   Yeah.
[00:35:41.760 --> 00:35:45.880]   But I kind of want to specifically ask about what are the biggest challenges around machine
[00:35:45.880 --> 00:35:51.120]   learning interpretation and also when you're training models using visualizations to debug
[00:35:51.120 --> 00:35:52.120]   these models.
[00:35:52.120 --> 00:35:54.680]   Do you have any thoughts around that, maybe?
[00:35:54.680 --> 00:35:58.640]   As I said earlier, I think data is essential for machine learning.
[00:35:58.640 --> 00:36:03.160]   And so understanding data is crucial.
[00:36:03.160 --> 00:36:08.000]   And I don't know whether the methods and tools we have for general data analysis, how much
[00:36:08.000 --> 00:36:10.720]   they might have to be adjusted for machine learning.
[00:36:10.720 --> 00:36:17.920]   Does, for instance, Tableau or Voyager, all these tools that are designed for exploratory
[00:36:17.920 --> 00:36:19.960]   analysis of tabular data.
[00:36:19.960 --> 00:36:22.400]   Where do they fall short when it comes to machine learning?
[00:36:22.400 --> 00:36:26.960]   Lukas was pointing out earlier that machine learning often has this high dimensional data,
[00:36:26.960 --> 00:36:30.360]   images and sound and so on.
[00:36:30.360 --> 00:36:34.200]   Can we design other representations?
[00:36:34.200 --> 00:36:39.840]   I don't even want to say visualizations, but just representations that help us see patterns
[00:36:39.840 --> 00:36:45.920]   in that data, meaningful patterns, meaningful for the task of training a model or understanding
[00:36:45.920 --> 00:36:46.920]   a model.
[00:36:46.920 --> 00:36:50.840]   I think this is going to be an interesting question for visualization tool designers
[00:36:50.840 --> 00:36:54.640]   who like to work in the machine learning space going forward in the future.
[00:36:54.640 --> 00:37:00.800]   It's funny, I feel like one thing that everybody working in machine learning misallocates their
[00:37:00.800 --> 00:37:06.960]   time a little bit, including me, is I feel like you almost always spend too much time
[00:37:06.960 --> 00:37:10.880]   looking at aggregate statistics versus individual examples.
[00:37:10.880 --> 00:37:13.840]   Every time you look at individual example, you're just like, "Oh, I can't believe I missed
[00:37:13.840 --> 00:37:19.000]   this stupid thing that is breaking my model or making it worse in some way."
[00:37:19.000 --> 00:37:23.200]   I wonder if the gap is we have really good tools, I feel like, for aggregate statistics,
[00:37:23.200 --> 00:37:31.520]   but it's hard to quickly drill into stuff, especially when your datasets get very large.
[00:37:31.520 --> 00:37:37.560]   I totally agree that we have very good tools for looking at aggregate statistics.
[00:37:37.560 --> 00:37:41.040]   I think we also have reasonable tools for looking at individual examples.
[00:37:41.040 --> 00:37:46.360]   You can look at an image, that's okay, or at a row in a table.
[00:37:46.360 --> 00:37:51.560]   But I think where it gets really tricky is understanding the in-between, so understanding
[00:37:51.560 --> 00:37:53.600]   the subgroups that exist in the data.
[00:37:53.600 --> 00:37:59.280]   That is because there exist n choose m possible subgroups in a dataset.
[00:37:59.280 --> 00:38:05.880]   If you have a million rows, that's a lot of subgroups, and only very few of them are actually
[00:38:05.880 --> 00:38:06.880]   meaningful.
[00:38:06.880 --> 00:38:14.080]   So understanding which subgroups are behaving oddly or are negatively affecting your model
[00:38:14.080 --> 00:38:20.280]   and looking at those, that is a challenge that I see over and over again.
[00:38:20.280 --> 00:38:25.040]   I think this problem of not aggregate and not individual, but somewhere in between and
[00:38:25.040 --> 00:38:31.080]   where in between do I want to look, that to me is where the difficulty lies.
[00:38:31.080 --> 00:38:32.080]   All right.
[00:38:32.080 --> 00:38:34.960]   I think that's a nice note to end on.
[00:38:34.960 --> 00:38:35.960]   Thank you so much.
[00:38:35.960 --> 00:38:36.960]   That was really fun.
[00:38:36.960 --> 00:38:37.960]   Yes.
[00:38:37.960 --> 00:38:41.480]   Thanks for all the questions and everything.
[00:38:41.480 --> 00:38:44.560]   Thanks for listening to another episode of Gradient Dissent.
[00:38:44.560 --> 00:38:48.800]   Doing these interviews are a lot of fun, and it's especially fun for me when I can actually
[00:38:48.800 --> 00:38:51.560]   hear from the people that are listening to these episodes.
[00:38:51.560 --> 00:38:55.640]   So if you wouldn't mind leaving a comment and telling me what you think or starting
[00:38:55.640 --> 00:38:59.600]   a conversation, that would make me inspired to do more of these episodes.
[00:38:59.600 --> 00:39:03.160]   And also if you wouldn't mind liking and subscribing, I'd appreciate that a lot.

