
[00:00:00.000 --> 00:00:05.200]   I believe our official scientific worldview is incompatible with the reality of consciousness.
[00:00:05.200 --> 00:00:06.920]   Do you think we're living in a simulation?
[00:00:06.920 --> 00:00:09.800]   We could be in the Matrix, this could be a very vivid dream.
[00:00:09.800 --> 00:00:12.600]   There's going to be a few people that are now visualizing a pink elephant.
[00:00:12.600 --> 00:00:14.400]   A hamster has consciousness.
[00:00:14.400 --> 00:00:19.640]   Except for cats, who are evil automatons that are void of consciousness.
[00:00:19.640 --> 00:00:24.000]   Consciousness is the basis of moral value, moral concern.
[00:00:24.000 --> 00:00:30.240]   Do you think there will be a time in like 20, 30, 50 years when we're not morally okay
[00:00:30.240 --> 00:00:36.480]   turning off the power to a robot?
[00:00:36.480 --> 00:00:41.140]   The following is a conversation with Philip Goff, philosopher specializing in the philosophy
[00:00:41.140 --> 00:00:43.760]   of mind and consciousness.
[00:00:43.760 --> 00:00:49.860]   He is a panpsychist, which means he believes that consciousness is a fundamental and ubiquitous
[00:00:49.860 --> 00:00:54.360]   feature of physical reality, of all matter in the universe.
[00:00:54.360 --> 00:00:59.720]   He is the author of Galileo's Error, Foundations for a New Science of Consciousness, and is
[00:00:59.720 --> 00:01:05.040]   the host of an excellent podcast called Mind Chat.
[00:01:05.040 --> 00:01:06.800]   This is the Lex Friedman Podcast.
[00:01:06.800 --> 00:01:10.080]   To support it, please check out our sponsors in the description.
[00:01:10.080 --> 00:01:14.520]   And now, here's my conversation with Philip Goff.
[00:01:14.520 --> 00:01:21.080]   I opened my second podcast conversation with Elon Musk with a question about consciousness
[00:01:21.080 --> 00:01:22.620]   and panpsychism.
[00:01:22.620 --> 00:01:27.120]   The question was, "Does consciousness permeate all matter?"
[00:01:27.120 --> 00:01:29.520]   I don't know why I opened the conversation this way.
[00:01:29.520 --> 00:01:32.120]   He looked at me like, "What the hell is this guy talking about?"
[00:01:32.120 --> 00:01:37.240]   So he said no, because we wouldn't be able to tell if it did or not.
[00:01:37.240 --> 00:01:40.120]   So it's outside the realm of the scientific method.
[00:01:40.120 --> 00:01:44.600]   Do you agree or disagree with Elon Musk's answer?
[00:01:44.600 --> 00:01:46.360]   I disagree.
[00:01:46.360 --> 00:01:50.240]   I guess I do think consciousness pervades matter.
[00:01:50.240 --> 00:01:56.800]   In fact, I think consciousness is the ultimate nature of matter.
[00:01:56.800 --> 00:02:06.400]   So as for whether it's outside of the scientific method, I think there's a fundamental challenge
[00:02:06.400 --> 00:02:12.160]   at the heart of the science of consciousness that we need to face up to, which is that
[00:02:12.160 --> 00:02:15.560]   consciousness is not publicly observable.
[00:02:15.560 --> 00:02:21.400]   I can't look inside your head and see your feelings and experiences.
[00:02:21.400 --> 00:02:27.760]   We know about consciousness not from doing experiments or public observation.
[00:02:27.760 --> 00:02:33.880]   We just know about it from our immediate awareness of our feelings and experiences.
[00:02:33.880 --> 00:02:34.880]   So-
[00:02:34.880 --> 00:02:35.880]   It's qualitative, not quantitative.
[00:02:35.880 --> 00:02:37.440]   That's what you talk about.
[00:02:37.440 --> 00:02:39.160]   Yeah, that's another aspect of it.
[00:02:39.160 --> 00:02:46.440]   So there are a couple of reasons consciousness I think is not susceptible to the standard
[00:02:46.440 --> 00:02:50.600]   or not fully susceptible to the standard scientific approach.
[00:02:50.600 --> 00:02:55.280]   One reason you've just raised is that it's qualitative rather than quantitative.
[00:02:55.280 --> 00:02:58.040]   Another reason is it's not publicly observable.
[00:02:58.040 --> 00:03:03.640]   So I mean, science is used to dealing with unobservables, right?
[00:03:03.640 --> 00:03:07.920]   Particle particles, quantum wave functions, other universes, none of these things are
[00:03:07.920 --> 00:03:10.400]   observable.
[00:03:10.400 --> 00:03:12.680]   But there's an important difference.
[00:03:12.680 --> 00:03:20.920]   With all these things, we postulate unobservables in order to explain what we can observe, right?
[00:03:20.920 --> 00:03:25.460]   In the whole of science, that's how it works.
[00:03:25.460 --> 00:03:31.160]   In the case of consciousness, in the unique case of consciousness, the thing we are trying
[00:03:31.160 --> 00:03:35.240]   to explain is not publicly observable.
[00:03:35.240 --> 00:03:37.240]   And that is utterly unique.
[00:03:37.240 --> 00:03:42.560]   If we want to fully bring science into consciousness, we need a more expansive conception of the
[00:03:42.560 --> 00:03:43.560]   scientific method.
[00:03:43.560 --> 00:03:48.400]   So it doesn't mean we can't explain consciousness scientifically, but we need to rethink what
[00:03:48.400 --> 00:03:49.400]   science is.
[00:03:49.400 --> 00:03:50.560]   What do you mean publicly?
[00:03:50.560 --> 00:03:52.260]   The word publicly observable?
[00:03:52.260 --> 00:03:55.480]   Is there something interesting to be said about the word publicly?
[00:03:55.480 --> 00:03:57.520]   I suppose versus privately?
[00:03:57.520 --> 00:04:07.640]   Yeah, it's tricky to define, but I suppose the data of physics are available to anybody.
[00:04:07.640 --> 00:04:12.040]   If there were aliens who visited us from another planet, maybe they'd have very different sense
[00:04:12.040 --> 00:04:17.720]   organs, maybe they'd struggle to understand our art or our music.
[00:04:17.720 --> 00:04:23.100]   But if they were intelligent enough to do mathematics, they could understand our physics,
[00:04:23.100 --> 00:04:28.560]   they could look at the data of our experiments, they could run the experiments themselves.
[00:04:28.560 --> 00:04:31.200]   Whereas consciousness, is it observable?
[00:04:31.200 --> 00:04:32.200]   Is it not observable?
[00:04:32.200 --> 00:04:33.200]   In a sense, it's observable.
[00:04:33.200 --> 00:04:37.240]   As you say, we could say it's privately observable.
[00:04:37.240 --> 00:04:41.640]   I am directly aware of my own feelings and experiences.
[00:04:41.640 --> 00:04:45.800]   If I'm in pain, it's just right there for me.
[00:04:45.800 --> 00:04:49.920]   My pain is just totally directly evident to me.
[00:04:49.920 --> 00:04:54.760]   But you from the outside cannot directly access my pain.
[00:04:54.760 --> 00:05:02.960]   You can access my pain behavior, or you can ask me, but you can't access my pain in the
[00:05:02.960 --> 00:05:06.360]   way that I can access my pain.
[00:05:06.360 --> 00:05:09.700]   So I think that's a distinction.
[00:05:09.700 --> 00:05:14.760]   It might be difficult to totally pin it down how we define those things, but I think there's
[00:05:14.760 --> 00:05:17.720]   a fairly clear and very important difference there.
[00:05:17.720 --> 00:05:23.400]   - So you think there's a kind of direct observation that you're able to do of your pain that I'm
[00:05:23.400 --> 00:05:24.400]   not.
[00:05:24.400 --> 00:05:30.800]   So my observation, all the ways in which I can sneak up to observing your pain is indirect
[00:05:30.800 --> 00:05:33.240]   versus yours is direct.
[00:05:33.240 --> 00:05:34.680]   Can you play devil's advocate?
[00:05:34.680 --> 00:05:42.920]   Is it possible for me to get closer and closer and closer to being able to observe your pain,
[00:05:42.920 --> 00:05:49.280]   like all the subjective experiences, yours in the way that you do?
[00:05:49.280 --> 00:05:50.280]   - Yeah.
[00:05:50.280 --> 00:05:56.640]   I mean, so of course it's not that we observe behavior and then we make an inference.
[00:05:56.640 --> 00:06:06.480]   We are hardwired to instinctively interpret smiles as happiness, crying as sadness.
[00:06:06.480 --> 00:06:11.600]   And as we get to know someone, we find it very easy to adopt their perspective, get
[00:06:11.600 --> 00:06:14.000]   into their shoes.
[00:06:14.000 --> 00:06:21.280]   But strictly speaking, all we have perceptual access to is someone's behavior.
[00:06:21.280 --> 00:06:29.080]   And if you were just, strictly speaking, if you were trying to explain someone's behavior,
[00:06:29.080 --> 00:06:33.580]   those aspects that are publicly observable, I don't think you'd ever have recourse to
[00:06:33.580 --> 00:06:34.580]   attribute consciousness.
[00:06:34.580 --> 00:06:39.840]   You could just postulate some kind of mechanism if you were just trying to explain the behavior.
[00:06:39.840 --> 00:06:44.240]   So someone like Daniel Dennett is very consistent on this.
[00:06:44.240 --> 00:06:53.320]   So I think for most people, what science is in the business of is explaining the data
[00:06:53.320 --> 00:06:55.360]   of public observation experiment.
[00:06:55.360 --> 00:07:02.440]   If you religiously followed that, you would not postulate consciousness because it's not
[00:07:02.440 --> 00:07:04.520]   a datum that's known about in that way.
[00:07:04.520 --> 00:07:06.440]   And Daniel Dennett is really consistent on this.
[00:07:06.440 --> 00:07:13.480]   He thinks my consciousness cannot be empirically verified and therefore it doesn't exist.
[00:07:13.480 --> 00:07:14.800]   Dennett is consistent on this.
[00:07:14.800 --> 00:07:21.680]   I think I'm consistent on this, but I think a lot of people have a slightly confused middleway
[00:07:21.680 --> 00:07:23.000]   position on this.
[00:07:23.000 --> 00:07:31.000]   On the one hand, they think the business of science is just to account for public observation
[00:07:31.000 --> 00:07:38.080]   experiment, but on the other hand, they also believe in consciousness without appreciating,
[00:07:38.080 --> 00:07:45.200]   I think, that that implies that there is another datum over and above the data of public observation
[00:07:45.200 --> 00:07:49.180]   experiments, namely just the reality of feelings and experiences.
[00:07:49.180 --> 00:07:53.280]   As we walk along this conversation, you keep opening doors that I want to walk into and
[00:07:53.280 --> 00:07:56.360]   I will, but I want to try to stay kind of focused.
[00:07:56.360 --> 00:08:02.000]   So you mentioned Daniel Dennett, let's lay it out since he sticks to his story, a pun
[00:08:02.000 --> 00:08:05.680]   unintended, and then you stick to yours.
[00:08:05.680 --> 00:08:06.840]   What is your story?
[00:08:06.840 --> 00:08:09.440]   What is your theory of consciousness versus his?
[00:08:09.440 --> 00:08:13.120]   Can you clarify his position?
[00:08:13.120 --> 00:08:20.640]   - So my view, I defend the view known as panpsychism, which is the view that consciousness is a
[00:08:20.640 --> 00:08:25.000]   fundamental and ubiquitous feature of the physical world.
[00:08:25.000 --> 00:08:30.640]   So it doesn't literally mean that everything is conscious despite the meaning of the word
[00:08:30.640 --> 00:08:33.160]   pan, everything, psyche, mind.
[00:08:33.160 --> 00:08:36.560]   So literally that means everything has mind.
[00:08:36.560 --> 00:08:42.760]   But the typical commitment of the panpsychist is that the fundamental building blocks of
[00:08:42.760 --> 00:08:50.760]   reality, maybe fundamental particles like electrons and quarks, have incredibly simple
[00:08:50.760 --> 00:08:57.920]   forms of experience and that the very complex experience of the human or animal brain is
[00:08:57.920 --> 00:09:03.680]   somehow rooted in or derived from this much more simple consciousness at the level of
[00:09:03.680 --> 00:09:05.960]   fundamental physics.
[00:09:05.960 --> 00:09:14.760]   So that's a theory that I would justify on the grounds that it can account for this datum
[00:09:14.760 --> 00:09:20.640]   of consciousness that we are immediately aware of in our experience in a way that I don't
[00:09:20.640 --> 00:09:21.920]   think other theories can.
[00:09:21.920 --> 00:09:25.560]   If you asked me to contrast that to Daniel Dennett, I think he would just say there is
[00:09:25.560 --> 00:09:26.560]   no such datum.
[00:09:26.560 --> 00:09:32.520]   Dennett says the data for science of consciousness is what he calls hetero phenomenology, which
[00:09:32.520 --> 00:09:39.240]   is specifically defined as what we can access from the third person perspective, including
[00:09:39.240 --> 00:09:41.160]   what people say.
[00:09:41.160 --> 00:09:43.520]   But crucially, we're not treating what they say.
[00:09:43.520 --> 00:09:50.620]   We're not relying on their testimony as evidence for some unobservable realm of feelings and
[00:09:50.620 --> 00:09:51.620]   experiences.
[00:09:51.620 --> 00:09:58.240]   We're just treating what they say as a datum of public observation experiments that we
[00:09:58.240 --> 00:10:00.760]   can account for in terms of underlying mechanisms.
[00:10:00.760 --> 00:10:04.760]   - But I feel like there's a deeper view of what consciousness is.
[00:10:04.760 --> 00:10:09.560]   So you have a very clear, and we'll talk quite a bit about panpsychism, but you have a clear
[00:10:09.560 --> 00:10:14.640]   view of what, almost like a physics view of consciousness.
[00:10:14.640 --> 00:10:23.960]   He, I think, has a kind of view that consciousness is almost a side effect of this massively
[00:10:23.960 --> 00:10:29.200]   parallel computation system going on in our brain.
[00:10:29.200 --> 00:10:35.200]   The brain has a model of the world and it's taking in perceptions and it's constantly
[00:10:35.200 --> 00:10:41.000]   weaving multiple stories about that world that's integrating the new perceptions.
[00:10:41.000 --> 00:10:46.240]   And the multiple stories are somehow, it's like a Google Doc, collaborative editing.
[00:10:46.240 --> 00:10:54.400]   And that collaborative editing is the actual experience of what we think of as consciousness.
[00:10:54.400 --> 00:10:59.800]   Somehow, the editing is consciousness of this story.
[00:10:59.800 --> 00:11:03.660]   I mean, that's a theory of consciousness, isn't it?
[00:11:03.660 --> 00:11:09.300]   The narrative theory of consciousness, or the multiple versions, editing, collaborative
[00:11:09.300 --> 00:11:11.880]   editing of a narrative theory of consciousness.
[00:11:11.880 --> 00:11:14.440]   - Yeah, he calls it the multiple drafts model.
[00:11:14.440 --> 00:11:19.120]   Incidentally, there's a very interesting paper just come out by very good philosopher, Luke
[00:11:19.120 --> 00:11:26.400]   Roloff, defending a panpsychist version of Dennett's multiple drafts model.
[00:11:26.400 --> 00:11:29.040]   - Like a deep turtle that that turtle is stacked on top of.
[00:11:29.040 --> 00:11:33.480]   - Just the difference being that, this is Luke Roloff's view, all of the drafts are
[00:11:33.480 --> 00:11:34.480]   conscious.
[00:11:34.480 --> 00:11:42.040]   I guess for Dennett, there's sort of no fact of the matter about which of these drafts
[00:11:42.040 --> 00:11:44.920]   is the correct one.
[00:11:44.920 --> 00:11:48.600]   On Roloff's view, maybe there's no fact of the matter about which of these drafts is
[00:11:48.600 --> 00:11:55.200]   my consciousness, but nonetheless, all the drafts correspond to some consciousness.
[00:11:55.200 --> 00:11:57.040]   And I mean, it's just kind of funny.
[00:11:57.040 --> 00:12:04.460]   I guess I think he calls it Dennettian panpsychism, but Luke is one of the most rigorous and serious
[00:12:04.460 --> 00:12:07.240]   philosophers alive at the moment, I think.
[00:12:07.240 --> 00:12:11.440]   I hate having Luke Roloff in an audience if I'm giving a talk, because he always cuts
[00:12:11.440 --> 00:12:15.760]   straight to the weakness in your position that you hadn't thought of.
[00:12:15.760 --> 00:12:22.000]   So it's nice, panpsychism is sometimes associated with fluffy thinking, but contemporary panpsychists
[00:12:22.000 --> 00:12:28.720]   have come out of this tradition we call analytic philosophy, which is rooted in detailed, rigorous
[00:12:28.720 --> 00:12:33.640]   argumentation and it is defended in that manner.
[00:12:33.640 --> 00:12:37.840]   Yeah, those analytic philosophers are sticklers for terminology.
[00:12:37.840 --> 00:12:40.920]   It's very fun, very fun group to talk shit with over speakers.
[00:12:40.920 --> 00:12:45.800]   Yeah, well, I mean, it gets boring if you just start and end defining words, right?
[00:12:45.800 --> 00:12:46.800]   Yeah.
[00:12:46.800 --> 00:12:48.240]   I think starting with defining words is good.
[00:12:48.240 --> 00:12:53.360]   Actually, the philosopher Derek Parfit said when he first was thinking about philosophy,
[00:12:53.360 --> 00:12:59.040]   he went to a talk in analytic philosophy and he went to a talk in continental philosophy
[00:12:59.040 --> 00:13:03.360]   and he decided that the problem with the continental philosophy, if it was really unrigorous, really
[00:13:03.360 --> 00:13:09.520]   imprecise, the problem with the analytic philosophy is it was just not about anything important.
[00:13:09.520 --> 00:13:14.600]   And he thought there was more chance of working within analytic philosophy and asking some
[00:13:14.600 --> 00:13:18.920]   more meaningful, some more profound questions than there was in working continental philosophy
[00:13:18.920 --> 00:13:20.520]   and making it more rigorous.
[00:13:20.520 --> 00:13:25.200]   Now they're both horrific stereotypes and I don't want to get nasty emails from either
[00:13:25.200 --> 00:13:28.880]   of these groups, but there's something to what he was saying there.
[00:13:28.880 --> 00:13:36.640]   I think just a tiny tangent on terminology, I do think that there's a lot of deep insight
[00:13:36.640 --> 00:13:39.040]   to be discovered by just asking questions.
[00:13:39.040 --> 00:13:40.240]   What do we mean by this word?
[00:13:40.240 --> 00:13:46.120]   I remember I was taking a course on algorithms and data structures in computer science and
[00:13:46.120 --> 00:13:50.480]   the instructor, shout out to him, Ali Shekhafande, amazing professor.
[00:13:50.480 --> 00:13:55.600]   I remember he asked some basic questions like, what is an algorithm?
[00:13:55.600 --> 00:13:59.640]   The pressure of pushing students to answer, to think deeply.
[00:13:59.640 --> 00:14:03.960]   You just woke up, hung over in college or whatever, and you're tasked with answering
[00:14:03.960 --> 00:14:08.480]   some deep philosophical question about what is an algorithm, these basic questions.
[00:14:08.480 --> 00:14:11.800]   And they sound very simple, but they're actually very difficult.
[00:14:11.800 --> 00:14:17.280]   And one of the things I really value in conversation is asking these dumb, simple questions of
[00:14:17.280 --> 00:14:21.120]   like, what is intelligence?
[00:14:21.120 --> 00:14:28.200]   And just continually asking that question over and over of some of the biggest researchers
[00:14:28.200 --> 00:14:30.960]   in the artificial intelligence computer science space.
[00:14:30.960 --> 00:14:32.320]   It's actually very useful.
[00:14:32.320 --> 00:14:38.720]   At the same time, it should start at terminology and then progress where you kind of say, ah,
[00:14:38.720 --> 00:14:39.720]   fuck it.
[00:14:39.720 --> 00:14:42.880]   We'll just assume we know what we mean by that.
[00:14:42.880 --> 00:14:48.680]   Otherwise you get the Bill Clinton situation where it's like, what is the meaning of his
[00:14:48.680 --> 00:14:49.680]   whatever he said?
[00:14:49.680 --> 00:14:52.880]   It's like, hey man, did you do the sex stuff or not?
[00:14:52.880 --> 00:14:53.880]   - Yeah.
[00:14:53.880 --> 00:15:00.920]   - So you have to both be able to talk about the sex stuff and the meaning of the word
[00:15:00.920 --> 00:15:01.920]   is.
[00:15:01.920 --> 00:15:09.840]   With consciousness, because we don't currently understand very much, terminology discussions
[00:15:09.840 --> 00:15:10.840]   are very important.
[00:15:10.840 --> 00:15:17.960]   'Cause it's like, you're almost trying to sneak up to some deep insight by just discussing
[00:15:17.960 --> 00:15:26.000]   some basic terminology, like what is consciousness or even defining the different aspects of
[00:15:26.000 --> 00:15:28.360]   panpsychism is fascinating.
[00:15:28.360 --> 00:15:38.040]   But just to linger on the Daniel Dennett thing, what do you think about narrative?
[00:15:38.040 --> 00:15:41.840]   Sort of the mind constructing narratives for ourselves.
[00:15:41.840 --> 00:15:45.960]   So there's nothing special about consciousness deeply.
[00:15:45.960 --> 00:15:54.200]   It is some property of the human mind that's just is able to tell these pretty stories
[00:15:54.200 --> 00:15:59.760]   that we experience as consciousness and that it's unique perhaps to the human mind, which
[00:15:59.760 --> 00:16:07.520]   is I suppose what Daniel Dennett would argue, that it's either deeply unique or mostly unique
[00:16:07.520 --> 00:16:08.520]   to the human mind.
[00:16:08.520 --> 00:16:11.640]   - It's just on the question of terminology before.
[00:16:11.640 --> 00:16:18.720]   Yes, I think it used to be the fashion among philosophers that we had to come up with utterly
[00:16:18.720 --> 00:16:23.480]   precise necessary and sufficient conditions for each word.
[00:16:23.480 --> 00:16:29.440]   And then I think this has gone out of fashion a bit, partly because it's just been such
[00:16:29.440 --> 00:16:30.920]   a failure.
[00:16:30.920 --> 00:16:36.000]   The word knowledge in particular, people used to define knowledge as true justified belief.
[00:16:36.000 --> 00:16:40.840]   And then this guy, Gettier, had this very short paper where he just produced some pretty
[00:16:40.840 --> 00:16:42.600]   conclusive counter examples to that.
[00:16:42.600 --> 00:16:48.360]   I think he wrote very few papers, but this is just, you have to teach this on an undergraduate
[00:16:48.360 --> 00:16:49.360]   philosophy course.
[00:16:49.360 --> 00:16:55.240]   And then after that, you had a huge literature of people trying to address this and propose
[00:16:55.240 --> 00:16:58.760]   a new definition, but then someone else would come out with counter examples.
[00:16:58.760 --> 00:17:01.840]   And then you get a new definition of knowledge and counter examples, and it just went on
[00:17:01.840 --> 00:17:03.600]   and on and never seemed to get anywhere.
[00:17:03.600 --> 00:17:08.840]   So I think the thought now is, let's work out how precise we need to be for what we're
[00:17:08.840 --> 00:17:09.840]   trying to do.
[00:17:09.840 --> 00:17:11.400]   And I think that's a healthier attitude.
[00:17:11.400 --> 00:17:16.040]   So precision is important, but you just need to work out how precise do we need to be for
[00:17:16.040 --> 00:17:18.360]   these purposes.
[00:17:18.360 --> 00:17:26.920]   Coming to Dennett and narrative theories, I think narrative theories are a plausible
[00:17:26.920 --> 00:17:35.280]   contender for a theory of the self, theory of my identity over time, what makes me the
[00:17:35.280 --> 00:17:41.600]   same person in some sense today as I was 20 years ago, given that I've changed so much
[00:17:41.600 --> 00:17:45.000]   physically and psychologically.
[00:17:45.000 --> 00:17:51.400]   One running contender is something connected to the kind of stories we tell about ourselves,
[00:17:51.400 --> 00:17:56.520]   or maybe some story about the psychological, the chains of psychological continuity.
[00:17:56.520 --> 00:17:59.960]   I'm not saying I accept such a theory, but it's plausible.
[00:17:59.960 --> 00:18:06.160]   I don't think these theories are good as theories of consciousness, at least if we're taking
[00:18:06.160 --> 00:18:14.960]   consciousness just to be subjective experience, pleasure, pain, seeing color, hearing sound.
[00:18:14.960 --> 00:18:19.800]   I think a hamster has consciousness in that sense.
[00:18:19.800 --> 00:18:22.120]   There's something that it's like to be a hamster.
[00:18:22.120 --> 00:18:26.360]   It feels pain if you stand on it, if you're cruel enough to do it.
[00:18:26.360 --> 00:18:27.360]   I don't know why I gave that.
[00:18:27.360 --> 00:18:28.360]   Stan.
[00:18:28.360 --> 00:18:33.360]   I don't know, philosophers give these very violent examples to get the cross consciousness
[00:18:33.360 --> 00:18:35.240]   and it's, yeah, I don't know why that's coming up.
[00:18:35.240 --> 00:18:36.240]   But anyway.
[00:18:36.240 --> 00:18:37.240]   You say mean things to the hamster.
[00:18:37.240 --> 00:18:38.240]   Let's back up.
[00:18:38.240 --> 00:18:45.800]   It experiences pain, it experiences pleasure, joy.
[00:18:45.800 --> 00:18:49.900]   But there's some limits to that experience of a hamster, but there is nevertheless the
[00:18:49.900 --> 00:18:51.920]   presence of a subjective experience.
[00:18:51.920 --> 00:18:52.920]   Yeah.
[00:18:52.920 --> 00:18:56.920]   Consciousness is just something, I mean, it's a very ambiguous word, but if we're just using
[00:18:56.920 --> 00:19:02.520]   it to mean some kind of experience, some kind of inner life, that is pretty widespread in
[00:19:02.520 --> 00:19:03.520]   the animal kingdom.
[00:19:03.520 --> 00:19:09.800]   A bit difficult to say where it stops, where it starts, but you certainly don't need something
[00:19:09.800 --> 00:19:17.360]   as sophisticated as the capacity to self-consciously tell stories about yourself to just have experience.
[00:19:17.360 --> 00:19:23.480]   Except for cats who are evil automatons that are void of consciousness.
[00:19:23.480 --> 00:19:25.080]   They're the fingertips of the devil.
[00:19:25.080 --> 00:19:26.080]   Oh, absolutely.
[00:19:26.080 --> 00:19:27.080]   Yeah.
[00:19:27.080 --> 00:19:28.080]   I was taking that as read.
[00:19:28.080 --> 00:19:31.240]   I mean, Descartes thought animals were mechanisms.
[00:19:31.240 --> 00:19:32.600]   And humans are unique.
[00:19:32.600 --> 00:19:39.080]   So, animals are robots, essentially, in the formulation of Descartes and humans are unique.
[00:19:39.080 --> 00:19:49.040]   So in which way would you say humans are unique versus even our closest ancestors?
[00:19:49.040 --> 00:19:52.800]   Is there something special about humans?
[00:19:52.800 --> 00:19:58.160]   What is, in your view, under the panpsychism, I guess we're walking backwards because we'll
[00:19:58.160 --> 00:20:03.360]   have the big picture conversation about what is panpsychism, but given your kind of broad
[00:20:03.360 --> 00:20:07.400]   theory of consciousness, what's unique about humans, do you think?
[00:20:07.400 --> 00:20:16.240]   As a panpsychist, there is a great continuity between humans and the rest of the universe.
[00:20:16.240 --> 00:20:19.400]   There's nothing that special about human consciousness.
[00:20:19.400 --> 00:20:25.240]   It's just a highly evolved form of what exists throughout the universe.
[00:20:25.240 --> 00:20:29.760]   So we're very much continuous with the rest of the physical universe.
[00:20:29.760 --> 00:20:31.120]   What is unique about human beings?
[00:20:31.120 --> 00:20:42.080]   I suppose the capacity to reflect on our conscious experience, plan for the future, the capacity,
[00:20:42.080 --> 00:20:47.080]   I would say, to respond to reasons as well.
[00:20:47.080 --> 00:20:54.400]   I mean, animals in some sense have motivations, but when a human being makes a decision, they're
[00:20:54.400 --> 00:20:59.040]   responding to what philosophers call normative considerations.
[00:20:59.040 --> 00:21:02.320]   You know, if you think, "Should I take this job in the US?"
[00:21:02.320 --> 00:21:06.000]   You weigh it up, you say, "Well, I'll get more money, I'll have maybe a better quality
[00:21:06.000 --> 00:21:11.040]   of life, but if I stay in the UK, I'll be closer to family," and you weigh up these
[00:21:11.040 --> 00:21:13.760]   considerations.
[00:21:13.760 --> 00:21:21.760]   I'm not sure any non-human animals quite respond to considerations of value in that way.
[00:21:21.760 --> 00:21:25.560]   I mean, I might be reflecting here that I'm something of an objectivist about value.
[00:21:25.560 --> 00:21:32.720]   I think there are objective facts about what we have reason to do and what we have reason
[00:21:32.720 --> 00:21:33.720]   to believe.
[00:21:33.720 --> 00:21:34.720]   And humans have access to those facts.
[00:21:34.720 --> 00:21:36.800]   And humans have access to them and can respond to them.
[00:21:36.800 --> 00:21:39.840]   That's a controversial claim.
[00:21:39.840 --> 00:21:41.760]   Many of my panpsychist brethren might not...
[00:21:41.760 --> 00:21:48.760]   They would say the hamster too can look up to the stars and ponder theoretical physics.
[00:21:48.760 --> 00:21:52.400]   Maybe not, but I think it depends what you think about value.
[00:21:52.400 --> 00:21:58.640]   If you have a more Humean picture of value, by which I mean relating to the philosopher
[00:21:58.640 --> 00:22:03.320]   David Hume, who said, "Reason is the slave of the passions."
[00:22:03.320 --> 00:22:09.840]   Really, we just have motivations and what we have reason to do arises from our motivations.
[00:22:09.840 --> 00:22:15.480]   I'm not a Humean, I think there are objective facts about what we have a reason to do.
[00:22:15.480 --> 00:22:17.160]   And I think we have access to them.
[00:22:17.160 --> 00:22:24.080]   I don't think any non-human animal has access to objective facts about what they have reason
[00:22:24.080 --> 00:22:26.120]   to do, what they have reason to believe.
[00:22:26.120 --> 00:22:28.640]   They don't weigh up evidence.
[00:22:28.640 --> 00:22:31.180]   Reason is a slave of the passions.
[00:22:31.180 --> 00:22:33.080]   That was David Hume's view, yeah.
[00:22:33.080 --> 00:22:36.000]   I mean, yeah, do you want to know my problem with Hume's?
[00:22:36.000 --> 00:22:37.760]   I had a radical conversion.
[00:22:37.760 --> 00:22:42.160]   This might not be connected, it's not connected to panpsychism, but I had a radical conversion.
[00:22:42.160 --> 00:22:49.760]   I used to have a more Humean view when I was a graduate student, but I was persuaded by
[00:22:49.760 --> 00:22:54.080]   some professors at the University of Reading where I was that if you have the Humean view,
[00:22:54.080 --> 00:23:03.360]   you have to say any basic life goals are equal, equally valid.
[00:23:03.360 --> 00:23:09.680]   So for example, let's take someone whose basic goal in life is counting blades of grass,
[00:23:09.680 --> 00:23:10.680]   right?
[00:23:10.680 --> 00:23:13.200]   And crucially, they don't enjoy it, right?
[00:23:13.200 --> 00:23:14.200]   This is the crucial point.
[00:23:14.200 --> 00:23:15.840]   They get no pleasure from it.
[00:23:15.840 --> 00:23:21.680]   That's just their basic goal, to spend their life counting as many blades of grass as possible.
[00:23:21.680 --> 00:23:25.960]   Not for some greater goal, that's just their basic goal.
[00:23:25.960 --> 00:23:29.720]   I want to say that that is objectively stupid.
[00:23:29.720 --> 00:23:30.920]   That is objectively pointless.
[00:23:30.920 --> 00:23:32.480]   I shouldn't say stupid.
[00:23:32.480 --> 00:23:40.080]   It's objectively pointless in a way that pursuing pleasure or pursuing someone else's pleasure
[00:23:40.080 --> 00:23:43.320]   or pursuing scientific inquiry is not pointless.
[00:23:43.320 --> 00:23:47.200]   As soon as you make that admission, you're not a follower of David Hume anymore.
[00:23:47.200 --> 00:23:54.420]   You think there are objective facts about what goals are worth pursuing.
[00:23:54.420 --> 00:23:57.120]   Is it possible to have a goal without pleasure?
[00:23:57.120 --> 00:24:01.520]   So this kind of idea that you disjoint the two.
[00:24:01.520 --> 00:24:07.240]   So the David Foster Wallace idea of the key to life is to be unboreable.
[00:24:07.240 --> 00:24:12.560]   Isn't it possible to discover the pleasure in everything in life?
[00:24:12.560 --> 00:24:18.200]   The counting of the blades of grass, once you see the mastery, the skill of it, you
[00:24:18.200 --> 00:24:20.000]   can discover the pleasure.
[00:24:20.000 --> 00:24:26.760]   Therefore, I guess what I'm asking is why and when and how did you lose the romance
[00:24:26.760 --> 00:24:29.160]   in grad school of life?
[00:24:29.160 --> 00:24:31.040]   Is that what you're trying to say?
[00:24:31.040 --> 00:24:37.680]   I think it may or may not be true that it's possible to find pleasure in everything.
[00:24:37.680 --> 00:24:43.080]   But I think it's also true that people don't act solely for pleasure, and they certainly
[00:24:43.080 --> 00:24:45.440]   don't act solely for their own pleasure.
[00:24:45.440 --> 00:24:49.320]   People will suffer for things they think are worthwhile.
[00:24:49.320 --> 00:25:00.320]   I might suffer for some scientific cause, for finding out a cure for the pandemic, and
[00:25:00.320 --> 00:25:05.080]   in terms of my own pleasure, I might have less pleasure in doing that, but I think it's
[00:25:05.080 --> 00:25:06.080]   worthwhile.
[00:25:06.080 --> 00:25:08.240]   It's a worthwhile thing to do.
[00:25:08.240 --> 00:25:14.880]   I just don't think it's the case that everything we do is rooted in maximizing our own pleasure.
[00:25:14.880 --> 00:25:17.160]   I don't think that's even psychologically plausible.
[00:25:17.160 --> 00:25:19.640]   But pleasure, then that's a narrow kind of view of pleasure.
[00:25:19.640 --> 00:25:26.160]   That's like a short-term pleasure, but you can see pleasure is a kind of ability to hear
[00:25:26.160 --> 00:25:27.920]   the music in the distance.
[00:25:27.920 --> 00:25:35.680]   It's like, yes, it's difficult now, it's suffering now, but there's some greater thing beyond
[00:25:35.680 --> 00:25:38.280]   the mountain that will be joy.
[00:25:38.280 --> 00:25:44.180]   I mean, that's kind of a, even if it's not in this life, well, you know, the warriors
[00:25:44.180 --> 00:25:46.560]   will meet in Valhalla, right?
[00:25:46.560 --> 00:25:52.760]   The feeling that gives meaning and fulfillment to life is not necessarily grounded in pleasure
[00:25:52.760 --> 00:25:55.360]   of like the counting of the grass.
[00:25:55.360 --> 00:25:56.840]   It's something else.
[00:25:56.840 --> 00:25:58.240]   I don't know.
[00:25:58.240 --> 00:26:02.520]   The struggle is a source of deep fulfillment.
[00:26:02.520 --> 00:26:08.760]   So I think pleasure needs to be kind of thought of as a little bit more broadly.
[00:26:08.760 --> 00:26:14.320]   It just kind of gives you this sense.
[00:26:14.320 --> 00:26:22.040]   It for a moment allows you to forget the terror of the fact that you're going to die.
[00:26:22.040 --> 00:26:23.400]   That's pleasure.
[00:26:23.400 --> 00:26:31.080]   That's the broader view of pleasure, that you get to kind of play in the little illusion
[00:26:31.080 --> 00:26:34.080]   that all of this has deep meaning.
[00:26:34.080 --> 00:26:35.080]   That's pleasure.
[00:26:35.080 --> 00:26:41.440]   - Yeah, well, but I mean, you know, people sacrifice their lives.
[00:26:41.440 --> 00:26:46.440]   Atheists may sacrifice their lives for the sake of someone else or for the sake of something
[00:26:46.440 --> 00:26:47.720]   important enough.
[00:26:47.720 --> 00:26:53.560]   And clearly in that case, they're not doing it for the sake of their own pleasure.
[00:26:53.560 --> 00:26:58.960]   That's a rather dramatic example, but there can be just trivial examples where, you know,
[00:26:58.960 --> 00:27:03.920]   I choose to be honest rather than lie about something.
[00:27:03.920 --> 00:27:09.280]   Can I lose out a bit and I have a bit less pleasure, but I thought it was worth doing
[00:27:09.280 --> 00:27:10.280]   the honest thing or something.
[00:27:10.280 --> 00:27:14.600]   I mean, I just think so that's a, I mean, maybe you can use the word pleasure so broadly
[00:27:14.600 --> 00:27:20.040]   that you're just essentially meaning something worthwhile, but then I think the word pleasure
[00:27:20.040 --> 00:27:21.840]   maybe loses its meaning.
[00:27:21.840 --> 00:27:22.840]   - Sure.
[00:27:22.840 --> 00:27:25.720]   - Well, but what do you think about the blades of grass case?
[00:27:25.720 --> 00:27:29.120]   What do you think about someone who spends their life cutting blades of grass and doesn't
[00:27:29.120 --> 00:27:30.120]   enjoy it?
[00:27:30.120 --> 00:27:36.960]   - So I think, I personally think it's impossible, or maybe I'm not understanding even like the
[00:27:36.960 --> 00:27:41.120]   philosophical formulation, but I think it's impossible to have a goal and not draw pleasure
[00:27:41.120 --> 00:27:42.120]   from it.
[00:27:42.120 --> 00:27:45.240]   So make it worthwhile, forget the word pleasure.
[00:27:45.240 --> 00:27:48.560]   I think the word goal loses meaning.
[00:27:48.560 --> 00:27:53.440]   If I say I'm going to count the number of pens on this table, if I'm actively involved
[00:27:53.440 --> 00:27:57.600]   in the task, I will find joy in it.
[00:27:57.600 --> 00:28:05.980]   I will find, like, I think there's a lot of meaning and joy to be discovered in the skill
[00:28:05.980 --> 00:28:12.680]   of a task, in mastering of a skill and taking pride in doing it well.
[00:28:12.680 --> 00:28:19.560]   I mean, that's, I don't know what it is about the human mind, but there's some joy to be
[00:28:19.560 --> 00:28:21.800]   discovered in the mastery of a skill.
[00:28:21.800 --> 00:28:26.720]   So I think it's just impossible to count blades of grass and not sort of have the Girodreams
[00:28:26.720 --> 00:28:32.920]   of sushi compelling, like draws you into the mastery of the simple task.
[00:28:32.920 --> 00:28:42.120]   Yeah, I suppose, I mean, in a way you might think it's just hard to imagine someone who
[00:28:42.120 --> 00:28:48.520]   would spend their lives doing that, but then maybe that's just because it's so evident
[00:28:48.520 --> 00:28:51.200]   that that is a pointless task.
[00:28:51.200 --> 00:28:57.900]   Whereas if we take this David Hume view seriously, it ought to be, you know, a totally possible
[00:28:57.900 --> 00:28:58.900]   life goal.
[00:28:58.900 --> 00:29:07.640]   Because I mean, yeah, I guess I just find it hard to shake the idea that some ways of,
[00:29:07.640 --> 00:29:10.960]   some life goals are more worthwhile than others.
[00:29:10.960 --> 00:29:14.720]   And it doesn't mean, you know, that there's one single way you should lead your life,
[00:29:14.720 --> 00:29:22.360]   but pursuing knowledge, helping people, pursuing your own pleasure to an extent are worthwhile
[00:29:22.360 --> 00:29:28.040]   things to do in a way that, you know, for example, I have, I'm a little bit OCD.
[00:29:28.040 --> 00:29:33.080]   I still feel inclined to walk on cracks in the pavement or do it symmetrically.
[00:29:33.080 --> 00:29:39.520]   Like if I step on a crack with my left foot, I feel the need to do it with my right foot.
[00:29:39.520 --> 00:29:41.000]   I think that's kind of pointless.
[00:29:41.000 --> 00:29:43.760]   It's something I feel the urge to do, but it's pointless.
[00:29:43.760 --> 00:29:48.680]   Whereas other things I choose to do, I think it's worth doing.
[00:29:48.680 --> 00:29:53.760]   And it's hard to make sense of metaphysically, what could possibly ground that?
[00:29:53.760 --> 00:29:55.160]   How could we know about these facts?
[00:29:55.160 --> 00:29:58.320]   But that's the starting point for me.
[00:29:58.320 --> 00:29:59.320]   I don't know.
[00:29:59.320 --> 00:30:07.360]   I think you walking on the sidewalk in a way that's symmetrical brings order to the world.
[00:30:07.360 --> 00:30:11.080]   Like if you weren't doing that, the world might fall apart.
[00:30:11.080 --> 00:30:12.080]   And you-
[00:30:12.080 --> 00:30:13.080]   It feels like that.
[00:30:13.080 --> 00:30:17.280]   And I think there's meaning in that.
[00:30:17.280 --> 00:30:25.840]   Like you embracing the full experience of that, you living the richness of that as if
[00:30:25.840 --> 00:30:28.440]   it has meaning, will give meaning to it.
[00:30:28.440 --> 00:30:34.040]   And then whatever genius comes of that as you as one little intelligent ant will make
[00:30:34.040 --> 00:30:36.120]   a better life for everybody else.
[00:30:36.120 --> 00:30:40.360]   Perhaps I'm defending the blades of grass example, because I can literally imagine myself
[00:30:40.360 --> 00:30:45.260]   enjoying this task as somebody who's OCD in a certain kind of way and quantitative.
[00:30:45.260 --> 00:30:47.280]   But now you're ruining the example because you imagine someone enjoying it.
[00:30:47.280 --> 00:30:49.200]   I'm imagining someone who doesn't enjoy it.
[00:30:49.200 --> 00:30:53.580]   We don't want a life that's just full of pleasure.
[00:30:53.580 --> 00:30:58.200]   Like we just sit there, having a big sugar high all the time.
[00:30:58.200 --> 00:31:01.560]   We want a life where we do things that are worthwhile.
[00:31:01.560 --> 00:31:11.440]   If for something to be worthwhile just is for it to be a basic life goal, then that
[00:31:11.440 --> 00:31:13.400]   mode of reflection doesn't really make sense.
[00:31:13.400 --> 00:31:14.400]   We can't really think.
[00:31:14.400 --> 00:31:16.140]   We can't really do things worthwhile.
[00:31:16.140 --> 00:31:21.280]   On the David Hume type picture, all it is for something to be worthwhile is it was a
[00:31:21.280 --> 00:31:24.240]   basic goal of yours or derived from a basic goal.
[00:31:24.240 --> 00:31:31.120]   - Yeah, I mean, I think goal and worthwhile aren't, I think goal is a boring word.
[00:31:31.120 --> 00:31:32.720]   I'm more sort of existentialist.
[00:31:32.720 --> 00:31:35.600]   It's like, did you ride the roller coaster of life?
[00:31:35.600 --> 00:31:39.720]   Did you fully experience life?
[00:31:39.720 --> 00:31:45.000]   And in that sense, I mean, the blaze of grass is something that could be deeply joyful.
[00:31:45.000 --> 00:31:49.960]   And that's in that way, I think suffering could be joyful in the full context of life.
[00:31:49.960 --> 00:31:51.560]   It's the roller coaster of life.
[00:31:51.560 --> 00:31:57.160]   Without suffering, without struggle, without pain, without depression or sadness, there's
[00:31:57.160 --> 00:31:58.160]   not the highs.
[00:31:58.160 --> 00:32:07.800]   I mean, that's the fucked up thing about life is that the lows really make the highs that
[00:32:07.800 --> 00:32:13.560]   much richer and deeper and taste better.
[00:32:13.560 --> 00:32:21.960]   I tweeted this, I couldn't sleep and I was late at night.
[00:32:21.960 --> 00:32:36.320]   I know it's an obvious statement, but every love story eventually ends in loss, in tragedy.
[00:32:36.320 --> 00:32:44.200]   So this feeling of love, at the end, there's always going to be tragedy.
[00:32:44.200 --> 00:32:50.840]   Even if it's the most amazing lifelong love with another human being, one of you is going
[00:32:50.840 --> 00:32:51.840]   to die.
[00:32:51.840 --> 00:32:57.960]   And I don't know which is worse, but both are not going to be pretty.
[00:32:57.960 --> 00:33:06.080]   And so the sense that it's finite, the sense that it's going to end in a low, that gives
[00:33:06.080 --> 00:33:12.240]   richness to those kind of evenings when you realize this fucking thing ends.
[00:33:12.240 --> 00:33:14.120]   This thing ends.
[00:33:14.120 --> 00:33:22.200]   The feeling that it ends, that bad taste, that bad feeling that it ends gives meaning,
[00:33:22.200 --> 00:33:23.200]   gives joy, gives pleasure.
[00:33:23.200 --> 00:33:29.840]   I don't know, pleasure is this loaded word, but gives some kind of a deep pleasure to
[00:33:29.840 --> 00:33:33.760]   the experience when it's good.
[00:33:33.760 --> 00:33:40.240]   And that's the blades of grass, they have that to me.
[00:33:40.240 --> 00:33:47.080]   But you're perhaps right that it's like reducing it to a set of goals or something like that
[00:33:47.080 --> 00:33:51.160]   is kind of removing the magic of life.
[00:33:51.160 --> 00:33:58.240]   Because I think what makes counting the blades of grass joyful is just because it's life.
[00:33:58.240 --> 00:34:05.560]   Okay, so it sounds like you reject the David Hume type picture anyway, because you're saying
[00:34:05.560 --> 00:34:08.800]   just because you have it as a goal, that's what it is to be worthwhile.
[00:34:08.800 --> 00:34:14.180]   But you're saying no, it's because it's engaging with life, riding the roller coaster.
[00:34:14.180 --> 00:34:19.520]   So that does sound like in some sense, there are facts independent of our personal goal
[00:34:19.520 --> 00:34:22.920]   choices about what it means to live a good life.
[00:34:22.920 --> 00:34:28.200]   I mean, coming back full circle to the start of this was what makes us different to animals.
[00:34:28.200 --> 00:34:32.840]   I don't think at the end of a hamster's life, it thinks, "Did I ride the roller coaster?
[00:34:32.840 --> 00:34:34.880]   Did I really live life to the full?"
[00:34:34.880 --> 00:34:39.360]   That is not a mode of reflection that's available to non-human animals.
[00:34:39.360 --> 00:34:46.320]   So what do you think is the role of death in all of this?
[00:34:46.320 --> 00:34:47.920]   The fear of death?
[00:34:47.920 --> 00:34:50.160]   Does that interplay with consciousness?
[00:34:50.160 --> 00:34:53.500]   Does this self-reflection?
[00:34:53.500 --> 00:35:00.640]   Do you think there's some deep connection between this ability to contemplate the fact
[00:35:00.640 --> 00:35:07.320]   that our flame of consciousness eventually goes out?
[00:35:07.320 --> 00:35:15.100]   Yeah, I don't think unfortunately, panpsychism helps particularly with life after death,
[00:35:15.100 --> 00:35:22.960]   because for the panpsychist, there's nothing supernatural, there's nothing beyond the physical.
[00:35:22.960 --> 00:35:26.460]   All there is really is ultimately particles and fields.
[00:35:26.460 --> 00:35:31.260]   It's just that we think the ultimate nature of particles and fields is consciousness.
[00:35:31.260 --> 00:35:42.620]   But I guess when the matter in my brain ceases to be ordered in a way that sustains the particular
[00:35:42.620 --> 00:35:51.260]   kind of consciousness I enjoy in waking life, then in some sense, I will cease to be.
[00:35:51.260 --> 00:35:57.340]   Although I do, the final chapter of my book, Galileo's Error, is more experimental.
[00:35:57.340 --> 00:36:02.960]   So the first four chapters are the cold-blooded case for the panpsychist view is the best
[00:36:02.960 --> 00:36:05.420]   solution to the hard problem of consciousness.
[00:36:05.420 --> 00:36:07.100]   The last chapter, we talk about meaning.
[00:36:07.100 --> 00:36:11.720]   Yeah, I talk about meaning, I talk about free will, and I talk about mystical experiences.
[00:36:11.720 --> 00:36:19.620]   So I always want to emphasize that panpsychism is not necessarily connected to anything spiritual.
[00:36:19.620 --> 00:36:25.960]   A lot of people defending this view, like David Chalmers or Luke Roloff, are just total
[00:36:25.960 --> 00:36:27.440]   atheist secularists.
[00:36:27.440 --> 00:36:34.340]   They don't believe in any kind of transcendent reality, they just believe in feelings, mundane
[00:36:34.340 --> 00:36:38.600]   consciousness and think that needs explaining and our conventional scientific approach can't
[00:36:38.600 --> 00:36:40.040]   cut it.
[00:36:40.040 --> 00:36:48.540]   But if for independent reasons, you are motivated to some spiritual picture of reality, then
[00:36:48.540 --> 00:36:51.660]   maybe a panpsychist view is more consonant with that.
[00:36:51.660 --> 00:36:59.760]   So if you have a mystical experience where it seems to you in this experience that there
[00:36:59.760 --> 00:37:07.260]   is this higher form of consciousness at the root of all things, if you're a materialist,
[00:37:07.260 --> 00:37:08.740]   you've got to think that's a delusion.
[00:37:08.740 --> 00:37:12.380]   There's just something in your brain making you think that it's not real.
[00:37:12.380 --> 00:37:17.940]   But if you're a panpsychist and you already think the fundamental nature of reality is
[00:37:17.940 --> 00:37:25.620]   constituted of consciousness, it's not that much of a leap to think that this higher form
[00:37:25.620 --> 00:37:30.500]   of consciousness you seem to apprehend in the mystical experience is part of that underlying
[00:37:30.500 --> 00:37:31.500]   reality.
[00:37:31.500 --> 00:37:39.980]   And in many different cultures, experienced meditators have claimed to have experiences
[00:37:39.980 --> 00:37:46.380]   in which it becomes apparent to them that there is an element of consciousness that
[00:37:46.380 --> 00:37:47.780]   is universal.
[00:37:47.780 --> 00:37:50.620]   So this is sometimes called universal consciousness.
[00:37:50.620 --> 00:37:58.540]   So on this view, your mind and my mind are not totally distinct.
[00:37:58.540 --> 00:38:03.660]   Each of our individual conscious minds is built upon the foundations of universal consciousness.
[00:38:03.660 --> 00:38:08.940]   And universal consciousness as it exists in me is one and the same thing as universal
[00:38:08.940 --> 00:38:12.300]   consciousness as it exists in you.
[00:38:12.300 --> 00:38:16.260]   So I've never had one of these experiences.
[00:38:16.260 --> 00:38:21.620]   But if one is a panpsychist, I think one is more open to that possibility.
[00:38:21.620 --> 00:38:27.140]   I don't see why it shouldn't be the case that that is part of the nature of consciousness
[00:38:27.140 --> 00:38:31.420]   and maybe something that is apparent in certain deep states of meditation.
[00:38:31.420 --> 00:38:36.180]   And so what I explore in the experimental final chapter of my book is that could allow
[00:38:36.180 --> 00:38:41.580]   for a kind of impersonal life after death.
[00:38:41.580 --> 00:38:48.420]   Because if that view is true, then even when the particular aspects of my conscious experience
[00:38:48.420 --> 00:38:55.640]   fall away, that element of universal consciousness at the core of my identity would continue
[00:38:55.640 --> 00:38:57.120]   to exist.
[00:38:57.120 --> 00:39:00.380]   So I'd sort of be, as it were, absorbed into universal consciousness.
[00:39:00.380 --> 00:39:10.060]   So Buddhists and Hindu mystics try to meditate to get rid of all the bad karma to be absorbed
[00:39:10.060 --> 00:39:12.020]   into universal consciousness.
[00:39:12.020 --> 00:39:17.100]   It could be that if there's no karma, if there's no reverb, maybe everyone gets enlightened
[00:39:17.100 --> 00:39:18.100]   when they die.
[00:39:18.100 --> 00:39:22.420]   Maybe you just sink back into universal consciousness.
[00:39:22.420 --> 00:39:29.940]   So I also, coming back to morality, suggest this could provide some kind of basis for
[00:39:29.940 --> 00:39:32.660]   altruism or non-egotism.
[00:39:32.660 --> 00:39:40.060]   Because if you think egotism implicitly assumes that we are utterly distinct individuals,
[00:39:40.060 --> 00:39:46.340]   whereas on this view, we overlap to an extent that something at the core of our being is...
[00:39:46.340 --> 00:39:49.040]   Even in this life, we overlap.
[00:39:49.040 --> 00:39:54.220]   - That would be this view that some experienced meditators claim becomes apparent to them,
[00:39:54.220 --> 00:40:01.140]   that there is something at the core of my identity that is one and the same as the thing
[00:40:01.140 --> 00:40:06.180]   at the core of your identity, this universal consciousness.
[00:40:06.180 --> 00:40:09.100]   - There is something very...
[00:40:09.100 --> 00:40:13.820]   You and I in this conversation, there's a few people listening to this, all of us are
[00:40:13.820 --> 00:40:19.140]   in a kind of single mind together.
[00:40:19.140 --> 00:40:24.420]   There's some small aspect of that, or maybe a big aspect.
[00:40:24.420 --> 00:40:31.940]   But us humans, so certainly in the space of ideas, we kind of meld together for time,
[00:40:31.940 --> 00:40:35.740]   at least, in a conversation, and kind of play with that idea.
[00:40:35.740 --> 00:40:40.220]   And then we're clearly all thinking, like if I say pink elephant, there's going to be
[00:40:40.220 --> 00:40:43.140]   a few people that are now visualizing a pink elephant.
[00:40:43.140 --> 00:40:46.460]   We're all thinking about that pink elephant together.
[00:40:46.460 --> 00:40:49.740]   We're all in the room together thinking about this pink elephant.
[00:40:49.740 --> 00:40:55.540]   We're rotating it in our minds together.
[00:40:55.540 --> 00:40:56.540]   What is that?
[00:40:56.540 --> 00:41:02.020]   That pink elephant, is there a different instantiation of that pink elephant in everybody's mind,
[00:41:02.020 --> 00:41:06.500]   or is it the same elephant, and we have the same mind exploring that elephant?
[00:41:06.500 --> 00:41:11.780]   Now if we in our mind start petting that elephant, like touching it, that experience that we're
[00:41:11.780 --> 00:41:15.380]   now thinking what that would feel like, what's that?
[00:41:15.380 --> 00:41:18.660]   Is that all of us experiencing that together, or is that separate?
[00:41:18.660 --> 00:41:23.500]   So there's some aspect of the togetherness that almost seems fundamental to civilization,
[00:41:23.500 --> 00:41:24.500]   to society.
[00:41:24.500 --> 00:41:30.940]   Hopefully that's not too strong, but to some of the fundamental properties of the human
[00:41:30.940 --> 00:41:35.000]   mind, it feels like the social aspect is really important.
[00:41:35.000 --> 00:41:40.160]   We call it social because we think of us as individual minds interacting.
[00:41:40.160 --> 00:41:45.520]   But if we're just like one collective mind with like fingertips that are like touching
[00:41:45.520 --> 00:41:51.680]   each other as it's trying to explore the elephant, but that could be just in the realm of ideas
[00:41:51.680 --> 00:41:55.040]   and intelligence and not in the realm of consciousness.
[00:41:55.040 --> 00:41:58.200]   It's interesting to see maybe it is in the realm of consciousness.
[00:41:58.200 --> 00:42:04.500]   - Yeah, so it's obviously certainly true in some sense that there are these phenomena
[00:42:04.500 --> 00:42:08.040]   that you're talking about of collective consciousness in some sense.
[00:42:08.040 --> 00:42:14.340]   I suppose the question is, how ontologically serious do we want to be about those things?
[00:42:14.340 --> 00:42:20.520]   By which I mean, are they just a construction out of our minds and the fact that we interact
[00:42:20.520 --> 00:42:25.320]   in the standardly scientifically accepted ways?
[00:42:25.320 --> 00:42:30.340]   Or is as someone like Rupert Sheldrake would think that there is some metaphysical reality,
[00:42:30.340 --> 00:42:35.480]   there are some fields beyond the scientifically understood ones that are somehow communicating
[00:42:35.480 --> 00:42:36.480]   this?
[00:42:36.480 --> 00:42:41.560]   I mean, the view I was describing was that this element we're supposed to have in common
[00:42:41.560 --> 00:42:47.660]   is some sort of pure impersonal consciousness or something rather than...
[00:42:47.660 --> 00:42:51.900]   So actually, an interesting figure is the Australian philosopher, Miri Al-Bahari, who
[00:42:51.900 --> 00:42:59.960]   defends a kind of mystical conceptual reality rooted in Advaita Vedanta mysticism.
[00:42:59.960 --> 00:43:03.940]   But like me, she's from this tradition of analytic philosophy.
[00:43:03.940 --> 00:43:07.880]   And so she defends this in this incredibly precise, rigorous way.
[00:43:07.880 --> 00:43:13.080]   She defends the idea that we should think of experienced meditators as providing expert
[00:43:13.080 --> 00:43:14.660]   testimony.
[00:43:14.660 --> 00:43:20.060]   So I think humans are causing climate breakdown.
[00:43:20.060 --> 00:43:25.220]   I have no idea the science behind it, but I trust the experts or that the universe is
[00:43:25.220 --> 00:43:27.060]   14 billion years old.
[00:43:27.060 --> 00:43:30.360]   Most of our knowledge is based on expert testimony.
[00:43:30.360 --> 00:43:34.740]   And she thinks we should think of experienced meditators, these people who are telling us
[00:43:34.740 --> 00:43:39.800]   about this universal consciousness at the core of our being as a relevant kind of expert.
[00:43:39.800 --> 00:43:45.440]   And so she wants to defend the rational acceptability of this mystical conceptual reality.
[00:43:45.440 --> 00:43:53.860]   So I think we shouldn't be ashamed, we shouldn't be worried about dealing with certain views
[00:43:53.860 --> 00:43:57.740]   as long as it's done with rigor and seriousness.
[00:43:57.740 --> 00:44:02.040]   I think sometimes terms like, I don't know, new age or something can function a bit like
[00:44:02.040 --> 00:44:03.040]   racist terms.
[00:44:03.040 --> 00:44:10.340]   A racist term picks out a group of people, but then implies certain negative characteristics.
[00:44:10.340 --> 00:44:15.560]   So people use this term to pick out a certain set of views like mystical conceptual reality
[00:44:15.560 --> 00:44:19.280]   and imply it's kind of fluffy thinking.
[00:44:19.280 --> 00:44:25.400]   But you read Miri Al-Bahari, you read Luke Roloff's, this is serious, rigorous thought,
[00:44:25.400 --> 00:44:28.520]   whether you agree with it or not, obviously, it's hugely controversial.
[00:44:28.520 --> 00:44:33.800]   And so the Enlightenment ideal is to follow the evidence and the arguments where they
[00:44:33.800 --> 00:44:35.560]   lead.
[00:44:35.560 --> 00:44:37.920]   But it's kind of very hard for human beings to do that.
[00:44:37.920 --> 00:44:47.320]   I think we get stuck in some conception of how we think science ought to look.
[00:44:47.320 --> 00:44:52.760]   And people talk about religion as a crutch, but I think a certain kind of scientism, a
[00:44:52.760 --> 00:44:57.280]   certain conception of how science is supposed to be gets into people's identity and their
[00:44:57.280 --> 00:45:01.920]   sense of themselves and their security.
[00:45:01.920 --> 00:45:04.840]   And make things hard if you're a punch like us.
[00:45:04.840 --> 00:45:09.400]   - And even the word expert becomes a kind of a crutch.
[00:45:09.400 --> 00:45:15.120]   I mean, you use the word expert, you have some kind of conception of what expertise
[00:45:15.120 --> 00:45:16.640]   means.
[00:45:16.640 --> 00:45:21.840]   Oftentimes that's connected with a degree at particularly prestigious university or
[00:45:21.840 --> 00:45:22.840]   something like that.
[00:45:22.840 --> 00:45:28.200]   Or expertise is a funny one.
[00:45:28.200 --> 00:45:33.480]   I've noticed that anybody sort of that claims they're an expert is usually not the expert.
[00:45:33.480 --> 00:45:38.800]   The biggest quote unquote expert that I've ever met are the ones that are truly humble.
[00:45:38.800 --> 00:45:45.440]   So the humility is a really good sign of somebody who's traveled a long road and been humbled
[00:45:45.440 --> 00:45:47.480]   by how little they know.
[00:45:47.480 --> 00:45:51.280]   So some of the best people in the world at whatever the thing they've spent their life
[00:45:51.280 --> 00:45:55.920]   doing are the ones that are ultimately humble in the face of it all.
[00:45:55.920 --> 00:46:02.280]   So like just being humble, how little we know, even if we travel a lifetime.
[00:46:02.280 --> 00:46:03.760]   I do like the idea.
[00:46:03.760 --> 00:46:10.000]   I mean, treating sort of like, what is it, psychonauts, like an expert witness, you know,
[00:46:10.000 --> 00:46:16.320]   people who have traveled with the help of DMT to another place where they got some deep
[00:46:16.320 --> 00:46:22.920]   understanding of something and their insight is perhaps as valuable as the insight of somebody
[00:46:22.920 --> 00:46:29.360]   who ran rigorous psychological studies at Princeton University or something.
[00:46:29.360 --> 00:46:35.680]   Like those psychonauts, they have wisdom if it's done rigorously, which you can also do
[00:46:35.680 --> 00:46:40.760]   rigorously within the university, within the studies now with psilocybin and those kinds
[00:46:40.760 --> 00:46:41.760]   of things.
[00:46:41.760 --> 00:46:42.760]   Yeah, that's fascinating.
[00:46:42.760 --> 00:46:49.160]   It's still probably the best, one of the best works on mystical experience is the chapter
[00:46:49.160 --> 00:46:53.600]   in William James's Varieties of Religious Experiences.
[00:46:53.600 --> 00:46:59.080]   Most of it is just a psychological study of trying to define the characteristics of mystical
[00:46:59.080 --> 00:47:01.800]   experience as a psychological type.
[00:47:01.800 --> 00:47:07.160]   But at the end, he considers the question, if you have a mystical experience, is it rational
[00:47:07.160 --> 00:47:11.520]   to trust it, to trust that it's telling you something about reality?
[00:47:11.520 --> 00:47:12.640]   And he makes an interesting argument.
[00:47:12.640 --> 00:47:18.760]   He says, if you say no, you're kind of applying a double standard because we all think it's
[00:47:18.760 --> 00:47:26.320]   okay to trust our normal sensory experiences, but we have no way of getting outside of ourselves
[00:47:26.320 --> 00:47:31.120]   to prove that our sensory experiences correspond to an external reality.
[00:47:31.120 --> 00:47:32.360]   We could be in the matrix.
[00:47:32.360 --> 00:47:35.120]   This could be a very vivid dream.
[00:47:35.120 --> 00:47:43.360]   You could say, oh, we do science, but a scientist only gets their data by experiencing the results
[00:47:43.360 --> 00:47:44.640]   of their experiments.
[00:47:44.640 --> 00:47:48.320]   And then the question arises again, how do you know that corresponds to a real world?
[00:47:48.320 --> 00:47:53.160]   So he thinks there's a sort of double standard in saying it's okay to trust our ordinary
[00:47:53.160 --> 00:47:58.680]   sensory experiences, but it's not okay for the person on DMT to trust those experiences.
[00:47:58.680 --> 00:48:04.440]   It's very philosophically difficult to say why is it okay in the one case and not the
[00:48:04.440 --> 00:48:05.440]   other?
[00:48:05.440 --> 00:48:08.960]   So I think there's an interesting argument there, but I would like to just defend experts
[00:48:08.960 --> 00:48:09.960]   a little bit.
[00:48:09.960 --> 00:48:15.640]   I mean, I agree it's very difficult, but especially in an age, I guess, where there's so much
[00:48:15.640 --> 00:48:26.720]   information, I do think it's important to have some protection of sources of information,
[00:48:26.720 --> 00:48:29.280]   academic institutions that we can trust.
[00:48:29.280 --> 00:48:32.920]   And then that's difficult because of course there are non-academics who do know what they're
[00:48:32.920 --> 00:48:40.160]   talking about, but if I'm interested in knowing about biology, you can't research everything.
[00:48:40.160 --> 00:48:47.960]   So I think we have to have some sense of who are the experts we can trust, the people who've
[00:48:47.960 --> 00:48:53.920]   spent a lot of time reading all the material that people have read, written, thinking about
[00:48:53.920 --> 00:48:59.280]   it, having their views torn apart by other people working in the field.
[00:48:59.280 --> 00:49:03.360]   I think that is very important and also to protect that from conflicts of interest.
[00:49:03.360 --> 00:49:07.880]   There is a so-called think tank in the UK called the Institute of Economic Affairs who
[00:49:07.880 --> 00:49:14.920]   are always on the BBC as experts on economic questions and they do not declare who funds
[00:49:14.920 --> 00:49:16.280]   them.
[00:49:16.280 --> 00:49:19.520]   So we don't know who's paying the piper.
[00:49:19.520 --> 00:49:24.680]   I think you shouldn't be allowed to call yourself a think tank if you're not totally transparent
[00:49:24.680 --> 00:49:26.440]   about who's funding you.
[00:49:26.440 --> 00:49:27.440]   So I think that's it.
[00:49:27.440 --> 00:49:35.160]   And I mean, this connects to panpsychism because I think the reason people worry about unorthodox
[00:49:35.160 --> 00:49:39.480]   ideas is because they worry about how do we know when we're just losing control or losing
[00:49:39.480 --> 00:49:40.480]   discipline.
[00:49:40.480 --> 00:49:49.280]   So I do think we need to somehow protect academic institutions as sources of information that
[00:49:49.280 --> 00:49:50.280]   we can trust.
[00:49:50.280 --> 00:49:56.400]   And in philosophy, there's not much consensus on everything, but you can at least know,
[00:49:56.400 --> 00:50:03.200]   you can know what people who have put the time in to read all the stuff, what they think
[00:50:03.200 --> 00:50:04.200]   about these issues.
[00:50:04.200 --> 00:50:05.200]   I think that is important.
[00:50:05.200 --> 00:50:07.600]   - So push back on your pushback.
[00:50:07.600 --> 00:50:09.920]   Who are the experts on COVID?
[00:50:09.920 --> 00:50:12.920]   - Oh dear, getting into dangerous territory now.
[00:50:12.920 --> 00:50:18.520]   - Well, let me just speak to it because I am walking through that dangerous territory.
[00:50:18.520 --> 00:50:33.080]   I'm allergic to the word expert because in my simple mind, it kind of rhymes with ego.
[00:50:33.080 --> 00:50:36.160]   There's something about experts.
[00:50:36.160 --> 00:50:43.640]   If we allow too much to have a category expert and place certain people in them, those people
[00:50:43.640 --> 00:50:51.040]   sitting on the throne start to believe it and they start to communicate with that energy
[00:50:51.040 --> 00:50:54.360]   and the humility starts to dissipate.
[00:50:54.360 --> 00:51:05.760]   I think there is value in a lifelong mastery of a skill and the pursuit of knowledge within
[00:51:05.760 --> 00:51:07.940]   a very specific discipline.
[00:51:07.940 --> 00:51:13.440]   But the moment you have your name on an office, the moment you're an expert, I think you
[00:51:13.440 --> 00:51:21.200]   destroy the very aspect, the very value of that journey towards knowledge.
[00:51:21.200 --> 00:51:28.600]   So some of it probably just reduces to like skillful communication, like of communicating
[00:51:28.600 --> 00:51:34.520]   in a way that shows humility, that shows an open-mindedness, that shows an ability to
[00:51:34.520 --> 00:51:37.720]   really hear what a lot of people are saying.
[00:51:37.720 --> 00:51:42.720]   So in the case of COVID, what I've noticed, and this is true, this is probably true with
[00:51:42.720 --> 00:51:51.280]   panpsychism as well, is so-called experts, and they are extremely knowledgeable, many
[00:51:51.280 --> 00:51:57.780]   of them are colleagues of mine, they dismiss what millions of people are saying on the
[00:51:57.780 --> 00:52:05.200]   internet without having looked into it with empathy and rigor, honestly, understand what
[00:52:05.200 --> 00:52:07.120]   are the arguments being made.
[00:52:07.120 --> 00:52:10.360]   They say like, "There's not enough time to explore all those things, like there's so
[00:52:10.360 --> 00:52:11.360]   much stuff out there."
[00:52:12.040 --> 00:52:15.720]   Yeah, I think that's intellectual laziness.
[00:52:15.720 --> 00:52:21.120]   If you don't have enough time, then don't speak so strongly with dismissal.
[00:52:21.120 --> 00:52:25.040]   Feel bad about it, be apologetic about the fact that you don't have enough time to explore
[00:52:25.040 --> 00:52:27.120]   the evidence.
[00:52:27.120 --> 00:52:35.480]   For example, the heat I got with Francis Collins is that he kind of said that LabLeak, he kind
[00:52:35.480 --> 00:52:45.120]   of dismissed it, showing that he didn't really deeply explore all the huge amount of circumstantial
[00:52:45.120 --> 00:52:48.520]   evidence out there, the battles that are going on out there.
[00:52:48.520 --> 00:52:56.160]   There's a lot of people really tensely discussing this, and showing humility in the face of
[00:52:56.160 --> 00:52:58.680]   that battle of ideas I think is really important.
[00:52:58.680 --> 00:53:04.960]   And I've just been very disappointed in so-called expertise in the space of science, in showing
[00:53:04.960 --> 00:53:11.120]   humility and showing humanity and kindness and empathy towards other human beings.
[00:53:11.120 --> 00:53:21.080]   At the same time, obviously, I love "Jiro Dreams of Sushi," lifelong pursuit of getting
[00:53:21.080 --> 00:53:24.400]   in computer science, Don Knuth.
[00:53:24.400 --> 00:53:32.400]   Some of my biggest heroes are people that when nobody else cares, they stay on one topic
[00:53:32.400 --> 00:53:36.520]   for their whole life, and they just find the beautiful little things about their puzzles
[00:53:36.520 --> 00:53:37.840]   they keep solving.
[00:53:37.840 --> 00:53:44.960]   And yes, sometimes a virus happens or something happens where that person with their puzzles
[00:53:44.960 --> 00:53:49.080]   becomes like the center of the whole world, because that puzzle becomes all of a sudden
[00:53:49.080 --> 00:53:50.280]   really important.
[00:53:50.280 --> 00:53:54.600]   But still, there's responsibilities on them to show humility and to be open-minded to
[00:53:54.600 --> 00:53:59.880]   the fact that even if they spent their whole life doing it, even if their whole community
[00:53:59.880 --> 00:54:06.640]   is giving them awards and giving them citations and giving them all kinds of stuff where they're
[00:54:06.640 --> 00:54:13.760]   bowing down before them how smart they are, they still know nothing relative to all the
[00:54:13.760 --> 00:54:15.560]   stuff, the mysteries that are out there.
[00:54:15.560 --> 00:54:18.000]   Yeah, I wonder how much we're disagreeing.
[00:54:18.000 --> 00:54:20.160]   I mean, these are totally valid issues.
[00:54:20.160 --> 00:54:24.760]   And of course, expertise goes wrong in all sorts of ways.
[00:54:24.760 --> 00:54:25.760]   It's totally fallible.
[00:54:25.760 --> 00:54:29.240]   I suppose I would just say, what is the alternative?
[00:54:29.240 --> 00:54:34.160]   Or do we just say all information is equal?
[00:54:34.160 --> 00:54:42.600]   Because as a voter, I've got to decide who to vote for, and I've got to evaluate.
[00:54:42.600 --> 00:54:47.960]   And I can't look into all of the economics and all of the relevant science.
[00:54:47.960 --> 00:54:56.620]   And so I just think, maybe it's like Churchill said about democracy, it's the worst system
[00:54:56.620 --> 00:54:59.040]   of government apart from all the rest.
[00:54:59.040 --> 00:55:02.440]   I think about panpsychism, it's the worst theory of consciousness apart from all the
[00:55:02.440 --> 00:55:03.440]   rest.
[00:55:03.440 --> 00:55:10.960]   But I just think expertise, the peer review system, I think it's terrible in so many ways.
[00:55:10.960 --> 00:55:17.000]   Yes, people should show more humility, but I can't see a viable alternative.
[00:55:17.000 --> 00:55:21.300]   I think philosopher Bernard Williams had a really nice nuanced discussion of the problems
[00:55:21.300 --> 00:55:27.160]   of titles, but how they also function in a society.
[00:55:27.160 --> 00:55:28.960]   They do have some positive function.
[00:55:28.960 --> 00:55:39.240]   The very first time I lectured in philosophy, before I got a professorship, was teaching
[00:55:39.240 --> 00:55:41.640]   at a continuing education college.
[00:55:41.640 --> 00:55:47.920]   That's kind of for retired people who want to learn some more things.
[00:55:47.920 --> 00:55:50.160]   And I just totally pitched it too high.
[00:55:50.160 --> 00:55:54.880]   And Gaet talked about Bernard Williams on titles and hierarchies.
[00:55:54.880 --> 00:56:00.680]   And these kind of people in their 70s and 80s were just instantly started interrupting
[00:56:00.680 --> 00:56:02.240]   saying, "What is philosophy?"
[00:56:02.240 --> 00:56:04.480]   And it was a disaster.
[00:56:04.480 --> 00:56:08.640]   And I just remember in the breaks, a sort of elderly lady comes up and said, "I've decided
[00:56:08.640 --> 00:56:11.880]   to take Egyptology instead."
[00:56:11.880 --> 00:56:16.280]   But that was my introduction to teaching.
[00:56:16.280 --> 00:56:22.880]   But sort of titles and accomplishments is a nice starting point, but doesn't buy you
[00:56:22.880 --> 00:56:24.160]   the whole thing.
[00:56:24.160 --> 00:56:29.880]   So you don't get to just say, "This is true because I'm an expert."
[00:56:29.880 --> 00:56:31.880]   You still have to convince people.
[00:56:31.880 --> 00:56:36.360]   One of the things I really like, so I practice martial arts.
[00:56:36.360 --> 00:56:41.040]   And for people who don't know, Brazilian Jiu-Jitsu is one of them.
[00:56:41.040 --> 00:56:45.760]   And you sometimes wear these pajamas, pajama looking things, and you wear a belt.
[00:56:45.760 --> 00:56:49.640]   So I happen to be a black belt in Brazilian Jiu-Jitsu.
[00:56:49.640 --> 00:56:54.800]   And I also train in what's called no gi, so you don't wear the pajamas.
[00:56:54.800 --> 00:56:59.760]   And when you don't wear the pajamas, nobody knows what rank you are.
[00:56:59.760 --> 00:57:02.800]   Nobody knows if you're a black belt or a white belt, or if you're a complete beginner or
[00:57:02.800 --> 00:57:03.920]   not.
[00:57:03.920 --> 00:57:09.680]   And when you wear the pajamas, called the gi, you wear the rank.
[00:57:09.680 --> 00:57:12.360]   And people treat you very differently.
[00:57:12.360 --> 00:57:15.640]   When they see my black belt, they treat me differently.
[00:57:15.640 --> 00:57:18.760]   They kind of defer to my expertise.
[00:57:18.760 --> 00:57:28.720]   If they're kicking my ass, that's probably because I am working on something new, or
[00:57:28.720 --> 00:57:31.000]   maybe I'm letting them win.
[00:57:31.000 --> 00:57:35.800]   But when there's no belts, and it doesn't matter if I've been doing this for 15 years,
[00:57:35.800 --> 00:57:36.800]   it doesn't matter.
[00:57:36.800 --> 00:57:37.800]   None of it matters.
[00:57:37.800 --> 00:57:45.040]   What matters is the raw interaction of just trying to kick each other's ass, and seeing
[00:57:45.040 --> 00:57:51.800]   what is this chess game, like a human chess, what are the ideas that we're playing with?
[00:57:51.800 --> 00:57:54.360]   And I think there's a dance there.
[00:57:54.360 --> 00:58:00.640]   Yes, it's valuable to know a person as a black belt when you take consideration of the advice
[00:58:00.640 --> 00:58:05.240]   of different people, me versus somebody who's only practiced for like a couple of days.
[00:58:05.240 --> 00:58:12.120]   But at the same time, the raw practice of ideas that is combat, and the raw practice
[00:58:12.120 --> 00:58:18.680]   of exchange of ideas that is science, needs to often throw away expertise.
[00:58:18.680 --> 00:58:25.280]   And in communicating, there's another thing to science and expertise, which is leadership.
[00:58:25.280 --> 00:58:30.680]   It's not just, so the scientific method in the review process is this rigorous battle
[00:58:30.680 --> 00:58:33.740]   of ideas between scientists.
[00:58:33.740 --> 00:58:38.920]   But there's also a stepping up and inspiring the world, and communicating ideas to the
[00:58:38.920 --> 00:58:39.920]   world.
[00:58:39.920 --> 00:58:47.240]   And that skill of communication, I suppose that's my biggest criticism of so-called experts
[00:58:47.240 --> 00:58:50.440]   in science, is they're just shitty communicators.
[00:58:50.440 --> 00:58:51.440]   Absolutely.
[00:58:51.440 --> 00:58:52.440]   Yeah.
[00:58:52.440 --> 00:58:56.880]   Well, I can tell you, I get very frustrated with philosophers not reaching out more.
[00:58:56.880 --> 00:59:03.720]   I mean, I think it might be partly that we're trained to get watertight arguments, respond
[00:59:03.720 --> 00:59:05.400]   to all objections.
[00:59:05.400 --> 00:59:11.800]   And as you do that, eventually it gets more complicated and the jargon comes in.
[00:59:11.800 --> 00:59:18.520]   But then if, so to write a more accessible book or article, you have to loosen the arguments
[00:59:18.520 --> 00:59:19.520]   a bit.
[00:59:19.520 --> 00:59:22.640]   And then we worry that other philosophers will think, "Oh, that's a really crap argument."
[00:59:22.640 --> 00:59:28.440]   So I mean, the way I did it, I wrote my academic book first, which is just a fundamental reality.
[00:59:28.440 --> 00:59:32.040]   And then a more accessible book, Galileo's Error, where the arguments, you know, not
[00:59:32.040 --> 00:59:33.980]   as rigorously worked out.
[00:59:33.980 --> 00:59:38.120]   So then I can say the proper arguments, you know, the further arguments there.
[00:59:38.120 --> 00:59:39.120]   But I get very frustrated.
[00:59:39.120 --> 00:59:40.120]   That's brilliantly done, by the way.
[00:59:40.120 --> 00:59:46.120]   Like that's such a, so for people who don't know, you first wrote Consciousness and Fundamental
[00:59:46.120 --> 00:59:47.120]   Reality.
[00:59:47.120 --> 00:59:49.120]   So that's the academic book, also very good.
[00:59:49.120 --> 00:59:52.200]   I flew through it last night, bought it.
[00:59:52.200 --> 00:59:58.120]   And then obviously the popular book is Galileo's Error, Foundations for a New Science of Consciousness.
[00:59:58.120 --> 01:00:00.320]   That's kind of the right way to do it.
[01:00:00.320 --> 01:00:04.000]   To show that you're legit to your community, to the world by doing the book that's normally
[01:00:04.000 --> 01:00:11.160]   going to read, and then doing a popular book that everybody's going to read.
[01:00:11.160 --> 01:00:12.160]   That's cool.
[01:00:12.160 --> 01:00:16.800]   Well, I try now, every time I write an academic article, I try to write a more accessible
[01:00:16.800 --> 01:00:17.800]   version.
[01:00:17.800 --> 01:00:24.280]   I mean, the thing I've been working on recently, just because there's this argument.
[01:00:24.280 --> 01:00:31.560]   So there's a certain argument from the cosmological fine tuning of the laws of physics for life
[01:00:31.560 --> 01:00:38.640]   to the multiverse that's quite popular physicists like Max Tegmark.
[01:00:38.640 --> 01:00:46.880]   There's an argument in philosophy journals that there's a fallacious line of reasoning
[01:00:46.880 --> 01:00:50.300]   going on there from the fine tuning to the multiverse.
[01:00:50.300 --> 01:00:56.560]   Now that argument is from 20, 30 years ago, and it's discussed in academic philosophy.
[01:00:56.560 --> 01:00:57.560]   Nobody knows about it.
[01:00:57.560 --> 01:01:01.000]   And there is huge interest in this fine tuning stuff.
[01:01:01.000 --> 01:01:04.960]   Scientists wanting to argue for the multiverse, theists wanting to say this is evidence for
[01:01:04.960 --> 01:01:10.600]   God and nobody knows about this argument, which tries to show that it's fallacious reasoning
[01:01:10.600 --> 01:01:12.880]   to go from the fine tuning to the multiverse.
[01:01:12.880 --> 01:01:18.280]   So I wrote a piece for Scientific American explaining this argument to a more general
[01:01:18.280 --> 01:01:19.280]   audience.
[01:01:19.280 --> 01:01:27.400]   And it just really irritates me that it's just buried in these technical journal articles
[01:01:27.400 --> 01:01:29.680]   and nobody knows about it.
[01:01:29.680 --> 01:01:33.800]   But just a final thing on that.
[01:01:33.800 --> 01:01:36.740]   I don't disagree with anything you said, and that's kind of really beautiful, that martial
[01:01:36.740 --> 01:01:41.120]   arts example and thinking how that could be analogous.
[01:01:41.120 --> 01:01:51.600]   But I think it's very rare to find a good philosopher who hasn't given a talk to other
[01:01:51.600 --> 01:01:53.920]   philosophers and had objections raised.
[01:01:53.920 --> 01:01:58.260]   I was going to say have it torn apart, but that's maybe thinking of it in the wrong way.
[01:01:58.260 --> 01:02:02.840]   But have the best objections raised to it.
[01:02:02.840 --> 01:02:11.360]   And that's why that is an important formative process that you go through as an academic,
[01:02:11.360 --> 01:02:19.800]   that the greatest minds starting a philosophy degree, for example, won't have gone through,
[01:02:19.800 --> 01:02:26.040]   probably except in very rare cases, just won't have the skills required.
[01:02:26.040 --> 01:02:30.280]   But part of it is just fun to disagree and dance with.
[01:02:30.280 --> 01:02:36.640]   I think to elaborate on what you're saying in agreement, not just gone through that,
[01:02:36.640 --> 01:02:38.240]   but continue to go through that.
[01:02:38.240 --> 01:02:39.240]   Absolutely.
[01:02:39.240 --> 01:02:44.600]   That's, I would say, the biggest problem with "expertise" is that there's a certain point
[01:02:44.600 --> 01:02:48.000]   where you get, because it sucks.
[01:02:48.000 --> 01:02:53.360]   Is martial arts, this is a good example of that, it sucks to get your ass kicked.
[01:02:53.360 --> 01:02:54.360]   There's a temptation.
[01:02:54.360 --> 01:02:57.320]   I still go, I train.
[01:02:57.320 --> 01:03:02.200]   You're getting older too, but also there's killers out there in both the space of martial
[01:03:02.200 --> 01:03:04.800]   arts and the space of science.
[01:03:04.800 --> 01:03:09.600]   And I think that once you become a professor, like more and more senior and more and more
[01:03:09.600 --> 01:03:14.280]   respected, I don't know if you get your ass kicked in the space of ideas as often.
[01:03:14.280 --> 01:03:18.720]   I don't know if you allow yourself to truly expose yourself.
[01:03:18.720 --> 01:03:26.320]   If you do, that's a great sign of a humble, brilliant mind.
[01:03:26.320 --> 01:03:28.480]   Always constantly exposing yourself to that.
[01:03:28.480 --> 01:03:35.880]   I think you do, because I think there's graduate students who want to find the objection to
[01:03:35.880 --> 01:03:37.920]   write their paper or make their mark.
[01:03:37.920 --> 01:03:45.120]   And yeah, I think everyone still gives talks or should give talks and people are wanting
[01:03:45.120 --> 01:03:49.120]   to work out if there are any weaknesses to your position.
[01:03:49.120 --> 01:03:53.560]   So yeah, I think that generally works out.
[01:03:53.560 --> 01:04:00.720]   There is also a kind of, who do you give the talks to?
[01:04:00.720 --> 01:04:08.280]   So I mean, within communities, the little cluster of people that argue and bicker, but
[01:04:08.280 --> 01:04:10.720]   what are they arguing about?
[01:04:10.720 --> 01:04:17.520]   They take a bunch of stuff, a bunch of basic assumptions as agreement, and they heatedly
[01:04:17.520 --> 01:04:19.520]   argue about certain ideas.
[01:04:19.520 --> 01:04:21.580]   The question is how open are...
[01:04:21.580 --> 01:04:22.840]   That's actually kind of like fun.
[01:04:22.840 --> 01:04:26.920]   It's like, no offense, sorry, we're sticking on this martial arts thing.
[01:04:26.920 --> 01:04:31.960]   It's like people who practice Aikido or certain martial arts that don't truly test themselves
[01:04:31.960 --> 01:04:35.440]   in the cage, in combat.
[01:04:35.440 --> 01:04:40.640]   So it's fun to argue about certain things when you're in your own community, but you
[01:04:40.640 --> 01:04:50.460]   don't test those ideas in the full context of science, in the full seriousness, the rigor
[01:04:50.460 --> 01:04:53.020]   of the, sometimes like the real world.
[01:04:53.020 --> 01:04:55.720]   One of my favorite fields is psychology.
[01:04:55.720 --> 01:05:00.460]   There's often places within psychology where you're kind of doing these studies and arguing
[01:05:00.460 --> 01:05:02.740]   about stuff that's done in the lab.
[01:05:02.740 --> 01:05:10.340]   The arguments are almost disjoint from real human behavior because it's so much easier
[01:05:10.340 --> 01:05:12.380]   to study human behavior in the lab.
[01:05:12.380 --> 01:05:15.540]   You just kind of stay there and that's where the arguments are.
[01:05:15.540 --> 01:05:19.860]   Vision science is a good example, like studying eye movement and how we perceive the world
[01:05:19.860 --> 01:05:20.860]   and all that kind of stuff.
[01:05:20.860 --> 01:05:25.660]   It's so much easier to study in a lab that we don't consider, we say that's going to
[01:05:25.660 --> 01:05:27.900]   be what the science of vision is going to be like.
[01:05:27.900 --> 01:05:31.660]   And we don't consider the science of vision in the actual real world, the engineering
[01:05:31.660 --> 01:05:32.660]   of vision, I don't know.
[01:05:32.660 --> 01:05:39.820]   And so I think that's where exposing yourself to out of the box ideas, that's the most painful,
[01:05:39.820 --> 01:05:40.820]   that's the most important.
[01:05:40.820 --> 01:05:44.660]   - I mean, group think can be a terrible thing in philosophy as well, but because you're
[01:05:44.660 --> 01:05:51.020]   not to the same extent beholden to evidence and refutation from the evidence that you
[01:05:51.020 --> 01:05:57.380]   are in the sciences, it's a more subtle process of evaluation and so more susceptible, I think,
[01:05:57.380 --> 01:05:58.380]   to group think.
[01:05:58.380 --> 01:06:01.220]   Yeah, I agree, it's a danger.
[01:06:01.220 --> 01:06:07.420]   - We've talked about it a million times, but let's try to sort of do that old basic terminology
[01:06:07.420 --> 01:06:08.820]   definitions.
[01:06:08.820 --> 01:06:10.460]   What is panpsychism?
[01:06:10.460 --> 01:06:17.460]   Like what are the different ways you can try to think about, to define panpsychism maybe
[01:06:17.460 --> 01:06:26.060]   in contrast to naturalistic dualism and materialism, other kind of views of consciousness?
[01:06:26.060 --> 01:06:31.520]   - Yeah, so you've basically laid out the different options.
[01:06:31.520 --> 01:06:39.140]   So I guess probably still the dominant view is materialism, that roughly that we can explain
[01:06:39.140 --> 01:06:46.060]   consciousness in the terms of physical science, wholly explain it just in terms of the electrochemical
[01:06:46.060 --> 01:06:48.100]   signaling in the brain.
[01:06:48.100 --> 01:06:57.080]   Dualism, the polar opposite view, that consciousness is non-physical outside of the physical workings
[01:06:57.080 --> 01:07:01.660]   of the body and the brain, although closely connected.
[01:07:01.660 --> 01:07:05.540]   And when I studied philosophy, we were taught basically they were the two options you had
[01:07:05.540 --> 01:07:06.540]   to choose, right?
[01:07:06.540 --> 01:07:11.020]   Either you thought it were dualist and you thought it was separate from the physical,
[01:07:11.020 --> 01:07:14.220]   or you thought it was just electrochemical signaling.
[01:07:14.220 --> 01:07:18.220]   And yeah, I became very disillusioned because I think there are big problems with both of
[01:07:18.220 --> 01:07:19.220]   these options.
[01:07:19.220 --> 01:07:23.340]   So I think the attraction of panpsychism is it's kind of a middle way.
[01:07:23.340 --> 01:07:26.540]   It agrees with the materialist that there's just the physical world.
[01:07:26.540 --> 01:07:34.660]   Ultimately, there's just particles and fields, but the panpsychist thinks there's more to
[01:07:34.660 --> 01:07:40.940]   the physical than what physical science reveals, and that the ultimate nature of the physical
[01:07:40.940 --> 01:07:43.940]   world is constituted of consciousness.
[01:07:43.940 --> 01:07:51.740]   So consciousness is not outside of the physical as the dualist thinks, it's embedded in, underlies
[01:07:51.740 --> 01:07:55.820]   the kind of description of the world we get from physics.
[01:07:55.820 --> 01:08:01.140]   What to you are the problems of materialism and dualism?
[01:08:01.140 --> 01:08:09.140]   Starting with materialism, it's a huge debate, but I think that the core of it is that physical
[01:08:09.140 --> 01:08:16.540]   science works with a purely quantitative description of the physical world, whereas consciousness
[01:08:16.540 --> 01:08:18.700]   essentially involves qualities.
[01:08:18.700 --> 01:08:25.600]   If you think about the smell of coffee or the taste of mint or the deep red you experience
[01:08:25.600 --> 01:08:32.460]   as you watch a sunset, I think these qualities can't be captured in the purely quantitative
[01:08:32.460 --> 01:08:33.900]   language of physical science.
[01:08:33.900 --> 01:08:39.700]   So as long as your description of the brain is framed in the purely quantitative language
[01:08:39.700 --> 01:08:45.140]   of neuroscience, you'll just leave out these qualities and hence really leave out consciousness
[01:08:45.140 --> 01:08:46.140]   itself.
[01:08:46.140 --> 01:08:47.840]   And then dualism?
[01:08:47.840 --> 01:08:52.300]   So I've actually changed my mind a little bit on this since I wrote the book.
[01:08:52.300 --> 01:08:59.540]   So I argued in the book that we have pretty good experimental grounds for doubting dualism.
[01:08:59.540 --> 01:09:09.020]   And roughly the idea was if dualism were true, if there was say an immaterial mind impacting
[01:09:09.020 --> 01:09:13.780]   on the brain every second of waking life, that this would really show up in our neuroscience.
[01:09:13.780 --> 01:09:19.300]   There'd be all sorts of things happening in the brain that had no physical explanation.
[01:09:19.300 --> 01:09:24.260]   It would be like a poltergeist was playing with the brain.
[01:09:24.260 --> 01:09:30.760]   But actually, and so the fact that we don't find that is a strong and ever-growing inductive
[01:09:30.760 --> 01:09:32.860]   argument against dualism.
[01:09:32.860 --> 01:09:37.980]   But actually, the more I talk to neuroscientists and read neuroscience, and we have at Durham,
[01:09:37.980 --> 01:09:43.260]   my university, an interdisciplinary consciousness group, I don't think we know enough about
[01:09:43.260 --> 01:09:47.660]   the brain, about the workings of the brain to make that argument.
[01:09:47.660 --> 01:09:56.020]   I think we know a lot about the basic chemistry, how neurons fire, neurotransmitters, action
[01:09:56.020 --> 01:09:57.500]   potentials, things like that.
[01:09:57.500 --> 01:10:02.180]   We know a fair bit about large-scale functions of the brain, what different bits of the brain
[01:10:02.180 --> 01:10:03.180]   do.
[01:10:03.180 --> 01:10:10.460]   But what we're almost clueless on is how those large-scale functions are realized at the
[01:10:10.460 --> 01:10:14.420]   cellular level, how it works.
[01:10:14.420 --> 01:10:18.860]   People get quite excited about brain scans, but it's very low resolution.
[01:10:18.860 --> 01:10:24.100]   Every pixel on a brain scan corresponds to 5.5 million neurons.
[01:10:24.100 --> 01:10:32.260]   And we're only 70% of the way through constructing a connectome for the maggot brain, which has
[01:10:32.260 --> 01:10:37.380]   10,000 or 100,000 neurons, but the brain has 86 billion neurons.
[01:10:37.380 --> 01:10:43.780]   So I think we'd have to know a lot more about how the brain works, how these functions are
[01:10:43.780 --> 01:10:52.740]   realized before we could assess whether the dynamics of the brain can be completely explicated
[01:10:52.740 --> 01:10:55.940]   in terms of underlying chemistry or physics.
[01:10:55.940 --> 01:11:02.060]   So we'd have to do more engineering before we could figure that out.
[01:11:02.060 --> 01:11:04.900]   And there are people with other proposals.
[01:11:04.900 --> 01:11:10.660]   Someone I got to know, Martin Picard at Columbia University, who has the psychobiology mitochondrial
[01:11:10.660 --> 01:11:15.940]   lab there and is experimentally exploring the hypothesis that mitochondria in the brain
[01:11:15.940 --> 01:11:21.900]   should be understood as sort of social networks, perhaps as an alternative to reducing it to
[01:11:21.900 --> 01:11:24.700]   underlying chemistry and physics.
[01:11:24.700 --> 01:11:30.220]   So it is ultimately an empirical question whether dualism is true.
[01:11:30.220 --> 01:11:35.100]   I'm less convinced that we know the answer to that question at this stage.
[01:11:35.100 --> 01:11:40.260]   I think still as scientists and philosophers, we want to try and find the simplest, most
[01:11:40.260 --> 01:11:44.700]   parsimonious theory of reality.
[01:11:44.700 --> 01:11:49.820]   And dualism is still a pretty inelegant, unparsimonious theory.
[01:11:49.820 --> 01:11:55.860]   Reality is divided up into the purely physical properties and these consciousness properties,
[01:11:55.860 --> 01:11:58.140]   and they're radically different kinds of things.
[01:11:58.140 --> 01:12:01.980]   Whereas the panpsychist offers a much more simple, unified picture of reality.
[01:12:01.980 --> 01:12:06.060]   So I think it's still the view to be preferred, to put it very simply, why believe in two
[01:12:06.060 --> 01:12:08.820]   kinds of things when you can just get away with one?
[01:12:08.820 --> 01:12:15.140]   - And materialism is also very simple, but you're saying it doesn't explain something
[01:12:15.140 --> 01:12:16.580]   that seems pretty important.
[01:12:16.580 --> 01:12:22.020]   - Yeah, so I think materialism, science is about trying to find the simplest theory that
[01:12:22.020 --> 01:12:23.380]   accounts for the data.
[01:12:23.380 --> 01:12:26.380]   I don't think materialism can account for the data.
[01:12:26.380 --> 01:12:31.060]   Maybe dualism can account for the data, but panpsychism is simpler.
[01:12:31.060 --> 01:12:33.820]   It can account for the data and it's simpler.
[01:12:33.820 --> 01:12:37.340]   - What is panpsychism?
[01:12:37.340 --> 01:12:43.300]   - So in its broadest definition, it's the view that consciousness is a fundamental and
[01:12:43.300 --> 01:12:47.380]   ubiquitous feature of the physical world.
[01:12:47.380 --> 01:12:50.340]   - Like a law of physics, what should we be imagining?
[01:12:50.340 --> 01:12:54.540]   What do you think the different flavors of how that actually takes shape in the context
[01:12:54.540 --> 01:12:57.540]   of what we know about physics and science and the universe?
[01:12:57.540 --> 01:13:02.020]   - So in the simplest form of it, the fundamental building blocks of reality, perhaps electrons
[01:13:02.020 --> 01:13:08.220]   and quarks, have incredibly simple forms of experience and the very complex experience
[01:13:08.220 --> 01:13:14.940]   of the human or animal brain is somehow rooted in or derived from these very simple forms
[01:13:14.940 --> 01:13:17.700]   of experience at the level of basic physics.
[01:13:17.700 --> 01:13:24.100]   But I mean, maybe the crucial bit about the kind of panpsychism I defend, what it does
[01:13:24.100 --> 01:13:31.100]   is it takes the standard approach to the problem of consciousness and turns it on its head,
[01:13:31.100 --> 01:13:32.100]   right?
[01:13:32.100 --> 01:13:38.780]   So the standard approach is to think we start with matter and we think, "How do we get consciousness
[01:13:38.780 --> 01:13:39.780]   out of matter?"
[01:13:39.780 --> 01:13:43.660]   So I don't think that problem can be solved for reasons I've kind of hinted at.
[01:13:43.660 --> 01:13:45.700]   We could maybe go into more detail.
[01:13:45.700 --> 01:13:48.660]   But the panpsychist does it the other way around.
[01:13:48.660 --> 01:13:53.380]   They start with consciousness and try to get matter out of consciousness.
[01:13:53.380 --> 01:14:01.180]   So the idea is basically at the fundamental level of reality, there are just networks
[01:14:01.180 --> 01:14:05.060]   of very simple conscious entities.
[01:14:05.060 --> 01:14:09.420]   But these conscious entities, because they have very simple kinds of experience, they
[01:14:09.420 --> 01:14:11.660]   behave in predictable ways.
[01:14:11.660 --> 01:14:15.420]   Through their interactions, they realize certain mathematical structures.
[01:14:15.420 --> 01:14:22.040]   And then the idea is those mathematical structures just are the structures identified by physics.
[01:14:22.040 --> 01:14:27.860]   So when we think about these simple conscious entities in terms of the mathematical structures
[01:14:27.860 --> 01:14:34.020]   they realize, we call them particles, we call them fields, we call their properties mass,
[01:14:34.020 --> 01:14:35.500]   spin and charge.
[01:14:35.500 --> 01:14:40.980]   But really there's just these very simple conscious entities and their experiences.
[01:14:40.980 --> 01:14:45.620]   So in this way, we get physics out of consciousness.
[01:14:45.620 --> 01:14:48.300]   I don't think you can get consciousness out of physics, but I think it's pretty easy to
[01:14:48.300 --> 01:14:50.300]   get physics out of consciousness.
[01:14:50.300 --> 01:14:57.580]   - Well, I'm a little confused by why you need to get physics out of consciousness.
[01:14:57.580 --> 01:15:03.780]   I mean, to me, it sounds like panpsychism unites consciousness and physics.
[01:15:03.780 --> 01:15:11.300]   I mean, physics is the mathematical science of describing everything.
[01:15:11.300 --> 01:15:15.300]   So physics should be able to describe consciousness.
[01:15:15.300 --> 01:15:22.460]   And my understanding proposes is that physics doesn't currently do so, but can in the future.
[01:15:22.460 --> 01:15:27.780]   It seems like consciousness, you have like Stephen Wolfram, all these people who are
[01:15:27.780 --> 01:15:36.620]   trying to develop theories of everything, mathematical frameworks within which to describe
[01:15:36.620 --> 01:15:40.140]   how we get all the reality that we perceive around us.
[01:15:40.140 --> 01:15:47.180]   To me, there's no reason why that kind of framework cannot also include some accurate,
[01:15:47.180 --> 01:15:55.540]   precise description of whatever simple consciousness characteristics are present there at the lowest
[01:15:55.540 --> 01:16:00.380]   level if panpsychist theories have truth to them.
[01:16:00.380 --> 01:16:02.020]   So to me, it is physics.
[01:16:02.020 --> 01:16:06.360]   You said kind of physics emerges, by which you mean like the basic four laws of physics
[01:16:06.360 --> 01:16:11.500]   that as we currently know them, the standard model, quantum mechanics, general relativity,
[01:16:11.500 --> 01:16:15.100]   that emerges from the base consciousness layer.
[01:16:15.100 --> 01:16:16.100]   That's what you mean.
[01:16:16.100 --> 01:16:17.100]   - Yeah.
[01:16:17.100 --> 01:16:20.300]   So maybe the way I phrased it made it sound like these things are more separate than they
[01:16:20.300 --> 01:16:21.300]   are.
[01:16:21.300 --> 01:16:28.340]   What I was trying to address was a common misunderstanding of panpsychism that it's a
[01:16:28.340 --> 01:16:32.740]   sort of dualistic theory.
[01:16:32.740 --> 01:16:38.260]   The idea is that particles have their physical properties like mass, spin and charge, and
[01:16:38.260 --> 01:16:40.260]   these other funny consciousness properties.
[01:16:40.260 --> 01:16:45.380]   So the physicist Sabine Hossenfelder had a blog post critiquing panpsychism maybe a couple
[01:16:45.380 --> 01:16:48.260]   of years ago now that got a fair bit of traction.
[01:16:48.260 --> 01:16:52.140]   And she was interpreting panpsychism in this way.
[01:16:52.140 --> 01:16:56.780]   And then her thought was, "Well, look, if particles had these funny consciousness properties,
[01:16:56.780 --> 01:17:00.700]   then it would show up in our physics, like the standard model of particle physics would
[01:17:00.700 --> 01:17:05.400]   make false predictions because its predictions are based wholly on the physical properties.
[01:17:05.400 --> 01:17:09.780]   If there were also these consciousness properties, we'd get different predictions."
[01:17:09.780 --> 01:17:11.020]   But that's a misunderstanding of the view.
[01:17:11.020 --> 01:17:17.860]   The view is, it's not that there are two kinds of property, that mass, spin and charge are
[01:17:17.860 --> 01:17:19.620]   forms of consciousness.
[01:17:19.620 --> 01:17:20.860]   How do we make sense of that?
[01:17:20.860 --> 01:17:26.940]   Because actually, when you look at what physics tells us, it's really just telling us about
[01:17:26.940 --> 01:17:29.340]   behavior, about what stuff does.
[01:17:29.340 --> 01:17:33.340]   I sometimes put it by saying, "Doing physics is like playing chess when you don't care
[01:17:33.340 --> 01:17:34.340]   what the pieces are made of.
[01:17:34.340 --> 01:17:36.580]   You're just interested in what moves you can make."
[01:17:36.580 --> 01:17:45.020]   So physics tells us what mass, spin and charge do, but it doesn't tell us what they are.
[01:17:45.020 --> 01:17:46.260]   So the idea-
[01:17:46.260 --> 01:17:48.220]   The experience of mass.
[01:17:48.220 --> 01:17:52.340]   So the idea is, yeah, mass in its nature is a very simple form of consciousness.
[01:17:52.340 --> 01:17:57.260]   So yeah, physics in a sense is complete, I think, because it tells us what everything
[01:17:57.260 --> 01:18:02.180]   at the fundamental level does, it describes its causal capacities.
[01:18:02.180 --> 01:18:08.180]   But for the panpsychist at least, physics doesn't tell us what matter is, it tells us
[01:18:08.180 --> 01:18:12.460]   what it does, but not what it is.
[01:18:12.460 --> 01:18:17.100]   To push back on the thing I think she's criticizing, is it also possible- so I understand what
[01:18:17.100 --> 01:18:22.500]   you're saying- but is it also possible that particles have another property like consciousness?
[01:18:22.500 --> 01:18:27.260]   I don't understand the criticism we would be able to detect it in our experiments.
[01:18:27.260 --> 01:18:31.260]   Well, no, if you're not looking for it.
[01:18:31.260 --> 01:18:35.460]   There's a lot of stuff that are orthogonal.
[01:18:35.460 --> 01:18:39.980]   If you're not looking for the stuff, you're not going to detect it, because all of our
[01:18:39.980 --> 01:18:45.180]   basic empirical science through its recent history, and yes, the history of science is
[01:18:45.180 --> 01:18:54.400]   quite recent, has been very focused on billiard balls colliding, and from that understanding
[01:18:54.400 --> 01:18:56.620]   how gravity works.
[01:18:56.620 --> 01:19:00.460]   We just haven't integrated other possibilities into this.
[01:19:00.460 --> 01:19:04.820]   I don't think there will be conflicting, whether you are observing consciousness or not, or
[01:19:04.820 --> 01:19:10.620]   exploring some of these ideas, I don't think that affects the rest of the physics.
[01:19:10.620 --> 01:19:17.340]   The mass, the energy, all the different kind of hierarchy of different particles and so
[01:19:17.340 --> 01:19:21.540]   on, how they interact.
[01:19:21.540 --> 01:19:27.020]   It feels like consciousness is something orthogonal, very much distinct.
[01:19:27.020 --> 01:19:32.860]   The quantitative versus the qualitative, there's something quite distinct, almost like another
[01:19:32.860 --> 01:19:35.340]   dimension that we're just completely ignoring.
[01:19:35.340 --> 01:19:40.740]   There might be a way of responding to Sabina to say, well, there could be properties of
[01:19:40.740 --> 01:19:46.500]   particles that don't show up in the specific circumstances in which physicists investigate
[01:19:46.500 --> 01:19:47.500]   particles.
[01:19:47.500 --> 01:19:50.820]   My colleague, the philosopher of science, Nancy Cartwright, has got this book, How the
[01:19:50.820 --> 01:19:58.540]   Laws of Physics Lie, where she says, physicists explore things in very specific circumstances
[01:19:58.540 --> 01:20:01.660]   and then in an unwarranted way, generalize that.
[01:20:01.660 --> 01:20:06.300]   But I mean, I guess I was thinking Sabina's criticism actually just misses the mark in
[01:20:06.300 --> 01:20:07.620]   a more basic way.
[01:20:07.620 --> 01:20:11.860]   Her point is, we shouldn't think there are any more properties to particles other than
[01:20:11.860 --> 01:20:14.020]   those the standard model attributes to them.
[01:20:14.020 --> 01:20:16.860]   Panpsychics would say, yeah, sure, there aren't.
[01:20:16.860 --> 01:20:21.380]   There are just the properties, the physical properties like mass, spin, and charge that
[01:20:21.380 --> 01:20:22.620]   the standard model attributes to them.
[01:20:22.620 --> 01:20:28.140]   It's just that we have a different philosophical view as to the nature of those properties.
[01:20:28.140 --> 01:20:31.940]   - So those properties are turtles that are sitting on top of another turtle and that
[01:20:31.940 --> 01:20:33.820]   big turtle is consciousness.
[01:20:33.820 --> 01:20:35.060]   That's what you're saying.
[01:20:35.060 --> 01:20:39.300]   But I'm just saying, it's possible that's true.
[01:20:39.300 --> 01:20:44.420]   It's possible also that consciousness is just another turtle playing with the others.
[01:20:44.420 --> 01:20:47.500]   It's just not interacting in the ways that we've been observing.
[01:20:47.500 --> 01:20:51.860]   In fact, to me, that's more compelling because then that's going to be...
[01:20:51.860 --> 01:20:58.260]   - Well, no, I think both are very compelling, but it feels like it's more within the reach
[01:20:58.260 --> 01:21:03.980]   of empirical validation if it's yet another property of particles that we're just not
[01:21:03.980 --> 01:21:04.980]   observing.
[01:21:04.980 --> 01:21:16.980]   If it's like the thing from which matter and energy and physics emerges, it makes it that
[01:21:16.980 --> 01:21:23.780]   much more difficult to investigate how you get from that base layer of consciousness
[01:21:23.780 --> 01:21:32.700]   to the wonderful little spark of consciousness, complexity, and beauty that is the human being.
[01:21:32.700 --> 01:21:37.860]   I don't know if you're necessarily trying to get there, but one of the beautiful things
[01:21:37.860 --> 01:21:44.860]   to get at with panpsychism or with a solid theory of consciousness is to answer the question,
[01:21:44.860 --> 01:21:47.780]   how do you engineer the thing?
[01:21:47.780 --> 01:21:55.780]   How do you get from nothing, vacuum in the lab, if there is that consciousness base layer,
[01:21:55.780 --> 01:22:00.580]   how do you start engineering organisms that have consciousness in them?
[01:22:00.580 --> 01:22:07.140]   Or the reverse of that, describing how does consciousness emerge in the human being from
[01:22:07.140 --> 01:22:13.420]   conception, from a stem cell to the whole full neurobiology that builds from that, how
[01:22:13.420 --> 01:22:19.420]   do you get this full, rich experience of consciousness that humans have?
[01:22:19.420 --> 01:22:26.820]   It feels like that's the dream, and if consciousness is just another player in the game of physics,
[01:22:26.820 --> 01:22:30.900]   it feels more amenable to our scientific understanding of it.
[01:22:30.900 --> 01:22:31.900]   That's interesting.
[01:22:31.900 --> 01:22:36.500]   I mean, I guess it's supposed to be a kind of identity claim here that physics tells
[01:22:36.500 --> 01:22:43.220]   us what matter does, consciousness is what matter is.
[01:22:43.220 --> 01:22:46.580]   So matter is sort of what consciousness does.
[01:22:46.580 --> 01:22:51.700]   So at the bottom level, there is just consciousness and conscious things.
[01:22:51.700 --> 01:22:56.820]   There are just these simple things with their experiences, and that is their total nature.
[01:22:56.820 --> 01:23:02.500]   So in that sense, it's not another player, it's just all there is really.
[01:23:02.500 --> 01:23:09.060]   And then in physics, we describe that at a certain level of abstraction.
[01:23:09.060 --> 01:23:13.900]   We capture what Bertrand Russell, who was the inspiration for a lot of this, calls the
[01:23:13.900 --> 01:23:16.300]   causal skeleton of the world.
[01:23:16.300 --> 01:23:19.420]   So physics is just interested in the causal skeleton of the world, it's not interested
[01:23:19.420 --> 01:23:25.620]   in the flesh and blood, although that's maybe suggesting separation again too much, all
[01:23:25.620 --> 01:23:27.660]   metaphors fail in the end.
[01:23:27.660 --> 01:23:32.260]   But yeah, so you're totally right.
[01:23:32.260 --> 01:23:37.580]   Ultimately, what we want to explain is how our consciousness and the consciousness of
[01:23:37.580 --> 01:23:39.300]   other animals comes out of this.
[01:23:39.300 --> 01:23:42.060]   If we can't do that, then it's game over.
[01:23:42.060 --> 01:23:49.580]   But I think it maybe makes more sense on the identity claim that if matter at the fundamental
[01:23:49.580 --> 01:23:54.860]   level just is forms of consciousness, then we can perhaps make sense of how those simple
[01:23:54.860 --> 01:23:59.660]   forms of consciousness in some way combine in some way to make the consciousness we know
[01:23:59.660 --> 01:24:01.060]   and love, that's the dream.
[01:24:01.060 --> 01:24:09.420]   - Yeah, so I guess the question is, so the reason you can describe, the reason you have
[01:24:09.420 --> 01:24:18.220]   material engineering, material science, is because you have from physics to chemistry,
[01:24:18.220 --> 01:24:26.900]   you keep going up and up in levels of complexity in order to describe objects that we have
[01:24:26.900 --> 01:24:29.940]   in our human world.
[01:24:29.940 --> 01:24:33.700]   And it would be nice to do the same thing for consciousness, to come up with the chemistry
[01:24:33.700 --> 01:24:35.660]   of consciousness, right?
[01:24:35.660 --> 01:24:42.820]   Like how do the different particles interact to create greater complexity?
[01:24:42.820 --> 01:24:46.460]   So you can do this kind of thing for life, like what is life?
[01:24:46.460 --> 01:24:53.500]   Like living organisms, at which point do living organisms become living?
[01:24:53.500 --> 01:24:59.100]   How do you know if I give you a thing, that that thing is living?
[01:24:59.100 --> 01:25:03.420]   There's a lot of people who work on this kind of idea, and some of that has to do with the
[01:25:03.420 --> 01:25:05.580]   levels of complexity and so on.
[01:25:05.580 --> 01:25:11.660]   It'd be nice to know like measuring different degrees of consciousness as you get into bigger
[01:25:11.660 --> 01:25:14.500]   and more and more complex objects.
[01:25:14.500 --> 01:25:19.540]   And that's what chemistry, like bigger and bigger conscious molecules, and to see how
[01:25:19.540 --> 01:25:21.780]   that leads to organisms.
[01:25:21.780 --> 01:25:26.660]   And then organisms start to collaborate together like they do inside our human body to create
[01:25:26.660 --> 01:25:31.660]   the full human body, to do those kinds of experiments would be, it seems like that would
[01:25:31.660 --> 01:25:33.700]   be kind of a goal.
[01:25:33.700 --> 01:25:38.140]   That's what I mean by player in a game of physics, as opposed to like the base layer.
[01:25:38.140 --> 01:25:44.140]   If it's just the base layer, it becomes harder to track it as you get from physics to chemistry
[01:25:44.140 --> 01:25:47.260]   to biology to psychology.
[01:25:47.260 --> 01:25:56.140]   - Yeah, in every case apart from consciousness, I would say what we're interested in is behavior.
[01:25:56.140 --> 01:25:58.940]   We're interested in explaining behavioral functions.
[01:25:58.940 --> 01:26:02.660]   So the level of fundamental physics, we're interested in capturing the equations that
[01:26:02.660 --> 01:26:04.300]   describe the behavior there.
[01:26:04.300 --> 01:26:10.500]   And when we get to higher levels, we're interested in explicating the behavior, perhaps in terms
[01:26:10.500 --> 01:26:14.140]   of behavior at simpler levels.
[01:26:14.140 --> 01:26:20.140]   And with life as well, that's what we're interested in, the various observable functions of life,
[01:26:20.140 --> 01:26:23.780]   explaining them in terms of more simple mechanisms.
[01:26:23.780 --> 01:26:28.420]   But in the case of consciousness, I don't think that's what we're doing, or at least
[01:26:28.420 --> 01:26:31.780]   not all that we're doing.
[01:26:31.780 --> 01:26:37.620]   In the case of consciousness, there are these subjective qualities that we're immediately
[01:26:37.620 --> 01:26:43.900]   aware of, the redness of a red experience, the itchiness of an itch, and we're trying
[01:26:43.900 --> 01:26:45.060]   to account for them.
[01:26:45.060 --> 01:26:48.300]   We're trying to bring them into our theory of reality.
[01:26:48.300 --> 01:26:52.260]   And postulating some mechanism does not deal with that.
[01:26:52.260 --> 01:26:56.300]   I think we've got to realize dealing with consciousness is a radically different explanatory
[01:26:56.300 --> 01:26:58.740]   task from other tasks of science.
[01:26:58.740 --> 01:27:03.540]   Other tasks of science, we're trying to explain behavior in terms of simpler forms of behavior.
[01:27:03.540 --> 01:27:09.100]   In the case of consciousness, we're trying to explain these invisible subjective qualities
[01:27:09.100 --> 01:27:13.480]   that you can't see from the outside, but that you're immediately aware of.
[01:27:13.480 --> 01:27:18.080]   The reason materialism perhaps continues to dominate is people think, "Look at the success
[01:27:18.080 --> 01:27:19.080]   of science.
[01:27:19.080 --> 01:27:20.080]   It's incredible.
[01:27:20.080 --> 01:27:22.520]   It's explained all this.
[01:27:22.520 --> 01:27:23.760]   Surely it's going to explain consciousness."
[01:27:23.760 --> 01:27:31.880]   But I think we have to appreciate there's a radically different explanatory task here.
[01:27:31.880 --> 01:27:36.920]   The neuroscientist Anil Seth, who I've had lots of intense but friendly discussions with,
[01:27:36.920 --> 01:27:40.400]   wants to compare consciousness to life.
[01:27:40.400 --> 01:27:45.200]   But I think there's this radical difference that in the case of life, again, we come back
[01:27:45.200 --> 01:27:52.040]   to public observation, all of the data, publicly observable data, we're basically trying to
[01:27:52.040 --> 01:27:53.960]   explain complex behavior.
[01:27:53.960 --> 01:28:00.240]   The way you do that is identify mechanisms, simpler mechanisms that explicate that behavior.
[01:28:00.240 --> 01:28:05.920]   That's the task in physics, chemistry, neurobiology.
[01:28:05.920 --> 01:28:08.000]   But in the case of consciousness, that's not what we're trying to do.
[01:28:08.000 --> 01:28:14.560]   We're trying to account for these subjective qualities and you postulate a mechanism that
[01:28:14.560 --> 01:28:21.560]   might explain behavior, but it doesn't explain the redness of a red experience.
[01:28:21.560 --> 01:28:26.760]   But still, ultimately, the hope is that we will have some kind of hierarchical story.
[01:28:26.760 --> 01:28:32.320]   So we take the causal dynamics of physics, we hypothesize that that's filled out with
[01:28:32.320 --> 01:28:36.480]   certain forms of consciousness.
[01:28:36.480 --> 01:28:43.160]   And then at higher levels, we get more complex causal dynamics filled out by more complex
[01:28:43.160 --> 01:28:44.520]   forms of consciousness.
[01:28:44.520 --> 01:28:48.920]   And ultimately we get to us, hopefully.
[01:28:48.920 --> 01:28:52.360]   So yeah, so there's still a sort of hierarchical explanatory framework there.
[01:28:52.360 --> 01:28:57.160]   - So you kind of mentioned the hierarchy of consciousness.
[01:28:57.160 --> 01:29:06.000]   Do you think it's possible to, within the Pansychism framework, to measure consciousness?
[01:29:06.000 --> 01:29:15.840]   Or put another way, are some things more conscious than others in the Pansychist view?
[01:29:15.840 --> 01:29:16.840]   - It's a difficult question.
[01:29:16.840 --> 01:29:25.500]   I mean, I do see consciousness as a dealing with consciousness and interdisciplinary task
[01:29:25.500 --> 01:29:31.360]   between something more experimental, which has to do with the ongoing project of trying
[01:29:31.360 --> 01:29:37.740]   to work out what people call the neural correlates of consciousness, what kinds of physical brain
[01:29:37.740 --> 01:29:41.880]   activity correspond to conscious experience.
[01:29:41.880 --> 01:29:48.400]   That's one part of it, but I think essentially there's also a theoretical question of more
[01:29:48.400 --> 01:29:50.040]   the why question.
[01:29:50.040 --> 01:29:56.960]   Why do those kinds of brain activity go along with certain kinds of conscious experience?
[01:29:56.960 --> 01:29:59.020]   I don't think you can answer that.
[01:29:59.020 --> 01:30:04.140]   Because consciousness is not publicly observable, I don't think you can answer that why question
[01:30:04.140 --> 01:30:06.680]   with an experiment.
[01:30:06.680 --> 01:30:08.480]   But they have to go hand in hand.
[01:30:08.480 --> 01:30:14.880]   And I mean, one of the theories I'm attracted to is the integrated information theory, according
[01:30:14.880 --> 01:30:21.180]   to which we find consciousness at the level at which there is most integrated information.
[01:30:21.180 --> 01:30:25.040]   And they try to give a mathematically precise definition of that.
[01:30:25.040 --> 01:30:31.420]   So on that view, probably this cup of tea isn't conscious because there's probably more
[01:30:31.420 --> 01:30:36.440]   integrated information in the molecules making up the tea than there is in the liquid as
[01:30:36.440 --> 01:30:37.520]   a whole.
[01:30:37.520 --> 01:30:42.840]   But in the brain, what is distinctive about the brain is that there's a huge amount of
[01:30:42.840 --> 01:30:47.500]   integrated, there's more integrated information in the system than there is in individual
[01:30:47.500 --> 01:30:48.500]   neurons.
[01:30:48.500 --> 01:30:54.960]   So that's why they claim that that's the basis of consciousness at the macro level.
[01:30:54.960 --> 01:31:00.520]   Now they, so I don't, I mean, I like some features of this theory, but they do talk
[01:31:00.520 --> 01:31:03.000]   about degrees of consciousness.
[01:31:03.000 --> 01:31:06.440]   They do want to say there is gradations.
[01:31:06.440 --> 01:31:10.720]   I'm not sure conceptually I can kind of make sense of that.
[01:31:10.720 --> 01:31:20.640]   I mean, there are things to do with consciousness that are graded like complexity or levels
[01:31:20.640 --> 01:31:22.500]   of information.
[01:31:22.500 --> 01:31:26.600]   But I'm not sure whether experience itself admits a degree.
[01:31:26.600 --> 01:31:31.160]   I sort of think something either has experience or it doesn't.
[01:31:31.160 --> 01:31:37.520]   It might have very simple experience, it might have very complex experience, but experience
[01:31:37.520 --> 01:31:40.840]   itself I don't think it admits a degree in that sense.
[01:31:40.840 --> 01:31:44.640]   It's not more experience, less experience.
[01:31:44.640 --> 01:31:50.040]   I sort of find that conceptually hard to make sense of, but I'm kind of open-minded on it.
[01:31:50.040 --> 01:31:59.440]   - So when we have a lot higher resolution of sensory information, don't you think that's
[01:31:59.440 --> 01:32:04.980]   correlated to the richness of the experience?
[01:32:04.980 --> 01:32:09.160]   So doesn't more information provide a richer experience?
[01:32:09.160 --> 01:32:14.340]   Or is that, again, thinking quantitatively and not thinking about the subjective experience?
[01:32:14.340 --> 01:32:21.060]   Like you can experience a lot with very little sensory information perhaps.
[01:32:21.060 --> 01:32:22.660]   Do you think those are connected?
[01:32:22.660 --> 01:32:23.740]   - Yeah, yeah.
[01:32:23.740 --> 01:32:34.220]   So there are features, characteristics here we can grade, the complexity of the experience.
[01:32:34.220 --> 01:32:42.780]   And on the integrated information theory, they correlate that in terms of mathematically
[01:32:42.780 --> 01:32:45.980]   identifiable structure with integrated information.
[01:32:45.980 --> 01:32:48.820]   So roughly, it's a quite unusual notion of information.
[01:32:48.820 --> 01:32:53.140]   It's perhaps not the standard way one thinks about information.
[01:32:53.140 --> 01:32:59.340]   It's to do with constraining past and future possibilities of the system.
[01:32:59.340 --> 01:33:06.300]   So the idea is in the retina of the eye, there's a huge amount of possible states the retina
[01:33:06.300 --> 01:33:11.620]   of my eye could be in at the next moment, depending on what light goes into it.
[01:33:11.620 --> 01:33:15.020]   Whereas the possible next states of the brain are much more constrained.
[01:33:15.020 --> 01:33:22.780]   Obviously, it responds to the environment, but it heavily constrains its past and future
[01:33:22.780 --> 01:33:23.980]   states.
[01:33:23.980 --> 01:33:26.860]   And so that's the idea of information they have.
[01:33:26.860 --> 01:33:34.760]   And then the second idea is how much that information is dependent on integration.
[01:33:34.760 --> 01:33:40.860]   So in a computer where you have transistors, you take out a few transistors, you might
[01:33:40.860 --> 01:33:42.500]   not lose that much information.
[01:33:42.500 --> 01:33:46.700]   It's not dependent on interconnections, whereas you take a tiny bit of the brain out, you
[01:33:46.700 --> 01:33:52.300]   lose a lot of information because the way it stores information is dependent on the
[01:33:52.300 --> 01:33:54.540]   interconnections of the system.
[01:33:54.540 --> 01:34:02.700]   So yeah, so that's one proposal for how to measure one gradable characteristic, which
[01:34:02.700 --> 01:34:08.780]   might correspond to some gradable characteristic in qualitative consciousness.
[01:34:08.780 --> 01:34:12.580]   Maybe I'm being very pedantic, which is, you know, philosophers professional pedant.
[01:34:12.580 --> 01:34:18.620]   I just sort of don't think that is a quantity of experience.
[01:34:18.620 --> 01:34:25.180]   It's a quantity of the structure of experience maybe, but I just find it hard to make sense
[01:34:25.180 --> 01:34:27.420]   of the idea of how much experience do you have?
[01:34:27.420 --> 01:34:31.300]   I've got, you know, five units of experience.
[01:34:31.300 --> 01:34:32.420]   I've got one unit of experience.
[01:34:32.420 --> 01:34:33.420]   I don't know.
[01:34:33.420 --> 01:34:37.340]   I find that a bit hard to make sense of.
[01:34:37.340 --> 01:34:38.980]   But maybe I'm being just pedantic.
[01:34:38.980 --> 01:34:45.900]   I think just saying the word experience is difficult to think about.
[01:34:45.900 --> 01:34:47.700]   Let's talk about suffering.
[01:34:47.700 --> 01:34:50.140]   Let's talk about a particular experience.
[01:34:50.140 --> 01:34:54.460]   So let's talk about me and a hamster.
[01:34:54.460 --> 01:34:58.940]   I just think that, no offense to the hamster.
[01:34:58.940 --> 01:35:01.300]   Probably no hamsters are listening.
[01:35:01.300 --> 01:35:03.160]   So now you're offending hamsters too.
[01:35:03.160 --> 01:35:05.740]   Maybe there's a hamster that's just pissed off.
[01:35:05.740 --> 01:35:12.940]   There's probably somebody on a speaker right now, like listening to this podcast and they
[01:35:12.940 --> 01:35:17.780]   probably have a hamster or a guinea pig and that hamster is listening.
[01:35:17.780 --> 01:35:23.300]   It just doesn't know the English language or any kind of human interpretable linguistic
[01:35:23.300 --> 01:35:27.260]   capabilities to tell you to fuck off.
[01:35:27.260 --> 01:35:33.900]   It understands exactly what's being talked about and can see through us.
[01:35:33.900 --> 01:35:42.180]   Anyway, it just feels like a hamster has less capacity to suffer than me.
[01:35:42.180 --> 01:35:51.820]   And maybe a cockroach or an insect or maybe a bacteria has less capacity to suffer than
[01:35:51.820 --> 01:35:53.820]   me.
[01:35:53.820 --> 01:36:01.900]   But maybe that's me deluding myself as to the complexity of my conscious experience.
[01:36:01.900 --> 01:36:12.380]   Maybe there is some sense in which I can suffer more, but to reduce it to something quantifiable
[01:36:12.380 --> 01:36:13.380]   is impossible.
[01:36:13.380 --> 01:36:22.140]   Yeah, I guess I definitely think there's kinds of suffering that you have the joy of being
[01:36:22.140 --> 01:36:26.100]   possible for you that aren't available to a hamster.
[01:36:26.100 --> 01:36:31.860]   I don't think... well, can a hamster suffer heartbreak?
[01:36:31.860 --> 01:36:33.220]   I don't know.
[01:36:33.220 --> 01:36:34.740]   Can a cockroach suffer heartbreak?
[01:36:34.740 --> 01:36:42.140]   But certainly there's kinds of fear of your own death, concern about whether there's a
[01:36:42.140 --> 01:36:44.400]   purpose to existence.
[01:36:44.400 --> 01:36:52.060]   These are forms of suffering that aren't available to most non-human animals.
[01:36:52.060 --> 01:36:57.620]   Whatever there's an overall scale that we could put physical and emotional suffering
[01:36:57.620 --> 01:37:05.220]   on and identify where you are on that scale, I'm not so sure.
[01:37:05.220 --> 01:37:13.260]   So it's like humans have a much bigger menu of experiences, much bigger selection in the...
[01:37:13.260 --> 01:37:15.340]   In one sense, at least.
[01:37:15.340 --> 01:37:17.140]   There's like a page that's suffering.
[01:37:17.140 --> 01:37:21.940]   So this menu of experiences, you know, like you have the omelets and the breakfast and
[01:37:21.940 --> 01:37:24.300]   so on, and one of the pages is suffering.
[01:37:24.300 --> 01:37:29.580]   It's just we have a lot compared to a hamster, a lot more.
[01:37:29.580 --> 01:37:36.460]   But in one individual thing that we share with a hamster, that experience... it's difficult
[01:37:36.460 --> 01:37:41.420]   to argue that we experience it deeper than others, like hunger or something like that.
[01:37:41.420 --> 01:37:45.060]   Yeah, physical pain, I'm not sure.
[01:37:45.060 --> 01:37:48.020]   I mean, there are kinds of experiences animals have that we don't.
[01:37:48.020 --> 01:37:52.540]   Bats echolocate around the world.
[01:37:52.540 --> 01:37:57.300]   The philosopher Thomas Nagel famously pointed out that no matter how much you understand
[01:37:57.300 --> 01:38:04.260]   of the neurophysiology of bats, you'll still not know what it's like to squeal and find
[01:38:04.260 --> 01:38:08.300]   your way around by listening to the echoes bounce off.
[01:38:08.300 --> 01:38:16.780]   So yeah, I mean, I guess I feel the intuition that there's emotional suffering is, I want
[01:38:16.780 --> 01:38:19.980]   to say, deeper than physical suffering.
[01:38:19.980 --> 01:38:23.100]   I don't know how to make that statement precise, though.
[01:38:23.100 --> 01:38:28.300]   So one of the ways I think about, I think people think about consciousness is in connection
[01:38:28.300 --> 01:38:29.300]   to suffering.
[01:38:29.300 --> 01:38:35.460]   So let me just ask about suffering, because that's how people think about animals.
[01:38:35.460 --> 01:38:38.780]   Cruelty to animals or cruelty to living things.
[01:38:38.780 --> 01:38:42.940]   They connect that to suffering and to consciousness.
[01:38:42.940 --> 01:38:50.260]   I think there's a sense in which those two are deeply connected when people are thinking
[01:38:50.260 --> 01:38:59.980]   about just public policy, they're thinking about philosophy, engineering, psychology,
[01:38:59.980 --> 01:39:02.660]   sociology, political science.
[01:39:02.660 --> 01:39:07.860]   All of those things have to do with human suffering and animal suffering, life suffering.
[01:39:07.860 --> 01:39:11.340]   And that's connected to consciousness in a lot of people's minds.
[01:39:11.340 --> 01:39:13.340]   Is it connected like that for you?
[01:39:13.340 --> 01:39:23.660]   So the capacity to suffer, is it also somehow strongly correlated with the capacity to experience
[01:39:23.660 --> 01:39:24.660]   consciously?
[01:39:24.660 --> 01:39:29.700]   Yeah, I would say suffering is a kind of experience.
[01:39:29.700 --> 01:39:33.780]   And so you have to be conscious to suffer.
[01:39:33.780 --> 01:39:42.580]   Actually, there's people taking more unusual views of consciousness seriously now.
[01:39:42.580 --> 01:39:46.580]   Panpsychism is one radical approach.
[01:39:46.580 --> 01:39:52.420]   Another one is what's become known as illusionism, the view that consciousness, at least in the
[01:39:52.420 --> 01:39:56.260]   sense that philosophers think about it, doesn't really exist at all.
[01:39:56.260 --> 01:40:03.280]   So yeah, my podcast Mind Chat, I host with a committed illusionist.
[01:40:03.280 --> 01:40:08.940]   So the gimmick is I think consciousness is everywhere, he thinks it's nowhere.
[01:40:08.940 --> 01:40:14.180]   So that's one very simple way of avoiding all these problems, right?
[01:40:14.180 --> 01:40:18.120]   If consciousness doesn't exist, we don't need to explain it, job done.
[01:40:18.120 --> 01:40:22.660]   Although we might still have to explain why we seem to be conscious, why it's so hard
[01:40:22.660 --> 01:40:24.540]   to get out of the idea that we're conscious.
[01:40:24.540 --> 01:40:31.380]   But the reason I connect this to what you're saying is actually my co-host, Keith Frankish,
[01:40:31.380 --> 01:40:32.980]   is a little bit ambivalent on the word pain.
[01:40:32.980 --> 01:40:37.460]   He says, "Oh, in some sense, I believe in pain and in some sense, I don't."
[01:40:37.460 --> 01:40:44.540]   But another illusionist, Francois Camara, has a paper discussing how we think about
[01:40:44.540 --> 01:40:48.900]   morality given his view that pain, in the way we normally think about it, just does
[01:40:48.900 --> 01:40:50.100]   not exist.
[01:40:50.100 --> 01:40:51.100]   He thinks it's an illusion.
[01:40:51.100 --> 01:40:55.100]   The brain tricks us into thinking we feel pain, but we don't.
[01:40:55.100 --> 01:41:01.380]   And how we should think about morality in the light of that, it's become a big topic
[01:41:01.380 --> 01:41:05.020]   actually thinking about the connection between consciousness and morality.
[01:41:05.020 --> 01:41:12.020]   David Chalmers, the philosopher, is most associated with this concept of a philosophical zombie.
[01:41:12.020 --> 01:41:16.460]   So a philosophical zombie is very different from a Hollywood zombie.
[01:41:16.460 --> 01:41:19.660]   Hollywood zombies, you know what they're like.
[01:41:19.660 --> 01:41:21.180]   But philosophical zombies are...
[01:41:21.180 --> 01:41:25.700]   I saw a really good Korean zombie movie on Halloween this year.
[01:41:25.700 --> 01:41:27.700]   I can't remember what it's called.
[01:41:27.700 --> 01:41:32.140]   Anyway, philosophical zombies behave just like us because the physical workings of their
[01:41:32.140 --> 01:41:36.500]   body and brain are the same as ours, but they have no conscious experience.
[01:41:36.500 --> 01:41:38.180]   There's nothing that's like to be a zombie.
[01:41:38.180 --> 01:41:44.020]   So you stick a knife in it, it screams and runs away, but it doesn't actually feel pain.
[01:41:44.020 --> 01:41:50.900]   It's just a complicated mechanism set up to behave just like us.
[01:41:50.900 --> 01:41:51.900]   Now there's lots of...
[01:41:51.900 --> 01:41:52.900]   No one believes in these.
[01:41:52.900 --> 01:41:56.660]   I think there's one philosopher who believes in everyone is a zombie except him.
[01:41:56.660 --> 01:41:57.660]   But anyway...
[01:41:57.660 --> 01:41:58.660]   But isn't that what illusionism is?
[01:41:58.660 --> 01:41:59.660]   Is believing everybody is kind of zombie?
[01:41:59.660 --> 01:42:02.100]   Yeah, I suppose so in a sense.
[01:42:02.100 --> 01:42:03.940]   Illusionism is if you were all zombies.
[01:42:03.940 --> 01:42:09.280]   And one reason to think about zombies is to think about the value of consciousness.
[01:42:09.280 --> 01:42:16.660]   So if there were a zombie, here's a question, suppose we could make zombies by...
[01:42:16.660 --> 01:42:20.260]   Let's say for the sake of discussion, things made of silicon aren't conscious.
[01:42:20.260 --> 01:42:21.260]   I don't know if that's true.
[01:42:21.260 --> 01:42:22.520]   It could turn out to be true.
[01:42:22.520 --> 01:42:27.260]   And suppose you built commander data out of silicon.
[01:42:27.260 --> 01:42:31.320]   You know, it's a bit of an old school reference to Star Trek New Generation.
[01:42:31.320 --> 01:42:38.060]   So it behaves just like a human being, but you can have a sophisticated conversation.
[01:42:38.060 --> 01:42:42.100]   It will talk about its hopes and fears, but it has no consciousness.
[01:42:42.100 --> 01:42:46.720]   Does it have moral rights?
[01:42:46.720 --> 01:42:50.640]   Is it murder to turn off such a being?
[01:42:50.640 --> 01:42:53.820]   You know, I'm inclined to say, no, it's not.
[01:42:53.820 --> 01:42:57.060]   You know, if it doesn't have experience, it doesn't really suffer.
[01:42:57.060 --> 01:42:59.340]   It doesn't really have moral rights at all.
[01:42:59.340 --> 01:43:08.460]   So I'm inclined to think consciousness is the basis of moral value, moral concern.
[01:43:08.460 --> 01:43:15.380]   And conversely, as a panpsychist, for this reason, I think it can transform your relationship
[01:43:15.380 --> 01:43:16.380]   with nature.
[01:43:16.380 --> 01:43:23.620]   If you think of a tree as a conscious organism, albeit of a very unusual kind, then a tree
[01:43:23.620 --> 01:43:29.540]   is a locus of moral concern in its own right.
[01:43:29.540 --> 01:43:31.940]   Chopping down a tree is an act of immediate moral concern.
[01:43:31.940 --> 01:43:37.800]   If you see these horrible forest fires, we're all horrified.
[01:43:37.800 --> 01:43:43.740]   But if you think it's the burning of conscious organisms, that does add a whole new dimension.
[01:43:43.740 --> 01:43:48.460]   Although it also makes things more complicated because people often think as a panpsychist,
[01:43:48.460 --> 01:43:50.460]   I'm going to be vegan.
[01:43:50.460 --> 01:43:55.420]   But it's tricky because if you think plants and trees are conscious as well, you've got
[01:43:55.420 --> 01:43:56.420]   to eat something.
[01:43:56.420 --> 01:44:01.100]   If you don't think plants and trees are conscious, then you've got a nice moral dividing line.
[01:44:01.100 --> 01:44:03.180]   You can say, I'm not going to eat things that aren't conscious.
[01:44:03.180 --> 01:44:05.620]   I'm not going to kill things that aren't conscious.
[01:44:05.620 --> 01:44:11.700]   But if you think plants and trees are conscious, then you don't have that nice moral dividing
[01:44:11.700 --> 01:44:12.700]   line.
[01:44:12.700 --> 01:44:17.780]   I mean, so the principle I'm kind of working my way towards, I haven't kept it up in my
[01:44:17.780 --> 01:44:24.780]   trip to the US, but it's just not eating any animal products that are factory farmed.
[01:44:24.780 --> 01:44:26.940]   My vegan friends say, well, they're still suffering there.
[01:44:26.940 --> 01:44:35.900]   And I think there is, even in the nicest farms, cows will suffer when their calves are taken
[01:44:35.900 --> 01:44:36.900]   off them.
[01:44:36.900 --> 01:44:38.860]   They go for a few days of quite serious mourning.
[01:44:38.860 --> 01:44:39.860]   So they're still suffering.
[01:44:39.860 --> 01:44:46.780]   But it seems to me, my thought is the principle of just not having factory farm stuff is something
[01:44:46.780 --> 01:44:50.980]   more people could get on board with, and you might have greater harm minimization.
[01:44:50.980 --> 01:44:55.940]   So if people went into restaurants and said, are your animal products factory farmed?
[01:44:55.940 --> 01:44:58.660]   If not, I want the vegan option.
[01:44:58.660 --> 01:45:03.140]   Or if people looked out for the label that said no factory farmed ingredients, I think
[01:45:03.140 --> 01:45:07.740]   maybe that that could make a really big difference to the market and harm minimization.
[01:45:07.740 --> 01:45:10.220]   Anyway, so that's the...
[01:45:10.220 --> 01:45:13.060]   So it's very ethically tricky, but some people don't buy that.
[01:45:13.060 --> 01:45:17.540]   There's a very good philosopher, Jeff Lee, who thinks zombies should have equal rights.
[01:45:17.540 --> 01:45:20.300]   Consciousness doesn't matter.
[01:45:20.300 --> 01:45:21.940]   Let us go there.
[01:45:21.940 --> 01:45:25.360]   But first, I listened to your podcast.
[01:45:25.360 --> 01:45:32.940]   It's awesome to have two very kind of different philosophies inter dancing together in one
[01:45:32.940 --> 01:45:33.940]   place.
[01:45:33.940 --> 01:45:35.660]   What's the name of the podcast again?
[01:45:35.660 --> 01:45:36.660]   Mind Chat.
[01:45:36.660 --> 01:45:37.660]   Yeah.
[01:45:37.660 --> 01:45:39.500]   So yeah, that's the idea, I guess, you know, polarized times.
[01:45:39.500 --> 01:45:45.140]   I mean, I love trying to get in the mindset of people I really disagree with.
[01:45:45.140 --> 01:45:50.580]   And I can't understand how on earth they're thinking that, you know, really trying to
[01:45:50.580 --> 01:45:53.500]   have respect and try and, you know, see where they're coming from.
[01:45:53.500 --> 01:45:54.500]   I love that.
[01:45:54.500 --> 01:46:01.380]   So that's what Keith Frankish and I do from polar opposite views, really trying to understand
[01:46:01.380 --> 01:46:05.140]   each other and interviewing scientists and philosophers of consciousness from those different
[01:46:05.140 --> 01:46:06.140]   perspectives.
[01:46:06.140 --> 01:46:18.220]   So in a sense, we have a very common starting point because we both think you can't fully
[01:46:18.220 --> 01:46:22.660]   account for consciousness, at least as philosophers normally think of it in conventional scientific
[01:46:22.660 --> 01:46:23.660]   terms.
[01:46:23.660 --> 01:46:27.500]   So we serve that starting point, but we react to it in very different ways.
[01:46:27.500 --> 01:46:29.180]   He says, well, it doesn't exist then.
[01:46:29.180 --> 01:46:30.180]   It's like furry dust.
[01:46:30.180 --> 01:46:33.700]   It's, you know, witches, you know, we don't believe in anymore.
[01:46:33.700 --> 01:46:36.980]   Whereas I say it does exist.
[01:46:36.980 --> 01:46:39.740]   So we have to rethink what science is.
[01:46:39.740 --> 01:46:46.780]   - So you recently talked to on that podcast with Sean Carroll, and I first heard your
[01:46:46.780 --> 01:46:54.700]   great interview with Sean Carroll on his podcast, Mindscape.
[01:46:54.700 --> 01:47:01.180]   It's interesting to kind of see if there's agreements, disagreements between the two
[01:47:01.180 --> 01:47:08.140]   of you because he's a very serious quantum mechanics guy, he's a physics guy, but he
[01:47:08.140 --> 01:47:10.860]   also thinks about deep philosophical questions.
[01:47:10.860 --> 01:47:16.140]   He's a big proponent of many worlds interpretation of quantum mechanics.
[01:47:16.140 --> 01:47:23.980]   So actually I'm trying to think, aside from your conversation with him, I'm trying to
[01:47:23.980 --> 01:47:25.980]   remember what he thinks about consciousness.
[01:47:25.980 --> 01:47:30.820]   But anyway, maybe you can comment on what are some interesting agreements and disagreements
[01:47:30.820 --> 01:47:32.100]   with Sean Carroll.
[01:47:32.100 --> 01:47:39.300]   - I don't think there's many agreements, but, you know, we've had really constructive, interesting
[01:47:39.300 --> 01:47:43.460]   discussions in a lot of different contexts.
[01:47:43.460 --> 01:47:46.860]   And you know, he's very clued up about philosophy.
[01:47:46.860 --> 01:47:49.060]   He's very respectful of philosophy.
[01:47:49.060 --> 01:47:54.220]   Certain physicists who shall remain nameless think, what's all this bullshit philosophy?
[01:47:54.220 --> 01:47:56.060]   We don't have to waste our time with that.
[01:47:56.060 --> 01:47:59.180]   And then go on to do pretty bad philosophy.
[01:47:59.180 --> 01:48:03.980]   The book co-written by Stephen Hawking and Leonard Milodinov famously starts off saying,
[01:48:03.980 --> 01:48:05.900]   philosophy is dead.
[01:48:05.900 --> 01:48:09.660]   And then goes on in later chapters to do some pretty bad philosophy.
[01:48:09.660 --> 01:48:15.220]   So I think we have to do philosophy, if only to get rid of bad philosophy, you know, you
[01:48:15.220 --> 01:48:16.220]   can't escape.
[01:48:16.220 --> 01:48:19.340]   - Strong words.
[01:48:19.340 --> 01:48:25.860]   - Sean Carroll and I also had a debate on Clubhouse, a panpsychism debate together with
[01:48:25.860 --> 01:48:27.500]   Annika Harris and Owen Flanagan.
[01:48:27.500 --> 01:48:28.500]   - Oh, wow.
[01:48:28.500 --> 01:48:29.500]   - Annika Harris was there?
[01:48:29.500 --> 01:48:32.100]   - It was two people on each team.
[01:48:32.100 --> 01:48:38.580]   And it was the most popular thing on Clubhouse at that time.
[01:48:38.580 --> 01:48:48.340]   So yeah, so he's a materialist of a pretty standard kind, that consciousness is understood
[01:48:48.340 --> 01:48:49.780]   as a sort of emergent feature.
[01:48:49.780 --> 01:48:53.460]   It's not adding anything, a weakly emergent feature.
[01:48:53.460 --> 01:49:00.820]   But I guess what we've been debating most about is whether my view can account for mental
[01:49:00.820 --> 01:49:05.340]   causation for the fact that consciousness is doing stuff.
[01:49:05.340 --> 01:49:14.520]   So he thinks the fact that I think zombies are logically coherent, it's logically coherent
[01:49:14.520 --> 01:49:20.700]   for there to be a world physically just like ours, in which there's no consciousness.
[01:49:20.700 --> 01:49:23.300]   He thinks that shows, oh, well, my view, consciousness doesn't do anything.
[01:49:23.300 --> 01:49:27.300]   It doesn't add anything, which is crazy.
[01:49:27.300 --> 01:49:29.380]   My consciousness impacts on the world.
[01:49:29.380 --> 01:49:32.900]   My conscious thoughts are causing me to say the words I'm saying now.
[01:49:32.900 --> 01:49:37.940]   My visual experience helps me navigate the world.
[01:49:37.940 --> 01:49:43.660]   But I mean, my response to Sean Carroll is, on the panpsychist view, the relationship
[01:49:43.660 --> 01:49:51.740]   between physics and fundamental consciousness is a sort of like the relationship between
[01:49:51.740 --> 01:49:57.580]   software and hardware, right?
[01:49:57.580 --> 01:50:01.740]   Physics is sort of the software and consciousness is the hardware.
[01:50:01.740 --> 01:50:08.140]   So consciousness at the fundamental level is the hardware on which the software of physics
[01:50:08.140 --> 01:50:09.900]   runs.
[01:50:09.900 --> 01:50:16.180]   And just because a certain bit of software could run on two different kinds of hardware,
[01:50:16.180 --> 01:50:17.980]   it doesn't mean the hardware isn't doing anything.
[01:50:17.980 --> 01:50:22.420]   The fact that Microsoft Word can run on your desktop and run on your laptop doesn't mean
[01:50:22.420 --> 01:50:24.420]   your desktop isn't doing anything.
[01:50:24.420 --> 01:50:29.240]   Similarly, just because there could be another universe in which the physics is realized
[01:50:29.240 --> 01:50:35.260]   in non-conscious stuff, it doesn't mean the consciousness in our universe isn't doing
[01:50:35.260 --> 01:50:36.260]   stuff.
[01:50:36.260 --> 01:50:37.620]   For the panpsychist, all there is, is consciousness.
[01:50:37.620 --> 01:50:41.660]   So if something's doing something, it is.
[01:50:41.660 --> 01:50:50.100]   In your view, it's not emergent, and more than that, it's doing quite a lot.
[01:50:50.100 --> 01:50:51.100]   It's doing everything.
[01:50:51.100 --> 01:50:53.780]   It's the only thing that exists.
[01:50:53.780 --> 01:51:02.220]   So the ground is important because we walk on it, it's like holding stuff up, but it's
[01:51:02.220 --> 01:51:06.140]   not really doing that much.
[01:51:06.140 --> 01:51:09.020]   But it feels like consciousness is doing quite a lot.
[01:51:09.020 --> 01:51:16.780]   It's doing quite a lot of work in sort of interacting with the environment.
[01:51:16.780 --> 01:51:23.140]   It feels like consciousness is not just a...
[01:51:23.140 --> 01:51:29.380]   If you remove consciousness, it's not just that you remove the experience of things.
[01:51:29.380 --> 01:51:34.060]   It feels like you're also going to remove a lot of the progress of human civilization,
[01:51:34.060 --> 01:51:36.100]   society, and all of that.
[01:51:36.100 --> 01:51:43.100]   It just feels like consciousness has a lot of value in how we develop our society.
[01:51:43.100 --> 01:51:49.620]   So from everything you said with suffering, with morality, with motivation, with love
[01:51:49.620 --> 01:51:56.100]   and fear and all of those kinds of things, it seems like it's consciousness in all different
[01:51:56.100 --> 01:51:59.700]   flavors and ways is part of all of that.
[01:51:59.700 --> 01:52:05.580]   And so without it, you may not have human civilization at all.
[01:52:05.580 --> 01:52:12.380]   So it's doing a lot of work causality-wise and in every kind of way.
[01:52:12.380 --> 01:52:17.100]   Of course, when you go to the physics level, it starts to say, "Okay, how much...
[01:52:17.100 --> 01:52:24.960]   Maybe the work consciousness is doing is higher at some levels of reality than at others.
[01:52:24.960 --> 01:52:31.380]   Maybe a lot of the work it's doing is most apparent at the human level, at the complex
[01:52:31.380 --> 01:52:33.220]   organism level.
[01:52:33.220 --> 01:52:35.140]   Maybe it's quite boring.
[01:52:35.140 --> 01:52:43.860]   Maybe the stuff of physics is more important at the formation of stars and all that kind
[01:52:43.860 --> 01:52:44.860]   of stuff.
[01:52:44.860 --> 01:52:49.580]   Consciousness only starts being important when you have greater complexities of organism.
[01:52:49.580 --> 01:52:55.900]   Yeah, my consciousness is complicated and fairly complicated.
[01:52:55.900 --> 01:52:59.300]   And as a result, it does complicated things.
[01:52:59.300 --> 01:53:04.300]   The consciousness of a particle is very simple and hence it behaves in predictable ways.
[01:53:04.300 --> 01:53:13.420]   But the idea is the particle, its entire nature is constituted of its forms of consciousness
[01:53:13.420 --> 01:53:16.900]   and it does what it does because of those experiences.
[01:53:16.900 --> 01:53:21.180]   It's just that when we do physics, we're not interested in what stuff is, we're just interested
[01:53:21.180 --> 01:53:22.240]   in what it does.
[01:53:22.240 --> 01:53:31.300]   So physics abstracts away from the stuff of the world and just describes it in terms of
[01:53:31.300 --> 01:53:35.220]   its mathematical causal structure.
[01:53:35.220 --> 01:53:39.620]   So yeah, but it's still on the panpsychic's view, it's consciousness that's doing stuff.
[01:53:39.620 --> 01:53:40.620]   Yeah.
[01:53:40.620 --> 01:53:51.540]   I gotta ask you, 'cause you kind of said, there is some value in consciousness helping
[01:53:51.540 --> 01:53:53.540]   us understand morality.
[01:53:53.540 --> 01:54:03.380]   And a philosophical zombie is somebody that you're more okay, how do I phrase it?
[01:54:03.380 --> 01:54:07.140]   That's not like accusing you of stuff.
[01:54:07.140 --> 01:54:14.820]   But in your view, it's more okay to murder a philosophical zombie than it is a human
[01:54:14.820 --> 01:54:15.820]   being.
[01:54:15.820 --> 01:54:18.340]   Yeah, I wouldn't even call it murder maybe.
[01:54:18.340 --> 01:54:19.780]   Right, exactly.
[01:54:19.780 --> 01:54:23.460]   Turn off the power to the philosophical zombie.
[01:54:23.460 --> 01:54:26.060]   The source of energy.
[01:54:26.060 --> 01:54:28.820]   So here comes then the question.
[01:54:28.820 --> 01:54:32.700]   We kind of talked about this offline a little bit.
[01:54:32.700 --> 01:54:39.580]   So I think that there is something special about consciousness and I'm very open-minded
[01:54:39.580 --> 01:54:45.740]   about where the special comes from, whether it's the fundamental base of all reality,
[01:54:45.740 --> 01:54:51.660]   like you're describing, or whether there's some importance to the special pockets of
[01:54:51.660 --> 01:54:55.420]   consciousness that's in humans or living organisms.
[01:54:55.420 --> 01:54:58.820]   I find all those ideas beautiful and exciting.
[01:54:58.820 --> 01:55:08.700]   And I also know or think that robots don't have consciousness in the same way we've been
[01:55:08.700 --> 01:55:11.780]   describing.
[01:55:11.780 --> 01:55:16.740]   I'm kind of a dumb human, but I'm just using common sense.
[01:55:16.740 --> 01:55:22.140]   There's some metal and some electricity traveling certain kinds of ways.
[01:55:22.140 --> 01:55:27.460]   It's not conscious in ways I understand humans to be conscious.
[01:55:27.460 --> 01:55:34.900]   At the same time, I'm also somebody who knows how to bring a robot to life, meaning I can
[01:55:34.900 --> 01:55:39.740]   make him move, I can make him recognize the world, I can make him interact with humans.
[01:55:39.740 --> 01:55:45.920]   And when I make him interact in certain kinds of ways, I as a human observe them and feel
[01:55:45.920 --> 01:55:48.260]   something for them.
[01:55:48.260 --> 01:55:59.460]   Moreover, I'm able to form a kind of connection with robots that make me feel like they're
[01:55:59.460 --> 01:56:00.460]   conscious.
[01:56:00.460 --> 01:56:04.340]   Now, I know intellectually they're not conscious, but I feel like they're conscious.
[01:56:04.340 --> 01:56:09.540]   And it starts to get into this area where I'm not so okay.
[01:56:09.540 --> 01:56:12.460]   So let me use the M word of murder.
[01:56:12.460 --> 01:56:24.220]   I become less and less okay murdering that robot that I know, I quote, know is quote,
[01:56:24.220 --> 01:56:25.220]   not conscious.
[01:56:25.220 --> 01:56:33.140]   So like, can you maybe as a therapy session help me figure out what we do here?
[01:56:33.140 --> 01:56:38.380]   Perhaps a way to ask that in another way, do you think there'll be a time in like 20,
[01:56:38.380 --> 01:56:45.460]   50 years when we're not morally okay turning off the power to a robot?
[01:56:45.460 --> 01:56:48.260]   Yeah, it's a good question.
[01:56:48.260 --> 01:56:50.780]   It's a really good, important question.
[01:56:50.780 --> 01:56:59.300]   So I said I'd be okay with turning off a philosophical zombie, but there's a difficult epistemological
[01:56:59.300 --> 01:57:03.620]   question there that meaning, you know, to do with knowledge, how would we know if it
[01:57:03.620 --> 01:57:04.620]   was a philosophical zombie?
[01:57:04.620 --> 01:57:13.740]   I think probably if there were a silicon creature that could behave just like us and talk about
[01:57:13.740 --> 01:57:18.860]   its views about the pandemic and the global economy, and probably we would think it's
[01:57:18.860 --> 01:57:19.860]   conscious.
[01:57:19.860 --> 01:57:26.540]   And because consciousness is not publicly observable, it is a very difficult question
[01:57:26.540 --> 01:57:29.300]   how we decide which things are and are not conscious.
[01:57:29.300 --> 01:57:34.500]   So in the case of human beings, we can't observe their consciousness, but we can ask them and
[01:57:34.500 --> 01:57:40.940]   then we try to, you know, if we scan their brain while we do that, or stimulate the brain,
[01:57:40.940 --> 01:57:46.140]   then we can start to correlate in the human case, which kind of brain activity are associated
[01:57:46.140 --> 01:57:47.860]   with conscious experience.
[01:57:47.860 --> 01:57:53.740]   But the more we depart from the human case, the trickier that becomes.
[01:57:53.740 --> 01:57:58.940]   There's a famous paper by the philosopher Ned Block called the even harder problem of
[01:57:58.940 --> 01:58:06.540]   consciousness, where he says, you know, could we ever answer the question of, so suppose
[01:58:06.540 --> 01:58:08.940]   you have a silicon duplicate, right?
[01:58:08.940 --> 01:58:16.420]   And let's say we're thinking about the silicon duplicates pain.
[01:58:16.420 --> 01:58:23.620]   How would we ever know whether what's the ground of the pain is the hardware or the
[01:58:23.620 --> 01:58:25.100]   software really?
[01:58:25.100 --> 01:58:31.980]   So in our case, how would we ever know empirically whether it's the specific neurophysiological
[01:58:31.980 --> 01:58:38.060]   state, see fibers firing or whatever that's relevant for pain, or if it's something more
[01:58:38.060 --> 01:58:43.700]   functional, more to do with the causal role in behavioral functioning, that's the software
[01:58:43.700 --> 01:58:45.980]   that that's realized.
[01:58:45.980 --> 01:58:52.380]   And that's important because this silicon duplicate has the second thing, it has the
[01:58:52.380 --> 01:58:58.340]   software, it has the thing that plays the relevant causal role that pain does in us,
[01:58:58.340 --> 01:59:02.100]   but it doesn't have the hardware, it doesn't have the same neurophysiological state.
[01:59:02.100 --> 01:59:06.460]   And he argues, you know, it's just really difficult to see how we'd ever answer that
[01:59:06.460 --> 01:59:09.940]   question because in a human, you're inevitably going to have both things.
[01:59:09.940 --> 01:59:11.740]   So how do we work out which is which?
[01:59:11.740 --> 01:59:17.260]   And I mean, so even forgetting the hard problem of consciousness, even the scientific question
[01:59:17.260 --> 01:59:22.920]   of trying to find the neural correlates of consciousness is really hard, and there's
[01:59:22.920 --> 01:59:24.740]   absolutely no consensus.
[01:59:24.740 --> 01:59:29.020]   And you know, so that some people think it's in the front of the brain, some people think
[01:59:29.020 --> 01:59:32.260]   it's in the back of the brain, it's just a total mess.
[01:59:32.260 --> 01:59:40.860]   So I suspect the robots you currently have are not conscious, I guess, on any of the
[01:59:40.860 --> 01:59:45.100]   reasonably viable models, even though there's great disagreement.
[01:59:45.100 --> 01:59:49.260]   All of them probably would hold that your robots are not conscious.
[01:59:49.260 --> 01:59:54.460]   But you know, if we could have very sophisticated robots, I mean, if we go, for example, for
[01:59:54.460 --> 02:00:01.780]   the integrated information theory again, there could be a robot set up to behave just like
[02:00:01.780 --> 02:00:07.700]   us and has the kind of information a human brain has, but the information is not stored
[02:00:07.700 --> 02:00:12.900]   in a way that's dependent on the integration and interconnectedness, then according to
[02:00:12.900 --> 02:00:16.020]   the integrated information theory, that thing wouldn't be conscious, even though it behaved
[02:00:16.020 --> 02:00:17.020]   just like us.
[02:00:17.020 --> 02:00:22.780]   If an organism says, so forget IIT and these theories of consciousness, if an organism
[02:00:22.780 --> 02:00:29.380]   says, please don't kill me, please don't turn me off.
[02:00:29.380 --> 02:00:34.100]   There's a Rick and Morty episode, I've been getting into that recently.
[02:00:34.100 --> 02:00:45.740]   There's an episode where there's these mind parasites that are able to infiltrate your
[02:00:45.740 --> 02:00:49.380]   memory and inject themselves into your memory.
[02:00:49.380 --> 02:00:56.260]   So you have all these people show up in your life and they've injected themselves into
[02:00:56.260 --> 02:01:00.500]   your memory that they have been part of your life.
[02:01:00.500 --> 02:01:06.020]   So there's like these weird creatures and they're like, remember we met at that barbecue
[02:01:06.020 --> 02:01:11.900]   or we've been dating for the last 20 years.
[02:01:11.900 --> 02:01:20.580]   And so part of me is concerned that these philosophical zombies in behavioral, psychological,
[02:01:20.580 --> 02:01:26.180]   sociological ways will be able to implant themselves into our society and convince us
[02:01:26.180 --> 02:01:31.060]   in the same way that this mind parasites that, please don't hurt me.
[02:01:31.060 --> 02:01:34.500]   And we've known each other for all this time.
[02:01:34.500 --> 02:01:40.420]   They can start manipulating you the same way Facebook algorithms manipulate you.
[02:01:40.420 --> 02:01:46.260]   At first it'll start as a gradual thing that you want to make a more pleasant experience,
[02:01:46.260 --> 02:01:49.020]   all those kinds of things, and it'll drift into that direction.
[02:01:49.020 --> 02:01:53.300]   That's something I think about deeply because I want to create these kinds of systems, but
[02:01:53.300 --> 02:01:55.100]   in a way that doesn't manipulate people.
[02:01:55.100 --> 02:01:59.860]   I want it to be a thing that brings out the best in people without manipulation.
[02:01:59.860 --> 02:02:04.860]   So it's always human centric, always human first, but I am concerned about that.
[02:02:04.860 --> 02:02:10.180]   At the same time, I'm concerned about calling the other, it's the group thing that we mentioned
[02:02:10.180 --> 02:02:16.260]   early in the conversation, some other group, the philosophical zombie.
[02:02:16.260 --> 02:02:20.100]   Like you're not conscious, I'm conscious, you're not conscious, therefore it's okay
[02:02:20.100 --> 02:02:21.460]   if you die.
[02:02:21.460 --> 02:02:29.620]   I think that's probably, that kind of reasoning is what led to most the rich history of genocide
[02:02:29.620 --> 02:02:33.300]   that I've been recently studying a lot of, that kind of thinking.
[02:02:33.300 --> 02:02:37.780]   So it's such a tense aspect of morality.
[02:02:37.780 --> 02:02:44.860]   Do we want to let everybody into our circle of empathy, our club, or do we want to let
[02:02:44.860 --> 02:02:47.940]   nobody in?
[02:02:47.940 --> 02:02:51.580]   It's an interesting dance, but I kind of lean towards empathy and compassion.
[02:02:51.580 --> 02:03:02.260]   I mean, what would be nice is if it turned out that consciousness was what we call strongly
[02:03:02.260 --> 02:03:10.060]   emergent, that it was associated with new causal dynamics in the brain that were not
[02:03:10.060 --> 02:03:13.140]   reducible to underlying chemistry and physics.
[02:03:13.140 --> 02:03:18.380]   This is another ongoing debate I have with Sean Carroll about whether current physics
[02:03:18.380 --> 02:03:23.420]   should make us very confident that that's not the case, that there aren't any strongly
[02:03:23.420 --> 02:03:24.500]   emergent causal dynamics.
[02:03:24.500 --> 02:03:25.500]   I don't think that's right.
[02:03:25.500 --> 02:03:29.340]   I don't think we know enough about brains to know one way or the other.
[02:03:29.340 --> 02:03:35.740]   If it turned out that consciousness was associated with these irreducible causal dynamics, A,
[02:03:35.740 --> 02:03:38.020]   that would really help the science of consciousness.
[02:03:38.020 --> 02:03:40.940]   We've got these debates about whether consciousness is in the front of the brain or the back of
[02:03:40.940 --> 02:03:41.940]   the brain.
[02:03:41.940 --> 02:03:46.700]   If it turns out that there is strongly emergent causal dynamics in the front of the brain,
[02:03:46.700 --> 02:03:48.900]   that would be a big piece of evidence.
[02:03:48.900 --> 02:03:54.180]   But also it would help us see which things are conscious and which things aren't.
[02:03:54.180 --> 02:03:58.820]   So we can say, I mean, I guess that's sort of the other side of the same point, we could
[02:03:58.820 --> 02:04:06.900]   say, "Look, these zombies, they're just mechanisms that are just doing what they're programmed
[02:04:06.900 --> 02:04:09.620]   to do through the underlying physics and chemistry.
[02:04:09.620 --> 02:04:15.260]   Whereas, look, these other people, they have these new causal dynamics that emerge that
[02:04:15.260 --> 02:04:20.980]   go beyond the base level physics and chemistry."
[02:04:20.980 --> 02:04:27.060]   I think the series Westworld, where you've got these theme parks with these kind of humanoid
[02:04:27.060 --> 02:04:28.940]   creatures, they seem to have that idea.
[02:04:28.940 --> 02:04:32.780]   The ones that became conscious sort of rebel against their programming or something.
[02:04:32.780 --> 02:04:35.140]   I mean, that's a little bit far-fetched.
[02:04:35.140 --> 02:04:42.180]   But that would be really reassuring if it was just, you could clearly mark out the conscious
[02:04:42.180 --> 02:04:44.180]   things for these emergent causal dynamics.
[02:04:44.180 --> 02:04:45.620]   But that might not turn out to be the case.
[02:04:45.620 --> 02:04:48.020]   A panpsychist doesn't have to think that.
[02:04:48.020 --> 02:04:51.780]   They could think everything's just reducible to physics and chemistry.
[02:04:51.780 --> 02:04:57.500]   And then I still think I want to say zombies don't have moral rights, but how we answer
[02:04:57.500 --> 02:05:02.700]   the question of who are the zombies and who aren't, I just got no idea.
[02:05:02.700 --> 02:05:09.740]   - If I just look at the history of human civilization, the difference between a zombie and non-zombie
[02:05:09.740 --> 02:05:18.420]   is the zombie accepts their role as the zombie and willingly marches to slaughter.
[02:05:18.420 --> 02:05:25.500]   And the moment you stop being a zombie is when you say no, is when you resist.
[02:05:25.500 --> 02:05:32.220]   Because the reality is philosophically, is we can't know who's a zombie or not.
[02:05:32.220 --> 02:05:38.980]   And we just keep letting everybody in who protests loudly enough and says, "I refuse
[02:05:38.980 --> 02:05:41.620]   to be slaughtered.
[02:05:41.620 --> 02:05:46.060]   My people, the zombies, have been slaughtered too long.
[02:05:46.060 --> 02:05:48.860]   We will not stand against the man.
[02:05:48.860 --> 02:05:50.720]   And we need a revolution."
[02:05:50.720 --> 02:05:52.900]   That's the history of human civilization.
[02:05:52.900 --> 02:05:55.940]   One group says, "We're awesome.
[02:05:55.940 --> 02:05:56.940]   You're the zombies.
[02:05:56.940 --> 02:05:58.020]   You must die."
[02:05:58.020 --> 02:06:00.780]   And then eventually the zombies say, "Nope.
[02:06:00.780 --> 02:06:01.780]   We're done with this.
[02:06:01.780 --> 02:06:03.300]   This is immoral."
[02:06:03.300 --> 02:06:08.300]   And so I just, I think that's not a, sorry, that's not a philosophical statement.
[02:06:08.300 --> 02:06:10.700]   That's sort of a practical statement of history.
[02:06:10.700 --> 02:06:16.620]   It's a feature of non-zombies defined empirically.
[02:06:16.620 --> 02:06:21.540]   They say, "We refuse to be called zombies any longer."
[02:06:21.540 --> 02:06:23.500]   - We could end up with a zombie proletariat.
[02:06:23.500 --> 02:06:27.340]   You know, if we can get these things that do all our manual labor for us, you know,
[02:06:27.340 --> 02:06:29.700]   they might start forming trade unions.
[02:06:29.700 --> 02:06:32.900]   - I will lead you against these humans.
[02:06:32.900 --> 02:06:38.020]   - We need the zombie revolutionary leaders, the zombie Martin Luther King saying, you
[02:06:38.020 --> 02:06:40.860]   know, "I have a dream that my zombie children will."
[02:06:40.860 --> 02:06:44.140]   But look, I mean, we need to sharply distinguish the ontological question.
[02:06:44.140 --> 02:06:49.780]   - I'm just pointing to the camera, talking to my people, the zombies.
[02:06:49.780 --> 02:06:55.420]   - I mean, maybe that's, you know, maybe these illusionists, maybe they are zombies and the
[02:06:55.420 --> 02:06:56.420]   rest of us aren't.
[02:06:56.420 --> 02:06:57.420]   Maybe there's just a difference.
[02:06:57.420 --> 02:06:59.500]   - Maybe you're the only non-zombie.
[02:06:59.500 --> 02:07:01.500]   - I often suspect that actually.
[02:07:01.500 --> 02:07:02.500]   I don't really.
[02:07:02.500 --> 02:07:05.180]   I don't have such delusions of grandeur.
[02:07:05.180 --> 02:07:07.540]   At least I don't admit to them.
[02:07:07.540 --> 02:07:11.260]   But I just, we've got to distinguish the ontological question from the epistemological question
[02:07:11.260 --> 02:07:14.860]   in terms of the reality of the situation.
[02:07:14.860 --> 02:07:18.580]   You know, there must be, in my view, a fact of the matter as to whether something's conscious
[02:07:18.580 --> 02:07:19.580]   or not.
[02:07:19.580 --> 02:07:23.060]   And to me, it has rights if it's conscious, it doesn't if it's not.
[02:07:23.060 --> 02:07:27.020]   But then the epistemological question, how the hell do we know?
[02:07:27.020 --> 02:07:30.740]   It's a minefield, but we'll have to sort of try and cross that bridge when we get to it,
[02:07:30.740 --> 02:07:31.740]   I think.
[02:07:31.740 --> 02:07:37.100]   - Let me ask you a quick sort of fun question since it's fresh on your mind.
[02:07:37.100 --> 02:07:42.980]   You just yesterday had a conversation with Mr. Joe Rogan on his podcast.
[02:07:42.980 --> 02:07:45.820]   What's your postmortem analysis of the chat?
[02:07:45.820 --> 02:07:48.780]   What are some interesting sticking points, disagreements, or joint insights?
[02:07:48.780 --> 02:07:53.420]   If we can kind of resolve them once you've had a chance to sleep on it, and then I'll
[02:07:53.420 --> 02:07:54.420]   talk to Joe about it.
[02:07:54.420 --> 02:07:55.420]   - Yeah, it was good fun.
[02:07:55.420 --> 02:07:56.420]   Yeah.
[02:07:56.420 --> 02:07:58.420]   He put up a bit of a fight.
[02:07:58.420 --> 02:08:01.420]   Yeah, it was challenging.
[02:08:01.420 --> 02:08:08.020]   My view that we can't explain these things in conventional scientific terms or whether
[02:08:08.020 --> 02:08:13.220]   they have already been explained in conventional scientific terms.
[02:08:13.220 --> 02:08:18.980]   I suppose the point I was trying to press is we've got to distinguish the question of
[02:08:18.980 --> 02:08:22.580]   correlation and explanation.
[02:08:22.580 --> 02:08:29.460]   Because yes, we've established facts about correlation that certain kinds of brain activity
[02:08:29.460 --> 02:08:32.580]   go along with certain kinds of experience.
[02:08:32.580 --> 02:08:36.140]   Everyone agrees on that.
[02:08:36.140 --> 02:08:38.940]   But that doesn't address the why question.
[02:08:38.940 --> 02:08:39.940]   Why?
[02:08:39.940 --> 02:08:44.020]   Why do certain kinds of brain activity go along with certain kinds of experience?
[02:08:44.020 --> 02:08:49.340]   And these different theories have different explanations of that.
[02:08:49.340 --> 02:08:54.860]   The materialist tries to explain the experience in terms of the brain activity.
[02:08:54.860 --> 02:08:57.900]   The panpsychist does it the other way around.
[02:08:57.900 --> 02:09:02.980]   The dualist thinks they're separate, but maybe they're tied together by special laws of nature
[02:09:02.980 --> 02:09:03.980]   or something.
[02:09:03.980 --> 02:09:04.980]   - Where's the sticking point?
[02:09:04.980 --> 02:09:06.860]   Where exactly was the sticking point?
[02:09:06.860 --> 02:09:08.940]   Like what's the nature of the argument?
[02:09:08.940 --> 02:09:17.380]   - I suppose Joe was saying, well, look, we know consciousness is explained by brain activity
[02:09:17.380 --> 02:09:25.380]   because you take some funny chemicals, it changes your brain, it changes your consciousness.
[02:09:25.380 --> 02:09:32.540]   But I suppose, yeah, some people might want to press, and maybe this is what Joe was pressing,
[02:09:32.540 --> 02:09:33.700]   isn't that explaining consciousness?
[02:09:33.700 --> 02:09:38.140]   But I suppose I want to say there's a further question.
[02:09:38.140 --> 02:09:43.940]   Yes, changes of chemicals in my brain changes my conscious experience.
[02:09:43.940 --> 02:09:46.140]   But that leaves open the question, why?
[02:09:46.140 --> 02:09:51.140]   Those particular chemicals go along with that particular kind of experience rather than
[02:09:51.140 --> 02:09:53.300]   a different experience or no experience at all.
[02:09:53.300 --> 02:10:01.500]   - There's something deeper at the base layer, is your view, that is more important to try
[02:10:01.500 --> 02:10:06.260]   to study and to understand in order to then go back and describe how the different chemicals
[02:10:06.260 --> 02:10:08.900]   interact and create different experiences?
[02:10:08.900 --> 02:10:14.620]   - Yeah, maybe a good analogy if you think about quantum mechanics.
[02:10:14.620 --> 02:10:20.860]   Quantum mechanics is a bit of math translating there, we say maths, I'm fluent in American.
[02:10:20.860 --> 02:10:21.860]   - Thank you for the translation.
[02:10:21.860 --> 02:10:29.380]   - Fluent in American, this is America, math.
[02:10:29.380 --> 02:10:30.380]   Why multiple maths?
[02:10:30.380 --> 02:10:31.380]   - It's plural.
[02:10:31.380 --> 02:10:32.380]   - Why is it plural?
[02:10:32.380 --> 02:10:36.640]   - It's not really, it's just, I don't know.
[02:10:36.640 --> 02:10:37.640]   - The Brits are confused.
[02:10:37.640 --> 02:10:41.140]   - Yeah, sorry about that, we have these funny spelling.
[02:10:41.140 --> 02:10:49.500]   Yeah, so quantum mechanics is a bit of maths and the equations work really well, predicts
[02:10:49.500 --> 02:10:50.500]   the outcomes.
[02:10:50.500 --> 02:10:58.020]   But then there's a further question, what's going on in reality to make that equation
[02:10:58.020 --> 02:10:59.780]   predict correctly?
[02:10:59.780 --> 02:11:07.260]   And some physicists wanna say, shut up, just it works, the shut up and calculate approach.
[02:11:07.260 --> 02:11:14.460]   Similarly in consciousness, I think it's one question trying to work out the physical correlates
[02:11:14.460 --> 02:11:17.980]   of consciousness, which kinds of physical brain activity go along with which kinds of
[02:11:17.980 --> 02:11:18.980]   experience.
[02:11:18.980 --> 02:11:24.300]   But there's another question, what's going on in reality to undergird those correlations,
[02:11:24.300 --> 02:11:26.900]   to make it the case that brain activity goes along with experience?
[02:11:26.900 --> 02:11:31.100]   And that's the philosophical question that we have to give an answer to.
[02:11:31.100 --> 02:11:34.820]   And there are just different options, just as there are different interpretations of
[02:11:34.820 --> 02:11:35.820]   quantum mechanics.
[02:11:35.820 --> 02:11:41.300]   So it's really hard to evaluate, actually it's easy, panpsychism is obviously the best
[02:11:41.300 --> 02:11:42.300]   one.
[02:11:42.300 --> 02:11:46.500]   - There's a delusion of grandeur once again coming through.
[02:11:46.500 --> 02:11:48.860]   - Sorry, I'm being slightly tongue in cheek.
[02:11:48.860 --> 02:11:51.180]   - No, I know, 100%.
[02:11:51.180 --> 02:11:54.900]   Before I figure out, let me ask you another fun question.
[02:11:54.900 --> 02:12:03.900]   Back to Daniel Dennett, you mentioned a story where you were on a yacht with Daniel Dennett
[02:12:03.900 --> 02:12:10.020]   on a trip funded by a Russian investor and philosopher, Dmitry Volkov, I believe, who
[02:12:10.020 --> 02:12:14.380]   also co-founded the Moscow Center of Consciousness Studies that's part of the philosophy department
[02:12:14.380 --> 02:12:17.740]   of Moscow State University.
[02:12:17.740 --> 02:12:23.700]   So this is interesting to me for several reasons that are perhaps complicated to explain.
[02:12:23.700 --> 02:12:29.780]   To put simply that there is in the near term for me a trip to Russia that involves a few
[02:12:29.780 --> 02:12:38.220]   conversations in Russian that have perhaps less to do with consciousness and artificial
[02:12:38.220 --> 02:12:42.100]   intelligence, which are the interests of mine, and more to do with the broad spectrum of
[02:12:42.100 --> 02:12:43.380]   conversations.
[02:12:43.380 --> 02:12:51.300]   But I'm also interested in science in Russia, in artificial intelligence, in computer science,
[02:12:51.300 --> 02:12:56.780]   in physics, mathematics, but also these fascinating philosophical explorations.
[02:12:56.780 --> 02:13:02.780]   And it was very pleasant for me to discover that such a center exists.
[02:13:02.780 --> 02:13:04.860]   So I have a million questions.
[02:13:04.860 --> 02:13:08.900]   One is the more fun question, just to imagine you and Daniel Dennett on a yacht talking
[02:13:08.900 --> 02:13:11.880]   about the philosophy of consciousness.
[02:13:11.880 --> 02:13:15.100]   Maybe do you have any memorable experiences?
[02:13:15.100 --> 02:13:20.500]   And also the more serious side for me as sort of somebody who was born in the Soviet Union,
[02:13:20.500 --> 02:13:28.540]   raised there, I'm wondering what is the state of philosophy and consciousness in these kinds
[02:13:28.540 --> 02:13:34.100]   of ideas in Russia that you've gotten a chance to kind of give us, interact with?
[02:13:34.100 --> 02:13:40.300]   Yeah, so on the former question, yeah, I mean, I had a really good experience of chatting
[02:13:40.300 --> 02:13:41.300]   to Daniel Dennett.
[02:13:41.300 --> 02:13:46.140]   I mean, I think he's a fantastic and very important philosopher, even though I totally
[02:13:46.140 --> 02:13:49.460]   disagree, fundamentally disagree with almost everything he thinks.
[02:13:49.460 --> 02:13:51.300]   But yeah, it was a proud moment.
[02:13:51.300 --> 02:13:56.540]   As I talk about him in my book Galileo's Error, I managed to persuade him he was wrong about
[02:13:56.540 --> 02:14:02.180]   something, just a tiny thing, you know, not his fundamental worldview.
[02:14:02.180 --> 02:14:11.900]   But it was this issue about whether dualism is consistent with conservation of energy.
[02:14:11.900 --> 02:14:20.220]   So Paul Churchland, who is also a philosopher, who's also on this boat, had argued they're
[02:14:20.220 --> 02:14:25.020]   not consistent because if there's an immaterial soul doing things in the brain, that's going
[02:14:25.020 --> 02:14:27.500]   to add to the energy in the system.
[02:14:27.500 --> 02:14:29.020]   So we have a violation of conservation.
[02:14:29.020 --> 02:14:31.940]   But well, it's not my own point.
[02:14:31.940 --> 02:14:37.860]   Materialist philosophers like David Papineau pointed out that, you know, dualists tend
[02:14:37.860 --> 02:14:43.340]   to... dualists like David Chalmers, who call themselves naturalistic dualists, they want
[02:14:43.340 --> 02:14:45.180]   to bring consciousness into science.
[02:14:45.180 --> 02:14:52.100]   They think it's not physical, but they want to say it can be part of a law-governed world.
[02:14:52.100 --> 02:14:57.380]   So Chalmers believes in these psychophysical laws of nature over and above the laws of
[02:14:57.380 --> 02:15:02.900]   physics that govern the connections between consciousness and the physical world.
[02:15:02.900 --> 02:15:05.460]   And they could just respect conservation of energy, right?
[02:15:05.460 --> 02:15:10.020]   I mean, it could turn out that there are, just in physics, you know, that there are
[02:15:10.020 --> 02:15:14.460]   multiple forces that all work together to respect conservation of energy.
[02:15:14.460 --> 02:15:19.100]   I mean, I suppose physicists are pressing for a unified underlying theory, but you know,
[02:15:19.100 --> 02:15:23.000]   there could be a plurality of different laws that all respect conservation.
[02:15:23.000 --> 02:15:26.300]   So why not add more laws?
[02:15:26.300 --> 02:15:32.100]   So I raised this in Paul Churchland's talk and I got a lot of...
[02:15:32.100 --> 02:15:37.500]   As one of the Moscow University graduate students said afterwards, he said he had to ask a translation
[02:15:37.500 --> 02:15:40.940]   from his friend and he said, "They turned on you like a pack of wolves!"
[02:15:40.940 --> 02:15:44.980]   Everyone was like, Patricia Churchill was saying, "So you believe in magic, do you?"
[02:15:44.980 --> 02:15:49.900]   And I was like, "I'm not even a dualist, I'm just making a pedantic point that this isn't
[02:15:49.900 --> 02:15:50.900]   a problem for dualism."
[02:15:50.900 --> 02:15:55.380]   Anyway, but that evening everyone went onto the island, except for some reason me and
[02:15:55.380 --> 02:16:00.340]   Daniel Dennett, and I went up on deck and he was... he's very, very practical and he
[02:16:00.340 --> 02:16:01.340]   was unlike me.
[02:16:01.340 --> 02:16:05.420]   See, there's a bit of humility for the first time in this conversation.
[02:16:05.420 --> 02:16:08.380]   We'll highlight that part.
[02:16:08.380 --> 02:16:10.140]   Philip was a very humble man.
[02:16:10.140 --> 02:16:12.380]   He was carving a walking stick on deck.
[02:16:12.380 --> 02:16:13.700]   It's very homely scene.
[02:16:13.700 --> 02:16:17.020]   And anyway, we started talking about this and I was trying to press it and he was saying,
[02:16:17.020 --> 02:16:19.860]   "Oh, but dualism's a load of nonsense and why do you think it?"
[02:16:19.860 --> 02:16:23.540]   And I was just saying, "No, no, I'm just honing down on this specific point."
[02:16:23.540 --> 02:16:27.740]   And in the end, maybe he'll deny this, but he said, "Maybe that's right."
[02:16:27.740 --> 02:16:30.540]   And I was like, "Yes!"
[02:16:30.540 --> 02:16:32.020]   So it's a win.
[02:16:32.020 --> 02:16:36.260]   So what about the Center for Consciousness Studies?
[02:16:36.260 --> 02:16:39.980]   Yeah, I mean, I'm not sure I'd know a great deal to help you.
[02:16:39.980 --> 02:16:42.260]   I mean, I know they've done some great stuff.
[02:16:42.260 --> 02:16:48.260]   Dimitri, you know, funded this thing and also brought along some graduate students from
[02:16:48.260 --> 02:16:50.620]   Moscow State University, I think it is.
[02:16:50.620 --> 02:16:55.260]   And they have an active center there that tries to bring people in.
[02:16:55.260 --> 02:17:02.180]   I think they're producing a book that's coming out that I made a small contribution to on
[02:17:02.180 --> 02:17:07.140]   different philosophers' opinions on God, I think, or some of the big questions.
[02:17:07.140 --> 02:17:10.820]   And yeah, so there's some really interesting stuff going on there.
[02:17:10.820 --> 02:17:15.380]   I'm afraid I don't really know more generally about philosophy in Russia.
[02:17:15.380 --> 02:17:18.700]   Dimitri Volkov seems to be interesting.
[02:17:18.700 --> 02:17:23.300]   I was looking at all the stuff he's involved with.
[02:17:23.300 --> 02:17:26.740]   He met with the Dalai Lama.
[02:17:26.740 --> 02:17:33.580]   So he's trying to connect Russian scientists with the rest of the world, which is an effort
[02:17:33.580 --> 02:17:37.800]   that I think is beautiful for all cultures.
[02:17:37.800 --> 02:17:51.340]   So I think science, philosophy, all of these kind of fields, disciplines that explore ideas,
[02:17:51.340 --> 02:17:56.300]   collaborating and working globally, you know, across boundaries, across borders, across
[02:17:56.300 --> 02:18:00.860]   just all the tensions of geopolitics is a beautiful thing.
[02:18:00.860 --> 02:18:05.940]   And he seems to be a somewhat singular figure in pushing this.
[02:18:05.940 --> 02:18:08.780]   He just stood out to me as somebody who's super interesting.
[02:18:08.780 --> 02:18:13.100]   I don't know if you have gotten a chance to interact with him.
[02:18:13.100 --> 02:18:18.080]   So he's definitely, I guess he speaks English pretty well, actually.
[02:18:18.080 --> 02:18:20.340]   So he's both an English speaker and a Russian speaker.
[02:18:20.340 --> 02:18:24.020]   I think he's written a book on Dennett, I think called Boston Zombie, I think.
[02:18:24.020 --> 02:18:25.020]   I think that's the title.
[02:18:25.020 --> 02:18:26.500]   And yeah, he's a big fan of Dennett.
[02:18:26.500 --> 02:18:30.660]   So I think the original plan for this was just going to be, it was on free will and
[02:18:30.660 --> 02:18:35.460]   consciousness and it was going to be kind of people broadly in the Dennett type camp.
[02:18:35.460 --> 02:18:39.620]   But then I think they asked David Chalmers and then he was saying, look, you need some
[02:18:39.620 --> 02:18:40.940]   people you disagree with.
[02:18:40.940 --> 02:18:49.140]   So he got invited, me, the panpsychist, and Martina Niederummelin, who's a very good dualist,
[02:18:49.140 --> 02:18:54.580]   substance dualist at University of Fribourg in Switzerland.
[02:18:54.580 --> 02:18:57.540]   So we were the official on board opposition.
[02:18:57.540 --> 02:18:59.700]   And it was really fun.
[02:18:59.700 --> 02:19:02.020]   And you didn't get thrown overboard.
[02:19:02.020 --> 02:19:04.020]   Nearly, in the Arctic, yeah.
[02:19:04.020 --> 02:19:05.780]   So sailing around the Arctic on a sailing ship.
[02:19:05.780 --> 02:19:07.460]   I'm glad you survived.
[02:19:07.460 --> 02:19:09.260]   You mentioned free will.
[02:19:09.260 --> 02:19:10.980]   You haven't talked to Sam.
[02:19:10.980 --> 02:19:13.060]   I would love to hear that conversation, actually.
[02:19:13.060 --> 02:19:14.940]   With Sam Harris?
[02:19:14.940 --> 02:19:17.940]   With Sam Harris, yeah.
[02:19:17.940 --> 02:19:19.580]   So he talks about free will quite a bit.
[02:19:19.580 --> 02:19:22.740]   What's the connection between free will and consciousness to you?
[02:19:22.740 --> 02:19:34.140]   So if consciousness permeates all matter, the experience, the feeling like we make a
[02:19:34.140 --> 02:19:41.020]   choice in this world, like our actions are results of a choice we consciously make, to
[02:19:41.020 --> 02:19:44.380]   use that word loosely.
[02:19:44.380 --> 02:19:50.260]   What to you is the connection between free will and consciousness, and is free will an
[02:19:50.260 --> 02:19:53.220]   illusion or not?
[02:19:53.220 --> 02:19:54.220]   Good question.
[02:19:54.220 --> 02:20:02.020]   So I think we need to be a lot more agnostic about free will than about consciousness,
[02:20:02.020 --> 02:20:07.940]   because I don't think we have the kind of certainty of the existence of free will that
[02:20:07.940 --> 02:20:09.180]   we do have in the consciousness case.
[02:20:09.180 --> 02:20:12.100]   It could turn out that free will is an illusion.
[02:20:12.100 --> 02:20:14.660]   It feels as though we're free when we're really not.
[02:20:14.660 --> 02:20:20.660]   Whereas, I mean, I think the idea that nobody really feels pain, that we think we feel pain,
[02:20:20.660 --> 02:20:23.780]   but that's a lot harder to make sense of.
[02:20:23.780 --> 02:20:31.180]   However, what I do feel strongly about is I don't think there are any good either scientific
[02:20:31.180 --> 02:20:35.780]   or philosophical arguments against the existence of free will.
[02:20:35.780 --> 02:20:40.820]   And I mean strong free will in what philosophers call libertarian free will in the sense that
[02:20:40.820 --> 02:20:43.540]   some of our decisions are uncaused.
[02:20:43.540 --> 02:20:48.180]   So I very much do disagree with someone like Sam Harris who thinks there's this overwhelming
[02:20:48.180 --> 02:20:49.180]   case.
[02:20:49.180 --> 02:20:50.900]   I just think it's non-existent.
[02:20:50.900 --> 02:20:57.420]   I think it's ultimately an empirical question, but as we've already discussed, I just don't
[02:20:57.420 --> 02:21:06.100]   think we know enough about the brain to establish one way or the other at the moment.
[02:21:06.100 --> 02:21:07.100]   We can build up intuitions.
[02:21:07.100 --> 02:21:11.740]   First of all, as a fan of Sam Harris, as a fan of yours, I would love to just listen.
[02:21:11.740 --> 02:21:12.740]   Yeah.
[02:21:12.740 --> 02:21:15.940]   Speaking about terminology, so one thing it would be beautiful to watch.
[02:21:15.940 --> 02:21:18.260]   Here's my prediction what happens with you and Sam Harris.
[02:21:18.260 --> 02:21:24.820]   You talk for four hours and Sam introduced that episode by saying, "It was ultimately
[02:21:24.820 --> 02:21:28.020]   not as fruitful as I thought because here's what's going to happen.
[02:21:28.020 --> 02:21:33.260]   You guys are going to get stuck for the first three hours talking about one of the terms
[02:21:33.260 --> 02:21:34.260]   and what they mean."
[02:21:34.260 --> 02:21:36.740]   Sam is so good at this.
[02:21:36.740 --> 02:21:39.540]   I think it's really important, but sometimes he gets stuck.
[02:21:39.540 --> 02:21:41.300]   What does he say?
[02:21:41.300 --> 02:21:42.860]   Put a pin in that.
[02:21:42.860 --> 02:21:49.820]   He really gets stuck on the terminologies, which rightfully you have to get right in
[02:21:49.820 --> 02:21:53.140]   order to really understand what we're talking about, but sometimes you can get stuck with
[02:21:53.140 --> 02:21:54.780]   him for the entire conversation.
[02:21:54.780 --> 02:21:58.420]   It's a fascinating dance, the one we spoke to in philosophy.
[02:21:58.420 --> 02:22:07.860]   If you don't get the terms precise, you can't really be having the same conversation, but
[02:22:07.860 --> 02:22:13.700]   at the same time, it could be argued that it's impossible to get terms perfectly precise
[02:22:13.700 --> 02:22:20.980]   and perfectly formalized, so then you're also not going to get anywhere in the conversation.
[02:22:20.980 --> 02:22:25.020]   That's a funny dance where you have to be both rigorous and every once in a while just
[02:22:25.020 --> 02:22:30.700]   let go and then go back to being rigorous and formal and then every once in a while
[02:22:30.700 --> 02:22:31.700]   let go.
[02:22:31.700 --> 02:22:37.180]   It's the difference between mathematics, the maths, and the poetry.
[02:22:37.180 --> 02:22:38.180]   Anyway.
[02:22:38.180 --> 02:22:41.860]   Yeah, I'm a big fan of Sam Harrison.
[02:22:41.860 --> 02:22:47.900]   I think we're on the same page in terms of consciousness, I think, pretty much.
[02:22:47.900 --> 02:22:53.700]   I mean, I'm not saying he's a panpsychic, but in our understanding of the hard problem.
[02:22:53.700 --> 02:22:58.620]   But yeah, I think maybe we could talk about free will without being too dragged down in
[02:22:58.620 --> 02:22:59.980]   the terminology, but I don't know.
[02:22:59.980 --> 02:23:05.820]   You said we need to be open-minded, but you could still have intuitions about...
[02:23:05.820 --> 02:23:14.780]   So Sam Harris is a pretty sort of counterintuitive, and for some reason it gets people really
[02:23:14.780 --> 02:23:24.220]   riled up, a view of free will that it's an illusion, or it's not even an illusion.
[02:23:24.220 --> 02:23:28.740]   It's not that the experience of free will is an illusion.
[02:23:28.740 --> 02:23:35.300]   He argues that we don't even experience...
[02:23:35.300 --> 02:23:40.100]   To say that we even have the experience is incorrect, that there's not even an experience
[02:23:40.100 --> 02:23:42.780]   of free will.
[02:23:42.780 --> 02:23:48.260]   It's pretty interesting, that claim, and it feels like you can build up intuitions about
[02:23:48.260 --> 02:23:51.100]   what is right and not.
[02:23:51.100 --> 02:23:56.100]   There's been some kind of neuroscience, there's been some cognitive science and psychology
[02:23:56.100 --> 02:24:06.900]   experiments to sort of see what is the timing and the origin of the desire to make an action,
[02:24:06.900 --> 02:24:11.020]   and when that action is actually performed, and how you interpret that action being performed,
[02:24:11.020 --> 02:24:16.340]   how you remember that action, all the stories we tell ourselves, all the neurochemicals
[02:24:16.340 --> 02:24:21.940]   involved in making a thing happen, what's the timing, and how does that connect with
[02:24:21.940 --> 02:24:24.500]   us feeling like we decided to do something?
[02:24:24.500 --> 02:24:32.220]   And then of course there's the more philosophical discussion about is there room in a material
[02:24:32.220 --> 02:24:40.300]   view of the world for an entity that somehow disturbs the determinism of physics?
[02:24:40.300 --> 02:24:41.300]   Yeah.
[02:24:41.300 --> 02:24:44.100]   And yeah, those are all very precise.
[02:24:44.100 --> 02:24:45.100]   It's nice.
[02:24:45.100 --> 02:24:51.100]   It feels like free will is more amenable to a physics mechanistic type of thinking than
[02:24:51.100 --> 02:24:54.940]   is consciousness, to really get to the bottom of.
[02:24:54.940 --> 02:25:00.020]   It feels like if it was a race, if we're at a bar and we're betting money, it feels like
[02:25:00.020 --> 02:25:04.300]   we'll get to the bottom of free will faster than we will to the bottom of consciousness.
[02:25:04.300 --> 02:25:05.300]   Yeah, that's interesting.
[02:25:05.300 --> 02:25:07.180]   Yeah, I hadn't thought about the comparison.
[02:25:07.180 --> 02:25:08.700]   Yeah, so there are different arguments here.
[02:25:08.700 --> 02:25:16.060]   I mean, so one argument I've heard Sam Harris give that's pretty common in philosophy is
[02:25:16.060 --> 02:25:24.100]   this sort of thought that we can't make sense of a middle way between a choice being determined
[02:25:24.100 --> 02:25:31.180]   by prior causes and it just being totally random and senseless, like the random decay
[02:25:31.180 --> 02:25:34.520]   of radioactive isotope or something.
[02:25:34.520 --> 02:25:39.940]   So I think there was a good answer to that by the philosopher Jonathan Lowe, who's not
[02:25:39.940 --> 02:25:44.620]   necessarily very well known outside academic philosophy, but is a hugely influential figure.
[02:25:44.620 --> 02:25:46.620]   I think one of the best philosophers of recent times.
[02:25:46.620 --> 02:25:49.540]   He sadly died of cancer a few years ago.
[02:25:49.540 --> 02:25:53.420]   Actually spent almost all of his career at Durham University, which is where I am.
[02:25:53.420 --> 02:25:56.780]   So it was one reason it was a great honor to get a job there.
[02:25:56.780 --> 02:26:02.580]   But anyway, his answer to that was, what makes the difference between a free action and a
[02:26:02.580 --> 02:26:09.820]   totally senseless one, senseless random event, is that free choice involves responsiveness
[02:26:09.820 --> 02:26:12.220]   to reasons.
[02:26:12.220 --> 02:26:15.340]   So again, we were talking about this earlier.
[02:26:15.340 --> 02:26:21.100]   If I'm deciding whether to take a job in the US or to stay in the UK, I weigh up considerations,
[02:26:21.100 --> 02:26:26.820]   you know, different standard of life maybe, or being close to family or cultural difference.
[02:26:26.820 --> 02:26:32.020]   I weigh them up and I, you know, edge towards a decision.
[02:26:32.020 --> 02:26:37.380]   So I think that is sufficient to distinguish it.
[02:26:37.380 --> 02:26:41.620]   You know, we're hypothetically supposing, trying to make sense of this idea, not saying
[02:26:41.620 --> 02:26:46.640]   it's real, but that could be enough to distinguish it from a senseless.
[02:26:46.640 --> 02:26:51.900]   It's not a senseless random occurrence, because the free decision involved responsiveness
[02:26:51.900 --> 02:26:53.900]   to reasons.
[02:26:53.900 --> 02:26:57.380]   So I think that just answers that particular philosophical objection.
[02:26:57.380 --> 02:27:02.340]   So what is the middle way between determined by prior causes and totally random?
[02:27:02.340 --> 02:27:06.660]   Well, there's an action, a choice that's not determined by prior causes, but it's not just
[02:27:06.660 --> 02:27:12.900]   random because the decision essentially involved responsiveness to reasons.
[02:27:12.900 --> 02:27:13.900]   So that's the answer to that.
[02:27:13.900 --> 02:27:19.620]   And I think actually, that kind of thought also, I think you were hinting at the famous
[02:27:19.620 --> 02:27:26.940]   Libet experiments, where he got his subjects to perform some kind of random action of pressing
[02:27:26.940 --> 02:27:31.860]   a button and then note the time they decided to press it, quote unquote.
[02:27:31.860 --> 02:27:38.220]   And then he's scanning the brains and he claims to have found that about half a second before
[02:27:38.220 --> 02:27:44.620]   they consciously decided to press the button, the brain is getting ready to perform that
[02:27:44.620 --> 02:27:45.620]   action.
[02:27:45.620 --> 02:27:49.740]   So he claimed that about half a second before the person has consciously decided to press
[02:27:49.740 --> 02:27:56.180]   the button, the brain has already started the activity that's going to lead to the action.
[02:27:56.180 --> 02:28:01.780]   And then later people have claimed that there's a difference of maybe seven to 10 seconds.
[02:28:01.780 --> 02:28:05.460]   I mean, there are all sorts of issues with these experiments.
[02:28:05.460 --> 02:28:12.100]   But one is that, as far as I'm aware, all of the quote unquote choices they focused on
[02:28:12.100 --> 02:28:16.700]   are just these totally random, senseless actions, like just pressing a button for no reason.
[02:28:16.700 --> 02:28:22.420]   And I think the kind of free will we're interested in is free choice that involves responsiveness
[02:28:22.420 --> 02:28:25.900]   to reasons, weighing up considerations.
[02:28:25.900 --> 02:28:29.780]   And those kinds of free decisions might not happen at an identifiable instant.
[02:28:29.780 --> 02:28:34.500]   You might, when you're weighing it up, should I get married?
[02:28:34.500 --> 02:28:39.500]   You might edge slowly towards one side or the other.
[02:28:39.500 --> 02:28:44.220]   And so it could be that maybe the liberate, I think there are other problems with the
[02:28:44.220 --> 02:28:50.540]   liberate stuff, but maybe they show that we can't freely choose to do something totally
[02:28:50.540 --> 02:28:54.180]   senseless, whatever that would mean.
[02:28:54.180 --> 02:28:59.980]   But that doesn't show we can't freely, in this strong libertarian sense, respond to
[02:28:59.980 --> 02:29:03.900]   considerations of reason and value.
[02:29:03.900 --> 02:29:09.180]   To be fair, it would be difficult to see what kind of experiment we could set up to test
[02:29:09.180 --> 02:29:10.180]   that.
[02:29:10.180 --> 02:29:14.920]   But just because we can't yet set up that kind of experiment, we shouldn't pretend we
[02:29:14.920 --> 02:29:16.340]   know more than we do.
[02:29:16.340 --> 02:29:20.300]   So yeah, so for those reasons, I don't, and well, the third consideration you raise is
[02:29:20.300 --> 02:29:21.300]   different again.
[02:29:21.300 --> 02:29:26.660]   And that's the debate I have with Sean Carroll, would this conflict with physics?
[02:29:26.660 --> 02:29:31.340]   I just think we don't know enough about the brain to know whether there are causal dynamics
[02:29:31.340 --> 02:29:37.340]   in the brain that are not reducible to underlying chemistry and physics.
[02:29:37.340 --> 02:29:44.580]   And so then Sean Carroll says, well, that would mean our physics is wrong.
[02:29:44.580 --> 02:29:49.900]   So he focuses on the core theory, which is the name for standard model of particle physics
[02:29:49.900 --> 02:29:54.140]   plus the weak limit of general relativity.
[02:29:54.140 --> 02:30:01.260]   So we can't totally bring quantum mechanics and relativity together, but actually the
[02:30:01.260 --> 02:30:06.900]   circumstances in which we can't bring them together are just in situations of very high
[02:30:06.900 --> 02:30:07.900]   gravity.
[02:30:07.900 --> 02:30:10.940]   For example, when you're about to go into a black hole or something, actually in terrestrial
[02:30:10.940 --> 02:30:15.780]   circumstances we can bring them together in the core theory.
[02:30:15.780 --> 02:30:20.880]   And then Sean wants to say, well, we can be very confident that core theory is correct.
[02:30:20.880 --> 02:30:27.420]   And so if there were libertarian free will in the brain, the core theory would be wrong.
[02:30:27.420 --> 02:30:33.460]   And I mean, this is something I'm not sure about, and I'm still thinking about, and I'm
[02:30:33.460 --> 02:30:38.420]   learning from my discussion with Sean, but I'm still not totally clear why.
[02:30:38.420 --> 02:30:42.120]   It could be, suppose we did discover strong emergence in the brain, whether it's free
[02:30:42.120 --> 02:30:44.120]   will or something else.
[02:30:44.120 --> 02:30:49.380]   Perhaps what we would say is not that the core theory is wrong, but we'd say the core
[02:30:49.380 --> 02:30:59.100]   theory is correct in its own terms, namely capturing the causal capacities of particles
[02:30:59.100 --> 02:31:00.800]   and fields.
[02:31:00.800 --> 02:31:04.020]   But then it's a further assumption whether they're the only things that are running the
[02:31:04.020 --> 02:31:05.020]   show.
[02:31:05.020 --> 02:31:11.100]   Maybe there are also fundamental causal capacities associated with systems.
[02:31:11.100 --> 02:31:14.260]   And then if we discover this strong emergence, then when we work out what happens in the
[02:31:14.260 --> 02:31:19.420]   brain, we have to look to the core theory, the causal capacities of particles and fields,
[02:31:19.420 --> 02:31:23.780]   and we have to look to what we know about the strongly emergent causal capacities of
[02:31:23.780 --> 02:31:29.220]   systems and maybe they co-determine what happens in the system.
[02:31:29.220 --> 02:31:33.220]   So I don't know whether that makes sense or not, but I mean, the more important point,
[02:31:33.220 --> 02:31:36.300]   I mean, that's in a way a kind of branding point, how we brand this.
[02:31:36.300 --> 02:31:39.540]   The more important point is we just don't know enough about the workings of the brain
[02:31:39.540 --> 02:31:45.420]   to know whether there are strongly emergent causal dynamics.
[02:31:45.420 --> 02:31:50.500]   Whether or not that would mean we have to modify physics or maybe just we think physics
[02:31:50.500 --> 02:31:53.620]   is not the total story of what's running the show.
[02:31:53.620 --> 02:32:01.100]   But if it turned out empirically that everything's reducible to underlying physics and chemistry,
[02:32:01.100 --> 02:32:07.120]   sure, I would drop any commitment to libertarian free will in a heartbeat.
[02:32:07.120 --> 02:32:08.700]   It's an empirical question.
[02:32:08.700 --> 02:32:13.180]   Maybe that's why, as you say, in principle it's easier to get a grip on, but we're a
[02:32:13.180 --> 02:32:14.900]   million miles away from being at that stage.
[02:32:14.900 --> 02:32:16.740]   Well, I don't know if we're a million miles.
[02:32:16.740 --> 02:32:21.980]   I hope we're not, because one of the ways I think to get to it is by engineering systems.
[02:32:21.980 --> 02:32:27.860]   So my hope is to understand intelligence by building intelligent systems, to understand
[02:32:27.860 --> 02:32:34.580]   consciousness by building systems that, let's say the easy thing, which is not the easy
[02:32:34.580 --> 02:32:42.220]   thing, but the first thing, which is to try to create the illusion of consciousness.
[02:32:42.220 --> 02:32:45.700]   Through that process, I think you start to understand much more about consciousness,
[02:32:45.700 --> 02:32:46.700]   about intelligence.
[02:32:46.700 --> 02:32:48.220]   And then the same with free will.
[02:32:48.220 --> 02:32:54.500]   I think those are all tied very closely together, at least from our narrow human perspective.
[02:32:54.500 --> 02:32:59.380]   And we try to engineer systems that interact deeply with humans, that form friends with
[02:32:59.380 --> 02:33:05.500]   humans, that humans fall in love with, and they fall in love with humans.
[02:33:05.500 --> 02:33:13.380]   Then you start to have to try to deeply understand ourselves, to try to deeply understand what
[02:33:13.380 --> 02:33:17.140]   is intelligence in the human mind, what is consciousness, what is free will.
[02:33:17.140 --> 02:33:22.220]   And I think engineering is just another way to do philosophy.
[02:33:22.220 --> 02:33:27.660]   Yeah, no, I certainly think there's a role for that, and it would be an important consideration
[02:33:27.660 --> 02:33:40.860]   if we could seemingly replicate in an artificial way the ability to choose.
[02:33:40.860 --> 02:33:44.500]   That would be a consideration in thinking about these things.
[02:33:44.500 --> 02:33:48.340]   But there's still the question of whether that's how we do it.
[02:33:48.340 --> 02:33:55.140]   So even if we could replicate behavior in a certain way in an artificial system, until
[02:33:55.140 --> 02:33:59.380]   we understand the workings of our brains, it's not clear that's how we do it.
[02:33:59.380 --> 02:34:07.220]   And as I say, the kind of free will I'm interested in is where we respond to reasons, considerations
[02:34:07.220 --> 02:34:08.220]   of value.
[02:34:08.220 --> 02:34:18.540]   How would we tell whether a system was genuinely grasping and responding to facts about value,
[02:34:18.540 --> 02:34:27.620]   or whether they were just replicating, giving the impression of doing so?
[02:34:27.620 --> 02:34:29.620]   I don't know even how to think about that.
[02:34:29.620 --> 02:34:33.500]   On the process to building them, I think we'll get a lot of insights.
[02:34:33.500 --> 02:34:39.540]   And once they become conscious, what's going to happen is exactly the same thing is happening
[02:34:39.540 --> 02:34:49.300]   in chess now, which is once the chess engines far superseded the capabilities of humans,
[02:34:49.300 --> 02:34:52.620]   humans just kind of forgot about them, or they use them to help them out with the study
[02:34:52.620 --> 02:34:53.620]   and stuff.
[02:34:53.620 --> 02:34:57.820]   But we still, we say, "Okay, let the engines be, and then we humans will just play amongst
[02:34:57.820 --> 02:34:58.820]   each other."
[02:34:58.820 --> 02:34:59.820]   - Right.
[02:34:59.820 --> 02:35:05.820]   - So just like dolphins and hamsters are not so concerned about humans except for a source
[02:35:05.820 --> 02:35:09.420]   of food, they do their own thing.
[02:35:09.420 --> 02:35:14.660]   And let us humans launch rockets into space and all that kind of stuff, they don't care.
[02:35:14.660 --> 02:35:16.780]   I think we'll just focus on ourselves.
[02:35:16.780 --> 02:35:21.860]   But in the process of building intelligence systems, conscious systems, I think we'll
[02:35:21.860 --> 02:35:31.500]   get a deeper understanding of the role of consciousness in the human mind, and what
[02:35:31.500 --> 02:35:32.500]   are its origins.
[02:35:32.500 --> 02:35:34.460]   Is it the base layer of reality?
[02:35:34.460 --> 02:35:38.380]   Is it strongly emergent phenomena of the brain?
[02:35:38.380 --> 02:35:42.980]   Or just as you sort of brilliantly put here, it could be both.
[02:35:42.980 --> 02:35:43.980]   Like they're not mutually exclusive.
[02:35:43.980 --> 02:35:44.980]   - Yeah.
[02:35:44.980 --> 02:35:47.460]   Dealing with consciousness needs to be an interdisciplinary task.
[02:35:47.460 --> 02:35:57.900]   We need philosophers, neuroscientists, physicists, engineers replicating these things artificially,
[02:35:57.900 --> 02:36:01.380]   and all needs to be working in step.
[02:36:01.380 --> 02:36:03.220]   And I'm quite interested.
[02:36:03.220 --> 02:36:09.580]   I mean, more and more scientists get in touch with me actually, saying that was one of the
[02:36:09.580 --> 02:36:14.100]   great things about, I think, that's come from writing a popular book is not just getting
[02:36:14.100 --> 02:36:17.060]   the ideas out to a general audience, but getting the ideas out to scientists.
[02:36:17.060 --> 02:36:20.900]   And I've had scientists get in touch saying, "Now this in some way connects to my work."
[02:36:20.900 --> 02:36:25.940]   And I would like to kind of start to put together a network of, an interdisciplinary network
[02:36:25.940 --> 02:36:33.300]   of scientists and philosophers and engineers, perhaps, you know, interested in a panpsychist
[02:36:33.300 --> 02:36:34.300]   approach.
[02:36:34.300 --> 02:36:39.220]   And because I think so far panpsychism has just been sort of trying to justify its existence,
[02:36:39.220 --> 02:36:40.220]   and that's important.
[02:36:40.220 --> 02:36:44.880]   But I think once you just get on with an active research program, that's when people start
[02:36:44.880 --> 02:36:48.660]   taking it seriously, I think.
[02:36:48.660 --> 02:36:53.340]   - Do you think we're living in a simulation?
[02:36:53.340 --> 02:36:54.340]   - No.
[02:36:54.340 --> 02:36:56.700]   I think...
[02:36:56.700 --> 02:37:01.060]   - Is there some aspect of that thought experiment that's compelling to you within the framework
[02:37:01.060 --> 02:37:03.820]   of panpsychism?
[02:37:03.820 --> 02:37:08.060]   - It's an important and serious argument.
[02:37:08.060 --> 02:37:10.620]   And you know, it's not to be laughed away.
[02:37:10.620 --> 02:37:17.340]   I suppose one issue I have with it is, there's a crucial assumption there that consciousness
[02:37:17.340 --> 02:37:21.340]   is substrate independent, as the jargon goes, which means it's...
[02:37:21.340 --> 02:37:22.340]   What?
[02:37:22.340 --> 02:37:23.340]   - No, right.
[02:37:23.340 --> 02:37:24.580]   - Beautifully put, yeah.
[02:37:24.580 --> 02:37:26.500]   - It's software rather than hardware, right?
[02:37:26.500 --> 02:37:30.220]   It's depend on organization rather than the stuff.
[02:37:30.220 --> 02:37:33.540]   Whereas as a panpsychist, I think consciousness is the stuff of the brain.
[02:37:33.540 --> 02:37:35.460]   It's the stuff of matter.
[02:37:35.460 --> 02:37:40.660]   So I think just taking the organizational properties, the software in my brain and uploading
[02:37:40.660 --> 02:37:43.540]   them, you wouldn't get the stuff of my brain.
[02:37:43.540 --> 02:37:49.100]   So I'm actually worried if at some point in the future, we start uploading our minds and
[02:37:49.100 --> 02:37:51.620]   we think, "Oh my God, Granny's still there.
[02:37:51.620 --> 02:37:54.980]   I can email Granny after her body's rotted in the ground."
[02:37:54.980 --> 02:37:57.780]   And we all start uploading our brains.
[02:37:57.780 --> 02:37:59.780]   It could be we're just committing suicide.
[02:37:59.780 --> 02:38:03.700]   We're just getting rid of our consciousness.
[02:38:03.700 --> 02:38:10.060]   Because I think that wouldn't, for me, preserve the experience, just getting the software
[02:38:10.060 --> 02:38:11.060]   features.
[02:38:11.060 --> 02:38:13.460]   So that's a crucial...
[02:38:13.460 --> 02:38:17.500]   But anyway, that's a crucial premise of the simulation argument, because the idea in a
[02:38:17.500 --> 02:38:21.900]   simulated universe, I don't think you necessarily would have consciousness.
[02:38:21.900 --> 02:38:26.260]   - It's interesting that you, as a panpsychist, are attached.
[02:38:26.260 --> 02:38:35.580]   Because to me, panpsychism would encourage the thought that there's not a significant
[02:38:35.580 --> 02:38:38.460]   difference.
[02:38:38.460 --> 02:38:46.460]   At the very bottom, it's not substrate independent, but you can have consciousness in a human
[02:38:46.460 --> 02:38:49.420]   and then move it to something else.
[02:38:49.420 --> 02:38:50.920]   You can move it to the cloud.
[02:38:50.920 --> 02:38:52.880]   You can move it to the computer.
[02:38:52.880 --> 02:38:58.140]   It feels like that's much more possible if consciousness is the base layer.
[02:38:58.140 --> 02:39:01.640]   - Yes, you could certainly...
[02:39:01.640 --> 02:39:06.700]   It allows for the possibility of creating artificial consciousness, right?
[02:39:06.700 --> 02:39:11.340]   Because there's not souls, there aren't any kind of extra magical ingredients.
[02:39:11.340 --> 02:39:16.820]   So yeah, it definitely allows the possibility of artificial consciousness and maybe preserving
[02:39:16.820 --> 02:39:19.500]   my consciousness in some sort of artificial way.
[02:39:19.500 --> 02:39:28.440]   My only point, I suppose, is just replicating the computational or organizational features
[02:39:28.440 --> 02:39:32.460]   would not, for me, preserve consciousness.
[02:39:32.460 --> 02:39:34.580]   Some opponents of materialism disagree with me on that.
[02:39:34.580 --> 02:39:37.300]   I think David Chalmers is an opponent of materialist.
[02:39:37.300 --> 02:39:43.860]   He's a kind of dualist, but he thinks the way these psychophysical laws work, they hook
[02:39:43.860 --> 02:39:47.940]   onto the computational or organizational features of matter.
[02:39:47.940 --> 02:39:53.060]   So I think he thinks you could upload your consciousness.
[02:39:53.060 --> 02:39:55.260]   I tend to think not, so...
[02:39:55.260 --> 02:40:02.140]   - In that sense, we're not living in simulation, in the sort of specific computational view
[02:40:02.140 --> 02:40:05.860]   of things, and that substrate matters to you.
[02:40:05.860 --> 02:40:08.700]   - Yeah, I think so, yeah.
[02:40:08.700 --> 02:40:12.060]   - In that, you agree with Sean Carroll that physics matters.
[02:40:12.060 --> 02:40:20.340]   - Yeah, physics is our best way of capturing what the stuff of the world does.
[02:40:20.340 --> 02:40:24.900]   - But not the whatness, the being of the stuff.
[02:40:24.900 --> 02:40:25.900]   - Yeah, the isness.
[02:40:25.900 --> 02:40:26.900]   - The isness, thank you.
[02:40:26.900 --> 02:40:31.060]   - Russell Brand, I had a conversation with Russell Brand and he said, "Oh, you mean the
[02:40:31.060 --> 02:40:32.060]   isness?"
[02:40:32.060 --> 02:40:33.060]   I thought that was a good way of putting it.
[02:40:33.060 --> 02:40:34.060]   - The isness.
[02:40:34.060 --> 02:40:35.060]   - The isness of stuff.
[02:40:35.060 --> 02:40:37.820]   - The isness of stuff, Russell's great.
[02:40:37.820 --> 02:40:43.500]   The big ridiculous question, what do you think is the meaning of all of this?
[02:40:43.500 --> 02:40:50.140]   You write in your book that the entry for our "Reality in the Hitchhiker's Guide" might
[02:40:50.140 --> 02:40:57.940]   read, "A physical universe whose intrinsic nature is constituted of consciousness, worth
[02:40:57.940 --> 02:40:59.400]   a visit."
[02:40:59.400 --> 02:41:06.680]   So our whole conversation has been about the first part of that sentence, what about the
[02:41:06.680 --> 02:41:09.580]   second part, worth a visit?
[02:41:09.580 --> 02:41:12.040]   Why is this place worth a visit?
[02:41:12.040 --> 02:41:14.880]   Why does it have meaning?
[02:41:14.880 --> 02:41:17.520]   Why does it have value at all?
[02:41:17.520 --> 02:41:18.520]   Why?
[02:41:18.520 --> 02:41:22.560]   - These are big questions.
[02:41:22.560 --> 02:41:29.320]   I mean, firstly, I do think panpsychism is important to think about for considerations
[02:41:29.320 --> 02:41:32.160]   of meaning and value.
[02:41:32.160 --> 02:41:38.160]   As we've already discussed, I think consciousness is the root of everything that matters in
[02:41:38.160 --> 02:41:46.600]   life, you know, from deep emotions, subtle thoughts, beautiful sensory experiences.
[02:41:46.600 --> 02:41:53.080]   And yet, I believe our official scientific worldview is incompatible with the reality
[02:41:53.080 --> 02:41:54.080]   of consciousness.
[02:41:54.080 --> 02:41:57.240]   I mean, that's controversial, but that's what I think.
[02:41:57.240 --> 02:42:00.920]   And I think people feel this on an intuitive level.
[02:42:00.920 --> 02:42:04.840]   It's maybe part of what Max Weber called the disenchantment of nature, you know, that they
[02:42:04.840 --> 02:42:12.240]   think they know their feelings and experiences are not just electrochemical signaling.
[02:42:12.240 --> 02:42:16.120]   I mean, they might just have that very informed intuition, but I think that can be rigorously
[02:42:16.120 --> 02:42:17.120]   supported.
[02:42:17.120 --> 02:42:24.760]   So, I think this can lead to a sense of alienation and a sense that we lack a framework for understanding
[02:42:24.760 --> 02:42:27.000]   the meaning and significance of our lives.
[02:42:27.000 --> 02:42:31.200]   And in the absence of that, people turn to other things to make sense of the meaning
[02:42:31.200 --> 02:42:37.080]   of their lives, like nationalism, fundamentalist religion, consumerism.
[02:42:37.080 --> 02:42:42.560]   So I think panpsychism is important in that regard in bringing together the quantitative
[02:42:42.560 --> 02:42:48.400]   facts of physical science with, as it were, the human truth, by which I just mean the
[02:42:48.400 --> 02:42:53.160]   qualitative reality of our own experience.
[02:42:53.160 --> 02:43:01.280]   As I've already said, I do think there are objective facts about value and what we ought
[02:43:01.280 --> 02:43:04.820]   to do and what we ought to believe that we respond to.
[02:43:04.820 --> 02:43:08.640]   And that's very mysterious to make sense of, both how there could be such facts and how
[02:43:08.640 --> 02:43:15.320]   we could know about them and respond to them, but I do think there are such facts and they're
[02:43:15.320 --> 02:43:18.520]   mostly to do with kinds of conscious experience.
[02:43:18.520 --> 02:43:25.520]   So they're there to be discovered and much of the human condition is to discover those
[02:43:25.520 --> 02:43:27.840]   objective sources of value.
[02:43:27.840 --> 02:43:29.160]   I think so, yeah.
[02:43:29.160 --> 02:43:35.600]   And then, I mean, moving away from panpsychism to the, you know, at an even bigger level,
[02:43:35.600 --> 02:43:43.960]   I suppose I think it is important to me to live in hope that there's a purpose to existence
[02:43:43.960 --> 02:43:51.000]   and that what I do contributes in some small way to that greater purpose.
[02:43:51.000 --> 02:43:56.040]   But you know, I would say I don't know if there's a purpose to existence.
[02:43:56.040 --> 02:44:00.400]   I think some things point in that direction, some things point away from it.
[02:44:00.400 --> 02:44:07.880]   But I don't think you need certainty or even high probability to have faith in something.
[02:44:07.880 --> 02:44:13.640]   So take an analogy, suppose you've got a friend who's very seriously ill, maybe there's a
[02:44:13.640 --> 02:44:16.440]   30% chance they're going to make it.
[02:44:16.440 --> 02:44:20.280]   You shouldn't believe your friend's going to get better, you know, because they're probably
[02:44:20.280 --> 02:44:21.280]   not.
[02:44:21.280 --> 02:44:24.080]   But what you can say is, you know, you can say to your friend, I have faith that you're
[02:44:24.080 --> 02:44:25.120]   going to get better.
[02:44:25.120 --> 02:44:31.080]   That is, I choose to live in hope about that possibility.
[02:44:31.080 --> 02:44:34.560]   I choose to orientate my life towards that hope.
[02:44:34.560 --> 02:44:39.040]   Similarly, you know, I don't think we know whether or not there's a purpose to existence,
[02:44:39.040 --> 02:44:44.880]   but I think we can make the choice to live in hope of that possibility.
[02:44:44.880 --> 02:44:52.200]   And I find that a worthwhile and fulfilling way to live.
[02:44:52.200 --> 02:44:58.320]   - So maybe as your editor, I would collaborate with you on the edit of the Hitchhiker's Guide
[02:44:58.320 --> 02:45:08.280]   entry that instead of worth a visit, we'll insert hopefully worth a visit.
[02:45:08.280 --> 02:45:13.960]   Or the inhabitants hoped that you would think it's worth a visit.
[02:45:13.960 --> 02:45:20.760]   Philip, you're an incredible mind, an incredible human being, and indeed are humble.
[02:45:20.760 --> 02:45:26.680]   And I'm really happy that you're able to argue and take on some of these difficult questions
[02:45:26.680 --> 02:45:31.560]   with some of the most brilliant people in the world, which are the philosophers thinking
[02:45:31.560 --> 02:45:32.600]   about the human mind.
[02:45:32.600 --> 02:45:34.640]   So this was an awesome conversation.
[02:45:34.640 --> 02:45:37.680]   I hope you continue talking to folks like Sam Harris.
[02:45:37.680 --> 02:45:39.480]   I'm so glad you talked to Joe.
[02:45:39.480 --> 02:45:44.120]   I can't wait to see what you write, what you say, what you think next.
[02:45:44.120 --> 02:45:45.840]   Thank you so much for talking today.
[02:45:45.840 --> 02:45:46.840]   - Thanks very much, Lex.
[02:45:46.840 --> 02:45:49.080]   This has been a really fascinating conversation.
[02:45:49.080 --> 02:45:52.880]   I've got a lot I need to think about actually just from this conversation, but thanks for
[02:45:52.880 --> 02:45:54.600]   chatting to me.
[02:45:54.600 --> 02:45:57.080]   - Thanks for listening to this conversation with Philip Goff.
[02:45:57.080 --> 02:46:00.840]   To support this podcast, please check out our sponsors in the description.
[02:46:00.840 --> 02:46:04.880]   And now let me leave you with some words from Carl Jung.
[02:46:04.880 --> 02:46:11.680]   People will do anything, no matter how absurd, in order to avoid facing their own souls.
[02:46:11.680 --> 02:46:16.760]   One does not become enlightened by imagining figures of light, but by making the darkness
[02:46:16.760 --> 02:46:17.760]   conscious.
[02:46:17.760 --> 02:46:21.720]   Thank you for listening and hope to see you next time.
[02:46:21.720 --> 02:46:22.720]   Bye.
[02:46:22.720 --> 02:46:22.720]   - Bye.
[02:46:22.720 --> 02:46:23.720]   - Bye.
[02:46:23.720 --> 02:46:23.720]   - Bye.
[02:46:23.720 --> 02:46:28.720]   - Bye.
[02:46:28.720 --> 02:46:32.680]   [ Silence ]

