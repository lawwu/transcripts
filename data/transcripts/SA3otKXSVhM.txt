
[00:00:00.000 --> 00:00:02.000]   All right, I'm gonna get started again.
[00:00:02.000 --> 00:00:06.820]   So I wanna cover a few things today.
[00:00:06.820 --> 00:00:09.400]   First, just kind of quickly talk
[00:00:09.400 --> 00:00:12.560]   through the data management lecture and just,
[00:00:12.560 --> 00:00:13.780]   you know, the goal here is again,
[00:00:13.780 --> 00:00:16.280]   like you've already watched the lecture, hopefully.
[00:00:16.280 --> 00:00:19.840]   Yeah, okay, a lot of nodding, so that's good.
[00:00:19.840 --> 00:00:21.740]   So the idea is just to give you a really quick review
[00:00:21.740 --> 00:00:23.840]   and give you a chance to ask any questions
[00:00:23.840 --> 00:00:24.920]   that, you know, weren't asked
[00:00:24.920 --> 00:00:27.100]   in the lecture that we recorded.
[00:00:28.240 --> 00:00:30.860]   And then since we have a little bit of extra time today,
[00:00:30.860 --> 00:00:33.740]   because we lost one of our speakers,
[00:00:33.740 --> 00:00:37.360]   there's a fun project, a labeling challenge,
[00:00:37.360 --> 00:00:39.960]   and I'll tell you more about that when we get to it.
[00:00:39.960 --> 00:00:42.680]   And then we'll just talk quickly about, you know,
[00:00:42.680 --> 00:00:44.000]   what we're hoping that you get done
[00:00:44.000 --> 00:00:45.960]   on your projects for the next week.
[00:00:45.960 --> 00:00:48.560]   And then finally, we're hoping to have a few minutes left
[00:00:48.560 --> 00:00:51.060]   at the end to just, for everyone to meet with their teams,
[00:00:51.060 --> 00:00:52.360]   and if you're still looking for teammates
[00:00:52.360 --> 00:00:55.660]   to spend a little bit of time on finalizing that.
[00:00:56.660 --> 00:00:59.500]   (computer mouse clicking)
[00:00:59.500 --> 00:01:01.860]   Okay, so, you know, again,
[00:01:01.860 --> 00:01:03.760]   reviewing the data management lecture.
[00:01:03.760 --> 00:01:07.880]   I think Sergei motivated this really well.
[00:01:07.880 --> 00:01:11.420]   You know, if you're a machine learning engineer,
[00:01:11.420 --> 00:01:12.400]   then there's a really good chance
[00:01:12.400 --> 00:01:14.900]   that you prefer thinking about models
[00:01:14.900 --> 00:01:16.820]   than you do thinking about data,
[00:01:16.820 --> 00:01:18.380]   'cause it's like kind of natural, right?
[00:01:18.380 --> 00:01:19.620]   Like models are exciting.
[00:01:19.620 --> 00:01:23.740]   But, you know, it turns out in the real world
[00:01:25.060 --> 00:01:27.780]   that collecting data is super hard,
[00:01:27.780 --> 00:01:28.980]   and it can be really interesting,
[00:01:28.980 --> 00:01:30.960]   and it's actually more important than models.
[00:01:30.960 --> 00:01:34.700]   So I like this slide from Andrej Karpathy,
[00:01:34.700 --> 00:01:39.140]   the amount of sleep lost over models versus datasets.
[00:01:39.140 --> 00:01:41.740]   During the PhD, it's like all models, you know,
[00:01:41.740 --> 00:01:43.020]   all models all the time.
[00:01:43.020 --> 00:01:47.000]   And then at Tesla, it's like 75% data, right?
[00:01:47.000 --> 00:01:49.340]   So, you know, even one of the best people in the world
[00:01:49.340 --> 00:01:51.540]   at thinking about models is now spending all this time
[00:01:51.540 --> 00:01:53.940]   thinking about data because it's that important.
[00:01:53.940 --> 00:01:56.700]   (mouse clicking)
[00:01:56.700 --> 00:02:00.660]   And so, you know, why is it so important?
[00:02:00.660 --> 00:02:03.160]   Well, most deep learning applications
[00:02:03.160 --> 00:02:05.780]   just require tons of labeled data.
[00:02:05.780 --> 00:02:08.960]   And there are some branches of deep learning
[00:02:08.960 --> 00:02:11.420]   like reinforcement learning or generative adversarial nets
[00:02:11.420 --> 00:02:13.580]   that don't require lots of labeled data,
[00:02:13.580 --> 00:02:15.100]   but they're not really in the realm
[00:02:15.100 --> 00:02:18.700]   of practical real world machine learning yet.
[00:02:18.700 --> 00:02:22.880]   So you can also use, you know, publicly available datasets
[00:02:22.880 --> 00:02:24.720]   where you can get a bunch of labeled data for free,
[00:02:24.720 --> 00:02:26.860]   but the problem there is if you're only training
[00:02:26.860 --> 00:02:28.380]   on publicly labeled datasets,
[00:02:28.380 --> 00:02:30.320]   and we talked a little bit about this last time,
[00:02:30.320 --> 00:02:32.780]   it's hard to really have a competitive advantage
[00:02:32.780 --> 00:02:35.480]   because everyone is kind of mining these for insights.
[00:02:35.480 --> 00:02:38.700]   They can be a good starting point though.
[00:02:38.700 --> 00:02:41.100]   And so in the lecture, Sergey talked about a few things,
[00:02:41.100 --> 00:02:43.620]   talked about data labeling, data storage.
[00:02:43.620 --> 00:02:45.740]   So where do your images go?
[00:02:45.740 --> 00:02:47.140]   Where does your metadata go?
[00:02:47.140 --> 00:02:51.380]   Data versioning, so how to make sure that you
[00:02:51.380 --> 00:02:53.300]   are keeping track of which version of your dataset
[00:02:53.300 --> 00:02:55.640]   that you're using to train your model at any given time
[00:02:55.640 --> 00:02:56.940]   so you can always go back.
[00:02:56.940 --> 00:03:00.000]   And then data workflow.
[00:03:00.000 --> 00:03:03.820]   So like how do you put this together on a day-to-day basis
[00:03:03.820 --> 00:03:06.200]   and create a workflow that allows you
[00:03:06.200 --> 00:03:09.080]   to build new datasets rapidly and repeatably.
[00:03:09.080 --> 00:03:16.400]   I think the conclusions that Sergey made on data labeling
[00:03:16.400 --> 00:03:18.920]   were just, you know, there's a bunch of different ways
[00:03:18.920 --> 00:03:19.760]   that you can do labeling.
[00:03:19.760 --> 00:03:20.620]   You can do it in-house.
[00:03:20.620 --> 00:03:24.640]   You can outsource it or, you know, something else.
[00:03:24.640 --> 00:03:27.520]   But the conclusion was that if you can,
[00:03:27.520 --> 00:03:28.360]   you should outsource it
[00:03:28.360 --> 00:03:30.320]   because this is sort of a difficult process
[00:03:30.320 --> 00:03:32.880]   and it makes sense to have a specialist do it.
[00:03:32.880 --> 00:03:35.840]   And if you can't outsource it for whatever reason,
[00:03:35.840 --> 00:03:37.000]   it's too expensive,
[00:03:37.000 --> 00:03:39.360]   then at least use some off-the-shelf software.
[00:03:39.360 --> 00:03:42.280]   And if you're gonna do that,
[00:03:42.280 --> 00:03:44.920]   then it makes more sense to hire people part-time
[00:03:44.920 --> 00:03:48.080]   rather than trying to, or sorry.
[00:03:48.080 --> 00:03:50.400]   So like rather than trying to go do things manually
[00:03:50.400 --> 00:03:51.900]   on Amazon Turk yourself,
[00:03:51.900 --> 00:03:53.680]   it might make sense to just hire people part-time
[00:03:53.680 --> 00:03:55.920]   so that you can train them and have the same people
[00:03:55.920 --> 00:03:58.800]   that are doing your task over and over again.
[00:03:58.800 --> 00:04:02.460]   Were there any questions on what Sergey covered
[00:04:02.460 --> 00:04:03.300]   on data labeling?
[00:04:03.300 --> 00:04:09.580]   Data versioning?
[00:04:09.580 --> 00:04:12.100]   I'll talk about that in a second, yeah.
[00:04:12.100 --> 00:04:13.340]   Okay.
[00:04:13.340 --> 00:04:17.420]   - So for some of these from the perspective of like managing,
[00:04:18.300 --> 00:04:22.280]   you know, like managing a big project
[00:04:22.280 --> 00:04:26.560]   or even for like, how does it translate to a small project
[00:04:26.560 --> 00:04:28.160]   like something we will be doing?
[00:04:28.160 --> 00:04:29.000]   - Yeah.
[00:04:29.000 --> 00:04:31.920]   - Like what, which of those points do you think
[00:04:31.920 --> 00:04:33.920]   are the most important?
[00:04:33.920 --> 00:04:35.920]   - How many of you are planning to collect some data
[00:04:35.920 --> 00:04:36.820]   for your projects?
[00:04:36.820 --> 00:04:41.640]   Okay, so more than half, right?
[00:04:41.640 --> 00:04:43.360]   So I'd say all of this still applies.
[00:04:43.360 --> 00:04:44.920]   It's, I think if you're running
[00:04:44.920 --> 00:04:46.240]   a really big machine learning project
[00:04:46.240 --> 00:04:48.000]   like a self-driving car team,
[00:04:48.000 --> 00:04:50.280]   then I think the percentage of time
[00:04:50.280 --> 00:04:51.420]   that you spend thinking about this,
[00:04:51.420 --> 00:04:53.700]   like goes up and up and up.
[00:04:53.700 --> 00:04:55.380]   If you're, you know, if you're just doing a,
[00:04:55.380 --> 00:04:56.640]   like a six week side project,
[00:04:56.640 --> 00:04:59.840]   then, you know, hopefully you won't need to spend more than,
[00:04:59.840 --> 00:05:01.080]   you know, a third or half of your time
[00:05:01.080 --> 00:05:02.960]   really thinking about data
[00:05:02.960 --> 00:05:05.240]   because you're just trying to make a proof of concept.
[00:05:05.240 --> 00:05:07.360]   But I think it's still important to think about.
[00:05:07.360 --> 00:05:10.360]   Yeah.
[00:05:10.360 --> 00:05:11.600]   - So for a bigger team,
[00:05:11.600 --> 00:05:15.000]   do you think, will there be specialist teams
[00:05:15.000 --> 00:05:18.440]   which were just doing the data management kind of roles
[00:05:18.440 --> 00:05:20.400]   or do you see the machine learning
[00:05:20.400 --> 00:05:23.160]   or AI engineer also doing all of these?
[00:05:23.160 --> 00:05:24.360]   - Yeah.
[00:05:24.360 --> 00:05:27.460]   So at some point it makes sense to split the roles.
[00:05:27.460 --> 00:05:28.760]   I think in a small organization,
[00:05:28.760 --> 00:05:31.760]   a lot of times you see people who are like data scientists
[00:05:31.760 --> 00:05:32.900]   or even machine learning engineers
[00:05:32.900 --> 00:05:35.080]   that do all of the data management,
[00:05:35.080 --> 00:05:38.200]   all of the data munging and all of the training
[00:05:38.200 --> 00:05:39.160]   because they're just, you know,
[00:05:39.160 --> 00:05:40.280]   only a few people working on it.
[00:05:40.280 --> 00:05:41.920]   And so you need to do everything.
[00:05:42.800 --> 00:05:45.520]   A model that a lot of startups that I've talked to like
[00:05:45.520 --> 00:05:47.560]   is to have, you know, at some point when the team
[00:05:47.560 --> 00:05:50.000]   gets big enough to have a separate data engineer,
[00:05:50.000 --> 00:05:52.320]   but to have that person sit on the machine learning team.
[00:05:52.320 --> 00:05:53.840]   So not have it actually be a separate team,
[00:05:53.840 --> 00:05:56.360]   but just have it be a separate person
[00:05:56.360 --> 00:05:58.880]   who works directly with the machine learning team
[00:05:58.880 --> 00:06:00.800]   so that they're like in all of the conversations
[00:06:00.800 --> 00:06:04.040]   around what is needed from the model building process.
[00:06:04.040 --> 00:06:07.160]   Bigger organizations, I mean, at some point,
[00:06:07.160 --> 00:06:10.360]   it seems like most companies split off data engineering
[00:06:10.360 --> 00:06:11.400]   into its own function.
[00:06:12.400 --> 00:06:15.760]   - Yeah, I've seen, I've interviewed with a company
[00:06:15.760 --> 00:06:17.920]   that has found two teams.
[00:06:17.920 --> 00:06:20.680]   - Yeah, yeah, and then labeling teams are,
[00:06:20.680 --> 00:06:22.440]   that's an entirely separate topic.
[00:06:22.440 --> 00:06:25.160]   And yeah, some companies just have, you know,
[00:06:25.160 --> 00:06:27.840]   many, many people that are, you know,
[00:06:27.840 --> 00:06:28.960]   essentially full-time employees
[00:06:28.960 --> 00:06:30.600]   that are working on labeling data.
[00:06:30.600 --> 00:06:33.480]   - So for a small project like,
[00:06:33.480 --> 00:06:36.920]   where like how would you structure your efforts?
[00:06:36.920 --> 00:06:41.160]   Like which things are easier to get at?
[00:06:41.160 --> 00:06:43.600]   Or which should be done first?
[00:06:43.600 --> 00:06:47.600]   - Yeah, I would definitely start with data,
[00:06:47.600 --> 00:06:52.040]   particularly if you want to collect your own dataset, right?
[00:06:52.040 --> 00:06:54.680]   If you're gonna, and we are starting with data this week.
[00:06:54.680 --> 00:06:57.920]   So if you're gonna be able to use entirely
[00:06:57.920 --> 00:06:59.760]   or mostly off the shelf data,
[00:06:59.760 --> 00:07:01.480]   then, you know, I wouldn't spend too much time
[00:07:01.480 --> 00:07:02.400]   thinking about it upfront.
[00:07:02.400 --> 00:07:05.080]   I would just go and create an initial version
[00:07:05.080 --> 00:07:07.200]   of the dataset and start working with it.
[00:07:07.200 --> 00:07:08.680]   But if you need to collect a dataset,
[00:07:08.680 --> 00:07:12.240]   then the usual advice of like starting small
[00:07:12.240 --> 00:07:14.400]   and getting everything working end to end first,
[00:07:14.400 --> 00:07:15.480]   there's a big caveat to that,
[00:07:15.480 --> 00:07:18.760]   which is that labeling a big dataset
[00:07:18.760 --> 00:07:19.760]   takes a lot of lead time
[00:07:19.760 --> 00:07:21.440]   because they're usually have to do
[00:07:21.440 --> 00:07:23.000]   a bunch of different iterations.
[00:07:23.000 --> 00:07:25.280]   So it's something to start thinking about early.
[00:07:25.280 --> 00:07:33.400]   All right, I wanna cover a couple of advanced topics
[00:07:33.400 --> 00:07:35.920]   in data labeling that were not in the lecture.
[00:07:38.200 --> 00:07:42.840]   So data labeling, you know, as we've seen
[00:07:42.840 --> 00:07:47.520]   is a really active and exciting research area.
[00:07:47.520 --> 00:07:49.280]   And there are a few directions
[00:07:49.280 --> 00:07:50.760]   that I think are really promising.
[00:07:50.760 --> 00:07:52.440]   Some are around how do you make
[00:07:52.440 --> 00:07:54.700]   the labeling process itself more efficient?
[00:07:54.700 --> 00:07:58.520]   You know, one idea there is weak supervision like Snorkel,
[00:07:58.520 --> 00:08:00.120]   which we just heard a lot about.
[00:08:00.120 --> 00:08:03.600]   There's another from Jeremy Howard.
[00:08:03.600 --> 00:08:05.920]   It's now a company called Platform.AI.
[00:08:05.920 --> 00:08:07.480]   How many people have seen this?
[00:08:08.480 --> 00:08:09.960]   Like, okay, great.
[00:08:09.960 --> 00:08:12.540]   I'm gonna show you a video of Jeremy Howard
[00:08:12.540 --> 00:08:13.540]   talking about this.
[00:08:13.540 --> 00:08:19.980]   (indistinct)
[00:08:19.980 --> 00:08:24.040]   - So here we're starting with about
[00:08:24.040 --> 00:08:25.840]   one and a half million car images.
[00:08:25.840 --> 00:08:27.800]   And I wanna create something that can split them
[00:08:27.800 --> 00:08:31.120]   into the angle of the photo that's being taken.
[00:08:31.120 --> 00:08:33.240]   So these images are entirely unlabeled.
[00:08:33.240 --> 00:08:35.400]   So I have to start from scratch.
[00:08:35.400 --> 00:08:36.720]   Without the learning algorithm,
[00:08:36.720 --> 00:08:39.240]   you can automatically identify areas of structure
[00:08:39.240 --> 00:08:40.480]   in these images.
[00:08:40.480 --> 00:08:42.320]   So the nice thing is that the human
[00:08:42.320 --> 00:08:44.160]   and the computer can now work together.
[00:08:44.160 --> 00:08:46.280]   So the human, as you can see here,
[00:08:46.280 --> 00:08:49.220]   is telling the computer about areas of interest,
[00:08:49.220 --> 00:08:52.320]   which it wants the computer then to try and use
[00:08:52.320 --> 00:08:54.320]   to improve its algorithm.
[00:08:54.320 --> 00:08:55.640]   Now, these deep learning systems
[00:08:55.640 --> 00:08:57.960]   actually are in 16,000 dimensional space.
[00:08:57.960 --> 00:09:00.440]   So you can see here the computer rotating this
[00:09:00.440 --> 00:09:03.520]   through that space, trying to find new areas of structure.
[00:09:03.520 --> 00:09:05.300]   And when it does so successfully,
[00:09:05.300 --> 00:09:07.760]   the human who's driving it can then point out
[00:09:07.760 --> 00:09:09.200]   the areas that are interesting.
[00:09:09.200 --> 00:09:11.480]   So here the computer has successfully found areas
[00:09:11.480 --> 00:09:14.360]   of, for example, angles.
[00:09:14.360 --> 00:09:15.840]   So as we go through this process,
[00:09:15.840 --> 00:09:17.920]   we're gradually telling the computer more and more
[00:09:17.920 --> 00:09:20.440]   about the kinds of structures we're looking for.
[00:09:20.440 --> 00:09:22.000]   You can imagine in a diagnostic test,
[00:09:22.000 --> 00:09:24.960]   this would be a pathologist identifying areas of photosis,
[00:09:24.960 --> 00:09:28.240]   for example, or a radiologist indicating
[00:09:28.240 --> 00:09:30.800]   potentially troublesome nodules.
[00:09:30.800 --> 00:09:33.400]   And sometimes it can be difficult for the algorithm.
[00:09:33.400 --> 00:09:35.120]   In this case, it's got kind of confused.
[00:09:35.120 --> 00:09:37.620]   The fronts and the backs of the cards are all mixed up.
[00:09:37.620 --> 00:09:39.760]   So here we have to be a bit more careful,
[00:09:39.760 --> 00:09:43.000]   manually selecting these fronts as opposed to the backs,
[00:09:43.000 --> 00:09:45.500]   and then telling the computer that this
[00:09:45.500 --> 00:09:50.100]   is a type of group that we're interested in.
[00:09:50.100 --> 00:09:51.180]   So we do that for a while.
[00:09:51.180 --> 00:09:52.300]   We skip over a little bit.
[00:09:52.300 --> 00:09:54.740]   And then we train a machine learning algorithm
[00:09:54.740 --> 00:09:56.700]   based on these couple of hundred things.
[00:09:56.700 --> 00:09:58.380]   And we hope that it's gone a lot better.
[00:09:58.380 --> 00:10:00.840]   You can see it's now started to fade some of these pictures
[00:10:00.840 --> 00:10:03.620]   out, showing us that it already is recognizing
[00:10:03.620 --> 00:10:06.540]   how to understand some of these itself.
[00:10:06.540 --> 00:10:09.580]   We can then use this concept of similar images.
[00:10:09.580 --> 00:10:11.220]   And using similar images, you can now
[00:10:11.220 --> 00:10:13.940]   see the computer at this point is able to entirely find just
[00:10:13.940 --> 00:10:15.740]   the fronts of cards.
[00:10:15.740 --> 00:10:19.140]   And so at this point, the human can tell the computer, OK, yes,
[00:10:19.140 --> 00:10:22.300]   you've done a good job of that.
[00:10:22.300 --> 00:10:24.140]   Sometimes, of course, even at this point,
[00:10:24.140 --> 00:10:27.900]   it's still difficult to separate out groups.
[00:10:27.900 --> 00:10:30.740]   In this case, even after we let the computer try
[00:10:30.740 --> 00:10:32.620]   and retake this for a while, we still
[00:10:32.620 --> 00:10:34.900]   find that the left sides and the right sides' pictures
[00:10:34.900 --> 00:10:36.580]   are all mixed up together.
[00:10:36.580 --> 00:10:38.500]   So we can again give the computer some hints.
[00:10:38.500 --> 00:10:40.580]   And we say, OK, try and find a projection that
[00:10:40.580 --> 00:10:43.020]   separates out the left sides and the right sides
[00:10:43.020 --> 00:10:46.380]   as much as possible using this deep learning algorithm.
[00:10:46.380 --> 00:10:49.260]   And giving it that hint, ah, OK, it's been successful.
[00:10:49.260 --> 00:10:51.900]   It's managed to find a way of thinking about these objects
[00:10:51.900 --> 00:10:54.340]   and separate about these together.
[00:10:54.340 --> 00:10:58.180]   So you get the idea here.
[00:10:58.180 --> 00:11:00.380]   This is a case not where the computer is
[00:11:00.380 --> 00:11:02.100]   being replaced by a machine.
[00:11:02.100 --> 00:11:05.580]   Sorry, the human is being replaced by a computer,
[00:11:05.580 --> 00:11:07.780]   but where they're working together.
[00:11:07.780 --> 00:11:09.940]   What we're doing here is we're replacing something
[00:11:09.940 --> 00:11:13.340]   that used to take a team of five or six people about seven years
[00:11:13.340 --> 00:11:14.900]   and replacing it with something that
[00:11:14.900 --> 00:11:18.740]   takes 15 minutes for one person acting alone.
[00:11:18.740 --> 00:11:22.300]   So this process takes about four or five iterations.
[00:11:22.300 --> 00:11:25.660]   You can see we now have 62% of our 1.5 billion images
[00:11:25.660 --> 00:11:27.100]   classified correctly.
[00:11:27.100 --> 00:11:29.820]   And at this point, we can start to quite quickly grab
[00:11:29.820 --> 00:11:32.060]   whole big sections, check through them
[00:11:32.060 --> 00:11:33.700]   to make sure that there's no mistakes.
[00:11:33.700 --> 00:11:35.200]   When there are mistakes, we can let
[00:11:35.200 --> 00:11:37.980]   the computer know about them.
[00:11:37.980 --> 00:11:40.300]   And using this kind of process, we now
[00:11:40.300 --> 00:11:43.740]   have an 80% success rate in classifying the 1.5 million
[00:11:43.740 --> 00:11:45.540]   images.
[00:11:45.540 --> 00:11:49.860]   At this point, it's just a case of finding the small number
[00:11:49.860 --> 00:11:54.620]   that aren't classified correctly and trying to understand why.
[00:11:54.620 --> 00:11:56.980]   And choosing that approach, by 15 minutes,
[00:11:56.980 --> 00:11:59.340]   we get to 97% classification.
[00:11:59.340 --> 00:12:02.260]   All right, so that's another kind of approach
[00:12:02.260 --> 00:12:06.460]   to this problem of how can we reduce the manual effort
[00:12:06.460 --> 00:12:08.820]   that it takes to label a big data set that I really like.
[00:12:08.820 --> 00:12:10.280]   And the reason I like it so much is
[00:12:10.280 --> 00:12:13.540]   because I think it's just a clever way of combining
[00:12:13.540 --> 00:12:15.540]   sort of what we do naturally when we're training
[00:12:15.540 --> 00:12:18.940]   deep learning models, which is kind of try to look at examples
[00:12:18.940 --> 00:12:21.620]   and build intuition about why the model is not
[00:12:21.620 --> 00:12:23.780]   doing well in these examples when it is doing well
[00:12:23.780 --> 00:12:26.260]   in these other examples, but then encoding that
[00:12:26.260 --> 00:12:28.100]   as part of the training process.
[00:12:28.100 --> 00:12:28.600]   Yeah?
[00:12:28.600 --> 00:12:30.500]   Do you know what's at the back end of this?
[00:12:30.500 --> 00:12:32.500]   Is it like, is it just the deep learning
[00:12:32.500 --> 00:12:35.060]   or just unsupervised learning?
[00:12:35.060 --> 00:12:36.620]   Yeah, so I'm not an expert on this.
[00:12:36.620 --> 00:12:39.580]   But my understanding from watching this video
[00:12:39.580 --> 00:12:40.960]   and talking to Jeremy about it is
[00:12:40.960 --> 00:12:43.700]   that they're training a classifier.
[00:12:43.700 --> 00:12:46.780]   And then they're using features of that classifier
[00:12:46.780 --> 00:12:50.180]   in kind of an unsupervised way to do nearest neighbors.
[00:12:50.180 --> 00:12:53.180]   So you label a bunch of images.
[00:12:53.180 --> 00:12:55.140]   Like, let's say you label a handful of images,
[00:12:55.140 --> 00:12:56.900]   train a classifier on those images.
[00:12:56.900 --> 00:12:59.320]   And then you can use the features of that classifier
[00:12:59.320 --> 00:13:02.360]   to click on an image and then find the most similar images
[00:13:02.360 --> 00:13:04.020]   according to that classifier.
[00:13:04.020 --> 00:13:05.940]   And then once you found those similar images,
[00:13:05.940 --> 00:13:07.940]   then it makes it easier for you to select those
[00:13:07.940 --> 00:13:09.400]   and label them all in a group.
[00:13:09.400 --> 00:13:18.740]   OK, but in addition to figuring out
[00:13:18.740 --> 00:13:20.640]   ways to reduce the manual effort in labeling,
[00:13:20.640 --> 00:13:22.340]   there's also some interesting efforts
[00:13:22.340 --> 00:13:26.380]   in how to make the labeling process more accurate.
[00:13:26.380 --> 00:13:28.660]   So I think when people think about labeling
[00:13:28.660 --> 00:13:29.620]   with--
[00:13:29.620 --> 00:13:32.540]   crowdsource labeling with Amazon Turk or something like that,
[00:13:32.540 --> 00:13:34.940]   sort of the default belief is you
[00:13:34.940 --> 00:13:36.660]   have to make things really dead simple.
[00:13:36.660 --> 00:13:38.660]   Otherwise, you're going to get garbage results.
[00:13:38.660 --> 00:13:44.780]   And if you want to get things that
[00:13:44.780 --> 00:13:47.020]   are accurate on sort of complicated,
[00:13:47.020 --> 00:13:49.780]   like not yes or no questions, then it's really hard
[00:13:49.780 --> 00:13:51.300]   and maybe even impossible.
[00:13:51.300 --> 00:13:53.420]   I think that intuition is still pretty valid.
[00:13:53.420 --> 00:13:56.980]   But there's a couple of things that can make that better.
[00:13:56.980 --> 00:13:58.800]   One is label quality control.
[00:13:58.800 --> 00:14:00.660]   And so I'm going to skip this because this
[00:14:00.660 --> 00:14:02.160]   is what we'll talk about in the lab
[00:14:02.160 --> 00:14:03.940]   that we'll do in a few minutes.
[00:14:03.940 --> 00:14:05.700]   And then the other thing I want to mention
[00:14:05.700 --> 00:14:08.060]   is this Soylent paper.
[00:14:08.060 --> 00:14:12.260]   How many people have seen this from Stanford?
[00:14:12.260 --> 00:14:12.940]   Yeah, one person.
[00:14:12.940 --> 00:14:13.660]   OK.
[00:14:13.660 --> 00:14:15.180]   This is a really fun paper.
[00:14:15.180 --> 00:14:18.380]   So the idea here was they wanted to do this really hard task
[00:14:18.380 --> 00:14:19.320]   using crowdsourcing.
[00:14:19.320 --> 00:14:22.120]   And the task is to take a paragraph of text.
[00:14:22.120 --> 00:14:23.700]   And they had a couple of other tasks.
[00:14:23.700 --> 00:14:25.500]   But this one is to take a paragraph of text
[00:14:25.500 --> 00:14:28.540]   and make that paragraph shorter without changing the meaning.
[00:14:28.540 --> 00:14:30.380]   So this is an unstructured task.
[00:14:30.380 --> 00:14:34.140]   And if you just ask people, random people on Amazon Turk
[00:14:34.140 --> 00:14:36.140]   to do it, they're not going to do a very good job
[00:14:36.140 --> 00:14:37.860]   because it's not very structured.
[00:14:37.860 --> 00:14:43.780]   And so what they came up with is a system
[00:14:43.780 --> 00:14:48.220]   that breaks this task into a bunch of subtasks, each one
[00:14:48.220 --> 00:14:49.660]   of which is pretty easy.
[00:14:49.660 --> 00:14:53.400]   And the way that they defined it is a find, fix, verify loop.
[00:14:53.400 --> 00:14:55.400]   And so the way it works is instead
[00:14:55.400 --> 00:14:57.240]   of having one task, like summarize
[00:14:57.240 --> 00:14:59.760]   this paragraph of text, there's three tasks.
[00:14:59.760 --> 00:15:02.000]   The first one is to find.
[00:15:02.000 --> 00:15:03.600]   And so in this example, it would be
[00:15:03.600 --> 00:15:05.600]   like find parts of the text that can be shortened
[00:15:05.600 --> 00:15:07.000]   without changing the meaning.
[00:15:07.000 --> 00:15:10.600]   And so a bunch of labelers will find parts of text
[00:15:10.600 --> 00:15:12.080]   that can be shortened.
[00:15:12.080 --> 00:15:13.000]   And then there's fix.
[00:15:13.000 --> 00:15:15.160]   And so then in fix, the labelers get
[00:15:15.160 --> 00:15:16.920]   the output of the previous step.
[00:15:16.920 --> 00:15:19.480]   So they get the parts of text that some other labeler
[00:15:19.480 --> 00:15:20.820]   said can be shortened.
[00:15:20.820 --> 00:15:22.580]   And then their job is to shorten them.
[00:15:22.580 --> 00:15:24.080]   So it's a much more constrained task
[00:15:24.080 --> 00:15:26.980]   because it's just this single block of text.
[00:15:26.980 --> 00:15:29.100]   They know they're supposed to shorten this.
[00:15:29.100 --> 00:15:31.540]   And then finally, verify.
[00:15:31.540 --> 00:15:34.980]   And this part is just looking at the results of the last step.
[00:15:34.980 --> 00:15:39.020]   And there's an interface where the labelers can say,
[00:15:39.020 --> 00:15:40.940]   which one of these changed the meaning
[00:15:40.940 --> 00:15:43.500]   and which one of these didn't actually make it shorter?
[00:15:43.500 --> 00:15:46.460]   And so they can start to eliminate the bad results
[00:15:46.460 --> 00:15:47.660]   from the previous step.
[00:15:47.660 --> 00:15:49.300]   And so with these three things together,
[00:15:49.300 --> 00:15:52.160]   you'll be able to get very good results for about--
[00:15:52.160 --> 00:15:56.040]   I think it was about $3 per paragraph and order
[00:15:56.040 --> 00:15:59.320]   of magnitude of minutes for each paragraph.
[00:15:59.320 --> 00:16:04.440]   Any other questions on data labeling?
[00:16:04.440 --> 00:16:07.860]   Yeah?
[00:16:07.860 --> 00:16:08.360]   [INAUDIBLE]
[00:16:08.360 --> 00:16:18.200]   I'm not familiar with whether big organizations have
[00:16:18.200 --> 00:16:19.240]   used this.
[00:16:19.240 --> 00:16:20.160]   Yeah.
[00:16:20.160 --> 00:16:21.680]   This is an idea I'm excited about.
[00:16:21.680 --> 00:16:24.400]   And I think it's an idea that's very underutilized in machine
[00:16:24.400 --> 00:16:26.100]   learning right now.
[00:16:26.100 --> 00:16:28.700]   I think there are a bunch of types of data
[00:16:28.700 --> 00:16:30.920]   that are really hard to label right now,
[00:16:30.920 --> 00:16:32.760]   three-dimensional data for robotics
[00:16:32.760 --> 00:16:35.000]   that you could potentially be able to label
[00:16:35.000 --> 00:16:36.160]   with an approach like this.
[00:16:36.160 --> 00:16:42.160]   OK, so moving on to data storage.
[00:16:42.160 --> 00:16:44.400]   Again, the idea here was that there's different ways
[00:16:44.400 --> 00:16:45.400]   of storing types of data.
[00:16:45.400 --> 00:16:50.680]   You can store it as an object in something like S3.
[00:16:50.680 --> 00:16:54.560]   You can store it in a database for things like metadata.
[00:16:54.560 --> 00:16:56.280]   If the data is totally unstructured,
[00:16:56.280 --> 00:16:58.120]   then you can just dump it in a big data lake
[00:16:58.120 --> 00:16:59.920]   and then aggregate it later.
[00:16:59.920 --> 00:17:01.920]   And at training time, everything needs
[00:17:01.920 --> 00:17:04.640]   to be locally on your file system.
[00:17:04.640 --> 00:17:07.400]   So just core concepts here of how to store data.
[00:17:07.400 --> 00:17:09.800]   The more interesting part here, I think, is data versioning.
[00:17:09.800 --> 00:17:12.460]   And so Sergey laid out the three or four,
[00:17:12.460 --> 00:17:15.360]   I guess, different levels of how organizations
[00:17:15.360 --> 00:17:17.120]   approach data versioning.
[00:17:17.120 --> 00:17:20.920]   Level 0 being what most people are doing when they train
[00:17:20.920 --> 00:17:23.420]   machine learning models, which is just you have a data set,
[00:17:23.420 --> 00:17:25.120]   and you train the model on that data set,
[00:17:25.120 --> 00:17:28.560]   and you have no way of tracking whether it's changed.
[00:17:28.560 --> 00:17:32.640]   Version 1 being every time you train a model on a data set,
[00:17:32.640 --> 00:17:36.200]   you snapshot that data and save it so that you can always
[00:17:36.200 --> 00:17:38.440]   go back to that specific data set.
[00:17:38.440 --> 00:17:41.800]   And then version 2, which is the one that Sergey and I really
[00:17:41.800 --> 00:17:45.520]   like, which is versioning data as a mix of assets and code.
[00:17:45.520 --> 00:17:49.320]   Meaning if you have a database that has all of your metadata,
[00:17:49.320 --> 00:17:52.240]   then one entry in that database for each row
[00:17:52.240 --> 00:17:55.560]   is also a link to the bigger file that's
[00:17:55.560 --> 00:17:59.560]   stored in asset storage.
[00:17:59.560 --> 00:18:02.920]   It sounded like there were some questions on this piece of it.
[00:18:02.920 --> 00:18:03.920]   Yeah?
[00:18:03.920 --> 00:18:33.400]   [INAUDIBLE]
[00:18:33.400 --> 00:18:36.440]   Yeah, it's a good question.
[00:18:36.440 --> 00:18:37.940]   So if I'm understanding correctly,
[00:18:37.940 --> 00:18:40.640]   you're asking when you design a data set,
[00:18:40.640 --> 00:18:43.720]   you have to specify some sort of API for that data set.
[00:18:43.720 --> 00:18:45.800]   And then how do you deal with that API being broken
[00:18:45.800 --> 00:18:47.920]   by adding types of data that, for example,
[00:18:47.920 --> 00:18:51.560]   have a label that's not in your original scheme?
[00:18:51.560 --> 00:18:56.440]   Yes, and more like breaking the scheme itself.
[00:18:56.440 --> 00:18:59.400]   Yeah, I think there's no really easy way around that.
[00:18:59.400 --> 00:19:01.160]   I think probably the way to do it
[00:19:01.160 --> 00:19:05.680]   is to sort of enforce it upstream using tests.
[00:19:05.680 --> 00:19:09.400]   So you have a test that says, does anything in your data set
[00:19:09.400 --> 00:19:10.200]   break the scheme?
[00:19:10.200 --> 00:19:12.120]   And then you'd make sure that that test has
[00:19:12.120 --> 00:19:14.360]   to pass before you can commit.
[00:19:14.360 --> 00:19:17.880]   And then sometimes you will have to break that backward
[00:19:17.880 --> 00:19:19.560]   compatibility.
[00:19:19.560 --> 00:19:21.360]   And so that's just kind of a decision
[00:19:21.360 --> 00:19:23.320]   that you have to make very consciously, I think.
[00:19:23.320 --> 00:19:27.140]   Yeah?
[00:19:27.140 --> 00:19:48.580]   [INAUDIBLE]
[00:19:48.580 --> 00:19:50.620]   Yeah, the main benefit is exactly what you said,
[00:19:50.620 --> 00:19:56.580]   which is a lot of times what you see--
[00:19:56.580 --> 00:19:58.860]   I mean, in software engineering in general,
[00:19:58.860 --> 00:20:01.020]   but particularly in machine learning--
[00:20:01.020 --> 00:20:04.900]   is you change part of your code base,
[00:20:04.900 --> 00:20:06.740]   and your performance gets way worse,
[00:20:06.740 --> 00:20:08.700]   and you just have no idea why.
[00:20:08.700 --> 00:20:11.300]   And it's super important to be able to catch those things
[00:20:11.300 --> 00:20:14.580]   early and revert quickly when that happens.
[00:20:14.580 --> 00:20:17.780]   Because otherwise, you can--
[00:20:17.780 --> 00:20:20.660]   before we started being really careful about testing
[00:20:20.660 --> 00:20:22.980]   at OpenAI, we would have times when
[00:20:22.980 --> 00:20:24.900]   we would go three weeks without training
[00:20:24.900 --> 00:20:26.700]   a particular type of model.
[00:20:26.700 --> 00:20:28.940]   And then we would train that model after three weeks,
[00:20:28.940 --> 00:20:30.220]   and it wouldn't work.
[00:20:30.220 --> 00:20:32.700]   And then it's like you have three weeks of people's
[00:20:32.700 --> 00:20:34.060]   commits in the code base that you
[00:20:34.060 --> 00:20:36.340]   have to try to somehow sift through to figure out
[00:20:36.340 --> 00:20:37.660]   where things broke.
[00:20:37.660 --> 00:20:39.700]   And if the breaking change happened earlier,
[00:20:39.700 --> 00:20:41.780]   then you still want all the good things
[00:20:41.780 --> 00:20:43.300]   that happened after that.
[00:20:43.300 --> 00:20:44.500]   And so it gets really messy.
[00:20:44.500 --> 00:20:47.180]   And so it's just a good software engineering practice
[00:20:47.180 --> 00:20:49.540]   to be able to catch things early and revert.
[00:20:49.540 --> 00:20:52.520]   [INAUDIBLE]
[00:20:52.520 --> 00:20:55.500]   [INAUDIBLE]
[00:20:55.500 --> 00:21:04.660]   Yeah.
[00:21:04.660 --> 00:21:07.940]   So the way I think about it is machine learning models
[00:21:07.940 --> 00:21:10.140]   are code plus data.
[00:21:10.140 --> 00:21:14.940]   So the data is actually part of the code in some sense.
[00:21:14.940 --> 00:21:17.700]   And so to be really concrete, things that can happen
[00:21:17.700 --> 00:21:20.620]   are like, let's say that you added a bunch of things
[00:21:20.620 --> 00:21:27.660]   to the data set, but your best labeler was on vacation.
[00:21:27.660 --> 00:21:30.100]   And you have a bunch of messy labels that get added.
[00:21:30.100 --> 00:21:32.520]   And then all of a sudden, you train a new model overnight,
[00:21:32.520 --> 00:21:34.500]   and that model is confused because it's
[00:21:34.500 --> 00:21:36.340]   been looking at a lot of bad data.
[00:21:36.340 --> 00:21:40.220]   You want to be able to revert that back.
[00:21:40.220 --> 00:21:43.680]   [INAUDIBLE]
[00:21:43.680 --> 00:21:47.540]   Sorry?
[00:21:47.540 --> 00:21:49.500]   [INAUDIBLE]
[00:21:49.500 --> 00:21:50.000]   Yeah.
[00:21:50.000 --> 00:21:51.780]   [INAUDIBLE]
[00:21:51.780 --> 00:21:52.260]   Yeah.
[00:21:52.260 --> 00:21:53.580]   This was covered in the lecture.
[00:21:53.580 --> 00:21:56.660]   The assets are things like S3 blobs.
[00:21:56.660 --> 00:21:57.660]   Yep.
[00:21:57.660 --> 00:22:00.660]   So when the assets are stored in multiple places,
[00:22:00.660 --> 00:22:03.140]   like some in S3, some in some database,
[00:22:03.140 --> 00:22:05.140]   doesn't it cause a lot of network traffic
[00:22:05.140 --> 00:22:09.140]   to pull in all of them just during the training?
[00:22:09.140 --> 00:22:11.140]   And you might be training multiple models
[00:22:11.140 --> 00:22:12.620]   at the same time as well.
[00:22:12.620 --> 00:22:14.780]   Yeah.
[00:22:14.780 --> 00:22:19.300]   So I haven't in practice seen this be a problem.
[00:22:19.300 --> 00:22:19.980]   Yeah.
[00:22:19.980 --> 00:22:22.540]   I think, in fact, you don't really
[00:22:22.540 --> 00:22:26.140]   have to worry so much about bandwidth on the S3 side.
[00:22:26.140 --> 00:22:28.180]   But you definitely have to worry about it locally.
[00:22:28.180 --> 00:22:29.940]   And so I think usually what people will do
[00:22:29.940 --> 00:22:33.500]   is they don't actually download the data from asset storage
[00:22:33.500 --> 00:22:34.500]   every single time.
[00:22:34.500 --> 00:22:36.180]   They have it backed up in asset storage,
[00:22:36.180 --> 00:22:38.260]   and then they just download a diff.
[00:22:38.260 --> 00:22:42.740]   So you're not actually downloading that much data.
[00:22:42.740 --> 00:22:48.740]   Is that automated, or you have to write your own scripts?
[00:22:48.740 --> 00:22:49.740]   We write our own scripts.
[00:22:49.740 --> 00:22:52.020]   There's probably a better way of automating it.
[00:22:52.020 --> 00:22:53.260]   Yeah.
[00:22:53.260 --> 00:22:54.900]   I'll take one more question on this,
[00:22:54.900 --> 00:22:56.300]   and then I really want to move on.
[00:22:56.300 --> 00:23:00.220]   Yeah.
[00:23:00.220 --> 00:23:04.060]   So are you running those tests on every commit
[00:23:04.060 --> 00:23:08.140]   to the data set for nightly or weekly?
[00:23:08.140 --> 00:23:08.740]   Yeah.
[00:23:08.740 --> 00:23:11.220]   We'll talk more about testing later in the class.
[00:23:11.220 --> 00:23:14.340]   But there are tests that run--
[00:23:14.340 --> 00:23:16.040]   I think the best practice here is
[00:23:16.040 --> 00:23:17.780]   there are some tests that you want
[00:23:17.780 --> 00:23:21.100]   to pass every single time you commit to the code base.
[00:23:21.100 --> 00:23:23.560]   But there are some tests that you still really need to run
[00:23:23.560 --> 00:23:26.020]   that can't be run fast enough to do that.
[00:23:26.020 --> 00:23:30.260]   So if you are training vision models,
[00:23:30.260 --> 00:23:33.020]   maybe it takes 12 hours to train your vision model.
[00:23:33.020 --> 00:23:35.820]   And it's still super important to make sure
[00:23:35.820 --> 00:23:38.420]   that you have a test so that your ability
[00:23:38.420 --> 00:23:40.420]   to train those vision models doesn't regress.
[00:23:40.420 --> 00:23:42.140]   But it doesn't make sense to do that every single time
[00:23:42.140 --> 00:23:43.760]   you commit, because then it would just
[00:23:43.760 --> 00:23:45.700]   take too long to merge commits.
[00:23:45.700 --> 00:23:47.540]   And so then there's a separate set of tests
[00:23:47.540 --> 00:23:50.340]   that you maybe run every night or every week or something
[00:23:50.340 --> 00:23:51.340]   like that.
[00:23:51.340 --> 00:23:53.100]   So you can still catch things pretty fast.
[00:23:53.100 --> 00:23:57.820]   Cool.
[00:23:57.820 --> 00:24:00.060]   Last topic was data workflows.
[00:24:00.060 --> 00:24:04.140]   And so the example was, if we're training a popularity
[00:24:04.140 --> 00:24:07.220]   predictor, there is a bunch of different components
[00:24:07.220 --> 00:24:08.140]   of that data.
[00:24:08.140 --> 00:24:09.540]   So you have metadata.
[00:24:09.540 --> 00:24:14.780]   You have some user data and some classifier data.
[00:24:14.780 --> 00:24:16.580]   And these are stored in different places.
[00:24:16.580 --> 00:24:19.660]   So in databases or in logs, or there
[00:24:19.660 --> 00:24:21.180]   may be the output of a model.
[00:24:21.180 --> 00:24:23.140]   And so the key idea here is you can
[00:24:23.140 --> 00:24:24.980]   manage all these dependencies every time
[00:24:24.980 --> 00:24:28.020]   you create your data set using something like a makefile.
[00:24:28.020 --> 00:24:29.980]   But it doesn't really scale all that well.
[00:24:29.980 --> 00:24:32.420]   And so there's these tools like Airflow,
[00:24:32.420 --> 00:24:36.060]   where you can manage the dependencies of your data set
[00:24:36.060 --> 00:24:39.700]   creation process as a directed acyclic graph
[00:24:39.700 --> 00:24:42.740]   and run everything in a more parallel way.
[00:24:42.740 --> 00:24:43.700]   So that's the idea.
[00:24:43.700 --> 00:24:49.820]   Cool.
[00:24:49.820 --> 00:24:50.580]   All right.
[00:24:50.580 --> 00:24:52.820]   Up next, we have the labeling challenge.
[00:24:52.820 --> 00:24:54.620]   So this is the reason why I asked everyone
[00:24:54.620 --> 00:24:56.700]   to bring their laptops today.
[00:24:56.700 --> 00:25:00.180]   So what I'm going to have you do is just everyone
[00:25:00.180 --> 00:25:02.820]   kind of get together in groups of two or three,
[00:25:02.820 --> 00:25:04.360]   just with the people around you.
[00:25:04.360 --> 00:25:07.140]   And go to this URL.
[00:25:07.140 --> 00:25:09.500]   And it'll have instructions there for how to get started.
[00:25:10.500 --> 00:25:13.500]   And we'll spend about 30 minutes on this.
[00:25:13.500 --> 00:25:14.980]   And so we'll just see how far we get.
[00:25:14.980 --> 00:25:18.580]   And then we'll regroup after that.
[00:25:18.580 --> 00:25:20.780]   So let's discuss this.
[00:25:20.780 --> 00:25:24.500]   How many were able to run the baseline?
[00:25:24.500 --> 00:25:25.500]   OK, that's really good.
[00:25:25.500 --> 00:25:30.300]   And how many people were just installing PyM the whole time?
[00:25:30.300 --> 00:25:32.100]   Yeah, I guess I hadn't anticipated that.
[00:25:32.100 --> 00:25:33.340]   But I probably should have.
[00:25:33.340 --> 00:25:34.800]   Part of your homework for next week
[00:25:34.800 --> 00:25:36.780]   is going to be to install PyM and make sure
[00:25:36.780 --> 00:25:39.140]   you can get it to work.
[00:25:39.140 --> 00:25:41.660]   All right, and how many were able to try your own thing
[00:25:41.660 --> 00:25:44.260]   and actually run it on the data set?
[00:25:44.260 --> 00:25:45.780]   OK, a couple.
[00:25:45.780 --> 00:25:47.420]   Good.
[00:25:47.420 --> 00:25:50.580]   I think probably within another 15 or 20 minutes,
[00:25:50.580 --> 00:25:54.140]   it would have been a much higher percentage of people.
[00:25:54.140 --> 00:25:56.580]   So what I want to talk about is just
[00:25:56.580 --> 00:25:58.380]   what are the ideas that you had?
[00:25:58.380 --> 00:26:01.580]   So the challenge was we had this kind of method
[00:26:01.580 --> 00:26:03.500]   of getting labels from a bunch of labelers
[00:26:03.500 --> 00:26:05.180]   who were already working on the dataset.
[00:26:05.180 --> 00:26:06.780]   And we were getting labels from a bunch of labelers
[00:26:06.780 --> 00:26:09.540]   who had solved the same problem, which was just have them vote.
[00:26:09.540 --> 00:26:12.660]   And if greater than 50% of them said that this is the label,
[00:26:12.660 --> 00:26:14.180]   then we say it's the label.
[00:26:14.180 --> 00:26:16.660]   So what are some ideas of how we can do better than that?
[00:26:16.660 --> 00:26:17.660]   Yeah?
[00:26:17.660 --> 00:26:18.140]   [INAUDIBLE]
[00:26:18.140 --> 00:26:27.340]   So we can score workers.
[00:26:27.340 --> 00:26:29.260]   And how can you do that?
[00:26:29.260 --> 00:26:29.740]   [INAUDIBLE]
[00:26:29.740 --> 00:26:33.460]   The basic law is all from data to each other.
[00:26:33.460 --> 00:26:33.960]   Mm-hmm.
[00:26:33.960 --> 00:26:40.980]   What else?
[00:26:40.980 --> 00:26:45.820]   I'm just going to weigh them by the seven-day accuracy.
[00:26:45.820 --> 00:26:47.380]   Yeah, seven-day accuracy.
[00:26:47.380 --> 00:26:49.820]   What's the issue with that, though?
[00:26:49.820 --> 00:26:52.100]   It's almost all the same.
[00:26:52.100 --> 00:26:53.780]   Yeah, it's almost all the same.
[00:26:53.780 --> 00:26:55.420]   And then also, this is sort of, I
[00:26:55.420 --> 00:26:57.060]   think, maybe a particular Amazon Turk.
[00:26:57.060 --> 00:26:59.140]   But when they show those seven-day accuracies,
[00:26:59.140 --> 00:27:00.620]   that's on all tasks.
[00:27:00.620 --> 00:27:03.700]   So we might want something that's more specific to our task.
[00:27:03.700 --> 00:27:05.300]   How else can we score the workers?
[00:27:05.300 --> 00:27:05.660]   Yeah?
[00:27:05.660 --> 00:27:07.300]   Just ignore all the workers you've done,
[00:27:07.300 --> 00:27:09.180]   like only less than five tasks.
[00:27:09.180 --> 00:27:13.060]   Yeah, so we could ignore infrequent.
[00:27:13.060 --> 00:27:15.860]   Yep.
[00:27:15.860 --> 00:27:17.420]   How else can we eliminate workers
[00:27:17.420 --> 00:27:18.820]   that we don't think are good?
[00:27:18.820 --> 00:27:20.660]   All the same answer.
[00:27:20.660 --> 00:27:21.220]   Sorry?
[00:27:21.220 --> 00:27:23.060]   All the same answer.
[00:27:23.060 --> 00:27:23.940]   Yeah, all the same.
[00:27:23.940 --> 00:27:28.540]   What else?
[00:27:28.540 --> 00:27:31.220]   Maybe something that requires a little bit more work on our end.
[00:27:31.220 --> 00:27:32.900]   They're judging too fast.
[00:27:32.900 --> 00:27:34.500]   Yeah, the speed that they're judging.
[00:27:34.500 --> 00:27:35.340]   I think that's reasonable.
[00:27:35.340 --> 00:27:35.840]   Yeah?
[00:27:35.840 --> 00:27:38.300]   I'm not sure how to write it.
[00:27:38.300 --> 00:27:42.260]   Like, out of 1 to 11 answers, we have the ground truth.
[00:27:42.260 --> 00:27:46.980]   We can check how many answers are in the ground truth.
[00:27:46.980 --> 00:27:48.980]   Yeah.
[00:27:48.980 --> 00:27:51.860]   Yeah, I think this is the key idea here, which is,
[00:27:51.860 --> 00:27:54.620]   what you can do is you can have some of the answers
[00:27:54.620 --> 00:27:56.780]   where you know what the ground truth is.
[00:27:56.780 --> 00:28:00.140]   So if you got a chance to look at the hints,
[00:28:00.140 --> 00:28:03.420]   then one of the hints was columns 11 through 15
[00:28:03.420 --> 00:28:07.740]   are actually-- they're not being used to compute the--
[00:28:07.740 --> 00:28:11.620]   to score how well our method is doing,
[00:28:11.620 --> 00:28:13.300]   because we actually know what the ground
[00:28:13.300 --> 00:28:14.580]   truth is for all of those.
[00:28:14.580 --> 00:28:15.960]   And so when we set up the survey,
[00:28:15.960 --> 00:28:18.060]   we knew that 11 through 15 were always true,
[00:28:18.060 --> 00:28:19.420]   and 16 was always false.
[00:28:19.420 --> 00:28:20.840]   And so one thing that we could do
[00:28:20.840 --> 00:28:22.780]   is we can look at how the workers are
[00:28:22.780 --> 00:28:26.220]   doing on those questions, and we can weight them based on that.
[00:28:26.860 --> 00:28:28.220]   So those are all ways of thinking
[00:28:28.220 --> 00:28:30.820]   about how to figure out who our best workers are.
[00:28:30.820 --> 00:28:32.780]   I think there are some others.
[00:28:32.780 --> 00:28:35.180]   But once we know what the best workers--
[00:28:35.180 --> 00:28:36.540]   who the best workers are, then we
[00:28:36.540 --> 00:28:38.180]   need to figure out how to combine them.
[00:28:38.180 --> 00:28:42.940]   And there are different ways of doing that.
[00:28:42.940 --> 00:28:47.340]   So let's say that we have some score for how good workers are.
[00:28:47.340 --> 00:28:53.060]   How can we use that score to combine what the workers said?
[00:28:53.060 --> 00:28:54.060]   Yeah.
[00:28:54.060 --> 00:28:54.960]   [INAUDIBLE]
[00:28:54.960 --> 00:28:58.380]   Either you weigh them by their score or have a threshold.
[00:28:58.380 --> 00:29:00.780]   And below the threshold, you compute their discard.
[00:29:00.780 --> 00:29:01.280]   Yep.
[00:29:01.280 --> 00:29:03.780]   You can have a weighted average, or you can have a threshold.
[00:29:03.780 --> 00:29:07.180]   I think those are both very reasonable.
[00:29:07.180 --> 00:29:08.940]   Any other ideas?
[00:29:08.940 --> 00:29:10.020]   Yeah.
[00:29:10.020 --> 00:29:14.180]   Take the top three best workers and just have them vote.
[00:29:14.180 --> 00:29:16.180]   Yeah.
[00:29:16.180 --> 00:29:17.620]   Three best vote.
[00:29:17.620 --> 00:29:21.260]   Very similar to a threshold, but subtly different.
[00:29:21.260 --> 00:29:23.740]   [INAUDIBLE]
[00:29:23.740 --> 00:29:30.500]   There's one other thing that you can do here
[00:29:30.500 --> 00:29:32.660]   that's slightly more complicated.
[00:29:32.660 --> 00:29:35.420]   And that's to actually formulate this as an EM algorithm.
[00:29:35.420 --> 00:29:37.080]   How many are familiar with EM algorithms
[00:29:37.080 --> 00:29:39.700]   from some intro to machine learning class?
[00:29:39.700 --> 00:29:41.580]   OK, only a few.
[00:29:41.580 --> 00:29:43.060]   Basically, the way an EM algorithm
[00:29:43.060 --> 00:29:45.940]   works is you have two steps in your process.
[00:29:45.940 --> 00:29:47.940]   And you alternate between doing those two steps.
[00:29:47.940 --> 00:29:51.660]   And so here, for this example, the two steps
[00:29:51.660 --> 00:29:54.940]   are you alternate between--
[00:29:54.940 --> 00:29:58.700]   for a given scoring of each of your labelers,
[00:29:58.700 --> 00:30:02.020]   you produce labels.
[00:30:02.020 --> 00:30:03.260]   So that's step one.
[00:30:03.260 --> 00:30:05.300]   And then step two is for a given set of labels
[00:30:05.300 --> 00:30:07.260]   that you predicted, you use those labels
[00:30:07.260 --> 00:30:09.660]   to score the workers.
[00:30:09.660 --> 00:30:11.740]   And so for your next set of labels,
[00:30:11.740 --> 00:30:14.540]   then you see how all of your workers did on those labels.
[00:30:14.540 --> 00:30:16.860]   And you use those weights to give
[00:30:16.860 --> 00:30:18.100]   new scores for your labelers.
[00:30:18.100 --> 00:30:20.500]   And you alternate between those two.
[00:30:20.500 --> 00:30:22.300]   And then eventually, this algorithm
[00:30:22.300 --> 00:30:24.700]   will converge into something that's slightly better
[00:30:24.700 --> 00:30:27.860]   than doing one of these.
[00:30:27.860 --> 00:30:29.460]   All right, there's another category
[00:30:29.460 --> 00:30:31.380]   of things that we haven't really talked about,
[00:30:31.380 --> 00:30:34.180]   which is how can we get better data?
[00:30:34.180 --> 00:30:36.540]   How can we go back to our data collection process
[00:30:36.540 --> 00:30:39.500]   and do better?
[00:30:39.500 --> 00:30:42.460]   [INAUDIBLE]
[00:30:42.460 --> 00:30:44.060]   Say it again.
[00:30:44.060 --> 00:30:47.980]   Things where there is two out of three,
[00:30:47.980 --> 00:30:50.180]   which is about 20% of the data, you
[00:30:50.180 --> 00:30:53.660]   could go back and ask three more people.
[00:30:53.660 --> 00:30:59.500]   Yeah, so ask where we disagree.
[00:30:59.500 --> 00:31:00.260]   I like that a lot.
[00:31:00.260 --> 00:31:04.220]   Other ideas?
[00:31:04.220 --> 00:31:06.500]   Can you format the question a bit better?
[00:31:06.500 --> 00:31:09.100]   Yeah, I think that's great.
[00:31:09.100 --> 00:31:11.900]   So what specifically did you see that was not great?
[00:31:11.900 --> 00:31:13.340]   It was pretty open-ended.
[00:31:13.340 --> 00:31:14.820]   You just had to write the adjective
[00:31:14.820 --> 00:31:17.260]   and give them a pool to select from.
[00:31:17.260 --> 00:31:18.780]   Yep.
[00:31:18.780 --> 00:31:20.540]   Yeah, I was hoping someone would say that,
[00:31:20.540 --> 00:31:22.700]   because that's definitely something that you can do.
[00:31:22.700 --> 00:31:23.540]   Any other ideas?
[00:31:23.540 --> 00:31:25.780]   Specifically, you could split synonyms and adjectives
[00:31:25.780 --> 00:31:27.260]   into separate steps.
[00:31:27.260 --> 00:31:28.220]   So that's easier.
[00:31:28.220 --> 00:31:29.620]   So that's less parabolic.
[00:31:29.620 --> 00:31:30.780]   Yeah, I totally agree.
[00:31:30.780 --> 00:31:32.660]   When I was going through and labeling these,
[00:31:32.660 --> 00:31:36.380]   that was very painful to keep in my mind the entire time.
[00:31:36.380 --> 00:31:37.780]   Another thing you could do is you
[00:31:37.780 --> 00:31:39.300]   can use your scores for the labelers.
[00:31:39.300 --> 00:31:40.300]   And you can go back.
[00:31:40.300 --> 00:31:43.420]   And as you're collecting more data, you could just say,
[00:31:43.420 --> 00:31:45.100]   I have some portion of my data set
[00:31:45.100 --> 00:31:47.500]   where I know how well the labelers are doing.
[00:31:47.500 --> 00:31:50.620]   And so I'm just literally only going to take the labelers
[00:31:50.620 --> 00:31:51.900]   that I know are good.
[00:31:51.900 --> 00:31:53.020]   And they're just going to be the only ones that
[00:31:53.020 --> 00:31:54.440]   are allowed to answer my question.
[00:31:54.440 --> 00:32:00.500]   Yeah, so the purpose of this exercise
[00:32:00.500 --> 00:32:02.060]   is just to give you a sense of--
[00:32:02.060 --> 00:32:04.100]   this is something that you often actually really
[00:32:04.100 --> 00:32:06.340]   have to do in a machine learning organization.
[00:32:06.340 --> 00:32:08.340]   And there's a lot of complexity to it.
[00:32:08.340 --> 00:32:10.100]   And so I was hoping that we could just
[00:32:10.100 --> 00:32:13.100]   get to some of the big ideas about how
[00:32:13.100 --> 00:32:15.340]   you can get better labels.
[00:32:15.340 --> 00:32:16.260]   Yeah?
[00:32:16.260 --> 00:32:17.220]   Sorry, just a second.
[00:32:17.220 --> 00:32:19.980]   Can you repeat the last part you mentioned?
[00:32:19.980 --> 00:32:21.980]   Last--
[00:32:21.980 --> 00:32:24.020]   For better data.
[00:32:24.020 --> 00:32:25.700]   Yeah, so one other thing that you can do
[00:32:25.700 --> 00:32:29.820]   is next time you go and collect data for this task,
[00:32:29.820 --> 00:32:33.060]   you can just specify in Mechanical Turk
[00:32:33.060 --> 00:32:35.540]   that you only want to accept answers from people
[00:32:35.540 --> 00:32:38.100]   that you already know are good labelers based
[00:32:38.100 --> 00:32:40.460]   on the scores that you gave them before.
[00:32:40.460 --> 00:32:40.960]   Yeah?
[00:32:40.960 --> 00:32:43.700]   Can you talk through the EM algorithm?
[00:32:43.700 --> 00:32:45.540]   I don't want to go through the EM algorithm.
[00:32:45.540 --> 00:32:46.920]   I'm happy to talk about it after,
[00:32:46.920 --> 00:32:49.620]   but just because we're running slightly low on time
[00:32:49.620 --> 00:32:51.220]   and it's a bit complex.
[00:32:51.220 --> 00:32:55.620]   But it's a good thing to read about as well.
[00:32:55.620 --> 00:32:57.380]   It's a good concept to be familiar with
[00:32:57.380 --> 00:32:59.920]   because it comes up in a lot of places in machine learning.
[00:32:59.920 --> 00:33:04.340]   All right, a couple of references
[00:33:04.340 --> 00:33:06.860]   I wanted to mention on getting better labels.
[00:33:06.860 --> 00:33:10.020]   There's a couple of papers and a course
[00:33:10.020 --> 00:33:13.540]   from UPenn, which I actually modified this project from.
[00:33:13.540 --> 00:33:19.860]   OK, so homework for next week.
[00:33:19.860 --> 00:33:22.780]   One note, class is going to be on Thursday next week instead
[00:33:22.780 --> 00:33:24.740]   of Wednesday.
[00:33:24.740 --> 00:33:26.420]   And there's a lecture to watch, which
[00:33:26.420 --> 00:33:29.660]   is the troubleshooting lecture.
[00:33:29.660 --> 00:33:31.820]   And in terms of your project, there's
[00:33:31.820 --> 00:33:34.660]   going to be two things to work on.
[00:33:34.660 --> 00:33:36.700]   The first is actually going and collecting
[00:33:36.700 --> 00:33:38.200]   an initial version of your data set.
[00:33:38.200 --> 00:33:40.220]   So hopefully, if it's publicly available data
[00:33:40.220 --> 00:33:41.720]   or if it's something you can scrape,
[00:33:41.720 --> 00:33:42.820]   then this is pretty easy.
[00:33:42.820 --> 00:33:44.780]   And if it's something that you need to collect yourself,
[00:33:44.780 --> 00:33:46.660]   then this is going to be an ongoing process,
[00:33:46.660 --> 00:33:48.060]   but just get that process started.
[00:33:48.060 --> 00:33:53.420]   And then complete a project proposal with your team.
[00:33:53.420 --> 00:33:55.740]   And I'll talk about this more in a second.
[00:33:55.740 --> 00:33:57.500]   And then once you've done these things,
[00:33:57.500 --> 00:33:59.380]   I want to get people in the habit of posting
[00:33:59.380 --> 00:34:01.780]   their updates on project updates so that you can start
[00:34:01.780 --> 00:34:04.340]   to get feedback from me and the other instructors
[00:34:04.340 --> 00:34:06.580]   and your fellow classmates to just kind of help you
[00:34:06.580 --> 00:34:09.740]   through this process.
[00:34:09.740 --> 00:34:11.500]   All right, project proposals.
[00:34:11.500 --> 00:34:13.420]   So why are we asking you to do this?
[00:34:13.420 --> 00:34:16.900]   Well, six weeks is pretty short to do a project like this.
[00:34:16.900 --> 00:34:18.420]   And so the goal is really to make sure
[00:34:18.420 --> 00:34:20.700]   that you have picked a project for you
[00:34:20.700 --> 00:34:22.740]   and your team that's actually possible to achieve
[00:34:22.740 --> 00:34:24.180]   in that amount of time.
[00:34:24.180 --> 00:34:27.180]   And then also, you're going to put some of your ideas there.
[00:34:27.180 --> 00:34:29.260]   And so hopefully, you can get some feedback
[00:34:29.260 --> 00:34:30.940]   on the things you're planning to try
[00:34:30.940 --> 00:34:34.220]   and what else you should look into.
[00:34:34.220 --> 00:34:37.900]   There's an example proposal that I'll talk about quickly.
[00:34:37.900 --> 00:34:39.700]   All right.
[00:34:39.700 --> 00:34:42.380]   And so it's just kind of like this is a sample format.
[00:34:42.380 --> 00:34:44.140]   You don't have to do it exactly like this,
[00:34:44.140 --> 00:34:45.660]   but you should cover the same topics.
[00:34:45.660 --> 00:34:49.620]   What project are you working on?
[00:34:49.620 --> 00:34:51.780]   Who's your team?
[00:34:51.780 --> 00:34:53.780]   And then what's the goal of your project?
[00:34:53.780 --> 00:34:55.620]   And then we want you to talk about what
[00:34:55.620 --> 00:34:58.540]   data set you're going to use or plan to collect,
[00:34:58.540 --> 00:35:00.820]   what baseline you're going to create for that data set.
[00:35:00.820 --> 00:35:03.820]   So are you using a linear regression
[00:35:03.820 --> 00:35:06.260]   or is there some way of telling whether your model is
[00:35:06.260 --> 00:35:08.300]   doing well or not?
[00:35:08.300 --> 00:35:11.780]   And then what model architecture and loss function.
[00:35:11.780 --> 00:35:13.860]   So what are you going to train on that data set?
[00:35:13.860 --> 00:35:17.860]   And then finally, since this is an applied deep learning class,
[00:35:17.860 --> 00:35:20.820]   we want to try to get at what is the end result of this
[00:35:20.820 --> 00:35:21.860]   going to look like.
[00:35:21.860 --> 00:35:22.820]   Is it a web app?
[00:35:22.820 --> 00:35:25.340]   Is it something that you're deploying on your phone?
[00:35:25.340 --> 00:35:28.620]   Is the project too complex to really be able to do that?
[00:35:28.620 --> 00:35:30.260]   But what is this going to look like?
[00:35:30.260 --> 00:35:32.380]   And then lastly, we have a section
[00:35:32.380 --> 00:35:35.180]   for what's the stretch goal of the project.
[00:35:35.180 --> 00:35:36.980]   So if all of this stuff goes well,
[00:35:36.980 --> 00:35:40.300]   what do you hope to achieve on top of it?
[00:35:40.300 --> 00:35:41.920]   Any questions on the project proposals?
[00:35:41.920 --> 00:35:47.000]   Yeah.
[00:35:47.000 --> 00:35:48.980]   So the project proposal is happening
[00:35:48.980 --> 00:35:51.460]   after we can form the teams, right?
[00:35:51.460 --> 00:35:51.960]   Yes.
[00:35:51.960 --> 00:35:55.460]   So there's going to be like a stage or a finalization
[00:35:55.460 --> 00:35:58.980]   kind of update when we're forming the teams?
[00:35:58.980 --> 00:36:01.320]   Yeah, we're going to finish formulating the teams now,
[00:36:01.320 --> 00:36:01.820]   hopefully.
[00:36:01.820 --> 00:36:04.020]   And hopefully over the-- well, we'll
[00:36:04.020 --> 00:36:05.860]   do our best to do it in the next 10 minutes.
[00:36:05.860 --> 00:36:07.740]   And what doesn't happen in the next 10 minutes
[00:36:07.740 --> 00:36:09.620]   can happen online in the next couple of days.
[00:36:09.620 --> 00:36:13.260]   All right, great.
[00:36:13.260 --> 00:36:16.980]   So most of you have signed up for a project.
[00:36:16.980 --> 00:36:20.900]   Is there anyone who hasn't chosen a project at all yet?
[00:36:20.900 --> 00:36:22.340]   OK, a couple people.
[00:36:22.340 --> 00:36:24.860]   But there are a lot of projects that are one.
[00:36:24.860 --> 00:36:27.580]   It's OK if you really want to do a project by yourself.
[00:36:27.580 --> 00:36:30.300]   But I would prefer to have projects be on teams,
[00:36:30.300 --> 00:36:31.900]   because it's important to figure out
[00:36:31.900 --> 00:36:33.860]   how to work on this stuff as part of a team.
[00:36:33.860 --> 00:36:35.460]   And also, there's just a lot of work.
[00:36:35.460 --> 00:36:37.740]   And so you're going to need more people to get it done.
[00:36:37.740 --> 00:36:39.660]   So what I want to do is, if you're
[00:36:39.660 --> 00:36:42.460]   on a team that's already two or three or four,
[00:36:42.460 --> 00:36:46.220]   and you feel like you're sort of settled as a team,
[00:36:46.220 --> 00:36:48.740]   then I want you to go into this kind of back room
[00:36:48.740 --> 00:36:50.420]   and just spend the next 10 minutes
[00:36:50.420 --> 00:36:52.580]   meeting with your team, planning,
[00:36:52.580 --> 00:36:55.180]   figuring out what you want to put in the project proposal.
[00:36:55.180 --> 00:36:57.100]   For everyone else-- so if you're not on a team
[00:36:57.100 --> 00:36:58.900]   or if you're on a team of one, or if you're
[00:36:58.900 --> 00:37:03.500]   looking for more people for your team, then just stay here.
[00:37:03.500 --> 00:37:05.420]   And the idea is, hopefully, we can start
[00:37:05.420 --> 00:37:08.180]   consolidating some of the teams.
[00:37:08.180 --> 00:37:10.060]   Yeah?
[00:37:10.060 --> 00:37:12.260]   I'll share all the slides after.
[00:37:12.260 --> 00:37:14.460]   Great, yeah, so you have the next 10 minutes.
[00:37:14.460 --> 00:37:17.860]   Let's try to get some project teams finalized.

