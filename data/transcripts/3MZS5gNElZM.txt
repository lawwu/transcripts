
[00:00:00.000 --> 00:00:22.200]   .
[00:00:22.200 --> 00:00:25.800]   So first question for you.
[00:00:25.800 --> 00:00:29.680]   What is definitely happening by the end of 2026?
[00:00:29.680 --> 00:00:36.960]   AI agents ship code directly to prod in your environment, right, not in some playground.
[00:00:36.960 --> 00:00:42.120]   Voice AI replaces text for most business communication.
[00:00:42.120 --> 00:00:46.060]   Inference cost drops below a cent per million tokens.
[00:00:46.060 --> 00:00:50.040]   Or Wall-E, like we're all chilling.
[00:00:50.040 --> 00:00:54.800]   Any of these?
[00:00:54.800 --> 00:00:59.360]   First one, ship code directly to prod, okay, this is a hopeful set of engineers.
[00:00:59.360 --> 00:01:06.640]   All of you want to get rid of your own jobs, I love that.
[00:01:06.640 --> 00:01:14.640]   The good thing is I also don't have Internet, so I can't look at my next question.
[00:01:14.640 --> 00:01:21.920]   No, it's going to be good, it's going to be good.
[00:01:21.920 --> 00:01:25.200]   Do you want to present from your phone?
[00:01:25.200 --> 00:01:29.200]   Oh, no, I was going to go through poll questions while we're trying to do AV setup.
[00:01:29.200 --> 00:01:31.200]   This one though?
[00:01:31.200 --> 00:01:40.480]   It's going to be good.
[00:01:40.480 --> 00:01:41.480]   Yeah.
[00:01:41.480 --> 00:01:46.480]   While this is happening, I'm actually just going to introduce myself so we're not wasting the time.
[00:01:46.480 --> 00:01:47.760]   So, my name is Sarah Gua.
[00:01:47.760 --> 00:01:51.760]   I helped start an AI-native venture fund.
[00:01:51.760 --> 00:01:53.760]   It's called Conviction.
[00:01:53.760 --> 00:02:01.040]   We got going about two and a half, almost three years ago now, just before the starting gun of Chad GPT.
[00:02:01.040 --> 00:02:05.440]   As always, in technology, investing most of life, it's better to be lucky than right.
[00:02:05.440 --> 00:02:07.360]   Hopefully, you can be a little of both.
[00:02:07.360 --> 00:02:13.600]   And the point of having a new venture firm, I worked at Greylock.
[00:02:13.600 --> 00:02:16.080]   It's kind of a traditionalist venture firm, a great one.
[00:02:16.080 --> 00:02:18.240]   My partner, Mike Vernal, used to work at Sequoia.
[00:02:18.240 --> 00:02:19.440]   You guys have probably heard of them.
[00:02:19.440 --> 00:02:25.360]   Was that we think, like, actually, you know, at risk of sounding like those people, this time it's
[00:02:25.360 --> 00:02:26.880]   different, right?
[00:02:26.880 --> 00:02:30.640]   That this is the largest technology revolution that we get to be a part of.
[00:02:30.640 --> 00:02:35.840]   And that there's so much change in the technology, the types of businesses you can build, the product
[00:02:35.840 --> 00:02:42.080]   decisions you make, what challenges these startups and big companies face that, you know, maybe there's
[00:02:42.080 --> 00:02:45.040]   opportunity for, like, a startup VC as well.
[00:02:45.040 --> 00:02:50.480]   And so, you know, I'm thrilled to be working with, like, really interesting people in the industry
[00:02:50.480 --> 00:02:50.960]   so far.
[00:02:50.960 --> 00:02:57.760]   Mike and I are investors in companies like Cursor, Cognition, Mistral, Thinking Machines, Harvey,
[00:02:57.760 --> 00:02:58.480]   Open Evidence.
[00:02:58.480 --> 00:03:05.520]   So a mix of base 10, like a mix of infrastructure, model, and application level companies.
[00:03:05.520 --> 00:03:09.200]   And, you know, one more, are my kids coming up yet?
[00:03:09.200 --> 00:03:09.760]   Okay, cool.
[00:03:11.120 --> 00:03:17.040]   One more just observation from the last two and a half, three years of doing venture.
[00:03:17.040 --> 00:03:23.840]   I was an investor for about 10 years before that, is I have never seen the, like, just the uptake
[00:03:23.840 --> 00:03:27.920]   from users that has been possible in the last couple years.
[00:03:27.920 --> 00:03:29.760]   I'm sure all of you have experienced that.
[00:03:29.760 --> 00:03:30.880]   It is not trivial.
[00:03:30.880 --> 00:03:37.040]   You know, AI product and AI engineering, and this is kind of the theme of my talk, so I'm
[00:03:37.040 --> 00:03:40.800]   sorry to give away the punchline, but it's quite a bit harder than people had hoped.
[00:03:40.800 --> 00:03:43.840]   But the value creation is massive.
[00:03:43.840 --> 00:03:50.400]   We see companies going from 0 to 10, 50, 100 million in run rate very, very quickly,
[00:03:50.400 --> 00:03:53.200]   faster than we've ever seen in any technology revolution before.
[00:03:53.200 --> 00:03:59.040]   And I get asked a lot, like, where are we in the AI hype cycle?
[00:03:59.040 --> 00:04:00.320]   Is the winter coming?
[00:04:00.320 --> 00:04:02.720]   Is this, like, infinite AI summer?
[00:04:02.720 --> 00:04:08.800]   And I would say, having actually been an investor or an operator through a macro cycle at this point,
[00:04:08.800 --> 00:04:13.280]   like, I try to pay very little attention to what the marketing world is saying,
[00:04:13.280 --> 00:04:15.280]   or even what the markets are saying, right?
[00:04:15.280 --> 00:04:21.200]   Because, you know, if you're an operator or an investor, maybe you care about what the stock price
[00:04:21.200 --> 00:04:26.000]   does every day, but really you want to figure out if the company you're working for or starting is
[00:04:26.000 --> 00:04:27.280]   going to work long-term, right?
[00:04:27.280 --> 00:04:29.040]   And if the products are going to work long-term.
[00:04:29.040 --> 00:04:33.920]   And the things that I get most excited about are seeing, like, crazy usage numbers.
[00:04:33.920 --> 00:04:35.200]   Okay!
[00:04:35.200 --> 00:04:37.200]   Whoo!
[00:04:37.200 --> 00:04:38.880]   Thank you, amazing AV team.
[00:04:38.880 --> 00:04:42.560]   Okay, I'm going to go real quick.
[00:04:42.560 --> 00:04:47.520]   Where are my presenter notes?
[00:04:47.520 --> 00:04:51.200]   Okay, we're just going to keep going.
[00:04:51.200 --> 00:04:51.840]   It's cool.
[00:04:51.840 --> 00:04:52.480]   It's cool.
[00:04:52.480 --> 00:04:57.360]   So, I want to talk really quickly about just a few things today.
[00:04:57.360 --> 00:05:01.040]   I think we lost a little bit of time, but let's say let's talk about capabilities,
[00:05:01.040 --> 00:05:07.040]   what we're seeing work in the market, and then maybe some advice on, like,
[00:05:07.040 --> 00:05:10.320]   what to build, if those are, you know, a question you're considering.
[00:05:10.320 --> 00:05:16.400]   I think the shorthand that we're going to use in this presentation is, like, cursor for X, right?
[00:05:16.400 --> 00:05:18.960]   And I do think that's a really massive opportunity.
[00:05:18.960 --> 00:05:23.520]   The first thing in capability for this past year is clearly reasoning.
[00:05:23.520 --> 00:05:27.280]   Reasoning's a new vector for scaling intelligence with more compute.
[00:05:27.280 --> 00:05:31.120]   The labs are really excited about this because they get to spend more money and get more output.
[00:05:31.120 --> 00:05:37.600]   But we should also be really excited about this in terms of unlocking new capabilities, right?
[00:05:37.600 --> 00:05:42.480]   If you just put aside how it works, it's a confidence-boosting implementation detail.
[00:05:43.520 --> 00:05:45.360]   But we should expect more capability.
[00:05:45.360 --> 00:05:50.800]   You're unlocking a new set of use cases, like transparent, high-stakes decisions
[00:05:50.800 --> 00:05:52.320]   where showing the work matters.
[00:05:52.320 --> 00:05:56.000]   Sequential problems, problems where you need to do systematic search.
[00:05:56.000 --> 00:06:01.600]   I think this looks like a lot of problems that we're excited about and face in knowledge work every day.
[00:06:03.200 --> 00:06:09.680]   As you have just seen demos of and I'm sure are working on, given reasoning, people are really excited about agents.
[00:06:09.680 --> 00:06:17.760]   To put a -- you know, I want to do, like, the Steve Ballmer impression that's, like, "Agents! Agents! Agents! Agents! Agents! Agents!"
[00:06:17.760 --> 00:06:22.000]   But I -- you have to give me more than 12 minutes to, like, get that sweaty.
[00:06:22.000 --> 00:06:29.280]   But, like, the non-marketing definition that I think of is it's software that --
[00:06:31.040 --> 00:06:37.680]   it takes some set of steps. It, like, plans. It includes AI. It takes ownership of a task.
[00:06:37.680 --> 00:06:42.800]   And it can hold a goal in memory, you know, try different hypotheses, backtrack. It ranges from
[00:06:42.800 --> 00:06:48.320]   super sophisticated to super simple. Some of the tools that you might use to accomplish a task include
[00:06:48.320 --> 00:06:55.520]   other models or search. And largely, it's just, like, AI systems that do something. And that's not a chatbot
[00:06:55.520 --> 00:07:00.880]   that looks more like a colleague. And, you know, one thing that I think we have a really unique vantage
[00:07:00.880 --> 00:07:07.280]   point on is we back a small number of companies at Conviction, but we also run a grant program for AI
[00:07:07.280 --> 00:07:11.600]   startups. It's called Embed. We get thousands of applications every year. And it includes, like,
[00:07:11.600 --> 00:07:16.560]   user data and revenue data and, like, really amazing people. And the number of agent startups has gone
[00:07:16.560 --> 00:07:21.520]   up 50 percent over the last year. And a lot of them are working. Like, we do see stuff that's working
[00:07:21.520 --> 00:07:27.360]   in the real world. And that's super exciting. Other modalities are progressing, too. I'm sure a lot of
[00:07:27.360 --> 00:07:34.480]   people are using voice, video, image generation, even beyond, you know, Studio Ghibli. But you have
[00:07:34.480 --> 00:07:39.840]   companies like HeyGen and Eleven and Midjourney that are rocketing past 50 million of ARR. These are real
[00:07:39.840 --> 00:07:44.080]   businesses now. I want to see if I can quickly play for you.
[00:07:44.080 --> 00:07:50.400]   They told me to express myself. So I did. They told me to express myself. So I did. Now I'm banned
[00:07:50.400 --> 00:07:56.000]   from three coffee shops. Hands can hurt or heal. That's the difference between chaos and creation.
[00:07:56.000 --> 00:08:01.040]   So if you're wondering where Q3 is headed. So if you're wondering where Q3 is headed,
[00:08:01.040 --> 00:08:07.680]   here's the thing. Consistency always beats urgency. We've got the projections ready. And let's just say,
[00:08:07.680 --> 00:08:12.720]   it's looking solid. I would definitely recommend it to anyone. I would definitely recommend it to any.
[00:08:12.720 --> 00:08:18.160]   So I think, like, if you just are looking for artifacts of improvement, this is from a company
[00:08:18.160 --> 00:08:24.560]   called HeyGen. You can make clones of yourself, of fake people. And it's like you have gestures and
[00:08:24.560 --> 00:08:31.200]   expressions that reflect emotion and content now, right? So these models work together. And like,
[00:08:31.200 --> 00:08:34.800]   I don't know about you guys, but looking at that last gal, like, I feel influenced. I don't know what
[00:08:34.800 --> 00:08:40.160]   the bunny is, but I would buy it. And so I think, like, huge swaths of the economy are going to be
[00:08:40.160 --> 00:08:46.000]   affected by this sort of multimodality. Some investors or operators would say multimodality
[00:08:46.000 --> 00:08:50.960]   would just be for niche verticals that enterprises don't have. You know, your average enterprise doesn't
[00:08:50.960 --> 00:08:56.400]   have that much voice, video, image data today. But I think that changes, right? When you can do stuff with
[00:08:56.400 --> 00:09:02.640]   this data when it is structured and understood, there's more reason to capture it. And I think of, like,
[00:09:02.640 --> 00:09:06.880]   how much video do all of us watch every day? It's one of the highest bandwidth communication methods,
[00:09:06.880 --> 00:09:12.880]   and we're just going to use more of it. We think voice is where we're going to see applications first
[00:09:12.880 --> 00:09:19.040]   in business workflows, because it's already a very natural communication mode. So everything from
[00:09:19.040 --> 00:09:24.480]   medical consults to lead generation, places you already had business voice, you just couldn't scale it
[00:09:24.480 --> 00:09:29.120]   before. I think that's where we're going to see it first. But as these other modalities become
[00:09:29.120 --> 00:09:35.440]   more controllable and also less costly, we should see all of them. I think it's safe to say you can
[00:09:35.440 --> 00:09:40.800]   expect capability improvement in every part of the model layer, which is really exciting. A lot of people
[00:09:40.800 --> 00:09:47.360]   are talking about the data wall or, like, the end of AI summer. But for anybody who's building applications,
[00:09:47.360 --> 00:09:55.760]   I'm at least to tell you one person's opinion is not coming. And then, usefully for all of us,
[00:09:55.760 --> 00:10:03.920]   that market for model capabilities is getting more competitive, not less. Sam Altman himself, I think,
[00:10:03.920 --> 00:10:08.720]   said it best. Last year's model is a commodity, which is a scary thing for a model provider to say.
[00:10:08.720 --> 00:10:14.080]   Because last year's model is now pretty damn good, right? The numbers tell the story. GPT-4
[00:10:14.080 --> 00:10:19.760]   went from $30 per million tokens to $2 in about 18 months. The distilled versions of that are, like,
[00:10:19.760 --> 00:10:26.480]   now 10 cents. So we can really use them very broadly. If you look at this chart, green is Google,
[00:10:26.480 --> 00:10:32.000]   yellow is Anthropics. You see, you know, it's a real mix. This is data from Open Router. So thank you,
[00:10:32.000 --> 00:10:38.880]   Open Router for that. But you really saw Claude cut into OpenAI's market share and Google come
[00:10:38.880 --> 00:10:42.960]   roaring back with Gemini. This data is obviously a little biased because a lot of people just go
[00:10:42.960 --> 00:10:47.920]   direct to OpenAI. But if you're into multi-model, there really is a mix. And you do have credible new
[00:10:47.920 --> 00:10:53.040]   players like SSI and Thinking Machines, some of the best researchers in the business, with orthogonal
[00:10:53.040 --> 00:10:59.120]   technical approaches entering the fray as well. And I'm sure many of you have experimented with DeepSeq,
[00:10:59.760 --> 00:11:06.640]   coming out with releases of both base and reasoning models that are reasonably competitive with a
[00:11:06.640 --> 00:11:11.280]   claimed fraction of the training cost. Like, we should just assume that open source will do as
[00:11:11.280 --> 00:11:15.760]   open source does. And we can rely on the model market to compete for our business, which is really
[00:11:15.760 --> 00:11:21.680]   exciting. And so the view is plan for a world that is multi-model. Tools like Open Router or inference
[00:11:21.680 --> 00:11:28.560]   platforms like Base 10 help that, and I think, like, be comfortable with that. I am. Okay, so we have all
[00:11:28.560 --> 00:11:35.120]   this capability. Let's shift quickly to the application layer. We have to start with Cursor. A million to 100
[00:11:35.120 --> 00:11:41.040]   million of ARR in 12 months and half a million developers. I assume all of you. Zero sales people to
[00:11:41.040 --> 00:11:47.760]   start. That's not growth. That is a killer application. Cognition, which started with more autonomy, is already the top
[00:11:47.760 --> 00:11:52.000]   committer in many companies. Feeling a little threatened, but also excited because recruiting
[00:11:52.000 --> 00:11:57.520]   is hard. And then Windsurf, who's on a tear itself and really beloved, is being acquired by OpenAI for
[00:11:57.520 --> 00:12:03.600]   three billion dollars. So we know for sure that the labs don't think that they can just, you know, steamroll
[00:12:03.600 --> 00:12:12.480]   everyone. Right? Lovable and Bolt hit 30 million of ARR each in a handful of weeks, helping non-engineers
[00:12:12.480 --> 00:12:19.440]   vibe as well. So, you know, our ranks are expanding. And I think it's useful to just, like, analyze a little
[00:12:19.440 --> 00:12:28.640]   bit why code was first. Fundamentally, it is text with its, like, logical language with structure. Right? So much
[00:12:28.640 --> 00:12:34.240]   of coding is sophisticated boilerplate. Like, we all love engineering, but some of it is, like, craft work,
[00:12:34.240 --> 00:12:42.000]   not new algorithm work. You don't need AGI to write, like, an API endpoint or a React component.
[00:12:42.000 --> 00:12:48.400]   Second, you have deterministic validation. You can automatically check if code works. Run tests,
[00:12:48.400 --> 00:12:55.360]   compile, execute, do things developers would do. And third, researchers believe code is crucial for AGI.
[00:12:55.360 --> 00:13:02.400]   Right? So they poured resources into it. And code became a key benchmark and a training priority and
[00:13:02.400 --> 00:13:09.920]   an area for data collection. But I think the last point is the money point to me. Engineers built tools
[00:13:09.920 --> 00:13:14.800]   for engineers. They understood the workflow intimately, and that made all the difference. And that last part
[00:13:14.800 --> 00:13:20.320]   is the playbook for every other industry. I'm sure people are building things that serve beyond engineers.
[00:13:20.320 --> 00:13:26.400]   And I don't think the winners will just be AI experts learning those domains. They'll be customer-centric,
[00:13:26.400 --> 00:13:32.000]   like, problem-centric builders who understand AI and then redesign workflows from first principles around
[00:13:32.000 --> 00:13:38.560]   manipulating those models. And so I think that's really the opportunity to build Cursor for X. Let's think a
[00:13:38.560 --> 00:13:46.240]   little bit about what that means. Cursor is not a single model. You know, one model's doing diffs, one's doing merge, one's embedding the files.
[00:13:46.240 --> 00:13:53.440]   They manipulate and package up the context. They prompt the models very skillfully. They let engineers
[00:13:53.440 --> 00:13:59.280]   avoid repetitive tasks and standardize with things like Cursor rules. And then if you're using Cursor
[00:13:59.280 --> 00:14:04.320]   in a team or even yourself, regularly retrieval accuracy gets better the more you use it with coverage and
[00:14:04.320 --> 00:14:11.760]   freshness. And so all of this happens in a UX that makes sense. Right? Like, I use VS Code. I'm familiar with it. My shortcuts work.
[00:14:11.760 --> 00:14:18.960]   And they make it safe to say yes. Right? Like, green for add and red for subtract makes sense. I can
[00:14:18.960 --> 00:14:25.120]   scroll through it. And it's fast enough that I don't get frustrated. So my view is Cursor, if it's a wrapper,
[00:14:25.120 --> 00:14:32.880]   it's like a very nice, thick, perhaps 14 or 15 billion dollar wrapper. Right? It's like if your burrito was 80%
[00:14:32.880 --> 00:14:38.640]   wrap and 20% fill, but you got to choose the fill and there's like an empty, like an open market for fill.
[00:14:38.640 --> 00:14:44.480]   Right? And so where's the value now? It may not be in the protein. It's kind of in the company.
[00:14:44.480 --> 00:14:53.120]   So, like, if we try to generalize that recipe a little bit, if you are building a generic text box,
[00:14:53.120 --> 00:14:58.880]   like, unless you're just like learning to do this, please don't. Like, OpenAI already won that.
[00:14:58.880 --> 00:15:03.360]   Or it's just not very valuable to do so. Your domain knowledge, your workflow knowledge can be the
[00:15:03.360 --> 00:15:10.240]   bootstrap. If you already know what users in your industry need, don't make them explain it. Build
[00:15:10.240 --> 00:15:14.960]   products that show up informed. They collect and package context automatically, including from other
[00:15:14.960 --> 00:15:19.760]   sources, not just natural language. Present it to the models. Use the right models at the right time,
[00:15:19.760 --> 00:15:25.760]   now known as orchestration, and present the outputs to the users thoughtfully. Right? So I do not think
[00:15:25.760 --> 00:15:30.880]   this is the end of the GUI. I think you can capture and enable workflow with these models. And all this
[00:15:30.880 --> 00:15:36.560]   requires taste and a ton of work. I'd argue that, like, some version of this recipe is much of the work
[00:15:36.560 --> 00:15:42.960]   each of us is going to do. So don't listen to the labs from a user experience perspective. The prompt is a bug,
[00:15:42.960 --> 00:15:48.640]   not a feature. I think it's like a stepping stone. Don't make me think as a user. The best AI products,
[00:15:48.640 --> 00:15:53.760]   they feel like mind reading because they are. There's enormous headroom in building these products,
[00:15:53.760 --> 00:15:57.040]   and I think that's really exciting because that's what most of us in this room have alpha on.
[00:15:57.040 --> 00:16:05.360]   What is a software company if not a very thick workflow wrapper most of the time? That was true in 2015.
[00:16:05.360 --> 00:16:14.960]   It's true in 2025. Besides code, where might you go apply this? We think the opportunities to build value
[00:16:14.960 --> 00:16:21.040]   around the LLMs exist in every vertical and profession. But here's something counterintuitive.
[00:16:21.040 --> 00:16:25.600]   Beyond coding, one of the things that I've been surprised by is that the most conservative,
[00:16:25.600 --> 00:16:31.040]   low-tech industries seem to be adopting AI fastest. We call this the AI leapfrog effect internally.
[00:16:31.040 --> 00:16:38.720]   These are three portfolio companies. They're working. Sierra resolves 70% of customer service queries
[00:16:38.720 --> 00:16:46.800]   for their customers. They serve people that you guys use, like SiriusXM or ADT. Harvey is two years in,
[00:16:46.800 --> 00:16:52.960]   well over 70 million of ARR. Its AI is essential now to being competitive in the legal industry.
[00:16:52.960 --> 00:16:58.960]   There's a company called Open Evidence, which helps doctors stay up to date with medical research.
[00:16:58.960 --> 00:17:04.080]   You have to be a clinician to use it, but you give it your medical ID number, and you can do intelligent
[00:17:04.080 --> 00:17:11.840]   search against medical research at the point of clinical decision making. Today, it reaches a third
[00:17:11.840 --> 00:17:17.760]   of doctors in the U.S. weekly, and the average user uses it daily, right? And so I think there's just
[00:17:17.760 --> 00:17:24.720]   examples of huge value beyond ChatGPT. These are companies that know their customer and solving real
[00:17:24.720 --> 00:17:30.800]   problems. As a piece of trivia that you may or may not know, Brett at Sierra is the chairman of the
[00:17:30.800 --> 00:17:40.080]   board at OpenAI. OpenAI was Harvey's seed investor, and if these people are not fretting about thin
[00:17:40.080 --> 00:17:42.000]   wrappers, I suggest you don't either.
[00:17:43.200 --> 00:17:48.400]   Okay. Finally, I'll make an observation. A lot of people are excited about full automation. Now I'm
[00:17:48.400 --> 00:17:54.240]   sweaty enough, so agents, agents, agents, agents, agents, agents. But when we analyzed the applications
[00:17:54.240 --> 00:18:01.040]   to embed, I said, you know, it's gone up to 50 percent, you know, doubling applications for agentic
[00:18:01.040 --> 00:18:07.760]   startups in the last year. I think some people think copilots are yesterday's news. They want to get to
[00:18:07.760 --> 00:18:13.840]   the endgame, right? Like, you know, your colleague and AGI. But in terms of what works, like the data
[00:18:13.840 --> 00:18:19.120]   on what's driving revenue, I think copilots are still really underrated. We see a whole spectrum
[00:18:19.120 --> 00:18:25.760]   of how much automation. And I think the Iron Man analogy is still really great here. Tony Stark's Iron
[00:18:25.760 --> 00:18:30.880]   Man suit augments him, right? He can do all these amazing things, but could also fly around on command,
[00:18:30.880 --> 00:18:36.480]   could do some basic tasks without Tony. And my experience with these companies has been that human
[00:18:36.480 --> 00:18:42.720]   tolerance for failure or hallucinations or lack of reliability, it just reduces dramatically as latency
[00:18:42.720 --> 00:18:48.960]   increases, right? So the path of least frustration today for many domains is to build great augmentation
[00:18:48.960 --> 00:18:54.720]   and then just ride the wave of capability because we know it's coming. And so my advice for many domains
[00:18:54.720 --> 00:19:00.480]   would think about, like, build the suit and you can extend out to the suit that flies on its own once
[00:19:00.480 --> 00:19:08.000]   Tony or any of us is wearing it. I'm not going to go through each of these, mostly because I lost time,
[00:19:08.000 --> 00:19:13.840]   but there are a ton of opportunities. We put requests for startups on our website. We're interested in a
[00:19:13.840 --> 00:19:22.000]   couple different categories of things. They go from, like, just good fit for purpose, like the law is a
[00:19:22.000 --> 00:19:28.880]   space of lots of text generation, right? To things that weren't possible before AI. My partner, Mike,
[00:19:28.880 --> 00:19:34.080]   will say, like, this is a really interesting era of machines interrogating humans. What can you do if
[00:19:34.080 --> 00:19:40.640]   you can go, like, collect data on demand from people? We could talk to every customer, not just the top 5% by
[00:19:40.640 --> 00:19:47.920]   contract value. We could root cause every alert proactively, right? Versus, like, just firefight.
[00:19:47.920 --> 00:19:52.960]   And the mental model is how can you build as if you had an army of compliant, infinitely patient
[00:19:52.960 --> 00:20:01.840]   knowledge workers. You know, one aside here is I think there are many hard problems where, like,
[00:20:01.840 --> 00:20:06.720]   the basic premise is the answer to them is not in common crawl, right? The reasoning around them is not in
[00:20:06.720 --> 00:20:14.160]   common crawl. So this would be robotics, biology, material science, physics simulation. They require
[00:20:14.160 --> 00:20:20.320]   clever data collection, probably interaction with atoms, not just bits. Super scary for a software
[00:20:20.320 --> 00:20:25.520]   person, but I think the juice is worth the squeeze, right? The same reasoning that crushes math olympiads
[00:20:25.520 --> 00:20:30.640]   can seemingly navigate molecular space, and I think there are some really fundamental questions for human
[00:20:30.640 --> 00:20:35.520]   society that can be answered when people work on these problems. And it's really cool as a machine
[00:20:35.520 --> 00:20:41.120]   learning person to meet people in their, at the top of their field at the intersection of machine
[00:20:41.120 --> 00:20:45.840]   learning in all of these other areas because, like, you guys would also understand, the same architectures
[00:20:45.840 --> 00:20:49.200]   apply, right? And that's just, that's really exciting.
[00:20:53.040 --> 00:20:56.880]   How should we think about defensibility to this advance?
[00:20:56.880 --> 00:21:05.520]   Okay. So one last point, and then I'll conclude here. Some would say stay out of the weight of the
[00:21:05.520 --> 00:21:10.880]   labs, don't pick up pennies in front of the steamroller, right? But I would offer what I think is an
[00:21:10.880 --> 00:21:18.080]   uncomfortable truth. Execution is the moat in AI, and that's available to all of us. Cursor arguably did not
[00:21:18.080 --> 00:21:22.160]   invent code completion, they did not invent the model, they didn't invent their product surface
[00:21:22.160 --> 00:21:27.360]   area, right? They just out-executed on every dimension of this. They shipped a great experience
[00:21:27.360 --> 00:21:31.760]   faster than their competitors could copy, and they captured the hearts and minds of developers, at least
[00:21:31.760 --> 00:21:38.560]   in this term. I don't mean this to be cruel, but I often get asked about, like, counter cases and the
[00:21:38.560 --> 00:21:43.920]   importance of first-mover advantage. Let's be brutally honest. In contrast, like, Jasper had first-mover
[00:21:43.920 --> 00:21:50.720]   advantage brand that raised $125 million, but its first product was a series of prompts in a text box
[00:21:50.720 --> 00:21:56.240]   and, like, very good SEO, and, like, you have to keep running. Like, ChatGPT, you know, crushed the first
[00:21:56.240 --> 00:22:01.440]   iteration pretty quickly. And so I don't think this is satisfying advice, but I think it is, like, real from
[00:22:01.440 --> 00:22:07.520]   the trenches. Build something thick and stay ahead, and, like, no domains are out of question. Magical AI
[00:22:07.520 --> 00:22:13.520]   experiences, they build customer trust and drive adoption. And a lot of the data we need to improve
[00:22:13.520 --> 00:22:20.000]   these experiences and the context we need, it is not easily available today. And that advantage is,
[00:22:20.000 --> 00:22:23.520]   you know, open for the taking and not for the labs.
[00:22:23.520 --> 00:22:31.120]   So I guess in conclusion, I think the opportunity is early and really massive. Like, I've made a career bet
[00:22:31.120 --> 00:22:36.720]   on it. I think many of you are. We're in the dial-up era of AI, and we're moving pretty quickly to
[00:22:36.720 --> 00:22:41.920]   broadband. Instagram came four years after the iPhone. Like, I was there when Greylock made that
[00:22:41.920 --> 00:22:47.280]   investment. Uber, five years. DoorDash, six, right? So the truly transformative companies,
[00:22:47.280 --> 00:22:53.200]   they weren't necessarily the first people to recognize the changes or the opportunity. It was
[00:22:53.200 --> 00:22:58.000]   those who reimagined the experiences. And the game board keeps getting shaken up. That's the thing that's
[00:22:58.000 --> 00:23:04.240]   different this time, right? It's like getting a new iPhone. That's actually different every 12 months.
[00:23:04.240 --> 00:23:09.840]   And so you have, like, new model release, new capability breakthrough, you know, one-tenth the cost.
[00:23:09.840 --> 00:23:15.280]   And every time the game board turns, I think there are, like, there's an opportunity to to win again.
[00:23:15.280 --> 00:23:21.040]   Okay, so I'll give you one last sentence and be chased off the stage. This was not my fault.
[00:23:21.040 --> 00:23:25.680]   Here's what I really want you to remember. You, as the engineers, got the magic first.
[00:23:26.240 --> 00:23:32.000]   The anthropic, like, economic index says that 40% of use was still coding. That's not, like,
[00:23:32.000 --> 00:23:37.520]   40% of the economic opportunity in the world, right? And so it is the job of everyone in this room
[00:23:37.520 --> 00:23:41.840]   and, you know, globally online to be the translators for the rest of the world. So I encourage you to
[00:23:41.840 --> 00:23:51.360]   build something revolutionary. Thanks.

