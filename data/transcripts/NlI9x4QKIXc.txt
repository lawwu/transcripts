
[00:00:00.000 --> 00:00:05.440]   Awesome. All right. Hey everyone, I'm here with Chris 50 who just came up to the
[00:00:05.440 --> 00:00:08.280]   way it's in by says booth and started giving a bunch of feedback and said hey
[00:00:08.280 --> 00:00:11.360]   let me just interview Chris welcome thanks for coming tonight. Thank you.
[00:00:11.360 --> 00:00:15.680]   You tell me about yourself your area of research what do you do kind of your
[00:00:15.680 --> 00:00:21.280]   work history some stuff yeah definitely previously I was a research researcher
[00:00:21.280 --> 00:00:25.280]   at Google brain for several years and then I returned to academia now I'm a
[00:00:25.280 --> 00:00:30.080]   PhD at Stanford Stanford doing deep learning research for drug discovery as
[00:00:30.080 --> 00:00:35.640]   well as metal learning that's awesome so what kind of you started already telling
[00:00:35.640 --> 00:00:41.000]   me but I would love to hear some stuff that you use feedback that would be
[00:00:41.000 --> 00:00:44.160]   super cool for us I guess since I'm a little older like I've seen the whole
[00:00:44.160 --> 00:00:47.600]   pipeline so I saw a tensor board that's a boy yeah all the tools we had in turn
[00:00:47.600 --> 00:00:51.160]   like Google and it's really cool to see like that natural evolution between okay
[00:00:51.160 --> 00:00:55.040]   maybe you can like print out like the different metrics you care about to
[00:00:55.040 --> 00:00:58.440]   visualizing the more intensive board now to like a whole platform like weights
[00:00:58.440 --> 00:01:01.440]   and biases where everything is just like beautifully visualized you can do a
[00:01:01.440 --> 00:01:05.240]   hyper parameter searches it seems to be like my all-in-one like plug-and-play
[00:01:05.240 --> 00:01:09.200]   paradigm for just like tuning the model seeing like which models do better than
[00:01:09.200 --> 00:01:13.000]   others and even like figuring out which ones you should actually sort of take
[00:01:13.000 --> 00:01:15.880]   further when you're actually sort of doing that research iteration it just
[00:01:15.880 --> 00:01:17.480]   makes things so much easier that's awesome
[00:01:17.480 --> 00:01:21.400]   do you use reports at all I don't you don't I do the visualizations I do the
[00:01:21.400 --> 00:01:26.560]   hyper parameter tuning maybe I've only been using it a year but yeah those
[00:01:26.560 --> 00:01:30.280]   humanities for just report is the feature where it's basically like a blog
[00:01:30.280 --> 00:01:34.080]   blog platform you can use markdown you can do like table of contents for
[00:01:34.080 --> 00:01:38.400]   everything you do and then you can add tables from your runs like live tables
[00:01:38.400 --> 00:01:41.960]   and when you share with your teammates they update live see on the fly I don't
[00:01:41.960 --> 00:01:45.160]   have teammates so it's just like I'm working by myself all right I see the
[00:01:45.160 --> 00:01:49.240]   visual social media I guess for a blog though yeah I work on the blog
[00:01:49.240 --> 00:01:53.360]   absolutely so thanks for coming I wanted one thing to ask you yeah you mentioned
[00:01:53.360 --> 00:01:55.880]   like the hyper parameter search the different methods could you talk about
[00:01:55.880 --> 00:01:59.320]   those yeah grid search random search Bayesian optimization everyone has their
[00:01:59.320 --> 00:02:02.440]   own like favorite ways to do hyper parameter tuning and especially like
[00:02:02.440 --> 00:02:05.960]   when you train these like massive models yeah you really only like hyper
[00:02:05.960 --> 00:02:10.360]   parameter tune for one epoch two epochs just because they're so big it's
[00:02:10.360 --> 00:02:14.920]   infeasible to tune them for so long so basically having the capacity to
[00:02:14.920 --> 00:02:19.600]   reproduce research code which also sort of follows these three different
[00:02:19.600 --> 00:02:23.560]   paradigms of random grid search or random search grid search and then
[00:02:23.560 --> 00:02:27.220]   Bayesian optimization it gives me a lot of confidence to basically say okay I'm
[00:02:27.220 --> 00:02:30.500]   ascribing to best research paradigms or even if I'm just trying to like push to
[00:02:30.500 --> 00:02:33.860]   say the art more and even for my own personal projects where I use machine
[00:02:33.860 --> 00:02:38.560]   learning outside of my work for research well it's awesome taxi like drive that
[00:02:38.560 --> 00:02:40.960]   for it and like have confidence that like I don't need to set up a
[00:02:40.960 --> 00:02:44.560]   optimization it works I can just like say here's the metric I care about
[00:02:44.560 --> 00:02:48.400]   optimize for it come back a week later and I have a great model that's so great
[00:02:48.400 --> 00:02:53.320]   and what's the biases gives you the the freedom to kind of choose between all
[00:02:53.320 --> 00:02:57.880]   these and the best practices that like all these big companies also use that's
[00:02:57.880 --> 00:03:01.160]   great so thank you for coming up and giving us a feedback what is one thing
[00:03:01.160 --> 00:03:04.400]   that you would like to improve like just of the top of your head was the you use
[00:03:04.400 --> 00:03:07.640]   it every day I think you said what's like one piece of like feedback you can
[00:03:07.640 --> 00:03:11.480]   give us that's annoying to you that we can fix or we can we can tell our
[00:03:11.480 --> 00:03:16.040]   engineers to fix I guess like sometimes I see like a surprisingly good model
[00:03:16.040 --> 00:03:19.760]   that I didn't think would be surprisingly good I wish like sometimes
[00:03:19.760 --> 00:03:23.840]   I could just like add a note to it other than like renaming it no there's a tax I
[00:03:23.840 --> 00:03:28.760]   guess I'm not like we're getting voices behind the tags you can tag you can add
[00:03:28.760 --> 00:03:32.560]   them to the model registry you can like a text specific runs yeah absolutely you
[00:03:32.560 --> 00:03:35.000]   guys already have it then we have a bunch of folks here who will teach you
[00:03:35.000 --> 00:03:38.680]   about like other stuff yeah even though you're one of the cooler users naive
[00:03:38.680 --> 00:03:41.800]   user naive user naive user thank you for coming out thank you for your feedback
[00:03:41.800 --> 00:03:46.320]   thank you thank you so much great platform

