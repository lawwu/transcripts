
[00:00:00.000 --> 00:00:03.200]   Nick, these guys are low energy today. You notice that? You know what we need to do? We
[00:00:03.200 --> 00:00:07.120]   need to gamble. Let's do it, Nick. Let's play a hand of blackjack. Let's get these guys.
[00:00:07.120 --> 00:00:12.880]   Gentlemen, what an absolute pleasure to walk amongst some goddamn greats. Let me see if I
[00:00:12.880 --> 00:00:18.080]   can put a bit of pip in your step with a one time blackjack hand to kickstart one of the greatest
[00:00:18.080 --> 00:00:23.280]   podcasts on earth. It is I can't confirm this is not a lie. You did this. We're going to rock and
[00:00:23.280 --> 00:00:31.600]   roll proper today. Let's go. All right. This guy on right now. Mate, you are going you I'm actually
[00:00:31.600 --> 00:00:36.800]   breaking my own rules for you guys. I filmed today's hand day 14. But I'm going to film
[00:00:36.800 --> 00:00:43.760]   tomorrow's hand for you guys right now. It'll roll out this week. Hold on. Hold on. Wait a
[00:00:43.760 --> 00:00:50.000]   minute, Tim. You are a Kiwi living in Calgary. Is that right? Yeah, correct. Yep. Kiwi living
[00:00:50.000 --> 00:00:55.200]   in Calgary. Been here since September 2022. The missus and I. Oh, my God, this is awesome.
[00:00:55.200 --> 00:01:01.840]   Welcome to my country. Welcome to the party. I don't know how I stumbled across you somewhere.
[00:01:01.840 --> 00:01:06.640]   And I started watching all your videos on Instagram. They were off the hook, man. Congrats.
[00:01:06.640 --> 00:01:10.320]   They're awesome. Thank you. So much fun. Where where in New Zealand are you from?
[00:01:10.320 --> 00:01:15.600]   From Taranaki. So West Coast, North Island, certainly not somewhere. It's not a holiday
[00:01:15.600 --> 00:01:19.920]   destination for certain if you're going it's like dairy farming country. It's it's beautiful, but
[00:01:19.920 --> 00:01:24.560]   it's off the beaten path. So, yeah. And how did you how did you choose Calgary of all places in
[00:01:24.560 --> 00:01:31.200]   Canada? Do you know what the missus we holiday here? My fiance and I may 2022. And we thought
[00:01:31.200 --> 00:01:36.640]   it was just gonna be a holiday then back to the farm. But I guess we had that COVID cabin fever
[00:01:36.640 --> 00:01:41.120]   like the rest of the world and loved our time here so much that we just decided before we even
[00:01:41.120 --> 00:01:46.960]   finished the holiday that we cracked on to get now visas and go back, sold up my livestock and
[00:01:46.960 --> 00:01:51.840]   leased the farm back to me parents and and made the move and we haven't looked back. I don't think
[00:01:51.840 --> 00:01:56.480]   they'll be seeing me pulling tits on the dairy farm anytime soon. I'll call it real for by the
[00:01:56.480 --> 00:02:04.560]   way. So lads, what do we want to do here? We want to put 10k and then give it to one of Tim's mates
[00:02:04.560 --> 00:02:09.280]   who's stuck or something. How do we do this? We Mr. Beast this we give 10k to the next time you
[00:02:09.280 --> 00:02:13.120]   get coffee if we win? When you give it to the barista or something? What should we do? Yeah,
[00:02:13.120 --> 00:02:18.400]   let's do it. Let's do it. Let's do a 10k free roll for Tim and his fans. Okay, okay. So now
[00:02:18.400 --> 00:02:24.160]   do you want me to add that to my bit for this? Yes, absolutely. We want to be one in 10k sweat
[00:02:24.160 --> 00:02:30.720]   with you. One and done is absolutely the the way to go. There we go. First part we've got to do
[00:02:30.720 --> 00:02:35.680]   here is pick out these real dealers. Are these AI? No, these definitely are real dealers that
[00:02:36.400 --> 00:02:40.320]   certainly Eastern European as far as I know, I don't know what the quality of life is like.
[00:02:40.320 --> 00:02:45.840]   I imagine that warehouse somewhere and put on the tools. Now I had a I went with a with a young
[00:02:45.840 --> 00:02:49.760]   lassie today and she roll ball and asked me so I'm going back to the point because they've been
[00:02:49.760 --> 00:02:56.240]   good to me. Yeah. Somebody who feels blue collar who wants to work for us. We need somebody who's
[00:02:56.240 --> 00:03:03.200]   a worker. And you have over a million followers now watching this. Yeah. 15,000 to 1.3 million
[00:03:03.200 --> 00:03:08.480]   in this entire journey. So yeah, a little bit nonsensical. But okay, this this looks like a good
[00:03:08.480 --> 00:03:13.840]   he looks like he's gonna work for us. You're gonna you're gonna copy it live as I do it.
[00:03:13.840 --> 00:03:21.840]   Alrighty. It is day 15. Got a blackjack committee once in three or I've got we have a $14,000 bit
[00:03:21.840 --> 00:03:27.840]   going on for me personally, but I actually have some absolute legends with me today. I'm bidding
[00:03:27.840 --> 00:03:31.280]   for the besties from the oil and podcasts as well. They're going to bring the luck. I think
[00:03:31.280 --> 00:03:38.480]   been rolled bold enough by a young lessee yesterday with $34,000 goes on the line.
[00:03:38.480 --> 00:03:43.280]   You guys want 10,000. All right. Oh, 20. Geez, I better not not take it. Put a stop for 10%.
[00:03:43.280 --> 00:03:50.320]   24,000 is going on the line. Our dealer looks like the kind of bloke who stops at red lights
[00:03:50.320 --> 00:03:55.520]   playing GTA. We won't hold that again. If you will, I need to see good God.
[00:03:55.840 --> 00:03:56.320]   Jackie
[00:03:56.320 --> 00:04:21.200]   I know he's doing for us. I can't believe we've just pulled that off.
[00:04:21.920 --> 00:04:28.640]   Oh, did that? Gentlemen, that is really just happened. You've just turned 10 at the 25.
[00:04:28.640 --> 00:04:31.920]   Holy, holy cow.
[00:04:31.920 --> 00:04:41.200]   Look, it's like doing this for the whole tape. That's amazing for another round.
[00:04:41.200 --> 00:04:46.000]   We turned 10 to 25. All right. So are we gonna have a separate all in balance? We just keep
[00:04:46.000 --> 00:04:51.840]   rolling it every week. Yeah. Can you come back next week? And can we just keep
[00:04:51.920 --> 00:04:57.760]   rolling it every week? We might have to. That is, I cannot believe we've just blackjacked.
[00:04:57.760 --> 00:05:05.440]   That is unbelievable. Well, Tim, have a good day. All right, Tim, you are a legend. Everybody
[00:05:05.440 --> 00:05:10.640]   follow Tim on Instagram. Let's get him to 10 million. Let's get, I mean, you have a future
[00:05:10.640 --> 00:05:17.200]   in broadcasting. You are going to make millions. You went from the farmhouse. Oh yeah, literally.
[00:05:17.200 --> 00:05:21.600]   And here we go. Now you're going to be running a casino. I think you should have Tim's
[00:05:21.600 --> 00:05:27.120]   blackjack. You should have your own brand. We could build a whole brand on this. Tim.Naki on
[00:05:27.120 --> 00:05:32.800]   Insta. Tim.Naki. I wouldn't have to run anything if I can just play one-handed blackjack with you
[00:05:32.800 --> 00:05:38.560]   guys and I'd land Jack Ace every week. That is unbelievable. And like we said, that 15K we won.
[00:05:38.560 --> 00:05:44.480]   That's yours for you and the misses. Go on vacation. No, no, no, no. We said it. We said it.
[00:05:44.480 --> 00:05:50.080]   We want you to do something. Go with it. We're already cashed up. You take that 15K. You take
[00:05:50.080 --> 00:05:55.680]   the misses out. You get some first class tickets. You meet Chamath in Italy and then let's go.
[00:05:55.680 --> 00:06:00.160]   That's it. How about I go first class to the Orland Summit now that now these are done.
[00:06:00.160 --> 00:06:05.120]   We could play some. Oh, we could have a whole session. We may or may not have a,
[00:06:05.120 --> 00:06:08.960]   have a fun casino night there. So this will be fun. Yeah. You got to come to the Orland Summit
[00:06:08.960 --> 00:06:14.320]   for sure. Yeah. Get the misses, take the 15K, two first class tickets, get yourself set up in a nice
[00:06:14.320 --> 00:06:19.360]   hotel and we will see you there. All right, everybody, let's get to the docket. Well done.
[00:06:19.360 --> 00:06:26.320]   Tim. Thank you, Tim. See you later. I can't believe they have live dealers standing in a
[00:06:26.320 --> 00:06:31.280]   warehouse in front of a webcam. I don't. That, that is such a like, imagine walking into that
[00:06:31.280 --> 00:06:37.600]   facility. You're surprised that facility only has what dealers. I think there's a lot of webcams
[00:06:37.600 --> 00:06:44.640]   there. I think you can choose a door of what you want to do. Or whatever else you want. Whatever
[00:06:44.640 --> 00:06:48.720]   else you want to be on a webcam. You'll be doing jewelry, probably making a porno in the next room.
[00:06:48.720 --> 00:06:54.400]   Above the table and below the table. There's two different tapings occurring.
[00:06:54.400 --> 00:07:04.000]   Oh my God. Well, that's rough. That was so awesome. So what happened? You DM'd him?
[00:07:04.000 --> 00:07:07.680]   That was so good. Yeah, we, he, you know what, no, what happened was somebody emailed me and
[00:07:07.680 --> 00:07:12.080]   they're like, Hey, that's my mate that you talked about. He's a big fan of the show. It turns out,
[00:07:12.080 --> 00:07:16.720]   you know, this is the thing about influencers. Now this is the thing about this micro celebrity
[00:07:16.720 --> 00:07:23.920]   stuff. We all, we all know each other by default. Right? So he was just slid into the DMs.
[00:07:23.920 --> 00:07:28.160]   There's definitely camaraderie. Yeah, that was awesome. That's awesome. I'm so glad he won.
[00:07:28.160 --> 00:07:33.200]   And, uh, you know, he, he basically got smashed in his DMs. Like 1000 people DM'd him. Oh,
[00:07:33.200 --> 00:07:37.520]   you're on all in. They're bugging out to you on all in. And, uh, so yeah, I just said, Hey,
[00:07:37.520 --> 00:07:40.160]   would you do a hand? Would you do your live hand with us? And then I didn't,
[00:07:40.720 --> 00:07:44.160]   I didn't, I want it to clear with you guys before I put our money on it or whatever,
[00:07:44.160 --> 00:07:47.680]   but I couldn't do that. Cause I wanted to surprise you. Yeah, but here we are.
[00:07:47.680 --> 00:07:50.880]   I did not think that was real when he popped up. I thought it was like a recording tech.
[00:07:50.880 --> 00:07:57.040]   Yeah. All I could think of was, do I look like an ass by saying more so that I just stay quiet?
[00:07:57.040 --> 00:08:03.280]   I was like, well, you know, I start with 50 K let's just see what happens.
[00:08:03.280 --> 00:08:08.320]   I know you're a feel like when you like tiptoe into the bat with like a small amount, but you're,
[00:08:08.320 --> 00:08:12.560]   you want to do more and then you win and you feel like you actually lost money because
[00:08:12.560 --> 00:08:25.920]   I lost 60 K. I would have put 50. I would have won 75 instead. We put 10, we won 15.
[00:08:25.920 --> 00:08:51.520]   I lost 60. I don't know what's going on. Anything going on in your life? Anybody
[00:08:52.800 --> 00:08:58.560]   been busy having some adventure sacks? Seems like you were busy last week. Any,
[00:08:58.560 --> 00:09:00.720]   anything to report from your side of the world?
[00:09:00.720 --> 00:09:05.200]   Well, should we take you, take you guys behind the scenes of a presidential fundraiser? I admit,
[00:09:05.200 --> 00:09:09.920]   I've never done one before. So it was, it was a new experience for me. When you host a president,
[00:09:09.920 --> 00:09:14.640]   it's just a whole different level of preparation. The secret service was out like a week before the
[00:09:14.640 --> 00:09:19.360]   president has an amazing advanced team. They work out every detail. They make a map of your house.
[00:09:19.360 --> 00:09:23.200]   So they really have to think through everything. The police shut down the street.
[00:09:23.200 --> 00:09:27.280]   It's really a very involved process.
[00:09:27.280 --> 00:09:34.240]   By the way, I went to dinner in the city that night and you know, I was right by your house.
[00:09:34.240 --> 00:09:38.800]   So I drove up the street and they had everything blocked off on like three blocks on both streets,
[00:09:38.800 --> 00:09:43.520]   like on both sides of your house. But there were all these protesters, like all throughout San
[00:09:43.520 --> 00:09:48.720]   Francisco, like pro Trump people had driven in from all over NorCal must've been, cause these
[00:09:48.720 --> 00:09:53.520]   were not supporters supporters. Yeah. And they came in with these like cars and the streets were
[00:09:53.520 --> 00:09:59.600]   blocked. It was a total zoo in the city for hours before and after your, I actually stayed in the
[00:09:59.600 --> 00:10:05.760]   city that night and I heard the people going nuts for hours afterwards, but it definitely like took
[00:10:05.760 --> 00:10:10.160]   over. It took over the city. Yeah. So what's really interesting is that all week, the San Francisco
[00:10:10.160 --> 00:10:14.880]   publications had been trying to gin up protesters by writing about that, you know, the president's
[00:10:14.880 --> 00:10:20.720]   coming to town and protesters are going to show up. And in fact, there was almost no anti-Trump
[00:10:20.720 --> 00:10:26.160]   protesters. And then a huge number of pro Trump demonstrators came out and they were waving flags
[00:10:26.160 --> 00:10:32.640]   and cheering along his motorcade as he was coming to the house. So the whole protest thing backfired.
[00:10:32.640 --> 00:10:38.560]   Why do you think anti-Trump protesters did not show up? What happened?
[00:10:38.560 --> 00:10:43.120]   I think there's just a big enthusiasm gap. I mean, I think that the pro Trump people are
[00:10:43.120 --> 00:10:49.120]   very enthusiastic and the let's call pro Biden or anti-Trump people are just not very motivated
[00:10:49.120 --> 00:10:54.560]   right now. So it's exhausting to be against Trump for eight years. Like this has been exhausting.
[00:10:54.560 --> 00:10:58.000]   People are wiped out. I think they've exhausted folks. It's a losing proposition.
[00:10:58.000 --> 00:11:03.520]   So anyway, so Owen McCabe, who's the founder of Intercom, he was there. And I think this was
[00:11:03.520 --> 00:11:08.800]   actually a good summary because he said that he spoke with a bunch of people and none of
[00:11:08.800 --> 00:11:13.520]   them identifies Republican, all voted or donated Democrat in the past. That's true for me too.
[00:11:13.520 --> 00:11:18.160]   Now they're backing this guy for his policies on war, immigration, crypto, and more.
[00:11:18.160 --> 00:11:23.360]   This election is referendum on those issues. So Owen came out, appreciate his support. But it's
[00:11:23.360 --> 00:11:28.000]   true. The campaign told us that they had more first-time donors at this event than they've
[00:11:28.000 --> 00:11:33.760]   seen before. And that's because a lot of these people hadn't supported Republicans or hadn't
[00:11:33.760 --> 00:11:37.760]   supported Trump and they came out. So we have a few photos and videos here to take you behind
[00:11:37.760 --> 00:11:42.720]   the scenes. I think that might be interesting for people. So the first thing to say is that
[00:11:42.720 --> 00:11:47.040]   President Trump is extremely charming. He connects with people in like five seconds. I mean,
[00:11:47.040 --> 00:11:54.160]   he meets you and find something interesting or funny to say. And he's hilarious. I mean,
[00:11:54.160 --> 00:12:01.120]   when he spoke in the living room and he talked extemporaneously for an hour, he's speaking off
[00:12:01.120 --> 00:12:07.920]   the cuff. Every speech he gives is different. This is him coming into the living room. He had made
[00:12:07.920 --> 00:12:12.640]   just a few notes about topics he wanted to talk about on a piece of paper, but that was it. It
[00:12:12.640 --> 00:12:17.840]   was all completely extemporaneous. No teleprompter, obviously. And he's hilarious. I mean, people
[00:12:17.840 --> 00:12:23.440]   don't realize how entertaining he is. What were some of the greatest hits? What did he hit on?
[00:12:23.440 --> 00:12:30.480]   Did he hit on low pressure from showers? Did he? Because I know he's got like some things he hits
[00:12:30.480 --> 00:12:36.160]   on that are relatable. Was it all like, specific crypto topics, tech topics? Or did he go?
[00:12:36.160 --> 00:12:41.520]   Well, he did, you know, he did talk crypto. And it was really interesting. At one point,
[00:12:41.520 --> 00:12:46.400]   in his speech, he called on the Winklevoss brothers who were there. And I'm only mentioning
[00:12:46.400 --> 00:12:50.480]   this because it was already reported that they were there. So I don't want to speak out of school.
[00:12:50.480 --> 00:12:56.640]   But he said to them, he says, I know you guys created Facebook. He was giving them credit for
[00:12:56.640 --> 00:13:02.880]   creating Facebook. And he said, but but it's okay. I mean, you guys look like models. You were dealt
[00:13:02.880 --> 00:13:10.240]   a lot of cards, you know, a lot of cards. I mean, they're very good looking, huge IQ. And I mean,
[00:13:10.240 --> 00:13:15.600]   looking great. And so I thought, okay, wow, like, he must know the Winklevoss brothers. He must have
[00:13:15.600 --> 00:13:20.720]   met them previously. And I found out this the first time that he had ever met them. So think
[00:13:20.720 --> 00:13:25.360]   about the awareness that he has to know that they're in the audience to see them, point them
[00:13:25.360 --> 00:13:29.760]   out and then have this kind of hilarious routine with them. So he's someone who's very sharp,
[00:13:29.760 --> 00:13:37.040]   very on the ball, very funny. And then his energy levels incredible. So he had started his day at
[00:13:37.040 --> 00:13:44.400]   Mar-a-Lago at 3.30am pacific time, 6.30am his time, then he flew to Arizona, did a Trump rally in
[00:13:44.400 --> 00:13:50.800]   Arizona. Then he flew to San Francisco for our event. He spent four hours at our event, he could
[00:13:50.800 --> 00:13:56.400]   have left an hour earlier if you wanted to, then he flew to LA for more events the next day there.
[00:13:56.400 --> 00:14:01.520]   So think about his day. And his energy level was just amazing the whole time.
[00:14:01.520 --> 00:14:04.160]   Chamath your thoughts before this goes on for an hour.
[00:14:04.160 --> 00:14:13.760]   Yeah, I'll give you two observations. The first is that I think that there is a huge gap
[00:14:15.680 --> 00:14:24.720]   between how the media tries to portray Donald Trump and what he's like when you meet him in
[00:14:24.720 --> 00:14:32.880]   person. And that gap is really wide. And so I would say specifically to Democrats and independents,
[00:14:32.880 --> 00:14:41.680]   you really do need to sit in the room and feel what it's like. He David, David is right. He is
[00:14:41.680 --> 00:14:47.040]   charismatic, he's intellectually sharp, and he's funny. And when you put that together,
[00:14:47.040 --> 00:14:52.240]   he can engage an audience for a long time and be totally extemporaneous. The other thing I would
[00:14:52.240 --> 00:14:59.600]   say that is that he is very polite. And he's kind in a way that was disarming and was not what I
[00:14:59.600 --> 00:15:07.920]   expected. And so I felt that I had misjudged him many years in the past. And so I was very glad
[00:15:09.040 --> 00:15:15.280]   that I had an opportunity to sit beside him and to actually interact with him one on one.
[00:15:15.280 --> 00:15:23.120]   It was really, really engaging. And so that's that's more about the style. And then about the
[00:15:23.120 --> 00:15:31.280]   substance, what I would say is, it was not just a pro America agenda. But it was, it's very clear
[00:15:31.280 --> 00:15:36.480]   that he was pro innovation. So he was really supportive of AI in the details that he talked
[00:15:36.480 --> 00:15:43.600]   about. He was very supportive of crypto in those details. And he's very much low regulation,
[00:15:43.600 --> 00:15:49.680]   low taxation. And so when you put that together, it does stand very much in contrast with what
[00:15:49.680 --> 00:15:58.800]   the alternative is. And so I think that both of those things are reason why even if you aren't
[00:15:58.800 --> 00:16:07.040]   willing to vote for him, I would encourage everybody to experience what it's like to hear
[00:16:07.040 --> 00:16:13.520]   freeberg, your thoughts on all this go to this. I didn't go to the event. I don't know. No,
[00:16:13.520 --> 00:16:18.160]   I know. Just big picture. I'm hosting this. I want to know why I came up didn't wear a tie.
[00:16:18.160 --> 00:16:21.120]   For analysis. You don't want the tie?
[00:16:21.120 --> 00:16:26.480]   Try doesn't need a tie is a baller. All right, say what what Trump said to you when he
[00:16:27.040 --> 00:16:31.360]   met Natalie. So it's us talking and he says, You guys are really beautiful couple.
[00:16:31.360 --> 00:16:39.360]   And I said, Well, thank you. And then he turns to me and he goes, Well, you must be really rich.
[00:16:39.360 --> 00:16:47.200]   And I started laughing out loud. Not thought he was hilarious.
[00:16:47.200 --> 00:16:52.000]   So because of the disparity in the looks between you and Nat is sort of implying
[00:16:52.000 --> 00:16:56.160]   you guys sat next to him at dinner. Yeah. And was that like an hour just
[00:16:56.160 --> 00:17:00.240]   private conversation between the three of you. This is the other thing that he does. He actually
[00:17:00.240 --> 00:17:04.720]   sits there and he says, you know, folks, I'm happy to continue to talk about whatever you want me to
[00:17:04.720 --> 00:17:09.840]   you feel free to ask me questions, or feel free to just go around the room and just tell me what you
[00:17:09.840 --> 00:17:14.160]   think. And what would happen is people would say different things. And then he would start asking
[00:17:14.160 --> 00:17:18.880]   questions of other people. And the thing becomes almost like this roundtable discussion of topics
[00:17:18.880 --> 00:17:23.360]   from we talked about Iran, we talked about foreign policy, we talked about deficits,
[00:17:24.960 --> 00:17:30.080]   regulation, everything. What did he say about deficit and debt?
[00:17:30.080 --> 00:17:37.600]   Well, he's very much he's very much on your side of, we have to really figure out how to get
[00:17:37.600 --> 00:17:41.600]   spending in order and get the deficit under control.
[00:17:41.600 --> 00:17:44.640]   Well, congrats on a sounds like a successful for you guys.
[00:17:44.640 --> 00:17:47.920]   Sounds like you guys are in the halls of power now. And
[00:17:47.920 --> 00:17:53.520]   Trump has flipped his positions on EVs, abortion and taking away a woman's right to choose
[00:17:53.520 --> 00:17:58.720]   slipped his position on Tick Tock and flipped his position on crypto. I give him a ton of credit
[00:17:58.720 --> 00:18:05.280]   for flips in a month. And he just sweeps all those votes. It's pretty smart. And for the
[00:18:05.280 --> 00:18:10.640]   Democrats who are listening, he's also pro losers, and you're not listening to people.
[00:18:10.640 --> 00:18:14.480]   So you're going to lose the election, and he's buying is going to get demolished.
[00:18:14.480 --> 00:18:16.720]   Nobody wants to vote for somebody who they think
[00:18:16.720 --> 00:18:21.040]   by Biden's getting demolished, right? That's your thought.
[00:18:21.040 --> 00:18:24.960]   I mean, did you see the video that came out this week where he was at some event? And
[00:18:24.960 --> 00:18:30.960]   yeah, it looks it looked like a moment, right? Where he was kind of frozen. He was like, I don't
[00:18:30.960 --> 00:18:38.320]   want to make it like elder abuse. And I know, like, elder abuse to sit to say, to be honest
[00:18:38.320 --> 00:18:42.960]   about what you're observing, especially when it comes to the most powerful role in America.
[00:18:42.960 --> 00:18:50.480]   Yeah, he's got a he's got a bow out 538 just put out their election forecast showing 51%
[00:18:50.480 --> 00:18:56.080]   chance of Biden winning 48% chance of Trump winning. As of two minutes ago.
[00:18:56.080 --> 00:18:59.520]   Yeah, who knows? I think it's all going to be determined by the deliveries,
[00:18:59.520 --> 00:19:00.720]   sacks, you were gonna say?
[00:19:00.720 --> 00:19:05.600]   Well, I just think what other job in America could Biden even be qualified for? Like, what
[00:19:05.600 --> 00:19:10.880]   would you hire him to do? Is there any? Is there any job you would hire him to do? Is there any
[00:19:10.880 --> 00:19:14.880]   physical job you would hire him to do? No, I'm to be your babysitter. I mean, I don't think there's
[00:19:14.880 --> 00:19:20.640]   any job in America that anybody would hire him to do. Except for maybe president. It's kind of kind
[00:19:20.640 --> 00:19:25.360]   of crazy. And this is where like the Democratic Party is in shambles. We should have the highest
[00:19:25.360 --> 00:19:31.280]   standards for the mental acuity, sharpness and energy level of our president. It's the most
[00:19:31.280 --> 00:19:35.440]   demanding job. We need a cognitive test. But the democrats need to just look deeply in the mirror
[00:19:35.440 --> 00:19:40.960]   and say, hey, you're fielding a candidate that nobody's going to vote for. That's the problem
[00:19:40.960 --> 00:19:46.080]   here. And there's not enough anti Trump sentiment. And Trump's a genius at flipping his position to
[00:19:46.080 --> 00:19:50.560]   get huge swaths of voters. And so you're going to get demolished if you don't hot swap them,
[00:19:50.560 --> 00:19:56.960]   I guarantee you hot swap is coming. I predicted the Trump flip. And I predict it now.
[00:19:56.960 --> 00:20:01.920]   I think I think you're right about maybe some of the issues where folks will get much more precise
[00:20:01.920 --> 00:20:07.920]   on these issues. But I actually think what's happening is that this is really going to be
[00:20:07.920 --> 00:20:12.800]   about Trump versus Kamala Harris. I don't think Biden is going to step down at all. But I do think
[00:20:12.800 --> 00:20:19.840]   there's a chance, a non trivial chance that Biden wins. And if he does, I don't think he's going to
[00:20:19.840 --> 00:20:25.760]   make it four years. And so then the real question is, do folks want Kamala? And have they had a
[00:20:25.760 --> 00:20:29.840]   chance to really figure out whether they want to vote for her or not? I think that's really where
[00:20:29.840 --> 00:20:34.000]   it's going to come down to. It's really Trump versus Kamala Harris. And if you if you frame
[00:20:34.000 --> 00:20:39.440]   it as that shemoth, then it's even a bigger trouncing, right? Like if you put Biden if you put
[00:20:39.440 --> 00:20:45.440]   Kamala against Trump, then what would the it would be a even bigger shellacking? Yeah.
[00:20:45.440 --> 00:20:51.120]   In your mind? I just think that without saying anything bad about Kamala, because I don't know
[00:20:51.120 --> 00:20:54.800]   much about her is really what I would say is I don't know much about her. And so you can't
[00:20:55.520 --> 00:21:03.280]   have somebody who gets into that role accidentally. I think there, we have to give
[00:21:03.280 --> 00:21:09.760]   both President Trump and President Biden a lot of credit, which is they stood in the eye of the
[00:21:09.760 --> 00:21:18.480]   hurricane, and which stood all the pressure and one and he who wins that way deserves to be the
[00:21:18.480 --> 00:21:26.800]   President of the United States. She hasn't withstood that. And so I think that it's pretty
[00:21:26.800 --> 00:21:36.240]   unfair for a lot of voters, if there is a bait and switch. And so I think that you have to look at
[00:21:36.240 --> 00:21:42.080]   both of these two candidates and assign a reasonable probability that both of them make it
[00:21:42.080 --> 00:21:47.520]   to the finish line. And from at least what I saw up close, I think it's a much higher probability
[00:21:47.520 --> 00:21:51.920]   that Donald Trump does than President Biden. And listen, Biden hasn't made it to the finish line
[00:21:51.920 --> 00:21:56.160]   of his first term. It's obvious to everybody who's in cognitive decline, you put up a candidate who's
[00:21:56.160 --> 00:22:02.880]   in cognitive decline, you're going to lose. Even against, you know, Trump, who people really don't
[00:22:02.880 --> 00:22:06.800]   like these are the two most unpopular candidates of our lifetime. I'm not sure about that. I don't
[00:22:06.800 --> 00:22:11.360]   think it's true that people don't like Trump. I think that he's got a core but yeah, no people,
[00:22:11.360 --> 00:22:17.280]   the Republicans, including yourself, we're looking for a different candidate just months ago,
[00:22:17.280 --> 00:22:22.080]   you said Trump was not your preferred candidate, and you were all in on DeSantis. So let's not
[00:22:22.080 --> 00:22:27.200]   pretend like he was your preferred candidate. He's the remaining can. So you're Yeah, I think it's
[00:22:27.200 --> 00:22:31.680]   wrong to say that there's not enthusiasm and love for Trump. We saw it on the streets. We saw it in
[00:22:31.680 --> 00:22:37.120]   that room. There's some do you see Logan Paul? Yes. Trump four years ago, he was for Biden.
[00:22:37.120 --> 00:22:41.280]   Now he's for Trump. Have you ever seen Trump walk into a UFC event? They go nuts for him.
[00:22:41.280 --> 00:22:45.680]   I'm just saying there's a lot of there's a lot of enthusiasm and a lot of love out there
[00:22:45.680 --> 00:22:50.000]   for Trump a lot of excitement. I don't see any of that for Biden. There are people who don't
[00:22:50.000 --> 00:22:55.520]   like Trump and that drives some support for Biden. But if you look at enthusiasm and excitement,
[00:22:55.520 --> 00:23:01.200]   it's all on the Trump side. In this we are in total agreement. Yes. There is no enthusiasm
[00:23:01.200 --> 00:23:06.160]   to put somebody in cognitive decline in the White House. All right, listen, we got to get to the
[00:23:06.160 --> 00:23:10.640]   docket. We could talk for hours about Biden, Biden, Biden, Trump, Trump, Trump, and we will
[00:23:10.640 --> 00:23:17.120]   it's going to be a continuing topic. But let's get to a very full docket here. Breaking news
[00:23:17.120 --> 00:23:24.720]   last night. Tesla shareholders have backed their guy. Yes, there was two important votes measures
[00:23:24.720 --> 00:23:32.400]   that Tesla just had taken with their shareholders. The first was approving
[00:23:32.400 --> 00:23:37.200]   Elon's pay package, the $56 billion pay package that was voided by a Delaware judge.
[00:23:37.200 --> 00:23:44.000]   We talked about that on episode 164 back in February. And then moving Tesla's incorporation
[00:23:44.000 --> 00:23:49.760]   from Delaware to Texas. This is also major. Remember we talked last week about the Texas
[00:23:49.760 --> 00:23:55.280]   stock exchange. Here's the two charts. Massive overwhelming support. There were some notable
[00:23:55.280 --> 00:24:01.040]   people who dissented I think Norway's sovereign wealth fund and helpers were two of the ones who
[00:24:01.040 --> 00:24:06.880]   were voting against it. Tesla share price popped 6% on the news. You don't want to lose
[00:24:06.880 --> 00:24:13.680]   Elon a Tesla that would be really bad. So your thoughts Chamath on this vote,
[00:24:13.680 --> 00:24:21.280]   and maybe the move and what that represents. It's kind of odd that we're in this crazy place.
[00:24:21.280 --> 00:24:30.400]   Same. When that original package was unveiled. There was a lot of people including me,
[00:24:31.360 --> 00:24:38.880]   who thought there's no way he's going to hit this. It's just way too aggressive. And it requires
[00:24:38.880 --> 00:24:47.040]   so many things to go right. And so I think in part, that's why three quarters of the Tesla
[00:24:47.040 --> 00:24:55.280]   shareholders approved it that 73% is not squeaking over the line. It's not 50% plus a vote. It's,
[00:24:55.280 --> 00:25:01.760]   it's a super majority. And that excluded Kimball and Elon shares. So, and then I think you have
[00:25:01.760 --> 00:25:09.200]   this very dangerous form of judicial activism, which essentially ignored the will of the
[00:25:09.200 --> 00:25:18.480]   shareholders and fight to create some administrative ruling that threw up this big question mark. So
[00:25:18.480 --> 00:25:24.400]   then in in typical Elon style, he's like, great, we're just going to get them to vote it again.
[00:25:25.040 --> 00:25:28.720]   And then yet again, it passes, and it looks like it's going to pass by around 73%.
[00:25:28.720 --> 00:25:33.440]   But the problem now is that it's still not clear what happens. I think that there's still some
[00:25:33.440 --> 00:25:42.160]   question marks where this may not nullify the judge's decision, it may actually create more
[00:25:42.160 --> 00:25:47.120]   question marks. So hopefully, this gets sorted out, he should get this stock, he never should
[00:25:47.120 --> 00:25:52.240]   have or these options, he never should have had them taken away. And so I just hope this thing,
[00:25:52.240 --> 00:25:57.440]   yeah, it becomes a nothing burger. Sachs, you have thoughts on this outcome?
[00:25:57.440 --> 00:26:02.240]   Is it surprising to you? Not surprising. And then I think the jurisdiction thing is bigger than
[00:26:02.240 --> 00:26:10.400]   maybe people are thinking because Delaware has been the standard for incorporating companies,
[00:26:10.400 --> 00:26:16.560]   but Elon is putting his companies in Nevada. And Texas, we saw the stock exchange last week,
[00:26:16.560 --> 00:26:20.960]   getting back to move to Texas. This does seem like there's something about jurisdiction
[00:26:22.000 --> 00:26:26.960]   in the water. What are your thoughts, Sachs? Well, I think it's ironic that the winning margin,
[00:26:26.960 --> 00:26:34.000]   73%, is the same margin by which shareholders approved his comp package back in 2018. So again,
[00:26:34.000 --> 00:26:40.320]   they got 73% voted for this 2018. Now they voted to reapprove it by the same margin.
[00:26:40.320 --> 00:26:45.840]   And the reason why they had to do it is because this activist judge in Delaware avoided it
[00:26:45.840 --> 00:26:50.160]   on the grounds that somehow the original shareholder vote wasn't valid. And I think
[00:26:50.160 --> 00:26:55.680]   this is interesting that the margin didn't change because it shows that shareholders aren't in
[00:26:55.680 --> 00:27:01.360]   grades. Elon delivered what he promised, and now shareholders are upholding their end of the
[00:27:01.360 --> 00:27:05.920]   bargain. And certainly they didn't have to take that position. There were different groups like
[00:27:05.920 --> 00:27:11.600]   CalSTRS who basically took the position, "What have you done for me lately?" Yeah, you delivered,
[00:27:11.600 --> 00:27:15.680]   but we don't have to pay you because of the judge, so we're not going to pay you. And I think
[00:27:15.680 --> 00:27:20.800]   shareholders wisely approved the package because I think there was some chance that if they were
[00:27:20.800 --> 00:27:25.360]   nagged that Elon could leave the company. And I still think he's absolutely vital to all the
[00:27:25.360 --> 00:27:31.120]   innovation that's going to come in the future from Tesla. And you see this, the stock is ripping on
[00:27:31.120 --> 00:27:38.720]   the news. It's up about 3% today in a down market. So clearly the market thinks that securing Elon's
[00:27:38.720 --> 00:27:45.120]   future at the company was the right decision and shareholders did the right thing. In terms of the
[00:27:45.120 --> 00:27:53.040]   downstream effect on this, like you said, it raises the specter of Delaware being an activist
[00:27:53.040 --> 00:27:57.360]   state. That's not why anyone incorporates in Delaware. The reason why you incorporated in
[00:27:57.360 --> 00:28:03.040]   Delaware is because you think it makes you subject to an extremely predictable body of
[00:28:03.040 --> 00:28:09.280]   corporate law that's been tested and become bulletproof over many, many decades. And now
[00:28:09.280 --> 00:28:16.640]   all of a sudden you have to worry that maybe a judge will set aside a shareholder vote for reasons
[00:28:16.640 --> 00:28:21.760]   that seem incredibly specious, especially in light of the fact that the shareholders just re-approved
[00:28:21.760 --> 00:28:27.680]   it. So obviously the shareholders didn't think they needed your protection and they voted to
[00:28:27.680 --> 00:28:34.240]   reverse you. And moreover, Tesla could still be subject to paying the legal fees of these trial
[00:28:34.240 --> 00:28:39.840]   lawyers who've asked for literally billions of dollars in legal fees that the judge still has
[00:28:39.840 --> 00:28:45.680]   to rule on. So imagine this. Imagine that the shareholder vote gets set aside by the judge,
[00:28:45.680 --> 00:28:50.320]   it then gets re-approved by shareholders, but the trial lawyers who brought this nuisance suit
[00:28:50.320 --> 00:28:56.000]   can now get billions of dollars. If that happens, I mean, Delaware can kind of kiss its status as
[00:28:56.000 --> 00:29:01.840]   the premier corporate law state away. - Friedberg, is this a John Galt moment?
[00:29:01.840 --> 00:29:08.640]   Is this where capitalism, socialism, and the state collide and people now start thinking,
[00:29:08.640 --> 00:29:14.240]   hmm, maybe we need to create a new jurisdiction, a new framework?
[00:29:14.240 --> 00:29:17.520]   - That's a good question. I think it's a good example for capitalism.
[00:29:17.520 --> 00:29:22.960]   And I think it should shine the light on how other CEOs are getting compensated
[00:29:22.960 --> 00:29:28.080]   at public companies where there's typically a multi-million dollar or multi-deca-million
[00:29:28.080 --> 00:29:33.440]   dollar pay package that has no dependency on the performance of the business. You can make
[00:29:33.440 --> 00:29:39.920]   tens of millions of dollars a year and not drive shareholder value. And I think that the way that
[00:29:39.920 --> 00:29:46.960]   this deal was structured, where Elon effectively got 10% of the company for 10X-ing the stock,
[00:29:46.960 --> 00:29:54.560]   should be an example that other boards should actively consider when considering both candidates
[00:29:54.560 --> 00:30:00.800]   and their appetite for this sort of a package and their compensation packages themselves.
[00:30:00.800 --> 00:30:04.880]   The way executive comp typically works at the board level at public companies
[00:30:04.880 --> 00:30:10.240]   is you hire these comp consultants. And the comp consultants come in and they use comparables,
[00:30:10.240 --> 00:30:16.080]   which basically means let's do what everyone else does. And so you have this self-reinforcing system
[00:30:16.080 --> 00:30:20.560]   of compensation and benefits for CEOs that bumps up a little bit every year
[00:30:21.120 --> 00:30:26.320]   that ultimately has some degree of ownership in the stock, but fundamentally has very little
[00:30:26.320 --> 00:30:32.880]   downside. And Elon had no guarantees in his pay package when he got this comp package originally
[00:30:32.880 --> 00:30:39.600]   in 2018. And he got 10% of the company if he 10X-ed the stock, which is what he did.
[00:30:39.600 --> 00:30:46.880]   I really think that it is worth having this become the kind of beacon for all boards to consider.
[00:30:46.880 --> 00:30:52.080]   And it seems like shareholders in aggregate are applauding the concept. And look, Elon is a
[00:30:52.080 --> 00:30:57.120]   special guy. And he gets special treatment. But I think that it moves the needle and should move
[00:30:57.120 --> 00:31:02.400]   the needle a little bit for other CEOs and other boards to stand up and say we should think about
[00:31:02.400 --> 00:31:07.040]   something that looks a lot more like this than what we typically do. And I think you would find
[00:31:07.040 --> 00:31:11.680]   a very different cast of people showing up to become CEOs and to drive performance out of
[00:31:11.680 --> 00:31:15.040]   these businesses and a lot more risky and aggressive behavior than what I think you
[00:31:15.040 --> 00:31:18.640]   would typically see in big companies that are in maintenance mode.
[00:31:18.640 --> 00:31:25.600]   What do you guys think of the organizations that initially voted yes and now voted no?
[00:31:25.600 --> 00:31:28.640]   They basically are saying, look, I mean, if you think about it, you're a big public company. I
[00:31:28.640 --> 00:31:31.520]   don't know what ISS recommended. This is institutional shareholder services.
[00:31:31.520 --> 00:31:33.920]   They recommended no both times.
[00:31:33.920 --> 00:31:39.840]   Right. And so ISS basically is what a lot of big public fund managers will follow when they make
[00:31:39.840 --> 00:31:45.360]   their votes. And so if I'm a shareholder, that's not what I'm saying. But like, let's say let's say
[00:31:45.360 --> 00:31:49.200]   that I'm BlackRock or I'm a shareholder, I'm not gonna put BlackRock as some big shareholder Tesla
[00:31:49.200 --> 00:31:55.760]   stock. Why would I vote to give away 10% of the company when I don't have to?
[00:31:55.760 --> 00:31:59.680]   Yeah, very simple, because he would leave, he would morals and ethics
[00:31:59.680 --> 00:32:06.160]   matter. And you want to do the right thing. And you want to incentivize capitalism to operate
[00:32:06.160 --> 00:32:10.800]   properly and want to incentivize the people who take on the burden of running these companies.
[00:32:10.800 --> 00:32:15.280]   And the people who voted against it, I think people should just make a list of those individuals,
[00:32:15.280 --> 00:32:20.320]   Jamal. And they should not do business with that. Because if somebody is going to double cross you,
[00:32:20.320 --> 00:32:24.880]   they've shown you who they are. These are people who double cross them. They got the benefit,
[00:32:24.880 --> 00:32:26.960]   and then they stabbed him in the back. Make a list.
[00:32:26.960 --> 00:32:29.520]   That's exactly what they did. That's exactly what they did.
[00:32:29.520 --> 00:32:32.960]   It's worse if they voted yes, the first time and then they voted no.
[00:32:32.960 --> 00:32:33.840]   No, I'm saying and then
[00:32:33.840 --> 00:32:38.160]   there's a no, no, then maybe you're just against the deal. But if you're yes, no,
[00:32:38.160 --> 00:32:40.320]   then that's a renege.
[00:32:40.320 --> 00:32:44.640]   Then you're a true scumbag. You're a scumbag. Is that public anywhere who did that?
[00:32:44.640 --> 00:32:48.000]   Yeah, there are a bunch of folks that said that they you know, I think it was CalPERS that voted
[00:32:48.000 --> 00:32:53.040]   yes. And then when they were on trying to explain they were like, tap dancing and like corporate
[00:32:53.040 --> 00:32:58.320]   jargon. But really what they are scumbags. Jason, you're right. They are morally and ethically void
[00:32:58.320 --> 00:33:02.720]   and they're reneging. And this is the one rule in business you're not allowed to do. And the
[00:33:02.720 --> 00:33:08.240]   people that do that are these penny pinching scumbags. I'm not saying a blacklist. But I would
[00:33:08.240 --> 00:33:12.720]   say making a list of people who maybe you want to consider not doing business with is how I would
[00:33:12.720 --> 00:33:17.760]   frame it. These are public market investors that are private investors, they buy the stock on the
[00:33:17.760 --> 00:33:21.040]   open market. So they don't have to worry. I mean, I think the question is, what are the chances that
[00:33:21.040 --> 00:33:25.760]   Elon leaves the company? If he doesn't didn't get the pay package, the chances that was a risk. And
[00:33:25.760 --> 00:33:30.080]   I think that was a non zero possibility about it. Yeah, non zero possibility.
[00:33:30.080 --> 00:33:32.400]   You made an agreement with somebody and you shook their hand.
[00:33:32.400 --> 00:33:38.240]   Yeah, well, I don't care whether he would have left or not left. This is I have to do the right
[00:33:38.240 --> 00:33:43.040]   thing. You have to do the right thing. You promised the guy X amount of money for doing Y amount of
[00:33:43.040 --> 00:33:48.880]   things. He did the Y things and then you had a judge come over the top because of somebody who
[00:33:48.880 --> 00:33:54.560]   owned 10 shares. And all I'm saying is if you if you don't have the intellectual intelligence to
[00:33:54.560 --> 00:33:58.400]   look past that and say, Wait a minute, we just paid the guy to do this work. And now we're going
[00:33:58.400 --> 00:34:04.160]   to rename their gaming the system. I just think that like, how can anyone who is capable of doing
[00:34:04.160 --> 00:34:10.480]   a job sign up for a pay package? How could anyone and the people that will sign up are these like
[00:34:10.480 --> 00:34:17.920]   middling corpo people who will accomplish nothing and will run these companies in ways that then
[00:34:17.920 --> 00:34:23.120]   speaks to organizations that have just proven themselves to be totally unreliable.
[00:34:23.920 --> 00:34:29.600]   The irony of the thing is that these folks thought that they were getting a 10% free roll
[00:34:29.600 --> 00:34:34.480]   when they voted no. And the reality is that by him getting the pay package,
[00:34:34.480 --> 00:34:38.320]   the certainty of him sticking around at the company caused the stock to go up by 10%.
[00:34:38.320 --> 00:34:43.280]   So they actually had the calculus wrong, that if they had gotten their way,
[00:34:43.280 --> 00:34:46.960]   the stock would have declined by more than the 10% free roll they thought they were getting.
[00:34:46.960 --> 00:34:50.880]   This is I think that the main point 10% being the ownership of the company that he gets. Yeah.
[00:34:51.520 --> 00:34:58.000]   The pay package was laughed at on CNBC by all the experts, there's no way for him to hit this stuff.
[00:34:58.000 --> 00:35:02.480]   If he does hit it, he's getting a fraction of the value of it. And this is why stock is
[00:35:02.480 --> 00:35:08.480]   such a valuable device. If employees get stock, and the CEO gets stock and everybody in between
[00:35:08.480 --> 00:35:12.880]   and retail investors get it and endowments get it and your retirement account gets it.
[00:35:12.880 --> 00:35:16.800]   Everybody rose in the right direction. Is it perfect? No, people can buy back their stock,
[00:35:16.800 --> 00:35:21.680]   they can do a little gaming on the margins. But it is the most pure system we have. Everybody
[00:35:21.680 --> 00:35:26.720]   has a share of the company. So if you're a socialist, you know, like you should actually
[00:35:26.720 --> 00:35:32.080]   kind of appreciate how stock works that everybody has a chance to buy, everybody has a chance to
[00:35:32.080 --> 00:35:38.480]   participate. This is the model we should be using for all CEOs, they should all get a massive
[00:35:38.480 --> 00:35:43.920]   package. If the stock goes up into the right. It's so obvious. And this was so unfair. Let's
[00:35:43.920 --> 00:35:49.520]   see this flipper. I want to see their explanation. Compensation is commensurate with the performance
[00:35:49.520 --> 00:35:55.920]   of the company. Did you vote for it in 2018? I believe we did vote for it in 2018. This is
[00:35:55.920 --> 00:36:02.000]   about long term value. But do you believe you were duped in 2018? No, I believe we use the
[00:36:02.000 --> 00:36:06.480]   information we had available and made the best choice. Okay, so here's what I find so interesting
[00:36:06.480 --> 00:36:13.600]   about this particular choice. 73% I believe of shareholders voted in favor of in 2018.
[00:36:13.600 --> 00:36:18.720]   A judge has said that shareholders were not informed properly. If you talk to most shareholders,
[00:36:18.720 --> 00:36:21.920]   by the way, especially big shareholders, they say we were not duped, we understood completely
[00:36:21.920 --> 00:36:28.080]   what we're doing. And we were on board with this. Now that this opportunity, almost opportunity has
[00:36:28.080 --> 00:36:35.040]   arrived on your doorstep, to say to actually rethink this, if you will. There's a view that,
[00:36:35.040 --> 00:36:40.000]   oh, maybe maybe we're not getting the value. We thought we thought we should. You thought you
[00:36:40.000 --> 00:36:46.240]   should get it. But he's worked by the way, under the assumption that he was hitting the numbers,
[00:36:46.240 --> 00:36:52.560]   right, and dealing with the contract. If I told you that you were being paid a certain amount of
[00:36:52.560 --> 00:36:56.560]   money in 2018, and then I called you and said, actually, you know what, we're not going to give
[00:36:56.560 --> 00:37:03.280]   you that money anymore. What would you do? That's a great question. I would, I would go to my board,
[00:37:03.280 --> 00:37:10.240]   you know, I would talk with my board is so smug. What is her name? Karen Frost. I don't think she's
[00:37:10.240 --> 00:37:15.520]   smug. Sorry, Marshy Frost. I'm sorry. That was Karen Frost. I think like this is emblematic
[00:37:15.520 --> 00:37:22.000]   of the kind of person who is incapable of actually doing the right thing. And there's a lot of these
[00:37:22.000 --> 00:37:27.440]   people that run a lot of these organizations that I mean, what what kind of an answer is?
[00:37:27.440 --> 00:37:32.960]   I mean, it was a non answer. That's why I said it was smug. Let me just ask each of you. You've all
[00:37:32.960 --> 00:37:36.880]   started companies. Some of you are still running companies. Would you take money from her and
[00:37:36.880 --> 00:37:42.400]   CalPERS? After that statement? Hard no for me. But remember, she's not investing in private
[00:37:42.400 --> 00:37:48.080]   companies. She's buying stock on the open market. So CalPERS announced that CalPERS announced that
[00:37:48.080 --> 00:37:52.640]   they're an LP and they're starting to do directs. Okay, I didn't know that. Yeah, they're trying to
[00:37:52.640 --> 00:37:58.720]   catch up. They've been behind on venture. Let's call this whole thing what it is. It was a heist.
[00:37:59.360 --> 00:38:04.000]   You had these trial lawyers, they find a name plaintiff who's got nine shares.
[00:38:04.000 --> 00:38:10.160]   And on a contingency fee basis, they go after Elon's pay package. What are they looking for?
[00:38:10.160 --> 00:38:17.520]   $5.6 billion. How does a lawyer make $5 billion? How motivated this whole thing? They don't care
[00:38:17.520 --> 00:38:21.840]   about Tesla. They don't care about the company. They don't care about shareholders. They're
[00:38:21.840 --> 00:38:27.520]   looking for a giant multi billion dollar contingency fee payment. And they took their
[00:38:27.520 --> 00:38:33.200]   shot and they found a Delaware judge to basically agree with them, even though shareholders approved
[00:38:33.200 --> 00:38:38.240]   it. And then shareholders re-approved it. So my question is, how much are these trial lawyers
[00:38:38.240 --> 00:38:42.960]   going to get? Is a judge going to award them billions of dollars for what was clearly now
[00:38:42.960 --> 00:38:50.160]   a mistake to avoid a pay package that shareholders wanted to stick with? If they award these lawyers
[00:38:50.160 --> 00:38:54.240]   billions of dollars, which is what they're seeking, no one's going to want to do business in Delaware
[00:38:54.240 --> 00:39:01.600]   anymore, because it subjects you to the stick up heist by trial lawyers. So I think that's
[00:39:01.600 --> 00:39:06.000]   going to be the next big shooter drop is what are these trial lawyers get awarded?
[00:39:06.000 --> 00:39:09.360]   Because they also wanted to get paid in Tesla shares.
[00:39:09.360 --> 00:39:13.920]   No, I'm serious. Here's an idea by the shares yourself.
[00:39:13.920 --> 00:39:17.600]   Yeah, they said we don't like your management of the company, but we will take your shares.
[00:39:17.600 --> 00:39:23.120]   Yeah, by the way, they got their shares, and then they voted to give you the next pay package.
[00:39:23.120 --> 00:39:24.560]   So it's just a full on grip.
[00:39:24.560 --> 00:39:30.080]   But Delaware is supposed to protect corporations against this grift.
[00:39:30.080 --> 00:39:31.520]   That's why people incorporate there.
[00:39:31.520 --> 00:39:36.560]   When people ask why does Delaware have this special place that everybody decided Delaware
[00:39:36.560 --> 00:39:40.640]   would be where we incorporate it was because it was predictable. Lawyers felt this was the
[00:39:40.640 --> 00:39:47.520]   most predictable jurisdiction that would be the most shareholder, friendly, most shareholder,
[00:39:47.520 --> 00:39:52.560]   thoughtful, whatever word you want to use, they would defend the shareholders. And here we are.
[00:39:52.560 --> 00:39:59.280]   The last company I started 8090 we incorporated in Nevada, and I just read domiciled a couple of
[00:39:59.280 --> 00:40:05.040]   other companies that I own into Nevada as well. It's becoming a trend. We're having very big
[00:40:05.040 --> 00:40:10.480]   discussions about this in the startup community of where to domicile your company and more to
[00:40:10.480 --> 00:40:15.600]   come on this one. Okay, let's keep moving. Apple had a huge announcement this week, Apple has
[00:40:15.600 --> 00:40:22.400]   entered the chat, they announced Apple intelligence, get it AI. And they have included a chat GPT
[00:40:22.400 --> 00:40:28.960]   integration from open AI. This was really, I think, impressive in many ways, because people
[00:40:28.960 --> 00:40:34.640]   thought Apple was far behind. It was a banger of a demo, a lot of un Apple like future looking
[00:40:34.640 --> 00:40:38.880]   demos. So none of these demos that we're going to show are coming to your phone this week.
[00:40:38.880 --> 00:40:45.840]   They were really, I think, playing catch up with Microsoft. And it worked stock is up 10%.
[00:40:46.720 --> 00:40:52.320]   They added about 300 billion in market cap. Now the top three market cap companies are all driven
[00:40:52.320 --> 00:40:58.640]   specifically by the perception that AI is going to be the next technological wave.
[00:40:58.640 --> 00:41:07.760]   Microsoft, Apple and Nvidia all cruising around about $3.2 trillion. And this top three keeps
[00:41:07.760 --> 00:41:13.760]   flipping back and forth Apple had passed Microsoft and market cap. Here's the features. I'll just
[00:41:13.760 --> 00:41:19.200]   give you a quick overview of what we're seeing. It's added grammarly like features, great product
[00:41:19.200 --> 00:41:23.840]   grammarly, I'm not an investor, but they added the ability to proof get grammar help AI will
[00:41:23.840 --> 00:41:28.880]   transcribe and summarize phone calls with permission, obviously double opt in, it will
[00:41:28.880 --> 00:41:33.600]   prioritize notifications and I message an email that are super important. You can do smart replies,
[00:41:33.600 --> 00:41:38.480]   and company where an investor in superhuman already does this kind of stuff. And they're
[00:41:38.480 --> 00:41:45.440]   bringing AI to Siri and this is going to be the big win in my mind, you're going to be able to
[00:41:45.440 --> 00:41:51.440]   say things like you want to order something in DoorDash or Uber Eats or Instacart. And it's the
[00:41:51.440 --> 00:41:57.920]   AI Siri will be able to dip down into apps, they're building a whole app AI interface, much like the
[00:41:57.920 --> 00:42:03.760]   rabbit device CEO talked about doing. And I think this means that Apple is going to win the AI
[00:42:03.760 --> 00:42:08.720]   consumer. There is a deal with chat GPT that I'll get your feedback on gentlemen in a moment.
[00:42:08.720 --> 00:42:14.160]   According to sources, Apple is not paying open AI. It's a non exclusive deal chat GPT can be
[00:42:14.160 --> 00:42:19.600]   swapped out. Apple is also talking to Google about a similar deal. Obviously, it doesn't take a
[00:42:19.600 --> 00:42:24.160]   genius to predict that Apple is going to auction off the LLM integration, I think to the highest
[00:42:24.160 --> 00:42:28.720]   bidder they did that with the search deal. Google pays Apple 20 billion to be the default search
[00:42:28.720 --> 00:42:34.960]   engine. That's about 5% of Apple's annual revenue, if you didn't know. And it's all profit, right? So
[00:42:34.960 --> 00:42:40.880]   this is a huge profit moment. I'm going to pause there for a second before I get into more of this
[00:42:40.880 --> 00:42:46.960]   and just get your general reaction, Chamath. I think you nailed it right at the beginning.
[00:42:46.960 --> 00:42:54.960]   The thing that I was struck by the most in this is we went from a phase where in the Steve Jobs era,
[00:42:56.320 --> 00:43:06.160]   these events were because you're about to unveil a product that was done and shipping as of that day.
[00:43:06.160 --> 00:43:13.200]   And then at some point, we transitioned to they are talking about products that they intend to
[00:43:13.200 --> 00:43:18.480]   release within a year. Now we've shifted to the part where they're talking about software
[00:43:18.480 --> 00:43:23.520]   integrations from a third party that will happen in a year. So if you just look at it sequentially,
[00:43:24.640 --> 00:43:28.560]   it's a little disappointing in that sense, because for a company this big,
[00:43:28.560 --> 00:43:35.760]   it's really not much of anything. You can't really touch it and feel it. And it's going to take a
[00:43:35.760 --> 00:43:44.560]   year before we really know what the totality of all of this is. Meanwhile, the economics of the
[00:43:44.560 --> 00:43:51.280]   chat GPT deal were leaked, and there's no money on either side. So I don't know, it's a little
[00:43:51.280 --> 00:43:56.080]   bit of like, it's really not much of anything, to be honest, because there's nothing we can
[00:43:56.080 --> 00:44:01.840]   actually play with and experience for your thoughts on the vision here, at least. And
[00:44:01.840 --> 00:44:10.560]   to Chamat's point, Apple used to release dope stuff, fully baked, ready to go. And now we
[00:44:10.560 --> 00:44:15.840]   are increasingly see them talking about what's coming next year, or at some point, do you think
[00:44:15.840 --> 00:44:18.720]   Apple's going to win the consumer? Do you think Apple's falling behind? Should they have built
[00:44:18.720 --> 00:44:25.680]   their own LLM by this point? I'm not sure I think what they have shown is more of a glimpse into the
[00:44:25.680 --> 00:44:34.160]   future of hardware, where for the last two decades or so, hardware has mostly been a portal to access
[00:44:34.160 --> 00:44:38.560]   the internet and use the internet through apps or through the browser. And hardware has done a good
[00:44:38.560 --> 00:44:43.200]   job of enabling that. But I think we're now going to see a much more tighter coupling, where the
[00:44:43.200 --> 00:44:49.440]   hardware becomes more valuable, and it's less of this kind of funnel for apps to flow through and
[00:44:49.440 --> 00:44:53.600]   data to flow through, but the hardware actually becomes the value creator. And you see a much more
[00:44:53.600 --> 00:44:59.040]   tighter integration in the hardware OS, and the AI or the software that enables you to do lots of
[00:44:59.040 --> 00:45:03.360]   things, you're no longer just going to use the hardware to access an app to do something. So a
[00:45:03.360 --> 00:45:08.320]   lot of the companies that are app developers are likely going to end up becoming services developers
[00:45:08.320 --> 00:45:13.120]   that enable that hardware AI to do something for you. And this coupling between hardware and
[00:45:13.120 --> 00:45:18.000]   software because of the way AI works, is I think, becoming more apparent, not just in consumer
[00:45:18.000 --> 00:45:22.960]   devices, but we see it in the data center and in the enterprise stack, as well. You know, we've
[00:45:22.960 --> 00:45:27.760]   seen that, obviously, there's this tight integration between the chip and the software stack that Grok
[00:45:27.760 --> 00:45:33.520]   built, there's a tight integration between Google's TPU stack, and then the ML instances and the and
[00:45:33.520 --> 00:45:39.360]   the tools that you can use in Google Cloud, that are optimized for use on that TPU hardware,
[00:45:39.360 --> 00:45:43.200]   Nvidia has got a big effort, obviously, in continuing to build out their software stack
[00:45:43.200 --> 00:45:47.360]   that sits on top of their hardware and works in a more coupled way. And then Google has this
[00:45:47.360 --> 00:45:52.400]   ability to kind of realize, I think, a similar outcome with pixel phones, which is a pretty
[00:45:52.400 --> 00:45:57.120]   sizable opportunity for them. And then all of the hardware manufacturers can probably grab more value
[00:45:57.120 --> 00:46:02.400]   now, as they build their own AI into their OS, and you start to see more of this value realized by
[00:46:02.400 --> 00:46:07.120]   the hardware companies. So I think that there's this really interesting shift, where we've all
[00:46:07.120 --> 00:46:11.120]   thought about hardware as being this like commodity, where there's some degree of like,
[00:46:11.120 --> 00:46:16.800]   improvement or innovation made over time. But now it seems like a lot of value might actually get
[00:46:16.800 --> 00:46:21.680]   captured by hardware companies in all points in the value stack. So it's an interesting moment.
[00:46:21.680 --> 00:46:26.080]   And I think that this just shines a light on that trend that I think is going to play out over the
[00:46:26.080 --> 00:46:32.400]   next couple of years. It's clear sacks that right now, to enable these features, you're going to
[00:46:32.400 --> 00:46:39.760]   have to have a pretty solid device. They announced here at the keynote at WWDC that you need to have
[00:46:39.760 --> 00:46:47.760]   an M one chip or better iPhone 15 or better. So and having all this local data is a huge advantage
[00:46:47.760 --> 00:46:53.440]   for Apple, they've got your messages, your phone, your calendar, your photos, your app behavior,
[00:46:53.440 --> 00:46:59.280]   the data inside of your wallet, all of this gives them a huge, huge advantage. So I guess the
[00:46:59.280 --> 00:47:05.920]   question is, do you think this renews the Apple franchise and people start upgrading their phones
[00:47:05.920 --> 00:47:10.560]   again to get all these new features, David sacks? Well, the market definitely thinks so because
[00:47:10.560 --> 00:47:15.600]   Apple was up big on this news. And even if it was largely vaporware, at this point, the market
[00:47:15.600 --> 00:47:20.080]   definitely liked where they were going. And frankly, Apple did exactly what I said they
[00:47:20.080 --> 00:47:25.600]   should do last week, which was to reinvent Siri as an LLM with the ability with the capability to
[00:47:25.600 --> 00:47:30.720]   reach into apps as an agent and take actions on the user's behalf. That's what they effectively
[00:47:30.720 --> 00:47:37.440]   announced. However, Apple took a shortcut to get here. They partnered with open AI. And this is
[00:47:37.440 --> 00:47:42.720]   something that I don't think they've ever really done before at the operating system level. Apple
[00:47:42.720 --> 00:47:46.960]   is famous for being vertically integrated for being a walled garden for being end to end,
[00:47:46.960 --> 00:47:52.640]   they control everything from the chips to the hardware to the operating system, and they don't
[00:47:52.640 --> 00:47:58.800]   let anybody else in until you're at the app store layer. This is allowing somebody in beneath the
[00:47:58.800 --> 00:48:04.240]   level of the app store. This is allowing someone open AI to get access to your data and to control
[00:48:04.240 --> 00:48:08.800]   your apps at the operating system level. And I think, you know, Elon pointed out, wait a second,
[00:48:08.800 --> 00:48:12.800]   what are the privacy implications here. And I think there are major privacy implications,
[00:48:12.800 --> 00:48:18.080]   there's simply no way that you're going to allow an AI on your phone to take all these actions on
[00:48:18.080 --> 00:48:26.080]   your behalf without giving that model substantial amounts of user data. And that is a huge change
[00:48:26.080 --> 00:48:33.360]   for Apple. Remember, Apple in the past has been the advocate for consumer privacy. There's a whole
[00:48:33.360 --> 00:48:38.640]   issue of the San Bernardino terrorist, where the FBI went to Apple and said, we want you to give
[00:48:38.640 --> 00:48:43.280]   us backdoor access to their phone, and Apple refused to do it and went to court to defend
[00:48:43.280 --> 00:48:49.680]   user privacy. And furthermore, one of Apple's defenses to the arguments, the antitrust arguments
[00:48:49.680 --> 00:48:55.120]   for allowing side loading, and allowing, you know, other apps to get access to parts of the operating
[00:48:55.120 --> 00:49:00.080]   system, as they've always said, we can't do this because it would jeopardize user privacy and user
[00:49:00.080 --> 00:49:07.360]   security. Well, here they are opening themselves up to open AI in a very deep and fundamental way,
[00:49:07.360 --> 00:49:11.520]   in order to accelerate the development of these features. In other words, they took the shortcut,
[00:49:11.520 --> 00:49:15.440]   they could have developed the LM themselves, they could have developed the AI themselves,
[00:49:15.440 --> 00:49:20.560]   but they chose not to do that. And I think this is going to open Pandora's box for Apple. Because
[00:49:20.560 --> 00:49:25.520]   again, they've proven that they can open up the operating system to a third party now. And who
[00:49:25.520 --> 00:49:30.000]   knows what the privacy implications of this are going to be. It turns out Apple has addressed
[00:49:30.000 --> 00:49:36.640]   this head on, they hear the concerns and much like when you share a photo, or you share your location,
[00:49:36.640 --> 00:49:41.600]   it's going to ask you over and over again, do you want to let this app do this? So they're aware that
[00:49:41.600 --> 00:49:46.400]   this is an issue, they brought up privacy every single time, but people don't trust open AI.
[00:49:46.400 --> 00:49:51.360]   And they do trust Apple. So this is strange bedfellows, to be short, your thoughts.
[00:49:51.360 --> 00:49:58.160]   I think that Apple really cares about privacy when they're trying to hurt a company they don't like,
[00:49:58.160 --> 00:50:04.160]   ie meta. They're willing to figure out a way to work around it when
[00:50:04.720 --> 00:50:08.640]   there's a company that they clearly support open AI.
[00:50:08.640 --> 00:50:12.560]   Yeah, well, you're behind, you know, you behave differently than when you're ahead and you have
[00:50:12.560 --> 00:50:16.880]   your monopoly. Freeberg, you wanted to add anything here before we move on to the next story. Okay,
[00:50:16.880 --> 00:50:25.040]   in related news, open AI has hit a run rate. And this is kind of stunning $3.4 billion.
[00:50:25.040 --> 00:50:31.520]   That means they've roughly doubled their monthly revenue in the past six months or so.
[00:50:32.240 --> 00:50:35.920]   These are not official numbers, open AI is denying them. But here's a chart
[00:50:35.920 --> 00:50:40.320]   that somebody put together based on all the different leaks and approximations of
[00:50:40.320 --> 00:50:46.800]   what open AI is making. The reason this makes no sense to chart and it shows a year,
[00:50:46.800 --> 00:50:50.320]   and then it shows a month, a month, a month, a month, is because there's been different leaks
[00:50:50.320 --> 00:50:55.120]   at different points in time. But just to normalize this in 2022, for all of 2022,
[00:50:55.120 --> 00:51:02.080]   before, they really had a lot of customers 28 million, and now on a $3.4 billion run rate.
[00:51:02.080 --> 00:51:07.360]   Again, it's pretty stunning number, if it's true, you can do apples to apples here, because like
[00:51:07.360 --> 00:51:14.480]   2023, Jan is 200 million. That means that June is 300 million, if they're on a $3.6 billion run rate.
[00:51:14.480 --> 00:51:20.720]   Yeah. And so if we were to even look at, you know, the number of people who work there 770,
[00:51:20.720 --> 00:51:24.240]   if you put that at 500,000, a person, some engineers getting a couple of million,
[00:51:24.240 --> 00:51:29.200]   some people may be getting less, they're probably only got a half billion dollars in salaries a year,
[00:51:29.200 --> 00:51:34.880]   who knows what they're spending on the infrastructure for this. If you were to do
[00:51:34.880 --> 00:51:40.400]   a valuation on this, everybody knows they sold a bunch of shares in secondary at around 80 billion,
[00:51:40.400 --> 00:51:46.000]   which means they're trading at, if these numbers are true, 25 times for revenue,
[00:51:46.000 --> 00:51:50.720]   which is close to what Nvidia is trading at right now. Obviously, they're two very different
[00:51:50.720 --> 00:51:56.960]   businesses. So your thoughts on this as a SaaS company, obviously, the majority of this revenue
[00:51:56.960 --> 00:52:02.320]   is consumption based, some portion of it is SaaS space reoccurring, like subscriptions, we pay for
[00:52:02.320 --> 00:52:09.760]   at launch my venture fund, we pay for 6000 a year to have all 2025 people on chat GPT,
[00:52:09.760 --> 00:52:14.080]   as a corporate account, maybe it's 250 300 a year per person. So what do you think of this business
[00:52:14.080 --> 00:52:19.440]   sacks and how fast it's growing? Obviously, some of its API consumption based, not reoccurring,
[00:52:19.440 --> 00:52:23.200]   some of it is reoccurring. First of all, let me say that, you know, we've talked about AI
[00:52:23.200 --> 00:52:28.160]   General Hospital and all the soap opera issues around open AI. Yeah. And, you know, judge tax
[00:52:28.160 --> 00:52:33.200]   had opinions on that. Yes. But putting that aside, I mean, everyone acknowledges that their products
[00:52:33.200 --> 00:52:39.440]   are awesome. I mean, open AI makes really great products with chat GPT 4.0 being at the top of
[00:52:39.440 --> 00:52:48.080]   the list. And I talked about how, when we moved from chat GPT 4.0 turbo to 4.0 at glue, the speed
[00:52:48.080 --> 00:52:54.960]   and quality went up, you know, at least two x and it felt like 10x. So they have the best language
[00:52:54.960 --> 00:52:59.040]   model as of this point in time. And they also have other products that are really great, like the
[00:52:59.040 --> 00:53:03.440]   whisper API, which does transcription. I mean, there's a whole bunch of tools they have that
[00:53:03.440 --> 00:53:08.720]   are great for developers. So nobody's taking anything away from them on the product side.
[00:53:08.720 --> 00:53:15.200]   And I think you're seeing that in this revenue number. Now, if I was to try and take apart this
[00:53:15.200 --> 00:53:21.840]   business as an investor, I would separate the b2c business from the b2b business. The b2c is a
[00:53:21.840 --> 00:53:27.040]   consumer subscription plan, people paying $20 a month. I'm one of them, I paid the 20 bucks a
[00:53:27.040 --> 00:53:34.400]   month is probably the only LLM that I would pay 20 bucks a month for how often you use it daily,
[00:53:34.400 --> 00:53:40.400]   weekly, monthly, I'd say a handful of times. It's not to be honest, it's not like a daily use for
[00:53:40.400 --> 00:53:46.000]   me. But I probably use it every week, I would say at least once. Yeah, so I still use it. I have to
[00:53:46.000 --> 00:53:52.240]   say, though, that the other LLMs are catching up. And if Gemini ever gets good enough, or you know,
[00:53:52.240 --> 00:53:56.960]   when Brock gets to the next level, am I going to stick with that $20 a month plan? I'm not sure it
[00:53:56.960 --> 00:54:03.040]   depends whether open AI can really maintain the the leadership it has or the perception of
[00:54:03.040 --> 00:54:08.480]   leadership. Okay, so that's half the business. And then the other part of the business is the b2b,
[00:54:08.480 --> 00:54:14.320]   which is the API products that effectively they're selling to developers. And that's where I would
[00:54:14.320 --> 00:54:19.520]   place the future value of this company. I mean, as somebody who invests in SAS, when we see a
[00:54:19.520 --> 00:54:25.280]   business that has b2c subscriptions and b2b, we place all the value on b2b. And the reason is
[00:54:25.280 --> 00:54:31.680]   because historically, the churn rates and b2c are too high. Yeah, five to 10% churn rates are common
[00:54:31.680 --> 00:54:40.080]   50% a year per month or month 50% churn a year very common. Open AI may not be experiencing that
[00:54:40.080 --> 00:54:47.120]   yet. But it's very hard to avoid the downdraft of consumer churn. And and, you know, on the other
[00:54:47.120 --> 00:54:54.400]   hand, on the b2b side, a good b2b business has expansion 120% 150% expansion year over year from
[00:54:54.400 --> 00:54:59.520]   same customers. In other words, they're ordering more. So you compare this business to Amazon Web
[00:54:59.520 --> 00:55:04.160]   Services, Google Cloud, Azure, that's really the business here. Yeah, the first thing I'd
[00:55:04.160 --> 00:55:09.280]   want to know is how much of the 3.4 billion is consumer and how much of it is is developers
[00:55:09.280 --> 00:55:14.000]   will find out eventually Chamath your thoughts on opening eyes surging revenue.
[00:55:14.000 --> 00:55:16.720]   I'm kind of in David's camp, which is I think, to the extent that the
[00:55:16.720 --> 00:55:24.240]   business has a large terminal value, it's going to be because of the enterprise cash flows.
[00:55:24.800 --> 00:55:32.320]   The thing to keep in mind is that I still haven't seen enterprises building
[00:55:32.320 --> 00:55:36.240]   production level products using AI.
[00:55:36.240 --> 00:55:38.960]   It's all experimentational, right? It's all experiments now.
[00:55:38.960 --> 00:55:43.280]   That's nothing against open AI. It's just a commentary on the fact that we are
[00:55:43.280 --> 00:55:50.000]   at a very, very early part of the cycle, where, when you use this term blast radius,
[00:55:50.560 --> 00:55:55.040]   right, what are you referring to, you're referring to this idea that you're stringing together
[00:55:55.040 --> 00:56:03.040]   elements of a model or multiple models that each have some non trivial error rate. And by multiplying
[00:56:03.040 --> 00:56:09.120]   all these error rates together, you get your final product. But the unfortunate reality in most AI
[00:56:09.120 --> 00:56:15.360]   workloads is that you end up with something that's not very good. And that's not the fault of open
[00:56:15.360 --> 00:56:19.840]   AI, nor is it the fault of llama. It's just the nature of how these bottles work. And the fact
[00:56:19.840 --> 00:56:24.080]   that you know, you've gone from something very, you know, deterministic to something that's very
[00:56:24.080 --> 00:56:31.360]   probabilistic. And we have not found a way to create extremely high quality experiences, we as
[00:56:31.360 --> 00:56:37.840]   an industry that make this cost justifiable. So right now, as you said, Jason, most of that is
[00:56:37.840 --> 00:56:44.560]   toy apps and a lot of experimentation. Will we get there? I absolutely think so. But we're not
[00:56:44.560 --> 00:56:51.920]   there yet. So I suspect that most of the revenue then is on the consumer side right now, actually.
[00:56:51.920 --> 00:56:55.760]   And so I just looked at Google Trends. And I first looked at the United States. And I just wanted to
[00:56:55.760 --> 00:57:01.680]   understand how is the traction. And what's interesting is, is that the traffic in the
[00:57:01.680 --> 00:57:10.000]   United States is down about 2526% since the end of the school year, which I think reinforces this
[00:57:10.000 --> 00:57:16.800]   belief that chat GPT has definitely over indexed in that young people's cohort where they rely on
[00:57:16.800 --> 00:57:22.080]   it to write essays or what have you. But then I looked outside the United States and worldwide.
[00:57:22.080 --> 00:57:26.720]   And what's interesting about that is that's actually still growing up into the right. So
[00:57:26.720 --> 00:57:31.920]   I think you have then an ARPU problem, which is the same thing that we had to deal with at Facebook,
[00:57:31.920 --> 00:57:36.880]   which is we have these extremely valuable users in America, they asymptote at some point, and
[00:57:36.880 --> 00:57:41.280]   then we have to grow in other markets, but those markets aren't nearly as lucrative. Right.
[00:57:41.280 --> 00:57:49.120]   They just use their ARPU per year is single digits, maybe it hits double digits, as opposed
[00:57:49.120 --> 00:57:52.480]   to states where it could be triple digits, right. So then I don't know, I would just wrap up by
[00:57:52.480 --> 00:57:58.000]   saying that I think that it's just if this number is right, it's just an incredible testament to
[00:57:58.000 --> 00:58:05.920]   what they've been able to uncover and create in a short amount of time. That is legendary stuff.
[00:58:05.920 --> 00:58:12.400]   Yep. But what I can tell you, in working with enterprises around these AI experiences through
[00:58:12.400 --> 00:58:22.640]   8090, we have not yet seen production quality models being deployed in the wild that are
[00:58:22.640 --> 00:58:28.960]   dealing with very, very important business processes, which means that most of the revenue
[00:58:28.960 --> 00:58:33.440]   right now is probably consumer oriented. Okay, Freiburg, you I don't know if you got to see
[00:58:33.440 --> 00:58:39.520]   Sonny's talk at liquidity last week, but he talked about how many of the CIOs CEOs are looking for
[00:58:39.520 --> 00:58:44.960]   open source solutions here. 80% of them want to go open source, they don't want a proprietary model
[00:58:44.960 --> 00:58:51.200]   to invest in. But the best model right now is a proprietary model. So what do you think about
[00:58:51.200 --> 00:58:58.320]   open AI's revenue surge? Is it sustainable? Or are there 20 better open source projects that
[00:58:58.320 --> 00:59:04.880]   are going to be death by 20 open source project cuts? And Tramont's general feeling here that Hey,
[00:59:04.880 --> 00:59:10.720]   it's not ready for primetime yet. It will be but we're in the AI dial up era to use an analogy
[00:59:10.720 --> 00:59:14.400]   here. Hey, you can see the promise, but it kind of sucks in terms of reliability.
[00:59:14.400 --> 00:59:20.320]   Maybe open AI is AOL. Right? Like, I think that there's going to be a Google that'll show up
[00:59:20.320 --> 00:59:27.680]   that'll maybe it's Google, it'll grab a large part of the value here. Or, you know, ultimately,
[00:59:27.680 --> 00:59:33.360]   the cost comes down so much with the open source tools. I do believe that these open source tools
[00:59:33.360 --> 00:59:39.600]   are incredible. I mean, the the open source llama instances are like they get you 85 to 90%
[00:59:39.600 --> 00:59:44.000]   of what you're looking for. So if you're an enterprise user, why would you pay 1000s of
[00:59:44.000 --> 00:59:49.120]   dollars for the open AI platform when you can use llama, and you can tune it and you can build your
[00:59:49.120 --> 00:59:54.080]   own front end to it, your own integration with your own data, etc, etc. It's just early days
[00:59:54.080 --> 01:00:01.440]   for enterprises figuring out how to do that. But I do really believe that the future is enterprises,
[01:00:01.440 --> 01:00:10.240]   companies building their own LLM driven tools for both internal and external products that leverage
[01:00:10.240 --> 01:00:16.640]   smaller open source models. And that we're kind of in this, you know, dearth of people's
[01:00:16.640 --> 01:00:20.720]   understanding and ability on how to actually execute against that, which makes the default to
[01:00:20.720 --> 01:00:26.640]   be go to the chat GPT interface, I will also provide a counter. I just did a big project at
[01:00:26.640 --> 01:00:31.440]   work this week, we had a like a big offsite with 20 people involved. And everyone use chat GPT to
[01:00:31.440 --> 01:00:36.320]   get ready for it. So there was a ton of analysis, a ton of data gathering a ton of reporting needed
[01:00:36.320 --> 01:00:42.320]   for the offsite. And rather than hire a third party or have people go out and source data
[01:00:42.320 --> 01:00:47.360]   themselves. A lot of us including myself, I prepared like maybe a quarter of the material,
[01:00:47.360 --> 01:00:50.320]   just use chat GPT and pull the sources to make sure it was all
[01:00:50.320 --> 01:00:53.520]   did you did pull sources and check facts, right? You do have to
[01:00:53.520 --> 01:00:56.800]   yeah, so we pulled the sort and there was a lot of wrong stuff, just to be clear.
[01:00:56.800 --> 01:01:02.960]   But for a ballpark percent, I would say 25% of it was like wrong. And then you had to clarify.
[01:01:02.960 --> 01:01:06.880]   But the truth is for this particular application, it didn't matter. We were making some
[01:01:06.880 --> 01:01:11.840]   approximations on markets and sizes and, and various facts that we were kind of using to
[01:01:11.840 --> 01:01:16.080]   do some strategy stuff, but some product development stuff. So I would say like,
[01:01:16.080 --> 01:01:20.240]   it wasn't useful, you found 100%. And I would say it saved us hundreds of hours,
[01:01:20.240 --> 01:01:24.720]   hundreds of hours. And were you paying them an enterprise license or a consumer license?
[01:01:24.720 --> 01:01:29.520]   20 bucks a month. What is that? It's the same thing for the enterprise, Jamal, you can
[01:01:29.520 --> 01:01:36.080]   just sign up and for 20 bucks a month, you can have your whole free bird. Yeah, no free bird,
[01:01:36.080 --> 01:01:39.200]   like you're just paying it yourself. Or you pay for everybody at Guadalajara.
[01:01:39.200 --> 01:01:42.960]   I think everyone has the right to pay for I think other people at the company pay for it too. I pay
[01:01:42.960 --> 01:01:48.080]   like I, I have my I don't have like a corporate thing set up. So everyone basically took the time
[01:01:48.080 --> 01:01:51.920]   to set up the corporate, it's really easy. And then anybody with your domain can sign up and
[01:01:51.920 --> 01:01:55.600]   let you track it, but it doesn't consolidate. That's what I'm looking for. Chamath is the
[01:01:55.600 --> 01:01:59.840]   ability to consolidate all the searches in one place. And everybody can share their searches.
[01:01:59.840 --> 01:02:04.960]   But like I said, we application is what you're doing, right? In some ways, x collaborative AI,
[01:02:04.960 --> 01:02:08.960]   it's an application today, meaning like, we go to the app, we ask questions, we get answers,
[01:02:08.960 --> 01:02:12.880]   and we use that. And I actually had to pull tables down. And I dropped those tables in,
[01:02:12.880 --> 01:02:16.880]   like all sorts of great stuff that could do, you know, do some analysis, pull out the stuff,
[01:02:16.880 --> 01:02:20.960]   what the analysis showed, understanding unit economics and various businesses,
[01:02:20.960 --> 01:02:25.920]   all this sort of stuff that it consolidates. Definitely makes everybody bionic. I agree.
[01:02:25.920 --> 01:02:30.640]   But what it's what it doesn't do yet, is take all of our internal data and all of our internal
[01:02:30.640 --> 01:02:36.560]   tooling and kind of reconfigure how we use that. So we're still paying for a whole bunch of
[01:02:36.560 --> 01:02:41.440]   enterprise software and SAS licenses for things that we know we don't want to be paying for in
[01:02:41.440 --> 01:02:46.960]   the future. And we're now starting to figure out how can we build our own AI based software
[01:02:46.960 --> 01:02:51.440]   to replace a lot of the dependency we have on third party software that uses our internal data
[01:02:51.440 --> 01:02:55.920]   for our internal consumption. So there's a lot of that still ahead of us. And that's why I know and
[01:02:55.920 --> 01:03:00.240]   we're pretty progressive. So that's why I know it's early innings, because I see the way we're
[01:03:00.240 --> 01:03:04.320]   going to use it. And I know that we're probably well ahead of a big enterprise companies that are
[01:03:04.320 --> 01:03:08.960]   more traditional. And so I can see like a couple years from now, all these big enterprises are
[01:03:08.960 --> 01:03:12.880]   going to figure the same thing out. And then you're not necessarily going to need to pay for
[01:03:12.880 --> 01:03:20.800]   this chat GPT stuff. If there's an internal tool and an internal LLM that young people are really
[01:03:20.800 --> 01:03:24.960]   getting dependent on this, and they use it constantly. We're on our investment team meeting,
[01:03:24.960 --> 01:03:28.560]   we're evaluating a company for real estate brokers, we're evaluating a company
[01:03:28.560 --> 01:03:34.240]   for therapists and like tools and SAS products for those type of people. And when I asked them,
[01:03:34.240 --> 01:03:38.000]   well, how many what's the total addressable market? Boom, three or four researchers and
[01:03:38.000 --> 01:03:42.080]   analysts on my team are doing that search, finding sources and saying there are this
[01:03:42.080 --> 01:03:45.840]   many therapists, this many social workers, this many real estate brokers as many buyers.
[01:03:45.840 --> 01:03:49.600]   And then I'm saying, Well, did you source them? Like, yeah, of course I asked. And like,
[01:03:49.600 --> 01:03:54.560]   one of them was like, Well, I asked Claude, I asked Gemini, I asked chat GPT, I asked them all
[01:03:54.560 --> 01:03:58.720]   for sources, I cross reference them. So they're like, have three of these things open. And so
[01:03:58.720 --> 01:04:03.040]   just everybody's knowledge level goes up. But you do have to check it because one out of four facts
[01:04:03.040 --> 01:04:08.320]   is probably wrong, or cited wrong. And so it's going to be, I think one out of four is about
[01:04:08.320 --> 01:04:14.640]   the right number. Yeah. And so it's interesting. So you use multiple LMS to find the hallucinations.
[01:04:14.640 --> 01:04:17.520]   Yeah, basically, you cross reference, actually, pretty interesting.
[01:04:17.520 --> 01:04:21.200]   I jump on Gemini, too. So I use Gemini dot Google, and I use chat GPT.
[01:04:21.200 --> 01:04:25.120]   And I just make sure that stuff lines up just sanity check things. Because I'm
[01:04:25.120 --> 01:04:28.880]   sure you're not going to pay for these, right? How many would you be willing to pay for?
[01:04:28.880 --> 01:04:33.840]   I mean, five, you'd pay for five different elements. Well, think about it. If somebody's
[01:04:33.840 --> 01:04:38.800]   salary is 100,000. And these costs $1,000 to have five of them, of course, I pay for five,
[01:04:38.800 --> 01:04:43.360]   because it's 1% of their size as a work tool, you know, I guess, I guess there's three categories
[01:04:43.360 --> 01:04:47.920]   to their business. Now that you're raising this, there's sort of the consumer subscriptions.
[01:04:47.920 --> 01:04:51.520]   Yeah, then there's the business descriptions, which are basically the consumer product,
[01:04:51.520 --> 01:04:55.120]   but a company's paying for it. Correct. And then there's the developers paying for
[01:04:55.120 --> 01:05:00.720]   metered consumption. Yeah, yeah, this that that enterprise is really powerful.
[01:05:00.720 --> 01:05:06.080]   Yeah, it's kind of like Microsoft Office or Google Docs, where consumers use them for,
[01:05:06.080 --> 01:05:09.680]   for free or want to use them for free. And companies will pay for it. And that's where
[01:05:09.680 --> 01:05:15.040]   the real money is. Anyway, this is going to make people bionic, I think all organizations will have
[01:05:15.040 --> 01:05:19.760]   the same number of people for the next couple of years. And then just individuals will get better
[01:05:19.760 --> 01:05:24.640]   and better at their jobs. And so efficiency is going to go way up. Speaking of efficiency,
[01:05:24.640 --> 01:05:31.040]   the market is ripping. We're going to get a little macro here in three acts inflation has
[01:05:31.040 --> 01:05:37.840]   been broken. I think it's safe to say we're down at three point x 3.3 lower than expected. And
[01:05:37.840 --> 01:05:44.960]   hiring wages are surging and stocks are surging. So let's go through it here and get the besties
[01:05:44.960 --> 01:05:49.920]   take on the vibe session. I actually disagree with that framing. Jason. Yeah, I agree. I
[01:05:49.920 --> 01:05:52.960]   disagree as well disagree with it. Let me go through the numbers. And then you can all disagree.
[01:05:52.960 --> 01:05:58.800]   That's how that's how this works, folks. Inflation print came at 3.3% lower than expected.
[01:05:58.800 --> 01:06:02.320]   Here's your 10 year chart. Super easy to explain what's happening here rates were low for a long
[01:06:02.320 --> 01:06:09.360]   time, inflation cruising at about 2%. And then lunatic spending during COVID. And we added a
[01:06:09.360 --> 01:06:13.920]   trillion to the national debt. And then Biden added a bunch everybody getting those STEMI checks and
[01:06:13.920 --> 01:06:17.760]   PPP loans. And so if you look at inflation here, we were just cruising along at 2%
[01:06:18.800 --> 01:06:25.280]   massive spike up to 9% year over year inflation and now coming back down to three point x. And
[01:06:25.280 --> 01:06:31.760]   the question is, can we get to a to handle and the rates went up faster than in ever in history.
[01:06:31.760 --> 01:06:36.960]   Here's the Fred chart you can see there in the and this goes from the 80s. So you see that massive
[01:06:36.960 --> 01:06:44.080]   spike when they try to break the back of inflation previously. So this is the fastest ever gone up.
[01:06:44.080 --> 01:06:49.520]   And here we go. The common sentiment here is that savings has been burned off and people are starting
[01:06:49.520 --> 01:06:57.280]   to have debt. And so now we are in act to the lowest unemployment rate of our lifetime continues.
[01:06:57.280 --> 01:07:04.000]   If you believe those numbers, some people do some people don't. Labor Department reported 272,000
[01:07:04.000 --> 01:07:13.280]   new jobs in May, smashing crushing the hundred 90,000 estimate. And then act three, average hourly
[01:07:13.280 --> 01:07:21.200]   wages up a massive 4% from last year at $35 an hour that also topped estimates. So if inflation
[01:07:21.200 --> 01:07:25.200]   is at three point x and hourly earnings are at four point x, maybe consumers will start feeling
[01:07:25.200 --> 01:07:31.360]   better about the economy eventually. They obviously been pretty shocked by that 9% inflation, and only
[01:07:31.360 --> 01:07:38.480]   4% growth. Here's your chart from Fred, and the hourly earnings of all employees. And you can feel
[01:07:38.480 --> 01:07:41.920]   pretty good about that where everybody's wages keep going up. The question is, do they go up
[01:07:41.920 --> 01:07:47.520]   faster than inflation? Okay, so there's my framing of the situation. Freeberg, tell me what I got
[01:07:47.520 --> 01:07:52.080]   right. Tell me what I got wrong. I think there are three numbers that matter. Okay, inflation rate,
[01:07:52.080 --> 01:07:59.840]   the growth in GDP, and the cost to borrow. The growth in GDP in the first quarter of 2024
[01:08:00.560 --> 01:08:09.280]   was a lousy 1.3% on an annualized basis. And even if the rate of inflation came down,
[01:08:09.280 --> 01:08:15.440]   we are still inflating the cost of everything by north of 3%. So the economy is only growing
[01:08:15.440 --> 01:08:22.720]   by 1.3%. And it costs more than 3% more each year to buy stuff. So that means everyone's spending
[01:08:22.720 --> 01:08:28.880]   power is reducing. And our ability and our government's ability to tax is declining because
[01:08:28.880 --> 01:08:34.320]   the economy is only growing by 1.3%. And the most important fact is that the interest rates
[01:08:34.320 --> 01:08:41.360]   are still between four and 5%, four and 4.7%. That means that to borrow money costs 4.7%.
[01:08:41.360 --> 01:08:47.680]   But the businesses the economy on average is only growing 1.3%. So just think about that for a
[01:08:47.680 --> 01:08:54.320]   second. We have a tremendous amount of leverage on businesses on the economy on on the federal
[01:08:54.320 --> 01:09:00.400]   government, that leverage the cost to pay for that debt is more than four to five, four to 5%.
[01:09:00.400 --> 01:09:06.960]   But you're only growing your revenue by 1.3%. So at some point, you cannot make your payments.
[01:09:06.960 --> 01:09:13.120]   And the rate and the goal was that is true for consumers. That is true for enterprises. And it
[01:09:13.120 --> 01:09:17.680]   is true for the federal government. Just to point out here, what you're saying the goal was to in
[01:09:17.680 --> 01:09:23.600]   fact, increase the interest rate just to cool the economy, right, which they got too late. But that
[01:09:23.600 --> 01:09:27.120]   was the goal. That was the explicit goal was to cool the economy. Yeah, the whole purpose of
[01:09:27.120 --> 01:09:32.240]   raising rates is to slow the flow of money through the economy. And by slowing the flow of money
[01:09:32.240 --> 01:09:36.960]   through the economy, there is less spending, which means that there is you're reducing the demand
[01:09:36.960 --> 01:09:41.600]   relative to the supply. So the cost of things should come down, you should reduce the rate of
[01:09:41.600 --> 01:09:46.320]   the increase in the cost of things. Now, if you click on this link, Nick that I just sent you,
[01:09:46.320 --> 01:09:52.960]   in response to the condition in the economy today, Elizabeth Warren sent this note to Jerome Powell,
[01:09:52.960 --> 01:09:58.880]   three days ago, saying, Dear Mr. Powell, or dear Chair Powell, we right today to urge the
[01:09:58.880 --> 01:10:05.840]   Federal Reserve to cut the federal funds rate from its current two decade high of 5.5%. The sustained
[01:10:05.840 --> 01:10:11.120]   period of high interest rates is already slowing the economy and is failing to address the remaining
[01:10:11.120 --> 01:10:16.800]   key drivers of inflation. She goes on to point out the fact that consumers are suffering, businesses
[01:10:16.800 --> 01:10:22.640]   are suffering. And the strain of these three numbers is really starting to show on individuals
[01:10:22.640 --> 01:10:27.040]   on businesses and obviously on the power of the dollar. But the dollar is a different story. So
[01:10:27.040 --> 01:10:31.840]   yeah, the condition of the economy and the rest of the world. And we're in a very unique position.
[01:10:31.840 --> 01:10:36.080]   But I think that things are not as rosy. Now, there's a certainly a shift in the market,
[01:10:36.080 --> 01:10:39.760]   because what this tells us is that the timeline at which the Fed will cut rates is coming in a
[01:10:39.760 --> 01:10:44.320]   little bit, relatively speaking. And so the market is saying, Okay, let's adjust to lower
[01:10:44.320 --> 01:10:49.280]   rates, the 10 year Treasury yield has come down a bit. But we are still in a difficult situation
[01:10:49.280 --> 01:10:53.920]   for people and for the for businesses. And you have Elizabeth Warren, who I think is the voice
[01:10:53.920 --> 01:10:58.480]   of small businesses and consumers. She's cut. She's trying to be the voice of those.
[01:10:58.480 --> 01:11:07.040]   This is very hard on people to mop. What's your take on this? We have a slowing GDP growth.
[01:11:07.040 --> 01:11:15.520]   We have inflation going from nine down to three. We have wages going up 4%. How do you make sense
[01:11:15.520 --> 01:11:20.000]   of all this? Do you feel like sorry, Friedberg? Are you saying we're going to have stagflation?
[01:11:20.000 --> 01:11:26.800]   Or we have stagflation right now? Definitely. But I what I'm saying is that it's not a rosy picture,
[01:11:26.800 --> 01:11:33.360]   just because labor rates are going up. If the labor rates aren't going up, you can see this
[01:11:33.360 --> 01:11:37.760]   ultimately the best number for this is the sum of GDP growth. So in aggregate, if the revenue of
[01:11:37.760 --> 01:11:43.280]   everything combined, which is GDP isn't going up faster than the increase in the cost of everything,
[01:11:43.280 --> 01:11:48.240]   people, businesses and the government can't afford their stuff. And that's fundamentally what's going
[01:11:48.240 --> 01:11:53.280]   on right now, what we need to see is a normalization, where GDP growth is greater than
[01:11:53.280 --> 01:11:59.280]   inflation rate. And as soon as that happens, then we have a more normalized and stable economy. So
[01:11:59.280 --> 01:12:03.040]   right now, things are not stable. There's a lot of difficulty and strain in the system.
[01:12:03.040 --> 01:12:10.960]   I will put myself on the other side of that trade. If there was one, if I had to simplify the United
[01:12:10.960 --> 01:12:22.000]   States economy, remember, GDP is 70% spending by individual people. And so people can spend two
[01:12:22.000 --> 01:12:29.840]   things savings that they have, or credit that they have. And what's interesting is that we have
[01:12:29.840 --> 01:12:37.040]   finally burned through and this is what this shows all of the money that folks had in their bank
[01:12:37.040 --> 01:12:44.800]   accounts. And so what does that force people to do it actually forces people to re enter the
[01:12:44.800 --> 01:12:51.120]   workforce so that they can start to make money. But the problem is that companies have been
[01:12:51.120 --> 01:12:57.520]   shrinking and have been on a defensive posture. And so as a result, which you started to see this
[01:12:57.520 --> 01:13:02.560]   past unemployment report, unemployment is now taking up because when these people re enter
[01:13:02.560 --> 01:13:07.520]   the workforce, there are no jobs for them to have people are filing incremental unemployment
[01:13:07.520 --> 01:13:12.880]   insurance claims, states like California, in fact, the state of California was the worst off
[01:13:12.880 --> 01:13:18.560]   this past month. So I think what we're starting to see is that for the large portion of the economy,
[01:13:18.560 --> 01:13:27.040]   we've run out of cash to spend. And as a result, I do think that we are going to see an economic
[01:13:27.040 --> 01:13:35.840]   slowing. And I think that that will create not just enormous, empirical justification for Jerome
[01:13:35.840 --> 01:13:41.200]   Powell, it'll be exacerbated by what Friedberg just showed, which is the political pressure
[01:13:41.200 --> 01:13:46.720]   that he's going to be under to cut. Will it cause him to cut more aggressively than he would have
[01:13:46.720 --> 01:13:54.160]   otherwise? On the margins, I actually think yes. But my perspective is that I think that we've run
[01:13:54.160 --> 01:13:59.120]   out of money, individual people. So I think unemployment is going back up. I think GDP
[01:13:59.120 --> 01:14:04.080]   is going to shrink. Yeah. And so I kind of tend to be in this camp that we're going to see more
[01:14:04.080 --> 01:14:08.880]   than one rate cut. So here is total job openings. To your point, Shamath, they're getting burned
[01:14:08.880 --> 01:14:13.120]   off. We peaked at 12 million. Again, if you believe the numbers are not there, they obviously
[01:14:13.120 --> 01:14:19.680]   have some value. And we've burned off a ton of those. So sex, what's your non political,
[01:14:19.680 --> 01:14:23.440]   non partisan take first principles of what's going on with the economy?
[01:14:23.440 --> 01:14:29.280]   Well, look, we just had this inflation report, CPI was 3.3%. The market was expecting 3.4%. So
[01:14:29.280 --> 01:14:35.520]   that's a teeny bit better than expected. But it's still persistently sticky, inflation is. And
[01:14:35.520 --> 01:14:44.240]   furthermore, Powell's comments were very hawkish. He basically said he could not commit to when
[01:14:44.240 --> 01:14:49.200]   rate cuts might begin. And we're ready. Remember, at the beginning of the year, we entered the year
[01:14:49.200 --> 01:14:55.760]   with expectations for seven rate cuts this year. Now we're down to an expectation of one rate cut.
[01:14:55.760 --> 01:15:00.400]   And we can't say for sure when that's going to happen. So honestly, I think your introduction
[01:15:00.400 --> 01:15:06.160]   overstated how positive this news was. And that's why I think if you look at the markets right now,
[01:15:06.160 --> 01:15:12.400]   it's very mixed. Most tech stocks that I'm seeing are actually in the red. And a few of them like
[01:15:12.400 --> 01:15:17.600]   Tesla and Apple and Nvidia are up. But the vast majority are in the red. So I think the market is
[01:15:18.240 --> 01:15:22.400]   taking this in stride. I think the big picture here is just we don't know when rate cuts are
[01:15:22.400 --> 01:15:27.760]   going to begin. And I think that Vinnie Lingham had a really interesting take on this, actually,
[01:15:27.760 --> 01:15:33.280]   where he said, look, could Powell cut by a quarter point? Would that matter that much? No,
[01:15:33.280 --> 01:15:37.840]   it wouldn't matter that much. But the point is, Powell doesn't want to say that the rate
[01:15:37.840 --> 01:15:44.160]   height cycle is over, right? If he were to cut by a quarter point, that by itself wouldn't do much,
[01:15:44.160 --> 01:15:48.160]   but it would be a huge statement that we're out of the woods on inflation, there's not going to be
[01:15:48.160 --> 01:15:53.360]   any more hikes coming. And we're beginning a new rate cut cycle. And Powell is clearly unwilling
[01:15:53.360 --> 01:15:58.480]   to say that. We're still in this like limbo where he is saying that we don't know when rate cuts are
[01:15:58.480 --> 01:16:03.600]   going to begin. Betting markets had to a 70% chance of two rate cuts before Powell spoke
[01:16:03.600 --> 01:16:11.680]   afterwards. Now it's one rate cut Dow record high again, this past week, and NASDAQ record highs
[01:16:11.680 --> 01:16:17.440]   each of the last like, month for the last four months of the market. Putting aside individual
[01:16:17.440 --> 01:16:23.440]   stocks has broken records almost every month for the last three free bird on the back of like two
[01:16:23.440 --> 01:16:28.320]   stocks. I mean, Nvidia is holding up the whole market. There's a lot of funny memes about this
[01:16:28.320 --> 01:16:34.640]   Nvidia, Microsoft, and stocks have are holding up the whole market.
[01:16:34.640 --> 01:16:39.120]   Correct. Yes, record stock market. What is Jerome Powell have to gain or lose
[01:16:40.000 --> 01:16:45.600]   by bowing to political pressure? So a lot of folks mentioned and references kind of
[01:16:45.600 --> 01:16:50.640]   there's political pressure for him to do something. But why would he bow? What does
[01:16:50.640 --> 01:16:57.440]   he care? What do you think the motivation is for Powell individually? And what is the political
[01:16:57.440 --> 01:17:01.360]   process that will ensue future? He doesn't bow to political pressure.
[01:17:01.360 --> 01:17:06.000]   I think it's the legacy and the perception that he leaves behind. I think, had he not
[01:17:06.880 --> 01:17:11.200]   over promised and under delivered at the end of last year, remember, he was promising a sack set
[01:17:11.200 --> 01:17:18.320]   six or seven rate cuts, and he's delivered bupkis. And the markets were none too pleased. And so now
[01:17:18.320 --> 01:17:22.480]   I think he's just swung the pendulum to the other side, which is he's going to massively under
[01:17:22.480 --> 01:17:28.720]   promise, and then over deliver if he can. And so as a result, I think he's being much more measured
[01:17:28.720 --> 01:17:32.960]   and guarded. I don't think he wants to be wrong here. So I think he's thinking about what most
[01:17:32.960 --> 01:17:36.960]   folks think about when they're at the tail end of their of a job like this. He's not going to
[01:17:36.960 --> 01:17:41.760]   get reappointed, he's going to go off into the sunset. It's roughly about how history will write
[01:17:41.760 --> 01:17:46.160]   how he handled the transition from that to the next phase, whatever that is. So I think he's
[01:17:46.160 --> 01:17:50.720]   probably very interested in making sure he doesn't break the economy. And also that he doesn't seem
[01:17:50.720 --> 01:17:55.040]   like he's constantly waffling and unpredictable. But isn't he just an autonomous agent that is
[01:17:55.040 --> 01:17:59.280]   meant to respond to the data? I guess I'm not quite understanding the degree of judgment and
[01:17:59.280 --> 01:18:04.800]   discretion that everyone seems to have a free bird. They have a mandate. But if you're asking
[01:18:04.800 --> 01:18:10.640]   what his incentives are, I think his main incentive at this point is concerned for his historical
[01:18:10.640 --> 01:18:16.880]   legacy. And specifically, he wants to be thought of like Volcker, not like Arthur Burns in the 70s.
[01:18:16.880 --> 01:18:23.440]   Volcker basically crushed inflation even at the cost of recession. And he is worshiped today as
[01:18:23.440 --> 01:18:29.760]   the best Fed chair ever. Whereas Burns let inflation slip the leash in the 1970s. And
[01:18:29.760 --> 01:18:34.560]   he's not thought of very highly. So I think that Powell's main concern here is with his historical
[01:18:34.560 --> 01:18:38.160]   legacy. At this point, I don't think he's expecting to be reappointed. He's wrapping up
[01:18:38.160 --> 01:18:44.160]   his second term already. Now, I think if you go back to 2021, the incentives were a little bit
[01:18:44.160 --> 01:18:49.840]   different. Powell wanted to be reappointed by Biden. And remember that in the summer of 2021,
[01:18:49.840 --> 01:18:56.080]   that's when the inflation began. We had that surprise 5.1% inflation Brent. Powell was up for
[01:18:56.080 --> 01:19:02.880]   renomination and confirmation in November of 2021. And I think what happened back in that year is the
[01:19:02.880 --> 01:19:08.080]   administration downplayed the inflation report. They called it transitory. Yellen did, Biden did.
[01:19:08.080 --> 01:19:12.720]   And so Powell had to get on board with that message if he wanted to get confirmed by the
[01:19:12.720 --> 01:19:16.880]   Democrats. And he did get on board with that message. He repeated the whole transitory point.
[01:19:16.880 --> 01:19:21.120]   And for that reason, they didn't begin the rate hike cycle until March of the following year.
[01:19:21.120 --> 01:19:27.520]   And from that May inflation Brent to November, they kept doing QE, even though we had inflation
[01:19:27.520 --> 01:19:35.040]   back in the system. So I think that Powell was actually intensely political in 2021. He knew
[01:19:35.040 --> 01:19:39.200]   who was going to reappoint him and who was going to have to confirm him. And he got on board with
[01:19:39.200 --> 01:19:43.920]   that message. And that's why they were so slow to react to the inflation. And I think it was
[01:19:43.920 --> 01:19:48.240]   disastrous. And that's one of the reasons why the rate tightening cycle was so steep is because he
[01:19:48.240 --> 01:19:53.040]   had to catch up with all this inflation that he had allowed for nine months longer than he should
[01:19:53.040 --> 01:19:59.200]   have. But if you ask me what's his incentive now, I think it's purely about legacy. And he does not
[01:19:59.200 --> 01:20:05.680]   want to let inflation come back after cutting rates a little too soon. So his incentive,
[01:20:05.680 --> 01:20:11.360]   I think at this point is to make sure that he's not wrong again about inflation.
[01:20:11.360 --> 01:20:16.400]   And to remind everybody, maximum employment, stable prices, moderate long-term interest
[01:20:16.400 --> 01:20:20.720]   rates is the mandate for the Federal Reserve. They're supposed to be independent,
[01:20:20.720 --> 01:20:29.040]   famously Reagan pushed Volcker to get rate cuts. And there is a lot of politics involved in this.
[01:20:29.040 --> 01:20:36.240]   And so legacy does seem like the organizing principle here. I would agree with Chamath and
[01:20:36.240 --> 01:20:40.320]   Sachs that it's legacy, but there's always political pressure here. As you can see,
[01:20:40.320 --> 01:20:45.040]   Elizabeth Warren is trying to push him to make cuts for obvious reasons.
[01:20:45.040 --> 01:20:51.440]   Well, no, there's politics when they're up for appointment or for reappointment
[01:20:51.440 --> 01:20:55.840]   for confirmation, basically, because they want to get that vote.
[01:20:55.840 --> 01:20:59.840]   Yes, but there's also subtle pressure. And then there's letter writing like Elizabeth
[01:20:59.840 --> 01:21:03.840]   Warren's doing here, right? So the pressure can be there. The question is, do they bow to it?
[01:21:03.840 --> 01:21:04.480]   Right, Sachs?
[01:21:04.480 --> 01:21:06.480]   Yeah, they don't have to. I mean, the Fed is independent.
[01:21:06.480 --> 01:21:10.720]   What do they stand to gain or lose by the pressure is my question. And I'm not sure I
[01:21:10.720 --> 01:21:15.520]   really like this concept. Exactly. And I think that's really where there's a important point
[01:21:15.520 --> 01:21:20.080]   to note here that you can identify the guy's motivation and how he's going to operate
[01:21:20.080 --> 01:21:24.880]   this year, because there is no political pressure. There wasn't in 2021. And I think that's why he
[01:21:24.880 --> 01:21:33.280]   was slow to react. Listen, if Powell can stick the landing here, then his legacy comes out intact.
[01:21:33.280 --> 01:21:39.840]   But if he screws this up, and then he was slow to react to the inflation back in 2021 and 2022,
[01:21:39.840 --> 01:21:46.720]   his legacy is going to be mud. So I think he's going to be more concerned about erring on the
[01:21:46.720 --> 01:21:52.560]   side of tamping down inflation than erring on the side of the economy not doing as well.
[01:21:52.560 --> 01:21:54.960]   I think those are the incentives.
[01:21:54.960 --> 01:21:59.920]   My position is I think he might have already stuck the landing. I think the fact that we've
[01:21:59.920 --> 01:22:03.840]   burned off all that savings to your point, Chamath, that people are going back to work,
[01:22:03.840 --> 01:22:09.200]   and that these businesses are doing fantastic and efficient because of AI and other gains.
[01:22:09.200 --> 01:22:15.920]   It feels like all the record that he I think he's already talks that are no, no, they're,
[01:22:15.920 --> 01:22:18.560]   they're trying to go back to work, but the jobs don't exist.
[01:22:18.560 --> 01:22:23.760]   I think they're going to take jobs, they just might get the job they want. And that's what
[01:22:23.760 --> 01:22:29.520]   I think people have to recognize is they have to take a job. And they may not be the one that they
[01:22:29.520 --> 01:22:30.960]   want working from home.
[01:22:30.960 --> 01:22:35.760]   We could have a negative recessionary print going into the election cycle. I think that's very
[01:22:35.760 --> 01:22:38.160]   possible. Yeah, exactly.
[01:22:38.160 --> 01:22:44.560]   I don't know, Jason, look, I'm hearing a lot of happy talk right now. And I agree with you. You
[01:22:44.560 --> 01:22:51.600]   had 1.3% GDP growth rate with a 6% of GDP deficit by the government. If the government wasn't
[01:22:51.600 --> 01:22:56.240]   printing so much money wasn't overspending. That's right. If you were to have a balanced budget,
[01:22:56.240 --> 01:22:57.440]   it would be a recession.
[01:22:57.440 --> 01:23:02.160]   Yeah. Think about that just to try to be negative, it would be negative GDP growth,
[01:23:02.160 --> 01:23:04.960]   if not for the government's program stimulating the economy.
[01:23:04.960 --> 01:23:10.320]   And a lot of the jobs you're talking about are government jobs, the government is creating jobs
[01:23:10.320 --> 01:23:15.520]   like crazy, not in the private sector, but in the public sector, because it is an election year. So
[01:23:15.520 --> 01:23:21.600]   there's a lot of political forces propping things up. And I wonder what happens after the election.
[01:23:22.480 --> 01:23:29.440]   Find out. All right, everybody, this has been another amazing episode of the all in podcast.
[01:23:29.440 --> 01:23:33.280]   Just one last thing, guys, this is really important. So friend of the pod, Peter Fenton,
[01:23:33.280 --> 01:23:40.400]   who's a famous VC in Silicon Valley tweeted that his sister has been diagnosed with a rare sarcoma.
[01:23:40.400 --> 01:23:49.280]   And they are searching for lookalike cases to do a study at Dana Farber. And if this works,
[01:23:49.280 --> 01:23:54.000]   it will change the future of cancer. But they are seeking this researcher William Gibson,
[01:23:54.000 --> 01:24:02.240]   who he's retweeting, is seeking patients with myoxoid myosarcoma, featuring a PLAG1 fusion.
[01:24:02.240 --> 01:24:10.960]   So if you are somebody out there who has a case like this, then please reach out and let us know
[01:24:10.960 --> 01:24:18.800]   or let Peter Fenton know this could save a life or many lives. His sister is also the wife of
[01:24:18.800 --> 01:24:24.080]   a good friend of ours, Peter Brigger. So our thoughts are definitely with you. And if there's
[01:24:24.080 --> 01:24:30.480]   anybody out there who has this type of rare sarcoma, please let us know. And we can refer
[01:24:30.480 --> 01:24:37.280]   you to Dana Farber. And this is a very important study that may save some lives. Pete and Peter
[01:24:37.280 --> 01:24:41.680]   are great guys. And our thoughts with Devin. I hope you guys find a cure. Okay, best wishes to
[01:24:41.680 --> 01:24:46.960]   Peter and his sister. Help out if you can. And you're in our thoughts and our prayers.

