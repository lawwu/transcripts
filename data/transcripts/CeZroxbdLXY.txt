
[00:00:00.000 --> 00:00:07.680]   Okay, so today we have an update on the AI Assistant project that we've been working on for a little while.
[00:00:07.680 --> 00:00:13.200]   It's kind of been on the back burner for a while with everything else that's been going on,
[00:00:13.200 --> 00:00:20.640]   but today I think it's probably the first exciting part of the tool that you can actually use.
[00:00:20.640 --> 00:00:23.840]   And, well, let me just show you what it looks like.
[00:00:23.840 --> 00:00:32.240]   So come over to Colab here, I just do the PIP install, the most recent version, so 0.5.
[00:00:32.240 --> 00:00:37.680]   And then we set our environment variables, so that's just API keys that we need from OpenAI and Pinecone.
[00:00:37.680 --> 00:00:44.800]   And then I come down to here and I initialize, so this is a new thing, this archiver bot, all right?
[00:00:44.800 --> 00:00:52.080]   So initialize that, and this archiver is everything we need to begin interacting with the code library
[00:00:52.080 --> 00:00:56.000]   that we've already built in the previous two videos.
[00:00:56.000 --> 00:01:02.800]   So the downloading of papers and the search through those papers,
[00:01:02.800 --> 00:01:07.120]   that can now, or that will be fully controlled through the chatbot.
[00:01:07.120 --> 00:01:10.240]   At the moment, it's just a search that is implemented
[00:01:10.240 --> 00:01:15.760]   and kind of in the progress of building the upload part of that as well.
[00:01:15.760 --> 00:01:21.920]   So we can run this and this is a question that is kind of covered in one of the papers
[00:01:21.920 --> 00:01:26.960]   that I have added, and it's, what is the general scientific consensus
[00:01:26.960 --> 00:01:29.280]   on development tool usage in early hominids?
[00:01:29.280 --> 00:01:33.040]   So it's from this paper here on, it's not even a paper,
[00:01:33.040 --> 00:01:36.080]   I think it's a chapter of a book on the evolution of intelligence.
[00:01:36.080 --> 00:01:44.400]   Now, I noticed adding like a non, like AI, computer science article into the dataset,
[00:01:44.400 --> 00:01:47.200]   that there are a few things with the library that doesn't quite work yet,
[00:01:47.200 --> 00:01:51.280]   like references here are mostly not archive papers.
[00:01:51.280 --> 00:01:54.160]   And I don't, there might not even be any archive papers in there.
[00:01:54.160 --> 00:01:57.680]   So I need to figure out a better way of dealing with that
[00:01:57.680 --> 00:02:03.440]   when we're doing like the propagation approach to finding all of the relevant papers.
[00:02:03.440 --> 00:02:06.960]   And I'm not sure how well it's being processed,
[00:02:06.960 --> 00:02:11.040]   like the chunks, maybe the size of chunks needs to be increased or decreased.
[00:02:11.040 --> 00:02:12.720]   I'm not sure.
[00:02:12.720 --> 00:02:14.720]   So let's have a look at this.
[00:02:14.720 --> 00:02:15.760]   What did we get?
[00:02:15.760 --> 00:02:21.280]   There's a scientific consensus that early hominids developed tool usage with Homo habilis,
[00:02:21.280 --> 00:02:24.800]   making tools a long time ago,
[00:02:24.800 --> 00:02:30.960]   Homo erectus showing evidence of enhanced intelligence with task-specific stone hand axes.
[00:02:30.960 --> 00:02:34.640]   Okay. So, I mean, this is a pretty good answer, I think.
[00:02:34.640 --> 00:02:36.800]   And it also tells me the source, right?
[00:02:36.800 --> 00:02:41.840]   So I could ask chatGPT this, and it may or it may not give me a good answer.
[00:02:41.840 --> 00:02:44.960]   I think on this sort of topic, it probably would give a decent answer,
[00:02:44.960 --> 00:02:47.280]   but I don't know where that information is coming from.
[00:02:47.280 --> 00:02:49.600]   And I don't want to just blindly rely on that.
[00:02:49.600 --> 00:02:52.000]   Okay. Especially when you're doing actual research
[00:02:52.000 --> 00:02:57.600]   and you need to source what you're talking about, right?
[00:02:57.600 --> 00:03:02.080]   So I can click on here and it's going to take us to that paper that we saw before.
[00:03:02.080 --> 00:03:09.200]   Okay. And we see it's the evolution of intelligence, which is from a book, I think.
[00:03:09.200 --> 00:03:13.680]   Then, okay. Could you tell me about development tool usage in this context?
[00:03:13.680 --> 00:03:14.800]   So it's kind of interesting.
[00:03:14.800 --> 00:03:18.640]   They have like the, we have some basic simple stone tools,
[00:03:18.640 --> 00:03:21.600]   and then it's talking about stone hand axes.
[00:03:21.600 --> 00:03:22.320]   It's kind of cool.
[00:03:22.320 --> 00:03:25.280]   So, okay. Tell me more about that.
[00:03:25.280 --> 00:03:27.120]   And this does take a little while to run.
[00:03:27.120 --> 00:03:29.760]   Maybe that's something we can try and improve.
[00:03:29.760 --> 00:03:34.960]   But I think right now it's kind of a consequence of what is happening.
[00:03:34.960 --> 00:03:38.640]   We're like, we're making multiple calls, open AI.
[00:03:38.640 --> 00:03:41.040]   And it just, it takes a while to process.
[00:03:41.040 --> 00:03:44.400]   Even though we're using, in this case, we're using GPT-3.5 Turbo,
[00:03:44.400 --> 00:03:46.080]   which is one of the faster models.
[00:03:46.080 --> 00:03:49.040]   I mean, if you did this with GPT-4, it would take a very long time.
[00:03:49.040 --> 00:03:51.920]   But anyway, so, okay.
[00:03:51.920 --> 00:03:54.720]   We've got this output they developed.
[00:03:54.720 --> 00:03:57.920]   Is this what I want?
[00:03:57.920 --> 00:04:00.880]   Sorry. It's a development of tool usage.
[00:04:00.880 --> 00:04:03.120]   And I'm kind of asking the same thing.
[00:04:03.120 --> 00:04:05.760]   Okay. Let me change that.
[00:04:05.760 --> 00:04:07.840]   So let's ask, okay.
[00:04:07.840 --> 00:04:09.920]   Tell me more about those hand axes.
[00:04:09.920 --> 00:04:15.200]   Tell me more about these hand axes.
[00:04:15.200 --> 00:04:18.320]   Okay. Let's try that.
[00:04:18.320 --> 00:04:21.760]   Okay. So it's being specific.
[00:04:21.760 --> 00:04:24.240]   Like it knows, I just said these hand axes,
[00:04:24.240 --> 00:04:27.440]   but because we have the chat history in there,
[00:04:27.440 --> 00:04:31.200]   it knows to actually search for the Homo erectus hand axes,
[00:04:31.200 --> 00:04:35.120]   because it can see the previous interactions that we had.
[00:04:35.120 --> 00:04:37.440]   Okay. And the answer is just that.
[00:04:37.440 --> 00:04:39.120]   Okay. It doesn't actually tell us much.
[00:04:39.120 --> 00:04:44.320]   Okay. And let's see if there's something else that we can have.
[00:04:44.320 --> 00:04:46.400]   So there's also evidence of great similarities
[00:04:46.400 --> 00:04:48.080]   between humans and great apes.
[00:04:48.080 --> 00:04:50.000]   So let's ask about that.
[00:04:50.000 --> 00:04:58.800]   So what are the similarities between humans and great apes?
[00:04:58.800 --> 00:05:05.120]   Okay. You can see again, it's creating the search term here.
[00:05:06.000 --> 00:05:09.440]   And our answer is similarities between humans and great apes
[00:05:09.440 --> 00:05:11.520]   include basic symbolism and creativity,
[00:05:11.520 --> 00:05:14.480]   which evolved as an adaption to forested environments
[00:05:14.480 --> 00:05:16.160]   of Eurasia during the Miocene.
[00:05:16.160 --> 00:05:20.560]   And then evidence of great similarities
[00:05:20.560 --> 00:05:22.560]   between humans and great apes and intelligent,
[00:05:22.560 --> 00:05:25.920]   in intelligence and traditionally believed has been found
[00:05:25.920 --> 00:05:28.960]   the apes ancestors from the mid-late Miocene
[00:05:28.960 --> 00:05:30.880]   had brains of comparable size.
[00:05:30.880 --> 00:05:33.280]   So these intellectual capabilities
[00:05:33.280 --> 00:05:41.520]   may have been potentiated as early as 12 to 14 million years ago.
[00:05:41.520 --> 00:05:43.440]   All right. Okay.
[00:05:43.440 --> 00:05:47.120]   So I think the point here is that we probably had like
[00:05:47.120 --> 00:05:49.520]   a common ancestor around that time ago.
[00:05:49.520 --> 00:05:52.240]   And at that point, we already, you know,
[00:05:52.240 --> 00:05:54.720]   the intelligence of humans was already well on its way
[00:05:54.720 --> 00:05:56.640]   to becoming what it was now.
[00:05:56.640 --> 00:05:59.360]   Right. Okay. Cool.
[00:06:00.240 --> 00:06:04.960]   So that is like the bot interface.
[00:06:04.960 --> 00:06:09.440]   Let me talk a little bit more about where this is going.
[00:06:09.440 --> 00:06:10.640]   Okay. Okay.
[00:06:10.640 --> 00:06:14.720]   So come over to, this is a new code that we have.
[00:06:14.720 --> 00:06:18.160]   So this is like the chat interface thing that we're doing.
[00:06:18.160 --> 00:06:20.400]   We're using line chain to create all of this.
[00:06:20.400 --> 00:06:23.040]   So we have a few things.
[00:06:23.040 --> 00:06:25.440]   So we have a couple of prompts that we're creating here.
[00:06:26.080 --> 00:06:29.520]   The initializing function of this class
[00:06:29.520 --> 00:06:32.000]   is basically just setting everything up.
[00:06:32.000 --> 00:06:34.640]   So initializing the large language model,
[00:06:34.640 --> 00:06:37.040]   the memory retrieval component,
[00:06:37.040 --> 00:06:40.400]   the chat bot, and also this splitter.
[00:06:40.400 --> 00:06:42.480]   So this, we haven't used this yet.
[00:06:42.480 --> 00:06:47.120]   This is when we start uploading documents via this function.
[00:06:47.120 --> 00:06:51.440]   So that's something I'll talk about a little bit later.
[00:06:51.440 --> 00:06:55.360]   So when we call this function, it just executes, right?
[00:06:55.360 --> 00:06:57.440]   So it executes on the agent that we create.
[00:06:57.440 --> 00:07:01.120]   So let's have a look at how we actually create those.
[00:07:01.120 --> 00:07:03.760]   So first we initialize a large language model.
[00:07:03.760 --> 00:07:05.440]   We can see that here.
[00:07:05.440 --> 00:07:08.400]   So that's just a chat model via line chain,
[00:07:08.400 --> 00:07:11.200]   gpt 3.5 turbo by default.
[00:07:11.200 --> 00:07:15.600]   And then we go on and we initialize our memory.
[00:07:15.600 --> 00:07:17.760]   So this is one of the more complicated parts.
[00:07:17.760 --> 00:07:22.160]   So the memory, we have this pine cone object,
[00:07:22.160 --> 00:07:25.120]   which is actually from here.
[00:07:25.120 --> 00:07:28.560]   Okay. So we have this pine cone class that we created.
[00:07:28.560 --> 00:07:30.720]   So we initialize that.
[00:07:30.720 --> 00:07:34.960]   We initialize a encoder via a line chain.
[00:07:34.960 --> 00:07:37.200]   We initialize a vector DB via line chain.
[00:07:37.200 --> 00:07:39.920]   So there's a bit of repetition here.
[00:07:39.920 --> 00:07:41.040]   We have this vector DB,
[00:07:41.040 --> 00:07:43.120]   and then we also have another version of it here.
[00:07:43.120 --> 00:07:45.360]   Something needs to be cleaned up.
[00:07:45.360 --> 00:07:48.720]   This is like the first version that I wrote pretty quickly.
[00:07:48.720 --> 00:07:51.360]   And then we have the retriever.
[00:07:51.360 --> 00:07:55.200]   So this is a retrieval Q&A with sources chain from line chain.
[00:07:55.200 --> 00:07:58.160]   So basically we're going to retrieve relevant documents,
[00:07:58.160 --> 00:08:00.320]   and we're also going to include the sources in there.
[00:08:00.320 --> 00:08:02.000]   That's super important.
[00:08:02.000 --> 00:08:05.360]   I tried in these prompts to make sure that it's going to include
[00:08:05.360 --> 00:08:07.760]   those sources of information all the time.
[00:08:07.760 --> 00:08:10.800]   Okay. So that's important.
[00:08:10.800 --> 00:08:11.940]   Okay.
[00:08:11.940 --> 00:08:17.200]   And then we come down here and we initialize a search tool, right?
[00:08:17.200 --> 00:08:18.880]   So this is just one of the tools.
[00:08:18.880 --> 00:08:21.360]   There will be multiple tools that the agent can use.
[00:08:21.360 --> 00:08:22.400]   This is just one of them.
[00:08:22.400 --> 00:08:24.640]   And it's like the core functionality,
[00:08:24.640 --> 00:08:26.960]   which is where we're chatting with the agent,
[00:08:26.960 --> 00:08:30.240]   and we want it to refer to these archive papers.
[00:08:30.240 --> 00:08:30.740]   Okay.
[00:08:30.740 --> 00:08:33.040]   This is how it does it, right?
[00:08:33.040 --> 00:08:38.320]   So it uses the search function, which is here.
[00:08:38.320 --> 00:08:38.820]   Okay.
[00:08:38.820 --> 00:08:45.680]   This is basically just a custom version of the retrieval tool
[00:08:45.680 --> 00:08:48.240]   that is already within line chain.
[00:08:48.240 --> 00:08:50.800]   The only difference is that we add in the sources
[00:08:50.800 --> 00:08:54.240]   to the answer response or the answer value here,
[00:08:54.240 --> 00:08:58.160]   because before it didn't seem to be using this,
[00:08:58.160 --> 00:09:02.480]   because you basically get a answer value and a sources value.
[00:09:02.480 --> 00:09:06.640]   It didn't seem to be considering the sources value in the final answer.
[00:09:06.640 --> 00:09:10.000]   So I just forced them into the actual answer value here.
[00:09:10.000 --> 00:09:11.520]   That's the only difference.
[00:09:11.520 --> 00:09:14.240]   I'll probably make some other changes to that in the future,
[00:09:14.240 --> 00:09:16.240]   but for now, that's fine.
[00:09:17.120 --> 00:09:19.120]   And then, okay.
[00:09:19.120 --> 00:09:24.160]   So that's the search function that our tool uses.
[00:09:24.160 --> 00:09:28.640]   We have a description, which is the search description here.
[00:09:28.640 --> 00:09:30.560]   So we need to use this tool when searching
[00:09:30.560 --> 00:09:32.400]   for scientific research information
[00:09:32.400 --> 00:09:35.360]   from our prebuilt archive papers database.
[00:09:35.360 --> 00:09:37.680]   This should be the first option when looking for information.
[00:09:37.680 --> 00:09:40.320]   When receiving information from this tool,
[00:09:40.320 --> 00:09:43.520]   you must always include all sources of information, right?
[00:09:43.520 --> 00:09:46.560]   So again, sources of information, super important.
[00:09:46.560 --> 00:09:49.520]   And then we append that tool to our tools list, right?
[00:09:49.520 --> 00:09:55.280]   So then that's kind of ready to be used by our agent, okay?
[00:09:55.280 --> 00:09:57.120]   And then we initialize our agent.
[00:09:57.120 --> 00:09:58.960]   That's the next step here.
[00:09:58.960 --> 00:10:00.480]   So the chatbot agent.
[00:10:00.480 --> 00:10:04.000]   So that is here, right?
[00:10:04.000 --> 00:10:06.640]   So we use the conversational memory.
[00:10:06.640 --> 00:10:09.120]   I haven't really messed around so much with this at the moment,
[00:10:09.120 --> 00:10:11.440]   but we use conversational buffer window memory.
[00:10:11.440 --> 00:10:15.120]   So we keep basically a track of the last five interactions.
[00:10:15.120 --> 00:10:17.440]   And then we forget it, okay?
[00:10:17.440 --> 00:10:20.400]   Then we initialize the agent.
[00:10:20.400 --> 00:10:23.840]   So we're using the chat conversational react description agent.
[00:10:23.840 --> 00:10:27.040]   What that means is that it's for a trap model,
[00:10:27.040 --> 00:10:31.760]   which is the GT 2.5 turbo model that we've initialized.
[00:10:31.760 --> 00:10:35.600]   It's conversational, meaning there is this conversational memory
[00:10:35.600 --> 00:10:37.280]   considered by the agent.
[00:10:37.280 --> 00:10:41.760]   So it's not just looking at a single interaction.
[00:10:41.760 --> 00:10:43.600]   It's looking at a history of interactions.
[00:10:44.640 --> 00:10:49.920]   The react is like a framework where you are basically saying,
[00:10:49.920 --> 00:10:56.320]   I want you to reason about what action to take and then take the action, okay?
[00:10:56.320 --> 00:11:04.480]   So the RE is reason and the act is action, okay?
[00:11:04.480 --> 00:11:06.000]   And then description is basically saying,
[00:11:06.000 --> 00:11:12.640]   base your decision on whether to use this agent on the agent description,
[00:11:12.640 --> 00:11:16.320]   which we defined here, okay?
[00:11:16.320 --> 00:11:22.240]   So that is our initialized agent.
[00:11:22.240 --> 00:11:24.480]   And then we just update the prompt.
[00:11:24.480 --> 00:11:28.880]   So we have this custom system message up here, okay?
[00:11:28.880 --> 00:11:32.320]   Which is your expert summarizer and deliver technical information.
[00:11:32.320 --> 00:11:36.160]   You make complex information incredibly simple to understand,
[00:11:36.160 --> 00:11:37.920]   so on and so on, okay?
[00:11:37.920 --> 00:11:39.280]   I just wrote this quickly.
[00:11:39.280 --> 00:11:41.040]   It definitely needs some work.
[00:11:41.680 --> 00:11:44.720]   But one thing I did add that again is pretty important
[00:11:44.720 --> 00:11:48.880]   is just really telling the agent again and again
[00:11:48.880 --> 00:11:53.680]   to include a source of information at the end of responses, okay?
[00:11:53.680 --> 00:11:57.520]   So I just like hammer that in as often as I can
[00:11:57.520 --> 00:12:00.640]   just to make sure that it's actually doing that, okay?
[00:12:00.640 --> 00:12:05.280]   So after that, we're done, right?
[00:12:05.280 --> 00:12:07.360]   So that is the agent, it's created.
[00:12:08.400 --> 00:12:12.800]   And then the final bit that is in this initialization component
[00:12:12.800 --> 00:12:15.680]   is initialize the extraction tooling.
[00:12:15.680 --> 00:12:19.760]   That is for later that I'm not using that right now,
[00:12:19.760 --> 00:12:22.400]   but I will be at some point.
[00:12:22.400 --> 00:12:24.800]   And I kind of show you what that is going to look like.
[00:12:24.800 --> 00:12:26.880]   So if we come over to here,
[00:12:26.880 --> 00:12:29.600]   we have basically the same code we saw before.
[00:12:29.600 --> 00:12:31.280]   This is running locally.
[00:12:31.280 --> 00:12:36.640]   So I can like test the most recent version of the bot.
[00:12:37.680 --> 00:12:39.440]   So we just asked questions.
[00:12:39.440 --> 00:12:42.080]   It's going to do the exact same thing, right?
[00:12:42.080 --> 00:12:43.840]   I'm AI language model, right?
[00:12:43.840 --> 00:12:46.080]   It's not accessing the database at this point.
[00:12:46.080 --> 00:12:47.520]   If I ask you a technical question,
[00:12:47.520 --> 00:12:50.640]   it's going to access the database, right?
[00:12:50.640 --> 00:12:52.160]   Okay, cool.
[00:12:52.160 --> 00:12:56.880]   Then the next thing that I'm doing here
[00:12:56.880 --> 00:13:00.080]   is I want to be able to use this chat interface
[00:13:00.080 --> 00:13:03.120]   to add new articles to the database, right?
[00:13:03.120 --> 00:13:06.640]   At the moment, we have to use a different script
[00:13:06.640 --> 00:13:08.880]   where we manually, not manually,
[00:13:08.880 --> 00:13:14.560]   but we write code in order to add those papers
[00:13:14.560 --> 00:13:15.520]   to the database.
[00:13:15.520 --> 00:13:16.320]   I don't want to do that.
[00:13:16.320 --> 00:13:18.800]   I want to let users interact with the chatbot
[00:13:18.800 --> 00:13:24.240]   and say, I would like to talk about this particular paper
[00:13:24.240 --> 00:13:28.000]   and for that paper to not be within the database already.
[00:13:28.000 --> 00:13:31.680]   And the chatbot know that, okay,
[00:13:31.680 --> 00:13:33.280]   if they want to talk about that,
[00:13:33.280 --> 00:13:34.400]   we need to search the internet.
[00:13:34.400 --> 00:13:36.640]   We need to retrieve that paper.
[00:13:36.640 --> 00:13:39.280]   We need to embed it, add it to the database,
[00:13:39.280 --> 00:13:41.600]   and then we can start talking about it, right?
[00:13:41.600 --> 00:13:43.760]   I'm not sure because that takes a little bit of time.
[00:13:43.760 --> 00:13:46.560]   So at some point there'll need to be
[00:13:46.560 --> 00:13:48.160]   some like async code in here,
[00:13:48.160 --> 00:13:49.840]   which handles that and then says, okay,
[00:13:49.840 --> 00:13:51.840]   you need to give me a bit of time to think about it.
[00:13:51.840 --> 00:13:53.600]   Something like that.
[00:13:53.600 --> 00:13:54.400]   I'm not sure yet,
[00:13:54.400 --> 00:13:59.520]   but for now it's just creating that, right?
[00:13:59.520 --> 00:14:03.040]   So the way that that will be implemented,
[00:14:03.040 --> 00:14:04.480]   I'm not a hundred percent sure yet,
[00:14:04.480 --> 00:14:06.160]   but I've started doing it.
[00:14:06.160 --> 00:14:11.920]   So we have this add article to database function, right?
[00:14:11.920 --> 00:14:16.000]   That is just getting the archive ID, basically.
[00:14:16.000 --> 00:14:18.880]   It's using that to download.
[00:14:18.880 --> 00:14:21.120]   So this is from constructors, I think.
[00:14:21.120 --> 00:14:25.120]   Yes, it's an archive class.
[00:14:25.120 --> 00:14:26.400]   Okay, archive class here.
[00:14:26.400 --> 00:14:28.720]   This is another function from the library.
[00:14:28.720 --> 00:14:32.480]   So that downloads the archive object.
[00:14:32.880 --> 00:14:34.480]   Or we get information on it.
[00:14:34.480 --> 00:14:36.080]   Then we download it.
[00:14:36.080 --> 00:14:38.560]   We get the metadata for the paper,
[00:14:38.560 --> 00:14:40.640]   and then we shrink the paper in smaller parts.
[00:14:40.640 --> 00:14:44.160]   So into the like 300 token slices,
[00:14:44.160 --> 00:14:47.040]   and then we add that to the database.
[00:14:47.040 --> 00:14:48.080]   Okay, right?
[00:14:48.080 --> 00:14:49.280]   And then we return,
[00:14:49.280 --> 00:14:50.880]   or we're going to return something like this.
[00:14:50.880 --> 00:14:52.240]   So we're going to return that saying,
[00:14:52.240 --> 00:14:53.760]   I've added this to my memory.
[00:14:53.760 --> 00:14:57.920]   It's now accessible via the search archive database tool.
[00:14:57.920 --> 00:15:01.360]   So this is both kind of for the user to see,
[00:15:01.360 --> 00:15:04.400]   but also actually more for the chatbot to see.
[00:15:04.400 --> 00:15:05.520]   So once it's seen that,
[00:15:05.520 --> 00:15:08.000]   okay, we have this in our memory now,
[00:15:08.000 --> 00:15:11.280]   we can now access it through this other tool, right?
[00:15:11.280 --> 00:15:13.200]   So if it's going through those multiple steps,
[00:15:13.200 --> 00:15:13.920]   it can download it,
[00:15:13.920 --> 00:15:16.240]   and then it can ask a question to the tool.
[00:15:16.240 --> 00:15:17.860]   Okay?
[00:15:17.860 --> 00:15:20.640]   So that is a function.
[00:15:20.640 --> 00:15:21.600]   I've tested it here.
[00:15:21.600 --> 00:15:24.880]   So I added the attention is all you need paper.
[00:15:24.880 --> 00:15:25.840]   You know, that worked.
[00:15:25.840 --> 00:15:29.760]   And then I asked the question,
[00:15:29.760 --> 00:15:32.560]   and it retrieved the relevant information from that paper.
[00:15:32.560 --> 00:15:33.920]   That's kind of what I want to do,
[00:15:33.920 --> 00:15:37.680]   but I don't want to write code like this to do it.
[00:15:37.680 --> 00:15:39.280]   I would rather write something like,
[00:15:39.280 --> 00:15:54.800]   but can you add the like 1706.03762 paper to your memory?
[00:15:54.800 --> 00:15:55.360]   Okay?
[00:15:55.360 --> 00:15:56.880]   I want to say something like that,
[00:15:56.880 --> 00:15:58.480]   or rather than that,
[00:15:58.480 --> 00:16:01.920]   I would like to say, can you add the attention
[00:16:01.920 --> 00:16:03.840]   is all you need paper to your memory,
[00:16:03.840 --> 00:16:07.200]   or can you add some papers, right?
[00:16:07.200 --> 00:16:09.840]   So this is where we might search for multiple papers,
[00:16:09.840 --> 00:16:15.280]   some papers about NLP attention to your memory, right?
[00:16:15.280 --> 00:16:17.440]   I want to be able to ask these things to the bot,
[00:16:17.440 --> 00:16:18.960]   and they actually go through that process
[00:16:18.960 --> 00:16:19.920]   that I just described.
[00:16:19.920 --> 00:16:24.480]   So that's what we're working on now.
[00:16:24.480 --> 00:16:28.720]   But for now, like you can actually kind of use this
[00:16:28.720 --> 00:16:31.280]   to some degree without too much effort.
[00:16:31.280 --> 00:16:37.280]   So you can use some code that will look like this.
[00:16:37.280 --> 00:16:37.600]   Okay.
[00:16:37.600 --> 00:16:38.720]   So you'd come here,
[00:16:38.720 --> 00:16:41.920]   you would initialize your knowledge base.
[00:16:41.920 --> 00:16:46.880]   You'd come down to here, right?
[00:16:46.880 --> 00:16:48.720]   So you'd use this sort of code here
[00:16:48.720 --> 00:16:52.560]   in order to add new papers to the database.
[00:16:52.560 --> 00:16:52.800]   Okay.
[00:16:52.800 --> 00:16:53.840]   If we come up to here,
[00:16:53.840 --> 00:16:56.320]   this is where we initialize that, right?
[00:16:56.320 --> 00:16:57.920]   So we have the archive bot
[00:16:57.920 --> 00:17:00.480]   and we initialize it with this paper here.
[00:17:00.480 --> 00:17:00.720]   Okay.
[00:17:00.720 --> 00:17:05.440]   And the extractor is what you can see here.
[00:17:05.440 --> 00:17:06.320]   Okay.
[00:17:06.320 --> 00:17:11.040]   So with that, you can actually use this library.
[00:17:11.040 --> 00:17:14.080]   I'll add like a notebook or something
[00:17:14.080 --> 00:17:15.680]   that will show you how to do that.
[00:17:15.680 --> 00:17:19.520]   But this is still like not ready yet.
[00:17:19.520 --> 00:17:19.920]   Okay.
[00:17:19.920 --> 00:17:24.160]   Because we want to basically make every interaction
[00:17:24.160 --> 00:17:27.520]   with this library accessible via the chat bot.
[00:17:27.520 --> 00:17:31.200]   But for now, you know, that's where we are.
[00:17:31.200 --> 00:17:33.120]   So I'll leave this video.
[00:17:33.120 --> 00:17:36.080]   I hope this has been a useful update.
[00:17:36.080 --> 00:17:38.880]   Hopefully there'll be a bit more progress on this very soon.
[00:17:38.880 --> 00:17:41.680]   And I'll be able to show you like an actual chat bot
[00:17:41.680 --> 00:17:45.680]   that you can genuinely use just like out of the box
[00:17:45.680 --> 00:17:51.280]   as a essentially like research assistant for archive papers
[00:17:51.280 --> 00:17:53.280]   and maybe in the future, other things as well.
[00:17:53.280 --> 00:17:55.920]   But yeah, that's everything for now.
[00:17:55.920 --> 00:17:59.440]   So I hope this was interesting and useful.
[00:17:59.440 --> 00:18:01.520]   Thank you very much for watching
[00:18:01.520 --> 00:18:03.600]   and I will see you again in the next one.
[00:18:03.600 --> 00:18:04.640]   Bye.
[00:18:04.640 --> 00:18:19.600]   (soft music)
[00:18:20.560 --> 00:18:22.560]   (music fades)
[00:18:22.560 --> 00:18:24.620]   you

