
[00:00:00.000 --> 00:00:03.320]   Paranoia of making sure we live because I've messed it up so
[00:00:03.320 --> 00:00:06.000]   many times. I'll just go to YouTube just to double check.
[00:00:06.000 --> 00:00:07.240]   Awesome.
[00:00:07.240 --> 00:00:10.760]   So that's what I'm trying to do right now.
[00:00:10.760 --> 00:00:18.240]   Paranoia of making sure we live because I've messed it up so
[00:00:18.240 --> 00:00:20.920]   many times. I'll just go to YouTube just to double check.
[00:00:20.920 --> 00:00:22.200]   Awesome.
[00:00:22.200 --> 00:00:26.720]   I can hear an echo which means we're live. Hey, everybody,
[00:00:26.720 --> 00:00:31.440]   welcome back to the Jack series. I'm super excited to host Sam
[00:00:31.440 --> 00:00:33.840]   today, Sam, thanks for your time. And thanks for joining us.
[00:00:33.840 --> 00:00:37.120]   I'll quickly remind everyone of what the session is introduce
[00:00:37.120 --> 00:00:43.240]   Sam and then hand it over to him. Last time we met before the
[00:00:43.240 --> 00:00:45.720]   New Year and we had the privilege to learn from
[00:00:45.720 --> 00:00:49.440]   Jonathan. This has been an ongoing course where we learn
[00:00:49.440 --> 00:00:52.760]   about Jacks I get to learn from incredible people like Jonathan
[00:00:52.760 --> 00:00:56.120]   like Sam and this is being hosted in collaboration with the
[00:00:56.120 --> 00:01:04.600]   Jacks global meetup series. I wanted to quickly introduce Sam
[00:01:04.600 --> 00:01:07.960]   and then hand it over to him. Sam is a senior research
[00:01:07.960 --> 00:01:11.160]   scientist at Google. He's the co-developer I believe co-
[00:01:11.160 --> 00:01:16.280]   co-developer if I may of Jacks MD. He has a PhD in physics and
[00:01:16.280 --> 00:01:22.280]   you can find him on Twitter at @scholenholz. I am not I was
[00:01:22.280 --> 00:01:25.480]   telling Sam off the call I'm not an expert in physics at all. I
[00:01:25.480 --> 00:01:29.680]   don't understand any details of it. So he's the two expert and I
[00:01:29.680 --> 00:01:32.760]   won't try to make any comment but I invite everyone and I want
[00:01:32.760 --> 00:01:35.760]   to remind everyone please keep the questions coming in. This is
[00:01:35.760 --> 00:01:40.040]   an interactive session and I'll be passing your questions on to
[00:01:40.040 --> 00:01:43.400]   Sam. Sam, thanks again for your time and thanks for joining us.
[00:01:43.400 --> 00:01:48.920]   Awesome. Thank you so much for having me. Um, yeah, so I you
[00:01:48.920 --> 00:01:55.320]   know, I wasn't sure. Wait, let me let me just get some also let
[00:01:55.320 --> 00:01:59.160]   me know sometimes when I I'm going to try to do a demo during
[00:01:59.160 --> 00:02:07.000]   the talk and sometimes when I switch slides, it doesn't it
[00:02:07.000 --> 00:02:10.520]   like loses the the share screen. So let me know if that happens.
[00:02:10.520 --> 00:02:14.320]   Anyway, but thanks for having me. Um, it's great to be here.
[00:02:14.320 --> 00:02:16.880]   I've seen you know, some of the talks in the series and they've
[00:02:16.880 --> 00:02:21.280]   I you know, I obviously love Jacks. So I'm really happy to be
[00:02:21.280 --> 00:02:25.920]   here and part of it. Um, you know, I wasn't sure what the
[00:02:25.920 --> 00:02:29.160]   audience was going to be like, especially because you know,
[00:02:29.160 --> 00:02:32.640]   when I give talks to more machine learning folks, I think
[00:02:32.640 --> 00:02:36.440]   probably people don't have a lot of background in physics or in
[00:02:36.440 --> 00:02:40.440]   molecular dynamics. So I'll throughout the talk be trying to
[00:02:40.440 --> 00:02:44.640]   just kind of make it a fun talk with some demos and kind of give
[00:02:44.640 --> 00:02:50.080]   a gist of the kinds of work that molecular dynamics and physics
[00:02:50.400 --> 00:02:55.400]   tries to like do and solve. But anyway, throughout, you know, I
[00:02:55.400 --> 00:02:58.480]   please please ask questions, I'd rather get through less stuff.
[00:02:58.480 --> 00:03:04.520]   And, and have people understand then then, you know, get through
[00:03:04.520 --> 00:03:10.240]   everything and have everyone be lost. So anyway, uh, Jacks MD is
[00:03:10.240 --> 00:03:15.120]   a project we started working on maybe about three years ago. And
[00:03:15.120 --> 00:03:19.160]   it's it's a when when Jacks came about, I was really one of the
[00:03:19.160 --> 00:03:20.800]   things that I was really excited about, you know, because I've
[00:03:20.800 --> 00:03:25.200]   been using TensorFlow, and I found it great for machine
[00:03:25.200 --> 00:03:27.880]   learning, but maybe not so great if you wanted to do other stuff
[00:03:27.880 --> 00:03:31.360]   like science. And one of the things that I loved about Jacks
[00:03:31.360 --> 00:03:34.680]   being built on NumPy was that it really seemed like an
[00:03:34.680 --> 00:03:40.000]   opportunity to write excellent scientific computing tools. And
[00:03:40.000 --> 00:03:42.880]   since my background is in physics, and in particular, I
[00:03:42.880 --> 00:03:46.720]   did a lot of like atomistic physics simulations, I decided
[00:03:46.720 --> 00:03:51.200]   to try and see how it worked with molecular dynamics, which
[00:03:51.200 --> 00:03:55.760]   is a kind of atomistic physics simulation. And I should say
[00:03:55.760 --> 00:04:01.080]   like, the, at the beginning, it was me and my colleague, Dosh,
[00:04:01.080 --> 00:04:05.760]   working on it. But ever since then, we've had, you know, a
[00:04:05.760 --> 00:04:08.560]   growing set of open source contributors. So you know, if
[00:04:08.560 --> 00:04:11.720]   you if you go to the GitHub, and you look at the contributors, I
[00:04:11.720 --> 00:04:15.840]   think we've now had a lot of people helping out and doing
[00:04:15.880 --> 00:04:20.160]   some great work. So so what is what is molecular dynamics?
[00:04:20.160 --> 00:04:26.320]   Molecular molecular dynamics is like a cornerstone of physics
[00:04:26.320 --> 00:04:29.640]   research, especially like atom, you know, if you want to
[00:04:29.640 --> 00:04:34.040]   understand like a material, or like, sometimes like a protein,
[00:04:34.040 --> 00:04:39.520]   or in bio in biophysics, what you'll do is you'll, you'll, you
[00:04:39.520 --> 00:04:41.680]   know, you know, sort of like what the atoms are in the
[00:04:41.680 --> 00:04:46.480]   system. And you'll run a computer simulation, instead of
[00:04:46.480 --> 00:04:49.360]   trying to do an experiment. And so you could do an experiment
[00:04:49.360 --> 00:04:52.440]   where you like actually try to produce the material or the
[00:04:52.440 --> 00:04:55.960]   protein and measure like a binding or the material and
[00:04:55.960 --> 00:05:00.080]   measure like, you know, let's say like, a glass and measure
[00:05:00.080 --> 00:05:02.960]   like, how much does it shatter if it gets impacted by
[00:05:02.960 --> 00:05:07.200]   something. So you might want to run these things and
[00:05:07.200 --> 00:05:09.920]   experiment, but that's hard, because you have to like,
[00:05:10.160 --> 00:05:12.840]   actually produce the experiment produce the material. But
[00:05:12.840 --> 00:05:17.480]   another approach that's kind of complimentary is to simulate
[00:05:17.480 --> 00:05:20.680]   the system in a computer. And what you do is you you have all
[00:05:20.680 --> 00:05:24.960]   the atoms that you kind of know, exist in the material or the
[00:05:24.960 --> 00:05:29.800]   the system, and you posit some interactions between them. And
[00:05:29.800 --> 00:05:33.360]   usually, these will be dictated by quantum mechanics, which is
[00:05:33.360 --> 00:05:36.120]   hard to simulate. So you'll use something more like approximate.
[00:05:36.360 --> 00:05:42.280]   But if the fidelity of the of the interactions or the atoms is
[00:05:42.280 --> 00:05:45.400]   high enough, you can get simulations that like agree very
[00:05:45.400 --> 00:05:49.320]   well with experiment. And what's nice about that is if you have a
[00:05:49.320 --> 00:05:52.720]   simulation, then you know exactly what everything is doing
[00:05:52.720 --> 00:05:56.280]   all the time. So so you can make measurements in computer
[00:05:56.280 --> 00:06:01.600]   simulations that you just can't make in experiments. So this,
[00:06:01.640 --> 00:06:07.240]   this is just an example that I ran in Jax MD of silicon
[00:06:07.240 --> 00:06:11.920]   dioxide at room temperature. So this would be like the glass in
[00:06:11.920 --> 00:06:15.200]   like a window that you might have, for example. And so so
[00:06:15.200 --> 00:06:18.440]   this is just being simulated. This was simulated in a Colab
[00:06:18.440 --> 00:06:22.520]   notebook. But the idea would be that if we know what all the
[00:06:22.520 --> 00:06:25.440]   atoms are doing, we might be able to ask questions about like,
[00:06:25.440 --> 00:06:30.440]   how hard is the is the window? How much force might it take to
[00:06:30.440 --> 00:06:32.800]   shatter? And if you're building something like an iPhone screen
[00:06:32.800 --> 00:06:39.680]   or something, this can be like a useful thing to do. So more
[00:06:39.680 --> 00:06:44.040]   often than not, you know, one of the things about physics
[00:06:44.040 --> 00:06:47.720]   simulations is that they are sort of stuck in the past a
[00:06:47.720 --> 00:06:53.160]   little bit, I think. And they're built in much the same way as
[00:06:53.160 --> 00:06:55.760]   code was written before libraries like TensorFlow or
[00:06:55.760 --> 00:06:59.960]   PyTorch or Jax. And so what you have is you have a very fast
[00:07:00.240 --> 00:07:04.040]   back end that's usually written in C, if you're running on CPU
[00:07:04.040 --> 00:07:08.000]   or CUDA, if you're running on GPU. And this is great, because
[00:07:08.000 --> 00:07:10.520]   it's like super, super fast and performant, and they've really
[00:07:10.520 --> 00:07:14.560]   optimized it for the workload that they're running on. But it
[00:07:14.560 --> 00:07:18.720]   has some disadvantages, because you have significant code
[00:07:18.720 --> 00:07:23.400]   duplication between the two paths. And then simulations are
[00:07:23.400 --> 00:07:26.440]   written in a front end language. And this will often be Python.
[00:07:26.440 --> 00:07:29.840]   But it could be something else. So for example, there's a
[00:07:29.880 --> 00:07:33.040]   popular library called LAMPS, which uses something called
[00:07:33.040 --> 00:07:35.760]   LAMPS script or its own scripting language. But in
[00:07:35.760 --> 00:07:38.160]   general, there's some higher level front end language that
[00:07:38.160 --> 00:07:41.920]   the user interacts with. And again, this is great, because
[00:07:41.920 --> 00:07:48.520]   you can tailor the front end to make it really easy to run
[00:07:48.520 --> 00:07:52.400]   certain workloads. But the problem is, if you are doing
[00:07:52.400 --> 00:07:55.720]   something that's quite different from what these systems were
[00:07:55.720 --> 00:08:00.120]   designed for, it's easy to fall off usability cliffs. And then
[00:08:00.120 --> 00:08:04.240]   if you want to change them, or like, do something a bit
[00:08:04.240 --> 00:08:08.240]   different, you're forced to go down into this like C and CUDA.
[00:08:08.240 --> 00:08:11.760]   And it's worse, right? Because because the code is duplicated,
[00:08:11.760 --> 00:08:15.680]   if I write, if I want to add some functionality, I have to
[00:08:15.680 --> 00:08:18.720]   implement it in principle in both C and CUDA. So I have to
[00:08:18.720 --> 00:08:22.400]   understand this like very kind of complicated tech stack.
[00:08:23.360 --> 00:08:28.360]   Moreover, all derivatives usually are handwritten. So so
[00:08:28.360 --> 00:08:32.880]   you know, I don't think the other two points here, I think
[00:08:32.880 --> 00:08:36.520]   there are positives to at this point, I'm pretty convinced that
[00:08:36.520 --> 00:08:38.760]   we should use automatic differentiation for everything.
[00:08:38.760 --> 00:08:42.160]   So anyway, this is like, I think pretty laborious and error
[00:08:42.160 --> 00:08:45.160]   prone. And altogether, what this means is that for a graduate
[00:08:45.160 --> 00:08:48.320]   student, starting out in physics, if they want to do
[00:08:48.320 --> 00:08:51.800]   something a bit different from the usual, new ideas can take
[00:08:51.800 --> 00:08:54.880]   months, because you have to compute all the derivatives,
[00:08:54.880 --> 00:08:58.040]   which can be complicated. You and like papers have been
[00:08:58.040 --> 00:09:00.800]   written about how to basically apply the chain rule in
[00:09:00.800 --> 00:09:04.120]   different situations. And then implementing these ideas can be
[00:09:04.120 --> 00:09:07.160]   hard. And I think it's an especially bad fit, if what you
[00:09:07.160 --> 00:09:11.240]   want to do is combine machine learning and physics. Because
[00:09:11.240 --> 00:09:15.120]   machine learning involves complicated derivatives and
[00:09:15.120 --> 00:09:17.880]   simulations that maybe don't look exactly like the
[00:09:17.880 --> 00:09:22.040]   simulations we're used to. So it's it can be somewhat
[00:09:22.040 --> 00:09:25.360]   difficult to merge these not impossible, people do it, but I
[00:09:25.360 --> 00:09:31.480]   think it adds a lot of friction. So so what I wanted to do, you
[00:09:31.480 --> 00:09:33.960]   know, with this project was to take inspiration from machine
[00:09:33.960 --> 00:09:36.040]   learning, because I think machine learning has great
[00:09:36.040 --> 00:09:41.000]   tools. Like, I think the machine learning libraries overall are
[00:09:41.000 --> 00:09:44.800]   all fantastic, compared to what people are using in the other
[00:09:44.800 --> 00:09:47.840]   sciences. And I think there are sort of two things that have
[00:09:47.840 --> 00:09:51.760]   really driven these tools to be so good. The first is automatic
[00:09:51.760 --> 00:09:54.800]   differentiation. And the second is this like just in time
[00:09:54.800 --> 00:09:58.840]   compilation, or like, you know, compiling to like a graph and
[00:09:58.840 --> 00:10:02.720]   then executing the graph and having these two things be done
[00:10:02.720 --> 00:10:09.520]   very efficiently. So with JaxMD, I wanted to target certain high
[00:10:09.520 --> 00:10:14.040]   level features, I wanted it to be easy to express complicated
[00:10:14.040 --> 00:10:18.560]   simulations. So there were two corollaries to this first
[00:10:18.560 --> 00:10:21.320]   simulation code should be written in the same language as
[00:10:21.320 --> 00:10:26.600]   experiments. So if you're a researcher, and you are trying
[00:10:26.600 --> 00:10:31.280]   to do some exotic simulation, you should be able to write code
[00:10:31.280 --> 00:10:33.880]   that's at the same level as the rest of the library without ever
[00:10:33.880 --> 00:10:37.680]   leaving Python. And the other idea is that we wanted it to be
[00:10:37.680 --> 00:10:41.000]   functional. So we wanted to borrow from Jax because I really
[00:10:41.000 --> 00:10:44.880]   like the functional style of Jax. So we wanted it to be
[00:10:44.880 --> 00:10:47.560]   functional with loosely connected primitives that can be
[00:10:47.560 --> 00:10:50.880]   composed. And so this lets you build new simulations by
[00:10:50.880 --> 00:10:54.640]   composing these sort of like primitives that are just
[00:10:54.640 --> 00:11:00.840]   generically useful. I also we also wanted JaxMD to be fast
[00:11:00.840 --> 00:11:03.480]   enough to do high quality research. As I said, I think
[00:11:03.480 --> 00:11:07.040]   existing libraries are just super, super well tuned. So it's
[00:11:07.040 --> 00:11:10.680]   unlikely that we'll be faster than those. But I think we can
[00:11:10.680 --> 00:11:14.840]   be sort of competitive enough that for a researcher, the
[00:11:14.840 --> 00:11:19.200]   the increased iteration speed of like writing research code is
[00:11:19.200 --> 00:11:23.480]   worth it. So we do this in two ways. We use, you know, just in
[00:11:23.480 --> 00:11:28.600]   time compile compilation to CPU, GPU, or TPU via XLA. And then as
[00:11:28.600 --> 00:11:32.080]   I'll talk about a little later, we've implemented certain
[00:11:32.080 --> 00:11:37.200]   spatial partitioning strategies that let us do calculate do
[00:11:37.200 --> 00:11:40.200]   simulations in like order n where n is the number of atoms
[00:11:40.200 --> 00:11:43.760]   in the system rather than n squared. So I'll talk, don't
[00:11:43.760 --> 00:11:46.920]   worry about that too much. I'll talk about it more in a little
[00:11:46.920 --> 00:11:50.000]   while. And then finally, we wanted machine learning to be a
[00:11:50.000 --> 00:11:54.320]   first class citizen. And to us that meant two things. One, any
[00:11:54.320 --> 00:11:57.960]   function should be a neural network. So if you want the
[00:11:57.960 --> 00:12:00.760]   simulation to be driven by a neural network, that should be
[00:12:00.760 --> 00:12:05.760]   fine. But moreover, we wanted the whole simulations to be end
[00:12:05.760 --> 00:12:07.880]   to end differentiable. So if you wanted to do sort of like
[00:12:07.880 --> 00:12:10.560]   meta optimization or something where you're like, let's say,
[00:12:10.560 --> 00:12:17.200]   I'm simulating a material like, like glass or metal, and I are a
[00:12:17.200 --> 00:12:21.800]   metal alloy, for example, and I wanted to like tune the amount
[00:12:21.800 --> 00:12:26.640]   of or like the structure to make it extra hard, I should be able
[00:12:26.640 --> 00:12:29.880]   to be able to do that by differentiating through the
[00:12:29.880 --> 00:12:36.400]   entire simulation. So these were the goals. I do think there are
[00:12:36.400 --> 00:12:39.680]   some limitations. Right now, as I said, we're slower than
[00:12:39.680 --> 00:12:44.280]   specialized software, and not all JIT backends are created
[00:12:44.280 --> 00:12:48.240]   equal. So the performance is not consistent across backends. I
[00:12:48.240 --> 00:12:51.160]   think actually, though, we've had some real improvement
[00:12:51.160 --> 00:12:56.840]   recently, and we're like maybe 30%, or so I think slower on
[00:12:56.840 --> 00:13:02.040]   GPU, which is our best backend CPU is a lot slower. And then
[00:13:02.040 --> 00:13:04.280]   we're missing some simulation environments. So we're always
[00:13:04.280 --> 00:13:09.760]   trying to increase the number of features as users want them. So
[00:13:09.760 --> 00:13:13.520]   we're still lacking, you know, long range interactions and
[00:13:13.520 --> 00:13:15.720]   systems with internal degrees of freedom. Don't worry too much
[00:13:15.720 --> 00:13:18.600]   about that. But anyway, we're all always trying to add more,
[00:13:18.600 --> 00:13:27.480]   add more. So I know this is the JAX talk series. So probably
[00:13:27.480 --> 00:13:30.160]   everyone is familiar with JAX. But just in case there were
[00:13:30.160 --> 00:13:32.520]   people here who like were not familiar with JAX, I wanted to
[00:13:32.520 --> 00:13:37.800]   give a two second high level overview. You know, JAX is a new
[00:13:37.800 --> 00:13:41.840]   machine learning library out of Google. It's the spiritual
[00:13:41.840 --> 00:13:46.880]   successor to AutoGrad, if you're familiar with that, and a lot of
[00:13:46.880 --> 00:13:50.720]   the same folks worked on both. It's basically NumPy on GPU with
[00:13:50.720 --> 00:13:53.640]   certain composable function transformations like the
[00:13:53.640 --> 00:13:56.560]   gradient, just-in-time compilation, or automatic
[00:13:56.560 --> 00:14:04.280]   vectorization, and it's functional. So I'll just go
[00:14:04.280 --> 00:14:07.000]   through like three examples of the three major function
[00:14:07.000 --> 00:14:12.520]   transformations. Grad, where like, I take a function f of x,
[00:14:12.520 --> 00:14:14.920]   which computes, let's say the dot product between two vectors
[00:14:14.920 --> 00:14:20.120]   x and itself, and I compute df as grad of f will give me a new
[00:14:20.120 --> 00:14:22.640]   function that computes the gradient. And so then I can
[00:14:22.640 --> 00:14:27.280]   either apply f of x, or I can apply df of x and get the
[00:14:27.280 --> 00:14:34.400]   gradient. JIT compiles to device. So let's say I have
[00:14:34.400 --> 00:14:38.080]   this, it returns a new function that compiles to device. So
[00:14:38.080 --> 00:14:41.360]   let's say I have a function f of x. And let's say this
[00:14:41.360 --> 00:14:44.400]   computes the dot product between x and itself, and then it adds
[00:14:44.400 --> 00:14:47.000]   the dot product of x and itself. So this, you know, this would be
[00:14:47.000 --> 00:14:52.000]   a stupid way to write the code, but I could do it. And if I
[00:14:52.000 --> 00:14:55.880]   were to just execute f of x, this would be executed as three
[00:14:55.880 --> 00:14:58.800]   separate calls to the GPU. So this would be like op by op
[00:14:58.800 --> 00:15:04.880]   mode in PyTorch or eager TensorFlow. If I wrap f in a JIT,
[00:15:04.880 --> 00:15:09.360]   then it executes as a single call. And moreover, XLA will
[00:15:09.360 --> 00:15:12.440]   optimize the code so that it won't even calculate the dot
[00:15:12.440 --> 00:15:14.880]   product twice, probably. It'll just do like twice the dot
[00:15:14.880 --> 00:15:18.760]   product. So it will do like common sub expression
[00:15:18.760 --> 00:15:23.760]   elimination and get rid of the extra dot product call. And
[00:15:23.760 --> 00:15:26.840]   finally, automatic vectorization, which is my
[00:15:26.840 --> 00:15:30.680]   personal favorite, I think, of the three, lets you take a
[00:15:30.680 --> 00:15:33.360]   function that applies to a single input and apply it over a
[00:15:33.360 --> 00:15:36.280]   batch of inputs. So here we have our function computing the dot
[00:15:36.280 --> 00:15:40.680]   product between the vector and itself. And if we VMAP f, we can
[00:15:40.680 --> 00:15:45.760]   apply it to a matrix of like vectors or like an array of
[00:15:45.760 --> 00:15:50.040]   vectors, and we'll get the dot product of the array with
[00:15:50.040 --> 00:15:52.880]   itself, or each vector with itself. And then this is nice
[00:15:52.880 --> 00:15:55.760]   because you don't need to think about batch dimensions, you can
[00:15:55.760 --> 00:15:59.640]   write code. And we use we use VMAP all over the place in
[00:15:59.640 --> 00:16:03.320]   Jacksonville. And I can maybe explain where we use it, if it
[00:16:03.320 --> 00:16:06.120]   would be interesting to people, because I think it's a super
[00:16:06.120 --> 00:16:14.040]   powerful tool. Okay, so I guess I'd like to give a very high
[00:16:14.040 --> 00:16:20.040]   level overview of the design. Again, I think this will make
[00:16:20.040 --> 00:16:23.120]   more sense, we'll go into a demo in a second and kind of walk
[00:16:23.120 --> 00:16:24.760]   through the different pieces, but I wanted to have like a
[00:16:24.760 --> 00:16:30.760]   bird's eye view before we do so. So at the lowest level of every
[00:16:30.760 --> 00:16:35.320]   simulation, we have sort of a notion of space, which is what's
[00:16:35.320 --> 00:16:38.000]   the space in which the simulation is being performed.
[00:16:38.000 --> 00:16:41.040]   And this might be just like Euclidean space. So this might
[00:16:41.040 --> 00:16:43.840]   just be like all the points are in two or three dimensions.
[00:16:44.240 --> 00:16:48.760]   But often what you do in physics is you have periodic boundary
[00:16:48.760 --> 00:16:51.560]   conditions. And you can think of that sort of like, I don't know
[00:16:51.560 --> 00:16:54.480]   if you've played the old video game asteroids, you know how
[00:16:54.480 --> 00:16:56.560]   you'd like you could go around the side of the screen, you'd
[00:16:56.560 --> 00:16:59.760]   wrap to the other side of the screen. So often in physics,
[00:16:59.760 --> 00:17:04.920]   because materials in the real world are huge, and they have
[00:17:04.920 --> 00:17:11.160]   like 10 to the 23 or 10 to the 30 atoms or whatever. And we
[00:17:11.160 --> 00:17:15.240]   can't simulate that. What we often do is we take our system
[00:17:15.240 --> 00:17:18.360]   and we wrap around the sides to try to like make it appear
[00:17:18.360 --> 00:17:21.000]   bigger than it is. And so this is what's called periodic
[00:17:21.000 --> 00:17:23.880]   boundary conditions. So you might have like normal space,
[00:17:23.880 --> 00:17:28.040]   you might have like periodic boundary conditions. And so
[00:17:28.040 --> 00:17:30.600]   spaces is like the first thing you need to specify when you're
[00:17:30.600 --> 00:17:34.680]   thinking about a simulation. On top of that, as I mentioned, we
[00:17:34.680 --> 00:17:39.040]   have these spatial partitioning systems, which basically take a
[00:17:39.040 --> 00:17:43.800]   system of particles or atoms, and separate it out into local
[00:17:43.800 --> 00:17:47.560]   neighborhoods. And I think maybe of all the pieces of Jax MD,
[00:17:47.560 --> 00:17:50.600]   this is the one that maybe is most generically useful to
[00:17:50.600 --> 00:17:54.040]   people. For example, there's like a lot of pure machine
[00:17:54.040 --> 00:17:56.040]   learning research that has nothing to do with molecular
[00:17:56.040 --> 00:17:59.760]   dynamics, that is like point cloud research. And I think one
[00:17:59.760 --> 00:18:03.640]   of the things that one of the things that you might want to do
[00:18:03.640 --> 00:18:08.040]   in point cloud research is separate points into local
[00:18:08.040 --> 00:18:10.160]   neighborhoods. So you don't need to consider all pairs of
[00:18:10.160 --> 00:18:13.080]   points, you can consider just like local regions of points. So
[00:18:13.080 --> 00:18:16.480]   so spatial partitioning does that. And I'll show you some
[00:18:16.480 --> 00:18:19.800]   examples later. And it lets us scale to really large systems.
[00:18:19.800 --> 00:18:24.680]   We have vectorization utilities that are all built on top of the
[00:18:24.680 --> 00:18:30.720]   map. And this lets you take a define a quantity for like one
[00:18:30.720 --> 00:18:35.000]   pair of atoms or one pair of particles and vectorize it over
[00:18:35.000 --> 00:18:38.120]   a whole system of particles. And then we have neural network
[00:18:38.120 --> 00:18:43.160]   primitives that you can use to drive simulations. Then we have
[00:18:43.160 --> 00:18:45.680]   a bunch of different energy energy functions. And I'm going
[00:18:45.680 --> 00:18:48.440]   to talk about this a little later. But I'm going to use the
[00:18:48.440 --> 00:18:52.160]   term energy because that's the common term in physics. If
[00:18:52.160 --> 00:18:56.040]   you're in machine learning, and you come from a machine learning
[00:18:56.040 --> 00:19:00.000]   background, energy is basically loss. They're very, they're very
[00:19:00.000 --> 00:19:04.160]   similar concepts. So in physics, you define like the energy
[00:19:04.160 --> 00:19:06.360]   function in machine learning, you'll define like the loss
[00:19:06.360 --> 00:19:10.400]   function. So just keeping that in mind, we have a bunch of
[00:19:10.400 --> 00:19:12.480]   different energy functions or a bunch of different loss
[00:19:12.480 --> 00:19:16.760]   functions. And then, then we have like higher level tools
[00:19:16.760 --> 00:19:20.240]   built on top of these, we have a bunch of minimizers that like,
[00:19:20.240 --> 00:19:24.400]   you know, you can think of stochastic gradient descent, or
[00:19:24.400 --> 00:19:29.520]   like momentum optimizer, physical systems, because have a
[00:19:29.520 --> 00:19:32.760]   bunch, the minimizers that are good in machine learning are
[00:19:32.760 --> 00:19:36.080]   typically not very good in in physics, and vice versa. In
[00:19:36.080 --> 00:19:38.680]   physics, you're always doing like full batch minimization,
[00:19:38.680 --> 00:19:41.920]   you don't have a notion of many batches. And you don't really
[00:19:41.920 --> 00:19:44.640]   have stochasticity for many batches. So typically,
[00:19:44.640 --> 00:19:46.960]   different minimizers are better. So we have a couple different
[00:19:46.960 --> 00:19:50.720]   minimizers, then we have a bunch of simulation environments to
[00:19:50.720 --> 00:19:54.520]   simulate systems in different settings. And I'll talk about
[00:19:54.520 --> 00:19:57.520]   some of those in a little while. And then we have some higher
[00:19:57.520 --> 00:20:00.520]   level tools to analyze the properties of these systems.
[00:20:01.520 --> 00:20:04.960]   And I think next, I have a demo. If there are any questions at
[00:20:04.960 --> 00:20:07.720]   this point, I'm happy to answer them. If not, I'm also happy to
[00:20:07.720 --> 00:20:09.240]   just dive, dive right in.
[00:20:09.240 --> 00:20:15.000]   Hey, Sam, I think I think we can get one of the questions. Sir
[00:20:15.000 --> 00:20:18.680]   Makash, he says like, what are your favorite features from
[00:20:18.680 --> 00:20:19.320]   Jax?
[00:20:19.320 --> 00:20:28.040]   From Jax? So absolutely love Vmap. I can't wait to see what
[00:20:28.040 --> 00:20:34.800]   you think of Vmap. I think that Vmap so so one of the great
[00:20:34.800 --> 00:20:38.280]   things I think about Vmap is that it lets you define a
[00:20:38.280 --> 00:20:43.800]   function once, and then use it in so many different ways. So
[00:20:43.800 --> 00:20:49.400]   for example, when we define our notion of a space, and I'll show
[00:20:49.400 --> 00:20:54.440]   this in a little while, we define a function that computes
[00:20:54.440 --> 00:20:57.280]   basically the displacement vector between two points. So if
[00:20:57.280 --> 00:21:00.960]   I have a set of points, it calculates the vector between
[00:21:00.960 --> 00:21:04.040]   those points. And that's like the fundamental thing that we
[00:21:04.040 --> 00:21:09.000]   define. When we want to actually use that, we use that in all
[00:21:09.000 --> 00:21:14.960]   sorts of ways. So for example, if I'm computing what, without
[00:21:14.960 --> 00:21:18.560]   spatial partitioning, I might want to compute the displacement
[00:21:18.560 --> 00:21:21.960]   vector between all pairs of points in a system. So that's
[00:21:22.000 --> 00:21:27.400]   to double Vmap. If I'm computing the displacement, if I'm using
[00:21:27.400 --> 00:21:30.360]   spatial partitioning, we actually include two different
[00:21:30.360 --> 00:21:32.640]   formats for the spatial partitioning. And the only reason
[00:21:32.640 --> 00:21:35.240]   why we can do that is because the two different formats for
[00:21:35.240 --> 00:21:40.160]   spatial partitioning correspond to two different Vmaps, or two
[00:21:40.160 --> 00:21:45.240]   different ways of applying Vmap to the displacement functions.
[00:21:45.240 --> 00:21:51.600]   So like, we're able to like get a lot of usage out of the same
[00:21:51.600 --> 00:21:56.920]   functions by applying Vmap in lots of different ways. So I
[00:21:56.920 --> 00:22:01.160]   think that's my favorite part, I think. And then I would say
[00:22:01.160 --> 00:22:09.600]   that just in general, I really like how unopinionated Jax is. I
[00:22:09.600 --> 00:22:12.600]   guess like, there's been some conversations lately about, I
[00:22:12.600 --> 00:22:17.120]   think, I'm biased because I think I'm biased, and probably
[00:22:17.120 --> 00:22:20.240]   not in a way that's helpful for most people, because I don't, I
[00:22:20.240 --> 00:22:23.480]   don't do some machine learning, but I don't do like, you know,
[00:22:23.480 --> 00:22:28.160]   my core research is not training models. Sometimes it is. But I
[00:22:28.160 --> 00:22:31.800]   think that, for example, having a privileged notion of like a TF
[00:22:31.800 --> 00:22:38.320]   variable, or like a PyTorch var, like, I think that's not maybe
[00:22:38.320 --> 00:22:42.440]   so helpful. So not, like kind of some of the stuff that I really
[00:22:42.440 --> 00:22:45.000]   like about Jax is that they've excluded things like that. I
[00:22:45.000 --> 00:22:50.160]   also have to say, I really like, similar to Vmap, Jax's
[00:22:50.160 --> 00:22:54.040]   parallelization story. So like, I think Pmap is really pretty
[00:22:54.040 --> 00:22:58.240]   easy to use. I haven't yet used like the Pjit or Xmap. So I
[00:22:58.240 --> 00:23:02.240]   don't have opinions about those. But the parallelization, I think
[00:23:02.240 --> 00:23:05.600]   I found it very easy as like someone who's never done much
[00:23:05.600 --> 00:23:09.880]   parallel computing. I've been able to get like a lot of large
[00:23:09.880 --> 00:23:13.640]   scale computing stuff working. So So yeah, so I think I also
[00:23:13.640 --> 00:23:17.440]   I could I could talk a lot about. Those are my highlights,
[00:23:17.440 --> 00:23:17.960]   though, I think.
[00:23:17.960 --> 00:23:20.880]   Have you used mask the mask transform?
[00:23:20.880 --> 00:23:26.800]   You know, I haven't. It's funny, we do a lot of masking actually
[00:23:26.800 --> 00:23:31.440]   in in Jax MD. And it's one of those things. I think one of the
[00:23:31.440 --> 00:23:35.000]   things that there's like pluses and minuses to me having started
[00:23:35.000 --> 00:23:37.680]   the project or perhaps having started the project so long ago.
[00:23:38.760 --> 00:23:45.360]   Like on the one hand, it's great, because we have been like
[00:23:45.360 --> 00:23:48.440]   maybe a little ahead of a little ahead of the curve. On the other
[00:23:48.440 --> 00:23:51.960]   hand, we've sort of had to implement a lot of stuff that
[00:23:51.960 --> 00:23:55.320]   the Jax team maybe has implemented better afterwards. So
[00:23:55.320 --> 00:24:01.400]   like, I think we do a lot of our own masking. Jax now, I don't
[00:24:01.400 --> 00:24:03.840]   know what the status of the masking is, because I like I
[00:24:03.840 --> 00:24:06.720]   said, I haven't used it. But I think like, for example, that's
[00:24:06.760 --> 00:24:11.160]   that's one place where maybe their solution would be a lot
[00:24:11.160 --> 00:24:15.320]   nicer than ours. So yes, it's on my list.
[00:24:15.320 --> 00:24:21.080]   I haven't used it, but I saw some spoilers. So I know that
[00:24:21.080 --> 00:24:23.840]   you guys do really awesome stuff with that with masking.
[00:24:23.840 --> 00:24:28.280]   Yeah, I have not yet. But I do think that it's one of the
[00:24:28.280 --> 00:24:31.760]   features that I'm really excited to try out. There's a bunch
[00:24:31.760 --> 00:24:36.200]   there's I think I am really excited about X map. Also, I
[00:24:36.200 --> 00:24:42.320]   think it seems super, super cool. And I think you know, the
[00:24:42.320 --> 00:24:47.880]   one Yeah, I think overall, very happy. I think there's like also
[00:24:47.880 --> 00:24:51.880]   spark like the sparse library stuff is coming along. And I
[00:24:51.880 --> 00:24:53.640]   haven't really played around with that. They've been adding
[00:24:53.640 --> 00:24:59.600]   so much stuff and I just haven't had time. Cool. Yeah. If there
[00:24:59.600 --> 00:25:04.200]   are any other questions happy, happy to answer. Otherwise also
[00:25:04.200 --> 00:25:06.920]   happy to do the demo, or go start the demo.
[00:25:06.920 --> 00:25:11.560]   There's a very controversial question here. Have you looked
[00:25:11.560 --> 00:25:14.520]   into the Julia side of what people are doing around this?
[00:25:14.520 --> 00:25:18.680]   Yeah, so people I think the most common question I get actually
[00:25:18.680 --> 00:25:25.520]   is is about Julia. And sadly, I will say that Julia has been on
[00:25:25.520 --> 00:25:28.480]   the list of things that I really want to learn for a long time.
[00:25:28.480 --> 00:25:32.360]   And I just like haven't. I think Julia seems awesome. Just to say
[00:25:32.400 --> 00:25:38.320]   I think there's certain areas where Julia seems a lot better,
[00:25:38.320 --> 00:25:42.600]   like for or have more stuff like I think for physical systems,
[00:25:42.600 --> 00:25:47.040]   they're like, I've been really impressed by their the things
[00:25:47.040 --> 00:25:51.400]   they've been working on for like different auto depth. And I know
[00:25:51.400 --> 00:25:54.400]   there is a molecular dynamics library in Julia, I just haven't
[00:25:54.400 --> 00:26:01.600]   used it. I will say I think, I think that it's a trade off. I
[00:26:01.600 --> 00:26:07.120]   think Julia, as far as I can tell, is lower level, it's
[00:26:07.120 --> 00:26:11.560]   trying to be somewhere between like C and Python with a lot of
[00:26:11.560 --> 00:26:17.040]   nice features. Python is higher level. And I think what that
[00:26:17.040 --> 00:26:21.040]   means is that there are things you can express in Julia that
[00:26:21.040 --> 00:26:28.360]   you can't express efficiently in Python or in jacks. However, I
[00:26:28.360 --> 00:26:34.320]   think that the code you write in jacks is very easy to understand
[00:26:34.320 --> 00:26:40.240]   typically, and very high level. And I think what that means is
[00:26:40.240 --> 00:26:45.800]   you lose some expressivity. But what you gain is that like you,
[00:26:45.800 --> 00:26:49.640]   you know, it's really easy for someone to come along and look
[00:26:49.640 --> 00:26:52.920]   at the jacks MD code and understand sort of for the most
[00:26:52.920 --> 00:26:57.960]   part what's going on. I think I imagine but I'm not sure,
[00:26:58.120 --> 00:27:02.200]   that some of the Julia stuff to be efficient, you need to get
[00:27:02.200 --> 00:27:05.480]   slightly lower level. Like for example, I know that Julia has
[00:27:05.480 --> 00:27:09.320]   like GPU, like, one of the things that I don't I don't
[00:27:09.320 --> 00:27:13.080]   understand, again, I might be saying stuff that's wrong. But
[00:27:13.080 --> 00:27:16.160]   this is my like, loose impression. However, I will say
[00:27:16.160 --> 00:27:19.280]   Julia seems super nice. And I really want to, it's it's high
[00:27:19.280 --> 00:27:21.120]   on my list of things to learn. I just think it's a trade off. I
[00:27:21.120 --> 00:27:24.720]   think you can express more stuff in Julia, but it's a bit lower
[00:27:24.720 --> 00:27:25.000]   level.
[00:27:25.000 --> 00:27:35.240]   And I think, maybe at some point, I will learn some Julia
[00:27:35.240 --> 00:27:36.880]   and then be able to say smarter stuff about it.
[00:27:36.880 --> 00:27:47.720]   Okay. Um, so yeah, so so maybe I'll start doing some demo work
[00:27:47.880 --> 00:27:58.440]   stuff. And again, I want for the most part. I can make. Okay, I
[00:27:58.440 --> 00:28:01.000]   wanted this demo, because I wasn't sure what the background
[00:28:01.000 --> 00:28:03.400]   of people would be. I wanted this demo to be very
[00:28:03.400 --> 00:28:05.160]   I'm sorry, I don't see anything.
[00:28:05.160 --> 00:28:07.520]   Oh, you don't? Okay, great. Thanks for letting me know. I
[00:28:07.520 --> 00:28:13.920]   think I need to stop and then reshare. This happens sometimes
[00:28:13.920 --> 00:28:19.000]   when I leave keynote. Okay, is that
[00:28:19.000 --> 00:28:20.520]   we can see it now? Yeah, thank you.
[00:28:20.520 --> 00:28:24.760]   Yeah. So I wanted this demo to be very like kind of fun, and
[00:28:24.760 --> 00:28:28.680]   not much physics. Because I thought, you know, I don't know,
[00:28:28.680 --> 00:28:31.880]   I think it's more of a machine learning crowd. And anyway, I
[00:28:31.880 --> 00:28:33.920]   think there's nothing wrong. I think one thing people think
[00:28:33.920 --> 00:28:36.920]   that, oh, if you're doing physics, it has to be like, very
[00:28:36.920 --> 00:28:40.160]   sterile, but you can I think, make it kind of fun. Okay, so
[00:28:40.200 --> 00:28:44.360]   what we're gonna do in the demo is, we're gonna, we're gonna
[00:28:44.360 --> 00:28:48.840]   try to like make a sandcastle, and then blow it up. That's,
[00:28:48.840 --> 00:28:55.040]   that's the goal. Okay. And so what I'm gonna do first is I
[00:28:55.040 --> 00:28:59.040]   have this little helper function. And this takes an
[00:28:59.040 --> 00:29:02.640]   image. And by the way, this is this notebook I put online. So
[00:29:02.640 --> 00:29:05.840]   if you go into Jackson D notebooks, sandcastle, you'll
[00:29:05.840 --> 00:29:08.880]   find basically this code. So so the first thing we're going to
[00:29:08.880 --> 00:29:14.520]   do is this, this code takes an image, and it fills in the
[00:29:14.520 --> 00:29:18.880]   pixels with like particles that I'm going to call grains of
[00:29:18.880 --> 00:29:21.560]   sand. So it's going to return three things, it's going to
[00:29:21.560 --> 00:29:27.560]   return the size of the image, the positions of the particles
[00:29:27.560 --> 00:29:30.040]   or the grains and the color of the grains, because they're
[00:29:30.040 --> 00:29:33.280]   going to correspond to the image. And so one of the things
[00:29:33.280 --> 00:29:35.880]   that Jackson D has, which I think might be useful for some
[00:29:35.880 --> 00:29:39.160]   people is it has a render that you can use from Colab. So you
[00:29:39.160 --> 00:29:44.560]   can just say, we're going to render an image of the size box,
[00:29:44.560 --> 00:29:47.880]   which is our simulation volume. And we're just going to put some
[00:29:47.880 --> 00:29:53.800]   disks with the given color at the right positions. So this is,
[00:29:53.800 --> 00:29:57.920]   this is the image that we loaded, I will say so this, this
[00:29:57.920 --> 00:30:03.480]   24 here, this number 24 is like, how much we're discretizing the
[00:30:03.480 --> 00:30:06.160]   image. So we took a high resolution image, and we sort of
[00:30:06.160 --> 00:30:10.640]   sub sampled it down into these like grains.
[00:30:10.640 --> 00:30:15.600]   Some just to clarify, it's taken from an image, but there they
[00:30:15.600 --> 00:30:16.680]   are particles.
[00:30:16.680 --> 00:30:22.080]   The image is just an image, image, I think I can just like
[00:30:22.080 --> 00:30:24.680]   look at it, right? Or can I I don't, I don't know, I don't
[00:30:24.680 --> 00:30:27.440]   know how to do this in I don't know how. Oh, there we go.
[00:30:27.440 --> 00:30:28.760]   Oops. Oh, what am I doing?
[00:30:28.760 --> 00:30:30.840]   I don't think to the right.
[00:30:30.880 --> 00:30:36.680]   Oh, right. Okay, so this is the image. And what I'm doing is,
[00:30:36.680 --> 00:30:42.320]   I'm basically going into the image. And I'm taking 24 by 24
[00:30:42.320 --> 00:30:47.840]   blocks. And I'm replacing it by a particle of grain, like so
[00:30:47.840 --> 00:30:50.640]   now I'm like discretizing it into particles. And each
[00:30:50.640 --> 00:30:53.360]   particle has the color of like the pixels that it's on top.
[00:30:53.360 --> 00:31:00.600]   Okay, so it's it's it is it is. So we're doing a
[00:31:00.600 --> 00:31:03.760]   discretization. And what we'll do later is we'll change the
[00:31:03.760 --> 00:31:07.120]   discretization. So so one thing we can do is we can be like, how
[00:31:07.120 --> 00:31:10.800]   many how many particles are there. And so positions, we can
[00:31:10.800 --> 00:31:13.480]   just like even look at we can be like, what is positions. So
[00:31:13.480 --> 00:31:19.120]   positions is is is an array, it's a it's a jacked array. And
[00:31:19.120 --> 00:31:23.040]   there are an end, it's a we can look at the shape to if we want.
[00:31:24.480 --> 00:31:31.400]   And we see that it's a 1616 by two, so there are 1616 grains of
[00:31:31.400 --> 00:31:39.880]   sand in two dimensions. And sort of, as I mentioned before, we
[00:31:39.880 --> 00:31:42.280]   the first thing we want to do whenever we're running a
[00:31:42.280 --> 00:31:45.400]   simulation like this is we want to define a space in which the
[00:31:45.400 --> 00:31:51.080]   simulation lives. So so I can, Jackson D has this library called
[00:31:51.080 --> 00:31:56.040]   space, and we can make a periodic boundary condition
[00:31:56.040 --> 00:32:01.160]   space. And there are a space is really two functions. It's a
[00:32:01.160 --> 00:32:04.720]   displacement function. And the displacement function computes
[00:32:04.720 --> 00:32:09.640]   displacements between particle or grains. So I can give it the
[00:32:09.640 --> 00:32:13.520]   position of the first atom and the position of the last grain,
[00:32:13.520 --> 00:32:18.200]   and it will give me a vector between them. And it also knows
[00:32:18.200 --> 00:32:23.960]   how to move grains. So so I can give it a position of a grain
[00:32:23.960 --> 00:32:27.240]   and an amount that I want to displace it by, and it will
[00:32:27.240 --> 00:32:32.120]   return a new position that's just shifted 10 to the right.
[00:32:32.120 --> 00:32:34.560]   It's really cool.
[00:32:34.560 --> 00:32:37.480]   So what we do is we you know, we take this image, and then we
[00:32:37.480 --> 00:32:41.440]   sub sample it. And so boxes just the image, the size of the image
[00:32:41.440 --> 00:32:42.000]   basically,
[00:32:42.000 --> 00:32:44.920]   after sub sampling.
[00:32:45.720 --> 00:32:49.680]   And when you pass it to periodic, that's kind of the
[00:32:49.680 --> 00:32:53.760]   like within height of the space.
[00:32:53.760 --> 00:32:57.400]   Yeah, exactly. So this so because we're doing periodic
[00:32:57.400 --> 00:33:01.360]   boundaries, you have to know how big the boundary is, where things
[00:33:01.360 --> 00:33:06.040]   will start wrapping around. And so that's what box tells it. Box,
[00:33:06.040 --> 00:33:12.440]   if you wanted to, you could also have box be like, an array that
[00:33:12.440 --> 00:33:17.400]   is like 118 by 118, for example, or like something else. So like,
[00:33:17.400 --> 00:33:21.800]   you could have it be like 118 by like 200, if you wanted. So so
[00:33:21.800 --> 00:33:24.880]   box can be a scalar, in which case it's assumed that the two
[00:33:24.880 --> 00:33:31.000]   sides are equal. Or it can be a vector of dimension, the size of
[00:33:31.000 --> 00:33:36.560]   the space, or the dimension of the space, and then it specifies
[00:33:36.560 --> 00:33:38.360]   the different axes separately.
[00:33:40.800 --> 00:33:45.120]   And then you have other spaces that are a little more nuanced
[00:33:45.120 --> 00:33:45.480]   also.
[00:33:45.480 --> 00:33:52.720]   So yeah, so then, then, as I said, you know, we want, we want
[00:33:52.720 --> 00:33:55.840]   to simulate the system and the way, like kind of like in
[00:33:55.840 --> 00:33:58.400]   machine learning, where if you have a problem, you need to
[00:33:58.400 --> 00:34:01.760]   define a loss function. In physics, we need to define an
[00:34:01.760 --> 00:34:07.360]   energy, which is going to be like, dictate. And in physics,
[00:34:07.360 --> 00:34:10.760]   you know, in nature, typically tries to like lower the energy
[00:34:11.160 --> 00:34:17.520]   to the lowest. And so what we want is we want an energy so
[00:34:17.520 --> 00:34:21.640]   that like the low, low energies correspond to like the behavior
[00:34:21.640 --> 00:34:26.480]   that we'd like to observe. And what we're going to do is we're
[00:34:26.480 --> 00:34:29.720]   going to do something that's like quite common in physics.
[00:34:29.720 --> 00:34:32.440]   And it's also common in machine learning. So what we're going to
[00:34:32.440 --> 00:34:34.760]   do is we're going to write down instead of, you know, we have
[00:34:34.760 --> 00:34:37.480]   all these grains of sand, instead of writing down an
[00:34:37.480 --> 00:34:40.720]   energy that's like a function of all the grains, we're going to
[00:34:40.720 --> 00:34:44.600]   write a function of just two of the grains. And then the total
[00:34:44.600 --> 00:34:49.920]   energy is going to be the sum of all pairs. So this is like n
[00:34:49.920 --> 00:34:54.080]   squared, basically. And it's going to be a sum of all pairs
[00:34:54.080 --> 00:34:58.520]   of grains, touch in, like, between like the energy between
[00:34:58.520 --> 00:35:02.720]   each pair. And you can think of all this, like, very similar to
[00:35:02.720 --> 00:35:07.440]   like, you know, writing down a loss in terms of a sum over data
[00:35:07.440 --> 00:35:12.680]   basically. So we want to model like sand that's maybe like a
[00:35:12.680 --> 00:35:18.600]   little bit wet. And what does wet sand do? So the grains of
[00:35:18.600 --> 00:35:21.920]   sand are very hard. So if you have two grains of sand, they
[00:35:21.920 --> 00:35:27.120]   can't interpenetrate hardly at all. But they stick together
[00:35:27.120 --> 00:35:30.400]   just a little bit because there's some water and the water
[00:35:30.400 --> 00:35:35.760]   causes an interaction that causes grains of sand to be a
[00:35:35.760 --> 00:35:38.760]   little bit sticky. And you know, if you've ever like been on a
[00:35:38.760 --> 00:35:41.880]   beach and like touch wet sand, you know that like kind of has
[00:35:41.880 --> 00:35:45.120]   some form that like sticks together. And the other thing is
[00:35:45.120 --> 00:35:47.080]   that grains of sand that are far away from each other don't
[00:35:47.080 --> 00:35:49.240]   notice each other at all. So if I have two grains of sand that
[00:35:49.240 --> 00:35:51.240]   are far from each other on a beach, they won't, they don't
[00:35:51.240 --> 00:35:56.400]   know that they exist. So we're going to use an energy function
[00:35:56.400 --> 00:36:00.200]   that is very common in physics. It's called the Leonard Jones
[00:36:00.200 --> 00:36:04.920]   energy. And so what I'm plotting here is and so in JaxMD, you
[00:36:04.920 --> 00:36:07.600]   just write energy dot Leonard Jones, and you give it the
[00:36:07.600 --> 00:36:10.240]   distance. So it's a function only of the distance between the
[00:36:10.240 --> 00:36:13.880]   grains of sand. So here I'm plotting the energy as a
[00:36:13.880 --> 00:36:17.200]   function of the distance. And what you see is for for
[00:36:17.200 --> 00:36:21.000]   distances less than about one, the energy is really high. And
[00:36:21.000 --> 00:36:25.320]   that means that if two grains of sand are closer than about one
[00:36:25.320 --> 00:36:28.600]   from each other, they'll really push each other apart very hard.
[00:36:29.880 --> 00:36:34.240]   And then if and then at when they went for very large values
[00:36:34.240 --> 00:36:38.040]   of distance, so when they're far apart, the energy goes to zero.
[00:36:38.040 --> 00:36:42.160]   So so far apart grains of sand don't don't touch each other at
[00:36:42.160 --> 00:36:47.000]   all. However, grains of sand that are kind of close to each
[00:36:47.000 --> 00:36:51.800]   other will have an energy that's less than zero. This is a little
[00:36:51.800 --> 00:36:56.920]   maybe and so so here is where they'd like to be. So so there's
[00:36:56.920 --> 00:36:59.840]   a little bit of attraction, because grains of sand would
[00:36:59.840 --> 00:37:04.680]   like in principle, to be maybe a little bit large, higher than
[00:37:04.680 --> 00:37:07.360]   their their radius. And there's, you know, maybe a little bit of
[00:37:07.360 --> 00:37:09.920]   water just between them. So that's, that's what we're going
[00:37:09.920 --> 00:37:15.640]   for here is, and so so, you know, we use this Leonard Jones,
[00:37:15.640 --> 00:37:18.880]   and this is an example of VMAP, by the way. So so we define
[00:37:18.880 --> 00:37:22.480]   Leonard Jones to be a function of the distance. And then we
[00:37:22.480 --> 00:37:25.360]   define this helper function, Leonard Jones pair, which
[00:37:25.360 --> 00:37:30.680]   computes the full energy between all pairs of atoms. So we give
[00:37:30.680 --> 00:37:33.800]   the Leonard Jones pair function, the displacement function, which
[00:37:33.800 --> 00:37:37.400]   says, we're going to tell it how to measure displacements. And
[00:37:37.400 --> 00:37:41.200]   then we can just feed in the positions, and we can get an
[00:37:41.200 --> 00:37:45.920]   energy. So this is like the energy of the whole system of
[00:37:45.920 --> 00:37:52.560]   all the of all the grains. And now now we can simulate. So so
[00:37:52.560 --> 00:37:54.680]   what we're going to do is we're going to just define some
[00:37:54.680 --> 00:37:58.000]   simulation parameters. So we're going to simulate for 10,000
[00:37:58.000 --> 00:38:01.200]   steps. And we're going to write out some information about the
[00:38:01.200 --> 00:38:07.720]   simulation every 50 steps. And then I, you can use so we're
[00:38:07.720 --> 00:38:10.720]   going to use a simulation environment called launch event
[00:38:10.720 --> 00:38:13.080]   dynamics, which you might be familiar with, which is used in
[00:38:13.080 --> 00:38:18.040]   machine learning a lot, also. And we give and so all the
[00:38:18.040 --> 00:38:21.400]   simulation environments in Jax MD, are written in exactly the
[00:38:21.400 --> 00:38:25.000]   same way as all the optimizers in Jax or all the optimizers in
[00:38:25.000 --> 00:38:28.840]   optics. So they have an initialization function that
[00:38:28.840 --> 00:38:31.560]   initializes the state of the simulation and a step function
[00:38:31.560 --> 00:38:35.600]   which takes one step of the simulation. So the launch event
[00:38:35.600 --> 00:38:40.160]   dynamics, you give it, we're going to give it the energy. And
[00:38:40.160 --> 00:38:43.080]   it also needs to know how to move things around. And then
[00:38:43.080 --> 00:38:46.080]   we're going to give it a step size, we're going to say, okay,
[00:38:46.080 --> 00:38:49.440]   we're at zero temperature. And gamma is like a damping
[00:38:49.440 --> 00:38:52.000]   parameter. So it says how damp the dynamics are. So this is
[00:38:52.000 --> 00:38:54.960]   just a number that I chose out of thin air, because it made
[00:38:54.960 --> 00:38:59.400]   videos that kind of look nice. But it's, you know, pretty
[00:38:59.400 --> 00:39:02.000]   arbitrary. And so then what we're going to do is we're going
[00:39:02.000 --> 00:39:05.120]   to initialize the state of the simulation, and we just give it
[00:39:05.120 --> 00:39:08.840]   a random key and the positions. And then we're going to JIT
[00:39:08.840 --> 00:39:14.560]   compile the step function. So this this sets up our simulation
[00:39:14.560 --> 00:39:16.480]   and now we just run our simulation. So we're going to
[00:39:16.480 --> 00:39:19.880]   run for the number of steps. And then we're going to take a
[00:39:19.880 --> 00:39:23.760]   step every step by taking one step of our step function. And
[00:39:23.760 --> 00:39:26.560]   we're going to have a trajectory which just records the position
[00:39:26.560 --> 00:39:30.560]   of the atom of the grains of sand every step, or every every
[00:39:30.560 --> 00:39:43.880]   right every step, so every 50 steps. Okay. And so now that
[00:39:43.880 --> 00:39:48.120]   it's running, now that it's run, we can we can draw the the
[00:39:48.120 --> 00:39:55.360]   simulation. And this will just take a moment, one thing that is
[00:39:55.360 --> 00:39:58.920]   like the slowest part, actually, which I think, okay, so here's
[00:39:58.920 --> 00:40:02.800]   the simulation. And so we can see that, like, everything is
[00:40:02.800 --> 00:40:04.800]   sticking together. I don't know if you can make it out, I'll
[00:40:04.800 --> 00:40:08.280]   like zoom in. But like, the the particles are like wiggling
[00:40:08.280 --> 00:40:11.440]   around a little bit. So when you first start the simulation, the
[00:40:11.480 --> 00:40:14.480]   the sand isn't exactly where it wants to be. So it starts like
[00:40:14.480 --> 00:40:20.440]   jostling a little bit. And we can make the simulation a little
[00:40:20.440 --> 00:40:23.160]   bit faster if we want to, this will be useful later on, which
[00:40:23.160 --> 00:40:26.960]   is why I'm doing it here. You might know, so so one thing
[00:40:26.960 --> 00:40:30.720]   about the code that we have up here is that this for loop is
[00:40:30.720 --> 00:40:36.280]   written in Python. And so we are just in time compiling the
[00:40:36.280 --> 00:40:40.200]   steps, but we're not just in time compiling multiple steps
[00:40:40.200 --> 00:40:43.840]   together, which can be a bit faster. So we're going to write
[00:40:43.840 --> 00:40:47.200]   a slightly different simulation function. And what we're going
[00:40:47.200 --> 00:40:57.520]   to do here is we are going to use so Jax has these loop
[00:40:57.520 --> 00:41:02.280]   constructs, which are compiled down to single calls to the GPU.
[00:41:02.280 --> 00:41:04.200]   And so what we're going to do is we're going to have a
[00:41:04.200 --> 00:41:08.920]   simulation function that takes the sand and the trajectory. And
[00:41:08.920 --> 00:41:13.160]   we're going to write out the positions to the trajectory. And
[00:41:13.160 --> 00:41:18.600]   then we're going to do an inner loop that takes 50 steps and
[00:41:18.600 --> 00:41:22.160]   just applies the step function. So this takes 50 steps, writes
[00:41:22.160 --> 00:41:25.240]   the trajectory, take 50 steps, and then it returns the new
[00:41:25.240 --> 00:41:29.520]   state and the new trajectory. And this is going to be and
[00:41:29.520 --> 00:41:33.320]   then we're going to just run it by doing another for I loop over
[00:41:33.320 --> 00:41:37.840]   the total number of remaining steps. And this, this will be
[00:41:37.840 --> 00:41:40.520]   like a little bit faster. It won't be much faster, but it'll
[00:41:40.520 --> 00:41:43.840]   be nice because now we're compiling everything. So if we
[00:41:43.840 --> 00:41:46.240]   want to write what we're going to do in a minute is we're going
[00:41:46.240 --> 00:41:50.240]   to write some custom simulation code in here. And we're not,
[00:41:50.240 --> 00:41:54.880]   we're going to be exactly as fast as the Langevin dynamics
[00:41:54.880 --> 00:41:57.640]   that we wrote that Jax MD comes with, because we're just in time
[00:41:57.640 --> 00:42:00.640]   compiling everything together. So this, this rendering code is
[00:42:00.640 --> 00:42:04.600]   going to look identical. We almost don't need to run it, but
[00:42:05.360 --> 00:42:11.720]   I will. Okay. Okay. Yeah. So here, here we go. Same thing
[00:42:11.720 --> 00:42:14.760]   happens. I think it's actually like very similar trajectory.
[00:42:14.760 --> 00:42:19.600]   Okay. So, and I'm just gonna, because I'm on my laptop and not
[00:42:19.600 --> 00:42:23.720]   my desktop, I am going to clear the output on both of these
[00:42:23.720 --> 00:42:29.480]   before we go forward. And if, you know, if there are any
[00:42:29.480 --> 00:42:32.120]   questions, happy to take some now before we move on to the
[00:42:32.120 --> 00:42:38.840]   next step. But also happy to just look good for now. I'll ask
[00:42:38.840 --> 00:42:43.120]   some questions at the end. Okay, great. So, so yeah, so now
[00:42:43.120 --> 00:42:46.160]   let's like blow up the sandcastle, which I think is the
[00:42:46.160 --> 00:42:50.240]   most fun part. And what we're going to do is we're going to
[00:42:50.240 --> 00:42:52.960]   have a projectile and the projectile is just going to be a
[00:42:52.960 --> 00:42:57.040]   position. So we're going to start it off at, I could make
[00:42:57.040 --> 00:43:02.160]   that zero, at just like a third of the way up the image and zero
[00:43:02.160 --> 00:43:07.280]   in the X direction. It's also going to have a radius, a
[00:43:07.280 --> 00:43:13.920]   strength, which is like how strongly does it repel the, the
[00:43:13.920 --> 00:43:16.920]   grains of sand. And it's going to have a velocity because like
[00:43:16.920 --> 00:43:22.280]   how fast is the projectile moving. And in physics, when you
[00:43:22.280 --> 00:43:25.320]   want to add something to a simulation, basically you just
[00:43:25.360 --> 00:43:28.000]   add something to the energy. So there's like this very nice
[00:43:28.000 --> 00:43:32.600]   analogy between like writing simulations and, or like
[00:43:32.600 --> 00:43:39.080]   modeling nature and adding terms to the energy. And so like,
[00:43:39.080 --> 00:43:41.240]   there's this thing, I don't know if you've looked at it, but
[00:43:41.240 --> 00:43:43.520]   there's this equation that goes around sometimes called like the
[00:43:43.520 --> 00:43:46.760]   standard model, which is like the model for like the universe.
[00:43:46.760 --> 00:43:49.880]   And it's just like a lot of terms in an energy function. So
[00:43:49.880 --> 00:43:53.360]   like, you know, maybe the universe is just really like
[00:43:53.360 --> 00:43:57.360]   this. So anyway, what we're going to do is this, this term
[00:43:57.360 --> 00:44:01.920]   is what we already had. And then this term is our energy between
[00:44:01.920 --> 00:44:05.720]   the sand and the projectile, the grains of sand and the
[00:44:05.720 --> 00:44:10.120]   projectile. And so what we're going to do is we're going to,
[00:44:10.120 --> 00:44:16.240]   we're going to use, we want the projectile to only repel the
[00:44:16.240 --> 00:44:19.120]   sand. So unlike the sand, which has this like little bit of
[00:44:19.120 --> 00:44:25.680]   attraction, the projectile is not going to have any
[00:44:25.680 --> 00:44:27.920]   attraction. So we're going to use an energy called soft
[00:44:27.920 --> 00:44:31.760]   sphere. It sounds soft, but we're going to, we're going to
[00:44:31.760 --> 00:44:34.440]   use 1000 for the strength. So it's actually not so soft. And
[00:44:34.440 --> 00:44:38.240]   so we can plot. So the blue is the Leonard Jones that we're
[00:44:38.240 --> 00:44:42.160]   using for the sand. And the orange is the energy that we're
[00:44:42.160 --> 00:44:45.480]   using for the projectile. And so what you see is like, basically
[00:44:45.480 --> 00:44:48.320]   it doesn't do anything, but then if it hits the sand, it pushes
[00:44:48.320 --> 00:44:52.440]   it away. So the energy cost for having the grains of sand close
[00:44:52.440 --> 00:44:55.000]   to each other is very high, or the grains of sand near the
[00:44:55.000 --> 00:44:58.400]   projectile is very high, but otherwise it doesn't affect them
[00:44:58.400 --> 00:45:04.400]   at all. And we're going to write that down by writing a
[00:45:04.400 --> 00:45:07.720]   projectile energy, which gets the sand, the position of the
[00:45:07.720 --> 00:45:10.840]   sand and the position of the projectile. We're going to
[00:45:10.840 --> 00:45:15.480]   compute the distance between the sand and the projectile. And
[00:45:15.480 --> 00:45:20.520]   then we're going to compute the energy, um, uh, based on the
[00:45:20.520 --> 00:45:24.720]   distance, and we're going to give it the strength and we're
[00:45:24.720 --> 00:45:27.120]   going to give it the size of the projectile. So we give it the
[00:45:27.120 --> 00:45:30.320]   size of the projectile. We give it the, the strength of the
[00:45:30.320 --> 00:45:33.000]   interaction and we give it the distance between the two things,
[00:45:33.000 --> 00:45:35.840]   the, the sand and the projectile. And then we sum over
[00:45:35.840 --> 00:45:39.640]   all the different grains of sand. And then our total energy,
[00:45:39.640 --> 00:45:43.960]   just as we wrote this above, the total energy is the energy of
[00:45:43.960 --> 00:45:47.720]   the sand, which between the grains of sand and the energy
[00:45:47.720 --> 00:45:53.120]   between the sand and the projectile. Um, and then what
[00:45:53.120 --> 00:45:56.680]   we're going to do is because we now have a sand and a
[00:45:56.680 --> 00:46:00.440]   projectile, we're going to have a little bit of a state. I'm
[00:46:00.440 --> 00:46:04.000]   just going to add this little convenience function or class to
[00:46:04.000 --> 00:46:07.320]   store the state of the system. So we're going to have the sand,
[00:46:07.320 --> 00:46:11.280]   which is going to be simulated using this like NVT Langevin
[00:46:11.280 --> 00:46:14.160]   dynamics. And then the projectile, we don't need
[00:46:14.160 --> 00:46:17.960]   anything. We're just going to have it be a position. Um, and
[00:46:17.960 --> 00:46:22.680]   now we're going to reinitialize our Langevin dynamics, but we're
[00:46:22.680 --> 00:46:25.160]   going to give it the total energy instead of the, just the
[00:46:25.160 --> 00:46:30.160]   energy between, uh, of, of the sand. Um, and then we're going
[00:46:30.160 --> 00:46:34.080]   to run our simulation and this code looks almost identical to
[00:46:34.080 --> 00:46:38.120]   the code above, but what we're going to do is our trajectory is
[00:46:38.120 --> 00:46:43.040]   also going to be a sand castle and it's going to store the sand
[00:46:43.040 --> 00:46:47.800]   position and the projectile position at each time step. And
[00:46:47.800 --> 00:46:50.240]   then our step function that we're going to use to actually
[00:46:50.240 --> 00:46:55.720]   simulate the dynamics is going to take one step of dynamics on
[00:46:55.720 --> 00:46:59.120]   the sand. And we're going to pass in the projectile position.
[00:46:59.120 --> 00:47:02.840]   And then we're just going to update the projectile by, by the
[00:47:02.840 --> 00:47:06.040]   velocity. So we're going to like move the projectile a little bit
[00:47:06.040 --> 00:47:10.760]   by the velocity, and we're going to update the step using the
[00:47:10.760 --> 00:47:13.560]   Langevin dynamics. And we're going to have a four eye loop
[00:47:13.560 --> 00:47:16.560]   that runs this for 50 steps. And then the outer loop is going to
[00:47:16.560 --> 00:47:20.760]   run for, uh, the total number of simulation steps. So we're going
[00:47:20.760 --> 00:47:21.840]   to run this simulation.
[00:47:21.840 --> 00:47:24.400]   Where does velocity come from here?
[00:47:24.400 --> 00:47:31.240]   Oh, we just put it in, uh, up here. So we just specified it as
[00:47:31.240 --> 00:47:35.960]   a global, like just, so I just chose this to look, to look
[00:47:35.960 --> 00:47:36.800]   nice. There's no, there's no,
[00:47:36.800 --> 00:47:38.800]   So it's just going to move linearly and, and.
[00:47:38.800 --> 00:47:41.800]   Yeah, it's just going to move a little bit every, every frame.
[00:47:41.800 --> 00:47:45.880]   And, you know, to be honest, if we wanted to make it better, we
[00:47:45.880 --> 00:47:48.680]   would have like DT, this time step be a parameter and it would
[00:47:48.680 --> 00:47:52.200]   really be like velocity times DT, but you know, just for the
[00:47:52.200 --> 00:47:56.240]   purposes of the demo, I think, uh, it's okay. So anyway, yeah,
[00:47:56.240 --> 00:47:59.240]   we ran, we ran the simulation and now let's, let's see what
[00:47:59.240 --> 00:48:02.120]   happens. So we can, we can now draw it. So, so the render can
[00:48:02.120 --> 00:48:05.280]   take multiple things. So now we'll, we'll draw the sand and
[00:48:05.280 --> 00:48:07.400]   we'll draw the, uh, projectile.
[00:48:07.400 --> 00:48:09.480]   That's two separate things.
[00:48:09.480 --> 00:48:19.600]   That's awesome. Why doesn't the ball reappear?
[00:48:19.600 --> 00:48:24.440]   Uh, so the ball, yeah, great question. So the ball, uh,
[00:48:24.440 --> 00:48:29.280]   doesn't reappear because here we're just doing state dot
[00:48:29.280 --> 00:48:30.920]   projectile plus velocity.
[00:48:32.360 --> 00:48:38.360]   We could do shift fun of state dot projectile comma velocity.
[00:48:38.360 --> 00:48:40.600]   And now if we ran this
[00:48:40.600 --> 00:48:49.040]   in a second,
[00:49:00.920 --> 00:49:03.320]   it's so cool to visually see this happening.
[00:49:03.320 --> 00:49:08.080]   Yeah. I think that's the thing. I think a lot of, yeah. So now
[00:49:08.080 --> 00:49:09.160]   it'll go back around.
[00:49:09.160 --> 00:49:15.560]   Oh, I feel like I'll just keep running this demo for like five
[00:49:15.560 --> 00:49:18.240]   to 10 hours just to enjoy it, just to play around with
[00:49:18.240 --> 00:49:19.040]   velocities.
[00:49:19.040 --> 00:49:24.560]   I have to say, like, I think the most time I spent like preparing
[00:49:24.560 --> 00:49:30.600]   the talk was like playing around with the visuals. Yeah. Um, and
[00:49:30.600 --> 00:49:32.920]   I think that's one thing, like when you're doing machine
[00:49:32.920 --> 00:49:35.680]   molecular dynamics normally, like it's very disconnected from
[00:49:35.680 --> 00:49:39.440]   the visualization. So I, we did try quite hard to like make it
[00:49:39.440 --> 00:49:41.160]   feel more interactive.
[00:49:41.160 --> 00:49:49.760]   Have a couple of questions. Okay. The first one is, is this
[00:49:49.760 --> 00:49:53.840]   like visualization library? Can you run it outside of Colab
[00:49:53.840 --> 00:49:55.800]   because it's super nice.
[00:49:56.360 --> 00:50:02.600]   Um, that's a good question. I have not made it work outside of
[00:50:02.600 --> 00:50:06.920]   Colab. I told, I think, okay. So the way it works is there's a
[00:50:06.920 --> 00:50:12.720]   JavaScript code that runs in, I mean, so it will work in any
[00:50:12.720 --> 00:50:16.080]   IPython notebook, I guess is one thing I would say. So if you
[00:50:16.080 --> 00:50:20.000]   were using it locally with IPython, it would work there. Um,
[00:50:20.000 --> 00:50:22.960]   I think it wouldn't be too much work in principle to get it to
[00:50:22.960 --> 00:50:26.560]   work elsewhere. The problem is that it, so it uses, um,
[00:50:26.560 --> 00:50:31.040]   JavaScript front end, and then it transfers the data actually
[00:50:31.040 --> 00:50:35.120]   from the kernel to the front end. So that part I think would
[00:50:35.120 --> 00:50:39.240]   need to be replaced because if you were running it externally,
[00:50:39.240 --> 00:50:40.840]   you wouldn't have a kernel.
[00:50:40.840 --> 00:50:44.960]   So it's like a, an IPython widget.
[00:50:44.960 --> 00:50:49.400]   It's it's yeah, exactly. It's an IPython widget. Exactly. Um,
[00:50:49.400 --> 00:50:52.920]   and so that's why when there's a lag, actually the longest part
[00:50:52.920 --> 00:50:56.960]   is, um, is running, uh, is, is doing the data transfer
[00:50:56.960 --> 00:50:57.520]   actually.
[00:50:57.520 --> 00:51:04.120]   Makes sense. But it's super nice because I, I think I, in my
[00:51:04.120 --> 00:51:07.680]   Jack's 27 days of Jack's, I did something with physics.
[00:51:07.680 --> 00:51:09.840]   I saw it. I liked it a lot.
[00:51:09.840 --> 00:51:15.120]   And, and I mean, if I had this, it would have been like five
[00:51:15.120 --> 00:51:16.240]   times more beautiful.
[00:51:16.240 --> 00:51:20.360]   So, yeah. So, so I guess like one thing I would say is like,
[00:51:20.360 --> 00:51:24.120]   you know, I think Jackson V is a pretty, I don't know, pretty
[00:51:24.120 --> 00:51:27.360]   lightweight dependency. So like people should definitely feel
[00:51:27.360 --> 00:51:30.200]   free to like use one part of it and discard the rest if it's
[00:51:30.200 --> 00:51:33.640]   not useful. Um, so I do think that this kind of like, by the
[00:51:33.640 --> 00:51:36.200]   way, all of this also works in, I have a, I don't know if we'll
[00:51:36.200 --> 00:51:39.960]   get to it, but there's a, it all works in 3d too. Um, so you can
[00:51:39.960 --> 00:51:40.480]   do 3d.
[00:51:40.480 --> 00:51:41.200]   That's awesome.
[00:51:41.200 --> 00:51:45.760]   Oh, wow. Maybe I should upgrade just for fun. Try to upgrade
[00:51:45.760 --> 00:51:48.480]   what I did and see if it works out. That would be awesome.
[00:51:49.200 --> 00:51:52.880]   I do have some, there is a question. I have a related
[00:51:52.880 --> 00:51:58.080]   question, maybe I'll mix in the two. Um, like, I don't know. I
[00:51:58.080 --> 00:52:04.400]   think, well, there, there are like, it's exactly that one.
[00:52:04.400 --> 00:52:07.520]   There, there's kind of different ways to do simulations, like
[00:52:07.520 --> 00:52:15.440]   ODEs or finite elements. Um, and can you give us, and this one,
[00:52:15.440 --> 00:52:18.320]   I guess it's energy based. I don't know if you could call it
[00:52:18.320 --> 00:52:21.680]   that. Uh, can you give it like an overview of when would you
[00:52:21.680 --> 00:52:24.560]   use each type?
[00:52:24.560 --> 00:52:27.600]   So, so there's a bunch of different simulation environments
[00:52:27.600 --> 00:52:36.000]   that we include and usually, so I think, you know, one of the
[00:52:36.000 --> 00:52:39.840]   things in physics simulations, that's, it's, it's kind of a
[00:52:39.840 --> 00:52:45.040]   subtle point, but when you want to simulate a physical system,
[00:52:47.280 --> 00:52:50.240]   you want to make sure there's sort of like a distribution that
[00:52:50.240 --> 00:52:53.760]   you want to be sampling from in the same way as like, you know,
[00:52:53.760 --> 00:52:57.200]   if you have like a VAE or something and you want to sample
[00:52:57.200 --> 00:53:00.960]   from the posterior, there's, there's a specific distribution
[00:53:00.960 --> 00:53:04.400]   that you would hopefully like to sample from. So one of the
[00:53:04.400 --> 00:53:09.520]   things that we've tried hard to get right is to make sure that
[00:53:09.520 --> 00:53:12.240]   the distribution you're sampling from is the distribution you
[00:53:12.240 --> 00:53:16.320]   think you're sampling from. And so that's why in these systems,
[00:53:16.320 --> 00:53:19.600]   you typically don't just want to use a standard ODE solver.
[00:53:19.600 --> 00:53:24.800]   You can. So there's actually a group that's using JAX-MD, like
[00:53:24.800 --> 00:53:29.200]   using the energy part of JAX-MD and the spaces, but it's just
[00:53:29.200 --> 00:53:35.040]   using a standard, like a, a, a Runge-Kutta ODE solver on top
[00:53:35.040 --> 00:53:37.760]   of it. So, so, so, you know, it's one of those things where
[00:53:37.760 --> 00:53:42.400]   again, like really, like you can combine, there are ODE
[00:53:42.400 --> 00:53:47.200]   solvers in JAX, right. And like, you can just use the other
[00:53:47.200 --> 00:53:49.680]   parts of JAX-MD with those solvers. The simulation
[00:53:49.680 --> 00:53:53.840]   environments in JAX-MD are typically designed to be quite
[00:53:53.840 --> 00:53:58.640]   careful in simulating the right distribution. And so for
[00:53:58.640 --> 00:54:01.680]   example, this system, we use like this NVT Langevin
[00:54:01.680 --> 00:54:06.320]   simulation and Langevin dynamics are typically for systems where
[00:54:06.320 --> 00:54:12.320]   you have some like particles in like a solution or something.
[00:54:12.320 --> 00:54:15.120]   So here I was like, okay, we have sand and it's sort of like
[00:54:15.120 --> 00:54:17.920]   in the air and maybe the air here is like a little too
[00:54:17.920 --> 00:54:21.920]   viscous, but basically the idea was we want something, see how
[00:54:21.920 --> 00:54:26.240]   like these particles sort of like slow down as they move. We
[00:54:26.240 --> 00:54:29.040]   want something to stop everything from just like moving
[00:54:29.040 --> 00:54:33.280]   indefinitely. We want like, we, we want some, some friction.
[00:54:33.280 --> 00:54:37.920]   And so that's why I chose that here. Often my favorite is
[00:54:37.920 --> 00:54:42.080]   something called NVT Nozze-Hoover. NVT, by the way, I
[00:54:42.080 --> 00:54:45.840]   should have said this earlier, basically means that it's being
[00:54:45.840 --> 00:54:51.360]   simulated at a certain temperature. Whereas, so, so, so
[00:54:51.360 --> 00:54:54.800]   if you just do a normal ODE solver, you'll be simulating a
[00:54:54.800 --> 00:54:58.000]   constant energy, which is fine. But, you know, if you're talking
[00:54:58.000 --> 00:55:01.360]   about like a system in the real world, usually that's not a
[00:55:01.360 --> 00:55:04.400]   constant energy, it's a constant temperature. And so one of the
[00:55:04.400 --> 00:55:06.320]   things these simulation environments do is keep the
[00:55:06.320 --> 00:55:10.480]   system at a fixed temperature. I don't know if that helps. Is
[00:55:10.480 --> 00:55:12.560]   that like a kind of an answer? I don't know.
[00:55:12.560 --> 00:55:18.240]   >> I mean, I think it does. I have like an additional
[00:55:18.240 --> 00:55:22.640]   question. Like, can you mix, let's say an energy with an ODE
[00:55:22.640 --> 00:55:26.720]   like kind of, okay, I have this ODE, but then I'm going to add
[00:55:26.720 --> 00:55:28.720]   like an energy term. Is that kind of a thing?
[00:55:28.720 --> 00:55:32.000]   >> Yeah. So, so one of the things you can do, right, is
[00:55:32.000 --> 00:55:36.080]   under the hood, when you pass an energy to, I can show you,
[00:55:37.040 --> 00:55:40.400]   when you pass an energy, what we're really doing, so,
[00:55:40.400 --> 00:55:46.640]   you have this library called quantity, which has some useful
[00:55:46.640 --> 00:55:50.160]   quantities. And we could be like, what we do is we convert
[00:55:50.160 --> 00:55:54.240]   it to a force, which is basically the negative gradient.
[00:55:54.240 --> 00:56:02.720]   So if you did this, right, if I did this, and then I looked at
[00:56:02.720 --> 00:56:12.960]   like the shape, projectile, okay. So, so here, this is now
[00:56:12.960 --> 00:56:17.920]   a 16 by 16, 16 by two vector. And this, you could plug
[00:56:17.920 --> 00:56:22.160]   directly into an ODE solver as the update.
[00:56:22.160 --> 00:56:26.720]   >> Oh, that's really interesting. But you, you, and
[00:56:26.720 --> 00:56:29.840]   what you showed us, you don't, you don't do this, or do you?
[00:56:29.840 --> 00:56:34.240]   >> We do. So, so Jax MD handles that for you.
[00:56:34.240 --> 00:56:35.600]   >> Oh, interesting.
[00:56:35.600 --> 00:56:38.400]   >> One thing we could do, for example, just to show you is if
[00:56:38.400 --> 00:56:46.240]   I were like quantity dot force, total energy here, this would
[00:56:46.240 --> 00:56:54.560]   be fine. This would just work. And it's just, what we do is we
[00:56:54.560 --> 00:56:59.040]   detect internally, whether you pass an energy or a force. And
[00:56:59.040 --> 00:57:02.640]   if you pass an energy, we just take the force for you. Because
[00:57:02.640 --> 00:57:06.160]   it's so common to pass energies. But, but yeah, if you
[00:57:06.160 --> 00:57:10.080]   were using like a, the Jax ODE solver, for example, you would
[00:57:10.080 --> 00:57:11.120]   just do this yourself.
[00:57:11.120 --> 00:57:17.040]   >> Yeah, I, I did that myself. So I was wondering like, okay,
[00:57:17.040 --> 00:57:21.920]   for, I, I did it in gravity, right? I was wondering, okay,
[00:57:21.920 --> 00:57:25.840]   how can I frame, reframe it such that I could do the gravity
[00:57:25.840 --> 00:57:31.200]   simulation with Jax MD? I think it's possible.
[00:57:31.200 --> 00:57:35.280]   >> Oh yeah. So if you wanted to do, so like, for example, right,
[00:57:35.280 --> 00:57:42.400]   we could be like gravity energy. Let's say I had a position,
[00:57:42.400 --> 00:57:46.480]   like positions or something, right? We would want to do
[00:57:46.480 --> 00:57:52.960]   something like return one over, like, so what we would do is we
[00:57:52.960 --> 00:57:57.600]   would use space. We have this, this helper function, map
[00:57:57.600 --> 00:58:03.520]   product, which is a wrapper on VMAP. And so this, this compute
[00:58:03.520 --> 00:58:06.640]   all pairs of displacements and we would give it positions,
[00:58:06.640 --> 00:58:10.320]   positions. So this would give all pairs of displacements
[00:58:10.320 --> 00:58:14.160]   between all vectors. And then we would be like, dr is like
[00:58:14.160 --> 00:58:17.920]   space dot distance, dr. So this gets all the distances. And
[00:58:17.920 --> 00:58:22.880]   then we could return something like, sum of like one over
[00:58:23.280 --> 00:58:28.080]   dr squared, basically. And this would be like more or less
[00:58:28.080 --> 00:58:32.160]   gravity. And then you could take the gradient of this and
[00:58:32.160 --> 00:58:36.240]   feed it into the ODE solver. Or you could do, if you did like,
[00:58:36.240 --> 00:58:39.680]   there's a simulate that NDE, which is constant energy. And
[00:58:39.680 --> 00:58:44.240]   you were just like gravity energy, comma shift, comma dt
[00:58:44.240 --> 00:58:48.560]   is like one E minus three. This would be like a good gravity
[00:58:48.560 --> 00:58:49.760]   simulation, for example.
[00:58:50.480 --> 00:58:54.880]   But like the formula is really similar to the one of the force,
[00:58:54.880 --> 00:58:58.240]   right? It's, you kind of just set the energy to something like
[00:58:58.240 --> 00:58:59.760]   the force and that's kind of the trick.
[00:58:59.760 --> 00:59:05.680]   So the, so this is the equation for the, for the energy. And
[00:59:05.680 --> 00:59:08.720]   then the, when you, when you calculate the force by, so this
[00:59:08.720 --> 00:59:11.200]   will calculate the force using autodiff, but if you're
[00:59:11.200 --> 00:59:15.200]   calculating the force by hand, basically what happens, I think
[00:59:15.200 --> 00:59:22.880]   is this becomes one over R times like dr over dr. Usually.
[00:59:22.880 --> 00:59:26.160]   Yeah. Oh, something like this.
[00:59:26.160 --> 00:59:29.920]   Very interesting. I'll give it a try. It sounds really cool.
[00:59:29.920 --> 00:59:35.120]   Yeah. I love, I love how you just think of, of the, like, I
[00:59:35.120 --> 00:59:38.240]   know it's kind of a simpler mental framework thinking about
[00:59:38.240 --> 00:59:39.520]   energies, it seems.
[00:59:39.520 --> 00:59:42.000]   Well, so that's actually one of the things that I really like
[00:59:42.000 --> 00:59:46.240]   about having the autodiff is when you're doing things using
[00:59:46.240 --> 00:59:51.520]   classical MD packages, you have to think about the force, but
[00:59:51.520 --> 00:59:55.760]   it's really like you would like actually to, in most cases,
[00:59:55.760 --> 00:59:59.200]   just think about the energy because it's simpler and you,
[00:59:59.200 --> 01:00:01.120]   you don't have to do as much work.
[01:00:01.120 --> 01:00:05.600]   Almost always the energy is the simpler thing to think about.
[01:00:05.600 --> 01:00:06.100]   I think.
[01:00:06.100 --> 01:00:10.480]   It's not here, but I remember your example from the Boids,
[01:00:10.480 --> 01:00:16.800]   the, I remember reading the energy function for that. And
[01:00:16.800 --> 01:00:20.800]   it was really intuitive, like, Hey, repel from this, go
[01:00:20.800 --> 01:00:22.560]   towards it. It was really fun.
[01:00:22.560 --> 01:00:29.840]   Yeah. Actually, I think physics, even like, even like particle
[01:00:29.840 --> 01:00:33.440]   physics, I would say is like, also shares that kind of
[01:00:33.440 --> 01:00:38.320]   intuition. You're like, Oh, so like, I think there's a lot
[01:00:38.320 --> 01:00:42.640]   more, I think that's like, actually like the, when you're
[01:00:42.640 --> 01:00:45.360]   trying to model something, it's like a very nice way of doing
[01:00:45.360 --> 01:00:47.680]   it is to be like, what are the properties that it has?
[01:00:47.680 --> 01:00:52.400]   How would I write this as like an energy or a loss problem?
[01:00:52.400 --> 01:00:56.960]   And then we can sort of get a lot for free.
[01:00:56.960 --> 01:01:01.540]   Okay.
[01:01:02.080 --> 01:01:06.320]   Okay. I have another question.
[01:01:06.320 --> 01:01:12.560]   Actually, what if I, so there's going to be one part at the end
[01:01:12.560 --> 01:01:13.360]   where, okay. Okay.
[01:01:13.360 --> 01:01:17.600]   Like I'm almost there, but there's going to be one part.
[01:01:17.600 --> 01:01:20.000]   Okay. Let's do it at the end.
[01:01:20.000 --> 01:01:23.520]   We have to wait a little bit because, because of the transfer
[01:01:23.520 --> 01:01:29.760]   to get the image to the thing. So, so, so maybe like, give me
[01:01:29.760 --> 01:01:33.280]   like two more minutes and then, and then I would love, I would
[01:01:33.280 --> 01:01:36.400]   love to take, but I actually, if it would be better now, that's
[01:01:36.400 --> 01:01:37.120]   also fine.
[01:01:37.120 --> 01:01:37.920]   No, no, no, no. Go ahead.
[01:01:37.920 --> 01:01:40.080]   Okay, cool.
[01:01:40.080 --> 01:01:43.360]   So, so, you know, this is, okay. The thing about this simulation
[01:01:43.360 --> 01:01:46.560]   is I think it's really fun. It's also like pretty small. So we
[01:01:46.560 --> 01:01:48.720]   had like a thousand grains.
[01:01:48.720 --> 01:01:52.960]   What I'd like to do is I'd like to do a much larger simulation.
[01:01:52.960 --> 01:01:57.360]   One of the things that we're doing in the simulation, right?
[01:01:57.360 --> 01:02:00.240]   Is at every step of the simulation, we're comparing the
[01:02:00.240 --> 01:02:02.800]   distance of every pair of grains.
[01:02:02.800 --> 01:02:05.280]   So this is like the order N squared algorithm.
[01:02:05.280 --> 01:02:08.240]   And so what I'd like to do is just show how we might go from
[01:02:08.240 --> 01:02:09.440]   N squared to order N.
[01:02:09.440 --> 01:02:14.080]   And so the first thing we're going to do is, remember we were
[01:02:14.080 --> 01:02:17.200]   discretizing in blocks of 24 pixels.
[01:02:17.200 --> 01:02:20.560]   I'm going to discretize in blocks of six pixels now.
[01:02:23.600 --> 01:02:28.800]   And this, this, this code to make the image, I didn't spend
[01:02:28.800 --> 01:02:30.080]   any time optimizing.
[01:02:30.080 --> 01:02:36.080]   So it's a little, it's a little painful, but it will, it will
[01:02:36.080 --> 01:02:38.320]   finish in like, I don't know.
[01:02:38.320 --> 01:02:40.480]   I think it takes like, I didn't time it.
[01:02:40.480 --> 01:02:45.280]   But the idea is going to be as this runs, the idea is going to
[01:02:45.280 --> 01:02:50.880]   be that instead of just computing the energy using all
[01:02:50.880 --> 01:02:54.400]   pairs, we're going to add a notion of like neighborhoods.
[01:02:54.400 --> 01:02:57.840]   And so what we're going to do is before we were using this
[01:02:57.840 --> 01:03:01.200]   function, Leonard Jones pair, and now we're using a function
[01:03:01.200 --> 01:03:04.240]   Leonard Jones neighborhood, neighbor list, which, which
[01:03:04.240 --> 01:03:08.320]   computes the energy using different local neighborhoods.
[01:03:08.320 --> 01:03:10.400]   Oh, here, so here's the new sandcastle.
[01:03:10.400 --> 01:03:13.280]   So this is a much higher resolution sandcastle.
[01:03:13.280 --> 01:03:15.840]   We can actually like make out the shell and the stars,
[01:03:16.560 --> 01:03:17.360]   dark fishes.
[01:03:17.360 --> 01:03:22.960]   And so what we're going to do is we're, and we're, is we're
[01:03:22.960 --> 01:03:25.600]   going to, and by the way, just like to go back to that
[01:03:25.600 --> 01:03:28.320]   question about what's my favorite Jax feature, Leonard
[01:03:28.320 --> 01:03:32.000]   Jones neighbor list and Leonard Jones pair are just two
[01:03:32.000 --> 01:03:35.440]   different V maps over the Leonard Jones energy.
[01:03:35.440 --> 01:03:36.960]   So that's all there they are.
[01:03:36.960 --> 01:03:41.680]   And so the neighbor, the neighbor, the neighbor list
[01:03:41.680 --> 01:03:42.720]   version gives two things.
[01:03:42.720 --> 01:03:45.680]   It gives a neighbor function, which computes neighborhoods
[01:03:45.680 --> 01:03:48.640]   and it gives an energy function, which computes the energy.
[01:03:48.640 --> 01:03:53.840]   And so when I want to compute neighborhoods, I, this is
[01:03:53.840 --> 01:03:57.840]   like a subtlety, but you know, within a JIT block, you can't
[01:03:57.840 --> 01:03:59.440]   do dynamic shapes.
[01:03:59.440 --> 01:04:02.400]   And so what you have to do is you have to allocate some
[01:04:02.400 --> 01:04:03.920]   amount of neighbors upfront.
[01:04:03.920 --> 01:04:05.920]   So this allocate function cannot be JIT.
[01:04:05.920 --> 01:04:08.480]   And we can ask how big it is.
[01:04:08.480 --> 01:04:12.400]   So this is saying we're allocating enough space for
[01:04:12.400 --> 01:04:18.560]   472,000 neighbors, and that's what it does is it takes the
[01:04:18.560 --> 01:04:21.360]   positions and it uses that to estimate the number of
[01:04:21.360 --> 01:04:22.240]   neighbors that we'll need.
[01:04:22.240 --> 01:04:27.280]   And then as before, we just define our total energy.
[01:04:27.280 --> 01:04:32.320]   And this time we just need to pass a neighbor into the
[01:04:32.320 --> 01:04:34.400]   neighbor, the neighborhood into the energy function.
[01:04:34.400 --> 01:04:37.200]   So the only change here from above is that now we're
[01:04:37.200 --> 01:04:38.160]   passing the neighborhood.
[01:04:40.880 --> 01:04:43.520]   And otherwise everything is really, really similar.
[01:04:43.520 --> 01:04:47.200]   So we're going to run 30,000 steps this time, and we're
[01:04:47.200 --> 01:04:48.560]   going to write out less frequently.
[01:04:48.560 --> 01:04:53.200]   Our projectile, we're going to make slightly bigger.
[01:04:53.200 --> 01:04:55.360]   So we're going to give it a radius of eight instead of a
[01:04:55.360 --> 01:04:56.240]   radius of two.
[01:04:56.240 --> 01:05:01.920]   Our state for our simulation is going to have the sand and
[01:05:01.920 --> 01:05:04.000]   the projectile, but now it's also going to have the
[01:05:04.000 --> 01:05:04.500]   neighborhood.
[01:05:04.500 --> 01:05:09.680]   And then we're going to still use the Langevin dynamics.
[01:05:10.240 --> 01:05:13.120]   And then our simulation function is also going to be
[01:05:13.120 --> 01:05:17.360]   very similar, except that in the step function, first we
[01:05:17.360 --> 01:05:22.400]   take a step, then we update the projectile, then we update
[01:05:22.400 --> 01:05:23.360]   the neighbor list.
[01:05:23.360 --> 01:05:26.240]   So we're going to say state.neighbor.update, and
[01:05:26.240 --> 01:05:27.680]   we're going to give it the new positions.
[01:05:27.680 --> 01:05:30.640]   And the update function can be JIT.
[01:05:30.640 --> 01:05:33.440]   So this will never change the size of the neighborhood.
[01:05:33.440 --> 01:05:36.480]   It will just update the neighborhoods with new
[01:05:36.480 --> 01:05:36.980]   positions.
[01:05:37.920 --> 01:05:41.840]   And so it's possible that if you allocate too small a
[01:05:41.840 --> 01:05:45.280]   neighbor list, this will not store everything.
[01:05:45.280 --> 01:05:48.160]   But I'll show you in a second that we can tell when it
[01:05:48.160 --> 01:05:48.660]   happens.
[01:05:48.660 --> 01:05:53.920]   So now we're just going to run this simulation using
[01:05:53.920 --> 01:05:54.480]   neighbor lists.
[01:05:54.480 --> 01:06:00.080]   And the only changes we needed to make to get neighbor
[01:06:00.080 --> 01:06:04.080]   lists working were to pass it into the energy function here
[01:06:04.080 --> 01:06:07.600]   and to update them.
[01:06:08.160 --> 01:06:08.660]   Yeah.
[01:06:08.660 --> 01:06:11.920]   And pass them into the step.
[01:06:11.920 --> 01:06:13.680]   So we pass the neighbor into the step.
[01:06:13.680 --> 01:06:15.680]   And OK, so we finished.
[01:06:15.680 --> 01:06:18.000]   And then we can ask-- so then we run the simulation.
[01:06:18.000 --> 01:06:21.680]   And then we can ask whether or not there was an overflow.
[01:06:21.680 --> 01:06:24.400]   So it might be that the neighbor list wasn't big
[01:06:24.400 --> 01:06:26.480]   enough, but it will always tell you if it wasn't big
[01:06:26.480 --> 01:06:26.980]   enough.
[01:06:26.980 --> 01:06:30.640]   And so if it were true, we might have needed to
[01:06:30.640 --> 01:06:31.680]   allocate a bit more space.
[01:06:31.680 --> 01:06:35.760]   And so now this is going to load the simulation.
[01:06:36.320 --> 01:06:38.400]   And this is going to take a second, because it needs to
[01:06:38.400 --> 01:06:40.400]   transfer all the data to my machine.
[01:06:40.400 --> 01:06:44.160]   So anyway, now would be a great question.
[01:06:44.160 --> 01:06:45.780]   OK.
[01:06:45.780 --> 01:06:50.320]   I think this is a good time now that you showed us the
[01:06:50.320 --> 01:06:52.080]   kind of modifications.
[01:06:52.080 --> 01:06:58.400]   To discuss the design of the API, I found it awesome that
[01:06:58.400 --> 01:07:04.000]   you separate the space from the energy and then from the
[01:07:04.000 --> 01:07:04.720]   dynamics.
[01:07:05.680 --> 01:07:07.840]   And I don't know.
[01:07:07.840 --> 01:07:13.440]   I think the majority of people are not familiar with
[01:07:13.440 --> 01:07:16.240]   simulation frameworks.
[01:07:16.240 --> 01:07:20.960]   Is this decoupling unique to JAX?
[01:07:20.960 --> 01:07:25.120]   I think it's pretty unique.
[01:07:25.120 --> 01:07:32.480]   I think if you look at most-- so I think-- oh, there we go.
[01:07:33.680 --> 01:07:36.640]   So anyway, this is the larger simulation.
[01:07:36.640 --> 01:07:46.320]   So most simulations, most MD libraries that I've seen--
[01:07:46.320 --> 01:07:51.520]   and this is maybe something that one of the goals, I think,
[01:07:51.520 --> 01:07:53.680]   of JAX MD is to maybe experiment.
[01:07:53.680 --> 01:07:57.680]   In the same way that JAX is experimental, I also thought
[01:07:57.680 --> 01:08:00.800]   it would be fun for JAX MD to be somewhat experimental.
[01:08:02.080 --> 01:08:06.560]   And one of the things that often molecular dynamic libraries
[01:08:06.560 --> 01:08:10.400]   do is they're quite monolithic in the sense that they have
[01:08:10.400 --> 01:08:11.920]   like a simulator class.
[01:08:11.920 --> 01:08:17.360]   And the simulator class stores data about the box, and it
[01:08:17.360 --> 01:08:20.240]   stores data about the particles and the energy, and it has
[01:08:20.240 --> 01:08:21.680]   everything kind of mixed together.
[01:08:21.680 --> 01:08:27.360]   And I wanted to see whether it was viable to get rid of a lot
[01:08:27.360 --> 01:08:28.080]   of that structure.
[01:08:29.200 --> 01:08:34.000]   So I think if you look in most MD packages, they will have
[01:08:34.000 --> 01:08:37.520]   energies, and they will have spaces, and they will have--
[01:08:37.520 --> 01:08:43.040]   they'll have the same pieces, but I think the coupling will
[01:08:43.040 --> 01:08:46.320]   be a lot stronger, I guess, in my experience.
[01:08:46.320 --> 01:08:50.640]   People might disagree with that take, but this is my impression.
[01:08:50.640 --> 01:08:54.480]   Interesting.
[01:08:55.120 --> 01:08:57.440]   Related to that, I don't know.
[01:08:57.440 --> 01:09:02.880]   I think most people in the--
[01:09:02.880 --> 01:09:07.840]   I don't know, maybe generalizing, but in the machine
[01:09:07.840 --> 01:09:12.960]   learning world, they're kind of not too familiar by the
[01:09:12.960 --> 01:09:16.400]   dynamic frameworks or that kind of stuff.
[01:09:16.400 --> 01:09:23.920]   I was very curious because this is a little bit rarer, but
[01:09:23.920 --> 01:09:24.880]   it's so nice.
[01:09:24.880 --> 01:09:28.480]   Can you tell us a bit about the field?
[01:09:28.480 --> 01:09:31.840]   And maybe people are interested in this kind of stuff.
[01:09:31.840 --> 01:09:33.920]   Like, what can they start doing?
[01:09:33.920 --> 01:09:36.000]   Or where do people hang out?
[01:09:36.000 --> 01:09:41.120]   I'm really curious to go and blow up different things and
[01:09:41.120 --> 01:09:42.400]   just run simulations.
[01:09:42.400 --> 01:09:44.560]   I want to spend weekends doing this now.
[01:09:44.560 --> 01:09:47.600]   Yeah, actually, so by the way, the notebook is online, and you
[01:09:47.600 --> 01:09:50.960]   can totally change the image to whatever you want.
[01:09:53.760 --> 01:09:58.640]   So that's a great question.
[01:09:58.640 --> 01:10:02.640]   Actually, maybe now that would be a good time to go back to my
[01:10:02.640 --> 01:10:03.140]   slides.
[01:10:03.140 --> 01:10:09.840]   And because the last thing is just maybe talking about where
[01:10:09.840 --> 01:10:12.320]   it's been used a little, which answers some of that question.
[01:10:12.320 --> 01:10:19.760]   And then I can answer some other parts after.
[01:10:20.720 --> 01:10:24.160]   So the idea, one of the things, like you said, there's a bit of
[01:10:24.160 --> 01:10:26.960]   a cultural difference between machine learning and physics.
[01:10:26.960 --> 01:10:35.600]   Physics is a more conservative, and I think rightly so, and
[01:10:35.600 --> 01:10:39.360]   maybe like slightly slower paced field than machine learning.
[01:10:39.360 --> 01:10:42.960]   We don't have like the three conferences a year every four
[01:10:42.960 --> 01:10:43.460]   months.
[01:10:43.460 --> 01:10:45.920]   It's more like a year time scale.
[01:10:45.920 --> 01:10:50.000]   But I think people have started using Jacksonian papers.
[01:10:50.960 --> 01:10:54.880]   Often these will be like combining machine learning and
[01:10:54.880 --> 01:10:55.680]   physics papers.
[01:10:55.680 --> 01:11:00.480]   So like we had a paper where we tried to apply like learned
[01:11:00.480 --> 01:11:07.760]   optimization to do optimization over atomic structures.
[01:11:07.760 --> 01:11:09.200]   There was a nice paper.
[01:11:09.200 --> 01:11:13.440]   There's been a lot of papers that have come out recently
[01:11:13.440 --> 01:11:19.520]   doing like machine learning to learn interactions.
[01:11:19.520 --> 01:11:22.800]   So like we had this energy function, and really what you
[01:11:22.800 --> 01:11:25.040]   would like is you would like nature's energy functions.
[01:11:25.040 --> 01:11:27.840]   So there's like an energy function that nature uses, and
[01:11:27.840 --> 01:11:30.720]   that's like given to us by nature.
[01:11:30.720 --> 01:11:33.920]   And it's in principle given by quantum mechanics.
[01:11:33.920 --> 01:11:39.920]   And quantum mechanics is really notoriously costly to simulate.
[01:11:39.920 --> 01:11:42.880]   And so one of the things that's been a very hot topic in
[01:11:42.880 --> 01:11:45.360]   machine learning, actually, and there are like many, many
[01:11:45.360 --> 01:11:52.000]   papers that have been published on this, is learning using
[01:11:52.000 --> 01:11:57.520]   neural networks as surrogates to the quantum mechanical
[01:11:57.520 --> 01:11:58.720]   energy functions.
[01:11:58.720 --> 01:12:01.920]   And so I think if I were like a machine learning person and I
[01:12:01.920 --> 01:12:04.400]   was sort of interested in getting my feet wet, I think
[01:12:04.400 --> 01:12:06.240]   that's maybe a nice place to start.
[01:12:06.240 --> 01:12:09.360]   So like people have done several different papers on this,
[01:12:09.360 --> 01:12:11.280]   some of them using Jackson MD.
[01:12:11.280 --> 01:12:13.920]   Like there's one learning neural network potentials from
[01:12:13.920 --> 01:12:16.320]   experimental data via trajectory, differentiable
[01:12:16.320 --> 01:12:17.600]   trajectory reweighting.
[01:12:17.600 --> 01:12:21.040]   There's this Lagrangian neural networks with differentiable
[01:12:21.040 --> 01:12:23.920]   symmetries and relational inductive biases.
[01:12:23.920 --> 01:12:26.560]   So I think that's one area.
[01:12:26.560 --> 01:12:30.800]   And I think there are loads of papers published on this in
[01:12:30.800 --> 01:12:33.840]   like all the major machine learning conferences.
[01:12:33.840 --> 01:12:42.560]   I do think that most physicists are nice if you're in a
[01:12:42.560 --> 01:12:45.520]   university and you go to the physics department, I think
[01:12:45.520 --> 01:12:49.840]   usually people will be pretty, especially if someone does
[01:12:49.840 --> 01:12:51.360]   molecular simulation stuff.
[01:12:51.360 --> 01:12:53.920]   I will say that the community is a little bit more diffuse
[01:12:53.920 --> 01:12:58.320]   and a little bit more academic just because of the nature of
[01:12:58.320 --> 01:13:01.840]   physics simulations, but also like definitely feel free if
[01:13:01.840 --> 01:13:06.880]   people are interested and you could reach out to me or Dosh
[01:13:06.880 --> 01:13:08.960]   and we can, we're always happy to chat.
[01:13:11.200 --> 01:13:16.640]   But yeah, I think machine learning for all, maybe people
[01:13:16.640 --> 01:13:18.720]   complain about, I think it actually has like a very nice
[01:13:18.720 --> 01:13:21.440]   community associated with it, especially online.
[01:13:21.440 --> 01:13:24.560]   And I think the physics community is very nice, but it's
[01:13:24.560 --> 01:13:27.200]   also more, it is more academic.
[01:13:27.200 --> 01:13:31.840]   Is this kind of tools used in like the industry?
[01:13:31.840 --> 01:13:39.440]   Well, I mean, probably yes, but like what, maybe Jackson MD
[01:13:39.440 --> 01:13:39.940]   or?
[01:13:40.400 --> 01:13:40.800]   Yeah.
[01:13:40.800 --> 01:13:45.680]   So one thing I think is that, physicists are much more
[01:13:45.680 --> 01:13:47.840]   conservative about picking up new tools.
[01:13:47.840 --> 01:13:51.440]   I don't know if Jackson D is being used in industry yet.
[01:13:51.440 --> 01:13:55.440]   I think there are sort of like two places where people, as
[01:13:55.440 --> 01:13:58.560]   far as I know, use molecular dynamics.
[01:13:58.560 --> 01:14:04.320]   So people do use it for like designing new materials and
[01:14:04.320 --> 01:14:10.800]   people use it for doing certain biochemistry simulations.
[01:14:10.800 --> 01:14:15.040]   So like, for example, if I have a protein and I want to know
[01:14:15.040 --> 01:14:19.760]   whether a drug will bind to the protein, that's often done
[01:14:19.760 --> 01:14:20.320]   with MD.
[01:14:20.320 --> 01:14:24.960]   But I think usually right now, at least companies will have
[01:14:24.960 --> 01:14:28.640]   their very specific, because one of the things about doing
[01:14:28.640 --> 01:14:32.480]   those simulations is you really want the simulations to be
[01:14:32.480 --> 01:14:35.840]   sort of as big as possible because the bigger the simulation
[01:14:35.840 --> 01:14:39.040]   or like the more, there's like different regimes of physics
[01:14:39.040 --> 01:14:39.600]   simulation.
[01:14:39.600 --> 01:14:42.640]   So like some physics simulations, you just want them to
[01:14:42.640 --> 01:14:44.800]   be as big or as long as possible.
[01:14:44.800 --> 01:14:49.760]   And I don't know if Jackson D is the best for that because
[01:14:49.760 --> 01:14:52.160]   Jackson D is, it's not like slow.
[01:14:52.160 --> 01:14:54.960]   Like, I think it's like, it's like, but it's, it's maybe,
[01:14:54.960 --> 01:14:58.960]   you know, it's slower than these really highly optimized
[01:14:58.960 --> 01:15:04.080]   libraries and maybe by like 30% or maybe, you know, maybe
[01:15:04.080 --> 01:15:04.560]   even 50%.
[01:15:04.560 --> 01:15:06.800]   Even on TPU?
[01:15:06.800 --> 01:15:09.520]   So actually, interesting question.
[01:15:09.520 --> 01:15:15.200]   TPU is a really challenging fit for molecular dynamics.
[01:15:15.200 --> 01:15:25.280]   We have not published yet, but we are working on an
[01:15:25.280 --> 01:15:28.480]   experimental library to do TPU MD simulations.
[01:15:29.360 --> 01:15:30.640]   But it is hard.
[01:15:30.640 --> 01:15:35.760]   And the reason why it's hard is the neighborhood finding.
[01:15:35.760 --> 01:15:40.800]   The actual calculation of like the energies for a small
[01:15:40.800 --> 01:15:45.440]   system are fine, but the gradient finding or the
[01:15:45.440 --> 01:15:52.000]   neighborhood finding is intractable on current TPU
[01:15:52.000 --> 01:15:52.720]   architectures.
[01:15:54.640 --> 01:15:59.760]   Basically because I think sorting numbers is slow.
[01:15:59.760 --> 01:16:06.880]   So I personally, so we have an example that actually does
[01:16:06.880 --> 01:16:09.600]   okay, but it's not quite ready yet.
[01:16:09.600 --> 01:16:12.640]   I think it could be the TPUs will be very good for this,
[01:16:12.640 --> 01:16:14.800]   but right now it's still, it's still challenging.
[01:16:14.800 --> 01:16:17.060]   Interesting.
[01:16:17.060 --> 01:16:23.840]   Also, no, no, no, just that, you know, these companies
[01:16:23.840 --> 01:16:27.440]   that are doing MD and like big academic groups use like
[01:16:27.440 --> 01:16:31.120]   large super computers with like a lot of like MPI between
[01:16:31.120 --> 01:16:31.760]   CPUs.
[01:16:31.760 --> 01:16:34.160]   And that's another thing that we don't have yet.
[01:16:34.160 --> 01:16:37.520]   We're basically focused right now on like single GPU or
[01:16:37.520 --> 01:16:39.840]   like multi TPU setups.
[01:16:39.840 --> 01:16:45.920]   I'm very curious about, well, now that you gave us like a
[01:16:45.920 --> 01:16:51.360]   lot of insights, if like projects that mix in like
[01:16:52.880 --> 01:16:56.800]   like molecular, maybe dynamics, I don't know, like
[01:16:56.800 --> 01:17:00.880]   alpha fold and machine learning, they would be like a
[01:17:00.880 --> 01:17:05.200]   really good fit for, for like Jackson D like.
[01:17:05.200 --> 01:17:06.000]   Yeah, totally.
[01:17:06.000 --> 01:17:09.680]   So one of, one of the goals maybe for this, like, you
[01:17:09.680 --> 01:17:12.240]   know, I have some high level things that we're, we're
[01:17:12.240 --> 01:17:13.360]   working towards this year.
[01:17:13.360 --> 01:17:18.560]   And one of them is to like try to get better integration,
[01:17:18.560 --> 01:17:22.400]   both with neural networks in general, but also with like
[01:17:22.400 --> 01:17:25.120]   alpha fold style models.
[01:17:25.120 --> 01:17:28.720]   So, so yeah, I think, I think it's, that's kind of was
[01:17:28.720 --> 01:17:29.220]   the dream.
[01:17:29.220 --> 01:17:33.760]   I don't know if it's quite realized yet, but I think, I
[01:17:33.760 --> 01:17:36.400]   think it is a, would be a really good combination.
[01:17:36.400 --> 01:17:41.040]   And I have a very similar question, but it's more like,
[01:17:41.040 --> 01:17:45.760]   I don't know, machine learning in general, but just by
[01:17:45.760 --> 01:17:50.400]   chance, I was kind of trying to update on these new
[01:17:50.400 --> 01:17:51.360]   diffusion models.
[01:17:51.680 --> 01:17:57.520]   And then I don't know, they, they use this, I don't know
[01:17:57.520 --> 01:18:04.160]   how to, to, to pronounce it, loving, loving dynamics.
[01:18:04.160 --> 01:18:04.660]   Yeah.
[01:18:04.660 --> 01:18:10.480]   So, so I got introduced to, to that kind of dynamics by
[01:18:10.480 --> 01:18:11.520]   reading diffusion models.
[01:18:11.520 --> 01:18:14.240]   And it's kind of interesting.
[01:18:14.240 --> 01:18:18.480]   I don't know if you check out the diffusion models
[01:18:18.480 --> 01:18:24.080]   literature, how it's, it's kind of maybe bridging a
[01:18:24.080 --> 01:18:30.800]   little bit between the energy, like function type of
[01:18:30.800 --> 01:18:33.600]   definition, which I think John Lacon is kind of been
[01:18:33.600 --> 01:18:34.960]   promoting for a while.
[01:18:34.960 --> 01:18:36.880]   What do you think about this from the physics side?
[01:18:36.880 --> 01:18:43.280]   Yeah, I, I actually, you know, this is why I never get
[01:18:43.280 --> 01:18:48.080]   to learn Julia because I, yeah, I think I really want to
[01:18:48.080 --> 01:18:50.640]   better under, I, you know, I've also read a bunch of
[01:18:50.640 --> 01:18:54.560]   the diffusion model papers and I think they seem great.
[01:18:54.560 --> 01:18:57.280]   I think, you know, people have tried to use generative
[01:18:57.280 --> 01:18:58.720]   models in physics before.
[01:18:58.720 --> 01:19:01.520]   I think Max Welling has some really nice papers where
[01:19:01.520 --> 01:19:03.840]   they are pretty successful.
[01:19:03.840 --> 01:19:06.160]   I don't think anyone, as far as I know, I don't think
[01:19:06.160 --> 01:19:09.120]   anyone has tried to use the scored based diffusion
[01:19:09.120 --> 01:19:13.280]   models to do generative modeling in atomistic
[01:19:13.280 --> 01:19:16.080]   subsystems, but I think it seems like a really
[01:19:16.080 --> 01:19:17.040]   outstanding fit.
[01:19:17.600 --> 01:19:24.480]   So yeah, I'm, I'm really pretty excited about that
[01:19:24.480 --> 01:19:25.040]   idea.
[01:19:25.040 --> 01:19:26.720]   What do you mean by animistic?
[01:19:26.720 --> 01:19:30.800]   Oh, like, like just like using it for these sort of
[01:19:30.800 --> 01:19:33.440]   systems of, of particles, particle-based.
[01:19:33.440 --> 01:19:33.940]   Oh, okay.
[01:19:33.940 --> 01:19:38.000]   And I will say one thing, you know, we, we're not there
[01:19:38.000 --> 01:19:45.520]   yet, but myself and a few folks from Harvard have been
[01:19:45.520 --> 01:19:51.280]   working on rewriting some of the, or reworking the
[01:19:51.280 --> 01:19:55.120]   Jax-MD simulations so that they'll work really easily
[01:19:55.120 --> 01:19:56.800]   with other kinds of things.
[01:19:56.800 --> 01:20:00.160]   So like, for example, you'll be able to use the
[01:20:00.160 --> 01:20:02.560]   Langevin dynamics with like a neural network, for
[01:20:02.560 --> 01:20:03.060]   example.
[01:20:03.060 --> 01:20:05.920]   So that, that's not there quite yet.
[01:20:05.920 --> 01:20:08.320]   But, but it, it will be.
[01:20:08.320 --> 01:20:11.200]   That would be amazing.
[01:20:11.200 --> 01:20:14.320]   I actually was working on porting some tutorials.
[01:20:14.880 --> 01:20:15.440]   Yeah.
[01:20:15.440 --> 01:20:19.200]   Of diffusion models from, from PyTorch to Jax.
[01:20:19.200 --> 01:20:23.760]   And then while you, I mean, the implementation of the
[01:20:23.760 --> 01:20:26.160]   dynamics are really simple, like adding a little bit of
[01:20:26.160 --> 01:20:29.760]   noise and, and moving in the direction of the gradient.
[01:20:29.760 --> 01:20:34.960]   But it would be very nice to see if, hey, well, I mean,
[01:20:34.960 --> 01:20:37.040]   you could just use that from another package.
[01:20:37.040 --> 01:20:38.080]   Yeah.
[01:20:38.080 --> 01:20:39.200]   You'll be able to just plug it in.
[01:20:39.200 --> 01:20:39.840]   I don't know.
[01:20:39.840 --> 01:20:43.680]   Like, I also know I was talking with someone who used
[01:20:43.680 --> 01:20:47.280]   actually NVT, like some of the, the Nozze-Hoover dynamics
[01:20:47.280 --> 01:20:51.280]   to do good optimization of a neural network.
[01:20:51.280 --> 01:20:55.120]   Like just like in the classical supervised setting.
[01:20:55.120 --> 01:20:58.400]   I don't remember exactly what they did, but it
[01:20:58.400 --> 01:20:59.600]   sounded quite interesting.
[01:20:59.600 --> 01:21:02.400]   So that's like one use case we'd like to support.
[01:21:02.400 --> 01:21:05.120]   Yeah.
[01:21:05.120 --> 01:21:05.360]   Yeah.
[01:21:05.360 --> 01:21:09.520]   The diffusion dynamics is very, very interesting.
[01:21:10.720 --> 01:21:13.680]   I hope, I don't know, maybe it bridges a little bit to the
[01:21:13.680 --> 01:21:18.160]   physics side of some things and, and then we can get like a,
[01:21:18.160 --> 01:21:21.520]   I don't know, like a broader community.
[01:21:21.520 --> 01:21:25.040]   Because the things you showed us, they're not like the day
[01:21:25.040 --> 01:21:26.320]   to day, but they're really nice.
[01:21:26.320 --> 01:21:28.240]   Yeah, no, exactly.
[01:21:28.240 --> 01:21:28.800]   Exactly.
[01:21:28.800 --> 01:21:30.960]   That's, that's, you know, and I think, I think it's one of
[01:21:30.960 --> 01:21:36.000]   those things where like, hopefully by having common tools,
[01:21:36.000 --> 01:21:40.080]   people can like dabble without having to like, you know,
[01:21:40.080 --> 01:21:44.240]   and just like lower the friction to like do some more
[01:21:44.240 --> 01:21:46.240]   interdisciplinary work.
[01:21:46.240 --> 01:21:48.240]   Yeah.
[01:21:48.240 --> 01:21:48.740]   Yeah.
[01:21:48.740 --> 01:21:52.720]   I wonder if you can eventually get it to sample images with
[01:21:52.720 --> 01:21:53.680]   Jackson D.
[01:21:53.680 --> 01:21:54.880]   That would be pretty cool.
[01:21:54.880 --> 01:21:59.600]   I, I think, you know, I don't think it's impossible.
[01:21:59.600 --> 01:22:00.160]   How about that?
[01:22:00.160 --> 01:22:02.800]   I don't think it's impossible.
[01:22:02.800 --> 01:22:05.040]   I don't know how I would do it, but I don't think it's
[01:22:05.040 --> 01:22:05.600]   impossible.
[01:22:05.600 --> 01:22:09.120]   I think once we have this change in where you can just use,
[01:22:09.760 --> 01:22:15.600]   basically the, the input to the simulations will be able to
[01:22:15.600 --> 01:22:16.800]   be like any PyTree.
[01:22:16.800 --> 01:22:24.000]   And so once you have that, I think you should be able to
[01:22:24.000 --> 01:22:25.520]   use them for a lot of different stuff.
[01:22:25.520 --> 01:22:30.000]   That was, I think I had it in the back of my mind.
[01:22:30.000 --> 01:22:33.360]   You pass a data class and I assume you implement it as a,
[01:22:33.360 --> 01:22:34.160]   as a PyTree.
[01:22:34.160 --> 01:22:35.520]   Yeah, exactly.
[01:22:35.520 --> 01:22:40.800]   We, we actually just like stole Flax's like data, you know,
[01:22:40.800 --> 01:22:43.680]   Flax has the struct.data class.
[01:22:43.680 --> 01:22:48.400]   So yeah, we don't do, we adapted a little, like we don't
[01:22:48.400 --> 01:22:50.640]   do the serialization part.
[01:22:50.640 --> 01:22:55.680]   We should, I, maybe we should just depend on Flax.
[01:22:55.680 --> 01:22:58.480]   When we were writing it initially, Flax was still
[01:22:58.480 --> 01:23:02.560]   pretty actively changing their structure.
[01:23:02.560 --> 01:23:04.800]   So I wanted to split it, but yeah.
[01:23:05.520 --> 01:23:08.720]   It's, it's, it's more or less the Flax version with a few
[01:23:08.720 --> 01:23:11.040]   other things and without the serialization.
[01:23:11.040 --> 01:23:14.800]   So you are going to support like any, any PyTree?
[01:23:14.800 --> 01:23:15.920]   Any PyTree, yeah.
[01:23:15.920 --> 01:23:17.200]   Is that amazing?
[01:23:17.200 --> 01:23:20.080]   So you'll be able to pass, like maybe I can just, I don't
[01:23:20.080 --> 01:23:25.680]   know, did my screen go away or can you still see?
[01:23:25.680 --> 01:23:28.240]   It got black.
[01:23:28.240 --> 01:23:28.560]   Okay.
[01:23:28.560 --> 01:23:30.160]   Let me quickly re-share.
[01:23:30.160 --> 01:23:34.000]   Share one more time.
[01:23:34.560 --> 01:23:37.120]   Meanwhile, there's a comment by Akash.
[01:23:37.120 --> 01:23:40.000]   He says of all the things he's read in machine learning,
[01:23:40.000 --> 01:23:42.080]   diffusion models still give him a hard time.
[01:23:42.080 --> 01:23:46.400]   Yeah, I think I, I, I might agree.
[01:23:46.400 --> 01:23:48.960]   And, but Akash has, I think, read a lot more than me at
[01:23:48.960 --> 01:23:52.640]   this point about stuff in machine learning.
[01:23:52.640 --> 01:23:54.560]   So yeah.
[01:23:54.560 --> 01:23:58.800]   Very mathy for, well, in, in, in machine learning, we kind
[01:23:58.800 --> 01:24:03.360]   of, I don't know, the thing is, oh, show us the architecture
[01:24:03.360 --> 01:24:06.560]   and that's kind of, but for diffusion models, there was a
[01:24:06.560 --> 01:24:07.120]   lot of math.
[01:24:07.120 --> 01:24:08.320]   Yep.
[01:24:08.320 --> 01:24:09.200]   Yeah.
[01:24:09.200 --> 01:24:13.120]   So, so here is like the, when we initialize the state, we
[01:24:13.120 --> 01:24:15.840]   initialize with the positions, but you'll be able to pass
[01:24:15.840 --> 01:24:20.640]   eventually any PyTree for this initial positions.
[01:24:20.640 --> 01:24:26.080]   And then you'll get the, the state dot positions will
[01:24:26.080 --> 01:24:27.840]   always be a, a PyTree.
[01:24:27.840 --> 01:24:33.280]   Is this implemented or it's kind of the, the future?
[01:24:33.280 --> 01:24:34.720]   It's, it's implemented.
[01:24:34.720 --> 01:24:38.880]   It is implemented, but it is not checked in.
[01:24:38.880 --> 01:24:44.160]   So, so and there's, it's a pretty big change.
[01:24:44.160 --> 01:24:49.280]   So I don't have an ETA, I think like, you know, but it's
[01:24:49.280 --> 01:24:49.760]   getting there.
[01:24:49.760 --> 01:24:52.800]   It's, it's, it's getting to the point where it's maybe
[01:24:52.800 --> 01:24:54.400]   going to be amazing.
[01:24:54.400 --> 01:24:57.440]   Well, I mean, I'm super invested in the PyTree side of
[01:24:57.440 --> 01:24:57.760]   things.
[01:24:57.760 --> 01:24:58.640]   I know, I know.
[01:24:58.640 --> 01:25:02.160]   I really liked watching your, your neural network
[01:25:02.160 --> 01:25:02.960]   explorations.
[01:25:02.960 --> 01:25:04.800]   I have to say, I think it's super cool.
[01:25:04.800 --> 01:25:07.280]   It makes a lot of sense to me.
[01:25:07.280 --> 01:25:11.760]   So yeah, I'd be eager to try when you have it out.
[01:25:11.760 --> 01:25:18.720]   And I don't know, Samyan, you have questions for?
[01:25:18.720 --> 01:25:21.600]   I do not.
[01:25:21.600 --> 01:25:24.560]   I was just trying to digest all of this information and I
[01:25:24.560 --> 01:25:25.440]   really enjoyed it.
[01:25:25.440 --> 01:25:30.640]   So, and I don't see any community questions as well.
[01:25:30.640 --> 01:25:32.880]   So Christian, if you have any questions, please continue.
[01:25:32.880 --> 01:25:36.400]   No, Sam, I enjoyed this a lot.
[01:25:36.400 --> 01:25:40.480]   I think one of the things I actually, I like the most about
[01:25:40.480 --> 01:25:43.920]   JAX is how it actually spins out of the machine learning
[01:25:43.920 --> 01:25:44.240]   world.
[01:25:44.240 --> 01:25:46.320]   Yeah, I agree.
[01:25:46.320 --> 01:25:49.360]   And they have like a lot of stuff, right?
[01:25:49.360 --> 01:25:53.840]   Like they have, there's like a fluid dynamics library now.
[01:25:53.840 --> 01:25:58.560]   There, there's the, I think a lot of the, like another area
[01:25:58.560 --> 01:26:00.800]   that I'm super interested in reading about more is the,
[01:26:00.800 --> 01:26:07.200]   the like nerf, like the rendering stuff, which I think
[01:26:07.200 --> 01:26:08.960]   is a lot in JAX at the moment.
[01:26:08.960 --> 01:26:17.040]   Yeah, we, we might have the, one of the authors of BRAX.
[01:26:17.040 --> 01:26:18.320]   Oh, cool.
[01:26:18.320 --> 01:26:18.720]   Yeah.
[01:26:18.720 --> 01:26:18.960]   Yep.
[01:26:18.960 --> 01:26:19.200]   Yep.
[01:26:19.200 --> 01:26:19.680]   Yep.
[01:26:19.680 --> 01:26:20.720]   BRAX is super cool.
[01:26:20.720 --> 01:26:25.200]   They do more like, they're very similar, but they, I mean,
[01:26:25.200 --> 01:26:26.800]   they do a lot more robotics.
[01:26:27.280 --> 01:26:31.520]   They are awesome as well.
[01:26:31.520 --> 01:26:33.600]   Awesome.
[01:26:33.600 --> 01:26:38.000]   I'll, I'll try to wrap up, wrap up since we're almost out of
[01:26:38.000 --> 01:26:38.240]   time.
[01:26:38.240 --> 01:26:41.120]   You can find Sam on Twitter.
[01:26:41.120 --> 01:26:44.320]   I've highlighted his Twitter on the YouTube page.
[01:26:44.320 --> 01:26:45.840]   I'm assuming it's visible to everyone.
[01:26:45.840 --> 01:26:49.040]   You can find JAX MD on GitHub.
[01:26:49.040 --> 01:26:51.520]   Even if you just Google JAX MD, that's the first link that
[01:26:51.520 --> 01:26:53.920]   shows up from where you can find the documentation, the
[01:26:53.920 --> 01:26:55.120]   examples, the paper.
[01:26:55.680 --> 01:26:56.640]   I tried to read it.
[01:26:56.640 --> 01:26:59.040]   If I was able to understand it, I'm sure everyone can.
[01:26:59.040 --> 01:27:00.720]   So it's, it's quite well documented.
[01:27:00.720 --> 01:27:02.880]   I would encourage everyone to check it out.
[01:27:02.880 --> 01:27:05.440]   Also, please check out Christian's work.
[01:27:05.440 --> 01:27:08.560]   He's the real host of the series, as I mentioned, and he's
[01:27:08.560 --> 01:27:10.800]   been doing amazing work in the JAX world as well.
[01:27:10.800 --> 01:27:15.840]   With that, I'd again, like to thank Sam for such an awesome
[01:27:15.840 --> 01:27:17.680]   walkthrough and such an awesome presentation.
[01:27:17.680 --> 01:27:18.480]   Thank you for your time.
[01:27:18.480 --> 01:27:22.160]   And thanks Christian for helping, helping make this
[01:27:22.160 --> 01:27:22.480]   happen.
[01:27:22.480 --> 01:27:24.480]   Yeah.
[01:27:24.480 --> 01:27:25.440]   Thanks so much for having me.
[01:27:25.440 --> 01:27:26.080]   This has been great.
[01:27:26.080 --> 01:27:27.120]   Yeah.
[01:27:27.120 --> 01:27:27.920]   Thanks a lot, Sam.
[01:27:27.920 --> 01:27:29.120]   It was a pleasure.
[01:27:29.120 --> 01:27:30.480]   Yeah, really, really fun.
[01:27:30.480 --> 01:27:31.200]   Really, really fun.
[01:27:31.200 --> 01:27:33.440]   Awesome.
[01:27:33.440 --> 01:27:34.560]   I'll end the broadcast.
[01:27:34.560 --> 01:27:36.960]   Thanks everyone for joining and we'll announce any future
[01:27:36.960 --> 01:27:37.600]   JAX meetups.
[01:27:37.600 --> 01:27:39.040]   We'll continue our other meetups.
[01:27:39.040 --> 01:27:42.560]   If you're curious to learn Keras, PyTorch, read papers,
[01:27:42.560 --> 01:27:44.080]   there's a lot going on.
[01:27:44.080 --> 01:27:47.200]   Please consider joining those.
[01:27:47.200 --> 01:27:51.200]   Bye.

