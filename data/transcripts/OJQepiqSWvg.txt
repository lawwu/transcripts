
[00:00:00.000 --> 00:00:04.960]   The following is a conversation with Paul Krugman, Nobel Prize winner in economics,
[00:00:04.960 --> 00:00:08.840]   professor at CUNY, and columnist at the New York Times.
[00:00:08.840 --> 00:00:14.720]   His academic work centers around international economics, economic geography, liquidity traps,
[00:00:14.720 --> 00:00:16.000]   and currency crises.
[00:00:16.000 --> 00:00:22.440]   But he also is an outspoken writer and commentator on the intersection of modern day politics
[00:00:22.440 --> 00:00:28.840]   and economics, which places him in the middle of the tense, divisive modern day political
[00:00:28.840 --> 00:00:30.280]   discourse.
[00:00:30.280 --> 00:00:34.280]   If you have clicked dislike on this video and started writing a comment of derision
[00:00:34.280 --> 00:00:39.280]   before listening to the conversation, I humbly ask that you please unsubscribe from this
[00:00:39.280 --> 00:00:44.640]   channel and from this podcast, not because you're conservative, a libertarian, a liberal,
[00:00:44.640 --> 00:00:50.320]   a socialist, an anarchist, but because you're not open to new ideas, at least in this case,
[00:00:50.320 --> 00:00:56.200]   especially at its most difficult, from people with whom you largely disagree.
[00:00:56.200 --> 00:01:01.320]   I do my best to stay away from politics of the day, because political discourse is filled
[00:01:01.320 --> 00:01:07.680]   with a degree of emotion and self-assured certainty that to me is not conducive to exploring
[00:01:07.680 --> 00:01:12.840]   questions that nobody knows the definitive right answer to.
[00:01:12.840 --> 00:01:18.360]   The role of government, the impact of automation, the regulation of tech, the medical system,
[00:01:18.360 --> 00:01:25.420]   guns, war, trade, foreign policy, are not easy topics and have no clear answers, despite
[00:01:25.420 --> 00:01:31.520]   the certainty of the so-called experts, the pundits, the trolls, the media personalities
[00:01:31.520 --> 00:01:34.200]   and the conspiracy theorists.
[00:01:34.200 --> 00:01:40.560]   Please listen, empathize, and allow yourself to explore ideas with curiosity and without
[00:01:40.560 --> 00:01:43.840]   judgment and without derision.
[00:01:43.840 --> 00:01:48.000]   I will speak with many more economists and political thinkers, trying to stay away from
[00:01:48.000 --> 00:01:53.360]   the political battles of the day and instead look at the long arc of history and the lessons
[00:01:53.360 --> 00:01:54.360]   it reveals.
[00:01:54.360 --> 00:01:59.760]   In this, I appreciate your patience and support.
[00:01:59.760 --> 00:02:02.840]   This is the Artificial Intelligence Podcast.
[00:02:02.840 --> 00:02:08.880]   If you enjoy it, subscribe on YouTube, give it 5 stars on Apple Podcasts, follow on Spotify,
[00:02:08.880 --> 00:02:16.040]   support on Patreon, or simply connect with me on Twitter at Lex Friedman, spelled F-R-I-D-M-A-N.
[00:02:16.040 --> 00:02:18.920]   I recently started doing ads at the end of the introduction.
[00:02:18.920 --> 00:02:23.440]   I'll do one or two minutes after introducing the episode and never any ads in the middle
[00:02:23.440 --> 00:02:25.520]   that can break the flow of the conversation.
[00:02:25.520 --> 00:02:30.640]   I hope that works for you and doesn't hurt the listening experience.
[00:02:30.640 --> 00:02:35.400]   This show is presented by Cash App, the number one finance app in the App Store.
[00:02:35.400 --> 00:02:40.120]   Cash App lets you send money to friends, buy Bitcoin, and invest in the stock market with
[00:02:40.120 --> 00:02:45.040]   fractional share trading, allowing you to buy $1 worth of a stock no matter what the
[00:02:45.040 --> 00:02:46.800]   stock price is.
[00:02:46.800 --> 00:02:51.600]   Brokerage services are provided by Cash App Investing, a subsidiary of Square and member
[00:02:51.600 --> 00:02:53.220]   SIPC.
[00:02:53.220 --> 00:02:58.720]   Get Cash App from the App Store and Google Play and use the code LEXPODCAST.
[00:02:58.720 --> 00:03:04.520]   You'll get $10 and Cash App will also donate $10 to FIRST, one of my favorite organizations
[00:03:04.520 --> 00:03:10.520]   that is helping to advance robotics and STEM education for young people around the world.
[00:03:10.520 --> 00:03:15.720]   Since Cash App does fractional share trading, let me say that to me, it's a fascinating
[00:03:15.720 --> 00:03:16.980]   concept.
[00:03:16.980 --> 00:03:21.920]   The order execution algorithm that works behind the scenes to create the abstraction of fractional
[00:03:21.920 --> 00:03:25.920]   orders for the investor is an algorithmic marvel.
[00:03:25.920 --> 00:03:28.600]   So big props to the Cash App engineers for that.
[00:03:28.600 --> 00:03:33.880]   I like it when tech teams solve complicated problems to provide, in the end, a simple,
[00:03:33.880 --> 00:03:39.240]   effortless interface that abstracts away all the details of the underlying algorithm.
[00:03:39.240 --> 00:03:44.240]   And now, here's my conversation with Paul Krugman.
[00:03:44.240 --> 00:03:49.160]   What does a perfect world, a utopia from an economics perspective look like?
[00:03:49.160 --> 00:03:53.960]   Wow, I don't really, I don't believe in perfection.
[00:03:53.960 --> 00:04:00.520]   I mean, somebody once said that his ideal was slightly imaginary Sweden.
[00:04:00.520 --> 00:04:10.080]   I mean, I like an economy that has a really high safety net for people, good environmental
[00:04:10.080 --> 00:04:16.800]   regulation and, you know, something that's not, that's kind of like some of the better
[00:04:16.800 --> 00:04:22.720]   run countries in the world, but with fixing all of the smaller things that are wrong with
[00:04:22.720 --> 00:04:23.720]   them.
[00:04:23.720 --> 00:04:24.720]   What about wealth distribution?
[00:04:24.720 --> 00:04:31.000]   Well, obviously, you know, total equality is neither possible nor, I think, especially
[00:04:31.000 --> 00:04:32.000]   desirable.
[00:04:32.000 --> 00:04:38.520]   But I think you want one where, basically one where nobody is hurting and where everybody
[00:04:38.520 --> 00:04:41.560]   lives in the same material universe.
[00:04:41.560 --> 00:04:45.320]   Everybody is basically living in the same society.
[00:04:45.320 --> 00:04:48.920]   So I think it's a bad thing to have people who are so wealthy that they're really not
[00:04:48.920 --> 00:04:51.280]   in the same world as the rest of us.
[00:04:51.280 --> 00:04:52.280]   What about competition?
[00:04:52.280 --> 00:04:55.960]   Do you see the value of competition?
[00:04:55.960 --> 00:04:57.360]   What may be its limits?
[00:04:57.360 --> 00:04:59.720]   Oh, competition is great when it can work.
[00:04:59.720 --> 00:05:04.720]   I mean, there's, you know, I remember, I'm old enough to remember when there was only
[00:05:04.720 --> 00:05:09.240]   one phone company and there was really limited choice.
[00:05:09.240 --> 00:05:16.680]   And I think the arrival of multiple phone carriers and all that has actually, you know,
[00:05:16.680 --> 00:05:18.200]   it's been a really good thing.
[00:05:18.200 --> 00:05:21.040]   And that's true across many areas.
[00:05:21.040 --> 00:05:26.760]   But not every industry is, not every activity is suitable for competition.
[00:05:26.760 --> 00:05:31.520]   So there are some things like healthcare where competition actually doesn't work.
[00:05:31.520 --> 00:05:36.040]   And so it's not one size fits all.
[00:05:36.040 --> 00:05:37.040]   That's interesting.
[00:05:37.040 --> 00:05:40.440]   Why does competition not work in healthcare?
[00:05:40.440 --> 00:05:42.760]   Oh, there's a long list.
[00:05:42.760 --> 00:05:47.760]   I mean, there's a famous paper by Kenneth Arrow from 1963, which still holds up very
[00:05:47.760 --> 00:05:51.280]   well, where he kind of runs down the list of things you need for competition to work
[00:05:51.280 --> 00:05:52.520]   well.
[00:05:52.520 --> 00:05:58.320]   Basically both sides to every transaction being well-informed, having the ability to
[00:05:58.320 --> 00:06:03.240]   make intelligent decisions, understanding what's going on.
[00:06:03.240 --> 00:06:05.440]   And healthcare fails on every dimension.
[00:06:05.440 --> 00:06:08.720]   Healthcare, so not health insurance, healthcare.
[00:06:08.720 --> 00:06:12.120]   Well both healthcare and health insurance, health insurance being part of it.
[00:06:12.120 --> 00:06:18.080]   But no, health insurance is really, the idea that there's effective competition between
[00:06:18.080 --> 00:06:19.680]   health insurers is wrong.
[00:06:19.680 --> 00:06:25.520]   Healthcare, I mean, the idea that you can comparison shop for major surgery is just,
[00:06:25.520 --> 00:06:32.040]   you know, when people say things like that, you wonder, are you living in the same world
[00:06:32.040 --> 00:06:33.720]   I'm living in?
[00:06:33.720 --> 00:06:38.440]   You know, that piece of well-informed, that was always an interesting piece for me, just
[00:06:38.440 --> 00:06:40.840]   observing as an outsider.
[00:06:40.840 --> 00:06:47.840]   Because so much beautiful, such a beautiful world is possible when everybody's well-informed.
[00:06:47.840 --> 00:06:51.760]   My question for you is, how hard is it to be well-informed about anything, whether it's
[00:06:51.760 --> 00:06:57.600]   healthcare or any kind of purchasing decisions, or just life in general in this world?
[00:06:57.600 --> 00:07:00.360]   Oh, information, you know, it varies hugely.
[00:07:00.360 --> 00:07:07.120]   I mean, there's more information at your fingertips than ever before in history.
[00:07:07.120 --> 00:07:13.360]   The trouble is, first of all, that some of that information isn't true, so it's really
[00:07:13.360 --> 00:07:14.920]   hard.
[00:07:14.920 --> 00:07:18.240]   And then some of it is just too hard to understand.
[00:07:18.240 --> 00:07:25.200]   So if I'm buying a car, I can actually probably do a pretty good job of looking up, you know,
[00:07:25.200 --> 00:07:29.080]   going to consumer reports, reviews, you can get a pretty good idea of what you're getting
[00:07:29.080 --> 00:07:30.880]   when you get a car.
[00:07:30.880 --> 00:07:39.560]   If I'm going in for surgery, first of all, you know, fairly often it happens without
[00:07:39.560 --> 00:07:46.480]   your being able to plan it, but also, you know, medical school takes many, many years,
[00:07:46.480 --> 00:07:52.640]   and going on the internet for some advice is not usually a very good substitute.
[00:07:52.640 --> 00:07:57.720]   So speaking about news and not being able to trust certain sources of information, how
[00:07:57.720 --> 00:08:02.720]   much disagreement is there about, I mentioned utopia, perfection in the beginning, but how
[00:08:02.720 --> 00:08:08.720]   much disagreement is there about what utopia looks like, or is most of the disagreement
[00:08:08.720 --> 00:08:11.360]   simply about the path to get there?
[00:08:11.360 --> 00:08:16.880]   Oh, I think there's two levels of disagreement.
[00:08:16.880 --> 00:08:20.640]   One, maybe not utopia, but justice.
[00:08:20.640 --> 00:08:22.040]   What is a just society?
[00:08:22.040 --> 00:08:24.280]   And that's, there are different views.
[00:08:24.280 --> 00:08:30.280]   I mean, I teach my students that there are, you know, broadly speaking, two views of justice.
[00:08:30.280 --> 00:08:36.880]   One focuses on outcomes.
[00:08:36.880 --> 00:08:43.800]   A just society is the one you would choose if you were trying to, the one that you would
[00:08:43.800 --> 00:08:48.560]   choose to live in if you didn't know who you were going to be, that's kind of John Rawls.
[00:08:48.560 --> 00:08:55.600]   And the other focuses on process, that a just society is one in which there is no coercion
[00:08:55.600 --> 00:09:01.520]   except where absolutely necessary, and there's no objective way to choose between those.
[00:09:01.520 --> 00:09:04.920]   I'm pretty much a Rawlsian, and I think many people are.
[00:09:04.920 --> 00:09:12.200]   But anyway, so there's a legitimate dispute about what we mean by a just society anyway.
[00:09:12.200 --> 00:09:18.400]   But then there's also a lot of dispute about what actually works.
[00:09:18.400 --> 00:09:20.960]   There's a range of legitimate dispute.
[00:09:20.960 --> 00:09:27.560]   I mean, any card-carrying economist will say that incentives matter, but how much do they
[00:09:27.560 --> 00:09:28.560]   matter?
[00:09:28.560 --> 00:09:32.000]   How much does a higher tax rate actually deter people from working?
[00:09:32.000 --> 00:09:40.040]   How much does a stronger safety net actually lead people to get lazy?
[00:09:40.040 --> 00:09:47.080]   I have a pretty strong view that the evidence points to conclusions that are considerably
[00:09:47.080 --> 00:09:53.720]   to the left of where most of our politicians are, but that there is legitimate room for
[00:09:53.720 --> 00:09:56.840]   disagreement on those things.
[00:09:56.840 --> 00:10:00.480]   So you've mentioned outcomes.
[00:10:00.480 --> 00:10:04.440]   What are some metrics you think about that you keep in mind, like the Gini coefficient,
[00:10:04.440 --> 00:10:10.920]   but really anything that measures how good we're doing, whatever we're trying to do,
[00:10:10.920 --> 00:10:12.880]   what are the metrics you keep an eye on?
[00:10:12.880 --> 00:10:17.400]   Well, I'm actually not a fan of the Gini coefficient, not because it's anything-
[00:10:17.400 --> 00:10:18.400]   What is the Gini coefficient?
[00:10:18.400 --> 00:10:23.880]   Okay, yeah, the Gini coefficient is a measure of inequality, and it is commonly used because
[00:10:23.880 --> 00:10:25.800]   it's a single number.
[00:10:25.800 --> 00:10:32.600]   It usually tracks with other measures, but the trouble is there's no sort of natural
[00:10:32.600 --> 00:10:34.280]   interpretation of it.
[00:10:34.280 --> 00:10:42.440]   If you ask me what does a society with a Gini of .45 look like as opposed to a society with
[00:10:42.440 --> 00:10:53.320]   a Gini of .25, and I can kind of tell you, .25 is Denmark and .45 is Brazil, but there's
[00:10:53.320 --> 00:10:56.960]   no sort of easy way to do that mapping.
[00:10:56.960 --> 00:11:04.880]   I mean, I look at things like what is, first of all, things like what is the income of
[00:11:04.880 --> 00:11:12.080]   the median family, what is the income of the top 1%, how many people are in poverty by
[00:11:12.080 --> 00:11:15.320]   various measures of poverty?
[00:11:15.320 --> 00:11:28.200]   And then I think you want to look at questions like how healthy are people, how is life expectancy
[00:11:28.200 --> 00:11:30.560]   doing and how satisfied are people with their lives?
[00:11:30.560 --> 00:11:35.280]   Because there is, that sounds like a squishy number, not so much happiness.
[00:11:35.280 --> 00:11:40.360]   It turns out that life satisfaction is a better measure than happiness, but life satisfaction,
[00:11:40.360 --> 00:11:43.480]   that varies quite a lot.
[00:11:43.480 --> 00:11:53.080]   I think it's meaningful, if not too rigorous, to say, "Look, according to polling, people
[00:11:53.080 --> 00:11:58.040]   in Denmark are pretty satisfied with their lives and people in the United States, not
[00:11:58.040 --> 00:11:59.040]   so much so."
[00:11:59.040 --> 00:12:01.760]   >>Bellamy And of course, Sweden wins every time.
[00:12:01.760 --> 00:12:04.640]   >>Yeah, no, actually Denmark wins these days.
[00:12:04.640 --> 00:12:06.320]   Denmark and Norway tend to win these days.
[00:12:06.320 --> 00:12:12.880]   Sweden doesn't do badly, but none of these are perfect.
[00:12:12.880 --> 00:12:20.080]   But look, I think by and large, there's a bit of a pornography test.
[00:12:20.080 --> 00:12:21.480]   How do you know a decent society?
[00:12:21.480 --> 00:12:23.560]   Well, you kind of know it when you see it.
[00:12:23.560 --> 00:12:26.280]   >>Corey Where does America stand on that?
[00:12:26.280 --> 00:12:34.360]   >>Bellamy We are, our society, there are a lot of virtues to America, but there's a level
[00:12:34.360 --> 00:12:42.880]   of harshness, brutality, an ability for somebody who just has bad luck to fall off the edge
[00:12:42.880 --> 00:12:49.520]   that is really, shouldn't be happening in a country as rich as ours.
[00:12:49.520 --> 00:12:58.760]   So we have somehow managed to produce a crueler society than almost any other wealthy country
[00:12:58.760 --> 00:12:59.760]   for no good reason.
[00:12:59.760 --> 00:13:03.880]   >>Corey What do you think is lacking in the safety net that the United States provides?
[00:13:03.880 --> 00:13:06.560]   You said there's a harshness to it.
[00:13:06.560 --> 00:13:13.520]   And what are the benefits and maybe limits of a safety net in a country like ours?
[00:13:13.520 --> 00:13:18.160]   >>Bellamy Well, every other advanced country has some universal guarantee of adequate health
[00:13:18.160 --> 00:13:19.160]   care.
[00:13:19.160 --> 00:13:25.960]   The United States is the only place where citizens can actually fail to get basic health
[00:13:25.960 --> 00:13:28.280]   care because they can't afford it.
[00:13:28.280 --> 00:13:33.240]   It's not hard to do, everybody else does it, but we don't.
[00:13:33.240 --> 00:13:37.680]   We've gotten a little bit better at it than we were, but still, that's a big deal.
[00:13:37.680 --> 00:13:46.000]   We have remarkably weak support for children.
[00:13:46.000 --> 00:13:52.320]   Most countries have substantial safety, you know, parents of young children get much more
[00:13:52.320 --> 00:13:53.360]   support elsewhere.
[00:13:53.360 --> 00:13:57.620]   They get often nothing in the US.
[00:13:57.620 --> 00:14:07.040]   We have limited care for people, long-term care for the elderly is a very hit and miss
[00:14:07.040 --> 00:14:08.040]   thing.
[00:14:08.040 --> 00:14:15.800]   But I think that the really big issues are that we don't take care of children who make
[00:14:15.800 --> 00:14:20.080]   the mistake of having the wrong parents, and we don't take care of people who make the
[00:14:20.080 --> 00:14:21.520]   mistake of getting sick.
[00:14:21.520 --> 00:14:25.560]   And those are things that a rich country should be doing.
[00:14:25.560 --> 00:14:31.800]   Sorry for sort of a difficult question, but what you just said kind of feels like the
[00:14:31.800 --> 00:14:38.920]   right thing to do in terms of a just society, but is it also good for the economic health
[00:14:38.920 --> 00:14:46.360]   of a society to take care of the people who are the unfortunate members of society?
[00:14:46.360 --> 00:14:53.040]   By and large, it looks like doing the right thing in terms of justice is also the right
[00:14:53.040 --> 00:14:55.320]   thing in terms of economics.
[00:14:55.320 --> 00:15:01.800]   If we're talking about a society that has extremely high tax rates that deter, you know,
[00:15:01.800 --> 00:15:09.120]   remove all incentives to provide a safety net that is so generous that why bother working
[00:15:09.120 --> 00:15:10.960]   or striving?
[00:15:10.960 --> 00:15:11.960]   That could be a problem.
[00:15:11.960 --> 00:15:15.480]   But I don't actually know any society that looks like that.
[00:15:15.480 --> 00:15:22.120]   Even in European countries with very generous safety nets, people work and innovate and
[00:15:22.120 --> 00:15:23.720]   do all of these things.
[00:15:23.720 --> 00:15:30.880]   And there's a lot of evidence now that lacking those basics is actually destructive, that
[00:15:30.880 --> 00:15:37.200]   children who grow up without adequate health care, without adequate nutrition, are developmentally
[00:15:37.200 --> 00:15:38.200]   challenged.
[00:15:38.200 --> 00:15:41.000]   They don't live up to their potential as adults.
[00:15:41.000 --> 00:15:45.640]   So the United States actually probably pays a price.
[00:15:45.640 --> 00:15:50.920]   We're harsh, we're cruel, and we actually make ourselves poorer as a society, not just
[00:15:50.920 --> 00:15:53.800]   the individuals, by being so harsh and cruel.
[00:15:53.800 --> 00:15:56.320]   Okay, so invisible hand, Smith.
[00:15:56.320 --> 00:15:57.880]   Where does that fit in?
[00:15:57.880 --> 00:16:05.080]   The power of just people acting selfishly and somehow everything taking care of itself
[00:16:05.080 --> 00:16:14.560]   to where, you know, the economy grows, there's no cruelty, no injustice, that the markets
[00:16:14.560 --> 00:16:17.080]   regulate themselves.
[00:16:17.080 --> 00:16:20.640]   Is there power to that idea and what are its limits?
[00:16:20.640 --> 00:16:22.200]   There's a lot of power to that.
[00:16:22.200 --> 00:16:29.680]   I mean, there's a reason why I don't think sensible people want the government running
[00:16:29.680 --> 00:16:36.000]   steel mills or they want the government to own the farms, right?
[00:16:36.000 --> 00:16:44.920]   The markets are a pretty effective way of getting incentives aligned, of inducing people
[00:16:44.920 --> 00:16:46.440]   to do stuff that works.
[00:16:46.440 --> 00:16:50.400]   And the invisible hand is saying that, you know, people, farmers aren't growing crops
[00:16:50.400 --> 00:16:54.040]   because they want to feed people, they're growing crops because they can make money
[00:16:54.040 --> 00:17:00.320]   by it, but it actually turns out to be a pretty good way of getting agricultural products
[00:17:00.320 --> 00:17:01.560]   grown.
[00:17:01.560 --> 00:17:07.440]   So the invisible hand is an important part, but it's not, there's nothing mystical about
[00:17:07.440 --> 00:17:08.440]   it.
[00:17:08.440 --> 00:17:13.640]   It's a mechanism, it's a way to organize economic activity, which works well given a bunch of
[00:17:13.640 --> 00:17:18.200]   preconditions, which means that it actually works well for agriculture, it works well
[00:17:18.200 --> 00:17:24.840]   for manufacturing, it works well for many services, it doesn't work well for healthcare,
[00:17:24.840 --> 00:17:26.960]   it doesn't work well for education.
[00:17:26.960 --> 00:17:36.240]   So there are, having a society which is kind of three quarters invisible hand and one quarter
[00:17:36.240 --> 00:17:41.680]   visible hand seems to be, something on that order seems to be the balance that works best.
[00:17:41.680 --> 00:17:50.040]   It's just, you don't want to romanticize or make something mystical out of it, it's just,
[00:17:50.040 --> 00:17:55.560]   this is one way to organize stuff that happens to have broad but not universal application.
[00:17:55.560 --> 00:18:02.480]   So then forgive me for romanticizing it, but it does seem pretty magical that, you know,
[00:18:02.480 --> 00:18:06.320]   I kind of have an intuitive understanding of what happens when you have like five, ten,
[00:18:06.320 --> 00:18:09.000]   maybe even a hundred people together, the dynamics of that.
[00:18:09.000 --> 00:18:14.440]   But the fact that these large society of people, for the most part, acting in a self-interested
[00:18:14.440 --> 00:18:20.240]   way and maybe electing representatives for themselves, that it all kind of seems to work,
[00:18:20.240 --> 00:18:22.080]   it's pretty magical.
[00:18:22.080 --> 00:18:29.920]   The fact that there's, you know, that right now there's a wide assortment of fresh fruit
[00:18:29.920 --> 00:18:40.040]   and vegetables in the local markets up and down the street, you know, who's planning
[00:18:40.040 --> 00:18:41.040]   that?
[00:18:41.040 --> 00:18:45.840]   And the answer is nobody, that's the invisible hand at work, and that's great.
[00:18:45.840 --> 00:18:55.040]   And that's a lesson that Adam Smith figured out more than 200 years ago, and it continues
[00:18:55.040 --> 00:18:56.040]   to apply.
[00:18:56.480 --> 00:19:01.560]   But you know, even Adam Smith has a section in his book about why it's important to regulate
[00:19:01.560 --> 00:19:02.760]   banks.
[00:19:02.760 --> 00:19:04.680]   So the invisible hand has its limits.
[00:19:04.680 --> 00:19:09.160]   - Yeah, and that example is actually a powerful one in terms of the supermarket of fruit.
[00:19:09.160 --> 00:19:14.040]   That was my experience coming from Russia, from the Soviet Union, is when I first entered
[00:19:14.040 --> 00:19:19.080]   a supermarket and just seeing the assortment of fruit, bananas.
[00:19:19.080 --> 00:19:24.160]   I don't think I've seen bananas before, first of all, but just the selection of fresh fruit
[00:19:24.160 --> 00:19:28.640]   was just mind-blowing, beyond words.
[00:19:28.640 --> 00:19:32.760]   And the fact that, like you said, I don't know what made that happen.
[00:19:32.760 --> 00:19:39.760]   - Well, there is some magic to the market, but as I'm showing my age, but you know the
[00:19:39.760 --> 00:19:42.760]   old movie quote, "Sometimes the magic works and sometimes it doesn't, and you have to
[00:19:42.760 --> 00:19:44.720]   have some idea of when it doesn't."
[00:19:44.720 --> 00:19:48.320]   So how do you get regulation right?
[00:19:48.320 --> 00:19:51.280]   - What can government at its best do?
[00:19:51.280 --> 00:19:57.120]   And strangely enough in this country today, it seems to get a bad rap.
[00:19:57.120 --> 00:20:00.880]   Everyone seems to, everybody's against the government.
[00:20:00.880 --> 00:20:04.880]   - Yeah, well a lot of money has been spent on making people hate the government.
[00:20:04.880 --> 00:20:11.760]   But the reality is government does some things pretty well.
[00:20:11.760 --> 00:20:16.360]   Government does health insurance pretty well, so much so, I mean given our anti-government
[00:20:16.360 --> 00:20:20.080]   bias, it really is true that there are people out there saying, "Don't let the government
[00:20:20.080 --> 00:20:23.520]   get its hands on Medicare."
[00:20:23.520 --> 00:20:28.880]   So people actually love the government health insurance program far more than they love
[00:20:28.880 --> 00:20:32.480]   private health insurance.
[00:20:32.480 --> 00:20:41.520]   Basic education, it turns out that your local public high school is the right place to have
[00:20:41.520 --> 00:20:42.720]   students trained.
[00:20:42.720 --> 00:20:53.600]   And certainly for-profit education is by and large a nightmare of rip-offs and grift and
[00:20:53.600 --> 00:20:59.320]   people not getting what they thought they were paying for.
[00:20:59.320 --> 00:21:06.360]   It's a judgment case, and it's funny, there are things, I mean everybody talks about the
[00:21:06.360 --> 00:21:12.200]   DMV as being, do you want the economy, actually my experience is that the DMV have always
[00:21:12.200 --> 00:21:13.200]   been positive.
[00:21:13.200 --> 00:21:19.200]   Maybe I'm just going to the right DMVs, but in fact a lot of government works pretty well.
[00:21:19.200 --> 00:21:24.880]   So you'd have to, to some extent you can do these things on a priori grounds.
[00:21:24.880 --> 00:21:29.320]   You can talk about the logic of why healthcare is not gonna be handled well by the market,
[00:21:29.320 --> 00:21:31.000]   but partly it's just experience.
[00:21:31.000 --> 00:21:35.000]   We tried, or at least some countries have tried nationalizing their steel industries,
[00:21:35.000 --> 00:21:37.000]   that didn't go well.
[00:21:37.000 --> 00:21:39.920]   But we've tried privatizing education, and that didn't go well.
[00:21:39.920 --> 00:21:43.360]   So you find out what works.
[00:21:43.360 --> 00:21:46.320]   What about this new world of tech?
[00:21:46.320 --> 00:21:49.320]   How do you see, what do you think works for tech?
[00:21:49.320 --> 00:21:52.760]   Is it more regulation or less regulation?
[00:21:52.760 --> 00:21:56.480]   There are some things that need more regulation.
[00:21:56.480 --> 00:22:07.400]   We're finding out that the world of social media is one in which competitive forces aren't
[00:22:07.400 --> 00:22:12.080]   working very well, and trusting the companies to regulate themselves isn't working very
[00:22:12.080 --> 00:22:13.080]   well.
[00:22:13.080 --> 00:22:18.280]   But I'm on the whole a tech skeptic, not in the sense that I think that tech doesn't work
[00:22:18.280 --> 00:22:22.640]   and it doesn't do stuff, but the idea that we're living through greater technological
[00:22:22.640 --> 00:22:28.080]   change than ever before is really an illusion.
[00:22:28.080 --> 00:22:32.360]   Ever since the beginning of the Industrial Revolution, we've had a series of ethical
[00:22:32.360 --> 00:22:39.440]   shifts in the nature of work and the kinds of jobs that are available.
[00:22:39.440 --> 00:22:46.760]   And it's not at all clear that what's happening now is any bigger or faster or harder to cope
[00:22:46.760 --> 00:22:49.440]   with than past shocks.
[00:22:49.440 --> 00:22:55.280]   It is a popular notion in today's sort of public discourse that automation is going
[00:22:55.280 --> 00:22:59.680]   to have a huge impact on the job market now.
[00:22:59.680 --> 00:23:02.800]   There is something transformational happening now.
[00:23:02.800 --> 00:23:08.480]   Can you talk about that, maybe elaborate a little bit more?
[00:23:08.480 --> 00:23:16.160]   Do you not see the software revolutions happening now with machine learning, availability of
[00:23:16.160 --> 00:23:22.360]   data, that kind of automation, being able to sort of process, clean, find patterns in
[00:23:22.360 --> 00:23:30.200]   data and do you not see that disrupting any one sector to a point where there's a huge
[00:23:30.200 --> 00:23:31.560]   loss of jobs?
[00:23:31.560 --> 00:23:32.960]   There may be some things.
[00:23:32.960 --> 00:23:39.040]   I mean, actually, translators, there's really reduced demand for translators because machine
[00:23:39.040 --> 00:23:42.960]   translation ain't perfect, but it ain't bad.
[00:23:42.960 --> 00:23:53.320]   There are some kinds of things that are changed, but overall productivity growth has actually
[00:23:53.320 --> 00:23:56.000]   been slow in recent years.
[00:23:56.000 --> 00:23:59.820]   It's been much slower than in some past periods.
[00:23:59.820 --> 00:24:03.760]   So the idea that automation is taking away all the jobs, the counterpart would be that
[00:24:03.760 --> 00:24:08.720]   we would be able to produce stuff with many fewer workers than before, and that's not
[00:24:08.720 --> 00:24:09.720]   happening.
[00:24:09.720 --> 00:24:15.040]   There are a few isolated sectors, there are some kinds of jobs that are going away, but
[00:24:15.040 --> 00:24:16.360]   that keeps on happening.
[00:24:16.360 --> 00:24:22.960]   I mean, New York City used to have thousands and thousands of longshoremen taking stuff
[00:24:22.960 --> 00:24:28.240]   off ships and putting them on ships.
[00:24:28.240 --> 00:24:29.760]   They're almost all gone now.
[00:24:29.760 --> 00:24:36.960]   Now you have the giant cranes taking containers on and off ships in Elizabeth, New Jersey.
[00:24:36.960 --> 00:24:45.600]   That's not robots, it doesn't sound high tech, but it actually pretty much destroyed an occupation.
[00:24:45.600 --> 00:24:55.040]   Well, it wasn't fun for the longshoremen, to say the least, but we coped, we moved on,
[00:24:55.040 --> 00:24:57.920]   and that sort of thing happens all the time.
[00:24:57.920 --> 00:24:59.440]   You mean farmers.
[00:24:59.440 --> 00:25:03.240]   We used to be a nation which was mostly farmers.
[00:25:03.240 --> 00:25:07.480]   There are now very few farmers left.
[00:25:07.480 --> 00:25:13.440]   And the reason is not that we've stopped eating, it's that farming has become so efficient
[00:25:13.440 --> 00:25:16.760]   that we don't need a lot of farmers, and we coped with that too.
[00:25:16.760 --> 00:25:22.320]   So the idea that there's something qualitatively different about what's happening now, so far
[00:25:22.320 --> 00:25:23.320]   isn't true.
[00:25:23.320 --> 00:25:28.560]   So yeah, your intuition is there is going to be a loss of jobs, but it's just a thing
[00:25:28.560 --> 00:25:30.720]   that just continues.
[00:25:30.720 --> 00:25:33.280]   There's nothing qualitatively different about this moment.
[00:25:33.280 --> 00:25:37.840]   Some jobs will be lost, others will be created, as has always been the case so far.
[00:25:37.840 --> 00:25:43.040]   Maybe there's a singularity, maybe there's a moment when the machines get smarter than
[00:25:43.040 --> 00:25:46.800]   we are and SkyTech kills us all or something, right?
[00:25:46.800 --> 00:25:51.520]   But that's not visible in anything we're seeing now.
[00:25:51.520 --> 00:25:52.840]   You mentioned the metric of productivity.
[00:25:52.840 --> 00:25:54.160]   Could you explain that a little bit?
[00:25:54.160 --> 00:25:55.440]   Because it's a really interesting one.
[00:25:55.440 --> 00:26:00.320]   I've heard you mention that before in connection with automation.
[00:26:00.320 --> 00:26:05.320]   So what is that metric, and if there is something qualitatively different, what should we see
[00:26:05.320 --> 00:26:06.320]   in that metric?
[00:26:06.320 --> 00:26:08.600]   Well, okay, productivity.
[00:26:08.600 --> 00:26:09.720]   First of all, production.
[00:26:09.720 --> 00:26:17.000]   We do have a measure of the economy's total production, real GDP, which is itself, it's
[00:26:17.000 --> 00:26:22.460]   a little bit of a construct because it's quite literally, it's adding apples and oranges.
[00:26:22.460 --> 00:26:27.880]   So we have to add together various things, which we basically do by using market prices,
[00:26:27.880 --> 00:26:30.480]   but we try to adjust for inflation.
[00:26:30.480 --> 00:26:34.040]   But it's a reasonable measure of how much the economy is producing.
[00:26:34.040 --> 00:26:36.520]   Is it goods and, sorry to interrupt, is it goods and services?
[00:26:36.520 --> 00:26:39.240]   Goods and services, it's everything.
[00:26:39.240 --> 00:26:45.480]   Productivity is, you divide that total output by the number of hours worked.
[00:26:45.480 --> 00:26:52.640]   So we're basically asking how much stuff does the average worker produce in an hour of work?
[00:26:52.640 --> 00:26:57.920]   And if you're seeing really rapid technological progress, then you'd expect to see productivity
[00:26:57.920 --> 00:27:02.680]   rising at a rapid clip, which we did.
[00:27:02.680 --> 00:27:10.240]   For the generation after World War II, productivity rose 2% a year on a sustained basis.
[00:27:10.240 --> 00:27:15.400]   Then it dropped down for a while, then there was a decade of fairly rapid growth from the
[00:27:15.400 --> 00:27:20.160]   mid '90s to the mid 2000s, and then it dropped off again.
[00:27:20.160 --> 00:27:24.480]   And it's not impressive right now.
[00:27:24.480 --> 00:27:29.000]   You're just not seeing an epical shift in the economy.
[00:27:29.000 --> 00:27:32.120]   Let me then ask you about the psychology of blaming automation.
[00:27:32.120 --> 00:27:36.800]   A few months ago you wrote in the New York Times, quote, "The other day I found myself,
[00:27:36.800 --> 00:27:41.760]   as I often do at a conference, discussing lagging wages and soaring inequality.
[00:27:41.760 --> 00:27:45.660]   There was a lot of interesting discussion, but one thing that struck me was how many
[00:27:45.660 --> 00:27:50.760]   of the participants just assumed that robots are a big part of the problem, that machines
[00:27:50.760 --> 00:27:54.480]   are taking away the good jobs, or even jobs in general.
[00:27:54.480 --> 00:27:59.120]   For the most part, this wasn't even presented as a hypothesis, just as part of what everyone
[00:27:59.120 --> 00:28:00.120]   knows."
[00:28:00.120 --> 00:28:01.120]   - Yeah.
[00:28:01.120 --> 00:28:09.820]   - So why is, maybe can you psychoanalyze the public intellectuals or economists, or us
[00:28:09.820 --> 00:28:14.360]   actually in the general public, why this is happening?
[00:28:14.360 --> 00:28:17.840]   Why this assumption has just infiltrated public discourse?
[00:28:17.840 --> 00:28:19.720]   - There's a couple of things.
[00:28:19.720 --> 00:28:25.540]   One is that the particular technologies that are advancing now are ones that are a lot
[00:28:25.540 --> 00:28:31.720]   more visible to the chattering class.
[00:28:31.720 --> 00:28:37.920]   When containerization did away with the jobs of longshoremen, well, not a whole lot of
[00:28:37.920 --> 00:28:40.800]   college professors are close friends with longshoremen, right?
[00:28:40.800 --> 00:28:44.280]   And so we see this one.
[00:28:44.280 --> 00:28:49.960]   Then there's a second thing, which is, we just went through a severe financial crisis
[00:28:49.960 --> 00:28:55.760]   and a period of very high unemployment has finally come down.
[00:28:55.760 --> 00:29:00.280]   There's really no question that that high unemployment was about macroeconomics, it
[00:29:00.280 --> 00:29:02.440]   was about a failure of demand.
[00:29:02.440 --> 00:29:05.840]   But macroeconomics is really non-intuitive.
[00:29:05.840 --> 00:29:09.920]   People just have a hard time wrapping their minds around it, and among other things, people
[00:29:09.920 --> 00:29:14.080]   have a hard time believing that something as trivial as, well, people just aren't spending
[00:29:14.080 --> 00:29:19.600]   enough can lead to the kind of mass misery that we saw in the 1930s, or the not quite
[00:29:19.600 --> 00:29:24.200]   so severe, but still serious misery that we saw after 2008.
[00:29:24.200 --> 00:29:28.520]   And there's always a tendency to say, it must be something big, it must be technological
[00:29:28.520 --> 00:29:31.240]   change that means we don't need workers anymore.
[00:29:31.240 --> 00:29:36.120]   There was a lot of that in the '30s, and that same thing happened after 2008, the assumption
[00:29:36.120 --> 00:29:43.760]   that it has to be some deep cause, not something as trivial as a failure of investor confidence
[00:29:43.760 --> 00:29:48.200]   and inadequate monetary and fiscal response.
[00:29:48.200 --> 00:29:53.720]   And the last thing, wages.
[00:29:53.720 --> 00:29:57.640]   A lot of what's happened on wages is at some level political.
[00:29:57.640 --> 00:30:02.320]   It's the collapse of the union movement, it's policies that have squeezed workers' bargaining
[00:30:02.320 --> 00:30:08.440]   power, and for kind of obvious reasons, there are a lot of influential people who don't
[00:30:08.440 --> 00:30:10.160]   want to hear that story.
[00:30:10.160 --> 00:30:14.840]   They want it to be an inevitable force of nature, technology has made it impossible
[00:30:14.840 --> 00:30:23.960]   to have people earn middle class wages, and they don't like the story that says actually,
[00:30:23.960 --> 00:30:29.380]   no, it's kind of the political decisions that we made that have caused this income stagnation,
[00:30:29.380 --> 00:30:34.160]   and so they're a receptive audience for technological determinism.
[00:30:34.160 --> 00:30:40.600]   So what comes first in your view, the economy or politics in terms of what has impact on
[00:30:40.600 --> 00:30:41.600]   the other?
[00:30:41.600 --> 00:30:44.920]   Oh, well, look, everything interacts.
[00:30:44.920 --> 00:30:49.800]   That's one of the rules that I was taught in economics, everything affects everything
[00:30:49.800 --> 00:30:51.160]   else in at least two ways.
[00:30:51.160 --> 00:31:01.900]   But I mean, clearly the economy drives a lot of political stuff, but also clearly politics
[00:31:01.900 --> 00:31:08.000]   has a huge impact on the economy.
[00:31:08.000 --> 00:31:13.520]   We look at the decline of unions in America and say, well, the world has changed and unions
[00:31:13.520 --> 00:31:20.440]   don't have a role, but two-thirds of workers in Denmark are unionized, and Denmark has
[00:31:20.440 --> 00:31:25.120]   the same technology and faces the same global economy that we do, it's just a difference
[00:31:25.120 --> 00:31:27.760]   in political choices that leads to that difference.
[00:31:27.760 --> 00:31:34.240]   So I actually teach a course here at CUNY called Economics of the Welfare State, which
[00:31:34.240 --> 00:31:39.160]   is about things like healthcare and retirement, and to some extent wage policy and so on.
[00:31:39.160 --> 00:31:45.880]   And the message I keep on trying to drive home is that, look, all advanced countries
[00:31:45.880 --> 00:31:50.560]   have got roughly equal competence, we all have the same technology, but we make very
[00:31:50.560 --> 00:31:52.060]   different choices.
[00:31:52.060 --> 00:31:56.020]   Not that America always makes the wrong choices, we do some things pretty well, our retirement
[00:31:56.020 --> 00:32:02.760]   system is one of the better ones, but the point is that there's a huge amount of political
[00:32:02.760 --> 00:32:05.440]   choice involved in the shape of the economy.
[00:32:05.440 --> 00:32:09.160]   So what is a welfare state?
[00:32:09.160 --> 00:32:16.080]   Welfare state is the old term, but it basically refers to all the programs that are there
[00:32:16.080 --> 00:32:23.120]   to mitigate, if you like, the risks and injustices of the market economy.
[00:32:23.120 --> 00:32:28.400]   So in the US, the welfare state is Social Security, Medicare, Medicaid, minimum wages,
[00:32:28.400 --> 00:32:29.740]   food stamps.
[00:32:29.740 --> 00:32:34.240]   When you say welfare state, my first sort of feeling is a negative one.
[00:32:34.240 --> 00:32:40.920]   Even though I like all, I probably generally, at least theoretically, like all the welfare
[00:32:40.920 --> 00:32:41.920]   programs.
[00:32:41.920 --> 00:32:48.120]   Well, it's been demonized, and to some extent I'm doing a little bit of thumbing my nose
[00:32:48.120 --> 00:32:52.920]   at all of that by just using the term welfare state.
[00:32:52.920 --> 00:32:53.920]   No, it's not.
[00:32:53.920 --> 00:32:55.240]   I see, yeah, I got you.
[00:32:55.240 --> 00:33:03.480]   But everybody, every advanced country actually has a lot of welfare state, even the US.
[00:33:03.480 --> 00:33:06.560]   That's a fundamental part of the fabric of our society.
[00:33:06.560 --> 00:33:12.840]   Social Security, Medicare, Medicaid are just things we take for granted as part of the
[00:33:12.840 --> 00:33:15.360]   scene.
[00:33:15.360 --> 00:33:23.880]   So there's a lot of people on the right wing who are saying, "Oh, it's all socialism."
[00:33:23.880 --> 00:33:28.200]   And well, I guess, mean what you want them to mean.
[00:33:28.200 --> 00:33:39.580]   And just today, I told my class about the record that Ronald Reagan made in 1961, warning
[00:33:39.580 --> 00:33:43.320]   that Medicare would destroy American freedom.
[00:33:43.320 --> 00:33:47.120]   But it sort of didn't happen.
[00:33:47.120 --> 00:33:52.160]   On the topic of welfare state, what are your thoughts on universal basic income?
[00:33:52.160 --> 00:33:59.140]   And that's sort of a, not a generic, but a universal safety net of this kind.
[00:33:59.140 --> 00:34:00.140]   There's always a trade-off.
[00:34:00.140 --> 00:34:09.440]   When we talk about social safety net programs, there's always a trade-off between universality,
[00:34:09.440 --> 00:34:13.840]   which is clean, but means that you're giving a lot of money to people who don't necessarily
[00:34:13.840 --> 00:34:23.400]   need it, and some kind of targeting, which makes it easier to deal with the crucial problems
[00:34:23.400 --> 00:34:25.760]   with limited resources.
[00:34:25.760 --> 00:34:33.360]   But both has incentive problems and kind of political, and I would say even psychological
[00:34:33.360 --> 00:34:34.360]   issues.
[00:34:34.360 --> 00:34:41.560]   But the great thing about Social Security and Medicare is no questions asked.
[00:34:41.560 --> 00:34:45.520]   You don't have to prove that you need them.
[00:34:45.520 --> 00:34:46.520]   It just comes.
[00:34:46.520 --> 00:34:48.440]   I mean, I didn't...
[00:34:48.440 --> 00:34:49.760]   I'm on Medicare, allegedly.
[00:34:49.760 --> 00:34:59.180]   I mean, it's run through my New York Times health insurance, but I didn't have to file
[00:34:59.180 --> 00:35:02.360]   an application with the Medicare office to prove that I needed it.
[00:35:02.360 --> 00:35:05.600]   It just happened when I turned 65.
[00:35:05.600 --> 00:35:10.720]   That's good for dignity, and it's also good for the political support, because everybody
[00:35:10.720 --> 00:35:13.800]   gets Medicare.
[00:35:13.800 --> 00:35:17.040]   On the other hand, if you...
[00:35:17.040 --> 00:35:21.260]   And we can do that with healthcare.
[00:35:21.260 --> 00:35:27.280]   To give everybody a guarantee of an income that's enough to live on comfortably, that's
[00:35:27.280 --> 00:35:29.000]   a lot of money.
[00:35:29.000 --> 00:35:36.080]   What about enough income to carry you over through difficult periods, like if you lose
[00:35:36.080 --> 00:35:37.080]   a job, that kind of thing?
[00:35:37.080 --> 00:35:41.600]   Well, we have unemployment insurance, and I think our unemployment insurance is too
[00:35:41.600 --> 00:35:43.440]   short-lived and too stingy.
[00:35:43.440 --> 00:35:50.540]   It would be better to have a more comprehensive unemployment insurance benefit.
[00:35:50.540 --> 00:35:56.440]   But the trouble with something like universal basic income is that either the bar is set
[00:35:56.440 --> 00:36:02.000]   too low, so it's really not something you can live on, or it's an enormously expensive
[00:36:02.000 --> 00:36:03.000]   program.
[00:36:03.000 --> 00:36:09.080]   And so at this point, I think that we can do far better by building on the kinds of
[00:36:09.080 --> 00:36:10.680]   safety net programs we have.
[00:36:10.680 --> 00:36:17.560]   I mean, food stamps, earned income tax credit, we should have a lot more family support policies.
[00:36:17.560 --> 00:36:19.720]   Those things can deal with...
[00:36:19.720 --> 00:36:24.000]   Can do a lot more to really diminish the amount of misery in this country.
[00:36:24.000 --> 00:36:28.400]   UBI is something that is being...
[00:36:28.400 --> 00:36:34.240]   I mean, it goes kind of hand-in-hand with this belief that the robots are going to take
[00:36:34.240 --> 00:36:35.600]   all of our jobs.
[00:36:35.600 --> 00:36:39.760]   And if that was really happening, then I might reconsider my views on UPI, but I don't see
[00:36:39.760 --> 00:36:41.160]   that happening.
[00:36:41.160 --> 00:36:47.760]   So are you happy with discourse that's going on now in terms of politics?
[00:36:47.760 --> 00:36:55.000]   You mentioned a few political candidates, is the kind of thing going on both on Twitter
[00:36:55.000 --> 00:37:00.760]   and debates and the media, through the written word, through the spoken word, how do you
[00:37:00.760 --> 00:37:04.000]   assess the public discourse now in terms of politics?
[00:37:04.000 --> 00:37:06.080]   We're in a fragmented world.
[00:37:06.080 --> 00:37:07.080]   So the public discourse...
[00:37:07.080 --> 00:37:08.080]   More so than before.
[00:37:08.080 --> 00:37:09.680]   More so than ever before.
[00:37:09.680 --> 00:37:21.280]   So at this point, the public discourse that you see if Fox News is your principal news
[00:37:21.280 --> 00:37:26.440]   source is very different from the one you get if you read the New York Times.
[00:37:26.440 --> 00:37:34.160]   On the whole, my sense is that mainstream political reporting, policy reporting is A,
[00:37:34.160 --> 00:37:37.840]   not too great, but B, better than it's ever been.
[00:37:37.840 --> 00:37:43.520]   Because when I first got into the pundit business, it was just awful.
[00:37:43.520 --> 00:37:45.560]   Lots of things just never got covered.
[00:37:45.560 --> 00:37:50.200]   And if things did get covered, it was always both sides.
[00:37:50.200 --> 00:37:55.840]   It's the line that comes back from me writing during the 2000 campaign was that if one of
[00:37:55.840 --> 00:38:01.600]   the candidates said that the Earth was flat, the headline would be "Views Differ on Shape
[00:38:01.600 --> 00:38:02.600]   of Planet."
[00:38:02.600 --> 00:38:05.880]   I mean, that's less true.
[00:38:05.880 --> 00:38:08.880]   There's still a fair bit of that out there, but it's less true than there used to be.
[00:38:08.880 --> 00:38:15.160]   And there are more people reporting, writing on policy issues who actually understand them
[00:38:15.160 --> 00:38:18.080]   than ever before.
[00:38:18.080 --> 00:38:20.200]   So that's good.
[00:38:20.200 --> 00:38:31.440]   But still, how much the typical voter is actually informed is unclear.
[00:38:31.440 --> 00:38:43.640]   I mean, the Democratic debates, I'm hoping that we finally get down to not having 27
[00:38:43.640 --> 00:38:46.560]   people on the stage or whatever it is they have.
[00:38:46.560 --> 00:38:52.000]   But they're reasonably substantive, certainly better than before.
[00:38:52.000 --> 00:38:59.560]   And while there's a lot of still theater criticism instead of actual analysis in the reporting,
[00:38:59.560 --> 00:39:02.400]   it's not as totally dominant as in the past.
[00:39:02.400 --> 00:39:05.640]   Can I ask maybe a dumb question?
[00:39:05.640 --> 00:39:15.920]   But from an open-minded perspective, when people on the left and people on the right,
[00:39:15.920 --> 00:39:22.840]   I think view the others as sometimes complete idiots.
[00:39:22.840 --> 00:39:23.840]   Yeah.
[00:39:23.840 --> 00:39:27.480]   What do we do with that?
[00:39:27.480 --> 00:39:37.080]   Is it possible that the people on the right are correct about what they currently believe?
[00:39:37.080 --> 00:39:40.720]   Is that kind of open-mindedness helpful?
[00:39:40.720 --> 00:39:48.240]   Or is this division long-term productive for us to sort of have this food fight?
[00:39:48.240 --> 00:39:55.480]   Well, the trouble you have to confront is that there's a lot of stuff that just is false
[00:39:55.480 --> 00:39:59.520]   out there, but commands extensive political allegiance.
[00:39:59.520 --> 00:40:04.200]   So the idea, well, both sides need to listen to each other respectfully.
[00:40:04.200 --> 00:40:10.800]   I'm happy to do that when there's a view that is worthy of respect, but a lot of stuff is
[00:40:10.800 --> 00:40:11.800]   not.
[00:40:11.800 --> 00:40:19.760]   And so economics is something where I think I know something, and I'm not sure that I'm
[00:40:19.760 --> 00:40:20.760]   always right.
[00:40:20.760 --> 00:40:24.840]   In fact, I know I've been wrong plenty of times.
[00:40:24.840 --> 00:40:32.160]   But I think there is a difference between economic views that are within the realm of
[00:40:32.160 --> 00:40:39.680]   we can actually have an interesting discussion, and those that are just crank doctrines or
[00:40:39.680 --> 00:40:45.840]   things that are purely being disseminated because people are being paid to disseminate
[00:40:45.840 --> 00:40:46.840]   them.
[00:40:46.840 --> 00:40:54.560]   So there are plenty of good, serious center-right economists that I'm happy to talk to.
[00:40:54.560 --> 00:40:57.720]   None of those center-right economists has any role in the Trump administration.
[00:40:57.720 --> 00:41:02.720]   The Trump administration and by and large Republicans in Congress only want to listen
[00:41:02.720 --> 00:41:05.520]   to people who are cranks.
[00:41:05.520 --> 00:41:11.520]   And so I think it's being dishonest with my readers to pretend otherwise.
[00:41:11.520 --> 00:41:18.880]   There's no way I can reach out to people who think that reading Ayn Rand novels is how
[00:41:18.880 --> 00:41:20.360]   you learn about monetary economics.
[00:41:20.360 --> 00:41:22.320]   Let me linger on that point.
[00:41:22.320 --> 00:41:25.800]   So if you look at Ayn Rand, okay, so you said center-right.
[00:41:25.800 --> 00:41:29.040]   What about extreme, people who have radical views?
[00:41:29.040 --> 00:41:36.640]   You think they're not grounded in any kind of data, in any kind of reality?
[00:41:36.640 --> 00:41:44.440]   I'm just sort of curious about how open we should be to ideas that seem radical.
[00:41:44.440 --> 00:41:51.680]   Oh, radical ideas is fine, but then you have to ask, is there some basis for the radicalism?
[00:41:51.680 --> 00:42:02.000]   And if it's something that is not grounded in anything, then, and particularly, by the
[00:42:02.000 --> 00:42:06.360]   way, if it's something that's been refuted by evidence again and again, and people just
[00:42:06.360 --> 00:42:11.920]   keep saying it, if it's a zombie idea, and there's a lot of those out there, then there
[00:42:11.920 --> 00:42:16.000]   comes a point when it's not worth trying to fake respect for it.
[00:42:16.000 --> 00:42:17.000]   I see.
[00:42:17.000 --> 00:42:22.520]   So through the scientific process, you've shown that this idea does not hold water,
[00:42:22.520 --> 00:42:28.080]   but I like the idea of zombie ideas, but they live on through, it's like the idea that the
[00:42:28.080 --> 00:42:34.120]   earth is flat, for example, has been, for the most part, disproven.
[00:42:34.120 --> 00:42:39.000]   But it lives on, actually, and growing in popularity currently.
[00:42:39.000 --> 00:42:45.320]   And there's a lot of that out there, and you can't wish it away, and you're not being fair
[00:42:45.320 --> 00:42:49.880]   to either yourself, or if you're somebody who writes for the public, you're not being
[00:42:49.880 --> 00:42:53.000]   fair to your readers to pretend otherwise.
[00:42:53.000 --> 00:42:59.280]   So quantum mechanics is a strange theory, but it's testable, and so while being strange
[00:42:59.280 --> 00:43:06.880]   is widely accepted amongst physicists, how robust and testable are economics theories,
[00:43:06.880 --> 00:43:11.200]   if we compare them to quantum mechanics and physics and so on?
[00:43:11.200 --> 00:43:17.640]   Okay, economics, look, it's a complex system, and it's also one in which, by and large,
[00:43:17.640 --> 00:43:19.800]   you don't get to do experiments.
[00:43:19.800 --> 00:43:24.560]   And so economics is never going to be like quantum mechanics.
[00:43:24.560 --> 00:43:31.360]   That said, you get natural experiments, you get tests of rival doctrines.
[00:43:31.360 --> 00:43:40.000]   In the immediate aftermath of the financial crisis, there was one style, one basic theory
[00:43:40.000 --> 00:43:45.160]   of macroeconomics, which ultimately goes back to John Maynard Keynes, that made a few predictions.
[00:43:45.160 --> 00:43:52.040]   It said, "Under these circumstances, printing money will not be inflationary, running big
[00:43:52.040 --> 00:43:58.680]   budget deficits will not cause a rise in interest rates, slashing government spending, austerity
[00:43:58.680 --> 00:44:04.660]   policies will lead to depressions if tried."
[00:44:04.660 --> 00:44:12.920]   Other people had exactly the opposite predictions, and we got a fairly robust test, and one theory
[00:44:12.920 --> 00:44:13.920]   won.
[00:44:13.920 --> 00:44:18.360]   Interest rates stayed low, inflation stayed low, austerity countries that implemented
[00:44:18.360 --> 00:44:23.500]   harsh austerity policies suffered severe economic downturns.
[00:44:23.500 --> 00:44:29.740]   You don't get much, that's pretty clear, and that's not going to be true on everything.
[00:44:29.740 --> 00:44:36.500]   But there's a lot of empirical, I mean, the younger economists these days are very heavily
[00:44:36.500 --> 00:44:43.640]   data-based, and that's great, and I think that's the way to go.
[00:44:43.640 --> 00:44:48.800]   What theories of economics is there currently a lot of disagreement about, would you say?
[00:44:48.800 --> 00:44:55.180]   Oh, first of all, there's just a lot less disagreement, really, among serious researchers
[00:44:55.180 --> 00:44:57.820]   in economics than people imagine.
[00:44:57.820 --> 00:45:04.460]   We can track that, the Chicago Booth School has a panel, an ideologically diverse panel,
[00:45:04.460 --> 00:45:13.180]   and they regularly pose questions, and on most things there's a huge, there's remarkable
[00:45:13.180 --> 00:45:14.180]   consensus.
[00:45:14.180 --> 00:45:21.340]   There are a lot of things where people imagine that there's dispute, but the illusion of
[00:45:21.340 --> 00:45:27.260]   dispute is something that's basically being fed by political forces, and there isn't really.
[00:45:27.260 --> 00:45:37.020]   There are, I think, questions about what are effective ways to regulate technology industries.
[00:45:37.020 --> 00:45:43.740]   We really don't know the answers there.
[00:45:43.740 --> 00:45:48.860]   There's a, or look, I don't follow every part.
[00:45:48.860 --> 00:45:55.980]   Minimum wages, I think there's pretty overwhelming evidence that a modest increase in the minimum
[00:45:55.980 --> 00:46:05.540]   wage from current levels would not have any noticeable adverse effect on jobs, but if
[00:46:05.540 --> 00:46:13.540]   you ask how high could it go, $12 seems pretty safe, given what we know.
[00:46:13.540 --> 00:46:14.980]   Is 15 okay?
[00:46:14.980 --> 00:46:22.220]   There's some legitimate disagreement there, I think probably, but people have a point.
[00:46:22.220 --> 00:46:27.300]   20, where is the line at which it starts to become a problem, and the answer is truly
[00:46:27.300 --> 00:46:28.300]   we don't know.
[00:46:28.300 --> 00:46:33.460]   It's fascinating to try to, such a cool, economics is cool in that sense, because you're trying
[00:46:33.460 --> 00:46:38.380]   to predict something that hasn't been done before, the impact, the effects of something
[00:46:38.380 --> 00:46:39.780]   that hasn't been done before.
[00:46:39.780 --> 00:46:44.980]   Yeah, you're trying, you're going out of sample, and we have good reason to believe that there
[00:46:44.980 --> 00:46:49.660]   are, that it's non-linear, that there comes a point at which it doesn't work the way it
[00:46:49.660 --> 00:46:51.940]   has in the past.
[00:46:51.940 --> 00:46:56.020]   So as an economist, how do you see science and technological innovation?
[00:46:56.020 --> 00:47:03.220]   When I took various economics courses in college, technological innovation seemed like a no-brainer
[00:47:03.220 --> 00:47:08.340]   way of growing an economy, and we should invest in it aggressively.
[00:47:08.340 --> 00:47:13.940]   I may be biased, but it seemed like the various ways to grow an economy, it seems like the
[00:47:13.940 --> 00:47:16.460]   easiest way, especially long-term.
[00:47:16.460 --> 00:47:17.460]   Is that correct?
[00:47:17.460 --> 00:47:18.460]   Yeah.
[00:47:18.460 --> 00:47:20.820]   And if so, why aren't we doing it more?
[00:47:20.820 --> 00:47:22.540]   Well, that's, okay.
[00:47:22.540 --> 00:47:28.180]   The first question is, yeah, I mean, all, it's pretty much overwhelming.
[00:47:28.180 --> 00:47:31.780]   We think we can more or less measure this, although there are some assumptions involved,
[00:47:31.780 --> 00:47:38.580]   but it's something like 70 to 80% of the growth in per capita income is basically the advance
[00:47:38.580 --> 00:47:40.420]   of knowledge.
[00:47:40.420 --> 00:47:46.260]   It's not just the crude accumulation of capital, it is the fact that we get smarter.
[00:47:46.260 --> 00:47:50.140]   A lot of that, by the way, is more prosaic kinds of technology.
[00:47:50.140 --> 00:48:02.300]   So I like to talk about things like containerization or, in an earlier period, the invention of
[00:48:02.300 --> 00:48:05.460]   the flat-packed cardboard box.
[00:48:05.460 --> 00:48:12.100]   That had to be invented, and now all of your deliveries from Amazon are made possible by
[00:48:12.100 --> 00:48:14.060]   the existence of that technology.
[00:48:14.060 --> 00:48:20.700]   The web stuff is important too, but what would we do without cardboard boxes?
[00:48:20.700 --> 00:48:25.860]   But all of that stuff is really important in driving economic progress.
[00:48:25.860 --> 00:48:35.340]   Why don't we invest more in, again, more prosaic stuff?
[00:48:35.340 --> 00:48:41.460]   Why haven't we built another goddamn rail tunnel under the Hudson River, for which the
[00:48:41.460 --> 00:48:45.060]   need is so totally overwhelmingly obvious?
[00:48:45.060 --> 00:48:48.260]   How do you think about, first of all, I don't even know what the word prosaic means, but
[00:48:48.260 --> 00:48:50.660]   I inferred it, but how do you think about prosaic?
[00:48:50.660 --> 00:48:59.420]   Is it the really most basic, dumb technology innovation, or is it just the lowest hanging
[00:48:59.420 --> 00:49:04.100]   fruit of where benefit can be gained?
[00:49:04.100 --> 00:49:10.100]   When I say prosaic, I mean stuff that is not sexy and fancy and high-tech.
[00:49:10.100 --> 00:49:23.980]   It's building bridges and tunnels, inventing the cardboard box.
[00:49:23.980 --> 00:49:29.780]   Where do we put EasyPass in there?
[00:49:29.780 --> 00:49:36.300]   It is actually using some modern technology and all that, but I don't think they're going
[00:49:36.300 --> 00:49:43.340]   to make a movie about the guy, whoever it was that invented EasyPass, but it's actually
[00:49:43.340 --> 00:49:46.340]   a pretty significant productivity booster.
[00:49:46.340 --> 00:49:51.700]   To me, it always seemed like it's something that everybody should be able to agree on
[00:49:51.700 --> 00:49:54.820]   and just invest.
[00:49:54.820 --> 00:50:02.860]   In the same way, the investment in the military and the DOD is huge.
[00:50:02.860 --> 00:50:14.460]   Not everyone, but there's an agreement amongst people that somehow a large defense is important.
[00:50:14.460 --> 00:50:21.960]   It always seemed to me like that should be shifted towards, if you want to grow prosperity
[00:50:21.960 --> 00:50:25.300]   of the nation, you should be investing in knowledge.
[00:50:25.300 --> 00:50:28.700]   Yes, prosaic stuff, investing in infrastructure and so on.
[00:50:28.700 --> 00:50:32.580]   I mean, sorry to linger on it, but do you have any intuition?
[00:50:32.580 --> 00:50:35.260]   Do you have hope that that changes?
[00:50:35.260 --> 00:50:37.780]   Do you have intuition why it's not changing?
[00:50:37.780 --> 00:50:38.780]   It's unclear which intuition-
[00:50:38.780 --> 00:50:39.780]   I have more than an intuition.
[00:50:39.780 --> 00:50:40.780]   I have a theory.
[00:50:40.780 --> 00:50:46.740]   I'm reasonably certain that I understand why we don't do it.
[00:50:46.740 --> 00:50:56.940]   It's because we have a real values dispute about the welfare state, about how much the
[00:50:56.940 --> 00:51:00.780]   government should do to help the unfortunate.
[00:51:00.780 --> 00:51:08.060]   And politicians believe, probably rightly, that there's a kind of halo effect that surrounds
[00:51:08.060 --> 00:51:10.660]   any kind of government intervention.
[00:51:10.660 --> 00:51:18.300]   That even though providing people with enhanced social security benefits is really very different
[00:51:18.300 --> 00:51:24.060]   from building a tunnel under the Hudson River, politicians of both parties seem to believe
[00:51:24.060 --> 00:51:29.200]   that if the government is seen to be successful at doing one kind of thing, it will make people
[00:51:29.200 --> 00:51:32.440]   think more favorably on doing other kinds of things.
[00:51:32.440 --> 00:51:37.620]   And so we have conservatives tend to be opposed to any kind of increase in government spending,
[00:51:37.620 --> 00:51:45.980]   except military, no matter how obviously a good idea it is, because they fear that it's
[00:51:45.980 --> 00:51:50.340]   the thin end of the wedge for bigger government in general.
[00:51:50.340 --> 00:51:57.020]   And to some extent, liberals tend to favor spending on these things, partly because they
[00:51:57.020 --> 00:52:02.660]   see it as a way of proving that government can do things well, and therefore it can turn
[00:52:02.660 --> 00:52:05.780]   to broader social goals.
[00:52:05.780 --> 00:52:13.060]   It's clearly, if you like, what you might have thought would be a technocratic discussion
[00:52:13.060 --> 00:52:18.660]   about government investment, both in research and in infrastructure, is contaminated by
[00:52:18.660 --> 00:52:25.580]   the fact that government is government, and people link it to other government actions.
[00:52:25.580 --> 00:52:30.380]   Perhaps a silly question, but as a species, we're currently working on venturing out into
[00:52:30.380 --> 00:52:32.740]   space, one day colonizing Mars.
[00:52:32.740 --> 00:52:40.140]   So when we start a society on Mars from scratch, what political and economic system should
[00:52:40.140 --> 00:52:41.540]   it operate under?
[00:52:41.540 --> 00:52:44.500]   Oh, I'm a big believer in...
[00:52:44.500 --> 00:52:47.500]   First of all, I don't think we're actually gonna do that, but let's...
[00:52:47.500 --> 00:52:48.500]   Let's imagine.
[00:52:48.500 --> 00:52:51.940]   Hypothesize that we colonize Mars or something.
[00:52:51.940 --> 00:52:59.820]   Look, representative democracy is...
[00:52:59.820 --> 00:53:01.060]   Versus pure democracy.
[00:53:01.060 --> 00:53:08.140]   Well, yeah, pure democracy, where people vote directly on everything, is really problematic,
[00:53:08.140 --> 00:53:15.540]   because people don't have time to try and master every issue.
[00:53:15.540 --> 00:53:18.140]   We can see what government by referendum looks like.
[00:53:18.140 --> 00:53:23.140]   There's a lot of that in California, and it doesn't work so good, because it's hard to
[00:53:23.140 --> 00:53:27.000]   explain to people that the various things they vote for may conflict.
[00:53:27.000 --> 00:53:33.020]   So representative democracy is...
[00:53:33.020 --> 00:53:35.380]   It's got lots of problems.
[00:53:35.380 --> 00:53:36.380]   And I...
[00:53:36.380 --> 00:53:37.860]   You kind of know the Winston Churchill thing, right?
[00:53:37.860 --> 00:53:42.740]   It's the worst system we know, except for all the others.
[00:53:42.740 --> 00:53:45.940]   But so yeah, sticking with the representative...
[00:53:45.940 --> 00:53:52.580]   And basically, the American system of regulation and markets and the economy we have going
[00:53:52.580 --> 00:53:54.860]   on is a pretty good one for Mars.
[00:53:54.860 --> 00:53:57.260]   If you start from scratch.
[00:53:57.260 --> 00:54:03.420]   If you're gonna start from scratch, you wouldn't want a Senate where 16% of the population
[00:54:03.420 --> 00:54:06.380]   has half the seats.
[00:54:06.380 --> 00:54:12.940]   You probably would want one which is actually more representative than what we have.
[00:54:12.940 --> 00:54:19.420]   And the details, it's unclear.
[00:54:19.420 --> 00:54:26.500]   When times are good, all of the various representative democracy systems, whether it's parliamentary
[00:54:26.500 --> 00:54:32.860]   democracies or a US style system, whether you have a prime minister or the head of state
[00:54:32.860 --> 00:54:37.340]   as an elected president, they all kind of work well when times are good, and they all
[00:54:37.340 --> 00:54:39.260]   have different modes of breakdown.
[00:54:39.260 --> 00:54:42.060]   So I'm not sure I know what the answer is.
[00:54:42.060 --> 00:54:50.500]   But something like that is, given what we've seen through history, it's the least bad system
[00:54:50.500 --> 00:54:51.500]   out there.
[00:54:51.500 --> 00:54:57.180]   I mean, I don't know if you...
[00:54:57.180 --> 00:55:03.420]   I'm a big fan of the TV series, The Expanse, and it's kind of gratifying that out there
[00:55:03.420 --> 00:55:05.300]   the...
[00:55:05.300 --> 00:55:07.860]   It's the Martian Congressional Republic.
[00:55:07.860 --> 00:55:10.180]   Okay.
[00:55:10.180 --> 00:55:18.940]   In a brief sense, so amongst many things, you're also an expert at international trade.
[00:55:18.940 --> 00:55:23.460]   What do you make of the complexity?
[00:55:23.460 --> 00:55:29.020]   So I can understand trade between two people, say two neighboring farmers.
[00:55:29.020 --> 00:55:31.820]   It seems pretty straightforward to me.
[00:55:31.820 --> 00:55:35.340]   But internationally, when you start talking about nations and nations trading, it seems
[00:55:35.340 --> 00:55:37.540]   to be very complicated.
[00:55:37.540 --> 00:55:41.460]   So from a high level, why is it so complicated?
[00:55:41.460 --> 00:55:46.460]   What are all the different factors that weigh the objectives that need to be considered
[00:55:46.460 --> 00:55:48.260]   in international trade?
[00:55:48.260 --> 00:55:54.780]   And maybe feeding that into a question of, do you have concerns about the two giants
[00:55:54.780 --> 00:56:00.860]   right now of the US and China, and the tension that's going on with the international trade
[00:56:00.860 --> 00:56:02.140]   there with the trade war?
[00:56:02.140 --> 00:56:05.860]   Well, first of all, international trade is not really that different from trade among
[00:56:05.860 --> 00:56:06.860]   individuals.
[00:56:06.860 --> 00:56:13.340]   It's vastly more complex, and there are many more players.
[00:56:13.340 --> 00:56:17.420]   But in the end, the reasons why countries trade are pretty much the same as the reasons
[00:56:17.420 --> 00:56:18.980]   why individuals trade.
[00:56:18.980 --> 00:56:24.180]   Countries trade because they're different, and they can derive mutual advantage from
[00:56:24.180 --> 00:56:26.620]   concentrating on the things they do relatively well.
[00:56:26.620 --> 00:56:35.580]   And also, there are economies of scale.
[00:56:35.580 --> 00:56:38.660]   Individuals have to decide whether to be a surgeon or an accountant.
[00:56:38.660 --> 00:56:42.380]   It's probably not a good idea to try and be both.
[00:56:42.380 --> 00:56:49.460]   And countries benefit from specializing just because of the inherent advantages of specialization.
[00:56:49.460 --> 00:56:56.060]   So now, the fact that it's a big world, and we're talking about millions of products being
[00:56:56.060 --> 00:57:02.260]   traded, and in today's world, often trade involves many stages.
[00:57:02.260 --> 00:57:08.140]   So that made in China iPhone is actually assembled from components that are made all over the
[00:57:08.140 --> 00:57:10.220]   world.
[00:57:10.220 --> 00:57:15.060]   But it doesn't really change the fundamentals all that much.
[00:57:15.060 --> 00:57:16.060]   There's a recurrent...
[00:57:16.060 --> 00:57:19.420]   I mean, the big...
[00:57:19.420 --> 00:57:26.060]   The very little secret of international trade conflict is that actually it's not...
[00:57:26.060 --> 00:57:29.540]   Conflicts among countries are really not that important.
[00:57:29.540 --> 00:57:37.540]   U.S. trade is beneficial to both sides, to both countries, but it has big impacts on
[00:57:37.540 --> 00:57:40.180]   the distribution of income within countries.
[00:57:40.180 --> 00:57:47.620]   So the growth of U.S. trade with China has made both U.S. and China richer, but it's
[00:57:47.620 --> 00:57:54.380]   been pretty bad for people who were employed in the North Carolina furniture industry,
[00:57:54.380 --> 00:57:58.740]   who did find that their jobs were displaced by a wave of imports from China.
[00:57:58.740 --> 00:58:03.620]   And so that's where the complexity comes in.
[00:58:03.620 --> 00:58:07.140]   Not at all clear to me...
[00:58:07.140 --> 00:58:11.540]   We have some real problems with China, although they don't really involve trade so much as
[00:58:11.540 --> 00:58:17.380]   things like respect for intellectual property.
[00:58:17.380 --> 00:58:22.100]   Not clear that those real problems that we do have with China have anything to do with
[00:58:22.100 --> 00:58:23.100]   the current trade war.
[00:58:23.100 --> 00:58:30.100]   The current trade war seems to be driven instead by a fundamentally wrong notion that when
[00:58:30.100 --> 00:58:33.780]   we sell goods to China, that's good, and when we buy goods from China, that's bad.
[00:58:33.780 --> 00:58:36.860]   And that's misunderstanding the whole point.
[00:58:36.860 --> 00:58:40.460]   Is trade with China in both directions a good thing?
[00:58:40.460 --> 00:58:43.740]   Yeah, we would be poorer if it wasn't for it.
[00:58:43.740 --> 00:58:47.340]   But there are downsides, as there are for any economic change.
[00:58:47.340 --> 00:58:53.460]   It's like any new technology makes us richer, but often hurts some people.
[00:58:53.460 --> 00:58:56.780]   Trade with China makes us richer, but hurts some people.
[00:58:56.780 --> 00:59:05.620]   And I wouldn't undo what has happened, but I wish we had had a better policy for supporting
[00:59:05.620 --> 00:59:09.460]   and compensating the losers from that growth.
[00:59:09.460 --> 00:59:15.820]   So we live in a time of radicalization of political ideas, Twitter mobs, and so on.
[00:59:15.820 --> 00:59:21.460]   And yet here you are in the midst of it, both tweeting and writing in the New York Times
[00:59:21.460 --> 00:59:26.660]   articles with strong opinions, riding this chaotic wave of public discourse.
[00:59:26.660 --> 00:59:34.380]   Do you ever hesitate or feel a tinge of fear for exploring your ideas publicly and unapologetically?
[00:59:34.380 --> 00:59:37.820]   Oh, I feel fear all the time.
[00:59:37.820 --> 00:59:42.260]   It's not too hard to imagine scenarios in which this is going to, I might personally
[00:59:42.260 --> 00:59:47.180]   find myself kind of in the crosshairs.
[00:59:47.180 --> 00:59:54.540]   And I mean, I am the king of hate mail, I get amazing correspondence.
[00:59:54.540 --> 00:59:56.380]   Does it affect you?
[00:59:56.380 --> 00:59:57.940]   It did when it started.
[00:59:57.940 --> 01:00:01.780]   These days I've developed a very thick skin.
[01:00:01.780 --> 01:00:08.260]   So I know I don't usually get, in fact, if I don't get a wave of hate mail after a column,
[01:00:08.260 --> 01:00:11.220]   then I probably wasted that day.
[01:00:11.220 --> 01:00:16.340]   So what do you make of that as a person who's putting ideas out there?
[01:00:16.340 --> 01:00:21.460]   If you look at the history of ideas, the way it works is you write about ideas, you put
[01:00:21.460 --> 01:00:22.460]   them out there.
[01:00:22.460 --> 01:00:28.860]   But now when there is so much hate mail, so much division, what advice do you have for
[01:00:28.860 --> 01:00:34.140]   yourself and for others trying to have a discussion about ideas, difficult ideas?
[01:00:34.140 --> 01:00:36.300]   Well, I don't know about advice for others.
[01:00:36.300 --> 01:00:44.260]   I mean, for most economists, just do your research.
[01:00:44.260 --> 01:00:47.140]   We can't all be public intellectuals and we shouldn't try to be.
[01:00:47.140 --> 01:00:55.180]   And in fact, I'm glad that I didn't get into this business until I was in my late 40s.
[01:00:55.180 --> 01:01:03.820]   I mean, it's probably best to spend your decades of greatest intellectual flexibility addressing
[01:01:03.820 --> 01:01:10.940]   deep questions, not confronting Twitter mobs.
[01:01:10.940 --> 01:01:20.340]   And as for the rest, I think when you're writing about stuff, sort of dance like no one's watching,
[01:01:20.340 --> 01:01:21.940]   write like nobody's reading.
[01:01:21.940 --> 01:01:24.420]   Write what you think is right.
[01:01:24.420 --> 01:01:30.220]   Trying to make it, obviously, trying to make it comprehensible and persuasive, but don't
[01:01:30.220 --> 01:01:40.580]   let yourself get intimidated by the fact that some people are going to say nasty things.
[01:01:40.580 --> 01:01:47.660]   You can't do your job if you are worried about criticism.
[01:01:47.660 --> 01:01:52.220]   Well, I think I speak for a lot of people in saying that I hope that you keep dancing
[01:01:52.220 --> 01:01:56.820]   like nobody's watching on Twitter and New York Times and books.
[01:01:56.820 --> 01:01:58.980]   So Paul, it's been an honor.
[01:01:58.980 --> 01:02:00.660]   Thank you so much for talking to me.
[01:02:00.660 --> 01:02:01.660]   Okay, great.
[01:02:01.660 --> 01:02:05.540]   Thanks for listening to this conversation with Paul Krugman and thank you to our presenting
[01:02:05.540 --> 01:02:07.460]   sponsor Cash App.
[01:02:07.460 --> 01:02:10.100]   Download it and use code LEXPODCAST.
[01:02:10.100 --> 01:02:15.220]   You'll get $10 and $10 will go to FIRST, an organization that inspires and educates young
[01:02:15.220 --> 01:02:19.820]   minds to become science and technology innovators of tomorrow.
[01:02:19.820 --> 01:02:24.780]   If you enjoy this podcast, subscribe on YouTube, get five stars on Apple Podcast, follow us
[01:02:24.780 --> 01:02:31.380]   on Spotify, support on Patreon, or simply connect with me on Twitter @LexFriedman.
[01:02:31.380 --> 01:02:36.820]   And now let me leave you some words from Adam Smith in The Wealth of Nations, one of the
[01:02:36.820 --> 01:02:40.980]   most influential philosophers and economists in our history.
[01:02:40.980 --> 01:02:45.860]   "It is not from the benevolence of the butcher, the brewer, or the baker that we expect our
[01:02:45.860 --> 01:02:49.820]   dinner, but from their regard to their own interest.
[01:02:49.820 --> 01:02:54.900]   We address ourselves not to their humanity, but to their self-love, and never talk to
[01:02:54.900 --> 01:03:00.540]   them of our necessities, but of their advantages."
[01:03:00.540 --> 01:03:03.180]   Thank you for listening and hope to see you next time.
[01:03:03.180 --> 01:03:03.680]   [END]
[01:03:03.680 --> 01:03:11.680]   1

