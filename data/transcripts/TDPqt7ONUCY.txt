
[00:00:00.000 --> 00:00:03.120]   >> My name is Pat Grady.
[00:00:03.120 --> 00:00:05.480]   I'm one of the members of Team Sequoia.
[00:00:05.480 --> 00:00:06.880]   I'm here with my partners,
[00:00:06.880 --> 00:00:09.480]   Sonia and Konstantin,
[00:00:09.480 --> 00:00:11.480]   who will be your MCs for the day.
[00:00:11.480 --> 00:00:13.840]   Along with all of our partners at Sequoia,
[00:00:13.840 --> 00:00:17.800]   we would like to welcome you to AI Ascent.
[00:00:17.800 --> 00:00:22.220]   There's a lot going on in the world of AI.
[00:00:22.220 --> 00:00:23.880]   We have an objective to
[00:00:23.880 --> 00:00:25.680]   learn a few things while we're here today.
[00:00:25.680 --> 00:00:28.440]   We have an objective to meet a few people who can be
[00:00:28.440 --> 00:00:30.000]   helpful in our journey while we're here
[00:00:30.000 --> 00:00:32.400]   today and hopefully, we'll have a little bit of fun.
[00:00:32.400 --> 00:00:36.160]   So just to frame the opportunity, what is it?
[00:00:36.160 --> 00:00:38.680]   Well, a year ago,
[00:00:38.680 --> 00:00:40.800]   it felt like this magic box
[00:00:40.800 --> 00:00:43.320]   that could do wonderful, amazing things.
[00:00:43.320 --> 00:00:44.740]   I think over the last 12 months,
[00:00:44.740 --> 00:00:47.640]   we've been through this contracted form of the hype cycle.
[00:00:47.640 --> 00:00:49.800]   We had the peak of inflated expectations,
[00:00:49.800 --> 00:00:51.320]   we have the trough of disillusionment,
[00:00:51.320 --> 00:00:53.920]   we're crawling back out into the plateau of productivity.
[00:00:53.920 --> 00:00:56.200]   I think we've realized that what LLMs,
[00:00:56.200 --> 00:00:57.720]   what AI really brings to us today are
[00:00:57.720 --> 00:01:00.240]   three distinct capabilities that can
[00:01:00.240 --> 00:01:02.920]   be woven into a wide variety of magical applications.
[00:01:02.920 --> 00:01:05.280]   The first is the ability to create,
[00:01:05.280 --> 00:01:06.680]   hence the name generative AI.
[00:01:06.680 --> 00:01:08.260]   You can create images, you can create text,
[00:01:08.260 --> 00:01:09.840]   you can create video, you can create audio,
[00:01:09.840 --> 00:01:11.240]   you can create all sorts of things.
[00:01:11.240 --> 00:01:13.440]   Not something software has been able to do before.
[00:01:13.440 --> 00:01:14.720]   So that's pretty cool.
[00:01:14.720 --> 00:01:17.520]   The second is the ability to reason,
[00:01:17.520 --> 00:01:20.800]   could be one-shot, could be multi-step agentic type reasoning.
[00:01:20.800 --> 00:01:24.340]   But again, not something software has been able to do before.
[00:01:24.340 --> 00:01:26.460]   Because it can create,
[00:01:26.460 --> 00:01:28.100]   because it can reason,
[00:01:28.100 --> 00:01:30.740]   we've got the right brain and the left brain covered,
[00:01:30.740 --> 00:01:34.660]   which means that software can also for the first time,
[00:01:34.660 --> 00:01:38.180]   interact in a human-like capacity.
[00:01:38.180 --> 00:01:39.780]   This is huge because this has
[00:01:39.780 --> 00:01:41.620]   profound business model implications
[00:01:41.620 --> 00:01:43.860]   that we're going to mention on the next slide.
[00:01:43.860 --> 00:01:47.740]   So what? A lot of times we try to
[00:01:47.740 --> 00:01:49.940]   reason by analogy when we see something new.
[00:01:49.940 --> 00:01:52.740]   In this case, the best analogy that we can come up with,
[00:01:52.740 --> 00:01:54.820]   which is imperfect for a million reasons,
[00:01:54.820 --> 00:01:57.500]   but still useful, is the Cloud transition.
[00:01:57.500 --> 00:01:59.140]   Over the last 20 years or so,
[00:01:59.140 --> 00:02:00.700]   that was a major tectonic shift in
[00:02:00.700 --> 00:02:03.100]   the technology landscape that led to new business models,
[00:02:03.100 --> 00:02:06.940]   new applications, new ways for people to interact with technology.
[00:02:06.940 --> 00:02:10.060]   If we go back to some of the early days of that Cloud transition,
[00:02:10.060 --> 00:02:12.260]   this is circa about 2010,
[00:02:12.260 --> 00:02:16.800]   the entire pie, the entire global TAM for software is about 350 billion,
[00:02:16.800 --> 00:02:18.720]   of which this tiny slice,
[00:02:18.720 --> 00:02:20.900]   just $6 billion is Cloud software.
[00:02:20.900 --> 00:02:22.940]   Fast forward to last year,
[00:02:22.940 --> 00:02:25.580]   the TAM has grown from about 350 to 650,
[00:02:25.580 --> 00:02:29.300]   but that slice has become 400 billion of revenue.
[00:02:29.300 --> 00:02:32.420]   That's a 40 percent CAGR over 15 years.
[00:02:32.420 --> 00:02:34.300]   That's massive growth.
[00:02:34.300 --> 00:02:37.980]   Now, if we're going to reason by analogy,
[00:02:37.980 --> 00:02:41.740]   Cloud was replacing software with software.
[00:02:41.740 --> 00:02:43.900]   Because of what I mentioned about the ability to
[00:02:43.900 --> 00:02:46.580]   interact in a human-like capability,
[00:02:46.580 --> 00:02:52.380]   one of the big opportunities for AI is to replace services with software.
[00:02:52.380 --> 00:02:54.380]   If that's the TAM that we're going after,
[00:02:54.380 --> 00:02:56.420]   the starting point is not hundreds of billions,
[00:02:56.420 --> 00:03:00.220]   the starting point is possibly tens of trillions.
[00:03:00.220 --> 00:03:05.820]   So you can really dream about what this has a chance to become.
[00:03:05.820 --> 00:03:08.420]   We would posit, and this is a hypothesis,
[00:03:08.420 --> 00:03:10.280]   as everything we say today will be,
[00:03:10.280 --> 00:03:12.860]   we would posit that we are standing at the precipice of
[00:03:12.860 --> 00:03:16.900]   the single greatest value creation opportunity mankind has ever known.
[00:03:16.900 --> 00:03:23.300]   Why now? One of the benefits of being part of Sequoia is that we have
[00:03:23.300 --> 00:03:26.100]   this long history and we've gotten to study
[00:03:26.100 --> 00:03:28.620]   the different waves of technology and understand how they
[00:03:28.620 --> 00:03:31.300]   interact and understand how they lead us to the present moment.
[00:03:31.300 --> 00:03:33.300]   We're going to take a quick trip down memory lane.
[00:03:33.300 --> 00:03:35.940]   So 1960s, our partner,
[00:03:35.940 --> 00:03:37.580]   Don Valentine, who founded Sequoia,
[00:03:37.580 --> 00:03:40.980]   was actually the guy who ran the go-to-market for Fairchild Semiconductor,
[00:03:40.980 --> 00:03:44.140]   which gave Silicon Valley its name with Silicon-based transistors.
[00:03:44.140 --> 00:03:45.500]   We got to see that happen.
[00:03:45.500 --> 00:03:49.940]   We got to see the 1970s when systems were built on top of those chips.
[00:03:49.940 --> 00:03:53.300]   We got to see the 1980s when they were connected up by
[00:03:53.300 --> 00:03:57.620]   networks with PCs as the endpoint and the advent of package software.
[00:03:57.620 --> 00:04:02.020]   We got to see the 1990s when those networks went public-facing in the form of the Internet,
[00:04:02.020 --> 00:04:03.340]   changed the way we communicate,
[00:04:03.340 --> 00:04:04.700]   changed the way we consume.
[00:04:04.700 --> 00:04:07.820]   We got to see the 2000s when the Internet matured to
[00:04:07.820 --> 00:04:10.380]   the point where it could support sophisticated applications,
[00:04:10.380 --> 00:04:12.260]   which became known as the Cloud.
[00:04:12.260 --> 00:04:15.500]   We got to see the 2010s where all those apps showed up in
[00:04:15.500 --> 00:04:19.700]   our pocket in the form of mobile devices and changed the way we work.
[00:04:19.700 --> 00:04:23.220]   So why do we bother going through this little build?
[00:04:23.220 --> 00:04:25.260]   Well, the point here is that each one of these waves is
[00:04:25.260 --> 00:04:28.180]   additive with what came before.
[00:04:28.180 --> 00:04:31.100]   The idea of AI is nothing new.
[00:04:31.100 --> 00:04:32.860]   It dates back to the 1940s.
[00:04:32.860 --> 00:04:36.180]   I think neural nets first became an idea in the 1940s.
[00:04:36.180 --> 00:04:40.900]   But the ingredients required to take AI from idea,
[00:04:40.900 --> 00:04:43.780]   from dream, into production,
[00:04:43.780 --> 00:04:47.620]   into reality, to actually solve real-world problems in
[00:04:47.620 --> 00:04:52.020]   a unique and compelling way that you can build a durable business around.
[00:04:52.020 --> 00:04:56.500]   The ingredients required to do that did not exist until the past couple of years.
[00:04:56.500 --> 00:04:59.980]   We finally have compute that is cheap and plentiful.
[00:04:59.980 --> 00:05:03.500]   We have networks that are fast and efficient and reliable.
[00:05:03.500 --> 00:05:05.100]   Seven of the eight billion people on
[00:05:05.100 --> 00:05:07.380]   the planet have a supercomputer in their pockets.
[00:05:07.380 --> 00:05:08.900]   Thanks in part to COVID,
[00:05:08.900 --> 00:05:10.780]   everything has been forced online,
[00:05:10.780 --> 00:05:12.900]   and the data required to fuel
[00:05:12.900 --> 00:05:15.700]   all of these delightful experiences is readily available.
[00:05:15.700 --> 00:05:19.380]   So now is the moment for AI to
[00:05:19.380 --> 00:05:23.900]   become the theme of the next 10, probably 20 years.
[00:05:23.900 --> 00:05:27.740]   So we have as strong conviction as you could possibly
[00:05:27.740 --> 00:05:30.620]   have in a hypothesis that is not yet proven,
[00:05:30.620 --> 00:05:35.020]   that the next couple of decades are going to be the time of AI.
[00:05:35.020 --> 00:05:38.180]   What shape would that opportunity take?
[00:05:38.180 --> 00:05:40.020]   Again, we're going to analogize to
[00:05:40.020 --> 00:05:41.820]   the Cloud transition and the mobile transition.
[00:05:41.820 --> 00:05:44.380]   These logos on the left side of the page,
[00:05:44.380 --> 00:05:46.860]   those are most of the companies born as a result of
[00:05:46.860 --> 00:05:49.740]   those transitions that got to a billion dollars plus of revenue.
[00:05:49.740 --> 00:05:51.140]   The list is not exhaustive,
[00:05:51.140 --> 00:05:54.140]   but this is probably 80 percent or so of the companies
[00:05:54.140 --> 00:05:57.300]   formed in those transitions that got to a billion plus of revenue,
[00:05:57.300 --> 00:05:59.540]   not valuation, revenue.
[00:05:59.540 --> 00:06:03.100]   The most interesting thing about this slide is the right side.
[00:06:03.100 --> 00:06:07.380]   It's not what's there, it's what isn't there.
[00:06:07.380 --> 00:06:10.380]   The landscape is wide open.
[00:06:10.380 --> 00:06:14.820]   The opportunity set is massive.
[00:06:14.820 --> 00:06:19.660]   We think if we were standing here 10 or 15 years from today,
[00:06:19.660 --> 00:06:23.660]   that right side is going to have 40 or 50 logos in it.
[00:06:23.660 --> 00:06:25.620]   Chances are, it's going to be a bunch of
[00:06:25.620 --> 00:06:28.260]   the logos of companies that are in this room.
[00:06:28.260 --> 00:06:29.860]   This is the opportunity,
[00:06:29.860 --> 00:06:31.700]   this is why we're excited.
[00:06:31.700 --> 00:06:34.740]   With that, I will hand it off to Sonia.
[00:06:34.740 --> 00:06:43.940]   >> Thanks Pat. Wow, what a year.
[00:06:43.940 --> 00:06:46.980]   ChatGPT came out a year and a half ago.
[00:06:46.980 --> 00:06:49.340]   I think it's been a whirlwind for everybody here.
[00:06:49.340 --> 00:06:51.860]   It probably feels like just about all of us have been going
[00:06:51.860 --> 00:06:55.220]   non-stop with the ground shifting under our feet constantly.
[00:06:55.220 --> 00:06:57.060]   So let's take a pause, zoom out,
[00:06:57.060 --> 00:06:59.580]   and take stock on what's happened so far.
[00:06:59.580 --> 00:07:02.220]   Last year, we were talking about how AI was going to
[00:07:02.220 --> 00:07:04.140]   revolutionize all these different fields
[00:07:04.140 --> 00:07:06.020]   and provide amazing productivity gains.
[00:07:06.020 --> 00:07:09.220]   A year later, it's starting to come into focus.
[00:07:09.220 --> 00:07:12.780]   Who here has seen this tweet from Sebastian at Klarna?
[00:07:12.780 --> 00:07:16.740]   Show of hands. It's pretty incredible.
[00:07:16.740 --> 00:07:18.380]   Klarna is now using OpenAI to
[00:07:18.380 --> 00:07:20.980]   handle two-thirds of customer service inquiries.
[00:07:20.980 --> 00:07:25.460]   They've automated the equivalent of 700 full-time agents jobs.
[00:07:25.460 --> 00:07:28.100]   We think there are tens of millions of call center agents
[00:07:28.100 --> 00:07:30.500]   globally and one of the most exciting areas
[00:07:30.500 --> 00:07:31.900]   where we've already seen AI find
[00:07:31.900 --> 00:07:35.740]   product market fit is in this customer support markets.
[00:07:35.740 --> 00:07:38.340]   Legal services. A year ago,
[00:07:38.340 --> 00:07:41.460]   the law was considered one of the least tech forward industries,
[00:07:41.460 --> 00:07:43.980]   one of the least likely to take risks.
[00:07:43.980 --> 00:07:46.740]   Now, we have companies like Harvey that are automating away
[00:07:46.740 --> 00:07:50.140]   a lot of the work that lawyers do from day-to-day grunt work and
[00:07:50.140 --> 00:07:53.340]   drudgery all the way to more advanced analysis.
[00:07:53.340 --> 00:07:55.980]   Or software engineering. I'm sure a bunch of people in
[00:07:55.980 --> 00:07:56.900]   this room have seen some of
[00:07:56.900 --> 00:07:59.660]   the demos floating around on Twitter recently.
[00:07:59.660 --> 00:08:02.220]   It's remarkable that we've gone from a year ago,
[00:08:02.220 --> 00:08:05.420]   AI theoretically writing our code to
[00:08:05.420 --> 00:08:08.900]   entirely self-contained AI software engineers.
[00:08:08.900 --> 00:08:10.420]   I think it's really exciting. The future's
[00:08:10.420 --> 00:08:12.420]   going to have a lot more software.
[00:08:12.420 --> 00:08:16.260]   AI isn't all about revolutionizing work.
[00:08:16.260 --> 00:08:18.060]   It's already increasing our quality of life.
[00:08:18.060 --> 00:08:20.580]   Now, the other day, I was in a Zoom with Pat,
[00:08:20.580 --> 00:08:23.660]   and I noticed that he looked a little bit suspicious,
[00:08:23.660 --> 00:08:25.900]   didn't speak the entire time.
[00:08:25.900 --> 00:08:27.460]   Having reflected on it more,
[00:08:27.460 --> 00:08:29.500]   I'm pretty sure that he actually sent in
[00:08:29.500 --> 00:08:32.740]   his virtual AI avatar and was actually hitting the gym,
[00:08:32.740 --> 00:08:34.260]   which would explain a lot.
[00:08:34.260 --> 00:08:37.020]   >> Hi, this is Pat Grady. This is definitely me.
[00:08:37.020 --> 00:08:40.220]   I'm definitely here and not at the gym right now.
[00:08:40.220 --> 00:08:44.660]   >> It even gets the facial scrunches.
[00:08:44.660 --> 00:08:46.580]   >> This is courtesy of Haygen.
[00:08:46.580 --> 00:08:48.620]   It's pretty amazing.
[00:08:48.620 --> 00:08:51.300]   This is how far technology has come in a year.
[00:08:51.300 --> 00:08:55.100]   It's scary and exciting
[00:08:55.100 --> 00:08:57.940]   to think about how this all plays out in the coming decade.
[00:08:57.940 --> 00:09:01.500]   All kidding aside, two years ago,
[00:09:01.500 --> 00:09:03.820]   when we thought that Generative AI might usher
[00:09:03.820 --> 00:09:06.260]   in the next great technology shift,
[00:09:06.260 --> 00:09:08.140]   we didn't know what to expect.
[00:09:08.140 --> 00:09:10.100]   Would real companies come out of it?
[00:09:10.100 --> 00:09:12.460]   Would real revenue materialize?
[00:09:12.460 --> 00:09:15.060]   I think the sheer scale of user pull and
[00:09:15.060 --> 00:09:18.620]   revenue momentum has surprised just about everybody.
[00:09:18.620 --> 00:09:20.260]   Generative AI, we think,
[00:09:20.260 --> 00:09:23.780]   is now clocking in around $3 billion of revenues in aggregate,
[00:09:23.780 --> 00:09:26.180]   and that's before you count all the incremental revenue
[00:09:26.180 --> 00:09:29.660]   generated by the FANG companies and the Cloud providers in AI.
[00:09:29.660 --> 00:09:31.740]   To put three billion in context,
[00:09:31.740 --> 00:09:34.220]   it took the SaaS market nearly a decade
[00:09:34.220 --> 00:09:36.020]   to reach that level of revenue.
[00:09:36.020 --> 00:09:38.780]   Generative AI got there its first year out the gate.
[00:09:38.780 --> 00:09:40.460]   The rate and the magnitude of
[00:09:40.460 --> 00:09:42.140]   the sea change make it very clear to us
[00:09:42.140 --> 00:09:44.740]   that Generative AI is here to stay.
[00:09:44.740 --> 00:09:49.580]   The customer pull in AI isn't restricted to one or two apps.
[00:09:49.580 --> 00:09:51.980]   It's everywhere. I'm sure everyone's aware of
[00:09:51.980 --> 00:09:54.020]   how many users ChatGPT has.
[00:09:54.020 --> 00:09:56.620]   But when you look at the revenue and the usage numbers,
[00:09:56.620 --> 00:09:58.060]   for a lot of AI apps,
[00:09:58.060 --> 00:10:00.820]   both consumer companies and enterprise companies,
[00:10:00.820 --> 00:10:02.940]   startups, and incumbents,
[00:10:02.940 --> 00:10:05.660]   many AI products are actually striking a chord with
[00:10:05.660 --> 00:10:07.060]   customers and starting to find
[00:10:07.060 --> 00:10:09.140]   product market fit across industries.
[00:10:09.140 --> 00:10:11.580]   We find the diversity of use cases that are starting to
[00:10:11.580 --> 00:10:14.020]   hit really exciting.
[00:10:14.020 --> 00:10:17.020]   The number one thing that has surprised me,
[00:10:17.020 --> 00:10:19.540]   at least, about the funding environment over
[00:10:19.540 --> 00:10:20.700]   the last year has been how
[00:10:20.700 --> 00:10:22.780]   uneven the share of funding has been.
[00:10:22.780 --> 00:10:24.740]   If you think of Generative AI as
[00:10:24.740 --> 00:10:27.820]   a layer cake where you have foundation models on the bottom,
[00:10:27.820 --> 00:10:29.860]   you have developer tools and infra above,
[00:10:29.860 --> 00:10:31.740]   and then you have applications on top.
[00:10:31.740 --> 00:10:33.300]   A year ago, we'd expected
[00:10:33.300 --> 00:10:35.500]   that there would be a Cambrian explosion in
[00:10:35.500 --> 00:10:37.060]   the application layer due to
[00:10:37.060 --> 00:10:39.540]   the new enabling technology in the foundation layer.
[00:10:39.540 --> 00:10:41.340]   Instead, we've actually found that
[00:10:41.340 --> 00:10:43.060]   new company formation and capital
[00:10:43.060 --> 00:10:44.980]   has formed in an inverse pattern.
[00:10:44.980 --> 00:10:47.220]   More and more foundation models are popping
[00:10:47.220 --> 00:10:49.660]   up and raising very large funding rounds,
[00:10:49.660 --> 00:10:51.060]   while the application layer feels
[00:10:51.060 --> 00:10:53.220]   like it is just getting going.
[00:10:53.220 --> 00:10:55.780]   Our partner, David, is right here,
[00:10:55.780 --> 00:10:58.540]   and posed a thought-provoking question last year with
[00:10:58.540 --> 00:11:01.860]   his article, AI's $200 billion question.
[00:11:01.860 --> 00:11:05.300]   If you look at the amount of money
[00:11:05.300 --> 00:11:08.300]   that companies are pouring into GPUs right now,
[00:11:08.300 --> 00:11:12.940]   we spent about $50 billion on NVIDIA GPUs just last year.
[00:11:12.940 --> 00:11:15.820]   Everybody's assuming if you build it, they will come.
[00:11:15.820 --> 00:11:17.660]   AI is a field of dreams.
[00:11:17.660 --> 00:11:19.700]   But so far, remember on the previous slide,
[00:11:19.700 --> 00:11:22.060]   we've identified about $3 billion or so of
[00:11:22.060 --> 00:11:25.100]   AI revenue plus change from the Cloud providers.
[00:11:25.100 --> 00:11:26.940]   We've put 50 billion into the ground,
[00:11:26.940 --> 00:11:29.500]   plus energy, plus data center costs and more.
[00:11:29.500 --> 00:11:31.220]   We've gotten three out.
[00:11:31.220 --> 00:11:34.380]   To me, that means the math isn't mathing yet.
[00:11:34.380 --> 00:11:36.540]   The amount of money it takes to build
[00:11:36.540 --> 00:11:38.820]   this stuff has vastly exceeded the amount of money
[00:11:38.820 --> 00:11:40.140]   coming out so far.
[00:11:40.140 --> 00:11:43.900]   So we've got some real problems to fix still.
[00:11:43.900 --> 00:11:46.780]   And even though the usage and--
[00:11:46.780 --> 00:11:48.740]   even though the revenue and the user numbers in AI
[00:11:48.740 --> 00:11:50.740]   look incredible, the usage data says
[00:11:50.740 --> 00:11:52.420]   that we're still really early.
[00:11:52.420 --> 00:11:54.820]   And so if you look at, for example, the ratio of daily
[00:11:54.820 --> 00:11:57.660]   to monthly active users, or if you look at one month
[00:11:57.660 --> 00:12:00.380]   retention, generative AI apps are still
[00:12:00.380 --> 00:12:03.580]   falling far short of their mobile peers.
[00:12:03.580 --> 00:12:06.100]   To me, that is both a problem and an opportunity.
[00:12:06.100 --> 00:12:08.540]   It's an opportunity because AI right now
[00:12:08.540 --> 00:12:12.420]   is a once a week, once a month kind of tinkery phenomenon
[00:12:12.420 --> 00:12:14.260]   for the most part for people.
[00:12:14.260 --> 00:12:16.620]   But we have the opportunity to use AI to create apps
[00:12:16.620 --> 00:12:20.180]   that people want to use every single day of their lives.
[00:12:20.180 --> 00:12:22.780]   When we interview users, one of the biggest reasons
[00:12:22.780 --> 00:12:26.540]   they don't stick on AI apps is the gap between expectations
[00:12:26.540 --> 00:12:27.780]   and reality.
[00:12:27.780 --> 00:12:30.940]   So that magical Twitter demo becomes a disappointment
[00:12:30.940 --> 00:12:33.080]   when you see that the model just isn't smart enough
[00:12:33.080 --> 00:12:36.200]   to reliably do the thing that you asked it to do.
[00:12:36.200 --> 00:12:37.820]   The good thing is with that $50 billion
[00:12:37.820 --> 00:12:40.520]   plus of GPU spend last year, we now
[00:12:40.520 --> 00:12:42.960]   have smarter and smarter base models to build on.
[00:12:42.960 --> 00:12:44.800]   And just in the last month, we've seen Sora.
[00:12:44.800 --> 00:12:45.840]   We've seen Cloud 3.
[00:12:45.840 --> 00:12:47.760]   We saw Grok over the weekend.
[00:12:47.760 --> 00:12:49.920]   And so as the level of intelligence of the baseline
[00:12:49.920 --> 00:12:52.320]   rises, we should expect AI's product market fit
[00:12:52.320 --> 00:12:53.320]   to accelerate.
[00:12:53.320 --> 00:12:55.640]   So unlike in some markets where the future of the market
[00:12:55.640 --> 00:12:57.840]   is very unclear, the good thing about AI
[00:12:57.840 --> 00:13:00.160]   is you can draw a very clear line to how those apps will
[00:13:00.160 --> 00:13:03.720]   get predictably better and better.
[00:13:03.720 --> 00:13:05.480]   Let's remember that success takes time.
[00:13:05.480 --> 00:13:08.600]   We said this at last year's AI Ascent, and we'll say it again.
[00:13:08.600 --> 00:13:12.800]   If you look at the iPhone, some of the first apps in the V1
[00:13:12.800 --> 00:13:15.640]   of the App Store were the beer drinking app or the lightsaber
[00:13:15.640 --> 00:13:19.760]   app or the flip cup app or the flashlight--
[00:13:19.760 --> 00:13:22.040]   kind of the fun, lightweight demonstrations
[00:13:22.040 --> 00:13:23.480]   of new technology.
[00:13:23.480 --> 00:13:25.920]   Those eventually became either native apps--
[00:13:25.920 --> 00:13:27.960]   AKA the flashlight, et cetera--
[00:13:27.960 --> 00:13:30.060]   or utilities and gimmicks.
[00:13:30.060 --> 00:13:31.920]   The iPhone came out in 2007.
[00:13:31.920 --> 00:13:34.120]   The App Store came out in 2008.
[00:13:34.120 --> 00:13:39.360]   It wasn't until 2010 that you saw Instagram and DoorDash 2013.
[00:13:39.360 --> 00:13:42.720]   So it took time for companies to discover and harness
[00:13:42.720 --> 00:13:45.160]   the net new capabilities of the iPhone in creative ways
[00:13:45.160 --> 00:13:47.080]   that we couldn't just imagine yet.
[00:13:47.080 --> 00:13:50.880]   We think the same thing is playing out in AI.
[00:13:50.880 --> 00:13:52.520]   We think we're already seeing a peek
[00:13:52.520 --> 00:13:55.840]   into what some of those next legendary companies might be.
[00:13:55.840 --> 00:13:58.880]   Here are a few of the ones that have captured our attention
[00:13:58.880 --> 00:14:01.900]   recently, but I think it's much broader than the set of use
[00:14:01.900 --> 00:14:03.340]   cases on this page.
[00:14:03.340 --> 00:14:05.060]   As I mentioned, we think customer support
[00:14:05.060 --> 00:14:07.340]   is one of the first handful of use cases that's really hitting
[00:14:07.340 --> 00:14:09.260]   product market fit in the enterprise.
[00:14:09.260 --> 00:14:10.820]   As I mentioned with the Klarna story,
[00:14:10.820 --> 00:14:12.260]   I don't think that's an exception.
[00:14:12.260 --> 00:14:12.820]   It's the rule.
[00:14:12.820 --> 00:14:14.220]   I think that is the rule.
[00:14:14.220 --> 00:14:17.060]   AI Friendship has been one of the most surprising
[00:14:17.060 --> 00:14:18.340]   applications for many of us.
[00:14:18.340 --> 00:14:20.620]   I think it took a few months of thinking for us
[00:14:20.620 --> 00:14:22.980]   to wrap our heads around.
[00:14:22.980 --> 00:14:26.100]   But I think the user and the usage metrics in this category
[00:14:26.100 --> 00:14:30.160]   imply very strong user love.
[00:14:30.160 --> 00:14:32.620]   And then Horizontal Enterprise Knowledge.
[00:14:32.620 --> 00:14:35.620]   We'll hear more from Glean and Dusk later today.
[00:14:35.620 --> 00:14:37.460]   We think that enterprise knowledge is finally
[00:14:37.460 --> 00:14:40.500]   starting to become unlocked.
[00:14:40.500 --> 00:14:42.000]   So here are some predictions for what
[00:14:42.000 --> 00:14:43.500]   we'll see over the coming year.
[00:14:43.500 --> 00:14:46.920]   Prediction number one, 2024 is the year
[00:14:46.920 --> 00:14:48.900]   that we see real applications take us
[00:14:48.900 --> 00:14:51.920]   from co-pilots that are kind of helpers on the side
[00:14:51.920 --> 00:14:54.180]   and suggest things to you and help you,
[00:14:54.180 --> 00:14:56.540]   to agents that can actually take the human out
[00:14:56.540 --> 00:14:58.180]   of the loop entirely.
[00:14:58.180 --> 00:15:01.140]   AI that feels more like a co-worker than a tool.
[00:15:01.140 --> 00:15:03.780]   We're seeing this start to work in domains like software
[00:15:03.780 --> 00:15:06.040]   engineering, customer service.
[00:15:06.040 --> 00:15:07.820]   And we'll hear more about this topic today.
[00:15:07.820 --> 00:15:09.900]   I think both Andrew Ng and Harrison Chase
[00:15:09.900 --> 00:15:12.540]   are planning to speak on it.
[00:15:12.540 --> 00:15:15.980]   Prediction number two, one of the biggest knocks against LLMs
[00:15:15.980 --> 00:15:17.420]   is that they seem to be parroting
[00:15:17.420 --> 00:15:20.180]   the statistical patterns in text and aren't actually
[00:15:20.180 --> 00:15:22.300]   taking the time to reason and plan through the tasks
[00:15:22.300 --> 00:15:23.460]   at hand.
[00:15:23.460 --> 00:15:26.300]   That's starting to change with a lot of new research,
[00:15:26.300 --> 00:15:29.140]   like inference time compute and gameplay-style value
[00:15:29.140 --> 00:15:30.140]   iteration.
[00:15:30.140 --> 00:15:32.180]   What happens when you give the model the time
[00:15:32.180 --> 00:15:34.380]   to actually think through what to do?
[00:15:34.380 --> 00:15:36.940]   We think that this is a major research
[00:15:36.940 --> 00:15:39.460]   thrust for many of the foundation model companies.
[00:15:39.460 --> 00:15:41.540]   And we expect it to result in AI that's
[00:15:41.540 --> 00:15:45.580]   more capable of higher-level cognitive tasks like planning
[00:15:45.580 --> 00:15:47.300]   and reasoning over the next year.
[00:15:47.300 --> 00:15:49.060]   And we'll hear more about this later today
[00:15:49.060 --> 00:15:52.820]   from Noam Brown of OpenAI.
[00:15:52.820 --> 00:15:55.760]   Prediction number three, we are seeing an evolution
[00:15:55.760 --> 00:15:58.860]   from fun consumer apps or prosumer apps,
[00:15:58.860 --> 00:16:02.180]   where you don't really care if the AI says something
[00:16:02.180 --> 00:16:06.720]   wrong or crazy occasionally, to real enterprise applications,
[00:16:06.720 --> 00:16:08.260]   where the stakes are really high,
[00:16:08.260 --> 00:16:09.900]   like hospitals and defense.
[00:16:09.900 --> 00:16:11.860]   The good thing is that there's different tools
[00:16:11.860 --> 00:16:15.220]   and techniques emerging to help bring these LLMs sometimes
[00:16:15.220 --> 00:16:17.060]   into the 5.9's reliability range,
[00:16:17.060 --> 00:16:19.660]   from RLHF to prompt training to vector databases.
[00:16:19.660 --> 00:16:21.540]   And I'm sure that's something that you guys can
[00:16:21.540 --> 00:16:22.740]   compare notes on later today.
[00:16:22.740 --> 00:16:24.020]   I think a lot of folks in this room
[00:16:24.020 --> 00:16:25.480]   are doing really interesting things
[00:16:25.480 --> 00:16:28.860]   to make LLMs more reliable in production.
[00:16:28.860 --> 00:16:31.060]   And finally, 2024 is the year that we
[00:16:31.060 --> 00:16:33.700]   expect to see a lot of AI prototypes and experiments
[00:16:33.700 --> 00:16:35.300]   go into production.
[00:16:35.300 --> 00:16:36.740]   And what happens when you do that?
[00:16:36.740 --> 00:16:38.380]   That means latency matters.
[00:16:38.380 --> 00:16:39.640]   That means cost matters.
[00:16:39.640 --> 00:16:41.420]   That means you care about model ownership.
[00:16:41.420 --> 00:16:43.300]   You care about data ownership.
[00:16:43.300 --> 00:16:45.180]   And it means we expect the balance of compute
[00:16:45.180 --> 00:16:47.220]   to begin shifting from pre-training over
[00:16:47.220 --> 00:16:48.500]   to inference.
[00:16:48.500 --> 00:16:50.020]   So 2024 is a big year.
[00:16:50.020 --> 00:16:52.220]   There's a lot of pressure and expectations
[00:16:52.220 --> 00:16:53.740]   built into some of these applications
[00:16:53.740 --> 00:16:55.780]   as they transition into production.
[00:16:55.780 --> 00:16:58.980]   And it's really important that we get it right.
[00:16:58.980 --> 00:17:00.940]   With that, I'll transition to Konstantin, who
[00:17:00.940 --> 00:17:04.580]   will help us dream about AI over an even longer time horizon.
[00:17:04.580 --> 00:17:09.460]   [APPLAUSE]
[00:17:09.460 --> 00:17:10.380]   Thank you, Sonia.
[00:17:10.380 --> 00:17:12.340]   And thank you, everyone, for being here today.
[00:17:12.340 --> 00:17:14.860]   Pat just set up the "so what?"
[00:17:14.860 --> 00:17:16.020]   Why is this so important?
[00:17:16.020 --> 00:17:17.700]   Why are we all in the room?
[00:17:17.700 --> 00:17:20.300]   And Sonia just walked us through the "what now?"
[00:17:20.300 --> 00:17:22.260]   Where are we in the state of AI?
[00:17:22.260 --> 00:17:25.700]   This section is going to be about what's next.
[00:17:25.700 --> 00:17:27.700]   We're going to take a step back and think
[00:17:27.700 --> 00:17:29.980]   through what this means in the broader
[00:17:29.980 --> 00:17:34.900]   concept of technology and society at large.
[00:17:34.900 --> 00:17:38.380]   So there are many types of technology revolution.
[00:17:38.380 --> 00:17:42.340]   There are communication revolutions, like telephony.
[00:17:42.340 --> 00:17:44.860]   There are transportation revolutions,
[00:17:44.860 --> 00:17:46.740]   like the locomotive.
[00:17:46.740 --> 00:17:48.940]   There are productivity revolutions,
[00:17:48.940 --> 00:17:52.900]   like the mechanization of food harvest.
[00:17:52.900 --> 00:17:58.340]   We believe that AI is primarily a productivity revolution.
[00:17:58.340 --> 00:18:01.580]   And these revolutions follow a pattern.
[00:18:01.580 --> 00:18:04.020]   It starts with a human with a tool.
[00:18:04.020 --> 00:18:07.860]   That transitions into a human with a machine assistant.
[00:18:07.860 --> 00:18:12.460]   And eventually, that moves into a human with a machine network.
[00:18:12.460 --> 00:18:14.580]   The two predictions that we're going to talk about
[00:18:14.580 --> 00:18:17.340]   both relate to this concept of humans
[00:18:17.340 --> 00:18:19.300]   working with machine networks.
[00:18:19.300 --> 00:18:21.300]   Let's look at a historical example.
[00:18:21.300 --> 00:18:23.700]   The sickle has been around as a tool for the human
[00:18:23.700 --> 00:18:26.300]   for over 10,000 years.
[00:18:26.300 --> 00:18:29.340]   The mechanical reaper, which is a human and a machine assistant,
[00:18:29.340 --> 00:18:33.900]   was invented in 1831, a single machine system
[00:18:33.900 --> 00:18:35.860]   being used by a human.
[00:18:35.860 --> 00:18:39.620]   Today, we live in an era where we have a combine harvester.
[00:18:39.620 --> 00:18:42.540]   The combine harvester is tens of thousands
[00:18:42.540 --> 00:18:48.740]   of machine systems working together as a complex network.
[00:18:48.740 --> 00:18:51.460]   We're starting to use language in AI to describe this.
[00:18:51.460 --> 00:18:54.220]   Language like individual machine participants in the system
[00:18:54.220 --> 00:18:55.340]   might be called an agent.
[00:18:55.340 --> 00:18:57.540]   We're talking about this quite a bit today.
[00:18:57.540 --> 00:18:58.980]   The way that topology and the way
[00:18:58.980 --> 00:19:00.500]   that the information is transferred
[00:19:00.500 --> 00:19:01.980]   between these agents, we're starting
[00:19:01.980 --> 00:19:04.060]   to talk about as reasoning, for example.
[00:19:04.060 --> 00:19:07.260]   In essence, we're creating very complicated layers
[00:19:07.260 --> 00:19:11.220]   of abstraction above the primitives of AI.
[00:19:11.220 --> 00:19:12.660]   I'll talk about two examples today,
[00:19:12.660 --> 00:19:14.900]   two examples that we're experiencing right in front
[00:19:14.900 --> 00:19:16.540]   of us in knowledge work.
[00:19:16.540 --> 00:19:18.300]   The first is software.
[00:19:18.300 --> 00:19:21.140]   So software started off as a very manual process.
[00:19:21.140 --> 00:19:24.580]   Here's Ada Lovelace, who wrote logical programming
[00:19:24.580 --> 00:19:27.380]   with pen and paper, was able to do these computations,
[00:19:27.380 --> 00:19:30.480]   but without the assistant of a machine.
[00:19:30.480 --> 00:19:31.820]   We've been living in an era where
[00:19:31.820 --> 00:19:35.780]   we have significant machine assistants for computation,
[00:19:35.780 --> 00:19:38.020]   not just the computer, but the integrated development
[00:19:38.020 --> 00:19:40.340]   environment, and increasingly more and more technologies
[00:19:40.340 --> 00:19:42.900]   to accelerate development of software.
[00:19:42.900 --> 00:19:45.460]   We're entering a new era in which
[00:19:45.460 --> 00:19:46.820]   these systems are working together
[00:19:46.820 --> 00:19:50.180]   in a complex machine network.
[00:19:50.180 --> 00:19:53.420]   What you see is a series of processes
[00:19:53.420 --> 00:19:56.020]   that are working together in order to produce
[00:19:56.020 --> 00:19:57.740]   complex engineering systems.
[00:19:57.740 --> 00:20:00.060]   And what you would see here is agents working together
[00:20:00.060 --> 00:20:02.020]   to produce code, not one at a time,
[00:20:02.020 --> 00:20:04.260]   but actually in unison and harmony.
[00:20:04.260 --> 00:20:06.000]   The same pattern is being applied
[00:20:06.000 --> 00:20:07.460]   in writing very commonly.
[00:20:07.460 --> 00:20:09.780]   Writing was a human process, human and a tool.
[00:20:09.780 --> 00:20:11.980]   Over time, this has progressed to human and a machine
[00:20:11.980 --> 00:20:13.020]   assistant.
[00:20:13.020 --> 00:20:14.780]   And now we have a human that's actually
[00:20:14.780 --> 00:20:17.440]   leveraging not one, but a network of assistants.
[00:20:17.440 --> 00:20:19.940]   I'll tell you in my own personal workflow,
[00:20:19.940 --> 00:20:22.060]   now any time I call an AI assistant,
[00:20:22.060 --> 00:20:24.940]   I'm not just calling GPT-4, I'm calling Mistral-Large,
[00:20:24.940 --> 00:20:26.140]   I'm calling Cloud-3.
[00:20:26.140 --> 00:20:28.980]   I'm having them work together and also against each other
[00:20:28.980 --> 00:20:30.620]   to have better answers.
[00:20:30.620 --> 00:20:34.260]   This is the future that we're seeing right in front of us.
[00:20:34.260 --> 00:20:34.840]   So what?
[00:20:34.840 --> 00:20:36.140]   What does this type of revolution
[00:20:36.140 --> 00:20:38.380]   mean for everyone in this room, and frankly, everyone
[00:20:38.380 --> 00:20:40.100]   outside of this room?
[00:20:40.100 --> 00:20:44.740]   In cold, hard economic terms, what this means
[00:20:44.740 --> 00:20:47.780]   is significant cost reduction.
[00:20:47.780 --> 00:20:49.540]   So this chart is the number of workers
[00:20:49.540 --> 00:20:53.420]   needed at an S&P 500 company to generate 1 million of revenue.
[00:20:53.420 --> 00:20:54.860]   It's going down rapidly.
[00:20:54.860 --> 00:20:57.700]   We're entering an era where this will continue to decline.
[00:20:57.700 --> 00:20:58.860]   What does that mean?
[00:20:58.860 --> 00:21:01.020]   Faster and fewer.
[00:21:01.020 --> 00:21:03.100]   The good news is it's not so that we can do less.
[00:21:03.100 --> 00:21:04.460]   It's so that we can do more.
[00:21:04.460 --> 00:21:07.080]   And we'll get to that in the next set of predictions.
[00:21:07.080 --> 00:21:09.460]   Also fortunate is all the areas where
[00:21:09.460 --> 00:21:11.660]   we've had this type of progress in the past
[00:21:11.660 --> 00:21:13.100]   have been deflationary.
[00:21:13.100 --> 00:21:15.400]   I'll call out computer software and accessories.
[00:21:15.400 --> 00:21:16.820]   The process of computer software,
[00:21:16.820 --> 00:21:18.820]   because we're constantly building on each other,
[00:21:18.820 --> 00:21:21.300]   has actually gone down in cost over time.
[00:21:21.300 --> 00:21:22.420]   Televisions are also here.
[00:21:22.420 --> 00:21:27.060]   But some of the most important things to our society--
[00:21:27.060 --> 00:21:31.220]   education, college tuition, medical care, housing--
[00:21:31.220 --> 00:21:33.700]   they've gone up far faster than inflation.
[00:21:33.700 --> 00:21:36.220]   And it's perhaps a very happy coincidence
[00:21:36.220 --> 00:21:37.900]   that artificial intelligence is poised
[00:21:37.900 --> 00:21:40.940]   to help drive down costs in these and many other crucial
[00:21:40.940 --> 00:21:42.380]   areas.
[00:21:42.380 --> 00:21:44.840]   So that's the first conclusion about the long-term future
[00:21:44.840 --> 00:21:46.340]   of artificial intelligence.
[00:21:46.340 --> 00:21:49.420]   As a massive cost driver, a productivity revolution
[00:21:49.420 --> 00:21:50.940]   that's going to be able to help us
[00:21:50.940 --> 00:21:52.820]   do more with less in some of the most
[00:21:52.820 --> 00:21:56.340]   critical areas of our society.
[00:21:56.340 --> 00:21:59.940]   The second is related to, what is it really doing?
[00:21:59.940 --> 00:22:02.820]   One year ago on the stage, we had Jensen Huang
[00:22:02.820 --> 00:22:04.860]   make a powerful prediction.
[00:22:04.860 --> 00:22:08.020]   He said that in the future, pixels
[00:22:08.020 --> 00:22:09.500]   are not going to be rendered.
[00:22:09.500 --> 00:22:10.800]   They're going to be generated.
[00:22:10.800 --> 00:22:13.900]   Any given image, even information, will be generated.
[00:22:13.900 --> 00:22:16.020]   What did he mean by this?
[00:22:16.020 --> 00:22:18.340]   Well, as everyone in this room knows,
[00:22:18.340 --> 00:22:21.980]   historically, images have been stored as rote memory.
[00:22:21.980 --> 00:22:25.900]   So let's think about the letter A, ASCII character number 97.
[00:22:25.900 --> 00:22:28.420]   That is stored as a matrix of pixels,
[00:22:28.420 --> 00:22:29.940]   either the presence or absence, if we
[00:22:29.940 --> 00:22:31.780]   use a very simple black and white, presence
[00:22:31.780 --> 00:22:33.900]   or absence of those pixels.
[00:22:33.900 --> 00:22:36.340]   Well, we're entering a period in which we already
[00:22:36.340 --> 00:22:39.300]   are representing concepts, like the letter A,
[00:22:39.300 --> 00:22:42.700]   not as rote storage, not as a presence or absence of pixels,
[00:22:42.700 --> 00:22:45.380]   but as a concept, a multidimensional point.
[00:22:45.380 --> 00:22:47.100]   I mean, the image to think about here
[00:22:47.100 --> 00:22:50.260]   is the concept of an A which is generalizable to any given
[00:22:50.260 --> 00:22:53.560]   format for that letter A. So many different typefaces
[00:22:53.560 --> 00:22:55.240]   in this multidimensional space.
[00:22:55.240 --> 00:22:57.100]   We're sitting at the center.
[00:22:57.100 --> 00:22:58.740]   And where do we go from here?
[00:22:58.740 --> 00:23:00.500]   Well, the powerful thing is the computers
[00:23:00.500 --> 00:23:03.060]   are now starting to understand not just
[00:23:03.060 --> 00:23:05.100]   this multidimensional point, not just how
[00:23:05.100 --> 00:23:07.740]   to take it and render it and generate that image,
[00:23:07.740 --> 00:23:09.420]   like Jensen was talking about.
[00:23:09.420 --> 00:23:11.380]   We are now at the point where we're
[00:23:11.380 --> 00:23:13.900]   going to be able to contextualize that understanding.
[00:23:13.900 --> 00:23:15.660]   The computer is going to understand the A,
[00:23:15.660 --> 00:23:17.780]   be able to render it, understand it's an alphabet,
[00:23:17.780 --> 00:23:19.660]   understand it's an English alphabet,
[00:23:19.660 --> 00:23:22.020]   and understand what that means in the broader context
[00:23:22.020 --> 00:23:23.340]   of this rendering.
[00:23:23.340 --> 00:23:24.780]   Computer is going to look at the word multidimensional
[00:23:24.780 --> 00:23:26.780]   and not even think about the A, but rather
[00:23:26.780 --> 00:23:30.140]   understand the full context of why that's being brought up.
[00:23:30.140 --> 00:23:32.860]   And amazingly, this future is how we think,
[00:23:32.860 --> 00:23:34.180]   how humans think.
[00:23:34.180 --> 00:23:37.540]   No longer are we going to be storing the rote pixels
[00:23:37.540 --> 00:23:38.420]   in a computer memory.
[00:23:38.420 --> 00:23:39.580]   That's not how we think.
[00:23:39.580 --> 00:23:41.180]   I wasn't taught about the letter A
[00:23:41.180 --> 00:23:44.780]   as the presence or absence of a pixel on a page.
[00:23:44.780 --> 00:23:47.540]   Instead, we're going to be thinking about that as a concept.
[00:23:47.540 --> 00:23:49.380]   Powerfully, this is how we've thought about it
[00:23:49.380 --> 00:23:51.180]   philosophically for thousands of years.
[00:23:51.180 --> 00:23:54.300]   Here's my fellow Greek Plato 2,500 years ago,
[00:23:54.300 --> 00:23:56.380]   who said this idea of a platonic form
[00:23:56.380 --> 00:23:59.100]   is what we all ascribe to, are all striving for,
[00:23:59.100 --> 00:24:01.420]   that you have this concept, in this case of a letter A,
[00:24:01.420 --> 00:24:03.340]   or this concept of software engineering
[00:24:03.340 --> 00:24:06.220]   that we actually are able to build a model around.
[00:24:06.220 --> 00:24:07.020]   So what?
[00:24:07.020 --> 00:24:09.180]   Now, we've talked about the second pattern, this idea
[00:24:09.180 --> 00:24:11.220]   that we're going to have generalization inside computing
[00:24:11.220 --> 00:24:11.700]   itself.
[00:24:11.700 --> 00:24:13.180]   What does that mean for each of us?
[00:24:13.180 --> 00:24:15.900]   Well, it's going to mean a lot for company building.
[00:24:15.900 --> 00:24:18.420]   Today, we're already integrating this
[00:24:18.420 --> 00:24:20.380]   into specific processes and KPIs.
[00:24:20.380 --> 00:24:21.900]   Sonia just mentioned how Klarna is
[00:24:21.900 --> 00:24:24.340]   using this in order to accelerate their KPIs
[00:24:24.340 --> 00:24:25.860]   around customer support.
[00:24:25.860 --> 00:24:28.140]   They know that they have certain KPIs that they can drive
[00:24:28.140 --> 00:24:30.300]   towards, and they can have a system that's actually
[00:24:30.300 --> 00:24:32.300]   delivering information, generating great customer
[00:24:32.300 --> 00:24:33.860]   experiences.
[00:24:33.860 --> 00:24:36.740]   Tomorrow-- and this is already happening alongside--
[00:24:36.740 --> 00:24:37.780]   new user interfaces.
[00:24:37.780 --> 00:24:39.300]   That might be a different interface
[00:24:39.300 --> 00:24:42.380]   for how the support is actually being communicated.
[00:24:42.380 --> 00:24:45.000]   And this is what I'm personally incredibly excited about,
[00:24:45.000 --> 00:24:47.860]   is because of this future in which concepts are rendered,
[00:24:47.860 --> 00:24:50.220]   because of this future in which everything is generated,
[00:24:50.220 --> 00:24:51.980]   eventually, the entire company might start
[00:24:51.980 --> 00:24:53.740]   working like a neural network.
[00:24:53.740 --> 00:24:57.300]   Let me break that down in a specific example.
[00:24:57.300 --> 00:24:58.700]   This is a caricature.
[00:24:58.700 --> 00:25:00.580]   As with everything in this presentation,
[00:25:00.580 --> 00:25:02.140]   in reality, everything is continuous.
[00:25:02.140 --> 00:25:03.220]   These are all discrete.
[00:25:03.220 --> 00:25:06.500]   This is a caricature of the customer support process.
[00:25:06.500 --> 00:25:09.220]   You have customer service that has certain KPIs.
[00:25:09.220 --> 00:25:10.820]   These are driven by text-to-voice,
[00:25:10.820 --> 00:25:14.060]   language generation, customer personalization, and the like.
[00:25:14.060 --> 00:25:16.940]   This feeds into subpatterns, subtrees
[00:25:16.940 --> 00:25:17.900]   that you're optimizing.
[00:25:17.900 --> 00:25:19.440]   And eventually, you're actually going
[00:25:19.440 --> 00:25:21.180]   to have a fully connected graph here.
[00:25:21.180 --> 00:25:23.560]   You're actually going to have feedback from the language
[00:25:23.560 --> 00:25:27.700]   generation to the end KPI for the servicing of the customers.
[00:25:27.700 --> 00:25:29.300]   This is going to be, at some point,
[00:25:29.300 --> 00:25:31.960]   a layer of abstraction, where customer support is managed,
[00:25:31.960 --> 00:25:34.540]   optimized, and improved by the neural network.
[00:25:34.540 --> 00:25:36.760]   Now, let's think about unique customers,
[00:25:36.760 --> 00:25:39.980]   another part of the important job of building a business.
[00:25:39.980 --> 00:25:41.540]   Well, again, you have the primitives
[00:25:41.540 --> 00:25:43.740]   of artificial intelligence, from language generation
[00:25:43.740 --> 00:25:46.820]   to a growth engine to add customization and optimization.
[00:25:46.820 --> 00:25:49.140]   This will all feed into each other, once again.
[00:25:49.140 --> 00:25:51.180]   The powerful conclusion here is, eventually,
[00:25:51.180 --> 00:25:53.660]   these layers of abstraction will become
[00:25:53.660 --> 00:25:57.260]   interoperable to the point where the entire company
[00:25:57.260 --> 00:26:00.260]   is able to function like a neural network.
[00:26:00.260 --> 00:26:04.920]   Here comes the rise of the one-person company.
[00:26:04.920 --> 00:26:07.500]   The one-person company is going to enable us not to do less,
[00:26:07.500 --> 00:26:09.260]   but to do more.
[00:26:09.260 --> 00:26:11.300]   More problems can be tackled by more people
[00:26:11.300 --> 00:26:13.740]   to create a better society.
[00:26:13.740 --> 00:26:16.440]   So what's next?
[00:26:16.440 --> 00:26:18.220]   The reality is, the people in the room here
[00:26:18.220 --> 00:26:19.520]   are going to decide what's next.
[00:26:19.520 --> 00:26:22.100]   You are the ones who are building this future.
[00:26:22.100 --> 00:26:24.300]   We personally are very excited about the future,
[00:26:24.300 --> 00:26:26.300]   because we think that AI is positioned
[00:26:26.300 --> 00:26:28.780]   to help drive down costs and increase productivity
[00:26:28.780 --> 00:26:31.740]   in some of the most crucial areas in our society--
[00:26:31.740 --> 00:26:34.200]   better education, healthier populations,
[00:26:34.200 --> 00:26:36.260]   more productive populations.
[00:26:36.260 --> 00:26:38.500]   And that's the purpose of convening this group today.
[00:26:38.500 --> 00:26:39.800]   You all are going to be able to talk about,
[00:26:39.800 --> 00:26:41.740]   how are we able to take our technologies,
[00:26:41.740 --> 00:26:44.300]   abstract away complexity, mundane details,
[00:26:44.300 --> 00:26:46.300]   and actually build something that's much more
[00:26:46.300 --> 00:26:48.120]   powerful for the future?
[00:26:48.120 --> 00:26:50.700]   I'll hand it off to Sonia to introduce our first speaker.
[00:26:50.700 --> 00:26:53.740]   [APPLAUSE]
[00:26:53.740 --> 00:27:03.740]   [BLANK_AUDIO]

