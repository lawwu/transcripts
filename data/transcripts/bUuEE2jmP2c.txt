
[00:00:00.000 --> 00:00:03.040]   All right, everybody, welcome back to your favorite podcast,
[00:00:03.040 --> 00:00:07.840]   the all in podcast. It's Episode 164. I'm down here in Miami,
[00:00:07.840 --> 00:00:12.400]   with me again, of course, the dictator chairman himself from
[00:00:12.400 --> 00:00:17.680]   off Polly hoppity. And the rain man. Yeah, burn baby, David
[00:00:17.680 --> 00:00:22.000]   Sachs. Unfortunately, we had a little bit of a challenge this
[00:00:22.000 --> 00:00:24.120]   week. We don't know where Friedberg is he somewhere lost
[00:00:24.120 --> 00:00:27.600]   in his Apple Vision pros, but he'll be back next week. As you
[00:00:27.600 --> 00:00:30.880]   guys know, I'm incredibly generous with my friends. So I
[00:00:30.880 --> 00:00:35.960]   sent all the besties the Apple Pro goggles. And so these Apple
[00:00:35.960 --> 00:00:40.760]   Pro goggles are amazing. But you bought me a pair of the Apple
[00:00:40.760 --> 00:00:44.120]   Pro. Yeah, we talked about this. Yeah, you guys actually you were
[00:00:44.120 --> 00:00:47.000]   using them. You just forgot. But Friedberg's been using them.
[00:00:47.000 --> 00:00:51.840]   Nobody can find Friedberg right now. Because apparently, he went
[00:00:51.840 --> 00:00:55.720]   to Uranus. I recorded in all of these sacks. What's happening
[00:00:55.720 --> 00:01:01.880]   inside each of our Apple goggles? A vision? Oh, yeah. And
[00:01:01.880 --> 00:01:04.280]   so but yeah, come on. Here they are. We actually took a picture.
[00:01:04.280 --> 00:01:06.640]   I had not take a picture of you wearing them. Do you want to
[00:01:06.640 --> 00:01:09.000]   have this actually want to see what Chamath was doing in his
[00:01:09.000 --> 00:01:12.920]   goggles? Yeah, let's see. I've recorded it. Yeah, look at that.
[00:01:12.920 --> 00:01:16.000]   See, he imagined that he did leg day.
[00:01:16.000 --> 00:01:22.920]   Oh, he's reveling. He's still reveling in that thirst trap
[00:01:22.920 --> 00:01:26.000]   that he posted in the I know but you see those legs. The Apple
[00:01:26.000 --> 00:01:30.000]   Vision Pro Tim can I look at that? Can I say something funny
[00:01:30.000 --> 00:01:34.960]   about this, which is that my legs are actually darker than my
[00:01:34.960 --> 00:01:37.880]   torso and my upper body. It's the weirdest thing. And so you
[00:01:37.880 --> 00:01:40.600]   have it in reverse. But it is true that my my legs are a
[00:01:40.600 --> 00:01:43.760]   different shade than my my trunk and my arms and my body. Okay.
[00:01:43.760 --> 00:01:46.720]   Well, here's sacks. By the way, sacks. You know, he loves his
[00:01:46.720 --> 00:01:48.760]   goggles. Chamath, do you have any interest in seeing what sacks
[00:01:48.760 --> 00:01:52.480]   was doing with his goggles? Oh my god, I can't imagine. There
[00:01:52.480 --> 00:01:59.040]   it is. He was doing the speed run on DJ. Absolutely getting
[00:01:59.040 --> 00:02:02.480]   into saving private Ryan, right? Yeah, that's you. That's you.
[00:02:02.480 --> 00:02:05.000]   You were speed running, saving private Ryan there. Oh, I got
[00:02:05.000 --> 00:02:07.480]   them too. Yes. I but I didn't record myself. I didn't record
[00:02:07.480 --> 00:02:11.000]   myself. I maybe nicked it. Oh, I was in there. Oh, look, what am
[00:02:11.000 --> 00:02:11.600]   I doing?
[00:02:11.600 --> 00:02:20.440]   Rain Man David Sacks.
[00:02:20.440 --> 00:02:26.760]   We open source it to the fans and they've just gone crazy.
[00:02:26.760 --> 00:02:27.720]   Love you guys.
[00:02:27.720 --> 00:02:34.120]   Wait, you're telling me that they didn't have the third or
[00:02:34.120 --> 00:02:37.240]   fourth investor and Uber up but ringing the bell with them at
[00:02:37.240 --> 00:02:38.000]   the original moment.
[00:02:38.000 --> 00:02:43.280]   I could tell you the backstory. I was invited by TK to come to
[00:02:43.280 --> 00:02:48.960]   the ringing of the bell. TK was disinvited. So he was there on
[00:02:48.960 --> 00:02:52.520]   the floor. It was very awkward. And then they didn't have him go
[00:02:52.520 --> 00:02:55.760]   up and ring the bell or be even there when Darwin rang the bell.
[00:02:55.760 --> 00:02:58.840]   It was because it was controversial. They didn't. They
[00:02:58.840 --> 00:03:02.600]   banned him. It was really, it was really sad. It was super
[00:03:02.600 --> 00:03:06.120]   sad. But anyway, everybody, I hope you're enjoying your
[00:03:06.120 --> 00:03:06.520]   story.
[00:03:06.520 --> 00:03:13.040]   I didn't go because he was like, we're gonna have a party. But
[00:03:13.040 --> 00:03:15.400]   we're not going to be able to ring the bell. And it was just
[00:03:15.400 --> 00:03:18.800]   all like very did you go to the party? I didn't. I should have
[00:03:19.120 --> 00:03:21.400]   regret not going. But it was unclear if there was even going
[00:03:21.400 --> 00:03:24.480]   to be a party or TK was going to go because of all the drama. I
[00:03:24.480 --> 00:03:26.920]   don't know if you remember on CNBC, they were like, TK is in
[00:03:26.920 --> 00:03:29.600]   the building, but he's not on the thing. And that became a big
[00:03:29.600 --> 00:03:32.680]   brouhaha. But yeah, so I missed my window.
[00:03:32.680 --> 00:03:36.160]   I mean, if you hadn't known that this was gonna be the big exit
[00:03:36.160 --> 00:03:39.400]   in your life, really the only one, then you would have made
[00:03:39.400 --> 00:03:42.400]   every effort to attend everything, right?
[00:03:42.400 --> 00:03:45.160]   Absolutely. Absolutely. Yeah. I mean, you're still riding on
[00:03:45.160 --> 00:03:50.560]   that. Yeah. PayPal. I was I was talking to somebody about this
[00:03:50.560 --> 00:03:54.880]   the other day, most people's careers you have, like, you
[00:03:54.880 --> 00:03:57.680]   know, it's not like a smooth up to upward trajectory. There's
[00:03:57.680 --> 00:04:00.960]   like, maybe a few pops that you get. You're lucky, actually, if
[00:04:00.960 --> 00:04:03.920]   you get a few, because most people only have one or maybe
[00:04:03.920 --> 00:04:07.080]   two. Yes. It's like a power law. It's like anything else in
[00:04:07.080 --> 00:04:09.680]   venture, right? Absolutely. I'm sure if you think back on like
[00:04:09.680 --> 00:04:12.320]   the big outcomes in your life, it's not like there's one every
[00:04:12.320 --> 00:04:15.880]   year and like some sort of smooth gradient. It's basically
[00:04:15.880 --> 00:04:18.960]   there's like, one, two or three over the course of your entire
[00:04:18.960 --> 00:04:22.560]   career that you remember, right? Yeah, absolutely. Yeah. I mean,
[00:04:22.560 --> 00:04:26.520]   it's it's good. It's good to consider that. Because you have
[00:04:26.520 --> 00:04:30.720]   to enjoy every sandwich, you have to enjoy every day, what
[00:04:30.720 --> 00:04:33.200]   you're doing, because those pops are out of your control. You
[00:04:33.200 --> 00:04:34.920]   don't know when they're going to happen, how they're going to
[00:04:34.920 --> 00:04:39.280]   manifest. So but you guys didn't get these. You didn't get the
[00:04:39.280 --> 00:04:41.480]   goggles, but these goggles came out this week. I don't know if
[00:04:41.480 --> 00:04:43.960]   you saw it. What I will say is at the poker game, three of the
[00:04:43.960 --> 00:04:49.080]   guys were talking about these goggles. Ah, Sammy woke up at
[00:04:49.080 --> 00:04:52.840]   five in the morning on the first day. He was he got them. And
[00:04:52.840 --> 00:04:56.000]   then Kuhn and robo were telling me that they just like bought
[00:04:56.000 --> 00:05:00.440]   them randomly in the next couple of days. And it was civilians,
[00:05:00.440 --> 00:05:02.760]   there was no like waiting in line, they were able to just
[00:05:02.760 --> 00:05:05.480]   order them as what they Yes, but they're civilians. So just to be
[00:05:05.480 --> 00:05:10.200]   clear, like in Silicon Valley, we're kind of like, whatever,
[00:05:10.200 --> 00:05:12.720]   you know, we've we've played with Oculus for so long. But now
[00:05:12.720 --> 00:05:14.880]   these are out. And there's a bunch of demos going around.
[00:05:14.880 --> 00:05:16.440]   This one I thought was interesting. I don't know if you
[00:05:16.440 --> 00:05:19.200]   saw this, but watching a basketball game, it actually is
[00:05:19.200 --> 00:05:21.440]   quite compelling to have all the stats on the screen with you.
[00:05:21.440 --> 00:05:24.360]   And you can kind of move them around. I maybe could see
[00:05:24.360 --> 00:05:27.240]   myself doing this. I don't know. Do you think you would do this?
[00:05:27.240 --> 00:05:28.640]   Watching a game maybe?
[00:05:28.640 --> 00:05:32.360]   So are you actually watching the TV through the goggles? Like
[00:05:32.360 --> 00:05:35.560]   what is real world? And what part is augmented? Obviously,
[00:05:35.560 --> 00:05:39.560]   all the stats are augmented reality. Yeah, this is all self
[00:05:39.560 --> 00:05:42.840]   is, is that that's a stream. That's a stream into the
[00:05:42.840 --> 00:05:46.200]   goggles. Yeah, it's not TV. So you know, I think he's just
[00:05:46.200 --> 00:05:49.840]   putting it on the TV there. But you could literally be outside
[00:05:49.840 --> 00:05:52.880]   on your deck, you could be on an airplane and do this. So that's
[00:05:52.880 --> 00:05:54.920]   like, you can see through the goggles, right? Is that the
[00:05:54.920 --> 00:05:58.360]   idea? It's, you can, if you want to, I think you can still see
[00:05:58.360 --> 00:06:00.360]   through the goggles. Yeah, is the idea. Yeah.
[00:06:00.360 --> 00:06:03.360]   You know that you could you can see the fact that you live in a
[00:06:03.360 --> 00:06:07.000]   tattered apartment without a girlfriend dressed poorly.
[00:06:07.000 --> 00:06:11.880]   You can see your sink, you can see the cupboard being bear
[00:06:11.880 --> 00:06:14.440]   bear, you can see the spoiled milk in your refrigerator,
[00:06:14.440 --> 00:06:17.440]   you're half used bong that you use to soothe yourself to sleep
[00:06:17.440 --> 00:06:20.560]   at night, whatever all of these 20 and 30 year olds do to cope.
[00:06:20.560 --> 00:06:23.640]   You'll see all of that while still being in an immersive
[00:06:23.640 --> 00:06:24.880]   environment. It's amazing. Yes.
[00:06:24.880 --> 00:06:30.560]   I mean, it is so dystopian. I just think like, if you take out
[00:06:30.560 --> 00:06:32.560]   your phone, your spouse is like, what are you doing on your
[00:06:32.560 --> 00:06:35.520]   phone? I can you imagine the audacity of being with your
[00:06:35.520 --> 00:06:37.840]   spouse or your family and be like, Hey, guys, I'll be right
[00:06:37.840 --> 00:06:40.440]   back. And you put the goggles on to watch the Knicks game with
[00:06:40.440 --> 00:06:41.160]   the Warriors.
[00:06:41.160 --> 00:06:44.000]   I mean, I think that's a snap divorce. I don't know.
[00:06:44.000 --> 00:06:49.720]   You said very well about the the Oculus one, which is you had to
[00:06:49.720 --> 00:06:51.760]   turn a phrase, which I really liked. But basically, it's like,
[00:06:51.760 --> 00:06:56.160]   you were very quick to try it. And then there was like a period
[00:06:56.160 --> 00:06:58.400]   and then you lost interest. I think that's just going to be
[00:06:58.400 --> 00:07:02.440]   the key thing with this. And the fact that it costs $3500,
[00:07:02.440 --> 00:07:05.640]   they have to get the price down fast enough for average folks to
[00:07:05.640 --> 00:07:07.920]   want and be able to buy it. Right?
[00:07:07.920 --> 00:07:12.720]   Yeah, I call this experience try the try. Oh, my goodbye. You
[00:07:12.720 --> 00:07:14.920]   try it. You're like, Oh, my God, this is incredible. And then
[00:07:14.920 --> 00:07:17.080]   you're like, we put it in your drawer, you never use it again.
[00:07:17.080 --> 00:07:18.880]   Because there's not an application.
[00:07:18.880 --> 00:07:21.480]   It's really a proof of concept. Look, I think it's a great thing
[00:07:21.480 --> 00:07:24.520]   for innovation that they're starting with this, you know,
[00:07:24.520 --> 00:07:28.120]   like you said, expensive headset that maybe is not that
[00:07:28.120 --> 00:07:31.440]   ergonomic, but eventually it'll come down and the form factor
[00:07:31.440 --> 00:07:34.560]   will be glasses or sunglasses. Facebook. I don't know if the
[00:07:34.560 --> 00:07:37.320]   products out yet. But you see their product where the ray
[00:07:37.320 --> 00:07:41.000]   bands? Yeah, it has the AI built into it. And you can ask it
[00:07:41.000 --> 00:07:43.560]   questions. And it will do computer vision and give you
[00:07:43.560 --> 00:07:46.920]   answers based on what it's seeing. It was a phenomenal
[00:07:46.920 --> 00:07:50.680]   demo. I don't know if that's actually real yet. But do you
[00:07:50.680 --> 00:07:51.400]   see that demo?
[00:07:51.400 --> 00:07:55.200]   Yeah, these are the Facebook Ray Ban glasses. And I do think
[00:07:55.200 --> 00:07:58.400]   these are met as smart glasses. They work particularly well
[00:07:58.400 --> 00:08:01.400]   taking pictures and sharing them on Instagram. So they're kind
[00:08:01.400 --> 00:08:04.640]   of single function. He you know, how Zuckerberg is he? He cribbed
[00:08:04.640 --> 00:08:08.720]   what Evan Spiegel did a couple years ago with Snapchat, he put
[00:08:08.720 --> 00:08:11.240]   out a demo that was a little different. The demo was like he
[00:08:11.240 --> 00:08:14.480]   was in his closet. He was wearing this and he had picked
[00:08:14.480 --> 00:08:17.600]   out a shirt or something. And that's like, give me, you know,
[00:08:17.600 --> 00:08:20.120]   tell me what I should match this with. Yeah, what goes with a
[00:08:20.120 --> 00:08:22.720]   gray shirt that I've worn for the last 14 years.
[00:08:22.720 --> 00:08:27.600]   You guys see this thing where they all had to testify in front
[00:08:27.600 --> 00:08:30.000]   of the Senate? We might as well, I guess we'll just jump right to
[00:08:30.000 --> 00:08:33.920]   that. It was like a public flogging. Yeah, once again, a
[00:08:33.920 --> 00:08:36.080]   public, public flogging. We'll just jump to it real quick,
[00:08:36.080 --> 00:08:38.360]   since we didn't want to go too deep on that one. But
[00:08:38.360 --> 00:08:42.560]   Josh Hawley made Zuck turn around and apologize to, to
[00:08:42.560 --> 00:08:44.760]   people in the audience. It was really intense.
[00:08:44.760 --> 00:08:47.640]   So this is the name of this hearing was big tech and online
[00:08:47.640 --> 00:08:50.200]   child sexual exploitation crisis, Zuckerberg, he was
[00:08:50.200 --> 00:08:54.480]   questioned, along with the CEO of tik tok, discord x and snap.
[00:08:55.440 --> 00:09:01.120]   But obviously, this is all around. Kids online safety, and
[00:09:01.120 --> 00:09:05.800]   also section 230, which I think the senators are, this is one of
[00:09:05.800 --> 00:09:09.080]   the few bipartisan moments, I think they're honing in on it.
[00:09:09.080 --> 00:09:12.800]   Yeah, they realize this is kind of like a way to take a run at
[00:09:12.800 --> 00:09:15.280]   this. They're taking a run at it for sure. They realize it's a
[00:09:15.280 --> 00:09:17.840]   winning ticket. But let's just play the clip. And then I'll get
[00:09:17.840 --> 00:09:19.400]   your thoughts, Saxon and Jamal.
[00:09:19.400 --> 00:09:21.800]   Let me ask you this. There's families of victims here today.
[00:09:21.800 --> 00:09:26.240]   Have you apologized to the victims? I would you like to do
[00:09:26.240 --> 00:09:29.280]   so now? Well, they're here. You're on national television.
[00:09:29.280 --> 00:09:32.400]   Would you like now to apologize to the victims who have been
[00:09:32.400 --> 00:09:35.440]   harmed by your product? Show them the pictures. Would you
[00:09:35.440 --> 00:09:37.720]   like to apologize for what you've done to these good
[00:09:37.720 --> 00:09:38.240]   people?
[00:09:38.240 --> 00:09:44.840]   I'm sorry, everything that you've all gone through. Terrible.
[00:09:44.840 --> 00:09:47.720]   No one should have to go through the things that your families
[00:09:47.720 --> 00:09:51.640]   have have suffered. And this is why we invest so much and are
[00:09:51.640 --> 00:09:56.000]   going to continue doing industry leading efforts to make sure
[00:09:56.000 --> 00:09:59.320]   that no one has to go through the types of things that your
[00:09:59.320 --> 00:10:00.560]   families have had to suffer.
[00:10:00.560 --> 00:10:05.120]   Excellent, powerful moment. And for Zuckerberg to get up and
[00:10:05.120 --> 00:10:07.560]   actually face the parents, he turned around, he faced the
[00:10:07.560 --> 00:10:11.240]   present very dramatic moment. And he apologized, Ned, you
[00:10:11.240 --> 00:10:16.000]   respect him for for doing that. And that was like a powerful
[00:10:16.000 --> 00:10:17.880]   moment as well. And where does this all wind up?
[00:10:17.880 --> 00:10:21.080]   This was a kangaroo court. I mean, this was basically all
[00:10:21.080 --> 00:10:24.800]   theatrics. This is basically bipartisan moral panic, where
[00:10:24.800 --> 00:10:27.680]   all these senators are basically grandstanding. And these are the
[00:10:27.680 --> 00:10:30.080]   same types of accusations that we've been hearing for years.
[00:10:30.080 --> 00:10:32.720]   Remember, this goes back to the whole Frances Hogan claims,
[00:10:32.720 --> 00:10:35.720]   where she says that Facebook wasn't doing enough to prevent
[00:10:35.720 --> 00:10:40.720]   various kinds of online harms. And I think that we're going to
[00:10:40.720 --> 00:10:42.680]   regret where this all leads, because where it's going to
[00:10:42.680 --> 00:10:45.640]   lead if they do repeal section 230 is towards greater
[00:10:45.640 --> 00:10:49.200]   censorship, all these companies are going to spend even more
[00:10:49.400 --> 00:10:54.800]   resources restricting what we can say and hear online, which
[00:10:54.800 --> 00:10:59.160]   is not the right direction. Listen, do some harms occur
[00:10:59.160 --> 00:11:02.640]   online? Yes. Do I believe that Facebook is taking substantial
[00:11:02.640 --> 00:11:05.680]   measures to stop them? Yes. I mean, but edge cases are always
[00:11:05.680 --> 00:11:09.280]   going to get through. When you're operating at that kind of
[00:11:09.280 --> 00:11:12.800]   scale, there are going to be these edge cases of kids who got
[00:11:12.800 --> 00:11:16.960]   harassed or content that shouldn't have getting through.
[00:11:17.240 --> 00:11:20.560]   It's just part of the fact that the internet operates a gigantic
[00:11:20.560 --> 00:11:23.640]   scale. And these harms have always been out there. I think
[00:11:23.640 --> 00:11:26.520]   that these companies do their best to try and stop them. But
[00:11:26.520 --> 00:11:29.880]   they're always going to get through and you can't make every
[00:11:29.880 --> 00:11:34.320]   aspect of our society perfectly safe and harm free. Somehow we
[00:11:34.320 --> 00:11:38.480]   have this expectation that we can eliminate 100% of every harm
[00:11:38.480 --> 00:11:41.320]   that occurs. And I do think that these online companies have been
[00:11:41.320 --> 00:11:44.320]   unfairly picked on in a sense. I mean, if you're going to talk
[00:11:44.320 --> 00:11:47.680]   about these types of harms, why aren't you targeting the music
[00:11:47.680 --> 00:11:50.800]   industry for all their incendiary lyrics that basically
[00:11:50.800 --> 00:11:54.920]   encourage all sorts of violent or sexist behavior? Why don't
[00:11:54.920 --> 00:11:57.320]   you target the advertising industry for creating
[00:11:57.320 --> 00:12:01.200]   unrealistic body image expectations? Why don't you
[00:12:01.200 --> 00:12:05.560]   target the Kardashians for setting unrealistic expectations
[00:12:05.560 --> 00:12:09.680]   around image? And you could go on down the list? I mean, why
[00:12:09.680 --> 00:12:13.000]   don't you target Hollywood for releasing a show like euphoria,
[00:12:13.000 --> 00:12:16.600]   which is a hit? It seems to me that the problem in our culture
[00:12:16.600 --> 00:12:19.360]   is not coming from the edge cases is coming from the
[00:12:19.360 --> 00:12:23.760]   mainstream entertainment that is fully allowed and is popular
[00:12:23.760 --> 00:12:27.120]   and is our hit shows and hit records and hit products. I
[00:12:27.120 --> 00:12:30.640]   mean, that's where the toxic pollution is coming from in our
[00:12:30.640 --> 00:12:33.880]   culture. So to turn around and now blame the online companies
[00:12:33.880 --> 00:12:36.400]   for creating all of this, I think is just anything basically
[00:12:36.400 --> 00:12:39.240]   they're being scapegoated. I mean, again, this is a moral
[00:12:39.240 --> 00:12:39.640]   panic.
[00:12:39.640 --> 00:12:42.640]   Chama, do you think it's a moral panic? Or, you know, there have
[00:12:42.640 --> 00:12:48.080]   been statistics and studies done about what is viral on social
[00:12:48.080 --> 00:12:51.400]   media, the algorithms targeting users, the addictive nature of
[00:12:51.400 --> 00:12:53.520]   it, you spoke earlier about the addictive nature of just
[00:12:53.520 --> 00:12:56.720]   gamification on watches, social media is a little bit different
[00:12:56.720 --> 00:12:59.960]   than music, and some of these other things, because they have
[00:12:59.960 --> 00:13:03.120]   these algorithms to increase watch time and engagement. So I
[00:13:03.120 --> 00:13:05.200]   think that's what the other side would say. What do you say?
[00:13:05.200 --> 00:13:06.840]   What do you say? Come on, where do you stand on this?
[00:13:06.840 --> 00:13:10.520]   Let me just give a coda to a couple things that Zack said. It
[00:13:10.520 --> 00:13:14.640]   is true that we've taken turns attacking other forms of media
[00:13:14.640 --> 00:13:16.880]   when they were ascending in their popularity. So in the
[00:13:16.880 --> 00:13:21.880]   1990s, if you guys remember, the politicians and their censorship
[00:13:21.880 --> 00:13:26.760]   attempts around gangster rap, and NWA and to life crew and
[00:13:26.760 --> 00:13:27.840]   certain songs,
[00:13:27.840 --> 00:13:29.640]   Al Gore's wife, right? What was her name?
[00:13:29.640 --> 00:13:30.360]   Tipper Gore.
[00:13:30.360 --> 00:13:33.120]   tirade against rap lyrics.
[00:13:33.120 --> 00:13:36.880]   What was the NWA song, you know, the police, that whole thing
[00:13:36.880 --> 00:13:41.120]   just set off a huge fear about people potentially, David, be
[00:13:41.120 --> 00:13:43.080]   motivated to kill cops or something, right?
[00:13:43.080 --> 00:13:46.520]   In the 80s, there was a trial Judas Priest went on trial,
[00:13:46.520 --> 00:13:49.480]   right? Because if you played one of their records backwards,
[00:13:49.480 --> 00:13:52.520]   supposedly promoted devil worship, devil worship. And I
[00:13:52.520 --> 00:13:55.360]   don't know who's playing records backwards. But if you did, then
[00:13:55.360 --> 00:13:58.360]   it promoted devil worship. I think a kid committed suicide
[00:13:58.360 --> 00:14:00.800]   and say, basically prosecuted Judas Priest for it.
[00:14:00.800 --> 00:14:05.920]   So that's comment number one, which is, this is not new. And
[00:14:05.960 --> 00:14:08.600]   the reason why social media is in the crosshairs is because
[00:14:08.600 --> 00:14:15.120]   instead of having this really diverse ecosystem of many small
[00:14:15.120 --> 00:14:18.800]   players, you have three or four folks. And so it's easier to
[00:14:18.800 --> 00:14:22.120]   bring them up on stage and sort of pillory them. Second is I
[00:14:22.120 --> 00:14:24.240]   actually thought that Zuck had a lot of moral clarity, because
[00:14:24.240 --> 00:14:27.120]   it's like, that's a tough position to be in. And the fact
[00:14:27.120 --> 00:14:29.440]   that he had the courage to turn around and actually apologize to
[00:14:29.440 --> 00:14:32.360]   those people shows he's trying to do the right thing. But the
[00:14:32.360 --> 00:14:36.800]   reality is, and sacks is right. If you apply a very, very small
[00:14:36.800 --> 00:14:40.160]   error rate to an incredibly large number, so they have a
[00:14:40.160 --> 00:14:42.760]   network of three and a half billion people monthly, right,
[00:14:42.760 --> 00:14:46.400]   or daily, or whatever thing is, even if you say that there's
[00:14:46.400 --> 00:14:51.440]   one 10th of 1% of an error rate, meaning things that are
[00:14:51.440 --> 00:14:55.480]   unintended, well, that's 3 million unintended consequences,
[00:14:55.480 --> 00:14:58.600]   right? That's a lot of unintended consequences. And so
[00:14:59.120 --> 00:15:02.520]   there's this massive law of large numbers at play. So what
[00:15:02.520 --> 00:15:07.440]   what do we do, I guess, is the question. And I think that there
[00:15:07.440 --> 00:15:14.640]   is enough knowledge that we have to know that the ability for a
[00:15:14.640 --> 00:15:20.240]   35 year old to use certain products today is very different
[00:15:20.240 --> 00:15:23.240]   than the ability for a 12 year old to use that same product
[00:15:23.240 --> 00:15:26.400]   because of where they are physiologically. Right. I think
[00:15:26.400 --> 00:15:29.160]   we all know that to be scientifically true, on the
[00:15:29.160 --> 00:15:31.840]   dimension of many products. And I think what we need to decide
[00:15:31.840 --> 00:15:36.400]   as a society is whether software and electronic products fall
[00:15:36.400 --> 00:15:39.720]   into that categorization. And if so, what does it mean? So in the
[00:15:39.720 --> 00:15:44.400]   case of China, they mandate top down what products can be used,
[00:15:44.400 --> 00:15:49.040]   and how many hours you can use it for video games are referring
[00:15:49.040 --> 00:15:52.560]   to you. Yeah. And David's right, which is that if we go there,
[00:15:52.560 --> 00:15:56.400]   and we rewrite the law, then there's going to be a different
[00:15:56.400 --> 00:15:59.400]   set of unintended consequences that's going to create, I think,
[00:15:59.400 --> 00:16:05.040]   a much poorer business landscape, frankly, to innovate
[00:16:05.040 --> 00:16:06.080]   and a bunch of other things.
[00:16:06.080 --> 00:16:09.640]   And building on your comments, there's clearly an age at which
[00:16:09.640 --> 00:16:14.320]   kids can shouldn't be on these systems and an age where, you
[00:16:14.320 --> 00:16:17.880]   know, maybe with some guidance, they can. Yeah, you want to add
[00:16:17.880 --> 00:16:18.520]   something? Yeah.
[00:16:18.520 --> 00:16:21.840]   And then I think the third thing is around the section 230 thing
[00:16:21.840 --> 00:16:26.000]   itself. I think that sacks, I'll give you a slightly different
[00:16:26.000 --> 00:16:30.520]   take. I don't think that the section 230 rewrite is going to
[00:16:30.520 --> 00:16:34.520]   be broad and sweeping. What I noticed from a bipartisan
[00:16:34.520 --> 00:16:37.880]   perspective, by both the Democrats and the Republicans is
[00:16:37.880 --> 00:16:43.280]   that the one single narrow issue that they all seem to align on
[00:16:43.280 --> 00:16:49.320]   is not necessarily about all of the different rules around
[00:16:49.320 --> 00:16:55.080]   censorship, but that the lack of liability for these folks should
[00:16:55.080 --> 00:16:58.960]   be relieved. And I think that if you were to write a narrow
[00:16:58.960 --> 00:17:02.680]   amendment to section 230, that said that these social media
[00:17:02.680 --> 00:17:05.520]   companies or other organizations that had certain characteristics
[00:17:05.520 --> 00:17:09.360]   were more liable where today they have no liability. I'm not
[00:17:09.360 --> 00:17:13.160]   saying that it's right. But my read of the temperature in that
[00:17:13.160 --> 00:17:18.200]   room was that that is the very narrow change in section 230
[00:17:18.200 --> 00:17:21.600]   that I think they all seem to want to make. And so that seems
[00:17:21.600 --> 00:17:24.560]   like a very likely thing that will happen in the next two or
[00:17:24.560 --> 00:17:25.080]   three years
[00:17:25.080 --> 00:17:28.560]   unpack that for the audience who might not know how they would do
[00:17:28.560 --> 00:17:31.600]   that section 230 says, if you're a publisher, you're a common
[00:17:31.600 --> 00:17:34.800]   carrier, you're not responsible for people post on your your
[00:17:34.800 --> 00:17:38.880]   system, blog, web host, or social media company, but where
[00:17:38.880 --> 00:17:41.880]   the social media companies move from being just a common
[00:17:41.880 --> 00:17:46.000]   carrier, you know, like paper might be or a website hosting
[00:17:46.000 --> 00:17:50.080]   company like WordPress, or Squarespace is when they flip
[00:17:50.080 --> 00:17:52.920]   over and they have an algorithm, and then they start picking and
[00:17:52.920 --> 00:17:55.280]   choosing. So once you start doing editorial, like the New
[00:17:55.280 --> 00:17:58.200]   York Times, and you have editors, then you're liable. If
[00:17:58.200 --> 00:18:00.680]   you're CNN, you're liable. If you're Fox, as we saw in the
[00:18:00.680 --> 00:18:03.600]   Dominion case, that's where the liability comes in. So I guess
[00:18:03.600 --> 00:18:07.000]   the question to you, sex is, you know, at the end of the day, now
[00:18:07.000 --> 00:18:10.160]   that we've seen these things at scale, is there not an argument
[00:18:10.160 --> 00:18:12.320]   that when you start editorializing through an
[00:18:12.320 --> 00:18:15.240]   algorithm, and you start promoting certain content, that
[00:18:15.240 --> 00:18:17.760]   you have some level of responsibility, like Fox News,
[00:18:17.760 --> 00:18:20.800]   CNN, or the New York Times has, where would you stand on that
[00:18:20.800 --> 00:18:23.920]   issue, some liability, if you're picking winners and losers in
[00:18:23.920 --> 00:18:26.320]   terms of what gets promoted in the system?
[00:18:26.320 --> 00:18:29.520]   Well, apparently, I'm the last person in America who thinks
[00:18:29.520 --> 00:18:32.160]   that section 230 was a good idea and a visionary piece of
[00:18:32.160 --> 00:18:35.800]   legislation that actually enabled the creation of user
[00:18:35.800 --> 00:18:39.240]   generated content platforms. Just to kind of slightly modify
[00:18:39.240 --> 00:18:42.440]   your description of how it works, I would analogize it to a
[00:18:42.440 --> 00:18:45.160]   newsstand, where there's magazines on the newsstand,
[00:18:45.160 --> 00:18:47.360]   their publishers, and then there's the newsstand itself,
[00:18:47.360 --> 00:18:53.400]   which the distributor, if a magazine engages in defamation,
[00:18:53.400 --> 00:18:56.920]   they're liable for it. But the newsstand is not the newsstand
[00:18:56.920 --> 00:18:59.960]   can't be sued. So the question is, when you have these massive
[00:18:59.960 --> 00:19:03.080]   user generated content platforms, are they operating as
[00:19:03.080 --> 00:19:06.600]   a publisher or as a distributor? And I think what section 230
[00:19:06.600 --> 00:19:09.560]   make clear is look, if you don't write the content, if the
[00:19:09.560 --> 00:19:14.320]   content is generated by users, your distributor, and that is, I
[00:19:14.320 --> 00:19:18.200]   believe, the better analogy to make for these huge UGC
[00:19:18.200 --> 00:19:22.400]   platforms. Now, at the same time, what section 230 said, is
[00:19:22.400 --> 00:19:26.680]   that if you take good Samaritan actions to reduce things like
[00:19:26.680 --> 00:19:29.480]   sex and violence on your platforms, then we won't make
[00:19:29.480 --> 00:19:33.080]   you liable. Because what happens in a lot of cases is that you
[00:19:33.080 --> 00:19:37.080]   can waive your protection legally by basically getting
[00:19:37.080 --> 00:19:40.720]   involved. And so the legislation didn't want to deter these
[00:19:40.720 --> 00:19:44.520]   platforms for taking again, good Samaritan steps. I think it's a
[00:19:44.520 --> 00:19:47.920]   pretty good combination of legislation. And that's what you
[00:19:47.920 --> 00:19:50.760]   see right now is that Zuckerberg doesn't want to let these edge
[00:19:50.760 --> 00:19:53.320]   cases through, I actually believe that they are taking
[00:19:53.320 --> 00:19:55.400]   huge efforts at scale,
[00:19:55.400 --> 00:19:58.440]   they have 40,000 people to give him some credit. There's 40,000
[00:19:58.440 --> 00:19:59.600]   people moderating stuff. That's
[00:19:59.600 --> 00:20:02.120]   these are edge cases that get through. And by the way, you
[00:20:02.120 --> 00:20:05.000]   have to wonder where were the parents when all this stuff
[00:20:05.000 --> 00:20:07.440]   happened? I mean, they're acting like they're victims in the
[00:20:07.440 --> 00:20:10.080]   audience. And I'm sorry for their particular cases. But at
[00:20:10.080 --> 00:20:13.160]   the end of the day, we do need the parents to step up here. If
[00:20:13.160 --> 00:20:16.160]   we want to have social media at scale at all, the parents have
[00:20:16.160 --> 00:20:18.360]   to play a more active role. But in any event, to go back to
[00:20:18.360 --> 00:20:22.000]   section 230. I just think that Republicans in particular are
[00:20:22.000 --> 00:20:26.760]   going to really regret getting rid of section 230. Because it's
[00:20:26.760 --> 00:20:28.200]   only going to lead to more censorship.
[00:20:28.200 --> 00:20:31.040]   I think what they're going to do, if I had to bet is that
[00:20:31.040 --> 00:20:36.040]   they're going to write a very narrow amendment to that law.
[00:20:36.040 --> 00:20:39.920]   And during some budget process or some other thing where you
[00:20:39.920 --> 00:20:43.560]   have a big Christmas tree bill, this will get in there. And I
[00:20:43.560 --> 00:20:47.200]   think it will have bipartisan support that effectively removes
[00:20:47.200 --> 00:20:50.800]   the liability protection that these companies have. I
[00:20:50.800 --> 00:20:54.040]   have a small change. That's the entirety of section 230.
[00:20:54.040 --> 00:20:57.760]   I think like these companies will not be able to use that
[00:20:57.760 --> 00:21:00.320]   that's a massive change. Listen, there are plaintiffs lawyers,
[00:21:00.640 --> 00:21:04.640]   the the plaintiffs lawyers bar, you know, the trial lawyers bar
[00:21:04.640 --> 00:21:08.200]   is salivating over the possibility that would happen.
[00:21:08.200 --> 00:21:10.560]   That's why this is going to happen. You know, wait, this is
[00:21:10.560 --> 00:21:11.080]   how America
[00:21:11.080 --> 00:21:15.240]   injury or they have personal injury lawsuits, lawsuits lined
[00:21:15.240 --> 00:21:18.120]   up in every jurisdiction United States. And here's the thing is
[00:21:18.120 --> 00:21:22.480]   because Facebook and all these other sites operate, you know,
[00:21:22.480 --> 00:21:26.520]   across the entire nation and across the entire world, they
[00:21:26.520 --> 00:21:30.280]   can be sued in every single jurisdiction. If you allow these
[00:21:30.280 --> 00:21:31.120]   types of lawsuits,
[00:21:31.120 --> 00:21:34.280]   okay, Chamath, you go, then I'm gonna get my position and move
[00:21:34.280 --> 00:21:37.080]   on. I'm going to say this in as unopinionated as a way as
[00:21:37.080 --> 00:21:41.360]   possible, whether we like it or not. There's an element of
[00:21:41.360 --> 00:21:46.840]   American capitalism that takes companies through seasons. And
[00:21:46.840 --> 00:21:49.400]   there are seasons where you're growing. And then there are
[00:21:49.400 --> 00:21:51.920]   seasons where you're over earning. And then there are
[00:21:51.920 --> 00:21:56.880]   seasons where if it is possible, the machinery, if you see that
[00:21:56.880 --> 00:22:00.320]   you are being you are over earning for a long time, the
[00:22:00.320 --> 00:22:03.520]   machinery of the economy comes and kind of pulls you back down
[00:22:03.520 --> 00:22:04.080]   to earth.
[00:22:04.080 --> 00:22:07.880]   You've won too much. And you're perceived as too powerful. Yeah.
[00:22:07.880 --> 00:22:11.720]   And I'm not saying this. Whether or not it's right. I'm just
[00:22:11.720 --> 00:22:15.240]   saying that if you look back in history, these chapters have
[00:22:15.240 --> 00:22:19.120]   been written umpteen times. And I and I think David, what you
[00:22:19.120 --> 00:22:23.120]   said is the absolute single most important thing if you had to
[00:22:23.120 --> 00:22:27.920]   figure out where this was going to go, is exactly that the
[00:22:27.920 --> 00:22:31.960]   plaintiff's lawyers, the class action lawsuits, the amount of
[00:22:31.960 --> 00:22:37.160]   money that they think they can extract. And they compare it to
[00:22:37.160 --> 00:22:39.920]   the amount of money that they were able to extract in two
[00:22:39.920 --> 00:22:44.840]   different kinds of cases. One was tobacco. And then the second
[00:22:44.840 --> 00:22:48.920]   was pharma. And I think that they look at this class of app.
[00:22:50.320 --> 00:22:54.320]   And the lack of empathy or the lack of popularity that the
[00:22:54.320 --> 00:22:59.240]   leaders of these companies have in Washington as a reason why
[00:22:59.240 --> 00:23:02.440]   they will probably be able to get this done to create this
[00:23:02.440 --> 00:23:05.680]   again, I'm not saying I think that's good. I'm saying that I
[00:23:05.680 --> 00:23:09.320]   think it's likely. And I think when that does happen, you will
[00:23:09.320 --> 00:23:12.440]   see a replay. Again, it'll be slightly different in terms of
[00:23:12.440 --> 00:23:15.880]   how it plays out. But exactly the kinds of plaintiff's lawsuits
[00:23:15.880 --> 00:23:19.320]   that we saw in pharma, and in tobacco, and I think it's going
[00:23:19.320 --> 00:23:22.480]   to play out here. And David, you're right, that hearing to
[00:23:22.480 --> 00:23:24.240]   me, was a setup for that.
[00:23:24.240 --> 00:23:28.360]   Yeah. And if you if you look at this through that lens, there
[00:23:28.360 --> 00:23:32.400]   will be some sort of negotiation. And it might be age
[00:23:32.400 --> 00:23:35.560]   because when you look at this, really what Americans are upset
[00:23:35.560 --> 00:23:38.400]   about is the impact this is having on kids. We have a limit
[00:23:38.400 --> 00:23:41.400]   for the age of smoking, vaping, etc. And when these things
[00:23:41.400 --> 00:23:44.480]   happen, I think an easy concession that Zuckerberg and
[00:23:44.480 --> 00:23:47.040]   others will make is hey, these products will be for 16 years
[00:23:47.040 --> 00:23:50.720]   old and up. That's my that's the age I think it's appropriate
[00:23:50.720 --> 00:23:52.400]   15 or 16 seems to be
[00:23:52.400 --> 00:23:55.400]   well, he also said, by the way, Jason, to your point, Lindsey
[00:23:55.400 --> 00:23:57.920]   Graham was the one that brought this up. And Lindsey Graham made
[00:23:57.920 --> 00:24:01.320]   the connection to tobacco and also to firearms. Yeah. And then
[00:24:01.320 --> 00:24:03.760]   mark at some point in there basically said, Well, listen,
[00:24:03.760 --> 00:24:07.680]   like, let's look at Apple and Google, we should expect them to
[00:24:07.680 --> 00:24:09.720]   do the actual age verification on us.
[00:24:09.720 --> 00:24:12.520]   Right, because they have the devices and they have credit
[00:24:12.520 --> 00:24:15.400]   cards, etc. That's actually a very reasonable thing for
[00:24:15.400 --> 00:24:17.360]   Americans to come to you. I think that breaks down a little
[00:24:17.360 --> 00:24:20.040]   bit sacks in your argument. And listen, there's no perfect
[00:24:20.040 --> 00:24:24.680]   analogies here. But if there was a repeated offense of a magazine
[00:24:24.680 --> 00:24:28.720]   on a newsstand, for example, if there was some magazine that had
[00:24:28.720 --> 00:24:31.840]   underage, you know, an adult magazine that underage kids in
[00:24:31.840 --> 00:24:35.600]   it, and people knew that and a newsstand continued to publish
[00:24:35.600 --> 00:24:38.320]   it, they would have liability for trafficking in child
[00:24:38.320 --> 00:24:41.480]   pornography or whatever it happens to be. And so the
[00:24:41.480 --> 00:24:43.760]   newsstand does get some liability. So there's again, no
[00:24:43.760 --> 00:24:46.040]   perfect analogies here. But I think
[00:24:46.040 --> 00:24:48.280]   Facebook and all these other sites are trying to remove the
[00:24:48.280 --> 00:24:50.480]   child porn or whatever. I don't think much that gets through at
[00:24:50.480 --> 00:24:54.600]   all. You know, I think maybe you have a better argument. And
[00:24:54.600 --> 00:24:57.000]   there is the argument that people make is that because of
[00:24:57.000 --> 00:24:59.320]   the feed, they're making editorial judgments. And that's
[00:24:59.320 --> 00:25:01.880]   publishing, not distributing. However, my counter arguments to
[00:25:01.880 --> 00:25:04.480]   that is that the feed just gives you more what you want. I mean,
[00:25:04.480 --> 00:25:06.440]   it just looks at what you're clicking on what you're viewing
[00:25:06.440 --> 00:25:08.320]   the time you're spending, and they just give you more of that.
[00:25:08.320 --> 00:25:11.320]   I don't think it's editorializing. Now, back to
[00:25:11.320 --> 00:25:14.120]   Jamal's point about this is the way things are headed, that may
[00:25:14.120 --> 00:25:17.200]   well be right, but I think we're gonna regret it. I mean, first
[00:25:17.200 --> 00:25:19.720]   of all, the Democrats interest that one of their biggest
[00:25:19.720 --> 00:25:23.680]   donors is the trial lawyers bar, and they generally will support
[00:25:23.680 --> 00:25:27.240]   any legislation that opens up the causes of actions. And
[00:25:27.240 --> 00:25:30.200]   that's where this is headed. And what's going to happen is if
[00:25:30.200 --> 00:25:33.600]   they get rid of Section 230, is that every time there's an
[00:25:33.600 --> 00:25:38.480]   alleged harm that occurs every time a kid gets bullied or beat
[00:25:38.480 --> 00:25:41.480]   up in school, every time something goes wrong in their
[00:25:41.480 --> 00:25:45.240]   life, they're going to try and in it on social media and try and
[00:25:45.240 --> 00:25:49.040]   show that they imbibe something on social media that led them
[00:25:49.040 --> 00:25:52.960]   down this dark path. And these types of companies are going to
[00:25:52.960 --> 00:25:56.920]   get sued in every jurisdiction in America. Recently, we've seen
[00:25:56.920 --> 00:26:01.440]   huge judgments related to defamation, where if you have,
[00:26:01.440 --> 00:26:05.400]   say, a red politically red defendant in a blue
[00:26:05.400 --> 00:26:08.400]   jurisdiction, huge awards, I think we could probably see the
[00:26:08.400 --> 00:26:10.680]   opposite as well, that basically, you'll start seeing
[00:26:10.680 --> 00:26:14.160]   blue defendants taken on in red jurisdictions, we've seen
[00:26:14.160 --> 00:26:17.600]   completely disproportionate judgments in again, around
[00:26:17.600 --> 00:26:20.200]   defamation, disproportionate relative to the harm that
[00:26:20.200 --> 00:26:23.160]   actually took place, you're going to see that on steroids,
[00:26:23.160 --> 00:26:26.440]   if we get rid of Section 230. Now, historically was the job
[00:26:26.440 --> 00:26:30.320]   of Republicans to oppose Democrats on this stuff, because
[00:26:30.320 --> 00:26:33.000]   they knew that Democrats were shilling for the plaintiff's
[00:26:33.000 --> 00:26:37.240]   bar. Republicans have not done that, because they're so mad at
[00:26:37.240 --> 00:26:39.800]   these social media companies for censorship. So remember, when I
[00:26:39.800 --> 00:26:43.240]   talked about Good Samaritan liability, these companies
[00:26:43.240 --> 00:26:47.680]   created content moderation, to basically try and remove the
[00:26:47.680 --> 00:26:50.400]   violent material, the pornographic material, the
[00:26:50.400 --> 00:26:54.920]   sexual material, the harassment material. But in the process of
[00:26:54.920 --> 00:26:58.280]   doing that, they started making political judgments, and they
[00:26:58.280 --> 00:27:01.560]   started engaging in political censorship. And that has made
[00:27:01.560 --> 00:27:04.560]   the Republicans so angry that they have now turned against
[00:27:04.720 --> 00:27:07.440]   these companies, and they are willing to remove Section 230.
[00:27:07.440 --> 00:27:10.000]   My point is, I think Republicans at the end, they are going to
[00:27:10.000 --> 00:27:13.200]   regret that because if you remove Section 230, it's going
[00:27:13.200 --> 00:27:15.640]   to open up this flood of litigation, maybe a free for
[00:27:15.640 --> 00:27:18.600]   all, it'll be a free for all. And what's going to happen is
[00:27:18.600 --> 00:27:23.120]   that these companies, just driven by simple corporate risk
[00:27:23.120 --> 00:27:26.120]   aversion, are going to clamp down even more. I mean, the
[00:27:26.120 --> 00:27:29.840]   content moderation is going to be even stricter. And because
[00:27:29.840 --> 00:27:32.800]   the content moderators, these companies basically are liberals,
[00:27:32.920 --> 00:27:36.280]   if you empower them to take down even more content, they're going
[00:27:36.280 --> 00:27:40.320]   to take down Republican stuff even more. Very, it'll be very
[00:27:40.320 --> 00:27:43.520]   easy for the plaintiffs to target that type of content,
[00:27:43.520 --> 00:27:47.640]   they'll say that, oh, that, you know, all of that Republican or
[00:27:47.640 --> 00:27:49.840]   conservative content that influence people in a very
[00:27:49.840 --> 00:27:52.680]   negative direction that created all of these harms, there'll be
[00:27:52.680 --> 00:27:56.960]   lawsuits targeting that sort of content, and Facebook and others
[00:27:56.960 --> 00:27:59.960]   will respond in the economically rational way, which is to shut
[00:27:59.960 --> 00:28:02.760]   it down completely. So I think senators like Josh Hawley
[00:28:02.760 --> 00:28:04.120]   are not going to get what they want.
[00:28:04.120 --> 00:28:06.160]   They're not thinking straight. Yeah, come on, it's gonna back
[00:28:06.160 --> 00:28:07.000]   fight. Yeah, it's gonna backfire.
[00:28:07.000 --> 00:28:12.120]   The reason why this is going to happen, if it does happen, and
[00:28:12.120 --> 00:28:14.880]   you want it to try to be probabilistic about it, is
[00:28:14.880 --> 00:28:17.280]   because when you look back at the tobacco settlement, the
[00:28:17.280 --> 00:28:20.600]   original settlement in today's dollars is about $370 billion.
[00:28:20.600 --> 00:28:25.120]   If you if you were the trial lawyers, and you're looking at a
[00:28:25.120 --> 00:28:29.920]   combination of Facebook and tick tock, and all of the all of
[00:28:29.920 --> 00:28:34.520]   that money, I suspect that they probably think that the
[00:28:34.520 --> 00:28:38.760]   potential that they can extract from these companies is going to
[00:28:38.760 --> 00:28:43.040]   be multiples of that number. And then as a result, their fees
[00:28:43.040 --> 00:28:47.320]   will be between 20 and 50% of that. So you're talking about
[00:28:47.320 --> 00:28:55.720]   hundreds of billions of dollars of revenue potential that will
[00:28:55.720 --> 00:29:03.880]   motivate I think these folks to get the law changed. And then
[00:29:03.880 --> 00:29:08.080]   the byproduct will not be framed in terms of dollars. It's these
[00:29:08.080 --> 00:29:11.040]   are highly kinetic issues when you're talking about sexual
[00:29:11.040 --> 00:29:15.120]   exploitation and young people and mental health and suicide
[00:29:15.120 --> 00:29:18.160]   and bullying. These are very kinetic issues, right. And so
[00:29:18.160 --> 00:29:22.360]   bringing these to jury trials all across the United States. I
[00:29:22.360 --> 00:29:26.000]   think that they probably think that they're on the right side
[00:29:26.000 --> 00:29:28.920]   of history and winning those things. So yeah, you know, again,
[00:29:28.920 --> 00:29:32.080]   I'm not saying it's highly emotional. And I'm highly
[00:29:32.080 --> 00:29:35.760]   emotional. I mean, listen, it's gonna win. It's gonna win. You
[00:29:35.760 --> 00:29:40.800]   bring a case of say, teen suicide, okay. Horrible that it
[00:29:40.800 --> 00:29:44.080]   happens. But there's gonna every time something like that
[00:29:44.080 --> 00:29:46.600]   happens, there's going to be a huge temptation. I'm sure
[00:29:46.600 --> 00:29:49.480]   there'll be trial lawyers who specialize in this, to bring a
[00:29:49.480 --> 00:29:53.000]   case against Facebook or some other social media company. And
[00:29:53.000 --> 00:29:56.960]   they're going to scour through these accounts and try to point
[00:29:56.960 --> 00:30:01.720]   to examples that could have led to this result. And the truth of
[00:30:01.720 --> 00:30:04.880]   the matter is that maybe social media contributed a little bit.
[00:30:04.880 --> 00:30:07.480]   What about popular culture and popular entertainment? What
[00:30:07.480 --> 00:30:11.000]   about all the messages? I'm not debating? I'm just I'm pointing
[00:30:11.000 --> 00:30:13.640]   out what's gonna happen. What about all the messages they
[00:30:13.640 --> 00:30:16.920]   received? Not not through the edge cases I got through on
[00:30:16.920 --> 00:30:19.280]   social media, but through the mainstream entertainment. I
[00:30:19.280 --> 00:30:21.480]   mean, all the shows are watching on television, all the music
[00:30:21.480 --> 00:30:24.040]   they're listening to the things that happened in their schools
[00:30:24.040 --> 00:30:26.960]   and day to day conversations with other kids. But you can't
[00:30:26.960 --> 00:30:30.200]   really sue any of those other things. But you can sue social
[00:30:30.200 --> 00:30:30.560]   media.
[00:30:30.560 --> 00:30:34.000]   The crazy thing about all of this is that all of these
[00:30:34.000 --> 00:30:37.520]   lawsuits are funded, in part by these hedge funds who will do
[00:30:37.520 --> 00:30:42.120]   litigation finance. And part of putting together a well
[00:30:42.120 --> 00:30:44.600]   performing litigation finance fund is underwriting the
[00:30:44.600 --> 00:30:47.840]   probability of success. And I think when you flow through the
[00:30:47.840 --> 00:30:51.840]   probabilities, and you apply it to these companies, largely
[00:30:51.840 --> 00:30:55.880]   because of their profitability and their ability to over earn
[00:30:55.880 --> 00:31:00.840]   and generate profits, I suspect that Wall Street is probably
[00:31:00.840 --> 00:31:04.320]   already involved if and if not, they'll probably get involved in
[00:31:04.320 --> 00:31:08.360]   due course. But it's it's an unfortunate thing, David, I
[00:31:08.360 --> 00:31:11.600]   agree, because this is sort of like, hey, the rules on the
[00:31:11.600 --> 00:31:15.400]   field were x, and folks operated by those and they are clear they
[00:31:15.400 --> 00:31:17.800]   are trying to do their best. But again, this is where
[00:31:17.800 --> 00:31:20.240]   capitalism, the part of capitalism that can be awkward
[00:31:20.240 --> 00:31:24.240]   and uncomfortable is when industries over earned for long
[00:31:24.240 --> 00:31:27.280]   periods of time, other folks say I'm going to compete away those
[00:31:27.280 --> 00:31:29.840]   returns somehow, and I want a share of those profits. And I
[00:31:29.840 --> 00:31:32.880]   think that that's going to be the large motivator. And it's
[00:31:32.880 --> 00:31:35.480]   just going to result in I think these things changing and a
[00:31:35.480 --> 00:31:36.640]   plethora of lawsuits.
[00:31:36.640 --> 00:31:40.600]   And at the end of the day, this is about children and protecting
[00:31:40.600 --> 00:31:43.800]   children. So the obvious solution here is society has to
[00:31:43.800 --> 00:31:44.640]   come up with a number.
[00:31:44.640 --> 00:31:47.920]   Well, sadly, I think that is, you know,
[00:31:47.920 --> 00:31:50.800]   hold on, let me finish my thought here. The The key thing
[00:31:50.800 --> 00:31:53.560]   is, there's some age in which we all agree, it's reasonable for
[00:31:53.560 --> 00:31:55.880]   kids to be using social media. And there's a certain age when
[00:31:55.880 --> 00:31:58.880]   we think it's not reasonable. And back to capitalism, I think
[00:31:58.880 --> 00:32:01.600]   a very good point you made from off, these companies are going
[00:32:01.600 --> 00:32:05.400]   to have to say, well, if we lose the 12 to 15 year olds, is that
[00:32:05.400 --> 00:32:08.720]   better for society and better for our business. And we just
[00:32:08.720 --> 00:32:12.080]   all agree that social media should start at 15 or 16. And
[00:32:12.080 --> 00:32:15.920]   then the handset manufacturers and the and the social sites all
[00:32:15.920 --> 00:32:18.000]   have you have to get permission from your parents to use them
[00:32:18.000 --> 00:32:19.680]   period, full stop. And that's it. And
[00:32:19.680 --> 00:32:22.400]   that may be where this all winds up, I think. And then also
[00:32:22.400 --> 00:32:24.840]   explaining the algorithms, I think is the next thing that's
[00:32:24.840 --> 00:32:26.760]   going to happen, people are going to have to disclose how
[00:32:26.760 --> 00:32:27.760]   these algorithms work.
[00:32:27.760 --> 00:32:30.160]   I think you're making a very good point, which is that is the
[00:32:30.160 --> 00:32:33.320]   right conversation to have. My point was that instead of having
[00:32:33.320 --> 00:32:37.160]   that conversation, which is more societal, it involves David's
[00:32:37.160 --> 00:32:39.960]   right parental responsibility. What is our role? Absolutely.
[00:32:39.960 --> 00:32:43.840]   But being actively involved. And by the way, the trends around
[00:32:43.840 --> 00:32:46.880]   family formation, and the fact that there's way more single
[00:32:46.880 --> 00:32:49.680]   parent families make this problem even harder, because now
[00:32:49.680 --> 00:32:52.360]   there's only one person to check in and not two people to check
[00:32:52.360 --> 00:32:55.480]   in. So all these things societally build on itself,
[00:32:55.480 --> 00:32:59.000]   Jason, that is the absolute right conversation to have. My
[00:32:59.000 --> 00:33:03.080]   point is, that's not going to be why the rules need to get
[00:33:03.080 --> 00:33:05.520]   rewritten, the rules will get rewritten, because there's an
[00:33:05.560 --> 00:33:08.720]   economic argument by a different sector of the economy, in this
[00:33:08.720 --> 00:33:11.320]   case, the trial lawyers and other folks that say there's a
[00:33:11.320 --> 00:33:14.560]   trillion dollars to be had, if we get this law change, they are
[00:33:14.560 --> 00:33:16.280]   motivated enough to do that. Yeah,
[00:33:16.280 --> 00:33:19.520]   a parasitic sector. So there is a bill right now working its way
[00:33:19.520 --> 00:33:22.720]   through the California Assembly that would go to Gavin Newsom
[00:33:22.720 --> 00:33:26.160]   that would prohibit the use of social media by under 16 year
[00:33:26.160 --> 00:33:30.360]   olds. So that is actually happening. Yeah, I agree with
[00:33:30.360 --> 00:33:33.280]   you, that's a better debate to have than changing section 230
[00:33:33.280 --> 00:33:35.120]   in a way that's going to lead to more censorship, by the way,
[00:33:35.120 --> 00:33:38.720]   just just on that point. I think republicans need to understand
[00:33:38.720 --> 00:33:42.680]   this in particular is that the anger towards these companies
[00:33:42.680 --> 00:33:46.280]   is bipartisan, the the outrage is bipartisan, the moral panic
[00:33:46.280 --> 00:33:48.960]   is bipartisan, you saw it on in that hearing, you couldn't
[00:33:48.960 --> 00:33:50.680]   really tell the difference between Republicans and
[00:33:50.680 --> 00:33:54.240]   Democrats. Okay, so full display, I wouldn't be surprised
[00:33:54.240 --> 00:33:58.480]   if they agreed like Jamal said, on some sort of change to
[00:33:58.480 --> 00:34:01.600]   section 230. But here's the catch, is that Republicans,
[00:34:01.600 --> 00:34:04.120]   Democrats have fundamentally different objectives,
[00:34:04.360 --> 00:34:07.240]   fundamentally, Democrats want there to be more censorship,
[00:34:07.240 --> 00:34:09.360]   they say this all the time, we want you taking down more
[00:34:09.360 --> 00:34:11.960]   content, not less, Republicans want there to be less
[00:34:11.960 --> 00:34:15.560]   censorship. Okay. So if they agree on the same piece of
[00:34:15.560 --> 00:34:19.720]   legislation, only one of them can be right. Okay. And the
[00:34:19.720 --> 00:34:22.280]   question is, who's gonna be right, my guess is that if
[00:34:22.280 --> 00:34:25.680]   Democrats and Republicans agree on a section 230 modification,
[00:34:25.680 --> 00:34:28.200]   the Democrats know what they're doing. And the Republicans,
[00:34:28.200 --> 00:34:30.840]   generally being the stupid party who get outsmarted all the time
[00:34:30.840 --> 00:34:33.240]   by Democrats are going to agree to something that they later
[00:34:33.240 --> 00:34:36.840]   regret. So at the end of the day, I don't think that
[00:34:36.840 --> 00:34:40.080]   bipartisan legislation should be possible. The anger is
[00:34:40.080 --> 00:34:43.400]   bipartisan, but the objectives are not. And if something gets
[00:34:43.400 --> 00:34:45.880]   through, it's gonna be because Republicans make a huge mistake.
[00:34:45.880 --> 00:34:49.520]   And just to give a tangible example of this, okay, take the
[00:34:49.520 --> 00:34:53.200]   Second Amendment. Okay. Do you think that in this world where
[00:34:53.200 --> 00:34:55.960]   there's no section 230, that Republicans are still gonna be
[00:34:55.960 --> 00:35:00.400]   out of conversations online about say, gun enthusiasm? No
[00:35:00.400 --> 00:35:04.480]   way. Because every time some harm happens, every time there's a
[00:35:04.480 --> 00:35:07.800]   shooting of some kind, a plain lawsuit, yeah, a plaintiff's
[00:35:07.800 --> 00:35:11.280]   lawyer is gonna sue, not the person who posted the content,
[00:35:11.280 --> 00:35:14.760]   talking about how much they love their guns. And, you know, look,
[00:35:14.760 --> 00:35:18.880]   it could be totally innocuous. Okay. It could be a forum on
[00:35:18.880 --> 00:35:22.720]   Facebook or Reddit, where people are just having conversations
[00:35:22.720 --> 00:35:25.720]   about gun reviews, or gun reviews. Yeah, it could be
[00:35:25.720 --> 00:35:29.360]   totally innocuous conversations. Okay. People having the right
[00:35:29.360 --> 00:35:33.480]   kind of conversations about guns, okay. But you know, that
[00:35:33.480 --> 00:35:37.760]   every one of those websites that hosts those conversations will
[00:35:37.760 --> 00:35:41.280]   be targeted in relation to any harm that occurs in the real
[00:35:41.280 --> 00:35:45.080]   world. And very soon, Reddit and Facebook and all the rest will
[00:35:45.080 --> 00:35:49.320]   feel compelled to ban any conversation related to even
[00:35:49.320 --> 00:35:53.560]   Second Amendment rights. Okay. This is where it will lead if
[00:35:53.560 --> 00:35:56.400]   Republicans get rid of section 230. You will be the ones
[00:35:56.400 --> 00:35:58.360]   targeted, not liberals.
[00:35:58.360 --> 00:36:01.600]   All right. Great discussion. You know, it's important to have
[00:36:01.600 --> 00:36:03.960]   the right discussion. And this reminds me of the abortion
[00:36:03.960 --> 00:36:05.960]   discussion where nobody would ever talk about the number of
[00:36:05.960 --> 00:36:08.760]   weeks. Like, that's at the core of the issue. If we could agree
[00:36:08.760 --> 00:36:11.560]   on the number of weeks, we can agree on the age here, you know,
[00:36:11.560 --> 00:36:14.200]   for for kids to, to use these things, maybe we can move
[00:36:14.200 --> 00:36:17.000]   forward. Let's move forward on the docket here. We got so much
[00:36:17.000 --> 00:36:21.520]   to talk about. And I think the number one story of the week was
[00:36:21.520 --> 00:36:25.200]   Ilan's pay package and this ruling that occurred in
[00:36:25.200 --> 00:36:28.680]   Delaware. Let me just see this up here. Many of you probably
[00:36:28.680 --> 00:36:32.600]   know about this already. But in 2018, Tesla's board approved a
[00:36:32.600 --> 00:36:36.400]   performance based compensation package for Ilan was approved by
[00:36:36.400 --> 00:36:41.120]   73% of shareholders. Ilan and his brother Kimball would have
[00:36:41.120 --> 00:36:43.760]   put that at 80%. But they were excluded. Obviously, this is
[00:36:43.760 --> 00:36:47.960]   lower than maybe some other support levels. According to
[00:36:47.960 --> 00:36:52.760]   Reuters, you typically see 95% for a executive compensation
[00:36:52.760 --> 00:36:55.360]   packet. But this one was very unique. It was all stock,
[00:36:55.360 --> 00:36:58.520]   there's no cash bonus, no salary, 12 tranches of stock was
[00:36:58.520 --> 00:37:01.160]   very creative in how this was put together because Ilan got
[00:37:01.160 --> 00:37:06.400]   nothing if he doubled the value of Tesla. But then if he, you
[00:37:06.400 --> 00:37:10.360]   know, increase the value of the top line revenue, and the market
[00:37:10.360 --> 00:37:14.480]   cap increased by $50 billion, he got 1% more of the outstanding
[00:37:14.480 --> 00:37:18.120]   shares, which is an amazing help for shareholders, obviously,
[00:37:18.120 --> 00:37:21.600]   because the market capital, the company went up 50 billion. The
[00:37:21.600 --> 00:37:25.280]   initial plan was only worth about 2.6 billion. But since
[00:37:25.280 --> 00:37:28.360]   Tesla crushed it from 2018 to 2023, we'll throw up a chart
[00:37:28.360 --> 00:37:31.800]   here. So the great runs in the history of capitalism, how
[00:37:31.800 --> 00:37:35.360]   revenue and sales grew at this company. So it made it the
[00:37:35.360 --> 00:37:37.880]   largest comp package in the history of public markets. And
[00:37:37.880 --> 00:37:41.280]   if you compare Tesla to Apple, the second highest increasing
[00:37:41.280 --> 00:37:44.960]   stock price during that same time period, Apple went up 345%.
[00:37:44.960 --> 00:37:49.640]   Tesla went up 800%. In 2018, a Tesla shareholder sued Elon and
[00:37:49.640 --> 00:37:52.920]   Tesla's board claiming the pay package was unfair. The guy had
[00:37:52.920 --> 00:37:57.840]   nine shares, a full nine shares, not 10, nine, worth $2,500. His
[00:37:57.840 --> 00:38:01.440]   stake went 10x in those six years. So he made a fortune on
[00:38:01.440 --> 00:38:04.640]   that bet. And then on Tuesday, a Delaware judge voided Elon's pay
[00:38:04.640 --> 00:38:09.920]   package, siding with the investor. Elon can appeal it to
[00:38:09.920 --> 00:38:14.520]   the Delaware Supreme Court, sacks, your thoughts on this
[00:38:14.520 --> 00:38:16.920]   ruling, I teed it up, I think I got all the details in there. If
[00:38:16.920 --> 00:38:18.280]   I missed any, please add them.
[00:38:18.280 --> 00:38:22.280]   Well, I think in order to reach this ruling, the judge had to
[00:38:22.280 --> 00:38:26.080]   find three things, and all of them had to be the case. And in
[00:38:26.080 --> 00:38:29.280]   her opinion, number one, that the pay package was excessive.
[00:38:29.280 --> 00:38:32.640]   Number two, that the process by which they came up with the pay
[00:38:32.640 --> 00:38:36.480]   package was not fair, meaning it was not sufficiently adversarial
[00:38:36.480 --> 00:38:40.520]   enough, that the directors, in her opinion, that too many ties
[00:38:40.520 --> 00:38:47.560]   to Elon, and didn't, again, take enough of a antagonistic role in
[00:38:47.560 --> 00:38:51.320]   negotiating that package. And number three, and I think most
[00:38:51.320 --> 00:38:54.360]   importantly, that the shareholder vote was invalid.
[00:38:54.360 --> 00:38:56.880]   Because even if the first two had been true, the shareholders
[00:38:56.880 --> 00:38:59.560]   approved it. And that would have been good enough. But she said
[00:38:59.560 --> 00:39:03.240]   that the shareholders weren't sufficiently informed. And
[00:39:03.240 --> 00:39:05.760]   specifically, I think this argument hung on a few internal
[00:39:05.760 --> 00:39:08.920]   emails, where people said that they thought that they could hit
[00:39:08.920 --> 00:39:13.000]   the numbers. I think that of the three legs of this, well, all
[00:39:13.000 --> 00:39:16.400]   three have been challenged by opponents to this verdict. I
[00:39:16.400 --> 00:39:19.200]   mean, number one, yes, the pay package ended up being a
[00:39:19.200 --> 00:39:22.520]   gargantuan amount, but you have to look at an ex ante, not ex
[00:39:22.520 --> 00:39:26.840]   post. Nobody thought Elon could hit all these numbers. Back at
[00:39:26.840 --> 00:39:28.560]   the time this package was negotiated.
[00:39:28.560 --> 00:39:32.040]   Let's be frank, it was absurd. The idea that he would 10x it
[00:39:32.040 --> 00:39:32.360]   was
[00:39:32.360 --> 00:39:34.800]   crazy. Great clip with Andrew Ross Sorkin, where they're all
[00:39:34.800 --> 00:39:36.960]   laughing at the idea that he's going to hit these numbers.
[00:39:36.960 --> 00:39:39.240]   Remember, this was at a time when Elon was going through what
[00:39:39.240 --> 00:39:41.200]   was called production hell, where he was sleeping on the
[00:39:41.200 --> 00:39:44.080]   floor in a factory. Yeah, I was there and come out yet and
[00:39:44.080 --> 00:39:47.160]   nobody, nobody believed that the model three was going to be the
[00:39:47.160 --> 00:39:50.680]   hit that it was. In fact, all the stories were pooh poohing
[00:39:50.680 --> 00:39:53.120]   that idea and basically saying that Tesla is basically screwed
[00:39:53.120 --> 00:39:54.720]   because they can't get the production line working
[00:39:54.720 --> 00:39:57.000]   correctly. Yeah, you don't play this
[00:39:57.000 --> 00:40:01.040]   Tesla now announcing a radical new compensation plan. It could
[00:40:01.040 --> 00:40:04.560]   be perhaps the most radical compensation plan in history.
[00:40:04.600 --> 00:40:07.960]   The executive will receive no guaranteed compensation of any
[00:40:07.960 --> 00:40:11.880]   time of any kind at all. He gets a salary cash bonus equity. He
[00:40:11.880 --> 00:40:15.240]   only gets equity that that vests over time, but only if he
[00:40:15.240 --> 00:40:19.440]   reaches these hurdle rates, which are, dare I say crazy.
[00:40:19.440 --> 00:40:22.560]   The only part of it that I think is really relevant is where
[00:40:22.560 --> 00:40:27.240]   Sorkin says that the milestones are crazy, meaning that everyone
[00:40:27.240 --> 00:40:30.680]   thought it was a pipe dream that the company would ever hit these
[00:40:30.680 --> 00:40:34.400]   numbers. Okay, so that's point number one on on magnitude. On
[00:40:34.400 --> 00:40:38.760]   the second part of the ruling about the process. It is true
[00:40:38.760 --> 00:40:42.520]   that, like in most venture backed startups, there's a
[00:40:42.520 --> 00:40:45.320]   long standing relationship between the founder and the
[00:40:45.320 --> 00:40:48.200]   investors because they work collaboratively to try and make
[00:40:48.200 --> 00:40:52.440]   the company a success. There were emails that came out where
[00:40:52.440 --> 00:40:55.920]   Elon shows that I'm not trying to go for the maximum here. So,
[00:40:55.920 --> 00:40:59.160]   you know, did the investors go in with a hostile antagonistic
[00:40:59.160 --> 00:41:01.320]   attitude that we're going to try and pay you the least? No. But
[00:41:01.320 --> 00:41:03.640]   did Elon go in with the attitude that I'm going to try and take
[00:41:03.640 --> 00:41:07.640]   the most? No, they eat the email showed that. Yes, they tried to
[00:41:07.640 --> 00:41:11.120]   do was come up with something that they thought was fair, that
[00:41:11.120 --> 00:41:15.160]   would fairly reward him for outsized performance. And if he
[00:41:15.160 --> 00:41:20.640]   had merely increased the value of Tesla, from 59 billion to 100
[00:41:20.640 --> 00:41:22.880]   billion, he would have gotten nothing. Let's just keep that in
[00:41:22.880 --> 00:41:25.680]   mind. So they tried to come up with something that would reward
[00:41:25.680 --> 00:41:28.400]   him for outsized performance, and give him absolutely nothing
[00:41:28.400 --> 00:41:32.560]   for merely decent or good performance. The third point
[00:41:32.600 --> 00:41:37.680]   about the shareholder vote. I don't think that there was
[00:41:37.680 --> 00:41:39.880]   anything about the shareholder vote that the shareholders
[00:41:39.880 --> 00:41:43.040]   didn't know. I don't think that the company didn't release. Elon
[00:41:43.040 --> 00:41:44.960]   always said, Yeah, we're going to do this, we're gonna be one
[00:41:44.960 --> 00:41:47.240]   of the most valuable companies in the world. He's always been
[00:41:47.240 --> 00:41:50.480]   super optimistic about their ability to reach these targets.
[00:41:50.480 --> 00:41:53.160]   But if you looked at all the Wall Street analysts, including
[00:41:53.160 --> 00:41:58.520]   Sorkin there, they thought that these targets were unreachable.
[00:41:58.520 --> 00:42:02.440]   Also, to add to that sex, this had the largest short position,
[00:42:02.440 --> 00:42:06.120]   I believe at that time of any company ever. People were
[00:42:06.120 --> 00:42:08.880]   betting with their dollars that this company was going to zero.
[00:42:08.880 --> 00:42:12.040]   There were a ton of people who the narrative was this, they'll
[00:42:12.040 --> 00:42:14.680]   never deliver the Model Three, it was two years late, right, or
[00:42:14.680 --> 00:42:17.480]   something in that range. It was, they kept trying to get the
[00:42:17.480 --> 00:42:21.000]   Model Three out, it was taking forever. So yeah, it's, it's
[00:42:21.000 --> 00:42:23.440]   absurd. Also, in that case, Sorkin said in that same clip,
[00:42:23.440 --> 00:42:25.160]   there's been a lot of speculation of Elon stepping
[00:42:25.160 --> 00:42:28.560]   down after the Model Three is in production in the judges ruling,
[00:42:28.560 --> 00:42:30.800]   she said the exact opposite, there is no reason to believe
[00:42:30.800 --> 00:42:33.840]   you on leave, except that he was running like two or three other
[00:42:33.840 --> 00:42:36.480]   companies that it was actually quite possible that he would
[00:42:36.480 --> 00:42:39.480]   leave, he never wanted to be CEO of Tesla, people forget that,
[00:42:39.480 --> 00:42:42.640]   too. He had tried three CEOs of Tesla, and he only took over
[00:42:42.640 --> 00:42:46.560]   Tesla. And I remember it was because he said, Jason, this
[00:42:46.560 --> 00:42:49.080]   thing's gonna fail if I don't take it over. He tried three
[00:42:49.080 --> 00:42:51.720]   different CEO, CEOs in the beginning, people forget that
[00:42:51.720 --> 00:42:52.000]   fact.
[00:42:52.000 --> 00:42:55.840]   And there was scuttlebutt that he would hire somebody I remember
[00:42:55.840 --> 00:42:58.120]   there was like rumors about Sheryl Sandberg, maybe getting
[00:42:58.120 --> 00:43:01.400]   off the job or something like that. I remember he was, he was
[00:43:01.400 --> 00:43:03.320]   going through production L he was sleeping on the factory
[00:43:03.320 --> 00:43:06.120]   floor. Yeah. And he was talking in interviews about how
[00:43:06.120 --> 00:43:08.760]   miserable his life was at that time. I mean, can confirm. Yeah,
[00:43:08.760 --> 00:43:11.960]   exactly. So look, did he have leverage to basically say, you
[00:43:11.960 --> 00:43:14.080]   know what, let's hire a CEO? Yeah, absolutely.
[00:43:14.080 --> 00:43:18.400]   Okay, come off any steel man you can do have the other side here,
[00:43:18.400 --> 00:43:22.600]   like as an investor, public market investor, sometimes. When
[00:43:22.600 --> 00:43:25.760]   you saw that pay package, what did you think? I don't know if
[00:43:25.760 --> 00:43:27.400]   you were a shareholder of Tesla at the time or not.
[00:43:27.520 --> 00:43:34.080]   In the mid teens, I started investing in public's stocks as
[00:43:34.080 --> 00:43:38.480]   well as private tech companies. And I got invited to give a
[00:43:38.480 --> 00:43:41.280]   presentation at the iris own conference, which is like the
[00:43:41.280 --> 00:43:45.360]   most prestigious conference of public market investors you in
[00:43:45.360 --> 00:43:49.520]   May, you show up at Lincoln Center, and everybody in the
[00:43:49.520 --> 00:43:52.000]   audience is paying like 10,000 bucks a ticket or something and
[00:43:52.000 --> 00:43:56.160]   all the proceeds go to a foundation in support of this
[00:43:56.160 --> 00:43:58.640]   gentleman iris own who passed away. But in any event, it's
[00:43:58.640 --> 00:44:05.600]   like, Ackman, Tapper, Einhorn, and I picked Tesla and I was a
[00:44:05.600 --> 00:44:12.160]   very big supporter in many ways and still am. And I think that I
[00:44:12.160 --> 00:44:15.360]   knew the company, frankly, better than most people, except
[00:44:15.360 --> 00:44:18.520]   for him, obviously. But I think that I studied this company
[00:44:18.520 --> 00:44:21.880]   quite deeply. When I and I'm just setting the context when I
[00:44:21.880 --> 00:44:27.120]   saw the pay package, I thought, he's making a mistake. This is
[00:44:27.120 --> 00:44:31.360]   unachievable. I thought the probabilities were in the low
[00:44:31.360 --> 00:44:37.440]   single digits. And then he did it, which just kinds of shows
[00:44:37.440 --> 00:44:44.600]   how incredibly adept he is as a CEO and a manager and an
[00:44:44.600 --> 00:44:49.360]   executor. So then, you know, to go back five or six years later,
[00:44:49.640 --> 00:44:54.360]   after he actually does something that so massively
[00:44:54.360 --> 00:44:59.800]   disproportionately, positively impacted investors, and then to
[00:44:59.800 --> 00:45:04.080]   just rescind it and unwind it, I think is really un American and
[00:45:04.080 --> 00:45:09.040]   unfair. And I think it sets a very poor standard for why
[00:45:09.040 --> 00:45:12.560]   anybody should actually build a company governed in Delaware, it
[00:45:12.560 --> 00:45:16.760]   makes no sense anymore. And just to give you that example, he and
[00:45:16.760 --> 00:45:19.440]   I have both now done this, but like these incremental companies
[00:45:19.440 --> 00:45:22.400]   that I've started, are in Nevada, they're in different
[00:45:22.400 --> 00:45:26.120]   places, because I find the Delaware court slightly and
[00:45:26.120 --> 00:45:31.080]   increasingly unpredictable, and acting with other mandates that
[00:45:31.080 --> 00:45:34.480]   they weren't ever given. So you what do you think that mandate
[00:45:34.480 --> 00:45:38.600]   is, you had a place where there was highly predictable
[00:45:38.600 --> 00:45:43.000]   governance, and they had very narrow ways in which they would
[00:45:43.000 --> 00:45:49.040]   act and opine. And I think in a situation like this, where you
[00:45:49.040 --> 00:45:53.600]   had every opportunity to actually vote this thing down,
[00:45:53.600 --> 00:45:56.920]   and what little of the documentation that I saw about
[00:45:56.920 --> 00:46:00.280]   the communication back and forth, doesn't seem to support
[00:46:00.280 --> 00:46:03.440]   this theory that he rammed it through. Nobody rams anything
[00:46:03.440 --> 00:46:07.320]   through over nine months where he takes month long breaks, and
[00:46:07.320 --> 00:46:10.520]   he tells the GC, this is actually more than I wanted.
[00:46:10.520 --> 00:46:13.560]   Nobody does. If you're right, it's the opposite of raving
[00:46:13.560 --> 00:46:17.840]   something through. It was and I suspect if you really asked him
[00:46:17.840 --> 00:46:21.480]   and I haven't, but I would, he probably thought it was like
[00:46:21.480 --> 00:46:25.800]   largely crazy. And so I think a lot of people thought that we
[00:46:25.800 --> 00:46:28.960]   that we were as shareholders, and I'll tell you that I felt
[00:46:28.960 --> 00:46:32.840]   this way, getting his hard work, and that he may have just
[00:46:32.840 --> 00:46:37.680]   mathematically been mistaken. So yes, he got 55 or that packages
[00:46:37.680 --> 00:46:41.760]   are at 55.8 billion. But you're missing the point where every
[00:46:41.760 --> 00:46:46.120]   other investor made $500 billion. Right? Yeah, the
[00:46:46.120 --> 00:46:49.320]   investors, investors did approve it, it will have a chilling
[00:46:49.320 --> 00:46:52.040]   effect, I think, and how people think about compensation, it
[00:46:52.040 --> 00:46:57.160]   will cause companies to be even more constipated and sclerotic
[00:46:57.160 --> 00:47:02.920]   and unimaginative as a result of this, because the most talented
[00:47:02.920 --> 00:47:07.240]   individual entrepreneurs now have even more of an incentive
[00:47:07.240 --> 00:47:10.840]   for incorporating in other places, and also staying
[00:47:10.840 --> 00:47:15.720]   private. And I think what that deprives is the broader
[00:47:15.720 --> 00:47:18.520]   shareholders, including this gentleman, look, we live in
[00:47:18.520 --> 00:47:22.560]   America, he had the right to sue, he had nine shares, and he
[00:47:22.560 --> 00:47:25.560]   was able to bring this lawsuit nine shares.
[00:47:25.560 --> 00:47:29.640]   I mean, David Elias, yeah, I mean, the idea that nine shares
[00:47:29.640 --> 00:47:33.520]   or 10 x their money, but what he does is, but you know, I don't
[00:47:33.520 --> 00:47:35.240]   know if he remained a shareholder through this whole
[00:47:35.240 --> 00:47:41.800]   period, but even those nine shares, 10 x in value. Yes. But
[00:47:41.800 --> 00:47:46.520]   he would now be deprived of that in this next iteration of Elon
[00:47:46.520 --> 00:47:49.520]   Musk's because why would they ever go through this to put that
[00:47:49.520 --> 00:47:55.040]   much work into something to be so at risk, personally, your own
[00:47:55.040 --> 00:47:59.040]   mental and physical health, we saw him in those periods. And
[00:47:59.040 --> 00:48:02.240]   then to have it taken away, I think is deeply, deeply unfair.
[00:48:02.240 --> 00:48:03.120]   Sex.
[00:48:03.120 --> 00:48:07.160]   You're right, this this deal was a win win. I mean, if Elon could
[00:48:07.160 --> 00:48:10.480]   achieve these numbers, it was good for him. And it was great
[00:48:10.480 --> 00:48:13.600]   for shareholders. And that's why I think the key point is that
[00:48:13.600 --> 00:48:17.440]   73 or 80%, depending on how you want to count it approved this
[00:48:17.440 --> 00:48:20.440]   deal. I think they knew everything relevant that they
[00:48:20.440 --> 00:48:23.600]   needed to know when they approved it. This is the deal
[00:48:23.600 --> 00:48:27.920]   that most shareholders in most companies would want for the CEO
[00:48:27.920 --> 00:48:32.480]   the deal is you get nothing unless you deliver an outsized
[00:48:32.480 --> 00:48:35.600]   return for shareholders. Most CEOs won't sign up for this
[00:48:35.600 --> 00:48:39.120]   deal. Most CEOs work their way up through the corporate ladder,
[00:48:39.120 --> 00:48:41.760]   they get into the CEO chair, and then they pay themselves huge
[00:48:41.760 --> 00:48:44.280]   amounts of money in regards to whether the company succeeds or
[00:48:44.280 --> 00:48:47.520]   fails. And that's the deal they want, because they don't really
[00:48:47.520 --> 00:48:52.520]   have confidence in themselves to deliver what Sorkin called the
[00:48:52.520 --> 00:48:56.200]   crazy outcome. Elon had the confidence in himself to deliver
[00:48:56.200 --> 00:48:59.280]   the crazy outcome. And nobody was really complaining about
[00:48:59.280 --> 00:49:03.360]   this until like you said, this small shareholder, who's really
[00:49:03.360 --> 00:49:07.200]   basically just, you know, a named plaintiff for the trial
[00:49:07.200 --> 00:49:10.280]   lawyers bar somebody who wants to get you on brick to bring
[00:49:10.280 --> 00:49:11.240]   this suit.
[00:49:11.240 --> 00:49:16.880]   6% to create 600 billion in value. I mean, it's quite a
[00:49:16.880 --> 00:49:20.480]   bargain, folks. And I think if you went to Ford or GM and said,
[00:49:20.480 --> 00:49:23.160]   Hey, would you like you want to be your CEO? I think that often
[00:49:23.160 --> 00:49:23.840]   half the company
[00:49:23.840 --> 00:49:25.560]   Mary bear doesn't want this deal.
[00:49:25.560 --> 00:49:28.280]   Yeah, no, Jake out sack said something really important that
[00:49:28.280 --> 00:49:30.760]   you just mentioned as well, which is that if you actually
[00:49:30.760 --> 00:49:34.200]   look at the average compensation plan of most public company
[00:49:34.200 --> 00:49:38.960]   CEOs, it actually is very much counter to shareholder value.
[00:49:38.960 --> 00:49:41.800]   I'll give you one simple example. If you look at the
[00:49:41.800 --> 00:49:45.480]   number of CEO comp packages that are tied to earnings per share
[00:49:45.480 --> 00:49:49.560]   growth. But then if you actually look at how these CEOs achieve
[00:49:49.560 --> 00:49:54.240]   their EPS targets, they do it by raising debt. So in getting the
[00:49:54.240 --> 00:49:57.920]   company right, increasing the enterprise value by by loading
[00:49:57.920 --> 00:50:00.760]   the company up with debt, and then driving repurchase plans.
[00:50:00.760 --> 00:50:03.720]   And what what do those do? I mean, look, if you look at
[00:50:03.720 --> 00:50:06.080]   Disney, where do their repurchases come from from debt?
[00:50:06.080 --> 00:50:10.440]   So does debt help an equity shareholder? It categorically
[00:50:10.440 --> 00:50:14.960]   does not under no world doesn't do that. However, for the CEO,
[00:50:14.960 --> 00:50:18.360]   and for the handful of investors that that can hold on for long
[00:50:18.360 --> 00:50:22.080]   periods of time, or have you, they benefit from a lower share
[00:50:22.080 --> 00:50:24.440]   count, they benefit from increased EPS, and then the CEO
[00:50:24.440 --> 00:50:28.280]   gets compensated. And so to say that tacitly, what you
[00:50:28.280 --> 00:50:32.640]   disapprove of our performance incentives, and what you are
[00:50:32.640 --> 00:50:38.080]   actually approving of our mechanics that saddle a company
[00:50:38.080 --> 00:50:43.920]   with debt, and allow basically gaming of numbers is what you've
[00:50:43.920 --> 00:50:48.200]   implicitly also said. And this is where I think the Delaware
[00:50:48.200 --> 00:50:52.880]   court used to be known for a level of intellectual clarity
[00:50:52.880 --> 00:50:56.640]   that would have prevented that implicit assumption. But that's
[00:50:56.640 --> 00:50:59.280]   now what's left on the table. And I think it will have a ripple
[00:50:59.280 --> 00:51:03.560]   effect across how so many other companies design, design their
[00:51:03.560 --> 00:51:07.880]   compensation plans, how CEOs think about risk, no CEO, as
[00:51:07.880 --> 00:51:11.680]   SAC said, will ever want an incentive laden plan like this
[00:51:11.680 --> 00:51:15.040]   ever, they will want 10 years later, you could do all the work
[00:51:15.040 --> 00:51:18.680]   and then it gets canceled, canceled. So they will want
[00:51:18.680 --> 00:51:23.440]   something that is totally gameable. Right, where you'll
[00:51:23.440 --> 00:51:27.880]   have 90 plus percent support and approval, because of how vanilla
[00:51:27.880 --> 00:51:32.440]   and benign it is on the surface. But it will actually be quite a
[00:51:32.440 --> 00:51:34.960]   terrible plan underneath the surface. And what I mean,
[00:51:34.960 --> 00:51:39.160]   specifically, are these EPS targets for CEOs. So Elon did
[00:51:39.160 --> 00:51:41.680]   the one thing that was crazy, which was I'm just going to do
[00:51:41.680 --> 00:51:45.960]   it based on pure profitability and performance. And he gets
[00:51:45.960 --> 00:51:49.160]   punished. And all these CEOs in this other class were like, let
[00:51:49.160 --> 00:51:52.200]   me saddle these companies with debt that actually undermine
[00:51:52.200 --> 00:51:54.400]   shareholders have been rewarded.
[00:51:54.400 --> 00:51:57.520]   There is already a mechanism for somebody who disagrees with the
[00:51:57.520 --> 00:52:00.000]   comp package, this person who on the nine shares could have sold
[00:52:00.000 --> 00:52:02.600]   their shares. It's a liquid market at any point in time, that
[00:52:02.600 --> 00:52:05.320]   person can say, I don't agree with this. I'm taking my nine
[00:52:05.320 --> 00:52:07.920]   shares and $2,500. I'm going to put it in Apple, I'm going to
[00:52:07.920 --> 00:52:11.000]   put it into. I like Tim Cook's pay package better. I like
[00:52:11.000 --> 00:52:14.080]   Benioff's package better. And I'll make my better person had
[00:52:14.080 --> 00:52:18.600]   choice. Yes, x. This person was not a victim. He's not victim
[00:52:18.600 --> 00:52:20.400]   because he could have sold the shares and bought other shares.
[00:52:20.400 --> 00:52:22.280]   And he's not a victim because he 10 x two shares and beat the
[00:52:22.280 --> 00:52:22.720]   market.
[00:52:22.720 --> 00:52:26.960]   Yeah, I mean, look, I don't place the blame on the
[00:52:27.000 --> 00:52:31.240]   shareholder per se. Because this is really about a judge's
[00:52:31.240 --> 00:52:33.560]   interpretation of Delaware law and what companies are allowed
[00:52:33.560 --> 00:52:37.560]   to do. So whether the shareholder was harmed or not,
[00:52:37.560 --> 00:52:41.040]   or had one share, or a million shares, that's just the way that
[00:52:41.040 --> 00:52:43.680]   this case gets into court. The question is the interpretation
[00:52:43.680 --> 00:52:46.400]   of Delaware law. And again, the part of this, I would go back
[00:52:46.400 --> 00:52:49.400]   to that, that I think was the mistake is that I think the
[00:52:49.400 --> 00:52:53.840]   shareholder vote was valid. I think the process was valid as
[00:52:53.840 --> 00:52:57.320]   well. I don't know that the process has to be this
[00:52:57.320 --> 00:53:00.080]   extremely adversarial process where one side is pulling for
[00:53:00.080 --> 00:53:02.640]   the most one sides pulling for the least. I don't think either
[00:53:02.640 --> 00:53:05.300]   side operated that way. But again, I think shareholders knew
[00:53:05.300 --> 00:53:08.760]   what they needed to know. And the evidence of that is, in all
[00:53:08.760 --> 00:53:12.320]   of the public coverage at that time, nobody thought he was
[00:53:12.320 --> 00:53:15.520]   getting a good deal. Right? No one thought he was getting
[00:53:15.520 --> 00:53:19.520]   excessively good. They thought he was getting a delusional deal
[00:53:19.520 --> 00:53:24.440]   meaning delusional for him. And everybody seemed to be okay with
[00:53:24.440 --> 00:53:28.480]   the idea that if somehow, Ilan could pull off this miracle that
[00:53:28.480 --> 00:53:30.960]   he would be entitled to this compensation, and he would get
[00:53:30.960 --> 00:53:35.000]   nothing if he did it. Now, again, I would go back to do you
[00:53:35.000 --> 00:53:39.600]   think Mary Barrow would have wanted this deal? While Ilan was
[00:53:39.600 --> 00:53:44.120]   spending the last five, six years, making Tesla go 10x. Let's
[00:53:44.120 --> 00:53:49.480]   look at GM, GM stock price was trading more or less in a flat
[00:53:49.480 --> 00:53:52.880]   range. I don't even think the share price doubled.
[00:53:52.880 --> 00:53:56.360]   Compare it to you see the compare to button there, put
[00:53:56.360 --> 00:53:58.000]   compare to and then put Tesla in there.
[00:53:58.000 --> 00:54:00.800]   Right. So if Mary Barra, GM had signed up for that comp package,
[00:54:00.800 --> 00:54:03.760]   she would have gotten absolutely nothing, which is why I'm sure
[00:54:03.760 --> 00:54:06.240]   that the thought and everyone crossed her mind of having an
[00:54:06.240 --> 00:54:10.240]   all incentive based comp package that doesn't even start until
[00:54:10.240 --> 00:54:12.920]   you at least double the value of the company. By the way, on
[00:54:12.920 --> 00:54:17.800]   those milestones, it wasn't just the share price, it was share
[00:54:17.800 --> 00:54:21.760]   price and revenue or profit targets being met. So in other
[00:54:21.760 --> 00:54:24.800]   words, if the stock just rallied because of macroeconomic
[00:54:24.800 --> 00:54:28.120]   conditions, like for example, interest rates go down, and then
[00:54:28.120 --> 00:54:30.760]   all of a sudden, the whole stock market goes up, that was not
[00:54:30.760 --> 00:54:35.520]   good enough. It was also tied to the combination of stock value
[00:54:35.520 --> 00:54:40.480]   increases with revenue and profit targets being met. It was
[00:54:40.480 --> 00:54:43.520]   a compact is that couldn't be gamed. I mean, you have to hit
[00:54:43.520 --> 00:54:45.960]   the numbers in order to get the comp package. That's what she
[00:54:45.960 --> 00:54:49.240]   got. And I don't want to pick too much on Mary Barry here. I
[00:54:49.240 --> 00:54:51.840]   guess I'm picking her out because Joe Biden said that she
[00:54:51.840 --> 00:54:53.680]   created the EV revolution.
[00:54:53.680 --> 00:54:58.320]   Well done. 17 cars. They canceled the car.
[00:54:58.320 --> 00:55:02.840]   Yeah. There was there was a remarkable article in the Wall
[00:55:02.840 --> 00:55:06.760]   Street Journal just in December, where they finally admitted that
[00:55:06.760 --> 00:55:10.880]   this whole idea that GM had been leading any kind of revolution
[00:55:10.880 --> 00:55:13.520]   or had been a transformational company was revealed as basically
[00:55:13.520 --> 00:55:18.360]   a ruse. But look, you have to wonder how much of this is
[00:55:18.360 --> 00:55:22.240]   political. I mean, Delaware is Joe Biden state. He's the
[00:55:22.240 --> 00:55:27.760]   senator. There were articles describing how this judge was
[00:55:27.760 --> 00:55:31.640]   connected to a law firm that had helped Joe Biden get elected.
[00:55:31.640 --> 00:55:36.800]   And you just kind of wonder whether Biden's directive from
[00:55:36.800 --> 00:55:39.320]   the White House podium that we got to get this guy, we got to
[00:55:39.320 --> 00:55:43.480]   look into this guy that he's an enemy, which has been reflected
[00:55:43.480 --> 00:55:46.280]   through all these different administrative agencies, sudden
[00:55:46.280 --> 00:55:49.760]   actions against Elon's companies for the glass house,
[00:55:49.760 --> 00:55:51.840]   starlink and the FCC.
[00:55:51.840 --> 00:55:54.360]   Yeah, there's been a whole bunch of these issues. And you just
[00:55:54.360 --> 00:55:57.520]   wonder, is this another manifestation of that?
[00:55:57.520 --> 00:56:03.280]   Yeah, I mean, the conspiracy theories are quickly coming
[00:56:03.280 --> 00:56:07.200]   closer to reality. And we definitely need to investigate
[00:56:07.200 --> 00:56:11.800]   that, for sure. Because the FCC thing is crazy. spending $15,000
[00:56:11.800 --> 00:56:14.360]   putting fiber into people's homes when you could spend
[00:56:14.360 --> 00:56:17.200]   $1,500, giving them starlink makes no sense. And the same
[00:56:17.200 --> 00:56:20.080]   people who have to wait for fiber. That's on a previous
[00:56:20.080 --> 00:56:22.760]   episode. They're gonna get starlink. Anyway, they're gonna
[00:56:22.760 --> 00:56:24.400]   buy starlink while they're waiting for the government
[00:56:24.400 --> 00:56:26.800]   fiber for 10 years. It's absurd.
[00:56:26.800 --> 00:56:29.680]   I do want to uplevel this just back to what I was saying. And
[00:56:29.680 --> 00:56:32.840]   I'll try to I'll try to make the point better. I think I think
[00:56:32.840 --> 00:56:37.560]   it's really, really unfair. What's happening to you on, but
[00:56:37.560 --> 00:56:41.400]   I want to take a step back and think about just the bigger
[00:56:41.400 --> 00:56:47.360]   picture. If we want an economy of vibrant companies that do
[00:56:47.360 --> 00:56:50.960]   great things, we're going to need to reward people to work at
[00:56:50.960 --> 00:56:56.280]   those companies. And in order for the United States to sort of
[00:56:56.280 --> 00:57:00.800]   continue to exert some amount of dominance in the areas that we
[00:57:00.800 --> 00:57:04.200]   think are important, we need to be economically vibrant, right?
[00:57:04.200 --> 00:57:07.000]   And fair and fair. And the problem is that this really
[00:57:07.000 --> 00:57:10.920]   perverts incentives. And it's going to exacerbate a trend that
[00:57:10.920 --> 00:57:14.280]   I think has actually held a bunch of our companies back. So
[00:57:14.280 --> 00:57:16.520]   the first thing I just wanted to show you guys was just this
[00:57:16.520 --> 00:57:20.640]   little thing that it's just a pie chart that shows Okay, how
[00:57:20.640 --> 00:57:26.040]   do CEOs get paid, right? So we want CEOs to go and run really
[00:57:26.040 --> 00:57:30.160]   important companies, right? We want those companies to do great
[00:57:30.160 --> 00:57:32.640]   things in the world. We want these CEOs to be deeply
[00:57:32.640 --> 00:57:35.640]   motivated to go and push the boundaries of what's possible,
[00:57:35.640 --> 00:57:38.960]   right? We want all that. And so we want to compensate them to do
[00:57:38.960 --> 00:57:42.400]   those things. This is just a representation of how CEOs have
[00:57:42.400 --> 00:57:45.920]   structured their pay packages. And you'd say, well, all of
[00:57:45.920 --> 00:57:49.040]   these numbers seem reasonable, return on capital, total
[00:57:49.040 --> 00:57:52.480]   shareholder return earnings per share. So what you need to do
[00:57:52.480 --> 00:57:56.960]   then is double click into this, right? So this is how CEO pay
[00:57:56.960 --> 00:58:00.240]   packages are made. But the problem is, and Jason, this is
[00:58:00.240 --> 00:58:04.360]   my problem with a bunch of these companies that all the returns
[00:58:04.360 --> 00:58:07.480]   all that shareholder return that you saw the return, it's all
[00:58:07.480 --> 00:58:11.120]   driven by share buybacks. Yep, this is an artificial
[00:58:11.120 --> 00:58:14.840]   gamesmanship of performance. This is not companies pushing
[00:58:14.840 --> 00:58:17.960]   the boundaries. You know, this is not Disney figuring out. It's
[00:58:17.960 --> 00:58:21.920]   not innovation. This is this is a this is Disney creating
[00:58:21.920 --> 00:58:24.840]   footfalls and falling into potholes of their own making.
[00:58:24.840 --> 00:58:28.480]   But you can drive great compensation because you can
[00:58:28.480 --> 00:58:33.560]   game the way that you are paid. This doesn't make America
[00:58:33.560 --> 00:58:36.640]   great. It doesn't create American exceptionalism. In
[00:58:36.640 --> 00:58:41.240]   fact, it just creates a bunch of financial engineering that
[00:58:41.240 --> 00:58:45.160]   results in marginal companies. And David just gave an example
[00:58:45.160 --> 00:58:48.680]   of one that could be considered that. So the point is that when
[00:58:48.680 --> 00:58:53.760]   you have one person that tries to buck this trend, I just think
[00:58:53.760 --> 00:58:58.800]   it has a huge impact by basically saying, hey, play the
[00:58:58.800 --> 00:59:02.920]   game like everybody else, just game it, just dial it in from
[00:59:02.920 --> 00:59:05.720]   your country club. Make sure that you become a member of
[00:59:05.720 --> 00:59:09.120]   Augusta. That's more important to us than actually sleeping on
[00:59:09.120 --> 00:59:10.160]   the factory floor.
[00:59:10.160 --> 00:59:13.240]   And don't take risk. I mean, if you think about what do you do
[00:59:13.240 --> 00:59:15.600]   if you're Apple, you're Google, you're Microsoft, you're
[00:59:15.600 --> 00:59:19.200]   sitting on tons of cash. It's a safe thing to do. You see what
[00:59:19.200 --> 00:59:23.000]   they do. You just buy back the shares. No, you can't do m&a.
[00:59:23.000 --> 00:59:26.240]   You issue debt. Yes. And then you buy back the shoes
[00:59:26.240 --> 00:59:31.280]   arbitrage, you encumber the shareholders with debt. And then
[00:59:31.280 --> 00:59:35.000]   you artificially inflate total shareholder return and earnings
[00:59:35.000 --> 00:59:38.120]   per share and the return on invested capital because of how
[00:59:38.120 --> 00:59:41.720]   we can play these games in America. So right now what we
[00:59:41.720 --> 00:59:45.840]   are doing is we are not motivating CEOs to run great
[00:59:45.840 --> 00:59:50.200]   companies were motivated to understand financial arbitrage,
[00:59:50.200 --> 00:59:55.360]   the result will be crappier companies that diminish American
[00:59:55.360 --> 00:59:57.280]   exceptionalism. That is the only outcome.
[00:59:57.280 --> 01:00:00.000]   Perfect. We said and there really are two caveats there.
[01:00:00.000 --> 01:00:03.000]   Number one, we have to let m&a occur as well, because that's a
[01:00:03.000 --> 01:00:06.320]   better thing to do in some cases with this, with this excess
[01:00:06.320 --> 01:00:09.000]   capital profits people have sitting there. And the only time
[01:00:09.000 --> 01:00:10.800]   really to buy shares back is when you think they're
[01:00:10.800 --> 01:00:11.960]   undervalued. You would agree
[01:00:11.960 --> 01:00:14.560]   to your point, I actually think you're absolutely right. If you
[01:00:14.560 --> 01:00:16.600]   have a bunch of CEOs that don't know what they're doing, which
[01:00:16.600 --> 01:00:19.040]   is what these charts kind of show, let them buy whatever they
[01:00:19.040 --> 01:00:21.200]   want, because you're going to screw it up. And that's fine for
[01:00:21.200 --> 01:00:22.040]   us anyways.
[01:00:22.040 --> 01:00:24.320]   Well, yeah, it's great for fluid marketplace.
[01:00:24.320 --> 01:00:28.280]   The CEO that you don't want to have be able to buy companies is
[01:00:28.280 --> 01:00:32.480]   the actually motivated one to get paid when things go really
[01:00:32.480 --> 01:00:35.720]   well and to be you know, more profitable. So that would be the
[01:00:35.720 --> 01:00:38.400]   CEO where you would be scared. Oh my gosh, more m&a for that
[01:00:38.400 --> 01:00:42.360]   person may be bad. But more m&a for these CEOs is who cares?
[01:00:42.360 --> 01:00:45.200]   Yeah, Microsoft starts buying a bunch of stuff. Google starts
[01:00:45.200 --> 01:00:47.760]   buying stuff at their primes, man, that's scary, right? When
[01:00:47.760 --> 01:00:50.200]   Bill Gates went on a heater, he bought, I think he bought
[01:00:50.200 --> 01:00:54.480]   PowerPoint, a bunch of these suite was bought, not created.
[01:00:54.480 --> 01:00:56.960]   And then Google and Facebook, man, they went on heaters,
[01:00:56.960 --> 01:01:00.240]   YouTube, Instagram, WhatsApp, and that was the golden age of
[01:01:00.240 --> 01:01:02.120]   m&a. All right, we got a couple more things on the docket. I
[01:01:02.120 --> 01:01:05.320]   want to catch on. I just found these stats. Good sex. Great
[01:01:05.320 --> 01:01:08.120]   conversation. So just while we were talking, I just looked up
[01:01:08.120 --> 01:01:12.680]   what Mary Barra's compensation was over the past several years.
[01:01:12.680 --> 01:01:18.160]   And according to this source, she was paid $167 million for
[01:01:18.160 --> 01:01:21.520]   four years. So while Elon got zero, thanks to the judge's
[01:01:21.520 --> 01:01:24.760]   decision, Mary Barra, basically, if you add in probably the fifth
[01:01:24.760 --> 01:01:28.400]   year, let's call it roughly $200 million of compensation over the
[01:01:28.400 --> 01:01:32.600]   last five years. Now look at the stock chart of GM. Literally,
[01:01:32.600 --> 01:01:37.320]   this it is the same price today as it was five years ago. It's
[01:01:37.320 --> 01:01:41.720]   $38 a share today. It was $38 a share five years ago. No, but
[01:01:41.720 --> 01:01:44.000]   it's worse. It's probably worse because they've issued options
[01:01:44.000 --> 01:01:46.160]   since then. So there's dilution you have to take in, right? So
[01:01:46.160 --> 01:01:49.440]   it's, it's worse than that, actually. But at best, the stock
[01:01:49.440 --> 01:01:53.840]   price is flat. And the stock basically fluctuated in line
[01:01:53.840 --> 01:01:56.760]   with market trends. So when there was an asset bubble in
[01:01:56.760 --> 01:02:01.960]   2021, the the share price went up about 50%. And she got even
[01:02:01.960 --> 01:02:06.120]   more stock and options during that time. But it was, it was a
[01:02:06.120 --> 01:02:08.760]   no lose proposition. Basically, she got paid regardless of how
[01:02:08.760 --> 01:02:11.280]   the stock did. And then when there was simply market
[01:02:11.280 --> 01:02:14.160]   volatility, she did even better. One of the nice things about
[01:02:14.160 --> 01:02:18.680]   Elon's package is that unless Tesla at least doubled in value,
[01:02:18.680 --> 01:02:22.000]   he would get nothing. And it was tied to milestones around
[01:02:22.000 --> 01:02:24.960]   revenue and profit. So he couldn't just ride market
[01:02:24.960 --> 01:02:29.000]   volatility. No, to getting more comp if you gave this executive
[01:02:29.000 --> 01:02:33.280]   the same deal, as Elon, she would have had to double 38. So
[01:02:33.280 --> 01:02:38.720]   you know, she would have had to get to 70 $60 bucks a share to
[01:02:38.720 --> 01:02:41.840]   get 80 bucks a share before she got anything. I bet you if she
[01:02:41.840 --> 01:02:44.960]   got zero, she got paid $1 and her healthcare, and she had to
[01:02:44.960 --> 01:02:47.640]   get $8 a share. I bet you that would be an $80 stock price.
[01:02:47.640 --> 01:02:51.920]   Well, I don't I don't know if she has the ability to engineer
[01:02:51.920 --> 01:02:55.400]   that outcome. But I doubt I don't. So she's saying she's
[01:02:55.400 --> 01:02:58.800]   unqualified. No, well, the Wall Street Journal said it the Wall
[01:02:58.800 --> 01:03:02.240]   Street Journal just had this 10 year. No, that's where they said
[01:03:02.240 --> 01:03:06.840]   that she failed. They they're they're hiding. And yeah, well,
[01:03:06.840 --> 01:03:08.840]   look, I mean, I don't want to say she's incompetent. I just
[01:03:08.840 --> 01:03:11.160]   want to say that the stock price is the same. The Wall Street
[01:03:11.160 --> 01:03:14.320]   Journal had an article talking about swept to answer all of our
[01:03:14.320 --> 01:03:17.080]   transformation initiatives have failed. She swept roughly 200
[01:03:17.080 --> 01:03:19.320]   million over just the last five years. I think she's been there.
[01:03:19.440 --> 01:03:22.680]   10. How is she in charge? She's probably made several $100
[01:03:22.680 --> 01:03:26.680]   million. And the company hasn't created any value for
[01:03:26.680 --> 01:03:29.440]   shareholders. So how is she still in charge? Just Jason,
[01:03:29.440 --> 01:03:32.880]   this is the way the fortune 500 works. It's a country club. Okay.
[01:03:32.880 --> 01:03:38.120]   Who gets appointed to these companies, these companies are
[01:03:38.120 --> 01:03:41.480]   not run by founders. They're not even run by VCs or serious skin
[01:03:41.480 --> 01:03:43.680]   of the game, the kind of directors that this judge
[01:03:43.680 --> 01:03:47.320]   didn't like, okay, it's run by people who play the game, they
[01:03:47.320 --> 01:03:51.160]   basically are on other boards. And it's basically a
[01:03:51.160 --> 01:03:55.040]   backscratching club. And they choose the CEO, they choose
[01:03:55.040 --> 01:03:57.680]   someone who's politically savvy, who's worked their way up
[01:03:57.680 --> 01:04:01.080]   through the system, who donates to the right people who can get
[01:04:01.080 --> 01:04:03.720]   Joe Biden to come to a factory and talk about how great they
[01:04:03.720 --> 01:04:07.080]   are, and and hold an EV summit at the White House and invent
[01:04:07.080 --> 01:04:10.080]   this, this fiction, that they were responsible for this
[01:04:10.080 --> 01:04:12.960]   innovation. This is basically how the system works. So
[01:04:12.960 --> 01:04:16.320]   corrupt. I'm glad that women have been admitted to this
[01:04:16.320 --> 01:04:19.280]   country club, it is still a country club, it is still a
[01:04:19.280 --> 01:04:23.000]   backscratching club. It is basically a collection of people
[01:04:23.000 --> 01:04:25.520]   who don't create any value, but pay themselves enormous amounts
[01:04:25.520 --> 01:04:28.520]   of money hob now at the right people and work their way in
[01:04:28.520 --> 01:04:31.360]   with the powers that be at the White House, who then talk about
[01:04:31.360 --> 01:04:34.720]   how great they are, while actually accomplishing nothing,
[01:04:34.720 --> 01:04:39.040]   nothing, 0.0. I think the common through line in these two
[01:04:39.040 --> 01:04:43.800]   conversations we've had this morning is about just how
[01:04:43.800 --> 01:04:48.880]   capitalism can be perverted, if you will, by a small group of
[01:04:48.880 --> 01:04:53.040]   actors. In the first example, I think what we were talking about
[01:04:53.040 --> 01:04:57.840]   is the trial lawyers association and their ability to impact and
[01:04:57.840 --> 01:05:01.200]   influence what is going to happen around section 230. And
[01:05:01.200 --> 01:05:04.560]   in this example, I think what it speaks to is the influence that
[01:05:04.560 --> 01:05:08.800]   a small group of consultants can have in having built a very
[01:05:08.800 --> 01:05:12.080]   thriving business in designing these compensation plans for
[01:05:12.080 --> 01:05:17.160]   CEOs. And it reminds me of a of a clip of Buffett and Munger.
[01:05:17.160 --> 01:05:20.200]   And Nick, if you just want to play it, I think they say it in
[01:05:20.200 --> 01:05:22.960]   very clear, plain English, and not to debate their opinion, just
[01:05:22.960 --> 01:05:24.280]   to state it, but Nick, if you want to play it,
[01:05:24.280 --> 01:05:27.600]   we do not bring in compensation consultants, we don't have a
[01:05:27.600 --> 01:05:30.440]   human relations department that we don't have, we don't have the
[01:05:30.440 --> 01:05:32.720]   headquarters, as you can see, we don't have any human relations
[01:05:32.720 --> 01:05:34.400]   department, we don't have a legal department, we don't have
[01:05:34.400 --> 01:05:36.360]   a public relations department, we don't have an investor
[01:05:36.360 --> 01:05:40.000]   relations department, we don't have those things. Because they
[01:05:40.000 --> 01:05:43.080]   make life way more complicated. And everybody gets a vested
[01:05:43.080 --> 01:05:46.040]   interest in going to conferences and calling in other consultants
[01:05:46.040 --> 01:05:48.240]   and it takes on a life of its own.
[01:05:48.240 --> 01:05:52.440]   Well, I would rather throw a Viper down my shirt front, than
[01:05:52.440 --> 01:05:54.520]   hire a compensation consultant.
[01:05:54.520 --> 01:06:02.040]   Tell me which kind of consultants you actually like.
[01:06:04.640 --> 01:06:08.560]   Oh, man, Waldorf and Statler, you know, from the Muppet sacks.
[01:06:08.560 --> 01:06:11.440]   Statler and Waldorf.
[01:06:11.440 --> 01:06:15.680]   Yeah, well, you mentioned grumpy, you mentioned this is a
[01:06:15.680 --> 01:06:18.480]   problem in capitalism. I think there's two kinds of capitalism,
[01:06:18.480 --> 01:06:21.000]   broadly speaking, there's corny capitalism, and there's risk
[01:06:21.000 --> 01:06:24.640]   capitalism. Risk capitalism is the founder who starts with
[01:06:24.640 --> 01:06:29.640]   nothing but an idea, along with the investors who are willing to
[01:06:29.640 --> 01:06:33.400]   write a check, knowing that nine times out of 10, it's going to
[01:06:33.400 --> 01:06:37.440]   be a zero, but maybe in that one out of 10 chance, it's going to
[01:06:37.440 --> 01:06:40.200]   be an outsized return. That is true risk capitalism, everyone
[01:06:40.200 --> 01:06:43.760]   has skin in the game, they work together, entrepreneur board
[01:06:43.760 --> 01:06:47.880]   members to try and create a great outcome. And they work out an
[01:06:47.880 --> 01:06:50.560]   arrangement where everyone benefits. It's a win win
[01:06:50.560 --> 01:06:54.280]   situation. Okay, that is risk capitalism. That's the part of
[01:06:54.280 --> 01:06:58.120]   our economy that drives all the innovation, all the progress of
[01:06:58.120 --> 01:07:01.320]   the job creation. Then you got corny capitalism, you got these
[01:07:01.320 --> 01:07:04.640]   companies that have been around for 100 years, the value was
[01:07:04.640 --> 01:07:08.840]   created by people long dead. And it is now managed by both
[01:07:08.840 --> 01:07:12.200]   directors and professional managers who work their way up
[01:07:12.200 --> 01:07:14.560]   through they go to like the right business schools, and they
[01:07:14.560 --> 01:07:17.040]   join the right organizations, they donate the right
[01:07:17.040 --> 01:07:22.320]   politicians. And they somehow engineer a situation where they
[01:07:22.320 --> 01:07:24.960]   get in control. And then they pay themselves as much comp as
[01:07:24.960 --> 01:07:28.560]   they can possibly justify whether or not they create any
[01:07:28.560 --> 01:07:32.320]   value for the shareholder. That's what we saw at GM. And
[01:07:32.320 --> 01:07:35.280]   that's corny capitalism. And you know, while they're doing it,
[01:07:35.280 --> 01:07:38.160]   the President's son is probably going to figure out a way to
[01:07:38.160 --> 01:07:41.960]   take a nice big chunk out of it, too. Okay. Oh, that's, that's
[01:07:41.960 --> 01:07:45.800]   the system that we have co is the grade. Here we go. Now,
[01:07:45.800 --> 01:07:50.660]   which of these two systems receives the brunt of the
[01:07:50.660 --> 01:07:55.080]   criticism by the mainstream media, who is attacked? And who
[01:07:55.080 --> 01:08:00.320]   is celebrated? Okay. Here we go. There's a great point. I've
[01:08:00.320 --> 01:08:04.880]   seen a zillion attacks on Elon Musk, I saw one article pointing
[01:08:04.880 --> 01:08:07.720]   out that all of Mary bears transformation, General Motors
[01:08:07.720 --> 01:08:10.920]   was a failure, created no value for shareholders. And the whole
[01:08:10.920 --> 01:08:12.080]   thing was basically a fraud.
[01:08:12.080 --> 01:08:14.920]   Well, how's the union doing? And how did the union one article,
[01:08:14.920 --> 01:08:18.240]   and I'm frankly shocked that the Wall Street Journal even ran
[01:08:18.240 --> 01:08:21.920]   that article? Yeah, okay. Yeah. And how did the union do? And
[01:08:21.920 --> 01:08:24.440]   who did the union get behind and vote for? Yeah, let's maybe
[01:08:24.440 --> 01:08:26.800]   double click on a couple items there. We'll see. All right.
[01:08:26.800 --> 01:08:28.360]   Listen, I want to go over one more thing where we're cooking
[01:08:28.360 --> 01:08:32.000]   with oil here. And I just wanted to talk a little bit about IPOs
[01:08:32.000 --> 01:08:35.360]   possibly coming back. I just interviewed Alexis Ohanian, the
[01:08:35.360 --> 01:08:38.880]   founder of Reddit, which according to Bloomberg, they've
[01:08:38.880 --> 01:08:42.600]   been advised by potential IPO investors to target a $5 billion
[01:08:42.600 --> 01:08:45.520]   valuation, they're going to go public possibly in March, which
[01:08:45.520 --> 01:08:49.280]   is wild. That's only a couple weeks away. In peak Zerp, Reddit
[01:08:49.280 --> 01:08:52.680]   had raised at a $10 billion valuation that was back in 2021.
[01:08:53.360 --> 01:08:56.200]   They were valued in 15 billion in the secondary market. That's
[01:08:56.200 --> 01:08:59.360]   where people like previous employees, angel investors, etc
[01:08:59.360 --> 01:09:04.200]   might trade their shares. And so if it goes out of five, it's
[01:09:04.200 --> 01:09:08.680]   going to be between a 50% to their tear cut. And it is
[01:09:08.680 --> 01:09:12.600]   trading at 4.5 billion tomorrow. We talked about this a bunch of
[01:09:12.600 --> 01:09:16.680]   the down run IPOs, Instacart, I think, being the best example
[01:09:16.680 --> 01:09:21.040]   they got out, but they've been hovering at a really low number
[01:09:21.040 --> 01:09:22.960]   for a long time. And people have been talking about them
[01:09:22.960 --> 01:09:26.200]   possibly being a takeout candidate by DoorDash or Amazon
[01:09:26.200 --> 01:09:29.840]   or Uber. So your thoughts on the Reddit IPO news?
[01:09:29.840 --> 01:09:36.600]   I think that if I had to price the IPO, I would be modeling two
[01:09:36.600 --> 01:09:40.320]   important levers in the business. The first is, what is
[01:09:40.320 --> 01:09:47.200]   the actual attainable revenue from my audience? And so what is
[01:09:47.200 --> 01:09:53.480]   the ARPU of the average Reddit user? And you can model it as a
[01:09:53.480 --> 01:09:55.880]   distribution. And I think Facebook has the best data
[01:09:55.880 --> 01:09:58.840]   because they've been publishing it in their quarterly returns
[01:09:58.840 --> 01:10:02.480]   for a very long time now for over a decade, which is, there
[01:10:02.480 --> 01:10:05.760]   is a distribution of value of a Facebook user economically,
[01:10:05.760 --> 01:10:09.120]   right at the upper end, you have the folks that are on Facebook
[01:10:09.120 --> 01:10:14.160]   proper, in America, in a certain age band in certain states that
[01:10:14.160 --> 01:10:19.000]   are probably like 30, 40, $50 ARPUs, all the way down to in
[01:10:19.000 --> 01:10:22.720]   developing countries, those users are worth low single digit
[01:10:22.720 --> 01:10:27.280]   dollars economically. And I think that people will have to
[01:10:27.280 --> 01:10:31.760]   very much understand what is the average Reddit user? And what is
[01:10:31.760 --> 01:10:34.200]   the distribution of economic value that they represent?
[01:10:34.200 --> 01:10:37.200]   That's the first thing. And I think that that's really the
[01:10:37.200 --> 01:10:39.760]   thing that will determine whether it's worth 5 billion or
[01:10:39.760 --> 01:10:43.840]   10 billion, or frankly, 2 billion. And then the second key
[01:10:43.840 --> 01:10:48.640]   lever, it will be the risk factors in the IPO, because
[01:10:48.640 --> 01:10:53.080]   where the shareholder lawsuits will come from, which will
[01:10:53.080 --> 01:10:56.720]   really dictate if the how the hedge fund community buys this
[01:10:56.720 --> 01:11:02.200]   thing is going to be the potential for my ad ran against
[01:11:02.200 --> 01:11:07.240]   content that is deeply offensive to me that whole construct. And
[01:11:07.240 --> 01:11:10.480]   I think that they are going to have to very carefully ring
[01:11:10.480 --> 01:11:15.040]   fence that liability to get this IPO to be successful, but also
[01:11:15.040 --> 01:11:21.240]   for them to execute a scaled ad revenue business. And not
[01:11:21.240 --> 01:11:25.000]   spending enough time on Reddit, I don't know how bad of a
[01:11:25.000 --> 01:11:28.280]   problem this is. I don't think it's for Chan or 8chan as an
[01:11:28.280 --> 01:11:32.120]   example. But I also don't think it's Facebook and Instagram. And
[01:11:32.120 --> 01:11:34.480]   so it's kind of somewhere in the middle. And I think that those
[01:11:34.480 --> 01:11:36.960]   risks are really what's going to determine its terminal
[01:11:36.960 --> 01:11:37.520]   valuation.
[01:11:37.600 --> 01:11:40.320]   You nailed it, they they've always been under monetized
[01:11:40.320 --> 01:11:45.120]   $800 million in revenue, reportedly, and 400 million
[01:11:45.120 --> 01:11:50.240]   monthly active users. So two bucks a user, compared to 2030
[01:11:50.240 --> 01:11:55.640]   40 for the prime users in on Facebook's network. So it's
[01:11:55.640 --> 01:11:58.320]   totally underutilized part of it is it's a little bit of spicy
[01:11:58.320 --> 01:12:00.840]   content. Part of it is that that's the number including all
[01:12:00.840 --> 01:12:04.640]   the international users, of course, sacks, there is this
[01:12:04.640 --> 01:12:09.240]   concept that Reddit has the greatest pool of data for large
[01:12:09.240 --> 01:12:13.040]   language models, and, you know, something like say, Quora,
[01:12:13.040 --> 01:12:18.080]   YouTube, amongst the great pools of data. So you think there's a
[01:12:18.080 --> 01:12:20.200]   play here with that they have talked about, they want to get
[01:12:20.200 --> 01:12:22.400]   paid for licensing, and that if you want to use their data for
[01:12:22.400 --> 01:12:24.360]   your language money, you got to get permission, your thoughts,
[01:12:24.360 --> 01:12:24.720]   sacks?
[01:12:24.720 --> 01:12:27.280]   Sure. I mean, that's going to be an incremental revenue source,
[01:12:27.280 --> 01:12:29.320]   for sure. It's hard to know exactly how valuable that is,
[01:12:29.320 --> 01:12:31.760]   because we're still in the early innings. But I mean, they can
[01:12:31.760 --> 01:12:33.760]   definitely do something with that data. Grok's whole
[01:12:33.760 --> 01:12:36.760]   competitive advantage is having exclusive access to Twitter's
[01:12:36.760 --> 01:12:40.640]   data, which is updated in real time, basically by hundreds of
[01:12:40.640 --> 01:12:44.080]   millions of users. So yeah, look, that data is valuable. We
[01:12:44.080 --> 01:12:47.760]   don't know how much I guess the numbers I saw were that they're
[01:12:47.760 --> 01:12:50.160]   doing about 800 million of revenue growing about 20% a
[01:12:50.160 --> 01:12:55.560]   year. The $5 billion valuation seems, I think, pretty good. I
[01:12:55.560 --> 01:12:59.280]   mean, is it down from 10 at the peak in 2021? Sure, but
[01:12:59.280 --> 01:13:01.760]   everything is down. Since that peak. I mean, that was
[01:13:01.760 --> 01:13:04.520]   definitely a bubble. I mean, I can tell you, we bought some
[01:13:04.520 --> 01:13:08.480]   shares as a late stage investment, I think, in 2018, at
[01:13:08.480 --> 01:13:12.840]   a $2 billion valuation. So you know, a two and a half x in five
[01:13:12.840 --> 01:13:14.680]   years, I mean, it's not setting the world on fire, but it's not
[01:13:14.680 --> 01:13:18.480]   a bad outcome. Yeah. And you know, the investment bankers
[01:13:18.480 --> 01:13:20.880]   will know how to price this to take it out and make it
[01:13:20.880 --> 01:13:21.440]   successful.
[01:13:21.440 --> 01:13:24.640]   Yeah. And if it had if it was, if it becomes a billion dollars
[01:13:24.640 --> 01:13:28.960]   in revenue, and they have a 20% profit margin 200 million, you
[01:13:28.960 --> 01:13:31.080]   can you can start doing your back of the envelope math there
[01:13:31.080 --> 01:13:35.600]   for a 25 EBITDA, you know, 20 times price earnings ratio. So
[01:13:35.600 --> 01:13:39.080]   it doesn't seem outrageous. It does seem like such valuable and
[01:13:39.080 --> 01:13:43.080]   under under monetized asset. Do you think there's a likely
[01:13:43.080 --> 01:13:45.520]   acquirer here, if you were to think about somebody who might
[01:13:45.520 --> 01:13:48.320]   want to own this? Do you think it's a Microsoft for the data?
[01:13:48.320 --> 01:13:49.480]   Google for the data?
[01:13:49.480 --> 01:13:51.920]   Yeah, I think there's probably people who'd like to own this.
[01:13:51.920 --> 01:13:54.720]   But the problem is that about two problems. One is they just
[01:13:54.720 --> 01:13:57.520]   can't get it through. We've talked about this before. The M
[01:13:57.520 --> 01:14:01.640]   and A window is even more closed than the IPO window, I would
[01:14:01.640 --> 01:14:06.600]   say. And the other thing is just because of the raunchy content,
[01:14:06.600 --> 01:14:10.760]   and all of the brand issues that come with that. It's not clear
[01:14:10.760 --> 01:14:13.840]   to me that let's say a Microsoft would want to own that headache.
[01:14:13.840 --> 01:14:16.200]   You know, they might not want to be hauled up in front of these
[01:14:16.200 --> 01:14:19.120]   congressional hearings that we talked about these kangaroo
[01:14:19.120 --> 01:14:22.160]   courts, where it's very easy to go on Reddit and pick out Well,
[01:14:22.160 --> 01:14:24.480]   what about this post? What about that post? Why do you let that
[01:14:24.480 --> 01:14:26.920]   one through? Why do you let that one through? Well, because it's
[01:14:26.920 --> 01:14:29.560]   a, it's a platform of user generated content, where
[01:14:29.560 --> 01:14:33.720]   hundreds of millions of people post what billions of items. And
[01:14:33.720 --> 01:14:35.760]   you can have the best content moderation policy in the world
[01:14:35.760 --> 01:14:37.360]   is always gonna be edge cases I get through.
[01:14:37.360 --> 01:14:40.480]   I think that Reddit is the honeypot of edge cases. It is
[01:14:40.480 --> 01:14:44.040]   the place you go. Yeah. When you're just so disaffected that
[01:14:44.040 --> 01:14:46.320]   you can just let loose anonymously. It's not
[01:14:46.320 --> 01:14:48.320]   right. I mean, at a certain point, you have to you have to
[01:14:48.320 --> 01:14:52.280]   realize that when people cherry pick those edge cases, what
[01:14:52.280 --> 01:14:54.600]   they're really saying is a platform like this shouldn't
[01:14:54.600 --> 01:14:58.040]   exist. Yeah, right. Because there's no way to eliminate
[01:14:58.040 --> 01:14:59.400]   every single one.
[01:14:59.400 --> 01:15:01.760]   Or which is basically like saying if you just take
[01:15:01.760 --> 01:15:04.640]   platform, you say conversation, you're saying this conversation
[01:15:04.640 --> 01:15:05.480]   shouldn't be allowed to
[01:15:05.480 --> 01:15:08.360]   exist. I want user generated content to exist. They don't
[01:15:08.360 --> 01:15:11.200]   want on what member within your times called unfettered
[01:15:11.200 --> 01:15:13.640]   conversations, unfettered conversations. They want
[01:15:13.640 --> 01:15:19.000]   controlled conversations. Yeah. Yeah, pretty dangerous. It just
[01:15:19.000 --> 01:15:22.800]   reminds me of remember that Bob Iger for like 10 seconds was
[01:15:22.800 --> 01:15:26.920]   actually considering Disney buying Twitter. Can you imagine
[01:15:26.920 --> 01:15:30.600]   if they actually bought it? What would have happened? I mean, it
[01:15:30.600 --> 01:15:31.720]   would have been chaos.
[01:15:31.720 --> 01:15:33.840]   Well, it would have been it would have been content
[01:15:33.840 --> 01:15:37.240]   moderation on steroids where, yeah, they would have massively
[01:15:37.240 --> 01:15:40.800]   empowered and scaled up content moderation, even more than what
[01:15:40.800 --> 01:15:43.680]   jack Dorsey's Twitter was doing. So I think jack actually, he was
[01:15:43.680 --> 01:15:45.920]   unable to operationalize his principles, but he did have
[01:15:45.920 --> 01:15:50.960]   principles in favor of free speech. Whereas, Disney, I don't
[01:15:50.960 --> 01:15:54.720]   even think has those principles. So they were there. They would
[01:15:54.720 --> 01:15:55.640]   have censored everything.
[01:15:55.640 --> 01:15:58.960]   Yeah, you know, it's paradoxically the most censored
[01:15:58.960 --> 01:16:03.200]   social media platform is Tick Tock. Like, my Tick Tock is
[01:16:03.200 --> 01:16:06.880]   bulldogs and sandwiches, like you trim off and then sopranos
[01:16:06.880 --> 01:16:09.360]   clips. And every time there's a sopranos clips, when somebody
[01:16:09.360 --> 01:16:12.240]   gets whacked, they have to blur it out. Or they the person who's
[01:16:12.240 --> 01:16:15.720]   uploading, it takes that clip and cuts out the actual person
[01:16:15.720 --> 01:16:18.760]   being whacked. It's crazy. All right, I got to give sex his red
[01:16:18.760 --> 01:16:21.720]   meat. We're going to now go to our war correspondent, David
[01:16:21.720 --> 01:16:26.040]   sacks. But in all seriousness, tragically, we had a terrorist
[01:16:26.040 --> 01:16:33.360]   attack. And the response from some of our Republican senators
[01:16:33.360 --> 01:16:38.560]   was absolutely insane. They want to bomb Tehran and go after Iran
[01:16:38.560 --> 01:16:41.080]   and start World War Three sacks. I know you have some strong
[01:16:41.080 --> 01:16:44.320]   feelings on this. And you're always about diplomacy and
[01:16:44.320 --> 01:16:47.440]   pursuing peace. What's your reaction to Lindsey Graham and
[01:16:47.440 --> 01:16:51.160]   the neocons? Well, you had several Republican senators try
[01:16:51.160 --> 01:16:55.560]   to goad Biden into striking Iran immediately. It was, you know,
[01:16:55.560 --> 01:16:59.000]   not just Lindsey Graham is in favor of every war, but it was
[01:16:59.000 --> 01:17:02.960]   Mitch McConnell, Senator, Republican leader, john Cornyn,
[01:17:02.960 --> 01:17:05.080]   and there were some other ones who were, you know, demanding
[01:17:05.080 --> 01:17:09.560]   immediate retaliatory strikes. It's very unfortunate that we
[01:17:09.560 --> 01:17:13.600]   had three of our troops get killed and another dozen or so
[01:17:13.600 --> 01:17:19.280]   get injured. This was at a base on the border between Syria and
[01:17:19.280 --> 01:17:23.120]   Jordan. Some of us have been saying that we have no business
[01:17:23.120 --> 01:17:26.280]   being in Syria. I mean, I tweeted 10 months ago, that all
[01:17:26.280 --> 01:17:31.120]   we were doing was putting our troops in harm's way, and
[01:17:31.120 --> 01:17:35.000]   risking getting drawn into a larger conflagration. And that's
[01:17:35.000 --> 01:17:39.000]   exactly where we are right now. I mean, you had to know, and
[01:17:39.000 --> 01:17:42.240]   many commentators pointed out that these bases are very
[01:17:42.240 --> 01:17:45.560]   exposed, they're very vulnerable, they don't have good
[01:17:45.560 --> 01:17:48.320]   enough air defense against they don't really have a good answer
[01:17:48.320 --> 01:17:54.400]   to the swarms of drones that these local militias have. And
[01:17:54.400 --> 01:17:58.920]   based on the intelligence we have right now, are the space
[01:17:58.920 --> 01:18:02.720]   this tower 22 was attacked by an Iraqi militia that's operating
[01:18:02.720 --> 01:18:07.520]   that there. Why did they get attacked? Well, these militias
[01:18:07.520 --> 01:18:10.400]   want the United States out of their countries, they want them
[01:18:10.480 --> 01:18:14.000]   out of Iraq, the government of Iraq has said we want the US out
[01:18:14.000 --> 01:18:17.240]   of Iraq, the government of Syria says we want you out of Syria.
[01:18:17.240 --> 01:18:21.960]   We are there without a congressional authorization for
[01:18:21.960 --> 01:18:26.320]   military force. I mean, what are we doing in Syria, we're just
[01:18:26.320 --> 01:18:31.000]   occupying that country without, again, without a war being ever
[01:18:31.000 --> 01:18:34.960]   declared against the Assad regime. So some of us have been
[01:18:34.960 --> 01:18:37.080]   saying we need to get out there for some time. And if we don't,
[01:18:37.080 --> 01:18:39.080]   it's inevitable that something like this is going to happen.
[01:18:39.280 --> 01:18:42.040]   And sure enough, it did. And when it does happen, you get
[01:18:42.040 --> 01:18:44.320]   this lunatic fringe, who unfortunately are some of the
[01:18:44.320 --> 01:18:48.360]   leaders of the Republican Party, calling for a larger war against
[01:18:48.360 --> 01:18:53.200]   Iran. And I think Biden to his credit, so far held back. And he
[01:18:53.200 --> 01:18:58.160]   has not a lot of restraint, however, they've been actively
[01:18:58.160 --> 01:19:00.960]   talking about this. And all the reports are they're gaming this
[01:19:00.960 --> 01:19:04.320]   out. And there is going to be some sort of retaliatory strike.
[01:19:04.660 --> 01:19:09.540]   It might be focused on these militias in Syria and Iraq, it
[01:19:09.540 --> 01:19:13.260]   could be attacking Iranian assets, we don't know, if they
[01:19:13.260 --> 01:19:17.820]   do attack Iranian assets, Iran has promised a response. So I
[01:19:17.820 --> 01:19:20.180]   think the Biden presidency is a little bit of a crossroads here,
[01:19:20.180 --> 01:19:22.900]   depending on the action they choose, we could very rapidly
[01:19:22.900 --> 01:19:27.820]   find ourselves engaged in a wider regional war on five
[01:19:27.820 --> 01:19:32.780]   different fronts. I mean, a war with Iran would involve us in
[01:19:32.900 --> 01:19:36.540]   Iran, Iraq, Syria, Lebanon, and Yemen, where we're already
[01:19:36.540 --> 01:19:41.320]   bombing. So this could turn into a huge conflagration in the
[01:19:41.320 --> 01:19:44.620]   Middle East. Yeah, I don't think we should be drawn into this.
[01:19:44.620 --> 01:19:48.620]   Yeah, no, the answer is here. And yeah, the craziness to me,
[01:19:48.620 --> 01:19:53.180]   Jamal is like, these people want to go bomb Tehran, because you
[01:19:53.180 --> 01:19:57.540]   have, you know, some militias doing these activities. I mean,
[01:19:57.540 --> 01:20:01.260]   this like would be, you know, some terrorist, who's French,
[01:20:01.260 --> 01:20:04.060]   we're going to just blow up Paris, and a bunch of civilians
[01:20:04.060 --> 01:20:06.220]   are going to die. It's there's no proportionality here. And
[01:20:06.220 --> 01:20:09.540]   there's, and there's, there's no direct relationship here. It's
[01:20:09.540 --> 01:20:11.540]   like two or three steps removed. What are your thoughts, Jamal?
[01:20:11.540 --> 01:20:17.740]   I think the thing that we've lost in this whole issue is, how
[01:20:17.740 --> 01:20:21.620]   is it possible that a multi decade billion dollar drone
[01:20:21.620 --> 01:20:26.940]   system was designed by the military industrial complex in a
[01:20:26.940 --> 01:20:30.260]   way where when one of our drones is coming back, and there's an
[01:20:30.260 --> 01:20:34.460]   inbound drone, that doesn't seem like a weird edge case, where we
[01:20:34.460 --> 01:20:37.380]   couldn't handle it. Because at the at the root cause of what
[01:20:37.380 --> 01:20:42.140]   happened was a pretty faulty way in which we were dealing with
[01:20:42.140 --> 01:20:46.380]   confusion about what was our drone and what was the enemy
[01:20:46.380 --> 01:20:50.540]   drone. And I think that that's also worth talking about before
[01:20:50.540 --> 01:20:53.940]   we talk about bombing another country is we're the most
[01:20:53.940 --> 01:20:56.540]   sophisticated technological country in the world, our weapon
[01:20:56.540 --> 01:20:58.780]   systems are the most sophisticated weapon systems in
[01:20:58.780 --> 01:21:02.500]   the world. Am I supposed to believe that if Palmer lucky and
[01:21:02.500 --> 01:21:05.340]   Andrew were building this system, that this is what would
[01:21:05.340 --> 01:21:08.580]   have happened? Absolutely not. Yeah, that there's no beaconing
[01:21:08.580 --> 01:21:11.140]   system on these drones that you could turn on remotely that
[01:21:11.140 --> 01:21:14.780]   there's no way when you see the number of drones in an aerospace
[01:21:14.780 --> 01:21:17.180]   that are yours, so that you can quickly triangulate which ones
[01:21:17.180 --> 01:21:20.740]   are not yours. And all of this, to me, I think is also worth
[01:21:20.740 --> 01:21:25.220]   exploring, because if it's really, again, faulty
[01:21:25.220 --> 01:21:30.500]   engineering, because of this monopoly oligopoly in certain
[01:21:30.500 --> 01:21:34.100]   sectors of our economy, that then cause us to go and make a
[01:21:34.100 --> 01:21:37.300]   foreign relations decision about going to war. And we don't even
[01:21:37.300 --> 01:21:40.140]   talk about this thing as a root cause it's worth talking about a
[01:21:40.140 --> 01:21:43.660]   different example. On the same vein of this is like, it turned
[01:21:43.660 --> 01:21:48.620]   out that in that Alaska Airlines issue, they actually shipped the
[01:21:48.620 --> 01:21:53.500]   plane without the door plugs. Oops, we are the most
[01:21:53.500 --> 01:21:57.860]   sophisticated country in the world, guys. Our most
[01:21:57.860 --> 01:22:02.540]   sophisticated industries are not showing their best in this
[01:22:02.540 --> 01:22:06.020]   moment. And I think that this is yet another example of before we
[01:22:06.020 --> 01:22:10.300]   make totally separate decisions about war and implicating our
[01:22:10.300 --> 01:22:14.100]   children's safety. We can also just ask, wait, we spent
[01:22:14.100 --> 01:22:17.380]   billions of dollars on this thing. How is it possible that
[01:22:17.380 --> 01:22:20.940]   this that this, like, honestly, like, this is exception
[01:22:20.940 --> 01:22:25.020]   handling. This is like, CS one on one type stuff, guys.
[01:22:25.020 --> 01:22:30.660]   Put the plugs in the door and it's regulatory captures the
[01:22:30.660 --> 01:22:32.340]   answer. This is crazy.
[01:22:32.340 --> 01:22:35.220]   There's no competition, and they're they're charging costs.
[01:22:35.220 --> 01:22:37.940]   Plus, they're not innovating anymore. And they need
[01:22:37.940 --> 01:22:41.380]   competition, right? Just like SpaceX was massive competition
[01:22:41.380 --> 01:22:44.620]   for all of the governmental agencies around.
[01:22:44.660 --> 01:22:51.260]   We have the execution in our industrial complex. And now the
[01:22:51.260 --> 01:22:55.020]   way to answer that turns out to be a foreign policy decision to
[01:22:55.020 --> 01:22:57.540]   go to war. And I think that those two things need to be
[01:22:57.540 --> 01:23:00.740]   decoupled for a second so that we can deescalate and say, hold
[01:23:00.740 --> 01:23:04.380]   on a second, this thing happened. But why did it happen?
[01:23:04.380 --> 01:23:07.620]   Meaning? Yeah, of course, people are going to attack us. We are
[01:23:07.620 --> 01:23:10.860]   the bright shining beacon on a hill. People should hate us and
[01:23:10.860 --> 01:23:13.420]   want to attack us. That's just the nature of being a winner.
[01:23:13.540 --> 01:23:16.340]   To be fair, they're not attacking us. Because we're the
[01:23:16.340 --> 01:23:18.620]   shining city on a hill over here, just minding our own
[01:23:18.620 --> 01:23:21.540]   business. They're attacking us because we're no, I know that
[01:23:21.540 --> 01:23:26.020]   Iraq. But yes, that yes, we should expect that these things
[01:23:26.020 --> 01:23:29.620]   work, we should expect it. So there's a few things happening
[01:23:29.620 --> 01:23:32.260]   here with our military industrial complex. So the first
[01:23:32.260 --> 01:23:34.980]   one is that drones have been a huge game changer. We've seen
[01:23:34.980 --> 01:23:39.300]   this in the Ukraine war. The one really new technological element
[01:23:39.340 --> 01:23:43.700]   has been drones has completely changed the face of war. And one
[01:23:43.700 --> 01:23:46.860]   of the things it does, it's a huge leveler, because these
[01:23:46.860 --> 01:23:51.140]   cheap drones give these militias in Syria and Iraq, or it gives
[01:23:51.140 --> 01:23:54.860]   the Houthis in Yemen, a capability to strike at us that
[01:23:54.860 --> 01:23:58.740]   they didn't have before. And we saw that our air defenses are
[01:23:58.740 --> 01:24:01.980]   just not really cut out to deal with this. There was that
[01:24:01.980 --> 01:24:06.380]   article describing how it was costing us $2 million to use an
[01:24:06.380 --> 01:24:10.740]   air defense missile to shoot down a drone, or a cheap rocket
[01:24:10.740 --> 01:24:15.980]   that costs just a few $1,000. So you have this asymmetric warfare
[01:24:15.980 --> 01:24:20.980]   now, where we simply cannot afford over sustained period to
[01:24:20.980 --> 01:24:22.900]   shoot down all these drones.
[01:24:22.900 --> 01:24:26.180]   But wait, sorry, can I ask a question? Yeah. Our most
[01:24:26.180 --> 01:24:31.980]   important partner in that region is Israel. Israel has what we
[01:24:31.980 --> 01:24:35.580]   have thought to up until now, an impregnable system, right, the
[01:24:35.580 --> 01:24:39.500]   Iron Dome, and which is meant to deal with all of these edge
[01:24:39.500 --> 01:24:43.660]   cases, right, projectiles of all sorts, shapes and sizes coming
[01:24:43.660 --> 01:24:46.580]   in every direction. Yeah, I've never heard of when the Iron
[01:24:46.580 --> 01:24:50.540]   Dome has failed. And we are sending Israel billions of
[01:24:50.540 --> 01:24:52.980]   dollars. Why couldn't we actually just buy the Iron Dome
[01:24:52.980 --> 01:24:55.260]   system for them and say, you know what, we're going to secure
[01:24:55.260 --> 01:24:58.980]   our bases in Syria. And in all these other places? Yeah.
[01:24:58.980 --> 01:25:01.820]   Well, I'll tell you. So there's a military analyst named Stephen
[01:25:01.820 --> 01:25:05.300]   Bryan, who I follow as a former Undersecretary of Defense, and
[01:25:05.300 --> 01:25:09.100]   he talked about this. He has been calling now for before this
[01:25:09.100 --> 01:25:13.660]   attack happened to send to Iron Dome systems to Syria to Iraq to
[01:25:13.660 --> 01:25:16.500]   basically the Middle East to protect our troops. He says he
[01:25:16.500 --> 01:25:19.340]   said in his article, the reason why the US Army hasn't done
[01:25:19.340 --> 01:25:22.140]   that is because they didn't want to buy the Israeli system.
[01:25:22.140 --> 01:25:24.540]   They've been favoring some homegrown system that has
[01:25:24.540 --> 01:25:28.180]   improved. There's a there's a big problem there that we should
[01:25:28.180 --> 01:25:31.140]   be deploying Iron Dome there. Look, I would just get out of
[01:25:31.140 --> 01:25:33.540]   that area. I don't think we should be there. But at a
[01:25:33.540 --> 01:25:35.460]   minimum, if we are going to stay there, we have to protect our
[01:25:35.460 --> 01:25:38.620]   troops. So yes, we should be deploying Iron Dome. But the
[01:25:38.620 --> 01:25:43.140]   problem is that again, just these drones are a game changer
[01:25:43.140 --> 01:25:47.300]   and they can overwhelm a system even Iron Dome can be
[01:25:47.300 --> 01:25:51.060]   overwhelmed. If Israel gets in a war with Hezbollah, which
[01:25:51.060 --> 01:25:55.540]   supposedly has one drone, it's n equals one, we were overwhelmed
[01:25:55.540 --> 01:25:59.980]   by n equals one. Well, I mean, I'm just I'm saying like, it's
[01:25:59.980 --> 01:26:03.620]   true, right? We were overwhelmed. When n equals one,
[01:26:03.620 --> 01:26:06.820]   there was a report just the other day that one of our ships
[01:26:06.820 --> 01:26:14.340]   in the Red Sea, it was fired on by a missile from Yemen. And it
[01:26:14.340 --> 01:26:17.060]   made it through the Aegis system. And they they took it
[01:26:17.060 --> 01:26:19.540]   down with their last line of defense, these like close in
[01:26:19.540 --> 01:26:24.100]   guns. That was kind of scary, because the Houthis have
[01:26:24.100 --> 01:26:26.900]   missiles that are capable of making it through our main air
[01:26:26.900 --> 01:26:30.340]   defense system for ships. So I'm just saying like these what's
[01:26:30.340 --> 01:26:32.580]   happening with these cheap rockets and these drones is
[01:26:32.580 --> 01:26:36.340]   it's giving our opponents capabilities that level the
[01:26:36.340 --> 01:26:37.380]   playing field a little bit.
[01:26:37.380 --> 01:26:39.780]   But this is what I'm saying. I understand that concept. But I
[01:26:39.780 --> 01:26:42.420]   also understand that we have people on the ground that work
[01:26:42.420 --> 01:26:46.020]   for Team America. Again, I'll just I'll take Palmer lucky as
[01:26:46.020 --> 01:26:49.500]   the example, who frankly, I would bet on 1000 times over a
[01:26:49.500 --> 01:26:53.340]   Houthi rebel, he'll outsmart now power these guys. Why aren't our
[01:26:53.340 --> 01:26:55.740]   best and brightest people in a position to make these things?
[01:26:55.980 --> 01:26:58.820]   Well, because you're right, the defense industry is dominated by
[01:26:58.820 --> 01:27:02.500]   five of these prime defense contractors who work on cost
[01:27:02.500 --> 01:27:05.260]   plus are basically an oligopoly. They're not particularly
[01:27:05.260 --> 01:27:08.220]   innovative, but they just keep charging more every year for the
[01:27:08.220 --> 01:27:10.820]   same product. So we're getting less for more money.
[01:27:10.820 --> 01:27:14.660]   And they're led by leadership, who are motivated in a way
[01:27:14.660 --> 01:27:17.900]   where the returns that they generate and the success and the
[01:27:17.900 --> 01:27:20.860]   progress they make is not really coupled to progress, right? It's
[01:27:20.860 --> 01:27:24.540]   not really coupled to building an even better version of Iron
[01:27:24.540 --> 01:27:28.700]   Dome. It's about, as you said, having a job that you've earned
[01:27:28.700 --> 01:27:33.020]   over many years of fealty, and then getting paid an enormous
[01:27:33.020 --> 01:27:36.340]   amount of money to just keep it going in the same direction, even
[01:27:36.340 --> 01:27:39.260]   if that direction means you've been adrift for decades. That's
[01:27:39.260 --> 01:27:42.140]   the shame of it. And then you're seeing every day, like, isn't it
[01:27:42.140 --> 01:27:42.780]   incredible?
[01:27:42.780 --> 01:27:46.580]   Graham is saying hit Iran. And I bet you Lindsey Graham is to
[01:27:46.580 --> 01:27:49.100]   getting donations from those five companies. I don't I don't
[01:27:49.100 --> 01:27:49.620]   know. But
[01:27:49.620 --> 01:27:53.180]   look, there's no question that we need to shake up the military
[01:27:53.180 --> 01:27:55.820]   industrial complex, we need to get a lot more startups in
[01:27:55.820 --> 01:28:00.340]   there. There's a lot of VCs now who are funding. Yeah, defense
[01:28:00.340 --> 01:28:03.180]   startups. So it is a big area. Andrew, obviously, is kind of
[01:28:03.180 --> 01:28:04.780]   the leader of the pack, but there's a bunch of others
[01:28:04.780 --> 01:28:07.780]   getting funded. I saw that Eric Schmidt even created a drone
[01:28:07.780 --> 01:28:13.020]   company. So this is gonna be a huge area of innovation. And I
[01:28:13.020 --> 01:28:17.580]   think that because of the Ukraine war, the Pentagon must
[01:28:17.580 --> 01:28:22.140]   now realize the urgency of being able to mass produce effective
[01:28:22.140 --> 01:28:26.220]   drones, as well as create effective drone air to
[01:28:26.220 --> 01:28:28.620]   countermeasures. Yeah, countermeasures. Yeah, just to
[01:28:28.620 --> 01:28:33.260]   give you a sense of this, like we led the series eight, a
[01:28:33.260 --> 01:28:37.300]   company called sail drone about seven years ago. And they make
[01:28:37.300 --> 01:28:40.860]   drones for the seas. Right. And what we did was we put these
[01:28:40.860 --> 01:28:45.340]   massive sensor arrays in these drones. And because of because
[01:28:45.340 --> 01:28:50.620]   of the sensors, it has perfect visibility into what's going on
[01:28:50.900 --> 01:28:53.780]   in any condition of weather, right day, night, it doesn't
[01:28:53.780 --> 01:28:57.660]   matter. And so these drones in the Middle East, all over the
[01:28:57.660 --> 01:29:01.180]   waterways allows us to have perfect understanding of what's
[01:29:01.180 --> 01:29:05.060]   going on. But despite that, it has taken years for us to be in
[01:29:05.060 --> 01:29:08.180]   a position to generate enough revenue. And now we're finally
[01:29:08.180 --> 01:29:12.500]   at that scale with the Navy and whatnot. But David, to your
[01:29:12.500 --> 01:29:16.300]   point, it is incredibly hard for startups, no matter how
[01:29:16.300 --> 01:29:20.620]   innovative we've been to break through this logjam. And the
[01:29:20.620 --> 01:29:23.700]   reason is, because what we are good at is not what's rewarded,
[01:29:23.700 --> 01:29:27.300]   we are good at engineering and execution. But what is rewarded,
[01:29:27.300 --> 01:29:31.780]   to your point is this very lobbying, specific form of
[01:29:31.780 --> 01:29:36.740]   relationship management, right? And cultivating certain pockets
[01:29:36.740 --> 01:29:40.020]   of influence. It's a very difficult game to play. If what
[01:29:40.020 --> 01:29:43.340]   we come as bright eyed bushy tailed from California with a
[01:29:43.340 --> 01:29:45.780]   product that we think is superior, that actually helps
[01:29:45.780 --> 01:29:49.780]   advance American exceptionalism. It still doesn't always land, it
[01:29:49.780 --> 01:29:52.420]   takes a lot longer than it needs to, in some cases.
[01:29:52.420 --> 01:29:55.660]   Yeah, I mean, so the Pentagon and the military industrial
[01:29:55.660 --> 01:29:58.780]   complex is going to be a lot more permeable to this type of
[01:29:58.780 --> 01:30:01.820]   innovation. I think that they're going to be incentivized to do
[01:30:01.820 --> 01:30:05.020]   it now. Because they have to see what's happening in Ukraine,
[01:30:05.020 --> 01:30:07.900]   what's happening in the Middle East, and they realized that the
[01:30:07.900 --> 01:30:08.900]   gap is closed.
[01:30:08.900 --> 01:30:11.340]   And we had three innocent people that were killed. These people
[01:30:11.340 --> 01:30:14.300]   didn't deserve to die. They didn't deserve to die in an end
[01:30:14.300 --> 01:30:17.940]   of one. It's not an edge case and have one there was a drone.
[01:30:18.940 --> 01:30:20.180]   Come on, guys, we're better than that.
[01:30:20.180 --> 01:30:22.580]   And so what do you think is gonna happen if we get in a war
[01:30:22.580 --> 01:30:26.940]   with Iran, every single one of our bases in Syria and Iraq, and
[01:30:26.940 --> 01:30:28.780]   we have a lot are going to be sitting ducks
[01:30:28.780 --> 01:30:31.020]   to your point, you're forecasting you're you're
[01:30:31.020 --> 01:30:33.700]   orchestrating a game plan for them. Because it's like, if you
[01:30:33.700 --> 01:30:36.820]   if you were going to enter a war, does it take a brilliant
[01:30:36.820 --> 01:30:38.820]   strategist to sit in a room and say, Wait a minute, if they
[01:30:38.820 --> 01:30:42.100]   can't defend against one, what happens when we send 12? What
[01:30:42.100 --> 01:30:45.260]   happens when we send 12 to every single place? And to your point,
[01:30:45.300 --> 01:30:49.180]   Jason, it's this is like the unnecessary escalation that then
[01:30:49.180 --> 01:30:53.460]   happens, because then we have to respond with more force. Well,
[01:30:53.460 --> 01:30:55.060]   and with more kinetic energy,
[01:30:55.060 --> 01:30:58.980]   it was a certainty. Look, I've been talking on the show about
[01:30:58.980 --> 01:31:02.860]   how our bases in Syria and Iraq have been under attack by these
[01:31:02.860 --> 01:31:05.780]   militias for months. I think the last time we talked about it,
[01:31:05.780 --> 01:31:08.580]   there had been something like 80 attacks. And it was just a
[01:31:08.580 --> 01:31:12.660]   matter of time before Americans, servicemen were were killed,
[01:31:12.700 --> 01:31:16.700]   unfortunately. And so like you said, this was predictable.
[01:31:16.700 --> 01:31:20.300]   What's also predictable is that if we get a war with Iran, every
[01:31:20.300 --> 01:31:23.220]   single one of our bases will be attacked. If we strike on their
[01:31:23.220 --> 01:31:26.660]   soil, they will strike back. And they have hypersonic missiles,
[01:31:26.660 --> 01:31:30.900]   they have precision missiles, they can destroy every one of
[01:31:30.900 --> 01:31:33.620]   these bases, unless those bases have the top of the line air
[01:31:33.620 --> 01:31:37.100]   defense, which most of them don't. But if you go to someone
[01:31:37.100 --> 01:31:39.820]   like Lindsey Graham and say, Listen, our troops are
[01:31:39.820 --> 01:31:43.100]   vulnerable, we need to basically either pull out of
[01:31:43.100 --> 01:31:46.780]   Syria and Iraq, or we need to consolidate down to a few bases
[01:31:46.780 --> 01:31:49.900]   that have Iron Dome or the best systems. These neocons will say
[01:31:49.900 --> 01:31:52.100]   absolutely not, we're not conceding anything.
[01:31:52.100 --> 01:31:55.300]   So they would they would never pick up a gun. They never wear
[01:31:55.300 --> 01:31:59.980]   uniform, right? They want us to strike Iran. So these these
[01:31:59.980 --> 01:32:04.820]   strategies don't line up. If you wanted to attack Iran, the first
[01:32:04.820 --> 01:32:07.460]   thing you would do is basically get all of our troops out of
[01:32:07.460 --> 01:32:10.660]   harm's way, who are currently sitting docks for Irani
[01:32:10.660 --> 01:32:13.700]   retaliation. By the way, I think it'd be a terrible idea. But
[01:32:13.700 --> 01:32:16.820]   that's what you do. So they have these strategies that don't make
[01:32:16.820 --> 01:32:17.460]   any sense.
[01:32:17.460 --> 01:32:22.140]   All right, everybody. It's been an amazing show for the dictator
[01:32:22.140 --> 01:32:25.500]   chairman himself. Shemoth Palihapitiya, the rain man. Yeah,
[01:32:25.500 --> 01:32:29.020]   David Sachs. I am the world's greatest moderator. We missed
[01:32:29.020 --> 01:32:31.860]   you. Sultan of science, David Fribourg couldn't make the show.
[01:32:31.860 --> 01:32:36.580]   And we'll see he's still in if anybody gets into the Apple Pro
[01:32:36.580 --> 01:32:41.500]   Vision Vision Pro. And is somewhere out in the universe by
[01:32:41.500 --> 01:32:43.980]   Uranus. And you see I'm bringing back for next week. So I'm gonna
[01:32:43.980 --> 01:32:46.740]   go find him. We got to send out a search party to Uranus. Love
[01:32:46.740 --> 01:32:49.900]   you boys. Bye bye bye bye.
[01:32:49.900 --> 01:32:52.820]   Let your winners ride.
[01:32:52.820 --> 01:32:55.700]   Rain Man David Sachs.
[01:32:55.700 --> 01:33:02.260]   We open source it to the fans and they've just gone crazy with
[01:33:02.260 --> 01:33:03.260]   it. Love you guys.
[01:33:03.260 --> 01:33:04.820]   I'm the queen of Kinwana.
[01:33:04.820 --> 01:33:06.460]   I'm going all in.
[01:33:06.460 --> 01:33:09.180]   Let your winners ride. Let your winners ride.
[01:33:09.180 --> 01:33:12.780]   Besties are gone.
[01:33:12.780 --> 01:33:16.300]   That's my dog taking a notice in your driveway.
[01:33:16.300 --> 01:33:24.660]   We should all just get a room and just have one big huge orgy
[01:33:24.660 --> 01:33:26.540]   because they're all just useless. It's like this like
[01:33:26.540 --> 01:33:28.780]   sexual tension that we just need to release somehow.
[01:33:29.980 --> 01:33:36.780]   Let your beat be. Let your beat be. We need to get besties are
[01:33:36.780 --> 01:33:37.060]   gone.
[01:33:37.060 --> 01:33:46.660]   I'm going all in.
[01:33:46.660 --> 01:33:48.720]   you

