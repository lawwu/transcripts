
[00:00:00.000 --> 00:00:11.840]   Thank you very much Charles and Kayla. So I'm quite excited to present our recent research work jointly done at Zurich University of Applied Sciences and Ulm University.
[00:00:11.840 --> 00:00:18.080]   And this work is about integrating radial basis function networks.
[00:00:18.080 --> 00:00:23.200]   To convolutional neural networks and using them for computer vision.
[00:00:24.640 --> 00:00:36.400]   This research is guided with my PhD advisor Friedhelm Schwenker from Ulm University and motivated by my second PhD advisor Tilo Stadelmann from Zurich University of Applied Sciences.
[00:00:36.400 --> 00:00:47.840]   So the radial basis function neural networks are three layer neural networks. They have been introduced first in 1988.
[00:00:48.520 --> 00:01:02.760]   For a given input feature vector in the forward pass firstly compute the distances of these features to some cluster centers which are encoded in the hidden layer and afterwards we apply a
[00:01:02.760 --> 00:01:15.800]   activation function to these distances and then train a output weight in order that to specify the classes. Radial basis function can also be used for regression.
[00:01:17.240 --> 00:01:28.320]   In this research we adopted the training process of the RBFs and also proposed an activation function in order that they can be integrated into CNNs.
[00:01:28.320 --> 00:01:39.080]   And as an advantage, we actually can learn a similarity distance metric and we could also interpret the decision process of
[00:01:40.760 --> 00:01:49.800]   the computer vision models using RBFs by looking at the clusters and distribution of the training and test samples around the clusters.
[00:01:49.800 --> 00:01:58.200]   You're welcome. And the related work that's related to the RBF networks are divided into three categories.
[00:01:58.200 --> 00:02:08.520]   So some works are focusing on the training process. There are different type of training process one, two, and three phase learning for RBFs.
[00:02:09.400 --> 00:02:18.160]   And here we actually combined two phases of training the RBFs by combining supervised and unsupervised learning.
[00:02:18.160 --> 00:02:24.400]   There are several different activation functions proposed in the literature for RBF networks based on
[00:02:24.400 --> 00:02:36.160]   different applications and here we propose a quadratic function in order that we can have a completely linear computational graph for efficient gradient flow for CNNs.
[00:02:37.280 --> 00:02:55.640]   And in terms of applications CNNs are used for classification, regression, and even function mathematical function interpolation. So here we present the first attempt of using RBFs in conjunction with CNNs for computer vision.
[00:02:55.640 --> 00:03:03.120]   And here I explain the training process of radial basis networks.
[00:03:04.280 --> 00:03:16.640]   In the hidden layer, as I mentioned earlier, the cluster centers are encoded. Here you can see an unsupervised loss inspired by K-means algorithm. The first sum shows
[00:03:16.640 --> 00:03:22.640]   an average over the clusters and the second is aimed at minimizing the
[00:03:22.640 --> 00:03:33.800]   distance between a feature vectors and a cluster center. Traditionally, the feature space used to be fixed for radial basis function networks.
[00:03:34.240 --> 00:03:39.800]   But in the architecture that we use it, we feed the embeddings of CNNs which are trained
[00:03:39.800 --> 00:03:52.880]   during the training process. So the input features of the RBFs are not fixed anymore. Therefore, we include this loss function in the training in order that the cluster centers are updated
[00:03:52.880 --> 00:03:58.640]   during the training process of the RBF networks and CNNs.
[00:04:00.280 --> 00:04:07.640]   Then we have to compute the distance. As you can see, the distance can be defined based on a distance metric. If the
[00:04:07.640 --> 00:04:18.040]   distance metric could be Euclidean distance. If we train the main diagonal of the covariance metrics, then we end up with having a Mahalanobis distance.
[00:04:18.040 --> 00:04:26.200]   And the entire covariance metrics can also be learned. And we can write it in terms of metrics multiplication, as you can see over here.
[00:04:27.440 --> 00:04:29.960]   Then we apply activations.
[00:04:29.960 --> 00:04:40.400]   And at the end, we can estimate the ground truth label shown by Y by a multiplication of output weights and the activations.
[00:04:42.920 --> 00:04:52.920]   And initializing the clusters are basically the second phase of the optimization and the one phase training algorithm of RBF only
[00:04:52.920 --> 00:05:03.400]   only computes the weights of the output layer. And the third phase is fine tuning the model using gradient descent end to end.
[00:05:09.360 --> 00:05:14.200]   In order to adopt the RBFs to CNNs, as we said, we first
[00:05:14.200 --> 00:05:21.680]   we connect the backbone of the CNNs via a fully connected layer to the RBFs.
[00:05:21.680 --> 00:05:32.840]   So in principle, we flatten the features and use a fully connected without any type of activation here. So experimentally, I noticed that
[00:05:33.760 --> 00:05:39.240]   RBFs don't work very well with dropout. Therefore, this
[00:05:39.240 --> 00:05:54.360]   layer is necessary. And since we have parameters, both in the hidden layer and output layer, if we use the original feature space, we easily undergo overfitting. So a
[00:05:54.360 --> 00:06:03.360]   fully connected layer to convert the output of the CNNs into a lower dimensional space is necessary here.
[00:06:04.360 --> 00:06:12.360]   Afterwards, we have the computation of the distance using metrics multiplication and our proposed activation is just
[00:06:12.360 --> 00:06:20.960]   an addition and division by constants, which shows the width of the kernel.
[00:06:20.960 --> 00:06:25.040]   And at the end during the optimization, we
[00:06:26.440 --> 00:06:42.200]   optimize the unsupervised loss and minimize it, as I mentioned earlier, and we will have a supervised loss, which could be a normal softmax cross entropy or any type of other loss that we would like to optimize for classification or regression.
[00:06:42.200 --> 00:06:56.400]   In this slide, I would like to show you how the training process works in practice. For this slide, I will show you
[00:06:57.400 --> 00:07:08.400]   the training process in a more general way. So in this slide, I used the MNIST dataset and on the right and left, you can see the two dimensional representation of first
[00:07:08.400 --> 00:07:22.400]   the input of the RBF, which is the embeddings of the CNNs and the activations of the clusters, basically after computing the distance and applying the activation functions.
[00:07:23.160 --> 00:07:36.640]   The other loss is more prominent, means that during the training process, the data samples are divided into clusters, which are not corresponding to the ground truth labels.
[00:07:36.640 --> 00:07:40.200]   On the right,
[00:07:42.080 --> 00:07:55.400]   the loss is more prominent, means supervised loss, and you can see that the data samples are dividing into clusters during the training process based on the ground truth labels.
[00:07:55.400 --> 00:08:07.080]   In the middle figure, I demonstrated the samples around a cluster center. So you can imagine that the center of the cluster is at zero and zero.
[00:08:07.560 --> 00:08:17.960]   These samples are distributed with a random angle based on their distance to the center of this cluster. Here is where both losses interact.
[00:08:17.960 --> 00:08:27.960]   The unsupervised loss tries to bring all the samples as close as possible to the center, as I explained earlier.
[00:08:28.600 --> 00:08:44.200]   And the supervised loss tries to put the samples from the same clusters with the same space from the cluster center. So this is why you can see some circles with the samples from same clusters around this cluster.
[00:08:44.200 --> 00:08:54.440]   And this process continues during the training of the CNN and RBF architecture.
[00:08:54.440 --> 00:08:57.560]   Furthermore, we used some
[00:08:57.560 --> 00:09:09.440]   benchmark computer vision datasets in order to confirm that this architecture can work for more complicated problems.
[00:09:10.400 --> 00:09:17.360]   Though we noticed that picking the correct set of hyperparameter, including number of clusters,
[00:09:17.360 --> 00:09:24.960]   as well as the dimensionality of the input and dimensionality of the RBF is not
[00:09:24.960 --> 00:09:33.880]   all the time trivial. So we had to use the Vade and Biases toolbox in order to have a hyperparameter search.
[00:09:35.240 --> 00:09:51.560]   And we also use the auto augment for augmenting our images to improve the performance. So at the end, we noticed that the radial basis function networks can work with a wide range of
[00:09:53.000 --> 00:10:01.480]   CNN backbones, such as efficient net and networks, including inception blocks, as well as the residual connections, though there is a
[00:10:01.480 --> 00:10:16.720]   small gap between the performances that we can achieve using RBFs on the top of CNNs and the state of the art, which is actually due to the overfitting. So we noticed that the training
[00:10:17.360 --> 00:10:30.560]   dataset can be learned very well, but we need to have novel methods for regularization of the RBFs.
[00:10:30.560 --> 00:10:32.600]   At the end,
[00:10:35.640 --> 00:10:52.320]   the metric that we learn based on the architecture of the RBFs can be used to find similar and dissimilar images. You can see that we apply it to the pet dataset, the dataset of aircrafts, as well as birds.
[00:10:53.200 --> 00:11:12.160]   And we can take a look at the position of the test images and corresponding closer train images around every cluster. This is not necessarily at the moment interpretable based on the ground truth label, since as I visualized in the training process as well,
[00:11:13.600 --> 00:11:25.760]   these clusters are learned completely unsupervised and they are not necessarily, the position of the samples are not necessarily relate to their labels.
[00:11:25.760 --> 00:11:38.840]   At the end, we had to modify the activation of the RBFs, as well as its training process in order to integrate it into CNNs.
[00:11:39.840 --> 00:11:50.520]   We have comparable results with the state of the arts, but there is still a gap and the RBFs provide us with the opportunity to
[00:11:50.520 --> 00:11:52.560]   have a
[00:11:52.560 --> 00:11:59.760]   more interpretable methods and decision making process.
[00:12:00.920 --> 00:12:17.080]   So maybe one of the most important questions for further investigation would be that the regularization techniques for RBF in order to fill the gap between our performances and the state of the art.
[00:12:17.080 --> 00:12:25.080]   Thank you very much for your attention and I'm very willing to hear your questions.
[00:12:27.720 --> 00:12:39.520]   Great. So folks have questions, either on YouTube or on Zoom, type them into your respective live chats and we'll pass them on to Mohamed Reza.
[00:12:39.520 --> 00:12:50.160]   So my first question was a little bit about the sort of readout layer on these things. So you said that you could use either a cross entropy loss or something else.
[00:12:51.200 --> 00:12:57.560]   So could you talk a little bit more about those choices and how you implement them, how you use them?
[00:12:57.560 --> 00:13:09.920]   Yeah, I mean, the output layer is actually very similar to the normal output layers that we kind of have for normal CNN. So depending on
[00:13:12.000 --> 00:13:24.720]   the task that you have, you can also use mean square error as well for regression, for instance. So any type of loss function which can be used in conjunction with CNNs can be used with this architecture as well.
[00:13:24.720 --> 00:13:32.240]   I see. So the output isn't necessarily those locations of those cluster centers
[00:13:32.240 --> 00:13:36.200]   that you were showing. That's not the final output layer of the network?
[00:13:36.480 --> 00:13:39.560]   No, like the output layer exactly has
[00:13:39.560 --> 00:13:51.640]   the same structure as the output of the CNN. So it has the same number as the number of classes and in principle, the training process is very the same.
[00:13:51.640 --> 00:13:58.880]   I see. So then what you were showing were those, it was the hidden layer of the RBF. Those are those cluster locations you were showing.
[00:13:58.920 --> 00:14:08.640]   Yeah, exactly. So this is basically the activation and not the output layer. So I visualized the activations.
[00:14:08.640 --> 00:14:19.080]   I see. Yeah. So I'm just, one reason I'm asking about that is I know folks have looked into ways to do classification that don't use softmax because
[00:14:19.080 --> 00:14:23.280]   various issues like the calibration of the softmax layer can be very difficult.
[00:14:23.520 --> 00:14:26.880]   It can be difficult to motivate why we're using a softmax in the first place.
[00:14:26.880 --> 00:14:38.880]   So it seems like those cluster centers that you have have a natural interpretation as, you know, as basically class labels, right, which cluster it is closest to. So is that a way that you can
[00:14:38.880 --> 00:14:48.200]   sort of train these networks or validate these networks or is that, is it important to include that readout and softmax?
[00:14:48.960 --> 00:15:00.960]   Yeah, actually, that's definitely true. So besides unsupervised initialization of the clusters, we can also do it based on supervised methods.
[00:15:00.960 --> 00:15:14.000]   So at the moment, the way that we completely use unsupervised learning on these clusters, but in principle, you can divide your classes into subclasses or super classes even
[00:15:14.520 --> 00:15:24.840]   and then you don't need the softmax layer at the end as well. So it's possible to just finish the network in the cluster level as well.
[00:15:24.840 --> 00:15:27.960]   Interesting.
[00:15:27.960 --> 00:15:37.800]   And so you mentioned your interest in explainability and interpretable AI. So are there,
[00:15:39.040 --> 00:15:49.440]   what are some of the ways that you see this as being directly enabling greater explainability for CNNs relative to the baseline?
[00:15:49.440 --> 00:16:02.600]   So I would say as soon as we have these supervised clusters, we will have a much better interpretability because at the moment, like the clusters doesn't really
[00:16:03.280 --> 00:16:11.840]   show anything interpretable based on common sense knowledge of humans. But in principle, we can divide
[00:16:11.840 --> 00:16:28.040]   every class into subclusters or even into super classes and then we can kind of interpret how, where these test sample really goes and interpret these based on the ground truth labels and subcategories, of course.
[00:16:28.040 --> 00:16:31.480]   I see.
[00:16:32.440 --> 00:16:39.200]   I see. So it gives you maybe a little bit more insight into that last bit of the CNN before the readout layer.
[00:16:39.200 --> 00:16:39.760]   Exactly.
[00:16:39.760 --> 00:16:43.240]   Like the sort of enforcing this unsupervised learning stuff.
[00:16:43.240 --> 00:16:44.120]   Yeah, that's true.
[00:16:44.120 --> 00:16:56.720]   Cool. All right. Well, thanks for answering those questions. And it looks like, oh, we've got one from Han Li here.
[00:16:58.080 --> 00:17:08.640]   So let me read it out to you. So how does the latent space transform between the latent space output of the CNN backbone versus afterwards? Right. So what, like, how does that
[00:17:08.640 --> 00:17:17.720]   I guess he wants a little bit of insight into what changes about that last layer of the CNN and what comes out of your RBF network.
[00:17:19.440 --> 00:17:33.720]   All right. I think it's basically just about how we can visualize the decision making. So I would say these cluster centers work as support points and we kind of can explain
[00:17:34.960 --> 00:17:35.560]   The
[00:17:35.560 --> 00:17:50.320]   Like the transformation of the CNN and based on these support points. So at the moment, since we do it completely unsupervised, they don't say anything about any kind of human interpretable concept.
[00:17:50.320 --> 00:18:00.960]   But as soon as we involve the ground truth labels into learning the clusters, then you can basically see the network made this decision because it's close to
[00:18:02.040 --> 00:18:06.640]   Cluster Center A, which contains a specific attribute of the image.
[00:18:06.640 --> 00:18:12.120]   I see that that's that's interesting.
[00:18:12.120 --> 00:18:15.520]   And I guess one last one last question for me.
[00:18:15.520 --> 00:18:28.720]   So how immediately extensible is this idea to other kinds of so like stacking it on the end of a fully a network that's fully connected or a recurrent network on its readout layer or
[00:18:29.240 --> 00:18:35.120]   You know, some other kind of network. Is there an immediate way to translate from the work you've done to that or is that another project.
[00:18:35.120 --> 00:18:46.360]   I would say that with some reasonable effort, it could be possible to integrate RBF as the configuration that we proposed here to other types of networks.
[00:18:46.360 --> 00:18:52.040]   And I mean LSTM or recurrent networks are a little bit tricky to train
[00:18:53.080 --> 00:19:02.120]   But I still think that the model that we have is basically ready for plug and play to any type of deep learning method.
[00:19:02.120 --> 00:19:17.920]   Cool. I would say the challenge would be to somewhat have a hyper parameter search as well as regularization for sure. So maybe at the very beginning, it takes some time to reproduce the same performance with more interpretability.
[00:19:17.920 --> 00:19:21.080]   Hmm. Hmm. Yeah, no free lunch. Yeah.
[00:19:21.080 --> 00:19:21.800]   Yeah.
[00:19:22.920 --> 00:19:31.200]   Cool. All right. Well, it's very, very late at night slash early in the morning in Switzerland. So we'll let you go. Thanks for presenting your research.
[00:19:31.200 --> 00:19:36.840]   Thank you very much for your interest and amazing questions. It was great to be with you.
[00:19:36.840 --> 00:19:39.200]   And thanks a lot for your invite.
[00:19:39.200 --> 00:19:40.760]   Yep. Take care.
[00:19:40.760 --> 00:19:42.440]   So thank you very much.

