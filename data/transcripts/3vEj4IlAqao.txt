
[00:00:00.000 --> 00:00:08.680]   When you do sentiment analysis in the huge set of industries, the companies we're trying
[00:00:08.680 --> 00:00:14.080]   to help to listen to their customers and employees, out of the box models, they don't work.
[00:00:14.080 --> 00:00:15.400]   So how do you customize them?
[00:00:15.400 --> 00:00:21.400]   You can always go through like customizing models to specific use cases, brands or industries,
[00:00:21.400 --> 00:00:26.680]   but a much more powerful way is combining the power of these language models and letting
[00:00:26.680 --> 00:00:30.600]   the customers override specific lexicals or rules and whatnot.
[00:00:30.600 --> 00:00:34.960]   You're listening to Gradient Dissent, a show about machine learning in the real world,
[00:00:34.960 --> 00:00:37.320]   and I'm your host, Lukas Biewald.
[00:00:37.320 --> 00:00:44.040]   Aaron Kolak leads a team of machine learning engineers, scientists, and linguists at Qualtrics.
[00:00:44.040 --> 00:00:48.120]   Qualtrics is a super big company that you might not have heard of that takes large language
[00:00:48.120 --> 00:00:52.600]   models and applies them to real world B2B use cases.
[00:00:52.600 --> 00:00:54.760]   This is a really interesting interview and I hope you enjoy it.
[00:00:54.760 --> 00:00:58.880]   Aaron, thanks so much for doing this.
[00:00:58.880 --> 00:00:59.880]   I really appreciate it.
[00:00:59.880 --> 00:01:03.520]   I kind of thought a good place to start would be Qualtrics.
[00:01:03.520 --> 00:01:06.680]   And it happens to be a company that I know well because I've worked with Qualtrics for
[00:01:06.680 --> 00:01:12.640]   a long time and a real star employee of mine, John Luh, ended up over there.
[00:01:12.640 --> 00:01:19.680]   And so I know Qualtrics well, but I'm thinking a lot of our listeners will not know even
[00:01:19.680 --> 00:01:20.680]   what Qualtrics does.
[00:01:20.680 --> 00:01:25.320]   So maybe you could just start by saying what does Qualtrics, the company, do and then tell
[00:01:25.320 --> 00:01:27.920]   us how machine learning fits into Qualtrics.
[00:01:27.920 --> 00:01:28.920]   Sure.
[00:01:28.920 --> 00:01:32.720]   I think that would be a good starting point.
[00:01:32.720 --> 00:01:38.640]   Like many B2B companies, sometimes it's a little bit not obvious when you just use the
[00:01:38.640 --> 00:01:41.320]   technical terms to explain what the company does.
[00:01:41.320 --> 00:01:45.140]   But when we get to the bottom of it, it actually is pretty cool.
[00:01:45.140 --> 00:01:46.920]   So let me start.
[00:01:47.640 --> 00:01:54.200]   We as individuals, human beings, use products, consume services every day.
[00:01:54.200 --> 00:02:00.240]   So every single usage of a product or a brand, being a customer brand, even working for a
[00:02:00.240 --> 00:02:06.680]   company or an organization, being an employee, from the individual's perspective, is an experience.
[00:02:06.680 --> 00:02:09.360]   Every single transaction is for us an experience.
[00:02:09.360 --> 00:02:14.480]   Going to a restaurant, taking a flight, taking an interview, working somewhere for some time
[00:02:14.480 --> 00:02:15.880]   is an experience.
[00:02:15.880 --> 00:02:25.640]   So what Qualtrics does is basically giving our customers tools to design these experiences,
[00:02:25.640 --> 00:02:31.280]   track those experiences, analyze those experiences, and act on those experiences.
[00:02:31.280 --> 00:02:34.120]   So there's four pillars to experience management.
[00:02:34.120 --> 00:02:40.520]   So overall, we're trying our customers to help them manage, find, detect, and fill those
[00:02:40.520 --> 00:02:43.000]   experience gaps.
[00:02:43.000 --> 00:02:52.680]   So our company roots started somehow an interesting domain, which is surveys.
[00:02:52.680 --> 00:02:57.640]   Especially in social scientists and business schools, doing surveys is the primary tool
[00:02:57.640 --> 00:03:00.120]   to do research.
[00:03:00.120 --> 00:03:06.720]   And our founders were trying to help their father to build a survey tool.
[00:03:06.720 --> 00:03:08.720]   And then that just exploded.
[00:03:08.720 --> 00:03:11.440]   It just became phenomenally successful.
[00:03:11.440 --> 00:03:21.240]   And then at the next level, those users of surveys, students, and researchers came back
[00:03:21.240 --> 00:03:26.320]   in the enterprise setting with different problems, trying to understand what customers think.
[00:03:26.320 --> 00:03:29.080]   And that became our basically...
[00:03:29.080 --> 00:03:34.760]   We shifted a little bit towards markets research and understanding customers, employees, and
[00:03:34.760 --> 00:03:35.760]   whatnot.
[00:03:35.760 --> 00:03:41.840]   And basically, last few years, we've been working on this new category, which is experience
[00:03:41.840 --> 00:03:42.840]   management.
[00:03:42.840 --> 00:03:47.640]   So we would like to think of ourselves as founders and leaders in that space.
[00:03:47.640 --> 00:03:49.840]   Could you tell us a little bit about the scale of Qualtrics?
[00:03:49.840 --> 00:03:50.840]   Sure.
[00:03:50.840 --> 00:03:52.240]   That's a great question.
[00:03:52.240 --> 00:03:56.800]   I would like to think about scale in a couple of different ways.
[00:03:56.800 --> 00:04:00.840]   One of them is obviously the number of customers we have.
[00:04:00.840 --> 00:04:05.520]   And we have tens of thousands of customers.
[00:04:05.520 --> 00:04:09.760]   But I would like to think about other ways in terms of the number of touch points we
[00:04:09.760 --> 00:04:17.120]   are going through our systems, number of experiences we're analyzing, and also the diversity of
[00:04:17.120 --> 00:04:24.040]   the type of experiences and channels from which you can actually track and improve experiences.
[00:04:24.040 --> 00:04:30.040]   So in that respect, our systems analyze millions of experiences every day.
[00:04:30.040 --> 00:04:35.920]   And we have different channels and modalities, that's social media channels or other input
[00:04:35.920 --> 00:04:44.920]   channels such as surveys, tech surveys, web surveys, mobile, and social media call center.
[00:04:44.920 --> 00:04:51.920]   So there's various modalities we're actually collecting and analyzing this data from.
[00:04:51.920 --> 00:04:56.280]   That is kind of, for me, one other aspects of scaling.
[00:04:56.280 --> 00:05:00.160]   And so what are the really important ML applications to Qualtrics?
[00:05:00.160 --> 00:05:03.920]   Is it somehow like processing those surveys in different ways?
[00:05:03.920 --> 00:05:05.480]   What's really at the core?
[00:05:05.480 --> 00:05:06.480]   Absolutely.
[00:05:06.480 --> 00:05:12.320]   So as I mentioned, survey is one of the most important channels, but it's not the only
[00:05:12.320 --> 00:05:13.320]   one.
[00:05:13.320 --> 00:05:20.120]   But even in surveys, there's definitely a big part of the data that's being structured.
[00:05:20.120 --> 00:05:28.240]   And in my opinion, there's experience data is most easily or most naturally expressed
[00:05:28.240 --> 00:05:30.580]   in unstructured data.
[00:05:30.580 --> 00:05:36.760]   So one of the obvious things where ML comes into equation is analyzing unstructured part
[00:05:36.760 --> 00:05:45.280]   of the surveys, such as open text questions, analyzing sentiment, emotion, effort, and
[00:05:45.280 --> 00:05:52.680]   finding what folks are talking about, employees or customers, what is individual team-specific
[00:05:52.680 --> 00:05:53.680]   sentiment, emotion.
[00:05:53.680 --> 00:06:00.760]   These are the sort of stuff where obviously machine learning utilize mostly, but obviously
[00:06:00.760 --> 00:06:02.240]   there's other aspects.
[00:06:02.240 --> 00:06:09.160]   For example, the minute you go into a call center, then comes conversation, which is
[00:06:09.160 --> 00:06:10.960]   a totally different beast.
[00:06:10.960 --> 00:06:13.200]   Can you make this more concrete for me though?
[00:06:13.200 --> 00:06:17.960]   Tell me one kind of common survey that people might not realize happens.
[00:06:17.960 --> 00:06:18.960]   Right.
[00:06:18.960 --> 00:06:23.200]   I think most folks would probably know about CSAT and MPS.
[00:06:23.200 --> 00:06:29.480]   MPS stands for Net Promoter Score and CSAT stands for Customer Satisfaction Score.
[00:06:29.480 --> 00:06:34.240]   So these are well-established industry standards where businesses basically ask their questions
[00:06:34.240 --> 00:06:35.240]   to customers.
[00:06:35.240 --> 00:06:40.400]   And those surveys can be structured or the input channels can be structured depending
[00:06:40.400 --> 00:06:42.600]   on how you score and what you express.
[00:06:42.600 --> 00:06:45.480]   And you might be actually just feeling in your experience.
[00:06:45.480 --> 00:06:47.920]   How was your experience, Lucas?
[00:06:47.920 --> 00:06:53.440]   You might be just feeling it a bit like, "Oh, the price was great, but the service was not
[00:06:53.440 --> 00:06:54.440]   good."
[00:06:54.440 --> 00:06:55.440]   Right.
[00:06:55.440 --> 00:07:00.280]   And you might imagine big enterprises when they're trying to listen to their customers,
[00:07:00.280 --> 00:07:08.280]   there might be literally possibly practically infinitely many topics customers might be
[00:07:08.280 --> 00:07:09.600]   thinking about.
[00:07:09.600 --> 00:07:12.840]   So how do you detect and act on this?
[00:07:12.840 --> 00:07:18.800]   So this is where comes machine learning, specifically NLP, detecting what your customers are talking
[00:07:18.800 --> 00:07:19.800]   about.
[00:07:19.800 --> 00:07:20.800]   Is it the price?
[00:07:20.800 --> 00:07:21.960]   Is it the service quality?
[00:07:21.960 --> 00:07:24.760]   Is it the taste of the food?
[00:07:24.760 --> 00:07:28.000]   And then what is the sentiment, topic level sentiment on this?
[00:07:28.000 --> 00:07:30.600]   What's the emotion on this?
[00:07:30.600 --> 00:07:31.600]   Things like that.
[00:07:31.600 --> 00:07:32.600]   I hope that made it a bit more concrete.
[00:07:32.600 --> 00:07:33.600]   Yeah.
[00:07:33.600 --> 00:07:37.480]   I mean, I just want to make it even a little more concrete for people that don't know.
[00:07:37.480 --> 00:07:41.600]   I mean, we actually measure NPS religiously at Weights & Biases.
[00:07:41.600 --> 00:07:47.640]   People sometimes complain that we're asking too much, but we really love to ask NPS.
[00:07:47.640 --> 00:07:53.280]   And that's a measure of would you recommend this product to a friend on a scale of one
[00:07:53.280 --> 00:07:54.280]   to 10, right?
[00:07:54.280 --> 00:08:00.520]   And then you take the nines and tens and subtract the one through six or zero through six.
[00:08:00.520 --> 00:08:03.240]   The low ones are the detractors and the high ones are the promoters.
[00:08:03.240 --> 00:08:07.600]   It's sort of a sense of are people liking your product?
[00:08:07.600 --> 00:08:14.400]   And then I think, is CSET the one where it's like, how would you feel if the service went
[00:08:14.400 --> 00:08:15.600]   away?
[00:08:15.600 --> 00:08:17.160]   Would you be disappointed or not?
[00:08:17.160 --> 00:08:18.160]   Is that right?
[00:08:18.160 --> 00:08:19.160]   Could be.
[00:08:19.160 --> 00:08:24.400]   I think depending on the context, the good way to think about CSET and NPS is a little
[00:08:24.400 --> 00:08:26.360]   bit in the following way.
[00:08:26.360 --> 00:08:33.800]   CSET tends to be focused on transactional experiences, whereas NPS is more about the
[00:08:33.800 --> 00:08:39.760]   relation, your relation to that service provider or the company or the brand, taking into everything
[00:08:39.760 --> 00:08:40.760]   into account.
[00:08:40.760 --> 00:08:41.760]   How is your overall experience?
[00:08:41.760 --> 00:08:46.440]   And sorry, CSET is like one moment in time or one thing that you did?
[00:08:46.440 --> 00:08:47.960]   Yeah, transactional experience.
[00:08:47.960 --> 00:08:48.960]   Yes.
[00:08:48.960 --> 00:08:54.520]   And so what's a typical question that a Qualtrics customer would have about all the NPS data
[00:08:54.520 --> 00:08:55.520]   they're collecting?
[00:08:55.520 --> 00:08:59.520]   They maybe want to know what are the themes of things that people are unhappy about?
[00:08:59.520 --> 00:09:00.520]   Right.
[00:09:00.520 --> 00:09:01.520]   Exactly.
[00:09:01.520 --> 00:09:04.440]   I think this is the most canonical use case.
[00:09:04.440 --> 00:09:08.600]   Everybody is obviously, every company that cares about customers.
[00:09:08.600 --> 00:09:15.440]   And this is really one of our biggest motivation because as you are familiar from the tech,
[00:09:15.440 --> 00:09:21.800]   big tech companies, some of them are phenomenally successful with their customer obsession.
[00:09:21.800 --> 00:09:25.840]   So how do you enable the rest of the world who doesn't have an army of data scientists
[00:09:25.840 --> 00:09:31.040]   and engineers, listen to their customers and employees too, not just customers.
[00:09:31.040 --> 00:09:36.200]   So our tool can be used in these different settings to listen to different personas from
[00:09:36.200 --> 00:09:38.880]   their experience perspective.
[00:09:38.880 --> 00:09:46.600]   And now when you analyze this free form, like NPS survey data, just to use a specific example,
[00:09:46.600 --> 00:09:52.800]   do you come at it with a specific set of categories that you're interested in or do you kind of
[00:09:52.800 --> 00:09:56.000]   draw themes out with clustering or something like that?
[00:09:56.000 --> 00:09:57.000]   That is a great question.
[00:09:57.000 --> 00:09:58.000]   Yes.
[00:09:58.000 --> 00:10:02.000]   So there's two type of experiences, speaking of experience with our products, if you want
[00:10:02.000 --> 00:10:05.560]   to do analytics and open-ended questions.
[00:10:05.560 --> 00:10:10.000]   This is where you usually most find especially emerging new stuff.
[00:10:10.000 --> 00:10:15.280]   You can go with what we call as industry specific libraries, where our expert, domain experts
[00:10:15.280 --> 00:10:21.800]   and industry specialists collect and create these library of topics.
[00:10:21.800 --> 00:10:26.120]   But as we know, world is changing fast, especially in certain industries.
[00:10:26.120 --> 00:10:29.120]   So how do you go on top of things?
[00:10:29.120 --> 00:10:30.800]   How do you find emerging new stuff?
[00:10:30.800 --> 00:10:32.720]   How do you make sure things are not under your radar?
[00:10:32.720 --> 00:10:34.300]   This is where ML comes into play.
[00:10:34.300 --> 00:10:39.600]   So we actually have deployed machine learning and things like topic detection, key phrase
[00:10:39.600 --> 00:10:45.120]   detection, things like that, and surface that with taking the temporality dimension into
[00:10:45.120 --> 00:10:47.960]   the equation, of course.
[00:10:47.960 --> 00:10:55.320]   And then, yeah, that's where they begin, either curated, ready to consume libraries or finding
[00:10:55.320 --> 00:10:57.520]   topics on the fly.
[00:10:57.520 --> 00:11:03.440]   And I feel like natural language processing in the past few years has moved faster than
[00:11:03.440 --> 00:11:05.360]   maybe any other field in ML.
[00:11:05.360 --> 00:11:13.240]   And suddenly you have this explosion of large language models, which are quite evocative
[00:11:13.240 --> 00:11:18.440]   in terms of text generation, but I'm always wondering how much this affects businesses
[00:11:18.440 --> 00:11:19.440]   like Qualtrics.
[00:11:19.440 --> 00:11:22.880]   Do you use large language models a lot?
[00:11:22.880 --> 00:11:26.960]   And if so, where do you use them and not use them?
[00:11:26.960 --> 00:11:28.840]   How are you thinking about that?
[00:11:28.840 --> 00:11:29.840]   Right.
[00:11:29.840 --> 00:11:34.000]   So I would like to first mention a disclaimer.
[00:11:34.000 --> 00:11:38.240]   Obviously, I'm a big fan of ML and deep learning.
[00:11:38.240 --> 00:11:42.440]   Having been in University of Toronto during my grad school when all these things are happening,
[00:11:42.440 --> 00:11:44.760]   you can't escape that gravity, obviously.
[00:11:44.760 --> 00:11:51.600]   But also having been in ML for so long, our approach is pretty much going after what our
[00:11:51.600 --> 00:11:53.880]   customers need to dictate.
[00:11:53.880 --> 00:11:58.160]   As you know, as you covered in this blog post many times, large language models, contextual
[00:11:58.160 --> 00:12:02.560]   models, cross-lingual models, they're game changing.
[00:12:02.560 --> 00:12:08.400]   If you use it the right way, if you use it, kind of identify the right situation for them,
[00:12:08.400 --> 00:12:10.040]   they can be really powerful.
[00:12:10.040 --> 00:12:11.040]   And we do.
[00:12:11.040 --> 00:12:15.880]   We do use large language cross-lingual models a lot.
[00:12:15.880 --> 00:12:20.160]   But you might be surprised, we also use rule-based systems a lot.
[00:12:20.160 --> 00:12:28.560]   I think rule-based systems, heuristics, they enable you to code not only fast and be scrappy,
[00:12:28.560 --> 00:12:32.240]   but also enables quite a bit of customization.
[00:12:32.240 --> 00:12:36.760]   Because when you use large language models, when you do sentiment analysis in the huge
[00:12:36.760 --> 00:12:42.440]   set of industries, the companies we're trying to help to listen to their customers and employees,
[00:12:42.440 --> 00:12:45.480]   out of the box models, they don't work.
[00:12:45.480 --> 00:12:46.840]   So how do you customize them?
[00:12:46.840 --> 00:12:52.800]   You can always go through customizing models to specific use cases, brands, or industries.
[00:12:52.800 --> 00:12:58.000]   But a much more powerful way is combining the power of these language models and letting
[00:12:58.000 --> 00:13:02.000]   the customers override specific lexicons or rules and whatnot.
[00:13:02.000 --> 00:13:09.160]   So yeah, we have the full spectrum, starting from classical linguistic analysis, lexicons
[00:13:09.160 --> 00:13:14.520]   all the way to the bleeding edge deep learning models, language models.
[00:13:14.520 --> 00:13:17.520]   We use the full spectrum.
[00:13:17.520 --> 00:13:22.640]   I think the future includes a hybrid, for us at least, for the foreseeable future.
[00:13:22.640 --> 00:13:26.480]   And when you use these large language models, where are you getting them?
[00:13:26.480 --> 00:13:32.200]   Are you using Hugging Face or using some of the APIs out there like OpenAI or Amazon or
[00:13:32.200 --> 00:13:33.200]   others?
[00:13:33.200 --> 00:13:34.200]   How do you think about that?
[00:13:34.200 --> 00:13:36.800]   Do you feel like it's important for you to train your own?
[00:13:36.800 --> 00:13:44.000]   Yes, because for a lot of the problems we're looking at, just taking a model, training
[00:13:44.000 --> 00:13:46.840]   it, training the domain.
[00:13:46.840 --> 00:13:52.200]   There are always some problems that can be solved with just simple tuning, domain adaptation.
[00:13:52.200 --> 00:13:59.840]   But there is a large spectrum of problems where it's not sufficient for us.
[00:13:59.840 --> 00:14:03.160]   There's also the whole aspect that when you operate at the scale we are dealing with millions
[00:14:03.160 --> 00:14:07.360]   of short and long texts, conversations.
[00:14:07.360 --> 00:14:10.300]   We also need to care about scale.
[00:14:10.300 --> 00:14:13.840]   So model compression is a big area for us as well.
[00:14:13.840 --> 00:14:16.280]   Right now we're focusing on.
[00:14:16.280 --> 00:14:21.560]   We do use pretty commonly the XLM, Roberta type of models.
[00:14:21.560 --> 00:14:25.640]   We experiment all like latest and greatest stuff that's coming our way and we pick the
[00:14:25.640 --> 00:14:27.840]   right model for the setup.
[00:14:27.840 --> 00:14:33.760]   And if need be, we also customizing them in terms of the downstream application, in terms
[00:14:33.760 --> 00:14:41.440]   of combining the language models with other modalities and whatnot.
[00:14:41.440 --> 00:14:46.520]   And how much customization we do in the model, how much tuning, where do we freeze?
[00:14:46.520 --> 00:14:50.560]   It all depends on the exact specific use case.
[00:14:50.560 --> 00:14:56.080]   Do you feel like the advances in NLP has changed your approach to machine learning over the
[00:14:56.080 --> 00:14:57.640]   last few years?
[00:14:57.640 --> 00:14:58.640]   Absolutely.
[00:14:58.640 --> 00:15:03.200]   I think, again, it's a powerful, powerful tool.
[00:15:03.200 --> 00:15:09.880]   It's not the silver bullet for everything, but especially organizations like us who tackle
[00:15:09.880 --> 00:15:18.640]   multilingual data in low resource languages, it has been a big, powerful tool.
[00:15:18.640 --> 00:15:19.640]   Interesting.
[00:15:19.640 --> 00:15:21.720]   How do you use it for low resource languages?
[00:15:21.720 --> 00:15:25.880]   I have to be careful here because when I say low resource language, I may not be using
[00:15:25.880 --> 00:15:32.120]   the exact academic sense of low resource because that seems to be a big moving target for this.
[00:15:32.120 --> 00:15:37.000]   What I mean is from our perspective, obviously every business have a target depending on
[00:15:37.000 --> 00:15:41.240]   where they operate and what kind of products they're developing, have business priorities
[00:15:41.240 --> 00:15:44.440]   in terms of languages they want to handle.
[00:15:44.440 --> 00:15:50.680]   And the amount of English data, both in terms of raw, labeled, or customer feedback data,
[00:15:50.680 --> 00:15:55.920]   which we use to train these models, obviously for English, we have disproportionately more
[00:15:55.920 --> 00:16:02.240]   English data than, say, even some common European languages.
[00:16:02.240 --> 00:16:07.800]   And some of the success we got from these models just purely based on zero-shot learning
[00:16:07.800 --> 00:16:14.960]   was sometimes more than enough for getting a POC out there and then iterating on it.
[00:16:14.960 --> 00:16:20.960]   Because more often than not, I don't know, having been in this field multiple times,
[00:16:20.960 --> 00:16:24.160]   getting training data, labeling, can always be an issue.
[00:16:24.160 --> 00:16:25.720]   Sometimes it's a chicken-egg problem.
[00:16:25.720 --> 00:16:30.440]   If I have one product out there, then I will have customers doing some edits for me or
[00:16:30.440 --> 00:16:32.080]   giving feedback and data.
[00:16:32.080 --> 00:16:35.280]   But how do I get there if I don't even have a model working?
[00:16:35.280 --> 00:16:39.440]   So zero-shot, in a way, game-changing in this respect, because it enables you to, as long
[00:16:39.440 --> 00:16:44.820]   as you set the expectations right, get something out there, make it a win-win situation for
[00:16:44.820 --> 00:16:49.840]   you and your customers, while start data-pouring in and you iterate from there, from the feedback,
[00:16:49.840 --> 00:16:55.640]   from the implicit or explicit labels that come to your system.
[00:16:55.640 --> 00:16:56.640]   In that respect, it's been game-changing.
[00:16:56.640 --> 00:17:06.240]   Obviously, when you take practically, in the past, if you want to support for any NLP system
[00:17:06.240 --> 00:17:15.040]   in X languages or K-many languages, you probably need K-many language export, K-many sub-teams
[00:17:15.040 --> 00:17:16.040]   working on those.
[00:17:16.040 --> 00:17:22.160]   But right now, again, it's not a silver bullet for everything, every use case, but for a
[00:17:22.160 --> 00:17:28.400]   lot of the use cases, simple investments on small datasets can go a long way.
[00:17:28.400 --> 00:17:34.960]   There's also actually changing the paradigm in a different way too, Lucas, in my opinion.
[00:17:34.960 --> 00:17:38.960]   In the past, when you were doing an NLP project, every single project, whether it's the same
[00:17:38.960 --> 00:17:43.400]   project in a different language or a different functionality in the same language, would
[00:17:43.400 --> 00:17:46.360]   require almost from a data perspective, getting ground zero.
[00:17:46.360 --> 00:17:49.920]   You start from ground zero, you cannot share a dataset, pretty much.
[00:17:49.920 --> 00:17:55.400]   But this cross-linguality, this pre-trained language models combined with cross-linguality
[00:17:55.400 --> 00:18:02.840]   enables basically doing a lot of new ideas, new projects for a fixed amount of budget,
[00:18:02.840 --> 00:18:07.520]   just because the amount of data you need to tune to a new feature, a new language is just
[00:18:07.520 --> 00:18:09.240]   significantly smaller.
[00:18:09.240 --> 00:18:15.360]   And that has been, for us and for many others I know in our industry, in technology and
[00:18:15.360 --> 00:18:20.120]   in NLP space, have been changing the way they look at data.
[00:18:20.120 --> 00:18:21.120]   Interesting.
[00:18:21.120 --> 00:18:22.120]   So how does this actually work?
[00:18:22.120 --> 00:18:28.920]   So you'd say you have some French language survey results.
[00:18:28.920 --> 00:18:32.880]   When you say zero shot, do you mean that you take some kind of embedding and put it into
[00:18:32.880 --> 00:18:35.240]   some comparable space as the English?
[00:18:35.240 --> 00:18:40.440]   How do you actually approach the rarer languages practically?
[00:18:40.440 --> 00:18:44.520]   Let's take an artificial problem, like text classification.
[00:18:44.520 --> 00:18:48.160]   I want to classify to ABC, whatever, sentiment and whatnot.
[00:18:48.160 --> 00:18:56.200]   We actually share this in our blog post, but basically you train for English, say you may
[00:18:56.200 --> 00:18:58.280]   have more data on it or label data on it.
[00:18:58.280 --> 00:19:04.200]   And for French, if you have limited data, the least you can do is using that data for
[00:19:04.200 --> 00:19:05.200]   testing.
[00:19:05.200 --> 00:19:07.920]   How is my zero shot performance?
[00:19:07.920 --> 00:19:14.480]   And sometimes we have little datasets in these languages and we say, okay, from a test perspective,
[00:19:14.480 --> 00:19:21.200]   it looks good enough to get, or even pretty satisfactory to get coming close to the English
[00:19:21.200 --> 00:19:27.600]   performance or whatever the performance metric we want to hit.
[00:19:27.600 --> 00:19:33.680]   And if they're not, you get an idea of how your model is doing, and then that might be
[00:19:33.680 --> 00:19:38.960]   enough for you to get a V0 out there and start collecting data from a feedback perspective,
[00:19:38.960 --> 00:19:43.240]   because our systems allow, not all, but some of them allow us, actually customers to give
[00:19:43.240 --> 00:19:45.440]   feedback in terms of our predictions.
[00:19:45.440 --> 00:19:51.640]   And then that basically compared to how we would do these kinds of things, not even like
[00:19:51.640 --> 00:19:57.320]   five years ago, you had to go and start from scratch in French, right?
[00:19:57.320 --> 00:19:58.840]   Yeah, it's really impressive.
[00:19:58.840 --> 00:20:02.920]   It just works reasonably well right out of the gate, typically.
[00:20:02.920 --> 00:20:11.480]   Usually, but again, some problems, sometimes, not all of them, nevertheless, very useful.
[00:20:11.480 --> 00:20:15.720]   Do you end up training separate models for each customer then?
[00:20:15.720 --> 00:20:20.960]   Are you fine tuning new models in every single customer's pieces of data?
[00:20:20.960 --> 00:20:24.880]   And if you have thousands of customers, does that create a huge logistical problem for
[00:20:24.880 --> 00:20:25.880]   you?
[00:20:25.880 --> 00:20:26.880]   Yeah, that's a good question.
[00:20:26.880 --> 00:20:30.040]   First of all, a couple of years ago, even if that was the right thing, it would not
[00:20:30.040 --> 00:20:31.040]   be feasible.
[00:20:31.040 --> 00:20:33.880]   I mean, practically, very challenging.
[00:20:33.880 --> 00:20:39.560]   But these days, fortunately, hyperscalers provide a lot of functionality with various
[00:20:39.560 --> 00:20:46.240]   services, in terms of multiple model endpoints and asynchronous predictions, bad predictions,
[00:20:46.240 --> 00:20:47.240]   and whatnot.
[00:20:47.240 --> 00:20:53.880]   So you don't have to have a model endpoint for every single language or task you have.
[00:20:53.880 --> 00:20:56.080]   But we do a combination.
[00:20:56.080 --> 00:21:00.920]   We try to use multitasking as often as we can.
[00:21:00.920 --> 00:21:04.360]   It's a powerful tool.
[00:21:04.360 --> 00:21:16.520]   Obviously, more often than not, you basically get a proportionally linear return on your
[00:21:16.520 --> 00:21:18.040]   combination of the tasks.
[00:21:18.040 --> 00:21:22.400]   So instead of having n models, you have basically one model doing n tasks, if it is possible,
[00:21:22.400 --> 00:21:23.880]   if it's applicable.
[00:21:23.880 --> 00:21:30.240]   It obviously, from a model lifecycle management perspective, it generates its own challenges
[00:21:30.240 --> 00:21:31.240]   as well.
[00:21:31.240 --> 00:21:35.200]   But it needs to be taken into account in the long-term design, because then you're coupling
[00:21:35.200 --> 00:21:36.200]   models.
[00:21:36.200 --> 00:21:40.000]   If model requirements change, you need to update one more one task.
[00:21:40.000 --> 00:21:42.520]   You don't need to really update other tasks.
[00:21:42.520 --> 00:21:44.160]   And how do you think about what a task is here?
[00:21:44.160 --> 00:21:45.760]   So I'm imagining if you have-
[00:21:45.760 --> 00:21:48.480]   Let's give a concrete example.
[00:21:48.480 --> 00:21:56.160]   Let's say you're trying to predict sentiment on a given text.
[00:21:56.160 --> 00:22:04.200]   And you might imagine sentiment and other related more nuanced dimensions of human experience,
[00:22:04.200 --> 00:22:11.120]   say emotion and whatnot, or other things you want to predict about this intent and whatnot.
[00:22:11.120 --> 00:22:16.200]   So same input, and you basically can predict at the same time with a single model, what's
[00:22:16.200 --> 00:22:20.840]   the emotion, what's the intent, what's the sentiment at the same time.
[00:22:20.840 --> 00:22:24.240]   So these are individual tasks.
[00:22:24.240 --> 00:22:27.680]   It doesn't have to be a single prediction that it can be a classification task combined
[00:22:27.680 --> 00:22:30.200]   with a sequence to sequence task.
[00:22:30.200 --> 00:22:32.360]   Doesn't matter.
[00:22:32.360 --> 00:22:35.900]   But if you're doing this on behalf of two customers, do you consider that to be a single
[00:22:35.900 --> 00:22:39.400]   task or does each customer look like a different task?
[00:22:39.400 --> 00:22:40.480]   Yeah, sorry.
[00:22:40.480 --> 00:22:47.200]   That reminds me, I didn't quite answer your first question.
[00:22:47.200 --> 00:22:54.480]   As I mentioned, for customer specific needs, we tend to think in terms of giving customer
[00:22:54.480 --> 00:23:00.000]   the full power to customize or overwrite the behavior of the model.
[00:23:00.000 --> 00:23:05.640]   That comes through using various enrichment we do to the text on top of whatever the target
[00:23:05.640 --> 00:23:06.640]   task.
[00:23:06.640 --> 00:23:10.480]   You can also do all the linguistic enrichments, and you can combine these linguistic enrichment
[00:23:10.480 --> 00:23:15.400]   with rules and other heuristics to actually overwrite the model behavior.
[00:23:15.400 --> 00:23:19.200]   There are some initiatives going on, which I'm not at the liberty of discussing here,
[00:23:19.200 --> 00:23:25.480]   but we are thinking of enabling customization on the ML level as well.
[00:23:25.480 --> 00:23:28.080]   This is not implemented yet.
[00:23:28.080 --> 00:23:29.080]   I see.
[00:23:29.080 --> 00:23:38.040]   But I guess, does allowing the individual customers to customize what the output's doing,
[00:23:38.040 --> 00:23:41.080]   I guess that means there's a single underlying model that's feeding the customers and then
[00:23:41.080 --> 00:23:42.800]   they sort of overwrite it?
[00:23:42.800 --> 00:23:44.840]   Right, right, right.
[00:23:44.840 --> 00:23:45.840]   That's a good point.
[00:23:45.840 --> 00:23:50.160]   I think I should have made that distinction upfront.
[00:23:50.160 --> 00:23:51.160]   So we have two types of models.
[00:23:51.160 --> 00:23:53.800]   One of them is what we call universal models.
[00:23:53.800 --> 00:23:59.040]   These are models that work for all customers the same way, irrespective of who's sending
[00:23:59.040 --> 00:24:00.040]   the data.
[00:24:00.040 --> 00:24:02.200]   But we have also customer specific models.
[00:24:02.200 --> 00:24:09.480]   For example, we have this tool called PredictIQ, where you can use experience data, which we
[00:24:09.480 --> 00:24:16.560]   call X data or operational data, O data, a combination of those to build predictive models,
[00:24:16.560 --> 00:24:19.320]   starting with Churn prediction.
[00:24:19.320 --> 00:24:22.840]   Actually that's one of John's products.
[00:24:22.840 --> 00:24:28.480]   But PredictIQ by definition is customer specific, because you as the customer bring your own
[00:24:28.480 --> 00:24:36.040]   data, define what your variables are, or let our system to kind of do auto ML and do automatically
[00:24:36.040 --> 00:24:39.480]   build, train, optimize, and deploy a model for you.
[00:24:39.480 --> 00:24:43.400]   And as new data comes in, you can actually, in a streamlined fashion, you can predict
[00:24:43.400 --> 00:24:44.520]   the...
[00:24:44.520 --> 00:24:48.200]   So customer specific model and universal models.
[00:24:48.200 --> 00:24:51.640]   But I understood with your question initially by mistake was like, what about these universal
[00:24:51.640 --> 00:24:52.640]   models?
[00:24:52.640 --> 00:24:53.720]   How do you customize them?
[00:24:53.720 --> 00:24:56.520]   So our approach with that is like letting the customer overwrite this behavior so it's
[00:24:56.520 --> 00:24:58.880]   not completely ML based.
[00:24:58.880 --> 00:25:04.180]   But there is, we can envision a future where we can totally completely let customers give
[00:25:04.180 --> 00:25:06.120]   feedback and continue to train these models.
[00:25:06.120 --> 00:25:07.720]   This is more on the thinking right now.
[00:25:07.720 --> 00:25:13.080]   There is no concrete plans or commitment on that one.
[00:25:13.080 --> 00:25:23.800]   And now I guess processing language data is pretty different from predicting churn.
[00:25:23.800 --> 00:25:28.880]   When you think about predicting churn from survey results or something like that, does
[00:25:28.880 --> 00:25:33.560]   deep learning have any role to play or do you go to kind of more traditional models
[00:25:33.560 --> 00:25:36.600]   for that kind of tabular data?
[00:25:36.600 --> 00:25:39.520]   That's a great question, Lucas.
[00:25:39.520 --> 00:25:43.880]   The interesting thing is that people have been trying to extend some of these ideas
[00:25:43.880 --> 00:25:48.440]   that came from transformers to tabular data as well.
[00:25:48.440 --> 00:25:53.720]   I think there are some variations of DevOps specifically for tabular data, but I'm not
[00:25:53.720 --> 00:26:00.280]   convinced that the concept of pre-training, which is where most of the power for these
[00:26:00.280 --> 00:26:05.320]   language models come from, doesn't quite apply, at least not in our setting.
[00:26:05.320 --> 00:26:10.000]   Everybody's customer data, everybody's transaction data is different.
[00:26:10.000 --> 00:26:12.240]   The semantics of it is different.
[00:26:12.240 --> 00:26:19.200]   That being said, there is a future which we are investing towards where we'll be able
[00:26:19.200 --> 00:26:27.240]   to hopefully, we give our customers options to schematize their data, to map them to a
[00:26:27.240 --> 00:26:30.000]   kind of a shared schema.
[00:26:30.000 --> 00:26:34.960]   And when that happens, obviously, things change a little bit.
[00:26:34.960 --> 00:26:42.040]   Then you can actually envision a future where learnings can translate, global patterns can
[00:26:42.040 --> 00:26:45.800]   translate from one dataset to another.
[00:26:45.800 --> 00:26:47.880]   And what would this mean to map to a schema?
[00:26:47.880 --> 00:26:52.100]   Like, this mean kind of standardizing the customer names and standardizing the definition
[00:26:52.100 --> 00:26:54.000]   of churn or something else?
[00:26:54.000 --> 00:26:55.000]   Right.
[00:26:55.000 --> 00:26:56.000]   Not quite that.
[00:26:56.000 --> 00:26:59.240]   So for example, think about the following.
[00:26:59.240 --> 00:27:05.800]   Say you have a question about NPS.
[00:27:05.800 --> 00:27:14.040]   How likely are you to recommend company or product X to your friends?
[00:27:14.040 --> 00:27:19.720]   Now you can imagine this can be expressed in many, many different lexical and semantic
[00:27:19.720 --> 00:27:22.600]   forms and different languages.
[00:27:22.600 --> 00:27:28.960]   So capturing that question, identifying, "Hey, this is the same question and this is the
[00:27:28.960 --> 00:27:29.960]   same.
[00:27:29.960 --> 00:27:30.960]   This is an age question.
[00:27:30.960 --> 00:27:34.040]   This is an income question."
[00:27:34.040 --> 00:27:40.320]   That is basically you're structuring the data in that way and identifying the fields and
[00:27:40.320 --> 00:27:43.160]   numerical values and the ranges and whatnot.
[00:27:43.160 --> 00:27:44.640]   Then data becomes mappable.
[00:27:44.640 --> 00:27:47.680]   Data becomes transferable.
[00:27:47.680 --> 00:27:49.760]   Learnings become transferable.
[00:27:49.760 --> 00:27:57.440]   Going back to predict IQ problem, yes, we use, again, deep learning there as well, mostly
[00:27:57.440 --> 00:28:00.760]   canonical techniques.
[00:28:00.760 --> 00:28:07.120]   But not surprisingly, with tabular data, 3-base models are pretty successful, even if they're
[00:28:07.120 --> 00:28:13.320]   not necessarily always successful in terms of performance metrics, which is much easier
[00:28:13.320 --> 00:28:21.400]   to work with them just because they have this natural way of dealing with missing data,
[00:28:21.400 --> 00:28:26.240]   combining categorical and continuous features, numerical features, and whatnot.
[00:28:26.240 --> 00:28:29.640]   So there's lots of ways.
[00:28:29.640 --> 00:28:34.000]   One way of still using deep learning, again, in tabular data is obviously even in tabular
[00:28:34.000 --> 00:28:38.960]   data, you can imagine certain questions are still open-ended.
[00:28:38.960 --> 00:28:39.960]   Totally.
[00:28:40.880 --> 00:28:43.840]   So I guess what does your infrastructure look like?
[00:28:43.840 --> 00:28:48.920]   Have you standardized everyone on a single machine learning platform?
[00:28:48.920 --> 00:28:56.120]   Have you standardized the frameworks that people use or is it open-ended?
[00:28:56.120 --> 00:29:03.840]   I think in many ways we are far ahead from past experiences or from colleagues that I
[00:29:03.840 --> 00:29:09.920]   know when we discuss about ML ecosystem and the state of affairs with colleagues.
[00:29:09.920 --> 00:29:12.560]   But we have one advantage.
[00:29:12.560 --> 00:29:17.360]   In a way, our ML platform development efforts are relatively new, so we leverage a lot of
[00:29:17.360 --> 00:29:24.840]   the functionality these days are coming from hyperscalers.
[00:29:24.840 --> 00:29:31.320]   Couple of years ago, building an ML platform was a very big deal.
[00:29:31.320 --> 00:29:38.640]   Being able to support different hardware, different workflows, different personas,
[00:29:38.640 --> 00:29:42.000]   even for a small ML team was a big, big deal.
[00:29:42.000 --> 00:29:48.200]   These days we are using hyperscalers, obviously, moving a lot of the kind of heavy lifting
[00:29:48.200 --> 00:29:51.440]   to hyperscale function.
[00:29:51.440 --> 00:29:58.400]   Most of the work we do is basically harmonizing our data and our workflows and expressing
[00:29:58.400 --> 00:30:05.760]   them operation in terms of our platform, which is based on tools like SageMaker and whatnot.
[00:30:05.760 --> 00:30:14.680]   But yeah, so our current ML training, serving, scientist work benches are all standardized.
[00:30:14.680 --> 00:30:16.280]   Yet this is a fast moving field.
[00:30:16.280 --> 00:30:19.080]   There's a lot of new systems, right?
[00:30:19.080 --> 00:30:21.280]   There's small and big players.
[00:30:21.280 --> 00:30:26.240]   You mix and match and then try to leverage the best of both worlds.
[00:30:26.240 --> 00:30:27.720]   Where do you feel like there are gaps?
[00:30:27.720 --> 00:30:33.400]   If somebody was listening and was thinking about making a company to do some ML tooling,
[00:30:33.400 --> 00:30:34.400]   where would you guide them?
[00:30:34.400 --> 00:30:38.640]   Or if our product team wanted to roll out something new, what would you appreciate the
[00:30:38.640 --> 00:30:39.640]   most?
[00:30:39.640 --> 00:30:45.640]   First of all, having been doing ML almost 20 years now, one of the things I most appreciate
[00:30:45.640 --> 00:30:51.760]   is it's kind of a dream coming true for me seeing such a big ecosystem.
[00:30:51.760 --> 00:30:54.640]   Things like, for example, experiment tracking, right?
[00:30:54.640 --> 00:31:01.240]   For those of us who went through grad school by tracking things, I always make this analogy.
[00:31:01.240 --> 00:31:07.160]   I used to work in computational biology field and a lot of my collaborators and peers have
[00:31:07.160 --> 00:31:11.280]   this really nicely organized experiment notebooks, right?
[00:31:11.280 --> 00:31:16.200]   And I felt like I will never be successful in this field because I'm never organized
[00:31:16.200 --> 00:31:17.720]   and in files and whatnot.
[00:31:17.720 --> 00:31:22.600]   With the computer scientists, we can still write scripts and whatnot to organize even
[00:31:22.600 --> 00:31:24.880]   if how messy things are.
[00:31:24.880 --> 00:31:32.840]   But when I work today, I see tools like weight and biases, other tools for monitoring, model
[00:31:32.840 --> 00:31:33.840]   performance monitoring.
[00:31:33.840 --> 00:31:36.920]   Do you have a favorite performance monitoring tool?
[00:31:36.920 --> 00:31:38.960]   Is there one that you use?
[00:31:38.960 --> 00:31:39.960]   Not yet.
[00:31:39.960 --> 00:31:44.000]   We've actually narrowed it down to a couple of things, but we're still actively working
[00:31:44.000 --> 00:31:45.520]   on it.
[00:31:45.520 --> 00:31:56.960]   But my point here is that one of the things I strongly recommend my team is leveraging
[00:31:56.960 --> 00:32:01.680]   productivity boosting tools such as experimentation tracking reproducibility.
[00:32:01.680 --> 00:32:07.080]   For me, the biggest gap is still in CI/CD for a couple of reasons, because I don't think
[00:32:07.080 --> 00:32:10.760]   it's as well understood as other parts of ML lifecycle.
[00:32:10.760 --> 00:32:16.960]   And there are different personas involved, data scientists, ML scientists, ML engineer,
[00:32:16.960 --> 00:32:18.680]   application engineer.
[00:32:18.680 --> 00:32:20.040]   That is a complex problem.
[00:32:20.040 --> 00:32:23.720]   I think the nature of the problem is complex.
[00:32:23.720 --> 00:32:26.960]   Solving that problem to me, it seems like a really, really big.
[00:32:26.960 --> 00:32:32.840]   And I see some actors, including yourself, are doing some really interesting stuff out
[00:32:32.840 --> 00:32:33.840]   there.
[00:32:33.840 --> 00:32:35.520]   So I'm eagerly observing this field.
[00:32:35.520 --> 00:32:39.840]   I think some of the core infrastructure problem in terms of ability to support different hardware
[00:32:39.840 --> 00:32:44.320]   combinations, scale, and all that stuff, that's been solved to a large degree these days.
[00:32:44.320 --> 00:32:50.040]   To me, the next level is really winning these scientists and MLE personas, building something
[00:32:50.040 --> 00:32:55.120]   really they can connect to, because I see the adoption of these tools are still, owing
[00:32:55.120 --> 00:33:00.920]   to being new industry, I still think the adoption is not quite there.
[00:33:00.920 --> 00:33:04.800]   So yeah, CI/CD, I guess I would put in the top there.
[00:33:04.800 --> 00:33:08.660]   And also depending on your application area, monitoring.
[00:33:08.660 --> 00:33:14.920]   And the third, I would probably put, depending again, your industry application focus area,
[00:33:14.920 --> 00:33:18.520]   monitoring but with more focus on that from an operational perspective and more from a
[00:33:18.520 --> 00:33:22.520]   fairness and bias perspective.
[00:33:22.520 --> 00:33:26.160]   There are, these are obviously good thing to pay attention to this.
[00:33:26.160 --> 00:33:33.000]   And there's also these days, societal and legal reasons to pay more attention to this
[00:33:33.000 --> 00:33:36.200]   kind of systems and regulations.
[00:33:36.200 --> 00:33:43.800]   Is there any tooling that you're using or have built to help with fairness or any kind
[00:33:43.800 --> 00:33:46.000]   of explainability at Qualtrics?
[00:33:46.000 --> 00:33:47.000]   Right.
[00:33:47.000 --> 00:33:52.320]   We are definitely looking at that because we know our systems are, we use in a kind
[00:33:52.320 --> 00:33:56.900]   of context sensitive applications.
[00:33:56.900 --> 00:34:01.120]   I don't want to disclose any kind of specific names, but one thing that's happening, I'm
[00:34:01.120 --> 00:34:07.300]   sure you probably are aware in this space is that testing AI systems, developing kind
[00:34:07.300 --> 00:34:14.120]   of testing frameworks, behavioral measurement frameworks for them is fortunately took off
[00:34:14.120 --> 00:34:15.120]   lately.
[00:34:15.120 --> 00:34:23.760]   So there's both tools from academia, papers, tools, as well as industry.
[00:34:23.760 --> 00:34:25.880]   I haven't seen industry adopting it as much.
[00:34:25.880 --> 00:34:29.240]   I might be wrong there to be frank.
[00:34:29.240 --> 00:34:34.400]   There's still, I think some way to go there, but this is becoming, we are definitely looking
[00:34:34.400 --> 00:34:35.400]   at it.
[00:34:35.400 --> 00:34:39.040]   We are looking at our models, how they're behaving under certain, without the gender
[00:34:39.040 --> 00:34:43.540]   bias, either social identity biases.
[00:34:43.540 --> 00:34:47.000]   But bias can creep up in many ways.
[00:34:47.000 --> 00:34:53.960]   So this is going to be a continuous effort in our agenda.
[00:34:53.960 --> 00:34:56.320]   How do you think about building your team?
[00:34:56.320 --> 00:35:00.600]   I guess, how is your team structured now and what skill sets do you look for?
[00:35:00.600 --> 00:35:03.160]   Well, let me start with what my team does.
[00:35:03.160 --> 00:35:13.360]   I guess, so we deal basically all things ML from building the ML platform to working building
[00:35:13.360 --> 00:35:20.040]   data set ontologies, libraries for applications and then beyond.
[00:35:20.040 --> 00:35:27.520]   And then I have two applied science teams that are, one of them is really focusing on
[00:35:27.520 --> 00:35:31.960]   NLP and NLX applications.
[00:35:31.960 --> 00:35:37.920]   As I mentioned, we discussed a lot about surveys, but surveys are basically solicited feedback.
[00:35:37.920 --> 00:35:44.840]   Qualtrics, you would be surprised, we're looking more in terms of volume of the data, actually
[00:35:44.840 --> 00:35:51.920]   much more text data is coming from other channels, social media and customer support applications.
[00:35:51.920 --> 00:35:58.600]   So for NLX, obviously we have a large team and we have made certain investment in this
[00:35:58.600 --> 00:36:03.040]   area to really grow our footprint and expertise in this one.
[00:36:03.040 --> 00:36:11.280]   The other team we have is focusing more on influencing ML to all our product lines.
[00:36:11.280 --> 00:36:16.760]   And that includes more canonical applications of ML from time series modeling, anomaly detection,
[00:36:16.760 --> 00:36:26.000]   recommendation systems, path optimization, yield optimization to fraud detection and
[00:36:26.000 --> 00:36:28.000]   things like that.
[00:36:28.000 --> 00:36:33.120]   And this, it really depends on what business for them, for NLX, obviously we're looking
[00:36:33.120 --> 00:36:35.560]   for subject matter experts, right?
[00:36:35.560 --> 00:36:41.800]   So as I mentioned, as much as we love and use deep learning, where we hire deep learning
[00:36:41.800 --> 00:36:45.840]   expert, we also look and make sure we are linguistically grounded.
[00:36:45.840 --> 00:36:52.880]   So we have a lot of linguist experts who are actually building very deep linguistic packages
[00:36:52.880 --> 00:36:58.280]   analysis to make sure we measure the systems in the right way to serve our customers' needs.
[00:36:58.280 --> 00:37:04.120]   On the more canonical problems, we're actually trying to have a diverse team from a skillset
[00:37:04.120 --> 00:37:07.880]   perspective, deep learning, statistics, engineering.
[00:37:07.880 --> 00:37:12.640]   That field requires really going fast, solving problems and not necessarily all the time
[00:37:12.640 --> 00:37:16.280]   coming with a new approach or bleeding edge algorithms.
[00:37:16.280 --> 00:37:18.560]   Interesting.
[00:37:18.560 --> 00:37:25.160]   And do you think there's anything that specifically makes somebody successful at Qualtrics or
[00:37:25.160 --> 00:37:30.400]   on your team outside of the kind of normal things that a company would look for?
[00:37:30.400 --> 00:37:32.320]   Sure.
[00:37:32.320 --> 00:37:46.680]   So Qualtrics ML is, we've been very focused on over the years as our vision evolved, data
[00:37:46.680 --> 00:37:52.440]   and ML is becoming more and more central to our business because listening to these different
[00:37:52.440 --> 00:37:58.400]   channels, different data model is understanding and predicting and ability to give an actionable
[00:37:58.400 --> 00:38:03.280]   data to our customers to be boiled down to deep data skills.
[00:38:03.280 --> 00:38:08.480]   And we have a lot of ways to leverage this different data, marrying experience data with
[00:38:08.480 --> 00:38:12.600]   operations data and we're uniquely positioned to do that.
[00:38:12.600 --> 00:38:17.680]   So somebody who are, maybe I should even ask everyone, why consider Qualtrics if you're
[00:38:17.680 --> 00:38:20.680]   working in, for example, in ML field?
[00:38:20.680 --> 00:38:26.800]   I think it's pretty much a lot to do with the uniqueness of the problems and the datasets.
[00:38:26.800 --> 00:38:31.800]   When we look at the spectrum of problems, yes, we do have a lot of problems where you
[00:38:31.800 --> 00:38:37.440]   can immediately relate to, but there's a lot of problems that are very unique that doesn't
[00:38:37.440 --> 00:38:45.040]   exist in other fields or the datasets don't exist in other places that are unique.
[00:38:45.040 --> 00:38:46.400]   Obviously the volume is there, right?
[00:38:46.400 --> 00:38:49.360]   The volume of the data we're tackling with.
[00:38:49.360 --> 00:38:56.720]   But someone, I particularly speaking from experience from my team and myself, developing
[00:38:56.720 --> 00:39:02.960]   ML applications for in a B2C setting is very different than B2B setting.
[00:39:02.960 --> 00:39:07.000]   You're dealing with a different customer person.
[00:39:07.000 --> 00:39:13.880]   The supporting the ML cycle, when you think about the model lifecycle, ability to new
[00:39:13.880 --> 00:39:21.680]   models refresh, the implications of them are much more permanent in an enterprise scale.
[00:39:21.680 --> 00:39:29.920]   It's like switching one model just because of new better results is not as fast as, or
[00:39:29.920 --> 00:39:36.160]   you don't have as much degree of freedom as you would have in, I would say, a B2C setting.
[00:39:36.160 --> 00:39:43.320]   I might be overgeneralizing here, but that's my kind of own personal experience.
[00:39:43.320 --> 00:39:44.320]   What else?
[00:39:44.320 --> 00:39:52.960]   Yeah, I guess being B2B, working on a very unique dataset and problems where it's not
[00:39:52.960 --> 00:39:55.720]   always easy to go look up a paper, implement the technique.
[00:39:55.720 --> 00:40:01.800]   You need to really be creative and synthesize new solutions, come up with new ways to look
[00:40:01.800 --> 00:40:03.600]   at the data.
[00:40:03.600 --> 00:40:11.880]   I guess looking at your career, when you came from school into academia, you went to Amazon,
[00:40:11.880 --> 00:40:12.880]   right?
[00:40:12.880 --> 00:40:13.880]   What was the biggest surprise?
[00:40:13.880 --> 00:40:18.440]   I mean, that's always kind of a shock for people, I think, going from research to practical
[00:40:18.440 --> 00:40:19.440]   applications.
[00:40:19.440 --> 00:40:22.760]   What was the biggest surprise for you?
[00:40:22.760 --> 00:40:31.800]   Biggest surprise for me, well, right, actually, 2020, exactly 10 years ago when I was doing
[00:40:31.800 --> 00:40:36.840]   a graduate internship, that was my first industry experience.
[00:40:36.840 --> 00:40:43.040]   I was very academically oriented, usual thing, writing papers, going to conferences and trying
[00:40:43.040 --> 00:40:47.040]   to look for the next step, which is postdoc.
[00:40:47.040 --> 00:40:53.000]   I did, for some personal reasons, instead of spending a research summer, I took an industry
[00:40:53.000 --> 00:40:54.000]   internship.
[00:40:54.000 --> 00:40:58.720]   And instead of ending up in a research lab, which because of visa problems, ended up in
[00:40:58.720 --> 00:41:01.080]   a more industrial applications lab.
[00:41:01.080 --> 00:41:10.720]   And I tremendously enjoyed it because I always, up until that point, I always thought I enjoyed
[00:41:10.720 --> 00:41:15.040]   really tackling tough, technical, scientific, open problems.
[00:41:15.040 --> 00:41:19.680]   But this is when for me, the realization was that I just like solving problems.
[00:41:19.680 --> 00:41:25.360]   And ML, being in the same space in ML, where you still like research, applied research
[00:41:25.360 --> 00:41:29.200]   field, your everyday pretty much is filled with some answer.
[00:41:29.200 --> 00:41:35.080]   You still have that everyday unknown and excitement about what's going to be that this experiment
[00:41:35.080 --> 00:41:36.080]   will work.
[00:41:36.080 --> 00:41:40.520]   You're always continuously thinking, creating, looking at the data, everything changes.
[00:41:40.520 --> 00:41:44.040]   It never gets monotone.
[00:41:44.040 --> 00:41:46.320]   For me, it was never like that.
[00:41:46.320 --> 00:41:52.880]   And then I was making this joke to my team members, but to some degree, it's I think
[00:41:52.880 --> 00:41:53.880]   true.
[00:41:53.880 --> 00:41:57.040]   Fastest return for your work.
[00:41:57.040 --> 00:42:02.800]   Like writing, I have wrote my fair share of papers, but here I see things going to production.
[00:42:02.800 --> 00:42:06.480]   It just gives a different sense of accomplishment, solving problems.
[00:42:06.480 --> 00:42:11.480]   And even today, when I look at what we're doing at Qualtrics, helping our customers
[00:42:11.480 --> 00:42:15.320]   solve their customer problems, I think is an amazing feeling.
[00:42:15.320 --> 00:42:20.880]   And that just keeps me going and focused on staying with problems, even though sometimes
[00:42:20.880 --> 00:42:23.160]   the data or technical problems might be very challenging.
[00:42:23.160 --> 00:42:27.080]   You just, you know, you are, I know it sounds cheesy a little bit, but it does, you are
[00:42:27.080 --> 00:42:28.880]   changing the world.
[00:42:28.880 --> 00:42:35.000]   I just had this terrible experience with one of my home projects and I feel like I've sent
[00:42:35.000 --> 00:42:36.680]   out 30 emails, nobody even bothering.
[00:42:36.680 --> 00:42:43.240]   I like to think in my way, like, "Hey, one day, you know, somebody at the end of that
[00:42:43.240 --> 00:42:47.040]   thing, they'll be at the end of the day, "Hey, Arian's experience is broken.
[00:42:47.040 --> 00:42:48.040]   Let's surface that.
[00:42:48.040 --> 00:42:49.040]   Let's do something about it."
[00:42:49.040 --> 00:42:52.720]   This is the future we're building for Qualtrics.
[00:42:52.720 --> 00:42:53.720]   That's great.
[00:42:53.720 --> 00:42:57.960]   I've definitely come to believe that listening to customer experience survey results is one
[00:42:57.960 --> 00:43:01.160]   of the real keys to building a successful company.
[00:43:01.160 --> 00:43:04.020]   So I actually totally identify with that.
[00:43:04.020 --> 00:43:07.760]   It's a good segue actually into our last two questions.
[00:43:07.760 --> 00:43:13.440]   And the second to last one is basically, what is something that you think is kind of understudied
[00:43:13.440 --> 00:43:14.440]   in machine learning?
[00:43:14.440 --> 00:43:18.640]   Like if you had more time or if you were back in academia, like that you would spend some
[00:43:18.640 --> 00:43:22.040]   time looking into because you think it would be valuable.
[00:43:22.040 --> 00:43:27.240]   I wouldn't say perhaps maybe not understudied, but one thing I'm making to make the big splash
[00:43:27.240 --> 00:43:31.240]   yet is causality.
[00:43:31.240 --> 00:43:38.040]   I must admit before Qualtrics for a couple of years, I worked in the healthcare space
[00:43:38.040 --> 00:43:44.840]   and surprisingly, healthcare is about a kind of a super rich with a lot of interesting
[00:43:44.840 --> 00:43:49.360]   ML problems, very meaningful problems, but also for various reasons, it was going a bit
[00:43:49.360 --> 00:43:54.060]   slow for regularity and other problems in that space.
[00:43:54.060 --> 00:44:03.820]   But it's been a fertile field for a lot of causality research, but we have also an industry
[00:44:03.820 --> 00:44:07.900]   with recommendation systems where we can do some treatment.
[00:44:07.900 --> 00:44:16.100]   We can see how these kinds of systems can actually make a big boost in terms of how
[00:44:16.100 --> 00:44:22.940]   the real way we should think about the ML or we should think about stochasticity and
[00:44:22.940 --> 00:44:24.860]   predictive systems.
[00:44:24.860 --> 00:44:33.140]   But one field, just because of the sheer complexity of obtaining treatment data, we need to work
[00:44:33.140 --> 00:44:36.740]   with observational data in most settings.
[00:44:36.740 --> 00:44:44.580]   And I know there are recent interest in kind of making causality work with observational
[00:44:44.580 --> 00:44:51.020]   data and that will be, I think, game changing for a lot of applications.
[00:44:51.020 --> 00:44:57.860]   But maybe it's not enough investment in that field or it's just fundamentally a hard problem
[00:44:57.860 --> 00:45:00.020]   that we need to be patient about.
[00:45:00.020 --> 00:45:07.780]   I don't know, but that's one field where I'm keenly observing on the side, sorry, waiting
[00:45:07.780 --> 00:45:08.780]   for.
[00:45:08.780 --> 00:45:09.780]   Interesting.
[00:45:09.780 --> 00:45:17.860]   And I guess final question, when you think about going from an idea of a new application
[00:45:17.860 --> 00:45:23.180]   to deployed working in production, what's the biggest bottleneck?
[00:45:23.180 --> 00:45:28.780]   Ah, this is a classical question.
[00:45:28.780 --> 00:45:32.420]   Is this a really classical question or is this just a question I ask all the time?
[00:45:32.420 --> 00:45:36.460]   Well, classical, I'm sorry, maybe classical is not the right term.
[00:45:36.460 --> 00:45:37.460]   Sorry.
[00:45:37.460 --> 00:45:38.460]   The equation.
[00:45:38.460 --> 00:45:39.460]   The equation, yeah.
[00:45:39.460 --> 00:45:40.460]   The equation, right.
[00:45:40.460 --> 00:45:41.460]   Yeah.
[00:45:41.460 --> 00:45:47.740]   The reason is that we know ML is, everybody is excited about it.
[00:45:47.740 --> 00:45:51.100]   Mat has proven its value, right?
[00:45:51.100 --> 00:45:56.180]   But is ML delivering at the scale it's been invested in?
[00:45:56.180 --> 00:45:57.180]   Probably not.
[00:45:57.180 --> 00:46:02.100]   There's all sorts of market research reports out there about showing how much ML is failing,
[00:46:02.100 --> 00:46:03.100]   why it is failing.
[00:46:03.100 --> 00:46:06.580]   I think this boils to that question.
[00:46:06.580 --> 00:46:14.060]   Most of the time it's from going from that proof of concept to production.
[00:46:14.060 --> 00:46:21.420]   To me, in my experience, depending on the settings you are, there can be a couple of
[00:46:21.420 --> 00:46:23.020]   reasons contributing that.
[00:46:23.020 --> 00:46:25.980]   One of them is structural, probably.
[00:46:25.980 --> 00:46:29.500]   And this is where most common case I have observed in my experience from startups to
[00:46:29.500 --> 00:46:32.140]   enterprises to hedge funds to other places.
[00:46:32.140 --> 00:46:37.860]   So it really requires, if you're working for ML, unless you're doing platform work, really,
[00:46:37.860 --> 00:46:48.980]   if you're working with ML for a product feature, that requires a really close connection with
[00:46:48.980 --> 00:46:53.500]   the ML folks with the product folks.
[00:46:53.500 --> 00:47:00.060]   I've seen time after time, ML folks go build models, not cognizant of the underlying production
[00:47:00.060 --> 00:47:06.060]   constraints and whatnot, solving sometimes even not the problem that the product requires.
[00:47:06.060 --> 00:47:09.180]   That's not specific to ML.
[00:47:09.180 --> 00:47:10.660]   That's a system design problem.
[00:47:10.660 --> 00:47:16.020]   You go design the wrong thing or you design the system that's not with respect to the
[00:47:16.020 --> 00:47:19.500]   constraints that system needs to work with.
[00:47:19.500 --> 00:47:29.140]   What particularly becomes problematic in ML is that if you don't have really that structural
[00:47:29.140 --> 00:47:35.940]   support processes in place, scientists, especially those working on not maybe current application,
[00:47:35.940 --> 00:47:46.220]   or a bit more deeper technical problem space, they usually don't know what having a model
[00:47:46.220 --> 00:47:51.620]   in production looks like from productionization, from latency, from input, from output, from
[00:47:51.620 --> 00:47:54.260]   monitoring, from system design perspective.
[00:47:54.260 --> 00:47:58.020]   The way we solve inequality is that we empower ML engineers.
[00:47:58.020 --> 00:48:00.380]   ML engineers, they know ML.
[00:48:00.380 --> 00:48:03.940]   They know they're engineers in heart by training.
[00:48:03.940 --> 00:48:06.460]   We include them from the get-go.
[00:48:06.460 --> 00:48:10.060]   They're in from conception all the way to the product launch.
[00:48:10.060 --> 00:48:14.740]   They moderate and play a very critical role between how this model is going to be used
[00:48:14.740 --> 00:48:16.980]   and what's being designed and moderating that.
[00:48:16.980 --> 00:48:19.700]   To me, that's the essential role machine learning engineers should play.
[00:48:19.700 --> 00:48:24.380]   There's obviously very biased opinion because machine learning engineer or data scientists
[00:48:24.380 --> 00:48:26.860]   and applied scientists, I don't think these are universal definitions.
[00:48:26.860 --> 00:48:29.980]   Every company go with their own way what's going on.
[00:48:29.980 --> 00:48:36.180]   But I've seen that when you don't have a person who understands both domains well and get
[00:48:36.180 --> 00:48:41.900]   involved in the process in place, and I'm not even counting all these infrastructure
[00:48:41.900 --> 00:48:47.060]   issues, I've seen places where they're trying to do NLP in traditional microservice architecture
[00:48:47.060 --> 00:48:48.340]   and things like that.
[00:48:48.340 --> 00:48:51.180]   You don't have the right architecture.
[00:48:51.180 --> 00:48:54.660]   Even if you have the right infrastructure, I think it boils down to having the right
[00:48:54.660 --> 00:48:59.380]   people with the right skillset and having a process, really.
[00:48:59.380 --> 00:49:00.380]   Learning process.
[00:49:00.380 --> 00:49:02.860]   So you don't have basically everybody doing everything.
[00:49:02.860 --> 00:49:05.660]   That's where things start to break down.
[00:49:05.660 --> 00:49:06.940]   That's how we do in Qualtrics.
[00:49:06.940 --> 00:49:13.780]   We have dedicated roles for specializing different aspects of this process, but working always
[00:49:13.780 --> 00:49:14.780]   together end to end.
[00:49:14.780 --> 00:49:17.780]   This is what we call as the trifecta model.
[00:49:17.780 --> 00:49:21.980]   A machine learning engineer, trifecta model.
[00:49:21.980 --> 00:49:27.580]   So the machine learning engineer, the product engineer, and the ML scientist working together.
[00:49:27.580 --> 00:49:29.580]   I see.
[00:49:29.580 --> 00:49:30.580]   Cool.
[00:49:30.580 --> 00:49:31.580]   Awesome.
[00:49:31.580 --> 00:49:32.580]   Well, thanks so much.
[00:49:32.580 --> 00:49:33.580]   I really appreciate your time.
[00:49:33.580 --> 00:49:37.220]   It's fun to talk to someone who's deploying so many models in production, especially at
[00:49:37.220 --> 00:49:38.220]   a B2B company.
[00:49:38.220 --> 00:49:40.300]   You don't hear as many stories of those.
[00:49:40.300 --> 00:49:41.700]   So thank you very much.
[00:49:41.700 --> 00:49:42.700]   Thank you, Lucas.
[00:49:42.700 --> 00:49:48.980]   If you're enjoying these interviews and you want to learn more, please click on the link
[00:49:48.980 --> 00:49:53.700]   to the show notes in the description where you can find links to all the papers that
[00:49:53.700 --> 00:49:58.100]   are mentioned, supplemental material, and a transcription that we work really hard to
[00:49:58.100 --> 00:49:59.100]   produce.
[00:49:59.100 --> 00:50:00.100]   So check it out.

