
[00:00:00.000 --> 00:00:02.720]   You know, the number one question I get from founders
[00:00:02.720 --> 00:00:03.560]   who come in here,
[00:00:03.560 --> 00:00:05.680]   the number one question I get from my LPs
[00:00:05.680 --> 00:00:08.160]   is where are we in this correction?
[00:00:08.160 --> 00:00:12.100]   What stage of grief are we in, Bill?
[00:00:12.100 --> 00:00:13.260]   - And when does it end?
[00:00:13.260 --> 00:00:15.840]   (upbeat music)
[00:00:15.840 --> 00:00:26.720]   - Hey man, good to see you.
[00:00:26.720 --> 00:00:27.600]   - Good to be seen.
[00:00:27.600 --> 00:00:29.320]   - Of course, you know, to the audience,
[00:00:29.320 --> 00:00:32.040]   do your own homework, make your own investing decisions.
[00:00:32.040 --> 00:00:35.080]   We are not your investment gurus.
[00:00:35.080 --> 00:00:36.880]   So Bill, talk to me a little bit
[00:00:36.880 --> 00:00:38.600]   about what you've been thinking about this week.
[00:00:38.600 --> 00:00:41.040]   - Yeah, so one of the things I've been thinking about lately
[00:00:41.040 --> 00:00:42.800]   and we'll go into it in more depth
[00:00:42.800 --> 00:00:46.520]   is how some of the big decisions
[00:00:46.520 --> 00:00:49.180]   and there've been kind of sequence of events
[00:00:49.180 --> 00:00:51.200]   in the large LLM market,
[00:00:51.200 --> 00:00:54.680]   I think are gonna create some pretty big market distortions
[00:00:54.680 --> 00:00:57.600]   that might be felt, you know, along the way
[00:00:57.600 --> 00:00:58.960]   by a number of different players.
[00:00:58.960 --> 00:01:01.240]   So I wanna go in deep on that.
[00:01:01.240 --> 00:01:02.180]   What about yourself?
[00:01:02.180 --> 00:01:05.800]   - Well, I was prepping for our annual LP update today.
[00:01:05.800 --> 00:01:08.440]   I mean, I've been doing these now for over 15 years
[00:01:08.440 --> 00:01:12.120]   and it's always that time of year where I stop,
[00:01:12.120 --> 00:01:15.720]   forces me to telescope out, I think about valuations,
[00:01:15.720 --> 00:01:18.840]   about what's going on with Mag7 over the last year,
[00:01:18.840 --> 00:01:22.800]   about long run tech compounding, about this AI cycle
[00:01:22.800 --> 00:01:24.720]   and what's gonna happen this year.
[00:01:24.720 --> 00:01:28.600]   Then I also had this, you know, I guess my first tweet
[00:01:28.600 --> 00:01:30.280]   that went over a million views
[00:01:30.280 --> 00:01:33.120]   over the course of the last week,
[00:01:33.120 --> 00:01:36.480]   which, you know, it's still amazing to me
[00:01:36.480 --> 00:01:38.980]   that because of regulatory capture,
[00:01:38.980 --> 00:01:41.420]   people just aren't getting their calcium CT exam.
[00:01:41.420 --> 00:01:44.640]   They're still like enslaved to looking at their cholesterol.
[00:01:44.640 --> 00:01:48.440]   We saw the tragic news on that Warriors coach this week,
[00:01:48.440 --> 00:01:52.120]   you know, so I'm just thinking everybody over the age of 40
[00:01:52.120 --> 00:01:54.440]   needs to get this CT scan, but--
[00:01:54.440 --> 00:01:56.160]   - Hey, let me ask you a quick question on this
[00:01:56.160 --> 00:01:57.000]   before we dive in.
[00:01:57.000 --> 00:01:59.120]   So you shared this with me.
[00:01:59.120 --> 00:02:03.640]   I had had a spiked LDL on just a simple test
[00:02:03.640 --> 00:02:07.220]   and I went and did this and it was pretty simple.
[00:02:07.220 --> 00:02:09.680]   I mean, I was in and out, you know, in a flash.
[00:02:09.680 --> 00:02:13.400]   Like it's not like it was a big invasive thing.
[00:02:13.400 --> 00:02:16.240]   And so if it's so simple and so powerful,
[00:02:16.240 --> 00:02:18.760]   why do you think the establishment's fighting it?
[00:02:18.760 --> 00:02:21.860]   - You know, I think we establish standards of care
[00:02:21.860 --> 00:02:23.440]   in this country and in this case,
[00:02:23.440 --> 00:02:27.120]   the standard of care is to track people's cholesterol
[00:02:27.120 --> 00:02:30.240]   and no doctors have an incentive to do anything
[00:02:30.240 --> 00:02:31.600]   other than standard of care.
[00:02:31.600 --> 00:02:33.560]   And so I think they worry about liability.
[00:02:33.560 --> 00:02:36.520]   I think other doctors just aren't on top of it,
[00:02:36.520 --> 00:02:38.440]   but the reality is a CT scan,
[00:02:38.440 --> 00:02:40.280]   you don't need a doctor referral.
[00:02:40.280 --> 00:02:42.320]   It costs less than a hundred bucks, as you know,
[00:02:42.320 --> 00:02:46.000]   takes less than 30 minutes in and out, non-invasive at all.
[00:02:46.000 --> 00:02:49.080]   And it actually will tell you whether or not
[00:02:49.080 --> 00:02:50.840]   you have plaque in your artery.
[00:02:50.840 --> 00:02:53.760]   So, you know, it's, you know, I saw,
[00:02:53.760 --> 00:02:56.320]   I saw after this tragic death this week,
[00:02:56.320 --> 00:02:59.160]   the head of preventative cardiology at Stanford,
[00:02:59.160 --> 00:03:01.060]   Dr. Marin said, you know,
[00:03:01.060 --> 00:03:03.500]   perhaps had he had a calcium CT, he'd be alive today.
[00:03:03.500 --> 00:03:05.000]   So it's just a no brainer.
[00:03:05.000 --> 00:03:07.240]   I'm thrilled that you did it.
[00:03:07.240 --> 00:03:09.760]   I know we've been on this with all of our friends
[00:03:09.760 --> 00:03:12.240]   and so that's good news.
[00:03:12.240 --> 00:03:13.120]   - Awesome.
[00:03:13.120 --> 00:03:14.240]   - Well, let's dig in.
[00:03:14.240 --> 00:03:18.220]   We may as well start with the hottest topic of the day
[00:03:18.220 --> 00:03:20.180]   in Silicon Valley, which is AI.
[00:03:20.180 --> 00:03:23.480]   You know, you stirred the pot a bit this week.
[00:03:23.480 --> 00:03:26.160]   - And it was reacting to a tweet out of your firm.
[00:03:26.160 --> 00:03:30.160]   So put the tweet up, let's tell the story.
[00:03:30.160 --> 00:03:31.120]   So put the tweet up.
[00:03:31.120 --> 00:03:34.760]   What was the point of the tweet and what was in the graph?
[00:03:34.760 --> 00:03:37.620]   Like what was being discussed?
[00:03:37.620 --> 00:03:40.680]   - You know, as you know, so Apoorv on my team
[00:03:40.680 --> 00:03:42.080]   who helps cover AI,
[00:03:42.080 --> 00:03:44.960]   he started looking into the amount
[00:03:44.960 --> 00:03:46.240]   of venture capital investment.
[00:03:46.240 --> 00:03:48.280]   Everybody's talking about whether or not
[00:03:48.280 --> 00:03:49.580]   we're in a VC winter.
[00:03:49.580 --> 00:03:52.640]   But if you look at the aggregated amount of VC capital
[00:03:52.640 --> 00:03:54.640]   that's being invested, it's a big number.
[00:03:54.640 --> 00:03:56.360]   But if you deconstruct it a little bit,
[00:03:56.360 --> 00:03:59.520]   what you see is that we have this explosion
[00:03:59.520 --> 00:04:01.000]   in venture capital investing
[00:04:01.000 --> 00:04:02.800]   coming out of four companies, right?
[00:04:02.800 --> 00:04:04.240]   He called them MANG.
[00:04:04.240 --> 00:04:08.480]   Microsoft, Amazon, you know, NVIDIA and Google.
[00:04:08.480 --> 00:04:10.840]   And so as you can see on this chart,
[00:04:10.840 --> 00:04:14.120]   we go from almost no venture capital investing,
[00:04:14.120 --> 00:04:16.440]   you know, out of these folks six or seven years ago
[00:04:16.440 --> 00:04:20.460]   to all of a sudden this $25 billion last year
[00:04:20.460 --> 00:04:23.140]   in VC investing, it led to the question like,
[00:04:23.140 --> 00:04:24.940]   why is this happening?
[00:04:24.940 --> 00:04:27.740]   And you know, it's not being distributed equally.
[00:04:27.740 --> 00:04:29.340]   It's only going to a few companies.
[00:04:29.340 --> 00:04:31.060]   So really what's going on?
[00:04:31.060 --> 00:04:34.260]   And so I turn to you, you know, you retweeted it.
[00:04:34.260 --> 00:04:36.260]   You had some things to say, what's going on?
[00:04:36.260 --> 00:04:41.260]   - Yeah, and let me start with two kind of high level thoughts
[00:04:41.260 --> 00:04:42.660]   before I drill in.
[00:04:42.660 --> 00:04:45.500]   The first thing is, you know, it's awesome
[00:04:45.500 --> 00:04:48.700]   that this new paradigm has come along.
[00:04:48.700 --> 00:04:51.860]   One of the things that makes venture capital investing,
[00:04:51.860 --> 00:04:54.860]   being a part of Silicon Valley so much fun
[00:04:54.860 --> 00:04:57.600]   is you always get to move on to the new thing.
[00:04:57.600 --> 00:05:00.620]   It's a learn it all mentality all the time.
[00:05:00.620 --> 00:05:03.900]   And it's just super invigorating when the new thing pops up
[00:05:03.900 --> 00:05:06.460]   and everyone gets to go play with it and talk about it.
[00:05:06.460 --> 00:05:07.380]   And you have to learn it.
[00:05:07.380 --> 00:05:09.020]   And if you don't, you get left behind
[00:05:09.020 --> 00:05:11.240]   and it's a big part of the ecosystem.
[00:05:11.240 --> 00:05:14.580]   So it's exciting that there's a new gold rush
[00:05:14.580 --> 00:05:17.220]   and 'cause I'm about to say something
[00:05:17.220 --> 00:05:18.260]   that's going to sound cynical.
[00:05:18.260 --> 00:05:20.260]   And so I want to start with that.
[00:05:20.260 --> 00:05:22.620]   The second thing is, you know, I don't,
[00:05:22.620 --> 00:05:23.820]   some of the things I'm going to say,
[00:05:23.820 --> 00:05:26.580]   I don't have perfect visibility, obviously,
[00:05:26.580 --> 00:05:29.540]   inside these large companies, exactly what they're doing.
[00:05:29.540 --> 00:05:31.380]   But I have an intuition of what's happening.
[00:05:31.380 --> 00:05:33.220]   If anyone out there, you know,
[00:05:33.220 --> 00:05:35.140]   after I make these statements says,
[00:05:35.140 --> 00:05:36.720]   no, Bill, you got it all wrong.
[00:05:36.720 --> 00:05:38.540]   You know, let me know and we'll correct it
[00:05:38.540 --> 00:05:40.000]   and we'll talk about it.
[00:05:40.000 --> 00:05:41.880]   So what I wrote, I'll just read it.
[00:05:41.880 --> 00:05:44.920]   I said, this is what happens when you invest with credits
[00:05:44.920 --> 00:05:47.320]   that allow you to goose your own revenues.
[00:05:47.320 --> 00:05:50.840]   So I think if we think about this historically,
[00:05:50.840 --> 00:05:53.640]   Microsoft found itself in a position
[00:05:53.640 --> 00:05:58.160]   where it realized, one, that AI could have a massive impact
[00:05:58.160 --> 00:05:59.840]   on the products they already have.
[00:05:59.840 --> 00:06:01.540]   And that's been proven, you know,
[00:06:01.540 --> 00:06:03.520]   in the development world with CoPilot,
[00:06:03.520 --> 00:06:05.640]   now they're implementing it for Office
[00:06:05.640 --> 00:06:07.560]   and all the productivity apps.
[00:06:07.560 --> 00:06:10.200]   So they knew it was powerful.
[00:06:10.200 --> 00:06:12.240]   Second, they felt they were behind.
[00:06:12.240 --> 00:06:14.720]   And so they embraced open AI.
[00:06:14.720 --> 00:06:17.200]   And obviously the relationship between Satya
[00:06:17.200 --> 00:06:20.680]   and Sam is quite well known at this point.
[00:06:20.680 --> 00:06:24.760]   As part of that relationship, they made a quote,
[00:06:24.760 --> 00:06:29.000]   and I definitely use quotes, investment in open AI.
[00:06:29.000 --> 00:06:32.160]   And we've been, the world's been told a big part
[00:06:32.160 --> 00:06:34.840]   of that investment wasn't cash dollars,
[00:06:34.840 --> 00:06:37.360]   but credits for cloud services.
[00:06:37.360 --> 00:06:38.200]   - Correct.
[00:06:38.200 --> 00:06:41.560]   - And what we then speculated happened after that
[00:06:41.560 --> 00:06:45.440]   is the other large cloud service providers
[00:06:45.440 --> 00:06:48.960]   became fearful of loss of relevance
[00:06:48.960 --> 00:06:53.120]   or loss of market share because of this type of transaction.
[00:06:53.120 --> 00:06:56.320]   And so we started seeing copycat transactions
[00:06:56.320 --> 00:06:57.960]   happen along the way.
[00:06:57.960 --> 00:07:01.120]   And so the reason I think that,
[00:07:01.120 --> 00:07:03.000]   well, I'll walk into some of the details
[00:07:03.000 --> 00:07:03.940]   of what could happen.
[00:07:03.940 --> 00:07:06.760]   But what I fear is that this is happening
[00:07:06.760 --> 00:07:08.240]   at such a large level,
[00:07:08.240 --> 00:07:10.080]   and maybe we haven't seen the end of it, right?
[00:07:10.080 --> 00:07:12.760]   I think there's reason you can see more,
[00:07:12.760 --> 00:07:14.960]   that it's gonna create a market distortion.
[00:07:14.960 --> 00:07:17.800]   And if we think back to the last cycle,
[00:07:17.800 --> 00:07:20.080]   I lived through the market distortion
[00:07:20.080 --> 00:07:22.320]   created by zero interest rates
[00:07:22.320 --> 00:07:26.280]   and the Vision Fund and the Vision Fund copycats,
[00:07:26.280 --> 00:07:27.760]   and all of a sudden billions of dollars
[00:07:27.760 --> 00:07:28.800]   are piling into companies.
[00:07:28.800 --> 00:07:30.360]   And the reason this matters,
[00:07:30.360 --> 00:07:32.320]   if you're a player in the ecosystem,
[00:07:32.320 --> 00:07:35.400]   is if there's a massive market distortion,
[00:07:35.400 --> 00:07:38.280]   the rules that you've been taught to live by
[00:07:38.280 --> 00:07:41.000]   can all of a sudden either not apply
[00:07:41.000 --> 00:07:42.800]   or there's new rules that apply.
[00:07:42.800 --> 00:07:43.640]   It can get messy.
[00:07:43.640 --> 00:07:44.720]   The playing field can get messy.
[00:07:44.720 --> 00:07:47.180]   - Okay, so let's break it down for just a second.
[00:07:47.180 --> 00:07:51.160]   So I think I understand what you're saying.
[00:07:51.160 --> 00:07:54.960]   So you're basically saying Microsoft decided
[00:07:54.960 --> 00:07:57.520]   to make a big investment in open AI.
[00:07:57.520 --> 00:08:01.200]   Amazon decided to make a big investment into Anthropic,
[00:08:01.200 --> 00:08:03.000]   just as two examples.
[00:08:03.000 --> 00:08:06.360]   And of the billions of dollars that they're investing
[00:08:06.360 --> 00:08:09.360]   at these very high valuations,
[00:08:09.360 --> 00:08:14.360]   those startup companies need to spend those billions
[00:08:14.360 --> 00:08:17.360]   back on the services from the people
[00:08:17.360 --> 00:08:19.160]   who gave them the money.
[00:08:19.160 --> 00:08:20.520]   - And they have the need, right?
[00:08:20.520 --> 00:08:22.120]   They have the need either for training
[00:08:22.120 --> 00:08:26.320]   or even a lot of them are reselling their software
[00:08:26.320 --> 00:08:29.520]   packaged with the compute.
[00:08:29.520 --> 00:08:32.760]   And so it's like a value added service, right?
[00:08:32.760 --> 00:08:35.640]   We're putting AI on top of a CPU
[00:08:35.640 --> 00:08:37.320]   that you would rent otherwise.
[00:08:37.320 --> 00:08:40.400]   Now, let's think about this from both players' side.
[00:08:40.400 --> 00:08:42.720]   From the big company players' side,
[00:08:42.720 --> 00:08:44.720]   I would just say definitively,
[00:08:44.720 --> 00:08:46.600]   and this could get me in trouble,
[00:08:46.600 --> 00:08:49.000]   but this is low quality revenue.
[00:08:49.000 --> 00:08:51.680]   Like this is flat out low quality revenue.
[00:08:51.680 --> 00:08:55.080]   And I'm certain that they've got their auditor
[00:08:55.080 --> 00:08:56.520]   to sign off on it.
[00:08:56.520 --> 00:08:59.080]   But I don't think there's any way you can argue
[00:08:59.080 --> 00:09:00.440]   that it's high quality revenue.
[00:09:00.440 --> 00:09:02.680]   Here's an example I'll give you.
[00:09:02.680 --> 00:09:04.240]   Well, first of all, it's cashless, right?
[00:09:04.240 --> 00:09:05.440]   It's cashless revenue.
[00:09:05.440 --> 00:09:09.600]   So when the credit's reused, you get zero cash coming in
[00:09:09.600 --> 00:09:11.840]   and we know you have an amortized cost
[00:09:11.840 --> 00:09:14.120]   against that big capex that you made.
[00:09:14.120 --> 00:09:16.600]   - And the reason you have zero cash coming in, Bill,
[00:09:16.600 --> 00:09:18.840]   is because you gave the cash,
[00:09:18.840 --> 00:09:21.120]   you gave it to them as a form of investment
[00:09:21.120 --> 00:09:22.960]   and they're turning around and handing it to you.
[00:09:22.960 --> 00:09:25.120]   So from a company's perspective,
[00:09:25.120 --> 00:09:26.920]   it's like taking out of your left pocket
[00:09:26.920 --> 00:09:28.480]   and putting it in your right pocket.
[00:09:28.480 --> 00:09:29.320]   - Well, yeah.
[00:09:29.320 --> 00:09:31.040]   I mean, a big skeptic would say
[00:09:31.040 --> 00:09:32.280]   you're using your balance sheet
[00:09:32.280 --> 00:09:34.480]   to drive your income statement,
[00:09:34.480 --> 00:09:36.560]   which should be a no-no.
[00:09:36.560 --> 00:09:41.600]   The other way I think to highlight the low quality revenue
[00:09:41.600 --> 00:09:43.360]   is imagine there's a startup.
[00:09:43.360 --> 00:09:44.960]   I came up with a cool name for the startup.
[00:09:44.960 --> 00:09:48.040]   It's called the Ultra Hosting Company, UHC.
[00:09:48.040 --> 00:09:52.000]   So UHC got a bunch of money from venture capitalists.
[00:09:52.000 --> 00:09:54.480]   They built a big server farm
[00:09:54.480 --> 00:09:57.600]   and their only customers they have
[00:09:57.600 --> 00:09:59.480]   are companies that they went out
[00:09:59.480 --> 00:10:02.160]   and gave credits away to as a form of investment.
[00:10:02.160 --> 00:10:04.880]   That's 100% of their customers.
[00:10:04.880 --> 00:10:09.160]   So they have tons of revenue as they reuse these things
[00:10:09.160 --> 00:10:11.240]   and zero cash flow whatsoever.
[00:10:11.240 --> 00:10:15.400]   And so I think that highlights it, right?
[00:10:15.400 --> 00:10:16.240]   'Cause some people will say,
[00:10:16.240 --> 00:10:17.720]   oh, it's just a small percentage
[00:10:17.720 --> 00:10:20.000]   of this big company's revenue.
[00:10:20.000 --> 00:10:21.400]   I'm like, it doesn't matter.
[00:10:21.400 --> 00:10:22.760]   It's still, it is what it is.
[00:10:22.760 --> 00:10:27.760]   - So Bill, if we steel man why this might be okay, right?
[00:10:28.360 --> 00:10:30.880]   Because I don't hear you saying this isn't illegal.
[00:10:30.880 --> 00:10:32.440]   You're not saying it's a violation of GAAP.
[00:10:32.440 --> 00:10:34.560]   You're not saying they're defying their auditors.
[00:10:34.560 --> 00:10:37.760]   What you're saying, I think at a minimum
[00:10:37.760 --> 00:10:41.040]   is that if Microsoft is putting money in,
[00:10:41.040 --> 00:10:42.200]   or I hear you saying two things.
[00:10:42.200 --> 00:10:46.480]   If Microsoft's putting money into OpenAI at $90 billion,
[00:10:46.480 --> 00:10:48.040]   I think the first thing I'm hearing you say
[00:10:48.040 --> 00:10:51.040]   is you gotta be a little bit skeptical of that valuation
[00:10:51.040 --> 00:10:54.000]   because it's not exactly an arm's length transaction.
[00:10:54.000 --> 00:10:55.520]   - Well, yeah, and here's another,
[00:10:55.520 --> 00:10:57.440]   here's a way to really drill in on that,
[00:10:57.440 --> 00:10:59.560]   going back to Ultra Hosting Company.
[00:10:59.560 --> 00:11:03.560]   Let's assume for the sake of this discussion
[00:11:03.560 --> 00:11:05.880]   that the service being provided is a commodity.
[00:11:05.880 --> 00:11:10.240]   And one could argue putting a bunch of NVIDIA servers
[00:11:10.240 --> 00:11:13.400]   and GPUs in a cluster and renting them to you
[00:11:13.400 --> 00:11:15.760]   is a commodity service, right?
[00:11:15.760 --> 00:11:20.760]   So if I'm competing with you to invest in this startup
[00:11:20.760 --> 00:11:24.720]   for you to turn around and use my commodity service,
[00:11:24.720 --> 00:11:26.360]   isn't there a strong argument
[00:11:26.360 --> 00:11:27.600]   that the way I would get there
[00:11:27.600 --> 00:11:29.880]   is by taking a price up to a level
[00:11:29.880 --> 00:11:32.200]   where you choose me over them?
[00:11:32.200 --> 00:11:35.840]   And so all of a sudden, you've got definitive proof
[00:11:35.840 --> 00:11:37.440]   that the way you would win the war,
[00:11:37.440 --> 00:11:39.360]   and you get another benefit.
[00:11:39.360 --> 00:11:41.640]   You get revenue, you get market share.
[00:11:41.640 --> 00:11:43.600]   So at the very least, there's an argument
[00:11:43.600 --> 00:11:47.160]   of might you be maximizing this versus that?
[00:11:47.160 --> 00:11:50.440]   And so yes, I think the valuations could be superfluous
[00:11:50.440 --> 00:11:51.440]   as a result of this.
[00:11:51.440 --> 00:11:54.000]   And that's one of the many market distortions
[00:11:54.000 --> 00:11:56.840]   that would happen as a result of this activity.
[00:11:56.840 --> 00:12:00.120]   The second thing is this could all come to an end.
[00:12:00.120 --> 00:12:03.680]   And so I think for the big hosting providers,
[00:12:03.680 --> 00:12:08.680]   having revenue that is non-typical,
[00:12:08.680 --> 00:12:10.600]   let's just call it atypical,
[00:12:10.600 --> 00:12:13.600]   could backfire if we reach a point
[00:12:13.600 --> 00:12:17.480]   which this type of activity is no longer done
[00:12:17.480 --> 00:12:18.360]   for whatever reason.
[00:12:18.360 --> 00:12:20.360]   - Okay, now let's describe a scenario
[00:12:20.360 --> 00:12:23.040]   that I think you would have less issue with, right?
[00:12:23.040 --> 00:12:28.040]   If $10 billion was just invested into OpenAI
[00:12:28.040 --> 00:12:32.640]   by the five leading SandHill firms,
[00:12:32.640 --> 00:12:36.160]   and then if OpenAI in an arm's length commercial transaction
[00:12:36.160 --> 00:12:40.160]   decided to buy $10 billion worth of services
[00:12:40.160 --> 00:12:45.160]   from Microsoft to Azure to train GPT-5, GPT-6, et cetera,
[00:12:45.160 --> 00:12:47.640]   you're saying like that's no problem.
[00:12:47.640 --> 00:12:49.320]   The problem that you see here
[00:12:49.320 --> 00:12:51.120]   is that that's coming from Microsoft.
[00:12:51.120 --> 00:12:55.760]   So I guess when we look at this,
[00:12:55.760 --> 00:13:00.000]   the indicator that there's a problem from you might be,
[00:13:00.000 --> 00:13:02.880]   do these companies have the ability
[00:13:02.880 --> 00:13:04.440]   to raise this type of capital?
[00:13:04.440 --> 00:13:06.680]   Because if they're just substituting Microsoft
[00:13:06.680 --> 00:13:09.160]   for somebody else who could provide the services,
[00:13:09.160 --> 00:13:10.280]   that's one thing.
[00:13:10.280 --> 00:13:13.280]   But if they don't have the ability to raise this capital
[00:13:13.280 --> 00:13:14.760]   from alternative sources,
[00:13:14.760 --> 00:13:19.080]   it would seem to be more evidence of your case.
[00:13:19.080 --> 00:13:21.840]   - Well, and there's another element
[00:13:21.840 --> 00:13:23.800]   that you're touching on 'cause we read,
[00:13:23.800 --> 00:13:26.680]   you might've seen an article in the information this week
[00:13:26.680 --> 00:13:29.800]   about how Google's having to change
[00:13:29.800 --> 00:13:32.160]   their compensation policies to keep up
[00:13:32.160 --> 00:13:36.680]   with the comp that's coming out of the major AI companies.
[00:13:36.680 --> 00:13:40.800]   And we've heard talk of what I would call
[00:13:40.800 --> 00:13:43.160]   pretty early secondaries at OpenAI.
[00:13:43.160 --> 00:13:48.160]   And so if, let's just call it accelerated liquidity
[00:13:49.160 --> 00:13:54.160]   is part of what it takes to get a killer AI engineer,
[00:13:54.160 --> 00:13:59.360]   then you will have to have funding other than just credits
[00:13:59.360 --> 00:14:01.000]   to be able to fund those secondaries.
[00:14:01.000 --> 00:14:03.080]   That's one thing.
[00:14:03.080 --> 00:14:04.160]   But yeah, I agree with you.
[00:14:04.160 --> 00:14:07.200]   Let me talk briefly about why I think this could be
[00:14:07.200 --> 00:14:09.760]   a problem for those players
[00:14:09.760 --> 00:14:14.280]   and even for the other smaller companies in the ecosystem.
[00:14:14.280 --> 00:14:18.880]   So I believe that once you have these credits
[00:14:18.880 --> 00:14:20.640]   inside your company,
[00:14:20.640 --> 00:14:24.760]   somebody is certainly gonna make the argument, right?
[00:14:24.760 --> 00:14:27.320]   Or they're either gonna be ignorant to the cost
[00:14:27.320 --> 00:14:30.840]   because it's now not a real cash cost, right?
[00:14:30.840 --> 00:14:33.440]   I have these huge credits that I'm using
[00:14:33.440 --> 00:14:36.880]   and or they'll fool themselves into thinking
[00:14:36.880 --> 00:14:41.880]   if I sell my service below the replaceable cost
[00:14:42.400 --> 00:14:46.920]   of the credit, that's really a negative gross margin sale.
[00:14:46.920 --> 00:14:50.840]   But I bet you a ton of people walk into that world.
[00:14:50.840 --> 00:14:54.640]   And if there's a price war for AI services,
[00:14:54.640 --> 00:14:55.800]   all these kinds of things,
[00:14:55.800 --> 00:15:00.080]   I could easily imagine people pricing below the credit cost.
[00:15:00.080 --> 00:15:02.760]   So just another distortion that could happen.
[00:15:02.760 --> 00:15:06.120]   I think the difficult thing as an investor for Altimeter,
[00:15:06.120 --> 00:15:11.400]   we looked at all of these businesses, all of these models,
[00:15:11.400 --> 00:15:13.760]   and there were two things that were really difficult for us.
[00:15:13.760 --> 00:15:17.480]   One was the complexity of the transaction.
[00:15:17.480 --> 00:15:22.480]   Just looking at open AI and trying to understand
[00:15:22.480 --> 00:15:25.440]   the nature of the relationship with Microsoft.
[00:15:25.440 --> 00:15:28.840]   Again, I wanna stipulate from the start, as I've said,
[00:15:28.840 --> 00:15:31.560]   I think AI is gonna be bigger than the internet itself.
[00:15:31.560 --> 00:15:36.560]   I mean, using compute to build intelligence
[00:15:36.560 --> 00:15:39.000]   is a powerful thing for all of us.
[00:15:39.000 --> 00:15:41.560]   So I'm actually happy as both a human
[00:15:41.560 --> 00:15:43.960]   and happy as an investor that in fact,
[00:15:43.960 --> 00:15:46.240]   these models are getting funded
[00:15:46.240 --> 00:15:47.640]   and that they're being built.
[00:15:47.640 --> 00:15:50.000]   But I'm just saying as an arm's length investor,
[00:15:50.000 --> 00:15:53.320]   looking at these valuations, it was hard for me to even,
[00:15:53.320 --> 00:15:54.920]   and I've been doing this a long time,
[00:15:54.920 --> 00:15:58.560]   to even understand the nature of the security I was buying
[00:15:58.560 --> 00:16:00.200]   and the relationship with these companies.
[00:16:00.200 --> 00:16:03.560]   So I think that's why a lot of firms like Altimeter
[00:16:03.560 --> 00:16:06.080]   have had trouble getting to a yes decision.
[00:16:06.080 --> 00:16:08.840]   Set aside the fundamental decision,
[00:16:08.840 --> 00:16:12.720]   which is can these companies actually generate
[00:16:12.720 --> 00:16:15.600]   a lot of durable and ongoing revenue from this
[00:16:15.600 --> 00:16:17.440]   if we have open source providers
[00:16:17.440 --> 00:16:19.840]   who are going to collapse the price of the market
[00:16:19.840 --> 00:16:20.680]   down to zero?
[00:16:20.680 --> 00:16:23.280]   So for us, we haven't invested in any of these.
[00:16:23.280 --> 00:16:24.680]   These were the two bigger challenges,
[00:16:24.680 --> 00:16:27.200]   but I will say I haven't invested,
[00:16:27.200 --> 00:16:29.920]   but I've sat here and thought to myself,
[00:16:29.920 --> 00:16:32.160]   man, I may be missing the biggest thing in the world
[00:16:32.160 --> 00:16:36.440]   because open AI and Anthropic and these other companies,
[00:16:36.440 --> 00:16:39.480]   their valuations have continued to skyrocket.
[00:16:39.480 --> 00:16:41.760]   The usage is very clear.
[00:16:41.760 --> 00:16:44.880]   The teams that they built are absolutely remarkable.
[00:16:44.880 --> 00:16:47.280]   What they're putting into the market is terrific,
[00:16:47.280 --> 00:16:49.880]   but I do think that it is a really important thing
[00:16:49.880 --> 00:16:54.880]   that you're pointing out, which is at a very minimum,
[00:16:54.880 --> 00:16:59.280]   I think we can say that the participation of MANG,
[00:16:59.280 --> 00:17:02.560]   Microsoft, Amazon, Nvidia, and Google,
[00:17:02.560 --> 00:17:05.480]   is distorting the price in the market
[00:17:05.480 --> 00:17:07.560]   in a way that wouldn't have occur
[00:17:07.560 --> 00:17:09.520]   if it was all arm's length transaction
[00:17:09.520 --> 00:17:10.600]   with financial investors.
[00:17:10.600 --> 00:17:14.560]   Yeah, and I'm also not saying anything negative
[00:17:14.560 --> 00:17:17.040]   about the companies or the technology or what they built.
[00:17:17.040 --> 00:17:20.520]   My primary point is that they've done
[00:17:20.520 --> 00:17:22.600]   these unusual transactions.
[00:17:22.600 --> 00:17:27.400]   That has become, that has been mimicked, right?
[00:17:27.400 --> 00:17:30.120]   It's become a bit viral and the competitors
[00:17:30.120 --> 00:17:31.760]   have had to do it as well.
[00:17:31.760 --> 00:17:34.080]   And now it's at such a scale where I think
[00:17:34.080 --> 00:17:36.480]   it could distort the market that we're in.
[00:17:36.480 --> 00:17:37.800]   In the ways that I talked about.
[00:17:37.800 --> 00:17:40.200]   I'll tell you one other negative externality of this,
[00:17:40.200 --> 00:17:42.840]   one other fallout of doing this, right?
[00:17:42.840 --> 00:17:44.840]   If we have the largest companies in the world
[00:17:44.840 --> 00:17:46.920]   who are effectively anointing the winners
[00:17:46.920 --> 00:17:49.560]   with their capital, it makes it really hard
[00:17:49.560 --> 00:17:51.840]   for a true startup that has to raise money
[00:17:51.840 --> 00:17:54.960]   from venture capitalists who don't have $25 billion
[00:17:54.960 --> 00:17:57.560]   to deploy to be able to raise the capital
[00:17:57.560 --> 00:17:59.360]   required to compete.
[00:17:59.360 --> 00:18:01.840]   It's a sport of kings, sport of kings.
[00:18:01.840 --> 00:18:04.680]   And look, one person said to me,
[00:18:04.680 --> 00:18:07.840]   well, if Amazon can't buy a vacuum cleaner company,
[00:18:07.840 --> 00:18:09.560]   what are they supposed to do with their capital?
[00:18:09.560 --> 00:18:14.560]   So it may be that the lack of M&A leads to people
[00:18:14.560 --> 00:18:20.800]   to be more experimental with how they wanna deploy CapEx
[00:18:20.800 --> 00:18:22.880]   and get usage off of that CapEx.
[00:18:22.880 --> 00:18:24.680]   That could play a role here as well.
[00:18:24.680 --> 00:18:27.680]   - Well, I think that the thing I'm gonna be looking for,
[00:18:27.680 --> 00:18:31.440]   Bill, we know there is a lot of secondary transaction
[00:18:31.440 --> 00:18:33.160]   being done at that $90 billion.
[00:18:33.160 --> 00:18:35.560]   In all of these, there's a lot of secondary being done.
[00:18:35.560 --> 00:18:38.240]   You've talked at length about secondary
[00:18:38.240 --> 00:18:41.520]   at these early stages as being a warning sign
[00:18:41.520 --> 00:18:44.920]   and not good for the culture of these companies.
[00:18:44.920 --> 00:18:47.440]   One of the things I'm gonna be looking for is,
[00:18:47.440 --> 00:18:48.680]   do they- - By the way,
[00:18:48.680 --> 00:18:51.720]   maybe it's a great thing for the players.
[00:18:51.720 --> 00:18:54.120]   They say, don't hate the player, hate the game.
[00:18:54.120 --> 00:18:57.640]   And in some ways, it's just equivalent
[00:18:57.800 --> 00:19:02.800]   to the latest sports figure getting the breakthrough deal.
[00:19:02.800 --> 00:19:06.000]   I'm talking about for the AI engineers themselves.
[00:19:06.000 --> 00:19:08.000]   - So is the answer to this, Bill,
[00:19:08.000 --> 00:19:09.400]   like if both of these companies,
[00:19:09.400 --> 00:19:12.240]   if OpenAI and Anthropic went public,
[00:19:12.240 --> 00:19:13.760]   washed their cap tables out,
[00:19:13.760 --> 00:19:15.880]   now had to raise the money from the public markets
[00:19:15.880 --> 00:19:17.360]   to the extent they were burning it,
[00:19:17.360 --> 00:19:21.680]   would you feel better about the health of the situation?
[00:19:21.680 --> 00:19:26.680]   - Yeah, by the way, health implies, once again, it's negative.
[00:19:27.040 --> 00:19:29.080]   I just think it's really different.
[00:19:29.080 --> 00:19:33.280]   And when you have different factors,
[00:19:33.280 --> 00:19:37.600]   these large externalities in the market that we all play in,
[00:19:37.600 --> 00:19:39.160]   all of a sudden the rules are different
[00:19:39.160 --> 00:19:41.160]   and the game plays out in a different way.
[00:19:41.160 --> 00:19:43.920]   That's my only warning is watch out.
[00:19:43.920 --> 00:19:47.400]   I think there will be ramifications of having done this.
[00:19:47.400 --> 00:19:48.320]   That's my main thing.
[00:19:48.320 --> 00:19:51.320]   - The one thing I'm pretty excited about
[00:19:51.320 --> 00:19:54.160]   is we have a lot of competition, right?
[00:19:54.160 --> 00:19:56.960]   It's very clear this is viewed internally
[00:19:56.960 --> 00:20:00.160]   as somewhat existential at Microsoft,
[00:20:00.160 --> 00:20:03.760]   Amazon, Nvidia, Google, et cetera.
[00:20:03.760 --> 00:20:06.080]   And you're gonna have a lot of competition.
[00:20:06.080 --> 00:20:08.880]   These companies have incredible balance sheets.
[00:20:08.880 --> 00:20:11.880]   As a result of this incredible investment,
[00:20:11.880 --> 00:20:16.400]   we're probably going to accelerate the path to AGI.
[00:20:16.400 --> 00:20:18.880]   So I'm glad they are deploying their capital,
[00:20:18.880 --> 00:20:20.800]   but I agree with you.
[00:20:20.800 --> 00:20:22.040]   It makes it very difficult
[00:20:22.040 --> 00:20:24.120]   for the venture capitalists out there.
[00:20:24.120 --> 00:20:25.480]   And for other founders,
[00:20:25.480 --> 00:20:27.720]   if you're a founder and you wanna compete in this,
[00:20:27.720 --> 00:20:29.680]   you know, in the model game,
[00:20:29.680 --> 00:20:31.240]   you know, and you don't have their backing,
[00:20:31.240 --> 00:20:32.960]   there is no chance.
[00:20:32.960 --> 00:20:35.400]   - And while we're here, I can't help but mention it.
[00:20:35.400 --> 00:20:38.640]   It's, you know, you mentioned open source.
[00:20:38.640 --> 00:20:43.200]   I personally am just a massive believer in open source.
[00:20:43.200 --> 00:20:45.040]   And there's a topic we're gonna get to later
[00:20:45.040 --> 00:20:47.520]   that I think we'll all come back to it.
[00:20:47.520 --> 00:20:50.280]   But it's so powerful for society
[00:20:50.280 --> 00:20:53.280]   that these ideas can be shared so openly.
[00:20:53.280 --> 00:20:57.080]   And for me, it's been a sad reality
[00:20:57.080 --> 00:20:59.760]   that some of the larger LLM players
[00:20:59.760 --> 00:21:02.880]   have literally attacked open source directly
[00:21:02.880 --> 00:21:06.840]   and are telling, you know, regulators to try and disable it.
[00:21:06.840 --> 00:21:09.040]   And when I see that, you know,
[00:21:09.040 --> 00:21:11.600]   because I've never seen it this early in a market,
[00:21:11.600 --> 00:21:15.440]   well, I've never even seen attacking open source before.
[00:21:15.440 --> 00:21:18.000]   And I recognize it's highly competitive,
[00:21:18.000 --> 00:21:19.840]   but when I see it, it makes me skeptical.
[00:21:19.840 --> 00:21:22.040]   And I look at the LLM models.
[00:21:22.040 --> 00:21:24.440]   I mean, they're scaled up on parameter count
[00:21:24.440 --> 00:21:27.040]   and the width of the attention window.
[00:21:27.040 --> 00:21:29.760]   There easily could be limitations to that.
[00:21:29.760 --> 00:21:34.760]   Like, if you just think about how optimization models work,
[00:21:34.760 --> 00:21:35.760]   they could run out.
[00:21:35.760 --> 00:21:39.240]   Like, it's not infinite scaling on those types of things.
[00:21:39.240 --> 00:21:41.240]   And then a very smart,
[00:21:41.240 --> 00:21:43.160]   I was having a conversation with Melanie Mitchell
[00:21:43.160 --> 00:21:47.200]   from the Santa Fe Institute is a very smart AI specialist.
[00:21:47.200 --> 00:21:50.720]   And she thinks data may be what causes the asymptote.
[00:21:50.720 --> 00:21:52.640]   In other words, what new data
[00:21:52.640 --> 00:21:54.320]   are you going to put in the training model?
[00:21:54.320 --> 00:21:56.160]   It's already sucked everything up.
[00:21:56.160 --> 00:22:00.680]   And so those things could cause a bit of an asymptote,
[00:22:00.680 --> 00:22:03.440]   a bit of a ceiling and the open source models,
[00:22:03.440 --> 00:22:06.160]   at least on all the performance tests that are being published
[00:22:06.160 --> 00:22:08.440]   are just running fast behind.
[00:22:08.440 --> 00:22:13.400]   And so I could see why the players might try
[00:22:13.400 --> 00:22:15.920]   and cut off open sources needs.
[00:22:15.920 --> 00:22:18.120]   It makes me disgusted.
[00:22:18.120 --> 00:22:19.320]   I really hate it.
[00:22:19.320 --> 00:22:20.680]   - I also think it's impossible.
[00:22:20.680 --> 00:22:24.720]   You saw that thread out of Zuckerberg this week,
[00:22:24.720 --> 00:22:25.840]   where he said by the end of the year,
[00:22:25.840 --> 00:22:26.880]   they're going to have the equivalent
[00:22:26.880 --> 00:22:31.880]   or this year 600,000 H100 GPUs running in super compute.
[00:22:31.880 --> 00:22:35.880]   And that he was, and there's been a lot of debate on this
[00:22:35.880 --> 00:22:39.880]   and he made it clear, they're committed to open sourcing AGI.
[00:22:39.880 --> 00:22:43.600]   And it just reminds me of the conversations
[00:22:43.600 --> 00:22:46.840]   that you've seen Elon have on X.
[00:22:46.840 --> 00:22:51.280]   And he's raising capital for his own X.AI.
[00:22:51.280 --> 00:22:54.440]   But we have a company called OpenAI
[00:22:54.440 --> 00:22:57.320]   that clearly is a closed model and we have-
[00:22:57.320 --> 00:22:58.760]   - And used to be open source.
[00:22:58.760 --> 00:22:59.600]   - Right.
[00:22:59.600 --> 00:23:00.880]   - And now attacking open source.
[00:23:00.880 --> 00:23:05.200]   - And we have the founder who everybody thought was,
[00:23:05.200 --> 00:23:07.360]   perhaps not in favor of open source
[00:23:07.360 --> 00:23:09.320]   who's actually running the open source model now.
[00:23:09.320 --> 00:23:12.680]   So I think the competitive landscape looks great.
[00:23:12.680 --> 00:23:16.120]   We have not seen any bumping up against those scaling laws.
[00:23:16.120 --> 00:23:19.560]   I think, you know, Alad said in a tweet yesterday,
[00:23:19.560 --> 00:23:20.960]   we're going to have four or five companies
[00:23:20.960 --> 00:23:23.960]   that hit chat GPT-4 level this year with their models.
[00:23:23.960 --> 00:23:26.280]   I think that's exactly right.
[00:23:26.280 --> 00:23:27.600]   I think it's going to be an exciting time,
[00:23:27.600 --> 00:23:29.280]   but maybe, what do you think about-
[00:23:29.280 --> 00:23:30.440]   - We can circle back to-
[00:23:30.440 --> 00:23:32.160]   - Let's jump over to our second topic.
[00:23:32.160 --> 00:23:33.000]   - Okay, great.
[00:23:33.000 --> 00:23:36.040]   So you just had your big LP meeting.
[00:23:36.040 --> 00:23:38.240]   Why don't you, if you're willing to,
[00:23:38.240 --> 00:23:40.240]   pull the curtain back a little bit
[00:23:40.240 --> 00:23:42.960]   and tell the world what you're talking about.
[00:23:42.960 --> 00:23:45.360]   - Well, you know, as you know,
[00:23:45.360 --> 00:23:48.280]   we cover both public and venture markets.
[00:23:48.280 --> 00:23:52.280]   And, you know, I had this thesis 15 years ago
[00:23:52.280 --> 00:23:56.640]   as a founder that venture capital companies
[00:23:56.640 --> 00:23:58.000]   were going to stay private longer.
[00:23:58.000 --> 00:23:59.400]   They were going to scale faster.
[00:23:59.400 --> 00:24:02.400]   They were going to have more impact on the public markets.
[00:24:02.400 --> 00:24:03.920]   I think that's played out exactly
[00:24:03.920 --> 00:24:05.160]   how we thought that it would.
[00:24:05.160 --> 00:24:08.120]   I mean, you have 40, 50, in the case of ByteDance,
[00:24:08.120 --> 00:24:11.400]   a $300 billion still venture company,
[00:24:11.400 --> 00:24:13.200]   private company that's not public.
[00:24:13.200 --> 00:24:16.400]   And so the insights you can glean from being in that market
[00:24:16.400 --> 00:24:19.440]   really in order to the value on the public side
[00:24:19.440 --> 00:24:21.600]   and then from public back to venture.
[00:24:21.600 --> 00:24:24.360]   This morning, you know, like the things we went through,
[00:24:24.360 --> 00:24:26.560]   it causes me to telescope out and think about this.
[00:24:26.560 --> 00:24:29.720]   Last year, we saw this multiple expansion.
[00:24:29.720 --> 00:24:32.080]   I would call it really reversion to the mean
[00:24:32.080 --> 00:24:35.680]   as the market played catch up to the big pullback, right?
[00:24:35.680 --> 00:24:38.800]   Remember 2022, and maybe we can pull up this chart
[00:24:38.800 --> 00:24:41.480]   that we showed on software valuations.
[00:24:41.480 --> 00:24:43.720]   But, you know, if you think about the pullback that
[00:24:43.720 --> 00:24:46.920]   happened, Mike Wilson said, we're
[00:24:46.920 --> 00:24:49.680]   going to have a hard landing at the beginning of last year.
[00:24:49.680 --> 00:24:53.400]   Larry Summers was causing a panic about interest rates.
[00:24:53.400 --> 00:24:55.760]   Things like Meta and Uber and Nvidia,
[00:24:55.760 --> 00:24:57.080]   they all had massive pullbacks.
[00:24:57.080 --> 00:24:57.720]   Think about it.
[00:24:57.720 --> 00:25:00.880]   Meta was trading at six times earnings.
[00:25:00.880 --> 00:25:03.640]   And so if you look at this chart, what this chart shows,
[00:25:03.640 --> 00:25:07.080]   and this is public software kind of valuations.
[00:25:07.080 --> 00:25:10.760]   And you can see that we were over 100%
[00:25:10.760 --> 00:25:14.280]   above the 10-year historical valuation,
[00:25:14.280 --> 00:25:18.000]   that blue line in the middle of '21 and '22.
[00:25:18.000 --> 00:25:22.000]   We troughed at the beginning of '23 at about 35%.
[00:25:22.000 --> 00:25:23.080]   And what was that, Brad?
[00:25:23.080 --> 00:25:27.480]   Was that this kind of, we live in a COVID world forever now,
[00:25:27.480 --> 00:25:30.760]   software is the only place that the world exists?
[00:25:30.760 --> 00:25:31.680]   That kind of thinking.
[00:25:31.680 --> 00:25:35.600]   Right, remember, we were talking about this chart
[00:25:35.600 --> 00:25:37.240]   in our own chats.
[00:25:37.240 --> 00:25:40.560]   And we were saying, man, this doesn't make any sense.
[00:25:40.560 --> 00:25:43.240]   But we knew it was zero interest rates,
[00:25:43.240 --> 00:25:45.200]   the ZURP environment that was leading to this.
[00:25:45.200 --> 00:25:48.240]   I just listened to a pod you and I did at Soan Conference
[00:25:48.240 --> 00:25:50.360]   in May of 2021, Bill.
[00:25:50.360 --> 00:25:52.600]   I should have been able to save myself a lot more money
[00:25:52.600 --> 00:25:55.760]   because we were worried about interest rates and multiples
[00:25:55.760 --> 00:25:59.320]   and inflation in May of '21 before the Fed started acting.
[00:25:59.320 --> 00:26:00.960]   And that was part of it.
[00:26:00.960 --> 00:26:02.640]   But remember, everybody said, well,
[00:26:02.640 --> 00:26:04.560]   maybe it's different this time.
[00:26:04.560 --> 00:26:07.640]   Because we pulled forward digitization,
[00:26:07.640 --> 00:26:09.600]   nobody's going to leave their house.
[00:26:09.600 --> 00:26:12.000]   Everybody's going to have to buy everything online
[00:26:12.000 --> 00:26:13.080]   and do everything online.
[00:26:13.080 --> 00:26:17.000]   So I think people tried to justify these multiples.
[00:26:17.000 --> 00:26:19.800]   But at the start of last year, we
[00:26:19.800 --> 00:26:26.440]   were down to 30%, 35% below the 10-year historical average.
[00:26:26.440 --> 00:26:27.640]   We had a big run up.
[00:26:27.640 --> 00:26:30.360]   You saw a lot of these names, Meta, Uber, Nvidia,
[00:26:30.360 --> 00:26:35.920]   up over 100% over the course of the last year.
[00:26:35.920 --> 00:26:38.120]   But that brings us to where we are today.
[00:26:38.120 --> 00:26:39.200]   So you really got to go.
[00:26:39.200 --> 00:26:42.920]   Maybe we can bring up this next chart, which
[00:26:42.920 --> 00:26:45.760]   is we shared this with our investors.
[00:26:45.760 --> 00:26:47.240]   We said, OK, great.
[00:26:47.240 --> 00:26:51.680]   The beginning of 2023 was an incredible opportunity,
[00:26:51.680 --> 00:26:53.880]   Meta trading at six times earnings.
[00:26:53.880 --> 00:26:55.160]   But what about today?
[00:26:55.160 --> 00:26:59.000]   Well, this shows you the multiple expansion
[00:26:59.000 --> 00:27:00.680]   that we saw in '23.
[00:27:00.680 --> 00:27:03.880]   And now both tech and non-tech are
[00:27:03.880 --> 00:27:07.440]   trading at a premium to the 10-year average.
[00:27:07.440 --> 00:27:09.400]   So the blue line represents tech.
[00:27:09.400 --> 00:27:10.600]   This is the Qs.
[00:27:10.600 --> 00:27:15.440]   We're trading at about a 36% premium to the 10-year average.
[00:27:15.440 --> 00:27:16.720]   I just showed you software.
[00:27:16.720 --> 00:27:18.880]   Software is still trading at a discount
[00:27:18.880 --> 00:27:21.160]   because people are more skeptical of software.
[00:27:21.160 --> 00:27:24.200]   But when you look at the Qs, Nvidia, Microsoft,
[00:27:24.200 --> 00:27:26.920]   some of these bigger names, it really shows you that premium.
[00:27:26.920 --> 00:27:28.880]   And then even non-tech-- and this
[00:27:28.880 --> 00:27:31.440]   is the one that's a bit of a head scratcher to me--
[00:27:31.440 --> 00:27:36.040]   non-tech is trading at a premium, a 12% premium
[00:27:36.040 --> 00:27:37.600]   to the 10-year average.
[00:27:37.600 --> 00:27:42.240]   And then finally, a show by comparison.
[00:27:42.240 --> 00:27:45.520]   If we look at this next chart, the big three, what I call
[00:27:45.520 --> 00:27:50.240]   Microsoft, Nvidia, and Meta, they, too,
[00:27:50.240 --> 00:27:53.400]   are trading at a premium, about a 14% premium.
[00:27:53.400 --> 00:27:54.960]   But if you look at their peg ratio,
[00:27:54.960 --> 00:27:59.600]   this is growth-adjusted on the bottom of that slide.
[00:27:59.600 --> 00:28:01.520]   They're basically trading in line
[00:28:01.520 --> 00:28:05.320]   with where they've traded the last 10 years.
[00:28:05.320 --> 00:28:07.840]   So what does all this tells us?
[00:28:07.840 --> 00:28:08.800]   It tells--
[00:28:08.800 --> 00:28:10.800]   Hey, can I-- let me interrupt.
[00:28:10.800 --> 00:28:15.440]   And then we're going to go back to what does all this tell you.
[00:28:15.440 --> 00:28:18.880]   One thing that we've never spent a lot of time talking about
[00:28:18.880 --> 00:28:22.920]   is that the largest companies in our world
[00:28:22.920 --> 00:28:25.400]   have some of the highest growth rates.
[00:28:25.400 --> 00:28:28.080]   And I think that's unprecedented.
[00:28:28.080 --> 00:28:30.640]   Why do you think that's happening?
[00:28:30.640 --> 00:28:31.960]   Well, I'll tell you.
[00:28:31.960 --> 00:28:35.080]   Remember, back at Harvard Business School,
[00:28:35.080 --> 00:28:38.880]   they taught us the diminishing returns of scale.
[00:28:38.880 --> 00:28:42.000]   Remember the-- I think it was Lou Gershner wrote the book
[00:28:42.000 --> 00:28:43.200]   Elephants Can Dance?
[00:28:43.200 --> 00:28:44.200]   Yeah.
[00:28:44.200 --> 00:28:46.800]   There was this idea that elephants can't dance,
[00:28:46.800 --> 00:28:49.880]   that companies get large, they can't innovate,
[00:28:49.880 --> 00:28:52.280]   they can't earn a great return on capital.
[00:28:52.280 --> 00:28:56.120]   And so eventually, they get competed away.
[00:28:56.120 --> 00:28:59.480]   I would suggest that we actually have a new phenomenon going on
[00:28:59.480 --> 00:29:03.480]   in the world, which is an increasing advantage of scale,
[00:29:03.480 --> 00:29:05.800]   not a decreasing advantage of scale.
[00:29:05.800 --> 00:29:07.000]   And why is that?
[00:29:07.000 --> 00:29:12.480]   Well, because if you want to train on 600,000 H100s
[00:29:12.480 --> 00:29:15.840]   like we just talked Zuckerberg doing with the Lama 3 model,
[00:29:15.840 --> 00:29:18.880]   you have to have a business that is generating
[00:29:18.880 --> 00:29:22.040]   the massive cash piles that he's generating in order
[00:29:22.040 --> 00:29:22.960]   to do that.
[00:29:22.960 --> 00:29:25.280]   And so I do think, like you said,
[00:29:25.280 --> 00:29:28.400]   it's a very unique moment in time.
[00:29:28.400 --> 00:29:31.800]   Now listen, that doesn't mean that you're there forever.
[00:29:31.800 --> 00:29:34.960]   I've been out there saying Google's got a lot of challenges
[00:29:34.960 --> 00:29:38.680]   as they try to transition their search monopoly to their answer
[00:29:38.680 --> 00:29:39.640]   monopoly.
[00:29:39.640 --> 00:29:41.920]   I think they're wrapped around an axle in terms
[00:29:41.920 --> 00:29:47.440]   of doing the things they need to do to catch up and to compete
[00:29:47.440 --> 00:29:50.160]   and to protect that search monopoly.
[00:29:50.160 --> 00:29:52.200]   But I do think that this is a moment in time
[00:29:52.200 --> 00:29:55.440]   where there are those increasing advantages of scale.
[00:29:55.440 --> 00:29:56.960]   Listen to this figure.
[00:29:56.960 --> 00:30:04.480]   We expect-- our forecast is that Microsoft and Amazon,
[00:30:04.480 --> 00:30:07.040]   Snowflake, they'll all accelerate their growth rates
[00:30:07.040 --> 00:30:08.080]   this year.
[00:30:08.080 --> 00:30:11.160]   Accelerating your growth rate-- as an old stock analyst,
[00:30:11.160 --> 00:30:13.960]   accelerating your growth rate at that scale
[00:30:13.960 --> 00:30:16.680]   is unheard of, unheard of.
[00:30:16.680 --> 00:30:20.280]   And so that's kind of the takedown, that we were--
[00:30:20.280 --> 00:30:22.480]   OK, so I took you off on that.
[00:30:22.480 --> 00:30:24.440]   Let's go back.
[00:30:24.440 --> 00:30:29.400]   You presented a lot of data, a lot of historic--
[00:30:29.400 --> 00:30:30.760]   to here we are now.
[00:30:30.760 --> 00:30:32.000]   Now what does it mean?
[00:30:32.000 --> 00:30:34.040]   What does that mean for people going forward?
[00:30:34.040 --> 00:30:34.960]   Yeah, I mean, listen.
[00:30:34.960 --> 00:30:39.720]   I think that, as the charts have showed, all attack,
[00:30:39.720 --> 00:30:43.400]   if you look at the Qs combined, they certainly aren't the deal
[00:30:43.400 --> 00:30:45.400]   they were at the start of '23.
[00:30:45.400 --> 00:30:49.240]   Like, the amazing thing is that we had the lowest exposures
[00:30:49.240 --> 00:30:51.240]   at the start of '23.
[00:30:51.240 --> 00:30:54.080]   Investors were so nervous they weren't investing,
[00:30:54.080 --> 00:30:56.560]   and yet things were being given away for free.
[00:30:56.560 --> 00:30:59.400]   And now we see some of that money coming off the sidelines,
[00:30:59.400 --> 00:31:00.880]   out of those money market accounts,
[00:31:00.880 --> 00:31:02.880]   into all of these names.
[00:31:02.880 --> 00:31:08.800]   After, meta has moved from $90 a share to $380 a share.
[00:31:08.800 --> 00:31:11.680]   I still think there are great returns to be had here,
[00:31:11.680 --> 00:31:13.840]   but the returns are much more normalized.
[00:31:13.840 --> 00:31:18.080]   I think the return to target in our portfolio is 20% to 30%,
[00:31:18.080 --> 00:31:22.480]   whereas the start of last year, Bill, it was like 80%.
[00:31:22.480 --> 00:31:24.920]   And we saw those returns play out.
[00:31:24.920 --> 00:31:25.880]   So that's the big thing.
[00:31:25.880 --> 00:31:27.440]   The world is normalized.
[00:31:27.440 --> 00:31:28.840]   Multiples have normalized.
[00:31:28.840 --> 00:31:32.120]   It's not going to be as easy as it was at the start of '23.
[00:31:32.120 --> 00:31:33.960]   I want to show one other chart, because I
[00:31:33.960 --> 00:31:37.600]   think this is the thing that we don't talk
[00:31:37.600 --> 00:31:39.000]   about enough in this business.
[00:31:39.000 --> 00:31:43.600]   And this is long-term, long-run compounding in tech.
[00:31:43.600 --> 00:31:45.120]   You know how it goes with our friends.
[00:31:45.120 --> 00:31:50.160]   We're always talking about much more shorter-term stuff.
[00:31:50.160 --> 00:31:53.440]   But this chart, I had my team pulled together.
[00:31:53.440 --> 00:31:58.600]   And I said, if we look over the last 10 years,
[00:31:58.600 --> 00:32:03.680]   what have earnings compounded at for tech versus non-tech?
[00:32:03.680 --> 00:32:05.800]   And what have stock prices compounded
[00:32:05.800 --> 00:32:07.520]   at at tech versus non-tech?
[00:32:07.520 --> 00:32:09.440]   Is all this just a bunch of crazy people
[00:32:09.440 --> 00:32:12.520]   in Silicon Valley that are running up prices and multiples?
[00:32:12.520 --> 00:32:16.440]   Or is there a reason that tech has grown faster?
[00:32:16.440 --> 00:32:20.000]   And if you look at this, over the last 10 years,
[00:32:20.000 --> 00:32:24.640]   technology companies have compounded earnings at 13%.
[00:32:24.640 --> 00:32:27.720]   And their stock prices have compounded at 17%,
[00:32:27.720 --> 00:32:30.920]   so a little bit faster than earnings have compounded.
[00:32:30.920 --> 00:32:33.680]   But if you look at non-tech, so if you take the S&P
[00:32:33.680 --> 00:32:35.800]   and you strip out all the tech companies,
[00:32:35.800 --> 00:32:40.600]   they've only compounded earnings at about 6%.
[00:32:40.600 --> 00:32:43.800]   And their stock prices have grown at about 8%.
[00:32:43.800 --> 00:32:46.280]   So let me ask you this question, Bill.
[00:32:46.280 --> 00:32:49.440]   Technology has gone from 5% of global GDP
[00:32:49.440 --> 00:32:52.800]   to 15% over the course of the last 15 years.
[00:32:52.800 --> 00:32:55.600]   When we have this conversation five or 10 years now,
[00:32:55.600 --> 00:33:01.120]   is tech going to be more or less than 15% of global GDP?
[00:33:01.120 --> 00:33:04.320]   I'm going to say more, but with an asterisk.
[00:33:04.320 --> 00:33:10.920]   So your chart has left off 2009 and 1999.
[00:33:10.920 --> 00:33:13.440]   And if you were--
[00:33:13.440 --> 00:33:16.680]   the argument you're making can be used holistically
[00:33:16.680 --> 00:33:18.360]   at any point in time.
[00:33:18.360 --> 00:33:24.080]   But if your point of entry is '99, '09, or the top of--
[00:33:24.080 --> 00:33:28.640]   the end of 2021 here, you're not in a good place.
[00:33:28.640 --> 00:33:30.240]   So maybe you have to--
[00:33:30.240 --> 00:33:32.240]   what do you call when you roll in?
[00:33:32.240 --> 00:33:35.320]   Like dollar cost average or something?
[00:33:35.320 --> 00:33:36.880]   Price of entry matters.
[00:33:36.880 --> 00:33:40.240]   But what I would suggest to you is it's almost certain
[00:33:40.240 --> 00:33:42.960]   that tech's going to be a larger portion of the global GDP
[00:33:42.960 --> 00:33:46.520]   in 5, 10 years because technology is becoming
[00:33:46.520 --> 00:33:48.600]   more important every day in every company's life,
[00:33:48.600 --> 00:33:49.720]   every person's life.
[00:33:49.720 --> 00:33:51.200]   The second thing I would tell you
[00:33:51.200 --> 00:33:53.600]   is that I think that technology in aggregate
[00:33:53.600 --> 00:33:57.800]   will continue to out-earn non-technology companies.
[00:33:57.800 --> 00:33:58.280]   Why?
[00:33:58.280 --> 00:34:01.120]   Because of the age of efficiency.
[00:34:01.120 --> 00:34:03.680]   Why? Because of an AI super cycle.
[00:34:03.680 --> 00:34:08.800]   And so what I said basically, if you're playing from home,
[00:34:08.800 --> 00:34:12.360]   I think the biggest free lunch in all of investing
[00:34:12.360 --> 00:34:16.560]   is the asymmetric bet over the long haul on technology
[00:34:16.560 --> 00:34:17.720]   companies compounding.
[00:34:17.720 --> 00:34:19.680]   Now, the hard thing, as you know, Bill,
[00:34:19.680 --> 00:34:23.400]   is are you able to pick the ones that do the best versus the
[00:34:23.400 --> 00:34:24.560]   ones that don't do great?
[00:34:24.560 --> 00:34:26.720]   Because we know lots of technology companies
[00:34:26.720 --> 00:34:29.040]   get wiped out, get wiped out.
[00:34:29.040 --> 00:34:31.240]   So I mean, I think unless you do it for a living,
[00:34:31.240 --> 00:34:33.320]   you probably just buy the index and you're betting
[00:34:33.320 --> 00:34:36.080]   on technology out-compounding.
[00:34:36.080 --> 00:34:39.080]   For us, we have a lot of fun trying
[00:34:39.080 --> 00:34:41.480]   to pick the ones that are going to be the winners versus--
[00:34:41.480 --> 00:34:42.680]   What are the best--
[00:34:42.680 --> 00:34:45.240]   I don't know if you know, but just for listeners,
[00:34:45.240 --> 00:34:48.160]   what are the best tech indexes?
[00:34:48.160 --> 00:34:49.600]   Or are there other ones?
[00:34:49.600 --> 00:34:52.880]   Listen, there are a lot of ETFs like growth software ETFs
[00:34:52.880 --> 00:34:55.600]   or growth internet ETFs.
[00:34:55.600 --> 00:34:57.120]   You can invest in the Qs.
[00:34:57.120 --> 00:35:01.800]   It turns out that even the SPY, which is the S&P 500 index,
[00:35:01.800 --> 00:35:04.840]   is very quickly becoming a tech index.
[00:35:04.840 --> 00:35:07.880]   And so I think a big mistake-- here's an interesting one.
[00:35:07.880 --> 00:35:12.680]   A big mistake that a lot of technology investors have made
[00:35:12.680 --> 00:35:15.600]   is nobody feels smart just investing
[00:35:15.600 --> 00:35:16.760]   in the big companies.
[00:35:16.760 --> 00:35:20.000]   They want to present to their friends the company nobody's
[00:35:20.000 --> 00:35:22.960]   ever heard of that turns into a 10-bagger or a 50-bagger
[00:35:22.960 --> 00:35:24.280]   or a 100-bagger.
[00:35:24.280 --> 00:35:26.040]   It's a much more interesting conversation
[00:35:26.040 --> 00:35:28.560]   to have a cocktail party presenting that idea
[00:35:28.560 --> 00:35:31.160]   than it is presenting the idea for Microsoft, which
[00:35:31.160 --> 00:35:32.880]   is going to compound at 15%, which
[00:35:32.880 --> 00:35:37.760]   has led investors to be grossly under-leveraged
[00:35:37.760 --> 00:35:40.160]   to the largest companies that have done the best
[00:35:40.160 --> 00:35:43.200]   and over-leveraged to the rest of the technology complex.
[00:35:43.200 --> 00:35:46.600]   And we just mentioned you had an unusual--
[00:35:46.600 --> 00:35:50.240]   I mean, I can't articulate how unusual
[00:35:50.240 --> 00:35:52.640]   it is for the biggest companies to be succeeding,
[00:35:52.640 --> 00:35:56.880]   because my entire career up until now,
[00:35:56.880 --> 00:35:59.440]   the large companies become a laughingstock.
[00:35:59.440 --> 00:36:02.520]   And Microsoft had a window, Freesatche,
[00:36:02.520 --> 00:36:04.240]   where it was in that place.
[00:36:04.240 --> 00:36:08.160]   It was considered to be like HP or DEC or IBM.
[00:36:08.160 --> 00:36:12.080]   And it was just assumed that the startups would come along
[00:36:12.080 --> 00:36:15.600]   and roll them, and that the big company gets stodgy and lead
[00:36:15.600 --> 00:36:17.720]   footed and falls behind.
[00:36:17.720 --> 00:36:20.640]   So this is a different world we're in.
[00:36:20.640 --> 00:36:21.840]   Yeah, I agree with that.
[00:36:21.840 --> 00:36:26.120]   Hey, how about we shift gears here a second?
[00:36:26.120 --> 00:36:27.200]   So that's public markets.
[00:36:27.200 --> 00:36:28.480]   Great year in '23.
[00:36:28.480 --> 00:36:30.320]   '24 going to be a little more challenging.
[00:36:30.320 --> 00:36:32.040]   People panicked when we started the year.
[00:36:32.040 --> 00:36:34.720]   Mag 7 was down, I don't know, 5%.
[00:36:34.720 --> 00:36:36.800]   Now it's up a lot.
[00:36:36.800 --> 00:36:39.960]   And so we'll see where it shakes out.
[00:36:39.960 --> 00:36:45.640]   But VC, man, we've talked a lot about this,
[00:36:45.640 --> 00:36:48.520]   where we are in this VC correction.
[00:36:48.520 --> 00:36:50.920]   The number one question I get from founders
[00:36:50.920 --> 00:36:53.840]   who come in here, the number one question I get from my LPs
[00:36:53.840 --> 00:36:56.400]   is, where are we in this correction?
[00:36:56.400 --> 00:37:00.240]   What stage of grief are we in, Bill?
[00:37:00.240 --> 00:37:02.440]   And when does it end?
[00:37:02.440 --> 00:37:05.720]   Well, look, for reasons that you and I have talked about a lot,
[00:37:05.720 --> 00:37:10.520]   I think the most differentiated element of this correction,
[00:37:10.520 --> 00:37:15.040]   versus '09, versus '01, is the amount of capital
[00:37:15.040 --> 00:37:18.240]   that the companies went into the correction with,
[00:37:18.240 --> 00:37:22.320]   the speed at which they lowered cost afterwards.
[00:37:22.320 --> 00:37:23.640]   So there wasn't denial.
[00:37:23.640 --> 00:37:25.640]   Everyone got along pretty quickly.
[00:37:25.640 --> 00:37:30.600]   And therefore, the elongated window, months of cash--
[00:37:30.600 --> 00:37:32.240]   it'll encourage a lot of our companies
[00:37:32.240 --> 00:37:35.440]   to track months of cash, just burn rate divided by how much
[00:37:35.440 --> 00:37:37.080]   you have in the bank account.
[00:37:37.080 --> 00:37:38.200]   That was elongated.
[00:37:38.200 --> 00:37:41.840]   And so things are taking long to play out,
[00:37:41.840 --> 00:37:44.760]   because the day of reckoning has been pushed out.
[00:37:44.760 --> 00:37:50.120]   Now, one thing that's really wild to me, in '01 and '02,
[00:37:50.120 --> 00:37:52.760]   when a company went bankrupt, it was news.
[00:37:52.760 --> 00:37:55.040]   Every single one of them, when they shut down,
[00:37:55.040 --> 00:38:01.280]   there was this website called F'd Company that literally
[00:38:01.280 --> 00:38:02.080]   tracked them.
[00:38:02.080 --> 00:38:03.520]   And the VCs were--
[00:38:03.520 --> 00:38:06.960]   For those at home who couldn't see your air quotes, Bill,
[00:38:06.960 --> 00:38:09.960]   that was F'd Up Company.
[00:38:09.960 --> 00:38:10.560]   Yeah.
[00:38:10.560 --> 00:38:12.640]   And the guy that ran that site actually
[00:38:12.640 --> 00:38:17.080]   runs a really cool company in the audio space
[00:38:17.080 --> 00:38:19.400]   that helps you post on Spotify.
[00:38:19.400 --> 00:38:22.720]   Anyway, we were all vilified.
[00:38:22.720 --> 00:38:24.040]   We were just taken down.
[00:38:24.040 --> 00:38:26.080]   Oh, you've got these dumb companies.
[00:38:26.080 --> 00:38:27.880]   That doesn't seem to be happening.
[00:38:27.880 --> 00:38:29.680]   You guys stumbled on this chart.
[00:38:29.680 --> 00:38:30.760]   You can pull up--
[00:38:30.760 --> 00:38:33.280]   I think it's from Carta data or something.
[00:38:33.280 --> 00:38:38.920]   But the first 3/4 of 2023 saw--
[00:38:38.920 --> 00:38:43.080]   what is it-- around 180, 1/4 of shutdowns.
[00:38:43.080 --> 00:38:46.320]   And so our run rate-- let's assume the run rate's like 200.
[00:38:46.320 --> 00:38:49.080]   We're at like 800 a year shutdown.
[00:38:49.080 --> 00:38:50.200]   No one's writing about it.
[00:38:50.200 --> 00:38:52.040]   I mean, we had convoy.
[00:38:52.040 --> 00:38:54.840]   There's a few high-profile ones where people wrote about.
[00:38:54.840 --> 00:38:59.200]   For the most part, I guess with the election in Ukraine
[00:38:59.200 --> 00:39:04.280]   and Gaza, there's so much going on that maybe people just
[00:39:04.280 --> 00:39:05.000]   don't give a shit.
[00:39:05.000 --> 00:39:09.120]   But it's wild that it's happening so quietly.
[00:39:09.120 --> 00:39:10.560]   So that's one thing.
[00:39:10.560 --> 00:39:12.360]   I guess it is happening, even though--
[00:39:12.360 --> 00:39:16.520]   I mean, it's not so quiet in Silicon Valley.
[00:39:16.520 --> 00:39:21.240]   Like, I feel for a lot of founders and, frankly,
[00:39:21.240 --> 00:39:23.080]   early-stage venture capital firms,
[00:39:23.080 --> 00:39:25.160]   even when companies are doing well,
[00:39:25.160 --> 00:39:27.400]   they're really having challenges raising
[00:39:27.400 --> 00:39:29.400]   a follow-on round of capital.
[00:39:29.400 --> 00:39:32.400]   Yeah, and if you look at this other chart,
[00:39:32.400 --> 00:39:35.920]   series A and series B type funding, it's way down.
[00:39:35.920 --> 00:39:39.640]   And that's where you take out the credit funding
[00:39:39.640 --> 00:39:42.800]   we were talking about and get that out of the mix.
[00:39:42.800 --> 00:39:46.280]   And so, yeah, it's tough.
[00:39:46.280 --> 00:39:48.320]   You and I have discussed this many times,
[00:39:48.320 --> 00:39:52.120]   but I think the number one thing a founder can do
[00:39:52.120 --> 00:39:55.680]   is to, as quickly as possible, get
[00:39:55.680 --> 00:39:59.400]   in touch with what your real actual valuation is
[00:39:59.400 --> 00:40:03.360]   and then ask yourself, what do I need to do structurally
[00:40:03.360 --> 00:40:05.280]   to give this company a fighting chance,
[00:40:05.280 --> 00:40:07.240]   knowing that that's reality?
[00:40:07.240 --> 00:40:12.440]   And I think a lot of people live in a reality distortion field.
[00:40:12.440 --> 00:40:18.920]   This, to me, is something that I'm deeply passionate about
[00:40:18.920 --> 00:40:23.160]   because I think it's a unique moment in time
[00:40:23.160 --> 00:40:27.920]   right now, where I think, because of what happened
[00:40:27.920 --> 00:40:33.000]   in Zerp, Bill, founder-friendly, this term founder-friendly,
[00:40:33.000 --> 00:40:36.240]   it kind of was like just telling the founder what
[00:40:36.240 --> 00:40:38.120]   they wanted to hear.
[00:40:38.120 --> 00:40:42.160]   Whereas, maybe pull up this tweet from Jam and Ball,
[00:40:42.160 --> 00:40:47.960]   my team last week, and I'll just read you what he said.
[00:40:47.960 --> 00:40:51.480]   Lots of talk about getting fit, but too few boards
[00:40:51.480 --> 00:40:55.800]   and founders are having honest conversations.
[00:40:55.800 --> 00:40:57.640]   I've always preached to the team here,
[00:40:57.640 --> 00:40:59.360]   founder-friendly is doing the right thing
[00:40:59.360 --> 00:41:01.520]   and being truthful with founders,
[00:41:01.520 --> 00:41:03.600]   like the letter to Meta on time to get fit,
[00:41:03.600 --> 00:41:08.600]   saying up front what's too often discussed outside the boardroom
[00:41:08.600 --> 00:41:12.440]   and behind their backs, even if it means making hard decisions
[00:41:12.440 --> 00:41:17.200]   like layoffs, selling, shutting down, down rounds, et cetera.
[00:41:17.200 --> 00:41:21.280]   And so I look at the situation today, frankly,
[00:41:21.280 --> 00:41:24.320]   I don't know whether it's because venture capitalists are
[00:41:24.320 --> 00:41:27.120]   a lot younger, a lot of people just moved into the system,
[00:41:27.120 --> 00:41:29.480]   they haven't seen a drawdown before,
[00:41:29.480 --> 00:41:32.280]   whether they're on too many boards and spread too thin,
[00:41:32.280 --> 00:41:35.360]   so they just can't handle the deluge of conversation.
[00:41:35.360 --> 00:41:39.360]   But my biggest concern is that boards haven't even
[00:41:39.360 --> 00:41:42.720]   been having the tough conversations, right?
[00:41:42.720 --> 00:41:46.800]   We certainly have the examples like you pointed out.
[00:41:46.800 --> 00:41:49.600]   And take something like Klarna, and I
[00:41:49.600 --> 00:41:52.040]   think Sequoia deserves some credit here.
[00:41:52.040 --> 00:41:53.680]   If you look at Klarna or you look
[00:41:53.680 --> 00:41:58.440]   at what happened in Instacart, I mean, Klarna's 2021 round,
[00:41:58.440 --> 00:42:03.640]   right, $46 billion led by SoftBank, Sequoia, Dragoneer,
[00:42:03.640 --> 00:42:06.400]   Silverlake in that round, $46 billion.
[00:42:06.400 --> 00:42:11.920]   They do a round in '22 at $6.7 billion, right,
[00:42:11.920 --> 00:42:13.320]   Sequoia and Silverlake.
[00:42:13.320 --> 00:42:17.680]   That, to me, is a great set of people around a board table
[00:42:17.680 --> 00:42:20.440]   having an honest conversation with the founder
[00:42:20.440 --> 00:42:22.560]   and getting the business reset.
[00:42:22.560 --> 00:42:26.160]   You cannot-- it's not good for the employees.
[00:42:26.160 --> 00:42:28.720]   It's not good for the company.
[00:42:28.720 --> 00:42:31.200]   It's not good for the investors if you're
[00:42:31.200 --> 00:42:35.880]   living in delusion when it comes to your cap table
[00:42:35.880 --> 00:42:37.120]   and to your evaluation.
[00:42:37.120 --> 00:42:40.320]   So I think we're starting to see more momentum of this.
[00:42:40.320 --> 00:42:42.320]   I certainly know in our portfolio,
[00:42:42.320 --> 00:42:45.680]   we're pushing really hard on every board that we're on,
[00:42:45.680 --> 00:42:48.080]   on having those conversations, getting liquid.
[00:42:48.080 --> 00:42:51.120]   If you don't have a model that you feel comfortable with
[00:42:51.120 --> 00:42:53.640]   to get back to that valuation, you can sell the business.
[00:42:53.640 --> 00:42:56.240]   But you've got to sell, restructure, or take
[00:42:56.240 --> 00:42:57.120]   the business public.
[00:42:57.120 --> 00:42:58.720]   I mean, those are the doors.
[00:42:58.720 --> 00:43:02.000]   Yeah, people get overly focused on this last round
[00:43:02.000 --> 00:43:03.040]   valuation thing.
[00:43:03.040 --> 00:43:04.040]   Like, it is--
[00:43:04.040 --> 00:43:07.640]   I can't tell you how many founders
[00:43:07.640 --> 00:43:09.280]   I've had a conversation with where
[00:43:09.280 --> 00:43:12.800]   it's clear the number one objective in their function
[00:43:12.800 --> 00:43:15.160]   about the next financing is to clear
[00:43:15.160 --> 00:43:16.640]   the bar of the last round.
[00:43:16.640 --> 00:43:19.280]   And it just shouldn't matter that much.
[00:43:19.280 --> 00:43:21.840]   Especially after we just went over the waterfall
[00:43:21.840 --> 00:43:24.800]   that we did, you've got to just get that out of your head.
[00:43:24.800 --> 00:43:26.040]   It's so stupid.
[00:43:26.040 --> 00:43:29.800]   You've created an artificial constraint
[00:43:29.800 --> 00:43:32.760]   that's just not that big a deal at the end of the day.
[00:43:32.760 --> 00:43:34.200]   I used to have this chart--
[00:43:34.200 --> 00:43:37.000]   I wish I had prepared it-- but of the logos
[00:43:37.000 --> 00:43:39.640]   of the public companies that traded below their offering
[00:43:39.640 --> 00:43:40.360]   price.
[00:43:40.360 --> 00:43:42.760]   And it's some of the best companies in the world.
[00:43:42.760 --> 00:43:44.280]   It includes Amazon and Salesforce.
[00:43:44.280 --> 00:43:45.040]   And Google.
[00:43:45.040 --> 00:43:47.920]   And yeah, a whole bunch of great companies.
[00:43:47.920 --> 00:43:52.120]   And yet, if you go to IPO and you're arguing over price,
[00:43:52.120 --> 00:43:55.920]   they'll say, the one thing you can't possibly let happen
[00:43:55.920 --> 00:43:58.040]   is you trade below your offering price,
[00:43:58.040 --> 00:44:01.000]   even though some of the greatest companies in the world did it.
[00:44:01.000 --> 00:44:04.160]   And so I think that's a similar kind of silly constraint
[00:44:04.160 --> 00:44:05.320]   that people throw out there.
[00:44:05.320 --> 00:44:08.720]   I would say this about your initial comment.
[00:44:08.720 --> 00:44:11.640]   Some of the board members are just too young.
[00:44:11.640 --> 00:44:13.000]   They have never lived through it.
[00:44:13.000 --> 00:44:14.200]   They don't know.
[00:44:14.200 --> 00:44:16.240]   They were trained in the last 10 years.
[00:44:16.240 --> 00:44:18.200]   They've only seen up.
[00:44:18.200 --> 00:44:21.040]   Some of them are naive, which means
[00:44:21.040 --> 00:44:23.960]   they haven't studied economics and finance to the extent
[00:44:23.960 --> 00:44:25.280]   that they should.
[00:44:25.280 --> 00:44:29.280]   I might point them to one of my favorite blog posts,
[00:44:29.280 --> 00:44:31.600]   the keys to the 10x revenue club.
[00:44:31.600 --> 00:44:36.160]   Because Silicon Valley mostly lives on price
[00:44:36.160 --> 00:44:38.120]   to revenue multiples.
[00:44:38.120 --> 00:44:42.560]   It is the conversation du jour in Silicon Valley.
[00:44:42.560 --> 00:44:44.840]   And it's one of the most naive ways
[00:44:44.840 --> 00:44:48.360]   you could value a financial asset in the world.
[00:44:48.360 --> 00:44:50.800]   And so people just need to sharpen their pencils
[00:44:50.800 --> 00:44:51.600]   to a certain extent.
[00:44:51.600 --> 00:44:53.800]   Yeah, I mean, just a couple of comments there.
[00:44:53.800 --> 00:44:57.600]   I mean, you and I both know, we talked about it even
[00:44:57.600 --> 00:44:59.800]   at the top, price to revenue.
[00:44:59.800 --> 00:45:02.360]   So you see this all the time in software.
[00:45:02.360 --> 00:45:05.440]   It's just a shorthand for investors
[00:45:05.440 --> 00:45:07.920]   to get to discounted free cash flow.
[00:45:07.920 --> 00:45:09.320]   But here's the problem.
[00:45:09.320 --> 00:45:11.080]   Because I live in the public markets,
[00:45:11.080 --> 00:45:13.320]   we do DCFs all the time.
[00:45:13.320 --> 00:45:15.920]   But how many people in Silicon Valley
[00:45:15.920 --> 00:45:19.000]   even build a model on the company, right?
[00:45:19.000 --> 00:45:21.000]   Like there's just not a lot of that that goes on.
[00:45:21.000 --> 00:45:22.800]   If you're doing seed in series A,
[00:45:22.800 --> 00:45:26.120]   that's not what this is predicated on either.
[00:45:26.120 --> 00:45:29.000]   But when you're investing in a business at over a billion
[00:45:29.000 --> 00:45:31.560]   dollar valuation, you sure as the hell
[00:45:31.560 --> 00:45:34.320]   better be building a model and understanding
[00:45:34.320 --> 00:45:36.840]   what the exit value is going to be based
[00:45:36.840 --> 00:45:40.120]   upon a normalized multiple into the public markets.
[00:45:40.120 --> 00:45:43.320]   And so I think way too little of that was going on.
[00:45:43.320 --> 00:45:47.200]   We're seeing these corrections beginning to occur.
[00:45:47.200 --> 00:45:49.520]   But if I go back to my first question
[00:45:49.520 --> 00:45:52.520]   I had for you on this topic, Bill, I went back
[00:45:52.520 --> 00:45:56.280]   and I saw a talk you did in 2012.
[00:45:56.280 --> 00:45:59.480]   And somebody said, oh, 2008 wasn't so bad.
[00:45:59.480 --> 00:46:01.480]   We've bounced right back, et cetera.
[00:46:01.480 --> 00:46:06.440]   And you said, you know, listen, 2008, 2009
[00:46:06.440 --> 00:46:09.040]   wasn't so bad because the bubble never got that big.
[00:46:09.040 --> 00:46:11.720]   And here's the interesting thing about what you said.
[00:46:11.720 --> 00:46:16.200]   You said, I don't know if we'll ever see a bubble again
[00:46:16.200 --> 00:46:19.120]   like we saw in 1999.
[00:46:19.120 --> 00:46:25.760]   So was the ZURP bubble as big as the bubble we saw in 1999?
[00:46:25.760 --> 00:46:30.080]   And will it take us the same four or five years
[00:46:30.080 --> 00:46:32.640]   that it took in 1999 for the world
[00:46:32.640 --> 00:46:37.200]   to work through that entire backlog?
[00:46:37.200 --> 00:46:39.840]   Well, it was wildly different in terms
[00:46:39.840 --> 00:46:41.600]   of one thing, which is the amount of capital
[00:46:41.600 --> 00:46:42.920]   being thrown around.
[00:46:42.920 --> 00:46:45.760]   And so the companies--
[00:46:45.760 --> 00:46:49.880]   in '99, a huge round was $20, $30 million.
[00:46:49.880 --> 00:46:53.120]   And so we went well past that with billion dollar rounds
[00:46:53.120 --> 00:46:53.920]   and whatnot.
[00:46:53.920 --> 00:46:56.360]   And so from that standpoint, I think
[00:46:56.360 --> 00:47:00.040]   you could argue maybe the price height of the bubble
[00:47:00.040 --> 00:47:02.400]   may have been similar, or maybe even lower,
[00:47:02.400 --> 00:47:04.440]   because then we were giving companies
[00:47:04.440 --> 00:47:05.880]   with no revenue huge prices.
[00:47:05.880 --> 00:47:09.120]   But the capital intensity of the bubble,
[00:47:09.120 --> 00:47:12.720]   I would say is a more important metric, was bigger.
[00:47:12.720 --> 00:47:13.680]   It was bigger.
[00:47:13.680 --> 00:47:15.320]   And how long will it take?
[00:47:15.320 --> 00:47:15.960]   I don't know.
[00:47:15.960 --> 00:47:17.760]   I mean, I'd love to see companies
[00:47:17.760 --> 00:47:19.040]   start going public again.
[00:47:19.040 --> 00:47:20.840]   You and I have talked about this.
[00:47:20.840 --> 00:47:22.720]   I don't think the window's closed.
[00:47:22.720 --> 00:47:24.760]   Like, you may not like the valuation.
[00:47:24.760 --> 00:47:26.680]   Like, you've got to decide.
[00:47:26.680 --> 00:47:29.080]   You may be afraid to be public.
[00:47:29.080 --> 00:47:31.560]   You may have had someone tell you it's too hard.
[00:47:31.560 --> 00:47:32.560]   Like, all those things.
[00:47:32.560 --> 00:47:33.600]   But it's not closed.
[00:47:33.600 --> 00:47:35.520]   Like, it's just a matter of price.
[00:47:35.520 --> 00:47:39.800]   And it just takes a while for everyone
[00:47:39.800 --> 00:47:42.200]   to get busy getting busy after you've come through--
[00:47:42.200 --> 00:47:42.680]   For sure.
[00:47:42.680 --> 00:47:45.280]   I may even take it a step further, Bill.
[00:47:45.280 --> 00:47:49.720]   There is a voracious, voracious appetite for IPOs.
[00:47:49.720 --> 00:47:53.400]   Normally, we have over 100 tech IPOs a year.
[00:47:53.400 --> 00:47:56.720]   And we've basically gone two years with no tech IPOs.
[00:47:56.720 --> 00:47:59.120]   Well, we had three, but whatever.
[00:47:59.120 --> 00:48:01.160]   No, you had a handful.
[00:48:01.160 --> 00:48:02.560]   But I'll tell you this.
[00:48:02.560 --> 00:48:03.480]   Yeah.
[00:48:03.480 --> 00:48:06.800]   Most of the folks who are on the buy side, right?
[00:48:06.800 --> 00:48:10.160]   So think about whether you're a long only fund, a capital
[00:48:10.160 --> 00:48:14.200]   group, or TRO, or whether you're Altimeter, or CO2, or Tiger,
[00:48:14.200 --> 00:48:15.840]   et cetera, right?
[00:48:15.840 --> 00:48:18.200]   If all you're buying is Mag 7, you're
[00:48:18.200 --> 00:48:19.960]   feeling a little bit uncomfortable.
[00:48:20.000 --> 00:48:23.560]   You're looking for new ideas all the time, right?
[00:48:23.560 --> 00:48:26.920]   And so I think the only thing holding us back
[00:48:26.920 --> 00:48:29.560]   is to find high-quality companies that
[00:48:29.560 --> 00:48:31.640]   are going to the public markets and accepting
[00:48:31.640 --> 00:48:34.680]   the valuations of the public markets, which
[00:48:34.680 --> 00:48:36.200]   is the market-clearing price.
[00:48:36.200 --> 00:48:39.600]   I think you're going to see the dam really
[00:48:39.600 --> 00:48:41.240]   break on this this year, particularly
[00:48:41.240 --> 00:48:42.520]   in the back half of this year.
[00:48:42.520 --> 00:48:46.040]   And the reason is because people got to raise capital, right?
[00:48:46.040 --> 00:48:48.520]   And I just think they're coming to grips with it.
[00:48:48.520 --> 00:48:50.600]   And I thought we would see some IPOs
[00:48:50.600 --> 00:48:54.320]   that were either related to recapping or raising capital.
[00:48:54.320 --> 00:48:58.400]   And sometimes what you need first
[00:48:58.400 --> 00:49:02.520]   is the derivative instrument that then makes you realize,
[00:49:02.520 --> 00:49:04.120]   oh, shit, I really got to get public
[00:49:04.120 --> 00:49:05.560]   and convert everyone to common.
[00:49:05.560 --> 00:49:07.960]   That happened to Square, actually.
[00:49:07.960 --> 00:49:11.960]   They had done a time bomb derivative thing that
[00:49:11.960 --> 00:49:13.800]   then made you go public.
[00:49:13.800 --> 00:49:16.520]   And so maybe we've got to have those first,
[00:49:16.520 --> 00:49:18.240]   and then we'll have more.
[00:49:18.240 --> 00:49:21.240]   But I would have thought you'd seen more.
[00:49:21.240 --> 00:49:26.720]   I think a lot of people also have this silly argument
[00:49:26.720 --> 00:49:29.160]   that we've got to wait for someone big to go first.
[00:49:29.160 --> 00:49:31.480]   And I actually think we'll probably
[00:49:31.480 --> 00:49:35.400]   see a smaller company with a courageous founder
[00:49:35.400 --> 00:49:38.080]   step through the window.
[00:49:38.080 --> 00:49:39.720]   We don't have to wait around for Stripe.
[00:49:39.720 --> 00:49:41.040]   That's kind of a silly notion.
[00:49:41.040 --> 00:49:43.320]   You asked a question earlier that I just
[00:49:43.320 --> 00:49:44.840]   wanted to touch on I just remembered,
[00:49:44.840 --> 00:49:47.880]   which was, why is it taking longer for founders, maybe,
[00:49:47.880 --> 00:49:51.680]   to come around to the valuation adjustment?
[00:49:51.680 --> 00:49:53.720]   I think one of the reasons is that
[00:49:53.720 --> 00:49:58.480]   with all the secondary liquidity that occurred this time around,
[00:49:58.480 --> 00:50:01.520]   you know the hardest thing is, if you ever anchor your net
[00:50:01.520 --> 00:50:05.080]   worth, if you ever look at, oh, I own 20% of this company,
[00:50:05.080 --> 00:50:06.800]   it's valued at $10 billion.
[00:50:06.800 --> 00:50:09.720]   So therefore, I'm worth $2 billion.
[00:50:09.720 --> 00:50:12.200]   And if you set that anchor in, and worse yet,
[00:50:12.200 --> 00:50:15.480]   if you start living your life that way,
[00:50:15.480 --> 00:50:20.400]   and then all of a sudden, you have this dramatic reset down
[00:50:20.400 --> 00:50:23.720]   80%, and you're like, oh, I'm not worth $2 billion.
[00:50:23.720 --> 00:50:26.520]   Instead, somebody says, your company's really worth
[00:50:26.520 --> 00:50:28.520]   a billion or $2 billion.
[00:50:28.520 --> 00:50:32.400]   All of a sudden, go back to the stages of grief.
[00:50:32.400 --> 00:50:33.400]   What's that stage?
[00:50:33.400 --> 00:50:34.600]   Denial.
[00:50:34.600 --> 00:50:35.800]   And then anger.
[00:50:35.800 --> 00:50:36.280]   No doubt.
[00:50:36.280 --> 00:50:37.720]   Right?
[00:50:37.720 --> 00:50:38.720]   I think it plays a role.
[00:50:38.720 --> 00:50:39.920]   You're nowhere close to it.
[00:50:39.920 --> 00:50:42.080]   What I finally see happening this year,
[00:50:42.080 --> 00:50:45.240]   I think 2024 in terms of the stages of grief,
[00:50:45.240 --> 00:50:47.640]   is the year of acceptance.
[00:50:47.640 --> 00:50:49.960]   I think people are just going to have to get liquid.
[00:50:49.960 --> 00:50:52.440]   They're going to accept the prices that they have to accept.
[00:50:52.440 --> 00:50:55.000]   Because frankly, there are no more soft banks
[00:50:55.000 --> 00:50:56.760]   to bail them out.
[00:50:56.760 --> 00:50:58.120]   And the public market's not going
[00:50:58.120 --> 00:51:00.400]   to overpay, because the public market knows
[00:51:00.400 --> 00:51:01.800]   what the clearing price is.
[00:51:01.800 --> 00:51:03.920]   And so that, I think, gets founders
[00:51:03.920 --> 00:51:05.080]   to the stage of acceptance.
[00:51:05.080 --> 00:51:08.040]   But I think we probably have another quarter or two
[00:51:08.040 --> 00:51:09.200]   to get there.
[00:51:09.200 --> 00:51:10.800]   I think we've beaten that one to death.
[00:51:10.800 --> 00:51:13.520]   By the way, I'll say something.
[00:51:13.520 --> 00:51:16.280]   You made me think of something that I will share, maybe
[00:51:16.280 --> 00:51:18.640]   on behalf of all venture capitalists,
[00:51:18.640 --> 00:51:22.920]   and maybe to make everyone's lives easier.
[00:51:22.920 --> 00:51:26.160]   One of the easy defaults you go to in the middle
[00:51:26.160 --> 00:51:29.800]   is, oh, I'll just go to my insiders and ask for a bridge.
[00:51:29.800 --> 00:51:33.360]   And I will tell you, at least all the data I've seen,
[00:51:33.360 --> 00:51:38.680]   the success stories coming off a bridge are few to none.
[00:51:38.680 --> 00:51:40.880]   That's why we always refer to them as peers,
[00:51:40.880 --> 00:51:42.200]   rather than bridges.
[00:51:42.200 --> 00:51:46.040]   Peers, as in walking off the end of a pier.
[00:51:46.040 --> 00:51:49.960]   Yeah, like it doesn't get you to the other side.
[00:51:49.960 --> 00:51:52.560]   It just takes you out into the water.
[00:51:52.560 --> 00:51:58.120]   You're much better off talking through a recap with investors
[00:51:58.120 --> 00:51:59.400]   than you are doing.
[00:51:59.400 --> 00:52:03.320]   You're just piling delay upon delay.
[00:52:03.320 --> 00:52:05.680]   You're just setting yourself up for more failure.
[00:52:05.680 --> 00:52:08.400]   It reminds me of a related subject, Bill.
[00:52:08.400 --> 00:52:10.240]   I remember at the start of last year,
[00:52:10.240 --> 00:52:12.560]   we were talking about who were the companies that
[00:52:12.560 --> 00:52:16.480]   were going to follow Facebook in terms down the path of layoffs
[00:52:16.480 --> 00:52:17.640]   and getting fit.
[00:52:17.640 --> 00:52:21.080]   And somebody produced an article.
[00:52:21.080 --> 00:52:27.120]   And they said, once we started to see a trickle of companies,
[00:52:27.120 --> 00:52:28.360]   they hired some consultants.
[00:52:28.360 --> 00:52:30.400]   And they said, how many people should we lay off?
[00:52:30.400 --> 00:52:34.200]   And they all magically came up with 13% or 14%.
[00:52:34.200 --> 00:52:36.680]   And we're like, why 13% or 14%?
[00:52:36.680 --> 00:52:39.880]   And they said, well, it's bigger than 10%.
[00:52:39.880 --> 00:52:42.600]   And it's not as hard as 20%.
[00:52:42.600 --> 00:52:46.760]   And I think that this is the other piece of evidence
[00:52:46.760 --> 00:52:50.400]   we have here that people just didn't get the drill.
[00:52:50.400 --> 00:52:52.480]   We always say, do it all up front.
[00:52:52.480 --> 00:52:53.760]   Get it over with.
[00:52:53.760 --> 00:52:56.840]   And get on to rebuilding your business with unit economics
[00:52:56.840 --> 00:52:57.840]   that makes sense.
[00:52:57.840 --> 00:52:59.760]   But unfortunately, if you just look
[00:52:59.760 --> 00:53:01.560]   at the number of layoffs being announced,
[00:53:01.560 --> 00:53:05.760]   I think we now are up to 40 or 50 big companies.
[00:53:05.760 --> 00:53:09.240]   I mean, just recently Wayfair and eBay and go through the list.
[00:53:09.240 --> 00:53:11.080]   But these were all decisions that
[00:53:11.080 --> 00:53:13.640]   could have been made at the beginning of '22.
[00:53:13.640 --> 00:53:16.600]   I'm wondering, at the beginning of '23,
[00:53:16.600 --> 00:53:22.280]   it's shocking to me that we're in the first quarter of '24.
[00:53:22.280 --> 00:53:25.680]   This correction started more than two years ago.
[00:53:25.680 --> 00:53:28.840]   Why are people just now getting to the conclusion
[00:53:28.840 --> 00:53:30.200]   that they should be getting fit?
[00:53:30.200 --> 00:53:35.520]   There's a lot of wishful thinking.
[00:53:35.520 --> 00:53:41.760]   And quite frankly, let's paint it in a very different light.
[00:53:41.760 --> 00:53:44.720]   Startups aren't created by pessimists.
[00:53:44.720 --> 00:53:47.280]   They're created by blind optimists, right?
[00:53:47.280 --> 00:53:51.840]   And so your most likely mindset, if you're
[00:53:51.840 --> 00:53:54.720]   the type of founder who runs at walls,
[00:53:54.720 --> 00:53:58.560]   is that you're going to figure it out, that it'll be better.
[00:53:58.560 --> 00:53:59.600]   I'll make it work.
[00:53:59.600 --> 00:54:01.560]   I'll get back to where we were.
[00:54:01.560 --> 00:54:03.760]   That's how you're programmed to behave.
[00:54:03.760 --> 00:54:08.240]   Although I'll tell you, the story of Elon
[00:54:08.240 --> 00:54:11.360]   is always up and to the right.
[00:54:11.360 --> 00:54:16.920]   People need to celebrate the stories about Elon's survival
[00:54:16.920 --> 00:54:21.960]   and Elon not hiring people and Elon making it
[00:54:21.960 --> 00:54:25.800]   through the near-death experiences of 2008.
[00:54:25.800 --> 00:54:28.760]   What he did at Twitter, laying off 75% of the people--
[00:54:28.760 --> 00:54:31.360]   I saw somebody tweet the other day, Bill.
[00:54:31.360 --> 00:54:35.880]   They said, I guess Twitter isn't going to fall over, right?
[00:54:35.880 --> 00:54:38.480]   I mean, the platform is as vibrant
[00:54:38.480 --> 00:54:39.800]   and the product development cycle
[00:54:39.800 --> 00:54:41.200]   is as vibrant as it's ever been.
[00:54:41.200 --> 00:54:45.120]   Why don't we maybe want to jump onto topic four?
[00:54:45.120 --> 00:54:45.840]   Sure.
[00:54:45.840 --> 00:54:49.440]   So I think through our discussion,
[00:54:49.440 --> 00:54:52.720]   we'll get back to why this relates to VC and tech.
[00:54:52.720 --> 00:54:58.240]   But a lot of people found it quite interesting,
[00:54:58.240 --> 00:55:02.240]   let's say, the new leader of Argentina's speech
[00:55:02.240 --> 00:55:07.760]   at the World Economic Forum, Mille.
[00:55:07.760 --> 00:55:10.160]   And we'll put a link in, but I'm sure most everyone's
[00:55:10.160 --> 00:55:11.240]   seen it by now.
[00:55:11.240 --> 00:55:15.320]   Obviously, very different from all the other talks
[00:55:15.320 --> 00:55:16.280]   that are there.
[00:55:16.280 --> 00:55:18.840]   But why was it meaningful to you?
[00:55:18.840 --> 00:55:24.800]   Well, the first thing I did when I listened to the speech--
[00:55:24.800 --> 00:55:27.040]   and it's something I've thought about a lot--
[00:55:27.040 --> 00:55:30.520]   was Mille's an economist.
[00:55:30.520 --> 00:55:32.800]   When's the last time you heard a politician
[00:55:32.800 --> 00:55:35.240]   give a major address?
[00:55:35.240 --> 00:55:39.240]   And he starts it off by talking about the empirical evidence
[00:55:39.240 --> 00:55:40.880]   and starts quoting data.
[00:55:40.880 --> 00:55:45.040]   So my first question was, I want to see this data.
[00:55:45.040 --> 00:55:48.760]   So I had one of my analysts go back and pull the data, which
[00:55:48.760 --> 00:55:52.600]   was the underlying support data that maybe we can bring up.
[00:55:52.600 --> 00:55:54.560]   And what this data shows-- so this
[00:55:54.560 --> 00:56:00.400]   is the years it takes to double global GDP per capita.
[00:56:00.400 --> 00:56:02.560]   Now, first, maybe we should just start off by saying,
[00:56:02.560 --> 00:56:05.040]   why should we care about this?
[00:56:05.040 --> 00:56:12.760]   So GDP really is the excess, the progress, the prosperity that's
[00:56:12.760 --> 00:56:16.120]   created by a fixed amount of labor and capital
[00:56:16.120 --> 00:56:16.640]   in the world.
[00:56:16.640 --> 00:56:18.300]   We have a fixed number of human beings.
[00:56:18.300 --> 00:56:20.440]   They can only work so many hours a day.
[00:56:20.440 --> 00:56:22.680]   And we have a fixed amount of capital in the world.
[00:56:22.680 --> 00:56:24.640]   And what are all the things and services
[00:56:24.640 --> 00:56:26.120]   that we can produce with that?
[00:56:26.120 --> 00:56:28.360]   And that is the global GDP.
[00:56:28.360 --> 00:56:30.080]   Well, what he noted in this chart
[00:56:30.080 --> 00:56:37.360]   shows that basically from year zero to the year 1800,
[00:56:37.360 --> 00:56:41.040]   we had almost zero GDP globally.
[00:56:41.040 --> 00:56:44.840]   And we had very little prosperity.
[00:56:44.840 --> 00:56:46.760]   We had very little excess.
[00:56:46.760 --> 00:56:49.360]   One might think of it in a very primitive way,
[00:56:49.360 --> 00:56:52.680]   even before the year zero, that we were hunter-gatherers
[00:56:52.680 --> 00:56:56.720]   and we basically lived a subsistence life, OK?
[00:56:56.720 --> 00:57:00.280]   So in that case, he said, takes you 3,500 years
[00:57:00.280 --> 00:57:01.880]   for global GDP to double.
[00:57:01.880 --> 00:57:05.240]   And then something crazy happens around the year 1800.
[00:57:05.240 --> 00:57:07.600]   Remember, Adam Smith's Wealth of Nation
[00:57:07.600 --> 00:57:13.000]   about free market capitalism published in like 1775, 1780.
[00:57:13.000 --> 00:57:15.520]   And so we have free market capitalism,
[00:57:15.520 --> 00:57:18.000]   market democracies introduced into the world
[00:57:18.000 --> 00:57:19.240]   about that point in time.
[00:57:19.240 --> 00:57:21.800]   And just coincidentally, we start
[00:57:21.800 --> 00:57:26.200]   seeing an acceleration in the rate of global GDP growth.
[00:57:26.200 --> 00:57:29.520]   So the period 1820 to 1900, it only
[00:57:29.520 --> 00:57:32.720]   takes 87 years to double GDP.
[00:57:32.720 --> 00:57:36.480]   And then 1900 to 1950, only 60 years.
[00:57:36.480 --> 00:57:39.280]   And by the time you get to the year 2000,
[00:57:39.280 --> 00:57:45.400]   we're doubling global GDP every 20 to 30 years, OK?
[00:57:45.400 --> 00:57:51.120]   Which results in this chart, the next chart, which is--
[00:57:51.120 --> 00:57:55.120]   this is just such a shocking hockey stick chart to look at,
[00:57:55.120 --> 00:57:56.480]   OK?
[00:57:56.480 --> 00:58:02.760]   So this is the increase in global GDP
[00:58:02.760 --> 00:58:08.200]   over the course of the last 2,000 years, right?
[00:58:08.200 --> 00:58:09.080]   You almost have none.
[00:58:09.080 --> 00:58:11.560]   And then it starts going up a hockey stick.
[00:58:11.560 --> 00:58:14.040]   And then we said, let's forecast it forward
[00:58:14.040 --> 00:58:15.600]   for the next 100 years.
[00:58:15.600 --> 00:58:17.640]   And if we forecast it forward and we just
[00:58:17.640 --> 00:58:24.360]   assume that we have the same rate of GDP being added
[00:58:24.360 --> 00:58:25.680]   every year that we have this year,
[00:58:25.680 --> 00:58:28.880]   so we're not assuming any acceleration from AI,
[00:58:28.880 --> 00:58:32.240]   no systems getting better, you just
[00:58:32.240 --> 00:58:34.240]   see the advancements caused by this.
[00:58:34.240 --> 00:58:36.400]   And Millet was, of course, arguing
[00:58:36.400 --> 00:58:40.520]   that this was the result of free markets and competition.
[00:58:40.520 --> 00:58:42.520]   Yep, no doubt.
[00:58:42.520 --> 00:58:47.400]   So Bill, I think if we look at this, one of my questions
[00:58:47.400 --> 00:58:50.360]   for you gets back to this.
[00:58:50.360 --> 00:58:54.880]   Why should we care so much about these empirical facts
[00:58:54.880 --> 00:58:56.160]   and this speech?
[00:58:56.160 --> 00:58:58.480]   And what are the risks to this?
[00:58:58.480 --> 00:59:06.200]   So I would highly encourage listeners to read two books.
[00:59:06.200 --> 00:59:09.560]   The first one is The Rational Optimist by Matt Ridley.
[00:59:09.560 --> 00:59:12.080]   And the second one is How Innovation Works, also
[00:59:12.080 --> 00:59:13.120]   by Matt Ridley.
[00:59:13.120 --> 00:59:15.560]   And they should be read in that order.
[00:59:15.560 --> 00:59:18.160]   One's almost a sequel of the first one.
[00:59:18.160 --> 00:59:22.080]   But in The Rational Optimist, Matt
[00:59:22.080 --> 00:59:24.360]   talks about the underlying mechanisms
[00:59:24.360 --> 00:59:26.880]   that lead to the data you just shared
[00:59:26.880 --> 00:59:29.400]   and what Millet was talking about.
[00:59:29.400 --> 00:59:34.840]   And he sums it up in around two functions.
[00:59:34.840 --> 00:59:37.240]   One is ideas being exchanged.
[00:59:37.240 --> 00:59:40.000]   He calls it ideas having sex.
[00:59:40.000 --> 00:59:42.160]   I'll give you an example.
[00:59:42.160 --> 00:59:44.280]   And we can go back to early agriculture.
[00:59:44.280 --> 00:59:47.600]   If I learn how to plow and put seeds in the ground
[00:59:47.600 --> 00:59:52.000]   and I go to a town to trade, I can tell someone else
[00:59:52.000 --> 00:59:52.560]   how to do it.
[00:59:52.560 --> 00:59:53.800]   I can show them how.
[00:59:53.800 --> 00:59:56.680]   And now they can go and do it on their own.
[00:59:56.680 --> 01:00:01.040]   And that exchange of idea was free.
[01:00:01.040 --> 01:00:05.840]   But it had a magnificent lift to prosperity.
[01:00:05.840 --> 01:00:07.920]   It's ironic because when I wrote down
[01:00:07.920 --> 01:00:10.240]   that I wanted to use that example, the thing that
[01:00:10.240 --> 01:00:14.640]   immediately popped in my mind was in the AI world,
[01:00:14.640 --> 01:00:17.920]   the DeepMind paper about the attention window,
[01:00:17.920 --> 01:00:19.800]   attention is all you can need.
[01:00:19.800 --> 01:00:23.120]   This concept was done inside of Google
[01:00:23.120 --> 01:00:26.720]   as an open source concept, immediately copied
[01:00:26.720 --> 01:00:28.000]   by all the other players.
[01:00:28.000 --> 01:00:33.240]   So open AI doesn't exist today if that's patented and controlled.
[01:00:33.240 --> 01:00:35.480]   It just doesn't, which is another irony
[01:00:35.480 --> 01:00:37.960]   around this open source argument because they've
[01:00:37.960 --> 01:00:41.600]   been affronted massively from a major--
[01:00:41.600 --> 01:00:43.720]   but the idea of being shared-- and this
[01:00:43.720 --> 01:00:46.920]   is also why I'm such a massive open source proponent
[01:00:46.920 --> 01:00:50.480]   because I think it's so relevant to prosperity for the masses.
[01:00:50.480 --> 01:00:54.320]   If ideas can be shared, there's zero cost but infinite lift.
[01:00:54.320 --> 01:00:57.440]   And then the second part of it in Ridley's book
[01:00:57.440 --> 01:00:58.720]   is commerce.
[01:00:58.720 --> 01:01:01.000]   For all the reasons Adam Smith talked about,
[01:01:01.000 --> 01:01:02.960]   it's just a way to allocate resources.
[01:01:02.960 --> 01:01:06.080]   So if you get both of those things humming,
[01:01:06.080 --> 01:01:07.800]   you get massive success.
[01:01:07.800 --> 01:01:11.760]   It's super interesting if you look at the history of China
[01:01:11.760 --> 01:01:14.800]   because they've opened up and closed multiple times.
[01:01:14.800 --> 01:01:17.960]   So they used to be like a third of world GDP.
[01:01:17.960 --> 01:01:20.440]   And then they closed their borders and quit trading.
[01:01:20.440 --> 01:01:25.120]   And they went down way into the low 200s or something.
[01:01:25.120 --> 01:01:27.400]   And then, of course--
[01:01:27.400 --> 01:01:30.880]   by the way, let me share something on my screen if I can.
[01:01:30.880 --> 01:01:32.120]   I'm going to try.
[01:01:32.120 --> 01:01:33.040]   Yeah, right here.
[01:01:33.040 --> 01:01:36.480]   So this is my favorite test of AI bot.
[01:01:36.480 --> 01:01:38.800]   I asked the very simple question,
[01:01:38.800 --> 01:01:41.600]   what single human being has brought the most humans out
[01:01:41.600 --> 01:01:42.600]   of poverty?
[01:01:42.600 --> 01:01:45.480]   And ChatGPT got it right, of course.
[01:01:45.480 --> 01:01:49.200]   Deng Xiaoping, who brought capitalism to China
[01:01:49.200 --> 01:01:54.240]   and brought 500 million people out of poverty.
[01:01:54.240 --> 01:01:57.960]   No other human being, not the most--
[01:01:57.960 --> 01:02:02.440]   not Mother Teresa, no altruist, no socialist,
[01:02:02.440 --> 01:02:05.440]   has come anywhere close to this number that
[01:02:05.440 --> 01:02:10.600]   was done merely by unleashing the human potential that
[01:02:10.600 --> 01:02:15.880]   was latent inside of China by allowing for idea sharing
[01:02:15.880 --> 01:02:19.040]   and commerce to have this massive impact.
[01:02:19.040 --> 01:02:23.600]   And I even think there's an argument in the past,
[01:02:23.600 --> 01:02:29.480]   let's say, three or four years, that by stopping commerce,
[01:02:29.480 --> 01:02:33.000]   or at least restricting it a bit and stopping trade,
[01:02:33.000 --> 01:02:35.720]   has led to at least the shakiness
[01:02:35.720 --> 01:02:37.400]   within the Chinese economy, which
[01:02:37.400 --> 01:02:43.200]   may have led to what happened in Silicon Valley in that meeting.
[01:02:43.200 --> 01:02:47.200]   And like, hey, maybe we need to get this thing back on tracks.
[01:02:47.200 --> 01:02:50.840]   Because of that, you asked what could harm it.
[01:02:50.840 --> 01:02:54.760]   One of my favorite thinkers and professors
[01:02:54.760 --> 01:02:57.760]   is a gentleman named Ricardo Hausman at the Kennedy School.
[01:02:57.760 --> 01:02:58.800]   He's Venezuelan.
[01:02:58.800 --> 01:03:01.000]   And he was giving a presentation once about what
[01:03:01.000 --> 01:03:02.600]   went wrong in Venezuela.
[01:03:02.600 --> 01:03:05.120]   And he said they attacked the invisible hand.
[01:03:05.120 --> 01:03:06.720]   And I love that phrase.
[01:03:06.720 --> 01:03:08.480]   Attacked the invisible hand.
[01:03:08.480 --> 01:03:08.960]   Yeah.
[01:03:08.960 --> 01:03:11.000]   And so these people--
[01:03:11.000 --> 01:03:13.520]   and I'm sure they're well-meaning,
[01:03:13.520 --> 01:03:20.560]   but that view capitalism as the cause of poverty
[01:03:20.560 --> 01:03:21.720]   or negative prosperity.
[01:03:21.720 --> 01:03:23.720]   When the data all says it's the opposite,
[01:03:23.720 --> 01:03:25.960]   it's actually the thing that brings people out
[01:03:25.960 --> 01:03:28.480]   of prosperity, that appears to be the way
[01:03:28.480 --> 01:03:29.800]   you get yourself in trouble.
[01:03:29.800 --> 01:03:30.480]   Yeah.
[01:03:30.480 --> 01:03:33.920]   I think you meant out of poverty and into prosperity.
[01:03:33.920 --> 01:03:35.760]   Out of poverty and into prosperity.
[01:03:35.760 --> 01:03:39.120]   And that seems to me, I think, the reason
[01:03:39.120 --> 01:03:43.440]   that this speech, in particular at Davos, right?
[01:03:43.440 --> 01:03:45.120]   Because there's this phenomenon that's
[01:03:45.120 --> 01:03:47.680]   been criticized there for years, that there's
[01:03:47.680 --> 01:03:51.640]   a move toward perhaps collectivism,
[01:03:51.640 --> 01:03:54.560]   that we need to move away from free markets.
[01:03:54.560 --> 01:03:57.680]   And I think people set up this false dichotomy,
[01:03:57.680 --> 01:04:00.280]   like that people are absolutists on free markets
[01:04:00.280 --> 01:04:02.880]   and they don't think that there should be any regulation,
[01:04:02.880 --> 01:04:05.400]   no government's kind of anarchist view,
[01:04:05.400 --> 01:04:10.000]   or that you should have this very collectivist organization.
[01:04:10.000 --> 01:04:13.960]   It seems to me like the United States has constantly
[01:04:13.960 --> 01:04:18.080]   been in search of a balance between embracing
[01:04:18.080 --> 01:04:21.080]   its DNA of free market capitalism,
[01:04:21.080 --> 01:04:24.360]   while at the same time putting in basic protections
[01:04:24.360 --> 01:04:25.880]   for the least fortunate among us,
[01:04:25.880 --> 01:04:27.760]   for those who can't take care of themselves,
[01:04:27.760 --> 01:04:31.200]   for the people who don't benefit equally in society.
[01:04:31.200 --> 01:04:33.840]   But I think what we've seen is over the last few years,
[01:04:33.840 --> 01:04:36.960]   some concerns among the two of us
[01:04:36.960 --> 01:04:40.760]   included, that the pendulum swung too far,
[01:04:40.760 --> 01:04:43.120]   that there was a lot of anti-capitalist,
[01:04:43.120 --> 01:04:47.440]   anti-free markets, almost anti-democratic fervor,
[01:04:47.440 --> 01:04:49.520]   that somehow it was unfair.
[01:04:49.520 --> 01:04:55.120]   It wasn't equitable to all participants.
[01:04:55.120 --> 01:04:56.620]   Go ahead.
[01:04:56.620 --> 01:04:58.960]   I would just say the social safety
[01:04:58.960 --> 01:05:02.360]   net is funded by the progress that's
[01:05:02.360 --> 01:05:06.360]   created from capitalism and tech and growth and all the things
[01:05:06.360 --> 01:05:07.280]   that we talked about.
[01:05:07.280 --> 01:05:10.480]   And if you eliminate the latter, there
[01:05:10.480 --> 01:05:14.320]   is no money for the former, at least in the long run.
[01:05:14.320 --> 01:05:18.880]   Well, that's exactly what I think Millet's argument is.
[01:05:18.880 --> 01:05:21.760]   And perhaps bringing this bill full circle
[01:05:21.760 --> 01:05:25.160]   back to Silicon Valley, back to tech investing,
[01:05:25.160 --> 01:05:26.760]   people--
[01:05:26.760 --> 01:05:28.880]   I have family members and others,
[01:05:28.880 --> 01:05:30.200]   they say, you've done well.
[01:05:30.200 --> 01:05:32.520]   Why are you still doing this?
[01:05:32.520 --> 01:05:34.000]   And it may sound a little cheesy,
[01:05:34.000 --> 01:05:37.760]   but I say the very nature of what we do, I think,
[01:05:37.760 --> 01:05:39.600]   is a public good.
[01:05:39.600 --> 01:05:41.320]   And I think about it in this way.
[01:05:41.320 --> 01:05:46.280]   Human progress-- I'm not just talking venture capitalists.
[01:05:46.280 --> 01:05:48.600]   In fact, less about venture capitalists.
[01:05:48.600 --> 01:05:50.520]   I'm talking about risk takers.
[01:05:50.520 --> 01:05:52.160]   I'm talking about founders.
[01:05:52.160 --> 01:05:56.080]   I'm talking about the engines of the innovative system.
[01:05:56.080 --> 01:06:00.160]   In fact, the rule of law around bankruptcy
[01:06:00.160 --> 01:06:02.840]   was a pretty novel concept in this country.
[01:06:02.840 --> 01:06:04.400]   But we wanted to make a deal.
[01:06:04.400 --> 01:06:06.440]   We were basically saying, if you're
[01:06:06.440 --> 01:06:08.240]   going to be the risk taker, if you're
[01:06:08.240 --> 01:06:09.800]   going to put your neck on the line
[01:06:09.800 --> 01:06:12.880]   to move our country forward, if it doesn't work out,
[01:06:12.880 --> 01:06:15.400]   we want to give you some protection
[01:06:15.400 --> 01:06:17.200]   so it doesn't ruin the rest of your life.
[01:06:17.200 --> 01:06:20.200]   Because we were trying to create a system of incentives
[01:06:20.200 --> 01:06:22.320]   for people to take that risk.
[01:06:22.320 --> 01:06:28.720]   And so when I look at where we are today, one of the things
[01:06:28.720 --> 01:06:30.920]   that you saw in the empirical facts
[01:06:30.920 --> 01:06:35.160]   is the accelerating rate of capitalism, right?
[01:06:35.160 --> 01:06:38.680]   And it seems to me part of the reason for that acceleration
[01:06:38.680 --> 01:06:42.000]   is that systems compound upon systems.
[01:06:42.000 --> 01:06:44.800]   These are non-linear, right?
[01:06:44.800 --> 01:06:49.600]   And so mobile compounded a lot faster because of the internet.
[01:06:49.600 --> 01:06:54.360]   Internet because of microcomputers.
[01:06:54.360 --> 01:06:57.080]   The cloud because of mobile and the internet.
[01:06:57.080 --> 01:07:02.800]   AI, all those things were preconditions to AI, right?
[01:07:02.800 --> 01:07:05.720]   You just made me think of something that--
[01:07:05.720 --> 01:07:08.520]   if you look at what Deng Xiaoping did in China
[01:07:08.520 --> 01:07:10.760]   and how quickly--
[01:07:10.760 --> 01:07:13.920]   and you've been over there and met with the founders.
[01:07:13.920 --> 01:07:18.160]   I mean, and you've seen comments from Moretz and others.
[01:07:18.160 --> 01:07:21.640]   Just like, at the least, they're equally good.
[01:07:21.640 --> 01:07:25.080]   And arguably, in some ways, in some dimensions, better.
[01:07:25.080 --> 01:07:30.320]   Certainly harder working from the cultural standpoint.
[01:07:30.320 --> 01:07:34.040]   And that happened pretty damn fast, right?
[01:07:34.040 --> 01:07:36.200]   We used to say there was only Silicon Valley,
[01:07:36.200 --> 01:07:38.800]   like there's no other place like it.
[01:07:38.800 --> 01:07:42.000]   And then China very quickly mimicked it, very quickly
[01:07:42.000 --> 01:07:43.320]   in the span of time.
[01:07:43.360 --> 01:07:46.320]   And it makes me wonder if you had,
[01:07:46.320 --> 01:07:50.360]   like, for say, inside of Russia, the type of embrace
[01:07:50.360 --> 01:07:53.320]   of capitalism and free trade that you
[01:07:53.320 --> 01:07:55.440]   did under Deng Xiaoping.
[01:07:55.440 --> 01:07:57.120]   You might see the same damn thing.
[01:07:57.120 --> 01:07:59.600]   People are certainly smart enough.
[01:07:59.600 --> 01:08:01.600]   I think you're spot on.
[01:08:01.600 --> 01:08:04.960]   I was having a conversation on Sunday with Mike Milken.
[01:08:04.960 --> 01:08:07.440]   And he's starting the Center for the American Dream.
[01:08:07.440 --> 01:08:11.320]   And Mike is very, very concerned about move away
[01:08:11.320 --> 01:08:14.680]   from just free market capitalist democracy.
[01:08:14.680 --> 01:08:16.480]   And he said to me something that struck me.
[01:08:16.480 --> 01:08:19.080]   He said, Brad, when I travel the world,
[01:08:19.080 --> 01:08:24.040]   it dawns on me that Vietnam, everybody there
[01:08:24.040 --> 01:08:25.600]   wants to be an entrepreneur.
[01:08:25.600 --> 01:08:29.400]   Everybody there is running hard after capitalism.
[01:08:29.400 --> 01:08:32.040]   In the Middle East, we see the same thing occurring.
[01:08:32.040 --> 01:08:34.680]   And he's like, I just want to make sure
[01:08:34.680 --> 01:08:37.360]   that we continue to underscore in this country
[01:08:37.360 --> 01:08:41.200]   that it is the thing that caused us to be at the top of the heap.
[01:08:41.200 --> 01:08:43.240]   It is what led to the progress.
[01:08:43.240 --> 01:08:44.600]   And we need to protect that.
[01:08:44.600 --> 01:08:47.280]   Because like you said, you can't take it for granted.
[01:08:47.280 --> 01:08:49.280]   And that's certainly-- that's even more true
[01:08:49.280 --> 01:08:52.480]   if you look at the last 20 years.
[01:08:52.480 --> 01:08:55.840]   Like, American industrialism could have arguably
[01:08:55.840 --> 01:08:59.840]   been a post-World War II thing, with all the factories
[01:08:59.840 --> 01:09:00.840]   that were blown out.
[01:09:00.840 --> 01:09:04.160]   But if you look at just the companies that
[01:09:04.160 --> 01:09:07.720]   lead our market caps today, they're all venture backed.
[01:09:07.720 --> 01:09:11.040]   And they're all started within the past 30 or 40 years.
[01:09:11.040 --> 01:09:13.720]   And most of them started by immigrants.
[01:09:13.720 --> 01:09:16.520]   Most of them started by people who didn't start with a lot,
[01:09:16.520 --> 01:09:18.520]   like the amount of economic mobility
[01:09:18.520 --> 01:09:21.240]   that we have in this country.
[01:09:21.240 --> 01:09:26.080]   And so I would say that was a hell of a conversation.
[01:09:26.080 --> 01:09:27.800]   I've enjoyed it, like I always do.
[01:09:27.800 --> 01:09:30.120]   We've been doing these things for a long time.
[01:09:30.120 --> 01:09:31.840]   But why don't we leave it there?
[01:09:31.840 --> 01:09:33.520]   It's a good note to end on.
[01:09:33.520 --> 01:09:34.920]   That was a lot of fun.
[01:09:34.920 --> 01:09:38.480]   And until next time, BG2 is out.
[01:09:38.480 --> 01:09:39.200]   Take care.

