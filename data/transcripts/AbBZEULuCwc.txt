
[00:00:00.000 --> 00:00:05.800]   We must be clear eyed and vigilant about the threats emerging from emerging technologies
[00:00:05.800 --> 00:00:11.240]   that can pose, don't have to, but can pose to our democracy and our values.
[00:00:11.240 --> 00:00:17.520]   Well, that's US President Joe Biden there speaking after signing the consensus with
[00:00:17.520 --> 00:00:23.560]   seven leading tech companies, including Meta, Google, Microsoft, and OpenAI.
[00:00:23.560 --> 00:00:29.760]   So AI and tech entrepreneur Jeremy Howard wrote about this very topic just a few months ago.
[00:00:29.760 --> 00:00:31.360]   He joins us now from Brisbane.
[00:00:31.360 --> 00:00:34.480]   Jeremy, thank you so much for taking the time to speak with us.
[00:00:34.480 --> 00:00:36.560]   You're welcome, Fazia.
[00:00:36.560 --> 00:00:39.160]   So let's start off with the very obvious here.
[00:00:39.160 --> 00:00:41.600]   These safeguards are voluntary.
[00:00:41.600 --> 00:00:45.980]   They're signed by seven major tech companies.
[00:00:45.980 --> 00:00:48.920]   These tech companies compete with each other really.
[00:00:48.920 --> 00:00:52.440]   So what's the point of this agreement?
[00:00:52.440 --> 00:00:58.640]   Well, the basic idea here is that AI has come a long way in the last year or two.
[00:00:58.640 --> 00:01:02.680]   And if you've ever used something like chat GPT, you'll have seen that you can now literally
[00:01:02.680 --> 00:01:08.160]   hold a conversation with an artificial intelligence model on almost any topic.
[00:01:08.160 --> 00:01:12.960]   Sometimes it says ridiculous things, but most of the time you'll have a pretty decent conversation.
[00:01:12.960 --> 00:01:15.600]   The technology's come to a whole new level.
[00:01:15.600 --> 00:01:18.240]   This is going to be a great productivity booster.
[00:01:18.240 --> 00:01:21.760]   There's a lot of things that are much easier to do now for more people than there used
[00:01:21.760 --> 00:01:22.760]   to be.
[00:01:22.760 --> 00:01:25.520]   But of course, some of those things could be bad things.
[00:01:25.520 --> 00:01:29.500]   And so people do worry about the misuse of this technology as well.
[00:01:29.500 --> 00:01:36.880]   We do understand the pros and cons of AI, but it's a voluntary agreement.
[00:01:36.880 --> 00:01:38.640]   It's a voluntary consensus.
[00:01:38.640 --> 00:01:44.240]   Is this just a PR job for the tech companies?
[00:01:44.240 --> 00:01:47.160]   I worry it actually might be something more than that.
[00:01:47.160 --> 00:01:51.480]   My concern is this is the American government starting an agreement with seven American
[00:01:51.480 --> 00:01:57.400]   firms on a vastly powerful technology that America's the clear leader in.
[00:01:57.400 --> 00:02:02.040]   I find this an overly cozy regulatory relationship, to be honest.
[00:02:02.040 --> 00:02:05.960]   And it might be pretty bad news for Australia.
[00:02:05.960 --> 00:02:09.880]   Australia relies on the ability to access what's called open source, which is to say
[00:02:09.880 --> 00:02:12.680]   we don't have any of these models ourselves.
[00:02:12.680 --> 00:02:15.080]   We haven't built any of these in Australia.
[00:02:15.080 --> 00:02:20.440]   So we rely on being able to access the weights of these models that are released on the internet.
[00:02:20.440 --> 00:02:23.960]   And under this voluntary agreement, they're saying, actually, they are not going to do
[00:02:23.960 --> 00:02:24.960]   that anymore.
[00:02:24.960 --> 00:02:29.440]   And it's going to put Australia and other countries in a pretty challenging situation.
[00:02:29.440 --> 00:02:36.400]   It does seem, too, that these tech companies are able to make a jump there on actual shaping
[00:02:36.400 --> 00:02:39.240]   of policies when it comes to regulating AI.
[00:02:39.240 --> 00:02:40.680]   Am I reading that right?
[00:02:40.680 --> 00:02:41.680]   Yes, exactly.
[00:02:41.680 --> 00:02:47.280]   I mean, we're seeing the head of OpenAI, Sam Altman, visiting world leaders, hanging out
[00:02:47.280 --> 00:02:54.160]   with Joe Biden, we're seeing Eric Schmidt from Google going around Congress lobbying.
[00:02:54.160 --> 00:02:59.440]   There's a huge amount of lobbying going on and a very, very cozy relationship developing
[00:02:59.440 --> 00:03:02.960]   between big tech and the American government.
[00:03:02.960 --> 00:03:06.120]   And also starting to see signs of that in Europe as well.
[00:03:06.120 --> 00:03:11.760]   I think this should be a big worry, particularly for countries like Australia, if we're going
[00:03:11.760 --> 00:03:18.240]   to get onto the frontier of this, then it's going to be harder and harder the more regulatory
[00:03:18.240 --> 00:03:23.280]   barriers Australia's face to accessing these big markets.
[00:03:23.280 --> 00:03:24.760]   So what can Australia do then?
[00:03:24.760 --> 00:03:29.240]   Be involved in the lobbying, make sure that they're in the room as well?
[00:03:29.240 --> 00:03:32.940]   I think first and foremost, Australia needs to really get our game together when it comes
[00:03:32.940 --> 00:03:34.200]   to the technology.
[00:03:34.200 --> 00:03:38.720]   So all of these models are built on a single set of technologies called deep learning and
[00:03:38.720 --> 00:03:40.040]   neural networks.
[00:03:40.040 --> 00:03:44.200]   That's an area which Australia unfortunately is not at the forefront of.
[00:03:44.200 --> 00:03:46.360]   There's basically no funding for this.
[00:03:46.360 --> 00:03:51.440]   If you think about groups like Google's DeepMind or Google's Brain, you can see from their
[00:03:51.440 --> 00:03:55.800]   names that they're all about building and harnessing these neural networks.
[00:03:55.800 --> 00:03:59.000]   So Australia actually just needs to get back on the technology leadership here.
[00:03:59.000 --> 00:04:01.520]   We need funding for this kind of technology.
[00:04:01.520 --> 00:04:06.120]   We need to be working hard to bring the many brilliant expats back into Australia who have
[00:04:06.120 --> 00:04:09.960]   been fleeing the countries in years because of the lack of technical leadership in this
[00:04:09.960 --> 00:04:10.960]   area.
[00:04:10.960 --> 00:04:15.960]   Once we've managed to return to a position of technical leadership like we had in the
[00:04:15.960 --> 00:04:20.560]   early days of computing, for example, then we'll be much better placed to actually lobby
[00:04:20.560 --> 00:04:24.640]   because we'll have Australian companies and Australian projects that we can lobby for.
[00:04:24.640 --> 00:04:29.880]   Jeremy, just going back to this voluntary agreement that the major tech companies have
[00:04:29.880 --> 00:04:35.000]   signed with the White House, the four main takeaways that I'm getting from this agreement
[00:04:35.000 --> 00:04:41.800]   is security testing of AI, watermarks to flood something that is AI generated, being transparent
[00:04:41.800 --> 00:04:47.520]   about AI capabilities, working against bias, discrimination and invasion of privacy, all
[00:04:47.520 --> 00:04:48.520]   well and good.
[00:04:48.520 --> 00:04:56.760]   But I do wonder if we take the speed at which AI is evolving, can it even be regulated?
[00:04:56.760 --> 00:05:01.640]   So that's a really great question, but I first want to mention a key fifth component that's
[00:05:01.640 --> 00:05:05.480]   been little noticed, which is the key fifth component is also that they're committing
[00:05:05.480 --> 00:05:11.480]   to not sharing these models with other people, keeping them secret.
[00:05:11.480 --> 00:05:17.480]   My guess is actually that this kind of regulation will not only be pointless, but actually damaging
[00:05:17.480 --> 00:05:20.920]   to global safety and to global innovation.
[00:05:20.920 --> 00:05:25.760]   As you're kind of implying, this probably isn't possible to directly regulate.
[00:05:25.760 --> 00:05:30.440]   I think what we need instead is a much more democratic approach where everybody has access
[00:05:30.440 --> 00:05:35.360]   to this powerful technology, just like everybody has access to the vote and everybody has access
[00:05:35.360 --> 00:05:38.760]   to education, everybody has access to the internet.
[00:05:38.760 --> 00:05:44.800]   It's not by restricting these things to an elite few that we see, you know, society thrive.
[00:05:44.800 --> 00:05:48.760]   It's actually through giving society access to these things that we see it thrive.
[00:05:48.760 --> 00:05:51.400]   And I think that's the safer approach, most likely.
[00:05:51.400 --> 00:05:53.720]   Jeremy, it's such a fascinating topic.
[00:05:53.720 --> 00:05:57.400]   Thank you so much for sharing your insights with us on this Sunday morning.
[00:05:57.400 --> 00:06:02.680]   We're glad to have you on the show. Jeremy Howard, there, tech entrepreneur.
[00:06:02.680 --> 00:06:04.560]   Thank you.
[00:06:04.560 --> 00:06:04.840]   Thank you.
[00:06:04.840 --> 00:06:14.840]   [BLANK_AUDIO]

