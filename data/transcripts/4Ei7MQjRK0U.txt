
[00:00:00.000 --> 00:00:04.160]   Ultimately, we currently operate on two layers.
[00:00:04.160 --> 00:00:11.960]   We have a limbic, primitive brain layer, which is where all of our impulses are coming from.
[00:00:11.960 --> 00:00:17.040]   It's sort of like we've got a monkey brain with a computer stuck on it.
[00:00:17.040 --> 00:00:18.480]   That's the human brain.
[00:00:18.480 --> 00:00:22.640]   A lot of our impulses and everything are driven by the monkey brain.
[00:00:22.640 --> 00:00:27.280]   The computer, the cortex, is constantly trying to make the monkey brain happy.
[00:00:27.280 --> 00:00:30.960]   It's not the cortex that's steering the monkey brain, it's the monkey brain steering the
[00:00:30.960 --> 00:00:31.960]   cortex.
[00:00:31.960 --> 00:00:37.320]   But the cortex is the part that tells the story of the whole thing.
[00:00:37.320 --> 00:00:42.360]   So we convince ourselves it's more interesting than just the monkey brain.
[00:00:42.360 --> 00:00:45.440]   Cortex is what we call human intelligence.
[00:00:45.440 --> 00:00:48.680]   That's like the advanced computer relative to other creatures.
[00:00:48.680 --> 00:00:52.720]   Other creatures do not have either...
[00:00:52.720 --> 00:01:00.040]   They don't have the computer, or they have a very weak computer relative to humans.
[00:01:00.040 --> 00:01:06.960]   But it sort of seems like surely the really smart thing should control the dumb thing,
[00:01:06.960 --> 00:01:10.640]   but actually the dumb thing controls the smart thing.
[00:01:10.640 --> 00:01:15.000]   So do you think some of the same kind of machine learning methods, whether that's natural language
[00:01:15.000 --> 00:01:20.740]   processing applications, are going to be applied for the communication between the machine
[00:01:20.740 --> 00:01:27.360]   and the brain to learn how to do certain things like movement of the body, how to process
[00:01:27.360 --> 00:01:29.480]   visual stimuli and so on?
[00:01:29.480 --> 00:01:35.800]   Do you see the value of using machine learning to understand the language of the two-way
[00:01:35.800 --> 00:01:37.320]   communication with the brain?
[00:01:37.320 --> 00:01:38.320]   Sure.
[00:01:38.320 --> 00:01:39.320]   Yeah, absolutely.
[00:01:39.320 --> 00:01:44.960]   I mean, we're a neural net, and AI is basically a neural net.
[00:01:44.960 --> 00:01:51.200]   So it's like digital neural net will interface with biological neural net and hopefully bring
[00:01:51.200 --> 00:01:52.920]   us along for the ride.
[00:01:52.920 --> 00:02:00.800]   But the vast majority of our intelligence will be digital.
[00:02:00.800 --> 00:02:08.440]   Think of the difference in intelligence between your cortex and your limbic system is gigantic.
[00:02:08.440 --> 00:02:15.680]   Your limbic system really has no comprehension of what the hell the cortex is doing.
[00:02:15.680 --> 00:02:25.520]   It's just literally hungry, or tired, or angry, or sexy, or something.
[00:02:25.520 --> 00:02:31.480]   And then that communicates that impulse to the cortex and tells the cortex to go satisfy
[00:02:31.480 --> 00:02:32.480]   that.
[00:02:32.480 --> 00:02:38.640]   So then a great deal of, like a massive amount of thinking, like truly stupendous amount
[00:02:38.640 --> 00:02:49.200]   of thinking has gone into sex without purpose, without procreation, which is actually quite
[00:02:49.200 --> 00:02:53.960]   a silly action in the absence of procreation.
[00:02:53.960 --> 00:02:54.960]   It's a bit silly.
[00:02:54.960 --> 00:02:57.120]   So why are you doing it?
[00:02:57.120 --> 00:02:58.400]   Because it makes the limbic system happy.
[00:02:58.400 --> 00:02:59.400]   That's why.
[00:02:59.400 --> 00:03:00.460]   That's why.
[00:03:00.460 --> 00:03:03.880]   But it's pretty absurd, really.
[00:03:03.880 --> 00:03:07.480]   Well the whole of existence is pretty absurd in some kind of sense.
[00:03:07.480 --> 00:03:08.480]   Yeah.
[00:03:08.480 --> 00:03:15.160]   But I mean, this is a lot of computation has gone into how can I do more of that with procreation
[00:03:15.160 --> 00:03:17.240]   not even being a factor.
[00:03:17.240 --> 00:03:20.320]   This is, I think, a very important area of research by NSFW.
[00:03:20.320 --> 00:03:26.640]   An agency that should receive a lot of funding, especially after this conversation.
[00:03:26.640 --> 00:03:30.760]   I propose the formation of a new agency.
[00:03:30.760 --> 00:03:34.880]   Oh boy.
[00:03:34.880 --> 00:03:38.120]   But people generally like the fact that they have a limbic system and a cortex.
[00:03:38.120 --> 00:03:40.360]   I haven't met anyone who wants to delete either one of them.
[00:03:40.360 --> 00:03:42.400]   They're like, okay, I'll keep them both.
[00:03:42.400 --> 00:03:43.400]   That's cool.
[00:03:43.400 --> 00:03:44.400]   The limbic system is kind of fun.
[00:03:44.400 --> 00:03:45.400]   It does.
[00:03:45.400 --> 00:03:46.400]   That's what the fun is.
[00:03:46.400 --> 00:03:47.400]   Absolutely.
[00:03:47.400 --> 00:03:51.080]   And then people generally don't want to lose their cortex either.
[00:03:51.080 --> 00:03:55.120]   So they like having the cortex and the limbic system.
[00:03:55.120 --> 00:03:58.880]   And then there's a tertiary layer which will be digital superintelligence.
[00:03:58.880 --> 00:04:06.680]   And I think there's room for optimism given that the cortex is very intelligent and the
[00:04:06.680 --> 00:04:07.680]   limbic system is not.
[00:04:07.680 --> 00:04:10.160]   And yet they work together well.
[00:04:10.160 --> 00:04:14.720]   Perhaps there can be a tertiary layer where digital superintelligence lies.
[00:04:14.720 --> 00:04:17.760]   And that will be vastly more intelligent than the cortex.
[00:04:17.760 --> 00:04:22.800]   But still coexist peacefully and in a benign manner with the cortex and limbic system.
[00:04:22.800 --> 00:04:23.320]   Thank you.
[00:04:23.320 --> 00:04:25.320]   [end]
[00:04:25.320 --> 00:04:26.320]   1
[00:04:26.320 --> 00:04:27.320]   1
[00:04:27.320 --> 00:04:28.320]   2
[00:04:28.320 --> 00:04:29.320]   3
[00:04:29.320 --> 00:04:30.320]   4
[00:04:30.320 --> 00:04:31.320]   5
[00:04:31.320 --> 00:04:32.320]   6
[00:04:32.320 --> 00:04:33.320]   7
[00:04:33.320 --> 00:04:34.320]   8
[00:04:34.320 --> 00:04:35.320]   9
[00:04:35.320 --> 00:04:36.320]   10
[00:04:36.320 --> 00:04:37.320]   11
[00:04:37.320 --> 00:04:38.320]   12
[00:04:38.320 --> 00:04:39.320]   13
[00:04:39.320 --> 00:04:40.320]   14
[00:04:40.320 --> 00:04:41.320]   15
[00:04:41.320 --> 00:04:42.320]   16
[00:04:42.320 --> 00:04:43.320]   17

