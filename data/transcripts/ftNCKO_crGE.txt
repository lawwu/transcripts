
[00:00:00.000 --> 00:00:01.800]   J. Cal, do you have intros today?
[00:00:01.800 --> 00:00:03.160]   No, I don't have time for intros.
[00:00:03.160 --> 00:00:04.440]   Oh, come on.
[00:00:04.440 --> 00:00:05.280]   All right, fine.
[00:00:05.280 --> 00:00:07.640]   He started as a nerd with no followers on Twitter.
[00:00:07.640 --> 00:00:09.480]   Now he's a nerd that gets recognized
[00:00:09.480 --> 00:00:10.520]   when leaving the shitter.
[00:00:10.520 --> 00:00:11.840]   He turned water into wine.
[00:00:11.840 --> 00:00:13.260]   He just wants to please us.
[00:00:13.260 --> 00:00:15.300]   Now he's a mixture of Kermit the Frog
[00:00:15.300 --> 00:00:16.880]   and a science nerd Jesus.
[00:00:16.880 --> 00:00:18.160]   He's the man with the stans,
[00:00:18.160 --> 00:00:20.040]   the queen of quinoa, the sultan of science,
[00:00:20.040 --> 00:00:22.680]   the prince of Prozac, the lord of Lexapro.
[00:00:22.680 --> 00:00:25.400]   He gets stops for selfies all over town.
[00:00:25.400 --> 00:00:28.120]   My producer fee gave him a mental breakdown.
[00:00:28.120 --> 00:00:30.680]   The sultan of Zoloft, Mr. David Brebarg.
[00:00:30.680 --> 00:00:32.680]   It's true, it did give me a breakdown.
[00:00:32.680 --> 00:00:33.520]   It's true. It did,
[00:00:33.520 --> 00:00:34.340]   but you're over it now.
[00:00:34.340 --> 00:00:36.600]   You just name dropped three SSRIs in that intro.
[00:00:36.600 --> 00:00:37.480]   It was incredible.
[00:00:37.480 --> 00:00:39.880]   Well, I talked to his psychiatrist.
[00:00:39.880 --> 00:00:41.240]   He said he's working on the cocktail.
[00:00:41.240 --> 00:00:42.640]   Yeah, save some for me.
[00:00:42.640 --> 00:00:44.680]   (laughing)
[00:00:44.680 --> 00:00:45.520]   Oh, you?
[00:00:45.520 --> 00:00:47.920]   Speaking of you, he's got a very quick wit
[00:00:47.920 --> 00:00:49.320]   and impeccable grammar,
[00:00:49.320 --> 00:00:51.600]   known for building beautiful products that don't work.
[00:00:51.600 --> 00:00:52.440]   Oh my God.
[00:00:52.440 --> 00:00:53.800]   Like Colin in Yammer.
[00:00:53.800 --> 00:00:56.040]   He used to invest in SaaS quite a lot.
[00:00:56.040 --> 00:00:58.800]   Now he's fighting a brigade of Ukraine bots.
[00:00:58.800 --> 00:01:00.920]   He's spending so much time in his bunker,
[00:01:00.920 --> 00:01:02.320]   it's starting to get smelly.
[00:01:02.320 --> 00:01:03.920]   We see him only three times a week,
[00:01:03.920 --> 00:01:06.200]   all in Tucker and Megyn Kelly.
[00:01:06.200 --> 00:01:08.600]   He'd invest in your startup if you had the knack,
[00:01:08.600 --> 00:01:12.200]   but right now he needs that cash for his GOP super pack.
[00:01:12.200 --> 00:01:13.560]   The world's biggest sass-o,
[00:01:13.560 --> 00:01:15.480]   the rain man himself, Mr. David Sacks.
[00:01:15.480 --> 00:01:16.320]   Sass-le.
[00:01:16.320 --> 00:01:19.480]   That's a repeat joke.
[00:01:19.480 --> 00:01:20.300]   That's not.
[00:01:20.300 --> 00:01:21.760]   I know, but it kills every time,
[00:01:21.760 --> 00:01:24.800]   so I'm gonna keep repeating it until you stop laughing.
[00:01:24.800 --> 00:01:27.840]   His wardrobe costs so much, he can't get into a scuffle.
[00:01:27.840 --> 00:01:30.240]   He bought all his friends with his white truffles.
[00:01:30.240 --> 00:01:32.120]   He scaled Facebook to a billy.
[00:01:32.120 --> 00:01:34.520]   That wine collection, it's just fucking silly.
[00:01:34.520 --> 00:01:37.120]   He's on the world tour meeting with princes and kings.
[00:01:37.120 --> 00:01:40.500]   Is he talking luxury sweaters or maybe bigger things?
[00:01:40.500 --> 00:01:43.560]   The dictator himself, Chamath Palihapitiya.
[00:01:43.560 --> 00:01:45.240]   - Wow, that was really nice, actually.
[00:01:45.240 --> 00:01:47.120]   - Wow, I mean, I appreciate that.
[00:01:47.120 --> 00:01:48.280]   - You were obviously trying to get invited
[00:01:48.280 --> 00:01:49.560]   to dinner tonight.
[00:01:49.560 --> 00:01:50.880]   - I'm trying to get off the alternate slide.
[00:01:50.880 --> 00:01:51.720]   - Alternate list.
[00:01:51.720 --> 00:01:52.840]   He's trying to get off the alternate.
[00:01:52.840 --> 00:01:54.080]   The email was harsh.
[00:01:54.080 --> 00:01:56.080]   Nine was alternate.
[00:01:56.080 --> 00:01:57.040]   You were trolling me.
[00:01:57.040 --> 00:01:58.520]   I know I have a seat.
[00:01:58.520 --> 00:02:00.520]   As for me, I'm the world's greatest moderator
[00:02:00.520 --> 00:02:01.600]   who can't take a note.
[00:02:01.600 --> 00:02:04.100]   Compared to these guys, I'm just a millionaire who's broke.
[00:02:04.100 --> 00:02:06.080]   The All In Summit almost killed us,
[00:02:06.080 --> 00:02:07.900]   but we came back from death's door.
[00:02:07.900 --> 00:02:11.080]   I knew we peaked when Freeberg took over the dance floor.
[00:02:11.080 --> 00:02:13.680]   We love the fans, but we love each other more.
[00:02:13.680 --> 00:02:15.360]   Thanks for the first 100, fellas.
[00:02:15.360 --> 00:02:16.560]   Here's to 100 more.
[00:02:16.560 --> 00:02:17.440]   - Really good.
[00:02:17.440 --> 00:02:18.520]   - Wow.
[00:02:18.520 --> 00:02:19.600]   - That's really, really good.
[00:02:19.600 --> 00:02:20.720]   Look at you touching a note.
[00:02:20.720 --> 00:02:23.040]   - Surprisingly, you became prepared today.
[00:02:23.280 --> 00:02:24.200]   (laughing)
[00:02:24.200 --> 00:02:25.600]   - First time.
[00:02:25.600 --> 00:02:27.560]   After 100 episodes, he finally figured out
[00:02:27.560 --> 00:02:29.120]   he has to prepare.
[00:02:29.120 --> 00:02:29.960]   So good.
[00:02:29.960 --> 00:02:30.780]   - That was the note.
[00:02:30.780 --> 00:02:31.620]   Just prepare.
[00:02:31.620 --> 00:02:33.120]   - Just do your job.
[00:02:33.120 --> 00:02:33.960]   - Do your job.
[00:02:33.960 --> 00:02:35.000]   - Do your job.
[00:02:35.000 --> 00:02:35.840]   - Do your job.
[00:02:35.840 --> 00:02:38.000]   - Do your unremunerated job.
[00:02:38.000 --> 00:02:38.840]   - Do your job.
[00:02:38.840 --> 00:02:40.120]   - Speaking of unremunerated,
[00:02:40.120 --> 00:02:43.160]   we heard that somebody's grifting off the pod.
[00:02:43.160 --> 00:02:44.860]   - Oh yeah, so good point.
[00:02:44.860 --> 00:02:46.720]   What we heard, Sax,
[00:02:46.720 --> 00:02:50.020]   is that you got a big care package from Montclair.
[00:02:50.020 --> 00:02:51.240]   - Yeah, that's true.
[00:02:51.240 --> 00:02:52.320]   - What?
[00:02:52.320 --> 00:02:53.840]   - What I think we're all gonna declare today
[00:02:53.840 --> 00:02:55.960]   is that we all wanna wet our beak.
[00:02:55.960 --> 00:02:58.560]   And if Montclair sends each of us a care package,
[00:02:58.560 --> 00:03:01.920]   we will all wear Montclair gear at episode 101.
[00:03:01.920 --> 00:03:02.920]   - Montclair's my brand.
[00:03:02.920 --> 00:03:04.280]   Go go your own brand.
[00:03:04.280 --> 00:03:05.960]   - Yeah, we decided to.
[00:03:05.960 --> 00:03:07.520]   - Jamal's got Laura Piano.
[00:03:07.520 --> 00:03:08.520]   I got Montclair.
[00:03:08.520 --> 00:03:11.280]   You go get like, you know, Izod or something.
[00:03:11.280 --> 00:03:12.120]   I don't know.
[00:03:12.120 --> 00:03:13.560]   - Izod, Izod, Izod.
[00:03:13.560 --> 00:03:15.320]   - Actually, I got Izod too.
[00:03:15.320 --> 00:03:17.400]   You have to do, get off Lauren.
[00:03:17.400 --> 00:03:18.240]   - I got Uniclou.
[00:03:18.240 --> 00:03:20.240]   - We got Gap Kids for J-Cal.
[00:03:20.240 --> 00:03:21.080]   (laughing)
[00:03:21.080 --> 00:03:23.840]   - Sax, you didn't declare your Montclair gift package,
[00:03:23.840 --> 00:03:24.680]   by the way.
[00:03:24.680 --> 00:03:26.600]   That was the discovery we made this weekend.
[00:03:26.600 --> 00:03:29.000]   - So I wanna thank the folks at,
[00:03:29.000 --> 00:03:31.000]   there's a company called (beep)
[00:03:31.000 --> 00:03:34.760]   and they sent me this gift,
[00:03:34.760 --> 00:03:36.480]   actually this hoodie, this Montclair hoodie,
[00:03:36.480 --> 00:03:37.320]   which I'd never seen before.
[00:03:37.320 --> 00:03:39.080]   - Wait, what is this plug you?
[00:03:39.080 --> 00:03:41.280]   They send you a hoodie for $1,200
[00:03:41.280 --> 00:03:43.360]   and they get a 50,000 ad slot?
[00:03:43.360 --> 00:03:44.480]   - There were several other things.
[00:03:44.480 --> 00:03:46.960]   I'll bring you guys each a shirt from Montclair.
[00:03:46.960 --> 00:03:47.800]   - Oh, we get the shirt?
[00:03:47.800 --> 00:03:48.640]   - A shirt?
[00:03:48.640 --> 00:03:49.460]   - Yeah.
[00:03:49.460 --> 00:03:50.300]   - You got the three for five.
[00:03:50.300 --> 00:03:52.480]   - These guys are getting hundreds of thousands
[00:03:52.480 --> 00:03:53.320]   of dollars of revenue.
[00:03:53.320 --> 00:03:54.160]   - Wow, Sax is the grifter now.
[00:03:54.160 --> 00:03:55.200]   - We get a shirt.
[00:03:55.200 --> 00:03:56.040]   Yeah.
[00:03:56.040 --> 00:03:57.880]   - How bad is your portfolio that you're grifting?
[00:03:57.880 --> 00:03:59.640]   Did you put this Montclair stuff
[00:03:59.640 --> 00:04:01.880]   onto like eBay after you got it?
[00:04:01.880 --> 00:04:03.760]   - I was already wearing it and they sent me more.
[00:04:03.760 --> 00:04:06.040]   So I'm gonna wear, this hoodie is pretty cool.
[00:04:06.040 --> 00:04:06.880]   What can I say?
[00:04:06.880 --> 00:04:07.720]   I'm not gonna, what else is cute?
[00:04:07.720 --> 00:04:08.560]   - Our stock is 3 cents
[00:04:08.560 --> 00:04:09.960]   and all of a sudden you're grifting.
[00:04:09.960 --> 00:04:11.720]   - I, just for everyone listening,
[00:04:11.720 --> 00:04:12.920]   I'm looking for a wardrobe upgrade.
[00:04:12.920 --> 00:04:13.880]   - Too soon?
[00:04:13.880 --> 00:04:16.000]   - Okay, just send my package to my office or something.
[00:04:16.000 --> 00:04:16.840]   - Let me tell you something,
[00:04:16.840 --> 00:04:17.840]   there's no upgrade that's gonna help.
[00:04:17.840 --> 00:04:19.600]   Freeberg, I think you're fucked.
[00:04:19.600 --> 00:04:21.260]   - No, I'm gonna bring you guys Montclair shirts
[00:04:21.260 --> 00:04:22.180]   to the poker game tonight.
[00:04:22.180 --> 00:04:23.300]   - Gee, thanks Sax.
[00:04:23.300 --> 00:04:24.140]   Appreciate that.
[00:04:24.140 --> 00:04:27.580]   - How did you guys even find out that he got this gift?
[00:04:27.580 --> 00:04:29.300]   - We're at his Fleet Week party
[00:04:29.300 --> 00:04:31.820]   and there was a Blue Angels party
[00:04:31.820 --> 00:04:35.060]   and there was someone there who started telling me,
[00:04:35.060 --> 00:04:37.380]   like, did you hear that Sax got this whole thing?
[00:04:37.380 --> 00:04:39.220]   - Oh, somebody, there's a rat?
[00:04:39.220 --> 00:04:40.040]   - There was a rat.
[00:04:40.040 --> 00:04:40.880]   I'm not telling you who it was,
[00:04:40.880 --> 00:04:41.720]   but someone told me. - He's got a leaf.
[00:04:41.720 --> 00:04:42.820]   He's got a mole.
[00:04:42.820 --> 00:04:44.140]   - We were talking about the podcast.
[00:04:44.140 --> 00:04:45.740]   We were talking about Sax's hat.
[00:04:45.740 --> 00:04:47.180]   - 100%, it was Wu Wei.
[00:04:47.180 --> 00:04:48.100]   100%.
[00:04:48.100 --> 00:04:49.260]   - No, no, it wasn't Wu Wei.
[00:04:49.260 --> 00:04:50.100]   - No. - 100%.
[00:04:50.100 --> 00:04:51.140]   - Was it Jeff?
[00:04:51.140 --> 00:04:54.620]   - No, one of my friends was in the man cave
[00:04:54.620 --> 00:04:56.900]   and he saw this, like, care package from Montclair
[00:04:56.900 --> 00:04:59.220]   and he really admired this, like, jacket.
[00:04:59.220 --> 00:05:00.500]   It was like a puffer jacket,
[00:05:00.500 --> 00:05:02.860]   but with, like, wool sleeves or something.
[00:05:02.860 --> 00:05:04.100]   - Oh, so you gave it to him?
[00:05:04.100 --> 00:05:04.940]   - And I gave it to him.
[00:05:04.940 --> 00:05:06.780]   He liked it so much, I'm like,
[00:05:06.780 --> 00:05:07.600]   here, you take it. - You gave what?
[00:05:07.600 --> 00:05:08.820]   - You're not even on the pod.
[00:05:08.820 --> 00:05:09.980]   - He's not even on the pod.
[00:05:09.980 --> 00:05:11.300]   Give it to producer Nick.
[00:05:11.300 --> 00:05:12.780]   - So he was walking around with it
[00:05:12.780 --> 00:05:14.420]   and he was really appreciative.
[00:05:14.420 --> 00:05:16.220]   So maybe he said something or what?
[00:05:16.220 --> 00:05:17.540]   - No. - I can't believe this.
[00:05:17.540 --> 00:05:18.860]   The grift is crazy.
[00:05:18.860 --> 00:05:20.820]   - Let's just say there was a lot of conversations
[00:05:20.820 --> 00:05:23.060]   going on about your care package, Sax.
[00:05:23.060 --> 00:05:24.940]   - Well, and it makes us wonder, Sax,
[00:05:24.940 --> 00:05:27.380]   are there other care packages that have come in?
[00:05:27.380 --> 00:05:28.220]   - Or Chamath?
[00:05:28.220 --> 00:05:29.780]   - Have you been promoting other stuff on here?
[00:05:29.780 --> 00:05:30.620]   So who makes the couch behind you?
[00:05:30.620 --> 00:05:32.700]   - Some political magazines that you wouldn't want to read.
[00:05:32.700 --> 00:05:33.940]   - Chamath, how much of your Loro Piano
[00:05:33.940 --> 00:05:36.020]   have you actually paid for over the past year?
[00:05:36.020 --> 00:05:38.980]   That's a great question. - 100%.
[00:05:38.980 --> 00:05:41.740]   I would never accept it for free.
[00:05:41.740 --> 00:05:42.940]   - Oh. - 100%.
[00:05:42.940 --> 00:05:45.900]   It's important, look, wait, no, all joking aside,
[00:05:45.900 --> 00:05:48.800]   it's hard if you're running a clothing business,
[00:05:48.800 --> 00:05:51.200]   especially if you're like a small niche provider of stuff.
[00:05:51.200 --> 00:05:53.220]   So, you know, you have a responsibility
[00:05:53.220 --> 00:05:55.180]   to pay for this stuff, not to grift and get it for free.
[00:05:55.180 --> 00:05:56.100]   - No, I know.
[00:05:56.100 --> 00:05:57.540]   When I was at the Loro Piano store
[00:05:57.540 --> 00:06:01.020]   on 57th Street in Manhattan, the 18,000 square foot store,
[00:06:01.020 --> 00:06:01.980]   I was thinking the same thing.
[00:06:01.980 --> 00:06:04.620]   These poor people, how do they survive?
[00:06:04.620 --> 00:06:05.620]   - Well, Loro Piano's only
[00:06:05.620 --> 00:06:08.180]   on the LG Amazon. - $270 square foot rent.
[00:06:08.180 --> 00:06:09.500]   Maybe Loro Piano. - How are they making it?
[00:06:09.500 --> 00:06:12.340]   - I would just go back. - Poor purveyors, Friedberg.
[00:06:12.340 --> 00:06:14.260]   - Exploiting poor baby goats.
[00:06:14.260 --> 00:06:16.580]   - Well, whatever, I mean, the fact is the market's down.
[00:06:16.580 --> 00:06:18.340]   There's gonna be a little grifting on the margins.
[00:06:18.340 --> 00:06:19.340]   It's understandable.
[00:06:19.340 --> 00:06:21.920]   (upbeat music)
[00:06:21.920 --> 00:06:39.540]   Friedberg, he loves to produce every 17th episode.
[00:06:39.540 --> 00:06:40.380]   He does a great job.
[00:06:40.380 --> 00:06:41.700]   - Oh no, I like to prepare,
[00:06:41.700 --> 00:06:43.480]   or at least know what the heck we're gonna talk about
[00:06:43.480 --> 00:06:44.320]   when we get together.
[00:06:44.320 --> 00:06:45.380]   - And here are some prompts.
[00:06:45.380 --> 00:06:46.220]   He got these prompts because--
[00:06:46.220 --> 00:06:48.500]   - Producer not doing his job, yeah, go ahead.
[00:06:48.500 --> 00:06:50.300]   - Producer, oh God.
[00:06:50.300 --> 00:06:53.780]   All right, so first up on Friedberg's curiousness,
[00:06:53.780 --> 00:06:55.620]   this is, Friedberg--
[00:06:55.620 --> 00:06:56.740]   - All right, if this is how you're gonna do it,
[00:06:56.740 --> 00:06:58.700]   let's skip ahead to the next section, come on.
[00:06:58.700 --> 00:06:59.620]   - No, no, no, okay.
[00:06:59.620 --> 00:07:01.580]   So-- - Go, go, go.
[00:07:01.580 --> 00:07:04.580]   - Why do you think Chamath people love the podcast?
[00:07:04.580 --> 00:07:05.500]   Why do you think they listen?
[00:07:05.500 --> 00:07:07.320]   Why do you think they love it?
[00:07:07.320 --> 00:07:08.980]   What is the phenomenon?
[00:07:08.980 --> 00:07:11.020]   What lightning has been captured in this bottle?
[00:07:11.020 --> 00:07:14.580]   - First is I think that they appreciate our friendship.
[00:07:14.580 --> 00:07:16.520]   It's kind of like odd and quirky.
[00:07:16.520 --> 00:07:20.180]   And I think a lot of, you know,
[00:07:20.180 --> 00:07:23.140]   it maps to like relationships that they have
[00:07:23.140 --> 00:07:24.260]   amongst their own friends.
[00:07:24.260 --> 00:07:26.500]   So that's what makes it relatable.
[00:07:26.500 --> 00:07:28.940]   But the second is that all of us uniquely
[00:07:28.940 --> 00:07:30.260]   have a point of view
[00:07:30.260 --> 00:07:35.100]   about stuff that matters more and more in the world.
[00:07:35.100 --> 00:07:36.640]   I think that's just the basics of it.
[00:07:36.640 --> 00:07:39.460]   Like, it's not like technology is going away
[00:07:39.460 --> 00:07:42.140]   and it's not like its impact in the world is going away.
[00:07:42.140 --> 00:07:43.420]   And the more it becomes mainstream,
[00:07:43.420 --> 00:07:45.540]   the more it's important for a lot of folks
[00:07:45.540 --> 00:07:47.860]   to understand what's happening.
[00:07:47.860 --> 00:07:50.960]   And I think we provide a pretty unfiltered view of it.
[00:07:50.960 --> 00:07:55.900]   And we do it where, and this is a lot of credit to Sax,
[00:07:55.900 --> 00:07:57.800]   more than anyone else on the show,
[00:07:57.800 --> 00:08:01.260]   has to take a counterpoint and steel man
[00:08:01.260 --> 00:08:03.100]   what would otherwise be controversial views.
[00:08:03.100 --> 00:08:05.500]   And if he didn't have his three friends around him,
[00:08:05.500 --> 00:08:08.900]   that would make the pod meaningfully worse, I think.
[00:08:08.900 --> 00:08:10.280]   - Can you explain for people who don't know
[00:08:10.280 --> 00:08:12.180]   what steel manning is, what that means?
[00:08:12.180 --> 00:08:15.140]   - Well, it just means like to have intellectual honesty
[00:08:15.140 --> 00:08:17.940]   around a point of view and actually put your best foot
[00:08:17.940 --> 00:08:19.060]   forward in trying to explain it,
[00:08:19.060 --> 00:08:20.540]   even when it's not orthodox,
[00:08:20.540 --> 00:08:23.540]   even when it's not what the mainstream would say is right.
[00:08:23.540 --> 00:08:27.640]   And so what it actually does is it creates a contrast
[00:08:27.640 --> 00:08:29.400]   against every other alternative
[00:08:29.400 --> 00:08:31.020]   that you have to learn about things,
[00:08:31.020 --> 00:08:35.280]   which you find incrementally is biased.
[00:08:35.280 --> 00:08:37.780]   And I think that's what we've gotten right.
[00:08:37.780 --> 00:08:40.820]   We are four friends that have a reasonable point of view
[00:08:40.820 --> 00:08:42.780]   rooted in some amount of success.
[00:08:42.780 --> 00:08:43.860]   And I think that that's important
[00:08:43.860 --> 00:08:45.740]   because it gives us credibility
[00:08:45.740 --> 00:08:48.420]   and we take all sides of issues.
[00:08:48.420 --> 00:08:49.260]   - Yeah.
[00:08:49.260 --> 00:08:52.740]   - And oftentimes it is not the obvious,
[00:08:52.740 --> 00:08:55.220]   simple, reductive answer.
[00:08:55.220 --> 00:08:58.420]   And I think that that's where it really shines.
[00:08:58.420 --> 00:08:59.940]   - Just so people know about the steel man argument,
[00:08:59.940 --> 00:09:01.500]   just wanna make sure people are crowded.
[00:09:01.500 --> 00:09:04.900]   I think most people refer to it as the act of presenting
[00:09:04.900 --> 00:09:07.140]   the other argument in the strongest way possible
[00:09:07.140 --> 00:09:09.860]   to be intellectually honest, like the opposite of strong man.
[00:09:09.860 --> 00:09:11.620]   - Exactly, opposite of strong man.
[00:09:11.620 --> 00:09:15.220]   'Cause the way the debate happens on Twitter and so forth
[00:09:15.220 --> 00:09:18.020]   is it's almost like the intellectual debate
[00:09:18.020 --> 00:09:22.620]   is being attacked using opposition research tactics
[00:09:22.620 --> 00:09:23.940]   like it were a political campaign.
[00:09:23.940 --> 00:09:25.940]   So in other words, they go back through anything
[00:09:25.940 --> 00:09:27.660]   you might've said or written,
[00:09:27.660 --> 00:09:31.660]   take the thing that was most wrong or least justifiable
[00:09:31.660 --> 00:09:34.300]   or the thing they can even just take out of context.
[00:09:34.300 --> 00:09:36.400]   And then they'll try to make it about that
[00:09:36.400 --> 00:09:39.340]   as opposed to the argument you're actually making.
[00:09:39.340 --> 00:09:41.980]   And we just see this tactic over and over again.
[00:09:41.980 --> 00:09:45.540]   And it's not an intellectually rigorous way
[00:09:45.540 --> 00:09:47.420]   of having a debate about something.
[00:09:47.420 --> 00:09:48.980]   - You don't learn anything.
[00:09:48.980 --> 00:09:51.860]   And deep down inside, you know that it's contrived.
[00:09:51.860 --> 00:09:53.780]   And that is the, in a nutshell,
[00:09:53.780 --> 00:09:56.500]   so it almost in many ways has less to do
[00:09:56.500 --> 00:09:58.380]   with how good we are,
[00:09:58.380 --> 00:10:01.460]   but frankly how bad all the alternatives are.
[00:10:01.460 --> 00:10:03.620]   So even if you wanted to learn about tech
[00:10:03.620 --> 00:10:07.420]   and you go up and you sign up for these newsletters,
[00:10:07.420 --> 00:10:09.420]   or if you look at some of these tech sites,
[00:10:09.420 --> 00:10:11.660]   they're really terrible.
[00:10:11.660 --> 00:10:14.980]   And they have done an increasingly terrible job
[00:10:14.980 --> 00:10:18.660]   over the last five years in telling the most important
[00:10:18.660 --> 00:10:21.780]   things, the truth and everything in between.
[00:10:21.780 --> 00:10:26.420]   And so if you can find a source for an hour a week
[00:10:26.420 --> 00:10:30.420]   that is trying to tell you how basically the world
[00:10:30.420 --> 00:10:33.820]   is going to come together in a really integrated,
[00:10:33.820 --> 00:10:36.640]   multifaceted way, it's not like we're right.
[00:10:37.640 --> 00:10:39.480]   And it's not like we know better than other people.
[00:10:39.480 --> 00:10:42.200]   In fact, many times a lot of the criticism I get is,
[00:10:42.200 --> 00:10:45.600]   how dare you talk about X or how dare you talk about Y?
[00:10:45.600 --> 00:10:48.560]   Because it makes people who are experts in that field,
[00:10:48.560 --> 00:10:50.560]   you know, feel like, how dare you come into my realm
[00:10:50.560 --> 00:10:53.200]   and even have an opinion on, you know,
[00:10:53.200 --> 00:10:56.320]   what Russian politics was like in the 1980s.
[00:10:56.320 --> 00:10:58.220]   And those things really annoy these folks
[00:10:58.220 --> 00:11:01.520]   because they feel that those opinions and that knowledge
[00:11:01.520 --> 00:11:04.800]   should be cordoned off and held tightly as this secret
[00:11:04.800 --> 00:11:07.440]   that only they are allowed to talk about into the world.
[00:11:07.440 --> 00:11:10.440]   And this is the point where with the internet,
[00:11:10.440 --> 00:11:12.520]   all this knowledge is accessible.
[00:11:12.520 --> 00:11:15.520]   So the value of that knowledge, in my opinion,
[00:11:15.520 --> 00:11:16.720]   is the least it's ever been.
[00:11:16.720 --> 00:11:19.240]   It's the interpretation that's valuable.
[00:11:19.240 --> 00:11:21.640]   And it's the ability to actually like think narratively
[00:11:21.640 --> 00:11:23.440]   around how all these things connect.
[00:11:23.440 --> 00:11:24.880]   And this is where I give a lot of credit.
[00:11:24.880 --> 00:11:26.360]   I think you guys do an incredible job.
[00:11:26.360 --> 00:11:28.920]   I think the way Friedbrook thinks is super unique.
[00:11:28.920 --> 00:11:31.220]   I think the way that Saksis thinks is unique.
[00:11:31.220 --> 00:11:34.800]   I think J. Cal, your courage to basically fight back
[00:11:34.800 --> 00:11:35.760]   is very special.
[00:11:35.760 --> 00:11:39.260]   All of it together is a really unique recipe at works.
[00:11:39.260 --> 00:11:41.440]   And what I will tell you consistently
[00:11:41.440 --> 00:11:46.440]   is the number of people that listen to this
[00:11:46.440 --> 00:11:50.160]   of import and influence, I am constantly shocked.
[00:11:50.160 --> 00:11:52.520]   And if you are not sure of it,
[00:11:52.520 --> 00:11:54.560]   you need to get out of this stupid little echo chamber
[00:11:54.560 --> 00:11:57.880]   of Silicon Valley, go to New York, go around the world.
[00:11:57.880 --> 00:11:59.080]   And if you're in the right meetings,
[00:11:59.080 --> 00:12:01.120]   it's incredible how folks are getting educated.
[00:12:01.120 --> 00:12:01.960]   Using this pod.
[00:12:01.960 --> 00:12:03.520]   And I think that's really amazing.
[00:12:03.520 --> 00:12:07.880]   - Yeah, I think there's like been a tendency
[00:12:07.880 --> 00:12:10.760]   in like what we call media today,
[00:12:10.760 --> 00:12:14.840]   historically kind of communication amongst humans.
[00:12:14.840 --> 00:12:18.280]   It was very slow for a communication cycle
[00:12:18.280 --> 00:12:19.920]   to go from beginning to end to close
[00:12:19.920 --> 00:12:22.960]   because we had print and books and then telegraphs
[00:12:22.960 --> 00:12:26.280]   and then telephones and then television and radio.
[00:12:26.280 --> 00:12:29.400]   And the internet I think has really changed the cycle,
[00:12:29.400 --> 00:12:33.920]   the loop cycle to the point that a story iterates
[00:12:33.920 --> 00:12:36.440]   and proliferates very quickly.
[00:12:36.440 --> 00:12:38.360]   And a lot of people talk about the news cycle
[00:12:38.360 --> 00:12:39.800]   being very short nowadays.
[00:12:39.800 --> 00:12:44.800]   And what that means is that there is a group think approach
[00:12:44.800 --> 00:12:48.440]   to resolving to a point of view on what the news is.
[00:12:48.440 --> 00:12:51.120]   So the news comes out, everyone iterates on it,
[00:12:51.120 --> 00:12:52.240]   they form their point of view,
[00:12:52.240 --> 00:12:54.480]   and all of a sudden everyone's on the same point of view.
[00:12:54.480 --> 00:12:58.060]   And so there is no room for dissent or debate or discussion
[00:12:58.060 --> 00:12:59.760]   because the cycle closes so quickly
[00:12:59.760 --> 00:13:02.880]   and everyone coalesces around the same point of view.
[00:13:02.880 --> 00:13:06.720]   And nowadays I think we see not just that unipolar behavior,
[00:13:06.720 --> 00:13:08.880]   but we see this bipolar behavior
[00:13:08.880 --> 00:13:11.640]   where everyone coalesces on their point of view
[00:13:11.640 --> 00:13:14.480]   and how their point of view is the opposite
[00:13:14.480 --> 00:13:16.000]   of the other side.
[00:13:16.000 --> 00:13:17.640]   And everyone has their own heuristic
[00:13:17.640 --> 00:13:19.160]   for what the other side is.
[00:13:19.160 --> 00:13:21.920]   There's this populism versus elitism siding,
[00:13:21.920 --> 00:13:24.680]   there's this red versus blue siding,
[00:13:24.680 --> 00:13:26.840]   there's this us versus them siding,
[00:13:26.840 --> 00:13:30.840]   us versus China siding, everything is now bipolar.
[00:13:30.840 --> 00:13:33.960]   And so you very quickly coalesce around what your poll says
[00:13:33.960 --> 00:13:37.340]   and what your poll is instructing you to believe.
[00:13:37.340 --> 00:13:39.600]   And that is what is fundamentally wrong
[00:13:39.600 --> 00:13:41.800]   with how the system is working today.
[00:13:41.800 --> 00:13:43.960]   And I think what people find refreshing
[00:13:43.960 --> 00:13:47.200]   about a discourse that doesn't succumb
[00:13:47.200 --> 00:13:50.280]   to that bipolarity as a standard
[00:13:50.280 --> 00:13:53.200]   is that it provides people the ability
[00:13:53.200 --> 00:13:56.240]   to have a real rational, out of sync point of view
[00:13:56.240 --> 00:13:57.800]   that maybe changes one's point of view
[00:13:57.800 --> 00:14:00.200]   and changes one's mind in a meaningful way.
[00:14:00.200 --> 00:14:01.840]   And I think that's what's really missing today.
[00:14:01.840 --> 00:14:04.360]   And I think maybe sometimes we do a good job
[00:14:04.360 --> 00:14:05.920]   and we touch on that.
[00:14:05.920 --> 00:14:07.320]   And so that's what I would strive to do
[00:14:07.320 --> 00:14:10.200]   is to always try and avoid that bipolarity on everything.
[00:14:10.200 --> 00:14:15.400]   Zen Buddhists call it dualistic thinking.
[00:14:15.400 --> 00:14:18.200]   The human brain and generally the universe
[00:14:18.200 --> 00:14:21.600]   seems to evolve into this kind of dualism on everything.
[00:14:21.600 --> 00:14:23.120]   And it's not really always the case
[00:14:23.160 --> 00:14:26.920]   that there are shades of gray, that there is nuance,
[00:14:26.920 --> 00:14:29.920]   that there is a complex dimensionality to things
[00:14:29.920 --> 00:14:31.160]   that I think people really,
[00:14:31.160 --> 00:14:32.680]   if they take the time to understand,
[00:14:32.680 --> 00:14:34.360]   recognize that maybe it's not left and right,
[00:14:34.360 --> 00:14:36.080]   maybe it's not elite and populism,
[00:14:36.080 --> 00:14:37.680]   maybe it's not all black and white.
[00:14:37.680 --> 00:14:40.680]   And that's an important, hopefully framing
[00:14:40.680 --> 00:14:43.080]   that maybe we can bring to light
[00:14:43.080 --> 00:14:45.200]   through our diagnosis of what's going on
[00:14:45.200 --> 00:14:46.280]   in things right now.
[00:14:46.280 --> 00:14:47.840]   - Yeah, I'd like to add to that.
[00:14:47.840 --> 00:14:50.080]   I think there's a ton of great journalism going out there.
[00:14:50.080 --> 00:14:51.000]   We see it.
[00:14:51.000 --> 00:14:52.400]   There's a ton of great sub-sacks out there.
[00:14:52.400 --> 00:14:53.240]   People go deep.
[00:14:53.240 --> 00:14:54.760]   There's other great podcasts out there.
[00:14:54.760 --> 00:14:58.760]   And right now it's a tumultuous time for media journalism
[00:14:58.760 --> 00:15:00.000]   and getting information.
[00:15:00.000 --> 00:15:02.800]   And what sources do we actually trust?
[00:15:02.800 --> 00:15:06.040]   Who actually is thinking in a crisp way
[00:15:06.040 --> 00:15:07.760]   and informing people?
[00:15:07.760 --> 00:15:10.400]   And having been a former journalist,
[00:15:10.400 --> 00:15:11.360]   when we were journalists,
[00:15:11.360 --> 00:15:14.480]   we knew that we would get 10, 20, 30, 40% of a story.
[00:15:14.480 --> 00:15:17.520]   We would publish it and we would try our best.
[00:15:17.520 --> 00:15:20.440]   But journalism has changed dramatically
[00:15:20.440 --> 00:15:21.600]   in the last 20 years.
[00:15:21.600 --> 00:15:23.200]   And I can tell you-
[00:15:23.200 --> 00:15:24.520]   - Journalism is dead.
[00:15:24.520 --> 00:15:25.360]   Sorry.
[00:15:25.360 --> 00:15:26.200]   - Okay.
[00:15:26.200 --> 00:15:27.020]   - I'm sorry.
[00:15:27.020 --> 00:15:27.860]   - There's still some great journalism occurring.
[00:15:27.860 --> 00:15:28.880]   It's on the margins.
[00:15:28.880 --> 00:15:29.960]   - It's irrelevant.
[00:15:29.960 --> 00:15:30.840]   And I'll tell you why.
[00:15:30.840 --> 00:15:33.360]   Because the facts are known instantaneously
[00:15:33.360 --> 00:15:34.680]   on Twitter and through the internet.
[00:15:34.680 --> 00:15:36.420]   We don't need people to relate facts.
[00:15:36.420 --> 00:15:39.000]   We need people to wrap facts in context
[00:15:39.000 --> 00:15:41.280]   and allow us to come to our own conclusions.
[00:15:41.280 --> 00:15:43.480]   That's why I think journalism isn't what it used to be.
[00:15:43.480 --> 00:15:46.880]   That's why people who are historically journalists
[00:15:46.880 --> 00:15:49.920]   struggle because now they actually have to create context
[00:15:49.920 --> 00:15:51.480]   and narrative and have an opinion.
[00:15:51.480 --> 00:15:53.520]   But when you publish that into the Wall Street Journal
[00:15:53.520 --> 00:15:56.280]   or the New York Times, it becomes very confusing.
[00:15:56.280 --> 00:15:58.400]   They don't know that that's what they were supposed to do.
[00:15:58.400 --> 00:15:59.800]   That's not what they used to do.
[00:15:59.800 --> 00:16:03.760]   That's not how Pulitzer Prizes were historically given out.
[00:16:03.760 --> 00:16:05.060]   And that's why everybody then, you know,
[00:16:05.060 --> 00:16:05.900]   rants and rails about things.
[00:16:05.900 --> 00:16:07.520]   - Well, that's where I was kind of going is, you know,
[00:16:07.520 --> 00:16:11.280]   if you look at it as journalists, people don't know this,
[00:16:11.280 --> 00:16:13.040]   but journalists are being compensated.
[00:16:13.040 --> 00:16:14.880]   Their little salaries in many cases
[00:16:14.880 --> 00:16:16.240]   are based on their follower counts.
[00:16:16.240 --> 00:16:17.800]   They're based on what audience
[00:16:17.800 --> 00:16:19.160]   they're bringing to the table.
[00:16:19.160 --> 00:16:20.320]   And you see this in Substack.
[00:16:20.320 --> 00:16:23.720]   Substack just said, we're going to hire the top journalists
[00:16:23.720 --> 00:16:25.360]   who have the most followers on Twitter.
[00:16:25.360 --> 00:16:26.480]   - But you have to change the word
[00:16:26.480 --> 00:16:28.040]   so that you change how people think about it.
[00:16:28.040 --> 00:16:29.520]   These people are not journalists.
[00:16:29.520 --> 00:16:31.160]   These people are opinion makers.
[00:16:31.160 --> 00:16:33.080]   - Okay, in some cases they're doing journalism.
[00:16:33.080 --> 00:16:33.920]   In some cases they're staying-
[00:16:33.920 --> 00:16:34.920]   - No, they're not. - No, no.
[00:16:34.920 --> 00:16:36.480]   There are some cases where they're actually doing
[00:16:36.480 --> 00:16:37.360]   real journalism, Chamath.
[00:16:37.360 --> 00:16:39.480]   There are people doing investigative reporting still.
[00:16:39.480 --> 00:16:42.280]   It's not the majority of what you see, but it still exists.
[00:16:42.280 --> 00:16:44.500]   It's just a very much smaller percentage.
[00:16:44.500 --> 00:16:46.680]   But putting that aside, if you think about-
[00:16:46.680 --> 00:16:49.160]   - But you can't wrap a virtuous blanket
[00:16:49.160 --> 00:16:52.560]   around a thousand people because of the acts of one.
[00:16:52.560 --> 00:16:53.840]   - I'm not, and I'm not.
[00:16:53.840 --> 00:16:55.560]   I said there's a range here.
[00:16:55.560 --> 00:16:56.560]   It's a small percentage,
[00:16:56.560 --> 00:16:58.800]   but there's still random acts of great journalism.
[00:16:58.800 --> 00:16:59.920]   - What do you think that percentage is?
[00:16:59.920 --> 00:17:01.920]   - Of content creation, I put it at 5%.
[00:17:01.920 --> 00:17:03.600]   So, you know, one out of 20. - That's a huge number.
[00:17:03.600 --> 00:17:04.440]   I'm shocked.
[00:17:04.440 --> 00:17:06.360]   - Yeah, anyway. - I think it's less than 1%.
[00:17:06.360 --> 00:17:08.560]   - But let me just finish this one thought here.
[00:17:08.560 --> 00:17:13.520]   If you are going to be hired and compensated,
[00:17:13.520 --> 00:17:15.120]   and we talk about systems here a lot.
[00:17:15.120 --> 00:17:16.400]   So just thinking from first principles,
[00:17:16.400 --> 00:17:17.520]   if you're a journalist,
[00:17:17.520 --> 00:17:18.960]   if you're a writer, opinion writer, whatever,
[00:17:18.960 --> 00:17:21.000]   you produce content for Wall Street Journal,
[00:17:21.000 --> 00:17:22.840]   for podcasts, et cetera.
[00:17:22.840 --> 00:17:25.440]   Today, let this sink in,
[00:17:25.440 --> 00:17:28.480]   your follower count is what your book advance is.
[00:17:28.480 --> 00:17:30.720]   It's what your compensation is.
[00:17:30.720 --> 00:17:32.040]   It's who hires you.
[00:17:32.040 --> 00:17:34.680]   Now, if that's the truth, and it's not all the time,
[00:17:34.680 --> 00:17:35.520]   but I think the majority of the time.
[00:17:35.520 --> 00:17:36.360]   - Which is a proof point
[00:17:36.360 --> 00:17:38.360]   that your job is not to relay facts.
[00:17:38.360 --> 00:17:39.200]   We can get facts from a thousand sources.
[00:17:39.200 --> 00:17:40.160]   - Exactly, that's right.
[00:17:40.160 --> 00:17:41.280]   Let me finish my thought here.
[00:17:41.280 --> 00:17:42.440]   And so then what happens is,
[00:17:42.440 --> 00:17:45.600]   how is follower count on Twitter actually derived?
[00:17:45.600 --> 00:17:47.240]   How do you get that follower count?
[00:17:47.240 --> 00:17:48.320]   By being tribal.
[00:17:48.320 --> 00:17:49.720]   And so what's happened is,
[00:17:49.720 --> 00:17:51.120]   journalists have became tribal,
[00:17:51.120 --> 00:17:53.360]   they get big followings, they give spicy takes,
[00:17:53.360 --> 00:17:56.160]   they pick a side, and then their compensation follows it.
[00:17:56.160 --> 00:17:57.600]   And that's why New York Times said,
[00:17:57.600 --> 00:17:58.920]   "Can we all stop on Twitter?"
[00:17:58.920 --> 00:18:00.440]   And they literally put an edict out.
[00:18:00.440 --> 00:18:02.360]   Then you look at this podcast,
[00:18:02.360 --> 00:18:04.560]   I think people look at us as,
[00:18:04.560 --> 00:18:07.120]   in their mixture, podcasting long form,
[00:18:07.120 --> 00:18:08.640]   taking the time week after week
[00:18:08.640 --> 00:18:11.720]   to spend 90 minutes chopping these things up.
[00:18:11.720 --> 00:18:13.240]   I think that's what, to the original question,
[00:18:13.240 --> 00:18:16.200]   Freiburg, you had, is what people find so great.
[00:18:16.200 --> 00:18:17.400]   When people ask me,
[00:18:17.400 --> 00:18:19.040]   I say it's really about the fact that,
[00:18:19.040 --> 00:18:21.320]   there's a friendships here and it's funny,
[00:18:21.320 --> 00:18:23.440]   but it's also informative and it's insightful.
[00:18:23.440 --> 00:18:26.000]   And at times, as you pointed out Chamath,
[00:18:26.000 --> 00:18:27.720]   you know, random acts of bravery
[00:18:27.720 --> 00:18:30.080]   and taking positions that are not popular.
[00:18:30.080 --> 00:18:32.400]   - And to think that you and Freiburg
[00:18:32.400 --> 00:18:34.440]   almost blew this up over a few hundred K.
[00:18:34.440 --> 00:18:36.160]   - I didn't.
[00:18:36.160 --> 00:18:37.000]   (laughing)
[00:18:37.000 --> 00:18:38.320]   - No, the two of you equally should share.
[00:18:38.320 --> 00:18:40.080]   - I wouldn't classify it that way.
[00:18:40.080 --> 00:18:40.920]   By the way, I think the point-
[00:18:40.920 --> 00:18:41.840]   - Yeah, here we go.
[00:18:41.840 --> 00:18:43.960]   Now the bad feelings are ready, getting spicy.
[00:18:43.960 --> 00:18:45.800]   - Just a, can I, can I-
[00:18:45.800 --> 00:18:47.440]   - I'm more of an ethical framework,
[00:18:47.440 --> 00:18:48.440]   but yeah, that's fine, go ahead.
[00:18:48.440 --> 00:18:50.480]   - Ooh, even worse.
[00:18:50.480 --> 00:18:52.240]   (laughing)
[00:18:52.240 --> 00:18:53.800]   - Look at Chamath stirring the pot.
[00:18:53.800 --> 00:18:54.960]   - Just to chime in on this point,
[00:18:54.960 --> 00:18:57.000]   I mean, I think I'm in violent agreement with you guys,
[00:18:57.000 --> 00:18:58.400]   but I'd frame it a little differently.
[00:18:58.400 --> 00:19:01.920]   I think the reason why people seek out our podcasts
[00:19:01.920 --> 00:19:05.640]   and other podcasts and sub stacks is,
[00:19:05.640 --> 00:19:07.680]   and sort of this kind of independent journalism
[00:19:07.680 --> 00:19:09.240]   and are willing to pay for it,
[00:19:09.240 --> 00:19:11.040]   is because the mainstream media
[00:19:11.040 --> 00:19:15.200]   has become totally devoid of substance.
[00:19:15.200 --> 00:19:20.200]   It's as partisan and ideologized as it's ever been.
[00:19:20.200 --> 00:19:22.040]   Reporters are extremely ideological.
[00:19:22.040 --> 00:19:24.640]   You look at the New York Times, the Washington Post,
[00:19:24.640 --> 00:19:26.760]   the major television networks,
[00:19:26.760 --> 00:19:28.280]   it's all kind of the same thing.
[00:19:28.280 --> 00:19:29.920]   And yeah, there is like,
[00:19:29.920 --> 00:19:31.520]   a little bit of an echo chamber problem
[00:19:31.520 --> 00:19:32.920]   in terms of the partisan politics,
[00:19:32.920 --> 00:19:35.880]   but the mainstream media is the most ideologized
[00:19:35.880 --> 00:19:37.360]   it's ever been.
[00:19:37.360 --> 00:19:38.960]   I mean, just to give you one small example
[00:19:38.960 --> 00:19:40.560]   that we talked about in the pod,
[00:19:40.560 --> 00:19:44.400]   we had two quarters of negative GDP growth,
[00:19:44.400 --> 00:19:45.720]   which the media has always considered
[00:19:45.720 --> 00:19:47.160]   to be the definition of recession.
[00:19:47.160 --> 00:19:48.240]   And then all of a sudden they said,
[00:19:48.240 --> 00:19:50.360]   no, we can't know what a recession is anymore
[00:19:50.360 --> 00:19:52.440]   because they know that'd be a horrible headline for Biden
[00:19:52.440 --> 00:19:53.840]   right before the midterm elections.
[00:19:53.840 --> 00:19:55.360]   That's more of a partisan version.
[00:19:55.360 --> 00:19:58.600]   I think on the, a more ideological version
[00:19:58.600 --> 00:20:00.600]   would be just around this Ukraine war.
[00:20:00.600 --> 00:20:04.200]   I mean, it's just incredible how biased the coverage is.
[00:20:04.200 --> 00:20:07.920]   They don't even present the other side of the story,
[00:20:07.920 --> 00:20:09.800]   like let's call it the Mearsheimer take
[00:20:09.800 --> 00:20:12.760]   about how we got to this point that we're in.
[00:20:12.760 --> 00:20:15.240]   So the American people just aren't being informed at all.
[00:20:15.240 --> 00:20:18.680]   You know, we love to talk about how the people
[00:20:18.680 --> 00:20:20.760]   of all these other countries are being propagandized
[00:20:20.760 --> 00:20:21.600]   by their governments.
[00:20:21.600 --> 00:20:23.680]   We never talk about how propagandized
[00:20:23.680 --> 00:20:24.680]   the American people are.
[00:20:24.680 --> 00:20:27.040]   The media does not present the other side of the story
[00:20:27.040 --> 00:20:31.440]   at all on how we got into the Ukraine war
[00:20:31.440 --> 00:20:32.600]   and how we're now at the brink
[00:20:32.600 --> 00:20:34.600]   of what Biden calls Armageddon.
[00:20:34.600 --> 00:20:36.120]   - Yeah. - So how are we gonna get out of it?
[00:20:36.120 --> 00:20:37.680]   How are we gonna get out of it?
[00:20:37.680 --> 00:20:39.240]   - Any topic, by the way.
[00:20:39.240 --> 00:20:40.680]   - I just said that was my punch.
[00:20:40.680 --> 00:20:43.360]   - There's so many topics that we see,
[00:20:43.360 --> 00:20:46.240]   you know, effectively short form
[00:20:46.240 --> 00:20:48.440]   and short form meaning it can be presented
[00:20:48.440 --> 00:20:50.800]   in a soundbite or on a TikTok clip
[00:20:50.800 --> 00:20:52.920]   or in a couple of paragraphs
[00:20:52.920 --> 00:20:54.160]   where someone's attention span,
[00:20:54.160 --> 00:20:56.920]   before someone's attention span lapses out,
[00:20:56.920 --> 00:21:00.480]   always misses the dimensionality that got us to that point.
[00:21:00.480 --> 00:21:01.960]   And so there's one perspective,
[00:21:01.960 --> 00:21:04.960]   one point of view on one dimension
[00:21:04.960 --> 00:21:06.840]   and the dimension like Sax is talking about
[00:21:06.840 --> 00:21:09.840]   about the time and the history of the dynamics
[00:21:09.840 --> 00:21:12.040]   of all the countries and all the people
[00:21:12.040 --> 00:21:13.760]   and all the interactions that have happened
[00:21:13.760 --> 00:21:17.040]   for the past couple of decades that led up to this moment.
[00:21:17.040 --> 00:21:20.280]   But then this moment is taken in its context alone
[00:21:20.280 --> 00:21:22.760]   and reclassified as being something
[00:21:22.760 --> 00:21:24.880]   that is good versus evil.
[00:21:24.880 --> 00:21:28.080]   It completely misses the entire storyline of what happened.
[00:21:28.080 --> 00:21:30.560]   It's like going to the end of a fairy tale
[00:21:30.560 --> 00:21:32.600]   and saying, here's this moment of what happened
[00:21:32.600 --> 00:21:34.840]   and all the buildup and all the things that occurred
[00:21:34.840 --> 00:21:36.480]   are often missing and all the different sides
[00:21:36.480 --> 00:21:37.960]   of the story are missing.
[00:21:37.960 --> 00:21:39.800]   And I think that that's really what makes it
[00:21:39.800 --> 00:21:43.720]   so difficult today to feel like you can trust authority
[00:21:43.720 --> 00:21:47.120]   and that you can trust the media that's presented to you
[00:21:47.120 --> 00:21:49.520]   as a consumer, not just in the US or in the West,
[00:21:49.520 --> 00:21:51.000]   but around the world,
[00:21:51.000 --> 00:21:52.720]   because there's so much that's left out
[00:21:52.720 --> 00:21:54.480]   and manipulated and kept away.
[00:21:54.480 --> 00:21:56.920]   And what people are waking up to is the fact,
[00:21:56.920 --> 00:21:59.920]   as Chamath points out, that so much of that information,
[00:21:59.920 --> 00:22:03.320]   the direct information is available now.
[00:22:03.320 --> 00:22:07.440]   And so this investigation, this ability to uncover the data
[00:22:07.440 --> 00:22:10.080]   and the storylines and the perspectives
[00:22:10.080 --> 00:22:12.720]   that are typically missing from one form of media
[00:22:12.720 --> 00:22:14.680]   is making people realize that there's so much
[00:22:14.680 --> 00:22:16.360]   that's being left out.
[00:22:16.360 --> 00:22:17.200]   The lie of a mission.
[00:22:17.200 --> 00:22:18.480]   - 100%, 100%.
[00:22:18.480 --> 00:22:19.320]   And I think in this podcast--
[00:22:19.320 --> 00:22:21.960]   - And that's what's really shocking to people nowadays.
[00:22:21.960 --> 00:22:23.800]   And I think that's what makes maybe to some degree,
[00:22:23.800 --> 00:22:26.800]   hold on, our conversation is a little more appealing.
[00:22:26.800 --> 00:22:28.600]   - I'll drop to you in a second there, Sax.
[00:22:28.600 --> 00:22:31.120]   But I did see this happen in three specific topics
[00:22:31.120 --> 00:22:32.400]   that we discussed here.
[00:22:32.400 --> 00:22:34.560]   If you remember, we talked about abortion
[00:22:34.560 --> 00:22:36.280]   and we were on that topic very early
[00:22:36.280 --> 00:22:37.760]   and no one wanted to talk.
[00:22:37.760 --> 00:22:39.040]   I remember when we started talking about
[00:22:39.040 --> 00:22:41.560]   the number of weeks, maybe how Europe looks at this,
[00:22:41.560 --> 00:22:43.360]   that wasn't part of the popular conversation.
[00:22:43.360 --> 00:22:45.600]   It was always just, are you against choice?
[00:22:45.600 --> 00:22:47.280]   Are you for killing babies?
[00:22:47.280 --> 00:22:50.200]   It was like a very two dimensional look at it.
[00:22:50.200 --> 00:22:51.640]   Immigration, same thing.
[00:22:51.640 --> 00:22:52.860]   Nobody would talk about the numbers.
[00:22:52.860 --> 00:22:53.960]   Nobody talked about recruitment.
[00:22:53.960 --> 00:22:55.360]   Nobody talked about the point systems
[00:22:55.360 --> 00:22:56.760]   used in other countries.
[00:22:56.760 --> 00:22:58.520]   It was almost like those basic things
[00:22:58.520 --> 00:23:01.440]   were not allowed to be discussed.
[00:23:01.440 --> 00:23:03.680]   Why can't the media discuss those nuances?
[00:23:03.680 --> 00:23:06.160]   And freedom of speech is, I think, the biggest one.
[00:23:06.160 --> 00:23:08.280]   And the search for truth.
[00:23:08.280 --> 00:23:11.360]   Nobody wants to talk about the fact that the ACLU
[00:23:11.360 --> 00:23:14.000]   used to actually protect unpopular speech.
[00:23:14.000 --> 00:23:16.320]   And unpopular speech is the hardest thing
[00:23:16.320 --> 00:23:17.440]   in the world to protect.
[00:23:17.440 --> 00:23:19.160]   But how did that become something
[00:23:19.160 --> 00:23:21.400]   we can't even talk about now?
[00:23:21.400 --> 00:23:24.900]   And just the snap silencing of any opinion,
[00:23:24.900 --> 00:23:26.480]   whether it's Chappelle or,
[00:23:26.480 --> 00:23:30.920]   pick a topic in freedom of speech, Trump, et cetera.
[00:23:30.920 --> 00:23:33.240]   Who gets protection for freedom of speech?
[00:23:33.240 --> 00:23:34.280]   And we'll talk about it later on the news
[00:23:34.280 --> 00:23:37.120]   but Alex Jones, obviously, a very controversial topic
[00:23:37.120 --> 00:23:37.960]   as well.
[00:23:37.960 --> 00:23:38.780]   Go ahead, Sax, you wanted to add something to it?
[00:23:38.780 --> 00:23:41.200]   - Well, I think just to take this Ukraine situation
[00:23:41.200 --> 00:23:44.400]   as an example, I think the media's biggest power
[00:23:44.400 --> 00:23:48.280]   is the power to define when time begins on an issue.
[00:23:48.280 --> 00:23:49.480]   So especially if-- - What does that mean?
[00:23:49.480 --> 00:23:51.120]   - Well, like with Ukraine,
[00:23:51.120 --> 00:23:54.560]   we're part of an escalatory spiral that's been going on
[00:23:54.560 --> 00:23:57.720]   for well more than eight or nine months.
[00:23:57.720 --> 00:23:59.400]   This issue's been going on since 2008.
[00:23:59.400 --> 00:24:00.240]   - A decade.
[00:24:00.240 --> 00:24:01.480]   Yeah, more than a decade. - Over a decade.
[00:24:01.480 --> 00:24:05.920]   So in other words, if you come in in like the seventh inning,
[00:24:05.920 --> 00:24:07.120]   okay, so to Freeworks' point,
[00:24:07.120 --> 00:24:08.600]   you come in at the end of the story
[00:24:08.600 --> 00:24:10.880]   and it's been an escalatory spiral,
[00:24:10.880 --> 00:24:14.760]   but the media just pretends like time begins on February 24th,
[00:24:14.760 --> 00:24:16.200]   of course, you're gonna have a certain kind of view
[00:24:16.200 --> 00:24:17.040]   on the subject.
[00:24:17.040 --> 00:24:20.840]   Whereas if you know the history of the situation,
[00:24:20.840 --> 00:24:22.840]   if you know that back in the 1990s,
[00:24:22.840 --> 00:24:24.320]   you had people like George Kennan,
[00:24:24.320 --> 00:24:26.840]   who was the architect of our Cold War containment policy,
[00:24:26.840 --> 00:24:28.480]   you had William J. Perry,
[00:24:28.480 --> 00:24:30.440]   who was Bill Clinton's defense secretary,
[00:24:30.440 --> 00:24:32.520]   you had Henry Kissinger, you had John Mearsheimer,
[00:24:32.520 --> 00:24:34.920]   all warned that bringing NATO right up
[00:24:34.920 --> 00:24:38.280]   to Russia's front porch was extremely provocative to them,
[00:24:38.280 --> 00:24:40.560]   that they would see that as a provocation
[00:24:40.560 --> 00:24:43.440]   that would eventually lead to a moment of crisis.
[00:24:43.440 --> 00:24:45.880]   When that moment of crisis finally came,
[00:24:45.880 --> 00:24:49.440]   we're not told that this was predicted.
[00:24:49.440 --> 00:24:52.240]   We're told that anyone who says that this war
[00:24:52.240 --> 00:24:54.240]   has anything to do with NATO expansion
[00:24:54.240 --> 00:24:56.000]   is basically a Putin apologist
[00:24:56.000 --> 00:24:57.560]   and is spouting Putin talking points.
[00:24:57.560 --> 00:25:00.160]   - All right, let's save some of that for the Ukraine talk.
[00:25:00.160 --> 00:25:01.600]   We're gonna talk about it in the news section.
[00:25:01.600 --> 00:25:02.440]   No, but I get your point.
[00:25:02.440 --> 00:25:04.440]   - You could agree or disagree with that take,
[00:25:04.440 --> 00:25:07.480]   but the point is the media doesn't even portray it.
[00:25:07.480 --> 00:25:08.760]   - They really just pick a side.
[00:25:08.760 --> 00:25:10.680]   And I think I like your analogy of like,
[00:25:10.680 --> 00:25:12.960]   just coming in for the last 15 minutes of the game
[00:25:12.960 --> 00:25:14.440]   and just describing that.
[00:25:14.440 --> 00:25:15.920]   You need to have a deeper discussion
[00:25:15.920 --> 00:25:16.960]   of how did we get here?
[00:25:16.960 --> 00:25:18.480]   How did we get here on immigration?
[00:25:18.480 --> 00:25:19.920]   Why don't we have a point system?
[00:25:19.920 --> 00:25:22.160]   Why do we look at people suddenly coming
[00:25:22.160 --> 00:25:23.520]   from south of the border differently
[00:25:23.520 --> 00:25:25.320]   than we did just 20 years ago?
[00:25:25.320 --> 00:25:26.720]   How did that become a politicized issue?
[00:25:26.720 --> 00:25:28.240]   What's the right solution here?
[00:25:28.240 --> 00:25:30.440]   Especially if we can't hire people
[00:25:30.440 --> 00:25:32.760]   for basic jobs in the United States.
[00:25:32.760 --> 00:25:35.040]   Everybody wants to know this question.
[00:25:35.040 --> 00:25:35.880]   What's your favorite,
[00:25:35.880 --> 00:25:39.440]   you have a favorite moment or a least favorite moment,
[00:25:39.440 --> 00:25:41.360]   a great moment in the show history.
[00:25:41.360 --> 00:25:42.860]   And then I guess we'll move on maybe
[00:25:42.860 --> 00:25:44.000]   to some audience questions here.
[00:25:44.000 --> 00:25:47.360]   But let's get this one 'cause an embarrassing moment,
[00:25:47.360 --> 00:25:50.240]   your favorite moment, your least favorite moment,
[00:25:50.240 --> 00:25:51.640]   a moment now you look back on
[00:25:51.640 --> 00:25:53.520]   and you're particularly proud of.
[00:25:53.520 --> 00:25:54.440]   - I love the cold opens.
[00:25:54.440 --> 00:25:57.680]   I think that they are unbelievably human
[00:25:57.680 --> 00:26:00.720]   and funny and normalizing.
[00:26:00.720 --> 00:26:06.880]   They are by far the best part of the pod in my opinion.
[00:26:06.880 --> 00:26:11.480]   And yeah, that's my absolute favorite part
[00:26:11.480 --> 00:26:13.420]   by like miles and miles.
[00:26:13.420 --> 00:26:18.600]   - Sax, you got a favorite moment other than Ukraine.
[00:26:18.600 --> 00:26:19.440]   Other than Ukraine.
[00:26:19.440 --> 00:26:21.160]   I know you got Ukraine on the brain.
[00:26:21.160 --> 00:26:24.160]   - Probably when you started talking like Joe Pesci.
[00:26:24.160 --> 00:26:25.720]   - The Joe Pesci voice.
[00:26:25.720 --> 00:26:28.680]   - I can't do it on command.
[00:26:28.680 --> 00:26:30.200]   I'm not your monkey Sax.
[00:26:30.200 --> 00:26:31.760]   Don't you talk to me like that.
[00:26:31.760 --> 00:26:35.920]   I'll get a fucking bat in here.
[00:26:35.920 --> 00:26:40.640]   No, seriously, you have any other favorite moments
[00:26:40.640 --> 00:26:42.360]   or things you're particularly proud of,
[00:26:42.360 --> 00:26:44.080]   things that people tell you,
[00:26:44.080 --> 00:26:46.280]   hey, I love this part of the show.
[00:26:46.280 --> 00:26:48.720]   - I'm also proud that we were able to air
[00:26:48.720 --> 00:26:50.760]   our dirty laundry a little bit in public
[00:26:50.760 --> 00:26:53.960]   and still get over ourselves and our own egos.
[00:26:53.960 --> 00:26:55.120]   And we're still here.
[00:26:55.120 --> 00:26:56.520]   I think that takes a lot of courage
[00:26:56.520 --> 00:26:58.600]   and a little bit of maturity
[00:26:58.600 --> 00:27:03.600]   that's not in public visibility all the time in the media.
[00:27:03.600 --> 00:27:05.840]   - I like that sentiment a lot.
[00:27:05.840 --> 00:27:06.680]   I think there's a lot of--
[00:27:06.680 --> 00:27:07.760]   - People were pretty uncomfortable about it.
[00:27:07.760 --> 00:27:09.560]   - They were uncomfortable about it.
[00:27:09.560 --> 00:27:10.800]   I think there's a lot of personal growth
[00:27:10.800 --> 00:27:14.320]   that's going on here for everybody involved.
[00:27:14.320 --> 00:27:18.200]   Freeberg, you got a favorite moment other, you know.
[00:27:18.200 --> 00:27:20.440]   - I don't like it when you and Sax fight.
[00:27:20.440 --> 00:27:21.800]   That's just annoying.
[00:27:21.800 --> 00:27:23.480]   - That's your least favorite moment when we are
[00:27:23.480 --> 00:27:24.320]   fighting while we die.
[00:27:24.320 --> 00:27:26.360]   - I literally turn my headphones off
[00:27:26.360 --> 00:27:28.280]   and I like do some emailing.
[00:27:28.280 --> 00:27:31.560]   - It really is just, it really is just this political thing,
[00:27:31.560 --> 00:27:32.640]   but yeah, it does come up.
[00:27:32.640 --> 00:27:33.480]   You know, I don't like the fact that--
[00:27:33.480 --> 00:27:35.360]   - All the moments I've been interrupted by you
[00:27:35.360 --> 00:27:37.720]   that like that just happened five seconds ago,
[00:27:37.720 --> 00:27:40.000]   like, you know, those are usually pretty tough.
[00:27:40.000 --> 00:27:41.680]   - Go ahead, Freeberg.
[00:27:41.680 --> 00:27:43.480]   - I don't know.
[00:27:43.480 --> 00:27:48.040]   What I did enjoy, I did enjoy meeting people at the summit
[00:27:48.040 --> 00:27:51.720]   who shared that this has been like a really important
[00:27:52.640 --> 00:27:54.400]   thing for them to listen to.
[00:27:54.400 --> 00:27:58.360]   I think I was at a Pete's Coffee in the city
[00:27:58.360 --> 00:27:59.680]   and some guy came up to me.
[00:27:59.680 --> 00:28:03.720]   This was early when we were doing the podcast.
[00:28:03.720 --> 00:28:05.840]   And he was like, listening to you guys
[00:28:05.840 --> 00:28:07.640]   has really helped me get through COVID.
[00:28:07.640 --> 00:28:09.280]   And he was like locked in his apartment
[00:28:09.280 --> 00:28:10.360]   and he didn't have a lot of friends
[00:28:10.360 --> 00:28:13.400]   and he didn't have a lot of people to talk with.
[00:28:13.400 --> 00:28:16.200]   And just being able to hear through, you know,
[00:28:16.200 --> 00:28:19.480]   kind of a good conversation around when's this gonna end?
[00:28:19.480 --> 00:28:22.120]   How's COVID gonna, you know,
[00:28:22.120 --> 00:28:23.440]   what's gonna change in the city?
[00:28:23.440 --> 00:28:25.000]   And hearing our friendship
[00:28:25.000 --> 00:28:26.960]   really made a big difference for him.
[00:28:26.960 --> 00:28:28.160]   And it was actually really interesting.
[00:28:28.160 --> 00:28:30.280]   That was off the show, but it made me realize
[00:28:30.280 --> 00:28:32.760]   that the show actually is impactful and helpful
[00:28:32.760 --> 00:28:35.080]   and gave me kind of the energy to keep going
[00:28:35.080 --> 00:28:38.320]   even though I've had frustrations in the past.
[00:28:38.320 --> 00:28:41.400]   So I don't know, I like those moments a lot, to be honest.
[00:28:41.400 --> 00:28:44.800]   That there's real value here for people.
[00:28:44.800 --> 00:28:49.160]   I also, I thought the summit was a lot of fun.
[00:28:49.160 --> 00:28:50.600]   I mean, I had a good time.
[00:28:50.600 --> 00:28:54.800]   - Well, you know, it's, I think we're steering towards,
[00:28:54.800 --> 00:28:56.880]   I think we're steering towards summit 2023.
[00:28:56.880 --> 00:28:58.800]   - That was me stirring the pot a little bit.
[00:28:58.800 --> 00:29:01.320]   - I think we're steering towards 2023.
[00:29:01.320 --> 00:29:02.160]   - One and done.
[00:29:02.160 --> 00:29:04.400]   - Listen, as far as I'm concerned,
[00:29:04.400 --> 00:29:06.720]   you do it, you produce it, or you hire a producer,
[00:29:06.720 --> 00:29:07.560]   I'll show up.
[00:29:07.560 --> 00:29:11.600]   I don't need to make a producer fee, you can do it.
[00:29:11.600 --> 00:29:13.040]   You can take the producer fee, whatever it is.
[00:29:13.040 --> 00:29:14.640]   - All right, guys, I got a couple of questions here
[00:29:14.640 --> 00:29:15.640]   from the audience.
[00:29:15.640 --> 00:29:18.640]   You guys see this list?
[00:29:18.640 --> 00:29:19.480]   - Yeah, we got it. - Anything stand out
[00:29:19.480 --> 00:29:20.320]   for you guys?
[00:29:20.320 --> 00:29:21.160]   - Well, you pick, you pick.
[00:29:21.160 --> 00:29:26.160]   - So here's a question, we got it over email from Nathan.
[00:29:26.160 --> 00:29:29.120]   And Nathan said, "We know the reasons,
[00:29:29.120 --> 00:29:30.760]   the reason you guys started the pod.
[00:29:30.760 --> 00:29:32.600]   What is the motivation of each bestie
[00:29:32.600 --> 00:29:34.560]   to continue doing it every week?"
[00:29:34.560 --> 00:29:37.840]   - Now I ask myself that every week.
[00:29:37.840 --> 00:29:38.680]   (laughing)
[00:29:38.680 --> 00:29:39.520]   - You and me both. - That's not to say.
[00:29:39.520 --> 00:29:40.360]   - You and me both.
[00:29:40.360 --> 00:29:42.440]   - That's sexist therapy.
[00:29:42.440 --> 00:29:43.760]   It was sexist therapy yesterday.
[00:29:43.760 --> 00:29:44.600]   Why am I doing this?
[00:29:44.600 --> 00:29:45.720]   - No, I mean, seriously, I'm thinking about taking a break.
[00:29:45.720 --> 00:29:48.440]   Not 'cause I don't like doing it, but it is time consuming.
[00:29:48.440 --> 00:29:50.200]   And I do want time to get back
[00:29:50.200 --> 00:29:51.560]   to doing some business writing.
[00:29:51.560 --> 00:29:56.000]   I was on a pretty good track to publish a book about SaaS.
[00:29:56.000 --> 00:29:57.200]   Before we started doing the pod,
[00:29:57.200 --> 00:29:59.040]   I had written a lot of business blogs.
[00:29:59.040 --> 00:29:59.880]   And this is kind of cut into that.
[00:29:59.880 --> 00:30:01.480]   - Whoa, taking a break?
[00:30:01.480 --> 00:30:02.320]   How many weeks? - I don't know,
[00:30:02.320 --> 00:30:03.520]   I'm thinking about it 'cause--
[00:30:03.520 --> 00:30:04.360]   - What, 10 weeks?
[00:30:04.360 --> 00:30:05.200]   What are you thinking?
[00:30:05.200 --> 00:30:07.040]   - Maybe like a month or something, yeah.
[00:30:07.040 --> 00:30:07.880]   - Oh, four weeks.
[00:30:07.880 --> 00:30:08.720]   Ah, you can take, that's no big deal.
[00:30:08.720 --> 00:30:10.280]   - Maybe 10 weeks maybe, I don't know.
[00:30:10.280 --> 00:30:11.760]   - Four to 10, all right, well.
[00:30:11.760 --> 00:30:12.600]   - I've got like a hopper.
[00:30:12.600 --> 00:30:15.040]   - Right now, Brad Gershner is like doing jumping jacks
[00:30:15.040 --> 00:30:15.880]   in his backyard. - Yeah.
[00:30:15.880 --> 00:30:17.120]   - He's like, "Put me in the game."
[00:30:17.120 --> 00:30:18.040]   - Well, we could do that.
[00:30:18.040 --> 00:30:21.040]   I mean, I've got like five half-written business blogs
[00:30:21.040 --> 00:30:23.040]   in my hopper that I really wanna finish.
[00:30:23.040 --> 00:30:25.360]   And so I don't know.
[00:30:25.360 --> 00:30:27.280]   - The show does take a lot of cognitive energy
[00:30:27.280 --> 00:30:28.120]   is what you're saying.
[00:30:28.120 --> 00:30:28.940]   It takes a lot of those cycles, right?
[00:30:28.940 --> 00:30:30.880]   - Does it take a lot of your time each week, Zacks?
[00:30:30.880 --> 00:30:32.160]   - I mean, as you guys know,
[00:30:32.160 --> 00:30:33.480]   the taping is only a couple hours,
[00:30:33.480 --> 00:30:35.960]   but then it's just keeping track of all the issues.
[00:30:35.960 --> 00:30:39.280]   And then, you know, if I'm preparing takes for this pod,
[00:30:39.280 --> 00:30:41.720]   I also turn some of those takes into articles.
[00:30:41.720 --> 00:30:43.320]   - This is the cost. - Like for Newsweek
[00:30:43.320 --> 00:30:44.960]   or the American Conservative or whatever.
[00:30:44.960 --> 00:30:45.800]   - And responding. - 'Cause I've been
[00:30:45.800 --> 00:30:46.620]   publishing a lot. - And responding.
[00:30:46.620 --> 00:30:47.460]   - And responding. - And responding.
[00:30:47.460 --> 00:30:50.520]   And then I have tweeting takes as I'm coming up with them.
[00:30:50.520 --> 00:30:51.360]   - Now it's three days. - This is my point,
[00:30:51.360 --> 00:30:54.640]   which is I think the load for Zacks,
[00:30:54.640 --> 00:30:58.480]   because he is the most heterodox, is the heaviest.
[00:30:58.480 --> 00:31:00.520]   And this is like poorly understood.
[00:31:00.520 --> 00:31:02.520]   It's easy to just basically be on the side
[00:31:02.520 --> 00:31:04.280]   of the current conventional wisdom,
[00:31:04.280 --> 00:31:05.560]   or to not have an opinion
[00:31:05.560 --> 00:31:07.400]   and to talk about things that are orthogonal.
[00:31:07.400 --> 00:31:09.140]   But David is consistently the one
[00:31:09.140 --> 00:31:10.760]   that wades into the middle of the ocean.
[00:31:10.760 --> 00:31:13.360]   And it is, I can understand why you find it exhausting.
[00:31:13.360 --> 00:31:14.480]   - There's an undertone there.
[00:31:14.480 --> 00:31:16.440]   - No, because he-- - He gets dragged under.
[00:31:16.440 --> 00:31:19.400]   - No, Jason, he has to be more prepared than the rest of us
[00:31:19.400 --> 00:31:21.280]   because he is more open to the attacks
[00:31:21.280 --> 00:31:23.120]   from all of these nitwits.
[00:31:23.120 --> 00:31:24.240]   (Jason laughs)
[00:31:24.240 --> 00:31:25.080]   - It's true. - He just is.
[00:31:25.080 --> 00:31:27.400]   - I mean, every day on Twitter,
[00:31:27.400 --> 00:31:29.780]   I'm being told I'm Neville Chamberlain or blah, blah, blah.
[00:31:29.780 --> 00:31:31.480]   - These are like uninformed nitwits.
[00:31:31.480 --> 00:31:35.560]   You know, the cancer of people who comment
[00:31:35.560 --> 00:31:37.340]   on Twitter is the following.
[00:31:37.340 --> 00:31:39.480]   They suffer from the worst kind of cancer,
[00:31:39.480 --> 00:31:41.800]   which is a lack of belief in themselves.
[00:31:41.800 --> 00:31:44.680]   And so what they do is they point to other people
[00:31:44.680 --> 00:31:47.600]   and try to convince yet more people to not believe in them.
[00:31:47.600 --> 00:31:48.960]   But that has nothing to do with anything.
[00:31:48.960 --> 00:31:51.240]   It's just misdirection from their core problem,
[00:31:51.240 --> 00:31:52.680]   which is they don't believe in themselves.
[00:31:52.680 --> 00:31:55.160]   And so, you know, David has to fight all of that stuff off,
[00:31:55.160 --> 00:31:56.620]   but he has to fight it off with logic,
[00:31:56.620 --> 00:31:58.160]   which must be exhausting.
[00:31:58.160 --> 00:32:00.260]   You know, my approach has just been to turn off comments
[00:32:00.260 --> 00:32:01.400]   and to not start.
[00:32:01.400 --> 00:32:03.320]   This is the single biggest problem, I think,
[00:32:03.320 --> 00:32:06.560]   with social media is it's at this heightened point
[00:32:06.560 --> 00:32:08.840]   where it's this virulent strain
[00:32:08.840 --> 00:32:10.560]   of a lack of belief in oneself
[00:32:10.560 --> 00:32:12.560]   that manifests in this hatred
[00:32:12.560 --> 00:32:14.680]   that you direct to anybody else that believes in themselves.
[00:32:14.680 --> 00:32:16.080]   - Interesting theory.
[00:32:16.080 --> 00:32:17.920]   - Yeah, and I would just add to that,
[00:32:17.920 --> 00:32:21.720]   you know, it's not like I haven't heard
[00:32:21.720 --> 00:32:24.200]   any of the arguments that they're making.
[00:32:24.200 --> 00:32:26.080]   I guarantee you they have not heard
[00:32:26.080 --> 00:32:27.320]   the arguments I'm making,
[00:32:27.320 --> 00:32:30.080]   but I've heard all the arguments they're making.
[00:32:30.080 --> 00:32:33.080]   I'm totally familiar with 1938, Munich, Neville Chamberlain,
[00:32:33.080 --> 00:32:34.080]   all this kind of stuff.
[00:32:34.080 --> 00:32:36.640]   I just don't think that is the correct understanding
[00:32:36.640 --> 00:32:37.520]   of what's happening right now.
[00:32:37.520 --> 00:32:39.400]   I think the correct historical analogy
[00:32:39.400 --> 00:32:43.080]   is either 1914 with World War I and the blank check guarantee
[00:32:43.080 --> 00:32:46.120]   or it's 1962, the Cuban Missile Crisis.
[00:32:46.120 --> 00:32:48.040]   The people on the other side
[00:32:48.040 --> 00:32:50.000]   generally don't understand that.
[00:32:50.000 --> 00:32:52.800]   They are just kind of part of this like Twitter mob
[00:32:52.800 --> 00:32:54.200]   who's buying into the current thing
[00:32:54.200 --> 00:32:56.160]   and whatever they're told by the media.
[00:32:56.160 --> 00:32:58.600]   So it is a little bit exhausting.
[00:32:58.600 --> 00:33:00.200]   - I think that that's what people don't realize
[00:33:00.200 --> 00:33:03.120]   is when this thing got very popular,
[00:33:03.120 --> 00:33:06.640]   the two or three days after an episode comes out
[00:33:06.640 --> 00:33:10.160]   becomes your texts, your email, your DMs,
[00:33:10.160 --> 00:33:13.560]   and your replies become filled, especially again.
[00:33:13.560 --> 00:33:15.280]   - I would encourage you to keep doing this thing
[00:33:15.280 --> 00:33:17.880]   and just to turn off comments and don't look back.
[00:33:17.880 --> 00:33:20.000]   It's hard for the first few weeks
[00:33:20.000 --> 00:33:22.880]   and then you realize 99% of people who comment
[00:33:22.880 --> 00:33:25.800]   have nothing important or useful or interesting to say,
[00:33:25.800 --> 00:33:28.040]   like zero, like negative zero.
[00:33:28.040 --> 00:33:32.120]   And you forget that there's like 99.999% of the world
[00:33:32.120 --> 00:33:33.840]   that just reads your content
[00:33:33.840 --> 00:33:37.080]   and couldn't even care about their comments.
[00:33:37.080 --> 00:33:37.920]   - Yeah, that's a good point.
[00:33:37.920 --> 00:33:40.720]   - And I would just, I would focus on what you have to say
[00:33:40.720 --> 00:33:42.600]   and ignore all these other.
[00:33:42.600 --> 00:33:43.440]   - Delete Twitter.
[00:33:43.440 --> 00:33:44.920]   - I agree that would make it less exhausting,
[00:33:44.920 --> 00:33:46.320]   but it would still be time consuming.
[00:33:46.320 --> 00:33:49.280]   There is a bunch of business blogs I want to get done, so.
[00:33:49.280 --> 00:33:50.680]   - I mean, I said, you take two weeks off,
[00:33:50.680 --> 00:33:52.000]   you come back and see how you feel.
[00:33:52.000 --> 00:33:53.920]   I mean, you can do it week by week too.
[00:33:53.920 --> 00:33:56.680]   I mean, just take one week off and see it.
[00:33:56.680 --> 00:33:57.520]   See how it feels, see if you catch up.
[00:33:57.520 --> 00:33:58.360]   - I think you'll miss it.
[00:33:58.360 --> 00:33:59.200]   - And then you'll be back.
[00:33:59.200 --> 00:34:00.040]   - Yeah, he'll be back.
[00:34:00.040 --> 00:34:01.880]   - Of course he'll be back.
[00:34:01.880 --> 00:34:04.040]   - Great, great question from Nathan.
[00:34:04.040 --> 00:34:06.840]   Thank you for your participation, Nathan.
[00:34:06.840 --> 00:34:08.440]   Next question, I actually like this one.
[00:34:08.440 --> 00:34:09.320]   I'm going to pull it out.
[00:34:09.320 --> 00:34:12.200]   It's an email question from Juan T.
[00:34:12.200 --> 00:34:13.320]   - Oh, hey, Juan T.
[00:34:13.320 --> 00:34:15.640]   - Juan said, "Bill Gurley recently put out a piece
[00:34:15.640 --> 00:34:18.240]   "explaining how this might be as good a time
[00:34:18.240 --> 00:34:20.320]   "as in a decade to build a company.
[00:34:20.320 --> 00:34:22.520]   "How are you guys seeing your own portfolio companies
[00:34:22.520 --> 00:34:24.480]   "trying to take advantage of the situation?"
[00:34:24.480 --> 00:34:25.880]   And I guess I'll add, do you guys agree?
[00:34:25.880 --> 00:34:28.360]   And how do you think about this as a moment
[00:34:28.360 --> 00:34:29.960]   for company building?
[00:34:29.960 --> 00:34:31.840]   - I could take that one.
[00:34:31.840 --> 00:34:33.880]   I am seeing a lot of the companies
[00:34:33.880 --> 00:34:37.520]   that had done a great job racing around,
[00:34:37.520 --> 00:34:40.120]   seed round, series A, never got product market fit,
[00:34:40.120 --> 00:34:41.720]   now wrap it up, right?
[00:34:41.720 --> 00:34:43.880]   They're shutting down, they're doing the wind down process.
[00:34:43.880 --> 00:34:47.880]   And then we're seeing lists of very talented people,
[00:34:47.880 --> 00:34:49.000]   and I've talked about this before on the show,
[00:34:49.000 --> 00:34:52.440]   the consolidation of talent behind the winning ideas,
[00:34:52.440 --> 00:34:55.000]   the experiments that actually worked,
[00:34:55.000 --> 00:34:56.680]   products that got some traction,
[00:34:56.680 --> 00:34:59.560]   are now having an easier time hiring talent.
[00:34:59.560 --> 00:35:01.760]   And so to Bill's point, he's got a lot more experience
[00:35:01.760 --> 00:35:03.840]   in this than the four of us put together,
[00:35:03.840 --> 00:35:04.680]   is absolutely right.
[00:35:04.680 --> 00:35:06.400]   When you build in this down market,
[00:35:06.400 --> 00:35:08.280]   yeah, it's harder to raise money, of course,
[00:35:08.280 --> 00:35:11.360]   but talent is what makes great products,
[00:35:11.360 --> 00:35:15.040]   and products that delight customers get the flywheel going.
[00:35:15.040 --> 00:35:18.080]   And if you survive through this, and you have that talent,
[00:35:18.080 --> 00:35:21.320]   you're not going to face 20 copycats,
[00:35:21.320 --> 00:35:24.560]   and there's not 50 new products coming out a day.
[00:35:24.560 --> 00:35:28.080]   People have more time to actually engage and try a product,
[00:35:28.080 --> 00:35:29.240]   which they've been burnt out on.
[00:35:29.240 --> 00:35:31.280]   And the peanut butter spreading,
[00:35:31.280 --> 00:35:33.440]   we have this thin layer of peanut butter talent,
[00:35:33.440 --> 00:35:35.240]   now it's getting consolidated in the winter.
[00:35:35.240 --> 00:35:39.840]   So absolutely a great time for five CEOs and founders,
[00:35:39.840 --> 00:35:42.200]   or 10 founders across five companies,
[00:35:42.200 --> 00:35:45.360]   to consolidate down to two, do those tuck in acquisitions,
[00:35:45.360 --> 00:35:47.720]   and get focused, and build really good teams,
[00:35:47.720 --> 00:35:49.200]   and cut the weakest people on the teams.
[00:35:49.200 --> 00:35:52.040]   There's a lot of weak talent that have been overpaid,
[00:35:52.040 --> 00:35:53.720]   and aren't actually contributing to these teams,
[00:35:53.720 --> 00:35:54.760]   and they need to get cut,
[00:35:54.760 --> 00:35:56.120]   and then you pull in the all stars.
[00:35:56.120 --> 00:35:58.960]   It's a fantastic time, he's 100% right.
[00:35:58.960 --> 00:36:02.000]   - All of the, if you look back in history since 2000,
[00:36:02.000 --> 00:36:04.040]   all of the best performing funds of all times,
[00:36:04.040 --> 00:36:05.640]   were the ones that were formed,
[00:36:05.640 --> 00:36:08.560]   right in the middle of the downturns, '03, '08, '09.
[00:36:08.560 --> 00:36:10.480]   These are the vintages that have always been the best.
[00:36:10.480 --> 00:36:12.600]   And what that means, it's a proxy for investing,
[00:36:12.600 --> 00:36:14.800]   which is, it's the hardest time right now.
[00:36:14.800 --> 00:36:17.360]   It's when you have the shakiest hand,
[00:36:17.360 --> 00:36:18.840]   when you're writing the check,
[00:36:18.840 --> 00:36:22.200]   but it'll probably be where all of the real money is made,
[00:36:22.200 --> 00:36:24.240]   or the real generational wealth,
[00:36:24.240 --> 00:36:27.280]   both for the entrepreneurs who have the courage to start,
[00:36:27.280 --> 00:36:29.680]   and the investors who have the courage to invest.
[00:36:29.680 --> 00:36:33.280]   There was a story that I heard in New York.
[00:36:33.280 --> 00:36:36.920]   I was talking to a really well-known hedge fund,
[00:36:36.920 --> 00:36:38.000]   or family office,
[00:36:38.000 --> 00:36:41.440]   and they were talking about how they were meeting
[00:36:41.440 --> 00:36:43.600]   with a CEO of a FinTech unicorn,
[00:36:43.600 --> 00:36:45.320]   very well-known FinTech unicorn.
[00:36:45.320 --> 00:36:48.760]   And they said they left the meeting, and they said,
[00:36:48.760 --> 00:36:53.520]   "This person had an unbelievable disrespect for money."
[00:36:53.520 --> 00:36:55.640]   And it was the most arrogant interaction
[00:36:55.640 --> 00:36:56.520]   that they had ever heard,
[00:36:56.520 --> 00:36:58.120]   and they said, "Under no circumstances
[00:36:58.120 --> 00:37:01.560]   would we invest in this guy and this company, at any price."
[00:37:01.560 --> 00:37:03.760]   And lo and behold, a year later,
[00:37:03.760 --> 00:37:05.600]   that company is now visibly going through
[00:37:05.600 --> 00:37:06.960]   a bunch of hiccups.
[00:37:06.960 --> 00:37:10.680]   And it just reminds me that, Jason,
[00:37:10.680 --> 00:37:14.400]   we've always had two problems when times are good.
[00:37:14.400 --> 00:37:16.680]   Problem number one is that there's never been
[00:37:16.680 --> 00:37:18.880]   a check and balance on that kind of behavior,
[00:37:18.880 --> 00:37:20.840]   a lack of respect for capital,
[00:37:20.840 --> 00:37:24.080]   and almost a disregard for business models,
[00:37:24.080 --> 00:37:25.560]   which is just inexcusable.
[00:37:25.560 --> 00:37:28.240]   And I think it's partly the fault
[00:37:28.240 --> 00:37:29.480]   of a very young entrepreneur,
[00:37:29.480 --> 00:37:31.160]   but it's also partly the fault of a board
[00:37:31.160 --> 00:37:32.600]   who doesn't know how to direct that person.
[00:37:32.600 --> 00:37:34.120]   - Enablement is real, yeah.
[00:37:34.120 --> 00:37:36.440]   - But then the second thing is we've always had
[00:37:36.440 --> 00:37:39.440]   this big tech put on the table,
[00:37:39.440 --> 00:37:43.280]   where every time you would try to really hone in
[00:37:43.280 --> 00:37:46.960]   on running a lean, highly efficient organization,
[00:37:46.960 --> 00:37:49.240]   the alternative would be to go work at Google,
[00:37:49.240 --> 00:37:51.280]   Facebook, Apple, Amazon, Microsoft,
[00:37:51.280 --> 00:37:54.440]   where the terms are just completely different
[00:37:54.440 --> 00:37:57.560]   to what the experience was at a startup.
[00:37:57.560 --> 00:38:00.560]   And the bigger the gap, the harder it was for you
[00:38:00.560 --> 00:38:02.240]   to be able to hire and retain good people
[00:38:02.240 --> 00:38:04.200]   without just copying them.
[00:38:04.200 --> 00:38:06.680]   And now that that's also coming off the table,
[00:38:06.680 --> 00:38:07.800]   that is a key moment.
[00:38:07.800 --> 00:38:10.000]   So Gurley is 100% right.
[00:38:10.000 --> 00:38:11.960]   There is no longer the big tech put.
[00:38:11.960 --> 00:38:14.080]   Those are the generals that are about to get shot
[00:38:14.080 --> 00:38:16.160]   over the next eight to 12 months, in my opinion,
[00:38:16.160 --> 00:38:17.320]   in the public markets,
[00:38:17.320 --> 00:38:20.760]   in terms of market cap and employment and perks.
[00:38:20.760 --> 00:38:24.960]   And then second is that these really thoughtful investors
[00:38:24.960 --> 00:38:27.400]   who felt pretty deeply disrespected
[00:38:27.400 --> 00:38:29.240]   will now be able to call the shots.
[00:38:29.240 --> 00:38:32.740]   And these founders will have to come back hat in hand
[00:38:32.740 --> 00:38:33.720]   and either apologize
[00:38:33.720 --> 00:38:36.080]   or just completely find a different religion.
[00:38:36.080 --> 00:38:36.960]   And I think in that,
[00:38:36.960 --> 00:38:39.520]   you'll have a lot of amazing opportunities
[00:38:39.520 --> 00:38:41.000]   to build companies.
[00:38:41.000 --> 00:38:41.820]   - I think it's well said.
[00:38:41.820 --> 00:38:43.400]   Sax, what are you saying?
[00:38:43.400 --> 00:38:44.280]   - Yeah, I think that's right.
[00:38:44.280 --> 00:38:46.400]   I mean, look, when times are as frothy as they were,
[00:38:46.400 --> 00:38:48.140]   a lot of bad ideas get funded
[00:38:48.140 --> 00:38:51.040]   and there's a lot of bad behavior that occurs.
[00:38:51.040 --> 00:38:52.520]   I don't think all of it's intentional.
[00:38:52.520 --> 00:38:54.600]   Some of it is just the lack of discipline
[00:38:54.600 --> 00:38:56.680]   that when capital is just so freely available,
[00:38:56.680 --> 00:38:58.720]   people are building their businesses
[00:38:58.720 --> 00:39:02.320]   in ways that we're optimizing solely for one variable,
[00:39:02.320 --> 00:39:03.720]   which was top line growth.
[00:39:03.720 --> 00:39:05.180]   They just weren't paying enough attention
[00:39:05.180 --> 00:39:08.040]   to gross margins or burn.
[00:39:08.040 --> 00:39:10.480]   And when you then have a downturn
[00:39:10.480 --> 00:39:11.680]   and capital is not so available,
[00:39:11.680 --> 00:39:12.680]   you have to build your business
[00:39:12.680 --> 00:39:14.480]   in a much more capital efficient way.
[00:39:14.480 --> 00:39:16.400]   And you can't create fake businesses
[00:39:16.400 --> 00:39:18.020]   where you're buying growth
[00:39:18.020 --> 00:39:20.640]   that's not economically justified,
[00:39:20.640 --> 00:39:23.200]   where you've got negative uniconomics around the growth.
[00:39:23.200 --> 00:39:25.640]   So I think that this downturn
[00:39:25.640 --> 00:39:27.600]   is going to create a shakeout.
[00:39:27.600 --> 00:39:31.920]   It's gonna weed out bad ideas, bad practices,
[00:39:31.920 --> 00:39:34.960]   and a lack of sort of focus. - Bad boards.
[00:39:34.960 --> 00:39:36.720]   - Bad boards and-
[00:39:36.720 --> 00:39:38.680]   - Or also bad investors. - And one trick ponies.
[00:39:38.680 --> 00:39:40.000]   - Or no boards.
[00:39:40.000 --> 00:39:41.160]   - Bad allocators.
[00:39:41.160 --> 00:39:42.400]   - One trick ponies.
[00:39:42.400 --> 00:39:44.100]   There's just a lot of one trick ponies out there
[00:39:44.100 --> 00:39:47.220]   who've optimized growth, but don't have a real business.
[00:39:47.220 --> 00:39:50.620]   And it's gonna require entrepreneurs
[00:39:50.620 --> 00:39:55.620]   to play sort of more like multivariable calculus or math,
[00:39:55.620 --> 00:39:57.260]   not just single variable.
[00:39:57.260 --> 00:40:00.680]   - It is extremely difficult to convert TVPI to DPI.
[00:40:00.680 --> 00:40:03.780]   You know, the value of paper values
[00:40:03.780 --> 00:40:06.760]   into actual distributions, and that takes a skilled hand.
[00:40:06.760 --> 00:40:11.860]   And I think that a lot of young folks
[00:40:11.860 --> 00:40:13.540]   were hired into venture
[00:40:13.540 --> 00:40:16.660]   that fundamentally did not know what they were doing.
[00:40:16.660 --> 00:40:18.160]   They've neither ever built a company
[00:40:18.160 --> 00:40:19.260]   or helped build a company,
[00:40:19.260 --> 00:40:22.380]   or actually learned how to generate returns.
[00:40:22.380 --> 00:40:24.440]   But they became very good
[00:40:24.440 --> 00:40:27.620]   at buying free call options on companies.
[00:40:27.620 --> 00:40:29.020]   You know, I remember like a lot of people,
[00:40:29.020 --> 00:40:30.700]   the way that you, these young people,
[00:40:30.700 --> 00:40:31.700]   I remember I heard a story
[00:40:31.700 --> 00:40:34.320]   that you would sell against Gurley, right?
[00:40:34.320 --> 00:40:35.700]   So let's just say you were trying to do a deal
[00:40:35.700 --> 00:40:38.500]   and Bill gives you a term sheet from Benchmark
[00:40:38.500 --> 00:40:40.140]   and you get somebody else.
[00:40:40.140 --> 00:40:40.980]   The young folks were like,
[00:40:40.980 --> 00:40:43.300]   "Oh, Bill's too negative and he doesn't get it."
[00:40:43.300 --> 00:40:45.420]   And they would try to convince these entrepreneurs
[00:40:45.420 --> 00:40:47.940]   that, you know, these rainy days don't happen.
[00:40:47.940 --> 00:40:48.980]   My experience with Gurley
[00:40:48.980 --> 00:40:53.180]   is he is the most sophisticated investor of our generation.
[00:40:53.180 --> 00:40:55.560]   And what I mean by that is, you know,
[00:40:55.560 --> 00:40:58.500]   he was trained as an equity analyst
[00:40:58.500 --> 00:41:02.560]   that really understood business models and cost of capital.
[00:41:02.560 --> 00:41:05.260]   And so in a moment like this,
[00:41:05.260 --> 00:41:07.080]   the way that Gurley would help you on a board
[00:41:07.080 --> 00:41:08.380]   is meaningfully more important
[00:41:08.380 --> 00:41:10.620]   than how some, you know, middling VP
[00:41:10.620 --> 00:41:14.580]   at some rando startup who's now a, you know,
[00:41:14.580 --> 00:41:16.180]   junior partner at a venture firm,
[00:41:16.180 --> 00:41:18.340]   because that person has literally no clue.
[00:41:18.340 --> 00:41:20.820]   And so these companies are gonna go through
[00:41:20.820 --> 00:41:22.500]   a very difficult moment,
[00:41:22.500 --> 00:41:26.460]   which again is the reason why a good steady hand
[00:41:26.460 --> 00:41:27.300]   who knows what they're doing
[00:41:27.300 --> 00:41:29.580]   will make a ton of money in this next cycle.
[00:41:29.580 --> 00:41:30.980]   - And for people who don't know TVP,
[00:41:30.980 --> 00:41:32.780]   let me just give you a quick definition.
[00:41:32.780 --> 00:41:35.280]   This is the total value divided by the paid-in capital.
[00:41:35.280 --> 00:41:37.960]   So total value is distributions,
[00:41:37.960 --> 00:41:39.780]   like, "Hey, here's your Robinhood stock,
[00:41:39.780 --> 00:41:41.780]   here's your Ubersock, here's cash,
[00:41:41.780 --> 00:41:42.940]   plus the net asset value."
[00:41:42.940 --> 00:41:46.300]   What's that fancy word for the value of the shares
[00:41:46.300 --> 00:41:48.460]   of the companies that haven't had an exit.
[00:41:48.460 --> 00:41:49.700]   And so you divide those two numbers,
[00:41:49.700 --> 00:41:52.580]   you get a ratio 1.5, 1.2, et cetera.
[00:41:52.580 --> 00:41:54.380]   But to Shmott's point,
[00:41:54.380 --> 00:41:57.220]   net asset value is debatable in some of these, right?
[00:41:57.220 --> 00:41:58.580]   And distributions are what matter.
[00:41:58.580 --> 00:42:01.640]   You can't eat the IRR.
[00:42:01.640 --> 00:42:03.940]   You gotta eat the stuff that's been distributed.
[00:42:03.940 --> 00:42:05.180]   - All right, let's keep going.
[00:42:05.180 --> 00:42:06.380]   I'll do one more.
[00:42:06.380 --> 00:42:08.180]   I'm gonna skip over.
[00:42:08.180 --> 00:42:10.900]   Well, I'll just, the question on Twitter
[00:42:10.900 --> 00:42:12.260]   that got the most votes was,
[00:42:12.260 --> 00:42:15.260]   "What's the exact net worth of each bestie?"
[00:42:15.260 --> 00:42:16.980]   I would make the case
[00:42:16.980 --> 00:42:20.260]   that that's probably not the best way to measure oneself.
[00:42:20.260 --> 00:42:22.860]   And I don't think we're gonna do it.
[00:42:22.860 --> 00:42:26.140]   I also would argue that we're probably all exposed
[00:42:26.140 --> 00:42:28.660]   to a lot of fuzzy math with private assets that we own
[00:42:28.660 --> 00:42:30.140]   and in terms of companies we're invested in.
[00:42:30.140 --> 00:42:30.980]   - Also, who cares?
[00:42:30.980 --> 00:42:33.100]   Like, how does that correlate with happiness in life?
[00:42:33.100 --> 00:42:33.940]   It doesn't.
[00:42:33.940 --> 00:42:34.760]   - Right, so it doesn't really-
[00:42:34.760 --> 00:42:35.600]   - Stupid question.
[00:42:35.600 --> 00:42:36.460]   - And I don't think it's a big focus
[00:42:36.460 --> 00:42:38.540]   in terms of objectives.
[00:42:38.540 --> 00:42:41.140]   I'll say the next one that got a lot of votes,
[00:42:41.140 --> 00:42:42.260]   which I really like.
[00:42:42.260 --> 00:42:45.060]   - It's a lagging indicator and a byproduct of what we do.
[00:42:45.060 --> 00:42:50.060]   There are moments when what we do reflects in value
[00:42:50.060 --> 00:42:52.500]   that frankly, where we are over-earning.
[00:42:52.500 --> 00:42:53.620]   And then there are periods
[00:42:53.620 --> 00:42:57.260]   where what we do is under-reflected and we are under-earning.
[00:42:57.260 --> 00:42:59.820]   And so the through line has to be
[00:42:59.820 --> 00:43:02.060]   that you need to survive in both good times and bad times,
[00:43:02.060 --> 00:43:04.540]   which means you gotta like what you're doing.
[00:43:04.540 --> 00:43:06.660]   And if you get caught up in a numerical number,
[00:43:06.660 --> 00:43:07.860]   there's all kinds of math you can do
[00:43:07.860 --> 00:43:09.780]   to make it look a lot bigger than it is,
[00:43:09.780 --> 00:43:10.820]   but it's all meaningless.
[00:43:10.820 --> 00:43:13.380]   - Yeah, I would argue as long as you're actively
[00:43:13.380 --> 00:43:15.740]   developing yourself over time,
[00:43:15.740 --> 00:43:17.980]   the weighing machine will do its job.
[00:43:17.980 --> 00:43:22.820]   - Somebody told me in my 20s when I was at AOL,
[00:43:22.820 --> 00:43:26.380]   he said, "If you're," because at the time,
[00:43:26.380 --> 00:43:29.540]   I grew up on welfare, I thought the goal was to make money.
[00:43:29.540 --> 00:43:30.940]   I didn't know any better.
[00:43:30.940 --> 00:43:34.740]   I've learned later that there's a lot more leading indicators
[00:43:34.740 --> 00:43:38.540]   of happiness and things that actually create happiness.
[00:43:38.540 --> 00:43:39.380]   - White truffles.
[00:43:39.380 --> 00:43:40.660]   - White truffles.
[00:43:40.660 --> 00:43:42.740]   - I was gonna say friendship, my family, but yeah.
[00:43:42.740 --> 00:43:43.580]   - Friendship and family.
[00:43:43.580 --> 00:43:46.020]   Laughs, I define it as laughs and friendships.
[00:43:46.020 --> 00:43:46.860]   - Friendships.
[00:43:46.860 --> 00:43:49.820]   - But he said to me, "Your goal should be
[00:43:49.820 --> 00:43:53.740]   to just be in the upper few percent of your age bracket
[00:43:53.740 --> 00:43:56.300]   and just enjoy what you're doing."
[00:43:56.300 --> 00:43:58.780]   And he said, "Let time take care of everything else."
[00:43:58.780 --> 00:44:02.620]   Because as long as you find something you decently enjoy
[00:44:02.620 --> 00:44:05.060]   and are good at, you'll just get better and better
[00:44:05.060 --> 00:44:06.240]   at that thing.
[00:44:06.240 --> 00:44:09.440]   And then at some point, you will lose track
[00:44:09.440 --> 00:44:12.340]   of what the measurement of that is
[00:44:12.340 --> 00:44:13.780]   because you're just too caught up
[00:44:13.780 --> 00:44:17.280]   in how much you enjoy doing the thing.
[00:44:17.280 --> 00:44:20.760]   And I thought that he had no idea what he was talking about.
[00:44:20.760 --> 00:44:24.660]   And now 25 years later, I can tell you he was totally right.
[00:44:24.660 --> 00:44:27.120]   Totally right.
[00:44:27.120 --> 00:44:28.180]   - Yeah.
[00:44:28.180 --> 00:44:31.020]   By the way, this was a question I was trying to skip over.
[00:44:31.020 --> 00:44:33.260]   - No, but it led to a good fork, yeah.
[00:44:33.260 --> 00:44:34.100]   - Okay.
[00:44:34.100 --> 00:44:34.920]   - What is happiness?
[00:44:34.920 --> 00:44:35.760]   - Yeah.
[00:44:35.760 --> 00:44:40.060]   - I think after observing outcomes for 25 years in tech,
[00:44:40.060 --> 00:44:43.640]   what I would say is that if you're smart, hardworking,
[00:44:43.640 --> 00:44:46.180]   don't have behaviors that sabotage yourself
[00:44:46.180 --> 00:44:48.100]   and take intelligent risks,
[00:44:48.100 --> 00:44:49.780]   you will be successful in this business.
[00:44:49.780 --> 00:44:53.240]   I mean, technology is such a wind at your backs.
[00:44:53.240 --> 00:44:54.780]   It's such an engine of wealth creation.
[00:44:54.780 --> 00:44:56.580]   How can you not do well?
[00:44:56.580 --> 00:44:58.940]   But the exact magnitude of how well you do,
[00:44:58.940 --> 00:44:59.860]   I think is ultimately,
[00:44:59.860 --> 00:45:02.340]   it is substantially affected by timing.
[00:45:02.340 --> 00:45:07.340]   And like if you were employee, whatever number X at Google,
[00:45:07.340 --> 00:45:10.220]   you're gonna do better than most founders,
[00:45:10.220 --> 00:45:11.540]   even of a unicorn company.
[00:45:11.540 --> 00:45:13.340]   And when you found your company
[00:45:13.340 --> 00:45:16.180]   and then when you exit what the market is doing,
[00:45:16.180 --> 00:45:20.080]   those things have a huge impact on the magnitude.
[00:45:20.080 --> 00:45:23.660]   So whether you end up being a billionaire,
[00:45:23.660 --> 00:45:25.840]   a centimillionaire, a decamillionaire,
[00:45:25.840 --> 00:45:26.680]   whatever you want to,
[00:45:26.680 --> 00:45:29.420]   those things are very affected by timing and chance,
[00:45:29.420 --> 00:45:32.860]   but not whether you're gonna be successful
[00:45:32.860 --> 00:45:35.020]   at a substantial level.
[00:45:35.020 --> 00:45:38.180]   And so just be smart, be hardworking,
[00:45:38.180 --> 00:45:42.500]   don't sabotage yourself, get into tech and you will do well.
[00:45:42.500 --> 00:45:43.700]   - Trust the process.
[00:45:43.700 --> 00:45:44.540]   Trust the process.
[00:45:44.540 --> 00:45:45.500]   - The exact amount of how well you do
[00:45:45.500 --> 00:45:49.140]   will be dependent on some stochastic factors,
[00:45:49.140 --> 00:45:50.700]   but not the fact that you're gonna do well.
[00:45:50.700 --> 00:45:54.580]   - We are enormous beneficiaries of having been born
[00:45:54.580 --> 00:45:57.880]   when we were, because we were a bunch of late 40
[00:45:57.880 --> 00:46:02.480]   and early 50 somethings that in the prime of our career
[00:46:02.480 --> 00:46:06.620]   in tech, the Federal Reserve took rates to zero.
[00:46:06.620 --> 00:46:11.200]   And we had no idea a priori how important that would be
[00:46:11.200 --> 00:46:13.520]   in all of our outcomes, but they were.
[00:46:13.520 --> 00:46:15.320]   - And even more importantly,
[00:46:15.320 --> 00:46:17.280]   PCs, internet and mobile happened.
[00:46:17.280 --> 00:46:20.160]   - All of that hard work was done beforehand
[00:46:20.160 --> 00:46:22.160]   by an entire court of people that had to fight
[00:46:22.160 --> 00:46:24.720]   much stronger headwinds than we had to fight.
[00:46:24.720 --> 00:46:26.520]   So, David, I just wanna build on that.
[00:46:26.520 --> 00:46:28.880]   We were extraordinarily lucky.
[00:46:28.880 --> 00:46:31.800]   And so don't get caught up in that
[00:46:31.800 --> 00:46:34.700]   because there's all these factors you cannot control.
[00:46:34.700 --> 00:46:35.540]   - I'll say one more thing
[00:46:35.540 --> 00:46:39.120]   that I think is the most important observation I've made
[00:46:39.120 --> 00:46:43.680]   in terms of whatever it is, building wealth over time
[00:46:43.680 --> 00:46:47.920]   is to make sure you're building equity in yourself.
[00:46:47.920 --> 00:46:51.120]   If you're in a services business and every day,
[00:46:51.120 --> 00:46:52.880]   and whether that's serving the clients
[00:46:52.880 --> 00:46:54.200]   of the company you work for,
[00:46:54.200 --> 00:46:57.140]   or just serving clients on behalf of yourself,
[00:46:57.140 --> 00:46:59.520]   and everything you do is a transaction,
[00:46:59.520 --> 00:47:01.920]   and that transaction doesn't build on itself,
[00:47:01.920 --> 00:47:04.600]   doesn't compound value in some way,
[00:47:04.600 --> 00:47:06.300]   then you're missing out on an opportunity.
[00:47:06.300 --> 00:47:09.120]   Every year that goes by that you're earning income
[00:47:09.120 --> 00:47:13.640]   or you're not building equity is a non-compounding year.
[00:47:13.640 --> 00:47:16.680]   And it's compounding equity value
[00:47:16.680 --> 00:47:19.480]   that I think ultimately pays off for you as an individual.
[00:47:19.480 --> 00:47:21.120]   And I can give a lot of examples of this,
[00:47:21.120 --> 00:47:24.820]   but if you're in a, let's say a brokerage business,
[00:47:24.820 --> 00:47:26.600]   and you just do deals,
[00:47:26.600 --> 00:47:28.760]   and you might have a good year, you might have a bad year.
[00:47:28.760 --> 00:47:31.080]   The real question you need to ask yourself is,
[00:47:31.080 --> 00:47:32.120]   what is compounding?
[00:47:32.120 --> 00:47:34.040]   Are you growing a client base?
[00:47:34.040 --> 00:47:35.640]   Are you growing your skillset?
[00:47:35.640 --> 00:47:38.400]   Are you next year able to do more things
[00:47:38.400 --> 00:47:40.440]   or have more options than you had this year?
[00:47:40.440 --> 00:47:41.840]   And if the number of options you have
[00:47:41.840 --> 00:47:44.040]   is declining or static every year,
[00:47:44.040 --> 00:47:45.480]   then you're limiting your equity value,
[00:47:45.480 --> 00:47:46.680]   and that ultimately will translate
[00:47:46.680 --> 00:47:48.040]   into limited wealth creation.
[00:47:48.040 --> 00:47:49.800]   - Can I chime in on that point around equity?
[00:47:49.800 --> 00:47:52.760]   So when I discovered what equity was,
[00:47:52.760 --> 00:47:54.140]   this was when I was in law school,
[00:47:54.140 --> 00:47:55.380]   and actually the guy who explained it to me
[00:47:55.380 --> 00:47:58.760]   was Antonio Gracias, a light bulb really went off for me
[00:47:58.760 --> 00:48:00.840]   because my dad is a doctor,
[00:48:00.840 --> 00:48:03.520]   and I was on a path to becoming a lawyer.
[00:48:03.520 --> 00:48:05.560]   And in both those cases, you're a professional,
[00:48:05.560 --> 00:48:08.160]   the way you get paid is you more or less
[00:48:08.160 --> 00:48:09.920]   charge an hourly rate.
[00:48:09.920 --> 00:48:13.160]   And so the amount of money you can make is capped, right?
[00:48:13.160 --> 00:48:15.440]   Just take the number of hours in the day and in the week,
[00:48:15.440 --> 00:48:17.240]   multiply it by your rate,
[00:48:17.240 --> 00:48:19.400]   and that's the most money you can make in a year.
[00:48:19.400 --> 00:48:23.040]   And the difference between that and equity
[00:48:23.040 --> 00:48:27.200]   is with equity, you own a piece of a business,
[00:48:27.200 --> 00:48:31.360]   and that business could be ultimately worth any amount,
[00:48:31.360 --> 00:48:33.880]   and so your equity could therefore be worth
[00:48:33.880 --> 00:48:36.840]   virtually any amount, and so you're uncapped.
[00:48:36.840 --> 00:48:39.920]   And so just, if you wanna have outside success,
[00:48:39.920 --> 00:48:42.360]   you have to have equity in something.
[00:48:42.360 --> 00:48:43.680]   I think that is exactly right.
[00:48:43.680 --> 00:48:48.080]   If you're just basically working for wages,
[00:48:48.080 --> 00:48:50.120]   even if you are the best at what you do
[00:48:50.120 --> 00:48:53.000]   and you get paid an insane hourly rate,
[00:48:53.000 --> 00:48:54.520]   again, you can be successful,
[00:48:54.520 --> 00:48:56.640]   but you're not gonna be uncapped.
[00:48:56.640 --> 00:48:59.200]   And so that's the beauty of Silicon Valley
[00:48:59.200 --> 00:49:01.840]   is all these companies offer equity to everybody.
[00:49:01.840 --> 00:49:04.200]   - And it's not just shares in something.
[00:49:04.200 --> 00:49:07.320]   You can actually get equity and create leverage in your life
[00:49:07.320 --> 00:49:10.160]   in this era more than any human has ever had
[00:49:10.160 --> 00:49:13.400]   in any era prior because of software
[00:49:13.400 --> 00:49:15.160]   and computing and automation.
[00:49:15.160 --> 00:49:17.960]   You can create a website that prints cash for you every day
[00:49:17.960 --> 00:49:19.040]   if you wanted to.
[00:49:19.040 --> 00:49:21.440]   You can create a service that you get leverage out of,
[00:49:21.440 --> 00:49:23.200]   and there's equity value in that.
[00:49:23.200 --> 00:49:24.480]   And I think that's really key
[00:49:24.480 --> 00:49:26.080]   because then you can go build another one, another one,
[00:49:26.080 --> 00:49:28.440]   and you're building value over time.
[00:49:28.440 --> 00:49:31.120]   And that's just the most simplistic example
[00:49:31.120 --> 00:49:33.640]   of how technology today provides leverage
[00:49:33.640 --> 00:49:36.920]   that can really allow anyone to pursue a path of equity.
[00:49:36.920 --> 00:49:39.120]   - And I think you made a good point about
[00:49:39.120 --> 00:49:41.520]   what are you getting leverage off of?
[00:49:41.520 --> 00:49:42.360]   - Yeah.
[00:49:42.360 --> 00:49:43.200]   - There's a bunch of different things
[00:49:43.200 --> 00:49:44.040]   you can get leverage off of.
[00:49:44.040 --> 00:49:44.880]   - It used to be labor, right?
[00:49:44.880 --> 00:49:45.960]   It's not anymore.
[00:49:45.960 --> 00:49:47.920]   - So the old way was leverage off labor.
[00:49:47.920 --> 00:49:50.920]   And I guess if you were to own like a consulting firm
[00:49:50.920 --> 00:49:52.840]   or like some sort of factory,
[00:49:52.840 --> 00:49:54.960]   then the more people you have working,
[00:49:54.960 --> 00:49:56.960]   the more money you'd make.
[00:49:56.960 --> 00:49:58.200]   The other way would be like,
[00:49:58.200 --> 00:50:01.480]   you can get leverage off capital, like a fund manager,
[00:50:01.480 --> 00:50:03.640]   or you can get leverage off of technology
[00:50:03.640 --> 00:50:05.040]   'cause software can basically create
[00:50:05.040 --> 00:50:06.480]   these super scaled outcomes.
[00:50:06.480 --> 00:50:07.480]   So you need to figure out like
[00:50:07.480 --> 00:50:09.480]   what is it you're getting leverage off of?
[00:50:09.480 --> 00:50:10.320]   - Yeah.
[00:50:10.320 --> 00:50:11.160]   So I'll do the last one,
[00:50:11.160 --> 00:50:13.000]   which I thought was a really good question.
[00:50:13.000 --> 00:50:16.960]   And it got a lot of votes from Marcos Ortiz.
[00:50:16.960 --> 00:50:19.840]   If you had to start from scratch, no money, no connections,
[00:50:19.840 --> 00:50:23.040]   only the knowledge you have right now and 100 bucks,
[00:50:23.040 --> 00:50:24.840]   what would you build in 2022?
[00:50:24.840 --> 00:50:29.080]   - I would build something in energy transition
[00:50:29.080 --> 00:50:30.520]   or in life sciences.
[00:50:30.520 --> 00:50:31.360]   - With $100?
[00:50:31.360 --> 00:50:34.720]   - Yeah.
[00:50:34.720 --> 00:50:38.240]   - I would build a startup incubator,
[00:50:38.240 --> 00:50:39.720]   venture fund of some type.
[00:50:40.880 --> 00:50:42.640]   A way to fund entrepreneurs
[00:50:42.640 --> 00:50:45.600]   and just be a capital allocator much earlier in my career.
[00:50:45.600 --> 00:50:51.120]   - I would create a B2B software company that,
[00:50:51.120 --> 00:50:52.720]   actually I'm already creating it.
[00:50:52.720 --> 00:50:54.080]   So I haven't unveiled it yet,
[00:50:54.080 --> 00:50:55.840]   but there's something I'm incubating right now.
[00:50:55.840 --> 00:50:56.800]   - Go David, go.
[00:50:56.800 --> 00:50:58.480]   - Whoa, whoa, whoa, where's the bet week?
[00:50:58.480 --> 00:50:59.560]   Wait, whoa, whoa, wait.
[00:50:59.560 --> 00:51:00.720]   - Wet my beak. - You wet your beak.
[00:51:00.720 --> 00:51:02.960]   What is going on here, Sax?
[00:51:02.960 --> 00:51:04.160]   - I haven't gotten the subscription documents.
[00:51:04.160 --> 00:51:05.360]   - Have you raised money for it?
[00:51:05.360 --> 00:51:06.560]   - No, I have not raised money yet.
[00:51:06.560 --> 00:51:07.400]   When I raise money, you guys can invest.
[00:51:07.400 --> 00:51:09.440]   - I have not gotten my subscription documents, sir.
[00:51:09.440 --> 00:51:11.960]   - You can think of this idea as Yammer 2.0.
[00:51:11.960 --> 00:51:14.400]   So J. Cal, you're not in because you criticize Yammer, but.
[00:51:14.400 --> 00:51:16.160]   - It was a joke, I gave you the,
[00:51:16.160 --> 00:51:17.800]   I let you win TechCrunch 50.
[00:51:17.800 --> 00:51:19.400]   I put the fucking fix in for you.
[00:51:19.400 --> 00:51:20.880]   - David, just to put my pitch in,
[00:51:20.880 --> 00:51:24.200]   I ran AIM and ICQ, helped Facebook,
[00:51:24.200 --> 00:51:25.480]   was an investor in Yammer,
[00:51:25.480 --> 00:51:27.120]   was the Series A investor in Slack.
[00:51:27.120 --> 00:51:28.320]   So I'm ready for you.
[00:51:28.320 --> 00:51:31.280]   - Yeah, you were there for us when we needed you
[00:51:31.280 --> 00:51:33.400]   back at Yammer days, unlike J. Cal.
[00:51:33.400 --> 00:51:34.440]   - What are you talking about?
[00:51:34.440 --> 00:51:36.520]   Your wife came to my line and they were like,
[00:51:36.520 --> 00:51:39.360]   "Sax has to win TechCrunch 50."
[00:51:39.360 --> 00:51:40.200]   - Don't worry, you're all in.
[00:51:40.200 --> 00:51:41.040]   - Let me in, Sax, let me in, let me in.
[00:51:41.040 --> 00:51:42.720]   - When I do the round, you guys are in.
[00:51:42.720 --> 00:51:43.560]   - Let me in, let me in.
[00:51:43.560 --> 00:51:44.400]   Let me lead it.
[00:51:44.400 --> 00:51:46.960]   - Let us do the pre-round round.
[00:51:46.960 --> 00:51:48.520]   We want to do the pre-round round.
[00:51:48.520 --> 00:51:51.360]   - Pre-round, pre-round, pre-round.
[00:51:51.360 --> 00:51:52.200]   - Thank you.
[00:51:52.200 --> 00:51:54.280]   - Did you just agree on TV?
[00:51:54.280 --> 00:51:55.320]   - Well, assuming, hold on,
[00:51:55.320 --> 00:51:56.320]   there's one thing you have to do,
[00:51:56.320 --> 00:51:58.880]   which is you've got to rip out Slack and use this instead.
[00:51:58.880 --> 00:52:00.560]   - Yes, 100%, 100%.
[00:52:00.560 --> 00:52:02.400]   I will start the all-in community.
[00:52:02.400 --> 00:52:04.280]   - I'm going to be very honest with you.
[00:52:04.280 --> 00:52:07.200]   The day I left Facebook, I stopped using it.
[00:52:07.200 --> 00:52:10.520]   The day we sold, we distributed Slack, stopped using it.
[00:52:10.520 --> 00:52:11.480]   So don't worry about me.
[00:52:11.480 --> 00:52:13.680]   I am 100% aligned with you.
[00:52:13.680 --> 00:52:15.520]   - I'm all in, I'm all in, absolutely.
[00:52:15.520 --> 00:52:16.640]   All right, let's do the show.
[00:52:16.640 --> 00:52:18.320]   - Let's do the show.
[00:52:18.320 --> 00:52:19.680]   - Freeberg, you didn't answer that question.
[00:52:19.680 --> 00:52:20.520]   What would you do?
[00:52:20.520 --> 00:52:23.320]   - Well, actually, I would get some water vaporizers
[00:52:23.320 --> 00:52:25.480]   and then I would get some molecules
[00:52:25.480 --> 00:52:27.880]   and I would make a new super protein
[00:52:27.880 --> 00:52:30.440]   that was made out of, God, sorry.
[00:52:30.440 --> 00:52:32.640]   - No, no, keep going, I like it.
[00:52:32.640 --> 00:52:34.720]   - I think it'd be something with the protein slurry.
[00:52:34.720 --> 00:52:35.880]   You'd make some kind of steak
[00:52:36.040 --> 00:52:38.600]   that tastes better than steak. - Protein slurry.
[00:52:38.600 --> 00:52:39.440]   - Some sort of protein.
[00:52:39.440 --> 00:52:41.640]   - I would definitely build a business again.
[00:52:41.640 --> 00:52:44.440]   I think the challenge is,
[00:52:44.440 --> 00:52:48.680]   as you move past that stage in your career
[00:52:48.680 --> 00:52:51.080]   where you have the willingness and the time
[00:52:51.080 --> 00:52:56.080]   to be 120% building one product every day,
[00:52:56.080 --> 00:52:59.080]   it's really hard to go back to that.
[00:52:59.080 --> 00:53:00.600]   And I think if I was in a position again
[00:53:00.600 --> 00:53:04.040]   where I had no money and had no connections.
[00:53:04.040 --> 00:53:05.600]   - I think that's the key part of the question,
[00:53:05.600 --> 00:53:07.200]   not the $100 part.
[00:53:07.200 --> 00:53:09.680]   - Yeah, I think I would go back to building something.
[00:53:09.680 --> 00:53:13.080]   I do think the intersection of life sciences with software
[00:53:13.080 --> 00:53:15.920]   creates this era of opportunity.
[00:53:15.920 --> 00:53:17.760]   It would probably be something in the realm
[00:53:17.760 --> 00:53:21.400]   of AI/ML meets life sciences
[00:53:21.400 --> 00:53:24.480]   where you can actually work in a leveraged way with software
[00:53:24.480 --> 00:53:26.920]   to drive outcomes in these important markets.
[00:53:26.920 --> 00:53:30.160]   - I would actually create a robotic cat.
[00:53:30.160 --> 00:53:31.800]   - Friedberg and I could have been co-founders.
[00:53:31.800 --> 00:53:33.640]   - We could have started something.
[00:53:33.640 --> 00:53:35.040]   - Maybe we can still.
[00:53:35.040 --> 00:53:37.120]   - Oh, here we go. - Not too late.
[00:53:37.120 --> 00:53:38.120]   - The co-founders.
[00:53:38.120 --> 00:53:39.560]   - Sax, we'll let you in the pre-round
[00:53:39.560 --> 00:53:41.600]   if you let us in your pre-round.
[00:53:41.600 --> 00:53:42.680]   - Okay, sounds good.
[00:53:42.680 --> 00:53:44.800]   - All right, Jake, you wanna take us forward?
[00:53:44.800 --> 00:53:45.640]   - Should we go forward?
[00:53:45.640 --> 00:53:47.400]   Okay, let's see what's on the docket.
[00:53:47.400 --> 00:53:53.280]   We've got Russia's invasion of Ukraine.
[00:53:53.280 --> 00:53:56.000]   - You had Biden last week saying
[00:53:56.000 --> 00:53:57.360]   we're facing the risk of Armageddon.
[00:53:57.360 --> 00:53:59.080]   How is that not the top story?
[00:53:59.080 --> 00:54:00.920]   - Go, Saxy Poot, go take it.
[00:54:00.920 --> 00:54:01.800]   - All right, here we go.
[00:54:01.800 --> 00:54:03.480]   Let me just queue it up for Sax.
[00:54:03.480 --> 00:54:05.400]   Biden last week said we're facing risk of Armageddon.
[00:54:05.400 --> 00:54:06.600]   That's your tee up.
[00:54:06.600 --> 00:54:07.440]   - Okay, here we go.
[00:54:07.440 --> 00:54:10.480]   - And then Leon Panetta, just let's tee it up, J.Cow.
[00:54:10.480 --> 00:54:12.200]   We don't need, everyone knows what's going on.
[00:54:12.200 --> 00:54:15.320]   Then you had Leon Panetta, who was the former
[00:54:15.320 --> 00:54:17.880]   Secretary of Defense and Director of Central Intelligence
[00:54:17.880 --> 00:54:21.640]   wrote an op-ed for Politico saying that
[00:54:21.640 --> 00:54:26.400]   intelligence analysts have now raised the probability
[00:54:26.400 --> 00:54:28.840]   of a use of a tactical nuclear weapon in Ukraine
[00:54:28.840 --> 00:54:31.840]   from one to 5% at the beginning of the war
[00:54:31.840 --> 00:54:35.520]   to 20 to 25% now is what he says.
[00:54:35.520 --> 00:54:38.200]   So, and I don't think he'd be saying that
[00:54:38.200 --> 00:54:40.320]   if this wasn't pretty much conventional wisdom
[00:54:40.320 --> 00:54:41.160]   in Washington now.
[00:54:41.160 --> 00:54:45.560]   I mean, Panetta is sort of a very respectable figure
[00:54:45.560 --> 00:54:46.920]   in the Beltway.
[00:54:46.920 --> 00:54:47.880]   - And Biden said it, right?
[00:54:47.880 --> 00:54:48.720]   For the first time two weeks ago.
[00:54:48.720 --> 00:54:49.920]   - And Biden said that we're facing
[00:54:49.920 --> 00:54:53.160]   the most dangerous situation and the highest risk
[00:54:53.160 --> 00:54:55.360]   of nuclear war since the Cuban Missile Crisis.
[00:54:55.360 --> 00:54:57.480]   He called it the risk of Armageddon.
[00:54:57.480 --> 00:55:01.800]   The problem is that nobody is willing to say
[00:55:01.800 --> 00:55:05.400]   what we should be doing differently to avoid this situation.
[00:55:05.400 --> 00:55:07.200]   So, people are always attacking us
[00:55:07.200 --> 00:55:09.200]   for having a point of view on foreign policy.
[00:55:09.200 --> 00:55:10.400]   First of all, this affects us.
[00:55:10.400 --> 00:55:12.640]   I don't know why we're not allowed to have a point of view,
[00:55:12.640 --> 00:55:14.600]   but in our business thinking,
[00:55:14.600 --> 00:55:16.840]   where there's an existential issue,
[00:55:16.840 --> 00:55:19.040]   you have the attitude of drop everything
[00:55:19.040 --> 00:55:20.160]   and figure this out.
[00:55:20.160 --> 00:55:22.960]   If somebody told you that there's a 25% chance
[00:55:22.960 --> 00:55:26.160]   of your company blowing up, maybe in the next few weeks,
[00:55:26.160 --> 00:55:28.720]   you would drop everything and focus on that problem.
[00:55:28.720 --> 00:55:31.160]   But it's like, after the Armageddon comments,
[00:55:31.160 --> 00:55:33.600]   it's like the media just passed over it.
[00:55:33.600 --> 00:55:36.400]   It's like, oh, this is like crazy Biden or whatever.
[00:55:36.400 --> 00:55:37.240]   It was minimized.
[00:55:37.240 --> 00:55:38.800]   It was contextualized.
[00:55:38.800 --> 00:55:40.520]   The White House walked it back.
[00:55:40.520 --> 00:55:42.120]   Nobody's really focusing on this
[00:55:42.120 --> 00:55:43.240]   and what we should be doing differently.
[00:55:43.240 --> 00:55:45.320]   And in fact, what Panetta recommends
[00:55:45.320 --> 00:55:47.360]   and Petraeus said the same thing,
[00:55:47.360 --> 00:55:50.760]   is that if Russia uses attack nuke in Ukraine,
[00:55:50.760 --> 00:55:54.760]   then we should respond by attacking Russia directly.
[00:55:54.760 --> 00:55:57.840]   Now, if we do that, we are literally in World War III.
[00:55:57.840 --> 00:55:59.280]   And remember, at the beginning of the war,
[00:55:59.280 --> 00:56:01.600]   Biden was really clear that we weren't gonna
[00:56:01.600 --> 00:56:02.800]   get directly involved.
[00:56:02.800 --> 00:56:06.560]   He vetoed the idea correctly of the no-fly zone,
[00:56:06.560 --> 00:56:09.360]   which would have required us to shoot down Russian planes.
[00:56:09.360 --> 00:56:11.400]   Biden, remember he was asked in the press conference
[00:56:11.400 --> 00:56:12.720]   at the beginning of the war by Lester Holt.
[00:56:12.720 --> 00:56:14.960]   He said, Holt said, "Mr. President,
[00:56:14.960 --> 00:56:17.920]   "what if Americans are trapped behind enemy lines in Ukraine?
[00:56:17.920 --> 00:56:20.440]   "Would you send in American troops to go get them?"
[00:56:20.440 --> 00:56:21.880]   Biden said, "No."
[00:56:21.880 --> 00:56:24.520]   I think very properly said no, because he said,
[00:56:24.520 --> 00:56:26.920]   "Listen, we do not wanna risk World War III."
[00:56:26.960 --> 00:56:30.360]   But now, because of mission creep and a slippery slope,
[00:56:30.360 --> 00:56:32.240]   and we've all gotten more involved in this war,
[00:56:32.240 --> 00:56:33.760]   we've gotten more emotionally committed,
[00:56:33.760 --> 00:56:36.560]   you now have Panetta and Petraeus calling for us
[00:56:36.560 --> 00:56:40.320]   to directly attack Russia and get in World War III.
[00:56:40.320 --> 00:56:43.200]   The Russians almost certainly would respond with nuclear
[00:56:43.200 --> 00:56:44.160]   because that's all they've got.
[00:56:44.160 --> 00:56:47.160]   They don't have the conventional forces to stand up to us.
[00:56:47.160 --> 00:56:50.120]   So look at how close we have now gotten
[00:56:50.120 --> 00:56:52.280]   to the brink of a nuclear showdown.
[00:56:52.280 --> 00:56:54.400]   And has anybody reassessed?
[00:56:54.400 --> 00:56:56.560]   Is anyone calling for us to reevaluate?
[00:56:56.560 --> 00:56:57.720]   Because that's the conversation
[00:56:57.720 --> 00:56:58.880]   we should be having right now.
[00:56:58.880 --> 00:57:01.400]   - And, Freeberg, this brings up two points
[00:57:01.400 --> 00:57:03.840]   that I think you can comment on.
[00:57:03.840 --> 00:57:08.160]   Naval, actually the founder of AngelList, Angel Investor,
[00:57:08.160 --> 00:57:12.000]   and just public thinker, I would say public intellectual.
[00:57:12.000 --> 00:57:14.480]   He came on to call in with the two of you,
[00:57:14.480 --> 00:57:18.200]   and he outlined who does get to have an opinion
[00:57:18.200 --> 00:57:21.160]   on Ukraine and other issues, which has dovetailed
[00:57:21.160 --> 00:57:25.560]   with this, who gets to be an expert in the world today?
[00:57:25.560 --> 00:57:27.280]   And of course, at the same time,
[00:57:27.280 --> 00:57:28.840]   not only Sachs has been commenting on,
[00:57:28.840 --> 00:57:30.320]   "Hey, what's the off ramp here?"
[00:57:30.320 --> 00:57:33.280]   Elon has been talking about, "Hey, how do we get out of this?
[00:57:33.280 --> 00:57:37.720]   Do we have some votes by these regions
[00:57:37.720 --> 00:57:40.640]   that have been annexed or that are in dispute?"
[00:57:40.640 --> 00:57:42.440]   AOC now is getting criticized on,
[00:57:42.440 --> 00:57:45.160]   and people shouting her down at a public event today
[00:57:45.160 --> 00:57:47.440]   or yesterday, that she's a warmonger
[00:57:47.440 --> 00:57:49.520]   and she won't speak out against war.
[00:57:49.520 --> 00:57:53.320]   How do you frame the public dialogue about this, Freeberg?
[00:57:53.320 --> 00:57:55.320]   And then do you see a potential off ramp here
[00:57:55.320 --> 00:57:57.400]   other than Putin leaves Russia,
[00:57:57.400 --> 00:58:01.080]   which is, I think, the public stance by a lot of folks.
[00:58:01.080 --> 00:58:03.360]   Putin can end this, he just has to leave Ukraine
[00:58:03.360 --> 00:58:05.160]   in order for this to end.
[00:58:05.160 --> 00:58:06.680]   So two questions there for you, Freeberg.
[00:58:06.680 --> 00:58:11.680]   - It's very hard to have good dialogue
[00:58:11.680 --> 00:58:17.480]   about any situation where an argument could be made
[00:58:17.480 --> 00:58:22.320]   on the grounds of morality in an absolute sense,
[00:58:22.320 --> 00:58:25.360]   making it really difficult to have a discourse
[00:58:25.360 --> 00:58:27.400]   around what the right thing to do is,
[00:58:27.400 --> 00:58:29.680]   because you don't agree fundamentally
[00:58:29.680 --> 00:58:31.880]   on the objective you're shooting for.
[00:58:31.880 --> 00:58:35.640]   One side says the objective is to preserve
[00:58:35.640 --> 00:58:40.640]   the integrity of democracy and the freedom of people.
[00:58:40.640 --> 00:58:43.920]   And the other side says the objective should be
[00:58:43.920 --> 00:58:47.840]   to secure the interests of the West and the United States
[00:58:47.840 --> 00:58:51.360]   and preserve the world from nuclear holocaust.
[00:58:51.360 --> 00:58:55.000]   I think that's what makes this a challenging conversation.
[00:58:55.000 --> 00:58:58.320]   The objective can be reframed,
[00:58:58.320 --> 00:59:00.080]   and then from that objective,
[00:59:00.080 --> 00:59:02.120]   each side can make their own case
[00:59:02.120 --> 00:59:05.320]   without being forced to take in the point of view
[00:59:05.320 --> 00:59:06.800]   of the other side.
[00:59:06.800 --> 00:59:09.080]   And it's why we're at a bit of a standstill,
[00:59:09.080 --> 00:59:12.240]   and it's also why it's so easy to get swept up
[00:59:12.240 --> 00:59:16.240]   in a mass point of view, a coalesce point of view
[00:59:16.240 --> 00:59:20.080]   of the masses that makes one feel good
[00:59:20.080 --> 00:59:23.120]   about what may end up being a very bad situation.
[00:59:23.120 --> 00:59:24.280]   It feels good to say,
[00:59:24.280 --> 00:59:26.240]   I'm doing this for freedom of the people.
[00:59:26.240 --> 00:59:28.560]   I'm doing this to save lives.
[00:59:28.560 --> 00:59:33.160]   And the end of the day, it may cause a nuclear war.
[00:59:33.160 --> 00:59:37.000]   And it's okay, because I feel good going into this debate,
[00:59:37.000 --> 00:59:38.120]   that this is the right thing.
[00:59:38.120 --> 00:59:41.640]   It's the morally superior thing to do.
[00:59:41.640 --> 00:59:44.400]   What's very hard is that we can't actually say,
[00:59:44.400 --> 00:59:48.520]   as a group, our objective should be to preserve
[00:59:48.520 --> 00:59:52.400]   the integrity of democracies around the world to an extent.
[00:59:52.400 --> 00:59:54.760]   And that's a nuanced point of view.
[00:59:54.760 --> 00:59:58.280]   To an extent means I'm willing to preserve the democracies
[00:59:58.280 --> 00:59:59.880]   through certain actions,
[00:59:59.880 --> 01:00:02.360]   but I'm not willing to cross a certain line.
[01:00:02.360 --> 01:00:05.280]   And absolutism doesn't need to come into play.
[01:00:05.280 --> 01:00:07.600]   That's what I think is making this
[01:00:07.600 --> 01:00:09.760]   such a very difficult conversation,
[01:00:09.760 --> 01:00:10.680]   and it's why it's so hard
[01:00:10.680 --> 01:00:13.160]   to actually have a conversation around it.
[01:00:13.160 --> 01:00:15.480]   And it's really, I would argue,
[01:00:15.480 --> 01:00:18.800]   the most poignant and the most dramatic moment
[01:00:18.800 --> 01:00:20.600]   in what we talked about earlier,
[01:00:20.600 --> 01:00:24.040]   which is this deep-seated kind of bipolarity.
[01:00:24.040 --> 01:00:25.760]   And once you're sitting on your pole,
[01:00:25.760 --> 01:00:26.600]   you don't wanna come off,
[01:00:26.600 --> 01:00:28.440]   and you don't realize that so much of the dialogue
[01:00:28.440 --> 01:00:29.880]   is in this middle.
[01:00:29.880 --> 01:00:31.440]   And we have to come to some point of view
[01:00:31.440 --> 01:00:33.860]   that maybe this isn't about an absolute outcome.
[01:00:33.860 --> 01:00:36.280]   It's not absolutely gonna be nuclear war,
[01:00:36.280 --> 01:00:39.040]   and it's not absolutely gonna be the end of democracy.
[01:00:39.040 --> 01:00:40.680]   There's some conversation in the middle
[01:00:40.680 --> 01:00:43.040]   that's very difficult to have.
[01:00:43.040 --> 01:00:46.760]   And people that work somewhere in the world,
[01:00:46.760 --> 01:00:49.680]   hopefully ambassadors, foreign policy people,
[01:00:49.680 --> 01:00:51.140]   State Department people,
[01:00:51.140 --> 01:00:54.400]   hopefully are having the more nuanced critical conversation
[01:00:54.400 --> 01:00:57.440]   about how do we resolve to the maximal outcome
[01:00:57.440 --> 01:00:59.920]   that doesn't necessarily take us to an absolute end.
[01:00:59.920 --> 01:01:01.240]   - Chamath, to that point,
[01:01:01.240 --> 01:01:03.160]   it's gonna be an imperfect outcome here.
[01:01:03.160 --> 01:01:05.840]   - I think this is much, much simpler than all of this.
[01:01:05.840 --> 01:01:09.560]   Leon Panetta is a senior counselor
[01:01:09.560 --> 01:01:11.960]   to this defense contracting agency
[01:01:11.960 --> 01:01:13.320]   called Beacon Global Strategies
[01:01:13.320 --> 01:01:15.080]   who works on behalf of Raytheon.
[01:01:15.080 --> 01:01:17.720]   I found that out while Friedberg was talking
[01:01:17.720 --> 01:01:19.240]   in a two-second Google search.
[01:01:19.240 --> 01:01:21.520]   I suspect that if you looked
[01:01:21.520 --> 01:01:23.360]   for Petraeus' conflicts of interest,
[01:01:23.360 --> 01:01:26.040]   you would find that through some Byzantine set
[01:01:26.040 --> 01:01:29.800]   of strategic consulting organizations and whatnot,
[01:01:29.800 --> 01:01:32.480]   he also works on behalf of the defense industry.
[01:01:32.480 --> 01:01:36.280]   So you have these people who will generate more revenue
[01:01:36.280 --> 01:01:39.640]   and more profit if there is a massive war.
[01:01:39.640 --> 01:01:42.720]   And those people have been trying to push us
[01:01:42.720 --> 01:01:47.720]   into a land war in Europe since this whole thing started.
[01:01:47.720 --> 01:01:50.120]   And so this is just yet another attempt.
[01:01:50.120 --> 01:01:51.900]   It's just the most final way of doing it.
[01:01:51.900 --> 01:01:53.400]   So I would just encourage people,
[01:01:53.400 --> 01:01:57.940]   whenever you see all these folks clamoring for war,
[01:01:57.940 --> 01:02:00.480]   is just to keep in mind
[01:02:00.480 --> 01:02:02.120]   that they are riddled with conflict
[01:02:02.120 --> 01:02:03.500]   and that you can find it out.
[01:02:03.500 --> 01:02:05.420]   Again, this information is sitting in plain sight
[01:02:05.420 --> 01:02:06.440]   on the internet,
[01:02:06.440 --> 01:02:08.120]   and you can figure out whether this person
[01:02:08.120 --> 01:02:11.680]   is really advocating a truth that makes sense
[01:02:11.680 --> 01:02:13.800]   or they're getting paid to shill
[01:02:13.800 --> 01:02:16.080]   a revenue generating mechanism
[01:02:16.080 --> 01:02:17.560]   for some part of the military industrial.
[01:02:17.560 --> 01:02:19.800]   - Sax, how much of this is people talking in their book,
[01:02:19.800 --> 01:02:21.760]   their book being the military industrial complex
[01:02:21.760 --> 01:02:23.160]   in your mind?
[01:02:23.160 --> 01:02:24.120]   - I think that's a big part of it.
[01:02:24.120 --> 01:02:25.800]   I think all of these Washington think tanks
[01:02:25.800 --> 01:02:28.320]   are funded by defense contractors.
[01:02:28.320 --> 01:02:29.960]   I think it's short-sighted, obviously,
[01:02:29.960 --> 01:02:31.800]   'cause if it leads to a nuclear war,
[01:02:31.800 --> 01:02:33.560]   there's not gonna be a defense industry,
[01:02:33.560 --> 01:02:34.920]   there won't be anything left.
[01:02:35.280 --> 01:02:40.280]   But look, I think that Washington is wired for war in part
[01:02:40.280 --> 01:02:43.520]   because there's a huge lobby for it,
[01:02:43.520 --> 01:02:44.960]   for all these defense contractors,
[01:02:44.960 --> 01:02:46.200]   and what's the lobby for peace?
[01:02:46.200 --> 01:02:48.560]   I mean, there's no one really arguing for peace.
[01:02:48.560 --> 01:02:51.440]   - Speaking of this, Elon tweeted.
[01:02:51.440 --> 01:02:54.040]   - I'll tell you what's lobbying for peace.
[01:02:54.040 --> 01:02:55.120]   And I'm gonna connect
[01:02:55.120 --> 01:02:57.680]   what may seem two disparate ideas together.
[01:02:57.680 --> 01:02:59.000]   But the single biggest thing
[01:02:59.000 --> 01:03:00.880]   I think that will prevent nuclear war
[01:03:00.880 --> 01:03:04.200]   is the inflation that we're feeling.
[01:03:04.200 --> 01:03:06.680]   And the reason is because it allows the Fed,
[01:03:06.680 --> 01:03:08.160]   in my opinion, for the first time,
[01:03:08.160 --> 01:03:11.880]   really in the last 15 years, to act properly.
[01:03:11.880 --> 01:03:14.280]   And if they hold the line
[01:03:14.280 --> 01:03:17.560]   and they take interest rates to 4% or 5%,
[01:03:17.560 --> 01:03:20.080]   I think one non-obvious outcome of all of that
[01:03:20.080 --> 01:03:23.520]   is that it becomes extremely expensive,
[01:03:23.520 --> 01:03:25.600]   next to impossible,
[01:03:25.600 --> 01:03:28.700]   to finance military adventurism abroad.
[01:03:28.700 --> 01:03:31.640]   And that's a practical economic outcrop
[01:03:31.640 --> 01:03:35.040]   of really meaningfully high rates greater than zero.
[01:03:35.040 --> 01:03:37.700]   And so I actually think the reality
[01:03:37.700 --> 01:03:39.880]   is that for a lot of these governments,
[01:03:39.880 --> 01:03:43.000]   the more that inflation sticks around,
[01:03:43.000 --> 01:03:45.960]   the stickier it is, the higher rates are in general,
[01:03:45.960 --> 01:03:48.220]   the bigger the problems at home are,
[01:03:48.220 --> 01:03:50.240]   and the less prone they're going to be likely.
[01:03:50.240 --> 01:03:54.320]   I actually think that explains the escalation
[01:03:54.320 --> 01:03:55.160]   of this rhetoric
[01:03:55.160 --> 01:03:57.520]   because people want to try to make this issue
[01:03:57.520 --> 01:03:58.720]   and put it on the table.
[01:03:58.720 --> 01:04:00.720]   But you understand that these folks don't say
[01:04:00.720 --> 01:04:02.480]   it's a 90% likelihood.
[01:04:02.480 --> 01:04:04.600]   They go from 1% to 25%,
[01:04:04.600 --> 01:04:06.560]   which if you understand probabilities
[01:04:06.560 --> 01:04:08.560]   is effectively a left tail risk
[01:04:08.560 --> 01:04:10.320]   that's effectively the same.
[01:04:10.320 --> 01:04:11.600]   And the reason they're trying to do it
[01:04:11.600 --> 01:04:13.400]   is they're trying to get it back, David, as you say,
[01:04:13.400 --> 01:04:14.920]   to timestamp it,
[01:04:14.920 --> 01:04:17.000]   to get it in front of people's perspectives
[01:04:17.000 --> 01:04:18.500]   to make it important,
[01:04:18.500 --> 01:04:21.240]   in a moment where everybody increasingly,
[01:04:21.240 --> 01:04:22.460]   not just in the United States,
[01:04:22.460 --> 01:04:24.400]   but in the UK, in Europe,
[01:04:24.400 --> 01:04:26.140]   are looking internally
[01:04:26.140 --> 01:04:28.760]   and trying to figure out how to keep their economies
[01:04:28.760 --> 01:04:30.800]   in a reasonably functioning way
[01:04:30.800 --> 01:04:32.280]   and how to make sure that their financial
[01:04:32.280 --> 01:04:34.240]   and other infrastructure keeps working.
[01:04:34.240 --> 01:04:35.080]   - So you're saying-
[01:04:35.080 --> 01:04:37.960]   - And that is not necessarily a priority when rates are zero,
[01:04:37.960 --> 01:04:39.240]   but when rates are 4%,
[01:04:39.240 --> 01:04:40.600]   I mean, just by the way,
[01:04:40.600 --> 01:04:42.120]   if you guys saw what happened today,
[01:04:42.120 --> 01:04:45.200]   it was the competing of two narratives this week.
[01:04:45.200 --> 01:04:46.880]   There was the financial narrative
[01:04:46.880 --> 01:04:51.240]   of the UK having to bail out their pension system, right?
[01:04:51.240 --> 01:04:52.240]   Of all of a sudden,
[01:04:52.240 --> 01:04:54.880]   the pensions being forced sellers,
[01:04:54.880 --> 01:04:57.580]   of those forced sellers now, you know,
[01:04:57.580 --> 01:05:00.840]   spilling into the United States debt markets around CLOs
[01:05:00.840 --> 01:05:04.160]   and collateralized loan obligations and junk debt,
[01:05:04.160 --> 01:05:06.460]   which then could theoretically spill as a contagion
[01:05:06.460 --> 01:05:07.580]   to other parts of the market.
[01:05:07.580 --> 01:05:09.540]   That was narrative one.
[01:05:09.540 --> 01:05:11.020]   And all of that, by the way,
[01:05:11.020 --> 01:05:12.640]   is a result of hiding inflation
[01:05:12.640 --> 01:05:15.140]   and the Fed moving up rates
[01:05:15.140 --> 01:05:17.200]   and other countries being forced
[01:05:17.200 --> 01:05:19.400]   to attack inflation with higher rates
[01:05:19.400 --> 01:05:21.540]   and creating all these dislocations,
[01:05:21.540 --> 01:05:22.720]   narrative one,
[01:05:22.720 --> 01:05:23.720]   versus narrative two,
[01:05:23.720 --> 01:05:24.840]   which is, hey, all of a sudden,
[01:05:24.840 --> 01:05:27.200]   we have to put the nuclear risk on the table.
[01:05:27.200 --> 01:05:31.080]   And if you actually saw the print that was spilled,
[01:05:31.080 --> 01:05:33.120]   the disproportionate amount of the rhetoric
[01:05:33.120 --> 01:05:36.280]   actually focused on the former narrative and not the latter.
[01:05:36.280 --> 01:05:40.400]   And so I think that that's why these folks
[01:05:40.400 --> 01:05:42.560]   are escalating the rhetoric
[01:05:42.560 --> 01:05:45.800]   in order to kind of create an equality
[01:05:45.800 --> 01:05:47.120]   so that they get enough print
[01:05:47.120 --> 01:05:49.320]   on that version of the outcome.
[01:05:49.320 --> 01:05:52.440]   - What you're saying is you have the world saying,
[01:05:52.440 --> 01:05:55.000]   we can't afford to have this conflict.
[01:05:55.000 --> 01:05:55.920]   We are broke.
[01:05:55.920 --> 01:05:57.680]   We've got too many chaotic issues.
[01:05:57.680 --> 01:05:58.760]   - The world is saying,
[01:05:58.760 --> 01:06:02.640]   we are increasingly under enormous domestic pressure.
[01:06:02.640 --> 01:06:06.560]   And as a result, we cannot spend on things abroad.
[01:06:06.560 --> 01:06:08.080]   - We can't afford this.
[01:06:08.080 --> 01:06:09.260]   And then the other side saying,
[01:06:09.260 --> 01:06:10.520]   well, we need you to afford this
[01:06:10.520 --> 01:06:12.200]   so nuclear is gonna happen.
[01:06:12.200 --> 01:06:13.840]   There's gonna be a nuclear annihilation.
[01:06:13.840 --> 01:06:14.680]   - And there's a small strain.
[01:06:14.680 --> 01:06:15.720]   - You gotta pay more attention to this.
[01:06:15.720 --> 01:06:17.120]   - There's a small strain of folks
[01:06:17.120 --> 01:06:19.160]   who would economically benefit
[01:06:19.160 --> 01:06:21.160]   and who are now ratcheting up their rhetoric
[01:06:21.160 --> 01:06:23.840]   so that that second path becomes more and more on the table.
[01:06:23.840 --> 01:06:24.880]   - What do you think of this, Freeberg,
[01:06:24.880 --> 01:06:26.600]   this analysis that Shemoth has?
[01:06:26.600 --> 01:06:31.440]   These two polar, these two groups
[01:06:31.440 --> 01:06:35.260]   vying for the attention and or budget of the world.
[01:06:35.260 --> 01:06:39.560]   - The military industrial complex?
[01:06:39.560 --> 01:06:42.160]   - Versus yeah, citizens saying,
[01:06:42.160 --> 01:06:43.440]   our country can't afford this.
[01:06:43.440 --> 01:06:44.800]   We need to focus inward.
[01:06:44.800 --> 01:06:46.520]   - Not citizens, the central banks.
[01:06:46.520 --> 01:06:48.020]   - Okay, but I think the central banks
[01:06:48.020 --> 01:06:49.000]   influenced by citizens, right?
[01:06:49.000 --> 01:06:51.340]   Like this is a whole system here we're talking about.
[01:06:51.340 --> 01:06:54.600]   People are, you know, watching their pensions go away.
[01:06:54.600 --> 01:06:56.520]   They're watching jobs get cut.
[01:06:56.520 --> 01:06:58.640]   - If I was a betting man, I spent,
[01:06:58.640 --> 01:07:00.520]   I would guess that the next half a trillion
[01:07:00.520 --> 01:07:02.620]   to a trillion dollars that is spent
[01:07:02.620 --> 01:07:06.160]   in Western world economies will be to subsidize
[01:07:06.160 --> 01:07:08.080]   something that's broken internally
[01:07:08.080 --> 01:07:09.880]   inside of one of our countries,
[01:07:09.880 --> 01:07:11.760]   whether it's the UK pension system
[01:07:11.760 --> 01:07:14.760]   or whether it's the high yield credit markets,
[01:07:14.760 --> 01:07:16.320]   and it will not be to finance
[01:07:16.320 --> 01:07:19.080]   military adventurism in Russia.
[01:07:19.080 --> 01:07:21.120]   - People, Sachs, hold on. - Just to underscore
[01:07:21.120 --> 01:07:22.640]   that point, so there's an article today
[01:07:22.640 --> 01:07:24.120]   in the Washington Post about how
[01:07:24.120 --> 01:07:25.800]   the US government's debt service
[01:07:25.800 --> 01:07:28.440]   is gonna be around 570 billion this year,
[01:07:28.440 --> 01:07:31.040]   which is a 45% increase.
[01:07:31.040 --> 01:07:34.040]   Biden's budget for 2023 is only 1.6 trillion.
[01:07:34.040 --> 01:07:37.640]   So you're talking about something like over a third now
[01:07:37.640 --> 01:07:40.240]   of the official budget is already going to debt service.
[01:07:40.240 --> 01:07:41.440]   - Because it's not a variable, right?
[01:07:41.440 --> 01:07:42.640]   It's a variable, right? - Yeah, exactly.
[01:07:42.640 --> 01:07:44.640]   'Cause so much of it is,
[01:07:44.640 --> 01:07:46.680]   it's not locked in a long-term rate.
[01:07:46.680 --> 01:07:48.560]   So because interest rates have gone up so much,
[01:07:48.560 --> 01:07:49.760]   the debt service has gone up
[01:07:49.760 --> 01:07:51.620]   and interest rates are still going up.
[01:07:51.620 --> 01:07:54.120]   And so, Druckenmiller had those points
[01:07:54.120 --> 01:07:57.000]   around how the debt services within a decade
[01:07:57.000 --> 01:07:59.720]   is gonna eat up practically the whole federal budget.
[01:07:59.720 --> 01:08:01.840]   So Chamath is right that we've never really had to choose
[01:08:01.840 --> 01:08:04.440]   between guns and butter before in the past.
[01:08:04.440 --> 01:08:05.760]   It was just, let's just do both
[01:08:05.760 --> 01:08:08.000]   and we'll rack up more national debt.
[01:08:08.000 --> 01:08:10.800]   I do think there will be more and more pressure
[01:08:10.800 --> 01:08:13.160]   to question this type of spending
[01:08:13.160 --> 01:08:17.380]   and why we've already given Ukraine $80 billion in handouts
[01:08:17.380 --> 01:08:21.520]   when we can't afford to basically pay for,
[01:08:21.520 --> 01:08:23.640]   major entitlements at home.
[01:08:23.640 --> 01:08:25.000]   So I think there'll be more pressure.
[01:08:25.000 --> 01:08:27.160]   Now, I don't know if that pressure
[01:08:27.160 --> 01:08:28.640]   is gonna come in time though,
[01:08:28.640 --> 01:08:30.320]   to deescalate this Ukraine war.
[01:08:30.320 --> 01:08:32.240]   - It's not. - And that's what concerns me.
[01:08:32.240 --> 01:08:34.440]   And just to cut to the chase on this,
[01:08:34.440 --> 01:08:37.080]   I think where the rubber meets the road on Ukraine
[01:08:37.080 --> 01:08:38.040]   is Crimea.
[01:08:38.040 --> 01:08:39.800]   And why?
[01:08:39.800 --> 01:08:42.520]   Because the Russians have a major naval base there
[01:08:42.520 --> 01:08:43.520]   at Sevastopol.
[01:08:43.520 --> 01:08:46.280]   It's the home of the Black Sea Fleet.
[01:08:46.280 --> 01:08:48.120]   And they will never give that up.
[01:08:48.120 --> 01:08:50.740]   They are willing to use nukes, I believe,
[01:08:50.740 --> 01:08:52.680]   to basically protect that asset.
[01:08:52.680 --> 01:08:53.880]   It's a vital interest of theirs.
[01:08:53.880 --> 01:08:54.720]   Hold on.
[01:08:54.720 --> 01:08:58.560]   80% of the population of Crimea, they're Russian.
[01:08:58.560 --> 01:09:00.520]   And three quarters of them, according to polling
[01:09:00.520 --> 01:09:02.800]   that was done by Gallup and by a German polling firm,
[01:09:02.800 --> 01:09:04.400]   so not Russian polls,
[01:09:04.400 --> 01:09:06.720]   indicated that they see themselves as Russian
[01:09:06.720 --> 01:09:07.760]   and wanna be part of Russia.
[01:09:07.760 --> 01:09:09.560]   So if we supported self-determination,
[01:09:09.560 --> 01:09:11.600]   we'd be fine with Crimea being part of Russia.
[01:09:11.600 --> 01:09:12.560]   But here's the rub.
[01:09:12.560 --> 01:09:14.960]   Ukrainian nationalism demands
[01:09:14.960 --> 01:09:18.120]   that every square inch of Crimea goes back to Ukraine.
[01:09:18.120 --> 01:09:20.600]   And it is State Department policy right now
[01:09:20.600 --> 01:09:23.600]   that we will never recognize Crimea as being Russian.
[01:09:23.600 --> 01:09:25.380]   We'll never recognize the annexation,
[01:09:25.380 --> 01:09:27.260]   which happened back in 2014.
[01:09:27.260 --> 01:09:28.680]   So something's gotta give here.
[01:09:28.680 --> 01:09:29.520]   Something's gotta give.
[01:09:29.520 --> 01:09:33.160]   Either we have to sit down, Zelensky,
[01:09:33.160 --> 01:09:35.640]   and say to him, "Listen, you're not getting back Crimea.
[01:09:35.640 --> 01:09:37.200]   "We're gonna make that part of a peace deal."
[01:09:37.200 --> 01:09:39.860]   Or we are gonna back the Ukrainians
[01:09:39.860 --> 01:09:42.320]   in their military effort to retake Crimea
[01:09:42.320 --> 01:09:44.980]   with the result that I think is quite likely
[01:09:44.980 --> 01:09:47.880]   that the Russians will be willing to use a tactical nuke
[01:09:47.880 --> 01:09:50.340]   to prevent their total defeat.
[01:09:50.340 --> 01:09:52.120]   So at some point, we're gonna have to choose here
[01:09:52.120 --> 01:09:53.720]   which of these outcomes do you want?
[01:09:53.720 --> 01:09:56.040]   Do you wanna basically go for a negotiated settlement,
[01:09:56.040 --> 01:09:57.400]   which means telling the Ukrainians
[01:09:57.400 --> 01:09:59.360]   they cannot have everything they want?
[01:09:59.360 --> 01:10:01.820]   Or do you really wanna risk a nuclear war
[01:10:01.820 --> 01:10:04.720]   to take back Crimea, which is Russian,
[01:10:04.720 --> 01:10:06.560]   and the people there see themselves as Russian?
[01:10:06.560 --> 01:10:08.640]   So we need to make a choice here.
[01:10:08.640 --> 01:10:09.480]   - Yeah, yeah.
[01:10:09.480 --> 01:10:13.040]   So Elon put out a tweet for, and got savaged for it.
[01:10:13.040 --> 01:10:16.160]   And he outlined sort of what you're saying here.
[01:10:16.160 --> 01:10:17.760]   So do you think his plan, he said,
[01:10:17.760 --> 01:10:19.260]   "Redo elections of annexed regions
[01:10:19.260 --> 01:10:21.540]   "under UN supervision, Russia leaves
[01:10:21.540 --> 01:10:24.080]   "if that is the will of the people."
[01:10:24.080 --> 01:10:25.820]   And then he says, "Crimea, formerly part of Russia,
[01:10:25.820 --> 01:10:27.260]   "as it's been since 1783,
[01:10:27.260 --> 01:10:29.440]   "water supply to Crimea assured."
[01:10:29.440 --> 01:10:31.400]   As you're saying, Ukraine remains neutral.
[01:10:31.400 --> 01:10:34.040]   Should the West force Ukraine
[01:10:34.040 --> 01:10:37.460]   to accept these type of terms, essentially elections,
[01:10:37.460 --> 01:10:39.040]   and I don't know why Crimea wouldn't be part
[01:10:39.040 --> 01:10:40.240]   of that election process.
[01:10:40.240 --> 01:10:43.440]   Do you think UN-supervised elections
[01:10:43.440 --> 01:10:45.480]   in those regions should occur,
[01:10:45.480 --> 01:10:47.920]   and we should force Zelensky to do that?
[01:10:47.920 --> 01:10:50.580]   - He who pays the piper calls the tune.
[01:10:50.580 --> 01:10:52.740]   Of course, we need to have a point of view
[01:10:52.740 --> 01:10:54.180]   on how this war should be resolved.
[01:10:54.180 --> 01:10:55.900]   - Should we force him to do that?
[01:10:55.900 --> 01:10:57.580]   - Listen, it's not about force.
[01:10:57.580 --> 01:10:59.700]   They can fight on and do whatever they want,
[01:10:59.700 --> 01:11:00.940]   as long as they want, hold on,
[01:11:00.940 --> 01:11:02.580]   without American weapons. - For our support, I'm saying.
[01:11:02.580 --> 01:11:03.980]   That's what you said. - Without American weapons.
[01:11:03.980 --> 01:11:04.820]   If they want-- - So you think
[01:11:04.820 --> 01:11:05.640]   he should do that?
[01:11:05.640 --> 01:11:07.620]   We should pull the American weapons if he doesn't.
[01:11:07.620 --> 01:11:11.020]   - If Zelensky wants our weapons and support,
[01:11:11.020 --> 01:11:12.420]   which appear to be infinite,
[01:11:12.420 --> 01:11:14.420]   we should not give him a blank check guarantee.
[01:11:14.420 --> 01:11:17.300]   The blank check is what started World War I,
[01:11:17.300 --> 01:11:20.060]   the German Kaiser gave Austria a blank check guarantee,
[01:11:20.060 --> 01:11:21.260]   and it led to World War I.
[01:11:21.260 --> 01:11:22.940]   That is how great powers get pulled
[01:11:22.940 --> 01:11:25.300]   into the wars of minor powers.
[01:11:25.300 --> 01:11:27.380]   And we absolutely have to have a point of view
[01:11:27.380 --> 01:11:29.660]   on how we do not get pulled into this.
[01:11:29.660 --> 01:11:33.020]   And I think one of our lines should be
[01:11:33.020 --> 01:11:35.340]   that we are not gonna fund the Ukrainians
[01:11:35.340 --> 01:11:37.020]   in retaking Crimea.
[01:11:37.020 --> 01:11:39.220]   - Got it, so just to clear this
[01:11:39.220 --> 01:11:40.780]   so we can move on to the next topic,
[01:11:40.780 --> 01:11:44.180]   you're in support of removing,
[01:11:44.180 --> 01:11:47.420]   not giving further weapons support to the Ukraine
[01:11:47.420 --> 01:11:48.740]   unless they negotiate this. - It's not gonna come to that.
[01:11:48.740 --> 01:11:49.740]   It's not gonna come to that.
[01:11:49.740 --> 01:11:50.940]   We need to have a point of view
[01:11:50.940 --> 01:11:51.780]   on how this war gets resolved. - But you are in support
[01:11:51.780 --> 01:11:54.500]   of that, stopping our support if they don't sit down
[01:11:54.500 --> 01:11:56.320]   and negotiate a settlement here.
[01:11:56.320 --> 01:11:57.340]   That's what you would do.
[01:11:57.340 --> 01:11:59.220]   - America needs to have a point of view
[01:11:59.220 --> 01:12:00.940]   of what is in its own interest.
[01:12:00.940 --> 01:12:03.820]   What is in our interest is for this to get resolved
[01:12:03.820 --> 01:12:06.380]   diplomatically at some point through negotiated settlement,
[01:12:06.380 --> 01:12:08.540]   not for it to escalate into a nuclear war
[01:12:08.540 --> 01:12:09.940]   that we could get pulled into.
[01:12:09.940 --> 01:12:12.580]   The only way that's gonna happen, okay,
[01:12:12.580 --> 01:12:14.220]   is if Crimea goes back to Russia.
[01:12:14.220 --> 01:12:15.820]   I'm telling you, they will be willing
[01:12:15.820 --> 01:12:16.820]   to pull out all the stops.
[01:12:16.820 --> 01:12:18.940]   And by the way, they could even use tech nukes
[01:12:18.940 --> 01:12:20.820]   before Crimea, but if-- - Can you answer
[01:12:20.820 --> 01:12:22.500]   the question though that I asked three times?
[01:12:22.500 --> 01:12:24.540]   Would you remove American support in weapons
[01:12:24.540 --> 01:12:25.780]   if they don't accept that?
[01:12:25.780 --> 01:12:26.820]   If Ukraine doesn't accept that,
[01:12:26.820 --> 01:12:29.060]   would you be comfortable taking away our support in weapons?
[01:12:29.060 --> 01:12:30.060]   - I don't think it's gonna come to that,
[01:12:30.060 --> 01:12:31.860]   but yes, we should be willing to threaten that, yes.
[01:12:31.860 --> 01:12:32.860]   - Okay, that's it, I'm just trying to get you
[01:12:32.860 --> 01:12:33.700]   to answer that one question.
[01:12:33.700 --> 01:12:34.540]   Let's-- - They are our,
[01:12:34.540 --> 01:12:37.500]   hold on a second, they are a client state of the US.
[01:12:37.500 --> 01:12:38.740]   They do not call the shots.
[01:12:38.740 --> 01:12:40.340]   We're America, we call the shots.
[01:12:40.340 --> 01:12:41.580]   We're the big dog here. - Got it, all right.
[01:12:41.580 --> 01:12:42.420]   - That's the bottom line. - All right.
[01:12:42.420 --> 01:12:44.460]   - And you really wanna get pulled into a nuclear war
[01:12:44.460 --> 01:12:45.300]   because of-- - I do not.
[01:12:45.300 --> 01:12:47.060]   I just wanted you to answer that one question.
[01:12:47.060 --> 01:12:48.580]   We should pull our weapons if they don't.
[01:12:48.580 --> 01:12:50.060]   - Let's get real. - Okay, got it.
[01:12:50.060 --> 01:12:51.540]   - This is about our future.
[01:12:51.540 --> 01:12:53.860]   You know, we are American nationalists, at least I am.
[01:12:53.860 --> 01:12:55.220]   I'm not a Ukrainian nationalist.
[01:12:55.220 --> 01:12:56.500]   I support self-rule.
[01:12:56.500 --> 01:12:57.700]   I think we accomplished something
[01:12:57.700 --> 01:13:00.180]   by preventing Kiev from getting toppled,
[01:13:00.180 --> 01:13:03.420]   but I wanna support self-rule for the people of Crimea.
[01:13:03.420 --> 01:13:05.420]   - It's time for a settlement in Saks and Matin.
[01:13:05.420 --> 01:13:06.740]   - I think the most important thing
[01:13:06.740 --> 01:13:08.300]   that we can all be thankful for,
[01:13:08.300 --> 01:13:11.220]   which I think will prevent a lot of wars
[01:13:11.220 --> 01:13:13.900]   in the next 10 or 20 years is inflation
[01:13:13.900 --> 01:13:15.340]   and non-zero interest rates.
[01:13:15.340 --> 01:13:17.060]   It's just gonna be really tough.
[01:13:17.060 --> 01:13:17.900]   Like, you know, first of all-- - I want both
[01:13:17.900 --> 01:13:20.060]   of these perspectives. - The UK cannot do anything
[01:13:20.060 --> 01:13:21.700]   right now other than make sure
[01:13:21.700 --> 01:13:23.700]   that they have foreign currency reserves
[01:13:23.700 --> 01:13:24.820]   to back up the pound,
[01:13:24.820 --> 01:13:26.880]   which they don't really have that much.
[01:13:26.880 --> 01:13:29.340]   They're gonna need money to bail out their pension system.
[01:13:29.340 --> 01:13:30.740]   Whoever thought it was a good idea
[01:13:30.740 --> 01:13:33.580]   to allow pensions to run levered risk,
[01:13:33.580 --> 01:13:35.560]   was, it's obviously insane.
[01:13:35.560 --> 01:13:36.900]   Could you imagine if it turned out
[01:13:36.900 --> 01:13:39.380]   that the teachers' pensions and the firefighters' pensions
[01:13:39.380 --> 01:13:41.740]   in America were running levered long?
[01:13:41.740 --> 01:13:43.220]   I mean-- - Oh, they are.
[01:13:43.220 --> 01:13:44.060]   They are. - They're not--
[01:13:44.060 --> 01:13:45.220]   - This has to get resolved now.
[01:13:45.220 --> 01:13:46.060]   I mean, it's just-- - You know what a pension is?
[01:13:46.060 --> 01:13:47.500]   - We're at a breaking point. - No, yeah, it's clear.
[01:13:47.500 --> 01:13:48.460]   - You know what a pension is?
[01:13:48.460 --> 01:13:49.300]   - I know, I'm not trying some fancy--
[01:13:49.300 --> 01:13:51.660]   - A pension is only, yeah, it's just a debt instrument.
[01:13:51.660 --> 01:13:52.500]   - No, no, no, no, no, I'm saying--
[01:13:52.500 --> 01:13:53.660]   - That's all it is.
[01:13:53.660 --> 01:13:55.900]   - I'm saying, don't use some fancy intellectual argument.
[01:13:55.900 --> 01:13:57.020]   I'm saying, practically speaking,
[01:13:57.020 --> 01:13:59.660]   the treasurer is not allowed to call Goldman Sachs
[01:13:59.660 --> 01:14:01.820]   and say, "I'm gonna run two turns of leverage on this money."
[01:14:01.820 --> 01:14:04.460]   That is not allowed to happen in the United States, okay?
[01:14:04.460 --> 01:14:06.500]   I get in some fancy way it could be thought of
[01:14:06.500 --> 01:14:09.020]   as levered long with all kinds of indirection,
[01:14:09.020 --> 01:14:10.660]   but that is not how the world works today,
[01:14:10.660 --> 01:14:11.780]   practically speaking.
[01:14:11.780 --> 01:14:13.580]   It is how the UK works.
[01:14:13.580 --> 01:14:15.620]   A treasurer in a UK pension system
[01:14:15.620 --> 01:14:18.580]   is allowed to call an investment bank
[01:14:18.580 --> 01:14:20.540]   and actually run levered.
[01:14:20.540 --> 01:14:23.260]   That is insane, okay?
[01:14:23.260 --> 01:14:26.060]   So my point is, when rates are non-zero,
[01:14:26.060 --> 01:14:28.180]   all of that jig is up,
[01:14:28.180 --> 01:14:31.380]   governments are forced to batten down the hatches,
[01:14:31.380 --> 01:14:34.540]   and husband cash,
[01:14:34.540 --> 01:14:37.020]   for God knows what will break in the system.
[01:14:37.020 --> 01:14:41.500]   And I think that that is, and as disruptive as that is,
[01:14:41.500 --> 01:14:45.140]   it may actually be the bulwark against war.
[01:14:45.140 --> 01:14:47.260]   - The jig is up, folks.
[01:14:47.260 --> 01:14:50.740]   I mean, I think that's what we should take away from this is
[01:14:50.740 --> 01:14:53.280]   we can't afford this, and the United States is funding it.
[01:14:53.280 --> 01:14:54.620]   We have to force a settlement here,
[01:14:54.620 --> 01:14:55.460]   and it will be a profound courage.
[01:14:55.460 --> 01:14:58.060]   - And that may be the silver lining of inflation.
[01:14:58.060 --> 01:15:00.780]   - Okay, Andy Jassy's had an all-hands meeting.
[01:15:00.780 --> 01:15:02.860]   Amazon is freezing hiring for corporate roles
[01:15:02.860 --> 01:15:03.860]   in its retail business.
[01:15:03.860 --> 01:15:05.940]   Almost 90 VPs or higher level execs
[01:15:05.940 --> 01:15:07.740]   have left Amazon since 2021.
[01:15:07.740 --> 01:15:10.380]   Earlier this week, there was an all-hands presentation,
[01:15:10.380 --> 01:15:13.380]   and the slides were leaked to Business Insider.
[01:15:13.380 --> 01:15:15.940]   Some of them, "Constraints breed resourcefulness,
[01:15:15.940 --> 01:15:17.580]   "self-sufficiency, and innovation.
[01:15:17.580 --> 01:15:19.720]   "There are no extra points for growing headcount,
[01:15:19.720 --> 01:15:21.180]   "budget size, or fixed expense.
[01:15:21.180 --> 01:15:23.620]   "The slide instructed employees to accomplish more
[01:15:23.620 --> 01:15:25.380]   "with less," sounds familiar,
[01:15:25.380 --> 01:15:27.220]   sounds like something the US needs to do,
[01:15:27.220 --> 01:15:28.740]   and foreign policy needs to do.
[01:15:28.740 --> 01:15:30.740]   "Amazon leadership team urged employees
[01:15:30.740 --> 01:15:33.140]   "to double down on frugality."
[01:15:33.140 --> 01:15:35.780]   Jassy also spoke in the meeting, just a couple of quotes,
[01:15:35.780 --> 01:15:37.940]   and then I'll get your thoughts, Chamath.
[01:15:37.940 --> 01:15:39.080]   "It's on a lot of people's minds,
[01:15:39.080 --> 01:15:40.760]   "and of course, none of us know for sure
[01:15:40.760 --> 01:15:42.960]   "what's gonna happen, but there are a lot of signs
[01:15:42.960 --> 01:15:44.680]   "that point to this being a difficult
[01:15:44.680 --> 01:15:45.840]   "and rough economy ahead of us,
[01:15:45.840 --> 01:15:47.960]   "and I don't know how long that'll last.
[01:15:47.960 --> 01:15:49.560]   "But I think it's one of the things
[01:15:49.560 --> 01:15:52.280]   "that we are thinking about, and we decided that
[01:15:52.280 --> 01:15:53.940]   "we're going to be more streamlined
[01:15:53.940 --> 01:15:56.860]   "in how we expand in 2023 good companies
[01:15:56.860 --> 01:15:58.420]   "that last a long period of time,
[01:15:58.420 --> 01:16:00.020]   "who are thinking about the long term,
[01:16:00.020 --> 01:16:02.220]   "always have this push and pull."
[01:16:02.220 --> 01:16:04.740]   Chamath, what do you read into this?
[01:16:04.740 --> 01:16:06.180]   - I'll say three quick things.
[01:16:06.180 --> 01:16:09.820]   One is that today, Thursday, October 13th,
[01:16:09.820 --> 01:16:14.040]   we had an inflation print which was worse than expected,
[01:16:14.040 --> 01:16:16.300]   and the markets are materially higher, right?
[01:16:16.300 --> 01:16:18.080]   So, you know-- - Strange, why?
[01:16:18.080 --> 01:16:20.900]   - Well, we talked about this a few weeks ago,
[01:16:20.900 --> 01:16:24.660]   but my thought then, and it's the same that I think now,
[01:16:24.660 --> 01:16:27.340]   is that we've effectively seen the near-term bottom,
[01:16:27.340 --> 01:16:28.780]   and we're now consolidating.
[01:16:28.780 --> 01:16:31.140]   And so every opportunity people have
[01:16:31.140 --> 01:16:33.620]   to justify that most of the news is behind them,
[01:16:33.620 --> 01:16:36.420]   they take, and they use that as a reason to buy.
[01:16:36.420 --> 01:16:37.760]   Okay, so that's number one,
[01:16:37.760 --> 01:16:40.540]   which is that we are sort of near the end.
[01:16:40.540 --> 01:16:45.440]   The second, however, is that if we do see another leg down,
[01:16:45.440 --> 01:16:49.300]   there is really only one cohort of company
[01:16:49.300 --> 01:16:51.300]   that hasn't been really whacked.
[01:16:51.300 --> 01:16:53.040]   And I'll summarize it very quickly by saying
[01:16:53.040 --> 01:16:57.140]   it's Microsoft, Amazon, Apple, and Google, that's it.
[01:16:57.140 --> 01:16:59.740]   Even Facebook has now been sort of put into the bucket
[01:16:59.740 --> 01:17:03.940]   of everybody else, where we've been crushed 60, 70, 80%
[01:17:03.940 --> 01:17:05.260]   in those companies.
[01:17:05.260 --> 01:17:07.780]   So what does that mean?
[01:17:07.780 --> 01:17:12.020]   Well, those four companies are now being identified
[01:17:12.020 --> 01:17:13.660]   for what they may be,
[01:17:13.660 --> 01:17:17.420]   which in capitalism is called over-earning, okay?
[01:17:17.420 --> 01:17:21.060]   They are making more money than we think is appropriate.
[01:17:21.060 --> 01:17:23.460]   This letter from Andy Jassy is his way
[01:17:23.460 --> 01:17:26.900]   of effectively telling his major shareholders
[01:17:26.900 --> 01:17:28.540]   that he is now moving the business
[01:17:28.540 --> 01:17:30.900]   to become more of a cash cow business.
[01:17:30.900 --> 01:17:35.540]   Tim Cook made this incredible decision in 2016, '17, '18
[01:17:35.540 --> 01:17:37.020]   that effectively did the same thing.
[01:17:37.020 --> 01:17:38.500]   That's when Buffett came in.
[01:17:38.500 --> 01:17:41.040]   That's when he established a huge ownership in the stock.
[01:17:41.040 --> 01:17:43.300]   That's when the stock absolutely ripped
[01:17:43.300 --> 01:17:46.660]   because it moved into a different bucket in people's minds.
[01:17:46.660 --> 01:17:49.540]   It became growth at a pretty reasonable price.
[01:17:49.540 --> 01:17:51.100]   And I think Andy is making the case
[01:17:51.100 --> 01:17:54.100]   that Amazon is gonna become one of these GARP stocks,
[01:17:54.100 --> 01:17:55.740]   growth at a reasonable price.
[01:17:55.740 --> 01:17:58.260]   He's gonna generate a ton of cash flow.
[01:17:58.260 --> 01:18:00.940]   He's gonna keep expenses nominal.
[01:18:00.940 --> 01:18:02.700]   He's gonna return a ton of cash
[01:18:02.700 --> 01:18:04.340]   to shareholders with buybacks.
[01:18:04.340 --> 01:18:07.300]   That's the reading in between the lines of that letter.
[01:18:07.300 --> 01:18:09.540]   I think it's a really profound statement
[01:18:09.540 --> 01:18:14.100]   and a very smart move because you haven't seen that letter
[01:18:14.100 --> 01:18:16.580]   or a version of that letter yet from Microsoft.
[01:18:16.580 --> 01:18:19.740]   And you started to see hints of that letter from Sundar
[01:18:19.740 --> 01:18:22.180]   where he said, you know, it's, and he's not-
[01:18:22.180 --> 01:18:23.340]   - He's saber rattling, yeah.
[01:18:23.340 --> 01:18:24.160]   - He's not there yet.
[01:18:24.160 --> 01:18:26.260]   He's in the appetizer part.
[01:18:26.260 --> 01:18:27.980]   You know, he's in the amuse-bouche where he's like,
[01:18:27.980 --> 01:18:29.900]   oh, you know, guys, you gotta work harder.
[01:18:29.900 --> 01:18:32.260]   Hey guys, let's create some fancy acronyms.
[01:18:32.260 --> 01:18:33.940]   But Sundar's got courage.
[01:18:33.940 --> 01:18:35.020]   No, no, no, but he's got courage.
[01:18:35.020 --> 01:18:37.020]   He is gonna rip the bandaid off too.
[01:18:37.020 --> 01:18:40.000]   And so I think what it means is these three
[01:18:40.000 --> 01:18:41.940]   and maybe these four companies
[01:18:41.940 --> 01:18:44.260]   are gonna draw a hard line in the sand
[01:18:44.260 --> 01:18:48.060]   and say, we are not over-earning, do not abandon this stock.
[01:18:48.060 --> 01:18:51.860]   That again will help put in a bottom in the stock market.
[01:18:51.860 --> 01:18:52.900]   - What do you think, Freeberg?
[01:18:52.900 --> 01:18:55.380]   You worked at this company and you know,
[01:18:55.380 --> 01:18:58.420]   the principles across the board,
[01:18:58.420 --> 01:19:01.140]   the saber rattling will turn into saber swinging
[01:19:01.140 --> 01:19:03.900]   in Q4, Q1, you think?
[01:19:03.900 --> 01:19:04.740]   Google, Apple?
[01:19:04.740 --> 01:19:07.460]   Cuts coming?
[01:19:07.460 --> 01:19:11.900]   - Amazon is affected in a different way
[01:19:11.900 --> 01:19:14.780]   because they operate this physical supply chain business.
[01:19:14.780 --> 01:19:16.760]   They're delivering goods to people's homes
[01:19:16.760 --> 01:19:17.660]   that people are buying.
[01:19:17.660 --> 01:19:22.660]   So they're, they really have to change their trajectory
[01:19:22.980 --> 01:19:23.820]   very quickly.
[01:19:23.820 --> 01:19:24.660]   It was incredible.
[01:19:24.660 --> 01:19:26.480]   You guys remember when COVID hit,
[01:19:26.480 --> 01:19:27.900]   you tried to place an order on Amazon.
[01:19:27.900 --> 01:19:29.340]   It was like three weeks to deliver
[01:19:29.340 --> 01:19:31.180]   because the infrastructure wasn't there to do it.
[01:19:31.180 --> 01:19:33.980]   So they actually were seeing more orders
[01:19:33.980 --> 01:19:35.700]   than their system had predicted.
[01:19:35.700 --> 01:19:37.140]   And they did massive build out.
[01:19:37.140 --> 01:19:39.700]   They hired what, a million people or something
[01:19:39.700 --> 01:19:41.520]   in their network to meet demand.
[01:19:41.520 --> 01:19:43.500]   And then over the next year,
[01:19:43.500 --> 01:19:45.420]   earnings went through the roof,
[01:19:45.420 --> 01:19:47.420]   their infrastructure and employee headcount
[01:19:47.420 --> 01:19:48.260]   went through the roof.
[01:19:48.260 --> 01:19:49.620]   And now we're obviously coming back down
[01:19:49.620 --> 01:19:51.220]   the other side of a mountain
[01:19:51.220 --> 01:19:53.500]   and they're having to shift strategy
[01:19:53.500 --> 01:19:56.700]   and shift their operating model yet again.
[01:19:56.700 --> 01:19:58.940]   There's a broader set,
[01:19:58.940 --> 01:20:02.180]   and that's because they're in the direct commerce business.
[01:20:02.180 --> 01:20:07.180]   Microsoft, Google, and other kind of software companies,
[01:20:07.180 --> 01:20:09.520]   some of which benefit from advertising,
[01:20:09.520 --> 01:20:11.060]   which is almost like a first derivative
[01:20:11.060 --> 01:20:12.700]   on the consumer market,
[01:20:12.700 --> 01:20:15.340]   or a first derivative on the spending of companies
[01:20:15.340 --> 01:20:16.740]   that sell to consumers,
[01:20:16.740 --> 01:20:19.140]   have a little bit of a different calculus.
[01:20:19.140 --> 01:20:21.420]   They're a much higher margin business,
[01:20:21.420 --> 01:20:23.980]   30% EBITDA kind of business,
[01:20:23.980 --> 01:20:26.220]   with EBITDA margin business,
[01:20:26.220 --> 01:20:29.460]   with a very distinct kind of set of challenges
[01:20:29.460 --> 01:20:31.960]   on how advertising revenue is gonna be affected
[01:20:31.960 --> 01:20:33.580]   over the next couple of quarters
[01:20:33.580 --> 01:20:36.380]   and balancing that against their cloud platform,
[01:20:36.380 --> 01:20:38.660]   which is sold to enterprises
[01:20:38.660 --> 01:20:40.780]   and their media consumption platform,
[01:20:40.780 --> 01:20:43.300]   which is generally like YouTube at Google's case,
[01:20:43.300 --> 01:20:44.140]   which is less affected.
[01:20:44.140 --> 01:20:46.180]   So it's not as much of a direct calculus.
[01:20:46.180 --> 01:20:48.060]   I will say what's happened over the past decade,
[01:20:48.060 --> 01:20:49.660]   which we're now seeing change,
[01:20:49.660 --> 01:20:52.340]   is these companies have had extraordinary growth,
[01:20:52.340 --> 01:20:54.580]   hiring people to no end.
[01:20:54.580 --> 01:20:59.420]   There's always been kind of this extended expense
[01:20:59.420 --> 01:21:01.500]   on human capital.
[01:21:01.500 --> 01:21:03.380]   And that expense on human capital
[01:21:03.380 --> 01:21:06.660]   has driven the average cost per employee through the roof.
[01:21:06.660 --> 01:21:08.420]   And it's not just the salaries,
[01:21:08.420 --> 01:21:09.820]   it's the cost of the RSUs,
[01:21:09.820 --> 01:21:12.100]   it's the cost of the facilities and the free ice cream
[01:21:12.100 --> 01:21:13.880]   and the gyms and all the other stuff
[01:21:13.880 --> 01:21:15.620]   that's gone on to compete.
[01:21:15.620 --> 01:21:17.140]   That's now changing.
[01:21:17.140 --> 01:21:18.940]   And so it really is creating a different model
[01:21:18.940 --> 01:21:21.020]   for operating that hasn't existed for the last decade,
[01:21:21.020 --> 01:21:22.500]   where everything has been,
[01:21:22.500 --> 01:21:24.740]   how many more things can we throw in the kitchen,
[01:21:24.740 --> 01:21:26.500]   like the kitchen sink at this problem
[01:21:26.500 --> 01:21:28.220]   to get all the human capital here?
[01:21:28.220 --> 01:21:30.220]   And I think that's really,
[01:21:30.220 --> 01:21:32.620]   what's gonna kind of structurally change in the Valley.
[01:21:32.620 --> 01:21:35.060]   It's not as acute as what Amazon is dealing with.
[01:21:35.060 --> 01:21:38.420]   - It does feel like those are the last
[01:21:38.420 --> 01:21:41.420]   cities to fall to them off.
[01:21:41.420 --> 01:21:45.140]   - They are the ones that take the index to 3,200.
[01:21:45.140 --> 01:21:46.820]   If we're gonna try to do it,
[01:21:46.820 --> 01:21:48.020]   there's only one place to look,
[01:21:48.020 --> 01:21:49.700]   you've whacked everybody else.
[01:21:49.700 --> 01:21:54.700]   Everything is down 50 to 90% in some cases.
[01:21:54.700 --> 01:21:56.820]   - And then finally--
[01:21:56.820 --> 01:21:59.140]   - And by the way, sorry, just at the end of last year,
[01:21:59.140 --> 01:22:02.220]   a quarter of every S&P dollar was crowded in those names,
[01:22:02.220 --> 01:22:03.340]   a quarter.
[01:22:03.340 --> 01:22:05.220]   So you gotta go there.
[01:22:05.220 --> 01:22:07.540]   - Yeah, I mean, and also they're automatically bought,
[01:22:07.540 --> 01:22:09.500]   they're automatically bought by these index funds.
[01:22:09.500 --> 01:22:12.100]   And so who's at the wheel saying,
[01:22:12.100 --> 01:22:13.860]   we're gonna take the money out of them?
[01:22:13.860 --> 01:22:15.980]   Who in their right mind is taking money
[01:22:15.980 --> 01:22:19.220]   out of Apple, Amazon, and Microsoft, where do you put it?
[01:22:19.220 --> 01:22:20.900]   I guess is everybody's question, right, Shamal?
[01:22:20.900 --> 01:22:23.460]   If you take it out of there, where do you put it?
[01:22:23.460 --> 01:22:25.020]   - Well, no, I think it's just that
[01:22:25.020 --> 01:22:27.700]   when you have patterns of selling,
[01:22:27.700 --> 01:22:29.580]   typically as I've seen it,
[01:22:29.580 --> 01:22:32.180]   my experience is that initially it's the algorithms
[01:22:32.180 --> 01:22:35.980]   that really start to push a market in a direction.
[01:22:35.980 --> 01:22:40.500]   Then you have the more traditional fund complexes,
[01:22:40.500 --> 01:22:42.180]   that's the hedge funds and the long onlys,
[01:22:42.180 --> 01:22:44.140]   they follow suit.
[01:22:44.140 --> 01:22:46.700]   And then the last group tends to be retail.
[01:22:46.700 --> 01:22:50.940]   And it works in reverse the other way as well.
[01:22:50.940 --> 01:22:53.420]   And so, obviously there's exceptions to all of these,
[01:22:53.420 --> 01:22:54.860]   but as a general rule.
[01:22:54.860 --> 01:22:57.060]   - So if retail starts bailing on Amazon and Apple.
[01:22:57.060 --> 01:22:58.580]   - Well, they are right now.
[01:22:58.580 --> 01:23:00.300]   They are sellers now.
[01:23:00.300 --> 01:23:02.340]   - So now time to buy it.
[01:23:02.340 --> 01:23:05.900]   - But again, this is where sort of organized capital now
[01:23:05.900 --> 01:23:07.260]   is finding a bottom.
[01:23:07.260 --> 01:23:09.100]   Again, like when you start to shake,
[01:23:09.100 --> 01:23:11.940]   just think about the psychology of like being delivered
[01:23:11.940 --> 01:23:13.300]   bad news after bad news.
[01:23:13.300 --> 01:23:14.740]   You go through the cycles, right?
[01:23:14.740 --> 01:23:17.140]   There's denial, there's anger, there's depression,
[01:23:17.140 --> 01:23:20.260]   there's bargaining, but then at some point there's acceptance
[01:23:20.260 --> 01:23:22.660]   and in that acceptance phase, you're like,
[01:23:22.660 --> 01:23:25.140]   "Yeah, you're right, things are bad."
[01:23:25.140 --> 01:23:27.860]   But when you see a market rally into a print like this,
[01:23:27.860 --> 01:23:32.340]   it's really, really interesting psychological turning point.
[01:23:32.340 --> 01:23:35.500]   - As a proof point to what you're saying, Sax, Chamath,
[01:23:35.500 --> 01:23:37.340]   and Sax, I wanna get your comment on this.
[01:23:37.340 --> 01:23:41.020]   Venture capital firms like Sequoia, Excel and others
[01:23:41.020 --> 01:23:44.500]   that have now changed their status as just private companies
[01:23:44.500 --> 01:23:48.260]   but also dabbling in public are buying public equities,
[01:23:48.260 --> 01:23:52.260]   which basically means they see more opportunity
[01:23:52.260 --> 01:23:56.660]   in public underpriced tech stocks, growth stocks, et cetera,
[01:23:56.660 --> 01:24:00.860]   than they do in late stage private companies, correct?
[01:24:00.860 --> 01:24:01.940]   And you saw the Wall Street Journal story,
[01:24:01.940 --> 01:24:03.460]   I'm assuming, Sax?
[01:24:03.460 --> 01:24:04.700]   - Yeah, I saw that.
[01:24:04.700 --> 01:24:06.700]   - What's your read into that?
[01:24:06.700 --> 01:24:08.740]   Is it overblown or is it indicative of something?
[01:24:08.740 --> 01:24:10.140]   - I think it's probably overblown
[01:24:10.140 --> 01:24:12.900]   because Sequoia created that fund that is a hedge fund
[01:24:12.900 --> 01:24:15.300]   and Andreessen Horowitz became a registered
[01:24:15.300 --> 01:24:17.540]   investment advisor so they could buy public securities.
[01:24:17.540 --> 01:24:19.820]   So look, I don't think most venture funds
[01:24:19.820 --> 01:24:21.460]   are all of a sudden investing in public markets.
[01:24:21.460 --> 01:24:23.900]   We aren't even allowed to do that as far as I know,
[01:24:23.900 --> 01:24:25.460]   nor would we ever try to.
[01:24:25.460 --> 01:24:28.260]   So I think probably it's exaggerated.
[01:24:28.260 --> 01:24:30.860]   - You have to give up, Sax, your VC exemption,
[01:24:30.860 --> 01:24:31.780]   but you could do it.
[01:24:31.780 --> 01:24:32.620]   - You could do it, yeah.
[01:24:32.620 --> 01:24:33.940]   - Yeah, I mean, we wouldn't want to,
[01:24:33.940 --> 01:24:35.900]   but it's kind of the point.
[01:24:35.900 --> 01:24:38.700]   But look, I can't explain why the market
[01:24:38.700 --> 01:24:40.140]   did what it did today.
[01:24:40.140 --> 01:24:41.340]   It could have, like Jamal said,
[01:24:41.340 --> 01:24:43.820]   it could have been some sort of algorithmic
[01:24:43.820 --> 01:24:46.340]   buying or selling.
[01:24:46.340 --> 01:24:49.660]   But I just think that the overall news today
[01:24:49.660 --> 01:24:53.180]   was the economic news was just another really bad report.
[01:24:53.180 --> 01:24:54.540]   I mean, just look at these headlines
[01:24:54.540 --> 01:24:55.540]   from the New York Times today.
[01:24:55.540 --> 01:24:58.060]   Okay, I'm gonna read you the headlines
[01:24:58.060 --> 01:25:00.980]   on a single sort of scrolling page here.
[01:25:00.980 --> 01:25:03.540]   Number one, inflation came in much faster than expected.
[01:25:03.540 --> 01:25:05.180]   Bad news for the Fed.
[01:25:05.180 --> 01:25:08.020]   Takeaways from another painful inflation report.
[01:25:08.020 --> 01:25:09.740]   Three, disappointing inflation data
[01:25:09.740 --> 01:25:11.820]   keeps Democrats on defense ahead of midterm elections.
[01:25:11.820 --> 01:25:13.700]   Four, food prices climb again,
[01:25:13.700 --> 01:25:14.820]   weighing on household budgets.
[01:25:14.820 --> 01:25:18.100]   Five, rent inflation remained tepid, a troubling sign.
[01:25:18.100 --> 01:25:20.220]   Six, used car prices aren't declining
[01:25:20.220 --> 01:25:21.340]   as much as the economists of the hope.
[01:25:21.340 --> 01:25:23.260]   - Slow down, slow down. - Seven.
[01:25:23.260 --> 01:25:25.060]   - Give Freeberg a chance to take some Xanax.
[01:25:25.060 --> 01:25:25.900]   Take Xanax, Freeberg.
[01:25:25.900 --> 01:25:27.660]   - Yeah, gas prices fall slightly,
[01:25:27.660 --> 01:25:29.940]   but overall energy costs are soon expected to rise.
[01:25:29.940 --> 01:25:33.620]   And eight, retirees are getting an 8.7% social security cost
[01:25:33.620 --> 01:25:34.780]   living raise, the biggest in decades.
[01:25:34.780 --> 01:25:36.300]   I guess that one is sort of positive,
[01:25:36.300 --> 01:25:38.580]   but it's like literally negative headline
[01:25:38.580 --> 01:25:40.580]   after negative headline in the New York Times.
[01:25:40.580 --> 01:25:42.620]   - But can I reinterpret that for you?
[01:25:42.620 --> 01:25:44.700]   I think the way to think about it is
[01:25:44.700 --> 01:25:47.140]   this gives the Fed the resolve it needs.
[01:25:47.140 --> 01:25:48.540]   It's gonna go by 75.
[01:25:48.540 --> 01:25:50.620]   It's probably gonna go another 75.
[01:25:50.620 --> 01:25:54.100]   We're gonna have rates by four to 450 to 5%,
[01:25:54.100 --> 01:25:56.860]   probably within Q1, which means if you're trying
[01:25:56.860 --> 01:25:59.820]   to figure out where the bottom is, it's roughly now-ish.
[01:25:59.820 --> 01:26:01.460]   And so that's why you see smart money,
[01:26:01.460 --> 01:26:03.340]   David, shaking this thing off
[01:26:03.340 --> 01:26:05.260]   and starting to enter the market.
[01:26:05.260 --> 01:26:08.580]   And so again, and the other version interpretation is
[01:26:08.580 --> 01:26:10.540]   when rates are four or 5%,
[01:26:10.540 --> 01:26:13.020]   the cost of servicing United States debt
[01:26:13.020 --> 01:26:15.780]   is so meaningful as a percentage of their budget,
[01:26:15.780 --> 01:26:18.540]   the incremental spend that they would need to make
[01:26:18.540 --> 01:26:21.660]   to enter a new war is too much, I think.
[01:26:21.660 --> 01:26:22.500]   - I love this point.
[01:26:22.500 --> 01:26:23.340]   I love this point.
[01:26:23.340 --> 01:26:25.380]   We're weaving all these things together.
[01:26:25.380 --> 01:26:27.740]   Do we want, I mean- - Yeah, well, look.
[01:26:27.740 --> 01:26:30.940]   Right, so on the economics page of the New York Times,
[01:26:30.940 --> 01:26:33.100]   it's just disastrous headline after disastrous headline.
[01:26:33.100 --> 01:26:34.420]   Then you turn to the foreign policy page,
[01:26:34.420 --> 01:26:37.500]   you got Tom Friedman writing a column here saying,
[01:26:37.500 --> 01:26:39.780]   "We are suddenly taking on China and Russia at the same time."
[01:26:39.780 --> 01:26:42.500]   And Tom Friedman historically has been a huge hawk.
[01:26:42.500 --> 01:26:45.580]   And he is even saying- - He's saying pump the brakes.
[01:26:45.580 --> 01:26:46.620]   - Yeah, pump on the brakes.
[01:26:46.620 --> 01:26:49.220]   Never fight Russia and China at the same time.
[01:26:49.220 --> 01:26:52.020]   So he says, "We are in uncharted waters.
[01:26:52.020 --> 01:26:54.060]   I just hope these are not our new forever wars."
[01:26:54.060 --> 01:26:55.340]   It's like, whoa.
[01:26:55.340 --> 01:26:57.540]   So basically, look, our economic base,
[01:26:57.540 --> 01:27:00.640]   our economy is crumbling at home at the same time
[01:27:00.640 --> 01:27:03.580]   that we are doing unprecedented saber-rattling abroad.
[01:27:03.580 --> 01:27:05.060]   This does not compute.
[01:27:05.060 --> 01:27:06.980]   We need to take a time out here.
[01:27:06.980 --> 01:27:07.820]   - My prediction, I agree with you.
[01:27:07.820 --> 01:27:08.860]   - No mention of Iran?
[01:27:08.860 --> 01:27:12.900]   - But my prediction is that we will not enter a new war
[01:27:12.900 --> 01:27:15.980]   with rates flexing up as aggressively as they are.
[01:27:15.980 --> 01:27:16.800]   - I love it.
[01:27:16.800 --> 01:27:17.860]   I love weaving these two stories together.
[01:27:17.860 --> 01:27:19.740]   I think it makes a lot of sense.
[01:27:19.740 --> 01:27:21.540]   We didn't have time for Alex Jones,
[01:27:21.540 --> 01:27:22.780]   but we'll save that for another episode.
[01:27:22.780 --> 01:27:24.620]   Gentlemen, I think it's our best episode ever.
[01:27:24.620 --> 01:27:27.300]   It's an honor and a privilege to spend this hour or so
[01:27:27.300 --> 01:27:28.140]   with you every week.
[01:27:28.140 --> 01:27:29.940]   I love you like brothers.
[01:27:29.940 --> 01:27:31.820]   And it's been a great 100 episodes.
[01:27:31.820 --> 01:27:33.780]   I look forward to 100 more.
[01:27:33.780 --> 01:27:35.740]   Sax, if you need a mental health break.
[01:27:35.740 --> 01:27:37.300]   Dr. Friedberg's a psychiatrist.
[01:27:37.300 --> 01:27:38.700]   He's got him doped up.
[01:27:38.700 --> 01:27:39.700]   - David will be back next Friday.
[01:27:39.700 --> 01:27:41.260]   I just want to say- - Turn off replies, David.
[01:27:41.260 --> 01:27:42.300]   Don't read your replies.
[01:27:42.300 --> 01:27:43.140]   Get off of that.
[01:27:43.140 --> 01:27:44.660]   - I just want to say how much I love you guys.
[01:27:44.660 --> 01:27:47.780]   And I'm really proud of what we've created.
[01:27:47.780 --> 01:27:50.080]   And I'm really excited to get to the next 100.
[01:27:50.080 --> 01:27:52.620]   And I'll see you guys tonight.
[01:27:52.620 --> 01:27:53.900]   I'll break out the white trumpet.
[01:27:53.900 --> 01:27:55.540]   - So you want to keep going?
[01:27:55.540 --> 01:27:56.700]   That's the news today?
[01:27:56.700 --> 01:27:58.460]   - I'm in for a hunty.
[01:27:58.460 --> 01:27:59.620]   I'm in for a hunty.
[01:27:59.620 --> 01:28:00.460]   I love you, Sax.
[01:28:00.460 --> 01:28:02.740]   - I will say that J.K. Hall's moderation's been
[01:28:02.740 --> 01:28:05.140]   a lot better since he got brigaded.
[01:28:05.140 --> 01:28:06.940]   - That is his way of saying he'll be,
[01:28:06.940 --> 01:28:08.260]   he'll see you next Friday.
[01:28:08.260 --> 01:28:09.100]   - He'll see you.
[01:28:09.100 --> 01:28:11.180]   - I love you guys. - It's been 100 episodes.
[01:28:11.180 --> 01:28:12.020]   I love you, Chamath.
[01:28:12.020 --> 01:28:12.840]   I love you, Friedberg.
[01:28:12.840 --> 01:28:15.100]   Let's see if we can get Sax to do it.
[01:28:15.100 --> 01:28:16.180]   It's been 100 episodes.
[01:28:16.180 --> 01:28:18.260]   He hasn't said it yet, but I love you, Sax.
[01:28:18.260 --> 01:28:19.420]   - David, are you coming tonight?
[01:28:19.420 --> 01:28:20.260]   Sax, are you coming tonight?
[01:28:20.260 --> 01:28:21.100]   - Yeah, I'll come.
[01:28:21.100 --> 01:28:22.340]   - You're coming? - Oh, wait, wait, wait.
[01:28:22.340 --> 01:28:23.180]   Let me check.
[01:28:23.180 --> 01:28:24.580]   I'll get back to you offline.
[01:28:24.580 --> 01:28:25.820]   - Jesus Christ, God, Jesus.
[01:28:25.820 --> 01:28:26.740]   - All right, but hold on a second.
[01:28:26.740 --> 01:28:27.580]   Hold on a second.
[01:28:27.580 --> 01:28:28.420]   Sax, I love you.
[01:28:28.420 --> 01:28:29.260]   Let's see if we can get him to say it.
[01:28:29.260 --> 01:28:30.100]   - Back at you.
[01:28:30.100 --> 01:28:31.540]   - Okay, I got him. - Sax, I love you.
[01:28:31.540 --> 01:28:32.380]   - Back at you.
[01:28:32.380 --> 01:28:33.200]   - That's two.
[01:28:33.200 --> 01:28:34.380]   Going around the horn.
[01:28:34.380 --> 01:28:35.220]   - Back at you.
[01:28:35.220 --> 01:28:36.660]   - Friedberg, can you say I love you too?
[01:28:36.660 --> 01:28:37.500]   Can you say I love you?
[01:28:37.500 --> 01:28:38.500]   - David, I love you. - Sax, I see you.
[01:28:38.500 --> 01:28:40.540]   I see you. - David, I love you.
[01:28:40.540 --> 01:28:41.860]   - What did you tell Coolio?
[01:28:41.860 --> 01:28:43.540]   - Friedberg, I love you. - I appreciate you.
[01:28:43.540 --> 01:28:44.460]   - Oh, you appreciate.
[01:28:44.460 --> 01:28:45.300]   Okay, we got him. - Chamath, I appreciate you.
[01:28:45.300 --> 01:28:46.940]   - We got him back at you, and I appreciate you.
[01:28:46.940 --> 01:28:48.540]   That's 100, baby. - You guys, I appreciate you.
[01:28:48.540 --> 01:28:49.380]   - That's 100.
[01:28:49.380 --> 01:28:50.220]   - See you at Florida. - Cal, I love you.
[01:28:50.220 --> 01:28:51.420]   - Episode two, I love you too, Chamath.
[01:28:51.420 --> 01:28:52.260]   I'll see you tonight. - Love you, Cal.
[01:28:52.260 --> 01:28:53.100]   - Bye, bye.
[01:28:53.100 --> 01:28:54.860]   ♪ I'm going all in ♪
[01:28:54.860 --> 01:28:57.580]   ♪ We'll let your winners ride ♪
[01:28:57.580 --> 01:28:59.460]   ♪ Rain Man, David Saxon ♪
[01:28:59.460 --> 01:29:01.940]   ♪ I'm going all in ♪
[01:29:01.940 --> 01:29:02.780]   ♪ And it said ♪
[01:29:02.780 --> 01:29:04.140]   ♪ We open sourced it to the fans ♪
[01:29:04.140 --> 01:29:06.020]   ♪ And they've just gone crazy with it ♪
[01:29:06.020 --> 01:29:08.100]   ♪ Love you, West, I'm the queen of quinoa ♪
[01:29:08.100 --> 01:29:10.940]   ♪ I'm going all in ♪
[01:29:10.940 --> 01:29:14.860]   ♪ We'll let your winners ride ♪
[01:29:14.860 --> 01:29:17.540]   ♪ Besties are gone ♪
[01:29:17.540 --> 01:29:22.540]   ♪ My dog taking a notice in your driveway ♪
[01:29:22.540 --> 01:29:25.220]   ♪ My avatar will meet me at the place ♪
[01:29:25.220 --> 01:29:26.260]   ♪ We should all just get a room ♪
[01:29:26.260 --> 01:29:27.860]   ♪ And just have one big huge orgy ♪
[01:29:27.860 --> 01:29:29.140]   ♪ 'Cause they're all just useless ♪
[01:29:29.140 --> 01:29:30.580]   ♪ It's like this like sexual tension ♪
[01:29:30.580 --> 01:29:33.220]   ♪ That they just need to release somehow ♪
[01:29:33.220 --> 01:29:36.060]   ♪ Wet your feet ♪
[01:29:36.060 --> 01:29:38.540]   ♪ Wet your feet ♪
[01:29:38.540 --> 01:29:39.380]   ♪ We need to get merch ♪
[01:29:39.380 --> 01:29:40.220]   ♪ Besties are gone ♪
[01:29:40.220 --> 01:29:43.220]   ♪ I'm going all in ♪
[01:29:43.220 --> 01:29:45.820]   (upbeat music)
[01:29:45.820 --> 01:29:50.860]   ♪ I'm going all in ♪
[01:29:50.860 --> 01:29:51.360]   you
[01:29:51.360 --> 01:29:53.420]   you

