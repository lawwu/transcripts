
[00:00:00.000 --> 00:00:03.080]   In this video, we're going to talk about one of the coolest
[00:00:03.080 --> 00:00:06.200]   applications of LSTMs, maybe the application that really
[00:00:06.200 --> 00:00:08.840]   justifies LSTMs' existence.
[00:00:08.840 --> 00:00:12.800]   And that is sequence-to-sequence models.
[00:00:12.800 --> 00:00:16.480]   It's also what Google now uses to do its translation system.
[00:00:16.480 --> 00:00:18.440]   They had an amazing blog post last year
[00:00:18.440 --> 00:00:20.120]   where they talked about replacing
[00:00:20.120 --> 00:00:23.600]   tons and tons of lines of code with a small sequence-to-sequence
[00:00:23.600 --> 00:00:28.920]   model that was just trained on lots and lots of data.
[00:00:28.920 --> 00:00:31.320]   So the canonical example-- not the only example,
[00:00:31.320 --> 00:00:32.860]   but the one people think of when they
[00:00:32.860 --> 00:00:36.760]   think of sequence-to-sequence models is translation.
[00:00:36.760 --> 00:00:38.840]   And I think if you haven't seen this before,
[00:00:38.840 --> 00:00:42.000]   you might even wonder, how do translation models work at all?
[00:00:42.000 --> 00:00:45.400]   So if I have input that says, my name is Lucas,
[00:00:45.400 --> 00:00:47.200]   that's an arbitrary length string.
[00:00:47.200 --> 00:00:50.800]   And then maybe I want as output the Japanese string,
[00:00:50.800 --> 00:00:53.680]   [SPEAKING JAPANESE]
[00:00:53.680 --> 00:00:55.400]   And that's a totally different length.
[00:00:55.400 --> 00:00:56.820]   In fact, it's a different language
[00:00:56.820 --> 00:00:58.200]   that doesn't even have spaces.
[00:00:58.200 --> 00:01:00.200]   So what's going on here?
[00:01:00.200 --> 00:01:02.720]   The API of machine learning, I keep telling you,
[00:01:02.720 --> 00:01:05.520]   is a sort of fixed-length input and fixed-length output.
[00:01:05.520 --> 00:01:08.840]   And here, neither the input nor the output is fixed-length.
[00:01:08.840 --> 00:01:12.080]   And I think because of that, it took a really long time
[00:01:12.080 --> 00:01:14.280]   to make really good translation models.
[00:01:14.280 --> 00:01:16.680]   But sequence-to-sequence absolutely nails this.
[00:01:16.680 --> 00:01:18.300]   So let's see how it works.
[00:01:18.300 --> 00:01:20.080]   And I'll give you a little bit of warning.
[00:01:20.080 --> 00:01:21.740]   There's actually a really funny blog post
[00:01:21.740 --> 00:01:23.080]   that we should definitely link to in the comments
[00:01:23.080 --> 00:01:25.280]   where it calls sequence-to-sequence the clown
[00:01:25.280 --> 00:01:26.640]   car of deep learning.
[00:01:26.640 --> 00:01:28.440]   And I think that sort of shows that this
[00:01:28.440 --> 00:01:31.200]   feels kind of counterintuitive at first,
[00:01:31.200 --> 00:01:34.280]   but it really does work super well with enough data.
[00:01:34.280 --> 00:01:36.720]   And I always look for kind of examples
[00:01:36.720 --> 00:01:39.480]   that would be fun for students, because a lot
[00:01:39.480 --> 00:01:40.980]   of these sequence-to-sequence models
[00:01:40.980 --> 00:01:44.480]   take massive amounts of data before they're interesting.
[00:01:44.480 --> 00:01:48.640]   And I actually found one in a set of Keras tutorials
[00:01:48.640 --> 00:01:50.920]   that I modified for this class.
[00:01:50.920 --> 00:01:55.240]   So in this case, our task is to do arithmetic,
[00:01:55.240 --> 00:01:57.560]   but with neural networks.
[00:01:57.560 --> 00:02:02.280]   So our input data is going to be a really simple equation.
[00:02:02.280 --> 00:02:04.560]   And then our output data is going
[00:02:04.560 --> 00:02:07.320]   to be the number that that equation solves to.
[00:02:07.320 --> 00:02:08.520]   So I'm talking really simple.
[00:02:08.520 --> 00:02:12.160]   It's going to be like 10 plus 12 as our input,
[00:02:12.160 --> 00:02:14.320]   and then our output is 22.
[00:02:14.320 --> 00:02:16.320]   What's kind of amazing here is we're
[00:02:16.320 --> 00:02:19.000]   going to treat this as a string-to-string translation
[00:02:19.000 --> 00:02:19.520]   problem.
[00:02:19.520 --> 00:02:22.960]   So the network has no idea what these symbols mean.
[00:02:22.960 --> 00:02:26.520]   It even has to learn that it should be outputting a number.
[00:02:26.520 --> 00:02:30.600]   So there's nothing that tells it it can't output 1 minus 4
[00:02:30.600 --> 00:02:33.520]   or 1, 4, minus, minus, minus.
[00:02:33.520 --> 00:02:35.360]   That would all be illegal in this case.
[00:02:35.360 --> 00:02:38.480]   But our input is going to be strings,
[00:02:38.480 --> 00:02:40.060]   and our output is going to be strings.
[00:02:40.060 --> 00:02:42.480]   And we're going to see if it can learn this task.
[00:02:42.480 --> 00:02:43.940]   The way it's going to work is we're
[00:02:43.940 --> 00:02:46.000]   going to take our character inputs,
[00:02:46.000 --> 00:02:49.480]   and we're going to put them in a character encoding.
[00:02:49.480 --> 00:02:52.000]   And we're going to pad out that encoding
[00:02:52.000 --> 00:02:56.000]   to be the length of the longest input.
[00:02:56.000 --> 00:03:00.880]   So because I think we have 12 or 13 possible characters here,
[00:03:00.880 --> 00:03:05.440]   the length of the encoded vector is going to be around 12 or 13
[00:03:05.440 --> 00:03:07.540]   with each cell in that vector corresponding
[00:03:07.540 --> 00:03:09.280]   to a different character that we have
[00:03:09.280 --> 00:03:11.520]   in our input and our output.
[00:03:11.520 --> 00:03:13.960]   And then we're going to feed that into our LSTM
[00:03:13.960 --> 00:03:18.640]   just like we saw in our text generation LSTM example.
[00:03:18.640 --> 00:03:23.080]   And that LSTM is going to output a single vector that's
[00:03:23.080 --> 00:03:28.320]   going to try to encode somehow the state of our input.
[00:03:28.320 --> 00:03:30.960]   And the length of that vector is a configurable parameter,
[00:03:30.960 --> 00:03:34.120]   like the hidden dimension of the LSTM.
[00:03:34.120 --> 00:03:35.720]   And we're going to take that vector,
[00:03:35.720 --> 00:03:38.320]   and we're going to do a layer we haven't seen before in Keras,
[00:03:38.320 --> 00:03:40.400]   which is called repeat vector, which basically takes
[00:03:40.400 --> 00:03:44.440]   that vector and uses it as input for every single step
[00:03:44.440 --> 00:03:47.720]   in the next layer in this network, which is another LSTM.
[00:03:47.720 --> 00:03:49.800]   And this is like our output LSTM.
[00:03:49.800 --> 00:03:53.280]   So this basically takes in a repeated vector as input,
[00:03:53.280 --> 00:03:55.880]   and then it tries to output a whole bunch
[00:03:55.880 --> 00:03:57.600]   of different numbers.
[00:03:57.600 --> 00:03:59.880]   So that's our output LSTM.
[00:03:59.880 --> 00:04:02.160]   And our output LSTM now is going to have to output
[00:04:02.160 --> 00:04:04.400]   every number in its system, and it's
[00:04:04.400 --> 00:04:08.360]   going to pass that into a time distributed dense layer.
[00:04:08.360 --> 00:04:09.680]   So what does that mean?
[00:04:09.680 --> 00:04:12.440]   We're basically going to take our dense layer, which
[00:04:12.440 --> 00:04:14.000]   you know, that's like a perceptron
[00:04:14.000 --> 00:04:15.600]   with multi-dimensional output.
[00:04:15.600 --> 00:04:17.720]   And in this case, the exact dimension of the output
[00:04:17.720 --> 00:04:19.400]   is going to be the number of characters
[00:04:19.400 --> 00:04:21.900]   that we have, because it's going to output one hot character
[00:04:21.900 --> 00:04:22.440]   encodings.
[00:04:22.440 --> 00:04:24.880]   But it's going to have to do that for each character
[00:04:24.880 --> 00:04:26.200]   that we want to output.
[00:04:26.200 --> 00:04:28.680]   So we're going to have to what's called time distribute
[00:04:28.680 --> 00:04:30.040]   the dense layer.
[00:04:30.040 --> 00:04:32.880]   And that means that we're going to make as many copies of it
[00:04:32.880 --> 00:04:33.960]   as we want outputs.
[00:04:33.960 --> 00:04:36.360]   So each one of these perceptrons is
[00:04:36.360 --> 00:04:38.200]   going to have the same set of parameters,
[00:04:38.200 --> 00:04:39.880]   but we're going to run it on each
[00:04:39.880 --> 00:04:43.240]   of the outputs of our output LSTM.
[00:04:43.240 --> 00:04:46.720]   And so finally, we're going to get a whole bunch of vectors
[00:04:46.720 --> 00:04:51.520]   where each vector corresponds to a character in our output.
[00:04:51.520 --> 00:04:53.800]   And then we're going to train this whole system
[00:04:53.800 --> 00:04:55.960]   in the same way that we train all the other systems.
[00:04:55.960 --> 00:05:00.320]   We're just trying to make our output as close as possible
[00:05:00.320 --> 00:05:03.520]   to the labeled output that's in our data set.
[00:05:03.520 --> 00:05:05.760]   And it's really easy for us to generate a lot of data
[00:05:05.760 --> 00:05:07.640]   for this quickly, because we can actually
[00:05:07.640 --> 00:05:10.080]   use a computer, even like a calculator,
[00:05:10.080 --> 00:05:11.760]   to do this really simple math.
[00:05:11.760 --> 00:05:14.040]   But we're going to convert these input and these output
[00:05:14.040 --> 00:05:16.880]   things into strings that our network is
[00:05:16.880 --> 00:05:19.720]   going to try to understand.
[00:05:19.720 --> 00:05:22.640]   So let's go to the code and see specifically how it works.
[00:05:22.640 --> 00:05:29.400]   OK, so in the code, go to ml class/videos/sequence
[00:05:29.400 --> 00:05:32.080]   to sequence.
[00:05:32.080 --> 00:05:34.280]   And then open up train.py.
[00:05:34.280 --> 00:05:36.680]   And this is some code that I got from an excellent blog
[00:05:36.680 --> 00:05:39.120]   post on the Keras blog, a 10-minute introduction
[00:05:39.120 --> 00:05:40.920]   to sequence to sequence learning in Keras,
[00:05:40.920 --> 00:05:42.300]   but I actually modified it to make
[00:05:42.300 --> 00:05:45.360]   a little bit more complicated and hopefully a little bit more
[00:05:45.360 --> 00:05:46.080]   understandable.
[00:05:46.080 --> 00:05:47.480]   But if you want to learn more, you
[00:05:47.480 --> 00:05:50.640]   should definitely go to that blog post also.
[00:05:50.640 --> 00:05:52.560]   So as usual, the first couple lines
[00:05:52.560 --> 00:05:54.760]   are just import statements and setting up
[00:05:54.760 --> 00:05:59.280]   W and B so that we can get a log of our training.
[00:05:59.280 --> 00:06:01.580]   And then this code defines what's
[00:06:01.580 --> 00:06:03.120]   called a character table.
[00:06:03.120 --> 00:06:05.040]   And really, this is just a convenience wrapper
[00:06:05.040 --> 00:06:08.440]   to make it easy to encode these integers
[00:06:08.440 --> 00:06:09.960]   and then decode these integers.
[00:06:09.960 --> 00:06:12.520]   So it basically gives us an encode function
[00:06:12.520 --> 00:06:15.160]   that does a one-hot encoding of a given string,
[00:06:15.160 --> 00:06:18.040]   and then a decode that takes an output from, say,
[00:06:18.040 --> 00:06:20.640]   our neural network and writes it out as a string
[00:06:20.640 --> 00:06:23.800]   that we can understand.
[00:06:23.800 --> 00:06:26.920]   So lines 44, 45, 46, and 47 are basically
[00:06:26.920 --> 00:06:28.320]   configuration parameters.
[00:06:28.320 --> 00:06:30.840]   And one important one here is training size.
[00:06:30.840 --> 00:06:33.500]   So that's how many training data points we're going to generate.
[00:06:33.500 --> 00:06:35.840]   And we could generate more if we wanted to.
[00:06:35.840 --> 00:06:38.360]   But this is going to be our complete data set when
[00:06:38.360 --> 00:06:40.200]   we train our model.
[00:06:40.200 --> 00:06:43.320]   And then digits corresponds to the longest digit
[00:06:43.320 --> 00:06:45.120]   that we're going to allow in our input.
[00:06:45.120 --> 00:06:50.280]   So we're going to have up to five digit inputs.
[00:06:50.280 --> 00:06:52.400]   And because we're only going to do plus and minus
[00:06:52.400 --> 00:06:56.200]   in this example, the maximum length of our input
[00:06:56.200 --> 00:06:59.080]   is two times the maximum size of digits plus one.
[00:06:59.080 --> 00:07:02.480]   Because you could have maybe 10,000 plus 10,000
[00:07:02.480 --> 00:07:05.280]   would be an example of the longest possible input that's
[00:07:05.280 --> 00:07:07.000]   allowed.
[00:07:07.000 --> 00:07:09.280]   And then line 54, we basically write down
[00:07:09.280 --> 00:07:10.360]   all the characters we have.
[00:07:10.360 --> 00:07:13.080]   So this is all the digits plus a plus and a minus,
[00:07:13.080 --> 00:07:15.960]   and then also a space for padding.
[00:07:15.960 --> 00:07:17.840]   And then we initialize our character table
[00:07:17.840 --> 00:07:21.200]   with those characters.
[00:07:21.200 --> 00:07:25.080]   Now, line 57 through 79 basically
[00:07:25.080 --> 00:07:28.520]   automatically generates these input and output strings.
[00:07:28.520 --> 00:07:32.680]   So we're basically calculating very, very simple arithmetic,
[00:07:32.680 --> 00:07:35.240]   like 10 plus 12 equals 22.
[00:07:35.240 --> 00:07:37.280]   And we're randomly generating these numbers
[00:07:37.280 --> 00:07:40.520]   and then recording the output.
[00:07:40.520 --> 00:07:43.680]   And then lines 84 through 89 take that output,
[00:07:43.680 --> 00:07:46.800]   and it encodes them into x and y.
[00:07:46.800 --> 00:07:49.920]   It basically one-hot encodes them into these vectors
[00:07:49.920 --> 00:07:52.080]   that we need to use for input and output
[00:07:52.080 --> 00:07:53.040]   into our neural network.
[00:07:53.040 --> 00:08:01.680]   Lines 93 through 96 basically shuffle the x and y.
[00:08:01.680 --> 00:08:05.120]   And then lines 99 through 101 does a test train split,
[00:08:05.120 --> 00:08:08.560]   and in this case, we use 90% of the data as training data
[00:08:08.560 --> 00:08:13.320]   and 10% of the data as validation data.
[00:08:13.320 --> 00:08:14.960]   Now, here we set up our model, and it
[00:08:14.960 --> 00:08:17.400]   should be just like the diagram that I outlined,
[00:08:17.400 --> 00:08:19.200]   but here it is in Keras code.
[00:08:19.200 --> 00:08:20.920]   So it's a sequential model.
[00:08:20.920 --> 00:08:24.800]   Line 104 sets up the encoding LSTM,
[00:08:24.800 --> 00:08:27.760]   and this has a hidden size configuration
[00:08:27.760 --> 00:08:31.440]   for the number of outputs of its state.
[00:08:31.440 --> 00:08:33.360]   And you could definitely play with this.
[00:08:33.360 --> 00:08:37.120]   Line 105 is a new type of layer, the repeat vector layer,
[00:08:37.120 --> 00:08:39.560]   which basically takes the output of this LSTM
[00:08:39.560 --> 00:08:41.720]   and makes copies of it, enough copies
[00:08:41.720 --> 00:08:46.600]   to feed in to the next LSTM down.
[00:08:46.600 --> 00:08:49.280]   And this LSTM is actually going to try to output
[00:08:49.280 --> 00:08:51.680]   the digits that we want.
[00:08:51.680 --> 00:08:53.880]   So we actually have to set return sequences
[00:08:53.880 --> 00:08:57.440]   equals to true, which is something you might remember
[00:08:57.440 --> 00:08:59.040]   from a previous video, which makes it
[00:08:59.040 --> 00:09:01.560]   so the LSTM doesn't just output its final state,
[00:09:01.560 --> 00:09:04.720]   but outputs every intermediate output state.
[00:09:04.720 --> 00:09:06.640]   And we need this because in this case,
[00:09:06.640 --> 00:09:08.480]   we're not just trying to classify something.
[00:09:08.480 --> 00:09:11.680]   We're trying to output an entire sequence of digits
[00:09:11.680 --> 00:09:15.320]   corresponding to the answer.
[00:09:15.320 --> 00:09:18.200]   Then in line 107, we take a dense layer,
[00:09:18.200 --> 00:09:20.200]   and the dense layer outputs a vector
[00:09:20.200 --> 00:09:22.120]   of the length of the number of characters
[00:09:22.120 --> 00:09:24.680]   because we can interpret this as essentially
[00:09:24.680 --> 00:09:28.120]   a one-hot encoded answer to what character
[00:09:28.120 --> 00:09:29.360]   occurs in each position.
[00:09:29.360 --> 00:09:30.900]   And we set our activation to softmax,
[00:09:30.900 --> 00:09:33.960]   because really this is a classification problem,
[00:09:33.960 --> 00:09:37.240]   in the sense we're classifying what we want each digit to be
[00:09:37.240 --> 00:09:38.920]   in our output.
[00:09:38.920 --> 00:09:41.520]   And then we add this time distributed wrapper.
[00:09:41.520 --> 00:09:43.320]   And what that does is it basically
[00:09:43.320 --> 00:09:46.640]   makes essentially the same dense layer,
[00:09:46.640 --> 00:09:49.080]   but on different input for each one of the outputs
[00:09:49.080 --> 00:09:49.640]   that we want.
[00:09:49.640 --> 00:09:54.760]   So in line 108, we compile our network.
[00:09:54.760 --> 00:09:56.600]   And actually, this should be super familiar.
[00:09:56.600 --> 00:09:58.920]   We can use the familiar categorical cross entropy
[00:09:58.920 --> 00:10:01.340]   that we always use when we're doing a classification.
[00:10:01.340 --> 00:10:02.700]   We can set the optimizer to atom.
[00:10:02.700 --> 00:10:04.620]   And of course, you can try other ones.
[00:10:04.620 --> 00:10:07.940]   And then we set metrics equals to accuracy.
[00:10:07.940 --> 00:10:09.620]   And what this is going to do is actually
[00:10:09.620 --> 00:10:12.940]   tell us the digit by digit accuracy of this network,
[00:10:12.940 --> 00:10:14.900]   as opposed to the accuracy of the entire thing.
[00:10:14.900 --> 00:10:16.520]   So you might expect the accuracy to be
[00:10:16.520 --> 00:10:19.500]   how often did it get the right answer for the equation
[00:10:19.500 --> 00:10:20.380]   that we put in.
[00:10:20.380 --> 00:10:21.760]   But actually, this is going to be
[00:10:21.760 --> 00:10:25.780]   how often do we get any particular digit correct.
[00:10:25.780 --> 00:10:28.500]   So lines 115 through 138, really what it does
[00:10:28.500 --> 00:10:30.220]   is it fits the model.
[00:10:30.220 --> 00:10:32.740]   And then it outputs some sample of the model data.
[00:10:32.740 --> 00:10:34.060]   So it's just kind of for fun.
[00:10:34.060 --> 00:10:35.680]   But we kind of want to see exactly what
[00:10:35.680 --> 00:10:37.900]   this network is outputting.
[00:10:37.900 --> 00:10:41.060]   So there's just a little bit of simple code
[00:10:41.060 --> 00:10:42.940]   that fits the network.
[00:10:42.940 --> 00:10:44.420]   And then in each step--
[00:10:44.420 --> 00:10:47.020]   so it fits it on one epoch at a time.
[00:10:47.020 --> 00:10:50.180]   And then each step outputs what the network would have said
[00:10:50.180 --> 00:10:52.500]   on a random set of data.
[00:10:52.500 --> 00:10:54.220]   So hopefully, that made sense.
[00:10:54.220 --> 00:10:55.300]   Let's try running the code.
[00:10:56.300 --> 00:10:58.740]   [AUDIO OUT]
[00:10:58.740 --> 00:11:06.580]   Here we are on iteration 22.
[00:11:06.580 --> 00:11:08.700]   And it actually got one of these digits--
[00:11:08.700 --> 00:11:10.360]   or one of these equations exactly right.
[00:11:10.360 --> 00:11:14.140]   So it knows that 3 minus 39 is negative 36.
[00:11:14.140 --> 00:11:15.900]   And it got the other ones wrong.
[00:11:15.900 --> 00:11:17.520]   But you can see that it's really close.
[00:11:17.520 --> 00:11:20.540]   It's almost close in a way that a human would be close.
[00:11:20.540 --> 00:11:27.820]   So it thinks that 49 minus 95,731 is negative 95,663,
[00:11:27.820 --> 00:11:32.420]   where the right answer is negative 95,682.
[00:11:32.420 --> 00:11:34.220]   So I think that's kind of amazing.
[00:11:34.220 --> 00:11:36.780]   This network almost feels like it's learning in some sense,
[00:11:36.780 --> 00:11:39.580]   maybe if we're getting a little wild here like a human being
[00:11:39.580 --> 00:11:41.780]   or something.
[00:11:41.780 --> 00:11:44.740]   And actually, I do know that if you run this network for longer,
[00:11:44.740 --> 00:11:46.160]   it gets higher and higher accuracy.
[00:11:46.160 --> 00:11:50.380]   In fact, it already has about 70% digit level accuracy,
[00:11:50.380 --> 00:11:53.180]   which is feeling pretty good.
[00:11:53.180 --> 00:11:55.300]   And one of the really cool things that you can do
[00:11:55.300 --> 00:11:57.300]   is you can take this code and you can modify it.
[00:11:57.300 --> 00:11:59.220]   So the simple modifications might
[00:11:59.220 --> 00:12:02.500]   be one to make this task a little bit harder.
[00:12:02.500 --> 00:12:04.380]   So you could add in multiplication.
[00:12:04.380 --> 00:12:06.500]   You could add in multiple additions,
[00:12:06.500 --> 00:12:07.980]   maybe put in parentheses.
[00:12:07.980 --> 00:12:10.060]   I think that would be a super interesting challenge
[00:12:10.060 --> 00:12:12.860]   to see how well the network can learn more complicated
[00:12:12.860 --> 00:12:14.540]   algebra.
[00:12:14.540 --> 00:12:16.220]   Some ways to improve the network are
[00:12:16.220 --> 00:12:18.900]   things that you might have seen in some of the previous videos
[00:12:18.900 --> 00:12:19.420]   that we've done.
[00:12:19.420 --> 00:12:20.980]   So I think a bidirectional network
[00:12:20.980 --> 00:12:22.580]   could be really effective here.
[00:12:22.580 --> 00:12:24.300]   If you make this thing more complicated,
[00:12:24.300 --> 00:12:26.820]   you might even want to multilayer LSTM,
[00:12:26.820 --> 00:12:28.500]   although you better be patient if you
[00:12:28.500 --> 00:12:33.700]   put in multiple LSTMs as the encoding or the decoding.
[00:12:33.700 --> 00:12:35.620]   And then finally, what's really cool
[00:12:35.620 --> 00:12:37.900]   is you can take this exact code and you
[00:12:37.900 --> 00:12:41.300]   can apply it to other sequence-to-sequence translation
[00:12:41.300 --> 00:12:41.860]   scenarios.
[00:12:41.860 --> 00:12:44.300]   So if you have what's called a parallel corpus,
[00:12:44.300 --> 00:12:46.220]   if you have examples of sentences
[00:12:46.220 --> 00:12:48.540]   in, say, English and Japanese, you
[00:12:48.540 --> 00:12:51.940]   can feed them in two at a time into this network.
[00:12:51.940 --> 00:12:53.400]   And you can see if it can learn it.
[00:12:53.400 --> 00:12:55.460]   And in the Keras blog post, they actually
[00:12:55.460 --> 00:12:57.580]   do show that they can learn simple translations
[00:12:57.580 --> 00:13:01.220]   from English to French with exactly the same architecture
[00:13:01.220 --> 00:13:03.580]   and almost exactly the same code, which I just
[00:13:03.580 --> 00:13:05.420]   think is the coolest thing.
[00:13:05.420 --> 00:13:08.060]   In future videos, we'll get more advanced here.
[00:13:08.060 --> 00:13:10.180]   We'll maybe even learn how to go from images
[00:13:10.180 --> 00:13:13.460]   to captions and other kind of more exotic sequence-to-sequence
[00:13:13.460 --> 00:13:14.540]   translations.
[00:13:14.540 --> 00:13:16.420]   But for now, if you do anything cool,
[00:13:16.420 --> 00:13:18.040]   please put it in the comments because I
[00:13:18.040 --> 00:13:22.100]   think there's so much to expand on in this framework.

