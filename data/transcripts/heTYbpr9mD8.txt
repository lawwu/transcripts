
[00:00:00.000 --> 00:00:02.240]   Hi, welcome to this video.
[00:00:02.240 --> 00:00:06.800]   So this is the third video in our Transformers
[00:00:06.800 --> 00:00:10.400]   from Scratch miniseries.
[00:00:10.400 --> 00:00:14.480]   And in the last two videos, we basically
[00:00:14.480 --> 00:00:18.480]   got a load of data and trained our tokenizer, which
[00:00:18.480 --> 00:00:20.880]   is what you can see here.
[00:00:20.880 --> 00:00:24.520]   So I'm going to have to rerun these.
[00:00:29.080 --> 00:00:33.560]   And we just tokenize some Italian.
[00:00:33.560 --> 00:00:39.040]   So this is a Italian BERT model, Roberta model.
[00:00:39.040 --> 00:00:41.520]   So we can write something like this,
[00:00:41.520 --> 00:00:43.780]   which means, hello, how are you?
[00:00:43.780 --> 00:00:48.520]   And it will tokenize our text here.
[00:00:48.520 --> 00:00:51.000]   Now, this is where we got to.
[00:00:51.000 --> 00:00:55.400]   What we now want to do is build out a input pipeline
[00:00:55.400 --> 00:00:56.960]   and train a model.
[00:00:56.960 --> 00:01:03.200]   Now, this is reasonably, I would say, involved,
[00:01:03.200 --> 00:01:07.520]   because we need to do a few things.
[00:01:07.520 --> 00:01:13.640]   First thing is we need three different tensors
[00:01:13.640 --> 00:01:14.400]   in our model here.
[00:01:14.400 --> 00:01:17.920]   We need the input IDs and attention mask.
[00:01:17.920 --> 00:01:21.200]   We also need the labels tensor as well.
[00:01:21.200 --> 00:01:24.000]   So the labels tensor is actually just
[00:01:24.000 --> 00:01:28.320]   going to be our input IDs as they are at the moment.
[00:01:28.320 --> 00:01:30.640]   But our input IDs are not going to be that.
[00:01:30.640 --> 00:01:34.760]   Our input IDs, they need to be passed
[00:01:34.760 --> 00:01:38.400]   through a mass language modeling script, which
[00:01:38.400 --> 00:01:44.280]   will mask around 15% of the tokens within that tensor.
[00:01:44.280 --> 00:01:47.080]   And then whilst we're training, our model
[00:01:47.080 --> 00:01:49.560]   is essentially going to try and guess
[00:01:49.560 --> 00:01:52.280]   what those masked tokens are.
[00:01:52.280 --> 00:01:54.280]   And we'll optimize the model using
[00:01:54.280 --> 00:01:58.200]   the loss between the guesses that the model outputs
[00:01:58.200 --> 00:02:05.160]   from the input IDs and the real values that are our labels.
[00:02:05.160 --> 00:02:11.720]   So that's essentially how it's going to work.
[00:02:11.720 --> 00:02:13.840]   I suppose it's a lot easier said than done.
[00:02:13.840 --> 00:02:18.120]   So first thing we're going to do is create our mass language
[00:02:18.120 --> 00:02:20.600]   modeling function.
[00:02:20.600 --> 00:02:24.760]   If you have watched some of my videos before,
[00:02:24.760 --> 00:02:30.680]   we quite recently did, I think, two videos, maybe two videos
[00:02:30.680 --> 00:02:32.960]   on mass language modeling.
[00:02:32.960 --> 00:02:35.440]   I'll leave a link to those in the description
[00:02:35.440 --> 00:02:38.080]   because the code is pretty much the same as what
[00:02:38.080 --> 00:02:39.200]   we cover there.
[00:02:39.200 --> 00:02:46.080]   And I will cover it very quickly here, but not too in-depth.
[00:02:46.080 --> 00:02:50.320]   So if you're interested, those links
[00:02:50.320 --> 00:02:53.920]   will be there in the description.
[00:02:53.920 --> 00:02:59.360]   So the very first thing we need to do, which I haven't done
[00:02:59.360 --> 00:03:03.360]   yet, is import torch.
[00:03:03.360 --> 00:03:07.120]   So we're using PyTorch here.
[00:03:07.120 --> 00:03:11.760]   And we need to create a random array.
[00:03:11.760 --> 00:03:14.800]   So we write torch rand.
[00:03:14.800 --> 00:03:17.560]   And this random array needs to be in the same shape
[00:03:17.560 --> 00:03:20.400]   as our tensor that we've input up here.
[00:03:20.400 --> 00:03:25.120]   So let's write tensor dot shape.
[00:03:25.120 --> 00:03:32.200]   And then we want to mass around 15% of those.
[00:03:32.200 --> 00:03:40.040]   So to do that, we can use rand, where rand is less than 0.15.
[00:03:40.040 --> 00:03:43.560]   Because what we've created here is
[00:03:43.560 --> 00:03:46.720]   an array in the shape of our input tensor, which
[00:03:46.720 --> 00:03:50.480]   is going to be our input IDs, where every value is
[00:03:50.480 --> 00:03:55.160]   within the range of 0 to 1.
[00:03:55.160 --> 00:03:56.400]   And that's completely random.
[00:03:56.400 --> 00:04:00.280]   So that means there should be--
[00:04:00.280 --> 00:04:03.640]   or for each token, there's a roughly 15% chance
[00:04:03.640 --> 00:04:06.920]   of that value being under 0.15.
[00:04:06.920 --> 00:04:14.280]   So that's our first criteria for our random masking array.
[00:04:14.280 --> 00:04:19.680]   The roughly 15% can call this mask array as well.
[00:04:19.680 --> 00:04:21.440]   But there's a few other criteria as well.
[00:04:21.440 --> 00:04:25.720]   And again, I covered that in the other videos.
[00:04:25.720 --> 00:04:30.680]   But in short, we don't want to mask special tokens.
[00:04:30.680 --> 00:04:33.200]   So we can see up here we have two special tokens.
[00:04:33.200 --> 00:04:35.160]   If we add padding--
[00:04:35.160 --> 00:04:37.920]   so I'm just going to add a little bit of padding,
[00:04:37.920 --> 00:04:38.680]   not loads.
[00:04:38.680 --> 00:04:40.960]   Let's go max length 10.
[00:04:40.960 --> 00:04:44.840]   And we write padding equals max length.
[00:04:44.840 --> 00:04:48.000]   If we do that, we get these extra ones here.
[00:04:48.000 --> 00:04:49.440]   They're our padding tokens.
[00:04:49.440 --> 00:04:51.480]   So we basically want to say we don't
[00:04:51.480 --> 00:04:55.600]   want to mask our 0's, 2's, or 1's,
[00:04:55.600 --> 00:04:58.520]   because they're special tokens that we don't want to mask.
[00:04:58.520 --> 00:05:06.000]   So we also just put where tensor is not equal to 0.
[00:05:06.000 --> 00:05:08.760]   And let's just copy that.
[00:05:08.760 --> 00:05:11.160]   It's a little bit easier.
[00:05:11.160 --> 00:05:12.640]   And also not equal to 1.
[00:05:12.640 --> 00:05:14.880]   And it will also not be equal to 2.
[00:05:14.880 --> 00:05:23.320]   And I do wonder if--
[00:05:23.320 --> 00:05:25.480]   yeah, we could make that a bit nicer.
[00:05:25.480 --> 00:05:28.680]   So if we just do--
[00:05:28.680 --> 00:05:32.160]   so you can either do this, where you specify each token.
[00:05:32.160 --> 00:05:34.760]   And you will want to do that sometimes, maybe,
[00:05:34.760 --> 00:05:37.280]   like with BERT, because your special tokens are
[00:05:37.280 --> 00:05:42.280]   in the range of, like, 100, 0, 101, and so on.
[00:05:42.280 --> 00:05:43.520]   There's a few different ones.
[00:05:43.520 --> 00:05:45.040]   But because we've got everything,
[00:05:45.040 --> 00:05:48.760]   it's either 2 or below, we could just write this.
[00:05:48.760 --> 00:05:54.680]   So we could say where it is not or where it is greater than 2.
[00:05:54.680 --> 00:05:57.480]   So this is like an AND statement saying,
[00:05:57.480 --> 00:06:02.840]   we're going to mask tokens that have a randomly generated
[00:06:02.840 --> 00:06:04.640]   value of less than 0.15.
[00:06:04.640 --> 00:06:08.120]   That's our 15% criteria.
[00:06:08.120 --> 00:06:10.440]   And they're not a special token, e.g.,
[00:06:10.440 --> 00:06:12.640]   they are greater than the value 2,
[00:06:12.640 --> 00:06:17.120]   because our special tokens are 0, 1, and 2.
[00:06:17.120 --> 00:06:18.320]   So that's cool.
[00:06:18.320 --> 00:06:25.600]   And now what we want to do is loop through each row
[00:06:25.600 --> 00:06:26.760]   in our tensor.
[00:06:26.760 --> 00:06:35.520]   So we want to do for i in range tensor dot shape 0.
[00:06:35.520 --> 00:06:38.040]   So this is how many rows we have in our tensor.
[00:06:38.040 --> 00:06:40.440]   And we can't do this in parallel,
[00:06:40.440 --> 00:06:44.840]   because each row is going to have a different number
[00:06:44.840 --> 00:06:47.320]   of tokens that will be masked.
[00:06:47.320 --> 00:06:49.600]   So if we did this in parallel, we
[00:06:49.600 --> 00:06:52.640]   end up trying to fit different size rows
[00:06:52.640 --> 00:06:55.200]   into an equally sized tensor.
[00:06:55.200 --> 00:06:57.560]   So we can't do that.
[00:06:57.560 --> 00:07:02.680]   Again, if this is confusing, I have those videos.
[00:07:02.680 --> 00:07:08.040]   But I mean, you don't need to specifically know everything
[00:07:08.040 --> 00:07:09.560]   that's going on here.
[00:07:09.560 --> 00:07:14.600]   This is just how we mask those roughly 15% of tokens.
[00:07:14.600 --> 00:07:20.720]   So we want torch flatten.
[00:07:20.720 --> 00:07:23.800]   And this bit is a bit confusing.
[00:07:23.800 --> 00:07:28.800]   But we want to take the mask array at the current position.
[00:07:28.800 --> 00:07:30.960]   I want to say where it's not 0.
[00:07:30.960 --> 00:07:34.240]   So when we create this mask array,
[00:07:34.240 --> 00:07:37.880]   we essentially get a load of true or false values
[00:07:37.880 --> 00:07:41.760]   in the size of our tensor shape.
[00:07:41.760 --> 00:07:46.760]   Where we have 1s, that is a mask.
[00:07:46.760 --> 00:07:48.800]   And what we're doing here is we're saying,
[00:07:48.800 --> 00:07:52.520]   get me a list of all the values that are not 0,
[00:07:52.520 --> 00:07:54.160]   which are 1s.
[00:07:54.160 --> 00:07:58.520]   And that gives us a list within a list.
[00:07:58.520 --> 00:07:59.760]   So we get something like this.
[00:07:59.760 --> 00:08:06.440]   And it will say, indices 2, 4, 18.
[00:08:06.440 --> 00:08:07.520]   I don't know why I said 4.
[00:08:07.520 --> 00:08:08.560]   It's 5.
[00:08:08.560 --> 00:08:11.280]   2, 5, 18.
[00:08:11.280 --> 00:08:14.440]   They are where your mask tokens will be.
[00:08:14.440 --> 00:08:19.960]   And then we use torch flatten here to remove that outer list.
[00:08:19.960 --> 00:08:23.440]   And at the end here, we're going to convert to a list
[00:08:23.440 --> 00:08:28.240]   so that we can do some fancy indexing in a moment.
[00:08:28.240 --> 00:08:30.480]   And that fancy indexing looks like this.
[00:08:30.480 --> 00:08:31.800]   So we have our tensor.
[00:08:31.800 --> 00:08:34.800]   We're specifying the current row.
[00:08:34.800 --> 00:08:37.400]   So we're going row at a time.
[00:08:37.400 --> 00:08:42.480]   And then we want to specify that selected number of indices,
[00:08:42.480 --> 00:08:46.880]   which are where we're going to place our mask.
[00:08:46.880 --> 00:08:51.360]   Now, what does the mask token look like?
[00:08:51.360 --> 00:09:04.680]   Well, we can actually find it over here in our vocab.json.
[00:09:04.680 --> 00:09:06.000]   Yeah.
[00:09:06.000 --> 00:09:11.120]   So scroll to the top, and we see our mappings here.
[00:09:11.120 --> 00:09:15.000]   So the mask token is number 4.
[00:09:15.000 --> 00:09:19.280]   So that's what we're going to use.
[00:09:19.280 --> 00:09:21.960]   Switch back over.
[00:09:21.960 --> 00:09:26.560]   So we're going to make those values equal to 4.
[00:09:26.560 --> 00:09:27.800]   That's our mask.
[00:09:27.800 --> 00:09:32.200]   Then at that point, we have successfully
[00:09:32.200 --> 00:09:38.120]   masked our input IDs, and we want to return the tensor.
[00:09:38.120 --> 00:09:41.360]   So that's our masking function.
[00:09:41.360 --> 00:09:43.680]   That's a big part of this video.
[00:09:43.680 --> 00:09:46.280]   That's one of the harder parts.
[00:09:46.280 --> 00:09:48.240]   So now what we're going to do is I'm
[00:09:48.240 --> 00:09:52.520]   going to scroll up a little bit to here.
[00:09:52.520 --> 00:09:57.880]   So we have-- I'm just going to take this.
[00:09:57.880 --> 00:10:03.120]   So this will give us a list of all of our training files.
[00:10:03.120 --> 00:10:05.720]   So here.
[00:10:05.720 --> 00:10:11.160]   And we just need to do from path lib, import path.
[00:10:11.160 --> 00:10:15.640]   OK, let's have a look at what we have.
[00:10:15.640 --> 00:10:20.680]   So this is just a list of everything
[00:10:20.680 --> 00:10:21.640]   that we have over here.
[00:10:21.640 --> 00:10:26.720]   So these are text files containing our Italian samples.
[00:10:26.720 --> 00:10:30.720]   Each sample is separated by a newline character.
[00:10:30.720 --> 00:10:35.000]   And each file also contains about 10,000 samples.
[00:10:35.000 --> 00:10:38.040]   So we have quite a bit of data.
[00:10:38.040 --> 00:10:41.120]   And what we're going to do here is
[00:10:41.120 --> 00:10:46.400]   we're going to create our three tensors that I mentioned
[00:10:46.400 --> 00:10:47.040]   before.
[00:10:47.040 --> 00:10:52.480]   We have-- before I make a list, I didn't make a list.
[00:10:52.480 --> 00:10:54.880]   So we have the labels and input IDs,
[00:10:54.880 --> 00:10:57.760]   and then we also have the attention mask as well.
[00:10:57.760 --> 00:11:02.800]   So let's first initialize a list.
[00:11:02.800 --> 00:11:13.240]   So input IDs, attention mask, or I'm just going to call it mask,
[00:11:13.240 --> 00:11:16.280]   and labels.
[00:11:16.280 --> 00:11:19.840]   And what we're going to do is I also--
[00:11:19.840 --> 00:11:21.600]   so we're going to use a progress bar here.
[00:11:21.600 --> 00:11:23.800]   So I'm just going to import.
[00:11:23.800 --> 00:11:29.640]   So from TQDM, auto import TQDM.
[00:11:29.640 --> 00:11:33.840]   So I'm just going to import that as well.
[00:11:33.840 --> 00:11:38.720]   And what I'm going to do is loop through each path in our--
[00:11:38.720 --> 00:11:40.360]   I'm going to wrap it in TQDM.
[00:11:40.360 --> 00:11:42.560]   This creates our progress bar in our paths.
[00:11:42.560 --> 00:11:50.480]   For each path, we're going to load it, extract our data,
[00:11:50.480 --> 00:11:53.720]   convert it into the correct format that we need here,
[00:11:53.720 --> 00:11:58.080]   and append each one of those to these lists,
[00:11:58.080 --> 00:12:01.400]   and then create a big tensor out of that.
[00:12:01.400 --> 00:12:05.120]   So we want to write with open.
[00:12:05.120 --> 00:12:08.560]   And then here we have our path, our reading,
[00:12:08.560 --> 00:12:15.040]   and the encoding is UTF-8 as F. We
[00:12:15.040 --> 00:12:22.920]   want to write text equals F.read.split, like that.
[00:12:22.920 --> 00:12:27.320]   So I'm going to rename it lines.
[00:12:27.320 --> 00:12:32.800]   So this is just a big list of 10,000 samples
[00:12:32.800 --> 00:12:35.680]   that are all Italian, OK?
[00:12:35.680 --> 00:12:37.360]   So then we want to encode that.
[00:12:37.360 --> 00:12:40.920]   So we write sample equals tokenizer.
[00:12:40.920 --> 00:12:46.440]   Lines, we want our max length, which is going to be 512.
[00:12:46.440 --> 00:12:50.200]   We want padding up to that max length.
[00:12:50.200 --> 00:12:51.800]   And we also want to truncate anything
[00:12:51.800 --> 00:12:53.840]   that is further than that.
[00:12:53.840 --> 00:12:58.840]   So truncation equals trunc.
[00:12:58.840 --> 00:13:03.360]   OK, that's our tokenization done.
[00:13:03.360 --> 00:13:05.640]   Then we want to extract.
[00:13:05.640 --> 00:13:11.560]   We want to extract all of those and add them to our list.
[00:13:11.560 --> 00:13:14.180]   So we get our labels first.
[00:13:14.180 --> 00:13:16.880]   Now, the labels are just the input IDs produced
[00:13:16.880 --> 00:13:18.280]   by our sample.
[00:13:18.280 --> 00:13:21.360]   So sample, input IDs.
[00:13:21.360 --> 00:13:28.000]   And I'm thinking here we can do turn tensors, use PyTorch.
[00:13:28.000 --> 00:13:33.680]   So append our input IDs to labels.
[00:13:33.680 --> 00:13:34.760]   And then we have our mask.
[00:13:34.760 --> 00:13:38.680]   We want to append the sample attention mask.
[00:13:38.680 --> 00:13:45.360]   And then we can also see that up here, by the way.
[00:13:45.360 --> 00:13:46.600]   Here, this is what we're doing.
[00:13:46.600 --> 00:13:49.040]   We're taking those out, putting them into our list.
[00:13:50.040 --> 00:13:51.840]   And then-- so we have labels, mask,
[00:13:51.840 --> 00:13:53.440]   and we want to create our input IDs.
[00:13:53.440 --> 00:13:58.360]   Now, input IDs, that's what we built this mass language
[00:13:58.360 --> 00:14:00.520]   modeling function for.
[00:14:00.520 --> 00:14:03.720]   And in there, we need to pass our tensor.
[00:14:03.720 --> 00:14:10.720]   So to do that, we just want to write sample input IDs.
[00:14:10.720 --> 00:14:16.720]   And before I forget, that needs to go within MLM, like that.
[00:14:16.720 --> 00:14:18.160]   Like that.
[00:14:18.160 --> 00:14:21.280]   Now, I don't want to modify that tensor,
[00:14:21.280 --> 00:14:23.640]   because it's being appended to labels.
[00:14:23.640 --> 00:14:27.160]   So I'm going to create a clone of that.
[00:14:27.160 --> 00:14:34.680]   And that will be done using detach and .clone, like that.
[00:14:34.680 --> 00:14:39.800]   So it's pretty good.
[00:14:39.800 --> 00:14:41.800]   Let's run that.
[00:14:44.960 --> 00:14:47.960]   OK, and it's going to take a long time.
[00:14:47.960 --> 00:14:53.800]   So, yeah, I'm not going to use all of them.
[00:14:53.800 --> 00:14:55.880]   It was going up as well, so I have no idea
[00:14:55.880 --> 00:14:58.080]   how long that would take.
[00:14:58.080 --> 00:15:00.360]   Let's leave that for a little bit.
[00:15:00.360 --> 00:15:04.160]   Let's go with the first 50 for now.
[00:15:04.160 --> 00:15:05.560]   Still got to wait a little while,
[00:15:05.560 --> 00:15:08.960]   but at least not as long.
[00:15:08.960 --> 00:15:14.800]   So I'll leave that to run.
[00:15:14.800 --> 00:15:16.360]   Hopefully it shouldn't take too long.
[00:15:16.360 --> 00:15:20.040]   And, yeah, I'll see you when it's done.
[00:15:20.040 --> 00:15:23.920]   OK, so that's done.
[00:15:23.920 --> 00:15:26.200]   It wasn't too long.
[00:15:26.200 --> 00:15:28.280]   And if we just have a look--
[00:15:28.280 --> 00:15:32.680]   so input IDs at the moment is just a big list.
[00:15:32.680 --> 00:15:35.520]   I don't know if it's a good idea, but here we go.
[00:15:35.520 --> 00:15:39.280]   So we just have a list of tensors.
[00:15:39.280 --> 00:15:43.640]   What we can do is, rather than having a list of tensors,
[00:15:43.640 --> 00:15:46.440]   we can use something called TorchCAT.
[00:15:46.440 --> 00:15:50.720]   And TorchCAT expects a list of tensors
[00:15:50.720 --> 00:15:53.600]   to be passed to it, which is why I've done this,
[00:15:53.600 --> 00:15:57.920]   where we have lists and we just append tensors to it.
[00:15:57.920 --> 00:16:02.440]   And we can do that, and it will concatenate our tensors, which
[00:16:02.440 --> 00:16:03.720]   is pretty cool.
[00:16:03.720 --> 00:16:10.040]   So what we want to do now is we write input IDs,
[00:16:10.040 --> 00:16:15.260]   and we're just going to concatenate all of our tensors.
[00:16:15.260 --> 00:16:22.920]   So then they're ready for formatting into a data set.
[00:16:22.920 --> 00:16:31.640]   So we have mask here and labels here.
[00:16:31.640 --> 00:16:36.920]   We can also see, just worth pointing out,
[00:16:36.920 --> 00:16:38.600]   we have that mask token there, so we
[00:16:38.600 --> 00:16:42.160]   know that we have mask tokens in our input IDs now.
[00:16:42.160 --> 00:16:47.800]   If we-- let's run that, and let's just compare.
[00:16:47.800 --> 00:16:51.640]   So let's go input IDs, 0.
[00:16:51.640 --> 00:16:57.720]   That's quite a lot, so can I--
[00:16:57.720 --> 00:17:00.200]   I'll just do the first 10.
[00:17:00.200 --> 00:17:02.240]   And then let's do the same for labels.
[00:17:02.240 --> 00:17:03.920]   We'll see that we don't have these 4s,
[00:17:03.920 --> 00:17:08.360]   or we hopefully shouldn't have those 4s.
[00:17:08.360 --> 00:17:11.040]   So that's essentially a masking operation.
[00:17:11.040 --> 00:17:14.040]   So cover this with a mask here, and then
[00:17:14.040 --> 00:17:17.320]   same here and here, here and here.
[00:17:17.320 --> 00:17:19.080]   OK, cool.
[00:17:19.080 --> 00:17:25.280]   Now the format that our data set needs and our model needs
[00:17:25.280 --> 00:17:30.280]   is a dictionary where we have input IDs, which
[00:17:30.280 --> 00:17:32.120]   maps to input IDs, obviously.
[00:17:32.120 --> 00:17:34.520]   And you can guess either two as well.
[00:17:34.520 --> 00:17:41.600]   So input IDs, this one, attention mask to mask,
[00:17:41.600 --> 00:17:46.320]   and the final one is labels.
[00:17:46.320 --> 00:17:49.640]   So there are encodings.
[00:17:49.640 --> 00:17:52.880]   Now we create a data set object.
[00:17:52.880 --> 00:17:56.120]   To create a data set object-- in fact,
[00:17:56.120 --> 00:17:58.880]   actually, we create a data set object
[00:17:58.880 --> 00:18:01.920]   to create a data loader object, which is what we
[00:18:01.920 --> 00:18:03.840]   use to load data into our model.
[00:18:03.840 --> 00:18:09.480]   And that's essentially our input pipeline.
[00:18:09.480 --> 00:18:11.160]   But to create that data loader, we
[00:18:11.160 --> 00:18:14.640]   need to create a data set object.
[00:18:14.640 --> 00:18:18.400]   Now the data set object, we create that by--
[00:18:18.400 --> 00:18:19.560]   well, like this.
[00:18:19.560 --> 00:18:23.240]   So we do class data set, color, whatever you want.
[00:18:23.240 --> 00:18:30.440]   And we want torch, utils, data, data set, like that.
[00:18:30.440 --> 00:18:36.920]   We need a initialization function,
[00:18:36.920 --> 00:18:41.480]   which is going to store our encodings internally.
[00:18:41.480 --> 00:18:44.680]   Don't forget the def there.
[00:18:44.680 --> 00:18:48.240]   So we want to write self encodings equals encoding.
[00:18:48.240 --> 00:18:53.280]   So this is initializing our data set object.
[00:18:53.280 --> 00:18:56.760]   And then there's two other methods that this object needs.
[00:18:56.760 --> 00:19:01.320]   We need a length method so that we can say length data set.
[00:19:01.320 --> 00:19:03.280]   And it will return the number of samples
[00:19:03.280 --> 00:19:04.800]   that are in the data set.
[00:19:04.800 --> 00:19:06.840]   And we also need a get item method,
[00:19:06.840 --> 00:19:13.680]   which will allow the data loader to extract a certain--
[00:19:13.680 --> 00:19:17.640]   so say if it says, give me number one,
[00:19:17.640 --> 00:19:19.880]   it's going to go into this data set object
[00:19:19.880 --> 00:19:23.240]   and extract the tensors, the input IDs, attention
[00:19:23.240 --> 00:19:27.360]   marks, and labels at position one.
[00:19:27.360 --> 00:19:31.280]   So that's what we need to do there.
[00:19:31.280 --> 00:19:35.000]   So we'll do length first.
[00:19:35.000 --> 00:19:37.440]   And length, we don't need to pass anything in there.
[00:19:37.440 --> 00:19:38.560]   We're just calling length.
[00:19:38.560 --> 00:19:44.120]   So from that, we just want to return the self encodings,
[00:19:44.120 --> 00:19:45.400]   do input IDs.
[00:19:45.400 --> 00:19:47.040]   And remember before, we did this shape.
[00:19:47.040 --> 00:19:49.480]   And we took the first one, which is the length.
[00:19:49.480 --> 00:19:55.560]   So if I take input IDs, in fact, I can just do it here.
[00:19:55.560 --> 00:19:56.440]   So I'll copy that.
[00:19:56.440 --> 00:20:02.800]   If I go here, we get that 500K, which
[00:20:02.800 --> 00:20:04.280]   is the number of samples we have.
[00:20:04.280 --> 00:20:05.520]   That's what we want to return.
[00:20:05.520 --> 00:20:09.720]   So that's our length.
[00:20:09.720 --> 00:20:11.720]   And then we also have the get item.
[00:20:11.720 --> 00:20:17.880]   So here, we do want to pass an index value.
[00:20:17.880 --> 00:20:19.280]   So this is going to be--
[00:20:19.280 --> 00:20:23.600]   our data load is requesting a certain position.
[00:20:23.600 --> 00:20:25.200]   And for that, we want to return.
[00:20:25.200 --> 00:20:26.700]   So we're going to return dictionary.
[00:20:26.700 --> 00:20:28.960]   It needs to be in this format here.
[00:20:28.960 --> 00:20:33.200]   But we need to specify the correct index.
[00:20:33.200 --> 00:20:40.520]   Now, what we could do is we could do self encodings
[00:20:40.520 --> 00:20:44.480]   and then access our input IDs like that.
[00:20:44.480 --> 00:20:47.400]   We also-- I need to change that here.
[00:20:47.400 --> 00:20:53.920]   So it'll give us an error, dot shape.
[00:20:53.920 --> 00:20:55.640]   And we could do that.
[00:20:55.640 --> 00:21:05.240]   So we could take that like so, and then just say,
[00:21:05.240 --> 00:21:06.640]   index position.
[00:21:06.640 --> 00:21:07.560]   That's fine.
[00:21:07.560 --> 00:21:09.280]   You can do that if you want.
[00:21:09.280 --> 00:21:11.000]   But an easier way of doing it, where
[00:21:11.000 --> 00:21:13.040]   we don't need to specify the--
[00:21:13.040 --> 00:21:16.200]   we don't care about the structure of the data set.
[00:21:16.200 --> 00:21:19.400]   We just want to get it out.
[00:21:19.400 --> 00:21:21.760]   We don't need to specify it.
[00:21:21.760 --> 00:21:25.000]   We can just do this.
[00:21:25.000 --> 00:21:28.760]   You write key tensor.
[00:21:28.760 --> 00:21:36.200]   So the specific index of that tensor for key tensor
[00:21:36.200 --> 00:21:40.840]   in self encodings, dot items.
[00:21:40.840 --> 00:21:45.480]   So if we were to go encodings, dot items--
[00:21:45.480 --> 00:21:47.760]   so we can do that here.
[00:21:47.760 --> 00:21:51.960]   See, we get essentially everything in our data set.
[00:21:51.960 --> 00:21:54.160]   So we're just looping through that, returning it,
[00:21:54.160 --> 00:21:58.240]   and specifying which index we're returning here.
[00:21:58.240 --> 00:22:02.680]   So once we have written that, we can initialize our data set.
[00:22:02.680 --> 00:22:08.880]   So write data set equals data set.
[00:22:08.880 --> 00:22:11.220]   And then we just pass in our encodings there.
[00:22:11.220 --> 00:22:14.760]   So just remove that, and encodings.
[00:22:14.760 --> 00:22:16.000]   That's it.
[00:22:16.000 --> 00:22:18.400]   So that's our data set.
[00:22:18.400 --> 00:22:22.280]   And now we initialize our data loader.
[00:22:22.280 --> 00:22:25.880]   So this is pretty much it for our input pipeline.
[00:22:25.880 --> 00:22:29.240]   So data loader equals torch utils.
[00:22:29.240 --> 00:22:33.240]   This is coming from the same area as our data set.
[00:22:33.240 --> 00:22:34.920]   Data loader.
[00:22:34.920 --> 00:22:37.680]   Now we pass in our data set object.
[00:22:37.680 --> 00:22:40.360]   We want to specify batch size.
[00:22:40.360 --> 00:22:43.680]   So I typically go with 16.
[00:22:43.680 --> 00:22:47.320]   This will depend on how much your computer can
[00:22:47.320 --> 00:22:48.820]   handle it once as well.
[00:22:48.820 --> 00:22:52.040]   So just play around with that, see what works.
[00:22:52.040 --> 00:22:54.400]   And we also want to shuffle our data set as well.
[00:22:54.400 --> 00:23:00.400]   So yeah, that's our input pipeline.
[00:23:00.400 --> 00:23:03.120]   After that, obviously, we want to feed it in and train
[00:23:03.120 --> 00:23:03.880]   our model with it.
[00:23:03.880 --> 00:23:08.160]   So we're going to cover that in the next video.
[00:23:08.160 --> 00:23:12.680]   So thank you for watching, and I will see you in the next one.

