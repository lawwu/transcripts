
[00:00:00.000 --> 00:00:02.000]   All right, let's do one last question.
[00:00:02.000 --> 00:00:04.800]   This one comes from Glenn.
[00:00:04.800 --> 00:00:09.600]   Glenn asks, "How do you think about thinking?"
[00:00:09.600 --> 00:00:12.700]   Glenn goes on to elaborate,
[00:00:12.700 --> 00:00:14.660]   "I was intrigued by a recent podcast
[00:00:14.660 --> 00:00:16.840]   "where you described how, when COVID started,
[00:00:16.840 --> 00:00:20.020]   "you sent out daily emails to your family,
[00:00:20.020 --> 00:00:20.900]   "helping them think about
[00:00:20.900 --> 00:00:22.860]   "what you and they were experiencing.
[00:00:22.860 --> 00:00:24.640]   "You mentioned a couple of reliable sources
[00:00:24.640 --> 00:00:27.800]   "for news about COVID, people you had learned to trust.
[00:00:27.800 --> 00:00:30.020]   "Selfishly, I'd be interested in hearing
[00:00:30.020 --> 00:00:32.880]   "who your trusted sources are.
[00:00:32.880 --> 00:00:34.380]   "But for the purposes of your podcast,
[00:00:34.380 --> 00:00:37.780]   "I would love to hear about how you think about thinking.
[00:00:37.780 --> 00:00:39.280]   "What I mean is, how did you decide
[00:00:39.280 --> 00:00:41.060]   "what was and was not a trusted source?
[00:00:41.060 --> 00:00:43.140]   "How do you distinguish between conspiratorial thinking
[00:00:43.140 --> 00:00:44.660]   "and good thinking?
[00:00:44.660 --> 00:00:45.940]   "When do you trust the science
[00:00:45.940 --> 00:00:49.180]   "and when is it proper to have some skepticism?"
[00:00:49.180 --> 00:00:52.580]   Well, it's a good question, Glenn.
[00:00:52.580 --> 00:00:54.500]   So I did do that newsletter for my family.
[00:00:54.500 --> 00:00:59.280]   It was positive news surrounding the COVID pandemic.
[00:00:59.280 --> 00:01:01.400]   It was trying to counteract
[00:01:01.400 --> 00:01:02.960]   all of the negativity out there.
[00:01:02.960 --> 00:01:04.540]   I stopped that after vaccines.
[00:01:04.540 --> 00:01:09.600]   So after my family had been vaccinated,
[00:01:09.600 --> 00:01:11.620]   after it was clear from the statistics
[00:01:11.620 --> 00:01:13.180]   that our risk was small,
[00:01:13.180 --> 00:01:15.720]   comparable to other things that we face on a daily basis
[00:01:15.720 --> 00:01:17.000]   and don't care about,
[00:01:17.000 --> 00:01:20.640]   I wanted to shift my focus away from COVID.
[00:01:20.640 --> 00:01:24.080]   And the reason is, of course, I mean, life is a gift
[00:01:24.080 --> 00:01:26.860]   and you don't wanna waste it, right?
[00:01:26.860 --> 00:01:28.400]   You don't wanna waste parts of your life
[00:01:28.400 --> 00:01:30.320]   that you could avoid not wasting.
[00:01:30.320 --> 00:01:34.760]   And it seemed to me that an excessive concentration
[00:01:34.760 --> 00:01:36.680]   on COVID as a unique threat,
[00:01:36.680 --> 00:01:39.660]   once we knew statistically that it wasn't a unique threat
[00:01:39.660 --> 00:01:41.400]   for us compared to other things,
[00:01:41.400 --> 00:01:42.880]   was in some sense,
[00:01:42.880 --> 00:01:46.760]   felt like we were dismissing the beauty that was life.
[00:01:46.760 --> 00:01:49.720]   To remain, I think, stuck and obsessed and anxious
[00:01:49.720 --> 00:01:51.400]   about just this one thing
[00:01:52.720 --> 00:01:54.800]   longer than we had to.
[00:01:54.800 --> 00:01:57.680]   And it was completely reasonable at some point,
[00:01:57.680 --> 00:01:59.720]   but to do that any minute longer than was necessary
[00:01:59.720 --> 00:02:02.000]   seemed like it was wasting this resource
[00:02:02.000 --> 00:02:03.120]   that we had been gifted.
[00:02:03.120 --> 00:02:06.640]   We wanted to see people experience art, enjoy experiences,
[00:02:06.640 --> 00:02:09.720]   like get back to the things that make human life human.
[00:02:09.720 --> 00:02:12.720]   So once we were no longer in that period of acute threat,
[00:02:12.720 --> 00:02:14.860]   I stopped that newsletter.
[00:02:14.860 --> 00:02:17.080]   You know, and I see it,
[00:02:17.080 --> 00:02:18.700]   I would say the bubbles in which people
[00:02:18.700 --> 00:02:21.440]   are excessively anxious about COVID have really shrunk
[00:02:22.120 --> 00:02:25.880]   as it was everyone, and then it shrunk.
[00:02:25.880 --> 00:02:27.240]   This is very crude.
[00:02:27.240 --> 00:02:29.480]   At some point it shrunk to, I guess, just blue states,
[00:02:29.480 --> 00:02:33.440]   and now it has shrunk to certain like metropolitan areas.
[00:02:33.440 --> 00:02:35.800]   And there's only a handful of them left.
[00:02:35.800 --> 00:02:38.220]   Our Deep Work HQ is in one of those areas.
[00:02:38.220 --> 00:02:42.600]   There's like a surprising amount of sort of people
[00:02:42.600 --> 00:02:45.560]   walking by themselves with high filtration mask on.
[00:02:45.560 --> 00:02:46.880]   And I just have a lot of empathy.
[00:02:46.880 --> 00:02:48.440]   I mean, I understand anxiety
[00:02:48.440 --> 00:02:52.320]   and something about viruses can tap something primal
[00:02:52.320 --> 00:02:54.320]   and create a really hard loop to break.
[00:02:54.320 --> 00:02:55.920]   And I am fortunate enough
[00:02:55.920 --> 00:02:57.880]   that we were able to break out of that loop
[00:02:57.880 --> 00:03:02.520]   and be able to go and basically live the best life we can
[00:03:02.520 --> 00:03:04.340]   in whatever the constraints were at the moment.
[00:03:04.340 --> 00:03:06.720]   But let's get to the bigger question here.
[00:03:06.720 --> 00:03:08.880]   How did I convince myself of that?
[00:03:08.880 --> 00:03:11.560]   How did I navigate the sea of COVID information?
[00:03:11.560 --> 00:03:14.920]   And more generally, how should people find good sources
[00:03:14.920 --> 00:03:18.980]   when it comes to any sort of issue that is important to you?
[00:03:18.980 --> 00:03:22.000]   How do we burst out of the filter bubbles
[00:03:22.000 --> 00:03:25.520]   that can put us into some sort of intellectual isolation
[00:03:25.520 --> 00:03:30.520]   and in doing so, perhaps lead to a narrowing of options
[00:03:30.520 --> 00:03:33.260]   or a dimming of what's possible in life?
[00:03:33.260 --> 00:03:39.400]   My big recommendation here is to luxuriate in the dialectic.
[00:03:40.760 --> 00:03:45.520]   You have to clash smart, convincing, good people
[00:03:45.520 --> 00:03:47.480]   on different sides of issues together.
[00:03:47.480 --> 00:03:49.280]   You have to do that.
[00:03:49.280 --> 00:03:51.920]   As soon as you stop doing that,
[00:03:51.920 --> 00:03:55.400]   you're in great danger of falling into a filter bubble
[00:03:55.400 --> 00:04:00.340]   where this is super true and this is super wrong.
[00:04:00.340 --> 00:04:03.280]   And I can't even believe those people can wake up
[00:04:03.280 --> 00:04:05.400]   in the morning knowing how wrong they are.
[00:04:05.400 --> 00:04:08.180]   And I just think as soon as you fall into a filter bubble,
[00:04:08.180 --> 00:04:12.500]   life narrows, options constrict, anger and anxiety raises,
[00:04:12.500 --> 00:04:15.740]   and you can fall into these negative loops
[00:04:15.740 --> 00:04:18.860]   like the people who like right now
[00:04:18.860 --> 00:04:21.120]   could be embracing what is good about life
[00:04:21.120 --> 00:04:23.380]   and still is very nervous
[00:04:23.380 --> 00:04:25.180]   about having someone into their home.
[00:04:25.180 --> 00:04:27.520]   And so filter bubbles can be a problem.
[00:04:27.520 --> 00:04:29.720]   So the dialectic is how you get out of this.
[00:04:29.720 --> 00:04:32.020]   Let me get someone who's convincing
[00:04:32.020 --> 00:04:33.000]   on the other side of this thing
[00:04:33.000 --> 00:04:35.260]   that kind of feels like right or what I've been hearing.
[00:04:35.260 --> 00:04:36.400]   Let's put them together.
[00:04:36.400 --> 00:04:37.240]   Let's collide them.
[00:04:37.240 --> 00:04:38.280]   Every time you do that,
[00:04:38.280 --> 00:04:40.400]   you get a deeper, more nuanced understanding
[00:04:40.400 --> 00:04:41.320]   of what's true.
[00:04:41.320 --> 00:04:44.000]   I did that all throughout COVID and you know what?
[00:04:44.000 --> 00:04:45.960]   The experts shifted.
[00:04:45.960 --> 00:04:48.780]   Like there was a time very early in COVID
[00:04:48.780 --> 00:04:50.860]   where there were certain commentators
[00:04:50.860 --> 00:04:52.440]   who were coming more from the conservative
[00:04:52.440 --> 00:04:56.520]   end of the spectrum that had critiques of lockdown policies.
[00:04:56.520 --> 00:04:58.560]   And I would steel man them
[00:04:58.560 --> 00:05:01.280]   and steel man their lockdown policy justifications.
[00:05:01.280 --> 00:05:02.880]   And I'd hit them together.
[00:05:02.880 --> 00:05:03.720]   And I'd come away and be like,
[00:05:03.720 --> 00:05:06.560]   "Hmm, there's something a little bit weird going on here."
[00:05:06.560 --> 00:05:09.200]   I think, and it's a complicated issue.
[00:05:09.200 --> 00:05:11.480]   But I was like, "Let me keep some of these sources
[00:05:11.480 --> 00:05:12.840]   in my queue of things I'm listening to."
[00:05:12.840 --> 00:05:16.120]   Because I think the front page of the New York Times
[00:05:16.120 --> 00:05:16.960]   or the Washington Post,
[00:05:16.960 --> 00:05:17.920]   there was things that was,
[00:05:17.920 --> 00:05:22.120]   there was angles that were being purposefully ignored.
[00:05:22.120 --> 00:05:23.160]   Information has been emphasized.
[00:05:23.160 --> 00:05:24.240]   I was like, "Okay, this is kind of,
[00:05:24.240 --> 00:05:26.060]   there's something interesting going on here."
[00:05:26.060 --> 00:05:28.320]   Those same sources that maybe I was looking at
[00:05:28.320 --> 00:05:31.600]   as the convincing counter examples to the lockdown policies
[00:05:31.600 --> 00:05:35.720]   later on became much less convincing
[00:05:35.720 --> 00:05:37.160]   when it came to things like vaccines.
[00:05:37.160 --> 00:05:39.600]   There's certain specific sources I can think about
[00:05:39.600 --> 00:05:42.920]   who they, for whatever reason,
[00:05:42.920 --> 00:05:45.000]   had a particular thought on vaccines.
[00:05:45.000 --> 00:05:46.160]   And when I would steel man that
[00:05:46.160 --> 00:05:47.440]   against the best other thought,
[00:05:47.440 --> 00:05:49.880]   they were just blown out of the water.
[00:05:49.880 --> 00:05:53.200]   It's like, "Oh, this is incredibly non-convincing
[00:05:53.200 --> 00:05:54.040]   and selective.
[00:05:54.040 --> 00:05:55.760]   And I can see you're ignoring this.
[00:05:55.760 --> 00:05:56.600]   And I'm reading the other side."
[00:05:56.600 --> 00:05:57.600]   And so it was the same people.
[00:05:57.600 --> 00:05:59.400]   Then they were no longer that trusted for me.
[00:05:59.400 --> 00:06:01.280]   Then there were sources that I thought were very useful
[00:06:01.280 --> 00:06:04.480]   early in vaccination that were very good about immunity
[00:06:04.480 --> 00:06:05.400]   and the immune system.
[00:06:05.400 --> 00:06:08.000]   These were often sources that came out of HIV medicine.
[00:06:08.000 --> 00:06:09.960]   People that came out of HIV were very useful
[00:06:09.960 --> 00:06:14.760]   in this sort of immediate post-vaccine moment
[00:06:14.760 --> 00:06:16.200]   because they, first of all,
[00:06:16.200 --> 00:06:20.080]   HIV knows a lot about harm reduction policies,
[00:06:20.080 --> 00:06:21.840]   which is quite different than what we were doing with COVID,
[00:06:21.840 --> 00:06:23.800]   which was more about risk elimination policies.
[00:06:23.800 --> 00:06:25.560]   And they knew a lot about the immune system.
[00:06:25.560 --> 00:06:27.480]   So here's what's gonna happen with a vaccine
[00:06:27.480 --> 00:06:28.840]   or prior infection.
[00:06:28.840 --> 00:06:31.160]   And that felt really useful.
[00:06:31.160 --> 00:06:34.600]   And when I was pushing them against other people
[00:06:34.600 --> 00:06:37.000]   who had different views on the vaccine,
[00:06:37.000 --> 00:06:38.680]   it's like, "Oh, I really understand more about immunity.
[00:06:38.680 --> 00:06:39.720]   That was very useful."
[00:06:39.720 --> 00:06:41.680]   And now there's other doctors who,
[00:06:41.680 --> 00:06:43.600]   I don't follow the news on COVID as much anymore now,
[00:06:43.600 --> 00:06:45.840]   because again, I'm trying to live life.
[00:06:45.840 --> 00:06:47.920]   And I think I can not think as much about it.
[00:06:47.920 --> 00:06:51.480]   But the point is dialectic, collision, collision, collision.
[00:06:51.480 --> 00:06:55.680]   And you get this nuanced view.
[00:06:55.680 --> 00:06:57.840]   And so early on, it's like,
[00:06:57.840 --> 00:06:59.160]   I see what's going on with the lockdowns,
[00:06:59.160 --> 00:07:00.800]   but I have these points of skepticism.
[00:07:00.800 --> 00:07:03.640]   And it's because I was putting these two things together.
[00:07:03.640 --> 00:07:05.440]   And if you looked at either of those sides in isolation,
[00:07:05.440 --> 00:07:06.920]   you'd be in a real extreme.
[00:07:06.920 --> 00:07:09.240]   You'd be either in the extreme of like,
[00:07:09.240 --> 00:07:10.840]   why can't we do what China's doing?
[00:07:10.840 --> 00:07:12.960]   If we could do that, COVID would go away.
[00:07:12.960 --> 00:07:15.680]   Or you're on this other extreme that was like,
[00:07:15.680 --> 00:07:18.040]   this is all a plot to, I don't know,
[00:07:18.040 --> 00:07:20.800]   some great reset plot.
[00:07:20.800 --> 00:07:22.880]   And there's no reason to be doing any of this.
[00:07:22.880 --> 00:07:24.520]   But you'd nail the most convincing people
[00:07:24.520 --> 00:07:27.040]   from both sides together, you get nuance.
[00:07:27.040 --> 00:07:29.960]   And you feel settled, you feel confident.
[00:07:29.960 --> 00:07:31.840]   With immunity, with all these different issues,
[00:07:31.840 --> 00:07:33.320]   always hit them together.
[00:07:33.320 --> 00:07:35.360]   And here's my, the big point I wanna make
[00:07:35.360 --> 00:07:38.120]   about this general filter bubble bursting approach
[00:07:38.120 --> 00:07:39.920]   is that you're not gonna be tricked.
[00:07:39.920 --> 00:07:43.800]   Exposing yourself to the other side of an idea,
[00:07:43.800 --> 00:07:45.640]   the other side of what seems instinctually right
[00:07:45.640 --> 00:07:46.800]   or what your tribe supports
[00:07:46.800 --> 00:07:49.720]   is not gonna trick you into the wrong information.
[00:07:49.720 --> 00:07:51.800]   As I talked about just multiple times here
[00:07:51.800 --> 00:07:53.200]   in these COVID specific examples,
[00:07:53.200 --> 00:07:56.400]   there is people that I was once kind of listening to
[00:07:56.400 --> 00:08:00.840]   that wilted, wilted under this exercise as time went on.
[00:08:00.840 --> 00:08:05.280]   I mean, it is a great identifier of true intellectual depth,
[00:08:05.280 --> 00:08:07.560]   intellectual honesty, accuracy.
[00:08:07.560 --> 00:08:08.840]   It really works very well.
[00:08:08.840 --> 00:08:10.200]   And it's not, you're not gonna be tricked
[00:08:10.200 --> 00:08:11.440]   into some weird conspiracy.
[00:08:11.440 --> 00:08:12.880]   It's actually gonna make your beliefs
[00:08:12.880 --> 00:08:14.360]   and the things you believe in stronger.
[00:08:14.360 --> 00:08:15.840]   It's gonna give you more confidence.
[00:08:15.840 --> 00:08:19.400]   It's probably why today I'm an extreme moderate with COVID
[00:08:19.400 --> 00:08:22.120]   because I've been doing this the whole time.
[00:08:22.120 --> 00:08:24.360]   And I feel confident in my risk assessments.
[00:08:24.360 --> 00:08:26.520]   I'm not super alarmist, I'm not super dismissive.
[00:08:26.520 --> 00:08:27.800]   And I think we've done the right things
[00:08:27.800 --> 00:08:30.800]   to keep our family risk low, but also I'm living life.
[00:08:30.800 --> 00:08:33.160]   And I think it's statistically valid that I am.
[00:08:33.160 --> 00:08:35.480]   And it's because I kept hitting these things
[00:08:35.480 --> 00:08:36.320]   against each other.
[00:08:36.320 --> 00:08:37.680]   And I didn't get captured by either side.
[00:08:37.680 --> 00:08:39.880]   I actually ended up in a sort of alt middle position
[00:08:39.880 --> 00:08:43.200]   that would end up, I think, being pretty useful.
[00:08:43.200 --> 00:08:44.160]   So I think that's what we need to do
[00:08:44.160 --> 00:08:47.840]   in this age of information abundance.
[00:08:47.840 --> 00:08:49.840]   When everyone is going through
[00:08:49.840 --> 00:08:51.960]   the same homogenized interface platforms
[00:08:51.960 --> 00:08:53.000]   like Twitter, Instagram.
[00:08:53.000 --> 00:08:54.760]   And so the crazy guy down the street,
[00:08:54.760 --> 00:08:58.280]   his tweet looks the same as the scholar of 50 years.
[00:08:58.280 --> 00:08:59.480]   And we're trying to sift through this
[00:08:59.480 --> 00:09:01.960]   and figure out what makes sense and what doesn't.
[00:09:01.960 --> 00:09:03.800]   That's the best thing you can do.
[00:09:03.800 --> 00:09:05.280]   Take the thing that sounds most convincing,
[00:09:05.280 --> 00:09:06.480]   take the thing that sounds most convincing
[00:09:06.480 --> 00:09:08.680]   on the other side, hit them together and repeat.
[00:09:08.680 --> 00:09:11.280]   That is how you burst out of filter bubbles.
[00:09:11.280 --> 00:09:12.680]   That's how you find what you really believe in.
[00:09:12.680 --> 00:09:13.560]   It's how you find nuance.
[00:09:13.560 --> 00:09:15.920]   I really think it's the way to go.
[00:09:15.920 --> 00:09:17.880]   And in doing that, the final thing I would say
[00:09:17.880 --> 00:09:21.320]   is be very wary of complete tribal allegiance.
[00:09:21.320 --> 00:09:23.240]   If you see in someone you're looking at
[00:09:23.240 --> 00:09:28.160]   as a source of information, an incredible, consistent,
[00:09:28.160 --> 00:09:30.680]   whatever that tribe says on the opposite.
[00:09:30.680 --> 00:09:34.120]   And even if it contradicts itself down the line,
[00:09:34.120 --> 00:09:38.160]   you see that going on, then don't even bother
[00:09:38.160 --> 00:09:41.000]   with that person in a dialectical collision.
[00:09:41.000 --> 00:09:42.960]   When I say convincing, you want someone who looks like
[00:09:42.960 --> 00:09:45.680]   they at least appear to be intellectually honest.
[00:09:45.680 --> 00:09:48.800]   If you see complete tribal allegiance,
[00:09:48.800 --> 00:09:52.040]   like I will keep, what does my team believe?
[00:09:52.040 --> 00:09:53.080]   That's what's right.
[00:09:53.080 --> 00:09:54.080]   What does that team believe?
[00:09:54.080 --> 00:09:55.160]   We're the opposite.
[00:09:55.160 --> 00:09:57.840]   That should be, you could filter those people out right away.
[00:09:57.840 --> 00:09:59.400]   But for the people who remain,
[00:09:59.400 --> 00:10:01.960]   dialectic, dialectic, dialectic,
[00:10:01.960 --> 00:10:04.400]   I think we all should be doing that.
[00:10:04.400 --> 00:10:05.800]   And if you do that, I don't know,
[00:10:05.800 --> 00:10:09.280]   you get a much more sophisticated, nuanced view of life.
[00:10:09.280 --> 00:10:11.760]   You won't end up at extreme, you won't end up tricked,
[00:10:11.760 --> 00:10:13.680]   and you'll probably end up in a better place.
[00:10:13.680 --> 00:10:16.000]   All right, well, a better place for us in this episode,
[00:10:16.000 --> 00:10:19.560]   I think, is to wrap it up as we went a little bit long here.
[00:10:19.560 --> 00:10:23.960]   I thank everyone who sent in their questions.
[00:10:23.960 --> 00:10:26.040]   As I like to say, if you like what you heard,
[00:10:26.040 --> 00:10:30.080]   you will like what you see at the show's YouTube channel,
[00:10:30.080 --> 00:10:32.200]   youtube.com/calnewportmedia.
[00:10:32.200 --> 00:10:34.360]   Full episodes and clips of every question
[00:10:34.360 --> 00:10:36.480]   and segment done on the show can be found there.
[00:10:36.480 --> 00:10:37.560]   You'll also like what you read
[00:10:37.560 --> 00:10:39.520]   at my long running newsletter.
[00:10:39.520 --> 00:10:42.080]   You can subscribe at calnewport.com.
[00:10:42.080 --> 00:10:44.640]   We'll be back on Thursday with a Listener Calls episode.
[00:10:44.640 --> 00:10:47.800]   And until then, as always, stay deep.
[00:10:47.800 --> 00:10:50.400]   (upbeat music)
[00:10:50.400 --> 00:10:53.740]   [MUSIC PLAYING]

