
[00:00:00.000 --> 00:00:02.760]   So I'm going to take a picture so I remember how many of you
[00:00:02.760 --> 00:00:05.560]   are here.
[00:00:05.560 --> 00:00:06.060]   Smile.
[00:00:06.060 --> 00:00:12.240]   Like Sami says, my name is Sherry Moore.
[00:00:12.240 --> 00:00:15.640]   I work in the Google Brain team.
[00:00:15.640 --> 00:00:18.800]   So today I'll be giving a tutorial on TensorFlow.
[00:00:18.800 --> 00:00:22.120]   First I'll talk a little bit about what TensorFlow is
[00:00:22.120 --> 00:00:26.400]   and how it works, how we use it at Google.
[00:00:26.400 --> 00:00:28.440]   And then the important part is that I'm
[00:00:28.440 --> 00:00:33.440]   going to work with you together to build a couple models
[00:00:33.440 --> 00:00:37.960]   to solve the most classic machine learning problems,
[00:00:37.960 --> 00:00:41.840]   so-called get your feet wet for those of you from New Zealand.
[00:00:41.840 --> 00:00:45.240]   Anybody from New Zealand?
[00:00:45.240 --> 00:00:48.440]   So hopefully at the end, you'll be going home
[00:00:48.440 --> 00:00:51.400]   with all the tools that you have to build
[00:00:51.400 --> 00:00:53.840]   all the wonderful things that you have watched today,
[00:00:53.840 --> 00:00:57.800]   like all the image recognition, the training
[00:00:57.800 --> 00:01:00.520]   of different colors, arts, making music.
[00:01:00.520 --> 00:01:02.800]   So that's the goal.
[00:01:02.800 --> 00:01:11.440]   So before I go any further, has everybody installed TensorFlow?
[00:01:11.440 --> 00:01:12.960]   Yay, brilliant.
[00:01:12.960 --> 00:01:13.520]   Thank you.
[00:01:13.520 --> 00:01:15.280]   And I would like to acknowledge--
[00:01:15.280 --> 00:01:17.040]   so I know the link here says Sherry-Ann,
[00:01:17.040 --> 00:01:21.520]   but if you have Wolf G, TF tutorial is perfectly fine.
[00:01:21.520 --> 00:01:23.800]   Wolf is actually my colleague who
[00:01:23.800 --> 00:01:26.160]   spent all the time verifying installation
[00:01:26.160 --> 00:01:27.360]   on every single platform.
[00:01:27.360 --> 00:01:29.160]   So I would really like to thank him.
[00:01:29.160 --> 00:01:31.200]   Thanks, Wolf, if you're watching.
[00:01:31.200 --> 00:01:34.800]   And also, I have my wonderful product boss or product manager
[00:01:34.800 --> 00:01:35.920]   in the audience somewhere.
[00:01:35.920 --> 00:01:38.840]   So if you guys have any request for TensorFlow,
[00:01:38.840 --> 00:01:41.360]   make sure that you go find him and tell him
[00:01:41.360 --> 00:01:45.200]   why TensorFlow must support this feature.
[00:01:45.200 --> 00:01:48.000]   Or is Zach somewhere?
[00:01:48.000 --> 00:01:50.480]   All right, so there he is.
[00:01:50.480 --> 00:01:53.720]   So with that, we can move forward
[00:01:53.720 --> 00:01:56.640]   to talk about TensorFlow.
[00:01:56.640 --> 00:01:58.000]   So what exactly is TensorFlow?
[00:01:58.000 --> 00:02:00.320]   TensorFlow is a machine learning library
[00:02:00.320 --> 00:02:03.120]   that we developed at Google.
[00:02:03.120 --> 00:02:06.400]   And we open sourced it last November.
[00:02:06.400 --> 00:02:10.800]   And ever since then, we have become the most, most popular
[00:02:10.800 --> 00:02:13.400]   machine learning library on GitHub.
[00:02:13.400 --> 00:02:15.280]   How do we know?
[00:02:15.280 --> 00:02:20.560]   Because we have over 32,000 stars.
[00:02:20.560 --> 00:02:22.200]   Those of you who track GitHub, you
[00:02:22.200 --> 00:02:25.000]   know how hard it is to get one of those acknowledgments.
[00:02:25.000 --> 00:02:28.040]   And we also have over 14,000 forks.
[00:02:28.040 --> 00:02:32.480]   And we have over 8,000 contributions
[00:02:32.480 --> 00:02:37.280]   from 400 individual developers.
[00:02:37.280 --> 00:02:40.360]   And we designed this specifically
[00:02:40.360 --> 00:02:41.520]   for machine learning.
[00:02:41.520 --> 00:02:43.960]   However, as you'll see later, because
[00:02:43.960 --> 00:02:47.960]   of its really flexible data flow infrastructure,
[00:02:47.960 --> 00:02:51.640]   it makes it really suitable for pretty much any application
[00:02:51.640 --> 00:02:52.840]   that can fit into that model.
[00:02:52.840 --> 00:02:58.600]   Basically, if your model can be asynchronous and fire
[00:02:58.600 --> 00:03:04.040]   on when data is ready, it can probably use TensorFlow.
[00:03:04.040 --> 00:03:07.240]   Originally, we worked alongside with other researchers.
[00:03:07.240 --> 00:03:09.240]   As a matter of fact, I was really fortunate.
[00:03:09.240 --> 00:03:12.440]   When I joined the team, I sat right next to Alex,
[00:03:12.440 --> 00:03:14.360]   the person who invented AlexNet.
[00:03:14.360 --> 00:03:17.400]   So that's how closely we worked together.
[00:03:17.400 --> 00:03:20.080]   As we developed TensorFlow, they would tell us, no,
[00:03:20.080 --> 00:03:21.840]   this is not how we use it.
[00:03:21.840 --> 00:03:24.880]   Yes, when you do this, it makes our lives a lot easier.
[00:03:24.880 --> 00:03:27.280]   And this is why we believe that we have developed
[00:03:27.280 --> 00:03:30.640]   an infrastructure that will work really well for researchers.
[00:03:30.640 --> 00:03:32.800]   And also, being Google, we also always
[00:03:32.800 --> 00:03:36.240]   have in mind that we would like to take from research
[00:03:36.240 --> 00:03:38.720]   to prototyping to a production in no time.
[00:03:38.720 --> 00:03:42.200]   We don't want you to write all the code that's typically
[00:03:42.200 --> 00:03:43.680]   just throwing away.
[00:03:43.680 --> 00:03:46.080]   We want you to write code that can literally cut and paste
[00:03:46.080 --> 00:03:49.760]   and save in a file and productize it immediately.
[00:03:49.760 --> 00:03:55.440]   So TensorFlow is really designed with that in mind.
[00:03:55.440 --> 00:03:59.080]   So we are halfway into your deep learning school.
[00:03:59.080 --> 00:04:03.640]   So can anybody tell me, if you want to build a neural net,
[00:04:03.640 --> 00:04:05.400]   what must you have?
[00:04:05.400 --> 00:04:07.680]   What are the primitives?
[00:04:07.680 --> 00:04:10.720]   What are the-- yeah, primitive, I think,
[00:04:10.720 --> 00:04:12.160]   is the word I'm looking for.
[00:04:12.160 --> 00:04:16.680]   What must you have to build a neural net?
[00:04:16.680 --> 00:04:17.640]   Anybody?
[00:04:17.640 --> 00:04:21.320]   What is in the neural net?
[00:04:21.320 --> 00:04:23.280]   [INAUDIBLE]
[00:04:23.280 --> 00:04:25.560]   That's a very good answer.
[00:04:25.560 --> 00:04:27.600]   So in a neural net, you have neurons.
[00:04:27.600 --> 00:04:32.240]   That's right.
[00:04:32.240 --> 00:04:38.280]   So all these neurons, what do they operate on?
[00:04:38.280 --> 00:04:41.880]   What do all these neurons do?
[00:04:41.880 --> 00:04:45.120]   They process data, and they operate on data.
[00:04:45.120 --> 00:04:48.800]   And they do something, such as convolution, matrix
[00:04:48.800 --> 00:04:52.240]   multiplication, max pooling average, pooling dropout,
[00:04:52.240 --> 00:04:53.640]   whatever that is.
[00:04:53.640 --> 00:04:57.640]   So in TensorFlow, all the data is held
[00:04:57.640 --> 00:05:00.520]   in something called a tensor.
[00:05:00.520 --> 00:05:03.960]   Tensor is nothing more than a multidimensional array.
[00:05:03.960 --> 00:05:07.040]   For those of you who are familiar with NumPy arrays,
[00:05:07.040 --> 00:05:10.320]   it's very similar to the ND array.
[00:05:10.320 --> 00:05:12.920]   And the graph, I think one of the gentlemen
[00:05:12.920 --> 00:05:15.000]   earlier this morning described, there
[00:05:15.000 --> 00:05:16.920]   is this concept of the graph, which
[00:05:16.920 --> 00:05:21.560]   is a composition of all these neurons that
[00:05:21.560 --> 00:05:23.640]   do different functions.
[00:05:23.640 --> 00:05:26.640]   And all these neurons are connected to each other
[00:05:26.640 --> 00:05:28.280]   through their inputs and outputs.
[00:05:28.280 --> 00:05:32.160]   So as data become available, they would fire--
[00:05:32.160 --> 00:05:33.840]   by fire, I mean they do what they're
[00:05:33.840 --> 00:05:35.800]   designed to do, such as doing matrix
[00:05:35.800 --> 00:05:38.160]   multiplication or convolution.
[00:05:38.160 --> 00:05:39.520]   And then they will produce output
[00:05:39.520 --> 00:05:42.280]   for the next computation node that's
[00:05:42.280 --> 00:05:44.160]   connected to the output.
[00:05:44.160 --> 00:05:46.560]   So by doing this--
[00:05:46.560 --> 00:05:51.720]   so I don't know how many of you can actually see this animation.
[00:05:51.720 --> 00:05:53.360]   Yeah?
[00:05:53.360 --> 00:05:57.200]   So this is to really visualize how TensorFlow works.
[00:05:57.200 --> 00:06:00.560]   All these nodes, the oval ones are computation.
[00:06:00.560 --> 00:06:03.840]   The rectangle ones are stateful nodes.
[00:06:03.840 --> 00:06:07.160]   So all these nodes, they would generate output,
[00:06:07.160 --> 00:06:08.320]   or they take input.
[00:06:08.320 --> 00:06:11.360]   And as soon as all the inputs for a particular node
[00:06:11.360 --> 00:06:16.000]   are available, it would do its thing, produce output.
[00:06:16.000 --> 00:06:20.240]   And then the tensor, all the data,
[00:06:20.240 --> 00:06:24.200]   which are held in tensors, will flow through your network.
[00:06:24.200 --> 00:06:26.360]   Therefore, tensor flow.
[00:06:26.360 --> 00:06:26.860]   Yeah?
[00:06:26.860 --> 00:06:32.920]   So everybody's like, wow, this sounds like magic.
[00:06:32.920 --> 00:06:34.520]   How does it work?
[00:06:34.520 --> 00:06:38.600]   So who said-- is it Sir Arthur Clark that says,
[00:06:38.600 --> 00:06:41.400]   any sufficiently-- what's the word?
[00:06:41.400 --> 00:06:43.360]   Any sufficiently advanced technology
[00:06:43.360 --> 00:06:45.520]   is indistinguishable from magic.
[00:06:45.520 --> 00:06:48.680]   So that's what this is.
[00:06:48.680 --> 00:06:52.240]   It's just really awesome.
[00:06:52.240 --> 00:06:53.440]   Excuse me for a second.
[00:06:53.440 --> 00:06:59.040]   I know I want to get through this as quickly as possible
[00:06:59.040 --> 00:07:02.880]   so we can actually do the lab that you're all dying to do.
[00:07:02.880 --> 00:07:05.240]   So as any good infrastructure-- so this is--
[00:07:05.240 --> 00:07:07.720]   I want to give you a little image of how
[00:07:07.720 --> 00:07:11.040]   we design this tensor flow.
[00:07:11.040 --> 00:07:13.160]   Just like any well-designed infrastructure,
[00:07:13.160 --> 00:07:15.000]   it has to be really modular.
[00:07:15.000 --> 00:07:19.080]   Because being modular allows you to innovate, to upgrade,
[00:07:19.080 --> 00:07:23.000]   to improve, to modify, to do whatever you want with any
[00:07:23.000 --> 00:07:26.320]   piece, as long as you keep the APIs consistent.
[00:07:26.320 --> 00:07:27.840]   Everybody can work in parallel.
[00:07:27.840 --> 00:07:29.280]   It's really empowering.
[00:07:29.280 --> 00:07:31.360]   I think that's one of the wonderful things that's
[00:07:31.360 --> 00:07:32.080]   done at Google.
[00:07:32.080 --> 00:07:35.080]   Pretty much any infrastructure at Google is really modular.
[00:07:35.080 --> 00:07:37.040]   They talk really well to each other.
[00:07:37.040 --> 00:07:42.280]   All you need to maintain is the API stability.
[00:07:42.280 --> 00:07:45.440]   So in this case, we have a front end.
[00:07:45.440 --> 00:07:48.160]   I think you guys must have seen some examples of how
[00:07:48.160 --> 00:07:49.360]   you construct a graph.
[00:07:49.360 --> 00:07:52.080]   So we have the front end libraries
[00:07:52.080 --> 00:07:53.720]   written in your favorite language.
[00:07:53.720 --> 00:07:56.920]   And if C++ and Python is not your favorite language,
[00:07:56.920 --> 00:07:58.080]   feel free to contribute.
[00:07:58.080 --> 00:08:00.200]   We always welcome contribution.
[00:08:00.200 --> 00:08:03.760]   So you construct your graph in your favorite language.
[00:08:03.760 --> 00:08:06.840]   And this graph will be sent to-- we
[00:08:06.840 --> 00:08:10.400]   call it the core TensorFlow execution system.
[00:08:10.400 --> 00:08:11.320]   That's your runtime.
[00:08:11.320 --> 00:08:14.560]   And that's what you all will be running today on your laptop
[00:08:14.560 --> 00:08:20.280]   when you open your Python notebook or Jupyter notebook.
[00:08:20.280 --> 00:08:23.400]   So the execution runtime, depending
[00:08:23.400 --> 00:08:27.640]   on where you are going to run this application,
[00:08:27.640 --> 00:08:31.400]   it will send the kernel to the corresponding device.
[00:08:31.400 --> 00:08:33.000]   So it could be a CPU, could be a GPU,
[00:08:33.000 --> 00:08:36.520]   could be a phone, could be TPU.
[00:08:36.520 --> 00:08:40.000]   Anybody knows what TPU is?
[00:08:40.000 --> 00:08:42.280]   Brilliant, very nice.
[00:08:42.280 --> 00:08:43.320]   I was at Strata.
[00:08:43.320 --> 00:08:44.920]   I said, anybody knows what TPU is?
[00:08:44.920 --> 00:08:48.600]   And everybody's like, hmm, translation?
[00:08:48.600 --> 00:08:50.160]   So this is good.
[00:08:50.160 --> 00:08:53.760]   So just to highlight our portability,
[00:08:53.760 --> 00:08:56.320]   today you'll be running TensorFlow on your laptop.
[00:08:56.320 --> 00:08:59.040]   We run it in our data center.
[00:08:59.040 --> 00:09:04.700]   Everybody can run it on your iPhone, your Android phone.
[00:09:04.700 --> 00:09:07.280]   I would love to see people putting it on Raspberry Pi,
[00:09:07.280 --> 00:09:09.040]   because can you imagine, you can just
[00:09:09.040 --> 00:09:11.680]   write your own TensorFlow application.
[00:09:11.680 --> 00:09:13.920]   It could be your security system,
[00:09:13.920 --> 00:09:17.340]   because somebody just stole my bike and my security camera,
[00:09:17.340 --> 00:09:20.040]   capture all this grainy stuff that I cannot tell.
[00:09:20.040 --> 00:09:24.680]   Wouldn't it be nice if you do machine learning on this thing
[00:09:24.680 --> 00:09:28.360]   and they just start taking high-resolution pictures when
[00:09:28.360 --> 00:09:31.480]   things are moving, rather than constantly capturing
[00:09:31.480 --> 00:09:34.520]   all those grainy images, which is totally useless?
[00:09:34.520 --> 00:09:36.160]   So I think the application-- literally,
[00:09:36.160 --> 00:09:39.120]   applications are limitless.
[00:09:39.120 --> 00:09:42.600]   Your imagination is the limit.
[00:09:42.600 --> 00:09:48.920]   So we talked about what TensorFlow is, how it works.
[00:09:48.920 --> 00:09:50.480]   How do we use it at Google?
[00:09:50.480 --> 00:09:51.500]   We use it everywhere.
[00:09:51.500 --> 00:09:53.800]   I think you have seen some of the examples.
[00:09:53.800 --> 00:09:55.960]   We use it to recognize pictures.
[00:09:55.960 --> 00:09:57.560]   This is actually done with Inception.
[00:09:57.560 --> 00:10:03.480]   They can recognize out of the box 1,000 images.
[00:10:03.480 --> 00:10:05.920]   You have to retrain it if you want it to recognize, say,
[00:10:05.920 --> 00:10:08.720]   all your relatives or your pets.
[00:10:08.720 --> 00:10:11.960]   But it's not difficult. And I have links for you to--
[00:10:11.960 --> 00:10:14.160]   actually, if you want to train on your own images,
[00:10:14.160 --> 00:10:15.120]   it's really easy.
[00:10:15.120 --> 00:10:16.600]   They should totally try it.
[00:10:16.600 --> 00:10:20.160]   Wouldn't it be fun if you go to your 40-year reunion
[00:10:20.160 --> 00:10:23.840]   and you just go, I know who you are.
[00:10:23.840 --> 00:10:25.160]   Just show off a little.
[00:10:25.160 --> 00:10:27.040]   It would be brilliant.
[00:10:27.040 --> 00:10:31.720]   And we also use it to do Google Voice Search.
[00:10:31.720 --> 00:10:33.680]   This is one that's super awesome.
[00:10:33.680 --> 00:10:37.240]   So how many of you use Smart Reply?
[00:10:37.240 --> 00:10:38.480]   Have you ever used Smart Reply?
[00:10:38.480 --> 00:10:42.240]   Yeah, yeah, this is awesome, especially for those of you
[00:10:42.240 --> 00:10:44.840]   who are doing what you're not supposed to do--
[00:10:44.840 --> 00:10:47.720]   texting while driving, you saw an email coming in,
[00:10:47.720 --> 00:10:50.740]   and you can just say, oh, yes, I'll be there.
[00:10:50.740 --> 00:10:55.440]   So based on the statistics that we collected in February,
[00:10:55.440 --> 00:10:58.920]   over 10% of all the responses sent on mobile
[00:10:58.920 --> 00:11:01.840]   is actually done by our Smart Reply.
[00:11:01.840 --> 00:11:03.480]   I believe if we have--
[00:11:03.480 --> 00:11:06.440]   maybe Zach can collect some stats for me later.
[00:11:06.440 --> 00:11:10.520]   And maybe by now, it'll be like 80%.
[00:11:10.520 --> 00:11:11.640]   It's actually really funny.
[00:11:11.640 --> 00:11:13.800]   At the very beginning, when we train it,
[00:11:13.800 --> 00:11:16.880]   the first answer is always, I love you.
[00:11:16.880 --> 00:11:20.200]   We're like, that's probably not the right answer.
[00:11:23.080 --> 00:11:25.080]   We also play games.
[00:11:25.080 --> 00:11:27.720]   All of you, I'm sure, have followed this.
[00:11:27.720 --> 00:11:30.360]   There are all kinds of games that are being developed.
[00:11:30.360 --> 00:11:32.480]   It's really fun to watch if you watch it.
[00:11:32.480 --> 00:11:34.680]   Literally, come up with scenarios for you
[00:11:34.680 --> 00:11:35.800]   to play as well.
[00:11:35.800 --> 00:11:38.000]   It not only learns to play the game,
[00:11:38.000 --> 00:11:40.640]   but learns how to make a game for you.
[00:11:40.640 --> 00:11:42.720]   It's fascinating.
[00:11:42.720 --> 00:11:43.960]   And of course, art.
[00:11:43.960 --> 00:11:46.320]   I think many of you have done this deep dream.
[00:11:46.320 --> 00:11:50.800]   If we have time in the end of the lab, we can try this.
[00:11:50.800 --> 00:11:55.280]   So if we are super fast, we can all try to make some art.
[00:11:55.280 --> 00:11:57.960]   And all those, what I just talked about, of course,
[00:11:57.960 --> 00:12:00.960]   Google being this wonderful, generous company,
[00:12:00.960 --> 00:12:02.680]   wants to share our knowledge.
[00:12:02.680 --> 00:12:05.760]   So we have actually published all our models.
[00:12:05.760 --> 00:12:07.480]   So if you go to that link, you'll
[00:12:07.480 --> 00:12:12.360]   find all these inception and captioning, language
[00:12:12.360 --> 00:12:14.760]   model on a billion words, the latest
[00:12:14.760 --> 00:12:17.120]   ResNet on CIFAR-10, sequence to sequence,
[00:12:17.120 --> 00:12:20.320]   which I think Kwok will be talking about tomorrow.
[00:12:20.320 --> 00:12:23.920]   And we have many other high-level libraries.
[00:12:23.920 --> 00:12:27.880]   So today, my lab, the lab that we will do,
[00:12:27.880 --> 00:12:30.560]   will be on the core TensorFlow APIs.
[00:12:30.560 --> 00:12:33.560]   But there are tons of new higher-level APIs,
[00:12:33.560 --> 00:12:36.000]   such as some of the mentioned Keras.
[00:12:36.000 --> 00:12:38.200]   And we have SLIM.
[00:12:38.200 --> 00:12:39.600]   We have PrettyTensor.
[00:12:39.600 --> 00:12:41.320]   We have TF Learn.
[00:12:41.320 --> 00:12:44.040]   We have many libraries that's developed on top
[00:12:44.040 --> 00:12:46.160]   of the core TensorFlow APIs.
[00:12:46.160 --> 00:12:47.660]   Then we encourage people to do so.
[00:12:47.660 --> 00:12:51.080]   If whatever is out there does not fit your needs perfectly,
[00:12:51.080 --> 00:12:51.600]   go for it.
[00:12:51.600 --> 00:12:52.360]   Develop your own.
[00:12:52.360 --> 00:12:54.000]   And we welcome the contribution.
[00:12:54.000 --> 00:12:56.200]   And we published a lot of that here.
[00:12:56.200 --> 00:12:58.040]   I might have blurred some of the boundaries.
[00:12:58.040 --> 00:13:01.280]   But these are basically all the models and libraries
[00:13:01.280 --> 00:13:02.600]   that we have produced.
[00:13:02.600 --> 00:13:05.440]   And we really love contribution.
[00:13:05.440 --> 00:13:07.520]   If you have developed a really cool model,
[00:13:07.520 --> 00:13:09.280]   please do send to us.
[00:13:09.280 --> 00:13:14.960]   And we will showcase your work.
[00:13:14.960 --> 00:13:17.820]   So that's the introduction of TensorFlow.
[00:13:17.820 --> 00:13:19.580]   How does everybody feel?
[00:13:19.580 --> 00:13:23.460]   Are you all ready to get started?
[00:13:23.460 --> 00:13:27.620]   All right, so OK, before you bring up your Python notebook,
[00:13:27.620 --> 00:13:30.540]   I want to say what we are going to do first.
[00:13:30.540 --> 00:13:33.820]   So as I mentioned, there are two classic machine learning
[00:13:33.820 --> 00:13:35.900]   problems that everybody does.
[00:13:35.900 --> 00:13:38.180]   One is linear regression.
[00:13:38.180 --> 00:13:39.440]   The other is classification.
[00:13:39.440 --> 00:13:43.580]   So we are going to do two simple labs to cover those.
[00:13:43.580 --> 00:13:46.140]   I do have a lot of small exercises you can play with.
[00:13:46.140 --> 00:13:49.460]   I encourage you to play with it to be a lot more comfortable.
[00:13:49.460 --> 00:13:52.940]   So the first one is linear regression.
[00:13:52.940 --> 00:13:55.820]   So I'm sure it has been covered, yeah, in today's lectures.
[00:13:55.820 --> 00:13:58.700]   Somebody must have covered linear regression.
[00:13:58.700 --> 00:14:02.340]   Can anybody give me a one-line summary?
[00:14:02.340 --> 00:14:05.820]   What is a linear regression problem?
[00:14:05.820 --> 00:14:06.320]   Anybody?
[00:14:06.320 --> 00:14:10.180]   The professors--
[00:14:10.180 --> 00:14:12.580]   [LAUGHTER]
[00:14:12.620 --> 00:14:14.540]   [LAUGHS]
[00:14:14.540 --> 00:14:18.940]   Well, if you don't know, go Google it.
[00:14:18.940 --> 00:14:22.860]   So I didn't know the audience when
[00:14:22.860 --> 00:14:24.740]   Sammy asked me to do this.
[00:14:24.740 --> 00:14:28.620]   So I wrote this for one of the high schools.
[00:14:28.620 --> 00:14:30.780]   So I think it still kind of makes sense, right?
[00:14:30.780 --> 00:14:33.340]   Because all of us have played this game
[00:14:33.340 --> 00:14:35.140]   at one point of our lives.
[00:14:35.140 --> 00:14:39.860]   Like, if you tell me 5 or tell you 10,
[00:14:39.860 --> 00:14:42.420]   and you try to guess what the equation is,
[00:14:42.420 --> 00:14:44.260]   we must have all done this.
[00:14:44.260 --> 00:14:47.620]   I think my friends are still doing on Facebook saying, oh,
[00:14:47.620 --> 00:14:50.340]   only genius can solve this kind of equation.
[00:14:50.340 --> 00:14:52.860]   And then they would be like, yeah, I solved it.
[00:14:52.860 --> 00:14:54.860]   I was like, my god, if anybody--
[00:14:54.860 --> 00:14:59.020]   I will unfriend you guys if you click on another one of those.
[00:14:59.020 --> 00:15:00.660]   But basically, this is what we are
[00:15:00.660 --> 00:15:02.820]   trying to do in the first lab.
[00:15:02.820 --> 00:15:04.820]   So we will have a mystery equation.
[00:15:04.820 --> 00:15:05.980]   It's really simple.
[00:15:05.980 --> 00:15:07.180]   It's just a linear--
[00:15:07.180 --> 00:15:08.660]   literally a line.
[00:15:08.660 --> 00:15:12.460]   And then I will tell you that this is the formula.
[00:15:12.460 --> 00:15:15.580]   But I'm not going to give you a weight, w and b.
[00:15:15.580 --> 00:15:19.180]   All of you have learned by now, w stands for weight and b
[00:15:19.180 --> 00:15:20.580]   stands for bias.
[00:15:20.580 --> 00:15:24.780]   So the idea is that if you are given enough samples,
[00:15:24.780 --> 00:15:27.940]   if you are given enough x and y values,
[00:15:27.940 --> 00:15:31.940]   you should be able to make a pretty good guess what w and b
[00:15:31.940 --> 00:15:32.940]   is.
[00:15:32.940 --> 00:15:35.420]   So that's what we are going to do.
[00:15:35.420 --> 00:15:39.660]   So now you can bring up your Jupyter Notebook
[00:15:39.660 --> 00:15:41.100]   if you don't have it up already.
[00:15:41.100 --> 00:15:47.420]   Yeah, everybody have it up?
[00:15:47.420 --> 00:15:48.300]   Yes?
[00:15:48.300 --> 00:15:51.700]   Can I see a show of hands, everybody?
[00:15:51.700 --> 00:15:53.340]   Those of-- yeah, brilliant.
[00:15:53.340 --> 00:15:55.060]   All right.
[00:15:55.060 --> 00:15:59.620]   So for pretty much any models, these
[00:15:59.620 --> 00:16:01.380]   are going to come up over and over again.
[00:16:01.380 --> 00:16:05.260]   And just to make sure that you're all paying attention,
[00:16:05.260 --> 00:16:07.980]   I do have--
[00:16:07.980 --> 00:16:11.540]   I asked Sammy if I was supposed to bring Shrek, and he said no.
[00:16:11.540 --> 00:16:13.420]   But I do have a lot of TensorFlow stickers,
[00:16:13.420 --> 00:16:16.340]   and I have all kinds of little toys.
[00:16:16.340 --> 00:16:18.140]   So later, I'm going to ask this question.
[00:16:18.140 --> 00:16:22.900]   Whoever can answer will get some mystery present.
[00:16:22.900 --> 00:16:24.860]   So really pay attention, OK?
[00:16:24.860 --> 00:16:27.620]   So pretty much whenever you build any model,
[00:16:27.620 --> 00:16:30.380]   there are, I would say, four things that you will need.
[00:16:30.380 --> 00:16:31.700]   You need input.
[00:16:31.700 --> 00:16:32.700]   You need data.
[00:16:32.700 --> 00:16:34.380]   So you're going to see in both labs,
[00:16:34.380 --> 00:16:36.580]   we're going to be defining some data.
[00:16:36.580 --> 00:16:39.220]   You're going to be building an inference graph.
[00:16:39.220 --> 00:16:42.980]   I think in other lectures, it's also called a Fourier graph,
[00:16:42.980 --> 00:16:47.780]   to the point that it produces logits, the logistic outputs.
[00:16:47.780 --> 00:16:52.540]   And then you're going to have training operations, which
[00:16:52.540 --> 00:16:57.220]   is where you would define a loss, an optimizer.
[00:16:57.220 --> 00:17:00.220]   And I think that's pretty much it.
[00:17:00.220 --> 00:17:01.020]   Hang on.
[00:17:01.020 --> 00:17:04.260]   And there's a fourth thing.
[00:17:04.260 --> 00:17:06.260]   Yeah, and then you will basically run the graph.
[00:17:06.260 --> 00:17:07.980]   So the three important things, OK, you'll
[00:17:07.980 --> 00:17:10.500]   always have your data, your inference graph.
[00:17:10.500 --> 00:17:15.060]   You always have to define your loss and your optimizer.
[00:17:15.060 --> 00:17:18.020]   And the training is basically to minimize your loss.
[00:17:18.020 --> 00:17:20.660]   So I'm going to be asking that later.
[00:17:20.660 --> 00:17:21.140]   All right.
[00:17:21.140 --> 00:17:23.020]   So now we know what we're going to do.
[00:17:23.020 --> 00:17:27.180]   So you can go to that lab.
[00:17:27.180 --> 00:17:28.140]   Yeah, everybody have it?
[00:17:28.140 --> 00:17:31.460]   So Shift, Return.
[00:17:31.460 --> 00:17:32.900]   We'll run the first one.
[00:17:32.900 --> 00:17:35.220]   You say, I have no idea what's happening.
[00:17:35.220 --> 00:17:36.020]   Here, we turn again.
[00:17:36.020 --> 00:17:37.060]   Still nothing.
[00:17:37.060 --> 00:17:40.700]   However, let's see what we are producing here.
[00:17:40.700 --> 00:17:42.860]   So you can also do the same on your laptop.
[00:17:42.860 --> 00:17:46.900]   You can uncomment that plot.
[00:17:46.900 --> 00:17:49.020]   You're going to say, so you know what kind of data
[00:17:49.020 --> 00:17:49.940]   you're generating.
[00:17:49.940 --> 00:17:54.980]   So in this case, when here we turn, what are we seeing?
[00:17:54.980 --> 00:17:56.140]   This is your input data.
[00:17:56.140 --> 00:17:58.100]   This is when you try to make a guess,
[00:17:58.100 --> 00:18:01.380]   when your friend tell me, oh, give me x and y.
[00:18:01.380 --> 00:18:06.380]   So this is when your x is 0.2, your y is 0.32.
[00:18:06.380 --> 00:18:09.620]   So this is basically your input data.
[00:18:09.620 --> 00:18:11.980]   Yeah, everybody following?
[00:18:11.980 --> 00:18:14.980]   If at any point you're kind of lost, raise your hand,
[00:18:14.980 --> 00:18:18.020]   and your buddy next to you will be able to help you.
[00:18:18.020 --> 00:18:25.540]   So now-- oh, OK, I want to say one more thing.
[00:18:25.540 --> 00:18:30.980]   So today, the labs are all on really core TensorFlow APIs.
[00:18:30.980 --> 00:18:32.420]   The reason I want to do that--
[00:18:32.420 --> 00:18:33.880]   I know there are a lot of people who
[00:18:33.880 --> 00:18:38.380]   use Keras use another thing that we heavily advertise,
[00:18:38.380 --> 00:18:41.900]   which is contript TF, contript TF learn.
[00:18:41.900 --> 00:18:45.620]   So I feel like I'm giving you all the ingredients.
[00:18:45.620 --> 00:18:49.300]   So even though you could go to Whole Foods
[00:18:49.300 --> 00:18:52.500]   and buy the package meal, maybe one day you
[00:18:52.500 --> 00:18:53.860]   don't like the way they cook it.
[00:18:53.860 --> 00:18:58.580]   So I'm giving you all your lobsters, your Kobe beef,
[00:18:58.580 --> 00:19:00.900]   so that you can actually assemble whatever
[00:19:00.900 --> 00:19:03.460]   you want to build yourself.
[00:19:03.460 --> 00:19:06.500]   So this next one is very key.
[00:19:06.500 --> 00:19:08.540]   It's a very key concept.
[00:19:08.540 --> 00:19:10.620]   Here you'll see variables.
[00:19:10.620 --> 00:19:13.780]   So variable in TensorFlow is how--
[00:19:13.780 --> 00:19:16.460]   it's corresponding to the square.
[00:19:16.460 --> 00:19:18.060]   Any of you remember this slide?
[00:19:18.060 --> 00:19:20.500]   OK, I'm going to switch quickly.
[00:19:20.500 --> 00:19:21.220]   Don't freak out.
[00:19:21.220 --> 00:19:28.340]   So actually, I wanted you all to commit this little graph
[00:19:28.340 --> 00:19:32.700]   to your memory, because you'll be seeing this over and over
[00:19:32.700 --> 00:19:33.200]   again.
[00:19:33.200 --> 00:19:35.000]   And it makes a lot more sense when you have
[00:19:35.000 --> 00:19:37.540]   this visual representation.
[00:19:37.540 --> 00:19:42.140]   So in TensorFlow, the way we hold all the data,
[00:19:42.140 --> 00:19:46.660]   the weights and the biases associated with your network
[00:19:46.660 --> 00:19:48.620]   is using something called variable.
[00:19:48.620 --> 00:19:51.740]   It's a stateful operation.
[00:19:51.740 --> 00:19:54.820]   I'm going to switch back, OK?
[00:19:54.820 --> 00:19:57.820]   So this is what we are doing in section 1.3.
[00:19:57.820 --> 00:20:02.860]   We are building those square nodes in your network
[00:20:02.860 --> 00:20:04.580]   to hold these weights and variables.
[00:20:04.580 --> 00:20:07.100]   And they are the ones when you train.
[00:20:07.100 --> 00:20:09.380]   That's where the gradients will be applied to,
[00:20:09.380 --> 00:20:14.100]   so that they will eventually resemble the target network
[00:20:14.100 --> 00:20:17.500]   that you are trying to train for.
[00:20:17.500 --> 00:20:18.500]   So now you have built it.
[00:20:18.500 --> 00:20:19.500]   Wonderful.
[00:20:19.500 --> 00:20:20.980]   So you can shift return.
[00:20:20.980 --> 00:20:23.980]   Do you see anything?
[00:20:23.980 --> 00:20:26.060]   Nope.
[00:20:26.060 --> 00:20:27.820]   So exactly what have we built?
[00:20:27.820 --> 00:20:28.540]   That's uncommon.
[00:20:28.540 --> 00:20:31.220]   Take a look.
[00:20:31.220 --> 00:20:33.660]   So these are called the variable objects.
[00:20:33.660 --> 00:20:36.980]   So at the bottom of the slide for this lab,
[00:20:36.980 --> 00:20:42.620]   I have a link, which is our Google 3 docs, the API docs,
[00:20:42.620 --> 00:20:45.780]   which is available in GitHub.
[00:20:45.780 --> 00:20:48.420]   I think you should always have that up,
[00:20:48.420 --> 00:20:50.260]   so whenever you want to do something,
[00:20:50.260 --> 00:20:52.300]   you would know what kind of operations
[00:20:52.300 --> 00:20:54.840]   are possible with this object.
[00:20:54.840 --> 00:21:01.740]   For example, I can say here, what's the name of this?
[00:21:01.740 --> 00:21:02.860]   Oh, it's called variable 6.
[00:21:02.860 --> 00:21:04.300]   Why is it called variable 6?
[00:21:04.300 --> 00:21:07.700]   Oh, it's because when I create this variable,
[00:21:07.700 --> 00:21:08.660]   I didn't give it a name.
[00:21:08.660 --> 00:21:11.660]   So I can say Sherry's--
[00:21:11.660 --> 00:21:14.660]   Sherry weight.
[00:21:14.660 --> 00:21:15.420]   I hope that's not--
[00:21:15.420 --> 00:21:22.860]   but so see, now my variable is called Sherry weight.
[00:21:22.860 --> 00:21:25.480]   Same thing with my--
[00:21:25.480 --> 00:21:27.800]   so this would be a good practice, because later--
[00:21:27.800 --> 00:21:45.400]   Sherry by is-- oh, because I ran this so many times.
[00:21:45.400 --> 00:21:47.680]   Every single time you run, if you don't restart,
[00:21:47.680 --> 00:21:51.000]   that is going to continue to grow your current path.
[00:21:51.000 --> 00:21:56.120]   So to avoid that confusion, let me restart it.
[00:21:56.120 --> 00:21:56.620]   Restart.
[00:21:56.620 --> 00:22:06.480]   I had to wait.
[00:22:06.480 --> 00:22:06.980]   Sorry.
[00:22:20.640 --> 00:22:22.480]   So now, so we have done--
[00:22:22.480 --> 00:22:24.600]   built our input, built our inference graph.
[00:22:24.600 --> 00:22:27.920]   Now we can actually build our training graph.
[00:22:27.920 --> 00:22:31.920]   And as you have all learned, we need to define a loss function.
[00:22:31.920 --> 00:22:34.600]   We need to define an optimizer.
[00:22:34.600 --> 00:22:37.000]   I think it's also called something else--
[00:22:37.000 --> 00:22:39.560]   regularizer, maybe some other terms.
[00:22:39.560 --> 00:22:42.760]   And your ultimate goal is to minimize your loss.
[00:22:42.760 --> 00:22:44.520]   So I'm not going to do it here, but you
[00:22:44.520 --> 00:22:46.440]   can do it at your leisure.
[00:22:46.440 --> 00:22:51.880]   You can uncomment all these things that you have created
[00:22:51.880 --> 00:22:53.280]   and see what they are.
[00:22:53.280 --> 00:22:55.840]   And I can tell you these are different operations.
[00:22:55.840 --> 00:22:59.100]   So that's how you actually get to learn about the network
[00:22:59.100 --> 00:23:00.680]   that you have built really well.
[00:23:00.680 --> 00:23:03.200]   In the next line, I'm also not going to uncomment,
[00:23:03.200 --> 00:23:05.740]   but you should at one point.
[00:23:05.740 --> 00:23:08.920]   This is how you can see what you have built.
[00:23:08.920 --> 00:23:10.680]   So actually, why don't we do that?
[00:23:10.680 --> 00:23:12.080]   Because this is really critical.
[00:23:12.080 --> 00:23:14.480]   And as you debug, this would become--
[00:23:14.480 --> 00:23:20.680]   so this is the network that you have built.
[00:23:20.680 --> 00:23:23.480]   They have names, different names.
[00:23:23.480 --> 00:23:24.720]   They have inputs and outputs.
[00:23:24.720 --> 00:23:25.560]   They have attributes.
[00:23:25.560 --> 00:23:29.920]   And this is how we connect all these nodes together.
[00:23:29.920 --> 00:23:31.480]   This is your neural net.
[00:23:31.480 --> 00:23:34.560]   So what you're seeing right now is your neural net
[00:23:34.560 --> 00:23:37.560]   that you have just built. Yeah?
[00:23:37.560 --> 00:23:39.560]   Everybody following?
[00:23:39.560 --> 00:23:41.760]   So now, the next step-- now you're done.
[00:23:41.760 --> 00:23:43.680]   You build your network.
[00:23:43.680 --> 00:23:44.960]   You build all your training.
[00:23:44.960 --> 00:23:47.920]   Now, let's do some training.
[00:23:47.920 --> 00:23:50.920]   So in TensorFlow, do you remember in the architecture
[00:23:50.920 --> 00:23:53.800]   that I showed, you have the front end, C++ and Python
[00:23:53.800 --> 00:23:54.300]   front end.
[00:23:54.300 --> 00:23:56.400]   You use that to build your graphs.
[00:23:56.400 --> 00:23:59.040]   And then you send a graph to your runtime.
[00:23:59.040 --> 00:24:01.480]   And this is exactly what we're doing here.
[00:24:01.480 --> 00:24:03.240]   This is how we talk to the runtime.
[00:24:03.240 --> 00:24:05.320]   We create something called a session.
[00:24:05.320 --> 00:24:07.400]   You get a handle to the session.
[00:24:07.400 --> 00:24:09.280]   And then when you say run, you're
[00:24:09.280 --> 00:24:12.680]   basically sending this session, your graph.
[00:24:12.680 --> 00:24:15.840]   So this is different from the other machine learning
[00:24:15.840 --> 00:24:16.720]   libraries.
[00:24:16.720 --> 00:24:17.840]   I forgot which one.
[00:24:17.840 --> 00:24:19.120]   Those are so-called imperative.
[00:24:19.120 --> 00:24:20.880]   It happens as you type.
[00:24:20.880 --> 00:24:21.960]   TensorFlow is different.
[00:24:21.960 --> 00:24:23.640]   You have to construct your graph.
[00:24:23.640 --> 00:24:26.500]   And then you create a session to talk to your runtime
[00:24:26.500 --> 00:24:29.440]   so that it knows how to run on your different devices.
[00:24:29.440 --> 00:24:34.200]   That's a very important concept because people constantly
[00:24:34.200 --> 00:24:34.760]   compare.
[00:24:34.760 --> 00:24:38.000]   And it's just different.
[00:24:38.000 --> 00:24:44.080]   So now you can also comment to see what the initial values
[00:24:44.080 --> 00:24:45.280]   are.
[00:24:45.280 --> 00:24:46.640]   But we're not going to do that.
[00:24:46.640 --> 00:24:48.560]   We're just going to run it.
[00:24:48.560 --> 00:24:49.720]   And now we're going to train.
[00:24:49.720 --> 00:24:56.200]   The data is not so--
[00:24:56.200 --> 00:24:58.760]   what do you think of the data?
[00:24:58.760 --> 00:25:01.000]   Did we succeed in guessing?
[00:25:01.000 --> 00:25:06.000]   Is everybody following what we are trying to do?
[00:25:07.000 --> 00:25:08.720]   [CHUCKLES]
[00:25:08.720 --> 00:25:09.280]   Yeah?
[00:25:09.280 --> 00:25:09.760]   Yes?
[00:25:09.760 --> 00:25:12.160]   No?
[00:25:12.160 --> 00:25:15.320]   So what was our objective before I started the lab?
[00:25:15.320 --> 00:25:18.760]   What did I say our objective was?
[00:25:18.760 --> 00:25:19.920]   Find the mic.
[00:25:19.920 --> 00:25:21.720]   Yes, to guess the mystery function.
[00:25:21.720 --> 00:25:24.360]   So have we succeeded?
[00:25:24.360 --> 00:25:26.040]   It's really hard to tell.
[00:25:26.040 --> 00:25:29.240]   All right, so now all of you can go to the end
[00:25:29.240 --> 00:25:31.360]   and comment this part.
[00:25:31.360 --> 00:25:32.840]   Let's see how successful we are.
[00:25:33.840 --> 00:25:36.280]   [PAUSE]
[00:25:36.280 --> 00:25:46.400]   So the green line was what we have initialized our weight
[00:25:46.400 --> 00:25:49.000]   and bias to.
[00:25:49.000 --> 00:25:49.560]   Yeah?
[00:25:49.560 --> 00:25:55.880]   The blue dots were the initial value, the target values.
[00:25:55.880 --> 00:26:00.240]   And the red dots is our trained value.
[00:26:00.240 --> 00:26:01.840]   Make sense?
[00:26:01.840 --> 00:26:04.120]   So how successful are we?
[00:26:04.120 --> 00:26:05.800]   Great big success?
[00:26:05.800 --> 00:26:07.600]   Yeah, I would say so.
[00:26:07.600 --> 00:26:11.120]   So any questions?
[00:26:11.120 --> 00:26:12.720]   Any questions so far?
[00:26:12.720 --> 00:26:13.680]   So what are the things?
[00:26:13.680 --> 00:26:15.120]   So everybody should play with this.
[00:26:15.120 --> 00:26:16.320]   You're not going to break it.
[00:26:16.320 --> 00:26:18.400]   This is a notebook, Python notebook.
[00:26:18.400 --> 00:26:21.160]   The worst that happens is they would just say, OK, clear all.
[00:26:21.160 --> 00:26:23.240]   Like, well, I just did, and change it.
[00:26:23.240 --> 00:26:24.320]   So what can you play with?
[00:26:24.320 --> 00:26:26.600]   Since today you learned all these concepts
[00:26:26.600 --> 00:26:29.640]   about different loss functions, different optimizers,
[00:26:29.640 --> 00:26:32.000]   all this crazy different inputs, different data.
[00:26:32.000 --> 00:26:33.880]   So now you can play with it.
[00:26:33.880 --> 00:26:36.600]   How about instead of--
[00:26:36.600 --> 00:26:39.120]   let's pick one.
[00:26:39.120 --> 00:26:47.160]   So instead of gradient descent, what are the other optimizers?
[00:26:47.160 --> 00:26:48.080]   How can you find out?
[00:26:48.080 --> 00:26:49.960]   I guess that's a better question.
[00:26:49.960 --> 00:26:51.760]   If I want to know what other optimizers are
[00:26:51.760 --> 00:26:55.480]   available in TensorFlow, how can I find out?
[00:26:55.480 --> 00:26:56.440]   Very good.
[00:26:56.440 --> 00:27:03.240]   Yes, the GitHub, Google 3, the G3 doc link with the APIs.
[00:27:03.240 --> 00:27:05.240]   I'm going to switch one more tab.
[00:27:05.240 --> 00:27:06.280]   Bear with me.
[00:27:06.280 --> 00:27:10.720]   So this is-- when you go there, this is what you can find.
[00:27:10.720 --> 00:27:12.440]   You can find all the--
[00:27:12.440 --> 00:27:15.800]   let me make it bigger.
[00:27:15.800 --> 00:27:17.840]   So you can find all the different optimizers.
[00:27:17.840 --> 00:27:19.400]   So you can play with that.
[00:27:19.400 --> 00:27:24.340]   So maybe gradient descent is not the best optimizer you can use.
[00:27:24.340 --> 00:27:28.400]   So you go there and say, what are the other optimizers?
[00:27:28.400 --> 00:27:32.600]   And then you can literally come here and search optimizer.
[00:27:32.600 --> 00:27:38.200]   Well, you can say, wow, I have add the delta, add a grad,
[00:27:38.200 --> 00:27:39.400]   add them.
[00:27:39.400 --> 00:27:41.920]   I'm sure there are more-- a momentum.
[00:27:41.920 --> 00:27:43.800]   So we also welcome contribution.
[00:27:43.800 --> 00:27:48.040]   If you don't like any of these, please do go contribute.
[00:27:48.040 --> 00:27:50.120]   A new optimizer, send a pull request.
[00:27:50.120 --> 00:27:51.640]   We would love to have it.
[00:27:51.640 --> 00:27:53.960]   So I would like to say this over and over again.
[00:27:53.960 --> 00:27:55.000]   We love contribution.
[00:27:55.000 --> 00:27:56.680]   It's an open source project.
[00:27:56.680 --> 00:27:57.660]   So keep that in mind.
[00:27:57.660 --> 00:28:03.160]   We would love to see your code or your models on GitHub.
[00:28:03.160 --> 00:28:09.960]   So back to this one.
[00:28:09.960 --> 00:28:11.120]   How is everybody feeling?
[00:28:11.120 --> 00:28:12.320]   This is too simple?
[00:28:12.320 --> 00:28:13.240]   Yeah?
[00:28:13.240 --> 00:28:14.880]   Should we go register?
[00:28:14.880 --> 00:28:15.880]   Yes?
[00:28:15.880 --> 00:28:23.360]   [INAUDIBLE]
[00:28:23.360 --> 00:28:26.760]   Can I say that one?
[00:28:26.760 --> 00:28:27.260]   Yeah.
[00:28:27.260 --> 00:28:29.720]   I mean, the gist is not good.
[00:28:29.720 --> 00:28:33.720]   The optimization rule says that it's
[00:28:33.720 --> 00:28:37.160]   up to all the [INAUDIBLE]
[00:28:37.160 --> 00:28:39.480]   Oh, is that right?
[00:28:39.480 --> 00:28:43.080]   Hit Tab to see all the other optimizers you meant?
[00:28:43.080 --> 00:28:43.960]   Oh, brilliant.
[00:28:43.960 --> 00:28:45.400]   See, I didn't even know that.
[00:28:45.400 --> 00:28:47.400]   Learn something new every day.
[00:28:47.400 --> 00:28:49.400]   Let me go there.
[00:28:49.400 --> 00:28:51.280]   Tab.
[00:28:51.280 --> 00:28:53.080]   Here?
[00:28:53.080 --> 00:28:56.160]   Oh, yay.
[00:28:56.160 --> 00:28:58.480]   So this is even easier.
[00:28:58.480 --> 00:28:59.640]   Thank you.
[00:28:59.640 --> 00:29:01.720]   Clearly, I don't program in Notebook
[00:29:01.720 --> 00:29:04.640]   as often as I should have.
[00:29:04.640 --> 00:29:07.120]   So this is where you can-- all the wonderful things
[00:29:07.120 --> 00:29:07.920]   that you can do.
[00:29:07.920 --> 00:29:08.440]   Thank you.
[00:29:08.440 --> 00:29:14.560]   This is probably a little too low level.
[00:29:14.560 --> 00:29:17.800]   I think it has everything.
[00:29:17.800 --> 00:29:18.960]   But that's a very good tip.
[00:29:18.960 --> 00:29:20.760]   Thank you.
[00:29:20.760 --> 00:29:23.640]   So anything else you would like to see with linear regression?
[00:29:23.640 --> 00:29:24.320]   It's too simple.
[00:29:24.320 --> 00:29:28.960]   You guys all want to recognize some digits.
[00:29:28.960 --> 00:29:29.840]   All right.
[00:29:29.840 --> 00:29:33.960]   So that sounds like a consensus to me.
[00:29:33.960 --> 00:29:34.680]   So let's move.
[00:29:34.680 --> 00:29:37.520]   If you just go to the bottom, you can say--
[00:29:37.520 --> 00:29:38.320]   click on this one.
[00:29:38.320 --> 00:29:51.240]   [VIDEO PLAYBACK]
[00:29:51.240 --> 00:29:53.960]   So this is our MNIST model.
[00:29:53.960 --> 00:29:56.080]   So before we start the lab, so once again,
[00:29:56.080 --> 00:29:58.720]   what are we trying to do?
[00:29:58.720 --> 00:30:00.640]   So we have all these handwritten digits.
[00:30:00.640 --> 00:30:02.280]   What does MNIST stand for?
[00:30:02.280 --> 00:30:03.280]   Does anybody know?
[00:30:03.280 --> 00:30:04.360]   What does MNIST stand for?
[00:30:04.360 --> 00:30:12.240]   [INAUDIBLE]
[00:30:12.240 --> 00:30:12.760]   Very good.
[00:30:12.760 --> 00:30:15.280]   See, somebody can Google.
[00:30:15.280 --> 00:30:16.920]   Very good.
[00:30:16.920 --> 00:30:20.360]   So it stands for, I think, Mixed National Institute
[00:30:20.360 --> 00:30:24.040]   of Standards and Technology, something like that.
[00:30:24.040 --> 00:30:26.520]   So they have this giant collection of digits.
[00:30:26.520 --> 00:30:30.080]   So if you go to the post office, you already
[00:30:30.080 --> 00:30:31.280]   know that it's a trivia.
[00:30:31.280 --> 00:30:32.200]   It's a solved problem.
[00:30:32.200 --> 00:30:33.840]   But I don't know if they actually
[00:30:33.840 --> 00:30:35.040]   use machine learning.
[00:30:35.040 --> 00:30:40.920]   But our goal today is to build a little network using TensorFlow
[00:30:40.920 --> 00:30:44.280]   that can recognize these digits.
[00:30:44.280 --> 00:30:47.040]   Once again, we will not have all the answers.
[00:30:47.040 --> 00:30:50.760]   So all we know is that the network, the input
[00:30:50.760 --> 00:30:52.320]   will give us a 1.
[00:30:52.320 --> 00:30:54.880]   And then we'll say it's a 9.
[00:30:54.880 --> 00:30:59.560]   And then we have the so-called ground truth.
[00:30:59.560 --> 00:31:01.880]   And then they will look at it and say, no, you're wrong.
[00:31:01.880 --> 00:31:03.440]   And then we'll have to say, OK, fine.
[00:31:03.440 --> 00:31:04.520]   This is the difference.
[00:31:04.520 --> 00:31:06.840]   We are going to train the network that way.
[00:31:06.840 --> 00:31:09.840]   So that's our goal.
[00:31:09.840 --> 00:31:10.520]   Yeah?
[00:31:10.520 --> 00:31:12.140]   Everybody see the network on the slide?
[00:31:12.140 --> 00:31:14.600]   So now we can go to the lab.
[00:31:14.600 --> 00:31:23.280]   So can anybody tell me what are the three or four things that's
[00:31:23.280 --> 00:31:25.640]   really important whenever you build a network?
[00:31:25.640 --> 00:31:28.040]   What's the first one?
[00:31:28.040 --> 00:31:28.720]   Your data.
[00:31:28.720 --> 00:31:31.640]   Second one?
[00:31:31.640 --> 00:31:32.560]   Inference graph.
[00:31:32.560 --> 00:31:35.600]   Third one?
[00:31:35.600 --> 00:31:36.680]   Your train graph.
[00:31:36.680 --> 00:31:40.320]   And with this lab, I'm going to teach you a little bit more.
[00:31:40.320 --> 00:31:42.400]   They are like the rock.
[00:31:42.400 --> 00:31:44.560]   Like when you go to a restaurant, I not only give you
[00:31:44.560 --> 00:31:46.720]   your lobster or your Kobe beef, I'm
[00:31:46.720 --> 00:31:50.000]   also going to give you a little rock so you can cook it.
[00:31:50.000 --> 00:31:54.480]   So in this lab, I've also teach some absolutely critical
[00:31:54.480 --> 00:31:56.480]   additional infrastructure pieces,
[00:31:56.480 --> 00:31:59.200]   such as how to save a checkpoint,
[00:31:59.200 --> 00:32:01.200]   how to load from a checkpoint, and how
[00:32:01.200 --> 00:32:03.160]   do you evaluate your network.
[00:32:03.160 --> 00:32:05.160]   I think somebody at one point asked,
[00:32:05.160 --> 00:32:07.040]   how do you know the network is enough?
[00:32:07.040 --> 00:32:09.520]   You evaluate it to see if it's good enough.
[00:32:09.520 --> 00:32:12.560]   So those are the three new pieces of information
[00:32:12.560 --> 00:32:14.560]   that I'll be teaching you.
[00:32:14.560 --> 00:32:18.000]   And also, I'll teach you a really, really useful concept.
[00:32:18.000 --> 00:32:20.600]   It's called placeholder.
[00:32:20.600 --> 00:32:22.840]   That was requested by all the researchers.
[00:32:22.840 --> 00:32:26.520]   We didn't used to have it, but they all came to us and say,
[00:32:26.520 --> 00:32:29.240]   when I train, I want to be able to feed my network any data
[00:32:29.240 --> 00:32:29.760]   we want.
[00:32:29.760 --> 00:32:31.440]   So that's a really key concept that's
[00:32:31.440 --> 00:32:34.600]   really useful for any practical training.
[00:32:34.600 --> 00:32:37.280]   Whenever you start writing real training code,
[00:32:37.280 --> 00:32:39.040]   I think that will come in handy.
[00:32:39.040 --> 00:32:41.880]   So those are the, I think, four concepts now
[00:32:41.880 --> 00:32:44.080]   that I will introduce in this lab that's
[00:32:44.080 --> 00:32:46.240]   slightly different from the previous one--
[00:32:46.240 --> 00:32:48.800]   how to save checkpoint, how to load from checkpoint,
[00:32:48.800 --> 00:32:51.440]   how to run evaluation, and how to use placeholders.
[00:32:51.440 --> 00:32:52.960]   I think the placeholder is actually
[00:32:52.960 --> 00:32:54.160]   going to be the first one.
[00:32:54.160 --> 00:32:57.760]   So once again, we have our typical boilerplate stuff.
[00:32:57.760 --> 00:33:02.920]   So you hit Return, you import a bunch of libraries.
[00:33:02.920 --> 00:33:06.840]   The second one, this is just for convenience.
[00:33:06.840 --> 00:33:10.040]   I define a set of constants.
[00:33:10.040 --> 00:33:13.000]   Some of them you can play with, such as the maximum number
[00:33:13.000 --> 00:33:16.320]   of steps, where you're going to save all your data,
[00:33:16.320 --> 00:33:19.320]   how big the batch sizes are, but some other things
[00:33:19.320 --> 00:33:21.320]   that you cannot change because of the data
[00:33:21.320 --> 00:33:22.400]   that I'm providing you.
[00:33:22.400 --> 00:33:26.840]   For example, the MNIST pictures.
[00:33:26.840 --> 00:33:27.880]   Any questions so far?
[00:33:27.880 --> 00:33:35.000]   So now we'll read some data.
[00:33:35.000 --> 00:33:36.840]   Is everybody there in 2.3?
[00:33:36.840 --> 00:33:38.680]   I'm at 2.3 right now.
[00:33:38.680 --> 00:33:41.120]   So now I use--
[00:33:41.120 --> 00:33:43.520]   if you don't have /tmp, it might be an issue,
[00:33:43.520 --> 00:33:46.000]   but hopefully you do.
[00:33:46.000 --> 00:33:52.360]   If you don't have /tmp, change the directory name.
[00:33:52.360 --> 00:33:54.600]   So the next one is where we build inference.
[00:33:54.600 --> 00:33:56.360]   So can anybody just glance and then
[00:33:56.360 --> 00:33:58.840]   tell me what we're building?
[00:33:58.840 --> 00:33:59.760]   What kind of network?
[00:33:59.760 --> 00:34:01.120]   How many layers am I building?
[00:34:01.120 --> 00:34:07.480]   I have two hidden layers.
[00:34:07.480 --> 00:34:12.080]   You have all learned hidden layers today.
[00:34:12.080 --> 00:34:19.520]   And I also have a linear layer, which will produce logits.
[00:34:19.520 --> 00:34:20.520]   That's correct.
[00:34:20.520 --> 00:34:23.840]   So that's what all the inference graphs will always do.
[00:34:23.840 --> 00:34:26.080]   They always construct your graph,
[00:34:26.080 --> 00:34:28.520]   and they produce logistic outputs.
[00:34:28.520 --> 00:34:31.480]   So once again, here you can uncomment it and see
[00:34:31.480 --> 00:34:34.440]   what kind of graph you have built.
[00:34:34.440 --> 00:34:38.880]   Once you have done the whole tutorial by yourself,
[00:34:38.880 --> 00:34:41.480]   you can actually run TensorBoard,
[00:34:41.480 --> 00:34:44.920]   and you can actually load this graph that you have saved.
[00:34:44.920 --> 00:34:48.600]   And you can visualize it, like what I have shown in the slide.
[00:34:48.600 --> 00:34:51.200]   I didn't draw that slide by hand.
[00:34:51.200 --> 00:34:53.160]   It's actually produced by TensorBoard.
[00:34:53.160 --> 00:34:56.200]   So you can see the connection of all your nodes.
[00:34:56.200 --> 00:34:58.840]   So I feel that that visual representation
[00:34:58.840 --> 00:34:59.680]   is really important.
[00:34:59.680 --> 00:35:01.560]   Also, it's very easy for you to validate
[00:35:01.560 --> 00:35:04.040]   that you have indeed built a graph that you thought.
[00:35:04.040 --> 00:35:06.480]   Sometimes people call something repeatedly,
[00:35:06.480 --> 00:35:08.480]   and they have generated this gigantic graph.
[00:35:08.480 --> 00:35:10.400]   They're like, oh, that wasn't what I meant.
[00:35:10.400 --> 00:35:14.560]   So being able to visualize is really important.
[00:35:14.560 --> 00:35:16.760]   Any questions so far?
[00:35:16.760 --> 00:35:18.280]   See here, I have good habits.
[00:35:18.280 --> 00:35:20.640]   I actually gave all my variables names.
[00:35:20.640 --> 00:35:22.960]   Once again, the hidden layer 1, hidden layer 2.
[00:35:22.960 --> 00:35:26.440]   They all have weights and biases, weights and biases,
[00:35:26.440 --> 00:35:28.040]   et cetera.
[00:35:28.040 --> 00:35:30.160]   So now we're going to build our train graph.
[00:35:30.160 --> 00:35:35.800]   So here is-- actually, here, there's no new concept.
[00:35:35.800 --> 00:35:38.720]   Once again, you define the loss function.
[00:35:38.720 --> 00:35:41.920]   We once again pick gradient descent as our optimizer.
[00:35:41.920 --> 00:35:44.560]   We added a global step variable.
[00:35:44.560 --> 00:35:48.000]   That's what we will use later when we save our checkpoints.
[00:35:48.000 --> 00:35:52.480]   So you actually know at which point, what checkpoint
[00:35:52.480 --> 00:35:53.480]   this corresponds to.
[00:35:53.480 --> 00:35:55.960]   Otherwise, if you always save it to the same name,
[00:35:55.960 --> 00:36:01.880]   then later you say, wow, this result is so wonderful.
[00:36:01.880 --> 00:36:03.240]   But how long did it take?
[00:36:03.240 --> 00:36:04.040]   You have no idea.
[00:36:04.040 --> 00:36:07.480]   So that's a training concept that we introduced.
[00:36:07.480 --> 00:36:08.940]   It's called global step, basically
[00:36:08.940 --> 00:36:10.360]   how long you have trained.
[00:36:10.360 --> 00:36:13.080]   And we usually save that with the checkpoint
[00:36:13.080 --> 00:36:18.080]   so you know which checkpoint has the best information.
[00:36:18.080 --> 00:36:21.040]   Yeah, everybody is good at 2.5?
[00:36:21.040 --> 00:36:23.440]   So now the next one is the additional stuff
[00:36:23.440 --> 00:36:26.720]   that I just mentioned.
[00:36:26.720 --> 00:36:28.520]   That piece of rock that I'm giving you now
[00:36:28.520 --> 00:36:29.880]   to cook your stuff.
[00:36:29.880 --> 00:36:33.040]   So one is a placeholder.
[00:36:33.040 --> 00:36:36.080]   So we are going to define two, one to hold your image
[00:36:36.080 --> 00:36:39.760]   and the other to hold your labels.
[00:36:39.760 --> 00:36:41.740]   We build it this way so that we only
[00:36:41.740 --> 00:36:43.880]   need to build a graph once.
[00:36:43.880 --> 00:36:47.960]   And we will be able to use it for both training, inference,
[00:36:47.960 --> 00:36:49.560]   and evaluation later.
[00:36:49.560 --> 00:36:51.320]   It's very handy.
[00:36:51.320 --> 00:36:52.880]   You don't have to do it this way.
[00:36:52.880 --> 00:36:55.080]   And one of the exercises I put in my slide
[00:36:55.080 --> 00:36:57.240]   is to try to do it differently.
[00:36:57.240 --> 00:36:59.000]   But this is a very handy way and get you
[00:36:59.000 --> 00:37:01.040]   very far with minimum work.
[00:37:01.040 --> 00:37:05.280]   So as I said in the slides, I know
[00:37:05.280 --> 00:37:09.120]   I don't have any highlighters, beams.
[00:37:09.120 --> 00:37:13.440]   But you see there it says, after you create your placeholders,
[00:37:13.440 --> 00:37:17.680]   I said, add to collection and remember this up.
[00:37:17.680 --> 00:37:19.920]   And later we'll see how we're going to call this up
[00:37:19.920 --> 00:37:23.160]   and how we're going to use it.
[00:37:23.160 --> 00:37:26.360]   And the next one, we're going to call our inference,
[00:37:26.360 --> 00:37:29.480]   build our inference.
[00:37:29.480 --> 00:37:32.200]   Is everybody following this part OK?
[00:37:32.200 --> 00:37:33.920]   And once again, we remember our logits.
[00:37:33.920 --> 00:37:39.880]   And then we create our train op and our loss op,
[00:37:39.880 --> 00:37:44.000]   just like with linear regression.
[00:37:44.000 --> 00:37:45.540]   Just like with the linear regression,
[00:37:45.540 --> 00:37:48.080]   we're going to initialize all our variables.
[00:37:48.080 --> 00:37:52.560]   And now at the bottom of this cell,
[00:37:52.560 --> 00:37:55.160]   that's the second new concept that I'm introducing,
[00:37:55.160 --> 00:37:56.760]   which is the saver.
[00:37:56.760 --> 00:37:59.720]   This is what you will use to do checkpoints,
[00:37:59.720 --> 00:38:01.640]   to save the states of your network
[00:38:01.640 --> 00:38:03.800]   so that later you can evaluate it.
[00:38:03.800 --> 00:38:06.480]   Or if your training was interrupted,
[00:38:06.480 --> 00:38:08.280]   you can load from a previous checkpoint
[00:38:08.280 --> 00:38:10.120]   and continue training from there,
[00:38:10.120 --> 00:38:13.840]   rather than always reinitialize all your variables
[00:38:13.840 --> 00:38:15.200]   and start from scratch.
[00:38:15.200 --> 00:38:17.820]   When you're training really big networks, such as Inception,
[00:38:17.820 --> 00:38:19.500]   it's absolutely critical.
[00:38:19.500 --> 00:38:23.540]   Because I think when I first trained Inception,
[00:38:23.540 --> 00:38:26.060]   it took probably six days.
[00:38:26.060 --> 00:38:28.240]   And then later, when we have 50 replicas,
[00:38:28.240 --> 00:38:30.920]   it took still-- like, stay of the hour is still 2 and 1/2
[00:38:30.920 --> 00:38:31.520]   days.
[00:38:31.520 --> 00:38:36.140]   You don't want to have to start from scratch every single time.
[00:38:36.140 --> 00:38:38.860]   So yeah, everybody got that?
[00:38:38.860 --> 00:38:42.780]   The placeholder and the saver.
[00:38:42.780 --> 00:38:45.340]   So now it's 2.7.
[00:38:45.340 --> 00:38:51.300]   We're going to go to 2.7.
[00:38:51.300 --> 00:38:52.620]   Lots of code.
[00:38:52.620 --> 00:38:54.420]   Can anybody tell me what it's trying to do?
[00:38:54.420 --> 00:39:07.300]   So this is an-- yes.
[00:39:07.300 --> 00:39:10.820]   So it's trying to minimize loss.
[00:39:10.820 --> 00:39:14.340]   We can actually see this.
[00:39:14.340 --> 00:39:16.300]   So we'll run it once, OK?
[00:39:16.300 --> 00:39:23.020]   Where did I go?
[00:39:23.020 --> 00:39:24.740]   OK.
[00:39:24.740 --> 00:39:25.580]   Very fast.
[00:39:25.580 --> 00:39:28.500]   It's done.
[00:39:28.500 --> 00:39:32.580]   But what if I really want to see what it's doing?
[00:39:32.580 --> 00:39:35.620]   So Python is wonderful.
[00:39:35.620 --> 00:39:38.100]   So I would like to actually see--
[00:39:38.100 --> 00:39:40.660]   did somebody show how you know your training
[00:39:40.660 --> 00:39:41.420]   is going well?
[00:39:41.420 --> 00:39:43.460]   They show the loss going down, going down.
[00:39:43.460 --> 00:39:46.060]   Oh, I think my training is going really well.
[00:39:46.060 --> 00:39:48.420]   So we're going to do something similar.
[00:39:48.420 --> 00:39:49.620]   Sorry.
[00:39:49.620 --> 00:39:52.860]   So I'm going to create a variable.
[00:39:52.860 --> 00:39:53.700]   What do you call it?
[00:39:53.700 --> 00:39:56.340]   Losses?
[00:39:56.340 --> 00:40:00.060]   Which is just an array.
[00:40:00.060 --> 00:40:06.300]   So here, I'm actually going to remember it.
[00:40:06.300 --> 00:40:06.800]   Pinned.
[00:40:06.800 --> 00:40:17.260]   So what am I collecting?
[00:40:17.260 --> 00:40:25.280]   Matplotlib.
[00:40:25.280 --> 00:40:35.380]   Anybody remember this?
[00:40:35.380 --> 00:40:38.500]   It's a plot.
[00:40:38.500 --> 00:40:39.260]   Let's try this.
[00:40:39.260 --> 00:40:49.100]   Oh, look at that.
[00:40:49.100 --> 00:40:51.820]   Now, do you see your loss going down?
[00:40:51.820 --> 00:40:55.900]   So as you train, your loss actually goes down.
[00:40:55.900 --> 00:40:59.660]   So this is how, when you do large-scale training,
[00:40:59.660 --> 00:41:00.820]   this is what we typically do.
[00:41:00.820 --> 00:41:04.060]   We have a gazillion of these jobs running.
[00:41:04.060 --> 00:41:06.420]   In the morning, we would just glance at it,
[00:41:06.420 --> 00:41:09.660]   and we know, oh, which one is doing really, really well.
[00:41:09.660 --> 00:41:12.820]   So of course, that's just when you are prototyping.
[00:41:12.820 --> 00:41:14.580]   That's a really, really handy tool.
[00:41:14.580 --> 00:41:17.660]   But I'm going to show you something even better.
[00:41:17.660 --> 00:41:20.260]   Oh, that's part of the exercise.
[00:41:20.260 --> 00:41:21.700]   Man, I don't have it.
[00:41:21.700 --> 00:41:24.460]   So as one of the exercises, I also
[00:41:24.460 --> 00:41:27.580]   put the answers in the backup slides
[00:41:27.580 --> 00:41:30.860]   that you guys are welcome to cut and paste into a cell.
[00:41:30.860 --> 00:41:34.940]   Then you can actually run all the evaluation
[00:41:34.940 --> 00:41:38.100]   sets against your checkpoint so that you know
[00:41:38.100 --> 00:41:39.300]   how well you're performing.
[00:41:39.300 --> 00:41:42.300]   So you don't have to rely on your eyes,
[00:41:42.300 --> 00:41:44.620]   glancing, oh, my loss is going down,
[00:41:44.620 --> 00:41:48.700]   or relying on validating a single image.
[00:41:48.700 --> 00:41:50.540]   But see, this is how easy it is.
[00:41:50.540 --> 00:41:52.260]   This is how easy the prototype.
[00:41:52.260 --> 00:41:53.700]   And you can learn it.
[00:41:53.700 --> 00:41:58.380]   Very often, our researchers will cut and paste their Colab code
[00:41:58.380 --> 00:42:02.260]   and put it in a file, and that's basically their algorithm.
[00:42:02.260 --> 00:42:04.740]   And they will publish that with their paper.
[00:42:04.740 --> 00:42:09.420]   They would send it to our data scientists or production
[00:42:09.420 --> 00:42:10.060]   people.
[00:42:10.060 --> 00:42:13.300]   We would actually prototype some of their research.
[00:42:13.300 --> 00:42:16.460]   This is how easy, literally, from research to prototyping
[00:42:16.460 --> 00:42:17.740]   to production.
[00:42:17.740 --> 00:42:22.140]   Really streamlined, and you can do it in no time.
[00:42:22.140 --> 00:42:25.340]   So for those of you who have run this step,
[00:42:25.340 --> 00:42:27.980]   can you do an LS in your data path,
[00:42:27.980 --> 00:42:32.140]   wherever you saved that, wherever you declare
[00:42:32.140 --> 00:42:33.980]   your trainer to be?
[00:42:33.980 --> 00:42:34.980]   What do you see in there?
[00:42:34.980 --> 00:42:39.380]   Checkpoints.
[00:42:39.380 --> 00:42:40.460]   That's right.
[00:42:40.460 --> 00:42:42.460]   That's the money.
[00:42:42.460 --> 00:42:46.940]   That's after all this work, all this training
[00:42:46.940 --> 00:42:48.580]   on all these gazillion machines.
[00:42:48.580 --> 00:42:52.180]   That's where all your ways, your biases are stored,
[00:42:52.180 --> 00:42:58.540]   so that later you can load this network up and do your inception
[00:42:58.540 --> 00:43:03.900]   to recognize images, to reply to email, to do art,
[00:43:03.900 --> 00:43:04.980]   et cetera, et cetera.
[00:43:04.980 --> 00:43:06.340]   So that's really critical.
[00:43:06.340 --> 00:43:09.100]   But how do we use it?
[00:43:09.100 --> 00:43:10.700]   Have no fear.
[00:43:10.700 --> 00:43:15.140]   All right, let's move on to 2.8, if you are not already there.
[00:43:15.140 --> 00:43:17.500]   So can somebody tell me what we are trying to do first?
[00:43:22.060 --> 00:43:22.620]   That's right.
[00:43:22.620 --> 00:43:24.140]   First, we load the checkpoint.
[00:43:24.140 --> 00:43:28.700]   And you remember all the things that we told our program
[00:43:28.700 --> 00:43:33.380]   to remember, the logits, and the image placeholder,
[00:43:33.380 --> 00:43:34.580]   and the label placeholder.
[00:43:34.580 --> 00:43:36.900]   How are we going to use it now?
[00:43:36.900 --> 00:43:40.260]   We're going to feed it some images from our evaluation
[00:43:40.260 --> 00:43:41.980]   and see what it thinks.
[00:43:41.980 --> 00:43:50.340]   So now if you hit Return, what's the ground truth?
[00:43:50.340 --> 00:43:51.180]   Five.
[00:43:51.180 --> 00:43:52.180]   What's our prediction?
[00:43:52.180 --> 00:43:55.500]   Three.
[00:43:55.500 --> 00:43:56.580]   What's the actual image?
[00:43:56.580 --> 00:44:02.580]   Could be three, could be five.
[00:44:02.580 --> 00:44:05.660]   But so the machine is getting pretty close.
[00:44:05.660 --> 00:44:07.020]   I would say that's a three.
[00:44:07.020 --> 00:44:13.100]   OK, let's try a different one.
[00:44:13.100 --> 00:44:16.340]   So you can hit Return again in the same cell.
[00:44:16.340 --> 00:44:18.140]   Oh, I need to somehow move this.
[00:44:18.140 --> 00:44:19.660]   So what's the ground truth this time?
[00:44:19.660 --> 00:44:21.540]   [INAUDIBLE]
[00:44:21.540 --> 00:44:23.100]   Yeah, I got it right.
[00:44:23.100 --> 00:44:24.500]   So you can keep hitting.
[00:44:24.500 --> 00:44:29.540]   You can keep hitting Return and see how well it's doing.
[00:44:29.540 --> 00:44:31.940]   But instead of validating, instead
[00:44:31.940 --> 00:44:34.860]   of hitting Return 100 times and count how many times
[00:44:34.860 --> 00:44:38.460]   it has gotten it wrong, as I said in one of the exercises,
[00:44:38.460 --> 00:44:41.500]   and I also put the answer in the slides,
[00:44:41.500 --> 00:44:42.980]   so you can cut and paste and actually
[00:44:42.980 --> 00:44:48.660]   do a complete validation on the whole validation set.
[00:44:48.660 --> 00:44:50.980]   But what do you think?
[00:44:50.980 --> 00:44:54.460]   So you can actually handwrite a different digit.
[00:44:54.460 --> 00:44:56.780]   But the trick is that a lot of people actually tried that
[00:44:56.780 --> 00:44:59.460]   and told me it doesn't seem to work.
[00:44:59.460 --> 00:45:03.300]   So remember on the slide, I said this is what the machine sees.
[00:45:03.300 --> 00:45:06.420]   This is what your eye sees, and this is what the machine sees.
[00:45:06.420 --> 00:45:09.100]   So in the MNIST data set, all the numbers
[00:45:09.100 --> 00:45:11.820]   are between 0 and 1, I believe.
[00:45:11.820 --> 00:45:14.300]   I could be wrong, but I believe it's between 0 and 1.
[00:45:14.300 --> 00:45:17.100]   So if you just use a random tool like your phone,
[00:45:17.100 --> 00:45:20.100]   you write a number and you upload it, number one,
[00:45:20.100 --> 00:45:25.060]   the picture might be too big and you need to scale it down.
[00:45:25.060 --> 00:45:27.900]   Number two, it might have a different representation.
[00:45:27.900 --> 00:45:30.420]   Sometimes it's from 0 to 255, and you
[00:45:30.420 --> 00:45:34.460]   need to scale it to the range, that MNIST.
[00:45:34.460 --> 00:45:36.500]   That's how you have trained your network.
[00:45:36.500 --> 00:45:38.580]   If you train your network with those data,
[00:45:38.580 --> 00:45:40.220]   and then it should be able to recognize
[00:45:40.220 --> 00:45:43.900]   the same set of data, just like when we teach a baby, right?
[00:45:43.900 --> 00:45:46.860]   If you have never been exposed to something,
[00:45:46.860 --> 00:45:49.580]   you are not going to be able to recognize it.
[00:45:49.580 --> 00:45:54.460]   Just like with the OREO, one of our colleagues
[00:45:54.460 --> 00:45:59.100]   captioned that program a while ago.
[00:45:59.100 --> 00:46:02.100]   Any time when it sees something that it doesn't recognize--
[00:46:02.100 --> 00:46:05.460]   have anybody played with that captioning software?
[00:46:05.460 --> 00:46:07.460]   It's super fun.
[00:46:07.460 --> 00:46:09.620]   So you can take a picture and say,
[00:46:09.620 --> 00:46:14.740]   two people eating pizza or dog surfing.
[00:46:14.740 --> 00:46:17.380]   But any time it sees something that it has never
[00:46:17.380 --> 00:46:21.540]   been trained on, it would say, man talking on a cell phone.
[00:46:21.540 --> 00:46:23.980]   So for a while, we had a lot of fun with it.
[00:46:23.980 --> 00:46:26.060]   We would put a watermelon on the post,
[00:46:26.060 --> 00:46:28.140]   and it would say, man talking on a cell phone.
[00:46:28.140 --> 00:46:31.220]   You put a bunch of furniture in the room with nothing,
[00:46:31.220 --> 00:46:33.140]   and it would say, man talking on a cell phone.
[00:46:33.140 --> 00:46:34.100]   So it was really fun.
[00:46:34.100 --> 00:46:36.860]   But just like with your numbers, if you have never
[00:46:36.860 --> 00:46:40.100]   trained it with that style--
[00:46:40.100 --> 00:46:42.420]   like if I write Chinese characters here,
[00:46:42.420 --> 00:46:44.100]   it's never going to recognize it.
[00:46:44.100 --> 00:46:46.900]   But this is pretty fun, so you can play with it.
[00:46:46.900 --> 00:46:48.780]   You can see how well--
[00:46:48.780 --> 00:46:49.620]   see every time.
[00:46:49.620 --> 00:46:52.100]   See, so far, it's 100% other than the first one,
[00:46:52.100 --> 00:46:54.740]   which I cannot tell either.
[00:46:54.740 --> 00:46:57.900]   So what are some of the exercises that we can do here?
[00:46:57.900 --> 00:47:00.220]   What do you want to do with this lab?
[00:47:00.220 --> 00:47:01.580]   It's too easy, huh?
[00:47:01.580 --> 00:47:03.260]   Because I made this so easy, because I
[00:47:03.260 --> 00:47:05.860]   didn't know that you guys are all experts by now.
[00:47:05.860 --> 00:47:09.660]   Otherwise, I would have done a much harder lab.
[00:47:09.660 --> 00:47:12.140]   Let me see what things we can do.
[00:47:12.620 --> 00:47:16.940]   So you can uncomment all the graphs.
[00:47:16.940 --> 00:47:18.900]   Oh, so here's one.
[00:47:18.900 --> 00:47:20.700]   Actually, you already see it.
[00:47:20.700 --> 00:47:21.820]   So try this.
[00:47:21.820 --> 00:47:26.460]   Can you guys try saving the checkpoint, say, every 100
[00:47:26.460 --> 00:47:26.960]   steps?
[00:47:26.960 --> 00:47:32.380]   And you're going to have a gazillion,
[00:47:32.380 --> 00:47:34.860]   but they're tiny, tiny checkpoints, so it's OK.
[00:47:34.860 --> 00:47:37.700]   And try the run evaluation with a different checkpoint
[00:47:37.700 --> 00:47:38.580]   and see what you get.
[00:47:38.580 --> 00:47:39.740]   Do you know how to do that?
[00:47:39.740 --> 00:47:41.260]   Yeah, everybody know how to do that?
[00:47:41.260 --> 00:47:52.100]   So the idea is that when you run the evaluation,
[00:47:52.100 --> 00:47:54.700]   it's very similar.
[00:47:54.700 --> 00:47:57.060]   So we typically run training and evaluation
[00:47:57.060 --> 00:47:59.380]   in parallel or validation.
[00:47:59.380 --> 00:48:05.140]   So as it trains, every so often, say, every half an hour,
[00:48:05.140 --> 00:48:08.220]   depending on your problem, so with the inception,
[00:48:08.220 --> 00:48:11.220]   every 10 minutes, we would also run evaluation
[00:48:11.220 --> 00:48:13.300]   to see how well our model is doing.
[00:48:13.300 --> 00:48:16.900]   So if our model gets to, say, 78.6%, which I believe
[00:48:16.900 --> 00:48:18.860]   is the state of the art, it would be like, oh,
[00:48:18.860 --> 00:48:20.260]   my model's done training.
[00:48:20.260 --> 00:48:25.140]   So that's why you want to save checkpoints often and then
[00:48:25.140 --> 00:48:26.100]   validate them often.
[00:48:26.100 --> 00:48:30.140]   If you're done with that already,
[00:48:30.140 --> 00:48:31.980]   this is the last thing I want to show you.
[00:48:32.980 --> 00:48:34.900]   If you're done with that already,
[00:48:34.900 --> 00:48:35.980]   did you notice anything?
[00:48:35.980 --> 00:48:41.620]   If you try to load from a really early checkpoint,
[00:48:41.620 --> 00:48:48.500]   how good is it when it tries to identify the digits?
[00:48:48.500 --> 00:48:49.820]   Just take a wild guess.
[00:48:49.820 --> 00:48:53.060]   Yeah, very bad.
[00:48:53.060 --> 00:48:55.980]   Maybe every other one is wrong.
[00:48:55.980 --> 00:48:58.140]   But this MNIST is such a small data set.
[00:48:58.140 --> 00:48:59.500]   It's very easy to train.
[00:48:59.500 --> 00:49:01.420]   And we have such a deep network.
[00:49:01.420 --> 00:49:03.740]   If you only have one layer, maybe it won't get it right.
[00:49:03.740 --> 00:49:10.420]   So another exercise-- I think all these you
[00:49:10.420 --> 00:49:13.940]   can do after this session--
[00:49:13.940 --> 00:49:18.980]   is really try to learn to run evaluation from scratch
[00:49:18.980 --> 00:49:20.580]   rather than--
[00:49:20.580 --> 00:49:22.900]   actually, another part-- but run evaluation
[00:49:22.900 --> 00:49:25.380]   on the complete validation set.
[00:49:25.380 --> 00:49:28.420]   That's a really necessary skill to develop
[00:49:28.420 --> 00:49:31.340]   as you build bigger models and you need to run validation.
[00:49:31.940 --> 00:49:34.420]   [END PLAYBACK]
[00:49:34.420 --> 00:49:39.540]   So I think this is the end of my lab.
[00:49:39.540 --> 00:49:42.700]   I do have bonus labs.
[00:49:42.700 --> 00:49:44.500]   But I want to cover this first.
[00:49:44.500 --> 00:49:47.620]   The bottom line is that TensorFlow is really--
[00:49:47.620 --> 00:49:48.700]   it's for machine learning.
[00:49:48.700 --> 00:49:51.860]   It's really from research to prototyping to production.
[00:49:51.860 --> 00:49:53.540]   It's really designed for that.
[00:49:53.540 --> 00:49:58.340]   And I really hope everybody in the audience can give it a try.
[00:49:58.340 --> 00:50:01.700]   And if there are any features that you find it lacking
[00:50:01.700 --> 00:50:04.860]   that you would like to see implemented,
[00:50:04.860 --> 00:50:06.780]   either send us pull requests.
[00:50:06.780 --> 00:50:08.980]   We always welcome contribution.
[00:50:08.980 --> 00:50:11.660]   Or talk to my wonderful product manager, Zach,
[00:50:11.660 --> 00:50:12.540]   sitting over there.
[00:50:12.540 --> 00:50:16.620]   He is taking requests for features.
[00:50:16.620 --> 00:50:19.580]   So with that, yeah, thanks and have fun.
[00:50:19.580 --> 00:50:21.980]   [APPLAUSE]
[00:50:21.980 --> 00:50:27.660]   Thank you, Sherry.
[00:50:27.660 --> 00:50:31.820]   We have time for questions for those who actually tried it.
[00:50:31.820 --> 00:50:35.380]   See, it's so well done.
[00:50:35.380 --> 00:50:36.900]   Everybody feel like they're experts.
[00:50:36.900 --> 00:50:39.420]   They're all ready to go make arts now, right?
[00:50:39.420 --> 00:50:40.260]   Go deep dream.
[00:50:40.260 --> 00:50:45.580]   Cool.
[00:50:45.580 --> 00:50:49.140]   If there are no questions--
[00:50:49.140 --> 00:50:50.500]   oh, there's one question, I think,
[00:50:50.500 --> 00:50:52.660]   someone who's trying desperately.
[00:50:56.220 --> 00:50:57.940]   Hi, my name is Pichin Lo.
[00:50:57.940 --> 00:51:01.860]   And first of all, thank you for introducing TensorFlow
[00:51:01.860 --> 00:51:04.020]   and for designing it.
[00:51:04.020 --> 00:51:04.980]   I have two questions.
[00:51:04.980 --> 00:51:08.860]   So the first question is, I know that TensorFlow
[00:51:08.860 --> 00:51:11.620]   have C++ API, right?
[00:51:11.620 --> 00:51:15.780]   So let's say if I use Keras or any of the Python front end,
[00:51:15.780 --> 00:51:16.620]   I train a model.
[00:51:16.620 --> 00:51:24.060]   Does TensorFlow support that I can pull out the C++ model
[00:51:24.060 --> 00:51:25.260]   of it and then just use that?
[00:51:26.260 --> 00:51:27.340]   Yes, you can.
[00:51:27.340 --> 00:51:31.060]   So even if I use, for example, Keras custom layer
[00:51:31.060 --> 00:51:33.660]   that I code using Python, I still can get those things?
[00:51:33.660 --> 00:51:34.460]   That's correct.
[00:51:34.460 --> 00:51:34.940]   Oh, there it goes.
[00:51:34.940 --> 00:51:36.660]   It's just the front end that's different,
[00:51:36.660 --> 00:51:38.020]   how you construct the graph.
[00:51:38.020 --> 00:51:38.540]   Nice.
[00:51:38.540 --> 00:51:43.740]   But we are not as complete on our C++ API design.
[00:51:43.740 --> 00:51:46.660]   For example, a lot of the training libraries
[00:51:46.660 --> 00:51:48.380]   are not complete yet.
[00:51:48.380 --> 00:51:52.300]   But for the simple models, yes, you can do it.
[00:51:52.300 --> 00:51:54.100]   Well, let's say-- not the training,
[00:51:54.100 --> 00:51:56.500]   but let's say if I just want the testing part.
[00:51:56.500 --> 00:51:57.660]   Because I don't need to do--
[00:51:57.660 --> 00:51:59.660]   I mean, the training I can always do in Python.
[00:51:59.660 --> 00:52:01.180]   We do have that already.
[00:52:01.180 --> 00:52:03.140]   Actually, if you go to our website,
[00:52:03.140 --> 00:52:05.820]   there's a label images, .cc.
[00:52:05.820 --> 00:52:08.620]   I think that's literally just loading from Checkpoint
[00:52:08.620 --> 00:52:13.140]   and run the inference in C. That's all written in C++.
[00:52:13.140 --> 00:52:16.140]   So that's a good example to follow.
[00:52:16.140 --> 00:52:16.900]   A second one.
[00:52:16.900 --> 00:52:20.100]   So another thing that I noticed that you support almost
[00:52:20.100 --> 00:52:22.860]   everything except Windows.
[00:52:22.860 --> 00:52:25.220]   Everything except what?
[00:52:25.220 --> 00:52:26.940]   I mean, iOS, Android, everything.
[00:52:26.940 --> 00:52:27.900]   Oh, have no fear.
[00:52:27.900 --> 00:52:30.620]   Actually, we are actively doing that.
[00:52:30.620 --> 00:52:32.260]   But when I first joined the team,
[00:52:32.260 --> 00:52:33.620]   I think there were 10 of us.
[00:52:33.620 --> 00:52:35.340]   And we have to do everything.
[00:52:35.340 --> 00:52:37.740]   Like before open sourcing, all of us
[00:52:37.740 --> 00:52:40.940]   were in the conference room together.
[00:52:40.940 --> 00:52:41.900]   We're all riding dogs.
[00:52:41.900 --> 00:52:43.100]   We're fixing everything.
[00:52:43.100 --> 00:52:45.620]   So now we have more people.
[00:52:45.620 --> 00:52:47.220]   That's like top of our list.
[00:52:47.220 --> 00:52:48.820]   We would love to support it.
[00:52:48.820 --> 00:52:50.780]   So I'm just curious, because I mean,
[00:52:50.780 --> 00:52:54.420]   when I look at the roadmap, I didn't see a clear timeline
[00:52:54.420 --> 00:52:55.980]   for Windows.
[00:52:55.980 --> 00:52:58.540]   But the thing I know that just like the reason why you cannot
[00:52:58.540 --> 00:53:00.700]   support Windows is because of Bazel.
[00:53:00.700 --> 00:53:02.620]   Bazel doesn't support Windows.
[00:53:02.620 --> 00:53:06.020]   So let's say, theoretically, I mean, what you think,
[00:53:06.020 --> 00:53:08.060]   just like I know Bazel that just like you
[00:53:08.060 --> 00:53:11.820]   will get Window 5 at some point in November.
[00:53:11.820 --> 00:53:12.860]   That is what they say.
[00:53:12.860 --> 00:53:15.700]   So once Bazel can run in Windows,
[00:53:15.700 --> 00:53:18.580]   can I expect like just like immediately do TensorFlow,
[00:53:18.580 --> 00:53:20.980]   or do you foresee some other problem?
[00:53:20.980 --> 00:53:22.940]   Maybe Zach would like to take that question.
[00:53:22.940 --> 00:53:25.340]   [LAUGHTER]
[00:53:25.340 --> 00:53:25.840]   Offline.
[00:53:25.840 --> 00:53:26.340]   OK.
[00:53:26.340 --> 00:53:27.500]   [LAUGHTER]
[00:53:27.500 --> 00:53:28.100]   OK, that's it.
[00:53:28.100 --> 00:53:29.340]   So yeah, let's talk offline.
[00:53:29.340 --> 00:53:29.860]   Yeah, sure.
[00:53:29.860 --> 00:53:32.380]   Thank you very much.
[00:53:32.380 --> 00:53:35.020]   Hi, great presentation and session.
[00:53:35.020 --> 00:53:36.060]   My name is Yuri Zifoysh.
[00:53:36.060 --> 00:53:37.660]   I have a question about TPUs.
[00:53:37.660 --> 00:53:40.980]   Are they available right now for testing and playing
[00:53:40.980 --> 00:53:42.940]   for non-Google employees?
[00:53:47.780 --> 00:53:48.740]   Are we--
[00:53:48.740 --> 00:53:52.020]   Is TPU-- are TPUs available outside?
[00:53:52.020 --> 00:53:54.940]   I don't think so at the moment.
[00:53:54.940 --> 00:53:57.460]   Do you know when it might be available in the Google Cloud?
[00:53:57.460 --> 00:53:59.080]   Zach, would you like to take that one?
[00:53:59.080 --> 00:54:00.060]   [LAUGHTER]
[00:54:00.060 --> 00:54:01.020]   It might be afterwards.
[00:54:01.020 --> 00:54:04.180]   [LAUGHTER]
[00:54:04.180 --> 00:54:08.380]   I'm so glad we have a product boss here so that he can--
[00:54:08.380 --> 00:54:08.880]   I'm sorry.
[00:54:08.880 --> 00:54:11.620]   OK, thank you.
[00:54:11.620 --> 00:54:12.700]   Hi, nice tutorial.
[00:54:12.700 --> 00:54:13.860]   I have a question.
[00:54:13.860 --> 00:54:18.620]   Are there any plans to integrate TensorFlow
[00:54:18.620 --> 00:54:24.340]   with the open source framework, like MySource and HDFS,
[00:54:24.340 --> 00:54:26.900]   to make the distributed TensorFlow run--
[00:54:26.900 --> 00:54:27.980]   Easy.
[00:54:27.980 --> 00:54:30.500]   So there are definitely plans.
[00:54:30.500 --> 00:54:33.540]   We are also always actively working on new features.
[00:54:33.540 --> 00:54:38.140]   But we cannot provide a solid timeline right now.
[00:54:38.140 --> 00:54:42.460]   So we do have plans.
[00:54:42.460 --> 00:54:45.500]   We do have projects in progress.
[00:54:45.500 --> 00:54:49.180]   But we cannot commit on a timeline.
[00:54:49.180 --> 00:54:51.620]   So I cannot give you a time saying, yes, by November,
[00:54:51.620 --> 00:54:52.980]   you have what.
[00:54:52.980 --> 00:54:54.340]   So thank you.
[00:54:54.340 --> 00:54:57.340]   But if you have this type of question,
[00:54:57.340 --> 00:54:59.340]   I think Zach is the best person to answer.
[00:54:59.340 --> 00:55:06.060]   Oh, hi.
[00:55:06.060 --> 00:55:08.260]   I was wondering, does TensorFlow have any examples
[00:55:08.260 --> 00:55:10.100]   to load your own data?
[00:55:10.100 --> 00:55:12.860]   Of what-- which data?
[00:55:12.860 --> 00:55:15.900]   So the current example has a MNIST data set.
[00:55:15.900 --> 00:55:18.340]   Are there examples out there to load your own data set?
[00:55:18.340 --> 00:55:19.300]   Yes.
[00:55:19.300 --> 00:55:20.380]   Yes, definitely.
[00:55:20.380 --> 00:55:21.980]   I think we have two.
[00:55:21.980 --> 00:55:24.860]   One is called the TensorFlow Poet.
[00:55:24.860 --> 00:55:27.140]   I think that one-- that example shows you
[00:55:27.140 --> 00:55:28.700]   how you can load your own data set.
[00:55:28.700 --> 00:55:35.300]   I think-- is there another one?
[00:55:35.300 --> 00:55:36.740]   Zach, are you aware of another one
[00:55:36.740 --> 00:55:38.700]   that might be loading your own data set?
[00:55:38.700 --> 00:55:41.220]   I know we have retraining model.
[00:55:41.220 --> 00:55:45.020]   If you go to TensorFlow, we have an example to do retraining.
[00:55:45.020 --> 00:55:46.780]   Those you can download from anywhere.
[00:55:46.780 --> 00:55:48.580]   So in our example, we just downloaded
[00:55:48.580 --> 00:55:50.420]   a bunch of flowers.
[00:55:50.420 --> 00:55:53.260]   So you can definitely download whatever pictures
[00:55:53.260 --> 00:55:56.140]   that you want to retrain.
[00:55:56.140 --> 00:55:56.640]   Thank you.
[00:55:56.640 --> 00:56:00.620]   Hello.
[00:56:00.620 --> 00:56:02.300]   Thank you for your presentation.
[00:56:02.300 --> 00:56:05.140]   I have a question concerning the training.
[00:56:05.140 --> 00:56:08.820]   You can't train using TensorFlow in any--
[00:56:08.820 --> 00:56:12.340]   virtually in any system, like Android.
[00:56:12.340 --> 00:56:16.340]   And what about the model?
[00:56:16.340 --> 00:56:20.220]   Do you provide anything to move the model to Android?
[00:56:20.220 --> 00:56:23.940]   Because generally, you program in Java there.
[00:56:23.940 --> 00:56:24.420]   Yes.
[00:56:24.420 --> 00:56:25.460]   So that's a beautiful thing.
[00:56:25.460 --> 00:56:27.340]   You remember the architecture that I showed?
[00:56:27.340 --> 00:56:27.700]   Yes.
[00:56:27.700 --> 00:56:30.180]   You build a model, and then just send it to the runtime.
[00:56:30.180 --> 00:56:34.740]   It's the same model running on any of the different platforms.
[00:56:34.740 --> 00:56:36.340]   It can be a laptop, Android.
[00:56:36.340 --> 00:56:40.900]   Do you have your own specific format for the model?
[00:56:40.900 --> 00:56:42.740]   Or it's just--
[00:56:42.740 --> 00:56:43.860]   You build the same model.
[00:56:43.860 --> 00:56:48.340]   Because the model is just a bunch of matrix and values.
[00:56:48.340 --> 00:56:53.220]   Is there any special format for your model?
[00:56:53.220 --> 00:56:55.820]   Because sometimes it is bigger.
[00:56:55.820 --> 00:56:56.340]   Yes.
[00:56:56.340 --> 00:56:58.340]   So I would not recommend training, say,
[00:56:58.340 --> 00:57:00.940]   Inception on your phone, because all the convolution
[00:57:00.940 --> 00:57:04.700]   and the backprop will probably kill it 10 times over.
[00:57:04.700 --> 00:57:10.260]   So definitely-- so there will be that type of limitation.
[00:57:10.260 --> 00:57:12.500]   I think you guys talked about the number of parameters.
[00:57:12.500 --> 00:57:15.100]   If it blows the memory footprint on your phone,
[00:57:15.100 --> 00:57:16.900]   it's just not going to work.
[00:57:16.900 --> 00:57:18.620]   And if the compute--
[00:57:18.620 --> 00:57:20.940]   especially for convolution, it uses a lot of compute.
[00:57:20.940 --> 00:57:21.440]   Yes.
[00:57:21.440 --> 00:57:22.540]   That's for training.
[00:57:22.540 --> 00:57:23.060]   But--
[00:57:23.060 --> 00:57:25.100]   But for inference, you can run it anywhere.
[00:57:25.100 --> 00:57:25.900]   OK.
[00:57:25.900 --> 00:57:26.380]   Thank you.
[00:57:26.380 --> 00:57:27.220]   It's the same model.
[00:57:27.220 --> 00:57:28.060]   You just restore it.
[00:57:28.060 --> 00:57:31.740]   There actually are examples like label image.
[00:57:31.740 --> 00:57:33.420]   That's the C++ version.
[00:57:33.420 --> 00:57:34.540]   I think I also wrote one.
[00:57:34.540 --> 00:57:35.660]   It's called classify image.
[00:57:35.660 --> 00:57:36.820]   It's in Python.
[00:57:36.820 --> 00:57:39.380]   That's also-- you can run it on your phone.
[00:57:39.380 --> 00:57:43.460]   So any of these, you can write your own and load a checkpoint
[00:57:43.460 --> 00:57:45.100]   and run it on your phone as well.
[00:57:45.100 --> 00:57:47.820]   So definitely, I encourage you to do that.
[00:57:47.820 --> 00:57:48.380]   Thank you.
[00:57:48.380 --> 00:57:48.880]   Cool.
[00:57:48.880 --> 00:57:51.780]   Hi.
[00:57:51.780 --> 00:57:54.620]   I have a question related to TensorFlow serving.
[00:57:54.620 --> 00:57:57.900]   So I went through the online documentation
[00:57:57.900 --> 00:58:02.220]   and currently, I think it requires some coding in C++
[00:58:02.220 --> 00:58:04.740]   and then combined with Python.
[00:58:04.740 --> 00:58:07.700]   Is there only going to be only Python solution that's
[00:58:07.700 --> 00:58:08.660]   going to be provided?
[00:58:08.660 --> 00:58:10.860]   Or is it always going to be--
[00:58:10.860 --> 00:58:13.740]   I think you need to do some first step to create a module
[00:58:13.740 --> 00:58:17.660]   and then just import it into Python.
[00:58:17.660 --> 00:58:21.340]   I am actually surprised to hear that because I'm pretty sure
[00:58:21.340 --> 00:58:25.860]   that you can write the model in just Python or just C++.
[00:58:25.860 --> 00:58:28.140]   You don't have to write it in one way or the other.
[00:58:28.140 --> 00:58:31.300]   They might have a special exporter tool.
[00:58:31.300 --> 00:58:32.660]   At one point, that was the case.
[00:58:32.660 --> 00:58:35.660]   They wrote their exporter in C++.
[00:58:35.660 --> 00:58:37.980]   I think that's probably what you were talking about.
[00:58:37.980 --> 00:58:42.780]   But you don't have to build it in any specific way.
[00:58:42.780 --> 00:58:43.980]   The model is just--
[00:58:43.980 --> 00:58:45.820]   you can write in whatever language you like,
[00:58:45.820 --> 00:58:48.780]   as long as it produces that graph.
[00:58:48.780 --> 00:58:52.020]   And that's all it needs.
[00:58:52.020 --> 00:58:55.220]   So TensorFlow serving, the tutorial, actually,
[00:58:55.220 --> 00:58:58.900]   if you go on the site, it had those steps, actually.
[00:58:58.900 --> 00:59:00.580]   OK, so I will look into that.
[00:59:00.580 --> 00:59:02.180]   So maybe you can come find me later,
[00:59:02.180 --> 00:59:04.220]   and I'll see what the situation is.
[00:59:04.220 --> 00:59:06.900]   I do know that at one point, they were writing the exporter
[00:59:06.900 --> 00:59:08.540]   in C++ only.
[00:59:08.540 --> 00:59:10.300]   But that should have changed by now
[00:59:10.300 --> 00:59:16.420]   because we are doing another version of TensorFlow serving.
[00:59:16.420 --> 00:59:22.260]   And is there any plan to provide APIs for other languages?
[00:59:22.260 --> 00:59:27.100]   Like MXNet has something called MXNetJS.
[00:59:27.100 --> 00:59:28.500]   You mean the front end?
[00:59:28.500 --> 00:59:29.140]   Front end, yes.
[00:59:29.140 --> 00:59:29.860]   Yeah, yeah, yeah.
[00:59:29.860 --> 00:59:30.620]   We have Go.
[00:59:30.620 --> 00:59:31.540]   I think we have Go.
[00:59:31.540 --> 00:59:33.180]   We have some other languages.
[00:59:33.180 --> 00:59:35.420]   Maybe Zach can speak more to it.
[00:59:35.420 --> 00:59:38.780]   And once again, if those languages are not our favorite,
[00:59:38.780 --> 00:59:40.780]   please do contribute.
[00:59:40.780 --> 00:59:43.680]   And if you would like us to do it, talk to Zach.
[00:59:43.680 --> 00:59:45.180]   And maybe he can put that--
[00:59:45.180 --> 00:59:46.620]   maybe-- I don't know.
[00:59:46.620 --> 00:59:48.900]   Because as somebody asked, for the Android,
[00:59:48.900 --> 00:59:50.580]   you need Java front end.
[00:59:50.580 --> 00:59:52.860]   So I think that's going to help out in integrating
[00:59:52.860 --> 00:59:54.340]   these models with--
[00:59:54.340 --> 00:59:55.900]   Yeah, that's great feedback.
[00:59:55.900 --> 00:59:57.980]   We'll definitely take note.
[00:59:57.980 --> 00:59:58.480]   Thank you.
[00:59:58.480 --> 00:59:59.540]   Thank you.
[00:59:59.540 --> 01:00:01.780]   I have a question.
[01:00:01.780 --> 01:00:04.500]   I'm having an embedded GPU board, the X1,
[01:00:04.500 --> 01:00:06.420]   which is an ARM processor.
[01:00:06.420 --> 01:00:08.780]   And I really wanted to work with the TensorFlow,
[01:00:08.780 --> 01:00:13.140]   but I got to know that it can only run on x86 boards.
[01:00:13.140 --> 01:00:16.740]   So when can we expect the TensorFlow
[01:00:16.740 --> 01:00:20.260]   can support ARM processors?
[01:00:20.260 --> 01:00:23.100]   We will have to get back to you after I have
[01:00:23.100 --> 01:00:27.220]   consulted with my product boss, see when we can add that
[01:00:27.220 --> 01:00:29.740]   support.
[01:00:29.740 --> 01:00:30.340]   Thank you.
[01:00:30.340 --> 01:00:30.980]   Sorry.
[01:00:30.980 --> 01:00:32.940]   One last question.
[01:00:32.940 --> 01:00:34.700]   Thanks for the presentation, Sherry.
[01:00:34.700 --> 01:00:36.980]   I have a question regarding the--
[01:00:36.980 --> 01:00:41.380]   when you have the model and you want to run inference,
[01:00:41.380 --> 01:00:44.460]   is it possible to make an executable out of it
[01:00:44.460 --> 01:00:47.060]   so they can drop it into a container
[01:00:47.060 --> 01:00:49.820]   or run it separately from serving?
[01:00:49.820 --> 01:00:52.540]   Is that something that you guys are looking into?
[01:00:52.540 --> 01:00:54.580]   Just run the inference?
[01:00:54.580 --> 01:00:56.980]   Yeah, just have it as a binary.
[01:00:56.980 --> 01:00:59.300]   Yeah, you can definitely do that.
[01:00:59.300 --> 01:01:00.420]   Right now you can?
[01:01:00.420 --> 01:01:04.020]   Yeah, you are always able to do that.
[01:01:04.020 --> 01:01:08.660]   You mean just save the--
[01:01:08.660 --> 01:01:09.180]   you want to--
[01:01:09.180 --> 01:01:11.500]   What I mean is that if you can package it
[01:01:11.500 --> 01:01:15.460]   into a single binary source that you can just pass around.
[01:01:15.460 --> 01:01:16.500]   Yes, yes.
[01:01:16.500 --> 01:01:17.820]   We actually do that today.
[01:01:17.820 --> 01:01:20.300]   That's how the label image works.
[01:01:20.300 --> 01:01:22.420]   It's just its own individual binary.
[01:01:22.420 --> 01:01:23.060]   OK.
[01:01:23.060 --> 01:01:26.060]   It actually converted all the checkpoints into constants.
[01:01:26.060 --> 01:01:29.220]   So it doesn't even need to do the slow, et cetera.
[01:01:29.220 --> 01:01:31.180]   It just reads a bunch of constants and runs it.
[01:01:31.180 --> 01:01:33.460]   So it's super fast.
[01:01:33.460 --> 01:01:34.020]   Thank you.
[01:01:34.020 --> 01:01:34.540]   Cool.
[01:01:34.540 --> 01:01:35.380]   You're welcome.
[01:01:35.380 --> 01:01:36.460]   Thanks, Sherry, again.
[01:01:36.460 --> 01:01:41.580]   [APPLAUSE]
[01:01:41.580 --> 01:01:43.580]   We're going to take a short break of 10 minutes.
[01:01:43.580 --> 01:01:46.420]   Let me remind you, for those who haven't noticed yet,
[01:01:46.420 --> 01:01:48.260]   but all the slides of all the talks
[01:01:48.260 --> 01:01:49.900]   will be available on the website.
[01:01:49.900 --> 01:01:51.100]   So do not worry.
[01:01:51.100 --> 01:01:53.380]   They will be available at some point, as soon as we
[01:01:53.380 --> 01:01:55.180]   get them from the speakers.
[01:01:55.180 --> 01:01:57.260]   Oh, I forgot to ask my bonus question.
[01:01:57.260 --> 01:02:00.020]   But in any case, I have a lot of TensorFlow stickers up here.
[01:02:00.020 --> 01:02:03.300]   If you would like one to proudly display on your laptop,
[01:02:03.300 --> 01:02:05.220]   come get it.

