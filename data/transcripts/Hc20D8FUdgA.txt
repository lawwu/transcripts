
[00:00:00.000 --> 00:00:06.580]   You may have heard rumours that ChatGPT 4 is going to be released imminently, say in January,
[00:00:06.580 --> 00:00:12.480]   and that it's going to dwarf ChatGPT 3's ability, just like you can see in this graph.
[00:00:12.480 --> 00:00:17.140]   Well, I'm going to let Sam Altman correct the record here on both fronts.
[00:00:17.140 --> 00:00:22.140]   And then at the end of the video, I'm going to discuss what I think ChatGPT 4 will be capable of.
[00:00:22.140 --> 00:00:27.100]   Here's Sam Altman on the timing of the release of ChatGPT 4.
[00:00:27.100 --> 00:00:32.440]   Can you comment on whether GPT 4 is coming out in the first quarter, first half of the year?
[00:00:32.440 --> 00:00:38.640]   It'll come out at some point when we are like confident that we can do it safely and responsibly.
[00:00:38.640 --> 00:00:45.840]   I think in general, we are going to release technology much more slowly than people would like.
[00:00:45.840 --> 00:00:48.300]   We're going to sit on it for much longer than people would like.
[00:00:48.300 --> 00:00:55.800]   Then referring to ChatGPT 4, he talked about whether it will be an exponential increase in terms of its abilities
[00:00:55.800 --> 00:00:58.040]   or more of an incremental upgrade.
[00:00:58.040 --> 00:01:03.700]   Given the magnitude of the economic impact we expect here, more gradual is better.
[00:01:03.700 --> 00:01:09.400]   And so putting out a very weak and imperfect system like ChatGPT and then making it a little better this year,
[00:01:09.400 --> 00:01:14.040]   a little better later this year, a little better next year, that seems much better than the alternative.
[00:01:14.040 --> 00:01:21.000]   Then Sam directly addressed the hype train that had been generated by graphics such as this one.
[00:01:21.000 --> 00:01:28.040]   I saw a visual, and I don't know if it was accurate, but it showed GPT 3.5 versus, I guess, what GPT 4 is expected.
[00:01:28.040 --> 00:01:29.240]   I saw that thing on Twitter.
[00:01:29.240 --> 00:01:30.740]   Did you? Was that accurate?
[00:01:30.740 --> 00:01:31.500]   Complete bullshit. No.
[00:01:31.500 --> 00:01:33.940]   Okay, because that was a little bit scary.
[00:01:33.940 --> 00:01:40.240]   The GPT 4 rumor mill is like a ridiculous thing.
[00:01:40.240 --> 00:01:41.740]   I don't know where it all comes from.
[00:01:41.740 --> 00:01:44.440]   I don't know why people don't have better things to speculate on.
[00:01:44.440 --> 00:01:50.200]   I get a little bit of it, like it's sort of fun, but that it's been going for like six months at this volume.
[00:01:50.200 --> 00:01:52.940]   People are begging to be disappointed, and they will be.
[00:01:52.940 --> 00:01:58.060]   Like it's, you know, people are going to like, the hype is just like, we don't have an actual AGI.
[00:01:58.060 --> 00:02:00.000]   And I think that's sort of what is expected of us.
[00:02:00.000 --> 00:02:02.440]   And, you know, yeah, we're going to disappoint those people.
[00:02:02.440 --> 00:02:09.260]   In a moment, you're going to see Sam respond to a question about ChatGPT putting Google out of business.
[00:02:09.260 --> 00:02:16.200]   And he made a fantastic point, which I'm going to go into more detail on after he gives his remarks.
[00:02:16.200 --> 00:02:21.500]   Yeah, I think whenever someone like talks about a technology being the end of some other giant company, it's usually wrong.
[00:02:21.500 --> 00:02:27.160]   Like I think people forget they get to make a counter move here and they're like pretty smart, pretty competent.
[00:02:27.160 --> 00:02:37.200]   The counter move that Sam is referring to may well be Palm, which is a 540 billion parameter transformer model.
[00:02:37.200 --> 00:02:43.900]   And you can see from the graphic the improvements that have been made by increasing the number of parameters.
[00:02:43.900 --> 00:02:52.400]   But I've done some research on Palm, see this graph, notice the line crossing the performance of the average human.
[00:02:52.400 --> 00:02:57.100]   It admits when you go into detail about the tasks that Palm can achieve,
[00:02:57.100 --> 00:03:04.600]   that we're still talking about solving 60% of problems that 9 to 12 year olds can solve.
[00:03:04.600 --> 00:03:05.960]   And that is incredible.
[00:03:05.960 --> 00:03:11.440]   So the average 12 year old can solve 60% of them and Palm can solve 58% of them.
[00:03:11.440 --> 00:03:14.640]   But that isn't exactly AGI, not yet, at least.
[00:03:14.640 --> 00:03:20.340]   So if ChatGPT-4 is anywhere in that kind of ballpark, we're going to notice the difference.
[00:03:20.340 --> 00:03:26.600]   We're going to see the improvement just as that graph increased quite dramatically by increasing the number of parameters.
[00:03:26.600 --> 00:03:31.300]   Maybe it will be able to explain jokes, for example, understand books a bit better.
[00:03:31.300 --> 00:03:35.400]   But we're definitely not talking about AGI, not yet.
[00:03:35.400 --> 00:03:40.060]   I am certain that the initial buzz around ChatGPT-4 is going to be amazing.
[00:03:40.060 --> 00:03:44.500]   But I'm going to let Sam address the difference between the initial buzz,
[00:03:44.500 --> 00:03:49.500]   the impressive achievements it can do, and the robustness of the entire model.
[00:03:49.500 --> 00:03:55.100]   One of the sort of strange things about these technologies is they are impressive, but not robust.
[00:03:55.100 --> 00:04:02.860]   And so you use them in a first demo, you kind of have this like very impressive, like, wow, this is like incredible and ready to go.
[00:04:02.860 --> 00:04:05.460]   You use them 100 times, you see the weaknesses.
[00:04:05.460 --> 00:04:12.540]   And so I think people can get a much sort of a false impression of how good they are.
[00:04:12.540 --> 00:04:15.100]   However, that's all going to get better.
[00:04:15.100 --> 00:04:22.740]   The critics who point these problems out and say, well, this is why it's like, you know, all like, like, you know, fake news or whatever, are equally wrong.
[00:04:22.740 --> 00:04:25.740]   Thank you for watching and do subscribe for more such content.

