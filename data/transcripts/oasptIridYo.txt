
[00:00:00.000 --> 00:00:04.960]   So I was recently listening to Tim Ferriss interview the prolific fantasy author
[00:00:04.960 --> 00:00:07.520]   Brandon Sanderson
[00:00:07.520 --> 00:00:14.360]   Now there's an exchange in this conversation. It was early on. It's right around the nine-minute mark of the podcast that caught my attention
[00:00:14.360 --> 00:00:21.200]   When I heard it it caught my attention because I think it actually says something profound
[00:00:21.200 --> 00:00:29.600]   About some of the deep problems in the way we organize work in our current moment. So here's what I want to do
[00:00:29.600 --> 00:00:34.560]   I'm going to first I'm going to play the clip. I'm going to detail what it is that that that lesson
[00:00:34.560 --> 00:00:38.600]   I think this clip is pointing towards then we're going to discuss a way
[00:00:38.600 --> 00:00:43.280]   to push back or try to correct for those issues and
[00:00:43.280 --> 00:00:50.500]   All this will really just be an excuse to geek out on Sanderson productivity chatter because all writers love to geek out on Sanderson productivity chatter
[00:00:50.500 --> 00:00:53.720]   All right. So anyways, let's get to the clip. Let me set the scene here
[00:00:53.720 --> 00:00:56.720]   This is Tim has traveled to Utah
[00:00:57.520 --> 00:01:03.200]   To talk to Sanderson at the headquarters of his publishing and merchandising company Dragonsteel books
[00:01:03.200 --> 00:01:06.440]   It's like a 70 person company that Sanderson started
[00:01:06.440 --> 00:01:10.280]   Kind of his empire built around his fantasy books
[00:01:10.280 --> 00:01:16.760]   Let's hear now this clip from the interview and I will all of that stuff
[00:01:16.760 --> 00:01:22.200]   I I joke that I've just got so much Ram and I've filled it all with story ideas
[00:01:22.200 --> 00:01:29.560]   And so everything else kind of just squeezed out the ears. It seems like where we're sitting and we're sitting at HQ. Mm-hmm. It seems like
[00:01:29.560 --> 00:01:32.160]   the design of
[00:01:32.160 --> 00:01:39.200]   Dragonsteel maybe the intention behind it is to allow you to do that on some level. Yeah. Yeah, I mean
[00:01:39.200 --> 00:01:45.600]   everything in our company is built around let Brandon cook and
[00:01:45.600 --> 00:01:50.520]   Take away from Brandon anything that he doesn't have to think about or you know
[00:01:50.520 --> 00:01:52.760]   It doesn't strictly need to I actually
[00:01:52.760 --> 00:01:56.000]   Alright, so that is the clip that caught my attention to let
[00:01:56.000 --> 00:02:04.240]   Brandon cook now as someone who writes a lot about knowledge work in the digital age. I'm fascinated by this idea of cooking
[00:02:04.240 --> 00:02:07.320]   Which in the work context I define to mean
[00:02:07.320 --> 00:02:14.320]   Letting someone who has a high return skill. So a skill that returns hot value at a high level
[00:02:14.320 --> 00:02:19.480]   Design a workflow that enables them to just basically spend all their time applying that skill
[00:02:20.200 --> 00:02:22.200]   minimizing other distractions
[00:02:22.200 --> 00:02:27.680]   So we can think about this idea of letting someone cook as a particular
[00:02:27.680 --> 00:02:36.520]   Strategy for workflow design now, it makes sense to me that in this particular example that dragon steel books goes out of its way to protect
[00:02:36.520 --> 00:02:41.760]   Sanderson's ability to think and write he produces roughly 300,000 words a year
[00:02:41.760 --> 00:02:48.360]   He'll geek out on the details of this some years. It's more he goes up to as much as 400,000. Sometimes it's less
[00:02:49.200 --> 00:02:54.180]   He does this on a pace of like roughly ten to twenty thousand words a week depending on whether he's revising or not
[00:02:54.180 --> 00:02:59.920]   Those words he produces is the raw material on which all revenue of dragon steel books is built
[00:02:59.920 --> 00:03:02.800]   You cut down those words
[00:03:02.800 --> 00:03:07.500]   It's like reducing the amount of steel that you're shipping to a Ford assembly line
[00:03:07.500 --> 00:03:11.120]   They're gonna produce less cars and if they produce less cars, they're gonna make less money
[00:03:11.120 --> 00:03:16.880]   So you you got to protect at the but what is the core raw material on which the value?
[00:03:17.280 --> 00:03:23.300]   That dragon steel sells or bases its business off of it is the words that Sanderson produces
[00:03:23.300 --> 00:03:26.280]   So, of course this idea of yeah, let's let Brandon cook
[00:03:26.280 --> 00:03:29.620]   Make sense. It's the same thing as saying your assembly line
[00:03:29.620 --> 00:03:34.640]   Let's make sure we have plenty of steel coming in so we can build a lot of cars. So that makes sense to me
[00:03:34.640 --> 00:03:37.360]   Here's what does it make sense to me?
[00:03:37.360 --> 00:03:40.040]   Why don't more?
[00:03:40.040 --> 00:03:42.500]   Companies have Sanderson figures
[00:03:42.500 --> 00:03:45.360]   Why is this model of cooking?
[00:03:46.080 --> 00:03:53.120]   Not more prevalent throughout the knowledge sector writ large where hey, we've set up our workflow so that this person can cook
[00:03:53.120 --> 00:03:54.840]   We've set up our workflows that that person can cook
[00:03:54.840 --> 00:03:57.400]   this person is producing the stuff that is at the core of our
[00:03:57.400 --> 00:04:03.360]   marketing company at the core of our technology company at the core of our research institute and we want them to produce that as much as
[00:04:03.360 --> 00:04:08.760]   Possible because that is going to help us be as successful as possible. Let's let them cook. You think you would see that more often
[00:04:08.760 --> 00:04:11.320]   But we don't
[00:04:11.320 --> 00:04:13.320]   To me that paradox is really interesting
[00:04:13.840 --> 00:04:16.800]   Now I need to put a clear caveat here
[00:04:16.800 --> 00:04:21.600]   Before we get the complaints. I am NOT arguing that
[00:04:21.600 --> 00:04:27.040]   All knowledge work jobs would benefit from the Sanderson model cooking
[00:04:27.040 --> 00:04:30.080]   Workflow
[00:04:30.080 --> 00:04:37.240]   Actually, probably most knowledge work jobs would not let me use myself as an example at the moment right as a full professor
[00:04:37.240 --> 00:04:41.000]   in Georgetown's computer science department we rotate
[00:04:41.760 --> 00:04:48.320]   Several key administrative roles among the full professors its faculty governance of departments. This is how academic institutions run
[00:04:48.320 --> 00:04:55.040]   I am currently the director of undergraduate studies for the computer science department at Georgetown. It's my turn
[00:04:55.040 --> 00:04:57.520]   So it came to me
[00:04:57.520 --> 00:05:00.280]   That is an example of a knowledge work role in
[00:05:00.280 --> 00:05:05.800]   Which there is not a single high return activity that I should be focusing on
[00:05:06.080 --> 00:05:12.000]   it's a much more varied role in terms of its its reactive it is it's taking in a lot of information and
[00:05:12.000 --> 00:05:16.840]   Processing it and coming up with answers. It's helping get people the information they need
[00:05:16.840 --> 00:05:20.800]   It's also a very interpersonal like counseling role like working with individual students
[00:05:20.800 --> 00:05:25.900]   So in that particular job, which is like one of seven I have in that particular job
[00:05:25.900 --> 00:05:27.900]   It would not make sense to say hey, let Cal cook
[00:05:27.900 --> 00:05:32.400]   There's nothing here for me to cook on so I'm not arguing that
[00:05:33.000 --> 00:05:38.960]   Most jobs should have this model. But what I am arguing is that most organizations should have some people who who are doing that
[00:05:38.960 --> 00:05:41.400]   Right that okay
[00:05:41.400 --> 00:05:49.160]   maybe not the director of undergraduate studies, but the the new professor who should just be doing research or the computer programmer or
[00:05:49.160 --> 00:05:56.240]   the the marketing ad writer or any number of a creative industry positions, right this just strategician the
[00:05:58.040 --> 00:06:03.680]   Economic analysis you should just be like there with the numbers trying to get the sort of the deepest most sophisticated analysis done
[00:06:03.680 --> 00:06:07.800]   There there should be a lot of positions in
[00:06:07.800 --> 00:06:10.600]   Which we would say yeah, of course, we want to let them cook
[00:06:10.600 --> 00:06:13.760]   This is what's going to produce the most value, but we don't so I think that's a paradox
[00:06:13.760 --> 00:06:17.200]   Let's explain this paradox
[00:06:17.200 --> 00:06:23.680]   So as I talked about at the opening of this show almost everything I talked about is motivated at the very top
[00:06:23.680 --> 00:06:26.560]   by the modern digital environment
[00:06:26.960 --> 00:06:28.960]   Everything I talked about is a reaction to that
[00:06:28.960 --> 00:06:34.720]   This is no different if you want to understand why it's so rare to see more Brandon Sanderson's in the world of knowledge work
[00:06:34.720 --> 00:06:36.720]   writ large it is because of digital
[00:06:36.720 --> 00:06:39.480]   business productivity software in particular
[00:06:39.480 --> 00:06:42.440]   digital communication tools
[00:06:42.440 --> 00:06:46.180]   So let's walk this through you introduce something like email
[00:06:46.180 --> 00:06:53.800]   Now you have an incredibly low friction way of reaching out and communicating with someone now. Why does this cause trouble?
[00:06:54.800 --> 00:07:01.360]   Well, this means now the social capital as well as just the strict time and effort cost of me
[00:07:01.360 --> 00:07:05.560]   Commanding some of your time and attention has just radically diminished
[00:07:05.560 --> 00:07:10.120]   if I want to ask you a question if I want to request that you jump on a call if I want to like
[00:07:10.120 --> 00:07:16.000]   Put a quick task onto your plate. I can do this at very low cost. So I'm gonna do this more
[00:07:16.000 --> 00:07:20.560]   Because every time I can command some of your time and attention what I am doing is reducing
[00:07:21.080 --> 00:07:23.560]   How much time and attention I have to expend?
[00:07:23.560 --> 00:07:29.080]   So now it becomes rational for me in a game theoretic way to try to command as much time and attention as possible from as
[00:07:29.080 --> 00:07:31.080]   Many people as possible because that will maximize
[00:07:31.080 --> 00:07:33.480]   What I can get out of my own time and attention
[00:07:33.480 --> 00:07:37.160]   so once you have this dynamic and
[00:07:37.160 --> 00:07:43.640]   You have this dynamic in a workplace where there are no hard structures or systems about here's how we figure out work
[00:07:43.640 --> 00:07:47.600]   Here's how we assign work. Here's how we talk about work in a workplace without those structures
[00:07:47.600 --> 00:07:53.760]   What's going to happen is we are going to all pull each other inexorably downwards towards this suboptimal equilibrium
[00:07:53.760 --> 00:07:57.160]   this degenerate equilibrium where no one can escape and
[00:07:57.160 --> 00:08:06.000]   Everyone finds themselves doing way too many things you find yourself in a state of almost constant distraction you find yourself with workload saturation
[00:08:06.000 --> 00:08:09.660]   I can't take anything more on my plate. I'm literally out of minutes to work on it
[00:08:09.660 --> 00:08:12.680]   this is what will happen in a world of
[00:08:13.360 --> 00:08:18.420]   Zero cost request of time and attention and every request gives you a personal benefit
[00:08:18.420 --> 00:08:22.800]   Everyone is going to drag everyone down until everyone is workload saturated and distracted
[00:08:22.800 --> 00:08:26.240]   So we don't have
[00:08:26.240 --> 00:08:31.660]   Sandersons of these companies cooking we have them checking email 150 times a day
[00:08:31.660 --> 00:08:39.440]   The technology I think is what created this if you're not in the mode of designing workflows or rules
[00:08:40.160 --> 00:08:46.600]   What will rule in your workplace is going to be something that emerges and unfortunately as I've captured in multiple books now in
[00:08:46.600 --> 00:08:49.560]   Digital knowledge work what's going to emerge?
[00:08:49.560 --> 00:08:55.120]   Bottom up is going to be this state this hyperactive hive mind state of saturation and distraction
[00:08:55.120 --> 00:08:59.240]   So let's talk about what a world would be like without this. So so what is
[00:08:59.240 --> 00:09:05.760]   What would a cooking model be if I said enough of this? I hate this like we're all saturated and distracted all the time
[00:09:05.760 --> 00:09:08.480]   No, no, no, we're gonna come in and these rules here in our company
[00:09:08.480 --> 00:09:12.240]   We want we want to let those people cook. What should a cooking model?
[00:09:12.240 --> 00:09:16.160]   Actually include well, we can go back to Sanderson here
[00:09:16.160 --> 00:09:21.000]   To help expand our understanding of what it means to let someone cook
[00:09:21.000 --> 00:09:26.020]   Hey, it's Cal. I wanted to interrupt briefly to say that if you're enjoying this video
[00:09:26.020 --> 00:09:32.880]   Then you need to check out my new book slow productivity the lost art of accomplishment without
[00:09:33.560 --> 00:09:39.680]   Burnout. This is like the Bible for most of the ideas we talked about here in these videos
[00:09:39.680 --> 00:09:44.840]   You can get a free excerpt at calnewport.com/slow
[00:09:44.840 --> 00:09:49.120]   I know you're gonna like it. Check it out. Now. Let's get back to the video
[00:09:49.120 --> 00:09:55.440]   There's two elements that come up when we hear Sanderson talk about his approaches to productivity. The first is reduction
[00:09:55.440 --> 00:09:57.880]   This is what was mentioned in that clip. We just listened to
[00:09:57.880 --> 00:10:02.320]   Where he said my company is set up to sort of take off my plate
[00:10:03.080 --> 00:10:08.600]   Everything I don't strictly need to do now. He goes on in that clip to give a like a somewhat facetious example
[00:10:08.600 --> 00:10:13.040]   He says there's someone who fills my water bottle for me, so I don't have to bother going to do it
[00:10:13.040 --> 00:10:14.320]   That is sort of a metaphor
[00:10:14.320 --> 00:10:15.440]   I mean, I'm sure that's probably true
[00:10:15.440 --> 00:10:18.440]   but that's sort of a metaphor for the broader things of all the
[00:10:18.440 --> 00:10:20.560]   decisions that have to be made the
[00:10:20.560 --> 00:10:26.800]   logistical steps that happen in producing merchandising and producing books and publishing books and marketing books and getting the rights from the Illustrator that you're
[00:10:26.800 --> 00:10:31.720]   Gonna use for the graphic on the self-published hardcover version of the book and the rights you need and all those type of things
[00:10:31.720 --> 00:10:34.780]   He gets himself out of those if I don't really have to be in those decisions
[00:10:34.780 --> 00:10:37.960]   Let's find a way for me not to be in them. So he reduces
[00:10:37.960 --> 00:10:41.280]   his cookie model reduces
[00:10:41.280 --> 00:10:44.080]   the amount of things that he's responsible for
[00:10:44.080 --> 00:10:48.920]   Now yes, this makes other people other people have to do more things
[00:10:48.920 --> 00:10:56.040]   But this is not an egalitarian commune. This is a business where we're trying to maximize the value produced and
[00:10:57.000 --> 00:11:01.320]   So it's not about trying to have an equal level of convenience or
[00:11:01.320 --> 00:11:06.040]   Disconvenience among all people in the organization. It's how do we get 300,000 words out of Brandon?
[00:11:06.040 --> 00:11:09.480]   You will do more of this stuff so he can do more of that stuff
[00:11:09.480 --> 00:11:12.320]   right, that is just
[00:11:12.320 --> 00:11:18.200]   Economics one-on-one the second element that I think goes into his cooking model and I got this from some of his essays
[00:11:18.200 --> 00:11:20.360]   Not from this interview is
[00:11:20.360 --> 00:11:21.800]   consolidation
[00:11:21.800 --> 00:11:23.520]   He reduces
[00:11:23.520 --> 00:11:26.320]   What's on his plate and then he consolidates?
[00:11:26.840 --> 00:11:28.360]   What remains?
[00:11:28.360 --> 00:11:31.720]   To try to minimize its footprint now this requires everyone else being on board
[00:11:31.720 --> 00:11:37.200]   That's why this has to be part of like an agreed-upon workflow. I'm gonna read here a quote from a blog post
[00:11:37.200 --> 00:11:41.760]   He wrote about his habits here. I'm gonna read this here. So this is Brandon talking. I
[00:11:41.760 --> 00:11:49.320]   Also set aside one day a week for business matters answering email signing things from my store phone calls with my agent, etc
[00:11:49.320 --> 00:11:53.120]   I'm lucky to have I'm lucky enough to have assistance I can trust
[00:11:53.120 --> 00:11:57.840]   I don't have to get distracted by day-to-day interruptions because I know my assistants will deal with most of it and only ask me about
[00:11:57.840 --> 00:12:01.200]   Things that really need my input and most of them can wait until my business day
[00:12:01.200 --> 00:12:06.920]   So he has one day where the stuff he really does need to do he can do
[00:12:06.920 --> 00:12:09.840]   So the other days he knows I'm just writing
[00:12:09.840 --> 00:12:13.520]   That's the cooking model
[00:12:13.520 --> 00:12:16.860]   Again, this model doesn't apply to a lot of jobs
[00:12:17.840 --> 00:12:23.400]   Maybe most jobs but the jobs that it does apply to could make a really big difference
[00:12:23.400 --> 00:12:29.200]   So why then is my final point I want to make about this. Why should we care?
[00:12:29.200 --> 00:12:35.760]   I mean we should care if we're if we're a Brandon Sanderson type at our company. This would be great
[00:12:35.760 --> 00:12:38.360]   Yeah, I could just cook right I could just like rock and roll
[00:12:38.360 --> 00:12:44.200]   I could have one day where I have to like talk to people and then otherwise I'm writing or I'm programming or I'm doing strategy
[00:12:44.200 --> 00:12:48.980]   Or I'm crunching numbers or doing research, whatever it is. Yeah for the small percentage of people in supply
[00:12:48.980 --> 00:12:49.560]   So that'd be great
[00:12:49.560 --> 00:12:55.000]   But why should the rest of us care about this because again most people have jobs like my temporary director of undergraduate study job
[00:12:55.000 --> 00:12:58.240]   My final point is here's why we should all care about it
[00:12:58.240 --> 00:13:04.200]   Here's why it would be a good thing if more organizations had a small number of people with cooking models for their workflows
[00:13:04.200 --> 00:13:07.080]   it would represent a
[00:13:07.080 --> 00:13:09.560]   notable incursion
[00:13:10.200 --> 00:13:13.760]   Against our broader embrace of pseudo productivity in the world of knowledge work
[00:13:13.760 --> 00:13:20.520]   So pseudo productivity this core concept for my new book slow productivity is the idea that
[00:13:20.520 --> 00:13:25.040]   Visible effort is a reasonable proxy for useful effort. The more stuff you do the better
[00:13:25.040 --> 00:13:27.640]   Busyness is the goal
[00:13:27.640 --> 00:13:29.840]   This would be an incursion against that
[00:13:29.840 --> 00:13:33.860]   Right because when you say no, no, I'm gonna let this person just write
[00:13:33.860 --> 00:13:36.640]   You're saying busyness is not the goal
[00:13:37.240 --> 00:13:42.240]   The goal here is the number of words he produces because that's valuable. I don't care if
[00:13:42.240 --> 00:13:47.840]   They respond to slacks quickly or if they're jumping on a bunch of zooms or we see them around the office
[00:13:47.840 --> 00:13:53.200]   I want them producing words. That is a completely different mindset. That is an output focused
[00:13:53.200 --> 00:13:57.320]   productivity mindset a result focused productivity mindset and once you have
[00:13:57.320 --> 00:14:02.000]   Established that as a valid mindset, even if you've just established in your organization for four people
[00:14:02.600 --> 00:14:06.440]   You've established that that is an alternative way to think about productivity. It is a
[00:14:06.440 --> 00:14:10.040]   Alternative to pseudo productivity and once that alternative exists
[00:14:10.040 --> 00:14:13.120]   it can begin to spread and
[00:14:13.120 --> 00:14:18.840]   So like once you acknowledge, okay for this salesperson this programmer and this strategist
[00:14:18.840 --> 00:14:22.280]   They're gonna cook once you acknowledge. That's a very
[00:14:22.280 --> 00:14:25.120]   effective way of thinking about productive output
[00:14:25.120 --> 00:14:28.760]   you can use that knowledge for other positions and
[00:14:29.480 --> 00:14:33.720]   Now maybe for other positions is like okay. I don't have one thing
[00:14:33.720 --> 00:14:37.400]   I should just be doing all day, but we're recognizing busyness is not that important
[00:14:37.400 --> 00:14:41.420]   So maybe in this other position like my director of undergraduate studies position
[00:14:41.420 --> 00:14:44.720]   Well, we have like this one day where all the meetings happen and this gets automated
[00:14:44.720 --> 00:14:50.160]   It allows you to explore workflow configurations that aren't just built on demonstrating busyness
[00:14:50.160 --> 00:14:56.140]   And once you're no longer just demonstrating busyness a lot of the pain points of modern knowledge work can be dissipated
[00:14:56.140 --> 00:14:59.360]   So that's why I'm interested in this in the in the big picture, right?
[00:14:59.360 --> 00:15:03.460]   I got small picture interest for the Brandon Sanderson's of the of this sector
[00:15:03.460 --> 00:15:07.120]   Let them cook it's gonna be better for the company's a better for them big picture
[00:15:07.120 --> 00:15:09.840]   Once you're doing that for some people
[00:15:09.840 --> 00:15:12.000]   you have
[00:15:12.000 --> 00:15:14.620]   Acknowledged that pseudo productivity is not the only way
[00:15:14.620 --> 00:15:17.440]   You have an incursion against small
[00:15:17.440 --> 00:15:23.820]   But definitive incursion against that reality and I am convinced that it is the end of the pseudo productivity regime
[00:15:23.820 --> 00:15:26.800]   that will
[00:15:27.000 --> 00:15:30.920]   Spark the beginning of a new era of knowledge work in the digital age. We can't actually
[00:15:30.920 --> 00:15:33.800]   reap the potential benefits of
[00:15:33.800 --> 00:15:39.420]   Digital technology and office work the potential almost like utopian visions
[00:15:39.420 --> 00:15:44.780]   We have for what work could be we cannot reap those until we take down the pseudo productivity regime
[00:15:44.780 --> 00:15:51.300]   Until we have our equivalent of pulling down, you know, the Saddam Hussein statue in Iraq
[00:15:51.300 --> 00:15:56.720]   we need somewhere for there to be some sort of metaphorical statue that is going to be
[00:15:56.720 --> 00:16:04.860]   Like a gmail unread message count and we're gonna pull on those ropes and pull that thing down and indicate that regime is done
[00:16:04.860 --> 00:16:08.440]   We're moving on to a new way of thinking about productivity. All right, so
[00:16:08.440 --> 00:16:11.100]   Sanderson's cool. I
[00:16:11.100 --> 00:16:15.980]   Like his approach that they built the whole business around just laying them, right?
[00:16:16.300 --> 00:16:22.340]   more companies should do that for their Sanderson style characters and once we do that things could get better for everyone else and
[00:16:22.340 --> 00:16:26.140]   Just you'll be proud that I got that whole distance without doing
[00:16:26.140 --> 00:16:29.060]   The whole segment without doing a name of the wind joke
[00:16:29.060 --> 00:16:33.940]   He talks about his writing schedule as he wakes up late
[00:16:33.940 --> 00:16:40.060]   He writes somewhere from 2 to 5 or 6 and then hangs with his family. Then he writes again from 10 to
[00:16:40.060 --> 00:16:45.700]   2 in the morning. Yeah, a lot of people do that like they get that Tim Ferriss writes that way
[00:16:46.580 --> 00:16:49.700]   He's got like two sessions a day for an Itali up to eight hours
[00:16:49.700 --> 00:16:54.360]   I mean a lot of people the people I know night right just do the night session, but Samson's is the beast
[00:16:54.360 --> 00:17:00.900]   Yeah, do you imagine writing for eight hours a day? No easy. They wrote four hours yesterday and they're the tear myself away
[00:17:00.900 --> 00:17:03.740]   Once you get going
[00:17:03.740 --> 00:17:05.060]   writing
[00:17:05.060 --> 00:17:10.780]   Right, like you just want to that's all you want to do. You probably average what three a day three
[00:17:10.780 --> 00:17:14.620]   I feel like three is a good session. Yeah, I wonder if he writes on the weekends
[00:17:15.620 --> 00:17:20.520]   That's a good question, I bet he does well, he's Mormon so I don't know if they
[00:17:20.520 --> 00:17:24.940]   Protect the Sabbath or not. They might they have a lot of rules
[00:17:24.940 --> 00:17:29.500]   So maybe not on I guess their Sabbath will be Sunday. I don't know about that
[00:17:29.500 --> 00:17:34.540]   But he probably does. I think that guy works a lot. He works a lot
[00:17:34.540 --> 00:17:40.140]   I say he has a quick commute. He just walks to his layer. I know we got to get to that layer Jesse
[00:17:40.140 --> 00:17:42.500]   We got to get to that layer
[00:17:42.500 --> 00:17:44.500]   We got to build a layer
[00:17:44.500 --> 00:17:50.540]   I watched the video with my son the other night where they took is like a boring
[00:17:50.540 --> 00:17:55.580]   Completely undecorated sort of home office room and they
[00:17:55.580 --> 00:17:59.340]   Renovated the whole thing into a dark academia
[00:17:59.340 --> 00:18:07.380]   Set so like old bookcases and leather-bound books and chairs and like a fake fireplace or whatever. I was like, oh man
[00:18:07.380 --> 00:18:10.180]   That's so awesome. Didn't you do that in your home office?
[00:18:10.480 --> 00:18:16.800]   Yeah, I guess so, but I want to do it more here. But here's the problem you watch this video and it takes them forever
[00:18:16.800 --> 00:18:24.920]   They worked on this that the channel is called nerdforge. It's like a Scandinavian maker DIY woman and it just must have been
[00:18:24.920 --> 00:18:30.920]   Three to four weeks of like all day work. Yeah, I would take away from writing. I keep telling my son
[00:18:30.920 --> 00:18:32.920]   I was like don't be
[00:18:32.920 --> 00:18:37.920]   You should not want to be a full-time youtuber this it's it's such hard work
[00:18:37.920 --> 00:18:41.240]   I guess I know the maker space best because I wrote that New Yorker article in that space
[00:18:41.240 --> 00:18:48.520]   I was like, it's such hard work. You got to do these projects and they're hard. It's full-time work for like months
[00:18:48.520 --> 00:18:48.880]   Yeah
[00:18:48.880 --> 00:18:54.080]   you get one video and that video better get the views because you're kind of screwed if it does it and you have to
[00:18:54.080 --> 00:18:59.120]   Constantly be like thinking about these over-the-top projects that are like really hard to do
[00:18:59.120 --> 00:19:03.600]   It seems like a stressful job. Mm-hmm, and the money's like, okay, but it's like
[00:19:04.400 --> 00:19:09.440]   Not there is no equivalent in that world of like Travis Kelsey's podcast contract
[00:19:09.440 --> 00:19:13.960]   Like if you want to look at independent media worlds like in podcasting there's paydays
[00:19:13.960 --> 00:19:21.640]   There's not really paydays like that in YouTube that the it's harder to squeeze dollars. It's all with these sponsorship deals. It's harder to squeeze
[00:19:21.640 --> 00:19:28.960]   Dollars you need like multi-million view videos that you can do like six times a year is kind of a sweet spot and then you're doing
[00:19:28.960 --> 00:19:31.200]   You're still nowhere near
[00:19:32.520 --> 00:19:37.640]   Really successful podcasters, but the same thing which Brandon was talking about in the interview with Ferris's
[00:19:37.640 --> 00:19:43.720]   He wanted to start his own ecosystem to get off of relying on Amazon if you're just a full-time youtuber
[00:19:43.720 --> 00:19:46.480]   Oh, it's been your channel gets canceled. What are you gonna do then?
[00:19:46.480 --> 00:19:51.640]   Oh, yeah, you put something out that yeah happens to get banned or the algorithm changes
[00:19:51.640 --> 00:19:55.080]   Yeah, like we see this we put our we put our you might be watching this on YouTube
[00:19:55.080 --> 00:20:02.160]   We put our podcast on YouTube because a lot of people actually listen to podcasts using the YouTube app. So fine
[00:20:02.160 --> 00:20:04.680]   We'll put it up there or they'll watch it. They like to have it on or whatever
[00:20:04.680 --> 00:20:07.680]   but the the numbers like views is
[00:20:07.680 --> 00:20:16.260]   Incredibly fickle, right? Like if I overwrite our YouTube guys like change that word. It'll be like 10,000 less people will watch it
[00:20:16.260 --> 00:20:18.680]   It's crazy like podcast
[00:20:18.680 --> 00:20:25.240]   I'm used to podcasting books and email newsletter or like every person who is consuming your stuff is hard one
[00:20:25.240 --> 00:20:27.520]   But then they're just gonna consume your stuff
[00:20:27.520 --> 00:20:33.520]   It's like I have this many people who will read my newsletter and it took a long time to build them up and they'll read
[00:20:33.520 --> 00:20:34.800]   It every time I write it, you know
[00:20:34.800 --> 00:20:37.240]   Or I have like this many readers who will buy my new book
[00:20:37.240 --> 00:20:42.960]   When it comes out or we have our podcast numbers are very stable, you know, it's hard one
[00:20:42.960 --> 00:20:47.600]   There's no algorithms, but it's stable YouTube is man's Wild West. Mm-hmm
[00:20:47.600 --> 00:20:52.640]   You just be like we have videos that'll have 600,000 views, you know
[00:20:52.640 --> 00:20:56.360]   And then other ones like nothing and also you'll you'll look in this world
[00:20:56.360 --> 00:20:58.880]   I guess we have to give more credit to our YouTube guy because I'll look at
[00:20:58.880 --> 00:21:01.680]   really popular podcasters
[00:21:01.680 --> 00:21:09.040]   Like Mel Robbins and like yeah, we're putting just huge massive podcast number one podcast this week actually on the Apple charts
[00:21:09.040 --> 00:21:11.600]   I've never even heard of that podcast before I'm going on it
[00:21:11.600 --> 00:21:15.580]   I don't know if I'm supposed to talk about that before but I may or may not be going on it
[00:21:15.580 --> 00:21:18.340]   We can edit it out. Yeah, I guess I don't know if it's a secret or not
[00:21:18.340 --> 00:21:21.440]   but like her YouTube page her show is
[00:21:22.120 --> 00:21:25.120]   Very popular. She puts her episodes on YouTube like we do
[00:21:25.120 --> 00:21:31.000]   Maybe there's just like a little bit of thumbnail title stuff. That's different. It know it just almost no views
[00:21:31.000 --> 00:21:39.060]   Like we're crushing those videos even though her audience is probably 5x our audience. So YouTube is yeah
[00:21:39.060 --> 00:21:45.520]   Put stuff on it, but it's like posting ghost. It's a hard world to make to make your main world
[00:21:45.520 --> 00:21:52.080]   But it has that appeal of you never know. There's this algorithmic lottery, right?
[00:21:52.080 --> 00:21:58.440]   You know what podcast he's just brutal. It's like no one listened to my podcast now five people downloaded it now seven people download
[00:21:58.440 --> 00:22:03.520]   It's brutal right there and there's no way that that's gonna change fast YouTube. It's always like you never know
[00:22:03.520 --> 00:22:05.840]   There could be some virality thing
[00:22:05.840 --> 00:22:09.360]   I could get a million people could look at this and I think that keeps people locked in
[00:22:09.360 --> 00:22:12.240]   Mm-hmm. This is kind of a divergence. We've kind of
[00:22:12.240 --> 00:22:14.760]   We've gone off
[00:22:14.760 --> 00:22:18.880]   We've gone from our digital knowledge work category to our attention economy category
[00:22:19.480 --> 00:22:22.160]   But we'll bring it back. All right, we got some good questions to go through
[00:22:22.160 --> 00:22:28.880]   But first I want to briefly talk about one of our sponsors in particular. I want to talk about our friends at cozy earth
[00:22:28.880 --> 00:22:34.920]   Longtime listeners know I am a cozy earth fanatic. We have multiple pairs of the sets
[00:22:34.920 --> 00:22:36.920]   I should say if the cozy earth bamboo sheets
[00:22:36.920 --> 00:22:40.560]   They are the most comfortable sheets that I have ever slept on
[00:22:40.560 --> 00:22:44.000]   So we now my wife and I have multiple pairs so that when one is being washed
[00:22:44.000 --> 00:22:47.120]   We have another pair that can be on the bed so that we're never without them
[00:22:47.360 --> 00:22:54.360]   My wife has the cozy earth bamboo pajama set so you get the the comfort feeling of the sheets in
[00:22:54.360 --> 00:22:57.240]   Your pajamas. I have the cozy earth
[00:22:57.240 --> 00:23:01.360]   It's like a sweatshirt that's made out of the material because it's really comfortable
[00:23:01.360 --> 00:23:05.960]   I mean, we really are sort of cozy earth fanatics. We push it on people all the time. We've given it as gifts to people
[00:23:05.960 --> 00:23:09.200]   It's just really comfortable stuff
[00:23:09.200 --> 00:23:12.120]   As you hear this Valentine's Day will be very
[00:23:13.080 --> 00:23:16.560]   imminent, so I need a last-minute gift maybe give cozy earth a
[00:23:16.560 --> 00:23:24.080]   Consideration. All right. So what makes them different a couple things I want to mention here temperature regulation
[00:23:24.080 --> 00:23:27.520]   They're known for being breathable and cool. They don't the the sheet material
[00:23:27.520 --> 00:23:33.800]   Doesn't heat up as much if it feels kind of cool same with the clothing. Actually, it's kind of it's kind of nice
[00:23:33.800 --> 00:23:36.200]   The fabric is very durable
[00:23:36.200 --> 00:23:41.080]   It won't pill it's guaranteed for 10 years. It's super soft. It really feels good
[00:23:41.720 --> 00:23:43.720]   And they have responsible
[00:23:43.720 --> 00:23:45.400]   production techniques
[00:23:45.400 --> 00:23:46.920]   so anyways
[00:23:46.920 --> 00:23:50.760]   You could surprise your Valentine or just surprise yourself with comfort
[00:23:50.760 --> 00:23:54.360]   With cozy earth you can get up to and it's a good offer
[00:23:54.360 --> 00:24:01.540]   40% off if you go to cozy earth comm slash deep and use the promo code deep
[00:24:01.540 --> 00:24:09.680]   That's cozy earth comm slash deep cozy why and use that promo code is deep and don't forget if you're asking a post
[00:24:09.880 --> 00:24:12.900]   Purchase survey if a thing pops up and says where'd you hear about us?
[00:24:12.900 --> 00:24:19.680]   Choose our podcast. It lets them know that people are actually listening. I also want to talk about our friends at
[00:24:19.680 --> 00:24:26.640]   Lofty what if your mornings didn't start with an annoying jolt, but with calm focus and energy
[00:24:26.640 --> 00:24:30.560]   Lofty is here to change the way you wake up and help you sleep better while you're at it
[00:24:30.560 --> 00:24:36.520]   if improving your sleep routine is a important priority for you in 2025 meet the lofty clock a
[00:24:37.040 --> 00:24:43.120]   Bedside essential engineered by sleep experts that transform both your bedtime and your mornings. We have several of these
[00:24:43.120 --> 00:24:46.780]   They look great. Very modernist. We have the black ones
[00:24:46.780 --> 00:24:50.080]   minimal switches
[00:24:50.080 --> 00:24:54.320]   So it's simple the idea for adults is you don't have to have your phone next to your bed
[00:24:54.320 --> 00:24:56.320]   You have an alarm clock
[00:24:56.320 --> 00:24:59.920]   but I also like the way it works where it you can set it to
[00:24:59.920 --> 00:25:04.480]   Begin to get brighter as you get towards to wake up and then have all sorts of different
[00:25:05.000 --> 00:25:10.680]   Wake up sounds that it switches to so it's not just like that jolting calypso music from your iPhone
[00:25:10.680 --> 00:25:15.920]   My son, so we have one of my youngest son's room and I don't know how we chose
[00:25:15.920 --> 00:25:18.040]   I think we let him choose the sound
[00:25:18.040 --> 00:25:21.880]   It's I don't know what you call it like monk gongs
[00:25:21.880 --> 00:25:24.360]   like
[00:25:24.360 --> 00:25:26.360]   Bung and it took me a while
[00:25:26.360 --> 00:25:29.680]   Because I just be walking around the house because I get up before him
[00:25:30.120 --> 00:25:34.800]   As I guess is there a monastic it like is there a monastery nearby like where is he sounds kind?
[00:25:34.800 --> 00:25:39.260]   It took me a while to realize. Oh, it's from our lofty clock. They look great
[00:25:39.260 --> 00:25:42.840]   They help you wake up and it gets that stupid phone out of your room
[00:25:42.840 --> 00:25:46.360]   You don't want your phone in your room have this elegant design clock instead
[00:25:46.360 --> 00:25:48.760]   So you can join over
[00:25:48.760 --> 00:25:52.600]   100,000 blissful sleepers who have upgraded their rest and mornings with lofty
[00:25:53.160 --> 00:26:01.000]   Go to buy lofty comm and use the code deep 20 to get 20% off orders over
[00:26:01.000 --> 00:26:04.040]   $100 that's B Y
[00:26:04.040 --> 00:26:07.760]   L O F T I E by lofty
[00:26:07.760 --> 00:26:14.080]   So be why not be you I buy lofty comm and use that code deep 20 and you will get 20% off your orders over
[00:26:14.080 --> 00:26:18.320]   $100. All right, Jesse. Let's move on to some questions
[00:26:20.160 --> 00:26:27.320]   The first questions from Joe, but before I said I have a quick question my own now that you don't wear the traditional podcast shirt
[00:26:27.320 --> 00:26:31.680]   Are you ever gonna wear that shirt again? I don't know why I've just been in a t-shirt mood
[00:26:31.680 --> 00:26:34.760]   recently
[00:26:34.760 --> 00:26:37.360]   I'll tell you what I I would like to
[00:26:37.360 --> 00:26:40.400]   Get a new set of podcast shirts
[00:26:40.400 --> 00:26:44.200]   But I don't know what they're gonna be something. I was gonna ask you offline
[00:26:44.200 --> 00:26:47.840]   But I was like, I'm the audience might be curious. Yeah, I mean
[00:26:49.320 --> 00:26:51.320]   I've been in a t-shirt mode
[00:26:51.320 --> 00:26:53.640]   but I do need
[00:26:53.640 --> 00:26:56.800]   We should have like a giant selection show about this. I
[00:26:56.800 --> 00:27:02.920]   Want to find some got around to it. I want I want a new podcast. I don't want to stick with t-shirts
[00:27:02.920 --> 00:27:05.160]   because I feel like
[00:27:05.160 --> 00:27:09.720]   It's such like a Silicon Valley cliche when like men in their 40s and 50s are like wearing
[00:27:09.720 --> 00:27:12.320]   Too many t-shirts and like formal settings, you know
[00:27:12.320 --> 00:27:17.320]   I couldn't wear a t-shirt in here because you run hot and I run cold. I'll just be freezing
[00:27:17.320 --> 00:27:19.320]   I know like I am
[00:27:19.320 --> 00:27:24.540]   Like slightly on the warm side of like normal right now, and I'm sure it's pretty cold in here. Yeah. Yeah, I run hot
[00:27:24.540 --> 00:27:29.160]   Yeah, so I don't I don't want to stick with the t-shirts, but I gotta find I don't know
[00:27:29.160 --> 00:27:35.160]   I want to I want to upgrade the look of the show. So I'm thinking about it. I don't know. Okay, probably I'm watching
[00:27:35.160 --> 00:27:40.200]   I'm doing a lot of PT right now and I've discovered like oh as everyone else knows you can watch
[00:27:40.200 --> 00:27:46.440]   Like dumb shows while you exercise especially like stretches or whatever and I'm watching like all the shows on Netflix
[00:27:46.960 --> 00:27:52.220]   I'm watching the Netflix documentary on the history of the TV show American Gladiators
[00:27:52.220 --> 00:27:57.360]   So I'm thinking is that any good? Well, I think what I should be wearing is an American Gladiator
[00:27:57.360 --> 00:28:00.080]   one of the deep-cut onesies
[00:28:00.080 --> 00:28:07.120]   Like Nitro or Malibu more on that show. I have to lift a few more weights. All right. What's our first question?
[00:28:07.120 --> 00:28:09.280]   All right first question from Joe
[00:28:09.280 --> 00:28:13.520]   You commented on Justin Sung's YouTube video last month
[00:28:13.640 --> 00:28:17.120]   He's big on mind mapping and how to become a straight-a student
[00:28:17.120 --> 00:28:25.040]   The intro says I promise you won't find any mention of the Cornell note-taking method mental map diagrams or any other optimal learning technique
[00:28:25.040 --> 00:28:26.620]   What is your opinion?
[00:28:26.620 --> 00:28:31.640]   Well, I mean that's an interesting quote you bring up there from the beginning of how to become a straight-a student that book came out
[00:28:31.640 --> 00:28:37.060]   in 2006 and I actually remember writing that introduction because at the time I
[00:28:37.060 --> 00:28:42.120]   Was looking at other not just student advice books, but sort of online
[00:28:42.760 --> 00:28:49.260]   Collections of student advice from university student resources websites or what-have-you and things were starting to get a little out of control
[00:28:49.260 --> 00:28:51.800]   like the
[00:28:51.800 --> 00:28:56.880]   number of systems and the complexity of systems were really expanding and my whole
[00:28:56.880 --> 00:29:04.340]   Unique selling proposition when I wrote that book is that I was a recent graduate like a graduate in 2004. I wrote that book
[00:29:04.340 --> 00:29:11.940]   Largely in 2005 and so I was grounded in the reality of college life when I was thinking about that
[00:29:11.940 --> 00:29:13.920]   And I was like, this is crazy
[00:29:13.920 --> 00:29:15.920]   This is gonna take way too long
[00:29:15.920 --> 00:29:20.440]   no one is gonna take notes with multiple columns and go back through and then write the
[00:29:20.440 --> 00:29:23.740]   Clarification and then go back through there and try to put this into some sort of structure
[00:29:23.740 --> 00:29:26.540]   there's all of this research, which I thought was kind of
[00:29:26.540 --> 00:29:29.560]   Silly or they said yes
[00:29:29.560 --> 00:29:35.780]   If you do this like incredibly time-consuming super structured note-taking you understand the material better
[00:29:35.780 --> 00:29:39.520]   Sure, but it takes forever and no one's going to do it
[00:29:39.520 --> 00:29:44.920]   And so no one does so my whole thing with that book is like let's get down to what actually works
[00:29:44.920 --> 00:29:50.340]   Let's get every unnecessary piece of friction out of the system so that you're spending as much time as possible
[00:29:50.340 --> 00:29:53.060]   Just on like the actual core
[00:29:53.060 --> 00:29:57.980]   Cognitive activity that is best preparing you for your goal, which is like doing well on this test
[00:29:57.980 --> 00:30:01.060]   Like we get in physical activity, you know
[00:30:01.060 --> 00:30:06.540]   What are the actual things that matter for the muscle development and like let's focus on that, you know
[00:30:06.540 --> 00:30:10.660]   And so that's what I thought the problem was with that world back then I was trying to simplify it
[00:30:10.660 --> 00:30:15.260]   So no, I was never a fan of these more advanced study techniques
[00:30:15.260 --> 00:30:18.460]   So because of that I've never been a fan of things like mental mapping. I mean, I don't I
[00:30:18.460 --> 00:30:23.960]   Don't mind it. Like if you like making mental maps, it's fine, right? You do you I don't think it's a bad thing
[00:30:23.960 --> 00:30:30.740]   But most professional thinkers I know don't use these sort of complicated thought organization techniques
[00:30:31.100 --> 00:30:35.820]   They don't use mental maps. They don't have zettelkasten systems. They take in a lot of information
[00:30:35.820 --> 00:30:38.300]   They trust their brain
[00:30:38.300 --> 00:30:42.620]   Their brain is the best mental map producer and zettelkasten organizer. There is
[00:30:42.620 --> 00:30:44.700]   ideas stick
[00:30:44.700 --> 00:30:50.140]   They keep recurring and they say okay, I'm gonna take that idea and I'm gonna work on it for professional thinkers
[00:30:50.140 --> 00:30:51.860]   I say this all the time on the show
[00:30:51.860 --> 00:30:56.140]   The hardest thing the thing that requires all the effort and help is not the ideas
[00:30:56.300 --> 00:31:02.340]   It's the transforming those ideas into something of sufficient quality that it is shareable and interesting to the world
[00:31:02.340 --> 00:31:06.640]   That's where all the time goes in. That's where the software matters. That's where the systems matters
[00:31:06.640 --> 00:31:11.700]   That's where like time management Maddox that takes forever. That's where it matters. If you're using Scrivener versus Microsoft Word
[00:31:11.700 --> 00:31:18.660]   That's where all of the the rubber is hitting the proverbial road is the taking the idea and turn it into something you can share
[00:31:18.660 --> 00:31:21.460]   And that people care about the ideas itself is like the easy part
[00:31:22.620 --> 00:31:25.660]   You know, I was thinking about this like when I write articles for the New Yorker
[00:31:25.660 --> 00:31:30.380]   Yeah, we come up with ideas, I don't know I'll have an idea an editor
[00:31:30.380 --> 00:31:34.260]   I'll write me what about this we dismiss both of them one kind of clicks like that makes sense
[00:31:34.260 --> 00:31:36.020]   Like that's not the hard part
[00:31:36.020 --> 00:31:40.300]   The hard part then is like how do we turn that into a 2000 word piece up to the caliber of New Yorker?
[00:31:40.300 --> 00:31:43.820]   Now that is you're gonna sweat bullets and that's where all the stuff matters. So no, I'm not
[00:31:43.820 --> 00:31:47.300]   Against these type of systems, but I I don't buy
[00:31:47.980 --> 00:31:54.620]   That these systems unlock more creativity or more efficiency or productivity when it comes to professional idea production
[00:31:54.620 --> 00:31:57.900]   Keep your system stupid. Keep your output great
[00:31:57.900 --> 00:32:01.740]   All right. Who do we have next next questions from Cara?
[00:32:01.740 --> 00:32:08.980]   How do you figure out the thing that really matters for developing career capital or maybe it's about optimizing from one to two qualities
[00:32:08.980 --> 00:32:15.940]   But still having satisfactory performance in many others. It's such such a key question and it's so hard. It's so hard
[00:32:15.940 --> 00:32:17.980]   All right. So let me give you a couple points about this
[00:32:17.980 --> 00:32:20.620]   one where you say
[00:32:20.620 --> 00:32:26.180]   Optimizing one or two qualities, but still have satisfactory performance in many others. This is really important
[00:32:26.180 --> 00:32:29.060]   the foundation
[00:32:29.060 --> 00:32:31.220]   to any career capital strategy
[00:32:31.220 --> 00:32:36.820]   So any strategy of using rare and valuable skills to as leverage to shape your career to be better for you?
[00:32:36.820 --> 00:32:39.860]   Any strategy like this you need a foundation
[00:32:39.860 --> 00:32:43.980]   Where you you're on the ball meaning?
[00:32:44.660 --> 00:32:49.300]   You do the things you say you're going to do and you do them at a reasonable level of quality
[00:32:49.300 --> 00:32:55.880]   That is the table stakes for any sort of interesting career capital strategy within a larger organization
[00:32:55.880 --> 00:33:01.780]   people trust if they ask you to do something that you are not going to forget it and it will get done and
[00:33:01.780 --> 00:33:05.260]   The quality will be good. You're not going to say like look
[00:33:05.260 --> 00:33:07.520]   I just want to get this off my plate and this is sort of
[00:33:07.520 --> 00:33:12.300]   Inappropriate quality, but I'm just gonna put it out there. Anyways, that's not my problem. You take responsibility
[00:33:12.420 --> 00:33:17.540]   You get it done. You get it done. Well, even if that means in the in the moment like oh shoot
[00:33:17.540 --> 00:33:20.300]   I really have to scramble here because I don't know how to do this, right?
[00:33:20.300 --> 00:33:28.840]   That's not about being fantastic at a single skill. That's just a foundational skill level. You have that foundational skill level
[00:33:28.840 --> 00:33:33.140]   Now they that organization wants you you are valuable
[00:33:33.140 --> 00:33:39.820]   You you are not a negative thing. You're a positive thing. So that has to be the table stakes and that's really much more about
[00:33:40.460 --> 00:33:44.740]   Organization, you know, you have full capture you do multi-scale planning
[00:33:44.740 --> 00:33:51.140]   You're just on the ball with what's going on what you need to do who you're waiting to hear back for all that sort of boring
[00:33:51.140 --> 00:33:57.460]   Organizational type strategy how to organize yourself in digital era knowledge work get that in place first
[00:33:57.460 --> 00:34:01.280]   Now you're invaluable and they don't want to lose you
[00:34:01.280 --> 00:34:05.260]   the next step is let me take a skill a
[00:34:05.260 --> 00:34:08.820]   singular skill or one or two skills like you say that has like really
[00:34:09.780 --> 00:34:16.460]   Unambiguous high value and let me start developing those and then that's where you really begin to become so good. They can't ignore you
[00:34:16.460 --> 00:34:19.380]   But you've got to do that on a foundation of being reliable
[00:34:19.380 --> 00:34:22.620]   You're not gonna drop the ball and produce quality work because if not
[00:34:22.620 --> 00:34:27.700]   Here's a mistake a lot of people get into is they say I'm gonna obsess about getting awesome at this skill
[00:34:27.700 --> 00:34:31.820]   But otherwise I'm dropping the ball left and right and I'm annoying and annoying people
[00:34:31.820 --> 00:34:36.820]   They're not going to give you dispensation to keep working on that skill. They're not gonna reward you for that skill
[00:34:36.820 --> 00:34:42.500]   They're gonna say stop working on that skill. What I need from you now is that if I email you about this thing
[00:34:42.500 --> 00:34:46.740]   I don't have to follow up 50 times. I don't want to hear the excuses, right?
[00:34:46.740 --> 00:34:51.760]   So you have to lay that foundation before you build the singular rare and valuable skill
[00:34:51.760 --> 00:34:54.980]   Second part of your questions. How do you find that skill? It's so hard
[00:34:54.980 --> 00:34:57.580]   We don't talk about this enough
[00:34:57.580 --> 00:35:02.660]   Because knowledge work is so messy and ambiguous and we sort of just like jump on laptops and give each other slack
[00:35:02.660 --> 00:35:07.820]   Handles and begin sending out zoom invites and no one really ever talks about like what is your job and how do we measure it?
[00:35:07.820 --> 00:35:12.220]   And what are you trying to do? And what does success look like? It's so ambiguous and messy so much
[00:35:12.220 --> 00:35:14.220]   It's so we have so many different roles
[00:35:14.220 --> 00:35:20.660]   There's so many different things were expected to do and it's so informal how we pass this around that it is not easy in many
[00:35:20.660 --> 00:35:26.340]   Knowledge work jobs to figure out what would make me invaluable. What is the most important skill here? It is hard to figure that out
[00:35:26.340 --> 00:35:29.420]   but it is really worth doing so and
[00:35:29.900 --> 00:35:35.380]   I suggest you actually treat your own job as if you're a business journalist writing about your your particular
[00:35:35.380 --> 00:35:37.700]   industry sector
[00:35:37.700 --> 00:35:42.580]   You got a look you got talk you got talk to people you got take people out for coffee people who are more successful
[00:35:42.580 --> 00:35:49.020]   What is it that made you successful walk them through their career transitions for every promotion they got up?
[00:35:49.020 --> 00:35:53.500]   What was at the core of it? What did they do that made them valuable look for examples?
[00:35:53.500 --> 00:35:55.740]   Here's someone from this other company that we really want to hire
[00:35:55.740 --> 00:35:59.420]   Why are we talking about them that way who is really favored within my team?
[00:35:59.420 --> 00:36:05.380]   Why are they really favored? What is it that they do that is valuable? You have to be doing research on your own job
[00:36:05.380 --> 00:36:09.940]   to begin to build hypotheses about what you think is really valuable and
[00:36:09.940 --> 00:36:13.580]   That is really important because if you don't do that
[00:36:13.580 --> 00:36:19.900]   Here's what ambitious people do who don't do the work of actually studying their own job. They write their own stories
[00:36:19.900 --> 00:36:23.740]   You will write your own story ambitious people do this all the time
[00:36:23.740 --> 00:36:26.740]   You will write your own story about what you want to be important
[00:36:26.740 --> 00:36:31.020]   And then you'll go spend two years doing that and discover at the end
[00:36:31.020 --> 00:36:33.540]   No one cares
[00:36:33.540 --> 00:36:38.860]   Right. You gotta figure out the reality. We call this evidence-based planning is the term we use
[00:36:38.860 --> 00:36:42.580]   You've got to figure out the reality of what matters you might not like what you discover
[00:36:42.580 --> 00:36:45.620]   But you've got to figure out the reality of what matters and it can be hard to figure it out
[00:36:45.620 --> 00:36:47.620]   But if you do it's like a superpower
[00:36:47.620 --> 00:36:53.900]   There's now other people are trying to distinguish themselves through pseudo productivity or answering emails
[00:36:54.180 --> 00:37:01.060]   Faster or just trying to do more things or pursuing random projects or kissing up to the boss. You're over here
[00:37:01.060 --> 00:37:04.420]   mastering linear algebra
[00:37:04.420 --> 00:37:07.340]   because you're realizing if you could do some sort of
[00:37:07.340 --> 00:37:12.940]   Customization of language models, it could make you a hundred X more valuable to this team
[00:37:12.940 --> 00:37:18.300]   They could stop hiring etc, etc, and you have evidence that this is what matters and when you pull that trigger
[00:37:18.300 --> 00:37:21.860]   They're like, okay, you are now like very important to us. Sure. You can go live
[00:37:22.420 --> 00:37:24.420]   you know in
[00:37:24.420 --> 00:37:29.340]   By the ocean and come in once a week and we have this weird setup and like yes
[00:37:29.340 --> 00:37:31.820]   Like you're making you're doing the steps actually matter
[00:37:31.820 --> 00:37:32.660]   All right
[00:37:32.660 --> 00:37:35.380]   So carry me says - that's a long answer to a short question
[00:37:35.380 --> 00:37:35.880]   but
[00:37:35.880 --> 00:37:42.100]   build the foundation of being responsible and delivering quality then do a lot of research on your own job like a journalist to figure out what
[00:37:42.100 --> 00:37:46.220]   Matters and then build that skill and then the final step is take that out for a ride
[00:37:46.220 --> 00:37:51.660]   Customize and shape your experience to be what resonates for you. That is how great jobs are formed
[00:37:52.660 --> 00:37:55.980]   All right, what do we got next next questions from Lisa
[00:37:55.980 --> 00:38:02.980]   What's your view on Daniel Immer Wars review of multiple books on the supposed attention crisis?
[00:38:02.980 --> 00:38:10.060]   The author seems to base this conclusion largely in the claim that people who fret over ruined attention are elitist members of the knowledge class
[00:38:10.060 --> 00:38:13.260]   Well, I like Daniel. So this this was a
[00:38:13.260 --> 00:38:18.820]   Big article in The New Yorker recently. So a fellow New Yorker writer. I like Daniel. He's a very good writer. I
[00:38:18.820 --> 00:38:20.540]   didn't
[00:38:20.540 --> 00:38:22.540]   Love this particular piece
[00:38:22.540 --> 00:38:27.300]   Felt a little bit like contrarianism for the sake of contrarianism. Here's the problem
[00:38:27.300 --> 00:38:28.940]   Here's the problem
[00:38:28.940 --> 00:38:33.700]   I think with the core argument there and I should say I'm biased because I think I was flagged in that article one of my
[00:38:33.700 --> 00:38:40.700]   Books was flagged just like an example of this class of books. So clearly I'm coming from a place of bias, but his main claim is
[00:38:40.700 --> 00:38:47.740]   The concerns about attention and diminishing attention are being
[00:38:48.580 --> 00:38:50.580]   engineered by elitists like me
[00:38:50.580 --> 00:38:57.020]   Because we're upset that people are paying less attention to our stuff and paying attention to like the new stuff on new media. I
[00:38:57.020 --> 00:39:00.900]   Think that's a bit of a nonsensical claim because here's the problem
[00:39:00.900 --> 00:39:04.500]   Everyone is feeling it
[00:39:04.500 --> 00:39:11.900]   Right if this was something where the average person is like, I don't I haven't really thought about this
[00:39:11.900 --> 00:39:16.100]   But oh, you're telling me this is a problem. That's interesting. Like are we losing our attention?
[00:39:16.140 --> 00:39:19.300]   You know if it was something where most people did not have direct experience of this
[00:39:19.300 --> 00:39:25.900]   Sure, like yeah, I don't know. Maybe it's a problem. Maybe it's not right but the attention issue this idea that I have a hard time
[00:39:25.900 --> 00:39:27.660]   paying attention
[00:39:27.660 --> 00:39:33.020]   Everybody is feeling it. That's the problem with this argument. Everyone is already feeling it. Everyone is already feeling it at their work
[00:39:33.020 --> 00:39:38.900]   I can't keep my focus on this memo I'm writing for more than a couple minutes. They see it with their kids
[00:39:38.900 --> 00:39:44.620]   I mean their kids can't get their eyes off of their phones for more than six seconds. Of course, it's a problem
[00:39:44.620 --> 00:39:46.100]   I see it right here
[00:39:46.100 --> 00:39:49.080]   The teacher is like this is what I'm seeing in the classroom
[00:39:49.080 --> 00:39:53.580]   It's like every moment of your life. I feel increasingly
[00:39:53.580 --> 00:39:59.460]   Drawn from it. I went back recently. I wrote this thing for my book that got cut
[00:39:59.460 --> 00:40:03.660]   but I have all this like research I did and I was going back and tracing the
[00:40:03.660 --> 00:40:06.620]   Reaction to
[00:40:06.620 --> 00:40:09.460]   The Nicholas Carr's book The Shallows, right?
[00:40:09.460 --> 00:40:16.420]   So this is this is kind of called out in Daniel's article as one of the core or text of the attention problem movement
[00:40:16.420 --> 00:40:20.940]   so Nicholas Carr writes this book The Shallows, which and this is in oh
[00:40:20.940 --> 00:40:23.940]   God, I should know
[00:40:23.940 --> 00:40:27.720]   2009 probably 2009 I think so
[00:40:27.720 --> 00:40:31.980]   He writes this book the subtitles like what the Internet is doing to our brain and this was like the first book to really
[00:40:31.980 --> 00:40:38.620]   Call out a major journalist writing and saying I think the Internet is changing our attention. I'm struggling to read books
[00:40:39.220 --> 00:40:42.940]   I think something is going on here and it gets a little bit to the neuroscience of why that might be
[00:40:42.940 --> 00:40:46.260]   the book was a surprise finalist for the Pulitzer Prize and
[00:40:46.260 --> 00:40:50.020]   not general nonfiction writing losing out only to
[00:40:50.020 --> 00:40:52.060]   Siddhartha's
[00:40:52.060 --> 00:40:57.060]   Mudeji's I think to his book on the gene or maybe the Emperor of All Maladies one of his books
[00:40:57.060 --> 00:41:02.320]   But it was it was like this big success. I went and cataloged the elite
[00:41:02.320 --> 00:41:05.300]   contrarian pushback Dakar
[00:41:06.180 --> 00:41:12.420]   Which there was like right when that right when that book came out we had this sort of similar style pushback
[00:41:12.420 --> 00:41:17.980]   There's review in The Guardian. I called out where they were being very sarcastic
[00:41:17.980 --> 00:41:21.500]   Like well, I'm looking at all the footnotes in cars book
[00:41:21.500 --> 00:41:25.980]   And he doesn't seem to be having that much trouble reading because look at all these books
[00:41:25.980 --> 00:41:28.500]   He's citing and then it was like what we should do is
[00:41:28.500 --> 00:41:33.820]   Chop up the pages in his book and shuffle them around and read them out of order like the Internet is right now
[00:41:33.820 --> 00:41:35.820]   He's honestly that would probably be better
[00:41:35.820 --> 00:41:38.300]   Steven Pinker in The New York Times
[00:41:38.300 --> 00:41:42.980]   Had like a real negative review of it. He's like Twitter is making me a better scientist, you know
[00:41:42.980 --> 00:41:46.620]   And he's like if you're having a problem, it was very quaint you're having a problem
[00:41:46.620 --> 00:41:52.660]   That's on you check Twitter less often. All right, like he was like really dismissive of the book Clay Shirky, you know
[00:41:52.660 --> 00:41:56.140]   Had that same year one of his books
[00:41:56.140 --> 00:42:00.540]   He had this whole series of books in that early 2000s late 90s about the Internet
[00:42:00.540 --> 00:42:04.580]   is this like utopian techno solutionist take on the Internet and Shirky is like
[00:42:04.580 --> 00:42:07.380]   The
[00:42:07.380 --> 00:42:12.980]   Internet is at the core of like the Arab Spring which was happening concurrently with this is bringing democracy to the world
[00:42:12.980 --> 00:42:16.820]   Like this is it's like this utopian force like all this pushback happened the cars book
[00:42:16.820 --> 00:42:20.780]   Then you trace this out. You pull this thread out a little bit longer
[00:42:20.780 --> 00:42:23.420]   by
[00:42:23.420 --> 00:42:24.580]   2014
[00:42:24.580 --> 00:42:27.340]   You have Clay Shirky talking about oh my god
[00:42:27.340 --> 00:42:31.700]   I have to ban phones and laptops from my classroom because my kids can't they can't even
[00:42:31.700 --> 00:42:35.220]   Keep your attention on more than a thought. It's like completely
[00:42:35.220 --> 00:42:43.100]   Tapping their brains the idea that this was like a utopian force for changing the world that had gone away by this point
[00:42:43.100 --> 00:42:47.460]   There was like this almost universal acceptance at that point. Actually, you're right
[00:42:47.460 --> 00:42:54.900]   I'm really distracted. I think this is a problem and what had changed between 2009 and 2014 was the mobile revolution
[00:42:55.340 --> 00:42:59.800]   So it was social media moving on the smartphones and then attention engineering really took off
[00:42:59.800 --> 00:43:04.540]   His attention engineering was not as big of a thing when it was on the web-based browser, right?
[00:43:04.540 --> 00:43:09.140]   But once was on the phone was how do we get people to look at these things and everyone was feeling it?
[00:43:09.140 --> 00:43:15.820]   So there's this contrarian pushback to that idea that then dissipated based on people's lived experience with the phone and then it became kind of
[00:43:15.820 --> 00:43:17.820]   Accepted so it's kind of interesting now
[00:43:17.820 --> 00:43:23.760]   Another ten years after that that we're trying to go back to contrarianism, but it's too late. Everyone is feeling it now
[00:43:24.620 --> 00:43:30.040]   everyone is feeling it there are there other types of things for this type of contrarianism makes sense because again
[00:43:30.040 --> 00:43:35.700]   Typically it is things where it's not you have to be told there's a problem or the problem is narrow, right?
[00:43:35.700 --> 00:43:37.660]   You have to be told
[00:43:37.660 --> 00:43:39.660]   the meat you're eating is
[00:43:39.660 --> 00:43:46.060]   Leading to heart disease like I kind of have to be told that someone has to be looking at the data. Like I can't directly
[00:43:46.060 --> 00:43:48.620]   feel
[00:43:48.620 --> 00:43:50.940]   Arthrosclerosis like growing in my heart while you eat meat
[00:43:50.940 --> 00:43:55.180]   Someone has to kind of like tell that to me and then maybe like someone else could come in and say that's overblown and looking
[00:43:55.180 --> 00:43:57.180]   at the data, but not with
[00:43:57.180 --> 00:44:01.420]   Attention reduction in the digital era because everyone directly and clearly feels it
[00:44:01.420 --> 00:44:05.960]   It's why when for example, you survey teenagers increasingly and this is international
[00:44:05.960 --> 00:44:09.820]   You're increasingly getting these surveys where teenagers saying I really don't like my phone and social media
[00:44:09.820 --> 00:44:12.000]   It's making me anxious and distracted and I hate it
[00:44:12.000 --> 00:44:14.780]   huge super majorities of the
[00:44:14.780 --> 00:44:21.220]   Teenagers who are surveying these surveys are saying that you can't find a single person who works in like an office environment who won't tell you
[00:44:21.220 --> 00:44:27.940]   I hate how distracted I am or I'm struggling to keep my concentration. So I think we're past the point of saying
[00:44:27.940 --> 00:44:30.660]   no, no, there's this is just like a
[00:44:30.660 --> 00:44:35.260]   Small group of people are complaining because people are looking at social media instead of their books. I
[00:44:35.260 --> 00:44:38.660]   I can't flatter myself
[00:44:38.660 --> 00:44:43.700]   Not that many people know who I am most people who will tell you I look at my phone too much
[00:44:43.700 --> 00:44:49.060]   And I feel distracted all the time. Don't read elite people. They don't read me and Daniel in The New Yorker
[00:44:49.060 --> 00:44:52.620]   They don't listen to my pod. They're not in part of some like elite conversation
[00:44:52.620 --> 00:44:57.860]   They were never reading my stuff anyways, but they'll still tell you. Yeah, I'm distracted all the time. Mm-hmm. So I
[00:44:57.860 --> 00:45:02.620]   Don't know. I mean a good article sparks good debate and I think this one did but I didn't agree with this one
[00:45:02.620 --> 00:45:05.500]   I actually have a question about that. So when I checked out the article online
[00:45:05.500 --> 00:45:09.460]   How can you tell if a New York article online is in the magazine?
[00:45:10.780 --> 00:45:17.500]   It'll say they'll put a byline usually at like the bottom. I think it'll say like appeared in the
[00:45:17.500 --> 00:45:23.980]   February bullet whatever issue with the title and it'll give like the the print title. Okay. Yeah, that's usually can tell
[00:45:23.980 --> 00:45:27.780]   All right. We've got next next questions from Alan. I
[00:45:27.780 --> 00:45:33.660]   Personally benefited a lot from mentoring in my professional career career whether formally or informally
[00:45:33.660 --> 00:45:38.500]   I even consider podcasts such as yours some form of coaching or mentoring in your view
[00:45:38.500 --> 00:45:42.880]   Where does mentoring or coaching fit in the professional development of knowledge workers?
[00:45:42.880 --> 00:45:46.860]   I think there should be a lot more coaching and knowledge work, right? I mean
[00:45:46.860 --> 00:45:49.500]   There's a lot of ambiguity
[00:45:49.500 --> 00:45:54.640]   Which means there is a huge inefficiencies that can be
[00:45:54.640 --> 00:45:59.460]   Exploited or taken, you know leverage. I don't say exploited seems negative
[00:45:59.460 --> 00:46:05.240]   But like there's huge inefficiencies where if you're more on the ball, you know, the stuff that matters the techniques that matters
[00:46:05.240 --> 00:46:07.920]   There's huge room for you to grow and succeed
[00:46:08.360 --> 00:46:14.280]   Right different than in an existing field that has like a really clear competitive structure like chess
[00:46:14.280 --> 00:46:20.800]   It's just hard and everyone is like training and more or less the same way and it's just really hard
[00:46:20.800 --> 00:46:24.400]   There's not you can only get better really slowly or whatever in knowledge work
[00:46:24.400 --> 00:46:30.640]   It's such the Wild West of cognitive activity and everyone's like on email all day and all this wasted cognitive resources
[00:46:30.640 --> 00:46:37.160]   There is a lot of benefit to coaching but there's not there's not a ton that happens. I think there should be more
[00:46:37.880 --> 00:46:40.040]   So the way I see it and there is some that exist
[00:46:40.040 --> 00:46:42.620]   so let me let me kind of walk through this the way I see it is there's sort of a
[00:46:42.620 --> 00:46:44.720]   hierarchy of
[00:46:44.720 --> 00:46:51.280]   Coaches from like as you move up the levels here things get more effective and more expensive and more rare
[00:46:51.280 --> 00:46:54.600]   All right. So like the base level of knowledge. We're coaching as it exists today
[00:46:54.600 --> 00:46:57.120]   I think of things like this podcaster books
[00:46:57.120 --> 00:47:00.160]   So it's not actually someone talking one-on-one to you
[00:47:00.160 --> 00:47:06.760]   But is giving specific advice about I think about how this world works and here's how it works and here's what matters and here's what?
[00:47:06.760 --> 00:47:10.200]   Doesn't so like this podcast as we talked about the beginning of today's episode
[00:47:10.200 --> 00:47:13.600]   one of the three big issues we talked about under the umbrella of
[00:47:13.600 --> 00:47:20.520]   Conflicts and mismatches with the modern digital environment is work in the age of digital communication and technology, right?
[00:47:20.520 --> 00:47:27.360]   So like this is a form of coaching so you should start at least at this level read books. Listen to podcast
[00:47:27.360 --> 00:47:33.280]   the next level and this is kind of new that this exists is this idea of
[00:47:34.040 --> 00:47:39.040]   It's like one-on-one coaching but the price is reduced from high-end one-on-one coaching because it's delivered through the internet
[00:47:39.040 --> 00:47:41.040]   So this is like I've been talking about done daily
[00:47:41.040 --> 00:47:44.640]   Because I know this is the guys over at my body tutor who longtime friends of the show
[00:47:44.640 --> 00:47:50.500]   They have this service done daily comm where you have a coach who checks in with you daily
[00:47:50.500 --> 00:47:55.900]   They use my sort of methodologies roughly speaking a multi-scale planning and full capture
[00:47:55.900 --> 00:47:59.600]   But you're checking in with a coach to help you on those plans and give you some accountability each day
[00:48:00.600 --> 00:48:04.720]   That is this sort of next level up now. You are you actually have a coach
[00:48:04.720 --> 00:48:11.540]   But because it's delivered online, it's like cheaper than traditionally what it takes to have like a dedicated coach
[00:48:11.540 --> 00:48:12.400]   All right
[00:48:12.400 --> 00:48:16.320]   So that's kind of like a new thing and I'm kind of excited about that space because I think it's more accessible
[00:48:16.320 --> 00:48:18.680]   the level above that is
[00:48:18.680 --> 00:48:22.380]   There are a lot of people out there a lot of knowledge or don't know this
[00:48:22.380 --> 00:48:27.700]   there's a lot of people out there that have dedicated coaches that they like weekly have sessions with that are
[00:48:28.080 --> 00:48:31.000]   Business coaches and they're just helping you
[00:48:31.000 --> 00:48:36.260]   Be better at your job or be better in your business like this is very common
[00:48:36.260 --> 00:48:40.140]   It's like friend of the show Brad Stolberg like he does this. He's like he's like a very well-known
[00:48:40.140 --> 00:48:43.620]   Executive coach and
[00:48:43.620 --> 00:48:48.500]   Don't try to sign up because I think his waiting list is you know a mile long
[00:48:48.500 --> 00:48:56.000]   Very popular, but if you're one of his clients once a week, you're talking to him and you're getting like expert level
[00:48:56.000 --> 00:49:00.180]   So that's like the next level up because Brad's like a very well-known thinker in the space or whatever
[00:49:00.180 --> 00:49:03.080]   so that's going to be more expensive than something like done daily and
[00:49:03.080 --> 00:49:09.340]   Then you have at the final level is like the high-end executive coaches where you know
[00:49:09.340 --> 00:49:12.580]   I have a fortune 500 company. I'm paying my CEO
[00:49:12.580 --> 00:49:18.140]   Fifty million dollars a year and salary and stock options. You better believe I want that person
[00:49:18.140 --> 00:49:22.460]   Operate on full cylinders and we're gonna have these high-end executive coaches are you know?
[00:49:23.700 --> 00:49:28.520]   100 $20,000 a year, you know that are gonna but if you're paying 50 million dollars for a CEO like yeah
[00:49:28.520 --> 00:49:33.880]   I want someone who all they do is think about how do you succeed running a company so that we have no inefficiencies there?
[00:49:33.880 --> 00:49:35.920]   You don't have to learn these things from scratch
[00:49:35.920 --> 00:49:39.500]   There's even like this super high level
[00:49:39.500 --> 00:49:44.240]   Super high level executive coach like Tony Robbins used to coach Bill Clinton. Really? Yeah
[00:49:44.240 --> 00:49:50.200]   So there used to be like these super high level, you know, like money is no object. I think all of that is great and
[00:49:52.040 --> 00:49:56.120]   More people should avail themselves of this coaching pyramid
[00:49:56.120 --> 00:50:02.560]   You know, I think everyone in my audience who likes my digital productivity advice like you're already on this pyramid
[00:50:02.560 --> 00:50:08.980]   You're getting coaching and if you know people who are talented but are like overwhelmed or struggling in their job
[00:50:08.980 --> 00:50:14.100]   Like get them on the bottom of this period then where things get interesting is where more people move up and say, okay
[00:50:14.100 --> 00:50:16.100]   I'm now in a position where
[00:50:16.940 --> 00:50:24.240]   My business success is on the line or I I just got a promotion. That is, you know a six-figure promotion. I
[00:50:24.240 --> 00:50:26.540]   Really got to succeed here
[00:50:26.540 --> 00:50:30.820]   I'm gonna move up a level and maybe I'm gonna go to like the done daily level and
[00:50:30.820 --> 00:50:37.060]   Have like an online coach to make sure I'm just like keeping things well organized because I do not want to let this slip up
[00:50:37.060 --> 00:50:41.720]   This is like a six-figure proposition or maybe I'm gonna go up a level over that and hire like a Brad Stolberg in my life
[00:50:42.260 --> 00:50:48.460]   Because like this is the difference between this multi-million dollar company succeeding or going bankrupt. This is the difference between
[00:50:48.460 --> 00:50:55.180]   Me keeping this new like $350,000 a year job or like having my salary cut in half
[00:50:55.180 --> 00:50:58.800]   Yeah, I'm gonna pay the 500 or the 2,000 or whatever it is a month to keep that
[00:50:58.800 --> 00:51:02.580]   so this is something that we should think about more because knowledge work is
[00:51:02.580 --> 00:51:08.020]   complicated and ambiguous which means there's a lot of opportunity for you to make big strides and
[00:51:08.860 --> 00:51:12.420]   Separate yourself from the pack if you have wisdom and guidance
[00:51:12.420 --> 00:51:18.420]   But also without that wisdom and guidance you can drown. So I'm a big believer in coaching
[00:51:18.420 --> 00:51:22.160]   There's a cool article that Sanjay not Sanjay Gupta. This was
[00:51:22.160 --> 00:51:26.260]   Who wrote the he's another New Yorker writer
[00:51:26.260 --> 00:51:29.580]   He wrote the checklist manifesto
[00:51:29.580 --> 00:51:32.580]   I'll look it up. Do you have a coach? I
[00:51:32.580 --> 00:51:37.860]   Yeah, I do. I have a coach who specializes in the business side of creative work
[00:51:38.380 --> 00:51:40.180]   She helps me with
[00:51:40.180 --> 00:51:45.480]   Thinking through like deep media and the stuff we do and how to try to make that fit a little go on
[00:51:45.480 --> 00:51:49.100]   Oh, I told one day man. I can't believe I forgot a tool's name another New Yorker writer
[00:51:49.100 --> 00:51:52.420]   He had this cool, New Yorker piece years ago about in surgery
[00:51:52.420 --> 00:51:57.140]   Then discovering like for doctors like having a coach
[00:51:57.140 --> 00:52:04.060]   That's like I'm gonna coach you like on this particular procedure makes people much better. So anyways, I'm a big I'm a big believer in coach
[00:52:04.060 --> 00:52:08.100]   And coaching. Yeah, so I got a coach that helps me once a month
[00:52:09.060 --> 00:52:10.900]   It's like all she does
[00:52:10.900 --> 00:52:14.900]   it'll be for example, like a movie director she works with right or
[00:52:14.900 --> 00:52:19.340]   Screenwriters like creatives who have
[00:52:19.340 --> 00:52:22.820]   These like organizational business challenges as well
[00:52:22.820 --> 00:52:25.420]   Like I have to figure out how to not just do the creative work
[00:52:25.420 --> 00:52:28.220]   But like keep the business around it or how do I make this fit?
[00:52:28.220 --> 00:52:30.980]   This thing's taking up too much time. Can I cut this off?
[00:52:30.980 --> 00:52:35.260]   And so I'm always running scenarios by her trying to figure out how do I get from seven jobs?
[00:52:35.860 --> 00:52:41.180]   to less and like what are the right places to cut and what's working and what's not is a sounding board and to me that's
[00:52:41.180 --> 00:52:45.780]   Like absolutely worth the money. Mm-hmm because like this is this is a big business. There's like a lot on the line
[00:52:45.780 --> 00:52:50.220]   There's a lot that matters, you know, and this is like a line item. It's not in the scheme of things
[00:52:50.220 --> 00:52:52.060]   Not that big of an expense
[00:52:52.060 --> 00:52:57.360]   All right. What do we got next? We have our corner slow productivity corner. Let's hear that theme music
[00:53:04.260 --> 00:53:08.300]   So once a week we have a question that relates to my last book I
[00:53:08.300 --> 00:53:15.260]   Shouldn't say last book people think I'm done. Right most recent my most recent book slow productivity the lost art of accomplishment
[00:53:15.260 --> 00:53:18.320]   Without burnout. I always get that wrong these days
[00:53:18.320 --> 00:53:22.740]   So we do a question about that each week and we call it a slow productivity corner. All right
[00:53:22.740 --> 00:53:30.620]   What's our slow productivity corner question of the week? It's from Sterling but real quick some fans have been requesting a for the year-end
[00:53:31.780 --> 00:53:37.660]   Anniversary a slow productivity themed episode. Can we play the music for every question?
[00:53:37.660 --> 00:53:41.460]   If so, I'm on board
[00:53:41.460 --> 00:53:48.780]   Hi, Sterling says an episode 336. You mentioned that starting up companies isn't compatible with slow productivity
[00:53:48.780 --> 00:53:53.220]   I was wondering could it be possible to reconcile the two or is it just not feasible?
[00:53:53.220 --> 00:53:59.620]   I tend to think of Paul Jarvis and his company of one model where a more minimalist approach can be successful
[00:53:59.860 --> 00:54:06.500]   Well, we got to get Sterling a copy of the book because I talk in depth about Paul Jarvis in slow productivity
[00:54:06.500 --> 00:54:10.820]   So for those who don't know who haven't read the book or heard me talk about him before
[00:54:10.820 --> 00:54:15.680]   Paul Jarvis wrote this cool book called company of one and his whole premise
[00:54:15.680 --> 00:54:20.380]   Was if you build like a company around your skill
[00:54:20.380 --> 00:54:26.820]   So actually this can be an interesting comparison to our Brandon Sanderson discussion from before because Brandon did not read this book
[00:54:26.820 --> 00:54:30.780]   that's for sure he says if you've kind of built the business around your skill like Paul was a
[00:54:30.780 --> 00:54:34.340]   web developer programmer as you get better
[00:54:34.340 --> 00:54:42.740]   The the pressures in the world of business will be to grow. There's a demand for your services. You only have so much time
[00:54:42.740 --> 00:54:47.720]   Hire more people and grow because if you can grow a business of a certain size
[00:54:47.720 --> 00:54:51.780]   Maybe 10-15 years down the line you can sell that business and get a nice payday out of it
[00:54:52.940 --> 00:54:57.980]   Jarvis's company of one model is no. No, no, if you're getting better and there's demand for your work
[00:54:57.980 --> 00:55:00.500]   Raise your prices
[00:55:00.500 --> 00:55:02.260]   Don't hire more people
[00:55:02.260 --> 00:55:08.420]   just become more expensive raise your prices and double your income or as he would recommend raise your prices and
[00:55:08.420 --> 00:55:12.140]   Have your working time and he's saying that actually could be
[00:55:12.140 --> 00:55:16.940]   Directly more valuable than this like potential payday 15 years from now
[00:55:16.940 --> 00:55:20.220]   Like this was his model of like I'm becoming really good at web development
[00:55:20.220 --> 00:55:24.740]   so why don't I double my prices and cut my hours in half and only work a couple days a week and
[00:55:24.740 --> 00:55:30.060]   He moved to Vancouver Island over by Tolfino. His wife was a surfer. There's a surf break there. They have greenhouses
[00:55:30.060 --> 00:55:32.060]   I talked about in the book. It's all sort of
[00:55:32.060 --> 00:55:37.740]   Rural and pastoral and his life is pretty cool because that's what he wanted to do
[00:55:37.740 --> 00:55:42.740]   So he said, okay, you can cash in your skill to make your life more flexible or to try to make more money down the line
[00:55:42.740 --> 00:55:45.100]   That's the company of one model
[00:55:45.220 --> 00:55:48.740]   This is a model that I then extrapolate in slow productivity, right?
[00:55:48.740 --> 00:55:54.180]   Because it comes in the chapter on the principle of obsessing over quality
[00:55:54.180 --> 00:55:59.860]   so there's three principles of slow productivity do fewer things work at a natural pace and
[00:55:59.860 --> 00:56:05.620]   Obsess over quality. So in that obsess over quality chapter, I was like, okay. Why is this important?
[00:56:05.620 --> 00:56:07.940]   Why is important to obsess over quality?
[00:56:07.940 --> 00:56:12.500]   And I said there's two effects that happen when you obsess over the quality of doing the things you do best
[00:56:13.780 --> 00:56:18.180]   The first thing that's going to happen if you obsess over quality busyness is going to seem superfluous
[00:56:18.180 --> 00:56:24.100]   The world of pseudo productivity will become increasingly intolerable when what you care about is doing something really well
[00:56:24.100 --> 00:56:27.020]   you begin to look at your inbox with
[00:56:27.020 --> 00:56:33.780]   Wrath in your eyes you begin to look at like a busy calendar full of zoom meetings as a tragic waste
[00:56:33.780 --> 00:56:38.700]   So the obsession over quality makes all the stuff I talked about in the first two principles
[00:56:39.580 --> 00:56:45.100]   Seem logical inevitable, like I don't need that's not how I'm about I'm not valuable through activity
[00:56:45.100 --> 00:56:49.980]   I'm valuable through doing this and this is getting in the way of this the second thing that made obsessing over quality
[00:56:49.980 --> 00:56:54.500]   Useful though I argue is that it then can give you
[00:56:54.500 --> 00:56:59.180]   The leverage required to actually start removing that other stuff from your life
[00:56:59.180 --> 00:57:05.860]   So it makes you begin to feel dismayed towards busyness while simultaneously giving you the leverage needed to actually reduce busyness
[00:57:05.860 --> 00:57:10.500]   And that's where I talked about Paul Jarvis that as you get better at something you get more options
[00:57:10.500 --> 00:57:16.100]   You can say I'm just going to do this because it's valuable to you. I don't want to do these other things anymore
[00:57:16.100 --> 00:57:20.220]   You can double your rates and reduce your hours in the big organization
[00:57:20.220 --> 00:57:25.100]   You can say I want to trade accessibility for accountability hold me accountable. I'm going to produce this stuff
[00:57:25.100 --> 00:57:27.380]   Look at the dollars. I bring in the door, but I'm not doing meetings
[00:57:27.380 --> 00:57:32.700]   And like all right, we'll make that fair trade so as you get good you get more leverage
[00:57:33.940 --> 00:57:38.700]   To actually simplify your life at the same time that getting good makes you want to simplify your life. I
[00:57:38.700 --> 00:57:41.620]   Talked to someone at a tech company not long ago
[00:57:41.620 --> 00:57:45.340]   Maybe I mentioned this in the book or he said yeah, we drown in meetings
[00:57:45.340 --> 00:57:47.540]   Except the sales staff
[00:57:47.540 --> 00:57:49.460]   They're exempt from meetings
[00:57:49.460 --> 00:57:56.060]   Is the sales staff has a big number that follows each of them around I brought this much money into the company and the sales
[00:57:56.060 --> 00:57:57.660]   staff is able to say
[00:57:57.660 --> 00:57:59.660]   This is what is
[00:58:00.060 --> 00:58:05.300]   Unambiguously valuable to our company just hold me accountable to that if I'm not bringing the money then you can fire me
[00:58:05.300 --> 00:58:09.700]   But if I am to let me do that and these meetings bring that number down so you guys have your meetings
[00:58:09.700 --> 00:58:14.660]   I'm gonna go bring in the money and the tech company allows them to do that because it brings in a lot more money
[00:58:14.660 --> 00:58:20.060]   If they have these people on zoom calls and teams meetings on slack all day those numbers would go down
[00:58:20.060 --> 00:58:22.060]   And so that's more important
[00:58:22.060 --> 00:58:24.180]   So as you obsess over quality
[00:58:24.180 --> 00:58:26.580]   You gain more freedom
[00:58:27.220 --> 00:58:30.700]   To simplify or slow down your life. So yes Paul Jarvis's book is great
[00:58:30.700 --> 00:58:36.820]   I recommend company of one and I recommend that general model, you know as you get better you could grow
[00:58:36.820 --> 00:58:39.340]   or you could slow and
[00:58:39.340 --> 00:58:41.420]   Sometimes the slow option is going to be the good one
[00:58:41.420 --> 00:58:46.680]   We should have Paul on the show at some point. Yeah, we can find him in the woods up there
[00:58:46.680 --> 00:58:49.420]   the woods up in
[00:58:49.420 --> 00:58:52.000]   so his book was edited by the editor who
[00:58:53.220 --> 00:58:56.140]   Edited so good. They can't ignore you and who?
[00:58:56.140 --> 00:58:59.340]   Acquired deep work. Okay same editor
[00:58:59.340 --> 00:59:03.500]   All right. What do we got next? We have a call. Oh, let's hear this
[00:59:03.500 --> 00:59:13.540]   Hey cow, my name is Antonio and I'm calling from my reading spot up in Griffith Park in the hills above Los Angeles I
[00:59:13.540 --> 00:59:21.220]   Have a 15 year old son and I did not give him a cell phone until ninth grade and the cell phone that he got
[00:59:21.220 --> 00:59:27.540]   Is it is a dumb phone where he can text and get music and browse maps, but he can't do anything else on it
[00:59:27.540 --> 00:59:34.740]   It has been great. And it has also ruined his life. He has said all of his friends have iPhones
[00:59:34.740 --> 00:59:38.220]   I feel like it's part of a fashion accessory as well as a device and
[00:59:38.220 --> 00:59:43.500]   He is definitely gonna get one when he's 16, and I'm wondering do you have any advice for this transition?
[00:59:43.500 --> 00:59:46.180]   For a kid whose life I've ruined
[00:59:46.860 --> 00:59:50.900]   To when he gets his cell phone for the first time a smartphone for the first time
[00:59:50.900 --> 00:59:57.660]   And I'm also wondering how you have navigated that with your own children as they get into I think they're probably middle school by now
[00:59:57.660 --> 01:00:03.360]   Any advice you or Jesse skeleton have for me and my son would be greatly appreciated
[01:00:03.360 --> 01:00:07.300]   Well, I think Jesse skeleton would just make
[01:00:07.300 --> 01:00:09.860]   bones puns
[01:00:09.860 --> 01:00:11.980]   If you were to ask Jesse skeleton for your advice
[01:00:11.980 --> 01:00:14.860]   so he would say
[01:00:16.100 --> 01:00:18.220]   16 is the right age for a phone
[01:00:18.220 --> 01:00:21.660]   There's no make no bones about it
[01:00:21.660 --> 01:00:26.940]   Then he would just stare at the camera. So we should be lucky that Jesse skeleton's not here
[01:00:26.940 --> 01:00:29.180]   Alright, so first of all, you're doing the right thing
[01:00:29.180 --> 01:00:31.860]   the the research
[01:00:31.860 --> 01:00:35.740]   Indicates that a I call it the John Height model. This is what height proposes
[01:00:35.740 --> 01:00:38.700]   but the height model is
[01:00:38.700 --> 01:00:40.620]   No smartphone till high school
[01:00:40.620 --> 01:00:45.280]   No social media till 16 those are often separated by a little bit like you get the high school before that
[01:00:45.280 --> 01:00:47.280]   So so smartphone
[01:00:47.280 --> 01:00:50.200]   Wait till high school social media wait till 16
[01:00:50.200 --> 01:00:54.580]   Really what you're trying to go for here is to make sure that they get through certain developmental
[01:00:54.580 --> 01:01:01.900]   Milestones before they get this big influence of attention economy apps on their social development and their attention
[01:01:01.900 --> 01:01:06.540]   So if you're waiting till 16, this is going to be like a post puberty most likely also post
[01:01:06.540 --> 01:01:09.340]   social identity formation and
[01:01:09.580 --> 01:01:14.120]   It's just going to have much less of an effect than getting this at like 12 or 13
[01:01:14.120 --> 01:01:18.800]   And I think the research is pretty clear on that. He curses it now. He'll thank you in a few years
[01:01:18.800 --> 01:01:24.440]   I mean I hear this again and again from my undergrads the undergrads. I work with now whose parents did something similar
[01:01:24.440 --> 01:01:27.680]   They thank me now in college separated from a few years like man
[01:01:27.680 --> 01:01:31.020]   I'm so glad I didn't have to get stuck in that world and tell I was X years old
[01:01:31.020 --> 01:01:32.800]   So he will thank you later
[01:01:32.800 --> 01:01:38.740]   even if he's cursing now big picture the solution of this is just a collective action problem and I really feel like we're at
[01:01:38.740 --> 01:01:44.240]   The cusp of this change. We're really at this cusp of like your situation now where it feels
[01:01:44.240 --> 01:01:46.480]   unusual
[01:01:46.480 --> 01:01:51.480]   the decision you're making among the peers of your kid to the place where that's going to be a
[01:01:51.480 --> 01:01:58.880]   Common behavior if not, the majority like the plurality of behavior that like yeah a large percent of the kids at your school
[01:01:58.880 --> 01:02:02.240]   Are getting a phone in high school social me at 16
[01:02:02.240 --> 01:02:07.760]   I mean this this is just starting to become more culturally accepted once it's more widespread
[01:02:08.440 --> 01:02:12.840]   then you don't have the collective action problem and it's not going to be as much of a a
[01:02:12.840 --> 01:02:18.120]   Pull or lift from you as the parent if you're a parent right now and your kids are younger
[01:02:18.120 --> 01:02:22.120]   But you're thinking they're coming up to this age now or they're in an age where some kids are getting this
[01:02:22.120 --> 01:02:26.040]   Try to find if people locally are doing something like the wait to eight pledge
[01:02:26.040 --> 01:02:29.480]   Which says we will wait until after eighth grade to give phones to our kids
[01:02:29.480 --> 01:02:32.320]   It helps if you have a group of people and you can say to your kid
[01:02:32.320 --> 01:02:36.600]   I signed a pledge and I'm one of 20 families that has made the same pledge and that's what we're doing
[01:02:36.600 --> 01:02:43.000]   So no, you can't just argue like I made this situation individually and you're going to convince me. It's wrong. You're arguing against this whole
[01:02:43.000 --> 01:02:49.600]   Community of people who've made a similar pledge in terms of my own kids. Yeah, my oldest is 12
[01:02:49.600 --> 01:02:57.640]   so, you know, he is as likely to get a smartphone this year as he is to get a
[01:02:57.640 --> 01:03:04.680]   Commercial grade crossbow. I would say those are about equally likely. He is as likely to be
[01:03:05.600 --> 01:03:13.880]   Chatting on his Android by the end of this school year as he is to be driving a Kawasaki Ninja motorcycle
[01:03:13.880 --> 01:03:18.320]   He's going to get a phone in high school. He'll get social media at 16
[01:03:18.320 --> 01:03:23.440]   And again, that's going to become more and more standard. It is becoming more and more standard and
[01:03:23.440 --> 01:03:28.320]   Your kid I'm telling you he's going to thank you in a couple years. So, you know what actually that was great
[01:03:28.320 --> 01:03:30.320]   I'm kind of glad you did that
[01:03:30.320 --> 01:03:32.840]   All right, what we got here Oh case study
[01:03:33.640 --> 01:03:38.680]   Where people write in the Jesse at Cal Newport comm with their own stories of putting the type of advice we talked about on the show
[01:03:38.680 --> 01:03:40.680]   into action in their own life
[01:03:40.680 --> 01:03:43.000]   Today's case study comes from Kyle
[01:03:43.000 --> 01:03:46.120]   Kyle says I'm a master student in biology
[01:03:46.120 --> 01:03:52.380]   Studying how monarch butterflies respond to strong winds during their over wintering period
[01:03:52.380 --> 01:03:57.020]   My research involves analyzing thousands of butterfly photos taken at regular intervals
[01:03:57.020 --> 01:04:00.280]   paired with wind condition data
[01:04:01.320 --> 01:04:05.440]   Boy, that's that's funny when people think about being like a graduate student biology
[01:04:05.440 --> 01:04:10.840]   They think about like Alan Grant in Jurassic Park like out in the Badlands digging up
[01:04:10.840 --> 01:04:14.280]   Velociraptors and now you're looking at pictures of butterflies all day long
[01:04:14.280 --> 01:04:16.640]   Alright back to the story
[01:04:16.640 --> 01:04:22.320]   I've reached a stage where I need to convert these photos into quantitative data to draw meaningful conclusions about their behavior
[01:04:22.320 --> 01:04:27.720]   After an unsuccessful search for both free and paid software to process my massive image collection
[01:04:27.720 --> 01:04:30.360]   I decided to take on the challenge of building my own tool
[01:04:31.040 --> 01:04:38.440]   With some background in Python and our programming and a passion for AI. I discovered coding tools like windsurf cursor and
[01:04:38.440 --> 01:04:42.600]   Klein for VS code that go beyond simple chatbots
[01:04:42.600 --> 01:04:47.580]   These tools can read your entire code base make targeted edits and help create new files when needed
[01:04:47.580 --> 01:04:53.120]   Using just natural language prompting. I was able to build exactly what I needed in about a week
[01:04:53.120 --> 01:04:59.600]   It feels like I've created a custom woodworking jig a specialized tool that makes the real work more efficient and elegant
[01:04:59.600 --> 01:05:05.880]   I was inspired to share this story after hearing your recent episode about AI you predicted that non computer scientists
[01:05:05.880 --> 01:05:10.480]   Would soon have expanded abilities to create software and my experience confirms this
[01:05:10.480 --> 01:05:14.000]   While I'm more technically inclined than many of my biology peers
[01:05:14.000 --> 01:05:15.680]   I'm not a software engineer
[01:05:15.680 --> 01:05:21.900]   my image labeling tool feels like a glimpse into the future AI has dramatically boosted my confidence to tackle technical challenges and
[01:05:21.900 --> 01:05:28.600]   I expect this effect will only grow stronger. I have attached a screenshot of the software to give you a sense of what I built
[01:05:29.520 --> 01:05:31.600]   Well, let's take a look at this. Alright, so for those who are
[01:05:31.600 --> 01:05:35.720]   Watching instead of just listening. We'll bring this up on the screen here
[01:05:35.720 --> 01:05:38.280]   That's interesting
[01:05:38.280 --> 01:05:41.560]   Yeah, that's better. I'll see that there it is full screen for those who are watching. Okay, it's cool
[01:05:41.560 --> 01:05:47.820]   So there's a picture of trees and black and white and then some of the it's gridded and some of the squares are colored
[01:05:47.820 --> 01:05:50.400]   God, I see I didn't find butterflies in there
[01:05:50.400 --> 01:05:56.520]   Yeah, Wow, or his program is there's that's like a non-trivial piece of software
[01:05:57.160 --> 01:06:01.080]   That he produced without coding ability. Yeah, that is this is my
[01:06:01.080 --> 01:06:03.760]   my argument about AI is
[01:06:03.760 --> 01:06:07.080]   There is
[01:06:07.080 --> 01:06:13.280]   One strain of discourse that's it's hype oriented in the sense of oh my god. Oh my god. Oh my god
[01:06:13.280 --> 01:06:15.240]   Like look at this thing
[01:06:15.240 --> 01:06:21.840]   This massive model is going to like do everything for you and make 10% of the workforce obsolete by tomorrow
[01:06:21.840 --> 01:06:24.540]   And it's a good attention-grabbing headline
[01:06:25.680 --> 01:06:32.200]   Every prediction that has been made from that strain of discourse though has been like slow or not to come to fruition or non-existent
[01:06:32.200 --> 01:06:36.960]   At all. I mean right from the beginning of chat GPT. It was like we're months away from X
[01:06:36.960 --> 01:06:39.280]   We're months away from Y and like the X and Y
[01:06:39.280 --> 01:06:45.660]   Impacts didn't happen. So there's this weird gap that's happening in AI development where AI
[01:06:45.660 --> 01:06:50.600]   Capabilities keeps hitting every every optimistic prediction that people make it's hitting it
[01:06:50.600 --> 01:06:53.520]   Well soon, it'll be able to do this hits it, but it can't do this
[01:06:53.520 --> 01:06:56.600]   But it will be soon hits it but the predictions about impacts
[01:06:56.600 --> 01:07:02.040]   Have not been panning out. It's these jobs are all going to go away. Have it
[01:07:02.040 --> 01:07:06.080]   Homework apocalypse in the homework as we know it not really the case
[01:07:06.080 --> 01:07:10.880]   It's going to make it obsolete to teach like intro computer
[01:07:10.880 --> 01:07:16.480]   Like so these type of impact product predictions those have been way less accurate than the capability
[01:07:16.480 --> 01:07:20.720]   so there's a a gap between AI capability and AI impact and
[01:07:21.040 --> 01:07:24.720]   the reason is like my argument about this is because there is a
[01:07:24.720 --> 01:07:28.060]   time consuming complicated step that actually
[01:07:28.060 --> 01:07:30.840]   bridges this gap between
[01:07:30.840 --> 01:07:34.240]   Capabilities and impact which is the product market fit
[01:07:34.240 --> 01:07:37.320]   actually developing the tools
[01:07:37.320 --> 01:07:38.880]   that work
[01:07:38.880 --> 01:07:43.720]   That actually solve a real problem for a real group of people and this is sort of painstaking and distributed
[01:07:43.720 --> 01:07:46.640]   So you have a couple big companies building massive models
[01:07:47.120 --> 01:07:52.200]   but then you have to have a lot of companies trying to build these tools that use them that are much more specialized and
[01:07:52.200 --> 01:07:54.440]   90% of them are going to fail and
[01:07:54.440 --> 01:07:59.200]   10% are going to work and 1% is going to catch us off guard and be a killer app
[01:07:59.200 --> 01:08:03.920]   Like there's gonna be that 1% that is the email to AI world and suddenly it spreads like really far
[01:08:03.920 --> 01:08:08.400]   but that takes time because you have to spin up companies and build products and adjust the products and get
[01:08:08.400 --> 01:08:14.320]   Market feedback and then try to spread that product through the market the hope of companies like open AI was that?
[01:08:14.640 --> 01:08:20.160]   That their their model with just a raw chat interface would be enough to have high impact, but it's not
[01:08:20.160 --> 01:08:24.200]   It's the type of thing. We're seeing here where Kyle
[01:08:24.200 --> 01:08:28.760]   Was able to build a custom butterfly tool and he otherwise wouldn't be able to do it
[01:08:28.760 --> 01:08:34.840]   Like it's these type of impacts and he was using tools that are built for VS codes over Visual Studio
[01:08:34.840 --> 01:08:38.540]   These were bespoke programming related tools built on the big models
[01:08:38.540 --> 01:08:41.860]   That's what it actually is going to take to get the impact and that just takes more time
[01:08:42.080 --> 01:08:47.960]   so the impact is coming from AI, but it's not going to be delivered through a single tool and
[01:08:47.960 --> 01:08:51.760]   It's going to be the aggregation in my opinion
[01:08:51.760 --> 01:08:57.440]   It's going to be the aggregation of many dozens of much more narrow impacts and over time that's going to add up
[01:08:57.440 --> 01:09:00.320]   It was similar to the Internet that there was like all of these
[01:09:00.320 --> 01:09:06.360]   Little things and innovations to begin to add it up. These companies are doing this those companies are doing this over here
[01:09:06.360 --> 01:09:09.320]   They're doing this and all that sort of added up until you look back and said wow
[01:09:09.480 --> 01:09:13.720]   The way like our economy executes has transformed pretty fundamentally
[01:09:13.720 --> 01:09:16.320]   but it was a
[01:09:16.320 --> 01:09:21.160]   Hundred different more niche products and applications that went and spread that made that happen
[01:09:21.160 --> 01:09:25.160]   It wasn't just here's Netflix or here's Netscape and the world was changed
[01:09:25.160 --> 01:09:31.240]   That's what I think is happening here. And one of the the the form factor of the tools. I think we're going to see first having
[01:09:31.240 --> 01:09:38.040]   Notable impacts over niches is like what Kyle talked about. I've talked about this in some talks
[01:09:38.040 --> 01:09:42.160]   I've been giving recently and on the show that that one of the early places. We're gonna see impact is
[01:09:42.160 --> 01:09:48.160]   Raising the capabilities within specific software packages of the average user
[01:09:48.160 --> 01:09:55.000]   So now like the average user of a software can get their skill ability with that software closer to like an expert level
[01:09:55.000 --> 01:10:01.080]   Without actually having to go through the long cycle training and becoming an expert that's going to unlock a lot of productivity
[01:10:01.080 --> 01:10:04.640]   Right like an expert in Microsoft Excel
[01:10:05.120 --> 01:10:09.120]   Can do a lot more with that than I can if you give me a tool
[01:10:09.120 --> 01:10:14.440]   That's AI natural language base that allows me to approximate a lot of what an expert can do
[01:10:14.440 --> 01:10:19.920]   I'm unlocking a lot of productivity and you multiply that across lots of people using lots of tools
[01:10:19.920 --> 01:10:21.280]   This is going to be the place
[01:10:21.280 --> 01:10:27.480]   I think at first we're gonna see the the productivity gains much more so than here's a robot that is going to take over these
[01:10:27.480 --> 01:10:29.160]   people's desks
[01:10:29.160 --> 01:10:34.960]   Coding is one of the big places I hear from more and more people who are able to build bespoke useful applications
[01:10:34.960 --> 01:10:37.480]   You couldn't release this thing. I'm sure it's buggy and
[01:10:37.480 --> 01:10:45.120]   The options are limited and it's probably not that elegant but building bespoke applications for things you need to do
[01:10:45.120 --> 01:10:51.000]   Like that is an example of where we're gonna get this like initial productivity boost from AI. So yeah, I think it's a good example
[01:10:51.000 --> 01:10:56.040]   I'm thinking about doing an in-depth episode Jesse with a AI expert do it
[01:10:56.040 --> 01:11:00.880]   I like I don't I guess our audience cares about this. Yeah on YouTube
[01:11:01.360 --> 01:11:07.920]   Well, I don't bonus. Anyway, that's bonus. Anyways YouTube. They do not like AI content. Really? Yeah, or when we talk AI
[01:11:07.920 --> 01:11:10.400]   It gets destroyed
[01:11:10.400 --> 01:11:16.560]   No one cares because all the YouTube AI content is like the Terminator is literally at your house right now
[01:11:16.560 --> 01:11:18.880]   Like it is we here is how?
[01:11:18.880 --> 01:11:23.200]   You can protect yourself from the Terminator that is at your house right now
[01:11:23.200 --> 01:11:26.380]   It is about to start shooting through the windows
[01:11:26.680 --> 01:11:33.140]   Here is how to use the mattress as a bulletproof shield, but the Terminator was back in the 90s as way before you I well
[01:11:33.140 --> 01:11:38.940]   Yes, but he traveled back in time. It took place. He used a neural link to Skynet neural link chip
[01:11:38.940 --> 01:11:41.700]   remember Terminator 2 they they had to go and
[01:11:41.700 --> 01:11:46.800]   Find the chip and destroy it before they go. Yeah, but that's like the content right now
[01:11:46.800 --> 01:11:50.680]   you can't compete with that on YouTube if I'm like, excuse me, but um
[01:11:51.200 --> 01:11:56.440]   There are Excel macro features that you will now have access to in your data
[01:11:56.440 --> 01:12:01.320]   analysis if you use AI and that's going to give you a 15% bump in your
[01:12:01.320 --> 01:12:03.980]   analysis productivity and over here
[01:12:03.980 --> 01:12:10.580]   You've got some like Jack guy in his cold plunge like the Terminator is coming for you now
[01:12:10.580 --> 01:12:13.320]   How do you do jiu-jitsu?
[01:12:13.320 --> 01:12:15.960]   against the AI power terminators
[01:12:16.560 --> 01:12:22.080]   Stay tuned can't compete with that on YouTube. But I guess our podcast listeners care, I guess
[01:12:22.080 --> 01:12:27.880]   Anyways, there's someone in mind a specific well-known expert that I that wants to come to show I want to come to show
[01:12:27.880 --> 01:12:33.520]   So we'll work that out. All right, so stay tuned make him sit in a cold place in a cold plunge and we're gonna flex I
[01:12:33.520 --> 01:12:39.560]   Don't know what else people talk about on and we're gonna how do you bow hunt the AI?
[01:12:40.560 --> 01:12:46.280]   Terminator how to use your bow hunt arrow and drive a side track from your cyber truck
[01:12:46.280 --> 01:12:50.880]   The AI Terminator can't puncture the bulletproof glass on your cyber truck
[01:12:50.880 --> 01:12:54.080]   We could have so many more viewers Jesse. All right
[01:12:54.080 --> 01:12:59.200]   Let's get to our we have a tech corner coming up speaking of tech. But first I want to talk about another sponsor
[01:12:59.200 --> 01:13:02.960]   one of our oldest sponsors of this show is
[01:13:02.960 --> 01:13:05.560]   our friends at
[01:13:05.600 --> 01:13:12.320]   Grammarly here's the thing your time and expertise are valuable and with professionals spending nearly half the workweek on written communication
[01:13:12.320 --> 01:13:15.160]   Focus is one of the most important things to have at work
[01:13:15.160 --> 01:13:22.040]   With a Grammarly as your AI writing partner, you can stay focused and get through your work faster with relevant real-time suggestions
[01:13:22.040 --> 01:13:28.360]   Wherever you write you can download Grammarly for free if you just go to grammarly.com
[01:13:28.360 --> 01:13:30.280]   slash
[01:13:30.280 --> 01:13:31.360]   podcast
[01:13:31.360 --> 01:13:37.040]   So Grammarly with its new its AI enhanced capabilities can do things like help you brainstorm
[01:13:37.040 --> 01:13:40.560]   Help you work your writing to be more confident or persuasive
[01:13:40.560 --> 01:13:46.600]   We have 90% of professionals saying Grammarly has saved them time by writing and editing their work
[01:13:46.600 --> 01:13:50.040]   You can use it wherever you write it works now across
[01:13:50.040 --> 01:13:52.840]   500,000 apps and websites
[01:13:52.840 --> 01:13:59.360]   93% of professionals report that Grammarly helps them get more done. This is just what we were talking about in
[01:14:00.000 --> 01:14:03.640]   In the previous segment. This is where AI has the impact
[01:14:03.640 --> 01:14:12.160]   Not some sort of AI power terminator is going to take over your complete job and chase down your you know
[01:14:12.160 --> 01:14:14.600]   Chase you down your cyber truck. It is AI
[01:14:14.600 --> 01:14:20.120]   Integrated in the things you're already doing letting you do those things at a higher level that adds up
[01:14:20.120 --> 01:14:25.320]   You have Grammarly on the app. So you do your writing put it in your email put it in Microsoft Word and
[01:14:26.040 --> 01:14:29.680]   Now your writing is better. It's more confident. You can check out your tone
[01:14:29.680 --> 01:14:33.680]   It can help with the brainstorming if these are this is the place that like what Grammarly is doing
[01:14:33.680 --> 01:14:35.680]   This is where you're going to see
[01:14:35.680 --> 01:14:42.080]   The initial major productivity gains of the AI revolution. So I'm really excited about their embrace of this technology
[01:14:42.080 --> 01:14:49.000]   I think it's really cool what they're doing. So get more done with Grammarly download Grammarly for free at Grammarly.com slash podcast
[01:14:49.000 --> 01:14:50.760]   That's Grammarly.com
[01:14:50.760 --> 01:14:52.280]   slash
[01:14:52.280 --> 01:14:53.800]   podcast
[01:14:53.800 --> 01:14:58.200]   All right, so if we're not going to have John gonna tell you everything to AI now Jesse this is my new challenge
[01:14:58.200 --> 01:15:05.000]   If we don't yet have AI power terminators ready to come in and take over all of our jobs
[01:15:05.000 --> 01:15:07.720]   We still have to hire
[01:15:07.720 --> 01:15:15.320]   How do you find the right people to hire? This is a hard task to do unless
[01:15:15.320 --> 01:15:21.360]   You have the help of indeed when it comes to hiring indeed is all you need
[01:15:21.800 --> 01:15:28.880]   Stop struggling to get your job post seen on other job sites indeed sponsored jobs will help you stand out and hire fast
[01:15:28.880 --> 01:15:33.640]   With sponsored jobs your post will jump to the top of the page for your relevant candidate
[01:15:33.640 --> 01:15:35.640]   So you're going to reach those people you want
[01:15:35.640 --> 01:15:37.800]   Faster look this makes a huge difference
[01:15:37.800 --> 01:15:44.880]   According to indeed data sponsored jobs posted directly on indeed have 45% more applications
[01:15:45.560 --> 01:15:51.520]   Than non sponsored jobs plus with indeed sponsored jobs. There are no monthly subscriptions
[01:15:51.520 --> 01:15:54.880]   No long-term contracts and you only pay for results
[01:15:54.880 --> 01:15:59.640]   How fast is indeed in the minute or so that I've just been talking to you?
[01:15:59.640 --> 01:16:06.000]   23 hires were made on indeed according to indeed data worldwide and in the time I spent
[01:16:06.000 --> 01:16:09.380]   Trying to do an impersonation of my AI videos
[01:16:10.520 --> 01:16:15.680]   Probably like 40 to 50 people were hired on indeed because I probably spent a couple of minutes actually working on that
[01:16:15.680 --> 01:16:22.200]   So there's no need to wait any longer speed up your hiring right now with indeed and listeners of this show will get
[01:16:22.200 --> 01:16:26.880]   $75 sponsored job credit to get your jobs more visibility if you go to
[01:16:26.880 --> 01:16:33.360]   indeed comm slash deep just go to indeed comm slash deep right now and
[01:16:33.360 --> 01:16:37.240]   Support our show by saying you heard about indeed on this podcast
[01:16:37.680 --> 01:16:40.680]   Indeed comm slash deep terms and conditions apply
[01:16:40.680 --> 01:16:42.560]   hiring
[01:16:42.560 --> 01:16:44.760]   Indeed is all you need. I
[01:16:44.760 --> 01:16:50.960]   Should write my own taglines for all of our sponsors. Yeah, I think they would be pretty terrible but
[01:16:50.960 --> 01:16:54.680]   Indeed is the job hiring service. You should heed
[01:16:54.680 --> 01:16:57.400]   It's pretty good. I
[01:16:57.400 --> 01:16:59.680]   Like it grammarly
[01:16:59.680 --> 01:17:02.000]   will
[01:17:02.000 --> 01:17:06.280]   Slammery slammerly the door shut on your promotion because your writing is better
[01:17:06.280 --> 01:17:08.280]   pretty
[01:17:08.280 --> 01:17:10.800]   Good. All right, let's get to our final segment
[01:17:10.800 --> 01:17:15.540]   By popular demand we want to do a tech corner
[01:17:15.540 --> 01:17:19.600]   That's where I put on my computer science hat a little bit
[01:17:19.600 --> 01:17:24.660]   We geek out about things are happening the world technology and sometimes try to draw some lessons from that for the rest of us
[01:17:24.660 --> 01:17:32.400]   Today, I want to talk about an article from the I triple-e spectrum about our friend Alan Turing
[01:17:33.080 --> 01:17:38.040]   You know load this up here on the screen for those who are watching in addition to just listening
[01:17:38.040 --> 01:17:43.440]   All right, so and explain this to you and then I'm going to connect it back to our initial deep dive
[01:17:43.440 --> 01:17:47.520]   So be some professional podcasting here. Here's the article
[01:17:47.520 --> 01:17:51.520]   The lost art the lost story of Alan Turing secret
[01:17:51.520 --> 01:17:54.400]   Delilah project
[01:17:54.400 --> 01:18:00.080]   so the the set here and I have a picture of his Delilah machine right here the setting here is there was just an auction of
[01:18:00.840 --> 01:18:07.340]   These papers of Turing that have brought the light in a way that we didn't know much about before
[01:18:07.340 --> 01:18:13.520]   his efforts sort of contemporaneously with his work at Bletchley Park on breaking the
[01:18:13.520 --> 01:18:16.040]   German codes and the enigma machine, but also
[01:18:16.040 --> 01:18:20.320]   They have another code. I think it's like SK for R
[01:18:20.320 --> 01:18:24.840]   But basically his code breaking work around that same time and as that kind of wound down
[01:18:24.840 --> 01:18:29.840]   he was also working on another top-secret project in the middle the countryside and
[01:18:30.760 --> 01:18:32.760]   England where I think now is like the
[01:18:32.760 --> 01:18:37.480]   Their British equivalent of the NSA is out there. He worked on this thing
[01:18:37.480 --> 01:18:40.780]   I have on the screen here the Delilah, which is a voice encryptor
[01:18:40.780 --> 01:18:45.340]   So I can talk this encrypts my voice and on the other end is decrypted
[01:18:45.340 --> 01:18:47.480]   So we didn't know much about this
[01:18:47.480 --> 01:18:48.400]   But now we do
[01:18:48.400 --> 01:18:53.680]   Because of these papers and the author of this article had been called in by the auction house to study the paper
[01:18:53.680 --> 01:18:59.340]   So he knows all about it. This is picture. I have up here of a room with
[01:18:59.340 --> 01:19:01.900]   50,000 kilograms worth of equipment
[01:19:01.900 --> 01:19:06.220]   This was the state-of-the-art from that time for doing voice encryption
[01:19:06.220 --> 01:19:12.240]   this was a setup for the Sig Solly system that Bell Labs did and so what was amazing about Turing's work is
[01:19:12.240 --> 01:19:17.800]   Right around that same time. He came up with a similar tool that was this big and if you could see it on the screen
[01:19:17.800 --> 01:19:19.360]   It's like a big briefcase
[01:19:19.360 --> 01:19:23.140]   You could put it in a big backpack and carry it. So it's a cool story
[01:19:24.140 --> 01:19:26.900]   Now if you get into it, here's what I want to point out
[01:19:26.900 --> 01:19:31.260]   I don't know how much one gets a technical details. So there was a
[01:19:31.260 --> 01:19:34.320]   Let me geek out briefly. It's a tech corner
[01:19:34.320 --> 01:19:36.960]   so he had been involved with
[01:19:36.960 --> 01:19:43.260]   Not just cracking the German Enigma text code. So by text code, I mean an encrypted text
[01:19:43.260 --> 01:19:47.500]   He also broke another German system or was involved in it called the sz-42
[01:19:47.500 --> 01:19:52.680]   Again, it was a text based system. So you you had text that you're encrypting
[01:19:53.200 --> 01:19:59.000]   The architecture of that German system is how we do most sort of digital encryption today
[01:19:59.000 --> 01:20:02.720]   so, you know the way this German system worked is
[01:20:02.720 --> 01:20:07.440]   The I'm talking about the sz-42 here is you had a sequence of letters
[01:20:07.440 --> 01:20:13.060]   You wanted to send to someone else and what you had was a box that generated
[01:20:13.060 --> 01:20:16.600]   Pseudorandom
[01:20:16.600 --> 01:20:20.760]   Characters, right? So like really what's happening here is like each letters change into a number and then you have this
[01:20:21.960 --> 01:20:23.960]   Mechanical thing that was creating
[01:20:23.960 --> 01:20:29.200]   Random numbers. I say pseudorandom though, because if you start with the same settings
[01:20:29.200 --> 01:20:31.920]   It will always produce the same stream of numbers that seem pretty random
[01:20:31.920 --> 01:20:37.260]   And then what you do is it's called a stream cipher you add these together. So like I'm trying to send, you know
[01:20:37.260 --> 01:20:42.500]   Activate Jesse skeleton as like my key command. Those are those letters
[01:20:42.500 --> 01:20:45.600]   If I was using a sz-42
[01:20:45.600 --> 01:20:50.840]   I'm generating random numbers and I'm adding a random number to each of those letters from activate Jesse skeleton
[01:20:50.840 --> 01:20:53.020]   If you know on the other end
[01:20:53.020 --> 01:20:55.960]   how I configured my
[01:20:55.960 --> 01:20:58.960]   Thing that spit out the random numbers you can figure yours the same way
[01:20:58.960 --> 01:21:04.360]   It spits out the same random numbers you subtract them away and you get the original message. That's actually how most
[01:21:04.360 --> 01:21:09.740]   Cryptography works now on the Internet like if you're communicating securely with a website
[01:21:09.740 --> 01:21:13.720]   you have just a digital version of one of these things that spits out a bunch of
[01:21:13.720 --> 01:21:19.920]   Random seeming numbers and as long as the person on the other ends like Amazon has the same key you have
[01:21:20.600 --> 01:21:25.560]   It can then create the same stream and take it off again, right? So these stream ciphers are very fast
[01:21:25.560 --> 01:21:28.240]   And it's how it's what we use to encrypt most things
[01:21:28.240 --> 01:21:34.320]   the problem of course is how do you share the key because you and I have to have this we have to set up our
[01:21:34.320 --> 01:21:41.560]   Generator of random seeming numbers the exact same but if I tell you that value and someone else could see me telling you that value
[01:21:41.560 --> 01:21:43.560]   I can't send it over the same channel
[01:21:43.560 --> 01:21:46.520]   The way they had to do this back in World War two was like literally
[01:21:46.840 --> 01:21:51.920]   Put these in pouches and send them to people right you would have a booklet to look up like on this day at this time
[01:21:51.920 --> 01:21:55.640]   Here's the thing we use the big breakthrough in internet based
[01:21:55.640 --> 01:22:05.280]   Cryptography is a public key encryption. So this was like the the key breakthrough. This is like RSA technologies to RSA algorithm
[01:22:05.280 --> 01:22:10.880]   Public key encryption is a way that I can encrypt something for you to read
[01:22:10.880 --> 01:22:13.020]   Send it to you
[01:22:13.020 --> 01:22:15.020]   No one can decrypt it except for you
[01:22:15.580 --> 01:22:20.240]   No, it's not very efficient. So I don't want to use this for my big message
[01:22:20.240 --> 01:22:25.500]   I want to send you so the big breakthrough in like internet cryptography was we use this very expensive method
[01:22:25.500 --> 01:22:32.340]   Asymmetric encryption public encryption just to trade our initial key to each other and then we can set up our very fast stream ciphers
[01:22:32.340 --> 01:22:34.340]   the same and then we can use that the
[01:22:34.340 --> 01:22:36.260]   communicate really fast
[01:22:36.260 --> 01:22:39.860]   So with like public key encryption you have a private key in a public key that are related
[01:22:39.860 --> 01:22:41.720]   You can publish your public key
[01:22:41.720 --> 01:22:47.300]   I can use your public key to encrypt something and send it to you and only someone who knows your private key can unencrypt it
[01:22:47.300 --> 01:22:49.300]   That's public key encryption. So
[01:22:49.300 --> 01:22:51.700]   That's that's in depth my geekage
[01:22:51.700 --> 01:22:55.780]   Anyways, the way that Turing's design worked is he said great
[01:22:55.780 --> 01:23:00.300]   We're going to take voice which is sound waves and we're going to break it up into little
[01:23:00.300 --> 01:23:07.820]   Discrete time stamps like a thousand times a second and we're going to measure like what's the height of the sound wave at each of?
[01:23:07.820 --> 01:23:11.760]   These points we'll make that a number. We'll add a random number to that
[01:23:11.760 --> 01:23:16.440]   Then we will this will give us like a random looking sound wave
[01:23:16.440 --> 01:23:21.700]   We'll send that like weird sounding sound wave across the radio channel or whatever
[01:23:21.700 --> 01:23:26.800]   And on the other end you subtract away those numbers from what you receive and then generate a new sound wave
[01:23:26.800 --> 01:23:29.740]   It'll be the original talking back. So like that's what he's doing. Okay
[01:23:29.740 --> 01:23:34.840]   What was cool about this is if you read this article, so here's the lesson. I want to draw all of this
[01:23:34.840 --> 01:23:36.720]   I'm not just geeking out
[01:23:36.720 --> 01:23:38.720]   Turing didn't know a lot about
[01:23:38.720 --> 01:23:41.080]   electrical engineering and
[01:23:41.080 --> 01:23:43.080]   If you read this article
[01:23:43.080 --> 01:23:48.740]   He was able to here's like part of his lab notebook on the screen here. He just went out to this place
[01:23:48.740 --> 01:23:50.800]   countryside
[01:23:50.800 --> 01:23:55.520]   There's like an army barracks there and like a mess hall to eat at and he could just spend months
[01:23:55.520 --> 01:24:01.760]   Figuring out electrical engineering and doing these experiments like this experiment. I have on the
[01:24:02.320 --> 01:24:06.800]   Screen here is just taking a particular component and just taking data
[01:24:06.800 --> 01:24:10.260]   Let me run it like this and this and how's this thing work and was just teaching himself
[01:24:10.260 --> 01:24:16.040]   Engineering just spending months doing that after about six months someone else joined the project
[01:24:16.040 --> 01:24:24.320]   Bailey b-a-y-l-e-y who was an accomplished engineer and he he began to give lessons to Turing like let me get you better up to speed
[01:24:24.320 --> 01:24:26.600]   about electrical engineering
[01:24:26.600 --> 01:24:33.120]   principles and like how to solder things correctly and and Turing got better at that and then Turing was able after about a year of
[01:24:33.120 --> 01:24:36.880]   this to mix his really innovative mathematical capability with this sort of
[01:24:36.880 --> 01:24:40.840]   Now reasonable engineering ability and they built this really cool thing
[01:24:40.840 --> 01:24:44.400]   I'm gonna connect this back to the beginning of the show
[01:24:44.400 --> 01:24:48.920]   Because what was the British government doing here during World War two and the immediate aftermath?
[01:24:48.920 --> 01:24:51.680]   They're letting Turing cook
[01:24:51.680 --> 01:24:54.560]   Go spend six months in the woods
[01:24:55.520 --> 01:25:01.720]   Just doing experiments on these components and teaching yourself how to build machines because you're brilliant and you have these other skills
[01:25:01.720 --> 01:25:05.480]   Right you had all these mathematical skills that were relevant
[01:25:05.480 --> 01:25:11.960]   He had encountered Claude Shannon during his time at Bell Labs and was able to use some of the mathematics that Shannon had innovated
[01:25:11.960 --> 01:25:14.360]   About sampling theory and he was able to bring that back over here
[01:25:14.360 --> 01:25:18.560]   Like you have the mathematics skills to do something cool. It's been a year figuring out the engineering
[01:25:18.560 --> 01:25:20.840]   Take your time
[01:25:20.840 --> 01:25:25.240]   Don't jump on zoom meetings. Don't do email. Don't be busy. We don't know what you're doing over there
[01:25:25.240 --> 01:25:31.000]   And come away of building this really cool thing. And then after he built this Delilah box now
[01:25:31.000 --> 01:25:37.360]   We had all this electrical engineering know-how in addition to his abstract mathematical and logic know-how. What did he do post-war?
[01:25:37.360 --> 01:25:39.720]   He built some of the very first electronic computers
[01:25:39.720 --> 01:25:42.120]   So he was able to put that skill to use
[01:25:42.120 --> 01:25:43.680]   building
[01:25:43.680 --> 01:25:49.440]   Britain Britain's contributions to the world of early electronic computers, right and he wasn't the first to build those, you know
[01:25:49.440 --> 01:25:52.720]   It's not accurate to say he invented the computer, but he was in the mix
[01:25:53.440 --> 01:25:57.960]   Because he had learned these skills. So anyways, the the nerd details about encryption are cool
[01:25:57.960 --> 01:26:03.600]   but I love this bigger notion of like why don't we people who have skills just let them cook and
[01:26:03.600 --> 01:26:09.560]   The return is so much bigger. You're getting so much more out of Alan Turing just let him cook than if he had to be
[01:26:09.560 --> 01:26:16.400]   Responding to memos and going to meetings at the the war HQ during the war. We need more
[01:26:16.400 --> 01:26:22.320]   Need more of this of just letting people cook because they can produce stuff. That is so high-value
[01:26:23.200 --> 01:26:26.920]   That any inconvenience of them not being very accessible. I think it's washed away
[01:26:26.920 --> 01:26:34.160]   Two quick things when you're talking about the crypto it reminded me of Neal Stevenson's book crypt Omicron. Yeah that sure
[01:26:34.160 --> 01:26:38.220]   I have yeah, Turing's in that book. Yeah. Yeah, I actually so
[01:26:38.220 --> 01:26:44.280]   the public key encryption algorithm that like made all of like internet encryption possible is RSA and
[01:26:44.280 --> 01:26:46.560]   The R in that is Ron Rivest
[01:26:46.560 --> 01:26:52.120]   And so when I was getting my doctorate MIT ITA for Ron in his like network security class
[01:26:52.440 --> 01:26:56.880]   So he's a cool guy because he he left and started a company RSA the
[01:26:56.880 --> 01:26:59.800]   Commercialized this thing and they sold it for
[01:26:59.800 --> 01:27:03.440]   Well over a billion dollars. Mm-hmm, then he came back
[01:27:03.440 --> 01:27:06.080]   But he was loaded
[01:27:06.080 --> 01:27:08.520]   He came back
[01:27:08.520 --> 01:27:13.920]   Because he loved being a professor, but he had really good Red Sox tickets. That's why I remember they had seized
[01:27:13.920 --> 01:27:19.240]   That's what you would do in Boston. If you make a billion dollars like I'm gonna get some get some Sox tickets
[01:27:19.760 --> 01:27:24.320]   He was a brilliant guy. I think it's still I think it's still active it then it turned out
[01:27:24.320 --> 01:27:31.200]   So, you know, they made bank, but then it turned out that a researcher in the NSA had solved the same problem in
[01:27:31.200 --> 01:27:34.180]   The 70s, but it was classified
[01:27:34.180 --> 01:27:38.320]   He solved it like so we were using it with within like the NSA and stuff like that
[01:27:38.320 --> 01:27:41.880]   But he couldn't talk about it. So then these academics came along and
[01:27:41.880 --> 01:27:48.000]   Solved it later and then made bank. So and now it's known like at least the other guy gets credit for
[01:27:48.640 --> 01:27:54.180]   Discovering it but and then the other thing with cooking is a lot of people say in basketball like let Steph cook
[01:27:54.180 --> 01:28:01.720]   You know Steph Curry was like cooking and hitting Bill Simmons always uses this terminology. Yeah. Yeah, I from like a physical standpoint
[01:28:01.720 --> 01:28:03.120]   I can't think of
[01:28:03.120 --> 01:28:05.120]   from like a physical discipline standpoint
[01:28:05.120 --> 01:28:11.680]   These define two ends of the wide spectrum would be like Steph Curry over here and Brandon Sanderson over here
[01:28:11.680 --> 01:28:15.240]   Like I wouldn't trust
[01:28:15.280 --> 01:28:18.080]   Sanderson to get the breakaway three, let's put it that way
[01:28:18.080 --> 01:28:23.360]   but and I wouldn't trust Steph Curry to write 300,000 words about yeah, you know the Kingkiller Chronicles or whatever, but
[01:28:23.360 --> 01:28:26.280]   wait a second, I
[01:28:26.280 --> 01:28:28.480]   think Kingkiller might be
[01:28:28.480 --> 01:28:30.760]   Patrick Rufus have I done it again? Oh
[01:28:30.760 --> 01:28:33.600]   It starts again
[01:28:33.600 --> 01:28:35.600]   It starts again. I
[01:28:35.600 --> 01:28:37.960]   didn't want to do too many of our
[01:28:37.960 --> 01:28:41.000]   Like super insider name of the wind jokes
[01:28:41.160 --> 01:28:46.320]   yeah, I was like for the audience you like I'll get so many emails like the I actually see this on YouTube is gonna be like
[01:28:46.320 --> 01:28:48.960]   for shame for shame
[01:28:48.960 --> 01:28:54.600]   And like that'll be the they'll be so upset and that'll be the end of us on YouTube. So I was trying to be respectful
[01:28:54.600 --> 01:28:58.040]   All right. That's all the time we have for today. Thanks for listening or watching
[01:28:58.040 --> 01:29:02.360]   We'll be back next week with another episode and until then as always stay deep
[01:29:02.360 --> 01:29:09.880]   Hey, if you like today's discussion about the power of just letting someone cook you might also like episode
[01:29:10.920 --> 01:29:18.720]   37 where we get into how to hack remote work to make yourself much more happy and much more productive check it out
[01:29:18.720 --> 01:29:21.640]   But I thought this timing might be good
[01:29:21.640 --> 01:29:27.200]   To talk to those of you who still have some sort of remote work
[01:29:27.200 --> 01:29:33.000]   Set up in your job about the very general topic of how do you make the most of that?

