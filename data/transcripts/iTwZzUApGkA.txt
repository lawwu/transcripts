
[00:00:00.000 --> 00:00:04.620]   Elon is building a much, much bigger cluster to train a much, much bigger
[00:00:04.620 --> 00:00:07.940]   model as is open AI, as is Zuckerberg.
[00:00:07.940 --> 00:00:08.240]   I mean,
[00:00:08.240 --> 00:00:11.420]   well, Sam just said the bigger models aren't the best.
[00:00:11.420 --> 00:00:14.940]   Well, I mean, he may be doing the same game that everybody else is doing,
[00:00:14.940 --> 00:00:17.180]   Bill, and trying to throw everybody off the scent.
[00:00:17.180 --> 00:00:32.000]   Great to have you guys.
[00:00:32.000 --> 00:00:33.840]   What a week it's been nuts.
[00:00:33.840 --> 00:00:37.400]   There's so much to talk about and we have our good buddy, Sonny.
[00:00:37.400 --> 00:00:37.920]   How are you doing?
[00:00:37.920 --> 00:00:39.880]   Deep Madra in the house.
[00:00:39.880 --> 00:00:44.400]   Sonny, somebody, Bill and I go too often when we're talking through all things.
[00:00:44.400 --> 00:00:48.240]   AI currently at Grok working on the inference cloud.
[00:00:48.240 --> 00:00:51.800]   So you're deep in thinking about all these things, all these models, AI, and
[00:00:51.800 --> 00:00:55.400]   we're going to talk a lot about models today with the release of Llama 3.
[00:00:55.400 --> 00:00:57.040]   So it's good to have you, Sonny.
[00:00:57.040 --> 00:00:57.640]   Good to be here.
[00:00:57.640 --> 00:00:58.380]   Thanks guys.
[00:00:58.380 --> 00:00:59.760]   Bill, why are you in town?
[00:00:59.760 --> 00:01:01.700]   Board meetings, a couple of board meetings.
[00:01:01.700 --> 00:01:02.700]   Good to have you.
[00:01:02.700 --> 00:01:02.960]   Yeah.
[00:01:02.960 --> 00:01:04.200]   I always like doing this in person.
[00:01:04.200 --> 00:01:04.800]   Yeah, I know you do.
[00:01:04.800 --> 00:01:05.200]   Okay.
[00:01:05.200 --> 00:01:06.560]   So let's, so let's roll.
[00:01:06.560 --> 00:01:08.240]   They're my favorite episodes when you do them live.
[00:01:08.240 --> 00:01:08.640]   Okay.
[00:01:08.640 --> 00:01:09.320]   There we go.
[00:01:09.320 --> 00:01:10.080]   There we go.
[00:01:10.080 --> 00:01:13.360]   So models, models, models, models.
[00:01:13.360 --> 00:01:18.360]   If AI is the next big thing, then this felt like another really important week.
[00:01:18.360 --> 00:01:22.400]   I mean, we got models being dropped by Meta with Llama 3.
[00:01:22.400 --> 00:01:26.720]   That was the one that was really, you know, the category five earthquake.
[00:01:26.720 --> 00:01:31.720]   Microsoft, Snowflake, everybody seems to be out with a new model, but let's start
[00:01:31.720 --> 00:01:37.640]   with Zuck, huge Llama 3 unveiling, three distinct models, an 8 billion, a 70
[00:01:37.640 --> 00:01:41.800]   billion, and a 405 billion parameter model, which is still training and still
[00:01:41.800 --> 00:01:46.280]   learning they're telling us, which is pretty fascinating, but what seems to
[00:01:46.280 --> 00:01:51.320]   have, you know, shocked the market is that Meta could pack so much intelligence
[00:01:51.320 --> 00:01:53.360]   into such a small model.
[00:01:53.360 --> 00:01:58.080]   And so both models quickly shot up the rankings this week.
[00:01:58.080 --> 00:02:00.880]   We have some, you know, a screenshot here of that.
[00:02:00.880 --> 00:02:05.920]   Of course the 405 is still training and there, there've been some hints out of
[00:02:05.920 --> 00:02:10.480]   the, a recent podcast with Zuck and Dwarkesh about it may in fact kind of
[00:02:10.480 --> 00:02:11.760]   come in at the top of the polls.
[00:02:11.760 --> 00:02:15.000]   We'll see, it's probably going to train for another couple of months, but I'd
[00:02:15.000 --> 00:02:16.600]   love to hear from both of you guys.
[00:02:16.600 --> 00:02:21.040]   What were your big takeaways from the launch of Llama 3 and maybe start with
[00:02:21.040 --> 00:02:25.320]   you, Sonny, walk us through kind of just the what and the how of Model 3 and why
[00:02:25.320 --> 00:02:27.680]   it really kind of shook things up.
[00:02:27.680 --> 00:02:33.240]   Yeah, I would say, you know, the biggest impact of Llama 3 is its
[00:02:33.240 --> 00:02:38.560]   capabilities and at the size and what, you know, Zuck shared in that interview
[00:02:38.920 --> 00:02:43.360]   was that they basically took the model and kept training it past the chinchilla
[00:02:43.360 --> 00:02:43.720]   point.
[00:02:43.720 --> 00:02:48.600]   And so really by doing that, which is generally considered like sort of the
[00:02:48.600 --> 00:02:52.920]   point of diminishing returns, they were able to pack much more information and
[00:02:52.920 --> 00:02:56.400]   much more capability into this model with the same data set.
[00:02:56.400 --> 00:02:59.240]   So, so, so just for, for, for everybody listening.
[00:02:59.240 --> 00:03:03.440]   So the chinchilla point, if I understand it correctly, right, that it's the
[00:03:03.440 --> 00:03:06.760]   by-product of this paper out of Google, which basically talked about the
[00:03:06.760 --> 00:03:11.080]   relationship between the optimal amount of data to use for an, for a certain
[00:03:11.080 --> 00:03:11.800]   amount of compute.
[00:03:11.800 --> 00:03:12.240]   Yep.
[00:03:12.240 --> 00:03:18.400]   But in the case of Meta, when they were training Llama 3, they were basically
[00:03:18.400 --> 00:03:21.520]   continued with these forward passes of the data.
[00:03:21.520 --> 00:03:25.560]   So they were curating the data, refining the data, pushing it back into the model.
[00:03:25.560 --> 00:03:30.480]   And I think several people who are working on pre-training at Meta said they
[00:03:30.480 --> 00:03:34.840]   were even surprised that it was still learning when they took it offline on
[00:03:34.840 --> 00:03:35.400]   that data.
[00:03:35.440 --> 00:03:39.080]   Yeah, and they only took it offline to reallocate the resources to, you know,
[00:03:39.080 --> 00:03:40.960]   405 and other efforts.
[00:03:40.960 --> 00:03:42.520]   And I think he said Llama 4.
[00:03:42.520 --> 00:03:43.120]   And Llama 4.
[00:03:43.120 --> 00:03:43.440]   Right.
[00:03:43.440 --> 00:03:46.200]   So the rate of innovation, certainly not slowing down there.
[00:03:46.200 --> 00:03:48.680]   So a 15 trillion parameter model.
[00:03:48.680 --> 00:03:50.840]   15 trillion tokens used to train it.
[00:03:50.840 --> 00:03:55.960]   Oh yeah, yeah, 15 trillion tokens used to train, you know, the model.
[00:03:55.960 --> 00:04:00.960]   I know at Grok, you guys are deploying Llama 3.
[00:04:00.960 --> 00:04:03.360]   I think you deployed it the same day that it came out.
[00:04:03.800 --> 00:04:06.440]   So how important is this?
[00:04:06.440 --> 00:04:09.480]   How important a development is it in the world of models?
[00:04:09.480 --> 00:04:14.680]   Well, really, you know, Zak came out and threw down for the entire world of folks
[00:04:14.680 --> 00:04:15.680]   that are building models.
[00:04:15.680 --> 00:04:20.640]   And it's really disruptive because when you look at the rankings, you have a model
[00:04:20.640 --> 00:04:25.560]   that's much smaller, so much easier to run on all different types of hardware and
[00:04:25.560 --> 00:04:26.440]   much faster.
[00:04:26.440 --> 00:04:30.640]   And so those two things are like catnip for developers.
[00:04:30.880 --> 00:04:36.400]   And for us, we saw within the first 48 hours, it become the most popular model that
[00:04:36.400 --> 00:04:37.280]   we run on Grok.
[00:04:37.280 --> 00:04:39.240]   And so, really.
[00:04:39.240 --> 00:04:40.240]   Replacing what?
[00:04:40.240 --> 00:04:42.960]   Replacing Mixtral 8x7 for us.
[00:04:42.960 --> 00:04:43.360]   Interesting.
[00:04:43.360 --> 00:04:46.760]   Which was, you know, generally considered the best open source model at that point.
[00:04:46.760 --> 00:04:52.440]   And what the capabilities have happened beyond us sort of running it, the developers
[00:04:52.440 --> 00:04:56.080]   that use it, the use cases we've seen it in are incredible.
[00:04:56.400 --> 00:05:00.920]   And people are doing a direct replacement with OpenAI across the board.
[00:05:00.920 --> 00:05:02.040]   They come to us.
[00:05:02.040 --> 00:05:06.880]   So they come to, you know, all the different providers and they replace out OpenAI and
[00:05:06.880 --> 00:05:11.400]   they don't really see any performance impact or any reasoning impact or, which is
[00:05:11.400 --> 00:05:11.600]   incredible.
[00:05:11.600 --> 00:05:12.480]   And why replace?
[00:05:12.480 --> 00:05:15.400]   What is being optimized in the switch?
[00:05:15.400 --> 00:05:17.520]   Price performance, right?
[00:05:17.520 --> 00:05:24.760]   You get probably on from a GPT-4, you're more than 10 times cheaper, right?
[00:05:24.880 --> 00:05:27.240]   And you're, yeah, 10 times cheaper.
[00:05:27.240 --> 00:05:35.480]   And well, let me just tell you, GPT-4 is $10 per million tokens input and $30 per
[00:05:35.480 --> 00:05:36.480]   million token output.
[00:05:36.480 --> 00:05:45.400]   And LLAMA370B is $0.60 for a million tokens input and $0.70 for a million tokens output.
[00:05:45.400 --> 00:05:51.720]   I mean, Bill, this seems to be playing right into your thesis around kind of just
[00:05:51.720 --> 00:05:53.120]   these models generally.
[00:05:53.120 --> 00:05:54.680]   Commoditization.
[00:05:54.680 --> 00:06:00.560]   Yeah, you've been skeptical about the amount of dollars it's taking to train some of
[00:06:00.560 --> 00:06:04.920]   these venture-backed models and the business models that would come out the other side.
[00:06:04.920 --> 00:06:09.720]   Now we have a business in meta, right, that just announced they're going to spend $40
[00:06:09.720 --> 00:06:16.400]   billion this year on CapEx that just trained a model that is 10x less expensive than, you
[00:06:16.400 --> 00:06:18.400]   know, the most performant model on the market.
[00:06:18.400 --> 00:06:21.160]   I mean, what does this mean for everybody else?
[00:06:21.400 --> 00:06:29.560]   Well, there's a couple of things that I put into the mix as I analyze this and answer
[00:06:29.560 --> 00:06:30.200]   your question.
[00:06:30.200 --> 00:06:39.280]   You know, first, he made meta AI free and he didn't proclaim that this was temporary or
[00:06:39.280 --> 00:06:40.720]   that he might pull it up later.
[00:06:40.720 --> 00:06:46.160]   And so, you know, that combined with, I think, Perplexity claiming they're going to have
[00:06:46.160 --> 00:06:52.280]   an ad portion and OpenAI hinting at that, at least for the time being, I think the $20
[00:06:52.280 --> 00:06:54.560]   concept is gone.
[00:06:54.560 --> 00:06:55.080]   Yep.
[00:06:55.080 --> 00:06:59.560]   And that was a big part of OpenAI's revenue, apparently, or we believe rumored to be.
[00:06:59.560 --> 00:07:02.160]   Yeah, over 50% of their revenue is, I think, from consumer.
[00:07:02.160 --> 00:07:03.760]   And so that's gone.
[00:07:03.760 --> 00:07:07.560]   As long as meta's free, I don't think anyone pays the $20.
[00:07:07.560 --> 00:07:11.240]   And I will say that is as things sit today.
[00:07:11.240 --> 00:07:16.920]   If some crazy feature comes along, you know, we've talked about personal memory, maybe
[00:07:16.920 --> 00:07:18.240]   that comes back.
[00:07:18.240 --> 00:07:20.240]   But for now, it feels dead.
[00:07:20.240 --> 00:07:20.720]   Right.
[00:07:20.720 --> 00:07:27.920]   And then I thought the podcast that you mentioned was just incredibly, like,
[00:07:27.920 --> 00:07:32.320]   disclosive, transparent, thoughtful.
[00:07:32.320 --> 00:07:35.800]   You're talking about Zuckerberg on Dwarkish?
[00:07:35.800 --> 00:07:36.120]   Yes.
[00:07:36.120 --> 00:07:36.440]   Yes.
[00:07:36.440 --> 00:07:37.440]   I thought it was incredible.
[00:07:38.080 --> 00:07:43.360]   And it's funny, because it came out at the exact same time that Sam and Brad were on
[00:07:43.360 --> 00:07:48.240]   Harry Stebbings in 20 BC, and Dario was on Ezra Klein.
[00:07:48.240 --> 00:07:54.120]   And I would encourage people to listen to all three of them, but Dario and Sam talk in
[00:07:54.120 --> 00:07:58.200]   these high-level platitudes about how this stuff's going to cure cancer, and we're all
[00:07:58.200 --> 00:08:00.120]   going to not have to work anymore.
[00:08:00.120 --> 00:08:06.320]   And Zuck was down in the weeds, in the meat, being super transparent.
[00:08:06.320 --> 00:08:09.960]   And I was just like, "Holy sh*t, maybe this guy's in charge now."
[00:08:09.960 --> 00:08:10.640]   Right, right.
[00:08:10.640 --> 00:08:11.080]   You know?
[00:08:11.080 --> 00:08:16.760]   I mean, I saw a lot of people on Twitter saying this was checkmate on all of these
[00:08:16.760 --> 00:08:20.920]   closed models that have gotten started and venture-backed over the course of last year.
[00:08:20.920 --> 00:08:23.640]   And certainly, you know, I'm not cheering for that.
[00:08:23.640 --> 00:08:26.640]   I'm not sure that I would go so far as to declare it.
[00:08:26.640 --> 00:08:30.560]   But I think if you're in the business of producing a closed model, right?
[00:08:30.560 --> 00:08:32.240]   We've talked a lot on this pod.
[00:08:32.240 --> 00:08:34.760]   There are one of two ways that you can build a business.
[00:08:35.000 --> 00:08:39.280]   You either have to sell it to a consumer for 20 bucks a month, or advertising, you
[00:08:39.280 --> 00:08:43.280]   have to get a billion consumers to use your product, or you have to sell it to an
[00:08:43.280 --> 00:08:43.800]   enterprise.
[00:08:43.800 --> 00:08:45.120]   Somebody has to pay you.
[00:08:45.120 --> 00:08:50.080]   And now you have a disruptor coming along and saying, "It's open, it's cheap or
[00:08:50.080 --> 00:08:52.800]   free, and I'm not going to charge for it."
[00:08:52.800 --> 00:08:54.360]   That's hard to compete with.
[00:08:54.360 --> 00:08:57.880]   And I use them all because I'm curious and I love playing.
[00:08:57.880 --> 00:09:00.560]   I'll do the same query on four of them.
[00:09:01.000 --> 00:09:06.840]   But right now, it's hard to believe that any of them, including the Google one, are
[00:09:06.840 --> 00:09:09.800]   going to have escape velocity because of differentiation.
[00:09:09.800 --> 00:09:14.680]   I'm not seeing, maybe you guys are, I'm not seeing an element of differentiation on
[00:09:14.680 --> 00:09:19.080]   the consumer-facing tool that's radically different.
[00:09:19.080 --> 00:09:21.200]   It's going to cause 80% market share.
[00:09:21.200 --> 00:09:23.680]   The differentiation is happening on the infrastructure side.
[00:09:23.680 --> 00:09:27.360]   And there's another thing that, you know, Zuck said in that, which was, I think, a
[00:09:27.360 --> 00:09:31.160]   big throwdown, which is, we're going to spend $100 billion on this.
[00:09:31.160 --> 00:09:37.240]   But if the community, because he's made it open, makes it 10% better, right, in some
[00:09:37.240 --> 00:09:40.680]   parameter, that's $10 billion savings for us.
[00:09:40.680 --> 00:09:41.480]   Right.
[00:09:41.480 --> 00:09:47.280]   If you just look at what they did this week, they pushed AI Search across their entire
[00:09:47.280 --> 00:09:48.680]   family of applications.
[00:09:48.680 --> 00:09:51.400]   They have 3 billion people using those every day.
[00:09:51.400 --> 00:09:55.040]   He said on his earnings call this week, they already have tens of millions of people
[00:09:55.200 --> 00:09:57.560]   running AI Searches on their applications.
[00:09:57.560 --> 00:10:01.440]   And he was even honest in the podcast where he's like, I don't know if this is where
[00:10:01.440 --> 00:10:02.840]   people want to do these searches.
[00:10:02.840 --> 00:10:08.160]   And it just earned so much credibility with me when someone kind of, you know, comes
[00:10:08.160 --> 00:10:08.800]   clean that way.
[00:10:08.800 --> 00:10:12.400]   I think one of the other interesting developments, again, just getting back, if I
[00:10:12.400 --> 00:10:18.040]   had one big takeaway, it was this large versus small.
[00:10:18.040 --> 00:10:18.800]   Okay.
[00:10:18.800 --> 00:10:21.360]   And so I think we have to...
[00:10:21.360 --> 00:10:23.000]   Before you go there, I got a question for you.
[00:10:23.000 --> 00:10:23.400]   Yeah.
[00:10:23.600 --> 00:10:26.160]   Could the CapEx thing be a throw down?
[00:10:26.160 --> 00:10:31.640]   Like, could it be a signal to the rest of the community?
[00:10:31.640 --> 00:10:33.640]   This is where we're going to be.
[00:10:33.640 --> 00:10:41.240]   Like, just to, could it be a move to tell everyone else, if you want to stay in this
[00:10:41.240 --> 00:10:42.280]   game, you got to play at this level.
[00:10:42.280 --> 00:10:44.600]   It's also two birds with one stone, right?
[00:10:44.600 --> 00:10:48.480]   I think there is that, but there's the second one, which is, you know, also talked
[00:10:48.480 --> 00:10:54.360]   about in another set of tweets this week, by putting more effort and resources towards
[00:10:54.360 --> 00:10:57.440]   the training, they reduce the inference costs.
[00:10:57.440 --> 00:10:57.760]   Yeah.
[00:10:57.760 --> 00:10:58.680]   Right, for sure.
[00:10:58.680 --> 00:11:01.640]   And for them, you can imagine everything that you're talking about, making it free
[00:11:01.640 --> 00:11:05.320]   everywhere, putting it inside all the products, millions of people using it.
[00:11:05.320 --> 00:11:06.400]   That's a huge impact.
[00:11:06.400 --> 00:11:10.080]   And I would remind people, you know, something we talked about several episodes
[00:11:10.080 --> 00:11:16.720]   ago, but there was a, there was a podcast I listened to, um, where Amazon was talking
[00:11:16.720 --> 00:11:20.120]   about, um, their Alexa product.
[00:11:20.120 --> 00:11:27.280]   And they said, you know, inference was way more of the cost than, than the
[00:11:27.280 --> 00:11:28.800]   training, like night and day.
[00:11:28.800 --> 00:11:32.160]   And so there's a real world application that's been alive.
[00:11:32.160 --> 00:11:36.120]   And, and if that's, do you believe that's true for almost all development projects?
[00:11:36.120 --> 00:11:36.560]   Oh, yeah.
[00:11:36.560 --> 00:11:37.360]   Yeah.
[00:11:37.760 --> 00:11:42.120]   And so it's, it's weird to, you know, to your question, is capital a signal?
[00:11:42.120 --> 00:11:43.080]   Of course it is.
[00:11:43.080 --> 00:11:43.360]   Yeah.
[00:11:43.360 --> 00:11:48.200]   I mean, in 2021, we talked about capital as, as, as being the kingmaker, like
[00:11:48.200 --> 00:11:50.000]   who would, who, who would win the game?
[00:11:50.000 --> 00:11:54.600]   I think there are four important ingredients, uh, to compete in this market.
[00:11:54.600 --> 00:11:59.320]   Number one, you have to have capital and the leaders are spending 40 billion a year.
[00:11:59.320 --> 00:12:03.480]   There aren't many sovereigns on the planet that can afford to spend $40 billion a year.
[00:12:03.720 --> 00:12:08.640]   Second, what you need, we just, the big, uh, you know, innovation this week is that
[00:12:08.640 --> 00:12:12.080]   data is scaling in the way that compute is scaling.
[00:12:12.080 --> 00:12:13.640]   So you need a lot of data.
[00:12:13.640 --> 00:12:15.360]   They have a massive amount of data.
[00:12:15.360 --> 00:12:16.880]   Third, you need compute.
[00:12:16.880 --> 00:12:18.480]   That's not just about capital.
[00:12:18.480 --> 00:12:22.240]   You have to have people who know how to build and stand up infrastructure.
[00:12:22.240 --> 00:12:25.840]   You have to have relationships with the entire supply chain, right?
[00:12:25.840 --> 00:12:28.480]   And fourth, you have to have distribution, right?
[00:12:28.480 --> 00:12:30.480]   And so they're touching 3 billion consumers.
[00:12:30.480 --> 00:12:31.560]   They have a business model.
[00:12:31.680 --> 00:12:38.360]   I think he said 50% of the content on Instagram was AI generated in the quarter.
[00:12:38.360 --> 00:12:38.760]   Right?
[00:12:38.760 --> 00:12:42.880]   So not AI generated, it was AI suggested, right?
[00:12:42.880 --> 00:12:45.720]   So it was no longer about your friends looking at something.
[00:12:45.720 --> 00:12:47.480]   It was something that, you know, they did.
[00:12:47.480 --> 00:12:51.840]   So that gives them a huge advantage, but I do think there's, you know, when I get
[00:12:51.840 --> 00:12:56.560]   back to this bifurcation and why I think this is important, we have these smaller
[00:12:56.560 --> 00:13:00.360]   models that are going to be specialized and have specialized use cases.
[00:13:00.800 --> 00:13:04.760]   You know, Microsoft is out with Fi and I want you to talk a little bit about that,
[00:13:04.760 --> 00:13:10.680]   Sonny, but we don't see any slowing down on the push to bigger models as well.
[00:13:10.680 --> 00:13:14.480]   So we really see both of these things happening simultaneously.
[00:13:14.480 --> 00:13:20.200]   And an analog I was discussing with our team was if you think about different use
[00:13:20.200 --> 00:13:25.360]   cases, you might build a small rocket to get a satellite into space and you might
[00:13:25.360 --> 00:13:27.400]   build a big rocket to try to get to Mars.
[00:13:27.400 --> 00:13:28.360]   Okay.
[00:13:28.360 --> 00:13:30.680]   Now those are both rockets.
[00:13:30.960 --> 00:13:34.400]   But they have radically different use cases and radically different cost
[00:13:34.400 --> 00:13:34.920]   structures.
[00:13:34.920 --> 00:13:39.560]   And I think that the cost structures that are going to be associated with frontier
[00:13:39.560 --> 00:13:43.440]   level models, there are going to be very few companies on the planet that are going
[00:13:43.440 --> 00:13:45.320]   to be able to build those models.
[00:13:45.320 --> 00:13:50.040]   Because I think the latest discussions, whether it's, you know, Stargate out of
[00:13:50.040 --> 00:13:54.560]   Microsoft, a hundred thousand GPU cluster, Elon's talking about a hundred thousand
[00:13:54.560 --> 00:13:57.120]   GPU cluster, Mark is talking about that.
[00:13:57.120 --> 00:14:00.560]   I just don't know many companies that are going to be able to compete with that.
[00:14:00.760 --> 00:14:05.120]   Yeah, I'll take maybe just a slightly tangential view to that, which is if you
[00:14:05.120 --> 00:14:11.600]   think about, you know, Meta's history in open source, open compute project, PyTorch,
[00:14:11.600 --> 00:14:15.920]   React.js, these are just infrastructure components for them, right?
[00:14:15.920 --> 00:14:19.920]   And they put the investment in so that they can drive improvements in the supply
[00:14:19.920 --> 00:14:20.440]   chain.
[00:14:20.440 --> 00:14:23.080]   They can drive the ecosystem to make it better.
[00:14:23.080 --> 00:14:26.840]   And I think they've really taken that approach with this technology and said,
[00:14:26.840 --> 00:14:30.440]   "Hey, this is a infrastructure level component that, you know, we want the
[00:14:30.440 --> 00:14:31.800]   ecosystem to make better."
[00:14:31.800 --> 00:14:37.000]   And everyone else is in the business of models, whether you're a hyperscaler or
[00:14:37.000 --> 00:14:38.960]   whether, you know, you're one of these model companies.
[00:14:38.960 --> 00:14:43.560]   And I think that's a distinctly different approach for them that puts them at an
[00:14:43.560 --> 00:14:44.240]   advantage.
[00:14:44.240 --> 00:14:47.040]   But by the way, I think this is worth drilling in on.
[00:14:47.040 --> 00:14:52.640]   So, unless one of you correct me, they are not in the cloud hosting business and
[00:14:52.640 --> 00:14:53.640]   remain not in the cloud.
[00:14:53.640 --> 00:14:54.600]   You're talking about Meta.
[00:14:54.600 --> 00:14:54.920]   Meta.
[00:14:54.920 --> 00:14:55.440]   Correct.
[00:14:55.520 --> 00:15:03.320]   And so the people that they're up against have businesses they're running based on
[00:15:03.320 --> 00:15:04.000]   these things.
[00:15:04.000 --> 00:15:10.880]   They're developing this thing, spending some number of billions and putting it out
[00:15:10.880 --> 00:15:11.920]   as open source.
[00:15:11.920 --> 00:15:18.040]   I think it's a little different than the open compute part where I don't think they
[00:15:18.040 --> 00:15:24.040]   felt the differentiation of their architecture had any impact on the strategic
[00:15:24.080 --> 00:15:28.560]   execution of their company, almost the opposite, like it's a commodity, so let's
[00:15:28.560 --> 00:15:30.160]   exploit it like a commodity.
[00:15:30.160 --> 00:15:38.320]   Here, this feels more kind of like a badass throwdown where there's a very
[00:15:38.320 --> 00:15:45.840]   intentional element of burning, you know, the strategic ground out there for
[00:15:45.840 --> 00:15:46.480]   everyone.
[00:15:46.480 --> 00:15:52.560]   You know, similar, I think, to what maybe Google did with Android when they came
[00:15:52.560 --> 00:15:59.280]   out, like just protect all around me by making it very hard to have differentiated
[00:15:59.280 --> 00:16:02.920]   products built on AI that you might come after me with.
[00:16:02.920 --> 00:16:03.680]   I mean, one of the-
[00:16:03.680 --> 00:16:04.680]   Is that fair or is that not?
[00:16:04.680 --> 00:16:07.760]   Yeah, I think it's fair, but I think I just want to make a couple of points that
[00:16:07.760 --> 00:16:13.280]   he, that Mark Zuckerberg talked about on the Dworkish podcast.
[00:16:13.280 --> 00:16:18.560]   One was, he said that they do in fact have revenue sharing relationships with the
[00:16:18.560 --> 00:16:23.440]   hyperscalers such that when they use their models, they ought to get compensated
[00:16:23.440 --> 00:16:24.120]   something for that.
[00:16:24.120 --> 00:16:27.720]   Now, he didn't go, I think he said it wasn't a very big number, but relative to
[00:16:27.720 --> 00:16:30.320]   $165 billion in revenue, nothing is a big-
[00:16:30.320 --> 00:16:31.200]   Any color on that?
[00:16:31.200 --> 00:16:32.480]   Yeah, no, nothing is a big number.
[00:16:32.480 --> 00:16:37.680]   You know, the hyperscalers have definitely been squeezing all the model
[00:16:37.680 --> 00:16:38.760]   makers, right?
[00:16:38.760 --> 00:16:42.840]   And they have a really interesting position because, you know, especially the
[00:16:42.840 --> 00:16:46.400]   ones that are creating their own because they have to create a marketplace and they
[00:16:46.400 --> 00:16:50.360]   have to ensure that they're operating sort of in a free market capacity.
[00:16:50.360 --> 00:16:53.320]   But it's difficult, right, when you have your own models, because there's
[00:16:53.320 --> 00:16:55.200]   obviously a lot of interest to drive that.
[00:16:55.200 --> 00:17:00.840]   I can definitely confirm that the data clouds are paying a revenue share to the
[00:17:00.840 --> 00:17:01.520]   open models.
[00:17:01.520 --> 00:17:05.000]   I don't know what the revenue share is, but there will be some compensation.
[00:17:05.000 --> 00:17:07.960]   And listen, that compensation can change over time.
[00:17:07.960 --> 00:17:11.120]   So that's one bit of it.
[00:17:11.120 --> 00:17:16.360]   The second thing is super important for all of us to listen to this again.
[00:17:17.200 --> 00:17:23.640]   Zuck said, "We believe in open source, but there may come a time where we have a
[00:17:23.640 --> 00:17:28.960]   discovery in our largest model, perhaps, that is fundamental and economic to our
[00:17:28.960 --> 00:17:33.120]   business, where we will elect to no longer open source said model."
[00:17:33.120 --> 00:17:37.720]   So you can see a world where they will always open source the 7B or, you know,
[00:17:37.720 --> 00:17:43.720]   he said he wants to build a 1B or a 500 million parameter model or the 70B, but
[00:17:43.720 --> 00:17:47.440]   you can also see a world where their most sophisticated model is not open source
[00:17:47.440 --> 00:17:51.240]   because he says, "Listen, I want to build the best personal AI in the world.
[00:17:51.240 --> 00:17:53.480]   It's central to what our business is about.
[00:17:53.480 --> 00:17:56.400]   We want to have the advantage associated with that."
[00:17:56.400 --> 00:18:03.040]   So I think the strategy for me, it feels like the reason the earth shook this week
[00:18:03.040 --> 00:18:10.000]   is that this felt like the most significant development and disruptive
[00:18:10.000 --> 00:18:12.200]   element in the model marketplace.
[00:18:12.200 --> 00:18:16.360]   I think it's going to be very difficult for new entrants to be venture-backed
[00:18:16.360 --> 00:18:21.360]   because to, you know, open AI will continue to get funding because they
[00:18:21.360 --> 00:18:22.880]   have this incredible team.
[00:18:22.880 --> 00:18:25.880]   They have a hundred million people using the product and paying them for the
[00:18:25.880 --> 00:18:29.280]   product, but I think for all the other closed models, they're going to have
[00:18:29.280 --> 00:18:31.360]   trouble getting follow-on financing.
[00:18:31.360 --> 00:18:34.920]   And I think any new models that come along, you would have to have something
[00:18:34.920 --> 00:18:40.080]   so different, such as orthogonal angle of attack in order to get funding.
[00:18:40.240 --> 00:18:45.040]   So I think to your point, by throwing down on the CapEx that you're going to
[00:18:45.040 --> 00:18:48.960]   spend, you are clearing the market of potential competitors, right?
[00:18:48.960 --> 00:18:51.160]   It's a very quickly depreciating asset.
[00:18:51.160 --> 00:19:00.320]   Boy, I mean, that's just so, like, unbelievable is the steepness of the
[00:19:00.320 --> 00:19:03.880]   price curve on a slightly older model.
[00:19:04.080 --> 00:19:11.000]   Like, and if people are maximizing ROI on an inference basis, they're going to
[00:19:11.000 --> 00:19:14.480]   use, they're going to take advantage of that like crazy.
[00:19:14.480 --> 00:19:15.240]   I mean, it's going to-
[00:19:15.240 --> 00:19:17.080]   We took LLAMA 2 out of Grok Cloud.
[00:19:17.080 --> 00:19:18.640]   It's not even available.
[00:19:18.640 --> 00:19:21.240]   We just took it out and replaced it with LLAMA 3 and all the
[00:19:21.240 --> 00:19:22.480]   developers went to LLAMA 3.
[00:19:22.480 --> 00:19:28.720]   But it's already, LLAMA 3 is already one 20th, one, whatever.
[00:19:28.720 --> 00:19:29.640]   Yeah.
[00:19:29.640 --> 00:19:30.760]   So there's no reason.
[00:19:30.760 --> 00:19:34.040]   Well, I mean, it seems to me where the value is again, coming back to maybe
[00:19:34.040 --> 00:19:38.880]   we'll switch to, you know, this is the right transition to talk about
[00:19:38.880 --> 00:19:45.680]   enterprise AI because the value is not in the model, right?
[00:19:45.680 --> 00:19:48.680]   Just like the value is not in storage, right?
[00:19:48.680 --> 00:19:52.680]   You could say storage is a part of the AWS cloud, but there's not a lot of
[00:19:52.680 --> 00:19:54.520]   value in that thing unto itself.
[00:19:54.520 --> 00:19:56.680]   The value is in the enterprise relationship.
[00:19:56.680 --> 00:20:01.480]   The value is in, right, the number of services that you're
[00:20:01.480 --> 00:20:02.720]   offering to your customers.
[00:20:03.000 --> 00:20:05.000]   So Microsoft and Google are out tonight.
[00:20:05.000 --> 00:20:09.720]   Both clouds accelerated their growth on the back of AI.
[00:20:09.720 --> 00:20:17.520]   64% of Fortune 500 customers are now Azure OpenAI customers, which I
[00:20:17.520 --> 00:20:18.840]   thought was pretty extraordinary.
[00:20:18.840 --> 00:20:19.320]   Big numbers.
[00:20:19.320 --> 00:20:19.640]   That's a-
[00:20:19.640 --> 00:20:23.600]   GitHub Copilot growing 35%, quarter over quarter.
[00:20:23.600 --> 00:20:26.680]   And the number of use cases seem absolutely wild.
[00:20:26.680 --> 00:20:30.400]   And what's even crazier is Satya said on the call, the revenue growth
[00:20:30.400 --> 00:20:32.960]   would be even higher, but they're GPU constrained.
[00:20:33.160 --> 00:20:34.680]   Yes, you heard me say it, Bill.
[00:20:34.680 --> 00:20:36.280]   They're GPU constrained.
[00:20:36.280 --> 00:20:37.280]   We'll come back to that.
[00:20:37.280 --> 00:20:42.200]   So I look at this and, you know, GCP is accelerating.
[00:20:42.200 --> 00:20:44.880]   Azure's accelerating.
[00:20:44.880 --> 00:20:48.240]   My assumption is you, we heard it out of ServiceNow, their
[00:20:48.240 --> 00:20:50.640]   demand, you know, is accelerating.
[00:20:50.640 --> 00:20:56.120]   So clearly enterprises are finding value in use, you know, in this.
[00:20:56.120 --> 00:20:59.720]   So Sonny, talk to us a little bit about what you're seeing.
[00:20:59.720 --> 00:21:03.720]   I know you have a hundred thousand developers in the long tail now using,
[00:21:03.720 --> 00:21:08.600]   or I think a lot of big enterprises as well, using the Grok cloud.
[00:21:08.600 --> 00:21:10.640]   But what are these enterprise use cases?
[00:21:10.640 --> 00:21:13.480]   And are you surprised when you see these hyperscalers
[00:21:13.480 --> 00:21:14.680]   racking up these numbers?
[00:21:14.680 --> 00:21:16.160]   I'm not surprised.
[00:21:16.160 --> 00:21:18.760]   And let me level up the question for a quick second into like,
[00:21:18.760 --> 00:21:20.240]   where is that spend coming from?
[00:21:20.240 --> 00:21:24.400]   And right now, and this is, you know, even verified by this report
[00:21:24.400 --> 00:21:28.080]   that Andreessen Horowitz put out a couple of weeks ago around enterprise AI.
[00:21:28.080 --> 00:21:30.840]   And what they really showed is like the distribution of use
[00:21:30.840 --> 00:21:34.680]   is coming from IT to the business units to support.
[00:21:34.680 --> 00:21:38.240]   And it's not in these innovation arms, because when usually you see
[00:21:38.240 --> 00:21:41.280]   these technologies, when they're there, you understand the budgets are limited.
[00:21:41.280 --> 00:21:42.840]   So that's awesome.
[00:21:42.840 --> 00:21:46.400]   They also just as a relative point, they showed that folks are tripling
[00:21:46.400 --> 00:21:48.480]   their AI spend this year, right?
[00:21:48.480 --> 00:21:50.880]   And so that that kind of lines up to what we're seeing there.
[00:21:50.880 --> 00:21:51.080]   Right.
[00:21:51.080 --> 00:21:52.120]   And we'll show these slides.
[00:21:52.120 --> 00:21:53.560]   Yeah, we'll show these charts there.
[00:21:53.560 --> 00:21:56.160]   And, you know, I think the most interesting thing,
[00:21:56.480 --> 00:22:00.560]   and I'll get into the use cases that 82 percent of the respondents said
[00:22:00.560 --> 00:22:04.280]   they are or either already on open source or will move to open source.
[00:22:04.280 --> 00:22:07.000]   So that's the interesting fact that's happening there.
[00:22:07.000 --> 00:22:09.840]   The use cases really.
[00:22:09.840 --> 00:22:13.200]   And, you know, let's maybe we got a little bit of alpha
[00:22:13.200 --> 00:22:17.520]   from Michael Dell a couple of weeks ago when, you know, he really talked to us
[00:22:17.520 --> 00:22:23.080]   about this use case for enterprise rag, right, where there's all this data.
[00:22:23.360 --> 00:22:26.960]   And I want to be able to reason over that data with a model.
[00:22:26.960 --> 00:22:27.600]   Right.
[00:22:27.600 --> 00:22:32.480]   And so, you know, his interests, obviously, what he's selling alongside,
[00:22:32.480 --> 00:22:33.840]   you know, his partners.
[00:22:33.840 --> 00:22:36.640]   But I think in the cloud, you're seeing that heavily happen right now.
[00:22:36.640 --> 00:22:38.240]   Customer support is number two.
[00:22:38.240 --> 00:22:40.280]   I know you guys just financed a company in this space.
[00:22:40.280 --> 00:22:43.280]   So congratulations on that deal, which is really interesting.
[00:22:43.280 --> 00:22:46.560]   And then I think content moderation and content generation.
[00:22:46.560 --> 00:22:48.960]   I think we don't really talk about it enough.
[00:22:48.960 --> 00:22:52.160]   But if you think about a business, this is happening all over the place
[00:22:52.160 --> 00:22:53.280]   all the time. Right.
[00:22:53.280 --> 00:22:57.560]   And we see a ton of use cases still there, where whether it's a daily report
[00:22:57.560 --> 00:23:00.240]   or whether it's something you send out to your customers
[00:23:00.240 --> 00:23:03.360]   and all of that coming out of those enterprise systems and being sent out.
[00:23:03.360 --> 00:23:05.040]   I mean, Bill, do you remember?
[00:23:05.040 --> 00:23:07.920]   I mean, 18 months ago, pre-chat GPT,
[00:23:07.920 --> 00:23:11.160]   I imagine less than five percent of enterprises in this,
[00:23:11.160 --> 00:23:16.040]   you know, were building AI production use cases.
[00:23:16.040 --> 00:23:21.240]   Today, I don't know an enterprise that's not at least running a test use case.
[00:23:21.240 --> 00:23:23.160]   Well, you said it was in a percentage there.
[00:23:23.160 --> 00:23:25.000]   It wasn't 100. No, no.
[00:23:25.000 --> 00:23:28.240]   But that was 64 percent using Azure.
[00:23:28.240 --> 00:23:32.160]   But I think it's probably close to 100 percent.
[00:23:32.160 --> 00:23:36.920]   I can't imagine a company in the S&P 500 that's not at least testing AI.
[00:23:36.920 --> 00:23:39.160]   Right. You would really have to be asleep.
[00:23:39.160 --> 00:23:43.560]   Do you remember any other technologies that went from zero to ubiquity this fast?
[00:23:43.560 --> 00:23:45.680]   I mean, maybe the Internet itself.
[00:23:45.680 --> 00:23:47.640]   People said, oh, my God, I got to get on the Internet.
[00:23:47.640 --> 00:23:49.760]   Mobile, mobile. I think mobile.
[00:23:50.000 --> 00:23:53.800]   Although this one, but I don't think that's a secret.
[00:23:53.800 --> 00:23:57.520]   We've talked about how the incumbents moved very quickly here.
[00:23:57.520 --> 00:24:01.480]   And I think you can give OpenAI a lot of credit because they were out
[00:24:01.480 --> 00:24:05.640]   selling the mission and out talking to the customer base
[00:24:05.640 --> 00:24:08.360]   and doing everything they could to promote.
[00:24:08.360 --> 00:24:10.400]   It's also easy to use.
[00:24:10.400 --> 00:24:12.280]   Like when you talked about some of these other technologies,
[00:24:12.280 --> 00:24:14.800]   like going to cloud was like a real effort. Right.
[00:24:14.800 --> 00:24:17.720]   Right. Using it to migrate your entire database.
[00:24:17.760 --> 00:24:20.160]   Exactly. You had to do a lot of real work.
[00:24:20.160 --> 00:24:23.120]   This is an API call. Right. Right.
[00:24:23.120 --> 00:24:24.920]   And again, credit to OpenAI.
[00:24:24.920 --> 00:24:27.280]   They're the ones that led everyone down that path.
[00:24:27.280 --> 00:24:31.320]   And everyone else now is OpenAI compatible or has a similar looking API.
[00:24:31.320 --> 00:24:32.840]   It's very easy to use.
[00:24:32.840 --> 00:24:35.480]   And part of the reason, you know, one of the things,
[00:24:35.480 --> 00:24:37.800]   you know, you mentioned, Michael Dell, he tweeted the other day
[00:24:37.800 --> 00:24:42.320]   this Barclays survey that I thought was really fascinating.
[00:24:42.320 --> 00:24:47.840]   So this is among the enterprise CIOs moving back to hybrid and on prem.
[00:24:47.840 --> 00:24:51.560]   The number was that 83 percent of respondents
[00:24:51.560 --> 00:24:56.000]   said that they were going to repatriate at least some of their workloads
[00:24:56.000 --> 00:24:57.640]   right back to on prem.
[00:24:57.640 --> 00:25:02.960]   And that was up from 49 percent or 43 percent in 2020. Right.
[00:25:02.960 --> 00:25:07.920]   And so I think it's an interesting case that you're moving back.
[00:25:07.920 --> 00:25:13.160]   My sense is it's because they don't trust certain data in the cloud. Right.
[00:25:13.160 --> 00:25:16.320]   So they want they don't want to run maybe code generation,
[00:25:16.320 --> 00:25:18.040]   you know, tools in the cloud.
[00:25:18.040 --> 00:25:20.040]   And the other one is just data gravity.
[00:25:20.040 --> 00:25:23.440]   Maybe they have on prem databases and they don't want the cost
[00:25:23.440 --> 00:25:25.640]   and the headache associated with moving that to the cloud.
[00:25:25.640 --> 00:25:29.640]   Do you see this in other parts of of your world, Sonny?
[00:25:29.640 --> 00:25:31.400]   Yeah, you know, definitely a lot.
[00:25:31.400 --> 00:25:34.760]   A third one, which is I think there's still a lack of trust.
[00:25:35.080 --> 00:25:37.000]   And this gets expanded every time.
[00:25:37.000 --> 00:25:40.840]   You know, we had that interview with the OpenAI CTO where they asked her,
[00:25:40.840 --> 00:25:42.800]   hey, have you trained this on, you know, data?
[00:25:42.800 --> 00:25:45.160]   And she didn't answer the question quite well.
[00:25:45.160 --> 00:25:47.240]   And so I think and I've heard this,
[00:25:47.240 --> 00:25:51.080]   you know, in conversation with hyperscalers where customers will not trust
[00:25:51.080 --> 00:25:53.520]   and hyperscale will legally sign that they will not train.
[00:25:53.520 --> 00:25:55.560]   They still will not trust. Right.
[00:25:55.560 --> 00:25:58.640]   They just they believe that all these stories around the data
[00:25:58.640 --> 00:26:01.080]   make these models better, that everyone is just wants a way
[00:26:01.080 --> 00:26:03.120]   to get access to that data to make the models better.
[00:26:03.360 --> 00:26:07.080]   So I think the combination of those three factors is 100 percent what we see.
[00:26:07.080 --> 00:26:10.600]   And so what what happens, you know, with us, which is just,
[00:26:10.600 --> 00:26:14.760]   you know, basically maybe a pattern, people come and try something in the cloud,
[00:26:14.760 --> 00:26:17.720]   make sure that it works and then immediately want to get on the phone
[00:26:17.720 --> 00:26:20.000]   with you and say, hey, can I can I get this on prem?
[00:26:20.000 --> 00:26:21.120]   Interesting.
[00:26:21.120 --> 00:26:22.440]   Or at least sequestered.
[00:26:22.440 --> 00:26:23.280]   Or sequestered, yeah.
[00:26:23.280 --> 00:26:25.360]   Like I use on prem as like some virtual.
[00:26:25.360 --> 00:26:28.920]   I think I thought there were two things in these podcasts
[00:26:28.920 --> 00:26:33.720]   that we keep referencing that relate to the enterprise decision making.
[00:26:33.720 --> 00:26:39.480]   One, you know, Zuck said something that kind of makes sense to me.
[00:26:39.480 --> 00:26:43.480]   He just said, like, you know, cramming data in the context
[00:26:43.480 --> 00:26:47.280]   window feels a little hacky or he I don't know what his exact words were.
[00:26:47.280 --> 00:26:52.040]   And so I think there's still this this future in front of us
[00:26:52.040 --> 00:26:57.240]   where data gets deeper integrated in the model and the trust issues there.
[00:26:57.240 --> 00:27:00.200]   And we don't quite know how that's all going to come together.
[00:27:00.200 --> 00:27:02.480]   It's still TBD. Yes.
[00:27:02.480 --> 00:27:05.680]   Yeah. And you guys probably haven't tried it because it's just not,
[00:27:05.680 --> 00:27:08.720]   you know, feasible if you're not a developer, but using like a million,
[00:27:08.720 --> 00:27:12.600]   you know, contact like a context window of like a million tokens.
[00:27:12.600 --> 00:27:14.280]   It's like really hard.
[00:27:14.280 --> 00:27:17.040]   Yes. You can't use it up, you're saying.
[00:27:17.040 --> 00:27:18.440]   Well, you can use it up.
[00:27:18.440 --> 00:27:21.440]   But the amount of gathering and work you have to do to get a million to,
[00:27:21.440 --> 00:27:23.840]   you know, think about it's like several books, you know.
[00:27:24.040 --> 00:27:27.240]   And so, you know, people talk about it like it's this wonderful thing,
[00:27:27.240 --> 00:27:29.920]   but it's not it's not, you know, overly usable.
[00:27:29.920 --> 00:27:33.880]   And then the other one, I thought the most interesting thing out of the the
[00:27:33.880 --> 00:27:40.160]   the Sam podcast was he talked about whether or not developers
[00:27:40.160 --> 00:27:43.840]   were kind of going wholesale on top of open
[00:27:43.840 --> 00:27:47.200]   AI or whether they were just using it in a lightweight way
[00:27:47.200 --> 00:27:49.720]   and then doing a bunch of stuff externally.
[00:27:50.600 --> 00:27:54.440]   And he implied that most people are doing the latter.
[00:27:54.440 --> 00:27:58.040]   But then he said, if you do that, we're going to steamroll you
[00:27:58.040 --> 00:28:00.560]   and you need to bet on us being successful.
[00:28:00.560 --> 00:28:07.160]   And which would mean dumping your data and and trusting open AI more fully.
[00:28:07.160 --> 00:28:10.360]   I don't know. What was your interpretation of what he was trying?
[00:28:10.360 --> 00:28:12.560]   It was exactly that, plus the following.
[00:28:12.560 --> 00:28:15.280]   If you if you take his, you know, take him for what he was saying,
[00:28:15.280 --> 00:28:17.080]   which is the models are going to get better.
[00:28:17.080 --> 00:28:19.080]   Well, what room does it leave for anything else?
[00:28:19.640 --> 00:28:23.720]   Because if you shouldn't be taking a model and wrapping it with your own,
[00:28:23.720 --> 00:28:26.440]   you know, your own code or your own technology or framework,
[00:28:26.440 --> 00:28:28.480]   and then you're going to assume the model gets better.
[00:28:28.480 --> 00:28:29.600]   Well, why do you need what?
[00:28:29.600 --> 00:28:32.400]   Why do you need whatever I'm building if the model can just do everything?
[00:28:32.400 --> 00:28:36.680]   I actually I actually thought Sam and Brad were really articulate
[00:28:36.680 --> 00:28:39.800]   on this point, whether you believe them or not.
[00:28:39.800 --> 00:28:43.600]   And I think it was consistent with the tweet that Aaron Levy sent out yesterday,
[00:28:43.600 --> 00:28:47.720]   which is people are not thinking ambitiously enough
[00:28:48.120 --> 00:28:50.200]   as to where these things are going.
[00:28:50.200 --> 00:28:53.920]   And, you know, today we're really in the land of answers, right?
[00:28:53.920 --> 00:28:56.480]   We're running some rag over some, you know,
[00:28:56.480 --> 00:29:00.000]   HR data that we have in our company and building a little chat bot
[00:29:00.000 --> 00:29:03.520]   so it can answer questions more efficiently than my HR group can
[00:29:03.520 --> 00:29:04.720]   can answer questions.
[00:29:04.720 --> 00:29:07.200]   But they're saying it really needs to think about agentic thinking.
[00:29:07.200 --> 00:29:10.760]   Like, what is that multistep reasoning that can be done in the business?
[00:29:10.760 --> 00:29:14.160]   And, you know, I know how big your HR group.
[00:29:14.160 --> 00:29:16.560]   Well, here it's pretty easy to do.
[00:29:16.560 --> 00:29:18.080]   Here it's pretty easy to do.
[00:29:18.080 --> 00:29:22.320]   But, you know, so my sense is that
[00:29:22.320 --> 00:29:27.000]   I'm kind of in this Aaron Levy camp that when you look out two or three years.
[00:29:27.000 --> 00:29:30.840]   I mean, listen, every week we're blown away
[00:29:30.840 --> 00:29:33.720]   by, you know, how these models are progressing.
[00:29:33.720 --> 00:29:37.440]   It's hard for me to think in three years at the rate of progress
[00:29:37.440 --> 00:29:39.600]   and the amount of investment that's going into this,
[00:29:39.600 --> 00:29:42.560]   that we're not going to be a lot further down the path in terms of this
[00:29:42.560 --> 00:29:44.680]   in terms of this reasoning.
[00:29:44.680 --> 00:29:47.360]   And when we get there, I think people are going to want that
[00:29:47.360 --> 00:29:50.000]   to be more proprietary, because I think the advantages
[00:29:50.000 --> 00:29:53.600]   that are going to inure to the enterprise are even more.
[00:29:53.600 --> 00:29:56.560]   Let me throw one other thing in here.
[00:29:56.560 --> 00:29:59.200]   You know, I was sitting with my team this week and we're trying to figure out
[00:29:59.200 --> 00:30:03.400]   who are the winners and losers, not of the providers of the arms,
[00:30:03.400 --> 00:30:05.760]   but the buyers of the arms. OK.
[00:30:05.760 --> 00:30:09.280]   So if every Fortune 500 company is buying AI,
[00:30:09.280 --> 00:30:13.960]   one of the things that Bill often reminds me is fine.
[00:30:14.000 --> 00:30:18.000]   It will give a little improvement to an airline that starts using AI.
[00:30:18.000 --> 00:30:20.720]   But airlines are a competitive industry
[00:30:20.720 --> 00:30:22.880]   and they're just going to compete away all the profits.
[00:30:22.880 --> 00:30:24.560]   And so that's a defensive move, right?
[00:30:24.560 --> 00:30:27.080]   You don't actually improve the business model
[00:30:27.080 --> 00:30:29.200]   because all the earnings get competed away.
[00:30:29.200 --> 00:30:32.960]   So what you want to find is a market leader, somebody who has 70
[00:30:32.960 --> 00:30:37.800]   or 80 percent of a given market who gets to hang on, right, to all of this.
[00:30:37.800 --> 00:30:40.520]   Or compound their lead. Right. Or compound their lead.
[00:30:40.520 --> 00:30:43.680]   And so, you know, there's a company coming public
[00:30:43.680 --> 00:30:47.920]   in a few weeks called Lineage, which is in the cold storage business.
[00:30:47.920 --> 00:30:51.240]   So they basically are an integral part of the food supply chain.
[00:30:51.240 --> 00:30:55.760]   You know, any refrigerated storage of, you know, a food.
[00:30:55.760 --> 00:30:58.440]   And I think they have a huge percentage of the market.
[00:30:58.440 --> 00:31:03.360]   And I think they have 50 data analysts and scientists now in San Francisco,
[00:31:03.360 --> 00:31:07.120]   because if they can turn the screw a quarter of an inch on spoilage,
[00:31:07.120 --> 00:31:11.160]   a quarter of an inch on energy consumption to keep this food
[00:31:11.160 --> 00:31:13.720]   all bottom line, and so it's all to their bottom line.
[00:31:13.720 --> 00:31:16.280]   And by the way, it doesn't get competed away. Yeah. Right.
[00:31:16.280 --> 00:31:19.800]   And so they're looking at leveraging, you know, I happen to know
[00:31:19.800 --> 00:31:23.640]   because they were a Snowflake customer and they were using some Snowflake
[00:31:23.640 --> 00:31:27.600]   AI, you know, to improve these use cases.
[00:31:27.600 --> 00:31:30.400]   And so I think they're going to be a whole host of businesses, Bill,
[00:31:30.400 --> 00:31:33.920]   industrial businesses that capture some of these profits
[00:31:33.920 --> 00:31:35.320]   and get to hold on to them.
[00:31:35.320 --> 00:31:38.880]   I'd be interested in Sonny's reaction to to your question
[00:31:38.880 --> 00:31:42.720]   and maybe to my answer, which is I
[00:31:42.720 --> 00:31:46.720]   when when I meet a company
[00:31:46.720 --> 00:31:51.120]   and see them using AI in a way that feels like ultra compelling
[00:31:51.120 --> 00:31:54.720]   from us, improvement of their own strategic business position.
[00:31:54.720 --> 00:31:58.800]   It's almost always a more traditional AI model
[00:31:58.800 --> 00:32:03.240]   that's running a very particular optimization problem.
[00:32:03.240 --> 00:32:05.240]   It's not an LLM application.
[00:32:06.320 --> 00:32:09.200]   And this stuff's all happening simultaneously.
[00:32:09.200 --> 00:32:12.000]   You know, I think I think that I think that's true.
[00:32:12.000 --> 00:32:15.600]   I don't think it particularly matters because what generative AI has done,
[00:32:15.600 --> 00:32:20.160]   what the chat moment has done is it's caused every enterprise
[00:32:20.160 --> 00:32:23.360]   to get off their ass to get all their data organized
[00:32:23.360 --> 00:32:26.600]   because that's a condition required to benefit from any of this stuff.
[00:32:26.600 --> 00:32:31.320]   But then I think what they do figure out along the way is some basic,
[00:32:31.320 --> 00:32:36.040]   you know, machine learning around time series or forecasting
[00:32:36.200 --> 00:32:38.480]   or things that have been around for quite a while, Bill,
[00:32:38.480 --> 00:32:42.120]   is where they get the most bang for the buck, maybe not from the generative AI,
[00:32:42.120 --> 00:32:45.320]   but they might get there because they got into the pool
[00:32:45.320 --> 00:32:47.840]   because they were motivated by generative AI.
[00:32:47.840 --> 00:32:51.440]   I certainly think it's an accelerant based on everything we're seeing.
[00:32:51.440 --> 00:32:53.960]   Yeah. You know, I'll disagree with you.
[00:32:53.960 --> 00:32:58.280]   I think, you know, what what this technology really enables is,
[00:32:58.280 --> 00:33:00.840]   you know, we get spoiled in Silicon Valley
[00:33:00.840 --> 00:33:03.960]   because we can get the best engineers to build like the most difficult things.
[00:33:04.280 --> 00:33:08.080]   But I think for the average business to do most problems,
[00:33:08.080 --> 00:33:12.240]   whether it was, you know, pre generative AI was very, very difficult.
[00:33:12.240 --> 00:33:15.200]   Now you can basically take a generative AI model
[00:33:15.200 --> 00:33:19.120]   and have it do one of the most advanced things in the world.
[00:33:19.120 --> 00:33:21.720]   And, you know, we've shared an example in our chat, right,
[00:33:21.720 --> 00:33:24.600]   where you can take a picture of a plate of food
[00:33:24.600 --> 00:33:27.600]   and tell it to return to you what's in that food
[00:33:27.600 --> 00:33:30.120]   and how many calories might it be and what's the portion size.
[00:33:30.120 --> 00:33:33.240]   Right. That's done sort of, again, with one prompt.
[00:33:33.520 --> 00:33:36.960]   And so now you've given that ability to every business, every small business.
[00:33:36.960 --> 00:33:38.920]   Right. It's like this business you're talking about.
[00:33:38.920 --> 00:33:42.720]   They can do a lot of improvements without having to have 50 people in San Francisco.
[00:33:42.720 --> 00:33:45.200]   So I think that's where the improvements are really going to come.
[00:33:45.200 --> 00:33:48.760]   Although I could push back on you and use your own
[00:33:48.760 --> 00:33:51.920]   statement about open AI.
[00:33:51.920 --> 00:33:57.600]   And if they achieve everything like what they may be commoditized just because.
[00:33:57.600 --> 00:34:00.920]   Well, someone still has to take it and apply it to that business. Right.
[00:34:00.920 --> 00:34:03.960]   And it may just be the one, you know, the one tech person in that business.
[00:34:03.960 --> 00:34:07.080]   It's a I was on a walk last weekend
[00:34:07.080 --> 00:34:11.440]   with a great economist over at Stanford, and we were talking about
[00:34:11.440 --> 00:34:14.800]   whether or not about the amount of productivity improvement
[00:34:14.800 --> 00:34:17.320]   that would be unleashed into the economy because of AI.
[00:34:17.320 --> 00:34:20.960]   And what was interesting is, you know, productivity
[00:34:20.960 --> 00:34:24.120]   has actually been under assault in this country
[00:34:24.120 --> 00:34:27.760]   because we've limited immigration, which was a huge source of productivity
[00:34:28.520 --> 00:34:32.360]   because de-globalization is actually hurting productivity
[00:34:32.360 --> 00:34:36.280]   because we're not moving the productions of goods and services
[00:34:36.280 --> 00:34:39.560]   to the lowest cost places, you know, anything that's causing friction.
[00:34:39.560 --> 00:34:42.520]   So it's like all the goodness to come out of AI.
[00:34:42.520 --> 00:34:45.440]   We need it just to replace the headwinds
[00:34:45.440 --> 00:34:48.120]   that we have on productivity in other places.
[00:34:48.120 --> 00:34:51.080]   But I digress. Let's move on to the.
[00:34:51.080 --> 00:34:54.400]   Well, can I add one thing to that, which is I think just building
[00:34:54.400 --> 00:34:56.720]   on the point that you said, like Aaron Levy was talking about,
[00:34:56.720 --> 00:34:58.560]   we're not thinking about it big enough.
[00:34:58.560 --> 00:35:02.280]   And, you know, where I where I, you know, someone share this on Twitter
[00:35:02.280 --> 00:35:03.800]   and I can't find the original author.
[00:35:03.800 --> 00:35:08.000]   But if we can, some point we'll share it, which is in the industrial revolution.
[00:35:08.000 --> 00:35:11.320]   You saw, you know, car making go from something bespoke
[00:35:11.320 --> 00:35:13.840]   one car per day to a factory making a thousand.
[00:35:13.840 --> 00:35:16.040]   Same for clothing, same for farms.
[00:35:16.040 --> 00:35:19.120]   And, you know, we've looked at technology as this huge accelerant,
[00:35:19.120 --> 00:35:22.560]   but we really haven't had the industrial revolution for technology.
[00:35:22.560 --> 00:35:24.360]   It's still pretty bespoke.
[00:35:24.360 --> 00:35:28.240]   You know, one developer writing code and and now you have this idea where,
[00:35:28.240 --> 00:35:31.080]   you know, go back to a place where you spend a lot of time travel search.
[00:35:31.080 --> 00:35:35.400]   Right. You could have one agent do a thousand or an agent
[00:35:35.400 --> 00:35:38.680]   and a thousand instances of it, do a thousand searches for you
[00:35:38.680 --> 00:35:40.320]   and find what you're looking for.
[00:35:40.320 --> 00:35:42.600]   We haven't seen that in technology yet.
[00:35:42.600 --> 00:35:45.800]   And I think that's that's the era we're really about to go into,
[00:35:45.800 --> 00:35:48.640]   which ties back to, you know, the point that you said
[00:35:48.640 --> 00:35:52.680]   that you were having on your walk around efficiency for for for society.
[00:35:52.720 --> 00:35:55.480]   Yeah, I mean, I think I think about it in the context
[00:35:55.480 --> 00:35:58.080]   of what we've called business intelligence, right?
[00:35:58.080 --> 00:36:00.440]   We've been investors in companies like Tableau,
[00:36:00.440 --> 00:36:04.480]   you know, obviously Snowflake, et cetera, over the years.
[00:36:04.480 --> 00:36:08.440]   And, you know, it's not really business intelligence, right?
[00:36:08.440 --> 00:36:11.720]   Issuing me a report that tells me how many black T-shirts
[00:36:11.720 --> 00:36:15.680]   I sold yesterday, right, is nice, but it's not all that informative.
[00:36:15.680 --> 00:36:19.240]   What you would like is an agent to scour all of your data,
[00:36:19.520 --> 00:36:22.480]   compare it to all the data of other companies and say,
[00:36:22.480 --> 00:36:26.880]   here's something that is anomalous or we can predict something
[00:36:26.880 --> 00:36:30.880]   or suggest something based upon patterns we're seeing in other businesses.
[00:36:30.880 --> 00:36:34.760]   That's all. You know, we've been talking about that for a decade, right?
[00:36:34.760 --> 00:36:37.400]   I actually think we're getting a lot closer to that moment
[00:36:37.400 --> 00:36:40.280]   where now we're going to be able to have these resources,
[00:36:40.280 --> 00:36:42.360]   because what are these things do really well, Bill?
[00:36:42.360 --> 00:36:44.320]   They devour data.
[00:36:44.320 --> 00:36:47.160]   They spot patterns and they predict. Yes. Right.
[00:36:47.200 --> 00:36:50.200]   Take what you said times a thousand shouldn't be a single age.
[00:36:50.200 --> 00:36:52.280]   It could be a thousand of them doing it on your data.
[00:36:52.280 --> 00:36:55.200]   We beat up what it's going to do in the enterprise.
[00:36:55.200 --> 00:36:58.440]   But, you know, one of the areas that I'm even more excited about
[00:36:58.440 --> 00:37:01.520]   as these models get smaller is what it's going to mean
[00:37:01.520 --> 00:37:04.480]   for personal search and personal AI.
[00:37:04.480 --> 00:37:09.000]   So when we think about that, you know, Google reported tonight
[00:37:09.000 --> 00:37:12.640]   they had billions of what they call their SGE searches.
[00:37:12.640 --> 00:37:15.840]   So these are, you know, their AI searches.
[00:37:16.520 --> 00:37:19.840]   They talked about dramatically driving down the cost of inference
[00:37:19.840 --> 00:37:23.280]   of those searches that you can probably tell us a little about.
[00:37:23.280 --> 00:37:26.760]   You know, Meta has rolled out search across all of their apps.
[00:37:26.760 --> 00:37:30.760]   There's a search bar on Facebook, on IG, on WhatsApp.
[00:37:30.760 --> 00:37:32.840]   And you can search any topic.
[00:37:32.840 --> 00:37:36.680]   You can go there and say, hey, show me the recipe for fried chicken
[00:37:36.680 --> 00:37:41.440]   or show me how to, you know, play a guitar or show me where I should stay
[00:37:41.440 --> 00:37:43.920]   at a hotel, you know, when I'm visiting Milan.
[00:37:44.400 --> 00:37:49.240]   And Zuck did say in his announcement, kind of as a shot across the bow
[00:37:49.240 --> 00:37:53.880]   at Claude and at ChatGPT
[00:37:53.880 --> 00:37:58.360]   that they had the most cap, the most capable, free
[00:37:58.360 --> 00:38:02.200]   personal assistant, right, you know, that you could get out there.
[00:38:02.200 --> 00:38:06.480]   You know, we had Apple announce Open ELM, which were these models
[00:38:06.480 --> 00:38:09.920]   from 270 million parameters to three billion parameters.
[00:38:09.920 --> 00:38:13.440]   You know, it seems like the next step that everybody's looking at
[00:38:13.520 --> 00:38:17.160]   is really the smaller models that can get us to,
[00:38:17.160 --> 00:38:21.240]   you know, a personal assistant on device, whether it's on phone,
[00:38:21.240 --> 00:38:23.520]   whether it's on glasses, et cetera.
[00:38:23.520 --> 00:38:28.240]   So when you looked at the announcements this week, you can go to either of you.
[00:38:28.240 --> 00:38:33.320]   It felt to me like the disruption caused by LLAMA 3
[00:38:33.320 --> 00:38:37.160]   was almost more impactful to what we're going to see
[00:38:37.160 --> 00:38:41.440]   along the lines of consumer AI and search than it was in the enterprise.
[00:38:41.440 --> 00:38:43.600]   Any thoughts about that?
[00:38:43.600 --> 00:38:47.040]   Yeah, I think, you know, it ties back to a point we touched on earlier, right?
[00:38:47.040 --> 00:38:50.720]   The as we make smaller models more capable
[00:38:50.720 --> 00:38:54.520]   and we make even smaller and smaller models that can maybe reference
[00:38:54.520 --> 00:38:59.520]   those larger models, we're on to a place where it becomes more affordable.
[00:38:59.520 --> 00:39:02.480]   Right. What we don't really think about, you know,
[00:39:02.480 --> 00:39:06.160]   if you think about the larger models is even so crazy.
[00:39:06.160 --> 00:39:07.920]   It's like a year ago. Right.
[00:39:07.920 --> 00:39:10.200]   You know, all the way back a year ago, back a year ago.
[00:39:10.360 --> 00:39:15.600]   You're using a, you know, thirty thousand dollar plus unit of compute
[00:39:15.600 --> 00:39:18.640]   to run this thing with, you know, hundreds of gigabytes of memory.
[00:39:18.640 --> 00:39:22.200]   Now, whether you look at the Apple stuff or fi
[00:39:22.200 --> 00:39:25.280]   that came out of Microsoft, you can run that on your phone.
[00:39:25.280 --> 00:39:26.840]   People are already running it on their phone.
[00:39:26.840 --> 00:39:30.200]   I saw a demo of some folks running it in Apple Vision Pro. Right.
[00:39:30.200 --> 00:39:32.440]   No specialized hardware. Right.
[00:39:32.440 --> 00:39:35.080]   And the key is, you know, if we're going to run it on the phone,
[00:39:35.080 --> 00:39:39.080]   we got to compress all of that intelligence into a smaller
[00:39:39.080 --> 00:39:42.600]   and smaller model that's less power consumptive. Right.
[00:39:42.600 --> 00:39:46.080]   If you put one of these larger models on, it burns up the battery,
[00:39:46.080 --> 00:39:49.720]   burns up the phone, too much heat, you know, generated by that.
[00:39:49.720 --> 00:39:53.920]   Bill, you referenced a quote, you know, Zuck from Dworkash, where he said,
[00:39:53.920 --> 00:39:56.680]   I don't think in the future we're going to be primarily shoving
[00:39:56.680 --> 00:40:00.160]   all these things in the context window to ask more complicated questions.
[00:40:00.160 --> 00:40:03.720]   There will be a different stores of memory or different custom models
[00:40:03.720 --> 00:40:06.080]   that are more personalized to people.
[00:40:06.520 --> 00:40:09.840]   One of the things that I was most intrigued by in that interview
[00:40:09.840 --> 00:40:13.120]   was his focus on the personalization to people.
[00:40:13.120 --> 00:40:17.480]   He went so far as to say, understanding the content around emotions
[00:40:17.480 --> 00:40:23.040]   is a different modality unto itself, which got me thinking, you know,
[00:40:23.040 --> 00:40:26.800]   not only are they producing smaller models, but they probably have
[00:40:26.800 --> 00:40:29.280]   the largest store of human emotions.
[00:40:29.280 --> 00:40:33.320]   What reactions to one another emoticons to one another?
[00:40:34.240 --> 00:40:38.040]   You know, biggest, certainly social graph on the planet,
[00:40:38.040 --> 00:40:41.280]   which seems to put them in a really good position
[00:40:41.280 --> 00:40:45.400]   when it comes to this personal assistant that we all talk about.
[00:40:45.400 --> 00:40:48.560]   I know you your view is we're not going to get anywhere close
[00:40:48.560 --> 00:40:51.440]   until we get memory and we haven't solved memory.
[00:40:51.440 --> 00:40:54.320]   Well, I mean, he hinted at it, but everyone hints at it.
[00:40:54.320 --> 00:40:55.520]   It comes up a lot.
[00:40:55.520 --> 00:41:00.960]   And there's a and I mean, I push it to Sonny, but it's unclear
[00:41:01.360 --> 00:41:03.960]   whether you can accomplish what people hope
[00:41:03.960 --> 00:41:09.120]   to be achieved in a personal assistant with rag, with fine tuning,
[00:41:09.120 --> 00:41:12.960]   or if you really need a model to be actually,
[00:41:12.960 --> 00:41:15.720]   you know, trained on my data.
[00:41:15.720 --> 00:41:19.800]   And that latter part, no one knows how to do a fat cost effectively.
[00:41:19.800 --> 00:41:21.800]   Yeah. So I don't know.
[00:41:21.800 --> 00:41:25.520]   I don't know what pieces have to fall in place for us to get to that place.
[00:41:25.520 --> 00:41:27.760]   Yeah. And there's no secret.
[00:41:27.760 --> 00:41:31.240]   Like everyone seems to be aware that that's the end goal.
[00:41:31.240 --> 00:41:34.600]   But I don't I think there are a few breadcrumbs that were.
[00:41:34.600 --> 00:41:37.600]   I don't know if you say, you know, I'll suggest some of them.
[00:41:37.600 --> 00:41:40.520]   Maybe you can say a few breadcrumbs that were dropped out there,
[00:41:40.520 --> 00:41:44.680]   both by Apple and by by Zuckerberg in this regard.
[00:41:44.680 --> 00:41:48.520]   I mean, I'll just kick it off by saying what he said in that podcast is like,
[00:41:48.520 --> 00:41:53.400]   listen, in the first instance, what we do is we build software around the model
[00:41:53.400 --> 00:41:57.560]   that kind of hacks this stuff together and we see kind of what works.
[00:41:57.560 --> 00:42:01.520]   And so, yes, in the first instance, it may in fact be
[00:42:01.520 --> 00:42:04.480]   you have a really small model, you do some rag on it.
[00:42:04.480 --> 00:42:08.880]   Maybe in certain instances it communicates with a more sophisticated model.
[00:42:08.880 --> 00:42:13.480]   But in that, you know, in that rag can be a lot of personal information.
[00:42:13.480 --> 00:42:15.880]   I think Apple has said the same thing.
[00:42:15.880 --> 00:42:19.240]   But then what he importantly said is if that works,
[00:42:19.240 --> 00:42:23.560]   then on the next go around, we figure out how to build that into the model itself.
[00:42:23.560 --> 00:42:28.160]   Yeah, I think building on that, if you look at the breadcrumbs
[00:42:28.160 --> 00:42:30.960]   from, you know, all the major folks, and I think there was like a
[00:42:30.960 --> 00:42:33.920]   a Wired article that came out where Sam said, you know,
[00:42:33.920 --> 00:42:36.080]   the next model necessarily won't be bigger.
[00:42:36.080 --> 00:42:37.200]   I think he did say that.
[00:42:37.200 --> 00:42:38.240]   I thought that was interesting.
[00:42:38.240 --> 00:42:41.240]   Yeah. And I and the reason is,
[00:42:41.240 --> 00:42:45.280]   and you know, you had a thing, Brad, last year at the Barn
[00:42:45.280 --> 00:42:48.400]   where you had Brad Lightcaps being right.
[00:42:48.400 --> 00:42:52.800]   And the general message that keeps coming out of the open
[00:42:52.800 --> 00:42:56.960]   AI contingent is that customization and memory.
[00:42:56.960 --> 00:43:01.200]   And so my and I don't have anything beyond this, but I would say my guess is
[00:43:01.200 --> 00:43:04.960]   that's what they focused on with GPT-5.
[00:43:04.960 --> 00:43:06.360]   That's an important point.
[00:43:06.360 --> 00:43:10.640]   Like, I think in GPT-5, it's not going to be the final state,
[00:43:10.640 --> 00:43:12.480]   but I think you're going to see the beginnings of memory
[00:43:12.480 --> 00:43:14.280]   and the beginnings of actions. Right.
[00:43:14.280 --> 00:43:15.720]   And this is, you know, months away.
[00:43:15.720 --> 00:43:17.920]   And you and I have a bet on this. I know.
[00:43:18.040 --> 00:43:22.200]   Well, well, yeah, but that could be a major another, you know, tremor.
[00:43:22.200 --> 00:43:25.640]   But one is one interpretation of the statement
[00:43:25.640 --> 00:43:27.720]   that the models aren't going to get bigger.
[00:43:27.720 --> 00:43:30.360]   One, it could be a mea culpa to the thing.
[00:43:30.360 --> 00:43:33.480]   Like, OK, like, I don't want to play this game anymore.
[00:43:33.480 --> 00:43:37.680]   But two, it could mean that the the LLM
[00:43:37.680 --> 00:43:42.920]   training has kind of just run its course and you got to go do this next thing.
[00:43:43.240 --> 00:43:50.000]   But the next thing is not a necessarily an exponential leap.
[00:43:50.000 --> 00:43:53.160]   It may it may be like an early alpha or beta,
[00:43:53.160 --> 00:43:55.800]   and it may be a little more stumbly as you.
[00:43:55.800 --> 00:44:00.640]   I don't think I see little evidence that the scaling has run its course.
[00:44:00.640 --> 00:44:02.840]   I mean, like the smartest people on the planet
[00:44:02.840 --> 00:44:05.880]   who are putting their own money, real money up against this.
[00:44:05.880 --> 00:44:11.360]   Elon is building a much, much bigger cluster to train a much, much bigger model
[00:44:11.640 --> 00:44:14.280]   as is open AI, as is Zuckerberg.
[00:44:14.280 --> 00:44:17.680]   I mean, what Sam just said, the bigger models aren't.
[00:44:17.680 --> 00:44:21.320]   Well, I mean, he may be doing the same game that everybody else is doing.
[00:44:21.320 --> 00:44:25.200]   I'm trying to throw everybody off the scent of building a bigger model.
[00:44:25.200 --> 00:44:28.360]   Why is he trying to build his own chips, nuclear power plants
[00:44:28.360 --> 00:44:30.960]   and everything else if he's not going to build big models?
[00:44:30.960 --> 00:44:32.960]   I mean, you only don't take him at his word.
[00:44:32.960 --> 00:44:37.040]   Well, I'm just saying that I think the world, as I said earlier,
[00:44:37.040 --> 00:44:41.080]   is bifurcating into two like a world of specialized models.
[00:44:41.280 --> 00:44:43.640]   We are going to have very large frontier models.
[00:44:43.640 --> 00:44:47.240]   There will be a point at which you hit the you hit diminishing returns.
[00:44:47.240 --> 00:44:50.840]   Jan LeCun has said we're going to need a different architecture to get to AGI.
[00:44:50.840 --> 00:44:54.040]   He speculated that it's probably two or three generations
[00:44:54.040 --> 00:44:57.480]   more of scaling before we get to that point
[00:44:57.480 --> 00:45:01.280]   where it no longer makes economic sense to continue to scale it.
[00:45:01.280 --> 00:45:05.040]   But we're going to I mean, that's a lot of if it continues apace.
[00:45:05.040 --> 00:45:09.280]   That's a lot of developments over the course of the next two, three
[00:45:09.280 --> 00:45:11.960]   generations before we hit the upper limits of that.
[00:45:11.960 --> 00:45:15.280]   And by the way, I think we're already seeing some creative things
[00:45:15.280 --> 00:45:20.080]   like the data scaling that we saw, you know, past the chinchilla point.
[00:45:20.080 --> 00:45:22.960]   Those are really creative innovations to get around
[00:45:22.960 --> 00:45:25.640]   or to augment kind of the compute problem.
[00:45:25.640 --> 00:45:30.840]   So to me, I come back to this and I, you know,
[00:45:30.840 --> 00:45:35.000]   it makes me really excited again about where we are
[00:45:35.000 --> 00:45:37.880]   in this state of consumer search,
[00:45:37.880 --> 00:45:41.120]   you know, and personal assistance.
[00:45:41.120 --> 00:45:43.520]   Google's probably innovating better than they ever have
[00:45:43.520 --> 00:45:47.080]   because they're pushed out of their monopoly position by everybody else.
[00:45:47.080 --> 00:45:50.840]   Now, it sounds like, you know, they're seeing some great results
[00:45:50.840 --> 00:45:52.440]   come out of that.
[00:45:52.440 --> 00:45:55.880]   You know, I thought it was really interesting, you know, when you see,
[00:45:55.880 --> 00:46:00.640]   you know, Dolly and and and David Woodland, who's the product lead on on
[00:46:00.640 --> 00:46:03.640]   on Metaglass's talk about what they announced this week.
[00:46:03.640 --> 00:46:05.720]   Now it has meta AI with vision.
[00:46:05.720 --> 00:46:08.080]   It's, you know, now available to everybody.
[00:46:08.080 --> 00:46:12.000]   You know, not only can you use these things to call and to message
[00:46:12.000 --> 00:46:16.800]   using WhatsApp, but as all these integrations and these overlays.
[00:46:16.800 --> 00:46:20.840]   So, I mean, we haven't seen this kind of shake up in the world of search
[00:46:20.840 --> 00:46:24.000]   and in the world of consumer products in a while.
[00:46:24.000 --> 00:46:29.080]   And now, you know, there was this all this noise this week about Humane.
[00:46:29.080 --> 00:46:31.680]   Yep. Right. The startup up in San Francisco.
[00:46:31.680 --> 00:46:34.440]   And, you know, it got panned in a consumer review,
[00:46:34.440 --> 00:46:39.200]   you know, and one of the biggest challenges with that product,
[00:46:39.200 --> 00:46:42.880]   because I use the product as well, right, is the models weren't small enough.
[00:46:42.880 --> 00:46:46.560]   It doesn't have it can't run the inference on device.
[00:46:46.560 --> 00:46:48.400]   So it has to go out to the cloud to do it.
[00:46:48.400 --> 00:46:51.560]   And the second you have to go out to the cloud, it ruins the experience
[00:46:51.560 --> 00:46:52.840]   because now you have latency.
[00:46:52.840 --> 00:46:57.560]   We're a year away, probably max from that thing, being able to have a billion
[00:46:57.560 --> 00:47:01.640]   parameter or 500 million parameter model that basically has all the capability
[00:47:01.640 --> 00:47:03.880]   you need it to have. Totally agree.
[00:47:03.880 --> 00:47:07.000]   And we're also compressing
[00:47:07.000 --> 00:47:11.080]   the amount of time that it takes to go out to the cloud
[00:47:11.080 --> 00:47:13.320]   because we'll get those models to start running faster.
[00:47:13.320 --> 00:47:16.840]   So we're going to see a convergence there on two fronts, the local
[00:47:16.840 --> 00:47:19.440]   and then the ability for that model to reach out in the cloud
[00:47:19.440 --> 00:47:21.160]   and get a faster response out of the cloud.
[00:47:21.160 --> 00:47:26.040]   That's what I think, you know, is being underestimated.
[00:47:26.240 --> 00:47:30.000]   You know, just swinging back around to model size, right.
[00:47:30.000 --> 00:47:32.680]   The smaller models run faster just naturally.
[00:47:32.680 --> 00:47:36.280]   And so that gets you to faster responses.
[00:47:36.280 --> 00:47:40.720]   And we know the Internet's been on a huge push for lower latency
[00:47:40.720 --> 00:47:44.160]   across whether it's loading web pages or search results or whatever it is.
[00:47:44.160 --> 00:47:46.600]   And so I think we're starting to see a push in that direction.
[00:47:46.600 --> 00:47:51.280]   We all got kind of comfortable with the pace of chat GPT.
[00:47:51.280 --> 00:47:54.800]   But if you kind of go away for a second and try one of these smaller models
[00:47:54.800 --> 00:47:58.040]   somewhere else and go back to chat GPT, you'll really have that.
[00:47:58.040 --> 00:48:01.680]   Like we all had that moment for a bit between dial up and high speed Internet
[00:48:01.680 --> 00:48:04.280]   where we maybe had dial up at home, still in high speed at work.
[00:48:04.280 --> 00:48:07.440]   That's the feeling that you get when you switch between those two things.
[00:48:07.440 --> 00:48:11.000]   One of the debates I know, Sonny, you've been having, you know, with our team
[00:48:11.000 --> 00:48:15.680]   and I'm firmly, you know, in your camp on is, you know, this idea
[00:48:15.680 --> 00:48:19.720]   dating back 20 years when it comes to consumer products, even,
[00:48:20.640 --> 00:48:25.080]   you know, speed improvements that are barely perceptible
[00:48:25.080 --> 00:48:29.480]   at Google have pretty important implications for their revenue.
[00:48:29.480 --> 00:48:34.160]   And so I think what we're seeing with these smaller models
[00:48:34.160 --> 00:48:36.480]   and all of these other developments and you guys are helping,
[00:48:36.480 --> 00:48:39.800]   you know, certainly to lead the way at Grok, you're just seeing massive
[00:48:39.800 --> 00:48:41.840]   improvements in token per second.
[00:48:41.840 --> 00:48:45.440]   And I think, you know, when you start having agents talk to agents,
[00:48:45.440 --> 00:48:47.920]   you take humans out of the loop, right?
[00:48:47.920 --> 00:48:51.200]   Now, computers can talk really fast to one another,
[00:48:51.200 --> 00:48:55.360]   but we have to have low cost, fast inference, you know, that's able to support that.
[00:48:55.360 --> 00:48:58.000]   We do. And we think of the use cases that we all like.
[00:48:58.000 --> 00:49:00.120]   And I think we all love perplexity.
[00:49:00.120 --> 00:49:02.920]   But you think about, you know, what happens behind the scenes
[00:49:02.920 --> 00:49:06.200]   when you type like a small request, it shoots off something
[00:49:06.200 --> 00:49:09.440]   into a couple of different places, including a search results, pictures
[00:49:09.440 --> 00:49:12.440]   and all those kind of things that all that has to be processed by the LLM
[00:49:12.440 --> 00:49:13.600]   like really quickly.
[00:49:13.600 --> 00:49:17.080]   Did you play with the Meta AI picture generator?
[00:49:17.080 --> 00:49:20.200]   I did. Where you just add another little word or add to it?
[00:49:20.200 --> 00:49:21.320]   Yes. What do you think of it?
[00:49:21.320 --> 00:49:23.200]   That speed is insane.
[00:49:23.200 --> 00:49:26.560]   Yeah. And compared to like a year ago when you were doing it,
[00:49:26.560 --> 00:49:28.640]   when you'd wait, you know, 15 seconds to get one.
[00:49:28.640 --> 00:49:30.240]   Right, for the next image.
[00:49:30.240 --> 00:49:32.040]   This gets back to Sonny's point as well.
[00:49:32.040 --> 00:49:35.960]   When you're doing that, just think if the cost of inference was really high,
[00:49:35.960 --> 00:49:39.840]   there's no way he could roll that out to three billion people, right?
[00:49:39.840 --> 00:49:42.120]   Because all of a sudden people would start playing with it.
[00:49:42.120 --> 00:49:45.400]   And his OpEx on, you know, on the business would blow up in his face.
[00:49:45.600 --> 00:49:49.600]   Part of the reason he's, I think, pushing toward these smaller models,
[00:49:49.600 --> 00:49:53.440]   opening these models, you know, and he said in that podcast interview,
[00:49:53.440 --> 00:49:56.000]   they helped me lower the cost of inference.
[00:49:56.000 --> 00:49:58.400]   You know, we eat the cost of training.
[00:49:58.400 --> 00:50:01.360]   So, you know, we can we can lower the cost of inference.
[00:50:01.360 --> 00:50:04.880]   Well, maybe to, you know, just to wrap, we can.
[00:50:04.880 --> 00:50:08.160]   I want to hit on a few topics, Sonny, that we've covered
[00:50:08.160 --> 00:50:10.480]   over the course of the last few weeks.
[00:50:10.480 --> 00:50:13.560]   Of course, Bill and I did have been doing a couple of deep dives
[00:50:13.840 --> 00:50:18.000]   on full self-driving at Tesla, as well as,
[00:50:18.000 --> 00:50:21.800]   you know, their ride share project that's now moved front and center
[00:50:21.800 --> 00:50:24.080]   because of the breakthroughs they've had on FSD.
[00:50:24.080 --> 00:50:28.960]   And on the Tesla earnings call this week, they answered some of our questions.
[00:50:28.960 --> 00:50:31.440]   So a couple of the questions Bill and I had is,
[00:50:31.440 --> 00:50:33.480]   is this going to occur within the Tesla app?
[00:50:33.480 --> 00:50:37.360]   Well, you can see here, you know, this beautiful depiction,
[00:50:37.360 --> 00:50:40.800]   you know, of a ride share within the Tesla app.
[00:50:40.800 --> 00:50:42.920]   There are a lot of Tesla app holders.
[00:50:42.920 --> 00:50:45.560]   We had a question was whether or not it was going to be owned and operated
[00:50:45.560 --> 00:50:46.720]   or whether it was going to leverage
[00:50:46.720 --> 00:50:49.080]   the millions and millions of cars that are out there in the fleet.
[00:50:49.080 --> 00:50:51.760]   And Elon, I thought, elegantly put this, you know,
[00:50:51.760 --> 00:50:54.000]   we're going to be both Uber and Airbnb.
[00:50:54.000 --> 00:50:57.400]   You know, we're going to, you know, own some of the fleet.
[00:50:57.400 --> 00:51:01.480]   We're also going to let those people who buy cars from us,
[00:51:01.480 --> 00:51:04.240]   you know, put their cars into the fleet.
[00:51:04.240 --> 00:51:08.880]   My own hunch is that it will also be distributed both one P and three P,
[00:51:08.880 --> 00:51:11.000]   although he didn't go so far as saying that.
[00:51:11.680 --> 00:51:14.600]   And what I mean by that is not only distributed in the Tesla app.
[00:51:14.600 --> 00:51:18.600]   My hunch is that as this scales, it'll make sense to do a partnership with Uber.
[00:51:18.600 --> 00:51:21.760]   And frankly, I wouldn't be surprised to see some of the people
[00:51:21.760 --> 00:51:27.200]   who operate on the Uber platform become fleet operators of Tesla's for Tesla.
[00:51:27.200 --> 00:51:30.640]   And so I think there's a really interesting opportunity
[00:51:30.640 --> 00:51:32.680]   for an integration there.
[00:51:32.680 --> 00:51:34.480]   But I thought that was pretty consistent.
[00:51:34.480 --> 00:51:38.800]   We weren't too far off in terms of our estimation there.
[00:51:38.800 --> 00:51:44.000]   And there's I mean, this is kind of they obviously have already made it clear
[00:51:44.000 --> 00:51:45.880]   they're going to be talking about this for a long time.
[00:51:45.880 --> 00:51:49.360]   But this is the kind of first draft, if you will.
[00:51:49.360 --> 00:51:52.160]   I think there's a lot to see as this stuff rolls out.
[00:51:52.160 --> 00:51:56.200]   You know, Waymo's had to apply for these licenses
[00:51:56.200 --> 00:51:58.240]   to get these cars on the street. Yes.
[00:51:58.240 --> 00:52:03.160]   We don't have Tesla's, one, they haven't even applied for those things,
[00:52:03.160 --> 00:52:07.120]   but we don't have them driverless on the road yet.
[00:52:07.360 --> 00:52:11.560]   Right. Which would be a step that would need to take place
[00:52:11.560 --> 00:52:12.640]   before this was rolled out.
[00:52:12.640 --> 00:52:16.600]   But it intersects with that really big purchase of,
[00:52:16.600 --> 00:52:19.640]   you know, H100s that they talked about as well.
[00:52:19.640 --> 00:52:24.960]   You know, we now have a lot of companies that are reported
[00:52:24.960 --> 00:52:30.080]   and there's not one of them yet that has not raised their capex guidance
[00:52:30.080 --> 00:52:32.760]   to buy more to buy more GPS.
[00:52:33.040 --> 00:52:38.200]   I mean, Elon himself is going to let his in the past four weeks,
[00:52:38.200 --> 00:52:44.080]   the incremental purchases they've signaled are in and not just Tesla.
[00:52:44.080 --> 00:52:50.400]   But there's data on the internets today that X.AI has raised six billion.
[00:52:50.400 --> 00:52:54.920]   Presumably most of that's going into infrastructure as well.
[00:52:54.920 --> 00:52:58.040]   And, you know, you and I have a couple of bets going.
[00:52:58.040 --> 00:53:01.240]   But, you know, when it comes to whether or not
[00:53:01.240 --> 00:53:03.840]   GPUs are undersupplied or oversupplied, you know,
[00:53:03.840 --> 00:53:06.880]   what I've stipulated is every supply shortage
[00:53:06.880 --> 00:53:08.920]   does ultimately result in a glut.
[00:53:08.920 --> 00:53:11.960]   But people have been calling for this glut now for,
[00:53:11.960 --> 00:53:14.680]   you know, 12 months anyway.
[00:53:14.680 --> 00:53:16.080]   And they're calling for it again this year.
[00:53:16.080 --> 00:53:17.480]   We're not going to see it again this year.
[00:53:17.480 --> 00:53:18.560]   There's, you know, and-
[00:53:18.560 --> 00:53:19.480]   So you bought the dip?
[00:53:19.480 --> 00:53:21.480]   We own plenty.
[00:53:21.480 --> 00:53:25.800]   And, you know, and you just see it, you know, in fact,
[00:53:25.800 --> 00:53:30.800]   you know, Meta was down 15 or I think it ended up down 10 or 11 percent.
[00:53:31.640 --> 00:53:34.840]   And one of the major reasons it was down is Zuckerberg said,
[00:53:34.840 --> 00:53:37.560]   I'm going to put the, you know, the accelerator to the floor.
[00:53:37.560 --> 00:53:41.400]   He increased the midpoint of his CapEx guide by three or four billion dollars.
[00:53:41.400 --> 00:53:45.400]   You know, which I said, you know, I had a lot of people inbound to me and say,
[00:53:45.400 --> 00:53:49.040]   hey, you know, they're no longer being efficient or they're no longer being fit.
[00:53:49.040 --> 00:53:53.080]   Which, you know, to which I responded by saying in two years,
[00:53:53.080 --> 00:53:57.920]   that company has gone from 22 billion in net income to 55 billion in net income.
[00:53:58.120 --> 00:54:02.160]   They've reduced their headcount from 85,000 people to 69,000 people.
[00:54:02.160 --> 00:54:06.840]   What they are demonstrating is what you can do when you're efficient.
[00:54:06.840 --> 00:54:11.040]   You can redeploy all of that incremental profitability into investing,
[00:54:11.040 --> 00:54:14.400]   not in some 10 year project that we don't know what the payback is,
[00:54:14.400 --> 00:54:17.640]   but directly into GPUs and AI, where you can see the payback
[00:54:17.640 --> 00:54:20.920]   in a pretty short period of time, leveraging it in their core business.
[00:54:20.920 --> 00:54:25.320]   And so, you know, it was, you know, while we're on it,
[00:54:26.520 --> 00:54:28.680]   you know, well, he went and bought gym equipment.
[00:54:28.680 --> 00:54:32.760]   I did see that, too.
[00:54:32.760 --> 00:54:34.200]   I did see that, too.
[00:54:34.200 --> 00:54:36.320]   Bill, you and I talked about IPOs.
[00:54:36.320 --> 00:54:40.800]   You know, Dan Primek, you know, came out with this article
[00:54:40.800 --> 00:54:43.640]   that was pretty controversial, I think, among VCs.
[00:54:43.640 --> 00:54:45.560]   I saw a lot of people responding to it.
[00:54:45.560 --> 00:54:48.960]   It was entitled VCs, you're blowing it.
[00:54:48.960 --> 00:54:52.440]   And there was one line in there that caught my attention,
[00:54:52.800 --> 00:54:57.360]   you know, where he said VCs let startups stay private too long,
[00:54:57.360 --> 00:55:01.680]   often well past their hyper growth phase that justified sky high valuations.
[00:55:01.680 --> 00:55:04.480]   You and I debated this last week.
[00:55:04.480 --> 00:55:07.640]   How much revenue do you have to have to go public?
[00:55:07.640 --> 00:55:10.240]   I think you and I are both in the camp
[00:55:10.240 --> 00:55:14.720]   that if you have 100 million of trailing revenue, you're growing well.
[00:55:14.720 --> 00:55:16.160]   You have great unit economics.
[00:55:16.160 --> 00:55:19.040]   You can certainly go public if you price it right.
[00:55:19.040 --> 00:55:21.520]   I'm you know, I've said it on Twitter.
[00:55:21.520 --> 00:55:22.720]   I say it in boardrooms.
[00:55:22.720 --> 00:55:27.400]   I think being in the public markets is a great place for companies to be.
[00:55:27.400 --> 00:55:30.080]   I think it, you know, it puts them in the big league.
[00:55:30.080 --> 00:55:33.240]   It makes them you know, there's plenty of room to innovate there.
[00:55:33.240 --> 00:55:37.880]   However, what I would say to Dan is, you know, when we sit on the board,
[00:55:37.880 --> 00:55:42.640]   we can advise, but ultimately we're not the decision maker.
[00:55:42.640 --> 00:55:46.200]   Right. It's got to be a collaboration with the founder of the company.
[00:55:46.200 --> 00:55:48.800]   And ultimately, I think the company should go public
[00:55:48.800 --> 00:55:51.040]   when it's the right time for the company to go public.
[00:55:51.200 --> 00:55:53.920]   And for some companies, that is at that earlier phase.
[00:55:53.920 --> 00:55:57.160]   I think a lot more could go public at that earlier phase.
[00:55:57.160 --> 00:56:02.440]   But I also think there are certain situations, you know, take SpaceX,
[00:56:02.440 --> 00:56:06.560]   for example, where I think it's behooved them to stay private longer. Right.
[00:56:06.560 --> 00:56:09.800]   And they've had plenty of access to the private markets to raise capital.
[00:56:09.800 --> 00:56:12.360]   So I didn't know if you had any reactions to the Dan.
[00:56:12.360 --> 00:56:15.720]   Well, I mean, I think
[00:56:15.720 --> 00:56:18.320]   in a lot of ways, I agree with what you're saying.
[00:56:18.320 --> 00:56:21.360]   And I disagree maybe with the way it was positioned.
[00:56:21.360 --> 00:56:24.160]   But keep in mind, Dan's one of the very few
[00:56:24.160 --> 00:56:28.120]   analysts and writers that focuses on LPs
[00:56:28.120 --> 00:56:34.040]   like most of these writers focus on VCs or the founders themselves or whatever.
[00:56:34.040 --> 00:56:36.760]   And he's he's constantly talking to LPs.
[00:56:36.760 --> 00:56:42.000]   And I think there is a a very real situation, especially where we came out
[00:56:42.000 --> 00:56:46.320]   of Zerp, where there's a vast amount of paper marks
[00:56:46.320 --> 00:56:49.880]   that are sitting on these LP books that are aging out,
[00:56:49.880 --> 00:56:55.040]   that are that are exposed to dilution, you know, on an annual basis.
[00:56:55.040 --> 00:57:00.200]   And I suspect they're very nervous and I suspect they're talking to him
[00:57:00.200 --> 00:57:02.480]   and that that's where he's building this thesis.
[00:57:02.480 --> 00:57:04.720]   And I think that's probably right.
[00:57:04.720 --> 00:57:09.920]   I also think that a number of people, you know, that invest in late stage
[00:57:09.920 --> 00:57:13.440]   and people that we know have have built a business model where
[00:57:13.440 --> 00:57:16.560]   they kind of like companies staying private longer.
[00:57:16.560 --> 00:57:18.480]   They are the ones that everyone talks about.
[00:57:18.480 --> 00:57:21.760]   Amazon went public at this price and then the public captured it.
[00:57:21.760 --> 00:57:25.400]   They they kind of view their game as capturing
[00:57:25.400 --> 00:57:27.720]   that growth instead of the public markets.
[00:57:27.720 --> 00:57:32.080]   And the third thing I would just say is our business has got nothing
[00:57:32.080 --> 00:57:35.400]   but more competitive from the minute I entered it to today.
[00:57:35.400 --> 00:57:37.360]   And I think that's going to keep happening.
[00:57:37.360 --> 00:57:42.480]   And that competition forces people to be very founder friendly,
[00:57:42.480 --> 00:57:46.880]   to say what they want to hear, to support secondaries, which we've talked about,
[00:57:46.880 --> 00:57:51.160]   that when you support massive secondaries,
[00:57:51.160 --> 00:57:53.200]   you're taking the number one pressure
[00:57:53.200 --> 00:57:59.040]   out of the system that used to lead founders to to want to go public
[00:57:59.040 --> 00:58:01.480]   because their employees are like, I need liquidity, I need liquidity.
[00:58:01.480 --> 00:58:05.240]   So you do a release valve and you take that away.
[00:58:05.520 --> 00:58:09.840]   And and I do think there will be a lot of situation.
[00:58:09.840 --> 00:58:12.240]   And then actually one last thing to mention, just
[00:58:12.240 --> 00:58:15.240]   because of where we came from, evaluation perspective,
[00:58:15.240 --> 00:58:18.960]   we know a lot of people are sitting there afraid
[00:58:18.960 --> 00:58:21.120]   that they can't meet their last mark. For sure.
[00:58:21.120 --> 00:58:23.520]   And so then you're kind of in Never Neverland.
[00:58:23.520 --> 00:58:24.720]   And how do you get out of this?
[00:58:24.720 --> 00:58:26.840]   And where are the odds you're going to grow back to that?
[00:58:26.840 --> 00:58:28.560]   And there's kind of a lack of.
[00:58:28.560 --> 00:58:31.960]   So anyway, those dimensions, I think he's hitting at it right.
[00:58:31.960 --> 00:58:33.320]   I agree with you.
[00:58:33.320 --> 00:58:37.000]   And this is where I think you got it wrong, is that like no single VCs
[00:58:37.000 --> 00:58:40.120]   going to stand up and make a company go public, right?
[00:58:40.120 --> 00:58:41.200]   That's not going to happen.
[00:58:41.200 --> 00:58:43.080]   I mean, I do see the market evolving.
[00:58:43.080 --> 00:58:47.240]   Listen, you got to get you're in you raise 10 year funds.
[00:58:47.240 --> 00:58:48.880]   You need to get liquidity.
[00:58:48.880 --> 00:58:53.040]   You're in the business to provide returns and liquidity to your partners.
[00:58:53.040 --> 00:58:57.480]   If I look at the private equity business, right, they evolved in such a way
[00:58:57.480 --> 00:58:59.480]   where they didn't have to take the company's public.
[00:58:59.480 --> 00:59:01.760]   They would just sell to another private equity company.
[00:59:02.160 --> 00:59:04.760]   And it may very well be in the VC landscape, Bill.
[00:59:04.760 --> 00:59:07.480]   And I see this more and more.
[00:59:07.480 --> 00:59:11.160]   You know, I know a big company right now raising it over 10 billion.
[00:59:11.160 --> 00:59:16.320]   And I know a lot of early stage VCs who are selling into that round.
[00:59:16.320 --> 00:59:19.280]   Right. And so that I thought there was one.
[00:59:19.280 --> 00:59:23.720]   Didn't Rippling say 600 million was going to people that are early?
[00:59:23.720 --> 00:59:25.840]   So that's not the one I was referencing.
[00:59:25.840 --> 00:59:27.880]   But Rippling may, in fact, be one of those.
[00:59:27.880 --> 00:59:31.400]   And so the market may be responding to some of these imperatives.
[00:59:32.200 --> 00:59:34.240]   You know, by LPs to get liquidity.
[00:59:34.240 --> 00:59:39.360]   But what I would say to Dan is certainly with the with the venture
[00:59:39.360 --> 00:59:42.840]   capitalists sitting around this table, you have two people who think
[00:59:42.840 --> 00:59:45.520]   that the public markets are a great place for companies to innovate,
[00:59:45.520 --> 00:59:48.920]   companies to thrive, companies to raise capital, companies to recruit,
[00:59:48.920 --> 00:59:50.720]   build, build brands, et cetera.
[00:59:50.720 --> 00:59:53.360]   And and we know we're in the business of liquidity.
[00:59:53.360 --> 00:59:56.760]   Seeking as an entrepreneur, though, can I add one thing to that, which is
[00:59:56.760 --> 00:59:59.440]   I think we're going to see like a bifurcation
[00:59:59.440 --> 01:00:01.480]   and builds on our conversation from earlier.
[01:00:01.480 --> 01:00:04.520]   There's going to be companies that are cheaper and cheaper to build and run.
[01:00:04.520 --> 01:00:07.200]   And, you know, that has one impact.
[01:00:07.200 --> 01:00:10.160]   But there's companies that are going to get a lot more capital to build and run.
[01:00:10.160 --> 01:00:13.880]   And so that may force folks into the public markets sort of like the way
[01:00:13.880 --> 01:00:15.720]   it was in the late 90s with a lot of those business
[01:00:15.720 --> 01:00:17.280]   because they needed a lot more capital.
[01:00:17.280 --> 01:00:18.480]   What do you guys think about that?
[01:00:18.480 --> 01:00:22.880]   I there was a there was a interesting article
[01:00:22.880 --> 01:00:26.240]   that Tim O'Reilly wrote about a month ago.
[01:00:26.240 --> 01:00:30.920]   I put the link in there, but he implied that he also attacked the VCs
[01:00:30.920 --> 01:00:32.600]   and said they were going about it all wrong.
[01:00:32.600 --> 01:00:38.560]   But he he implied that the AI was now in its Uber phase where the, you know,
[01:00:38.560 --> 01:00:42.520]   talk about Uber and Lyft and DoorDash all raising billions
[01:00:42.520 --> 01:00:44.480]   and it's spilling out on the floor.
[01:00:44.480 --> 01:00:47.880]   And I personally think part of it is simply
[01:00:47.880 --> 01:00:52.040]   a recognition by the investment community
[01:00:52.040 --> 01:00:57.360]   writ large that network effects exist and increasing return exists.
[01:00:57.360 --> 01:01:01.520]   Yes. And so when they think this is the next big thing
[01:01:01.520 --> 01:01:05.880]   and they see open AI take a lead, their gut response is,
[01:01:05.880 --> 01:01:09.040]   well, if I had invested early in Amazon or Google or whatever,
[01:01:09.040 --> 01:01:11.520]   I'd get paid almost no matter what the price.
[01:01:11.520 --> 01:01:16.200]   And so it's the institutionalization of a belief in network effects
[01:01:16.200 --> 01:01:18.960]   that's leading to the the money pouring in.
[01:01:18.960 --> 01:01:21.240]   And then and then it's a competitive dynamic.
[01:01:21.280 --> 01:01:25.760]   Like once your company raises, you know, 200 million, a billion,
[01:01:25.760 --> 01:01:28.000]   if you're in that market, you raise it, too.
[01:01:28.000 --> 01:01:29.920]   And it does create chaos.
[01:01:29.920 --> 01:01:32.240]   Like, I do think it creates chaos.
[01:01:32.240 --> 01:01:37.240]   Maybe we'll just we'll end with just kind of the volatile week
[01:01:37.240 --> 01:01:39.280]   it's been in markets.
[01:01:39.280 --> 01:01:42.680]   You know, we talked to, you know, you asked me what I thought
[01:01:42.680 --> 01:01:44.920]   was going to happen this week.
[01:01:44.920 --> 01:01:46.360]   You told me you'd give me a scorecard.
[01:01:46.360 --> 01:01:51.240]   But, you know, the reason it's so volatile this week
[01:01:51.240 --> 01:01:54.600]   is not just because we've had some mixed earnings reports
[01:01:54.600 --> 01:01:57.000]   or at least mixed reactions.
[01:01:57.000 --> 01:02:00.720]   But I think the economic backdrop is, you know, is unsettling.
[01:02:00.720 --> 01:02:04.440]   GDP came in a lot weaker than expected this morning.
[01:02:04.440 --> 01:02:09.120]   At the same time, the PC for Q1 came in a little bit higher.
[01:02:09.120 --> 01:02:11.800]   Now we got the monthly PC report coming out tomorrow.
[01:02:11.800 --> 01:02:13.240]   We'll see where that shakes out.
[01:02:13.240 --> 01:02:17.000]   But this idea that we could have a slowing economy
[01:02:17.000 --> 01:02:20.080]   at the same time that we have inflation continuing to go up.
[01:02:20.080 --> 01:02:23.600]   Right. This is this very fearful place called stagflation
[01:02:23.600 --> 01:02:25.160]   that nobody wants to be in.
[01:02:25.160 --> 01:02:28.320]   Now the market is now pushed out the rate cut forecast
[01:02:28.320 --> 01:02:30.480]   to December of this year. Right.
[01:02:30.480 --> 01:02:32.960]   So this higher for longer is now in place.
[01:02:32.960 --> 01:02:35.200]   Remember, when we started the year, we thought we were going to have six
[01:02:35.200 --> 01:02:38.520]   rate cuts, very accommodating Goldilocks environment.
[01:02:38.520 --> 01:02:41.880]   What's surprising to me, to be perfectly honest, is how well
[01:02:42.080 --> 01:02:46.000]   technology stocks have performed outside probably software,
[01:02:46.000 --> 01:02:48.840]   but how well they perform notwithstanding this fact.
[01:02:48.840 --> 01:02:50.960]   And the only reason they've been able to do that
[01:02:50.960 --> 01:02:53.600]   is the reacceleration caused by AI.
[01:02:53.600 --> 01:02:56.600]   So if you look at what happened tonight, Google beat.
[01:02:56.600 --> 01:02:58.640]   They issued a dividend for the first time.
[01:02:58.640 --> 01:03:00.480]   They announced a buyback. Right.
[01:03:00.480 --> 01:03:03.920]   So they're really they're their margins are expanding.
[01:03:03.920 --> 01:03:06.000]   So they're finding efficiencies in that business.
[01:03:06.000 --> 01:03:08.360]   They're listening to the markets.
[01:03:08.360 --> 01:03:11.120]   But, you know, I think impressively,
[01:03:11.120 --> 01:03:14.160]   you know what they're doing in that core business, the things they announced
[01:03:14.160 --> 01:03:17.160]   around SG, you got to give that management team a lot of credit.
[01:03:17.160 --> 01:03:20.160]   We talked about what's the stock.
[01:03:20.160 --> 01:03:23.160]   The stock was up, I think, 10 or 15 percent after hours.
[01:03:23.160 --> 01:03:27.480]   So I think it's at an all time high and and and doing incredibly well.
[01:03:27.480 --> 01:03:32.840]   Metta, you know, missed is down 10 percent, but still up 30 percent on the year.
[01:03:32.840 --> 01:03:36.440]   So I imagine those those two companies are about in the same area.
[01:03:36.440 --> 01:03:40.240]   You know, year to date, we talked about why they why they got hammered
[01:03:40.240 --> 01:03:43.920]   is because, you know, they're going to invest even more aggressively in A.I.,
[01:03:43.920 --> 01:03:45.400]   which is a long term investor.
[01:03:45.400 --> 01:03:46.560]   I'm pretty thrilled about.
[01:03:46.560 --> 01:03:49.240]   And then if you look at Azure or Microsoft's quarter,
[01:03:49.240 --> 01:03:52.000]   it was pretty blockbuster.
[01:03:52.000 --> 01:03:53.640]   And we'll show this chart by jamming.
[01:03:53.640 --> 01:03:56.920]   But Azure, I contributed seven percent of growth this quarter.
[01:03:56.920 --> 01:04:01.840]   So it's now translates into about a four billion run rate business,
[01:04:01.840 --> 01:04:06.520]   you know, that didn't even get broken out until five quarters ago, you know.
[01:04:06.520 --> 01:04:12.440]   So, again, I think if you look at technology generally, it's performing.
[01:04:12.440 --> 01:04:17.400]   It's performing really well, despite this kind of volatile economic backdrop.
[01:04:17.400 --> 01:04:22.720]   And we'll see where where PC rolls in on Friday.
[01:04:22.720 --> 01:04:25.600]   We'll see where the rest of technology comes in.
[01:04:25.600 --> 01:04:29.240]   My hunch is that the largest companies in technology,
[01:04:29.240 --> 01:04:31.800]   back to your network effects and your scale advantages.
[01:04:32.240 --> 01:04:35.280]   I'm not sure that smaller tech technology
[01:04:35.280 --> 01:04:39.160]   companies are seeing the benefits that the largest technology companies.
[01:04:39.160 --> 01:04:42.600]   Certainly, it looks like, you know, so we'll see that as it reports.
[01:04:42.600 --> 01:04:46.560]   But I think the largest data platforms and hyperscalers continue to benefit.
[01:04:46.560 --> 01:04:49.320]   Boys has been fun. Yeah, great.
[01:04:49.320 --> 01:04:51.680]   Let's do it again. Thanks for being on, Sonny.
[01:04:51.680 --> 01:04:52.560]   Until next time.
[01:04:53.560 --> 01:04:54.080]   Bye.
[01:04:54.080 --> 01:04:55.080]   I.
[01:04:55.080 --> 01:04:56.080]   I.
[01:04:56.080 --> 01:04:57.080]   I.
[01:04:57.080 --> 01:04:58.080]   I.
[01:04:58.080 --> 01:04:59.080]   I.
[01:04:59.080 --> 01:05:00.080]   I.
[01:05:00.080 --> 01:05:01.080]   I.
[01:05:01.080 --> 01:05:02.080]   I.
[01:05:02.080 --> 01:05:03.080]   I.
[01:05:03.080 --> 01:05:04.080]   I.
[01:05:04.080 --> 01:05:05.080]   I.
[01:05:05.080 --> 01:05:06.080]   I.

