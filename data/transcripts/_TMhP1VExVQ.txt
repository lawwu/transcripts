
[00:00:00.000 --> 00:00:21.680]   Hi everybody, nice to see you all here.
[00:00:21.680 --> 00:00:37.480]   Can you guys all hear me okay?
[00:00:37.480 --> 00:00:44.800]   Great.
[00:00:44.800 --> 00:00:54.360]   I don't have too much logistic stuff to mention, other than that ... well, we'll see what happens.
[00:00:54.360 --> 00:00:59.340]   I have a feeling this course is going to go a lot longer than I expected, so just putting
[00:00:59.340 --> 00:01:06.160]   that out there to warn you right now, it could be more of a marathon than we originally thought,
[00:01:06.160 --> 00:01:10.560]   which may require having some breaks in the middle or something.
[00:01:10.560 --> 00:01:15.240]   Anyway, we've got a lot of stuff to cover, and I don't want to hurry, I want to do it
[00:01:15.240 --> 00:01:23.200]   all carefully and properly, so I decided rather than hurrying, we'll just do what it takes.
[00:01:23.200 --> 00:01:32.840]   All right, so I think we are ready to get into it, a never-ending course, exactly, Sam,
[00:01:32.840 --> 00:01:42.720]   never-ending story.
[00:01:42.720 --> 00:01:45.600]   Hi everybody, welcome to lesson 11.
[00:01:45.600 --> 00:01:48.760]   This is the third lesson in part two.
[00:01:48.760 --> 00:01:52.000]   Depending on how you count things, there's been a lesson A and a lesson B, it's kind
[00:01:52.000 --> 00:01:54.820]   of the fifth lesson in part two, I don't know what it is, so we'll just stick to calling
[00:01:54.820 --> 00:02:01.060]   it lesson 11 and avoid getting too confused, I'm already confused.
[00:02:01.060 --> 00:02:04.480]   My goodness, I've got so much stuff to show you, I'm only going to show you a tiny fraction
[00:02:04.480 --> 00:02:09.900]   of the cool stuff that's been happening on the forum this week, but it's been amazing.
[00:02:09.900 --> 00:02:21.640]   I'm going to start by sharing this beautiful video from John Robinson, and I've never seen
[00:02:21.640 --> 00:02:27.220]   anything like this before, as you can see it's very stable, and it's really showing
[00:02:27.220 --> 00:02:33.240]   this beautiful movement between seasons.
[00:02:33.240 --> 00:02:38.840]   So what I did on the forum was I said to folks, "Hey, you should try interpolating between
[00:02:38.840 --> 00:02:46.200]   prompts," which is what John did, "and I also said you should try using the last image
[00:02:46.200 --> 00:02:53.680]   of the previous prompt interpolation as the initial image for the next prompt."
[00:02:53.680 --> 00:02:58.800]   And anyway, here it is, it came out beautifully, John was the first to get that working, so
[00:02:58.800 --> 00:03:05.400]   I was very excited about that.
[00:03:05.400 --> 00:03:17.600]   And the second one I wanted to show you is this really amazing work from Seb Dehi, who,
[00:03:17.600 --> 00:03:23.960]   Sebastian, who did something that I've been thinking about as well, I'm really thrilled
[00:03:23.960 --> 00:03:33.680]   that he also thought about this, which was he noticed that this update we do, unconditional
[00:03:33.680 --> 00:03:41.120]   embeddings plus guidance times text embeddings minus unconditional embeddings, has a bit
[00:03:41.120 --> 00:03:47.600]   of a problem, which is that it gets big.
[00:03:47.600 --> 00:03:57.080]   To show you what I mean by it gets big, is like, imagine that we've got, you know, we've
[00:03:57.080 --> 00:04:04.360]   got a couple of vectors, right, oops, that's not a vector, let's try that again, we've
[00:04:04.360 --> 00:04:15.000]   got a couple of vectors on this chart here, okay.
[00:04:15.000 --> 00:04:20.080]   And so we've got, let's see, so we've got, that's just, okay, so we've got the original
[00:04:20.080 --> 00:04:27.400]   unconditional piece here, so we've got u, so let's say this is u, okay, and then we add
[00:04:27.400 --> 00:04:40.840]   to that some amount of t minus u, so if we've got like t, let's say it's huge, right, and
[00:04:40.840 --> 00:04:53.400]   we've got u again, then the difference between those is the vector which goes here, right.
[00:04:53.400 --> 00:04:59.800]   Now you can see here that if there's a big difference between t and u, then the eventual
[00:04:59.800 --> 00:05:11.520]   update which actually happens is, oopsie daisy, that's gonna be an arrow, let's try that again,
[00:05:11.520 --> 00:05:18.560]   the eventual update which happens is far bigger than the original update, and so it jumps
[00:05:18.560 --> 00:05:24.160]   too far.
[00:05:24.160 --> 00:05:31.520]   So this idea is basically to say well let's make it so that the update is no longer than
[00:05:31.520 --> 00:05:37.440]   the original unconditioned update would have been, and we're going to be talking more about
[00:05:37.440 --> 00:05:44.380]   norms later, but basically we scale it by the ratio of the norms.
[00:05:44.380 --> 00:05:56.320]   And what happens is we start with this astronaut, and we move to this astronaut, and it's kind
[00:05:56.320 --> 00:06:01.680]   of a, it's a subtle change, but you can see there's a lot more before, after, before,
[00:06:01.680 --> 00:06:09.880]   after, a lot more texture in the background, and like on the earth there's a lot more detail
[00:06:09.880 --> 00:06:13.160]   before, after, you see that?
[00:06:13.160 --> 00:06:18.200]   And even little things like before the bridal kind of rains, whatever, were pretty flimsy,
[00:06:18.200 --> 00:06:23.120]   now they look quite proper, so it's made quite a big difference just to kind of get this
[00:06:23.120 --> 00:06:28.040]   scaling correct.
[00:06:28.040 --> 00:06:33.520]   So another example, there's a couple of other things that Sebastian tried, which I'll explain
[00:06:33.520 --> 00:06:38.320]   in a moment, but you can see how they, they, some of them actually resulted in changing
[00:06:38.320 --> 00:06:43.720]   the, the image, and this one's actually important because the poor horse used to be missing
[00:06:43.720 --> 00:06:48.640]   a leg, and now it's not missing a leg, so that's good.
[00:06:48.640 --> 00:06:53.200]   And so here's the detailed one with its extra leg, and so how did he do this?
[00:06:53.200 --> 00:06:59.640]   Well, so what he did was he started with this unconditioned prompt plus the guidance times
[00:06:59.640 --> 00:07:07.920]   the difference between the conditional and unconditioned, and then as we discussed, the
[00:07:07.920 --> 00:07:15.100]   next version that, well actually the next version we then saw is to basically just take
[00:07:15.100 --> 00:07:21.080]   that prediction and scale it according to the difference in the lengths, so the norms
[00:07:21.080 --> 00:07:24.000]   is basically the lengths of the vectors.
[00:07:24.000 --> 00:07:27.920]   And so this, this is the second one I did in lesson 9, you'll see it's gone from here,
[00:07:27.920 --> 00:07:34.880]   so when we go from 1a to 1b, you can see here it's got, look at this, this boot's gone from
[00:07:34.880 --> 00:07:39.280]   nothing to having texture, this, I don't know, whatever the hell this thing is, suddenly he's
[00:07:39.280 --> 00:07:44.080]   got texture, and look, we've now got proper stars in the sky.
[00:07:44.080 --> 00:07:49.880]   It's made a really big difference, and then the second change is not just to rescale the
[00:07:49.880 --> 00:07:56.560]   whole prediction, but to rescale the, the update, and when we rescale the update it
[00:07:56.560 --> 00:08:01.300]   actually not surprisingly changes the image entirely because we're now changing the direction
[00:08:01.300 --> 00:08:07.720]   it goes, and so I don't know, is this better than this, I mean maybe, maybe not, but you
[00:08:07.720 --> 00:08:12.720]   know, I think so, you know, particularly because this was the difference that added the correct
[00:08:12.720 --> 00:08:18.440]   fourth leg to the horse before, and then we can do both, we can rescale the difference
[00:08:18.440 --> 00:08:23.560]   and then rescale the result, and then we get the best of both worlds, as you can see, big
[00:08:23.560 --> 00:08:27.640]   difference, we get a nice background, this weird thing on his back's actually become
[00:08:27.640 --> 00:08:35.680]   an arm, that's not what a foot looks like, that is what a foot looks like, so these little
[00:08:35.680 --> 00:08:42.000]   details make a big difference, as you can see.
[00:08:42.000 --> 00:08:51.120]   So this is a really cool, or two really cool new things, new things tend to have wrinkles
[00:08:51.120 --> 00:09:00.640]   though, wrinkle number one is after I shared on Twitter Sebastian's approach, Ben Paul,
[00:09:00.640 --> 00:09:05.800]   who's Google brain, I think if I remember correctly, pointed out that this already exists,
[00:09:05.800 --> 00:09:10.520]   he thinks it's the same as what's shown in this paper, which is a diffusion model for
[00:09:10.520 --> 00:09:14.440]   text-to-speech, I haven't read the paper yet to check whether it's got all the different
[00:09:14.440 --> 00:09:19.480]   options or whether it's checked them all out like this, so maybe this is reinventing something
[00:09:19.480 --> 00:09:24.720]   that already existed and putting it into a new field, which would still be interesting,
[00:09:24.720 --> 00:09:29.720]   anyway, so hopefully folks on the forum you can help figure out whether this paper is
[00:09:29.720 --> 00:09:36.280]   actually showing the same thing or not, and then the other interesting thing was John
[00:09:36.280 --> 00:09:44.040]   Robinson got back in touch on the forum and said oh actually that tree video doesn't actually
[00:09:44.040 --> 00:09:50.120]   do what we think it does at all, there's a bug in his code and despite the bug it accidentally
[00:09:50.120 --> 00:09:53.840]   worked really well, so now we're in this interesting question of trying to figure out like oh why
[00:09:53.840 --> 00:09:59.760]   did we, how did he create such a beautiful video by mistake and okay so reverse engineering
[00:09:59.760 --> 00:10:04.920]   exactly what the bug did and then figuring out how to do that more intentionally, and
[00:10:04.920 --> 00:10:11.080]   this is great right, it's really good to you know having a lot of people working on something
[00:10:11.080 --> 00:10:19.860]   and the bugs often yeah they tell us about new ideas, so that's very interesting, so watch
[00:10:19.860 --> 00:10:27.280]   this space where we find out what John actually did and how come it worked so well, and then
[00:10:27.280 --> 00:10:32.200]   something that I just saw like two hours ago on the forum which I'd never thought of before
[00:10:32.200 --> 00:10:38.600]   but I thought of something a little bit similar, Rekyo Prashanth said like well what if we
[00:10:38.600 --> 00:10:41.920]   took this, so as you can see all the students are really bouncing ideas of each other it's
[00:10:41.920 --> 00:10:47.000]   like oh it's interesting we're doing different things with a guidance scale, what if we take
[00:10:47.000 --> 00:10:53.400]   the guidance scale and rather than keeping it at 7.5 all the time let's reduce it, and
[00:10:53.400 --> 00:10:57.000]   this is a little bit similar to something I suggested to John over a few weeks ago where
[00:10:57.000 --> 00:11:03.440]   I said he was doing some stuff with like modifying gradients based on additional loss functions
[00:11:03.440 --> 00:11:07.320]   and I said to him maybe you should just use them like occasionally at the start because
[00:11:07.320 --> 00:11:11.480]   I think the key thing is once the model kind of knows roughly what image it's trying to
[00:11:11.480 --> 00:11:17.440]   draw even if it's noisy you know you can let it do its thing and this is exactly what's
[00:11:17.440 --> 00:11:23.560]   happening here is Rekyo's idea is to say well let's decrease the guidance scale so at the
[00:11:23.560 --> 00:11:28.440]   end it's basically zero and so once it kind of is in going in the right direction we let
[00:11:28.440 --> 00:11:36.760]   it do its thing, so this little doggy is with the normal 7.5 guidance scale now have a look
[00:11:36.760 --> 00:11:43.720]   for example it's eye here it's pretty uninteresting pretty flat and if I go to the next one as
[00:11:43.720 --> 00:11:50.260]   you can see now actually look at the eye that's a proper eye before totally glassy black now
[00:11:50.260 --> 00:12:00.120]   proper eye or like look at all this fur very textured previously very out of focus so this
[00:12:00.120 --> 00:12:14.360]   is again a new technique so I love this you know you you folks are trying things out and
[00:12:14.360 --> 00:12:19.640]   some things are working and some things not working and that's all that's all good I kind
[00:12:19.640 --> 00:12:22.000]   of feel like you're going to have to slow down because I'm having trouble keeping up
[00:12:22.000 --> 00:12:30.800]   with you all but apart from that this is great good work I also wanted to mention on a different
[00:12:30.800 --> 00:12:41.240]   theme to check out Alex's notes on the on the lesson because I thought he's done a fantastic
[00:12:41.240 --> 00:12:48.040]   job of showing like how to how to study how to study a lesson and so what Alex did for
[00:12:48.040 --> 00:12:53.080]   example was he made a list in his notes of all the different steps we did as we started
[00:12:53.080 --> 00:13:01.200]   the front of the foundations what is the library that it comes from links to the documentation
[00:13:01.200 --> 00:13:08.600]   and I know that Alex's background actually is history you know not not computer science
[00:13:08.600 --> 00:13:12.100]   and so you know for somebody moving into a different field like this this is a great
[00:13:12.100 --> 00:13:16.160]   idea you know particularly to be able to like look at like okay what are all the things
[00:13:16.160 --> 00:13:22.240]   that I'm going to have to learn and read about and then he did something which we always
[00:13:22.240 --> 00:13:28.520]   recommend which is to try the lesson on a new data set and he very sensibly picked out
[00:13:28.520 --> 00:13:32.480]   the fashion MNIST data set which is something we'll be using a lot in this course because
[00:13:32.480 --> 00:13:39.100]   it's a lot like MNIST and it's just different enough to be interesting and so he's described
[00:13:39.100 --> 00:13:44.960]   in his post or his notes how he went about doing that and then something else I thought
[00:13:44.960 --> 00:13:51.320]   was interesting in his notes at the very end was he just jotted down my tips it's very
[00:13:51.320 --> 00:13:56.640]   easy when I throw a tip out there to think oh that's interesting that's good to know
[00:13:56.640 --> 00:14:02.160]   and then it can disappear so here's a good way to make sure you don't forget about all
[00:14:02.160 --> 00:14:09.800]   the little the little tricks and I think I've put those notes in the forum wiki so you
[00:14:09.800 --> 00:14:14.080]   can you can check them out if you've if you'd like to learn from them as well so I think
[00:14:14.080 --> 00:14:31.840]   this is a great role model good job Alex okay so during the week Jono taught us about a new
[00:14:31.840 --> 00:14:38.800]   paper that had just come out called deaf edit and he told us he thought this was an interesting
[00:14:38.800 --> 00:14:45.880]   paper and it came out during the week and I thought it might be good practice for us
[00:14:45.880 --> 00:14:55.200]   to try reading this paper together so let's do that so here's the paper deaf edit and
[00:14:55.200 --> 00:15:02.820]   you'll find that probably the majority of papers that you come across in deep learning
[00:15:02.820 --> 00:15:11.580]   will take you to archive archive is a preprint server so these are models these are papers
[00:15:11.580 --> 00:15:19.480]   that have not been peer-reviewed I would say in our field we don't generally or I certainly
[00:15:19.480 --> 00:15:24.840]   don't generally care about that at all because we have code we can try it we can see things
[00:15:24.840 --> 00:15:30.400]   whether it works or not you know we tend to be very you know most papers are very transparent
[00:15:30.400 --> 00:15:35.240]   about here's what we did and how we did it and you can replicate it and it gets a huge
[00:15:35.240 --> 00:15:41.360]   amount of peer-review on Twitter so if there's a problem generally within 24 hours somebody
[00:15:41.360 --> 00:15:47.240]   has pointed it out so we use archive a lot and if you wait until it's been peer-reviewed
[00:15:47.240 --> 00:15:52.400]   you know you'll be way out of date because this field is moving so quickly so here so
[00:15:52.400 --> 00:15:58.140]   here it is on archive and we can read it by clicking on the PDF button I don't do that
[00:15:58.140 --> 00:16:04.920]   instead I click on this little button up here which is the save to Zotero button so I figured
[00:16:04.920 --> 00:16:09.240]   I'd show you like my preferred workflows you don't have to do the same thing there are
[00:16:09.240 --> 00:16:14.480]   different workflows but here's one that I find works very well which is a Zotero is
[00:16:14.480 --> 00:16:20.200]   a piece of free software that you can download for Mac Windows Linux and install a Chrome
[00:16:20.200 --> 00:16:27.580]   connector oh Tanishka saying the buttons covered all right so in my taskbar I have a button
[00:16:27.580 --> 00:16:32.760]   that I can click that says save to Zotero sorry not taskbar Chrome menu bar and when
[00:16:32.760 --> 00:16:41.040]   I click it I'll show you what happens so after I've downloaded this the paper will automatically
[00:16:41.040 --> 00:16:54.840]   appear here in this software which is Zotero and so here it is diffedit and you can see
[00:16:54.840 --> 00:17:01.600]   it's told us it's got here the abstract the authors where it came from and so later on
[00:17:01.600 --> 00:17:06.240]   I can go in like if I want to check some detail I can go back and see the URL I can click
[00:17:06.240 --> 00:17:11.440]   on it pops up and so in this case what I'm going to do is I'm going to double click on
[00:17:11.440 --> 00:17:21.600]   it and that brings up the paper now the reason I like to read my papers in Zotero is that
[00:17:21.600 --> 00:17:28.920]   I can you know annotate them edit them tag them put them in folders and so forth and
[00:17:28.920 --> 00:17:34.400]   also add them to my kind of reading list directly from my web browser so as you can see you
[00:17:34.400 --> 00:17:40.040]   know I've started this fast diffusion folder which is actually a group library which I
[00:17:40.040 --> 00:17:45.280]   share with the other folks working on this fast diffusion project that we're all doing
[00:17:45.280 --> 00:17:54.640]   together and so we can all see the same paper library so Maribou on YouTube chat is asking
[00:17:54.640 --> 00:17:59.480]   is this better than Mendeley yeah I used to use Mendeley and it's kind of gone downhill
[00:17:59.480 --> 00:18:06.220]   I think Zotero is far far better but they're both very similar okay so we double click
[00:18:06.220 --> 00:18:21.320]   on it it opens up and here is a paper so reading a paper is always extremely intimidating and
[00:18:21.320 --> 00:18:27.080]   so you just have to do it anyway and you have to realize that your goal is not to understand
[00:18:27.080 --> 00:18:34.280]   every word your goal is to understand the basic idea well enough that for example when
[00:18:34.280 --> 00:18:39.160]   you look at the code hopefully it's comes with code most things do that you'll be able
[00:18:39.160 --> 00:18:43.840]   to kind of see how the code matches to it and that you could try writing your own code
[00:18:43.840 --> 00:18:49.680]   to implement parts of it yourself so over on the left you can open up the sidebar here
[00:18:49.680 --> 00:18:55.640]   so I generally open up the table of contents and get a bit of a sense of okay so there's
[00:18:55.640 --> 00:19:04.520]   some experimental results there's some theoretical results introduction related work okay tells
[00:19:04.520 --> 00:19:11.180]   us about this new diff edit thing some experiments okay so that's a pretty standard approach
[00:19:11.180 --> 00:19:17.680]   that you would see in papers so I would always start with the abstract okay so what's it
[00:19:17.680 --> 00:19:23.640]   saying this does so generally it's going to be some background sentence or two about how
[00:19:23.640 --> 00:19:27.520]   interesting this field is it's just saying wow image generation scroll which is fine
[00:19:27.520 --> 00:19:29.840]   and then they're going to tell us what they're going to do which is they're going to create
[00:19:29.840 --> 00:19:40.780]   something called diff edit and so this is a what is it for it's going to use text condition
[00:19:40.780 --> 00:19:44.480]   diffusion models so we know what those are now that's what we've been using that's where
[00:19:44.480 --> 00:19:49.960]   we type in some text and get back an image of that that matches the text but this is
[00:19:49.960 --> 00:19:54.120]   going to be different it's the task of semantic image editing okay we don't know what that
[00:19:54.120 --> 00:19:59.280]   is yet so let's put that aside and think okay let's make sure we understand that later the
[00:19:59.280 --> 00:20:04.460]   goal is to edit an image based on a text query oh okay so we're going to edit an image based
[00:20:04.460 --> 00:20:09.480]   on text how on earth would you do that they're going to tell us right away what this is semantic
[00:20:09.480 --> 00:20:15.400]   image editing it's an extension of image generation with an additional constraint which is the
[00:20:15.400 --> 00:20:20.000]   generated image should be as similar as possible to the given input and so generally as they've
[00:20:20.000 --> 00:20:26.340]   done here there's going to be a picture that shows us what's going on and so in this picture
[00:20:26.340 --> 00:20:32.840]   you can see here an example here's an input image and originally it was attached to a
[00:20:32.840 --> 00:20:39.600]   caption a bowl of fruits okay we want to change this into a bowl of pairs so we type a bowl
[00:20:39.600 --> 00:20:49.040]   of pairs and it generates oh a bowl of pairs or we could change it from a bowl of fruit
[00:20:49.040 --> 00:20:54.160]   to a basket of fruits and oh it's become a basket of fruits okay so I think I get the
[00:20:54.160 --> 00:21:03.320]   idea right what it's saying is that we can edit an image by typing what we want that
[00:21:03.320 --> 00:21:07.440]   image to represent so this actually looks a lot like the paper that we looked at last
[00:21:07.440 --> 00:21:18.400]   week so that's cool so the abstract says that currently so I guess there are current ways
[00:21:18.400 --> 00:21:22.360]   of doing this but they require you to provide a mask that means you have to basically draw
[00:21:22.360 --> 00:21:27.880]   the area you're replacing okay so that sounds really annoying but our main contribution so
[00:21:27.880 --> 00:21:32.980]   what this paper does is we automatically generate the mask so they simply just type in the new
[00:21:32.980 --> 00:21:37.240]   query and get the new image so that sounds actually really impressive so if you read
[00:21:37.240 --> 00:21:43.680]   the abstract and you think I don't care about doing that then you can skip the paper you
[00:21:43.680 --> 00:21:50.680]   know or or look at the results and if the results don't look impressive then just skip
[00:21:50.680 --> 00:21:55.400]   the paper so that's that's kind of your first point where we can be like okay we're done
[00:21:55.400 --> 00:22:00.080]   but in this case this sounds great the results look amazing so I think we should keep going
[00:22:00.080 --> 00:22:07.560]   okay it achieves data the updating performance of course fine and we try some right whatever
[00:22:07.560 --> 00:22:16.880]   okay so the introduction to a paper is going to try to give you a sense of you know what
[00:22:16.880 --> 00:22:22.880]   they're trying to do and so this first paragraph here is just repeating what we've already
[00:22:22.880 --> 00:22:28.920]   read in the abstract and repeating what we see in figure one so saying that we can take
[00:22:28.920 --> 00:22:34.720]   a text query like a basket of fruits see the examples alright fine we'll skip through there
[00:22:34.720 --> 00:22:45.660]   so the key thing about academic papers is that they are full of citations you should
[00:22:45.660 --> 00:22:50.560]   not expect to read all of them because if you do then to read each of those citations
[00:22:50.560 --> 00:22:54.160]   that's full of citations and then they're full of citations and before you know it you've
[00:22:54.160 --> 00:23:01.600]   read the entire academic literature which has taken you 5,000 years so for now let's
[00:23:01.600 --> 00:23:05.000]   just recognize that it says text conditional image generations undergoing a revolution
[00:23:05.000 --> 00:23:09.680]   here's some examples well fine we actually already know that okay Dali's call latent
[00:23:09.680 --> 00:23:15.080]   diffusion that's what we've been using that's called the Emma Jan apparently that's cool
[00:23:15.080 --> 00:23:19.240]   so cool alright so we kind of know that so generally there's this like okay our area
[00:23:19.240 --> 00:23:22.720]   that we're working on is important in this case we already agree it's important so we
[00:23:22.720 --> 00:23:27.640]   can skip through it pretty quickly they've asked vast amounts of data are used yes we
[00:23:27.640 --> 00:23:37.360]   know okay so diffusion models are interesting yes we know that they denoise starting from
[00:23:37.360 --> 00:23:41.120]   Gaussian noise we know that so you can see like there's a lot of stuff once you're kind
[00:23:41.120 --> 00:23:46.000]   of in the field you can skip over pretty quickly you can guide it using clip guidance yeah
[00:23:46.000 --> 00:23:51.680]   that's what we've been doing we know about that oh wait this is new or by in painting
[00:23:51.680 --> 00:23:58.080]   by copy pasting pixel values outside a mask alright so there's a new technique that we
[00:23:58.080 --> 00:24:02.720]   haven't done but I think it makes a lot of intuitive sense that is during that diffusion
[00:24:02.720 --> 00:24:08.680]   process if there are some pixels you don't want to change such as all the ones that aren't
[00:24:08.680 --> 00:24:13.760]   orange here you can just paste them from the original after each stage of the diffusion
[00:24:13.760 --> 00:24:17.560]   alright that makes perfect sense if I want to know more about that I could always look
[00:24:17.560 --> 00:24:23.000]   at this paper but I don't think I do for now okay and again it's just repeating something
[00:24:23.000 --> 00:24:33.220]   they've already told us that there they require us to provide a mask so it's a bit of a problem
[00:24:33.220 --> 00:24:39.760]   and then you know this is interesting it's also says that when you mask out an area that's
[00:24:39.760 --> 00:24:44.600]   a problem because if you're trying to for example change a dog into a cat you want to
[00:24:44.600 --> 00:24:49.800]   keep the animals color and pose so this is a new technique which is not deleting the
[00:24:49.800 --> 00:24:54.660]   original not deleting a section and replacing it with something else but it's actually going
[00:24:54.660 --> 00:24:59.040]   to take advantage of knowledge about what that thing looked like so that this is called
[00:24:59.040 --> 00:25:05.560]   to call new things so hopefully at this point we know what they're trying to achieve if
[00:25:05.560 --> 00:25:09.240]   you don't know what they're trying to achieve when you're reading a paper the paper won't
[00:25:09.240 --> 00:25:14.320]   make any sense so again that's a point where you should stop maybe this is not the right
[00:25:14.320 --> 00:25:18.440]   time to be reading this paper maybe you need to read some of the references maybe you need
[00:25:18.440 --> 00:25:23.440]   to look more at the examples so you can always skip straight to the experiments so I often
[00:25:23.440 --> 00:25:28.560]   skip straight to the experiments in this case I don't need to because they've put enough
[00:25:28.560 --> 00:25:33.240]   experiments on the very first page me to see what it's doing so yeah don't always read
[00:25:33.240 --> 00:25:43.480]   it from top to bottom okay so all right so they've got some examples of conditioning a
[00:25:43.480 --> 00:25:50.120]   diffusion model on an input without a mask okay for example you can use a noised version
[00:25:50.120 --> 00:25:53.960]   of the input as a starting point hey we've done that too so as you can see we've already
[00:25:53.960 --> 00:26:00.600]   covered a lot of the techniques that they're referring to here something we haven't done
[00:26:00.600 --> 00:26:04.480]   but makes a lot of sense is that we can look at the distance to the input image as a loss
[00:26:04.480 --> 00:26:12.720]   function okay that makes sense to me and there's some references here all right so we're going
[00:26:12.720 --> 00:26:16.600]   to create this new thing called diffedit it's going to be amazing wait till you check it
[00:26:16.600 --> 00:26:24.280]   out okay fine okay so that's the introduction hopefully you found that useful to understand
[00:26:24.280 --> 00:26:30.160]   what we're trying to do the next section is generally called related work as it is here
[00:26:30.160 --> 00:26:38.920]   and that's going to tell us about other approaches so if you're doing a deep dive this is a good
[00:26:38.920 --> 00:26:46.000]   thing to study carefully I don't think we're going to do a deep dive right now so I think
[00:26:46.000 --> 00:26:51.920]   we can happily skip over it we could kind of do a quick glance of like oh image editing
[00:26:51.920 --> 00:26:57.440]   can include colorization retouching style transfer okay cool lots of interesting topics
[00:26:57.440 --> 00:27:03.820]   definitely getting more excited about this idea of image editing and there's some different
[00:27:03.820 --> 00:27:15.120]   techniques you can use clip guidance okay they can be computationally expensive we can
[00:27:15.120 --> 00:27:22.720]   use diffusion for image editing okay fine we can use flip to help us so there's a lot
[00:27:22.720 --> 00:27:26.560]   of repetition in these papers as well which is nice because we can skip over it pretty
[00:27:26.560 --> 00:27:32.360]   quickly more about the high computational costs okay so they're saying this is going
[00:27:32.360 --> 00:27:41.400]   to be not so computationally expensive that sounds hopeful and often the very end of the
[00:27:41.400 --> 00:27:45.120]   related work is most interesting as it is here where they've talked about how somebody
[00:27:45.120 --> 00:27:50.800]   else has done concurrent to ours somebody else is working at the exactly the same time
[00:27:50.800 --> 00:28:00.240]   they've looked at some different approach okay so not sure we learned too much from
[00:28:00.240 --> 00:28:06.280]   the related work but if you were trying to really do the very very best possible thing
[00:28:06.280 --> 00:28:18.720]   you could study the related work and get the best ideas from each okay now background so
[00:28:18.720 --> 00:28:30.800]   this is where it starts to look scary I think we could all agree the and this is often the
[00:28:30.800 --> 00:28:37.480]   scariest bit the background this is basically saying like mathematically here's how the
[00:28:37.480 --> 00:28:42.080]   problem that we're trying to solve is set up and so we're going to start by looking
[00:28:42.080 --> 00:28:50.520]   at denoising diffusion probabilistic models DDPM now if you've watched lesson 9b with
[00:28:50.520 --> 00:28:58.840]   Wasim and Tanishk then you've already seen some of the math of DDPM and the important
[00:28:58.840 --> 00:29:05.760]   thing to recognize is that basically no one in the world pretty much it's going to look
[00:29:05.760 --> 00:29:13.000]   at these paragraphs of text and these equations and go oh I get it that's what DDPM is that's
[00:29:13.000 --> 00:29:20.600]   not how it works right to understand DDPM you would have to read and study the original
[00:29:20.600 --> 00:29:27.360]   paper and then you would have to read and study the papers it's based on and talk to
[00:29:27.360 --> 00:29:33.600]   lots of people and watch videos and go to classes just like this one and after a while
[00:29:33.600 --> 00:29:39.420]   you'll understand DDPM and then you'll be able to look at this section and say oh okay
[00:29:39.420 --> 00:29:43.800]   I see they're just talking about this thing I'm already familiar with so this is meant
[00:29:43.800 --> 00:29:48.260]   to be a reminder of something that you already know it's not something you should expect
[00:29:48.260 --> 00:29:58.600]   to learn from scratch so let me take you through these equations somewhat briefly because Wasim
[00:29:58.600 --> 00:30:03.200]   and Tanishk have kind of done them already because every diffusion paper pretty much
[00:30:03.200 --> 00:30:09.960]   is going to have these equations okay so oh and I'm just going to read something that
[00:30:09.960 --> 00:30:13.640]   John knows pointed out in the chat he says it's worth remembering the background is often
[00:30:13.640 --> 00:30:18.840]   written last and tries to look smart for the reviewers which is correct so feel free to
[00:30:18.840 --> 00:30:26.680]   read it last too yeah absolutely I think the main reason to read it is to find out what
[00:30:26.680 --> 00:30:31.400]   the different letters mean what the different symbols mean because they'll probably refer
[00:30:31.400 --> 00:30:39.760]   to them later but in this case I want to actually take this as a way to learn how to read math
[00:30:39.760 --> 00:30:47.080]   so let's start with this very first equation which how on earth do you even read this so
[00:30:47.080 --> 00:30:54.600]   the first thing I'll say is that this is not an E right it's a weird looking E and the
[00:30:54.600 --> 00:30:59.400]   reason it's a weird looking E is because it's a Greek letter and so something I always recommend
[00:30:59.400 --> 00:31:07.360]   to students is that you learn the Greek alphabet because it's much easier to be able to actually
[00:31:07.360 --> 00:31:12.880]   read this to yourself so here's another one right if you don't know that's called theta
[00:31:12.880 --> 00:31:18.040]   I guess you have to read it as like circle with line through it it's just going to get
[00:31:18.040 --> 00:31:29.000]   confusing trying to read an equation where you just can't actually say it out loud so
[00:31:29.000 --> 00:31:38.560]   what I suggest is that you learn that learn the Greek alphabet and let me find the right
[00:31:38.560 --> 00:31:53.640]   place so it's very easy to look it up just on Wikipedia is the Greek alphabet and if
[00:31:53.640 --> 00:31:59.680]   we go down here you'll see they've all got names and we can go and try and find our one
[00:31:59.680 --> 00:32:10.400]   curvy e okay here it is epsilon and oh circle with a line through it theta alright so practice
[00:32:10.400 --> 00:32:18.280]   and you will get used to recognizing these so you've got epsilon theta this is just a
[00:32:18.280 --> 00:32:26.280]   weird curly L so that's this is used for the loss function okay so how do we find out what
[00:32:26.280 --> 00:32:34.560]   this symbol means and what this symbol means well what we can do is there's a few ways
[00:32:34.560 --> 00:32:56.640]   to do it one way which is kind of cool is we can use a program called MathPix which
[00:32:56.640 --> 00:33:08.360]   is and what it does is you basically select anything on your screen and it will turn it
[00:33:08.360 --> 00:33:15.960]   into LaTeX so that's one way you can do this is you can select on the screen it turns it
[00:33:15.960 --> 00:33:19.960]   into LaTeX and the reason it's good to turn it into LaTeX is because LaTeX is written
[00:33:19.960 --> 00:33:28.960]   as actual stuff that you can search for on Google so that's technique number one technique
[00:33:28.960 --> 00:33:40.320]   number two is you can download the other formats of the paper and that will have a download
[00:33:40.320 --> 00:33:54.800]   source and if we say download source then what we'll be able to do is we'll be able
[00:33:54.800 --> 00:34:00.880]   to actually open up that LaTeX and have a look at it so we'll wait for that to download
[00:34:00.880 --> 00:34:09.800]   while it's happening let's keep moving along here so in this case we've got these these
[00:34:09.800 --> 00:34:18.660]   two bars so can we find out what that means so we could try a few things we could try
[00:34:18.660 --> 00:34:30.800]   looking for two bars maybe math notation oh here we are looks hopeful what does this mean
[00:34:30.800 --> 00:34:37.240]   in mathematics oh and here there's a glossary of mathematical symbols here there's a meaning
[00:34:37.240 --> 00:34:47.800]   of this in math so that looks hopeful okay so it definitely doesn't look like this it's
[00:34:47.800 --> 00:34:56.520]   not between two sets of letters ah but it is around something that looks hopeful so
[00:34:56.520 --> 00:35:01.560]   it looks like we found it it's a vector norm okay so then you can start looking for these
[00:35:01.560 --> 00:35:09.960]   things up so we can say norm or maybe vector norm and so once you can actually find the
[00:35:09.960 --> 00:35:27.080]   term then we kind of know what to look for okay so in our case we've got this surrounding
[00:35:27.080 --> 00:35:34.280]   all this stuff and then there's twos here and here what's going on here alright if we
[00:35:34.280 --> 00:35:47.520]   scroll through oh this is pretty close actually so okay so two bars can mean a matrix norm
[00:35:47.520 --> 00:35:51.240]   otherwise a single for a vector norm that's just here in particular so it looks like we
[00:35:51.240 --> 00:35:56.560]   don't have to worry too much about whether it's one or two bars oh and here's the definition
[00:35:56.560 --> 00:36:03.920]   oh that's handy so we've got the two one alright so it's equal to root sum of squares so that's
[00:36:03.920 --> 00:36:10.560]   good to know so this norm thing means a root sum of squares but then we've got a two up
[00:36:10.560 --> 00:36:17.880]   here well that just means squared ah so this is a root sum of squares squared well the
[00:36:17.880 --> 00:36:22.400]   square of a square root is just the thing itself ah so actually this whole thing is
[00:36:22.400 --> 00:36:29.120]   just the sum of squares it's a bit of a weird way to write it in a sense we could perfectly
[00:36:29.120 --> 00:36:42.440]   well have just written it as you know like sum of you know whatever it is squared fine
[00:36:42.440 --> 00:36:53.080]   but there we go okay and then what about this thing here weird a thing so how would you
[00:36:53.080 --> 00:37:21.400]   find out what the weird a thing is my goodness this is still downloading that's crazy
[00:37:21.400 --> 00:37:37.280]   wow 20k per second that's strange wonder why that's taking so long all right hmm maybe
[00:37:37.280 --> 00:38:03.360]   if we search for it copy and now it's just searching for an a rotten thing well it's
[00:38:03.360 --> 00:38:26.360]   kind of speedy fancy e okay try fancy e maybe fancy a math symbol weird a letter no oh finished
[00:38:26.360 --> 00:38:45.920]   great okay so our our um laytech has finally finished downloading and if we open it up
[00:38:45.920 --> 00:38:56.080]   we can find there's a tech file in here here we are main tech so we'll open it
[00:38:56.080 --> 00:39:02.280]   and it's not the most you know amazingly smooth process but you know what we could just do
[00:39:02.280 --> 00:39:07.800]   is we could say okay it's just after it says minimizing the denoising objective okay so
[00:39:07.800 --> 00:39:14.080]   let's search for many my seeing the D oh here it is minimizing the denoising objective
[00:39:14.080 --> 00:39:22.040]   so the laytech here let's get it back from the screen at the same time okay so here it
[00:39:22.040 --> 00:39:34.000]   is l math l equals math bbe x naught t epsilon okay and here's that vertical bar thing epsilon
[00:39:34.000 --> 00:39:39.680]   minus epsilon theta xt and then the bar thing to two all right so the thing that we've got
[00:39:39.680 --> 00:39:49.480]   new is math bbe okay so finally we've got something we can search for
[00:39:49.480 --> 00:40:02.600]   math bbe ah fantastic what does math bbe mean that's the expected value operator aha fantastic
[00:40:02.600 --> 00:40:09.320]   all right so it takes a bit of fussing around but once you've got either math picks working
[00:40:09.320 --> 00:40:13.040]   or actually another thing you could try because math picks is ridiculously expensive in my
[00:40:13.040 --> 00:40:33.440]   opinion is there is there is a free version called picks to tech that actually is a python
[00:40:33.440 --> 00:40:37.560]   thing and you could actually even have fun playing with this because the whole thing
[00:40:37.560 --> 00:40:45.640]   is just a pytorch python script and it even describes you know how if used to transformers
[00:40:45.640 --> 00:40:51.040]   model and you can train it yourself in colab and so forth but basically as you can see
[00:40:51.040 --> 00:40:59.720]   yeah you can snip and convert to latex which is pretty awesome so you could use this instead
[00:40:59.720 --> 00:41:10.280]   of paying the math picks guys anyway so we are on the right track now I think so expected
[00:41:10.280 --> 00:41:17.080]   value and then we can start reading about what expected value is and you might actually
[00:41:17.080 --> 00:41:22.120]   remember that because we did a bit of it in high school at least in Australia we did it's
[00:41:22.120 --> 00:41:37.240]   basically like let's maybe jump over here so expected value of something is saying what's
[00:41:37.240 --> 00:41:42.040]   what's the likely value of that thing so for example let's say you toss a coin which could
[00:41:42.040 --> 00:41:48.000]   be heads or it could be tails and you want to know how often it's heads and so maybe
[00:41:48.000 --> 00:41:53.760]   the core heads one tails zero so you toss it and you get a one zero zero one one zero
[00:41:53.760 --> 00:42:00.920]   one zero one okay and so forth right and then you can calculate the mean of that right so
[00:42:00.920 --> 00:42:09.200]   if that's X you can calculate X bar the mean which would be the sum of all that divided
[00:42:09.200 --> 00:42:18.480]   by the count of all that so it'd be one two three four five five divided by one two three
[00:42:18.480 --> 00:42:25.280]   four five six seven eight nine okay so that would be the mean but the expected value is
[00:42:25.280 --> 00:42:30.840]   like well what do you expect to happen and we can calculate that by adding up for all
[00:42:30.840 --> 00:42:37.200]   of the possibilities for each I don't know what to call them X for each possibility X
[00:42:37.200 --> 00:42:43.640]   how likely is X and what score do you get if you get X so in this example of heads and
[00:42:43.640 --> 00:42:50.520]   tails our two possibilities is that we either get heads or we get tails so if for the version
[00:42:50.520 --> 00:43:03.120]   where X is heads we get probability is 0.5 and the score if it's an X is going to be
[00:43:03.120 --> 00:43:13.380]   1 and then what about tails for tails the probability is 0.5 and the score if you get tails is 0
[00:43:13.380 --> 00:43:20.360]   and so overall the expected is 0.5 times 1 plus 0 is 0.5 so our expected score if we're
[00:43:20.360 --> 00:43:29.300]   tossing a coin is 0.5 if getting heads is a win let me give you another example another
[00:43:29.300 --> 00:43:35.440]   example is let's say that we're rolling a die and we want to know what the expected
[00:43:35.440 --> 00:43:46.920]   score is if we roll a die so again we could roll it a bunch of times and see what happens
[00:43:46.920 --> 00:43:53.840]   okay and so we could sum all that up last night before and divide it by the count and
[00:43:53.840 --> 00:43:57.880]   that'll tell us the mean for this particular example but what's the expected value more
[00:43:57.880 --> 00:44:05.240]   generally well again it's the sum of all the possibilities of the probability of each possibility
[00:44:05.240 --> 00:44:12.640]   times that score so the possibilities for rolling a die is that you can get a one a
[00:44:12.640 --> 00:44:25.600]   two a three a four a five or a six the probability of each one is a sixth okay and the score
[00:44:25.600 --> 00:44:31.800]   that you get is well it's this this is the score and so then you can multiply all these
[00:44:31.800 --> 00:44:50.040]   together and sum them up which would be 1/6 plus 2/6 plus 3/6 plus 4/6 plus 5/6 plus 6/6
[00:44:50.040 --> 00:44:57.420]   and that would give you the expected value of that particular thing which is rolling
[00:44:57.420 --> 00:45:07.640]   die rolling rolling a die so that's what expected value means all right so that's a really important
[00:45:07.640 --> 00:45:17.360]   concept that's going to come up a lot as we read papers and so in particular this is telling
[00:45:17.360 --> 00:45:22.680]   us what are all the things that we're averaging it over that with the expectations over and
[00:45:22.680 --> 00:45:26.440]   so there's a whole lot of letters here you're not expected to just know what they are in
[00:45:26.440 --> 00:45:30.000]   fact in every paper they could mean totally different things so you have to look immediately
[00:45:30.000 --> 00:45:38.920]   underneath where they'll be defined so x0 is an image it's an input image epsilon is
[00:45:38.920 --> 00:45:45.120]   the noise and the noise has a mean of zero and a standard deviation of I which if you
[00:45:45.120 --> 00:45:50.440]   watch the lesson 9b you'll know it's like a standard deviation of one when you're doing
[00:45:50.440 --> 00:46:01.240]   multiple normal variables okay and then this is kind of confusing either just on its own
[00:46:01.240 --> 00:46:06.240]   is a normally distributed random variable so it's just grabbing random numbers but either
[00:46:06.240 --> 00:46:13.620]   the if sorry epsilon but epsilon theta is a noise estimator that means it's a function
[00:46:13.620 --> 00:46:18.400]   you can tell it's a function kind of because it's got these parentheses and stuff direct
[00:46:18.400 --> 00:46:25.120]   next to it so that's a function so presumably most functions like this in these papers and
[00:46:25.120 --> 00:46:28.960]   neural networks okay so we're finally at a point where this actually is going to make
[00:46:28.960 --> 00:46:35.440]   perfect sense we've got the noise we've got the prediction of that noise we subtract one
[00:46:35.440 --> 00:46:43.680]   from the other we square it and we take the expected value so in other words this is mean
[00:46:43.680 --> 00:46:50.340]   squared error so well that's a lot of fiddling around to find out that we've this whole thing
[00:46:50.340 --> 00:46:56.900]   here means mean squared error so the loss function is the mean squared error and unfortunately
[00:46:56.900 --> 00:47:00.680]   I don't think the paper ever says that it says minimizing the denoising objective L
[00:47:00.680 --> 00:47:11.160]   bloody bloody bloody but anyway we got there eventually fine we also as well as learning
[00:47:11.160 --> 00:47:20.160]   about X naught we also learn here about X T and so X T is the original unnoised image
[00:47:20.160 --> 00:47:29.560]   times some number plus some noise times one minus that number okay and so hopefully you'll
[00:47:29.560 --> 00:47:34.280]   recognize this from lesson 9b this is the thing where we reduce the value of each pixel
[00:47:34.280 --> 00:47:42.540]   and we add noise to each pixel so that's that all right so I'm not going to keep going through
[00:47:42.540 --> 00:47:47.280]   it but you can kind of basically get the idea here is that once you know what you're looking
[00:47:47.280 --> 00:47:55.960]   for the equations do actually make sense right but but all this is doing is remember this
[00:47:55.960 --> 00:48:00.760]   is background right this is telling you what already exists this is telling you this is
[00:48:00.760 --> 00:48:10.640]   what a DDPM is and then it tells you what a DDIM is DDIM is let's think of it as a more
[00:48:10.640 --> 00:48:18.600]   recent version of DDPM it's some very minor changes to the to the way it's set up which
[00:48:18.600 --> 00:48:26.880]   allows us to go faster okay so the thing is though once we keep reading what you'll find
[00:48:26.880 --> 00:48:33.320]   is none of this background actually matters but you know I thought we'd kind of go through
[00:48:33.320 --> 00:48:41.080]   it just to get a sense of like what what's in a paper okay so for the purpose of our
[00:48:41.080 --> 00:48:47.640]   background it's enough to know that DDPM and DDIM are kind of the foundational papers on
[00:48:47.640 --> 00:49:07.640]   which diffusion models today based okay so the encoding process which encodes an image
[00:49:07.640 --> 00:49:16.440]   onto a latent variable okay and then this is basically adding noise this is called DDIM
[00:49:16.440 --> 00:49:23.120]   encoding and the thing that goes from the input image to the noised image they're going to
[00:49:23.120 --> 00:49:29.360]   call capital ER and R is the encoding ratios that's going to be some like how much noise
[00:49:29.360 --> 00:49:37.400]   are we adding if you use small steps then decoding that so going backwards gives you
[00:49:37.400 --> 00:49:40.120]   back the original image okay so that's what the stuff that we've learned about that's
[00:49:40.120 --> 00:49:50.680]   what diffusion models are all right so this looks like a very useful picture so maybe
[00:49:50.680 --> 00:49:55.760]   let's take a look and see what this says so what is diffedit diffedit has three steps
[00:49:55.760 --> 00:50:01.360]   step one we add noise to the input image that sounds pretty normal here's our input image
[00:50:01.360 --> 00:50:12.280]   x naught okay and we add noise to it fine and then we denoise it okay fine ah but we
[00:50:12.280 --> 00:50:25.680]   denoise it twice one time we denoise it using the reference text R horse or this special
[00:50:25.680 --> 00:50:31.560]   symbol here means nothing at all so either unconditional or horse all right so we do
[00:50:31.560 --> 00:50:39.680]   it once using the word horse so we take this and we decode it estimate the noise and then
[00:50:39.680 --> 00:50:49.840]   we can remove that noise on the assumption that it's a horse then we do it again but
[00:50:49.840 --> 00:50:57.200]   the second time we do that noise when we calculate the noise we pass in our query Q which is
[00:50:57.200 --> 00:51:04.320]   zebra wow those are going to be very different noises the noise for horse is just going to
[00:51:04.320 --> 00:51:10.240]   be literally these Gaussian pixels these are all dots right because it is a horse but if
[00:51:10.240 --> 00:51:15.800]   the claim is no no this is actually a zebra then all of these pixels here are all wrong
[00:51:15.800 --> 00:51:23.940]   they're all the wrong color so the noise that's calculated if we say this is our query it's
[00:51:23.940 --> 00:51:28.200]   going to be totally different to the noise if we say this is our query and so then we
[00:51:28.200 --> 00:51:35.000]   just take one minus the other and here it is here right so we derive a mask based on
[00:51:35.000 --> 00:51:41.040]   the difference in the denoising results and then you take that and binarize it so basically
[00:51:41.040 --> 00:51:49.080]   turn that into ones and zeros so that's actually the key idea that's a really cool idea which
[00:51:49.080 --> 00:51:54.000]   is that once you have a diffusion model that's trained you can do inference on it where you
[00:51:54.000 --> 00:51:59.400]   tell it the truth about what the thing is and then you can do it again but lie about
[00:51:59.400 --> 00:52:04.200]   what the thing is and in your lying version it's going to say okay all the stuff that
[00:52:04.200 --> 00:52:10.160]   doesn't match zebra must be noise and so the difference between the noise prediction when
[00:52:10.160 --> 00:52:15.160]   you say hey it's a zebra versus the noise prediction when you say hey it's a horse will
[00:52:15.160 --> 00:52:22.400]   be all the pixels that it says no these pixels are not zebra the rest of it it's fine there's
[00:52:22.400 --> 00:52:29.380]   nothing particularly about the background that wouldn't work with a zebra okay so that's
[00:52:29.380 --> 00:52:45.160]   step one so then step two is we take the horse and we add noise to it okay that's this XR
[00:52:45.160 --> 00:52:54.120]   thing that we learned about before and then step three we deducating conditioned on the
[00:52:54.120 --> 00:53:01.400]   text query using the mask to replace the background with pixel values so this is like the idea
[00:53:01.400 --> 00:53:07.760]   that we heard about before which is that during the inference time as you do diffusion from
[00:53:07.760 --> 00:53:17.080]   this fuzzy horse what happens is that we do a step of diffusion inference and then all
[00:53:17.080 --> 00:53:23.240]   these black pixels we replace with the noised version of the original and so we do that
[00:53:23.240 --> 00:53:29.300]   multiple times and so that means that the original pixels in this black area won't get
[00:53:29.300 --> 00:53:35.760]   changed and that's why you can see in this picture here and this picture here the backgrounds
[00:53:35.760 --> 00:53:43.600]   all the same and the only thing that's changed is that the horse has been turned into a zebra
[00:53:43.600 --> 00:53:51.040]   so this paragraph describes it and then you can see here it gives you in a lot more detail
[00:53:51.040 --> 00:53:56.300]   and the detail often has all kinds of like little tips about things they tried and things
[00:53:56.300 --> 00:54:05.880]   they found which is pretty cool so I won't read through all that because it says the
[00:54:05.880 --> 00:54:10.920]   same as what I've already just said one of the interesting little things they noted note
[00:54:10.920 --> 00:54:18.080]   here actually is that this binarized mask so this difference between the R decoding
[00:54:18.080 --> 00:54:24.240]   and the Q decoding tends to be a bit bigger than the actual area where the horse is which
[00:54:24.240 --> 00:54:28.080]   you can kind of see with these legs for example and their point is that they actually say
[00:54:28.080 --> 00:54:32.920]   that's a good thing because actually often you want to slightly change some of the details
[00:54:32.920 --> 00:54:41.440]   around the object so this is actually fine all right so we have a description of what
[00:54:41.440 --> 00:54:46.840]   the thing is lots of details there and then here's the bit that I totally skip the bit
[00:54:46.840 --> 00:54:51.720]   called theoretical analysis where this is the stuff that people really generally just
[00:54:51.720 --> 00:54:56.720]   add to try to get their papers past review you have to have fancy math and so they're
[00:54:56.720 --> 00:55:03.020]   basically proving you can see what it says here insight into why this component yields
[00:55:03.020 --> 00:55:08.440]   better editing results than other approaches I'm not sure we particularly care because
[00:55:08.440 --> 00:55:13.520]   like it makes perfect sense what they're doing it's intuitive and we can see it works I don't
[00:55:13.520 --> 00:55:19.800]   feel like I need it proven to me so I skip over that so then they'll show us their experiments
[00:55:19.800 --> 00:55:27.360]   to tell us what datasets they you did the experiments on and so then you know they have
[00:55:27.360 --> 00:55:34.440]   metrics with names like LP IPS and CSF ID you'll come across F ID a lot this is just
[00:55:34.440 --> 00:55:41.360]   a version of that where basically they're trying to score how good their generated images
[00:55:41.360 --> 00:55:45.240]   and we don't normally care about that either they care because they need to be able to
[00:55:45.240 --> 00:55:48.920]   say you should publish our paper because it has a higher number than the other people
[00:55:48.920 --> 00:55:56.520]   that have worked on this area in our case we can just say yeah you know it looks good
[00:55:56.520 --> 00:56:04.060]   I like it so excellent question in the chat from Michelage which is so with this only
[00:56:04.060 --> 00:56:08.840]   work on things that are relatively similar and I think this is a great point right this
[00:56:08.840 --> 00:56:14.440]   is where understanding this helps to know what its limitations are going to be and that's
[00:56:14.440 --> 00:56:21.840]   exactly right if if you can't come up with a mask for the change you want this isn't
[00:56:21.840 --> 00:56:27.680]   going to work very well on on the whole yeah because those the masked areas the pixels
[00:56:27.680 --> 00:56:34.280]   going to be copied so for example if you wanted to change it from you know a bowl of fruits
[00:56:34.280 --> 00:56:41.920]   to a bowl of fruits with a bokeh background I don't know like a bowl of fruits with you
[00:56:41.920 --> 00:56:46.920]   know with a you know a purple tinged photo of a bowl of fruit if you want the whole color
[00:56:46.920 --> 00:56:52.120]   to change that's not going to work right because you're not masking off an area yeah so by
[00:56:52.120 --> 00:56:59.080]   understanding the detail here Michelage is correctly recognized a limitation or or like
[00:56:59.080 --> 00:57:03.520]   what's this for this is the things where you can just say just change this bit and leave
[00:57:03.520 --> 00:57:12.120]   everything else the same all right so there's lots of experiments so yeah for some things
[00:57:12.120 --> 00:57:15.680]   do you care about the experiments a lot if it's something like classification first up
[00:57:15.680 --> 00:57:21.040]   for generation the main thing you probably want to look at is the actual results and
[00:57:21.040 --> 00:57:26.900]   so and often for whatever reason I guess because this is most people read these electronically
[00:57:26.900 --> 00:57:29.800]   the results often you have to zoom into a lot to be able to see whether they're any
[00:57:29.800 --> 00:57:36.200]   pretty good so here's the input image they want to turn this into an English foxhound
[00:57:36.200 --> 00:57:41.120]   so here's the thing they're comparing themselves to SD edit and it changed the composition
[00:57:41.120 --> 00:57:47.000]   quite a lot and their version it hasn't changed it at all it's only changed the dog and ditto
[00:57:47.000 --> 00:57:53.720]   here semi-trailer truck SD edits totally changed it if edit hasn't so you can kind of get a
[00:57:53.720 --> 00:57:58.600]   sense of like you know the author's showing off what they're good at here this is this
[00:57:58.600 --> 00:58:06.360]   is what this technique is effective at doing changing animals and vehicles and so forth
[00:58:06.360 --> 00:58:15.920]   it does a very good job of it all right so then there's going to be a conclusion at the
[00:58:15.920 --> 00:58:22.120]   end which I find almost never adds anything on top of what we've already read and as you
[00:58:22.120 --> 00:58:33.480]   can see it's very short anyway now quite often the appendices are really interesting so don't
[00:58:33.480 --> 00:58:39.000]   skip over them often you'll find like more examples of pictures they might show some
[00:58:39.000 --> 00:58:44.180]   examples of pictures that didn't work very well stuff like that so it's often well worth
[00:58:44.180 --> 00:58:51.040]   looking at the appendices often some of the most interesting examples are there and that's
[00:58:51.040 --> 00:58:57.720]   it all right so that is I guess our first full-on paper walkthrough and you know it's
[00:58:57.720 --> 00:59:04.640]   important to remember this is not like a carefully chosen paper that that we've picked specifically
[00:59:04.640 --> 00:59:08.120]   because you can handle it like this is the most interesting paper that came out this
[00:59:08.120 --> 00:59:17.840]   week and so you know it gives you a sense of what it's really like and for those of
[00:59:17.840 --> 00:59:23.880]   you who are you know ready to try something that's going to stretch you see if you can
[00:59:23.880 --> 00:59:31.260]   implement any of this paper so there are three steps the first step is kind of the most interesting
[00:59:31.260 --> 00:59:37.480]   one which is to generate automatically generate a mask and the information that you have and
[00:59:37.480 --> 00:59:43.720]   the code that's in the lesson 9 notebook actually contains everything you need to do it so maybe
[00:59:43.720 --> 00:59:51.160]   give it a go see if you can mask out the area of a horse that does not look like a zebra
[00:59:51.160 --> 00:59:54.920]   and that's actually you know that's actually useful of itself like that's that's allows
[00:59:54.920 --> 01:00:01.040]   you to create segmentation masks automatically so that's pretty cool and then if you get
[01:00:01.040 --> 01:00:05.920]   that working then you can go and try and do step two if you get that working you can try
[01:00:05.920 --> 01:00:15.120]   and do step three and this only came out this week so I haven't really seen examples of
[01:00:15.120 --> 01:00:19.600]   easy to use interfaces to this so here's an example of a paper that you could be the first
[01:00:19.600 --> 01:00:25.160]   person to create a call interface to it so there's some yeah there's a fun little project
[01:00:25.160 --> 01:00:29.040]   and even if you're watching this a long time after this was released and everybody's been
[01:00:29.040 --> 01:00:41.040]   doing this for years still good homework I think to to practice if you can alright I
[01:00:41.040 --> 01:01:00.320]   think now's a good time to have a 10 minute break so I'll see you all back here in 10
[01:01:00.320 --> 01:01:05.720]   minutes.
[01:01:05.720 --> 01:01:10.960]   And pop questions into the forum topic if you've got questions that haven't been answered
[01:01:10.960 --> 01:01:11.960]   yet.
[01:01:11.960 --> 01:01:40.960]   Okay.
[01:01:40.960 --> 01:02:05.960]   Okay.
[01:02:05.960 --> 01:02:34.960]   Okay.
[01:02:34.960 --> 01:03:03.960]   Okay.
[01:03:03.960 --> 01:03:31.960]   Okay.
[01:03:31.960 --> 01:03:32.960]   Okay.
[01:03:32.960 --> 01:03:33.960]   Okay.
[01:03:33.960 --> 01:03:34.960]   Okay.
[01:03:34.960 --> 01:03:35.960]   Okay.
[01:03:35.960 --> 01:03:36.960]   Okay.
[01:03:37.960 --> 01:03:38.960]   Okay.
[01:03:38.960 --> 01:03:39.960]   Okay.
[01:03:40.960 --> 01:03:41.960]   Okay.
[01:03:41.960 --> 01:03:42.960]   Okay.
[01:03:43.960 --> 01:03:44.960]   Okay.
[01:03:44.960 --> 01:03:45.960]   Okay.
[01:03:46.960 --> 01:03:47.960]   Okay.
[01:03:47.960 --> 01:03:48.960]   Okay.
[01:03:49.960 --> 01:03:50.960]   Okay.
[01:03:50.960 --> 01:03:51.960]   Okay.
[01:03:52.960 --> 01:03:53.960]   Okay.
[01:03:53.960 --> 01:03:54.960]   Okay.
[01:03:55.960 --> 01:03:56.960]   Okay.
[01:03:56.960 --> 01:03:57.960]   Okay.
[01:03:58.960 --> 01:03:59.960]   Okay.
[01:03:59.960 --> 01:04:00.960]   Okay.
[01:04:00.960 --> 01:04:01.960]   Okay.
[01:04:01.960 --> 01:04:02.960]   Okay.
[01:04:02.960 --> 01:04:03.960]   Okay.
[01:04:03.960 --> 01:04:04.960]   Okay.
[01:04:04.960 --> 01:04:05.960]   Okay.
[01:04:05.960 --> 01:04:06.960]   Okay.
[01:04:06.960 --> 01:04:07.960]   Okay.
[01:04:07.960 --> 01:04:08.960]   Okay.
[01:04:08.960 --> 01:04:08.960]   Okay.
[01:04:09.960 --> 01:04:10.960]   Okay.
[01:04:10.960 --> 01:04:11.960]   Okay.
[01:04:12.960 --> 01:04:13.960]   Okay.
[01:04:14.960 --> 01:04:15.960]   Okay.
[01:04:15.960 --> 01:04:16.960]   Okay.
[01:04:16.960 --> 01:04:17.960]   Okay.
[01:04:17.960 --> 01:04:18.960]   Okay.
[01:04:18.960 --> 01:04:19.960]   Okay.
[01:04:19.960 --> 01:04:20.960]   Okay.
[01:04:20.960 --> 01:04:21.960]   Okay.
[01:04:21.960 --> 01:04:22.960]   Okay.
[01:04:22.960 --> 01:04:22.960]   Okay.
[01:04:22.960 --> 01:04:23.960]   Okay.
[01:04:23.960 --> 01:04:24.960]   Okay.
[01:04:24.960 --> 01:04:25.960]   Okay.
[01:04:25.960 --> 01:04:26.960]   Okay.
[01:04:26.960 --> 01:04:27.960]   Okay.
[01:04:27.960 --> 01:04:28.960]   Okay.
[01:04:28.960 --> 01:04:28.960]   Okay.
[01:04:29.960 --> 01:04:30.960]   Okay.
[01:04:30.960 --> 01:04:31.960]   Okay.
[01:04:31.960 --> 01:04:32.960]   Okay.
[01:04:32.960 --> 01:04:33.960]   Okay.
[01:04:33.960 --> 01:04:34.960]   Okay.
[01:04:34.960 --> 01:04:35.960]   Okay.
[01:04:35.960 --> 01:04:37.960]   (no audio)
[01:04:37.960 --> 01:04:39.960]   (no audio)
[01:04:39.960 --> 01:04:45.960]   (no audio)
[01:04:45.960 --> 01:04:51.960]   (no audio)
[01:04:51.960 --> 01:04:57.960]   (no audio)
[01:04:57.960 --> 01:05:03.960]   (no audio)
[01:05:03.960 --> 01:05:09.960]   (no audio)
[01:05:09.960 --> 01:05:15.960]   (no audio)
[01:05:15.960 --> 01:05:21.960]   (no audio)
[01:05:21.960 --> 01:05:27.960]   (no audio)
[01:05:27.960 --> 01:05:33.960]   (no audio)
[01:05:33.960 --> 01:05:39.960]   (no audio)
[01:05:39.960 --> 01:05:45.960]   (no audio)
[01:05:45.960 --> 01:05:51.960]   (no audio)
[01:05:51.960 --> 01:05:57.960]   (no audio)
[01:05:57.960 --> 01:06:03.960]   (no audio)
[01:06:03.960 --> 01:06:09.960]   (no audio)
[01:06:09.960 --> 01:06:15.960]   (no audio)
[01:06:15.960 --> 01:06:21.960]   (no audio)
[01:06:21.960 --> 01:06:27.960]   (no audio)
[01:06:27.960 --> 01:06:33.960]   (no audio)
[01:06:33.960 --> 01:06:39.960]   (no audio)
[01:06:39.960 --> 01:06:45.960]   (no audio)
[01:06:45.960 --> 01:06:51.960]   (no audio)
[01:06:51.960 --> 01:06:57.960]   (no audio)
[01:06:57.960 --> 01:07:03.960]   (no audio)
[01:07:03.960 --> 01:07:09.960]   (no audio)
[01:07:09.960 --> 01:07:15.960]   (no audio)
[01:07:15.960 --> 01:07:21.960]   (no audio)
[01:07:21.960 --> 01:07:27.960]   (no audio)
[01:07:27.960 --> 01:07:33.960]   (no audio)
[01:07:33.960 --> 01:07:39.960]   (no audio)
[01:07:39.960 --> 01:07:45.960]   (no audio)
[01:07:45.960 --> 01:07:51.960]   (no audio)
[01:07:51.960 --> 01:07:57.960]   (no audio)
[01:07:57.960 --> 01:08:03.960]   (no audio)
[01:08:03.960 --> 01:08:09.960]   (no audio)
[01:08:09.960 --> 01:08:15.960]   (no audio)
[01:08:15.960 --> 01:08:21.960]   (no audio)
[01:08:21.960 --> 01:08:27.960]   (no audio)
[01:08:27.960 --> 01:08:33.960]   (no audio)
[01:08:33.960 --> 01:08:39.960]   (no audio)
[01:08:39.960 --> 01:08:45.960]   (no audio)
[01:08:45.960 --> 01:08:51.960]   (no audio)
[01:08:51.960 --> 01:08:57.960]   (no audio)
[01:08:57.960 --> 01:09:03.960]   (no audio)
[01:09:03.960 --> 01:09:09.960]   (no audio)
[01:09:09.960 --> 01:09:15.960]   (no audio)
[01:09:15.960 --> 01:09:21.960]   (no audio)
[01:09:21.960 --> 01:09:27.960]   (no audio)
[01:09:27.960 --> 01:09:33.960]   (no audio)
[01:09:33.960 --> 01:09:39.960]   (no audio)
[01:09:39.960 --> 01:09:45.960]   (no audio)
[01:09:45.960 --> 01:09:51.960]   (no audio)
[01:09:51.960 --> 01:09:57.960]   (no audio)
[01:09:57.960 --> 01:10:03.960]   (no audio)
[01:10:03.960 --> 01:10:09.960]   (no audio)
[01:10:09.960 --> 01:10:15.960]   (no audio)
[01:10:15.960 --> 01:10:21.960]   (no audio)
[01:10:21.960 --> 01:10:27.960]   (no audio)
[01:10:27.960 --> 01:10:33.960]   (no audio)
[01:10:33.960 --> 01:10:39.960]   (no audio)
[01:10:39.960 --> 01:10:45.960]   (no audio)
[01:10:45.960 --> 01:10:51.960]   (no audio)
[01:10:51.960 --> 01:10:57.960]   (no audio)
[01:10:57.960 --> 01:11:03.960]   (no audio)
[01:11:03.960 --> 01:11:07.960]   (no audio)
[01:11:07.960 --> 01:11:13.960]   (no audio)
[01:11:13.960 --> 01:11:19.960]   (no audio)
[01:11:19.960 --> 01:11:25.960]   (no audio)
[01:11:25.960 --> 01:11:31.960]   (no audio)
[01:11:31.960 --> 01:11:37.960]   (no audio)
[01:11:37.960 --> 01:11:43.960]   (no audio)
[01:11:43.960 --> 01:11:49.960]   (no audio)
[01:11:49.960 --> 01:11:55.960]   (no audio)
[01:11:55.960 --> 01:12:01.960]   (no audio)
[01:12:01.960 --> 01:12:07.960]   (no audio)
[01:12:07.960 --> 01:12:13.960]   (no audio)
[01:12:13.960 --> 01:12:19.960]   (no audio)
[01:12:19.960 --> 01:12:25.960]   (no audio)
[01:12:25.960 --> 01:12:31.960]   (no audio)
[01:12:31.960 --> 01:12:37.960]   (no audio)
[01:12:37.960 --> 01:12:43.960]   (no audio)
[01:12:43.960 --> 01:12:49.960]   (no audio)
[01:12:49.960 --> 01:12:55.960]   (no audio)
[01:12:55.960 --> 01:13:01.960]   (no audio)
[01:13:01.960 --> 01:13:07.960]   (no audio)
[01:13:07.960 --> 01:13:13.960]   (no audio)
[01:13:13.960 --> 01:13:19.960]   (no audio)
[01:13:19.960 --> 01:13:25.960]   (no audio)
[01:13:25.960 --> 01:13:31.960]   (no audio)
[01:13:31.960 --> 01:13:37.960]   (no audio)
[01:13:37.960 --> 01:13:43.960]   (no audio)
[01:13:43.960 --> 01:13:49.960]   (no audio)
[01:13:49.960 --> 01:13:55.960]   (no audio)
[01:13:55.960 --> 01:14:01.960]   (no audio)
[01:14:01.960 --> 01:14:07.960]   (no audio)
[01:14:07.960 --> 01:14:13.960]   (no audio)
[01:14:13.960 --> 01:14:19.960]   (no audio)
[01:14:19.960 --> 01:14:25.960]   (no audio)
[01:14:25.960 --> 01:14:31.960]   (no audio)
[01:14:31.960 --> 01:14:37.960]   (no audio)
[01:14:37.960 --> 01:14:43.960]   (no audio)
[01:14:43.960 --> 01:14:49.960]   (no audio)
[01:14:49.960 --> 01:14:55.960]   (no audio)
[01:14:55.960 --> 01:15:01.960]   (no audio)
[01:15:01.960 --> 01:15:07.960]   (no audio)
[01:15:07.960 --> 01:15:13.960]   (no audio)
[01:15:13.960 --> 01:15:19.960]   (no audio)
[01:15:19.960 --> 01:15:25.960]   (no audio)
[01:15:25.960 --> 01:15:29.960]   Okay, welcome back. One thing
[01:15:29.960 --> 01:15:33.960]   during the break that Diego reminded us about, which
[01:15:33.960 --> 01:15:37.960]   I normally describe and I totally forgot about this time is
[01:15:37.960 --> 01:15:41.960]   detectify, which is another really great way to find symbols you
[01:15:41.960 --> 01:15:45.960]   don't know about. So let's try it for that expectation.
[01:15:45.960 --> 01:15:49.960]   So if you go to detectify, and
[01:15:49.960 --> 01:15:53.960]   you draw the thing.
[01:15:53.960 --> 01:15:57.960]   It doesn't always work fantastically well, but sometimes
[01:15:57.960 --> 01:16:01.960]   it works very nicely.
[01:16:01.960 --> 01:16:05.960]   Yeah, in this case not quite.
[01:16:05.960 --> 01:16:09.960]   What about the double line thing?
[01:16:09.960 --> 01:16:13.960]   It's good to know all the techniques, I guess.
[01:16:13.960 --> 01:16:17.960]   (no audio)
[01:16:17.960 --> 01:16:21.960]   You'd think you could do this one.
[01:16:21.960 --> 01:16:25.960]   I guess part of the problem is there's so many options that actually
[01:16:25.960 --> 01:16:29.960]   you know, okay, in this case it wasn't particularly helpful. Normally it's more helpful than that.
[01:16:29.960 --> 01:16:33.960]   I mean, if we use a simple one like epsilon,
[01:16:33.960 --> 01:16:37.960]   I think it should be fine. There's a lot of room to improve this app
[01:16:37.960 --> 01:16:41.960]   actually. If anybody's interested in a project, I think you could make
[01:16:41.960 --> 01:16:45.960]   it, you know, more successful. Okay, there you go.
[01:16:45.960 --> 01:16:49.960]   SignoSum, that's cool. Anyway, so it's another useful thing to know about. Just Google
[01:16:49.960 --> 01:16:53.960]   for detectify. Okay, so
[01:16:53.960 --> 01:16:57.960]   let's move on with our from the foundations now.
[01:16:57.960 --> 01:17:01.960]   And so we were working
[01:17:01.960 --> 01:17:05.960]   on trying to
[01:17:05.960 --> 01:17:09.960]   at least get the start of a forward pass of a linear model
[01:17:09.960 --> 01:17:13.960]   or a simple multi-layer perceptron
[01:17:13.960 --> 01:17:17.960]   for MNIST going. And we had successfully
[01:17:17.960 --> 01:17:21.960]   created a basic tensor. We've got some random numbers going.
[01:17:21.960 --> 01:17:25.960]   So what we now need to do is we now need
[01:17:25.960 --> 01:17:29.960]   to be able to multiply these things
[01:17:29.960 --> 01:17:33.960]   together, matrix multiplication. So matrix
[01:17:33.960 --> 01:17:37.960]   multiplication
[01:17:37.960 --> 01:17:41.960]   to remind you
[01:17:41.960 --> 01:17:45.960]   in this case, so we're doing MNIST, right? So we've
[01:17:45.960 --> 01:17:49.960]   got, well I think we're going to use a subset.
[01:17:49.960 --> 01:17:53.960]   Let's see. Yeah, okay. So we're going to
[01:17:53.960 --> 01:17:57.960]   create a matrix called M1, which is just the first five digits.
[01:17:57.960 --> 01:18:01.960]   So M1 will be the first five
[01:18:01.960 --> 01:18:05.960]   digits. So five rows.
[01:18:05.960 --> 01:18:09.960]   And dot dot dot
[01:18:09.960 --> 01:18:13.960]   dot dot dot. And then
[01:18:13.960 --> 01:18:17.960]   780, what was it again? 784 columns.
[01:18:17.960 --> 01:18:21.960]   784 columns. Because it's 28 by 28 pixels.
[01:18:21.960 --> 01:18:25.960]   And we flattened it out. So this is our
[01:18:25.960 --> 01:18:29.960]   first matrix and our matrix multiplication. And then we're going to
[01:18:29.960 --> 01:18:33.960]   multiply that by some weights.
[01:18:33.960 --> 01:18:37.960]   So
[01:18:37.960 --> 01:18:41.960]   the weights are going to be 784 by 10
[01:18:41.960 --> 01:18:45.960]   random numbers. So for every one of these
[01:18:45.960 --> 01:18:49.960]   784 pixels, each one is going to have a weight.
[01:18:49.960 --> 01:18:53.960]   So 784 down here.
[01:18:53.960 --> 01:18:57.960]   784
[01:18:57.960 --> 01:19:01.960]   by 10. So this first column, for example,
[01:19:01.960 --> 01:19:05.960]   is going to tell us all the weights
[01:19:05.960 --> 01:19:09.960]   in order to figure out if something's a zero. And the second column will have all the
[01:19:09.960 --> 01:19:13.960]   weights in deciding if the probability of something's a one and so forth, assuming we're just doing a linear model.
[01:19:13.960 --> 01:19:17.960]   And so then we're going to multiply these two matrices together.
[01:19:17.960 --> 01:19:21.960]   So when we multiply matrices together,
[01:19:21.960 --> 01:19:25.960]   we take row one of matrix one
[01:19:25.960 --> 01:19:29.960]   and we take column one of matrix
[01:19:29.960 --> 01:19:33.960]   two and we take each one in turns.
[01:19:33.960 --> 01:19:37.960]   We take this one and we take this one and we multiply them together.
[01:19:37.960 --> 01:19:41.960]   And then we take this one and this one
[01:19:41.960 --> 01:19:45.960]   and we multiply them together.
[01:19:45.960 --> 01:19:49.960]   And we do that for every element-wise pair
[01:19:49.960 --> 01:19:53.960]   and then we add them all up. And that would give us
[01:19:53.960 --> 01:19:57.960]   the value
[01:19:57.960 --> 01:20:01.960]   for the very first cell.
[01:20:01.960 --> 01:20:05.960]   That would go in here. That's what matrix
[01:20:05.960 --> 01:20:09.960]   multiplication is.
[01:20:09.960 --> 01:20:13.960]   So
[01:20:13.960 --> 01:20:17.960]   let's go ahead then and create our random numbers for the weights
[01:20:17.960 --> 01:20:21.960]   since we're allowed to use random number generators now. And for the bias
[01:20:21.960 --> 01:20:25.960]   we'll just use a bunch of zeros to start with.
[01:20:25.960 --> 01:20:29.960]   So the bias is just what we're going to add to each one.
[01:20:29.960 --> 01:20:33.960]   And so for our matrix multiplication we're going to be doing a little mini-batch here.
[01:20:33.960 --> 01:20:37.960]   We're going to be doing five rows of, as we discussed,
[01:20:37.960 --> 01:20:41.960]   five rows of, so five images
[01:20:41.960 --> 01:20:45.960]   flattened out
[01:20:45.960 --> 01:20:49.960]   and then multiplied by this
[01:20:49.960 --> 01:20:53.960]   weights matrix. So here are the shapes. M1 is 5
[01:20:53.960 --> 01:20:57.960]   by 784, as we saw. M2 is 784 by 10.
[01:20:57.960 --> 01:21:01.960]   So keep those in mind. So here's a handy
[01:21:01.960 --> 01:21:05.960]   thing. M1 dot shape contains two
[01:21:05.960 --> 01:21:09.960]   numbers and I want to pull them out. I want to call
[01:21:09.960 --> 01:21:13.960]   the, I'm going to think of that as, I'm going to actually think of this
[01:21:13.960 --> 01:21:17.960]   as like A and B rather than M1 and M2. So this is like A and B.
[01:21:17.960 --> 01:21:21.960]   So the number of rows in A and the number of columns in A
[01:21:21.960 --> 01:21:25.960]   if I say equals M1 dot shape, that will put
[01:21:25.960 --> 01:21:29.960]   5 in AR and 784 in AC.
[01:21:29.960 --> 01:21:33.960]   So you'll probably notice this. I do this a lot, this de-structure, and we talked about it last week too.
[01:21:33.960 --> 01:21:37.960]   So we can do the same for M2 dot shape, put that into B rows and B columns.
[01:21:37.960 --> 01:21:41.960]   And so now if I write out ARAC and
[01:21:41.960 --> 01:21:45.960]   BRBC, you can again see the same things from the sizes.
[01:21:45.960 --> 01:21:49.960]   So that's a good way to kind of give us the stuff we have to look through.
[01:21:49.960 --> 01:21:53.960]   So here's our result. So our resultant tensor,
[01:21:53.960 --> 01:21:57.960]   well we're multiplying together all of these
[01:21:57.960 --> 01:22:01.960]   784 things and adding them up. So the resultant tensor is going to be
[01:22:01.960 --> 01:22:05.960]   5 by 10.
[01:22:05.960 --> 01:22:09.960]   And then each thing in here is the result of multiplying and adding
[01:22:09.960 --> 01:22:13.960]   784 pairs.
[01:22:13.960 --> 01:22:17.960]   So the result here is going to start with zeros
[01:22:17.960 --> 01:22:21.960]   and this is the result and it's going to contain
[01:22:21.960 --> 01:22:25.960]   AR rows, 5 rows, and BC columns,
[01:22:25.960 --> 01:22:29.960]   10 columns, 5 comma 10. So now we have to fill that in.
[01:22:29.960 --> 01:22:33.960]   And so to do a matrix multiplication,
[01:22:33.960 --> 01:22:37.960]   first we have to go through each row one at a time.
[01:22:37.960 --> 01:22:41.960]   And
[01:22:41.960 --> 01:22:45.960]   here we have that. Go through each row one at a time.
[01:22:45.960 --> 01:22:49.960]   And then go through each column
[01:22:49.960 --> 01:22:53.960]   one at a time. And then we have to go through each
[01:22:53.960 --> 01:22:57.960]   pair in that row column one at a time. So there's going to be a loop,
[01:22:57.960 --> 01:23:01.960]   in a loop, in a loop.
[01:23:01.960 --> 01:23:05.960]   So here we're going to loop over each row.
[01:23:05.960 --> 01:23:09.960]   And here we're going to loop over each column. And then here
[01:23:09.960 --> 01:23:13.960]   we're going to loop over each column of C. And then here we're going to loop over
[01:23:13.960 --> 01:23:17.960]   each column of A, which is going to be
[01:23:17.960 --> 01:23:21.960]   the same as the number of rows of B, which we can see here
[01:23:21.960 --> 01:23:25.960]   AC, 784, BR, 784, they're the same.
[01:23:25.960 --> 01:23:29.960]   So it wouldn't matter whether we said AC or BR. So then our result
[01:23:29.960 --> 01:23:33.960]   for that row and that column
[01:23:33.960 --> 01:23:37.960]   we have to add onto it the product
[01:23:37.960 --> 01:23:41.960]   of IK
[01:23:41.960 --> 01:23:45.960]   in the first matrix by KJ in the second matrix.
[01:23:45.960 --> 01:23:49.960]   So K is going up through those 784
[01:23:49.960 --> 01:23:53.960]   and so we're going to go across the columns and down, sorry, across the rows
[01:23:53.960 --> 01:23:57.960]   and down the columns. So it's going to go across the row whilst it goes
[01:23:57.960 --> 01:24:01.960]   down this column. So here is the world's
[01:24:01.960 --> 01:24:05.960]   most naive, slow, uninteresting matrix
[01:24:05.960 --> 01:24:09.960]   multiplication.
[01:24:09.960 --> 01:24:13.960]   And if we run it, okay, it's done something.
[01:24:13.960 --> 01:24:17.960]   We have successfully, apparently hopefully successfully,
[01:24:17.960 --> 01:24:21.960]   multiplied the matrices M1 and M2. It's a little hard to read this I find
[01:24:21.960 --> 01:24:25.960]   because
[01:24:25.960 --> 01:24:29.960]   lunch cards used to be 80 columns wide. We still assume screens are 80
[01:24:29.960 --> 01:24:33.960]   columns wide. Everything defaults to 80 wide, which is ridiculous.
[01:24:33.960 --> 01:24:37.960]   But you can easily change it. So if you say
[01:24:37.960 --> 01:24:41.960]   set print options you can choose your own line width.
[01:24:41.960 --> 01:24:45.960]   You can see, well we know that's 5 by 10, we did it before.
[01:24:45.960 --> 01:24:49.960]   So if we change the line width, okay, that's much easier to read now. We can see here
[01:24:49.960 --> 01:24:53.960]   the five rows and here are the ten columns for that matrix
[01:24:53.960 --> 01:24:57.960]   multiplication. I tend to always put this
[01:24:57.960 --> 01:25:01.960]   at the top of my notebooks and you can do the same thing for NumPy as well.
[01:25:01.960 --> 01:25:09.960]   So what I like to do, this is
[01:25:09.960 --> 01:25:13.960]   really important, is when I'm working on
[01:25:13.960 --> 01:25:17.960]   code, particularly numeric code, I like to do it all
[01:25:17.960 --> 01:25:21.960]   step by step in Jupyter. And then what I do
[01:25:21.960 --> 01:25:25.960]   is once I've got it working is I copy
[01:25:25.960 --> 01:25:29.960]   all the cells that have implemented that and I paste them
[01:25:29.960 --> 01:25:33.960]   and then I select them all and I hit shift M to merge.
[01:25:33.960 --> 01:25:37.960]   Get rid of anything that prints out stuff I don't need.
[01:25:37.960 --> 01:25:41.960]   And then I put a header on the top, give it a function name.
[01:25:41.960 --> 01:25:45.960]   And then I select the whole lot and I hit
[01:25:45.960 --> 01:25:49.960]   control or apple right square bracket and I've turned it into a function.
[01:25:49.960 --> 01:25:53.960]   But I still keep the stuff above it so I can see all the step by step stuff
[01:25:53.960 --> 01:25:57.960]   for learning about it later.
[01:25:57.960 --> 01:26:01.960]   And so that's what I've done here to create this function.
[01:26:01.960 --> 01:26:05.960]   And so this function does exactly the same things we just did
[01:26:05.960 --> 01:26:09.960]   and we can see how long it takes to run by using percent time.
[01:26:09.960 --> 01:26:13.960]   And it took about half a second.
[01:26:13.960 --> 01:26:17.960]   Which, gosh, that's a long time to generate
[01:26:17.960 --> 01:26:21.960]   such a small matrix. This is just to do five
[01:26:21.960 --> 01:26:25.960]   MNIST digits. So that's
[01:26:25.960 --> 01:26:29.960]   not going to be great. We're going to have to speed that up.
[01:26:29.960 --> 01:26:33.960]   I'm actually quite surprised at how slow that is because there's only
[01:26:33.960 --> 01:26:37.960]   39,200. So if you look at how
[01:26:37.960 --> 01:26:41.960]   we've got a loop within a loop within a loop.
[01:26:41.960 --> 01:26:45.960]   It's doing 39,200 of these.
[01:26:45.960 --> 01:26:49.960]   Python, yeah. Python, when you're just doing Python, it is slow.
[01:26:49.960 --> 01:26:53.960]   So we can't do that. That's why we can't
[01:26:53.960 --> 01:26:57.960]   just write Python. But there is something that kind of
[01:26:57.960 --> 01:27:01.960]   lets us write Python. We could instead use number.
[01:27:01.960 --> 01:27:05.960]   Number is
[01:27:05.960 --> 01:27:09.960]   a system that takes Python
[01:27:09.960 --> 01:27:13.960]   and turns it into
[01:27:13.960 --> 01:27:17.960]   basically into machine code. And it's
[01:27:17.960 --> 01:27:21.960]   amazingly easy to do. You can basically take a function
[01:27:21.960 --> 01:27:25.960]   and write njit at njit on top.
[01:27:25.960 --> 01:27:29.960]   And what it's going to do is it's going to look, the first
[01:27:29.960 --> 01:27:33.960]   time you call this function, it's going to compile it down to machine code.
[01:27:33.960 --> 01:27:37.960]   And it will run much more quickly. So what
[01:27:37.960 --> 01:27:41.960]   I've done here is I've taken the innermost loop.
[01:27:41.960 --> 01:27:45.960]   So just looping through and adding
[01:27:45.960 --> 01:27:49.960]   up all these.
[01:27:49.960 --> 01:27:53.960]   So start at zero, go through and add up all those.
[01:27:53.960 --> 01:27:57.960]   Just for two vectors and return it.
[01:27:57.960 --> 01:28:01.960]   This is called a dot product in linear algebra. So we'll call it dot.
[01:28:01.960 --> 01:28:05.960]   And so number only works with numpy.
[01:28:05.960 --> 01:28:09.960]   It doesn't work with pytorch. So we're just going to use arrays instead of tensors for a moment.
[01:28:09.960 --> 01:28:13.960]   Now have a look at this. If I try to do a dot product of
[01:28:13.960 --> 01:28:17.960]   one, two, three, and two, three, four, it's pretty easy to do.
[01:28:17.960 --> 01:28:21.960]   It took a fifth of a second, which sounds
[01:28:21.960 --> 01:28:25.960]   terrible. But the reason it took a fifth of a second is because that's actually
[01:28:25.960 --> 01:28:29.960]   how long it took to compile this and run it. Now that it's compiled
[01:28:29.960 --> 01:28:33.960]   the second time, it just has to call it.
[01:28:33.960 --> 01:28:37.960]   It's now 21 microseconds. And so that's actually very fast.
[01:28:37.960 --> 01:28:41.960]   So with number, we can basically
[01:28:41.960 --> 01:28:45.960]   make Python run at C speed.
[01:28:45.960 --> 01:28:49.960]   So now the important thing to recognize is if I
[01:28:49.960 --> 01:28:53.960]   replace this loop
[01:28:53.960 --> 01:28:57.960]   in Python with a called a dot
[01:28:57.960 --> 01:29:01.960]   which is running in machine code, then we now have
[01:29:01.960 --> 01:29:05.960]   one, two loops running in Python.
[01:29:05.960 --> 01:29:09.960]   And then we have dot three. So our
[01:29:09.960 --> 01:29:13.960]   448 milliseconds
[01:29:13.960 --> 01:29:17.960]   well, first of all, let's make sure if I run it
[01:29:17.960 --> 01:29:21.960]   run that matmul
[01:29:21.960 --> 01:29:25.960]   it should be close to my T1. T1 is what
[01:29:25.960 --> 01:29:29.960]   we got before, remember?
[01:29:29.960 --> 01:29:33.960]   So when I'm refactoring or performance improving or whatever, I always like to put
[01:29:33.960 --> 01:29:37.960]   every step in the notebook and then test. So this
[01:29:37.960 --> 01:29:41.960]   test close comes from fastcore.test and it just checks that two things are
[01:29:41.960 --> 01:29:45.960]   very similar. They might not be exactly the same because of little floating point differences
[01:29:45.960 --> 01:29:49.960]   which is fine. Okay, so our matmul is working correctly, or at least it's
[01:29:49.960 --> 01:29:53.960]   doing the same thing it did before. So if we now run it
[01:29:53.960 --> 01:29:57.960]   it's taking 268 microseconds
[01:29:57.960 --> 01:30:01.960]   versus 448 milliseconds.
[01:30:01.960 --> 01:30:05.960]   So it's taking
[01:30:05.960 --> 01:30:09.960]   about 2,000 times faster just by changing
[01:30:09.960 --> 01:30:13.960]   the one innermost loop. So really all we've done is we've added
[01:30:13.960 --> 01:30:17.960]   @endgit to make it 2,000 times faster.
[01:30:17.960 --> 01:30:21.960]   So number is well worth knowing about. It can make your Python code
[01:30:21.960 --> 01:30:25.960]   very, very fast. Okay,
[01:30:25.960 --> 01:30:29.960]   let's keep making it faster.
[01:30:29.960 --> 01:30:33.960]   So we're going to use stuff again which kind of goes back to
[01:30:33.960 --> 01:30:37.960]   APL. And a lot of
[01:30:37.960 --> 01:30:41.960]   people say that learning APL is a thing that's taught them more about programming than anything
[01:30:41.960 --> 01:30:45.960]   else. So it's probably worth considering
[01:30:45.960 --> 01:30:49.960]   learning APL. And let's just
[01:30:49.960 --> 01:30:53.960]   look at these various things. We've got a is 10, 6, minus 4.
[01:30:53.960 --> 01:30:57.960]   So remember in APL we don't say equals, equals actually means
[01:30:57.960 --> 01:31:01.960]   equals funnily enough. To say set to we use this arrow.
[01:31:01.960 --> 01:31:05.960]   And this is a list of 10, 6, 4.
[01:31:05.960 --> 01:31:09.960]   Okay, and then B is
[01:31:09.960 --> 01:31:13.960]   287.
[01:31:13.960 --> 01:31:17.960]   Okay, and we're going to add them up.
[01:31:17.960 --> 01:31:21.960]   A plus B.
[01:31:21.960 --> 01:31:25.960]   So what's going on here? So it's really important that you
[01:31:25.960 --> 01:31:29.960]   can think of a symbol
[01:31:29.960 --> 01:31:33.960]   like A as representing
[01:31:33.960 --> 01:31:37.960]   a tensor or an array.
[01:31:37.960 --> 01:31:41.960]   APL calls them arrays. PyTorch calls them tensors. NumPy calls them arrays.
[01:31:41.960 --> 01:31:45.960]   They're the same thing. So this is a single thing that contains a bunch of numbers.
[01:31:45.960 --> 01:31:49.960]   This is a single thing that contains a bunch of numbers. This is an operation
[01:31:49.960 --> 01:31:53.960]   that applies to arrays or tensors. And what it does is it works what's
[01:31:53.960 --> 01:31:57.960]   called element-wise. It takes each pair, 10 and 2, and adds them
[01:31:57.960 --> 01:32:01.960]   together. Each pair, 6 and 8, add them together. This is
[01:32:01.960 --> 01:32:05.960]   element-wise addition. And Fred's asking in the chat how do you
[01:32:05.960 --> 01:32:09.960]   put in these symbols. If you just mouse over any of them
[01:32:09.960 --> 01:32:13.960]   it will show you how to write it. And the one you want is
[01:32:13.960 --> 01:32:17.960]   the one at the very bottom, which is the one
[01:32:17.960 --> 01:32:21.960]   where it says prefix. Now the prefix is the backtick character.
[01:32:21.960 --> 01:32:25.960]   So here it's saying prefix hyphen gives us times.
[01:32:25.960 --> 01:32:29.960]   A
[01:32:29.960 --> 01:32:33.960]   backtick- B is A times B, for example.
[01:32:33.960 --> 01:32:37.960]   So yeah, they all have shortcut keys which you learn
[01:32:37.960 --> 01:32:41.960]   pretty quickly, I find. And there's a fairly
[01:32:41.960 --> 01:32:45.960]   consistent kind of system for those shortcut keys too.
[01:32:45.960 --> 01:32:49.960]   Alright, so we can do the same thing in PyTorch. It's a little bit more
[01:32:49.960 --> 01:32:53.960]   verbose in PyTorch, which is one reason I often like to do my
[01:32:53.960 --> 01:32:57.960]   mathematical fiddling around in APL. I can often do it with less
[01:32:57.960 --> 01:33:01.960]   boilerplate, which means I can spend more time thinking.
[01:33:01.960 --> 01:33:05.960]   You know, I can see everything on the screen at once. I don't have to spend as much time
[01:33:05.960 --> 01:33:09.960]   trying to like ignore the tensor, round bracket, square bracket, dot
[01:33:09.960 --> 01:33:13.960]   comma, blah blah blah. It's all cognitive load, which I'd rather ignore.
[01:33:13.960 --> 01:33:17.960]   But anyway, it does the same thing. So I can say A plus B, and it works exactly
[01:33:17.960 --> 01:33:21.960]   like APL. So here's an interesting
[01:33:21.960 --> 01:33:25.960]   example. I can go A less than B
[01:33:25.960 --> 01:33:29.960]   dot float dot mean. So let's try that one over here.
[01:33:29.960 --> 01:33:33.960]   A less than B. So this is a really important idea which I think was
[01:33:33.960 --> 01:33:37.960]   invented by Ken Iverson, the APL guy, which is the true and false
[01:33:37.960 --> 01:33:41.960]   represented by 0 and 1. And because they're represented
[01:33:41.960 --> 01:33:45.960]   by 0 and 1, we can
[01:33:45.960 --> 01:33:49.960]   do things to them. We can add them up and subtract them and so forth. It's a really
[01:33:49.960 --> 01:33:53.960]   important idea. So in this case I
[01:33:53.960 --> 01:33:57.960]   want to take the mean of them. And I'm going to tell you something
[01:33:57.960 --> 01:34:01.960]   amazing, which is that in APL
[01:34:01.960 --> 01:34:05.960]   there is no function called mean. Why not?
[01:34:05.960 --> 01:34:09.960]   That's because we can write the mean function
[01:34:09.960 --> 01:34:13.960]   which, so that's four letters, mean, M-E-A-N, we can write the mean function
[01:34:13.960 --> 01:34:17.960]   from scratch with four characters.
[01:34:17.960 --> 01:34:21.960]   I'll show you. Here is the whole mean function. We're going to create
[01:34:21.960 --> 01:34:25.960]   a function called mean. And the mean is equal to the sum
[01:34:25.960 --> 01:34:29.960]   of a list divided by
[01:34:29.960 --> 01:34:33.960]   the count of a list.
[01:34:33.960 --> 01:34:37.960]   So this here is sum divided by count. And so I have now
[01:34:37.960 --> 01:34:41.960]   defined a new function called mean, which calculates the mean.
[01:34:41.960 --> 01:34:45.960]   The mean of a is less than b.
[01:34:45.960 --> 01:34:49.960]   There we go. And so in practice I'm not sure people would even bother
[01:34:49.960 --> 01:34:53.960]   defining a function called mean because it's just as easy to actually write its implementation
[01:34:53.960 --> 01:34:57.960]   in APL, in NumPy
[01:34:57.960 --> 01:35:01.960]   or whatever Python. It's going to take a lot more than four letters to implement
[01:35:01.960 --> 01:35:05.960]   mean. So anyway, it's a math notation. And so being a math notation
[01:35:05.960 --> 01:35:09.960]   we can do a lot with a little, which I find helpful because I can
[01:35:09.960 --> 01:35:13.960]   see everything going on at once.
[01:35:13.960 --> 01:35:17.960]   So that's how we do the same thing in PyTorch. And again, you can see that the less than
[01:35:17.960 --> 01:35:21.960]   in both cases are operating element-wise. So a is less than b
[01:35:21.960 --> 01:35:25.960]   is saying ten is less than two, six is less than eight, four is less than seven
[01:35:25.960 --> 01:35:29.960]   and gives us back each of those trues and falses as zeros and ones.
[01:35:29.960 --> 01:35:33.960]   And according to the emoji on our YouTube chat, Siva's head just exploded
[01:35:33.960 --> 01:35:37.960]   as it should. This is why APL is
[01:35:37.960 --> 01:35:41.960]   life-changing.
[01:35:41.960 --> 01:35:45.960]   Okay, let's now go up to higher ranks. So this here is a
[01:35:45.960 --> 01:35:49.960]   rank one tensor. So a rank one tensor
[01:35:49.960 --> 01:35:53.960]   means it's a list of things. It's a vector.
[01:35:53.960 --> 01:35:57.960]   Where else a rank two tensor is like
[01:35:57.960 --> 01:36:01.960]   a list of lists. They all have to be the same length lists. Or it's like a rectangular
[01:36:01.960 --> 01:36:05.960]   bunch of numbers. And we call it, in math we call it a matrix.
[01:36:05.960 --> 01:36:09.960]   So this is how we can create a tensor containing one, two, three, four, five, six, seven, eight, nine.
[01:36:09.960 --> 01:36:13.960]   And you can see often what I like to do
[01:36:13.960 --> 01:36:17.960]   is I want to print out the thing I just created after I
[01:36:17.960 --> 01:36:21.960]   created it. So two ways to do it. You can say put an enter
[01:36:21.960 --> 01:36:25.960]   and then write m and that's going to do that. Or if you want to put it all on the same line
[01:36:25.960 --> 01:36:29.960]   that works too. You just use a semicolon. Neither one's better than the other.
[01:36:29.960 --> 01:36:33.960]   They're just different. So we could do the same
[01:36:33.960 --> 01:36:37.960]   thing in APL. Of course in APL it's going to be much easier.
[01:36:37.960 --> 01:36:41.960]   So we're going to define a matrix called m
[01:36:41.960 --> 01:36:45.960]   which is going to be a three by three
[01:36:45.960 --> 01:36:49.960]   tensor containing the numbers from
[01:36:49.960 --> 01:36:53.960]   one to nine.
[01:36:53.960 --> 01:36:57.960]   Okay and there we go. That's
[01:36:57.960 --> 01:37:01.960]   done it in APL. A three by three tensor containing
[01:37:01.960 --> 01:37:05.960]   the numbers from one to nine. A lot of these ideas from APL
[01:37:05.960 --> 01:37:09.960]   you'll find have made their way into other programming languages. For example if you use go
[01:37:09.960 --> 01:37:13.960]   you might recognize this. This is the iota character and go
[01:37:13.960 --> 01:37:17.960]   uses the word iota so they spell it out in a
[01:37:17.960 --> 01:37:21.960]   somewhat similar way. A lot of these ideas from APL
[01:37:21.960 --> 01:37:25.960]   have found themselves into math notation and other
[01:37:25.960 --> 01:37:29.960]   languages. It's been around since the late fifties.
[01:37:29.960 --> 01:37:33.960]   Okay so here's a bit of fun.
[01:37:33.960 --> 01:37:37.960]   We're going to learn about a new thing that looks kind of crazy called Frobenius
[01:37:37.960 --> 01:37:41.960]   norm. And we'll use that from time to time as we're
[01:37:41.960 --> 01:37:45.960]   doing generative modeling. And here's the definition of a Frobenius norm.
[01:37:45.960 --> 01:37:49.960]   It's the sum over
[01:37:49.960 --> 01:37:53.960]   all of the rows and columns of a matrix.
[01:37:53.960 --> 01:37:57.960]   And we're going to take each one and square it.
[01:37:57.960 --> 01:38:01.960]   You're going to add them up and they're going to take the square root.
[01:38:01.960 --> 01:38:05.960]   And so to implement that in PyTorch
[01:38:05.960 --> 01:38:09.960]   is as simple as going n times m dot sum
[01:38:09.960 --> 01:38:13.960]   dot square root.
[01:38:13.960 --> 01:38:17.960]   So this looks like a pretty complicated thing.
[01:38:17.960 --> 01:38:21.960]   When you kind of look at it at first it looks like a lot of squiggly business. Or if you said this
[01:38:21.960 --> 01:38:25.960]   thing here you might be like what on earth is that? Well now you know it's just
[01:38:25.960 --> 01:38:29.960]   square, sum, square root.
[01:38:29.960 --> 01:38:33.960]   So again we could do the same thing in APL.
[01:38:33.960 --> 01:38:39.960]   So let's do, so in APL we want
[01:38:39.960 --> 01:38:43.960]   the, okay so we're going to create something called sf.
[01:38:43.960 --> 01:38:47.960]   Now it's interesting, APL does this a little bit differently.
[01:38:47.960 --> 01:38:51.960]   So dot sum by default in PyTorch sums
[01:38:51.960 --> 01:38:55.960]   over everything. And if you want to sum over just one dimension you have to pass
[01:38:55.960 --> 01:38:59.960]   in a dimension keyword. For very good reasons, APL is the opposite.
[01:38:59.960 --> 01:39:03.960]   It just sums across rows or just down columns.
[01:39:03.960 --> 01:39:07.960]   So actually we have to say sum up the flattened
[01:39:07.960 --> 01:39:11.960]   out version of the matrix. And to say flattened out you use comma.
[01:39:11.960 --> 01:39:15.960]   So here's sum up the flattened out version of the matrix.
[01:39:15.960 --> 01:39:21.960]   Okay so that's our sf. Oh sorry.
[01:39:21.960 --> 01:39:25.960]   And the matrix is meant to be m times m.
[01:39:25.960 --> 01:39:31.960]   There we go. So there's the same thing.
[01:39:31.960 --> 01:39:35.960]   Sum up the flattened out m by m matrix. And another interesting thing about APL
[01:39:35.960 --> 01:39:39.960]   is it always is read right to left. There's no such thing as operator precedence
[01:39:39.960 --> 01:39:43.960]   which makes life a lot easier.
[01:39:43.960 --> 01:39:47.960]   Okay and then we take the square root of that.
[01:39:47.960 --> 01:39:51.960]   There isn't a square root function so we have to
[01:39:51.960 --> 01:39:55.960]   do to the power of 0.5. And there we go, same thing.
[01:39:55.960 --> 01:39:59.960]   Alright, you get the idea.
[01:39:59.960 --> 01:40:03.960]   Yes, a very interesting question here from Marabou.
[01:40:03.960 --> 01:40:07.960]   Are the bars for norm or absolute value? And I like Siva's answer
[01:40:07.960 --> 01:40:11.960]   which is the norm is the same as the
[01:40:11.960 --> 01:40:15.960]   absolute value for a scalar. So in this case you can think of it as absolute value
[01:40:15.960 --> 01:40:19.960]   and it's kind of not needed because it's being squared anyway.
[01:40:19.960 --> 01:40:23.960]   But yes, in this case the norm, well
[01:40:23.960 --> 01:40:27.960]   in every case for a scalar the norm is the absolute value which is kind of a cute
[01:40:27.960 --> 01:40:31.960]   discovery when you realize it. So thank you for pointing that out Siva.
[01:40:31.960 --> 01:40:35.960]   Alright, so this is just fiddling around
[01:40:35.960 --> 01:40:39.960]   a little bit to kind of get a sense of how these things work.
[01:40:39.960 --> 01:40:43.960]   So really importantly you can
[01:40:43.960 --> 01:40:47.960]   index into a matrix and
[01:40:47.960 --> 01:40:51.960]   you'll say rows first and then columns. And if you say colon it means all the columns.
[01:40:51.960 --> 01:40:55.960]   So if I say row 2, here it is, row 2,
[01:40:55.960 --> 01:40:59.960]   all the columns, sorry this is row 2 so that's at 0,
[01:40:59.960 --> 01:41:03.960]   APL starts at 1, all the columns, that's going to be 7, 8, 9.
[01:41:03.960 --> 01:41:07.960]   And you can see I often use comma to print out multiple
[01:41:07.960 --> 01:41:11.960]   things and I don't have to say print in Jupiter, it's kind of assumed.
[01:41:11.960 --> 01:41:15.960]   And so this is just a quick way of printing out the second row
[01:41:15.960 --> 01:41:19.960]   and then here every row column 2.
[01:41:19.960 --> 01:41:23.960]   So here is every row of column 2 and here you can see
[01:41:23.960 --> 01:41:27.960]   3, 6, 9.
[01:41:27.960 --> 01:41:31.960]   So one thing very useful
[01:41:31.960 --> 01:41:35.960]   to recognize is that for tensors
[01:41:35.960 --> 01:41:39.960]   of higher rank than 1, such as a matrix,
[01:41:39.960 --> 01:41:43.960]   any trailing colons are optional. So you see this here
[01:41:43.960 --> 01:41:47.960]   M2, that's the same as M2, colon.
[01:41:47.960 --> 01:41:51.960]   It's really important to remember. So M2, you can see the result
[01:41:51.960 --> 01:41:55.960]   is the same. So that means row 2 every column.
[01:41:55.960 --> 01:41:59.960]   So now
[01:41:59.960 --> 01:42:03.960]   with all that in place, we've got quite an easy way
[01:42:03.960 --> 01:42:07.960]   we don't need a number anymore.
[01:42:07.960 --> 01:42:11.960]   We can multiply, so we can get rid of that innermost loop.
[01:42:11.960 --> 01:42:15.960]   So we're going to get rid of this loop, because this is
[01:42:15.960 --> 01:42:19.960]   just multiplying together all of the corresponding rows of
[01:42:19.960 --> 01:42:23.960]   a, sorry, all the corresponding columns of a row of a
[01:42:23.960 --> 01:42:27.960]   with all the corresponding rows of a column of b.
[01:42:27.960 --> 01:42:31.960]   And so we can just use an element-wise operation for that.
[01:42:31.960 --> 01:42:35.960]   So here is the
[01:42:35.960 --> 01:42:39.960]   i-th row of a, and here is the j-th column
[01:42:39.960 --> 01:42:43.960]   of b. And so those are both, as we've seen,
[01:42:43.960 --> 01:42:47.960]   just vectors, and therefore we can do an element-wise
[01:42:47.960 --> 01:42:51.960]   multiplication of them, and then sum them up. And that's the same
[01:42:51.960 --> 01:42:55.960]   as a dot product. So that's handy.
[01:42:55.960 --> 01:42:59.960]   And so again, we'll do test close. Okay, it's the same. Great.
[01:42:59.960 --> 01:43:03.960]   And again, you'll see we kind of did all of our experimenting
[01:43:03.960 --> 01:43:07.960]   first, right, to make sure we understood how it all worked, and then
[01:43:07.960 --> 01:43:11.960]   put it together, and then if we time it,
[01:43:11.960 --> 01:43:15.960]   661 microseconds. Okay, so it's interesting. It's actually slower
[01:43:15.960 --> 01:43:19.960]   than, which really shows you how good number is, but it's certainly a hell
[01:43:19.960 --> 01:43:23.960]   of a lot better than our 450 milliseconds.
[01:43:23.960 --> 01:43:27.960]   But we're using something that's kind of a lot more general now.
[01:43:27.960 --> 01:43:31.960]   This is exactly the same as dot, as we've discussed.
[01:43:31.960 --> 01:43:35.960]   So we could just use torch dot, torch dot dot,
[01:43:35.960 --> 01:43:39.960]   I suppose I should say. And if we run that,
[01:43:39.960 --> 01:43:43.960]   okay, a little faster. It's still, interestingly, it's still slower
[01:43:43.960 --> 01:43:47.960]   than the number, which is quite amazing, actually.
[01:43:47.960 --> 01:43:51.960]   Alright, so that one
[01:43:51.960 --> 01:43:55.960]   was not exactly a speedup, but it's kind of more general, which is nice.
[01:43:55.960 --> 01:43:59.960]   Now we're going to get something into something
[01:43:59.960 --> 01:44:03.960]   really fun, which is broadcasting.
[01:44:03.960 --> 01:44:07.960]   And broadcasting is about what if you have arrays with different
[01:44:07.960 --> 01:44:11.960]   shapes. So what's a shape? The shape is the number of
[01:44:11.960 --> 01:44:15.960]   rows, or the number of rows and columns, or the number of
[01:44:15.960 --> 01:44:19.960]   what would you say, faces, rows and columns,
[01:44:19.960 --> 01:44:23.960]   and so forth. So for example, the shape of M
[01:44:23.960 --> 01:44:27.960]   is three by three. So what happens if you multiply, or add,
[01:44:27.960 --> 01:44:31.960]   or do operations to tensors of different shapes? Well there's one
[01:44:31.960 --> 01:44:35.960]   very simple one, which is if you've got
[01:44:35.960 --> 01:44:39.960]   a rank one tensor, the vector,
[01:44:39.960 --> 01:44:43.960]   then you can use any operation with a scalar
[01:44:43.960 --> 01:44:47.960]   and it broadcasts that scalar across
[01:44:47.960 --> 01:44:51.960]   the tensor. So a is greater than zero is exactly the same
[01:44:51.960 --> 01:44:55.960]   as saying a is greater than tensor, zero
[01:44:55.960 --> 01:44:59.960]   comma zero
[01:44:59.960 --> 01:45:03.960]   comma zero. So it's basically copying
[01:45:03.960 --> 01:45:07.960]   that across three times. Now it's not literally making a copy
[01:45:07.960 --> 01:45:11.960]   in memory, but it's acting as if we'd said that. And this is the most simple
[01:45:11.960 --> 01:45:15.960]   version of broadcasting. It's broadcasting the zero
[01:45:15.960 --> 01:45:19.960]   across the ten, and the six, and the negative four.
[01:45:19.960 --> 01:45:23.960]   And APL does exactly the same thing.
[01:45:23.960 --> 01:45:27.960]   A is less than five.
[01:45:27.960 --> 01:45:31.960]   So zero, zero, one.
[01:45:31.960 --> 01:45:35.960]   Same idea.
[01:45:35.960 --> 01:45:39.960]   Okay.
[01:45:39.960 --> 01:45:47.960]   So we can do plus with a scalar, and
[01:45:47.960 --> 01:45:51.960]   we can do exactly the same thing with higher than rank one, so two times a
[01:45:51.960 --> 01:45:55.960]   matrix is just going to be broadcast across all the rows
[01:45:55.960 --> 01:45:59.960]   and all the columns.
[01:45:59.960 --> 01:46:03.960]   Okay, now it gets interesting.
[01:46:03.960 --> 01:46:07.960]   So broadcasting dates back to APL,
[01:46:07.960 --> 01:46:11.960]   but a really interesting idea is that we can broadcast not just
[01:46:11.960 --> 01:46:15.960]   scalars, but we can broadcast vectors across matrices, or broadcast
[01:46:15.960 --> 01:46:19.960]   any kind of lower ranked tensor
[01:46:19.960 --> 01:46:23.960]   across higher ranked tensors, or even broadcast
[01:46:23.960 --> 01:46:27.960]   together two tensors of the same rank, but different shapes
[01:46:27.960 --> 01:46:31.960]   in a really powerful way. And as I was exploring this,
[01:46:31.960 --> 01:46:35.960]   I loved doing this kind of computer archaeology, I was trying
[01:46:35.960 --> 01:46:39.960]   to find out where the hell this comes from, and it actually turns out
[01:46:39.960 --> 01:46:43.960]   from this email message in
[01:46:43.960 --> 01:46:47.960]   1995 that the idea actually comes
[01:46:47.960 --> 01:46:51.960]   from a language that I'd never heard of called Yorick, which
[01:46:51.960 --> 01:46:55.960]   still apparently exists.
[01:46:55.960 --> 01:46:59.960]   Here's Yorick. And so Yorick has talks about
[01:46:59.960 --> 01:47:03.960]   broadcasting and conformability. So what happened is this
[01:47:03.960 --> 01:47:07.960]   very obscure language
[01:47:07.960 --> 01:47:11.960]   has this very powerful idea, and
[01:47:11.960 --> 01:47:15.960]   NumPy has happily stolen the
[01:47:15.960 --> 01:47:19.960]   idea from Yorick that allows us to
[01:47:19.960 --> 01:47:23.960]   broadcast together tensors
[01:47:23.960 --> 01:47:27.960]   that don't appear to match. So let me give an example. Here's a tensor
[01:47:27.960 --> 01:47:31.960]   called C that's a vector, it's a rank 1 tensor, 10, 20, 30.
[01:47:31.960 --> 01:47:35.960]   And here's a tensor called M, which is a matrix, we've seen this one before.
[01:47:35.960 --> 01:47:39.960]   And one of them is shape 3,
[01:47:39.960 --> 01:47:43.960]   the other is shape 3. And yet
[01:47:43.960 --> 01:47:47.960]   we can add them together. Now what's
[01:47:47.960 --> 01:47:51.960]   happened when we added it together? Well what's happened
[01:47:51.960 --> 01:47:55.960]   is 10, 20, 30 got added to 1, 2, 3.
[01:47:55.960 --> 01:47:59.960]   And then 10, 20, 30 got added to 4, 5, 6.
[01:47:59.960 --> 01:48:03.960]   And then 10, 20, 30 got added to 7, 8, 9.
[01:48:03.960 --> 01:48:07.960]   And hopefully you can see this looks quite familiar.
[01:48:07.960 --> 01:48:11.960]   Instead of broadcasting a scalar
[01:48:11.960 --> 01:48:15.960]   over a higher rank tensor, this is broadcasting a vector
[01:48:15.960 --> 01:48:19.960]   across every row of a matrix.
[01:48:19.960 --> 01:48:23.960]   And
[01:48:23.960 --> 01:48:27.960]   it works both ways, so we can say C plus M gives us exactly the same thing.
[01:48:27.960 --> 01:48:31.960]   And so let me explain what's actually happening here.
[01:48:31.960 --> 01:48:35.960]   The trick is to know about this somewhat obscure method called expandAs.
[01:48:35.960 --> 01:48:39.960]   And what expandAs does is this creates a new thing called T,
[01:48:39.960 --> 01:48:43.960]   which contains exactly the same thing as C, but expanded,
[01:48:43.960 --> 01:48:47.960]   or kind of copied over, so it has the same shape as M.
[01:48:47.960 --> 01:48:51.960]   So here's what T looks like. Now T
[01:48:51.960 --> 01:48:55.960]   contains exactly the same thing as C does, but it's got three copies of it now.
[01:48:55.960 --> 01:48:59.960]   And you can see we can definitely add T to M because
[01:48:59.960 --> 01:49:03.960]   they match shapes.
[01:49:03.960 --> 01:49:07.960]   We can say M plus T, we know we can say M plus T because we've already learned
[01:49:07.960 --> 01:49:11.960]   that you can do element-wise operations on two things that have matching shapes.
[01:49:11.960 --> 01:49:15.960]   Now by the way, this thing T
[01:49:15.960 --> 01:49:19.960]   didn't actually create three copies. Check this out.
[01:49:19.960 --> 01:49:23.960]   If we call T.storage it tells us what's actually in memory. It actually
[01:49:23.960 --> 01:49:27.960]   just contains the numbers 10, 20, 30. But it does a really
[01:49:27.960 --> 01:49:31.960]   clever trick. It has a stride of
[01:49:31.960 --> 01:49:35.960]   zero across the rows, and a size of 3,3.
[01:49:35.960 --> 01:49:39.960]   And so what that means is that it acts as if it's a 3x3
[01:49:39.960 --> 01:49:43.960]   matrix, and each time it goes to the next row, it actually
[01:49:43.960 --> 01:49:47.960]   stays exactly where it is. And this idea of strides is the trick
[01:49:47.960 --> 01:49:51.960]   which NumPy and PyTorch and so forth
[01:49:51.960 --> 01:49:55.960]   use for all kinds of things where you basically can create
[01:49:55.960 --> 01:49:59.960]   very efficient ways to
[01:49:59.960 --> 01:50:03.960]   do things like expanding, or to kind of jump over things, and stuff
[01:50:03.960 --> 01:50:07.960]   like that. You know, switch between columns and rows, stuff like that.
[01:50:07.960 --> 01:50:11.960]   Anyway, the important thing here for us to recognize is that we didn't actually make a copy.
[01:50:11.960 --> 01:50:15.960]   This is totally efficient, and it's all going to be run in C code very fast.
[01:50:15.960 --> 01:50:19.960]   So remember, this expand ads is critical. This is the thing
[01:50:19.960 --> 01:50:23.960]   that will teach you to understand how broadcasting works, which is really
[01:50:23.960 --> 01:50:27.960]   important for implementing deep learning algorithms, or any
[01:50:27.960 --> 01:50:31.960]   kind of linear algebra on any Python system.
[01:50:31.960 --> 01:50:35.960]   Because the NumPy rules are used exactly the same
[01:50:35.960 --> 01:50:39.960]   in JAX, in TensorFlow, in PyTorch,
[01:50:39.960 --> 01:50:43.960]   and so forth. Now I'll show you a little
[01:50:43.960 --> 01:50:47.960]   trick, which is going to be very important in a moment. If we take
[01:50:47.960 --> 01:50:51.960]   C, which remember is a vector containing
[01:50:51.960 --> 01:50:55.960]   10, 20, 30, and we say
[01:50:55.960 --> 01:50:59.960]   dot unsqueezed zero, then it changes
[01:50:59.960 --> 01:51:03.960]   the shape from three to one comma three.
[01:51:03.960 --> 01:51:07.960]   So it changes it from a vector of length three to a matrix of
[01:51:07.960 --> 01:51:11.960]   one row by three columns. This will turn out to be very important
[01:51:11.960 --> 01:51:15.960]   in a moment. And you can see how it's printed. It's printed out with two square brackets.
[01:51:15.960 --> 01:51:19.960]   Now I never use unsqueezed, because I much prefer doing something
[01:51:19.960 --> 01:51:23.960]   more flexible, which is if you index into an axis with a special value
[01:51:23.960 --> 01:51:27.960]   none, also known as np.newaxis,
[01:51:27.960 --> 01:51:31.960]   it does exactly the same thing. It inserts a new axis here.
[01:51:31.960 --> 01:51:35.960]   So here we'll get exactly
[01:51:35.960 --> 01:51:39.960]   the same thing. One row by all the columns,
[01:51:39.960 --> 01:51:43.960]   three columns. So this is exactly the same as saying unsqueezed.
[01:51:43.960 --> 01:51:47.960]   So this inserts a new
[01:51:47.960 --> 01:51:51.960]   unit axis. This is a unit axis, a single row,
[01:51:51.960 --> 01:51:55.960]   in this dimension. And this does the same thing.
[01:51:55.960 --> 01:51:59.960]   So these are the same. So we could
[01:51:59.960 --> 01:52:03.960]   do the same thing and say unsqueezed one, which means now
[01:52:03.960 --> 01:52:07.960]   we're going to unsqueeze into the first dimension.
[01:52:07.960 --> 01:52:11.960]   So that means we now have three rows and one column.
[01:52:11.960 --> 01:52:15.960]   See the shape here? The shape is
[01:52:15.960 --> 01:52:19.960]   inserting a unit axis in position one. Three rows
[01:52:19.960 --> 01:52:23.960]   and one column. And so we can do
[01:52:23.960 --> 01:52:27.960]   exactly the same thing here. Give us every row
[01:52:27.960 --> 01:52:31.960]   and a new unit axis in position one. Same thing.
[01:52:31.960 --> 01:52:35.960]   So those two are exactly the same. So
[01:52:35.960 --> 01:52:39.960]   this is how we create a
[01:52:39.960 --> 01:52:43.960]   matrix with one row. This is how we create a matrix with one
[01:52:43.960 --> 01:52:47.960]   column. None, colon versus colon, colon, none.
[01:52:47.960 --> 01:52:51.960]   Or unsqueeze.
[01:52:51.960 --> 01:52:55.960]   We don't have to say, as we've
[01:52:55.960 --> 01:52:59.960]   learned before, none, colon, because you remember
[01:52:59.960 --> 01:53:03.960]   trailing columns are optional. So therefore just C none
[01:53:03.960 --> 01:53:07.960]   is also going to give you a row matrix, one row
[01:53:07.960 --> 01:53:11.960]   matrix. This is a little trick here.
[01:53:11.960 --> 01:53:15.960]   If you say dot, dot, dot, that means all of the dimensions.
[01:53:15.960 --> 01:53:19.960]   And so dot, dot, dot, none will always insert
[01:53:19.960 --> 01:53:23.960]   a unit axis at the end regardless of what rank a tensor is.
[01:53:23.960 --> 01:53:27.960]   So, yeah, so none and NP new axis
[01:53:27.960 --> 01:53:31.960]   mean exactly the same thing. NP new axis is actually a synonym for none.
[01:53:31.960 --> 01:53:35.960]   If you've ever used that, I always use none.
[01:53:35.960 --> 01:53:39.960]   Because why not? It's short and simple.
[01:53:39.960 --> 01:53:43.960]   So here's something interesting. If we go C colon, colon, none,
[01:53:43.960 --> 01:53:47.960]   so let's go and check out what C colon, colon, none looked like.
[01:53:47.960 --> 01:53:51.960]   C colon, colon, none
[01:53:51.960 --> 01:53:55.960]   is a column. And if we say expand
[01:53:55.960 --> 01:53:59.960]   as M, which is 3 by 3, then it's going to take that
[01:53:59.960 --> 01:54:03.960]   10/20/30 column and replicate it. 10/20/30, 10/20/30, 10/20/30.
[01:54:03.960 --> 01:54:07.960]   So we could add,
[01:54:07.960 --> 01:54:11.960]   so remember, like, well, remember, I'll explain that.
[01:54:11.960 --> 01:54:15.960]   When you say matrix plus
[01:54:15.960 --> 01:54:19.960]   C colon, colon, none, it's basically
[01:54:19.960 --> 01:54:23.960]   going to do this dot expand as for you.
[01:54:23.960 --> 01:54:27.960]   So if I want to add this matrix here to M,
[01:54:27.960 --> 01:54:31.960]   I don't need to say dot expand as, I just write this, I just write
[01:54:31.960 --> 01:54:35.960]   M plus C colon, colon, none. And so this is exactly
[01:54:35.960 --> 01:54:39.960]   the same as doing M plus C.
[01:54:39.960 --> 01:54:43.960]   But now, rather than adding the vector to each row,
[01:54:43.960 --> 01:54:47.960]   it's adding the vector to each column.
[01:54:47.960 --> 01:54:51.960]   See, plus 10/20/30, 10/20/30, 10/20/30.
[01:54:51.960 --> 01:54:55.960]   So that's a really simple way that we
[01:54:55.960 --> 01:54:59.960]   now get kind of for free, thanks to this really nifty notation, this
[01:54:59.960 --> 01:55:03.960]   approach that came from Yorick.
[01:55:03.960 --> 01:55:07.960]   So here you can see M plus C, none, colon,
[01:55:07.960 --> 01:55:11.960]   is adding 10/20/30 to each row, and M plus
[01:55:11.960 --> 01:55:15.960]   C colon, none is adding 10/20/30 to each column.
[01:55:15.960 --> 01:55:19.960]   All right, so that's the basic, like, hand-wavy
[01:55:19.960 --> 01:55:23.960]   version, so let's look at, like, what are
[01:55:23.960 --> 01:55:27.960]   the rules, and how does it work?
[01:55:27.960 --> 01:55:31.960]   Okay, so C none, colon is 1 by 3.
[01:55:31.960 --> 01:55:35.960]   C colon, none is 3 by 1.
[01:55:35.960 --> 01:55:39.960]   What happens if we multiply C none, colon
[01:55:39.960 --> 01:55:43.960]   by C colon, none?
[01:55:43.960 --> 01:55:47.960]   Well, it's going to do, if you think about it,
[01:55:47.960 --> 01:55:51.960]   which you definitely should, because thinking is very helpful,
[01:55:51.960 --> 01:55:55.960]   if we say, so what it's going to do
[01:55:55.960 --> 01:55:59.960]   is it's going to have to expand
[01:55:59.960 --> 01:56:03.960]   as,
[01:56:03.960 --> 01:56:07.960]   let's see if this works, actually. I'm not quite sure if expand as will do this.
[01:56:07.960 --> 01:56:11.960]   C none, colon, expand as C
[01:56:11.960 --> 01:56:15.960]   colon, colon, none.
[01:56:15.960 --> 01:56:23.960]   No.
[01:56:23.960 --> 01:56:27.960]   No.
[01:56:27.960 --> 01:56:31.960]   No.
[01:56:31.960 --> 01:56:35.960]   No.
[01:56:59.960 --> 01:57:03.960]   What is going on here?
[01:57:03.960 --> 01:57:07.960]   Okay, so what happens if we go C none, colon
[01:57:07.960 --> 01:57:11.960]   times C colon, colon, none? So what it's going to have to do is it's going to have to take this
[01:57:11.960 --> 01:57:15.960]   10/20/30
[01:57:15.960 --> 01:57:19.960]   column vector, or 3 by 1 matrix,
[01:57:19.960 --> 01:57:23.960]   and it's going to have to make it
[01:57:23.960 --> 01:57:27.960]   work across each of these rows. So what it does is expands it to be 10/20/30,
[01:57:27.960 --> 01:57:31.960]   10/20/30, 10/20/30, 10/20/30. So it's going to do it just like this.
[01:57:31.960 --> 01:57:35.960]   And then it's going to do the same thing
[01:57:35.960 --> 01:57:39.960]   for C none, colon. So that's going to become 3 rows
[01:57:39.960 --> 01:57:43.960]   of 10/20/30. So we're going to end up with 3 rows of 10/20/30
[01:57:43.960 --> 01:57:47.960]   times 3 columns of 10/20/30,
[01:57:47.960 --> 01:57:51.960]   which gives us our answer.
[01:57:51.960 --> 01:57:55.960]   And so this is going to do an outer product.
[01:57:55.960 --> 01:57:59.960]   So it's very nifty that you can actually do
[01:57:59.960 --> 01:58:03.960]   an outer product without any special
[01:58:03.960 --> 01:58:07.960]   functions or anything, just using broadcasting.
[01:58:07.960 --> 01:58:11.960]   And it's not just outer products, you can do outer boolean operations.
[01:58:11.960 --> 01:58:15.960]   And this kind of stuff comes up all the time. Now remember, you don't need
[01:58:15.960 --> 01:58:19.960]   the comma, colon, so get rid of it. So this is showing us all the places
[01:58:19.960 --> 01:58:23.960]   where
[01:58:23.960 --> 01:58:27.960]   it's kind of an outer boolean, if you want to call it that.
[01:58:27.960 --> 01:58:31.960]   So this is super nifty, and you can do all
[01:58:31.960 --> 01:58:35.960]   kinds of tricks with this because it runs very, very fast. So this is going to be
[01:58:35.960 --> 01:58:39.960]   accelerated in C. So here are the rules.
[01:58:39.960 --> 01:58:43.960]   When you operate on 2 arrays or tensors, NumPy and PyTorch
[01:58:43.960 --> 01:58:47.960]   will compare their shapes. So remember this is a shape.
[01:58:47.960 --> 01:58:51.960]   You can tell it's a shape because we said shape.
[01:58:51.960 --> 01:58:55.960]   And it goes from right to left, starts with the trailing dimensions.
[01:58:55.960 --> 01:58:59.960]   And it checks whether the dimensions are compatible.
[01:58:59.960 --> 01:59:03.960]   Now they're compatible if they're equal, right? So for example,
[01:59:03.960 --> 01:59:07.960]   if we say m times m,
[01:59:07.960 --> 01:59:11.960]   then those two shapes are compatible because
[01:59:11.960 --> 01:59:15.960]   the
[01:59:15.960 --> 01:59:19.960]   because in each case, it's just going to be 3,
[01:59:19.960 --> 01:59:23.960]   right? So they're going to be equal. So if the
[01:59:23.960 --> 01:59:27.960]   shape in that dimension is equal, they're compatible.
[01:59:27.960 --> 01:59:31.960]   Or if one of them's 1, and if one of them's
[01:59:31.960 --> 01:59:35.960]   1, then that dimension is broadcast to make it the same size as the
[01:59:35.960 --> 01:59:39.960]   other. So that's why the
[01:59:39.960 --> 01:59:43.960]   outer product worked. We had a
[01:59:43.960 --> 01:59:47.960]   1 by 3 times a 3 by 1.
[01:59:47.960 --> 01:59:51.960]   And so this 1 got copied 3 times
[01:59:51.960 --> 01:59:55.960]   to make it this long. And this 1 got copied 3 times to make it this long.
[01:59:55.960 --> 02:00:03.960]   Okay, so those are the rules. So the arrays don't have to have the same number of
[02:00:03.960 --> 02:00:07.960]   dimensions. So this is an example that comes up all the time.
[02:00:07.960 --> 02:00:11.960]   Let's say you've got a 256 by 256 by 3 array or tensor of RGB
[02:00:11.960 --> 02:00:15.960]   values. So you've got an image, in other words, a color image.
[02:00:15.960 --> 02:00:19.960]   And you want to normalize it. So you want to scale each color
[02:00:19.960 --> 02:00:23.960]   in the image by a different value. So this is how we normalize
[02:00:23.960 --> 02:00:27.960]   colors.
[02:00:27.960 --> 02:00:31.960]   So one way is you could multiply, or divide, or whatever,
[02:00:31.960 --> 02:00:35.960]   multiply the image by a one-dimensional array with 3 values.
[02:00:35.960 --> 02:00:39.960]   So you've got a 1D array, so that's
[02:00:39.960 --> 02:00:43.960]   just 3. And then the image is
[02:00:43.960 --> 02:00:47.960]   256 by 256 by 3. And we go right to left, and we
[02:00:47.960 --> 02:00:51.960]   check, "Are they the same?" And we say, "Yes, they are."
[02:00:51.960 --> 02:00:55.960]   And then we keep going left, and we say, "Are they the same?" And if it's missing,
[02:00:55.960 --> 02:00:59.960]   we act as if it's 1. And if we keep going,
[02:00:59.960 --> 02:01:03.960]   if it's missing, we act as if it's 1. So this is going to be the same as doing 1
[02:01:03.960 --> 02:01:07.960]   by 1 by 3. And so this is going to be broadcast, this
[02:01:07.960 --> 02:01:11.960]   three elements will be broadcast over all 256
[02:01:11.960 --> 02:01:15.960]   by 256 pixels. So this is a super fast
[02:01:15.960 --> 02:01:19.960]   and convenient and nice way of normalizing image data
[02:01:19.960 --> 02:01:23.960]   with a single expression. And this is exactly how we do it in the Fast.ai library,
[02:01:23.960 --> 02:01:27.960]   in fact.
[02:01:27.960 --> 02:01:31.960]   So we can use this
[02:01:31.960 --> 02:01:35.960]   to dramatically speed up our matrix multiplication.
[02:01:35.960 --> 02:01:39.960]   Let's just grab a single digit, just for simplicity. And I really like doing
[02:01:39.960 --> 02:01:43.960]   this in Jupyter Notebooks. And if you build Jupyter Notebooks
[02:01:43.960 --> 02:01:47.960]   to explain stuff that you've learned in this course or ways that you can apply it,
[02:01:47.960 --> 02:01:51.960]   consider doing this for your readers, but add a lot more prose. I
[02:01:51.960 --> 02:01:55.960]   haven't added prose here because I want to use my voice.
[02:01:55.960 --> 02:01:59.960]   For example, in our book that we published, it's all
[02:01:59.960 --> 02:02:03.960]   written in notebooks, and there's a lot more prose, obviously. But really,
[02:02:03.960 --> 02:02:07.960]   I like to show every example all along the way, using
[02:02:07.960 --> 02:02:11.960]   simple as possible. So let's just grab a single digit. So here's the first digit.
[02:02:11.960 --> 02:02:15.960]   So its shape is a 784 long vector.
[02:02:15.960 --> 02:02:19.960]   And remember that our weight matrix is
[02:02:19.960 --> 02:02:23.960]   784 by 10.
[02:02:23.960 --> 02:02:27.960]   So if we say digit colon common none
[02:02:27.960 --> 02:02:31.960]   dot shape, then that is a
[02:02:31.960 --> 02:02:35.960]   784 by 1 row matrix.
[02:02:35.960 --> 02:02:39.960]   So there's our matrix.
[02:02:39.960 --> 02:02:43.960]   And so if we then take that,
[02:02:43.960 --> 02:02:47.960]   784 by 1, and expand as M2,
[02:02:47.960 --> 02:02:51.960]   it's going to be the same shape as our weight matrix. So it's copied
[02:02:51.960 --> 02:02:55.960]   our image data
[02:02:55.960 --> 02:02:59.960]   for that digit across all of the 10
[02:02:59.960 --> 02:03:03.960]   vectors representing the 10 linear projections we're doing
[02:03:03.960 --> 02:03:07.960]   for our linear model.
[02:03:07.960 --> 02:03:11.960]   And so that means that we can take the digit colon common
[02:03:11.960 --> 02:03:15.960]   none, so 784 by 1, and multiply it by the weights.
[02:03:15.960 --> 02:03:19.960]   And so that's going to get us back 784 by 10.
[02:03:19.960 --> 02:03:23.960]   And so what it's doing, remember, is it's basically looping through
[02:03:23.960 --> 02:03:27.960]   each of these 10
[02:03:27.960 --> 02:03:31.960]   784 long vectors, and for each one of them, it's multiplying
[02:03:31.960 --> 02:03:35.960]   it by this digit. So that's
[02:03:35.960 --> 02:03:39.960]   exactly what we want to do in our matrix multiplication.
[02:03:39.960 --> 02:03:43.960]   So originally we had, well not originally,
[02:03:43.960 --> 02:03:47.960]   most recently I should say, we had this dot product
[02:03:47.960 --> 02:03:51.960]   where we were actually looping over
[02:03:51.960 --> 02:03:55.960]   J, which was the columns of B.
[02:03:55.960 --> 02:03:59.960]   So we don't have to do that anymore, because we can do it all
[02:03:59.960 --> 02:04:03.960]   at once by doing exactly what we just did. So we can take
[02:04:03.960 --> 02:04:07.960]   the ith row
[02:04:07.960 --> 02:04:11.960]   and all the columns
[02:04:11.960 --> 02:04:15.960]   and add an axis to the end
[02:04:15.960 --> 02:04:19.960]   and then just like we did here, multiply
[02:04:19.960 --> 02:04:23.960]   it by B, and then dot sum.
[02:04:23.960 --> 02:04:27.960]   And so that is, again, exactly
[02:04:27.960 --> 02:04:31.960]   the same thing. That is another matrix multiplication
[02:04:31.960 --> 02:04:35.960]   doing it using broadcasting. Now this is like
[02:04:35.960 --> 02:04:39.960]   tricky to get your head around, and so
[02:04:39.960 --> 02:04:43.960]   if you haven't done this kind of broadcasting before, it's a really good time
[02:04:43.960 --> 02:04:47.960]   to pause the video and look carefully at each of
[02:04:47.960 --> 02:04:51.960]   these four cells before. Understand
[02:04:51.960 --> 02:04:55.960]   what did I do there? Why did I do it? What am I showing you?
[02:04:55.960 --> 02:04:59.960]   And then experiment with trying to, and to remember
[02:04:59.960 --> 02:05:03.960]   that we started with M1 0, so just like
[02:05:03.960 --> 02:05:07.960]   we have here a i.
[02:05:07.960 --> 02:05:11.960]   So that's why we've got i comma comma colon comma none, because this
[02:05:11.960 --> 02:05:15.960]   digit is actually M1 0, so this is like M1
[02:05:15.960 --> 02:05:19.960]   0 colon none. So this line
[02:05:19.960 --> 02:05:23.960]   is doing exactly the same thing as this here,
[02:05:23.960 --> 02:05:27.960]   plus the sum. So let's check if this
[02:05:27.960 --> 02:05:31.960]   matmul is the same as it used to be, yet it's still working, and
[02:05:31.960 --> 02:05:35.960]   the speed of it, okay, not bad, so
[02:05:35.960 --> 02:05:39.960]   137 microseconds. So we've now
[02:05:39.960 --> 02:05:43.960]   gone from a time from 500 milliseconds to about
[02:05:43.960 --> 02:05:47.960]   0.1 milliseconds. Funnily enough on my, oh actually now I think about it, my MacBook
[02:05:47.960 --> 02:05:51.960]   Air is an M2, whereas this Mac Mini is an M1, so that's a little bit
[02:05:51.960 --> 02:05:55.960]   far. So my Air was a bit faster than 0.1 milliseconds.
[02:05:55.960 --> 02:05:59.960]   So overall we've got about a 5000 times speed improvement.
[02:05:59.960 --> 02:06:03.960]   So that is
[02:06:03.960 --> 02:06:07.960]   pretty exciting. And since it's so fast now, there's no need to use a mini-batch
[02:06:07.960 --> 02:06:11.960]   anymore. If you remember, we used a mini-batch of
[02:06:11.960 --> 02:06:15.960]   of, where is it,
[02:06:15.960 --> 02:06:19.960]   of
[02:06:19.960 --> 02:06:23.960]   five images. But now we can actually use the whole data set because it's so fast.
[02:06:23.960 --> 02:06:27.960]   So now we can do the whole data set.
[02:06:27.960 --> 02:06:31.960]   There it is. We've now got 50000 by 10,
[02:06:31.960 --> 02:06:35.960]   which is what we want. And so it's taking us only
[02:06:35.960 --> 02:06:39.960]   656 milliseconds now to do the whole data set. So this is
[02:06:39.960 --> 02:06:43.960]   actually getting to a point now where we could start to create and train some simple models
[02:06:43.960 --> 02:06:47.960]   in a reasonable amount of time. So that's good news.
[02:06:47.960 --> 02:06:51.960]   All right.
[02:06:51.960 --> 02:06:55.960]   I think that's a probably good time to take a break. We don't have too much more of this
[02:06:55.960 --> 02:06:59.960]   to go, but I don't want to keep you guys up too late.
[02:06:59.960 --> 02:07:03.960]   So hopefully you learned something interesting about
[02:07:03.960 --> 02:07:07.960]   broadcasting today. I cannot overemphasize
[02:07:07.960 --> 02:07:11.960]   how widely useful this is in
[02:07:11.960 --> 02:07:15.960]   all deep learning and machine learning code. It comes up all the time.
[02:07:15.960 --> 02:07:19.960]   It's basically our number one
[02:07:19.960 --> 02:07:23.960]   most critical kind of foundational operation.
[02:07:23.960 --> 02:07:27.960]   So yeah, take your time practicing it and also good
[02:07:27.960 --> 02:07:31.960]   luck with your diffusion homework from the first half of the lesson.
[02:07:31.960 --> 02:07:35.960]   Thanks for joining us and I'll see you next time.
[02:07:35.960 --> 02:07:39.960]   [silence]
[02:07:39.960 --> 02:07:43.960]   [silence]
[02:07:43.960 --> 02:07:47.960]   [silence]
[02:07:47.960 --> 02:07:51.960]   [silence]
[02:07:51.960 --> 02:07:55.960]   [silence]
[02:07:55.960 --> 02:07:59.960]   [silence]
[02:07:59.960 --> 02:08:03.960]   [silence]
[02:08:03.960 --> 02:08:15.960]   [silence]
[02:08:15.960 --> 02:08:19.960]   [silence]
[02:08:19.960 --> 02:08:23.960]   [silence]
[02:08:23.960 --> 02:08:27.960]   [silence]

