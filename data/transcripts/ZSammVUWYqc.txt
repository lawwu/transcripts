
[00:00:00.000 --> 00:00:10.000]   [BLANK_AUDIO]
[00:00:10.000 --> 00:00:20.000]   [BLANK_AUDIO]
[00:00:20.000 --> 00:00:30.000]   [BLANK_AUDIO]
[00:00:30.000 --> 00:00:40.000]   [BLANK_AUDIO]
[00:00:40.000 --> 00:00:50.000]   [BLANK_AUDIO]
[00:00:50.000 --> 00:00:54.000]   [BLANK_AUDIO]
[00:00:54.000 --> 00:00:58.400]   Hey everybody and welcome back to another week of Fastbook.
[00:00:58.400 --> 00:01:02.200]   So this week is week five and I'm excited.
[00:01:02.200 --> 00:01:07.400]   So last week we built a simple classifier of training images.
[00:01:07.400 --> 00:01:09.760]   Three digits three versus digit seven.
[00:01:09.760 --> 00:01:14.760]   And we built a simple classifier just by finding what an ideal three looks like and
[00:01:14.760 --> 00:01:16.720]   what an ideal seven looks like.
[00:01:16.720 --> 00:01:21.160]   And then we built a simple heuristic that could classify the two digits.
[00:01:21.160 --> 00:01:24.000]   And we had over 90% accuracy just building that baseline.
[00:01:24.000 --> 00:01:26.040]   So that's something that's really exciting.
[00:01:26.040 --> 00:01:30.240]   When I was first reading Fastbook, it kind of blew my mind.
[00:01:30.240 --> 00:01:34.560]   I hope it kind of had the same effect on everybody as well who were here last week.
[00:01:34.560 --> 00:01:38.320]   So, but today then we'll wrap up chapter four and
[00:01:38.320 --> 00:01:42.400]   we're going to look at stochastic gradient descent.
[00:01:42.400 --> 00:01:47.680]   Another thing, this week's format is gonna be slightly different.
[00:01:47.680 --> 00:01:51.640]   I'm just trying to come up with the best format that kind of supports and
[00:01:51.640 --> 00:01:55.880]   is as we go week on week, I'm trying to improve the experience for
[00:01:55.880 --> 00:01:58.760]   everybody who's part of this call.
[00:01:58.760 --> 00:02:01.760]   So as part of that, for example, instead of using two screens,
[00:02:01.760 --> 00:02:03.080]   I'm using just the one screen.
[00:02:03.080 --> 00:02:07.560]   Like and I'll try and zoom in.
[00:02:07.560 --> 00:02:11.760]   I think last time there was some issues where I was quite zoomed out and
[00:02:11.760 --> 00:02:14.080]   people couldn't read what was on the screen.
[00:02:14.080 --> 00:02:18.560]   And something else we will do is we will try and use most majorly the clean
[00:02:18.560 --> 00:02:21.800]   version of the notebooks to understand things to understand code.
[00:02:21.800 --> 00:02:24.400]   And as part of this session, we're gonna do that.
[00:02:24.400 --> 00:02:28.000]   So we're gonna spend more time looking at the clean version of the notebooks.
[00:02:28.000 --> 00:02:32.040]   So because I feel then the text maybe could be distracting to everybody who's
[00:02:32.040 --> 00:02:32.640]   part of this call.
[00:02:32.640 --> 00:02:36.240]   So as we go forward, if there's comments, if there's feedback that you have,
[00:02:36.240 --> 00:02:38.880]   keep putting them in the Zoom chat or
[00:02:38.880 --> 00:02:43.800]   just as comments on the report that I'll share that we do every week.
[00:02:43.800 --> 00:02:46.080]   So with that being said, let's get started.
[00:02:46.080 --> 00:02:51.040]   So this week has been really, really, what we'll do this week would set us up for
[00:02:51.040 --> 00:02:53.600]   the whole of deep learning.
[00:02:53.600 --> 00:02:57.560]   And it will set us up for everything that's to come, whether it's NLP or
[00:02:57.560 --> 00:02:59.680]   whether it's computer vision or any other.
[00:02:59.680 --> 00:03:04.200]   Yeah, anything that we do in deep learning would require something like
[00:03:04.200 --> 00:03:07.240]   a stochastic gradient descent or would require optimizers.
[00:03:07.240 --> 00:03:08.560]   And that's what we're gonna cover today.
[00:03:08.560 --> 00:03:15.160]   As is usual for every week, go to this link 1db.me/fastbook5.
[00:03:15.160 --> 00:03:17.480]   So if I go to that link, let's see.
[00:03:17.480 --> 00:03:29.400]   So I'm going to 1db.me/, well, I'm not going to 1db.me/fastbook5.
[00:03:29.400 --> 00:03:31.320]   It's taken me to some other page.
[00:03:31.320 --> 00:03:33.680]   But now I'm going to 1db.me/fastbook5.
[00:03:33.680 --> 00:03:38.200]   And that brings me to this report.
[00:03:38.200 --> 00:03:41.600]   So as part of this report, it's everything the same.
[00:03:41.600 --> 00:03:43.400]   I'm not monitoring the Zoom chat.
[00:03:43.400 --> 00:03:45.360]   I'm only looking at the comments here.
[00:03:45.360 --> 00:03:48.600]   So you can just go here, click on write a comment and post comment.
[00:03:48.600 --> 00:03:49.800]   And then that way it's live.
[00:03:49.800 --> 00:03:54.640]   And this is where we will be hosting most of our discussions for week five as well.
[00:03:54.640 --> 00:03:58.040]   This is exactly what we've done for the past four weeks.
[00:03:58.040 --> 00:04:06.440]   Cool, so then this week has been, I've got some exciting news to share.
[00:04:06.440 --> 00:04:09.760]   So if you're interested, majorly as part of Fast.ai,
[00:04:09.760 --> 00:04:12.920]   as part of this Fastbook reading sessions, we're covering Fast.ai,
[00:04:12.920 --> 00:04:15.080]   we're covering the basics of deep learning,
[00:04:15.080 --> 00:04:17.360]   we'll be looking into computer vision.
[00:04:17.360 --> 00:04:21.160]   But if Hugging Face and if NLP, natural language processing,
[00:04:21.160 --> 00:04:24.520]   if transformers are your thing, then Weights and Biases
[00:04:24.520 --> 00:04:26.360]   is hosting another study group.
[00:04:26.360 --> 00:04:30.480]   So it's being hosted every Sunday, I believe.
[00:04:30.480 --> 00:04:31.760]   Exact timings are here.
[00:04:31.760 --> 00:04:34.880]   So it starts July 11, 10 AM Pacific time.
[00:04:34.880 --> 00:04:35.840]   So you can have a look.
[00:04:35.840 --> 00:04:39.000]   That's 1030 IST.
[00:04:39.000 --> 00:04:43.960]   I believe that would be PM, I assume.
[00:04:43.960 --> 00:04:47.040]   But have a look, just convert them to your own time zones.
[00:04:47.040 --> 00:04:51.040]   And then if you go to this link, 1db.me/fastaihf,
[00:04:51.040 --> 00:04:52.840]   that will take you to this meeting registration.
[00:04:52.840 --> 00:04:58.840]   And you should be able to register for the study group if Hugging Face is your thing
[00:04:58.840 --> 00:05:02.240]   and NLP is something you're interested in.
[00:05:02.240 --> 00:05:03.520]   We've had another exciting week.
[00:05:03.520 --> 00:05:05.280]   So thanks to everybody who've contributed.
[00:05:05.280 --> 00:05:08.520]   Thanks to everybody who've been writing about Fastbook week four.
[00:05:08.520 --> 00:05:12.640]   And I do feel like doing this week over week,
[00:05:12.640 --> 00:05:15.360]   like I'm seeing the same number of people come up.
[00:05:15.360 --> 00:05:18.200]   And I'm seeing new people also come up.
[00:05:18.200 --> 00:05:21.760]   But then I'm seeing constant people who do write blogs.
[00:05:21.760 --> 00:05:25.160]   And I feel that that is something really exciting for me.
[00:05:25.160 --> 00:05:29.640]   Because I feel that that's the exact same process
[00:05:29.640 --> 00:05:32.840]   I was doing when I was doing FastAI course for the first time.
[00:05:32.840 --> 00:05:37.600]   And I also feel that by doing this week over week and by being consistent,
[00:05:37.600 --> 00:05:41.960]   these few people will actually get the most out of this Fastbook reading session.
[00:05:41.960 --> 00:05:46.400]   So not to say that not anybody else who's not writing blogs
[00:05:46.400 --> 00:05:48.640]   won't benefit from Fastbook reading sessions.
[00:05:48.640 --> 00:05:52.680]   But because I went through the same process and for me, this is what worked,
[00:05:52.680 --> 00:05:59.760]   I'm kind of biased that writing about what we learn as we go is kind of the best way forward.
[00:05:59.760 --> 00:06:04.080]   So Sai Amrit, thanks for writing a blog about Let's Keep Classification Simple.
[00:06:04.080 --> 00:06:05.800]   I think that's a really wonderful blog.
[00:06:05.800 --> 00:06:07.000]   I've read it.
[00:06:07.000 --> 00:06:11.120]   One of the best things that I like about this blog is he's used fast pages
[00:06:11.120 --> 00:06:13.600]   that Parul recommended last time.
[00:06:13.600 --> 00:06:17.120]   And it's really simple to get started with fast pages.
[00:06:17.120 --> 00:06:21.880]   So thanks, Sai, for writing about Let's Keep Classification Simple.
[00:06:21.880 --> 00:06:22.800]   And that's the blog.
[00:06:22.800 --> 00:06:28.400]   So Angelica, could you also please post all the links for all these tweets
[00:06:28.400 --> 00:06:31.920]   and all the reports in the Zoom chat?
[00:06:31.920 --> 00:06:34.000]   Thank you.
[00:06:34.000 --> 00:06:35.760]   We've also had Ravi.
[00:06:35.760 --> 00:06:38.040]   And these are people who've been writing week over week.
[00:06:38.040 --> 00:06:40.160]   So Ravi's come back again for week four.
[00:06:40.160 --> 00:06:42.520]   And he's also written everything about that's the key points.
[00:06:42.520 --> 00:06:43.960]   And he's got his own blog.
[00:06:43.960 --> 00:06:48.200]   And he's sharing what he's been learning every week with us.
[00:06:48.200 --> 00:06:49.880]   So thanks, Ravi, for your efforts.
[00:06:49.880 --> 00:06:52.840]   Really appreciate that.
[00:06:52.840 --> 00:06:53.760]   We've also seen Korean.
[00:06:53.760 --> 00:07:00.120]   So he's also been here, has been writing almost every week that I've seen.
[00:07:00.120 --> 00:07:04.040]   And he's also come back and he's done a whole recap of week four.
[00:07:04.040 --> 00:07:06.400]   So we built the MNIST digit classifier.
[00:07:06.400 --> 00:07:10.480]   And he's also got his own blog going, which is really exciting to see.
[00:07:10.480 --> 00:07:13.520]   And something I feel like--
[00:07:13.520 --> 00:07:15.760]   I don't know how your journey is about blogging is.
[00:07:15.760 --> 00:07:20.000]   And this is not to say about Korean, but for everybody that's been blogging.
[00:07:20.000 --> 00:07:22.840]   Something that I do is I find myself--
[00:07:22.840 --> 00:07:27.240]   if I wrote a blog about a year ago-- and I have presented another talk
[00:07:27.240 --> 00:07:29.800]   about this, about publicly sharing your work.
[00:07:29.800 --> 00:07:33.080]   But something that does happen very often to me
[00:07:33.080 --> 00:07:36.560]   is that I've written a blog, say, in 2019 or 2020.
[00:07:36.560 --> 00:07:39.360]   And I'm doing object detection in 2021.
[00:07:39.360 --> 00:07:41.880]   Then what happens is I'd find myself going back
[00:07:41.880 --> 00:07:43.840]   to the blog that I wrote in 2020.
[00:07:43.840 --> 00:07:46.840]   And not only because I've written it, that's
[00:07:46.840 --> 00:07:50.520]   the easiest way for me to then have a recap because I'm the one who wrote it.
[00:07:50.520 --> 00:07:55.360]   And I also find myself referring to my own blogs in the past.
[00:07:55.360 --> 00:07:58.800]   So if you are someone who's going to, by the time we finish,
[00:07:58.800 --> 00:08:01.080]   and you want to see, OK, what did we do every week,
[00:08:01.080 --> 00:08:03.080]   then you could very well go to your own blogs
[00:08:03.080 --> 00:08:04.960]   and you could have a look at what happened in week one, what
[00:08:04.960 --> 00:08:05.840]   happened in week two.
[00:08:05.840 --> 00:08:08.600]   And that could be a whole set of notes that you could refer.
[00:08:08.600 --> 00:08:12.000]   So I think I really, really encourage writing more and more blogs
[00:08:12.000 --> 00:08:13.280]   as we keep going forward.
[00:08:13.280 --> 00:08:16.760]   And thanks to everybody who've been doing it so far.
[00:08:16.760 --> 00:08:18.600]   Vinayak has come back again this week.
[00:08:18.600 --> 00:08:21.000]   And he's written about week four as well.
[00:08:21.000 --> 00:08:23.320]   So there's plenty of people who've been writing about it.
[00:08:23.320 --> 00:08:25.600]   I'm really excited to see this.
[00:08:25.600 --> 00:08:29.080]   And it's really good practice to do so.
[00:08:29.080 --> 00:08:32.160]   So Vinayak has got his own blog, which I would highly
[00:08:32.160 --> 00:08:34.400]   recommend checking out.
[00:08:34.400 --> 00:08:35.960]   And then we've had Ravi.
[00:08:35.960 --> 00:08:37.840]   Ravi's come back and he shared his blog.
[00:08:37.840 --> 00:08:42.200]   I particularly like the images, how he's defined that.
[00:08:42.200 --> 00:08:43.400]   I read this blog as well.
[00:08:43.400 --> 00:08:46.640]   And I really liked that how he's separated an RGB image
[00:08:46.640 --> 00:08:48.880]   into three channels, red, green, and blue.
[00:08:48.880 --> 00:08:50.320]   And he's provided a source for it.
[00:08:50.320 --> 00:08:53.640]   But it's just a really gentle introduction
[00:08:53.640 --> 00:08:55.200]   to how images are stored in computers.
[00:08:55.200 --> 00:08:58.760]   So thanks, Ravi, for sharing your blog with us as well.
[00:08:58.760 --> 00:09:06.200]   With that being said, let's get started
[00:09:06.200 --> 00:09:07.720]   with stochastic gradient descent.
[00:09:07.720 --> 00:09:10.680]   And as I've mentioned, I'll be spending more time
[00:09:10.680 --> 00:09:12.120]   writing code this time.
[00:09:12.120 --> 00:09:20.280]   And we will come back to this OneNote PDF as we need to.
[00:09:20.280 --> 00:09:21.520]   But let's get started with--
[00:09:22.520 --> 00:09:23.520]   gradient descent.
[00:09:23.520 --> 00:09:30.840]   Sorry, one second.
[00:09:30.840 --> 00:09:33.160]   I'm just trying to find where gradient descent is.
[00:09:33.160 --> 00:09:35.040]   Oh, here it is, 1.6.
[00:09:35.040 --> 00:09:37.000]   So we'll be referring--
[00:09:37.000 --> 00:09:38.800]   I will be providing on--
[00:09:38.800 --> 00:09:40.200]   as part of this chapter, we'll be
[00:09:40.200 --> 00:09:42.200]   covering what stochastic gradient descent is.
[00:09:42.200 --> 00:09:46.320]   And we'll also be looking at code as over here.
[00:09:46.320 --> 00:09:47.920]   And we will be looking at the code
[00:09:47.920 --> 00:09:49.920]   as a reference to the gradient descent.
[00:09:50.080 --> 00:09:50.800]   Over here.
[00:09:50.800 --> 00:09:54.240]   And we will be looking at how everything is implemented.
[00:09:54.240 --> 00:09:56.240]   And we'll implement it on the side.
[00:09:56.240 --> 00:09:58.280]   So that's how this session is going
[00:09:58.280 --> 00:09:59.640]   to look like going forward.
[00:09:59.640 --> 00:10:02.440]   And of course, we'll take breaks in the middle.
[00:10:02.440 --> 00:10:04.160]   If there's any questions that you have,
[00:10:04.160 --> 00:10:08.360]   keep posting them on at the fastbook5--
[00:10:08.360 --> 00:10:12.480]   1db.me/fastbook5 link.
[00:10:12.480 --> 00:10:14.000]   And that's where we'll be.
[00:10:14.000 --> 00:10:15.560]   That's where I'll constantly look at.
[00:10:17.960 --> 00:10:22.000]   If-- I do believe that today could be a longer session.
[00:10:22.000 --> 00:10:25.840]   Because my motive is to make sure that we cover
[00:10:25.840 --> 00:10:27.440]   and we wrap up chapter 4.
[00:10:27.440 --> 00:10:31.320]   If it goes above 90 minutes and you have to go in the middle,
[00:10:31.320 --> 00:10:32.400]   feel free to do so.
[00:10:32.400 --> 00:10:34.800]   Because everything that we do cover is recorded.
[00:10:34.800 --> 00:10:37.120]   But I would highly appreciate if you want to stay around.
[00:10:37.120 --> 00:10:39.280]   I'm not sure exactly on how long it's going to take.
[00:10:39.280 --> 00:10:41.200]   But if it takes longer, then feel
[00:10:41.200 --> 00:10:44.520]   free to leave in the middle and come back to the YouTube video
[00:10:44.520 --> 00:10:47.440]   and have a look from where you left.
[00:10:47.440 --> 00:10:49.000]   So that being said, let's get started.
[00:10:49.000 --> 00:10:55.560]   And when I say let's get started and I've
[00:10:55.560 --> 00:10:59.640]   pressed something that's taken me to a different spot,
[00:10:59.640 --> 00:11:03.680]   thanks to the new setup that I have.
[00:11:03.680 --> 00:11:07.680]   And I'm trying to go back to stochastic gradient descent.
[00:11:07.680 --> 00:11:08.240]   Where is it?
[00:11:08.240 --> 00:11:08.840]   Oh, here it is.
[00:11:08.840 --> 00:11:10.120]   Found it.
[00:11:10.120 --> 00:11:11.120]   OK.
[00:11:11.120 --> 00:11:12.640]   So stochastic gradient descent, then.
[00:11:12.640 --> 00:11:15.560]   What is stochastic gradient descent?
[00:11:15.560 --> 00:11:19.320]   Remember when we started with Fastbook week 1?
[00:11:19.320 --> 00:11:25.080]   And we saw Arthur Samuel's way back in the 1900s.
[00:11:25.080 --> 00:11:29.240]   And he was sharing on how a machine could learn.
[00:11:29.240 --> 00:11:33.520]   So far, we've built a digit 3 versus a digit 7 classifier.
[00:11:33.520 --> 00:11:35.400]   But we haven't done any learning.
[00:11:35.400 --> 00:11:36.840]   We've just given it--
[00:11:36.840 --> 00:11:38.320]   we've just provided a set of rules.
[00:11:38.320 --> 00:11:39.960]   OK, this is how it looks like.
[00:11:39.960 --> 00:11:41.720]   If something's closer to the digit--
[00:11:41.720 --> 00:11:45.480]   ideal digit 3, then the new image
[00:11:45.480 --> 00:11:48.800]   is classified as a 3 and otherwise classified as a 7.
[00:11:48.800 --> 00:11:50.520]   But what we haven't done so far is
[00:11:50.520 --> 00:11:52.560]   we haven't done any learning.
[00:11:52.560 --> 00:11:55.480]   As in, the model hasn't really been trained.
[00:11:55.480 --> 00:11:58.120]   So it's just a simple model that we used,
[00:11:58.120 --> 00:12:00.000]   which had no training.
[00:12:00.000 --> 00:12:01.840]   And as part of that, then, we'll be
[00:12:01.840 --> 00:12:03.400]   covering stochastic gradient descent.
[00:12:03.400 --> 00:12:06.440]   And we'll see what stochastic gradient descent is.
[00:12:06.440 --> 00:12:08.680]   Then the two main things, if we want
[00:12:08.680 --> 00:12:11.560]   to start looking at stochastic gradient descent,
[00:12:11.560 --> 00:12:12.840]   the two main things are--
[00:12:12.840 --> 00:12:15.440]   the first thing is an automatic means of testing,
[00:12:15.440 --> 00:12:16.600]   which is written here.
[00:12:16.600 --> 00:12:20.080]   So because every model would have some weights,
[00:12:20.080 --> 00:12:23.000]   then we need to be able to see if the weights that we've
[00:12:23.000 --> 00:12:24.840]   assigned to a model, are they good weights
[00:12:24.840 --> 00:12:26.200]   or are they bad weights?
[00:12:26.200 --> 00:12:28.840]   So that means we need some automatic means
[00:12:28.840 --> 00:12:32.120]   of testing the weights, the model-- current model weights.
[00:12:32.120 --> 00:12:33.760]   And the second thing that we need
[00:12:33.760 --> 00:12:37.480]   is we need a mechanism for altering the weight assignment.
[00:12:37.480 --> 00:12:40.320]   So if the weights are bad, then we
[00:12:40.320 --> 00:12:44.440]   need a way to be able to update the weights automatically.
[00:12:44.440 --> 00:12:46.160]   This is not something we should do.
[00:12:46.160 --> 00:12:47.840]   It's something the machine or the computer
[00:12:47.840 --> 00:12:49.360]   should be able to do on its own.
[00:12:49.360 --> 00:12:50.640]   So that's two main things that we
[00:12:50.640 --> 00:12:54.280]   need if we want to make sure that a computer can
[00:12:54.280 --> 00:12:55.360]   learn on its own.
[00:12:55.360 --> 00:12:58.360]   And let's see how we could do that.
[00:12:58.360 --> 00:13:01.760]   So let's say-- remember last time when you were looking at--
[00:13:01.760 --> 00:13:04.200]   if an image 7-- because everything is a number
[00:13:04.200 --> 00:13:05.560]   underneath, right?
[00:13:05.560 --> 00:13:07.480]   And if an image 7 looks something like this,
[00:13:07.480 --> 00:13:10.960]   and an image 8 looks something on the right,
[00:13:10.960 --> 00:13:14.880]   then if we have a look at this area, the one in green,
[00:13:14.880 --> 00:13:17.880]   if you have a look at this area, then for a 7,
[00:13:17.880 --> 00:13:19.920]   it's all background.
[00:13:19.920 --> 00:13:21.640]   There's nothing related to the digit 7
[00:13:21.640 --> 00:13:23.160]   in the bottom right of the image.
[00:13:23.160 --> 00:13:25.200]   But whereas in the number 8, there
[00:13:25.200 --> 00:13:28.840]   is this section of the 8 that is in this bottom right
[00:13:28.840 --> 00:13:29.960]   of the image.
[00:13:29.960 --> 00:13:34.160]   So what if we have a weight matrix?
[00:13:34.160 --> 00:13:36.560]   And what's going to happen with this weight matrix
[00:13:36.560 --> 00:13:41.200]   is what we ideally want is we want this weight matrix
[00:13:41.200 --> 00:13:44.480]   to have higher weights or to be activated more when it sees
[00:13:44.480 --> 00:13:45.400]   the digit 8.
[00:13:45.400 --> 00:13:47.400]   And when it sees the bottom right of the digit,
[00:13:47.400 --> 00:13:49.600]   then it needs to have higher weights so it can give us
[00:13:49.600 --> 00:13:51.120]   a higher activation.
[00:13:51.120 --> 00:13:55.000]   So if we have something like a weight matrix that's, again,
[00:13:55.000 --> 00:13:58.160]   a grid of the same size of image 7 and image 8,
[00:13:58.160 --> 00:14:03.600]   and if it has higher weights for this side when it sees 8
[00:14:03.600 --> 00:14:07.120]   and when it sees 7, then in that case, for a digit 8,
[00:14:07.120 --> 00:14:10.360]   it's going to have higher numbers over here.
[00:14:10.360 --> 00:14:12.840]   So that's just one way, and that's just one example
[00:14:12.840 --> 00:14:14.560]   of how we could get started.
[00:14:14.560 --> 00:14:17.040]   So let's say the probability of being 8,
[00:14:17.040 --> 00:14:21.720]   just as what I've shared, is just x star w times sum.
[00:14:21.720 --> 00:14:23.000]   So this is just as an example.
[00:14:23.000 --> 00:14:28.760]   x star w means this digit 7 or 8 being referred to as x,
[00:14:28.760 --> 00:14:33.720]   and the weight matrix being referred to as weight or w.
[00:14:33.720 --> 00:14:37.480]   So then how does the stochastic gradient descent or SGD
[00:14:37.480 --> 00:14:38.640]   process look like?
[00:14:38.640 --> 00:14:40.640]   And this is just the overview of SGD.
[00:14:40.640 --> 00:14:45.240]   This is really, really helpful, and it contains everything
[00:14:45.240 --> 00:14:46.680]   that we need to know about SGD.
[00:14:46.680 --> 00:14:49.840]   So the process of SGD looks like the first thing we do
[00:14:49.840 --> 00:14:50.960]   is we--
[00:14:50.960 --> 00:14:54.200]   of that weight matrix, what we do is we initialize the weights.
[00:14:54.200 --> 00:14:56.440]   These could be random weights.
[00:14:56.440 --> 00:14:57.680]   These could be random weights.
[00:14:57.680 --> 00:14:59.680]   These could be pre-trained weights.
[00:14:59.680 --> 00:15:04.480]   And these could be any values as far as we are concerned.
[00:15:04.480 --> 00:15:07.520]   But then the first step is you initialize your weight matrix
[00:15:07.520 --> 00:15:09.720]   with some weights.
[00:15:09.720 --> 00:15:11.760]   Then the second thing is because now you
[00:15:11.760 --> 00:15:14.840]   have your weight matrix or your model has some weights,
[00:15:14.840 --> 00:15:17.200]   and the next thing is you can pass in some inputs
[00:15:17.200 --> 00:15:18.480]   to get some predictions.
[00:15:18.480 --> 00:15:20.760]   So that's the second step here.
[00:15:20.760 --> 00:15:23.560]   So you see, for each image, we use these weights
[00:15:23.560 --> 00:15:24.720]   to get the predictions.
[00:15:24.720 --> 00:15:26.960]   That's the second step.
[00:15:26.960 --> 00:15:29.600]   Then the third step is now you have your predictions
[00:15:29.600 --> 00:15:31.600]   for all the images that you have,
[00:15:31.600 --> 00:15:33.360]   and you also have the ground truth label,
[00:15:33.360 --> 00:15:36.200]   so you know which images were digit 3
[00:15:36.200 --> 00:15:38.360]   or which images were digit 7.
[00:15:38.360 --> 00:15:40.160]   Then you're able to calculate something
[00:15:40.160 --> 00:15:43.240]   called the loss, which we've already discussed what it is.
[00:15:43.240 --> 00:15:46.720]   So the third step is you calculate the loss.
[00:15:46.720 --> 00:15:49.080]   Then the fourth step is you calculate the gradients.
[00:15:49.080 --> 00:15:50.320]   This is something that's new.
[00:15:50.320 --> 00:15:53.280]   This is something that we're looking at for the first time.
[00:15:53.280 --> 00:15:55.680]   But essentially, what the gradient will tell you
[00:15:55.680 --> 00:15:58.240]   is that if we change the weights,
[00:15:58.240 --> 00:16:00.080]   how the loss is going to change.
[00:16:00.080 --> 00:16:04.720]   So the loss and the gradient are related to each other.
[00:16:04.720 --> 00:16:07.920]   We will look into the details of this very soon.
[00:16:07.920 --> 00:16:11.360]   But for now, just understand that what the gradient will
[00:16:11.360 --> 00:16:14.080]   tell us, it will tell us that if we change the weight,
[00:16:14.080 --> 00:16:16.040]   then how is the loss going to change.
[00:16:16.040 --> 00:16:18.160]   That's been written here, how changing that weight
[00:16:18.160 --> 00:16:20.360]   would change the loss.
[00:16:20.360 --> 00:16:22.600]   The fifth step is you take a step.
[00:16:22.600 --> 00:16:24.200]   What does that mean?
[00:16:24.200 --> 00:16:29.600]   We started with some initial weights over here.
[00:16:29.600 --> 00:16:33.080]   What we want to do, remember, as part of the two things
[00:16:33.080 --> 00:16:35.160]   that we got started with, the first step
[00:16:35.160 --> 00:16:37.720]   is we want to check if the weights that we have,
[00:16:37.720 --> 00:16:38.880]   are they good or bad?
[00:16:38.880 --> 00:16:40.480]   And the second thing that we want to do
[00:16:40.480 --> 00:16:42.200]   is want to be able to alter these weights.
[00:16:42.200 --> 00:16:43.560]   We want to make them bigger or we
[00:16:43.560 --> 00:16:47.000]   want to make them smaller automatically.
[00:16:47.000 --> 00:16:49.520]   So the second thing, so this step
[00:16:49.520 --> 00:16:52.760]   is this idea of being able to update the weights
[00:16:52.760 --> 00:16:54.160]   automatically.
[00:16:54.160 --> 00:16:56.360]   And we do that by using the loss function
[00:16:56.360 --> 00:16:57.520]   and by using the gradients.
[00:16:57.520 --> 00:16:58.680]   So we take a step.
[00:16:58.680 --> 00:17:00.560]   So that's the fifth step.
[00:17:00.560 --> 00:17:03.760]   It is written here in the book.
[00:17:03.760 --> 00:17:06.160]   You take a step, basically, update all the weights
[00:17:06.160 --> 00:17:08.360]   based on the calculations, based on the loss,
[00:17:08.360 --> 00:17:11.080]   based on the gradients that we have so far.
[00:17:11.080 --> 00:17:14.760]   And once you finally have-- sorry, one second.
[00:17:14.760 --> 00:17:18.800]   And once you finally have a good set of weights,
[00:17:18.800 --> 00:17:19.760]   then you finally stop.
[00:17:19.760 --> 00:17:22.640]   So in the end, when you have a trained model, you stop.
[00:17:22.640 --> 00:17:25.040]   When you're happy with the performance of the model,
[00:17:25.040 --> 00:17:27.760]   that's when you stop.
[00:17:27.760 --> 00:17:29.280]   So that's what STD looks like.
[00:17:29.280 --> 00:17:32.160]   So see what happens is if I repeat
[00:17:32.160 --> 00:17:35.440]   this process of making some predictions,
[00:17:35.440 --> 00:17:38.480]   calculating the loss, calculating
[00:17:38.480 --> 00:17:41.160]   gradients of the loss, and then taking a step so
[00:17:41.160 --> 00:17:43.200]   that my model performance becomes better,
[00:17:43.200 --> 00:17:45.480]   if I keep doing this over and over again,
[00:17:45.480 --> 00:17:48.360]   then I'm going to end up after, say, 100 iterations or 50
[00:17:48.360 --> 00:17:49.120]   iterations.
[00:17:49.120 --> 00:17:52.360]   I'm going to end up at a point where the model performance is
[00:17:52.360 --> 00:17:52.960]   high.
[00:17:52.960 --> 00:17:54.840]   And then I can say I can be satisfied
[00:17:54.840 --> 00:17:56.000]   with that model performance.
[00:17:56.000 --> 00:17:57.480]   And I can say it's time to stop.
[00:17:57.480 --> 00:17:59.760]   And my model has finished training.
[00:17:59.760 --> 00:18:04.760]   So that's the general idea of stochastic gradient descent.
[00:18:04.760 --> 00:18:07.440]   Below, then, in the book, every step
[00:18:07.440 --> 00:18:11.320]   has just been explained in a bit more detail.
[00:18:11.320 --> 00:18:12.840]   As I've already said, initialize means
[00:18:12.840 --> 00:18:16.600]   you initialize the parameters to some random values.
[00:18:16.600 --> 00:18:17.480]   Loss.
[00:18:17.480 --> 00:18:18.400]   What is loss?
[00:18:18.400 --> 00:18:20.000]   We've already looked at the difference
[00:18:20.000 --> 00:18:21.480]   between the loss and a metric.
[00:18:21.480 --> 00:18:26.720]   A loss is just a number that will tell us about the--
[00:18:26.720 --> 00:18:29.200]   the loss will tell us about the model's performance.
[00:18:29.200 --> 00:18:33.000]   We want to be able to assess that the weights
[00:18:33.000 --> 00:18:35.280]   that a model has, are they good or bad?
[00:18:35.280 --> 00:18:38.120]   So see this.
[00:18:38.120 --> 00:18:40.080]   This was my model.
[00:18:40.080 --> 00:18:43.840]   And each model would have some weights, w.
[00:18:43.840 --> 00:18:47.040]   I need to be able to tell if these weights that this model
[00:18:47.040 --> 00:18:49.080]   has, are they good or bad?
[00:18:49.080 --> 00:18:53.480]   And then something that will help me understand this
[00:18:53.480 --> 00:18:55.160]   is called loss.
[00:18:55.160 --> 00:18:58.560]   So loss is that one thing that will help me assess.
[00:18:58.560 --> 00:19:01.600]   If the loss is a number that's generally high,
[00:19:01.600 --> 00:19:03.720]   it means that the model performance is bad.
[00:19:03.720 --> 00:19:05.960]   And if the loss is a number that's generally low,
[00:19:05.960 --> 00:19:07.920]   then that means the model performance is good.
[00:19:07.920 --> 00:19:13.960]   So then the-- so now you have--
[00:19:13.960 --> 00:19:15.240]   you've initialized your weights.
[00:19:15.240 --> 00:19:17.680]   And you have calculated the loss.
[00:19:17.680 --> 00:19:20.600]   Then the third step is you take a step.
[00:19:20.600 --> 00:19:23.520]   So you take a step to update the weights.
[00:19:23.520 --> 00:19:25.800]   And you-- this step will basically--
[00:19:25.800 --> 00:19:28.880]   you only take a step to update the weights
[00:19:28.880 --> 00:19:31.800]   that you know is going to improve the model performance.
[00:19:31.800 --> 00:19:32.720]   How do you know that?
[00:19:32.720 --> 00:19:34.160]   You know that through the gradient.
[00:19:34.160 --> 00:19:37.320]   And we will look at this as we go forward in the chapter.
[00:19:37.320 --> 00:19:40.760]   But for now, just understand that when you're taking a step,
[00:19:40.760 --> 00:19:43.320]   you're basically taking a step to improve the model
[00:19:43.320 --> 00:19:45.520]   performance.
[00:19:45.520 --> 00:19:47.480]   And you keep doing this over and over again.
[00:19:47.480 --> 00:19:50.280]   And you finally stop.
[00:19:50.280 --> 00:19:50.920]   So that's that.
[00:19:50.920 --> 00:19:55.480]   So that's just an overview of what STD looks like.
[00:19:55.480 --> 00:19:58.400]   So let's understand this with the help of images.
[00:19:58.400 --> 00:20:02.320]   So let's say I have a loss function that looks like this,
[00:20:02.320 --> 00:20:03.880]   that looks like x squared.
[00:20:03.880 --> 00:20:07.280]   And if you plot that function of x squared,
[00:20:07.280 --> 00:20:08.480]   it looks something like this.
[00:20:08.480 --> 00:20:12.360]   In mathematics, this is a parabola, upward looking.
[00:20:12.360 --> 00:20:15.320]   But you don't have to worry about that at all.
[00:20:15.320 --> 00:20:18.400]   Just use this plot function in the library.
[00:20:18.400 --> 00:20:23.960]   And Fast.ai has this function called plot function.
[00:20:23.960 --> 00:20:27.000]   And then you can use that plot function to plot any function.
[00:20:27.000 --> 00:20:28.440]   And if we plot this, then you can
[00:20:28.440 --> 00:20:31.440]   see that it looks like this curve that's upward looking.
[00:20:31.440 --> 00:20:36.520]   So then the first step, as I said,
[00:20:36.520 --> 00:20:39.800]   in stochastic gradient descent is to random initialize.
[00:20:39.800 --> 00:20:41.320]   This is my first step.
[00:20:41.320 --> 00:20:44.400]   So as part of my first step, if I randomly initialize,
[00:20:44.400 --> 00:20:48.160]   then let's say I'm somewhere here on the loss curve.
[00:20:48.160 --> 00:20:49.360]   So I can randomly--
[00:20:49.360 --> 00:20:53.960]   if this x represents the parameters, just as an example,
[00:20:53.960 --> 00:20:57.720]   if this represents the model parameters,
[00:20:57.720 --> 00:21:01.480]   then let's say if I initialize my value,
[00:21:01.480 --> 00:21:05.400]   the first value at somewhere around minus 1.6,
[00:21:05.400 --> 00:21:10.280]   then the loss would be somewhere around 2.4.
[00:21:10.280 --> 00:21:11.320]   Does that make sense?
[00:21:11.320 --> 00:21:13.000]   So that's just my random initialization.
[00:21:13.000 --> 00:21:16.880]   It could be any number, but I just randomly initialize.
[00:21:16.880 --> 00:21:19.480]   Then, as I said, the next thing that you want to do
[00:21:19.480 --> 00:21:22.360]   is you want to be able to calculate the gradient.
[00:21:22.360 --> 00:21:23.400]   So think of this.
[00:21:23.400 --> 00:21:26.560]   If I'm somebody who's trying to reduce the loss,
[00:21:26.560 --> 00:21:30.280]   and that loss looks like this upward looking curve,
[00:21:30.280 --> 00:21:34.520]   and I want to reduce the loss, then this value of parameter,
[00:21:34.520 --> 00:21:36.560]   I should move in this direction.
[00:21:36.560 --> 00:21:39.000]   Basically, to bring this loss down,
[00:21:39.000 --> 00:21:42.160]   I need to update the value of x such
[00:21:42.160 --> 00:21:44.560]   that it's more closer to 0, because that's
[00:21:44.560 --> 00:21:46.680]   when the loss is the lowest.
[00:21:46.680 --> 00:21:48.680]   But right now, I'm at minus 1.6.
[00:21:48.680 --> 00:21:50.440]   So I need to go towards 0.
[00:21:50.440 --> 00:21:54.360]   I need to update the value of this parameter x towards 0
[00:21:54.360 --> 00:21:56.120]   such that my loss can decrease.
[00:21:56.120 --> 00:21:59.600]   And then how do I know that I need to go--
[00:21:59.600 --> 00:22:01.840]   for a human, I can just have a look at this image,
[00:22:01.840 --> 00:22:04.680]   and I can say, oh, I need to go towards 0
[00:22:04.680 --> 00:22:06.680]   so my loss will decrease.
[00:22:06.680 --> 00:22:08.120]   But how does a computer know?
[00:22:08.120 --> 00:22:11.320]   How would a computer know which direction it needs to go?
[00:22:11.320 --> 00:22:16.640]   That's something that a slope can tell us.
[00:22:16.640 --> 00:22:18.880]   In mathematics, then, just think of this.
[00:22:18.880 --> 00:22:22.080]   The slope or the gradient will tell you the direction
[00:22:22.080 --> 00:22:25.640]   that you have to move, and it will tell you the direction
[00:22:25.640 --> 00:22:28.680]   that you have to move to reduce the loss.
[00:22:28.680 --> 00:22:30.520]   So what this slope is telling me--
[00:22:30.520 --> 00:22:33.000]   the slope looks like this.
[00:22:33.000 --> 00:22:35.280]   What it's telling me is that I need
[00:22:35.280 --> 00:22:39.800]   to go from this point towards the right
[00:22:39.800 --> 00:22:42.120]   so that I can reduce my loss.
[00:22:42.120 --> 00:22:45.680]   So that's another step in stochastic gradient descent.
[00:22:45.680 --> 00:22:50.680]   That's the third step, actually.
[00:22:50.680 --> 00:22:53.040]   So when I say that's the third step, it's basically,
[00:22:53.040 --> 00:22:56.400]   I'm referring to this.
[00:22:56.400 --> 00:22:57.760]   I initialized.
[00:22:57.760 --> 00:22:58.720]   I made some predictions.
[00:22:58.720 --> 00:23:01.240]   I calculated the loss, and now I'm calculating the gradients.
[00:23:01.240 --> 00:23:11.160]   So the slope will tell me which direction
[00:23:11.160 --> 00:23:13.360]   I need to move to be able to reduce the loss.
[00:23:13.360 --> 00:23:19.640]   And then if I make a step in that direction--
[00:23:19.640 --> 00:23:23.680]   so if I was here previously, this is where I started.
[00:23:23.680 --> 00:23:26.600]   If that's my starting point, I'm just going to call it S,
[00:23:26.600 --> 00:23:28.000]   which is my starting point.
[00:23:28.000 --> 00:23:29.840]   And if I made a step in this direction,
[00:23:29.840 --> 00:23:32.200]   as you can see, my loss has decreased.
[00:23:32.200 --> 00:23:34.240]   So if my loss was a higher value,
[00:23:34.240 --> 00:23:35.960]   now it is some lower value.
[00:23:35.960 --> 00:23:38.640]   And that is what SDD does.
[00:23:38.640 --> 00:23:43.120]   SDD is just a way of automatically reducing
[00:23:43.120 --> 00:23:44.760]   the loss.
[00:23:44.760 --> 00:23:46.240]   And if you keep doing that, if you
[00:23:46.240 --> 00:23:49.520]   keep following this process over and over and over again,
[00:23:49.520 --> 00:23:53.080]   you're going to come to a point where the loss is a minimum.
[00:23:53.080 --> 00:23:54.680]   And when your loss is the minimum,
[00:23:54.680 --> 00:23:56.360]   your model performance is high.
[00:23:56.360 --> 00:23:58.040]   And when your model performance is high,
[00:23:58.040 --> 00:24:00.680]   that means it can do the task you're asking it to do.
[00:24:00.680 --> 00:24:03.000]   So if you're training a model for cats versus dogs,
[00:24:03.000 --> 00:24:07.320]   and initially, the model has really bad performance.
[00:24:07.320 --> 00:24:09.400]   It cannot classify cats versus dogs.
[00:24:09.400 --> 00:24:12.720]   That means the loss is really high initially.
[00:24:12.720 --> 00:24:14.640]   But then if you start taking steps,
[00:24:14.640 --> 00:24:16.680]   start taking these steps towards the gradient,
[00:24:16.680 --> 00:24:19.640]   so you start taking these steps towards the slope of the loss,
[00:24:19.640 --> 00:24:21.560]   then you know how that loss is going to--
[00:24:21.560 --> 00:24:23.280]   as in, you know the direction that you have
[00:24:23.280 --> 00:24:24.600]   to move to reduce the loss.
[00:24:24.600 --> 00:24:26.520]   And if you keep doing that over and over again,
[00:24:26.520 --> 00:24:28.360]   you're finally going to reach a point where
[00:24:28.360 --> 00:24:30.720]   the loss is the minimum and the model performance is
[00:24:30.720 --> 00:24:31.360]   the highest.
[00:24:31.360 --> 00:24:32.840]   That means that now you're modeling
[00:24:32.840 --> 00:24:36.360]   classify cats versus dogs.
[00:24:36.360 --> 00:24:39.440]   So that's the basic idea of SGD.
[00:24:39.440 --> 00:24:40.880]   What time is it?
[00:24:40.880 --> 00:24:42.600]   I'm going to take two minutes break,
[00:24:42.600 --> 00:24:44.220]   and I'm going to look at the questions.
[00:24:44.220 --> 00:24:45.560]   If there's any questions that are
[00:24:45.560 --> 00:24:47.600]   related to what we've looked at in terms
[00:24:47.600 --> 00:24:53.880]   of the basic idea of SGD, that's what we'll look at now.
[00:24:53.880 --> 00:24:55.120]   So one second, please.
[00:24:55.120 --> 00:25:02.040]   OK, we have some comments.
[00:25:02.040 --> 00:25:10.880]   That's OK.
[00:25:10.880 --> 00:25:13.400]   Higher activations, just ignore that for now.
[00:25:13.400 --> 00:25:16.120]   As long as you understand that SGD is just
[00:25:16.120 --> 00:25:18.800]   the process of being able to move
[00:25:18.800 --> 00:25:20.200]   in the direction of the gradients,
[00:25:20.200 --> 00:25:22.120]   and SGD is just this process of being
[00:25:22.120 --> 00:25:24.760]   able to reduce the loss iteratively,
[00:25:24.760 --> 00:25:25.760]   then that's good enough.
[00:25:25.760 --> 00:25:27.680]   As long as you get the main point,
[00:25:27.680 --> 00:25:29.280]   then don't worry about this, because everything
[00:25:29.280 --> 00:25:30.560]   will become clear as we go.
[00:25:30.560 --> 00:25:32.280]   And we're going to dig deeper and deeper.
[00:25:32.280 --> 00:25:34.640]   And my apologies for using the word activations
[00:25:34.640 --> 00:25:36.080]   without telling you what they are.
[00:25:36.080 --> 00:25:39.440]   So ignore me for now.
[00:25:39.440 --> 00:25:41.560]   Gradient initialization, when he's
[00:25:41.560 --> 00:25:43.640]   talking about randomly initializing the parameters,
[00:25:43.640 --> 00:25:46.080]   it does mean picking random, complete randomness.
[00:25:46.080 --> 00:25:46.840]   Yes.
[00:25:46.840 --> 00:25:49.720]   So wait, unless everything that I'm explaining right now,
[00:25:49.720 --> 00:25:51.680]   we're going to look at in terms of code.
[00:25:51.680 --> 00:25:53.960]   So that's OK if you only get some part of it.
[00:25:53.960 --> 00:25:57.480]   But as long as you get the basic idea,
[00:25:57.480 --> 00:25:59.240]   gradientization could just mean if you
[00:25:59.240 --> 00:26:01.920]   have an array of five numbers, then
[00:26:01.920 --> 00:26:03.560]   you just initialize those five numbers
[00:26:03.560 --> 00:26:05.400]   to be some random values.
[00:26:05.400 --> 00:26:07.360]   So that's just gradient initialization.
[00:26:07.360 --> 00:26:10.200]   That just means you're picking some random numbers,
[00:26:10.200 --> 00:26:13.600]   and you're assigning those random numbers to the parameters.
[00:26:21.240 --> 00:26:22.920]   So I'm now looking at the next question,
[00:26:22.920 --> 00:26:24.360]   when validating error is increasing
[00:26:24.360 --> 00:26:26.560]   after a number of iterations.
[00:26:26.560 --> 00:26:30.120]   It was told that the model tried to remember the training data.
[00:26:30.120 --> 00:26:30.640]   Yes.
[00:26:30.640 --> 00:26:32.160]   It's still out of my intuition how
[00:26:32.160 --> 00:26:36.640]   a model which uses data to learn also remembers data.
[00:26:36.640 --> 00:26:37.840]   OK.
[00:26:37.840 --> 00:26:40.880]   Like model is not thinker, how it remembers.
[00:26:40.880 --> 00:26:42.760]   A little awkward for me to think on that.
[00:26:42.760 --> 00:26:43.320]   OK.
[00:26:43.320 --> 00:26:45.760]   So you're referring to overfitting.
[00:26:45.760 --> 00:26:47.920]   What I would recommend is have a look.
[00:26:48.920 --> 00:26:52.040]   What I would recommend is just read more about overfitting
[00:26:52.040 --> 00:26:52.880]   and what that means.
[00:26:52.880 --> 00:26:57.400]   But basically, the model is not a thinker, yes.
[00:26:57.400 --> 00:26:59.680]   But if you keep reducing the loss,
[00:26:59.680 --> 00:27:01.680]   and you keep-- over time, when you're
[00:27:01.680 --> 00:27:04.440]   going over the input data, what you'll see
[00:27:04.440 --> 00:27:06.920]   is all the model is doing, it's starting
[00:27:06.920 --> 00:27:09.640]   to learn the patterns of the input data.
[00:27:09.640 --> 00:27:10.720]   OK.
[00:27:10.720 --> 00:27:12.800]   And if you keep going over and over
[00:27:12.800 --> 00:27:15.240]   and through multiple iterations, then what it's going to do
[00:27:15.240 --> 00:27:17.120]   is it's going to remember those patterns.
[00:27:17.120 --> 00:27:18.760]   It's going to-- the model is going
[00:27:18.760 --> 00:27:22.640]   to just overlearn all those patterns,
[00:27:22.640 --> 00:27:24.160]   and then it won't be able to class--
[00:27:24.160 --> 00:27:26.360]   like you want the model to learn general patterns.
[00:27:26.360 --> 00:27:28.960]   You don't want the model to learn the exact patterns.
[00:27:28.960 --> 00:27:30.800]   An example of this is if you're trying
[00:27:30.800 --> 00:27:34.240]   to classify, say, a particular cat from a particular dog,
[00:27:34.240 --> 00:27:37.880]   then each cat of the same breed are going to look different.
[00:27:37.880 --> 00:27:39.520]   Like they could be in a different pose.
[00:27:39.520 --> 00:27:40.720]   They could be in a different--
[00:27:40.720 --> 00:27:42.880]   they could have slightly different color of the fur.
[00:27:42.880 --> 00:27:46.120]   They could have some slight small variances, right?
[00:27:46.120 --> 00:27:49.960]   But if you keep training a model over and over again,
[00:27:49.960 --> 00:27:51.280]   then what the model will learn is
[00:27:51.280 --> 00:27:53.560]   it will only learn a particular type of fur.
[00:27:53.560 --> 00:27:55.760]   It will only learn a particular type of--
[00:27:55.760 --> 00:27:58.760]   like if the cat is sitting in a particular position,
[00:27:58.760 --> 00:28:01.280]   that's what it means that the model has overfit.
[00:28:01.280 --> 00:28:03.920]   It just means that the model has learned everything
[00:28:03.920 --> 00:28:05.840]   that there is to learn about the single image.
[00:28:05.840 --> 00:28:07.680]   Instead, what we want the model to learn
[00:28:07.680 --> 00:28:10.480]   is we want it to learn the general pattern.
[00:28:10.480 --> 00:28:11.400]   Cats have furs.
[00:28:11.400 --> 00:28:13.960]   This is what the furs look like.
[00:28:13.960 --> 00:28:15.880]   And that's just the basic idea of--
[00:28:15.880 --> 00:28:18.160]   so I think what you're referring to here is overfitting.
[00:28:18.160 --> 00:28:20.840]   And I hope what I've explained would help.
[00:28:20.840 --> 00:28:28.640]   Oh, gradient descent.
[00:28:28.640 --> 00:28:31.240]   And for now, let's just assume stochastic gradient descent
[00:28:31.240 --> 00:28:32.600]   and gradient descent are the difference.
[00:28:32.600 --> 00:28:34.080]   So don't worry about the difference
[00:28:34.080 --> 00:28:36.480]   between gradient descent and stochastic gradient descent.
[00:28:36.480 --> 00:28:40.000]   Stochastic gradient descent is just through mini-batches.
[00:28:40.000 --> 00:28:41.360]   But that's OK.
[00:28:41.360 --> 00:28:44.680]   Don't worry about these small, small things for now.
[00:28:44.680 --> 00:28:46.360]   Let's just get the basic idea.
[00:28:46.360 --> 00:28:50.240]   And as we go forward, we will understand every small thing
[00:28:50.240 --> 00:28:52.280]   that there is to know and all the small differences
[00:28:52.280 --> 00:28:54.480]   as we keep going further and further
[00:28:54.480 --> 00:28:56.080]   into the fast book sessions.
[00:28:56.080 --> 00:28:59.360]   Is this similar to finding the arg min for the parameter?
[00:28:59.360 --> 00:29:02.080]   No, it's not the same as just finding the minimum value
[00:29:02.080 --> 00:29:03.960]   for the parameter.
[00:29:03.960 --> 00:29:07.240]   You're just trying to minimize the loss.
[00:29:07.240 --> 00:29:10.040]   So what arg min does is arg min just calculates
[00:29:10.040 --> 00:29:11.360]   what the minimum value is.
[00:29:11.360 --> 00:29:14.000]   So that's completely different than what we're trying to do.
[00:29:14.000 --> 00:29:16.600]   We're trying to go over and over in iterations.
[00:29:16.600 --> 00:29:19.640]   And we are trying to find--
[00:29:19.640 --> 00:29:22.520]   we're trying to update the parameters in a way.
[00:29:22.520 --> 00:29:25.640]   So going back to the image, we're
[00:29:25.640 --> 00:29:27.800]   trying to update the parameters in a way
[00:29:27.800 --> 00:29:32.000]   that your predictions match the ground truth variables.
[00:29:32.000 --> 00:29:34.420]   And when your predictions match the ground truth variables,
[00:29:34.420 --> 00:29:36.120]   that's when the loss is at a minimum.
[00:29:36.120 --> 00:29:42.080]   OK.
[00:29:42.080 --> 00:29:47.360]   So that's the basics of stochastic gradient descent.
[00:29:47.360 --> 00:29:50.640]   Now, something, as I said, in stochastic gradient descent,
[00:29:50.640 --> 00:29:52.200]   what you need to be able to do is you
[00:29:52.200 --> 00:29:54.800]   need to calculate the gradients.
[00:29:54.800 --> 00:29:56.240]   So you start with--
[00:29:56.240 --> 00:29:58.680]   again, to repeat what happened in stochastic gradient descent
[00:29:58.680 --> 00:29:59.160]   is--
[00:29:59.160 --> 00:30:00.520]   or generally in any deep learning
[00:30:00.520 --> 00:30:02.640]   is you start with some initialization
[00:30:02.640 --> 00:30:03.920]   or some random values.
[00:30:03.920 --> 00:30:05.800]   You make predictions from the model.
[00:30:05.800 --> 00:30:07.480]   You calculate the loss.
[00:30:07.480 --> 00:30:10.680]   Then using that loss, you calculate the gradients.
[00:30:10.680 --> 00:30:14.520]   And that gradient is the slope that we saw before.
[00:30:14.520 --> 00:30:16.880]   Now, how do we calculate the gradients?
[00:30:16.880 --> 00:30:18.920]   Like in calculus, there's derivatives, right?
[00:30:18.920 --> 00:30:21.440]   In math, derivatives can help you.
[00:30:21.440 --> 00:30:24.760]   And that's how you can calculate the gradients.
[00:30:24.760 --> 00:30:26.800]   But when you're in code, you don't
[00:30:26.800 --> 00:30:28.520]   need to worry about the mathematics.
[00:30:28.520 --> 00:30:32.400]   Sure, it will help to understand the basics of what gradient
[00:30:32.400 --> 00:30:34.800]   means and what slope means.
[00:30:34.800 --> 00:30:36.440]   But if you go back, when you go back
[00:30:36.440 --> 00:30:38.140]   and you read this chapter, you'll
[00:30:38.140 --> 00:30:40.760]   see that there's lots of resources in Khan Academy
[00:30:40.760 --> 00:30:43.080]   that have been provided as part of this chapter
[00:30:43.080 --> 00:30:45.760]   to help you with the basics.
[00:30:45.760 --> 00:30:48.640]   But for now, for what we want to know
[00:30:48.640 --> 00:30:52.840]   is let's say I have my loss function, which is x square.
[00:30:52.840 --> 00:30:55.440]   So I can just say plot--
[00:30:55.440 --> 00:30:57.360]   or I don't need to say plot function, actually.
[00:30:57.360 --> 00:31:02.240]   We all know that this x square looks--
[00:31:02.240 --> 00:31:06.960]   this x square looks like this, the upward-looking parabola.
[00:31:06.960 --> 00:31:10.220]   So then in PyTorch, if we want to be
[00:31:10.220 --> 00:31:14.500]   able to calculate gradients, then all I need to do in PyTorch
[00:31:14.500 --> 00:31:19.020]   is I need to be able to say that starting with some number,
[00:31:19.020 --> 00:31:22.420]   if I pass in requires grad, then PyTorch
[00:31:22.420 --> 00:31:26.100]   knows that this number, anything that I do to this tensor,
[00:31:26.100 --> 00:31:30.140]   rather, PyTorch will keep a track of everything
[00:31:30.140 --> 00:31:31.500]   that I do to this tensor.
[00:31:31.500 --> 00:31:33.260]   And it will know that later I'm going
[00:31:33.260 --> 00:31:34.680]   to come back to this tensor, and it
[00:31:34.680 --> 00:31:37.020]   needs to be able to find the gradients with respect
[00:31:37.020 --> 00:31:39.740]   to this xt.
[00:31:39.740 --> 00:31:45.120]   So let's assume that my input to this function f
[00:31:45.120 --> 00:31:46.700]   is this tensor 3.
[00:31:46.700 --> 00:31:48.820]   And I've already said that this tensor 3,
[00:31:48.820 --> 00:31:51.660]   I need to be able to calculate the gradients.
[00:31:51.660 --> 00:31:53.380]   So I start with that.
[00:31:53.380 --> 00:31:55.900]   And in PyTorch, you can see how now in xt,
[00:31:55.900 --> 00:31:58.740]   it says requires grad is true, which
[00:31:58.740 --> 00:32:00.140]   means PyTorch knows that it needs
[00:32:00.140 --> 00:32:01.580]   to calculate the gradients.
[00:32:01.580 --> 00:32:03.500]   So it needs to be able to calculate
[00:32:03.500 --> 00:32:06.260]   the gradients on this xt.
[00:32:06.260 --> 00:32:09.060]   So now I can get my output, so yt.
[00:32:09.060 --> 00:32:13.420]   So if I pass in 3 to x squared, I will get the value 9.
[00:32:13.420 --> 00:32:15.340]   So I can calculate my yt.
[00:32:15.340 --> 00:32:18.100]   Now, to be able to calculate the gradients,
[00:32:18.100 --> 00:32:20.980]   the function call that you tell PyTorch to calculate
[00:32:20.980 --> 00:32:22.860]   the gradients is backward.
[00:32:22.860 --> 00:32:27.020]   So when I say yt.backward, it's going to go backwards and look
[00:32:27.020 --> 00:32:31.100]   at all the function calls that we've made to this number xt.
[00:32:31.100 --> 00:32:33.100]   And then it's going to calculate the gradients
[00:32:33.100 --> 00:32:35.540]   with respect to xt.
[00:32:35.540 --> 00:32:39.300]   So if I go yt.backward, and I now check the--
[00:32:39.300 --> 00:32:44.340]   now, xt will have basically an attribute called grad,
[00:32:44.340 --> 00:32:46.180]   which is the gradient of xt.
[00:32:46.180 --> 00:32:49.380]   So if I press xt.grad, the gradient is 6.
[00:32:49.380 --> 00:32:53.460]   So in mathematics, if you come from a mathematical background,
[00:32:53.460 --> 00:32:56.500]   you would know that the derivative of x squared
[00:32:56.500 --> 00:32:58.300]   is 2x, right?
[00:32:58.300 --> 00:33:01.340]   And then if the input is 3, which
[00:33:01.340 --> 00:33:05.460]   means the gradient would be 2 times 3, which is 6.
[00:33:05.460 --> 00:33:07.460]   So all I wanted to show as part of this
[00:33:07.460 --> 00:33:09.780]   is that you don't need to worry about how
[00:33:09.780 --> 00:33:11.780]   to calculate the gradients.
[00:33:11.780 --> 00:33:13.780]   PyTorch can do it all for you.
[00:33:13.780 --> 00:33:19.420]   So when we are at this step in stochastic gradient descent,
[00:33:19.420 --> 00:33:22.820]   I'm trying to find the figure again of the whole process.
[00:33:22.820 --> 00:33:24.380]   So here's the process.
[00:33:24.380 --> 00:33:26.420]   At step 4, when we need to be able to calculate
[00:33:26.420 --> 00:33:30.220]   the gradients of the loss with respect to the parameters,
[00:33:30.220 --> 00:33:33.140]   then you don't need to worry about how that happens.
[00:33:33.140 --> 00:33:35.420]   For now, just to be able to do all of this,
[00:33:35.420 --> 00:33:38.540]   you can just say loss.backward, which will
[00:33:38.540 --> 00:33:41.700]   calculate the gradients for you.
[00:33:41.700 --> 00:33:44.180]   So that's the basics of it.
[00:33:44.180 --> 00:33:47.820]   So let's say if my input, instead of being just one
[00:33:47.820 --> 00:33:51.620]   tensor with a single number 3, let's say my input was this
[00:33:51.620 --> 00:33:56.420]   number 3.4 and then 10, or just some floats.
[00:33:56.420 --> 00:33:58.420]   I remember what my fx looks like.
[00:33:58.420 --> 00:34:00.620]   I can just say my yt.
[00:34:00.620 --> 00:34:03.940]   So my output, I pass in my input and I just get my output.
[00:34:03.940 --> 00:34:05.620]   So my output is some value.
[00:34:05.620 --> 00:34:09.740]   Then I can again say backward, because this tensor
[00:34:09.740 --> 00:34:12.940]   has been initialized to say, hey, PyTorch,
[00:34:12.940 --> 00:34:16.580]   I need you to remember that I need
[00:34:16.580 --> 00:34:18.940]   you to know that I want to be able to calculate the gradients
[00:34:18.940 --> 00:34:20.580]   with respect to this xt.
[00:34:20.580 --> 00:34:24.980]   So I can just say now my output.backward or yt.backward,
[00:34:24.980 --> 00:34:26.620]   and I can check the gradients.
[00:34:26.620 --> 00:34:28.180]   They are 6, 8, and 20.
[00:34:28.180 --> 00:34:32.420]   So remember, because the input function was x squared,
[00:34:32.420 --> 00:34:36.340]   the gradients would be 2x, which means for value of 3,
[00:34:36.340 --> 00:34:37.580]   the gradient would be 6.
[00:34:37.580 --> 00:34:39.500]   For value of 4, the gradient would be 8.
[00:34:39.500 --> 00:34:41.980]   For value of 10, the gradient would be 20.
[00:34:41.980 --> 00:34:43.340]   And that's it.
[00:34:43.340 --> 00:34:47.700]   So again, to repeat, PyTorch can calculate the gradients.
[00:34:47.700 --> 00:34:49.420]   You don't need to worry about being
[00:34:49.420 --> 00:34:51.140]   able to calculate the gradients.
[00:34:56.500 --> 00:35:00.540]   So that's the basics about being able to calculate
[00:35:00.540 --> 00:35:04.140]   the gradients and using PyTorch.
[00:35:04.140 --> 00:35:07.380]   Now we move to our next thing that we need to know
[00:35:07.380 --> 00:35:10.420]   is stepping with a learning rate.
[00:35:10.420 --> 00:35:11.020]   One second.
[00:35:11.020 --> 00:35:21.460]   Sorry, one sec.
[00:35:21.460 --> 00:35:25.100]   I've just got a technical thing I need to solve.
[00:35:26.100 --> 00:35:28.980]   OK, all good.
[00:35:28.980 --> 00:35:31.460]   So then the next thing that we need to be able to look at
[00:35:31.460 --> 00:35:34.820]   is what is a learning rate?
[00:35:34.820 --> 00:35:38.100]   So far, what I've told you is that calculating the gradients
[00:35:38.100 --> 00:35:40.820]   will tell you the direction that we need to go
[00:35:40.820 --> 00:35:42.980]   to be able to reduce the loss.
[00:35:42.980 --> 00:35:45.580]   So when we calculate the slope at some point--
[00:35:45.580 --> 00:35:47.580]   so going back to the figure--
[00:35:47.580 --> 00:35:51.060]   if I started at this point here, then the slope
[00:35:51.060 --> 00:35:53.980]   tells me that the direction of the loss
[00:35:53.980 --> 00:35:56.260]   towards the minimum is in that side, which
[00:35:56.260 --> 00:35:58.620]   means that I need to update my value from here.
[00:35:58.620 --> 00:36:02.940]   And I need to go on the right towards the value 0, as we saw.
[00:36:02.940 --> 00:36:05.660]   So this slope is just telling me the direction.
[00:36:05.660 --> 00:36:08.340]   It's not telling me what is the magnitude,
[00:36:08.340 --> 00:36:11.180]   like how big should my step be.
[00:36:11.180 --> 00:36:13.780]   So I know that I need to update my parameter
[00:36:13.780 --> 00:36:15.580]   towards the right side direction.
[00:36:15.580 --> 00:36:17.860]   But I don't know-- like how far do I need to go?
[00:36:17.860 --> 00:36:19.700]   Do I go from here all the way to here?
[00:36:19.700 --> 00:36:23.860]   Or do I go from here just till this point, small point b?
[00:36:23.860 --> 00:36:24.860]   Or this point c?
[00:36:24.860 --> 00:36:26.580]   Or do I need to go all the way to point d?
[00:36:26.580 --> 00:36:30.620]   So that's something that the learning rate will tell us.
[00:36:30.620 --> 00:36:37.860]   So going back to the learning rate,
[00:36:37.860 --> 00:36:39.940]   as I said, in stochastic gradient descent,
[00:36:39.940 --> 00:36:41.940]   then when you calculate the gradients,
[00:36:41.940 --> 00:36:43.820]   you update the weights.
[00:36:43.820 --> 00:36:45.820]   And how do you update those weights?
[00:36:45.820 --> 00:36:49.140]   You just say that my weights are weights minus
[00:36:49.140 --> 00:36:51.460]   equal to gradient w star lr.
[00:36:51.460 --> 00:36:54.500]   So if I am to write that, then that's
[00:36:54.500 --> 00:36:56.940]   just that my updated weight--
[00:36:56.940 --> 00:36:59.460]   I'm going to call it w dash--
[00:36:59.460 --> 00:37:04.980]   is equal to the initial weight w minus learning rate
[00:37:04.980 --> 00:37:09.060]   star the gradient of w.
[00:37:09.060 --> 00:37:13.660]   And as I've already said, you can calculate this gradient
[00:37:13.660 --> 00:37:16.540]   using PyTorch, TensorFlow, or any library.
[00:37:16.540 --> 00:37:20.220]   Basically, libraries can calculate the gradients for you.
[00:37:20.220 --> 00:37:22.940]   So this lr refers to the learning rate.
[00:37:22.940 --> 00:37:30.860]   So what I'm saying is I want my updated weight.
[00:37:30.860 --> 00:37:34.980]   It's my initial weight minus lr star grad.
[00:37:34.980 --> 00:37:39.660]   So gradient times lr is the amount by which we move.
[00:37:39.660 --> 00:37:41.300]   So until now, I knew the direction
[00:37:41.300 --> 00:37:42.580]   in which I need to go.
[00:37:42.580 --> 00:37:47.740]   Now the learning rate is telling us the amount by which to move.
[00:37:47.740 --> 00:37:50.340]   Something I wanted to share, if you
[00:37:50.340 --> 00:37:52.060]   want to run experiments as part of this
[00:37:52.060 --> 00:37:55.780]   and you want to write blogs for your next week or for this week,
[00:37:55.780 --> 00:37:59.420]   try removing the lr from this equation.
[00:37:59.420 --> 00:38:02.100]   And an experiment here could be to remove lr
[00:38:02.100 --> 00:38:03.380]   and see what happens.
[00:38:03.380 --> 00:38:06.580]   So see how the stochastic gradient descent
[00:38:06.580 --> 00:38:10.180]   would behave if you just remove this learning rate parameter.
[00:38:10.180 --> 00:38:12.340]   I think that will really help anybody
[00:38:12.340 --> 00:38:14.740]   who's doing this experiment to then understand
[00:38:14.740 --> 00:38:16.740]   the importance of lr.
[00:38:16.740 --> 00:38:19.100]   But for now, let's just understand
[00:38:19.100 --> 00:38:24.740]   that lr is just telling me how far my step needs to be.
[00:38:24.740 --> 00:38:28.260]   So if lr-- but I need to be careful with this lr.
[00:38:28.260 --> 00:38:30.300]   I need to be careful with this learning rate.
[00:38:30.300 --> 00:38:32.140]   So if my learning rate is really slow--
[00:38:32.140 --> 00:38:34.140]   so let's say this is where I started.
[00:38:34.140 --> 00:38:37.180]   This was my random initialization.
[00:38:37.180 --> 00:38:40.060]   So I'm just going to call it random init.
[00:38:40.060 --> 00:38:43.900]   So this is my point A is where I started.
[00:38:43.900 --> 00:38:46.740]   Now I already know that I need to make
[00:38:46.740 --> 00:38:49.060]   a step in this direction.
[00:38:49.060 --> 00:38:53.660]   If my learning rate is really small or it's really low,
[00:38:53.660 --> 00:38:56.580]   then I will only make a tiny step.
[00:38:56.580 --> 00:39:00.500]   So the tiny step will take me from here, point A to point B
[00:39:00.500 --> 00:39:01.900]   on the loss curve.
[00:39:01.900 --> 00:39:05.140]   And then I will make another tiny step to point C,
[00:39:05.140 --> 00:39:08.860]   another tiny step to point D, another tiny step to point E,
[00:39:08.860 --> 00:39:10.060]   and so on.
[00:39:10.060 --> 00:39:12.940]   So you see how I need to make so many tiny steps
[00:39:12.940 --> 00:39:18.420]   to reach the lowest point on the loss curve.
[00:39:18.420 --> 00:39:21.380]   The problem with this is you're wasting computation
[00:39:21.380 --> 00:39:23.700]   or it's going to take you very long.
[00:39:23.700 --> 00:39:27.900]   You have to-- if ideally it would take you 10 iterations,
[00:39:27.900 --> 00:39:30.220]   then because your learning rate is so slow,
[00:39:30.220 --> 00:39:32.900]   you would have to do 1,000 iterations to then reach
[00:39:32.900 --> 00:39:36.140]   the lowest point on the loss curve.
[00:39:36.140 --> 00:39:39.500]   So you can't have your learning rate be very low.
[00:39:39.500 --> 00:39:42.660]   You also can't have your learning rate be too high.
[00:39:42.660 --> 00:39:44.300]   If the learning rate is too high,
[00:39:44.300 --> 00:39:49.420]   and let's say I started at this point,
[00:39:49.420 --> 00:39:52.900]   I already know that I need to make a step in this direction.
[00:39:52.900 --> 00:39:54.580]   But if my learning rate is too high
[00:39:54.580 --> 00:39:58.260]   and I made a too big a step, and instead of going from point A,
[00:39:58.260 --> 00:40:01.300]   I went to point B, then on the loss curve,
[00:40:01.300 --> 00:40:03.500]   I've made my loss bigger.
[00:40:03.500 --> 00:40:06.580]   So if my loss had a lower value, this is my lower value,
[00:40:06.580 --> 00:40:08.420]   now my loss has a bigger value.
[00:40:08.420 --> 00:40:10.300]   And then if I make a bigger jump again,
[00:40:10.300 --> 00:40:13.940]   then I've landed at this point and my loss is again higher.
[00:40:13.940 --> 00:40:16.580]   And then I make a bigger jump again to point D
[00:40:16.580 --> 00:40:17.860]   and my loss is again higher.
[00:40:17.860 --> 00:40:20.860]   So you can't have the learning rate be too high either,
[00:40:20.860 --> 00:40:23.780]   because then your loss is just going to go bigger and bigger
[00:40:23.780 --> 00:40:25.780]   and bigger.
[00:40:25.780 --> 00:40:28.300]   Or your loss is going to bounce around.
[00:40:28.300 --> 00:40:31.300]   So if you started at point A, ideally what you want to do
[00:40:31.300 --> 00:40:33.980]   is you want to go to this point B, then this point C,
[00:40:33.980 --> 00:40:35.900]   and then finally this point D. So you'd
[00:40:35.900 --> 00:40:37.740]   reach the lowest point on the loss curve.
[00:40:37.740 --> 00:40:39.380]   But if your learning rate is too high,
[00:40:39.380 --> 00:40:41.780]   you start at this point, then you go to this point,
[00:40:41.780 --> 00:40:43.500]   then you go to this point, then here.
[00:40:43.500 --> 00:40:45.420]   So all you're doing is you're jumping around
[00:40:45.420 --> 00:40:47.740]   in the loss curve and you never reach the bottom.
[00:40:47.740 --> 00:40:49.540]   Because to reach the bottom then,
[00:40:49.540 --> 00:40:52.620]   you need to have perfect size steps.
[00:40:52.620 --> 00:40:54.820]   So you see how learning rate is a really, really
[00:40:54.820 --> 00:40:57.980]   crucial parameter.
[00:40:57.980 --> 00:41:00.100]   And in Fast.ai, there's something
[00:41:00.100 --> 00:41:01.540]   called the learning rate finder.
[00:41:01.540 --> 00:41:04.660]   I shouldn't have said it, but I will say it still.
[00:41:04.660 --> 00:41:07.620]   As we go forward, you will see a learning rate finder example.
[00:41:07.620 --> 00:41:11.220]   And we will look at that when we look at the Pets chapter next.
[00:41:11.220 --> 00:41:14.100]   But basically what this learning rate finder tells you
[00:41:14.100 --> 00:41:16.100]   is it tells you a good learning rate
[00:41:16.100 --> 00:41:17.740]   or how big your steps should be.
[00:41:17.740 --> 00:41:19.900]   It gives you some intuition.
[00:41:19.900 --> 00:41:22.660]   Or it gives you some idea on what the steps should be.
[00:41:22.660 --> 00:41:25.460]   But the steps that you have to make
[00:41:25.460 --> 00:41:27.620]   towards the lowest point on the loss curve,
[00:41:27.620 --> 00:41:30.940]   they can't be too high or they can't be too small.
[00:41:30.940 --> 00:41:33.340]   That's the basic main thing that you
[00:41:33.340 --> 00:41:37.060]   should know from this example.
[00:41:37.060 --> 00:41:40.700]   OK, so now we're ready to look at an end-to-end SGD example.
[00:41:40.700 --> 00:41:54.380]   So we are now ready to look at the end-to-end SGD example.
[00:41:54.380 --> 00:41:55.500]   So here it is.
[00:41:55.500 --> 00:41:58.860]   So just to recap, my SGD looks like this.
[00:41:58.860 --> 00:42:00.300]   I start with some initialization.
[00:42:00.300 --> 00:42:01.140]   I make predictions.
[00:42:01.140 --> 00:42:02.460]   I calculate the loss.
[00:42:02.460 --> 00:42:05.580]   I calculate the gradients on the loss
[00:42:05.580 --> 00:42:06.900]   with respect to the parameters.
[00:42:06.900 --> 00:42:08.180]   And then I take the step.
[00:42:08.180 --> 00:42:10.140]   This step depends on this parameter
[00:42:10.140 --> 00:42:11.660]   called learning rate.
[00:42:11.660 --> 00:42:13.140]   If the learning rate is too high,
[00:42:13.140 --> 00:42:14.460]   then I've made the wrong step.
[00:42:14.460 --> 00:42:16.140]   If the learning rate is too small,
[00:42:16.140 --> 00:42:17.740]   then I'll have to make many steps
[00:42:17.740 --> 00:42:19.260]   to be able to minimize the loss.
[00:42:19.260 --> 00:42:21.660]   And then once finally I've reached the lowest point
[00:42:21.660 --> 00:42:23.500]   on the loss curve, then I stop.
[00:42:23.500 --> 00:42:25.460]   So that's my stochastic gradient descent.
[00:42:25.460 --> 00:42:35.780]   OK, so now we're looking at an end-to-end example on SGD.
[00:42:35.780 --> 00:42:37.820]   So let's say my time--
[00:42:37.820 --> 00:42:40.740]   let's say I only have some numbers from 0 to 19,
[00:42:40.740 --> 00:42:42.140]   and I refer to that as time.
[00:42:42.140 --> 00:42:44.540]   These could be 20 seconds, the first 20 seconds.
[00:42:44.540 --> 00:42:47.300]   So let's say that's time.
[00:42:47.300 --> 00:42:52.260]   And let's have speed as some value of this time.
[00:42:52.260 --> 00:42:54.820]   So if I plot them, this just tells me
[00:42:54.820 --> 00:42:59.940]   that at time, 10th second, my speed was somewhere around 5
[00:42:59.940 --> 00:43:00.740]   or at the bottom.
[00:43:00.740 --> 00:43:04.220]   But this is just the curve that we have to fit.
[00:43:04.220 --> 00:43:07.220]   Like, we want to train a model that can then predict this time
[00:43:07.220 --> 00:43:10.140]   and speed curve.
[00:43:10.140 --> 00:43:12.740]   Now, in SGD--
[00:43:12.740 --> 00:43:15.420]   or forget SGD, let's just say that my model only
[00:43:15.420 --> 00:43:16.820]   has three parameters.
[00:43:16.820 --> 00:43:18.740]   So the three parameters that my model has--
[00:43:18.740 --> 00:43:21.900]   I'll zoom in a little bit just to--
[00:43:21.900 --> 00:43:23.780]   just let me know if this is too zoomed out.
[00:43:23.780 --> 00:43:28.060]   But I'll try and zoom in a little bit, one second.
[00:43:28.060 --> 00:43:29.220]   Let's start this.
[00:43:29.220 --> 00:43:30.660]   I hope this is better.
[00:43:30.660 --> 00:43:33.660]   So let's say now my model has only three parameters--
[00:43:33.660 --> 00:43:36.340]   a, b, and c.
[00:43:36.340 --> 00:43:40.900]   Then I can define my model as being at squared plus bd plus c.
[00:43:40.900 --> 00:43:43.500]   Basically, it's just a quadratic equation.
[00:43:43.500 --> 00:43:45.380]   But let's say this is what my model is.
[00:43:45.380 --> 00:43:47.060]   It only has three parameters.
[00:43:47.060 --> 00:43:50.700]   And the model function-- remember, from deep learning,
[00:43:50.700 --> 00:43:53.740]   you already know that a model is not something magical.
[00:43:53.740 --> 00:43:55.740]   It's just a function.
[00:43:55.740 --> 00:43:59.300]   And let's say right now my model is just this function, f,
[00:43:59.300 --> 00:44:03.100]   that looks like at squared plus bd plus c.
[00:44:03.100 --> 00:44:06.460]   Then I need to be able to calculate the loss.
[00:44:06.460 --> 00:44:09.260]   So if I have some inputs and I can pass those inputs
[00:44:09.260 --> 00:44:12.260]   to this function, f, I will get some predictions.
[00:44:12.260 --> 00:44:14.780]   But I need to be able to calculate the loss.
[00:44:14.780 --> 00:44:18.820]   Let's say I'm using a loss as MSC, or the mean square error.
[00:44:18.820 --> 00:44:20.580]   Without telling you what it is, let's just
[00:44:20.580 --> 00:44:23.020]   say this is what the mean square error looks like.
[00:44:23.020 --> 00:44:25.740]   And that's just my loss function,
[00:44:25.740 --> 00:44:27.220]   without going into the details.
[00:44:27.220 --> 00:44:29.500]   But for now, just to get the basic idea
[00:44:29.500 --> 00:44:34.220]   and just now to get the basic understanding of STD
[00:44:34.220 --> 00:44:35.860]   from the viewpoint of a code.
[00:44:35.860 --> 00:44:38.820]   So because my parameters were three numbers,
[00:44:38.820 --> 00:44:40.300]   I can initialize them.
[00:44:40.300 --> 00:44:43.020]   I can say-- so torch.random, these
[00:44:43.020 --> 00:44:44.680]   are things you should-- when you go back
[00:44:44.680 --> 00:44:47.020]   and you're looking at this clean version of the notebook,
[00:44:47.020 --> 00:44:51.460]   just create new cells and type this, OK?
[00:44:51.460 --> 00:44:52.620]   And see what that does.
[00:44:52.620 --> 00:44:54.660]   So every time I press this, it's just returning
[00:44:54.660 --> 00:44:56.100]   three random parameters.
[00:44:56.100 --> 00:44:58.820]   If you want to check the documentation of this,
[00:44:58.820 --> 00:45:02.300]   you can press question mark at the bottom.
[00:45:02.300 --> 00:45:04.620]   That will bring up the documentation like this.
[00:45:04.620 --> 00:45:06.380]   Or if you want to look at the source code,
[00:45:06.380 --> 00:45:09.660]   you can press double question mark, which will bring up the--
[00:45:09.660 --> 00:45:13.860]   basically, then it will bring up the code as well.
[00:45:13.860 --> 00:45:15.300]   So let's say then-- so as I said,
[00:45:15.300 --> 00:45:17.180]   my parameters are just three numbers.
[00:45:17.180 --> 00:45:18.940]   So the first step in STD was to be
[00:45:18.940 --> 00:45:21.980]   able to initialize my parameters with some random values.
[00:45:21.980 --> 00:45:25.260]   And I say requires grad, because what we want to do
[00:45:25.260 --> 00:45:27.460]   is we want to update these parameters based
[00:45:27.460 --> 00:45:28.820]   on the gradients, right?
[00:45:28.820 --> 00:45:30.580]   Because these are the model weights.
[00:45:30.580 --> 00:45:32.460]   What we want to do is we want to update these model
[00:45:32.460 --> 00:45:33.820]   weights based on the gradients.
[00:45:33.820 --> 00:45:35.900]   So we have the perfect model weights
[00:45:35.900 --> 00:45:38.060]   so that the model performance is high.
[00:45:38.060 --> 00:45:40.300]   So that's what this step is doing.
[00:45:40.300 --> 00:45:43.300]   It's just initializing parameters.
[00:45:43.300 --> 00:45:46.820]   Step two is I want to be able to calculate the predictions.
[00:45:46.820 --> 00:45:48.900]   So I can pass in to that function.
[00:45:48.900 --> 00:45:51.500]   I can pass in those values of time.
[00:45:51.500 --> 00:45:54.100]   And I can pass in the value of the parameters.
[00:45:54.100 --> 00:45:56.820]   So remember, from deep learning images
[00:45:56.820 --> 00:45:59.420]   that we've seen before, a model gets two things.
[00:45:59.420 --> 00:46:01.660]   It gets some input, and it has some weights.
[00:46:01.660 --> 00:46:04.540]   So these parameters are the weights.
[00:46:04.540 --> 00:46:07.140]   So I can get my predictions, and the predictions
[00:46:07.140 --> 00:46:08.660]   look something like this.
[00:46:08.660 --> 00:46:10.860]   It has a gradient function, OK?
[00:46:10.860 --> 00:46:13.100]   This is just telling PyTorch that I
[00:46:13.100 --> 00:46:17.620]   need to be able to calculate the gradients.
[00:46:17.620 --> 00:46:20.340]   So now I can plot my predictions.
[00:46:20.340 --> 00:46:24.180]   So the blue is the actual line of the time versus speed.
[00:46:24.180 --> 00:46:27.460]   The red is what this prediction looks like.
[00:46:27.460 --> 00:46:30.060]   The third thing that I can do is I can calculate my loss.
[00:46:30.060 --> 00:46:32.260]   So I can pass in my predictions, and I
[00:46:32.260 --> 00:46:35.940]   can calculate the actual values of speed, which go in here.
[00:46:35.940 --> 00:46:37.500]   And I can calculate my loss.
[00:46:37.500 --> 00:46:39.580]   So see how loss is a random number,
[00:46:39.580 --> 00:46:41.780]   and it has a gradient function, OK?
[00:46:41.780 --> 00:46:45.300]   So when I say loss.backward in the next step,
[00:46:45.300 --> 00:46:50.460]   then the parameters get an attribute called grad,
[00:46:50.460 --> 00:46:52.220]   and the grad has some values.
[00:46:52.220 --> 00:46:55.140]   So now each parameter has the value of the gradient.
[00:46:55.140 --> 00:47:00.740]   So this gradient is just telling us,
[00:47:00.740 --> 00:47:02.580]   from everything that we've learned so far,
[00:47:02.580 --> 00:47:04.300]   by calculating the gradients, we know
[00:47:04.300 --> 00:47:06.580]   which direction we have to go.
[00:47:06.580 --> 00:47:09.180]   The next step that we have to do is we have to take a step
[00:47:09.180 --> 00:47:10.780]   in that direction, right?
[00:47:10.780 --> 00:47:12.740]   So when we take a step in that direction,
[00:47:12.740 --> 00:47:15.700]   that stepping in that direction, given my learning rate,
[00:47:15.700 --> 00:47:17.620]   is some value 1 e neg 3.
[00:47:17.620 --> 00:47:21.500]   That's just 0.001.
[00:47:21.500 --> 00:47:23.780]   So let's say my learning rate is that value.
[00:47:23.780 --> 00:47:26.020]   Then I can take a step in that direction.
[00:47:26.020 --> 00:47:28.140]   Remember how the step in the direction looks like?
[00:47:28.140 --> 00:47:29.980]   It was w.
[00:47:29.980 --> 00:47:33.380]   Trying to find that stepping in that direction in my notes,
[00:47:33.380 --> 00:47:34.460]   so I can refer to that.
[00:47:34.460 --> 00:47:37.380]   One second.
[00:47:37.380 --> 00:47:38.100]   Where is it?
[00:47:38.100 --> 00:47:42.740]   Somewhere at the top, maybe.
[00:47:42.740 --> 00:47:50.500]   Can't find it.
[00:47:50.500 --> 00:47:51.900]   All I'm trying to do is I'm trying
[00:47:51.900 --> 00:47:56.020]   to show the stepping on the formula for that stepping is.
[00:47:56.020 --> 00:47:57.220]   So let me see if that was--
[00:47:57.220 --> 00:48:05.220]   I think it was somewhere lower, somewhere at the bottom.
[00:48:05.220 --> 00:48:10.660]   There it is.
[00:48:10.660 --> 00:48:12.020]   So when you were taking the step,
[00:48:12.020 --> 00:48:13.420]   that's what the step looked like.
[00:48:13.420 --> 00:48:16.980]   My updated weights are--
[00:48:16.980 --> 00:48:19.460]   if you remember, my updated weights are this value.
[00:48:19.460 --> 00:48:22.740]   w minus LR star grad of w.
[00:48:22.740 --> 00:48:24.300]   So this is what it looks like.
[00:48:24.300 --> 00:48:27.900]   My updated weights are my initial weights.
[00:48:27.900 --> 00:48:29.580]   I can just say minus equal to.
[00:48:29.580 --> 00:48:33.580]   So my initial weights minus LR times the gradient.
[00:48:33.580 --> 00:48:35.060]   So this is just STD.
[00:48:35.060 --> 00:48:37.700]   And now we're updating the parameter weights.
[00:48:37.700 --> 00:48:39.300]   So let's do that.
[00:48:39.300 --> 00:48:41.180]   And then we get the predictions again.
[00:48:41.180 --> 00:48:43.220]   And we can calculate the loss.
[00:48:43.220 --> 00:48:46.540]   So see how the loss this time is 343.
[00:48:46.540 --> 00:48:49.260]   And the loss previously was 371.
[00:48:49.260 --> 00:48:50.980]   So just by taking one step, we've
[00:48:50.980 --> 00:48:52.300]   been able to reduce the loss.
[00:48:52.300 --> 00:48:55.740]   So if my loss was a curve that was an upward-looking parabola,
[00:48:55.740 --> 00:48:59.300]   I've made a step in the direction that reduces the loss.
[00:48:59.300 --> 00:49:07.700]   So I can now show my predictions.
[00:49:07.700 --> 00:49:09.740]   It's still bad, but it's just one step.
[00:49:09.740 --> 00:49:11.300]   We've only taken one step.
[00:49:11.300 --> 00:49:14.060]   So now I can make all of this as a function.
[00:49:14.060 --> 00:49:16.580]   Basically, we get the predictions.
[00:49:16.580 --> 00:49:18.140]   We calculate the loss.
[00:49:18.140 --> 00:49:20.700]   We say loss.backward to Python--
[00:49:20.700 --> 00:49:21.780]   or sorry, to PyTorch.
[00:49:21.780 --> 00:49:24.300]   In that way, it can calculate the gradients.
[00:49:24.300 --> 00:49:27.380]   So when it has the gradients, I can now update my parameters.
[00:49:27.380 --> 00:49:30.860]   And I can say they are minus equal to LR times gradients.
[00:49:30.860 --> 00:49:33.940]   And then you just print the loss.
[00:49:33.940 --> 00:49:35.820]   So if I do this 20 times--
[00:49:35.820 --> 00:49:37.180]   let's do it 20 times--
[00:49:37.180 --> 00:49:40.220]   see how I started with a loss value that was 343?
[00:49:40.220 --> 00:49:43.940]   I've ended up with a loss value that's 26.
[00:49:43.940 --> 00:49:45.540]   So let's plot that.
[00:49:45.540 --> 00:49:48.820]   So right now, this still doesn't look really good.
[00:49:48.820 --> 00:49:50.220]   So let's do it 20 more times.
[00:49:50.220 --> 00:49:56.180]   And now you can see how my red, which is the predictions,
[00:49:56.180 --> 00:50:00.860]   it's trying to match the exact values of the time versus
[00:50:00.860 --> 00:50:01.500]   speed.
[00:50:01.500 --> 00:50:02.740]   So this is--
[00:50:02.740 --> 00:50:05.300]   I hope that by doing this, now we can stop.
[00:50:05.300 --> 00:50:09.180]   Because we can stop now, because now the loss is at a low value.
[00:50:09.180 --> 00:50:12.700]   And now we know that the predictions are looking good.
[00:50:12.700 --> 00:50:16.940]   And the predictions are finally--
[00:50:16.940 --> 00:50:18.260]   they're matching my expectation.
[00:50:18.260 --> 00:50:19.820]   And the model performance is high.
[00:50:19.820 --> 00:50:23.500]   So this is the overall process of stochastic gradient descent.
[00:50:23.500 --> 00:50:26.260]   And I've just shown you how it looks like in code.
[00:50:26.260 --> 00:50:27.940]   So when you go back, something--
[00:50:27.940 --> 00:50:29.340]   when you're going back and you're
[00:50:29.340 --> 00:50:31.660]   looking at this clean version of the notebook,
[00:50:31.660 --> 00:50:34.460]   make sure then in your head that you're
[00:50:34.460 --> 00:50:38.060]   able to match all those steps to--
[00:50:38.060 --> 00:50:40.340]   I'm trying to find the stochastic gradient descent
[00:50:40.340 --> 00:50:40.860]   image.
[00:50:41.860 --> 00:50:42.380]   Yes.
[00:50:42.380 --> 00:50:45.460]   Make sure that you're able to match all those steps
[00:50:45.460 --> 00:50:49.180]   that we've just had a look at over here.
[00:50:49.180 --> 00:50:51.460]   So these steps of--
[00:50:51.460 --> 00:50:58.460]   so this step one of initializing the parameters,
[00:50:58.460 --> 00:51:00.540]   calculating the predictions, calculating the loss,
[00:51:00.540 --> 00:51:03.260]   calculating the gradients, making a step on the weights,
[00:51:03.260 --> 00:51:04.660]   and then repeating the process.
[00:51:04.660 --> 00:51:08.260]   So make sure that you're able to have a look at these six
[00:51:08.260 --> 00:51:08.780]   steps.
[00:51:08.780 --> 00:51:10.820]   And you're able to match them to what
[00:51:10.820 --> 00:51:15.700]   we saw with stochastic gradient descent when we first started.
[00:51:15.700 --> 00:51:17.900]   So that's stochastic gradient descent.
[00:51:17.900 --> 00:51:18.780]   Any questions?
[00:51:18.780 --> 00:51:21.700]   I'll take two minutes for questions
[00:51:21.700 --> 00:51:23.140]   on stochastic gradient descent.
[00:51:23.140 --> 00:51:25.580]   And then after this, what we will do
[00:51:25.580 --> 00:51:27.540]   is we'll use stochastic gradient descent
[00:51:27.540 --> 00:51:29.820]   to calculate our MNIST classifier.
[00:51:29.820 --> 00:51:32.940]   So until now, we've only created a classifier
[00:51:32.940 --> 00:51:34.500]   based on some rule.
[00:51:34.500 --> 00:51:35.780]   But we didn't do any training.
[00:51:35.780 --> 00:51:37.780]   But now we can use stochastic gradient descent.
[00:51:37.780 --> 00:51:40.180]   But now we can use stochastic gradient descent
[00:51:40.180 --> 00:51:44.820]   to classify 3s from 7s.
[00:51:44.820 --> 00:51:46.780]   So let's see if there's more questions.
[00:51:46.780 --> 00:51:55.820]   If learning rate is too high, can we
[00:51:55.820 --> 00:51:57.860]   detect that in training and repeat the last step
[00:51:57.860 --> 00:52:00.900]   with a smaller LR?
[00:52:00.900 --> 00:52:02.820]   OK, so if learning rate is too high
[00:52:02.820 --> 00:52:05.380]   and you've already made a step, then your parameters
[00:52:05.380 --> 00:52:07.260]   are already at a bad value.
[00:52:07.260 --> 00:52:09.220]   You will have to, unfortunately, unless you
[00:52:09.220 --> 00:52:12.100]   have the last epoch's weights or unless you
[00:52:12.100 --> 00:52:14.700]   have the last weights, you will have to restart training.
[00:52:14.700 --> 00:52:16.940]   But you can definitely detect that because your loss
[00:52:16.940 --> 00:52:18.220]   is going to diverge.
[00:52:18.220 --> 00:52:19.820]   So if your loss in the first epoch
[00:52:19.820 --> 00:52:21.660]   was, let's say, some number 4, then
[00:52:21.660 --> 00:52:23.100]   if your learning rate is too high,
[00:52:23.100 --> 00:52:25.420]   it's going to go to that number either 6,
[00:52:25.420 --> 00:52:27.500]   or it's going to be like 4.5, or it's just
[00:52:27.500 --> 00:52:28.940]   going to continue bouncing around.
[00:52:28.940 --> 00:52:32.260]   So if you see over time, over multiple epochs,
[00:52:32.260 --> 00:52:34.340]   your loss isn't decreasing.
[00:52:34.340 --> 00:52:36.740]   And your loss is basically increasing
[00:52:36.740 --> 00:52:37.580]   or it's diverging.
[00:52:37.580 --> 00:52:39.740]   That's when you know the learning rate is too high.
[00:52:39.740 --> 00:52:42.580]   But as we train more and more models--
[00:52:42.580 --> 00:52:46.620]   so right now, it's just giving us the basics of MNIST,
[00:52:46.620 --> 00:52:50.340]   or doing image classifier, digit classifier.
[00:52:50.340 --> 00:52:53.340]   In the next chapters, as we go more and more deeper
[00:52:53.340 --> 00:52:56.700]   into computer vision, we will train more and more models.
[00:52:56.700 --> 00:52:58.500]   And then as we train more and more models,
[00:52:58.500 --> 00:53:00.140]   all of these things will become clear.
[00:53:00.140 --> 00:53:04.060]   We'll get more intuition about how things look like.
[00:53:04.060 --> 00:53:07.020]   Can we keep changing the learning rate?
[00:53:07.020 --> 00:53:09.580]   It looks like a good idea to have a larger learning
[00:53:09.580 --> 00:53:10.700]   rate in the beginning.
[00:53:10.700 --> 00:53:12.220]   But as we get closer to the minimum,
[00:53:12.220 --> 00:53:14.140]   we use a smaller learning rate so that we
[00:53:14.140 --> 00:53:15.500]   don't overshoot the minimum.
[00:53:15.500 --> 00:53:18.980]   Ravi, you're 100% right, and you've caught the pulse of it.
[00:53:18.980 --> 00:53:22.060]   But 100%, it definitely makes sense
[00:53:22.060 --> 00:53:25.540]   to have a bigger learning rate at the beginning,
[00:53:25.540 --> 00:53:26.940]   and then a smaller learning rate.
[00:53:26.940 --> 00:53:30.380]   Or there's different-- what are you referring to,
[00:53:30.380 --> 00:53:32.860]   of being able to update the learning rate as we
[00:53:32.860 --> 00:53:35.900]   go through different epochs, is referred to as learning rate
[00:53:35.900 --> 00:53:36.700]   scheduling.
[00:53:36.700 --> 00:53:38.540]   And there's multiple schedulers.
[00:53:38.540 --> 00:53:41.380]   So if you search learning rate scheduling,
[00:53:41.380 --> 00:53:46.220]   it's learning rate schedulers, PyTorch.
[00:53:46.220 --> 00:53:48.820]   This will bring a big list of--
[00:53:48.820 --> 00:53:50.180]   it will take you to Torch.optimum,
[00:53:50.180 --> 00:53:53.100]   and it will bring you a big list of the different scheduling
[00:53:53.100 --> 00:53:54.140]   that you can do.
[00:53:54.140 --> 00:53:56.460]   This is definitely a good idea.
[00:53:56.460 --> 00:53:58.540]   Question two, I mean, what extensions do you have
[00:53:58.540 --> 00:53:59.140]   for notebooks?
[00:53:59.140 --> 00:54:01.060]   I'll cover this later.
[00:54:01.060 --> 00:54:02.940]   But I will come back to this, Sanyam.
[00:54:02.940 --> 00:54:08.700]   In FastAI LRFinder, we usually have a minimum and maximum
[00:54:08.700 --> 00:54:09.220]   learning rate.
[00:54:09.220 --> 00:54:11.420]   What is the ideal learning rate to choose from it?
[00:54:11.420 --> 00:54:14.620]   We will get to this question when we get to the FastAI LRFinder.
[00:54:14.620 --> 00:54:18.220]   I'm going to skip on this for now.
[00:54:18.220 --> 00:54:20.780]   Hi, the loss after 20 iterations and the total loss
[00:54:20.780 --> 00:54:22.820]   after foot research is closer values,
[00:54:22.820 --> 00:54:25.100]   and yet the model is performing much better.
[00:54:25.100 --> 00:54:26.100]   Can you explain how?
[00:54:26.100 --> 00:54:26.740]   Thanks, Rahul.
[00:54:26.740 --> 00:54:29.820]   I think it's-- yes, the loss is much better.
[00:54:29.820 --> 00:54:33.820]   And I think what you're referring to is the stepping.
[00:54:33.820 --> 00:54:39.140]   So when we started after 20 steps, the loss was 26.
[00:54:39.140 --> 00:54:40.380]   And when we started after--
[00:54:40.380 --> 00:54:44.940]   so it's basically the same thing.
[00:54:44.940 --> 00:54:46.380]   Like, I've still done--
[00:54:46.380 --> 00:54:49.180]   what I've done is I've done the mistake of plotting--
[00:54:49.180 --> 00:54:51.540]   when I did the show preds the first time,
[00:54:51.540 --> 00:54:54.860]   it wasn't actually showing the predictions for this lower loss.
[00:54:54.860 --> 00:54:57.340]   So it's just a mistake on my part.
[00:54:57.340 --> 00:54:59.700]   If you delete this and you run this notebook on your own,
[00:54:59.700 --> 00:55:02.660]   you will see that you don't have to run it after--
[00:55:02.660 --> 00:55:03.860]   for 20 steps again.
[00:55:03.860 --> 00:55:07.700]   So I've just made a mistake in that little section
[00:55:07.700 --> 00:55:08.940]   of the code.
[00:55:08.940 --> 00:55:09.940]   But you can ignore that.
[00:55:09.940 --> 00:55:11.900]   You're 100% right in catching it,
[00:55:11.900 --> 00:55:14.740]   but it's a mistake on my part.
[00:55:14.740 --> 00:55:16.340]   How to decide that the loss is minimum
[00:55:16.340 --> 00:55:17.780]   and it will not go below this?
[00:55:17.780 --> 00:55:21.820]   There's no good way to decide that the loss is minimum.
[00:55:21.820 --> 00:55:25.100]   But basically, if you do multiple epochs
[00:55:25.100 --> 00:55:29.220]   and your loss is continuing to decrease,
[00:55:29.220 --> 00:55:30.140]   you keep doing that.
[00:55:30.140 --> 00:55:31.860]   So if your loss is still decreasing,
[00:55:31.860 --> 00:55:35.940]   which means you still haven't reached the bottom
[00:55:35.940 --> 00:55:38.100]   part of the loss curve--
[00:55:38.100 --> 00:55:40.340]   so say if you're somewhere here and your loss is still
[00:55:40.340 --> 00:55:41.900]   decreasing and you get to this point
[00:55:41.900 --> 00:55:43.780]   and your loss is still decreasing.
[00:55:43.780 --> 00:55:46.780]   So when you're at the lowest point, after that,
[00:55:46.780 --> 00:55:51.180]   the loss will not decrease any further.
[00:55:51.180 --> 00:55:54.020]   So your idea is then, as long as your loss is decreasing,
[00:55:54.020 --> 00:55:55.220]   you keep playing the model.
[00:55:55.220 --> 00:55:57.700]   Unless the loss starts to diverge,
[00:55:57.700 --> 00:55:59.980]   that's when you know that you have to stop training.
[00:55:59.980 --> 00:56:09.300]   That's the basics for SGD and how SGD looks like in code.
[00:56:09.300 --> 00:56:11.220]   So let's move on.
[00:56:11.220 --> 00:56:26.580]   So now let's use SGD to be able to classify my MNIST digit 3
[00:56:26.580 --> 00:56:27.780]   versus digit 7.
[00:56:27.780 --> 00:56:29.860]   So remember, when I had my stacked--
[00:56:29.860 --> 00:56:33.540]   well, my 3 is basically, if I take the first element
[00:56:33.540 --> 00:56:36.260]   from all the 3s that we had--
[00:56:36.260 --> 00:56:38.900]   actually, just to give you a background so far,
[00:56:38.900 --> 00:56:41.460]   now from section 1.7 onwards, we're
[00:56:41.460 --> 00:56:43.420]   just going to apply what we've learned
[00:56:43.420 --> 00:56:45.820]   about stochastic gradient descent.
[00:56:45.820 --> 00:56:47.740]   And we're going to apply that, and we're
[00:56:47.740 --> 00:56:51.580]   going to use it to be able to classify 3s versus 7s.
[00:56:51.580 --> 00:56:54.340]   So if I just take the first element of all the 3s
[00:56:54.340 --> 00:56:56.700]   that I had and I plot it, it looks like that.
[00:56:56.700 --> 00:56:58.460]   And I plot my number 7.
[00:56:58.460 --> 00:57:00.580]   That looks like this.
[00:57:00.580 --> 00:57:02.060]   Then all my 3s--
[00:57:02.060 --> 00:57:04.740]   remember, we've already covered this last week.
[00:57:04.740 --> 00:57:06.380]   I put them in a tensor.
[00:57:06.380 --> 00:57:08.660]   So all my 3s are now stacked.
[00:57:08.660 --> 00:57:12.780]   This stacked 3s is just a tensor that looks like 6131 by 28
[00:57:12.780 --> 00:57:13.660]   by 28.
[00:57:13.660 --> 00:57:14.740]   What does that mean?
[00:57:14.740 --> 00:57:18.660]   I have 6131 images of the number 3.
[00:57:18.660 --> 00:57:22.260]   And each image has a dimension of 28 by 28.
[00:57:22.260 --> 00:57:26.020]   So this is my 28 width, and this is my 28 height.
[00:57:26.020 --> 00:57:27.660]   Same for stacked 7s.
[00:57:27.660 --> 00:57:33.060]   I have 6265 number of 7 images.
[00:57:33.060 --> 00:57:36.060]   And each image has a shape of 28 by 28.
[00:57:36.060 --> 00:57:37.420]   So this is my width.
[00:57:37.420 --> 00:57:40.260]   This is my height.
[00:57:40.260 --> 00:57:46.980]   So then my training variable, I can put them all in one list.
[00:57:46.980 --> 00:57:49.460]   And let's see what I get.
[00:57:49.460 --> 00:57:51.980]   So when you're running back this notebook by yourself,
[00:57:51.980 --> 00:57:54.460]   try doing just this part first.
[00:57:54.460 --> 00:57:58.100]   So if I do this, and I check the shape, all I'm doing
[00:57:58.100 --> 00:58:00.380]   is I had two things.
[00:58:00.380 --> 00:58:02.940]   I had my stacked 3s, and I had my stacked 7s.
[00:58:02.940 --> 00:58:04.940]   I can put them together in one tensor.
[00:58:04.940 --> 00:58:10.380]   So if you add 6131 by 6265, that will give you 12,396 images.
[00:58:10.380 --> 00:58:13.540]   So we have 12,396 images in total.
[00:58:13.540 --> 00:58:18.060]   And each image has a shape of 28 by 28.
[00:58:18.060 --> 00:58:20.460]   In PyTorch, when I call--
[00:58:20.460 --> 00:58:23.180]   excuse me.
[00:58:23.180 --> 00:58:24.060]   Sorry, one second.
[00:58:24.060 --> 00:58:38.700]   Sorry, guys, I'm back.
[00:58:38.700 --> 00:58:40.700]   Just have a bad cough these days.
[00:58:40.700 --> 00:58:46.580]   So when I say .view minus 1, 28 by 28, all I'm saying
[00:58:46.580 --> 00:58:50.580]   is whatever the shape of this is--
[00:58:50.580 --> 00:58:53.580]   so let's see what the shape of this is.
[00:58:53.580 --> 00:59:00.140]   So it is 12,396 by 28 in my second axis
[00:59:00.140 --> 00:59:02.620]   and 28 in my third axis.
[00:59:02.620 --> 00:59:05.780]   All I'm saying is ignore the minus 1 for now.
[00:59:05.780 --> 00:59:09.340]   What I'm saying is you reshape this tensor such
[00:59:09.340 --> 00:59:12.900]   that the last axis has a shape of 28 by 28.
[00:59:12.900 --> 00:59:14.260]   So how is that going to happen?
[00:59:14.260 --> 00:59:17.300]   All it's going to do is it's going to store this 28 by 28
[00:59:17.300 --> 00:59:19.180]   as one vector now.
[00:59:19.180 --> 00:59:22.620]   So if I do that, then my final shape of the train x
[00:59:22.620 --> 00:59:24.580]   looks like 12,396.
[00:59:24.580 --> 00:59:27.660]   But instead of having two x's with width and height,
[00:59:27.660 --> 00:59:29.620]   now it's just a single vector.
[00:59:29.620 --> 00:59:31.940]   So let me show you what that means.
[00:59:31.940 --> 00:59:36.420]   If I look at the 0th element of this,
[00:59:36.420 --> 00:59:40.660]   see how it's still a matrix, OK?
[00:59:40.660 --> 00:59:45.540]   Whereas if I look at the 0th element of the reshaped
[00:59:45.540 --> 00:59:47.620]   version, instead of it being a matrix,
[00:59:47.620 --> 00:59:54.420]   it's now just a long vector of length 784.
[00:59:54.420 --> 00:59:55.760]   So these are things you should be
[00:59:55.760 --> 01:00:00.140]   able to do when you're running these notebooks by yourself.
[01:00:00.140 --> 01:00:04.380]   OK, so now I stacked my 3's as the first part
[01:00:04.380 --> 01:00:06.660]   and then my 7's as the second part, which
[01:00:06.660 --> 01:00:09.540]   means I can have my label.
[01:00:09.540 --> 01:00:12.980]   My 1 would be times length of 3's plus 0 times
[01:00:12.980 --> 01:00:13.940]   length of 7's.
[01:00:13.940 --> 01:00:14.940]   What does that mean?
[01:00:14.940 --> 01:00:21.460]   That I will have 6131 1's in my train y and 6265 0's
[01:00:21.460 --> 01:00:23.780]   in my train y.
[01:00:23.780 --> 01:00:29.180]   So for 12,396, the first 6131 images
[01:00:29.180 --> 01:00:33.540]   are 3's, which means the first 6131
[01:00:33.540 --> 01:00:36.460]   tensors in this train y are value 1.
[01:00:36.460 --> 01:00:41.100]   So let me show you that, train y until 6131.
[01:00:41.100 --> 01:00:42.540]   See how they're all 1?
[01:00:42.540 --> 01:00:45.860]   And then after this, they're all going to be 0's, right?
[01:00:45.860 --> 01:00:47.580]   Because that makes sense, because we just
[01:00:47.580 --> 01:00:53.340]   stacked my 3's and 7's and my first 6131 with 3's.
[01:00:53.340 --> 01:00:56.620]   OK, now we're looking at what is a data set.
[01:00:56.620 --> 01:00:59.220]   In PyTorch, you can just say list and zip,
[01:00:59.220 --> 01:01:03.220]   and you can pass in to basically train x and train y.
[01:01:03.220 --> 01:01:05.260]   When you do this, then your data set
[01:01:05.260 --> 01:01:08.900]   becomes a list, which is zipping through train x and train y.
[01:01:08.900 --> 01:01:14.380]   And when you go and you check the first item of this,
[01:01:14.380 --> 01:01:16.900]   it will return the first item from x,
[01:01:16.900 --> 01:01:19.220]   and it will return the 0th item from y.
[01:01:19.220 --> 01:01:21.660]   So my first item from x looks this long,
[01:01:21.660 --> 01:01:24.660]   which is 784 vector, and my first item from y
[01:01:24.660 --> 01:01:25.340]   looks this long.
[01:01:30.140 --> 01:01:32.260]   So finally, I have my independent
[01:01:32.260 --> 01:01:33.940]   and my dependent variables.
[01:01:33.940 --> 01:01:35.220]   So I can just check the shape.
[01:01:35.220 --> 01:01:42.140]   So my x.shape is 784, which represents the first 3 digit--
[01:01:42.140 --> 01:01:44.020]   so the first image of digit 3.
[01:01:44.020 --> 01:01:46.540]   And because it was 28 by 28, and we reshaped it,
[01:01:46.540 --> 01:01:48.580]   so it has a shape of 784.
[01:01:48.580 --> 01:01:51.580]   And y has a value of 1.
[01:01:51.580 --> 01:01:54.660]   I can do the same thing for my validation set.
[01:01:54.660 --> 01:01:58.460]   So I can get a validation data set.
[01:01:58.460 --> 01:02:00.740]   Now, next thing you want to be able to do
[01:02:00.740 --> 01:02:03.460]   is when you're able to initialize the random--
[01:02:03.460 --> 01:02:05.580]   we need to be able to initialize the variables using
[01:02:05.580 --> 01:02:06.260]   random weights.
[01:02:06.260 --> 01:02:08.620]   So I can just use tors.random to be
[01:02:08.620 --> 01:02:10.060]   able to initialize the weights.
[01:02:10.060 --> 01:02:13.420]   And I say requires grad, because I want them to be parameters,
[01:02:13.420 --> 01:02:16.300]   and I want to be able to update and calculate the gradients.
[01:02:16.300 --> 01:02:19.500]   So I initialize my weights using this function.
[01:02:19.500 --> 01:02:20.540]   I initialize my bias.
[01:02:20.540 --> 01:02:27.180]   And then this is what my model looks like.
[01:02:27.180 --> 01:02:30.660]   So if I'm doing classification of digit 3s versus 7,
[01:02:30.660 --> 01:02:33.300]   I'm just trying to use a linear layer.
[01:02:33.300 --> 01:02:34.980]   So what's a linear layer in mathematics?
[01:02:34.980 --> 01:02:37.260]   Ax plus b represents a line.
[01:02:37.260 --> 01:02:39.780]   In PyTorch or in deep learning world,
[01:02:39.780 --> 01:02:42.380]   you'll see that this is being referred to as a linear layer.
[01:02:42.380 --> 01:02:45.420]   So I just say that my prediction function right now
[01:02:45.420 --> 01:02:48.380]   is just this linear 1.
[01:02:48.380 --> 01:02:50.420]   So what does the prediction function do then?
[01:02:50.420 --> 01:02:55.420]   I can pass in my independent variables or my x items,
[01:02:55.420 --> 01:02:57.060]   basically, to get some predictions.
[01:02:57.060 --> 01:02:57.860]   And here it is.
[01:02:57.860 --> 01:02:59.260]   I get my predictions.
[01:02:59.260 --> 01:03:08.020]   So if I have a look at the threads.shape and trainx.shape,
[01:03:08.020 --> 01:03:11.700]   then for every 12,396 images that we input,
[01:03:11.700 --> 01:03:15.100]   we get some predictions.
[01:03:15.100 --> 01:03:19.300]   So if I want to check how if the predictions are correct or not,
[01:03:19.300 --> 01:03:20.300]   this should be 0.5.
[01:03:20.300 --> 01:03:23.660]   There's an error in the notebook that says 0.
[01:03:23.660 --> 01:03:25.820]   I can check the value of my corrects,
[01:03:25.820 --> 01:03:27.260]   and I can check the float.
[01:03:27.260 --> 01:03:28.220]   So what does this mean?
[01:03:28.220 --> 01:03:30.060]   What am I doing at this point?
[01:03:30.060 --> 01:03:34.260]   So see how I had a prediction that looks like this.
[01:03:34.260 --> 01:03:38.060]   If the value is a 3, then my ground truth label is 1.
[01:03:38.060 --> 01:03:39.620]   If the value is--
[01:03:39.620 --> 01:03:42.940]   if my ground truth label is 0, then the number was a 7.
[01:03:42.940 --> 01:03:43.940]   Remember that.
[01:03:43.940 --> 01:03:46.460]   So when I do something like threads greater than equal to--
[01:03:46.460 --> 01:03:52.100]   or threads greater than 0.5, so if my prediction is greater
[01:03:52.100 --> 01:03:55.260]   than 0.5, then that means that the model is trying to say
[01:03:55.260 --> 01:03:56.380]   it's a digit 3.
[01:03:56.380 --> 01:03:58.300]   If my prediction is less than 0.5,
[01:03:58.300 --> 01:04:00.300]   then that means that the model is trying to say
[01:04:00.300 --> 01:04:02.780]   that the prediction is 0.
[01:04:02.780 --> 01:04:06.900]   So I can then check my accuracy just by calculating the mean.
[01:04:06.900 --> 01:04:09.220]   I convert everything to a float, and I can say mean,
[01:04:09.220 --> 01:04:11.180]   and I can calculate the item.
[01:04:11.180 --> 01:04:14.620]   Without saying item, it would have returned a tensor.
[01:04:14.620 --> 01:04:16.300]   In PyTorch, you can just say item,
[01:04:16.300 --> 01:04:20.260]   which will convert that tensor into a number.
[01:04:20.260 --> 01:04:22.860]   So until now, all I'm using is just PyTorch.
[01:04:22.860 --> 01:04:25.900]   If there's parts of this that you don't understand,
[01:04:25.900 --> 01:04:27.980]   then that means you need to go back and you need to learn
[01:04:27.980 --> 01:04:30.340]   PyTorch, and you need to learn more about Python.
[01:04:30.340 --> 01:04:35.940]   So practice more and more about every code line
[01:04:35.940 --> 01:04:37.540]   that's written so far.
[01:04:37.540 --> 01:04:45.460]   All right, so now I can get predictions.
[01:04:45.460 --> 01:04:47.820]   So now going back to the notebook,
[01:04:47.820 --> 01:04:50.820]   something I want to share without going
[01:04:50.820 --> 01:04:53.060]   into the code for now.
[01:04:53.060 --> 01:05:12.020]   OK, here we are.
[01:05:12.020 --> 01:05:19.300]   OK, so this is where we ended up in our notebook, right?
[01:05:19.300 --> 01:05:20.780]   So what's the difference?
[01:05:20.780 --> 01:05:22.940]   Until now, what have we done so far?
[01:05:22.940 --> 01:05:24.740]   So let me try and summarize that.
[01:05:24.740 --> 01:05:26.020]   One second.
[01:05:26.020 --> 01:05:28.020]   So let me try and summarize that over here.
[01:05:28.020 --> 01:05:34.140]   What we have done so far is we have
[01:05:34.140 --> 01:05:39.140]   a model that looks like this linear one function.
[01:05:39.140 --> 01:05:43.180]   We provided it with some weights,
[01:05:43.180 --> 01:05:45.980]   and we passed in some input.
[01:05:45.980 --> 01:05:51.420]   So remember the initWeights function, initWeight function.
[01:05:51.420 --> 01:05:53.300]   That's what's initializing these weights
[01:05:53.300 --> 01:05:56.300]   with some random values.
[01:05:56.300 --> 01:06:00.580]   So I initialized this with some random weights.
[01:06:00.580 --> 01:06:01.940]   I passed in the input.
[01:06:01.940 --> 01:06:05.500]   In code, this was called as frame x,
[01:06:05.500 --> 01:06:10.460]   and I get some predictions.
[01:06:10.460 --> 01:06:12.100]   Now, to do SGD--
[01:06:12.100 --> 01:06:13.300]   so so far, all good, right?
[01:06:13.780 --> 01:06:16.940]   This is exactly what we've done in code so far.
[01:06:16.940 --> 01:06:20.020]   But to be able to do SGD, I need to be
[01:06:20.020 --> 01:06:23.620]   able to then calculate the loss, and then I
[01:06:23.620 --> 01:06:25.980]   need to calculate the gradients, and I
[01:06:25.980 --> 01:06:28.380]   need to do the stepping and all that
[01:06:28.380 --> 01:06:29.860]   that we've looked at before.
[01:06:29.860 --> 01:06:33.780]   So we need to define a loss function that we can then
[01:06:33.780 --> 01:06:38.180]   call backward, and then we will update these weights based
[01:06:38.180 --> 01:06:43.300]   on the gradients so that the loss becomes lower.
[01:06:43.300 --> 01:06:43.980]   So let's do that.
[01:06:43.980 --> 01:06:46.180]   We haven't defined the loss function so far.
[01:06:46.180 --> 01:06:47.740]   So that's what I've written here.
[01:06:47.740 --> 01:06:50.180]   So far, we have not defined the loss function.
[01:06:50.180 --> 01:06:52.260]   We need to define a loss, and then we
[01:06:52.260 --> 01:06:54.220]   can calculate the gradients and do SGD.
[01:06:54.220 --> 01:06:59.180]   So let's try and create a loss function.
[01:06:59.180 --> 01:07:05.740]   I'm still-- I'm using this PDF version now.
[01:07:05.740 --> 01:07:07.020]   I'm not going back to the code.
[01:07:07.020 --> 01:07:09.900]   I will go back to the notebook in just a sec,
[01:07:09.900 --> 01:07:13.300]   but I need to be able to explain how a loss function is defined.
[01:07:13.300 --> 01:07:18.940]   So if I have my targets, which is 1, 0, 1,
[01:07:18.940 --> 01:07:21.420]   and let's say the predictions that the model weight makes
[01:07:21.420 --> 01:07:26.660]   are 0.9, 0.4, and 0.2, then my loss function
[01:07:26.660 --> 01:07:30.060]   could be torch.where targets equal to equal to 1,
[01:07:30.060 --> 01:07:34.100]   1 minus predictions, or otherwise predictions.
[01:07:34.100 --> 01:07:35.700]   Now, let me try and explain that.
[01:07:36.700 --> 01:07:44.980]   So if I have some inputs, if my targets were 1, 0, 0, 1--
[01:07:44.980 --> 01:07:46.820]   remember, we converted everything.
[01:07:46.820 --> 01:07:48.940]   My targets were just 0s or 1s, right?
[01:07:48.940 --> 01:07:50.780]   And let's say the predictions from the model
[01:07:50.780 --> 01:07:54.060]   are 0.9, 0.4, and 0.2.
[01:07:54.060 --> 01:07:54.860]   Then what is this--
[01:07:54.860 --> 01:08:05.260]   then what is this MNIST loss function going to do?
[01:08:05.260 --> 01:08:07.660]   What this tells us-- what is this?
[01:08:07.660 --> 01:08:13.260]   It says if targets equal to equal to 1,
[01:08:13.260 --> 01:08:18.020]   then my loss is 1 minus predictions,
[01:08:18.020 --> 01:08:24.180]   else that is basically saying my target--
[01:08:24.180 --> 01:08:27.580]   that is just basically saying my target is 0.
[01:08:27.580 --> 01:08:30.060]   In that case, my loss is equal to predictions.
[01:08:33.980 --> 01:08:35.260]   So why could this--
[01:08:35.260 --> 01:08:38.260]   why could just this be a loss function?
[01:08:38.260 --> 01:08:39.860]   Why could this be a loss function?
[01:08:39.860 --> 01:08:41.140]   So let me try and explain that.
[01:08:41.140 --> 01:08:51.620]   So my predictions-- let's say if I'm somewhere here, my 3s,
[01:08:51.620 --> 01:08:52.500]   let's say, are here.
[01:08:52.500 --> 01:08:53.700]   My 7s are here.
[01:08:53.700 --> 01:08:58.140]   So let's say my 3s are represented as the labels--
[01:08:58.140 --> 01:08:59.620]   basically, the tensor 0.
[01:08:59.700 --> 01:09:02.300]   And my 7s are represented as tensor 1.
[01:09:02.300 --> 01:09:07.940]   Then I need to be able to know--
[01:09:07.940 --> 01:09:11.140]   basically, I want my predictions for 7s to be close to 1,
[01:09:11.140 --> 01:09:13.980]   and I want my predictions for 3s to be close to 0.
[01:09:13.980 --> 01:09:16.060]   That's how I know that my model is accurate.
[01:09:16.060 --> 01:09:19.060]   But let's say if the model makes predictions everywhere,
[01:09:19.060 --> 01:09:21.540]   this is where the predictions are.
[01:09:21.540 --> 01:09:23.060]   So this is a prediction for 3.
[01:09:23.060 --> 01:09:25.860]   This is a prediction if actually the image was 7.
[01:09:25.860 --> 01:09:28.940]   This is, again, a prediction if actually the image was 7.
[01:09:28.940 --> 01:09:31.220]   This is a prediction if actually the image was 3.
[01:09:31.220 --> 01:09:34.780]   And this is a prediction if actually the image was 7.
[01:09:34.780 --> 01:09:36.660]   So what we want to do--
[01:09:36.660 --> 01:09:38.100]   instead of the model--
[01:09:38.100 --> 01:09:40.460]   this is a poor model.
[01:09:40.460 --> 01:09:42.060]   What we want to do instead--
[01:09:42.060 --> 01:09:46.060]   if this represents my 3s, this represents my--
[01:09:46.060 --> 01:09:49.700]   what we want to do is we want all model predictions related
[01:09:49.700 --> 01:09:51.420]   to 3 to be closer to 0.
[01:09:51.420 --> 01:09:54.060]   And we want all model predictions
[01:09:54.060 --> 01:09:57.860]   for an actual digit 7 to be closer to 1.
[01:09:57.860 --> 01:10:00.500]   So we need to be able to define a loss function that
[01:10:00.500 --> 01:10:04.460]   can say that, hey, model, these predictions that you're making,
[01:10:04.460 --> 01:10:06.220]   these are bad predictions.
[01:10:06.220 --> 01:10:08.740]   Because that's how, then, we know that the loss is bad.
[01:10:08.740 --> 01:10:10.700]   And that's when we can calculate the gradients.
[01:10:10.700 --> 01:10:13.060]   And that's when we can try and reduce the loss.
[01:10:13.060 --> 01:10:15.340]   So if you're trying to say to this model
[01:10:15.340 --> 01:10:18.100]   that these predictions are bad, then a simple loss function
[01:10:18.100 --> 01:10:24.540]   could just be the distance of how far my predictions are
[01:10:24.540 --> 01:10:26.140]   from where they should be.
[01:10:26.140 --> 01:10:28.580]   So if I calculate with respect to 7s,
[01:10:28.580 --> 01:10:31.060]   I can see that this prediction is this far,
[01:10:31.060 --> 01:10:34.860]   this prediction is this far, and this prediction is this far.
[01:10:34.860 --> 01:10:36.820]   So these predictions are very far away
[01:10:36.820 --> 01:10:38.420]   from where they should be.
[01:10:38.420 --> 01:10:42.140]   What I want to do is I want to minimize this distance.
[01:10:42.140 --> 01:10:45.380]   Or for 3s, this is the distance, and this
[01:10:45.380 --> 01:10:48.300]   is the distance for this prediction 3.
[01:10:48.300 --> 01:10:50.300]   What I want to do is I want to be able to minimize
[01:10:50.300 --> 01:10:51.700]   the distance.
[01:10:51.700 --> 01:10:54.700]   So in that case, I can define my loss function
[01:10:54.700 --> 01:10:59.420]   as if the actual image is a 7, then
[01:10:59.420 --> 01:11:02.620]   my loss is 1 minus prediction.
[01:11:02.620 --> 01:11:09.340]   So 1 minus prediction would give me all these distances,
[01:11:09.340 --> 01:11:11.060]   all these distances for 7.
[01:11:11.060 --> 01:11:15.100]   So that gives me, basically, the distances for 7s.
[01:11:15.100 --> 01:11:19.180]   And when the actual digit is a 3,
[01:11:19.180 --> 01:11:21.060]   then I can just say my predictions,
[01:11:21.060 --> 01:11:23.420]   my loss is equal to predictions.
[01:11:23.420 --> 01:11:27.180]   Because then that will give me these distances.
[01:11:27.180 --> 01:11:28.740]   So it gives me this distance of 3.
[01:11:28.740 --> 01:11:31.660]   And then once I have the loss, then all I have to do
[01:11:31.660 --> 01:11:34.860]   is I have to minimize this.
[01:11:34.860 --> 01:11:35.980]   I hope this helps.
[01:11:35.980 --> 01:11:39.420]   This has been explained in this much detail in the book,
[01:11:39.420 --> 01:11:42.740]   but I wanted to make an effort to try and explain the loss
[01:11:42.740 --> 01:11:44.100]   function that we have so far.
[01:11:44.100 --> 01:11:45.980]   So that's why this is a loss function.
[01:11:45.980 --> 01:11:51.860]   And basically, when you represent this in code,
[01:11:51.860 --> 01:11:54.180]   it can be just a single line.
[01:11:54.180 --> 01:11:56.020]   So tors dot where targets are 1.
[01:11:56.020 --> 01:11:59.140]   So tors dot where targets are 1 refer to everywhere
[01:11:59.140 --> 01:12:01.500]   where it's actually, say, a 7.
[01:12:01.500 --> 01:12:04.700]   That's when your loss would be 1 minus predictions.
[01:12:04.700 --> 01:12:07.700]   Because 1 minus predictions will give you the sum of all of
[01:12:07.700 --> 01:12:09.100]   these, like how far.
[01:12:09.100 --> 01:12:10.900]   Because these should be closer to 1.
[01:12:10.900 --> 01:12:14.340]   So then the distance is telling me how far it is from 1.
[01:12:14.340 --> 01:12:17.260]   And otherwise, you could have just said over here,
[01:12:17.260 --> 01:12:18.820]   it could have been 0 minus predictions,
[01:12:18.820 --> 01:12:20.020]   which wouldn't make sense.
[01:12:20.020 --> 01:12:21.820]   Or you could just say predictions minus 0,
[01:12:21.820 --> 01:12:23.220]   which wouldn't make sense either.
[01:12:23.220 --> 01:12:24.540]   So you can just say predictions.
[01:12:24.540 --> 01:12:27.060]   So that just means this is how far it is,
[01:12:27.060 --> 01:12:29.980]   how far my predictions are from 0.
[01:12:29.980 --> 01:12:34.740]   So that's why this is how this MNIST loss has been defined.
[01:12:34.740 --> 01:12:36.900]   So if I calculate the loss on, let's say,
[01:12:36.900 --> 01:12:38.900]   my targets are this and my predictions are this,
[01:12:38.900 --> 01:12:40.460]   then if I calculate the MNIST loss,
[01:12:40.460 --> 01:12:42.740]   then that's how that gives me sum.
[01:12:42.740 --> 01:12:45.780]   So this is the sum of distances--
[01:12:45.780 --> 01:12:49.740]   or sorry, it is the mean of distances, my loss function.
[01:12:49.740 --> 01:12:52.260]   So once I have all the distances,
[01:12:52.260 --> 01:12:54.580]   I can just calculate the mean.
[01:12:54.580 --> 01:12:56.340]   So this is what my MNIST loss looks like.
[01:12:56.340 --> 01:13:03.260]   And the key thing then to note--
[01:13:03.260 --> 01:13:06.740]   the key thing to note here is--
[01:13:06.740 --> 01:13:10.380]   if I don't remove-- if I remove the mean, let me show you.
[01:13:10.380 --> 01:13:15.020]   The key thing to note here is when your prediction is 0.9
[01:13:15.020 --> 01:13:19.700]   and the actual value is 1, then your loss is 0.1.
[01:13:19.700 --> 01:13:25.820]   When your actual value is 0 and your prediction is 0.4,
[01:13:25.820 --> 01:13:28.460]   then your loss is 0.4.
[01:13:28.460 --> 01:13:31.500]   When your actual value is 1 and your prediction is 0.2,
[01:13:31.500 --> 01:13:34.260]   then your loss is 0.8.
[01:13:34.260 --> 01:13:38.460]   So when the model is actually closer to the actual value--
[01:13:38.460 --> 01:13:48.140]   so when your model is actually closer to the actual value,
[01:13:48.140 --> 01:13:50.700]   that's when the loss is lower.
[01:13:50.700 --> 01:13:54.220]   But the further away you go from the ground truth value,
[01:13:54.220 --> 01:13:56.460]   if it was a 1 and you're somewhere here,
[01:13:56.460 --> 01:13:59.220]   that's when your loss is the maximum.
[01:13:59.220 --> 01:14:01.340]   So that's the intuition behind this loss.
[01:14:01.340 --> 01:14:09.940]   So that's how MNIST loss has been defined.
[01:14:09.940 --> 01:14:13.420]   But there is a problem with this loss function.
[01:14:13.420 --> 01:14:17.700]   The problem is this assumes that all my predictions are
[01:14:17.700 --> 01:14:19.380]   between 0 and 1.
[01:14:19.380 --> 01:14:21.900]   That wouldn't always be the case.
[01:14:21.900 --> 01:14:24.060]   Why?
[01:14:24.060 --> 01:14:28.500]   Because remember, my model was just this AX plus B.
[01:14:28.500 --> 01:14:31.420]   It was just XB at the rate weights plus bias.
[01:14:31.420 --> 01:14:33.340]   So at the rate function in PyTorch
[01:14:33.340 --> 01:14:37.140]   represents matrix multiplication.
[01:14:37.140 --> 01:14:40.140]   And when you get the predictions using this function,
[01:14:40.140 --> 01:14:45.260]   then if you think of it in terms of mathematical terms,
[01:14:45.260 --> 01:14:47.340]   then a linear line could be just like this.
[01:14:47.340 --> 01:14:50.380]   So it's not always that all my predictions
[01:14:50.380 --> 01:14:51.620]   would be between 0 and 1.
[01:14:51.620 --> 01:14:54.220]   They could be higher than 1, or they could be lower than 0.
[01:14:54.220 --> 01:14:57.180]   So how do we fix this?
[01:14:57.180 --> 01:14:59.260]   There's a function called sigmoid.
[01:14:59.260 --> 01:15:01.580]   So that's what the sigmoid function looks like.
[01:15:01.580 --> 01:15:03.540]   What does this sigmoid function do?
[01:15:03.540 --> 01:15:07.980]   This sigmoid function looks like this.
[01:15:07.980 --> 01:15:11.220]   And basically, all it does is it converts all my predictions
[01:15:11.220 --> 01:15:13.060]   between 0 and 1.
[01:15:13.060 --> 01:15:16.060]   So that's what the sigmoid function can do.
[01:15:16.060 --> 01:15:20.940]   If my value is really high, like let's say 1,000,
[01:15:20.940 --> 01:15:24.900]   then in that case, it will just be like a value of 0.99
[01:15:24.900 --> 01:15:26.340]   or closer to 1.
[01:15:26.340 --> 01:15:29.220]   And if my value is like minus 4, then it's closer to 0.
[01:15:29.220 --> 01:15:33.780]   So it converts my whole thing into 0s and 1s.
[01:15:33.780 --> 01:15:36.980]   So I can then update my MNIST loss function.
[01:15:36.980 --> 01:15:38.660]   First, I can take the sigmoid.
[01:15:38.660 --> 01:15:39.820]   So that means that now--
[01:15:39.820 --> 01:15:43.580]   I'll just write it here.
[01:15:43.620 --> 01:15:50.140]   At this point, after taking the sigmoid,
[01:15:50.140 --> 01:15:55.940]   my predictions are between 0 and 1.
[01:15:55.940 --> 01:15:58.100]   So after taking the sigmoid, then I
[01:15:58.100 --> 01:16:00.740]   can be sure that all my predictions are between 0 and 1.
[01:16:00.740 --> 01:16:05.900]   And then after this, I can just apply this distance loss
[01:16:05.900 --> 01:16:07.820]   function that I've explained.
[01:16:07.820 --> 01:16:11.980]   And that's it.
[01:16:11.980 --> 01:16:14.060]   Now we are ready to do STD.
[01:16:14.060 --> 01:16:18.340]   But I will take questions for five minutes on--
[01:16:18.340 --> 01:16:20.820]   basically, if you have any questions about how this loss
[01:16:20.820 --> 01:16:21.900]   function has been defined.
[01:16:21.900 --> 01:16:35.180]   How to decide the losses minimum and not go below this.
[01:16:39.900 --> 01:16:42.420]   I see that Pred's values were not between 0 and 1.
[01:16:42.420 --> 01:16:46.380]   So does it make sense to keep the threshold for Pred as 0.5?
[01:16:46.380 --> 01:16:47.100]   Thanks, Bhavani.
[01:16:47.100 --> 01:16:48.460]   I think that's a great question.
[01:16:48.460 --> 01:16:53.300]   And I hope taking the sigmoid will now answer this question.
[01:16:53.300 --> 01:16:55.700]   Because when we're taking the sigmoid,
[01:16:55.700 --> 01:16:57.780]   then that makes sure that all my predictions are
[01:16:57.780 --> 01:17:00.540]   between 0 and 1.
[01:17:00.540 --> 01:17:02.540]   This explanation of loss function is phenomenal.
[01:17:02.540 --> 01:17:03.540]   Thanks, Kirijesh.
[01:17:03.540 --> 01:17:07.380]   I'm glad it's explained.
[01:17:07.380 --> 01:17:08.540]   OK, it helps.
[01:17:09.540 --> 01:17:12.860]   OK, so now that we have everything,
[01:17:12.860 --> 01:17:16.260]   now we are ready to do STD.
[01:17:16.260 --> 01:17:22.060]   So remember, we have a data set that looks something like this.
[01:17:22.060 --> 01:17:23.860]   It has around-- well, it has around--
[01:17:23.860 --> 01:17:28.180]   for 3s and 7s, it has around 12k images.
[01:17:28.180 --> 01:17:32.460]   But my first set was 3s, and my second set was 7s.
[01:17:32.460 --> 01:17:35.020]   Then what I can do is I can pass all of these--
[01:17:35.020 --> 01:17:38.620]   the first thing I can do is I can pass all the whole data
[01:17:38.620 --> 01:17:42.060]   set to the model, and I can get some predictions.
[01:17:42.060 --> 01:17:43.660]   And then I can calculate the loss.
[01:17:43.660 --> 01:17:45.140]   Then I can calculate the gradients.
[01:17:45.140 --> 01:17:47.300]   And then I can do this step over and over again
[01:17:47.300 --> 01:17:48.900]   until my loss is reduced.
[01:17:48.900 --> 01:17:51.940]   But it's not a good way of doing so.
[01:17:51.940 --> 01:17:54.100]   Why?
[01:17:54.100 --> 01:17:57.420]   This is dependent on the fact that my whole data
[01:17:57.420 --> 01:17:59.980]   set can fit on a GPU.
[01:17:59.980 --> 01:18:03.420]   Because remember, the model is on a GPU.
[01:18:03.420 --> 01:18:06.820]   So this is dependent on the fact that my whole data
[01:18:06.820 --> 01:18:10.220]   set can fit on a GPU, which would never be the case.
[01:18:10.220 --> 01:18:15.940]   When you have image net size data sets,
[01:18:15.940 --> 01:18:19.060]   which are 1 million images, then they will never
[01:18:19.060 --> 01:18:21.660]   fit on a single GPU.
[01:18:21.660 --> 01:18:24.260]   So something you instead do is you just
[01:18:24.260 --> 01:18:27.740]   take a subset of this data set, which is called a batch.
[01:18:27.740 --> 01:18:31.220]   So let's say I just take my first 64 images.
[01:18:31.220 --> 01:18:33.780]   So in that case, my batch size is 64.
[01:18:33.780 --> 01:18:35.780]   And I pass this 64 to the model.
[01:18:35.780 --> 01:18:36.940]   I get the predictions.
[01:18:36.940 --> 01:18:38.740]   I calculate the loss.
[01:18:38.740 --> 01:18:40.860]   I update my parameters based on this loss.
[01:18:40.860 --> 01:18:42.620]   And I keep doing this over and over again.
[01:18:42.620 --> 01:18:46.700]   So next 64, then 64, and the last 64.
[01:18:46.700 --> 01:18:48.460]   And once I've done all of them, that's
[01:18:48.460 --> 01:18:51.780]   when it's referred to as one epoch.
[01:18:51.780 --> 01:18:55.420]   But I can do this over and over and over again.
[01:18:55.420 --> 01:18:58.020]   And that is referred to as mini batch.
[01:18:58.020 --> 01:19:01.780]   So this 64 is just a mini batch of the whole data set.
[01:19:01.780 --> 01:19:03.500]   So now let me try and show that in code.
[01:19:03.500 --> 01:19:11.540]   OK.
[01:19:11.540 --> 01:19:15.620]   So in PyTorch, when you have a data set of 10,000 images,
[01:19:15.620 --> 01:19:22.340]   or basically, let's say my data set looks something like this.
[01:19:22.340 --> 01:19:26.420]   Let's say my data set is just 15 numbers.
[01:19:26.420 --> 01:19:28.220]   OK?
[01:19:28.220 --> 01:19:30.980]   And what can happen is then, even if it's just 15 numbers,
[01:19:30.980 --> 01:19:33.860]   let's say my GPU is so, so small that these 15 numbers won't
[01:19:33.860 --> 01:19:36.900]   fit, then I need to be able to convert this
[01:19:36.900 --> 01:19:38.980]   into small batches.
[01:19:38.980 --> 01:19:41.140]   In PyTorch, you have something called the data loader.
[01:19:41.140 --> 01:19:43.020]   In Fast.ai, you also have something
[01:19:43.020 --> 01:19:44.220]   called the data loader.
[01:19:44.220 --> 01:19:47.980]   Then what this data loader does is--
[01:19:47.980 --> 01:19:48.900]   see what it does?
[01:19:48.900 --> 01:19:52.700]   It converts those 15 into batches of 5.
[01:19:52.700 --> 01:19:54.940]   Because I pass my batch size as 5.
[01:19:54.940 --> 01:19:57.580]   That means I'm going to have three batches.
[01:19:57.580 --> 01:20:00.220]   And then because I said shuffle equal to true,
[01:20:00.220 --> 01:20:01.620]   then what it's going to do is it's
[01:20:01.620 --> 01:20:04.980]   going to randomly pick five elements first from 15.
[01:20:04.980 --> 01:20:07.620]   Then it's going to randomly pick next five elements.
[01:20:07.620 --> 01:20:10.980]   Then it's going to randomly pick next five elements.
[01:20:10.980 --> 01:20:13.700]   You could have also done this for--
[01:20:13.700 --> 01:20:15.620]   let's say my data set looks something like this,
[01:20:15.620 --> 01:20:17.460]   like 0A, 1B.
[01:20:17.460 --> 01:20:20.140]   Then I could have, again, passed my data loader.
[01:20:20.140 --> 01:20:21.780]   I could have said my batch size is 6.
[01:20:21.780 --> 01:20:22.780]   [CLEARS THROAT]
[01:20:22.780 --> 01:20:23.780]   Excuse me.
[01:20:23.780 --> 01:20:26.780]   [AUDIO OUT]
[01:20:26.780 --> 01:20:27.780]   Sorry, what's that?
[01:20:27.780 --> 01:20:31.260]   [AUDIO OUT]
[01:20:31.260 --> 01:20:37.020]   Then I could have, again, said--
[01:20:37.020 --> 01:20:39.540]   I could have, again, said my batch size is 6.
[01:20:39.540 --> 01:20:42.140]   And in this case, then I pass in my data set
[01:20:42.140 --> 01:20:44.620]   and I again get a data loader.
[01:20:44.620 --> 01:20:46.700]   So that's what PyTorch data loader is for.
[01:20:46.700 --> 01:20:50.660]   It can be used to create mini batches.
[01:20:50.660 --> 01:20:52.140]   OK, so that's it.
[01:20:52.140 --> 01:20:54.140]   So now we are ready to do-- because we've
[01:20:54.140 --> 01:20:55.780]   defined the loss function.
[01:20:55.780 --> 01:21:01.300]   Now we're ready to do SGD on these 3s versus 7s.
[01:21:01.300 --> 01:21:05.580]   So the first thing I do is I initialize my weights randomly.
[01:21:05.580 --> 01:21:08.220]   The second thing I do is I can calculate my--
[01:21:08.220 --> 01:21:10.460]   basically, I can calculate mini batches.
[01:21:10.460 --> 01:21:14.300]   So that mini batches is just like getting this first half
[01:21:14.300 --> 01:21:17.340]   of the data set.
[01:21:17.340 --> 01:21:21.940]   I can do the same thing for my validation images.
[01:21:21.940 --> 01:21:25.180]   And then I can check what my shape of the batch is.
[01:21:25.180 --> 01:21:27.900]   So my batch has just a batch size of 4.
[01:21:27.900 --> 01:21:30.780]   And each element is 784 long.
[01:21:30.780 --> 01:21:34.580]   Because remember, each image was 28 by 28.
[01:21:34.580 --> 01:21:35.820]   But we've flattened it out.
[01:21:35.820 --> 01:21:37.340]   That means now each image is just
[01:21:37.340 --> 01:21:40.340]   represented by a vector of 784.
[01:21:40.340 --> 01:21:42.540]   So now I can pass this whole batch
[01:21:42.540 --> 01:21:44.420]   to my model, which we call linear 1.
[01:21:44.420 --> 01:21:47.700]   And we can get predictions.
[01:21:47.700 --> 01:21:49.740]   Finally, in SGD, then, these predictions--
[01:21:49.740 --> 01:21:52.660]   based on these predictions, I can calculate the MNIST loss.
[01:21:52.660 --> 01:21:54.620]   So what MNIST loss will do is it will first
[01:21:54.620 --> 01:21:57.260]   convert these using sigmoid.
[01:21:57.260 --> 01:22:00.700]   So let me show you how that looks like.
[01:22:00.700 --> 01:22:05.740]   So if I say preds.sigmoid, see how it converts everything
[01:22:05.740 --> 01:22:08.420]   to between 0 and 1?
[01:22:08.420 --> 01:22:09.620]   This is 0.99.
[01:22:09.620 --> 01:22:12.340]   This is 0.05, and so on.
[01:22:12.340 --> 01:22:14.500]   So then I can calculate my MNIST loss, which
[01:22:14.500 --> 01:22:16.820]   gives me some value of loss.
[01:22:16.820 --> 01:22:18.100]   Now I can do the gradient.
[01:22:18.100 --> 01:22:21.060]   So loss.backward will calculate the gradients,
[01:22:21.060 --> 01:22:23.460]   which means it will tell me which is the direction that I
[01:22:23.460 --> 01:22:26.020]   need to go.
[01:22:26.020 --> 01:22:28.620]   And then basically now we can just
[01:22:28.620 --> 01:22:30.020]   put this all in a function.
[01:22:30.020 --> 01:22:31.540]   So don't worry about that for now.
[01:22:31.540 --> 01:22:33.380]   Or actually, let me just show you.
[01:22:33.380 --> 01:22:35.860]   So if you pass in some input, you can get the predictions.
[01:22:35.860 --> 01:22:36.980]   You can calculate the loss.
[01:22:36.980 --> 01:22:39.620]   And then you can call loss.backward.
[01:22:39.620 --> 01:22:41.660]   So let's see.
[01:22:41.660 --> 01:22:43.420]   I can calculate my gradients.
[01:22:43.420 --> 01:22:47.020]   And I can see that the gradient now has some value.
[01:22:47.020 --> 01:22:50.140]   And basically, the model weights have--
[01:22:50.140 --> 01:22:51.580]   the gradients have some value.
[01:22:51.580 --> 01:22:54.100]   And the bias of the model also has
[01:22:54.100 --> 01:22:55.300]   some value for the gradients.
[01:22:55.300 --> 01:22:59.500]   I need to zero out the gradients.
[01:22:59.500 --> 01:23:02.500]   I will explain this why in a second.
[01:23:02.500 --> 01:23:08.100]   But then the train epoch, like this process of SGD
[01:23:08.100 --> 01:23:16.180]   of this whole image, which should be at the top,
[01:23:16.180 --> 01:23:20.540]   this image of initializing, predicting loss gradient step
[01:23:20.540 --> 01:23:22.900]   can be converted into just this one function.
[01:23:22.900 --> 01:23:25.220]   So this calculate gradient takes in the inputs,
[01:23:25.220 --> 01:23:28.540]   takes in the actual values, and takes in the model.
[01:23:28.540 --> 01:23:31.780]   And it will-- all this is doing is then it makes predictions.
[01:23:31.780 --> 01:23:34.540]   It calculates the loss and calculates the gradient.
[01:23:34.540 --> 01:23:36.540]   So then I know the gradients, which
[01:23:36.540 --> 01:23:39.140]   means the next step for me is to take the step.
[01:23:39.140 --> 01:23:43.580]   So that step looks like this, p.data minus equal to p.grad
[01:23:43.580 --> 01:23:45.540]   slash star LR.
[01:23:45.540 --> 01:23:49.460]   And then I need to zero out my gradients.
[01:23:49.460 --> 01:23:52.540]   This should again be 0.5.
[01:23:52.540 --> 01:23:56.540]   So see how it gives me basically--
[01:23:56.540 --> 01:23:58.900]   it tells me that only my model accuracy,
[01:23:58.900 --> 01:24:02.380]   like it's 1 by 4, which means 25%.
[01:24:02.380 --> 01:24:05.860]   So I can calculate accuracy just by using this.
[01:24:05.860 --> 01:24:09.580]   So my batch accuracy, as I said, is 25%.
[01:24:09.580 --> 01:24:15.460]   I can calculate the accuracy for my validation set,
[01:24:15.460 --> 01:24:16.980]   which is 0.344.
[01:24:16.980 --> 01:24:21.020]   And let's say my learning rate is 1.
[01:24:21.020 --> 01:24:23.180]   Then let me train the model 20 times.
[01:24:23.180 --> 01:24:35.700]   And we can see that the accuracy has gone up from 68 to 97.4.
[01:24:35.700 --> 01:24:36.620]   Sorry, guys, one sec.
[01:24:36.620 --> 01:24:57.620]   Wow, I really have a bad cough.
[01:24:57.620 --> 01:24:59.340]   I didn't realize.
[01:24:59.340 --> 01:25:01.860]   I think it's all the talking that's irritating my throat
[01:25:01.860 --> 01:25:02.380]   a little bit.
[01:25:03.380 --> 01:25:06.020]   [CLEARS THROAT]
[01:25:06.020 --> 01:25:09.260]   So in that case, then, we get all the predictions.
[01:25:09.260 --> 01:25:11.300]   And we can see how my loss is going up.
[01:25:11.300 --> 01:25:18.540]   OK, I think I will stop here.
[01:25:18.540 --> 01:25:20.300]   I did mean to cover the optimizer,
[01:25:20.300 --> 01:25:22.940]   but I'm not feeling the best.
[01:25:22.940 --> 01:25:24.740]   But I will stop here.
[01:25:24.740 --> 01:25:27.420]   Let me just go back and see if there's any questions.
[01:25:27.420 --> 01:25:30.220]   [AUDIO OUT]
[01:25:30.220 --> 01:25:34.140]   Please try the YouTube session link.
[01:25:34.140 --> 01:25:35.540]   We will do.
[01:25:35.540 --> 01:25:40.820]   What impact would it have for the training if all 3s,
[01:25:40.820 --> 01:25:44.780]   all 7s, all firsts as 3s and all firsts as 7s,
[01:25:44.780 --> 01:25:46.620]   or randomly shuffle them?
[01:25:46.620 --> 01:25:48.740]   OK, Vinayak.
[01:25:48.740 --> 01:25:50.100]   That's a great question.
[01:25:50.100 --> 01:25:52.980]   But something I would say is, instead of asking,
[01:25:52.980 --> 01:25:56.380]   do an experiment and write a blog about it.
[01:25:56.380 --> 01:25:58.980]   So this is a great question that you've asked.
[01:25:58.980 --> 01:26:01.780]   Go back and see if there's any difference
[01:26:01.780 --> 01:26:03.860]   that you can get in accuracy.
[01:26:03.860 --> 01:26:06.940]   And then try and come up with a possible theory
[01:26:06.940 --> 01:26:08.060]   on why it could be.
[01:26:08.060 --> 01:26:14.740]   If you think deep enough and you can't come up with a reason,
[01:26:14.740 --> 01:26:17.220]   start a discussion group.
[01:26:17.220 --> 01:26:18.340]   Put it on Slack.
[01:26:18.340 --> 01:26:19.500]   Share your experiment.
[01:26:19.500 --> 01:26:23.060]   And then share your findings with people.
[01:26:23.060 --> 01:26:26.060]   And this is how you learn the most about deep learning.
[01:26:26.060 --> 01:26:29.500]   That is something I did a lot when I first started.
[01:26:29.500 --> 01:26:35.060]   Cool.
[01:26:35.060 --> 01:26:37.060]   So that's where we'll stop.
[01:26:37.060 --> 01:26:37.900]   I'm really sorry.
[01:26:37.900 --> 01:26:41.260]   I am not feeling very well on my throat.
[01:26:41.260 --> 01:26:42.140]   But I will go back.
[01:26:42.140 --> 01:26:44.340]   And we will just wrap this up.
[01:26:44.340 --> 01:26:46.900]   It will take us the next 10 minutes
[01:26:46.900 --> 01:26:50.660]   to wrap this up from this point forward in our next session.
[01:26:50.660 --> 01:26:52.740]   But in our next session, then, when you come back,
[01:26:52.740 --> 01:26:58.660]   we will start with pet breeds.
[01:26:58.660 --> 01:27:00.100]   But for now, go back.
[01:27:00.100 --> 01:27:03.380]   Have a look at stochastic gradient descent.
[01:27:03.380 --> 01:27:05.940]   Understand everything.
[01:27:05.940 --> 01:27:08.980]   Relate what we've learned so far to code.
[01:27:08.980 --> 01:27:13.220]   And then run all the code that there is.
[01:27:13.220 --> 01:27:14.780]   And that should be all.
[01:27:14.780 --> 01:27:15.420]   Thanks, guys.
[01:27:15.420 --> 01:27:16.420]   Thanks for today.
[01:27:16.420 --> 01:27:20.060]   I'm really sorry for not feeling very well.
[01:27:20.060 --> 01:27:30.060]   [BLANK_AUDIO]

