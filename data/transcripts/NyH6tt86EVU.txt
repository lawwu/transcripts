
[00:00:00.000 --> 00:00:07.040]   So I was kind of using data science as a backdoor to problems where I could talk to people,
[00:00:07.040 --> 00:00:12.880]   figure out what they're working on and kind of figure out how the software and algorithms,
[00:00:12.880 --> 00:00:17.480]   analytical methods they were using mapped to problems that I'd worked on previously
[00:00:17.480 --> 00:00:25.760]   and sort of use those analogies to move sideways from work that I had done outside the biomedical
[00:00:25.760 --> 00:00:27.800]   domain into the biomedical domain.
[00:00:27.800 --> 00:00:32.160]   You're listening to Gradient Dissent, a show about machine learning in the real world,
[00:00:32.160 --> 00:00:34.120]   and I'm your host, Lukas Biewald.
[00:00:34.120 --> 00:00:38.520]   I've known Jeff Hammerbacher for a long time, and he's had a truly incredible career.
[00:00:38.520 --> 00:00:44.320]   He started off running what was essentially the data science team at Facebook and then
[00:00:44.320 --> 00:00:51.200]   founded Cloudera, which was a really early company in the data science space and recently
[00:00:51.200 --> 00:00:54.260]   went private after being public for quite a long time.
[00:00:54.260 --> 00:01:00.400]   But mid-Cloudera, he actually left and became a professor at Mount Sinai and started his
[00:01:00.400 --> 00:01:01.400]   own lab.
[00:01:01.400 --> 00:01:05.440]   Now, he's working on a company called Related Sciences that does drug discovery with machine
[00:01:05.440 --> 00:01:06.440]   learning.
[00:01:06.440 --> 00:01:09.520]   I actually run out of time talking to him today because I have so many questions and
[00:01:09.520 --> 00:01:10.520]   his stories are so good.
[00:01:10.520 --> 00:01:12.840]   This is a super fun one.
[00:01:12.840 --> 00:01:15.960]   Jeff, thanks so much for doing this.
[00:01:15.960 --> 00:01:16.960]   Yeah, man.
[00:01:16.960 --> 00:01:17.960]   Good to see you.
[00:01:17.960 --> 00:01:18.960]   Yeah, good to see you.
[00:01:18.960 --> 00:01:25.040]   I want to get into the stuff that you're working on at the Hammer Lab, but this is obviously
[00:01:25.040 --> 00:01:29.220]   for a lot of people have come up through data science that we record this for.
[00:01:29.220 --> 00:01:33.980]   I thought it might be interesting to start just with your early career, just because
[00:01:33.980 --> 00:01:37.780]   I think people would want to know about it and you had such an outsized impact on the
[00:01:37.780 --> 00:01:38.980]   field of data science.
[00:01:38.980 --> 00:01:43.900]   I was curious to hear your story about how you came into Facebook and how you...
[00:01:43.900 --> 00:01:47.100]   I think you started a data science team there, right?
[00:01:47.100 --> 00:01:48.100]   Yeah.
[00:01:48.100 --> 00:01:50.340]   So let's see.
[00:01:50.340 --> 00:01:59.360]   I landed at Facebook in early 2006.
[00:01:59.360 --> 00:02:09.420]   My initial title was research scientist and then yeah, eventually I ran a group of what
[00:02:09.420 --> 00:02:13.740]   we would soon call data scientists.
[00:02:13.740 --> 00:02:20.740]   The next step after that was absorbing what we called data infrastructure at the time,
[00:02:20.740 --> 00:02:23.340]   which would I suppose now be called data engineering.
[00:02:23.340 --> 00:02:26.860]   And so yeah, we ended up with a team called the data team.
[00:02:26.860 --> 00:02:33.380]   It was almost 30 people by the time I left, so it was pretty good sized.
[00:02:33.380 --> 00:02:39.740]   And yeah, our mandate was effectively to collect all the data generated by this site and then
[00:02:39.740 --> 00:02:44.260]   do analyses on it to improve the business outcomes.
[00:02:44.260 --> 00:02:46.300]   And it was a rapid learning experience.
[00:02:46.300 --> 00:02:54.460]   I was there for less than three years and we went from effectively zero data for offline
[00:02:54.460 --> 00:02:57.740]   analytics to petabytes per day.
[00:02:57.740 --> 00:03:01.880]   And there was no real technology to support doing that at the time.
[00:03:01.880 --> 00:03:10.120]   So I was really spending a lot of time talking to people at Yahoo and eBay and Google, just
[00:03:10.120 --> 00:03:12.280]   trying to figure out what was going on.
[00:03:12.280 --> 00:03:17.160]   Commercial vendors, it wasn't really a blip on their radar yet to do data at that scale.
[00:03:17.160 --> 00:03:21.560]   So yeah, it was pretty intense and I learned a lot and I met a lot of great people and
[00:03:21.560 --> 00:03:24.040]   it eventually led to starting Cloudera.
[00:03:24.040 --> 00:03:29.240]   And people might not realize back then, it wasn't standard practice even to keep all
[00:03:29.240 --> 00:03:30.240]   your data.
[00:03:30.240 --> 00:03:33.520]   And talking to the CTO of eBay, even though I think a little bit after that, you're saying
[00:03:33.520 --> 00:03:38.640]   you don't want to keep like 1% of our click logs because it's just too expensive to store
[00:03:38.640 --> 00:03:39.640]   it all.
[00:03:39.640 --> 00:03:45.120]   I mean, why do you think Facebook was so out on the forefront of doing this kind of data
[00:03:45.120 --> 00:03:47.120]   analysis?
[00:03:47.120 --> 00:03:52.960]   We were certainly not ahead of Google.
[00:03:52.960 --> 00:03:54.920]   So I would never claim-
[00:03:54.920 --> 00:03:55.920]   That's a high bar.
[00:03:55.920 --> 00:03:58.240]   Yeah, I wouldn't claim that we were at the forefront.
[00:03:58.240 --> 00:04:02.780]   I would say it was kind of a necessity as the mother of invention in that we just had
[00:04:02.780 --> 00:04:08.960]   so much data and so much user activity that we wanted to understand and our product was
[00:04:08.960 --> 00:04:11.360]   evolving so quickly.
[00:04:11.360 --> 00:04:18.760]   So I think the need for offline analytics was really driven home to executives during
[00:04:18.760 --> 00:04:21.280]   the newsfeed launch.
[00:04:21.280 --> 00:04:26.600]   So this is something that's probably incomprehensible to most people listening, but Facebook didn't
[00:04:26.600 --> 00:04:30.360]   have a newsfeed when I joined.
[00:04:30.360 --> 00:04:35.240]   And we went and launched that six to eight months after I joined.
[00:04:35.240 --> 00:04:37.760]   And I remember getting a phone call.
[00:04:37.760 --> 00:04:44.640]   So Mark and Chris Hughes, two of the founders, were doing Facebook's first ever press tour.
[00:04:44.640 --> 00:04:51.240]   Newsfeed was a big deal and we had a PR and marketing function at the company finally.
[00:04:51.240 --> 00:04:55.240]   And so they had lined up all of these interviews on the East Coast.
[00:04:55.240 --> 00:04:59.040]   And the launch was like a disaster.
[00:04:59.040 --> 00:05:06.320]   They were out here fielding questions and freaking out because the narrative around
[00:05:06.320 --> 00:05:10.620]   the response was very negative, or around the product launch was very negative.
[00:05:10.620 --> 00:05:12.280]   But our metrics were pretty solid.
[00:05:12.280 --> 00:05:17.800]   So we were spending a lot of time really digging in to understand what was happening to user
[00:05:17.800 --> 00:05:24.960]   activity to try and distinguish the narrative, to distinguish what the users were telling
[00:05:24.960 --> 00:05:30.880]   us from what the press was telling us, and then helping to decide whether we needed to
[00:05:30.880 --> 00:05:31.880]   roll the thing back.
[00:05:31.880 --> 00:05:34.760]   It was a pretty big crisis at the company.
[00:05:34.760 --> 00:05:39.920]   And so using data to help stabilize product decision making.
[00:05:39.920 --> 00:05:45.840]   And then I think after that, it became a more critical function at the company.
[00:05:45.840 --> 00:05:46.840]   But it took a long time.
[00:05:46.840 --> 00:05:49.600]   I think growth was another big motivator.
[00:05:49.600 --> 00:05:53.160]   It's another part of the Facebook story that's not really well understood is that we kind
[00:05:53.160 --> 00:05:55.960]   of went sideways for like six months there.
[00:05:55.960 --> 00:06:03.360]   And like late 2007, early 2008, there was a lot of stress in the executive team and
[00:06:03.360 --> 00:06:04.360]   the engineering team.
[00:06:04.360 --> 00:06:10.000]   And a large chunk of people got like reorg to really focus on growth.
[00:06:10.000 --> 00:06:16.640]   And that ended up creating probably like the highest level awareness that we needed to
[00:06:16.640 --> 00:06:20.240]   invest in data infrastructure and data science.
[00:06:20.240 --> 00:06:24.240]   I think those are probably the two things that I look back on and think.
[00:06:24.240 --> 00:06:27.320]   And also just internationalization, it's tightly coupled to growth.
[00:06:27.320 --> 00:06:31.680]   But at some point, you're navigating the product through your intuitive understanding of what
[00:06:31.680 --> 00:06:36.440]   people in your demographic cohort want to see from the product.
[00:06:36.440 --> 00:06:43.360]   But then you have to transition to understanding what a grandma in Turkey wants from Facebook.
[00:06:43.360 --> 00:06:47.440]   And at that point, you really need to start flying with instruments.
[00:06:47.440 --> 00:06:53.560]   So yeah, I think those are kind of some milestones that I can recall from over a decade ago.
[00:06:53.560 --> 00:06:58.960]   And it's funny even to think back to then, but NoSQL was not really a thing a lot of
[00:06:58.960 --> 00:07:00.760]   people knew about.
[00:07:00.760 --> 00:07:02.360]   What was your tech stack in 2008?
[00:07:02.360 --> 00:07:03.360]   Do you remember?
[00:07:03.360 --> 00:07:06.400]   Like, where are you storing all this data and how you're querying it?
[00:07:06.400 --> 00:07:07.400]   Oh, totally.
[00:07:07.400 --> 00:07:08.400]   Yeah.
[00:07:08.400 --> 00:07:13.160]   So when I landed in 2006, the tech stack, well, first of all, in 2005, they didn't use
[00:07:13.160 --> 00:07:14.520]   version control.
[00:07:14.520 --> 00:07:20.760]   So this is like one of my favorite things about Facebook was they had a cron job that
[00:07:20.760 --> 00:07:26.400]   ran every night and tarred up the source code and copied it off to storage.
[00:07:26.400 --> 00:07:28.040]   Like that was how they did version control.
[00:07:28.040 --> 00:07:29.520]   So it was a different time.
[00:07:29.520 --> 00:07:33.040]   I mean, GitHub didn't exist.
[00:07:33.040 --> 00:07:35.860]   Version was kind of the dominant source control product.
[00:07:35.860 --> 00:07:38.000]   So the tech stack was the LAMP stack.
[00:07:38.000 --> 00:07:43.480]   It was Linux, Apache, MySQL, PHP.
[00:07:43.480 --> 00:07:50.720]   And Facebook played a big role in adding another M to that stack, memcached, which was essentially,
[00:07:50.720 --> 00:07:51.720]   I guess, Redis-ish.
[00:07:51.720 --> 00:07:58.800]   It was like the current modern thing I would refer to as a key value cache so you didn't
[00:07:58.800 --> 00:07:59.800]   have to hit the database.
[00:07:59.800 --> 00:08:07.200]   It was basically like if we hit the database, we had failed on the application side because
[00:08:07.200 --> 00:08:08.200]   the user activity was so high.
[00:08:08.200 --> 00:08:10.280]   So it had to all come out of the cache.
[00:08:10.280 --> 00:08:15.640]   So in terms of the stack for analytics, when I got there, Dustin Moskovitz, one of the
[00:08:15.640 --> 00:08:19.360]   founders had built something called the watch page.
[00:08:19.360 --> 00:08:24.320]   And the watch page was powered by a cron job that woke up every minute, issued a query
[00:08:24.320 --> 00:08:30.920]   to every MySQL production database to just gather some stats about user activity, and
[00:08:30.920 --> 00:08:35.520]   then pulled the results of those queries down into another offline MySQL database, which
[00:08:35.520 --> 00:08:40.120]   contained a rolling time series of per minute metrics.
[00:08:40.120 --> 00:08:41.120]   And that was great.
[00:08:41.120 --> 00:08:42.120]   And we used it for a long time.
[00:08:42.120 --> 00:08:45.960]   That's what everybody internally was watching to see user signups.
[00:08:45.960 --> 00:08:50.680]   And that's where a lot of the metrics around daily active, monthly active would get defined
[00:08:50.680 --> 00:08:51.680]   and pushed out.
[00:08:51.680 --> 00:08:57.280]   But we had no offline data store to do analytics work on.
[00:08:57.280 --> 00:09:00.400]   These were summaries that were computed at the time of the query and pulled back.
[00:09:00.400 --> 00:09:03.720]   So you couldn't do any kind of post hoc analytics over it.
[00:09:03.720 --> 00:09:09.600]   So the initial attempt at a tech stack for a data warehouse was to use Oracle.
[00:09:09.600 --> 00:09:12.440]   So I actually, that was me.
[00:09:12.440 --> 00:09:15.320]   I didn't make the purchasing decision, but I had to do a lot of the installation and
[00:09:15.320 --> 00:09:16.320]   maintenance of that thing.
[00:09:16.320 --> 00:09:21.760]   So I very clearly remember the Sun T2000 server that we were running on.
[00:09:21.760 --> 00:09:27.160]   And obviously this is all coload, not in the cloud at the time.
[00:09:27.160 --> 00:09:35.680]   And fiber channel interconnect to a network attached storage device and running Oracle
[00:09:35.680 --> 00:09:36.680]   Rack at the time.
[00:09:36.680 --> 00:09:40.200]   And was it sharded or is this like one machine is holding the whole thing?
[00:09:40.200 --> 00:09:44.520]   So Oracle Rack was a shared storage distributed compute.
[00:09:44.520 --> 00:09:48.760]   So a bit like the architectures that we end up with today in the cloud, where we have
[00:09:48.760 --> 00:09:51.760]   kind of this bottleneck to get to your object store.
[00:09:51.760 --> 00:09:52.760]   That's kind of how databases work.
[00:09:52.760 --> 00:09:53.760]   And these were blocked stores.
[00:09:53.760 --> 00:09:57.560]   I said network attached storage, but it was actually a storage area network, which was
[00:09:57.560 --> 00:10:02.060]   speaking a block protocol to the server, not a file oriented protocol.
[00:10:02.060 --> 00:10:04.720]   So that's how databases were built at the time.
[00:10:04.720 --> 00:10:09.000]   It was insane to conceive of writing a database that wrote to a file system.
[00:10:09.000 --> 00:10:10.200]   They had to talk to the block layer.
[00:10:10.200 --> 00:10:11.760]   The file system was just going to slow you down.
[00:10:11.760 --> 00:10:16.280]   So yes, we ran Oracle Rack, which was like I said, shared storage distributed compute
[00:10:16.280 --> 00:10:19.480]   and it fell over immediately.
[00:10:19.480 --> 00:10:24.360]   We actually, I remember we hired a DBA, a database administrator, and he quit on his
[00:10:24.360 --> 00:10:25.360]   third day.
[00:10:25.360 --> 00:10:28.800]   He was just like, I've never seen that.
[00:10:28.800 --> 00:10:29.800]   Like, this is crazy.
[00:10:29.800 --> 00:10:30.800]   Like, what are you doing?
[00:10:30.800 --> 00:10:35.240]   So, I was reading a lot of, there's this guy, Tom Kite, who wrote a lot of books about Oracle
[00:10:35.240 --> 00:10:36.240]   database internals.
[00:10:36.240 --> 00:10:41.400]   I was reading a lot of Tom Kite books, learning a lot about like tuning, his early multi-core,
[00:10:41.400 --> 00:10:47.320]   things like Sun Niagara chips were kind of like one of the first multi-core, like, now
[00:10:47.320 --> 00:10:51.720]   we're all stuck with it because Moore's law has basically ended, but it was the beginning
[00:10:51.720 --> 00:10:52.720]   of the end there.
[00:10:52.720 --> 00:10:57.560]   So learning a lot about how to scale up on multi-core settings and then just starting
[00:10:57.560 --> 00:11:01.040]   to look around frantically for something that could scale past that.
[00:11:01.040 --> 00:11:03.560]   So, we had two sources of data at the time.
[00:11:03.560 --> 00:11:06.760]   We have production databases, but then we had the major source of data that just ended
[00:11:06.760 --> 00:11:08.280]   up totally flattening us.
[00:11:08.280 --> 00:11:10.120]   We called it Falcon.
[00:11:10.120 --> 00:11:13.840]   And it was built by a guy named James Wang to power the newsfeed.
[00:11:13.840 --> 00:11:15.080]   And it was just an event log.
[00:11:15.080 --> 00:11:19.120]   So it was the kind of thing that you would pass through Kafka today, but it was just
[00:11:19.120 --> 00:11:21.480]   this homegrown C++ toolkit.
[00:11:21.480 --> 00:11:24.800]   It was eventually replaced by Scribe, which we made open source and was a popular tool
[00:11:24.800 --> 00:11:25.800]   for log tailing.
[00:11:25.800 --> 00:11:27.960]   That was written by a guy named Bobby Johnson.
[00:11:27.960 --> 00:11:31.920]   So the Falcon logs were the vast majority of data, all the event data.
[00:11:31.920 --> 00:11:34.400]   Anytime a user did anything on the site, we'd log it.
[00:11:34.400 --> 00:11:38.560]   And then we wanted to use that to reconstitute information about user activities.
[00:11:38.560 --> 00:11:42.120]   So Falcon is what really ended up just knocking us down.
[00:11:42.120 --> 00:11:47.960]   And so I was frantically looking for a new tech stack beyond just an Oracle RAC instance.
[00:11:47.960 --> 00:11:48.960]   And there were a few alternatives.
[00:11:48.960 --> 00:11:52.960]   So at the time, there were a lot of shared nothing distributed database companies targeting
[00:11:52.960 --> 00:11:54.120]   the data warehousing market.
[00:11:54.120 --> 00:12:00.880]   So Natiza had been very successful using custom Silicon ASICs to accelerate queries and a
[00:12:00.880 --> 00:12:02.420]   shared nothing architecture.
[00:12:02.420 --> 00:12:05.600]   And they had gotten bought by IBM for like 400 plus million.
[00:12:05.600 --> 00:12:09.480]   And that really caused a lot of new entrants to come to the market.
[00:12:09.480 --> 00:12:15.400]   So these were companies like Greenplum, Astro Data, Vertica, Par Excel.
[00:12:15.400 --> 00:12:21.240]   So a lot of interesting distributed database companies, but most of them couldn't scale
[00:12:21.240 --> 00:12:23.240]   to what we needed.
[00:12:23.240 --> 00:12:30.280]   So honestly, the Yahoo experience was what I modeled a lot of our tech stack after.
[00:12:30.280 --> 00:12:34.560]   And you'll be familiar with that from your time there.
[00:12:34.560 --> 00:12:43.640]   So they had a similar SQL querying over event log data infrastructure called Mina, My NetApp,
[00:12:43.640 --> 00:12:46.160]   which unfortunately I didn't spend a lot of time talking publicly about, but I managed
[00:12:46.160 --> 00:12:48.800]   to get to know the people that built it and learn about how it worked.
[00:12:48.800 --> 00:12:53.320]   And it was effectively like a Hadoop-like architecture, but instead of a data node in
[00:12:53.320 --> 00:12:59.320]   a distributed file system, they had NetApp filers where they were querying data over.
[00:12:59.320 --> 00:13:05.360]   And so we hired a guy named Suresh Anthony who built effectively a very rapidly implemented
[00:13:05.360 --> 00:13:10.800]   version of Mina called Cheetah to kind of bridge us between the Oracle era and whatever
[00:13:10.800 --> 00:13:12.320]   came next.
[00:13:12.320 --> 00:13:18.680]   And then we started really looking around and we found the Hadoop group at Yahoo, Eric
[00:13:18.680 --> 00:13:24.120]   Baldischwiler and folks, Owen O'Malley, they were doing, and Doug Cutting, obviously, were
[00:13:24.120 --> 00:13:28.060]   doing some really interesting work to pick up this work that had been published by Google
[00:13:28.060 --> 00:13:34.640]   about MapReduce in the Google file system and implement it as an open source project.
[00:13:34.640 --> 00:13:38.760]   And everybody thought it was insane at Facebook.
[00:13:38.760 --> 00:13:41.600]   Writing stuff on the JVM was just very much frowned upon.
[00:13:41.600 --> 00:13:46.400]   It was a very polyglot programming languages environment, but it was not.
[00:13:46.400 --> 00:13:50.880]   The only exclusion was Java from that zoo.
[00:13:50.880 --> 00:13:55.960]   So it was an uphill battle to convince people that this was going to be something that might
[00:13:55.960 --> 00:14:02.160]   solve our problems, but eventually it became a pretty significant component of our infrastructure.
[00:14:02.160 --> 00:14:07.520]   And we ended up writing a lot of database utilities on top of it.
[00:14:07.520 --> 00:14:12.800]   So a project like Hive, it's what a SQL query interface and a metadata manager in front
[00:14:12.800 --> 00:14:17.160]   of the distributed file system and MapReduce implementation ended up becoming a really
[00:14:17.160 --> 00:14:21.520]   significant component of our analytics tech stack there.
[00:14:21.520 --> 00:14:26.120]   And so it sounds like you had some of this infrastructure built when the growth stopped.
[00:14:26.120 --> 00:14:30.720]   I think a lot of people, myself included, can relate to the pain of growth stopping
[00:14:30.720 --> 00:14:33.800]   and trying to figure out how to get it going again.
[00:14:33.800 --> 00:14:40.120]   I guess, was there some piece of analysis that you felt like you did to get that restarted?
[00:14:40.120 --> 00:14:41.840]   Or was it just a lot of little things?
[00:14:41.840 --> 00:14:44.120]   How did that go down?
[00:14:44.120 --> 00:14:50.000]   I mean, I've actually gotten a cease and desist from Facebook before for saying this in an
[00:14:50.000 --> 00:14:53.920]   interview, but the honest answer is the Hotmail contact importer.
[00:14:53.920 --> 00:14:57.400]   I remember that, yeah.
[00:14:57.400 --> 00:14:59.600]   Yeah, that was the era.
[00:14:59.600 --> 00:15:03.000]   That was the social graph of 2006 to 2008.
[00:15:03.000 --> 00:15:05.200]   It was Hotmail.
[00:15:05.200 --> 00:15:10.160]   Yahoo Mail, to a lesser extent, a tenth, and Gmail even smaller than Yahoo Mail.
[00:15:10.160 --> 00:15:16.280]   So it was really about kind of, what do they call them, dark design tactics or something.
[00:15:16.280 --> 00:15:20.680]   But it was these things where it was like, put in your email address and we'll invite
[00:15:20.680 --> 00:15:26.160]   all your friends and we'll just auto-select all of the emails and obfuscate that.
[00:15:26.160 --> 00:15:31.040]   And if you click OK, we're just going to spam your inbox and spam your mailing list.
[00:15:31.040 --> 00:15:33.960]   And that was really how Facebook grew.
[00:15:33.960 --> 00:15:38.880]   There was a lot of stuff after that that was a lot more targeted.
[00:15:38.880 --> 00:15:44.960]   So in our group, we had a guy named Itamar Rosen, who was my first hire and is still
[00:15:44.960 --> 00:15:45.960]   there.
[00:15:45.960 --> 00:15:49.600]   He's a classmate of mine.
[00:15:49.600 --> 00:15:50.600]   He's still there.
[00:15:50.600 --> 00:15:52.360]   I was just texting with him yesterday.
[00:15:52.360 --> 00:15:55.640]   I got to catch up and see how that's going.
[00:15:55.640 --> 00:15:59.720]   So Itamar, there's a guy, Matt Kohler, who was an executive, who was really one of the
[00:15:59.720 --> 00:16:03.520]   key kind of strategists for early Facebook.
[00:16:03.520 --> 00:16:07.760]   And Kohler, I'm sure at the behest of Mark and some of the board, or potentially it was
[00:16:07.760 --> 00:16:12.160]   his own idea, I'm not sure exactly who, but it was communicated to me through Matt Kohler.
[00:16:12.160 --> 00:16:16.920]   He pulled me and Naomi Gleit, who you may have also been a classmate of, if I know my
[00:16:16.920 --> 00:16:17.920]   Stanford connections.
[00:16:17.920 --> 00:16:23.480]   He pulled me and Naomi and he said, "Hey, growth is an issue.
[00:16:23.480 --> 00:16:25.520]   Let's start dedicating some analyses to it."
[00:16:25.520 --> 00:16:29.600]   And we started meeting regularly and doing analyses.
[00:16:29.600 --> 00:16:31.800]   And Itamar joined not long after.
[00:16:31.800 --> 00:16:35.680]   And so Itamar generated this weekly growth report, which was a set of standard metrics
[00:16:35.680 --> 00:16:37.320]   as well as a deep dive every week.
[00:16:37.320 --> 00:16:42.560]   It was distinct and specific to some high level question we had at the time.
[00:16:42.560 --> 00:16:48.360]   And that growth report, we turned it into a PDF to make it look nice and sent it out
[00:16:48.360 --> 00:16:49.360]   to the company.
[00:16:49.360 --> 00:16:50.360]   Oh, really?
[00:16:50.360 --> 00:16:51.360]   A PDF?
[00:16:51.360 --> 00:16:52.360]   Oh, yeah.
[00:16:52.360 --> 00:16:53.360]   I used a lot of LaTeX back in the day for my math notes in college.
[00:16:53.360 --> 00:16:54.360]   So I like to...
[00:16:54.360 --> 00:16:57.360]   You teed that up in LaTeX and then used that as a company report?
[00:16:57.360 --> 00:16:58.360]   That's amazing.
[00:16:58.360 --> 00:17:03.600]   You do it for like a year and all of a sudden you're fluent.
[00:17:03.600 --> 00:17:07.240]   And so then it's hard to go back because it just looks so much better when it's in like
[00:17:07.240 --> 00:17:08.240]   a nice...
[00:17:08.240 --> 00:17:11.920]   I mean, there's all kinds of better ways to do it today, but that was my solution then.
[00:17:11.920 --> 00:17:15.760]   So yeah, so Itamar would send out the growth report with a lot of input from Naomi and
[00:17:15.760 --> 00:17:20.920]   Kohler and that became sort of a focal point for analyses to better understand growth.
[00:17:20.920 --> 00:17:23.440]   And then ultimately, a growth team was built.
[00:17:23.440 --> 00:17:27.480]   And if I recall correctly, James Wang, the guy that wrote Falcon, ended up being the
[00:17:27.480 --> 00:17:29.640]   engineering manager for that growth team.
[00:17:29.640 --> 00:17:34.200]   And he played a big role in the initial work that they did over there.
[00:17:34.200 --> 00:17:35.200]   Wow.
[00:17:35.200 --> 00:17:36.200]   That was really fun.
[00:17:36.200 --> 00:17:37.200]   Thanks for taking me through that.
[00:17:37.200 --> 00:17:41.360]   And then I guess I have the same question on Cloudera, which is also kind of an iconic
[00:17:41.360 --> 00:17:43.240]   company in data science.
[00:17:43.240 --> 00:17:46.840]   I remember when you were starting it and kind of thinking about the market size would be,
[00:17:46.840 --> 00:17:51.960]   but I guess what really prompted you to start it?
[00:17:51.960 --> 00:17:54.440]   And can you tell me a little bit about the kind of early days of getting that off the
[00:17:54.440 --> 00:17:55.440]   ground?
[00:17:55.440 --> 00:17:56.440]   Sure.
[00:17:56.440 --> 00:18:00.480]   Well, we tried to start it earlier in 2008.
[00:18:00.480 --> 00:18:08.320]   So this guy Christoph Meschilia was at Google and was teaching a MapReduce class at University
[00:18:08.320 --> 00:18:17.020]   of Washington and was really trying to push Google to proselytize their approach to data
[00:18:17.020 --> 00:18:21.360]   management and data analysis into the academic environment.
[00:18:21.360 --> 00:18:24.720]   And he was using Hadoop in that course.
[00:18:24.720 --> 00:18:32.040]   So he was connected to the Hadoop community through that.
[00:18:32.040 --> 00:18:36.760]   So Microsoft made a bid to buy Yahoo in early 2008.
[00:18:36.760 --> 00:18:38.400]   And that catalyzed...
[00:18:38.400 --> 00:18:42.760]   So Christoph and I had been chatting about what would it look like to start a company
[00:18:42.760 --> 00:18:49.320]   to support Hadoop because he needed it for his work and I needed it for my work.
[00:18:49.320 --> 00:18:55.640]   And when Microsoft said they were going to buy Yahoo, then we were like, "Oh boy, we
[00:18:55.640 --> 00:18:57.440]   really need to accelerate the timing on this."
[00:18:57.440 --> 00:18:59.440]   So that was early 2008.
[00:18:59.440 --> 00:19:02.480]   And we had a third guy who was going to be a co-founder, a guy that I had gotten to know
[00:19:02.480 --> 00:19:04.920]   because we interviewed him to be VP of Engineering at Facebook.
[00:19:04.920 --> 00:19:07.280]   And we actually offered him and he turned us down.
[00:19:07.280 --> 00:19:08.920]   Mike Abbott was his name.
[00:19:08.920 --> 00:19:13.080]   So Mike is now at Apple running a big swath of their software development.
[00:19:13.080 --> 00:19:14.080]   And Mike was...
[00:19:14.080 --> 00:19:19.280]   I really hit it off with him during the interview process and I stayed in touch with him.
[00:19:19.280 --> 00:19:21.160]   And I was like, "Hey man, this is..."
[00:19:21.160 --> 00:19:23.160]   He had a lot of experience with database internals.
[00:19:23.160 --> 00:19:27.360]   He had started a company called Composite Software that did federated query, which I
[00:19:27.360 --> 00:19:29.440]   guess today would be called a data mesh.
[00:19:29.440 --> 00:19:32.520]   And Mike was a really smart guy and I really wanted him to come start the company, but
[00:19:32.520 --> 00:19:36.120]   he actually had some personal life issues that made it not really work out.
[00:19:36.120 --> 00:19:42.140]   So it fell apart in March '08, but that got Christoph and I talking and he started working
[00:19:42.140 --> 00:19:47.480]   on his own and he recruited a guy named Mike Olson, who I had followed for a while because
[00:19:47.480 --> 00:19:51.880]   Mike was the CEO of SleepyCast Software, the maker of BerkeleyDB, which is an embedded
[00:19:51.880 --> 00:19:55.320]   database that was very, very successful.
[00:19:55.320 --> 00:19:57.600]   The killer app was like Active Directory.
[00:19:57.600 --> 00:20:02.240]   So Mike had sold his company to Oracle, had done two years and was on the way out.
[00:20:02.240 --> 00:20:04.320]   Christoph had recruited him to...
[00:20:04.320 --> 00:20:07.760]   He actually incorporated the company as Cloudera with two Rs.
[00:20:07.760 --> 00:20:10.120]   And Mike was the CEO.
[00:20:10.120 --> 00:20:15.040]   But another guy, a third guy, Amr Awadallah, who you probably know from your time at Yahoo,
[00:20:15.040 --> 00:20:18.200]   he ran a group called Product Intelligence Engineering that was very successful.
[00:20:18.200 --> 00:20:23.480]   Amr had spun out of Yahoo and was convinced by a guy named Andrew Braccia at Excel to
[00:20:23.480 --> 00:20:25.760]   be an entrepreneur in residence at Excel Partners.
[00:20:25.760 --> 00:20:32.520]   And Amr was actually at the time working on a spot market for cloud resources, which was
[00:20:32.520 --> 00:20:35.760]   very early in 2008 to have this idea.
[00:20:35.760 --> 00:20:38.900]   So we were kind of like, "Maybe this isn't the right time for that.
[00:20:38.900 --> 00:20:40.520]   Maybe someday it'll work."
[00:20:40.520 --> 00:20:47.760]   And so I spun out of Facebook to do an entrepreneur residence program at Excel Partners as well.
[00:20:47.760 --> 00:20:51.880]   And I had actually hooked up with a guy named Eric Vishria, who's now a partner at Benchmark.
[00:20:51.880 --> 00:20:58.480]   And we were working on a consumer energy monitoring, demand monitoring system.
[00:20:58.480 --> 00:21:03.480]   And eventually Amr and I got to chatting and Christoph really catalyzed the whole thing.
[00:21:03.480 --> 00:21:06.880]   So he and Mike were kind of moving forward and Amr and I were kind of like, "We should
[00:21:06.880 --> 00:21:09.440]   probably sort of hop on there."
[00:21:09.440 --> 00:21:15.600]   So Amr, me, Christoph and Mike ended up sort of reconstituting it as Cloudera with one
[00:21:15.600 --> 00:21:20.000]   R and then just refounded the company going forward.
[00:21:20.000 --> 00:21:21.960]   And yeah, that's how it ultimately...
[00:21:21.960 --> 00:21:24.640]   We ended up hiring Doug Cutting about a year later once we had established some credibility,
[00:21:24.640 --> 00:21:27.220]   but it was just the four of us when we got moving.
[00:21:27.220 --> 00:21:28.680]   And what did you work on in the early days?
[00:21:28.680 --> 00:21:34.320]   It must've been a pretty big change going from running a data science team to founding
[00:21:34.320 --> 00:21:35.320]   a company.
[00:21:35.320 --> 00:21:36.320]   Oh yeah, for sure.
[00:21:36.320 --> 00:21:41.400]   On the one hand, yes, on the other hand, no, because at Facebook, it was a very sink or
[00:21:41.400 --> 00:21:43.120]   swim culture.
[00:21:43.120 --> 00:21:47.440]   And I really felt like I built that data team with no real supervision.
[00:21:47.440 --> 00:21:51.280]   I basically went around the block once a week with Adam D'Angelo to just kind of have a
[00:21:51.280 --> 00:21:52.280]   conversation for an hour.
[00:21:52.280 --> 00:21:55.560]   And he was very helpful about kind of just clearing roadblocks for me and helping me
[00:21:55.560 --> 00:21:57.320]   think through strategic things.
[00:21:57.320 --> 00:22:00.680]   But ultimately it was just something that I thought needed to be built and they just
[00:22:00.680 --> 00:22:01.680]   kind of said, "Go build it."
[00:22:01.680 --> 00:22:05.400]   I don't think anyone up top at Facebook was like, "Let's hire 30 people to work on a data
[00:22:05.400 --> 00:22:06.400]   team."
[00:22:06.400 --> 00:22:07.400]   I think I just kept hiring people.
[00:22:07.400 --> 00:22:12.320]   And at some point they looked over and they were like, "That's a pretty big data team."
[00:22:12.320 --> 00:22:17.440]   People talk about like an intrapreneur or whatever, and I guess it did feel a bit like
[00:22:17.440 --> 00:22:18.440]   that.
[00:22:18.440 --> 00:22:21.200]   So I did kind of feel like I was just building a little company inside of Facebook.
[00:22:21.200 --> 00:22:26.000]   And ultimately the Cloudera product roadmap was just sort of like the Facebook data infrastructure
[00:22:26.000 --> 00:22:29.280]   product roadmap, just done as a...
[00:22:29.280 --> 00:22:32.520]   Most of the reason I started Cloudera or I got involved with Cloudera, to be honest,
[00:22:32.520 --> 00:22:38.080]   was I just wanted to see the things that I wanted to build exist in the world.
[00:22:38.080 --> 00:22:40.880]   And I knew that Facebook, they were kind of entering a period where they weren't going
[00:22:40.880 --> 00:22:42.640]   to be quite so excited to...
[00:22:42.640 --> 00:22:46.960]   It was more of a buy versus build period, which made complete sense given the scale
[00:22:46.960 --> 00:22:48.360]   of the business and the success of the business.
[00:22:48.360 --> 00:22:51.280]   So I was kind of like, "Yeah, I'd rather build some of this stuff."
[00:22:51.280 --> 00:22:53.620]   So yeah, so we got to work.
[00:22:53.620 --> 00:22:59.240]   Hiring was obviously a lot harder to hire for a random startup versus the hottest startup
[00:22:59.240 --> 00:23:00.240]   in Silicon Valley.
[00:23:00.240 --> 00:23:04.760]   So I had to do a lot of legwork on hiring and then just figuring out what to build.
[00:23:04.760 --> 00:23:09.000]   So sequencing, I knew what the end state was going to look like, but I didn't know how
[00:23:09.000 --> 00:23:10.540]   we were going to get there.
[00:23:10.540 --> 00:23:14.120]   So figuring out what to build first was pretty hard.
[00:23:14.120 --> 00:23:18.560]   So we started with a couple of open source projects to just get data into the Cloudera
[00:23:18.560 --> 00:23:23.120]   environment, a project called Scoop and a project called Flume that were dedicated to
[00:23:23.120 --> 00:23:25.520]   database and log data in particular.
[00:23:25.520 --> 00:23:30.120]   Honestly, I saw Splunk at the time and I was like, "I want to get to a pricing structure
[00:23:30.120 --> 00:23:31.200]   that looks like that."
[00:23:31.200 --> 00:23:40.040]   I think the reason why data companies work in 2021 is the consumption-based pricing and
[00:23:40.040 --> 00:23:44.880]   Splunk had that figured out in 2005.
[00:23:44.880 --> 00:23:46.520]   We never really could figure it out at Cloudera.
[00:23:46.520 --> 00:23:50.520]   We ended up getting stuck with a more Oracle Teradata-like pricing model.
[00:23:50.520 --> 00:23:58.080]   So yeah, so we were working on effectively filling out the stack to become a vertically
[00:23:58.080 --> 00:24:02.120]   integrated data platform, whatever they're calling them these days, but a place where
[00:24:02.120 --> 00:24:07.880]   you would collect data, put it, structure it, query it, analyze it, fit models to it.
[00:24:07.880 --> 00:24:12.400]   What Snowflake and Databricks are trying to build today, it was a very obvious product
[00:24:12.400 --> 00:24:13.400]   roadmap.
[00:24:13.400 --> 00:24:14.400]   So that's what we want to build.
[00:24:14.400 --> 00:24:17.240]   We just couldn't figure out how to build it or how to get there, what the right sequencing
[00:24:17.240 --> 00:24:18.240]   was to get there.
[00:24:18.240 --> 00:24:21.320]   And the other thing that we had to do is swap out components over time.
[00:24:21.320 --> 00:24:27.480]   We all knew that there was a shelf life to the core Hadoop projects.
[00:24:27.480 --> 00:24:30.280]   And so we were kind of trying to think beyond it.
[00:24:30.280 --> 00:24:36.640]   And so how do you make that transition from these legacy products to what we felt could
[00:24:36.640 --> 00:24:40.800]   actually service production enterprise workloads competitively with what other vendors were
[00:24:40.800 --> 00:24:41.800]   offering.
[00:24:41.800 --> 00:24:47.880]   So things like Impala for a query engine or Kudu for table storage were always something
[00:24:47.880 --> 00:24:51.360]   we wanted to build, but just had to figure out when and how to get it out.
[00:24:51.360 --> 00:24:55.440]   I mean, I think one thing that was kind of interesting at the time, I mean, it seems
[00:24:55.440 --> 00:24:59.360]   so wrong in retrospect that it's hard to believe people thought this, but I remember
[00:24:59.360 --> 00:25:05.240]   actually talking to Matt Kohler about Cloudera and he was thinking, how many companies would
[00:25:05.240 --> 00:25:06.320]   really use this?
[00:25:06.320 --> 00:25:10.080]   Maybe it's like tens or maybe like a hundred or something like that at the time.
[00:25:10.080 --> 00:25:14.880]   And I think even you expressed a little bit of doubt to me when you were starting.
[00:25:14.880 --> 00:25:21.600]   Did you feel worried about the market size or how did you think about that?
[00:25:21.600 --> 00:25:24.400]   Were you just sure that it would work or was that-
[00:25:24.400 --> 00:25:30.000]   No, I mean, for me, it was about manifesting a product vision, not about building a huge
[00:25:30.000 --> 00:25:31.000]   company.
[00:25:31.000 --> 00:25:32.000]   Interesting.
[00:25:32.000 --> 00:25:38.000]   So I didn't expect it to get as big as it did or people to care as much as they did.
[00:25:38.000 --> 00:25:41.800]   When I was leaving Facebook, I kind of wanted to work on like a super nerdy infrastructure
[00:25:41.800 --> 00:25:43.800]   software company.
[00:25:43.800 --> 00:25:47.840]   Like what could be nerdier than Hadoop?
[00:25:47.840 --> 00:25:55.080]   And like within a year we were in the New York Times and that part of the hype around
[00:25:55.080 --> 00:25:57.480]   it was always a huge turnoff to me.
[00:25:57.480 --> 00:25:59.480]   It wasn't something that I wanted.
[00:25:59.480 --> 00:26:06.040]   I wanted to hire like the best engineers from Sun and VMware and Oracle and Google and get
[00:26:06.040 --> 00:26:10.680]   them to build open source infrastructure that would allow any company to do what Google
[00:26:10.680 --> 00:26:11.680]   could do.
[00:26:11.680 --> 00:26:13.160]   Like that was what I wanted to do.
[00:26:13.160 --> 00:26:17.560]   And whether or not it had commercial value at the scale that would necessitate like venture
[00:26:17.560 --> 00:26:22.060]   returns, it wasn't that critical to me because we didn't raise that much money.
[00:26:22.060 --> 00:26:24.580]   Our series A was $5 million.
[00:26:24.580 --> 00:26:26.840]   Our series B was like $8 or $9 million.
[00:26:26.840 --> 00:26:29.360]   Like these aren't even like seed rounds anymore.
[00:26:29.360 --> 00:26:34.160]   So what we were building was different from what it became.
[00:26:34.160 --> 00:26:38.360]   And so I never really, I mean, I agree with Kohler at the time, like it was, I didn't
[00:26:38.360 --> 00:26:42.680]   worry about who was going to use this because I just worried about kind of completing the
[00:26:42.680 --> 00:26:46.440]   product and I just knew everybody was going to need it to be honest.
[00:26:46.440 --> 00:26:47.600]   Everybody was going to have petabyte scale data.
[00:26:47.600 --> 00:26:51.320]   I didn't know in what form they were going to be storing and analyzing it, but I wanted
[00:26:51.320 --> 00:26:55.280]   to solve problems to facilitate that world.
[00:26:55.280 --> 00:26:59.000]   But yeah, our series B was a brutal fundraise.
[00:26:59.000 --> 00:27:02.160]   Our series A was easy because Amr and I were both entrepreneurs and residents.
[00:27:02.160 --> 00:27:05.400]   And so we had two partners who loved us and believed in us and they would have given us
[00:27:05.400 --> 00:27:08.040]   money to start whatever we wanted.
[00:27:08.040 --> 00:27:13.320]   But then our series B, yeah, we ran around Sandhill and I actually remember I got a nice
[00:27:13.320 --> 00:27:19.200]   note from Dana Stadler at Matrix Partners a few years after, because he just like beat
[00:27:19.200 --> 00:27:23.560]   us up in the pitch where he was just like, I don't ever expect you'll get a seven figure
[00:27:23.560 --> 00:27:24.560]   deal for this.
[00:27:24.560 --> 00:27:29.000]   He was like, and you'll probably get less than 10, you know, six figure deals for this.
[00:27:29.000 --> 00:27:30.680]   Like, it's just, there just isn't a market.
[00:27:30.680 --> 00:27:32.320]   You should just pack it up now.
[00:27:32.320 --> 00:27:35.200]   This was like a science project.
[00:27:35.200 --> 00:27:38.360]   And you know, you're in those meetings and you just hear that over and over and over
[00:27:38.360 --> 00:27:41.880]   again and it's kind of like, yeah, that's like a valid position to take.
[00:27:41.880 --> 00:27:44.320]   I didn't necessarily disagree with it.
[00:27:44.320 --> 00:27:46.440]   So yeah, I couldn't be happier.
[00:27:46.440 --> 00:27:50.080]   And the fact that they're still focused on open source is quite cool.
[00:27:50.080 --> 00:27:53.360]   Do you feel any frustration that they're not a more iconic company?
[00:27:53.360 --> 00:27:56.360]   I mean, they were so early with the strategy that's worked so well.
[00:27:56.360 --> 00:28:00.320]   And it's hard to say like, I don't know, whatever their $5 billion market cap is, you know,
[00:28:00.320 --> 00:28:04.360]   not a wild success, but it does sort of seem like they missed kind of people shifting to
[00:28:04.360 --> 00:28:05.360]   Spark.
[00:28:05.360 --> 00:28:09.080]   Like, does that feel, I don't know, do you, does that bother you?
[00:28:09.080 --> 00:28:12.760]   Well, I mean, I'm kind of weird in that, like, I don't like big companies.
[00:28:12.760 --> 00:28:20.520]   So to me, it's not a success if you have like a hundred billion dollar market cap, but you've
[00:28:20.520 --> 00:28:25.040]   got all closed source software and you have it like, like, so to me, I always talked about
[00:28:25.040 --> 00:28:31.360]   Cloudera as like an engine for turning, you know, VC first and then company enterprise
[00:28:31.360 --> 00:28:33.240]   dollars into open source software.
[00:28:33.240 --> 00:28:35.800]   So for me, I look at the public goods that were created.
[00:28:35.800 --> 00:28:39.560]   So I look at the standards, the software, those kinds of things.
[00:28:39.560 --> 00:28:44.240]   And so in that sense, I, and honestly, like I made plenty of money, I'm going to be okay.
[00:28:44.240 --> 00:28:49.760]   So I really like people who want another zero, at this point, it's all going to some kind
[00:28:49.760 --> 00:28:50.760]   of like foundation.
[00:28:50.760 --> 00:28:51.760]   You know what I mean?
[00:28:51.760 --> 00:28:55.040]   Like there's no like material need that's going to be resolved by if there was another
[00:28:55.040 --> 00:28:57.400]   zero on the end of Cloudera's valuations.
[00:28:57.400 --> 00:29:03.160]   I honestly don't know why people want more money than what we were able to make.
[00:29:03.160 --> 00:29:05.600]   And that was honestly a pretty big surprise anyway.
[00:29:05.600 --> 00:29:07.120]   I didn't start Cloudera to make money.
[00:29:07.120 --> 00:29:16.080]   So, for me, I look at things like, you know, Arrow and Parquet and Ibis and other kinds
[00:29:16.080 --> 00:29:21.600]   of like open source infrastructure, even Hue, our user interface has become adopted by pretty
[00:29:21.600 --> 00:29:23.240]   much all the cloud providers.
[00:29:23.240 --> 00:29:28.780]   So I look more at like, how do you change the tools that people use and how do you change
[00:29:28.780 --> 00:29:29.780]   their thinking?
[00:29:29.780 --> 00:29:35.780]   And so, you know, Impala was really the first open source vectorized code gen distributed
[00:29:35.780 --> 00:29:37.340]   query engine.
[00:29:37.340 --> 00:29:39.540]   And it was something that everybody knew we needed to build.
[00:29:39.540 --> 00:29:42.300]   And I was really proud of it when we built it.
[00:29:42.300 --> 00:29:46.060]   And like, whose name is on the Jersey at the end of the day, I don't really care.
[00:29:46.060 --> 00:29:51.060]   So it was more about kind of like impacting the universe of ideas and public goods.
[00:29:51.060 --> 00:29:53.500]   And I'm really happy with a lot of the work that we did.
[00:29:53.500 --> 00:30:01.780]   I mean, I will say, I think just being on the JVM is just tough for day to day developers.
[00:30:01.780 --> 00:30:07.980]   So it was hard to, you know, you can impact enterprise, but ultimately, like no one uses
[00:30:07.980 --> 00:30:10.260]   enterprise stuff in their day to day.
[00:30:10.260 --> 00:30:14.420]   Like Snowflake is a huge company and they've built great technology, but it doesn't change
[00:30:14.420 --> 00:30:19.700]   how I do data analysis on a day to day because like, I just I don't need like a super expensive
[00:30:19.700 --> 00:30:22.900]   data warehouse for my like day to day data analysis.
[00:30:22.900 --> 00:30:29.260]   And that was, you know, so we built a lot of stuff off the JVM at Cloudera subsequent
[00:30:29.260 --> 00:30:30.260]   to founding.
[00:30:30.260 --> 00:30:34.700]   And I guess I just, it was a funny era to get stuck in JVM.
[00:30:34.700 --> 00:30:36.380]   I wish we'd have pushed more Python.
[00:30:36.380 --> 00:30:41.100]   I mean, we ended up buying Datapad, Wes McKinney's company, and we had Wes McKinney in the company
[00:30:41.100 --> 00:30:42.420]   for a while.
[00:30:42.420 --> 00:30:45.220]   And it was after I was, I kind of checked out.
[00:30:45.220 --> 00:30:47.620]   I was like founder emeritus at the time, I referred to myself.
[00:30:47.620 --> 00:30:51.740]   So I could never really convince our head of product management to like really push
[00:30:51.740 --> 00:30:54.220]   on the Python ecosystem harder.
[00:30:54.220 --> 00:30:56.620]   But yeah, you can kind of see that's where everybody's going now.
[00:30:56.620 --> 00:31:00.860]   And I think if there's anything that I regret, it's not being able to influence people to
[00:31:00.860 --> 00:31:03.700]   get more into like the PyData ecosystem sooner.
[00:31:03.700 --> 00:31:04.700]   Interesting.
[00:31:04.700 --> 00:31:09.380]   And I mean, I guess I also wanted to ask you about this incredible career transition that
[00:31:09.380 --> 00:31:12.980]   you made that I'm just so impressed by to go into research.
[00:31:12.980 --> 00:31:15.900]   Can you talk about like how you did that?
[00:31:15.900 --> 00:31:20.420]   Like how you got up to speed enough to start your lab, how you learned about almost like
[00:31:20.420 --> 00:31:22.260]   a totally different field?
[00:31:22.260 --> 00:31:24.700]   Yeah, totally.
[00:31:24.700 --> 00:31:30.460]   So 2012-ish at Cloudera, we were four years in and it was bigger than I ever expected
[00:31:30.460 --> 00:31:31.460]   it to be.
[00:31:31.460 --> 00:31:36.180]   I'd replaced myself twice, first as VP product and then VP of data science.
[00:31:36.180 --> 00:31:38.380]   I'd hired people who were better than me at that job.
[00:31:38.380 --> 00:31:42.780]   So the only thing left to do is kind of hire a professional CEO.
[00:31:42.780 --> 00:31:44.700]   And we kicked off that search.
[00:31:44.700 --> 00:31:49.980]   And to be honest, I was also having a lot of sort of misgivings and also health issues
[00:31:49.980 --> 00:31:58.660]   that just made sort of being a high intensity startup founder, executive job in San Francisco
[00:31:58.660 --> 00:31:59.900]   just very unpleasant to me.
[00:31:59.900 --> 00:32:05.060]   And when I was thinking about what I wanted to do next, I really wanted to focus on finding
[00:32:05.060 --> 00:32:11.100]   a domain where I could do data science and not get bored of the entities under analysis.
[00:32:11.100 --> 00:32:15.140]   So I'd started my career on Wall Street and very quickly realized I didn't really want
[00:32:15.140 --> 00:32:17.060]   to think about money all day.
[00:32:17.060 --> 00:32:21.060]   And then I moved to Facebook and pretty quickly realized I didn't want to think about how
[00:32:21.060 --> 00:32:23.980]   people like navigate consumer web products all day.
[00:32:23.980 --> 00:32:29.060]   But I loved the software methods at both jobs.
[00:32:29.060 --> 00:32:30.500]   Like I really, it was like a weird thing.
[00:32:30.500 --> 00:32:31.740]   I really enjoyed my jobs.
[00:32:31.740 --> 00:32:37.260]   I just could not care less about what the product was at each of those jobs.
[00:32:37.260 --> 00:32:41.260]   And so Clutter was always to me like a way point where I was like, "Hey, I want to be
[00:32:41.260 --> 00:32:43.300]   able to do data analysis scale.
[00:32:43.300 --> 00:32:46.300]   Tools don't exist to do that with open source software."
[00:32:46.300 --> 00:32:50.660]   So like this is our best hope of just getting some tools for doing data analysis scale into
[00:32:50.660 --> 00:32:51.660]   the world.
[00:32:51.660 --> 00:32:52.660]   So I'm going to do that.
[00:32:52.660 --> 00:32:54.060]   But I always like, I do data analysis.
[00:32:54.060 --> 00:32:58.660]   I don't necessarily see myself making tools for data analysis for the rest of my life.
[00:32:58.660 --> 00:33:04.760]   And so in 2012, I started thinking about like different domains where I might not get bored.
[00:33:04.760 --> 00:33:10.740]   And biomedicine was just a big expansive domain where I thought there's a lot of sophisticated
[00:33:10.740 --> 00:33:15.040]   work happening, but the technical infrastructure was actually pretty limited.
[00:33:15.040 --> 00:33:21.340]   We had sold into pharma companies at Cloudera and they were some of the last to adopt modern
[00:33:21.340 --> 00:33:22.780]   technology stacks.
[00:33:22.780 --> 00:33:27.340]   We had partnered with some large academic institutions and I saw their infrastructure
[00:33:27.340 --> 00:33:30.100]   and it was very outmoded and slow moving.
[00:33:30.100 --> 00:33:33.580]   And so I thought, "Oh, hey, like there's some things that we learned over here that could
[00:33:33.580 --> 00:33:37.580]   be useful over there and I probably won't get bored of what's going on."
[00:33:37.580 --> 00:33:39.180]   And I had gotten to know...
[00:33:39.180 --> 00:33:44.220]   So in 2008, when I left Facebook, I had looked into the biomedical domain to do a startup
[00:33:44.220 --> 00:33:47.540]   and I had met a bunch of interesting companies at the time.
[00:33:47.540 --> 00:33:51.380]   So this is like when 23andMe was getting started and oh, there's another company that was just
[00:33:51.380 --> 00:33:53.820]   like 23andMe that I went and visited as well.
[00:33:53.820 --> 00:33:54.820]   I can't remember their name.
[00:33:54.820 --> 00:34:01.860]   But so I got to know a group of people in the biomedical field who had started a nonprofit
[00:34:01.860 --> 00:34:07.300]   called Sage Bionetworks that was creating a shared infrastructure for storing and analyzing
[00:34:07.300 --> 00:34:11.740]   data in a pre-competitive open source fashion.
[00:34:11.740 --> 00:34:17.020]   And they asked me to come and advise them on data infrastructure and open source strategies
[00:34:17.020 --> 00:34:20.420]   as they were creating this nonprofit and eventually asked me to join the board.
[00:34:20.420 --> 00:34:24.460]   So I served on the board of that nonprofit and through that lens, I got to see and meet
[00:34:24.460 --> 00:34:28.820]   a lot of interesting people and it kind of helped confirm for me that this was a field
[00:34:28.820 --> 00:34:31.220]   that I would enjoy working in.
[00:34:31.220 --> 00:34:37.260]   And ultimately what catalyzed me moving into an actual role in that field was Eric Schott,
[00:34:37.260 --> 00:34:42.100]   one of my fellow board members at Sage Bionetworks, one of the creators of Sage Bionetworks.
[00:34:42.100 --> 00:34:48.260]   He was recruited to run the Department of Genetics at Mount Sinai in New York City.
[00:34:48.260 --> 00:34:52.340]   And I like New York a lot more than San Francisco.
[00:34:52.340 --> 00:34:56.180]   I moved to San Francisco from New York and I was very dismayed.
[00:34:56.180 --> 00:34:58.620]   I was like, I thought this was supposed to be a city.
[00:34:58.620 --> 00:35:03.060]   Everything closes at midnight or two, I don't remember when it closed.
[00:35:03.060 --> 00:35:05.580]   It certainly wasn't 4 a.m. in New York City.
[00:35:05.580 --> 00:35:09.100]   And it was so tiny and the public transportation was terrible.
[00:35:09.100 --> 00:35:12.140]   So I was always very underwhelmed with San Francisco as a place to live.
[00:35:12.140 --> 00:35:14.480]   It was so cold all the time.
[00:35:14.480 --> 00:35:21.540]   So I was very excited about New York City as a place to live relative to San Francisco.
[00:35:21.540 --> 00:35:26.900]   And I was excited about doing something in the biomedical domain with software and data.
[00:35:26.900 --> 00:35:31.980]   And it was actually, we were getting beers at the Nuthouse in Palo Alto, which I'm sure
[00:35:31.980 --> 00:35:33.340]   you know.
[00:35:33.340 --> 00:35:38.580]   And he just kind of said, he was having me kind of talk to people over there to kind
[00:35:38.580 --> 00:35:39.900]   of just talk them through what they could build.
[00:35:39.900 --> 00:35:44.700]   And he was like, what would you think about just being out here with an actual position
[00:35:44.700 --> 00:35:45.700]   at Mount Sinai?
[00:35:45.700 --> 00:35:48.640]   And I thought about it and ultimately I was like, okay, that sounds fun.
[00:35:48.640 --> 00:35:51.860]   So we kind of worked something out with Cloudera where I was notionally part-time.
[00:35:51.860 --> 00:35:54.900]   So I was going back and forth between San Francisco and New York for a while.
[00:35:54.900 --> 00:35:59.260]   And then in the fall of 2013, this was really when I was like full-time in New York and
[00:35:59.260 --> 00:36:01.300]   started hiring people into the lab.
[00:36:01.300 --> 00:36:04.740]   So I had a year to just like read a lot of textbooks, talk to a lot of the people who
[00:36:04.740 --> 00:36:07.060]   were working around, play around with the software.
[00:36:07.060 --> 00:36:08.060]   I've always been autodidactic.
[00:36:08.060 --> 00:36:09.820]   I got terrible grades in school.
[00:36:09.820 --> 00:36:13.780]   It was always about like reading and thinking more than it was about like doing homework
[00:36:13.780 --> 00:36:14.780]   for me.
[00:36:14.780 --> 00:36:17.780]   But you got terrible grades, but you went to Harvard, right?
[00:36:17.780 --> 00:36:18.780]   Yeah.
[00:36:18.780 --> 00:36:21.740]   So it's a little bit complicated.
[00:36:21.740 --> 00:36:23.140]   I had a good SAT score.
[00:36:23.140 --> 00:36:25.540]   I started getting terrible grades junior year of high school.
[00:36:25.540 --> 00:36:30.980]   So I had, I guess, enough good grades to sort of buoy my grades, my overall GPA.
[00:36:30.980 --> 00:36:32.380]   And then I played baseball.
[00:36:32.380 --> 00:36:38.580]   So I ended up getting into Harvard primarily as an athlete and an SAT score and like a
[00:36:38.580 --> 00:36:39.580]   decent GPA.
[00:36:39.580 --> 00:36:45.180]   But yeah, so I was, I, yeah, it was basically like once I hit 16 that I stopped caring about
[00:36:45.180 --> 00:36:46.180]   school.
[00:36:46.180 --> 00:36:51.540]   So yeah, I think early Jeff was engaged enough to achieve a GPA that was not going to be
[00:36:51.540 --> 00:36:55.780]   fully dismissed by Harvard during the admissions process, thankfully.
[00:36:55.780 --> 00:37:00.380]   But yeah, I guess you've done an incredible job of quickly learning really hard topics.
[00:37:00.380 --> 00:37:03.620]   So I mean, yeah, that, that, that makes sense.
[00:37:03.620 --> 00:37:07.300]   So you, you got up to speed on, I mean, I actually like, I tried to research all the
[00:37:07.300 --> 00:37:10.980]   people that I talked to and I was looking through your list of papers and I could barely
[00:37:10.980 --> 00:37:15.540]   like parse the title to them, honestly.
[00:37:15.540 --> 00:37:16.820]   Yeah.
[00:37:16.820 --> 00:37:20.560]   You know, you talk to people who are doing work, you read papers, like review papers
[00:37:20.560 --> 00:37:25.460]   are key for me, you know, finding a good review paper on a topic and then figuring out who
[00:37:25.460 --> 00:37:29.260]   wrote it and then what their research research is.
[00:37:29.260 --> 00:37:32.860]   And just finding like kindred spirits, people who think like you do and being able to just
[00:37:32.860 --> 00:37:38.140]   converse with them and interactively map a domain.
[00:37:38.140 --> 00:37:42.580]   You know, I had had biology education previously, like thankfully Harvard is a liberal arts
[00:37:42.580 --> 00:37:43.580]   education.
[00:37:43.580 --> 00:37:49.300]   So I had done courses on DNA and neuroscience and molecular biology.
[00:37:49.300 --> 00:37:50.640]   So I had the basics.
[00:37:50.640 --> 00:37:55.340]   So, so yeah, just read a lot of papers and like software is a good angle.
[00:37:55.340 --> 00:38:02.060]   So like I used to reference a lot John Tukey, who's kind of a proto data scientist.
[00:38:02.060 --> 00:38:05.740]   And he has a quote where he said, you know, I love being a statistician because I get
[00:38:05.740 --> 00:38:08.060]   to play in everyone's backyard.
[00:38:08.060 --> 00:38:11.900]   So I was kind of using like data science as like a backdoor to problems where it was like,
[00:38:11.900 --> 00:38:14.380]   I could, I could talk to people, figure out what they're working on and kind of figure
[00:38:14.380 --> 00:38:21.140]   out how the software and algorithms, like analytical methods they were using mapped
[00:38:21.140 --> 00:38:27.740]   problems that I'd worked on previously and, you know, sort of use those analogies to move
[00:38:27.740 --> 00:38:32.820]   sideways from work that I had done outside of the biomedical domain into the biomedical
[00:38:32.820 --> 00:38:33.820]   domains.
[00:38:33.820 --> 00:38:37.820]   There's a lot of problems that you can find analogies for and choose methods for.
[00:38:37.820 --> 00:38:43.220]   So, you know, in particular, we were able to find a really cool problem in a domain
[00:38:43.220 --> 00:38:44.740]   of cancer immunotherapy.
[00:38:44.740 --> 00:38:54.140]   So when I was moving into biomedicine, 2012 was really sort of, so 2011 was a milestone
[00:38:54.140 --> 00:39:00.580]   year for the approval of a immune checkpoint blockade drug.
[00:39:00.580 --> 00:39:05.700]   So this was a drug, which rather than targeting anything related to cancer, it was actually
[00:39:05.700 --> 00:39:07.700]   targeting the immune system.
[00:39:07.700 --> 00:39:12.260]   And so what it was actually targeting was like a T cell is a cell in your immune system
[00:39:12.260 --> 00:39:14.940]   that's responsible for cellular immunity for killing bad cells.
[00:39:14.940 --> 00:39:16.900]   And so cancer cells are bad cells.
[00:39:16.900 --> 00:39:22.460]   And so T cells were believed to be kind of the mediator of the immune response to cancer.
[00:39:22.460 --> 00:39:24.020]   And there was this protein.
[00:39:24.020 --> 00:39:29.140]   So when a T cell gets angry and starts wanting to kill stuff, it expresses an off switch
[00:39:29.140 --> 00:39:31.940]   because it's very important that you'd be able to turn T cells off.
[00:39:31.940 --> 00:39:35.700]   T cells are very destructive and your body needs to be able to like resolve the immune
[00:39:35.700 --> 00:39:37.140]   response.
[00:39:37.140 --> 00:39:39.340]   And so the T cell exposes this off switch.
[00:39:39.340 --> 00:39:43.700]   And the notion behind immune checkpoint blockade is cancer might've figured out how to press
[00:39:43.700 --> 00:39:45.100]   that off switch.
[00:39:45.100 --> 00:39:49.620]   And so what if we basically covered up the off switch and we made it so that T cells
[00:39:49.620 --> 00:39:51.840]   couldn't be turned off by cancer?
[00:39:51.840 --> 00:39:57.300]   Perhaps that would cause the immune response to cancer to fully eradicate the tumor.
[00:39:57.300 --> 00:40:02.780]   And it works for a shockingly high percentage of people.
[00:40:02.780 --> 00:40:08.540]   And the most exciting thing about immune checkpoint blockade at the time was these Kaplan-Meier
[00:40:08.540 --> 00:40:14.940]   curves, these survival curves, where you could see that the immune checkpoint blockade was
[00:40:14.940 --> 00:40:20.020]   raising the floor for long-term survival of patients.
[00:40:20.020 --> 00:40:24.940]   It wasn't just advancing survival by a few months or years.
[00:40:24.940 --> 00:40:28.140]   And then ultimately everyone had the same sort of 10 year outcomes.
[00:40:28.140 --> 00:40:31.100]   It was like genuinely changing like five to 10 year outcomes.
[00:40:31.100 --> 00:40:35.120]   And obviously it took a long time to see that, but those results are holding.
[00:40:35.120 --> 00:40:41.340]   And that kind of durable response to cancer was like wildly unusual.
[00:40:41.340 --> 00:40:42.340]   And then-
[00:40:42.340 --> 00:40:44.940]   So is that something you worked on?
[00:40:44.940 --> 00:40:47.480]   So, I mean, ultimately, yes.
[00:40:47.480 --> 00:40:52.180]   So when I came to Mount Sinai, I'd never heard of it, but there was a principal investigator
[00:40:52.180 --> 00:40:54.660]   at Mount Sinai named Nina Bardwaj.
[00:40:54.660 --> 00:41:04.220]   And Nina was a very successful immunologist who was pursuing a few ideas for ways of stimulating
[00:41:04.220 --> 00:41:07.060]   an immune response to cancer.
[00:41:07.060 --> 00:41:14.320]   And one of the things that she was very early on was an approach called a neoantigen vaccine.
[00:41:14.320 --> 00:41:16.020]   And so this is a therapeutic vaccine.
[00:41:16.020 --> 00:41:18.580]   So most people think of prophylactic or protective vaccines.
[00:41:18.580 --> 00:41:21.020]   So something you get so that you don't get a disease.
[00:41:21.020 --> 00:41:26.300]   Therapeutic vaccines are given to stimulate a specific immune response while you currently
[00:41:26.300 --> 00:41:29.040]   have the disease with a goal of curing it.
[00:41:29.040 --> 00:41:32.820]   So a neoantigen vaccine is a therapeutic vaccine.
[00:41:32.820 --> 00:41:37.580]   And so an antigen is a specific target of the immune response.
[00:41:37.580 --> 00:41:45.420]   And a neoantigen is an antigen created inside of a tumor cell due to the mutations that
[00:41:45.420 --> 00:41:46.740]   the tumor accrues.
[00:41:46.740 --> 00:41:49.940]   So cancer is a disease of the genome.
[00:41:49.940 --> 00:41:56.020]   The way that a cell becomes cancerous is that it accumulates mutations that equip it with
[00:41:56.020 --> 00:41:59.620]   behaviors that allow it to grow out of control.
[00:41:59.620 --> 00:42:02.700]   And often there's kind of a positive feedback cycle.
[00:42:02.700 --> 00:42:08.540]   So getting additional mutations might damage like your DNA repair machinery, for example,
[00:42:08.540 --> 00:42:11.380]   that then causes you to accumulate even more mutations.
[00:42:11.380 --> 00:42:15.940]   So a lot of cancers have accumulated many mutations.
[00:42:15.940 --> 00:42:19.160]   And the more mutations you've accumulated, the more likely that one of those mutations
[00:42:19.160 --> 00:42:25.020]   is to have changed a protein produced by that cell in a way that causes that protein to
[00:42:25.020 --> 00:42:29.540]   become immunogenic, that is to create an immune response directed against it.
[00:42:29.540 --> 00:42:35.460]   So neoantigens are those sub-sequences of amino acids inside of proteins that have been
[00:42:35.460 --> 00:42:41.300]   altered by mutations accumulated by the tumor cells, which create these novel or neo-antigenic
[00:42:41.300 --> 00:42:43.740]   targets for cancer.
[00:42:43.740 --> 00:42:49.660]   And so the idea was, what if we could sequence someone's tumor, sequence their normal tissue,
[00:42:49.660 --> 00:42:55.100]   look for mutations that are in the tumor but not in the normal tissue, and figure out which
[00:42:55.100 --> 00:43:00.140]   one of those mutations might generate an immune response for this particular patient.
[00:43:00.140 --> 00:43:05.100]   And for this particular patient, can we then synthesize a vaccine which will stimulate
[00:43:05.100 --> 00:43:12.340]   an immune response specifically against those neoantigens in their tumor, suited for their
[00:43:12.340 --> 00:43:13.340]   immune system?
[00:43:13.340 --> 00:43:14.660]   Because everyone has a different immune...
[00:43:14.660 --> 00:43:18.740]   So everyone's tumor is unique, but also everyone's immune system is unique.
[00:43:18.740 --> 00:43:24.020]   And so this is, if you ever have to do like tissue or organ transplant, you get HLA typing
[00:43:24.020 --> 00:43:25.020]   done.
[00:43:25.020 --> 00:43:30.940]   And the HLA type is what effectively determines which amino acid sub-sequences of a protein
[00:43:30.940 --> 00:43:32.380]   your immune system cares about.
[00:43:32.380 --> 00:43:33.900]   So you had kind of two inputs.
[00:43:33.900 --> 00:43:38.900]   You had the HLA type of a patient, and then you had the somatic mutations, that is the
[00:43:38.900 --> 00:43:42.660]   mutations present in the tumor and not in the germline tissue.
[00:43:42.660 --> 00:43:48.780]   And those became inputs into a predictive algorithm that would predict, these are the
[00:43:48.780 --> 00:43:51.180]   most likely to generate a response to neoantigens.
[00:43:51.180 --> 00:43:55.340]   And so that was kind of like the data science problem that we identified embedded within
[00:43:55.340 --> 00:43:57.340]   this larger research.
[00:43:57.340 --> 00:44:04.220]   And at the time, Nina's group was just leveraging a web server built by another group that generated
[00:44:04.220 --> 00:44:05.220]   predictions for her.
[00:44:05.220 --> 00:44:09.420]   And so we kind of looked at it and said, "Oh, hey, maybe we can build you a better predictor
[00:44:09.420 --> 00:44:10.980]   of neoantigens."
[00:44:10.980 --> 00:44:14.820]   And then ultimately she was very trusting and allowed us to participate in the phase
[00:44:14.820 --> 00:44:16.080]   one clinical trial.
[00:44:16.080 --> 00:44:20.900]   So our group wrote the computational component of the clinical trial protocol, and ultimately
[00:44:20.900 --> 00:44:24.860]   administered the computational algorithms that generated the vaccines that went into
[00:44:24.860 --> 00:44:25.860]   like actual humans.
[00:44:25.860 --> 00:44:30.940]   So that was like a pretty fun research project to be involved in.
[00:44:30.940 --> 00:44:35.580]   And ultimately the software we wrote called McFlurry is, so finally it gets to something
[00:44:35.580 --> 00:44:40.380]   that might matter to your listeners now that we're like, what, 48 minutes into the conversation.
[00:44:40.380 --> 00:44:43.440]   If you made it this far, machine learning happens here.
[00:44:43.440 --> 00:44:49.180]   So we ended up building a neural network that predicted neoantigens called McFlurry that's
[00:44:49.180 --> 00:44:54.540]   now one of the better approaches and is still actively developed by several people.
[00:44:54.540 --> 00:44:56.860]   So just two questions to make sure I understand what's going on here.
[00:44:56.860 --> 00:45:02.260]   So one, does this mean that every single person gets a slightly different medicine based on
[00:45:02.260 --> 00:45:04.520]   their...
[00:45:04.520 --> 00:45:08.180]   And so can you even do a clinical trial where everyone's getting different...
[00:45:08.180 --> 00:45:11.660]   I always just sort of imagine a clinical trial, like everyone gets the same thing.
[00:45:11.660 --> 00:45:15.220]   I guess in this case, everyone sort of gets the same process.
[00:45:15.220 --> 00:45:16.220]   Is that right?
[00:45:16.220 --> 00:45:17.220]   Yeah.
[00:45:17.220 --> 00:45:21.660]   So that's a very fascinating question that is generated conversation at the FDA that
[00:45:21.660 --> 00:45:31.100]   continues to this day, which is when the therapeutic is an algorithm and not a molecule, how do
[00:45:31.100 --> 00:45:36.740]   you administer a clinical trial that can generate evidence that the algorithm itself can create
[00:45:36.740 --> 00:45:37.740]   better outcomes?
[00:45:37.740 --> 00:45:43.600]   I mean, fortunately for us, they were pretty understanding, allowed the trial to go forward.
[00:45:43.600 --> 00:45:44.900]   I don't know how it's going to work.
[00:45:44.900 --> 00:45:49.320]   So we were building what's called a peptide vaccine.
[00:45:49.320 --> 00:45:55.080]   So the actual molecules that we put into patients were little sub-sequences of amino acids called
[00:45:55.080 --> 00:45:58.220]   peptides together with what are called adjuvants.
[00:45:58.220 --> 00:46:02.180]   It's just general purpose immune stimulants to draw the attention of your immune system
[00:46:02.180 --> 00:46:04.340]   to those peptides.
[00:46:04.340 --> 00:46:09.280]   And peptide vaccines are very well understood as a therapeutic modality and widely considered
[00:46:09.280 --> 00:46:10.900]   to be safe.
[00:46:10.900 --> 00:46:12.580]   So I think that certainly helped.
[00:46:12.580 --> 00:46:17.660]   But yeah, I mean, the intervention under study in that clinical trial is an algorithm, not
[00:46:17.660 --> 00:46:18.740]   a specific molecule.
[00:46:18.740 --> 00:46:20.380]   It's different for every patient.
[00:46:20.380 --> 00:46:21.380]   That's so cool.
[00:46:21.380 --> 00:46:28.460]   And I guess the other thing, I hope I'm following all the steps here, but it felt pretty deterministic
[00:46:28.460 --> 00:46:32.580]   to me, like what's going on and then what intervention you would want.
[00:46:32.580 --> 00:46:36.180]   So what's the part where you need a machine learning algorithm?
[00:46:36.180 --> 00:46:38.700]   I guess the way you're explaining it, I was sort of thinking, oh, you kind of look at
[00:46:38.700 --> 00:46:42.380]   the genome and see where the problem is and then you know the amino acid and then you
[00:46:42.380 --> 00:46:45.300]   kind of know the medicine that you need.
[00:46:45.300 --> 00:46:51.380]   I guess, where's the uncertainty that requires you to use an ML algorithm versus, I guess,
[00:46:51.380 --> 00:46:53.700]   just sort of like some kind of deterministic logic.
[00:46:53.700 --> 00:46:55.020]   Sure.
[00:46:55.020 --> 00:47:05.420]   So the HLA type of a patient is a set of genome sequences for genes that code for proteins,
[00:47:05.420 --> 00:47:06.920]   which are highly polymorphic.
[00:47:06.920 --> 00:47:09.780]   That is, they're different across the population.
[00:47:09.780 --> 00:47:18.660]   So there's at least six of these proteins that matter and every person has a distinct
[00:47:18.660 --> 00:47:22.740]   repertoire of those six proteins.
[00:47:22.740 --> 00:47:27.900]   And so one input to the predictive model is the amino acid sequence of all six of those
[00:47:27.900 --> 00:47:28.900]   proteins.
[00:47:28.900 --> 00:47:32.860]   So that's pretty variable across the population.
[00:47:32.860 --> 00:47:40.340]   And then the other input to the model is a window of amino acids around every point mutation
[00:47:40.340 --> 00:47:45.540]   that occurs in your tumors that doesn't exist in your normal tissue.
[00:47:45.540 --> 00:47:51.260]   And cancers can accumulate hundreds, thousands, hundreds of thousands, sometimes even millions
[00:47:51.260 --> 00:47:56.100]   somatic mutations and like melanomas, which have the largest mutational burden.
[00:47:56.100 --> 00:48:02.740]   So you end up with two sets of sequences as inputs, the neural network.
[00:48:02.740 --> 00:48:05.320]   I'm sorry, what's the output of the neural network?
[00:48:05.320 --> 00:48:08.540]   So the output of the neural network is a predicted binding.
[00:48:08.540 --> 00:48:14.460]   So I don't want to explain exactly what HLA molecules do, but effectively your body chops
[00:48:14.460 --> 00:48:20.780]   up all the proteins in your cells, a subset of them for like processing, and it chops
[00:48:20.780 --> 00:48:22.940]   them up into smaller fragments.
[00:48:22.940 --> 00:48:30.660]   And your HLA proteins bind selectively to a subset of those smaller fragments, which
[00:48:30.660 --> 00:48:37.380]   your body believes to be interesting to present for inspection to your immune system.
[00:48:37.380 --> 00:48:45.580]   So what you're ultimately trying to predict is the binding affinity between peptide fragments
[00:48:45.580 --> 00:48:50.340]   generated from the proteins in your tumor cells and the HLA proteins that are specific
[00:48:50.340 --> 00:48:51.740]   to your immune system.
[00:48:51.740 --> 00:48:56.280]   So ultimately the thing you're predicting is this protein peptide binding affinity.
[00:48:56.280 --> 00:48:59.820]   And how did you get labeled data for this task?
[00:48:59.820 --> 00:49:05.220]   There's a group in San Diego that generates the vast majority of the label data, and they've
[00:49:05.220 --> 00:49:07.560]   done a great job of curating it.
[00:49:07.560 --> 00:49:13.500]   There's something called the immune epitope database, and it's a fairly difficult...
[00:49:13.500 --> 00:49:17.300]   We actually got to the point where I had a wet lab and I talked to the group in San Diego
[00:49:17.300 --> 00:49:22.740]   about generating measurements of our own to create label data, and they were like, "It's
[00:49:22.740 --> 00:49:23.740]   not worth it.
[00:49:23.740 --> 00:49:24.740]   It's really hard.
[00:49:24.740 --> 00:49:26.700]   Just use our stuff."
[00:49:26.700 --> 00:49:35.060]   Later in the lab's life, some new techniques for generating label data from in vivo tissue
[00:49:35.060 --> 00:49:37.180]   came out that use a different measurement paradigm.
[00:49:37.180 --> 00:49:41.620]   And so some of the work that we did in the lab as I was leaving, and it was carried on
[00:49:41.620 --> 00:49:47.020]   by members of my lab in the new labs they worked in, was to leverage this alternative
[00:49:47.020 --> 00:49:50.940]   source of label data and bring it together with this early source of label data.
[00:49:50.940 --> 00:49:55.500]   So there's a few different places, a few different assays, all of which are pretty difficult
[00:49:55.500 --> 00:49:56.500]   to run.
[00:49:56.500 --> 00:49:58.500]   So we don't get super high throughput.
[00:49:58.500 --> 00:50:06.060]   And the mass spectrometry data, this novel source of label data, often it's positives
[00:50:06.060 --> 00:50:08.100]   only, so you're not necessarily measuring.
[00:50:08.100 --> 00:50:13.540]   So there's a lot of work that has to go in, and as you're very much aware, you don't just
[00:50:13.540 --> 00:50:16.940]   get to pick up a dataset and fit a model to it and call it a win.
[00:50:16.940 --> 00:50:20.980]   There's a lot of work that goes into massaging the training data to get it ready for machine
[00:50:20.980 --> 00:50:23.180]   learning.
[00:50:23.180 --> 00:50:28.940]   Is it important for this task or these kinds of tasks to use modern techniques like deep
[00:50:28.940 --> 00:50:34.220]   neural networks, or do you think simpler techniques would also work pretty well?
[00:50:34.220 --> 00:50:39.380]   So one of my frustrations is we didn't write more papers about the work that we did, because
[00:50:39.380 --> 00:50:42.500]   one of the theories that I had for this lab was to just hire a bunch of people from industry
[00:50:42.500 --> 00:50:45.500]   and see if we could turn them into academics.
[00:50:45.500 --> 00:50:48.820]   And one of the hardest things to do with people from industry is to convince them that writing
[00:50:48.820 --> 00:50:49.820]   a paper is worthwhile.
[00:50:49.820 --> 00:50:50.820]   But we did.
[00:50:50.820 --> 00:50:52.620]   We tried a lot of cutting edge.
[00:50:52.620 --> 00:50:56.380]   So one of the guys that worked on the problem early on was a guy named Alex Rubinstein,
[00:50:56.380 --> 00:51:02.020]   who's now actually a professor at University of North Carolina Chapel Hill in a biomedical
[00:51:02.020 --> 00:51:03.180]   department, which is kind of cool.
[00:51:03.180 --> 00:51:11.100]   So he did a PhD at NYU in the whole deep learning craze.
[00:51:11.100 --> 00:51:15.140]   So he was pretty experienced with the models.
[00:51:15.140 --> 00:51:18.700]   And we iterated through a lot of more complex...
[00:51:18.700 --> 00:51:27.300]   This is sort of the era when LSTMs were becoming very exciting, like sequence learning models.
[00:51:27.300 --> 00:51:32.500]   So I remember Lasagna was a library built on top of Theano.
[00:51:32.500 --> 00:51:37.140]   There was a guy like Colin Raffel, who was really good with it, who came down to talk
[00:51:37.140 --> 00:51:38.140]   with us.
[00:51:38.140 --> 00:51:44.260]   And I feel like it was Alex Graves at DeepMind that had a lot of sequence to sequence learning.
[00:51:44.260 --> 00:51:49.540]   And we went up to NeurIPS three years in a row as a lab and presented some work up there.
[00:51:49.540 --> 00:51:52.860]   So we were definitely kind of paying attention to what was happening in the state of the
[00:51:52.860 --> 00:51:54.420]   art for learning on sequences.
[00:51:54.420 --> 00:51:57.540]   It didn't make a huge difference.
[00:51:57.540 --> 00:52:01.900]   I remember trying out Siamese networks and things like this, and it wasn't really moving
[00:52:01.900 --> 00:52:02.900]   the needle.
[00:52:02.900 --> 00:52:07.300]   So I honestly don't know where they landed, what the current version of McFlurry is from
[00:52:07.300 --> 00:52:10.380]   like a neural architecture standpoint.
[00:52:10.380 --> 00:52:16.140]   But I want to say that nothing we tried that was more exotic made a huge difference.
[00:52:16.140 --> 00:52:19.900]   So ultimately, I think mostly no for that problem.
[00:52:19.900 --> 00:52:25.980]   And I should also say that the leading predictor prior to ours for a decade was a neural network.
[00:52:25.980 --> 00:52:30.220]   So this is a field where they already were using neural networks before the deep learning
[00:52:30.220 --> 00:52:31.920]   craze happened.
[00:52:31.920 --> 00:52:36.060]   So it's not like we were coming into the field and we were like, "Hey, everyone, neural networks."
[00:52:36.060 --> 00:52:40.120]   They were like, "Yeah, of course, neural networks."
[00:52:40.120 --> 00:52:43.380]   We weren't trying to act like we were bringing fire from Olympus.
[00:52:43.380 --> 00:52:49.220]   It was like, "Everybody's already using neural networks, but could you make better use of
[00:52:49.220 --> 00:52:50.220]   them?"
[00:52:50.220 --> 00:52:53.020]   So embedding layers and things were relatively novel approaches.
[00:52:53.020 --> 00:52:57.700]   So there were some ideas that we could bring to bear, but it wasn't just like a slam dunk
[00:52:57.700 --> 00:53:00.820]   to just use the latest neural architecture.
[00:53:00.820 --> 00:53:04.100]   And so what types of things are you working on now in your lab?
[00:53:04.100 --> 00:53:05.780]   Nothing, actually.
[00:53:05.780 --> 00:53:08.140]   I'm on leave from my lab.
[00:53:08.140 --> 00:53:11.140]   So what are you working on?
[00:53:11.140 --> 00:53:12.380]   What are you up to?
[00:53:12.380 --> 00:53:19.180]   So I went on leave from my lab in January of 2020 because I started a biotech venture
[00:53:19.180 --> 00:53:27.380]   creation firm with two of my friends, Adam Colum and Jack Millwood in mid-2019.
[00:53:27.380 --> 00:53:31.860]   So one of the things that I did with my lab, so I started my lab up in New York City and
[00:53:31.860 --> 00:53:33.660]   it was purely computational.
[00:53:33.660 --> 00:53:40.260]   But one thing that you learn quickly if you're running an academic lab is that it's difficult
[00:53:40.260 --> 00:53:43.820]   to collaborate in academia.
[00:53:43.820 --> 00:53:50.780]   And it's a lot easier if you own sort of vertical research ideas rather than being a person
[00:53:50.780 --> 00:53:54.140]   who brings a skill into a horizontal research network.
[00:53:54.140 --> 00:53:56.620]   Those are just a lot harder to build, those horizontal research groups.
[00:53:56.620 --> 00:53:58.140]   And they're often built through pedigree.
[00:53:58.140 --> 00:54:01.820]   Like, "Oh, I did my PhD with this professor, and so I'm going to work with you."
[00:54:01.820 --> 00:54:03.320]   I mean, I had zero pedigree.
[00:54:03.320 --> 00:54:08.060]   So I recognized pretty quickly that this theory that my lab could be this sort of ally to
[00:54:08.060 --> 00:54:11.460]   many other labs was like, no one wanted an ally.
[00:54:11.460 --> 00:54:15.300]   So I had to kind of build data generating capacity on my own.
[00:54:15.300 --> 00:54:20.340]   So I ultimately ended up building a wet lab as well.
[00:54:20.340 --> 00:54:26.140]   And for a variety of reasons, realized that academia was a better place for me to be doing
[00:54:26.140 --> 00:54:28.420]   basic science rather than translational science.
[00:54:28.420 --> 00:54:33.620]   So this new antigen vaccine idea that we worked on when it was very early stage, ultimately
[00:54:33.620 --> 00:54:38.540]   there were several venture-backed companies that went public and had hundreds of employees
[00:54:38.540 --> 00:54:43.140]   working on the idea, including BioNTech, actually, which is the vaccine that I got, the maker
[00:54:43.140 --> 00:54:46.460]   of the vaccine that I got for COVID-19, which was nice.
[00:54:46.460 --> 00:54:49.020]   So there was a lot of...
[00:54:49.020 --> 00:54:54.100]   100X more resources could get put into that problem on the commercial side versus the
[00:54:54.100 --> 00:54:55.420]   academic side.
[00:54:55.420 --> 00:55:00.780]   So I decided to kind of start angling my lab towards more basic science questions and doing
[00:55:00.780 --> 00:55:05.220]   mostly data generation with some computational work layered on top.
[00:55:05.220 --> 00:55:11.620]   So we started working on things like optimizing protocols for genome editing in T-cells and
[00:55:11.620 --> 00:55:17.420]   growing organoids, which are like small three-dimensional model systems to represent tumors in vitro
[00:55:17.420 --> 00:55:20.720]   that we could do more reliable experimentation upon.
[00:55:20.720 --> 00:55:23.700]   We layered some computer vision work on top of that, which was pretty fun.
[00:55:23.700 --> 00:55:28.220]   And we did some natural language processing work over the research literature as well.
[00:55:28.220 --> 00:55:32.660]   But the lab became more of a traditional biology lab than a computational group.
[00:55:32.660 --> 00:55:37.140]   But it's kind of like the sort of other part of that idea was that, okay, my lab should
[00:55:37.140 --> 00:55:40.420]   become more basic, but I want to have some translational work.
[00:55:40.420 --> 00:55:44.740]   And so the translational work, I decided to kind of funnel through this BioNTech venture
[00:55:44.740 --> 00:55:47.280]   creation firm that we created called Related Sciences.
[00:55:47.280 --> 00:55:54.220]   So yeah, for the last two years or so, I've been working mostly full-time on Related Sciences.
[00:55:54.220 --> 00:56:00.540]   And the idea of Related Sciences is to use data to identify promising preclinical therapeutic
[00:56:00.540 --> 00:56:07.060]   opportunities and to create companies to then pursue those preclinical therapeutic opportunities.
[00:56:07.060 --> 00:56:08.060]   Wow.
[00:56:08.060 --> 00:56:09.060]   Very cool.
[00:56:09.060 --> 00:56:10.060]   Awesome.
[00:56:10.060 --> 00:56:12.580]   Well, thanks so much for your time.
[00:56:12.580 --> 00:56:16.380]   It's such a pleasure to catch up and so cool, the things that you've done.
[00:56:16.380 --> 00:56:18.900]   I love that I got a chance to hear all these stories.
[00:56:18.900 --> 00:56:19.900]   Yeah.
[00:56:19.900 --> 00:56:25.180]   I wish I could talk more about the fun machine learning tools and techniques we're trying
[00:56:25.180 --> 00:56:29.700]   out at Related Sciences some other time, but I'm always happy to talk about my history
[00:56:29.700 --> 00:56:30.700]   as well.
[00:56:30.700 --> 00:56:31.700]   Yeah, I really appreciate it.
[00:56:31.700 --> 00:56:32.980]   Yeah, we should do a follow-up.
[00:56:32.980 --> 00:56:37.340]   If you're enjoying these interviews and you want to learn more, please click on the link
[00:56:37.340 --> 00:56:42.080]   to the show notes in the description where you can find links to all the papers that
[00:56:42.080 --> 00:56:46.500]   are mentioned, supplemental material, and a transcription that we work really hard to
[00:56:46.500 --> 00:56:47.500]   produce.
[00:56:47.500 --> 00:56:47.500]   So check it out.
[00:56:47.660 --> 00:56:48.160]   [music]
[00:56:48.160 --> 00:56:50.220]   you
[00:56:50.220 --> 00:56:52.280]   you

