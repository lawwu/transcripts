
[00:00:00.000 --> 00:00:07.960]   I mentioned data leakage in passing, but I just want to come back to that subject a bit
[00:00:07.960 --> 00:00:08.960]   more.
[00:00:08.960 --> 00:00:14.920]   So, I think it's a very important subject because you're likely to come across it as
[00:00:14.920 --> 00:00:17.080]   a machine learning practitioner.
[00:00:17.080 --> 00:00:23.400]   In fact, I've come across it approximately, I would say in 75% or more of all the projects
[00:00:23.400 --> 00:00:26.040]   that I've worked on in companies.
[00:00:26.040 --> 00:00:27.520]   So it's really that common.
[00:00:27.520 --> 00:00:35.440]   And even on this dataset, when we source this dataset for this class, the way it's provided
[00:00:35.440 --> 00:00:40.440]   is that it's already segmented into train, test and validation splits in case people
[00:00:40.440 --> 00:00:47.720]   want to have a competition or make a competition somehow with this dataset.
[00:00:47.720 --> 00:00:54.440]   And so we actually found that these images were crossing those boundaries.
[00:00:54.440 --> 00:01:01.400]   And so it just goes to show that even when you are preparing datasets for a competition,
[00:01:01.400 --> 00:01:07.600]   it's very easy to get this issue of data leakage wrong.
[00:01:07.600 --> 00:01:10.620]   Because it's very tricky to think about or to even detect.
[00:01:10.620 --> 00:01:16.160]   And so a lot of diligence is required to actually catch data leakage.
[00:01:16.160 --> 00:01:20.900]   And I want to give you some examples of data leakage from my own experience.
[00:01:20.900 --> 00:01:23.460]   And so the first story I want to share is from Airbnb.
[00:01:23.460 --> 00:01:30.100]   So at Airbnb, we were working on a variety of models that predict various things that
[00:01:30.100 --> 00:01:35.000]   customers might do, such as book an Airbnb.
[00:01:35.000 --> 00:01:42.320]   And so there is a customer table, or there was a table of all users of Airbnb, with all
[00:01:42.320 --> 00:01:47.600]   of, you know, with various demographic data and other attributes that we use for predictive
[00:01:47.600 --> 00:01:48.680]   models.
[00:01:48.680 --> 00:01:55.700]   And on that table was a very convenient field called first booking date, which had the first
[00:01:55.700 --> 00:02:02.200]   booking date, the first day a user booked an Airbnb, if they ever booked an Airbnb.
[00:02:02.200 --> 00:02:08.760]   And this table had a date field on it, which this was a snapshot table.
[00:02:08.760 --> 00:02:11.300]   So every day this table was recreated.
[00:02:11.300 --> 00:02:15.260]   And so at some point, you know, we were using this for many predictive models.
[00:02:15.260 --> 00:02:23.140]   And at some point, this data was refreshed, such that people, you know, the user table
[00:02:23.140 --> 00:02:31.360]   had first booking dates on it prior to the, before their first booking.
[00:02:31.360 --> 00:02:35.540]   So it kind of leaked information from the future.
[00:02:35.540 --> 00:02:42.720]   So for example, if I joined Airbnb in June, it would have a first booking date of whenever
[00:02:42.720 --> 00:02:47.320]   I made my first booking, let's say December, as of June.
[00:02:47.320 --> 00:02:52.680]   And so if I joined on the June data, it brought that information from the future, and it was
[00:02:52.680 --> 00:02:56.060]   extremely predictive for many things.
[00:02:56.060 --> 00:03:01.240]   And it was really hard to catch because, you know, we, you know, these types of things
[00:03:01.240 --> 00:03:02.240]   happen.
[00:03:02.240 --> 00:03:05.000]   So data pipelines can change.
[00:03:05.000 --> 00:03:10.540]   And you know, you have to be careful of using data that's intended for analytics and reporting
[00:03:10.540 --> 00:03:12.440]   for machine learning.
[00:03:12.440 --> 00:03:19.860]   You have to be really careful about minding which data is being updated at what time.
[00:03:19.860 --> 00:03:27.360]   And I would say this is a very common culprit of data leakage problems, data being updated
[00:03:27.360 --> 00:03:32.240]   or database tables being updated in a way that is not necessarily compatible with machine
[00:03:32.240 --> 00:03:34.000]   learning.
[00:03:34.000 --> 00:03:37.800]   And the same thing happened there with models.
[00:03:37.800 --> 00:03:44.240]   There was a model about rebooking, you know, our customers booking listings, and there
[00:03:44.240 --> 00:03:48.800]   was a field that indicated if an account was deactivated.
[00:03:48.800 --> 00:03:55.640]   And similarly, that was backfilled, and that created a situation where we had information
[00:03:55.640 --> 00:03:58.000]   leaking from the future.
[00:03:58.000 --> 00:04:03.480]   There's also an example I want to talk about a bit later is time series forecasting without
[00:04:03.480 --> 00:04:04.480]   a blackout window.
[00:04:04.480 --> 00:04:09.320]   I won't linger too much on that, but I just want to bring up that I've seen this happen
[00:04:09.320 --> 00:04:12.040]   at almost every place I've worked.
[00:04:12.040 --> 00:04:14.200]   And we'll get into that.
[00:04:14.200 --> 00:04:21.120]   At GitHub, we actually had models that were language models that were being trained on
[00:04:21.120 --> 00:04:23.680]   code.
[00:04:23.680 --> 00:04:29.480]   And as you might imagine, even in different repos, there tends to be duplicate code because
[00:04:29.480 --> 00:04:31.800]   code, you know, people use each other's code.
[00:04:31.800 --> 00:04:38.720]   There's a lot of copying and pasting of code, or some languages, we vendor code as libraries.
[00:04:38.720 --> 00:04:43.880]   And so we had a lot of nearly duplicate code across train and test sets, kind of similar
[00:04:43.880 --> 00:04:49.680]   to this dataset where we have images that are almost the same because they're taken
[00:04:49.680 --> 00:04:50.680]   from the same camera.
[00:04:50.680 --> 00:04:55.720]   We had the exact same problem at GitHub, and that was really tricky to find and realize
[00:04:55.720 --> 00:04:57.000]   that we have that.
[00:04:57.000 --> 00:04:59.840]   Similarly, we had auto-generated issues.
[00:04:59.840 --> 00:05:05.440]   So if you've used GitHub before, you may have noticed from time to time on certain repositories,
[00:05:05.440 --> 00:05:10.200]   there's automated issues, maybe issues generated by bots.
[00:05:10.200 --> 00:05:15.760]   And then so, you know, we noticed that, you know, a lot of these automated issues, they're
[00:05:15.760 --> 00:05:17.800]   very much the same.
[00:05:17.800 --> 00:05:22.280]   And that causes a form of leakage to some degree.
[00:05:22.280 --> 00:05:27.520]   Another example is from my consulting days when I was advising a hospital and building
[00:05:27.520 --> 00:05:33.960]   there, helping them fix their, you know, various machine learning problems there, is they were
[00:05:33.960 --> 00:05:40.120]   trying to predict hospital readmission, but they had a field in their dataset which indicated
[00:05:40.120 --> 00:05:42.600]   if the patient died or not.
[00:05:42.600 --> 00:05:44.920]   And so this might seem silly.
[00:05:44.920 --> 00:05:50.600]   You might say, oh, okay, this might seem silly on this slide, but it wasn't really clear
[00:05:50.600 --> 00:05:53.040]   that this was data leakage at the time.
[00:05:53.040 --> 00:05:59.360]   The trick here was thinking carefully about when the model is used.
[00:05:59.360 --> 00:06:09.000]   So the model is used in this particular situation when a customer is first, or sorry, when a
[00:06:09.000 --> 00:06:15.680]   patient is in the very early stages of being admitted to the hospital.
[00:06:15.680 --> 00:06:21.240]   And at this point in time, when you are using the model in practice, you don't know if the
[00:06:21.240 --> 00:06:23.000]   patient is dead.
[00:06:23.000 --> 00:06:25.960]   That only happens much later.
[00:06:25.960 --> 00:06:33.640]   And so if you don't understand how the model is used in the business process, you might
[00:06:33.640 --> 00:06:35.840]   not realize that you have data leakage.
[00:06:35.840 --> 00:06:40.100]   You might not realize that, hey, there's a feature here that contains information that
[00:06:40.100 --> 00:06:45.760]   you don't normally have at the time that you are going to use this model.
[00:06:45.760 --> 00:06:51.560]   You know, this field is always going to be null or blank or not even available at the
[00:06:51.560 --> 00:06:53.800]   time this model will be used.
[00:06:53.800 --> 00:07:00.720]   And so you will get a very optimistic estimate of your performance.
[00:07:00.720 --> 00:07:02.560]   And so, you know, these things can be hard to catch.
[00:07:02.560 --> 00:07:07.160]   They might not even be labeled so easily.
[00:07:07.160 --> 00:07:12.920]   The names of these fields may not be so blatantly labeled.
[00:07:12.920 --> 00:07:15.120]   And so what can you do about this?
[00:07:15.120 --> 00:07:19.220]   So there's a lot of things you can do about data leakage.
[00:07:19.220 --> 00:07:27.280]   One is, you know, to have good evaluation practices, you know, to look at feature importances,
[00:07:27.280 --> 00:07:29.760]   to monitor your production performance.
[00:07:29.760 --> 00:07:32.000]   But we don't want to get too deep into that.
[00:07:32.000 --> 00:07:34.880]   Those are all separate courses on their own.
[00:07:34.880 --> 00:07:41.080]   But I just wanted to mention data leakage in this sense so that you can have an awareness
[00:07:41.080 --> 00:07:46.440]   and think more about data leakage, including the kind of data leakage that we have discussed
[00:07:46.440 --> 00:07:51.800]   in this course with respect to images not-- from the same camera not crossing boundaries.
[00:07:51.800 --> 00:07:52.800]   Thank you.
[00:07:52.800 --> 00:07:52.820]   [END]
[00:07:52.820 --> 00:07:53.820]   Page 2 of 10
[00:07:53.820 --> 00:07:53.820]   Page 2 of 10
[00:07:53.820 --> 00:07:54.820]   Page 2 of 10
[00:07:54.820 --> 00:07:54.820]   Page 2 of 10
[00:07:54.820 --> 00:07:55.820]   Page 2 of 10
[00:07:55.820 --> 00:07:55.820]   Page 2 of 10
[00:07:55.820 --> 00:07:56.820]   Page 2 of 10
[00:07:56.820 --> 00:07:56.820]   Page 2 of 10
[00:07:56.820 --> 00:08:01.820]   Page 2 of 10
[00:08:01.820 --> 00:08:26.060]   (silence)

