
[00:00:00.000 --> 00:00:04.640]   Our next guest needs no introduction.
[00:00:04.640 --> 00:00:09.640]   She has an incredible career in film.
[00:00:09.640 --> 00:00:12.200]   She's an entrepreneur, she's a podcaster.
[00:00:12.200 --> 00:00:16.680]   But interestingly learned about a year and a half ago
[00:00:16.680 --> 00:00:19.080]   that our friend Gwyneth Paltrow
[00:00:19.080 --> 00:00:21.480]   is also a fan of the All In podcast.
[00:00:21.480 --> 00:00:22.440]   (laughing)
[00:00:22.440 --> 00:00:25.200]   So welcome Gwyneth Paltrow.
[00:00:25.200 --> 00:00:27.780]   (upbeat music)
[00:00:27.780 --> 00:00:29.360]   ♪ All in ♪
[00:00:29.360 --> 00:00:31.980]   ♪ Let your winners ride ♪
[00:00:31.980 --> 00:00:34.440]   ♪ Rain Man David Sackman ♪
[00:00:34.440 --> 00:00:36.360]   ♪ I'm going all in ♪
[00:00:36.360 --> 00:00:37.200]   ♪ And it said ♪
[00:00:37.200 --> 00:00:38.540]   ♪ We open sourced it to the fans ♪
[00:00:38.540 --> 00:00:40.180]   ♪ And they've just gone crazy with it ♪
[00:00:40.180 --> 00:00:41.020]   ♪ Love you guys ♪
[00:00:41.020 --> 00:00:42.540]   ♪ I'm queen of Kinwans ♪
[00:00:42.540 --> 00:00:44.380]   ♪ I'm going all in ♪
[00:00:44.380 --> 00:00:46.900]   - Are you trolling me with my glasses?
[00:00:46.900 --> 00:00:48.460]   Do you have your blue lights on?
[00:00:48.460 --> 00:00:50.740]   - I can't, I honestly can't see
[00:00:50.740 --> 00:00:53.580]   without these things at this point, so forgive me.
[00:00:53.580 --> 00:00:57.620]   - I'm just curious, thanks for zooming in here.
[00:00:57.620 --> 00:00:59.620]   When did you become aware of the podcast?
[00:00:59.620 --> 00:01:01.220]   'Cause you said you listen to two podcasts,
[00:01:01.220 --> 00:01:02.860]   you have your own amazing podcast.
[00:01:02.860 --> 00:01:05.180]   How did you discover the All In podcast?
[00:01:05.180 --> 00:01:07.100]   'Cause you wrote about us so graciously
[00:01:07.100 --> 00:01:09.880]   in the Goop newsletter and said it's your latest obsession.
[00:01:09.880 --> 00:01:12.340]   Then you shouted us out on another podcast.
[00:01:12.340 --> 00:01:14.300]   So I get like a hundred,
[00:01:14.300 --> 00:01:16.900]   we all get like a hundred inbounds when you do that.
[00:01:16.900 --> 00:01:19.060]   But how did you find out about our podcast?
[00:01:19.060 --> 00:01:23.260]   - We just recommended it to a nearby friend.
[00:01:23.260 --> 00:01:25.820]   And I just, you know, there's so many people
[00:01:25.820 --> 00:01:27.500]   who's really proud of it, but I thought, okay,
[00:01:27.500 --> 00:01:29.100]   this is interesting.
[00:01:29.100 --> 00:01:32.860]   And I put it on and honestly, you guys are the only thing
[00:01:32.860 --> 00:01:35.260]   I listen to religiously every single week.
[00:01:35.260 --> 00:01:36.660]   I love all of you.
[00:01:36.660 --> 00:01:39.100]   You open my mind, you challenge my thinking,
[00:01:39.100 --> 00:01:42.100]   and I learn so much from all of you.
[00:01:42.100 --> 00:01:45.260]   So I just, I appreciate what you guys do
[00:01:45.260 --> 00:01:50.260]   and I really feel very honored that you have me on.
[00:01:50.260 --> 00:01:53.260]   You know, my husband, the little bonus contention
[00:01:53.260 --> 00:01:55.860]   is he thinks I'm in love with David Satch.
[00:01:55.860 --> 00:01:58.900]   But people don't even do it, so it's okay.
[00:01:58.900 --> 00:02:00.100]   - But you're breaking up a little bit,
[00:02:00.100 --> 00:02:02.060]   but I think I heard in there that--
[00:02:02.060 --> 00:02:02.900]   - She hates David Satch.
[00:02:02.900 --> 00:02:05.700]   - She hates David Satch, is that correct?
[00:02:05.700 --> 00:02:06.540]   That you just--
[00:02:06.540 --> 00:02:09.140]   - I heard that I was the favorite bestie, but--
[00:02:09.140 --> 00:02:11.300]   - So you're traveling right now.
[00:02:11.300 --> 00:02:13.200]   You don't have Starlink on your plane?
[00:02:13.200 --> 00:02:16.420]   - I'm flying on American.
[00:02:16.420 --> 00:02:18.700]   Shamoff did not lend me his plane for this.
[00:02:18.700 --> 00:02:20.200]   I can't regret it.
[00:02:20.200 --> 00:02:21.180]   (laughing)
[00:02:21.180 --> 00:02:22.340]   - We'll make sure we're correct.
[00:02:22.340 --> 00:02:24.220]   We brought the summit to you this year,
[00:02:24.220 --> 00:02:26.060]   but you couldn't make it in person.
[00:02:26.060 --> 00:02:29.620]   I wanted to ask you, of all the things you've done,
[00:02:29.620 --> 00:02:32.140]   you had this incredible career in Hollywood,
[00:02:32.140 --> 00:02:34.660]   which really spanned from the independent film era
[00:02:34.660 --> 00:02:37.140]   all the way to the blockbuster superhero era.
[00:02:37.140 --> 00:02:40.940]   Obviously, Goop and the tremendous success there
[00:02:40.940 --> 00:02:42.460]   and podcasting.
[00:02:42.460 --> 00:02:43.900]   What have you enjoyed most?
[00:02:43.900 --> 00:02:46.660]   And then, I'm wondering, I know you get harangued
[00:02:46.660 --> 00:02:49.420]   by all the Marvel fans to play Pepper Potts again,
[00:02:49.420 --> 00:02:51.160]   but it's not exactly your decision.
[00:02:52.080 --> 00:02:54.940]   What have you enjoyed most in your career?
[00:02:54.940 --> 00:02:59.280]   - I have to say, I genuinely have enjoyed
[00:02:59.280 --> 00:03:01.480]   all of the chapters.
[00:03:01.480 --> 00:03:04.240]   I've been incredibly fortunate in that I've had this
[00:03:04.240 --> 00:03:06.040]   amazingly diverse life.
[00:03:06.040 --> 00:03:08.400]   I've been an expat in London for a decade.
[00:03:08.400 --> 00:03:13.440]   And it's been really, it's been just thrilling
[00:03:13.440 --> 00:03:15.640]   to be able to do that and then kind of segue
[00:03:15.640 --> 00:03:17.520]   into a life of entrepreneurship.
[00:03:17.520 --> 00:03:20.320]   And I would be hard-pressed to pick a favorite.
[00:03:20.320 --> 00:03:21.720]   - Yeah.
[00:03:21.720 --> 00:03:23.920]   - How did you make that decision, Gwyneth?
[00:03:23.920 --> 00:03:27.000]   We talked with Alexandra Botez before this.
[00:03:27.000 --> 00:03:31.320]   She's gotten a lot of notoriety and built an audience
[00:03:31.320 --> 00:03:34.440]   streaming chess, chess matches.
[00:03:34.440 --> 00:03:36.200]   And now she's building her own business,
[00:03:36.200 --> 00:03:37.520]   and we're gonna talk to Jimmy Donaldson,
[00:03:37.520 --> 00:03:38.920]   Mr. Beast, here in a minute.
[00:03:38.920 --> 00:03:40.840]   And he's similarly building his own business
[00:03:40.840 --> 00:03:42.440]   with his audience.
[00:03:42.440 --> 00:03:44.720]   How did you make the decision to build Goop,
[00:03:44.720 --> 00:03:46.280]   to build a business with your audience
[00:03:46.280 --> 00:03:48.880]   instead of endorse other businesses
[00:03:48.880 --> 00:03:51.280]   and get paid to put your stamp on other products
[00:03:51.280 --> 00:03:53.920]   that were already in market and help us think about
[00:03:53.920 --> 00:03:56.560]   the intention on being an entrepreneur and an owner
[00:03:56.560 --> 00:04:00.040]   instead of being an endorser and a service provider?
[00:04:00.040 --> 00:04:05.840]   - I mean, I think that in my position,
[00:04:05.840 --> 00:04:07.760]   we're expected to kind of be an endorser
[00:04:07.760 --> 00:04:11.040]   and put our name on something more white label.
[00:04:11.040 --> 00:04:12.920]   In my case, maybe it was naivete.
[00:04:12.920 --> 00:04:15.520]   Like I just really wanted to try to build something
[00:04:15.520 --> 00:04:19.720]   brick by brick and have that incredible
[00:04:19.720 --> 00:04:21.720]   hockey stick education.
[00:04:21.720 --> 00:04:25.040]   And the business happened very iteratively.
[00:04:25.040 --> 00:04:27.240]   It really just started with me kind of writing content
[00:04:27.240 --> 00:04:30.320]   in my kitchen in London almost 15 years ago,
[00:04:30.320 --> 00:04:32.440]   which is kind of hard to believe.
[00:04:32.440 --> 00:04:34.800]   And the business models, there've been a few of them.
[00:04:34.800 --> 00:04:36.480]   They've slowly evolved over time.
[00:04:36.480 --> 00:04:39.040]   You know, we started monetizing content
[00:04:39.040 --> 00:04:42.840]   and then moved into product and then making our own product.
[00:04:44.080 --> 00:04:46.160]   And I think it's sort of what I didn't like
[00:04:46.160 --> 00:04:48.440]   so much about acting was the part where you're kind of
[00:04:48.440 --> 00:04:52.440]   waiting around, waiting for permission to engage,
[00:04:52.440 --> 00:04:54.480]   to create something, to put something out in the world.
[00:04:54.480 --> 00:04:56.960]   And this is far more immediate.
[00:04:56.960 --> 00:05:00.640]   And I love my acting career, but I find this like
[00:05:00.640 --> 00:05:03.280]   incredibly fulfilling in a much different way.
[00:05:03.280 --> 00:05:06.160]   - Yeah, maybe you could talk a little bit.
[00:05:06.160 --> 00:05:08.960]   I know I listened to your pod and I've been watching
[00:05:08.960 --> 00:05:10.440]   your intellectual curiosity.
[00:05:10.440 --> 00:05:14.040]   It seems like aging and kind of living our best lives
[00:05:14.040 --> 00:05:16.360]   in our fifties and Gen X is kind of moving
[00:05:16.360 --> 00:05:17.640]   into this new era.
[00:05:17.640 --> 00:05:21.520]   I'm curious what you think about this having multiple
[00:05:21.520 --> 00:05:24.200]   careers and moving into this new era of life
[00:05:24.200 --> 00:05:27.840]   and living your best life in your fifties and your sixties.
[00:05:27.840 --> 00:05:30.240]   People are staying healthier longer skiing into their
[00:05:30.240 --> 00:05:31.080]   sixties and seventies.
[00:05:31.080 --> 00:05:32.320]   I don't want to bring up too much skiing.
[00:05:32.320 --> 00:05:35.360]   I know that was a bit of a distraction this year for you.
[00:05:35.360 --> 00:05:37.000]   Congratulations on the case.
[00:05:42.120 --> 00:05:45.360]   I mean, the best part of it was when you walked out
[00:05:45.360 --> 00:05:47.040]   of the case and you put your head on his shoulder,
[00:05:47.040 --> 00:05:49.080]   you said, I just wish you well or something.
[00:05:49.080 --> 00:05:52.240]   You were very kind and magnanimous, but maybe talk
[00:05:52.240 --> 00:05:55.480]   about just how great it is to be able to just keep
[00:05:55.480 --> 00:05:57.880]   having this healthy lifestyle and what you're doing
[00:05:57.880 --> 00:06:01.240]   on the pod, because I'm watching you intellectually
[00:06:01.240 --> 00:06:05.120]   go from shorter to longer to longer and more in depth
[00:06:05.120 --> 00:06:06.320]   conversations.
[00:06:06.320 --> 00:06:09.640]   - Thanks, J. Cal.
[00:06:11.560 --> 00:06:13.560]   You know, I...
[00:06:13.560 --> 00:06:15.640]   - That's her way of saying you're full of shit.
[00:06:15.640 --> 00:06:25.640]   - You know, I think what I've watched over the span
[00:06:25.640 --> 00:06:30.640]   of this kind of 15, kind of general curiosity in wellness
[00:06:30.640 --> 00:06:35.480]   and this idea that we can impact the way that we feel.
[00:06:35.480 --> 00:06:37.840]   I think, you know, we were a little bit early
[00:06:37.840 --> 00:06:39.760]   on the early side in the trends
[00:06:40.840 --> 00:06:45.640]   and I really am so happy to see people understanding
[00:06:45.640 --> 00:06:48.200]   that how they think and how they breathe
[00:06:48.200 --> 00:06:50.440]   and what they eat really impacts how they feel,
[00:06:50.440 --> 00:06:52.680]   the quality of their relationships and everything.
[00:06:52.680 --> 00:06:57.600]   And I think it's, it only intensifies in your fifties,
[00:06:57.600 --> 00:06:59.880]   I think, when you start to understand that life really
[00:06:59.880 --> 00:07:03.000]   is finite and in a way that you don't,
[00:07:03.000 --> 00:07:05.560]   you can't conceptualize that when you're 26 years old.
[00:07:05.560 --> 00:07:10.560]   And so I'm glad that I feel bullish about aging,
[00:07:10.720 --> 00:07:14.480]   you know, I definitely want to do whatever interventions
[00:07:14.480 --> 00:07:18.160]   I can to feel good and happy and live a long life.
[00:07:18.160 --> 00:07:19.920]   I love my kids so much.
[00:07:19.920 --> 00:07:22.120]   I wanna live a long time and meet their kids.
[00:07:22.120 --> 00:07:27.000]   And I think the pod, the Goop pod is just a way for me
[00:07:27.000 --> 00:07:29.920]   to learn more about kind of what's out there.
[00:07:29.920 --> 00:07:33.120]   And we talked to amazing doctors and experts
[00:07:33.120 --> 00:07:35.040]   and scientists and thinkers.
[00:07:35.040 --> 00:07:38.800]   And so for me, it's just a wonderful opportunity to learn.
[00:07:38.800 --> 00:07:40.200]   And that's why I said in the beginning,
[00:07:40.200 --> 00:07:41.040]   I don't know if it cut out,
[00:07:41.040 --> 00:07:43.360]   but that's why I listened to your pod
[00:07:43.360 --> 00:07:44.480]   religiously every week.
[00:07:44.480 --> 00:07:47.320]   It's the only one that I listen to every week
[00:07:47.320 --> 00:07:49.760]   because of the depth of knowledge.
[00:07:49.760 --> 00:07:52.880]   And you guys, I think, are bringing this amazing
[00:07:52.880 --> 00:07:55.840]   kind of open-minded perspective.
[00:07:55.840 --> 00:07:57.600]   And that's why I think you're so resonant
[00:07:57.600 --> 00:07:58.960]   with your listeners.
[00:07:58.960 --> 00:08:02.480]   - You probably read then,
[00:08:02.480 --> 00:08:05.720]   you heard us talk a lot about Brian Armstrong's memo.
[00:08:05.720 --> 00:08:08.080]   You probably heard us mention Toby Lutke,
[00:08:08.080 --> 00:08:10.360]   the CEO of Shopify, his memo.
[00:08:10.360 --> 00:08:13.000]   Now both are sort of in one end of the spectrum,
[00:08:13.000 --> 00:08:16.360]   which is we're a team, we're not a family,
[00:08:16.360 --> 00:08:19.360]   keep your views to yourself, essentially.
[00:08:19.360 --> 00:08:21.720]   And we're coming here to work,
[00:08:21.720 --> 00:08:23.360]   but there's a spectrum of different ways.
[00:08:23.360 --> 00:08:25.880]   Can you just describe where you are on that spectrum
[00:08:25.880 --> 00:08:28.960]   and some challenges or things that you've had to go through
[00:08:28.960 --> 00:08:30.680]   in building this business,
[00:08:30.680 --> 00:08:33.800]   relative to how those guys would have run their companies?
[00:08:33.800 --> 00:08:37.200]   - Yeah, I mean, I think that's been kind of
[00:08:37.200 --> 00:08:41.000]   the most unexpected challenge is the people piece,
[00:08:41.000 --> 00:08:42.520]   the team building piece,
[00:08:42.520 --> 00:08:45.920]   knowing how once you're at a certain scale,
[00:08:45.920 --> 00:08:47.560]   and you're not a CEO interacting
[00:08:47.560 --> 00:08:49.280]   with every single member of the team every day,
[00:08:49.280 --> 00:08:52.840]   how difficult it is to define a culture,
[00:08:52.840 --> 00:08:55.320]   be agile about the changes in the culture.
[00:08:55.320 --> 00:08:59.480]   And I think for us, I think it's hard, right?
[00:08:59.480 --> 00:09:04.480]   Like I'm a woman founder, our team is probably 70% women.
[00:09:04.480 --> 00:09:09.480]   Women, archetypally, we're collaborative, we are creative.
[00:09:09.480 --> 00:09:13.600]   And I think that it's very hard to,
[00:09:13.600 --> 00:09:15.320]   for us anyway, at Groupton,
[00:09:15.320 --> 00:09:18.280]   it would be impossible for there to be this kind of
[00:09:18.280 --> 00:09:21.920]   strict team mentality only.
[00:09:21.920 --> 00:09:24.360]   I think we do bring our hearts to what we do.
[00:09:24.360 --> 00:09:26.720]   There's meaning at what we're trying to create.
[00:09:26.720 --> 00:09:31.960]   But then again, there are boundaries
[00:09:31.960 --> 00:09:32.920]   that need to be created.
[00:09:32.920 --> 00:09:35.360]   And honestly, I think when I look back
[00:09:35.360 --> 00:09:38.520]   at all the mistakes that I've made in growing this company,
[00:09:38.520 --> 00:09:44.400]   all of them stem from my wanting to be a family,
[00:09:44.400 --> 00:09:46.400]   set a different way,
[00:09:46.400 --> 00:09:49.680]   my inability to sometimes say what needed to be said
[00:09:49.680 --> 00:09:51.720]   in order to spare somebody's feelings.
[00:09:51.720 --> 00:09:55.240]   And so there's a lot of personal work for me
[00:09:55.240 --> 00:09:56.960]   in that spectrum.
[00:09:56.960 --> 00:10:00.600]   And I think that I'm sort of starting to really get the hang
[00:10:00.600 --> 00:10:02.800]   of how to do that and do it in my own way.
[00:10:02.800 --> 00:10:05.400]   But I kind of had to give myself permission
[00:10:05.400 --> 00:10:08.200]   to navigate through it and sort of define
[00:10:08.200 --> 00:10:10.920]   how I want to operate like that as a leader.
[00:10:10.920 --> 00:10:15.160]   - And I suppose being a celebrity
[00:10:15.160 --> 00:10:18.440]   is an adjustment for people working for you.
[00:10:18.440 --> 00:10:21.040]   I'm curious how that transition was.
[00:10:21.040 --> 00:10:23.920]   And can people be normal around you at work?
[00:10:23.920 --> 00:10:24.760]   And how do you navigate that?
[00:10:24.760 --> 00:10:26.120]   - Yeah, do they tell you the truth?
[00:10:26.120 --> 00:10:26.960]   - Yeah.
[00:10:26.960 --> 00:10:29.760]   - I mean, it just must be hard at first, no?
[00:10:29.760 --> 00:10:31.880]   - I think it is hard.
[00:10:31.880 --> 00:10:35.800]   I think people come in and I've been in the culture
[00:10:35.800 --> 00:10:38.080]   for better or worse for a really long time now.
[00:10:38.080 --> 00:10:40.160]   So I think everybody kind of has something
[00:10:40.160 --> 00:10:45.160]   they're coming in with, a prejudice or a projection.
[00:10:45.160 --> 00:10:47.760]   And I also just am famous.
[00:10:47.760 --> 00:10:49.840]   So sometimes that's kind of,
[00:10:49.840 --> 00:10:51.920]   it feels like a filter that lives between me
[00:10:51.920 --> 00:10:53.560]   and other people.
[00:10:53.560 --> 00:10:55.360]   I think the best people at Goop,
[00:10:55.360 --> 00:10:57.920]   you can feel like they drop that really quickly.
[00:10:58.960 --> 00:11:02.320]   And we work best and make the best stuff
[00:11:02.320 --> 00:11:05.600]   and grow in the best way when people say no
[00:11:05.600 --> 00:11:07.600]   and people challenge me.
[00:11:07.600 --> 00:11:12.240]   - Is Hollywood challenged in being able to speak its mind?
[00:11:12.240 --> 00:11:15.080]   Hollywood from the outside seems to have
[00:11:15.080 --> 00:11:17.920]   a very kind of monocultural point of view
[00:11:17.920 --> 00:11:20.920]   and you're very quickly canceled if you say the wrong thing
[00:11:20.920 --> 00:11:22.360]   or you say something that's on your mind
[00:11:22.360 --> 00:11:24.720]   that doesn't fit with the standard.
[00:11:24.720 --> 00:11:26.040]   And is that something that you view
[00:11:26.040 --> 00:11:28.840]   to be kind of an inherent challenge in Hollywood today?
[00:11:29.840 --> 00:11:31.920]   - You know, it's interesting.
[00:11:31.920 --> 00:11:35.520]   Like I think that,
[00:11:35.520 --> 00:11:39.000]   I think cancel culture is really toxic
[00:11:39.000 --> 00:11:42.520]   and really stems from, you know,
[00:11:42.520 --> 00:11:44.720]   I mean, I have a whole long theory about this,
[00:11:44.720 --> 00:11:49.720]   but I do feel like in our culture,
[00:11:49.720 --> 00:11:53.240]   there's a very binary way we look at good and bad.
[00:11:53.240 --> 00:11:55.600]   And I think we put a lot of pressure on ourselves
[00:11:55.600 --> 00:11:57.840]   and we are not good at understanding
[00:11:57.840 --> 00:12:01.840]   that we are human, we are all light and dark.
[00:12:01.840 --> 00:12:04.000]   And at various times we have great qualities,
[00:12:04.000 --> 00:12:06.640]   we have qualities we're working on.
[00:12:06.640 --> 00:12:08.880]   And I think what happens is
[00:12:08.880 --> 00:12:10.160]   because we don't live in a culture
[00:12:10.160 --> 00:12:14.160]   where we're allowed to sort of show our shadow sides,
[00:12:14.160 --> 00:12:18.640]   when somebody else does something that, you know,
[00:12:18.640 --> 00:12:20.640]   we can quickly have Schadenfreude over,
[00:12:20.640 --> 00:12:23.240]   we sort of jump on it because it feels like a release.
[00:12:23.240 --> 00:12:24.600]   You know, it feels like a relief, like,
[00:12:24.600 --> 00:12:26.640]   oh, well, at least I didn't do X.
[00:12:26.640 --> 00:12:27.920]   Like this guy.
[00:12:27.920 --> 00:12:31.560]   And I don't think it gets us very far as a culture.
[00:12:31.560 --> 00:12:34.200]   I think it's actually really reductive.
[00:12:34.200 --> 00:12:37.440]   And I'm hoping that we're gonna kind of mature
[00:12:37.440 --> 00:12:42.120]   out of this binary cancel culture way of looking at things.
[00:12:42.120 --> 00:12:45.520]   You know, I personally don't think about it
[00:12:45.520 --> 00:12:47.680]   because I would never open my mouth.
[00:12:47.680 --> 00:12:49.840]   Like I have to be myself.
[00:12:49.840 --> 00:12:52.440]   And of course you wanna be measured
[00:12:52.440 --> 00:12:55.040]   and you don't wanna unnecessarily, you know,
[00:12:55.040 --> 00:12:56.880]   get yourself in trouble or say something stupid.
[00:12:56.880 --> 00:12:58.360]   But at the same time, I think it's important
[00:12:58.360 --> 00:13:00.640]   to be true to who you are, be in integrity,
[00:13:00.640 --> 00:13:01.800]   say what you mean.
[00:13:01.800 --> 00:13:03.520]   And sometimes, you know,
[00:13:03.520 --> 00:13:05.560]   you see that that creates controversy,
[00:13:05.560 --> 00:13:08.520]   but I don't think that that's always a bad thing.
[00:13:08.520 --> 00:13:10.960]   - What is the future of Hollywood?
[00:13:10.960 --> 00:13:13.320]   I feel like I was thinking about your career
[00:13:13.320 --> 00:13:15.480]   'cause I was reviewing all the amazing films
[00:13:15.480 --> 00:13:16.640]   you were in in the '90s.
[00:13:16.640 --> 00:13:19.000]   And then obviously I mentioned, you know,
[00:13:19.000 --> 00:13:21.600]   the last run of the superhero films.
[00:13:21.600 --> 00:13:24.480]   It feels like you're a part of the last generation
[00:13:24.480 --> 00:13:27.520]   of movie stars and Freeberg and Sax and I
[00:13:27.520 --> 00:13:30.760]   are huge cinema buffs and fans of what you do.
[00:13:30.760 --> 00:13:32.880]   Maybe you could talk about--
[00:13:32.880 --> 00:13:34.560]   - I've watched your movies.
[00:13:34.560 --> 00:13:37.400]   - Chemop, he like popped, Chemop texted me like,
[00:13:37.400 --> 00:13:38.640]   "Hey, what should I watch tonight?"
[00:13:38.640 --> 00:13:39.840]   And I give him-- - Wrong.
[00:13:39.840 --> 00:13:42.720]   - Well, no, I tell you to watch something really great
[00:13:42.720 --> 00:13:44.120]   and you're like, "That was terrible."
[00:13:44.120 --> 00:13:45.080]   And I'm like, "Well, okay,
[00:13:45.080 --> 00:13:46.760]   "it's got seven Oscar nominations, I'm sorry."
[00:13:46.760 --> 00:13:47.760]   - Let's not say the name.
[00:13:47.760 --> 00:13:48.600]   - I'm not gonna say it. - It's hard.
[00:13:48.600 --> 00:13:49.440]   - We bleeped it.
[00:13:49.440 --> 00:13:50.880]   - Yeah. - Anyway.
[00:13:50.880 --> 00:13:51.720]   - Terrible movie.
[00:13:51.720 --> 00:13:52.560]   - Yes.
[00:13:52.560 --> 00:13:53.400]   - She wasn't in it.
[00:13:53.400 --> 00:13:54.840]   If she was in it, it'd be better.
[00:13:54.840 --> 00:13:56.000]   (audience laughing)
[00:13:56.000 --> 00:13:56.840]   - There I said it.
[00:13:56.840 --> 00:13:57.680]   - Tar was a great film.
[00:13:57.680 --> 00:13:59.480]   - Speaking of great film. - It was incredible.
[00:13:59.480 --> 00:14:00.840]   Did you see Tar, Gwyneth?
[00:14:00.840 --> 00:14:02.800]   Did you see Tar?
[00:14:02.800 --> 00:14:03.640]   - No, I have not.
[00:14:03.640 --> 00:14:05.680]   I have not, I've only heard Chemop's review.
[00:14:05.680 --> 00:14:06.520]   - Thank you.
[00:14:06.520 --> 00:14:07.360]   (audience laughing)
[00:14:07.360 --> 00:14:08.400]   - Oh, so you decided not to see it.
[00:14:08.400 --> 00:14:09.720]   But to the point, it seems like--
[00:14:09.720 --> 00:14:12.240]   - You are setting the agenda for Hollywood now, Chemop.
[00:14:12.240 --> 00:14:16.800]   - So what have we lost now with this,
[00:14:16.800 --> 00:14:18.440]   kind of the end of cinema?
[00:14:18.440 --> 00:14:19.760]   It's kind of heartbreaking for me
[00:14:19.760 --> 00:14:22.600]   and I wonder if it's heartbreaking for you too.
[00:14:22.600 --> 00:14:24.400]   And maybe then you could speak on the strike
[00:14:24.400 --> 00:14:26.680]   and maybe how that might get resolved.
[00:14:26.680 --> 00:14:28.040]   I know you're out of it pretty much,
[00:14:28.040 --> 00:14:30.800]   but maybe you could talk a little bit about the end of--
[00:14:30.800 --> 00:14:32.840]   - Yeah, what should the unions be fighting for?
[00:14:32.840 --> 00:14:34.840]   I mean, you're on the other side in a sense.
[00:14:34.840 --> 00:14:36.320]   You're running a tech company.
[00:14:36.320 --> 00:14:38.600]   You're probably figuring out how to use AI
[00:14:38.600 --> 00:14:41.040]   and all of these disruptive tools.
[00:14:41.040 --> 00:14:44.160]   Your old compatriots must need a lot of help and guidance
[00:14:44.160 --> 00:14:46.360]   to not fight for the wrong things.
[00:14:46.360 --> 00:14:48.560]   So yeah, how do you think about the future of Hollywood?
[00:14:48.560 --> 00:14:50.160]   Like how would you direct them like,
[00:14:50.160 --> 00:14:51.840]   "Hey guys, this matters
[00:14:51.840 --> 00:14:54.440]   "and this other stuff just doesn't matter."
[00:14:54.440 --> 00:14:57.520]   - Yeah, I mean, I think we're at an incredible inflection
[00:14:57.520 --> 00:15:02.520]   point and to start with your question, J. Cal,
[00:15:02.520 --> 00:15:06.000]   the inherent models of the business have changed so much
[00:15:06.000 --> 00:15:07.600]   as we know with streaming.
[00:15:07.600 --> 00:15:13.120]   I do think that it brings up really interesting questions
[00:15:13.120 --> 00:15:17.000]   around like, what does this mean for artists going forward?
[00:15:17.000 --> 00:15:19.960]   The business isn't monetized the way that it used to be.
[00:15:19.960 --> 00:15:22.640]   Residuals used to be a huge part
[00:15:22.640 --> 00:15:24.560]   of how artists made their living.
[00:15:24.560 --> 00:15:26.400]   And I do think that this is an area
[00:15:26.400 --> 00:15:30.040]   where the studios kind of need to readdress
[00:15:30.040 --> 00:15:33.000]   how they have been paying in the backend,
[00:15:33.000 --> 00:15:34.880]   especially on TV.
[00:15:34.880 --> 00:15:36.600]   But we are living in a time
[00:15:36.600 --> 00:15:38.280]   where there are these emerging technologies
[00:15:38.280 --> 00:15:41.760]   that just are going to change the way that things are made.
[00:15:41.760 --> 00:15:45.680]   And so I think, look, as you said, I'm kind of out of it.
[00:15:45.680 --> 00:15:49.520]   I don't act very much anymore.
[00:15:49.520 --> 00:15:52.320]   I am married to a television writer
[00:15:52.320 --> 00:15:55.040]   who knows far more about the ins and outs of this.
[00:15:55.040 --> 00:15:59.960]   But I do think there are,
[00:15:59.960 --> 00:16:02.440]   I think artists do need to understand that,
[00:16:02.440 --> 00:16:04.960]   it's like with anything, when an industry led by,
[00:16:04.960 --> 00:16:13.760]   first these technology, streaming, and now AI
[00:16:13.760 --> 00:16:15.040]   and these things that are coming around the corner,
[00:16:15.040 --> 00:16:18.920]   I think we all need to be open-minded
[00:16:19.560 --> 00:16:23.440]   and understand that the train has left the station.
[00:16:23.440 --> 00:16:24.880]   These technologies exist.
[00:16:24.880 --> 00:16:26.520]   So we're gonna have to find
[00:16:26.520 --> 00:16:28.560]   the best way forward through them.
[00:16:28.560 --> 00:16:30.160]   - What is your point of view?
[00:16:30.160 --> 00:16:32.280]   What is the conversation behind closed doors
[00:16:32.280 --> 00:16:35.200]   on generative art, generative film, where we're headed?
[00:16:35.200 --> 00:16:36.760]   Not the public conversation,
[00:16:36.760 --> 00:16:38.360]   but the behind doors dinner conversation
[00:16:38.360 --> 00:16:40.640]   with your colleagues and friends.
[00:16:40.640 --> 00:16:42.440]   - I think people that are really concerned,
[00:16:42.440 --> 00:16:45.240]   my actor friends are very concerned about the idea that,
[00:16:45.240 --> 00:16:47.800]   for example, I'll just use myself,
[00:16:47.800 --> 00:16:52.800]   that they could decide to make "The Royal Tenenbaums 2."
[00:16:52.800 --> 00:16:57.320]   And because I don't own my IP, Disney owns that IP
[00:16:57.320 --> 00:16:58.920]   and my name and likeness for that film,
[00:16:58.920 --> 00:17:02.040]   that they could just theoretically create a sequel
[00:17:02.040 --> 00:17:03.640]   and not ask my permission
[00:17:03.640 --> 00:17:07.680]   and that I wouldn't have to be paid for it.
[00:17:07.680 --> 00:17:10.760]   So that's kind of what the actors, where they go.
[00:17:10.760 --> 00:17:13.840]   For example, I invested in a company called Speechify
[00:17:13.840 --> 00:17:15.600]   where they use AI.
[00:17:15.600 --> 00:17:17.160]   You can, I don't know if you guys know the company.
[00:17:17.160 --> 00:17:20.200]   - I use it and you can read "The New York Times."
[00:17:20.200 --> 00:17:22.520]   You're one of the official voices on Speechify.
[00:17:22.520 --> 00:17:27.160]   - So, I read a bunch of stuff into a microphone
[00:17:27.160 --> 00:17:28.600]   and then AI took my voice.
[00:17:28.600 --> 00:17:32.400]   And now if you wanna read Walter Isaacson's new book
[00:17:32.400 --> 00:17:34.160]   on Elon, which I know David Sacks
[00:17:34.160 --> 00:17:36.920]   is gonna be the first person in line to buy that book.
[00:17:36.920 --> 00:17:40.280]   You can listen to it with my voice.
[00:17:40.280 --> 00:17:44.120]   So in that case, I said, I'm licensing it to you
[00:17:44.120 --> 00:17:45.240]   and here are the parameters.
[00:17:45.240 --> 00:17:47.520]   But I think the idea is going forward,
[00:17:47.520 --> 00:17:52.520]   if that wasn't the case, it could be a free for all.
[00:17:52.520 --> 00:17:55.680]   That's kind of what, that's what the actors are worried
[00:17:55.680 --> 00:17:56.520]   about.
[00:17:56.520 --> 00:18:00.080]   I think the writers that I speak to,
[00:18:00.080 --> 00:18:05.680]   they seem to be less worried about the AI piece right now
[00:18:05.680 --> 00:18:07.520]   because it's so nascent and obviously it's mining things
[00:18:07.520 --> 00:18:09.080]   that have already been written.
[00:18:09.080 --> 00:18:13.840]   And I think art that resonates with people comes
[00:18:13.840 --> 00:18:18.840]   from new ideas and new ways of creating resonant
[00:18:18.840 --> 00:18:20.560]   intersections for people.
[00:18:20.560 --> 00:18:23.200]   And I think we're always gonna need people for that.
[00:18:23.200 --> 00:18:25.240]   I mean, maybe I'm naive, but that's,
[00:18:25.240 --> 00:18:28.320]   so I don't think, I don't find writers behind closed doors
[00:18:28.320 --> 00:18:29.800]   as concerned about the AI piece
[00:18:29.800 --> 00:18:31.880]   as I do the actors right now.
[00:18:31.880 --> 00:18:32.720]   - That makes sense.
[00:18:32.720 --> 00:18:35.480]   We have a friend here who's a showrunner,
[00:18:35.480 --> 00:18:36.520]   is a television writer.
[00:18:36.520 --> 00:18:38.320]   He may be in the audience here somewhere.
[00:18:38.320 --> 00:18:39.640]   I think that's his attitude as well,
[00:18:39.640 --> 00:18:41.840]   which is like, I don't really wanna be on strike
[00:18:41.840 --> 00:18:46.000]   and I don't need to be protected from AI
[00:18:46.000 --> 00:18:48.320]   that's kind of like protecting me from a word processor
[00:18:48.320 --> 00:18:49.920]   or something like that.
[00:18:49.920 --> 00:18:52.160]   I mean, I think these AI tools are gonna be really useful
[00:18:52.160 --> 00:18:53.000]   to writers.
[00:18:53.000 --> 00:18:57.000]   It's gonna be kind of crazy to say that writers can't use
[00:18:57.000 --> 00:18:59.720]   generative AI tools in their research or writing
[00:18:59.720 --> 00:19:00.560]   or whatever.
[00:19:00.560 --> 00:19:01.840]   I agree with you about the actors.
[00:19:01.840 --> 00:19:02.880]   That's different.
[00:19:02.880 --> 00:19:05.200]   I think actors should be able to control their name
[00:19:05.200 --> 00:19:07.840]   and likeness and make licensing deals for that,
[00:19:07.840 --> 00:19:09.000]   that kind of stuff.
[00:19:09.000 --> 00:19:11.240]   But I think, but I do think there's like a little bit
[00:19:11.240 --> 00:19:14.520]   of paranoia going on with the Writers Guild.
[00:19:14.520 --> 00:19:17.920]   I think they're way too concerned that writers rooms
[00:19:17.920 --> 00:19:20.520]   are gonna get replaced with AI software.
[00:19:20.520 --> 00:19:22.760]   And I just think, this is a debate we have
[00:19:22.760 --> 00:19:24.280]   in other occupations as well,
[00:19:24.280 --> 00:19:27.840]   where people are really afraid that AI's just gonna replace
[00:19:27.840 --> 00:19:28.680]   all the jobs.
[00:19:28.680 --> 00:19:32.040]   And I think our view is, at least for the foreseeable future
[00:19:32.040 --> 00:19:33.840]   is gonna be more like co-pilots,
[00:19:33.840 --> 00:19:35.840]   where it's a human working with the software,
[00:19:35.840 --> 00:19:38.360]   not a total replacement of the human.
[00:19:38.360 --> 00:19:39.200]   - Yeah.
[00:19:40.960 --> 00:19:42.320]   I think that's right.
[00:19:42.320 --> 00:19:45.360]   - Can I ask you about unions for a second?
[00:19:45.360 --> 00:19:49.160]   So part of revitalizing maybe the movie industry,
[00:19:49.160 --> 00:19:52.680]   but a lot of these industries is just that sometimes
[00:19:52.680 --> 00:19:55.300]   the costs of making these things just get really
[00:19:55.300 --> 00:19:56.800]   outrageously high, right?
[00:19:56.800 --> 00:19:59.160]   And you've probably lived on sets of movies
[00:19:59.160 --> 00:20:00.920]   where it's just like these cost overruns
[00:20:00.920 --> 00:20:03.000]   and then you get into this tricky accounting
[00:20:03.000 --> 00:20:05.280]   and then all of a sudden one producer is suing the other.
[00:20:05.280 --> 00:20:08.280]   All of this stuff, at some level just boils down
[00:20:08.280 --> 00:20:12.440]   to there's just massive cost inflation that exists
[00:20:12.440 --> 00:20:14.200]   that probably shouldn't exist.
[00:20:14.200 --> 00:20:17.320]   Nine people doing a job that one person, et cetera.
[00:20:17.320 --> 00:20:19.640]   Just talk to us about what is the future
[00:20:19.640 --> 00:20:20.800]   of that kind of stuff?
[00:20:20.800 --> 00:20:24.560]   Like how do you provide opportunity?
[00:20:24.560 --> 00:20:26.200]   How do you protect folks?
[00:20:26.200 --> 00:20:28.640]   But then how do you make sure that the costs
[00:20:28.640 --> 00:20:30.980]   don't become so exorbitant that it just kills the industry
[00:20:30.980 --> 00:20:32.040]   without you noticing?
[00:20:32.040 --> 00:20:35.080]   - I think it's a really good question.
[00:20:36.080 --> 00:20:38.920]   I think you have to look at who profits
[00:20:38.920 --> 00:20:40.680]   from all of the inefficiencies.
[00:20:40.680 --> 00:20:45.680]   And it's one of the reasons that I feel so frustrated
[00:20:45.680 --> 00:20:50.080]   when I'm on set is because it is inefficient
[00:20:50.080 --> 00:20:52.440]   and it does feel like there's a lot of padding.
[00:20:52.440 --> 00:20:58.520]   But again, the systems that exist have been in place
[00:20:58.520 --> 00:21:03.120]   for a really long time.
[00:21:03.120 --> 00:21:08.120]   I don't really wanna opine on the state of unions per se.
[00:21:08.120 --> 00:21:13.920]   I think I would focus more on,
[00:21:13.920 --> 00:21:16.640]   like if I was running a store with efficiencies
[00:21:16.640 --> 00:21:21.640]   and I would rather create profit for shareholders
[00:21:21.640 --> 00:21:23.640]   from creating efficiencies and like dealing
[00:21:23.640 --> 00:21:26.400]   with all of the essentially off backs
[00:21:26.400 --> 00:21:28.000]   that it takes to make something like that.
[00:21:28.000 --> 00:21:31.880]   And less about not wanting to share profits
[00:21:31.880 --> 00:21:33.560]   with the artists.
[00:21:33.560 --> 00:21:38.480]   - As somebody who did movies in this incredible golden era,
[00:21:38.480 --> 00:21:40.440]   Sundance era, independent film,
[00:21:40.440 --> 00:21:42.160]   all these incredible new directors
[00:21:42.160 --> 00:21:43.680]   who you got to work with.
[00:21:43.680 --> 00:21:46.080]   And then this golden era of television arrived
[00:21:46.080 --> 00:21:47.360]   over the last four or five years,
[00:21:47.360 --> 00:21:50.040]   which is I'm sure you've enjoyed.
[00:21:50.040 --> 00:21:53.840]   And I know your husband's participated in that meaningfully.
[00:21:53.840 --> 00:21:57.600]   You must have gotten tons and tons of offers
[00:21:57.600 --> 00:22:01.240]   'cause they keep trying to get movie stars to do TV shows.
[00:22:01.240 --> 00:22:02.560]   Did you ever consider any of them?
[00:22:02.560 --> 00:22:05.560]   Are there any you passed on that we could hear about?
[00:22:05.560 --> 00:22:10.040]   What would it take to get you to do one of those TV shows?
[00:22:10.040 --> 00:22:11.440]   Like what have you passed on?
[00:22:11.440 --> 00:22:12.940]   I'm always interested in that.
[00:22:12.940 --> 00:22:16.400]   - My mother says, who's also a great actress,
[00:22:16.400 --> 00:22:19.120]   she says, "I'm never allowed to say anything
[00:22:19.120 --> 00:22:20.760]   "about what I passed on."
[00:22:20.760 --> 00:22:23.440]   She says, "It's not ladylike and I can't do it in public."
[00:22:23.440 --> 00:22:26.200]   So I have to defer to Blair and Danner.
[00:22:26.200 --> 00:22:27.740]   - Not even one, okay.
[00:22:27.740 --> 00:22:30.120]   (audience applauding)
[00:22:30.120 --> 00:22:32.400]   What would it take to, and have you considered it?
[00:22:32.400 --> 00:22:33.240]   Like it does seem like--
[00:22:33.240 --> 00:22:34.360]   - How about moderating?
[00:22:34.360 --> 00:22:35.520]   Have you ever moderated?
[00:22:35.520 --> 00:22:39.040]   (audience laughing)
[00:22:39.040 --> 00:22:39.880]   - We could use a new moderator here.
[00:22:39.880 --> 00:22:40.700]   - Just gonna throw it out there.
[00:22:40.700 --> 00:22:42.160]   - We'll be a panel of new moderators soon.
[00:22:42.160 --> 00:22:43.000]   - Yeah.
[00:22:43.000 --> 00:22:43.840]   - Can I ask you--
[00:22:43.840 --> 00:22:45.800]   - I assume meeting like in the next two hours
[00:22:45.800 --> 00:22:47.360]   when this thing is done.
[00:22:47.360 --> 00:22:48.560]   - Can I ask you your point of view
[00:22:48.560 --> 00:22:50.780]   on the rules that the Academy passed
[00:22:50.780 --> 00:22:53.260]   for qualifying for Best Picture?
[00:22:53.260 --> 00:22:55.960]   Obviously they added all these diversity rules
[00:22:55.960 --> 00:22:56.880]   this past year.
[00:22:56.880 --> 00:22:59.240]   I think they were formalized this past year.
[00:22:59.240 --> 00:23:01.160]   And we heard from Larry Summers earlier today.
[00:23:01.160 --> 00:23:03.320]   I know it's a pity you weren't here
[00:23:03.320 --> 00:23:05.720]   'cause there was a lot of great conversations.
[00:23:05.720 --> 00:23:09.080]   But Larry said something along the lines of
[00:23:09.080 --> 00:23:12.320]   self-esteem should come from achievement,
[00:23:12.320 --> 00:23:15.820]   not achievement coming, or I don't wanna butcher it.
[00:23:15.820 --> 00:23:18.840]   But basically we have a challenge right now
[00:23:18.840 --> 00:23:22.340]   that we aren't really earning the credit we get.
[00:23:22.340 --> 00:23:26.600]   And we risk seeing the best things not always win.
[00:23:26.600 --> 00:23:28.440]   Does the best film not win?
[00:23:28.440 --> 00:23:31.100]   If there's a lot of new qualifying criteria
[00:23:31.100 --> 00:23:34.640]   that might keep the best film out of the Best Picture
[00:23:34.640 --> 00:23:37.960]   nomination because it doesn't fit these new diversity rules,
[00:23:37.960 --> 00:23:38.800]   how do you view that?
[00:23:38.800 --> 00:23:41.800]   How does Hollywood behind closed doors talk about this?
[00:23:41.800 --> 00:23:43.600]   And is this the right way to kind of
[00:23:43.600 --> 00:23:47.240]   give the awards for the Best Pictures every year?
[00:23:47.240 --> 00:23:52.320]   - You know, Kratenberg, I honestly don't even know.
[00:23:52.320 --> 00:23:53.840]   Like I feel so out of this business.
[00:23:53.840 --> 00:23:57.240]   I don't even know about these new diversity rules.
[00:23:57.240 --> 00:23:58.480]   - Well to get nominated you have to be--
[00:23:58.480 --> 00:23:59.320]   - Let me come back to you.
[00:23:59.320 --> 00:24:00.720]   Can I educate myself and come back to you?
[00:24:00.720 --> 00:24:02.400]   - Yeah, that's the whole point of the podcast.
[00:24:02.400 --> 00:24:03.240]   - All good.
[00:24:03.240 --> 00:24:04.920]   - Well when you moderate these next episodes
[00:24:04.920 --> 00:24:05.760]   you'll be a better--
[00:24:05.760 --> 00:24:07.120]   - So I'm looking forward to it.
[00:24:07.120 --> 00:24:07.960]   I need a break.
[00:24:07.960 --> 00:24:10.160]   - I have a question which is, back to Goop for a second.
[00:24:10.160 --> 00:24:11.760]   So you're building distribution.
[00:24:11.760 --> 00:24:14.920]   This is like this theme this afternoon a little bit.
[00:24:14.920 --> 00:24:17.640]   With Alex, with you, with Jimmy who we're gonna talk about
[00:24:17.640 --> 00:24:20.400]   which is these new content creators emerge.
[00:24:20.400 --> 00:24:23.220]   You guys create formats that engage an audience.
[00:24:23.220 --> 00:24:24.840]   What they really give you is their trust.
[00:24:24.840 --> 00:24:27.080]   You build these new distribution rails.
[00:24:27.080 --> 00:24:28.360]   And then you decide, Gwyneth,
[00:24:28.360 --> 00:24:29.960]   where do you wanna point those distribution?
[00:24:29.960 --> 00:24:31.640]   Is it chocolate bars in Jimmy's case?
[00:24:31.640 --> 00:24:34.940]   Is it merch and chess related things for Alex?
[00:24:34.940 --> 00:24:38.760]   I'm sure that you and your team are looking at
[00:24:38.760 --> 00:24:41.060]   what are these areas that are just so brittle
[00:24:41.060 --> 00:24:43.420]   that can just be totally ripped apart?
[00:24:43.420 --> 00:24:45.400]   Where new brand consideration can happen.
[00:24:45.400 --> 00:24:47.200]   You can establish the trust.
[00:24:47.200 --> 00:24:49.240]   Can you just give us some insight into that?
[00:24:49.240 --> 00:24:51.220]   What are the old laggard businesses
[00:24:51.220 --> 00:24:53.120]   that are just ready to get dismantled?
[00:24:53.120 --> 00:24:55.720]   - That's a really good question.
[00:24:55.720 --> 00:24:57.960]   You know, I honestly don't think about
[00:24:57.960 --> 00:25:00.160]   going into new products in that way.
[00:25:00.160 --> 00:25:02.940]   Like I kind of do it more from the inside out.
[00:25:02.940 --> 00:25:05.940]   Like where is the (audio cuts out)
[00:25:05.940 --> 00:25:13.720]   - Uh-oh. - Uh-oh.
[00:25:13.720 --> 00:25:14.560]   - Uh-oh.
[00:25:14.560 --> 00:25:16.160]   - Zoom.
[00:25:16.160 --> 00:25:19.640]   I mean, it's held up pretty well so far.
[00:25:19.640 --> 00:25:24.720]   All right, with that, we'll thank.
[00:25:24.720 --> 00:25:26.120]   (audience laughs)
[00:25:26.120 --> 00:25:27.720]   - Gwyneth Paltrow.
[00:25:27.720 --> 00:25:29.180]   Amazing, well done.
[00:25:29.180 --> 00:25:32.520]   I mean, it's kind of great
[00:25:32.520 --> 00:25:36.240]   that she is so engaged with the pod.
[00:25:36.240 --> 00:25:41.420]   - Well, I'll tell you, her comment about waiting around
[00:25:41.420 --> 00:25:43.120]   on a film set really resonated with me.
[00:25:43.120 --> 00:25:44.120]   I've produced a couple of movies.
[00:25:44.120 --> 00:25:45.400]   I've been to movie sets.
[00:25:45.400 --> 00:25:47.840]   - Dolly and Thank You for Smoking, congratulations.
[00:25:47.840 --> 00:25:50.560]   - And if you talk to anybody who's ever visited a movie set,
[00:25:50.560 --> 00:25:53.840]   the first thing they will say every time is,
[00:25:53.840 --> 00:25:55.120]   there's so much waiting around.
[00:25:55.120 --> 00:25:56.320]   It's like, it's boring.
[00:25:56.320 --> 00:25:58.640]   It's a lot more boring than they thought it was gonna be.
[00:25:58.640 --> 00:26:01.400]   And there's a huge amount of time waiting around on sets
[00:26:01.400 --> 00:26:03.640]   for the next setup.
[00:26:03.640 --> 00:26:05.640]   They have to move the lights around or whatever.
[00:26:05.640 --> 00:26:10.160]   So I'll tell you, with Dolly, the Dolly movie we did,
[00:26:10.160 --> 00:26:12.400]   they would do like an eight to 10 hour shooting day.
[00:26:12.400 --> 00:26:14.040]   I would get the dailies,
[00:26:14.040 --> 00:26:16.840]   which is all the material they shot in a link.
[00:26:16.840 --> 00:26:18.660]   It's basically like a Dropbox folder.
[00:26:18.660 --> 00:26:20.560]   Everything they shot was two hours.
[00:26:20.560 --> 00:26:22.080]   So you take a 10 hour shooting day,
[00:26:22.080 --> 00:26:24.560]   you're only shooting for two hours of that.
[00:26:24.560 --> 00:26:27.160]   And then that two hours is maybe
[00:26:27.160 --> 00:26:29.040]   two or three pages of material.
[00:26:29.040 --> 00:26:30.480]   - So two or three minutes.
[00:26:30.480 --> 00:26:33.380]   - You're watching five takes of every angle or whatever.
[00:26:33.380 --> 00:26:37.280]   So there is a huge amount of just sort of boredom on a set.
[00:26:37.280 --> 00:26:40.640]   So I think it's really cool that she,
[00:26:40.640 --> 00:26:41.760]   while thinking about this, is like,
[00:26:41.760 --> 00:26:43.400]   hey, I could start a company.
[00:26:43.400 --> 00:26:45.960]   And I think you're going through one of the first
[00:26:45.960 --> 00:26:47.880]   to do this, like 15 years ago.
[00:26:47.880 --> 00:26:49.880]   - Yeah, I mean, she came before anybody
[00:26:49.880 --> 00:26:54.880]   and I think she had a lot of iteration along the way.
[00:26:54.880 --> 00:26:58.060]   (upbeat music)
[00:26:58.900 --> 00:27:01.480]   (upbeat music)
[00:27:02.400 --> 00:27:04.980]   (upbeat music)
[00:27:04.980 --> 00:27:07.560]   (upbeat music)
[00:27:07.560 --> 00:27:10.140]   (upbeat music)
[00:27:10.140 --> 00:27:12.720]   (upbeat music)
[00:27:13.560 --> 00:27:16.140]   (upbeat music)
[00:27:16.140 --> 00:27:18.720]   (upbeat music)
[00:27:18.720 --> 00:27:22.500]   (upbeat music)
[00:27:22.500 --> 00:27:33.080]   (upbeat music)
[00:27:33.080 --> 00:27:41.040]   (upbeat music)
[00:27:45.180 --> 00:27:47.760]   (upbeat music)
[00:27:47.760 --> 00:27:50.340]   (upbeat music)
[00:27:50.340 --> 00:27:52.920]   (upbeat music)
[00:27:52.920 --> 00:27:54.920]   I'm doing all of it
[00:27:54.920 --> 00:27:56.920]   (music)

