
[00:00:00.000 --> 00:00:07.000]   Elisabeth Buffard Reviewer: Peter van de Ven
[00:00:07.000 --> 00:00:16.120]   Hey, good morning, everyone.
[00:00:16.120 --> 00:00:21.160]   Let's start by taking a step back.
[00:00:21.160 --> 00:00:26.240]   Remember GANs, Generative Adversarial Networks.
[00:00:27.000 --> 00:00:31.560]   They represented a very compelling architecture, in my opinion.
[00:00:31.560 --> 00:00:34.440]   Two neural networks working hand-in-hand,
[00:00:34.440 --> 00:00:36.520]   one generating and one is the critic,
[00:00:36.520 --> 00:00:39.080]   in order to generate high-quality outcomes.
[00:00:39.080 --> 00:00:44.920]   Then came Transformers, that changed everything.
[00:00:44.920 --> 00:00:46.840]   We dropped the adversarial,
[00:00:46.840 --> 00:00:50.120]   and the focus became solely on the generative.
[00:00:50.120 --> 00:00:54.960]   And they became the state-of-the-art for a variety of use cases.
[00:00:54.960 --> 00:00:59.520]   But code is very, very nuanced.
[00:00:59.520 --> 00:01:05.520]   We believe that in order to generate code that actually works as intended,
[00:01:05.520 --> 00:01:10.480]   the right architecture is actually GAN-like architecture.
[00:01:10.480 --> 00:01:15.040]   And what I mean by that is not the actual neural network.
[00:01:15.040 --> 00:01:16.400]   It's the system.
[00:01:16.400 --> 00:01:19.920]   It's the concept of having two different components.
[00:01:19.920 --> 00:01:23.040]   One focused on the code generation piece,
[00:01:23.040 --> 00:01:26.000]   and one that serves as the critic.
[00:01:26.000 --> 00:01:28.040]   We call it the code integrity component.
[00:01:29.040 --> 00:01:35.120]   It actually analyzes the outcomes, the generation of the code gen component,
[00:01:35.120 --> 00:01:38.160]   and it reviews it, it analyzes it.
[00:01:38.160 --> 00:01:41.280]   It tries to figure out all the different edge cases,
[00:01:41.280 --> 00:01:46.720]   in order to generate high-quality code that works as intended,
[00:01:46.720 --> 00:01:48.720]   based on the developer's actual intent.
[00:01:49.600 --> 00:01:54.160]   This is our focus at Codium AI, on the critic piece.
[00:01:54.160 --> 00:01:58.160]   We help developers understand the behaviors of their code.
[00:01:58.160 --> 00:02:02.640]   We believe that behavior coverage
[00:02:02.640 --> 00:02:06.400]   is a more useful metric than actual code coverage.
[00:02:06.400 --> 00:02:09.280]   We help them generate tests for these behaviors,
[00:02:09.280 --> 00:02:12.160]   enhance their code, and review their code.
[00:02:12.160 --> 00:02:15.840]   And we do that throughout the developer lifecycle,
[00:02:15.840 --> 00:02:20.400]   leveraging our IDE extensions for both JetBrains and VS Code,
[00:02:20.400 --> 00:02:22.960]   and our Git plugin.
[00:02:22.960 --> 00:02:27.040]   And then soon in the future, in the near future,
[00:02:27.040 --> 00:02:29.680]   we will also offer APIs for this,
[00:02:29.680 --> 00:02:33.040]   to be able to be embedded in various agents.
[00:02:33.040 --> 00:02:39.440]   So, we're going to focus the majority of the time in a live demo,
[00:02:40.960 --> 00:02:44.000]   which is a risky thing to do in this situation here.
[00:02:44.000 --> 00:02:58.000]   But let's go for it.
[00:02:58.000 --> 00:03:01.440]   Okay, I'm here in my VS Code.
[00:03:01.440 --> 00:03:03.600]   I have the Codium AI extension installed.
[00:03:03.600 --> 00:03:09.360]   We now have around 200,000 installs across both JetBrains and VS Code.
[00:03:10.480 --> 00:03:13.840]   I have here an open source project that's called AutoScraper.
[00:03:13.840 --> 00:03:18.720]   It's basically a scraping class that automates the process of
[00:03:18.720 --> 00:03:23.040]   generating the rules for scraping information from websites.
[00:03:23.040 --> 00:03:25.520]   It's a very cool project.
[00:03:25.520 --> 00:03:28.320]   It has more than 5,000 GitHub stars.
[00:03:28.320 --> 00:03:31.920]   But the problem is that it doesn't have any tests.
[00:03:31.920 --> 00:03:35.920]   So, it's very hard to make changes to a project
[00:03:35.920 --> 00:03:40.560]   where it doesn't have any tests because there's nothing that protects you from making changes.
[00:03:40.560 --> 00:03:45.120]   So, I'm going to go ahead here and trigger Codium AI on this class.
[00:03:45.120 --> 00:03:49.440]   This is a 600-line class, complex code.
[00:03:49.440 --> 00:03:54.160]   And you can see that I can trigger Codium AI either on the class level or at the method level.
[00:03:55.760 --> 00:03:58.480]   So, I'm starting on the class. I'm actually going to re-trigger it.
[00:03:58.480 --> 00:04:04.800]   The first thing that happens is that Codium analyzes the class.
[00:04:04.800 --> 00:04:08.480]   It basically maps out different behaviors.
[00:04:08.480 --> 00:04:10.880]   And it starts generating tests.
[00:04:10.880 --> 00:04:14.240]   You can see it starts streaming the tests.
[00:04:14.240 --> 00:04:15.520]   I already have one, two.
[00:04:15.520 --> 00:04:16.800]   I'm getting more tests.
[00:04:16.800 --> 00:04:18.560]   You can see some of them are quite complex.
[00:04:18.560 --> 00:04:23.360]   It also generates a code explanation, detailed code explanation,
[00:04:23.360 --> 00:04:25.280]   that shows me how this class actually works.
[00:04:25.280 --> 00:04:31.440]   The example usage, the different components, the methods, very detailed.
[00:04:31.440 --> 00:04:35.280]   And then I have all my tests.
[00:04:40.000 --> 00:04:46.400]   As you can see, we look at different examples, both happy path, edge cases, variety of cases.
[00:04:46.400 --> 00:04:59.920]   Okay, so here I have the different behaviors that were generated.
[00:04:59.920 --> 00:05:01.440]   Now, this is crucial.
[00:05:01.440 --> 00:05:04.640]   We're basically mapping the different behaviors of this class,
[00:05:04.640 --> 00:05:07.040]   doing both happy path, edge cases.
[00:05:07.040 --> 00:05:12.000]   And for each one of them, we can drill deeper down and see the sub behaviors below them.
[00:05:12.000 --> 00:05:15.920]   And we can generate tests for anyone that is important for us.
[00:05:15.920 --> 00:05:18.160]   So, let's pick a few and add additional tests.
[00:05:18.160 --> 00:05:22.960]   Let's pick some edge cases as well.
[00:05:22.960 --> 00:05:24.480]   Let's generate a test here.
[00:05:24.480 --> 00:05:26.880]   Maybe here we'll generate another one for an edge case.
[00:05:26.880 --> 00:05:32.000]   And you can see it's very simple.
[00:05:32.000 --> 00:05:35.920]   A few clicks, and I have a test suite that is built out.
[00:05:35.920 --> 00:05:37.120]   I already have nine tests here.
[00:05:37.120 --> 00:05:40.000]   The next step will be to run these tests.
[00:05:40.000 --> 00:05:41.040]   So, let's go ahead and do that.
[00:05:41.040 --> 00:05:49.200]   So, I'm hitting run and auto fix.
[00:05:49.200 --> 00:05:52.640]   You can see some of these very complex tests are actually passing.
[00:05:52.640 --> 00:05:55.920]   And here I have a test that actually failed.
[00:05:55.920 --> 00:06:01.440]   What happens in a failure is that the model actually analyzes, reflects on the failure,
[00:06:02.160 --> 00:06:05.440]   and then it tries to generate a fix in an automated manner.
[00:06:05.440 --> 00:06:09.680]   So, we have a fix generated.
[00:06:09.680 --> 00:06:12.240]   And now it's going to be run.
[00:06:12.240 --> 00:06:16.320]   And it passed in a second try.
[00:06:17.360 --> 00:06:19.840]   So, this is this chain of thought.
[00:06:19.840 --> 00:06:23.360]   This reflection process in order to get to a high-quality test suite.
[00:06:23.360 --> 00:06:26.320]   Okay.
[00:06:26.320 --> 00:06:28.240]   So, I'm going to start with these eight tests.
[00:06:28.240 --> 00:06:30.400]   Let's open them as a file.
[00:06:34.240 --> 00:06:43.520]   I'm going to save them in my project.
[00:06:50.080 --> 00:06:50.480]   And done.
[00:06:50.480 --> 00:06:52.560]   I have a test suite that now protects me.
[00:06:52.560 --> 00:06:58.240]   So, now I'm going to go ahead and take the next step.
[00:06:58.240 --> 00:07:00.720]   Let's use Codium AI to actually enhance this code.
[00:07:00.720 --> 00:07:03.680]   Now that I have a test suite that protects me.
[00:07:04.800 --> 00:07:07.200]   So, I'm going to choose a method here.
[00:07:07.200 --> 00:07:10.960]   The build method that has a lot of the main functionality of the class.
[00:07:10.960 --> 00:07:14.800]   I'm going to trigger Codium AI on that.
[00:07:14.800 --> 00:07:20.320]   And now let's focus on the code suggestions component of Codium AI.
[00:07:20.320 --> 00:07:25.840]   So, Codium analyzes this code.
[00:07:26.960 --> 00:07:30.800]   And it basically recommends different improvements, enhancements.
[00:07:30.800 --> 00:07:33.200]   And these are deep enhancements.
[00:07:33.200 --> 00:07:37.680]   We're not talking about linting or things like that.
[00:07:37.680 --> 00:07:44.400]   We're talking about things related to performance, security, best practices, readability.
[00:07:44.400 --> 00:07:46.720]   So, I'm going to look at this.
[00:07:46.720 --> 00:07:50.240]   Let's choose one that makes sense.
[00:07:50.240 --> 00:07:53.920]   Maybe the first one that looks quite important for performance.
[00:07:54.800 --> 00:08:00.800]   Basically, it recommends to replace the hash leave with Blake 3.
[00:08:00.800 --> 00:08:02.800]   I'm going to prepare the code changes.
[00:08:02.800 --> 00:08:05.120]   And apply it to my code.
[00:08:05.120 --> 00:08:09.760]   And now I can save this.
[00:08:09.760 --> 00:08:13.040]   But remember, now I have a test suite.
[00:08:13.040 --> 00:08:16.400]   So, now I can actually go to my test suite.
[00:08:16.400 --> 00:08:19.680]   And run it.
[00:08:19.680 --> 00:08:24.240]   And, of course, it broke on me.
[00:08:24.800 --> 00:08:28.400]   For some reason, as things happen in a demo.
[00:08:28.400 --> 00:08:35.360]   But, let's see this again.
[00:08:35.360 --> 00:08:39.600]   Okay, I have one test that failed.
[00:08:39.600 --> 00:08:43.680]   I'm going to ignore that for now.
[00:08:49.920 --> 00:08:50.960]   Okay, so let's continue.
[00:08:50.960 --> 00:08:55.920]   I created my test suite.
[00:08:55.920 --> 00:08:57.360]   I enhanced my code.
[00:08:57.360 --> 00:09:00.160]   The next step would be to prepare for my PR.
[00:09:00.160 --> 00:09:04.960]   So, I'm going to go ahead here and commit these changes.
[00:09:08.960 --> 00:09:11.600]   And I'm going to go to the code you may I PR assistant.
[00:09:11.600 --> 00:09:14.640]   And I'm going to do a slash commit to get a commit message.
[00:09:14.640 --> 00:09:21.120]   And now I have a commit message.
[00:09:21.120 --> 00:09:21.920]   So, I can commit.
[00:09:27.200 --> 00:09:33.600]   And now that I committed my changes, I can then go ahead to the last step and prepare for the PR.
[00:09:33.600 --> 00:09:34.880]   So, I'm going to do a slash review.
[00:09:34.880 --> 00:09:41.520]   And that's basically a review process that code you may I would do.
[00:09:41.520 --> 00:09:45.360]   And it will try to see if there is any issues, anything I may have missed.
[00:09:45.360 --> 00:09:47.680]   It will summarize the PR.
[00:09:47.680 --> 00:09:48.720]   It will give it a score.
[00:09:48.720 --> 00:09:53.200]   And then we can see if there is anything that maybe I have missed here.
[00:09:53.200 --> 00:09:54.480]   Let's take a look.
[00:09:54.480 --> 00:09:57.200]   So, this is the main theme of the PR.
[00:09:57.200 --> 00:09:58.960]   You can see that it's tested.
[00:09:58.960 --> 00:10:02.240]   You can see that it's basically telling me that it's pretty well structured.
[00:10:02.240 --> 00:10:06.720]   Let's let it continue.
[00:10:10.160 --> 00:10:14.240]   But it says that it does introduce a potential security vulnerability.
[00:10:14.240 --> 00:10:18.320]   So, I'm going to do a slash improve to try to fix that.
[00:10:18.320 --> 00:10:23.040]   And it looks like I forgot an API key in my code.
[00:10:23.040 --> 00:10:32.880]   So, CodeMai will then suggest a fix for this.
[00:10:32.880 --> 00:10:36.080]   And I can actually see the API in my code.
[00:10:39.680 --> 00:10:40.560]   Let's give it a second.
[00:10:40.560 --> 00:10:46.320]   It looks like I'm going to do it again.
[00:10:46.320 --> 00:10:56.000]   And this is where I actually have the API in my code.
[00:10:56.000 --> 00:11:01.920]   Yeah.
[00:11:01.920 --> 00:11:02.560]   Now, here we go.
[00:11:02.560 --> 00:11:06.560]   So, basically, it's saying here's the API key.
[00:11:06.560 --> 00:11:09.200]   I'm going to click on this and it will launch me to where I actually forgot
[00:11:09.200 --> 00:11:09.920]   the API key.
[00:11:09.920 --> 00:11:12.160]   Forgot the API key.
[00:11:12.160 --> 00:11:14.960]   And this is the actual fix.
[00:11:14.960 --> 00:11:20.960]   So, with that, I'm going to conclude the demo so we can go back to the slides.
[00:11:20.960 --> 00:11:29.520]   So, we were able to see how we were able to use CodeMai to map our behaviors, to generate tests,
[00:11:29.520 --> 00:11:32.320]   to review our code, and to do it throughout the entire life cycle.
[00:11:32.320 --> 00:11:37.840]   We also have, as I mentioned, a Git plugin that enables us to do that inside of GitHub as well.
[00:11:38.480 --> 00:11:42.880]   So, I'm going to end with a personal note.
[00:11:42.880 --> 00:11:47.840]   So, we're a company that is based in Israel.
[00:11:47.840 --> 00:11:55.200]   While we were on the plane on the way here, the Hamas terrorist organization launched a vicious attack on Israel.
[00:11:55.200 --> 00:12:00.880]   The Hamas terrorists are not humans.
[00:12:00.880 --> 00:12:02.000]   They are animals.
[00:12:02.000 --> 00:12:05.680]   Maybe not even animals.
[00:12:07.920 --> 00:12:20.320]   They entered into towns, they slaughtered men, women, and children, innocent people in their home, and abducted many.
[00:12:20.320 --> 00:12:21.280]   They entered into the Gaza Strip.
[00:12:21.280 --> 00:12:27.520]   This is the picture that my co-founder and CEO, Itamao, sent me.
[00:12:27.520 --> 00:12:33.840]   He left his eight months pregnant wife at home, and is now in military reserve duty.
[00:12:34.400 --> 00:12:41.520]   In the screen, you can see a chart that shows the CodeMai usage constantly increasing.
[00:12:41.520 --> 00:12:44.960]   Behind it is his rifle.
[00:12:44.960 --> 00:12:48.240]   We will prevail.
[00:12:49.520 --> 00:13:00.080]   Thank you.

