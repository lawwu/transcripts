
[00:00:00.000 --> 00:00:07.400]   It's not only software engineering problem, it's also you have subject matter experts.
[00:00:07.400 --> 00:00:12.600]   So you have logistics experts looking at the process and saying, "Here's where a robot
[00:00:12.600 --> 00:00:14.680]   would make sense to integrate."
[00:00:14.680 --> 00:00:20.320]   So in this way, you did increase efficiency, not by removing one task and saying, "Okay,
[00:00:20.320 --> 00:00:26.680]   that's the robot, it's doing it," but by re-architecting how you're just moving or efficiently working
[00:00:26.680 --> 00:00:28.120]   inside the factory itself.
[00:00:28.120 --> 00:00:32.520]   You're listening to Gradient Dissent, a show about machine learning in the real world,
[00:00:32.520 --> 00:00:34.560]   and I'm your host, Lukas Biewald.
[00:00:34.560 --> 00:00:40.200]   Jean-Marc Galkazzi is a research engineer and founding member of a company called Idealworks.
[00:00:40.200 --> 00:00:42.400]   Tell me about what you're working on at Idealworks.
[00:00:42.400 --> 00:00:43.400]   Sure.
[00:00:43.400 --> 00:00:50.640]   So yeah, basically in startups, it's a little bit hard to have a specific job, like a very
[00:00:50.640 --> 00:00:52.240]   specific task.
[00:00:52.240 --> 00:01:01.960]   But basically what I'm working on is applied AI, and what this means is we have basically
[00:01:01.960 --> 00:01:03.000]   two products.
[00:01:03.000 --> 00:01:06.040]   Maybe we can start even with what Idealworks is doing.
[00:01:06.040 --> 00:01:07.040]   So we have two products.
[00:01:07.040 --> 00:01:11.720]   One of them is our smart transport robot, which is an AMR.
[00:01:11.720 --> 00:01:14.240]   We call it the IW Hub.
[00:01:14.240 --> 00:01:17.280]   And sorry, what's an AMR?
[00:01:17.280 --> 00:01:18.320]   What's an AMR?
[00:01:18.320 --> 00:01:26.680]   So imagine it as a small robot which can drive autonomously inside your factory or maybe
[00:01:26.680 --> 00:01:27.680]   even outdoors.
[00:01:27.680 --> 00:01:30.440]   You can find outdoors AMRs also.
[00:01:30.440 --> 00:01:37.160]   And it can take decisions on its own for its navigation in a known environment or even
[00:01:37.160 --> 00:01:39.520]   sometimes in unknown environments.
[00:01:39.520 --> 00:01:47.240]   And basically the task of our IW Hub, the AMR, is to transport objects inside the factory
[00:01:47.240 --> 00:01:52.280]   from one place to the other and do it autonomously.
[00:01:52.280 --> 00:01:57.560]   And once you have multiple of those in the same factory, you're like, "Okay, how do I
[00:01:57.560 --> 00:02:00.040]   coordinate all this work?"
[00:02:00.040 --> 00:02:05.920]   Because even if you get human level intelligence on the robots, you still need rules.
[00:02:05.920 --> 00:02:09.200]   You still need rules to just avoid chaos.
[00:02:09.200 --> 00:02:14.920]   And that's where our AnyFleet software comes in, which is a fleet management system.
[00:02:14.920 --> 00:02:21.440]   And what we call a fleet is just a group of our AMRs in this case.
[00:02:21.440 --> 00:02:28.600]   And where do we find the use of some AI tool or AI solutions?
[00:02:28.600 --> 00:02:35.400]   Could be both on the robot itself, some edge AI, which is common, I guess, to listeners
[00:02:35.400 --> 00:02:42.440]   of your podcast, everything related to computer vision, to even RL for navigation or for movement
[00:02:42.440 --> 00:02:44.080]   and control.
[00:02:44.080 --> 00:02:47.840]   But you can also find it on our fleet management system.
[00:02:47.840 --> 00:02:55.400]   And on the fleet management system, it could look more like the operations research aspect
[00:02:55.400 --> 00:03:02.320]   more than models being just deployed and trained to control the robots.
[00:03:02.320 --> 00:03:03.320]   Yeah.
[00:03:03.320 --> 00:03:08.880]   It kind of sounds like a classic optimization problem from way back, right?
[00:03:08.880 --> 00:03:11.160]   To manage a fleet of robots.
[00:03:11.160 --> 00:03:12.160]   Exactly.
[00:03:12.240 --> 00:03:17.320]   And these boring solutions are the ones that work best in production environments.
[00:03:17.320 --> 00:03:24.640]   So are these robots designed for a specific factory or are you selling general purpose
[00:03:24.640 --> 00:03:25.640]   robots?
[00:03:25.640 --> 00:03:26.640]   How does that work?
[00:03:26.640 --> 00:03:27.640]   Yeah.
[00:03:27.640 --> 00:03:31.080]   So basically they are designed for indoors factories.
[00:03:31.080 --> 00:03:33.320]   So that's for first case.
[00:03:33.320 --> 00:03:37.020]   But we don't design them for specific kinds of factories.
[00:03:37.020 --> 00:03:45.560]   So we have now external customers, which are warehouses where the main tasks of a warehouse
[00:03:45.560 --> 00:03:52.640]   is just delivering objects inside the warehouse itself and packaging them in a specific way.
[00:03:52.640 --> 00:03:54.780]   And we have production lines.
[00:03:54.780 --> 00:04:00.860]   So for instance, Idealworks is 100% owned by BMW Group.
[00:04:00.860 --> 00:04:04.480]   And that's where the project initially started at BMW Group.
[00:04:04.480 --> 00:04:10.060]   And that's why we have a lot of factories building cars where our robot is actually
[00:04:10.060 --> 00:04:12.980]   helping in this process.
[00:04:12.980 --> 00:04:17.960]   And you can see multiple kinds of dynamics that you can find.
[00:04:17.960 --> 00:04:22.140]   So a warehouse dynamics is a bit different than the production line dynamics in this
[00:04:22.140 --> 00:04:23.140]   case.
[00:04:23.140 --> 00:04:30.600]   But they are similar enough for the robot to be able to act and take decisions correctly
[00:04:30.600 --> 00:04:31.980]   in both of them.
[00:04:31.980 --> 00:04:37.580]   And are humans putting the objects on the robot and then they travel around?
[00:04:37.580 --> 00:04:40.020]   Or how do things get on the robot?
[00:04:40.020 --> 00:04:41.320]   Yeah, nice question.
[00:04:41.320 --> 00:04:49.260]   So our robot is basically like a rectangular shape and it's very low on the ground.
[00:04:49.260 --> 00:04:55.300]   So what it basically does, it drives under a specific object and then lift it up and
[00:04:55.300 --> 00:04:56.780]   then moves around.
[00:04:56.780 --> 00:05:01.020]   And is this like a big box or what kind of objects should I be imagining?
[00:05:01.020 --> 00:05:03.420]   Yeah, you can imagine it.
[00:05:03.420 --> 00:05:11.260]   So what we call a dolly basically is a rectangular metallic shape with four wheels.
[00:05:11.260 --> 00:05:15.060]   And on top of the shape, you can put whatever you want.
[00:05:15.060 --> 00:05:22.260]   And this gives some flexibility on the types of objects you can carry around.
[00:05:22.260 --> 00:05:26.820]   Because as long as we can go under this dolly, we can carry the object itself.
[00:05:26.820 --> 00:05:29.540]   But actually it's kind of a special shape that you can drive under, right?
[00:05:29.540 --> 00:05:34.300]   Like do you have some kind of custom thing that lifts an object off the ground where
[00:05:34.300 --> 00:05:37.140]   the robot can get underneath it?
[00:05:37.140 --> 00:05:44.820]   If the object is directly on the ground, we have specific, I would say custom blocks that
[00:05:44.820 --> 00:05:47.820]   we can sell our customers where they can put them.
[00:05:47.820 --> 00:05:56.140]   Let's say if they have a wooden pallet that's like directly on the ground, we can sell specific
[00:05:56.140 --> 00:06:01.660]   objects where you can put on the pallets on top of them and then you can drive around
[00:06:01.660 --> 00:06:06.380]   like you can be able to lift up the pallets easily in this case.
[00:06:06.380 --> 00:06:09.460]   And I guess, are these actually deployed in real factories?
[00:06:09.460 --> 00:06:12.460]   Could I go see one driving around?
[00:06:12.460 --> 00:06:13.460]   Of course.
[00:06:13.460 --> 00:06:14.460]   Of course.
[00:06:14.460 --> 00:06:23.020]   So like last time, Chris, I guess was at our company and we didn't have the chance to show
[00:06:23.020 --> 00:06:25.300]   him the robot directly.
[00:06:25.300 --> 00:06:29.140]   But of course we have robots driving already at BMW.
[00:06:29.140 --> 00:06:34.900]   So we have multiple factories inside BMW group where our robots are already moving around.
[00:06:34.900 --> 00:06:40.860]   And literally as we speak now, some robots are just moving objects around and then delivering
[00:06:40.860 --> 00:06:45.860]   them while keeping the logistics process efficient.
[00:06:45.860 --> 00:06:47.780]   And can the robots really freely move?
[00:06:47.780 --> 00:06:52.180]   I feel like I've been at factories where there's like specific lines that the robots drive
[00:06:52.180 --> 00:06:55.500]   on to sort of separate them from the humans.
[00:06:55.500 --> 00:06:57.340]   Can they really like navigate anywhere in the factory?
[00:06:57.340 --> 00:06:58.980]   How do you do that?
[00:06:58.980 --> 00:06:59.980]   Yeah.
[00:06:59.980 --> 00:07:04.340]   That's actually a very good question because in factories, especially in Germany, you have
[00:07:04.340 --> 00:07:10.260]   very specific rules on how you can drive or where you can drive.
[00:07:10.260 --> 00:07:15.260]   And basically you can imagine it as kind of free.
[00:07:15.260 --> 00:07:20.340]   You have kind of a lane as if you're driving your own car.
[00:07:20.340 --> 00:07:27.500]   So you can't go on the sidewalk basically, because that's like restricted area for pedestrians,
[00:07:27.500 --> 00:07:32.500]   but you are free to overtake obstacles in your own lane.
[00:07:32.500 --> 00:07:34.260]   And what were people doing before this?
[00:07:34.260 --> 00:07:36.700]   Were they driving around like forklifts or something?
[00:07:36.700 --> 00:07:39.100]   Or what is this actually replacing?
[00:07:39.100 --> 00:07:40.100]   Yeah.
[00:07:40.100 --> 00:07:50.340]   So that's one question, which like always, whenever you talk about autonomy in factories,
[00:07:50.340 --> 00:07:53.700]   the first instinct is we're replacing humans.
[00:07:53.700 --> 00:07:56.740]   Like we're just doing it to replace humans.
[00:07:56.740 --> 00:08:04.100]   And actually when the project started at BMW Group, the main goal was that in some cities
[00:08:04.100 --> 00:08:12.180]   in Germany where you have huge factories for BMW Group, literally everyone is already employed
[00:08:12.180 --> 00:08:13.180]   at the factory.
[00:08:13.180 --> 00:08:19.640]   So there's no one without a job and they need to expand this factory itself.
[00:08:19.640 --> 00:08:27.500]   So it's more of a way to expand easily than to actually replace the people who are working
[00:08:27.500 --> 00:08:28.580]   now.
[00:08:28.580 --> 00:08:31.700]   And is it like hard to coordinate with humans?
[00:08:31.700 --> 00:08:36.620]   Like I would think that, how does it work?
[00:08:36.620 --> 00:08:42.020]   So the robot goes and wants to pick something up, but then presumably a human needs to do
[00:08:42.020 --> 00:08:43.020]   something with it.
[00:08:43.020 --> 00:08:49.420]   So how does it know to kind of like wait until it's ready to take the part to some other
[00:08:49.420 --> 00:08:50.420]   place?
[00:08:50.420 --> 00:08:51.420]   Yeah.
[00:08:51.420 --> 00:08:58.980]   So this human robot interaction is also important, not only on the pickup or delivery, but even
[00:08:58.980 --> 00:09:00.940]   whenever it's driving.
[00:09:00.940 --> 00:09:08.700]   So usually if you're on the road and you see someone coming in the car, maybe a simple
[00:09:08.700 --> 00:09:14.540]   eye contact, you would understand if they will let you go or they want to just keep
[00:09:14.540 --> 00:09:15.740]   going.
[00:09:15.740 --> 00:09:20.220]   But with the robot, it's a bit difficult because when you look at it, you're like, okay, what
[00:09:20.220 --> 00:09:21.220]   is it about to do?
[00:09:21.220 --> 00:09:24.740]   Is it about to accelerate now or what?
[00:09:24.740 --> 00:09:31.540]   So we have some kind of lights on the robot itself to give some kind of visual feedback
[00:09:31.540 --> 00:09:35.140]   for humans to understand what it's about to do.
[00:09:35.140 --> 00:09:42.300]   And on delivery locations or on pickup locations, it's basically requested already by humans.
[00:09:42.300 --> 00:09:49.000]   So you can imagine as you have a production line and you have like a huge stack of objects
[00:09:49.000 --> 00:09:53.260]   that you're taking and building the car, putting the objects inside.
[00:09:53.260 --> 00:09:55.980]   And then at one point it's empty.
[00:09:55.980 --> 00:10:03.420]   So you click on what we call a call button, which will call a robot to come in and it
[00:10:03.420 --> 00:10:05.260]   will actually call two robots.
[00:10:05.260 --> 00:10:10.460]   So the first one will come in and take the empty one out and the second one will come
[00:10:10.460 --> 00:10:13.060]   in with a full one.
[00:10:13.060 --> 00:10:15.540]   And that's how the process keeps going.
[00:10:15.540 --> 00:10:21.620]   And it's either requested directly by humans or by warehouse management systems, which
[00:10:21.620 --> 00:10:25.380]   are optimizing the flow of objects in the factory already.
[00:10:25.380 --> 00:10:29.780]   And so what are some of the surprisingly hard things about doing this?
[00:10:29.780 --> 00:10:35.020]   I'm imagining when you sort of dream up this plan and then you deploy it, there's a lot
[00:10:35.020 --> 00:10:39.340]   of things that I wouldn't think of as problems that turn out to be problems.
[00:10:39.340 --> 00:10:43.060]   Can you give me some examples of those things?
[00:10:43.060 --> 00:10:44.060]   Yeah.
[00:10:44.060 --> 00:10:49.740]   Especially if you want to talk about the machine learning aspect.
[00:10:49.740 --> 00:10:56.780]   What is really challenging is, or how I can summarize it a bit, is like a quote by Richard
[00:10:56.780 --> 00:10:57.780]   Feynman.
[00:10:57.780 --> 00:11:03.100]   It's like, the first principle is not to fool yourself and you are the easiest person to
[00:11:03.100 --> 00:11:04.460]   fool.
[00:11:04.460 --> 00:11:08.340]   And basically it englobes multiple aspects.
[00:11:08.340 --> 00:11:14.340]   And the first one being, whenever you face a problem, if you're very deep into machine
[00:11:14.340 --> 00:11:19.540]   learning and just getting all the news and all the hype of it, your first reflex is just
[00:11:19.540 --> 00:11:21.220]   solve it directly.
[00:11:21.220 --> 00:11:25.980]   Just solve it with whatever tool you have now, whatever is state of the art.
[00:11:25.980 --> 00:11:31.140]   And just like the early days of the iPhone, you had like, there's an app for that.
[00:11:31.140 --> 00:11:33.140]   Whatever you want, there's an app for that.
[00:11:33.140 --> 00:11:34.860]   Now there's a model for that.
[00:11:34.860 --> 00:11:41.220]   So any issue, any challenge you face, there's certainly a model for that, especially with
[00:11:41.220 --> 00:11:42.260]   hugging face now.
[00:11:42.260 --> 00:11:45.940]   So you can literally do any specific task.
[00:11:45.940 --> 00:11:54.860]   And one, like one small example, which can show that is when you first deploy a robot
[00:11:54.860 --> 00:12:00.540]   in the factories, you soon figure out that lighting system inside the factory is super
[00:12:00.540 --> 00:12:05.980]   bright and you will face a lot of reflections.
[00:12:05.980 --> 00:12:12.900]   And especially the objects that you're trying to carry around are already metallic objects.
[00:12:12.900 --> 00:12:18.180]   So and your camera is just looking at the objects and then you realize that the floor
[00:12:18.180 --> 00:12:22.780]   is even reflective because the material on the floor should be done in a specific way
[00:12:22.780 --> 00:12:26.020]   for safety regulations and so on.
[00:12:26.020 --> 00:12:33.060]   So your first instinct is, yeah, we could use any deep learning model to try to reduce
[00:12:33.060 --> 00:12:39.420]   this reflection aspect or try to segment the floor out and so on and so forth.
[00:12:39.420 --> 00:12:47.100]   But what we ended up having is just tilt the camera seven degrees.
[00:12:47.100 --> 00:12:48.620]   That's it.
[00:12:48.620 --> 00:12:56.340]   Like just go for the simple aspect that you can control and not directly for the complex
[00:12:56.340 --> 00:12:58.340]   solution.
[00:12:58.340 --> 00:13:07.100]   And some challenges also from reflection is we received once like a bug on our system
[00:13:07.100 --> 00:13:11.900]   that's happening very rarely, but it does happen that our robot, whenever it's trying
[00:13:11.900 --> 00:13:20.420]   to go under this object to lift it up, sometimes it's drifting way too much in a very unreasonable
[00:13:20.420 --> 00:13:21.740]   way.
[00:13:21.740 --> 00:13:24.480]   And we didn't really know why it was drifting.
[00:13:24.480 --> 00:13:31.000]   There wasn't like specific time of day or any specific task or not even a specific mission
[00:13:31.000 --> 00:13:33.420]   where it's drifting.
[00:13:33.420 --> 00:13:37.420]   And then we went to the factory because we have access to the factories, which is also
[00:13:37.420 --> 00:13:41.580]   a huge advantage where we can see what's actually happening.
[00:13:41.580 --> 00:13:49.260]   And it turns out that sometimes as we're trying to detect the object that we're driving under,
[00:13:49.260 --> 00:13:56.260]   there's one person with a safety vest, like with the reflective stripes on it, passing
[00:13:56.260 --> 00:13:59.320]   just behind the object.
[00:13:59.320 --> 00:14:04.140]   And then it's causing all this reflective aspect, and then we're not detecting where
[00:14:04.140 --> 00:14:07.660]   we should go in and it's drifting a bit.
[00:14:07.660 --> 00:14:14.300]   So such edge cases show up even more and more whenever you deploy stuff.
[00:14:14.300 --> 00:14:15.300]   It's kind of interesting.
[00:14:15.300 --> 00:14:20.820]   I mean, I obviously love machine learning and would want to apply it everywhere, but
[00:14:20.820 --> 00:14:25.780]   I would think even for just driving underneath an object, wouldn't there be like a cheap
[00:14:25.780 --> 00:14:31.260]   way to know where the object is and know where the robot is?
[00:14:31.260 --> 00:14:35.940]   And just couldn't you do it with some other kind of localization technique that might
[00:14:35.940 --> 00:14:38.420]   be simpler and more reliable?
[00:14:38.420 --> 00:14:42.740]   Why do you have to even rely on vision for that?
[00:14:42.740 --> 00:14:43.740]   Yeah.
[00:14:43.740 --> 00:14:50.900]   So that's an amazing question because there are so many ways that the robots are trying
[00:14:50.900 --> 00:14:53.300]   to do the same exact task.
[00:14:53.300 --> 00:15:00.460]   And if you're trying to simplify the problem, why should I even do all this vision aspect
[00:15:00.460 --> 00:15:03.140]   or vision processing on edge?
[00:15:03.140 --> 00:15:10.460]   And it turns out that some objects like chargers, for instance, are very fixed in the ground.
[00:15:10.460 --> 00:15:15.920]   They have their own electric system and they can't be really moved around.
[00:15:15.920 --> 00:15:22.580]   So whenever you're trying to go under it, even if after a long period of time of driving,
[00:15:22.580 --> 00:15:29.340]   the robot could drift a little bit in terms of localization, whenever you reach this object,
[00:15:29.340 --> 00:15:32.300]   you can somehow understand exactly where it is.
[00:15:32.300 --> 00:15:35.540]   It's not really shifted from where it should be.
[00:15:35.540 --> 00:15:43.820]   But whenever you have dollies, those are sometimes pushed by humans and/or rotated by humans.
[00:15:43.820 --> 00:15:50.540]   And this could be up to half a meter off the actual location where it should be.
[00:15:50.540 --> 00:15:53.860]   And then when you reach the location, you should know, is it the one that I should go
[00:15:53.860 --> 00:15:57.380]   under or is it actually the one next to it?
[00:15:57.380 --> 00:16:03.780]   And such aspects could need a bit more of processing on edge to do it.
[00:16:03.780 --> 00:16:12.460]   Now, some people may argue with the fact that you could put QR codes or any aspect for localization.
[00:16:12.460 --> 00:16:18.780]   This turns out to be-- it is a cheap solution first, actually printing them out.
[00:16:18.780 --> 00:16:25.900]   But at the same time, the tearing of it with time will make you try to replace them and
[00:16:25.900 --> 00:16:28.980]   you could have thousands of them per factory.
[00:16:28.980 --> 00:16:36.420]   So looking at the problem from a more long-term perspective, it makes sense to put more effort
[00:16:36.420 --> 00:16:43.420]   now into a bit more autonomy on the robot itself in this task.
[00:16:43.420 --> 00:16:46.180]   And so do you also use simulation?
[00:16:46.180 --> 00:16:47.340]   Yes.
[00:16:47.340 --> 00:16:49.020]   We definitely do.
[00:16:49.020 --> 00:16:58.500]   So we started first, as I said, in Omniverse, but we had even simulation environments way
[00:16:58.500 --> 00:16:59.660]   before.
[00:16:59.660 --> 00:17:07.420]   And then once NVIDIA jumped into the equation, we're like, "Okay, that's really good from
[00:17:07.420 --> 00:17:11.500]   a physics perspective and from being realistic enough."
[00:17:11.500 --> 00:17:12.500]   So as I said--
[00:17:12.500 --> 00:17:13.900]   But what does simulation do for you?
[00:17:13.900 --> 00:17:19.940]   Is it like testing scenarios or testing what a new version of your robot is going to do?
[00:17:19.940 --> 00:17:22.940]   Or how does simulation fit in?
[00:17:22.940 --> 00:17:27.700]   So we have multiple aspects where simulation could be useful.
[00:17:27.700 --> 00:17:35.500]   First one is whenever you're trying to test one isolated behavior of our robot, we can
[00:17:35.500 --> 00:17:37.180]   test that directly in simulation.
[00:17:37.180 --> 00:17:43.100]   So as we said, the docking aspect where you're going under a specific object and seeing if
[00:17:43.100 --> 00:17:49.580]   shifting it left or right or rotating it could affect or could affect it negatively, this
[00:17:49.580 --> 00:17:51.980]   can be tested on its own.
[00:17:51.980 --> 00:17:58.580]   But at the same time, the fun part is testing more complex scenarios or stuff that you can't
[00:17:58.580 --> 00:18:00.460]   really test in the real world.
[00:18:00.460 --> 00:18:07.420]   So for instance, what would our robot do if a forklift just dropped in front of it suddenly?
[00:18:07.420 --> 00:18:09.680]   How would it behave?
[00:18:09.680 --> 00:18:13.960]   So we could test that in our simulation environment.
[00:18:13.960 --> 00:18:21.060]   And what we did is whenever we found this need for testing such scenarios, you can imagine
[00:18:21.060 --> 00:18:23.260]   them as like driving tests.
[00:18:23.260 --> 00:18:26.420]   So if they pass the driving test, that's fine.
[00:18:26.420 --> 00:18:28.700]   You can keep going.
[00:18:28.700 --> 00:18:34.820]   And we were inspired by the CARLA simulator for autonomous driving.
[00:18:34.820 --> 00:18:38.980]   And they had some kind of scenario definition.
[00:18:38.980 --> 00:18:43.580]   So you can define what you want to happen in a simulation environment.
[00:18:43.580 --> 00:18:49.820]   So it can be automatically run on with your robots.
[00:18:49.820 --> 00:18:54.620]   And we adapted that for factory settings and for AMRs.
[00:18:54.620 --> 00:19:01.860]   And now we have our own kind of language where we can say, send this robot from this location
[00:19:01.860 --> 00:19:03.500]   to this other location.
[00:19:03.500 --> 00:19:09.340]   And while it's driving, just make a forklift drive around randomly, delivering objects,
[00:19:09.340 --> 00:19:13.580]   and let's see what happens in the scenario.
[00:19:13.580 --> 00:19:15.540]   Interesting.
[00:19:15.540 --> 00:19:22.660]   And so when you go to work, what are you thinking about improving?
[00:19:22.660 --> 00:19:24.860]   What would a new version of a robot have?
[00:19:24.860 --> 00:19:30.480]   What are the main metrics that you're working on optimizing?
[00:19:30.480 --> 00:19:39.540]   So what we focus on a generic level, let's say, is the total efficiency of the factory
[00:19:39.540 --> 00:19:41.060]   itself.
[00:19:41.060 --> 00:19:47.580]   And sometimes this is translated into either features for the robot itself and driving
[00:19:47.580 --> 00:19:52.700]   smoothly or docking other objects faster and so on.
[00:19:52.700 --> 00:19:59.980]   Or it can be translated into a task assignment or scheduling or route finding from the fleet
[00:19:59.980 --> 00:20:02.060]   management system.
[00:20:02.060 --> 00:20:10.580]   And the main focus is how can we reach a higher throughput and be safe whenever delivering
[00:20:10.580 --> 00:20:12.500]   all objects in the factory.
[00:20:12.500 --> 00:20:16.700]   Because that's, from a logistics perspective, those are the priorities.
[00:20:16.700 --> 00:20:19.740]   You have to deliver everything on time.
[00:20:19.740 --> 00:20:24.420]   Like at BMW, there's this just on time, just in sequence.
[00:20:24.420 --> 00:20:29.900]   So everything should be exactly delivered at the time it should be delivered in and
[00:20:29.900 --> 00:20:34.980]   in the sequence it should be delivered in to have the whole workflow efficient.
[00:20:34.980 --> 00:20:41.620]   And we try, as I said, to not fool ourselves and say, whoa, that's a nice segmentation
[00:20:41.620 --> 00:20:42.620]   model.
[00:20:42.620 --> 00:20:45.780]   Let's put it on our robot and understand the world.
[00:20:45.780 --> 00:20:52.900]   But if it's not really driving any return on investment for our bigger goal, it's just
[00:20:52.900 --> 00:20:55.100]   a gimmick in this case.
[00:20:55.100 --> 00:21:01.420]   So we try to always connect it with what will improve the efficiency of the factory.
[00:21:01.420 --> 00:21:06.340]   And how do you predict how much it's going to improve the efficiency of the factory?
[00:21:06.340 --> 00:21:15.140]   Like are you able to simulate the whole factory and software before you put something live?
[00:21:15.140 --> 00:21:23.140]   So we have one of our, I would say, biggest experiences in the simulation started when
[00:21:23.140 --> 00:21:26.860]   we simulated a full BMW factory.
[00:21:26.860 --> 00:21:36.700]   And that was also showcased in one of the GTC keynotes by Jensen, even, showing exactly
[00:21:36.700 --> 00:21:44.420]   how Omniverse helped in simulating a full working factory from BMW Group.
[00:21:44.420 --> 00:21:50.580]   And what you can see are literally even humans moving around, like doing basic tasks, but
[00:21:50.580 --> 00:21:53.180]   actually being in the environment.
[00:21:53.180 --> 00:22:00.720]   And in such situations, you can deliver a specific robot and see what will happen.
[00:22:00.720 --> 00:22:08.180]   But I always like to have, or like to say that 3D simulations and high fidelity simulations
[00:22:08.180 --> 00:22:11.580]   have their advantages.
[00:22:11.580 --> 00:22:19.620]   But we always also need 2D, fast, and largely scalable simulations.
[00:22:19.620 --> 00:22:27.380]   Because one of them is helping the intelligence of the robot itself and being realistic enough
[00:22:27.380 --> 00:22:30.360]   from a vision perspective and navigation and so on.
[00:22:30.360 --> 00:22:34.020]   And the second one is helping in the coordination aspect.
[00:22:34.020 --> 00:22:40.380]   So whenever you're trying to use simulation or create a simulation environment, it should
[00:22:40.380 --> 00:22:44.620]   be scoped around the metric you're trying to improve.
[00:22:44.620 --> 00:22:47.100]   So what are you trying to test now?
[00:22:47.100 --> 00:22:51.820]   Are you trying to test the high fidelity and the behavior of your robot in high fidelity
[00:22:51.820 --> 00:22:52.820]   environments?
[00:22:52.820 --> 00:22:59.180]   Or are you testing, or regardless of that, considering a perfect behavior of the robot,
[00:22:59.180 --> 00:23:06.060]   are you testing now the coordination or the assignment of tasks and scheduling of tasks?
[00:23:06.060 --> 00:23:13.540]   And that's where, from a simulation perspective, we try to tackle it based on the need we have.
[00:23:13.540 --> 00:23:14.540]   I see.
[00:23:14.540 --> 00:23:15.900]   I see.
[00:23:15.900 --> 00:23:22.140]   And do you further make components that different people work on?
[00:23:22.140 --> 00:23:25.740]   How do you actually structure the team and the projects?
[00:23:25.740 --> 00:23:26.740]   Yeah.
[00:23:26.740 --> 00:23:34.020]   So at first, we were all trying to build the robot, so make the robot really good.
[00:23:34.020 --> 00:23:39.980]   And then we moved into, now that the robot is working well in the factory, let's work
[00:23:39.980 --> 00:23:42.180]   on the fleet management system.
[00:23:42.180 --> 00:23:48.260]   And at this stage, we are split into, I would say, for each team.
[00:23:48.260 --> 00:23:55.420]   So from the any fleet aspect of our fleet management aspect, we have the software engineering
[00:23:55.420 --> 00:24:01.940]   or back-end services, which is connecting to warehouse management systems, making all
[00:24:01.940 --> 00:24:06.580]   the integrations possible, getting all the messages from the robots.
[00:24:06.580 --> 00:24:12.060]   Because you can imagine that every robot should report what it's doing to the fleet management
[00:24:12.060 --> 00:24:13.060]   system.
[00:24:13.060 --> 00:24:15.780]   And in our case, it's at the one hertz frequency.
[00:24:15.780 --> 00:24:17.660]   So every second you get one message.
[00:24:17.660 --> 00:24:18.660]   I'm here.
[00:24:18.660 --> 00:24:19.660]   That's what I'm doing.
[00:24:19.660 --> 00:24:20.660]   I'm here.
[00:24:20.660 --> 00:24:21.660]   That's what I'm doing.
[00:24:21.660 --> 00:24:22.660]   I'm here.
[00:24:22.660 --> 00:24:23.660]   That's what I'm doing.
[00:24:23.660 --> 00:24:27.220]   And that's what the fleet management system tries to ingest.
[00:24:27.220 --> 00:24:31.920]   And part of it is also from this AI perspective.
[00:24:31.920 --> 00:24:34.120]   So how can we optimize the flow?
[00:24:34.120 --> 00:24:39.100]   Knowing what's happening now, how can we optimize the flow moving forward?
[00:24:39.100 --> 00:24:44.460]   And you could potentially even have machine learning approaches, not only operations research
[00:24:44.460 --> 00:24:52.140]   aspect, in terms of traffic prediction or predictive maintenance.
[00:24:52.140 --> 00:24:58.820]   And the sense where you can understand that one robot has a battery which is potentially
[00:24:58.820 --> 00:25:03.120]   draining more than it should in a specific sense.
[00:25:03.120 --> 00:25:06.060]   So you can directly look into that.
[00:25:06.060 --> 00:25:12.460]   And so that's how we try to split this workload on the cloud part.
[00:25:12.460 --> 00:25:17.920]   And on edge, it's also split into the robotics aspect of it.
[00:25:17.920 --> 00:25:22.380]   So robotics engineers writing the software itself.
[00:25:22.380 --> 00:25:28.920]   And there is also AI on edge, which is focusing on the vision aspect or navigation aspect
[00:25:28.920 --> 00:25:31.520]   also on the robot.
[00:25:31.520 --> 00:25:36.500]   We have the hardware team.
[00:25:36.500 --> 00:25:38.540]   Usually they say, like, it's all software.
[00:25:38.540 --> 00:25:40.180]   Hardware is already solved.
[00:25:40.180 --> 00:25:41.720]   It's all software.
[00:25:41.720 --> 00:25:46.060]   But hardware is here just to make your life harder.
[00:25:46.060 --> 00:25:49.660]   That's exactly what it does for robotics.
[00:25:49.660 --> 00:25:51.300]   And there's also the safety team.
[00:25:51.300 --> 00:25:55.700]   So we have one team specifically focusing on the safety aspect.
[00:25:55.700 --> 00:25:59.960]   Because as I said, in Germany, you have specific regulations you have to follow.
[00:25:59.960 --> 00:26:02.200]   But our customers are not only in Germany.
[00:26:02.200 --> 00:26:06.280]   So we have customers in France, in Spain, in England.
[00:26:06.280 --> 00:26:12.900]   So multiple countries have different regulations that you have to follow or certificates that
[00:26:12.900 --> 00:26:16.740]   you have to get for your robot itself.
[00:26:16.740 --> 00:26:19.620]   And that's what our safety team focuses on.
[00:26:19.620 --> 00:26:24.700]   And I would imagine there's a huge project to do like testing and simulation too, right?
[00:26:24.700 --> 00:26:26.540]   Like, how does that fit into that?
[00:26:26.540 --> 00:26:27.540]   Yeah.
[00:26:27.540 --> 00:26:29.260]   So that's where our simulation team.
[00:26:29.260 --> 00:26:34.460]   So our simulation team, from a simulation perspective, we have the people writing the
[00:26:34.460 --> 00:26:40.780]   code to enable all the scenario definition and enable multiple robots in the same environment,
[00:26:40.780 --> 00:26:46.260]   which is also a collaboration always ongoing with NVIDIA regarding this topic.
[00:26:46.260 --> 00:26:50.500]   And the second aspect is industrial designers.
[00:26:50.500 --> 00:26:56.580]   Because you could put all the robots inside the factory, but you need to really model
[00:26:56.580 --> 00:26:58.220]   the factory.
[00:26:58.220 --> 00:27:04.020]   And in a sense, you need the objects to be as reflective as they are in the real world.
[00:27:04.020 --> 00:27:06.500]   And to look as big as they are in the real world.
[00:27:06.500 --> 00:27:13.260]   So dimensions and textures of objects and how they interact with light.
[00:27:13.260 --> 00:27:18.380]   And if you hit it, what happens whenever you hit a specific object, all of that is also
[00:27:18.380 --> 00:27:25.460]   from our industrial designers who are focusing basically on getting...
[00:27:25.460 --> 00:27:30.260]   You can imagine the workflow as scanning a factory, trying to understand exactly where
[00:27:30.260 --> 00:27:34.020]   each object is, and then trying to replicate it manually.
[00:27:34.020 --> 00:27:39.160]   Trying to see, okay, here's a specific object that we can drop in.
[00:27:39.160 --> 00:27:45.780]   So the point cloud that we generate from the whole factory can be replaced with the actual
[00:27:45.780 --> 00:27:51.060]   objects which have physics enabled objects, let's say.
[00:27:51.060 --> 00:27:56.220]   And this final simulation can be used by the robots to drive around and interact with it.
[00:27:56.220 --> 00:27:57.220]   I see.
[00:27:57.220 --> 00:28:02.700]   So every factory that you go into, every new factory, you try to really simulate all the
[00:28:02.700 --> 00:28:05.180]   lighting and objects and all that?
[00:28:05.180 --> 00:28:06.860]   It's not necessary.
[00:28:06.860 --> 00:28:07.860]   So it's not necessary.
[00:28:07.860 --> 00:28:08.860]   Yeah.
[00:28:08.860 --> 00:28:14.220]   So whenever we start, we try to start in gradual steps.
[00:28:14.220 --> 00:28:18.460]   And usually some customers request it.
[00:28:18.460 --> 00:28:24.820]   So it is one of our offerings, I would say, that we can scan the whole factory because
[00:28:24.820 --> 00:28:30.560]   it doesn't only help in testing our robots.
[00:28:30.560 --> 00:28:33.940]   It also helps them in managing their own factory.
[00:28:33.940 --> 00:28:35.620]   So they can see everything.
[00:28:35.620 --> 00:28:40.340]   They can move objects around and they see, "Oh, that's better.
[00:28:40.340 --> 00:28:41.940]   That's more efficient this way.
[00:28:41.940 --> 00:28:43.140]   Let's do it."
[00:28:43.140 --> 00:28:50.660]   So it's also a win-win situation sometimes whenever we do the scan.
[00:28:50.660 --> 00:28:53.220]   But it is time intensive.
[00:28:53.220 --> 00:29:00.260]   So it's, of course, not a requirement before going inside the factory to do so.
[00:29:00.260 --> 00:29:05.780]   And when you roll out a new version of your perception algorithm, for example, do you
[00:29:05.780 --> 00:29:08.620]   push it into every robot and every factory at once?
[00:29:08.620 --> 00:29:11.620]   I would think that would be kind of a scary update.
[00:29:11.620 --> 00:29:13.580]   No, yeah.
[00:29:13.580 --> 00:29:16.900]   That's a scary move to do.
[00:29:16.900 --> 00:29:24.560]   Even changes on the fleet management system, we try to approach it as a feature flag approach.
[00:29:24.560 --> 00:29:32.380]   So from a robotics perspective, I would say the changes of features recently wasn't too
[00:29:32.380 --> 00:29:33.560]   frequent.
[00:29:33.560 --> 00:29:35.640]   So it wasn't a main concern.
[00:29:35.640 --> 00:29:39.720]   It's becoming more and more important as we're going.
[00:29:39.720 --> 00:29:42.840]   So especially this year, for instance.
[00:29:42.840 --> 00:29:47.480]   But from a fleet management perspective, the features are way more frequent.
[00:29:47.480 --> 00:29:53.880]   And the changes that you need to do to keep the system more efficient are more frequent.
[00:29:53.880 --> 00:29:58.520]   And whenever we're deploying, we try to deploy per area first.
[00:29:58.520 --> 00:30:02.680]   And even before that, we test it in simulation.
[00:30:02.680 --> 00:30:06.160]   So we test specific scenarios.
[00:30:06.160 --> 00:30:11.240]   The same ones that we said can help like the scenario definition language, which can help
[00:30:11.240 --> 00:30:14.240]   that the robot pass the driving test.
[00:30:14.240 --> 00:30:19.720]   They could also help our fleet management system to pass some efficiency tests.
[00:30:19.720 --> 00:30:24.060]   So can you really manage this load of tasks?
[00:30:24.060 --> 00:30:27.920]   Or can you manage the sequence of tasks in a specific way?
[00:30:27.920 --> 00:30:36.400]   And then we deploy it sequentially on our customer facilities with their knowledge also.
[00:30:36.400 --> 00:30:43.140]   That's also one of the, I would say, challenges is in logistics environments, you can't just
[00:30:43.140 --> 00:30:44.140]   update your code.
[00:30:44.140 --> 00:30:47.980]   And say, okay, now it's working.
[00:30:47.980 --> 00:30:58.740]   Because whenever any factory sees that your system is working, they just don't need any
[00:30:58.740 --> 00:30:59.740]   updates.
[00:30:59.740 --> 00:31:00.740]   That's it.
[00:31:00.740 --> 00:31:01.740]   It's working.
[00:31:01.740 --> 00:31:03.460]   Just don't touch it for the next 10 years.
[00:31:03.460 --> 00:31:04.460]   That's it.
[00:31:04.460 --> 00:31:06.220]   You're like, no, we can't do that.
[00:31:06.220 --> 00:31:10.840]   And then there's always a back-end force on when the update will happen.
[00:31:10.840 --> 00:31:16.980]   And we need to give them time to prepare kind of more mentally, mental preparation more
[00:31:16.980 --> 00:31:21.080]   than actual physical preparation.
[00:31:21.080 --> 00:31:28.260]   Because change is very hard to be accepted in logistics environments.
[00:31:28.260 --> 00:31:35.460]   Once it's running, and it's running well, they don't need updates.
[00:31:35.460 --> 00:31:38.880]   Because they're afraid any downtime is very critical.
[00:31:38.880 --> 00:31:39.880]   That's why.
[00:31:39.880 --> 00:31:44.500]   Everyone is afraid of any, even one minute of downtime.
[00:31:44.500 --> 00:31:47.820]   That's why they just want to keep it as it is.
[00:31:47.820 --> 00:31:54.260]   Well, I suppose, why do you then do updates if the customers don't want it?
[00:31:54.260 --> 00:32:00.780]   I mean, couldn't you, if it's working, couldn't you let the robots run forever?
[00:32:00.780 --> 00:32:02.660]   That's one way of looking at it.
[00:32:02.660 --> 00:32:03.660]   Yes.
[00:32:03.660 --> 00:32:10.640]   At the same time, we would be handling many versions of our own app.
[00:32:10.640 --> 00:32:12.200]   So you would...
[00:32:12.200 --> 00:32:16.320]   Yeah, I understand that, believe me.
[00:32:16.320 --> 00:32:24.080]   So that would be a huge mess and trying to manage all of it and trying to keep developers
[00:32:24.080 --> 00:32:29.480]   focusing on old bugs for old systems, working for just one customer who doesn't want to
[00:32:29.480 --> 00:32:32.640]   update ever in their life.
[00:32:32.640 --> 00:32:37.740]   And that's why we decided to be a more dynamic approach to it.
[00:32:37.740 --> 00:32:42.040]   And even from our side, our whole system is running on the cloud.
[00:32:42.040 --> 00:32:48.640]   So it's even easier for us to do the updates because usually in logistics environments,
[00:32:48.640 --> 00:32:53.680]   you can have more of on-premise servers.
[00:32:53.680 --> 00:33:02.600]   And then you just deploy hardware stuff and they have to see what's happening and feel
[00:33:02.600 --> 00:33:06.280]   confident that, okay, that's the fleet management system.
[00:33:06.280 --> 00:33:07.280]   That's it.
[00:33:07.280 --> 00:33:11.080]   This box sitting in the corner, that's our fleet management system.
[00:33:11.080 --> 00:33:12.360]   Don't touch it.
[00:33:12.360 --> 00:33:14.180]   It's working.
[00:33:14.180 --> 00:33:20.120]   But now we're taking a bit more modern approach to it, saying, okay, you have to accept...
[00:33:20.120 --> 00:33:22.000]   It's a transition phase.
[00:33:22.000 --> 00:33:25.200]   So it's still hard with some customers.
[00:33:25.200 --> 00:33:27.920]   Some others are really open to it.
[00:33:27.920 --> 00:33:29.840]   And they're like, yeah, of course we want to try it.
[00:33:29.840 --> 00:33:32.480]   We want to be even better users.
[00:33:32.480 --> 00:33:37.240]   So try even newer features before anyone else.
[00:33:37.240 --> 00:33:41.840]   But yeah, it's more of an educational transition phase.
[00:33:41.840 --> 00:33:47.520]   So when I've gone into car factories in my life, I actually haven't seen robots moving
[00:33:47.520 --> 00:33:52.920]   things around, but I've seen lots of robots doing different things and manipulating and
[00:33:52.920 --> 00:33:55.440]   welding and all that.
[00:33:55.440 --> 00:34:01.360]   Do you think about adding capabilities to manipulate the world you're in?
[00:34:01.360 --> 00:34:10.400]   Maybe have arms that pick stuff up or modify the objects?
[00:34:10.400 --> 00:34:17.800]   For the moment, we're focusing on moving robots, moving parts inside the factory.
[00:34:17.800 --> 00:34:21.280]   So AMRs or even AGVs, which could be moving.
[00:34:21.280 --> 00:34:23.320]   What's an AGV?
[00:34:23.320 --> 00:34:31.040]   It's let's say a simpler version of an AMR and its autonomy is a bit more restricted.
[00:34:31.040 --> 00:34:36.920]   So you can imagine it as robots driving on a specific magnetic line.
[00:34:36.920 --> 00:34:40.000]   So if they see any obstacle, they just stop.
[00:34:40.000 --> 00:34:44.760]   There's proximity sensor, they just pose and then they keep going.
[00:34:44.760 --> 00:34:50.520]   So the autonomy is a bit more restrictive on an AGV than it is on AMR.
[00:34:50.520 --> 00:34:58.120]   And we try in our AnyFleet, that's where the name came from, to be able to manage any fleet
[00:34:58.120 --> 00:35:00.080]   of robots in this case.
[00:35:00.080 --> 00:35:07.160]   Now at BMW, we have a lot of robotic arms, as you said, they are used for welding and
[00:35:07.160 --> 00:35:11.720]   you can see them in even cages for safety purposes.
[00:35:11.720 --> 00:35:13.840]   They have four robot arms.
[00:35:13.840 --> 00:35:18.240]   One of them is holding an object, second one is welding it in place and so on.
[00:35:18.240 --> 00:35:20.280]   But usually there's not intelligence there, right?
[00:35:20.280 --> 00:35:22.920]   They're just completely scripted what they do, right?
[00:35:22.920 --> 00:35:23.920]   Yeah.
[00:35:23.920 --> 00:35:24.920]   Am I wrong?
[00:35:24.920 --> 00:35:25.920]   Yeah.
[00:35:25.920 --> 00:35:31.160]   So they're completely scripted because you need it to be as fast as possible and there's
[00:35:31.160 --> 00:35:35.160]   no intervention or interaction with any human.
[00:35:35.160 --> 00:35:42.480]   So every task is just repetitive, exactly the same, enclosed even physically is limited
[00:35:42.480 --> 00:35:45.560]   in this physical space.
[00:35:45.560 --> 00:35:53.240]   And what you can see basically is, or where our robot comes into play is whenever those
[00:35:53.240 --> 00:36:00.240]   robots finish welding and finish specific object and put it aside on specific dolly,
[00:36:00.240 --> 00:36:06.280]   we are the robot which comes in, lift it up and go deliver it to specific locations.
[00:36:06.280 --> 00:36:09.600]   That's how the integration is happening for now.
[00:36:09.600 --> 00:36:15.160]   And so do people with factories come to you and say, "Hey, I want you to automate my factory.
[00:36:15.160 --> 00:36:16.160]   Is that how it works?
[00:36:16.160 --> 00:36:20.960]   Like if I was manufacturing something, could I say, 'Hey, can you make my factory more
[00:36:20.960 --> 00:36:21.960]   efficient?'"
[00:36:21.960 --> 00:36:24.680]   It goes both ways.
[00:36:24.680 --> 00:36:32.240]   So sometimes we see specific factories which can use our help and we try to approach them
[00:36:32.240 --> 00:36:41.040]   or we can see it in logistics conferences, for example, whenever you have demos of robots,
[00:36:41.040 --> 00:36:46.680]   clients going in and seeing, okay, which robot could support in my process.
[00:36:46.680 --> 00:36:51.920]   And we always try to show the customer exactly how the robot could behave in their own environment.
[00:36:51.920 --> 00:36:57.200]   And try to study this use case on its own.
[00:36:57.200 --> 00:37:03.520]   Because as much as we would like to have it as a plug and play, like here's a robot, it
[00:37:03.520 --> 00:37:06.840]   will just work, it will improve your process.
[00:37:06.840 --> 00:37:09.020]   It's usually not that easy.
[00:37:09.020 --> 00:37:17.080]   So just like whenever you're talking about machine learning, it's not like always the
[00:37:17.080 --> 00:37:22.380]   solution to any problem because whenever you have a hammer, everything looks like a nail.
[00:37:22.380 --> 00:37:27.960]   Also in the robot aspect, sometimes you don't really need this kind of autonomy or sometimes
[00:37:27.960 --> 00:37:30.340]   you don't really need that many robots.
[00:37:30.340 --> 00:37:35.080]   You need way less or you need to optimize your process because whenever you're trying
[00:37:35.080 --> 00:37:41.980]   to automate, it doesn't make sense to just throw robots at it and just make it work.
[00:37:41.980 --> 00:37:49.300]   So what kinds of factories benefit the most from these autonomous robots?
[00:37:49.300 --> 00:37:57.060]   First, the people who are open to understand that change will be necessary.
[00:37:57.060 --> 00:38:02.840]   And change not in a way that you're changing your factory, because the whole point of having
[00:38:02.840 --> 00:38:08.320]   our AMR solution is we don't touch any of your objects.
[00:38:08.320 --> 00:38:11.420]   So we don't put markers on your objects.
[00:38:11.420 --> 00:38:13.200]   We don't put any markers on the ground.
[00:38:13.200 --> 00:38:16.160]   We don't have any reflectors for localization.
[00:38:16.160 --> 00:38:19.220]   We just deploy our robot itself on your ground.
[00:38:19.220 --> 00:38:27.220]   So that's also one of the selling points, I would say, which helps customers look at
[00:38:27.220 --> 00:38:29.940]   the robot in terms of a more positive approach.
[00:38:29.940 --> 00:38:31.460]   Okay, we can try it.
[00:38:31.460 --> 00:38:38.900]   It's not a higher cost of just having it and seeing what it does for a few days.
[00:38:38.900 --> 00:38:45.300]   But yeah, the first one is people who are open to understand how to improve the process.
[00:38:45.300 --> 00:38:49.700]   Because from our side, it's not only software engineering problem.
[00:38:49.700 --> 00:38:52.340]   It's also you have subject matter experts.
[00:38:52.340 --> 00:38:58.900]   So you have logistics experts looking at the process and saying, here's where a robot would
[00:38:58.900 --> 00:39:01.220]   make sense to integrate.
[00:39:01.220 --> 00:39:07.020]   Those kinds of transports can be automated by a robot so that your forklift can be free
[00:39:07.020 --> 00:39:11.020]   to do more transports of this other type.
[00:39:11.020 --> 00:39:16.900]   So in this way, you did increase efficiency, not by removing one task and saying, okay,
[00:39:16.900 --> 00:39:19.180]   that's the robot, it's doing it.
[00:39:19.180 --> 00:39:25.860]   But by re-architecting how you're just moving or efficiently working inside the factory
[00:39:25.860 --> 00:39:26.860]   itself.
[00:39:26.860 --> 00:39:32.700]   And so have you been to lots and lots of factories to see how they work?
[00:39:32.700 --> 00:39:33.700]   Yeah.
[00:39:33.700 --> 00:39:36.900]   Is that a core part of your job?
[00:39:36.900 --> 00:39:39.060]   It is most of the time.
[00:39:39.060 --> 00:39:47.780]   So we even have our own small scale factory where we have objects which we see usually
[00:39:47.780 --> 00:39:51.980]   in the real world, and we set it in our own testing factory.
[00:39:51.980 --> 00:39:55.660]   And this one is just like a full empty warehouse.
[00:39:55.660 --> 00:39:58.540]   And then we added all the objects needed.
[00:39:58.540 --> 00:40:05.420]   And what we try to do is whenever we go to new customers, we try to replicate stuff that
[00:40:05.420 --> 00:40:11.220]   we see in reality, in our testing environment.
[00:40:11.220 --> 00:40:16.980]   Because as much as you want to improve from a simulation perspective, seeing it physically
[00:40:16.980 --> 00:40:24.500]   live working is way more important from a robotics perspective than just staying on
[00:40:24.500 --> 00:40:25.500]   the software level.
[00:40:25.500 --> 00:40:29.740]   So the two aspects are very, very important in this case.
[00:40:29.740 --> 00:40:37.540]   And the more you see the problem and you see a factory, you can like dissociate between
[00:40:37.540 --> 00:40:45.380]   or differentiate between what the customer would like or is asking for and the actual
[00:40:45.380 --> 00:40:47.620]   problem the customer has.
[00:40:47.620 --> 00:40:51.340]   And those are usually not the same most of the times.
[00:40:51.340 --> 00:40:58.220]   Because the customer is most of the time reporting a symptom, not the actual root cause problem.
[00:40:58.220 --> 00:40:59.940]   That makes sense.
[00:40:59.940 --> 00:41:04.260]   It sounds really interesting working in the real world.
[00:41:04.260 --> 00:41:09.460]   I imagine each factory has a new surprise or challenge.
[00:41:09.460 --> 00:41:10.460]   Always.
[00:41:10.460 --> 00:41:11.460]   Always, yeah.
[00:41:11.460 --> 00:41:22.420]   And one thing we noticed is you were tweeting a lot about time management and optimizing
[00:41:22.420 --> 00:41:24.620]   code for long-term productivity.
[00:41:24.620 --> 00:41:30.220]   Do you have any thoughts there, especially around machine learning code and making sure
[00:41:30.220 --> 00:41:34.780]   that it's kind of maintainable and developer productivity stays high?
[00:41:34.780 --> 00:41:42.460]   Yeah, that's, I would say, one aspect which is taking more interest recently in the ML
[00:41:42.460 --> 00:41:51.100]   community, which is the code quality itself, but also software engineering best practices.
[00:41:51.100 --> 00:41:58.340]   Because having more and more tutorials of machine learning is both a blessing and a
[00:41:58.340 --> 00:42:03.660]   curse because now you can write everything in two lines and it works.
[00:42:03.660 --> 00:42:08.180]   And the bad part is you can write everything in two lines and it actually works.
[00:42:08.180 --> 00:42:13.700]   But how well can you extend that whenever you're working in a team and how well are
[00:42:13.700 --> 00:42:20.540]   you really using some software engineering best practices whenever you're doing this
[00:42:20.540 --> 00:42:22.100]   development?
[00:42:22.100 --> 00:42:31.340]   And basically there's nothing very specific that's, like I would say, like focus on this
[00:42:31.340 --> 00:42:39.660]   or that, but as a general idea, whenever we're approaching a problem, or my personal preference
[00:42:39.660 --> 00:42:48.580]   is having faster iteration cycles, whatever the problem is, the faster you can experiment
[00:42:48.580 --> 00:42:53.020]   and see what gets out of it and then experiment again and see what gets out of it.
[00:42:53.020 --> 00:42:57.980]   So which most of the time, for example, in machine learning aspect, we use weights and
[00:42:57.980 --> 00:43:04.540]   biases sweeps, which is awesome to just look at and say, okay, we know for a fact that
[00:43:04.540 --> 00:43:11.260]   some, like for a rule of thumb, we know such parameters would make sense.
[00:43:11.260 --> 00:43:14.820]   Which combination it is, you have two choices.
[00:43:14.820 --> 00:43:20.420]   Either you have to compute and just try it out, or you can go into the theoretical aspect
[00:43:20.420 --> 00:43:24.760]   and try to really figure out which combination would make more sense.
[00:43:24.760 --> 00:43:27.520]   If you have sweeps, you can have faster iterations.
[00:43:27.520 --> 00:43:30.340]   So you can literally just see it in front of you.
[00:43:30.340 --> 00:43:34.740]   Okay, that's exactly what's happening here and act accordingly.
[00:43:34.740 --> 00:43:36.820]   And it's the same from a software perspective.
[00:43:36.820 --> 00:43:41.980]   So whenever you're writing code, how fast can you see your changes on the robot?
[00:43:41.980 --> 00:43:45.580]   Or how fast can you see your changes on the fleet management system?
[00:43:45.580 --> 00:43:52.780]   The shorter this period of time, the harder the problems you can solve.
[00:43:52.780 --> 00:44:05.460]   And the second aspect is avoid the bias of looking at what you would like to see.
[00:44:05.460 --> 00:44:12.500]   So this is a huge problem, because whenever you do anything, or like deploy any machine
[00:44:12.500 --> 00:44:19.940]   learning model, or solve any problem in any kind of way, any small hint that will let
[00:44:19.940 --> 00:44:25.860]   you feel that you were right, you will just take it and then feed on it.
[00:44:25.860 --> 00:44:27.180]   And then that's it.
[00:44:27.180 --> 00:44:34.460]   You go into the sloop of using the wrong way of solving the problem, or just not solving
[00:44:34.460 --> 00:44:37.860]   it or not looking at the correct metrics.
[00:44:37.860 --> 00:44:47.300]   So the faster iteration cycles and not fooling yourself are two, I would say, aspects in
[00:44:47.300 --> 00:44:51.740]   general to look at from a development perspective.
[00:44:51.740 --> 00:44:57.380]   One thing that people always ask me about that I would imagine would be particularly
[00:44:57.380 --> 00:45:09.260]   acute for you is ML ops, like keeping the models organized and deployed reliably.
[00:45:09.260 --> 00:45:14.020]   Can you share any best practices that you have since you're really deploying models
[00:45:14.020 --> 00:45:16.660]   into a really high stakes environment?
[00:45:16.660 --> 00:45:17.660]   What have you learned?
[00:45:17.660 --> 00:45:19.380]   How frequently do you do updates?
[00:45:19.380 --> 00:45:22.260]   How do you keep track of the updates that you put in?
[00:45:22.260 --> 00:45:32.440]   How do you make sure that your tests really matter for the use cases before they're deployed?
[00:45:32.440 --> 00:45:39.260]   So given that now we're still early on the stage, I wouldn't say that we're experts or
[00:45:39.260 --> 00:45:43.820]   we're doing it in any best practice way.
[00:45:43.820 --> 00:45:52.820]   But at least from the challenges that we may face whenever we're doing so is...
[00:45:52.820 --> 00:46:02.180]   So from a data perspective, one aspect which is positive for having factories is you usually
[00:46:02.180 --> 00:46:05.700]   see the same stuff.
[00:46:05.700 --> 00:46:09.940]   So some objects are a standard.
[00:46:09.940 --> 00:46:15.380]   So specific boxes are the standard boxes for putting this type of objects.
[00:46:15.380 --> 00:46:21.160]   So you would see the same box everywhere in any factory in Germany.
[00:46:21.160 --> 00:46:27.480]   Anyone using this size of boxes would be exactly the same, for example, or same color.
[00:46:27.480 --> 00:46:35.180]   And from this data perspective, whenever you're training a model and you want to keep track
[00:46:35.180 --> 00:46:42.100]   of which model was trained on which data, given that at the same time we're generating
[00:46:42.100 --> 00:46:50.660]   synthetic data from our simulation environment, and then keeping track of all of that is one
[00:46:50.660 --> 00:46:55.920]   of the challenges or one challenge that you may face in this case.
[00:46:55.920 --> 00:47:08.720]   And the second one is whenever you're deploying anything to a robot or to any system in particular,
[00:47:08.720 --> 00:47:14.240]   keeping track of a metric which will let you know if it's better than whatever you had
[00:47:14.240 --> 00:47:15.760]   before.
[00:47:15.760 --> 00:47:24.080]   Because still in your evaluation process, you can't face all the potential edge cases,
[00:47:24.080 --> 00:47:29.120]   whatever your evaluation data set or evaluation scenarios and simulation is.
[00:47:29.120 --> 00:47:37.560]   And whenever you're deploying any code changes to your system, deciding what is better in
[00:47:37.560 --> 00:47:41.960]   a specific situation is always a challenging problem.
[00:47:41.960 --> 00:47:50.340]   So because some of those metrics can only be seen after a specific period of time.
[00:47:50.340 --> 00:47:56.900]   And then you see degrading behavior versus the older version.
[00:47:56.900 --> 00:48:01.500]   And that's where, for example, in our fleet management system, whenever we're trying to
[00:48:01.500 --> 00:48:08.780]   deploy anything, I can talk more about this operations research aspect more than the machine
[00:48:08.780 --> 00:48:14.460]   learning training, we try to deploy services in shadow mode.
[00:48:14.460 --> 00:48:21.540]   So what the shadow mode will do, it will literally take the same input as a normal service.
[00:48:21.540 --> 00:48:25.700]   It will take the decisions, but it will not execute it.
[00:48:25.700 --> 00:48:28.640]   To just stop after taking the decision.
[00:48:28.640 --> 00:48:36.000]   And in this way, we can actually see the difference in the decisions being made.
[00:48:36.000 --> 00:48:40.760]   And whenever there's a difference, we try to understand this difference over time.
[00:48:40.760 --> 00:48:46.640]   This way we get kind of a testing in production, but it's not really testing in production
[00:48:46.640 --> 00:48:50.040]   because the customer is not affected at all.
[00:48:50.040 --> 00:48:55.300]   And at the same time, we get the insights of the production aspect and the metrics that
[00:48:55.300 --> 00:48:58.640]   we need from this deployment.
[00:48:58.640 --> 00:49:07.960]   What do you believe are the most challenges faced in such MLOps approaches from your experience?
[00:49:07.960 --> 00:49:13.880]   Well, I think what it comes from, I don't know if you'd agree with this, but I think
[00:49:13.880 --> 00:49:20.720]   machine learning is more stochastic than code.
[00:49:20.720 --> 00:49:25.800]   And it has some key differences.
[00:49:25.800 --> 00:49:29.640]   I think we don't actually understand the internal mechanisms of the models very well.
[00:49:29.640 --> 00:49:34.260]   And it kind of gets worse as the models get bigger and bigger and more and more complicated.
[00:49:34.260 --> 00:49:39.040]   And so I think people have trouble just having best practices around things that we're used
[00:49:39.040 --> 00:49:40.040]   to with software.
[00:49:40.040 --> 00:49:46.600]   What's the equivalent of CI/CD for machine learning is an interesting question, right?
[00:49:46.600 --> 00:49:51.440]   Because the models are typically not going to behave exactly the same way every time.
[00:49:51.440 --> 00:49:56.720]   Whereas with software, if any test fails, of course you just wouldn't deploy.
[00:49:56.720 --> 00:50:03.480]   Or I think monitoring things the right way in production is an unsolved problem.
[00:50:03.480 --> 00:50:08.440]   We still see lots and lots of people have these failure modes where in retrospect, you're
[00:50:08.440 --> 00:50:10.280]   like, "Oh, that was so dumb.
[00:50:10.280 --> 00:50:13.800]   It should have been so clear that that was going to break."
[00:50:13.800 --> 00:50:20.600]   But I think that we kind of know how to monitor software, but I think ML has a lot of cases
[00:50:20.600 --> 00:50:23.760]   where it quietly fails and that can be really tough.
[00:50:23.760 --> 00:50:30.780]   So we just see a lot of concern from our customers around, "Hey, how do you get this whole thing
[00:50:30.780 --> 00:50:31.780]   working at the end?"
[00:50:31.780 --> 00:50:37.040]   And I think it's kind of because the methods are newer than software development and we
[00:50:37.040 --> 00:50:40.840]   haven't really discovered the right ways to do it.
[00:50:40.840 --> 00:50:47.080]   And of course, as a tool maker, I think that a lot of the tools are not really good enough
[00:50:47.080 --> 00:50:52.680]   yet and that's why we want to make better ones to help folks like you deploy things
[00:50:52.680 --> 00:50:57.480]   reliably and get the outputs that you'd expect.
[00:50:57.480 --> 00:50:58.480]   And I think there's another phenomenon.
[00:50:58.480 --> 00:51:02.600]   I'm kind of curious about your background, but I think a lot of people come out of grad
[00:51:02.600 --> 00:51:06.720]   school where they're working on things that are kind of more contained.
[00:51:06.720 --> 00:51:12.060]   I don't want to say like toy problems, but kind of toy-like problems.
[00:51:12.060 --> 00:51:17.520]   And then suddenly they're doing something where people really expect it to be reliable
[00:51:17.520 --> 00:51:20.320]   and working in the real world and they're just not trained for it.
[00:51:20.320 --> 00:51:21.320]   I remember that myself.
[00:51:21.320 --> 00:51:26.760]   If you're writing for a paper, you're really trying to rush the paper out and there's not
[00:51:26.760 --> 00:51:29.680]   a lot of incentive to write high quality, reusable code.
[00:51:29.680 --> 00:51:31.520]   So you actually don't really learn it.
[00:51:31.520 --> 00:51:33.560]   And a lot of professors don't actually know how to do that.
[00:51:33.560 --> 00:51:37.760]   So you're not around mentors that are teaching you to do it.
[00:51:37.760 --> 00:51:42.360]   And then suddenly you're really expected to...
[00:51:42.360 --> 00:51:47.040]   The maintenance cycle is a lot longer than the development cycle for everything.
[00:51:47.040 --> 00:51:49.800]   I think that leads to a lot of problems.
[00:51:49.800 --> 00:51:52.760]   I don't know if that resonates with you.
[00:51:52.760 --> 00:51:56.240]   Yeah, actually.
[00:51:56.240 --> 00:52:03.040]   So when I was doing my master's, I started out being interested in cybersecurity first.
[00:52:03.040 --> 00:52:05.600]   So that was my main focus.
[00:52:05.600 --> 00:52:11.840]   And then I got some opportunities in focusing on ML application and they were basically
[00:52:11.840 --> 00:52:15.160]   in nature language processing.
[00:52:15.160 --> 00:52:22.040]   And it was in the early days of NLP where having a good word2vec model was like the
[00:52:22.040 --> 00:52:25.360]   state of the art at this stage.
[00:52:25.360 --> 00:52:32.800]   And the first time where I saw deployments to production or where I personally deployed
[00:52:32.800 --> 00:52:36.920]   to production was in the first startup I joined.
[00:52:36.920 --> 00:52:41.640]   So we were trying to analyze the news articles.
[00:52:41.640 --> 00:52:47.800]   And the whole point was to build a tool for journalists and for anyone who's interested
[00:52:47.800 --> 00:52:54.440]   in searching and understanding what's actually happening, including some kind of map where
[00:52:54.440 --> 00:52:59.320]   you can have the news article pop up and say, okay, that's happening here and that's happening
[00:52:59.320 --> 00:53:02.560]   there and so on in real time.
[00:53:02.560 --> 00:53:07.440]   And deploying to production was scary at this stage.
[00:53:07.440 --> 00:53:18.160]   So whenever you deploy anything, for instance, our last feature was about incident detection.
[00:53:18.160 --> 00:53:27.640]   And the point was we needed to be able to detect incidents like stabbing, protests,
[00:53:27.640 --> 00:53:34.960]   any killing or like natural disasters and so on before mainstream media.
[00:53:34.960 --> 00:53:41.480]   So just gathering it from all sources, from tweets, from news sources, from local news
[00:53:41.480 --> 00:53:45.360]   sources, local magazines from all around the world.
[00:53:45.360 --> 00:53:55.000]   And at the time, trying to understand, so in 2016 or 2017, it was still starting out
[00:53:55.000 --> 00:54:01.560]   where spacey was like English and a bit of German, like early versions.
[00:54:01.560 --> 00:54:07.920]   And understanding very small text like tweets was very challenging.
[00:54:07.920 --> 00:54:10.300]   Even classifying them was very challenging.
[00:54:10.300 --> 00:54:19.860]   So whenever we deployed to production, I remember one funny bug at the time, which was, so we're
[00:54:19.860 --> 00:54:24.060]   trying to detect stuff that are bad, like incidents and so on.
[00:54:24.060 --> 00:54:33.600]   And then one user reported that they are seeing one article or one tweet saying that donkeys
[00:54:33.600 --> 00:54:37.760]   kill more people than airplane crashes per year.
[00:54:37.760 --> 00:54:43.060]   And it was just like fact of the day tweet, but it was classified as an incident because
[00:54:43.060 --> 00:54:46.820]   there's killing and people and like all of it.
[00:54:46.820 --> 00:54:52.540]   So this aspect of deploying to production started at this stage.
[00:54:52.540 --> 00:54:58.140]   And then you start to see that whatever you're reading from research paper perspective, they
[00:54:58.140 --> 00:55:04.660]   are trying to push the theoretical aspect or theoretical understanding of the field
[00:55:04.660 --> 00:55:06.140]   further.
[00:55:06.140 --> 00:55:10.300]   But they are not telling you to just take it and go deploy it in production or deploy
[00:55:10.300 --> 00:55:13.820]   it in like anywhere.
[00:55:13.820 --> 00:55:21.700]   So whenever you're looking at research papers, you need to understand what they are trying
[00:55:21.700 --> 00:55:28.120]   to give you and not just take whatever is given and just go deploy it somewhere.
[00:55:28.120 --> 00:55:33.580]   So get the lessons learned from this paper and try to implement them in your application
[00:55:33.580 --> 00:55:35.660]   if it makes sense.
[00:55:35.660 --> 00:55:42.580]   And also take a look at the benchmark they are working on because most of the time, yes,
[00:55:42.580 --> 00:55:49.360]   it's state of the art based on what compared to who explicitly, what's the actual data
[00:55:49.360 --> 00:55:50.600]   set.
[00:55:50.600 --> 00:55:55.980]   And that's where you can understand if it makes sense to integrate in your work or not.
[00:55:55.980 --> 00:56:04.200]   So as you said, those toy problems, you always face specific aspects where you have toy problems,
[00:56:04.200 --> 00:56:10.340]   but I still believe they are very important in a research setting because from a research
[00:56:10.340 --> 00:56:15.780]   perspective, as I said, you're trying to improve your understanding of a problem or understanding
[00:56:15.780 --> 00:56:17.240]   of how it works.
[00:56:17.240 --> 00:56:21.640]   So you need to drill down the constraints and let's say have a grid work.
[00:56:21.640 --> 00:56:22.640]   So it's not a free space.
[00:56:22.640 --> 00:56:24.480]   You can just up, down, left, right.
[00:56:24.480 --> 00:56:30.900]   It's small game, but it gets the essence of the theoretical aspect.
[00:56:30.900 --> 00:56:37.140]   The problem happens when people consider state of the art on the game equals state of the
[00:56:37.140 --> 00:56:39.500]   art in production.
[00:56:39.500 --> 00:56:42.020]   And this is where it's messed up.
[00:56:42.020 --> 00:56:43.020]   Yeah.
[00:56:43.020 --> 00:56:45.140]   I wonder if you have any thoughts.
[00:56:45.140 --> 00:56:49.980]   As you were talking about factory robots, I was thinking about visiting my friend over
[00:56:49.980 --> 00:56:56.260]   Christmas and she had one of those Amazon robots that kind of drives around her house.
[00:56:56.260 --> 00:57:02.180]   And she was pretty impressed with it, but I was kind of looking at it and it was like
[00:57:02.180 --> 00:57:07.420]   a pretty, I mean, compared to what I thought we might have when I was young, it really
[00:57:07.420 --> 00:57:08.820]   can't do that much.
[00:57:08.820 --> 00:57:10.420]   I hope no one from Amazon is offended.
[00:57:10.420 --> 00:57:15.940]   It's kind of an amazing thing to ship something, but still it's not like, it's like washing
[00:57:15.940 --> 00:57:18.500]   my dishes or anything like that.
[00:57:18.500 --> 00:57:24.080]   I'm kind of curious if you think some of this technology could be repurposed for consumer
[00:57:24.080 --> 00:57:29.860]   applications or how far away we are from useful consumer robots.
[00:57:29.860 --> 00:57:31.340]   Yeah.
[00:57:31.340 --> 00:57:37.820]   I like to think about this problem from a video.
[00:57:37.820 --> 00:57:42.620]   It was, I believe a talk by Professor Amanda Prorok.
[00:57:42.620 --> 00:57:48.700]   She works on multi-agent robotics, basically.
[00:57:48.700 --> 00:57:54.800]   And she showed hundreds of small robots, tiny robots going around and making the work of
[00:57:54.800 --> 00:57:57.720]   the lab written on the ground.
[00:57:57.720 --> 00:58:01.320]   And then she said, look how amazing it is.
[00:58:01.320 --> 00:58:07.700]   And what the catch was, it was a video where it was already written on the ground and then
[00:58:07.700 --> 00:58:14.960]   they drove randomly and they played the video backwards.
[00:58:14.960 --> 00:58:20.360]   And the main idea was that from a hardware perspective, it's kind of solved, like the
[00:58:20.360 --> 00:58:26.400]   behavior itself, like moving whenever you know what you should be doing, moving towards
[00:58:26.400 --> 00:58:30.080]   your goal is solved in some sense.
[00:58:30.080 --> 00:58:35.920]   And the same aspect I believe happened also with like humanoid robots, where you have
[00:58:35.920 --> 00:58:42.040]   robotic arms doing the dishes and doing all kinds of stuff inside the house.
[00:58:42.040 --> 00:58:47.280]   And then it turns out to be a human controlled robot.
[00:58:47.280 --> 00:58:51.320]   And I like this example because it shows where the gap is.
[00:58:51.320 --> 00:58:58.380]   And the gap is in the software aspect from this planning perspective.
[00:58:58.380 --> 00:59:02.300]   So whenever planning and control, of course.
[00:59:02.300 --> 00:59:07.480]   And we see, for instance, control and Boston Dynamics videos.
[00:59:07.480 --> 00:59:12.640]   So two days ago, it was just running around throwing a bag for someone and then doing
[00:59:12.640 --> 00:59:18.960]   a front flip just to showcase how good they are from a control perspective.
[00:59:18.960 --> 00:59:26.000]   But I believe from a consumer point of view, it depends how complex you want your object
[00:59:26.000 --> 00:59:27.620]   to be, your robot to be.
[00:59:27.620 --> 00:59:34.080]   So do you really want a robot with two arms walking around in the house doing stuff?
[00:59:34.080 --> 00:59:37.040]   Because it could be simpler.
[00:59:37.040 --> 00:59:38.520]   Some stuff could be simpler.
[00:59:38.520 --> 00:59:42.920]   Now how far are we from having such a robot?
[00:59:42.920 --> 00:59:53.000]   I would say maybe if asked me a year ago, I would give some kind of estimates.
[00:59:53.000 --> 01:00:02.320]   But after seeing the last two months' development in deep learning, especially in like NLP models,
[01:00:02.320 --> 01:00:07.680]   that was beyond what was understood that could happen.
[01:00:07.680 --> 01:00:14.640]   So some aspects happened so fast that people are not even keeping up with the pace now.
[01:00:14.640 --> 01:00:20.880]   And you have startups like Stability AI doing outstanding work in the field of even computer
[01:00:20.880 --> 01:00:23.640]   vision and diffusion models and so on.
[01:00:23.640 --> 01:00:28.560]   And every version is even more outstanding than the previous one.
[01:00:28.560 --> 01:00:37.160]   Now how much of this is actually related or transferable to production robotics aspect
[01:00:37.160 --> 01:00:39.400]   is still unknown.
[01:00:39.400 --> 01:00:47.160]   But I believe during 2023, we will see a lot of changes which are dramatic in terms of
[01:00:47.160 --> 01:00:50.920]   planning and behavior of such small robots.
[01:00:50.920 --> 01:00:55.200]   Well, look, as you know, we always end with two questions and I want to make sure we get
[01:00:55.200 --> 01:00:59.800]   them in, the second to last one being, what's a topic in machine learning that you think
[01:00:59.800 --> 01:01:03.560]   is under appreciated or under researched?
[01:01:03.560 --> 01:01:07.000]   Troubleshooting, I would say.
[01:01:07.000 --> 01:01:14.280]   I would say it's troubleshooting because as you said, there are differences with the software
[01:01:14.280 --> 01:01:20.640]   approach and CI/CD pipelines and all the tests and unit and integration tests and so on work
[01:01:20.640 --> 01:01:23.400]   well in the software scope.
[01:01:23.400 --> 01:01:30.640]   You go to the machine learning scope and it's very different on how you can test a model.
[01:01:30.640 --> 01:01:37.440]   Troubleshooting is even worse in this case because there's no real feedback.
[01:01:37.440 --> 01:01:40.840]   There's no, I'm not working here.
[01:01:40.840 --> 01:01:42.440]   It just fails.
[01:01:42.440 --> 01:01:48.480]   And it feels like whenever you're deploying any model, what you're trying to do is not
[01:01:48.480 --> 01:01:55.920]   make it outstanding, but what you're actually trying is whenever it fails, I hope it's above
[01:01:55.920 --> 01:01:56.920]   average.
[01:01:56.920 --> 01:02:03.320]   Like whenever it fails doing what it should do, I hope it's still good enough.
[01:02:03.320 --> 01:02:09.120]   And this aspect of understanding when it's good enough and whenever it's bad, understanding
[01:02:09.120 --> 01:02:18.240]   why it's bad, I believe it's still not really researched enough.
[01:02:18.240 --> 01:02:19.240]   I like that answer.
[01:02:19.240 --> 01:02:22.080]   No one's given that before, but I like it a lot.
[01:02:22.080 --> 01:02:31.560]   And then our final question is for you, what's been the hardest part about going from a research-like
[01:02:31.560 --> 01:02:36.860]   model that worked to a production model that's actually useful in factories?
[01:02:36.860 --> 01:02:44.400]   The understanding that baselines are more important than having a state of the art model
[01:02:44.400 --> 01:02:51.240]   whenever you start, and this works even in a software perspective, but from a machine
[01:02:51.240 --> 01:03:00.400]   learning perspective, understanding what good means and what good enough means are very
[01:03:00.400 --> 01:03:05.400]   important whenever you're deploying or whenever you're switching from research to production
[01:03:05.400 --> 01:03:07.000]   environment.
[01:03:07.000 --> 01:03:13.840]   And connecting that with your business and the eventual return on investment for your
[01:03:13.840 --> 01:03:15.480]   business.
[01:03:15.480 --> 01:03:23.280]   This whole flow, it feels harder than the technical aspect of it, because from technical
[01:03:23.280 --> 01:03:26.000]   perspective, you can Google it.
[01:03:26.000 --> 01:03:29.920]   You can have communities, you can have people helping you.
[01:03:29.920 --> 01:03:36.540]   Some stuff are changing and are becoming way better now that you have way bigger communities
[01:03:36.540 --> 01:03:39.880]   helping each other in specific technical aspect.
[01:03:39.880 --> 01:03:47.120]   But understanding when and what to implement so that your company actually improves and
[01:03:47.120 --> 01:03:51.760]   actually gets this return in this whole flow.
[01:03:51.760 --> 01:03:56.740]   I believe that's one of the hardest aspects to get right, because it's very use case specific
[01:03:56.740 --> 01:03:58.000]   and company specific.
[01:03:58.000 --> 01:03:59.000]   Awesome.
[01:03:59.000 --> 01:04:00.000]   Well, thank you very much.
[01:04:00.000 --> 01:04:01.000]   That was a lot of fun.
[01:04:01.000 --> 01:04:02.000]   I really appreciate it.
[01:04:02.000 --> 01:04:03.000]   Thanks a lot.
[01:04:03.000 --> 01:04:08.240]   If you're enjoying these interviews and you want to learn more, please click on the link
[01:04:08.240 --> 01:04:12.960]   to the show notes in the description where you can find links to all the papers that
[01:04:12.960 --> 01:04:17.120]   are mentioned, supplemental material, and a transcription that we worked really hard
[01:04:17.120 --> 01:04:18.120]   to produce.
[01:04:18.120 --> 01:04:18.620]   So check it out.
[01:04:18.620 --> 01:04:21.200]   (upbeat music)
[01:04:21.200 --> 01:04:23.260]   you

