
[00:00:00.000 --> 00:00:02.580]   (upbeat music)
[00:00:02.580 --> 00:00:08.640]   - You're listening to Let's Talk Jobs,
[00:00:08.640 --> 00:00:11.600]   where we give you practical insights into jobs and careers.
[00:00:11.600 --> 00:00:15.000]   I'm Tim Chen, and today we're joined by Jesse Ratner.
[00:00:15.000 --> 00:00:17.400]   He's a marketing consultant for copywriting,
[00:00:17.400 --> 00:00:19.240]   content strategy, and so much more.
[00:00:19.240 --> 00:00:20.920]   Jesse, how are you doing?
[00:00:20.920 --> 00:00:23.360]   - I'm great, Tim, thanks for having me.
[00:00:23.360 --> 00:00:26.200]   - Now today's podcast episode's gonna be very interesting
[00:00:26.200 --> 00:00:27.040]   'cause we're gonna be talking
[00:00:27.040 --> 00:00:29.040]   about artificial intelligence,
[00:00:29.040 --> 00:00:32.160]   and then we're gonna go into authenticity and humanity,
[00:00:32.160 --> 00:00:34.800]   and then we're gonna somehow end on personal growth
[00:00:34.800 --> 00:00:36.920]   and just freedom from our addictions.
[00:00:36.920 --> 00:00:39.240]   So hang tight, 'cause this is gonna be a fun ride.
[00:00:39.240 --> 00:00:40.320]   Jesse, before we get started,
[00:00:40.320 --> 00:00:41.320]   can you just tell me a little bit
[00:00:41.320 --> 00:00:43.560]   about what you're doing today?
[00:00:43.560 --> 00:00:44.880]   - Yeah, I'd love to.
[00:00:44.880 --> 00:00:49.640]   So today, as of April 5th, 2024,
[00:00:49.640 --> 00:00:52.400]   I'm doing a couple of things.
[00:00:52.400 --> 00:00:57.000]   My main engagement is with a laser manufacturer
[00:00:58.000 --> 00:01:01.160]   called Coherent, where I'm the lead content strategist,
[00:01:01.160 --> 00:01:06.160]   and I'm doing team management and digital strategy
[00:01:06.160 --> 00:01:08.280]   and a whole bunch of other things,
[00:01:08.280 --> 00:01:10.840]   and I've been doing that for about four years.
[00:01:10.840 --> 00:01:14.880]   In addition, I'm a copywriter for Kalibra,
[00:01:14.880 --> 00:01:16.480]   which is a data intelligence company
[00:01:16.480 --> 00:01:19.520]   that's been pivoting into the AI space more recently,
[00:01:19.520 --> 00:01:23.680]   and I write blogs and eBooks and things like that for them.
[00:01:23.680 --> 00:01:28.080]   I'm doing some work for MongoDB, writing SEO pages,
[00:01:28.080 --> 00:01:33.080]   mainly about AI topics like what is prompt engineering,
[00:01:33.080 --> 00:01:37.360]   what are embedded vectors,
[00:01:37.360 --> 00:01:40.920]   and then I'm also doing a little bit of work
[00:01:40.920 --> 00:01:42.920]   for another agency, Outliant,
[00:01:42.920 --> 00:01:45.320]   where I'm helping them with some brand repositioning
[00:01:45.320 --> 00:01:47.080]   and hopefully some other things.
[00:01:47.080 --> 00:01:49.560]   So I'm busy.
[00:01:49.560 --> 00:01:51.940]   I like the variety, I've always liked that.
[00:01:52.940 --> 00:01:56.620]   I like to work different parts of my brain,
[00:01:56.620 --> 00:02:01.180]   so my main role at Coherent, I'm a strategist,
[00:02:01.180 --> 00:02:03.060]   I'm managing the writers,
[00:02:03.060 --> 00:02:06.460]   I'm working with the stakeholders.
[00:02:06.460 --> 00:02:08.420]   Coherent has a very broad portfolio.
[00:02:08.420 --> 00:02:12.540]   They offer products for the life sciences space
[00:02:12.540 --> 00:02:14.300]   and the networking space,
[00:02:14.300 --> 00:02:18.820]   which means they're selling transceivers to hyperscalers
[00:02:18.820 --> 00:02:21.620]   and they're selling lasers, for example,
[00:02:21.620 --> 00:02:24.660]   to the EV markets, so EV manufacturers
[00:02:24.660 --> 00:02:27.900]   that are doing very advanced production lines
[00:02:27.900 --> 00:02:31.020]   and need very fast, high power lasers
[00:02:31.020 --> 00:02:34.340]   to help do the welding and all sorts of stuff.
[00:02:34.340 --> 00:02:36.220]   So that's a fascinating job.
[00:02:36.220 --> 00:02:39.580]   And my role is mostly strategic and planning,
[00:02:39.580 --> 00:02:43.040]   and the other roles are more,
[00:02:43.040 --> 00:02:49.900]   I'm executing on briefs, I'm writing blogs and eBooks
[00:02:49.900 --> 00:02:52.500]   and webpages and things like that.
[00:02:52.500 --> 00:02:54.580]   And other things come up now and again.
[00:02:54.580 --> 00:02:56.140]   I keep myself pretty busy
[00:02:56.140 --> 00:02:58.480]   and it's been that way for quite a while.
[00:02:58.480 --> 00:03:03.480]   I've been a consultant for nearly seven years now.
[00:03:03.480 --> 00:03:05.940]   - No, it's been fascinating
[00:03:05.940 --> 00:03:08.900]   just watching your career trajectory,
[00:03:08.900 --> 00:03:11.500]   'cause when you and I met back at Logitech,
[00:03:11.500 --> 00:03:13.460]   you were writing copy for .com
[00:03:13.460 --> 00:03:15.300]   and I was managing the website of stuff,
[00:03:15.300 --> 00:03:18.140]   and I've always known you to be a very creative,
[00:03:18.140 --> 00:03:20.540]   hilarious, and just a fun guy to be around.
[00:03:20.540 --> 00:03:22.940]   And just kind of seeing you broaden your skillset
[00:03:22.940 --> 00:03:24.780]   and applying to different things,
[00:03:24.780 --> 00:03:26.780]   it's just really, really cool.
[00:03:26.780 --> 00:03:29.500]   And recently, you and I have been going back and forth
[00:03:29.500 --> 00:03:31.740]   online just talking about AI, right?
[00:03:31.740 --> 00:03:36.580]   And how does that affect our various lines of work
[00:03:36.580 --> 00:03:39.780]   or just addressing the fear of possibly
[00:03:39.780 --> 00:03:41.460]   AI displacing jobs and whatnot.
[00:03:41.460 --> 00:03:43.940]   So I'm just kind of curious, just jump right into that.
[00:03:43.940 --> 00:03:45.260]   What's top of mind for you
[00:03:45.260 --> 00:03:47.660]   and how do you see it impacting your field?
[00:03:48.540 --> 00:03:53.540]   - In a big way, I think it's already changing
[00:03:53.540 --> 00:04:00.660]   how creatives, copywriters, designers, SEO folks,
[00:04:00.660 --> 00:04:04.020]   strategists, creative directors,
[00:04:04.020 --> 00:04:06.620]   it's changing how I think fundamentally,
[00:04:06.620 --> 00:04:10.700]   not only how we go about our work,
[00:04:10.700 --> 00:04:15.020]   because I would say the majority of creators are using it.
[00:04:15.020 --> 00:04:16.220]   And if you're not using it,
[00:04:16.220 --> 00:04:17.780]   there's probably some resistance
[00:04:17.780 --> 00:04:21.420]   that's rooted in a real sort of animosity
[00:04:21.420 --> 00:04:22.260]   toward the technology.
[00:04:22.260 --> 00:04:26.820]   But I feel like I use it.
[00:04:26.820 --> 00:04:27.860]   I use the heck out of it.
[00:04:27.860 --> 00:04:31.420]   I have a subscription to ChatGPT Pro,
[00:04:31.420 --> 00:04:36.420]   to Gemini Pro, and to Cloud3 Opus.
[00:04:36.420 --> 00:04:40.780]   Because I wanna try them out and see which one's the best.
[00:04:42.780 --> 00:04:46.860]   Frankly, I find Cloud3 quite good
[00:04:46.860 --> 00:04:49.900]   and a lot better in a lot of ways than ChatGPT,
[00:04:49.900 --> 00:04:52.380]   even though that one gets most of the attention.
[00:04:52.380 --> 00:04:58.540]   So for now, in the moment today, April, 2024,
[00:04:58.540 --> 00:05:01.700]   it's affecting, I think everybody,
[00:05:01.700 --> 00:05:03.580]   to the extent that everyone's trying to use it
[00:05:03.580 --> 00:05:05.460]   and figure out how to use it well.
[00:05:05.460 --> 00:05:09.580]   If you wanna write a blog about embedded vectors,
[00:05:09.580 --> 00:05:14.300]   which I did recently, I'll use ChatGPT
[00:05:14.300 --> 00:05:17.740]   because it'll not only source the information for me,
[00:05:17.740 --> 00:05:20.260]   I'm not an expert in, I'm not a computer scientist,
[00:05:20.260 --> 00:05:24.340]   I'm not a data scientist, I'm not an AI engineer,
[00:05:24.340 --> 00:05:27.340]   but I know how to use the prompts to get me a draft.
[00:05:27.340 --> 00:05:29.620]   Now, there are lots of ticks,
[00:05:29.620 --> 00:05:33.180]   like there's certain linguistic patterns that,
[00:05:33.180 --> 00:05:36.060]   for example, ChatGPT often repeats,
[00:05:36.060 --> 00:05:38.420]   people will be familiar with this if they use it,
[00:05:38.420 --> 00:05:39.940]   the phrase in the realm of,
[00:05:39.940 --> 00:05:42.540]   like everything seems to start with that.
[00:05:42.540 --> 00:05:46.420]   And if you don't, if I were to be the kind of writer
[00:05:46.420 --> 00:05:48.860]   that just got a draft out of ChatGPT,
[00:05:48.860 --> 00:05:51.020]   said, "Oh, that's good enough, it makes sense,
[00:05:51.020 --> 00:05:52.740]   "the sentences are complete,
[00:05:52.740 --> 00:05:55.300]   "there's a subject and a verb and it's all,
[00:05:55.300 --> 00:05:58.540]   "it sounds right," and handed that over to my client,
[00:05:58.540 --> 00:06:01.340]   I would be surprised if they didn't throw it back at me
[00:06:01.340 --> 00:06:02.940]   and say, "What are you doing?"
[00:06:02.940 --> 00:06:06.820]   So any copywriter, I think, with his song
[00:06:06.820 --> 00:06:09.660]   is gonna know, okay, I really need to heavily edit it.
[00:06:09.660 --> 00:06:13.220]   Not only do I edit it, I need to work with the tool,
[00:06:13.220 --> 00:06:18.220]   the chatbot, to prompt it to iterate and improve.
[00:06:18.220 --> 00:06:21.580]   And so there's lots of things I think,
[00:06:21.580 --> 00:06:24.020]   whether it's executing on a blog
[00:06:24.020 --> 00:06:25.900]   or creating content strategy
[00:06:25.900 --> 00:06:28.540]   or thinking about brand strategy
[00:06:28.540 --> 00:06:31.060]   or coming up with a creative brief.
[00:06:31.060 --> 00:06:34.300]   I worked for a stint for Snapchat.
[00:06:34.300 --> 00:06:35.540]   And when I was at Snapchat,
[00:06:35.540 --> 00:06:38.980]   I was asked to develop some digital ad campaigns.
[00:06:38.980 --> 00:06:41.780]   And in order to get a quick look at some ideas,
[00:06:41.780 --> 00:06:44.260]   I worked with ChatGPT, I used Chat,
[00:06:44.260 --> 00:06:47.300]   I mean, I worked with ChatGPT,
[00:06:47.300 --> 00:06:50.380]   I used it as an assistant to help generate some ideas,
[00:06:50.380 --> 00:06:52.700]   but not only was it helpful in generating some ideas,
[00:06:52.700 --> 00:06:54.820]   some of which were really bad, like used to race,
[00:06:54.820 --> 00:06:56.860]   some of which were okay, needed refinement,
[00:06:56.860 --> 00:07:01.860]   but it gave me like a structure for a creative brief
[00:07:01.860 --> 00:07:04.860]   that was instantaneous.
[00:07:04.860 --> 00:07:09.740]   So although maybe only 50% of it was useful
[00:07:09.740 --> 00:07:11.300]   from beginning to end,
[00:07:11.300 --> 00:07:14.820]   and I had to do a lot of work to get it into a good spot,
[00:07:14.820 --> 00:07:18.340]   it's a productivity accelerator.
[00:07:18.340 --> 00:07:20.020]   I think none of us can deny that.
[00:07:20.020 --> 00:07:21.380]   And that's just for today.
[00:07:21.380 --> 00:07:22.980]   I think, so for today,
[00:07:22.980 --> 00:07:25.180]   I think we're trying to make sense of it.
[00:07:25.180 --> 00:07:27.660]   There's a lot of folks that are scared about it.
[00:07:27.660 --> 00:07:31.380]   Recently, Jon Stewart did this hilarious piece
[00:07:31.380 --> 00:07:36.380]   where he has snapshots of like Sam Altman saying,
[00:07:36.380 --> 00:07:41.860]   "I hate to be the awful tech bro,
[00:07:41.860 --> 00:07:45.100]   "but this stuff is gonna solve cancer.
[00:07:45.100 --> 00:07:46.780]   "It's like a no brainer."
[00:07:46.780 --> 00:07:50.580]   And then, this isn't exactly what he said verbatim.
[00:07:50.580 --> 00:07:53.820]   And then Sundar from Google says,
[00:07:53.820 --> 00:07:58.500]   "AI is more profound than fire or electricity."
[00:07:58.500 --> 00:08:01.300]   And then Jon Stewart like stops the tape
[00:08:01.300 --> 00:08:06.300]   and he says, I don't know if I can curse on this podcast.
[00:08:06.300 --> 00:08:07.780]   I guess I can, right?
[00:08:07.780 --> 00:08:12.780]   And he says, "Suck my beep, fire."
[00:08:12.780 --> 00:08:18.780]   Like, yeah, suck.
[00:08:18.780 --> 00:08:20.900]   So he's like, and I think Jon Stewart
[00:08:20.900 --> 00:08:23.900]   was just highlighting how optimistic
[00:08:23.900 --> 00:08:30.100]   I think some people are about it.
[00:08:30.100 --> 00:08:33.300]   It's gonna save cancer, cure cancer
[00:08:33.300 --> 00:08:37.980]   and solve climate change and overpopulation.
[00:08:37.980 --> 00:08:41.380]   And so I think you have very respected leaders
[00:08:41.380 --> 00:08:42.860]   in the tech industry saying,
[00:08:42.860 --> 00:08:44.380]   it's more profound than fire,
[00:08:44.380 --> 00:08:46.420]   which on the face of it sounds totally ridiculous.
[00:08:46.420 --> 00:08:48.620]   So when Jon Stewart satirizes that,
[00:08:48.620 --> 00:08:52.060]   I think we all just laugh 'cause, oh yeah, no way.
[00:08:52.060 --> 00:08:56.380]   But I don't know if he's wrong.
[00:08:56.380 --> 00:08:58.740]   I mean, honestly, and the reason is,
[00:08:58.740 --> 00:09:01.340]   so I'm talking about the things I'm using it for now,
[00:09:01.340 --> 00:09:03.980]   it's chat GPT-4.
[00:09:03.980 --> 00:09:08.380]   Well, what about, think back into like 2010
[00:09:08.380 --> 00:09:10.700]   when the iPhone three or four was out
[00:09:10.700 --> 00:09:14.220]   and it was kind of smallish and boxy.
[00:09:14.220 --> 00:09:16.980]   There was a lot of things that it didn't do
[00:09:16.980 --> 00:09:18.780]   that it can do today.
[00:09:18.780 --> 00:09:20.900]   The quality has improved tremendously.
[00:09:20.900 --> 00:09:23.420]   What are we on iOS 18?
[00:09:26.380 --> 00:09:29.140]   And so imagine chat GPT-18 or 10.
[00:09:29.140 --> 00:09:34.140]   So I think it's ability to accelerate productivity,
[00:09:34.140 --> 00:09:39.220]   to help creatives get to places
[00:09:39.220 --> 00:09:43.420]   that they need to go faster is transformative,
[00:09:43.420 --> 00:09:46.420]   but we're all scared.
[00:09:46.420 --> 00:09:51.260]   I'm scared that, okay, chat GPT-6 or 7 or 8
[00:09:51.260 --> 00:09:56.020]   maybe does my work better than I do and faster.
[00:09:56.020 --> 00:09:57.620]   - Yeah, I know it's interesting.
[00:09:57.620 --> 00:10:01.380]   In the hands of the right person
[00:10:01.380 --> 00:10:03.060]   who knows how to utilize it,
[00:10:03.060 --> 00:10:05.220]   that individual will probably be the one
[00:10:05.220 --> 00:10:07.540]   that displaces an individual who does not use it, right?
[00:10:07.540 --> 00:10:08.900]   'Cause I think you're right.
[00:10:08.900 --> 00:10:13.020]   Like the ability for it to help refine your ideas
[00:10:13.020 --> 00:10:17.340]   or help you expand your brainstorming is just unparalleled.
[00:10:17.340 --> 00:10:19.380]   Right, like the way in my own applications
[00:10:19.380 --> 00:10:21.580]   when I'm writing content or headlines
[00:10:21.580 --> 00:10:26.580]   or even for website, as long as I am topically aligned
[00:10:26.580 --> 00:10:33.140]   to where I wanna go and feed it as much conditions
[00:10:33.140 --> 00:10:36.180]   or input as possible, it really helps refine ideas
[00:10:36.180 --> 00:10:38.260]   or exposes other things I haven't thought about.
[00:10:38.260 --> 00:10:40.780]   To your point, yeah, for me, it's even lower than that.
[00:10:40.780 --> 00:10:43.300]   Like only 30% of the stuff I'd probably even be comfortable
[00:10:43.300 --> 00:10:46.940]   using out of the box, but it's the constant iterations
[00:10:46.940 --> 00:10:48.980]   and refinement of ideas.
[00:10:48.980 --> 00:10:51.380]   That's where I think it's really cool right now.
[00:10:51.380 --> 00:10:54.500]   And I'm kind of curious about your take on this,
[00:10:54.500 --> 00:10:58.580]   which is, you know, my company included,
[00:10:58.580 --> 00:11:01.780]   and I know many companies have a lot of hesitancy
[00:11:01.780 --> 00:11:05.860]   or straight out ban chat GPT from internal use
[00:11:05.860 --> 00:11:09.540]   because they don't wanna put private information
[00:11:09.540 --> 00:11:11.260]   to be made publicly available, right?
[00:11:11.260 --> 00:11:13.620]   And so have you found, like,
[00:11:13.620 --> 00:11:15.780]   has that been a requirement imposed upon you
[00:11:15.780 --> 00:11:18.020]   where they want to limit your use of the tools
[00:11:18.020 --> 00:11:20.380]   for maybe certain topics or whatnot?
[00:11:20.380 --> 00:11:22.180]   Like, do you have to use discretion?
[00:11:22.180 --> 00:11:26.780]   - Companies have different policies around this.
[00:11:26.780 --> 00:11:29.460]   So right now, Coherent has issued licenses
[00:11:29.460 --> 00:11:33.540]   for all employees to use chat GPT 4 Pro.
[00:11:33.540 --> 00:11:37.180]   So they're encouraging us to use it as much as possible.
[00:11:37.180 --> 00:11:38.580]   Same thing with Mongo.
[00:11:38.580 --> 00:11:43.060]   Mongo, I worked on a sort of a playbook for them
[00:11:43.060 --> 00:11:47.020]   to help introduce AI and prompt engineering to their staff.
[00:11:47.020 --> 00:11:49.180]   They want folks to use it as much as possible.
[00:11:49.180 --> 00:11:50.700]   I mean, it's kind of core to their business.
[00:11:50.700 --> 00:11:54.980]   They're developing versions of their databases
[00:11:54.980 --> 00:11:56.980]   that are optimized for AI
[00:11:56.980 --> 00:11:59.340]   and for folks that wanna build AI applications.
[00:11:59.340 --> 00:12:03.140]   For Collibra, it's not as clear,
[00:12:03.140 --> 00:12:06.500]   and I don't generally use it for anything related to it.
[00:12:06.500 --> 00:12:10.300]   I certainly don't put anything that's, you know,
[00:12:10.300 --> 00:12:12.220]   not public or IP.
[00:12:12.220 --> 00:12:14.740]   I don't have really access to that stuff anyway.
[00:12:14.740 --> 00:12:19.740]   So, but I think it's a grab bag there.
[00:12:19.740 --> 00:12:22.420]   But just to go back to what you were saying
[00:12:22.420 --> 00:12:26.020]   about its usefulness and how much of it we can use.
[00:12:26.020 --> 00:12:30.380]   The challenge here is, and I do see Cloud3
[00:12:30.380 --> 00:12:32.340]   as quite a bit better than chat GPT
[00:12:32.340 --> 00:12:34.220]   in terms of reasoning skills,
[00:12:34.220 --> 00:12:37.980]   not just communication capability,
[00:12:37.980 --> 00:12:42.980]   but more of a natural conversational communication ability.
[00:12:44.060 --> 00:12:46.980]   Speed, it has a much larger, what they call context window,
[00:12:46.980 --> 00:12:50.620]   which means it can like hold more information at one time
[00:12:50.620 --> 00:12:52.300]   in one thread in its compute.
[00:12:52.300 --> 00:12:55.580]   So it's just, I think a lot better at this point
[00:12:55.580 --> 00:12:56.620]   for whatever reason.
[00:12:56.620 --> 00:13:02.900]   But I think the difference is, here's the thing.
[00:13:02.900 --> 00:13:07.420]   I think a lot of professionals, a lot of marketers,
[00:13:07.420 --> 00:13:10.260]   especially those that have budget responsibilities
[00:13:10.260 --> 00:13:12.580]   are gonna say to themselves,
[00:13:12.580 --> 00:13:15.500]   well, you know, chat GPT or cloud or Gemini or whatever
[00:13:15.500 --> 00:13:18.500]   is getting, or copilot, is getting useful headlines.
[00:13:18.500 --> 00:13:25.500]   Like they're not, I don't think,
[00:13:25.500 --> 00:13:29.540]   I don't think chat GPT or any of their cousins
[00:13:29.540 --> 00:13:34.180]   can at this point really write a super headline.
[00:13:34.180 --> 00:13:35.700]   Like recently I was blogging about,
[00:13:35.700 --> 00:13:39.740]   I posted on LinkedIn about my first,
[00:13:39.740 --> 00:13:41.460]   my very first, like actually my second,
[00:13:41.460 --> 00:13:43.500]   my first client as a copywriter,
[00:13:43.500 --> 00:13:46.220]   I was working on this movie, "Private Parts"
[00:13:46.220 --> 00:13:48.700]   by, that was a Howard Stern biopic.
[00:13:48.700 --> 00:13:50.060]   And I described like my process
[00:13:50.060 --> 00:13:51.820]   of getting to the line that made it.
[00:13:51.820 --> 00:13:54.460]   And if you know, many people probably recognize this poster.
[00:13:54.460 --> 00:13:56.700]   It's this giant Howard Stern.
[00:13:56.700 --> 00:14:00.100]   He's naked and he's standing in the New York City skyline.
[00:14:00.100 --> 00:14:01.660]   He's taller than the Empire State Building,
[00:14:01.660 --> 00:14:03.780]   which is sort of coming up between him,
[00:14:03.780 --> 00:14:05.340]   his legs and in front of his chest.
[00:14:05.340 --> 00:14:08.580]   And he's got this incredible Photoshop body.
[00:14:08.580 --> 00:14:09.980]   And so the movie is "Private Parts"
[00:14:09.980 --> 00:14:11.300]   and the title and the tagline is,
[00:14:11.300 --> 00:14:14.300]   never before has a man done so much with so little.
[00:14:14.300 --> 00:14:17.580]   I don't think chat GPT could come up with that line
[00:14:17.580 --> 00:14:20.660]   or a lot of other lines that other copywriters have written.
[00:14:20.660 --> 00:14:24.060]   But it could come up with a line that's serviceable for sure.
[00:14:24.060 --> 00:14:25.860]   And I think the challenge is gonna be,
[00:14:25.860 --> 00:14:28.940]   if you have P&L responsibilities or you're a founder,
[00:14:28.940 --> 00:14:34.140]   sometimes it's good enough, you know?
[00:14:34.140 --> 00:14:34.980]   - Yeah.
[00:14:34.980 --> 00:14:38.540]   - And sometimes I think, especially founders,
[00:14:38.540 --> 00:14:40.820]   what I've found working with startups,
[00:14:40.820 --> 00:14:42.300]   if it's a technical founder,
[00:14:42.300 --> 00:14:44.100]   they often don't know the difference
[00:14:44.100 --> 00:14:46.140]   with any kind of nuance.
[00:14:46.140 --> 00:14:48.380]   So I think creatives are in a position
[00:14:48.380 --> 00:14:53.380]   where we have to do a lot more to prove our value,
[00:14:53.380 --> 00:14:57.780]   to be nuanced about our choices with language,
[00:14:57.780 --> 00:15:02.780]   to, you know, resurrect cliches, but in an interesting way,
[00:15:04.660 --> 00:15:07.220]   to take a line and kind of fit it
[00:15:07.220 --> 00:15:10.420]   so it works a little bit harder.
[00:15:10.420 --> 00:15:13.540]   And I think that's something that AI can't do right now.
[00:15:13.540 --> 00:15:17.500]   It can't, AI is not, at least at this point,
[00:15:17.500 --> 00:15:20.980]   you're never gonna have an E.E. Cummings AI
[00:15:20.980 --> 00:15:24.980]   or a Toni Morrison AI or a T.S. Eliot AI
[00:15:24.980 --> 00:15:26.340]   or a Jordan Peele AI.
[00:15:26.340 --> 00:15:27.700]   I don't see that happening
[00:15:27.700 --> 00:15:32.460]   because AI can't make that intuitive leap
[00:15:32.460 --> 00:15:35.180]   that goes back to who we are as humans.
[00:15:35.180 --> 00:15:38.660]   We exist on this.
[00:15:38.660 --> 00:15:41.540]   I mean, a lot of times we're unconscious of it,
[00:15:41.540 --> 00:15:45.460]   but deep down, what is, who are we?
[00:15:45.460 --> 00:15:46.980]   What is in our souls?
[00:15:46.980 --> 00:15:51.980]   And what is that deep well of memory and relationships
[00:15:51.980 --> 00:15:58.900]   and childhood experiences and ancestors and all that stuff?
[00:16:00.500 --> 00:16:01.860]   AI just has data.
[00:16:01.860 --> 00:16:06.340]   - Yeah, you know, that reminds me of something,
[00:16:06.340 --> 00:16:09.580]   the inability for it to replicate human emotion
[00:16:09.580 --> 00:16:14.580]   or empathy or compassion, or even like cliches, right?
[00:16:14.580 --> 00:16:17.700]   There's a project I'm working on specifically right now
[00:16:17.700 --> 00:16:19.740]   where I'm sensing the limitation.
[00:16:19.740 --> 00:16:21.740]   And this could actually be a area
[00:16:21.740 --> 00:16:23.340]   for technology breakthrough, quite frankly,
[00:16:23.340 --> 00:16:25.860]   where I'm working on this project
[00:16:25.860 --> 00:16:28.580]   on globalization and localization, right?
[00:16:28.580 --> 00:16:32.540]   Your traditional workflow is you have a tool,
[00:16:32.540 --> 00:16:34.860]   you put a copy, you translate it,
[00:16:34.860 --> 00:16:38.500]   humans review it, and you upload it to a website, right?
[00:16:38.500 --> 00:16:41.220]   I'm trying to figure out how do I use machine learning,
[00:16:41.220 --> 00:16:43.380]   machine training, and AI/ML
[00:16:43.380 --> 00:16:47.380]   to hopefully reduce budget over time
[00:16:47.380 --> 00:16:49.260]   by using like machine language, right?
[00:16:49.260 --> 00:16:53.100]   And the limitation I'm discovering is,
[00:16:53.100 --> 00:16:54.180]   and this is why I asked you earlier
[00:16:54.180 --> 00:16:57.260]   about like closed versus open systems for AI.
[00:16:57.260 --> 00:16:59.860]   Like the way you talk about a brand,
[00:16:59.860 --> 00:17:03.940]   your tone, the way you talk about a product,
[00:17:03.940 --> 00:17:06.180]   specific phrases you use that are unique
[00:17:06.180 --> 00:17:09.100]   to you as a company, like those are not,
[00:17:09.100 --> 00:17:10.900]   those are purely internal, right?
[00:17:10.900 --> 00:17:13.940]   And so if I'm gonna train an engine
[00:17:13.940 --> 00:17:15.980]   to translate something in a way
[00:17:15.980 --> 00:17:18.140]   that I would speak as a human,
[00:17:18.140 --> 00:17:21.060]   it can't pull that data set from outside the company
[00:17:21.060 --> 00:17:23.500]   'cause you don't want to pull in,
[00:17:23.500 --> 00:17:25.060]   you wanna be informed by whatever
[00:17:25.060 --> 00:17:25.980]   your competitors are saying, right?
[00:17:25.980 --> 00:17:27.020]   So it's very much internal.
[00:17:27.020 --> 00:17:29.500]   And that the limiting fact I'm realizing
[00:17:29.500 --> 00:17:34.100]   is that requires then a human piece of it
[00:17:34.100 --> 00:17:37.340]   where you have to train the engine.
[00:17:37.340 --> 00:17:38.500]   And the way you train the engine
[00:17:38.500 --> 00:17:41.660]   is it outputs a translation.
[00:17:41.660 --> 00:17:43.900]   As a human, you need to post edit it.
[00:17:43.900 --> 00:17:46.100]   And then you need to take that and retrain the engine.
[00:17:46.100 --> 00:17:49.540]   You have to do it at scale and my high quantity
[00:17:49.540 --> 00:17:51.900]   in order for the algorithm to be trained.
[00:17:51.900 --> 00:17:53.540]   And I'm realizing that this takes a lot
[00:17:53.540 --> 00:17:55.820]   of human resource and capital,
[00:17:55.820 --> 00:17:57.540]   and it takes a lot of money, right?
[00:17:57.540 --> 00:17:59.700]   And I think the area where I think
[00:17:59.700 --> 00:18:01.300]   technology breakthrough is gonna happen,
[00:18:01.300 --> 00:18:04.580]   I do know of one company which will not be named,
[00:18:04.580 --> 00:18:05.980]   but they're working on this,
[00:18:05.980 --> 00:18:08.660]   is they're using internally trained
[00:18:08.660 --> 00:18:11.500]   and built gen AI internally,
[00:18:11.500 --> 00:18:15.260]   and using that to train the translation engine.
[00:18:15.260 --> 00:18:17.460]   So the area where the humans doing the post editing,
[00:18:17.460 --> 00:18:19.740]   now the gen AI is talking to AI together
[00:18:19.740 --> 00:18:20.900]   to kind of figure it out.
[00:18:20.900 --> 00:18:23.140]   And then of course, there's still a human
[00:18:23.140 --> 00:18:24.460]   like a conductor piece of that,
[00:18:24.460 --> 00:18:26.340]   but that's what's fascinating to me.
[00:18:26.340 --> 00:18:30.380]   Like how do you take what's internal
[00:18:30.380 --> 00:18:31.740]   and then build that scale,
[00:18:31.740 --> 00:18:33.140]   especially sort of for smaller companies
[00:18:33.140 --> 00:18:35.860]   who may not have the budget to do something like that, right?
[00:18:35.860 --> 00:18:37.340]   It definitely takes an investment.
[00:18:37.340 --> 00:18:39.260]   But the thing I'm definitely realizing
[00:18:39.260 --> 00:18:41.100]   as I'm going through all this is,
[00:18:41.100 --> 00:18:45.100]   you're right, like it cannot replicate human tone
[00:18:45.100 --> 00:18:48.540]   and just the nuances of speech.
[00:18:48.540 --> 00:18:50.860]   And that's where I still have a little bit of hope,
[00:18:50.860 --> 00:18:55.100]   you know, like humanity will still thrive
[00:18:55.100 --> 00:18:56.340]   'cause it has to, right?
[00:18:56.340 --> 00:18:58.220]   And there's a piece of that just can't be replicated.
[00:18:58.220 --> 00:19:00.380]   I'm just kind of curious, like what are your thoughts?
[00:19:00.380 --> 00:19:01.860]   Is something you've experienced as well?
[00:19:01.860 --> 00:19:04.180]   You know, like earlier you're talking about humanity
[00:19:04.180 --> 00:19:06.300]   and emotion drawing from your history,
[00:19:06.300 --> 00:19:08.380]   and obviously it's a crowded space right now
[00:19:08.380 --> 00:19:09.820]   in social media.
[00:19:09.820 --> 00:19:12.620]   I'm just kind of curious your thoughts on all that.
[00:19:12.620 --> 00:19:17.620]   - Are you saying if companies have sufficient technology,
[00:19:20.500 --> 00:19:22.580]   sufficient AI capabilities
[00:19:22.580 --> 00:19:27.060]   that they can build their own internal AI applications
[00:19:27.060 --> 00:19:32.060]   to leverage their brand voice requirements, et cetera,
[00:19:32.060 --> 00:19:37.540]   then they should be able to replicate what a human can do?
[00:19:37.540 --> 00:19:38.380]   Or is that?
[00:19:38.380 --> 00:19:40.380]   - No, it's more maybe even beyond that,
[00:19:40.380 --> 00:19:43.260]   which is maybe it's a different way
[00:19:43.260 --> 00:19:46.180]   of looking at this conversation and possibly a tangent,
[00:19:46.180 --> 00:19:48.740]   which is like, we're so focused right now with AI
[00:19:48.740 --> 00:19:51.900]   and how it's impacting social media and all the algorithms
[00:19:51.900 --> 00:19:56.900]   where I feel like the topic of transparency and authenticity
[00:19:56.900 --> 00:19:58.740]   it's starting to become blurred, right?
[00:19:58.740 --> 00:20:01.020]   Where you have all this information,
[00:20:01.020 --> 00:20:02.700]   you don't know where it's being sourced from,
[00:20:02.700 --> 00:20:04.020]   you don't know how genuine it is.
[00:20:04.020 --> 00:20:07.580]   And I feel like it's so much more important now
[00:20:07.580 --> 00:20:12.580]   to somehow cut through the clutter and be more genuine,
[00:20:12.580 --> 00:20:13.860]   right?
[00:20:13.860 --> 00:20:14.980]   'Cause that's how I feel like the voices
[00:20:14.980 --> 00:20:17.020]   started becoming differentiated and heard.
[00:20:17.020 --> 00:20:19.220]   Is that something that you, can you relate to that?
[00:20:19.220 --> 00:20:21.020]   Or am I alone in that point of view?
[00:20:21.020 --> 00:20:26.020]   - I think it's always been a problem.
[00:20:26.020 --> 00:20:29.540]   In my experience, I have quite a number of years
[00:20:29.540 --> 00:20:31.060]   of experience working in tech.
[00:20:31.060 --> 00:20:35.420]   The challenge for tech companies is because they're technical
[00:20:35.420 --> 00:20:36.420]   when they go to market,
[00:20:36.420 --> 00:20:38.300]   their brand voice ought to be more human
[00:20:38.300 --> 00:20:41.860]   just to counteract the over technical language,
[00:20:41.860 --> 00:20:44.700]   especially if they're trying to reach decision makers
[00:20:44.700 --> 00:20:46.020]   and may not be engineers.
[00:20:46.020 --> 00:20:48.940]   So that's always been a challenge.
[00:20:48.940 --> 00:20:51.900]   And if you read, excuse me,
[00:20:51.900 --> 00:20:55.660]   if you look at one tech company's website
[00:20:55.660 --> 00:20:57.020]   and another and another and another,
[00:20:57.020 --> 00:20:58.380]   they all kind of sound the same.
[00:20:58.380 --> 00:20:59.460]   They're trying to be clear.
[00:20:59.460 --> 00:21:00.500]   They're trying to be concise.
[00:21:00.500 --> 00:21:02.740]   They're trying to be conversational.
[00:21:02.740 --> 00:21:05.900]   It's very rare that you find a brand voice
[00:21:05.900 --> 00:21:06.900]   that's very distinct.
[00:21:06.900 --> 00:21:08.980]   Like Apple is quite distinct.
[00:21:08.980 --> 00:21:13.980]   They're unabashedly boastful about their technology.
[00:21:14.100 --> 00:21:17.140]   So, and the difference between them and say Google
[00:21:17.140 --> 00:21:18.940]   is Google is gonna, okay.
[00:21:18.940 --> 00:21:21.820]   Let's say Google and Apple are both releasing new phones.
[00:21:21.820 --> 00:21:24.580]   Apple will say something more clever than this,
[00:21:24.580 --> 00:21:28.460]   but it would say the world's best phone just got better.
[00:21:28.460 --> 00:21:34.940]   But Google will say now 17.5 gillion gigabytes
[00:21:34.940 --> 00:21:37.860]   on our photos.
[00:21:37.860 --> 00:21:40.060]   Well, it used to,
[00:21:40.060 --> 00:21:44.900]   it would be more about the speeds and feeds
[00:21:44.900 --> 00:21:48.700]   and less about sort of the approach Apple often takes,
[00:21:48.700 --> 00:21:51.180]   which is more sort of boastful.
[00:21:51.180 --> 00:21:52.700]   So, but that's rare.
[00:21:52.700 --> 00:21:53.540]   And I think,
[00:21:53.540 --> 00:21:55.380]   and they have lots of marketers to help them
[00:21:55.380 --> 00:21:57.740]   get to that point, lots of creatives too.
[00:21:57.740 --> 00:22:01.140]   So, and it just, I think goes to show you
[00:22:01.140 --> 00:22:03.740]   that those brands that have those resources,
[00:22:03.740 --> 00:22:06.540]   and we know those two companies have lots of resources.
[00:22:07.900 --> 00:22:09.500]   That's what it takes, I think,
[00:22:09.500 --> 00:22:12.780]   to get to a really distinctive brand.
[00:22:12.780 --> 00:22:14.860]   And if you're not being distinctive on brand voice,
[00:22:14.860 --> 00:22:17.020]   you're really just distinguishing yourself on message.
[00:22:17.020 --> 00:22:22.020]   So, company is better at,
[00:22:22.020 --> 00:22:27.020]   I don't know, database speed.
[00:22:27.020 --> 00:22:32.300]   And another company is better at database flexibility.
[00:22:32.300 --> 00:22:36.220]   And another company is better at database scale
[00:22:36.220 --> 00:22:39.820]   or capabilities in some kind of way.
[00:22:39.820 --> 00:22:43.460]   So, it's not so much that the brand voice is distinctive.
[00:22:43.460 --> 00:22:45.900]   I think, especially when you see above the line marketing,
[00:22:45.900 --> 00:22:47.620]   when you look at commercials,
[00:22:47.620 --> 00:22:49.540]   that's where it often comes into play
[00:22:49.540 --> 00:22:52.460]   that I don't see right now AI being able
[00:22:52.460 --> 00:22:54.860]   to do the thing you're describing,
[00:22:54.860 --> 00:22:56.220]   because in order to really,
[00:22:56.220 --> 00:22:59.980]   let's think about some of the most memorable commercials
[00:22:59.980 --> 00:23:02.700]   over the years, like Apple's Think Different,
[00:23:03.620 --> 00:23:06.860]   or Wendy's Where's the Beef,
[00:23:06.860 --> 00:23:11.940]   or Budweiser's What's Was That, right?
[00:23:11.940 --> 00:23:14.420]   That one, or the Old Spice.
[00:23:14.420 --> 00:23:23.700]   I'm the man your man wishes he was, that kind of thing.
[00:23:23.700 --> 00:23:28.340]   Those ideas came out of, I think,
[00:23:28.340 --> 00:23:33.340]   not just an existing brand voice book,
[00:23:33.700 --> 00:23:35.460]   that the creators looked at and said,
[00:23:35.460 --> 00:23:36.660]   "Oh, okay, this is the idea,
[00:23:36.660 --> 00:23:38.580]   and here's how we're gonna say it."
[00:23:38.580 --> 00:23:41.300]   They came out of sparks of creativity.
[00:23:41.300 --> 00:23:43.500]   They came out of understanding the culture.
[00:23:43.500 --> 00:23:49.620]   They came out of leaps and intuition.
[00:23:49.620 --> 00:23:51.940]   And while that doesn't need to get worked
[00:23:51.940 --> 00:23:53.140]   into every line of copy,
[00:23:53.140 --> 00:23:55.660]   it doesn't always need to be in a lot of the copy,
[00:23:55.660 --> 00:23:59.020]   I think for brands that really
[00:23:59.020 --> 00:24:00.540]   wanna distinguish themselves,
[00:24:01.900 --> 00:24:03.860]   they're still gonna need to invest in creatives,
[00:24:03.860 --> 00:24:08.860]   humans that are creatives to help chart that path.
[00:24:08.860 --> 00:24:13.500]   And I think that's a real challenge
[00:24:13.500 --> 00:24:14.740]   when you look at it above the line,
[00:24:14.740 --> 00:24:17.140]   I think it's gonna be really hard to replace.
[00:24:17.140 --> 00:24:22.140]   But then again, OpenAI just released, is it Sona,
[00:24:22.140 --> 00:24:23.900]   which is the text-to-video,
[00:24:23.900 --> 00:24:26.580]   Sora, the text-to-video technology,
[00:24:26.580 --> 00:24:30.500]   and they had recently released some videos
[00:24:30.500 --> 00:24:34.580]   that they gave the technologies to some creative agencies,
[00:24:34.580 --> 00:24:36.700]   and they asked them to come up with something.
[00:24:36.700 --> 00:24:38.700]   And they just published this last month,
[00:24:38.700 --> 00:24:42.500]   and they are creative ideas.
[00:24:42.500 --> 00:24:44.940]   There's one called Airhead,
[00:24:44.940 --> 00:24:47.500]   which is basically the experience of this person
[00:24:47.500 --> 00:24:50.740]   with a yellow balloon as a head.
[00:24:50.740 --> 00:24:53.140]   And it's funny, and it's evocative,
[00:24:53.140 --> 00:24:55.500]   and they use this technology.
[00:24:55.500 --> 00:24:59.180]   Now, it was heavily directed by the people in the agency,
[00:24:59.180 --> 00:25:02.540]   but it was a beautiful piece of video.
[00:25:02.540 --> 00:25:07.060]   It didn't have some of the things we're seeing right now
[00:25:07.060 --> 00:25:11.780]   in fake videos where hands are weird and things like that.
[00:25:11.780 --> 00:25:15.500]   So, I mean, the truth is below the line stuff,
[00:25:15.500 --> 00:25:20.500]   like fact sheets for widgets and even web pages,
[00:25:20.500 --> 00:25:25.660]   like imagine product pages for, excuse me,
[00:25:25.660 --> 00:25:27.820]   like product page, imagine if you're at Logitech
[00:25:27.820 --> 00:25:31.380]   and you need a product page for a new mouse at $9,
[00:25:31.380 --> 00:25:33.100]   and there's like 42 other mice
[00:25:33.100 --> 00:25:34.540]   that they're selling for $9.
[00:25:34.540 --> 00:25:39.100]   Well, what better way to differentiate maybe
[00:25:39.100 --> 00:25:40.220]   and get those out quickly,
[00:25:40.220 --> 00:25:42.300]   but then to use T to produce it
[00:25:42.300 --> 00:25:45.020]   and just have a writer check it?
[00:25:45.020 --> 00:25:47.020]   - Yeah, you said something earlier
[00:25:47.020 --> 00:25:49.460]   that kind of reminded me of something,
[00:25:49.460 --> 00:25:53.500]   and maybe we can shift away from AI for a moment,
[00:25:53.500 --> 00:25:56.820]   which is you mentioned around speeds and feeds.
[00:25:56.820 --> 00:25:59.260]   And I'll use LinkedIn as an example in this case,
[00:25:59.260 --> 00:26:02.820]   where I remember at the very beginning,
[00:26:02.820 --> 00:26:04.460]   like everyone's used to Facebook, right?
[00:26:04.460 --> 00:26:05.620]   And then when LinkedIn came out,
[00:26:05.620 --> 00:26:07.620]   they weren't sure like, what do I post on here?
[00:26:07.620 --> 00:26:08.820]   Do I go personal?
[00:26:08.820 --> 00:26:09.900]   Do I go professional?
[00:26:09.900 --> 00:26:10.740]   Wherever it is, right?
[00:26:10.740 --> 00:26:12.620]   And clearly it's a professional network.
[00:26:12.620 --> 00:26:16.220]   And so people don't share as many personal stuff.
[00:26:16.220 --> 00:26:19.540]   And I feel like recently I've seen a big shift
[00:26:19.540 --> 00:26:20.940]   towards more of a speeds and feeds.
[00:26:20.940 --> 00:26:21.860]   And I don't know if part of it is like
[00:26:21.860 --> 00:26:25.340]   building your own cloud and your brand on LinkedIn
[00:26:25.340 --> 00:26:28.940]   as a professional, but I see it's starting
[00:26:28.940 --> 00:26:30.540]   to all kind of look the same.
[00:26:30.540 --> 00:26:34.540]   And your recent posts have been a little different
[00:26:34.540 --> 00:26:36.340]   where you kind of cut the clutter
[00:26:36.340 --> 00:26:38.060]   and there is some like truth
[00:26:38.060 --> 00:26:40.860]   and some pretty provocative thoughts
[00:26:40.860 --> 00:26:42.780]   in the things you're posting.
[00:26:42.780 --> 00:26:45.380]   I'm kind of curious, like what's driving you to do that?
[00:26:45.380 --> 00:26:47.820]   Like where's it coming from?
[00:26:47.820 --> 00:26:49.620]   And what are you passionate about
[00:26:49.620 --> 00:26:51.660]   that's changing the way you present yourself
[00:26:51.660 --> 00:26:52.540]   on social media?
[00:26:54.780 --> 00:26:56.660]   - Unprocessed emotions.
[00:26:56.660 --> 00:27:00.300]   I mean, that's some of it, right?
[00:27:00.300 --> 00:27:03.420]   I think in some ways, some of the things I've posted
[00:27:03.420 --> 00:27:06.580]   have been an effort to express some things
[00:27:06.580 --> 00:27:08.780]   that I've bottled up inside for a long time.
[00:27:08.780 --> 00:27:13.740]   And I felt they needed to be said.
[00:27:13.740 --> 00:27:16.100]   And for a long time, maybe I was worried.
[00:27:16.100 --> 00:27:17.620]   I was scared of the repercussions.
[00:27:17.620 --> 00:27:21.500]   I was scared of, would there be a backlash?
[00:27:21.500 --> 00:27:23.980]   Would I get fired from any of my current jobs?
[00:27:23.980 --> 00:27:26.260]   Because I'm saying stuff that maybe suggests
[00:27:26.260 --> 00:27:28.060]   that some of the places I've worked for
[00:27:28.060 --> 00:27:29.460]   have been a bit toxic.
[00:27:29.460 --> 00:27:36.140]   It's tough, yeah.
[00:27:36.140 --> 00:27:37.620]   - Were there a few posts in particular
[00:27:37.620 --> 00:27:42.620]   that really made you wonder if you should put out or not?
[00:27:42.620 --> 00:27:45.180]   Would you believe they'd be controversial?
[00:27:45.180 --> 00:27:47.820]   - Yeah, so I recently posted something about my experience
[00:27:47.820 --> 00:27:51.140]   getting pushed out of a big agency on the Google account.
[00:27:53.820 --> 00:27:57.660]   And I went into some detail about the way it happened.
[00:27:57.660 --> 00:28:00.420]   And I guess I had gotten to a point where,
[00:28:00.420 --> 00:28:01.980]   A, the company had been sold.
[00:28:01.980 --> 00:28:06.020]   I was less worried that they would sort of come back
[00:28:06.020 --> 00:28:09.460]   and it would hurt me, although it might.
[00:28:09.460 --> 00:28:11.540]   And I took a risk in posting this.
[00:28:11.540 --> 00:28:18.260]   You know, I was struck by something you said maybe,
[00:28:18.260 --> 00:28:20.500]   you had a podcast that you put out there
[00:28:20.500 --> 00:28:21.660]   about your own personal growth
[00:28:21.660 --> 00:28:25.940]   and about being in some tough situations
[00:28:25.940 --> 00:28:30.420]   where managers were not necessarily professional to you.
[00:28:30.420 --> 00:28:32.300]   And I was struck by, you said,
[00:28:32.300 --> 00:28:36.500]   one person came back to you and reached out and apologized.
[00:28:36.500 --> 00:28:37.340]   - Yeah.
[00:28:37.340 --> 00:28:38.180]   - And that really touched me.
[00:28:38.180 --> 00:28:40.780]   And that was after I had posted this thing
[00:28:40.780 --> 00:28:42.220]   about getting pushed out.
[00:28:42.220 --> 00:28:45.140]   That hasn't happened to me.
[00:28:45.140 --> 00:28:50.140]   And I'm grateful that maybe I've had the experiences
[00:28:50.740 --> 00:28:53.940]   I've had because when I got pushed out of the agency,
[00:28:53.940 --> 00:28:56.580]   it pushed me into being a consultant.
[00:28:56.580 --> 00:29:00.140]   And quickly after that, I started a small boutique agency
[00:29:00.140 --> 00:29:01.300]   and then that didn't work out.
[00:29:01.300 --> 00:29:03.020]   And I started another one and that didn't work out.
[00:29:03.020 --> 00:29:06.460]   But all those experiences gave me a lot of confidence
[00:29:06.460 --> 00:29:08.060]   and not just my skillset,
[00:29:08.060 --> 00:29:11.100]   'cause I felt like I was already a capable copywriter
[00:29:11.100 --> 00:29:14.660]   and I could get jobs and hold them and advance
[00:29:14.660 --> 00:29:19.180]   and move up and manage other writers and other creatives.
[00:29:19.180 --> 00:29:24.180]   But I didn't know my worth in terms of the value of marketing
[00:29:24.180 --> 00:29:26.140]   as it relates to creative.
[00:29:26.140 --> 00:29:27.980]   As creatives, we're marketers
[00:29:27.980 --> 00:29:31.300]   and we have a lot of value to businesses.
[00:29:31.300 --> 00:29:34.740]   In fact, businesses only really have two jobs.
[00:29:34.740 --> 00:29:37.100]   That's to create a product or service
[00:29:37.100 --> 00:29:38.340]   and tell people about it.
[00:29:38.340 --> 00:29:43.700]   And, excuse me.
[00:29:47.820 --> 00:29:51.020]   And I wanted to start being...
[00:29:51.020 --> 00:29:53.420]   You're right in saying a lot of what I've seen
[00:29:53.420 --> 00:29:58.420]   also on Facebook, LinkedIn, it's a bit formulaic.
[00:29:58.420 --> 00:30:01.740]   It's like, I just reached a hundred million.
[00:30:01.740 --> 00:30:02.780]   Well, not a hundred million,
[00:30:02.780 --> 00:30:05.620]   but I just reached 10,000 followers.
[00:30:05.620 --> 00:30:07.420]   Thank you, which is great.
[00:30:07.420 --> 00:30:10.340]   Or here's three steps you need
[00:30:10.340 --> 00:30:13.180]   to make a million dollars in three days.
[00:30:13.180 --> 00:30:14.620]   Oh, that's not gonna work.
[00:30:14.780 --> 00:30:19.780]   Or here's all you need to do to be successful on LinkedIn,
[00:30:19.780 --> 00:30:21.540]   just post every day.
[00:30:21.540 --> 00:30:27.940]   Or any number of other kind of sort of really vapid stuff
[00:30:27.940 --> 00:30:33.540]   that I understand it's brand awareness, right?
[00:30:33.540 --> 00:30:37.500]   I mean, that's what folks are doing on LinkedIn.
[00:30:37.500 --> 00:30:38.820]   You're not getting leads right away.
[00:30:38.820 --> 00:30:39.860]   I mean, maybe some people are,
[00:30:39.860 --> 00:30:42.940]   but if you're looking for leads,
[00:30:42.940 --> 00:30:45.140]   I suppose to post regularly,
[00:30:45.140 --> 00:30:47.940]   put your name out there and you're creating brand awareness.
[00:30:47.940 --> 00:30:50.500]   Not that I like the term personal brand at all,
[00:30:50.500 --> 00:30:53.700]   but I think, so it has value, right?
[00:30:53.700 --> 00:30:56.100]   But you could be hurting your brand too.
[00:30:56.100 --> 00:30:58.380]   You can be putting stuff out there
[00:30:58.380 --> 00:30:59.580]   that undercuts your value,
[00:30:59.580 --> 00:31:01.100]   that says some things about you
[00:31:01.100 --> 00:31:05.660]   that maybe is not gonna help advance your business.
[00:31:05.660 --> 00:31:10.140]   So I've posted more, I think frankly,
[00:31:10.140 --> 00:31:11.300]   and I've always tried to do that.
[00:31:11.300 --> 00:31:15.660]   I think I don't see it as a place
[00:31:15.660 --> 00:31:17.660]   just to kind of post vapid stuff.
[00:31:17.660 --> 00:31:19.260]   Like I'm working on this post right now
[00:31:19.260 --> 00:31:21.420]   that I'm really worried about posting.
[00:31:21.420 --> 00:31:23.900]   It's a post about content marketing.
[00:31:23.900 --> 00:31:27.500]   It's called "Why Donald Trump is a Great Content Marketer."
[00:31:27.500 --> 00:31:30.900]   And I focus on his mugshot,
[00:31:30.900 --> 00:31:33.820]   which he sells as a coffee cup, or at least somebody does.
[00:31:33.820 --> 00:31:37.340]   So why is his mugshot coffee cup great content marketing?
[00:31:37.340 --> 00:31:40.060]   I break it down, like why it's helpful,
[00:31:40.060 --> 00:31:44.100]   'cause it gives you a lot of information about him.
[00:31:44.100 --> 00:31:46.180]   It makes some great promises,
[00:31:46.180 --> 00:31:48.140]   and I add in some more colorful language,
[00:31:48.140 --> 00:31:50.500]   but oh man, I'm scared.
[00:31:50.500 --> 00:31:53.140]   If I post that, what's gonna, I mean, what kind of,
[00:31:53.140 --> 00:31:53.980]   I don't know.
[00:31:53.980 --> 00:31:56.180]   So it's kind of on the same level
[00:31:56.180 --> 00:31:59.020]   when I posted that thing
[00:31:59.020 --> 00:32:00.860]   about getting pushed out of the agency.
[00:32:00.860 --> 00:32:02.500]   It was scary.
[00:32:02.500 --> 00:32:04.700]   I thought a lot about it.
[00:32:04.700 --> 00:32:07.300]   I showed it to a couple of people, gave me some help.
[00:32:08.500 --> 00:32:12.940]   And I had people reach out to me immediately
[00:32:12.940 --> 00:32:15.580]   that I didn't know, strangers, and said thank you.
[00:32:15.580 --> 00:32:17.860]   I went through the same thing.
[00:32:17.860 --> 00:32:19.580]   And that's very gratifying.
[00:32:19.580 --> 00:32:21.940]   - Yeah, I totally agree.
[00:32:21.940 --> 00:32:25.500]   I've had several people reach out to me saying,
[00:32:25.500 --> 00:32:27.900]   hey, we looked at your YouTube channel,
[00:32:27.900 --> 00:32:30.780]   and here's things you can do to monetize it.
[00:32:30.780 --> 00:32:32.740]   And I'm like, you know what?
[00:32:32.740 --> 00:32:35.340]   I don't care about monetization.
[00:32:35.340 --> 00:32:38.140]   The whole reason for me to do this podcast
[00:32:38.140 --> 00:32:40.260]   was I'm just trying to help people, right?
[00:32:40.260 --> 00:32:41.620]   Like there's people who are struggling,
[00:32:41.620 --> 00:32:45.060]   and if there's any insight or knowledge
[00:32:45.060 --> 00:32:47.660]   or even one piece of advice that would allow them
[00:32:47.660 --> 00:32:49.900]   to approach and interview differently
[00:32:49.900 --> 00:32:51.740]   or to do a job search differently
[00:32:51.740 --> 00:32:53.460]   or just amplify their own work differently,
[00:32:53.460 --> 00:32:55.220]   like that's the whole point of it,
[00:32:55.220 --> 00:32:56.420]   especially with this economy
[00:32:56.420 --> 00:32:58.260]   with so much uncertainty around AI.
[00:32:58.260 --> 00:32:59.660]   Like that's why I'm doing it.
[00:32:59.660 --> 00:33:01.660]   And that's why your post really just kind of stood out to me
[00:33:01.660 --> 00:33:04.180]   because it's freaking refreshing, man.
[00:33:06.420 --> 00:33:10.220]   The lesson that someone should take from this is like,
[00:33:10.220 --> 00:33:12.660]   obviously you haven't posted your thing yet, right?
[00:33:12.660 --> 00:33:15.100]   What will be interesting is a discourse
[00:33:15.100 --> 00:33:17.060]   around like why you did it.
[00:33:17.060 --> 00:33:20.460]   'Cause if you go in front of, let's say a,
[00:33:20.460 --> 00:33:22.940]   let's say somebody, you're interviewing for a job,
[00:33:22.940 --> 00:33:23.940]   and you've done something
[00:33:23.940 --> 00:33:25.380]   that might've been controversial,
[00:33:25.380 --> 00:33:29.940]   but the thought process that allowed you to take that risk,
[00:33:29.940 --> 00:33:31.940]   that is something that's worth inspecting into.
[00:33:31.940 --> 00:33:35.700]   It's like, what outcome were you trying to get
[00:33:35.700 --> 00:33:37.460]   for your audience?
[00:33:37.460 --> 00:33:39.540]   What were, what's your point of view?
[00:33:39.540 --> 00:33:43.180]   And what was your methodology in getting to that point?
[00:33:43.180 --> 00:33:47.420]   That skillset and, or courage,
[00:33:47.420 --> 00:33:51.060]   or even the thought process to go through that,
[00:33:51.060 --> 00:33:52.060]   you can't replicate that.
[00:33:52.060 --> 00:33:53.540]   You can't teach that.
[00:33:53.540 --> 00:33:55.780]   And for someone who's willing to do something like that
[00:33:55.780 --> 00:33:57.460]   versus just doing the safe thing,
[00:33:57.460 --> 00:34:01.580]   like I don't think right now is the right time to be safe
[00:34:01.580 --> 00:34:04.260]   because the market is tough.
[00:34:04.260 --> 00:34:05.820]   Companies have to stand out.
[00:34:05.820 --> 00:34:07.620]   And if you're just doing the same old thing,
[00:34:07.620 --> 00:34:08.980]   like it's just not gonna work.
[00:34:08.980 --> 00:34:13.100]   Like I'm proactively getting budgets cut
[00:34:13.100 --> 00:34:14.780]   because they are the same.
[00:34:14.780 --> 00:34:17.580]   And I'm being challenged to do more with less.
[00:34:17.580 --> 00:34:18.900]   And what does that mean?
[00:34:18.900 --> 00:34:22.580]   I gotta find a way to like innovate, right?
[00:34:22.580 --> 00:34:24.420]   And sometimes the innovating way you think
[00:34:24.420 --> 00:34:25.740]   and approach something is totally it.
[00:34:25.740 --> 00:34:28.500]   And again, it's really refreshing for me to see that.
[00:34:28.500 --> 00:34:32.980]   And I tend to gravitate a lot towards YouTube channels,
[00:34:32.980 --> 00:34:36.140]   you know, whether they're for work or just for fun, right?
[00:34:36.140 --> 00:34:39.740]   Like, and it's not even a political thing.
[00:34:39.740 --> 00:34:43.860]   Both aisles, if I see a truly authentic point of view,
[00:34:43.860 --> 00:34:44.700]   I wanna watch that.
[00:34:44.700 --> 00:34:46.300]   I don't wanna see the safe thing
[00:34:46.300 --> 00:34:50.540]   and something that clearly has an ulterior motive.
[00:34:50.540 --> 00:34:52.660]   So I just wanna kind of give you kudos on that, man.
[00:34:52.660 --> 00:34:55.900]   Like I hope you, whatever the reaction is,
[00:34:55.900 --> 00:34:58.700]   that it can turn into a different conversation
[00:34:58.700 --> 00:35:01.100]   'cause I think the world needs it.
[00:35:01.100 --> 00:35:02.340]   - Thank you, I appreciate that.
[00:35:02.340 --> 00:35:04.620]   I think it is important.
[00:35:04.620 --> 00:35:08.420]   There's great pressure in corporate culture,
[00:35:08.420 --> 00:35:12.340]   whether you're in-house or not, to conform.
[00:35:12.340 --> 00:35:13.180]   - Yeah.
[00:35:13.180 --> 00:35:14.380]   - And often for good reason,
[00:35:14.380 --> 00:35:16.580]   because we all have to row sort of in the same direction
[00:35:16.580 --> 00:35:17.780]   to make progress.
[00:35:17.780 --> 00:35:22.980]   But can you row faster if you have some folks
[00:35:22.980 --> 00:35:25.940]   that maybe can help you build a bigger oar?
[00:35:25.940 --> 00:35:28.900]   I think, or a bigger sale.
[00:35:30.580 --> 00:35:33.820]   And I think maybe we could have more sales
[00:35:33.820 --> 00:35:38.820]   and less rowers, we get a little further down the line.
[00:35:38.820 --> 00:35:42.620]   It's very hard when you're trying to conform to be honest.
[00:35:42.620 --> 00:35:48.100]   And you touched on this, I think,
[00:35:48.100 --> 00:35:50.020]   in your podcast about personal growth,
[00:35:50.020 --> 00:35:53.140]   where you start then doubting yourself.
[00:35:53.140 --> 00:35:57.820]   Okay, why if I'm conforming,
[00:35:57.820 --> 00:35:59.900]   but I'm in a toxic culture, let's say,
[00:35:59.900 --> 00:36:02.900]   that's not validating my value,
[00:36:02.900 --> 00:36:06.420]   my skills and everything I'm clearly doing,
[00:36:06.420 --> 00:36:08.780]   you start to doubt yourself.
[00:36:08.780 --> 00:36:09.620]   And I think,
[00:36:09.620 --> 00:36:17.620]   I had another post that I posted.
[00:36:17.620 --> 00:36:19.580]   It was about racism.
[00:36:19.580 --> 00:36:24.580]   And I had this experience that I read something
[00:36:26.780 --> 00:36:31.780]   that took some lyrics from a Tupac song that changes lyrics,
[00:36:31.780 --> 00:36:37.820]   which is a song about the persistence of racism.
[00:36:37.820 --> 00:36:40.620]   And this person was,
[00:36:40.620 --> 00:36:47.900]   this person was an exec who was promoting a salesperson
[00:36:47.900 --> 00:36:50.500]   who in their sales pitch had leveraged these lyrics,
[00:36:50.500 --> 00:36:52.380]   but changed them from what they were
[00:36:52.380 --> 00:36:56.460]   to say something like, my website's broken,
[00:36:56.460 --> 00:36:59.780]   it really sucks, I need a new solution,
[00:36:59.780 --> 00:37:01.260]   I'm gonna get this new solution,
[00:37:01.260 --> 00:37:02.700]   which happened to be Webflow.
[00:37:02.700 --> 00:37:09.380]   And then all these people were jumping on her saying 100,
[00:37:09.380 --> 00:37:13.340]   but the emoji 100 and fire.
[00:37:13.340 --> 00:37:16.780]   And I was so offended,
[00:37:16.780 --> 00:37:20.100]   like righteously offended, unfortunately.
[00:37:20.100 --> 00:37:22.940]   And so I posted on it,
[00:37:22.940 --> 00:37:27.940]   don't you think this is appropriation and isn't that wrong?
[00:37:27.940 --> 00:37:32.820]   And the person, the original poster posted back,
[00:37:32.820 --> 00:37:35.100]   this isn't appropriation, this is respect,
[00:37:35.100 --> 00:37:37.060]   we loved blah, blah, blah.
[00:37:37.060 --> 00:37:39.540]   So I said, I think this is a parody.
[00:37:39.540 --> 00:37:42.100]   And she said, no.
[00:37:42.100 --> 00:37:43.860]   And I posted a definition of the parody,
[00:37:43.860 --> 00:37:45.380]   of what a parody is.
[00:37:45.380 --> 00:37:46.420]   And she deleted it.
[00:37:46.420 --> 00:37:48.820]   And then she DMs me on the side.
[00:37:48.820 --> 00:37:50.140]   And we had this long back and forth.
[00:37:50.140 --> 00:37:52.620]   It was my first Twitter war on LinkedIn.
[00:37:52.620 --> 00:37:57.100]   And anyway, so like a year went by.
[00:37:57.100 --> 00:37:59.340]   Well, no, that night I was so incensed.
[00:37:59.340 --> 00:38:01.620]   I wrote this like awful screed.
[00:38:01.620 --> 00:38:04.940]   I was gonna post about terrible this person was.
[00:38:04.940 --> 00:38:07.380]   I waited a whole year, I didn't post it.
[00:38:07.380 --> 00:38:11.180]   I posted it a couple of weeks ago.
[00:38:11.180 --> 00:38:12.740]   And for whatever reason, crickets,
[00:38:12.740 --> 00:38:14.940]   and I got really depressed and I deleted it.
[00:38:14.940 --> 00:38:18.220]   I should post it again.
[00:38:18.220 --> 00:38:23.220]   This person recently got promoted to a very senior position
[00:38:23.220 --> 00:38:28.260]   at a very prominent social media tool solution.
[00:38:28.260 --> 00:38:30.220]   Yeah.
[00:38:30.220 --> 00:38:34.260]   We disagreed.
[00:38:34.260 --> 00:38:37.060]   She had a great fondness, I guess, for Tupac.
[00:38:37.060 --> 00:38:39.660]   And she felt like she wasn't misappropriating
[00:38:39.660 --> 00:38:42.700]   or culturally appropriating his work.
[00:38:42.700 --> 00:38:43.780]   I thought she was.
[00:38:43.780 --> 00:38:46.900]   And I thought, it was more than just that she posted it.
[00:38:46.900 --> 00:38:48.180]   It was also the reaction.
[00:38:48.180 --> 00:38:50.380]   Like the hundreds of people that liked it.
[00:38:50.380 --> 00:38:52.900]   It was disgusting to me.
[00:38:52.900 --> 00:38:57.380]   I mean, so there's that.
[00:38:57.380 --> 00:39:00.220]   So some things I post, and then if I don't get a reaction,
[00:39:00.220 --> 00:39:03.940]   like I'm self-conscious about not getting a reaction.
[00:39:03.940 --> 00:39:08.460]   When I feel so invested in it, then I delete it.
[00:39:08.460 --> 00:39:09.980]   'Cause I don't want it hanging out there
[00:39:09.980 --> 00:39:13.820]   and reminding me that no one really seems to care.
[00:39:13.820 --> 00:39:15.580]   Even though it's not about reactions.
[00:39:15.580 --> 00:39:16.980]   In reality, it's about, I mean,
[00:39:16.980 --> 00:39:20.860]   if you wanna think about performance per se on LinkedIn,
[00:39:20.860 --> 00:39:21.860]   it's about impressions.
[00:39:21.860 --> 00:39:24.020]   So, because you don't really know
[00:39:24.020 --> 00:39:25.540]   if someone's gonna react or not.
[00:39:25.540 --> 00:39:28.620]   If they saw it, then that means you reached somebody.
[00:39:28.620 --> 00:39:29.460]   - Yeah.
[00:39:29.460 --> 00:39:33.300]   So, you know, I've never had conversations with you
[00:39:33.300 --> 00:39:34.820]   like this before, you know?
[00:39:34.820 --> 00:39:37.060]   And it's pretty cool.
[00:39:37.060 --> 00:39:40.060]   And I see a lot of growth, you know?
[00:39:40.060 --> 00:39:44.340]   And you've clearly overcome a lot of things,
[00:39:44.340 --> 00:39:46.500]   whether it's self-inflicted or not.
[00:39:46.500 --> 00:39:48.300]   Can you tell us a little bit about your journey?
[00:39:48.300 --> 00:39:50.220]   You know, 'cause you and I have talked about
[00:39:50.220 --> 00:39:52.180]   whether it's addiction or could be whatever, right?
[00:39:52.180 --> 00:39:53.740]   And you and I have our own versions
[00:39:53.740 --> 00:39:55.660]   of whatever that looks like to us.
[00:39:55.660 --> 00:39:57.900]   But can you tell us about like your little journey
[00:39:57.900 --> 00:40:01.580]   and what you went through and where you are today?
[00:40:01.580 --> 00:40:03.700]   - Sure.
[00:40:03.700 --> 00:40:06.340]   You want the short version or the semi-short version?
[00:40:06.340 --> 00:40:08.140]   - Let's do semi-short.
[00:40:08.140 --> 00:40:08.980]   - Okay.
[00:40:11.180 --> 00:40:15.740]   When I was a youngster, I went to college in Oberlin,
[00:40:15.740 --> 00:40:16.820]   my first college.
[00:40:16.820 --> 00:40:19.220]   I ended up in Ohio.
[00:40:19.220 --> 00:40:20.820]   I was a California kid.
[00:40:20.820 --> 00:40:22.660]   I grew up in LA.
[00:40:22.660 --> 00:40:27.660]   And I ended up going to Oberlin, loved it.
[00:40:27.660 --> 00:40:31.420]   But also the summer before I left, my parents got divorced.
[00:40:31.420 --> 00:40:34.260]   There was a lot of kind of chaos
[00:40:34.260 --> 00:40:35.780]   in the few years leading up to that.
[00:40:35.780 --> 00:40:38.220]   I had been quite a good student.
[00:40:38.220 --> 00:40:40.340]   Like I was a scholar athlete,
[00:40:40.340 --> 00:40:44.500]   but I'd also gotten into using and drinking.
[00:40:44.500 --> 00:40:49.500]   And when I ended up at Oberlin, I was pretty isolated.
[00:40:49.500 --> 00:40:54.100]   I started smoking pot on my own a lot.
[00:40:54.100 --> 00:40:59.900]   Couple of years go by and I had this bad experience
[00:40:59.900 --> 00:41:03.740]   with mescaline and I lost it.
[00:41:03.740 --> 00:41:04.740]   I had a mental breakdown.
[00:41:04.740 --> 00:41:05.980]   So I dropped out of school
[00:41:05.980 --> 00:41:09.420]   and I ended up like going through a lot of stuff.
[00:41:09.420 --> 00:41:13.180]   Like eventually I ended up back at UCLA somehow.
[00:41:13.180 --> 00:41:16.860]   And I graduated from UCLA with an English degree
[00:41:16.860 --> 00:41:20.340]   and about the time I started that job
[00:41:20.340 --> 00:41:22.820]   writing copy for Howard Stern.
[00:41:22.820 --> 00:41:27.220]   But at the time, it's in 1993,
[00:41:27.220 --> 00:41:30.260]   my folks did an intervention and they said,
[00:41:30.260 --> 00:41:32.860]   'cause I was living at my dad's house in Santa Monica
[00:41:32.860 --> 00:41:35.460]   and riding the big blue bus to UCLA.
[00:41:35.460 --> 00:41:40.460]   And he said, "You can't stay here anymore and keep using."
[00:41:40.460 --> 00:41:43.180]   I was getting high smoking pot.
[00:41:43.180 --> 00:41:45.980]   And it probably doesn't sound like a big thing,
[00:41:45.980 --> 00:41:48.420]   but I was stealing money from him to buy it.
[00:41:48.420 --> 00:41:51.540]   It was just not so hot.
[00:41:51.540 --> 00:41:54.980]   And so I ended up at a recovery house
[00:41:54.980 --> 00:41:57.220]   and I lived at a recovery house for 15 months
[00:41:57.220 --> 00:41:59.340]   while I went to UCLA.
[00:41:59.340 --> 00:42:00.740]   So imagine I was in a room
[00:42:00.740 --> 00:42:02.500]   with like six other recovery addicts
[00:42:02.500 --> 00:42:04.380]   and a house full of 25.
[00:42:04.380 --> 00:42:06.500]   It was a very intense experience.
[00:42:06.500 --> 00:42:10.020]   They had, I don't know if anyone's familiar with Synanon,
[00:42:10.020 --> 00:42:14.900]   but it's a cult out of Santa Monica that was eventually,
[00:42:14.900 --> 00:42:18.540]   the leader was like charged with federal crimes
[00:42:18.540 --> 00:42:21.740]   for like all sorts of awful stuff.
[00:42:21.740 --> 00:42:23.940]   Anyway, the guy that ran the house
[00:42:23.940 --> 00:42:25.860]   had an experience like that.
[00:42:25.860 --> 00:42:27.900]   He was very hardcore.
[00:42:27.900 --> 00:42:32.060]   We had groups where it was like ego smashing.
[00:42:32.060 --> 00:42:33.020]   You sat in the middle of the room
[00:42:33.020 --> 00:42:36.180]   and people just hurled insults at you for like hours.
[00:42:36.180 --> 00:42:37.580]   But it was supposedly, it was recovery.
[00:42:37.580 --> 00:42:40.620]   At the same time, I got involved with some other people
[00:42:40.620 --> 00:42:43.580]   that had a much more loving response.
[00:42:43.580 --> 00:42:50.420]   And so I stayed sober for a long time,
[00:42:50.420 --> 00:42:53.780]   moved up to the Bay Area in 2001.
[00:42:53.780 --> 00:42:58.780]   And I had done some work as a writer for taglines.
[00:42:58.780 --> 00:43:02.020]   And then eventually I got a job.
[00:43:02.020 --> 00:43:03.980]   I went back to school.
[00:43:03.980 --> 00:43:05.420]   I got an MFA in creative writing.
[00:43:05.420 --> 00:43:10.420]   I wrote a novel and I was teaching freshman composition.
[00:43:10.420 --> 00:43:12.900]   I got paid $400 a class.
[00:43:12.900 --> 00:43:15.500]   I had two classes per month, $400 per month.
[00:43:15.500 --> 00:43:18.620]   And I got a call from eBay to get a job as a writer
[00:43:18.620 --> 00:43:20.700]   and they were gonna pay $400 a day.
[00:43:20.700 --> 00:43:23.660]   So I took that and I've been a writer ever since.
[00:43:23.660 --> 00:43:25.420]   And then along the way, I guess,
[00:43:28.660 --> 00:43:33.180]   I was mainly sober, but until about, I guess,
[00:43:33.180 --> 00:43:37.980]   2000, really about the time I had that push out,
[00:43:37.980 --> 00:43:39.340]   I have experience at the agency
[00:43:39.340 --> 00:43:42.660]   and I had a pretty rough time with this agency.
[00:43:42.660 --> 00:43:44.500]   I started where I had recruited a couple of people
[00:43:44.500 --> 00:43:45.460]   from the Google account
[00:43:45.460 --> 00:43:48.700]   and we just didn't work out together as partners.
[00:43:48.700 --> 00:43:51.220]   And I started using again off and on
[00:43:51.220 --> 00:43:52.420]   and then more intensely.
[00:43:52.420 --> 00:43:54.780]   And then in the last couple of years, quite a bit.
[00:43:54.780 --> 00:43:59.780]   And so I was sneaking it and I wasn't smoking so much.
[00:43:59.780 --> 00:44:03.980]   I would use other things like edibles or tinctures
[00:44:03.980 --> 00:44:06.720]   and I was really stoned all the time.
[00:44:06.720 --> 00:44:13.860]   I was functional, highly functional.
[00:44:13.860 --> 00:44:17.460]   I was earning a lot more than I'd ever learned,
[00:44:17.460 --> 00:44:18.740]   three, four times as much as I did
[00:44:18.740 --> 00:44:20.500]   as in-house corporate person.
[00:44:20.500 --> 00:44:23.900]   So that on the face of it, I was doing okay.
[00:44:23.900 --> 00:44:27.220]   Bought a house in San Francisco, have two cars,
[00:44:27.220 --> 00:44:30.140]   an Audi and a BMW, like we're doing fine.
[00:44:30.140 --> 00:44:36.980]   But emotionally I was dead in a way.
[00:44:36.980 --> 00:44:39.860]   And I was really dead to my wife and daughter.
[00:44:39.860 --> 00:44:44.860]   And at some point my wife said to me,
[00:44:44.860 --> 00:44:49.820]   "I know what you're doing, your daughter does too."
[00:44:52.100 --> 00:44:54.300]   She's like, "You have to stop."
[00:44:54.300 --> 00:45:01.500]   And so I did for a while and then I started again.
[00:45:01.500 --> 00:45:05.540]   And then more recently she said the same thing
[00:45:05.540 --> 00:45:09.020]   and I stopped again.
[00:45:09.020 --> 00:45:14.020]   And like immediately I had this intense explosion of energy
[00:45:14.020 --> 00:45:21.460]   and all that stuff I had bottled up,
[00:45:21.460 --> 00:45:25.340]   I was masking, was unmasked.
[00:45:25.340 --> 00:45:29.140]   And I'm still very close to that.
[00:45:29.140 --> 00:45:32.580]   I'm still working through it.
[00:45:32.580 --> 00:45:37.580]   I'm getting some therapy and a lot of therapy.
[00:45:37.580 --> 00:45:46.240]   And yeah, so I think all those things make up who I am today
[00:45:46.240 --> 00:45:50.860]   and I think I have a lot of respect for all the people
[00:45:50.860 --> 00:45:54.340]   that have been through things like this in other ways,
[00:45:54.340 --> 00:45:59.340]   but understand that we really only have today.
[00:45:59.340 --> 00:46:05.100]   - Yeah, I'm really proud of you, dude.
[00:46:05.100 --> 00:46:14.140]   When you have roots deep in anger or fear or pain
[00:46:14.140 --> 00:46:19.980]   and life adds to it and you cover it,
[00:46:19.980 --> 00:46:22.500]   when things bubble up, it's always really, really intense.
[00:46:22.500 --> 00:46:26.340]   And I can understand how you could fall back into it.
[00:46:26.340 --> 00:46:31.780]   I think for people listening to this,
[00:46:31.780 --> 00:46:33.620]   the part that's encouraging for me
[00:46:33.620 --> 00:46:36.620]   is you're able to find ways to get out.
[00:46:36.620 --> 00:46:38.740]   I think the key is obviously figuring out
[00:46:38.740 --> 00:46:43.560]   how to notice the indicators that pull you back in.
[00:46:43.560 --> 00:46:47.860]   But I'm excited that this time
[00:46:47.860 --> 00:46:49.500]   you described a burst of energy
[00:46:49.500 --> 00:46:53.060]   'cause that's the first time you used that word
[00:46:53.060 --> 00:46:57.820]   at the exit of an addiction that you didn't use before.
[00:46:57.820 --> 00:47:01.900]   And I'm hoping this new life that you're discovering
[00:47:01.900 --> 00:47:03.460]   and re-energizing, reinvigorating,
[00:47:03.460 --> 00:47:05.240]   that you're channeling it into something else
[00:47:05.240 --> 00:47:07.780]   where those previous triggers that used to pull you in
[00:47:07.780 --> 00:47:09.720]   are now displaced by something new.
[00:47:09.720 --> 00:47:13.140]   And there is no need to go back
[00:47:13.140 --> 00:47:15.460]   'cause now you found a new thing that gives you,
[00:47:15.460 --> 00:47:19.020]   that kind of hopefully covers over
[00:47:19.020 --> 00:47:21.540]   or makes up for some of the deficiencies you've had
[00:47:21.540 --> 00:47:23.860]   where you had to go and lean towards a substance
[00:47:23.860 --> 00:47:26.220]   to kind of take over.
[00:47:26.220 --> 00:47:29.280]   And so I'm happy for you, man.
[00:47:29.280 --> 00:47:31.700]   - Thank you.
[00:47:31.700 --> 00:47:32.660]   I appreciate that.
[00:47:32.660 --> 00:47:34.180]   And I don't think it's one thing.
[00:47:34.180 --> 00:47:39.180]   It's family, it's friends, it's really relationships.
[00:47:42.820 --> 00:47:47.820]   Some of it is what I think hopefully this podcast enables
[00:47:47.820 --> 00:47:50.700]   which is to help somebody else.
[00:47:50.700 --> 00:47:54.300]   Just one person would be a lot.
[00:47:54.300 --> 00:47:59.300]   And to know that we can go through hard times
[00:47:59.300 --> 00:48:03.760]   and still keep going that...
[00:48:03.760 --> 00:48:12.540]   I went to this concert in 2001 right after 9/11
[00:48:13.380 --> 00:48:16.540]   when Marsalis was playing at the Hollywood Bowl.
[00:48:16.540 --> 00:48:21.540]   And he played this 12 part symphony.
[00:48:21.540 --> 00:48:26.420]   And we mean he had the Lincoln Center Jazz Orchestra
[00:48:26.420 --> 00:48:28.780]   and then the LA Philharmonic and then the choir.
[00:48:28.780 --> 00:48:32.620]   And I think the symphony is named "All Rise."
[00:48:32.620 --> 00:48:37.020]   But at the end of it, they did the whole thing.
[00:48:37.020 --> 00:48:38.940]   It was like a two hour performance.
[00:48:38.940 --> 00:48:43.940]   And he gives this speech about how this horrible thing
[00:48:43.940 --> 00:48:50.500]   had happened in New York City, like the previous week.
[00:48:50.500 --> 00:48:52.220]   And he said, "You know what?
[00:48:52.220 --> 00:48:54.860]   We're gonna get up and keep going
[00:48:54.860 --> 00:48:57.300]   'cause what else can we do?"
[00:48:57.300 --> 00:49:04.620]   Man, and then they did an encore.
[00:49:04.620 --> 00:49:08.180]   Like the LA Phil does not do encores.
[00:49:08.180 --> 00:49:10.940]   And it was cool.
[00:49:10.940 --> 00:49:12.020]   I lived in Hollywood at the time.
[00:49:12.020 --> 00:49:13.740]   I was like skipping all the way home.
[00:49:13.740 --> 00:49:14.980]   I was so happy.
[00:49:14.980 --> 00:49:19.060]   Yeah, I think music, for me,
[00:49:19.060 --> 00:49:20.780]   music is certainly inspiring.
[00:49:20.780 --> 00:49:23.860]   Writing, I've been writing a lot more.
[00:49:23.860 --> 00:49:25.020]   More personal stuff, too.
[00:49:25.020 --> 00:49:30.020]   I wanna really write more about more fiction,
[00:49:30.020 --> 00:49:34.820]   longer form stuff.
[00:49:35.220 --> 00:49:38.700]   I got an editor and I've been working on that.
[00:49:38.700 --> 00:49:42.220]   Exercise.
[00:49:42.220 --> 00:49:43.460]   Yeah, there's a bunch of things.
[00:49:43.460 --> 00:49:44.860]   I don't think it's any one thing,
[00:49:44.860 --> 00:49:47.300]   but I appreciate what you said.
[00:49:47.300 --> 00:49:51.660]   And I really do hope this reaches somebody
[00:49:51.660 --> 00:49:54.860]   and lets them know.
[00:49:54.860 --> 00:50:01.420]   I wanna say something about AI,
[00:50:01.420 --> 00:50:05.380]   but also something about just being human.
[00:50:05.380 --> 00:50:07.540]   AI feels really scary, I think,
[00:50:07.540 --> 00:50:09.460]   to creatives and maybe a lot of other people right now,
[00:50:09.460 --> 00:50:11.860]   because it feels like it's coming for our jobs.
[00:50:11.860 --> 00:50:16.660]   But AI doesn't really know right.
[00:50:16.660 --> 00:50:17.740]   I can say definitively,
[00:50:17.740 --> 00:50:21.340]   AI does not know right from wrong, but you do.
[00:50:21.340 --> 00:50:27.580]   AI doesn't have a soul, but you do.
[00:50:30.740 --> 00:50:33.140]   And I think that's really important to remember.
[00:50:33.140 --> 00:50:39.380]   - Yeah, I love that, man.
[00:50:39.380 --> 00:50:42.380]   I'm kind of in awe of just everything you said
[00:50:42.380 --> 00:50:44.860]   and quote, "What can't we do?"
[00:50:44.860 --> 00:50:48.460]   And I think maybe the advice I would give
[00:50:48.460 --> 00:50:50.380]   to people who are younger in their careers
[00:50:50.380 --> 00:50:52.020]   is look at me and you.
[00:50:52.020 --> 00:50:53.460]   We're old hats.
[00:50:53.460 --> 00:50:54.860]   I've got a white, my beard is white.
[00:50:54.860 --> 00:50:56.500]   I just cut it down.
[00:50:56.500 --> 00:50:57.340]   And I think that--
[00:50:57.340 --> 00:50:59.180]   - I'm white on my beard, I guess I do.
[00:50:59.180 --> 00:51:00.580]   It's salt and pepper.
[00:51:00.580 --> 00:51:03.660]   I think the thing that you and I are realizing
[00:51:03.660 --> 00:51:06.940]   is as we're kind of in this season
[00:51:06.940 --> 00:51:08.740]   of our career in our lives,
[00:51:08.740 --> 00:51:11.620]   we've done a lot of that, right?
[00:51:11.620 --> 00:51:14.540]   And we've, for the most part, we know who we are,
[00:51:14.540 --> 00:51:16.580]   or in some cases, maybe rediscovering.
[00:51:16.580 --> 00:51:20.140]   But there isn't this need or feeling
[00:51:20.140 --> 00:51:22.020]   like we need to go out and put ourselves
[00:51:22.020 --> 00:51:23.300]   in a way that we did when we were younger.
[00:51:23.300 --> 00:51:25.460]   And I think there is a need now
[00:51:25.460 --> 00:51:28.020]   to develop more genuine relationships
[00:51:28.020 --> 00:51:29.180]   or having more authenticity.
[00:51:29.180 --> 00:51:32.820]   Just coming back to the true center of who you are.
[00:51:32.820 --> 00:51:35.140]   And I think for someone who's young in their career,
[00:51:35.140 --> 00:51:38.540]   I would encourage you to discover that earlier.
[00:51:38.540 --> 00:51:40.700]   You know, 'cause I remember when I was early on my career,
[00:51:40.700 --> 00:51:43.660]   I was so focused on making a name for myself
[00:51:43.660 --> 00:51:45.860]   or creating a version of myself
[00:51:45.860 --> 00:51:48.780]   that I thought would be more marketable for employers.
[00:51:48.780 --> 00:51:51.220]   And along the way, it kept taking me away
[00:51:51.220 --> 00:51:53.740]   from my true north, my true center, right?
[00:51:53.740 --> 00:51:56.540]   And if I had just someone who just grabbed me
[00:51:56.540 --> 00:51:59.140]   and be like, "Dude, this is who you are.
[00:51:59.140 --> 00:52:02.500]   "Be who you are, be authentic.
[00:52:02.500 --> 00:52:04.340]   "Don't be afraid to be transparent."
[00:52:04.340 --> 00:52:07.300]   I think that would have caused me
[00:52:07.300 --> 00:52:10.260]   to make different decisions in my career.
[00:52:10.260 --> 00:52:12.140]   I think it would have made me approach conversations
[00:52:12.140 --> 00:52:13.780]   and relationships differently.
[00:52:13.780 --> 00:52:16.500]   It definitely would have made me approach interviews
[00:52:16.500 --> 00:52:18.540]   differently as well, in a way that probably
[00:52:18.540 --> 00:52:20.260]   would have felt refreshing to the interviewer,
[00:52:20.260 --> 00:52:21.820]   'cause now they're getting something real
[00:52:21.820 --> 00:52:24.260]   and not some canned thing that was prepared.
[00:52:25.620 --> 00:52:28.060]   So yeah, and I love the reminder at the end of the day,
[00:52:28.060 --> 00:52:30.700]   it's like AI is there,
[00:52:30.700 --> 00:52:32.500]   but it's not gonna displace us as humans.
[00:52:32.500 --> 00:52:37.500]   And there's a role in it where we're invaluable, right?
[00:52:37.500 --> 00:52:42.620]   - There's a great poem by this Polish writer,
[00:52:42.620 --> 00:52:45.740]   Adam Zagajewski, I think he recently passed away.
[00:52:45.740 --> 00:52:47.820]   He has a poem entitled,
[00:52:47.820 --> 00:52:50.260]   "Do Not Let the Luminous Moment Dissolve."
[00:52:51.380 --> 00:52:56.380]   It's this amazing poem about the luminous moment,
[00:52:56.380 --> 00:52:58.500]   but he has a line in there,
[00:52:58.500 --> 00:53:02.700]   "We have yet to rise to the level of ourselves."
[00:53:02.700 --> 00:53:08.940]   That always struck me, like, okay,
[00:53:08.940 --> 00:53:14.660]   if I have to, what am I gonna do today?
[00:53:14.660 --> 00:53:16.540]   I don't know.
[00:53:16.540 --> 00:53:18.660]   I mean, maybe I have a plan, I have a list or whatever,
[00:53:18.660 --> 00:53:22.620]   but where can I really land at the end of the day?
[00:53:22.620 --> 00:53:25.460]   And then when I get to the end of the day,
[00:53:25.460 --> 00:53:28.260]   and I look back, where am I going tomorrow?
[00:53:28.260 --> 00:53:30.140]   I mean, in some ways it's a mystery.
[00:53:30.140 --> 00:53:32.180]   That's kind of the beauty of our lives,
[00:53:32.180 --> 00:53:35.140]   is if we can open ourselves up to the mystery
[00:53:35.140 --> 00:53:37.420]   and take a little bit of risk,
[00:53:37.420 --> 00:53:41.260]   even when we don't fully fill those shoes.
[00:53:41.260 --> 00:53:48.100]   I think I'm often surprised where I end up.
[00:53:48.100 --> 00:53:51.940]   I didn't expect to be doing this with you a year ago.
[00:53:51.940 --> 00:53:56.180]   I think you saw one of my posts and you reached out.
[00:53:56.180 --> 00:53:57.020]   - Yep.
[00:53:57.020 --> 00:54:00.460]   - So, yeah.
[00:54:00.460 --> 00:54:01.300]   - Yeah.
[00:54:01.300 --> 00:54:05.860]   Well, man, I wanna thank you for being on the show.
[00:54:05.860 --> 00:54:08.180]   I think there's so much goodness
[00:54:08.180 --> 00:54:11.580]   of what you kind of walk through in your stories,
[00:54:11.580 --> 00:54:14.900]   and I'm hoping that you'll join me again
[00:54:14.900 --> 00:54:15.780]   for a future episode.
[00:54:15.780 --> 00:54:17.020]   We're gonna talk about anything else,
[00:54:17.020 --> 00:54:18.900]   but Jesse Ratner, just wanna thank you
[00:54:18.900 --> 00:54:20.980]   for being on the show, man.
[00:54:20.980 --> 00:54:22.340]   - You're absolutely welcome, Tim.
[00:54:22.340 --> 00:54:23.620]   Thank you so much.
[00:54:23.620 --> 00:54:24.460]   - Take care.
[00:54:24.460 --> 00:54:25.300]   - All right, bye.
[00:54:25.460 --> 00:54:28.060]   (gentle music)
[00:54:28.060 --> 00:54:38.060]   [BLANK_AUDIO]

