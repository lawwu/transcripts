
[00:00:00.000 --> 00:00:02.380]   You may also be running up against the,
[00:00:02.380 --> 00:00:07.380]   even for the Mag 7, the size of Capo X deployment,
[00:00:07.380 --> 00:00:10.440]   where their CFOs start to talk at higher levels.
[00:00:10.440 --> 00:00:12.700]   - For sure, totally.
[00:00:12.700 --> 00:00:15.280]   (upbeat music)
[00:00:15.280 --> 00:00:26.980]   Sonny, Bill, great to see you guys.
[00:00:26.980 --> 00:00:28.060]   - Good to see you.
[00:00:28.060 --> 00:00:29.540]   - Good to be back.
[00:00:29.540 --> 00:00:31.100]   - Thanks, man, it's great to have you.
[00:00:31.100 --> 00:00:32.780]   We literally just finished two days
[00:00:32.780 --> 00:00:34.860]   of the Altimeter annual meetings.
[00:00:34.860 --> 00:00:38.540]   I mean, we had hundreds of investors, CEOs, founders,
[00:00:38.540 --> 00:00:43.120]   and the theme was scaling intelligence to AGI.
[00:00:43.120 --> 00:00:45.740]   We had Nikesh talking about enterprise AI.
[00:00:45.740 --> 00:00:48.660]   We had Rene Haas talking about AI at the edge.
[00:00:48.660 --> 00:00:51.500]   We had Noam Brown talking about, you know,
[00:00:51.500 --> 00:00:54.140]   the Strawberry and O1 model and inference time reasoning.
[00:00:54.140 --> 00:00:58.300]   We had Sonny talking about, you know, accelerating inference.
[00:00:58.300 --> 00:01:01.020]   And of course, we kicked off with Jensen
[00:01:01.020 --> 00:01:03.460]   talking about the future of compute.
[00:01:03.460 --> 00:01:07.100]   You know, I did the Jensen talk with my partner, Clark Tang,
[00:01:07.100 --> 00:01:09.540]   who covers the compute layer and the public side.
[00:01:09.540 --> 00:01:11.260]   We recorded it on Friday.
[00:01:11.260 --> 00:01:14.020]   We'll be releasing it as part of this pod.
[00:01:14.020 --> 00:01:15.460]   And man, was it dense.
[00:01:15.460 --> 00:01:18.620]   I mean, he was, you know, he was on fire.
[00:01:18.620 --> 00:01:20.240]   He told me, I asked him at the beginning of the pod,
[00:01:20.240 --> 00:01:21.080]   "What do you want to do?"
[00:01:21.080 --> 00:01:22.260]   He said, "Grip it and rip it."
[00:01:22.260 --> 00:01:23.540]   And we did.
[00:01:23.540 --> 00:01:25.560]   90 minutes, we went deep.
[00:01:25.560 --> 00:01:26.860]   I shared it with you guys.
[00:01:26.860 --> 00:01:28.000]   We've all listened to it.
[00:01:28.000 --> 00:01:30.740]   I learned so much playing it back
[00:01:30.740 --> 00:01:34.060]   that I just thought it made sense for us to unpack it,
[00:01:34.060 --> 00:01:36.980]   right, to really, to really analyze it,
[00:01:36.980 --> 00:01:39.460]   see what we agree with, what we may disagree with,
[00:01:39.460 --> 00:01:40.860]   things we want to further explore.
[00:01:40.860 --> 00:01:44.820]   Sonny, any high level reactions to it?
[00:01:44.820 --> 00:01:47.380]   Yeah, you know, first, it's the first time
[00:01:47.380 --> 00:01:49.340]   I've really seen him in a format
[00:01:49.340 --> 00:01:52.620]   where you got all that information out in one setting,
[00:01:52.620 --> 00:01:54.820]   'cause you kind of get the, you get the tidbits.
[00:01:54.820 --> 00:01:57.740]   And the ones that really struck with me was when he said,
[00:01:57.740 --> 00:01:59.340]   "NVIDIA's not a GPU company.
[00:01:59.340 --> 00:02:01.880]   "They're an accelerated compute company."
[00:02:01.880 --> 00:02:05.120]   I think the next one, you know, which you'll touch on
[00:02:05.120 --> 00:02:06.060]   is where he really said,
[00:02:06.060 --> 00:02:09.440]   "The data center's the unit of compute."
[00:02:09.440 --> 00:02:11.760]   I thought that was massive.
[00:02:11.760 --> 00:02:13.240]   And, you know, sort of just closing out
[00:02:13.240 --> 00:02:16.680]   when he talked about, he thinks about using
[00:02:16.680 --> 00:02:20.120]   and already utilizing so much AI within NVIDIA
[00:02:20.120 --> 00:02:22.680]   and how that's a superpower for them to accelerate
[00:02:22.680 --> 00:02:24.000]   over everyone they're competing with.
[00:02:24.000 --> 00:02:27.320]   I thought those were kind of really awesome points in him,
[00:02:27.320 --> 00:02:29.540]   you know, eating the dog food, as they say.
[00:02:29.540 --> 00:02:31.380]   It is incredible, you know,
[00:02:31.380 --> 00:02:33.300]   there's this thing we'll talk about later,
[00:02:33.300 --> 00:02:36.820]   but he said he thinks they can 3X, you know,
[00:02:36.820 --> 00:02:38.740]   the top line of the business
[00:02:38.740 --> 00:02:41.820]   while only adding 25% more humans
[00:02:41.820 --> 00:02:45.380]   because they can have 100,000 autonomous agents
[00:02:45.380 --> 00:02:47.620]   doing things like building the software,
[00:02:47.620 --> 00:02:49.140]   doing the security,
[00:02:49.140 --> 00:02:51.200]   and that he becomes really a prompt agent,
[00:02:51.200 --> 00:02:53.540]   not only for his human direct reports,
[00:02:53.540 --> 00:02:56.620]   but also for these agents, which, you know,
[00:02:56.620 --> 00:02:58.360]   really is mind-boggling.
[00:02:58.360 --> 00:03:00.600]   Bill, anything stand out for you?
[00:03:00.600 --> 00:03:03.240]   Well, one, I mean, you should be pleased
[00:03:03.240 --> 00:03:05.620]   that you were able to get his time.
[00:03:05.620 --> 00:03:09.360]   You know, this is, at points in time,
[00:03:09.360 --> 00:03:13.980]   the largest market cap company in the world, if not one too.
[00:03:13.980 --> 00:03:16.840]   And so it was so, I think, kind of him
[00:03:16.840 --> 00:03:18.320]   to sit down with you for so long.
[00:03:18.320 --> 00:03:20.600]   And during the pod, he kept saying,
[00:03:20.600 --> 00:03:22.360]   "I can stay as long as you want."
[00:03:22.360 --> 00:03:24.800]   I was like, "Doesn't he have something to be doing?"
[00:03:24.800 --> 00:03:26.900]   (laughing)
[00:03:26.900 --> 00:03:28.620]   Is incredibly generous and-
[00:03:28.620 --> 00:03:29.940]   It's fantastic.
[00:03:29.940 --> 00:03:33.380]   But my other big, I mean, I had two big takeaways.
[00:03:33.380 --> 00:03:37.540]   One, I mean, it's obvious that this guy's, you know,
[00:03:37.540 --> 00:03:39.700]   rolling on all cylinders here, right?
[00:03:39.700 --> 00:03:44.700]   Like you have a company at a 3.3 trillion market cap
[00:03:44.700 --> 00:03:47.540]   that's still growing over 100% a year.
[00:03:47.540 --> 00:03:49.620]   And the margins are insane.
[00:03:49.620 --> 00:03:52.380]   I mean, 65% operating margins.
[00:03:52.380 --> 00:03:55.200]   There's only like five companies in the S&P 500
[00:03:55.200 --> 00:03:56.120]   at that level.
[00:03:56.120 --> 00:03:59.120]   And they certainly aren't growing at this pace.
[00:03:59.120 --> 00:04:02.960]   And when you bring up that point about getting more done
[00:04:02.960 --> 00:04:04.920]   on the increment with fewer employees,
[00:04:04.920 --> 00:04:06.360]   where's this gonna go?
[00:04:06.360 --> 00:04:08.720]   Like 80% operating margins?
[00:04:08.720 --> 00:04:10.040]   I mean, that would be unprecedented.
[00:04:10.040 --> 00:04:13.300]   There's a lot that's already here that's unprecedented,
[00:04:13.300 --> 00:04:17.200]   but obviously Wall Street is fully aware
[00:04:17.200 --> 00:04:21.120]   of the unbelievable performance of this company.
[00:04:21.120 --> 00:04:23.580]   And, you know, the multiples reflected
[00:04:23.580 --> 00:04:25.760]   and the market cap reflects it,
[00:04:25.760 --> 00:04:29.200]   but it's super powerful how they're executing.
[00:04:29.200 --> 00:04:31.880]   And you can see the confidence in every answer
[00:04:31.880 --> 00:04:32.960]   that he gives.
[00:04:32.960 --> 00:04:35.060]   We spent about a third of the pod
[00:04:35.060 --> 00:04:37.120]   on NVIDIA's competitive mode,
[00:04:37.120 --> 00:04:38.440]   really trying to break it down,
[00:04:38.440 --> 00:04:40.720]   really trying to understand this idea
[00:04:40.720 --> 00:04:42.600]   of systems level advantages,
[00:04:42.600 --> 00:04:46.460]   the combinatorial advantages that he has in the business.
[00:04:46.460 --> 00:04:48.680]   Because I think when I talk to people
[00:04:48.680 --> 00:04:50.080]   around the investment community,
[00:04:50.080 --> 00:04:52.640]   despite how well it's covered, Bill, right?
[00:04:52.640 --> 00:04:55.680]   There's still this idea that it's just a GPU
[00:04:55.680 --> 00:04:57.840]   and that somebody is gonna build a better chip.
[00:04:57.840 --> 00:05:00.360]   They're gonna come along and displace the business.
[00:05:00.360 --> 00:05:02.920]   And so when he said, again,
[00:05:02.920 --> 00:05:05.000]   it can sound like marketing speak, Sonny,
[00:05:05.000 --> 00:05:07.620]   when somebody says it's not a GPU company,
[00:05:07.620 --> 00:05:10.080]   it's an accelerated compute company.
[00:05:10.080 --> 00:05:12.600]   You know, we showed this chart
[00:05:12.600 --> 00:05:15.240]   where you can see kind of the NVIDIA full stack.
[00:05:15.240 --> 00:05:18.200]   And he talked about how he just built layer after layer
[00:05:18.200 --> 00:05:20.280]   after layer of the stack, you know,
[00:05:20.280 --> 00:05:23.600]   over the course of the last decade and a half.
[00:05:23.600 --> 00:05:25.200]   But when he said that, Sonny,
[00:05:25.200 --> 00:05:27.440]   I know you had a reaction to it, right?
[00:05:27.440 --> 00:05:30.560]   Even though you know, it's not just a GPU company,
[00:05:30.560 --> 00:05:32.640]   when he really broke it down,
[00:05:32.640 --> 00:05:36.600]   it seemed like, you know, he did break new territory here.
[00:05:36.600 --> 00:05:39.680]   Yeah, like what was great to hear from him
[00:05:39.680 --> 00:05:42.120]   and really, you know, positive for, you know,
[00:05:42.120 --> 00:05:44.000]   folks thinking about where NVIDIA
[00:05:44.000 --> 00:05:45.640]   lives in the stack right now,
[00:05:45.640 --> 00:05:48.080]   is he kind of got into details
[00:05:48.080 --> 00:05:50.280]   and then the sub details below CUDA.
[00:05:50.280 --> 00:05:53.840]   And he really started going into what they're doing
[00:05:53.840 --> 00:05:56.280]   very particularly on mathematical operations
[00:05:56.280 --> 00:05:58.000]   to accelerate their partners
[00:05:58.000 --> 00:06:00.520]   and how they work really closely with their partners.
[00:06:00.520 --> 00:06:03.040]   You know, all the cloud service providers
[00:06:03.040 --> 00:06:04.560]   to basically build these functions
[00:06:04.560 --> 00:06:06.840]   so that they can further accelerate workloads.
[00:06:06.840 --> 00:06:09.320]   The other little nuance that I picked up in there,
[00:06:09.320 --> 00:06:11.760]   he didn't focus purely on LLMs.
[00:06:11.760 --> 00:06:14.080]   He talked in that particular area
[00:06:14.080 --> 00:06:15.320]   about how they're doing that
[00:06:15.320 --> 00:06:17.640]   for a lot of traditional models
[00:06:17.640 --> 00:06:20.200]   and even newer models are being deployed for AI.
[00:06:20.200 --> 00:06:22.400]   And I think just really showed
[00:06:22.400 --> 00:06:25.680]   how they're partnering much closer on the software layer
[00:06:25.680 --> 00:06:27.800]   than the hardware layer alone.
[00:06:27.800 --> 00:06:29.600]   Right, I mean, in fact, you know,
[00:06:29.600 --> 00:06:32.760]   he talked about, you know, the CUDA library
[00:06:32.760 --> 00:06:35.440]   now has over 300 industry specific
[00:06:35.440 --> 00:06:37.720]   acceleration algorithms, right?
[00:06:37.720 --> 00:06:40.520]   Where they deeply learn the industry, right?
[00:06:40.520 --> 00:06:42.480]   So whether this is synthetic biology
[00:06:42.480 --> 00:06:46.480]   or this is image generation, or this is autonomous driving,
[00:06:46.480 --> 00:06:48.520]   they learn the needs of that industry
[00:06:48.520 --> 00:06:51.080]   and then they accelerate the particular workloads.
[00:06:51.080 --> 00:06:54.760]   And that for me was also one of the key things.
[00:06:54.760 --> 00:06:57.600]   This idea that every workload
[00:06:57.600 --> 00:07:01.680]   is moving from kind of this deterministic,
[00:07:01.680 --> 00:07:04.840]   you know, handmade workload
[00:07:04.840 --> 00:07:07.840]   to something that's really driven by machine learning
[00:07:07.840 --> 00:07:09.360]   and really infused with AI
[00:07:09.360 --> 00:07:11.720]   and therefore benefits from acceleration.
[00:07:11.720 --> 00:07:15.240]   Even something as ubiquitous as data processing.
[00:07:15.240 --> 00:07:17.840]   - Yeah, and I shared this code sample with Bill
[00:07:17.840 --> 00:07:20.480]   as, you know, we were just preparing for this pod
[00:07:20.480 --> 00:07:23.840]   and, you know, I knew Bill processed it right away
[00:07:23.840 --> 00:07:25.480]   and then ran it, which was,
[00:07:25.480 --> 00:07:27.440]   it really showed like every piece of code
[00:07:27.440 --> 00:07:29.560]   that's out there now that's related to,
[00:07:29.560 --> 00:07:31.360]   or not every piece, many of the pieces
[00:07:31.360 --> 00:07:34.240]   have this like sort of, if device equals CUDA,
[00:07:34.240 --> 00:07:36.320]   do X, and if it's not, do Y.
[00:07:36.320 --> 00:07:38.280]   And that's the level of impact they're having
[00:07:38.280 --> 00:07:41.560]   across the, you know, entire ecosystem of services
[00:07:41.560 --> 00:07:43.800]   and apps that are being built that are related to AI.
[00:07:43.800 --> 00:07:44.760]   Bill, I don't know what you thought
[00:07:44.760 --> 00:07:46.880]   when you saw that piece.
[00:07:46.880 --> 00:07:51.000]   - Yeah, I mean, I think there's a question
[00:07:51.000 --> 00:07:54.360]   for the long-term that relates to CUDA.
[00:07:54.360 --> 00:07:56.880]   And I wanna go back to the system point you made later,
[00:07:56.880 --> 00:07:58.760]   Brad, but while we're on CUDA,
[00:07:58.760 --> 00:08:04.680]   is what percentage of developers will touch CUDA
[00:08:04.680 --> 00:08:07.280]   and is that number going up or down?
[00:08:07.280 --> 00:08:09.920]   And I could see arguments on both sides.
[00:08:09.920 --> 00:08:12.400]   You could say the A models are gonna get
[00:08:12.400 --> 00:08:15.880]   more and more hyper-specialized and performance matters
[00:08:15.880 --> 00:08:19.440]   so much that the one, the models that matter the most,
[00:08:19.440 --> 00:08:21.160]   the deployments that matter the most,
[00:08:21.160 --> 00:08:24.200]   they're gonna get as close to the metal as possible
[00:08:24.200 --> 00:08:26.080]   and then CUDA is gonna matter.
[00:08:26.080 --> 00:08:28.320]   The other side you can make is,
[00:08:28.320 --> 00:08:31.120]   those optimizations are gonna live in PyTorch,
[00:08:31.120 --> 00:08:33.320]   they're gonna live in other tools like that.
[00:08:33.320 --> 00:08:37.080]   And the marginal developer's not gonna need to know that.
[00:08:37.080 --> 00:08:40.000]   And I don't, I could make both arguments,
[00:08:40.000 --> 00:08:42.680]   but I think it's an interesting question going forward.
[00:08:42.680 --> 00:08:44.880]   - I mean, I just asked Chet GPT
[00:08:44.880 --> 00:08:46.360]   how many CUDA developers there are today
[00:08:46.360 --> 00:08:47.440]   just to be on top of it.
[00:08:47.440 --> 00:08:50.120]   Three million CUDA developers, right?
[00:08:50.120 --> 00:08:54.000]   And a lot more that touch CUDA that aren't specifically
[00:08:54.000 --> 00:08:55.160]   kind of developing on CUDA.
[00:08:55.160 --> 00:08:56.520]   So it is one of these things
[00:08:56.520 --> 00:08:58.640]   that has become pretty ubiquitous.
[00:08:58.640 --> 00:09:01.000]   And his point was, it's not just CUDA, of course.
[00:09:01.000 --> 00:09:05.480]   It's really full stack, all the way from data ingestion,
[00:09:05.480 --> 00:09:07.680]   all the way through kind of the post-training.
[00:09:07.680 --> 00:09:09.600]   - I think I'm on the ladder of your point, Bill.
[00:09:09.600 --> 00:09:12.240]   I think there's gonna be fewer people touching that.
[00:09:12.240 --> 00:09:14.360]   And I do think that's a point where there,
[00:09:14.360 --> 00:09:17.880]   the moat is not as strong as a longer term, as you say.
[00:09:17.880 --> 00:09:19.760]   And think about like, you know, the way,
[00:09:19.760 --> 00:09:21.800]   the analogy that I would go with is like,
[00:09:21.800 --> 00:09:23.840]   think about the number of iPhone, iOS,
[00:09:23.840 --> 00:09:26.240]   like developers working at Apple building that
[00:09:26.240 --> 00:09:28.200]   versus the number of app developers, right?
[00:09:28.200 --> 00:09:30.280]   And I think you're gonna have a, you know,
[00:09:30.280 --> 00:09:32.640]   10 to one or a hundred to one ratio of people
[00:09:32.640 --> 00:09:34.480]   building at layers above
[00:09:34.480 --> 00:09:36.920]   versus people building down closer to the bare metal.
[00:09:36.920 --> 00:09:38.000]   - That'd be something to watch.
[00:09:38.000 --> 00:09:40.520]   We can ask more people over time.
[00:09:40.520 --> 00:09:43.240]   Obviously it's a big lock today, for sure.
[00:09:43.240 --> 00:09:44.840]   - You know, and I think, Bill, to your point,
[00:09:44.840 --> 00:09:46.720]   you know, I reached out to Gavin.
[00:09:46.720 --> 00:09:48.280]   Actually, before I did the interview,
[00:09:48.280 --> 00:09:50.120]   Gavin Baker, who's a good buddy
[00:09:50.120 --> 00:09:52.480]   and who obviously knows the space incredibly well,
[00:09:52.480 --> 00:09:55.160]   has followed it at a deeper level
[00:09:55.160 --> 00:09:57.640]   for a longer period of time than I have.
[00:09:57.640 --> 00:09:59.960]   And, you know, like when I asked him
[00:09:59.960 --> 00:10:02.280]   about the competitive advantage,
[00:10:02.280 --> 00:10:04.800]   he really said a lot of the competitive advantages
[00:10:04.800 --> 00:10:06.680]   around this algorithmic diversity
[00:10:06.680 --> 00:10:09.640]   and innovation and why CUDA matters.
[00:10:09.640 --> 00:10:11.760]   He said, if the world standardizes
[00:10:11.760 --> 00:10:14.480]   on transformers on PyTorch,
[00:10:14.480 --> 00:10:18.640]   then it's less relevant for GPUs, you know,
[00:10:18.640 --> 00:10:19.480]   in that environment.
[00:10:19.480 --> 00:10:22.000]   Like if you have a lot of standardization, right,
[00:10:22.000 --> 00:10:25.960]   then advantage goes to the custom ASICs.
[00:10:25.960 --> 00:10:27.400]   But I'll tell you this, you know,
[00:10:27.400 --> 00:10:29.960]   and I've had this conversation with a lot of people.
[00:10:29.960 --> 00:10:33.080]   When I asked Jensen, I pushed him on, you know, custom ASICs.
[00:10:33.080 --> 00:10:35.280]   I was like, hey, you know, you've got, you know,
[00:10:35.280 --> 00:10:37.240]   accelerated inference coming from Meta
[00:10:37.240 --> 00:10:38.480]   with their MTIA chip.
[00:10:38.480 --> 00:10:40.480]   You know, you've got Inferentia and Tranium,
[00:10:40.480 --> 00:10:41.320]   you know, coming.
[00:10:41.320 --> 00:10:43.880]   He's like, yeah, Brad, like they're, you know,
[00:10:43.880 --> 00:10:44.960]   they're my biggest partners.
[00:10:44.960 --> 00:10:47.640]   I actually share my three to five-year roadmap with them.
[00:10:47.640 --> 00:10:50.320]   Yes, they're going to have these point solutions
[00:10:50.320 --> 00:10:52.880]   that are going to do these very specific tasks.
[00:10:52.880 --> 00:10:54.280]   But at the end of the day,
[00:10:54.280 --> 00:10:56.840]   the vast majority of the workloads in the world
[00:10:56.840 --> 00:10:59.000]   that are machine learning and AI infused
[00:10:59.000 --> 00:11:00.360]   are gonna run on NVIDIA.
[00:11:00.360 --> 00:11:01.840]   And the more people I talk to,
[00:11:01.840 --> 00:11:04.280]   the more I'm convinced that that's the case,
[00:11:04.280 --> 00:11:06.800]   despite the fact that there'll be a lot of other winners,
[00:11:06.800 --> 00:11:09.320]   including Grok and Cerebrus, et cetera.
[00:11:09.320 --> 00:11:11.200]   And they're acquiring companies.
[00:11:11.200 --> 00:11:12.360]   They're moving up the stack.
[00:11:12.360 --> 00:11:15.600]   They're trying to do more optimization at higher levels.
[00:11:15.600 --> 00:11:19.360]   So they want to extend, obviously, what CUDA is doing.
[00:11:19.360 --> 00:11:20.480]   Don't go to inference yet.
[00:11:20.480 --> 00:11:22.680]   That's a whole nother story.
[00:11:22.680 --> 00:11:25.480]   I'm actually on that bit about the deep integrations.
[00:11:25.480 --> 00:11:26.320]   Yes.
[00:11:26.320 --> 00:11:28.840]   Because, you know, really that's a playbook
[00:11:28.840 --> 00:11:32.400]   that I think Microsoft really had done well
[00:11:32.400 --> 00:11:34.440]   for a long time in enterprise software.
[00:11:34.440 --> 00:11:37.120]   And you really haven't seen that in hardware ever.
[00:11:37.120 --> 00:11:40.320]   You know, if you go back to say Cisco or the PC era,
[00:11:40.320 --> 00:11:41.320]   or, you know, the cloud era,
[00:11:41.320 --> 00:11:42.880]   you didn't see that deep level integration.
[00:11:42.880 --> 00:11:44.960]   Now, Microsoft pulled it off with Azure.
[00:11:44.960 --> 00:11:46.360]   And when I heard him talking,
[00:11:46.360 --> 00:11:49.880]   all I could think about was, man, that was really smart.
[00:11:49.880 --> 00:11:51.800]   What he's done is he's gotten together,
[00:11:51.800 --> 00:11:53.960]   really understand what the use cases are,
[00:11:53.960 --> 00:11:55.360]   and build an organization
[00:11:55.360 --> 00:11:58.080]   that deeply integrates into his customers,
[00:11:58.080 --> 00:12:00.920]   and does it so well all the way up into his roadmap
[00:12:00.920 --> 00:12:04.920]   that he's much more deeply embedded than anyone else is.
[00:12:04.920 --> 00:12:06.280]   When I heard that part,
[00:12:06.280 --> 00:12:08.760]   I kind of gave him a real tip of the hat on that one.
[00:12:08.760 --> 00:12:12.040]   But what did you, you know, Brad, what was your take on that?
[00:12:12.040 --> 00:12:13.840]   You and I had this conversation
[00:12:13.840 --> 00:12:15.760]   after we first listened to it.
[00:12:15.760 --> 00:12:19.200]   And, you know, if you really telescope out,
[00:12:19.200 --> 00:12:23.200]   you know, he talks as a systems level engineer, right?
[00:12:23.200 --> 00:12:25.360]   Even if you hear like people, you know,
[00:12:25.360 --> 00:12:26.760]   people went to Harvard Business School and say,
[00:12:26.760 --> 00:12:30.040]   how can this guy possibly have 60 direct reports, right?
[00:12:30.040 --> 00:12:32.760]   But how many direct reports does Elon have, right?
[00:12:32.760 --> 00:12:34.720]   These systems level, and he said,
[00:12:34.720 --> 00:12:37.960]   I have situational awareness, right?
[00:12:37.960 --> 00:12:41.080]   I'm a prompt engineer to the best people in the world
[00:12:41.080 --> 00:12:42.560]   at these specific tasks.
[00:12:42.560 --> 00:12:44.120]   I think when I look at this,
[00:12:44.120 --> 00:12:46.320]   the thing that I deeply underappreciated
[00:12:46.320 --> 00:12:48.400]   a year and a half ago about this company
[00:12:48.400 --> 00:12:51.440]   was the systems level thinking, right?
[00:12:51.440 --> 00:12:54.640]   That these are, that he spent years thinking about
[00:12:54.640 --> 00:12:56.840]   how to embed this competitive advantage,
[00:12:56.840 --> 00:12:59.920]   and how it really, it goes all the way from power,
[00:12:59.920 --> 00:13:01.800]   all the way through application.
[00:13:01.800 --> 00:13:04.120]   And every day they're launching these new things
[00:13:04.120 --> 00:13:06.160]   to further embed themselves in the ecosystem.
[00:13:06.160 --> 00:13:09.880]   But I did hear from somebody over the last two days who,
[00:13:09.880 --> 00:13:13.320]   you know, Rene Haas, the CEO of Arm, right?
[00:13:13.320 --> 00:13:17.800]   Rene was also at our event and he's a huge Jensen fan.
[00:13:17.800 --> 00:13:20.040]   He worked eight years at NVIDIA
[00:13:20.040 --> 00:13:23.000]   before becoming the CEO of Arm in 2013.
[00:13:23.000 --> 00:13:25.440]   And he said, listen, nobody is going to assault
[00:13:25.440 --> 00:13:27.840]   the NVIDIA castle head on, right?
[00:13:27.840 --> 00:13:30.880]   Like the mainframe of AI, right?
[00:13:30.880 --> 00:13:33.720]   Is entrenched and it's going to become a lot bigger,
[00:13:33.720 --> 00:13:36.760]   at least as far as the eye can see.
[00:13:36.760 --> 00:13:39.560]   He said, however, if you think about
[00:13:39.560 --> 00:13:43.440]   where we're interacting with AI today, right?
[00:13:43.440 --> 00:13:46.360]   On these devices, on edge devices.
[00:13:46.360 --> 00:13:48.360]   He's like, our installed base at Arm
[00:13:48.360 --> 00:13:52.160]   is 300 billion devices.
[00:13:52.160 --> 00:13:56.240]   And increasingly a lot more of this compute
[00:13:56.240 --> 00:13:58.920]   can run closer to the edge.
[00:13:58.920 --> 00:14:03.400]   If you think about an orthogonal competitor, right?
[00:14:03.400 --> 00:14:06.360]   Again, if he has a deep competitive moat in the cloud,
[00:14:06.360 --> 00:14:07.640]   what's the orthogonal competitor?
[00:14:07.640 --> 00:14:09.960]   The orthogonal competitor peels off
[00:14:09.960 --> 00:14:11.400]   a lot of the AI on the edge.
[00:14:11.400 --> 00:14:14.280]   And I think Arm's incredibly well positioned to do that.
[00:14:14.280 --> 00:14:17.000]   Clearly NVIDIA has got Arm embedded now
[00:14:17.000 --> 00:14:19.080]   in a lot of their, you know,
[00:14:19.080 --> 00:14:22.040]   in a lot of their Grace Blackwell, et cetera.
[00:14:22.040 --> 00:14:23.680]   But that to me would be one area.
[00:14:23.680 --> 00:14:24.920]   Like if you looked out and you said,
[00:14:24.920 --> 00:14:27.240]   where can their competitive advantage,
[00:14:27.240 --> 00:14:28.560]   you know, be challenged a little bit?
[00:14:28.560 --> 00:14:30.320]   I don't think they necessarily have
[00:14:30.320 --> 00:14:32.680]   the same level of advantage on the edge
[00:14:32.680 --> 00:14:34.960]   as they have in the cloud.
[00:14:34.960 --> 00:14:37.320]   - You started the pod by saying, you know,
[00:14:37.320 --> 00:14:39.320]   everyone's heard this in the investment community.
[00:14:39.320 --> 00:14:41.600]   It's not a GPU company, it's a systems company.
[00:14:41.600 --> 00:14:45.120]   And I, in my brain, I think had thought,
[00:14:45.120 --> 00:14:46.960]   oh, well, they've got four in a box
[00:14:46.960 --> 00:14:50.720]   instead of, you know, just one GPU or eight in a box.
[00:14:50.720 --> 00:14:53.000]   At the time I was listening to the podcast
[00:14:53.000 --> 00:14:55.440]   you did with Jensen, I was reading this
[00:14:55.440 --> 00:14:59.400]   Neo cloud playbook and anatomy post by Dylan Patel.
[00:14:59.400 --> 00:15:00.840]   - Yes, that was a good one.
[00:15:00.840 --> 00:15:05.840]   - He goes into extreme detail about the architecture
[00:15:05.840 --> 00:15:08.640]   of some of the larger systems, you know,
[00:15:08.640 --> 00:15:11.920]   like the one that X.AI that we're going to talk about
[00:15:11.920 --> 00:15:15.440]   that was just deployed, which I think is 100,000 nodes
[00:15:15.440 --> 00:15:16.880]   or something like that.
[00:15:16.880 --> 00:15:20.000]   And it literally changed my opinion
[00:15:20.000 --> 00:15:21.960]   of exactly what's going on in the world.
[00:15:21.960 --> 00:15:25.040]   And actually answered a lot of questions I had,
[00:15:25.040 --> 00:15:29.920]   but it appears to me that NVIDIA's competitive advantage
[00:15:29.920 --> 00:15:34.880]   is strongest where the size of the system is largest,
[00:15:34.880 --> 00:15:37.040]   which is another way of saying what Renee said,
[00:15:37.040 --> 00:15:38.680]   it's flipping it on its head.
[00:15:38.680 --> 00:15:42.080]   It's not to say it's weak on the edge,
[00:15:42.080 --> 00:15:44.000]   but it's super powerful
[00:15:44.000 --> 00:15:45.920]   when you put a whole bunch of them together.
[00:15:45.920 --> 00:15:48.440]   That's when the networking piece thrives.
[00:15:48.440 --> 00:15:50.200]   That's where NVLink thrives.
[00:15:50.200 --> 00:15:52.600]   That's where CUDA really comes alive
[00:15:52.600 --> 00:15:54.920]   in the biggest systems that are out there.
[00:15:54.920 --> 00:15:58.800]   And some of the questions that answered for me was,
[00:15:58.800 --> 00:16:02.400]   one, why is demand so high at the high end
[00:16:02.400 --> 00:16:05.560]   and why are nodes available on the internet,
[00:16:05.560 --> 00:16:07.560]   you know, single nodes available on the internet
[00:16:07.560 --> 00:16:09.360]   for at or below cost?
[00:16:09.360 --> 00:16:10.720]   And this starts to get at that,
[00:16:10.720 --> 00:16:13.560]   'cause you can do things with the large systems
[00:16:13.560 --> 00:16:16.320]   that you just can't do with a single node.
[00:16:16.320 --> 00:16:19.520]   And so those two things can be simultaneously true.
[00:16:19.520 --> 00:16:23.480]   Why was NVIDIA so interested in CoreWeave existing?
[00:16:23.480 --> 00:16:27.320]   Now, I understand like if the biggest systems
[00:16:27.320 --> 00:16:29.640]   are where the biggest competitive advantage is,
[00:16:29.640 --> 00:16:32.160]   you need as many of these big system companies
[00:16:32.160 --> 00:16:33.880]   as you can possibly have.
[00:16:33.880 --> 00:16:38.880]   And there may be, if that trajectory remains true,
[00:16:38.880 --> 00:16:40.560]   you could have an evolution
[00:16:40.560 --> 00:16:45.160]   where customer concentration increases for NVIDIA over time
[00:16:45.160 --> 00:16:46.880]   rather than going the other way.
[00:16:46.880 --> 00:16:48.080]   Depending on how, you know,
[00:16:48.080 --> 00:16:51.520]   if Sam's right that they're gonna spend a hundred billion
[00:16:51.520 --> 00:16:52.800]   or whatever on a single model,
[00:16:52.800 --> 00:16:54.080]   there's only so many places
[00:16:54.080 --> 00:16:56.720]   they're gonna be able to afford that.
[00:16:56.720 --> 00:16:59.200]   But a lot of stuff started to make sense to me
[00:16:59.200 --> 00:17:00.360]   that didn't before.
[00:17:00.360 --> 00:17:04.240]   And I clearly underestimated the scale
[00:17:04.240 --> 00:17:06.800]   of what it meant to be a non-GPU company,
[00:17:06.800 --> 00:17:08.200]   to be a system company.
[00:17:08.200 --> 00:17:11.080]   This goes way, way up.
[00:17:11.080 --> 00:17:13.600]   - Yeah, and you know, again, Bill,
[00:17:13.600 --> 00:17:15.160]   you touched on something that I think
[00:17:15.160 --> 00:17:17.280]   is really important here.
[00:17:17.280 --> 00:17:21.640]   And this is this question of whether their competitive mode
[00:17:21.640 --> 00:17:25.760]   is also as powerful in training as it is in inference, right?
[00:17:25.760 --> 00:17:29.720]   Because I think that there's a lot of doubt
[00:17:29.720 --> 00:17:31.400]   as to whether their competitive mode
[00:17:31.400 --> 00:17:32.520]   is as strong as inference.
[00:17:32.520 --> 00:17:35.160]   But, you know, let's just-
[00:17:35.160 --> 00:17:36.680]   - You wanna flip to that?
[00:17:36.680 --> 00:17:40.560]   - Well, no, but I asked him if it was as strong.
[00:17:40.560 --> 00:17:41.560]   - No, I heard you.
[00:17:41.560 --> 00:17:44.840]   - He actually said it was greater, right?
[00:17:44.840 --> 00:17:45.680]   - I heard him.
[00:17:45.680 --> 00:17:48.840]   - To me, you know, when you think about that,
[00:17:48.840 --> 00:17:51.000]   in the first instance, right,
[00:17:51.000 --> 00:17:52.800]   I think it didn't make a lot of sense.
[00:17:52.800 --> 00:17:54.520]   But then when you really started thinking about it,
[00:17:54.520 --> 00:17:55.840]   he said there's a trail of infra
[00:17:55.840 --> 00:17:58.240]   behind the infrastructure that's already out there
[00:17:58.240 --> 00:18:01.360]   that is CUDA compatible and can be amortized
[00:18:01.360 --> 00:18:02.440]   for all this inference.
[00:18:02.440 --> 00:18:04.520]   And so he, like for example,
[00:18:04.520 --> 00:18:07.320]   referenced that OpenAI had just decommissioned Volta.
[00:18:07.320 --> 00:18:10.080]   So it's like this massive installed base.
[00:18:10.080 --> 00:18:11.920]   And when they improve their algorithms,
[00:18:11.920 --> 00:18:13.280]   when they improve their frameworks,
[00:18:13.280 --> 00:18:15.720]   when they improve their CUDA libraries,
[00:18:15.720 --> 00:18:17.840]   it's all backward compatible.
[00:18:17.840 --> 00:18:20.040]   So Hopper gets better and Ampere gets better
[00:18:20.040 --> 00:18:21.520]   and Volta gets better.
[00:18:21.520 --> 00:18:23.760]   That combined with the fact that he said
[00:18:23.760 --> 00:18:25.120]   everything in the world today
[00:18:25.120 --> 00:18:27.960]   is becoming highly machine learned, right?
[00:18:27.960 --> 00:18:29.080]   Almost everything that we do,
[00:18:29.080 --> 00:18:30.880]   he said almost every single application,
[00:18:30.880 --> 00:18:33.720]   Word, Excel, PowerPoint, Photoshop, AutoCAD,
[00:18:33.720 --> 00:18:38.720]   like it all will run on these modern systems.
[00:18:38.720 --> 00:18:40.840]   Sonny, do you buy that?
[00:18:40.840 --> 00:18:43.880]   Do you buy that, you know, when people go to replace,
[00:18:43.880 --> 00:18:44.720]   you know, compute,
[00:18:44.720 --> 00:18:46.840]   they're gonna replace it on these modern systems?
[00:18:46.840 --> 00:18:49.920]   So when I was listening to it, I was buying it.
[00:18:49.920 --> 00:18:51.920]   But then when I, he said one thing
[00:18:51.920 --> 00:18:53.280]   that kept resonating in my mind,
[00:18:53.280 --> 00:18:55.960]   which he said inference is going to be
[00:18:55.960 --> 00:18:59.160]   a billion times larger than training.
[00:18:59.160 --> 00:19:01.920]   And if you kind of double click into that,
[00:19:01.920 --> 00:19:05.360]   these old systems aren't gonna be sufficient enough, right?
[00:19:05.360 --> 00:19:07.200]   If you're gonna have that much more demand,
[00:19:07.200 --> 00:19:10.000]   that much more workload, which I think we all agree,
[00:19:10.000 --> 00:19:12.920]   then how is it that these old systems,
[00:19:12.920 --> 00:19:14.680]   which are being decommissioned from training
[00:19:14.680 --> 00:19:15.920]   are gonna be sufficient?
[00:19:15.920 --> 00:19:18.480]   So I think that's where that argument didn't hold,
[00:19:18.480 --> 00:19:20.320]   just didn't hold strong enough for me.
[00:19:20.320 --> 00:19:22.520]   If that grows as fast as he says it is,
[00:19:22.520 --> 00:19:25.760]   as fast as, you know, you guys have seen it in their numbers,
[00:19:25.760 --> 00:19:28.520]   then it's gonna be a lot more net new
[00:19:28.520 --> 00:19:31.800]   inference related, you know, deployments.
[00:19:31.800 --> 00:19:34.680]   And there, I don't think that that argument
[00:19:34.680 --> 00:19:38.200]   holds on the transfer from older hardware to newer hardware.
[00:19:38.200 --> 00:19:42.560]   - Well, you said something pretty casually there, right?
[00:19:42.560 --> 00:19:44.320]   Let's underscore this, right?
[00:19:44.320 --> 00:19:46.960]   We were talking about the strawberry in the '01 preview,
[00:19:46.960 --> 00:19:48.440]   and he said there's a whole new vector
[00:19:48.440 --> 00:19:52.080]   of scaling intelligence, inference time reasoning, right?
[00:19:52.080 --> 00:19:53.960]   That's not gonna be single shot,
[00:19:53.960 --> 00:19:58.760]   but it's going to be lots of agent to agent interactions,
[00:19:58.760 --> 00:20:02.400]   thinking time as Noam Brown likes to say, right?
[00:20:02.400 --> 00:20:04.920]   And he said as a consequence of that,
[00:20:04.920 --> 00:20:08.440]   inference is going to 100X, 1,000X, a million X,
[00:20:08.440 --> 00:20:10.560]   maybe even a billion X.
[00:20:10.560 --> 00:20:13.160]   And that in and of itself, right,
[00:20:13.160 --> 00:20:16.560]   to me was, you know, kind of a wow moment.
[00:20:16.560 --> 00:20:19.680]   40% of their revenues are already inference.
[00:20:19.680 --> 00:20:21.840]   And I said, over time, does your inference
[00:20:21.840 --> 00:20:24.760]   become a higher percentage of your revenue mix?
[00:20:24.760 --> 00:20:26.600]   And he said, of course, right?
[00:20:26.600 --> 00:20:28.720]   But again, I think conventional wisdom
[00:20:28.720 --> 00:20:30.480]   is all around the size of clusters
[00:20:30.480 --> 00:20:31.680]   and the size of training.
[00:20:31.680 --> 00:20:33.880]   And if models don't keep getting bigger,
[00:20:33.880 --> 00:20:35.920]   then their relevance will dissipate.
[00:20:35.920 --> 00:20:39.120]   But he's basically saying every single workload
[00:20:39.120 --> 00:20:41.520]   is gonna benefit from acceleration, right?
[00:20:41.520 --> 00:20:43.360]   It's gonna be an inference workload,
[00:20:43.360 --> 00:20:45.360]   and the number of inference interactions
[00:20:45.360 --> 00:20:46.800]   is gonna explode higher.
[00:20:46.800 --> 00:20:49.400]   Yeah, one technical detail,
[00:20:49.400 --> 00:20:51.920]   which is you need bigger clusters
[00:20:51.920 --> 00:20:54.080]   if you're training bigger models.
[00:20:54.080 --> 00:20:55.640]   But if you're running bigger models,
[00:20:55.640 --> 00:20:56.760]   you don't need bigger clusters.
[00:20:56.760 --> 00:20:59.080]   It can be distributed, right?
[00:20:59.080 --> 00:21:02.200]   And so I think what we're gonna see here
[00:21:02.200 --> 00:21:05.520]   is that the larger clusters will continue to get deployed,
[00:21:05.520 --> 00:21:07.640]   and as Bill said, they'll get deployed for folks,
[00:21:07.640 --> 00:21:09.800]   maybe a limited number of folks that need to deploy it
[00:21:09.800 --> 00:21:11.680]   for a hundred billion dollar runs
[00:21:11.680 --> 00:21:12.960]   or even bigger than that.
[00:21:12.960 --> 00:21:16.760]   But you'll see inference clusters be large,
[00:21:16.760 --> 00:21:18.400]   but not as large as a training clusters
[00:21:18.400 --> 00:21:19.880]   and be a lot more distributed
[00:21:19.880 --> 00:21:22.080]   because you don't need it to be all in the same place.
[00:21:22.080 --> 00:21:24.200]   And I think that's what'll be really interesting.
[00:21:24.200 --> 00:21:25.200]   It was interesting.
[00:21:25.200 --> 00:21:28.840]   He simplified it even more than you did there, Brad.
[00:21:28.840 --> 00:21:30.960]   He said, think about a human.
[00:21:30.960 --> 00:21:34.440]   How much time do you spend learning versus doing?
[00:21:34.440 --> 00:21:37.360]   And he used that analogy as to why
[00:21:37.360 --> 00:21:38.640]   this was gonna be so great.
[00:21:38.640 --> 00:21:43.240]   But I, in a little different way than Sonny,
[00:21:43.240 --> 00:21:45.080]   I thought the argument
[00:21:45.080 --> 00:21:47.080]   that the reason we're gonna be great at inference
[00:21:47.080 --> 00:21:50.200]   is 'cause there's so much of our old stuff laying around
[00:21:50.200 --> 00:21:52.120]   wasn't super solid.
[00:21:52.120 --> 00:21:56.640]   In other words, what if some other company,
[00:21:56.680 --> 00:22:01.680]   Sonny's or some other one decided to optimize inference?
[00:22:01.680 --> 00:22:04.160]   It wasn't an argument for optimization.
[00:22:04.160 --> 00:22:07.400]   It was an argument for cost advantage
[00:22:07.400 --> 00:22:10.240]   because it might be fully distributed or whatever.
[00:22:10.240 --> 00:22:14.000]   And of course, if you had maybe poked him back on that,
[00:22:14.000 --> 00:22:18.440]   he might've had another answer about why for optimization,
[00:22:18.440 --> 00:22:21.280]   but there are clearly gonna be people,
[00:22:21.280 --> 00:22:24.760]   whether it's other chips companies,
[00:22:24.760 --> 00:22:26.600]   some of these accelerator companies,
[00:22:26.600 --> 00:22:30.000]   there are gonna be people working on inference optimization,
[00:22:30.000 --> 00:22:31.560]   which may include edge techniques.
[00:22:31.560 --> 00:22:36.080]   I think some of the accelerators may look like AI CDNs,
[00:22:36.080 --> 00:22:37.800]   if you will, and they're gonna be buying stuff
[00:22:37.800 --> 00:22:39.120]   closer to the customer.
[00:22:39.120 --> 00:22:42.960]   So all TBD, but just the argument
[00:22:42.960 --> 00:22:46.480]   that you've got it left over didn't seem super solid to me.
[00:22:46.480 --> 00:22:49.240]   - And the three fastest companies in inference right now
[00:22:49.240 --> 00:22:50.240]   are not NVIDIA.
[00:22:50.240 --> 00:22:52.760]   - Right, so who are they, Sonny?
[00:22:52.760 --> 00:22:54.880]   Show it, we'll post the leaderboard.
[00:22:54.880 --> 00:22:57.520]   - Yeah, it's a combination of Grok,
[00:22:57.520 --> 00:22:59.680]   Cerebris, and SambaNova, right?
[00:22:59.680 --> 00:23:02.040]   Those are three companies that are not NVIDIA
[00:23:02.040 --> 00:23:05.400]   that are on the leaderboards of all the models that they run.
[00:23:05.400 --> 00:23:06.640]   - You're talking about performance.
[00:23:06.640 --> 00:23:07.480]   Performance is what you're talking about.
[00:23:07.480 --> 00:23:09.040]   - Performance, yeah. - Yeah.
[00:23:09.040 --> 00:23:11.600]   - Yeah, and I would argue even price.
[00:23:11.600 --> 00:23:12.440]   - Yeah.
[00:23:12.440 --> 00:23:15.480]   - And make the argument, why are they faster?
[00:23:15.480 --> 00:23:18.240]   Why are they cheaper in your mind?
[00:23:18.240 --> 00:23:20.840]   But yet, notwithstanding that fact,
[00:23:20.840 --> 00:23:22.680]   NVIDIA is gonna do, let's call it,
[00:23:22.680 --> 00:23:25.520]   50 or 60 billion of inference this year,
[00:23:25.520 --> 00:23:29.400]   and these companies are still just getting started, right?
[00:23:29.400 --> 00:23:30.840]   Why is their inference business?
[00:23:30.840 --> 00:23:33.400]   Is it just because of installed base?
[00:23:33.400 --> 00:23:35.560]   - Yeah, I think it's a combination of installed base,
[00:23:35.560 --> 00:23:37.560]   and I think it's because that inference market
[00:23:37.560 --> 00:23:39.280]   is growing so incredibly fast.
[00:23:39.280 --> 00:23:42.840]   I think if you're making this decision even 18 months ago,
[00:23:42.840 --> 00:23:44.520]   it would be a really difficult decision
[00:23:44.520 --> 00:23:46.200]   to buy any of those three companies,
[00:23:46.200 --> 00:23:48.280]   because your primary workload was training,
[00:23:48.280 --> 00:23:50.000]   and the first part of this pod,
[00:23:50.000 --> 00:23:53.440]   we talked about how they have such a strong tie-in,
[00:23:53.440 --> 00:23:55.880]   integration to getting training done properly.
[00:23:55.880 --> 00:23:57.040]   I think when it comes to inference,
[00:23:57.040 --> 00:23:59.640]   you can see all the non-NVIDIA folks
[00:23:59.640 --> 00:24:01.320]   can get the models up and running right away.
[00:24:01.320 --> 00:24:04.840]   There is no tie-in to CUDA that's required to go faster,
[00:24:04.840 --> 00:24:06.920]   that's required to get the models running, right?
[00:24:06.920 --> 00:24:09.480]   Obviously, none of the three companies run CUDA,
[00:24:09.480 --> 00:24:12.760]   and so that moat doesn't exist around inference.
[00:24:12.760 --> 00:24:15.280]   - Yeah, CUDA's less relevant in inference.
[00:24:15.280 --> 00:24:18.080]   That's another point worth making.
[00:24:18.080 --> 00:24:19.640]   But I wanted to say one other thing
[00:24:19.640 --> 00:24:20.720]   to what Sonny just said.
[00:24:20.720 --> 00:24:24.240]   If you go back to the early internet days,
[00:24:24.240 --> 00:24:25.800]   and this is just an argument
[00:24:25.800 --> 00:24:28.280]   that optimization takes a while,
[00:24:28.280 --> 00:24:32.880]   all of the startups were running on Oracle and Sun.
[00:24:32.880 --> 00:24:34.320]   Every single (beep) one of them
[00:24:34.320 --> 00:24:35.960]   were running on Oracle and Sun,
[00:24:35.960 --> 00:24:38.560]   and five years later, they were all running on Linux
[00:24:38.560 --> 00:24:41.600]   and MySQL, like in five years.
[00:24:41.600 --> 00:24:43.480]   And so, and it was literally,
[00:24:43.480 --> 00:24:47.080]   it went from 100% to 3%,
[00:24:47.080 --> 00:24:50.040]   and I'm not making that projection
[00:24:50.040 --> 00:24:51.120]   that that's gonna happen here,
[00:24:51.120 --> 00:24:56.120]   but you did have a wholesale shift as the industry,
[00:24:56.120 --> 00:24:59.400]   they went from developing and building it
[00:24:59.400 --> 00:25:01.320]   for the first time to optimizing,
[00:25:01.320 --> 00:25:03.720]   which are really two separate motions.
[00:25:03.720 --> 00:25:06.000]   - It seems to me, I pulled up this chart, right,
[00:25:06.000 --> 00:25:08.040]   that we shared, we made, Bill,
[00:25:08.040 --> 00:25:10.160]   way earlier this year for the pod,
[00:25:10.160 --> 00:25:14.720]   which showed the trillion dollars of new AI workloads
[00:25:14.720 --> 00:25:16.960]   expected over the next four to five years,
[00:25:16.960 --> 00:25:18.360]   and the trillion dollars
[00:25:18.360 --> 00:25:21.240]   of effectively data center replacement.
[00:25:21.240 --> 00:25:23.240]   And I just wanted to get his updated
[00:25:23.240 --> 00:25:24.800]   kind of reaction or forecast,
[00:25:24.800 --> 00:25:28.320]   now that he's had six more months to think about
[00:25:28.320 --> 00:25:31.720]   whether or not he thinks that's achievable.
[00:25:31.720 --> 00:25:33.760]   And what I heard him say was,
[00:25:33.760 --> 00:25:35.520]   "Yes, the data center replacement's
[00:25:35.520 --> 00:25:37.720]   gonna look exactly like that."
[00:25:37.720 --> 00:25:41.520]   Of course, he's just making his best educated guess,
[00:25:41.520 --> 00:25:42.640]   but he seemed to suggest
[00:25:42.640 --> 00:25:45.400]   that the AI workloads could be even bigger, right?
[00:25:45.400 --> 00:25:48.480]   Like that once he saw Strawberry in '01,
[00:25:48.480 --> 00:25:51.120]   that he thought the amount of compute
[00:25:51.120 --> 00:25:53.120]   that was gonna be required to power this,
[00:25:53.120 --> 00:25:54.960]   and the more people I talk to,
[00:25:54.960 --> 00:25:57.920]   the more I get that same sense,
[00:25:57.920 --> 00:25:59.720]   there is this insatiable demand.
[00:25:59.720 --> 00:26:01.800]   So maybe we just touch on this.
[00:26:01.800 --> 00:26:06.800]   He goes on CNBC and he says, "The demand is insane," right?
[00:26:06.800 --> 00:26:08.640]   And I kept trying to push on that.
[00:26:08.640 --> 00:26:11.600]   I was like, "Yeah, but what about MTIA?
[00:26:11.600 --> 00:26:13.880]   What about custom inference?
[00:26:13.880 --> 00:26:16.200]   What about all these other factors?
[00:26:16.200 --> 00:26:19.040]   What if models stop getting so big?"
[00:26:19.040 --> 00:26:21.920]   I said, "Will any of that change the equation?"
[00:26:21.920 --> 00:26:25.360]   And he consistently pushed back and said,
[00:26:25.360 --> 00:26:27.840]   "You still don't understand the amount of demand
[00:26:27.840 --> 00:26:32.800]   in the world because all compute is changing," right?
[00:26:32.800 --> 00:26:35.400]   I thought he had one nuance, that answer,
[00:26:35.400 --> 00:26:38.480]   which was when you asked him that, he said,
[00:26:38.480 --> 00:26:40.920]   "Look, if you have to replace
[00:26:40.920 --> 00:26:42.680]   some amount of infrastructure,"
[00:26:42.680 --> 00:26:44.240]   whatever the number was, was really big,
[00:26:44.240 --> 00:26:46.280]   "and you're part of that,
[00:26:46.280 --> 00:26:50.280]   and you're a CIO somewhere tasked with doing this,
[00:26:50.280 --> 00:26:51.320]   what are you gonna do?
[00:26:51.320 --> 00:26:52.360]   What are you gonna replace it with?
[00:26:52.360 --> 00:26:53.880]   It's accelerated compute."
[00:26:53.880 --> 00:26:56.920]   And then immediately, once you make that choice,
[00:26:56.920 --> 00:26:58.920]   'cause you're not going to traditional compute,
[00:26:58.920 --> 00:27:00.920]   then NVIDIA is your number one choice.
[00:27:00.920 --> 00:27:02.920]   So I thought he kind of tied that back together
[00:27:02.920 --> 00:27:06.120]   in that like, are you really gonna get yourself in trouble
[00:27:06.120 --> 00:27:07.440]   by having something else there,
[00:27:07.440 --> 00:27:09.160]   or are you just gonna go to NVIDIA?
[00:27:09.160 --> 00:27:12.600]   When he said it, I didn't wanna say that, Bill,
[00:27:12.600 --> 00:27:14.520]   but it felt like the old IBM argument.
[00:27:14.520 --> 00:27:16.560]   Yeah, look, I mean, one thing, Brad,
[00:27:16.560 --> 00:27:18.040]   is this company's public.
[00:27:18.040 --> 00:27:21.200]   When a private company says, "Oh, the demand's insane,"
[00:27:21.200 --> 00:27:23.600]   you know, I immediately get skeptical.
[00:27:23.600 --> 00:27:26.040]   This company's doing 30 billion a quarter,
[00:27:26.040 --> 00:27:30.600]   growing 122%, like, the demand is insane.
[00:27:30.600 --> 00:27:33.040]   Like, we can see it.
[00:27:33.040 --> 00:27:34.600]   There's no doubt about it.
[00:27:34.600 --> 00:27:38.520]   And part of that demand was a conversation
[00:27:38.520 --> 00:27:42.760]   about Elon and x.ai and what they did.
[00:27:42.760 --> 00:27:46.400]   And I thought it was also just incredibly fascinating, right?
[00:27:46.400 --> 00:27:47.360]   I thought it was funny.
[00:27:47.360 --> 00:27:48.760]   I asked him a question about the dinner
[00:27:48.760 --> 00:27:51.760]   that he and Elon and Larry Ellison apparently had.
[00:27:51.760 --> 00:27:55.080]   And he's like, you know, just because that dinner occurred
[00:27:55.080 --> 00:27:57.560]   and they ended up with 100,000 H100s,
[00:27:57.560 --> 00:28:01.040]   don't necessarily connect the dots.
[00:28:01.040 --> 00:28:06.040]   But listen, he confirmed that his mind was blown by Elon.
[00:28:07.720 --> 00:28:11.360]   And he said he is an N of one superhuman
[00:28:11.360 --> 00:28:13.240]   that could possibly pull off,
[00:28:13.240 --> 00:28:15.320]   that could energize a data center,
[00:28:15.320 --> 00:28:17.560]   that could liquid cool a data center.
[00:28:17.560 --> 00:28:21.120]   And he said, what would take somebody else years
[00:28:21.120 --> 00:28:23.040]   to get permitted, to get energized,
[00:28:23.040 --> 00:28:25.040]   to get liquid cooled, to get stood up,
[00:28:25.040 --> 00:28:29.400]   that x.ai did in 19 days, you know?
[00:28:29.400 --> 00:28:32.520]   And you could just tell the immense respect
[00:28:32.520 --> 00:28:34.280]   that he had for Elon.
[00:28:34.280 --> 00:28:35.840]   It's clear, you know,
[00:28:35.840 --> 00:28:38.840]   he said it's the single largest coherent supercomputer
[00:28:38.840 --> 00:28:42.160]   in the world today, that it's gonna get bigger.
[00:28:42.160 --> 00:28:44.360]   And if you believe that the future of AI
[00:28:44.360 --> 00:28:48.280]   is tied closely together with the systems engineering
[00:28:48.280 --> 00:28:50.320]   on the hardware side, you know,
[00:28:50.320 --> 00:28:53.000]   what hit me in that moment was,
[00:28:53.000 --> 00:28:56.040]   that's a huge, huge advantage for Elon.
[00:28:56.040 --> 00:28:58.600]   Yeah, I think he, I forgot the exact number,
[00:28:58.600 --> 00:29:01.400]   but like he talked about how many thousands of miles
[00:29:01.400 --> 00:29:03.480]   of cabling that were just in there.
[00:29:04.200 --> 00:29:05.960]   As part of the task.
[00:29:05.960 --> 00:29:10.080]   Look, you know, coming to it from a bit, you know,
[00:29:10.080 --> 00:29:11.840]   doing a lot of that ourselves right now,
[00:29:11.840 --> 00:29:14.000]   building data centers, standing them up,
[00:29:14.000 --> 00:29:17.360]   racking and stacking, you know, our nodes,
[00:29:17.360 --> 00:29:18.200]   it's impressive.
[00:29:18.200 --> 00:29:21.680]   It's impressive to do something at that scale in 19 days.
[00:29:21.680 --> 00:29:24.080]   You know, it doesn't even include
[00:29:24.080 --> 00:29:25.880]   how quickly they built that data center.
[00:29:25.880 --> 00:29:29.520]   I think it's all happened, you know, within 2024.
[00:29:29.520 --> 00:29:32.040]   And so that's part of the advantage.
[00:29:32.040 --> 00:29:35.040]   The interesting thing there is he didn't touch on it
[00:29:35.040 --> 00:29:37.200]   as much as what, when he talked about it,
[00:29:37.200 --> 00:29:39.920]   doing the integration with cloud service providers.
[00:29:39.920 --> 00:29:42.400]   What I'd love to kind of double click into is,
[00:29:42.400 --> 00:29:44.640]   because, you know, Elon is in a unique situation
[00:29:44.640 --> 00:29:46.440]   where he's obviously bought this cluster.
[00:29:46.440 --> 00:29:48.160]   He has a ton of respect for NVIDIA,
[00:29:48.160 --> 00:29:49.720]   but he, you know, is building his own chip,
[00:29:49.720 --> 00:29:51.760]   building their own clusters with Tesla.
[00:29:51.760 --> 00:29:55.000]   So I wonder how much, you know,
[00:29:55.000 --> 00:29:58.000]   cross correlation or information there is for them,
[00:29:58.000 --> 00:30:00.200]   for them to be able to do that at scale.
[00:30:00.200 --> 00:30:01.560]   And, you know, you guys look at this.
[00:30:01.560 --> 00:30:04.960]   What have you kind of seen on their clusters?
[00:30:04.960 --> 00:30:06.560]   I don't really have a lot of data
[00:30:06.560 --> 00:30:09.840]   on the non-NVIDIA clusters that they have.
[00:30:09.840 --> 00:30:11.480]   I'm sure Freedom, my team, does.
[00:30:11.480 --> 00:30:13.080]   I just don't have it off the top of my head.
[00:30:13.080 --> 00:30:15.560]   If we have it, you know, I'll pull a chart and I'll show it.
[00:30:15.560 --> 00:30:18.880]   Sonny, you said you now think the XAI cluster
[00:30:18.880 --> 00:30:21.560]   is the largest NVIDIA cluster alive today?
[00:30:21.560 --> 00:30:24.320]   I'm saying, 'cause I believe Jensen said it in the pod,
[00:30:24.320 --> 00:30:26.840]   that he said it's the largest supercomputer in the world.
[00:30:26.840 --> 00:30:30.520]   Yeah, I mean, I just want to spend 30 seconds
[00:30:30.520 --> 00:30:32.080]   on what you said, Brad, about Elon.
[00:30:32.080 --> 00:30:35.540]   I'm staring out my window at the Gigafactory in Austin
[00:30:35.540 --> 00:30:37.880]   that was also built in record time.
[00:30:37.880 --> 00:30:39.520]   Starlink's insane.
[00:30:39.520 --> 00:30:42.120]   When we were walking in Diablo, I just kept thinking,
[00:30:42.120 --> 00:30:45.040]   "You know who I'd love to reimagine this place?
[00:30:45.040 --> 00:30:46.320]   Elon," right?
[00:30:46.320 --> 00:30:49.840]   And I don't, the world should study
[00:30:49.840 --> 00:30:52.640]   how he can do infrastructure fast,
[00:30:52.640 --> 00:30:56.600]   because if that could be cloned, it would be so valuable.
[00:30:56.600 --> 00:30:59.720]   Not really relevant to this podcast, but worth noting.
[00:30:59.720 --> 00:31:03.200]   The other thing that I thought about on the Elon thing,
[00:31:03.200 --> 00:31:07.000]   and this also, where these pieces coming together,
[00:31:07.000 --> 00:31:09.520]   my mind about these large clusters
[00:31:09.520 --> 00:31:12.760]   and how important that was to NVIDIA,
[00:31:12.760 --> 00:31:14.720]   he got allocation, right?
[00:31:14.720 --> 00:31:17.920]   This is supposed to be like the hottest company,
[00:31:17.920 --> 00:31:22.920]   the hottest product backed up for years on demand.
[00:31:22.920 --> 00:31:25.560]   And he walks in and takes what equates,
[00:31:25.560 --> 00:31:30.240]   sounds, looks like about 10% of the quarter's availability.
[00:31:30.240 --> 00:31:34.680]   And in my mind, I'm thinking that's because,
[00:31:34.680 --> 00:31:36.160]   hey, if there's another company
[00:31:36.160 --> 00:31:38.280]   that's gonna develop these big ones,
[00:31:38.280 --> 00:31:40.960]   I'm gonna let him to the front of the line.
[00:31:40.960 --> 00:31:43.920]   And that speaks to what's happening in Malaysia
[00:31:43.920 --> 00:31:47.520]   and the Middle East, and any one of these people
[00:31:47.520 --> 00:31:50.680]   that are gonna get excited, he's gonna spend time with them,
[00:31:50.680 --> 00:31:52.200]   put them at the front of the line.
[00:31:52.200 --> 00:31:55.240]   You know, I'll tell you, I pushed him on this.
[00:31:55.240 --> 00:31:57.840]   I said, you know, Elon's gonna,
[00:31:57.840 --> 00:32:01.280]   you know, rumor is that he's gonna get another 100,000,
[00:32:01.280 --> 00:32:04.120]   you know, H200s, add them to this cluster.
[00:32:04.120 --> 00:32:06.280]   I said, are we already at the phase
[00:32:06.280 --> 00:32:09.520]   of two and 300,000 cluster scale?
[00:32:09.520 --> 00:32:11.000]   And he said, yes.
[00:32:11.000 --> 00:32:14.520]   And then I said, and will we go to 500,000 a million?
[00:32:14.520 --> 00:32:15.960]   And he's like, yes.
[00:32:15.960 --> 00:32:18.400]   Now, I think these things, Bill,
[00:32:18.400 --> 00:32:20.960]   are already being planned and built.
[00:32:20.960 --> 00:32:24.400]   And what he said is beyond that, beyond that,
[00:32:24.400 --> 00:32:25.960]   he said, you start bumping up
[00:32:25.960 --> 00:32:28.920]   against the limitations of base power.
[00:32:28.920 --> 00:32:32.120]   Like, can you find something that can be energized
[00:32:32.120 --> 00:32:34.000]   to power a single cluster?
[00:32:34.000 --> 00:32:35.120]   And he said, we're gonna have
[00:32:35.120 --> 00:32:38.400]   to develop distributed training.
[00:32:38.400 --> 00:32:41.360]   And he said, but just like with Megatron
[00:32:41.360 --> 00:32:45.480]   that we developed to allow to occur what is occurring today,
[00:32:45.480 --> 00:32:48.120]   we're working on the distributed stuff
[00:32:48.120 --> 00:32:50.480]   because we know we're gonna have to decompose
[00:32:50.480 --> 00:32:52.240]   these clusters at some point
[00:32:52.240 --> 00:32:54.200]   in order to continue scaling them.
[00:32:54.200 --> 00:32:56.600]   - You may also be running up against the,
[00:32:56.600 --> 00:33:01.600]   even for the Mag 7, the size of Capo X deployment,
[00:33:01.600 --> 00:33:04.640]   where their CFOs start to talk at higher levels.
[00:33:04.640 --> 00:33:07.240]   - For sure, totally.
[00:33:07.240 --> 00:33:09.560]   - And there's a super interesting article
[00:33:09.560 --> 00:33:11.960]   in the information just now where,
[00:33:11.960 --> 00:33:15.680]   it came out today where Sam Altman is questioning
[00:33:15.680 --> 00:33:18.880]   whether Microsoft's willing to put up the money
[00:33:18.880 --> 00:33:20.120]   and build a cluster.
[00:33:20.120 --> 00:33:22.000]   And it may have been,
[00:33:22.000 --> 00:33:23.920]   that may have been kind of triggered
[00:33:23.920 --> 00:33:28.920]   by Elon's comments or Elon's willingness to do it at X.AI.
[00:33:28.920 --> 00:33:31.600]   - What I will say on like the size of the models,
[00:33:31.600 --> 00:33:34.040]   like we're gonna push into this really interesting realm
[00:33:34.040 --> 00:33:35.640]   where obviously we can have bigger
[00:33:35.640 --> 00:33:37.320]   and bigger training clusters.
[00:33:37.320 --> 00:33:39.720]   That naturally imposes that the models
[00:33:39.720 --> 00:33:40.880]   are bigger and bigger.
[00:33:40.880 --> 00:33:43.160]   But what you can't do is you can't take a single,
[00:33:43.160 --> 00:33:46.120]   like you can train a model across a distributed site
[00:33:46.120 --> 00:33:48.760]   and it may just take you a month longer
[00:33:48.760 --> 00:33:50.920]   because you have to move traffic around.
[00:33:50.920 --> 00:33:52.040]   And so instead of taking three months,
[00:33:52.040 --> 00:33:53.280]   it takes you four months.
[00:33:53.280 --> 00:33:55.920]   But you can't really run a model across a distributed site
[00:33:55.920 --> 00:33:58.680]   'cause that inferences in like real time thing.
[00:33:58.680 --> 00:34:01.440]   And so we do, we're not pushing it there,
[00:34:01.440 --> 00:34:02.640]   but when you start to get to models,
[00:34:02.640 --> 00:34:05.440]   it became way too big to run in single locations.
[00:34:05.440 --> 00:34:07.520]   That may be a problem that we wanna be aware of
[00:34:07.520 --> 00:34:10.560]   and we wanna keep in our minds as well.
[00:34:10.560 --> 00:34:15.560]   - On this question of scaling our way to intelligence.
[00:34:15.560 --> 00:34:20.040]   One of the things I asked Noam Brown today
[00:34:20.040 --> 00:34:21.960]   in our fireside chat,
[00:34:21.960 --> 00:34:24.480]   he made very clear his perspective,
[00:34:24.480 --> 00:34:26.800]   although he's working on inference time reasoning,
[00:34:26.800 --> 00:34:28.600]   which is a totally different vector
[00:34:28.600 --> 00:34:31.040]   and a breakthrough vector at OpenAI,
[00:34:31.040 --> 00:34:33.320]   which we ought to spend a little bit of time talking about.
[00:34:33.320 --> 00:34:37.240]   He said, now there are these two vectors, right?
[00:34:37.240 --> 00:34:41.400]   That again are multiplicative in terms of the path to AGI.
[00:34:41.400 --> 00:34:43.520]   He's like, make no mistake about it,
[00:34:43.520 --> 00:34:45.680]   like we're still seeing big advantages
[00:34:45.680 --> 00:34:47.400]   to scaling bigger models, right?
[00:34:47.400 --> 00:34:50.000]   We have the data, we have the synthetic data,
[00:34:50.000 --> 00:34:51.760]   we're going to build those bigger models
[00:34:51.760 --> 00:34:54.960]   and we have an economic engine that can fund it, right?
[00:34:54.960 --> 00:34:58.680]   Don't forget this company is over 4 billion in revenue,
[00:34:58.680 --> 00:35:01.680]   scaling probably most people think to 10 billion plus
[00:35:01.680 --> 00:35:04.040]   in revenue over the course of the next year.
[00:35:04.040 --> 00:35:05.560]   They just raised 6.5 billion,
[00:35:05.560 --> 00:35:08.760]   they got a $4 billion line of credit from Citigroup.
[00:35:08.760 --> 00:35:12.120]   So among the independent players, Bill, right?
[00:35:12.120 --> 00:35:13.960]   Like Microsoft can choose whether or not
[00:35:13.960 --> 00:35:14.840]   they're going to fund it,
[00:35:14.840 --> 00:35:16.560]   but I don't think it's a question of whether or not
[00:35:16.560 --> 00:35:17.920]   they're gonna have the funding.
[00:35:17.920 --> 00:35:20.120]   At this point, they've achieved escape velocity.
[00:35:20.120 --> 00:35:22.520]   I think for a lot of the other independent players,
[00:35:22.520 --> 00:35:23.520]   there's a real question
[00:35:23.520 --> 00:35:26.160]   whether they have the economic model
[00:35:26.160 --> 00:35:28.120]   to continue to fund the activity.
[00:35:28.120 --> 00:35:29.840]   So they have to find a proxy
[00:35:29.840 --> 00:35:31.600]   because I don't think a lot of venture capitalists
[00:35:31.600 --> 00:35:33.680]   are going to write multi-billion dollar checks
[00:35:33.680 --> 00:35:35.280]   into the players that haven't yet
[00:35:35.280 --> 00:35:37.600]   caught lightning in a bottle.
[00:35:37.600 --> 00:35:39.680]   That would be my guess.
[00:35:39.680 --> 00:35:43.000]   I mean, you know, I just think it's hard.
[00:35:43.000 --> 00:35:44.320]   You know, listen, at the end of the day,
[00:35:44.320 --> 00:35:48.360]   we're economic animals, you know, and I've said before,
[00:35:48.360 --> 00:35:49.960]   you know, if you look at the forward multiple,
[00:35:49.960 --> 00:35:52.040]   most of us underwrote to on open AI,
[00:35:52.040 --> 00:35:54.480]   it was about 15 times forward earnings, right?
[00:35:54.480 --> 00:35:56.440]   If Chad GPT wasn't doing what it was doing,
[00:35:56.440 --> 00:35:58.880]   if the revenue wasn't doing what it was doing, right,
[00:35:58.880 --> 00:36:01.360]   this would have meant massively dilutive to the company.
[00:36:01.360 --> 00:36:03.200]   It would have been very hard to raise the money.
[00:36:03.200 --> 00:36:05.800]   I think if Mistral or all these other companies
[00:36:05.800 --> 00:36:08.080]   want to raise that money, I think it'd be very difficult,
[00:36:08.080 --> 00:36:09.840]   but you know, you never, I mean, you know,
[00:36:09.840 --> 00:36:12.160]   there's still a lot of money out there, so it's possible,
[00:36:12.160 --> 00:36:13.880]   but I think this is, you know, you should-
[00:36:13.880 --> 00:36:16.160]   - You said 15 times earnings, I think you meant revenue.
[00:36:16.160 --> 00:36:18.760]   - Oh, 15 times revenue, for sure.
[00:36:18.760 --> 00:36:21.480]   Which I said, you know, when Google went public,
[00:36:21.480 --> 00:36:23.680]   it was about 13 or 14 times revenue
[00:36:23.680 --> 00:36:26.360]   and Meta was like 13 or 14 times revenue.
[00:36:26.360 --> 00:36:29.520]   So I do think we're on the precipice
[00:36:29.520 --> 00:36:31.760]   of a lot of this consolidation among the new entrants.
[00:36:31.760 --> 00:36:34.920]   What I think is so interesting about X is, you know,
[00:36:34.920 --> 00:36:37.680]   when I was pushing him on this model consolidation,
[00:36:37.680 --> 00:36:40.320]   pushing Jensen on it, he was like, listen,
[00:36:40.320 --> 00:36:42.800]   with Elon, you have somebody with the ambition,
[00:36:42.800 --> 00:36:45.880]   with the capability, with the know-how, with the money,
[00:36:45.880 --> 00:36:48.720]   right, with the brands, with the businesses.
[00:36:48.720 --> 00:36:52.160]   So I think a lot of times when we're talking about AI today,
[00:36:52.160 --> 00:36:54.440]   we oftentimes talk about open AI,
[00:36:54.440 --> 00:36:56.200]   but a lot of people quickly then go
[00:36:56.200 --> 00:36:58.080]   into all of the other model companies.
[00:36:58.080 --> 00:37:01.520]   I think X is often left out of the conversation.
[00:37:01.520 --> 00:37:03.840]   And one of the things I took away
[00:37:03.840 --> 00:37:07.000]   from this conversation with Jensen is, again,
[00:37:07.000 --> 00:37:09.920]   if scaling these data centers
[00:37:09.920 --> 00:37:14.920]   is a key competitive advantage to winning an AI, right,
[00:37:15.120 --> 00:37:19.800]   like you absolutely cannot count out X.AI in this battle.
[00:37:19.800 --> 00:37:21.480]   They're certainly going to have to figure out, you know,
[00:37:21.480 --> 00:37:23.920]   something with the consumer that's going to have a flywheel
[00:37:23.920 --> 00:37:26.520]   like ChatGPT or something with the enterprise.
[00:37:26.520 --> 00:37:28.000]   But in terms of standing it up,
[00:37:28.000 --> 00:37:30.000]   building the model, having the compute,
[00:37:30.000 --> 00:37:32.040]   I think they're, you know,
[00:37:32.040 --> 00:37:34.720]   going to be one of the three or four in the game.
[00:37:34.720 --> 00:37:37.960]   You touched on maybe wanting to close out
[00:37:37.960 --> 00:37:41.280]   on the strawberry-like models.
[00:37:41.280 --> 00:37:46.040]   You know, one thing we don't have exposure to,
[00:37:46.040 --> 00:37:48.360]   but we can guess at is cost.
[00:37:48.360 --> 00:37:52.240]   And that chart that they showed when they released Strawberry,
[00:37:52.240 --> 00:37:56.280]   the X-axis was logarithmic.
[00:37:56.280 --> 00:38:01.280]   So the cost of a search with the new preview model
[00:38:01.280 --> 00:38:06.160]   is probably costing them 20X or 30X
[00:38:06.160 --> 00:38:08.760]   what it does to do a normal ChatGPT search.
[00:38:09.760 --> 00:38:12.560]   - Which I think is fractions of a penny.
[00:38:12.560 --> 00:38:15.360]   - But figuring out which, and it also takes longer.
[00:38:15.360 --> 00:38:19.400]   So figuring out which problems it's acceptable,
[00:38:19.400 --> 00:38:21.760]   and Jensen gave a few examples for it,
[00:38:21.760 --> 00:38:24.120]   to take more time and cost more
[00:38:24.120 --> 00:38:28.080]   and to get the cost benefit right for that type of result
[00:38:28.080 --> 00:38:29.560]   is something we're going to have to figure out,
[00:38:29.560 --> 00:38:32.600]   like which problems tilt to that place.
[00:38:32.600 --> 00:38:33.680]   - Right, and you know,
[00:38:33.680 --> 00:38:35.360]   the one thing I feel good about there,
[00:38:35.360 --> 00:38:37.760]   and again, I'm speculating,
[00:38:37.760 --> 00:38:40.720]   I don't have information from OpenAI on this,
[00:38:40.720 --> 00:38:42.640]   but what we know is that the cost of inference
[00:38:42.640 --> 00:38:44.760]   has fallen by 90% over the course of last year.
[00:38:44.760 --> 00:38:46.840]   What we, you know, what Sonny has told us
[00:38:46.840 --> 00:38:49.400]   and other people, you know, in the field have told us
[00:38:49.400 --> 00:38:52.280]   that inference is going to drop by another 90%
[00:38:52.280 --> 00:38:56.160]   over the course of the next, you know, period of months.
[00:38:56.160 --> 00:38:58.600]   - If you're racing logarithmic needs,
[00:38:58.600 --> 00:39:00.440]   you're going to need that.
[00:39:00.440 --> 00:39:01.880]   - Right, and you know,
[00:39:01.880 --> 00:39:04.960]   and here's what I also think happens, Bill,
[00:39:04.960 --> 00:39:07.600]   is in this chain of reasoning,
[00:39:07.600 --> 00:39:09.200]   you're going to build intelligence
[00:39:09.200 --> 00:39:11.600]   into the chain of reasoning, right?
[00:39:11.600 --> 00:39:14.200]   So that, you know, you're going to optimize
[00:39:14.200 --> 00:39:16.080]   where you send these, you know,
[00:39:16.080 --> 00:39:18.040]   each of these inference interactions,
[00:39:18.040 --> 00:39:19.440]   you're going to batch them,
[00:39:19.440 --> 00:39:21.120]   you're going to take more time with,
[00:39:21.120 --> 00:39:24.080]   because it's just a time money trade-off, right?
[00:39:24.080 --> 00:39:25.480]   At the end of the day.
[00:39:25.480 --> 00:39:28.880]   I also think that we're in the very earliest innings
[00:39:28.880 --> 00:39:31.640]   as to how we're going to think
[00:39:31.640 --> 00:39:33.360]   about pricing these models, right?
[00:39:33.360 --> 00:39:35.560]   So if we think about this in terms of systems one,
[00:39:35.560 --> 00:39:38.080]   systems two level thinking, right?
[00:39:38.080 --> 00:39:39.400]   Systems one being, you know,
[00:39:39.400 --> 00:39:41.480]   what's the capital of France, right?
[00:39:41.480 --> 00:39:44.240]   You're going to be able to do that for fractions of a penny
[00:39:44.240 --> 00:39:49.000]   using pretty simple models on chat GPT, right?
[00:39:49.000 --> 00:39:50.960]   When you want to do something more complex,
[00:39:50.960 --> 00:39:53.120]   if you're a scientist and you want to use O1
[00:39:53.120 --> 00:39:55.000]   as your research partner, right?
[00:39:55.000 --> 00:39:56.600]   You may end up paying it by the hour
[00:39:56.600 --> 00:39:59.480]   and relative to the cost of an actual research partner,
[00:39:59.480 --> 00:40:01.400]   it may be really cheap, right?
[00:40:01.400 --> 00:40:04.240]   So I think there are going to be consumption models,
[00:40:04.240 --> 00:40:05.080]   you know, for this.
[00:40:05.080 --> 00:40:07.680]   I think we haven't even scratched the surface
[00:40:07.680 --> 00:40:09.280]   to think about how that's going to be priced,
[00:40:09.280 --> 00:40:11.680]   but I totally agree with you
[00:40:11.680 --> 00:40:13.280]   that it's going to be priced very differently.
[00:40:13.280 --> 00:40:14.920]   Again, I think this puts,
[00:40:14.920 --> 00:40:18.840]   I think OpenAI has suggested, you know,
[00:40:18.840 --> 00:40:23.160]   that the O1 full model may even be released yet this year,
[00:40:23.160 --> 00:40:24.360]   right?
[00:40:24.360 --> 00:40:27.600]   One of the things that I'm kind of waiting to see
[00:40:27.600 --> 00:40:29.200]   is I think, you know, listen,
[00:40:29.200 --> 00:40:32.000]   having known Noam Brown for quite a while now,
[00:40:32.000 --> 00:40:33.920]   he's an N of one, right?
[00:40:33.920 --> 00:40:35.720]   And he wasn't the only one working on this
[00:40:35.720 --> 00:40:39.360]   for sure at OpenAI, but, you know, listen,
[00:40:39.360 --> 00:40:42.920]   whether it was pluribus or winning at the game of diplomas,
[00:40:42.920 --> 00:40:46.080]   he's been thinking about this for a decade, right?
[00:40:46.080 --> 00:40:47.680]   It was his major breakthrough
[00:40:47.680 --> 00:40:50.280]   on how to win the game of six-handed poker.
[00:40:50.280 --> 00:40:52.720]   And so he brought this to OpenAI.
[00:40:52.720 --> 00:40:55.120]   I think they have a real lead here,
[00:40:55.120 --> 00:40:57.480]   which leads me back to this question, Bill,
[00:40:57.480 --> 00:40:59.680]   you and I talk about all the time,
[00:40:59.680 --> 00:41:02.280]   which is memory and actions, right?
[00:41:02.280 --> 00:41:04.880]   And so I have to tell you this funny thing
[00:41:04.880 --> 00:41:08.440]   that occurred at our investor day.
[00:41:08.440 --> 00:41:11.040]   So I had Nikesh on stage and, you know,
[00:41:11.040 --> 00:41:12.560]   obviously Nikesh, you know,
[00:41:12.560 --> 00:41:14.760]   was instrumental at Google for a decade.
[00:41:14.760 --> 00:41:16.920]   And so I wanted to talk to him about both consumer AI
[00:41:16.920 --> 00:41:18.680]   as well as enterprise AI.
[00:41:18.680 --> 00:41:21.440]   And I asked him, I said, I want to make a wager with you.
[00:41:21.440 --> 00:41:23.840]   I knew of course he would take a bet.
[00:41:23.840 --> 00:41:26.280]   And I said, I want to make a wager with you.
[00:41:26.280 --> 00:41:29.800]   Over, under, I'll set the line at two years
[00:41:29.800 --> 00:41:33.720]   until we have an agent that has memory and can take action.
[00:41:33.720 --> 00:41:35.720]   And the canonical use case, of course,
[00:41:35.720 --> 00:41:38.560]   that I used was that I could tell my agent,
[00:41:38.560 --> 00:41:40.640]   book me the Mercer Hotel next Tuesday
[00:41:40.640 --> 00:41:42.680]   in New York at the lowest price.
[00:41:42.680 --> 00:41:44.800]   And I said, over, under, you know,
[00:41:44.800 --> 00:41:46.640]   two years on getting that done.
[00:41:46.640 --> 00:41:51.640]   I said, I'll start 5,000 bucks, I'll take the under.
[00:41:51.640 --> 00:41:55.320]   He snap calls me, he says, I'll take the over.
[00:41:55.320 --> 00:41:58.320]   And he said, but only if you 10X the bet.
[00:41:58.320 --> 00:42:02.080]   And of course we're doing it for a good cause.
[00:42:02.080 --> 00:42:04.600]   So I had to call him because I, you know,
[00:42:04.600 --> 00:42:09.080]   I can't not step up to a good cause.
[00:42:09.080 --> 00:42:11.520]   So we're taking the opposite sides of that trade.
[00:42:11.520 --> 00:42:13.400]   Now, what was interesting is over the course
[00:42:13.400 --> 00:42:14.720]   of the next couple of days,
[00:42:14.720 --> 00:42:18.280]   I asked some other friends who took the stage, you know,
[00:42:18.280 --> 00:42:22.600]   where they would come down on the same bet, right?
[00:42:22.600 --> 00:42:25.240]   Our friend, Stanley Tang took the under.
[00:42:25.240 --> 00:42:29.080]   A friend from Apple, who will remain nameless,
[00:42:29.080 --> 00:42:30.080]   kind of took the over.
[00:42:30.080 --> 00:42:34.240]   And then Noam Brown, who was there, pleaded the fifth.
[00:42:34.240 --> 00:42:36.640]   He says, I know the answer, so I can't say.
[00:42:36.640 --> 00:42:40.560]   And so, yeah, it was kind of provocative.
[00:42:40.560 --> 00:42:43.320]   And I, you know, I texted Nikesh and I said,
[00:42:43.320 --> 00:42:46.320]   I think you better get your checkbook ready.
[00:42:46.320 --> 00:42:49.560]   You know, so coming back to that, Bill,
[00:42:49.560 --> 00:42:52.000]   you know, Strawberry O'Wan's an incredible breakthrough,
[00:42:52.000 --> 00:42:52.960]   something that thinks,
[00:42:52.960 --> 00:42:55.920]   so this whole new vector of intelligence,
[00:42:55.920 --> 00:42:58.080]   but it kind of makes us forget
[00:42:58.080 --> 00:42:59.920]   about the thing you and I focus so much on,
[00:42:59.920 --> 00:43:02.520]   which was memory and actions, right?
[00:43:02.520 --> 00:43:06.240]   And I think that we are on the real precipice
[00:43:06.240 --> 00:43:09.040]   of not only these models think, you know,
[00:43:09.040 --> 00:43:10.640]   can spend more time thinking,
[00:43:10.640 --> 00:43:14.680]   not only can they give us less hallucinations, you know,
[00:43:14.680 --> 00:43:17.440]   and just scaled compute, but I also think,
[00:43:17.440 --> 00:43:19.120]   I mean, you already see the makings of this.
[00:43:19.120 --> 00:43:20.360]   I mean, use these things today.
[00:43:20.360 --> 00:43:22.840]   They already remember quite a bit.
[00:43:22.840 --> 00:43:26.760]   So I think they're sliding this into the experience,
[00:43:26.760 --> 00:43:28.360]   but I think we're going to have the ability
[00:43:28.360 --> 00:43:29.520]   to take simple actions.
[00:43:29.520 --> 00:43:32.280]   And I think this metaphor that people had in their minds,
[00:43:32.280 --> 00:43:34.840]   that they were going to have to build deep APIs
[00:43:34.840 --> 00:43:37.800]   and deep integrations to everybody,
[00:43:37.800 --> 00:43:40.040]   I don't think is the way this is going to play out.
[00:43:40.040 --> 00:43:41.480]   And let me just--
[00:43:41.480 --> 00:43:42.760]   What do you think is going to play out?
[00:43:42.760 --> 00:43:44.000]   Well, I mean, the Easter egg
[00:43:44.000 --> 00:43:45.640]   that I thought got dropped last week
[00:43:45.640 --> 00:43:50.560]   is they did this event on, you know, their voice API, right?
[00:43:50.560 --> 00:43:53.680]   And it's literally your GPT calling a human
[00:43:53.680 --> 00:43:55.760]   on the telephone and placing an order.
[00:43:55.760 --> 00:43:59.600]   So why the hell can't my GPT just call up the Mercer Hotel
[00:43:59.600 --> 00:44:02.240]   and say, "Brad Gerstner would like to make a reservation.
[00:44:02.240 --> 00:44:03.360]   Here's his credit card number,"
[00:44:03.360 --> 00:44:05.400]   and pass along the information?
[00:44:05.400 --> 00:44:06.560]   There is a reason for that.
[00:44:06.560 --> 00:44:11.400]   I mean, look, scrapers and form fillers have existed
[00:44:11.400 --> 00:44:12.640]   for how long, Sonny?
[00:44:12.640 --> 00:44:13.800]   15 years?
[00:44:13.800 --> 00:44:17.320]   Like, you could write an agent to go fill out
[00:44:17.320 --> 00:44:20.320]   and book at the Mercer Hotel 15 years ago.
[00:44:20.320 --> 00:44:22.760]   There's nothing impossible about that.
[00:44:22.760 --> 00:44:26.360]   It's the corner cases and, like, the hallucination
[00:44:26.360 --> 00:44:29.120]   when your credit card gets charged 10 grand.
[00:44:29.120 --> 00:44:31.680]   Like, you just can't have failure.
[00:44:31.680 --> 00:44:34.240]   And how you architect this
[00:44:34.240 --> 00:44:36.600]   so that there's not failure and there's trust,
[00:44:36.600 --> 00:44:38.960]   I'm sure you could demo this tomorrow.
[00:44:38.960 --> 00:44:41.400]   I have zero doubt you could demo it tomorrow.
[00:44:41.400 --> 00:44:44.520]   Could you provide it at scale in a trustworthy way
[00:44:44.520 --> 00:44:47.480]   where people are allocating their credit cards to it?
[00:44:47.480 --> 00:44:48.560]   That might take a little longer.
[00:44:48.560 --> 00:44:51.800]   Okay, so over-under bill on two years.
[00:44:51.800 --> 00:44:54.840]   I mean, I'm gonna get to action either way.
[00:44:54.840 --> 00:44:55.960]   But what's the test?
[00:44:55.960 --> 00:44:56.800]   The demo?
[00:44:56.800 --> 00:44:57.640]   I think you can do it today.
[00:44:57.640 --> 00:44:59.720]   No, not the cheesy demo you just said.
[00:44:59.720 --> 00:45:02.520]   I'm talking about a release that allows me,
[00:45:02.520 --> 00:45:04.760]   you know, at scale to book a hotel.
[00:45:04.760 --> 00:45:06.600]   Where it's spending your credit card?
[00:45:06.600 --> 00:45:09.600]   And not just you, but everybody, full release?
[00:45:09.600 --> 00:45:11.120]   Yeah, we'll call it a full release,
[00:45:11.120 --> 00:45:12.440]   just because I know that's the only way
[00:45:12.440 --> 00:45:14.080]   I can entice you to take the bet.
[00:45:16.240 --> 00:45:20.360]   Which today is October 8th, 2024.
[00:45:20.360 --> 00:45:22.960]   I mean, Sonny, you already know what he's gonna say.
[00:45:22.960 --> 00:45:25.280]   You'll take the over, right, Bill?
[00:45:25.280 --> 00:45:26.120]   Yeah, yes.
[00:45:26.120 --> 00:45:27.560]   Okay, so Bill's into cash camp.
[00:45:27.560 --> 00:45:28.640]   Sonny, where do you come down?
[00:45:28.640 --> 00:45:30.040]   Over-under on two years.
[00:45:30.040 --> 00:45:31.720]   No, don't start hedging, Bill.
[00:45:31.720 --> 00:45:32.560]   Don't start hedging.
[00:45:32.560 --> 00:45:33.400]   Go ahead, Sonny.
[00:45:33.400 --> 00:45:34.400]   I already said it, demo today.
[00:45:34.400 --> 00:45:36.920]   It's 15 years ago you could do that.
[00:45:36.920 --> 00:45:39.320]   Let me comment on what you're worried about, Bill.
[00:45:39.320 --> 00:45:41.840]   And I think people still are still working
[00:45:41.840 --> 00:45:42.800]   their way through it.
[00:45:42.800 --> 00:45:44.960]   You don't need a single agent right now
[00:45:44.960 --> 00:45:47.280]   to book the Mercer and deal with all the scraping stuff
[00:45:47.280 --> 00:45:48.200]   you're talking about.
[00:45:48.200 --> 00:45:50.400]   You can have a thousand agents working together.
[00:45:50.400 --> 00:45:51.600]   You can have one that's making sure
[00:45:51.600 --> 00:45:53.480]   that the credit card charge is not too big.
[00:45:53.480 --> 00:45:54.760]   You can have another one to make sure
[00:45:54.760 --> 00:45:55.800]   that the address is right.
[00:45:55.800 --> 00:45:57.880]   You can have another one checking against your calendar.
[00:45:57.880 --> 00:45:59.600]   And so all of that's free.
[00:45:59.600 --> 00:46:01.320]   So I'm on the under, and Brad,
[00:46:01.320 --> 00:46:03.400]   I'll even go under one year.
[00:46:03.400 --> 00:46:05.240]   Wow, wow.
[00:46:05.240 --> 00:46:08.240]   So we got a little side action, you and I, Sonny.
[00:46:08.240 --> 00:46:09.760]   I'm not gonna go under a year,
[00:46:09.760 --> 00:46:13.200]   but I think we could have limited releases in a year.
[00:46:13.200 --> 00:46:16.920]   But Sonny, you and I now have action with Bill.
[00:46:16.920 --> 00:46:18.880]   What do you want, Bill, a thousand bucks?
[00:46:18.880 --> 00:46:19.880]   Sure. To a good cause?
[00:46:19.880 --> 00:46:22.120]   Okay, a thousand bucks each to a good cause.
[00:46:22.120 --> 00:46:23.920]   And I'll just assume, Sonny,
[00:46:23.920 --> 00:46:26.080]   that we'll get action from Nikesh as well.
[00:46:26.080 --> 00:46:27.680]   And you know our friend Stanley Tang
[00:46:27.680 --> 00:46:29.600]   is definitely in the tank for some.
[00:46:29.600 --> 00:46:32.960]   So we're gonna give some good money to a good cause.
[00:46:32.960 --> 00:46:35.800]   And listen, I think this is the trillion dollar question.
[00:46:35.800 --> 00:46:39.080]   I know we're all focused on scaling models,
[00:46:39.080 --> 00:46:41.200]   and I know we're all focused on the compute layer,
[00:46:41.200 --> 00:46:44.160]   but what really transforms people's lives,
[00:46:44.160 --> 00:46:47.360]   what really disrupts 10 Blue Links,
[00:46:47.360 --> 00:46:49.920]   what really disrupts the entire architecture
[00:46:49.920 --> 00:46:52.200]   of the app ecosystem,
[00:46:52.200 --> 00:46:54.560]   is that when we have an intelligent assistant
[00:46:54.560 --> 00:46:57.160]   that we can interact with that gets smarter over time,
[00:46:57.160 --> 00:46:59.360]   that has memory and could take actions.
[00:46:59.360 --> 00:47:03.360]   And when I see the combination of advanced voice mode,
[00:47:03.360 --> 00:47:05.480]   voice-to-voice API,
[00:47:05.480 --> 00:47:09.720]   Strawberry 01 thinking combined with scaling intelligence,
[00:47:09.720 --> 00:47:12.320]   I just think this is going to go a lot faster
[00:47:12.320 --> 00:47:13.160]   than most of us think.
[00:47:13.160 --> 00:47:16.040]   Now, listen, they may pull on the reins, right?
[00:47:16.040 --> 00:47:19.080]   They may slow down the release schedule in order,
[00:47:19.080 --> 00:47:20.800]   you know, for a lot of business reasons.
[00:47:20.800 --> 00:47:22.720]   That's harder to predict.
[00:47:22.720 --> 00:47:25.600]   But I think the technology, I mean, even Noam said,
[00:47:25.600 --> 00:47:28.400]   I thought it was gonna take us much, much longer
[00:47:28.400 --> 00:47:30.720]   to see the results that we have seen.
[00:47:30.720 --> 00:47:32.400]   Can I hit on one other thing?
[00:47:32.400 --> 00:47:34.360]   This is, you know, we started the pod
[00:47:34.360 --> 00:47:35.880]   a little bit talking about it.
[00:47:35.880 --> 00:47:38.360]   I just wanna get your impression, Bill.
[00:47:38.360 --> 00:47:40.840]   This idea that Jensen can scale the business
[00:47:40.840 --> 00:47:42.680]   two or three times with, you know,
[00:47:42.680 --> 00:47:47.280]   increasing the head count by, you know, 20 or 25%, right?
[00:47:47.280 --> 00:47:48.720]   We know that Meta's done that
[00:47:48.720 --> 00:47:51.240]   over the course of the last two years.
[00:47:51.240 --> 00:47:52.400]   And you and I've talked about,
[00:47:52.400 --> 00:47:55.960]   are we on the eve of just massive productivity boom
[00:47:55.960 --> 00:47:58.840]   and massive margin expansion
[00:47:58.840 --> 00:48:01.240]   like we've never seen before, right?
[00:48:01.240 --> 00:48:04.760]   Nikesh said, we ought to be able to get 20 or 30%,
[00:48:04.760 --> 00:48:06.640]   you know, productivity gains out of everybody
[00:48:06.640 --> 00:48:07.880]   in the business.
[00:48:07.880 --> 00:48:10.680]   - First of all, I think NVIDIA is a very special company.
[00:48:10.680 --> 00:48:15.680]   And it's a company that's even if it's a systems company,
[00:48:15.680 --> 00:48:17.280]   it's an IP company.
[00:48:17.280 --> 00:48:20.160]   And the demand is growing at such a rate
[00:48:20.160 --> 00:48:22.680]   that they don't need more designers
[00:48:22.680 --> 00:48:27.680]   or more developer engineers to create incremental revenue.
[00:48:27.680 --> 00:48:29.280]   That's happening on its own.
[00:48:29.280 --> 00:48:32.920]   And so their operating margins are record levels.
[00:48:32.920 --> 00:48:36.640]   For the majority of companies, you know,
[00:48:36.640 --> 00:48:39.480]   I've always just held this belief that, you know,
[00:48:39.480 --> 00:48:41.040]   you evolve with your tools.
[00:48:41.040 --> 00:48:44.920]   And the real answer is the companies
[00:48:44.920 --> 00:48:46.480]   that don't deploy these things
[00:48:46.480 --> 00:48:47.600]   are gonna go out of business.
[00:48:47.600 --> 00:48:48.440]   - Yeah.
[00:48:48.440 --> 00:48:51.360]   - And so I think margins get competed away
[00:48:51.360 --> 00:48:52.560]   in many, many cases.
[00:48:52.560 --> 00:48:55.800]   I think it's ridiculous to imagine,
[00:48:55.800 --> 00:48:58.120]   oh, every company goes to 60% operating margin.
[00:48:58.120 --> 00:48:59.280]   - No, no, no, no.
[00:48:59.280 --> 00:49:01.320]   I mean, listen, Delta Airlines
[00:49:01.320 --> 00:49:04.600]   is going to do all of these things with AI
[00:49:04.600 --> 00:49:07.160]   and immediately because it's in a commodity market,
[00:49:07.160 --> 00:49:09.320]   it'll get competed away by Southwestern United.
[00:49:09.320 --> 00:49:11.720]   Bad industries remain bad industries.
[00:49:11.720 --> 00:49:12.960]   - Yeah, yeah, yeah.
[00:49:12.960 --> 00:49:16.920]   So, but there might be some, you know, that figure it out.
[00:49:16.920 --> 00:49:21.920]   And I have another theory that I always keep in mind,
[00:49:21.920 --> 00:49:25.960]   which is hyper growth tends to delay
[00:49:25.960 --> 00:49:28.600]   what you learned in microeconomics class.
[00:49:28.600 --> 00:49:31.040]   You know, I remember when I was a PC analyst
[00:49:31.040 --> 00:49:33.240]   and there were five public PC companies
[00:49:33.240 --> 00:49:35.200]   all growing 100%.
[00:49:35.200 --> 00:49:38.000]   And so in moments of hyper growth,
[00:49:38.000 --> 00:49:41.280]   you will have margins that may or may not be durable.
[00:49:41.280 --> 00:49:44.360]   And you'll have a number of participants in a market
[00:49:44.360 --> 00:49:46.640]   that may or may not be durable
[00:49:46.640 --> 00:49:48.840]   during periods of hyper growth.
[00:49:48.840 --> 00:49:51.080]   - I have two more things on my mind, Sunday.
[00:49:51.080 --> 00:49:52.680]   Do you have any reactions to that?
[00:49:52.680 --> 00:49:55.280]   I mean, I just have to get to a couple of these topics.
[00:49:55.280 --> 00:49:56.480]   - No, like-
[00:49:56.480 --> 00:50:00.240]   - There's gonna be a Lex Friedman links podcast
[00:50:00.240 --> 00:50:03.040]   once you've finished the interview.
[00:50:03.040 --> 00:50:06.080]   - No, look, I really, you know,
[00:50:06.080 --> 00:50:09.160]   been thinking a lot about Jensen's point in the pod about,
[00:50:09.160 --> 00:50:12.040]   you know, how much AI they're using internally for design,
[00:50:12.040 --> 00:50:14.520]   design verification for all those pieces, right?
[00:50:14.520 --> 00:50:17.680]   And I think, you know, it's not 30%.
[00:50:17.680 --> 00:50:21.160]   I actually think sort of that's an underestimate.
[00:50:21.160 --> 00:50:22.960]   I think you're talking, you know,
[00:50:22.960 --> 00:50:24.880]   multiple hundreds of percent improvement
[00:50:24.880 --> 00:50:26.560]   in productivity gains.
[00:50:26.560 --> 00:50:28.920]   And the only issue is that not every company
[00:50:28.920 --> 00:50:31.320]   can grasp that that quickly.
[00:50:31.320 --> 00:50:33.560]   And so, you know,
[00:50:33.560 --> 00:50:35.960]   I think he was kind of holding some cards back
[00:50:35.960 --> 00:50:37.840]   at that point when he made that comment.
[00:50:37.840 --> 00:50:39.400]   And it really got me thinking about like,
[00:50:39.400 --> 00:50:40.880]   how much are they doing there
[00:50:40.880 --> 00:50:42.960]   that they don't want everybody to know about?
[00:50:42.960 --> 00:50:46.280]   And you kind of see it now in the model development
[00:50:46.280 --> 00:50:47.440]   because they, you know,
[00:50:47.440 --> 00:50:48.800]   if you've noticed the last couple of weeks,
[00:50:48.800 --> 00:50:50.280]   they put some models out there
[00:50:50.280 --> 00:50:51.680]   that are models trained on their own
[00:50:51.680 --> 00:50:54.440]   and they don't get as much noise as, you know,
[00:50:54.440 --> 00:50:56.800]   ones from Meta and, you know,
[00:50:56.800 --> 00:50:59.080]   the other players that are out there,
[00:50:59.080 --> 00:51:01.760]   but they're really doing a lot more than we think.
[00:51:01.760 --> 00:51:04.320]   And they, I think they have their arms
[00:51:04.320 --> 00:51:07.120]   around a lot of these very, very difficult problems.
[00:51:07.120 --> 00:51:09.680]   Brad, why did they put their own model up?
[00:51:09.680 --> 00:51:13.040]   Well, it's related to this topic of open versus closed.
[00:51:13.040 --> 00:51:16.200]   So Bill, you know, I hope you're proud of me.
[00:51:16.200 --> 00:51:17.520]   You know, I went back and I said,
[00:51:17.520 --> 00:51:20.000]   I have to ask this question. I do.
[00:51:20.000 --> 00:51:23.160]   Right, and you know, I thought Jensen, you know,
[00:51:23.160 --> 00:51:25.680]   I thought he gave a great answer, which is like, listen,
[00:51:25.680 --> 00:51:28.320]   we're gonna have companies that for economic reasons,
[00:51:28.320 --> 00:51:30.800]   right, push the boundary toward AGI
[00:51:30.800 --> 00:51:32.240]   or whatever they're doing.
[00:51:32.240 --> 00:51:34.000]   And it makes sense to have a closed model
[00:51:34.000 --> 00:51:36.840]   that can be the best and they can monetize.
[00:51:36.840 --> 00:51:39.200]   But the world's not gonna develop with just closed models.
[00:51:39.200 --> 00:51:40.240]   We're gonna, you know, he's like,
[00:51:40.240 --> 00:51:42.640]   it's both open and closed.
[00:51:42.640 --> 00:51:45.160]   And, you know, he said, because open,
[00:51:45.160 --> 00:51:47.720]   he's like, it's absolutely a condition required.
[00:51:47.720 --> 00:51:49.040]   It's gonna be the vast majority
[00:51:49.040 --> 00:51:50.440]   of the models in the industry.
[00:51:50.440 --> 00:51:52.360]   He's right now, if we didn't have open source,
[00:51:52.360 --> 00:51:55.000]   how would you have all these different fields in science,
[00:51:55.000 --> 00:51:57.120]   you know, be able to be activated on AI?
[00:51:57.120 --> 00:52:00.040]   He talked about llama models exploding higher.
[00:52:00.040 --> 00:52:02.440]   And then with respect to his own open source model,
[00:52:02.440 --> 00:52:04.480]   which I thought was really interesting.
[00:52:04.480 --> 00:52:07.400]   He said, we focused on, right,
[00:52:07.400 --> 00:52:10.840]   something that a specific capability.
[00:52:10.840 --> 00:52:13.520]   And the capability that we were focused on
[00:52:13.520 --> 00:52:16.280]   is how to agentically use this model
[00:52:16.280 --> 00:52:19.240]   to make your model smarter, faster, right?
[00:52:19.240 --> 00:52:21.600]   So it's almost like a training coaching model
[00:52:21.600 --> 00:52:22.680]   that he built.
[00:52:22.680 --> 00:52:25.160]   And so I think for them, it makes perfect sense
[00:52:25.160 --> 00:52:29.400]   why they may, you know, put that out into the world.
[00:52:29.400 --> 00:52:31.240]   But I also, you know, a lot of times
[00:52:31.240 --> 00:52:34.200]   the open versus closed debate, you know,
[00:52:34.200 --> 00:52:36.680]   gets hijacked into this conversation
[00:52:36.680 --> 00:52:38.600]   about safety and security.
[00:52:38.600 --> 00:52:40.280]   And, you know, and I think he said, you know,
[00:52:40.280 --> 00:52:41.800]   listen, these two things are related,
[00:52:41.800 --> 00:52:43.640]   but they're not the same thing.
[00:52:43.640 --> 00:52:46.440]   You know, one of the things he commented on that is just,
[00:52:46.440 --> 00:52:49.120]   he said, there's so much coordination going on
[00:52:49.120 --> 00:52:50.560]   on the safety and security level.
[00:52:50.560 --> 00:52:52.640]   Like we have so many agents
[00:52:52.640 --> 00:52:56.480]   and so much activity going on, on making sure, you know,
[00:52:56.480 --> 00:53:00.120]   just look at what Meta's doing, you know, on this.
[00:53:00.120 --> 00:53:02.840]   He's like, I think that's one thing that's under-celebrated
[00:53:02.840 --> 00:53:05.680]   that even in the absence of any, you know,
[00:53:05.680 --> 00:53:09.080]   platonic guardian sort of regulation, right?
[00:53:09.080 --> 00:53:10.320]   Without any top-down,
[00:53:10.320 --> 00:53:14.040]   you already have an extraordinary amount of effort
[00:53:14.040 --> 00:53:18.080]   going in by all of these companies into AI safety
[00:53:18.080 --> 00:53:20.280]   and security that I thought was,
[00:53:20.280 --> 00:53:22.520]   I thought was a really important comment.
[00:53:22.520 --> 00:53:25.120]   Thanks for jumping in, guys, kicking this one around.
[00:53:25.120 --> 00:53:26.480]   It was a special one to--
[00:53:26.480 --> 00:53:28.520]   - Yeah, congrats on having that opportunity.
[00:53:28.520 --> 00:53:30.880]   That's pretty, that's pretty unique.
[00:53:30.880 --> 00:53:32.640]   - And now we got a little wager.
[00:53:32.640 --> 00:53:36.760]   So I mean, listen, I am so looking forward
[00:53:36.760 --> 00:53:41.760]   to like doing a live booking at the Mercer on the pod, right?
[00:53:41.760 --> 00:53:45.640]   And then Sonny, we can just drop the money from the sky.
[00:53:45.640 --> 00:53:49.880]   We can just collect, we can just collect, exactly, exactly.
[00:53:49.880 --> 00:53:50.720]   Good to see you guys.
[00:53:50.720 --> 00:53:51.560]   We'll talk soon.
[00:53:51.560 --> 00:53:53.240]   - All right, peace. - Take care.
[00:53:53.240 --> 00:53:55.840]   (upbeat music)
[00:53:55.840 --> 00:54:04.280]   - As a reminder to everybody,
[00:54:04.280 --> 00:54:06.440]   just our opinions, not investment advice.

