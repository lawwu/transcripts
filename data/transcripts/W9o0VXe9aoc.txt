
[00:00:00.000 --> 00:00:02.580]   (upbeat music)
[00:00:02.580 --> 00:00:06.500]   - Welcome to Weights & Biases
[00:00:06.500 --> 00:00:08.760]   fully connected user conference.
[00:00:08.760 --> 00:00:10.860]   I'm Lucas Biewald, the CEO and co-founder
[00:00:10.860 --> 00:00:12.640]   of Weights & Biases.
[00:00:12.640 --> 00:00:14.400]   And our goal with Weights & Biases
[00:00:14.400 --> 00:00:17.080]   is to build useful tools to support you,
[00:00:17.080 --> 00:00:19.560]   the ML engineers building and deploying
[00:00:19.560 --> 00:00:21.480]   machine learning models.
[00:00:21.480 --> 00:00:24.400]   Now, the most important and toughest part
[00:00:24.400 --> 00:00:27.360]   of building great products for people like you,
[00:00:27.360 --> 00:00:30.480]   especially in 2023, is anticipating
[00:00:30.480 --> 00:00:33.360]   where the machine learning industry is moving.
[00:00:33.360 --> 00:00:34.980]   And so my goal with this presentation
[00:00:34.980 --> 00:00:38.060]   is actually to take you through our big predictions
[00:00:38.060 --> 00:00:41.480]   and our thinking around how machine learning is changing
[00:00:41.480 --> 00:00:44.000]   and what new problems we are anticipating
[00:00:44.000 --> 00:00:45.440]   and what we can do together
[00:00:45.440 --> 00:00:47.400]   to push forward the state of the art
[00:00:47.400 --> 00:00:50.600]   and have as much positive impact on the world as possible.
[00:00:50.600 --> 00:00:52.840]   Let me start by walking you through
[00:00:52.840 --> 00:00:54.800]   the data that we're looking at.
[00:00:54.800 --> 00:00:56.680]   And then I wanna take you through
[00:00:56.680 --> 00:00:58.840]   the big trends that we've identified
[00:00:58.840 --> 00:01:01.180]   starting at the beginning of 2023.
[00:01:01.180 --> 00:01:03.860]   This is rapid growth in production ML deployments,
[00:01:03.860 --> 00:01:06.080]   rapid growth in the size of machine learning teams,
[00:01:06.080 --> 00:01:07.960]   and rapid growth in the volume
[00:01:07.960 --> 00:01:10.600]   of meaningful applied research.
[00:01:10.600 --> 00:01:14.160]   As Weights & Biases has become an industry standard tool,
[00:01:14.160 --> 00:01:16.640]   we've started to collect more and more data.
[00:01:16.640 --> 00:01:20.240]   And for the first time, I'm gonna walk you through
[00:01:20.240 --> 00:01:23.140]   some of the things that we're seeing on our platform.
[00:01:23.140 --> 00:01:26.340]   First of all, you might expect this,
[00:01:26.340 --> 00:01:28.720]   we track a ton of compute hours
[00:01:28.720 --> 00:01:31.720]   and the volume of compute hours is accelerating.
[00:01:31.720 --> 00:01:33.580]   At first, this growth is probably due
[00:01:33.580 --> 00:01:35.200]   to adoption of Weights & Biases,
[00:01:35.200 --> 00:01:38.520]   but now this growth mainly comes from the general trend
[00:01:38.520 --> 00:01:41.640]   towards longer and bigger training runs.
[00:01:41.640 --> 00:01:44.520]   We started tracking library use at the end of 2019
[00:01:44.520 --> 00:01:47.560]   in order to understand which integrations to prioritize.
[00:01:47.560 --> 00:01:50.220]   And since the beginning, and this might surprise you,
[00:01:50.220 --> 00:01:54.280]   PyTorch has been the clear number one ML framework.
[00:01:54.280 --> 00:01:56.100]   Lately though, we see some changes.
[00:01:56.100 --> 00:01:57.780]   We see the amount of hugging face,
[00:01:57.780 --> 00:02:01.100]   which is obviously complimentary with PyTorch growing.
[00:02:01.100 --> 00:02:04.340]   Maybe more surprising, we see that XGBoost,
[00:02:04.340 --> 00:02:06.040]   the famous boosted tree library,
[00:02:06.040 --> 00:02:08.200]   and Lightning, a newer research framework
[00:02:08.200 --> 00:02:10.480]   built on top of PyTorch, alternating,
[00:02:10.480 --> 00:02:13.260]   holding the number three spot for most of 2022.
[00:02:13.260 --> 00:02:17.120]   So Jonathan Geifman asked us a great question,
[00:02:17.120 --> 00:02:19.920]   what are the most popular random seeds on Weights & Biases?
[00:02:19.920 --> 00:02:21.620]   And so we pulled the data for him.
[00:02:22.720 --> 00:02:26.380]   The top random seed, the number one, makes total sense,
[00:02:26.380 --> 00:02:29.360]   but the next three might be a little harder to explain.
[00:02:29.360 --> 00:02:34.360]   42, 920, 3,407, serious nerd points
[00:02:34.360 --> 00:02:36.660]   if you know why this is happening.
[00:02:36.660 --> 00:02:38.680]   We can also look at more practical things,
[00:02:38.680 --> 00:02:40.560]   like what are the most popular optimizers,
[00:02:40.560 --> 00:02:43.520]   which turn out to be L, BFGS, and Atom,
[00:02:43.520 --> 00:02:45.440]   but we sort of suspect that that has more to do
[00:02:45.440 --> 00:02:46.920]   with the framework defaults
[00:02:46.920 --> 00:02:50.060]   than the real efficacy of these techniques.
[00:02:50.060 --> 00:02:51.980]   We also see a strong correlation
[00:02:51.980 --> 00:02:53.800]   between learning rates and accuracy,
[00:02:53.800 --> 00:02:56.640]   which certainly warrants more investigation.
[00:02:56.640 --> 00:02:58.580]   And I should say, if this stuff piques your interest,
[00:02:58.580 --> 00:03:00.760]   feel free to send us ideas for more analysis,
[00:03:00.760 --> 00:03:03.800]   or even send us your resume, as we are hiring.
[00:03:03.800 --> 00:03:05.720]   And one of the really fun things
[00:03:05.720 --> 00:03:06.960]   about the machine learning field
[00:03:06.960 --> 00:03:10.700]   is that the state of the art is constantly improving.
[00:03:10.700 --> 00:03:12.240]   Sometimes as consumers,
[00:03:12.240 --> 00:03:14.180]   we feel like there's this punctuated equilibrium
[00:03:14.180 --> 00:03:17.240]   of breakthroughs, but if you really go and look at the data,
[00:03:17.240 --> 00:03:18.840]   like this graph in The Economist
[00:03:18.840 --> 00:03:21.520]   of the state of the art of speech recognition accuracy,
[00:03:21.520 --> 00:03:23.840]   you see that error rates have been steadily dropping
[00:03:23.840 --> 00:03:25.200]   since the 90s.
[00:03:25.200 --> 00:03:27.180]   Of course, as a user of this technology,
[00:03:27.180 --> 00:03:28.600]   it can feel like speech recognition
[00:03:28.600 --> 00:03:31.880]   suddenly went from incredibly annoying to fantastic
[00:03:31.880 --> 00:03:33.960]   when it crosses a specific threshold,
[00:03:33.960 --> 00:03:37.040]   but the reality is that it's been continuously improving
[00:03:37.040 --> 00:03:39.420]   since we started working on it.
[00:03:39.420 --> 00:03:42.280]   So what's coming in 2023?
[00:03:42.280 --> 00:03:45.760]   The biggest, most important trend happening in ML right now
[00:03:45.760 --> 00:03:48.920]   is a rapid shift into production deployments.
[00:03:50.480 --> 00:03:53.180]   This graph summarizes how quickly production deployments
[00:03:53.180 --> 00:03:54.720]   could start coming.
[00:03:54.720 --> 00:03:56.920]   It's a survey of enterprises,
[00:03:56.920 --> 00:04:00.540]   and 14% say they have production models deployed,
[00:04:00.540 --> 00:04:03.020]   while 47% say they plan to deploy models
[00:04:03.020 --> 00:04:04.000]   in the next two years.
[00:04:04.000 --> 00:04:06.240]   That's an absolutely massive rate of change.
[00:04:06.240 --> 00:04:09.640]   But should we take enterprises at their word?
[00:04:09.640 --> 00:04:12.620]   Machine learning has this long history
[00:04:12.620 --> 00:04:15.420]   of over-promising and under-delivering,
[00:04:15.420 --> 00:04:17.480]   and it started here with Frank Rosenblatt,
[00:04:17.480 --> 00:04:19.160]   the inventor of neural nets,
[00:04:19.160 --> 00:04:22.140]   interviewed in the New York Times in 1958,
[00:04:22.140 --> 00:04:24.200]   claiming that perceptrons will be able
[00:04:24.200 --> 00:04:26.800]   to instantly translate speech in one language
[00:04:26.800 --> 00:04:28.200]   into another language,
[00:04:28.200 --> 00:04:30.920]   something that might actually happen in the next few years,
[00:04:30.920 --> 00:04:34.240]   but this is almost 70 years after this prediction.
[00:04:34.240 --> 00:04:36.860]   And Rosenblatt is far from the only offender.
[00:04:36.860 --> 00:04:39.480]   I don't know if anyone remembers IBM Watson.
[00:04:39.480 --> 00:04:40.640]   After winning at Jeopardy,
[00:04:40.640 --> 00:04:42.560]   IBM made all kinds of wild predictions
[00:04:42.560 --> 00:04:44.040]   about the state of machine learning,
[00:04:44.040 --> 00:04:47.160]   and then a few years ago went completely quiet.
[00:04:47.160 --> 00:04:50.360]   And of course you have Elon Musk in 2019
[00:04:50.360 --> 00:04:53.400]   predicting a really, truly self-driving Tesla
[00:04:53.400 --> 00:04:55.200]   happening in 2020.
[00:04:55.200 --> 00:04:57.120]   Now, the progress in autonomous vehicles
[00:04:57.120 --> 00:04:57.960]   is really impressive,
[00:04:57.960 --> 00:05:00.440]   and I might be tempted to let him off the hook here,
[00:05:00.440 --> 00:05:02.320]   except that this isn't the only time
[00:05:02.320 --> 00:05:04.080]   he's made this kind of claim.
[00:05:04.080 --> 00:05:05.760]   I guess here he's a little more cautious
[00:05:05.760 --> 00:05:09.440]   saying that self-driving is two years away,
[00:05:09.440 --> 00:05:12.100]   but that was actually back in 2015.
[00:05:12.100 --> 00:05:16.300]   So we say this with some humility.
[00:05:16.300 --> 00:05:18.320]   We believe in 2023,
[00:05:18.320 --> 00:05:21.240]   the growth in production ML will outperform the hype,
[00:05:21.240 --> 00:05:22.940]   and there is a lot of hype.
[00:05:22.940 --> 00:05:27.000]   Now, why do we have the confidence to say this?
[00:05:27.000 --> 00:05:28.080]   One place it comes from
[00:05:28.080 --> 00:05:28.960]   is that we've been working
[00:05:28.960 --> 00:05:30.860]   with the most transformative companies
[00:05:30.860 --> 00:05:33.280]   like OpenAI, Anthropic, and Stability
[00:05:33.280 --> 00:05:34.640]   virtually since they were formed,
[00:05:34.640 --> 00:05:37.200]   and we've seen their progress firsthand.
[00:05:37.200 --> 00:05:38.620]   And maybe more importantly,
[00:05:38.620 --> 00:05:40.440]   we work with a ton of the enterprises
[00:05:40.440 --> 00:05:42.520]   that have successfully deployed machine learning
[00:05:42.520 --> 00:05:43.400]   into production,
[00:05:43.400 --> 00:05:45.900]   and they span virtually every industry.
[00:05:45.900 --> 00:05:48.420]   Back when I graduated and went into machine learning,
[00:05:48.420 --> 00:05:50.800]   there were just a handful of companies doing real ML,
[00:05:50.800 --> 00:05:52.880]   and even when I started my last ML company,
[00:05:52.880 --> 00:05:54.480]   CrowdFlower, in 2008,
[00:05:54.480 --> 00:05:56.560]   machine learning was really confined
[00:05:56.560 --> 00:05:58.840]   to mostly tech and a little bit of e-commerce,
[00:05:58.840 --> 00:06:01.220]   and then we saw a rise in autonomous vehicles,
[00:06:01.220 --> 00:06:02.960]   but still not much.
[00:06:02.960 --> 00:06:05.200]   Now, at Waste & Biases,
[00:06:05.200 --> 00:06:07.580]   we see machine learning everywhere.
[00:06:07.580 --> 00:06:10.520]   One notable new place is in healthcare and pharma,
[00:06:10.520 --> 00:06:11.920]   our fastest-growing segment.
[00:06:11.920 --> 00:06:15.100]   But we also see it in industrial farming,
[00:06:15.100 --> 00:06:17.080]   where customers, including John Deere,
[00:06:17.080 --> 00:06:19.520]   have actually built and deployed autonomous tractors
[00:06:19.520 --> 00:06:21.120]   that you can buy right now.
[00:06:21.120 --> 00:06:23.880]   We also see virtually every major bank using ML
[00:06:23.880 --> 00:06:26.720]   for a number of things, including fraud detection,
[00:06:26.720 --> 00:06:29.500]   which is absolutely a mission-critical application.
[00:06:29.500 --> 00:06:33.400]   And we see ML as a core enabler of new industries,
[00:06:33.400 --> 00:06:34.560]   such as satellite data.
[00:06:34.560 --> 00:06:37.720]   And we are still constantly finding
[00:06:37.720 --> 00:06:39.480]   new unexpected applications,
[00:06:39.480 --> 00:06:40.880]   like Formula 1 racing,
[00:06:40.880 --> 00:06:42.960]   where several of the teams built models
[00:06:42.960 --> 00:06:44.880]   and deployed them with Weights & Biases
[00:06:44.880 --> 00:06:46.140]   in order to get an edge.
[00:06:46.140 --> 00:06:48.660]   And in all these applications,
[00:06:48.660 --> 00:06:50.860]   there are a number of companies we are working with
[00:06:50.860 --> 00:06:53.140]   who haven't deployed their models yet.
[00:06:53.140 --> 00:06:56.300]   So our observation is that even without
[00:06:56.300 --> 00:06:57.720]   new breakthroughs in performance,
[00:06:57.720 --> 00:07:00.380]   we're on the precipice of a massive switch
[00:07:00.380 --> 00:07:01.780]   to ML in production.
[00:07:01.780 --> 00:07:04.340]   But of course, there are breakthroughs,
[00:07:04.340 --> 00:07:06.580]   like DALI and ChatGPT,
[00:07:06.580 --> 00:07:08.680]   which might seem like toys at first,
[00:07:08.680 --> 00:07:11.040]   but actually open up a massive swath
[00:07:11.040 --> 00:07:13.820]   of totally new ways to use machine learning.
[00:07:13.820 --> 00:07:15.380]   And if you don't believe me,
[00:07:15.380 --> 00:07:17.140]   or you don't think the industry cares,
[00:07:17.140 --> 00:07:19.580]   look at what happened to BuzzFeed's stock price
[00:07:19.580 --> 00:07:21.340]   when all they did was announce
[00:07:21.340 --> 00:07:24.400]   that they were thinking about working with ChatGPT.
[00:07:24.400 --> 00:07:26.940]   And this is important.
[00:07:26.940 --> 00:07:31.660]   The technology is poised to keep improving.
[00:07:31.660 --> 00:07:34.740]   Transformers, the underlying tech
[00:07:34.740 --> 00:07:37.940]   behind the big 2022 breakthroughs like DALI and GPT,
[00:07:37.940 --> 00:07:40.120]   is still getting consistently better
[00:07:40.120 --> 00:07:42.160]   as more compute is added.
[00:07:42.160 --> 00:07:44.420]   And all of our big customers are adding compute
[00:07:44.420 --> 00:07:47.020]   and training bigger models right now.
[00:07:47.020 --> 00:07:50.660]   So we expect to see a ton of further breakthroughs in 2023.
[00:07:50.660 --> 00:07:53.940]   And of course, rapid growth in production ML
[00:07:53.940 --> 00:07:56.700]   comes with serious operational challenges.
[00:07:56.700 --> 00:07:58.540]   Google was one of the first to deploy
[00:07:58.540 --> 00:08:00.460]   ML into mission-critical applications
[00:08:00.460 --> 00:08:02.540]   and wrote an ominous article called
[00:08:02.540 --> 00:08:04.940]   "Machine Learning, the High-Interest Credit Card
[00:08:04.940 --> 00:08:06.020]   of Technical Debt."
[00:08:06.020 --> 00:08:08.980]   And of course, when Google breaks,
[00:08:08.980 --> 00:08:12.200]   someone gets an irrelevant ad or Google loses money.
[00:08:12.200 --> 00:08:14.580]   When Tesla's machine learning malfunctions,
[00:08:14.580 --> 00:08:15.920]   someone could die.
[00:08:15.920 --> 00:08:17.960]   When Genentech's machine learning malfunctions,
[00:08:17.960 --> 00:08:20.720]   they could spend years investigating a worthless drug.
[00:08:20.720 --> 00:08:24.920]   Another major trend is the rapid growth
[00:08:24.920 --> 00:08:26.940]   in machine learning team size.
[00:08:26.940 --> 00:08:29.840]   Now you might ask, is this really an interesting trend?
[00:08:29.840 --> 00:08:31.000]   Machine learning engineer
[00:08:31.000 --> 00:08:33.160]   has been the fastest growing job for years.
[00:08:33.160 --> 00:08:36.120]   But most of the companies in our space
[00:08:36.120 --> 00:08:38.320]   talk about democratizing AI.
[00:08:38.320 --> 00:08:39.160]   They imagine a future
[00:08:39.160 --> 00:08:41.360]   where anyone can build machine learning models
[00:08:41.360 --> 00:08:44.200]   and machine learning engineers are really unnecessary.
[00:08:44.200 --> 00:08:45.560]   And this makes total sense.
[00:08:45.560 --> 00:08:47.600]   If you talk to execs in large companies,
[00:08:47.600 --> 00:08:51.040]   nearly all are hoping for the democratization of AI
[00:08:51.040 --> 00:08:54.140]   because ML engineers are incredibly expensive.
[00:08:54.140 --> 00:08:55.540]   And there's another big movement,
[00:08:55.540 --> 00:08:57.340]   the rise of prompt engineering.
[00:08:57.340 --> 00:09:00.160]   Some of our best customers, such as OpenAI,
[00:09:00.160 --> 00:09:02.320]   imagine a future where ML model training
[00:09:02.320 --> 00:09:03.640]   is not even necessary.
[00:09:03.640 --> 00:09:07.280]   The real skill is asking a model clearly for what you need.
[00:09:07.280 --> 00:09:08.960]   We're also in the middle of a recession,
[00:09:08.960 --> 00:09:11.240]   which has affected tech companies the most.
[00:09:11.240 --> 00:09:13.300]   Companies everywhere, especially tech,
[00:09:13.300 --> 00:09:15.960]   are looking for places to cut costs.
[00:09:15.960 --> 00:09:17.900]   So will ML teams continue to grow?
[00:09:17.900 --> 00:09:22.180]   We're betting big that the answer is yes,
[00:09:22.180 --> 00:09:25.480]   that ML teams will continue to grow in 2023
[00:09:25.480 --> 00:09:27.120]   faster than ever before.
[00:09:27.120 --> 00:09:29.640]   And one simple reason that we think that
[00:09:29.640 --> 00:09:30.760]   is that according to surveys,
[00:09:30.760 --> 00:09:32.760]   such as this one done by Credit Suisse,
[00:09:32.760 --> 00:09:37.360]   ML is the top area for enterprise budget prioritization.
[00:09:37.360 --> 00:09:41.200]   And this survey was done in the middle of 2022.
[00:09:41.200 --> 00:09:43.380]   And what happened right after the survey came out
[00:09:43.380 --> 00:09:48.200]   is that DALI, and even more importantly, ChatGPT launched.
[00:09:48.200 --> 00:09:50.540]   And this made companies like Google realize
[00:09:50.540 --> 00:09:53.440]   that falling behind in ML is an existential threat.
[00:09:53.440 --> 00:09:56.360]   Just like no successful company
[00:09:56.360 --> 00:09:58.440]   would outsource their software development,
[00:09:58.440 --> 00:10:00.400]   no successful company is going to outsource
[00:10:00.400 --> 00:10:03.600]   their ML development, leading to a massive demand
[00:10:03.600 --> 00:10:05.200]   for ML talent.
[00:10:05.200 --> 00:10:07.000]   We see this inside our customers.
[00:10:07.000 --> 00:10:10.400]   When we first talked to Genentech, they had no ML team.
[00:10:10.400 --> 00:10:14.080]   Now their team is over 100 people and growing fast.
[00:10:14.080 --> 00:10:16.080]   This is while Genentech as a business
[00:10:16.080 --> 00:10:19.320]   faces major headwinds and cuts in other places.
[00:10:19.320 --> 00:10:21.960]   ML is not an area to cut in 2023.
[00:10:21.960 --> 00:10:26.160]   Of course, as teams grow, they face new challenges.
[00:10:26.160 --> 00:10:29.080]   Building models or doing anything as a team of two
[00:10:29.080 --> 00:10:32.600]   is very different than building models as a team of 200.
[00:10:32.600 --> 00:10:35.200]   Companies need to find new ways to work together
[00:10:35.200 --> 00:10:37.600]   and keep track of what they're doing.
[00:10:37.600 --> 00:10:40.800]   The third big trend we see is the rapid growth
[00:10:40.800 --> 00:10:42.840]   of applied ML research.
[00:10:42.840 --> 00:10:45.840]   There is no doubt that the volume of ML research
[00:10:45.840 --> 00:10:47.220]   is growing exponentially.
[00:10:47.220 --> 00:10:50.880]   But does this really matter for industry?
[00:10:50.880 --> 00:10:53.040]   Historically, the purpose of research
[00:10:53.040 --> 00:10:57.080]   has been to influence industry far out into the future.
[00:10:57.080 --> 00:11:00.840]   In machine learning though, research has really emphasized
[00:11:00.840 --> 00:11:03.280]   model performance on a fixed set of data,
[00:11:03.280 --> 00:11:06.360]   which is a very unrealistic real-world scenario.
[00:11:06.360 --> 00:11:08.800]   Andrej Karpathy talked about it in his keynote
[00:11:08.800 --> 00:11:10.440]   at my last company's conference,
[00:11:10.440 --> 00:11:13.620]   noting that his focus pre and post PhD
[00:11:13.620 --> 00:11:15.600]   were incredibly different.
[00:11:15.600 --> 00:11:16.960]   But this is changing.
[00:11:16.960 --> 00:11:19.920]   Research has started to emphasize data collection
[00:11:19.920 --> 00:11:22.600]   and industry has been publishing larger and larger
[00:11:22.600 --> 00:11:24.820]   and more realistic data sets to work on.
[00:11:26.040 --> 00:11:28.120]   The state of the art is improving rapidly
[00:11:28.120 --> 00:11:30.200]   and new techniques can be the difference
[00:11:30.200 --> 00:11:32.040]   between a model working for a business purpose
[00:11:32.040 --> 00:11:33.480]   and just not being relevant.
[00:11:33.480 --> 00:11:36.560]   And research has started to really emphasize
[00:11:36.560 --> 00:11:38.020]   things that companies care about,
[00:11:38.020 --> 00:11:41.020]   like model explainability, production monitoring, and more.
[00:11:41.020 --> 00:11:43.600]   There's also a wonderful trend
[00:11:43.600 --> 00:11:45.480]   where academic papers' authors
[00:11:45.480 --> 00:11:48.440]   now typically produce useful code with their papers
[00:11:48.440 --> 00:11:50.000]   that makes it really practical
[00:11:50.000 --> 00:11:53.360]   for industry to immediately adopt what they're doing.
[00:11:53.360 --> 00:11:55.240]   And we're also seeing paper authors
[00:11:55.240 --> 00:11:57.320]   publish their weights and biases experiments
[00:11:57.320 --> 00:11:59.980]   to help someone pick up where they left off.
[00:11:59.980 --> 00:12:03.140]   So what does this trend mean?
[00:12:03.140 --> 00:12:05.700]   Well, what we're seeing is that technologies change
[00:12:05.700 --> 00:12:08.760]   inside companies faster than ever before.
[00:12:08.760 --> 00:12:12.160]   First, PyTorch replaced TensorFlow inside our customers
[00:12:12.160 --> 00:12:14.320]   because our customers wanted to quickly adopt
[00:12:14.320 --> 00:12:17.520]   research papers published in PyTorch.
[00:12:17.520 --> 00:12:20.880]   This was a major change inside many, many companies.
[00:12:20.880 --> 00:12:23.760]   But now, this is happening all the time
[00:12:23.760 --> 00:12:25.980]   as companies rapidly adopt new technologies
[00:12:25.980 --> 00:12:28.640]   like Hugging Face and new techniques.
[00:12:28.640 --> 00:12:31.740]   Will companies be able to keep up with this rate of change?
[00:12:31.740 --> 00:12:34.960]   In summary, we see three important trends
[00:12:34.960 --> 00:12:38.120]   and three big emerging needs in the ML space.
[00:12:38.120 --> 00:12:40.680]   Rapid growth in real-world production ML
[00:12:40.680 --> 00:12:43.640]   leading to a deep need for standardization
[00:12:43.640 --> 00:12:46.420]   and reliability in ML deployments.
[00:12:46.420 --> 00:12:48.960]   Rapid growth in the size of ML teams
[00:12:48.960 --> 00:12:50.840]   forcing teams to learn new ways
[00:12:50.840 --> 00:12:53.520]   to collaborate on ML projects at scale.
[00:12:53.520 --> 00:12:56.240]   And rapid growth in applied ML research
[00:12:56.240 --> 00:12:58.740]   causing an incredible amount of pressure
[00:12:58.740 --> 00:13:01.200]   to adapt and change workflows rapidly
[00:13:01.200 --> 00:13:02.840]   as the state of the art improves.
[00:13:02.840 --> 00:13:06.780]   So what is Weights & Biases doing about this?
[00:13:06.780 --> 00:13:09.960]   Let's talk about the issues one by one
[00:13:09.960 --> 00:13:12.280]   starting with the need for best practices
[00:13:12.280 --> 00:13:13.800]   around ML and production.
[00:13:13.800 --> 00:13:18.820]   Now, ML and production has been the focus of my career.
[00:13:18.820 --> 00:13:20.520]   Since we've started Weights & Biases,
[00:13:20.520 --> 00:13:21.840]   we've been working on building
[00:13:21.840 --> 00:13:24.320]   an end-to-end industrial strength workflow
[00:13:24.320 --> 00:13:25.780]   that our customers can use.
[00:13:25.780 --> 00:13:29.280]   Our approach has always been to build useful tools
[00:13:29.280 --> 00:13:31.640]   one at a time to serve real pain points
[00:13:31.640 --> 00:13:34.980]   and then make them work together as a cohesive platform.
[00:13:34.980 --> 00:13:39.240]   We've also launched a class called Effective ML Ops
[00:13:39.240 --> 00:13:42.280]   on best practices for deploying ML in the real world
[00:13:42.280 --> 00:13:45.280]   that includes all the learnings we've had from our customers
[00:13:45.280 --> 00:13:47.780]   and we've made it available to the world for free.
[00:13:47.780 --> 00:13:51.520]   We've moved our popular model registry
[00:13:51.520 --> 00:13:53.760]   a critical piece of ML Ops infrastructure
[00:13:53.760 --> 00:13:55.440]   into general availability
[00:13:55.440 --> 00:13:57.600]   and we'll be talking more about this today.
[00:13:57.600 --> 00:14:01.080]   We've launched a product called Launch
[00:14:01.080 --> 00:14:03.360]   that can be triggered off of the model registry
[00:14:03.360 --> 00:14:07.080]   and helps customers build reliable CI/CD platforms
[00:14:07.080 --> 00:14:07.920]   for ML products
[00:14:07.920 --> 00:14:11.240]   and we'll also talk about that a lot more today.
[00:14:11.240 --> 00:14:13.160]   What about collaboration?
[00:14:13.160 --> 00:14:15.400]   This is what Weights & Biases has been known for
[00:14:15.400 --> 00:14:16.840]   and we've gotten an early look
[00:14:16.840 --> 00:14:18.980]   at the collaboration challenges that happen
[00:14:18.980 --> 00:14:21.640]   with huge customers like Toyota and NVIDIA
[00:14:21.640 --> 00:14:24.200]   who each have over 500 ML engineers
[00:14:24.200 --> 00:14:26.600]   collaborating daily on our platform.
[00:14:26.600 --> 00:14:29.200]   The most important feature for collaboration
[00:14:29.200 --> 00:14:31.560]   that we've had since the beginning is reports
[00:14:31.560 --> 00:14:34.860]   and actually only 10% of our users make use of them
[00:14:34.860 --> 00:14:36.920]   but we think it's one of the most critical things
[00:14:36.920 --> 00:14:38.160]   that we offer.
[00:14:38.160 --> 00:14:39.760]   Nearly everyone that tries it
[00:14:39.760 --> 00:14:43.160]   says they can't imagine how they worked without it.
[00:14:43.160 --> 00:14:45.800]   We added long requested universal search
[00:14:45.800 --> 00:14:47.960]   to help teams find all the important insights
[00:14:47.960 --> 00:14:49.000]   they're generating.
[00:14:49.000 --> 00:14:53.320]   We've added now the ability to generate reports
[00:14:53.320 --> 00:14:55.080]   completely through an API
[00:14:55.080 --> 00:14:57.680]   which hopefully will encourage more ML engineers
[00:14:57.680 --> 00:14:59.120]   to automatically make them.
[00:14:59.120 --> 00:15:03.840]   Finally, what are we doing about the pressing need
[00:15:03.840 --> 00:15:06.180]   to integrate the latest ML research?
[00:15:06.180 --> 00:15:09.960]   We've always been passionate about integrating research
[00:15:09.960 --> 00:15:11.000]   into our platform
[00:15:11.000 --> 00:15:13.420]   so that our users could have easy access to it.
[00:15:13.420 --> 00:15:15.820]   For example, our parameter importance panel
[00:15:15.820 --> 00:15:17.720]   is something I personally worked on
[00:15:17.720 --> 00:15:19.280]   and it builds a random forest
[00:15:19.280 --> 00:15:20.960]   on top of your hyper parameters
[00:15:20.960 --> 00:15:24.260]   to predict how they affect an output parameter.
[00:15:24.260 --> 00:15:25.960]   It's something that ML engineers have done
[00:15:25.960 --> 00:15:28.800]   on an ad hoc basis for quite a long time
[00:15:28.800 --> 00:15:31.120]   but now it makes it trivial to access this
[00:15:31.120 --> 00:15:33.880]   and it makes this technique more useful.
[00:15:33.880 --> 00:15:36.060]   We have a fantastic embedding projector
[00:15:36.060 --> 00:15:37.760]   that's useful across many domains
[00:15:37.760 --> 00:15:40.160]   and we've made a lot of improvements to it recently.
[00:15:40.160 --> 00:15:42.820]   But the big internal project is Weave,
[00:15:42.820 --> 00:15:45.000]   something you can see in parts of our platform
[00:15:45.000 --> 00:15:47.600]   where you can actually go in and edit the data
[00:15:47.600 --> 00:15:50.200]   that your panels are using directly.
[00:15:50.200 --> 00:15:52.960]   We plan to open this up in a big way
[00:15:52.960 --> 00:15:55.640]   and allow for more flexible use of our platform
[00:15:55.640 --> 00:15:57.700]   so that researchers can publish their work
[00:15:57.700 --> 00:15:59.360]   directly into Weights & Biases
[00:15:59.360 --> 00:16:02.220]   and give everyone simple access to it.
[00:16:02.220 --> 00:16:03.920]   Now, we're just getting started
[00:16:03.920 --> 00:16:06.300]   and we're still listening to all of you.
[00:16:06.300 --> 00:16:08.440]   Most of our good ideas have come from our users
[00:16:08.440 --> 00:16:10.280]   and we hope that you'll tell us what you need
[00:16:10.280 --> 00:16:11.880]   so that we can serve you better.
[00:16:11.880 --> 00:16:14.560]   If you want even more detail
[00:16:14.560 --> 00:16:16.420]   on what's going on in the ML space,
[00:16:16.420 --> 00:16:18.220]   we've made a lot of our interviews public
[00:16:18.220 --> 00:16:20.920]   with a podcast that we do called Gradient Descent.
[00:16:20.920 --> 00:16:23.720]   And it's had everyone from Jensen, the CEO of NVIDIA,
[00:16:23.720 --> 00:16:25.560]   to Berkeley professor Peter Abbeel,
[00:16:25.560 --> 00:16:27.960]   to Clem, the CEO of Hugging Face.
[00:16:27.960 --> 00:16:30.440]   At the end of every episode, I ask guests,
[00:16:30.440 --> 00:16:33.320]   what's the hardest part about making machine learning work
[00:16:33.320 --> 00:16:34.600]   in the real world?
[00:16:34.600 --> 00:16:35.920]   And it's the same question
[00:16:35.920 --> 00:16:38.520]   I want to ask all of you right now.
[00:16:38.520 --> 00:16:40.680]   Making ML work reliably in production
[00:16:40.680 --> 00:16:42.880]   is the big challenge our industry faces
[00:16:42.880 --> 00:16:45.400]   and it's the point of this conference.
[00:16:45.400 --> 00:16:46.900]   Let's figure out together
[00:16:46.900 --> 00:16:48.640]   how to turn these research breakthroughs
[00:16:48.640 --> 00:16:50.400]   into fantastic products.
[00:16:50.400 --> 00:16:52.980]   (upbeat music)
[00:16:52.980 --> 00:16:55.560]   (upbeat music)
[00:16:55.560 --> 00:16:58.320]   (logo whooshing)

