
[00:00:00.000 --> 00:00:01.120]   Nick, can you cue the tape?
[00:00:01.120 --> 00:00:04.880]   This is now the worst form of a shot. Oh my god.
[00:00:04.880 --> 00:00:09.840]   I mean, the fact that he hit the rim is a miracle.
[00:00:09.840 --> 00:00:12.720]   The most unathletic, what is, oh god.
[00:00:12.720 --> 00:00:15.760]   Wish we could get slow motion on that.
[00:00:15.760 --> 00:00:21.440]   Look at his hand, look at the right hand, look.
[00:00:21.440 --> 00:00:24.560]   What is that about?
[00:00:24.560 --> 00:00:25.840]   One hand is.
[00:00:25.840 --> 00:00:29.840]   I mean, that has nothing to do with basketball.
[00:00:29.840 --> 00:00:35.680]   It was the most unnatural basketball/athletic movement I've seen.
[00:00:35.680 --> 00:00:36.800]   Come on, wasn't that bad?
[00:00:36.800 --> 00:00:41.280]   I mean, the lean forward too.
[00:00:41.280 --> 00:00:46.400]   The lean forward, the kind of like sassy jump, you know, the sassy jump.
[00:00:46.400 --> 00:00:47.600]   A little sashay.
[00:00:47.600 --> 00:00:50.000]   He little sashayed on the side there. It's nice.
[00:00:50.000 --> 00:01:12.000]   All right, everybody, welcome to the all-in podcast with me again,
[00:01:12.000 --> 00:01:17.680]   the chairman dictator Chamath Palihapitiya, David Freeberg, the sultan of science,
[00:01:18.240 --> 00:01:20.880]   and the rain man himself named Sachs.
[00:01:20.880 --> 00:01:24.080]   Our first topic, we'll go to our war correspondent.
[00:01:24.080 --> 00:01:28.800]   The US and its allies have struck Houthi targets in Yemen. Sachs?
[00:01:28.800 --> 00:01:33.120]   Well, we talked about this two weeks ago on the show, and we talked about it as a
[00:01:33.120 --> 00:01:37.520]   escalatory risk in the Middle East back then, and I think that that is playing out now.
[00:01:37.520 --> 00:01:45.040]   We fired, I don't know, maybe 100 rockets and missiles at Yemen last night.
[00:01:45.760 --> 00:01:53.040]   The purpose of the strike is to restore deterrence and, I guess, try and prevent the Houthis from
[00:01:53.040 --> 00:01:58.800]   attacking commercial shipping in the Red Sea, but that deterrence is not working.
[00:01:58.800 --> 00:02:05.040]   I mean, there was already a new attack by the Houthis this morning of a commercial ship in the
[00:02:05.040 --> 00:02:09.760]   Red Sea. So, I don't think this is going to have any impact other than to escalate the conflict in
[00:02:09.760 --> 00:02:17.440]   the Middle East and put us on a path to war with Iran, which is really where the neocons want to
[00:02:17.440 --> 00:02:22.720]   take us. You've heard, obviously, the warmongers like Lindsey Graham are calling for that, but
[00:02:22.720 --> 00:02:27.520]   even Speaker Mike Johnson is talking about that. I think that's where this is all headed is a
[00:02:27.520 --> 00:02:31.920]   larger war in the Middle East that features the US and Israel going to war with Iran.
[00:02:31.920 --> 00:02:33.920]   I think we should all be very concerned about that, actually.
[00:02:33.920 --> 00:02:40.480]   >> But, I mean, you have to be fair. It's not just the US, right? It's now the US, the UK,
[00:02:40.480 --> 00:02:47.680]   Israel, Qatar, UAE, and Saudi against the Houthi rebels. That's a big alliance,
[00:02:47.680 --> 00:02:54.800]   and you've got to think that Iran will think very carefully about how close they want to get to the
[00:02:54.800 --> 00:03:01.040]   Houthis in the middle of all of this because that's a huge armada, if you will, of countries
[00:03:01.040 --> 00:03:03.920]   that I don't think you really want to cross as a group.
[00:03:03.920 --> 00:03:09.440]   >> Well, I think Saudi Arabia and UAE are playing this very carefully, I think. They did not
[00:03:09.440 --> 00:03:16.000]   participate in the strikes. They did allow the US to fly overhead or to use its territory,
[00:03:16.000 --> 00:03:22.160]   but they released a statement calling for restraint and de-escalation. So I think they're
[00:03:22.160 --> 00:03:26.880]   very nervous about this blowing up into a wider regional war. I don't think they want that.
[00:03:27.840 --> 00:03:33.840]   The allies who participated in the campaign of airstrikes were UK, Australia, Canada,
[00:03:33.840 --> 00:03:37.680]   Netherlands, and Bahrain, but I don't think they actually did anything. I don't think
[00:03:37.680 --> 00:03:41.840]   they contributed any assets. They just provided their names to this operation
[00:03:41.840 --> 00:03:45.760]   and provided some diplomatic cover. Freeberg, any thoughts?
[00:03:45.760 --> 00:03:50.800]   >> Well, Sax, you posted a comment on Twitter, which I wanted to respond to,
[00:03:51.680 --> 00:03:57.600]   where you said China has the largest shipping volume through the Red Sea,
[00:03:57.600 --> 00:04:03.680]   and they're staying out of this conflict, letting the US do the dirty work. But the Houthis didn't
[00:04:03.680 --> 00:04:07.760]   attack Chinese ships. They specifically attacked Western ships. Isn't that correct? I mean,
[00:04:07.760 --> 00:04:12.560]   this is a very targeted, disruptive event that the Houthis have been undertaking for some time now.
[00:04:12.560 --> 00:04:18.160]   And they're using these very interesting tactics with drones that can be very destructive and very
[00:04:18.160 --> 00:04:22.320]   hard to block, and doing it not at Chinese ships, but at a very targeted enemy.
[00:04:22.320 --> 00:04:26.800]   >> Right. Well, what the Houthis have said is that they're only attacking ships that are either
[00:04:26.800 --> 00:04:33.280]   Israeli or going to Israel. But in reality, they've attacked a much wider range than that.
[00:04:33.280 --> 00:04:34.320]   >> But not Chinese.
[00:04:34.320 --> 00:04:40.080]   >> It may be true that they haven't attacked ships that are declaring themselves to be
[00:04:40.080 --> 00:04:45.520]   Chinese ships or Russian ships. However, there are more Chinese shipping containers
[00:04:46.400 --> 00:04:51.600]   on all of the ships that are going through the Red Sea and the Suez Canal than any other country.
[00:04:51.600 --> 00:04:55.200]   So there's no question that if we're talking about the disruption of global trade,
[00:04:55.200 --> 00:05:01.040]   this is going to have a big impact on Chinese trade, whether it's on Chinese ships or not.
[00:05:01.040 --> 00:05:05.000]   >> Or it could benefit them, because they can get through that shipping lane and the West cannot.
[00:05:05.000 --> 00:05:09.600]   >> Their own ships can get through, but foreign ships, European ships that have
[00:05:09.600 --> 00:05:13.920]   Chinese shipping containers on them are not getting through. So their trade is still getting
[00:05:13.920 --> 00:05:20.640]   disrupted. And nevertheless, they don't feel the need to engage in this militaristic response or
[00:05:20.640 --> 00:05:20.960]   participate in that.
[00:05:20.960 --> 00:05:25.760]   >> So in terms of understanding implications of the escalation in this conflict, let's just
[00:05:25.760 --> 00:05:31.040]   quickly talk about, number one, I'm assuming shipping prices are going to go up, freight
[00:05:31.040 --> 00:05:34.720]   prices are going to go up. But hold on a second. We talked about this with Ryan. Remember the
[00:05:34.720 --> 00:05:38.480]   question that I asked him. This is really an issue for Europe. It's not an issue for the United
[00:05:38.480 --> 00:05:42.560]   States, because there are alternative routes. You can go through the Pacific and you can go down
[00:05:42.560 --> 00:05:49.200]   through the bottom of Africa. And all that does is add like a 5% or 10% increase. So what we're
[00:05:49.200 --> 00:05:56.080]   really debating is what is the risk of inflation and a backup of goods and shipping rates into
[00:05:56.080 --> 00:06:01.280]   Europe? And this is why I don't understand why America needs to even get involved. I understand
[00:06:01.280 --> 00:06:07.440]   why the Netherlands and the UK and France and all these folks need to send resources to unclog this.
[00:06:07.440 --> 00:06:14.000]   That makes a lot of sense. But I don't see why the U.S. needs to be involved. Other than
[00:06:14.000 --> 00:06:17.680]   providing moral support or logistical support, what is the point?
[00:06:17.680 --> 00:06:23.120]   >> Well, Chamath, this is exactly my point, is the number one type of trade that's going
[00:06:23.120 --> 00:06:30.480]   through the Red Sea are shipping containers from China going to European ports. And as
[00:06:30.480 --> 00:06:33.920]   a result of what the Houthis are doing, it's having to go around the Horn of Africa, it's
[00:06:33.920 --> 00:06:38.640]   adding two or three weeks to the trip, and it's raising the cost of a shipping container from
[00:06:38.640 --> 00:06:45.840]   China from, say, $1,500 to $3,000. It's Europe and China who are impacted the most. But for some
[00:06:45.840 --> 00:06:50.720]   reason, it's the U.S. that decides it has to take the lead in doing this. And the problem is that,
[00:06:50.720 --> 00:06:57.680]   first of all, the action is futile. I mean, the Houthis have been at war on and off with the
[00:06:57.680 --> 00:07:03.040]   Saudis for a decade, and the Saudis have been backed by Western weapons. And we have not been
[00:07:03.040 --> 00:07:08.560]   able to defeat the Houthis. So this missile strike last night is not going to deter them. It's not
[00:07:08.560 --> 00:07:13.360]   going to stop them. They're very determined, very tough fighters. Second, they are going to be
[00:07:13.360 --> 00:07:18.960]   looking for retaliation. They're going to be looking for blowback. And Chamath, to your point,
[00:07:18.960 --> 00:07:22.480]   they're not going to be looking for retaliation against China or Europe. They're going to be
[00:07:22.480 --> 00:07:28.560]   looking at it against the United States. So we're incurring this cost and risk onto ourselves.
[00:07:28.560 --> 00:07:35.920]   So let me put this question to you, then. We have no obvious economic incentive to get involved,
[00:07:35.920 --> 00:07:41.280]   because we can sustain our economy through different shipping ports that at best raise
[00:07:41.280 --> 00:07:46.480]   rates 5% or 10%, right? We can absorb that in the economy. 100%, which could drive inflation,
[00:07:46.480 --> 00:07:51.360]   is a European problem. So there's no economic incentive necessarily to get involved. So
[00:07:51.360 --> 00:07:56.480]   what is the incentive? It feels like, not to play conspiracy theorist, but like a
[00:07:57.280 --> 00:08:01.920]   wag the dog moment, another distraction to add to the plate.
[00:08:01.920 --> 00:08:07.200]   What do you think about that line of thinking? I tweeted something just like that.
[00:08:07.200 --> 00:08:12.880]   This does feel... It's a wag the dog in the sense that the Biden administration was looking...
[00:08:12.880 --> 00:08:14.720]   You want to explain the reference for folks that may not get it?
[00:08:14.720 --> 00:08:18.240]   Yeah. There's a movie called Wag the Dog that came out in the early '90s, where
[00:08:18.240 --> 00:08:24.560]   the president is up for re-election, and there's a horrible scandal that's about to come out,
[00:08:24.560 --> 00:08:29.600]   like a Monica Lewinsky-type scandal. This is before Monica Lewinsky, by the way, but it really
[00:08:29.600 --> 00:08:34.640]   was sort of one of those movies that kind of predicted the future. But in any event, the
[00:08:34.640 --> 00:08:42.080]   president's trying to avoid this Monica Lewinsky-type scandal. And so the political aides and advisors
[00:08:42.080 --> 00:08:47.040]   decide the way to do that is to start a war. But they don't start a real war. They basically
[00:08:47.040 --> 00:08:53.440]   manufacture a fake war on a soundstage and in a movie studio. And it's pretty hilarious how
[00:08:53.440 --> 00:08:57.600]   they keep the whole thing going. David Mamet, who's a brilliant, brilliant writer, wrote that
[00:08:57.600 --> 00:09:03.280]   script. But this movie came out right around the time of the Lewinsky scandal with Clinton.
[00:09:03.280 --> 00:09:06.560]   And so therefore, it took on this larger political and cultural significance.
[00:09:06.560 --> 00:09:07.360]   Yeah. It's been used...
[00:09:07.360 --> 00:09:12.400]   So, yeah. So, Wag the Dog is, you know, you basically start a war because of the political
[00:09:12.400 --> 00:09:17.920]   benefits as opposed to the real necessity of going to war. And I think you can make that
[00:09:17.920 --> 00:09:22.400]   accusation here, Chamath, because I think that the Biden administration was looking impotent. I mean,
[00:09:22.400 --> 00:09:26.240]   they were basically telling the Houthis to stop. They were pleading with them to stop interfering
[00:09:26.240 --> 00:09:31.280]   with international shipping. The Houthis weren't listening. By the way, the reason why the Houthis
[00:09:31.280 --> 00:09:36.000]   are doing this is they're doing it in solidarity with the Palestinians in Gaza. They've demanded
[00:09:36.000 --> 00:09:40.880]   that the Israeli invasion of Gaza stop and humanitarian aid be let in. And they're not
[00:09:40.880 --> 00:09:45.360]   going to stop interfering with global trade until that happens. So, that's the Houthis position.
[00:09:45.360 --> 00:09:50.560]   The Biden administration has been telling them to stop. And I think that they were looking
[00:09:50.560 --> 00:09:55.760]   increasingly feckless and impotent. And that's why they did this strike.
[00:09:55.760 --> 00:09:56.320]   Well, is it that...
[00:09:56.320 --> 00:10:02.000]   The problem is that the strike's not going to have any impact. And so, what's the point?
[00:10:02.000 --> 00:10:06.080]   Well, is it that or is it that I think if you take the Wag the Dog analogy
[00:10:06.080 --> 00:10:10.560]   to the limit, I think maybe a different interpretation, I'm not saying that they
[00:10:10.560 --> 00:10:15.520]   did this, but a different interpretation of that analogy would be that they are struggling
[00:10:15.520 --> 00:10:19.760]   domestically. And I think J-Cal tweeted this, but if you look at the polls and you look at
[00:10:19.760 --> 00:10:23.360]   Dean Phillips all of a sudden, and you look at what's happening on the Republican side,
[00:10:23.360 --> 00:10:33.920]   there's so much activity and momentum, frankly, for non-Biden candidates all across the board
[00:10:33.920 --> 00:10:39.520]   that that would be the most Wag the Dog explanation, in my opinion, which is like
[00:10:39.520 --> 00:10:45.280]   to distract folks from the domestic malaise by pointing someplace far away and saying,
[00:10:45.280 --> 00:10:49.360]   "We're doing something very righteous here. Let's all get on the same page and support us."
[00:10:49.360 --> 00:10:55.360]   How does that logically make sense, Jamal, if the US is against wars and people are tired of wars?
[00:10:55.360 --> 00:11:00.160]   Like, what would be the... This is the only problem I have with the logic of the Wag the Dog theory
[00:11:00.160 --> 00:11:02.320]   is nobody wants wars.
[00:11:02.320 --> 00:11:04.080]   Who's against wars, Jason?
[00:11:04.080 --> 00:11:08.240]   The American people. They've been very much against starting foreign wars. We've talked
[00:11:08.240 --> 00:11:09.120]   about it here, so...
[00:11:09.120 --> 00:11:11.360]   Let's talk about the people that run the country.
[00:11:11.360 --> 00:11:16.000]   No, I know that. So, but if you're saying they're doing it, the logic here is Wag the Dog is to
[00:11:16.000 --> 00:11:21.680]   curry favor. Sax, you said they're rallying. This is to rally the American people around like a
[00:11:21.680 --> 00:11:29.040]   patriotic cause. But this isn't like a 9/11 situation where Bush got a lot of credibility
[00:11:29.040 --> 00:11:33.280]   for saying, "Hey, we're going to go get these terrorists." Americans don't want more wars
[00:11:33.280 --> 00:11:37.040]   right now. The polling is very specific on that. So then, I guess, Sax, what is the
[00:11:37.040 --> 00:11:42.480]   logic there to Wag the Dog if this is something American people don't want?
[00:11:43.120 --> 00:11:48.080]   Well, I think you're right, Jason, in the sense that the American people are exhausted by wars,
[00:11:48.080 --> 00:11:53.520]   especially Middle Eastern wars. We've just gotten out of two decades of endless forever wars in the
[00:11:53.520 --> 00:11:58.800]   Middle East, and I don't think the majority of the American people want to get back in.
[00:11:58.800 --> 00:12:03.600]   So, I think you're right on that level. And it's true that if you were to poll the American people
[00:12:03.600 --> 00:12:07.440]   and ask them, "Are you in favor of getting in more wars?" They would say, "No." The problem is
[00:12:08.080 --> 00:12:13.600]   that with every war, the mainstream media starts propagandizing for the wars, and they'll basically
[00:12:13.600 --> 00:12:19.280]   demonize whoever it is that we're going to go to war with and explaining why they're a huge
[00:12:19.280 --> 00:12:24.240]   threat. They'll engage in threat inflation. And so, the American people end up supporting it.
[00:12:24.240 --> 00:12:29.120]   So, we're against war in the abstract, but in every particular case, we end up supporting it.
[00:12:29.120 --> 00:12:32.880]   That's what happened with Ukraine. It's even happening right now. If you look at polling
[00:12:32.880 --> 00:12:37.600]   for this Hootie conflict, I think most Americans believe it's a good thing to strike the Hooties.
[00:12:38.560 --> 00:12:43.040]   So, yeah, they're against it in the abstract, but in each particular case,
[00:12:43.040 --> 00:12:48.480]   the media is able to manufacture consent for the U.S. involvement.
[00:12:48.480 --> 00:12:57.600]   So, just to challenge that as well. So, now our theory is, or your theory is, the media plus the
[00:12:57.600 --> 00:13:05.280]   Biden administration are in cahoots to wag the dog, create this support of a war in order to
[00:13:05.280 --> 00:13:11.680]   distract from domestic issues in order to curry favor with the American public that doesn't really
[00:13:11.680 --> 00:13:15.520]   want more wars. That's where I'm saying, like, I think wag the dog might have been something 20
[00:13:15.520 --> 00:13:22.160]   years ago, like you're saying, that could work as a technique, but I can't imagine anybody would
[00:13:22.160 --> 00:13:28.960]   want to do more military action at this point in time when the American public is exhausted from
[00:13:28.960 --> 00:13:33.360]   it, which is what you've said for the last six months on this podcast. Yeah, look, I tweeted
[00:13:33.360 --> 00:13:37.280]   exactly that sentiment is that I don't think wagging the dog is going to work. I think there'll
[00:13:37.280 --> 00:13:44.880]   be a short-term rally around the flag effect, but I think that overall, if this conflict is still
[00:13:44.880 --> 00:13:49.840]   going on in November, it's going to weaken Biden by making him look like a president who's lost
[00:13:49.840 --> 00:13:56.240]   control of events. So, I agree with you that ultimately the perpetuation of this conflict
[00:13:56.240 --> 00:14:01.760]   is not ultimately in Biden's interest. Now, nonetheless, it may factor into their
[00:14:01.760 --> 00:14:06.000]   political calculation that in the short-term, they think this makes them look good.
[00:14:06.000 --> 00:14:10.080]   - That would seem super incompetent as, like, a political strategy to me.
[00:14:10.080 --> 00:14:14.480]   - Well, I mean, this is not, I mean, despite the fact that this administration claimed to be the
[00:14:14.480 --> 00:14:18.560]   foreign policy grown-ups, they haven't shown a lot of competence. They couldn't even find
[00:14:18.560 --> 00:14:22.320]   Lloyd Austin, who was the Secretary of Defense for five days. I mean, no one knew where he was.
[00:14:22.320 --> 00:14:23.520]   - That's the one that happened.
[00:14:23.520 --> 00:14:29.120]   - No, he checked into the hospital for a procedure and no one could find him for several days.
[00:14:29.120 --> 00:14:32.480]   And there was an article, I think, on CNN talking about how he was managing
[00:14:32.480 --> 00:14:34.320]   this Hootie strike from his hospital bed.
[00:14:34.320 --> 00:14:37.200]   - Yeah, that was weird.
[00:14:37.200 --> 00:14:39.600]   - I hope the man's okay. I don't want, you know, but…
[00:14:39.600 --> 00:14:41.280]   - He's got prostate cancer.
[00:14:41.280 --> 00:14:42.880]   - I know. It's, that's sad, but…
[00:14:42.880 --> 00:14:45.360]   - And he had a UTI. He had a UTI. That's why he was in the hospital.
[00:14:45.360 --> 00:14:47.600]   - But fair enough, but no one in the White House,
[00:14:47.600 --> 00:14:49.440]   the White House couldn't find him for a couple of days.
[00:14:49.440 --> 00:14:51.200]   - Is that true, they couldn't find him?
[00:14:51.200 --> 00:14:51.440]   - Yes.
[00:14:51.440 --> 00:14:54.560]   - I mean, having a UTI is a very benign kind of thing, right?
[00:14:54.640 --> 00:14:59.680]   - Well, he had a prostatectomy and then he got discharged from the hospital.
[00:14:59.680 --> 00:15:05.440]   And somewhere along the way, he got a UTI, which was severe, apparently.
[00:15:05.440 --> 00:15:05.840]   - Oh, okay.
[00:15:05.840 --> 00:15:09.520]   - Went back to Walter Reed. And yeah, in those three or four days,
[00:15:09.520 --> 00:15:16.880]   the handoff of power to his deputy happened. She was on vacation on a beach somewhere.
[00:15:16.880 --> 00:15:21.840]   So, and you're right, the, and the problem was that the other person,
[00:15:21.840 --> 00:15:26.320]   the chief of staff had the flu. So, they couldn't escalate to the White House. So,
[00:15:26.320 --> 00:15:29.760]   it was like a comedy of errors, but I don't think it was anything.
[00:15:29.760 --> 00:15:35.520]   - But I mean, imagine if you were like a C-level executive at a company,
[00:15:35.520 --> 00:15:39.760]   and you're going to be out of the office for a few days and unreachable,
[00:15:39.760 --> 00:15:44.880]   you would set up a clear chain of command. You'd have a deputy who the CEO could get
[00:15:44.880 --> 00:15:49.840]   ahold of if necessary. In this case, you've got the Secretary of Defense who,
[00:15:49.840 --> 00:15:54.560]   if the United States was attacked in some way, is part of the chain of command. The president
[00:15:54.560 --> 00:15:58.240]   would need that person in the situation room. So, the fact that they couldn't find him for
[00:15:58.240 --> 00:16:02.480]   a couple of days is really, I think, unforgivable. How does that even happen?
[00:16:02.480 --> 00:16:05.840]   - Is that really true that they couldn't find him? Like, they literally could not call-
[00:16:05.840 --> 00:16:08.400]   - They didn't know where he was for a couple of days. This was widely reported.
[00:16:08.400 --> 00:16:12.880]   - But they couldn't call him on his cell phone or his chief of staff or the-
[00:16:12.880 --> 00:16:14.080]   - Nobody knew where he was.
[00:16:15.040 --> 00:16:17.840]   - Ah, wow. Yeah, okay.
[00:16:17.840 --> 00:16:19.120]   - All right. Very good.
[00:16:19.120 --> 00:16:24.240]   - Having kept up on the details of his UTI and his cancer, I hope he's okay.
[00:16:24.240 --> 00:16:32.400]   So, segwaying into markets, the likelihood of a Q1 rate cut is not looking good. We had a slightly
[00:16:32.400 --> 00:16:37.920]   hotter than expected December CPI interest rates hit a 22-year high in July, as everybody knows,
[00:16:37.920 --> 00:16:43.520]   when the Fed raised the range from 5.25 to 5.5. But they've left rates unchanged,
[00:16:43.520 --> 00:16:51.920]   if you haven't been following it, as inflation has cooled. But in December, the CPI rose 3.4%
[00:16:51.920 --> 00:16:57.920]   from a year earlier. That was just a slight tick above. And, of course, markets are wondering,
[00:16:57.920 --> 00:17:05.440]   is this going to be a glide path into a soft landing, or could it be choppy going forward?
[00:17:05.440 --> 00:17:10.960]   Freeberg, higher for longer interest rates, you think that's still going to be the case?
[00:17:10.960 --> 00:17:13.520]   And what are your thoughts going into the new year?
[00:17:13.520 --> 00:17:20.240]   - Well, Larry Summers put out a note saying that he thinks that the rates are going to stay higher
[00:17:20.240 --> 00:17:26.080]   than the market is predicting based on the yield curve right now. So, I think the market's
[00:17:26.080 --> 00:17:36.560]   currently saying no cuts in March and high probability of cuts in June. But some folks
[00:17:36.560 --> 00:17:42.080]   like Larry are saying it might be longer because inflation is very sticky. And if you look at the
[00:17:42.080 --> 00:17:48.640]   breakdown on the drivers of inflation, you start to think about what's the underlying business
[00:17:48.640 --> 00:17:54.480]   activity that's going on, like car insurance went up by 20%, which was one of the key drivers.
[00:17:55.360 --> 00:18:03.440]   And car insurance has always been this lagging indicator, but it does ultimately drive costs up
[00:18:03.440 --> 00:18:08.080]   later. The reason car insurance rates go up is because the cost to repair a car goes up and the
[00:18:08.080 --> 00:18:12.480]   cost for medical care goes up. When that happens, the insurance companies actually have to file with
[00:18:12.480 --> 00:18:17.200]   state regulators to get approval to raise their rates. And it can take over a year for the
[00:18:17.200 --> 00:18:22.000]   regulators to then approve those raising of rates. So, by the time the rates get raised,
[00:18:22.640 --> 00:18:27.840]   the other factors have maybe leveled out, but you're still going to have some elements of
[00:18:27.840 --> 00:18:32.880]   costs that are going to continue to climb for some period of time after you get the core engine
[00:18:32.880 --> 00:18:39.440]   tuned down. So, these are the sorts of things that I think we're seeing in the current CPI data
[00:18:39.440 --> 00:18:44.480]   is that there are some of these lagging effects of an overheated economy or overstimulated economy
[00:18:44.480 --> 00:18:49.280]   that are now starting to play through. And so, there's a number of these, it's not just car
[00:18:49.280 --> 00:18:51.680]   insurance, but there's a lot of things that are going to linger for a while, and they're going
[00:18:51.680 --> 00:18:55.680]   to be very hard to work their way through the system very quickly. And as a result,
[00:18:55.680 --> 00:18:58.480]   it may be the case that rates are going to need to stay higher for longer.
[00:18:58.480 --> 00:19:01.440]   I think the thing with inflation that is worth noting is that
[00:19:01.440 --> 00:19:05.280]   a couple of things are true at the same time, which I think is interesting.
[00:19:05.280 --> 00:19:13.200]   I think we were the ones in May of 21 that started getting very antsy around inflation,
[00:19:13.200 --> 00:19:17.840]   and we started to look at the five and 10 year break evens. Do you guys remember that we would
[00:19:17.840 --> 00:19:24.720]   like to look at that chart a lot? And I think it was very predictive. We also used to look at the
[00:19:24.720 --> 00:19:31.840]   future oil curve, not that we're macro economists, but I think it's useful if average everyday
[00:19:31.840 --> 00:19:37.280]   people can have a few things to look at. If you look at those things today, it tells you
[00:19:37.280 --> 00:19:42.480]   the same picture, which is inflation has cooled, we're going through the last
[00:19:43.600 --> 00:19:50.000]   kind of like rows of some of the random variables still being a little sticky,
[00:19:50.000 --> 00:19:55.920]   but the broad trend is down. I think it's indisputable. At the same time,
[00:19:55.920 --> 00:20:02.480]   even with the conflagrations in the Middle East, if you look at what people think about the future
[00:20:02.480 --> 00:20:09.920]   price of oil, it's also down. Oil futures are, I think, about five to 10%. Future prices are about
[00:20:09.920 --> 00:20:14.240]   five to 10% lower than spot right now, for whatever that's worth. But the third thing,
[00:20:14.240 --> 00:20:19.600]   which I think is important, is we've now started to see folks come back from the new year and start
[00:20:19.600 --> 00:20:26.000]   to affect some pretty big layoffs, and they're across industries, right? Citibank today just
[00:20:26.000 --> 00:20:30.640]   announced 20,000 layoffs. That's a huge amount of people that are going to lose their jobs.
[00:20:30.640 --> 00:20:36.880]   So what does all of this mean? It's that I think that people expect that as inflation contracts,
[00:20:37.680 --> 00:20:45.040]   the money supply will expand, but demand has yet to reset properly. So that's the last thing. And
[00:20:45.040 --> 00:20:48.880]   I think Freeberg's mentioned this a bunch. Consumer spending has always been crazy,
[00:20:48.880 --> 00:20:55.120]   people living on credit, all of this stuff. That is now finally, I think, the last thing that has
[00:20:55.120 --> 00:21:00.160]   to get sorted out. So in the absence of demand, back to the way you started, Jason, companies
[00:21:00.160 --> 00:21:03.200]   will cut expenses in order to maintain profitability, because they don't really
[00:21:03.200 --> 00:21:08.480]   want to cut prices unless their product really sucks. Yeah, and just to note that Citigroup,
[00:21:08.480 --> 00:21:15.680]   as you mentioned, 20,000 cuts by 2026. Google also laid off hundreds of people, Amazon hundreds
[00:21:15.680 --> 00:21:21.280]   of people, Discord laid off 17%. And there's a viral video going around of a woman laid off by
[00:21:21.280 --> 00:21:26.960]   Cloudflare, you know, who was only on the team for like six months or something, or five months.
[00:21:26.960 --> 00:21:32.560]   And it does seem like, yeah, firing people before the holidays, laying them off is considered,
[00:21:32.560 --> 00:21:37.120]   yeah, you don't do it in the fourth quarter. So maybe there was some backed up layoffs that
[00:21:37.120 --> 00:21:42.480]   people decided to do into this year. But it certainly feels like SAC's people are,
[00:21:42.480 --> 00:21:47.200]   and you said this, I think, in the predictions episode or the recap episode, hey, you know,
[00:21:47.200 --> 00:21:51.520]   maybe it's still going to be a little bit of turbulence, and the soft landing isn't guaranteed.
[00:21:51.520 --> 00:21:56.480]   Maybe you could expand on that. Yeah, my prediction for the year was bumpy landing.
[00:21:56.480 --> 00:22:00.480]   I thought soft landing was a little too optimistic. And I also thought that this
[00:22:00.480 --> 00:22:05.520]   big stock market rally that we had in November, December was too much too soon. The market,
[00:22:05.520 --> 00:22:10.480]   starting in November, started pricing in about one and a half percent of rate cuts this year,
[00:22:10.480 --> 00:22:14.880]   believing that the inflation problem had been licked. And now what we're seeing is, first of
[00:22:14.880 --> 00:22:19.760]   all, you had a slightly hotter than expected inflation report. And now we have this escalating
[00:22:19.760 --> 00:22:28.000]   situation in Yemen, where this war in the Middle East might expand. And just so you understand,
[00:22:28.000 --> 00:22:35.520]   I mean, the Houthis have already said that if the United States attacks them and uses Saudi or UAE
[00:22:35.520 --> 00:22:40.160]   airspace to do it, that they will consider themselves at war with Saudi Arabia and UAE,
[00:22:40.160 --> 00:22:44.800]   and that they will try to do things like light the Saudi oil fields on fire. I don't think they
[00:22:44.800 --> 00:22:49.920]   have the capability to do that necessarily, but it's an indication that things are very volatile.
[00:22:49.920 --> 00:22:55.200]   Another thing I think we're likely to see in the Middle East is continued attacks on US military
[00:22:55.200 --> 00:23:02.960]   bases in Iraq and Syria. So, that whole region is a powder keg. And if it develops into a wider
[00:23:02.960 --> 00:23:07.920]   regional war, then I think you could see an oil shock. And if there's an oil shock, I think you
[00:23:07.920 --> 00:23:12.240]   can kiss rate cuts goodbye, because that's going to percolate through the whole economy and have a
[00:23:12.240 --> 00:23:20.240]   big impact on inflation. So, I just think that there's a lot of downside to these very optimistic
[00:23:20.240 --> 00:23:26.960]   projections that we're going to get these huge rate cuts. It might happen, but I just see a lot
[00:23:26.960 --> 00:23:32.480]   of risk. Yeah. Friedberg, do you think these oil shocks are here for the long term or a possibility?
[00:23:32.480 --> 00:23:42.160]   You've been talking a lot about alternative energy, nuclear, obviously. And the US has become
[00:23:42.160 --> 00:23:49.520]   a net exporter of oil. So, do you think this risk of oil disruption from the Middle East is with us
[00:23:49.520 --> 00:23:54.800]   for the long term? Or do you think that's waning now? There's definitely structural risk, because
[00:23:54.800 --> 00:24:05.200]   you have a supply chain that can get disrupted in a number of ways and limited alternative options.
[00:24:05.200 --> 00:24:12.400]   If you look at the chart I just shared, it's the US Strategic Petroleum Reserve. So, we have about
[00:24:12.400 --> 00:24:22.720]   350 million barrels in the Strategic Petroleum Reserve today. That's down from call it early 21,
[00:24:22.720 --> 00:24:29.440]   when we were at 650 million barrels. And, you know, it was pretty much at that level for decades.
[00:24:29.440 --> 00:24:35.600]   After the buildup leading up to 1990. We haven't been at a level this low in the Strategic Petroleum
[00:24:35.600 --> 00:24:44.960]   Reserve since 1983. And so there's not a lot of levers for the government to intervene to support
[00:24:44.960 --> 00:24:50.880]   the supply, as there may have been in the last couple of years, in the case of some supply shock
[00:24:50.880 --> 00:24:55.840]   because of a conflict that arises in a major oil producing region. It's really interesting chart,
[00:24:55.840 --> 00:25:00.560]   isn't it? Because that was after the oil crisis of the 70s. And you look at how long it took to
[00:25:00.560 --> 00:25:05.200]   build it up, and how large we built it. It's a really fast. I've never seen that chart before.
[00:25:05.200 --> 00:25:09.680]   But if you look at the, you know, I don't know if you guys remember the oil lines, did you have
[00:25:09.680 --> 00:25:14.560]   them in Canada, Shama? Where in I remember in Brooklyn, you had an even number, odd number,
[00:25:14.560 --> 00:25:19.840]   license plate thing, if you wanted to get gas, you know, some days was the even number some days was
[00:25:19.840 --> 00:25:23.280]   the odd number, I remember my parents getting online for gas and waiting for two hours or three
[00:25:23.280 --> 00:25:28.640]   hours to get gas. Yeah, by the way, I'll say this is not a real cost today that we're experiencing.
[00:25:28.640 --> 00:25:32.880]   But as Saxe is pointing out, there's a number of ways that this can become a real cost. I was in
[00:25:33.600 --> 00:25:39.040]   Austin this week. And the thing that shocked me the most was how cheap gas was the gas station,
[00:25:39.040 --> 00:25:43.520]   you can get gas for like, two bucks and 25 cents a gallon. Pretty awesome.
[00:25:43.520 --> 00:25:46.160]   It's like $6 when you're in Lake Tahoe.
[00:25:46.160 --> 00:25:52.320]   Yeah, just so everyone understands how the SPR got depleted last year, when inflation was the
[00:25:52.320 --> 00:25:57.120]   top story, you know, on the front page of every newspaper, and gas prices were hitting what seven
[00:25:57.120 --> 00:26:04.960]   or $8. The administration started releasing crude from the SPR to try and bring the price down. And
[00:26:04.960 --> 00:26:10.240]   they did that for about a year, and they were basically subsidizing the price of oil. Now,
[00:26:10.240 --> 00:26:16.000]   that's why our stockpile is low. And that was a really great political strategy. But if we end up
[00:26:16.000 --> 00:26:21.600]   in a real crisis, we're going to have less dry powder to deal with it. So, you know, we could
[00:26:21.600 --> 00:26:27.680]   have a perfect storm of things coming together here, where at precisely the time we end up
[00:26:27.680 --> 00:26:34.000]   getting involved in a big war in the Middle East, our tools to mitigate the oil shock that would
[00:26:34.000 --> 00:26:40.000]   create have been reduced by what the administration has done over the past year. Now, I don't know
[00:26:40.000 --> 00:26:45.280]   that that's going to happen. I mean, I still think we're several steps away from a regional war. But
[00:26:45.280 --> 00:26:50.640]   you look at how many fronts now we have conflict in the Middle East, there's about five different
[00:26:50.640 --> 00:26:57.600]   fronts, where there's conflict, you've obviously got Israel's war in Gaza, you've got Hezbollah
[00:26:57.600 --> 00:27:05.520]   in the north, basically firing rockets, you've got US bases in Syria and Iraq coming under attack.
[00:27:05.520 --> 00:27:10.960]   And now we have the US striking Yemen. So there's just so many ways that this could
[00:27:10.960 --> 00:27:12.000]   spiral out of control.
[00:27:12.000 --> 00:27:16.080]   Jared Ranere isn't the SPR designed so that when we have an economic crisis like this to use it,
[00:27:16.080 --> 00:27:19.440]   like I mean, it's Yeah, you're the Biden administration does a lot to dip in,
[00:27:19.440 --> 00:27:22.160]   by the way, you have to give credit to the Biden administration in one,
[00:27:22.160 --> 00:27:29.520]   in one form. It's not necessarily skilled per se. But when you look at the SPR depletion,
[00:27:29.520 --> 00:27:34.800]   they were selling at incredible moments in the market. And the Energy Department, I actually I
[00:27:34.800 --> 00:27:40.560]   think they they just announced that they're buying another, you know, four or $8 billion
[00:27:40.560 --> 00:27:46.560]   to replenish the SPR. So they'll be doing that now. But they were selling if you look at these
[00:27:46.560 --> 00:27:52.000]   price points here, they were selling when prices were 80 and $90 a barrel, and now they're buying
[00:27:52.000 --> 00:27:57.680]   it back at 70. So at least the United States can take some solace in the fact that we are doubt
[00:27:57.680 --> 00:28:03.600]   a few billion dollars for treasure. I wonder how the SPR relates to consumption, you know,
[00:28:03.600 --> 00:28:08.880]   we see this chart, but it's in the number of barrels, right? 350 million barrels or something
[00:28:08.880 --> 00:28:13.280]   like that. Is that what the chart says? And then it peaked at six or 700,000? I wonder what it
[00:28:13.280 --> 00:28:19.040]   needs to be Chamath or Freiburg on as a percentage of our consumption as more EVs hit the market,
[00:28:19.040 --> 00:28:25.120]   right. And as the number of miles per gallon goes up, so I couldn't find a chart for that. I tried
[00:28:25.120 --> 00:28:30.080]   to find if anybody in the audience knows, the SPR in relation to consumption, that would be a
[00:28:30.080 --> 00:28:36.400]   very important chart. No, I think they're pretty independent, Jason. How so like, we just build it
[00:28:36.400 --> 00:28:41.040]   up independent of what we need. No, the the strategic petroleum reserve is is essentially
[00:28:41.040 --> 00:28:49.120]   that it's it's not meant to be something that's, that's meant to bookend usage, you know, if in a
[00:28:49.120 --> 00:28:53.920]   highly functioning market, there's theoretically an infinite amount of oil that's available. And
[00:28:53.920 --> 00:28:58.240]   so if there's more consumption, you'll be able to find more oil, you'll just have to pay a different
[00:28:58.240 --> 00:29:03.120]   price for it. This SPR is meant to be used in very different kinds of situations. This one is
[00:29:03.120 --> 00:29:07.120]   interesting. Yeah, right. Like when there's a disruption, when there's an acute disruption,
[00:29:07.120 --> 00:29:11.280]   it's supposed to be break glass in case of emergency. Exactly. But how many days is it
[00:29:11.280 --> 00:29:15.600]   supposed to last is what I'm sort of getting at, like, that's what I wonder, because over time,
[00:29:15.600 --> 00:29:20.240]   are we consuming more oil now as a country? Or are we consuming less? I would think consuming
[00:29:20.240 --> 00:29:25.280]   more, but but the thing you have to keep in mind is that even in acute shock, what you can't just
[00:29:25.280 --> 00:29:31.600]   look at the SPR, because we have now domestic oil capability. Right. And a lot of that developed
[00:29:31.600 --> 00:29:35.840]   under two presidents, Obama and Trump. And both of them deserve a lot of credit, because we have a
[00:29:35.840 --> 00:29:43.920]   capability now to be self sufficient. And we are a net exporter because of the work that happened
[00:29:43.920 --> 00:29:49.520]   neck during that time. Yeah, not guess. Oh, my gosh, do you guys see all of this machina with
[00:29:49.520 --> 00:29:54.880]   Carta this week? Crazy? Absolutely. Actually, it's on the docket. So those of you who don't
[00:29:54.880 --> 00:29:59.840]   know Carta is cap table software. If you don't know what the cap and cap table is, which many
[00:29:59.840 --> 00:30:05.440]   of you might not stands for capitalization. What is it? It's a Google or an Excel sheet that says
[00:30:05.440 --> 00:30:09.280]   who owns the number of shares in a company, this gets very complex and private companies.
[00:30:09.280 --> 00:30:13.200]   And they've made quite a business out of it. Wait, wait, wait, can I pause you there? There
[00:30:13.200 --> 00:30:18.480]   was a lot of comments that said exactly that it gets very complicated. I apologize. I've owned
[00:30:18.480 --> 00:30:24.720]   equity in companies for 20 years. What the hell is exactly complicated? Well, I don't understand
[00:30:24.720 --> 00:30:28.320]   that statement. I'm not I'm not directing it to you, Jason. Yeah, but I want I can tell you.
[00:30:28.320 --> 00:30:35.040]   Yeah. Because I feel like that is like some BS statement. Yeah, it's not the thing is you as
[00:30:35.040 --> 00:30:40.800]   acting as a price round individual. In a lot of these cases, it was very simple to do a price
[00:30:40.800 --> 00:30:47.360]   round. But when you inserted safes into this, you know, a simple agreement for future equity that
[00:30:47.360 --> 00:30:53.840]   Y Combinator created, and you put capital convertible notes into this founder started
[00:30:53.840 --> 00:30:59.040]   doing like dozens of these Chamath and at the early stages, the cleanup work and understanding
[00:30:59.040 --> 00:31:02.560]   how many shares people owned, especially with a J Cal, what I'm saying is,
[00:31:02.560 --> 00:31:06.720]   what, like, okay, tell me, let me stop. Let me ask a different way.
[00:31:06.720 --> 00:31:09.440]   Yeah, sure. We did this with spreadsheets.
[00:31:09.440 --> 00:31:14.400]   Let me answer your question. Okay. So in a private company, let's say a company issues
[00:31:14.400 --> 00:31:18.880]   options to an employee, they don't have a good record of that. The employee executes the options,
[00:31:18.880 --> 00:31:24.880]   they now believe that they own shares. Unlike in a public company, where there's a broker of record,
[00:31:24.880 --> 00:31:28.800]   every share is registered in a public company, you know, who owns the shares, you know, what
[00:31:28.800 --> 00:31:33.440]   broker is holding those shares, and every share is traded through a public exchange. So there's a
[00:31:33.440 --> 00:31:38.400]   record of every transaction that takes place with every share in a public company. In a private
[00:31:38.400 --> 00:31:44.720]   company, there's no independent legal regulator that tracks all the shares. So you could issue
[00:31:44.720 --> 00:31:50.240]   options to an employee, and forget that you did that, put the document in a drawer, and the
[00:31:50.240 --> 00:31:54.560]   employee shows up five years later, and they're like, wait, or I've experienced this, I've had
[00:31:54.560 --> 00:31:59.200]   advisors show up, be like, look, here's my advisory agreement, I was given options. I'm
[00:31:59.200 --> 00:32:03.120]   asking a different question. You're saying something great. I get that. I'll tell you
[00:32:03.120 --> 00:32:07.760]   what I think the killer feature was. Why is that complicated to implement in software? I don't
[00:32:07.760 --> 00:32:12.720]   understand. I think the killer feature for Carta, it was called eShares back then, was getting the
[00:32:12.720 --> 00:32:18.160]   shareholder to sign for their stock certificates. So to Freeburg's point, in the old world, where
[00:32:18.160 --> 00:32:22.720]   it was all done by email and a spreadsheet, they would literally have to send you a paper stock
[00:32:22.720 --> 00:32:25.280]   certificate that you put in a file cabinet somewhere. And if you lost it, you had to sign
[00:32:25.280 --> 00:32:31.520]   a document with a lawyer saying, oh, I lost my certificate, I promise you I lost it, all that
[00:32:31.520 --> 00:32:35.440]   sort of stuff. So I think the killer feature was digitizing the stock certificates, and then you
[00:32:35.440 --> 00:32:41.760]   would sign for them using like an e-signature, you know, on Carta, and they would just keep it
[00:32:41.760 --> 00:32:46.560]   for you. No, I get it. I'm not debating the value, guys. You're saying why is the software
[00:32:46.560 --> 00:32:50.000]   complicated? Yeah, why is the software complicated? This is not complicated. Nothing you guys have
[00:32:50.000 --> 00:32:54.640]   said is complicated. But what happened was, because I remember when like the market tipped,
[00:32:54.640 --> 00:33:01.840]   right, is I got one email from a company that was using eShares back then, and I would just do the
[00:33:01.840 --> 00:33:06.320]   digital signature, and I started getting a few more and a few more. Pretty soon, there was a
[00:33:06.320 --> 00:33:12.240]   network effect. Like, I don't want to have to wonder where my digital stock certificates are.
[00:33:12.240 --> 00:33:16.880]   I just know that they're all at Carta. That's very convenient for me as an investor. I think
[00:33:16.880 --> 00:33:20.720]   it's very convenient for the company to be able to manage all this stuff digitally. So look, I mean,
[00:33:20.720 --> 00:33:26.160]   DocuSign is not a complicated technology either, and that is, what, a multi-billion dollar company
[00:33:26.160 --> 00:33:30.000]   because there's a very strong network effect. You don't want to have to have all of your signatures
[00:33:30.000 --> 00:33:35.360]   at a whole bunch of different companies. So I think that's how it kind of got off to the races.
[00:33:35.360 --> 00:33:39.760]   And then since then, they've been able to add more workflows. They've been able to add fund
[00:33:39.760 --> 00:33:45.120]   management. They've been able to add a number of things to make it stickier and more feature-rich.
[00:33:45.680 --> 00:33:49.200]   And it's not that expensive. It's like $10,000 a year or something like that.
[00:33:49.200 --> 00:33:52.560]   It's kind of getting very expensive for startups. We're talking-
[00:33:52.560 --> 00:33:56.160]   $10,000 a year is expensive? I mean, for a seed state startup,
[00:33:56.160 --> 00:34:00.240]   it's a lot. And then we invested in a company called Cake Equity that's doing it for like
[00:34:00.240 --> 00:34:04.800]   $1,000 a year. To Chamath's point, you tweeted, "Why can't this be $1,000 a year? Go to Cake
[00:34:04.800 --> 00:34:09.760]   Equity. You'll see." Well, can we just go to my tweet? I was confused by all of this stuff.
[00:34:09.760 --> 00:34:12.160]   Well, we haven't even gotten to the story yet. So just, sorry, Jason, go ahead.
[00:34:12.160 --> 00:34:14.640]   Yeah, yeah, sorry, Jason, go ahead. So anyway, what you're hearing is
[00:34:15.200 --> 00:34:20.400]   this software is very integrated into startup culture. We all have a lot of opinions on it
[00:34:20.400 --> 00:34:26.240]   because the cap table is where all the value is recorded. The cap tables have gotten much
[00:34:26.240 --> 00:34:31.840]   more complicated, but this is not like building the TikTok algorithm or chat GPT. To be clear,
[00:34:31.840 --> 00:34:36.640]   to Chamath's point, this is not really hard software to build. So correct on that.
[00:34:36.640 --> 00:34:41.600]   And Saxe, correct to your point, it's super convenient if everybody uses the same platform.
[00:34:41.600 --> 00:34:46.240]   And for a Series A, B, C company, spending $10,000, $20,000 a year on this is not
[00:34:46.240 --> 00:34:48.640]   that big of a deal, although there are cheaper options.
[00:34:48.640 --> 00:34:51.360]   And VCs and investors use it too to track their portfolios.
[00:34:51.360 --> 00:34:53.280]   Absolutely. And so...
[00:34:53.280 --> 00:34:56.080]   It grew from one to the other, just to be clear. So, I mean, first,
[00:34:56.080 --> 00:35:00.320]   companies started using it for their cap tables, then they got into the fund management business.
[00:35:00.320 --> 00:35:04.720]   So if you were a fund, you were receiving all of your stock certificates, then you started using
[00:35:04.720 --> 00:35:09.120]   it to communicate with your LPs. So we've started doing that. And it's very convenient for that.
[00:35:09.120 --> 00:35:13.040]   So it's a real, it's more of a network effect business than a hard software business,
[00:35:13.040 --> 00:35:13.760]   I think is Saxe's point.
[00:35:13.760 --> 00:35:15.600]   Totally. Totally. Because it's super network.
[00:35:15.600 --> 00:35:17.760]   This business has benefited from the network effects.
[00:35:17.760 --> 00:35:22.000]   So they had such strong network effects. Here's the brouhaha,
[00:35:22.000 --> 00:35:25.760]   the Donniebrook that came up this past week.
[00:35:25.760 --> 00:35:26.800]   Donniebrook.
[00:35:26.800 --> 00:35:27.840]   So you can look it up.
[00:35:27.840 --> 00:35:30.720]   I like that word.
[00:35:30.720 --> 00:35:31.840]   Yeah, me too.
[00:35:31.840 --> 00:35:32.560]   Yeah.
[00:35:32.560 --> 00:35:34.160]   So the company...
[00:35:34.160 --> 00:35:36.000]   I bet you knew a lot of Donnies in Brooklyn.
[00:35:37.120 --> 00:35:42.720]   I was involved in a couple of Brooks, if I'm being honest, and they escalated from brouhahas,
[00:35:42.720 --> 00:35:47.200]   typically. Not unlike an average episode of this podcast. And so...
[00:35:47.200 --> 00:35:50.000]   There are probably some Donniebrooks involving guys named Donnie.
[00:35:50.000 --> 00:35:52.560]   Yeah, Donnie was typically the guy who started...
[00:35:52.560 --> 00:35:55.040]   This episode is going to be named the Donniebrook episode, please.
[00:35:55.040 --> 00:36:02.480]   So the company had a massive violation of trust. As they were expanding to figure out other
[00:36:02.480 --> 00:36:07.040]   businesses to come into, they got into what's called the secondary market. For those of you
[00:36:07.040 --> 00:36:11.600]   who don't know what the secondary market is, people like to trade stocks of private companies.
[00:36:11.600 --> 00:36:17.520]   You may have heard people buying and selling Stripe or SpaceX. And so employees, early investors
[00:36:17.520 --> 00:36:21.600]   might sell their shares to other people. Now, this is not happening as a primary offering from
[00:36:21.600 --> 00:36:25.120]   the company where they raise money and issue new shares. This is people who have shares.
[00:36:25.120 --> 00:36:29.200]   Carta was in a great position to do this because they had the cap table.
[00:36:29.200 --> 00:36:34.480]   Now, on your cap table might be 100 investors. 30 of them might be your friends, family,
[00:36:34.480 --> 00:36:39.200]   very quiet. It could be Jeff Bezos, who was a seed investor in Google.
[00:36:39.200 --> 00:36:47.040]   Some folks at Carta who were in the secondary business violated the trust and the privacy of
[00:36:47.040 --> 00:36:51.840]   companies who had angel investors or early stage investors on their cap table and started contacting
[00:36:51.840 --> 00:36:57.040]   them directly saying, "Hey, do you want to sell your shares in company A to this person? We're
[00:36:57.040 --> 00:37:04.480]   trying to create a market for it." They got called out publicly. The CEO, Henry Ward, who is a unique
[00:37:04.480 --> 00:37:12.720]   individual, as many CEOs are, tried to do some comms. It was a disaster of comms for a couple
[00:37:12.720 --> 00:37:19.440]   of days while they tried to explain basically breaking their own terms of service. And it all
[00:37:19.440 --> 00:37:24.000]   ended up with them selling the secondary business, which I understand was a tiny business for them.
[00:37:24.720 --> 00:37:27.200]   Overall, your thoughts, gentlemen. I don't know if anybody has strong thoughts.
[00:37:27.200 --> 00:37:30.320]   Why did you say he was an interesting individual? Do you mean?
[00:37:30.320 --> 00:37:39.040]   He communicates directly in a very effervescent, candid way, like some founders do.
[00:37:39.040 --> 00:37:42.000]   Effervescent. Wow, that's a nice, nice. Effervescent.
[00:37:42.000 --> 00:37:45.280]   I mean, I'm just trying to- What I was saying, he's sparkling?
[00:37:45.280 --> 00:37:53.520]   I think he is bad at PR, but entertaining to listen to, right? I think maybe they should have
[00:37:53.520 --> 00:37:57.600]   had a little bit of a slightly more thoughtful approach to this, but it all happened in real
[00:37:57.600 --> 00:38:00.160]   time. So it's very difficult to deal with the crisis in real time, I think.
[00:38:00.160 --> 00:38:06.960]   I have two comments. The first is I actually disagree with David Sacks. I think that there's
[00:38:06.960 --> 00:38:11.200]   literally no concept of network effects in this business, and it makes no sense here.
[00:38:11.200 --> 00:38:16.240]   And the reason is that when you look at the public markets, which are infinitely larger,
[00:38:16.240 --> 00:38:21.280]   we have a vibrant public stock market that has no concept of this, and it works.
[00:38:21.280 --> 00:38:28.160]   Where you have companies like ComputerShares, you have companies like SS&C, there's just a
[00:38:28.160 --> 00:38:33.120]   plethora of providers that do fund administration, and frankly, I'm glad that there's a plethora of
[00:38:33.120 --> 00:38:37.840]   providers. I use some of them, and I trade one against the other to get a constantly cheaper
[00:38:37.840 --> 00:38:45.120]   price. We use the distribution agents, and depending on which bank I'm working with on
[00:38:45.120 --> 00:38:51.680]   whatever deal, I have shares at multiple different agents. And they also cost virtually nothing, and
[00:38:51.680 --> 00:38:58.400]   I don't see a world where that deflationary cost reduction doesn't come to this market either,
[00:38:58.400 --> 00:39:04.080]   because I don't see this as a defensible area of software. I think it's a necessary piece of
[00:39:04.080 --> 00:39:09.200]   software. So I kind of like randomly tweeted out just kind of like, "Oh," because I was just
[00:39:09.200 --> 00:39:14.400]   watching from the sidelines. Now, in full disclosure, I was a Carta investor. I sold all
[00:39:14.400 --> 00:39:18.880]   my equity in a secondary transaction, actually. Speaking of secondary transactions, was that a
[00:39:18.880 --> 00:39:24.160]   good trade? Yeah, I sold it all two and a half years ago. So I have no opinion one way or the
[00:39:24.160 --> 00:39:29.200]   other on this company. I understand process automation, but I don't think process automation is
[00:39:29.200 --> 00:39:36.320]   defensible. So if you build software around process automation, you will be competing in a race to the
[00:39:36.320 --> 00:39:41.360]   bottom on price. That is, and I have not seen a single example of a company that's proven this
[00:39:41.360 --> 00:39:46.080]   otherwise. There are different companies that create real lock-in because of what they build.
[00:39:46.080 --> 00:39:51.840]   That isn't one. So I tweeted this out. Some person sent me this, and Jason, to your point, the two
[00:39:51.840 --> 00:39:59.120]   most prevalent competitors that they showed me were Mantle and Pulley. I think one is a YC company,
[00:39:59.120 --> 00:40:04.160]   and one is not, but Mantle and Pulley I think were the two that came up the most often. And Jason,
[00:40:04.160 --> 00:40:11.120]   to your point, what they both told me was Carta is like 10K a year, 12K a year, and these guys are
[00:40:11.120 --> 00:40:18.160]   90% discounted at a 10th of the price, which again, proves there is not a lot of super compelling
[00:40:18.160 --> 00:40:23.600]   software lock-in here. It's useful stuff, but that useful stuff is eventually going to get as
[00:40:23.600 --> 00:40:28.400]   close to free as possible. These guys are proving it. And then last night while we were at poker,
[00:40:28.400 --> 00:40:35.920]   I got this thing. Somebody in two days built an open source competitor and just put the code out
[00:40:35.920 --> 00:40:43.120]   there and said, "Here you go. Take it." Isn't that incredible? Guys, that happened in two days from
[00:40:43.120 --> 00:40:51.280]   that tweet. How crazy is that? If I got a stock certificate from, what's the name of this thing?
[00:40:52.800 --> 00:41:01.040]   Open source clone. Buybycarta.com. I'd groan. I'd be like, "Oh, here we go. I've got to find my
[00:41:01.040 --> 00:41:04.640]   certs in five different sites, and this thing's probably going to go out of business in six
[00:41:04.640 --> 00:41:08.320]   months." Come on. That's not true, and you know it. You know it. You don't know where the certs
[00:41:08.320 --> 00:41:12.000]   are. You don't care. It'd be seriously annoying to have to deal with something new. I can actually
[00:41:12.000 --> 00:41:16.240]   tell you what's happening in the market with startups. Startups are looking at the alternatives.
[00:41:16.240 --> 00:41:21.200]   They want to save money. The bigger companies are probably not as price sensitive, Chamath. So
[00:41:22.320 --> 00:41:28.480]   spending $20,000 as a Series B company, nobody cares. But for the startups, they tend to find
[00:41:28.480 --> 00:41:32.560]   the most efficient software, and you're exactly right, Chamath, on that.
[00:41:32.560 --> 00:41:40.320]   Yeah. My comment is less about Carta itself and its price point. My observation is twofold. One is
[00:41:40.320 --> 00:41:46.640]   software that doesn't have a fundamental lock-in does not have pricing power,
[00:41:47.520 --> 00:41:53.280]   number one, and number two, we are almost at the tipping point of a set of tools that will
[00:41:53.280 --> 00:41:58.880]   allow competitors in a matter of days to compete with an 80% feature-complete solution at a fraction
[00:41:58.880 --> 00:42:05.360]   of the price. That's my generalized observation as manifested in this Carta example in less than a
[00:42:05.360 --> 00:42:09.440]   week. Well, what do you do with some observation like this? If you have this 80% observation,
[00:42:09.440 --> 00:42:12.560]   is there anything you could... So then I was like, "Well, you know what? I'm just going to go for it."
[00:42:12.560 --> 00:42:18.960]   So I'm starting this thing, and I've been working on this idea for a little bit,
[00:42:18.960 --> 00:42:22.960]   and I've been experimenting with it with some of my companies. But then I was like, "You know what?
[00:42:22.960 --> 00:42:27.360]   We should just do this." So the concept here is we're going to build this incubator. It's called
[00:42:27.360 --> 00:42:32.880]   80/90. I have a team. I have a bunch of developers offshore, and we are going to
[00:42:32.880 --> 00:42:39.520]   basically create a hit list of software that we think is relatively straightforward
[00:42:40.720 --> 00:42:46.480]   and mispriced and could be built much more efficiently in 2024 using all of these co-pilots
[00:42:46.480 --> 00:42:53.200]   and tools. Our boundary conditions will be, "Can we deliver 80% of the functionality
[00:42:53.200 --> 00:42:59.040]   at 10% of the price?" So at a 90% discount. So 80/90 is sort of where you're going?
[00:42:59.040 --> 00:43:03.600]   80/90 is what the name of the incubator is. And what was interesting is when I tweeted this out,
[00:43:03.600 --> 00:43:09.920]   we had 1,200 people essentially give us a product roadmap. They told us the software
[00:43:09.920 --> 00:43:13.040]   that they would want. They told us the features that they need. They told us the things that
[00:43:13.040 --> 00:43:17.920]   they don't need. And so the idea here, Jason, I think is I'm just going to build this in the wild.
[00:43:17.920 --> 00:43:23.040]   I'll create the list of companies. We'll publish that out, let people vote on it. Then we'll
[00:43:23.040 --> 00:43:29.040]   publish the PRDs of what the 80% version is, and we're going to work backwards with my team
[00:43:29.040 --> 00:43:34.880]   in South Asia to try to build these things at a 10% price point.
[00:43:34.880 --> 00:43:40.880]   So Sax, your thoughts, you're a SaaS investor. You're vertical. Your thoughts on Chamath's plan
[00:43:40.880 --> 00:43:47.600]   to be the most hated person in Silicon Valley by underpricing every piece of SaaS software by 90%
[00:43:47.600 --> 00:43:52.240]   in real time. Can he do it in your estimation?
[00:43:52.240 --> 00:43:55.200]   Yeah. Well, I think there probably are categories where you could do that.
[00:43:55.200 --> 00:44:02.480]   But in general, what I would say is that it always looks easier from the outside
[00:44:02.480 --> 00:44:07.680]   than from the inside, meaning that you look at any particular SaaS category leader,
[00:44:07.680 --> 00:44:12.560]   and you're like, "This is easy. I could do this." And then when you actually get into it,
[00:44:12.560 --> 00:44:17.120]   you realize that, "Okay, the product I'm seeing is kind of an iceberg. I'm just seeing the tip
[00:44:17.120 --> 00:44:20.960]   of the iceberg. Below the waterline is all the business logic that's been written into the
[00:44:20.960 --> 00:44:26.480]   system. There's a much deeper and longer list of features." Not in every category. You might be
[00:44:26.480 --> 00:44:30.960]   right that in some categories, you don't need the product depth. But in many other categories,
[00:44:30.960 --> 00:44:35.360]   there's just a lot of subtle features, usability issues have been figured out, integrations
[00:44:35.360 --> 00:44:38.960]   with other- Ongoing support.
[00:44:38.960 --> 00:44:40.320]   Ongoing support. Training.
[00:44:40.320 --> 00:44:44.720]   And then you have the whole sales and marketing component to it. So what ends up happening is
[00:44:44.720 --> 00:44:50.400]   you attack a category saying, "Oh, this is going to be easy." A year or two into it, you're like,
[00:44:50.400 --> 00:44:56.240]   "Wow, the category leader, we're not even close to where it is in terms of table stakes here."
[00:44:56.240 --> 00:45:00.560]   And it ends up being more of a slog than you thought. And then you find out the market
[00:45:00.560 --> 00:45:04.320]   doesn't actually have as much of an incentive to switch. I'm not saying it can't be done.
[00:45:04.320 --> 00:45:09.840]   There are categories where I think the category leader has become stagnant
[00:45:09.840 --> 00:45:14.160]   and has stopped innovating. And I think those are ripe for disruption. I mean, look,
[00:45:14.160 --> 00:45:17.760]   I'm kind of trying in a way we're going to be launching my Slack killer soon.
[00:45:17.760 --> 00:45:23.840]   I feel a lot better about that because Slack Ad Acquire hasn't really innovated in a few years.
[00:45:23.840 --> 00:45:29.520]   And Salesforce, by the way, just announced zero hiring in 2024. And the Slack teams were like,
[00:45:29.520 --> 00:45:33.200]   "What? How are we supposed to hit our roadmap without more people? What's going on here?"
[00:45:33.200 --> 00:45:33.520]   Right.
[00:45:33.520 --> 00:45:34.800]   So there is that.
[00:45:34.800 --> 00:45:39.440]   Look, I definitely think it can be done. But I don't know. I think you got to choose
[00:45:39.440 --> 00:45:44.800]   carefully the categories where the iceberg isn't bigger than you think, basically.
[00:45:44.800 --> 00:45:49.120]   Do you think that there's a shift in the business model for SaaS companies
[00:45:49.120 --> 00:45:53.600]   that emerges from what Chamath is talking about, where I think right now sales and
[00:45:53.600 --> 00:45:58.000]   marketing costs as a percent of revenue on average for a scaling enterprise software
[00:45:58.000 --> 00:46:04.240]   company around 55% of revenue, or something in that range? Does that number get compressed
[00:46:04.240 --> 00:46:08.880]   by bringing price down? So you bring price down, but you need fewer people to go in and do the
[00:46:08.880 --> 00:46:10.320]   selling, fewer folks to do marketing?
[00:46:10.320 --> 00:46:14.640]   I don't think so. That has not been the pattern. I mean, look, everyone was saying things like this
[00:46:14.640 --> 00:46:20.480]   when enterprise software shifted from on-prem to the cloud. When we went from Oracle and
[00:46:20.480 --> 00:46:25.200]   Siebel to Salesforce.com, people would say, "Oh, it's going to fundamentally change the business.
[00:46:25.760 --> 00:46:28.480]   Sales won't become that important. Product's going to be all-important."
[00:46:28.480 --> 00:46:31.360]   It was true to some degree. I mean, I do think that-
[00:46:31.360 --> 00:46:35.520]   You tried to do it. That was what you pioneered at Yammer. You tried to do bottom-up sales.
[00:46:35.520 --> 00:46:40.960]   Yeah. So there was product-led growth became a thing, and a very important thing. And I still
[00:46:40.960 --> 00:46:45.520]   think that's the best way to build a SaaS company is you let the users just try it on a freemium
[00:46:45.520 --> 00:46:51.280]   basis as opposed to having sales knock on the CIO's door, let the employees pull the product
[00:46:51.280 --> 00:46:56.400]   into the company, then go close the deal. So it did make important changes, but it did not get
[00:46:56.400 --> 00:47:01.840]   rid of sales. I mean, what I believed doing this stuff way back in 2008 is we'd be able to get rid
[00:47:01.840 --> 00:47:06.560]   of sales and just make enterprise products completely self-distributing. That never
[00:47:06.560 --> 00:47:11.440]   happened. People have been predicting the death of sales for a long time, and it's never happened.
[00:47:11.440 --> 00:47:16.000]   I think your vision is absolutely right. And I think this, in a world of auto GPTs,
[00:47:16.000 --> 00:47:20.000]   it's going to happen. And I think the way that it's roughly going to happen is as follows.
[00:47:20.000 --> 00:47:25.120]   I think what happens is that, and Zoho is another good example of how you can do this, which is
[00:47:25.120 --> 00:47:30.960]   what you need are a small set of tools that provide useful capability for a company that
[00:47:30.960 --> 00:47:35.040]   work elegantly together. Now, when you work elegantly together, there's a bunch of things
[00:47:35.040 --> 00:47:39.120]   that you need. You need security, you need handoffs and handshakes, you need different
[00:47:39.120 --> 00:47:45.520]   ways of handling exceptions, you need a common kind of data model. All of those things can
[00:47:45.520 --> 00:47:52.480]   actually be configured on the fly dynamically by in between two sets of software if you let the AI
[00:47:52.480 --> 00:47:58.240]   actually run and auto configure itself. And so I think the experimentation is as follows. You have
[00:47:58.240 --> 00:48:03.440]   product A and product B, you want to adopt them both. They have elements of an agent that can go
[00:48:03.440 --> 00:48:10.240]   and auto configure themselves to each other. Separately, I think what the CFO or the CEO does
[00:48:10.240 --> 00:48:16.320]   is allocate a budget. And that budget is an agent. And what that agent does is it works with these
[00:48:16.320 --> 00:48:20.880]   other agents to say, okay, great, I can spend money on these features. That is the thing we've
[00:48:20.880 --> 00:48:27.280]   not explored. We've always taken software that we build, and all of a sudden pause automation
[00:48:27.280 --> 00:48:32.480]   and hand it over to people to run it through a relatively archaic go to market process.
[00:48:32.480 --> 00:48:38.720]   And I think what's worth trying to figure out in 2024 and beyond is how to use these tools
[00:48:38.720 --> 00:48:43.600]   to automate all of the low level negotiation that happens before you can adopt software,
[00:48:43.600 --> 00:48:48.400]   I just think it's totally unnecessary. And I think that this is where software can do
[00:48:48.400 --> 00:48:53.680]   a very powerful job on behalf of the salesperson. Does it mean the salesperson is totally out of
[00:48:53.680 --> 00:49:00.000]   the loop? No. But I do think that if these tools are lightweight enough, especially the young,
[00:49:00.000 --> 00:49:06.000]   nimble companies will actually say, great, my procurement person is actually an AI agent with
[00:49:06.000 --> 00:49:11.280]   a budget. And it's the products that then figure out how to negotiate for the share of that budget,
[00:49:11.280 --> 00:49:16.960]   and then configure how to work amongst itself. That is the key innovation that I think someone
[00:49:16.960 --> 00:49:24.240]   will figure out that is the Zoho 2.0. Right? That is the Salesforce 2.0. It's sort of this
[00:49:24.240 --> 00:49:29.120]   app App Store, common data bus, kind of an idea that that I think somebody will build,
[00:49:29.120 --> 00:49:34.000]   I would like to try to help people have started building into math, because you're starting to
[00:49:34.000 --> 00:49:38.480]   see the features overlap in many programs, you're seeing HubSpot, Salesforce, Zendesk,
[00:49:38.480 --> 00:49:40.560]   they're all kind of getting into each other's business.
[00:49:40.560 --> 00:49:45.760]   Yeah, those are, that's a great observation. But those are all closed products. What I mean is
[00:49:45.760 --> 00:49:52.880]   like, there is like a totally open protocol and set of standards for how product A integrates
[00:49:52.880 --> 00:49:58.800]   and interacts with product B on many levels, right from security to data model, and everything in
[00:49:58.800 --> 00:50:03.680]   between. And I think that that is what needs to get figured out and be very much an open source
[00:50:03.680 --> 00:50:08.400]   idea. The great part about this is this is going to be massive competition, it will lower prices,
[00:50:08.400 --> 00:50:14.000]   it'll add features, and the team over at 37 signals is doing something similar. If you look
[00:50:14.000 --> 00:50:19.920]   at once.com, they are also going to go after slack sacks, and they're going to just charge
[00:50:19.920 --> 00:50:23.360]   one time for the software. I think I may have mentioned it on a previous one, but their concept
[00:50:23.360 --> 00:50:29.360]   is, yeah, just my gosh, can we can we take a moment actually, can you throw up my tweet? Can
[00:50:29.360 --> 00:50:36.640]   you take a moment to just say thank you to Stuart Butterfield and what he pulled off? Thank you. As
[00:50:36.640 --> 00:50:44.560]   a series A investor, I thank you, sir. 27 times ARR is looking like a pretty great exit multiple.
[00:50:44.560 --> 00:50:51.040]   Oh, there's my reply. Oh, yeah, look at my reply. Yeah. I mean, my gosh, what a deal.
[00:50:51.040 --> 00:50:55.520]   And at the time it was, they were public and people were wondering, like,
[00:50:55.520 --> 00:51:00.160]   Hmm, which is a good deal or not, should they have stayed independent, but the product velocity
[00:51:00.160 --> 00:51:02.480]   sacks, how do you get going? How are you
[00:51:02.480 --> 00:51:10.880]   thinking about what the critical go to market MVP capability is for slack. So this year is what I'm
[00:51:10.880 --> 00:51:20.400]   curious about. There's chat, right. But the problem with chat, in my opinion, is that slack has become
[00:51:20.400 --> 00:51:24.560]   totally overrun, where you could be a five person company, and all of a sudden you have 500 channels.
[00:51:24.560 --> 00:51:30.480]   So there's no scarcity. And that scarcity is, in my opinion, what makes what makes all corporate
[00:51:30.480 --> 00:51:37.040]   chats in this modern version, teams included, totally unusable, so much noise and distraction.
[00:51:37.040 --> 00:51:42.000]   So how are you thinking about that problem? Yeah, I totally agree with that. What you hear
[00:51:42.000 --> 00:51:48.000]   from every single company that has more than I don't know, 50 employees, is that slack doesn't
[00:51:48.000 --> 00:51:54.800]   scale. Because what happens is, you have a channel get created. And there's a whole bunch of
[00:51:54.800 --> 00:51:58.560]   conversations in there that are kind of munched together. If anybody in the company wants to
[00:51:58.560 --> 00:52:03.360]   participate in any one of those conversations, they have to join that entire channel. And as a
[00:52:03.360 --> 00:52:07.440]   result, every single employee ends up in every single channel. And it's just a giant mess. And
[00:52:07.440 --> 00:52:13.120]   there's way too much noise. So I think that the channel model was beautiful in terms of letting
[00:52:13.120 --> 00:52:17.440]   people get started really easily. You just jump into a channel and start posting. That's why it
[00:52:17.440 --> 00:52:24.800]   took off. But it's not particular enough in terms of, of addressing conversations to the right
[00:52:24.800 --> 00:52:29.440]   people. So that's basically one of the problems that we're fixing. The other thing I've heard
[00:52:29.440 --> 00:52:34.960]   from people is that we love chat, but we also really liked the feed that Yammer had as a way
[00:52:34.960 --> 00:52:39.680]   to quickly scroll through new stuff. You have a top level corporate feed, people forget that there
[00:52:39.680 --> 00:52:43.840]   was like this, hey, if you want to get the pulse of the entire organization, go to this one
[00:52:43.840 --> 00:52:48.560]   corporate feed. We were the first ones to figure out that like a feed should be used inside of an
[00:52:48.560 --> 00:52:53.760]   enterprise, not just in a consumer social network. So in any event, I'd say those are like two of the
[00:52:53.760 --> 00:53:00.000]   main concepts is combining feed and chat in a way that actually makes sense and solving the noise,
[00:53:00.000 --> 00:53:04.320]   the signal noise problem. Do you have a name for it yet? Yeah, it's gonna be called glue.
[00:53:04.320 --> 00:53:11.040]   Ooh, I love that. Can I remind you, can I, can I remind you that as a, as a humble investor,
[00:53:11.040 --> 00:53:17.440]   sir, I, I think I was part of Yammer and Slack. So I can add value.
[00:53:17.440 --> 00:53:22.640]   You're in, you're in. There's just one requirement for the early investors is you guys actually have
[00:53:22.640 --> 00:53:27.680]   to use it. You got to do a rip and replace on your Slack and sure. If you're willing to do that,
[00:53:27.680 --> 00:53:35.440]   you're in. Perfect. I'll take 250, 500 K. Yeah. I'll take 500. So I think we're going to do is
[00:53:35.440 --> 00:53:40.400]   before launch, we'll do like a seed round. Right now it's all been incubated by craft. So we'll do
[00:53:40.400 --> 00:53:50.400]   a seed round. So like 6 million posts, six posts. I'll put 50 in at six pre 56 posts,
[00:53:50.400 --> 00:53:55.920]   but it won't be, it won't be a super expensive round. Cause what we want to do is incentivize,
[00:53:55.920 --> 00:54:00.720]   you know, influencers to like support the products, switch to the product.
[00:54:00.720 --> 00:54:03.360]   So it really is going to be, do you have glue.com?
[00:54:04.640 --> 00:54:10.640]   We have glue.ai. Oh, wow. Nice. I was going to get 80, 90.ai,
[00:54:10.640 --> 00:54:13.520]   but then I didn't like it. You know what I got instead. Tell me if you like this
[00:54:13.520 --> 00:54:20.640]   80, 90.ink. So it's just 80, 90. That's fine. It doesn't matter. Everybody searches. I mean,
[00:54:20.640 --> 00:54:24.960]   eventually you fake it till you make it. If the 80, 90 domain happens, you get it,
[00:54:24.960 --> 00:54:30.800]   or you put get or go 80, 90.com. So do that before the show gets published. What is it? Get or go
[00:54:30.800 --> 00:54:38.080]   like if people have an 80, 90 or go 80, 90. So, you know, if it's a service, you say go 80, 90.
[00:54:38.080 --> 00:54:42.080]   And if it's whatever you say, get, if it's an app or something, right? Like you're just going to go
[00:54:42.080 --> 00:54:47.120]   get it here at this domain name. It's just easy to remember. I also got vc saskoboom.com.
[00:54:47.120 --> 00:54:51.440]   Oh, excellent. Well, I have wet your, people don't remember it's for a callback. I have
[00:54:51.440 --> 00:54:56.800]   wetyourbeak.com. I think it just goes to whatyourbeak.com just goes to our website.
[00:54:56.800 --> 00:55:04.160]   So that I mean, that was the basic scandal. Saks, they let the sales team doing secondary,
[00:55:04.160 --> 00:55:07.520]   apparently, or somebody broke a rule, they weren't exactly clear with it.
[00:55:07.520 --> 00:55:12.720]   It sounded to me like, you know, they didn't want to throw anybody under the bus exactly.
[00:55:12.720 --> 00:55:22.000]   But how big of a violation is it to let people go sell into the cap table, secondary shares without
[00:55:22.000 --> 00:55:25.920]   the CEO or your customer even knowing that you access that data? Where would you put that on a
[00:55:25.920 --> 00:55:31.120]   violation of trust scale? I think it was a huge issue for them because the only reason startups
[00:55:31.120 --> 00:55:37.040]   give their data to Carta is because they trust them to keep it private. Yes. And I think a big
[00:55:37.040 --> 00:55:41.920]   part of the problem with the Carta vision of creating the secondary marketplace is that
[00:55:41.920 --> 00:55:46.640]   founders don't want it. Fundamentally, that's the problem. I mean, Carta is in the perfect position
[00:55:46.640 --> 00:55:53.760]   to rationalize and make liquid the secondary market. The vision was correct in that sense.
[00:55:53.760 --> 00:55:58.480]   And the reason for that is because Carta not only has the cap table and they know who all
[00:55:58.480 --> 00:56:01.680]   the investors are, they also have all the documents. They got all of your corporate
[00:56:01.680 --> 00:56:06.560]   documents, the bylaws, all that kind of stuff. They can very easily execute these transactions.
[00:56:06.560 --> 00:56:12.160]   So Carta was in a great position to replace all of these secondary brokers who are running around
[00:56:12.160 --> 00:56:16.880]   creating books on their own. The problem they have is that at the end of the day,
[00:56:16.880 --> 00:56:22.000]   founders don't really want secondary markets to take place in their company shares.
[00:56:22.800 --> 00:56:27.680]   And I think there's a few reasons for that. One is price discovery. I think a lot of these
[00:56:27.680 --> 00:56:32.560]   startups now, if their shares were to be freely traded, would be trading below.
[00:56:32.560 --> 00:56:33.200]   Bad timing.
[00:56:33.200 --> 00:56:39.920]   Below the last round's mark. So they don't want it. Second, the founders don't necessarily want
[00:56:39.920 --> 00:56:43.840]   their investors getting out and then getting new investors on the cap table that they don't know.
[00:56:43.840 --> 00:56:48.480]   So founders are somewhat particular about who their shareholders are. It's different than
[00:56:49.040 --> 00:56:52.880]   public companies in that way. I mean, Apple doesn't really care who its shareholders are.
[00:56:52.880 --> 00:56:54.000]   Private companies do care.
[00:56:54.000 --> 00:56:57.440]   Do you think that that's sustainable in a world where companies take 14 or 15
[00:56:57.440 --> 00:56:58.960]   years and they're trying to retain talent?
[00:56:58.960 --> 00:57:03.520]   Well, I think it would be better for everybody if there was more
[00:57:03.520 --> 00:57:07.440]   organized liquidity. I mean, one of the things I love that SpaceX has done
[00:57:07.440 --> 00:57:12.560]   is that for the last number of years now, they've had a tender offer every year.
[00:57:12.560 --> 00:57:15.680]   And not even every year, like almost every quarter, right? It's every six months, I
[00:57:15.680 --> 00:57:18.480]   think was what my understanding of it is. But yeah, I mean, it would be
[00:57:19.120 --> 00:57:22.880]   Think about that example. So with SpaceX, it's been up and to the right on a pretty
[00:57:22.880 --> 00:57:28.320]   consistent basis. So every tender round has been a bump. Sometimes it's been a small bump,
[00:57:28.320 --> 00:57:33.520]   sometimes it's been a larger bump. The company, I don't think, has gotten greedy. So they haven't
[00:57:33.520 --> 00:57:37.920]   tried to shoot the moon and raise the valuation too much. So they've been able to keep a very
[00:57:37.920 --> 00:57:42.560]   organized process. And they've had this attitude from the beginning of letting their employees
[00:57:42.560 --> 00:57:47.280]   and investors get liquidity when they need to. So it's been great. But that's very different.
[00:57:47.280 --> 00:57:53.040]   By the way, that sort of organized tender process is very different than the secondary market that
[00:57:53.040 --> 00:57:57.600]   Carta was organizing, right? Because Carta was trying to do what all these secondary brokers
[00:57:57.600 --> 00:58:01.600]   are doing, which is they hit up people one at a time, and just say, Are you looking to buy or
[00:58:01.600 --> 00:58:06.560]   sell? And they're trying to organize secondary transactions that are not part of an official
[00:58:06.560 --> 00:58:12.400]   process. And I think that's a huge part of the problem here. Freeberg, did you have thoughts
[00:58:12.400 --> 00:58:17.840]   on it? Yeah. Well, I mean, there's an element of secondary transactions and private companies
[00:58:17.840 --> 00:58:22.720]   that are unstructured, generally being a problem. The issue with Carta was was there a violation of
[00:58:22.720 --> 00:58:27.040]   trust with respect to the transparency onto the cap table that they have access to because they
[00:58:27.040 --> 00:58:37.680]   have all the data in their systems. And when I was at Google, in '04 or so, Sergey was kind of
[00:58:37.680 --> 00:58:41.680]   throwing around the idea, why don't we start a hedge fund, because we have all this data about
[00:58:41.680 --> 00:58:46.080]   what people are searching for, and we can see all of this consumer behavior. And we could trade on
[00:58:46.080 --> 00:58:52.720]   that and have a huge data advantage in the marketplace. And ultimately, whether or not
[00:58:52.720 --> 00:58:58.960]   there was an impropriety of the use of data, and even if we excluded personal data and search data,
[00:58:58.960 --> 00:59:04.080]   just using internet based traffic and internet data, the perception of the problem would have
[00:59:04.080 --> 00:59:07.920]   damaged Google's brand so much. First of all, is there an actual conflict where you're taking
[00:59:07.920 --> 00:59:12.720]   people's what they consider to be private data, and using that to make money from their data,
[00:59:12.720 --> 00:59:19.280]   without their permission or acknowledgement or explicit consent? And secondly, even if you are
[00:59:19.280 --> 00:59:22.560]   doing this in a way that doesn't use their data, because you just generally have knowledge about
[00:59:22.560 --> 00:59:28.240]   who buyers and sellers are in the market, outside of your software, the view that you may be using
[00:59:28.240 --> 00:59:34.240]   the data in conflict can damage your brand and damage your customer relationships so much.
[00:59:34.240 --> 00:59:38.320]   So it seems, in hindsight, a little silly, but I think to Jamal's point earlier,
[00:59:38.320 --> 00:59:42.320]   it may indicate the necessity for them to think about building another business on top of this
[00:59:42.320 --> 00:59:47.120]   core software business. That is a more true marketplace driven business. So they can make,
[00:59:47.120 --> 00:59:50.480]   you know, over time more money. And that's probably where this all came from. They
[00:59:50.480 --> 00:59:53.600]   saw a need to build something that was more than just monthly.
[00:59:53.600 --> 00:59:57.680]   The truth is, they weren't making money from it, and they shut it down.
[00:59:57.680 --> 01:00:03.200]   It's true that Carta is trying to become a multi product business. They started with,
[01:00:03.200 --> 01:00:07.760]   you know, start cap tables, then they added fund management, then they added this broker business.
[01:00:07.760 --> 01:00:13.760]   But if you read Henry's last blog, the secondary market is what he originally wanted to disrupt,
[01:00:13.760 --> 01:00:19.440]   is he always wanted to create the secondary market. And he created the cap table business,
[01:00:19.440 --> 01:00:24.880]   the SaaS software, as a way to get to that. I think what he's realized is that the real value
[01:00:24.880 --> 01:00:30.320]   is in the SaaS software. And this marketplace is not that valuable. I mean, the SaaS business is
[01:00:30.320 --> 01:00:34.720]   doing something like 250 million a year of revenue. And the broker business is only doing
[01:00:34.720 --> 01:00:40.000]   a few million. Yeah, 3 million. So I think the value has turned out to be in the SaaS. And moreover,
[01:00:40.000 --> 01:00:46.400]   this broker business was compromising the trust and safety or the perception of trust
[01:00:46.400 --> 01:00:50.640]   that the company has from customers. The problem with that SaaS revenue is if you
[01:00:50.640 --> 01:00:56.160]   look at mantle and pulley, that 250 million could be 25 million.
[01:00:56.160 --> 01:00:58.480]   And cake. My investment. Yeah.
[01:00:58.480 --> 01:01:04.080]   And cake. Sorry. Yeah, and cake. But But the point is, the fact that there are there are many
[01:01:04.080 --> 01:01:10.880]   competitors, I think is a sign of the of a low barrier to entry, and a lack of a true fundamental
[01:01:10.880 --> 01:01:14.720]   lock in. Let's say you are an investor, and you're looking at pulley or mantle,
[01:01:14.720 --> 01:01:20.560]   why would you even think that's an attractive company to invest in if success looks like
[01:01:20.560 --> 01:01:24.960]   you're compressing a $250 million market down to 25 million? Like, what's the point?
[01:01:24.960 --> 01:01:28.720]   Well, I think a lot of these competitors got funded during the whole Zerp era,
[01:01:28.720 --> 01:01:32.320]   where everything got funded. I mean, if you were to if you were to look at that
[01:01:32.320 --> 01:01:34.800]   market today, why would you even fund a disruptor?
[01:01:34.800 --> 01:01:38.960]   Well, so look, I think, man, there are other strategies to those other strategies,
[01:01:38.960 --> 01:01:43.040]   you could add on to this and adjacencies. My understanding is mantle and pulley raised in the
[01:01:43.040 --> 01:01:49.680]   low single digit millions that gives them a lot of room to run a 25 and $50 million business
[01:01:49.680 --> 01:01:54.320]   profitably and never raise any more money. The problem is on the opposite side, if you raise
[01:01:54.320 --> 01:02:00.800]   money eight or nine or $10 billion, when companies traded 20 times, and now companies traded six
[01:02:00.800 --> 01:02:06.560]   times, now all of a sudden, you have to have $1.3 billion of revenue a year to break even.
[01:02:06.560 --> 01:02:10.960]   And I think that's the real problem. So it's not that Henry hasn't built a great company,
[01:02:10.960 --> 01:02:15.680]   I think he deserves a lot of credit. The question is entry point and the question is upside.
[01:02:15.680 --> 01:02:21.600]   And the upside is governed by the difficulty of the things that you're doing and how much
[01:02:21.600 --> 01:02:26.240]   pricing power you have for those difficult things. And so I think what we're realizing
[01:02:26.240 --> 01:02:31.200]   is that there are a few difficult things in software, few, it's just like, it's just true.
[01:02:31.200 --> 01:02:36.960]   And as a result, every product, this is not a Carta thing, every product will see a ton of
[01:02:36.960 --> 01:02:44.960]   competitors. So the only thing that you can do is have an extremely leveraged OpEx and an extremely
[01:02:44.960 --> 01:02:51.280]   low cost to serve. That is the only protective, protective mechanism one has, it seems to me on
[01:02:51.280 --> 01:02:57.040]   the outside looking in. Network effects are also important. Unless you have an Instagram, you're
[01:02:57.040 --> 01:03:01.680]   right, that product is infinitely better with everybody, or a tick tock. Great. Now you can
[01:03:01.680 --> 01:03:07.840]   just you can spend as much money as you want Airbnb. But that's not what I think procedural
[01:03:07.840 --> 01:03:13.440]   software is. Yeah, I don't know. I mean, look, we're gonna just have to agree to disagree. I
[01:03:13.440 --> 01:03:18.880]   think there is some pricing risks to Carta from these competitors, but my guess is it ends up
[01:03:18.880 --> 01:03:24.480]   being stickier than that. But in any event, I mean, I do think that Henry at the end of the day
[01:03:24.480 --> 01:03:28.480]   pulled off a nice save by just getting rid of the business. I agree with that altogether. I think
[01:03:28.480 --> 01:03:33.920]   that was a smart way to respond. Clearly, the first response didn't work. No, the first response
[01:03:33.920 --> 01:03:38.960]   was sort of like a very, yeah, it was a very confusing denial where he said this isn't our
[01:03:38.960 --> 01:03:44.960]   policy. But he also blamed, he also got into it and blame the person who called him out on it was
[01:03:44.960 --> 01:03:48.720]   like, what, why are you calling us out on this? And then like, every founder was like, because
[01:03:48.720 --> 01:03:55.440]   you violated our trust. And he was like, Oh, yeah, sorry. Yeah. People are showing like email
[01:03:55.440 --> 01:03:59.680]   campaigns that have been going on for months, and it seemed much more organized. And it was very
[01:03:59.680 --> 01:04:03.600]   hard to believe that this was just an accident instead of a deliberate strategy. And you could
[01:04:03.600 --> 01:04:09.840]   see the whole startup community was, you know, evaluating its options in real time on x. Yeah.
[01:04:09.840 --> 01:04:12.720]   And that's when he came out and hit the whole thing with a sledgehammer and just said, we're
[01:04:12.720 --> 01:04:16.960]   going to get out of this business. And I think it was really smart to do that. It's kind of
[01:04:16.960 --> 01:04:22.240]   called the crisis. Like I said, I don't think this is a business that startup founders want
[01:04:22.240 --> 01:04:27.680]   their cap table software to be engaged in. No, definitely not. And just by the way,
[01:04:27.680 --> 01:04:31.760]   just a third point on that, you know, one reason was price discovery. Another reason was having
[01:04:31.760 --> 01:04:36.480]   undesirable shareholders. The third reason is just founders don't want to create a competing
[01:04:36.480 --> 01:04:41.600]   fundraising process to primary financing. Yeah, I think this is actually a really important point.
[01:04:41.600 --> 01:04:46.640]   The reason why founders don't want there to be a secondary market is because their company may
[01:04:46.640 --> 01:04:52.320]   need to raise money. You want to go to the front door to the CEO and the board, not the side door
[01:04:52.320 --> 01:04:57.440]   to get a get some, you know, exposure to the company. Well, I think I think in the ZURP era,
[01:04:57.440 --> 01:05:02.400]   where there was all this excess funding flying around, then it kind of made sense to let
[01:05:02.400 --> 01:05:07.120]   secondaries happen. But in a world in which funding is scarce, you want that money to go
[01:05:07.120 --> 01:05:11.680]   into the company, not in the pockets of the early shareholders. And so I think like the timing of
[01:05:11.680 --> 01:05:16.720]   this whole thing is like really off. It all feels like kind of a function of ZURP in its own way.
[01:05:16.720 --> 01:05:20.320]   Agreed. All right, so actually we're in the group chat talking about this
[01:05:20.320 --> 01:05:25.280]   viral clip about Star Wars. You wanted to chime in on it. Maybe you could cue it up, Nick.
[01:05:25.280 --> 01:05:29.440]   I mean, as you may recall, my pick for business loser of 2023 was Disney.
[01:05:29.440 --> 01:05:34.160]   And it seems like they haven't learned anything from the horrible year they've just had.
[01:05:34.160 --> 01:05:42.480]   What is the balance of activating a force for change, but also trying to
[01:05:42.480 --> 01:05:51.120]   permeate that patriarchy, that power structure? And is that a part of the calculation of your art
[01:05:51.120 --> 01:05:54.080]   as well? And what's been the reaction to that?
[01:05:54.080 --> 01:06:02.960]   Oh, absolutely. I like to make men uncomfortable. I enjoy making men uncomfortable.
[01:06:02.960 --> 01:06:06.080]   This is the new director of Star Wars.
[01:06:06.080 --> 01:06:06.720]   All right, your thoughts.
[01:06:06.720 --> 01:06:11.520]   Well, I saw the comment on that tweet was this is going to be the
[01:06:11.520 --> 01:06:16.160]   biggest Disney flop yet. Isn't that what it said? I mean, look, I don't know what Bob Iger is doing.
[01:06:16.160 --> 01:06:21.840]   He seems to want to burn Star Wars to the ground like the rest of the Disney brands by
[01:06:21.840 --> 01:06:29.680]   playing politics. This director doesn't seem to have had a lifelong fandom for the franchise.
[01:06:29.680 --> 01:06:35.280]   She didn't really talk about how she had grown up marinating in this universe, loving its characters.
[01:06:35.280 --> 01:06:39.520]   Her background is in documentary filmmaking, and there's nothing wrong with that. But
[01:06:39.520 --> 01:06:44.400]   there's no indication from her that she truly loves Star Wars. And in fact, the
[01:06:44.400 --> 01:06:48.560]   comments that she's making right now are indicating that she's going to politicize it.
[01:06:48.560 --> 01:06:53.520]   The patriarchy is not why anybody is a fan of Star Wars or goes to see its movies.
[01:06:53.520 --> 01:06:55.840]   So nobody wants to see that movie.
[01:06:55.840 --> 01:06:56.880]   It's the opposite.
[01:06:56.880 --> 01:07:00.400]   It's the opposite. They want to avoid it. They don't go to Star Wars movies for the politics.
[01:07:00.400 --> 01:07:08.240]   And she's also trying to solve a problem that doesn't really exist. I mean, science fiction
[01:07:08.240 --> 01:07:15.200]   may skew male in its fan base, but it's not because sci-fi franchises don't like strong
[01:07:15.200 --> 01:07:19.600]   female characters. I mean, just stepping out to the larger world for a second. You've got Ripley
[01:07:19.600 --> 01:07:22.720]   in Aliens. You've got Sarah Connor in the Terminator movies. You've got-
[01:07:22.720 --> 01:07:23.440]   Princess Leia.
[01:07:23.440 --> 01:07:30.400]   Trinity and the Matrix. You've got Princess Leia, Padme, Ahsoka in Star Wars.
[01:07:30.400 --> 01:07:33.440]   You seem to know a lot of these female characters. You're deeply in Star Wars.
[01:07:33.440 --> 01:07:35.040]   Yeah, I did as well. I'm a Star Wars geek.
[01:07:35.040 --> 01:07:35.680]   I'm a Star Wars geek.
[01:07:35.680 --> 01:07:37.680]   You've got some good pulls here. Yeah, Padme.
[01:07:37.680 --> 01:07:42.560]   This idea that there aren't strong female characters in Star Wars, that's just kind
[01:07:42.560 --> 01:07:48.640]   of a myth, right? So it's not like the universe needs to be reset in this way. And you could just
[01:07:48.640 --> 01:07:53.760]   see the whole fan community kind of groaned at this comment because they're just like,
[01:07:53.760 --> 01:07:59.680]   "Oh, here we go again. Star Wars is going to ruin another franchise by playing politics."
[01:07:59.680 --> 01:08:04.400]   And the amazing thing is that Iger just doesn't seem to learn from this at all.
[01:08:04.400 --> 01:08:09.040]   But there's nothing wrong with having a female director either, right, Alex? I mean,
[01:08:09.040 --> 01:08:12.560]   you're not saying that. You're saying that a particular person who has a political agenda
[01:08:12.560 --> 01:08:16.240]   in how they want to shape the story of Star Wars is the issue?
[01:08:16.240 --> 01:08:16.880]   Of course.
[01:08:16.880 --> 01:08:17.200]   Right.
[01:08:17.200 --> 01:08:17.840]   Of course.
[01:08:17.840 --> 01:08:20.720]   I'll also say, I think one of the core driving narratives,
[01:08:20.720 --> 01:08:25.920]   emotional narratives of Star Wars is the oppressor oppressed storyline.
[01:08:25.920 --> 01:08:28.960]   It's a highly political story.
[01:08:28.960 --> 01:08:34.160]   I've always said, I think Star Wars has been like the most anti-technology
[01:08:34.160 --> 01:08:39.600]   effector in society since the 70s. Because Star Wars is all about the, I've said this before,
[01:08:39.600 --> 01:08:46.080]   but the Ewoks destroying the Death Star and like the no-tech overcoming the oppressor big tech.
[01:08:46.080 --> 01:08:50.560]   And so we have to destroy big tech. And anyone who has the better technology
[01:08:50.560 --> 01:08:55.200]   is very likely the oppressor. And they have all the wealth, and they have all the power,
[01:08:55.200 --> 01:08:59.120]   and they have all the control. And so those who do not have the power, do not have the wealth,
[01:08:59.120 --> 01:09:03.440]   do not have the control, do not have the technology, have to go and destroy that,
[01:09:03.440 --> 01:09:08.640]   whether it's the empire or that kind of evil force. And that's the core narrative of Star Wars.
[01:09:08.640 --> 01:09:12.720]   So I do think that at its heart, Star Wars in and of itself is an oppressor oppressed
[01:09:12.720 --> 01:09:19.440]   storyline that relates very deeply to technology and wealth, and has helped shape the Western
[01:09:19.440 --> 01:09:23.680]   psyche for a couple of decades in a very meaningful way, or has really reflected maybe
[01:09:23.680 --> 01:09:27.120]   perhaps the Western psyche. What did you think of Andor?
[01:09:27.120 --> 01:09:34.880]   I think you're super imposing current day terminology on a movie that was created in
[01:09:34.880 --> 01:09:41.120]   the first one in the 1970s when intersectionality did not exist. Yes, there are political overtones
[01:09:41.120 --> 01:09:47.040]   to Star Wars. You've got the rebel alliance against the empire. That is not diversity politics.
[01:09:47.040 --> 01:09:48.240]   Sorry, it's about...
[01:09:48.240 --> 01:09:50.080]   I'm not saying diversity politics.
[01:09:50.080 --> 01:09:56.240]   It's really about the corruption of power. I mean, you know, the famous phrase by Lord Acton,
[01:09:56.240 --> 01:10:00.240]   which is power corrupts and absolute power corrupts absolutely. To me, those are the
[01:10:00.240 --> 01:10:06.160]   political overtones of Star Wars. It's not about dividing the world into intersectional categories.
[01:10:06.160 --> 01:10:10.720]   It was about war. I mean, let's be honest. Lucas was a child of the Vietnam War era,
[01:10:10.720 --> 01:10:14.560]   and he was highly influenced as was Francis Ford Coppola, and...
[01:10:14.560 --> 01:10:18.800]   Yeah, the Americans with all this wealth and power came into the jungle to try and destroy
[01:10:18.800 --> 01:10:24.640]   a peasant nation and cause death upon a peasant nation, and the peasant nation survived and won.
[01:10:24.640 --> 01:10:28.800]   And there was a narrative to that, that I think is reflected in this and is reflected very deeply
[01:10:28.800 --> 01:10:34.000]   in a lot of the stories that have come since. And I'm not saying DEI as a solution was the
[01:10:34.000 --> 01:10:37.840]   storyline out of the original Star Wars, but the original Star Wars was very much driven by
[01:10:37.840 --> 01:10:43.200]   the leverage that technology provides to those in power that gives them, you know,
[01:10:43.200 --> 01:10:45.360]   extraordinary influence over those who don't have power.
[01:10:45.360 --> 01:10:49.200]   Well, if there were political overtones to the original two trilogies,
[01:10:49.200 --> 01:10:52.560]   and actually, I think there were some really interesting themes, especially in that second
[01:10:52.560 --> 01:10:56.880]   one where Palpatine sees his power. Not even political. By the way, not even political.
[01:10:56.880 --> 01:11:00.320]   Let me just be clear. Social, right? So social systems, which...
[01:11:00.320 --> 01:11:08.000]   I understand. But my point is that Lucas didn't hit anybody over the head with those themes.
[01:11:08.000 --> 01:11:13.920]   And his goal certainly wasn't to make anyone feel uncomfortable. His goal was to entertain,
[01:11:13.920 --> 01:11:18.560]   and whatever political or social overtones there were, were very much in the background,
[01:11:18.560 --> 01:11:24.800]   because that's what good art does. One of the reasons why Hollywood produces so few really
[01:11:24.800 --> 01:11:29.680]   interesting movies these days is because the political overtones are really in the forefront,
[01:11:29.680 --> 01:11:34.800]   and they really hit you over the head with them. And so therefore, they're just not very entertaining.
[01:11:34.800 --> 01:11:40.160]   It's not very good art. And I think that's why the fan community was like, "Oh, here we go again."
[01:11:40.160 --> 01:11:44.160]   Let me just make sure people understand. This is a nine-year-old clip. And for context,
[01:11:44.160 --> 01:11:49.840]   this is probably during the early days of the DEI movement, just so we're clear on that. But
[01:11:49.840 --> 01:11:54.240]   you had another point to make. David, go ahead. Well, Sax, I think that Hollywood has imposed
[01:11:54.240 --> 01:12:00.720]   upon itself certain degrees of restriction on the artistry of the artists in the community,
[01:12:00.720 --> 01:12:07.600]   because the standards now to be nominated for Best Picture define a number of DEI representation and
[01:12:07.600 --> 01:12:12.320]   inclusion standards, and they're listed here. So in order to... And if you guys will remember it
[01:12:12.320 --> 01:12:18.000]   at our summit in LA, I asked Gwyneth Paltrow about this, and she wasn't familiar with these changes
[01:12:18.000 --> 01:12:23.520]   that had been put in place. But in order to qualify for a Best Picture nomination,
[01:12:23.520 --> 01:12:28.960]   you have to meet some of these standards. And these standards include on-screen representation,
[01:12:28.960 --> 01:12:33.920]   beams and narratives that relate to having at least one of the lead characters or significant
[01:12:33.920 --> 01:12:39.520]   supporting actors come from a minority background, including ethnic background,
[01:12:40.960 --> 01:12:47.600]   or by gender... I could get nominated for an Oscar. Look, I'm Sri Lankan. South Asian. Look,
[01:12:47.600 --> 01:12:56.480]   I'm in the Parens here. Or at least 30% of the actors in a secondary group have to be women,
[01:12:56.480 --> 01:13:02.000]   racial or ethnic group, LGBTQ+, or people with cognitive or physical disabilities,
[01:13:02.000 --> 01:13:06.800]   or who are deaf or hard of hearing. The main storyline, theme, or narrative of the film is
[01:13:06.800 --> 01:13:11.440]   centered on an unrepresented group, either women, racial or ethnic group, or LGBTQ+.
[01:13:11.440 --> 01:13:16.160]   They can meet the criteria if the creative leadership team has at least two of the
[01:13:16.160 --> 01:13:19.920]   following creative leadership positions met by one of the underrepresented groups,
[01:13:19.920 --> 01:13:24.880]   and so on and so forth. If you're an artist, a filmmaker, and you wanted to make a film,
[01:13:24.880 --> 01:13:30.000]   a World War Two biopic, which was on the front lines in World War Two and was entirely white
[01:13:30.000 --> 01:13:36.160]   males, would you have been able to be nominated for Best Picture? Or would you have had to go and,
[01:13:36.160 --> 01:13:40.400]   you know, take some actions that would have affected your artistry and your freedom of
[01:13:40.400 --> 01:13:45.200]   expression in making that film? And as a big fan of film, and you guys, I think all of us are
[01:13:45.200 --> 01:13:48.880]   probably in the same boat, at least a couple of us are. Three of us are. Three of us are.
[01:13:48.880 --> 01:13:52.160]   This would have limited a lot of the best pictures of all time, I would say,
[01:13:52.160 --> 01:13:58.000]   if you had to impose standards on what the artists were allowed to do, or how they were
[01:13:58.000 --> 01:14:01.840]   allowed to make their film. And that's really what's taken over Hollywood. So I would say it's
[01:14:01.840 --> 01:14:07.120]   not just a Bob Iger Disney thing. But this has become a standard in Hollywood, that the DEI
[01:14:07.120 --> 01:14:12.560]   movement has so deeply affected the intentionality of what has historically been a truly creative.
[01:14:12.560 --> 01:14:17.600]   I agree. If you talk to Hollywood writers, if you talk to Hollywood writers, they'll tell you that
[01:14:17.600 --> 01:14:22.000]   things have become extremely politicized, and it's a mess. Iger has been a little bit contradictory
[01:14:22.000 --> 01:14:27.200]   about this. In April of last year, there was this article saying that Iger was doubling down
[01:14:27.760 --> 01:14:31.200]   on inclusivity and diversity, and he described that at a shareholders meeting.
[01:14:31.200 --> 01:14:36.800]   By November, he was saying that Disney movies have become too focused on messaging. So it
[01:14:36.800 --> 01:14:43.200]   seemed like he was finally getting it after the horrible year they had. But then we had this Star
[01:14:43.200 --> 01:14:48.160]   Wars news, and it seemed to suggest that they were hiring a director who really wasn't right
[01:14:48.160 --> 01:14:54.000]   for the material. So we'll just have to see. My sense is that they have not made the course
[01:14:54.000 --> 01:14:59.600]   correction they need. If you want to see the peak of this, there was a bunch of blowback on Dunkirk,
[01:14:59.600 --> 01:15:06.000]   and absolutely tour de force of a film if you haven't seen it. Especially go see it in IMAX,
[01:15:06.000 --> 01:15:11.600]   just extraordinary Christopher Nolan film, that it lacked diversity and gender diversity. It's
[01:15:11.600 --> 01:15:18.240]   a war film. Historically, kind of hard to make it about anything else if it was just narrowly
[01:15:18.240 --> 01:15:23.840]   focused on a couple of battles. And so yeah, this has gotten to the point of, yeah, a little bit of
[01:15:23.840 --> 01:15:28.560]   absurdity. I relate this very much to the point that we made a couple months ago about stand up
[01:15:28.560 --> 01:15:33.280]   comics being restricted and cancelled based on the things that they say that are offensive to the
[01:15:33.280 --> 01:15:40.480]   narratives of social inclusion. And de AI, these are artists who should have freedom of expression,
[01:15:40.480 --> 01:15:44.480]   creative freedom, unlimited creative freedom, if we want to have a different set of standards for
[01:15:44.480 --> 01:15:49.120]   how we value the art that comes out of it, fine, but I don't think that it ends up being true.
[01:15:50.000 --> 01:15:55.600]   So what the peer group would otherwise recognize and say, you know, is the greatest art of the
[01:15:55.600 --> 01:16:01.200]   year is the most impressive achievement of the year, in some particular artistic discipline.
[01:16:01.200 --> 01:16:08.880]   It's really sad. There's also been this change in live performances in symphonies used to be that
[01:16:08.880 --> 01:16:14.560]   to avoid discrimination, in auditions for symphony orchestras, auditions were conducted behind a
[01:16:14.560 --> 01:16:19.280]   curtain. So the director, and those who were making the election on who would get to join
[01:16:19.280 --> 01:16:24.720]   the orchestra would listen, and they wouldn't see the person performing because they were behind a
[01:16:24.720 --> 01:16:30.960]   curtain. Recently, that trend has changed. And now those artists are required to perform not behind
[01:16:30.960 --> 01:16:35.680]   a curtain, but in front of the curtain, so that we can judge them not on their musicianship,
[01:16:35.680 --> 01:16:41.120]   and their artistry, but on their race on their gender, and on some other standards. So I think
[01:16:41.120 --> 01:16:45.280]   this is obviously part of a very broad narrative, but it's it's very deeply affecting Can I ask a
[01:16:45.280 --> 01:16:50.880]   question? Community of Art? Yeah, I was about to bring you in on this, Jamal. Yeah. Is listenership
[01:16:50.880 --> 01:16:56.480]   of the symphony gone up or down? It's a load of going down for a long time, but around the world
[01:16:56.480 --> 01:17:01.280]   are seeing decline in audience, but it's it happened before the changes. Yeah, it's been
[01:17:01.280 --> 01:17:06.960]   happening. Yeah. Has it accelerated? Or has it slowed the negative decay to zero? I'm not sure.
[01:17:06.960 --> 01:17:12.160]   I'm not sure. Yeah, to be honest. Well, if it hasn't, it hasn't made a difference, then you're
[01:17:12.800 --> 01:17:18.720]   then it has made it. I mean, I think this is part of a wider discussion of dei the goal of some of
[01:17:18.720 --> 01:17:23.120]   some forms of art, like these live performing arts may not necessarily be audience growth.
[01:17:23.120 --> 01:17:29.680]   The goal may be, you know, finding the best. But I suspected it should be to sustain itself
[01:17:29.680 --> 01:17:34.000]   indefinitely. I mean, and by the way, that's, that's a big point. I've had it, which I disagree
[01:17:34.000 --> 01:17:38.640]   with the roads, as the quality of roads, fewer people will care because there are other options
[01:17:38.640 --> 01:17:43.280]   that you can go to that are high quality. And then these things will die off. And, you know,
[01:17:43.280 --> 01:17:47.760]   maybe that's what it's supposed to happen. I mean, this is part of a wider discussion about I think
[01:17:47.760 --> 01:17:54.960]   dei facing the reality of whether it's like, I guess this whole pilot thing with Boeing and who's
[01:17:54.960 --> 01:18:00.080]   getting hired to be pilots and training and what should the focus of a company board? What should
[01:18:00.080 --> 01:18:05.920]   the focus of hiring be? The problem, I think, with the argument you guys are having, in my opinion,
[01:18:05.920 --> 01:18:11.600]   is that it's a little too premature. And the reason is that there are other people who will make
[01:18:11.600 --> 01:18:18.960]   semi credible claims, while you guys make semi credible claims, and no progress is made on this
[01:18:18.960 --> 01:18:25.040]   whole dei discussion as it touches cinema and Hollywood, or music. What's much easier if you
[01:18:25.040 --> 01:18:32.640]   want to dismantle dei, which will eventually come in, cleanse Hollywood and the symphony is if you
[01:18:32.640 --> 01:18:39.200]   go to the jobs where it's irrefutable, where even the most ardent defender of dei says, you know
[01:18:39.200 --> 01:18:43.680]   what, I can't take that risk with my own family, or with my own life and the lives of my family.
[01:18:43.680 --> 01:18:49.360]   And I think that we're, we would be better off if we just focus in a really disciplined way on those
[01:18:49.360 --> 01:18:54.640]   and get the criteria to be entirely based on skill. And then eventually,
[01:18:54.640 --> 01:18:57.920]   it'll come back in Hollywood and the symphony will also get cleansed.
[01:18:59.440 --> 01:19:05.440]   So doctors, pilots, I mean, I would say certain doctors, I would just say pilots, for sure.
[01:19:05.440 --> 01:19:11.920]   I would say surgeons, I would say that you could probably go through, I haven't thought enough
[01:19:11.920 --> 01:19:17.360]   about it to know. But you could go through and say, systematically, what are the categories
[01:19:17.360 --> 01:19:27.600]   in the professional world that we interact with every day where skill can be the only criteria
[01:19:28.240 --> 01:19:33.760]   must be because otherwise, innocent lives will be lost. That's an important question.
[01:19:33.760 --> 01:19:37.760]   I agree with you that the fundamental choice that we have a society is whether
[01:19:37.760 --> 01:19:43.120]   skills is going to be the determinant of success, skills and merit, or whether it's going to be
[01:19:43.120 --> 01:19:47.360]   about something else. You know, and as soon as you tell somebody that they can't get the job,
[01:19:47.360 --> 01:19:52.720]   even though they're the most qualified, because of their race or gender, then I think that is
[01:19:53.360 --> 01:20:01.040]   racism or sexism. So it's doubly bad. But Chamath, I think the reason why this happens is because
[01:20:01.040 --> 01:20:07.120]   people don't really have the right skin in the game. So the reason why the recent discussions
[01:20:07.120 --> 01:20:14.240]   about pilots and whether cockpits should have this sort of DEI program is that everyone can relate,
[01:20:14.240 --> 01:20:20.560]   everyone has skin in the game. If your kids are going to fly on a plane, the only determinant
[01:20:20.560 --> 01:20:25.520]   you want for who the pilot is, is skill, obviously, because you have real skin in the game.
[01:20:25.520 --> 01:20:30.480]   The problem is people will falsify their preferences when they're discussing other
[01:20:30.480 --> 01:20:35.280]   people flying on the plane. So people will start saying, Well, you know, we need to have DEI
[01:20:35.280 --> 01:20:40.080]   programs. You know, in other words, when it doesn't affect me, you're willing to basically
[01:20:40.080 --> 01:20:46.160]   virtue signal and genuflect towards these programs. And I think that that's the fundamental
[01:20:46.160 --> 01:20:52.720]   problem is that people will pretend to support something other than skill and all these contexts
[01:20:52.720 --> 01:20:58.160]   where they're not directly affected. But as a society we are, with respect to aviation,
[01:20:58.160 --> 01:21:06.720]   specifically, my thought is that this is a very easy skill to determine who is high quality,
[01:21:06.720 --> 01:21:13.760]   versus not because you have such sophisticated training apparatus and schemes, simulators,
[01:21:13.760 --> 01:21:19.680]   and all of this stuff, it's easy to know how to rank people from one through n. And I think that
[01:21:19.680 --> 01:21:23.760]   as a society, if you want an efficient transportation infrastructure and aviation
[01:21:23.760 --> 01:21:27.840]   infrastructure, where the consequences are really bad, if things go wrong, you just want the best
[01:21:27.840 --> 01:21:32.240]   period end of story. However, I think it's also fair to say that then the government owes
[01:21:32.240 --> 01:21:40.000]   the people a responsibility to advance the technology, if they actually want to have
[01:21:40.000 --> 01:21:47.520]   a multifaceted hiring criteria. So what do I mean, we can have a lot more automation in the cockpit.
[01:21:47.520 --> 01:21:57.840]   The reason we don't is because of how certain lobbies are able to affect rules inside the
[01:21:57.840 --> 01:22:02.560]   federal transportation infrastructure. And we know this because our friend has been trying to
[01:22:02.560 --> 01:22:09.520]   our friend sky Dayton, wonderful pilot has been trying to improve airline safety. And he's talked
[01:22:09.520 --> 01:22:13.440]   about this a lot. And these things get blocked by the pilots union and otherwise, because they don't
[01:22:13.440 --> 01:22:17.840]   want to get disintermediate. Okay, fair enough. That's the game. Well, if that's the game,
[01:22:17.840 --> 01:22:22.560]   at some point, we need to have a conversation as a society that says, Okay, look, if we're going to
[01:22:22.560 --> 01:22:29.200]   hire on a multifaceted basis for pilots, let's also tell Boeing and Airbus, you need to build
[01:22:29.200 --> 01:22:34.800]   even better, more automated planes. That's a fair trade off. The great irony of all this acts is
[01:22:34.800 --> 01:22:41.200]   it's illegal to hire based upon gender, race, etc. And then at the same time, people are trying to
[01:22:41.200 --> 01:22:44.880]   hold this contract of, hey, we want more diversity, we want more inclusion,
[01:22:44.880 --> 01:22:51.120]   at the same time in their heads, and we're seeing lawsuits happen. So they're, you know,
[01:22:51.120 --> 01:22:55.040]   want tech companies to report on their diversity, they want venture firms to report on,
[01:22:55.040 --> 01:23:02.160]   you know, either diversity and investment, but it's illegal. And you can be sued. If you were
[01:23:02.160 --> 01:23:08.960]   to give investment dollars based on race, gender, etc. And fierce founders, I believe, is the name
[01:23:08.960 --> 01:23:14.240]   of the firm that's being sued for only investing in a certain demographic of women. Yeah, we're
[01:23:14.240 --> 01:23:17.840]   to ask people their sexual preference. You're not allowed to ask that in an employment. I don't
[01:23:17.840 --> 01:23:21.920]   know. I've always had a problem with how do you keep these two things in your mind in our own
[01:23:21.920 --> 01:23:27.120]   venture firm. And I just said to folks, just this is considered a diversity target. And now to hire
[01:23:27.120 --> 01:23:31.360]   people, whether it's on a Hollywood film set, or in your company, you've got to go ask them what
[01:23:31.360 --> 01:23:37.040]   their sexual preferences. That's, I mean, it's crazy that we're being asked to do that. And what
[01:23:37.040 --> 01:23:41.200]   I did in our company was I said, Hey, if we don't feel we're getting enough applicants for the
[01:23:41.200 --> 01:23:47.920]   programs found university, the accelerator, we could have, you know, efforts to increase the
[01:23:47.920 --> 01:23:52.960]   number of applicants. But we can't make investment decisions based on anything other than the merit
[01:23:52.960 --> 01:23:57.680]   of the company, or we will get sued. And so this is I think, the problem in corporate America with
[01:23:57.680 --> 01:24:02.400]   these issues is how do I try to help this problem if we think there is a diversity problem in our
[01:24:02.400 --> 01:24:06.960]   particular industry, which is noble and thoughtful, and I wouldn't criticize anybody for that. But
[01:24:06.960 --> 01:24:11.680]   then the rubber meets the road at legal and then performance, right. And it's very hard for,
[01:24:11.680 --> 01:24:18.480]   I think, leaders to manage those two dichotomies. I could see a case for why barbers and priests
[01:24:18.480 --> 01:24:24.880]   should be multifaceted. Good bedside manner, crack a few jokes, be able to listen,
[01:24:24.880 --> 01:24:32.480]   relate ability, ability. But if a pilot, but the first time, like the thing is now this thing is so
[01:24:32.480 --> 01:24:40.960]   on the front burner of people's minds, that, heaven forbid, if there is an incident or a near
[01:24:40.960 --> 01:24:46.400]   incident, you're going to see lawsuits that are going to focus on this issue. Show me the training
[01:24:46.400 --> 01:24:53.040]   records of the pilots. And show me show me how they fared relative to alternative folks that you
[01:24:53.040 --> 01:24:59.040]   either did hire or didn't hire. And, you know, why was this selection, it's going to be a mess.
[01:24:59.040 --> 01:25:01.520]   We might even see that with Harvard and their selection of their president.
[01:25:01.520 --> 01:25:07.040]   Like, why was this person selected as president, right? And did we change the new one or the past
[01:25:07.040 --> 01:25:11.360]   one? Like, what was there? Did we know about the plagiarism stuff? You know, did we not know about
[01:25:11.360 --> 01:25:17.600]   it? And this is, I think, the race to nowhere when you get into identity politics. And I think this
[01:25:17.600 --> 01:25:22.080]   is why everybody, and I think Coleman Hughes said it really brilliantly when he was on this pod,
[01:25:22.080 --> 01:25:27.920]   talking about his TED talk, like, we at least want the aspiration of having a colorblind society.
[01:25:27.920 --> 01:25:32.560]   I think what Coleman said that was really, I think, profound was, well, where can we actually
[01:25:32.560 --> 01:25:38.400]   affect change that will be important? And I think that's early education, it could be providing
[01:25:38.400 --> 01:25:43.760]   pre K, it could be providing, you know, support for people with childcare, so that, you know,
[01:25:43.760 --> 01:25:49.200]   they can they can get into, you know, more job training, etc. So like, where do we where do we
[01:25:49.200 --> 01:25:54.880]   put our efforts if we do want to see a more inclusive, diverse, just world is, I think,
[01:25:54.880 --> 01:25:55.280]   the question.
[01:25:55.280 --> 01:26:00.240]   Backing up a second, I think there's a fundamental dishonesty about the DEI movement that's really
[01:26:00.240 --> 01:26:05.840]   coming to the fore right now. On the one hand, the DEI activists will explicitly say that their goal
[01:26:05.840 --> 01:26:15.120]   is to engineer job categories to explicit population numbers. But like you said,
[01:26:15.120 --> 01:26:19.520]   that's actually illegal to do. So when they get in a lawsuit, like the Harvard Affirmative Action
[01:26:19.520 --> 01:26:23.920]   case that went this from court, they'll deny that they're discriminating against Asian Americans. So
[01:26:23.920 --> 01:26:27.920]   when they're preaching for what they want to do, when they talk about, say,
[01:26:27.920 --> 01:26:33.600]   Kennedy style anti racism, they will say that the explicit goal here is proportional representation.
[01:26:33.600 --> 01:26:38.400]   But then when that results in discrimination against groups that are basically selected
[01:26:38.400 --> 01:26:42.480]   against, they'll deny that that's what they're doing. And I think it's gotten to the point now
[01:26:42.480 --> 01:26:47.600]   where they just can't maintain both things being true. And I think we saw this in the
[01:26:47.600 --> 01:26:53.200]   dustup that just happened between Elon and Mark Cuban, where Elon was saying, "Look, we should be
[01:26:53.200 --> 01:27:00.240]   a colorblind, meritorious society. We just shouldn't discriminate for or against anybody
[01:27:00.240 --> 01:27:04.160]   on the basis of race." And then Cuban jumps in and says, "Oh, no, that's not what DEI is doing.
[01:27:04.160 --> 01:27:09.440]   DEI is just trying to expand the pool of applicants." And it's just not true. I mean,
[01:27:09.440 --> 01:27:12.720]   I don't know if he's being disingenuous. I don't know if he's virtue signaling.
[01:27:12.720 --> 01:27:15.040]   Aaron Powell: I think they were talking through each other. I mean,
[01:27:15.040 --> 01:27:19.200]   you do want to expand the pool if you're not getting a pool of diverse applicants.
[01:27:19.200 --> 01:27:22.640]   There's nothing wrong with that, expanding the pool. But what you are correct,
[01:27:22.640 --> 01:27:26.480]   there was a DEI grift that occurred. I think that's kind of what you're alluding to. And I
[01:27:26.480 --> 01:27:28.560]   can tell you the inside story on the grift. Mark Miller: I think that if you look at the
[01:27:28.560 --> 01:27:34.560]   DEI movement, it goes way, way beyond just expanding the pool of applicants. It explicitly
[01:27:35.120 --> 01:27:41.760]   puts its thumb on the scale in terms of what it's looking for in terms of hiring and promotion.
[01:27:41.760 --> 01:27:45.120]   Aaron Powell: It turned into a grift. And I can tell you the inside story on this. And it's going
[01:27:45.120 --> 01:27:50.080]   to come out eventually. But there was a, I don't know if you experienced this in any of your
[01:27:50.080 --> 01:27:57.120]   companies, or if anybody's willing to talk about it, but company has lack of diversity in their
[01:27:57.120 --> 01:28:03.120]   company. Then diversity activists, and this is, I think, where it really started to build up
[01:28:03.120 --> 01:28:08.000]   resentment. Diversity activist comes in, says, "Hey, you have problems." They call them out on
[01:28:08.000 --> 01:28:14.320]   social media. There was a Twitter brigade comes in, "Oh, my God, look how horrible this company
[01:28:14.320 --> 01:28:17.520]   is." People go, "Oh, I'm sorry, we didn't want to be horrible." And then they say, "Oh, well,
[01:28:17.520 --> 01:28:22.160]   hire us. And we'll teach you how to do DEI. And let's build a DEI group. And we want to be
[01:28:22.160 --> 01:28:26.320]   consultants. Pay us to come in, pay us to speak at your organization, to tell you what you're
[01:28:26.320 --> 01:28:33.200]   doing wrong. And then rally a reverse support of it after you've gotten paid for solving the
[01:28:33.200 --> 01:28:38.400]   problem for them." And I saw this shakedown occur. And I had people ask me for advice on like, "Hey,
[01:28:38.400 --> 01:28:43.120]   what do we do here?" And you can just imagine, you know, you're a person of good faith who
[01:28:43.120 --> 01:28:49.360]   wants to do the right thing. And then these DEI folks come in and then try to brigade you basically
[01:28:49.360 --> 01:28:55.200]   publicly shame you in order to get like rich DEI contracts. And we saw this with like the size of
[01:28:55.200 --> 01:28:58.560]   DEI groups at companies and you're wondering, "Well, what are these people actually doing? Are
[01:28:58.560 --> 01:29:05.360]   they just what does a DEI department actually do inside of a company that is a creative or
[01:29:05.360 --> 01:29:10.960]   valuable?" It creates more bureaucracy to do more DEI. Right. Exactly. And that's why I keep saying
[01:29:10.960 --> 01:29:14.800]   bigger and bigger. Did you guys see the size of the Michigan DEI group? Did you see that tweet?
[01:29:14.800 --> 01:29:18.800]   I thought that was a I thought this was a Babylon B story when I first saw it because
[01:29:19.920 --> 01:29:24.800]   there are 250 people working for DEI. 500 people at Michigan. What?
[01:29:24.800 --> 01:29:29.120]   What's the denominator? 500 out of how many people? I don't know,
[01:29:29.120 --> 01:29:35.360]   but they're spending $30 million on payroll benefits. I mean, look, big companies can
[01:29:35.360 --> 01:29:39.680]   kind of afford this stuff, but startups cannot. I mean, this is really the kiss of death for
[01:29:39.680 --> 01:29:45.600]   startups. You just can't afford to have these large bureaucracies. And then also, you know,
[01:29:45.600 --> 01:29:50.720]   when you're a startup founder, if you have six months of runway, 12 months of runway,
[01:29:50.720 --> 01:29:54.080]   you might not have the luxury to be looking at your statistics and saying, "You know what?
[01:29:54.080 --> 01:30:02.320]   We've got 10 people who are of this demographic. Statistically, we should have this. So the next
[01:30:02.320 --> 01:30:08.640]   hire we need to make our sales numbers has to be of this composure." And I've have seen people do
[01:30:08.640 --> 01:30:12.480]   this. Actually, you've probably seen it too on boards or whatever. "Hey, we need to hire more
[01:30:12.480 --> 01:30:19.120]   of this type of person, this profile." And, you know, then hiring gets slowed and, you know,
[01:30:19.120 --> 01:30:24.800]   yeah, it's challenging and it's also illegal. So, I don't know how you win in this thing
[01:30:24.800 --> 01:30:31.360]   other than have a colorblind society as a goal, at least, you know, and to put your efforts-
[01:30:31.360 --> 01:30:34.960]   Jason, are you familiar with a Mott and Bailey tactic?
[01:30:34.960 --> 01:30:36.480]   No, Tom.
[01:30:36.480 --> 01:30:41.360]   Have you heard of this? This is a rhetorical technique or fallacy?
[01:30:42.000 --> 01:30:44.240]   No, I haven't heard this one. Yeah. I love a good-
[01:30:44.240 --> 01:30:48.640]   So, this comes from medieval times. The Mott and Bailey was a type of castle where
[01:30:48.640 --> 01:30:53.520]   the Bailey was this wider area that was just defended by a wooden wall. So, it's not that
[01:30:53.520 --> 01:31:00.560]   secure. The Mott was basically the, you know, stone fortress on the hill. So, a Mott and Bailey
[01:31:00.560 --> 01:31:05.440]   tactic is when you go out and stake out a very aggressive position. You take the Bailey,
[01:31:05.440 --> 01:31:10.080]   basically. But then when you get challenged, you retreat into the Mott and pretend like you never
[01:31:10.080 --> 01:31:17.120]   took the Bailey position. The Bailey position is basically the Kendi-style anti-racism where you
[01:31:17.120 --> 01:31:22.240]   say, "Look, we have to achieve proportional representation in every job category." And
[01:31:22.240 --> 01:31:29.680]   that is what the DI movement in the main advocates for. But then when they get challenged by somebody
[01:31:29.680 --> 01:31:33.200]   like Elon or by somebody like the Supreme Court, they retreat into the Mott and just say, "No,
[01:31:33.200 --> 01:31:38.160]   no. We weren't trying to do that. We're just trying to expand the pool of qualified applicants
[01:31:38.160 --> 01:31:42.640]   because who could be against that?" And they'll claim that they were never doing the whole
[01:31:42.640 --> 01:31:46.880]   proportional representation thing. And then on top of it, they'll say, "Well, listen, obviously,
[01:31:46.880 --> 01:31:53.120]   increasing the pool of qualified applicants is so unobjectionable that if you're against that,
[01:31:53.120 --> 01:31:58.480]   then you must be racist." And then you get all the accusations. And so, this is basically the
[01:31:58.480 --> 01:32:04.400]   rhetorical technique that the movement uses to defend itself. But eventually, when this stuff
[01:32:04.400 --> 01:32:08.880]   gets litigated, as it just did at the Supreme Court, you start to pick this apart and you see
[01:32:08.880 --> 01:32:14.240]   that there's a lot of evidence that they are actually engaged in overt discrimination against
[01:32:14.240 --> 01:32:21.280]   certain groups like Asian Americans. >>No easy answers here, but I, for one,
[01:32:21.280 --> 01:32:27.280]   think that that's bad. >>Yeah. There was something really nice about a merit-based society if there
[01:32:27.280 --> 01:32:31.520]   was fairness at the starting line. But that's the thing I've learned is not everybody starts at the
[01:32:31.520 --> 01:32:36.080]   same place. And so, if you just look at, it seems to me, and listen, I'm no expert,
[01:32:36.080 --> 01:32:43.040]   but the starting line seems to matter most. So, if we could focus on making it as equal and fair
[01:32:43.040 --> 01:32:49.440]   and just when it comes to education, that seems to me to be like the quickest solution to feeling
[01:32:49.440 --> 01:32:54.560]   better about all this. I just think we should have seven-day, 365-day-a-year school available,
[01:32:54.560 --> 01:33:00.320]   public school available, competitive schools available to make the world more just and give
[01:33:00.320 --> 01:33:04.720]   people more opportunity, right, skills training, etc. >>Why do you think that having school
[01:33:04.720 --> 01:33:12.240]   365 days a year will make the world more just? >>Well, because I do think that if you had more
[01:33:12.240 --> 01:33:17.680]   competition in schools and you had parents who care or students who care and they could get
[01:33:17.680 --> 01:33:23.280]   more education and there was more available, then you could say, "Well, how many days a week did
[01:33:23.280 --> 01:33:27.920]   you go to school? How much effort did you put in?" And there was just more high-quality school
[01:33:27.920 --> 01:33:31.840]   available. And if you look at public schools right now, there's just, it's very unjust how
[01:33:31.840 --> 01:33:36.720]   poor the schools are and how poorly run they are and what the teachers' unions have done to these
[01:33:36.720 --> 01:33:43.200]   schools in disadvantaged communities. And if I look back on my life and I look at people who
[01:33:43.200 --> 01:33:48.800]   did well, they had engaged parents and they had opportunities in education that other people
[01:33:48.800 --> 01:33:53.600]   didn't. And that seems... >>How does keeping the school open all year round change that?
[01:33:53.600 --> 01:33:59.600]   >>You think about parents who maybe don't have coverage for their kids after 2.30 or 3 o'clock,
[01:33:59.600 --> 01:34:03.520]   and then those kids, you know, we called them, we were called latchkey kids, I think,
[01:34:03.520 --> 01:34:08.400]   in the 80s and 90s. You're having the ability for them to do more enriching things, to be in chess
[01:34:08.400 --> 01:34:14.000]   club, to be in Taekwondo club, to do a little extra math, whatever it is. That could be something
[01:34:14.000 --> 01:34:18.800]   society could do for a very low cost or skills training even, right? Hey, this is a culinary
[01:34:18.800 --> 01:34:22.240]   school after school, this is a culinary school on the weekends, this is a coding school on the
[01:34:22.240 --> 01:34:26.720]   weekends. It doesn't have to be just STEM, it could be welding, it could be, like I said, you
[01:34:26.720 --> 01:34:31.520]   know, it could be design, whatever it is. More opportunities for people to learn more skills
[01:34:31.520 --> 01:34:36.960]   without, you know, having the benchmark be my parents can afford Kumon, my parents can afford
[01:34:36.960 --> 01:34:42.400]   a chess tutor, right? We live in a time of incredible privilege and all of us have unlimited
[01:34:42.400 --> 01:34:46.320]   resources and many of the people who listen to this podcast have a lot of resources to hire
[01:34:46.320 --> 01:34:49.840]   tutors for their kids and give them more opportunity. I didn't have that opportunity,
[01:34:49.840 --> 01:34:55.040]   you know, and if I had that opportunity, I would have learned chess faster, right? I would have had
[01:34:55.040 --> 01:34:58.720]   more opportunity for it, it just wasn't available to me and then there's a lot of people who started
[01:34:58.720 --> 01:35:04.640]   behind me who certainly didn't have it available, single parent, you know, and in a worse school
[01:35:04.640 --> 01:35:09.040]   environment than Brooklyn where I grew up. So, I don't know, do you disagree, Chamar?
[01:35:09.040 --> 01:35:13.600]   Would you have a better idea of how to make the world more fair and just than education
[01:35:13.600 --> 01:35:15.040]   and skills training?
[01:35:15.040 --> 01:35:21.360]   I think education is probably the most important. I do think that we need to find it fashionable
[01:35:21.360 --> 01:35:30.880]   again to have nuclear families. I think that if you look at the marriage rates of 20 and 30 year
[01:35:30.880 --> 01:35:36.320]   olds, it's meaningfully depressed relative to older cohorts including ours. We're the last
[01:35:36.320 --> 01:35:42.560]   generation where it's a structural part of our identity is being married and I think that that
[01:35:42.560 --> 01:35:47.920]   has long-term implications because when you look at the success rates of how to grow kids,
[01:35:47.920 --> 01:35:53.280]   poverty matters a lot less than having a structural nuclear family, meaning a two-parent
[01:35:53.280 --> 01:35:59.360]   household. And so, I think that there's a lot of work we need to do to figure out how to
[01:35:59.360 --> 01:36:07.360]   re-incentivize folks to want to commit to a single person, not this rampant promiscuity but
[01:36:07.360 --> 01:36:11.440]   just kind of lock down and find somebody and build a long-term partnership with them. I think that
[01:36:11.440 --> 01:36:13.760]   that's really crucial for a functioning society.
[01:36:13.760 --> 01:36:18.480]   >> Giving tax incentives is the way to do that or just cultural norms?
[01:36:18.480 --> 01:36:20.960]   >> I haven't studied the problem to have the right idea.
[01:36:20.960 --> 01:36:25.280]   >> Yeah, I've heard this before. I just don't know how that gets implemented in society,
[01:36:25.280 --> 01:36:30.880]   right? And I can think of ways that tutoring and having more education available, vouchers,
[01:36:30.880 --> 01:36:36.480]   etc. I mean, if you gave every parent under a certain dollar amount of income a year,
[01:36:36.480 --> 01:36:41.600]   a voucher to hire tutors, man, that could change the world, right? It could change a
[01:36:41.600 --> 01:36:44.080]   lot of people's fate. >> We need more two-parent households.
[01:36:44.080 --> 01:36:49.200]   >> That would certainly help more. All right, well, we really got into it here in the end,
[01:36:49.200 --> 01:36:56.720]   man. What a great episode. All right, for the rain man, David Sachs, with a tight haircut now,
[01:36:56.720 --> 01:37:00.560]   the dream is over. I mean, it's just... >> It's a new year.
[01:37:00.560 --> 01:37:02.400]   >> I don't know who got to you. >> It's a new year.
[01:37:02.400 --> 01:37:05.520]   >> It's an election year. It's a big year for you.
[01:37:05.520 --> 01:37:10.080]   >> Got to clean it up, clean it up for... >> I think it's just a huge critical mistake.
[01:37:10.080 --> 01:37:15.680]   I think you were going to a certain iconic look, and I think you've blown it. I'm going
[01:37:15.680 --> 01:37:20.400]   to take the other side of that bet. And for David Freeberg, the CEO of Ohalo,
[01:37:20.400 --> 01:37:28.160]   and Chamath Palihapitiya, the founder of the new 80/90 incubator, and the chairman dictator
[01:37:28.160 --> 01:37:33.920]   of the all-in LLC, I am the world's greatest moderator. >> Yes, you are.
[01:37:33.920 --> 01:37:36.720]   >> And angel investor, and we'll see you all next time. Bye-bye.
[01:37:36.720 --> 01:37:37.840]   >> Love you, boys. >> Bye-bye.
[01:37:37.840 --> 01:37:38.720]   >> Love you, guys. >> Bye-bye.
[01:37:38.720 --> 01:37:48.720]   [Music]
[01:37:48.720 --> 01:37:51.680]   >> Consorts it to the fans, and they've just gone crazy with it.
[01:37:51.680 --> 01:37:53.600]   >> Love you, Wesley. >> I'm the queen of quinoa.
[01:37:53.600 --> 01:37:56.720]   >> I'm going all in. >> What's your winner's line?
[01:37:56.720 --> 01:38:01.600]   What's your winner's line? >> Besties are gone.
[01:38:01.600 --> 01:38:08.960]   >> That's my dog taking a piss in your driveway. >> Oh, man.
[01:38:08.960 --> 01:38:14.000]   >> We should all just get a room and just have one big huge orgy, because they're all
[01:38:14.000 --> 01:38:17.760]   just useless. It's like this sexual tension that they just need to release somehow.
[01:38:18.560 --> 01:38:22.480]   >> Wet your beef. >> Wet your beef.
[01:38:22.480 --> 01:38:24.240]   >> Wet your beef. >> Beef, that's going to be good.
[01:38:24.240 --> 01:38:26.240]   We need to get merch. >> Besties are gone.
[01:38:26.240 --> 01:38:36.880]   >> I'm going all in. I'm going all in.
[01:38:36.880 --> 01:38:37.380]   you
[01:38:37.380 --> 01:38:47.380]   [BLANK_AUDIO]

