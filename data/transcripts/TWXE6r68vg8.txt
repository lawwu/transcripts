
[00:00:00.000 --> 00:00:09.900]   [MUSIC]
[00:00:09.900 --> 00:00:14.160]   Welcome to Bogleheads on Investing, episode number 56.
[00:00:14.160 --> 00:00:18.920]   Today's special guest is Dr. Daniel Crosby, a psychologist and
[00:00:18.920 --> 00:00:23.040]   a behavioral finance expert who helps organizations and
[00:00:23.040 --> 00:00:27.480]   individuals understand the intersection of mind and markets.
[00:00:27.480 --> 00:00:37.480]   [MUSIC]
[00:00:37.480 --> 00:00:41.980]   Hi everyone, my name is Rick Ferry and I'm the host of Bogleheads on Investing.
[00:00:41.980 --> 00:00:44.520]   This episode, as with all episodes,
[00:00:44.520 --> 00:00:48.800]   is brought to you by the John C. Bogle Center for Financial Literacy.
[00:00:48.800 --> 00:00:52.720]   A non-profit organization that is building a world of well-informed,
[00:00:52.720 --> 00:00:55.280]   capable, and empowered investors.
[00:00:55.280 --> 00:01:00.280]   Visit the Bogle Center at boglecenter.net, where you will find a treasure
[00:01:00.280 --> 00:01:04.280]   trove of information, including transcripts of these podcasts.
[00:01:04.280 --> 00:01:07.960]   Today, our special guest is Dr. Daniel Crosby.
[00:01:07.960 --> 00:01:13.360]   Educated at Brigham Young and Emory University, Dr. Crosby is a psychologist
[00:01:13.360 --> 00:01:17.480]   and behavioral finance expert who helps organizations and
[00:01:17.480 --> 00:01:22.400]   individuals understand their mind and the markets.
[00:01:22.400 --> 00:01:26.120]   He has written several books on behavioral finance.
[00:01:26.120 --> 00:01:31.920]   The Laws of Wealth was named one of the best investment books of 2017, and
[00:01:31.920 --> 00:01:37.560]   his latest book, The Behavioral Investor, is an in-depth look at how sociology,
[00:01:37.560 --> 00:01:42.600]   psychology, and neurology all impact investment decision-making.
[00:01:42.600 --> 00:01:46.680]   So with no further ado, let me introduce Dr. Daniel Crosby.
[00:01:46.680 --> 00:01:50.560]   Welcome to the Bogleheads on Investing podcast, Doctor.
[00:01:50.560 --> 00:01:54.320]   Yeah, Rick, great to be here, and please just call me Daniel.
[00:01:54.320 --> 00:01:55.640]   Daniel, thank you so much.
[00:01:55.640 --> 00:02:02.360]   You've got a very deep background in behavioral investing and
[00:02:02.360 --> 00:02:07.440]   have written several books and are a noted authority on this topic.
[00:02:07.440 --> 00:02:10.280]   So I'm really happy to have you on the podcast.
[00:02:10.280 --> 00:02:14.240]   Although I do say every time I have a behavioral finance person,
[00:02:14.240 --> 00:02:17.160]   I feel very inadequate at the end of the podcast.
[00:02:17.160 --> 00:02:23.440]   [LAUGH] Because all of my mistakes are remembered during the podcast.
[00:02:23.440 --> 00:02:29.360]   But tell us a little bit about you, your childhood memories, school.
[00:02:29.360 --> 00:02:32.040]   I mean, how did you get to where you are today?
[00:02:32.040 --> 00:02:36.920]   Sure, you got to ask about childhood memories when you have a shrink on,
[00:02:36.920 --> 00:02:37.440]   for sure.
[00:02:37.440 --> 00:02:39.320]   So great question.
[00:02:39.320 --> 00:02:42.360]   So I'm actually a clinical psychologist by education.
[00:02:42.360 --> 00:02:44.200]   I wasn't joking about being a shrink.
[00:02:44.200 --> 00:02:48.800]   I went to school with the aim of working in clinical psychology, and
[00:02:48.800 --> 00:02:50.920]   indeed, that's what my degree is in.
[00:02:50.920 --> 00:02:56.840]   But about three years into what is a five-year program, I began to burn out.
[00:02:56.840 --> 00:02:58.960]   I was already seeing 30 or
[00:02:58.960 --> 00:03:05.160]   40 clients a week as part of sort of fulfillment of my doctoral degree.
[00:03:05.160 --> 00:03:09.320]   And most of them were what we would call the worried well,
[00:03:09.320 --> 00:03:12.960]   folks like me or you who are just like hit a rough patch.
[00:03:12.960 --> 00:03:17.840]   But some of them were court appointed, some of them were criminals, and
[00:03:17.840 --> 00:03:21.200]   some of them were acutely suicidal.
[00:03:21.200 --> 00:03:25.680]   And I was just candidly had poor boundaries.
[00:03:25.680 --> 00:03:30.640]   I was taking my work home with me, and it was just taking a toll on me.
[00:03:30.640 --> 00:03:35.240]   I went to my father, who is a financial advisor.
[00:03:35.240 --> 00:03:39.400]   And I said, look, dad, I love human psychology.
[00:03:39.400 --> 00:03:43.080]   I love studying the reasons why people do the things that they do.
[00:03:43.080 --> 00:03:46.960]   I love the academic pursuit of studying human behavior.
[00:03:46.960 --> 00:03:52.800]   But I don't know if this applied medical context is the right one for me.
[00:03:52.800 --> 00:03:57.160]   And he said, well, there's a ton of psychology in my work.
[00:03:57.160 --> 00:04:01.160]   And at the time, I started my PhD when I was 23.
[00:04:01.160 --> 00:04:05.040]   I don't think I had a real deep understanding of what my dad did.
[00:04:05.040 --> 00:04:08.240]   To me, he was a numbers guy and a sales guy.
[00:04:08.240 --> 00:04:10.600]   And so I was like, what are you talking about?
[00:04:10.600 --> 00:04:12.600]   And he said, no, give it a look.
[00:04:12.600 --> 00:04:17.800]   Now, my dad is a wire house advisor in a midsize town in Alabama.
[00:04:17.800 --> 00:04:21.200]   He didn't have an understanding of what behavioral economics or
[00:04:21.200 --> 00:04:22.800]   behavioral finance were.
[00:04:22.800 --> 00:04:27.240]   But he knew that a big part of his job was counseling his clients.
[00:04:27.240 --> 00:04:31.880]   Long story short, this conversation with my dad pointed me in a direction
[00:04:31.880 --> 00:04:36.320]   where I went and started looking into the literature around money.
[00:04:36.320 --> 00:04:39.560]   There weren't a lot of resources for folks like my dad.
[00:04:39.560 --> 00:04:42.840]   There was this ivory tower, sort of academic research being done.
[00:04:42.840 --> 00:04:47.320]   But there wasn't a whole lot of translating that down in applied ways
[00:04:47.320 --> 00:04:49.960]   for people on the street and for advisors.
[00:04:49.960 --> 00:04:53.720]   And so I've tried to make that my place in the food chain.
[00:04:53.720 --> 00:04:59.520]   And along the way in this journey, you've written five books.
[00:04:59.520 --> 00:05:02.880]   The first book, again, to make me feel inadequate,
[00:05:02.880 --> 00:05:05.800]   was called You're Not That Great.
[00:05:05.800 --> 00:05:09.680]   Could you just tell us what are two sentences about that book?
[00:05:09.680 --> 00:05:14.320]   Yeah, that was based on a TEDx talk I did that was really well-received.
[00:05:14.320 --> 00:05:17.720]   And basically, the idea of You're Not That Great
[00:05:17.720 --> 00:05:20.680]   is that part of living an extraordinary life
[00:05:20.680 --> 00:05:25.080]   is accepting your own personal banality and mediocrity.
[00:05:25.080 --> 00:05:28.040]   And I think no one understands that better than Fogelheads.
[00:05:28.040 --> 00:05:29.400]   And that's not a diss, right?
[00:05:29.400 --> 00:05:34.040]   It's that you understand that, on average, you are pretty average.
[00:05:34.040 --> 00:05:38.160]   And accepting that and owning your own failings
[00:05:38.160 --> 00:05:41.440]   is sort of paradoxically a way to enjoy great returns
[00:05:41.440 --> 00:05:42.640]   and to have a great life.
[00:05:42.640 --> 00:05:45.640]   So it was sort of the perils of overconfidence
[00:05:45.640 --> 00:05:49.800]   and the joys of mediocrity is what that book is about.
[00:05:49.800 --> 00:05:54.600]   Getting into another topic, another book, the second one you wrote,
[00:05:54.600 --> 00:05:56.880]   Everyone You Love Will Die.
[00:05:56.880 --> 00:05:59.560]   OK, so what's this about?
[00:05:59.560 --> 00:06:01.160]   Are you sensing a theme here?
[00:06:01.160 --> 00:06:07.080]   So yeah, for what it's worth, neither of these books sold very well.
[00:06:07.080 --> 00:06:10.720]   So Everyone You Love Will Die is kind of a funny story, believe it or not.
[00:06:10.720 --> 00:06:15.920]   I have three children, and we had a close family friend pass away.
[00:06:15.920 --> 00:06:17.480]   And we were going to the funeral.
[00:06:17.480 --> 00:06:19.960]   And at the time, my children were very young.
[00:06:19.960 --> 00:06:23.000]   And I was writing poetry.
[00:06:23.000 --> 00:06:26.040]   And one of the ways that I tried to communicate with my kids
[00:06:26.040 --> 00:06:29.760]   was by writing sort of Shel Silverstein-esque poems
[00:06:29.760 --> 00:06:31.520]   about difficult topics.
[00:06:31.520 --> 00:06:37.520]   And so I wrote this poem that is, believe it or not, kind of sweet.
[00:06:37.520 --> 00:06:41.960]   And the last stanza of the poem is, yes, everyone you love will die,
[00:06:41.960 --> 00:06:44.200]   but you're here today and so am I.
[00:06:44.200 --> 00:06:45.040]   Very nice.
[00:06:45.040 --> 00:06:49.400]   It's just sort of the stoic idea that understanding life's brevity
[00:06:49.400 --> 00:06:53.400]   gives it punch and gives it importance and gives you a sense of how
[00:06:53.400 --> 00:06:55.440]   you want to spend your time.
[00:06:55.440 --> 00:06:57.120]   And so I wrote this poem.
[00:06:57.120 --> 00:06:59.320]   I put it on Facebook.
[00:06:59.320 --> 00:07:04.000]   A friend of mine who is an artist really liked it and illustrated it
[00:07:04.000 --> 00:07:07.880]   without my knowledge, sort of illustrated each stanza,
[00:07:07.880 --> 00:07:09.800]   sent me the drawing.
[00:07:09.800 --> 00:07:12.800]   And I said, well, look, now we've got words and pictures.
[00:07:12.800 --> 00:07:13.840]   Let's make this a book.
[00:07:13.840 --> 00:07:15.440]   We put it on Kickstarter.
[00:07:15.440 --> 00:07:18.240]   Kickstarter made it their editor's pick of the day.
[00:07:18.240 --> 00:07:21.200]   And so it got funded in like five hours.
[00:07:21.200 --> 00:07:24.080]   And we had enough to print a couple hundred copies
[00:07:24.080 --> 00:07:26.080]   and send them out to the people who backed it.
[00:07:26.080 --> 00:07:29.080]   So it's actually free on Amazon now.
[00:07:29.080 --> 00:07:31.880]   So yeah, go get it for free on Amazon and have a look.
[00:07:31.880 --> 00:07:32.960]   I love that line.
[00:07:32.960 --> 00:07:36.480]   Everyone we know will die, but you are here and so am I.
[00:07:36.480 --> 00:07:38.040]   That's a great line.
[00:07:38.040 --> 00:07:39.360]   Thank you.
[00:07:39.360 --> 00:07:41.320]   OK, now we're going to pivot a little bit.
[00:07:41.320 --> 00:07:43.880]   And now we're going to get into investing topics.
[00:07:43.880 --> 00:07:46.080]   Because your first book seems to be more of kind
[00:07:46.080 --> 00:07:48.920]   of an institutional book for advisors.
[00:07:48.920 --> 00:07:54.000]   It's called Personal Benchmark, Integrating Behavioral Finance
[00:07:54.000 --> 00:07:55.400]   and Investment Management.
[00:07:55.400 --> 00:07:59.680]   So this is your first forte into behavioral investing.
[00:07:59.680 --> 00:08:01.160]   So tell us about this book.
[00:08:01.160 --> 00:08:04.800]   Personal Benchmark is really about indexing to your life.
[00:08:04.800 --> 00:08:06.600]   We know that benchmarks matter.
[00:08:06.600 --> 00:08:09.480]   What you choose to measure your life and your performance
[00:08:09.480 --> 00:08:13.120]   against has a material impact on your behavior.
[00:08:13.120 --> 00:08:16.320]   There's actually a really robust literature around the idea
[00:08:16.320 --> 00:08:19.520]   that benchmarking to things that matter to you
[00:08:19.520 --> 00:08:21.560]   can elicit better behavior.
[00:08:21.560 --> 00:08:24.960]   People in named accounts are more likely to save.
[00:08:24.960 --> 00:08:26.480]   They're less likely to go to cash
[00:08:26.480 --> 00:08:28.720]   when markets get turbulent.
[00:08:28.720 --> 00:08:31.160]   And so it's sort of the overarching idea
[00:08:31.160 --> 00:08:35.400]   is integrate your personal mission, your personal purpose
[00:08:35.400 --> 00:08:37.600]   into the way that you think about your wealth,
[00:08:37.600 --> 00:08:42.120]   and you'll likely be better at staying the course.
[00:08:42.120 --> 00:08:45.760]   The next book now you're really beginning to dig into this idea
[00:08:45.760 --> 00:08:49.800]   is called The Laws of Wealth, Psychology and the Secret
[00:08:49.800 --> 00:08:52.120]   to Investing Success.
[00:08:52.120 --> 00:08:55.040]   So tell us the main points of this book.
[00:08:55.040 --> 00:08:59.040]   Yeah, so The Laws of Wealth came about in an interesting way.
[00:08:59.040 --> 00:09:02.120]   In almost every instance, there was some sort of spark
[00:09:02.120 --> 00:09:04.520]   that was sort of the genesis for these books.
[00:09:04.520 --> 00:09:08.240]   I was speaking, and I was setting forth this idea
[00:09:08.240 --> 00:09:12.200]   to advisors of a behavioral policy statement.
[00:09:12.200 --> 00:09:14.800]   So you know, I work primarily with financial advisors,
[00:09:14.800 --> 00:09:16.920]   and an advisor will give their clients
[00:09:16.920 --> 00:09:19.200]   an investment policy statement.
[00:09:19.200 --> 00:09:21.160]   That sort of, these are the rules of the road, right?
[00:09:21.160 --> 00:09:22.800]   Like, these are the best practices
[00:09:22.800 --> 00:09:27.120]   I will adhere to in the management of your wealth.
[00:09:27.120 --> 00:09:31.000]   But I was advocating for the other side of that,
[00:09:31.000 --> 00:09:33.960]   sort of understanding that the advisor-client relationship
[00:09:33.960 --> 00:09:37.600]   requires both people pulling in the same direction.
[00:09:37.600 --> 00:09:40.040]   And I said, look, it's important that you help manage
[00:09:40.040 --> 00:09:42.200]   your client's expectations and let them know
[00:09:42.200 --> 00:09:44.040]   that this is a two-way street.
[00:09:44.040 --> 00:09:46.680]   So I said, look, you should have a behavioral policy statement
[00:09:46.680 --> 00:09:48.240]   that says, I, your advisor,
[00:09:48.240 --> 00:09:50.040]   these are the things that I will do.
[00:09:50.040 --> 00:09:53.280]   You, the client, these are sort of my expectations of you.
[00:09:53.280 --> 00:09:55.720]   And it's all this stuff you'd expect,
[00:09:55.720 --> 00:09:59.560]   remaining long-term, sort of having a proper media diet,
[00:09:59.560 --> 00:10:01.120]   things like that.
[00:10:01.120 --> 00:10:03.920]   - Well, say that again, a proper media diet?
[00:10:03.920 --> 00:10:05.520]   - Yeah, a proper media diet.
[00:10:05.520 --> 00:10:08.900]   So like, making sure you're not filling your head
[00:10:08.900 --> 00:10:12.680]   with doom-scrolling and unnecessary cataclysmic--
[00:10:12.680 --> 00:10:14.640]   - Oh, you mean watching Jim Cramer.
[00:10:14.640 --> 00:10:15.560]   (laughing)
[00:10:15.560 --> 00:10:17.480]   - I will refrain from naming names.
[00:10:17.480 --> 00:10:18.320]   (laughing)
[00:10:18.320 --> 00:10:22.200]   But yeah, just putting the right ideas in your head, right?
[00:10:22.200 --> 00:10:25.200]   Like, and knowing that these can have a material impact
[00:10:25.200 --> 00:10:27.880]   on the way you think and act in markets.
[00:10:27.880 --> 00:10:30.400]   And so someone quite astutely said,
[00:10:30.400 --> 00:10:33.480]   well, what would be on your behavioral policy statement?
[00:10:33.480 --> 00:10:36.380]   And I had never, through the act of putting one together,
[00:10:36.380 --> 00:10:39.680]   so I said, give me a minute and I'll get back to you.
[00:10:39.680 --> 00:10:41.400]   And so the laws of wealth
[00:10:41.400 --> 00:10:44.480]   is really my behavioral policy statement.
[00:10:44.480 --> 00:10:47.860]   It's things like, you control what matters most,
[00:10:47.860 --> 00:10:51.760]   which is trying to help investors take the power back.
[00:10:51.760 --> 00:10:53.680]   You maybe have a similar experience,
[00:10:53.680 --> 00:10:56.840]   but when people find out that I work in finance,
[00:10:56.840 --> 00:10:58.960]   I get a host of questions.
[00:10:58.960 --> 00:11:02.360]   And it's things like, what's the Fed gonna do?
[00:11:02.360 --> 00:11:04.080]   Like, what's Russia gonna do?
[00:11:04.080 --> 00:11:05.700]   What's the virus gonna do?
[00:11:05.700 --> 00:11:07.520]   And of course, I have no idea.
[00:11:07.520 --> 00:11:09.080]   And even if I did know,
[00:11:09.080 --> 00:11:12.200]   I wouldn't know how it would impact markets.
[00:11:12.200 --> 00:11:14.520]   And so the first chapter is like,
[00:11:14.520 --> 00:11:16.240]   all of the things that matter most
[00:11:16.240 --> 00:11:18.540]   about you crossing your financial finish line
[00:11:18.540 --> 00:11:19.980]   are within your power.
[00:11:19.980 --> 00:11:23.660]   And it's things like maximizing your human capital,
[00:11:23.660 --> 00:11:27.380]   saving enough, managing your fees, diversifying.
[00:11:27.380 --> 00:11:29.140]   - Sounds like Boglehead principles.
[00:11:29.140 --> 00:11:31.740]   We have basically 10 Boglehead principles
[00:11:31.740 --> 00:11:33.300]   and it's all the same thing.
[00:11:33.300 --> 00:11:36.140]   Live below your means, keep your fees low,
[00:11:36.140 --> 00:11:40.140]   keep taxes low, don't try to time markets,
[00:11:40.140 --> 00:11:41.580]   on and on, and so it's the same.
[00:11:41.580 --> 00:11:42.460]   Sounds like the same.
[00:11:42.460 --> 00:11:44.940]   - Yeah, ideas like this too shall pass.
[00:11:44.940 --> 00:11:48.720]   We know that human nature is sort of to project
[00:11:48.720 --> 00:11:52.100]   the present moment into the future indefinitely.
[00:11:52.100 --> 00:11:55.260]   Whatever's going on now is how we presume
[00:11:55.260 --> 00:11:58.420]   the next three, five, seven years will go.
[00:11:58.420 --> 00:12:02.180]   And markets almost work 180 degrees of that, right?
[00:12:02.180 --> 00:12:05.860]   I mean, there's short-term persistence and short-term trend,
[00:12:05.860 --> 00:12:07.620]   but markets are mean reverting.
[00:12:07.620 --> 00:12:10.220]   And so the fact that markets are mean reverting
[00:12:10.220 --> 00:12:13.340]   should make us humble in good times
[00:12:13.340 --> 00:12:15.380]   and should give us hard and bad times
[00:12:15.380 --> 00:12:16.780]   and things like this.
[00:12:16.780 --> 00:12:20.340]   So it's basically my behavioral policy statement.
[00:12:20.340 --> 00:12:21.180]   - Very good.
[00:12:21.180 --> 00:12:22.020]   Well, thank you for that.
[00:12:22.020 --> 00:12:23.420]   It sounds very interesting.
[00:12:23.420 --> 00:12:26.060]   A good idea too, I think, a lot of people
[00:12:26.060 --> 00:12:28.260]   create an investment policy statement,
[00:12:28.260 --> 00:12:30.060]   but they don't have this side of it.
[00:12:30.060 --> 00:12:32.940]   You had a couple of chapters in there
[00:12:32.940 --> 00:12:35.340]   about forecasting is for weathermen.
[00:12:35.340 --> 00:12:39.740]   And if you're excited, it's probably a bad idea,
[00:12:39.740 --> 00:12:40.580]   things like this.
[00:12:41.300 --> 00:12:43.900]   Human words there, not clinical words,
[00:12:43.900 --> 00:12:46.020]   but human words, so very good.
[00:12:46.020 --> 00:12:49.500]   All right, so now the latest book is called
[00:12:49.500 --> 00:12:52.500]   "The Behavioral Investor."
[00:12:52.500 --> 00:12:55.540]   And basically four parts.
[00:12:55.540 --> 00:13:00.180]   Start out with some basics about human psychology.
[00:13:00.180 --> 00:13:02.340]   And then you go into the second part,
[00:13:02.340 --> 00:13:05.780]   which I call risks or behavioral risks.
[00:13:05.780 --> 00:13:10.100]   And then the third part is how to fix these risks.
[00:13:10.100 --> 00:13:12.020]   And then finally, you have some ideas
[00:13:12.020 --> 00:13:13.940]   for building a behavioral portfolio.
[00:13:13.940 --> 00:13:15.580]   So we're gonna go through the book
[00:13:15.580 --> 00:13:18.380]   and spend as much time as you want on each part,
[00:13:18.380 --> 00:13:21.260]   but let's start out at the beginning.
[00:13:21.260 --> 00:13:22.900]   And I thought this was interesting
[00:13:22.900 --> 00:13:24.300]   because I happen to be writing a book
[00:13:24.300 --> 00:13:26.460]   and I start the book talking about cavemen
[00:13:26.460 --> 00:13:29.860]   and the idea of the hunter-gatherers
[00:13:29.860 --> 00:13:31.980]   and that our brain is not wired
[00:13:31.980 --> 00:13:34.940]   for saving for retirement 30 years down the road.
[00:13:34.940 --> 00:13:37.580]   So could you start out with the psychological part?
[00:13:37.580 --> 00:13:40.260]   - Yeah, so that first part,
[00:13:40.260 --> 00:13:43.580]   I wanted to give some coverage to the psychological,
[00:13:43.580 --> 00:13:47.380]   the sociological, and even the physiological
[00:13:47.380 --> 00:13:51.260]   elements of investing, because all of these things
[00:13:51.260 --> 00:13:53.580]   can impinge on our ability
[00:13:53.580 --> 00:13:55.820]   to make good, sound financial decisions.
[00:13:55.820 --> 00:13:58.700]   And I didn't think that it had been adequately covered
[00:13:58.700 --> 00:14:00.100]   in the literature.
[00:14:00.100 --> 00:14:02.100]   So from a psychological,
[00:14:02.100 --> 00:14:04.820]   from sort of the caveman perspective,
[00:14:04.820 --> 00:14:08.740]   we know that our brains have not had an upgrade
[00:14:08.740 --> 00:14:11.020]   in, depending on who you ask,
[00:14:11.020 --> 00:14:13.540]   I think there's lots of different ideas about this,
[00:14:13.540 --> 00:14:16.460]   but something like 200,000 years.
[00:14:16.460 --> 00:14:20.220]   Since our brains sort of had a meaningful upgrade,
[00:14:20.220 --> 00:14:23.740]   we're working with sort of the iPhone 1 of brains
[00:14:23.740 --> 00:14:28.740]   and we're being called on to make iPhone 14 type decisions.
[00:14:28.740 --> 00:14:31.540]   Capital markets, true stock markets
[00:14:31.540 --> 00:14:32.900]   like the ones we trade in now
[00:14:32.900 --> 00:14:35.060]   are only a couple of hundred years old.
[00:14:35.060 --> 00:14:37.740]   And we're trying to navigate these with brains
[00:14:37.740 --> 00:14:39.700]   that haven't had an upgrade in hundreds
[00:14:39.700 --> 00:14:41.620]   of thousands of years.
[00:14:41.620 --> 00:14:45.980]   And so I think it helps to understand how we're wired.
[00:14:45.980 --> 00:14:49.060]   And one of the ways that we're wired,
[00:14:49.060 --> 00:14:51.460]   we're wired for ease,
[00:14:51.460 --> 00:14:54.260]   we're wired to maintain the status quo,
[00:14:54.260 --> 00:14:56.700]   and we're wired to avoid loss.
[00:14:56.700 --> 00:15:00.100]   And we have this profound asymmetry
[00:15:00.100 --> 00:15:02.060]   between how we think about upside
[00:15:02.060 --> 00:15:04.020]   and how we think about downside.
[00:15:04.020 --> 00:15:08.940]   And it's directly tied to these cave people ancestors,
[00:15:08.940 --> 00:15:12.860]   where you get one bad day, right?
[00:15:12.860 --> 00:15:16.180]   Back then when life was so brutal and so hard,
[00:15:16.180 --> 00:15:18.700]   one bad day was all you got, right?
[00:15:18.700 --> 00:15:21.380]   If it was sufficiently bad, that's the end of you.
[00:15:21.380 --> 00:15:24.540]   And I mean, I guess that's still the case in many respects.
[00:15:24.540 --> 00:15:28.620]   And so we're wired to avoid that one bad day
[00:15:28.620 --> 00:15:30.300]   because it can be fatal.
[00:15:30.300 --> 00:15:33.340]   Well, if you have a good day, that's nice,
[00:15:33.340 --> 00:15:37.220]   but it's not essential from a pure evolutionary,
[00:15:37.220 --> 00:15:40.580]   like live long enough to pass on your genes standpoint.
[00:15:40.580 --> 00:15:42.620]   It's not essential that you have a good day,
[00:15:42.620 --> 00:15:45.580]   but it is essential that you avoid bad days.
[00:15:45.580 --> 00:15:50.180]   And so we see this profound asymmetry and loss aversion
[00:15:50.180 --> 00:15:52.820]   and all the things that the behavioral economists
[00:15:52.820 --> 00:15:54.300]   talk about.
[00:15:54.300 --> 00:15:58.060]   - You talk about humans communicating
[00:15:58.060 --> 00:16:02.780]   on a social level in what's called non-real terms,
[00:16:02.780 --> 00:16:04.660]   ideas, religion, and so forth,
[00:16:04.660 --> 00:16:08.500]   and really not communicating on say a mathematical level.
[00:16:08.500 --> 00:16:10.420]   This also creates an issue.
[00:16:10.420 --> 00:16:14.100]   - Yeah, so this is perhaps a little esoteric,
[00:16:14.100 --> 00:16:16.420]   but there's this other animals, right?
[00:16:16.420 --> 00:16:18.340]   Humans, humans are animals.
[00:16:18.340 --> 00:16:22.340]   Other animals communicate in very literal terms.
[00:16:22.340 --> 00:16:25.860]   So the idea of something that's metaphysical
[00:16:25.860 --> 00:16:30.620]   or bigger than is a uniquely human creation.
[00:16:30.620 --> 00:16:34.820]   And so I talk about these functional fictions in the book,
[00:16:34.820 --> 00:16:38.660]   the borders of the state of Georgia or Texas,
[00:16:38.660 --> 00:16:42.020]   an economy, a fiat currency,
[00:16:42.020 --> 00:16:45.540]   all of these things are things that are not real
[00:16:45.540 --> 00:16:47.700]   in the strictest sense,
[00:16:47.700 --> 00:16:50.500]   the US constitution, our laws,
[00:16:50.500 --> 00:16:52.380]   like these things are not real
[00:16:52.380 --> 00:16:55.540]   in the strictest most material sense,
[00:16:55.540 --> 00:16:58.220]   but the fact that we agree upon them,
[00:16:58.220 --> 00:17:02.460]   fact that we sort of collectively agree upon their reality
[00:17:02.460 --> 00:17:06.060]   allows us to do great things.
[00:17:06.060 --> 00:17:09.020]   And I mean, it's really the thing that sets us aside
[00:17:09.020 --> 00:17:11.340]   from the rest of the animal kingdom
[00:17:11.340 --> 00:17:14.140]   is these functional fictions.
[00:17:14.140 --> 00:17:17.660]   But what that means is that we are wired to believe
[00:17:17.660 --> 00:17:20.460]   in things that are literally not true,
[00:17:20.460 --> 00:17:24.460]   and we are wired to reason and think in social terms.
[00:17:24.460 --> 00:17:26.900]   And so I give an example in the book,
[00:17:26.900 --> 00:17:30.540]   there's a famous experiment called the Asch experiment,
[00:17:30.540 --> 00:17:32.860]   where Solomon Asch, the psychologist,
[00:17:32.860 --> 00:17:37.140]   was studying the impact of peer pressure on decision-making.
[00:17:37.140 --> 00:17:40.620]   Imagine one line on the left that's of a certain length,
[00:17:40.620 --> 00:17:43.020]   and then he shows three lines on the right
[00:17:43.020 --> 00:17:44.540]   that are of varying lengths,
[00:17:44.540 --> 00:17:48.420]   one of which corresponds directly to the line on the left.
[00:17:48.420 --> 00:17:50.780]   And he says, "Which line on the right
[00:17:50.780 --> 00:17:53.020]   "is the same length as the line on the left?"
[00:17:53.020 --> 00:17:55.580]   And I mean, a kindergartner could do this, right?
[00:17:55.580 --> 00:17:57.420]   It's easy as can be.
[00:17:57.420 --> 00:17:59.900]   And when you ask people in isolation,
[00:17:59.900 --> 00:18:01.820]   everyone gets it right.
[00:18:01.820 --> 00:18:04.740]   But when you ask people in groups,
[00:18:04.740 --> 00:18:06.940]   you have confederates of the experiment.
[00:18:06.940 --> 00:18:11.700]   So seven people go before Rick goes, right?
[00:18:11.700 --> 00:18:12.940]   And Rick's number eight,
[00:18:12.940 --> 00:18:15.980]   and he's the only one who's not in on the joke.
[00:18:15.980 --> 00:18:18.900]   The correct answer is C, say,
[00:18:18.900 --> 00:18:20.820]   but the seven people ahead of you
[00:18:20.820 --> 00:18:23.820]   are sort of prompted to say B.
[00:18:23.820 --> 00:18:25.740]   So they say, "Oh, it's definitely B.
[00:18:25.740 --> 00:18:28.500]   "It's B, it's B, of course it's B."
[00:18:28.500 --> 00:18:29.340]   - Right.
[00:18:29.340 --> 00:18:30.980]   - It comes down to you now.
[00:18:30.980 --> 00:18:33.620]   You would never, Rick.
[00:18:33.620 --> 00:18:37.340]   I know you're an icon of class and a truth teller.
[00:18:37.340 --> 00:18:38.820]   - I've been accused of not working well
[00:18:38.820 --> 00:18:40.020]   in a group, by the way.
[00:18:40.020 --> 00:18:44.940]   - 76% of the time, people give the wrong answer.
[00:18:44.940 --> 00:18:48.900]   They give the peer pressure answer 76% of the time
[00:18:48.900 --> 00:18:51.020]   on this really basic thing.
[00:18:51.020 --> 00:18:54.780]   Now, we used to think that that was just a function
[00:18:54.780 --> 00:18:56.060]   of peer pressure.
[00:18:56.060 --> 00:18:59.860]   We used to think, "Oh, they know the answer is B,
[00:18:59.860 --> 00:19:02.300]   "but they're just saying C because everyone else is
[00:19:02.300 --> 00:19:04.140]   "and they don't wanna stick out."
[00:19:04.140 --> 00:19:07.540]   But what's fascinating now is we can look inside the brain,
[00:19:07.540 --> 00:19:09.380]   right, with these fMRI studies,
[00:19:09.380 --> 00:19:12.340]   and we can monitor what's going on in the brain.
[00:19:12.340 --> 00:19:14.300]   And the part of the brain that's lighting up
[00:19:14.300 --> 00:19:16.060]   when this is going on
[00:19:16.140 --> 00:19:20.660]   is actually the part associated with not peer pressure,
[00:19:20.660 --> 00:19:22.780]   but sensation and perception.
[00:19:22.780 --> 00:19:26.380]   So quite literally,
[00:19:26.380 --> 00:19:30.540]   the peer pressure has, in the most literal sense,
[00:19:30.540 --> 00:19:33.420]   changed the way you view the line.
[00:19:33.420 --> 00:19:36.740]   And so you think about the implications of that for markets
[00:19:36.740 --> 00:19:40.900]   and how social consensus can not only pressure us
[00:19:40.900 --> 00:19:44.300]   to do things we might not want to do otherwise,
[00:19:44.300 --> 00:19:47.860]   but literally, in the most literal sense possible,
[00:19:47.860 --> 00:19:50.500]   shape the way that we perceive the world,
[00:19:50.500 --> 00:19:51.940]   and it's pretty wild.
[00:19:51.940 --> 00:19:54.900]   So it's this double-edged sword for humankind
[00:19:54.900 --> 00:19:57.740]   that functional fictions help us build churches
[00:19:57.740 --> 00:20:00.580]   and economies and governments and all these great things,
[00:20:00.580 --> 00:20:03.540]   but they also can be our undoing.
[00:20:03.540 --> 00:20:07.740]   - So lately, with the demise of Silicon Valley Bank,
[00:20:07.740 --> 00:20:11.060]   and now problems at other banks,
[00:20:11.060 --> 00:20:13.900]   I've gotten two calls from clients who said,
[00:20:13.900 --> 00:20:16.940]   "Should I be taking my money out of my bank?
[00:20:16.940 --> 00:20:18.540]   "Where should I be putting it?"
[00:20:18.540 --> 00:20:21.300]   And I said, "No, why would you do that?
[00:20:21.300 --> 00:20:24.860]   "I mean, first of all, you have 250,000 of FDIC insurance."
[00:20:24.860 --> 00:20:28.740]   And they go, "Yeah, but I'm a little afraid of even that."
[00:20:28.740 --> 00:20:31.300]   And I think it gets to what you're talking about.
[00:20:31.300 --> 00:20:33.340]   - No, it absolutely does.
[00:20:33.340 --> 00:20:36.780]   And what's so interesting is we have a host of biases
[00:20:36.780 --> 00:20:38.020]   that kind of load onto this.
[00:20:38.020 --> 00:20:40.540]   One is sort of this collective reasoning
[00:20:40.540 --> 00:20:42.100]   that we just talked about.
[00:20:42.100 --> 00:20:44.540]   But I think all of this,
[00:20:44.540 --> 00:20:47.580]   this most recent banking crisis, if we want to call it that,
[00:20:47.580 --> 00:20:51.540]   is exacerbated by the fact that in recent memory,
[00:20:51.540 --> 00:20:53.180]   we have another banking crisis.
[00:20:53.180 --> 00:20:54.020]   - Right, true.
[00:20:54.020 --> 00:20:56.780]   - So there's a recency bias at play.
[00:20:56.780 --> 00:20:59.380]   There's sort of this comparative bias at play,
[00:20:59.380 --> 00:21:01.820]   this called representativeness heuristic,
[00:21:01.820 --> 00:21:04.860]   that sort of the idea that this thing is like that thing.
[00:21:04.860 --> 00:21:06.740]   People go, "Oh, banking crisis.
[00:21:06.740 --> 00:21:08.180]   "I know a banking crisis.
[00:21:08.180 --> 00:21:11.380]   "I lived through that in 2008, and it was gnarly."
[00:21:11.380 --> 00:21:13.780]   So I got to get out of here.
[00:21:13.780 --> 00:21:16.580]   And even the fundaments of those two things
[00:21:16.580 --> 00:21:17.740]   are quite different.
[00:21:17.740 --> 00:21:20.340]   The brain doesn't parse those kind of distinctions
[00:21:20.340 --> 00:21:22.140]   very easily.
[00:21:22.140 --> 00:21:25.260]   - In that sense, we can go to the second part of the book.
[00:21:25.260 --> 00:21:27.260]   And now I call the second part of the book
[00:21:27.260 --> 00:21:29.020]   the behavioral risks.
[00:21:29.020 --> 00:21:30.820]   You might call it something else.
[00:21:30.820 --> 00:21:34.020]   But you list out four of them,
[00:21:34.020 --> 00:21:38.260]   ego, conservatism, attention, and emotion.
[00:21:38.260 --> 00:21:43.260]   So four categories of behavioral risks.
[00:21:43.260 --> 00:21:45.860]   So if you could talk about this.
[00:21:45.860 --> 00:21:50.460]   - Yeah, so my purpose here was there has been
[00:21:50.460 --> 00:21:53.380]   the cataloging of behavioral biases
[00:21:53.380 --> 00:21:55.780]   has become a growth industry, right?
[00:21:55.780 --> 00:21:59.980]   So there's all these ways in which we've,
[00:21:59.980 --> 00:22:00.900]   maybe you've seen this.
[00:22:00.900 --> 00:22:04.860]   There's a sort of a lovely visual called the codex of,
[00:22:04.860 --> 00:22:07.380]   the codex of cognitive biases or something.
[00:22:07.380 --> 00:22:10.580]   - I have seen that a circle with all of these things.
[00:22:10.580 --> 00:22:12.900]   And by the time I get to 1/3 the way around it,
[00:22:12.900 --> 00:22:14.980]   or even 1/4 of the way, I just stop.
[00:22:14.980 --> 00:22:16.780]   - No, you gotta stop.
[00:22:16.780 --> 00:22:19.500]   Well, and there's something like 200, right?
[00:22:19.500 --> 00:22:21.140]   Like I've lost track, but there's something,
[00:22:21.140 --> 00:22:24.620]   there's give or take 200 different cognitive biases.
[00:22:24.620 --> 00:22:26.980]   And so this sort of rubbed me the wrong way
[00:22:26.980 --> 00:22:28.220]   in a couple of ways.
[00:22:28.220 --> 00:22:31.180]   So first of all, it's not a very empowering thing
[00:22:31.180 --> 00:22:33.060]   to tell the average investor like,
[00:22:33.060 --> 00:22:36.140]   "Look, there's 200 ways that you can screw this up."
[00:22:36.140 --> 00:22:41.140]   And even your sort of offhanded comment earlier about like,
[00:22:41.140 --> 00:22:44.140]   "Oh God, every time a behavioral finance person
[00:22:44.140 --> 00:22:45.700]   "comes on here, I feel like crap
[00:22:45.700 --> 00:22:48.860]   "because I gotta deal with them."
[00:22:48.860 --> 00:22:50.100]   We don't want that.
[00:22:50.100 --> 00:22:52.460]   So what I set out to do was I said,
[00:22:52.460 --> 00:22:56.540]   "Look, I know that many of these biases have a common root.
[00:22:56.540 --> 00:22:58.820]   "There's some sort of larger meta bias
[00:22:58.820 --> 00:23:01.100]   "that underpins a lot of these things
[00:23:01.100 --> 00:23:03.980]   "'cause some of them are enormously specific."
[00:23:03.980 --> 00:23:06.660]   And so I said, "I wanna sort of set out to see
[00:23:06.660 --> 00:23:09.500]   "what are the ones that I consider a meta bias."
[00:23:09.500 --> 00:23:11.380]   And so that's what these four are,
[00:23:11.380 --> 00:23:13.820]   ego, emotion, attention, and conservatism.
[00:23:13.820 --> 00:23:17.420]   These are my four meta biases, if you will.
[00:23:17.420 --> 00:23:21.300]   Because once we have a manageable universe of bias,
[00:23:21.300 --> 00:23:25.500]   you can set out to try and set up risk management procedures
[00:23:25.500 --> 00:23:27.100]   and things like that to control them.
[00:23:27.100 --> 00:23:30.900]   You can control for four biases, you can't control for 200.
[00:23:30.900 --> 00:23:33.020]   - So let's go through them, these four biases,
[00:23:33.020 --> 00:23:34.820]   starting with ego.
[00:23:34.820 --> 00:23:38.700]   - Yeah, so ego is the various flavors of overconfidence,
[00:23:38.700 --> 00:23:41.460]   going back to my "You're Not That Great" book, right?
[00:23:41.460 --> 00:23:43.180]   Ego, there's actually a couple
[00:23:43.180 --> 00:23:45.220]   of specific types of overconfidence,
[00:23:45.220 --> 00:23:48.620]   all of which I think are interesting to bogal heads.
[00:23:48.620 --> 00:23:52.460]   We'll call it the "I'm better than you" sort of variety,
[00:23:52.460 --> 00:23:54.980]   which is the one that gets the most play.
[00:23:54.980 --> 00:23:59.180]   So it's thinking that I'm better, faster, smarter, stronger.
[00:23:59.180 --> 00:24:00.380]   And you see this a lot.
[00:24:00.380 --> 00:24:03.300]   It's why people choose not to be bogal heads,
[00:24:03.300 --> 00:24:05.020]   because they think, "Yep, on average,
[00:24:05.020 --> 00:24:08.460]   market participants underperform, but I'm different."
[00:24:08.460 --> 00:24:09.620]   - Let me throw something in on that,
[00:24:09.620 --> 00:24:12.260]   because I hear it once in a while.
[00:24:12.260 --> 00:24:16.060]   From what I read, all of these big institutional investors
[00:24:16.060 --> 00:24:17.660]   who are doing these big trades,
[00:24:17.660 --> 00:24:19.940]   they can't really outperform the market.
[00:24:19.940 --> 00:24:21.900]   But me, as an individual investor,
[00:24:21.900 --> 00:24:25.100]   because I'm doing little trades
[00:24:25.100 --> 00:24:27.180]   and I'm sort of weaving in and out of the market,
[00:24:27.180 --> 00:24:29.700]   I have a much higher probability of outperforming
[00:24:29.700 --> 00:24:32.780]   than these big institutional investors.
[00:24:32.780 --> 00:24:34.180]   - Yeah, and here's the thing.
[00:24:34.180 --> 00:24:37.700]   The devil sort of speaks in half-truths, you know?
[00:24:37.700 --> 00:24:40.140]   There is some truth to that sentiment,
[00:24:40.140 --> 00:24:44.500]   that yes, an average person managing their own portfolio
[00:24:44.500 --> 00:24:47.100]   isn't susceptible to career risk
[00:24:47.100 --> 00:24:49.700]   and sort of some of the other external pressures
[00:24:49.700 --> 00:24:52.380]   that, say, a big fund manager would be.
[00:24:52.380 --> 00:24:55.900]   But the average investor also does not have access
[00:24:55.900 --> 00:24:57.500]   to the same level of education
[00:24:57.500 --> 00:24:59.340]   and resources and information.
[00:24:59.340 --> 00:25:01.100]   So, I mean, there's some ups and downs.
[00:25:01.100 --> 00:25:03.940]   But yeah, it's the stuff that you see everywhere.
[00:25:03.940 --> 00:25:05.820]   I cite studies in the laws of wealth.
[00:25:05.820 --> 00:25:07.860]   There was one hilarious study.
[00:25:07.860 --> 00:25:10.260]   700 men were interviewed.
[00:25:10.260 --> 00:25:13.700]   95% of them thought they had a better
[00:25:13.700 --> 00:25:15.500]   than average sense of humor.
[00:25:15.500 --> 00:25:19.860]   100% of them said that they were friendlier than average.
[00:25:19.860 --> 00:25:22.100]   And 94% of them said
[00:25:22.100 --> 00:25:24.380]   that they were better looking than average.
[00:25:24.380 --> 00:25:26.420]   And it's like this idea that, you know,
[00:25:26.420 --> 00:25:29.620]   we're all smarter, funnier, more attractive than average.
[00:25:29.620 --> 00:25:31.260]   It's just not true.
[00:25:31.260 --> 00:25:33.820]   And we see that in markets all the time.
[00:25:33.820 --> 00:25:37.420]   So that's sort of the first flavor of overconfidence.
[00:25:37.420 --> 00:25:41.500]   The second one is thinking that we're luckier than average.
[00:25:41.500 --> 00:25:45.020]   We sort of own the optimistic and delegate the dangerous.
[00:25:45.020 --> 00:25:47.540]   We know from a base rate perspective
[00:25:47.540 --> 00:25:51.540]   that 50% of marriages end in divorce, but not my marriage.
[00:25:51.540 --> 00:25:56.060]   We know that people abstractly get cancer, but not me.
[00:25:56.060 --> 00:25:57.820]   And, you know, we know that,
[00:25:57.820 --> 00:26:01.620]   yeah, my odds of winning the lottery are long, but I might.
[00:26:01.620 --> 00:26:03.620]   We tend to sort of own the optimistic
[00:26:03.620 --> 00:26:05.140]   and delegate the dangerous.
[00:26:05.140 --> 00:26:07.100]   And then the last sort of major form
[00:26:07.100 --> 00:26:09.780]   of overconfidence is over-precision,
[00:26:09.780 --> 00:26:12.060]   which is thinking that we know more
[00:26:12.060 --> 00:26:14.660]   about the future than we actually do.
[00:26:14.660 --> 00:26:16.940]   So people think that they're better
[00:26:16.940 --> 00:26:19.180]   at predicting what's coming,
[00:26:19.180 --> 00:26:21.460]   and they can see the future more clearly
[00:26:21.460 --> 00:26:22.780]   than they actually can.
[00:26:22.780 --> 00:26:25.620]   - So the second one is conservatism.
[00:26:25.620 --> 00:26:26.620]   - Yeah.
[00:26:26.620 --> 00:26:27.940]   - How did that play in?
[00:26:27.940 --> 00:26:30.540]   - So one of the things that must be said about us
[00:26:30.540 --> 00:26:33.620]   is that we're what Kahneman and Thaler have referred
[00:26:33.620 --> 00:26:36.220]   to as being cognitive misers.
[00:26:36.220 --> 00:26:41.220]   So we want to do as little thinking as possible.
[00:26:41.220 --> 00:26:44.140]   So our brains, our brains are small.
[00:26:44.140 --> 00:26:46.660]   Well, they're large relative to the animal kingdom,
[00:26:46.660 --> 00:26:48.580]   but relative to our body,
[00:26:48.580 --> 00:26:51.420]   they're two to 3% of our body weight,
[00:26:51.420 --> 00:26:55.740]   but they're like 20 to 25% of our caloric expenditure.
[00:26:55.740 --> 00:26:58.660]   And so your body is kind of always looking
[00:26:58.660 --> 00:27:00.620]   for ways to think less
[00:27:00.620 --> 00:27:03.580]   and to sort of offload some of this thinking.
[00:27:03.580 --> 00:27:07.060]   And so doing what you've always done
[00:27:07.060 --> 00:27:08.580]   is a good way to do that.
[00:27:08.580 --> 00:27:10.780]   Just sort of sticking with the status quo
[00:27:10.780 --> 00:27:12.780]   is a good way to do that.
[00:27:12.780 --> 00:27:14.940]   Not taking risk is a good way to do that.
[00:27:14.940 --> 00:27:18.060]   Following what other people do is a good way to do that.
[00:27:18.060 --> 00:27:21.020]   So conservatism is our tendency
[00:27:21.020 --> 00:27:23.940]   to be kind of status quo prone, lazy,
[00:27:23.940 --> 00:27:27.420]   and to confuse what we know with what is good.
[00:27:27.420 --> 00:27:30.060]   - All right, third one is called attention.
[00:27:30.060 --> 00:27:33.540]   - Yeah, so attention is this tendency
[00:27:33.540 --> 00:27:37.180]   to confuse what is loud with what is likely.
[00:27:37.180 --> 00:27:40.060]   - Oh, what is loud with what is likely, I like that.
[00:27:40.060 --> 00:27:43.620]   - Yeah, so it's confusing what is loud with what is likely.
[00:27:43.620 --> 00:27:46.620]   So there's a couple of funny examples of this.
[00:27:46.620 --> 00:27:50.220]   One that I like is you ask people to think about words
[00:27:50.220 --> 00:27:52.380]   that begin with the letter K, right?
[00:27:52.380 --> 00:27:54.220]   So like list all the words you can
[00:27:54.220 --> 00:27:55.780]   that begin with the letter K.
[00:27:55.780 --> 00:27:57.340]   Now in a second column,
[00:27:57.340 --> 00:28:00.940]   list all the words that have K as the third letter
[00:28:00.940 --> 00:28:03.220]   and like see which list is longer.
[00:28:03.220 --> 00:28:06.900]   People have much longer lists of words that begin with K
[00:28:06.900 --> 00:28:09.420]   than words in which K is the third letter,
[00:28:09.420 --> 00:28:11.740]   but there's three and a half times as many words
[00:28:11.740 --> 00:28:14.940]   with K as the third letter as there are the first,
[00:28:14.940 --> 00:28:16.660]   but the way that our brain works,
[00:28:16.660 --> 00:28:19.260]   we have sort of what's called a primacy effect.
[00:28:19.260 --> 00:28:20.980]   We remember things that come
[00:28:20.980 --> 00:28:22.880]   at the first part of the sequence.
[00:28:22.880 --> 00:28:24.880]   So the way that our brain is wired,
[00:28:24.880 --> 00:28:26.340]   we think there are more words
[00:28:26.340 --> 00:28:28.220]   with K as the first letter than the third,
[00:28:28.220 --> 00:28:29.760]   but that's not true.
[00:28:29.760 --> 00:28:31.980]   The same thing is true of markets.
[00:28:31.980 --> 00:28:34.540]   We misremember things all the time.
[00:28:34.540 --> 00:28:38.380]   We have really great memory for all the bad stuff
[00:28:38.380 --> 00:28:41.380]   and really bad memory for all the good stuff.
[00:28:41.380 --> 00:28:45.540]   I talk in the book about how the brain works extra hard
[00:28:45.540 --> 00:28:48.380]   to hang on to scary information.
[00:28:48.380 --> 00:28:53.380]   And so when somebody is watching Silicon Valley Bank collapse
[00:28:53.380 --> 00:28:56.860]   they have a very vivid, very salient memory
[00:28:56.860 --> 00:28:59.040]   of the great financial crisis.
[00:28:59.040 --> 00:29:02.940]   They have a less salient memory of the 10 years in between
[00:29:02.940 --> 00:29:06.980]   where they were popping double digit returns every year.
[00:29:06.980 --> 00:29:09.660]   Sort of the way that we remember things
[00:29:09.660 --> 00:29:11.900]   and the way that things actually are
[00:29:11.900 --> 00:29:14.180]   can be quite disconnected.
[00:29:14.180 --> 00:29:16.700]   - You talk about the tendency
[00:29:16.700 --> 00:29:20.540]   to confuse ease of recall with probability.
[00:29:20.540 --> 00:29:21.380]   - That's right.
[00:29:21.380 --> 00:29:23.380]   - How quickly recall something
[00:29:23.380 --> 00:29:25.340]   that gets assigned a higher probability,
[00:29:25.340 --> 00:29:26.840]   whether it's true or not.
[00:29:26.840 --> 00:29:29.220]   - Yeah, there's all kinds of different things here.
[00:29:29.220 --> 00:29:31.940]   There's shark attacks and selfies,
[00:29:31.940 --> 00:29:33.380]   I think I talk about in the book.
[00:29:33.380 --> 00:29:35.620]   Your probability of getting bit by a shark
[00:29:35.620 --> 00:29:37.980]   is like one in 300 million.
[00:29:37.980 --> 00:29:41.740]   And yet all these people die every year taking selfies
[00:29:41.740 --> 00:29:44.620]   because they stumble into traffic or whatever.
[00:29:44.620 --> 00:29:46.420]   But we think of sharks as dangerous
[00:29:46.420 --> 00:29:48.860]   and we don't think of taking a selfie as dangerous
[00:29:48.860 --> 00:29:51.220]   because one is loud, right?
[00:29:51.220 --> 00:29:53.940]   One is loud and dramatic and scary
[00:29:53.940 --> 00:29:56.700]   and one is just dumb and bumbling.
[00:29:56.700 --> 00:29:58.960]   And you know, we see this all the time with the news,
[00:29:58.960 --> 00:30:02.400]   like things that make it onto the news are there,
[00:30:02.400 --> 00:30:05.300]   they're newsworthy because they're rare.
[00:30:05.300 --> 00:30:07.820]   And yet we have an awesome recall
[00:30:07.820 --> 00:30:10.580]   for things like what's on the news.
[00:30:10.580 --> 00:30:14.460]   The things that kill the average portfolio, as you know,
[00:30:14.460 --> 00:30:16.860]   are typically things like under diversification
[00:30:16.860 --> 00:30:21.860]   and excessive fees, boring, not loud, unsexy,
[00:30:21.860 --> 00:30:23.700]   hard to recall.
[00:30:23.700 --> 00:30:27.380]   And it's not stuff like a financial crisis even.
[00:30:27.380 --> 00:30:30.100]   - Or Bitcoin, or owning Bitcoin or not owning Bitcoin.
[00:30:30.100 --> 00:30:33.220]   - Sure, yeah, totally, great example.
[00:30:33.220 --> 00:30:38.180]   The last one then of the four categories is emotion.
[00:30:38.180 --> 00:30:39.940]   - Yeah, so emotion's probably the one
[00:30:39.940 --> 00:30:41.380]   that's the most self-evident.
[00:30:41.380 --> 00:30:46.180]   It's just this tendency to confuse your heart with your head.
[00:30:46.180 --> 00:30:50.140]   And humans have something called the affect heuristic,
[00:30:50.140 --> 00:30:53.020]   which is just a fancy way of saying
[00:30:53.020 --> 00:30:56.060]   that the emotional state that you find yourself in
[00:30:56.060 --> 00:30:58.620]   colors your perception of risk.
[00:30:58.620 --> 00:31:01.580]   Someone who's having a good day
[00:31:01.580 --> 00:31:04.220]   tends to not see risk anywhere.
[00:31:04.220 --> 00:31:05.660]   Someone who's having a bad day
[00:31:05.660 --> 00:31:07.860]   tends to see risk everywhere.
[00:31:07.860 --> 00:31:10.100]   And so there's just a host of ways
[00:31:10.100 --> 00:31:14.660]   in which emotion can color our views on markets.
[00:31:14.660 --> 00:31:19.460]   And it's best to invest in a more or less mechanical way.
[00:31:19.460 --> 00:31:22.100]   And we're just not really wired for that.
[00:31:22.100 --> 00:31:24.420]   - You mentioned something under emotion,
[00:31:24.420 --> 00:31:25.740]   which I found interesting.
[00:31:25.740 --> 00:31:30.380]   You talk about intense emotions shorten timelines.
[00:31:30.380 --> 00:31:32.500]   Talk about that.
[00:31:32.500 --> 00:31:37.500]   - Again, so much of how we're wired is evolutionary.
[00:31:37.500 --> 00:31:41.300]   There's a strong dose of evolutionary psychology here.
[00:31:41.300 --> 00:31:42.980]   If someone's in danger,
[00:31:42.980 --> 00:31:47.100]   emotion is an early warning detection system for danger,
[00:31:47.100 --> 00:31:48.660]   among other things.
[00:31:48.660 --> 00:31:50.100]   But if someone is in danger
[00:31:50.100 --> 00:31:53.020]   and they're experiencing stress or anxiety
[00:31:53.020 --> 00:31:54.420]   or something like that,
[00:31:54.420 --> 00:31:58.660]   your body cannot differentiate your worry
[00:31:58.660 --> 00:32:00.740]   about Silicon Valley Bank
[00:32:00.740 --> 00:32:04.140]   from you being chased by a wild animal, right?
[00:32:04.140 --> 00:32:07.740]   The physiological response to that is identical.
[00:32:07.740 --> 00:32:09.660]   You know, your pupils dilate,
[00:32:09.660 --> 00:32:11.580]   your heart races, you sweat,
[00:32:11.580 --> 00:32:13.940]   blood gets shunted away from your extremities.
[00:32:13.940 --> 00:32:16.140]   All the same things happen
[00:32:16.140 --> 00:32:19.420]   and you are preparing to defend yourself
[00:32:19.420 --> 00:32:23.020]   in a moment of physical harm.
[00:32:23.020 --> 00:32:25.140]   And again, the physiological response
[00:32:25.140 --> 00:32:29.140]   between a physical danger and an emotional danger,
[00:32:29.140 --> 00:32:30.700]   there's no difference.
[00:32:30.700 --> 00:32:34.340]   And so you don't need to think about your future, right?
[00:32:34.340 --> 00:32:36.780]   Like you don't need to think about your 80 year old self.
[00:32:36.780 --> 00:32:40.060]   If you're getting attacked by a bear, you need to run.
[00:32:40.060 --> 00:32:42.180]   And so the same thing happens though
[00:32:42.180 --> 00:32:43.980]   when we have a bear market.
[00:32:43.980 --> 00:32:45.940]   We become very myopic.
[00:32:45.940 --> 00:32:47.980]   We forget about our future self.
[00:32:47.980 --> 00:32:50.220]   We forget about our goals.
[00:32:50.220 --> 00:32:52.180]   And so that's one of the most powerful things
[00:32:52.180 --> 00:32:54.660]   that we can do is just take a breath
[00:32:54.660 --> 00:32:58.020]   and realign our gaze with our goals
[00:32:58.020 --> 00:33:01.180]   and sort of remember those long-term goals
[00:33:01.180 --> 00:33:04.180]   because we're wired to become very short-term
[00:33:04.180 --> 00:33:08.180]   and very immediate in our thinking when we're emotional.
[00:33:08.180 --> 00:33:09.900]   - So now we're gonna go circle back
[00:33:09.900 --> 00:33:14.540]   to these four buckets of behavioral risk,
[00:33:14.540 --> 00:33:18.300]   ego, conservatism, attention, and emotion.
[00:33:18.300 --> 00:33:20.780]   And in your book, you have fixes
[00:33:20.780 --> 00:33:24.020]   or how to mitigate these risks.
[00:33:24.020 --> 00:33:26.180]   And so we'll go back up to the top.
[00:33:26.180 --> 00:33:28.140]   Start out with ego.
[00:33:28.140 --> 00:33:30.900]   Give us a quick reminder of what that is
[00:33:30.900 --> 00:33:32.780]   and then how do you fix it?
[00:33:32.780 --> 00:33:34.500]   - Yeah, so I mean, there's a couple of ways
[00:33:34.500 --> 00:33:36.860]   that I think you can combat ego,
[00:33:36.860 --> 00:33:40.340]   which is this tendency to think you're better,
[00:33:40.340 --> 00:33:41.620]   to think you're luckier,
[00:33:41.620 --> 00:33:44.060]   and to think you're more prescient about the future
[00:33:44.060 --> 00:33:45.580]   than you actually are.
[00:33:45.580 --> 00:33:48.060]   I think bogal heads understand many of these well.
[00:33:48.060 --> 00:33:50.100]   I think the bogal head mentality
[00:33:50.100 --> 00:33:53.180]   is based on a low ego proposition.
[00:33:53.180 --> 00:33:54.900]   I'm not going to try and beat the market.
[00:33:54.900 --> 00:33:56.500]   I'm just going to be the market.
[00:33:56.500 --> 00:33:59.900]   I think the bogal head mentality is sort of lived humility.
[00:33:59.900 --> 00:34:02.140]   It's sort of humility embodied.
[00:34:02.140 --> 00:34:04.340]   And so I think something as simple as that
[00:34:04.340 --> 00:34:06.500]   is a way to combat ego.
[00:34:06.500 --> 00:34:09.540]   I think where appropriate working with a professional
[00:34:09.540 --> 00:34:13.420]   to get some help is lived humility as well.
[00:34:13.420 --> 00:34:18.340]   One of the most important parts of knowledge
[00:34:18.340 --> 00:34:20.060]   is something called meta-knowledge,
[00:34:20.060 --> 00:34:23.060]   which is just basically knowing what you don't know, right?
[00:34:23.060 --> 00:34:25.140]   Like I'm not handy at all.
[00:34:25.140 --> 00:34:27.180]   Like, I mean, I can't hammer a nail.
[00:34:27.180 --> 00:34:29.180]   I can't do anything with a car,
[00:34:29.180 --> 00:34:32.460]   but like I know that about myself and I don't try.
[00:34:32.460 --> 00:34:36.140]   So I just go get some help.
[00:34:36.140 --> 00:34:37.700]   I know there's probably a lot of folks
[00:34:37.700 --> 00:34:40.540]   who work with advisors here, a lot of folks who DIY,
[00:34:40.540 --> 00:34:43.140]   but where appropriate going to get that help
[00:34:43.140 --> 00:34:45.820]   is I think another piece of humility.
[00:34:45.820 --> 00:34:47.980]   - So secondly, conservatism?
[00:34:47.980 --> 00:34:51.140]   - Yeah, so conservatism is this tendency
[00:34:51.140 --> 00:34:54.780]   to confuse what we know with what is good.
[00:34:54.780 --> 00:34:57.060]   And it's our tendency to be sort of lazy
[00:34:57.060 --> 00:34:58.820]   and status quo prone.
[00:34:58.820 --> 00:35:00.900]   And so I'll take each of these in turn,
[00:35:00.900 --> 00:35:04.020]   and maybe at the risk of disagreeing with Jack Bogle,
[00:35:04.020 --> 00:35:08.460]   I believe that one of the things that's cool about investing
[00:35:08.460 --> 00:35:11.140]   is that it's a way to sort of see the world.
[00:35:11.140 --> 00:35:13.060]   And so one of the things that I do personally
[00:35:13.060 --> 00:35:16.460]   is that I diversify my portfolio by geography.
[00:35:16.460 --> 00:35:18.380]   We see that there's a huge tendency
[00:35:18.380 --> 00:35:22.100]   to engage in something that's called home country bias,
[00:35:22.100 --> 00:35:25.980]   but it actually gets a lot more granular than that.
[00:35:25.980 --> 00:35:30.100]   So we know that Americans over-invest in American stocks
[00:35:30.100 --> 00:35:31.820]   and that Canadians over-index
[00:35:31.820 --> 00:35:34.100]   on Canadian stocks and so forth,
[00:35:34.100 --> 00:35:36.900]   but we actually see this at a much more granular level.
[00:35:36.900 --> 00:35:39.580]   People in tech tend to over-invest in tech.
[00:35:39.580 --> 00:35:42.700]   People tend to over-invest in their own company.
[00:35:42.700 --> 00:35:46.140]   People in the Northeast are over-indexed on financials.
[00:35:46.140 --> 00:35:48.980]   People on the West Coast are overweight tech.
[00:35:48.980 --> 00:35:51.540]   People in the Midwest are overweight agriculture.
[00:35:51.540 --> 00:35:54.020]   People in Texas are overweight energy.
[00:35:54.020 --> 00:35:56.420]   Like we just see this all over the place
[00:35:56.420 --> 00:36:00.860]   that people confuse the stuff they see around them every day
[00:36:00.860 --> 00:36:03.500]   with things that are safe or desirable.
[00:36:03.500 --> 00:36:07.340]   And to get beyond this sort of parochial mindset,
[00:36:07.340 --> 00:36:10.380]   I think one of the things that we can do is use investing,
[00:36:10.380 --> 00:36:12.860]   treat it kind of like a liberal art
[00:36:12.860 --> 00:36:17.020]   and use it as a way to learn more about different industries,
[00:36:17.020 --> 00:36:18.580]   to learn more about the world
[00:36:18.580 --> 00:36:21.820]   and sort of expand our view of what's possible.
[00:36:21.820 --> 00:36:26.620]   So I think overcoming that is tough, but rewarding.
[00:36:26.620 --> 00:36:30.180]   And then on sort of the status quo piece,
[00:36:30.180 --> 00:36:34.860]   I think this is a good time to talk about wherever possible,
[00:36:34.860 --> 00:36:37.380]   these biases that we talk about
[00:36:37.380 --> 00:36:40.900]   should be flipped on their head to work to our benefit.
[00:36:40.900 --> 00:36:42.020]   We are lazy.
[00:36:42.020 --> 00:36:43.420]   We are status quo prone.
[00:36:43.420 --> 00:36:45.180]   That is undeniable,
[00:36:45.180 --> 00:36:47.700]   but that can actually work to our advantage.
[00:36:47.700 --> 00:36:52.140]   If we automate our saving and investing process,
[00:36:52.140 --> 00:36:55.620]   we tend to leave it alone and we tend to do much better
[00:36:55.620 --> 00:36:59.740]   than if we try and white-knuckle restraint
[00:36:59.740 --> 00:37:02.620]   every two weeks when the paycheck comes in and we go,
[00:37:02.620 --> 00:37:06.460]   "Oh God, am I gonna save again this two weeks
[00:37:06.460 --> 00:37:08.980]   and have to make the right decision week after week?"
[00:37:08.980 --> 00:37:10.940]   So if there's ways to take,
[00:37:10.940 --> 00:37:13.340]   look, I'm lazy, I'm status quo prone,
[00:37:13.340 --> 00:37:15.620]   but I know that can work in my advantage
[00:37:15.620 --> 00:37:17.100]   if I can automate that process.
[00:37:17.100 --> 00:37:18.500]   That's a powerful thing.
[00:37:18.500 --> 00:37:23.660]   - And the third one is attention.
[00:37:23.660 --> 00:37:26.380]   - Yeah, so we talked earlier about this media diet
[00:37:26.380 --> 00:37:29.940]   and I'll kind of draw on my clinical research
[00:37:29.940 --> 00:37:30.780]   here a little bit.
[00:37:30.780 --> 00:37:33.180]   I actually entered the industry
[00:37:33.180 --> 00:37:35.420]   to work with women with eating disorders.
[00:37:35.420 --> 00:37:37.420]   That was what brought me to the industry.
[00:37:37.420 --> 00:37:40.060]   Someone I loved had an eating disorder
[00:37:40.060 --> 00:37:44.340]   and helping her overcome that was formative
[00:37:44.340 --> 00:37:46.460]   in me getting into the industry.
[00:37:46.460 --> 00:37:47.380]   When I was working
[00:37:47.380 --> 00:37:50.700]   at this inpatient eating disorder treatment center,
[00:37:50.700 --> 00:37:53.740]   the very first thing that we did with the women that came in
[00:37:53.740 --> 00:37:55.180]   was sort of media training,
[00:37:55.180 --> 00:37:59.220]   was helping to make them an informed consumer
[00:37:59.220 --> 00:38:01.620]   of the way that women are marketed to,
[00:38:01.620 --> 00:38:04.060]   the way women are made to feel small
[00:38:04.060 --> 00:38:05.580]   and imperfect and ugly
[00:38:05.580 --> 00:38:08.140]   and the way the lighting and Photoshop
[00:38:08.140 --> 00:38:09.940]   and all this stuff works.
[00:38:09.940 --> 00:38:13.180]   And by helping them to become an informed consumer
[00:38:13.180 --> 00:38:15.700]   of the messages that were targeting them
[00:38:15.700 --> 00:38:18.700]   and to understand sort of the motivation beneath that
[00:38:18.700 --> 00:38:20.380]   was not virtuous motivation.
[00:38:20.380 --> 00:38:22.700]   I mean, it was sort of motivating them
[00:38:22.700 --> 00:38:25.380]   to feel like garbage to buy stuff.
[00:38:25.380 --> 00:38:27.620]   It empowered them to make different decisions.
[00:38:27.620 --> 00:38:30.700]   And I think that once people understand
[00:38:30.700 --> 00:38:33.660]   how the sausage is made with news in general
[00:38:33.660 --> 00:38:35.940]   and financial news in specific,
[00:38:35.940 --> 00:38:38.220]   you can become an informed consumer of media.
[00:38:38.220 --> 00:38:40.500]   And look, I'm not picking on the media.
[00:38:40.500 --> 00:38:43.420]   We need a robust media to keep us informed.
[00:38:43.420 --> 00:38:46.500]   That's a beautiful part of a functioning democracy.
[00:38:46.500 --> 00:38:50.220]   But media companies are companies that have bottom lines,
[00:38:50.220 --> 00:38:51.540]   that have a profit motive
[00:38:51.540 --> 00:38:55.460]   and understand that bad news is stickier than good news
[00:38:55.460 --> 00:38:59.660]   by a function of about three times and they know.
[00:38:59.660 --> 00:39:03.420]   And so they have a desire to report on things
[00:39:03.420 --> 00:39:06.500]   that are unusual or scary.
[00:39:06.500 --> 00:39:09.140]   And that's not always in the best interest
[00:39:09.140 --> 00:39:10.900]   of us making good financial decisions.
[00:39:10.900 --> 00:39:15.180]   So I think controlling that media diet is a powerful hack.
[00:39:15.180 --> 00:39:19.140]   - I would also add from my years talking with journalists
[00:39:19.140 --> 00:39:23.540]   that they have advertisers in their magazines
[00:39:23.540 --> 00:39:25.420]   and they have advertisers on their website
[00:39:25.420 --> 00:39:29.620]   and they cannot upset the apple cart too much
[00:39:29.620 --> 00:39:30.580]   with what they say,
[00:39:30.580 --> 00:39:33.100]   or they're going to get pulled into the editor's office
[00:39:33.100 --> 00:39:34.740]   and have a talking to.
[00:39:34.740 --> 00:39:37.340]   - I have one funny story here, if you'll indulge me.
[00:39:37.340 --> 00:39:41.620]   I was on a large, promoting this book actually,
[00:39:41.620 --> 00:39:45.500]   I was on a large cable financial news program.
[00:39:45.500 --> 00:39:47.020]   And when you're on TV,
[00:39:47.020 --> 00:39:49.420]   you've got this sort of earpiece in your ear
[00:39:49.420 --> 00:39:51.900]   where the producer is talking to you.
[00:39:51.900 --> 00:39:52.740]   - Right. - And you can hear
[00:39:52.740 --> 00:39:53.580]   what's going on.
[00:39:53.580 --> 00:39:55.660]   Like you can hear what everyone's seeing on the screen,
[00:39:55.660 --> 00:39:56.940]   but you can also hear this person
[00:39:56.940 --> 00:39:59.140]   and they're kind of counting me down.
[00:39:59.140 --> 00:40:02.460]   And I was in my full like psychologist regalia.
[00:40:02.460 --> 00:40:05.580]   Like I'm like wearing tweed and tortoise shell glasses
[00:40:05.580 --> 00:40:08.060]   and like a bow tie probably or something.
[00:40:08.060 --> 00:40:10.580]   And so looking very academic.
[00:40:10.580 --> 00:40:13.020]   And so she's counting me down,
[00:40:13.020 --> 00:40:16.220]   like five, four, three, I'm about to go on.
[00:40:16.220 --> 00:40:19.460]   Five, four, three, two, give me something good,
[00:40:19.460 --> 00:40:22.140]   don't be a nerd, one.
[00:40:22.140 --> 00:40:26.740]   And I go on and I laugh at that,
[00:40:26.740 --> 00:40:29.100]   but it's so telling, right?
[00:40:29.100 --> 00:40:32.500]   I mean, it wasn't give us nuanced commentary
[00:40:32.500 --> 00:40:33.820]   that's based in the literature.
[00:40:33.820 --> 00:40:37.660]   It was don't be a nerd, give me something good, right?
[00:40:37.660 --> 00:40:39.940]   And it's like, that's what they want.
[00:40:39.940 --> 00:40:42.420]   - Yeah, over the last several years
[00:40:42.420 --> 00:40:44.260]   since I'm no longer managing money,
[00:40:44.260 --> 00:40:47.780]   so I'm no longer a potential client for asset managers
[00:40:47.780 --> 00:40:50.380]   who have mutual funds or ETFs
[00:40:50.380 --> 00:40:51.740]   or whatever they're trying to sell.
[00:40:51.740 --> 00:40:53.820]   I'm no longer in that environment anymore.
[00:40:53.820 --> 00:40:56.620]   I'm just doing an hourly advisory model now,
[00:40:56.620 --> 00:40:59.260]   which I don't get invited to speak
[00:40:59.260 --> 00:41:01.940]   at any investor conferences anymore,
[00:41:01.940 --> 00:41:03.900]   barring the Boglehead conference,
[00:41:03.900 --> 00:41:05.820]   which I'm on the investment committee.
[00:41:05.820 --> 00:41:09.420]   But no, I mean, all the large conferences I used to go to,
[00:41:09.420 --> 00:41:11.980]   I used to be a speaker talking about asset allocation,
[00:41:11.980 --> 00:41:14.700]   talking about index investing, all of this.
[00:41:14.700 --> 00:41:18.780]   And now never do I get invited
[00:41:18.780 --> 00:41:21.540]   because I'm of no use to the sponsors.
[00:41:21.540 --> 00:41:23.620]   - Well, yeah, I mean, look,
[00:41:23.620 --> 00:41:25.780]   we know incentives drive behavior.
[00:41:25.780 --> 00:41:27.380]   We're not picking on anybody,
[00:41:27.380 --> 00:41:29.980]   but that's just what it is.
[00:41:29.980 --> 00:41:31.340]   We're all trying to make a living.
[00:41:31.340 --> 00:41:32.580]   Incentives drive behavior,
[00:41:32.580 --> 00:41:35.220]   and the financial news media has an incentive
[00:41:35.220 --> 00:41:37.900]   to get you to look at it.
[00:41:37.900 --> 00:41:41.460]   And they know that you'll look at it when it's bloody.
[00:41:41.460 --> 00:41:43.980]   So, I mean, that's just kind of is what it is.
[00:41:43.980 --> 00:41:45.660]   - Yeah, I'm not going to bring him any business
[00:41:45.660 --> 00:41:46.500]   because what I'm going to say
[00:41:46.500 --> 00:41:48.940]   is going to drive business away from those sponsors.
[00:41:48.940 --> 00:41:52.020]   And so, well, we'll skip him this year.
[00:41:52.020 --> 00:41:53.380]   Anyway, I understand that.
[00:41:53.380 --> 00:41:54.820]   It is the way it is.
[00:41:54.820 --> 00:41:59.380]   The last one, fixing our emotional issues.
[00:41:59.380 --> 00:42:00.460]   - Yeah, so, you know,
[00:42:00.460 --> 00:42:03.220]   I think a lot of these things manage emotion.
[00:42:03.220 --> 00:42:04.980]   One of the things that I love
[00:42:04.980 --> 00:42:08.860]   about the bogal head type style investing,
[00:42:08.860 --> 00:42:11.300]   it's shown that that sort of investor
[00:42:11.300 --> 00:42:13.300]   actually stays the course better
[00:42:13.300 --> 00:42:16.580]   largely as a function of their expectation.
[00:42:16.580 --> 00:42:19.380]   Your expectations matter,
[00:42:19.380 --> 00:42:21.660]   sort of your emotional expectations matter.
[00:42:21.660 --> 00:42:24.300]   When you expect that you will be mirroring the market
[00:42:24.300 --> 00:42:25.900]   rather than beating it,
[00:42:25.900 --> 00:42:28.380]   your expectations are more aligned with your emotions
[00:42:28.380 --> 00:42:29.980]   and you make better choices.
[00:42:29.980 --> 00:42:31.860]   There's actually a way that we can, again,
[00:42:31.860 --> 00:42:33.700]   use emotion to our advantage
[00:42:33.700 --> 00:42:37.020]   'cause there's plenty of ways that emotion can trip us up.
[00:42:37.020 --> 00:42:41.260]   We go back to this idea of the personal benchmark.
[00:42:41.260 --> 00:42:44.260]   You know, there was a study out of Canada that I just love
[00:42:44.260 --> 00:42:48.300]   that compared a control group to an experimental group
[00:42:48.300 --> 00:42:50.340]   that had to look at a picture of their children
[00:42:50.340 --> 00:42:54.300]   for five seconds before they made a financial decision
[00:42:54.300 --> 00:42:57.340]   and they monitored decisions over this time.
[00:42:57.340 --> 00:43:00.060]   And the people who looked at the picture of their children
[00:43:00.060 --> 00:43:02.420]   before they made financial decisions,
[00:43:02.420 --> 00:43:03.460]   made better decisions,
[00:43:03.460 --> 00:43:06.660]   they saved twice as much money on and on,
[00:43:06.660 --> 00:43:08.540]   that's totally irrational, right?
[00:43:08.540 --> 00:43:11.140]   Like just from like a purely behavioral standpoint,
[00:43:11.140 --> 00:43:12.660]   it's totally irrational.
[00:43:12.660 --> 00:43:14.900]   You should just save what you need to save
[00:43:14.900 --> 00:43:16.060]   and you should just make
[00:43:16.060 --> 00:43:18.300]   the mathematical decisions around that.
[00:43:18.300 --> 00:43:20.980]   But you can bring emotion into your financial life
[00:43:20.980 --> 00:43:22.060]   in a positive way.
[00:43:22.060 --> 00:43:24.380]   You can recenter yourself on your why,
[00:43:24.380 --> 00:43:27.500]   you can recenter yourself on the things that matter to you
[00:43:27.500 --> 00:43:30.580]   and use that to propel you forward.
[00:43:30.580 --> 00:43:32.500]   So if there's something you really want
[00:43:32.500 --> 00:43:34.660]   or a goal you have or a dream,
[00:43:34.660 --> 00:43:36.460]   wrap your financial life up in that
[00:43:36.460 --> 00:43:38.300]   and you'll make better decisions.
[00:43:38.300 --> 00:43:41.420]   - Okay, now we're gonna get into the fourth part of the book
[00:43:41.420 --> 00:43:44.740]   where you list out several different things
[00:43:44.740 --> 00:43:47.940]   an investor can do to maybe mitigate
[00:43:47.940 --> 00:43:50.140]   some of these behavioral biases.
[00:43:50.140 --> 00:43:52.220]   - So in the last part of the book, as you've said,
[00:43:52.220 --> 00:43:54.860]   I touch on how to kind of put this all together
[00:43:54.860 --> 00:43:56.500]   and what it looks like in a portfolio.
[00:43:56.500 --> 00:43:58.060]   And there's a couple of things that I think
[00:43:58.060 --> 00:44:00.380]   are worth mentioning that I would highlight here.
[00:44:00.380 --> 00:44:02.300]   So the first of these is fees.
[00:44:02.300 --> 00:44:06.020]   I know, look, I'm preaching to the converted on this podcast
[00:44:06.020 --> 00:44:08.300]   about the benefits of managing fees,
[00:44:08.300 --> 00:44:10.580]   but Morningstar did a study a few years ago
[00:44:10.580 --> 00:44:12.900]   where they looked at the drivers of fund performance
[00:44:12.900 --> 00:44:15.180]   and the number one driver was fees.
[00:44:15.180 --> 00:44:18.300]   That was the single best predictor of how a fund did,
[00:44:18.300 --> 00:44:20.140]   was how expensive it was.
[00:44:20.140 --> 00:44:22.820]   It's absolutely in our control.
[00:44:22.820 --> 00:44:25.300]   And so when you have something that's so controllable
[00:44:25.300 --> 00:44:29.540]   and so predictive, it makes absolute sense to go and get it.
[00:44:29.540 --> 00:44:31.900]   You know, the other thing that I talk about
[00:44:31.900 --> 00:44:34.060]   is being systematic.
[00:44:34.060 --> 00:44:37.500]   And this one rubs a lot of people the wrong way,
[00:44:37.500 --> 00:44:39.620]   but I talked in this book and my other book,
[00:44:39.620 --> 00:44:42.380]   there was a meta-analysis that was done
[00:44:42.380 --> 00:44:47.060]   on roughly 200 different studies of decision making.
[00:44:47.060 --> 00:44:50.780]   And it compares discretionary decision making,
[00:44:50.780 --> 00:44:55.780]   like PhD level discretion to just following simple rules.
[00:44:55.780 --> 00:45:01.620]   And what we find is that 94% of the time,
[00:45:01.620 --> 00:45:06.900]   simple rules beat or equal PhD level discretion.
[00:45:06.900 --> 00:45:08.820]   - Ah, interesting.
[00:45:08.820 --> 00:45:12.940]   - Yeah, and that's sort of compelling in and of itself.
[00:45:12.940 --> 00:45:14.980]   But the second thing you have to think about
[00:45:14.980 --> 00:45:19.660]   is that in markets and in funds, discretion costs, right?
[00:45:19.660 --> 00:45:22.660]   Rules are free, discretion is not.
[00:45:22.660 --> 00:45:26.060]   A bunch of PhDs like me in a fund family
[00:45:26.060 --> 00:45:27.900]   are gonna charge you for their time.
[00:45:27.900 --> 00:45:30.340]   So not only does being systematic
[00:45:30.340 --> 00:45:33.860]   have some behavioral upside, it costs less too.
[00:45:33.860 --> 00:45:36.540]   And we've talked about the power of fees.
[00:45:36.540 --> 00:45:37.980]   The last thing that I'll touch on
[00:45:37.980 --> 00:45:41.180]   is I look at some different factors of investment.
[00:45:41.180 --> 00:45:45.620]   So basically we're looking at what sorts of elements
[00:45:45.620 --> 00:45:48.980]   of an investment style might be predictive
[00:45:48.980 --> 00:45:52.220]   of it being something you should pay attention to.
[00:45:52.220 --> 00:45:54.340]   And so I looked at different things
[00:45:54.340 --> 00:45:55.740]   and one of the things I found,
[00:45:55.740 --> 00:45:58.140]   the first sort of condition that needs to be met
[00:45:58.140 --> 00:46:00.820]   is it needs to show up in the research, right?
[00:46:00.820 --> 00:46:03.260]   There needs to be data, there needs to be evidence
[00:46:03.260 --> 00:46:08.260]   to support that what you want to do makes sense, okay?
[00:46:08.260 --> 00:46:10.540]   The second thing is there needs to be
[00:46:10.540 --> 00:46:14.180]   some sort of philosophical underpinning to it.
[00:46:14.180 --> 00:46:17.500]   And this is, I think, a little bit less intuitive.
[00:46:17.500 --> 00:46:21.740]   Markets are so busy and so noisy
[00:46:21.740 --> 00:46:24.420]   that sometimes we will find correlations
[00:46:24.420 --> 00:46:25.900]   where none truly exist.
[00:46:25.900 --> 00:46:28.220]   There's the famous Super Bowl indicator.
[00:46:28.220 --> 00:46:31.420]   I can't remember if it's the AFC or the NFC,
[00:46:31.420 --> 00:46:35.740]   whoever wins is deeply predictive of how markets have done.
[00:46:35.740 --> 00:46:38.700]   There was a funny one from a couple years ago
[00:46:38.700 --> 00:46:42.100]   where Bangladeshi butter production
[00:46:42.100 --> 00:46:45.760]   and movements in the S&P 500 were deeply correlated,
[00:46:45.760 --> 00:46:48.180]   like at the 96th percentile.
[00:46:48.180 --> 00:46:49.820]   But if I said, hey, Rick,
[00:46:49.820 --> 00:46:52.980]   let's go start a Bangladeshi butter production hedge fund,
[00:46:52.980 --> 00:46:56.620]   no one should give us their money because it's, right?
[00:46:56.620 --> 00:46:58.820]   Like it doesn't make sense.
[00:46:58.820 --> 00:47:00.940]   - There's gotta be a fundamental basis behind it
[00:47:00.940 --> 00:47:02.860]   and a business basis behind it in a way.
[00:47:02.860 --> 00:47:04.480]   - Yeah, well said, right?
[00:47:04.480 --> 00:47:06.220]   Like there needs to be something fundamental,
[00:47:06.220 --> 00:47:07.740]   like why does this make sense?
[00:47:07.740 --> 00:47:10.220]   So first of all, does it show up in the data?
[00:47:10.220 --> 00:47:12.260]   Second of all, does it make sense?
[00:47:12.260 --> 00:47:13.500]   And then third of all,
[00:47:13.500 --> 00:47:18.260]   is there a behavioral reason why it will persist, right?
[00:47:18.260 --> 00:47:21.820]   This is what gives staying power to something.
[00:47:21.820 --> 00:47:25.740]   We know now a lot more than we did
[00:47:25.740 --> 00:47:28.540]   a hundred years ago about nutrition.
[00:47:28.540 --> 00:47:31.500]   We know better now than we do a hundred years ago
[00:47:31.500 --> 00:47:35.620]   what we ought to be eating, drinking, smoking, not smoking.
[00:47:35.620 --> 00:47:37.140]   Not to say we have perfect knowledge,
[00:47:37.140 --> 00:47:40.180]   but it's improved over the last hundred years.
[00:47:40.180 --> 00:47:43.420]   And yet our health outcomes are diminished
[00:47:43.420 --> 00:47:45.700]   because it is behaviorally difficult
[00:47:45.700 --> 00:47:47.940]   to eat salad over a donut.
[00:47:47.940 --> 00:47:50.800]   Even though I know the salad's better for me,
[00:47:50.800 --> 00:47:52.640]   the donut tastes better.
[00:47:52.640 --> 00:47:54.500]   And the same thing is true of markets.
[00:47:54.500 --> 00:47:58.380]   So you look at things like value investing,
[00:47:58.380 --> 00:48:03.060]   value investing has a behavioral underpinning to it.
[00:48:03.060 --> 00:48:04.680]   It's not always gonna win.
[00:48:04.680 --> 00:48:07.420]   There will be long stretches where it doesn't,
[00:48:07.420 --> 00:48:10.560]   but I still think it's a sensible way to invest
[00:48:10.560 --> 00:48:12.720]   because it shows up in the data,
[00:48:12.720 --> 00:48:14.980]   there's a reason it makes sense,
[00:48:14.980 --> 00:48:17.280]   and there's something psychological to it
[00:48:17.280 --> 00:48:20.020]   that means it's probably gonna stick around for a minute.
[00:48:20.020 --> 00:48:22.660]   So I think this is just sort of a good three-part test
[00:48:22.660 --> 00:48:24.520]   for an investment idea
[00:48:24.520 --> 00:48:26.980]   to see if it's worth taking seriously.
[00:48:27.900 --> 00:48:28.740]   - Okay, very good.
[00:48:28.740 --> 00:48:30.940]   Well, thank you for going through the book.
[00:48:30.940 --> 00:48:32.620]   It's always humbling to read these books
[00:48:32.620 --> 00:48:34.620]   because they come after story after story
[00:48:34.620 --> 00:48:35.680]   where I say, yeah, that's me.
[00:48:35.680 --> 00:48:37.260]   Yeah, yeah, that's me.
[00:48:37.260 --> 00:48:38.100]   - Yep.
[00:48:38.100 --> 00:48:39.480]   - But I do have some other questions for you
[00:48:39.480 --> 00:48:40.540]   before I let you go today
[00:48:40.540 --> 00:48:42.580]   and things that have been pressing me.
[00:48:42.580 --> 00:48:47.580]   First of all, you talk about this concept of never enough.
[00:48:47.580 --> 00:48:48.820]   We'd never have enough money.
[00:48:48.820 --> 00:48:51.380]   In fact, John Bogle wrote a book called "Enough."
[00:48:51.380 --> 00:48:54.300]   And talk about psychologically why that is.
[00:48:54.300 --> 00:48:56.100]   - I'm actually writing a new book right now
[00:48:56.100 --> 00:48:57.660]   and something I'm digging deeper into.
[00:48:57.660 --> 00:48:59.100]   So I'll have more to say soon.
[00:48:59.100 --> 00:49:03.460]   But the basic idea is, first of all,
[00:49:03.460 --> 00:49:08.460]   our ability to get enough is, again, fairly recent.
[00:49:08.460 --> 00:49:10.820]   Until modern times,
[00:49:10.820 --> 00:49:15.820]   you couldn't really stockpile resources in a way
[00:49:15.820 --> 00:49:18.500]   that would see you through the next 50 years.
[00:49:18.500 --> 00:49:21.820]   I mean, that is a relatively recent phenomenon.
[00:49:21.820 --> 00:49:22.660]   - Right.
[00:49:22.660 --> 00:49:26.340]   - And so again, we are wired for inadequacy.
[00:49:26.340 --> 00:49:29.180]   We are wired to keep grinding and to keep hunting
[00:49:29.180 --> 00:49:31.100]   and to keep pushing
[00:49:31.100 --> 00:49:36.020]   because that used to be the truth of how humans lived.
[00:49:36.020 --> 00:49:38.420]   Now, it doesn't happen a ton,
[00:49:38.420 --> 00:49:41.460]   but now you could sell a business when you're 30 years old
[00:49:41.460 --> 00:49:44.100]   and have enough money to never work again.
[00:49:44.100 --> 00:49:47.980]   And yet most people struggle to have enough.
[00:49:47.980 --> 00:49:51.580]   And there's all sorts of high-profile examples
[00:49:52.380 --> 00:49:57.380]   of people with plenty who act with a scarcity mindset.
[00:49:57.380 --> 00:49:59.340]   - Oh, I see that all the time in my business.
[00:49:59.340 --> 00:50:01.700]   I mean, if somebody has 2 million,
[00:50:01.700 --> 00:50:03.660]   they say, "If I only had 3 million."
[00:50:03.660 --> 00:50:05.020]   If somebody has 3 million,
[00:50:05.020 --> 00:50:06.820]   they say, "If I only had 5 million."
[00:50:06.820 --> 00:50:08.000]   If somebody has 50 million,
[00:50:08.000 --> 00:50:09.780]   they say, "If only I have 75 million."
[00:50:09.780 --> 00:50:11.540]   I can't get away from it.
[00:50:11.540 --> 00:50:13.140]   We humans, all we can think of
[00:50:13.140 --> 00:50:15.780]   is getting through the winter with enough food supply.
[00:50:15.780 --> 00:50:20.460]   I mean, this idea of saving for 10, 15, 20 years
[00:50:20.460 --> 00:50:22.740]   down the road, I mean, that doesn't compute.
[00:50:22.740 --> 00:50:25.100]   - Yeah, so I talk in the "Laws of Wealth."
[00:50:25.100 --> 00:50:26.980]   Gallup did a study a while back
[00:50:26.980 --> 00:50:29.460]   that looked at people at different income levels
[00:50:29.460 --> 00:50:31.820]   and it showed exactly what you just said.
[00:50:31.820 --> 00:50:34.620]   It said, "How much money would you need to be happy?"
[00:50:34.620 --> 00:50:38.100]   And the people who made 50 grand a year needed 75.
[00:50:38.100 --> 00:50:40.300]   The people who made 100 needed 150.
[00:50:40.300 --> 00:50:43.740]   The people who made half a million needed 600.
[00:50:43.740 --> 00:50:48.300]   At every income bracket, it was just out of reach.
[00:50:48.300 --> 00:50:51.700]   The psychological tendency is called the hedonic treadmill.
[00:50:51.700 --> 00:50:56.180]   We quickly adapt to whatever our reality is.
[00:50:56.180 --> 00:50:59.940]   A house is one of the worst ways that you can buy happiness
[00:50:59.940 --> 00:51:01.980]   because I have a beautiful home.
[00:51:01.980 --> 00:51:03.740]   When I bought it eight years ago,
[00:51:03.740 --> 00:51:05.860]   it was beyond my wildest dreams.
[00:51:05.860 --> 00:51:07.820]   Like, the first time I saw it,
[00:51:07.820 --> 00:51:09.380]   I couldn't believe this was mine.
[00:51:09.380 --> 00:51:11.340]   I couldn't believe I could afford it.
[00:51:11.340 --> 00:51:14.740]   And now it's just where I throw my dirty socks.
[00:51:14.740 --> 00:51:17.340]   We quickly become habituated to things.
[00:51:17.340 --> 00:51:19.580]   And the hedonic treadmill is
[00:51:19.580 --> 00:51:21.860]   whatever level of wealth you attain
[00:51:21.860 --> 00:51:23.700]   becomes your new reality.
[00:51:23.700 --> 00:51:25.740]   And then you're always running.
[00:51:25.740 --> 00:51:29.900]   And so it's imperative that we avoid lifestyle creep,
[00:51:29.900 --> 00:51:33.060]   that we study the literature around positive psychology
[00:51:33.060 --> 00:51:36.260]   and try and do things that truly sate us,
[00:51:36.260 --> 00:51:38.580]   like focusing on relationships,
[00:51:38.580 --> 00:51:40.260]   focusing on new experiences
[00:51:40.260 --> 00:51:42.140]   and new knowledge and new learning,
[00:51:42.140 --> 00:51:44.300]   and not just being more acquisitive.
[00:51:44.300 --> 00:51:46.660]   It's a pitcher that will never be filled.
[00:51:47.620 --> 00:51:51.460]   - The last thing is through our lives,
[00:51:51.460 --> 00:51:54.340]   as we get to older age,
[00:51:54.340 --> 00:51:58.500]   these cognitive or behavioral issues change.
[00:51:58.500 --> 00:52:00.940]   And I particularly wanna talk about
[00:52:00.940 --> 00:52:04.260]   as we move from our accumulation years
[00:52:04.260 --> 00:52:08.260]   to our retirement years and then to our golden years,
[00:52:08.260 --> 00:52:10.460]   how we change.
[00:52:10.460 --> 00:52:14.820]   - Yeah, so we'll speak first from the bias perspective.
[00:52:14.820 --> 00:52:17.820]   There's actually, there's good news as we age.
[00:52:17.820 --> 00:52:20.940]   The level of bias tends to diminish
[00:52:20.940 --> 00:52:24.220]   and life has a way of teaching us things
[00:52:24.220 --> 00:52:26.340]   about our own exceptionalism.
[00:52:26.340 --> 00:52:29.380]   So, what we see in the research
[00:52:29.380 --> 00:52:31.100]   is that the older people are,
[00:52:31.100 --> 00:52:32.740]   the less overconfident they are,
[00:52:32.740 --> 00:52:34.460]   the more humble they are,
[00:52:34.460 --> 00:52:37.540]   or sort of the more sort of equally calibrated they are.
[00:52:37.540 --> 00:52:39.700]   So I think this really conforms
[00:52:39.700 --> 00:52:43.100]   to our popular conception as youthful hubris,
[00:52:43.100 --> 00:52:45.740]   but we do learn and markets will teach us
[00:52:45.740 --> 00:52:48.260]   that we're not as great as we thought we were.
[00:52:48.260 --> 00:52:51.100]   So a lot of the biases that we've talked about today
[00:52:51.100 --> 00:52:54.580]   can kind of diminish, at least overconfidence can.
[00:52:54.580 --> 00:52:58.300]   But I think what we're seeing a lot of now,
[00:52:58.300 --> 00:53:01.740]   and I saw a heartbreaking story shared about on Twitter
[00:53:01.740 --> 00:53:03.220]   about this yesterday,
[00:53:03.220 --> 00:53:05.060]   was we're getting into sort of
[00:53:05.060 --> 00:53:08.100]   the happiness research with retirement.
[00:53:08.100 --> 00:53:11.700]   And a lot of people have put so much focus
[00:53:11.700 --> 00:53:16.460]   on preparing for their financial lives in retirement
[00:53:16.460 --> 00:53:20.740]   and very little focus on their personal lives.
[00:53:20.740 --> 00:53:25.620]   And what we see is that work checks a lot of boxes
[00:53:25.620 --> 00:53:27.460]   in terms of what makes people happy.
[00:53:27.460 --> 00:53:30.140]   So, you know, Martin Seligman has this great
[00:53:30.140 --> 00:53:33.260]   sort of five-part process, five-part model
[00:53:33.260 --> 00:53:36.660]   for what makes us happy called the PERMA model.
[00:53:36.660 --> 00:53:39.340]   The P in PERMA is for positive experiences.
[00:53:39.340 --> 00:53:41.020]   So this is having fun,
[00:53:41.020 --> 00:53:43.860]   going to a ball game, eating an ice cream cone, whatever.
[00:53:43.860 --> 00:53:44.980]   - Being with your grandkids.
[00:53:44.980 --> 00:53:48.300]   - Yeah, arguably work gets in the way of that, right?
[00:53:48.300 --> 00:53:51.100]   So in retirement, you have more positive experiences.
[00:53:51.100 --> 00:53:52.860]   You have more leisure time.
[00:53:52.860 --> 00:53:55.420]   The E though is for engagement.
[00:53:55.420 --> 00:53:58.620]   And this is doing deep, meaningful work.
[00:53:58.620 --> 00:54:00.380]   And a lot of people who are bought into
[00:54:00.380 --> 00:54:02.220]   sort of this old school idea of like,
[00:54:02.220 --> 00:54:05.460]   I'm just gonna hit the links and sit on a beach somewhere,
[00:54:05.460 --> 00:54:07.100]   they find that it's not fulfilling.
[00:54:07.100 --> 00:54:09.020]   We need that deep, meaningful work.
[00:54:09.020 --> 00:54:10.980]   - Oh, by the way, the work doesn't have to be for money.
[00:54:10.980 --> 00:54:12.380]   It could be nonprofit.
[00:54:12.380 --> 00:54:15.140]   - 100%, it could be volunteerism.
[00:54:15.140 --> 00:54:17.020]   - Like what I'm doing here.
[00:54:17.020 --> 00:54:18.940]   - Sure, it could be a hobby.
[00:54:18.940 --> 00:54:20.940]   I'm sitting here looking at my guitars, right?
[00:54:20.940 --> 00:54:24.140]   It just needs to be something that engages you.
[00:54:24.140 --> 00:54:26.820]   The R in PERMA is for relationships.
[00:54:26.820 --> 00:54:28.660]   A lot of our closest relationships
[00:54:28.660 --> 00:54:30.540]   are with people we work with.
[00:54:30.540 --> 00:54:33.060]   Work is a real source of relationships.
[00:54:33.060 --> 00:54:34.780]   The M is for meaning,
[00:54:34.780 --> 00:54:37.140]   working for something larger than yourself,
[00:54:37.140 --> 00:54:39.580]   whether it's religion, spirituality,
[00:54:39.580 --> 00:54:41.860]   charitable giving, philanthropy.
[00:54:41.860 --> 00:54:44.420]   Like work helps us be part of a team,
[00:54:44.420 --> 00:54:46.100]   work for something bigger.
[00:54:46.100 --> 00:54:47.860]   And then the A is for advancement.
[00:54:47.860 --> 00:54:50.780]   We are wired to wanna be better today
[00:54:50.780 --> 00:54:52.460]   than we were yesterday.
[00:54:52.460 --> 00:54:53.980]   And work gives us that.
[00:54:53.980 --> 00:54:56.300]   Work gives us opportunity for growth.
[00:54:56.300 --> 00:54:59.300]   So I mean, you could argue that's four of the five things
[00:54:59.300 --> 00:55:00.900]   that make people truly happy
[00:55:00.900 --> 00:55:03.780]   are itches that are scratched by work, right?
[00:55:03.780 --> 00:55:07.100]   I know enough bogleheads to know how fastidiously
[00:55:07.100 --> 00:55:09.580]   they prepare for retirement in many cases,
[00:55:09.580 --> 00:55:12.100]   but we have to be equally attentive
[00:55:12.100 --> 00:55:13.500]   just making sure our personal
[00:55:13.500 --> 00:55:16.940]   and our psychological lives are locked down
[00:55:16.940 --> 00:55:18.540]   because there's a lot that work does
[00:55:18.540 --> 00:55:21.420]   that I don't think we commonly recognize.
[00:55:21.420 --> 00:55:23.060]   - Well, Dan, it's been great having you on today.
[00:55:23.060 --> 00:55:25.260]   Are there any last words that you have for us?
[00:55:25.260 --> 00:55:29.020]   - Yeah, I hope this podcast will just encourage people
[00:55:29.020 --> 00:55:31.100]   to think about some of the things that we just talked about
[00:55:31.100 --> 00:55:33.460]   with those five pillars of happiness.
[00:55:33.460 --> 00:55:35.020]   And I hope if you read my books
[00:55:35.020 --> 00:55:36.860]   or other books on behavioral economics
[00:55:36.860 --> 00:55:38.660]   and behavioral finance,
[00:55:38.660 --> 00:55:40.060]   I hope you'll do it with an eye
[00:55:40.060 --> 00:55:42.780]   to just improving your life holistically.
[00:55:42.780 --> 00:55:44.860]   One of the cool things about studying this
[00:55:44.860 --> 00:55:48.100]   is it can make you a better market participant for sure,
[00:55:48.100 --> 00:55:50.180]   but I think it can make you a better wife,
[00:55:50.180 --> 00:55:52.660]   brother, grandfather, son, whatever.
[00:55:52.660 --> 00:55:54.560]   I think it can make you a better human
[00:55:54.560 --> 00:55:55.620]   as you're more thoughtful.
[00:55:55.620 --> 00:55:57.340]   So that's why I love this work.
[00:55:57.340 --> 00:55:59.060]   It can make you money, sure,
[00:55:59.060 --> 00:56:01.180]   but it can also make a difference in your life.
[00:56:01.180 --> 00:56:03.420]   So I think it's powerful for that reason.
[00:56:03.420 --> 00:56:05.580]   - Thanks, Dan, for being on "Bogleheads on Investing."
[00:56:05.580 --> 00:56:08.140]   Great comments, good insight.
[00:56:08.140 --> 00:56:10.860]   I don't feel bad about myself, which is a good thing.
[00:56:10.860 --> 00:56:12.620]   - That was my goal.
[00:56:12.620 --> 00:56:14.500]   Thank you for having me.
[00:56:14.500 --> 00:56:18.580]   - This concludes this episode of "Bogleheads on Investing."
[00:56:18.580 --> 00:56:21.340]   Join us each month as we interview a new guest
[00:56:21.340 --> 00:56:22.380]   on a new topic.
[00:56:22.380 --> 00:56:26.660]   In the meantime, visit boglcenter.net, bogleheads.org,
[00:56:26.660 --> 00:56:29.140]   the Bogleheads Wiki, Bogleheads Twitter.
[00:56:29.140 --> 00:56:31.380]   Listen live each week to "Bogleheads Live"
[00:56:31.380 --> 00:56:34.100]   on Twitter Spaces, the Bogleheads YouTube channel,
[00:56:34.100 --> 00:56:37.020]   Bogleheads Facebook, Bogleheads Reddit.
[00:56:37.020 --> 00:56:39.940]   Join one of your local "Bogleheads" chapters
[00:56:39.940 --> 00:56:41.260]   and get others to join.
[00:56:41.260 --> 00:56:42.260]   Thanks for listening.
[00:56:42.260 --> 00:56:44.840]   (upbeat music)
[00:56:44.840 --> 00:56:47.420]   (upbeat music)
[00:56:47.420 --> 00:56:50.000]   (upbeat music)
[00:56:50.000 --> 00:56:52.580]   (upbeat music)

