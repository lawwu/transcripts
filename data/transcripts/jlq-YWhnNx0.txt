
[00:00:00.000 --> 00:00:06.560]   this sort of standard drug discovery process at a high level? And where does machine learning fit
[00:00:06.560 --> 00:00:13.520]   into this or improve it? I don't know if one can really talk about a standard journey because
[00:00:13.520 --> 00:00:21.280]   it's been an evolving process over the last few years. But if you want to draw a very coarse
[00:00:21.280 --> 00:00:30.480]   grained caricature, you could say, well, I have a disease and I do usually, it's best done in an
[00:00:30.480 --> 00:00:38.240]   academic center, a bunch of biology to uncover the genes and the biological mechanisms, pathways
[00:00:38.240 --> 00:00:44.320]   that are implicated in disease. And then someone has a hypothesis about, okay, if I make an
[00:00:44.320 --> 00:00:51.840]   intervention at this gene, it may cure or at least help address, cure is a very broad word,
[00:00:51.840 --> 00:00:57.200]   very ambitious word. We've cured precious few diseases, but help address some of the aspects
[00:00:57.200 --> 00:01:03.360]   of the disease. And once you have that target, you can start to identify, well, first of all,
[00:01:03.360 --> 00:01:09.120]   you have to validate the target. And oftentimes that's done using animal models that attempt to
[00:01:09.120 --> 00:01:14.000]   simulate some aspects of the disease. And for many of the diseases that we have today,
[00:01:14.000 --> 00:01:18.800]   the animals don't get the disease naturally. And so you kind of have to create the disease
[00:01:18.800 --> 00:01:23.200]   in the animal and then try and address it in the animal. And it oftentimes turns out that
[00:01:23.200 --> 00:01:27.760]   what you're addressing really isn't the true disease. It's some simulation of it that is very
[00:01:27.760 --> 00:01:33.600]   imprecise and sometimes just downright wrong. And then once you have a target,
[00:01:33.600 --> 00:01:39.520]   then you typically look for chemical matter, a compound that helps modulate that target.
[00:01:39.520 --> 00:01:43.840]   And there's different, what are called therapeutic modalities, which are different kinds of
[00:01:43.840 --> 00:01:51.120]   interventions. So used to be, you know, whatever, 30, 40 years ago that the main form of a
[00:01:51.120 --> 00:01:57.920]   therapeutic modality we had was small molecules. And then around came biologics, which are larger
[00:01:57.920 --> 00:02:04.560]   molecules, basically proteins and antibodies, which are a type of protein that are in many cases,
[00:02:04.560 --> 00:02:10.880]   more precision mechanisms. So they're much more precise in their action, but they're also harder
[00:02:10.880 --> 00:02:16.800]   to administer and they are able to address a narrower set of targets. And now over time,
[00:02:16.800 --> 00:02:22.480]   we have additional therapeutic modalities that have emerged over the last few years that
[00:02:22.480 --> 00:02:27.040]   help intervene in the body and other types of mechanisms. So everyone's talking about
[00:02:27.040 --> 00:02:32.480]   gene therapy as they should, in which case we can come in and intervene in the DNA itself.
[00:02:32.480 --> 00:02:37.840]   And, you know, there's only a very few of those that have been approved so far,
[00:02:37.840 --> 00:02:44.960]   but it's very much a growing field. Now with the COVID-19 vaccine, everyone is talking about RNA
[00:02:44.960 --> 00:02:51.680]   therapeutics, which is intervening in between DNA and protein at the RNA level. So all of these are
[00:02:51.680 --> 00:02:58.240]   ways that are expanding our capabilities to make intelligent interventions in the human body and
[00:02:58.240 --> 00:03:04.560]   hence in a disease process. Oftentimes where it fails is really at the very beginning, which is
[00:03:05.600 --> 00:03:14.000]   we do not understand biology well at all. And therefore our ability to recognize when intervening
[00:03:14.000 --> 00:03:21.920]   in a target is going to actually have meaningful clinical benefit to a human is very, very limited.
[00:03:21.920 --> 00:03:29.040]   And oftentimes we guess and we guess wrong. And sometimes we also fail to understand all of the
[00:03:29.040 --> 00:03:34.880]   other implications that an intervention in a given target might have. For example, all of the other
[00:03:34.880 --> 00:03:40.960]   things that this particular gene does in the body. And if we intervene in a way that may,
[00:03:40.960 --> 00:03:47.040]   maybe even beneficial for this might be detrimental for that. And so that's where a lot of our
[00:03:47.040 --> 00:03:54.480]   ability to make valid predictions really falls short. And that's where a lot of drugs fail.
[00:03:54.480 --> 00:03:59.200]   Right now, the failure rate, depending on, you know, what you consider to be the denominator,
[00:03:59.200 --> 00:04:06.320]   like when do you start counting a program as a drug program is between 90 and 95%. That's the
[00:04:06.320 --> 00:04:12.240]   failure rate, not the success rate, which means between one in 10 and one in 20 drugs actually go
[00:04:12.240 --> 00:04:17.440]   on to be approved and an even smaller number actually ended up making a real difference to
[00:04:17.440 --> 00:04:23.200]   patients. So, and that's what we're looking to fix is how can we make better predictions
[00:04:23.760 --> 00:04:31.360]   first and foremost about what kinds of targets you would want to intervene in for a given disease
[00:04:31.360 --> 00:04:37.680]   in the context of a given patient population. And then subsequently find we want to intervene at
[00:04:37.680 --> 00:04:43.680]   this target. What is the right chemical matter to put in that might have fewer side effects that
[00:04:43.680 --> 00:04:50.320]   might have better drug-like properties? What is the right patient population to use? A lot of the
[00:04:50.320 --> 00:04:58.240]   failures that I think we have today are because we try and go after a much broader or miscalibrated
[00:04:58.240 --> 00:05:04.080]   patient population. And so over time, I think there's many questions in this process where
[00:05:04.080 --> 00:05:09.280]   machine learning can make an intervention, the target, the drug, the patient population,
[00:05:09.280 --> 00:05:14.800]   the biomarker that tells us when a drug is working so that we can cut things short if it's not and
[00:05:14.800 --> 00:05:19.280]   transition the patient to another drug. All of these are areas where I think machine learning
[00:05:19.280 --> 00:05:25.360]   can play a role. And does the machine learning try to kind of model the physical reality of the
[00:05:25.360 --> 00:05:30.800]   world here? Or does it sort of ignore that and just sort of look at like past experiments that
[00:05:30.800 --> 00:05:38.480]   were tried? I think people have tried both. And as we've seen in other cases where machine learning
[00:05:38.480 --> 00:05:45.200]   has been applied, there are some benefits to incorporating a lot of prior knowledge about
[00:05:45.200 --> 00:05:51.760]   the world. But then over time, that begins to become a limitation. So I used to work in
[00:05:51.760 --> 00:05:58.960]   computer vision way back when people still tried to create models of how light is refracted off
[00:05:58.960 --> 00:06:04.960]   of surfaces and having geometric models for computer vision and models of illumination and
[00:06:04.960 --> 00:06:11.840]   so on and so forth. And we don't do that anymore. What we now do is create really, really large
[00:06:11.840 --> 00:06:17.200]   training sets and give the computer enough data that it can learn the patterns without having to
[00:06:17.200 --> 00:06:23.200]   be told a lot about the structure of the world. We haven't quite hit that tipping point in most
[00:06:23.200 --> 00:06:30.400]   biological problems because the data that's been available has just been insufficient. And so right
[00:06:30.400 --> 00:06:37.440]   now there is a lot of problems where models that incorporate more of our understanding of biology
[00:06:37.440 --> 00:06:44.720]   are actually in many cases outperforming models that are less informed. But one of, to my mind,
[00:06:44.720 --> 00:06:50.480]   a real highlight achievement from the past year that starts to go in the other direction
[00:06:50.480 --> 00:06:58.560]   is the incredible success of DeepMind's AlphaFold algorithm, which uses somewhat similar machine
[00:06:58.560 --> 00:07:05.280]   learning tools to AlphaGo, which they used in a very different domain. And AlphaFold is basically
[00:07:05.280 --> 00:07:10.400]   addressing the problem of protein folding. So to take an amino acid sequence that represents
[00:07:10.400 --> 00:07:17.600]   a protein and ask what it will look like in 3D space. There's been multiple groups over the past,
[00:07:17.600 --> 00:07:23.280]   I don't know, 10, if not more years that have built computer tools, some incorporating machine
[00:07:23.280 --> 00:07:28.800]   learning, but certainly all incorporating a relatively large amount of prior knowledge about
[00:07:28.800 --> 00:07:36.560]   physics and chemistry and forces and electrons and so on and so forth, and asking what the
[00:07:36.560 --> 00:07:40.400]   folded protein would look like. And all of them kind of asymptoted at a certain
[00:07:40.400 --> 00:07:46.320]   level of performance, which was reasonable, but not usable. And by the way, I forgot to say that
[00:07:46.320 --> 00:07:53.360]   there's been a biannual competition once every two years called CASP, which is one of the best
[00:07:53.360 --> 00:08:00.160]   designed real blinded tests for machine learning model, one where you can't cheat, in which labs
[00:08:00.160 --> 00:08:06.400]   that are experimenting on a particular protein by generating its crystal structure, which is the 3D
[00:08:06.400 --> 00:08:14.880]   structure, would submit the sequence to the CASP competition and they would not release the solved
[00:08:14.880 --> 00:08:21.520]   structure until the competition was done. And since no one can, I mean, it's months of experimental
[00:08:21.520 --> 00:08:26.400]   work to come up with that structure, people couldn't cheat on the test data. So in this
[00:08:26.400 --> 00:08:34.400]   CASP competition, you could see that there was a plateau of performance. And in this last year,
[00:08:34.400 --> 00:08:40.720]   DeepMind really broke through that plateau and achieved a performance that is actually usable for
[00:08:40.720 --> 00:08:48.960]   real biological problems. And the way they did that is by not incorporating into the model,
[00:08:48.960 --> 00:08:54.320]   a lot of preconceptions about physics and chemistry and different kinds of chemical bonds,
[00:08:54.320 --> 00:09:00.000]   but really just giving the machine learning model enough pairs of sequences and solve structures to
[00:09:00.000 --> 00:09:05.120]   train on. And then they said, okay, now that you've learned, go and run on a new protein.
[00:09:05.120 --> 00:09:11.280]   And they were able to break through that ceiling that we've seen. So I think to my mind, that's
[00:09:11.280 --> 00:09:19.600]   an indication that we need to be really thinking hard about how to generate enough data at scale
[00:09:19.600 --> 00:09:24.320]   for biological or chemical problems so that you can get machine learning to break through that
[00:09:24.320 --> 00:09:30.400]   ceiling and performance. And that's kind of what we're trying to do at In-sitro is build massive
[00:09:30.400 --> 00:09:37.680]   data production capabilities across the problems that we care about so that we can generate data
[00:09:37.680 --> 00:09:44.880]   that's enough high quality and large enough and that is fit to purpose so that you can train
[00:09:44.880 --> 00:09:48.960]   machine learning models to solve the problems that we care to solve in the drug discovery process.
[00:09:48.960 --> 00:09:55.040]   So I guess, I want to get back to In-sitro in a second, but since the protein folding
[00:09:55.040 --> 00:10:00.320]   thing was so high profile, I'll ask you my dumb questions, which is such a waste, but
[00:10:00.320 --> 00:10:06.080]   I was kind of curious, what was the insight then? It seems like just actually removing prior
[00:10:06.080 --> 00:10:11.040]   beliefs from a model wouldn't be enough to have a breakthrough improvement in the quality. And
[00:10:11.040 --> 00:10:15.840]   surely lots of people had access to lots of examples of proteins and how they fold, right?
[00:10:15.840 --> 00:10:22.960]   So I can't speak to that yet because they have not yet published their latest model. And so we're
[00:10:22.960 --> 00:10:29.040]   relying on the very limited information that's in a press release. And so I would be curious to read
[00:10:29.040 --> 00:10:36.000]   the paper once it's out, but I do know that they incorporated a lot of insight from the latest
[00:10:36.000 --> 00:10:41.360]   machine learning models in terms of, for instance, attention models that you can look to see where
[00:10:41.360 --> 00:10:47.440]   you would want to kind of have one amino acid look elsewhere in the sequence to figure out
[00:10:47.440 --> 00:10:53.280]   where to fold. But I wish I could give you more insight into exactly how this works and I'm
[00:10:53.280 --> 00:10:57.680]   hoping that they will publish the results soon and we will all learn from how they did this.
[00:10:58.320 --> 00:11:02.640]   And is protein folding, is that a sub problem of one of the problems that you mentioned,
[00:11:02.640 --> 00:11:06.560]   or is that just an example of how much momentum there is in the field?
[00:11:06.560 --> 00:11:12.320]   You know, I think people have differing opinions on the extent to which protein
[00:11:12.320 --> 00:11:17.840]   folding matters in drug discovery. I think there's a lot of proteins where the structure is actually
[00:11:17.840 --> 00:11:22.400]   pretty well understood and we just don't know how to drug them. Protein folding certainly doesn't
[00:11:22.400 --> 00:11:28.240]   help you with the fundamental question of picking the right target to go after because the folding
[00:11:28.240 --> 00:11:33.840]   comes after you decide that this is a target that you need. There certainly are a set of targets
[00:11:33.840 --> 00:11:39.680]   where you really would like to go after them and what's missing is an understanding of their 3D
[00:11:39.680 --> 00:11:45.840]   structure. How big that set is, I think is a matter for debate. But so to my mind, it's less
[00:11:45.840 --> 00:11:50.800]   about whether protein folding is the key problem in drug discovery. It's certainly not the key
[00:11:50.800 --> 00:11:56.400]   problem. It may be a problem, but it's certainly not at the core of what's holding drug discovery
[00:11:56.400 --> 00:12:05.680]   back. But it's really an illustration of taking a problem that everyone agreed was hard, people had
[00:12:05.680 --> 00:12:12.800]   struggled to solve or tried to solve using a range of other methods and machine learning came in and
[00:12:12.800 --> 00:12:18.000]   with the right type of model and the right type of data was really able to crack that nut open.
[00:12:18.000 --> 00:12:22.320]   And so that to me is the real lesson here rather than we've transformed drug discovery.
[00:12:23.440 --> 00:12:27.360]   Thanks for watching this clip. You can see the full episode on our YouTube channel.
[00:12:27.360 --> 00:12:31.600]   And you can join our friendly Slack community with over 4,000
[00:12:31.600 --> 00:12:38.720]   ML engineers to participate in paper reading groups, AMAs, and other fun events.

