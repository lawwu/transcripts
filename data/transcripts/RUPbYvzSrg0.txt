
[00:00:00.000 --> 00:00:03.680]   It's my pleasure to introduce Paroma Varma.
[00:00:03.680 --> 00:00:06.680]   Paroma is a fourth year PhD student at Stanford
[00:00:06.680 --> 00:00:09.000]   working on machine learning, and in particular on weak
[00:00:09.000 --> 00:00:09.840]   supervision.
[00:00:09.840 --> 00:00:12.480]   In my opinion, weak supervision is a really, really exciting
[00:00:12.480 --> 00:00:17.080]   approach to alleviating some of the issues around how
[00:00:17.080 --> 00:00:19.800]   difficult it is to label training data.
[00:00:19.800 --> 00:00:22.200]   And in particular, she's worked on SNRCL,
[00:00:22.200 --> 00:00:25.480]   which is one of the most promising systems
[00:00:25.480 --> 00:00:26.640]   for doing that.
[00:00:26.640 --> 00:00:28.320]   And so I'm really excited to have her here
[00:00:28.320 --> 00:00:29.880]   to hear a lot more about the work that she's
[00:00:29.880 --> 00:00:30.880]   been doing at Stanford.
[00:00:30.880 --> 00:00:31.380]   So welcome.
[00:00:31.380 --> 00:00:40.040]   Well, thank you for that amazing introduction.
[00:00:40.040 --> 00:00:43.040]   Hope I can live up to that, and SNRCL can live up to that.
[00:00:43.040 --> 00:00:45.000]   So I'll do a brief overview of the work
[00:00:45.000 --> 00:00:47.040]   we've been doing around weak supervision,
[00:00:47.040 --> 00:00:49.440]   and particularly our system SNRCL.
[00:00:49.440 --> 00:00:51.520]   Feel free to ask questions as I give the talk.
[00:00:51.520 --> 00:00:54.560]   If I don't get through all the slides, no big deal.
[00:00:54.560 --> 00:00:55.360]   So I'll start off.
[00:00:55.360 --> 00:00:59.160]   So SNRCL is a system to help program training data
[00:00:59.160 --> 00:00:59.800]   efficiently.
[00:00:59.800 --> 00:01:03.800]   This is work that I did during my PhD in Chris Ray's lab
[00:01:03.800 --> 00:01:07.520]   at Stanford, along with other members of the lab.
[00:01:07.520 --> 00:01:09.880]   So as we know, machine learning is everywhere.
[00:01:09.880 --> 00:01:11.520]   I'm kind of preaching to the choir
[00:01:11.520 --> 00:01:13.720]   here if I say that people are using it
[00:01:13.720 --> 00:01:17.440]   for natural language processing, analyzing images, but also
[00:01:17.440 --> 00:01:20.880]   things that ML wasn't thought to be used for,
[00:01:20.880 --> 00:01:23.840]   like things like networking or data cleaning.
[00:01:23.840 --> 00:01:27.160]   And because machine learning has kind of
[00:01:27.160 --> 00:01:31.240]   exploded in its popularity, one of the things that we noticed
[00:01:31.240 --> 00:01:33.640]   was that people are spending a lot of their time
[00:01:33.640 --> 00:01:36.380]   kind of just working with their training data.
[00:01:36.380 --> 00:01:38.840]   And we call this shaping training data.
[00:01:38.840 --> 00:01:40.780]   And it's kind of this ad hoc procedure
[00:01:40.780 --> 00:01:42.680]   where people have to label their data.
[00:01:42.680 --> 00:01:45.560]   They have to make sure they have a good representation of the data
[00:01:45.560 --> 00:01:46.700]   they're looking for.
[00:01:46.700 --> 00:01:48.880]   They try different augmentation schemes.
[00:01:48.880 --> 00:01:51.280]   They try reweighting the data that they have
[00:01:51.280 --> 00:01:54.680]   and telling the model to focus on specific parts of it.
[00:01:54.680 --> 00:01:57.400]   And it's a really time-consuming process.
[00:01:57.400 --> 00:01:59.320]   And what we wanted to do was kind of focus
[00:01:59.320 --> 00:02:02.080]   on one aspect of it, which is the labeling part,
[00:02:02.080 --> 00:02:05.080]   and try to make it more efficient.
[00:02:05.080 --> 00:02:08.520]   The key idea that we have behind our system, which is Snorkel,
[00:02:08.520 --> 00:02:10.360]   which is this cute octopus--
[00:02:10.360 --> 00:02:13.240]   don't ask me why this has to do with labeling training data.
[00:02:13.240 --> 00:02:15.600]   It's like this long story about another project
[00:02:15.600 --> 00:02:16.480]   that was in our lab.
[00:02:16.480 --> 00:02:19.800]   But for now, octopus means labeling training data.
[00:02:19.800 --> 00:02:22.240]   The key idea behind this is essentially
[00:02:22.240 --> 00:02:26.760]   we want to take advantage of noisy sources of labels, which
[00:02:26.760 --> 00:02:30.560]   don't kind of work on an individual data point basis,
[00:02:30.560 --> 00:02:33.720]   but rather work on a higher level of abstraction
[00:02:33.720 --> 00:02:36.540]   and be able to model their noise and combine them so that we
[00:02:36.540 --> 00:02:39.600]   can get labels more efficiently.
[00:02:39.600 --> 00:02:42.040]   So before jumping into the details,
[00:02:42.040 --> 00:02:44.120]   I want to thank everyone in our lab who
[00:02:44.120 --> 00:02:47.880]   helped build this project, as well as our collaborators
[00:02:47.880 --> 00:02:50.480]   on the industry side, who were really patient with us
[00:02:50.480 --> 00:02:53.440]   and tried out research code on their real data
[00:02:53.440 --> 00:02:56.240]   and gave us really helpful feedback.
[00:02:56.240 --> 00:02:58.040]   So to start off with Snorkel and kind
[00:02:58.040 --> 00:03:00.760]   of going through the basic steps of that system,
[00:03:00.760 --> 00:03:03.600]   Snorkel consists of three main steps.
[00:03:03.600 --> 00:03:05.680]   So the first step, which is the labeling part,
[00:03:05.680 --> 00:03:08.120]   is users write these heuristics that
[00:03:08.120 --> 00:03:10.000]   are called labeling functions.
[00:03:10.000 --> 00:03:11.680]   And labeling functions are essentially
[00:03:11.680 --> 00:03:13.680]   these rules that are not perfect,
[00:03:13.680 --> 00:03:16.520]   but they kind of encapsulate some knowledge people
[00:03:16.520 --> 00:03:18.760]   have about the data that they're trying to label.
[00:03:18.760 --> 00:03:21.380]   And I'll show some examples of that next.
[00:03:21.380 --> 00:03:23.080]   The second part of the Snorkel system
[00:03:23.080 --> 00:03:25.440]   is the actual algorithm that helps
[00:03:25.440 --> 00:03:28.840]   learn and model these heuristics that users have written.
[00:03:28.840 --> 00:03:31.600]   We need to know how accurate they are.
[00:03:31.600 --> 00:03:34.160]   We need to know if they're correlated in some manner.
[00:03:34.160 --> 00:03:36.040]   And once we have this information learned,
[00:03:36.040 --> 00:03:38.120]   we can combine them in an optimal manner
[00:03:38.120 --> 00:03:41.680]   to assign training labels to the data that we have.
[00:03:41.680 --> 00:03:43.560]   Once we have these training labels now,
[00:03:43.560 --> 00:03:46.080]   we can train any deep learning model
[00:03:46.080 --> 00:03:47.380]   that we're interested in.
[00:03:47.380 --> 00:03:50.040]   We just have to make a one line change in terms
[00:03:50.040 --> 00:03:51.400]   of the loss it uses.
[00:03:51.400 --> 00:03:54.040]   But you can just kind of keep doing
[00:03:54.040 --> 00:03:55.720]   the rest of your machine learning pipeline
[00:03:55.720 --> 00:03:58.400]   as you were before.
[00:03:58.400 --> 00:04:00.760]   The first step, which I think the most important part
[00:04:00.760 --> 00:04:04.280]   of the system, but I only have one slide on it--
[00:04:04.280 --> 00:04:06.480]   I'll have more slides later on--
[00:04:06.480 --> 00:04:08.160]   is writing labeling functions.
[00:04:08.160 --> 00:04:10.320]   And we kind of see writing labeling functions
[00:04:10.320 --> 00:04:13.680]   as a way of encoding domain knowledge people
[00:04:13.680 --> 00:04:16.640]   have about the data that they want to label.
[00:04:16.640 --> 00:04:18.760]   So what this looks like for Snorkel,
[00:04:18.760 --> 00:04:22.120]   which is written in Python, are these little Python snippets
[00:04:22.120 --> 00:04:23.080]   of code.
[00:04:23.080 --> 00:04:26.000]   So in the first task that I have up here,
[00:04:26.000 --> 00:04:28.520]   we want to see if the chemical name and the disease
[00:04:28.520 --> 00:04:31.280]   name in a particular sentence have a relationship.
[00:04:31.280 --> 00:04:33.360]   Like, does the chemical cause the disease that's
[00:04:33.360 --> 00:04:34.840]   mentioned in the sentence?
[00:04:34.840 --> 00:04:37.440]   Now, you can imagine going through every single sentence
[00:04:37.440 --> 00:04:39.960]   with different names of chemicals and diseases
[00:04:39.960 --> 00:04:42.300]   and labeling them one by one.
[00:04:42.300 --> 00:04:43.720]   Like, this is a true relation.
[00:04:43.720 --> 00:04:45.280]   This is not a true relation.
[00:04:45.280 --> 00:04:47.680]   And this can take a long time, especially if your data
[00:04:47.680 --> 00:04:49.400]   set is really large.
[00:04:49.400 --> 00:04:52.040]   What we do instead is we ask users
[00:04:52.040 --> 00:04:53.720]   to write these labeling functions.
[00:04:53.720 --> 00:04:57.060]   It can look for words in the sentence or certain patterns
[00:04:57.060 --> 00:05:00.600]   that tell us a good enough signal of whether the sentence
[00:05:00.600 --> 00:05:01.800]   is true or false.
[00:05:01.800 --> 00:05:05.160]   So in this case, we can look for words like "due to" or "because"
[00:05:05.160 --> 00:05:07.000]   and whether they appear in between the name
[00:05:07.000 --> 00:05:08.720]   of the chemical and the disease.
[00:05:08.720 --> 00:05:11.560]   Something else that we can do is we can also have negative rules.
[00:05:11.560 --> 00:05:14.500]   So if there's clearly a phrase like "not cause"
[00:05:14.500 --> 00:05:16.980]   that appears in the sentence, then this relation
[00:05:16.980 --> 00:05:18.620]   is probably not true.
[00:05:18.620 --> 00:05:20.160]   We can do this not just for text.
[00:05:20.160 --> 00:05:22.160]   We can do it for images as well.
[00:05:22.160 --> 00:05:24.060]   Let's say we have an image, and we
[00:05:24.060 --> 00:05:27.060]   used one of the out-of-the-box object detectors,
[00:05:27.060 --> 00:05:29.900]   and we have bounding boxes for people and bikes.
[00:05:29.900 --> 00:05:31.960]   But now we want to know if we actually
[00:05:31.960 --> 00:05:35.380]   have pictures of people riding the bike in these images
[00:05:35.380 --> 00:05:36.140]   or not.
[00:05:36.140 --> 00:05:39.820]   So again, we can imagine crowdsourcing this entire task,
[00:05:39.820 --> 00:05:41.980]   training a specialized model for it.
[00:05:41.980 --> 00:05:44.420]   But instead, maybe we can make use
[00:05:44.420 --> 00:05:47.540]   of the bounding boxes that are within the image already
[00:05:47.540 --> 00:05:50.460]   and say something like, if the person is above the bike,
[00:05:50.460 --> 00:05:53.220]   it's probably true that the person is riding the bike.
[00:05:53.220 --> 00:05:55.980]   If the person is much smaller than the bike,
[00:05:55.980 --> 00:05:58.140]   then maybe the person is in the background
[00:05:58.140 --> 00:06:00.560]   and the bike is in the foreground.
[00:06:00.560 --> 00:06:04.820]   So that particular person is not riding the bike.
[00:06:04.820 --> 00:06:07.560]   The key thing to remember with these labeling function
[00:06:07.560 --> 00:06:10.220]   is that we can write multiple of these, but none of them
[00:06:10.220 --> 00:06:11.440]   are going to be perfect.
[00:06:11.440 --> 00:06:13.700]   If you could have written a perfect labeling function,
[00:06:13.700 --> 00:06:15.540]   then we wouldn't need to do machine learning
[00:06:15.540 --> 00:06:18.580]   for our specific classification task.
[00:06:18.580 --> 00:06:20.700]   The second step now is given--
[00:06:20.700 --> 00:06:21.200]   yeah?
[00:06:21.200 --> 00:06:24.340]   Have you-- these rules, do they have to be mutually exclusive?
[00:06:24.340 --> 00:06:25.660]   No, that's a great question.
[00:06:25.660 --> 00:06:27.380]   They don't have to be mutually exclusive,
[00:06:27.380 --> 00:06:31.580]   because we can actually learn their correlations as well.
[00:06:31.580 --> 00:06:33.380]   So great-- yeah?
[00:06:33.380 --> 00:06:34.540]   So they're not for--
[00:06:34.540 --> 00:06:37.500]   so the error rate would be common on them?
[00:06:37.500 --> 00:06:41.540]   Yeah, so I can talk about a few example tasks that we had.
[00:06:41.540 --> 00:06:44.300]   We see, for a binary classification task,
[00:06:44.300 --> 00:06:48.820]   for example, we see anything between 60% accurate and 90%
[00:06:48.820 --> 00:06:49.620]   accurate.
[00:06:49.620 --> 00:06:51.900]   Another key thing about these labeling functions
[00:06:51.900 --> 00:06:53.880]   is they can actually abstain.
[00:06:53.880 --> 00:06:56.820]   So what abstain means is that it will return true
[00:06:56.820 --> 00:06:58.820]   if it finds a particular phrase.
[00:06:58.820 --> 00:07:01.380]   But if it doesn't find it, it's not going to return false.
[00:07:01.380 --> 00:07:03.460]   It's just going to return I don't know.
[00:07:03.460 --> 00:07:06.460]   So what you end up with is you have some labeling functions
[00:07:06.460 --> 00:07:09.780]   that are-- they only assign a label to 10% of the data
[00:07:09.780 --> 00:07:12.900]   points, but they're 90% accurate on that subset,
[00:07:12.900 --> 00:07:16.300]   versus you have other ones that are only 60% accurate,
[00:07:16.300 --> 00:07:21.380]   but now they've labeled, say, 90% of the data points.
[00:07:21.380 --> 00:07:23.420]   So in order to learn their accuracies
[00:07:23.420 --> 00:07:27.860]   and model their correlations, we can't rely on any label data.
[00:07:27.860 --> 00:07:31.260]   The whole idea is to move away from hand labeling any data.
[00:07:31.260 --> 00:07:32.980]   So what we do instead is we just look
[00:07:32.980 --> 00:07:36.180]   at the overlaps and conflicts among the labels assigned
[00:07:36.180 --> 00:07:37.940]   by these different labeling functions,
[00:07:37.940 --> 00:07:41.220]   and we can actually use that to learn what the accuracy is.
[00:07:41.220 --> 00:07:43.100]   We do this in a factor graph-based model,
[00:07:43.100 --> 00:07:44.660]   and if we have time after the talk,
[00:07:44.660 --> 00:07:47.820]   I would love to get into details of that as well.
[00:07:47.820 --> 00:07:49.500]   And to answer your question, we do
[00:07:49.500 --> 00:07:51.840]   model the correlations among these labeling functions
[00:07:51.840 --> 00:07:53.940]   as well, because often we see you
[00:07:53.940 --> 00:07:56.580]   have multiple people on a team writing these,
[00:07:56.580 --> 00:07:58.180]   and they're not exclusive.
[00:07:58.180 --> 00:08:00.000]   Both people have the same idea.
[00:08:00.000 --> 00:08:02.580]   They're trying to encode in these Python programs,
[00:08:02.580 --> 00:08:05.100]   and we don't want to double count their vote.
[00:08:05.100 --> 00:08:08.020]   So we do need to know if they're related or dependent
[00:08:08.020 --> 00:08:09.980]   on each other in some way.
[00:08:09.980 --> 00:08:10.480]   Yeah?
[00:08:10.480 --> 00:08:14.420]   When you're comparing their accuracy,
[00:08:14.420 --> 00:08:16.980]   are you comparing-- this is not comparing to a ground truth,
[00:08:16.980 --> 00:08:17.500]   right?
[00:08:17.500 --> 00:08:18.260]   No, no.
[00:08:18.260 --> 00:08:19.860]   This is not comparing to ground truth.
[00:08:19.860 --> 00:08:20.360]   [INAUDIBLE]
[00:08:20.360 --> 00:08:29.380]   Right, right.
[00:08:29.380 --> 00:08:31.460]   So when we learn the accuracies, we're
[00:08:31.460 --> 00:08:34.740]   learning how accurate it is compared to ground truth.
[00:08:34.740 --> 00:08:38.140]   So the reason we can do this is we have, at a high level,
[00:08:38.140 --> 00:08:41.820]   the intuition is that if two labeling functions tend
[00:08:41.820 --> 00:08:44.660]   to agree a lot, they're probably both fairly accurate.
[00:08:44.660 --> 00:08:46.420]   And then you have a third labeling function
[00:08:46.420 --> 00:08:48.860]   that randomly agrees and disagrees with these two,
[00:08:48.860 --> 00:08:51.100]   then it's probably not as accurate.
[00:08:51.100 --> 00:08:55.340]   Mathematically, we can form this covariance matrix
[00:08:55.340 --> 00:08:57.460]   that helps where we basically solve
[00:08:57.460 --> 00:08:59.820]   for this variable of how correlated
[00:08:59.820 --> 00:09:01.940]   are the labels that the labeling function assigns
[00:09:01.940 --> 00:09:03.220]   to the ground truth variable.
[00:09:03.220 --> 00:09:05.260]   And I have that towards the end of my talk
[00:09:05.260 --> 00:09:06.860]   to go into the details of that.
[00:09:06.860 --> 00:09:09.060]   That's the really cool and interesting part anyways.
[00:09:09.060 --> 00:09:14.460]   So once we've modeled the accuracies
[00:09:14.460 --> 00:09:16.460]   and we have learned the correlations,
[00:09:16.460 --> 00:09:17.980]   what's the next step?
[00:09:17.980 --> 00:09:19.500]   So the next step that we want to do
[00:09:19.500 --> 00:09:22.140]   is we actually want to use these labels that we've
[00:09:22.140 --> 00:09:26.380]   assigned to the data and train a machine learning model with it.
[00:09:26.380 --> 00:09:28.340]   One of the questions that we commonly get
[00:09:28.340 --> 00:09:30.140]   is you have all these heuristics.
[00:09:30.140 --> 00:09:32.460]   Say you have 10 or 15 heuristics.
[00:09:32.460 --> 00:09:35.460]   You've learned their accuracies, hopefully really well.
[00:09:35.460 --> 00:09:36.260]   You've modeled them.
[00:09:36.260 --> 00:09:38.100]   You've combined them according to that.
[00:09:38.100 --> 00:09:39.180]   Why not just stop here?
[00:09:39.180 --> 00:09:41.420]   Why can't you just use these labels
[00:09:41.420 --> 00:09:43.540]   as kind of your end product?
[00:09:43.540 --> 00:09:46.900]   And the reason is because these labels that's
[00:09:46.900 --> 00:09:48.700]   been assigned to the data, it's not
[00:09:48.700 --> 00:09:51.980]   using all the information available in the data.
[00:09:51.980 --> 00:09:54.260]   Let's go back to the text example that we had.
[00:09:54.260 --> 00:09:56.020]   It's only looking for certain phrases.
[00:09:56.020 --> 00:09:57.940]   Like it's looking for the phrase "due to,"
[00:09:57.940 --> 00:10:00.460]   or it's looking for the phrase "not cause."
[00:10:00.460 --> 00:10:02.820]   But it's ignoring all the other information
[00:10:02.820 --> 00:10:05.780]   that's present in the sentence that, say, an LSTM could pick
[00:10:05.780 --> 00:10:06.300]   up.
[00:10:06.300 --> 00:10:08.140]   So once we have these noisy labels,
[00:10:08.140 --> 00:10:12.060]   we do want to take advantage of all the rich structural data
[00:10:12.060 --> 00:10:14.580]   that we have access to and then train another end
[00:10:14.580 --> 00:10:16.620]   model using these labels.
[00:10:16.620 --> 00:10:19.420]   The second reason we want to train another model is,
[00:10:19.420 --> 00:10:20.820]   remember, these labeling functions
[00:10:20.820 --> 00:10:24.220]   don't necessarily assign a label to every single data point.
[00:10:24.220 --> 00:10:26.420]   So they might only end up covering, say,
[00:10:26.420 --> 00:10:28.780]   60% or 80% of your data points.
[00:10:28.780 --> 00:10:30.300]   But a model that you build, you want
[00:10:30.300 --> 00:10:32.740]   it to be able to predict a label for any data point
[00:10:32.740 --> 00:10:33.540]   that it sees.
[00:10:33.540 --> 00:10:37.140]   So that's another reason to take these labels that you have,
[00:10:37.140 --> 00:10:39.860]   treat them as training labels, and then train another end
[00:10:39.860 --> 00:10:42.220]   model with it.
[00:10:42.220 --> 00:10:45.220]   So one of the things we did after we built the system-- yeah?
[00:10:45.220 --> 00:10:49.180]   Would the model then encode the logic in the labels?
[00:10:49.180 --> 00:10:51.380]   Or would it be able to do something more than what
[00:10:51.380 --> 00:10:52.260]   the labels have done?
[00:10:52.260 --> 00:10:53.900]   Yeah, that's a really good question.
[00:10:53.900 --> 00:10:55.980]   So the question was, will the model just
[00:10:55.980 --> 00:10:58.540]   encode the logic that was in the training labels
[00:10:58.540 --> 00:11:00.540]   that we got from the labeling functions?
[00:11:00.540 --> 00:11:03.580]   Or will it be able to generalize to other information?
[00:11:03.580 --> 00:11:07.260]   So we've seen, in practice, if we have access
[00:11:07.260 --> 00:11:09.300]   to a large amount of features, which is usually
[00:11:09.300 --> 00:11:11.260]   true for deep learning models, it's
[00:11:11.260 --> 00:11:14.220]   able to generalize beyond just the logic that's contained
[00:11:14.220 --> 00:11:16.140]   in these training labels.
[00:11:16.140 --> 00:11:18.900]   Another point is that when we assign training labels,
[00:11:18.900 --> 00:11:20.660]   they're not just--
[00:11:20.660 --> 00:11:22.020]   it's not, say, in a binary test.
[00:11:22.020 --> 00:11:24.260]   It's not just true, false, true, false.
[00:11:24.260 --> 00:11:27.300]   We actually have an associated confidence with the labels
[00:11:27.300 --> 00:11:28.260]   that we assign.
[00:11:28.260 --> 00:11:32.420]   So we have labels like, this is 40% likelihood of being true.
[00:11:32.420 --> 00:11:34.780]   This has 60% likelihood of being true.
[00:11:34.780 --> 00:11:38.540]   So encoding that kind of confidence parameter
[00:11:38.540 --> 00:11:41.100]   in the training labels also helps the end model
[00:11:41.100 --> 00:11:43.620]   go beyond the logic that was encoded in the labeling
[00:11:43.620 --> 00:11:46.020]   functions.
[00:11:46.020 --> 00:11:46.520]   Yeah?
[00:11:46.520 --> 00:11:49.060]   When you say encoded, that's not part of the label function,
[00:11:49.060 --> 00:11:49.560]   right?
[00:11:49.560 --> 00:11:52.740]   That's something you do after the label function.
[00:11:52.740 --> 00:11:54.660]   So the encoding part of--
[00:11:54.660 --> 00:11:58.140]   The label function is not what is 40% sure.
[00:11:58.140 --> 00:11:58.700]   Right, right.
[00:11:58.700 --> 00:12:01.300]   The labeling function is just going to say, this is true.
[00:12:01.300 --> 00:12:02.380]   This is not true.
[00:12:02.380 --> 00:12:03.660]   I don't know.
[00:12:03.660 --> 00:12:06.700]   When we run our model and learn its accuracies,
[00:12:06.700 --> 00:12:10.340]   we essentially do a weighted majority vote
[00:12:10.340 --> 00:12:13.020]   across all the labels that were assigned.
[00:12:13.020 --> 00:12:16.140]   And we get confidence according to that.
[00:12:16.140 --> 00:12:18.540]   We're trying to do something right now in lab
[00:12:18.540 --> 00:12:21.740]   where the labeling functions can also encode a confidence.
[00:12:21.740 --> 00:12:24.180]   Because sometimes you have, say, another model
[00:12:24.180 --> 00:12:26.280]   that you might be using as a labeling function.
[00:12:26.280 --> 00:12:29.080]   And then we should be able to learn that accuracy as well.
[00:12:29.080 --> 00:12:30.620]   And we hope that will do much better
[00:12:30.620 --> 00:12:34.060]   than just having labeling functions that are binary.
[00:12:34.060 --> 00:12:38.860]   What we did once we had the snorkel system built out
[00:12:38.860 --> 00:12:41.860]   was we wanted to see if it's actually easy to use.
[00:12:41.860 --> 00:12:44.580]   Obviously, for people in lab who were spending time building
[00:12:44.580 --> 00:12:47.060]   it, we knew exactly how to write the labeling functions
[00:12:47.060 --> 00:12:49.180]   for the tasks we were looking at.
[00:12:49.180 --> 00:12:51.140]   So what we did was we held this workshop
[00:12:51.140 --> 00:12:54.540]   where we had biomedical scientists come
[00:12:54.540 --> 00:12:57.280]   who had very beginner knowledge of Python.
[00:12:57.280 --> 00:13:00.280]   And they had their own tasks that they wanted to work on.
[00:13:00.280 --> 00:13:04.140]   And we had them hand label data for seven hours one day.
[00:13:04.140 --> 00:13:05.340]   I don't know why they did it.
[00:13:05.340 --> 00:13:06.220]   They were very kind.
[00:13:06.220 --> 00:13:08.100]   We gave them food.
[00:13:08.100 --> 00:13:11.260]   And then the second day, the next seven hours,
[00:13:11.260 --> 00:13:13.780]   we spent teaching them how to use snorkel,
[00:13:13.780 --> 00:13:16.360]   how to write labeling functions for their task.
[00:13:16.360 --> 00:13:19.020]   And then they spent some time writing their labeling
[00:13:19.020 --> 00:13:21.540]   functions, iterating them, editing them,
[00:13:21.540 --> 00:13:22.880]   collaborating on them.
[00:13:22.880 --> 00:13:26.420]   And what we found was that given the same amount of time,
[00:13:26.420 --> 00:13:29.340]   writing labeling functions and training an N model
[00:13:29.340 --> 00:13:33.300]   does almost 25 points better in terms of model performance
[00:13:33.300 --> 00:13:35.060]   than hand labeling data.
[00:13:35.060 --> 00:13:37.740]   And the main reason for this is the scale
[00:13:37.740 --> 00:13:39.340]   that we can label data in.
[00:13:39.340 --> 00:13:41.220]   You can write five labeling functions
[00:13:41.220 --> 00:13:43.700]   and apply it to 100,000 data points.
[00:13:43.700 --> 00:13:45.660]   But you can spend hours and hours
[00:13:45.660 --> 00:13:48.260]   having to manually hand label those data points.
[00:13:48.260 --> 00:13:49.700]   So even though the training labels
[00:13:49.700 --> 00:13:52.400]   that you get out of this system are fairly noisy,
[00:13:52.400 --> 00:13:55.300]   it's the scale that makes it work so well at the end.
[00:13:55.300 --> 00:13:58.540]   Yeah?
[00:13:58.540 --> 00:14:00.260]   Oh, so you said 25% better.
[00:14:00.260 --> 00:14:01.140]   Like, in what metric?
[00:14:01.140 --> 00:14:01.640]   Oh, yeah.
[00:14:01.640 --> 00:14:04.980]   So this was an F1 score of the N model.
[00:14:04.980 --> 00:14:07.140]   Is the dotted line the baseline?
[00:14:07.140 --> 00:14:08.780]   The dotted line is the baseline, yeah.
[00:14:08.780 --> 00:14:11.740]   Is that like a random baseline or a rule-based--
[00:14:11.740 --> 00:14:15.300]   So that baseline was we labeled a small amount of data
[00:14:15.300 --> 00:14:17.720]   that when people are writing their labeling functions,
[00:14:17.720 --> 00:14:20.660]   they kind of want to know, is this logical or not?
[00:14:20.660 --> 00:14:25.300]   So they labeled around, I think, 100 data points or 50 data
[00:14:25.300 --> 00:14:26.380]   points.
[00:14:26.380 --> 00:14:28.720]   And then they were just testing their labeling functions
[00:14:28.720 --> 00:14:29.220]   with it.
[00:14:29.220 --> 00:14:31.340]   So that baseline sort of represents,
[00:14:31.340 --> 00:14:34.140]   if we only had that very, very small amount of labeled data,
[00:14:34.140 --> 00:14:35.700]   how would we do?
[00:14:35.700 --> 00:14:39.740]   And then you have a baseline of how the rules themselves
[00:14:39.740 --> 00:14:40.740]   perform?
[00:14:40.740 --> 00:14:41.980]   Yeah, I don't have it here.
[00:14:41.980 --> 00:14:44.260]   But I think I might have it in one of my extra slides
[00:14:44.260 --> 00:14:45.860]   that I can show towards the end.
[00:14:45.860 --> 00:14:48.940]   But in general, there were-- for text examples,
[00:14:48.940 --> 00:14:52.540]   we usually have 15, 16 rules.
[00:14:52.540 --> 00:14:54.420]   If we just learn their accuracies,
[00:14:54.420 --> 00:14:57.020]   combine them, assign probabilistic labels,
[00:14:57.020 --> 00:15:00.740]   we see that the F1 score is around 30-something.
[00:15:00.740 --> 00:15:04.260]   And then because we train an LSTM model at the end,
[00:15:04.260 --> 00:15:07.020]   we're able to generalize and get that 48 F1 score
[00:15:07.020 --> 00:15:07.860]   that we have up here.
[00:15:07.860 --> 00:15:13.060]   So another thing that we did once we kind of went
[00:15:13.060 --> 00:15:16.340]   through this process of writing labeling functions in Python
[00:15:16.340 --> 00:15:19.860]   is we wanted to make it kind of more widely applicable.
[00:15:19.860 --> 00:15:22.140]   Not everyone might know how to write Python.
[00:15:22.140 --> 00:15:24.700]   They might not know how to iterate in that context.
[00:15:24.700 --> 00:15:26.140]   So we wanted to make this process
[00:15:26.140 --> 00:15:29.100]   of writing labeling functions and encoding domain knowledge
[00:15:29.100 --> 00:15:30.660]   much easier.
[00:15:30.660 --> 00:15:32.620]   So we made this beautiful pyramid,
[00:15:32.620 --> 00:15:36.040]   which we were trying to say people had machine language
[00:15:36.040 --> 00:15:38.740]   before, which is kind of like manually labeling data.
[00:15:38.740 --> 00:15:41.940]   It's kind of painful to go through individual data points
[00:15:41.940 --> 00:15:43.300]   and label them by hand.
[00:15:43.300 --> 00:15:45.540]   But now they kind of went up the stack.
[00:15:45.540 --> 00:15:47.380]   And now we have declarative interfaces.
[00:15:47.380 --> 00:15:48.820]   We have applications.
[00:15:48.820 --> 00:15:51.420]   So we kind of wanted to do the same with this idea of being
[00:15:51.420 --> 00:15:52.580]   able to label data.
[00:15:52.580 --> 00:15:54.980]   So instead of manually labeling them,
[00:15:54.980 --> 00:15:57.900]   we now have a way of programmatically labeling them.
[00:15:57.900 --> 00:15:59.840]   Maybe we can do something like label them
[00:15:59.840 --> 00:16:01.340]   using natural language.
[00:16:01.340 --> 00:16:04.580]   Or at the end, do some sort of semi-supervised structure
[00:16:04.580 --> 00:16:08.700]   to be able to create them automatically.
[00:16:08.700 --> 00:16:11.220]   So I think this is one of my favorite projects in lab,
[00:16:11.220 --> 00:16:15.180]   which is using natural language to label data automatically.
[00:16:15.180 --> 00:16:17.220]   So two reasons this is my favorite.
[00:16:17.220 --> 00:16:21.220]   One, we used this project and we collected explanations
[00:16:21.220 --> 00:16:23.300]   from Amazon Mechanical Turk.
[00:16:23.300 --> 00:16:24.860]   And it was a really easy comparison
[00:16:24.860 --> 00:16:27.180]   because that's kind of what people tend to do when they
[00:16:27.180 --> 00:16:28.780]   want to collect training data.
[00:16:28.780 --> 00:16:30.780]   And our thought process was whenever
[00:16:30.780 --> 00:16:34.220]   people are labeling data on a platform like this,
[00:16:34.220 --> 00:16:36.380]   they have some reason in their head
[00:16:36.380 --> 00:16:39.340]   for why they're assigning a label of, say, true versus
[00:16:39.340 --> 00:16:40.260]   false.
[00:16:40.260 --> 00:16:42.740]   And if we could only capture that reasoning in their head
[00:16:42.740 --> 00:16:46.100]   in some form, we could have so much extra information
[00:16:46.100 --> 00:16:49.940]   that can help us label data much faster and more efficiently.
[00:16:49.940 --> 00:16:53.060]   So what we did this time, instead of just asking people
[00:16:53.060 --> 00:16:55.220]   to hand label data, we also asked
[00:16:55.220 --> 00:16:57.780]   them to tell us a reason why they assigned a particular
[00:16:57.780 --> 00:16:58.380]   label.
[00:16:58.380 --> 00:17:03.060]   Say, going back to this chemical and disease relation task,
[00:17:03.060 --> 00:17:04.860]   when they said, OK, this is true,
[00:17:04.860 --> 00:17:07.120]   they said, the reason I think this is true
[00:17:07.120 --> 00:17:09.980]   is because I saw the word "because" in the sentence.
[00:17:09.980 --> 00:17:11.780]   Or the reason I think this is true
[00:17:11.780 --> 00:17:15.140]   is because the word "due to" was in the sentence.
[00:17:15.140 --> 00:17:17.300]   And there were a collection of these reasons
[00:17:17.300 --> 00:17:19.300]   that we collected.
[00:17:19.300 --> 00:17:23.060]   What we saw was that with just 30 of these explanations,
[00:17:23.060 --> 00:17:26.220]   we were able to label training data that was so good that it
[00:17:26.220 --> 00:17:29.220]   matched the performance of a machine learning model trained
[00:17:29.220 --> 00:17:31.580]   on 600 hand-labeled examples.
[00:17:31.580 --> 00:17:33.620]   That's not saying much because saying,
[00:17:33.620 --> 00:17:35.740]   oh, we have 600 hand-labeled examples
[00:17:35.740 --> 00:17:37.060]   doesn't sound that great.
[00:17:37.060 --> 00:17:38.440]   But it's just about the scale.
[00:17:38.440 --> 00:17:41.540]   We were able to reduce it by a 5x factor.
[00:17:41.540 --> 00:17:43.780]   In terms of time, we were able to reduce it
[00:17:43.780 --> 00:17:46.220]   by around a 2.5x factor.
[00:17:46.220 --> 00:17:48.220]   And that's because it does take a little longer
[00:17:48.220 --> 00:17:50.580]   to type out the reasoning that you have than just
[00:17:50.580 --> 00:17:54.860]   to label individual data points one by one.
[00:17:54.860 --> 00:17:56.580]   Another thing that we were excited about
[00:17:56.580 --> 00:17:59.180]   was moving away from the text case
[00:17:59.180 --> 00:18:01.900]   to cases where you have numerical data
[00:18:01.900 --> 00:18:04.260]   or where you're writing these heuristics that
[00:18:04.260 --> 00:18:05.620]   are threshold-based.
[00:18:05.620 --> 00:18:07.900]   And that, what we saw, was that it
[00:18:07.900 --> 00:18:10.380]   required a lot of guess and check work.
[00:18:10.380 --> 00:18:11.980]   And it could become painful.
[00:18:11.980 --> 00:18:14.980]   Say we had this example of, is the person riding a bike
[00:18:14.980 --> 00:18:15.660]   or not?
[00:18:15.660 --> 00:18:17.980]   We could say, is the person above the bike?
[00:18:17.980 --> 00:18:19.820]   We can say, is the person bounding blocks
[00:18:19.820 --> 00:18:22.860]   two pixels above the bike, four pixels above the bike?
[00:18:22.860 --> 00:18:24.740]   And then now you've made the process
[00:18:24.740 --> 00:18:27.580]   of writing labeling functions almost as cumbersome
[00:18:27.580 --> 00:18:30.300]   as individually labeling those data points.
[00:18:30.300 --> 00:18:33.540]   So what we did was we tried taking a semi-supervised
[00:18:33.540 --> 00:18:37.060]   learning approach where we use a small amount of labeled data,
[00:18:37.060 --> 00:18:40.500]   so say, 50 labeled data points or 100 labeled data points,
[00:18:40.500 --> 00:18:44.020]   and a large amount of unlabeled data, around 100,000.
[00:18:44.020 --> 00:18:46.980]   And we were able to kind of automatically learn
[00:18:46.980 --> 00:18:48.780]   these labeling function templates
[00:18:48.780 --> 00:18:51.260]   with certain thresholds pre-filled.
[00:18:51.260 --> 00:18:52.420]   We gave it to the user.
[00:18:52.420 --> 00:18:53.860]   And they could sometimes adjust it
[00:18:53.860 --> 00:18:55.460]   based on their domain knowledge.
[00:18:55.460 --> 00:18:57.540]   Sometimes they just kind of took it out of the box
[00:18:57.540 --> 00:19:00.780]   and fed it into the snorkel system to see how it does.
[00:19:00.780 --> 00:19:07.300]   And what we saw was that for numerical-based processes,
[00:19:07.300 --> 00:19:08.660]   this system worked really well.
[00:19:08.660 --> 00:19:13.340]   It usually beat the hand-tuned rules by almost 10 F1 points.
[00:19:13.340 --> 00:19:16.340]   Where it didn't do well is for text.
[00:19:16.340 --> 00:19:19.020]   Because in text, when people write labeling functions,
[00:19:19.020 --> 00:19:20.780]   they kind of write regexed rules.
[00:19:20.780 --> 00:19:22.740]   They look for common phrases.
[00:19:22.740 --> 00:19:24.740]   They know maybe the word like "at"
[00:19:24.740 --> 00:19:27.020]   needs to be at the beginning and "because of"
[00:19:27.020 --> 00:19:28.460]   needs to be at the end.
[00:19:28.460 --> 00:19:30.260]   But we weren't able to generate templates
[00:19:30.260 --> 00:19:31.260]   that were so complex.
[00:19:31.260 --> 00:19:32.900]   So that's kind of still something
[00:19:32.900 --> 00:19:33.900]   that we're working on.
[00:19:33.900 --> 00:19:36.260]   And hopefully, while we're trying
[00:19:36.260 --> 00:19:37.680]   to build templates for text, people
[00:19:37.680 --> 00:19:39.620]   can just use the natural language interface
[00:19:39.620 --> 00:19:42.540]   instead to label the data.
[00:19:42.540 --> 00:19:44.660]   So I'm at the end of my talk.
[00:19:44.660 --> 00:19:48.380]   So the three things we kind of believe in moving forward
[00:19:48.380 --> 00:19:51.740]   with research is that we kind of see supervision as an interface
[00:19:51.740 --> 00:19:53.220]   to be able to label data.
[00:19:53.220 --> 00:19:55.180]   And we want to move to higher and higher levels
[00:19:55.180 --> 00:19:57.940]   of supervision so that labeling training data becomes
[00:19:57.940 --> 00:20:00.380]   much easier and much more efficient.
[00:20:00.380 --> 00:20:03.580]   We believe that our technology of being
[00:20:03.580 --> 00:20:05.740]   able to model the noise and the correlation
[00:20:05.740 --> 00:20:07.820]   in these different sources of labels
[00:20:07.820 --> 00:20:10.100]   is what really helps us scale and get the numbers
[00:20:10.100 --> 00:20:12.780]   that we're getting.
[00:20:12.780 --> 00:20:14.380]   Other things that are going on in lab
[00:20:14.380 --> 00:20:17.500]   are related to kind of making machine learning easier.
[00:20:17.500 --> 00:20:21.480]   So we look at efficient model training, low memory training,
[00:20:21.480 --> 00:20:22.980]   different sorts of embeddings that
[00:20:22.980 --> 00:20:24.780]   are more stable and accurate.
[00:20:24.780 --> 00:20:26.340]   So if you have questions about that,
[00:20:26.340 --> 00:20:28.860]   I can talk a little bit about those as well.
[00:20:28.860 --> 00:20:31.260]   I just won't know that much about it.
[00:20:31.260 --> 00:20:32.460]   Thank you.
[00:20:32.460 --> 00:20:35.900]   [APPLAUSE]
[00:20:35.900 --> 00:20:42.200]   Yeah.
[00:20:42.200 --> 00:20:42.700]   [INAUDIBLE]
[00:20:42.700 --> 00:20:44.180]   --more about modeling of the noise?
[00:20:44.180 --> 00:20:44.680]   Sorry?
[00:20:44.680 --> 00:20:45.180]   [INAUDIBLE]
[00:20:45.180 --> 00:20:46.900]   --second bullet, modeling noise?
[00:20:46.900 --> 00:20:48.220]   Yeah, so modeling noise.
[00:20:48.220 --> 00:20:52.220]   Actually, I'll show the slide I was talking about,
[00:20:52.220 --> 00:20:54.740]   which kind of goes through the math of how we actually
[00:20:54.740 --> 00:20:56.260]   learn these accuracies.
[00:20:56.260 --> 00:20:58.260]   So when we're modeling noise, all we mean
[00:20:58.260 --> 00:21:00.020]   is we are able to kind of capture
[00:21:00.020 --> 00:21:02.300]   how accurate these labeling functions are
[00:21:02.300 --> 00:21:05.260]   and how correlated these labeling functions are.
[00:21:05.260 --> 00:21:07.180]   So let's just start with accuracy.
[00:21:07.180 --> 00:21:10.780]   So what we do is we build a covariance matrix
[00:21:10.780 --> 00:21:12.820]   that's shown over here.
[00:21:12.820 --> 00:21:16.540]   And what we see is that O is these labeling functions
[00:21:16.540 --> 00:21:21.900]   that we have, and S is sort of the ground truth Y label.
[00:21:21.900 --> 00:21:24.980]   So if we can kind of learn this parameter, which
[00:21:24.980 --> 00:21:27.380]   is the covariance between the labeling functions
[00:21:27.380 --> 00:21:29.460]   and the ground truth parameter, we're fine.
[00:21:29.460 --> 00:21:31.860]   That's just going to give us the accuracy out.
[00:21:31.860 --> 00:21:33.980]   The problem is we don't have the ground truth,
[00:21:33.980 --> 00:21:38.740]   so we can't really completely see this variable
[00:21:38.740 --> 00:21:40.460]   that we want to solve for.
[00:21:40.460 --> 00:21:45.420]   So what we do instead is we rely on one little neat trick that
[00:21:45.420 --> 00:21:48.780]   says the inverse covariance matrix of any kind of factor
[00:21:48.780 --> 00:21:51.020]   graph that's graph structured is also
[00:21:51.020 --> 00:21:52.700]   going to be graph structured.
[00:21:52.700 --> 00:21:55.500]   And what that means is that in our factor graph model,
[00:21:55.500 --> 00:21:58.140]   we have our ground truth variable over here,
[00:21:58.140 --> 00:22:01.020]   and we have the labeling functions all correlated
[00:22:01.020 --> 00:22:03.660]   in some manner to this ground truth variable.
[00:22:03.660 --> 00:22:07.220]   So if we take our covariance matrix
[00:22:07.220 --> 00:22:10.740]   and invert it, the entries where there are dependencies,
[00:22:10.740 --> 00:22:13.380]   we're going to have non-zero values.
[00:22:13.380 --> 00:22:15.220]   But we still have a problem.
[00:22:15.220 --> 00:22:17.280]   We have to invert this entire matrix
[00:22:17.280 --> 00:22:18.780]   to be able to see that structure.
[00:22:18.780 --> 00:22:21.500]   And again, we don't have access to that entire matrix
[00:22:21.500 --> 00:22:24.540]   because we don't have access to the ground truth variable.
[00:22:24.540 --> 00:22:28.400]   So what we do instead is we look at this matrix, which
[00:22:28.400 --> 00:22:30.460]   is supposed to be graph structured, which
[00:22:30.460 --> 00:22:35.060]   means this top left corner of it is also graph structured.
[00:22:35.060 --> 00:22:38.940]   Then we use some matrix inversion identities
[00:22:38.940 --> 00:22:42.720]   to be able to represent this variable in terms
[00:22:42.720 --> 00:22:46.980]   of the other variables that are in this matrix over here.
[00:22:46.980 --> 00:22:49.700]   I'll break it down to this simplistic part.
[00:22:49.700 --> 00:22:51.540]   So this is the sparse matrix.
[00:22:51.540 --> 00:22:54.620]   This tells you what correlations we have.
[00:22:54.620 --> 00:22:57.300]   We learned this using a robust PCA approach.
[00:22:57.300 --> 00:23:00.220]   Sometimes it's user defined, so this is known.
[00:23:00.220 --> 00:23:02.900]   This is something that we can observe.
[00:23:02.900 --> 00:23:06.160]   This sigma o over here is just the covariance
[00:23:06.160 --> 00:23:08.100]   of the labeling functions themselves.
[00:23:08.100 --> 00:23:10.660]   So we take the labeling functions, do a cross product,
[00:23:10.660 --> 00:23:12.780]   and we get a matrix that's just the agreements
[00:23:12.780 --> 00:23:15.340]   and disagreements of the labeling functions.
[00:23:15.340 --> 00:23:18.020]   And then this is this low rank matrix
[00:23:18.020 --> 00:23:20.180]   that depends exactly on this variable
[00:23:20.180 --> 00:23:22.820]   that we're trying to get out, which encodes the accuracies
[00:23:22.820 --> 00:23:24.580]   of these labeling functions.
[00:23:24.580 --> 00:23:27.580]   So once we solve this problem using a matrix completion
[00:23:27.580 --> 00:23:29.860]   approach, we can solve for z.
[00:23:29.860 --> 00:23:33.740]   And then because we know exactly what the formulation of z
[00:23:33.740 --> 00:23:37.660]   is compared to this constant c and the sigma o observable
[00:23:37.660 --> 00:23:41.260]   matrix, we can solve for the accuracy parameter.
[00:23:41.260 --> 00:23:46.620]   So we used to solve for this in a Gibbs sampling way,
[00:23:46.620 --> 00:23:49.020]   have the factor graph sample multiple times
[00:23:49.020 --> 00:23:50.380]   to learn the parameters.
[00:23:50.380 --> 00:23:51.340]   It was really slow.
[00:23:51.340 --> 00:23:54.140]   And when we started to move towards applications
[00:23:54.140 --> 00:23:56.460]   with 100,000 data points, it used
[00:23:56.460 --> 00:23:59.780]   to take 10, 15 minutes to run, which was crazy.
[00:23:59.780 --> 00:24:01.420]   So this new approach where we're just
[00:24:01.420 --> 00:24:03.860]   doing a matrix completion thing, which we've implemented
[00:24:03.860 --> 00:24:06.540]   in PyTorch and TensorFlow, that's much faster.
[00:24:06.540 --> 00:24:08.220]   With 100,000 data points, I think
[00:24:08.220 --> 00:24:11.180]   it takes a second, if not less.
[00:24:11.180 --> 00:24:13.620]   So this matrix completion approach
[00:24:13.620 --> 00:24:15.980]   lets us do a lot more a lot faster.
[00:24:15.980 --> 00:24:17.540]   And now we've also looked at how we
[00:24:17.540 --> 00:24:20.060]   can do multitask supervision, how
[00:24:20.060 --> 00:24:22.180]   we can do supervision across video
[00:24:22.180 --> 00:24:26.380]   and other temporally related data types as well.
[00:24:26.380 --> 00:24:30.380]   So the ZZ transpose is a way to pretty much estimate
[00:24:30.380 --> 00:24:33.260]   the covariance of the observed versus the labeling?
[00:24:33.260 --> 00:24:33.900]   Exactly.
[00:24:33.900 --> 00:24:36.420]   ZZ transpose captures the accuracies
[00:24:36.420 --> 00:24:37.580]   of the labeling functions.
[00:24:37.580 --> 00:24:39.500]   Yeah.
[00:24:39.500 --> 00:24:41.420]   Where does the graph structure come from?
[00:24:41.420 --> 00:24:43.220]   Isn't every labeling function potentially
[00:24:43.220 --> 00:24:44.740]   correlated with every other?
[00:24:44.740 --> 00:24:47.140]   Yeah, so the graph structure, which is shown here,
[00:24:47.140 --> 00:24:49.180]   it sort of comes from--
[00:24:49.180 --> 00:24:50.700]   first, the labeling functions all
[00:24:50.700 --> 00:24:55.500]   have to be correlated in some manner to the ground truth
[00:24:55.500 --> 00:24:56.460]   label that we have.
[00:24:56.460 --> 00:24:57.460]   So that's why.
[00:24:57.460 --> 00:24:59.500]   And that's the variable that we can't observe.
[00:24:59.500 --> 00:25:02.980]   So that's essentially a latent variable in our factor graph.
[00:25:02.980 --> 00:25:05.620]   The second thing, in terms of all the labeling functions
[00:25:05.620 --> 00:25:08.180]   being correlated in some way, we're
[00:25:08.180 --> 00:25:11.660]   OK as long as they're not correlated with each other,
[00:25:11.660 --> 00:25:14.380]   kind of conditioned on the ground truth variable.
[00:25:14.380 --> 00:25:18.140]   So obviously, they won't all be independent completely,
[00:25:18.140 --> 00:25:19.660]   because if they were all independent,
[00:25:19.660 --> 00:25:21.180]   they're going to end up being random
[00:25:21.180 --> 00:25:23.020]   and have no signal about the data.
[00:25:23.020 --> 00:25:25.300]   So as long as conditioned on the ground truth variable,
[00:25:25.300 --> 00:25:26.460]   they're independent.
[00:25:26.460 --> 00:25:29.460]   Or we can learn how the dependencies occur.
[00:25:29.460 --> 00:25:31.700]   We can still learn their accuracies.
[00:25:31.700 --> 00:25:34.340]   In the theoretical component of our paper, what we show
[00:25:34.340 --> 00:25:36.980]   is we need to have at least three
[00:25:36.980 --> 00:25:39.900]   kind of conditionally independent labeling
[00:25:39.900 --> 00:25:40.600]   functions.
[00:25:40.600 --> 00:25:43.960]   The rest of them can be correlated in whatever manner.
[00:25:43.960 --> 00:25:46.260]   And we can still learn their accuracies.
[00:25:46.260 --> 00:25:52.140]   OK, so you don't know the sparsity structure in advance.
[00:25:52.140 --> 00:25:54.580]   So there's two ways of going about this.
[00:25:54.580 --> 00:25:56.900]   One is we know the sparsity structure in advance,
[00:25:56.900 --> 00:25:59.780]   because maybe when people wrote their labeling functions,
[00:25:59.780 --> 00:26:01.860]   they said, oh, one looks for the word cause,
[00:26:01.860 --> 00:26:03.420]   one looks for the word not cause.
[00:26:03.420 --> 00:26:05.500]   They're definitely correlated.
[00:26:05.500 --> 00:26:07.620]   Just recently at ICML, we had a paper
[00:26:07.620 --> 00:26:09.980]   on how we can learn this sparsity structure.
[00:26:09.980 --> 00:26:11.740]   And in this case, what happens is
[00:26:11.740 --> 00:26:15.820]   the only thing that's known is this variable over here.
[00:26:15.820 --> 00:26:19.200]   And now we do this decomposition of a matrix
[00:26:19.200 --> 00:26:22.020]   into a sparse component and a low-rank component.
[00:26:22.020 --> 00:26:25.940]   And in terms of implementation, we essentially use CVX pi.
[00:26:25.940 --> 00:26:28.140]   And we have some constraints on the structure
[00:26:28.140 --> 00:26:30.980]   of the sparse matrix as well as the low-rank matrix.
[00:26:30.980 --> 00:26:34.900]   And then we can solve for both simultaneously.
[00:26:34.900 --> 00:26:36.420]   Do you have a GitHub for this?
[00:26:36.420 --> 00:26:36.920]   Yeah.
[00:26:36.920 --> 00:26:42.800]   So all the information is at snorkel.stanford.edu.
[00:26:42.800 --> 00:26:45.480]   That has a link to the GitHub page for the project,
[00:26:45.480 --> 00:26:48.360]   as well as all the papers and some blogs related
[00:26:48.360 --> 00:26:51.080]   to the theoretical work that's gone on in the lab as well.
[00:26:51.080 --> 00:26:55.620]   Yeah?
[00:26:55.620 --> 00:26:56.620]   Can I ask-- OK.
[00:26:56.620 --> 00:26:59.080]   I'm going to ask a question from the perspective of someone
[00:26:59.080 --> 00:27:01.320]   who actually didn't really understand most of the math.
[00:27:01.320 --> 00:27:02.800]   That's totally fine.
[00:27:02.800 --> 00:27:06.560]   That was me three years ago when I joined lab.
[00:27:06.560 --> 00:27:09.080]   Just from what I understand you're saying,
[00:27:09.080 --> 00:27:11.480]   it sounds as though there's some wizardry happening here,
[00:27:11.480 --> 00:27:14.720]   where you put in what feels like a small amount of information,
[00:27:14.720 --> 00:27:16.180]   and then you get out something that
[00:27:16.180 --> 00:27:17.520]   seems like a lot of information.
[00:27:17.520 --> 00:27:20.680]   So I'm wondering how does that intuitively make sense?
[00:27:20.680 --> 00:27:22.920]   If the labeling functions don't capture
[00:27:22.920 --> 00:27:26.760]   all of the information you need to actually make a decision,
[00:27:26.760 --> 00:27:28.120]   other things about--
[00:27:28.120 --> 00:27:29.320]   About the data, right.
[00:27:29.320 --> 00:27:31.960]   About the data that are too complicated to write
[00:27:31.960 --> 00:27:34.880]   as a labeling function.
[00:27:34.880 --> 00:27:37.920]   Does that information come from somewhere?
[00:27:37.920 --> 00:27:41.640]   Does it just cause an upper limit on the score you can get?
[00:27:41.640 --> 00:27:43.280]   Your scores are around 25, 50.
[00:27:43.280 --> 00:27:44.880]   So that seems not too surprising.
[00:27:44.880 --> 00:27:45.380]   Right.
[00:27:45.380 --> 00:27:48.080]   Does that mean that it would be really hard to get up to 80
[00:27:48.080 --> 00:27:50.680]   or 90 because the information isn't in the labeling functions?
[00:27:50.680 --> 00:27:53.800]   So I think the score, that was just for a particular task.
[00:27:53.800 --> 00:27:56.080]   So I'll just throw up this model.
[00:27:56.080 --> 00:27:58.840]   What we saw was that by doing this weak supervision
[00:27:58.840 --> 00:28:02.160]   approach of using labeling functions to assign labels
[00:28:02.160 --> 00:28:05.560]   to training data, we actually got within one point
[00:28:05.560 --> 00:28:08.560]   if we had actually used all the ground truth labels available
[00:28:08.560 --> 00:28:11.000]   to us to train the same model.
[00:28:11.000 --> 00:28:15.040]   So I think the scoring was more specific to the data set
[00:28:15.040 --> 00:28:16.080]   that we were looking at.
[00:28:16.080 --> 00:28:21.160]   We have seen scores up to 95 F1, 98 F1 for certain applications
[00:28:21.160 --> 00:28:21.800]   as well.
[00:28:21.800 --> 00:28:23.700]   The first question that you had, which
[00:28:23.700 --> 00:28:25.880]   was about how does this wizardry work,
[00:28:25.880 --> 00:28:28.860]   I think that is a really good question.
[00:28:28.860 --> 00:28:31.840]   And it has three components to it.
[00:28:31.840 --> 00:28:34.520]   So one, we write multiple labeling functions,
[00:28:34.520 --> 00:28:37.720]   which do capture multiple aspects of the data.
[00:28:37.720 --> 00:28:39.440]   So there is a lot of information that we
[00:28:39.440 --> 00:28:41.800]   are capturing by combining the information
[00:28:41.800 --> 00:28:44.440]   from these different labeling functions.
[00:28:44.440 --> 00:28:47.200]   The second part is that we can model the noise in them.
[00:28:47.200 --> 00:28:49.560]   So we know exactly when to trust one labeling
[00:28:49.560 --> 00:28:51.000]   function over the other.
[00:28:51.000 --> 00:28:53.080]   And I think that gives us a little bit of an edge
[00:28:53.080 --> 00:28:57.000]   versus just trusting all these signals blindly and equally.
[00:28:57.000 --> 00:28:59.400]   The third thing is we only use this approach
[00:28:59.400 --> 00:29:01.040]   to assign training labels.
[00:29:01.040 --> 00:29:02.560]   The question that you asked about,
[00:29:02.560 --> 00:29:05.480]   it's ignoring a lot of the information present in the data
[00:29:05.480 --> 00:29:09.320]   that we leave to these complex deep learning models you have.
[00:29:09.320 --> 00:29:11.440]   So with our labeling functions, we only
[00:29:11.440 --> 00:29:14.080]   generate enough training data, which is definitely
[00:29:14.080 --> 00:29:15.960]   noisy and not very accurate.
[00:29:15.960 --> 00:29:17.840]   But then we allow this deep learning model
[00:29:17.840 --> 00:29:22.120]   to use that noisy labeled information that we have
[00:29:22.120 --> 00:29:24.180]   and generalize using the access it
[00:29:24.180 --> 00:29:27.840]   has to these deep learning features and the sentence
[00:29:27.840 --> 00:29:29.280]   structure and things like that.
[00:29:29.280 --> 00:29:32.080]   And then it's actually able to get that big bump
[00:29:32.080 --> 00:29:33.760]   to be able to match what we would
[00:29:33.760 --> 00:29:35.360]   get with ground truth labels.
[00:29:35.360 --> 00:29:37.480]   So yeah, just using the labeling functions
[00:29:37.480 --> 00:29:38.920]   usually doesn't do that great.
[00:29:38.920 --> 00:29:41.000]   That's why you can't use it as a final predictor.
[00:29:41.000 --> 00:29:43.500]   You have to end up training another model with it
[00:29:43.500 --> 00:29:44.800]   at the end.
[00:29:44.800 --> 00:29:46.240]   I really like that question.
[00:29:46.240 --> 00:29:52.160]   Question.
[00:29:52.160 --> 00:29:56.320]   So it sounds a little bit like a learning
[00:29:56.320 --> 00:29:59.040]   problem on the labeling itself.
[00:29:59.040 --> 00:30:02.160]   So the labeling functions are kind of like a weak predictor.
[00:30:02.160 --> 00:30:06.400]   And you're going to want boosting to come up with this.
[00:30:06.400 --> 00:30:08.880]   So in that sense, then, it depends a lot
[00:30:08.880 --> 00:30:12.920]   on your labeling functions and also if your data is balanced
[00:30:12.920 --> 00:30:15.560]   or if the labels are balanced or imbalanced.
[00:30:15.560 --> 00:30:19.200]   So does this approach-- have you tried it
[00:30:19.200 --> 00:30:21.200]   on very heavily imbalanced--
[00:30:21.200 --> 00:30:22.960]   Yeah, so that's a really good point.
[00:30:22.960 --> 00:30:25.000]   And that's something that we recently worked on.
[00:30:25.000 --> 00:30:29.120]   So in the mathematical formulation that I just showed,
[00:30:29.120 --> 00:30:30.920]   we have another more complex one that I
[00:30:30.920 --> 00:30:33.400]   don't have on my slides where we kind of learn
[00:30:33.400 --> 00:30:36.360]   a different accuracy and correlation parameter
[00:30:36.360 --> 00:30:38.520]   conditioned on the true variable.
[00:30:38.520 --> 00:30:41.000]   So then if you have class imbalanced data sets,
[00:30:41.000 --> 00:30:43.520]   we can actually handle learning and accuracy
[00:30:43.520 --> 00:30:46.200]   depending on if it's like the majority class or the minority
[00:30:46.200 --> 00:30:46.920]   class.
[00:30:46.920 --> 00:30:49.800]   And one of the most imbalanced data sets that we've worked on
[00:30:49.800 --> 00:30:51.800]   is it's currently in a Nature paper
[00:30:51.800 --> 00:30:56.920]   where we had only 1% positives and 99% negatives.
[00:30:56.920 --> 00:30:59.080]   So we were able to apply six labeling
[00:30:59.080 --> 00:31:00.360]   functions in that case.
[00:31:00.360 --> 00:31:01.960]   And we got really good scores.
[00:31:01.960 --> 00:31:06.200]   I think that's another one where we got 80 or 90 F1 score
[00:31:06.200 --> 00:31:08.840]   versus like before, given the amount of label data
[00:31:08.840 --> 00:31:12.640]   that they had, they were getting 20.
[00:31:12.640 --> 00:31:14.760]   You mentioned that you have confidence
[00:31:14.760 --> 00:31:17.040]   for each labeling function and accuracy
[00:31:17.040 --> 00:31:20.160]   for the overall labeling logic.
[00:31:20.160 --> 00:31:22.640]   When you usually use a supervised learning model,
[00:31:22.640 --> 00:31:24.120]   you have labels.
[00:31:24.120 --> 00:31:24.620]   Right.
[00:31:24.620 --> 00:31:26.400]   This label or that label or that label.
[00:31:26.400 --> 00:31:27.080]   Yeah.
[00:31:27.080 --> 00:31:30.680]   How do you encode this confidence in the model
[00:31:30.680 --> 00:31:31.320]   itself?
[00:31:31.320 --> 00:31:33.720]   So in a binary case, instead of just passing
[00:31:33.720 --> 00:31:37.320]   in a hard label of 1, negative 1, we instead pass in an array.
[00:31:37.320 --> 00:31:39.200]   So it gives you the confidence that it
[00:31:39.200 --> 00:31:41.200]   belongs to class 1 and a confidence
[00:31:41.200 --> 00:31:42.760]   that it belongs to class 2.
[00:31:42.760 --> 00:31:44.920]   So we do have to change the input layer a little bit
[00:31:44.920 --> 00:31:46.880]   so that it can accept an array.
[00:31:46.880 --> 00:31:48.920]   And then in terms of the loss, we usually
[00:31:48.920 --> 00:31:51.960]   use BCE with logits or a cross-entropy loss, which
[00:31:51.960 --> 00:31:54.480]   can accept probabilistic labels.
[00:31:54.480 --> 00:31:56.120]   Exactly.
[00:31:56.120 --> 00:31:57.360]   One more question.
[00:31:57.360 --> 00:31:58.520]   Yeah, so I was just--
[00:31:58.520 --> 00:32:00.440]   correct me if I'm wrong, but I want
[00:32:00.440 --> 00:32:04.280]   to understand this process coming from somebody who don't
[00:32:04.280 --> 00:32:08.200]   necessarily have enough training data to use
[00:32:08.200 --> 00:32:12.120]   Snorkel to complete their project.
[00:32:12.120 --> 00:32:15.480]   So it sounds like what you need is you would still
[00:32:15.480 --> 00:32:17.680]   need labelers to label some of the data.
[00:32:17.680 --> 00:32:22.600]   And they provide-- in one of your high level,
[00:32:22.600 --> 00:32:27.040]   we're extracting rule-based labeling function
[00:32:27.040 --> 00:32:28.680]   from their sentences.
[00:32:28.680 --> 00:32:34.760]   And then from there, we build a rule-based model
[00:32:34.760 --> 00:32:36.920]   that's encoding the labeling function.
[00:32:36.920 --> 00:32:42.400]   And then from there, it generates data from the model.
[00:32:42.400 --> 00:32:44.960]   And that's how you get labels.
[00:32:44.960 --> 00:32:48.360]   And then you can then pipe it into the actual training.
[00:32:48.360 --> 00:32:48.880]   Right.
[00:32:48.880 --> 00:32:51.480]   So I think with the example that I showed,
[00:32:51.480 --> 00:32:53.480]   where you have a natural language explanation
[00:32:53.480 --> 00:32:55.520]   that someone actually writes and we convert it
[00:32:55.520 --> 00:32:58.240]   to labeling functions, so that you don't necessarily
[00:32:58.240 --> 00:32:59.680]   have to go down that route.
[00:32:59.680 --> 00:33:01.600]   You can just start writing labeling functions
[00:33:01.600 --> 00:33:03.160]   from scratch, in which case you don't
[00:33:03.160 --> 00:33:06.200]   have to collect any kind of labeled data
[00:33:06.200 --> 00:33:07.320]   from the beginning.
[00:33:07.320 --> 00:33:10.040]   You do need to have access to unlabeled data, though.
[00:33:10.040 --> 00:33:12.800]   Because say, if you don't have--
[00:33:12.800 --> 00:33:14.320]   you write your labeling functions,
[00:33:14.320 --> 00:33:17.200]   you have to apply it to some set of data points, which you then
[00:33:17.200 --> 00:33:19.000]   will use to train your end model.
[00:33:19.000 --> 00:33:21.040]   So sometimes we've seen applications
[00:33:21.040 --> 00:33:24.400]   where there's only maybe 100 unlabeled data points.
[00:33:24.400 --> 00:33:26.600]   So there's not even enough unlabeled data.
[00:33:26.600 --> 00:33:29.600]   We have another project that's on that snorkel.stanford.edu
[00:33:29.600 --> 00:33:33.040]   page, which uses a very similar labeling function-based
[00:33:33.040 --> 00:33:35.080]   approach to augment the data set.
[00:33:35.080 --> 00:33:37.400]   So then you can combine these two approaches,
[00:33:37.400 --> 00:33:40.560]   if you don't have enough data, to first augment your data set
[00:33:40.560 --> 00:33:42.840]   and then assign noisy labels to it
[00:33:42.840 --> 00:33:44.440]   to then do the training process.
[00:33:44.440 --> 00:33:50.360]   [INAUDIBLE]
[00:33:50.360 --> 00:33:53.560]   Some of them have taken this, like,
[00:33:53.560 --> 00:33:56.000]   if person and size and then--
[00:33:56.000 --> 00:33:58.760]   so I would imagine that coming up
[00:33:58.760 --> 00:34:03.080]   with the notion of person would be [INAUDIBLE] itself.
[00:34:03.080 --> 00:34:06.800]   How does that is handled in function execution?
[00:34:06.800 --> 00:34:08.400]   Yeah, that's a really good question.
[00:34:08.400 --> 00:34:10.520]   So the question is, if you have something like,
[00:34:10.520 --> 00:34:13.200]   you know, there's a person in the picture, then do this.
[00:34:13.200 --> 00:34:15.320]   But whether the person is in the picture or not
[00:34:15.320 --> 00:34:17.320]   is also going to be noisy, because it's coming
[00:34:17.320 --> 00:34:19.320]   from another deep learning model.
[00:34:19.320 --> 00:34:23.480]   So in our image-based algorithm that does weak supervision,
[00:34:23.480 --> 00:34:26.960]   we actually learn not only the accuracy of the labeling
[00:34:26.960 --> 00:34:30.480]   functions, we also learn how accurate these inputs
[00:34:30.480 --> 00:34:32.240]   that the labeling function takes.
[00:34:32.240 --> 00:34:34.640]   We call them primitives, how accurate they are.
[00:34:34.640 --> 00:34:37.720]   So we have some notion of accuracy on two scales.
[00:34:37.720 --> 00:34:40.280]   One, like, how accurate is your object detector?
[00:34:40.280 --> 00:34:41.680]   And because of that, how accurate
[00:34:41.680 --> 00:34:43.280]   is your labeling function going to be?
[00:34:43.280 --> 00:34:47.240]   So we can model noise at both those levels.
[00:34:47.240 --> 00:34:47.740]   Yeah?
[00:34:47.740 --> 00:34:52.480]   What's going on with the whole human data set?
[00:34:52.480 --> 00:34:54.000]   Ah, yes.
[00:34:54.000 --> 00:34:55.920]   It was the, you know, put this in the paper
[00:34:55.920 --> 00:34:58.400]   and then everyone's going to notice it.
[00:34:58.400 --> 00:35:01.600]   So what's happening here is all these lines
[00:35:01.600 --> 00:35:04.160]   are essentially using weak supervision.
[00:35:04.160 --> 00:35:07.800]   And we were able to label twice as much data
[00:35:07.800 --> 00:35:10.800]   using weak supervision as we had ground truth labels for.
[00:35:10.800 --> 00:35:13.440]   So we're just saying that if you have labeling functions,
[00:35:13.440 --> 00:35:15.720]   you can label twice as much data noisily,
[00:35:15.720 --> 00:35:18.160]   but even that helps improve your end model score.
[00:35:18.160 --> 00:35:23.960]   Would you trust labeling functions
[00:35:23.960 --> 00:35:25.760]   for medical applications?
[00:35:25.760 --> 00:35:27.680]   Yes, so that was a big question when
[00:35:27.680 --> 00:35:29.800]   we were getting reviews for this Nature paper
[00:35:29.800 --> 00:35:31.680]   I was talking about with the class imbalance,
[00:35:31.680 --> 00:35:37.000]   because it was to assign labels to these really
[00:35:37.000 --> 00:35:39.600]   rare heart malformations in children.
[00:35:39.600 --> 00:35:41.720]   So it's a big question of whether we would trust
[00:35:41.720 --> 00:35:43.600]   the labeling functions or not.
[00:35:43.600 --> 00:35:46.920]   I think compared to just general deep learning,
[00:35:46.920 --> 00:35:49.840]   when there are a lot of questions about interpretability
[00:35:49.840 --> 00:35:52.600]   and trust, in this case, there's actually
[00:35:52.600 --> 00:35:55.640]   some way of mapping back to where you got the label from.
[00:35:55.640 --> 00:35:57.960]   Because when you look at a label assigned by a labeling
[00:35:57.960 --> 00:36:01.480]   function, you know exactly why it got assigned that label.
[00:36:01.480 --> 00:36:04.520]   Because it says, oh, it's 50% because of this rule,
[00:36:04.520 --> 00:36:08.080]   80% because of this rule, and 30% because of this rule.
[00:36:08.080 --> 00:36:10.680]   So you can map back your errors to exactly where
[00:36:10.680 --> 00:36:12.080]   it's coming from.
[00:36:12.080 --> 00:36:14.640]   Another thing, we never use these labels directly
[00:36:14.640 --> 00:36:16.080]   to assign predictions.
[00:36:16.080 --> 00:36:20.080]   We always train an end machine learning model with it.
[00:36:20.080 --> 00:36:23.480]   But if there's some sense of auditability that we want,
[00:36:23.480 --> 00:36:25.480]   we can look back at the labeling functions.
[00:36:25.480 --> 00:36:27.760]   But I think it still has the same issues
[00:36:27.760 --> 00:36:31.320]   that deep learning is facing today of how interpretable is
[00:36:31.320 --> 00:36:32.880]   it and how much should I trust it.
[00:36:33.880 --> 00:36:34.880]   Yeah?
[00:36:34.880 --> 00:36:38.120]   I have a follow-up question about the labeling function.
[00:36:38.120 --> 00:36:41.120]   So using this snorkel, then general strategy,
[00:36:41.120 --> 00:36:44.200]   which one would be more beneficial to have
[00:36:44.200 --> 00:36:46.800]   a lot of very simple label learners,
[00:36:46.800 --> 00:36:49.760]   like very almost linear kind of thing,
[00:36:49.760 --> 00:36:54.520]   versus a few of very complex and more layered
[00:36:54.520 --> 00:36:56.800]   labeled functions?
[00:36:56.800 --> 00:36:57.760]   That's a good question.
[00:36:57.760 --> 00:37:01.120]   So do we want to have a bunch of really simple rules,
[00:37:01.120 --> 00:37:03.920]   or do we want to have a few very complex rules?
[00:37:03.920 --> 00:37:06.280]   Theoretically, my answer is just put them all in,
[00:37:06.280 --> 00:37:08.960]   because it can model the accuracies of all of them.
[00:37:08.960 --> 00:37:12.160]   So it'll know exactly when to trust one versus the other.
[00:37:12.160 --> 00:37:14.880]   In practice, you do kind of have to see--
[00:37:14.880 --> 00:37:17.200]   you have to play around with it a little bit.
[00:37:17.200 --> 00:37:20.000]   I haven't seen a big difference between using
[00:37:20.000 --> 00:37:21.120]   a few complex ones.
[00:37:21.120 --> 00:37:24.760]   Like for images, we usually just use four or five, and then
[00:37:24.760 --> 00:37:28.200]   many simple ones, because in text, we use up to 20 or 30.
[00:37:28.200 --> 00:37:30.120]   So we've seen kind of both extremes,
[00:37:30.120 --> 00:37:31.680]   and it's very application dependent
[00:37:31.680 --> 00:37:33.520]   on which set of labeling functions
[00:37:33.520 --> 00:37:35.040]   would work better for you.
[00:37:35.040 --> 00:37:37.480]   Theoretically, all of them.
[00:37:37.480 --> 00:37:37.980]   Yeah.
[00:37:37.980 --> 00:37:40.560]   So just picking up on that, if there
[00:37:40.560 --> 00:37:45.240]   are some bad labeling functions in there,
[00:37:45.240 --> 00:37:48.240]   would it be better just to get rid of them,
[00:37:48.240 --> 00:37:50.680]   rather than putting them all in?
[00:37:50.680 --> 00:37:52.480]   So what we've seen is that usually,
[00:37:52.480 --> 00:37:54.200]   if people write a labeling function
[00:37:54.200 --> 00:37:56.760]   and they have it in there, it's good for something.
[00:37:56.760 --> 00:37:59.440]   Like it might be good for a small subset of the data,
[00:37:59.440 --> 00:38:01.600]   but it's going to have some signal in it.
[00:38:01.600 --> 00:38:04.400]   So we usually tell people not to throw away anything
[00:38:04.400 --> 00:38:06.520]   that they've written, unless it's labeling
[00:38:06.520 --> 00:38:08.160]   the same thing as another one.
[00:38:08.160 --> 00:38:10.320]   But if it has any useful information,
[00:38:10.320 --> 00:38:14.880]   we are usually able to model that, OK, overall, it's
[00:38:14.880 --> 00:38:18.000]   only like 50% or 51% accurate.
[00:38:18.000 --> 00:38:20.400]   But on this specific subset of the data,
[00:38:20.400 --> 00:38:22.240]   it's actually 80% accurate.
[00:38:22.240 --> 00:38:25.800]   So only trust it when it belongs to this specific subset
[00:38:25.800 --> 00:38:26.680]   of the data.
[00:38:26.680 --> 00:38:29.080]   So that's another layer of learning we can do.
[00:38:29.080 --> 00:38:32.640]   So usually, we tell people don't throw them away,
[00:38:32.640 --> 00:38:37.560]   if we are able to model these fine-grained accuracies.
[00:38:37.560 --> 00:38:40.680]   If we can't, then you can always just remove a row
[00:38:40.680 --> 00:38:42.840]   from this matrix you have, run the model again,
[00:38:42.840 --> 00:38:44.480]   and you're like, oh, it's doing better.
[00:38:44.480 --> 00:38:46.240]   So I'll remove it.
[00:38:46.240 --> 00:38:48.360]   I'll come back to you one more question here.
[00:38:48.360 --> 00:38:51.160]   So what's the process of iterating the development
[00:38:51.160 --> 00:38:52.480]   of your labeling functions like?
[00:38:52.480 --> 00:38:54.160]   If you run a glance with some functions,
[00:38:54.160 --> 00:38:55.480]   you get some results.
[00:38:55.480 --> 00:38:56.600]   Does that tell you something about how
[00:38:56.600 --> 00:38:57.880]   you might want to change labeling functions
[00:38:57.880 --> 00:38:58.720]   and try again?
[00:38:58.720 --> 00:39:01.320]   Yeah, so we do have some really simple tools built
[00:39:01.320 --> 00:39:03.800]   into the code base right now, which
[00:39:03.800 --> 00:39:06.000]   tell you what the overlaps and conflicts
[00:39:06.000 --> 00:39:07.840]   between the different labeling functions are.
[00:39:07.840 --> 00:39:09.200]   So that can help sometimes.
[00:39:09.200 --> 00:39:12.160]   If you see you have one labeling function that never disagrees
[00:39:12.160 --> 00:39:15.200]   with anything else, that's not adding too much to it.
[00:39:15.200 --> 00:39:16.680]   Like, you want to model it in a way
[00:39:16.680 --> 00:39:19.480]   that it actually disagrees with some of them.
[00:39:19.480 --> 00:39:23.560]   In terms of iterating, the model takes a few seconds to run.
[00:39:23.560 --> 00:39:25.520]   So it's not a slow process.
[00:39:25.520 --> 00:39:28.360]   You don't have to wait or watch any gradients
[00:39:28.360 --> 00:39:30.480]   go up and down.
[00:39:30.480 --> 00:39:32.720]   But we've seen that depending on the application,
[00:39:32.720 --> 00:39:36.600]   it can take somewhere from one hour, which was this case,
[00:39:36.600 --> 00:39:39.800]   because we had images, to a few days for some of the text
[00:39:39.800 --> 00:39:41.200]   applications.
[00:39:41.200 --> 00:39:44.880]   And after that result happens, is there a way to go back
[00:39:44.880 --> 00:39:46.840]   and say, OK, now I want to improve my labeling functions
[00:39:46.840 --> 00:39:47.800]   to get a better result?
[00:39:47.800 --> 00:39:49.200]   Yeah, you can definitely do that.
[00:39:49.200 --> 00:39:51.400]   How would you know what to do?
[00:39:51.400 --> 00:39:54.280]   So sometimes what we see is people,
[00:39:54.280 --> 00:39:56.000]   they generate their training labels.
[00:39:56.000 --> 00:39:57.480]   They train their end model.
[00:39:57.480 --> 00:39:59.840]   And then they see that their end model is always
[00:39:59.840 --> 00:40:02.440]   making mistakes in a particular subset of the data.
[00:40:02.440 --> 00:40:04.640]   So then they can go back to their labeling functions
[00:40:04.640 --> 00:40:06.120]   and say, OK, let me write one that's
[00:40:06.120 --> 00:40:07.560]   very specific to this subset.
[00:40:07.560 --> 00:40:12.920]   So just to comment, I'm just wondering,
[00:40:12.920 --> 00:40:15.520]   how is it different than the traditional 1.4 model
[00:40:15.520 --> 00:40:19.280]   of writing an algorithm?
[00:40:19.280 --> 00:40:21.080]   As you go more and more accurate labeling,
[00:40:21.080 --> 00:40:24.280]   you're essentially writing an algorithm to predict.
[00:40:24.280 --> 00:40:29.360]   Second thing is, is the final validation and test set
[00:40:29.360 --> 00:40:32.360]   hand-labeled with the ground truth, or is that also--
[00:40:32.360 --> 00:40:34.520]   So I'll answer the second question first.
[00:40:34.520 --> 00:40:36.280]   The test set is hand-labeled.
[00:40:36.280 --> 00:40:38.280]   So that we would need no matter what
[00:40:38.280 --> 00:40:39.440]   we do with machine learning.
[00:40:39.440 --> 00:40:42.280]   So whatever people have for their specific application,
[00:40:42.280 --> 00:40:43.280]   we use that test set.
[00:40:43.280 --> 00:40:46.680]   And it's definitely labeled by hand.
[00:40:46.680 --> 00:40:50.040]   The first question, which was about the more you iterate
[00:40:50.040 --> 00:40:52.320]   on your labeling functions, the more you're building out
[00:40:52.320 --> 00:40:54.240]   an entire algorithm.
[00:40:54.240 --> 00:40:56.920]   That's why we try and keep these sessions of writing
[00:40:56.920 --> 00:41:00.480]   the labeling functions to maximum a few days.
[00:41:00.480 --> 00:41:04.240]   So that'll be like total of like six hours of one person
[00:41:04.240 --> 00:41:05.760]   writing them and iterating on them.
[00:41:05.760 --> 00:41:07.360]   And they usually don't touch it again
[00:41:07.360 --> 00:41:09.600]   unless their data distribution changes.
[00:41:09.600 --> 00:41:12.200]   And sometimes we do get away with just sitting together
[00:41:12.200 --> 00:41:13.920]   and writing for an hour.
[00:41:13.920 --> 00:41:16.560]   Because if you try to over-engineer your labeling
[00:41:16.560 --> 00:41:19.400]   functions and they become super accurate,
[00:41:19.400 --> 00:41:21.680]   then maybe you've solved your problem already.
[00:41:21.680 --> 00:41:24.040]   The idea here is that you can't over-engineer them
[00:41:24.040 --> 00:41:26.000]   because you just don't have access to that data.
[00:41:26.000 --> 00:41:28.400]   And it's just not a very logical problem
[00:41:28.400 --> 00:41:30.480]   that you can do this with.
[00:41:30.480 --> 00:41:31.000]   Yes.
[00:41:31.000 --> 00:41:33.960]   So on the example on text, you showed how you can just
[00:41:33.960 --> 00:41:34.720]   use a regex.
[00:41:34.720 --> 00:41:36.560]   And people can say what they're looking for.
[00:41:36.560 --> 00:41:38.000]   You can search in that.
[00:41:38.000 --> 00:41:40.600]   But maybe that same thing doesn't work with images.
[00:41:40.600 --> 00:41:42.840]   It's not that easy to search in images.
[00:41:42.840 --> 00:41:45.120]   And if you have open source model to object detect,
[00:41:45.120 --> 00:41:45.960]   that's great.
[00:41:45.960 --> 00:41:48.400]   But what you're doing is not an open source model.
[00:41:48.400 --> 00:41:51.680]   What are some of the challenges you've faced with image-based
[00:41:51.680 --> 00:41:53.320]   labeling and using snorkels?
[00:41:53.320 --> 00:41:55.720]   Yeah, I think image-based labeling has
[00:41:55.720 --> 00:41:57.080]   been one of the tricky things.
[00:41:57.080 --> 00:41:59.200]   That was my first project when I joined lab,
[00:41:59.200 --> 00:42:01.880]   was actually extending it to image-based work.
[00:42:01.880 --> 00:42:03.920]   When we had these object detectors,
[00:42:03.920 --> 00:42:06.280]   it's really easy because you have bounding boxes you can
[00:42:06.280 --> 00:42:08.400]   write labeling functions over.
[00:42:08.400 --> 00:42:11.320]   For medical applications, it's a little more challenging
[00:42:11.320 --> 00:42:14.040]   because you don't know what to write labeling functions over.
[00:42:14.040 --> 00:42:16.480]   You can't write it over raw pixel values.
[00:42:16.480 --> 00:42:17.560]   That just doesn't work.
[00:42:17.560 --> 00:42:20.600]   So you still need to depend on some other existing
[00:42:20.600 --> 00:42:23.480]   algorithm for that specific data set that you can use,
[00:42:23.480 --> 00:42:26.240]   say, like something that does core segmentation.
[00:42:26.240 --> 00:42:29.040]   Maybe something even that's not a deep learning-based model,
[00:42:29.040 --> 00:42:30.760]   but just from scikit-learn.
[00:42:30.760 --> 00:42:33.120]   It just does a threshold-based operator.
[00:42:33.120 --> 00:42:36.160]   And then once we have something to work with, say,
[00:42:36.160 --> 00:42:39.080]   a binary mask, then we can write labeling functions
[00:42:39.080 --> 00:42:41.040]   over that information.
[00:42:41.040 --> 00:42:43.360]   And those masks themselves are also noisy.
[00:42:43.360 --> 00:42:45.920]   So I think we had this question before about how do we
[00:42:45.920 --> 00:42:47.520]   model that noise as well.
[00:42:47.520 --> 00:42:49.800]   So for image cases, we add another layer
[00:42:49.800 --> 00:42:51.280]   to our factor graph because we need
[00:42:51.280 --> 00:42:52.760]   to model that noise as well.
[00:42:52.760 --> 00:42:56.160]   But images in general are harder to write labeling functions
[00:42:56.160 --> 00:42:58.840]   for as well because there's not a lot of signal
[00:42:58.840 --> 00:43:00.320]   you can call upon.
[00:43:00.320 --> 00:43:02.080]   You always have to stick to--
[00:43:02.080 --> 00:43:02.960]   I'll use the area.
[00:43:02.960 --> 00:43:03.960]   I'll use the perimeter.
[00:43:03.960 --> 00:43:05.360]   I'll use the intensity.
[00:43:05.360 --> 00:43:08.200]   I'll use maybe the ratio of area and perimeter.
[00:43:08.200 --> 00:43:09.040]   But that's it.
[00:43:09.040 --> 00:43:12.800]   After a point, you can't extract as much signal as possible.
[00:43:12.800 --> 00:43:16.200]   We have time for one last question if anyone has one.
[00:43:16.200 --> 00:43:19.640]   [INAUDIBLE]
[00:43:19.640 --> 00:43:21.560]   I noticed that you didn't go too much into it.
[00:43:21.560 --> 00:43:23.280]   But I was curious what you're doing
[00:43:23.280 --> 00:43:26.920]   with the embeddings and making those more or less--
[00:43:26.920 --> 00:43:31.000]   Yeah, so in our lab, we have two pieces of work.
[00:43:31.000 --> 00:43:33.680]   One is around using hyperbolic embeddings
[00:43:33.680 --> 00:43:37.360]   to look at data that has some sort of tree structure.
[00:43:37.360 --> 00:43:39.840]   So right now, we're using it to create parse trees
[00:43:39.840 --> 00:43:42.000]   because we think hyperbolic embeddings are
[00:43:42.000 --> 00:43:44.720]   going to work better than embeddings that are created
[00:43:44.720 --> 00:43:46.240]   in the Euclidean space.
[00:43:46.240 --> 00:43:48.160]   Another project that we have with embeddings
[00:43:48.160 --> 00:43:51.120]   is building a system around them because a lot of times
[00:43:51.120 --> 00:43:53.280]   for text data, we see you have to kind of retrain
[00:43:53.280 --> 00:43:55.280]   your embeddings and recreate them.
[00:43:55.280 --> 00:43:57.400]   And there's a lot of issues around stability.
[00:43:57.400 --> 00:44:00.280]   So we are studying how stable we can make these embeddings
[00:44:00.280 --> 00:44:03.040]   and how we can make the process of retraining more efficient
[00:44:03.040 --> 00:44:04.640]   given we have new data coming in.
[00:44:04.640 --> 00:44:07.040]   How are those challenges coming in the medical space,
[00:44:07.040 --> 00:44:08.040]   do you imagine?
[00:44:08.040 --> 00:44:11.200]   In the medical space, we haven't seen it as much.
[00:44:11.200 --> 00:44:17.040]   I think we've seen it mostly for some biomedical applications.
[00:44:17.040 --> 00:44:20.520]   So they kind of look at all the abstracts from one year,
[00:44:20.520 --> 00:44:22.400]   and they want to build embeddings around that
[00:44:22.400 --> 00:44:24.040]   for a particular application.
[00:44:24.040 --> 00:44:25.840]   And the next year rolls around, and now you
[00:44:25.840 --> 00:44:27.640]   have another set of abstracts that you
[00:44:27.640 --> 00:44:30.120]   have to kind of incorporate in the embeddings
[00:44:30.120 --> 00:44:31.080]   that you created.
[00:44:31.080 --> 00:44:32.800]   So those are the kind of challenges
[00:44:32.800 --> 00:44:33.880]   that we're looking at.
[00:44:33.880 --> 00:44:35.300]   In the medical space, I think we've
[00:44:35.300 --> 00:44:37.960]   been focusing on the weak supervision aspect of it
[00:44:37.960 --> 00:44:39.480]   and labeling images.
[00:44:39.480 --> 00:44:41.480]   Yeah.
[00:44:41.480 --> 00:44:41.980]   Great.
[00:44:41.980 --> 00:44:43.080]   Let's thank Roma again.
[00:44:43.080 --> 00:44:44.920]   [APPLAUSE]
[00:44:44.920 --> 00:44:48.280]   [APPLAUSE]

