
[00:00:00.000 --> 00:00:06.560]   It's a simple but profound insight, which is that it's very difficult for a model to
[00:00:06.560 --> 00:00:19.000]   generate something creative and aesthetic and correct from nothing.
[00:00:19.000 --> 00:00:24.560]   And the profound insight is to say, well, given that that's hard, why don't we not ask
[00:00:24.560 --> 00:00:30.080]   a model to do that directly, but why don't we train a model to do something a little
[00:00:30.080 --> 00:00:35.240]   bit better than nothing, and then make a model that if we run it multiple times, takes the
[00:00:35.240 --> 00:00:38.720]   thing that's a little bit better than nothing and makes that a little bit better still.
[00:00:38.720 --> 00:00:44.840]   And the interesting thing is that we're not close at all to doing that in an optimal way.
[00:00:44.840 --> 00:00:49.280]   So the fantastic results you're seeing at the moment are based on what in a year's time
[00:00:49.280 --> 00:00:57.400]   or two will be considered extremely primitive approaches.
[00:00:57.400 --> 00:00:59.580]   (upbeat music)

