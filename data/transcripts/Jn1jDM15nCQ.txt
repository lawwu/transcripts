
[00:00:00.000 --> 00:00:01.720]   - Sweet, thank you, Sean.
[00:00:01.720 --> 00:00:04.000]   Hey folks, I can't see you with the bright lights,
[00:00:04.000 --> 00:00:06.440]   but my name's Ari Kalfayan, like Sean said.
[00:00:06.440 --> 00:00:09.200]   And before we get started, as the first employee
[00:00:09.200 --> 00:00:11.020]   at Weights & Biases and part of the founding team,
[00:00:11.020 --> 00:00:14.380]   I just wanna say how fucking amazing it is
[00:00:14.380 --> 00:00:17.160]   to be on this stage and see this community so engaged
[00:00:17.160 --> 00:00:22.000]   and how it's grown over the last five and a half years.
[00:00:22.000 --> 00:00:24.000]   I've seen the blood, sweat, and tears
[00:00:24.000 --> 00:00:27.900]   the team's put overnight, working through the night,
[00:00:27.900 --> 00:00:30.400]   getting the demos done, even to this day.
[00:00:30.400 --> 00:00:32.880]   And it's an honor to get to participate in this way
[00:00:32.880 --> 00:00:35.400]   on behalf of AWS and sponsor this event.
[00:00:35.400 --> 00:00:37.620]   So thank you for joining us today.
[00:00:37.620 --> 00:00:40.240]   And I have the pleasure of introducing
[00:00:40.240 --> 00:00:43.320]   our inaugural Gen AI cohort today.
[00:00:43.320 --> 00:00:45.240]   So without further ado, Mikhail.
[00:00:45.240 --> 00:00:47.040]   - Can people hear me?
[00:00:47.040 --> 00:00:48.320]   Oh wow.
[00:00:48.320 --> 00:00:51.120]   Well this is like a rock concert, my God.
[00:00:51.120 --> 00:00:51.960]   Very cool.
[00:00:51.960 --> 00:00:53.680]   So hi everyone, I'm Mikhail.
[00:00:53.680 --> 00:00:55.600]   I'm one of the co-founders of Storia.
[00:00:55.600 --> 00:00:58.740]   We are building a creative assistant for storytelling.
[00:00:58.740 --> 00:01:00.520]   And we're starting by supercharging
[00:01:00.520 --> 00:01:05.520]   the pre-production process of film and television projects.
[00:01:05.520 --> 00:01:09.300]   And my background is I have about a decade of experience
[00:01:09.300 --> 00:01:11.860]   researching and engineering AI systems.
[00:01:11.860 --> 00:01:15.300]   And before that, my past life, I built some
[00:01:15.300 --> 00:01:16.660]   of the earliest deep learning systems
[00:01:16.660 --> 00:01:20.580]   for conversational AI at Stanford University.
[00:01:20.580 --> 00:01:22.460]   And then also was one of the founding members
[00:01:22.460 --> 00:01:26.080]   of the Alexa AI's first special projects team
[00:01:26.080 --> 00:01:28.760]   where I built the organization's first LLMs.
[00:01:28.760 --> 00:01:30.780]   And yeah, really excited to be here.
[00:01:30.780 --> 00:01:34.100]   - Great, hi, my name is Max.
[00:01:34.100 --> 00:01:37.000]   I'm CEO and co-founder of Nixle.
[00:01:37.000 --> 00:01:38.960]   Me and my co-founders have been working
[00:01:38.960 --> 00:01:41.980]   in the time series field for the last decade.
[00:01:41.980 --> 00:01:45.320]   And we're building foundational models for time series.
[00:01:45.320 --> 00:01:47.440]   I want to use the intro to also mention
[00:01:47.440 --> 00:01:49.200]   that Nixle is founded by members
[00:01:49.200 --> 00:01:52.640]   of the Latinx and LGTB community.
[00:01:52.640 --> 00:01:54.960]   And we believe that not only transformer-based
[00:01:54.960 --> 00:01:57.900]   architectures will benefit from diversity,
[00:01:57.900 --> 00:02:00.320]   but the whole field could use more diversity.
[00:02:00.320 --> 00:02:04.320]   (audience cheering)
[00:02:04.320 --> 00:02:08.680]   - Hi, my name is Iman.
[00:02:08.680 --> 00:02:13.000]   I'm the co-founder and CEO of Protopia AI.
[00:02:13.000 --> 00:02:16.660]   Prior to Protopia, I was at NVIDIA for about a decade
[00:02:16.660 --> 00:02:20.760]   where I worked on distributed training
[00:02:20.760 --> 00:02:25.480]   of large language models and enabling thousands of GPUs
[00:02:25.480 --> 00:02:27.840]   to kind of train those models.
[00:02:27.840 --> 00:02:30.920]   And we've started Protopia with kind of identifying
[00:02:30.920 --> 00:02:33.760]   a problem space in the enterprise adoption
[00:02:33.760 --> 00:02:35.320]   of machine learning that's very focused
[00:02:35.320 --> 00:02:37.320]   on data protection and data ownership.
[00:02:37.320 --> 00:02:39.860]   And thanks for being here.
[00:02:39.860 --> 00:02:42.600]   - Yeah, hello everyone.
[00:02:42.600 --> 00:02:44.740]   My name is Bernardo Aceituno.
[00:02:44.740 --> 00:02:47.360]   I'm the co-founder of Stack.AI.
[00:02:47.360 --> 00:02:51.360]   Stack.AI is basically the simplest and most reliable way
[00:02:51.360 --> 00:02:53.440]   to build your own LLM application
[00:02:53.440 --> 00:02:55.600]   with a simple clicks and drag and drops.
[00:02:55.600 --> 00:02:58.000]   You can have a custom chapel with your own data,
[00:02:58.000 --> 00:03:00.040]   securely deployed and auto scalable
[00:03:00.040 --> 00:03:03.860]   and auto replicated on the cloud for your website,
[00:03:03.860 --> 00:03:07.160]   running and easy to manage while maintained by your team.
[00:03:07.160 --> 00:03:09.760]   Before founding Stack.AI, me and my co-founder
[00:03:09.760 --> 00:03:12.080]   were doing our PhDs at MIT.
[00:03:12.080 --> 00:03:13.680]   We've been in the world of computer science
[00:03:13.680 --> 00:03:15.080]   and machine learning for over 10 years.
[00:03:15.080 --> 00:03:17.400]   And for a long time we started doing research
[00:03:17.400 --> 00:03:20.520]   at places like Facebook AI Research,
[00:03:20.520 --> 00:03:23.480]   now Meta.AI and NASA JPL.
[00:03:23.480 --> 00:03:25.040]   So yeah, pleasure to be here.
[00:03:25.040 --> 00:03:26.640]   - Cool, pleasure for having you.
[00:03:26.640 --> 00:03:29.800]   So at Weights & Biases, one of my favorite things
[00:03:29.800 --> 00:03:32.280]   that I got to see is actually that you saw that photo
[00:03:32.280 --> 00:03:34.600]   of Kerry with OpenAI, right?
[00:03:34.600 --> 00:03:36.640]   And getting to see the robotics hand learn
[00:03:36.640 --> 00:03:39.040]   how to use its fingers and solve a Rubik's Cube.
[00:03:39.040 --> 00:03:40.900]   And this is like six years ago, right?
[00:03:40.900 --> 00:03:43.280]   Since then, I had a front row seat
[00:03:43.280 --> 00:03:44.400]   where I've got to work with, you know,
[00:03:44.400 --> 00:03:49.000]   Anthropic and Stability AI as part of my work at AWS
[00:03:49.000 --> 00:03:50.680]   and start the GenAI Accelerator.
[00:03:50.680 --> 00:03:53.720]   But there's also a lot of hype around generative AI.
[00:03:53.720 --> 00:03:55.960]   So what's real and what are some of the practical
[00:03:55.960 --> 00:03:57.840]   applications folks can expect to see
[00:03:57.840 --> 00:04:00.000]   in the next 12 to 24 months?
[00:04:00.000 --> 00:04:04.920]   - Yeah, I guess I'll get started.
[00:04:04.920 --> 00:04:08.320]   So I think GenAI has come a long way
[00:04:08.320 --> 00:04:11.800]   and there are a lot of very cool demos on Twitter.
[00:04:12.640 --> 00:04:16.640]   I think that there is, we should probably think
[00:04:16.640 --> 00:04:19.280]   about GenAI in terms of where,
[00:04:19.280 --> 00:04:22.560]   not super high precision tasks yet,
[00:04:22.560 --> 00:04:27.000]   but really more about prototyping and exploration
[00:04:27.000 --> 00:04:29.080]   and kind of these more like softer tasks
[00:04:29.080 --> 00:04:31.160]   where there's the ability to really supercharge
[00:04:31.160 --> 00:04:34.680]   creative endeavors and really get people going
[00:04:34.680 --> 00:04:36.060]   and get over sort of those initial,
[00:04:36.060 --> 00:04:39.700]   maybe artistic or creative blocks that they might have.
[00:04:39.700 --> 00:04:42.500]   And so that's where we think there might be some benefit.
[00:04:42.500 --> 00:04:47.720]   - Yeah, we think that there have been great advancements
[00:04:47.720 --> 00:04:51.720]   in terms of big models for language and for perception,
[00:04:51.720 --> 00:04:55.620]   but we're gonna see more and more foundational models
[00:04:55.620 --> 00:04:56.860]   for time series.
[00:04:56.860 --> 00:05:00.640]   And this is really important because time is fundamental
[00:05:00.640 --> 00:05:03.140]   to understand anything that has to do with change,
[00:05:03.140 --> 00:05:04.880]   growth, and even decay.
[00:05:04.880 --> 00:05:07.520]   And furthermore, first class citizens of the world
[00:05:07.520 --> 00:05:10.120]   like businesses, systems, institutions,
[00:05:10.120 --> 00:05:12.160]   they don't really speak in images or languages.
[00:05:12.160 --> 00:05:14.840]   They speak in data, they speak in time series.
[00:05:14.840 --> 00:05:17.360]   So I think we're gonna see a lot of very important
[00:05:17.360 --> 00:05:19.960]   practical applications in those areas,
[00:05:19.960 --> 00:05:22.680]   in finance, IOT, healthcare, retail,
[00:05:22.680 --> 00:05:25.080]   involving large time series models.
[00:05:25.080 --> 00:05:29.760]   - And maybe what are some of the weird edge cases
[00:05:29.760 --> 00:05:30.800]   that we're gonna see?
[00:05:30.800 --> 00:05:31.680]   Bernardo?
[00:05:31.680 --> 00:05:34.020]   - Yeah, I think that people will be surprised
[00:05:34.020 --> 00:05:36.860]   in the next 12, 24 months about how much
[00:05:36.860 --> 00:05:39.220]   of the way we interact with data in the world
[00:05:39.220 --> 00:05:41.480]   is gonna become some sort of chat interface.
[00:05:41.480 --> 00:05:43.160]   Whether if it is the way that we interact
[00:05:43.160 --> 00:05:45.240]   with our business data, or the way that we interact
[00:05:45.240 --> 00:05:46.480]   with our friends that are using data,
[00:05:46.480 --> 00:05:47.840]   that really surprises me.
[00:05:47.840 --> 00:05:49.480]   At StackAlike we see it, we have customers
[00:05:49.480 --> 00:05:52.040]   from all sorts of enterprises and markets
[00:05:52.040 --> 00:05:53.840]   building a chatbot interface,
[00:05:53.840 --> 00:05:56.400]   or even just a form interface to interact
[00:05:56.400 --> 00:05:58.560]   with what your connections are,
[00:05:58.560 --> 00:05:59.600]   what your world around you is,
[00:05:59.600 --> 00:06:01.400]   and build actions around it.
[00:06:01.400 --> 00:06:03.480]   So it's gonna be a truly transformational way
[00:06:03.480 --> 00:06:06.520]   on the way that we ingest and interact with information.
[00:06:07.500 --> 00:06:10.500]   - And then I think the audience may be curious,
[00:06:10.500 --> 00:06:12.460]   like, do we have any artists in the room?
[00:06:12.460 --> 00:06:13.280]   Raise your hand.
[00:06:13.280 --> 00:06:16.340]   Artists, writers, creatives?
[00:06:16.340 --> 00:06:17.380]   Couple hands?
[00:06:17.380 --> 00:06:18.740]   I can't really see, honestly.
[00:06:18.740 --> 00:06:20.360]   The lights are really bright.
[00:06:20.360 --> 00:06:22.660]   But like, the writer strike's going on in LA, right?
[00:06:22.660 --> 00:06:25.980]   And one of the main concerns is around, you know,
[00:06:25.980 --> 00:06:28.780]   creatives being replaced by AI.
[00:06:28.780 --> 00:06:30.300]   Do we think they're actually gonna be replaced,
[00:06:30.300 --> 00:06:32.680]   or should they even be worried about this
[00:06:32.680 --> 00:06:35.740]   in the near term, or is it really like farther out?
[00:06:36.740 --> 00:06:38.600]   - Yeah, I'm happy to take this question.
[00:06:38.600 --> 00:06:41.280]   And I think maybe one way to illustrate this
[00:06:41.280 --> 00:06:43.880]   in terms of how we at Storia think about what's going on
[00:06:43.880 --> 00:06:46.280]   with the creative community is a story
[00:06:46.280 --> 00:06:47.600]   that I'll share, actually.
[00:06:47.600 --> 00:06:49.600]   So when we released our first product,
[00:06:49.600 --> 00:06:51.920]   we actually had a woman named Charletta
[00:06:51.920 --> 00:06:54.360]   who reached out to us, and she basically said
[00:06:54.360 --> 00:06:57.120]   that she had recently had a stroke,
[00:06:57.120 --> 00:06:58.840]   and she wanted to have the,
[00:06:58.840 --> 00:07:01.080]   but she didn't have the resources nor the budget
[00:07:01.080 --> 00:07:03.880]   to actually visualize and sort of explore
[00:07:03.880 --> 00:07:05.720]   what her stroke story could look like.
[00:07:05.720 --> 00:07:08.520]   And so she was applying to get early access to our tool.
[00:07:08.520 --> 00:07:11.040]   And so for us, when we look at what AI means
[00:07:11.040 --> 00:07:15.000]   in broader society, real stories are written by real people,
[00:07:15.000 --> 00:07:16.820]   and that's always gonna be the case.
[00:07:16.820 --> 00:07:19.120]   AI is just gonna be a powerful sidekick,
[00:07:19.120 --> 00:07:21.220]   and that's something that we are working toward.
[00:07:21.220 --> 00:07:23.620]   You know, we see all these amazing generative abilities,
[00:07:23.620 --> 00:07:26.240]   but the truth is that the questions to ask,
[00:07:26.240 --> 00:07:27.640]   the stories that are worth sharing,
[00:07:27.640 --> 00:07:30.080]   that's all something that anyone in this room
[00:07:30.080 --> 00:07:32.400]   who has the full wealth of human experience,
[00:07:32.400 --> 00:07:34.240]   we're only the ones that are able to do that.
[00:07:34.240 --> 00:07:36.880]   And so, you know, to the writers, to the creatives,
[00:07:36.880 --> 00:07:38.600]   I think really what we should think about it is
[00:07:38.600 --> 00:07:41.660]   this is a sidekick for your creative abilities, right?
[00:07:41.660 --> 00:07:44.260]   It's about taking what, the abilities you already have,
[00:07:44.260 --> 00:07:47.160]   going to the next level, doing it faster, more cheaply.
[00:07:47.160 --> 00:07:49.880]   It's almost like thinking about what's happening now
[00:07:49.880 --> 00:07:52.480]   is the same paradigm shift when Photoshop came around,
[00:07:52.480 --> 00:07:54.540]   and all of a sudden, visual editing abilities
[00:07:54.540 --> 00:07:56.200]   were made available to so many more people
[00:07:56.200 --> 00:07:58.560]   than was previously the case.
[00:07:58.560 --> 00:08:00.980]   So people that are underprivileged communities,
[00:08:00.980 --> 00:08:03.640]   underprivileged walks of life, but even power users,
[00:08:03.640 --> 00:08:05.320]   everyone really stands to gain from this.
[00:08:05.320 --> 00:08:07.680]   - So, I mean, when we launched the Gen AI Accelerator,
[00:08:07.680 --> 00:08:09.680]   I was shocked at how many companies
[00:08:09.680 --> 00:08:11.360]   came in from entertainment, right?
[00:08:11.360 --> 00:08:13.540]   And they're really taking on that vertical.
[00:08:13.540 --> 00:08:15.600]   So how much faster is the creative process
[00:08:15.600 --> 00:08:16.800]   actually gonna get?
[00:08:16.800 --> 00:08:21.760]   - I would say that the, when we first,
[00:08:21.760 --> 00:08:23.240]   you know, we're building a storyboarding tool,
[00:08:23.240 --> 00:08:24.160]   that's one of the first products
[00:08:24.160 --> 00:08:25.480]   that we've actually released,
[00:08:25.480 --> 00:08:28.520]   and we've been onboarding directors and screenwriters
[00:08:29.360 --> 00:08:31.940]   very gradually to sort of see and show them
[00:08:31.940 --> 00:08:34.160]   what's possible with the technology today.
[00:08:34.160 --> 00:08:36.900]   One of our first users, our first sort of user interviews,
[00:08:36.900 --> 00:08:38.500]   when we showed them and got them to actually play
[00:08:38.500 --> 00:08:40.180]   with the tool, they literally said,
[00:08:40.180 --> 00:08:42.120]   "How is this fucking possible?"
[00:08:42.120 --> 00:08:44.640]   And that is what we're seeing time and time again,
[00:08:44.640 --> 00:08:49.080]   is just the speed, the cost is way lower.
[00:08:49.080 --> 00:08:51.100]   It is orders of magnitude better,
[00:08:51.100 --> 00:08:53.500]   more richly expressive, more capable,
[00:08:53.500 --> 00:08:55.660]   just all these things, and that's really where
[00:08:55.660 --> 00:08:56.980]   I think there's gonna be a lot of interest
[00:08:56.980 --> 00:08:59.240]   and more improved capabilities.
[00:08:59.240 --> 00:09:01.820]   - So bonus question here for the cohort.
[00:09:01.820 --> 00:09:04.140]   What are the coolest creative applications
[00:09:04.140 --> 00:09:05.620]   you've seen for generative AI,
[00:09:05.620 --> 00:09:06.920]   and what makes it so cool?
[00:09:06.920 --> 00:09:10.500]   - I think I'm gonna give a shout out
[00:09:10.500 --> 00:09:12.380]   to another one of the cohort companies here.
[00:09:12.380 --> 00:09:16.020]   There's a company called Elo in the cohort
[00:09:16.020 --> 00:09:21.020]   that teaches kids to learn reading better
[00:09:21.020 --> 00:09:24.360]   by providing kind of this character,
[00:09:24.360 --> 00:09:27.740]   I think it's an elephant, that finds out
[00:09:27.740 --> 00:09:30.820]   what it is that a child can't read properly
[00:09:30.820 --> 00:09:32.420]   or what they're having trouble with
[00:09:32.420 --> 00:09:35.860]   and kind of creates a story around that
[00:09:35.860 --> 00:09:37.580]   to practice with the character.
[00:09:37.580 --> 00:09:41.060]   I think things like that in education especially
[00:09:41.060 --> 00:09:46.060]   are going to be very strong kind of uses
[00:09:46.060 --> 00:09:50.800]   of LLMs for the broader community and society.
[00:09:50.800 --> 00:09:56.720]   - I also wanna give a shout out not to a cohort company,
[00:09:56.720 --> 00:09:58.860]   but I think RunwayML is actually doing a great job.
[00:09:58.860 --> 00:10:01.860]   Their Gen 1, Gen 2 stuff is pretty exemplary.
[00:10:01.860 --> 00:10:05.340]   And I think that's still very early days
[00:10:05.340 --> 00:10:07.140]   showing us a glimpse of what's possible,
[00:10:07.140 --> 00:10:09.260]   but I expect that there's gonna be more
[00:10:09.260 --> 00:10:11.140]   really, really cool stuff in that vein
[00:10:11.140 --> 00:10:14.140]   that is gonna really change how stories are told,
[00:10:14.140 --> 00:10:16.800]   how movies are made, how so many things are done.
[00:10:16.800 --> 00:10:19.580]   So good work if you're in the room, Chris.
[00:10:19.580 --> 00:10:22.580]   - I love RunwayML, we've been supporting them
[00:10:22.580 --> 00:10:24.140]   for a couple years, and it was cool to see them.
[00:10:24.140 --> 00:10:26.540]   I mean, they contributed the best picture this year, right?
[00:10:26.540 --> 00:10:28.080]   The scene with the rock.
[00:10:28.080 --> 00:10:32.480]   Oh, everywhere, all at once, everywhere.
[00:10:32.480 --> 00:10:35.280]   Yeah, I'm blanking on the full name right now.
[00:10:35.280 --> 00:10:37.080]   So I think let's move it to security
[00:10:37.080 --> 00:10:38.500]   and privacy for a second.
[00:10:38.500 --> 00:10:41.580]   I mean, enterprise companies want to use LLM,
[00:10:41.580 --> 00:10:44.240]   but data security and privacy is really
[00:10:44.240 --> 00:10:48.240]   an important subject for the enterprise to adopt LLMs.
[00:10:48.240 --> 00:10:51.140]   What are some of the concerns around security and privacy,
[00:10:51.140 --> 00:10:53.840]   and how can they assuage those concerns?
[00:10:55.560 --> 00:10:57.400]   - Yeah, we hear all the time,
[00:10:57.400 --> 00:10:59.880]   people definitely want to understand
[00:10:59.880 --> 00:11:02.000]   where their data lives, what part of their data
[00:11:02.000 --> 00:11:04.760]   is being shared, and understand through the entire process
[00:11:04.760 --> 00:11:05.800]   where it's going.
[00:11:05.800 --> 00:11:07.600]   We shape our entire product, actually,
[00:11:07.600 --> 00:11:08.840]   with this idea in mind.
[00:11:08.840 --> 00:11:11.000]   And there's a few players that are important here.
[00:11:11.000 --> 00:11:12.760]   First and most obvious, open source
[00:11:12.760 --> 00:11:14.980]   and language models are gonna be very important for this,
[00:11:14.980 --> 00:11:16.640]   as companies start to self-host
[00:11:16.640 --> 00:11:19.960]   and build on-prem solutions that may have to be trained
[00:11:19.960 --> 00:11:23.220]   with custom data that is safer and only controlled by them,
[00:11:23.220 --> 00:11:26.200]   such that they cannot guarantee that it only exists there.
[00:11:26.200 --> 00:11:29.120]   But I think people also ignore a little bit
[00:11:29.120 --> 00:11:31.040]   what's the role that big model providers
[00:11:31.040 --> 00:11:32.800]   need to play in there.
[00:11:32.800 --> 00:11:36.440]   Being able to set up virtual clouds with foundation models
[00:11:36.440 --> 00:11:37.680]   is still very powerful.
[00:11:37.680 --> 00:11:40.460]   Foundation models can empower organizations
[00:11:40.460 --> 00:11:45.160]   to build AI to a very large magnitude of applications,
[00:11:45.160 --> 00:11:47.120]   with significantly less effort and resources
[00:11:47.120 --> 00:11:48.400]   than training one yourself.
[00:11:48.400 --> 00:11:50.680]   So there needs to be both players in there,
[00:11:50.680 --> 00:11:53.120]   as we understand how this moves around,
[00:11:53.120 --> 00:11:54.580]   how it's being used by players,
[00:11:54.580 --> 00:11:57.360]   and a lot of people, in terms of privacy,
[00:11:57.360 --> 00:11:58.560]   is being shared as well.
[00:11:58.560 --> 00:12:01.860]   - Yeah, just to add there,
[00:12:01.860 --> 00:12:05.800]   I think some of the concerns around data protection
[00:12:05.800 --> 00:12:10.800]   and privacy are actually more of a data ownership issue,
[00:12:10.800 --> 00:12:16.020]   in that the enterprise where data gets gathered
[00:12:16.020 --> 00:12:17.620]   from a lot of different individuals,
[00:12:17.620 --> 00:12:21.940]   that kind of large amount of data
[00:12:21.940 --> 00:12:25.380]   starts becoming important to the enterprise
[00:12:25.380 --> 00:12:26.220]   that has gathered it.
[00:12:26.220 --> 00:12:28.380]   So when they want to use something like an LLM
[00:12:28.380 --> 00:12:30.260]   that's going to be hosted somewhere,
[00:12:30.260 --> 00:12:33.780]   the idea of exposing that information in plain text
[00:12:33.780 --> 00:12:36.540]   somewhere else can be problematic,
[00:12:36.540 --> 00:12:38.840]   because much of that data has never lived
[00:12:38.840 --> 00:12:41.740]   outside of the four walls of the organization before.
[00:12:41.740 --> 00:12:45.780]   And so this is actually something that is not a problem
[00:12:45.780 --> 00:12:48.100]   just in generative AI and LLMs.
[00:12:48.100 --> 00:12:49.820]   This has been a problem for machine learning,
[00:12:49.820 --> 00:12:53.500]   especially when it's deployed in hosted form for a long time.
[00:12:53.500 --> 00:12:57.540]   And it is one of the main focuses of us at Protopia
[00:12:57.540 --> 00:13:00.260]   is enabling, essentially, the enterprise
[00:13:00.260 --> 00:13:03.380]   to be able to access machine learning and use it
[00:13:03.380 --> 00:13:07.940]   without exposing the data in plain text form.
[00:13:07.940 --> 00:13:10.300]   And so for the LLM world, in particular,
[00:13:10.300 --> 00:13:11.180]   how that would work,
[00:13:11.180 --> 00:13:14.580]   we're actually setting up a sandbox with AWS
[00:13:14.580 --> 00:13:17.700]   that, if you're interested, you can go to Protopia AI
[00:13:17.700 --> 00:13:19.020]   and sign up for early access,
[00:13:19.020 --> 00:13:21.580]   but essentially it'll give you the ability to see
[00:13:21.580 --> 00:13:24.820]   what does it mean that when you query a language model,
[00:13:24.820 --> 00:13:28.140]   that query and whatever context you provide to it
[00:13:28.140 --> 00:13:29.780]   doesn't need to be in plain text,
[00:13:29.780 --> 00:13:33.220]   and the LLM can still provide accurate answers
[00:13:33.220 --> 00:13:34.220]   based off of that.
[00:13:34.220 --> 00:13:37.540]   - So you guys are insiders, right?
[00:13:37.540 --> 00:13:42.260]   Like, we've seen a lot of different LLMs and companies
[00:13:42.260 --> 00:13:45.340]   spin out of major labs in the last couple years.
[00:13:45.340 --> 00:13:48.260]   How do you think the large language model
[00:13:48.260 --> 00:13:49.100]   is gonna develop?
[00:13:49.100 --> 00:13:50.820]   Is it gonna verticalize?
[00:13:50.820 --> 00:13:52.700]   Is it one player that's gonna own it all?
[00:13:52.700 --> 00:13:54.460]   Are there a variety of players
[00:13:54.460 --> 00:13:56.220]   that are gonna move forward in this space?
[00:13:56.220 --> 00:13:58.620]   Let's keep it to like 30 seconds, maybe.
[00:13:58.620 --> 00:14:04.180]   - Maybe I will go one step back
[00:14:04.180 --> 00:14:08.020]   and advocate in favor for open source business models.
[00:14:08.020 --> 00:14:10.220]   We at Nixlar are completely open source,
[00:14:10.220 --> 00:14:12.820]   and we think that we are at the verge
[00:14:12.820 --> 00:14:16.140]   of a very important generational transformation.
[00:14:16.140 --> 00:14:18.780]   And one of the elements that we have
[00:14:18.780 --> 00:14:20.740]   to make that transformation probably more helpful
[00:14:20.740 --> 00:14:22.980]   for everyone is to keep things open.
[00:14:22.980 --> 00:14:26.100]   So I definitely hope and think that we're gonna see
[00:14:26.100 --> 00:14:28.660]   more and more proliferation of different companies,
[00:14:28.660 --> 00:14:31.700]   different players building open source models.
[00:14:31.700 --> 00:14:34.540]   - So let's keep going with that for a second in closing,
[00:14:34.540 --> 00:14:35.780]   but we'll start with you, Max.
[00:14:35.780 --> 00:14:37.340]   How can people support you
[00:14:37.340 --> 00:14:40.940]   in building your open source framework for time series data?
[00:14:40.940 --> 00:14:45.780]   - Yeah, so just go to the GitHub and try to collaborate.
[00:14:45.780 --> 00:14:49.700]   We really think the future is gonna be
[00:14:49.700 --> 00:14:53.100]   not only multi-model, but multi-temporal.
[00:14:53.100 --> 00:14:55.980]   So what we're trying to build is technology
[00:14:55.980 --> 00:14:58.740]   that fits into the large language models
[00:14:58.740 --> 00:15:02.140]   and allows you to ask questions not only about the past,
[00:15:02.140 --> 00:15:03.620]   but also about the future.
[00:15:03.620 --> 00:15:06.940]   So imagine being able not just to run analytics
[00:15:06.940 --> 00:15:11.020]   about what has happened, but also about what will happen.
[00:15:12.820 --> 00:15:14.780]   - I think just taking that question
[00:15:14.780 --> 00:15:17.540]   of how this particular audience
[00:15:17.540 --> 00:15:20.260]   can impact what we're building,
[00:15:20.260 --> 00:15:23.820]   I think understanding the art of the possible
[00:15:23.820 --> 00:15:27.300]   is what the curious minds in this room are all about.
[00:15:27.300 --> 00:15:32.020]   And it's important to remind ourselves that technology,
[00:15:32.020 --> 00:15:34.300]   especially like LLMs and generative AI
[00:15:34.300 --> 00:15:36.340]   that has come to market at very high speed
[00:15:36.340 --> 00:15:39.340]   and speed to market has been the most important thing so far.
[00:15:39.340 --> 00:15:42.340]   It's not always going to at first blush
[00:15:42.340 --> 00:15:44.180]   have the best answers, right?
[00:15:44.180 --> 00:15:47.100]   In terms of how to use it, how it should be deployed,
[00:15:47.100 --> 00:15:49.340]   what needs to be exposed, et cetera.
[00:15:49.340 --> 00:15:54.060]   And I think just being able to bring this message
[00:15:54.060 --> 00:15:57.820]   to this crowd of go check out the type of things
[00:15:57.820 --> 00:15:58.980]   that this cohort is building
[00:15:58.980 --> 00:16:01.700]   or go try out the sandbox on AWS.
[00:16:01.700 --> 00:16:05.780]   I think that will ultimately just enhance the understanding
[00:16:05.780 --> 00:16:07.860]   at a broader level of what's possible.
[00:16:07.860 --> 00:16:12.020]   And that will help all of the startups like ours.
[00:16:12.020 --> 00:16:13.140]   - How about you, Bernardo?
[00:16:13.140 --> 00:16:14.980]   - Yeah, I definitely think that in the future
[00:16:14.980 --> 00:16:19.100]   our foundation models are gonna become a big empower tool
[00:16:19.100 --> 00:16:20.820]   for most of the community.
[00:16:20.820 --> 00:16:25.060]   Not just for people that are experts in data science and ML,
[00:16:25.060 --> 00:16:26.900]   but in general for people that just want
[00:16:26.900 --> 00:16:29.380]   to get their hands dirty and build their own tool.
[00:16:29.380 --> 00:16:31.460]   Just like technologies like Wix and Shopify
[00:16:31.460 --> 00:16:34.100]   became enabled for society to enter the web,
[00:16:34.100 --> 00:16:36.180]   I think foundation models will be enabled for society
[00:16:36.180 --> 00:16:40.020]   to interact with data, process it and generate with it.
[00:16:40.020 --> 00:16:42.500]   So it's a very exciting future building on top of that.
[00:16:42.500 --> 00:16:43.900]   - Thank you, and closing word, Mikhail.
[00:16:43.900 --> 00:16:45.500]   How can the audience help you?
[00:16:45.500 --> 00:16:49.220]   - Keep being awesome, I guess.
[00:16:49.220 --> 00:16:52.900]   No, I mean, seriously, be awesome,
[00:16:52.900 --> 00:16:54.700]   but also do other stuff too.
[00:16:54.700 --> 00:16:58.940]   I would say that we're onboarding people,
[00:16:58.940 --> 00:17:00.540]   directors, producers, screenwriters.
[00:17:00.540 --> 00:17:02.420]   If there's any people that do that kind of stuff,
[00:17:02.420 --> 00:17:04.140]   please come talk to me afterwards.
[00:17:04.140 --> 00:17:05.860]   But otherwise, just developers are some
[00:17:05.860 --> 00:17:08.780]   of the most forward-thinking individuals in the world,
[00:17:08.780 --> 00:17:09.860]   and really pushing the frontiers.
[00:17:09.860 --> 00:17:12.580]   So keep being awesome.
[00:17:12.580 --> 00:17:16.380]   - So in closing, I just want to thank Weights & Biases,
[00:17:16.380 --> 00:17:18.820]   the audience, all the sponsors for being here today.
[00:17:18.820 --> 00:17:21.260]   And if you're running an amazing machine learning startup,
[00:17:21.260 --> 00:17:22.460]   I'll be hanging out.
[00:17:22.460 --> 00:17:24.100]   And happy Pride Month, folks.
[00:17:24.100 --> 00:17:25.100]   Bye.
[00:17:25.100 --> 00:17:25.940]   - Bye.
[00:17:25.940 --> 00:17:26.780]   - Bye, thank you.
[00:17:26.780 --> 00:17:27.940]   (audience applauding)
[00:17:27.940 --> 00:17:30.520]   (upbeat music)
[00:17:30.520 --> 00:17:33.600]   (upbeat music fades)
[00:17:33.600 --> 00:17:43.600]   [BLANK_AUDIO]

