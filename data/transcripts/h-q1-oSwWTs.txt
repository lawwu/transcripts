
[00:00:00.000 --> 00:00:03.240]   I'm gonna click go live and that should be fine.
[00:00:03.240 --> 00:00:05.120]   I guess that should be it.
[00:00:05.120 --> 00:00:06.760]   All right, we should be live now.
[00:00:06.760 --> 00:00:12.020]   Okay, so let me just share my screen.
[00:00:12.020 --> 00:00:18.980]   And let's go here.
[00:00:18.980 --> 00:00:26.080]   Okay, so everybody welcome back to chapter 13.
[00:00:26.080 --> 00:00:29.040]   This is week 13 and we're gonna be looking
[00:00:29.040 --> 00:00:30.800]   at our first CNNs from scratch.
[00:00:30.800 --> 00:00:34.760]   So last week what we did, we covered off convolutions.
[00:00:34.760 --> 00:00:38.320]   And this week what we're going to do is we're gonna build
[00:00:38.320 --> 00:00:40.000]   on top of that and we're gonna start doing
[00:00:40.000 --> 00:00:41.760]   our first convolutions.
[00:00:41.760 --> 00:00:43.280]   And basically we're gonna start building
[00:00:43.280 --> 00:00:45.480]   our first CNNs from scratch.
[00:00:45.480 --> 00:00:50.000]   So the reason why this week is actually very exciting
[00:00:50.000 --> 00:00:52.980]   and this is the week where we make a lot of progress.
[00:00:52.980 --> 00:00:55.480]   So we started with a journey where we didn't know
[00:00:55.480 --> 00:00:56.520]   what convolutions are.
[00:00:56.520 --> 00:01:00.680]   We pretty much used fast AI and we used those five
[00:01:00.680 --> 00:01:03.040]   or six lines of code and we built,
[00:01:03.040 --> 00:01:05.640]   we didn't really build things from scratch.
[00:01:05.640 --> 00:01:08.600]   So from the last session, we've been going deeper
[00:01:08.600 --> 00:01:09.680]   and deeper into vision.
[00:01:09.680 --> 00:01:12.520]   And we're actually at that point where we can build
[00:01:12.520 --> 00:01:14.120]   our own CNNs from scratch.
[00:01:14.120 --> 00:01:17.680]   And what I mean by that, like we built a very simple CNNs
[00:01:17.680 --> 00:01:20.520]   where we use the convolution followed by value
[00:01:20.520 --> 00:01:22.560]   which was the activation function.
[00:01:22.560 --> 00:01:24.760]   This week what we're gonna do is we're gonna start
[00:01:24.760 --> 00:01:27.040]   wrapping up, like we're gonna get a good understanding
[00:01:27.040 --> 00:01:28.320]   of what more can be done.
[00:01:28.320 --> 00:01:30.360]   Like we're gonna start looking at batch norm.
[00:01:30.360 --> 00:01:32.520]   We're going to start looking at everything,
[00:01:32.520 --> 00:01:34.320]   pretty much wrap up chapter 30.
[00:01:34.320 --> 00:01:38.000]   And then next week we're going to do ResNet.
[00:01:38.000 --> 00:01:41.240]   So ResNet is this, let me show you what ResNet is.
[00:01:41.240 --> 00:01:45.680]   So let me go, one sec, let me go to Chrome,
[00:01:45.680 --> 00:01:50.260]   go to my profile and search ResNet.
[00:01:50.260 --> 00:01:52.160]   So ResNet is this paper,
[00:01:52.160 --> 00:01:54.920]   Deep Residual Learning for Image Recognition.
[00:01:54.920 --> 00:01:57.880]   And it's a really, really influential paper.
[00:01:57.880 --> 00:01:59.880]   So if I go to Semantic Scholar, by the way,
[00:01:59.880 --> 00:02:02.920]   if you haven't checked out what Semantic Scholar is,
[00:02:02.920 --> 00:02:06.720]   I would recommend now is a good time to just know
[00:02:06.720 --> 00:02:07.760]   what Semantic Scholar is.
[00:02:07.760 --> 00:02:09.160]   If you go deep learning.
[00:02:09.160 --> 00:02:11.760]   Now, if I just search paper name,
[00:02:11.760 --> 00:02:16.440]   then what this does is it will not only show me like,
[00:02:16.440 --> 00:02:17.480]   sorry, one sec.
[00:02:17.480 --> 00:02:19.120]   So I can click on that paper.
[00:02:19.120 --> 00:02:21.880]   It will give me, it will show me the title of the paper,
[00:02:21.880 --> 00:02:23.600]   but it will also tell me like how many times
[00:02:23.600 --> 00:02:26.600]   it has been cited, how many times it has been cited.
[00:02:26.600 --> 00:02:29.480]   It will show me which other papers that cite this paper.
[00:02:29.480 --> 00:02:33.100]   So basically in research, citation means like,
[00:02:33.100 --> 00:02:39.120]   if I reference something that's related to this paper,
[00:02:39.120 --> 00:02:41.720]   then I will cite it or give credit to this paper.
[00:02:41.720 --> 00:02:44.140]   Then this is where the idea originated from.
[00:02:44.140 --> 00:02:49.140]   And then 74,018 citations is a massive, massive number.
[00:02:49.760 --> 00:02:52.640]   So ResNet is one of those papers
[00:02:52.640 --> 00:02:55.540]   that has been absolutely influential
[00:02:55.540 --> 00:02:56.960]   in the deep learning world.
[00:02:56.960 --> 00:03:01.800]   And Kaiming He, I believe was the main author.
[00:03:01.800 --> 00:03:04.480]   And then what we're gonna do from going forward
[00:03:04.480 --> 00:03:06.420]   from this week is we're gonna start,
[00:03:06.420 --> 00:03:07.720]   we're gonna wrap up convolutions,
[00:03:07.720 --> 00:03:09.000]   and then we're gonna be at a point
[00:03:09.000 --> 00:03:10.760]   where we can start looking at this paper.
[00:03:10.760 --> 00:03:14.160]   So if I go and I check out the PDF of this,
[00:03:14.160 --> 00:03:19.680]   if I check out the PDF of ResNet,
[00:03:19.680 --> 00:03:21.000]   and then this is the paper that,
[00:03:21.000 --> 00:03:23.240]   we're now at this point where we can start reading
[00:03:23.240 --> 00:03:25.280]   this research paper from scratch,
[00:03:25.280 --> 00:03:27.280]   and we can also implement this in PyTorch.
[00:03:27.280 --> 00:03:29.600]   So there's a lot of things that we will understand
[00:03:29.600 --> 00:03:31.560]   from this paper.
[00:03:31.560 --> 00:03:34.480]   And one thing that I do wanna highlight
[00:03:34.480 --> 00:03:39.000]   and also point out is that if I go to a community 1DB,
[00:03:39.000 --> 00:03:41.320]   so if you haven't looked at the 1DB forums,
[00:03:41.320 --> 00:03:42.400]   now is a good time.
[00:03:42.400 --> 00:03:45.640]   And I just wanna show you particularly two things.
[00:03:45.640 --> 00:03:47.920]   So if I go into community events
[00:03:47.920 --> 00:03:49.920]   and I go into paper reading group,
[00:03:49.920 --> 00:03:53.000]   then click on this master list bi-weekly,
[00:03:53.000 --> 00:03:54.360]   which is the pinned post,
[00:03:54.360 --> 00:03:59.560]   you will see the upcoming paper reading sessions over here,
[00:03:59.560 --> 00:04:02.200]   and you will also see the past paper reading sessions.
[00:04:02.200 --> 00:04:04.760]   So we've looked at MData, we've looked at Dita,
[00:04:04.760 --> 00:04:05.680]   we've looked at Kite.
[00:04:05.680 --> 00:04:09.480]   So there's like all of these past paper reading groups
[00:04:09.480 --> 00:04:10.800]   that we've done in the past.
[00:04:10.800 --> 00:04:15.040]   And from this week, or basically from next week,
[00:04:15.040 --> 00:04:17.120]   we're gonna start looking at ResNet
[00:04:17.120 --> 00:04:18.440]   in the paper reading group.
[00:04:18.440 --> 00:04:21.160]   So I was thinking maybe this is the perfect time
[00:04:21.160 --> 00:04:23.280]   for everybody in this group
[00:04:23.280 --> 00:04:25.640]   to transition to paper reading group as well,
[00:04:25.640 --> 00:04:26.880]   'cause you're at that point
[00:04:26.880 --> 00:04:30.520]   where you can start looking at papers.
[00:04:30.520 --> 00:04:33.480]   And I think if you need an easier way
[00:04:33.480 --> 00:04:36.040]   to get started with this paper,
[00:04:36.040 --> 00:04:38.040]   you could do it using like blog posts,
[00:04:38.040 --> 00:04:41.680]   or you could use read chapter 14,
[00:04:41.680 --> 00:04:42.880]   and even for DenseNet,
[00:04:42.880 --> 00:04:45.320]   then there's blog posts for squeeze and excitation,
[00:04:45.320 --> 00:04:46.920]   there's blog posts for efficiency,
[00:04:46.920 --> 00:04:48.440]   there's blog posts.
[00:04:48.440 --> 00:04:52.080]   So I think from this point on in computer vision,
[00:04:52.080 --> 00:04:55.400]   we can only build on top of what we know.
[00:04:55.400 --> 00:04:58.640]   And like now, like after chapter 13,
[00:04:58.640 --> 00:05:00.240]   the platform is set for you guys.
[00:05:00.240 --> 00:05:03.840]   Like this is where kind of fast books jobs,
[00:05:03.840 --> 00:05:06.200]   like there's more concepts to learn,
[00:05:06.200 --> 00:05:07.560]   but this is kind of where,
[00:05:07.560 --> 00:05:09.560]   this is where the platform is set now
[00:05:09.560 --> 00:05:11.400]   for you to build things on top of.
[00:05:11.400 --> 00:05:13.120]   So now we can all go in our directions,
[00:05:13.120 --> 00:05:14.480]   we can all start learning papers,
[00:05:14.480 --> 00:05:16.920]   we can all start learning more about things.
[00:05:16.920 --> 00:05:20.520]   And in fact, what we're gonna do is from next week,
[00:05:20.520 --> 00:05:22.520]   we're not only gonna look at ResNet,
[00:05:22.520 --> 00:05:25.160]   but I'm also planning on starting like the,
[00:05:25.160 --> 00:05:28.000]   some paper reading groups are biweekly,
[00:05:28.000 --> 00:05:29.320]   but I'm also planning to start
[00:05:29.320 --> 00:05:31.000]   like these live coding sessions
[00:05:31.000 --> 00:05:34.080]   where we build ResNet from scratch in PyTorch
[00:05:34.080 --> 00:05:35.360]   or using Fast.ai,
[00:05:35.360 --> 00:05:37.120]   and we do the same for DenseNet.
[00:05:37.120 --> 00:05:38.360]   So I think this is, again,
[00:05:38.360 --> 00:05:40.120]   this is my appeal to you guys
[00:05:40.120 --> 00:05:44.440]   that if you have followed me with fast books so far,
[00:05:44.440 --> 00:05:46.040]   then now is a really good point
[00:05:46.040 --> 00:05:47.960]   to start doing these on the side as well,
[00:05:47.960 --> 00:05:49.840]   'cause this will help you
[00:05:49.840 --> 00:05:52.720]   in your deep learning journeys quite a bit.
[00:05:52.720 --> 00:05:54.120]   So that being said,
[00:05:54.120 --> 00:05:56.200]   again, that's something that's next week.
[00:05:56.200 --> 00:05:58.400]   And also next week, if we have a look at,
[00:05:58.400 --> 00:05:59.880]   if I go to fast book,
[00:05:59.880 --> 00:06:03.120]   so we're on chapter 13,
[00:06:03.120 --> 00:06:07.760]   and you'll see chapter 14 is ResNet.
[00:06:07.760 --> 00:06:09.720]   So next week at Wix and Biosys,
[00:06:09.720 --> 00:06:11.480]   we are discussing the ResNet paper
[00:06:11.480 --> 00:06:12.760]   at the paper reading group,
[00:06:12.760 --> 00:06:15.440]   and we're also doing chapter 14,
[00:06:15.440 --> 00:06:17.360]   which is ResNet at fast book.
[00:06:17.360 --> 00:06:19.920]   So it might be a really good idea
[00:06:19.920 --> 00:06:21.320]   to do both of them together,
[00:06:21.320 --> 00:06:24.040]   and you can definitely attend the paper reading group.
[00:06:24.040 --> 00:06:29.280]   Coming back to this week,
[00:06:29.280 --> 00:06:31.440]   I really thanks everybody
[00:06:31.440 --> 00:06:33.840]   for giving such good feedback
[00:06:33.840 --> 00:06:37.320]   about our last lecture on convolutions.
[00:06:37.320 --> 00:06:39.320]   I really appreciate the feedback that I've received,
[00:06:39.320 --> 00:06:42.240]   and it's really exciting to see,
[00:06:42.240 --> 00:06:45.040]   I'll get back to that this slide before,
[00:06:45.040 --> 00:06:46.680]   but it's really exciting to see
[00:06:46.680 --> 00:06:48.880]   all these blog posts now being written about convolutions.
[00:06:48.880 --> 00:06:51.840]   So Ravi Mashu has written one about
[00:06:51.840 --> 00:06:53.480]   convolutions in fast AI,
[00:06:53.480 --> 00:06:56.400]   and this is a really, really wonderful blog post.
[00:06:56.400 --> 00:06:58.120]   Now, if I go to that link,
[00:06:58.120 --> 00:07:01.920]   1db.me/fastbook13,
[00:07:01.920 --> 00:07:05.240]   that should take everybody
[00:07:05.240 --> 00:07:07.320]   to the week 13 discussion thread.
[00:07:07.320 --> 00:07:08.720]   So this is where we're gonna start
[00:07:08.720 --> 00:07:09.880]   discussing all our threads.
[00:07:09.880 --> 00:07:12.080]   Somebody's already typing, which is great to see.
[00:07:12.080 --> 00:07:14.960]   So I can just go into this thread,
[00:07:14.960 --> 00:07:16.000]   like this one by Ashley,
[00:07:16.000 --> 00:07:18.200]   'cause she's already provided links
[00:07:18.200 --> 00:07:20.760]   for all the blog posts that people have written last week.
[00:07:20.760 --> 00:07:23.320]   So if we go to this thread,
[00:07:23.320 --> 00:07:25.560]   which is 1db.me, I'll say it again,
[00:07:25.560 --> 00:07:28.720]   1db.me/fastbook13,
[00:07:28.720 --> 00:07:30.120]   this should bring you to the discussion thread.
[00:07:30.120 --> 00:07:33.360]   So as we keep going forward in our session today,
[00:07:33.360 --> 00:07:36.600]   feel free to ask me questions just at this thread.
[00:07:36.600 --> 00:07:39.400]   Okay, so I was coming back to the blog post,
[00:07:39.400 --> 00:07:41.080]   going to Ravi Mashu's blog post,
[00:07:41.080 --> 00:07:42.120]   which is on convolutions.
[00:07:42.120 --> 00:07:44.640]   You can see like there's these nice visualizations
[00:07:44.640 --> 00:07:46.400]   and it's been explained on what strides are,
[00:07:46.400 --> 00:07:47.240]   what padding is,
[00:07:47.240 --> 00:07:49.080]   and it's really, really nice blog post
[00:07:49.080 --> 00:07:50.240]   that contains everything.
[00:07:50.240 --> 00:07:52.840]   I particularly like this one by Naresh as well.
[00:07:52.840 --> 00:07:55.640]   So let me go back to that week 13 thread.
[00:07:55.640 --> 00:07:57.440]   There's this Naresh's blog post.
[00:07:57.440 --> 00:07:59.040]   I click on that and you can see,
[00:07:59.040 --> 00:08:01.840]   you can see this convolution explained.
[00:08:01.840 --> 00:08:03.320]   And the reason why I like this,
[00:08:03.320 --> 00:08:04.800]   really like this is it also explains
[00:08:04.800 --> 00:08:08.280]   like all these kernels that we discussed about last week.
[00:08:08.280 --> 00:08:09.880]   So you can see blurring effect,
[00:08:09.880 --> 00:08:11.280]   or you can see the box kernel.
[00:08:11.280 --> 00:08:12.760]   There's like all of these different kernels
[00:08:12.760 --> 00:08:15.040]   that you can see, caution, sharpening.
[00:08:15.040 --> 00:08:17.640]   So there's like these different kernels
[00:08:17.640 --> 00:08:19.040]   that Naresh has pointed out.
[00:08:19.040 --> 00:08:20.600]   So I really like this,
[00:08:20.600 --> 00:08:22.360]   really like that blog post as well.
[00:08:22.360 --> 00:08:25.360]   One of my favorite ones though,
[00:08:25.360 --> 00:08:28.080]   I just found about this 20 minutes ago,
[00:08:28.080 --> 00:08:32.000]   has been Prime Minister Modi's beard detector.
[00:08:32.000 --> 00:08:33.520]   So if I go to that,
[00:08:33.520 --> 00:08:35.800]   I'm not sure if this is here, it is not.
[00:08:35.800 --> 00:08:40.800]   So let me just find it on Twitter.
[00:08:40.800 --> 00:08:42.040]   It's this one.
[00:08:42.040 --> 00:08:45.840]   So let me go to this,
[00:08:45.840 --> 00:08:47.120]   let me go to this blog post.
[00:08:47.120 --> 00:08:48.320]   So what Durga has done,
[00:08:48.320 --> 00:08:50.680]   he did, and he's just catching up with Fast.ai
[00:08:50.680 --> 00:08:53.120]   and it's so exciting to see that he's writing this
[00:08:53.120 --> 00:08:55.640]   about Fast.ai chapter two.
[00:08:55.640 --> 00:08:58.400]   But what he's actually done is that he's going,
[00:08:58.400 --> 00:09:00.640]   he started with the beard detector,
[00:09:00.640 --> 00:09:02.080]   which was the black beard.
[00:09:02.080 --> 00:09:04.560]   But what he did is he got Prime Minister Modi's
[00:09:04.560 --> 00:09:05.960]   images from 2014,
[00:09:05.960 --> 00:09:08.720]   and then Prime Minister Modi's images from 2021.
[00:09:08.720 --> 00:09:10.480]   So you can see how the beard has grown
[00:09:10.480 --> 00:09:13.760]   and it's like very different facial recognition.
[00:09:13.760 --> 00:09:15.600]   Like he's basically doing facial recognition
[00:09:15.600 --> 00:09:17.840]   and that the beard is the difference
[00:09:17.840 --> 00:09:19.360]   between the two mainly.
[00:09:19.360 --> 00:09:21.400]   And then he's built this classifier
[00:09:21.400 --> 00:09:23.680]   that can classify Prime Minister Modi's beard
[00:09:23.680 --> 00:09:28.680]   and it can do so with about 93% accuracy.
[00:09:28.680 --> 00:09:30.520]   So I really, really like this.
[00:09:30.520 --> 00:09:33.240]   I really enjoyed reading this blog post.
[00:09:33.240 --> 00:09:36.960]   And then Vinayak did a nice tweet about convolutions.
[00:09:36.960 --> 00:09:41.640]   And then there's another one, which is by Ravi Chandra.
[00:09:41.640 --> 00:09:45.520]   He's also written about chapter 13,
[00:09:45.520 --> 00:09:47.480]   which we covered off last week.
[00:09:47.480 --> 00:09:49.480]   So this is really, really lovely to see
[00:09:49.480 --> 00:09:51.600]   all of these great blog posts
[00:09:51.600 --> 00:09:54.600]   that all of you have been writing week after week.
[00:09:54.600 --> 00:09:58.000]   Again, I will say this again,
[00:09:58.000 --> 00:10:00.080]   this is a good time to start reading papers.
[00:10:00.080 --> 00:10:04.760]   This is, if you wanna improve or like build on top
[00:10:04.760 --> 00:10:05.960]   of what we've been doing,
[00:10:05.960 --> 00:10:08.320]   this is a really, really good time to start learning
[00:10:08.320 --> 00:10:10.040]   about transformers on the side.
[00:10:10.040 --> 00:10:11.680]   This is a really good time to start learning
[00:10:11.680 --> 00:10:13.160]   about like all the basic concepts.
[00:10:13.160 --> 00:10:15.360]   If you find something you don't know,
[00:10:15.360 --> 00:10:16.840]   this is a good time to Google it.
[00:10:16.840 --> 00:10:20.120]   And this is a good time to like actually spend time
[00:10:20.120 --> 00:10:22.760]   just trying to understand what's really going on.
[00:10:22.760 --> 00:10:26.560]   So one of the things I did ask,
[00:10:26.560 --> 00:10:28.520]   so we'll go back to the chapter 13.
[00:10:28.520 --> 00:10:30.320]   Let me just close all of this.
[00:10:30.320 --> 00:10:31.920]   So we'll go back to chapter 13.
[00:10:31.920 --> 00:10:35.800]   And where we finished last time
[00:10:35.800 --> 00:10:38.160]   was we created our simple nets.
[00:10:38.160 --> 00:10:42.360]   So that is, so we saw like what the broken CNN is.
[00:10:42.360 --> 00:10:44.280]   We saw what the output shapes are.
[00:10:44.280 --> 00:10:47.840]   We saw what a CNN, simple CNN looked like.
[00:10:47.840 --> 00:10:49.400]   But one thing I did ask everybody
[00:10:49.400 --> 00:10:52.640]   is like to figure out why the spatial dimensions
[00:10:52.640 --> 00:10:54.400]   are 14 by 14 and so on.
[00:10:54.400 --> 00:10:57.480]   So I hope you guys spend some time on this.
[00:10:58.480 --> 00:11:01.280]   And we kind of wrapped up just above this.
[00:11:01.280 --> 00:11:03.480]   So we looked at the convolution arithmetic,
[00:11:03.480 --> 00:11:06.760]   but this is kind of where we stopped.
[00:11:06.760 --> 00:11:09.720]   So we kind of created our first very simple CNN.
[00:11:09.720 --> 00:11:12.280]   And now we're at that point where we can start looking
[00:11:12.280 --> 00:11:14.800]   at the convolutional arithmetic.
[00:11:14.800 --> 00:11:16.720]   So let's start here.
[00:11:16.720 --> 00:11:17.920]   So just give me one sec.
[00:11:17.920 --> 00:11:21.600]   Let me open a note.
[00:11:26.000 --> 00:11:30.000]   And I'm just gonna go fast forward, chapter 13.
[00:11:30.000 --> 00:11:36.480]   All right.
[00:11:36.480 --> 00:11:40.440]   That's where we are.
[00:11:40.440 --> 00:11:45.840]   Okay, so that's chapter 13.
[00:11:45.840 --> 00:11:50.000]   So let's start with 1.2.2,
[00:11:50.000 --> 00:11:52.080]   which is understanding convolutional arithmetic.
[00:11:52.080 --> 00:11:54.160]   So today what we're gonna do
[00:11:54.160 --> 00:11:56.240]   is we're going to finish chapter 13
[00:11:56.240 --> 00:11:58.400]   all the way to batch normalization.
[00:11:58.400 --> 00:12:00.680]   And I'm gonna show you some parts of like the batch
[00:12:00.680 --> 00:12:04.240]   non-paper and how that translates into code.
[00:12:04.240 --> 00:12:05.800]   So I'm just gonna show you some bits
[00:12:05.800 --> 00:12:08.200]   of what that looks like.
[00:12:08.200 --> 00:12:11.280]   But then we're gonna actually finish off chapter 13.
[00:12:11.280 --> 00:12:13.680]   And then next week we're gonna pick up rest net.
[00:12:13.680 --> 00:12:16.560]   And then we're not left with much.
[00:12:16.560 --> 00:12:18.960]   We just left with then the architecture.
[00:12:18.960 --> 00:12:21.280]   We're pretty much left with four or five chapters
[00:12:21.280 --> 00:12:24.320]   and we're left with Tableau and NLP.
[00:12:24.320 --> 00:12:26.240]   So that's not a lot left.
[00:12:26.240 --> 00:12:29.040]   Okay.
[00:12:29.040 --> 00:12:32.480]   Cool, a lot of talk,
[00:12:32.480 --> 00:12:36.240]   but now in this understanding convolutional arithmetic,
[00:12:36.240 --> 00:12:39.560]   basically this isn't something new.
[00:12:39.560 --> 00:12:41.360]   Like this is something I explained,
[00:12:41.360 --> 00:12:43.320]   I believe very well last week.
[00:12:43.320 --> 00:12:45.320]   It's like, if we have an input size,
[00:12:45.320 --> 00:12:47.480]   like if we have a model,
[00:12:47.480 --> 00:12:49.440]   let me just rerun this whole notebook again.
[00:12:49.440 --> 00:12:51.960]   I hope it won't take forever,
[00:12:51.960 --> 00:12:54.240]   but I can just grab from my model.
[00:12:54.240 --> 00:12:55.800]   I can just grab the first layer
[00:12:55.800 --> 00:12:59.360]   and you can see like the first layer is convolution 2D.
[00:12:59.360 --> 00:13:00.480]   I'm just trying to zoom in
[00:13:00.480 --> 00:13:02.520]   so everybody can read this better.
[00:13:02.520 --> 00:13:05.440]   So then there's the first layer is a convolution 2D.
[00:13:05.440 --> 00:13:07.360]   The number of input channels is one.
[00:13:07.360 --> 00:13:09.400]   The number of output channels is four.
[00:13:09.400 --> 00:13:11.160]   And the kernel size is three by three,
[00:13:11.160 --> 00:13:13.280]   spiked two by two and padding one by one.
[00:13:13.280 --> 00:13:15.080]   And then it's followed by a value.
[00:13:15.080 --> 00:13:17.440]   So as it says, we have one input channel,
[00:13:17.440 --> 00:13:20.040]   four output channels and a three by three kernel.
[00:13:20.040 --> 00:13:22.000]   I hope I don't need to explain this again,
[00:13:22.000 --> 00:13:25.600]   'cause this is something we spent a lot of time on last week.
[00:13:25.600 --> 00:13:27.920]   So if there's any doubts about this,
[00:13:27.920 --> 00:13:30.680]   just have a look at last week's YouTube.
[00:13:30.680 --> 00:13:34.360]   So I'm actually just gonna just very quickly run all of this.
[00:13:34.360 --> 00:13:37.720]   Like we know that the shape of this convolution layer is,
[00:13:37.720 --> 00:13:40.960]   again, this just means four kernels
[00:13:40.960 --> 00:13:42.760]   where the input channel is one
[00:13:42.760 --> 00:13:45.440]   and the spatial dimension is three by three.
[00:13:45.440 --> 00:13:49.400]   Okay, we can see the bias 'cause in convolution,
[00:13:49.400 --> 00:13:50.760]   you just add the bias as well.
[00:13:50.760 --> 00:13:54.120]   So remember from, where was that?
[00:13:54.120 --> 00:13:58.640]   Remember from this, we are also adding bias terms
[00:13:58.640 --> 00:14:00.560]   in the end to all the convolutions.
[00:14:00.560 --> 00:14:01.480]   So that's just that.
[00:14:01.480 --> 00:14:05.960]   So because we have four kernels, we just add four biases.
[00:14:05.960 --> 00:14:07.400]   So that's going back to that.
[00:14:13.200 --> 00:14:15.720]   Sorry, that was 1.2.2, wasn't it?
[00:14:15.720 --> 00:14:18.440]   So 1.2.2, so you can see the bias shape is four.
[00:14:18.440 --> 00:14:21.640]   So I won't spend a lot of time on 1.2.2,
[00:14:21.640 --> 00:14:24.440]   'cause again, this is something that we covered
[00:14:24.440 --> 00:14:26.440]   in a lot of depth last week.
[00:14:26.440 --> 00:14:29.760]   I'm just starting with receptive fields.
[00:14:29.760 --> 00:14:38.520]   Okay, so let's say if I have my input image
[00:14:41.520 --> 00:14:43.600]   that looks like this, right?
[00:14:43.600 --> 00:14:45.000]   And then what I'm gonna do,
[00:14:45.000 --> 00:14:47.640]   'cause let's say I just have a single channel input image,
[00:14:47.640 --> 00:14:49.200]   so the number of channels is one,
[00:14:49.200 --> 00:14:52.400]   and let's say this is two to four by two to four.
[00:14:52.400 --> 00:14:56.160]   Okay, two to four by two to four.
[00:14:56.160 --> 00:15:00.280]   And then let's say I have a convolution kernel
[00:15:00.280 --> 00:15:04.600]   that is also single channel, but it's three by three.
[00:15:04.600 --> 00:15:06.440]   Now, if this convolution kernel
[00:15:06.440 --> 00:15:09.680]   goes all the way across my image,
[00:15:10.760 --> 00:15:15.400]   then what's gonna happen is that my output member
[00:15:15.400 --> 00:15:19.680]   is going to be, I think it's gonna be two to two, right?
[00:15:19.680 --> 00:15:23.040]   'Cause it's gonna skip, it's gonna miss the two boundaries,
[00:15:23.040 --> 00:15:24.240]   it's gonna miss the location.
[00:15:24.240 --> 00:15:29.120]   So it's gonna be two to two by two to two.
[00:15:29.120 --> 00:15:33.160]   So what's happened is like starting
[00:15:33.160 --> 00:15:38.160]   from a bigger size image, our spatial features
[00:15:38.160 --> 00:15:41.760]   on when we do the first convolution are less.
[00:15:41.760 --> 00:15:44.880]   And then when we do the convolution filter,
[00:15:44.880 --> 00:15:49.880]   like these three points, like this point has actually,
[00:15:49.880 --> 00:15:54.120]   like that particular point of this second filter,
[00:15:54.120 --> 00:15:59.720]   this particular point has actually looked at those nine,
[00:15:59.720 --> 00:16:05.600]   basically those nine coordinates in the image, right?
[00:16:05.600 --> 00:16:07.360]   So I think this will be much more clear
[00:16:07.360 --> 00:16:09.640]   if I show you over here.
[00:16:09.640 --> 00:16:13.960]   Okay. So let's say this is my image.
[00:16:13.960 --> 00:16:18.960]   I apply my convolution filter. I get some output.
[00:16:18.960 --> 00:16:21.800]   So this particular pixel in my second layer
[00:16:21.800 --> 00:16:25.240]   has seen the nine pixels in my first layer, correct?
[00:16:25.240 --> 00:16:30.400]   And then when I do a convolution after this,
[00:16:30.400 --> 00:16:32.880]   so my next convolution happens on this,
[00:16:32.880 --> 00:16:36.920]   let's say I'm gonna use a different color.
[00:16:36.920 --> 00:16:38.760]   So let's say I'm using orange.
[00:16:38.760 --> 00:16:41.040]   So when I do a convolution on this,
[00:16:41.040 --> 00:16:43.800]   then these nine pixels have actually seen
[00:16:43.800 --> 00:16:45.080]   more of the image, right?
[00:16:45.080 --> 00:16:46.560]   So that they've seen almost,
[00:16:46.560 --> 00:16:49.480]   they've covered more of the first image.
[00:16:49.480 --> 00:16:52.000]   I hope this makes sense because then when we do this,
[00:16:52.000 --> 00:16:55.040]   then the next spatial filter has seen
[00:16:55.040 --> 00:16:56.600]   like more of the first image.
[00:16:56.600 --> 00:17:00.520]   So basically what we have is like you have first image,
[00:17:00.520 --> 00:17:02.880]   then you have a smaller spatial filter
[00:17:02.880 --> 00:17:05.040]   and then you have a smaller spatial filter.
[00:17:05.040 --> 00:17:08.840]   But this output is from that much.
[00:17:08.840 --> 00:17:11.000]   And then when you say this output
[00:17:11.000 --> 00:17:14.160]   is from that much of the second layer,
[00:17:14.160 --> 00:17:19.160]   but all of this is actually all of that yellow region.
[00:17:19.160 --> 00:17:22.800]   So the point that I wanna make here
[00:17:22.800 --> 00:17:26.680]   is that this single pixel here,
[00:17:26.680 --> 00:17:28.760]   let me just use a different color.
[00:17:28.760 --> 00:17:31.400]   So the point that I wanna make here
[00:17:31.400 --> 00:17:33.280]   is that this single pixel here
[00:17:33.280 --> 00:17:37.400]   has actually seen that much of the actual image.
[00:17:37.400 --> 00:17:42.080]   But this particular, again,
[00:17:42.080 --> 00:17:43.560]   I'm gonna use a different color,
[00:17:43.560 --> 00:17:45.520]   but the, so this is again, my,
[00:17:45.520 --> 00:17:49.160]   I'm just gonna call this on zero.
[00:17:49.160 --> 00:17:51.040]   Let's say that's my input image.
[00:17:51.040 --> 00:17:52.360]   I'm gonna call this conf one
[00:17:52.360 --> 00:17:54.440]   and I'm gonna call this conf two, right?
[00:17:54.440 --> 00:17:57.600]   So conf two, when you do the convolution,
[00:17:57.600 --> 00:18:00.640]   like when you stack convolutions more and more on top,
[00:18:00.640 --> 00:18:05.640]   conf two has seen, like the, has interacted,
[00:18:05.640 --> 00:18:07.560]   or like the calculation is done
[00:18:07.560 --> 00:18:10.000]   with that much of the convolution one,
[00:18:10.000 --> 00:18:12.960]   that many spatial dimensions.
[00:18:12.960 --> 00:18:17.720]   And then similarly, all of that for convolution zero.
[00:18:17.720 --> 00:18:20.360]   So as we keep going down deeper and deeper
[00:18:20.360 --> 00:18:22.760]   into the convolution, basically,
[00:18:22.760 --> 00:18:25.880]   as we keep going down into the deeper and deeper layers,
[00:18:25.880 --> 00:18:29.120]   they have more context of the overall image.
[00:18:29.120 --> 00:18:31.160]   So when we keep going down deeper and deeper,
[00:18:31.160 --> 00:18:33.920]   there's gonna be a point when the convolution
[00:18:33.920 --> 00:18:36.000]   or basically the output activation
[00:18:36.000 --> 00:18:38.040]   would have seen maybe the whole of image.
[00:18:38.040 --> 00:18:40.280]   So this particular idea of,
[00:18:40.280 --> 00:18:43.840]   this way of like thinking of things
[00:18:43.840 --> 00:18:45.480]   is just called receptive field.
[00:18:45.480 --> 00:18:47.760]   So we just refer to this as the receptive field
[00:18:47.760 --> 00:18:49.360]   of the convolution kernel.
[00:18:49.360 --> 00:18:52.080]   So you can see there's this,
[00:18:52.080 --> 00:18:54.360]   there is this, if you go to the book's website,
[00:18:54.360 --> 00:18:56.160]   there is this Excel spreadsheet
[00:18:56.160 --> 00:18:57.800]   that shows the receptive field,
[00:18:57.800 --> 00:19:00.000]   but it is exactly what I've explained here.
[00:19:00.000 --> 00:19:02.520]   Is that as you go down deeper and deeper
[00:19:02.520 --> 00:19:03.960]   into the convolution network,
[00:19:03.960 --> 00:19:06.240]   it has seen more and more of the image
[00:19:06.240 --> 00:19:08.160]   or like interacted with more and more of the image
[00:19:08.160 --> 00:19:10.320]   or looked at more and more pixels.
[00:19:10.320 --> 00:19:12.720]   So that's just this basic idea of receptive field.
[00:19:12.720 --> 00:19:14.640]   It's not something that will,
[00:19:14.640 --> 00:19:17.120]   it's really handy to know,
[00:19:17.120 --> 00:19:21.440]   but like not like not knowing this would not mean
[00:19:21.440 --> 00:19:23.120]   that you can't train a CNN.
[00:19:23.120 --> 00:19:24.680]   So you can still train a CNN
[00:19:24.680 --> 00:19:26.560]   in case you didn't know about receptive fields,
[00:19:26.560 --> 00:19:27.680]   but that's just something
[00:19:27.680 --> 00:19:28.680]   I want to share.
[00:19:28.680 --> 00:19:31.560]   Another thing that this,
[00:19:31.560 --> 00:19:33.400]   and this is actually an interesting one.
[00:19:33.400 --> 00:19:35.160]   So let me just go with,
[00:19:35.160 --> 00:19:37.880]   I just want to go at the top and see where my index is.
[00:19:37.880 --> 00:19:50.960]   This should show my index.
[00:19:50.960 --> 00:19:51.960]   Okay, there it is.
[00:19:51.960 --> 00:19:52.800]   That's bad.
[00:19:52.800 --> 00:19:56.080]   And I'm just going to go down back to
[00:19:57.480 --> 00:19:58.640]   a note about Twitter.
[00:19:58.640 --> 00:19:59.680]   Okay.
[00:19:59.680 --> 00:20:01.520]   So then the,
[00:20:01.520 --> 00:20:04.320]   if there's any questions about receptive fields,
[00:20:04.320 --> 00:20:06.760]   let me just go back and have a look.
[00:20:06.760 --> 00:20:08.440]   If there's any questions about receptive field,
[00:20:08.440 --> 00:20:10.240]   the questions so far.
[00:20:10.240 --> 00:20:13.680]   This may be a,
[00:20:13.680 --> 00:20:15.400]   why do we train ReSNAP50?
[00:20:15.400 --> 00:20:19.200]   Why do we train ReSNAP50 from scratch
[00:20:19.200 --> 00:20:21.400]   and why not import weights from ImageNet?
[00:20:21.400 --> 00:20:25.680]   Sorry, let me know if there's a lot of background.
[00:20:25.680 --> 00:20:28.360]   This is just a plain classifier.
[00:20:28.360 --> 00:20:33.920]   I'll just shut down the door to see what's there.
[00:20:33.920 --> 00:20:37.640]   That should be better.
[00:20:37.640 --> 00:20:39.800]   Okay.
[00:20:39.800 --> 00:20:40.880]   So the question is,
[00:20:40.880 --> 00:20:42.840]   why do we not import weights
[00:20:42.840 --> 00:20:44.400]   or why do we do this?
[00:20:44.400 --> 00:20:47.840]   Where are we training ReSNAP50?
[00:20:47.840 --> 00:20:50.320]   Like, is this for pets or,
[00:20:50.320 --> 00:20:52.720]   like in which context is this question from,
[00:20:52.720 --> 00:20:53.840]   is my question.
[00:20:53.840 --> 00:20:56.320]   So like, is this for pets classifier?
[00:20:56.320 --> 00:21:00.360]   If you could please comment and reply to this
[00:21:00.360 --> 00:21:01.200]   and let me,
[00:21:01.200 --> 00:21:02.680]   and provide me with more context.
[00:21:02.680 --> 00:21:04.760]   It's like we've trained ReSNAP50
[00:21:04.760 --> 00:21:07.600]   at a few different situations or a few different cases.
[00:21:07.600 --> 00:21:10.280]   So where is this coming from, please?
[00:21:10.280 --> 00:21:12.920]   Okay.
[00:21:12.920 --> 00:21:15.120]   So now I'm gonna go back to Twitter.
[00:21:15.120 --> 00:21:16.360]   Something I do wanna
[00:21:16.360 --> 00:21:19.920]   actually talk about is,
[00:21:19.920 --> 00:21:22.000]   you know, every week I show you the,
[00:21:22.000 --> 00:21:25.440]   every week I show you these PowerPoint slides about like,
[00:21:25.440 --> 00:21:28.200]   oh, some Neerzy did a nice blog post
[00:21:28.200 --> 00:21:29.560]   on collaborative filtering
[00:21:29.560 --> 00:21:31.760]   or Durga did a nice blog post
[00:21:31.760 --> 00:21:35.160]   on Prime Minister Modi's beard.
[00:21:35.160 --> 00:21:37.080]   But where do I actually find them?
[00:21:37.080 --> 00:21:39.560]   I find all of this on Twitter.
[00:21:39.560 --> 00:21:44.560]   So Twitter, there's a really, really strong ML.
[00:21:44.560 --> 00:21:48.400]   There's a really, really strong ML community on Twitter.
[00:21:48.400 --> 00:21:51.760]   And I pretty much use Twitter to highlight all of my work
[00:21:51.760 --> 00:21:53.000]   and blog posts.
[00:21:53.000 --> 00:21:56.280]   And that's something that's definitely worked in my favor.
[00:21:56.280 --> 00:21:58.640]   So I also recently gave a talk about like,
[00:21:58.640 --> 00:22:01.600]   how to publicly share your work at the AI Hub.
[00:22:01.600 --> 00:22:03.560]   So I can try and find the link for that
[00:22:03.560 --> 00:22:05.480]   and put it on the blog post.
[00:22:05.480 --> 00:22:07.840]   But basically the idea is,
[00:22:07.840 --> 00:22:11.360]   Twitter is this place where this,
[00:22:11.360 --> 00:22:15.280]   Twitter is this single place where the ML researchers
[00:22:15.280 --> 00:22:16.680]   are really, really active.
[00:22:16.680 --> 00:22:19.880]   You'd be surprised to see like a paper gets highlighted.
[00:22:19.880 --> 00:22:22.280]   For example, let's have a look at this one.
[00:22:22.280 --> 00:22:25.280]   There was one by Bharat Soukh that he's a researcher.
[00:22:25.280 --> 00:22:26.400]   Yes, this one.
[00:22:26.400 --> 00:22:28.960]   So the way I keep up with research papers
[00:22:28.960 --> 00:22:30.520]   is mostly on Twitter,
[00:22:30.520 --> 00:22:33.320]   or the way even I ask questions is mostly on Twitter.
[00:22:33.320 --> 00:22:35.000]   And I learned this from Jeremy.
[00:22:35.000 --> 00:22:37.280]   Like this is not something I learned on my own.
[00:22:37.280 --> 00:22:39.800]   This is something I picked up from Jeremy.
[00:22:39.800 --> 00:22:41.960]   And when I was reading "Fastbook,"
[00:22:41.960 --> 00:22:43.560]   the first time I saw like,
[00:22:43.560 --> 00:22:45.360]   I saw this section about Twitter
[00:22:45.360 --> 00:22:46.880]   and I didn't know about Twitter.
[00:22:46.880 --> 00:22:48.720]   Like I didn't know like how active
[00:22:48.720 --> 00:22:50.720]   the machine learning community is on Twitter.
[00:22:50.720 --> 00:22:53.720]   And this is something I was so surprised to learn
[00:22:53.720 --> 00:22:56.360]   and find out that now I'm actually using Twitter
[00:22:56.360 --> 00:22:59.480]   on a daily basis for at least a few minutes a day.
[00:22:59.480 --> 00:23:01.440]   And you can see Bharat Soukh
[00:23:01.440 --> 00:23:03.640]   is a senior research scientist at Google Brain.
[00:23:03.640 --> 00:23:06.280]   And he recently published a paper,
[00:23:06.280 --> 00:23:09.800]   which is called, I think it's called "Multitask."
[00:23:09.800 --> 00:23:12.520]   Or let me just double check what that is called
[00:23:12.520 --> 00:23:13.840]   when that opens.
[00:23:13.840 --> 00:23:16.080]   But the point is like,
[00:23:17.120 --> 00:23:20.120]   there's this paper that tries to answer this question,
[00:23:20.120 --> 00:23:21.480]   which is how do we combine knowledge
[00:23:21.480 --> 00:23:23.840]   from multiple labeled and unlabeled datasets
[00:23:23.840 --> 00:23:27.400]   to train a great general model?
[00:23:27.400 --> 00:23:31.040]   And you can see that that's being discussed on Twitter.
[00:23:31.040 --> 00:23:33.800]   There's an example, there's visualizations,
[00:23:33.800 --> 00:23:35.600]   there's the results of that.
[00:23:35.600 --> 00:23:39.320]   There's what happens when you add more pseudo labels.
[00:23:39.320 --> 00:23:41.720]   They studied like a suite on different tasks,
[00:23:41.720 --> 00:23:43.720]   these are different experiments that were done.
[00:23:43.720 --> 00:23:45.640]   And looks like archives now.
[00:23:45.640 --> 00:23:50.640]   Anyway, and then there were like this different experiment
[00:23:50.640 --> 00:23:53.000]   on what if they already trained the checkpoint.
[00:23:53.000 --> 00:23:54.640]   So the point is like Twitter is this,
[00:23:54.640 --> 00:23:57.280]   and this is as of 12 hours ago.
[00:23:57.280 --> 00:23:59.520]   So you can see the value,
[00:23:59.520 --> 00:24:01.120]   there's a lot of value in Twitter
[00:24:01.120 --> 00:24:02.360]   and to be active on Twitter.
[00:24:02.360 --> 00:24:05.520]   So please, as you write your blog posts,
[00:24:05.520 --> 00:24:08.200]   use Twitter to highlight and publicly share your work.
[00:24:08.200 --> 00:24:12.080]   Like use Twitter as a platform where you follow people,
[00:24:12.080 --> 00:24:15.440]   use Twitter as a platform where you share knowledge
[00:24:15.440 --> 00:24:18.920]   and then eventually you'll see in your deep learning journeys
[00:24:18.920 --> 00:24:22.120]   that you'll get to a point where you're using Twitter
[00:24:22.120 --> 00:24:24.600]   on a daily basis to like keep up with,
[00:24:24.600 --> 00:24:26.120]   oh, what's new in this world.
[00:24:26.120 --> 00:24:31.120]   So it's even more so like Twitter is possibly,
[00:24:31.120 --> 00:24:36.000]   is 90% of the updates that are fine on what's going on
[00:24:36.000 --> 00:24:39.800]   with say team or what's going on with research side
[00:24:39.800 --> 00:24:42.000]   of things is from Twitter.
[00:24:42.000 --> 00:24:45.200]   And in fact, I even have notifications turned on
[00:24:45.200 --> 00:24:48.960]   for a few people that I do have to follow on Twitter.
[00:24:48.960 --> 00:24:50.240]   So these are like these different things
[00:24:50.240 --> 00:24:52.000]   that you can try.
[00:24:52.000 --> 00:24:53.480]   And I know I'm taking a lot of time
[00:24:53.480 --> 00:24:56.680]   just to talk about Twitter right now,
[00:24:56.680 --> 00:25:00.520]   but see like even this example from Jeremy.
[00:25:00.520 --> 00:25:05.000]   So when he was working on,
[00:25:05.000 --> 00:25:06.400]   Jeremy just wanted to double check,
[00:25:06.400 --> 00:25:10.200]   like what was it when he wanted to basically use
[00:25:10.200 --> 00:25:11.280]   Stripe to Convolutions.
[00:25:11.280 --> 00:25:13.920]   And he just wanted to ask that what was written
[00:25:13.920 --> 00:25:15.800]   in this book about Stripe to Convolutions,
[00:25:15.800 --> 00:25:16.960]   was that accurate?
[00:25:16.960 --> 00:25:18.400]   So he pretty much asked on Twitter,
[00:25:18.400 --> 00:25:20.160]   it's like, I forget why did we move?
[00:25:20.160 --> 00:25:22.160]   Like he basically asked the question
[00:25:22.160 --> 00:25:23.760]   and then Christian Zegedi,
[00:25:23.760 --> 00:25:26.200]   he's the author of I think InceptionNet.
[00:25:26.200 --> 00:25:28.360]   So there we go.
[00:25:28.360 --> 00:25:30.520]   Christian Zegedi is the first author of Inception
[00:25:30.520 --> 00:25:32.800]   and he's the 2014 ImageNet winner
[00:25:32.800 --> 00:25:34.960]   and he's responding to that question.
[00:25:34.960 --> 00:25:37.280]   And then you can see Jan Le Coon,
[00:25:37.280 --> 00:25:41.960]   he's definitely, Jan Le Coon
[00:25:41.960 --> 00:25:44.280]   and he's a Turing Award winners.
[00:25:44.280 --> 00:25:47.040]   And we talked about him in chapter production as well,
[00:25:47.040 --> 00:25:51.560]   but you can see like all of the highly influential people
[00:25:51.560 --> 00:25:53.080]   are on Twitter.
[00:25:53.080 --> 00:25:55.960]   So if I, and people who have defined
[00:25:55.960 --> 00:25:58.080]   kind of the way deep learning is.
[00:25:58.080 --> 00:25:59.680]   So if I search Jan Le Coon,
[00:25:59.680 --> 00:26:02.320]   you can see and there's like a lot of tweets.
[00:26:02.320 --> 00:26:05.640]   You can see that there's,
[00:26:05.640 --> 00:26:08.120]   again he retweeted something seven hours ago,
[00:26:08.120 --> 00:26:10.120]   which is about ruling Facebook Pay
[00:26:10.120 --> 00:26:11.680]   or like there's all of these different things
[00:26:11.680 --> 00:26:13.480]   that you can follow on Twitter.
[00:26:13.480 --> 00:26:19.520]   So I would definitely, definitely say
[00:26:19.520 --> 00:26:21.200]   from this point forward,
[00:26:21.200 --> 00:26:24.160]   use Twitter as a platform to share your work
[00:26:24.160 --> 00:26:27.600]   and use Twitter as a platform to follow other people's work.
[00:26:27.600 --> 00:26:30.040]   And the best way to get started with Twitter
[00:26:30.040 --> 00:26:32.760]   is just to follow Jeremy
[00:26:32.760 --> 00:26:35.280]   and then see the people that he follows.
[00:26:35.280 --> 00:26:36.400]   Like that's how I started.
[00:26:36.400 --> 00:26:38.840]   I just went to Jeremy's profile and I saw like,
[00:26:38.840 --> 00:26:39.960]   okay, he follows about,
[00:26:39.960 --> 00:26:42.360]   he used to follow about a thousand people at the time.
[00:26:42.360 --> 00:26:44.400]   And then I followed all of those thousand people.
[00:26:44.400 --> 00:26:48.360]   And then suddenly my homepage was full of research papers.
[00:26:48.360 --> 00:26:50.560]   And then as you go, you're like, okay,
[00:26:50.560 --> 00:26:52.560]   these particular kinds of research papers
[00:26:52.560 --> 00:26:54.040]   are not useful to me.
[00:26:54.040 --> 00:26:56.960]   So you don't follow them, like you unfollow them.
[00:26:56.960 --> 00:26:59.520]   And that's how you then build your Twitter profile.
[00:26:59.520 --> 00:27:00.960]   So I just want to share this,
[00:27:00.960 --> 00:27:04.480]   share that definitely from going forward,
[00:27:04.480 --> 00:27:07.240]   please, please get more active on Twitter
[00:27:07.240 --> 00:27:09.000]   'cause it will definitely help you.
[00:27:09.560 --> 00:27:11.720]   (claps)
[00:27:11.720 --> 00:27:15.360]   Okay, so now we're back to color images.
[00:27:15.360 --> 00:27:18.000]   So a color, sorry, just give me one sec, please.
[00:27:18.000 --> 00:27:23.520]   One sec.
[00:27:23.520 --> 00:27:31.400]   Okay, so now we,
[00:27:31.400 --> 00:27:35.640]   oh, give me just 'cause I did the opposite.
[00:27:35.640 --> 00:27:39.240]   I followed you and I followed you and Sayem first
[00:27:39.240 --> 00:27:40.240]   and then onwards.
[00:27:40.240 --> 00:27:41.080]   I think that's also fine.
[00:27:41.080 --> 00:27:42.640]   Sayem and I pretty much follow,
[00:27:42.640 --> 00:27:48.160]   I think most of the, like Sayem also has lists.
[00:27:48.160 --> 00:27:50.960]   So on Twitter, Sayem also has these machine learning lists
[00:27:50.960 --> 00:27:54.360]   where he's brought all of the people
[00:27:54.360 --> 00:27:55.600]   in the fast.ai community.
[00:27:55.600 --> 00:27:58.320]   So he's got like these different lists that he follows.
[00:27:58.320 --> 00:27:59.920]   He's got a list of I think researchers.
[00:27:59.920 --> 00:28:02.320]   He's got a list for fast.ai folks.
[00:28:02.320 --> 00:28:04.800]   So do check that out as well.
[00:28:04.800 --> 00:28:07.920]   But either way should be fine to get you started.
[00:28:07.920 --> 00:28:11.360]   Okay, so color images.
[00:28:11.360 --> 00:28:13.680]   So now we're back to like, how does this convolution,
[00:28:13.680 --> 00:28:16.600]   like until now we've just looked at convolutions
[00:28:16.600 --> 00:28:18.960]   on single channel images.
[00:28:18.960 --> 00:28:20.720]   We haven't really looked at color images
[00:28:20.720 --> 00:28:23.640]   or how that is different with color images.
[00:28:23.640 --> 00:28:25.840]   So let's do that now.
[00:28:25.840 --> 00:28:27.920]   So how does that look like?
[00:28:27.920 --> 00:28:32.920]   So we already know color images are blue RGB basically.
[00:28:33.440 --> 00:28:35.560]   So let me just, I draw that blue.
[00:28:35.560 --> 00:28:38.880]   I'm gonna draw a red.
[00:28:38.880 --> 00:28:45.360]   Just need to make that thin.
[00:28:45.360 --> 00:28:49.080]   And finally a green.
[00:28:49.080 --> 00:28:56.400]   All right, so that's RGB, right?
[00:28:56.400 --> 00:28:57.600]   So that's my RGB image.
[00:28:57.600 --> 00:28:58.680]   That's my input.
[00:28:58.680 --> 00:29:01.040]   And now when I'm gonna do a convolution,
[00:29:01.040 --> 00:29:03.080]   the way that convolution looks like,
[00:29:03.080 --> 00:29:05.320]   like how is that any different
[00:29:05.320 --> 00:29:07.640]   for a three channel input image
[00:29:07.640 --> 00:29:09.720]   versus a single channel input image?
[00:29:09.720 --> 00:29:12.160]   The only difference that you will see over here,
[00:29:12.160 --> 00:29:14.320]   as you can see like every image,
[00:29:14.320 --> 00:29:16.400]   if you see like every image is basically
[00:29:16.400 --> 00:29:18.800]   consists of three channels, red, green, and blue.
[00:29:18.800 --> 00:29:21.000]   And then the only difference that you will see
[00:29:21.000 --> 00:29:24.640]   is like you have now basically your kernel size.
[00:29:24.640 --> 00:29:25.880]   In your kernel, you just define
[00:29:25.880 --> 00:29:28.520]   your input number of channels is three.
[00:29:28.520 --> 00:29:32.560]   So what you have, instead of having a single channel kernel,
[00:29:32.560 --> 00:29:34.200]   you have a three channel kernel.
[00:29:34.200 --> 00:29:37.000]   So you have one channel for blue,
[00:29:37.000 --> 00:29:39.040]   you have one channel for red,
[00:29:39.040 --> 00:29:41.280]   and you have one channel for green.
[00:29:41.280 --> 00:29:45.000]   So now instead of like having a single channel kernel
[00:29:45.000 --> 00:29:46.120]   that we used to have,
[00:29:46.120 --> 00:29:47.720]   like we used to have single channel kernel,
[00:29:47.720 --> 00:29:50.360]   now we have a three channel.
[00:29:50.360 --> 00:29:55.360]   So this is all, actually I should just draw this like that.
[00:29:55.360 --> 00:30:00.480]   So now that becomes my kernel, okay?
[00:30:00.480 --> 00:30:05.480]   And what happens is, so if that's my kernel,
[00:30:05.480 --> 00:30:09.680]   what happens is this three channel kernel
[00:30:09.680 --> 00:30:13.240]   will again go around the three channel image
[00:30:13.240 --> 00:30:14.920]   in the similar manner as it did
[00:30:14.920 --> 00:30:16.840]   for a single channel image, okay?
[00:30:16.840 --> 00:30:21.560]   So what that means is that you have your blue channel,
[00:30:21.560 --> 00:30:22.760]   you have your blue kernel,
[00:30:22.760 --> 00:30:24.480]   and it's gonna go all the way around.
[00:30:24.480 --> 00:30:26.240]   You have your red channel,
[00:30:26.240 --> 00:30:28.920]   then the red kernel is gonna go all the way around.
[00:30:28.920 --> 00:30:31.320]   You have your green channel,
[00:30:31.320 --> 00:30:33.960]   and the same thing for the green kernel, okay?
[00:30:33.960 --> 00:30:36.720]   And then what you have, as you can see here,
[00:30:36.720 --> 00:30:39.560]   you get the outputs and you just add them up.
[00:30:39.560 --> 00:30:43.000]   So this is how you do convolution with color images.
[00:30:43.000 --> 00:30:46.960]   So remember this, when I have my red,
[00:30:46.960 --> 00:30:49.840]   basically my blue, red, and green,
[00:30:49.840 --> 00:30:53.840]   I can just, like this thing is gonna give me some output,
[00:30:53.840 --> 00:30:55.960]   this thing is gonna give me some output,
[00:30:55.960 --> 00:31:00.280]   and the last one is also gonna give me some output, right?
[00:31:00.280 --> 00:31:02.400]   So this is gonna give me one feature map.
[00:31:02.400 --> 00:31:04.160]   Actually, I should just start with blue.
[00:31:04.160 --> 00:31:06.360]   So it's gonna give me like a smaller blue feature map.
[00:31:06.360 --> 00:31:09.120]   This one is gonna give me a smaller red feature map.
[00:31:09.120 --> 00:31:14.800]   Blue, red, green.
[00:31:14.800 --> 00:31:18.160]   And you basically just add them up.
[00:31:18.160 --> 00:31:19.680]   So you just add them up
[00:31:22.720 --> 00:31:26.200]   to get your final thing, your final output.
[00:31:26.200 --> 00:31:29.720]   So that's how this thing works.
[00:31:29.720 --> 00:31:32.760]   Let me show you, just show you an example.
[00:31:32.760 --> 00:31:37.240]   So if I have, say, my input, so import torch,
[00:31:37.240 --> 00:31:48.560]   my input is torch one, three, two to four by two to four.
[00:31:48.560 --> 00:31:52.000]   That just means I have a single image,
[00:31:52.000 --> 00:31:55.160]   single three-channel image of two to four by two to four.
[00:31:55.160 --> 00:31:56.800]   I can say my conf,
[00:31:56.800 --> 00:32:01.320]   I should also import torch.nn,
[00:32:01.320 --> 00:32:06.880]   import torch.nn as nn,
[00:32:06.880 --> 00:32:11.280]   and I can just have nn.conf2d,
[00:32:11.280 --> 00:32:14.800]   and I just say my input number of channels is one,
[00:32:14.800 --> 00:32:18.040]   out channels is one, and the kernel size is three.
[00:32:18.040 --> 00:32:20.320]   All right, and then I can just do conf x,
[00:32:20.320 --> 00:32:22.840]   and I can check my output shape.
[00:32:22.840 --> 00:32:27.400]   So as you can see, now the output is basically,
[00:32:27.400 --> 00:32:29.720]   it's one feature map because you had one input,
[00:32:29.720 --> 00:32:31.720]   but the number of channels in your output is one
[00:32:31.720 --> 00:32:33.920]   'cause we set output channels as one.
[00:32:33.920 --> 00:32:37.520]   We could have also done output channels as, say, 64,
[00:32:37.520 --> 00:32:40.440]   in which case we would have gotten 64 channels in our output.
[00:32:40.440 --> 00:32:42.440]   So this is, again, very, very similar
[00:32:42.440 --> 00:32:44.200]   to what we did for single channel.
[00:32:44.200 --> 00:32:46.360]   Instead, it's just being occurred for three channels.
[00:32:46.360 --> 00:32:49.600]   So in your three channel, you just have a 3D kernel.
[00:32:49.600 --> 00:32:54.600]   So one of the differences that's key over here
[00:32:54.600 --> 00:32:58.800]   is even though it's called convolution 2D,
[00:32:58.800 --> 00:33:02.080]   so you will see in convolutions, you'll find three things.
[00:33:02.080 --> 00:33:02.920]   You'll find,
[00:33:02.920 --> 00:33:10.120]   in convolutions, you'll find conf 1D,
[00:33:10.120 --> 00:33:14.880]   you'll find conf 2D, conf 3D, and so on.
[00:33:14.880 --> 00:33:18.520]   But right now, we're looking at this 2D conf,
[00:33:18.520 --> 00:33:21.280]   and what you did see over here is like
[00:33:21.280 --> 00:33:24.120]   the convolution kernel is actually 3D, right?
[00:33:24.120 --> 00:33:26.800]   'Cause it has three channels, red, green, and blue.
[00:33:26.800 --> 00:33:28.880]   So conf 2D doesn't really mean
[00:33:28.880 --> 00:33:31.680]   that your kernel size is 2D as well.
[00:33:31.680 --> 00:33:33.760]   It just means it goes in two dimensions.
[00:33:33.760 --> 00:33:36.160]   It just means it goes, so if this is my image,
[00:33:36.160 --> 00:33:37.840]   it just means it goes across the height
[00:33:37.840 --> 00:33:39.120]   and it goes across the width.
[00:33:39.120 --> 00:33:41.720]   So it's just the convolution kernel is just going
[00:33:41.720 --> 00:33:44.760]   in towards your width and towards your height.
[00:33:44.760 --> 00:33:46.240]   So that's just the main difference
[00:33:46.240 --> 00:33:48.120]   that I did wanna highlight over here.
[00:33:48.120 --> 00:33:50.920]   Are there any questions on convolutions?
[00:33:50.920 --> 00:33:54.920]   Let me just go, oh, there's quite a few questions.
[00:33:54.920 --> 00:33:56.760]   Okay, let's cover these up.
[00:33:56.760 --> 00:34:03.480]   Okay, is conf 2 uses a receptive field of both conf 1
[00:34:03.480 --> 00:34:05.760]   and the one before that for the final convolutions?
[00:34:05.760 --> 00:34:07.960]   No, it's just using conf 1.
[00:34:07.960 --> 00:34:09.840]   So I guess there's some,
[00:34:09.840 --> 00:34:14.200]   it's unclear on what receptive fields are.
[00:34:14.200 --> 00:34:16.280]   So if this is my input, right?
[00:34:16.280 --> 00:34:17.960]   This is my input image.
[00:34:17.960 --> 00:34:21.600]   If I apply, let's say my,
[00:34:21.600 --> 00:34:25.840]   I apply that massive convolution kernel on,
[00:34:25.840 --> 00:34:30.560]   like this is say my input image is two to four by two to four
[00:34:30.560 --> 00:34:34.480]   and let's say my kernel is 64 by 64, right?
[00:34:34.480 --> 00:34:35.640]   So what's that gonna do?
[00:34:35.640 --> 00:34:38.120]   That's gonna produce one output, right?
[00:34:38.120 --> 00:34:39.600]   This is something we covered last week.
[00:34:39.600 --> 00:34:41.120]   It's gonna have one output.
[00:34:41.120 --> 00:34:44.320]   And then this is gonna go all the way around.
[00:34:44.320 --> 00:34:48.160]   So if it goes, let's say it brings over here,
[00:34:48.160 --> 00:34:51.360]   then this 64 by 64, all of this block
[00:34:51.360 --> 00:34:52.960]   is then gonna produce one output.
[00:34:52.960 --> 00:34:57.120]   So you have a smaller size feature map, right?
[00:34:57.120 --> 00:35:00.480]   This is my smaller size feature map.
[00:35:00.480 --> 00:35:02.080]   So let's say, I'm not exactly sure
[00:35:02.080 --> 00:35:03.720]   on what the dimensions would be.
[00:35:03.720 --> 00:35:05.160]   Maybe let's just find out.
[00:35:05.160 --> 00:35:09.600]   I should be able to do this, but sadly I'm really bad.
[00:35:09.600 --> 00:35:12.400]   So let's say my input is one by one
[00:35:12.400 --> 00:35:14.680]   and this is just something you should also,
[00:35:14.680 --> 00:35:17.840]   like if you don't understand anything on what the output is,
[00:35:17.840 --> 00:35:19.920]   I always just code it up.
[00:35:19.920 --> 00:35:23.960]   So my output, I have one channel and my kernel size is 64.
[00:35:23.960 --> 00:35:28.960]   So my con x.shape would be 161 by 161.
[00:35:28.960 --> 00:35:31.720]   Okay, thanks.
[00:35:31.720 --> 00:35:36.720]   So this is just gonna be 161 by 161.
[00:35:36.720 --> 00:35:41.200]   And then when you have your next convolution kernel,
[00:35:41.200 --> 00:35:44.880]   let's say I again have that massive convolution kernel.
[00:35:44.880 --> 00:35:49.240]   So all of that is then gonna produce one output.
[00:35:49.240 --> 00:35:52.800]   But what this output has seen
[00:35:52.800 --> 00:35:56.200]   is like it has seen all of the convolution kernel too,
[00:35:56.200 --> 00:35:58.400]   but all of these individual,
[00:35:58.400 --> 00:36:00.720]   basically all of these individual activations
[00:36:00.720 --> 00:36:03.680]   or all of these individual outputs from the convolution
[00:36:03.680 --> 00:36:07.160]   had come from these massive receptive fields before.
[00:36:07.160 --> 00:36:09.840]   So they've seen, so in turn,
[00:36:09.840 --> 00:36:13.720]   this particular pixel in my conv two
[00:36:13.720 --> 00:36:16.960]   has seen like a bigger part of conv one,
[00:36:16.960 --> 00:36:19.160]   like it would have seen something like that
[00:36:19.160 --> 00:36:21.040]   than just 64 by 64.
[00:36:21.040 --> 00:36:23.240]   So that's just what I wanted to make.
[00:36:23.240 --> 00:36:24.800]   Like that was the point that I wanted to make
[00:36:24.800 --> 00:36:27.720]   about receptive fields is like, as we go down,
[00:36:27.720 --> 00:36:29.480]   the deeper layers of the convolution
[00:36:29.480 --> 00:36:31.720]   have seen just a bigger part of the image.
[00:36:31.720 --> 00:36:36.280]   I hope it is clear now, Durga.
[00:36:37.720 --> 00:36:39.840]   I mean, what's the, oh, sorry.
[00:36:39.840 --> 00:36:40.680]   Thanks.
[00:36:40.680 --> 00:36:41.800]   This is what's the necessity of training
[00:36:41.800 --> 00:36:43.640]   an architecture model from scratch?
[00:36:43.640 --> 00:36:45.640]   Why not initialize the model directly?
[00:36:45.640 --> 00:36:46.480]   Okay.
[00:36:46.480 --> 00:36:47.320]   And that's a really good question.
[00:36:47.320 --> 00:36:49.760]   Generally, almost always you wanna start
[00:36:49.760 --> 00:36:51.160]   with pre-trained weights.
[00:36:51.160 --> 00:36:56.880]   And you would train from scratch in particular
[00:36:56.880 --> 00:37:01.120]   in cases where the, like the dataset that you're working on
[00:37:01.120 --> 00:37:02.960]   is completely, completely different
[00:37:02.960 --> 00:37:05.080]   from what you're trying to do.
[00:37:05.080 --> 00:37:07.840]   So for example, if you're working with cellular data
[00:37:07.840 --> 00:37:10.520]   or like histopathology,
[00:37:10.520 --> 00:37:12.720]   or like you're working with medical data,
[00:37:12.720 --> 00:37:15.840]   so there could be cases where ImageNet images
[00:37:15.840 --> 00:37:17.680]   are going to be very, very different
[00:37:17.680 --> 00:37:22.160]   with the medical images that you're trying to work on.
[00:37:22.160 --> 00:37:25.400]   And then in that case, you would wanna start from scratch.
[00:37:25.400 --> 00:37:28.760]   But particularly for all of these tasks,
[00:37:28.760 --> 00:37:30.200]   like for PETS classification,
[00:37:30.200 --> 00:37:31.640]   for all of these different tasks,
[00:37:31.640 --> 00:37:34.440]   you could start with initialized weights
[00:37:34.440 --> 00:37:36.040]   that are trained on ImageNet.
[00:37:36.040 --> 00:37:38.360]   So I hope that answers the question.
[00:37:38.360 --> 00:37:39.640]   It's like most generally,
[00:37:39.640 --> 00:37:42.560]   you wanna start with pre-trained weights.
[00:37:42.560 --> 00:37:45.400]   And then if your downstream dataset
[00:37:45.400 --> 00:37:47.160]   or the task that you're trying to do
[00:37:47.160 --> 00:37:49.080]   is very, very different from ImageNet,
[00:37:49.080 --> 00:37:51.160]   that is when you would try starting
[00:37:51.160 --> 00:37:53.280]   and training an architecture from scratch.
[00:37:53.280 --> 00:37:55.040]   Okay.
[00:37:55.040 --> 00:37:58.000]   Naresh has answered this one for me.
[00:37:58.000 --> 00:37:59.320]   So thanks very much.
[00:37:59.320 --> 00:38:02.320]   Usually we want to use some sort of pre-training.
[00:38:02.320 --> 00:38:04.760]   Okay, that's again, that's a good answer.
[00:38:04.760 --> 00:38:05.800]   Thanks very much.
[00:38:05.800 --> 00:38:07.880]   Oh, thanks for sharing this one.
[00:38:07.880 --> 00:38:09.400]   My Queensland AI Hub talk.
[00:38:09.400 --> 00:38:13.080]   So yes, if I go to this Queensland AI Hub talk,
[00:38:13.080 --> 00:38:15.280]   I won't play it, but you can see like,
[00:38:15.280 --> 00:38:18.440]   I kind of, this is where my past AI journey started
[00:38:18.440 --> 00:38:21.000]   and these were, it's not very clear, is it?
[00:38:21.000 --> 00:38:25.000]   And then in this talk,
[00:38:25.000 --> 00:38:26.520]   there was like all of these different papers
[00:38:26.520 --> 00:38:27.680]   that I was reading at the time.
[00:38:27.680 --> 00:38:30.160]   And then I just kind of shared my journey
[00:38:30.160 --> 00:38:32.040]   on how I started with one paper
[00:38:32.040 --> 00:38:34.600]   and then went on to all the other papers.
[00:38:34.600 --> 00:38:35.720]   Ah, it's a really bad quality.
[00:38:35.720 --> 00:38:38.840]   I should reach out to Queensland AI Hub about that.
[00:38:38.840 --> 00:38:40.760]   Okay, leave that one with me.
[00:38:40.760 --> 00:38:42.560]   But basically that was the talk.
[00:38:42.560 --> 00:38:43.800]   Thanks for sharing, Alan.
[00:38:43.800 --> 00:38:47.240]   So it will not be sufficient just to do convolutions.
[00:38:47.240 --> 00:38:48.760]   I hope this has been answered.
[00:38:48.760 --> 00:38:52.160]   Impressively close.
[00:38:52.160 --> 00:38:54.560]   Okay, that's something we can talk about later.
[00:38:54.560 --> 00:38:56.720]   Cool.
[00:38:56.720 --> 00:38:59.760]   So thanks for the great questions.
[00:38:59.760 --> 00:39:01.640]   And I hope now it's also clear
[00:39:01.640 --> 00:39:04.000]   about what's going on with colored images.
[00:39:04.000 --> 00:39:06.040]   So now I feel from this point forward,
[00:39:06.040 --> 00:39:08.280]   like there isn't a lot to Peter.
[00:39:08.280 --> 00:39:11.000]   There isn't a lot that's new in this chapter.
[00:39:11.000 --> 00:39:12.480]   But if you go back and you start looking
[00:39:12.480 --> 00:39:14.280]   at the chapter 13 convolutions,
[00:39:14.280 --> 00:39:15.960]   everything should be clear to you now.
[00:39:15.960 --> 00:39:18.600]   You shouldn't have even a single question about like,
[00:39:18.600 --> 00:39:20.680]   oh, what's happening over here?
[00:39:20.680 --> 00:39:25.480]   Or like, why is this output of that particular shade?
[00:39:25.480 --> 00:39:27.920]   So have a think about all of that.
[00:39:27.920 --> 00:39:30.000]   And if there's any questions,
[00:39:30.000 --> 00:39:32.320]   I suggest we reach out to me on the forums.
[00:39:32.320 --> 00:39:34.120]   Okay.
[00:39:34.120 --> 00:39:38.720]   So now from this point on, we're in 1.4.
[00:39:38.720 --> 00:39:40.400]   At this point, we're gonna start looking
[00:39:40.400 --> 00:39:42.800]   at a simple baseline of convolutions.
[00:39:42.800 --> 00:39:46.480]   Then we're gonna see and understand the training stability,
[00:39:46.480 --> 00:39:48.040]   or we're gonna start looking at like,
[00:39:48.040 --> 00:39:51.720]   okay, how do we know that our network is stable
[00:39:51.720 --> 00:39:53.960]   and it's training nicely?
[00:39:53.960 --> 00:39:56.120]   And we're gonna look at this one cycle training.
[00:39:56.120 --> 00:39:58.400]   And finally, we're gonna wrap up with batch norm.
[00:39:58.400 --> 00:40:00.960]   These are the last four things for chapter 13.
[00:40:00.960 --> 00:40:06.880]   So, you know, we're just gonna grab our MNIST dataset.
[00:40:06.880 --> 00:40:10.040]   So MNIST is just 10, basically,
[00:40:10.040 --> 00:40:13.040]   MNIST is just basically 10 digits.
[00:40:13.040 --> 00:40:15.680]   So let me just create my data loaders
[00:40:15.680 --> 00:40:18.000]   and just show you the, show you the batch.
[00:40:18.000 --> 00:40:21.680]   When that runs, hopefully it won't take that long.
[00:40:21.680 --> 00:40:22.520]   Okay.
[00:40:22.520 --> 00:40:23.920]   So I've got like, this is what I have.
[00:40:23.920 --> 00:40:28.360]   Like my input dataset is basically, we have 10 digits.
[00:40:28.360 --> 00:40:32.200]   Which are 10 digit images of four is like,
[00:40:32.200 --> 00:40:34.840]   and the output labels are just what that digit is.
[00:40:34.840 --> 00:40:37.800]   So if you have an image of the input digit as four,
[00:40:37.800 --> 00:40:39.680]   the label for that is four.
[00:40:39.680 --> 00:40:42.640]   Or if you have an input digit of like handwritten digit zero,
[00:40:42.640 --> 00:40:44.480]   then the label that the model needs to classify
[00:40:44.480 --> 00:40:46.000]   is just zero.
[00:40:46.000 --> 00:40:47.760]   So in this case,
[00:40:47.760 --> 00:40:51.080]   you can just define a simple function called conv.
[00:40:51.080 --> 00:40:53.760]   What that does is that first it will create
[00:40:53.760 --> 00:40:56.960]   a convolution 2D, 'cause in deep learning,
[00:40:56.960 --> 00:40:59.800]   everything is just convolution, batch norm,
[00:40:59.800 --> 00:41:01.240]   Relu, pretty much.
[00:41:01.240 --> 00:41:03.480]   Right now, I haven't told you what batch norm is.
[00:41:03.480 --> 00:41:05.880]   So until now, what I want to say,
[00:41:05.880 --> 00:41:06.760]   okay, in deep learning,
[00:41:06.760 --> 00:41:08.720]   everything is convolution and Relu.
[00:41:08.720 --> 00:41:10.600]   So you can see, this is again, what's happening here.
[00:41:10.600 --> 00:41:14.480]   You have your convolution 2D and you have Relu.
[00:41:14.480 --> 00:41:17.360]   So what is nn.sequential?
[00:41:17.360 --> 00:41:19.560]   nn.sequential just means in PyTorch,
[00:41:19.560 --> 00:41:20.760]   it just says, okay,
[00:41:20.760 --> 00:41:23.640]   first, please apply convolution operation
[00:41:23.640 --> 00:41:26.240]   and then apply the Relu operation.
[00:41:26.240 --> 00:41:27.680]   So if you want to check out,
[00:41:27.680 --> 00:41:30.080]   if there's any questions about what Relu is,
[00:41:30.080 --> 00:41:33.160]   we've already discussed that this is an activation function,
[00:41:33.160 --> 00:41:35.560]   but this activation function basically,
[00:41:35.560 --> 00:41:40.560]   for everything that's negative,
[00:41:40.560 --> 00:41:43.920]   it gives us the value of zero.
[00:41:43.920 --> 00:41:45.240]   And for everything positive,
[00:41:45.240 --> 00:41:47.200]   it gives us the, basically,
[00:41:47.200 --> 00:41:48.520]   it gives us like a positive slope.
[00:41:48.520 --> 00:41:50.440]   So it just returns the positive value.
[00:41:50.440 --> 00:41:53.680]   So that's a non-linearity.
[00:41:53.680 --> 00:41:56.480]   So in this, I've just created a convolution function.
[00:41:56.480 --> 00:41:59.200]   It basically has, creates a convolution 2D,
[00:41:59.200 --> 00:42:00.840]   followed by a value.
[00:42:00.840 --> 00:42:01.880]   So you can just apply that.
[00:42:01.880 --> 00:42:04.760]   If I create something called conv,
[00:42:04.760 --> 00:42:06.600]   it says missing two input channels.
[00:42:06.600 --> 00:42:08.360]   So let's say input channels is one and three.
[00:42:08.360 --> 00:42:10.720]   So see how that creates a convolution 2D.
[00:42:10.720 --> 00:42:13.960]   So that's my first, and then that creates a value.
[00:42:13.960 --> 00:42:18.960]   So I could do something like ni nf for ni, nf,
[00:42:19.520 --> 00:42:24.520]   ni nf for ni, nf in zip.
[00:42:24.520 --> 00:42:31.600]   I'm just one, three, seven, nine.
[00:42:31.600 --> 00:42:37.240]   And I could have my second list as three, seven, nine, 12.
[00:42:37.240 --> 00:42:38.400]   Let's see if that works.
[00:42:38.400 --> 00:42:40.880]   Oh, I need to close the zip.
[00:42:40.880 --> 00:42:43.440]   Does that work?
[00:42:43.440 --> 00:42:44.280]   Yeah, there we go.
[00:42:44.280 --> 00:42:45.480]   So now I have basically,
[00:42:45.480 --> 00:42:48.360]   like I could create these bunch of convolutions
[00:42:48.360 --> 00:42:51.640]   and I could put this all again in a sequential.
[00:42:51.640 --> 00:42:55.440]   I'm just like showing you some coding techniques
[00:42:55.440 --> 00:42:59.200]   that I could do.
[00:42:59.200 --> 00:43:02.320]   I think I need to pass in a star over here.
[00:43:02.320 --> 00:43:03.160]   That work?
[00:43:03.160 --> 00:43:04.000]   Yeah, there we go.
[00:43:04.000 --> 00:43:06.320]   So I can basically now, what I've done,
[00:43:06.320 --> 00:43:09.480]   is like I was able to create four convolution.
[00:43:09.480 --> 00:43:12.640]   Like this is why you want to define everything as functions.
[00:43:12.640 --> 00:43:16.760]   So just using like list comprehension in Python,
[00:43:16.760 --> 00:43:20.520]   I was able to create like a four layer deep
[00:43:20.520 --> 00:43:21.920]   convolution network.
[00:43:21.920 --> 00:43:24.240]   So this is what we're doing in this chapter
[00:43:24.240 --> 00:43:26.400]   is like we're creating our own convolution,
[00:43:26.400 --> 00:43:28.800]   we're creating our own convolution networks from scratch.
[00:43:28.800 --> 00:43:31.160]   So what this does is if you have an input image
[00:43:31.160 --> 00:43:34.440]   of one channel, it converts that to a three channel
[00:43:34.440 --> 00:43:35.720]   spatial feature map.
[00:43:35.720 --> 00:43:37.480]   Then it takes that three channel feature map
[00:43:37.480 --> 00:43:39.640]   and converts it to a seven channel feature map.
[00:43:39.640 --> 00:43:41.520]   Then it takes that seven, goes to nine,
[00:43:41.520 --> 00:43:43.840]   and from nine, it goes to 12.
[00:43:43.840 --> 00:43:45.360]   And then it does that sequentially.
[00:43:45.360 --> 00:43:49.000]   So if I, let's say I'm going to call this my first,
[00:43:49.000 --> 00:43:52.240]   like this is not what the CNN that's been described
[00:43:52.240 --> 00:43:55.720]   in Fastbook, it's just a CNN that I've created now.
[00:43:55.720 --> 00:43:58.840]   So first CNN, and I'm just going to call it bad
[00:43:58.840 --> 00:44:01.800]   because it's really bad network architecture.
[00:44:01.800 --> 00:44:06.800]   And then my input is let's say one by one by two to four
[00:44:06.800 --> 00:44:10.080]   by two to four, which is just saying I have a single image,
[00:44:10.080 --> 00:44:11.640]   one channel image.
[00:44:11.640 --> 00:44:14.360]   So let's see what the output is going to be.
[00:44:14.360 --> 00:44:15.680]   I guess you remove that.
[00:44:15.680 --> 00:44:21.640]   Cool, so then that gives me some output.
[00:44:21.640 --> 00:44:24.440]   So basically what's happened is like,
[00:44:24.440 --> 00:44:29.440]   I would ask everybody to spend some time on why the output.
[00:44:29.440 --> 00:44:31.960]   So let me just paste this.
[00:44:31.960 --> 00:44:38.920]   Let me just take a snapshot of this and paste it here.
[00:44:44.120 --> 00:44:49.120]   And just say, why is the output that one by 12,
[00:44:49.120 --> 00:44:58.720]   basically one by 12 by 14 by 14.
[00:44:58.720 --> 00:45:01.280]   So I have a thing, like this could be something
[00:45:01.280 --> 00:45:03.880]   that would be a nice exercise to check.
[00:45:03.880 --> 00:45:05.840]   Like based on the understanding of convolutions,
[00:45:05.840 --> 00:45:08.320]   this could be a nice exercise to just check,
[00:45:08.320 --> 00:45:11.400]   okay, why is this output one by 12 by 14 by 14?
[00:45:11.400 --> 00:45:14.320]   So have a go like layer by layer and check the outputs
[00:45:14.320 --> 00:45:16.520]   and then check this for CNN.
[00:45:16.520 --> 00:45:19.120]   Anyway, that's just something I think it will be helpful
[00:45:19.120 --> 00:45:22.720]   if I just added that code, so copy paste.
[00:45:22.720 --> 00:45:26.920]   So anyway, just moving on,
[00:45:26.920 --> 00:45:29.160]   like that's why you're gonna define things in functions.
[00:45:29.160 --> 00:45:32.600]   It's gonna be really easy to define CNN architectures.
[00:45:32.600 --> 00:45:36.360]   And similarly, instead of like this pretty bad CNN
[00:45:36.360 --> 00:45:38.680]   that I had defined, in this book,
[00:45:38.680 --> 00:45:40.960]   you will see like this is a much nicer example.
[00:45:40.960 --> 00:45:43.760]   It goes from single channel to then eight channels,
[00:45:43.760 --> 00:45:45.360]   the kernel size is five.
[00:45:45.360 --> 00:45:47.880]   Then it goes from eight channels to 16 channels
[00:45:47.880 --> 00:45:51.520]   from 16 to 32, from 32 to 64.
[00:45:51.520 --> 00:45:54.080]   And finally it goes from 64 channels to 10 channels.
[00:45:54.080 --> 00:45:56.240]   So you get your output, that's one by one by 10.
[00:45:56.240 --> 00:45:58.740]   So you can just flatten it and you get 10 outputs.
[00:45:58.740 --> 00:46:05.120]   So with that being said, like Fast.ai also has a callback.
[00:46:05.120 --> 00:46:07.920]   So what you can do is you can pass in
[00:46:07.920 --> 00:46:10.480]   an activation stats callback.
[00:46:10.480 --> 00:46:13.880]   What that does, I will share very quickly in just a tick.
[00:46:13.880 --> 00:46:16.880]   So let me just run that.
[00:46:16.880 --> 00:46:19.160]   So if there's any questions on like what we've done so far,
[00:46:19.160 --> 00:46:20.800]   it's no magic.
[00:46:20.800 --> 00:46:24.920]   Like we just created a very, very simple CNN architecture.
[00:46:24.920 --> 00:46:27.920]   So this is our very first simple CNN
[00:46:27.920 --> 00:46:31.220]   that we've created from scratch, right?
[00:46:31.220 --> 00:46:35.240]   We just basically defined a convolution layer
[00:46:35.240 --> 00:46:36.820]   followed by value.
[00:46:36.820 --> 00:46:38.760]   That was the one basic block.
[00:46:39.660 --> 00:46:42.620]   From that basic block, we just use that basic block
[00:46:42.620 --> 00:46:46.260]   to define like four or like one, two, three, four, five,
[00:46:46.260 --> 00:46:48.220]   five-layer deep architecture.
[00:46:48.220 --> 00:46:52.600]   And then we can use that five-layer deep architecture
[00:46:52.600 --> 00:46:56.320]   to train, like we can use this five-layer deep architecture
[00:46:56.320 --> 00:47:01.320]   and we can try and train to classify digits.
[00:47:01.320 --> 00:47:05.060]   And what you can see is that the accuracy is 0.1.
[00:47:05.060 --> 00:47:08.860]   It's just 10% accurate, which is really, really bad.
[00:47:09.120 --> 00:47:11.480]   Okay, and now you're gonna be,
[00:47:11.480 --> 00:47:12.700]   as deep learning practitioners,
[00:47:12.700 --> 00:47:16.400]   you're going to be in situations where you train a network
[00:47:16.400 --> 00:47:17.820]   and it doesn't train.
[00:47:17.820 --> 00:47:20.460]   You train a network and the accuracy that you expect
[00:47:20.460 --> 00:47:22.920]   is about 50%, but the accuracy that you get,
[00:47:22.920 --> 00:47:25.880]   or like the metric that you get is so low.
[00:47:25.880 --> 00:47:28.360]   So in those cases, what you wanna do,
[00:47:28.360 --> 00:47:31.720]   FastAI has this really cool trick
[00:47:31.720 --> 00:47:35.360]   'cause we passed in a callback activation stacks, right?
[00:47:35.360 --> 00:47:37.640]   What that does is it will plot,
[00:47:37.640 --> 00:47:40.400]   start plotting the activations or like the values,
[00:47:40.400 --> 00:47:43.080]   mean and standard deviation of these values
[00:47:43.080 --> 00:47:47.160]   at pretty much what the layer index that I pass in.
[00:47:47.160 --> 00:47:49.500]   So remember, I said,
[00:47:49.500 --> 00:47:51.800]   remember what I said?
[00:47:51.800 --> 00:47:53.900]   I said, this is five-layer deep.
[00:47:53.900 --> 00:47:58.900]   So one, two, three, four, and five, right?
[00:47:58.900 --> 00:48:03.140]   So I'm just gonna call this one, two, three, four, five.
[00:48:03.140 --> 00:48:07.480]   And then what I'm doing is like, remember,
[00:48:07.480 --> 00:48:11.480]   I would have an input image, right?
[00:48:11.480 --> 00:48:15.160]   So this input image would go all the way through my network
[00:48:15.160 --> 00:48:18.600]   to give me some output.
[00:48:18.600 --> 00:48:20.760]   So it would give me some output, right?
[00:48:20.760 --> 00:48:22.880]   Like that's how this thing would work.
[00:48:22.880 --> 00:48:26.800]   Now, what I want to do is like, I've created this network,
[00:48:26.800 --> 00:48:28.160]   but it's not training well.
[00:48:28.160 --> 00:48:30.960]   The accuracy that it's giving me is 10%
[00:48:30.960 --> 00:48:32.840]   and that's a really bad accuracy.
[00:48:32.840 --> 00:48:35.420]   So what I wanna do is I wanna check, okay,
[00:48:35.420 --> 00:48:39.120]   hey, image, when you went through layer one,
[00:48:39.120 --> 00:48:42.360]   how was the mean and standard deviation?
[00:48:42.360 --> 00:48:44.700]   Then when you went to layer two,
[00:48:44.700 --> 00:48:47.740]   what was the mean and standard deviation of the activations?
[00:48:47.740 --> 00:48:48.840]   What was after three?
[00:48:48.840 --> 00:48:50.240]   What was after four and five?
[00:48:50.240 --> 00:48:52.100]   So like I could actually plot these things
[00:48:52.100 --> 00:48:54.300]   and Fastly AI really makes it easy.
[00:48:54.300 --> 00:48:56.260]   You can just say plot layer stats
[00:48:56.260 --> 00:48:58.020]   and you can pass in the layer index.
[00:48:58.020 --> 00:49:00.180]   So passing in layer index will pretty much
[00:49:00.180 --> 00:49:02.440]   plot the layer stats for layer one.
[00:49:03.300 --> 00:49:06.260]   So you can see, if I plot the layer stats,
[00:49:06.260 --> 00:49:10.020]   you can see that the activations of like the mean
[00:49:10.020 --> 00:49:13.220]   is around minus 0.3
[00:49:13.220 --> 00:49:15.100]   and the standard deviation is all over the place.
[00:49:15.100 --> 00:49:18.460]   And then most of my activations are close to zero,
[00:49:18.460 --> 00:49:21.220]   like 60% of my activations are close to zero.
[00:49:21.220 --> 00:49:22.900]   What does that mean?
[00:49:22.900 --> 00:49:26.420]   So activations, what is an activation?
[00:49:26.420 --> 00:49:29.940]   Activation is the output of a convolution layer.
[00:49:29.940 --> 00:49:34.940]   So what these three graphs are telling me
[00:49:34.940 --> 00:49:39.100]   is like I had my first layer, right?
[00:49:39.100 --> 00:49:42.500]   I had my input, I passed it through this
[00:49:42.500 --> 00:49:44.220]   and I get some output, right?
[00:49:44.220 --> 00:49:47.240]   It's gonna be like, if I had two to four by two to four,
[00:49:47.240 --> 00:49:49.720]   I'm gonna say get an output of two to two by two to two
[00:49:49.720 --> 00:49:53.780]   and this is gonna be say 32 channels, right?
[00:49:53.780 --> 00:49:56.160]   Now, what this graph is telling me,
[00:49:56.160 --> 00:49:58.100]   this graph is basically telling me
[00:49:58.140 --> 00:50:00.940]   that the mean, like all of these remember
[00:50:00.940 --> 00:50:02.180]   are just some values, right?
[00:50:02.180 --> 00:50:04.500]   These are all pixel values, right?
[00:50:04.500 --> 00:50:09.500]   They're like, it could be 0.7, 0.9, minus 1.2, minus 0.3
[00:50:09.500 --> 00:50:11.340]   or so on, like these are just values.
[00:50:11.340 --> 00:50:15.240]   This is just an output of the convolution, correct?
[00:50:15.240 --> 00:50:16.900]   And because there was a value,
[00:50:16.900 --> 00:50:19.060]   so there's no negative values actually,
[00:50:19.060 --> 00:50:20.620]   they're all gonna be zero,
[00:50:20.620 --> 00:50:22.100]   but there's some positive values.
[00:50:22.100 --> 00:50:26.020]   So what this graph is telling me
[00:50:26.020 --> 00:50:29.820]   is that it's telling me that my output,
[00:50:29.820 --> 00:50:32.620]   the mean of this output is minus 0.3.
[00:50:32.620 --> 00:50:35.620]   So there's definitely some negative values in there.
[00:50:35.620 --> 00:50:37.620]   Okay, forgive me for saying
[00:50:37.620 --> 00:50:39.900]   that there's no negative values in there.
[00:50:39.900 --> 00:50:41.660]   But where would the negative values be coming from
[00:50:41.660 --> 00:50:43.500]   if you have a value?
[00:50:43.500 --> 00:50:46.060]   Oh, okay, so the last one has activation false.
[00:50:46.060 --> 00:50:48.020]   Okay, that makes sense.
[00:50:48.020 --> 00:50:52.620]   All right, so, but the point is like,
[00:50:52.620 --> 00:50:57.620]   out of all of these values, 60% of them are equal to zero.
[00:50:57.620 --> 00:50:59.620]   And that's not a good thing.
[00:50:59.620 --> 00:51:01.980]   Like you don't want all the activations to be zero.
[00:51:01.980 --> 00:51:05.140]   It just means that the network isn't learning much.
[00:51:05.140 --> 00:51:07.820]   And you can see that by plotting this,
[00:51:07.820 --> 00:51:10.420]   by plotting list that's of the first layer.
[00:51:10.420 --> 00:51:12.460]   And what that does is if you plot the list
[00:51:12.460 --> 00:51:14.300]   that's of the penultimate layer
[00:51:14.300 --> 00:51:16.340]   or the second from the last layer,
[00:51:16.340 --> 00:51:20.060]   they can see that all of the activations are close to zero.
[00:51:20.060 --> 00:51:21.100]   So what does that mean?
[00:51:21.100 --> 00:51:23.860]   That means that this is a really, really bad network.
[00:51:23.860 --> 00:51:25.580]   It's not really learning much.
[00:51:25.580 --> 00:51:27.220]   And that is the reason why,
[00:51:27.220 --> 00:51:29.780]   like as the image is going through our network,
[00:51:29.780 --> 00:51:31.260]   through each of the list,
[00:51:31.260 --> 00:51:34.700]   what's happening is that initially
[00:51:34.700 --> 00:51:36.580]   all of these are pixel values, right?
[00:51:36.580 --> 00:51:40.020]   They're like all are between values say zero to 255.
[00:51:40.020 --> 00:51:41.820]   And as this is going through the network,
[00:51:41.820 --> 00:51:43.300]   most of these activations
[00:51:43.300 --> 00:51:46.060]   or most of the information is being lost.
[00:51:46.060 --> 00:51:49.780]   'Cause by the end, you get out from your fifth layer,
[00:51:49.780 --> 00:51:51.060]   'cause it's gonna go through first layer,
[00:51:51.060 --> 00:51:53.300]   and second, and third, and fourth, and fifth.
[00:51:53.300 --> 00:51:55.740]   By the time you reach out to your fifth layer,
[00:51:55.740 --> 00:51:59.540]   about a hundred percent, 'cause you can see over here,
[00:51:59.540 --> 00:52:01.220]   not a hundred percent exactly,
[00:52:01.220 --> 00:52:02.900]   but like about a hundred percent,
[00:52:02.900 --> 00:52:04.820]   there's a lot of those activations
[00:52:04.820 --> 00:52:08.100]   that have a value of zero.
[00:52:08.100 --> 00:52:09.780]   So that's really, really bad.
[00:52:09.780 --> 00:52:12.500]   And that's the reason why we get that bad in accuracy,
[00:52:12.500 --> 00:52:14.140]   which is 10%.
[00:52:14.140 --> 00:52:18.140]   So like, how do we solve this?
[00:52:18.140 --> 00:52:20.780]   Now we need to find ways on like how to solve this.
[00:52:20.780 --> 00:52:23.380]   How to make sure that our network is training.
[00:52:23.380 --> 00:52:25.740]   And so the one of those things that could be done
[00:52:25.740 --> 00:52:27.940]   is that we just increase the bat size.
[00:52:27.940 --> 00:52:29.700]   So we could try a bigger bat size.
[00:52:29.700 --> 00:52:30.620]   And what does that do?
[00:52:30.620 --> 00:52:33.020]   And these are again, tricks that you should try
[00:52:33.020 --> 00:52:34.660]   when even on Cassava,
[00:52:34.660 --> 00:52:37.100]   remember when we were talking about Cassava,
[00:52:37.100 --> 00:52:38.940]   try increasing the bat size.
[00:52:38.940 --> 00:52:41.220]   If you're training on a bat size of eight,
[00:52:41.220 --> 00:52:44.420]   see what happens if we go on a bat size of 64,
[00:52:44.420 --> 00:52:47.900]   or see what happens when you go on a bat size of 128.
[00:52:47.900 --> 00:52:52.700]   The reason why a higher bat size kind of stabilizes training
[00:52:52.700 --> 00:52:55.020]   is because the gradients are more accurate.
[00:52:55.020 --> 00:52:57.060]   So what that means is,
[00:52:57.060 --> 00:53:00.620]   remember how that looks like?
[00:53:00.620 --> 00:53:04.300]   You have a batch of images, right?
[00:53:04.300 --> 00:53:06.300]   So this is two to four by two to four,
[00:53:06.300 --> 00:53:08.220]   but you have 64 such images.
[00:53:08.220 --> 00:53:11.420]   And this is what gets passed to my neural network, right?
[00:53:11.420 --> 00:53:15.020]   And if you increase the bat size to be like 512,
[00:53:15.020 --> 00:53:17.500]   as this goes through the networks,
[00:53:17.500 --> 00:53:20.020]   you pass your network, you get some output,
[00:53:20.020 --> 00:53:21.300]   you calculate the loss.
[00:53:21.300 --> 00:53:24.180]   So my first step is get some output.
[00:53:24.180 --> 00:53:26.420]   My second step is calculate the loss.
[00:53:26.420 --> 00:53:29.620]   And my third step is called loss dot backward.
[00:53:29.620 --> 00:53:32.140]   So this is something I think we discussed in the first
[00:53:32.140 --> 00:53:34.820]   or the second chapter,
[00:53:34.820 --> 00:53:36.940]   but you're practically calculating the gradients
[00:53:36.940 --> 00:53:39.020]   and you're making a backward propagation.
[00:53:39.020 --> 00:53:41.420]   Remember, that's what we did in chapter one.
[00:53:41.420 --> 00:53:42.580]   So let me see and find.
[00:53:42.580 --> 00:53:45.860]   I think it was intro.
[00:53:45.860 --> 00:53:48.620]   So anyway, all I wanna say is what happens
[00:53:48.620 --> 00:53:50.820]   is if you have a bigger batch size,
[00:53:50.820 --> 00:53:52.460]   then the gradients are more accurate
[00:53:52.460 --> 00:53:55.540]   'cause it's just easier for the network to train.
[00:53:55.540 --> 00:53:57.660]   And then when we increase the batch size
[00:53:57.660 --> 00:54:00.020]   and we check the percentage of near zero
[00:54:00.020 --> 00:54:01.340]   for the penultimate layer,
[00:54:01.340 --> 00:54:03.700]   you can see that even though it's slightly better,
[00:54:03.700 --> 00:54:07.460]   it hasn't really done a lot of difference.
[00:54:07.460 --> 00:54:10.660]   So then the last thing, or like the one,
[00:54:10.660 --> 00:54:14.380]   another thing that was introduced by Leslie Smith
[00:54:14.380 --> 00:54:16.940]   is this idea of one cycle training.
[00:54:16.940 --> 00:54:19.460]   And what this one cycle training does is,
[00:54:19.460 --> 00:54:22.740]   this is a really, really good time
[00:54:22.740 --> 00:54:24.460]   to start looking at papers.
[00:54:24.460 --> 00:54:27.500]   So sorry, one sec, let me just stop that.
[00:54:27.500 --> 00:54:28.780]   So this is a really, really good time
[00:54:28.780 --> 00:54:30.340]   to start looking at papers.
[00:54:30.340 --> 00:54:32.060]   So if I were you, what I would do
[00:54:32.060 --> 00:54:35.140]   is I would take the explanation that I will provide now,
[00:54:35.140 --> 00:54:37.660]   and then I would go to this paper, super convergence,
[00:54:37.660 --> 00:54:39.260]   and I would read all of it.
[00:54:39.260 --> 00:54:42.100]   Oh, sorry, I forgot to archive this down right now.
[00:54:42.100 --> 00:54:42.980]   I don't know why.
[00:54:43.980 --> 00:54:47.700]   But basically what I would do this week is like,
[00:54:47.700 --> 00:54:50.740]   I would take this explanation of one cycle learning,
[00:54:50.740 --> 00:54:54.100]   and then I would start reading this paper.
[00:54:54.100 --> 00:54:56.980]   But the idea with one cycle learning,
[00:54:56.980 --> 00:54:59.100]   and we've already discussed this,
[00:54:59.100 --> 00:55:04.100]   is you start out with a really small learning rate,
[00:55:04.100 --> 00:55:08.420]   then you increase the learning rate to a maximum value,
[00:55:08.420 --> 00:55:10.300]   and then you decrease it.
[00:55:10.300 --> 00:55:13.260]   So you go down as you go in your epochs.
[00:55:13.260 --> 00:55:15.180]   So in your zeroth epoch,
[00:55:15.180 --> 00:55:17.500]   to say if you're training for a hundred epoch,
[00:55:17.500 --> 00:55:20.380]   you reach the highest value at the 10th epoch,
[00:55:20.380 --> 00:55:22.780]   and then you make it go sliding down.
[00:55:22.780 --> 00:55:24.420]   And this is the idea.
[00:55:24.420 --> 00:55:27.060]   Like instead of basically until now,
[00:55:27.060 --> 00:55:29.260]   like how is that different from until now?
[00:55:29.260 --> 00:55:31.420]   Until now, we have a constant learning rate.
[00:55:31.420 --> 00:55:33.620]   So if I have a hundred epochs,
[00:55:33.620 --> 00:55:35.660]   we're just training with a constant learning rate
[00:55:35.660 --> 00:55:37.220]   of say one e-next three.
[00:55:37.220 --> 00:55:38.140]   But in this case,
[00:55:38.140 --> 00:55:40.380]   you start out with a really small learning rate
[00:55:40.380 --> 00:55:41.980]   of say one e-next five,
[00:55:41.980 --> 00:55:45.420]   then you go to the highest value of one e-next three,
[00:55:45.420 --> 00:55:47.180]   which is 0.001.
[00:55:47.180 --> 00:55:49.260]   And then you go all the way down to like,
[00:55:49.260 --> 00:55:50.260]   not negative of course,
[00:55:50.260 --> 00:55:52.540]   but you go to like one e-next eight or something.
[00:55:52.540 --> 00:55:54.100]   You go to a really small value.
[00:55:54.100 --> 00:55:58.100]   And the reason why this kind of learning rate,
[00:55:58.100 --> 00:55:59.300]   like you start from small,
[00:55:59.300 --> 00:56:00.700]   then you increase it to the maximum,
[00:56:00.700 --> 00:56:02.420]   and then you make it go down.
[00:56:02.420 --> 00:56:05.020]   The reason why this is really good,
[00:56:05.020 --> 00:56:07.020]   or the reason why this will help
[00:56:07.460 --> 00:56:08.700]   increase convergence,
[00:56:08.700 --> 00:56:11.540]   or the reason why this will make the training more stable
[00:56:11.540 --> 00:56:15.620]   is that if you start out with a learning rate like this,
[00:56:15.620 --> 00:56:19.060]   okay, remember our loss function
[00:56:19.060 --> 00:56:20.660]   looks just something like this.
[00:56:20.660 --> 00:56:25.660]   And there's like all of these small,
[00:56:25.660 --> 00:56:27.900]   or you have these local minima.
[00:56:27.900 --> 00:56:29.260]   So you have something like,
[00:56:29.260 --> 00:56:32.540]   yeah, something like that, okay?
[00:56:32.540 --> 00:56:34.700]   And then when you start with one e-next three,
[00:56:34.700 --> 00:56:35.820]   let's say I started here.
[00:56:35.820 --> 00:56:36.900]   So you jump around,
[00:56:36.900 --> 00:56:38.060]   you get this point,
[00:56:38.060 --> 00:56:39.380]   then you jump around,
[00:56:39.380 --> 00:56:40.780]   then you jump around,
[00:56:40.780 --> 00:56:42.380]   then you keep jumping around,
[00:56:42.380 --> 00:56:43.620]   you keep jumping around,
[00:56:43.620 --> 00:56:44.780]   you keep jumping around.
[00:56:44.780 --> 00:56:45.620]   But at this point,
[00:56:45.620 --> 00:56:47.060]   you want it to stay here, right?
[00:56:47.060 --> 00:56:48.780]   You want it to get to the lowest point.
[00:56:48.780 --> 00:56:50.980]   But because your learning rate is so high,
[00:56:50.980 --> 00:56:55.100]   that the model will just keep jumping around.
[00:56:55.100 --> 00:56:57.980]   Like your steps are too big, right?
[00:56:57.980 --> 00:57:00.700]   So instead, what you want to do
[00:57:00.700 --> 00:57:02.980]   is
[00:57:05.540 --> 00:57:08.820]   if I take that same example,
[00:57:08.820 --> 00:57:10.140]   instead what you want to do
[00:57:10.140 --> 00:57:12.420]   is you start with small steps.
[00:57:12.420 --> 00:57:14.660]   And once you know you're headed in the right direction,
[00:57:14.660 --> 00:57:15.900]   'cause remember, that's what's happening.
[00:57:15.900 --> 00:57:18.060]   You start small learning rate,
[00:57:18.060 --> 00:57:19.420]   then you increase your learning rate,
[00:57:19.420 --> 00:57:21.100]   and then you decrease the learning rate.
[00:57:21.100 --> 00:57:24.860]   So once you start taking small steps in the direction,
[00:57:24.860 --> 00:57:26.820]   and you know you're headed downwards,
[00:57:26.820 --> 00:57:28.700]   then you start taking big steps.
[00:57:28.700 --> 00:57:29.700]   And what that does is,
[00:57:29.700 --> 00:57:31.580]   the reason why I have a big step here
[00:57:31.580 --> 00:57:34.300]   is because it will take you out of the local minimas.
[00:57:34.300 --> 00:57:36.100]   So you start taking a big step
[00:57:36.100 --> 00:57:38.460]   until you reach to your global minima,
[00:57:38.460 --> 00:57:41.420]   which is the lowest point in a loss curve.
[00:57:41.420 --> 00:57:43.700]   And then what happens is like,
[00:57:43.700 --> 00:57:46.060]   once you've reached your highest learning rate,
[00:57:46.060 --> 00:57:48.860]   or you've reached like even a bigger learning rate,
[00:57:48.860 --> 00:57:50.460]   you start to reduce your learning rate,
[00:57:50.460 --> 00:57:53.500]   which means you start to reduce the step size, right?
[00:57:53.500 --> 00:57:55.220]   So what's that gonna look like?
[00:57:55.220 --> 00:57:58.500]   Now you'd start taking smaller steps, right?
[00:57:58.500 --> 00:57:59.340]   'Cause that's what we're doing.
[00:57:59.340 --> 00:58:01.060]   We're reducing the learning rate.
[00:58:01.060 --> 00:58:02.100]   So you get to this point
[00:58:02.100 --> 00:58:04.620]   where the learning rate is so small
[00:58:04.620 --> 00:58:09.260]   that your step is practically like that small.
[00:58:09.260 --> 00:58:11.460]   So what we've done is like,
[00:58:11.460 --> 00:58:15.100]   this way the model is able to train a lot better,
[00:58:15.100 --> 00:58:17.540]   and it's able to reach the global minimum.
[00:58:17.540 --> 00:58:20.100]   Instead of like just jumping around the global minima,
[00:58:20.100 --> 00:58:21.980]   it's able to reach it.
[00:58:21.980 --> 00:58:24.260]   And this is what is one cycle training.
[00:58:24.260 --> 00:58:26.100]   So what I would do,
[00:58:26.100 --> 00:58:28.340]   if I were you is again, go back and read this paper.
[00:58:28.340 --> 00:58:30.020]   It's a really, really nice paper.
[00:58:30.020 --> 00:58:31.260]   It's really nice read.
[00:58:31.260 --> 00:58:32.300]   And when you read this,
[00:58:32.300 --> 00:58:37.300]   it will expand your knowledge about learning rates.
[00:58:37.300 --> 00:58:40.300]   It will expand your knowledge about a lot of other things,
[00:58:40.300 --> 00:58:42.300]   about warmup, and it will introduce you.
[00:58:42.300 --> 00:58:43.620]   And not even if it expands,
[00:58:43.620 --> 00:58:48.620]   it will introduce you to like concepts
[00:58:48.620 --> 00:58:52.340]   or words like warmup or annealing.
[00:58:52.340 --> 00:58:54.260]   So these are words or this is vocabulary
[00:58:54.260 --> 00:58:55.980]   that you would have never heard before.
[00:58:55.980 --> 00:58:57.860]   And then what will happen is like,
[00:58:57.860 --> 00:59:00.620]   when you see a new word, you will probably Google it.
[00:59:00.620 --> 00:59:04.700]   And then that's the whole knowledge expansion, right?
[00:59:04.700 --> 00:59:07.420]   So once you start hitting those words
[00:59:07.420 --> 00:59:09.940]   or hitting those points where you don't know about them,
[00:59:09.940 --> 00:59:12.300]   this is where the real learning happens.
[00:59:12.300 --> 00:59:16.300]   And so I would definitely recommend trying to read that.
[00:59:16.300 --> 00:59:21.300]   So let's try adding like one cycle learning to my network.
[00:59:21.300 --> 00:59:23.980]   So if I add one cycle learning,
[00:59:23.980 --> 00:59:25.700]   I just have to say fit one cycle
[00:59:25.700 --> 00:59:28.340]   instead of saying like fit before.
[00:59:28.340 --> 00:59:31.780]   So I was previously, I was saying learn.fit,
[00:59:31.780 --> 00:59:34.660]   but now I can just say learn.fit one cycle.
[00:59:34.660 --> 00:59:40.220]   So if I train my model now, you can see,
[00:59:40.220 --> 00:59:42.420]   let's see what the accuracy is.
[00:59:42.420 --> 00:59:44.900]   Let's just wait, maybe five seconds.
[00:59:44.900 --> 00:59:47.220]   In that time, I will just have a look
[00:59:47.220 --> 00:59:48.540]   if there's any questions.
[00:59:48.540 --> 00:59:51.500]   Okay. No questions after this.
[00:59:51.500 --> 00:59:55.660]   So there's different weights of,
[00:59:55.660 --> 00:59:58.220]   there's different types of initializing the weights
[00:59:58.220 --> 00:59:59.820]   on nn.conf2d.
[00:59:59.820 --> 01:00:01.500]   It is a good question,
[01:00:01.500 --> 01:00:04.420]   but I would just recommend you to go nn.conf2d.
[01:00:04.420 --> 01:00:07.340]   And I think there will be an answer
[01:00:07.340 --> 01:00:09.100]   about initialization over here.
[01:00:09.100 --> 01:00:11.300]   I think they do it using
[01:00:11.300 --> 01:00:13.700]   climbing_her initialization if I'm not wrong.
[01:00:13.700 --> 01:00:17.180]   Let's see.
[01:00:17.180 --> 01:00:18.780]   There's definitely a parameter
[01:00:18.780 --> 01:00:21.220]   that lets you initialize them a certain way.
[01:00:21.220 --> 01:00:27.340]   In Fast.ai, I think it's climbing_her initialization.
[01:00:27.340 --> 01:00:31.140]   So that again is the learnable weights,
[01:00:31.140 --> 01:00:31.980]   the values of these.
[01:00:31.980 --> 01:00:33.020]   There we go.
[01:00:33.020 --> 01:00:36.020]   So in this case, I think it's a normal distribution.
[01:00:36.020 --> 01:00:39.820]   So you can definitely,
[01:00:39.820 --> 01:00:42.100]   I think I won't go into the details of initialization
[01:00:42.100 --> 01:00:44.260]   because that's not something we're covering today,
[01:00:44.260 --> 01:00:45.900]   but you can definitely have a look at here,
[01:00:45.900 --> 01:00:48.060]   but there's like all of those different initializations.
[01:00:48.060 --> 01:00:51.460]   So the answer is you can definitely customize it
[01:00:51.460 --> 01:00:53.780]   on however you want to.
[01:00:57.220 --> 01:00:58.060]   Okay.
[01:00:58.060 --> 01:01:00.900]   So where were we?
[01:01:00.900 --> 01:01:03.900]   Okay, we were just having a look at what the accuracy is.
[01:01:03.900 --> 01:01:06.700]   So you can see just by using this one cycle,
[01:01:06.700 --> 01:01:09.740]   now instead, like we didn't really change anything, right?
[01:01:09.740 --> 01:01:11.380]   We just started using this one cycle
[01:01:11.380 --> 01:01:14.420]   and we can see now our accuracy is 95%.
[01:01:14.420 --> 01:01:18.540]   So it's really important that our model trains
[01:01:18.540 --> 01:01:21.220]   that our model trains stably
[01:01:21.220 --> 01:01:24.020]   and the activations remain stable.
[01:01:24.020 --> 01:01:25.060]   So now I can just see like,
[01:01:25.060 --> 01:01:26.540]   this is exactly as I was saying,
[01:01:26.540 --> 01:01:28.740]   our learning rate starts from a really small value,
[01:01:28.740 --> 01:01:32.180]   goes to the top and then goes back to a smaller value again.
[01:01:32.180 --> 01:01:34.700]   And now we can see the activation stats
[01:01:34.700 --> 01:01:36.140]   of the presentation is zero.
[01:01:36.140 --> 01:01:38.180]   It's much less than one, so we're doing better,
[01:01:38.180 --> 01:01:40.980]   but again, it's still a large, large percentage
[01:01:40.980 --> 01:01:42.980]   of my activations are close to zero.
[01:01:42.980 --> 01:01:44.420]   So we might want to fix that.
[01:01:44.420 --> 01:01:48.140]   One thing that you'll see over here is like,
[01:01:48.140 --> 01:01:52.420]   okay, so I should just fix that.
[01:01:52.420 --> 01:01:54.820]   Just give me one second, please.
[01:01:54.820 --> 01:01:56.820]   I think I just need to rerun.
[01:01:56.820 --> 01:02:01.660]   This I did just rerun, so I can just rerun that,
[01:02:01.660 --> 01:02:04.540]   that and that.
[01:02:04.540 --> 01:02:07.340]   Okay, so that's just how many activations I have.
[01:02:07.340 --> 01:02:08.340]   Cool.
[01:02:08.340 --> 01:02:11.300]   So then in this case, there's this idea of,
[01:02:11.300 --> 01:02:15.620]   the way this particular,
[01:02:15.620 --> 01:02:18.620]   there's this, one of the fast AI students,
[01:02:18.620 --> 01:02:23.060]   what they did was they kind of developed a chart
[01:02:23.060 --> 01:02:25.980]   to look at how the distribution
[01:02:25.980 --> 01:02:28.940]   of my activation function looks like after each layers.
[01:02:28.940 --> 01:02:31.900]   So this is an, I will just go to the in-depth explanation
[01:02:31.900 --> 01:02:34.780]   and try and explain what's happening,
[01:02:34.780 --> 01:02:38.540]   is there is this idea of called a colorful dimension.
[01:02:38.540 --> 01:02:40.900]   So what happens is basically,
[01:02:40.900 --> 01:02:43.580]   see how this is a normal distribution.
[01:02:43.580 --> 01:02:47.260]   If you have a higher value, it's represented by green.
[01:02:47.260 --> 01:02:50.260]   If you have a lower value, it's represented by red.
[01:02:50.260 --> 01:02:53.860]   So in this case, for a distribution like this one,
[01:02:53.860 --> 01:02:55.300]   you get the output,
[01:02:55.300 --> 01:02:57.220]   which looks like something at the bottom.
[01:02:57.220 --> 01:02:59.540]   So you have red, red, red, green, green, green,
[01:02:59.540 --> 01:03:04.420]   and red, red, red, which just means that there's a lot,
[01:03:04.420 --> 01:03:06.260]   there's not a lot of negative values.
[01:03:06.260 --> 01:03:07.940]   So the number of negative values is low
[01:03:07.940 --> 01:03:09.340]   'cause it's all red,
[01:03:09.340 --> 01:03:12.340]   but there's a lot of values that are close to zero.
[01:03:12.340 --> 01:03:14.900]   And then there's less values that are close
[01:03:14.900 --> 01:03:17.220]   to really high positive values.
[01:03:17.220 --> 01:03:20.100]   So you could actually, so you can see like,
[01:03:20.100 --> 01:03:23.860]   I think there was a nice graph that explains
[01:03:23.860 --> 01:03:25.780]   how that looks like, yes, over here.
[01:03:25.780 --> 01:03:28.820]   So you can see that for my normal distribution,
[01:03:28.820 --> 01:03:31.900]   if you plot it using this colorful dimension idea
[01:03:31.900 --> 01:03:34.060]   that was developed by a fast AI student,
[01:03:34.060 --> 01:03:37.700]   you can see it's like red, red, red, green, and red, red.
[01:03:37.700 --> 01:03:39.740]   Similarly, if you have something like a bias,
[01:03:39.740 --> 01:03:42.780]   which is something where it peaks instead of at zero,
[01:03:42.780 --> 01:03:46.820]   it peaks at say minus 0.3 or 0.3,
[01:03:46.820 --> 01:03:49.100]   then in that case, you can see it's,
[01:03:49.100 --> 01:03:50.380]   there's a different, like the green,
[01:03:50.380 --> 01:03:53.140]   instead of being at zero, the green is over here.
[01:03:53.140 --> 01:03:56.020]   If the activations are well spread out,
[01:03:56.020 --> 01:03:59.260]   you can see that the values are much lighter,
[01:03:59.260 --> 01:04:00.700]   but if it's something like condensed,
[01:04:00.700 --> 01:04:02.780]   you can see like this is a really dark green
[01:04:02.780 --> 01:04:04.900]   as opposed to this green over here.
[01:04:04.900 --> 01:04:07.660]   That's because you have a lot more values at zero
[01:04:07.660 --> 01:04:09.460]   in this case than over this case.
[01:04:09.460 --> 01:04:13.980]   So in this idea, what you have is like,
[01:04:13.980 --> 01:04:17.180]   you basically have,
[01:04:18.020 --> 01:04:19.260]   you basically, what you do
[01:04:19.260 --> 01:04:22.100]   with this colorful dimension plot is,
[01:04:22.100 --> 01:04:26.980]   I had five layers, right?
[01:04:26.980 --> 01:04:31.980]   Layer one, two, three, and four, let's say four layers, right?
[01:04:31.980 --> 01:04:37.380]   So what you do is you have your input over here,
[01:04:37.380 --> 01:04:40.980]   then you get some output, so I'm gonna call it O1,
[01:04:40.980 --> 01:04:43.060]   and you get some output, I'm gonna call it O2,
[01:04:43.060 --> 01:04:45.100]   I'm gonna get some output, I'm gonna call it O3,
[01:04:45.100 --> 01:04:46.700]   and then finally O4.
[01:04:46.700 --> 01:04:51.340]   So what you could do is you could plot, like using this,
[01:04:51.340 --> 01:04:53.940]   you could plot the activation statistics,
[01:04:53.940 --> 01:04:56.420]   which we just plotted here, right?
[01:04:56.420 --> 01:04:57.740]   We can plot the means.
[01:04:57.740 --> 01:05:01.500]   So let's say the mean of O1 is like,
[01:05:01.500 --> 01:05:02.620]   everything is near zero,
[01:05:02.620 --> 01:05:06.380]   so it's something like that, right?
[01:05:06.380 --> 01:05:07.980]   Something like that.
[01:05:07.980 --> 01:05:12.460]   For O2, pretty much everything is zero,
[01:05:12.460 --> 01:05:15.100]   so it's like a bar chart like that.
[01:05:15.100 --> 01:05:17.580]   For O3, everything is zero.
[01:05:17.580 --> 01:05:19.020]   So what you could do is like,
[01:05:19.020 --> 01:05:23.140]   all of these could be converted into those colorful charts,
[01:05:23.140 --> 01:05:25.180]   which looks like this, like based on that,
[01:05:25.180 --> 01:05:28.700]   and then you could stack them together, like horizontally,
[01:05:28.700 --> 01:05:30.260]   'cause these are vertical bars,
[01:05:30.260 --> 01:05:31.980]   you could stack them together.
[01:05:31.980 --> 01:05:35.580]   And then if I do that, I get this really nice visualization
[01:05:35.580 --> 01:05:37.620]   that looks something like this, right?
[01:05:37.620 --> 01:05:40.100]   So what that means, yellow is again,
[01:05:40.100 --> 01:05:42.020]   where the bulk of the activations are,
[01:05:42.020 --> 01:05:43.940]   or yellow or bright yellow is the point
[01:05:43.940 --> 01:05:48.020]   where the things are, like it's a peak.
[01:05:48.020 --> 01:05:51.300]   So if I have a look at this first batch,
[01:05:51.300 --> 01:05:54.660]   I can see most of my values are zero, right?
[01:05:54.660 --> 01:05:56.460]   Then the model starts to learn,
[01:05:56.460 --> 01:05:58.540]   so my values are well spread out,
[01:05:58.540 --> 01:05:59.940]   like there's some positive values,
[01:05:59.940 --> 01:06:02.260]   and then there's a lot of still zero values,
[01:06:02.260 --> 01:06:05.820]   until it suddenly drops, right?
[01:06:05.820 --> 01:06:07.660]   And then as I keep going forward,
[01:06:07.660 --> 01:06:10.780]   you can see there's still a lot of bright yellow values
[01:06:10.780 --> 01:06:11.820]   at the bottom.
[01:06:11.820 --> 01:06:14.060]   What that means is that my network
[01:06:14.060 --> 01:06:17.140]   isn't really learning well, right?
[01:06:17.140 --> 01:06:19.740]   There's still a lot of values that are zero,
[01:06:19.740 --> 01:06:24.180]   'cause remember, bright meant a higher number,
[01:06:24.180 --> 01:06:26.380]   and dark meant a lower number.
[01:06:26.380 --> 01:06:28.460]   So you can see there's still blue at the top
[01:06:28.460 --> 01:06:29.820]   and light green at the bottom,
[01:06:29.820 --> 01:06:32.300]   which just means there's a lot of values that are close to,
[01:06:32.300 --> 01:06:35.140]   there's a lot of values that are close to zero, okay?
[01:06:35.140 --> 01:06:39.300]   So this picture shows a classic picture of bad training.
[01:06:40.260 --> 01:06:44.860]   So again, we wanna make things more stable,
[01:06:44.860 --> 01:06:47.180]   and then the idea to make things more stable
[01:06:47.180 --> 01:06:49.540]   is to try and add batch normalization.
[01:06:49.540 --> 01:06:51.460]   So the next thing that you add to this
[01:06:51.460 --> 01:06:52.780]   is batch normalization.
[01:06:52.780 --> 01:06:54.300]   So I'm not gonna tell you right now
[01:06:54.300 --> 01:06:56.060]   what batch normalization looks like,
[01:06:56.060 --> 01:06:58.300]   but let's see how that same chart looks like
[01:06:58.300 --> 01:06:59.420]   with batch normalization.
[01:06:59.420 --> 01:07:01.420]   Oh, it looks like this, this is perfect.
[01:07:01.420 --> 01:07:03.940]   So why is this perfect?
[01:07:03.940 --> 01:07:06.340]   Okay, in my first batch,
[01:07:06.340 --> 01:07:09.940]   I start with a lot of my values that are close to zero.
[01:07:09.940 --> 01:07:11.980]   See this bright yellow at the bottom?
[01:07:11.980 --> 01:07:15.100]   I'm starting with a lot of values that are close to zero.
[01:07:15.100 --> 01:07:17.740]   And then in my second batch, I'm going,
[01:07:17.740 --> 01:07:21.500]   okay, now there's like more values that are positive.
[01:07:21.500 --> 01:07:23.860]   Then as I'm going forward in my next layer,
[01:07:23.860 --> 01:07:25.580]   there's more values that are positive.
[01:07:25.580 --> 01:07:27.340]   Then I'm going as forward in my next layer,
[01:07:27.340 --> 01:07:29.300]   then there's more values that are positive.
[01:07:29.300 --> 01:07:32.100]   And in my next layer, there's more values that are positive
[01:07:32.100 --> 01:07:34.740]   until I reach this fifth or sixth batch,
[01:07:34.740 --> 01:07:36.020]   or like the 10th batch,
[01:07:36.020 --> 01:07:39.540]   where there's a nice even spread of the values.
[01:07:39.540 --> 01:07:42.340]   Whilst still there's quite a number of values
[01:07:42.340 --> 01:07:44.300]   that are close to zero,
[01:07:44.300 --> 01:07:47.740]   but you can see now like this thing shows
[01:07:47.740 --> 01:07:49.660]   that now my network is learning.
[01:07:49.660 --> 01:07:53.900]   Instead of like my network learning like this,
[01:07:53.900 --> 01:07:55.780]   instead of like, it's showing like the values
[01:07:55.780 --> 01:07:58.420]   are going from all of them being close to zero
[01:07:58.420 --> 01:08:01.020]   to being spread out and then suddenly dropping again
[01:08:01.020 --> 01:08:03.340]   and then suddenly dropping again and then dropping again,
[01:08:03.340 --> 01:08:06.540]   like this is an instable learning chart.
[01:08:06.540 --> 01:08:08.620]   You can see from this,
[01:08:08.620 --> 01:08:09.460]   you can see from this,
[01:08:09.460 --> 01:08:11.780]   like what happens after adding batch normalization
[01:08:11.780 --> 01:08:14.060]   is that my network becomes more stable.
[01:08:14.060 --> 01:08:18.180]   So I will now touch upon batch normalization,
[01:08:18.180 --> 01:08:19.860]   but before I do, let me just have a look
[01:08:19.860 --> 01:08:21.740]   if there's any questions.
[01:08:21.740 --> 01:08:27.020]   Are you going forward to the next model layer
[01:08:27.020 --> 01:08:28.420]   or the next mini batch?
[01:08:28.420 --> 01:08:33.420]   In this case, because we're plotting the activations
[01:08:35.660 --> 01:08:39.420]   for one layer, which means what you do is,
[01:08:39.420 --> 01:08:43.580]   remember, I have say five layers
[01:08:43.580 --> 01:08:48.580]   and I have one, two, three, say a hundred batches.
[01:08:48.580 --> 01:08:50.180]   You first pass the first batch,
[01:08:50.180 --> 01:08:54.300]   you take this, you draw a vertical colorful dimension.
[01:08:54.300 --> 01:08:56.420]   You pass the second batch, you take this,
[01:08:56.420 --> 01:08:58.180]   you draw a colorful dimension.
[01:08:58.180 --> 01:09:01.660]   Third batch, take the output, colorful dimension.
[01:09:01.660 --> 01:09:03.900]   And then when you stack this all up,
[01:09:03.900 --> 01:09:07.700]   you get this image, right?
[01:09:07.700 --> 01:09:12.700]   So this is just, if I take this over here,
[01:09:12.700 --> 01:09:17.980]   if I take that there, then,
[01:09:17.980 --> 01:09:22.580]   because this is output for one layer,
[01:09:22.580 --> 01:09:24.460]   that's the first batch, second batch,
[01:09:24.460 --> 01:09:26.820]   third batch, fourth batch, and so on.
[01:09:26.820 --> 01:09:28.700]   And then from this particular thing,
[01:09:28.700 --> 01:09:32.380]   remember, if I have a look at the first batch,
[01:09:32.380 --> 01:09:36.820]   so I could maybe crop this part, right?
[01:09:36.820 --> 01:09:40.420]   I could just paste it here.
[01:09:40.420 --> 01:09:44.860]   What does that mean?
[01:09:44.860 --> 01:09:49.860]   This means that the activations look something like that.
[01:09:49.860 --> 01:09:51.060]   Remember?
[01:09:51.060 --> 01:09:53.580]   So if I have, that's my flat line,
[01:09:53.580 --> 01:09:58.580]   then that's how my activations look like.
[01:10:00.060 --> 01:10:05.060]   It starts to peak at zero until that.
[01:10:05.060 --> 01:10:07.860]   That's how my activations look like at this point.
[01:10:07.860 --> 01:10:11.860]   And then if I go to this particular point, say,
[01:10:11.860 --> 01:10:14.860]   or that particular batch,
[01:10:14.860 --> 01:10:17.860]   then my activations look something like,
[01:10:17.860 --> 01:10:20.020]   because there's still a,
[01:10:20.020 --> 01:10:22.700]   so they look something like that.
[01:10:22.700 --> 01:10:24.740]   Because it's still, it's not as bright,
[01:10:24.740 --> 01:10:26.140]   which means the values aren't,
[01:10:26.140 --> 01:10:29.700]   there's not that many values in that particular place,
[01:10:29.700 --> 01:10:30.780]   but it's still a peak,
[01:10:30.780 --> 01:10:33.620]   but this is still better than this, right?
[01:10:33.620 --> 01:10:39.100]   That's the, I hope that answers the question, Kevin.
[01:10:39.100 --> 01:10:45.940]   So is it okay to remove those zero values
[01:10:45.940 --> 01:10:47.220]   from the architecture for inference
[01:10:47.220 --> 01:10:49.740]   so that we get a learning model which predicts faster?
[01:10:49.740 --> 01:10:52.780]   Oh, we're not trying to, we're not trying to,
[01:10:52.780 --> 01:10:55.620]   oh, sorry, I guess that's confusing.
[01:10:55.620 --> 01:10:58.260]   We're not trying to remove any zero values.
[01:10:58.260 --> 01:11:00.700]   What this chart, like this,
[01:11:00.700 --> 01:11:02.980]   what that chart at the top was showing
[01:11:02.980 --> 01:11:05.140]   is like as your image,
[01:11:05.140 --> 01:11:07.820]   or as the activations go through your network,
[01:11:07.820 --> 01:11:10.140]   as they go from the first layer to the second layer
[01:11:10.140 --> 01:11:11.900]   to the third layer to the fourth layer,
[01:11:11.900 --> 01:11:16.740]   what happens is most of those activation values become zero.
[01:11:16.740 --> 01:11:19.700]   So it's called a zero propagation or something like that.
[01:11:19.700 --> 01:11:21.660]   I can't remember the technical term,
[01:11:21.660 --> 01:11:22.900]   but that just basically means
[01:11:22.900 --> 01:11:24.780]   like if most of your values are zero,
[01:11:24.780 --> 01:11:26.540]   then the gradients are zero.
[01:11:26.540 --> 01:11:27.900]   And when the gradients are zero,
[01:11:27.900 --> 01:11:30.100]   that just means you can't do a backward pass.
[01:11:30.100 --> 01:11:31.860]   And if you can't do a backward pass,
[01:11:31.860 --> 01:11:34.340]   that means your network isn't learning, right?
[01:11:34.340 --> 01:11:37.100]   So it's in everybody's best interest
[01:11:37.100 --> 01:11:39.460]   to have a mean zero and standard deviation of one,
[01:11:39.460 --> 01:11:43.780]   or like have that for the network to train stably.
[01:11:43.780 --> 01:11:47.460]   So what we wanna do is we wanna see our model,
[01:11:47.460 --> 01:11:49.780]   we wanna see our model look like this,
[01:11:49.780 --> 01:11:52.060]   where there's an even spread, like it starts,
[01:11:52.060 --> 01:11:54.260]   like even though in my first batch,
[01:11:54.260 --> 01:11:56.500]   a lot of the values are close to zero,
[01:11:56.500 --> 01:11:59.460]   and then the activations are more spread out,
[01:11:59.460 --> 01:12:01.940]   'cause that's my understanding of this image.
[01:12:01.940 --> 01:12:03.620]   It's like when that happens,
[01:12:03.620 --> 01:12:06.060]   that just means that now my network is learning
[01:12:06.060 --> 01:12:08.860]   and doing a much better job at learning than before.
[01:12:08.860 --> 01:12:14.100]   Okay, so what does batch norm do?
[01:12:14.100 --> 01:12:16.500]   So basically, remember normalization is what?
[01:12:16.500 --> 01:12:19.820]   X minus mean divided by standard deviation in a way.
[01:12:19.820 --> 01:12:23.380]   So what this, again, not going too deeply
[01:12:23.380 --> 01:12:24.740]   into batch normalization,
[01:12:24.740 --> 01:12:26.300]   'cause it's just like one paragraph
[01:12:26.300 --> 01:12:28.020]   that's been touched in fast book.
[01:12:28.020 --> 01:12:34.260]   So what that means is in batch normalization,
[01:12:34.260 --> 01:12:40.060]   you basically, as you go through the network,
[01:12:40.060 --> 01:12:41.820]   so as you go through the network,
[01:12:41.820 --> 01:12:47.580]   remember where are we?
[01:12:47.580 --> 01:12:50.420]   This is what my network looked like, right?
[01:12:50.420 --> 01:12:51.900]   As I keep going through the network,
[01:12:51.900 --> 01:12:55.540]   I have now batch norm layers in between.
[01:12:55.540 --> 01:12:57.180]   So batch norm layers in between.
[01:12:57.180 --> 01:12:59.300]   And what this batch norm layer does
[01:12:59.300 --> 01:13:02.500]   is that it normalizes my output activations.
[01:13:02.500 --> 01:13:04.020]   So what's gonna happen?
[01:13:04.020 --> 01:13:05.380]   You already know what it means
[01:13:05.380 --> 01:13:07.300]   to normalize an input image, right?
[01:13:07.300 --> 01:13:08.500]   If you have an input image
[01:13:08.500 --> 01:13:10.060]   and the values are all over the place,
[01:13:10.060 --> 01:13:13.780]   like 128 minus 100 or so on,
[01:13:13.780 --> 01:13:15.060]   when you normalize this,
[01:13:15.060 --> 01:13:17.060]   that just means it has a mean of zero
[01:13:17.060 --> 01:13:18.940]   and standard deviation of one, right?
[01:13:18.940 --> 01:13:20.620]   That's just what normalization does.
[01:13:20.620 --> 01:13:23.620]   So now you have really nice spread of activations here,
[01:13:23.700 --> 01:13:26.940]   like 0.5 minus 0.3 and so on.
[01:13:26.940 --> 01:13:29.100]   And you normalize this whole image.
[01:13:29.100 --> 01:13:31.420]   So it's much easier for the model to train.
[01:13:31.420 --> 01:13:35.340]   But what the authors of this batch normalization said
[01:13:35.340 --> 01:13:38.380]   is like, instead of just normalizing the input images
[01:13:38.380 --> 01:13:40.580]   before feeding them to the network,
[01:13:40.580 --> 01:13:43.060]   why don't we apply batch normalization
[01:13:43.060 --> 01:13:48.060]   at every point after getting my output from the layers?
[01:13:48.060 --> 01:13:51.100]   So what this does is that it makes sure
[01:13:51.100 --> 01:13:53.380]   that my activations have a mean zero
[01:13:53.380 --> 01:13:54.660]   and standard deviation of one
[01:13:54.660 --> 01:13:56.460]   as it propagates through the network.
[01:13:56.460 --> 01:14:00.540]   And what that does is it makes training a lot easier.
[01:14:00.540 --> 01:14:02.620]   So I will only touch that much
[01:14:02.620 --> 01:14:05.780]   when I talk about batch normalization.
[01:14:05.780 --> 01:14:07.980]   But basically, if you wanna learn more,
[01:14:07.980 --> 01:14:09.740]   or it looks like Archive is back.
[01:14:09.740 --> 01:14:12.260]   If you wanna learn more about batch normalization,
[01:14:12.260 --> 01:14:14.500]   I would say we go to this PDF
[01:14:14.500 --> 01:14:17.580]   and we start having a look at this paper.
[01:14:17.580 --> 01:14:22.020]   But otherwise, I've written a blog on
[01:14:23.140 --> 01:14:25.580]   group normalization.
[01:14:25.580 --> 01:14:28.300]   So if you go to this blog on group normalization,
[01:14:28.300 --> 01:14:30.820]   you will see an introduction to batch normalization.
[01:14:30.820 --> 01:14:33.260]   So you will see what batch normalization does,
[01:14:33.260 --> 01:14:35.020]   what's the drawback of batch normalization.
[01:14:35.020 --> 01:14:37.300]   So I think at this point,
[01:14:37.300 --> 01:14:39.580]   I will only cover batch normalization
[01:14:39.580 --> 01:14:42.540]   as much as it has been mentioned in the book,
[01:14:42.540 --> 01:14:44.300]   which is exactly what I've told you.
[01:14:44.300 --> 01:14:46.900]   But this is a good point then for everybody
[01:14:46.900 --> 01:14:49.860]   to pick up this basic idea
[01:14:49.860 --> 01:14:52.100]   that we wanna normalize all our activations
[01:14:52.100 --> 01:14:53.460]   as we go through the network.
[01:14:53.460 --> 01:14:55.100]   But now this is a good point to like,
[01:14:55.100 --> 01:14:58.740]   just increase and expand your understanding of batch norm.
[01:14:58.740 --> 01:15:00.940]   Go through the blog, go through the paper,
[01:15:00.940 --> 01:15:03.460]   ask questions, ask questions on the forum,
[01:15:03.460 --> 01:15:05.660]   ask questions on Twitter, tag me on Twitter,
[01:15:05.660 --> 01:15:09.140]   or like, you know, nudge me at forums,
[01:15:09.140 --> 01:15:12.980]   or nudge Jeremy, nudge Fast.ai, tag a researcher.
[01:15:12.980 --> 01:15:14.300]   Like these are the different things.
[01:15:14.300 --> 01:15:15.500]   If you don't find an answer,
[01:15:15.500 --> 01:15:18.180]   of course, I don't mean to say like spam anybody,
[01:15:18.180 --> 01:15:20.860]   but if you really have a genuine question
[01:15:20.860 --> 01:15:23.300]   that you can't find the answer of it,
[01:15:23.300 --> 01:15:25.180]   try tagging people, try asking them,
[01:15:25.180 --> 01:15:26.740]   try emailing researchers.
[01:15:26.740 --> 01:15:29.580]   So generally lots of researchers provide the email.
[01:15:29.580 --> 01:15:32.740]   So if you generally have a really, really good question,
[01:15:32.740 --> 01:15:33.900]   which you cannot find,
[01:15:33.900 --> 01:15:36.460]   of course, the first step is to try and Google it.
[01:15:36.460 --> 01:15:39.220]   The next step is trying to look at Stack Overflow,
[01:15:39.220 --> 01:15:41.420]   spend more time on the Fast.ai forums.
[01:15:41.420 --> 01:15:43.980]   Most of the Fast book related questions
[01:15:43.980 --> 01:15:45.500]   you will find on Fast.ai forums,
[01:15:45.500 --> 01:15:47.020]   so I wouldn't be too worried.
[01:15:47.020 --> 01:15:48.700]   But I'm just saying this generally
[01:15:48.700 --> 01:15:51.020]   as we go down this journey.
[01:15:51.020 --> 01:15:53.140]   Two years down the line when you're reading a paper,
[01:15:53.140 --> 01:15:55.100]   like I was in detail,
[01:15:55.100 --> 01:15:56.220]   and I was reading the,
[01:15:56.220 --> 01:15:58.700]   actually this was a true story for,
[01:15:58.700 --> 01:16:01.460]   I think it was Convid.
[01:16:01.460 --> 01:16:03.820]   So I was reading this paper called Convid,
[01:16:03.820 --> 01:16:07.340]   which is improving vision transformers.
[01:16:07.340 --> 01:16:12.340]   We also did, again, we also covered this at Wits and Biases,
[01:16:12.340 --> 01:16:14.340]   but I actually reached out to the author,
[01:16:14.340 --> 01:16:19.340]   Stefani, and basically he was so nice
[01:16:19.340 --> 01:16:24.580]   that he got on a call on Zoom with me
[01:16:24.580 --> 01:16:27.140]   and he helped me with the answer.
[01:16:27.140 --> 01:16:28.700]   And he helped me with the,
[01:16:28.700 --> 01:16:31.020]   he basically helped me provide that answer.
[01:16:31.020 --> 01:16:33.100]   And then what that meant is like,
[01:16:33.100 --> 01:16:35.340]   then of course, all of that got converted
[01:16:35.340 --> 01:16:37.340]   into a blog post.
[01:16:37.340 --> 01:16:40.220]   So you can see when that comes up,
[01:16:40.220 --> 01:16:41.780]   if I go to this Convid,
[01:16:42.500 --> 01:16:45.500]   blog post, which I wrote based on that,
[01:16:45.500 --> 01:16:47.660]   of course, then this thing,
[01:16:47.660 --> 01:16:49.260]   this blog post just starts with a credit
[01:16:49.260 --> 01:16:50.860]   to Stefani and to Yosolit
[01:16:50.860 --> 01:16:52.660]   for like getting on a call with me
[01:16:52.660 --> 01:16:54.860]   and helping me understand the Convid architecture.
[01:16:54.860 --> 01:16:56.580]   So if in your future,
[01:16:56.580 --> 01:16:58.980]   in your deep learning journeys,
[01:16:58.980 --> 01:17:00.860]   you do get stuck at a point
[01:17:00.860 --> 01:17:04.460]   where you really can't find the solution of it anywhere,
[01:17:04.460 --> 01:17:05.940]   try emailing the researchers,
[01:17:05.940 --> 01:17:07.820]   try looking on Twitter
[01:17:07.820 --> 01:17:09.660]   or like all of these different things.
[01:17:09.660 --> 01:17:12.060]   But the main point that I want to highlight
[01:17:12.060 --> 01:17:15.140]   after like wrapping up this chapter 13
[01:17:15.140 --> 01:17:17.700]   is that now is a good time
[01:17:17.700 --> 01:17:19.620]   to start reading research papers.
[01:17:19.620 --> 01:17:21.740]   Now is a good time to start experimenting
[01:17:21.740 --> 01:17:25.500]   and now is a good time to start being more active on Twitter
[01:17:25.500 --> 01:17:27.620]   and sharing those blog posts on Twitter
[01:17:27.620 --> 01:17:30.020]   and like tagging people and all of that.
[01:17:30.020 --> 01:17:33.420]   So that's just what I'd like to say.
[01:17:38.420 --> 01:17:43.420]   Oh, it looks like I've been...
[01:17:43.420 --> 01:17:54.020]   So let's just see if there's any questions.
[01:17:54.020 --> 01:17:54.980]   Here's another blog post.
[01:17:54.980 --> 01:17:56.900]   Thanks very much for sharing.
[01:17:56.900 --> 01:17:58.140]   Let's click on that.
[01:17:58.140 --> 01:18:04.660]   Batch norm in three levels of understanding.
[01:18:04.660 --> 01:18:07.940]   There's a lot of content in batch norm
[01:18:07.940 --> 01:18:09.380]   that is true.
[01:18:09.380 --> 01:18:13.220]   So, okay, this is massive,
[01:18:13.220 --> 01:18:14.820]   but it looks like somebody is pointing that out.
[01:18:14.820 --> 01:18:16.940]   So yeah, there's lots of different blog posts
[01:18:16.940 --> 01:18:20.620]   that you would find on all of these different ideas.
[01:18:20.620 --> 01:18:22.060]   So I would definitely recommend
[01:18:22.060 --> 01:18:24.220]   going through all of those different.
[01:18:24.220 --> 01:18:27.340]   Could you share some resources
[01:18:27.340 --> 01:18:28.940]   on how to do data pre-processing?
[01:18:28.940 --> 01:18:31.500]   Of course, but what kind of pre-processing
[01:18:31.500 --> 01:18:34.220]   or like what do you mean when you say data pre-processing?
[01:18:34.220 --> 01:18:36.500]   There's all of these different types of things.
[01:18:36.500 --> 01:18:38.020]   Do you mean normalization?
[01:18:38.020 --> 01:18:46.380]   All right, I guess this is where we'll stop.
[01:18:46.380 --> 01:18:49.020]   And this is where we'll stop.
[01:18:49.020 --> 01:18:53.220]   So you can see like when we added batch normalization,
[01:18:53.220 --> 01:18:55.020]   and we of course, went for more epochs,
[01:18:55.020 --> 01:18:59.380]   we got to that point of like 0.99 or 99% accuracy
[01:18:59.380 --> 01:19:02.420]   on the MNIST dataset.
[01:19:02.420 --> 01:19:05.340]   So I guess for this week,
[01:19:05.340 --> 01:19:08.140]   what I would recommend everybody to do is,
[01:19:08.140 --> 01:19:09.860]   there were quite a few research papers
[01:19:09.860 --> 01:19:13.460]   that were mentioned in this chapter 13 convolution.
[01:19:13.460 --> 01:19:15.380]   There was one on by Leslie Smith,
[01:19:15.380 --> 01:19:17.620]   which is this super convergence one.
[01:19:17.620 --> 01:19:19.140]   I think there was one about momentum.
[01:19:19.140 --> 01:19:20.940]   I haven't really told you what momentum is.
[01:19:20.940 --> 01:19:25.700]   That is something that will come, I guess, in chapter 16.
[01:19:25.700 --> 01:19:29.660]   And so we will cover up momentum the next week.
[01:19:29.660 --> 01:19:31.900]   But next week, we're looking at ResNet.
[01:19:31.900 --> 01:19:34.660]   So next week, then let's join the Pave Reading Group
[01:19:34.660 --> 01:19:37.940]   and cover that off as part of the Pave Reading Group.
[01:19:37.940 --> 01:19:40.220]   And then you can definitely spend more time
[01:19:40.220 --> 01:19:42.460]   reading all of these different papers and batch norm.
[01:19:42.460 --> 01:19:44.500]   So now the onus is on everybody
[01:19:44.500 --> 01:19:49.420]   that's a part of FastBook to build upon this platform
[01:19:49.420 --> 01:19:53.460]   and go about their ways on learning more from it.
[01:19:53.460 --> 01:19:55.740]   So with that being said,
[01:19:55.740 --> 01:19:57.820]   thanks everybody for joining me this week,
[01:19:57.820 --> 01:20:00.580]   and I will see you next week.
[01:20:00.580 --> 01:20:04.140]   Also, I'm flying to India this Saturday.
[01:20:04.140 --> 01:20:07.380]   So it is very possible that the timings
[01:20:07.380 --> 01:20:10.340]   for FastBook from next week might change.
[01:20:10.340 --> 01:20:13.220]   I'll have to confirm, but just want to highlight
[01:20:13.220 --> 01:20:16.860]   that it is possible that the timings might change next week.
[01:20:16.860 --> 01:20:18.660]   So thanks for joining.
[01:20:18.660 --> 01:20:20.780]   See you next week.
[01:20:21.620 --> 01:20:24.620]   (footsteps tapping)
[01:20:24.620 --> 01:20:26.020]   Bye.

