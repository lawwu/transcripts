
[00:00:00.000 --> 00:00:00.840]   I'm Josh Tobin.
[00:00:00.840 --> 00:00:03.440]   I'm a research scientist at OpenAI,
[00:00:03.440 --> 00:00:06.040]   working kind of right at the intersection
[00:00:06.040 --> 00:00:08.120]   of deep learning and robotics.
[00:00:08.120 --> 00:00:11.140]   So a lot of my work is on using deep neural networks
[00:00:11.140 --> 00:00:13.320]   to learn perception models,
[00:00:13.320 --> 00:00:14.520]   so that we can then have robots
[00:00:14.520 --> 00:00:16.380]   that do things in the real world.
[00:00:16.380 --> 00:00:19.640]   And one of the main focuses of my research and my PhD
[00:00:19.640 --> 00:00:22.720]   is on how to actually do that with synthetic data.
[00:00:22.720 --> 00:00:25.640]   So how to generate data from a physics simulator
[00:00:25.640 --> 00:00:27.800]   or a graphics engine,
[00:00:27.800 --> 00:00:30.760]   and then bridge the gap to make that data work
[00:00:30.760 --> 00:00:31.640]   in the real world.
[00:00:31.640 --> 00:00:36.360]   And I've been working in AI for about four years now.
[00:00:36.360 --> 00:00:40.120]   I got started when I got to Berkeley as a grad student.
[00:00:40.120 --> 00:00:42.880]   And I was actually, I had been kind of,
[00:00:42.880 --> 00:00:45.080]   I'd studied pure math as an undergrad.
[00:00:45.080 --> 00:00:47.000]   Like, you know, I like to tell people
[00:00:47.000 --> 00:00:48.440]   I was like a philosophy major
[00:00:48.440 --> 00:00:50.480]   who had taken four semesters of calculus.
[00:00:50.480 --> 00:00:52.600]   Like, I learned really all of the useless stuff
[00:00:52.600 --> 00:00:55.000]   and, you know, I didn't know how to program.
[00:00:55.000 --> 00:00:56.960]   And then I, you know, went and worked for a while
[00:00:56.960 --> 00:00:59.200]   as a consultant, and then coming back to grad school,
[00:00:59.200 --> 00:01:00.920]   I knew I wanted to, you know,
[00:01:00.920 --> 00:01:04.000]   find some way to apply math to technology.
[00:01:04.000 --> 00:01:07.320]   And then just took an amazing class with my, you know,
[00:01:07.320 --> 00:01:10.940]   my now advisor at Berkeley, Peter Abbeel,
[00:01:10.940 --> 00:01:12.920]   kind of working on deep learning and robotics,
[00:01:12.920 --> 00:01:15.560]   and just kind of immediately saw that this is like,
[00:01:15.560 --> 00:01:18.320]   this is the exciting thing to be working on right now.
[00:01:18.320 --> 00:01:21.080]   And I've just kind of gotten swept up in it ever since.
[00:01:21.080 --> 00:01:23.880]   So, you know, in addition to the organizers,
[00:01:23.880 --> 00:01:25.600]   we have an amazing set of guest lecturers
[00:01:25.600 --> 00:01:27.960]   over the next few weeks.
[00:01:27.960 --> 00:01:29.280]   You know, Peter Abbeel from Berkeley,
[00:01:29.280 --> 00:01:33.400]   kind of one of the foremost researchers in AI and robotics.
[00:01:33.400 --> 00:01:35.320]   Stuart Bowers from Tesla.
[00:01:35.320 --> 00:01:37.280]   Sergey Karayev, who built an amazing product
[00:01:37.280 --> 00:01:40.600]   called Gradescope, that recently got acquired by Turnitin.
[00:01:40.600 --> 00:01:42.080]   Neil Kozloff, who will be here tonight,
[00:01:42.080 --> 00:01:45.280]   who founded, you know, two AI startups.
[00:01:45.280 --> 00:01:47.280]   Roseanne Liu from Uber.
[00:01:47.280 --> 00:01:49.480]   Lee Redden from Blue River Technologies.
[00:01:49.480 --> 00:01:53.280]   Paroma Sharma, who kind of works on an amazing
[00:01:53.280 --> 00:01:55.080]   data labeling system at Stanford.
[00:01:55.080 --> 00:01:55.920]   And then Peter Wellender,
[00:01:55.920 --> 00:01:58.320]   who's one of my colleagues at OpenAI.
[00:01:58.320 --> 00:02:03.160]   So we're really excited to have all these great people here.
[00:02:03.160 --> 00:02:06.160]   I wanted to just say a few things about, you know,
[00:02:06.160 --> 00:02:08.920]   kind of why this class, like, why are we organizing this?
[00:02:08.920 --> 00:02:12.460]   You know, I think like all of you are probably familiar
[00:02:12.460 --> 00:02:16.160]   with lots of the successes of deep learning at this point.
[00:02:16.160 --> 00:02:18.400]   You know, this chart shows image error rate
[00:02:18.400 --> 00:02:20.800]   before and after deep learning.
[00:02:20.800 --> 00:02:22.680]   There are amazing successes in games.
[00:02:22.680 --> 00:02:25.360]   Recently, team at OpenAI beat the world champions
[00:02:25.360 --> 00:02:28.200]   at Dota 5v5, which is pretty amazing.
[00:02:28.200 --> 00:02:30.640]   A couple of years ago,
[00:02:30.640 --> 00:02:34.000]   DeepMind beat the best Go players in the world.
[00:02:34.000 --> 00:02:37.140]   Speech recognition kind of followed a similar trend.
[00:02:37.140 --> 00:02:41.000]   You know, before 2008 or 2009 or 2010,
[00:02:41.000 --> 00:02:43.560]   kind of all of the major successes
[00:02:43.560 --> 00:02:44.920]   had incremental progress.
[00:02:44.920 --> 00:02:47.120]   And then after deep learning came in,
[00:02:47.120 --> 00:02:50.800]   progress sort of became exponential for the next few years.
[00:02:50.800 --> 00:02:53.920]   Image captioning, applications in medicine,
[00:02:53.920 --> 00:02:54.840]   there's quite a lot.
[00:02:54.840 --> 00:02:57.680]   And the amazing thing about it to me is that,
[00:02:57.680 --> 00:03:00.160]   like the amount of time between
[00:03:00.160 --> 00:03:02.400]   when these academic successes started coming out
[00:03:02.400 --> 00:03:04.880]   and when deep learning started getting used in products,
[00:03:04.880 --> 00:03:06.560]   which is like really, really short.
[00:03:06.560 --> 00:03:08.540]   And so here, you know, here are some products
[00:03:08.540 --> 00:03:11.400]   that are like actually really using deep learning right now.
[00:03:11.400 --> 00:03:12.760]   You know, if you use Google Translate,
[00:03:12.760 --> 00:03:15.840]   then there's, you know, basically a big LSTM,
[00:03:15.840 --> 00:03:18.880]   or maybe they have like a more state of the art model now,
[00:03:18.880 --> 00:03:21.800]   but a big deep learning model behind the hood.
[00:03:21.800 --> 00:03:23.640]   You know, Tesla yesterday demonstrated,
[00:03:23.640 --> 00:03:25.240]   yesterday, two days ago maybe,
[00:03:25.240 --> 00:03:27.080]   demonstrated some like pretty incredible
[00:03:27.080 --> 00:03:28.920]   self-driving capabilities.
[00:03:28.920 --> 00:03:31.240]   Their team there relies pretty heavily on deep learning
[00:03:31.240 --> 00:03:32.600]   for their perception stack.
[00:03:32.600 --> 00:03:35.920]   Speech to text is, you know,
[00:03:35.920 --> 00:03:37.640]   mostly deep learning based now.
[00:03:37.640 --> 00:03:39.160]   Photo tagging.
[00:03:39.160 --> 00:03:41.180]   And then, you know, up on the right,
[00:03:41.180 --> 00:03:44.560]   this is kind of like a press image from DeepMind's
[00:03:44.560 --> 00:03:48.780]   data center optimization program,
[00:03:48.780 --> 00:03:50.520]   where they used deep reinforcement learning
[00:03:50.520 --> 00:03:52.940]   to reduce cooling costs in their data centers
[00:03:52.940 --> 00:03:55.480]   by something like 30%.
[00:03:55.480 --> 00:03:56.840]   And so this is kind of like,
[00:03:56.840 --> 00:03:58.880]   this is really inspirational to me,
[00:03:58.880 --> 00:04:00.960]   because it's like all the stuff that, you know,
[00:04:00.960 --> 00:04:03.240]   people at Berkeley and other places are writing papers about
[00:04:03.240 --> 00:04:07.380]   is really quickly making its way into the real world.
[00:04:07.380 --> 00:04:12.040]   But what's kind of challenging about that is that,
[00:04:12.040 --> 00:04:13.560]   you know, deploying deep learning systems
[00:04:13.560 --> 00:04:16.880]   is really different than deploying typical software systems.
[00:04:17.860 --> 00:04:21.620]   And so, you know, there's a bunch of reasons for that.
[00:04:21.620 --> 00:04:25.140]   I like this cartoon from XKCD.
[00:04:25.140 --> 00:04:27.980]   So it's like, this is kind of a characterization
[00:04:27.980 --> 00:04:29.180]   of a machine learning system, right?
[00:04:29.180 --> 00:04:33.700]   Like, you know, you have this pile of data and, you know,
[00:04:33.700 --> 00:04:35.720]   and then you stir it around and then eventually,
[00:04:35.720 --> 00:04:39.520]   like maybe some magical answer pops out, right?
[00:04:39.520 --> 00:04:41.160]   So the idea here is that like deep learning
[00:04:41.160 --> 00:04:44.060]   is like really a black box, I think, for a lot of people.
[00:04:45.420 --> 00:04:47.040]   But it's worse than that.
[00:04:47.040 --> 00:04:49.360]   Deep learning also creates a ton of technical debt.
[00:04:49.360 --> 00:04:51.360]   And there was a great paper about this,
[00:04:51.360 --> 00:04:53.640]   from 2016 from Google,
[00:04:53.640 --> 00:04:55.220]   the high interest credit card of technical debt.
[00:04:55.220 --> 00:04:58.080]   I would highly recommend reading this at some point,
[00:04:58.080 --> 00:05:00.400]   because they point out a lot of ways in which
[00:05:00.400 --> 00:05:01.760]   building machine learning systems, you know,
[00:05:01.760 --> 00:05:03.280]   while it kind of feels like cheating,
[00:05:03.280 --> 00:05:04.760]   you're getting the algorithm to figure out
[00:05:04.760 --> 00:05:06.160]   the answer for you.
[00:05:06.160 --> 00:05:09.140]   In reality, you're kind of accelerating the rate at which
[00:05:09.140 --> 00:05:11.660]   you're, you know, doing things that are not gonna scale
[00:05:11.660 --> 00:05:13.720]   with your engineering system.
[00:05:14.720 --> 00:05:17.560]   And then lastly, kind of there's this idea that maybe
[00:05:17.560 --> 00:05:20.680]   actually deep learning is not really software engineering
[00:05:20.680 --> 00:05:22.360]   at all, it's actually an entirely different
[00:05:22.360 --> 00:05:23.760]   programming paradigm.
[00:05:23.760 --> 00:05:26.560]   And so this is a slide from Andrej Karpathy,
[00:05:26.560 --> 00:05:28.880]   who has this idea of software 2.0.
[00:05:28.880 --> 00:05:32.560]   And the idea is basically, you know, in software 1.0,
[00:05:32.560 --> 00:05:36.000]   traditional programming, you have some goal
[00:05:36.000 --> 00:05:39.600]   and then a human manually encodes some rules
[00:05:39.600 --> 00:05:42.280]   that help the machine solve the problem.
[00:05:42.280 --> 00:05:44.880]   That help the machine solve that goal.
[00:05:44.880 --> 00:05:48.980]   And, you know, in AI programming,
[00:05:48.980 --> 00:05:51.720]   you have some abstract goal, like you have some,
[00:05:51.720 --> 00:05:54.480]   something that you want the system to be able to do.
[00:05:54.480 --> 00:05:57.560]   And then the way that you program the system is through data.
[00:05:57.560 --> 00:05:59.640]   And so the programmers in this paradigm are actually people
[00:05:59.640 --> 00:06:02.200]   who are collecting and labeling data sets.
[00:06:02.200 --> 00:06:06.080]   And then there's an optimization program that
[00:06:06.080 --> 00:06:08.720]   selects the best program from within program space
[00:06:08.720 --> 00:06:09.880]   to achieve that outcome.
[00:06:11.200 --> 00:06:14.000]   And so if you ascribe to this viewpoint, then, you know,
[00:06:14.000 --> 00:06:16.240]   you might think that deep learning programming
[00:06:16.240 --> 00:06:19.080]   is something entirely different than software engineering.
[00:06:19.080 --> 00:06:23.740]   And so I think, you know,
[00:06:23.740 --> 00:06:28.580]   one of the side effects of all of this kind of
[00:06:28.580 --> 00:06:30.880]   getting adoption in industry so fast is that
[00:06:30.880 --> 00:06:34.240]   a lot of the knowledge of how to do this well, right?
[00:06:34.240 --> 00:06:36.280]   So it's different than software engineering.
[00:06:36.280 --> 00:06:40.480]   It's harder in some ways and easier in some ways,
[00:06:40.480 --> 00:06:42.440]   but the way, the knowledge of how to do that
[00:06:42.440 --> 00:06:45.360]   is kind of locked away in big companies, right?
[00:06:45.360 --> 00:06:49.940]   I think, you know, Google employs a huge percentage
[00:06:49.940 --> 00:06:53.520]   of the people who are great machine learning engineers.
[00:06:53.520 --> 00:06:55.840]   And in general, I think people that I've talked to
[00:06:55.840 --> 00:06:58.160]   at startups talk about how difficult it is to find people
[00:06:58.160 --> 00:07:00.660]   who have experience deploying systems like this
[00:07:00.660 --> 00:07:01.560]   in the real world.
[00:07:01.560 --> 00:07:05.340]   And then, you know, in addition to kind of talent
[00:07:05.340 --> 00:07:07.520]   being concentrated, a lot of times these rules,
[00:07:07.520 --> 00:07:09.920]   like just really aren't written down and you have to,
[00:07:09.920 --> 00:07:11.960]   you know, one thing that I found really surprising
[00:07:11.960 --> 00:07:13.800]   when I started working in the field was, you know,
[00:07:13.800 --> 00:07:16.200]   I thought that if you just read all the papers,
[00:07:16.200 --> 00:07:18.620]   then you could learn everything there is to know
[00:07:18.620 --> 00:07:22.380]   about machine learning, but that was very naive thing
[00:07:22.380 --> 00:07:23.560]   to assume.
[00:07:23.560 --> 00:07:25.300]   It turns out that like really one of the best ways
[00:07:25.300 --> 00:07:27.360]   to learn this stuff is to go and talk to the people
[00:07:27.360 --> 00:07:28.320]   that already know how to do it,
[00:07:28.320 --> 00:07:29.840]   because a lot of this information
[00:07:29.840 --> 00:07:31.480]   is really trapped in their heads.
[00:07:31.480 --> 00:07:36.040]   And even once you get a handle on things, you know,
[00:07:36.040 --> 00:07:39.140]   the field is still evolving so rapidly that it's, you know,
[00:07:39.140 --> 00:07:41.600]   it's often difficult to hold onto that.
[00:07:41.600 --> 00:07:43.640]   And, you know, I think another thing that I've heard
[00:07:43.640 --> 00:07:46.560]   from a lot of organizations is that a lot of these practices
[00:07:46.560 --> 00:07:48.880]   around like how do we actually get these systems to work
[00:07:48.880 --> 00:07:50.580]   is kind of figured out on the fly.
[00:07:50.580 --> 00:07:53.800]   And so, you know, the reason that we put together
[00:07:53.800 --> 00:07:57.480]   this course in part is to try to teach you, you know,
[00:07:57.480 --> 00:08:01.940]   some of what we as practitioners know about this.
[00:08:01.940 --> 00:08:03.520]   So to, you know, solve the problem of things
[00:08:03.520 --> 00:08:05.040]   not being written down.
[00:08:05.040 --> 00:08:07.160]   But I think the, you know, the goal is actually bigger
[00:08:07.160 --> 00:08:12.160]   than that and, you know, hope you all have had a few minutes
[00:08:12.160 --> 00:08:13.020]   to chat with each other.
[00:08:13.020 --> 00:08:14.740]   And I think one of the great things about this class
[00:08:14.740 --> 00:08:17.900]   is we have pretty amazing set of participants.
[00:08:17.900 --> 00:08:22.900]   And so I hope that throughout the course of the class,
[00:08:22.900 --> 00:08:25.560]   you get a chance to get to know each other
[00:08:25.560 --> 00:08:27.900]   and share knowledge and kind of just talk about
[00:08:27.900 --> 00:08:28.980]   the challenges that you're facing
[00:08:28.980 --> 00:08:30.280]   as you're learning the field
[00:08:30.280 --> 00:08:32.800]   or as you're actually going and deploying stuff.
[00:08:32.800 --> 00:08:33.980]   So just have a community of people
[00:08:33.980 --> 00:08:36.120]   that are all thinking about these problems.
[00:08:36.740 --> 00:08:41.180]   And then the last goal is really to learn by doing.
[00:08:41.180 --> 00:08:46.760]   So, you know, again, most of machine learning is,
[00:08:46.760 --> 00:08:48.820]   machine learning is an empirical science
[00:08:48.820 --> 00:08:51.520]   and a lot of what you need to know about it,
[00:08:51.520 --> 00:08:53.080]   you can only kind of really figure it out
[00:08:53.080 --> 00:08:55.680]   by going and trying this stuff on your own.
[00:08:55.680 --> 00:08:56.980]   And so the way that we set up this class
[00:08:56.980 --> 00:08:59.940]   is it's centered around a project.
[00:08:59.940 --> 00:09:01.120]   And, you know, we're gonna have,
[00:09:01.120 --> 00:09:02.640]   I'll talk in more detail about this later,
[00:09:02.640 --> 00:09:06.300]   but we're gonna have kind of four or five people per team,
[00:09:06.300 --> 00:09:08.180]   or actually three to four people per team,
[00:09:08.180 --> 00:09:10.660]   and you're gonna pick sort of apply deep learning project
[00:09:10.660 --> 00:09:15.300]   and work on it together throughout the course of the class.
[00:09:15.300 --> 00:09:16.940]   In addition to that,
[00:09:16.940 --> 00:09:19.580]   we're trying out a flip classroom style.
[00:09:19.580 --> 00:09:22.260]   So we have a bunch of lectures on this subject
[00:09:22.260 --> 00:09:26.220]   that we recorded for full stack deep learning bootcamp.
[00:09:26.220 --> 00:09:27.980]   And so one thing that we're gonna do in this class
[00:09:27.980 --> 00:09:30.100]   is we're gonna have you all watch the, you know,
[00:09:30.100 --> 00:09:32.560]   the lecture videos before you come to class.
[00:09:32.560 --> 00:09:33.680]   And for the most part,
[00:09:33.680 --> 00:09:35.240]   and this class will be a bit of an exception,
[00:09:35.240 --> 00:09:36.200]   but for the most part,
[00:09:36.200 --> 00:09:38.320]   the goal is to like kind of minimize the amount of time
[00:09:38.320 --> 00:09:41.320]   that I'm talking at you and to, you know,
[00:09:41.320 --> 00:09:43.680]   spend more time listening to guest lecturers,
[00:09:43.680 --> 00:09:45.520]   share their experience and kind of working
[00:09:45.520 --> 00:09:46.660]   on exercises together.
[00:09:46.660 --> 00:09:54.960]   I'll say a few more words about the project.
[00:09:54.960 --> 00:09:57.200]   You know, we have seven or so weeks.
[00:09:57.200 --> 00:10:00.920]   And so, you know, it's a pretty tight timeline
[00:10:00.920 --> 00:10:03.720]   to do a really good machine learning project,
[00:10:03.720 --> 00:10:04.840]   but it's very, very doable.
[00:10:04.840 --> 00:10:06.800]   And so the goal is like really to get a demo
[00:10:06.800 --> 00:10:08.800]   of what your system looks like end to end.
[00:10:08.800 --> 00:10:11.880]   You know, we're not expecting to like fully solve,
[00:10:11.880 --> 00:10:13.500]   solve this problem.
[00:10:13.500 --> 00:10:14.920]   And my other goal is like,
[00:10:14.920 --> 00:10:16.400]   I really want everyone to work on something
[00:10:16.400 --> 00:10:17.760]   that they're excited about.
[00:10:17.760 --> 00:10:21.400]   And so I've compiled a list of project ideas
[00:10:21.400 --> 00:10:24.100]   that I'll share with you towards the end of class.
[00:10:24.100 --> 00:10:26.560]   But my hope is that a lot of people have their own ideas
[00:10:26.560 --> 00:10:28.640]   about what would be a fun project to work on.
[00:10:28.640 --> 00:10:30.440]   And, you know, I would really like you
[00:10:30.440 --> 00:10:32.440]   to work on those ideas and maybe even convince
[00:10:32.440 --> 00:10:34.880]   some of your classmates to work on them with you.
[00:10:34.880 --> 00:10:38.940]   And then the last thing to say here, just so, you know,
[00:10:38.940 --> 00:10:40.440]   so it doesn't catch you by surprise at the end,
[00:10:40.440 --> 00:10:44.400]   but we're gonna ask everyone to kind of put together
[00:10:44.400 --> 00:10:47.520]   a presentation about their project at the end of the class.
[00:10:47.520 --> 00:10:50.160]   And this is really just meant as a way of, you know,
[00:10:50.160 --> 00:10:53.240]   providing you like kind of a goal at the end of the class,
[00:10:53.240 --> 00:10:54.440]   something that you can build up to.
[00:10:54.440 --> 00:10:57.160]   And I think that people are gonna do pretty amazing things.
[00:10:57.160 --> 00:10:59.640]   And so I hope it's also inspirational
[00:10:59.640 --> 00:11:02.360]   to see what your classmates were able to produce.
[00:11:02.360 --> 00:11:08.800]   Schedule for the class.
[00:11:08.800 --> 00:11:11.840]   This is also up on the website, but you know,
[00:11:11.840 --> 00:11:15.040]   this week we're gonna talk about selecting
[00:11:15.040 --> 00:11:16.400]   and scoping a project.
[00:11:16.400 --> 00:11:19.560]   Next week, we're gonna talk about, you know,
[00:11:19.560 --> 00:11:20.960]   once you have a machine learning project,
[00:11:20.960 --> 00:11:21.800]   you need some data.
[00:11:21.800 --> 00:11:23.640]   And so we're gonna talk about kind of best practices
[00:11:23.640 --> 00:11:26.520]   for designing a dataset and managing that dataset.
[00:11:26.520 --> 00:11:29.400]   Then we're gonna talk about troubleshooting.
[00:11:29.400 --> 00:11:31.920]   So, you know, when you're training your model,
[00:11:31.920 --> 00:11:32.960]   things go wrong.
[00:11:32.960 --> 00:11:36.200]   How do you figure out what the next step is
[00:11:36.200 --> 00:11:37.640]   and what to do about that?
[00:11:37.640 --> 00:11:40.600]   And then we're gonna talk about infrastructure
[00:11:40.600 --> 00:11:41.900]   and tests and tooling.
[00:11:41.900 --> 00:11:44.840]   So, you know, you're working on a larger team
[00:11:44.840 --> 00:11:46.360]   on this machine learning project.
[00:11:46.360 --> 00:11:49.560]   What is, you know, what is best in class infrastructure
[00:11:49.560 --> 00:11:50.400]   look like there?
[00:11:51.560 --> 00:11:53.760]   Then we'll kind of have an interlude to hear
[00:11:53.760 --> 00:11:56.720]   from Peter Abbeel about research areas.
[00:11:56.720 --> 00:11:58.840]   Since machine learning is moving so fast,
[00:11:58.840 --> 00:12:00.880]   it's more important in this field than in most fields
[00:12:00.880 --> 00:12:02.160]   to kind of try to stay up to date
[00:12:02.160 --> 00:12:04.360]   on what the latest research is.
[00:12:04.360 --> 00:12:06.640]   Because, you know, oftentimes people will, you know,
[00:12:06.640 --> 00:12:08.680]   very quickly beat what you think is the state of the art
[00:12:08.680 --> 00:12:09.500]   on some problem.
[00:12:09.500 --> 00:12:12.080]   And so this will be a good way to get a sense of that.
[00:12:12.080 --> 00:12:15.560]   Kind of the last class week,
[00:12:15.560 --> 00:12:18.220]   we'll be talking about continuous integration and testing.
[00:12:18.220 --> 00:12:20.480]   So, you know, for those of you that are software engineers,
[00:12:20.480 --> 00:12:21.640]   you've probably thought a lot about this,
[00:12:21.640 --> 00:12:24.520]   but testing and continuous integration,
[00:12:24.520 --> 00:12:26.360]   there are a lot of things that are slightly different
[00:12:26.360 --> 00:12:28.000]   in a machine learning context.
[00:12:28.000 --> 00:12:29.640]   And so we'll cover that.
[00:12:29.640 --> 00:12:33.040]   Final week will just be the project presentations.
[00:12:33.040 --> 00:12:39.920]   There's a couple of things that we're gonna ask you to do
[00:12:39.920 --> 00:12:42.060]   just to be prepared for each week.
[00:12:42.060 --> 00:12:43.180]   The first, as I already mentioned,
[00:12:43.180 --> 00:12:46.800]   is to watch a lecture video on your own before.
[00:12:46.800 --> 00:12:48.040]   And, you know, as you're watching,
[00:12:48.040 --> 00:12:50.400]   I would encourage you just to kind of write down
[00:12:50.400 --> 00:12:52.880]   all the questions you have.
[00:12:52.880 --> 00:12:55.400]   I will make time in each class to, you know,
[00:12:55.400 --> 00:12:57.000]   do a quick summary of the lecture
[00:12:57.000 --> 00:13:00.200]   and make sure that there's a chance to answer any questions.
[00:13:00.200 --> 00:13:04.280]   Then also, I think it's important to start making progress
[00:13:04.280 --> 00:13:05.640]   on your project early.
[00:13:05.640 --> 00:13:08.080]   And so we're gonna have a mechanism for this,
[00:13:08.080 --> 00:13:11.120]   which is we're gonna have a project update Slack channel,
[00:13:11.120 --> 00:13:13.040]   which I think is already created.
[00:13:13.040 --> 00:13:17.480]   And we just want you, you know, to be posting updates
[00:13:17.480 --> 00:13:18.840]   kind of like maybe around Tuesday
[00:13:19.320 --> 00:13:21.120]   by the end of day each week,
[00:13:21.120 --> 00:13:22.400]   just to hold yourself accountable
[00:13:22.400 --> 00:13:24.720]   to like making progress on the project every week.
[00:13:24.720 --> 00:13:26.080]   And then I'll be going through those
[00:13:26.080 --> 00:13:28.920]   and, you know, just giving feedback and helping you
[00:13:28.920 --> 00:13:30.420]   if you are stuck on anything.
[00:13:30.420 --> 00:13:36.120]   Cool, that's a bit about the class.
[00:13:36.120 --> 00:13:37.520]   Are there any questions about, you know,
[00:13:37.520 --> 00:13:39.960]   what we're gonna cover or what this is all about?
[00:13:39.960 --> 00:13:47.240]   Yeah.
[00:13:47.240 --> 00:13:48.280]   - Can you make slides available?
[00:13:48.280 --> 00:13:49.560]   - I can make slides available, yeah.
[00:13:49.560 --> 00:13:50.760]   I'll post them on Slack.
[00:13:50.760 --> 00:13:54.160]   I'll try to, I'll post it after class today
[00:13:54.160 --> 00:13:56.320]   and I'll try to do it before class going forward.
[00:13:56.320 --> 00:14:01.120]   - I'm assuming this is probably a guess,
[00:14:01.120 --> 00:14:02.960]   but like it's expectation that they're bringing,
[00:14:02.960 --> 00:14:05.920]   organizing a lot of other class meetings with their teams
[00:14:05.920 --> 00:14:07.760]   to spend time together working on projects.
[00:14:07.760 --> 00:14:09.680]   - Yeah, it's kind of up to you how you wanna do that.
[00:14:09.680 --> 00:14:13.380]   I think, you know, if you all live nearby each other
[00:14:13.380 --> 00:14:14.560]   and you wanna just meet up after work,
[00:14:14.560 --> 00:14:16.560]   then I think that's a great way to do it.
[00:14:17.400 --> 00:14:20.200]   It's very possible to do it asynchronously as well.
[00:14:20.200 --> 00:14:27.280]   Great.
[00:14:27.280 --> 00:14:30.560]   So what are we gonna cover for the rest of today?
[00:14:30.560 --> 00:14:35.020]   The first thing I'll do is just kind of, you know,
[00:14:35.020 --> 00:14:37.920]   actually the project selection lecture.
[00:14:37.920 --> 00:14:43.120]   Okay, almost everyone, almost everyone is,
[00:14:43.120 --> 00:14:44.720]   is at least not admitting that they didn't have a chance
[00:14:44.720 --> 00:14:45.560]   to watch it.
[00:14:46.600 --> 00:14:49.120]   Regardless, I'm gonna quickly review it
[00:14:49.120 --> 00:14:50.500]   just to kind of catch the highlights
[00:14:50.500 --> 00:14:53.160]   and refresh your memory and, you know,
[00:14:53.160 --> 00:14:54.800]   give you a chance to ask any questions
[00:14:54.800 --> 00:14:56.200]   you had about that material.
[00:14:56.200 --> 00:15:00.060]   Then I wanna actually build on a couple of points
[00:15:00.060 --> 00:15:02.640]   that we covered in that lecture.
[00:15:02.640 --> 00:15:05.480]   One is, you know, we kind of breezed over this question
[00:15:05.480 --> 00:15:08.440]   in that lecture of how to think about, you know,
[00:15:08.440 --> 00:15:09.960]   what machine learning problems are easy
[00:15:09.960 --> 00:15:12.160]   and what machine learning problems are hard
[00:15:12.160 --> 00:15:13.440]   beyond data availability.
[00:15:13.440 --> 00:15:18.000]   Like, right, like what problems are hard to train models on?
[00:15:18.000 --> 00:15:19.320]   So I put together some thoughts on that
[00:15:19.320 --> 00:15:20.960]   and we'll talk through that.
[00:15:20.960 --> 00:15:23.240]   And then also in that lecture,
[00:15:23.240 --> 00:15:26.520]   we skipped over how to think about setting up a code base.
[00:15:26.520 --> 00:15:29.960]   And so, you know, with the remaining time, we'll talk,
[00:15:29.960 --> 00:15:32.960]   I'll walk you through kind of what a relatively mature
[00:15:32.960 --> 00:15:34.880]   machine learning code base looks like.
[00:15:34.880 --> 00:15:37.240]   So you can have some inspiration for how you wanna set things
[00:15:37.240 --> 00:15:39.120]   up for your project.
[00:15:39.120 --> 00:15:41.080]   And then we'll talk about homework for next week.
[00:15:41.080 --> 00:15:44.200]   And then we have our guest speaker, Neil, at the end.
[00:15:44.200 --> 00:15:50.580]   All right, so to review,
[00:15:50.580 --> 00:15:54.080]   we covered a few things in this project
[00:15:54.080 --> 00:15:56.200]   and the first one, or in this lecture rather.
[00:15:56.200 --> 00:15:58.560]   And the first was how to think about the lifecycle
[00:15:58.560 --> 00:16:00.060]   of a machine learning project.
[00:16:00.060 --> 00:16:04.160]   And so to review, you know, there's kind of a bunch
[00:16:04.160 --> 00:16:06.680]   of different steps that happen in any machine learning
[00:16:06.680 --> 00:16:08.400]   project that you're working on.
[00:16:08.400 --> 00:16:10.680]   The first is, you know, planning and project setup.
[00:16:10.680 --> 00:16:14.720]   So, you know, what are we gonna work on at an abstract level
[00:16:14.720 --> 00:16:17.180]   and then more specifically, like in a machine learning
[00:16:17.180 --> 00:16:20.120]   context, what metric are we actually gonna be optimizing?
[00:16:20.120 --> 00:16:23.880]   Once you kind of have a plan for your project,
[00:16:23.880 --> 00:16:27.080]   then you go and collect a dataset and you label it.
[00:16:27.080 --> 00:16:30.400]   And once you have a labeled dataset,
[00:16:30.400 --> 00:16:32.380]   then you go and train a model and debug it.
[00:16:32.380 --> 00:16:34.000]   And once you're happy with the performance,
[00:16:34.000 --> 00:16:35.680]   you deploy it and you test it.
[00:16:35.680 --> 00:16:37.640]   And the key point here was that, like,
[00:16:37.640 --> 00:16:40.760]   this is not actually a linear flow from beginning to end.
[00:16:40.760 --> 00:16:43.400]   What actually happens in practice is that people
[00:16:43.400 --> 00:16:45.280]   kind of move through these steps fluidly
[00:16:45.280 --> 00:16:46.780]   and loop back frequently.
[00:16:46.780 --> 00:16:49.760]   So for example, you know, if you're collecting your dataset
[00:16:49.760 --> 00:16:52.280]   and you realize, actually this is kind of impossible
[00:16:52.280 --> 00:16:54.320]   to get labeled data for this problem, right?
[00:16:54.320 --> 00:16:56.180]   Then you might go back to project planning and say,
[00:16:56.180 --> 00:16:57.800]   like, okay, is there a different way of formulating
[00:16:57.800 --> 00:17:00.520]   this problem where it's easier for us to get labeled data?
[00:17:00.520 --> 00:17:03.200]   Similarly, if you're, you know, if you're training
[00:17:03.200 --> 00:17:06.680]   your model and you just can't get the loss low enough,
[00:17:06.680 --> 00:17:08.720]   like it just doesn't really seem to be possible
[00:17:08.720 --> 00:17:11.120]   to get a model to work well enough on this dataset,
[00:17:11.120 --> 00:17:13.620]   then you might go back and look at your data collection
[00:17:13.620 --> 00:17:15.640]   process and you might see if there's like maybe
[00:17:15.640 --> 00:17:19.000]   some mislabeled data or if there's, you know,
[00:17:19.000 --> 00:17:20.480]   some way of making that easier,
[00:17:20.480 --> 00:17:22.280]   or you might go back to project planning and say,
[00:17:22.280 --> 00:17:24.040]   you know what, this isn't gonna work.
[00:17:24.040 --> 00:17:27.520]   And then finally, like in the deployment stage,
[00:17:27.520 --> 00:17:29.600]   I think this is like a really, really common point
[00:17:29.600 --> 00:17:31.180]   for things to loop back.
[00:17:31.180 --> 00:17:33.320]   You know, in like academic machine learning,
[00:17:33.320 --> 00:17:36.600]   you're typically given a dataset and you train models
[00:17:36.600 --> 00:17:39.200]   over and over and over on that dataset until your loss,
[00:17:39.200 --> 00:17:42.080]   like finally gets low enough and then you're like, yes,
[00:17:42.080 --> 00:17:44.240]   and you publish the paper and you're done.
[00:17:44.240 --> 00:17:45.280]   It's really exciting.
[00:17:45.280 --> 00:17:48.040]   But in the real world, it doesn't work that way, right?
[00:17:48.040 --> 00:17:51.040]   Because in the real world, you have, you know,
[00:17:51.040 --> 00:17:53.680]   way more varied data than you can possibly collect
[00:17:53.680 --> 00:17:58.680]   a small dataset to cover.
[00:17:58.680 --> 00:18:01.540]   And so what often happens is you deploy your model
[00:18:01.540 --> 00:18:04.120]   in production or like hopefully in some sandbox version
[00:18:04.120 --> 00:18:06.040]   of production, and then you realize like,
[00:18:06.040 --> 00:18:08.600]   hey, this isn't actually doing exactly what we want it
[00:18:08.600 --> 00:18:10.000]   to do.
[00:18:10.000 --> 00:18:12.120]   And so that's, you know, often when people will go back
[00:18:12.120 --> 00:18:14.720]   and, you know, figure out what the edge cases are,
[00:18:14.720 --> 00:18:18.740]   recollect data, or maybe add some other metric
[00:18:18.740 --> 00:18:21.560]   that they wanna make sure that their model is optimizing.
[00:18:21.560 --> 00:18:26.200]   And so beyond the stuff that happens for every project,
[00:18:26.200 --> 00:18:28.440]   there's also kind of things that go into making
[00:18:28.440 --> 00:18:31.680]   a really good machine learning team.
[00:18:31.680 --> 00:18:33.320]   One of them is like, just kind of how do you find
[00:18:33.320 --> 00:18:34.160]   good people?
[00:18:34.160 --> 00:18:35.560]   How do you hire?
[00:18:35.560 --> 00:18:37.380]   How do you manage a machine learning team?
[00:18:37.380 --> 00:18:39.800]   And then the other is what is infrastructure
[00:18:39.800 --> 00:18:42.320]   and tooling look like to, you know, be able to run
[00:18:42.320 --> 00:18:44.680]   a number of these projects successfully.
[00:18:44.680 --> 00:18:47.920]   And we'll talk about almost all of these things
[00:18:47.920 --> 00:18:50.140]   throughout the course of this class.
[00:18:50.140 --> 00:18:54.500]   Were there any questions on this concept,
[00:18:54.500 --> 00:18:56.620]   like kind of how the life cycle of a machine learning
[00:18:56.620 --> 00:18:57.460]   project evolves?
[00:19:03.140 --> 00:19:03.980]   Okay, good.
[00:19:03.980 --> 00:19:08.040]   The next thing that we talked about was, you know,
[00:19:08.040 --> 00:19:09.760]   you're in this planning phase, right?
[00:19:09.760 --> 00:19:11.800]   And so you're trying to figure out like,
[00:19:11.800 --> 00:19:13.680]   we have this machine learning team, you know,
[00:19:13.680 --> 00:19:16.800]   amazing machine learning engineers, what should we work on?
[00:19:16.800 --> 00:19:18.980]   Like what's gonna be the highest impact thing
[00:19:18.980 --> 00:19:20.380]   that we could possibly find?
[00:19:20.380 --> 00:19:24.760]   This is a really hard problem, but you know,
[00:19:24.760 --> 00:19:26.520]   there are a couple of mental models that we talked about
[00:19:26.520 --> 00:19:29.480]   that can be useful when you're thinking about this.
[00:19:29.480 --> 00:19:32.200]   One is the idea that like, fundamentally,
[00:19:32.200 --> 00:19:34.080]   one of the things that machine learning really does
[00:19:34.080 --> 00:19:38.520]   is it allows you to create zero cost predictions.
[00:19:38.520 --> 00:19:41.320]   So, you know, traditionally, like if you want someone
[00:19:41.320 --> 00:19:43.600]   to predict something for you, like if you,
[00:19:43.600 --> 00:19:44.860]   and you want that person to be good,
[00:19:44.860 --> 00:19:46.980]   it's gonna be expensive to ask them like, okay,
[00:19:46.980 --> 00:19:49.160]   what is, you know, which way should I turn the steering
[00:19:49.160 --> 00:19:53.400]   wheel or, you know, what is the economy gonna do next year?
[00:19:53.400 --> 00:19:55.160]   But in machine learning, if you have a trained system,
[00:19:55.160 --> 00:19:57.800]   then that, you know, the marginal cost of producing
[00:19:57.800 --> 00:19:59.360]   additional predictions is zero.
[00:20:00.220 --> 00:20:02.500]   And so you can, you know, one thing to think about
[00:20:02.500 --> 00:20:05.260]   is like within your organization, what are places
[00:20:05.260 --> 00:20:07.900]   where like free prediction essentially
[00:20:07.900 --> 00:20:09.300]   would make a big difference?
[00:20:09.300 --> 00:20:12.300]   And then the second, and this comes back
[00:20:12.300 --> 00:20:15.820]   to this software 2.0 idea, but you know,
[00:20:15.820 --> 00:20:18.220]   where can you take, you know, if the idea is that like
[00:20:18.220 --> 00:20:21.420]   gradient descents can write better code than you, right?
[00:20:21.420 --> 00:20:23.500]   This is kind of tongue in cheek, like it actually,
[00:20:23.500 --> 00:20:26.420]   you know, can't write better code than you in most cases,
[00:20:26.420 --> 00:20:29.500]   but in some cases, like your optimization algorithm
[00:20:29.500 --> 00:20:32.260]   is gonna find a much better way of, you know,
[00:20:32.260 --> 00:20:35.860]   classifying images or translating text
[00:20:35.860 --> 00:20:39.060]   than you can possibly do with a rules-based system.
[00:20:39.060 --> 00:20:42.020]   And so thinking about parts of your software pipeline
[00:20:42.020 --> 00:20:44.220]   where you have like a bunch of handwritten rules,
[00:20:44.220 --> 00:20:47.800]   a bunch of heuristics, and then thinking about
[00:20:47.800 --> 00:20:49.520]   how you can automate them.
[00:20:49.520 --> 00:20:55.180]   Yeah, question in the back.
[00:20:55.180 --> 00:20:58.220]   - Where does stuff that was not possible
[00:20:58.220 --> 00:21:00.660]   before these learning fit into this bucket?
[00:21:00.660 --> 00:21:03.580]   So something like auto-reply, it's almost,
[00:21:03.580 --> 00:21:05.820]   it's near impossible, it's not cheap,
[00:21:05.820 --> 00:21:07.100]   but it's near impossible to do it
[00:21:07.100 --> 00:21:10.260]   in manual software techniques.
[00:21:10.260 --> 00:21:13.340]   - Yeah, so how would you think about auto-reply?
[00:21:13.340 --> 00:21:18.020]   I would say that like, you could imagine auto-reply
[00:21:18.020 --> 00:21:19.520]   before machine learning, right?
[00:21:19.520 --> 00:21:21.460]   You could say like, maybe, you know,
[00:21:21.460 --> 00:21:25.300]   if like if Google's customers were high enough value,
[00:21:25.300 --> 00:21:27.900]   then they would totally just hire people to, you know,
[00:21:27.900 --> 00:21:30.700]   come up with suggested replies for you, right?
[00:21:30.700 --> 00:21:32.140]   But the problem is that like, you know,
[00:21:32.140 --> 00:21:33.860]   I'm not creating that much value for Google,
[00:21:33.860 --> 00:21:36.180]   so they're not willing to pay someone
[00:21:36.180 --> 00:21:38.560]   to write my emails for me, unfortunately.
[00:21:38.560 --> 00:21:41.580]   But if it's free, then they might as well do that.
[00:21:41.580 --> 00:21:51.580]   Other questions about how to think about
[00:21:51.580 --> 00:21:53.900]   how to find high impact projects?
[00:21:53.900 --> 00:21:55.300]   I'm kind of expecting a lot of questions here,
[00:21:55.300 --> 00:21:58.900]   'cause I feel like, you know, this doesn't really,
[00:21:58.900 --> 00:22:00.420]   this is not comprehensive, right?
[00:22:00.420 --> 00:22:04.380]   Like, there are a lot of projects that are high impact
[00:22:04.380 --> 00:22:06.180]   that are not covered by either of these things,
[00:22:06.180 --> 00:22:09.180]   and you know, this is kind of vague in some sense, right?
[00:22:09.180 --> 00:22:10.660]   So like, how do you all think about this?
[00:22:10.660 --> 00:22:11.500]   Yeah.
[00:22:11.500 --> 00:22:15.340]   - This is maybe answering a slightly different question,
[00:22:15.340 --> 00:22:17.460]   but when you're saying high impact ML projects,
[00:22:17.460 --> 00:22:20.900]   you're thinking of like very specific applied use cases.
[00:22:20.900 --> 00:22:23.100]   Do you have any sort of general advice
[00:22:23.100 --> 00:22:25.740]   if you're interested in like a more research flavored,
[00:22:25.740 --> 00:22:27.420]   but still high impact project?
[00:22:27.420 --> 00:22:32.020]   - Yeah.
[00:22:32.020 --> 00:22:36.380]   So yeah, so the question was how to think about this
[00:22:36.380 --> 00:22:38.260]   if you're interested in finding a project
[00:22:38.260 --> 00:22:40.940]   that's high impact like in a business sense,
[00:22:40.940 --> 00:22:42.780]   but also is really interesting from a research sense.
[00:22:42.780 --> 00:22:43.620]   Is that?
[00:22:43.620 --> 00:22:45.500]   Yeah, I think like, I mean,
[00:22:45.500 --> 00:22:48.140]   the currency of like interesting research,
[00:22:48.140 --> 00:22:49.780]   most people would say is novelty.
[00:22:49.780 --> 00:22:52.420]   And so the thing I would look for there is like,
[00:22:52.420 --> 00:22:56.380]   I would look at projects that you think
[00:22:56.380 --> 00:22:58.060]   could have a big impact to like,
[00:22:58.060 --> 00:23:01.260]   that you can make a bit.
[00:23:01.260 --> 00:23:02.740]   And then I would think about the ones where
[00:23:02.740 --> 00:23:04.940]   like you kind of know what the answer is already.
[00:23:04.940 --> 00:23:07.180]   Like, okay, we could, you know,
[00:23:07.180 --> 00:23:08.900]   we kind of know how to do classification.
[00:23:08.900 --> 00:23:10.020]   We need to build a big data set,
[00:23:10.020 --> 00:23:11.620]   and then we need to train a model,
[00:23:11.620 --> 00:23:15.240]   like a confident to classify things in those images.
[00:23:15.240 --> 00:23:18.940]   But, you know, if the application itself
[00:23:18.940 --> 00:23:22.300]   is sort of more like something that's really difficult,
[00:23:22.300 --> 00:23:24.340]   that's like less understood
[00:23:24.340 --> 00:23:25.580]   how you actually do that with machine learning,
[00:23:25.580 --> 00:23:27.140]   then that can be a good way
[00:23:27.140 --> 00:23:29.060]   of finding problems like that, I think.
[00:23:29.060 --> 00:23:32.060]   Yeah.
[00:23:32.060 --> 00:23:36.940]   Oh yeah, cost is on the next slide.
[00:23:36.940 --> 00:23:38.540]   Yeah, that's a good point though.
[00:23:38.540 --> 00:23:40.340]   Yeah.
[00:23:40.340 --> 00:23:43.260]   (student speaking)
[00:23:44.100 --> 00:23:47.380]   The, again, uncheap thing,
[00:23:47.380 --> 00:23:51.740]   but the kind of advantage of resilience
[00:23:51.740 --> 00:23:53.740]   and resilience of particular rules
[00:23:53.740 --> 00:23:56.380]   is that you know exactly what leads to.
[00:23:56.380 --> 00:23:57.220]   Yep.
[00:23:57.220 --> 00:24:00.340]   And you have a predictive algorithm.
[00:24:00.340 --> 00:24:04.020]   It's not always the case with machine learning.
[00:24:04.020 --> 00:24:06.940]   So usually the high impact projects
[00:24:06.940 --> 00:24:09.820]   are the ones that are close to money.
[00:24:09.820 --> 00:24:14.820]   And it also means that the cost of hiring all is good.
[00:24:14.820 --> 00:24:19.180]   So how do you bridge that?
[00:24:19.180 --> 00:24:20.020]   Yeah.
[00:24:20.020 --> 00:24:22.980]   So the question is, how do you bridge the fact
[00:24:22.980 --> 00:24:25.820]   that most high impact machine learning projects
[00:24:25.820 --> 00:24:28.420]   are also gonna be very expensive, essentially?
[00:24:28.420 --> 00:24:32.220]   Expensive if you make the wrong prediction.
[00:24:32.220 --> 00:24:33.060]   Yeah.
[00:24:33.060 --> 00:24:34.540]   I mean, the way, like just in general,
[00:24:34.540 --> 00:24:36.220]   the way I think about selecting project is,
[00:24:36.220 --> 00:24:38.540]   you know, you wanna think about like,
[00:24:38.540 --> 00:24:40.260]   how impactful is this gonna be?
[00:24:40.260 --> 00:24:42.820]   Meaning like, if we're able to do this successfully,
[00:24:42.820 --> 00:24:45.260]   then what's the value that we're creating?
[00:24:45.260 --> 00:24:46.740]   And then what's the cost?
[00:24:46.740 --> 00:24:48.660]   And then you wanna like pick projects that are,
[00:24:48.660 --> 00:24:52.900]   you know, low expected cost and high expected impact.
[00:24:52.900 --> 00:24:55.380]   And so, you know, so I would try to balance
[00:24:55.380 --> 00:24:56.220]   those two things.
[00:24:56.220 --> 00:24:58.180]   Like if the project is extremely risky,
[00:24:58.180 --> 00:24:59.980]   then maybe you just don't do it.
[00:24:59.980 --> 00:25:08.220]   Yeah.
[00:25:08.220 --> 00:25:13.220]   - Do you think explainability is also considered cost?
[00:25:13.220 --> 00:25:17.860]   - Yeah, so the question was, is explainability a cost?
[00:25:17.860 --> 00:25:20.020]   Yeah, so I think explainability is one thing
[00:25:20.020 --> 00:25:24.900]   that makes projects expensive because it's very difficult.
[00:25:24.900 --> 00:25:27.780]   Yeah, so I would consider this like something
[00:25:27.780 --> 00:25:29.700]   that ramps up the difficulty of the problem.
[00:25:29.700 --> 00:25:31.380]   And so, you know, by doing that,
[00:25:31.380 --> 00:25:33.540]   it makes the project more expensive.
[00:25:33.540 --> 00:25:36.900]   And so like, let's actually use that as a segue
[00:25:36.900 --> 00:25:37.940]   to talk about costs.
[00:25:37.940 --> 00:25:41.780]   The way I think about like kind of how to figure out
[00:25:41.780 --> 00:25:45.140]   how expensive a machine learning project is gonna be is,
[00:25:45.140 --> 00:25:49.140]   you know, some cost drivers on the left from, you know,
[00:25:49.140 --> 00:25:52.820]   bottom to top in order of how important they are
[00:25:52.820 --> 00:25:53.860]   in terms of driving the costs.
[00:25:53.860 --> 00:25:55.680]   And I think that really the number one thing
[00:25:55.680 --> 00:25:56.980]   is data availability.
[00:25:56.980 --> 00:25:59.820]   And so this means both like how easy is it to collect data?
[00:25:59.820 --> 00:26:04.300]   You know, how available is it?
[00:26:04.300 --> 00:26:05.940]   How expensive is it to collect?
[00:26:05.940 --> 00:26:08.420]   But then also how expensive is it to label?
[00:26:08.420 --> 00:26:11.000]   And this is super, super critical for a lot of applications
[00:26:11.000 --> 00:26:14.260]   because, you know, for example, if you're working in medicine
[00:26:14.260 --> 00:26:19.260]   and you don't want random people on Amazon Turk
[00:26:19.260 --> 00:26:21.140]   making your medical decisions for you,
[00:26:21.140 --> 00:26:24.860]   then that means that you need to have doctors
[00:26:24.860 --> 00:26:26.740]   that are actually labeling your data for you.
[00:26:26.740 --> 00:26:28.540]   And so the labelers can actually turn out
[00:26:28.540 --> 00:26:30.300]   to be one of the most expensive parts
[00:26:30.300 --> 00:26:31.660]   about creating the dataset.
[00:26:34.060 --> 00:26:36.260]   In addition to data availability,
[00:26:36.260 --> 00:26:38.180]   the accuracy requirement of your system
[00:26:38.180 --> 00:26:40.140]   is also a very big cost driver.
[00:26:40.140 --> 00:26:42.820]   And so there's a slide in kind of the main presentation
[00:26:42.820 --> 00:26:45.740]   that showed like kind of an exponentially growing curve.
[00:26:45.740 --> 00:26:48.220]   And the idea is that like generally speaking,
[00:26:48.220 --> 00:26:52.180]   from what I've seen, project costs tend to grow
[00:26:52.180 --> 00:26:56.940]   faster than linearly in the sort of the number of nines
[00:26:56.940 --> 00:26:59.460]   that you need in your final accuracy, right?
[00:26:59.460 --> 00:27:01.940]   So like if you need your thing to be 99% accurate
[00:27:02.780 --> 00:27:06.040]   and that changes and now you need it to be 99.9% accurate,
[00:27:06.040 --> 00:27:09.000]   then like sort of like very, very rough rule of thumb
[00:27:09.000 --> 00:27:12.420]   is like maybe that project would be 10 times as expensive.
[00:27:12.420 --> 00:27:16.620]   So, you know, if for your application,
[00:27:16.620 --> 00:27:17.980]   you need things to be super accurate,
[00:27:17.980 --> 00:27:20.740]   then the project is gonna be very expensive.
[00:27:20.740 --> 00:27:23.620]   And in particular, the cost of wrong predictions
[00:27:23.620 --> 00:27:25.300]   is like a major driver of that, right?
[00:27:25.300 --> 00:27:28.960]   So self-driving cars have very expensive wrong predictions.
[00:27:28.960 --> 00:27:31.280]   And that's one of the reasons why
[00:27:31.280 --> 00:27:33.280]   it's been so expensive to develop them.
[00:27:33.280 --> 00:27:36.840]   And then the last thing is problem difficulty.
[00:27:36.840 --> 00:27:39.560]   And I think this, you know, generally seems to be
[00:27:39.560 --> 00:27:40.860]   less important than the other two things,
[00:27:40.860 --> 00:27:43.160]   but is also can be important.
[00:27:43.160 --> 00:27:46.160]   And I wanna talk a little bit more about that
[00:27:46.160 --> 00:27:48.140]   in a few minutes.
[00:27:48.140 --> 00:27:52.800]   Questions on assessing costs of projects?
[00:27:52.800 --> 00:28:00.320]   Yeah.
[00:28:00.320 --> 00:28:01.800]   - I have a problem with the one before.
[00:28:01.800 --> 00:28:04.720]   So one before is kind of how do you decide
[00:28:04.720 --> 00:28:06.360]   what projects you want to do?
[00:28:06.360 --> 00:28:09.160]   Maybe they're the big thing,
[00:28:09.160 --> 00:28:10.880]   might decide what projects you can do
[00:28:10.880 --> 00:28:12.800]   with what you have at hand.
[00:28:12.800 --> 00:28:13.640]   - Totally.
[00:28:13.640 --> 00:28:16.200]   - How often, like which direction do you find yourself
[00:28:16.200 --> 00:28:17.200]   starting projects?
[00:28:17.200 --> 00:28:21.380]   - I almost always, for me,
[00:28:21.380 --> 00:28:24.240]   find myself starting from sort of impact
[00:28:24.240 --> 00:28:27.540]   and then trying to assess whether it's feasible.
[00:28:27.540 --> 00:28:29.080]   But that's, I think like driven by
[00:28:29.080 --> 00:28:30.440]   the context that I work in.
[00:28:30.440 --> 00:28:34.760]   I think from like from companies that I talk to, you know,
[00:28:34.760 --> 00:28:38.880]   and I think this would also be a really interesting question
[00:28:38.880 --> 00:28:40.880]   to ask to Neil when he speaks later.
[00:28:40.880 --> 00:28:43.240]   But, you know, I think like oftentimes
[00:28:43.240 --> 00:28:45.800]   the impact question is like sort of
[00:28:45.800 --> 00:28:47.280]   part of your strategic planning.
[00:28:47.280 --> 00:28:49.960]   And then you start to build a data set, you know,
[00:28:49.960 --> 00:28:51.760]   based on like data that you get from your users
[00:28:51.760 --> 00:28:54.040]   or that you're building to, you know,
[00:28:54.040 --> 00:28:56.560]   to be an input to a system that's part of your product.
[00:28:56.560 --> 00:28:59.600]   And then from there, like the, you know,
[00:28:59.600 --> 00:29:01.200]   the smaller projects that you decide to do
[00:29:01.200 --> 00:29:03.560]   within that context are largely driven
[00:29:03.560 --> 00:29:06.100]   by what data you already have available.
[00:29:06.100 --> 00:29:07.640]   Because if you're building like a massive data set
[00:29:07.640 --> 00:29:08.840]   from scratch, then that's just, you know,
[00:29:08.840 --> 00:29:11.040]   it takes a long time and it's super expensive.
[00:29:11.040 --> 00:29:14.640]   Yeah.
[00:29:14.640 --> 00:29:16.640]   - Like what's like usually the most surprising
[00:29:16.640 --> 00:29:17.800]   that comes up as you're doing this,
[00:29:17.800 --> 00:29:19.680]   like you didn't think about?
[00:29:19.680 --> 00:29:20.520]   - Yeah.
[00:29:26.440 --> 00:29:28.560]   - Or like easy to get wrong.
[00:29:28.560 --> 00:29:31.480]   - Yeah, I think figuring out how much data
[00:29:31.480 --> 00:29:32.400]   you're gonna need.
[00:29:32.400 --> 00:29:35.400]   Sorry.
[00:29:35.400 --> 00:29:38.560]   Yeah, the question is like what's the most surprising thing
[00:29:38.560 --> 00:29:40.280]   that people get wrong?
[00:29:40.280 --> 00:29:42.680]   I think one thing that comes to mind is just like,
[00:29:42.680 --> 00:29:44.680]   how do you figure out how much data you're gonna need
[00:29:44.680 --> 00:29:46.000]   for this problem, right?
[00:29:46.000 --> 00:29:49.560]   And so oftentimes you see like, well, all right,
[00:29:49.560 --> 00:29:51.960]   we're gonna budget for 100,000 labeled images
[00:29:51.960 --> 00:29:53.980]   for this problem because, you know,
[00:29:53.980 --> 00:29:56.320]   we read some paper and they used 100,000 images.
[00:29:56.320 --> 00:29:58.760]   But then what you realize is that like that paper
[00:29:58.760 --> 00:30:01.720]   only works in some really, really narrow circumstance.
[00:30:01.720 --> 00:30:04.520]   And so to solve the broader problem, you know,
[00:30:04.520 --> 00:30:06.960]   maybe you need millions or tens of millions
[00:30:06.960 --> 00:30:09.360]   of labeled images or more.
[00:30:09.360 --> 00:30:11.320]   And so I think if you don't take that into account,
[00:30:11.320 --> 00:30:14.020]   then that's an easy way to get it wrong by quite a bit.
[00:30:14.020 --> 00:30:16.800]   Yeah.
[00:30:16.800 --> 00:30:19.220]   (indistinct)
[00:30:25.400 --> 00:30:27.960]   - Yeah, so the question is, are the sizes of the parts
[00:30:27.960 --> 00:30:29.380]   of the pyramid representative?
[00:30:29.380 --> 00:30:31.320]   No, it's more just illustrative.
[00:30:31.320 --> 00:30:35.040]   Like I think data availability is like usually the,
[00:30:35.040 --> 00:30:35.880]   you know, the biggest driver.
[00:30:35.880 --> 00:30:37.400]   If it's really, really hard to get data,
[00:30:37.400 --> 00:30:38.960]   then the project is gonna be extremely expensive
[00:30:38.960 --> 00:30:39.800]   no matter what.
[00:30:39.800 --> 00:30:43.900]   But yeah, it's, I mean, it's very problem dependent, right?
[00:30:43.900 --> 00:30:47.640]   Like for some problems, you know, if some problems are like
[00:30:47.640 --> 00:30:49.400]   some projects can still be super expensive,
[00:30:49.400 --> 00:30:51.880]   even if data is cheap, because they're just research
[00:30:51.880 --> 00:30:53.700]   problems and you need to hire, you know,
[00:30:53.700 --> 00:30:55.640]   star researchers who, you know,
[00:30:55.640 --> 00:30:57.600]   who are expensive and difficult to hire.
[00:30:57.600 --> 00:30:59.960]   So it's sort of a rule of thumb.
[00:30:59.960 --> 00:31:07.720]   Cool.
[00:31:07.720 --> 00:31:12.980]   So the next thing that we talked about was, you know,
[00:31:12.980 --> 00:31:17.200]   once you have picked what problem to work on,
[00:31:17.200 --> 00:31:18.640]   you need to choose a metric.
[00:31:18.640 --> 00:31:19.800]   And so, you know, in the real world,
[00:31:19.800 --> 00:31:21.120]   you care about a lot of different things.
[00:31:21.120 --> 00:31:23.000]   You care about your accuracy.
[00:31:23.000 --> 00:31:25.160]   You care about, you know, how fast,
[00:31:25.160 --> 00:31:27.420]   like whether things run in real time and like maybe many,
[00:31:27.420 --> 00:31:28.800]   many other things,
[00:31:28.800 --> 00:31:31.340]   but machine learning systems tend to work best when you're
[00:31:31.340 --> 00:31:34.680]   like trying to drive down one number at any given time.
[00:31:34.680 --> 00:31:36.760]   And the reason that this is important is because, you know,
[00:31:36.760 --> 00:31:39.040]   we saw an example of three different ways of combining
[00:31:39.040 --> 00:31:40.320]   precision and recall.
[00:31:40.320 --> 00:31:42.540]   And those three different ways of combining them could give
[00:31:42.540 --> 00:31:45.840]   you different scores for three different choices of model.
[00:31:45.840 --> 00:31:47.960]   And so if you want to pick which model performs best for
[00:31:47.960 --> 00:31:48.780]   your problem,
[00:31:48.780 --> 00:31:51.480]   you need some kind of canonical way at any given time of
[00:31:51.480 --> 00:31:53.960]   combining the metrics that you care about.
[00:31:53.960 --> 00:31:55.520]   And, you know,
[00:31:55.520 --> 00:31:58.360]   that way of combining them will evolve because, you know,
[00:31:58.360 --> 00:32:00.800]   oftentimes you don't really get it right the first time,
[00:32:00.800 --> 00:32:03.960]   but it's, I think it's important at any given time to have
[00:32:03.960 --> 00:32:07.240]   like kind of alignment on your team about what's the,
[00:32:07.240 --> 00:32:09.600]   like, what's the number that we're trying to make go lower.
[00:32:09.600 --> 00:32:13.020]   Questions on, on metrics.
[00:32:13.020 --> 00:32:16.960]   - So do you see like how's the,
[00:32:16.960 --> 00:32:18.120]   I guess scoring is,
[00:32:18.120 --> 00:32:20.160]   I guess scoring is kind of a combination of precision
[00:32:20.160 --> 00:32:21.480]   and recall.
[00:32:21.480 --> 00:32:24.880]   I've seen a lot of cases, F score and then beta score.
[00:32:24.880 --> 00:32:26.120]   - Yeah. So the question is about F score,
[00:32:26.120 --> 00:32:28.140]   which is a way of combining precision and recall.
[00:32:28.140 --> 00:32:30.920]   There are a lot of ways of combining precision and recall
[00:32:30.920 --> 00:32:32.120]   depends on your problem.
[00:32:32.120 --> 00:32:35.460]   (indistinct)
[00:32:35.460 --> 00:32:40.440]   Yeah. Mean average precision is another common way of
[00:32:40.440 --> 00:32:42.280]   combining precision and recall.
[00:32:42.280 --> 00:32:44.360]   Again, like the point of this is not really to make an
[00:32:44.360 --> 00:32:48.320]   argument for any one way of combining them over another.
[00:32:48.320 --> 00:32:50.160]   It's like, the point of this is really,
[00:32:50.160 --> 00:32:51.560]   there are many ways to combine them.
[00:32:51.560 --> 00:32:53.480]   Some of them are better in different circumstances than
[00:32:53.480 --> 00:32:56.780]   other others, but it's important to kind of like,
[00:32:56.780 --> 00:32:59.800]   when you start training models to have an idea of what
[00:32:59.800 --> 00:33:01.320]   metric you're going to use to evaluate them.
[00:33:01.320 --> 00:33:04.120]   So you can decide which hyper parameter choices and which
[00:33:04.120 --> 00:33:07.280]   model architectures are performing best in some canonical
[00:33:07.280 --> 00:33:08.120]   way.
[00:33:08.120 --> 00:33:10.640]   Yeah.
[00:33:10.640 --> 00:33:13.060]   (indistinct)
[00:33:13.060 --> 00:33:15.740]   - Which metrics really proves your model is good,
[00:33:15.740 --> 00:33:20.060]   but in real business scenario, like I saw in the test,
[00:33:20.060 --> 00:33:22.220]   how they really validate from the systems.
[00:33:22.220 --> 00:33:26.500]   So like, how do you think the real business scenario
[00:33:26.500 --> 00:33:27.340]   plays out?
[00:33:27.340 --> 00:33:30.580]   Like, you know, apart from the model metrics,
[00:33:30.580 --> 00:33:32.740]   have you seen some kind of calibrated values
[00:33:32.740 --> 00:33:35.580]   using real business systems and these models?
[00:33:35.580 --> 00:33:36.420]   - Yeah. Yeah.
[00:33:36.420 --> 00:33:39.860]   So the question is, you know, in a real business setting
[00:33:39.860 --> 00:33:41.260]   where you also have like,
[00:33:41.260 --> 00:33:43.340]   where you're also deploying this model,
[00:33:43.340 --> 00:33:45.420]   how does this play out?
[00:33:45.420 --> 00:33:46.940]   A couple of thoughts there.
[00:33:46.940 --> 00:33:49.460]   One is that like one thing that a lot of people that I talk
[00:33:49.460 --> 00:33:52.500]   to do is they have, they have like,
[00:33:52.500 --> 00:33:53.380]   they have their metric.
[00:33:53.380 --> 00:33:55.140]   They're like one canonical metric that they're trying to
[00:33:55.140 --> 00:33:55.980]   drive down,
[00:33:55.980 --> 00:33:58.060]   but then they also have a lot of other things that they care
[00:33:58.060 --> 00:33:58.900]   about, right?
[00:33:58.900 --> 00:34:00.780]   Like they care about whether their Twitter bot is like
[00:34:00.780 --> 00:34:03.220]   going to say tweet racist stuff, right?
[00:34:03.220 --> 00:34:04.740]   So that's not the number that they're driving down,
[00:34:04.740 --> 00:34:07.520]   but if it did tweet racist stuff, that'd be really bad.
[00:34:07.520 --> 00:34:10.140]   And so what you might do is you might actually create a
[00:34:10.140 --> 00:34:12.980]   separate test set or a separate validation set that captures
[00:34:12.980 --> 00:34:15.400]   like this particular property of your model that, you know,
[00:34:15.400 --> 00:34:16.460]   you need it to have,
[00:34:16.460 --> 00:34:19.380]   and then just kind of threshold whatever your metric is on
[00:34:19.380 --> 00:34:22.140]   that. So you might say, you know,
[00:34:22.140 --> 00:34:27.760]   I know that I like when my model reads these types of texts,
[00:34:27.760 --> 00:34:31.380]   I have 0% tolerance for it saying the wrong things on these
[00:34:31.380 --> 00:34:32.300]   examples, because these are,
[00:34:32.300 --> 00:34:34.520]   these are just critical, critical examples.
[00:34:34.520 --> 00:34:36.060]   So that's kind of one thing that you can do,
[00:34:36.060 --> 00:34:39.460]   like still in the training and validation environment.
[00:34:39.460 --> 00:34:41.740]   One thing from the Tesla talk that I think is really cool.
[00:34:41.740 --> 00:34:44.460]   And I think more companies should be doing is,
[00:34:44.460 --> 00:34:48.340]   is like deploying their models kind of side by side with the
[00:34:48.340 --> 00:34:50.460]   production model to,
[00:34:50.460 --> 00:34:52.780]   and then keeping track of the,
[00:34:52.780 --> 00:34:56.900]   the predicted performance in like in a sandboxed way.
[00:34:56.900 --> 00:34:59.500]   So you have like both models running in production,
[00:34:59.500 --> 00:35:02.660]   but the one that you already know works pretty well is like
[00:35:02.660 --> 00:35:05.380]   actually making the decisions, but then the new one,
[00:35:05.380 --> 00:35:06.420]   like sort of the,
[00:35:06.420 --> 00:35:08.840]   the prototype model is there alongside it.
[00:35:08.840 --> 00:35:10.580]   And you're comparing the predictions and then you can go
[00:35:10.580 --> 00:35:13.700]   back and analyze those and say, all right, for, you know,
[00:35:13.700 --> 00:35:17.420]   for these hundred or thousands of miles of driving,
[00:35:17.420 --> 00:35:20.140]   like how many mistakes did this model make?
[00:35:20.140 --> 00:35:22.020]   And then you can be more confident that in a production
[00:35:22.020 --> 00:35:22.860]   setting,
[00:35:22.860 --> 00:35:23.980]   the model is going to perform the way that you expect it to
[00:35:23.980 --> 00:35:24.820]   perform.
[00:35:24.820 --> 00:35:33.740]   All right.
[00:35:33.740 --> 00:35:35.800]   So in addition to choosing a metric,
[00:35:35.800 --> 00:35:38.080]   there's this other concept of a baseline.
[00:35:38.080 --> 00:35:39.780]   And what a baseline is,
[00:35:39.780 --> 00:35:43.360]   is it some kind of measure of what performance you can
[00:35:43.360 --> 00:35:45.720]   expect your model to be able to achieve.
[00:35:45.720 --> 00:35:46.620]   So it's a,
[00:35:46.620 --> 00:35:50.040]   it's really like a lower bound on the expected performance
[00:35:50.040 --> 00:35:51.140]   of your model.
[00:35:51.140 --> 00:35:52.940]   And we talked a little bit about why this is important.
[00:35:52.940 --> 00:35:55.600]   So, you know, two different learning curves or sorry,
[00:35:55.600 --> 00:35:57.200]   two of the same learning curves, right?
[00:35:57.200 --> 00:36:00.100]   So our validation score and our training score,
[00:36:00.100 --> 00:36:01.200]   but different baselines, right?
[00:36:01.200 --> 00:36:04.780]   So different values for what human performance is.
[00:36:04.780 --> 00:36:05.620]   So on the left,
[00:36:05.620 --> 00:36:09.240]   human performance is like 36 or 37%.
[00:36:09.240 --> 00:36:10.260]   In that chart, you know,
[00:36:10.260 --> 00:36:13.260]   our training areas is kind of exactly hitting human
[00:36:13.260 --> 00:36:14.100]   performance.
[00:36:14.100 --> 00:36:16.620]   So, but our validation score is much higher.
[00:36:16.620 --> 00:36:19.280]   And so in that type of setting, we would say, well,
[00:36:19.280 --> 00:36:22.400]   we're we're actually overfitting to our training set,
[00:36:22.400 --> 00:36:25.520]   but in the scenario on the right where human performance is
[00:36:25.520 --> 00:36:27.940]   close to 20%,
[00:36:27.940 --> 00:36:29.460]   your, our training error is actually very,
[00:36:29.460 --> 00:36:32.540]   very far off from what we might expect human performance to
[00:36:32.540 --> 00:36:33.380]   be.
[00:36:33.380 --> 00:36:35.660]   So in this situation, we're overfitting.
[00:36:35.660 --> 00:36:37.820]   And the interventions that you would have for your model in
[00:36:37.820 --> 00:36:40.360]   those two scenarios are very different.
[00:36:40.360 --> 00:36:42.040]   So the, you know, the same model,
[00:36:42.040 --> 00:36:44.940]   but a different baseline implies different next steps.
[00:36:44.940 --> 00:36:47.440]   And so that's why it's important to pick a good baseline.
[00:36:47.440 --> 00:36:50.260]   And the, the,
[00:36:50.260 --> 00:36:51.720]   the better the performance of your baseline,
[00:36:51.720 --> 00:36:54.160]   the more useful it is for doing this type of thing.
[00:36:54.160 --> 00:36:55.880]   Yeah.
[00:36:55.880 --> 00:36:58.300]   (indistinct)
[00:37:02.700 --> 00:37:03.900]   Yes.
[00:37:03.900 --> 00:37:04.740]   Yeah, exactly.
[00:37:04.740 --> 00:37:05.560]   So the question is,
[00:37:05.560 --> 00:37:07.020]   wouldn't you want your model to do better than human
[00:37:07.020 --> 00:37:07.960]   performance?
[00:37:07.960 --> 00:37:09.700]   In many cases, yes.
[00:37:09.700 --> 00:37:12.300]   Cause that's why this is a lower bound on the expected
[00:37:12.300 --> 00:37:13.140]   performance.
[00:37:13.140 --> 00:37:15.260]   This is more a tool when you're still in the regime of like
[00:37:15.260 --> 00:37:16.980]   trying to hit human performance.
[00:37:16.980 --> 00:37:18.380]   Once you get past human performance,
[00:37:18.380 --> 00:37:21.100]   then your baseline might be your previous best model or
[00:37:21.100 --> 00:37:22.100]   something like that.
[00:37:22.100 --> 00:37:26.080]   (indistinct)
[00:37:26.080 --> 00:37:30.680]   Yeah.
[00:37:30.680 --> 00:37:33.100]   (indistinct)
[00:37:33.100 --> 00:37:37.380]   So, sorry, I didn't understand the question.
[00:37:37.380 --> 00:37:38.780]   How do you get more data?
[00:37:38.780 --> 00:37:41.200]   (indistinct)
[00:37:41.200 --> 00:37:48.340]   I see.
[00:37:48.340 --> 00:37:49.380]   So how do you do better than,
[00:37:49.380 --> 00:37:50.860]   so if your labels are coming from humans,
[00:37:50.860 --> 00:37:52.820]   then how do you beat your labels?
[00:37:52.820 --> 00:37:53.660]   It's hard.
[00:37:53.660 --> 00:37:56.180]   One thing that can work is, you know,
[00:37:56.180 --> 00:37:58.500]   oftentimes when people say they're doing better than humans,
[00:37:58.500 --> 00:38:00.020]   they, what they really mean is they're doing better than a
[00:38:00.020 --> 00:38:00.860]   single human.
[00:38:00.860 --> 00:38:06.340]   So you see this a lot in like in these like medical papers
[00:38:06.340 --> 00:38:07.580]   is, you know, the,
[00:38:07.580 --> 00:38:10.140]   the ground truth score that they get is an ensemble of
[00:38:10.140 --> 00:38:10.960]   humans.
[00:38:10.960 --> 00:38:14.900]   So they have 10 experts say, you know, does this is,
[00:38:14.900 --> 00:38:16.140]   is the cancer in this,
[00:38:16.140 --> 00:38:18.820]   in this image pulling it or something like that.
[00:38:18.820 --> 00:38:21.500]   And then they take the average of those 10 experts.
[00:38:21.500 --> 00:38:23.680]   And then, but then when they say they beat humans,
[00:38:23.680 --> 00:38:26.860]   that means that they beat a single average expert.
[00:38:27.820 --> 00:38:30.240]   (indistinct)
[00:38:30.240 --> 00:38:37.580]   There are a lot of different places to get baselines.
[00:38:37.580 --> 00:38:39.260]   These can kind of come from,
[00:38:39.260 --> 00:38:41.420]   from, you know,
[00:38:41.420 --> 00:38:43.660]   from outside of the machine learning team.
[00:38:43.660 --> 00:38:44.780]   So like, you know,
[00:38:44.780 --> 00:38:45.920]   engineering team might say like,
[00:38:45.920 --> 00:38:49.160]   we need this to run in this specific,
[00:38:49.160 --> 00:38:51.380]   like kind of latency to run in real time,
[00:38:51.380 --> 00:38:53.660]   or you can look at papers to get that.
[00:38:53.660 --> 00:38:55.660]   But oftentimes like the best thing to do is actually build
[00:38:55.660 --> 00:38:56.520]   your own baseline.
[00:38:56.520 --> 00:38:59.500]   And so that can be human performance.
[00:38:59.500 --> 00:39:02.380]   It can also be just be like a simple linear regression model
[00:39:02.380 --> 00:39:04.220]   or it can also be a scripted baseline,
[00:39:04.220 --> 00:39:05.920]   something like an open CV script.
[00:39:05.920 --> 00:39:08.260]   And I'll just tell you a little story about that.
[00:39:08.260 --> 00:39:10.820]   I can't remember if I told this in the lecture or not,
[00:39:10.820 --> 00:39:12.420]   but I did.
[00:39:12.420 --> 00:39:13.820]   Okay. I'll skip it then.
[00:39:13.820 --> 00:39:16.800]   But, but the story is basically like the first month or so
[00:39:16.800 --> 00:39:19.700]   of the Dota project, the best engineer on the team,
[00:39:19.700 --> 00:39:21.060]   basically spent the entire time,
[00:39:21.060 --> 00:39:23.320]   like not doing any machine learning training at all.
[00:39:23.320 --> 00:39:24.500]   Just like trying to beat,
[00:39:24.500 --> 00:39:27.740]   like trying to build a really, really good scripted Dota bot
[00:39:27.740 --> 00:39:28.820]   that can, you know,
[00:39:28.820 --> 00:39:32.500]   because the built-in bots in the game were pretty bad.
[00:39:32.500 --> 00:39:34.940]   And so he ended up over the course of a month building,
[00:39:34.940 --> 00:39:36.700]   you know, the best Dota bot in history
[00:39:36.700 --> 00:39:38.660]   at that point actually.
[00:39:38.660 --> 00:39:39.580]   But you know,
[00:39:39.580 --> 00:39:40.700]   the machine learning bot beat it
[00:39:40.700 --> 00:39:41.860]   within another month of that.
[00:39:41.860 --> 00:39:43.260]   So, but it just,
[00:39:43.260 --> 00:39:45.100]   I think illustrates the importance of,
[00:39:45.100 --> 00:39:46.940]   of having a good baseline that,
[00:39:46.940 --> 00:39:49.420]   that he invested that time in building that bot.
[00:39:50.080 --> 00:39:52.240]   (silence)
[00:39:52.240 --> 00:39:55.540]   Okay. Yeah.
[00:39:55.540 --> 00:39:56.360]   So, so to summarize, you know,
[00:39:56.360 --> 00:39:59.180]   when you're planning and choosing a project, you know,
[00:39:59.180 --> 00:40:00.540]   there's a few different steps that you follow.
[00:40:00.540 --> 00:40:03.620]   You first figure out what the goals of that project are.
[00:40:03.620 --> 00:40:05.420]   You pick a project.
[00:40:05.420 --> 00:40:07.860]   Then you choose what metric you're going to optimize,
[00:40:07.860 --> 00:40:09.540]   at least initially on the project.
[00:40:09.540 --> 00:40:10.660]   And then you, you know,
[00:40:10.660 --> 00:40:13.300]   pick some baseline and you evaluate it to get a sense of
[00:40:13.300 --> 00:40:15.700]   what performance you can expect to try to beat.
[00:40:15.700 --> 00:40:18.460]   And then finally you have to, to set up your code base.
[00:40:18.460 --> 00:40:20.820]   And I'll talk, I'll go into a little bit more detail on
[00:40:20.820 --> 00:40:23.480]   code base setup in a few minutes.
[00:40:23.480 --> 00:40:28.900]   All right. Any other questions on this lecture?
[00:40:28.900 --> 00:40:31.260]   Yeah.
[00:40:31.260 --> 00:40:37.800]   (indistinct)
[00:40:37.800 --> 00:40:47.460]   So, so the question is how is the code base setup
[00:40:47.460 --> 00:40:49.740]   after evaluating choosing metrics?
[00:40:49.740 --> 00:40:52.180]   Usually like when I say choosing metrics,
[00:40:52.180 --> 00:40:55.220]   it's kind of like looking at your problem and saying,
[00:40:55.220 --> 00:40:56.700]   you know, okay, is this like,
[00:40:56.700 --> 00:40:58.140]   is this a place where we use, you know,
[00:40:58.140 --> 00:41:00.220]   mean average error or mean squared error?
[00:41:00.220 --> 00:41:01.700]   And so you can often just kind of do that
[00:41:01.700 --> 00:41:03.060]   by thinking about it.
[00:41:03.060 --> 00:41:06.060]   And also often like you'll have some sort of hacky scripts
[00:41:06.060 --> 00:41:08.220]   that you can use to start training things before you really
[00:41:08.220 --> 00:41:09.620]   invest in a code base that a lot of people
[00:41:09.620 --> 00:41:10.660]   can work together on.
[00:41:10.660 --> 00:41:15.260]   Yeah.
[00:41:15.260 --> 00:41:17.680]   (indistinct)
[00:41:17.680 --> 00:41:26.260]   Yeah, I think, so the question is how do you justify
[00:41:26.260 --> 00:41:28.240]   spending the time on building a bot?
[00:41:28.240 --> 00:41:30.220]   I think they just kind of felt like the bots that were
[00:41:30.220 --> 00:41:34.180]   built into Dodo were so pitiful that they, you know,
[00:41:34.180 --> 00:41:35.820]   they, they didn't feel like if they beat them,
[00:41:35.820 --> 00:41:39.360]   that would really be indicative of any sort of like,
[00:41:39.360 --> 00:41:40.700]   you know, performance.
[00:41:40.700 --> 00:41:43.200]   And so they wanted something where they know if you beat it,
[00:41:43.200 --> 00:41:45.540]   then your model is learning something intelligent.
[00:41:45.540 --> 00:41:50.020]   Yeah.
[00:41:50.020 --> 00:41:52.440]   (indistinct)
[00:41:52.440 --> 00:42:02.860]   Yeah, I would say, you know,
[00:42:02.860 --> 00:42:04.680]   like almost everything else in machine learning,
[00:42:04.680 --> 00:42:05.540]   it can be iterative.
[00:42:05.540 --> 00:42:07.320]   So maybe when you first start on your project,
[00:42:07.320 --> 00:42:09.800]   you just use a linear regression,
[00:42:09.800 --> 00:42:11.200]   but the more,
[00:42:11.200 --> 00:42:13.300]   the better their performance of your baseline,
[00:42:13.300 --> 00:42:14.760]   the more useful it is to you.
[00:42:14.760 --> 00:42:18.260]   Because if the performance, if you know,
[00:42:18.260 --> 00:42:20.460]   you get a baseline that has,
[00:42:20.460 --> 00:42:23.620]   has better performance, then that means that, you know,
[00:42:23.620 --> 00:42:25.460]   that means that there's a bigger gap between your model
[00:42:25.460 --> 00:42:26.700]   and what you can expect it to do.
[00:42:26.700 --> 00:42:27.760]   And so that tells you,
[00:42:27.760 --> 00:42:29.660]   that gives you a better sense of how well you can expect
[00:42:29.660 --> 00:42:30.560]   your models to do.
[00:42:30.560 --> 00:42:34.780]   Yeah.
[00:42:34.780 --> 00:42:37.200]   (indistinct)
[00:42:37.200 --> 00:42:39.700]   - The timeline for the class is,
[00:42:39.700 --> 00:42:40.940]   it seems like maybe there's more to do
[00:42:40.940 --> 00:42:42.600]   to build a baseline.
[00:42:42.600 --> 00:42:44.940]   And it seems like, I don't know,
[00:42:44.940 --> 00:42:46.100]   it seems like a really short time,
[00:42:46.100 --> 00:42:47.820]   and I'm wondering how that, you know,
[00:42:47.820 --> 00:42:49.940]   might contribute to the rest of the project.
[00:42:49.940 --> 00:42:50.780]   - Yeah.
[00:42:50.780 --> 00:42:51.860]   - It's been a long time, you know,
[00:42:51.860 --> 00:42:52.840]   trying to build a baseline.
[00:42:52.840 --> 00:42:53.980]   - Totally.
[00:42:53.980 --> 00:42:55.460]   Yeah, it is,
[00:42:55.460 --> 00:42:57.580]   the question is about the timeline of the projects.
[00:42:57.580 --> 00:42:59.600]   It is a very tight timeline,
[00:42:59.600 --> 00:43:01.700]   but I think it's more than enough time to kind of,
[00:43:01.700 --> 00:43:03.620]   to build a cool machine learning project.
[00:43:03.620 --> 00:43:05.640]   And yeah, I think it does,
[00:43:05.640 --> 00:43:06.900]   I think it very much should influence
[00:43:06.900 --> 00:43:08.300]   the choice of projects that you make.
[00:43:08.300 --> 00:43:11.060]   And so one thing that we'll ask you to do,
[00:43:11.060 --> 00:43:12.100]   not this week, but next week,
[00:43:12.100 --> 00:43:13.900]   is to put together a project proposal.
[00:43:13.900 --> 00:43:15.500]   And then I'll kind of give you feedback
[00:43:15.500 --> 00:43:17.260]   on whether it seems like it's, you know,
[00:43:17.260 --> 00:43:19.960]   feasible to achieve within the timeframe.
[00:43:19.960 --> 00:43:21.780]   Mm-hmm.
[00:43:21.780 --> 00:43:24.200]   (indistinct)
[00:43:24.200 --> 00:43:32.420]   Yeah.
[00:43:32.420 --> 00:43:34.840]   (indistinct)
[00:43:34.840 --> 00:43:37.260]   (indistinct)
[00:43:37.260 --> 00:43:43.980]   Yeah, so it was the question,
[00:43:43.980 --> 00:43:45.660]   sometimes people choose randomly as a baseline,
[00:43:45.660 --> 00:43:46.820]   and why would you do that
[00:43:46.820 --> 00:43:49.220]   as opposed to something like regression?
[00:43:49.220 --> 00:43:51.640]   (indistinct)
[00:43:51.640 --> 00:43:56.660]   Yeah, I think,
[00:43:56.660 --> 00:43:59.100]   so sometimes these like really naive baselines
[00:43:59.100 --> 00:44:00.400]   are the best you can get.
[00:44:00.400 --> 00:44:02.700]   And sometimes, you know,
[00:44:02.700 --> 00:44:04.100]   if you have bugs in your machine learning system,
[00:44:04.100 --> 00:44:05.460]   you won't even beat them.
[00:44:05.460 --> 00:44:07.020]   So I remember actually like one time,
[00:44:07.020 --> 00:44:08.100]   spending a really long time
[00:44:08.100 --> 00:44:09.100]   trying to figure out why my model
[00:44:09.100 --> 00:44:09.940]   wasn't performing that well.
[00:44:09.940 --> 00:44:12.140]   And then I compared it to the average
[00:44:12.140 --> 00:44:13.900]   of the outputs of the model,
[00:44:13.900 --> 00:44:15.620]   and I actually wasn't beating that.
[00:44:15.620 --> 00:44:17.420]   So I was very confident,
[00:44:17.420 --> 00:44:18.780]   but I had a bug after that.
[00:44:18.780 --> 00:44:26.540]   All right, the next thing I wanna talk about
[00:44:26.540 --> 00:44:28.620]   is how to think about what types
[00:44:28.620 --> 00:44:31.780]   of machine learning problems are easy and hard.
[00:44:32.780 --> 00:44:37.020]   And so the first thing to say here is,
[00:44:37.020 --> 00:44:40.100]   you know, there's a long and illustrious history
[00:44:40.100 --> 00:44:42.820]   of people getting this very, very wrong.
[00:44:42.820 --> 00:44:47.020]   So this is a quote from the New York Times
[00:44:47.020 --> 00:44:48.900]   about how long it was gonna take humans
[00:44:48.900 --> 00:44:50.900]   to beat the best players in Go, right?
[00:44:50.900 --> 00:44:53.160]   So this is right after Deep Blue.
[00:44:53.160 --> 00:44:55.120]   So right after AI beat humans in chess.
[00:44:55.120 --> 00:44:59.360]   And, you know, contrast that with this headline
[00:44:59.360 --> 00:45:00.860]   from less than 20 years later.
[00:45:01.860 --> 00:45:04.180]   About, you know, DeepMind actually finally beating
[00:45:04.180 --> 00:45:05.740]   the best humans in Go, right?
[00:45:05.740 --> 00:45:07.460]   And so this is like one of many, many examples
[00:45:07.460 --> 00:45:10.220]   of how difficult it is to figure out
[00:45:10.220 --> 00:45:12.020]   what machine, like what AI problems
[00:45:12.020 --> 00:45:13.260]   in general are difficult.
[00:45:13.260 --> 00:45:16.340]   And so, you know, all of this is said
[00:45:16.340 --> 00:45:19.900]   with that in mind,
[00:45:19.900 --> 00:45:21.660]   that like this is all just a guess.
[00:45:21.660 --> 00:45:25.460]   But, you know, I think that we can confidently say
[00:45:25.460 --> 00:45:27.300]   that there are some things that are still hard
[00:45:27.300 --> 00:45:30.540]   to do in production right now in machine learning.
[00:45:30.540 --> 00:45:32.740]   And so a couple of those things are anything
[00:45:32.740 --> 00:45:34.180]   that's not supervised learning.
[00:45:34.180 --> 00:45:36.980]   So unsupervised learning, reinforcement learning,
[00:45:36.980 --> 00:45:39.540]   both of these things are extremely promising
[00:45:39.540 --> 00:45:41.340]   research directions, and there are a couple
[00:45:41.340 --> 00:45:44.340]   of use cases for them in production right now,
[00:45:44.340 --> 00:45:47.180]   but generally speaking, they're showing promise
[00:45:47.180 --> 00:45:49.980]   in kind of more limited domains and places
[00:45:49.980 --> 00:45:52.780]   where you have a ton of data available.
[00:45:52.780 --> 00:45:55.500]   So I would say, you know, as a rule of thumb,
[00:45:55.500 --> 00:45:57.340]   applications of unsupervised learning
[00:45:57.340 --> 00:45:59.300]   and reinforcement learning with a couple of exceptions
[00:45:59.300 --> 00:46:01.780]   are sort of not quite ready for primetime yet.
[00:46:01.780 --> 00:46:06.700]   But what about within supervised learning?
[00:46:06.700 --> 00:46:08.500]   Actually, I kind of want to just,
[00:46:08.500 --> 00:46:09.380]   I want to crowdsource this.
[00:46:09.380 --> 00:46:12.500]   So like, can anyone think of examples of problems
[00:46:12.500 --> 00:46:14.420]   where, you know, it's a supervised learning problem,
[00:46:14.420 --> 00:46:15.980]   but we still, like machines can't,
[00:46:15.980 --> 00:46:17.500]   still can't perform very well on them.
[00:46:17.500 --> 00:46:19.540]   You know, it's like, let's say that we still can't
[00:46:19.540 --> 00:46:20.900]   do nearly as well as humans.
[00:46:20.900 --> 00:46:23.020]   Yeah.
[00:46:23.020 --> 00:46:25.660]   Document summarization.
[00:46:25.660 --> 00:46:26.860]   Yep, that's a great one.
[00:46:27.860 --> 00:46:28.700]   Yeah.
[00:46:28.700 --> 00:46:31.340]   Can you be more specific?
[00:46:31.340 --> 00:46:38.620]   Yeah, detection of diseases from lab results and x-rays.
[00:46:38.620 --> 00:46:41.140]   Yeah, I mean, there are some specific medical applications
[00:46:41.140 --> 00:46:43.660]   where people now are claiming that AI does better
[00:46:43.660 --> 00:46:44.500]   than doctors.
[00:46:44.500 --> 00:46:45.940]   Most of those are things like radiology,
[00:46:45.940 --> 00:46:47.300]   where they're just kind of inferring something
[00:46:47.300 --> 00:46:49.140]   from an image, but the more general problem
[00:46:49.140 --> 00:46:50.940]   of like looking at all of someone's clinical data
[00:46:50.940 --> 00:46:53.580]   and determining what disease they have
[00:46:53.580 --> 00:46:56.140]   or what action should be taken is very much uncertain.
[00:46:56.140 --> 00:46:58.180]   It's very much unsolved still.
[00:46:58.180 --> 00:47:01.500]   Yeah.
[00:47:01.500 --> 00:47:02.340]   - Grasping objects.
[00:47:02.340 --> 00:47:03.220]   - Grasping objects, yeah.
[00:47:03.220 --> 00:47:06.420]   This is a great one because I spent a lot of time
[00:47:06.420 --> 00:47:08.700]   working on this in my PhD.
[00:47:08.700 --> 00:47:10.860]   Yeah, I was actually, this is actually really surprising
[00:47:10.860 --> 00:47:13.260]   to me when I started working in robotics.
[00:47:13.260 --> 00:47:14.820]   One of the really surprising things about robotics
[00:47:14.820 --> 00:47:18.260]   is that like, you know, you can, like,
[00:47:18.260 --> 00:47:20.460]   all of the questions that a five-year-old can ask
[00:47:20.460 --> 00:47:23.020]   are still, and can solve, are still unsolved.
[00:47:24.260 --> 00:47:26.900]   It's one of the fun things about working in robotics.
[00:47:26.900 --> 00:47:31.220]   - It requires a lot of data.
[00:47:31.220 --> 00:47:33.100]   - Yeah, sure, if anything requires a lot of data,
[00:47:33.100 --> 00:47:34.940]   then it's still very difficult, yeah.
[00:47:34.940 --> 00:47:36.980]   Mm-hmm.
[00:47:36.980 --> 00:47:38.460]   - I think the data is a problem,
[00:47:38.460 --> 00:47:42.500]   so any kind of interpolation questions,
[00:47:42.500 --> 00:47:46.420]   so your data kind of covers the domain
[00:47:46.420 --> 00:47:48.540]   of the problem that you're trying to solve,
[00:47:48.540 --> 00:47:50.460]   then superlatively it works well,
[00:47:50.460 --> 00:47:53.660]   but if you have to start explaining,
[00:47:53.660 --> 00:47:54.500]   - Yeah.
[00:47:54.500 --> 00:47:56.060]   - Or if your data has,
[00:47:56.060 --> 00:48:00.020]   cannot cover all the domains that you have,
[00:48:00.020 --> 00:48:03.500]   then the problem becomes pretty hard.
[00:48:03.500 --> 00:48:04.780]   - Yeah, I think that's right.
[00:48:04.780 --> 00:48:08.980]   So the idea was anytime you need to extrapolate
[00:48:08.980 --> 00:48:11.660]   from your data, so you need to answer some question
[00:48:11.660 --> 00:48:14.420]   that's not kind of explicitly present in your data,
[00:48:14.420 --> 00:48:17.500]   generally supervised learning does not work for those things.
[00:48:17.500 --> 00:48:22.660]   I'll list some things that I came up with.
[00:48:22.660 --> 00:48:26.060]   Answering questions is still very hard.
[00:48:26.060 --> 00:48:28.140]   Summarizing text was mentioned.
[00:48:28.140 --> 00:48:31.540]   Predicting video, so you see some sequences of video frame
[00:48:31.540 --> 00:48:34.580]   and you need to decide what the next one's gonna look like.
[00:48:34.580 --> 00:48:36.300]   Building 3D models of the world.
[00:48:36.300 --> 00:48:37.820]   This one I think is pretty surprising actually,
[00:48:37.820 --> 00:48:40.380]   but actually traditional computer vision
[00:48:40.380 --> 00:48:41.580]   is still better than deep learning
[00:48:41.580 --> 00:48:45.040]   at kind of understanding 3D structure of the environment.
[00:48:45.040 --> 00:48:48.660]   Speech recognition in the real world.
[00:48:48.660 --> 00:48:50.820]   There's a lot of amazing kind of academic results
[00:48:50.820 --> 00:48:54.300]   in speech recognition, but understanding,
[00:48:54.300 --> 00:48:57.740]   like doing voice to text in crowded environments
[00:48:57.740 --> 00:48:58.860]   over the phone and things like that
[00:48:58.860 --> 00:49:00.580]   are still extremely difficult.
[00:49:00.580 --> 00:49:03.280]   Resisting adversarial examples.
[00:49:03.280 --> 00:49:05.680]   How many are familiar with adversarial examples?
[00:49:05.680 --> 00:49:08.860]   Okay, most are familiar.
[00:49:08.860 --> 00:49:11.620]   Adversarial examples, essentially the idea is
[00:49:11.620 --> 00:49:15.060]   you can take an image classifier
[00:49:15.060 --> 00:49:16.860]   that does really, really well,
[00:49:16.860 --> 00:49:18.820]   and then you can create an image
[00:49:19.800 --> 00:49:21.840]   that looks identical to us,
[00:49:21.840 --> 00:49:23.880]   but completely fools the classifier.
[00:49:23.880 --> 00:49:25.580]   And there's a very simple procedure to do that
[00:49:25.580 --> 00:49:28.800]   that involves just kind of like backpropagating the error
[00:49:28.800 --> 00:49:33.280]   from that image and adjusting the pixel values of the image
[00:49:33.280 --> 00:49:35.160]   by some extremely small value.
[00:49:35.160 --> 00:49:36.740]   And so when you look at it as a human,
[00:49:36.740 --> 00:49:38.940]   it looks exactly the same, but for some reason,
[00:49:38.940 --> 00:49:40.380]   the machine is confused by it.
[00:49:40.380 --> 00:49:45.380]   And so this is kind of like a challenging thing
[00:49:45.380 --> 00:49:48.360]   for like if you think that, you know,
[00:49:48.360 --> 00:49:50.520]   if you're worried about people kind of hacking
[00:49:50.520 --> 00:49:53.120]   deep learning systems in the real world.
[00:49:53.120 --> 00:49:56.640]   Doing math, which is funny, right?
[00:49:56.640 --> 00:49:57.600]   Computers are great at math,
[00:49:57.600 --> 00:50:00.200]   but like there are a lot of really interesting results
[00:50:00.200 --> 00:50:03.300]   of people training recurrent neural networks to add numbers
[00:50:03.300 --> 00:50:05.080]   and then seeing that they don't generalize
[00:50:05.080 --> 00:50:07.140]   even when you just add a couple more digits
[00:50:07.140 --> 00:50:07.980]   to the end of it.
[00:50:07.980 --> 00:50:11.840]   Solving word puzzles, like kind of, you know,
[00:50:11.840 --> 00:50:14.760]   the type that you might've seen in lower school
[00:50:14.760 --> 00:50:15.600]   or middle school.
[00:50:17.260 --> 00:50:19.600]   Bongard problems, I'll show you what those are.
[00:50:19.600 --> 00:50:21.620]   This is kind of like visual analogy problems,
[00:50:21.620 --> 00:50:23.060]   visual reasoning problems.
[00:50:23.060 --> 00:50:25.760]   So you have, you know, shapes on two different sizes
[00:50:25.760 --> 00:50:28.860]   or on two sides, and the goal is to kind of see
[00:50:28.860 --> 00:50:31.540]   what facet of the shapes is different
[00:50:31.540 --> 00:50:33.380]   between the examples on one side or the other.
[00:50:33.380 --> 00:50:35.160]   So the ones on the right are,
[00:50:35.160 --> 00:50:38.040]   the ones on the left are convex
[00:50:38.040 --> 00:50:40.300]   and the ones on the right are not.
[00:50:40.300 --> 00:50:42.880]   This is still not solvable by neural nets.
[00:50:46.060 --> 00:50:48.500]   Okay, so let's try to categorize these
[00:50:48.500 --> 00:50:50.220]   and understand a little bit about, you know,
[00:50:50.220 --> 00:50:52.540]   what makes these problems more difficult
[00:50:52.540 --> 00:50:54.580]   than things that we do know how to do well.
[00:50:54.580 --> 00:50:58.500]   So I think, the way I think about it
[00:50:58.500 --> 00:51:00.340]   is that there are a few different types of problems
[00:51:00.340 --> 00:51:02.020]   that tend to be really hard.
[00:51:02.020 --> 00:51:05.660]   The first is if the output itself is very complex.
[00:51:05.660 --> 00:51:07.460]   So it could be high dimensional,
[00:51:07.460 --> 00:51:11.820]   like in 3D reconstruction or in video prediction,
[00:51:11.820 --> 00:51:13.460]   or it could be ambiguous, right?
[00:51:13.460 --> 00:51:16.860]   Like if there's many different possible outputs,
[00:51:16.860 --> 00:51:19.780]   like in dialogue systems or also in video prediction,
[00:51:19.780 --> 00:51:21.880]   then that also makes things very difficult.
[00:51:21.880 --> 00:51:26.940]   I think also if reliability is required, the system,
[00:51:26.940 --> 00:51:29.300]   and reliability can mean different things.
[00:51:29.300 --> 00:51:30.560]   It can mean robustness,
[00:51:30.560 --> 00:51:32.840]   like robustness to adversarial examples,
[00:51:32.840 --> 00:51:34.880]   and it can also mean high precision.
[00:51:34.880 --> 00:51:37.820]   And so, you know, one thing that we have found
[00:51:37.820 --> 00:51:39.140]   very challenging at OpenAI
[00:51:39.140 --> 00:51:42.020]   that has been very surprising to us has been that,
[00:51:42.020 --> 00:51:44.140]   you know, to create a very accurate,
[00:51:44.140 --> 00:51:47.140]   to create a model that estimates the pose of an object.
[00:51:47.140 --> 00:51:49.280]   So like kind of the position and rotation of the object
[00:51:49.280 --> 00:51:51.400]   in the 3D world is very easy.
[00:51:51.400 --> 00:51:53.300]   But then once you try to start getting
[00:51:53.300 --> 00:51:56.300]   that pose estimation down below some threshold,
[00:51:56.300 --> 00:51:58.620]   it starts to become very, very hard.
[00:51:58.620 --> 00:52:00.800]   'Cause neural networks like tend not to do very well
[00:52:00.800 --> 00:52:02.820]   at things that require a lot of precision.
[00:52:02.820 --> 00:52:04.720]   They're much better at things like classification,
[00:52:04.720 --> 00:52:07.660]   where you're just getting a course answer from the network.
[00:52:07.660 --> 00:52:11.660]   And then anything I think where generalization is required.
[00:52:11.660 --> 00:52:13.540]   So if you're, you know,
[00:52:13.540 --> 00:52:17.020]   if the data that you're ultimately going to evaluate on
[00:52:17.020 --> 00:52:19.340]   looks different than the data that you're training on,
[00:52:19.340 --> 00:52:20.820]   you, you know, generally speaking,
[00:52:20.820 --> 00:52:23.380]   have no guarantees that your model is gonna do
[00:52:23.380 --> 00:52:25.780]   anything reasonable whatsoever, right?
[00:52:25.780 --> 00:52:27.300]   Like much less be good,
[00:52:27.300 --> 00:52:30.000]   but like it could be kind of wildly wrong.
[00:52:30.000 --> 00:52:31.420]   And also in this category,
[00:52:31.420 --> 00:52:33.660]   I'd put anything that kind of feels like reasoning
[00:52:33.660 --> 00:52:36.520]   or planning or understanding causality.
[00:52:36.520 --> 00:52:39.660]   These things are still very difficult to do.
[00:52:39.660 --> 00:52:40.780]   Yeah.
[00:52:40.780 --> 00:52:41.860]   - When you said about reliability,
[00:52:41.860 --> 00:52:42.740]   it made me think of a question.
[00:52:42.740 --> 00:52:44.860]   So I don't know what the state of the art is,
[00:52:44.860 --> 00:52:47.220]   but how are neural networks at estimating
[00:52:47.220 --> 00:52:49.100]   their own confidence in the result?
[00:52:49.100 --> 00:52:50.060]   Do they do that well?
[00:52:50.060 --> 00:52:52.140]   - Yeah, so there's a lot of research going to this,
[00:52:52.140 --> 00:52:53.500]   into understanding how neural networks
[00:52:53.500 --> 00:52:55.340]   understand their own confidence.
[00:52:55.340 --> 00:52:58.020]   Generally speaking, I'm not,
[00:52:58.020 --> 00:53:01.220]   I would say that neural networks are extremely bad
[00:53:01.220 --> 00:53:02.500]   at understanding their own confidence.
[00:53:02.500 --> 00:53:05.860]   And so there's kind of like an interesting paper
[00:53:05.860 --> 00:53:10.140]   that illustrates this, which it takes MNIST,
[00:53:10.140 --> 00:53:13.180]   which is kind of like the classic computer vision dataset,
[00:53:13.180 --> 00:53:14.120]   a bunch of digits.
[00:53:14.120 --> 00:53:18.140]   And then it takes another dataset called Omniglot.
[00:53:18.140 --> 00:53:19.700]   And Omniglot is handwritten digits
[00:53:19.700 --> 00:53:21.540]   from like foreign languages.
[00:53:21.540 --> 00:53:23.420]   So they're like kind of different.
[00:53:23.420 --> 00:53:26.060]   They all look kind of look like MNIST images,
[00:53:26.060 --> 00:53:28.140]   but the digits themselves are different.
[00:53:28.140 --> 00:53:30.060]   They're not zero through nine.
[00:53:30.060 --> 00:53:33.020]   And so what they did in this paper is they showed that
[00:53:33.020 --> 00:53:35.660]   if you train a model on MNIST
[00:53:35.660 --> 00:53:37.220]   that does really well on MNIST,
[00:53:37.220 --> 00:53:39.820]   and then you feed it some data from Omniglot,
[00:53:39.820 --> 00:53:41.700]   you can find examples where the model
[00:53:41.700 --> 00:53:44.060]   makes extremely confident wrong predictions.
[00:53:44.060 --> 00:53:45.620]   So it sees some kind of some digit
[00:53:45.620 --> 00:53:48.500]   that doesn't look anything like us to a zero through nine,
[00:53:48.500 --> 00:53:51.980]   but the model will say like, you know, 95% accuracy that,
[00:53:51.980 --> 00:53:55.460]   95% confidence that this is a two or something like that.
[00:53:55.460 --> 00:53:57.540]   Yeah.
[00:53:57.540 --> 00:54:00.460]   (student mumbling)
[00:54:00.460 --> 00:54:03.380]   (student mumbling)
[00:54:03.380 --> 00:54:13.500]   I think in that particular paper, if I remember correctly,
[00:54:13.500 --> 00:54:16.580]   they did not have like a strange class.
[00:54:16.580 --> 00:54:18.300]   They just did zero through nine.
[00:54:18.300 --> 00:54:19.740]   And then, but then confidence,
[00:54:19.740 --> 00:54:21.880]   you can still get confidence by looking at the weights
[00:54:21.880 --> 00:54:22.720]   of the softmax.
[00:54:22.720 --> 00:54:24.460]   So like what you would expect to happen is
[00:54:24.460 --> 00:54:27.260]   the model would produce equal probability on all of them.
[00:54:27.260 --> 00:54:28.280]   And I think follow up papers,
[00:54:28.280 --> 00:54:30.540]   they've explored the idea that you're talking about.
[00:54:30.540 --> 00:54:36.740]   Okay, questions, thoughts on this?
[00:54:36.740 --> 00:54:40.620]   Other counter examples to this?
[00:54:40.620 --> 00:54:42.800]   Things that are hard that this doesn't capture?
[00:54:42.800 --> 00:54:51.320]   Okay, yeah, I just wanted to give you
[00:54:51.320 --> 00:54:53.360]   a little bit of a flavor of, you know,
[00:54:53.360 --> 00:54:55.280]   to build a little bit of intuition about, you know,
[00:54:55.280 --> 00:54:56.960]   if you're thinking about some problem,
[00:54:56.960 --> 00:54:58.360]   how to get a sense of, you know,
[00:54:58.360 --> 00:54:59.760]   beyond just going and reading papers,
[00:54:59.760 --> 00:55:01.040]   whether this is something that's,
[00:55:01.040 --> 00:55:03.500]   should be feasible for machine learning to do or not.
[00:55:03.500 --> 00:55:09.240]   All right, and the last thing that I wanna do today
[00:55:09.240 --> 00:55:12.600]   is just kind of start to walk you through
[00:55:12.600 --> 00:55:15.260]   what a mature machine learning code base looks like.
[00:55:15.260 --> 00:55:19.000]   And then, and then I'll ask you to kind of
[00:55:19.000 --> 00:55:21.360]   like spend more time looking at it on your own.
[00:55:21.360 --> 00:55:24.160]   But so first, just to give you a sense
[00:55:24.160 --> 00:55:25.680]   of what this code base is doing,
[00:55:25.680 --> 00:55:26.960]   this was kind of the class project
[00:55:26.960 --> 00:55:29.200]   for one of the boot camps that we did.
[00:55:29.200 --> 00:55:31.240]   And so the goal of the project is, you know,
[00:55:31.240 --> 00:55:33.440]   you have like, you have like an app.
[00:55:33.440 --> 00:55:35.700]   And what you do on the app is you take a picture
[00:55:35.700 --> 00:55:37.100]   of some handwritten text.
[00:55:37.100 --> 00:55:41.080]   And then the goal is to then produce the, you know,
[00:55:41.080 --> 00:55:45.040]   the typed version of the text that the user input.
[00:55:45.040 --> 00:55:47.480]   And so the way the system that we built works is,
[00:55:47.480 --> 00:55:49.800]   you know, first there's a web backend
[00:55:49.800 --> 00:55:52.960]   that takes kind of the raw data from this app,
[00:55:52.960 --> 00:55:55.760]   decodes it into a format that the neural network
[00:55:55.760 --> 00:55:59.480]   can understand, and then sends it to a prediction model.
[00:55:59.480 --> 00:56:01.240]   So this is like kind of, you can think about this
[00:56:01.240 --> 00:56:03.560]   as like the weights of a neural network.
[00:56:03.560 --> 00:56:06.200]   And that, it's not super important,
[00:56:06.200 --> 00:56:07.800]   like the details of that model structure,
[00:56:07.800 --> 00:56:10.240]   but it's actually in two separate modules.
[00:56:10.240 --> 00:56:16.120]   And then that's kind of sent back to the web backend
[00:56:16.120 --> 00:56:17.740]   and produces the final result.
[00:56:17.740 --> 00:56:21.360]   But that's kind of not all the parts of the code base.
[00:56:21.360 --> 00:56:23.800]   You also need to figure out how to produce the weights
[00:56:23.800 --> 00:56:27.760]   of this model, like what weights of the neural net
[00:56:27.760 --> 00:56:29.940]   actually produce the best loss.
[00:56:29.940 --> 00:56:32.560]   And so there's also a bunch of code for training models.
[00:56:32.560 --> 00:56:35.280]   So there's data sets and there's training code,
[00:56:35.280 --> 00:56:37.800]   and those produce the final model weights.
[00:56:37.800 --> 00:56:46.700]   Also just wanna quickly mention a couple of best practices
[00:56:46.700 --> 00:56:49.520]   for like at high level, how to think about machine learning
[00:56:49.520 --> 00:56:50.360]   code-based design.
[00:56:50.360 --> 00:56:51.640]   And this is not really all that different
[00:56:51.640 --> 00:56:53.920]   than just general code-based design
[00:56:53.920 --> 00:56:55.960]   for software engineering.
[00:56:55.960 --> 00:56:58.140]   Modularity is really important.
[00:56:58.140 --> 00:57:00.960]   In machine learning context, what this typically means
[00:57:00.960 --> 00:57:04.560]   is that you have separate code for data sets,
[00:57:04.560 --> 00:57:07.560]   models, optimizers, loss functions, things like that.
[00:57:07.560 --> 00:57:08.920]   And you wanna set up your code base in a way
[00:57:08.920 --> 00:57:11.460]   that you can mix and match between them.
[00:57:11.460 --> 00:57:14.600]   So like a lot of times what I see kind of with people
[00:57:14.600 --> 00:57:16.360]   that are less experienced software engineers
[00:57:16.360 --> 00:57:18.240]   that are building machine learning code bases
[00:57:18.240 --> 00:57:22.280]   is that the model that they build
[00:57:22.280 --> 00:57:23.820]   depends really heavily on assumptions
[00:57:23.820 --> 00:57:26.860]   from the specific data set that they're using at this time.
[00:57:26.860 --> 00:57:30.480]   And the problem with that is like oftentimes
[00:57:30.480 --> 00:57:32.520]   you need to change what data set you're using,
[00:57:32.520 --> 00:57:34.960]   or you wanna just reuse the code
[00:57:34.960 --> 00:57:36.460]   that you've already written for training
[00:57:36.460 --> 00:57:37.880]   on some different problem,
[00:57:37.880 --> 00:57:39.960]   where you have some data set that looks kind of different.
[00:57:39.960 --> 00:57:41.880]   And so a lot of the design choices
[00:57:41.880 --> 00:57:45.160]   that we made in the code base that I'll show you
[00:57:45.160 --> 00:57:48.240]   in a second are meant to have modularity
[00:57:48.240 --> 00:57:49.560]   for those types of things.
[00:57:49.560 --> 00:57:55.640]   Another kind of best practice that I've heard
[00:57:55.640 --> 00:57:57.040]   from a lot of people is having
[00:57:57.040 --> 00:57:58.820]   a self-contained prediction module.
[00:57:58.820 --> 00:58:03.200]   So having kind of like a folder within your directory
[00:58:03.200 --> 00:58:06.600]   that has just the minimum set of things that you need
[00:58:06.600 --> 00:58:09.680]   in order to actually serve predictions to the user.
[00:58:09.680 --> 00:58:13.400]   So it might be like the raw weights of the model
[00:58:13.400 --> 00:58:18.400]   and the logic for interacting with the raw data.
[00:58:18.400 --> 00:58:21.540]   And then a very thin wrapper around those weights
[00:58:21.540 --> 00:58:23.540]   that tell you how to turn those weights
[00:58:23.540 --> 00:58:25.600]   and the data into raw predictions.
[00:58:25.600 --> 00:58:26.820]   And so the idea is like,
[00:58:26.820 --> 00:58:29.080]   this is just something that should be super easy to deploy
[00:58:29.080 --> 00:58:32.320]   and doesn't have to deal with the complexity
[00:58:32.320 --> 00:58:33.760]   of all of your training code.
[00:58:33.760 --> 00:58:37.640]   And then one other thing I'll mention,
[00:58:37.640 --> 00:58:40.040]   I think is important is like,
[00:58:40.040 --> 00:58:43.220]   usually what I see is people manage their data separately
[00:58:43.220 --> 00:58:46.720]   from the way that they do version code in their control.
[00:58:46.720 --> 00:58:50.580]   But oftentimes like what is checked into Git
[00:58:50.580 --> 00:58:54.560]   is like some sort of logic for getting the data.
[00:58:54.560 --> 00:58:57.840]   So you might have your data stored on S3
[00:58:57.840 --> 00:59:01.400]   or some other sort of data storage.
[00:59:01.400 --> 00:59:03.780]   And then like within your code base on Git,
[00:59:03.780 --> 00:59:06.600]   you might have some rules for like the specific version
[00:59:06.600 --> 00:59:08.400]   of the dataset that you're using,
[00:59:08.400 --> 00:59:11.340]   how to actually go and download that from S3.
[00:59:11.340 --> 00:59:16.340]   All right, actually any questions about this?
[00:59:16.340 --> 00:59:28.200]   Yeah, is there a reference for a good project?
[00:59:28.200 --> 00:59:30.160]   I'll show you one that I think is pretty good in a second.
[00:59:30.160 --> 00:59:31.440]   Yeah, yeah.
[00:59:31.440 --> 00:59:36.000]   (student mumbling)
[00:59:37.000 --> 00:59:42.000]   Yeah, so keeping track of model performance and versions.
[00:59:42.000 --> 00:59:53.880]   I swear this is not a plant,
[00:59:53.880 --> 00:59:56.160]   but I actually use weights and biases for this
[00:59:56.160 --> 00:59:58.080]   and I think it's really great.
[00:59:58.080 --> 01:00:00.000]   And yeah, I would encourage you all
[01:00:00.000 --> 01:00:01.640]   to at least try using it as well.
[01:00:01.640 --> 01:00:03.960]   Yeah.
[01:00:03.960 --> 01:00:06.880]   (student mumbling)
[01:00:06.880 --> 01:00:21.720]   Yeah, so how do you deal with,
[01:00:21.720 --> 01:00:22.960]   once you have deployed model,
[01:00:22.960 --> 01:00:24.600]   you might have some data drift
[01:00:24.600 --> 01:00:26.680]   and how do you catch that early?
[01:00:26.680 --> 01:00:30.520]   I think the way to do that is by trying to capture
[01:00:30.520 --> 01:00:32.520]   some of that drift with tests
[01:00:32.520 --> 01:00:35.640]   and then like, I mean, the idea is to try to capture it
[01:00:35.640 --> 01:00:37.140]   as early as possible and flag it.
[01:00:37.140 --> 01:00:39.020]   And there are a couple of different causes,
[01:00:39.020 --> 01:00:39.920]   like potential causes.
[01:00:39.920 --> 01:00:42.840]   One is data drift, but another is, you know,
[01:00:42.840 --> 01:00:44.320]   some sort of regression in your code base.
[01:00:44.320 --> 01:00:47.680]   Like you push, you train some model
[01:00:47.680 --> 01:00:50.040]   and it looks like the model is performing really well,
[01:00:50.040 --> 01:00:52.000]   but in reality, you know,
[01:00:52.000 --> 01:00:53.620]   it doesn't perform as well in the real data.
[01:00:53.620 --> 01:00:55.680]   And so you need to like kind of quickly be able to go
[01:00:55.680 --> 01:00:57.600]   and revert that back.
[01:00:57.600 --> 01:00:59.960]   And yeah, we'll talk about this in more detail
[01:00:59.960 --> 01:01:00.960]   second to last week.
[01:01:01.960 --> 01:01:04.880]   (student mumbling)
[01:01:04.880 --> 01:01:29.600]   Yeah, how do you keep track of,
[01:01:29.600 --> 01:01:31.880]   so you have version control for your code
[01:01:31.880 --> 01:01:34.160]   and then you have, and what I'm saying is
[01:01:34.160 --> 01:01:35.840]   you wanna manage your data separately from that.
[01:01:35.840 --> 01:01:37.360]   And those two things interact.
[01:01:37.360 --> 01:01:40.440]   So the question is how do you manage that interaction?
[01:01:40.440 --> 01:01:41.880]   Yeah, I think like one way to do this,
[01:01:41.880 --> 01:01:44.560]   I'm not, this is something that I've seen in practice.
[01:01:44.560 --> 01:01:46.960]   I'm not sure if this is, there might be a better way
[01:01:46.960 --> 01:01:51.960]   is to sort of pin your, like your training code
[01:01:51.960 --> 01:01:55.160]   and your model code to a specific version of the data.
[01:01:55.160 --> 01:01:57.640]   And then you can be conscious about how you update that.
[01:01:57.640 --> 01:01:59.840]   So it's kind of like if you have to manage
[01:01:59.840 --> 01:02:02.620]   some unstable dependency in your code base.
[01:02:02.620 --> 01:02:11.620]   All right, I wanna quickly just kind of take you
[01:02:11.620 --> 01:02:13.680]   on like a very, very brief tour of this code base.
[01:02:13.680 --> 01:02:15.680]   And then I'm going to encourage you all
[01:02:15.680 --> 01:02:18.440]   to spend time looking at this on your own.
[01:02:18.440 --> 01:02:25.620]   But if you have your computers, you can follow along.
[01:02:25.620 --> 01:02:26.620]   This is the URL.
[01:02:26.620 --> 01:02:30.120]   (computer mouse clicking)
[01:02:30.120 --> 01:02:41.620]   Okay, so what you're looking at is the code for the labs
[01:02:41.620 --> 01:02:45.380]   for this bootcamp that we ran a month or so ago.
[01:02:45.380 --> 01:02:49.140]   And if you go to this URL on your own,
[01:02:49.140 --> 01:02:50.580]   I would encourage you to kind of poke through
[01:02:50.580 --> 01:02:53.840]   each of the labs and maybe try some of the exercises
[01:02:53.840 --> 01:02:56.140]   and just kind of get a feel for it.
[01:02:56.140 --> 01:03:00.380]   But right now I'm looking at the solutions for lab nine
[01:03:00.380 --> 01:03:02.140]   because this is kind of like shows the code base
[01:03:02.140 --> 01:03:04.060]   in its most mature form.
[01:03:04.060 --> 01:03:06.220]   So a few things to notice here.
[01:03:06.220 --> 01:03:08.940]   The first is that we have this API folder.
[01:03:08.940 --> 01:03:12.280]   And this is kind of like the minimal version
[01:03:12.280 --> 01:03:14.460]   of serving the model that I talked about.
[01:03:14.460 --> 01:03:17.460]   And so it contains a Docker file for those of you
[01:03:17.460 --> 01:03:21.280]   that use Docker to kind of to specify
[01:03:21.280 --> 01:03:23.820]   what the dependencies are for the production version
[01:03:23.820 --> 01:03:26.180]   of the model, and then it contains kind of an app,
[01:03:26.180 --> 01:03:28.220]   which is the logic for how you serve predictions
[01:03:28.220 --> 01:03:29.060]   from the model.
[01:03:29.060 --> 01:03:34.020]   And then some other specifications for how to make this run.
[01:03:34.020 --> 01:03:37.580]   And the weights, like when you deploy your model,
[01:03:37.580 --> 01:03:40.180]   the weights are actually just copied into this folder.
[01:03:40.180 --> 01:03:47.540]   Then there's kind of a couple of folders
[01:03:47.540 --> 01:03:48.780]   that are just more for convenience.
[01:03:48.780 --> 01:03:50.060]   So there's notebooks.
[01:03:50.060 --> 01:03:53.700]   A lot of times, Jupyter notebooks are really good ways
[01:03:53.700 --> 01:03:55.860]   of playing around with your data,
[01:03:55.860 --> 01:03:58.420]   testing out your models and just kind of seeing
[01:03:58.420 --> 01:04:00.540]   in an informal way how they work.
[01:04:00.540 --> 01:04:02.220]   And then tasks.
[01:04:02.220 --> 01:04:04.260]   These are just convenience scripts for doing things
[01:04:04.260 --> 01:04:08.340]   that you are gonna do frequently in your code base.
[01:04:08.340 --> 01:04:13.340]   So things like running your tests, training your models,
[01:04:13.340 --> 01:04:17.020]   and linting to make sure that your code
[01:04:17.020 --> 01:04:18.400]   meets code standards.
[01:04:18.400 --> 01:04:22.660]   And then the meat of this folder is in,
[01:04:22.660 --> 01:04:24.980]   or this project is in training.
[01:04:24.980 --> 01:04:27.900]   Wait, sorry, it's in Text Recognizer.
[01:04:27.900 --> 01:04:31.520]   And so this is where we have most of the code
[01:04:31.520 --> 01:04:36.300]   for kind of how you build models
[01:04:36.300 --> 01:04:39.060]   and how you build loss functions and neural networks,
[01:04:39.060 --> 01:04:42.280]   and then how they interact with optimizers.
[01:04:42.280 --> 01:04:43.540]   So there's datasets.
[01:04:43.540 --> 01:04:45.620]   And so this is not actually where the raw data is contained,
[01:04:45.620 --> 01:04:48.180]   but this contains the logic for how to turn the raw data
[01:04:48.180 --> 01:04:50.480]   into something that's consumable by the model.
[01:04:51.460 --> 01:04:53.420]   Then there's models and networks.
[01:04:53.420 --> 01:04:56.300]   The distinction here is that I think of a network
[01:04:56.300 --> 01:04:59.540]   as sort of like a dumb input-output mapping.
[01:04:59.540 --> 01:05:03.520]   So a network is f of x equals y.
[01:05:03.520 --> 01:05:06.400]   And then a model contains all of the other stuff
[01:05:06.400 --> 01:05:10.020]   that you need in order to use that network and train it.
[01:05:10.020 --> 01:05:14.100]   So it contains things like how you define the optimizer
[01:05:14.100 --> 01:05:16.980]   for that model, what does it mean to take a gradient step
[01:05:16.980 --> 01:05:21.100]   on that model, how do you turn sort of the raw output
[01:05:21.100 --> 01:05:23.980]   into the actual structured prediction and things like that.
[01:05:23.980 --> 01:05:25.580]   And so the reason that there's this split
[01:05:25.580 --> 01:05:27.740]   is because if you just have networks,
[01:05:27.740 --> 01:05:29.140]   then you can kind of really easily change
[01:05:29.140 --> 01:05:30.600]   your neural network architecture
[01:05:30.600 --> 01:05:33.460]   without having to fuddle with how that interacts
[01:05:33.460 --> 01:05:34.700]   with the rest of your code base.
[01:05:34.700 --> 01:05:36.100]   So it sort of isolates that.
[01:05:36.100 --> 01:05:39.540]   And then we have tests and a folder here
[01:05:39.540 --> 01:05:42.440]   for storing the best current weights.
[01:05:48.660 --> 01:05:51.420]   All right, so that's just a very, very brief tour
[01:05:51.420 --> 01:05:53.140]   of what this code base looks like.
[01:05:53.140 --> 01:05:55.480]   And the next thing I wanna talk about is your homework,
[01:05:55.480 --> 01:05:57.700]   which part of that will be looking through
[01:05:57.700 --> 01:05:59.200]   this code base in more detail.
[01:05:59.200 --> 01:06:11.420]   All right, so again, each week we're gonna have you watch
[01:06:11.420 --> 01:06:12.620]   one of the lectures.
[01:06:12.620 --> 01:06:14.480]   And so for next week, we'll have you watch
[01:06:14.480 --> 01:06:15.780]   the data management lecture.
[01:06:15.780 --> 01:06:16.820]   And you don't need to write this down.
[01:06:16.820 --> 01:06:19.380]   We'll kind of post all this stuff to Slack as well.
[01:06:19.380 --> 01:06:21.940]   But that's the link on YouTube.
[01:06:21.940 --> 01:06:26.300]   And then, I didn't really have time to go through
[01:06:26.300 --> 01:06:28.780]   the text recognizer code base in a lot of detail.
[01:06:28.780 --> 01:06:31.900]   And so I want you all to start getting familiar with this
[01:06:31.900 --> 01:06:33.620]   so that you have a sense of like kind of
[01:06:33.620 --> 01:06:35.980]   what a really good sort of production ready
[01:06:35.980 --> 01:06:37.520]   machine learning code base looks like.
[01:06:37.520 --> 01:06:39.260]   So I want you all to read through it
[01:06:39.260 --> 01:06:41.660]   and then kind of pick, like take your choice,
[01:06:41.660 --> 01:06:44.020]   which of the following assignments you wanna do.
[01:06:45.020 --> 01:06:47.780]   You can do one of the labs if you want.
[01:06:47.780 --> 01:06:51.900]   Most of them involve filling in code to kind of specify
[01:06:51.900 --> 01:06:53.380]   the way that you do the neural net
[01:06:53.380 --> 01:06:55.540]   or like the way that you serve predictions.
[01:06:55.540 --> 01:06:59.340]   Or you can post a question about it on Slack.
[01:06:59.340 --> 01:07:02.020]   So find something in the code base that you're not sure
[01:07:02.020 --> 01:07:03.860]   about like, why did we structure it this way?
[01:07:03.860 --> 01:07:06.860]   Or, you know, why aren't we doing this thing and post that?
[01:07:06.860 --> 01:07:10.740]   Or, and this is like highly, highly encouraged.
[01:07:10.740 --> 01:07:12.580]   You submit a pull request to this code base,
[01:07:12.580 --> 01:07:15.900]   you'll get extra credit in the meaningless point system
[01:07:15.900 --> 01:07:16.740]   of the course.
[01:07:16.740 --> 01:07:18.700]   But I think this is actually,
[01:07:18.700 --> 01:07:20.380]   this is like the best way to learn your way around it.
[01:07:20.380 --> 01:07:22.200]   And so I'm not expecting everyone to do this,
[01:07:22.200 --> 01:07:24.200]   but I hope a few of you choose to do it.
[01:07:24.200 --> 01:07:29.420]   All right, but kind of more importantly than these
[01:07:29.420 --> 01:07:32.220]   is to start working on your projects.
[01:07:32.220 --> 01:07:35.780]   And the first step here is we want you all
[01:07:35.780 --> 01:07:37.980]   to pick your projects.
[01:07:37.980 --> 01:07:40.540]   And we have a specific way that we're gonna do that.
[01:07:41.260 --> 01:07:43.500]   (mimics drum roll)
[01:07:43.500 --> 01:07:44.780]   So we've set up a,
[01:07:44.780 --> 01:07:47.360]   I can't find my mouse.
[01:07:47.360 --> 01:07:50.620]   There we go.
[01:07:50.620 --> 01:07:54.460]   We've set up an Excel or a Google sheet
[01:07:54.460 --> 01:07:56.700]   that has a bunch of, it's pre-populated
[01:07:56.700 --> 01:07:58.860]   with a bunch of suggested project ideas.
[01:07:58.860 --> 01:08:03.820]   And so each of these project ideas
[01:08:03.820 --> 01:08:05.940]   kind of has a very brief description
[01:08:05.940 --> 01:08:08.060]   and like sort of a very rough estimate
[01:08:08.060 --> 01:08:09.180]   of how hard they're gonna be,
[01:08:09.180 --> 01:08:10.740]   both in terms of how hard they're gonna be
[01:08:10.740 --> 01:08:12.380]   to build a good label data set,
[01:08:12.380 --> 01:08:13.640]   and also how hard they're gonna be
[01:08:13.640 --> 01:08:15.740]   to like find a good model to train on them.
[01:08:15.740 --> 01:08:20.340]   And then what we have over here is columns for people.
[01:08:20.340 --> 01:08:23.260]   So there's a maximum of four people for the project.
[01:08:23.260 --> 01:08:25.100]   And so what we want all of you to do
[01:08:25.100 --> 01:08:27.660]   is to start going through these projects.
[01:08:27.660 --> 01:08:29.580]   And when you kind of have a sense
[01:08:29.580 --> 01:08:31.060]   of what project you wanna work on,
[01:08:31.060 --> 01:08:35.080]   add yourself to one of these columns for that project.
[01:08:35.080 --> 01:08:36.780]   One other thing I wanna say on this,
[01:08:36.780 --> 01:08:38.820]   the projects I put in here are kind of just
[01:08:38.820 --> 01:08:40.380]   like projects that I think would be fun to do,
[01:08:40.380 --> 01:08:41.540]   but what I really want people to do
[01:08:41.540 --> 01:08:43.780]   is to come up with their own projects.
[01:08:43.780 --> 01:08:46.660]   So if you have ideas for like a cool side project
[01:08:46.660 --> 01:08:49.020]   that you wanna work on and wanna get people's help with,
[01:08:49.020 --> 01:08:52.220]   then I would highly encourage you to add them to this sheet
[01:08:52.220 --> 01:08:54.660]   and maybe lobby in Slack a little bit
[01:08:54.660 --> 01:08:56.420]   to convince other people in the class
[01:08:56.420 --> 01:08:59.120]   that your project is the most exciting one to work on.
[01:08:59.120 --> 01:09:01.260]   Yeah.
[01:09:01.260 --> 01:09:03.820]   - [Student] Are these projects have data available?
[01:09:03.820 --> 01:09:04.660]   - Sorry?
[01:09:04.660 --> 01:09:07.060]   - [Student] The projects that you have mentioned in the book,
[01:09:07.060 --> 01:09:10.460]   would they have the data available on the backup?
[01:09:10.460 --> 01:09:11.580]   - Yeah, so the question was,
[01:09:11.580 --> 01:09:14.620]   is the data available for the projects that I suggested?
[01:09:14.620 --> 01:09:15.780]   It's a mix.
[01:09:15.780 --> 01:09:19.300]   So for the ones where I said data availability is like a two,
[01:09:19.300 --> 01:09:20.900]   generally what I meant by that is
[01:09:20.900 --> 01:09:23.840]   there's some publicly available dataset
[01:09:23.840 --> 01:09:25.880]   that will get you most of the way there.
[01:09:25.880 --> 01:09:30.060]   And for the ones that I said were a four or five,
[01:09:30.060 --> 01:09:31.860]   generally that means that part of what you're gonna have to
[01:09:31.860 --> 01:09:34.500]   do for this project is to build the dataset yourself.
[01:09:35.540 --> 01:09:38.600]   Building datasets is challenging.
[01:09:38.600 --> 01:09:40.780]   And if you choose one of those projects,
[01:09:40.780 --> 01:09:43.620]   I'd highly suggest getting started on that very early.
[01:09:43.620 --> 01:09:46.100]   But oftentimes those can be the most rewarding projects
[01:09:46.100 --> 01:09:48.900]   because if you're working with some publicly available
[01:09:48.900 --> 01:09:51.560]   dataset, then chances are a lot of people have tried things
[01:09:51.560 --> 01:09:52.700]   on that dataset before.
[01:09:52.700 --> 01:09:54.980]   So it's up to you.
[01:09:54.980 --> 01:09:57.020]   I leave it up to you how much effort you wanna put
[01:09:57.020 --> 01:09:58.580]   into building your own dataset.
[01:09:58.580 --> 01:10:01.060]   Yeah.
[01:10:01.060 --> 01:10:03.060]   - [Student] Do you have objectives on what should be
[01:10:03.060 --> 01:10:05.060]   the goal of the project?
[01:10:05.060 --> 01:10:12.140]   - So what I'm hoping for these projects is that
[01:10:12.140 --> 01:10:14.620]   at the end of the course, so seven weeks from now,
[01:10:14.620 --> 01:10:18.100]   each team, so each one or two or three or four of you
[01:10:18.100 --> 01:10:21.860]   have something that you can showcase that demonstrates
[01:10:21.860 --> 01:10:26.620]   that you've built a prototype of a machine learning system
[01:10:26.620 --> 01:10:27.460]   end to end.
[01:10:27.460 --> 01:10:32.460]   So I'm not expecting you to go and solve some problem
[01:10:32.660 --> 01:10:36.140]   and sell your system to Google for $100 million.
[01:10:36.140 --> 01:10:37.980]   'Cause if you can do that in six weeks,
[01:10:37.980 --> 01:10:41.080]   then you can teach the next version of the course.
[01:10:41.080 --> 01:10:45.900]   But it's gonna be very difficult to completely solve
[01:10:45.900 --> 01:10:46.840]   a problem in this timeframe.
[01:10:46.840 --> 01:10:50.620]   But what I'm hoping is that we'll have really cool demos
[01:10:50.620 --> 01:10:53.940]   that kind of show that you have a system that is starting
[01:10:53.940 --> 01:10:55.460]   to work in the real world.
[01:10:55.460 --> 01:10:57.820]   Yeah.
[01:10:57.820 --> 01:11:01.380]   - So one of the steps in proposing a new project idea
[01:11:01.380 --> 01:11:02.540]   would be like filling, okay,
[01:11:02.540 --> 01:11:03.820]   here's a description of the project,
[01:11:03.820 --> 01:11:05.860]   but then also to estimate the difficulty.
[01:11:05.860 --> 01:11:06.700]   - Yeah.
[01:11:06.700 --> 01:11:08.660]   - And I'm curious if you have sort of a,
[01:11:08.660 --> 01:11:12.420]   I don't know, just a process for vetting our estimates
[01:11:12.420 --> 01:11:15.620]   of just guessing before you can sign up,
[01:11:15.620 --> 01:11:17.180]   or if we just kind of like try it
[01:11:17.180 --> 01:11:19.180]   and then we try it wrong.
[01:11:19.180 --> 01:11:20.020]   - Yeah, totally.
[01:11:20.020 --> 01:11:22.780]   - Or how does that fit into the selection process?
[01:11:22.780 --> 01:11:25.540]   - Yeah, so when you're putting your projects in,
[01:11:25.540 --> 01:11:26.940]   yeah, you should just guess at the difficult.
[01:11:26.940 --> 01:11:31.040]   I mean, you should use the tools that we talked about
[01:11:31.040 --> 01:11:33.260]   in this class to guess the difficulty.
[01:11:33.260 --> 01:11:36.460]   And like, to be clear, the difficulties that I have here
[01:11:36.460 --> 01:11:38.500]   were like my guess that I did this morning.
[01:11:38.500 --> 01:11:43.140]   So those are also like very much subject to be wrong.
[01:11:43.140 --> 01:11:46.720]   But if you put like some guess for difficulty
[01:11:46.720 --> 01:11:48.340]   that's like wildly incorrect,
[01:11:48.340 --> 01:11:50.420]   just know that I'm gonna be stocking the sheet
[01:11:50.420 --> 01:11:51.300]   and calling you out for it.
[01:11:51.300 --> 01:11:53.820]   So yeah, that's the accountability mechanism.
[01:11:53.820 --> 01:11:56.460]   Yeah.
[01:11:56.460 --> 01:11:59.340]   - With the growth of the end-to-end project,
[01:11:59.340 --> 01:12:01.260]   is it that we want to pick projects
[01:12:01.260 --> 01:12:02.780]   that have more work in their company
[01:12:02.780 --> 01:12:04.220]   than we do in our companies
[01:12:04.220 --> 01:12:07.020]   in order to focus on best practices
[01:12:07.020 --> 01:12:08.860]   and the core work that's under that.
[01:12:08.860 --> 01:12:11.180]   - Yeah, I kind of want to leave this up to you.
[01:12:11.180 --> 01:12:14.340]   I think, you know, I think if you're sort of newer
[01:12:14.340 --> 01:12:18.740]   to machine learning and you haven't like built a project
[01:12:18.740 --> 01:12:20.540]   on your own before, then I would recommend
[01:12:20.540 --> 01:12:22.280]   choosing something where you kind of know
[01:12:22.280 --> 01:12:23.900]   where you're gonna get the data from already.
[01:12:23.900 --> 01:12:26.600]   And you have a good sense that you can find a model
[01:12:26.600 --> 01:12:28.060]   that's going to work for this data.
[01:12:28.060 --> 01:12:29.780]   And then just like focus on getting one thing
[01:12:29.780 --> 01:12:30.780]   working end-to-end.
[01:12:30.780 --> 01:12:33.960]   If you're sort of more experienced,
[01:12:33.960 --> 01:12:36.060]   like some of you kind of have been like working
[01:12:36.060 --> 01:12:39.260]   as machine learning engineers for quite some time already,
[01:12:39.260 --> 01:12:40.660]   then you know, challenge yourself
[01:12:40.660 --> 01:12:42.260]   and like use your best judgment.
[01:12:42.260 --> 01:12:44.700]   Yeah.
[01:12:44.700 --> 01:12:46.060]   - Maybe a little late, but I have a question
[01:12:46.060 --> 01:12:48.460]   about the pull request, whether you had any
[01:12:48.460 --> 01:12:50.460]   sort of guidelines as to what you should take
[01:12:50.460 --> 01:12:51.300]   that we should be able to do,
[01:12:51.300 --> 01:12:53.180]   but what kind of pull requests are you looking for?
[01:12:53.180 --> 01:12:54.660]   - Yeah, submit a pull request
[01:12:54.660 --> 01:12:56.220]   that I will be excited to merge.
[01:12:56.220 --> 01:12:57.060]   Yeah.
[01:12:57.060 --> 01:12:58.460]   (audience laughing)
[01:12:58.460 --> 01:13:00.900]   No, I think there's like, you know,
[01:13:00.900 --> 01:13:02.740]   this code base is not actually used in production.
[01:13:02.740 --> 01:13:04.780]   We built it as an example of a sort of like
[01:13:04.780 --> 01:13:06.740]   a simplified example of a production system.
[01:13:06.740 --> 01:13:08.220]   And so there are a lot of things
[01:13:08.220 --> 01:13:11.040]   that we just didn't really have time
[01:13:11.040 --> 01:13:12.580]   to get working the right way.
[01:13:12.580 --> 01:13:15.260]   And so, you know, as you poke around the code,
[01:13:15.260 --> 01:13:17.440]   you will find those and yeah.
[01:13:17.440 --> 01:13:22.200]   (man speaking indistinctly)
[01:13:25.740 --> 01:13:29.620]   So for the demo, I think it depends a little bit
[01:13:29.620 --> 01:13:31.500]   on what your dataset looks like.
[01:13:31.500 --> 01:13:32.340]   Yeah.
[01:13:32.340 --> 01:13:38.620]   What's the question?
[01:13:38.620 --> 01:13:42.200]   (man speaking indistinctly)
[01:13:42.200 --> 01:13:47.180]   Yeah, I mean, so the goal is like, you know,
[01:13:47.180 --> 01:13:50.260]   if your thing is like an app, like to have, you know,
[01:13:50.260 --> 01:13:51.720]   you don't need to build like an iOS app,
[01:13:51.720 --> 01:13:54.260]   but to have some sort of, you know,
[01:13:54.260 --> 01:13:55.540]   web endpoint that you can like,
[01:13:55.540 --> 01:13:58.220]   so you can pull out your phone and show it to your friends.
[01:13:58.220 --> 01:14:00.800]   Yeah.
[01:14:00.800 --> 01:14:06.080]   (man speaking indistinctly)
[01:14:22.180 --> 01:14:24.140]   So the question is, is there a language expectation
[01:14:24.140 --> 01:14:24.980]   for this?
[01:14:24.980 --> 01:14:29.460]   I'm going to strongly encourage people to use Keras.
[01:14:29.460 --> 01:14:31.620]   And we'll talk more about this next week.
[01:14:31.620 --> 01:14:32.820]   I just kind of think it's like the best way
[01:14:32.820 --> 01:14:35.140]   to get things to actually work.
[01:14:35.140 --> 01:14:36.980]   If you have a problem where Keras doesn't make sense,
[01:14:36.980 --> 01:14:39.660]   then, you know, then let me know why.
[01:14:39.660 --> 01:14:42.100]   And there are like definitely other languages
[01:14:42.100 --> 01:14:44.100]   that could make sense for certain projects.
[01:14:44.100 --> 01:14:47.700]   Yeah, I'll take this as the last question
[01:14:47.700 --> 01:14:48.540]   and then we're gonna move on.
[01:14:48.540 --> 01:14:50.460]   (woman speaking indistinctly)
[01:14:50.460 --> 01:14:51.300]   Yeah.
[01:14:51.300 --> 01:14:55.140]   (woman speaking indistinctly)
[01:14:55.140 --> 01:15:01.020]   What are the problems where deep learning
[01:15:01.020 --> 01:15:03.500]   does worse than classical machine learning?
[01:15:03.500 --> 01:15:04.560]   A few things come to mind.
[01:15:04.560 --> 01:15:08.040]   One is just anywhere where you don't have a lot of data.
[01:15:08.040 --> 01:15:11.780]   So if you're in a domain that has limited data,
[01:15:11.780 --> 01:15:14.820]   classical machine learning tends to do better,
[01:15:14.820 --> 01:15:16.140]   tends to generalize better.
[01:15:16.140 --> 01:15:19.220]   Another thing that comes to mind is causal reasoning.
[01:15:19.220 --> 01:15:21.180]   So there's sort of like a whole literature
[01:15:21.180 --> 01:15:23.020]   around causal reasoning in classical ML
[01:15:23.020 --> 01:15:24.640]   that doesn't work all that well,
[01:15:24.640 --> 01:15:26.820]   but it works better than sort of the non-existent
[01:15:26.820 --> 01:15:28.720]   causal reasoning in deep learning.
[01:15:28.720 --> 01:15:35.220]   And then the only other thing that really comes to mind
[01:15:35.220 --> 01:15:38.280]   is sort of geometric understanding,
[01:15:38.280 --> 01:15:40.400]   like understanding of 3D structure.
[01:15:40.400 --> 01:15:42.620]   And this is actually really surprising to me.
[01:15:42.620 --> 01:15:43.620]   I don't think it should be true,
[01:15:43.620 --> 01:15:45.740]   but as far as I can tell,
[01:15:45.740 --> 01:15:47.740]   for things like 3D reconstruction,
[01:15:47.740 --> 01:15:49.700]   classical pipelines still tend to work better,
[01:15:49.700 --> 01:15:51.900]   maybe with a little bit of deep learning sprinkled in.
[01:15:51.900 --> 01:15:55.980]   Great.
[01:15:55.980 --> 01:15:58.420]   That's all for me.
[01:15:58.420 --> 01:16:01.560]   Next up, we have our guest speaker, Neil Kosa.
[01:16:01.560 --> 01:16:06.900]   Neil is, I would describe Neil as sort of
[01:16:06.900 --> 01:16:10.420]   the rare entrepreneur that is crazy enough
[01:16:10.420 --> 01:16:12.980]   not only to start a machine learning startup
[01:16:12.980 --> 01:16:14.620]   and not only to do it in healthcare,
[01:16:14.620 --> 01:16:17.500]   but actually to do two at the same time.
[01:16:17.500 --> 01:16:19.740]   And so Neil, I think, I've always been super impressed
[01:16:19.740 --> 01:16:22.500]   by Neil's insight about how to think about
[01:16:22.500 --> 01:16:24.420]   sort of like what machine learning problems
[01:16:24.420 --> 01:16:25.460]   or just what problems in general
[01:16:25.460 --> 01:16:28.340]   will be really impactful for people to be working on.
[01:16:28.340 --> 01:16:30.860]   So I'm really excited to have him here.
[01:16:30.860 --> 01:16:31.700]   Thanks, welcome.

