
[00:00:00.000 --> 00:00:02.920]   The following is a conversation with Richard Karp,
[00:00:02.920 --> 00:00:06.320]   a professor at Berkeley and one of the most important figures
[00:00:06.320 --> 00:00:09.480]   in the history of theoretical computer science.
[00:00:09.480 --> 00:00:12.680]   In 1985, he received the Turing Award
[00:00:12.680 --> 00:00:15.140]   for his research in the theory of algorithms,
[00:00:15.140 --> 00:00:18.420]   including the development of the admirance Karp algorithm
[00:00:18.420 --> 00:00:21.800]   for solving the max flow problem on networks,
[00:00:21.800 --> 00:00:24.380]   Hopcroft-Karp algorithm for finding
[00:00:24.380 --> 00:00:27.980]   maximum cardinality matchings in bipartite graphs,
[00:00:27.980 --> 00:00:31.000]   and his landmark paper in complexity theory
[00:00:31.000 --> 00:00:35.320]   called "Reducibility Among Combinatorial Problems,"
[00:00:35.320 --> 00:00:39.040]   in which he proved 21 problems to be NP-complete.
[00:00:39.040 --> 00:00:41.880]   This paper was probably the most important catalyst
[00:00:41.880 --> 00:00:45.400]   in the explosion of interest in the study of NP-completeness
[00:00:45.400 --> 00:00:48.800]   and the P versus NP problem in general.
[00:00:48.800 --> 00:00:50.220]   Quick summary of the ads.
[00:00:50.220 --> 00:00:53.600]   Two sponsors, 8Sleep Mattress and Cash App.
[00:00:53.600 --> 00:00:55.680]   Please consider supporting this podcast
[00:00:55.680 --> 00:00:58.820]   by going to 8sleep.com/lex
[00:00:58.820 --> 00:01:03.040]   and downloading Cash App and using code LEXPODCAST.
[00:01:03.040 --> 00:01:04.600]   Click the links, buy the stuff.
[00:01:04.600 --> 00:01:08.080]   It really is the best way to support this podcast.
[00:01:08.080 --> 00:01:10.280]   If you enjoy this thing, subscribe on YouTube,
[00:01:10.280 --> 00:01:12.480]   review it with Firestarz and Apple Podcast,
[00:01:12.480 --> 00:01:13.840]   support it on Patreon,
[00:01:13.840 --> 00:01:16.840]   or connect with me on Twitter @lexfriedman.
[00:01:16.840 --> 00:01:18.840]   As usual, I'll do a few minutes of ads now
[00:01:18.840 --> 00:01:20.120]   and never any ads in the middle
[00:01:20.120 --> 00:01:23.000]   that can break the flow of the conversation.
[00:01:23.000 --> 00:01:27.380]   This show is sponsored by 8Sleep and its Pod Pro mattress
[00:01:27.380 --> 00:01:32.380]   that you can check out at 8sleep.com/lex to get $200 off.
[00:01:32.380 --> 00:01:35.920]   It controls temperature with an app.
[00:01:35.920 --> 00:01:38.360]   It can cool down to as low as 55 degrees
[00:01:38.360 --> 00:01:41.040]   on each side of the bed separately.
[00:01:41.040 --> 00:01:43.560]   Research shows that temperature has a big impact
[00:01:43.560 --> 00:01:45.020]   on the quality of our sleep.
[00:01:45.020 --> 00:01:47.800]   Anecdotally, it's been a game changer for me.
[00:01:47.800 --> 00:01:48.800]   I love it.
[00:01:48.800 --> 00:01:50.180]   It's been a couple of weeks now.
[00:01:50.180 --> 00:01:52.520]   I've just been really enjoying it,
[00:01:52.520 --> 00:01:54.680]   both in the fact that I'm getting better sleep
[00:01:54.680 --> 00:01:58.280]   and that it's a smart mattress, essentially.
[00:01:58.280 --> 00:02:00.080]   I kind of imagine this being the early days
[00:02:00.080 --> 00:02:02.840]   of artificial intelligence being a part
[00:02:02.840 --> 00:02:04.360]   of every aspect of our lives.
[00:02:04.360 --> 00:02:06.440]   And certainly infusing AI
[00:02:06.440 --> 00:02:08.400]   in one of the most important aspects of life,
[00:02:08.400 --> 00:02:11.360]   which is sleep, I think has a lot of potential
[00:02:11.360 --> 00:02:13.160]   for being beneficial.
[00:02:13.160 --> 00:02:15.320]   The Pod Pro is packed with sensors
[00:02:15.320 --> 00:02:17.760]   that track heart rate, heart rate variability,
[00:02:17.760 --> 00:02:21.800]   and respiratory rate, showing it all in their app.
[00:02:21.800 --> 00:02:24.360]   The app's health metrics are amazing,
[00:02:24.360 --> 00:02:27.160]   but the cooling alone is honestly worth the money.
[00:02:27.160 --> 00:02:29.320]   I don't always sleep, but when I do,
[00:02:29.320 --> 00:02:32.000]   I choose the 8Sleep Pod Pro mattress.
[00:02:32.000 --> 00:02:37.000]   Check it out at 8sleep.com/flex to get $200 off.
[00:02:37.000 --> 00:02:39.080]   And remember, just visiting the site
[00:02:39.080 --> 00:02:42.040]   and considering the purchase helps convince the folks
[00:02:42.040 --> 00:02:44.880]   at 8Sleep that this silly old podcast
[00:02:44.880 --> 00:02:46.580]   is worth sponsoring in the future.
[00:02:46.580 --> 00:02:50.580]   This show is also presented by the great
[00:02:50.580 --> 00:02:54.380]   and powerful Cash App, the number one finance app
[00:02:54.380 --> 00:02:55.360]   in the App Store.
[00:02:55.360 --> 00:02:58.200]   When you get it, use code LEXPODCAST.
[00:02:58.200 --> 00:03:00.160]   Cash App lets you send money to friends,
[00:03:00.160 --> 00:03:02.560]   buy Bitcoin, and invest in the stock market
[00:03:02.560 --> 00:03:04.680]   with as little as $1.
[00:03:04.680 --> 00:03:06.760]   It's one of the best designed interfaces
[00:03:06.760 --> 00:03:08.520]   of an app that I've ever used.
[00:03:08.520 --> 00:03:12.360]   To me, good design is when everything is easy and natural.
[00:03:12.360 --> 00:03:15.120]   Bad design is when the app gets in the way,
[00:03:15.120 --> 00:03:16.600]   either because it's buggy
[00:03:16.600 --> 00:03:19.300]   or because it tries too hard to be helpful.
[00:03:19.300 --> 00:03:21.580]   I'm looking at you, Clippy, from Microsoft,
[00:03:21.580 --> 00:03:23.160]   even though I love you.
[00:03:23.160 --> 00:03:25.500]   Anyway, there's a big part of my brain and heart
[00:03:25.500 --> 00:03:27.400]   that loves to design things
[00:03:27.400 --> 00:03:30.000]   and also to appreciate great design by others.
[00:03:30.000 --> 00:03:31.740]   So again, if you get Cash App
[00:03:31.740 --> 00:03:33.280]   from the App Store or Google Play
[00:03:33.280 --> 00:03:36.840]   and use the code LEXPODCAST, you get $10.
[00:03:36.840 --> 00:03:39.600]   Cash App will also donate $10 to FIRST,
[00:03:39.600 --> 00:03:42.320]   an organization that is helping to advance robotics
[00:03:42.320 --> 00:03:45.720]   and STEM education for young people around the world.
[00:03:45.720 --> 00:03:49.600]   And now, here's my conversation with Richard Karp.
[00:03:49.600 --> 00:03:52.820]   You wrote that at the age of 13,
[00:03:52.820 --> 00:03:55.220]   you were first exposed to plane geometry
[00:03:55.220 --> 00:03:57.620]   and was wonderstruck by the power
[00:03:57.620 --> 00:04:00.260]   and elegance of formal proofs.
[00:04:00.260 --> 00:04:02.640]   Are there problems, proofs, properties, ideas
[00:04:02.640 --> 00:04:04.940]   in plane geometry that, from that time,
[00:04:04.940 --> 00:04:07.860]   that you remember being mesmerized by
[00:04:07.860 --> 00:04:12.860]   or just enjoying to go through to prove various aspects?
[00:04:13.060 --> 00:04:15.200]   - So Michael Rabin told me this story
[00:04:15.200 --> 00:04:19.480]   about an experience he had when he was a young student
[00:04:19.480 --> 00:04:25.400]   who was tossed out of his classroom for bad behavior
[00:04:25.400 --> 00:04:28.240]   and was wandering through the corridors of his school
[00:04:28.240 --> 00:04:31.800]   and came upon two older students
[00:04:31.800 --> 00:04:35.240]   who were studying the problem
[00:04:35.240 --> 00:04:37.240]   of finding the shortest distance
[00:04:37.240 --> 00:04:40.860]   between two non-overlapping circles.
[00:04:41.680 --> 00:04:45.860]   And Michael thought about it and said,
[00:04:45.860 --> 00:04:52.520]   "You take the straight line between the two centers
[00:04:52.520 --> 00:04:56.240]   "and the segment between the two circles is the shortest
[00:04:56.240 --> 00:04:58.760]   "because a straight line is the shortest distance
[00:04:58.760 --> 00:05:00.760]   "between the two centers.
[00:05:00.760 --> 00:05:03.820]   "And any other line connecting the circles
[00:05:03.820 --> 00:05:07.880]   "would be on a longer line."
[00:05:07.880 --> 00:05:09.920]   And I thought, and he thought,
[00:05:09.920 --> 00:05:13.000]   and I agreed that this was just elegant,
[00:05:13.000 --> 00:05:17.800]   that pure reasoning could come up with such a result.
[00:05:17.800 --> 00:05:21.240]   - Certainly the shortest distance
[00:05:21.240 --> 00:05:24.820]   from the two centers of the circles is a straight line.
[00:05:24.820 --> 00:05:29.920]   Could you once again say what's the next step in that proof?
[00:05:29.920 --> 00:05:34.920]   - Well, any segment joining the two circles,
[00:05:36.840 --> 00:05:41.640]   if you extend it by taking the radius on each side,
[00:05:41.640 --> 00:05:46.640]   you get a path with three edges
[00:05:46.640 --> 00:05:48.560]   which connects the two centers.
[00:05:48.560 --> 00:05:52.720]   And this has to be at least as long as the shortest path,
[00:05:52.720 --> 00:05:53.920]   which is the straight line.
[00:05:53.920 --> 00:05:54.960]   - The straight line, yeah.
[00:05:54.960 --> 00:05:58.680]   Wow, yeah, that's quite simple.
[00:05:58.680 --> 00:06:00.940]   So what is it about that elegance
[00:06:00.940 --> 00:06:04.760]   that you just find compelling?
[00:06:04.760 --> 00:06:09.760]   - Well, just that you could establish a fact
[00:06:09.760 --> 00:06:15.080]   about geometry beyond dispute by pure reasoning.
[00:06:15.080 --> 00:06:20.640]   I also enjoy the challenge
[00:06:20.640 --> 00:06:23.520]   of solving puzzles in plane geometry.
[00:06:23.520 --> 00:06:27.600]   It was much more fun than the earlier mathematics courses
[00:06:27.600 --> 00:06:31.160]   which were mostly about arithmetic operations
[00:06:31.160 --> 00:06:33.000]   and manipulating them.
[00:06:33.000 --> 00:06:36.000]   - Was there something about geometry itself,
[00:06:36.000 --> 00:06:38.280]   the slightly visual component of it,
[00:06:38.280 --> 00:06:40.320]   that you can visualize? - Oh, yes, absolutely.
[00:06:40.320 --> 00:06:44.280]   Although I lacked three-dimensional vision.
[00:06:44.280 --> 00:06:47.440]   I wasn't very good at three-dimensional vision.
[00:06:47.440 --> 00:06:49.840]   - You mean being able to visualize three-dimensional objects?
[00:06:49.840 --> 00:06:54.440]   - Three-dimensional objects or surfaces,
[00:06:54.440 --> 00:06:55.980]   hyperplanes and so on.
[00:06:55.980 --> 00:07:01.880]   So there I didn't have an intuition,
[00:07:01.880 --> 00:07:06.880]   but for example, the fact that the sum of the angles
[00:07:06.880 --> 00:07:12.160]   of a triangle is 180 degrees is proved convincingly,
[00:07:12.160 --> 00:07:19.720]   and it comes as a surprise that that can be done.
[00:07:19.720 --> 00:07:22.960]   - Why is that surprising?
[00:07:22.960 --> 00:07:29.560]   - Well-- - Well, it is a surprising idea,
[00:07:29.560 --> 00:07:30.640]   I suppose.
[00:07:30.640 --> 00:07:32.440]   - Why is that proved difficult?
[00:07:32.440 --> 00:07:33.320]   - It's not.
[00:07:33.320 --> 00:07:34.240]   That's the point.
[00:07:34.240 --> 00:07:36.500]   It's so easy, and yet it's so convincing.
[00:07:36.500 --> 00:07:39.200]   - Do you remember what is the proof
[00:07:39.200 --> 00:07:41.920]   that it adds up to 180?
[00:07:41.920 --> 00:07:48.360]   - You start at a corner and draw a line
[00:07:48.360 --> 00:07:54.640]   parallel to the opposite side,
[00:07:56.200 --> 00:08:00.720]   and that line sort of trisects the angle
[00:08:00.720 --> 00:08:04.360]   between the other two sides,
[00:08:04.360 --> 00:08:10.440]   and you get a half-plane which has to add up
[00:08:10.440 --> 00:08:15.760]   to 180 degrees, and it consists,
[00:08:15.760 --> 00:08:20.760]   and the angles, by the equality of alternate angles,
[00:08:20.760 --> 00:08:22.520]   what's it called?
[00:08:24.180 --> 00:08:27.220]   You get a correspondence between the angles
[00:08:27.220 --> 00:08:31.940]   created along the side of the triangle
[00:08:31.940 --> 00:08:34.700]   and the three angles of the triangle.
[00:08:34.700 --> 00:08:37.780]   - Has geometry had an impact on,
[00:08:37.780 --> 00:08:39.700]   when you look into the future of your work
[00:08:39.700 --> 00:08:41.340]   with combinatorial algorithms,
[00:08:41.340 --> 00:08:45.000]   has it had some kind of impact in terms of,
[00:08:45.000 --> 00:08:48.720]   yeah, being able, the puzzles, the visual aspects
[00:08:48.720 --> 00:08:51.420]   that were first so compelling to you?
[00:08:51.420 --> 00:08:54.500]   - Not Euclidean geometry particularly.
[00:08:54.500 --> 00:08:59.500]   I think I use tools like linear programming
[00:08:59.500 --> 00:09:01.860]   and integer programming a lot,
[00:09:01.860 --> 00:09:08.020]   but those require high-dimensional visualization,
[00:09:08.020 --> 00:09:12.180]   and so I tend to go by the algebraic properties.
[00:09:12.180 --> 00:09:16.660]   - Right, you go by the linear algebra
[00:09:16.660 --> 00:09:19.580]   and not by the visualization.
[00:09:19.580 --> 00:09:23.700]   - Well, the interpretation in terms of, for example,
[00:09:23.700 --> 00:09:26.380]   finding the highest point on a polyhedron,
[00:09:26.380 --> 00:09:31.140]   as in linear programming, is motivating,
[00:09:31.140 --> 00:09:37.580]   but again, I don't have the high-dimensional intuition
[00:09:37.580 --> 00:09:40.140]   that would particularly inform me,
[00:09:40.140 --> 00:09:43.860]   so I sort of lean on the algebra.
[00:09:43.860 --> 00:09:46.120]   - So to linger on that point,
[00:09:46.120 --> 00:09:51.000]   what kind of visualization do you do
[00:09:51.000 --> 00:09:53.280]   when you're trying to think about,
[00:09:53.280 --> 00:09:55.400]   we'll get to combinatorial algorithms,
[00:09:55.400 --> 00:09:57.280]   but just algorithms in general.
[00:09:57.280 --> 00:09:58.120]   - Yeah.
[00:09:58.120 --> 00:10:00.640]   - What's inside your mind when you're thinking
[00:10:00.640 --> 00:10:02.260]   about designing algorithms?
[00:10:02.260 --> 00:10:07.480]   Or even just tackling any mathematical problem?
[00:10:07.480 --> 00:10:12.640]   - Well, I think that usually an algorithm
[00:10:13.840 --> 00:10:18.840]   involves a repetition of some inner loop,
[00:10:18.840 --> 00:10:24.240]   and so I can sort of visualize the distance
[00:10:24.240 --> 00:10:29.680]   from the desired solution as iteratively reducing
[00:10:29.680 --> 00:10:33.360]   until you finally hit the exact solution.
[00:10:33.360 --> 00:10:35.640]   - And try to take steps that get you closer to the--
[00:10:35.640 --> 00:10:38.160]   - Try to take steps that get closer
[00:10:38.160 --> 00:10:41.280]   and having the certainty of converging.
[00:10:41.280 --> 00:10:46.280]   So it's basically the mechanics of the algorithm
[00:10:46.280 --> 00:10:48.080]   is often very simple,
[00:10:48.080 --> 00:10:52.480]   but especially when you're trying something out
[00:10:52.480 --> 00:10:53.320]   on the computer.
[00:10:53.320 --> 00:10:57.080]   So for example, I did some work
[00:10:57.080 --> 00:10:58.960]   on the traveling salesman problem,
[00:10:58.960 --> 00:11:03.040]   and I could see there was a particular function
[00:11:03.040 --> 00:11:04.680]   that had to be minimized,
[00:11:04.680 --> 00:11:08.600]   and it was fascinating to see the successive approaches
[00:11:08.600 --> 00:11:10.180]   to the optimum.
[00:11:11.020 --> 00:11:13.020]   - You mean, so first of all,
[00:11:13.020 --> 00:11:16.340]   traveling salesman problem is where you have to visit
[00:11:16.340 --> 00:11:21.300]   every city without ever, only once.
[00:11:21.300 --> 00:11:22.420]   - Yeah, that's right.
[00:11:22.420 --> 00:11:25.100]   Find the shortest path through a set of cities.
[00:11:25.100 --> 00:11:27.900]   - Yeah, which is sort of a canonical,
[00:11:27.900 --> 00:11:29.540]   a standard, a really nice problem
[00:11:29.540 --> 00:11:31.300]   that's really hard in computer science.
[00:11:31.300 --> 00:11:32.580]   - Exactly, yes.
[00:11:32.580 --> 00:11:34.460]   - So can you say again what was nice
[00:11:34.460 --> 00:11:38.380]   about being able to think about the objective function there
[00:11:38.380 --> 00:11:41.540]   and maximizing it or minimizing it?
[00:11:41.540 --> 00:11:45.220]   - Well, it's just that as the algorithm proceeded,
[00:11:45.220 --> 00:11:49.700]   you were making progress, continual progress,
[00:11:49.700 --> 00:11:53.940]   and eventually getting to the optimum point.
[00:11:53.940 --> 00:11:57.060]   - So there's two parts, maybe.
[00:11:57.060 --> 00:11:58.060]   Maybe you can correct me,
[00:11:58.060 --> 00:12:00.300]   but first is like getting an intuition
[00:12:00.300 --> 00:12:02.860]   about what the solution would look like,
[00:12:02.860 --> 00:12:05.540]   and or even maybe coming up with a solution,
[00:12:05.540 --> 00:12:07.260]   and two is proving that this thing
[00:12:07.260 --> 00:12:09.860]   is actually going to be pretty good.
[00:12:09.860 --> 00:12:13.580]   What part is harder for you?
[00:12:13.580 --> 00:12:14.940]   Where does the magic happen?
[00:12:14.940 --> 00:12:17.740]   Is it in the first sets of intuitions,
[00:12:17.740 --> 00:12:22.100]   or is it in the messy details of actually showing
[00:12:22.100 --> 00:12:25.420]   that it is going to get to the exact solution
[00:12:25.420 --> 00:12:30.420]   and it's gonna run at a certain complexity?
[00:12:32.360 --> 00:12:34.800]   - Well, the magic is just the fact
[00:12:34.800 --> 00:12:39.800]   that the gap from the optimum decreases monotonically,
[00:12:39.800 --> 00:12:44.520]   and you can see it happening,
[00:12:44.520 --> 00:12:48.720]   and various metrics of what's going on
[00:12:48.720 --> 00:12:53.680]   are improving all along until finally you hit the optimum.
[00:12:53.680 --> 00:12:56.200]   Perhaps later we'll talk about the assignment problem,
[00:12:56.200 --> 00:12:58.480]   and I can illustrate.
[00:12:58.480 --> 00:12:59.840]   - Illustrate a little better.
[00:12:59.840 --> 00:13:00.720]   - Yeah.
[00:13:00.720 --> 00:13:03.120]   - Now zooming out again, as you write,
[00:13:03.120 --> 00:13:06.880]   Don Knuth has called attention to a breed of people
[00:13:06.880 --> 00:13:10.520]   who derive great aesthetic pleasure
[00:13:10.520 --> 00:13:13.920]   from contemplating the structure of computational processes.
[00:13:13.920 --> 00:13:16.600]   So Don calls these folks geeks,
[00:13:16.600 --> 00:13:18.600]   and you write that you remember the moment
[00:13:18.600 --> 00:13:20.680]   you realized you were such a person,
[00:13:20.680 --> 00:13:23.120]   you were shown the Hungarian algorithm
[00:13:23.120 --> 00:13:25.720]   to solve the assignment problem.
[00:13:25.720 --> 00:13:29.120]   So perhaps you can explain what the assignment problem is
[00:13:29.120 --> 00:13:32.000]   and what the Hungarian algorithm is.
[00:13:32.000 --> 00:13:35.480]   - So in the assignment problem,
[00:13:35.480 --> 00:13:40.320]   you have n boys and n girls,
[00:13:40.320 --> 00:13:45.320]   and you are given the desirability of,
[00:13:45.320 --> 00:13:50.240]   or the cost of matching the i-th boy
[00:13:50.240 --> 00:13:52.680]   with the j-th girl for all i and j.
[00:13:52.680 --> 00:13:54.600]   You're given a matrix of numbers,
[00:13:55.640 --> 00:14:00.640]   and you want to find the one-to-one matching
[00:14:00.640 --> 00:14:04.320]   of the boys with the girls,
[00:14:04.320 --> 00:14:08.760]   such that the sum of the associated costs will be minimized.
[00:14:08.760 --> 00:14:13.280]   So the best way to match the boys with the girls
[00:14:13.280 --> 00:14:16.480]   or men with jobs or any two sets.
[00:14:16.480 --> 00:14:20.640]   - Now any possible matching is possible?
[00:14:20.640 --> 00:14:21.840]   Or there's constraints?
[00:14:21.840 --> 00:14:26.840]   - All one-to-one correspondences are permissible.
[00:14:26.840 --> 00:14:29.480]   If there is a connection that is not allowed,
[00:14:29.480 --> 00:14:32.120]   then you can think of it as having an infinite cost.
[00:14:32.120 --> 00:14:32.960]   - I see, yeah.
[00:14:32.960 --> 00:14:39.360]   - So what you do is to depend on the observation
[00:14:39.360 --> 00:14:48.320]   that the identity of the optimal assignment,
[00:14:50.360 --> 00:14:53.160]   or as we call it, the optimal permutation,
[00:14:53.160 --> 00:14:58.080]   is not changed if you subtract a constant
[00:14:58.080 --> 00:15:04.920]   from any row or column of the matrix.
[00:15:04.920 --> 00:15:06.680]   You can see that the comparison
[00:15:06.680 --> 00:15:09.720]   between the different assignments is not changed by that.
[00:15:09.720 --> 00:15:15.560]   Because if you decrease a particular row,
[00:15:15.560 --> 00:15:18.720]   all the elements of a row by some constant,
[00:15:18.720 --> 00:15:21.840]   all solutions decrease by the cost of that,
[00:15:21.840 --> 00:15:24.100]   by an amount equal to that constant.
[00:15:24.100 --> 00:15:27.520]   So the idea of the algorithm is to start
[00:15:27.520 --> 00:15:30.280]   with a matrix of non-negative numbers
[00:15:30.280 --> 00:15:36.280]   and keep subtracting from rows or entire columns
[00:15:36.280 --> 00:15:44.800]   in such a way that you subtract the same constant
[00:15:44.800 --> 00:15:47.060]   from all the elements of that row or column,
[00:15:48.440 --> 00:15:50.760]   while maintaining the property
[00:15:50.760 --> 00:15:55.760]   that all the elements are non-negative.
[00:15:55.760 --> 00:15:59.280]   - Simple.
[00:15:59.280 --> 00:16:04.280]   - Yeah, and so what you have to do
[00:16:04.280 --> 00:16:09.680]   is find small moves which will decrease the total cost
[00:16:09.680 --> 00:16:17.560]   while subtracting constants from rows or columns.
[00:16:17.560 --> 00:16:19.480]   And there's a particular way of doing that
[00:16:19.480 --> 00:16:22.200]   by computing the kind of shortest path
[00:16:22.200 --> 00:16:24.000]   through the elements in the matrix.
[00:16:24.000 --> 00:16:28.520]   And you just keep going in this way
[00:16:28.520 --> 00:16:33.240]   until you finally get a full permutation of zeros
[00:16:33.240 --> 00:16:34.920]   while the matrix is non-negative,
[00:16:34.920 --> 00:16:37.440]   and then you know that that has to be the cheapest.
[00:16:37.440 --> 00:16:42.560]   - Is that as simple as it sounds?
[00:16:42.560 --> 00:16:45.560]   So the shortest path through the matrix part?
[00:16:45.560 --> 00:16:48.880]   - Yeah, the simplicity lies in how you find,
[00:16:48.880 --> 00:16:52.240]   I oversimplified slightly,
[00:16:52.240 --> 00:16:56.440]   you will end up subtracting a constant
[00:16:56.440 --> 00:16:59.120]   from some rows or columns
[00:16:59.120 --> 00:17:04.120]   and adding the same constant back to other rows and columns.
[00:17:04.120 --> 00:17:09.200]   So as not to reduce any of the zero elements,
[00:17:09.200 --> 00:17:11.080]   you leave them unchanged.
[00:17:13.000 --> 00:17:18.000]   But each individual step modifies
[00:17:18.000 --> 00:17:24.080]   several rows and columns by the same amount,
[00:17:24.080 --> 00:17:26.600]   but overall decreases the cost.
[00:17:26.600 --> 00:17:29.800]   - So there's something about that elegance
[00:17:29.800 --> 00:17:32.240]   that made you go, "Aha, this is a beautiful,"
[00:17:32.240 --> 00:17:35.680]   like it's amazing that something like this,
[00:17:35.680 --> 00:17:38.080]   something so simple can solve a problem like this.
[00:17:38.080 --> 00:17:39.760]   - Yeah, it's really cool.
[00:17:39.760 --> 00:17:42.320]   If I had mechanical ability,
[00:17:42.320 --> 00:17:44.800]   I would probably like to do woodworking
[00:17:44.800 --> 00:17:49.080]   or other activities where you sort of shape something
[00:17:49.080 --> 00:17:55.480]   into something beautiful and orderly.
[00:17:55.480 --> 00:17:58.360]   And there's something about the orderly,
[00:17:58.360 --> 00:18:03.360]   systematic nature of that iterative algorithm
[00:18:03.360 --> 00:18:05.560]   that is pleasing to me.
[00:18:05.560 --> 00:18:09.000]   - So what do you think about this idea of geeks,
[00:18:09.000 --> 00:18:10.520]   as Don Knuth calls them?
[00:18:11.360 --> 00:18:15.560]   What do you think, is it something specific
[00:18:15.560 --> 00:18:19.880]   to a mindset that allows you to discover the elegance
[00:18:19.880 --> 00:18:23.160]   in computational processes, or is this all of us?
[00:18:23.160 --> 00:18:25.280]   Can all of us discover this beauty?
[00:18:25.280 --> 00:18:28.480]   Were you born this way? (laughs)
[00:18:28.480 --> 00:18:30.920]   - I think so, I always like to play with numbers.
[00:18:30.920 --> 00:18:35.640]   I used to amuse myself
[00:18:35.640 --> 00:18:39.360]   by multiplying four-digit decimal numbers in my head.
[00:18:40.280 --> 00:18:44.400]   And putting myself to sleep by starting with one
[00:18:44.400 --> 00:18:48.200]   and doubling the number as long as I could go.
[00:18:48.200 --> 00:18:50.060]   And testing my memory,
[00:18:50.060 --> 00:18:52.680]   my ability to retain the information.
[00:18:52.680 --> 00:18:55.880]   - And I also read somewhere that you wrote
[00:18:55.880 --> 00:18:59.840]   that you enjoyed showing off to your friends
[00:18:59.840 --> 00:19:03.320]   by, I believe, multiplying four-digit numbers.
[00:19:03.320 --> 00:19:05.400]   - Right.
[00:19:05.400 --> 00:19:07.040]   - A couple of four-digit numbers.
[00:19:07.040 --> 00:19:10.760]   - Yeah, I had a summer job at a beach resort
[00:19:10.760 --> 00:19:12.680]   outside of Boston.
[00:19:12.680 --> 00:19:16.760]   And the other employee,
[00:19:16.760 --> 00:19:20.200]   I was the barker at a skee-ball game.
[00:19:20.200 --> 00:19:21.040]   - Yeah.
[00:19:21.040 --> 00:19:25.680]   - I used to sit at a microphone saying,
[00:19:25.680 --> 00:19:28.160]   "Come one, come all, come in and play skee-ball.
[00:19:28.160 --> 00:19:31.080]   "Five cents to play, a nickel to win," and so on.
[00:19:31.080 --> 00:19:33.860]   - That's what a barker, I wasn't sure if I should know,
[00:19:33.860 --> 00:19:38.860]   but barker, you're the charming, outgoing person
[00:19:38.860 --> 00:19:41.240]   that's getting people to come in.
[00:19:41.240 --> 00:19:43.600]   - Yeah, well, I wasn't particularly charming,
[00:19:43.600 --> 00:19:46.180]   but I could be very repetitious and loud.
[00:19:46.180 --> 00:19:52.140]   And the other employees were sort of juvenile delinquents
[00:19:52.140 --> 00:19:57.360]   who had no academic bent,
[00:19:57.360 --> 00:20:00.520]   but somehow I found that I could impress them
[00:20:00.520 --> 00:20:05.520]   by performing this mental arithmetic.
[00:20:05.520 --> 00:20:08.340]   - Yeah, there's something to that.
[00:20:08.340 --> 00:20:14.580]   Some of the most popular videos on the internet is,
[00:20:14.580 --> 00:20:18.000]   there's a YouTube channel called Numberphile
[00:20:18.000 --> 00:20:20.440]   that shows off different mathematical ideas.
[00:20:20.440 --> 00:20:21.280]   - I see.
[00:20:21.280 --> 00:20:23.360]   - There's still something really profoundly interesting
[00:20:23.360 --> 00:20:27.160]   to people about math, the beauty of it.
[00:20:27.160 --> 00:20:30.400]   Something, even if they don't understand
[00:20:30.400 --> 00:20:33.640]   the basic concept even being discussed,
[00:20:33.640 --> 00:20:35.040]   there's something compelling to it.
[00:20:35.040 --> 00:20:36.400]   What do you think that is?
[00:20:36.400 --> 00:20:40.540]   Any lessons you drew from your early teen years
[00:20:40.540 --> 00:20:45.540]   when you were showing off to your friends with the numbers?
[00:20:45.540 --> 00:20:47.640]   What is it that attracts us
[00:20:47.640 --> 00:20:50.480]   to the beauty of mathematics, do you think?
[00:20:50.480 --> 00:20:54.560]   The general population, not just the computer scientists
[00:20:54.560 --> 00:20:56.560]   and mathematicians.
[00:20:56.560 --> 00:20:59.600]   - I think that you can do amazing things.
[00:20:59.600 --> 00:21:03.300]   You can test whether large numbers are prime.
[00:21:03.300 --> 00:21:09.440]   You can solve little puzzles
[00:21:09.440 --> 00:21:12.340]   about cannibals and missionaries.
[00:21:12.340 --> 00:21:13.180]   (laughing)
[00:21:13.180 --> 00:21:14.000]   - Yeah.
[00:21:14.000 --> 00:21:19.000]   - And there's a kind of achievement, it's puzzle solving.
[00:21:19.000 --> 00:21:22.720]   And at a higher level, the fact that you can do
[00:21:22.720 --> 00:21:24.600]   this reasoning, that you can prove
[00:21:24.600 --> 00:21:29.000]   in an absolutely ironclad way that some of the angles
[00:21:29.000 --> 00:21:31.540]   of a triangle is 180 degrees.
[00:21:31.540 --> 00:21:35.320]   - Yeah, it's a nice escape from the messiness
[00:21:35.320 --> 00:21:38.120]   of the real world where nothing can be proved.
[00:21:38.120 --> 00:21:41.360]   So, and we'll talk about it, but sometimes the ability
[00:21:41.360 --> 00:21:43.560]   to map the real world into such problems
[00:21:43.560 --> 00:21:47.120]   where you can't prove it is a powerful step.
[00:21:47.120 --> 00:21:47.960]   - Yeah.
[00:21:47.960 --> 00:21:48.780]   - It's amazing that we can do it.
[00:21:48.780 --> 00:21:50.080]   - Of course, another attribute of geeks
[00:21:50.160 --> 00:21:53.640]   is they're not necessarily endowed
[00:21:53.640 --> 00:21:55.480]   with emotional intelligence.
[00:21:55.480 --> 00:21:59.240]   And so they can live in a world of abstractions
[00:21:59.240 --> 00:22:03.280]   without having to master the complexities
[00:22:03.280 --> 00:22:05.160]   of dealing with people.
[00:22:05.160 --> 00:22:09.440]   - So just to link on the historical note,
[00:22:09.440 --> 00:22:12.120]   as a PhD student in 1955, you joined
[00:22:12.120 --> 00:22:14.280]   the computational lab at Harvard
[00:22:14.280 --> 00:22:17.040]   where Howard Aiken had built the Mark I
[00:22:17.040 --> 00:22:18.540]   and the Mark IV computers.
[00:22:19.760 --> 00:22:22.000]   Just to take a step back into that history,
[00:22:22.000 --> 00:22:23.880]   what were those computers like?
[00:22:23.880 --> 00:22:30.300]   - The Mark IV filled a large room,
[00:22:30.300 --> 00:22:33.660]   much bigger than this large office
[00:22:33.660 --> 00:22:36.840]   that we're talking in now.
[00:22:36.840 --> 00:22:39.080]   And you could walk around inside it.
[00:22:39.080 --> 00:22:43.300]   There were rows of relays.
[00:22:43.300 --> 00:22:45.360]   You could just walk around the interior
[00:22:45.360 --> 00:22:50.360]   and the machine would sometimes fail
[00:22:50.360 --> 00:22:55.120]   because of bugs, which literally meant
[00:22:55.120 --> 00:22:57.960]   flying creatures landing on the switches.
[00:22:57.960 --> 00:23:04.840]   So I never used that machine for any practical purpose.
[00:23:04.840 --> 00:23:09.360]   The lab eventually acquired
[00:23:09.360 --> 00:23:14.640]   one of the earlier commercial computers.
[00:23:14.640 --> 00:23:16.680]   - This is already in the '60s.
[00:23:16.680 --> 00:23:17.880]   - No, in the mid '50s.
[00:23:17.880 --> 00:23:18.720]   - The mid '50s?
[00:23:18.720 --> 00:23:19.840]   - Or the late '50s.
[00:23:19.840 --> 00:23:21.800]   - There was already commercial computers in the--
[00:23:21.800 --> 00:23:26.240]   - Yeah, we had a UNIVAC with 2,000 words of storage.
[00:23:26.240 --> 00:23:30.220]   And so you had to work hard to allocate
[00:23:30.220 --> 00:23:34.920]   the memory properly to also the excess time
[00:23:34.920 --> 00:23:38.520]   from one word to another depended on the number
[00:23:38.520 --> 00:23:41.240]   of the particular words.
[00:23:41.240 --> 00:23:44.880]   And so there was an art to sort of arranging
[00:23:44.880 --> 00:23:49.880]   the storage allocation to make fetching data rapid.
[00:23:49.880 --> 00:23:55.000]   - Were you attracted to this actual physical world
[00:23:55.000 --> 00:23:58.180]   implementation of mathematics?
[00:23:58.180 --> 00:24:00.480]   So it's a mathematical machine that's actually
[00:24:00.480 --> 00:24:03.160]   doing the math physically for you?
[00:24:03.160 --> 00:24:04.840]   - No, not at all.
[00:24:04.840 --> 00:24:09.440]   I think I was attracted to the underlying algorithms.
[00:24:10.920 --> 00:24:12.880]   - But did you draw any inspiration?
[00:24:12.880 --> 00:24:15.280]   So could you have imagined,
[00:24:15.280 --> 00:24:18.080]   like what did you imagine was the future
[00:24:18.080 --> 00:24:20.120]   of these giant computers?
[00:24:20.120 --> 00:24:22.040]   Could you have imagined that 60 years later
[00:24:22.040 --> 00:24:25.800]   we'd have billions of these computers all over the world?
[00:24:25.800 --> 00:24:27.220]   - I couldn't imagine that,
[00:24:27.220 --> 00:24:32.840]   but there was a sense in the laboratory
[00:24:32.840 --> 00:24:36.120]   that this was the wave of the future.
[00:24:36.120 --> 00:24:38.480]   In fact, my mother influenced me.
[00:24:38.480 --> 00:24:42.280]   She told me that data processing was gonna be really big
[00:24:42.280 --> 00:24:43.580]   and I should get into it.
[00:24:43.580 --> 00:24:47.240]   - She's a smart woman.
[00:24:47.240 --> 00:24:49.040]   - Yeah, she was a smart woman.
[00:24:49.040 --> 00:24:53.040]   And there was just a feeling that this was going
[00:24:53.040 --> 00:24:55.640]   to change the world, but I didn't think of it
[00:24:55.640 --> 00:24:57.120]   in terms of personal computing.
[00:24:57.120 --> 00:25:02.120]   I had no anticipation that we would be walking around
[00:25:02.120 --> 00:25:06.080]   with computers in our pockets or anything like that.
[00:25:06.080 --> 00:25:11.000]   - Did you see computers as tools,
[00:25:11.000 --> 00:25:13.840]   as mathematical mechanisms to analyze
[00:25:13.840 --> 00:25:16.560]   sort of theoretical computer science,
[00:25:16.560 --> 00:25:21.020]   or as the AI folks, which is an entire other community
[00:25:21.020 --> 00:25:24.480]   of dreamers, as something that could one day
[00:25:24.480 --> 00:25:26.840]   have human level intelligence?
[00:25:26.840 --> 00:25:29.560]   - Well, AI wasn't very much on my radar.
[00:25:29.560 --> 00:25:32.960]   I did read Turing's paper about the
[00:25:33.960 --> 00:25:38.120]   - The Turing test, computing and intelligence?
[00:25:38.120 --> 00:25:39.540]   - Yeah, the Turing test.
[00:25:39.540 --> 00:25:41.880]   - What'd you think about that paper?
[00:25:41.880 --> 00:25:43.780]   Was that just like science fiction?
[00:25:43.780 --> 00:25:48.320]   - I thought that it wasn't a very good test
[00:25:48.320 --> 00:25:50.480]   because it was too subjective.
[00:25:50.480 --> 00:25:55.320]   So I didn't feel that the Turing test
[00:25:55.320 --> 00:25:58.440]   was really the right way to calibrate
[00:25:58.440 --> 00:26:01.040]   how intelligent an algorithm could be.
[00:26:01.040 --> 00:26:03.220]   - But to linger on that, do you think it's part,
[00:26:03.220 --> 00:26:06.440]   because you've come up with some incredible tests
[00:26:06.440 --> 00:26:09.400]   later on, tests on algorithms, right?
[00:26:09.400 --> 00:26:13.360]   That are strong, reliable, robust
[00:26:13.360 --> 00:26:16.520]   across a bunch of different classes of algorithms.
[00:26:16.520 --> 00:26:21.240]   But returning to this emotional mess that is intelligence,
[00:26:21.240 --> 00:26:24.560]   do you think it's possible to come up with a test
[00:26:24.560 --> 00:26:28.360]   that's as ironclad as some of the
[00:26:28.360 --> 00:26:30.320]   computational complexity work?
[00:26:31.240 --> 00:26:32.800]   - Well, I think the greater question
[00:26:32.800 --> 00:26:35.160]   is whether it's possible to achieve
[00:26:35.160 --> 00:26:38.720]   human level intelligence.
[00:26:38.720 --> 00:26:40.120]   - Right, so that's, so first of all,
[00:26:40.120 --> 00:26:42.080]   let me, at the philosophical level,
[00:26:42.080 --> 00:26:46.320]   do you think it's possible to create algorithms
[00:26:46.320 --> 00:26:51.320]   that reason and would seem to us
[00:26:51.320 --> 00:26:54.080]   to have the same kind of intelligence as human beings?
[00:26:54.080 --> 00:26:56.660]   - It's an open question.
[00:26:58.140 --> 00:27:03.140]   It seems to me that most of the achievements
[00:27:03.140 --> 00:27:09.060]   have operate within a very limited set of ground rules
[00:27:09.060 --> 00:27:15.360]   and for a very limited, precise task,
[00:27:15.360 --> 00:27:17.560]   which is a quite different situation
[00:27:17.560 --> 00:27:22.300]   from the processes that go on in the minds of humans,
[00:27:22.300 --> 00:27:25.020]   which, where they have to sort of function
[00:27:25.020 --> 00:27:27.740]   in changing environments.
[00:27:27.740 --> 00:27:32.220]   They have emotions, they have physical attributes
[00:27:32.220 --> 00:27:38.980]   for exploring their environment.
[00:27:38.980 --> 00:27:44.620]   They have intuition, they have desires, emotions.
[00:27:44.620 --> 00:27:52.100]   And I don't see anything in the current achievements
[00:27:52.100 --> 00:27:56.940]   of what's called AI that come close to that capability.
[00:27:56.940 --> 00:28:01.940]   I don't think there's any computer program
[00:28:01.940 --> 00:28:05.740]   which surpasses a six-month-old child
[00:28:05.740 --> 00:28:09.040]   in terms of comprehension of the world.
[00:28:09.040 --> 00:28:15.580]   - Do you think this complexity of human intelligence,
[00:28:15.580 --> 00:28:18.180]   all the cognitive abilities we have, all the emotion,
[00:28:18.180 --> 00:28:21.380]   do you think that could be reduced one day
[00:28:21.380 --> 00:28:23.940]   or just fundamentally, can it be reduced
[00:28:23.940 --> 00:28:26.580]   to a set of algorithms or an algorithm?
[00:28:27.260 --> 00:28:31.880]   So can a Turing machine achieve human-level intelligence?
[00:28:31.880 --> 00:28:35.940]   - I am doubtful about that.
[00:28:35.940 --> 00:28:38.620]   I guess the argument in favor of it
[00:28:38.620 --> 00:28:43.620]   is that the human brain seems to achieve
[00:28:43.620 --> 00:28:47.940]   what we call intelligence,
[00:28:47.940 --> 00:28:50.760]   cognitive abilities of different kinds.
[00:28:50.760 --> 00:28:54.300]   And if you buy the premise that the human brain
[00:28:54.300 --> 00:28:58.620]   is just an enormous interconnected set of switches,
[00:28:58.620 --> 00:29:02.220]   so to speak, then in principle,
[00:29:02.220 --> 00:29:04.460]   you should be able to diagnose
[00:29:04.460 --> 00:29:07.420]   what that interconnection structure is like,
[00:29:07.420 --> 00:29:09.380]   characterize the individual switches,
[00:29:09.380 --> 00:29:12.920]   and build a simulation outside.
[00:29:12.920 --> 00:29:17.660]   But while that may be true in principle,
[00:29:17.660 --> 00:29:19.900]   that cannot be the way we're eventually
[00:29:19.900 --> 00:29:21.660]   gonna tackle this problem.
[00:29:21.660 --> 00:29:26.660]   That's, you know, that does not seem
[00:29:26.660 --> 00:29:29.360]   like a feasible way to go about it.
[00:29:29.360 --> 00:29:32.460]   So there is, however, an existence proof that
[00:29:32.460 --> 00:29:40.380]   if you believe that the brain is just a network
[00:29:40.380 --> 00:29:44.280]   of neurons operating by rules,
[00:29:44.280 --> 00:29:46.660]   I guess you could say that that's an existence proof
[00:29:46.660 --> 00:29:48.000]   of the ability to build,
[00:29:49.220 --> 00:29:51.240]   the capabilities of a mechanism.
[00:29:51.240 --> 00:29:55.100]   But it would be almost impossible
[00:29:55.100 --> 00:29:57.300]   to acquire the information
[00:29:57.300 --> 00:30:00.500]   unless we got enough insight
[00:30:00.500 --> 00:30:02.780]   into the operation of the brain.
[00:30:02.780 --> 00:30:04.300]   - But there's so much mystery there.
[00:30:04.300 --> 00:30:06.700]   Do you think, what do you make of consciousness,
[00:30:06.700 --> 00:30:08.220]   for example?
[00:30:08.220 --> 00:30:10.660]   There's something, as an example,
[00:30:10.660 --> 00:30:13.180]   something we completely have no clue about,
[00:30:13.180 --> 00:30:15.380]   the fact that we have this subjective experience.
[00:30:15.380 --> 00:30:16.220]   - Right.
[00:30:16.220 --> 00:30:19.820]   - Is it possible that this network of,
[00:30:19.820 --> 00:30:22.940]   this circuit of switches is able to create
[00:30:22.940 --> 00:30:24.980]   something like consciousness?
[00:30:24.980 --> 00:30:26.860]   - To know its own identity.
[00:30:26.860 --> 00:30:30.300]   - Yeah, to know the algorithm, to know itself.
[00:30:30.300 --> 00:30:32.140]   - To know itself.
[00:30:32.140 --> 00:30:35.380]   I think if you try to define that rigorously,
[00:30:35.380 --> 00:30:36.660]   you'd have a lot of trouble.
[00:30:36.660 --> 00:30:37.780]   - Yeah, that seems to.
[00:30:37.780 --> 00:30:44.100]   - So I know that there are many who
[00:30:45.100 --> 00:30:50.100]   believe that general intelligence can be achieved,
[00:30:50.100 --> 00:30:55.780]   and there are even some who feel certain
[00:30:55.780 --> 00:30:59.180]   that the singularity will come
[00:30:59.180 --> 00:31:01.740]   and we will be surpassed by the machines,
[00:31:01.740 --> 00:31:04.380]   which will then learn more and more about themselves
[00:31:04.380 --> 00:31:08.640]   and reduce humans to an inferior breed.
[00:31:08.640 --> 00:31:11.540]   I am doubtful that this will ever be achieved.
[00:31:12.700 --> 00:31:14.000]   - Just for the fun of it,
[00:31:14.000 --> 00:31:18.020]   could you linger on what's your intuition,
[00:31:18.020 --> 00:31:19.060]   why you're doubtful?
[00:31:19.060 --> 00:31:20.900]   So there are quite a few people
[00:31:20.900 --> 00:31:25.220]   that are extremely worried about this existential threat
[00:31:25.220 --> 00:31:29.220]   of artificial intelligence, of us being left behind
[00:31:29.220 --> 00:31:32.340]   by the super intelligent new species.
[00:31:32.340 --> 00:31:36.900]   What's your intuition why that's not quite likely?
[00:31:36.900 --> 00:31:41.420]   - Just because none of the achievements
[00:31:41.420 --> 00:31:46.420]   in speech or robotics or natural language processing
[00:31:46.420 --> 00:31:52.660]   or creation of flexible computer assistants
[00:31:52.660 --> 00:31:56.460]   or any of that comes anywhere near close
[00:31:56.460 --> 00:32:00.300]   to that level of cognition.
[00:32:00.300 --> 00:32:02.300]   - What do you think about ideas of sort of,
[00:32:02.300 --> 00:32:05.300]   if we look at Moore's law, an exponential improvement
[00:32:05.300 --> 00:32:09.300]   to allow us, that would surprise us?
[00:32:09.300 --> 00:32:11.180]   Sort of our intuition fall apart
[00:32:11.180 --> 00:32:14.340]   with exponential improvement because,
[00:32:14.340 --> 00:32:16.060]   I mean, we're not able to kind of,
[00:32:16.060 --> 00:32:18.020]   we kind of think in linear improvement.
[00:32:18.020 --> 00:32:18.860]   - Yeah.
[00:32:18.860 --> 00:32:20.220]   - We're not able to imagine a world
[00:32:20.220 --> 00:32:25.220]   that goes from the Mark I computer to an iPhone 10.
[00:32:25.220 --> 00:32:27.540]   - Yeah.
[00:32:27.540 --> 00:32:31.260]   - So do you think we could be really surprised
[00:32:31.260 --> 00:32:33.420]   by the exponential growth?
[00:32:33.420 --> 00:32:37.540]   Or on the flip side, is it possible
[00:32:37.540 --> 00:32:42.220]   that also intelligence is actually way, way, way, way harder
[00:32:42.220 --> 00:32:47.100]   even with exponential improvement to be able to crack?
[00:32:47.100 --> 00:32:50.260]   - I don't think any constant factor improvement
[00:32:50.260 --> 00:32:53.980]   could change things.
[00:32:53.980 --> 00:32:57.500]   I mean, given our current comprehension
[00:32:57.500 --> 00:33:04.900]   of what cognition requires,
[00:33:04.900 --> 00:33:08.740]   it seems to me that multiplying the speed of the switches
[00:33:08.740 --> 00:33:10.940]   by a factor of a thousand or a million
[00:33:10.940 --> 00:33:16.580]   will not be useful until we really understand
[00:33:16.580 --> 00:33:21.260]   the organizational principle behind the network of switches.
[00:33:21.260 --> 00:33:25.420]   - Well, let's jump into the network of switches
[00:33:25.420 --> 00:33:28.020]   and talk about combinatorial algorithms if we could.
[00:33:28.020 --> 00:33:31.660]   Let's step back for the very basics.
[00:33:31.660 --> 00:33:33.660]   What are combinatorial algorithms?
[00:33:33.660 --> 00:33:35.060]   And what are some major examples
[00:33:35.060 --> 00:33:36.980]   of problems they aim to solve?
[00:33:36.980 --> 00:33:43.140]   - A combinatorial algorithm is one which deals
[00:33:43.140 --> 00:33:48.380]   with a system of discrete objects
[00:33:48.380 --> 00:33:52.340]   that can occupy various states
[00:33:52.340 --> 00:33:57.340]   or take on various values from a discrete set of values
[00:33:59.740 --> 00:34:04.740]   and need to be arranged or selected in such a way
[00:34:04.740 --> 00:34:12.260]   as to achieve some, to minimize some cost function
[00:34:12.260 --> 00:34:16.260]   or to prove the existence
[00:34:16.260 --> 00:34:19.980]   of some combinatorial configuration.
[00:34:19.980 --> 00:34:24.980]   So an example would be coloring the vertices of a graph.
[00:34:24.980 --> 00:34:25.980]   - What's a graph?
[00:34:25.980 --> 00:34:28.140]   Let's step back.
[00:34:28.140 --> 00:34:33.140]   So what, it's fun to ask one of the greatest
[00:34:33.140 --> 00:34:36.140]   computer scientists of all time
[00:34:36.140 --> 00:34:39.260]   the most basic questions in the beginning of most books.
[00:34:39.260 --> 00:34:41.380]   But for people who might not know,
[00:34:41.380 --> 00:34:44.460]   but in general how you think about it, what is a graph?
[00:34:44.460 --> 00:34:47.220]   - A graph, that's simple.
[00:34:47.220 --> 00:34:51.180]   It's a set of points, certain pairs of which
[00:34:51.180 --> 00:34:54.080]   are joined by lines called edges.
[00:34:55.060 --> 00:34:57.820]   And they sort of represent the,
[00:34:57.820 --> 00:35:02.300]   in different applications represent the interconnections
[00:35:02.300 --> 00:35:05.860]   between discrete objects.
[00:35:05.860 --> 00:35:07.700]   So they could be the interactions,
[00:35:07.700 --> 00:35:12.460]   interconnections between switches in a digital circuit
[00:35:12.460 --> 00:35:16.380]   or interconnections indicating the communication patterns
[00:35:16.380 --> 00:35:17.940]   of a human community.
[00:35:17.940 --> 00:35:21.420]   - And they could be directed or undirected.
[00:35:21.420 --> 00:35:23.180]   And then as you've mentioned before,
[00:35:23.180 --> 00:35:25.580]   you might have costs.
[00:35:25.580 --> 00:35:27.980]   - Right, they can be directed or undirected.
[00:35:27.980 --> 00:35:30.660]   They can be, you can think of them as,
[00:35:30.660 --> 00:35:34.300]   if you think if a graph were representing
[00:35:34.300 --> 00:35:36.660]   a communication network,
[00:35:36.660 --> 00:35:38.740]   then the edge could be undirected,
[00:35:38.740 --> 00:35:41.820]   meaning that information could flow along it
[00:35:41.820 --> 00:35:44.580]   in both directions, or it could be directed
[00:35:44.580 --> 00:35:47.020]   with only one way communication.
[00:35:47.020 --> 00:35:49.780]   A road system is another example of a graph
[00:35:49.780 --> 00:35:52.260]   with weights on the edges.
[00:35:52.260 --> 00:35:57.260]   And then a lot of problems of optimizing
[00:35:57.260 --> 00:36:02.780]   the efficiency of such networks or learning about
[00:36:02.780 --> 00:36:05.860]   the performance of such networks
[00:36:05.860 --> 00:36:11.340]   are the object of combinatorial algorithms.
[00:36:11.340 --> 00:36:15.580]   So it could be scheduling classes at a school
[00:36:15.580 --> 00:36:20.580]   where the vertices, the nodes of the network
[00:36:20.780 --> 00:36:25.780]   are the individual classes and the edges indicate
[00:36:25.780 --> 00:36:30.660]   the constraints which say that certain classes
[00:36:30.660 --> 00:36:32.940]   cannot take place at the same time,
[00:36:32.940 --> 00:36:35.740]   or certain teachers are available only
[00:36:35.740 --> 00:36:38.460]   for certain classes, et cetera.
[00:36:38.460 --> 00:36:43.140]   Or I talked earlier about the assignment problem
[00:36:43.140 --> 00:36:45.180]   of matching the boys with the girls,
[00:36:47.940 --> 00:36:52.220]   where you have a, there a graph with an edge
[00:36:52.220 --> 00:36:54.020]   from each boy to each girl
[00:36:54.020 --> 00:36:58.060]   with a weight indicating the cost.
[00:36:58.060 --> 00:37:02.900]   Or in logical design of computers,
[00:37:02.900 --> 00:37:07.900]   you might want to find a set of so-called gates,
[00:37:07.900 --> 00:37:11.940]   switches that perform logical functions,
[00:37:11.940 --> 00:37:15.140]   which can be interconnected to realize some function.
[00:37:15.140 --> 00:37:20.140]   So you might ask how many gates do you need
[00:37:20.140 --> 00:37:27.020]   in order to, for a circuit to give a yes output
[00:37:27.020 --> 00:37:37.780]   if at least a given number of its inputs are ones
[00:37:37.780 --> 00:37:42.780]   and no if fewer are present.
[00:37:42.980 --> 00:37:46.620]   - My favorite is probably all the work with network flows.
[00:37:46.620 --> 00:37:50.780]   So anytime you have, I don't know why it's so compelling,
[00:37:50.780 --> 00:37:52.420]   but there's something just beautiful about it.
[00:37:52.420 --> 00:37:54.340]   It seems like there's so many applications
[00:37:54.340 --> 00:37:59.340]   and communication networks and traffic flow
[00:37:59.340 --> 00:38:02.580]   that you can map into these.
[00:38:02.580 --> 00:38:04.620]   And then you can think of pipes and water
[00:38:04.620 --> 00:38:06.580]   going through pipes and you can optimize it
[00:38:06.580 --> 00:38:07.420]   in different ways.
[00:38:07.420 --> 00:38:09.540]   There's something always visually
[00:38:09.540 --> 00:38:12.340]   and intellectually compelling to me about it.
[00:38:12.340 --> 00:38:14.660]   And of course you've done work there.
[00:38:14.660 --> 00:38:20.580]   - Yeah, so there the edges represent channels
[00:38:20.580 --> 00:38:24.540]   along which some commodity can flow.
[00:38:24.540 --> 00:38:28.080]   It might be gas, it might be water,
[00:38:28.080 --> 00:38:29.900]   it might be information.
[00:38:29.900 --> 00:38:33.860]   - Maybe supply chain as well, like products being--
[00:38:33.860 --> 00:38:36.740]   - Products flowing from one operation to another.
[00:38:36.740 --> 00:38:37.700]   - Yeah.
[00:38:37.700 --> 00:38:40.280]   - And the edges have a capacity,
[00:38:40.280 --> 00:38:43.700]   which is the rate at which the commodity can flow.
[00:38:43.700 --> 00:38:48.700]   And a central problem is to determine,
[00:38:48.700 --> 00:38:51.660]   given a network of these channels,
[00:38:51.660 --> 00:38:54.560]   in this case, the edges are communication channels.
[00:38:54.560 --> 00:39:01.300]   The challenge is to find the maximum rate
[00:39:01.300 --> 00:39:05.540]   at which the information can flow along these channels
[00:39:05.540 --> 00:39:09.180]   to get from a source to a destination.
[00:39:09.180 --> 00:39:12.700]   And that's a fundamental combinatorial problem
[00:39:12.700 --> 00:39:14.240]   that I've worked on.
[00:39:14.240 --> 00:39:19.100]   Jointly with the scientist, Jack Edmonds,
[00:39:19.100 --> 00:39:22.460]   we, I think we're the first to give a formal proof
[00:39:22.460 --> 00:39:27.460]   that this maximum flow problem through a network
[00:39:27.460 --> 00:39:30.740]   can be solved in polynomial time.
[00:39:30.740 --> 00:39:33.940]   - Which I remember the first time I learned that,
[00:39:33.940 --> 00:39:38.940]   just learning that in maybe even grad school,
[00:39:39.780 --> 00:39:42.080]   I don't think it was even undergrad, no.
[00:39:42.080 --> 00:39:43.400]   Algorithm, yeah.
[00:39:43.400 --> 00:39:48.400]   Do network flows get taught in basic algorithms courses?
[00:39:48.400 --> 00:39:51.140]   - Yes, probably.
[00:39:51.140 --> 00:39:53.780]   - Okay, so yeah, I remember being very surprised
[00:39:53.780 --> 00:39:56.580]   that max flow is a polynomial time algorithm.
[00:39:56.580 --> 00:39:57.420]   - Yeah.
[00:39:57.420 --> 00:40:00.140]   - That there's a nice, fast algorithm that solves max flow.
[00:40:00.140 --> 00:40:05.140]   But, so there is an algorithm named after you in Edmonds.
[00:40:05.140 --> 00:40:08.380]   The Edmond-Karp algorithm for max flow.
[00:40:08.380 --> 00:40:12.580]   So what was it like tackling that problem
[00:40:12.580 --> 00:40:15.700]   and trying to arrive at a polynomial time solution?
[00:40:15.700 --> 00:40:17.180]   And maybe you can describe the algorithm,
[00:40:17.180 --> 00:40:19.900]   maybe you can describe what's the running time complexity
[00:40:19.900 --> 00:40:20.740]   that you showed.
[00:40:20.740 --> 00:40:23.340]   - Yeah, well, first of all,
[00:40:23.340 --> 00:40:25.380]   what is a polynomial time algorithm?
[00:40:25.380 --> 00:40:26.220]   - Yeah.
[00:40:26.220 --> 00:40:28.580]   - Perhaps we could discuss that.
[00:40:28.580 --> 00:40:31.300]   - So yeah, let's actually just even, yeah.
[00:40:31.300 --> 00:40:34.180]   That's what is algorithmic complexity?
[00:40:34.180 --> 00:40:38.220]   What are the major classes of algorithm complexity?
[00:40:38.220 --> 00:40:41.860]   So we, in a problem like the assignment problem
[00:40:41.860 --> 00:40:46.860]   or scheduling schools or any of these applications,
[00:40:46.860 --> 00:40:51.460]   you have a set of input data,
[00:40:51.460 --> 00:40:57.380]   which might, for example, be a set of vertices
[00:40:57.380 --> 00:41:01.900]   connected by edges with,
[00:41:01.900 --> 00:41:06.400]   you're given for each edge, the capacity of the edge.
[00:41:07.340 --> 00:41:10.980]   And you have algorithms,
[00:41:10.980 --> 00:41:14.740]   which are, think of them as computer programs
[00:41:14.740 --> 00:41:18.540]   with operations such as addition, subtraction,
[00:41:18.540 --> 00:41:22.000]   multiplication, division, comparison of numbers and so on.
[00:41:22.000 --> 00:41:26.940]   And you're trying to construct an algorithm
[00:41:26.940 --> 00:41:32.560]   based on those operations,
[00:41:32.560 --> 00:41:35.020]   which will determine in a minimum number
[00:41:35.020 --> 00:41:38.440]   of computational steps, the answer to the problem.
[00:41:38.440 --> 00:41:41.060]   In this case, the computational step
[00:41:41.060 --> 00:41:43.340]   is one of those operations.
[00:41:43.340 --> 00:41:46.140]   And the answer to the problem is, let's say,
[00:41:46.140 --> 00:41:50.360]   the configuration of the network
[00:41:50.360 --> 00:41:52.460]   that carries the maximum amount of flow.
[00:41:52.460 --> 00:41:58.300]   And an algorithm is said to run in polynomial time
[00:41:58.300 --> 00:42:04.900]   if as a function of the size of the input,
[00:42:04.980 --> 00:42:07.900]   the number of vertices, the number of edges and so on.
[00:42:07.900 --> 00:42:12.020]   The number of basic computational steps
[00:42:12.020 --> 00:42:15.200]   grows only as some fixed power of that size.
[00:42:15.200 --> 00:42:21.900]   A linear algorithm would execute a number of steps
[00:42:21.900 --> 00:42:24.700]   linearly proportional to the size.
[00:42:24.700 --> 00:42:27.740]   Quadratic algorithm would be steps proportional
[00:42:27.740 --> 00:42:29.680]   to the square of the size and so on.
[00:42:29.680 --> 00:42:34.680]   And algorithms whose running time is bounded
[00:42:34.680 --> 00:42:37.260]   by some fixed power of the size
[00:42:37.260 --> 00:42:39.900]   are called polynomial algorithms.
[00:42:39.900 --> 00:42:42.140]   - And that's supposed to be
[00:42:42.140 --> 00:42:44.820]   relatively fast class of algorithms.
[00:42:44.820 --> 00:42:45.740]   - That's right.
[00:42:45.740 --> 00:42:49.500]   Theoreticians take that to be the definition
[00:42:49.500 --> 00:42:53.260]   of an algorithm being efficient.
[00:42:53.260 --> 00:42:57.900]   And we're interested in which problems can be solved
[00:42:57.900 --> 00:43:02.280]   by such efficient algorithms.
[00:43:02.280 --> 00:43:04.920]   One can argue whether that's the right definition
[00:43:04.920 --> 00:43:08.080]   of efficient because you could have an algorithm
[00:43:08.080 --> 00:43:11.380]   whose running time is the 10,000th power
[00:43:11.380 --> 00:43:12.540]   of the size of the input,
[00:43:12.540 --> 00:43:15.800]   and that wouldn't be really efficient.
[00:43:15.800 --> 00:43:19.160]   - And in practice, it's oftentimes reducing
[00:43:19.160 --> 00:43:22.560]   from an N squared algorithm to an N log N
[00:43:22.560 --> 00:43:26.900]   or a linear time is practically the jump
[00:43:26.900 --> 00:43:30.200]   that you wanna make to allow a real world system
[00:43:30.200 --> 00:43:31.160]   to solve a problem.
[00:43:31.160 --> 00:43:33.240]   - Yeah, that's also true because especially
[00:43:33.240 --> 00:43:35.840]   as we get very large networks,
[00:43:35.840 --> 00:43:38.060]   the size can be in the millions
[00:43:38.060 --> 00:43:43.060]   and then anything above N log N,
[00:43:43.060 --> 00:43:45.380]   where N is the size,
[00:43:45.380 --> 00:43:50.000]   would be too much for a practical solution.
[00:43:50.000 --> 00:43:52.560]   - Okay, so that's polynomial time algorithms.
[00:43:52.560 --> 00:43:55.120]   What other classes of algorithms are there?
[00:43:57.360 --> 00:44:01.120]   So that usually they designate polynomials
[00:44:01.120 --> 00:44:02.400]   as a letter P.
[00:44:02.400 --> 00:44:03.240]   - Yeah.
[00:44:03.240 --> 00:44:06.200]   - There's also NP, NP complete, NP hard.
[00:44:06.200 --> 00:44:07.200]   - Yeah.
[00:44:07.200 --> 00:44:09.720]   - So can you try to disentangle those
[00:44:09.720 --> 00:44:14.280]   by trying to define them simply?
[00:44:14.280 --> 00:44:16.960]   - Right, so a polynomial time algorithm
[00:44:16.960 --> 00:44:20.480]   is one whose running time is bounded
[00:44:20.480 --> 00:44:22.720]   by a polynomial in the size of the input.
[00:44:24.560 --> 00:44:29.400]   Then the class of such algorithms is called P.
[00:44:29.400 --> 00:44:31.440]   - In the worst case, by the way, we should say, right?
[00:44:31.440 --> 00:44:32.280]   - Yeah.
[00:44:32.280 --> 00:44:33.100]   - So for every case of the problem.
[00:44:33.100 --> 00:44:34.320]   - Yes, that's right, and that's very important
[00:44:34.320 --> 00:44:36.560]   that in this theory,
[00:44:36.560 --> 00:44:40.880]   when we measure the complexity of an algorithm,
[00:44:40.880 --> 00:44:45.040]   we really measure the number of steps,
[00:44:45.040 --> 00:44:48.960]   the growth of the number of steps in the worst case.
[00:44:48.960 --> 00:44:50.280]   So you may have an algorithm
[00:44:50.280 --> 00:44:55.040]   that runs very rapidly in most cases,
[00:44:55.040 --> 00:44:56.880]   but if there's any case
[00:44:56.880 --> 00:45:00.160]   where it gets into a very long computation,
[00:45:00.160 --> 00:45:03.480]   that would increase the computational complexity
[00:45:03.480 --> 00:45:04.500]   by this measure.
[00:45:04.500 --> 00:45:07.440]   And that's a very important issue
[00:45:07.440 --> 00:45:10.600]   because there, as we may discuss later,
[00:45:10.600 --> 00:45:13.320]   there are some very important algorithms
[00:45:13.320 --> 00:45:15.600]   which don't have a good standing
[00:45:15.600 --> 00:45:18.200]   from the point of view of their worst case performance
[00:45:18.200 --> 00:45:19.780]   and yet are very effective.
[00:45:19.780 --> 00:45:24.360]   So theoreticians are interested in P,
[00:45:24.360 --> 00:45:27.580]   the class of problems solvable in polynomial time.
[00:45:27.580 --> 00:45:34.000]   Then there's NP, which is the class of problems
[00:45:34.000 --> 00:45:38.880]   which may be hard to solve,
[00:45:38.880 --> 00:45:43.880]   but where the, where when confronted with a solution,
[00:45:43.880 --> 00:45:46.660]   you can check it in polynomial time.
[00:45:46.660 --> 00:45:49.200]   Let me give you an example there.
[00:45:49.200 --> 00:45:52.460]   So if we look at the assignment problem,
[00:45:52.460 --> 00:45:56.000]   so you have n boys, you have n girls,
[00:45:56.000 --> 00:45:58.780]   the number of numbers that you need to write down
[00:45:58.780 --> 00:46:02.920]   to specify the problem instances, n squared.
[00:46:02.920 --> 00:46:06.240]   And the question is
[00:46:06.240 --> 00:46:11.560]   how many steps are needed to solve it.
[00:46:11.560 --> 00:46:15.680]   And Jack Edmonds and I were the first to show
[00:46:15.680 --> 00:46:18.460]   that it could be done in time n cubed.
[00:46:18.460 --> 00:46:23.900]   Earlier algorithms required n to the fourth.
[00:46:23.900 --> 00:46:27.320]   So as a polynomial function of the size of the input,
[00:46:27.320 --> 00:46:29.180]   this is a fast algorithm.
[00:46:29.180 --> 00:46:33.280]   Now to illustrate the class NP,
[00:46:33.280 --> 00:46:37.280]   the question is how long would it take to verify
[00:46:37.280 --> 00:46:41.720]   that a solution is optimal?
[00:46:42.680 --> 00:46:47.680]   So for example, if the input was a graph,
[00:46:47.680 --> 00:46:53.160]   we might want to find the largest clique in the graph,
[00:46:53.160 --> 00:46:58.520]   or a clique is a set of vertices such that any vertex,
[00:46:58.520 --> 00:47:03.880]   each vertex in the set is adjacent to each of the others.
[00:47:03.880 --> 00:47:08.960]   So the clique is a complete subgraph.
[00:47:08.960 --> 00:47:11.920]   - Yeah, so if it's a Facebook social network,
[00:47:11.920 --> 00:47:14.120]   everybody's friends with everybody else,
[00:47:14.120 --> 00:47:14.960]   close clique of friends.
[00:47:14.960 --> 00:47:17.280]   - No, that would be what's called a complete graph,
[00:47:17.280 --> 00:47:18.240]   it would be.
[00:47:18.240 --> 00:47:20.640]   - No, I mean within that clique.
[00:47:20.640 --> 00:47:22.000]   - Within that clique, yeah.
[00:47:22.000 --> 00:47:25.640]   They're all friends.
[00:47:25.640 --> 00:47:27.820]   - So a complete graph is when--
[00:47:27.820 --> 00:47:28.840]   - Everybody is friendly.
[00:47:28.840 --> 00:47:31.360]   - Is everybody is friends with everybody, yeah.
[00:47:31.360 --> 00:47:35.480]   - So the problem might be to determine
[00:47:35.480 --> 00:47:39.600]   whether in a given graph there exists a clique
[00:47:39.600 --> 00:47:41.000]   of a certain size.
[00:47:41.920 --> 00:47:45.760]   - Well, that turns out to be a very hard problem,
[00:47:45.760 --> 00:47:49.440]   but if somebody hands you a clique
[00:47:49.440 --> 00:47:52.040]   and asks you to check whether it is,
[00:47:52.040 --> 00:47:56.160]   hands you a set of vertices and asks you to check
[00:47:56.160 --> 00:48:00.480]   whether it's a clique, you could do that simply
[00:48:00.480 --> 00:48:02.920]   by exhaustively looking at all of the edges
[00:48:02.920 --> 00:48:05.200]   between the vertices in the clique
[00:48:05.200 --> 00:48:08.040]   and verifying that they're all there.
[00:48:08.040 --> 00:48:10.480]   - And that's a polynomial time algorithm.
[00:48:10.480 --> 00:48:15.440]   - That's a polynomial, so the problem of finding the clique
[00:48:15.440 --> 00:48:19.280]   appears to be extremely hard,
[00:48:19.280 --> 00:48:21.680]   but the problem of verifying a clique
[00:48:21.680 --> 00:48:26.480]   to see if it reaches a target number of vertices
[00:48:26.480 --> 00:48:31.640]   is easy to verify.
[00:48:31.640 --> 00:48:35.720]   So finding the clique is hard, checking it is easy.
[00:48:35.720 --> 00:48:39.000]   Problems of that nature are called
[00:48:39.000 --> 00:48:42.440]   non-deterministic polynomial time algorithms,
[00:48:42.440 --> 00:48:44.280]   and that's the class NP.
[00:48:44.280 --> 00:48:48.320]   - And what about NP complete and NP hard?
[00:48:48.320 --> 00:48:50.880]   - Okay, let's talk about problems
[00:48:50.880 --> 00:48:53.760]   where you're getting a yes or no answer
[00:48:53.760 --> 00:48:55.400]   rather than a numerical value.
[00:48:55.400 --> 00:48:58.760]   So either there is a perfect matching
[00:48:58.760 --> 00:49:03.760]   of the boys with the girls or there isn't.
[00:49:04.140 --> 00:49:09.140]   It's clear that every problem in NP is also in NP.
[00:49:09.140 --> 00:49:12.540]   If you can solve the problem exactly,
[00:49:12.540 --> 00:49:17.500]   then you can certainly verify the solution.
[00:49:17.500 --> 00:49:22.500]   On the other hand, there are problems in the class NP.
[00:49:22.500 --> 00:49:27.100]   This is the class of problems that are easy to check,
[00:49:27.100 --> 00:49:29.660]   although they may be hard to solve.
[00:49:29.660 --> 00:49:33.740]   It's not at all clear that problems in NP lie in P.
[00:49:33.740 --> 00:49:37.420]   So for example, if we're looking at scheduling classes
[00:49:37.420 --> 00:49:42.420]   at a school, the fact that you can verify
[00:49:42.420 --> 00:49:45.780]   when handed a schedule for the school,
[00:49:45.780 --> 00:49:47.980]   whether it meets all the requirements,
[00:49:47.980 --> 00:49:51.380]   that doesn't mean that you can find the schedule rapidly.
[00:49:51.380 --> 00:49:55.300]   So intuitively, NP, non-deterministic polynomial,
[00:49:55.300 --> 00:49:57.120]   checking rather than finding,
[00:49:58.860 --> 00:50:01.600]   is going to be harder than,
[00:50:01.600 --> 00:50:06.140]   is going to include, is easier.
[00:50:06.140 --> 00:50:08.820]   Checking is easier, and therefore the class of problems
[00:50:08.820 --> 00:50:11.940]   that can be checked appears to be much larger
[00:50:11.940 --> 00:50:14.620]   than the class of problems that can be solved.
[00:50:14.620 --> 00:50:17.380]   - And then you keep adding appears to
[00:50:17.380 --> 00:50:21.500]   and sort of these additional words
[00:50:21.500 --> 00:50:24.060]   that designate that we don't know for sure yet.
[00:50:24.060 --> 00:50:25.180]   - We don't know for sure.
[00:50:25.180 --> 00:50:26.980]   So the theoretical question,
[00:50:27.020 --> 00:50:30.420]   which is considered to be the most central problem
[00:50:30.420 --> 00:50:32.640]   in theoretical computer science,
[00:50:32.640 --> 00:50:35.500]   or at least computational complexity theory,
[00:50:35.500 --> 00:50:38.560]   combinatorial algorithm theory,
[00:50:38.560 --> 00:50:42.720]   question is whether P is equal to NP.
[00:50:42.720 --> 00:50:46.300]   If P were equal to NP, it would be amazing.
[00:50:46.300 --> 00:50:50.820]   It would mean that every problem
[00:50:54.240 --> 00:50:56.920]   where a solution can be rapidly checked
[00:50:56.920 --> 00:51:00.880]   can actually be solved in polynomial time.
[00:51:00.880 --> 00:51:03.400]   We don't really believe that's true.
[00:51:03.400 --> 00:51:05.780]   If you're scheduling classes at a school,
[00:51:05.780 --> 00:51:13.040]   we expect that if somebody hands you a satisfying schedule,
[00:51:13.040 --> 00:51:15.640]   you can verify that it works.
[00:51:15.640 --> 00:51:17.140]   That doesn't mean that you should be able
[00:51:17.140 --> 00:51:18.960]   to find such a schedule.
[00:51:18.960 --> 00:51:23.960]   So intuitively, NP encompasses a lot more problems than P.
[00:51:24.160 --> 00:51:28.040]   - So can we take a small tangent
[00:51:28.040 --> 00:51:30.480]   and break apart that intuition?
[00:51:30.480 --> 00:51:34.560]   So do you, first of all, think that the biggest
[00:51:34.560 --> 00:51:36.200]   sort of open problem in computer science,
[00:51:36.200 --> 00:51:40.000]   maybe mathematics, is whether P equals NP?
[00:51:40.000 --> 00:51:43.240]   Do you think P equals NP?
[00:51:43.240 --> 00:51:46.320]   Or do you think P is not equal to NP?
[00:51:46.320 --> 00:51:48.840]   If you had to bet all your money on it.
[00:51:48.840 --> 00:51:52.040]   - I would bet that P is unequal to NP,
[00:51:52.040 --> 00:51:54.320]   simply because there are problems
[00:51:54.320 --> 00:51:55.960]   that have been around for centuries
[00:51:55.960 --> 00:51:59.020]   and have been studied intensively in mathematics,
[00:51:59.020 --> 00:52:02.120]   and even more so in the last 50 years
[00:52:02.120 --> 00:52:05.600]   since the P versus NP was stated.
[00:52:05.600 --> 00:52:10.160]   And no polynomial time algorithms have been found
[00:52:10.160 --> 00:52:13.720]   for these easy to check problems.
[00:52:13.720 --> 00:52:17.640]   So one example is a problem that goes back
[00:52:17.640 --> 00:52:19.880]   to the mathematician Gauss,
[00:52:19.880 --> 00:52:24.480]   who was interested in factoring large numbers.
[00:52:24.480 --> 00:52:27.960]   So we know what a number is prime
[00:52:27.960 --> 00:52:31.480]   if it cannot be written as the product
[00:52:31.480 --> 00:52:35.120]   of two or more numbers unequal to one.
[00:52:35.120 --> 00:52:41.360]   So if we can factor a number like 91, it's seven times 13.
[00:52:41.360 --> 00:52:48.880]   But if I give you 20 digit or 30 digit numbers,
[00:52:49.880 --> 00:52:52.560]   you're probably going to be at a loss
[00:52:52.560 --> 00:52:55.460]   to have any idea whether they can be factored.
[00:52:55.460 --> 00:53:00.080]   So the problem of factoring very large numbers
[00:53:00.080 --> 00:53:05.080]   does not appear to have an efficient solution.
[00:53:05.080 --> 00:53:09.600]   But once you have found the factors,
[00:53:09.600 --> 00:53:14.600]   expressed the number as a product of two smaller numbers,
[00:53:16.560 --> 00:53:19.960]   you can quickly verify that they are factors of the number.
[00:53:19.960 --> 00:53:22.480]   - And your intuition is a lot of people finding,
[00:53:22.480 --> 00:53:24.680]   you know, a lot of brilliant people
[00:53:24.680 --> 00:53:25.720]   have tried to find algorithms.
[00:53:25.720 --> 00:53:28.600]   This one particular problem, there's many others like it
[00:53:28.600 --> 00:53:30.560]   that are really well studied,
[00:53:30.560 --> 00:53:33.920]   and it would be great to find an efficient algorithm for.
[00:53:33.920 --> 00:53:38.920]   - Right, and in fact, we have some results
[00:53:38.920 --> 00:53:43.460]   that I was instrumental in obtaining,
[00:53:43.460 --> 00:53:46.940]   following up on work by the mathematician Stephen Cook,
[00:53:46.940 --> 00:53:52.920]   to show that within the class NP,
[00:53:52.920 --> 00:53:55.820]   of easy to check problems,
[00:53:55.820 --> 00:53:59.380]   there's a huge number that are equivalent in the sense
[00:53:59.380 --> 00:54:03.220]   that either all of them or none of them lie in P.
[00:54:03.220 --> 00:54:06.420]   And this happens only if P is equal to NP.
[00:54:06.420 --> 00:54:10.900]   So if P is unequal to NP, we would also know
[00:54:10.900 --> 00:54:15.900]   that virtually all the standard combinatorial problems,
[00:54:15.900 --> 00:54:22.460]   if P is unequal to NP,
[00:54:22.460 --> 00:54:25.860]   none of them can be solved in polynomial time.
[00:54:25.860 --> 00:54:28.500]   - Can you explain how that's possible
[00:54:28.500 --> 00:54:32.240]   to tie together so many problems in a nice bunch
[00:54:32.240 --> 00:54:36.540]   that if one is proven to be efficient, then all are?
[00:54:36.540 --> 00:54:40.580]   - The first and most important stage of progress
[00:54:40.580 --> 00:54:44.500]   was a result by Stephen Cook,
[00:54:44.500 --> 00:54:49.660]   who showed that a certain problem
[00:54:49.660 --> 00:54:54.500]   called the satisfiability problem of propositional logic
[00:54:54.500 --> 00:55:00.140]   is as hard as any problem in the class P.
[00:55:00.140 --> 00:55:05.140]   So the propositional logic problem is expressed
[00:55:05.140 --> 00:55:10.180]   in terms of expressions involving the logical operations
[00:55:11.020 --> 00:55:16.020]   and or and not operating on variables
[00:55:16.020 --> 00:55:19.200]   that can be either true or false.
[00:55:19.200 --> 00:55:24.200]   So an instance of the problem would be some formula
[00:55:24.200 --> 00:55:26.740]   involving and or and not.
[00:55:26.740 --> 00:55:31.140]   And the question would be whether there is an assignment
[00:55:31.140 --> 00:55:34.860]   of truth values to the variables in the problem
[00:55:34.860 --> 00:55:37.360]   that would make the formula true.
[00:55:37.360 --> 00:55:42.360]   So for example, if I take the formula A or B
[00:55:42.360 --> 00:55:47.860]   and A or not B and not A or B and not A or not B
[00:55:47.860 --> 00:55:51.220]   and take the conjunction of all four
[00:55:51.220 --> 00:55:54.580]   of those so-called expressions,
[00:55:54.580 --> 00:55:59.020]   you can determine that no assignment of truth values
[00:55:59.020 --> 00:56:03.860]   to the variables A and B will allow that conjunction
[00:56:03.860 --> 00:56:08.860]   of what are called clauses to be true.
[00:56:08.860 --> 00:56:14.160]   So that's an example of a formula in propositional logic
[00:56:14.160 --> 00:56:21.900]   involving expressions based on the operations and or and not.
[00:56:21.900 --> 00:56:27.240]   That's an example of a problem which is not satisfiable.
[00:56:27.240 --> 00:56:29.240]   There is no solution that satisfies
[00:56:29.240 --> 00:56:31.160]   all of those constraints.
[00:56:31.160 --> 00:56:32.880]   - And that's like one of the cleanest
[00:56:32.880 --> 00:56:35.300]   and fundamental problems in computer science.
[00:56:35.300 --> 00:56:37.680]   It's like a nice statement of a really hard problem.
[00:56:37.680 --> 00:56:39.960]   - It's a nice statement of a really hard problem.
[00:56:39.960 --> 00:56:44.960]   And what Cook showed is that every problem in NP
[00:56:44.960 --> 00:56:53.560]   can be re-expressed as an instance
[00:56:53.560 --> 00:56:56.080]   of the satisfiability problem.
[00:56:56.080 --> 00:57:01.080]   So to do that, he used the observation
[00:57:02.080 --> 00:57:04.160]   that a very simple abstract machine
[00:57:04.160 --> 00:57:08.360]   called the Turing machine can be used
[00:57:08.360 --> 00:57:12.400]   to describe any algorithm.
[00:57:12.400 --> 00:57:17.800]   An algorithm for any realistic computer
[00:57:17.800 --> 00:57:22.800]   can be translated into an equivalent algorithm
[00:57:22.800 --> 00:57:25.840]   on one of these Turing machines,
[00:57:25.840 --> 00:57:27.960]   which are extremely simple.
[00:57:27.960 --> 00:57:29.760]   - So Turing machine, there's a tape
[00:57:29.760 --> 00:57:32.400]   and you can walk along that tape.
[00:57:32.400 --> 00:57:33.360]   - Yeah, you have data on a tape
[00:57:33.360 --> 00:57:35.680]   and you have basic instructions,
[00:57:35.680 --> 00:57:37.800]   a finite list of instructions,
[00:57:37.800 --> 00:57:42.240]   which say if you're reading a particular symbol on the tape
[00:57:42.240 --> 00:57:45.480]   and you're in a particular state,
[00:57:45.480 --> 00:57:49.800]   then you can move to a different state
[00:57:49.800 --> 00:57:52.200]   and change the state of the number,
[00:57:52.200 --> 00:57:53.760]   the element that you were looking at,
[00:57:53.760 --> 00:57:55.720]   the cell of the tape that you were looking at.
[00:57:55.720 --> 00:57:58.520]   - And that was like a metaphor and a mathematical construct
[00:57:58.520 --> 00:57:59.840]   that Turing put together
[00:57:59.840 --> 00:58:02.160]   to represent all possible computation.
[00:58:02.160 --> 00:58:03.560]   - All possible computation.
[00:58:03.560 --> 00:58:06.200]   Now, one of these so-called Turing machines
[00:58:06.200 --> 00:58:09.260]   is too simple to be useful in practice,
[00:58:09.260 --> 00:58:11.320]   but for theoretical purposes,
[00:58:11.320 --> 00:58:15.820]   we can depend on the fact that an algorithm
[00:58:15.820 --> 00:58:18.800]   for any computer can be translated
[00:58:18.800 --> 00:58:21.280]   into one that would run on a Turing machine.
[00:58:21.280 --> 00:58:24.900]   And then using that fact,
[00:58:26.260 --> 00:58:29.220]   he could sort of describe
[00:58:29.220 --> 00:58:35.660]   any possible non-deterministic polynomial time algorithm,
[00:58:35.660 --> 00:58:40.020]   any algorithm for a problem in NP
[00:58:40.020 --> 00:58:44.520]   could be expressed as a sequence of moves
[00:58:44.520 --> 00:58:47.360]   of the Turing machine described
[00:58:47.360 --> 00:58:51.520]   in terms of reading a symbol on the tape
[00:58:51.520 --> 00:58:55.560]   while you're in a given state
[00:58:55.560 --> 00:58:56.840]   and moving to a new state
[00:58:56.840 --> 00:58:59.960]   and leaving behind a new symbol.
[00:58:59.960 --> 00:59:04.800]   And given that fact that any
[00:59:04.800 --> 00:59:07.640]   non-deterministic polynomial time algorithm
[00:59:07.640 --> 00:59:12.640]   can be described by a list of such instructions,
[00:59:12.640 --> 00:59:15.840]   you could translate the problem
[00:59:15.840 --> 00:59:19.080]   into the language of the satisfiability problem.
[00:59:19.080 --> 00:59:20.360]   - Is that amazing to you, by the way,
[00:59:20.360 --> 00:59:22.300]   if you take yourself back when you were first thinking
[00:59:22.300 --> 00:59:23.520]   about this space of problems?
[00:59:23.520 --> 00:59:26.760]   How amazing is that?
[00:59:26.760 --> 00:59:27.920]   - It's astonishing.
[00:59:27.920 --> 00:59:30.320]   When you look at Cook's proof,
[00:59:30.320 --> 00:59:34.520]   it's not too difficult to sort of figure out
[00:59:34.520 --> 00:59:38.520]   why this is so,
[00:59:38.520 --> 00:59:40.760]   but the implications are staggering.
[00:59:40.760 --> 00:59:46.280]   It tells us that this, of all the problems in NP,
[00:59:46.280 --> 00:59:48.940]   all the problems where solutions are easy to check,
[00:59:51.120 --> 00:59:54.600]   they can all be rewritten in terms of
[00:59:54.600 --> 00:59:57.760]   the satisfiability problem.
[00:59:57.760 --> 01:00:04.040]   - Yeah, it's adding so much more weight
[01:00:04.040 --> 01:00:06.840]   to the P equals NP question,
[01:00:06.840 --> 01:00:09.320]   because all it takes is to show that one--
[01:00:09.320 --> 01:00:10.160]   - That's right.
[01:00:10.160 --> 01:00:11.240]   - One algorithm in this class--
[01:00:11.240 --> 01:00:13.720]   - So the P versus NP can be re-expressed
[01:00:13.720 --> 01:00:17.560]   as simply asking whether the satisfiability problem
[01:00:17.560 --> 01:00:21.460]   of propositional logic is solvable in polynomial time.
[01:00:21.460 --> 01:00:25.120]   But there's more.
[01:00:25.120 --> 01:00:30.320]   I encountered Cook's paper
[01:00:30.320 --> 01:00:34.560]   when he published it in a conference in 1971.
[01:00:34.560 --> 01:00:37.720]   Yeah, so when I saw Cook's paper
[01:00:37.720 --> 01:00:42.720]   and saw this reduction of each of the problems in NP
[01:00:44.360 --> 01:00:49.120]   by a uniform method to the satisfiability problem
[01:00:49.120 --> 01:00:50.820]   of propositional logic,
[01:00:50.820 --> 01:00:54.560]   that meant that the satisfiability problem
[01:00:54.560 --> 01:00:57.640]   was a universal combinatorial problem.
[01:00:57.640 --> 01:01:04.080]   And it occurred to me through experience I had had
[01:01:04.080 --> 01:01:07.720]   in trying to solve other combinatorial problems
[01:01:07.720 --> 01:01:10.380]   that there were many other problems
[01:01:10.380 --> 01:01:14.620]   which seemed to have that universal structure.
[01:01:14.620 --> 01:01:19.780]   And so I began looking for reductions
[01:01:19.780 --> 01:01:26.060]   from the satisfiability to other problems.
[01:01:26.060 --> 01:01:32.460]   One of the other problems would be
[01:01:32.460 --> 01:01:35.660]   the so-called integer programming problem
[01:01:35.660 --> 01:01:40.260]   of determining whether there's a solution
[01:01:40.260 --> 01:01:45.100]   to a set of linear inequalities
[01:01:45.100 --> 01:01:47.260]   involving integer variables.
[01:01:47.260 --> 01:01:49.540]   - Just like linear programming,
[01:01:49.540 --> 01:01:50.900]   but there's a constraint
[01:01:50.900 --> 01:01:53.620]   that the variables must remain integers.
[01:01:53.620 --> 01:01:56.380]   - Integers, in fact, must be either zero or one.
[01:01:56.380 --> 01:01:58.500]   It could only take on those values.
[01:01:58.500 --> 01:02:00.820]   - And that makes the problem much harder.
[01:02:00.820 --> 01:02:03.540]   - Yes, that makes the problem much harder.
[01:02:03.540 --> 01:02:07.340]   And it was not difficult to show
[01:02:07.340 --> 01:02:11.660]   that the satisfiability problem can be restated
[01:02:11.660 --> 01:02:13.860]   as an integer programming problem.
[01:02:13.860 --> 01:02:15.220]   - So can you pause on that?
[01:02:15.220 --> 01:02:17.220]   Was that one of the first problem mappings
[01:02:17.220 --> 01:02:19.100]   that you tried to do?
[01:02:19.100 --> 01:02:20.380]   And how hard is that map?
[01:02:20.380 --> 01:02:21.760]   And you said it wasn't hard to show,
[01:02:21.760 --> 01:02:26.760]   but that's a big leap.
[01:02:26.760 --> 01:02:29.340]   - It is a big leap, yeah.
[01:02:29.340 --> 01:02:32.980]   Well, let me give you another example.
[01:02:32.980 --> 01:02:35.180]   Another problem in NP
[01:02:35.180 --> 01:02:39.620]   is whether a graph contains a clique of a given size.
[01:02:39.620 --> 01:02:46.700]   And now the question is,
[01:02:46.700 --> 01:02:51.220]   can we reduce the propositional logic problem
[01:02:51.220 --> 01:02:55.500]   to the problem of whether there's a clique
[01:02:55.500 --> 01:02:56.720]   of a certain size?
[01:02:56.720 --> 01:03:01.300]   Well, if you look at the propositional logic problem,
[01:03:01.300 --> 01:03:05.460]   it can be expressed as a number of clauses,
[01:03:05.460 --> 01:03:10.460]   each of which is of the form A or B or C,
[01:03:10.460 --> 01:03:18.380]   where A is either one of the variables in the problem
[01:03:18.380 --> 01:03:20.860]   or the negation of one of the variables.
[01:03:20.860 --> 01:03:27.620]   And an instance of the propositional logic problem
[01:03:30.220 --> 01:03:35.220]   can be rewritten using operations of Boolean logic.
[01:03:35.220 --> 01:03:41.300]   Can be rewritten as the conjunction of a set of clauses,
[01:03:41.300 --> 01:03:43.700]   the and of a set of ors,
[01:03:43.700 --> 01:03:48.020]   where each clause is a disjunction,
[01:03:48.020 --> 01:03:51.520]   an or of variables or negated variables.
[01:03:51.520 --> 01:03:56.460]   So the question of,
[01:03:58.940 --> 01:04:01.220]   in the satisfiability problem,
[01:04:01.220 --> 01:04:05.980]   is whether those clauses can be simultaneously satisfied.
[01:04:05.980 --> 01:04:09.100]   Now to satisfy all those clauses,
[01:04:09.100 --> 01:04:13.100]   you have to find one of the terms in each clause,
[01:04:13.100 --> 01:04:18.940]   which is going to be true in your truth assignment,
[01:04:18.940 --> 01:04:24.740]   but you can't make the same variable both true and false.
[01:04:24.740 --> 01:04:29.580]   So if you have the variable A in one clause
[01:04:29.580 --> 01:04:34.260]   and you want to satisfy that clause by making A true,
[01:04:34.260 --> 01:04:38.380]   you can't also make the complement of A true
[01:04:38.380 --> 01:04:39.700]   in some other clause.
[01:04:39.700 --> 01:04:43.060]   - And so the goal is to make every single clause true
[01:04:43.060 --> 01:04:45.220]   if it's possible to satisfy this.
[01:04:45.220 --> 01:04:47.940]   And the way you make it true is at least...
[01:04:47.940 --> 01:04:52.460]   - One term in the clause must be true.
[01:04:52.460 --> 01:04:53.940]   - Got it.
[01:04:53.940 --> 01:04:58.420]   So now we, to convert this problem
[01:04:58.420 --> 01:05:01.180]   to something called the independent set problem,
[01:05:01.180 --> 01:05:06.180]   where you're just sort of asking for a set of vertices
[01:05:06.180 --> 01:05:08.860]   in a graph such that no two of them are adjacent,
[01:05:08.860 --> 01:05:11.060]   sort of the opposite of the clique problem.
[01:05:11.060 --> 01:05:19.980]   So we've seen that we can now express that as...
[01:05:19.980 --> 01:05:24.980]   Finding a set of terms, one in each clause,
[01:05:24.980 --> 01:05:36.220]   without picking both the variable
[01:05:36.220 --> 01:05:39.020]   and the negation of that variable.
[01:05:39.020 --> 01:05:42.860]   Because if the variable is assigned the truth value,
[01:05:42.860 --> 01:05:46.300]   the negated variable has to have the opposite truth value.
[01:05:46.300 --> 01:05:47.140]   - Right.
[01:05:47.140 --> 01:05:50.420]   - And so we can construct a graph
[01:05:50.420 --> 01:05:55.420]   where the vertices are the terms in all of the clauses.
[01:05:55.420 --> 01:06:03.140]   And you have an edge between two terms,
[01:06:03.140 --> 01:06:13.740]   if an edge between two occurrences of terms.
[01:06:14.740 --> 01:06:17.020]   Either if they're both in the same clause,
[01:06:17.020 --> 01:06:20.740]   because you're only picking one element from each clause.
[01:06:20.740 --> 01:06:23.380]   And also an edge between them
[01:06:23.380 --> 01:06:27.300]   if they represent opposite values of the same variable,
[01:06:27.300 --> 01:06:30.660]   because you can't make a variable both true and false.
[01:06:30.660 --> 01:06:32.460]   And so you get a graph
[01:06:32.460 --> 01:06:35.460]   where you have all of these occurrences of variables.
[01:06:35.460 --> 01:06:38.780]   You have edges, which mean that you're not allowed
[01:06:38.780 --> 01:06:42.380]   to choose both of the variables.
[01:06:42.380 --> 01:06:44.860]   Both ends of the edge,
[01:06:44.860 --> 01:06:46.940]   either because they're in the same clause
[01:06:46.940 --> 01:06:50.580]   or they're negations of one another.
[01:06:50.580 --> 01:06:53.180]   - Right, and that's a, first of all,
[01:06:53.180 --> 01:06:56.300]   sort of to zoom out, that's a really powerful idea
[01:06:56.300 --> 01:06:59.100]   that you could take a graph
[01:06:59.100 --> 01:07:03.940]   and connect it to a logic equation somehow.
[01:07:03.940 --> 01:07:08.100]   And do that mapping for all possible formulations
[01:07:08.100 --> 01:07:10.180]   of a particular problem on a graph.
[01:07:10.180 --> 01:07:11.020]   - Yeah.
[01:07:11.020 --> 01:07:15.460]   - I mean, that still is hard for me to believe
[01:07:15.460 --> 01:07:17.640]   that that's possible.
[01:07:17.640 --> 01:07:20.820]   Like, what do you make of that,
[01:07:20.820 --> 01:07:24.860]   that there's such a union of,
[01:07:24.860 --> 01:07:28.780]   there's such a friendship among all these problems across
[01:07:28.780 --> 01:07:33.780]   that somehow are akin to combinatorial algorithms,
[01:07:33.780 --> 01:07:35.940]   that they're all somehow related.
[01:07:35.940 --> 01:07:39.980]   I know it can be proven, but what do you make of it,
[01:07:39.980 --> 01:07:41.740]   that that's true?
[01:07:41.740 --> 01:07:46.780]   - Well, that they just have the same expressive power.
[01:07:46.780 --> 01:07:49.580]   You can take any one of them
[01:07:49.580 --> 01:07:53.460]   and translate it into the terms of the other.
[01:07:53.460 --> 01:07:55.580]   - The fact that they have the same expressive power
[01:07:55.580 --> 01:07:59.020]   also somehow means that they can be translatable.
[01:07:59.020 --> 01:08:00.180]   - Right.
[01:08:00.180 --> 01:08:03.540]   And what I did in the 1971 paper
[01:08:03.540 --> 01:08:08.460]   was to take 21 fundamental problems,
[01:08:09.500 --> 01:08:12.380]   commonly occurring problems of packing,
[01:08:12.380 --> 01:08:14.420]   covering, matching, and so forth,
[01:08:14.420 --> 01:08:19.220]   lying in the class NP,
[01:08:19.220 --> 01:08:21.860]   and show that the satisfiability problem
[01:08:21.860 --> 01:08:24.300]   can be re-expressed as any of those,
[01:08:24.300 --> 01:08:29.300]   that any of those have the same expressive power.
[01:08:29.300 --> 01:08:30.340]   So--
[01:08:30.340 --> 01:08:31.980]   - And that was like throwing down the gauntlet
[01:08:31.980 --> 01:08:35.900]   of saying there's probably many more problems like this.
[01:08:35.900 --> 01:08:36.740]   - Right.
[01:08:36.740 --> 01:08:37.580]   - But that's just saying that,
[01:08:37.660 --> 01:08:39.660]   look, that they're all the same.
[01:08:39.660 --> 01:08:43.140]   - They're all the same, but not exactly.
[01:08:43.140 --> 01:08:45.180]   Yeah, they're all the same in terms of
[01:08:45.180 --> 01:08:50.180]   whether they are rich enough to express any of the others.
[01:08:50.180 --> 01:08:55.260]   But that doesn't mean that they have
[01:08:55.260 --> 01:08:57.780]   the same computational complexity.
[01:08:57.780 --> 01:09:02.220]   But what we can say is that either all of these problems
[01:09:02.220 --> 01:09:05.820]   or none of them are solvable in polynomial time.
[01:09:05.820 --> 01:09:10.300]   - Yeah, so where does NP completeness and NP hard
[01:09:10.300 --> 01:09:11.140]   as classes fit?
[01:09:11.140 --> 01:09:14.060]   - Oh, that's just a small technicality.
[01:09:14.060 --> 01:09:17.300]   So when we're talking about decision problems,
[01:09:17.300 --> 01:09:20.940]   that means that the answer is just yes or no.
[01:09:20.940 --> 01:09:23.300]   There is a clique of size 15
[01:09:23.300 --> 01:09:25.540]   or there's not a clique of size 15.
[01:09:25.540 --> 01:09:29.980]   On the other hand, an optimization problem would be asking,
[01:09:29.980 --> 01:09:33.180]   find the largest clique.
[01:09:33.180 --> 01:09:34.980]   The answer would not be yes or no,
[01:09:34.980 --> 01:09:36.500]   it would be 15.
[01:09:36.500 --> 01:09:41.300]   So when you're asking for the,
[01:09:41.300 --> 01:09:46.660]   when you're putting a valuation on the different solutions
[01:09:46.660 --> 01:09:49.060]   and you're asking for the one with the highest valuation,
[01:09:49.060 --> 01:09:51.380]   that's an optimization problem.
[01:09:51.380 --> 01:09:52.900]   And there's a very close affinity
[01:09:52.900 --> 01:09:55.420]   between the two kinds of problems.
[01:09:55.420 --> 01:10:00.420]   But the counterpart of being the hardest decision problem,
[01:10:00.420 --> 01:10:04.220]   the hardest yes/no problem,
[01:10:04.220 --> 01:10:09.220]   the counterpart of that is to minimize
[01:10:09.220 --> 01:10:13.380]   or maximize an objective function.
[01:10:13.380 --> 01:10:16.380]   And so a problem that's hardest in the class
[01:10:16.380 --> 01:10:19.900]   when viewed in terms of optimization,
[01:10:19.900 --> 01:10:24.420]   those are called NP hard rather than NP complete.
[01:10:24.420 --> 01:10:26.260]   - And NP complete is for decision problems.
[01:10:26.260 --> 01:10:28.700]   - And NP complete is for decision problems.
[01:10:29.900 --> 01:10:34.900]   - So if somebody shows that P equals NP,
[01:10:34.900 --> 01:10:39.420]   what do you think that proof will look like
[01:10:39.420 --> 01:10:41.500]   if you were to put on yourself,
[01:10:41.500 --> 01:10:45.300]   if it's possible to show that as a proof
[01:10:45.300 --> 01:10:47.260]   or to demonstrate an algorithm?
[01:10:47.260 --> 01:10:52.220]   - All I can say is that it will involve concepts
[01:10:52.220 --> 01:10:56.380]   that we do not now have and approaches that we don't have.
[01:10:56.380 --> 01:10:58.580]   - Do you think those concepts are out there
[01:10:58.580 --> 01:11:01.980]   in terms of inside complexity theory,
[01:11:01.980 --> 01:11:04.740]   inside of computational analysis of algorithms?
[01:11:04.740 --> 01:11:05.820]   Do you think there's concepts
[01:11:05.820 --> 01:11:07.900]   that are totally outside of the box
[01:11:07.900 --> 01:11:09.140]   that we haven't considered yet?
[01:11:09.140 --> 01:11:13.180]   - I think that if there is a proof that P is equal to NP
[01:11:13.180 --> 01:11:15.040]   or that P is not equal to NP,
[01:11:15.040 --> 01:11:21.320]   it'll depend on concepts that are now outside the box.
[01:11:21.320 --> 01:11:25.900]   - Now if that's shown, either way, P equals NP or P not,
[01:11:25.900 --> 01:11:28.240]   well, actually P equals NP,
[01:11:28.240 --> 01:11:32.260]   what impact, you kind of mentioned a little bit,
[01:11:32.260 --> 01:11:34.140]   but can you linger on it?
[01:11:34.140 --> 01:11:36.760]   What kind of impact would it have
[01:11:36.760 --> 01:11:38.340]   on theoretical computer science
[01:11:38.340 --> 01:11:42.180]   and perhaps software systems in general?
[01:11:42.180 --> 01:11:44.700]   - Well, I think it would have enormous impact
[01:11:44.700 --> 01:11:49.160]   on the world in either way case.
[01:11:49.160 --> 01:11:52.240]   If P is unequal to NP, which is what we expect,
[01:11:52.240 --> 01:11:56.860]   then we know that for the great majority
[01:11:56.860 --> 01:11:59.500]   of the combinatorial problems that come up,
[01:11:59.500 --> 01:12:02.100]   since they're known to be NP complete,
[01:12:02.100 --> 01:12:05.060]   we're not going to be able to solve them
[01:12:05.060 --> 01:12:07.780]   by efficient algorithms.
[01:12:07.780 --> 01:12:11.620]   However, there's a little bit of hope
[01:12:11.620 --> 01:12:16.580]   in that it may be that we can solve most instances.
[01:12:16.580 --> 01:12:19.860]   All we know is that if a problem is not in P,
[01:12:19.860 --> 01:12:22.940]   then it can't be solved efficiently on all instances.
[01:12:25.540 --> 01:12:27.500]   But basically, it will,
[01:12:27.500 --> 01:12:32.700]   if we find that P is unequal to NP,
[01:12:32.700 --> 01:12:35.300]   it will mean that we can't expect always
[01:12:35.300 --> 01:12:38.640]   to get the optimal solutions to these problems.
[01:12:38.640 --> 01:12:41.020]   And we have to depend on heuristics
[01:12:41.020 --> 01:12:43.140]   that perhaps work most of the time
[01:12:43.140 --> 01:12:45.820]   or give us good approximate solutions.
[01:12:45.820 --> 01:12:51.260]   - So we would turn our eye towards the heuristics
[01:12:52.220 --> 01:12:56.420]   with a little bit more acceptance and comfort on our hearts.
[01:12:56.420 --> 01:12:57.580]   - Exactly.
[01:12:57.580 --> 01:13:01.060]   - Okay, so let me ask a romanticized question.
[01:13:01.060 --> 01:13:04.460]   What to you is one of the most
[01:13:04.460 --> 01:13:08.180]   or the most beautiful combinatorial algorithm
[01:13:08.180 --> 01:13:10.180]   in your own life or just in general
[01:13:10.180 --> 01:13:12.500]   in the field that you've ever come across
[01:13:12.500 --> 01:13:14.100]   or have developed yourself?
[01:13:14.100 --> 01:13:17.820]   - I like the stable matching problem
[01:13:17.820 --> 01:13:22.780]   or the stable marriage problem very much.
[01:13:22.780 --> 01:13:25.180]   - What's the stable matching problem?
[01:13:25.180 --> 01:13:26.460]   - Yeah.
[01:13:26.460 --> 01:13:31.460]   Imagine that you want to marry off N boys
[01:13:31.460 --> 01:13:34.140]   with N girls.
[01:13:34.140 --> 01:13:39.940]   And each boy has an ordered list
[01:13:39.940 --> 01:13:42.340]   of his preferences among the girls,
[01:13:42.340 --> 01:13:44.780]   his first choice, his second choice,
[01:13:44.780 --> 01:13:46.220]   through her Nth choice.
[01:13:47.400 --> 01:13:52.400]   And each girl also has an ordering of the boys,
[01:13:52.400 --> 01:13:57.580]   his first choice, second choice, and so on.
[01:13:57.580 --> 01:14:03.460]   And we'll say that a matching,
[01:14:03.460 --> 01:14:07.580]   a one-to-one matching of the boys with the girls is stable
[01:14:07.580 --> 01:14:13.840]   if there are no two couples in the matching
[01:14:15.140 --> 01:14:18.660]   such that the boy in the first couple
[01:14:18.660 --> 01:14:23.220]   prefers the girl in the second couple to her mate
[01:14:23.220 --> 01:14:27.060]   and she prefers the boy to her current mate.
[01:14:27.060 --> 01:14:31.300]   In other words, if there is, the matching is stable
[01:14:31.300 --> 01:14:35.460]   if there is no pair who want to run away with each other,
[01:14:35.460 --> 01:14:37.340]   leaving their partners behind.
[01:14:37.340 --> 01:14:41.220]   - Gotcha. (laughs)
[01:14:41.220 --> 01:14:44.940]   Yeah.
[01:14:44.940 --> 01:14:49.100]   - Actually, this is relevant to matching residents
[01:14:49.100 --> 01:14:52.300]   with hospitals and some other real-life problems,
[01:14:52.300 --> 01:14:55.580]   although not quite in the form that I described.
[01:14:55.580 --> 01:14:59.780]   So it turns out that there is,
[01:14:59.780 --> 01:15:04.780]   that for any set of preferences, a stable matching exists.
[01:15:04.780 --> 01:15:10.980]   And moreover, it can be computed by a simple algorithm
[01:15:14.020 --> 01:15:19.020]   in which each boy starts making proposals to girls.
[01:15:19.020 --> 01:15:23.940]   And if a girl receives a proposal,
[01:15:23.940 --> 01:15:27.780]   she accepts it tentatively, but she can drop it if,
[01:15:27.780 --> 01:15:32.780]   she can end it, she can drop it later
[01:15:32.780 --> 01:15:35.740]   if she gets a better proposal from her point of view.
[01:15:35.740 --> 01:15:39.000]   And the boys start going down their list,
[01:15:39.000 --> 01:15:41.980]   proposing to their first, second, third choices
[01:15:41.980 --> 01:15:46.980]   until stopping when a proposal is accepted.
[01:15:46.980 --> 01:15:53.380]   But the girls, meanwhile, are watching the proposals
[01:15:53.380 --> 01:15:55.380]   that are coming into them,
[01:15:55.380 --> 01:15:58.700]   and the girl will drop her current partner
[01:15:58.700 --> 01:16:03.500]   if she gets a better proposal.
[01:16:03.500 --> 01:16:06.300]   - And the boys never go back through the list?
[01:16:06.300 --> 01:16:07.580]   - They never go back, yeah.
[01:16:07.580 --> 01:16:09.700]   So once they've been denied.
[01:16:09.700 --> 01:16:11.740]   (both laugh)
[01:16:11.740 --> 01:16:12.820]   - They don't try again?
[01:16:12.820 --> 01:16:14.640]   - They don't try again,
[01:16:14.640 --> 01:16:19.220]   because the girls are always improving their status
[01:16:19.220 --> 01:16:22.780]   as they receive better and better proposals.
[01:16:22.780 --> 01:16:25.100]   The boys are going down their list,
[01:16:25.100 --> 01:16:28.580]   starting with their top preferences.
[01:16:28.580 --> 01:16:33.580]   And one can prove that the process will come to an end
[01:16:39.540 --> 01:16:43.460]   where everybody will get matched with somebody,
[01:16:43.460 --> 01:16:48.460]   and you won't have any pair that want to abscond
[01:16:48.460 --> 01:16:50.420]   from each other.
[01:16:50.420 --> 01:16:54.140]   - Do you find the proof or the algorithm itself beautiful,
[01:16:54.140 --> 01:16:56.700]   or is it the fact that with the simplicity
[01:16:56.700 --> 01:16:59.540]   of just the two marching,
[01:16:59.540 --> 01:17:01.780]   I mean, the simplicity of the underlying rule
[01:17:01.780 --> 01:17:04.820]   of the algorithm, is that the beautiful part?
[01:17:04.820 --> 01:17:06.320]   - Both, I would say.
[01:17:07.540 --> 01:17:11.740]   And you also have the observation that you might ask,
[01:17:11.740 --> 01:17:14.700]   who is better off, the boys who are doing the proposing
[01:17:14.700 --> 01:17:17.740]   or the girls who are reacting to proposals?
[01:17:17.740 --> 01:17:22.740]   And it turns out that it's the boys who are doing the best,
[01:17:22.740 --> 01:17:25.900]   and as each boy is doing at least as well
[01:17:25.900 --> 01:17:30.520]   as he could do in any other staple matching.
[01:17:30.520 --> 01:17:33.220]   So there's a sort of lesson for the boys
[01:17:33.220 --> 01:17:36.100]   that you should go out and be proactive
[01:17:36.100 --> 01:17:39.680]   and make those proposals, go for broke.
[01:17:39.680 --> 01:17:43.460]   - I don't know if this is directly mappable
[01:17:43.460 --> 01:17:45.120]   philosophically to our society,
[01:17:45.120 --> 01:17:48.140]   but certainly seems like a compelling notion.
[01:17:48.140 --> 01:17:51.340]   And like you said, there's probably a lot
[01:17:51.340 --> 01:17:54.580]   of actual real-world problems that this could be mapped to.
[01:17:54.580 --> 01:17:58.620]   - Yeah, well, you get complications.
[01:17:58.620 --> 01:18:01.500]   For example, what happens when a husband and wife
[01:18:01.500 --> 01:18:03.740]   want to be assigned to the same hospital?
[01:18:03.740 --> 01:18:08.740]   So you have to take those constraints into account.
[01:18:08.740 --> 01:18:13.100]   And then the problem becomes NP-hard.
[01:18:13.100 --> 01:18:18.020]   - Why is it a problem for the husband and wife
[01:18:18.020 --> 01:18:19.980]   to be assigned to the same hospital?
[01:18:19.980 --> 01:18:21.660]   - No, it's desirable.
[01:18:21.660 --> 01:18:22.500]   - Desirable.
[01:18:22.500 --> 01:18:24.060]   - Or at least go to the same city.
[01:18:24.060 --> 01:18:26.540]   So you can't, if you're--
[01:18:26.540 --> 01:18:27.380]   - I see.
[01:18:27.380 --> 01:18:29.580]   - If you're assigning residents to hospitals.
[01:18:29.580 --> 01:18:32.100]   - And then you have some preferences
[01:18:32.100 --> 01:18:34.620]   for the husband and wife or for the hospitals.
[01:18:34.620 --> 01:18:37.100]   - The residents have their own preferences.
[01:18:37.100 --> 01:18:41.660]   References, residents, both male and female,
[01:18:41.660 --> 01:18:43.220]   have their own preferences.
[01:18:43.220 --> 01:18:47.700]   The hospitals have their preferences.
[01:18:47.700 --> 01:18:52.700]   But if resident A, the boy, is going to Philadelphia,
[01:18:52.700 --> 01:19:00.940]   then you'd like his wife also to be assigned to a hospital.
[01:19:01.220 --> 01:19:04.420]   - To be assigned to a hospital in Philadelphia.
[01:19:04.420 --> 01:19:08.020]   - Which step makes it a NP-hard problem that you mentioned?
[01:19:08.020 --> 01:19:11.140]   - The fact that you have this additional constraint.
[01:19:11.140 --> 01:19:15.020]   That it's not just the preferences of individuals,
[01:19:15.020 --> 01:19:19.820]   but the fact that the two partners to a marriage
[01:19:19.820 --> 01:19:22.860]   have to be assigned to the same place.
[01:19:22.860 --> 01:19:24.420]   - I'm being a little dense.
[01:19:29.300 --> 01:19:30.780]   The perfect matching?
[01:19:30.780 --> 01:19:33.860]   No, not the perfect, stable matching is what you refer to.
[01:19:33.860 --> 01:19:36.060]   That's when two partners are trying to--
[01:19:36.060 --> 01:19:39.260]   - Okay, what's confusing you is that in the first
[01:19:39.260 --> 01:19:40.740]   interpretation of the problem,
[01:19:40.740 --> 01:19:42.860]   I had boys matching with girls.
[01:19:42.860 --> 01:19:44.180]   - Yes.
[01:19:44.180 --> 01:19:46.500]   - In the second interpretation,
[01:19:46.500 --> 01:19:49.620]   you have humans matching with institutions.
[01:19:49.620 --> 01:19:50.460]   - With institutions.
[01:19:50.460 --> 01:19:54.340]   And there's a coupling between within the,
[01:19:54.340 --> 01:19:56.780]   gotcha, within the humans.
[01:19:56.780 --> 01:19:59.180]   - Any added little constraint will make it
[01:19:59.180 --> 01:20:00.380]   an NP-hard problem.
[01:20:00.380 --> 01:20:01.500]   - Well, yeah.
[01:20:01.500 --> 01:20:04.220]   - Okay.
[01:20:04.220 --> 01:20:06.180]   By the way, the algalene you mentioned,
[01:20:06.180 --> 01:20:07.780]   was it one of yours?
[01:20:07.780 --> 01:20:11.500]   - No, no, that was due to Gale and Shapley.
[01:20:11.500 --> 01:20:16.860]   My friend David Gale passed away before he could get part
[01:20:16.860 --> 01:20:21.780]   of the Nobel Prize, but his partner Shapley shared
[01:20:21.780 --> 01:20:24.340]   in the Nobel Prize with somebody else for--
[01:20:24.340 --> 01:20:25.180]   - Economics?
[01:20:25.180 --> 01:20:29.700]   - For economics, for ideas stemming
[01:20:29.700 --> 01:20:31.540]   from the stable matching idea.
[01:20:31.540 --> 01:20:36.060]   - So you've also developed yourself some elegant,
[01:20:36.060 --> 01:20:37.340]   beautiful algorithms.
[01:20:37.340 --> 01:20:42.340]   Again, picking your children, so the Robin Karp algorithm
[01:20:42.340 --> 01:20:45.060]   for string searching, pattern matching, Edmund Karp
[01:20:45.060 --> 01:20:46.860]   algorithm for max flows we mentioned,
[01:20:46.860 --> 01:20:50.260]   Hopcroft Karp algorithm for finding maximum cardinality
[01:20:50.260 --> 01:20:52.180]   matchings in bipartite graphs.
[01:20:52.180 --> 01:20:55.460]   Is there ones that stand out to you,
[01:20:55.460 --> 01:21:00.460]   ones you're most proud of, or just whether it's beauty,
[01:21:00.460 --> 01:21:05.740]   elegance, or just being the right discovery,
[01:21:05.740 --> 01:21:08.740]   development in your life that you're especially proud of?
[01:21:08.740 --> 01:21:13.140]   - I like the Robin Karp algorithm because it illustrates
[01:21:13.140 --> 01:21:15.500]   the power of randomization.
[01:21:17.500 --> 01:21:22.500]   So the problem there is to decide whether a given long string
[01:21:22.500 --> 01:21:38.220]   of symbols from some alphabet contains a given word,
[01:21:38.220 --> 01:21:42.940]   whether a particular word occurs within some very much
[01:21:42.940 --> 01:21:47.940]   longer word, and so the idea of the algorithm
[01:21:47.940 --> 01:21:57.180]   is to associate with the word that we're looking for,
[01:21:57.180 --> 01:22:02.180]   a fingerprint, some number or some combinatorial object
[01:22:02.180 --> 01:22:10.300]   that describes that word, and then to look for an occurrence
[01:22:12.260 --> 01:22:15.660]   of that same fingerprint as you slide along the longer word.
[01:22:15.660 --> 01:22:23.500]   And what we do is we associate with each word a number.
[01:22:23.500 --> 01:22:29.660]   So we, first of all, we think of the letters that occur
[01:22:29.660 --> 01:22:33.620]   in a word as the digits of, let's say, decimal
[01:22:33.620 --> 01:22:38.620]   or whatever base here, whatever number of different symbols
[01:22:38.620 --> 01:22:42.020]   there are in the alphabet.
[01:22:42.020 --> 01:22:44.340]   - That's the base of the numbers, yeah.
[01:22:44.340 --> 01:22:48.180]   - Right, so every word can then be thought of as a number
[01:22:48.180 --> 01:22:52.380]   with the letters being the digits of that number.
[01:22:52.380 --> 01:22:58.380]   And then we pick a random prime number in a certain range
[01:22:58.380 --> 01:23:03.260]   and we take that word viewed as a number
[01:23:03.260 --> 01:23:08.260]   and take the remainder on dividing that number by the prime.
[01:23:09.260 --> 01:23:14.260]   - So coming up with a nice hash function.
[01:23:14.260 --> 01:23:16.620]   - It's a kind of hash function.
[01:23:16.620 --> 01:23:20.820]   - Yeah, it gives you a little shortcut
[01:23:20.820 --> 01:23:22.420]   for that particular word.
[01:23:22.420 --> 01:23:26.380]   - Yeah, so that's the--
[01:23:26.380 --> 01:23:31.060]   - It's very different than other algorithms of its kind
[01:23:31.060 --> 01:23:35.540]   that were trying to do search, string matching.
[01:23:35.540 --> 01:23:38.060]   - Yeah, which usually are combinatorial
[01:23:38.060 --> 01:23:42.660]   and don't involve the idea of taking a random fingerprint.
[01:23:42.660 --> 01:23:43.620]   - Yes.
[01:23:43.620 --> 01:23:48.060]   - And doing the fingerprinting has two advantages.
[01:23:48.060 --> 01:23:51.580]   One is that as we slide along the long word,
[01:23:51.580 --> 01:23:56.580]   digit by digit, we keep a window of a certain size,
[01:23:56.580 --> 01:24:00.660]   the size of the word we're looking for.
[01:24:00.660 --> 01:24:05.660]   And we compute the fingerprint of every stretch
[01:24:05.780 --> 01:24:09.500]   of that length and it turns out that just a couple
[01:24:09.500 --> 01:24:11.900]   of arithmetical operations will take you
[01:24:11.900 --> 01:24:16.380]   from the fingerprint of one part to what you get
[01:24:16.380 --> 01:24:18.740]   when you slide over by one position.
[01:24:18.740 --> 01:24:24.540]   So the computation of all the fingerprints is simple.
[01:24:24.540 --> 01:24:31.740]   And secondly, it's unlikely if the prime is chosen randomly
[01:24:32.780 --> 01:24:37.540]   from a certain range that you will get two of the segments
[01:24:37.540 --> 01:24:40.020]   in question having the same fingerprint.
[01:24:40.020 --> 01:24:43.980]   And so there's a small probability of error
[01:24:43.980 --> 01:24:46.500]   which can be checked after the fact
[01:24:46.500 --> 01:24:48.740]   and also the ease of doing the computation
[01:24:48.740 --> 01:24:51.620]   because you're working with these fingerprints
[01:24:51.620 --> 01:24:54.640]   which are remainder's modulo some big prime.
[01:24:54.640 --> 01:24:58.040]   - So that's the magical thing about randomized algorithms
[01:24:58.040 --> 01:25:02.460]   is that if you add a little bit of randomness,
[01:25:02.460 --> 01:25:05.420]   it somehow allows you to take a pretty naive approach,
[01:25:05.420 --> 01:25:07.260]   a simple looking approach
[01:25:07.260 --> 01:25:10.700]   and allow it to run extremely well.
[01:25:10.700 --> 01:25:14.140]   So can you maybe take a step back and say,
[01:25:14.140 --> 01:25:16.020]   like what is a randomized algorithm,
[01:25:16.020 --> 01:25:18.340]   this category of algorithms?
[01:25:18.340 --> 01:25:22.460]   - Well, it's just the ability to draw a random number
[01:25:22.460 --> 01:25:27.460]   from some range or to associate a random number
[01:25:30.480 --> 01:25:35.280]   with some object or to draw at random from some set.
[01:25:35.280 --> 01:25:40.280]   So another example is very simple
[01:25:40.280 --> 01:25:45.360]   if we're conducting a presidential election
[01:25:45.360 --> 01:25:50.400]   and we would like to pick the winner.
[01:25:50.400 --> 01:25:57.320]   In principle, we could draw a random sample
[01:25:57.320 --> 01:25:59.320]   of all of the voters in the country.
[01:26:00.160 --> 01:26:05.160]   And if it was of substantial size, say a few thousand
[01:26:05.160 --> 01:26:08.920]   then the most popular candidate in that group
[01:26:08.920 --> 01:26:12.280]   would be very likely to be the correct choice
[01:26:12.280 --> 01:26:15.840]   that would come out of counting all the millions of votes.
[01:26:15.840 --> 01:26:17.480]   And of course we can't do this
[01:26:17.480 --> 01:26:18.440]   because first of all,
[01:26:18.440 --> 01:26:21.920]   everybody has to feel that his or her vote counted.
[01:26:21.920 --> 01:26:25.280]   And secondly, we can't really do a purely random sample
[01:26:25.280 --> 01:26:28.000]   from that population.
[01:26:28.000 --> 01:26:31.080]   And I guess thirdly, there could be a tie in which case
[01:26:31.080 --> 01:26:34.080]   we wouldn't have a significant difference
[01:26:34.080 --> 01:26:36.360]   between two candidates.
[01:26:36.360 --> 01:26:37.560]   - But those things aside,
[01:26:37.560 --> 01:26:40.480]   if you didn't have all that messiness of human beings,
[01:26:40.480 --> 01:26:43.320]   you could prove that that kind of random picking would--
[01:26:43.320 --> 01:26:48.000]   - You guess that random picking would solve the problem
[01:26:48.000 --> 01:26:51.360]   with a very low probability of error.
[01:26:51.360 --> 01:26:55.520]   Another example is testing whether a number is prime.
[01:26:55.520 --> 01:27:00.280]   So if I want to test whether 17 is prime,
[01:27:00.280 --> 01:27:06.760]   I could pick any number between one and 17
[01:27:06.760 --> 01:27:12.320]   and raise it to the 16th power modulo 17
[01:27:12.320 --> 01:27:15.040]   and you should get back the original number.
[01:27:15.040 --> 01:27:18.800]   That's a famous formula due to Fermat
[01:27:18.800 --> 01:27:21.240]   about it's called Fermat's little theorem
[01:27:21.240 --> 01:27:26.240]   that if you take any number A in the range
[01:27:26.240 --> 01:27:31.000]   zero through N minus one
[01:27:31.000 --> 01:27:37.080]   and raise it to the N minus one power modulo N,
[01:27:37.080 --> 01:27:43.280]   you'll get back the number A if A is prime.
[01:27:43.280 --> 01:27:45.920]   So if you don't get back the number A,
[01:27:45.920 --> 01:27:48.320]   that's a proof that a number is not prime.
[01:27:49.840 --> 01:27:52.360]   - Wow. (laughs)
[01:27:52.360 --> 01:27:57.360]   - And you can show that suitably define
[01:27:57.360 --> 01:28:05.280]   the probability that you will get a value unequal,
[01:28:05.280 --> 01:28:14.320]   you will get a violation of Fermat's result is very high
[01:28:14.320 --> 01:28:18.600]   and so this gives you a way of rapidly proving
[01:28:18.600 --> 01:28:20.040]   that a number is not prime.
[01:28:20.040 --> 01:28:22.840]   It's a little more complicated than that
[01:28:22.840 --> 01:28:26.320]   because there are certain values of N
[01:28:26.320 --> 01:28:28.640]   where something a little more elaborate has to be done
[01:28:28.640 --> 01:28:30.220]   but that's the basic idea.
[01:28:30.220 --> 01:28:34.920]   Taking an identity that holds for primes
[01:28:34.920 --> 01:28:39.500]   and therefore if it ever fails on any instance
[01:28:39.500 --> 01:28:43.480]   for a non-prime, you know that the number is not prime.
[01:28:43.480 --> 01:28:45.720]   It's a quick choice, a fast choice,
[01:28:45.720 --> 01:28:47.800]   fast proof that a number is not prime.
[01:28:48.760 --> 01:28:50.920]   - Can you maybe elaborate a little bit more
[01:28:50.920 --> 01:28:54.200]   of what's your intuition why randomness works so well
[01:28:54.200 --> 01:28:56.460]   and results in such simple algorithms?
[01:28:56.460 --> 01:29:00.840]   - Well, the example of conducting an election
[01:29:00.840 --> 01:29:04.360]   where you could take in theory, you could take a sample
[01:29:04.360 --> 01:29:07.060]   and depend on the validity of the sample
[01:29:07.060 --> 01:29:09.200]   to really represent the whole,
[01:29:09.200 --> 01:29:12.040]   is it just the basic fact of statistics
[01:29:12.040 --> 01:29:14.860]   which gives a lot of opportunities.
[01:29:17.760 --> 01:29:22.760]   And I actually exploited that sort of random sampling idea
[01:29:22.760 --> 01:29:28.120]   in designing an algorithm for counting the number
[01:29:28.120 --> 01:29:33.560]   of solutions that satisfy a particular formula
[01:29:33.560 --> 01:29:36.880]   and propositional logic.
[01:29:36.880 --> 01:29:41.280]   - A particular, so some version
[01:29:41.280 --> 01:29:44.360]   of the satisfiability problem or?
[01:29:44.360 --> 01:29:46.640]   - A version of the satisfiability problem.
[01:29:47.480 --> 01:29:49.400]   - Is there some interesting insight
[01:29:49.400 --> 01:29:50.480]   that you wanna elaborate on?
[01:29:50.480 --> 01:29:53.320]   Like what some aspect of that algorithm
[01:29:53.320 --> 01:29:57.480]   that might be useful to describe?
[01:29:57.480 --> 01:30:02.480]   - So you have a collection of formulas
[01:30:02.480 --> 01:30:10.800]   and you want to count the number of solutions
[01:30:14.400 --> 01:30:18.920]   that satisfy at least one of the formulas.
[01:30:18.920 --> 01:30:23.480]   And you can count the number of solutions
[01:30:23.480 --> 01:30:27.320]   that satisfy any particular one of the formulas,
[01:30:27.320 --> 01:30:29.920]   but you have to account for the fact
[01:30:29.920 --> 01:30:33.700]   that that solution might be counted many times
[01:30:33.700 --> 01:30:38.460]   if it solves more than one of the formulas.
[01:30:40.840 --> 01:30:45.840]   And so what you do is you sample from the formulas
[01:30:45.840 --> 01:30:49.440]   according to the number of solutions
[01:30:49.440 --> 01:30:52.300]   that satisfy each individual one.
[01:30:52.300 --> 01:30:55.640]   And that way you draw a random solution,
[01:30:55.640 --> 01:31:00.200]   but then you correct by looking at the number of formulas
[01:31:00.200 --> 01:31:05.200]   that satisfy that random solution and don't double count.
[01:31:08.840 --> 01:31:11.600]   So if you, you can think of it this way.
[01:31:11.600 --> 01:31:15.160]   So you have a matrix of zeros and ones,
[01:31:15.160 --> 01:31:18.160]   and you wanna know how many columns
[01:31:18.160 --> 01:31:20.600]   of that matrix contain at least one one.
[01:31:20.600 --> 01:31:26.000]   And you can count in each row how many ones there are.
[01:31:26.000 --> 01:31:29.440]   So what you can do is draw from the rows
[01:31:29.440 --> 01:31:31.680]   according to the number of ones.
[01:31:31.680 --> 01:31:34.880]   If a row has more ones, it gets drawn more frequently.
[01:31:35.980 --> 01:31:39.060]   But then if you draw from that row,
[01:31:39.060 --> 01:31:42.580]   you have to go up the column and looking at
[01:31:42.580 --> 01:31:45.940]   where that same one is repeated in different rows
[01:31:45.940 --> 01:31:51.260]   and only count it as a success or a hit
[01:31:51.260 --> 01:31:54.840]   if it's the earliest row that contains the one.
[01:31:54.840 --> 01:31:55.680]   - Right.
[01:31:55.680 --> 01:32:00.300]   - And that gives you a robust statistical estimate
[01:32:00.300 --> 01:32:02.020]   of the total number of columns
[01:32:02.020 --> 01:32:04.540]   that contain at least one of the ones.
[01:32:04.540 --> 01:32:09.020]   So that is an example of the same principle
[01:32:09.020 --> 01:32:13.340]   that was used in studying random sampling.
[01:32:13.340 --> 01:32:18.340]   Another viewpoint is that if you have a phenomenon
[01:32:18.340 --> 01:32:21.400]   that occurs almost all the time,
[01:32:21.400 --> 01:32:27.580]   then if you sample one of the occasions where it occurs,
[01:32:27.580 --> 01:32:32.620]   you're most likely to, and you're looking for an occurrence,
[01:32:32.620 --> 01:32:34.820]   a random occurrence is likely to work.
[01:32:34.820 --> 01:32:39.420]   So that comes up in solving identities,
[01:32:39.420 --> 01:32:42.660]   solving algebraic identities.
[01:32:42.660 --> 01:32:46.460]   You get two formulas that may look very different.
[01:32:46.460 --> 01:32:48.960]   You wanna know if they're really identical.
[01:32:48.960 --> 01:32:52.860]   What you can do is just pick a random value
[01:32:52.860 --> 01:32:55.980]   and evaluate the formulas at that value
[01:32:55.980 --> 01:32:58.820]   and seeing if they agree.
[01:32:58.820 --> 01:33:01.980]   And you depend on the fact
[01:33:01.980 --> 01:33:04.300]   that if the formulas are distinct,
[01:33:04.300 --> 01:33:06.780]   then they're gonna disagree a lot.
[01:33:06.780 --> 01:33:08.460]   And so therefore a random choice
[01:33:08.460 --> 01:33:10.600]   will exhibit the disagreement.
[01:33:10.600 --> 01:33:15.200]   And if there are many ways for the two to disagree,
[01:33:15.200 --> 01:33:18.540]   and you only need to find one disagreement,
[01:33:18.540 --> 01:33:22.500]   then random choice is likely to yield it.
[01:33:22.500 --> 01:33:23.540]   - And in general,
[01:33:23.540 --> 01:33:26.020]   so we've just talked about randomized algorithms,
[01:33:26.020 --> 01:33:28.620]   but we can look at the probabilistic analysis
[01:33:28.620 --> 01:33:29.700]   of algorithms.
[01:33:29.700 --> 01:33:32.060]   And that gives us an opportunity to step back.
[01:33:32.060 --> 01:33:34.260]   And as we've said,
[01:33:34.260 --> 01:33:37.220]   everything we've been talking about is worst case analysis.
[01:33:37.220 --> 01:33:38.060]   - Right.
[01:33:38.060 --> 01:33:43.060]   - Could you maybe comment on the usefulness
[01:33:43.060 --> 01:33:45.420]   and the power of worst case analysis
[01:33:45.420 --> 01:33:50.420]   versus best case analysis, average case, probabilistic?
[01:33:50.420 --> 01:33:52.760]   How do we think about the future
[01:33:52.760 --> 01:33:55.480]   of theoretical computer science, computer science,
[01:33:56.620 --> 01:33:59.100]   in the kind of analysis we do of algorithms?
[01:33:59.100 --> 01:34:01.620]   Does worst case analysis still have a place,
[01:34:01.620 --> 01:34:02.780]   an important place,
[01:34:02.780 --> 01:34:04.600]   or do we want to try to move forward
[01:34:04.600 --> 01:34:06.700]   towards kind of average case analysis?
[01:34:06.700 --> 01:34:07.540]   - Yeah.
[01:34:07.540 --> 01:34:09.340]   - And what are the challenges there?
[01:34:09.340 --> 01:34:11.580]   - So if worst case analysis shows
[01:34:11.580 --> 01:34:16.140]   that an algorithm is always good, that's fine.
[01:34:16.140 --> 01:34:22.260]   If worst case analysis is used to show
[01:34:23.580 --> 01:34:28.580]   that the problem, that the solution is not always good,
[01:34:28.580 --> 01:34:32.660]   then you have to step back and do something else to ask,
[01:34:32.660 --> 01:34:34.960]   how often will you get a good solution?
[01:34:34.960 --> 01:34:38.060]   - Just to pause on that for a second,
[01:34:38.060 --> 01:34:40.180]   that's so beautifully put,
[01:34:40.180 --> 01:34:43.300]   because I think we tend to judge algorithms.
[01:34:43.300 --> 01:34:46.340]   We throw them in the trash the moment
[01:34:46.340 --> 01:34:48.260]   their worst case is shown to be bad.
[01:34:48.260 --> 01:34:49.100]   - Right.
[01:34:49.100 --> 01:34:50.700]   And that's unfortunate.
[01:34:50.700 --> 01:34:55.700]   I think a good example is going back
[01:34:55.700 --> 01:34:58.860]   to the satisfiability problem.
[01:34:58.860 --> 01:35:04.500]   There are very powerful programs called SAT solvers,
[01:35:04.500 --> 01:35:09.500]   which in practice fairly reliably solve instances
[01:35:09.500 --> 01:35:12.480]   with many millions of variables that arise
[01:35:12.480 --> 01:35:16.180]   in a digital design or in proving programs correct
[01:35:16.180 --> 01:35:17.800]   in other applications.
[01:35:20.220 --> 01:35:24.460]   And so in many application areas,
[01:35:24.460 --> 01:35:25.980]   even though satisfiability,
[01:35:25.980 --> 01:35:29.220]   as we've already discussed, is NP-complete,
[01:35:29.220 --> 01:35:34.820]   the SAT solvers will work so well
[01:35:34.820 --> 01:35:37.780]   that the people in that discipline tend to think
[01:35:37.780 --> 01:35:40.040]   of satisfiability as an easy problem.
[01:35:40.040 --> 01:35:45.220]   So in other words, just for some reason
[01:35:45.220 --> 01:35:47.700]   that we don't entirely understand,
[01:35:47.700 --> 01:35:50.540]   the instances that people formulate
[01:35:50.540 --> 01:35:54.380]   in designing digital circuits or other applications
[01:35:54.380 --> 01:35:59.380]   are such that satisfiability is not hard to check.
[01:35:59.380 --> 01:36:07.400]   And even searching for a satisfying solution
[01:36:07.400 --> 01:36:10.300]   can be done efficiently in practice.
[01:36:10.300 --> 01:36:13.280]   And there are many examples.
[01:36:13.280 --> 01:36:15.620]   For example, we talked about
[01:36:15.620 --> 01:36:17.340]   the traveling salesman problem.
[01:36:17.340 --> 01:36:21.420]   So just to refresh our memories,
[01:36:21.420 --> 01:36:23.580]   the problem is you've got a set of cities,
[01:36:23.580 --> 01:36:27.040]   you have pairwise distances between cities,
[01:36:27.040 --> 01:36:31.460]   and you want to find a tour through all the cities
[01:36:31.460 --> 01:36:36.460]   that minimizes the total cost of all the edges traversed,
[01:36:36.460 --> 01:36:38.980]   all the trips between cities.
[01:36:38.980 --> 01:36:42.040]   The problem is NP-hard,
[01:36:42.040 --> 01:36:46.160]   but people using integer programming codes
[01:36:46.160 --> 01:36:50.480]   together with some other mathematical tricks
[01:36:50.480 --> 01:36:56.600]   can solve geometric instances of the problem
[01:36:56.600 --> 01:36:59.900]   where the cities are, let's say, points in the plane,
[01:36:59.900 --> 01:37:03.320]   and get optimal solutions to problems
[01:37:03.320 --> 01:37:05.300]   with tens of thousands of cities.
[01:37:05.300 --> 01:37:08.460]   Actually, it'll take a few computer months
[01:37:08.460 --> 01:37:10.500]   to solve a problem of that size,
[01:37:10.500 --> 01:37:13.400]   but for problems of size 1,000 or 2,
[01:37:13.400 --> 01:37:16.520]   it'll rapidly get optimal solutions,
[01:37:16.520 --> 01:37:19.200]   provably optimal solutions,
[01:37:19.200 --> 01:37:23.240]   even though, again, we know that it's unlikely
[01:37:23.240 --> 01:37:25.960]   that the traveling salesman problem
[01:37:25.960 --> 01:37:28.640]   can be solved in polynomial time.
[01:37:28.640 --> 01:37:31.040]   - Are there methodologies,
[01:37:31.040 --> 01:37:35.000]   like rigorous systematic methodologies for,
[01:37:35.000 --> 01:37:38.360]   you said in practice.
[01:37:38.360 --> 01:37:40.060]   In practice, this algorithm is pretty good.
[01:37:40.060 --> 01:37:42.200]   Are there systematic ways of saying,
[01:37:42.200 --> 01:37:43.840]   in practice, this one is pretty good?
[01:37:43.840 --> 01:37:46.120]   So in other words, average case analysis,
[01:37:46.120 --> 01:37:49.080]   or you've also mentioned that average case
[01:37:49.080 --> 01:37:50.920]   kind of requires you to understand
[01:37:50.920 --> 01:37:53.760]   what the typical case is, typical instances,
[01:37:53.760 --> 01:37:55.520]   and that might be really difficult.
[01:37:55.520 --> 01:37:56.600]   - That's very difficult.
[01:37:56.600 --> 01:37:59.760]   So after I did my original work
[01:37:59.760 --> 01:38:04.760]   on getting, showing all these problems to be NP-complete,
[01:38:06.560 --> 01:38:09.740]   I looked around for a way to get some,
[01:38:09.740 --> 01:38:13.780]   shed some positive light on combinatorial algorithms,
[01:38:13.780 --> 01:38:16.140]   and what I tried to do was to study
[01:38:16.140 --> 01:38:23.380]   problems, behavior on the average or with high probability,
[01:38:23.380 --> 01:38:26.140]   but I had to make some assumptions
[01:38:26.140 --> 01:38:29.680]   about what's the probability space,
[01:38:29.680 --> 01:38:30.820]   what's the sample space,
[01:38:30.820 --> 01:38:33.820]   what do we mean by typical problems?
[01:38:33.820 --> 01:38:35.260]   That's very hard to say,
[01:38:35.260 --> 01:38:37.680]   so I took the easy way out
[01:38:37.680 --> 01:38:40.500]   and made some very simplistic assumptions.
[01:38:40.500 --> 01:38:42.000]   So I assumed, for example,
[01:38:42.000 --> 01:38:44.420]   that if we were generating a graph
[01:38:44.420 --> 01:38:47.440]   with a certain number of vertices and edges,
[01:38:47.440 --> 01:38:48.920]   then we would generate the graph
[01:38:48.920 --> 01:38:53.840]   by simply choosing one edge at a time at random
[01:38:53.840 --> 01:38:56.820]   until we got the right number of edges.
[01:38:56.820 --> 01:38:59.800]   That's a particular model of random graphs
[01:38:59.800 --> 01:39:02.020]   that has been studied mathematically a lot,
[01:39:02.880 --> 01:39:05.120]   and within that model,
[01:39:05.120 --> 01:39:07.560]   I could prove all kinds of wonderful things,
[01:39:07.560 --> 01:39:10.640]   I and others who also worked on this.
[01:39:10.640 --> 01:39:15.640]   So we could show that we know exactly how many edges
[01:39:15.640 --> 01:39:17.760]   there have to be in order for
[01:39:17.760 --> 01:39:24.060]   there be a so-called Hamiltonian circuit
[01:39:24.060 --> 01:39:29.060]   that's a cycle that visits each vertex exactly once.
[01:39:31.560 --> 01:39:35.240]   We know that if the number of edges
[01:39:35.240 --> 01:39:37.520]   is a little bit more than n log n,
[01:39:37.520 --> 01:39:39.160]   where n is the number of vertices,
[01:39:39.160 --> 01:39:44.000]   then such a cycle is very likely to exist,
[01:39:44.000 --> 01:39:45.680]   and we can give a heuristic
[01:39:45.680 --> 01:39:47.880]   that'll find it with high probability.
[01:39:47.880 --> 01:39:53.880]   And we got the community in which I was working,
[01:39:53.880 --> 01:39:57.180]   got a lot of results along these lines,
[01:39:58.540 --> 01:40:03.540]   but the field tended to be rather lukewarm
[01:40:03.540 --> 01:40:07.340]   about accepting these results as meaningful
[01:40:07.340 --> 01:40:09.900]   because we were making such a simplistic assumption
[01:40:09.900 --> 01:40:13.980]   about the kinds of graphs that we would be dealing with.
[01:40:13.980 --> 01:40:16.020]   So we could show all kinds of wonderful things,
[01:40:16.020 --> 01:40:18.900]   it was a great playground, I enjoyed doing it,
[01:40:18.900 --> 01:40:23.100]   but after a while, I concluded that
[01:40:27.220 --> 01:40:29.060]   it didn't have a lot of bite
[01:40:29.060 --> 01:40:31.320]   in terms of the practical application.
[01:40:31.320 --> 01:40:35.300]   - Okay, so there's too much into the world of toy problems.
[01:40:35.300 --> 01:40:36.140]   - Yeah.
[01:40:36.140 --> 01:40:41.140]   - Okay, but all right, is there a way to find
[01:40:41.140 --> 01:40:45.100]   nice representative real-world impactful instances
[01:40:45.100 --> 01:40:48.840]   of a problem on which demonstrate that an algorithm is good?
[01:40:48.840 --> 01:40:51.380]   So this is kind of like the machine learning world,
[01:40:51.380 --> 01:40:54.220]   that's kind of what they at its best tries to do
[01:40:54.220 --> 01:40:57.940]   is find a dataset from the real world
[01:40:57.940 --> 01:40:59.380]   and show the performance,
[01:40:59.380 --> 01:41:02.780]   all the conferences are all focused
[01:41:02.780 --> 01:41:07.180]   on beating the performance on that real-world dataset.
[01:41:07.180 --> 01:41:10.740]   Is there an equivalent in the complexity analysis?
[01:41:10.740 --> 01:41:12.840]   - Not really.
[01:41:12.840 --> 01:41:19.380]   Don Knuth started to collect examples of graphs
[01:41:19.380 --> 01:41:21.620]   coming from various places,
[01:41:21.620 --> 01:41:26.140]   so he would have a whole zoo of different graphs
[01:41:26.140 --> 01:41:27.260]   that he could choose from
[01:41:27.260 --> 01:41:30.100]   and he could study the performance of algorithms
[01:41:30.100 --> 01:41:31.660]   on different types of graphs.
[01:41:31.660 --> 01:41:37.300]   - But there it's really important and compelling
[01:41:37.300 --> 01:41:39.980]   to be able to define a class of graphs.
[01:41:39.980 --> 01:41:44.060]   The actual act of defining a class of graphs
[01:41:44.060 --> 01:41:44.900]   that you're interested in,
[01:41:44.900 --> 01:41:47.740]   it seems to be a non-trivial step
[01:41:47.740 --> 01:41:49.460]   if we're talking about instances
[01:41:49.460 --> 01:41:51.540]   that we should care about in the real world.
[01:41:51.540 --> 01:41:55.860]   - Yeah, there's nothing available there
[01:41:55.860 --> 01:41:58.780]   that would be analogous to the training set
[01:41:58.780 --> 01:42:00.180]   for supervised learning,
[01:42:00.180 --> 01:42:03.820]   where you sort of assume that the world
[01:42:03.820 --> 01:42:08.820]   has given you a bunch of examples to work with.
[01:42:08.820 --> 01:42:14.580]   We don't really have that for problems,
[01:42:14.580 --> 01:42:18.220]   for combinatorial problems on graphs and networks.
[01:42:18.220 --> 01:42:20.980]   - You know, there's been a huge growth,
[01:42:20.980 --> 01:42:23.980]   a big growth of data sets available.
[01:42:23.980 --> 01:42:28.180]   Do you think some aspect of theoretical computer science,
[01:42:28.180 --> 01:42:30.620]   I might be contradicting my own question while saying it,
[01:42:30.620 --> 01:42:33.400]   but will there be some aspect,
[01:42:33.400 --> 01:42:36.900]   an empirical aspect of theoretical computer science
[01:42:36.900 --> 01:42:41.100]   which will allow the fact that these data sets are huge,
[01:42:41.100 --> 01:42:43.280]   we'll start using them for analysis?
[01:42:45.660 --> 01:42:48.980]   - If you want to say something about a graph algorithm,
[01:42:48.980 --> 01:42:53.860]   you might take a social network like Facebook
[01:42:53.860 --> 01:42:55.540]   and looking at subgraphs of that
[01:42:55.540 --> 01:42:58.740]   and prove something about the Facebook graph
[01:42:58.740 --> 01:43:01.860]   and at the same time be respected
[01:43:01.860 --> 01:43:03.820]   in the theoretical computer science community.
[01:43:03.820 --> 01:43:06.260]   - That hasn't been achieved yet, I'm afraid.
[01:43:06.260 --> 01:43:10.280]   - Is that P equals NP, is that impossible?
[01:43:10.280 --> 01:43:14.580]   Is it impossible to publish a successful paper
[01:43:14.580 --> 01:43:17.060]   in the theoretical computer science community
[01:43:17.060 --> 01:43:22.060]   that shows some performance on a real world data set?
[01:43:22.060 --> 01:43:26.340]   Or is that really just those are two different worlds?
[01:43:26.340 --> 01:43:27.840]   - They haven't really come together.
[01:43:27.840 --> 01:43:31.820]   I would say that there is a field
[01:43:31.820 --> 01:43:35.300]   of experimental algorithmics where people,
[01:43:35.300 --> 01:43:39.940]   sometimes they're given some family of examples.
[01:43:39.940 --> 01:43:42.620]   Sometimes they just generate them at random
[01:43:42.620 --> 01:43:44.860]   and they report on performance,
[01:43:44.860 --> 01:43:51.580]   but there's no convincing evidence
[01:43:51.580 --> 01:43:56.700]   that the sample is representative of anything at all.
[01:43:56.700 --> 01:44:02.500]   - So let me ask in terms of breakthroughs and open problems,
[01:44:02.500 --> 01:44:05.620]   what are the most compelling open problems to you
[01:44:05.620 --> 01:44:08.260]   and what possible breakthroughs do you see in the near term
[01:44:08.260 --> 01:44:11.900]   in terms of theoretical computer science?
[01:44:12.900 --> 01:44:15.460]   - Well, there are all kinds of relationships
[01:44:15.460 --> 01:44:18.920]   among complexity classes that can be studied.
[01:44:18.920 --> 01:44:21.820]   Just to mention one thing,
[01:44:21.820 --> 01:44:26.260]   I wrote a paper with Richard Lipton in 1979
[01:44:26.260 --> 01:44:30.940]   where we asked the following question.
[01:44:30.940 --> 01:44:39.500]   If you take a problem, a combinatorial problem in NP,
[01:44:40.620 --> 01:44:45.620]   let's say, and you choose,
[01:44:45.620 --> 01:44:51.540]   and you pick the size of the problem,
[01:44:51.540 --> 01:44:58.060]   say it's a traveling salesman problem, but of size 52.
[01:44:58.060 --> 01:45:03.460]   And you ask, could you get an efficient,
[01:45:03.460 --> 01:45:08.460]   a small Boolean circuit tailored for that size, 52,
[01:45:09.860 --> 01:45:12.500]   where you could feed the edges of the graph
[01:45:12.500 --> 01:45:16.660]   in as Boolean inputs and get as an output,
[01:45:16.660 --> 01:45:17.940]   the question of whether or not
[01:45:17.940 --> 01:45:20.040]   there's a tour of a certain length.
[01:45:20.040 --> 01:45:23.220]   And that would, in other words,
[01:45:23.220 --> 01:45:25.900]   briefly what you would say in that case
[01:45:25.900 --> 01:45:28.660]   is that the problem has small circuits,
[01:45:28.660 --> 01:45:30.420]   polynomial size circuits.
[01:45:30.420 --> 01:45:35.380]   Now we know that if P is equal to NP,
[01:45:35.380 --> 01:45:39.700]   then in fact, these problems will have small circuits,
[01:45:39.700 --> 01:45:41.340]   but what about the converse?
[01:45:41.340 --> 01:45:43.220]   Could a problem have small circuits,
[01:45:43.220 --> 01:45:45.940]   meaning that an algorithm tailored
[01:45:45.940 --> 01:45:48.540]   to any particular size could work well
[01:45:48.540 --> 01:45:52.220]   and yet not be a polynomial time algorithm?
[01:45:52.220 --> 01:45:53.420]   That is, you couldn't write it
[01:45:53.420 --> 01:45:56.940]   as a single uniform algorithm good for all sizes.
[01:45:56.940 --> 01:45:59.780]   - Just to clarify, small circuits
[01:45:59.780 --> 01:46:02.180]   for a problem of particular size
[01:46:02.180 --> 01:46:03.980]   or even further constraint,
[01:46:03.980 --> 01:46:06.180]   small circuit for a particular--
[01:46:06.180 --> 01:46:09.180]   - No, for all the inputs of that size.
[01:46:09.180 --> 01:46:10.100]   - Of that size.
[01:46:10.100 --> 01:46:13.620]   Is that a trivial problem for a particular instance?
[01:46:13.620 --> 01:46:17.900]   So coming up, an automated way of coming up with a circuit,
[01:46:17.900 --> 01:46:18.740]   I guess that's just--
[01:46:18.740 --> 01:46:21.140]   - That would be hard, yeah.
[01:46:21.140 --> 01:46:25.340]   But there's the existential question.
[01:46:25.340 --> 01:46:28.940]   Everybody talks nowadays about existential questions,
[01:46:28.940 --> 01:46:33.260]   existential challenges.
[01:46:33.260 --> 01:46:37.500]   You could ask the question,
[01:46:38.860 --> 01:46:43.860]   does the Hamiltonian circuit problem
[01:46:43.860 --> 01:46:48.900]   have a small circuit for every size?
[01:46:48.900 --> 01:46:51.780]   For each size, a different small circuit?
[01:46:51.780 --> 01:46:55.620]   In other words, could you tailor solutions
[01:46:55.620 --> 01:47:00.620]   depending on the size and get polynomial size?
[01:47:00.620 --> 01:47:02.660]   - Even if P is not equal to NP.
[01:47:02.660 --> 01:47:03.500]   - Right.
[01:47:03.500 --> 01:47:08.660]   - That would be fascinating if that's true.
[01:47:08.660 --> 01:47:13.660]   - Yeah, what we proved is that if that were possible,
[01:47:13.660 --> 01:47:18.140]   then something strange would happen in complexity theory.
[01:47:18.140 --> 01:47:23.980]   Some high-level class, which I could briefly describe,
[01:47:23.980 --> 01:47:28.420]   something strange would happen.
[01:47:28.420 --> 01:47:33.100]   So I'll take a stab at describing what I mean by that.
[01:47:33.100 --> 01:47:33.980]   - Let's go there.
[01:47:33.980 --> 01:47:37.740]   - So we have to define this hierarchy
[01:47:37.740 --> 01:47:41.500]   in which the first level of the hierarchy is P
[01:47:41.500 --> 01:47:44.140]   and the second level is NP.
[01:47:44.140 --> 01:47:45.340]   And what is NP?
[01:47:45.340 --> 01:47:48.300]   NP involves statements of the form,
[01:47:48.300 --> 01:47:52.380]   there exists a something such that something holds.
[01:47:52.380 --> 01:47:56.740]   So for example,
[01:47:56.740 --> 01:48:01.940]   there exists a coloring such that a graph can be colored
[01:48:01.940 --> 01:48:06.700]   with only that number of colors.
[01:48:06.700 --> 01:48:09.180]   Or there exists a Hamiltonian circuit.
[01:48:09.180 --> 01:48:10.860]   - There's a statement about this graph.
[01:48:10.860 --> 01:48:11.700]   - Yeah.
[01:48:11.700 --> 01:48:22.940]   And NP deals with statements of that kind,
[01:48:22.940 --> 01:48:24.660]   that there exists a solution.
[01:48:24.660 --> 01:48:30.740]   Now you could imagine a more complicated expression,
[01:48:32.700 --> 01:48:37.700]   which says for all X, there exists a Y
[01:48:37.700 --> 01:48:43.700]   such that some proposition holds involving both X and Y.
[01:48:43.700 --> 01:48:50.140]   So that would say, for example, in game theory,
[01:48:50.140 --> 01:48:55.020]   for all strategies for the first player,
[01:48:55.020 --> 01:48:57.820]   there exists a strategy for the second player
[01:48:57.820 --> 01:48:59.620]   such that the first player wins.
[01:48:59.660 --> 01:49:03.460]   That would be at the second level of the hierarchy.
[01:49:03.460 --> 01:49:06.100]   The third level would be, there exists an A
[01:49:06.100 --> 01:49:09.340]   such that for all B, there exists a C that something holds.
[01:49:09.340 --> 01:49:12.820]   And you can imagine going higher and higher in the hierarchy
[01:49:12.820 --> 01:49:17.620]   and you'd expect that the complexity classes
[01:49:17.620 --> 01:49:22.540]   that correspond to those different cases
[01:49:22.540 --> 01:49:25.380]   would get bigger and bigger.
[01:49:25.380 --> 01:49:28.940]   - What do you mean by bigger and bigger?
[01:49:28.940 --> 01:49:31.220]   - Sorry, they'd get harder and harder to solve.
[01:49:31.220 --> 01:49:32.060]   - Harder and harder, right.
[01:49:32.060 --> 01:49:34.180]   - Harder and harder to solve.
[01:49:34.180 --> 01:49:38.100]   And what Lyfton and I showed was that
[01:49:38.100 --> 01:49:41.700]   if NP had small circuits,
[01:49:41.700 --> 01:49:45.500]   then this hierarchy would collapse down to the second level.
[01:49:45.500 --> 01:49:48.500]   In other words, you wouldn't get any more mileage
[01:49:48.500 --> 01:49:51.660]   by complicating your expressions with three quantifiers
[01:49:51.660 --> 01:49:53.620]   or four quantifiers or any number.
[01:49:53.620 --> 01:49:57.860]   - I'm not sure what to make of that exactly.
[01:49:57.860 --> 01:49:59.420]   - Well, I think it would be evidence
[01:49:59.420 --> 01:50:03.060]   that NP doesn't have small circuits
[01:50:03.060 --> 01:50:07.220]   'cause something so bizarre would happen.
[01:50:07.220 --> 01:50:09.140]   But again, it's only evidence, not proof.
[01:50:09.140 --> 01:50:12.660]   - Well, yeah, that's not even evidence
[01:50:12.660 --> 01:50:17.100]   because you're saying P's not equal to NP
[01:50:17.100 --> 01:50:19.700]   because something bizarre has to happen.
[01:50:19.700 --> 01:50:24.700]   I mean, that's proof by the lack of bizarreness
[01:50:25.260 --> 01:50:27.980]   in our science, but it seems like
[01:50:27.980 --> 01:50:33.200]   just the very notion of P equals NP would be bizarre.
[01:50:33.200 --> 01:50:36.340]   So any way you arrive at, there's no way.
[01:50:36.340 --> 01:50:38.580]   You have to fight the dragon at some point.
[01:50:38.580 --> 01:50:40.880]   - Yeah, okay, well, anyway.
[01:50:40.880 --> 01:50:43.420]   For whatever it's worth, that's what we proved.
[01:50:43.420 --> 01:50:47.660]   - Awesome, so that's a potential space
[01:50:47.660 --> 01:50:49.500]   of open, interesting problems.
[01:50:49.500 --> 01:50:53.460]   Let me ask you about this other world
[01:50:54.780 --> 01:50:57.380]   of machine learning, of deep learning.
[01:50:57.380 --> 01:50:59.780]   What's your thoughts on the history
[01:50:59.780 --> 01:51:02.740]   and the current progress of machine learning field
[01:51:02.740 --> 01:51:05.860]   that's often progressed sort of separately
[01:51:05.860 --> 01:51:08.940]   as a space of ideas and space of people
[01:51:08.940 --> 01:51:11.000]   than the theoretical computer science
[01:51:11.000 --> 01:51:12.740]   or just even computer science world?
[01:51:12.740 --> 01:51:15.780]   - Yeah, it's really very different
[01:51:15.780 --> 01:51:17.860]   from the theoretical computer science world
[01:51:17.860 --> 01:51:22.380]   because the results about it,
[01:51:22.380 --> 01:51:25.500]   algorithmic performance tend to be empirical.
[01:51:25.500 --> 01:51:28.980]   It's more akin to the world of SAT solvers
[01:51:28.980 --> 01:51:33.980]   where we observe that for formulas arising in practice,
[01:51:33.980 --> 01:51:36.020]   the solver does well.
[01:51:36.020 --> 01:51:37.780]   So it's of that type.
[01:51:37.780 --> 01:51:42.460]   It's where we're moving into the empirical
[01:51:42.460 --> 01:51:45.420]   evaluation of algorithms.
[01:51:45.420 --> 01:51:47.900]   Now, it's clear that there've been huge successes
[01:51:47.900 --> 01:51:52.860]   in image processing, robotics,
[01:51:52.860 --> 01:51:55.500]   natural language processing, a little less so,
[01:51:55.500 --> 01:52:00.500]   but across the spectrum of game playing is another one.
[01:52:00.500 --> 01:52:02.780]   There've been great successes.
[01:52:02.780 --> 01:52:09.220]   And one of those effects is that it's not too hard
[01:52:09.220 --> 01:52:11.860]   to become a millionaire if you can get a reputation
[01:52:11.860 --> 01:52:13.700]   in machine learning and there'll be all kinds
[01:52:13.700 --> 01:52:16.700]   of companies that will be willing to offer you the moon
[01:52:16.700 --> 01:52:21.700]   because they think that if they have AI at their disposal,
[01:52:21.700 --> 01:52:25.920]   then they can solve all kinds of problems.
[01:52:25.920 --> 01:52:30.640]   But there are limitations.
[01:52:30.640 --> 01:52:38.140]   One is that the solutions that you get
[01:52:38.140 --> 01:52:43.140]   by from to supervise learning problems
[01:52:46.100 --> 01:52:50.380]   through convolutional neural networks
[01:52:50.380 --> 01:52:56.220]   seem to perform amazingly well,
[01:52:56.220 --> 01:52:59.220]   even for inputs that are outside the training set.
[01:52:59.220 --> 01:53:06.340]   But we don't have any theoretical understanding
[01:53:06.340 --> 01:53:07.580]   of why that's true.
[01:53:07.580 --> 01:53:13.500]   Secondly, the solutions, the networks that you get
[01:53:14.620 --> 01:53:16.620]   are very hard to understand.
[01:53:16.620 --> 01:53:18.900]   And so very little insight comes out.
[01:53:18.900 --> 01:53:24.020]   So yeah, yeah, they may seem to work on your training set
[01:53:24.020 --> 01:53:29.020]   and you may be able to discover whether your photos occur
[01:53:29.020 --> 01:53:34.020]   in a different sample of inputs or not,
[01:53:34.020 --> 01:53:37.560]   but we don't really know what's going on.
[01:53:37.560 --> 01:53:41.700]   We don't know the features that distinguish the photographs
[01:53:41.700 --> 01:53:46.700]   or the objects are not easy to characterize.
[01:53:46.700 --> 01:53:51.180]   - Well, it's interesting 'cause you mentioned
[01:53:51.180 --> 01:53:53.820]   coming up with a small circuit
[01:53:53.820 --> 01:53:56.420]   to solve a particular size problem.
[01:53:56.420 --> 01:53:59.940]   It seems that neural networks are kind of small circuits.
[01:53:59.940 --> 01:54:01.420]   - In a way, yeah.
[01:54:01.420 --> 01:54:02.860]   - But they're not programs.
[01:54:02.860 --> 01:54:05.820]   Sort of like the things you've designed are algorithms,
[01:54:05.820 --> 01:54:08.980]   programs, algorithms.
[01:54:08.980 --> 01:54:12.620]   Neural networks aren't able to develop algorithms
[01:54:12.620 --> 01:54:13.820]   to solve a problem.
[01:54:13.820 --> 01:54:15.860]   It's more of a function.
[01:54:15.860 --> 01:54:18.460]   - They are algorithms, it's just that they're--
[01:54:18.460 --> 01:54:25.220]   - But sort of, yeah, it could be a semantic question,
[01:54:25.220 --> 01:54:30.020]   but there's not a algorithmic style
[01:54:30.020 --> 01:54:32.060]   manipulation of the input.
[01:54:32.060 --> 01:54:35.300]   Perhaps you could argue there is.
[01:54:35.300 --> 01:54:37.120]   - Yeah, well--
[01:54:37.120 --> 01:54:40.520]   - It feels a lot more like a function of the input.
[01:54:40.520 --> 01:54:43.220]   - It's a function, it's a computable function.
[01:54:43.220 --> 01:54:48.400]   Once you have the network, you can simulate it
[01:54:48.400 --> 01:54:51.280]   on a given input and figure out the output.
[01:54:51.280 --> 01:54:56.280]   But if you're trying to recognize images,
[01:54:56.280 --> 01:55:00.860]   then you don't know what features of the image
[01:55:00.860 --> 01:55:05.860]   are really being determined by the input.
[01:55:06.580 --> 01:55:09.420]   Determinant of what the circuit is doing.
[01:55:09.420 --> 01:55:13.980]   The circuit is sort of very intricate,
[01:55:13.980 --> 01:55:18.980]   and it's not clear that the simple characteristics
[01:55:18.980 --> 01:55:23.940]   that you're looking for, the edges of the objects
[01:55:23.940 --> 01:55:27.140]   or whatever they may be, they're not emerging
[01:55:27.140 --> 01:55:29.580]   from the structure of the circuit.
[01:55:29.580 --> 01:55:31.060]   - Well, it's not clear to us humans,
[01:55:31.060 --> 01:55:33.000]   but it's clear to the circuit.
[01:55:33.000 --> 01:55:34.860]   - Yeah, well, right.
[01:55:34.860 --> 01:55:39.860]   I mean, it's not clear to sort of the elephant
[01:55:39.860 --> 01:55:46.860]   how the human brain works, but it's clear to us humans,
[01:55:46.860 --> 01:55:49.180]   we can explain to each other our reasoning,
[01:55:49.180 --> 01:55:50.740]   and that's why the cognitive science
[01:55:50.740 --> 01:55:52.740]   and psychology field exists.
[01:55:52.740 --> 01:55:56.280]   Maybe the whole thing of being explainable to humans
[01:55:56.280 --> 01:55:57.700]   is a little bit overrated.
[01:55:57.700 --> 01:55:59.740]   - Oh, maybe, yeah.
[01:55:59.740 --> 01:56:02.460]   I guess you can say the same thing about our brain,
[01:56:02.460 --> 01:56:06.140]   that when we perform acts of cognition,
[01:56:06.140 --> 01:56:07.940]   we have no idea how we do it, really.
[01:56:07.940 --> 01:56:08.780]   - That's true.
[01:56:08.780 --> 01:56:09.620]   - We do, though.
[01:56:09.620 --> 01:56:13.700]   I mean, we, at least for the visual system,
[01:56:13.700 --> 01:56:15.220]   the auditory system, and so on,
[01:56:15.220 --> 01:56:19.260]   we do get some understanding of the principles
[01:56:19.260 --> 01:56:23.500]   that they operate under, but for many deeper
[01:56:23.500 --> 01:56:25.620]   cognitive tasks, we don't have that.
[01:56:25.620 --> 01:56:26.660]   - That's right.
[01:56:26.660 --> 01:56:27.580]   Let me ask.
[01:56:27.580 --> 01:56:28.580]   - Yeah.
[01:56:28.580 --> 01:56:33.020]   - You've also been doing work on bioinformatics.
[01:56:33.020 --> 01:56:37.020]   Does it amaze you that the fundamental building blocks,
[01:56:37.020 --> 01:56:39.860]   so if we take a step back and look at us humans,
[01:56:39.860 --> 01:56:41.820]   the building blocks used by evolution
[01:56:41.820 --> 01:56:44.660]   to build us intelligent human beings
[01:56:44.660 --> 01:56:47.200]   is all contained there in our DNA?
[01:56:47.200 --> 01:56:51.900]   - It's amazing, and what's really amazing
[01:56:51.900 --> 01:56:56.900]   is that we are beginning to learn how to edit,
[01:56:57.420 --> 01:57:02.420]   how to edit DNA, which is very, very fascinating,
[01:57:02.420 --> 01:57:10.580]   this ability to take a sequence,
[01:57:10.580 --> 01:57:18.980]   find it in the genome, and do something to it.
[01:57:18.980 --> 01:57:21.260]   - I mean, that's really taking our biological system
[01:57:21.260 --> 01:57:24.500]   towards the worlds of algorithms.
[01:57:24.500 --> 01:57:27.140]   - Yeah, but it raises a lot of questions.
[01:57:27.140 --> 01:57:33.900]   You have to distinguish between doing it on an individual
[01:57:33.900 --> 01:57:35.740]   or doing it on somebody's germline,
[01:57:35.740 --> 01:57:38.840]   which means that all of their descendants will be affected.
[01:57:38.840 --> 01:57:42.180]   - So that's like an ethical...
[01:57:42.180 --> 01:57:46.060]   - Yeah, so it raises very severe ethical questions,
[01:57:46.060 --> 01:57:52.760]   and even doing it on individuals.
[01:57:53.760 --> 01:57:58.760]   Um, is, there's a lot of hubris involved
[01:57:58.760 --> 01:58:04.200]   that you can assume that knocking out a particular gene
[01:58:04.200 --> 01:58:06.180]   is going to be beneficial because you don't know
[01:58:06.180 --> 01:58:08.120]   what the side effects are going to be.
[01:58:08.120 --> 01:58:14.000]   So we have this wonderful new world of gene editing,
[01:58:20.240 --> 01:58:23.240]   which is very, very impressive,
[01:58:23.240 --> 01:58:27.320]   and it could be used in agriculture,
[01:58:27.320 --> 01:58:31.340]   it could be used in medicine in various ways,
[01:58:31.340 --> 01:58:35.560]   but very serious ethical problems arise.
[01:58:35.560 --> 01:58:39.920]   - What are, to you, the most interesting places
[01:58:39.920 --> 01:58:44.600]   where algorithms, sort of the ethical side,
[01:58:44.600 --> 01:58:46.060]   is an exceptionally challenging thing
[01:58:46.060 --> 01:58:48.080]   that I think we're going to have to tackle
[01:58:48.080 --> 01:58:51.840]   with all of genetic engineering.
[01:58:51.840 --> 01:58:53.760]   But on the algorithmic side,
[01:58:53.760 --> 01:58:55.560]   there's a lot of benefit that's possible.
[01:58:55.560 --> 01:59:00.280]   So is there areas where you see exciting possibilities
[01:59:00.280 --> 01:59:02.640]   for algorithms to help model,
[01:59:02.640 --> 01:59:05.120]   optimize, study biological systems?
[01:59:05.120 --> 01:59:11.720]   - Yeah, I mean, we can certainly analyze genomic data
[01:59:11.720 --> 01:59:17.480]   to figure out which genes are operative in the cell
[01:59:17.480 --> 01:59:18.800]   and under what conditions
[01:59:18.800 --> 01:59:21.300]   and which proteins affect one another,
[01:59:21.300 --> 01:59:26.100]   which proteins physically interact.
[01:59:26.100 --> 01:59:30.660]   We can sequence proteins and modify them.
[01:59:30.660 --> 01:59:33.840]   - Is there some aspect of that
[01:59:33.840 --> 01:59:35.920]   that's a computer science problem,
[01:59:35.920 --> 01:59:39.840]   or is that still fundamentally a biology problem?
[01:59:39.840 --> 01:59:41.600]   - Well, it's a big data,
[01:59:41.600 --> 01:59:44.680]   it's a statistical big data problem for sure.
[01:59:45.700 --> 01:59:48.480]   So, you know, the biological data sets
[01:59:48.480 --> 01:59:53.480]   are increasing our ability to study our ancestry,
[01:59:53.480 --> 01:59:59.940]   to study the tendencies towards disease,
[01:59:59.940 --> 02:00:04.940]   to personalize treatment according to what's in our genomes
[02:00:04.940 --> 02:00:09.320]   and what tendencies for disease we have,
[02:00:09.320 --> 02:00:13.920]   to be able to predict what troubles might come upon us
[02:00:13.920 --> 02:00:16.100]   in the future and anticipate them,
[02:00:16.100 --> 02:00:21.100]   to understand whether you,
[02:00:21.100 --> 02:00:29.340]   for a woman, whether her proclivity for breast cancer
[02:00:29.340 --> 02:00:34.840]   is so strong enough that she would want to take action
[02:00:34.840 --> 02:00:36.640]   to avoid it.
[02:00:36.640 --> 02:00:41.060]   - You dedicate your 1985 Turing Award lecture
[02:00:41.060 --> 02:00:42.580]   to the memory of your father.
[02:00:42.840 --> 02:00:43.680]   - Mm-hmm.
[02:00:43.680 --> 02:00:47.140]   - What's your fondest memory of your dad?
[02:00:47.140 --> 02:00:56.160]   - Seeing him standing in front of a class
[02:00:56.160 --> 02:01:00.840]   at the blackboard, drawing perfect circles by hand,
[02:01:00.840 --> 02:01:08.720]   and showing his ability to attract the interest
[02:01:11.420 --> 02:01:14.760]   of the motley collection of eighth grade students
[02:01:14.760 --> 02:01:15.820]   that he was teaching.
[02:01:15.820 --> 02:01:21.640]   - When did you get a chance to see him
[02:01:21.640 --> 02:01:23.080]   draw the perfect circles?
[02:01:23.080 --> 02:01:27.480]   - On rare occasions, I would get a chance
[02:01:27.480 --> 02:01:32.480]   to sneak into his classroom and observe it.
[02:01:32.480 --> 02:01:36.320]   And I think he was at his best in the classroom.
[02:01:36.320 --> 02:01:38.120]   I think he really came to life
[02:01:40.820 --> 02:01:43.880]   and had fun not only teaching,
[02:01:43.880 --> 02:01:48.880]   but engaging in chit-chat with the students
[02:01:48.880 --> 02:01:53.800]   and ingratiating himself with the students.
[02:01:53.800 --> 02:01:57.120]   And what I inherited from that
[02:01:57.120 --> 02:02:01.920]   is a great desire to be a teacher.
[02:02:01.920 --> 02:02:06.920]   I retired recently and a lot of my former students came,
[02:02:08.360 --> 02:02:11.240]   students with whom I had done research
[02:02:11.240 --> 02:02:14.800]   or who had read my papers or who had been in my classes.
[02:02:14.800 --> 02:02:19.860]   And when they talked about me,
[02:02:19.860 --> 02:02:27.560]   they talked not about my 1979 paper or my 1992 paper,
[02:02:27.560 --> 02:02:33.600]   but about what came away in my classes.
[02:02:33.600 --> 02:02:36.400]   And not just the details, but just the approach
[02:02:36.400 --> 02:02:39.400]   and the manner of teaching.
[02:02:39.400 --> 02:02:43.600]   And so I sort of take pride in the,
[02:02:43.600 --> 02:02:47.680]   at least in my early years as a faculty member at Berkeley,
[02:02:47.680 --> 02:02:51.760]   I was exemplary in preparing my lectures
[02:02:51.760 --> 02:02:56.760]   and I always came in prepared to the teeth
[02:02:56.760 --> 02:02:58.960]   and able therefore to deviate
[02:02:58.960 --> 02:03:01.240]   according to what happened in the class
[02:03:01.240 --> 02:03:06.240]   and to really provide a model
[02:03:06.840 --> 02:03:08.760]   for the students.
[02:03:08.760 --> 02:03:12.120]   - So is there advice you can give out
[02:03:12.120 --> 02:03:16.480]   for others on how to be a good teacher?
[02:03:16.480 --> 02:03:19.000]   So preparation is one thing you've mentioned,
[02:03:19.000 --> 02:03:20.440]   being exceptionally well prepared,
[02:03:20.440 --> 02:03:21.520]   but are there other things,
[02:03:21.520 --> 02:03:24.460]   pieces of advice that you can impart?
[02:03:24.460 --> 02:03:26.600]   - Well, the top three would be preparation,
[02:03:26.600 --> 02:03:28.160]   preparation, and preparation.
[02:03:28.160 --> 02:03:29.720]   (laughing)
[02:03:29.720 --> 02:03:31.920]   - Why is preparation so important, I guess?
[02:03:31.920 --> 02:03:34.400]   - It's because it gives you the ease
[02:03:34.400 --> 02:03:38.680]   to deal with any situation that comes up in the classroom.
[02:03:38.680 --> 02:03:43.680]   And if you discover that you're not getting through
[02:03:43.680 --> 02:03:45.840]   one way, you can do it another way.
[02:03:45.840 --> 02:03:47.280]   If the students have questions,
[02:03:47.280 --> 02:03:48.960]   you can handle the questions.
[02:03:48.960 --> 02:03:53.960]   - Ultimately, you're also feeling the crowd,
[02:03:53.960 --> 02:03:57.080]   the students of what they're struggling with,
[02:03:57.080 --> 02:03:57.940]   what they're picking up,
[02:03:57.940 --> 02:03:59.740]   just looking at them through the questions,
[02:03:59.740 --> 02:04:01.440]   but even just through their eyes.
[02:04:01.440 --> 02:04:02.280]   - Yeah, that's right.
[02:04:02.280 --> 02:04:05.440]   - So the preparation, you can dance.
[02:04:05.440 --> 02:04:09.880]   - You can dance, you can say it another way,
[02:04:09.880 --> 02:04:11.680]   give it another angle.
[02:04:11.680 --> 02:04:14.840]   - Are there, in particular, ideas and algorithms
[02:04:14.840 --> 02:04:17.120]   of computer science that you find
[02:04:17.120 --> 02:04:19.960]   were big aha moments for students,
[02:04:19.960 --> 02:04:22.800]   where they, for some reason, once they got it,
[02:04:22.800 --> 02:04:24.760]   it clicked for them and they fell in love
[02:04:24.760 --> 02:04:26.680]   with computer science?
[02:04:26.680 --> 02:04:29.360]   Or is it individual, is it different for everybody?
[02:04:29.360 --> 02:04:30.880]   - It's different for everybody.
[02:04:30.880 --> 02:04:33.080]   You have to work differently with students.
[02:04:33.080 --> 02:04:38.080]   Some of them just don't need much influence.
[02:04:38.080 --> 02:04:42.400]   They're just running with what they're doing
[02:04:42.400 --> 02:04:44.880]   and they just need an ear now and then.
[02:04:44.880 --> 02:04:47.280]   Others need a little prodding.
[02:04:47.280 --> 02:04:49.960]   Others need to be persuaded to collaborate
[02:04:49.960 --> 02:04:52.500]   among themselves rather than working alone.
[02:04:52.500 --> 02:04:57.200]   They have their personal ups and downs.
[02:04:57.200 --> 02:05:02.200]   So you have to deal with each student as a human being
[02:05:02.200 --> 02:05:06.640]   and bring out the best.
[02:05:06.640 --> 02:05:08.160]   - Humans are complicated.
[02:05:08.160 --> 02:05:09.240]   - Yeah.
[02:05:09.240 --> 02:05:11.240]   - Perhaps a silly question.
[02:05:11.240 --> 02:05:15.400]   If you could relive a moment in your life outside of family
[02:05:15.400 --> 02:05:17.440]   because it made you truly happy,
[02:05:17.440 --> 02:05:19.920]   or perhaps because it changed the direction of your life
[02:05:19.920 --> 02:05:23.560]   in a profound way, what moment would you pick?
[02:05:24.640 --> 02:05:28.280]   - I was kind of a lazy student as an undergraduate
[02:05:28.280 --> 02:05:32.500]   and even in my first year in graduate school.
[02:05:32.500 --> 02:05:37.360]   And I think it was when I started doing research.
[02:05:37.360 --> 02:05:41.560]   I had a couple of summer jobs where I was able to contribute
[02:05:41.560 --> 02:05:45.080]   and I had an idea.
[02:05:45.080 --> 02:05:47.800]   And then there was one particular course
[02:05:47.800 --> 02:05:50.560]   on mathematical methods and operations research
[02:05:50.560 --> 02:05:53.640]   where I just gobbled up the material
[02:05:53.640 --> 02:05:57.600]   and I scored 20 points higher than anybody else in the class
[02:05:57.600 --> 02:06:00.720]   then came to the attention of the faculty.
[02:06:00.720 --> 02:06:04.640]   And it made me realize that I had some ability
[02:06:04.640 --> 02:06:06.160]   that was going somewhere.
[02:06:06.160 --> 02:06:11.560]   - You realize you're pretty good at this thing.
[02:06:11.560 --> 02:06:14.360]   I don't think there's a better way to end it, Richard.
[02:06:14.360 --> 02:06:15.280]   It was a huge honor.
[02:06:15.280 --> 02:06:18.280]   Thank you for decades of incredible work.
[02:06:18.280 --> 02:06:19.120]   Thank you for talking to me.
[02:06:19.120 --> 02:06:21.120]   - Thank you, it's been a great pleasure.
[02:06:21.120 --> 02:06:23.760]   You're a superb interviewer.
[02:06:23.760 --> 02:06:25.040]   (laughing)
[02:06:25.040 --> 02:06:25.880]   - I'll stop it.
[02:06:25.880 --> 02:06:29.640]   Thanks for listening to this conversation with Richard Karp
[02:06:29.640 --> 02:06:34.160]   and thank you to our sponsors, Eight Sleep and Cash App.
[02:06:34.160 --> 02:06:35.920]   Please consider supporting this podcast
[02:06:35.920 --> 02:06:39.160]   by going to eightsleep.com/lex
[02:06:39.160 --> 02:06:41.960]   to check out their awesome mattress
[02:06:41.960 --> 02:06:46.080]   and downloading Cash App and using code LEXPODCAST.
[02:06:46.080 --> 02:06:49.840]   Click the links, buy the stuff, even just visiting the site
[02:06:49.840 --> 02:06:52.440]   but also considering the purchase helps them know
[02:06:52.440 --> 02:06:55.880]   that this podcast is worth supporting in the future.
[02:06:55.880 --> 02:06:59.680]   It really is the best way to support this journey I'm on.
[02:06:59.680 --> 02:07:02.080]   If you enjoy this thing, subscribe on YouTube,
[02:07:02.080 --> 02:07:04.120]   review it with Five Stars and Apple Podcast,
[02:07:04.120 --> 02:07:07.360]   support it on Patreon, connect with me on Twitter
[02:07:07.360 --> 02:07:11.320]   at Lex Friedman if you can figure out how to spell that.
[02:07:11.320 --> 02:07:16.000]   And now let me leave you with some words from Isaac Asimov.
[02:07:16.000 --> 02:07:18.200]   I do not fear computers.
[02:07:18.200 --> 02:07:19.820]   I fear lack of them.
[02:07:19.820 --> 02:07:23.720]   Thank you for listening and hope to see you next time.
[02:07:23.720 --> 02:07:26.300]   (upbeat music)
[02:07:26.300 --> 02:07:28.880]   (upbeat music)
[02:07:28.880 --> 02:07:38.880]   [BLANK_AUDIO]

