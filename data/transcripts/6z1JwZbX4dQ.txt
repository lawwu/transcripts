
[00:00:00.000 --> 00:00:02.720]   The following is a conversation with Po Shen Lo,
[00:00:02.720 --> 00:00:06.300]   a professor of mathematics at Carnegie Mellon University,
[00:00:06.300 --> 00:00:09.960]   national coach of the USA International Math Olympia Team,
[00:00:09.960 --> 00:00:11.920]   and founder of XP,
[00:00:11.920 --> 00:00:15.260]   that does online education of basic math and science.
[00:00:15.260 --> 00:00:17.080]   He's also the founder of Novid,
[00:00:17.080 --> 00:00:19.560]   an app that takes a really interesting approach
[00:00:19.560 --> 00:00:20.800]   to contact tracing,
[00:00:20.800 --> 00:00:23.120]   making sure you stay completely anonymous,
[00:00:23.120 --> 00:00:25.880]   and it gives you statistical information about COVID cases
[00:00:25.880 --> 00:00:28.920]   in your physical network of interactions.
[00:00:28.920 --> 00:00:31.680]   So you can maintain privacy, very important,
[00:00:31.680 --> 00:00:34.240]   and make informed decisions.
[00:00:34.240 --> 00:00:37.000]   In my opinion, we desperately needed solutions like this
[00:00:37.000 --> 00:00:38.800]   in early 2020.
[00:00:38.800 --> 00:00:41.480]   And unfortunately, I think,
[00:00:41.480 --> 00:00:44.760]   we will again need it for the next pandemic.
[00:00:44.760 --> 00:00:46.960]   To me, solutions that require large-scale,
[00:00:46.960 --> 00:00:49.680]   distributed coordination of human beings
[00:00:49.680 --> 00:00:53.480]   need ideas that emphasize freedom and knowledge.
[00:00:53.480 --> 00:00:55.160]   Quick mention of our sponsors,
[00:00:55.160 --> 00:00:58.760]   Jordan Harbinger Show, Onnit, BetterHelp,
[00:00:58.760 --> 00:01:01.240]   8sleep, and Element.
[00:01:01.240 --> 00:01:04.360]   Check them out in the description to support this podcast.
[00:01:04.360 --> 00:01:07.160]   As a side note, let me say that Po and I
[00:01:07.160 --> 00:01:08.440]   filmed a few short videos
[00:01:08.440 --> 00:01:10.660]   about simple, beautiful math concepts
[00:01:10.660 --> 00:01:12.980]   that I will release soon.
[00:01:12.980 --> 00:01:14.120]   It was really fun.
[00:01:14.120 --> 00:01:16.680]   I really enjoyed Po sharing his passion for math with me
[00:01:16.680 --> 00:01:17.880]   in those videos.
[00:01:17.880 --> 00:01:20.000]   I'm hoping to do a few more short videos
[00:01:20.000 --> 00:01:23.180]   in the coming months that are educational in nature,
[00:01:23.180 --> 00:01:26.560]   on AI, robotics, math, science, philosophy,
[00:01:26.560 --> 00:01:28.880]   or if all else fails,
[00:01:28.880 --> 00:01:31.280]   just fun snippets into my life on music,
[00:01:31.280 --> 00:01:34.760]   books, martial arts, and other random things,
[00:01:34.760 --> 00:01:38.260]   if that's of interest to anyone at all.
[00:01:38.260 --> 00:01:40.240]   This is the Lex Figman Podcast,
[00:01:40.240 --> 00:01:42.980]   and here's my conversation with Po Shenlo.
[00:01:42.980 --> 00:01:46.540]   You know, you mentioned you really enjoy flying
[00:01:46.540 --> 00:01:49.760]   and experiencing different people in different places.
[00:01:49.760 --> 00:01:51.200]   There's something about flying for me,
[00:01:51.200 --> 00:01:53.120]   I don't know if you have the same experience,
[00:01:53.120 --> 00:01:55.720]   that every time I get on an airplane,
[00:01:55.720 --> 00:01:58.080]   it's incredible to me that human beings
[00:01:58.080 --> 00:02:00.280]   have actually been able to achieve this.
[00:02:00.280 --> 00:02:03.760]   And when I look at what's happening now
[00:02:03.760 --> 00:02:06.440]   with humans traveling out into space,
[00:02:06.440 --> 00:02:08.120]   I see it as all the same thing.
[00:02:08.120 --> 00:02:11.280]   It's incredible that humans are able to get into a box
[00:02:11.280 --> 00:02:16.280]   and fly in the air and safely and land.
[00:02:16.280 --> 00:02:18.080]   And the same, it seems like,
[00:02:18.080 --> 00:02:19.960]   and everybody's taking it for granted.
[00:02:19.960 --> 00:02:22.520]   So when I observe them, it's quite fascinating
[00:02:22.520 --> 00:02:25.920]   because I see that cleanly mapping to the world
[00:02:25.920 --> 00:02:30.920]   where we're now in rockets and traveling to the moon,
[00:02:30.920 --> 00:02:34.360]   traveling to Mars, and at the same kind of way,
[00:02:34.360 --> 00:02:36.480]   I can already see the future
[00:02:36.480 --> 00:02:38.700]   where we will all take it for granted.
[00:02:38.700 --> 00:02:43.600]   So I don't know if you have, you personally,
[00:02:43.600 --> 00:02:46.440]   when you fly, have the same kind of magical experience
[00:02:46.440 --> 00:02:49.100]   of how the heck did humans actually accomplish this?
[00:02:49.100 --> 00:02:51.880]   - So I do, especially when there's turbulence.
[00:02:52.600 --> 00:02:55.240]   Which is, you know, like on the way here,
[00:02:55.240 --> 00:02:58.120]   there was turbulence and the plane jiggled,
[00:02:58.120 --> 00:03:00.280]   even the flight attendant had to hold on to the side.
[00:03:00.280 --> 00:03:01.400]   And I was just thinking to myself,
[00:03:01.400 --> 00:03:03.280]   it's amazing that this happens all the time
[00:03:03.280 --> 00:03:04.480]   and the wings don't fall off,
[00:03:04.480 --> 00:03:06.680]   you know, given how many planes are flying.
[00:03:06.680 --> 00:03:08.560]   But then I often think about it and I'm like,
[00:03:08.560 --> 00:03:09.880]   you know, a long time ago,
[00:03:09.880 --> 00:03:12.200]   I think people didn't trust elevators
[00:03:12.200 --> 00:03:14.440]   in a 40-story building in New York City.
[00:03:14.440 --> 00:03:17.080]   And now we just take it completely for granted
[00:03:17.080 --> 00:03:18.640]   that you can step into this shaft,
[00:03:18.640 --> 00:03:21.560]   which is 40 floors up and down.
[00:03:21.560 --> 00:03:23.220]   And it will just not fail.
[00:03:23.220 --> 00:03:26.800]   - Yeah, again, I'm the same way with elevators,
[00:03:26.800 --> 00:03:28.160]   but also buildings.
[00:03:28.160 --> 00:03:31.640]   When I'll stand on the 40th floor and wonder
[00:03:31.640 --> 00:03:35.360]   how the heck are we not falling right now?
[00:03:35.360 --> 00:03:39.160]   Like how amazing it is with the high winds,
[00:03:39.160 --> 00:03:42.260]   like structurally just the earthquakes and the vibrations,
[00:03:42.260 --> 00:03:44.560]   I mean, natural vibrations in the ground.
[00:03:44.560 --> 00:03:47.000]   Like how is this, how are all of these,
[00:03:47.000 --> 00:03:48.080]   you go to like New York City,
[00:03:48.080 --> 00:03:49.960]   all of these buildings standing.
[00:03:49.960 --> 00:03:52.160]   I mean, to me, one of the most beautiful things,
[00:03:52.160 --> 00:03:54.800]   actually mathematically too, is bridges.
[00:03:54.800 --> 00:03:57.600]   I used to build bridges in high school from like toothpicks,
[00:03:57.600 --> 00:04:02.400]   just like out of the pure joy of like physics
[00:04:02.400 --> 00:04:05.840]   making some structure really strong.
[00:04:05.840 --> 00:04:09.640]   Understanding like from a civil engineering perspective,
[00:04:09.640 --> 00:04:12.080]   what kind of structure will be stronger
[00:04:12.080 --> 00:04:14.880]   than another kind of structure, like suspension bridges.
[00:04:14.880 --> 00:04:17.200]   And then you see that at scale,
[00:04:17.200 --> 00:04:20.440]   humans being able to span a body of water
[00:04:20.440 --> 00:04:22.280]   with a giant bridge.
[00:04:22.280 --> 00:04:26.520]   And it's, I don't know, it's so humbling.
[00:04:26.520 --> 00:04:31.520]   It makes you realize how dependent we are on each other.
[00:04:31.520 --> 00:04:33.400]   Sort of, I talk about level up,
[00:04:33.400 --> 00:04:37.980]   but there's a certain element in which we little ants
[00:04:37.980 --> 00:04:39.660]   have just a small amount of knowledge
[00:04:39.660 --> 00:04:41.920]   about our particular thing.
[00:04:41.920 --> 00:04:45.400]   And then we're depending on a network of knowledge
[00:04:45.400 --> 00:04:47.440]   that other experts hold.
[00:04:47.440 --> 00:04:49.280]   And then most of our lives,
[00:04:49.280 --> 00:04:51.160]   most of the quality of life we have
[00:04:51.160 --> 00:04:56.160]   has to do with the richness of that network of knowledge,
[00:04:56.160 --> 00:04:58.360]   of that collaboration,
[00:04:58.360 --> 00:05:02.040]   and then sort of the ability to build on top of it.
[00:05:02.040 --> 00:05:03.280]   Levels of abstractions.
[00:05:03.280 --> 00:05:05.800]   You start from like bits in a computer,
[00:05:05.800 --> 00:05:07.520]   then you can have assembly,
[00:05:07.520 --> 00:05:08.840]   then you can have C++,
[00:05:08.840 --> 00:05:10.000]   or you have an operating system,
[00:05:10.000 --> 00:05:11.760]   then you can have C++ and Python,
[00:05:11.760 --> 00:05:13.480]   finally some machine learning on top.
[00:05:13.480 --> 00:05:15.000]   All of these are abstractions.
[00:05:15.000 --> 00:05:17.160]   And eventually we'll have AI that runs all of us humans.
[00:05:17.160 --> 00:05:21.320]   But anyway, but speaking of abstractions and programming,
[00:05:21.320 --> 00:05:26.120]   in high school you wrote some impressive games for MS-DOS.
[00:05:26.120 --> 00:05:28.840]   I got a chance to, in browser somehow, it's magic.
[00:05:28.840 --> 00:05:30.540]   I got a chance to play them.
[00:05:30.540 --> 00:05:34.640]   Alien Attack 1, 2, 3, and 4.
[00:05:34.640 --> 00:05:37.280]   What's the hardest part about programming those games?
[00:05:37.280 --> 00:05:38.440]   And maybe can you tell the story
[00:05:38.440 --> 00:05:41.120]   about building those games?
[00:05:41.120 --> 00:05:41.960]   - Sure.
[00:05:41.960 --> 00:05:44.280]   I actually tried to do those in high school
[00:05:44.280 --> 00:05:46.280]   because I was just curious if I could.
[00:05:46.280 --> 00:05:48.080]   Yeah.
[00:05:48.080 --> 00:05:49.280]   - That's a good starting point for anything, right?
[00:05:49.280 --> 00:05:50.120]   - Yeah, yeah, yeah.
[00:05:50.120 --> 00:05:50.960]   It's like, could you?
[00:05:50.960 --> 00:05:52.040]   But the appealing thing was also,
[00:05:52.040 --> 00:05:54.200]   it was a soup to nuts kind of thing.
[00:05:54.200 --> 00:05:55.880]   So something that has always attracted me
[00:05:55.880 --> 00:05:58.460]   is I like beautiful ideas.
[00:05:58.460 --> 00:05:59.960]   I like seeing beautiful ideas,
[00:05:59.960 --> 00:06:03.800]   but I actually also like seeing execution of an idea
[00:06:03.800 --> 00:06:06.400]   all the way from beginning to end in something that works.
[00:06:06.400 --> 00:06:08.040]   So for example, in high school,
[00:06:08.040 --> 00:06:10.920]   I was lucky enough to grow up in the late '90s
[00:06:10.920 --> 00:06:13.320]   when even a high school student
[00:06:13.320 --> 00:06:16.240]   could hope to make something sort of comparable
[00:06:16.240 --> 00:06:18.720]   to the shareware games that were out there.
[00:06:18.720 --> 00:06:21.280]   I say the word sort of, like still quite far away,
[00:06:21.280 --> 00:06:25.040]   but at least I didn't need to hire a 3D CG artist.
[00:06:25.040 --> 00:06:27.240]   There weren't enough pixels to draw anyway,
[00:06:27.240 --> 00:06:28.400]   even I can draw, right?
[00:06:28.400 --> 00:06:30.320]   Bad art, of course.
[00:06:30.320 --> 00:06:31.680]   But the point is I wanted to know,
[00:06:31.680 --> 00:06:34.660]   is it possible for me to try to do those things
[00:06:34.660 --> 00:06:36.580]   where back in those days,
[00:06:36.580 --> 00:06:38.440]   you didn't even have an easy way
[00:06:38.440 --> 00:06:41.200]   to draw letters on the screen in a particular font.
[00:06:41.200 --> 00:06:42.880]   You couldn't just say import a font.
[00:06:42.880 --> 00:06:44.080]   It wasn't like Python.
[00:06:44.080 --> 00:06:45.440]   So for example, back then,
[00:06:45.440 --> 00:06:47.560]   if you play those games in the web browser,
[00:06:47.560 --> 00:06:51.800]   which is emulating the old school computer,
[00:06:51.800 --> 00:06:53.520]   those, even the letters you see,
[00:06:53.520 --> 00:06:55.120]   those are made by individual calls
[00:06:55.120 --> 00:06:56.800]   to draw pixels on the screen.
[00:06:56.800 --> 00:06:58.320]   - So you built that from scratch,
[00:06:58.320 --> 00:07:01.000]   almost building a computer graphics library from scratch?
[00:07:01.000 --> 00:07:01.840]   - Yes.
[00:07:01.840 --> 00:07:03.120]   The primitive that I got to use
[00:07:03.120 --> 00:07:05.600]   was some code I copied off of a book in assembly
[00:07:05.600 --> 00:07:08.680]   of how to put a pixel on a screen in a particular color.
[00:07:08.680 --> 00:07:11.760]   - And the programming language was Pascal?
[00:07:11.760 --> 00:07:12.720]   - Ah, yeah.
[00:07:12.720 --> 00:07:14.440]   The first one was in Pascal,
[00:07:14.440 --> 00:07:18.200]   but then the other ones were in C++ after that.
[00:07:18.200 --> 00:07:20.720]   - How's the emulation in the browser work, by the way?
[00:07:20.720 --> 00:07:21.680]   Is that trivial?
[00:07:21.680 --> 00:07:22.560]   'Cause it's pretty cool.
[00:07:22.560 --> 00:07:23.560]   You get to play these games
[00:07:23.560 --> 00:07:26.520]   that have a very much 90s feeling to them.
[00:07:26.520 --> 00:07:29.360]   - Ah, so it's literally making an MS-DOS environment,
[00:07:29.360 --> 00:07:32.280]   which is literally running the old .exe file.
[00:07:32.280 --> 00:07:33.120]   Wow, I didn't have to do that.
[00:07:33.120 --> 00:07:33.960]   - In the browser.
[00:07:33.960 --> 00:07:37.840]   That could be more amazing than the airplane.
[00:07:37.840 --> 00:07:40.280]   So it wasn't so much about the video games.
[00:07:40.280 --> 00:07:41.400]   It was more about,
[00:07:41.400 --> 00:07:44.120]   can you build something really cool from scratch?
[00:07:44.120 --> 00:07:45.440]   - Yes.
[00:07:45.440 --> 00:07:50.280]   - And you did a bunch of programming competitions.
[00:07:50.280 --> 00:07:54.080]   What was your interest, your love for programming?
[00:07:54.080 --> 00:07:56.880]   What did you learn through that experience?
[00:07:56.880 --> 00:07:59.680]   Especially now that much of your work
[00:07:59.680 --> 00:08:02.240]   has taken a long journey through mathematics.
[00:08:02.240 --> 00:08:04.920]   - I think I always was amazed
[00:08:04.920 --> 00:08:08.440]   by how computers could do things fast.
[00:08:08.440 --> 00:08:11.560]   If I wanted to make it an abstract analysis
[00:08:11.560 --> 00:08:14.600]   of why it is that I saw some power in the computer.
[00:08:14.600 --> 00:08:16.360]   Because if the computer can do things
[00:08:16.360 --> 00:08:18.280]   so many times faster than humans,
[00:08:18.280 --> 00:08:20.240]   where the hard part is telling the computer
[00:08:20.240 --> 00:08:21.840]   what to do and how to do it,
[00:08:21.840 --> 00:08:23.840]   if you can master that,
[00:08:23.840 --> 00:08:25.560]   asking the computer what to do,
[00:08:25.560 --> 00:08:28.200]   then you could conceivably achieve more things.
[00:08:28.200 --> 00:08:29.640]   And those contests I was in,
[00:08:29.640 --> 00:08:31.840]   those were the opposite in some sense
[00:08:31.840 --> 00:08:34.120]   of making a complete product,
[00:08:34.120 --> 00:08:35.880]   like a game is a product.
[00:08:35.880 --> 00:08:38.560]   Those contests were effectively write a function
[00:08:38.560 --> 00:08:40.800]   to do something extremely efficiently.
[00:08:40.800 --> 00:08:42.480]   And if you are able to do that,
[00:08:42.480 --> 00:08:45.800]   then you can unlock more of the power of the computer.
[00:08:45.800 --> 00:08:47.440]   - But also doing it quickly.
[00:08:47.440 --> 00:08:49.640]   There's a time element from the human perspective
[00:08:49.640 --> 00:08:53.400]   to be able to program quickly.
[00:08:53.400 --> 00:08:54.880]   There's something nice.
[00:08:54.880 --> 00:08:57.920]   So there's an almost like an athletics component
[00:08:57.920 --> 00:09:01.280]   to where you're almost like an athlete
[00:09:01.280 --> 00:09:03.920]   seeking optimal performance as a human being
[00:09:03.920 --> 00:09:05.680]   trying to write these programs.
[00:09:05.680 --> 00:09:06.520]   And at the same time,
[00:09:06.520 --> 00:09:08.840]   it's kind of art because you're,
[00:09:08.840 --> 00:09:11.080]   the best way to write a program quickly
[00:09:11.080 --> 00:09:13.440]   is to write a simple program.
[00:09:13.440 --> 00:09:14.840]   You still have a damn good solution.
[00:09:14.840 --> 00:09:17.040]   So it's not necessarily you have to type fast.
[00:09:17.040 --> 00:09:19.520]   You have to think through a really clean,
[00:09:19.520 --> 00:09:22.760]   beautiful solution.
[00:09:22.760 --> 00:09:26.080]   I mean, what do you think is the use
[00:09:26.080 --> 00:09:27.760]   of those programming competitions?
[00:09:27.760 --> 00:09:29.160]   Do you think they're ultimately something
[00:09:29.160 --> 00:09:30.600]   you would recommend for students,
[00:09:30.600 --> 00:09:32.000]   for people interested in programming
[00:09:32.000 --> 00:09:33.960]   or people interested in building stuff?
[00:09:33.960 --> 00:09:34.800]   - Yes.
[00:09:34.800 --> 00:09:37.120]   I think so because especially with the work
[00:09:37.120 --> 00:09:38.120]   that I've been doing nowadays,
[00:09:38.120 --> 00:09:40.240]   even trying to control COVID,
[00:09:40.240 --> 00:09:42.600]   something that was very helpful from day one
[00:09:42.600 --> 00:09:45.600]   was understanding that the kinds of computations
[00:09:45.600 --> 00:09:47.120]   we would want to do,
[00:09:47.120 --> 00:09:50.480]   we could conceivably do on like a four core cloud machine
[00:09:50.480 --> 00:09:53.800]   on Amazon web services out to a population
[00:09:53.800 --> 00:09:55.320]   which might have hundreds of thousands
[00:09:55.320 --> 00:09:56.520]   or millions of people.
[00:09:56.520 --> 00:09:57.880]   The reason why that was important
[00:09:57.880 --> 00:10:00.800]   to have that back of the envelope calculation
[00:10:00.800 --> 00:10:02.760]   with efficient algorithms
[00:10:02.760 --> 00:10:05.000]   is because if we couldn't do that,
[00:10:05.000 --> 00:10:06.320]   then we would bankrupt ourselves
[00:10:06.320 --> 00:10:08.200]   before we could get to a big enough scale.
[00:10:08.200 --> 00:10:11.520]   If you think about how you grow anything from small to big,
[00:10:11.520 --> 00:10:13.640]   if in order to grow it from small to big,
[00:10:13.640 --> 00:10:16.480]   you also already need 10,000 cloud servers,
[00:10:16.480 --> 00:10:17.680]   you'll never get to big.
[00:10:17.680 --> 00:10:22.360]   - And also the nice thing about programming competitions
[00:10:22.360 --> 00:10:26.440]   is that you actually build a thing that works.
[00:10:26.440 --> 00:10:28.080]   So you finish it.
[00:10:28.080 --> 00:10:30.800]   There's a completion thing and you realize,
[00:10:30.800 --> 00:10:32.560]   I think there's a magic to it
[00:10:32.560 --> 00:10:35.560]   where you realize that it's not so hard
[00:10:35.560 --> 00:10:37.560]   to build something that works.
[00:10:37.560 --> 00:10:40.600]   To have a system that successfully takes in inputs
[00:10:40.600 --> 00:10:43.400]   and produces outputs and solves a difficult problem
[00:10:43.400 --> 00:10:46.560]   and that directly transfers to building a startup,
[00:10:46.560 --> 00:10:50.040]   essentially that can help some aspect of this world
[00:10:50.040 --> 00:10:53.880]   as long as it's mostly based on software engineering.
[00:10:53.880 --> 00:10:55.000]   Things get really tricky
[00:10:55.000 --> 00:10:56.760]   when you have to manufacture stuff.
[00:10:56.760 --> 00:11:00.760]   That's why people like Elon Musk are so impressive
[00:11:00.760 --> 00:11:02.880]   that it's not just software.
[00:11:02.880 --> 00:11:05.360]   Tesla Autopilot is not just software.
[00:11:05.360 --> 00:11:07.680]   It's like you have to actually have factories
[00:11:07.680 --> 00:11:11.440]   that build cars and there's a million components
[00:11:11.440 --> 00:11:14.320]   involved in the machinery required
[00:11:14.320 --> 00:11:16.200]   to assemble those cars and so on.
[00:11:16.200 --> 00:11:19.040]   But in software, one person can change the world,
[00:11:19.040 --> 00:11:21.440]   which is incredible.
[00:11:21.440 --> 00:11:23.240]   But on the mathematics side,
[00:11:23.240 --> 00:11:26.760]   what if you look back or maybe today,
[00:11:26.760 --> 00:11:29.680]   what made you fall in love with mathematics?
[00:11:29.680 --> 00:11:33.320]   - For me, I think I've always been very attracted
[00:11:33.320 --> 00:11:35.720]   to challenge, as I already indicated
[00:11:35.720 --> 00:11:37.320]   with writing the program.
[00:11:37.320 --> 00:11:40.440]   I guess if I see something that's hard
[00:11:40.440 --> 00:11:41.960]   or supposed to be impossible,
[00:11:41.960 --> 00:11:45.720]   sometimes I say, "Maybe I want to see
[00:11:45.720 --> 00:11:47.120]   "if I can pull that off."
[00:11:47.120 --> 00:11:49.920]   And with the mathematics, the math competitions
[00:11:49.920 --> 00:11:53.560]   presented problems that were hard,
[00:11:53.560 --> 00:11:55.040]   that I didn't know how to start,
[00:11:55.040 --> 00:11:57.640]   but for which I could conceivably try to learn
[00:11:57.640 --> 00:11:59.120]   how to solve them.
[00:11:59.120 --> 00:12:00.480]   So, I mean, there are other things that are hard
[00:12:00.480 --> 00:12:03.360]   called like get something to Mars, get people to Mars.
[00:12:03.360 --> 00:12:05.840]   And I didn't, and I still don't think
[00:12:05.840 --> 00:12:08.200]   that I'm able to solve that problem.
[00:12:08.200 --> 00:12:10.000]   On the other hand, the math problems struck me
[00:12:10.000 --> 00:12:11.440]   as things which are hard
[00:12:11.440 --> 00:12:13.560]   and with significant amount of extra work,
[00:12:13.560 --> 00:12:14.760]   I could figure it out.
[00:12:14.760 --> 00:12:16.560]   And maybe they would actually even be useful.
[00:12:16.560 --> 00:12:18.960]   Like that mathematical skill is the core
[00:12:18.960 --> 00:12:20.240]   of lots of other things.
[00:12:20.240 --> 00:12:23.720]   - That's really interesting.
[00:12:23.720 --> 00:12:25.120]   Maybe you could speak to that
[00:12:25.120 --> 00:12:28.560]   because a lot of people say that math is hard.
[00:12:29.480 --> 00:12:31.640]   As a kind of negative statement.
[00:12:31.640 --> 00:12:35.160]   It always seemed to me a little bit like
[00:12:35.160 --> 00:12:37.400]   that's kind of a positive statement
[00:12:37.400 --> 00:12:40.400]   that all things that are worth having in this world,
[00:12:40.400 --> 00:12:41.480]   they're hard.
[00:12:41.480 --> 00:12:44.520]   I mean, everything that people think about
[00:12:44.520 --> 00:12:46.440]   that they would love to do,
[00:12:46.440 --> 00:12:49.960]   whether it's sports, whether it's art, music,
[00:12:49.960 --> 00:12:52.760]   and all the sciences,
[00:12:52.760 --> 00:12:56.560]   it's going to be hard if you want to do something special.
[00:12:56.560 --> 00:12:59.040]   So is there something you could say to that idea
[00:12:59.040 --> 00:13:00.200]   that math is hard?
[00:13:00.200 --> 00:13:03.880]   Should it be made easy or should it be hard?
[00:13:03.880 --> 00:13:07.160]   - So I think maybe I want to dig in a little bit
[00:13:07.160 --> 00:13:09.680]   onto this hard part and say,
[00:13:09.680 --> 00:13:12.120]   I think the interesting thing about the math
[00:13:12.120 --> 00:13:14.800]   is that you can see a question
[00:13:14.800 --> 00:13:18.240]   that you didn't know how to start doing it before.
[00:13:18.240 --> 00:13:20.920]   And over a course of thinking about it,
[00:13:20.920 --> 00:13:24.440]   you can come up with a way to solve it.
[00:13:24.440 --> 00:13:26.000]   And so you can move from a state
[00:13:26.000 --> 00:13:28.200]   of not being able to do something
[00:13:28.200 --> 00:13:30.320]   to a state of being able to do something
[00:13:30.320 --> 00:13:33.320]   where you help to take yourself through that
[00:13:33.320 --> 00:13:37.640]   instead of somebody else spoon feeding you that technique.
[00:13:37.640 --> 00:13:39.520]   So actually here, I'm already digging into
[00:13:39.520 --> 00:13:42.080]   maybe part of my teaching philosophy also,
[00:13:42.080 --> 00:13:45.440]   which is that I actually don't want to ever
[00:13:45.440 --> 00:13:48.040]   just tell somebody, here's how you do something.
[00:13:48.040 --> 00:13:52.200]   I actually prefer to say, here's an interesting question.
[00:13:52.200 --> 00:13:54.280]   I know you don't quite know how to do it.
[00:13:54.280 --> 00:13:55.440]   Do you have any ideas?
[00:13:55.440 --> 00:13:58.960]   I'm actually explaining another way
[00:13:58.960 --> 00:14:00.440]   that you could try to do teaching.
[00:14:00.440 --> 00:14:03.080]   And I'm contrasting this to a method of,
[00:14:03.080 --> 00:14:06.360]   watch me do this, now practice it 20 times.
[00:14:06.360 --> 00:14:09.080]   I'm trying to say a lot of people consider math to be hard
[00:14:09.080 --> 00:14:10.800]   because maybe they can't remember
[00:14:10.800 --> 00:14:12.800]   all of the methods that were taught.
[00:14:12.800 --> 00:14:15.560]   But for me, I look at the hardness
[00:14:15.560 --> 00:14:17.600]   and I don't think of it as a memory hardness.
[00:14:17.600 --> 00:14:21.960]   I think of it as a, can you invent something hardness?
[00:14:21.960 --> 00:14:24.360]   And I think that if we can teach more people
[00:14:24.360 --> 00:14:28.680]   how to do that art of invention in a pure cognitive way,
[00:14:28.680 --> 00:14:31.280]   not as hard as the actual hardware stuff, right?
[00:14:31.280 --> 00:14:32.680]   But like in terms of the concepts
[00:14:32.680 --> 00:14:34.040]   and the thoughts and the mathematics,
[00:14:34.040 --> 00:14:36.400]   teaching people how to invent,
[00:14:36.400 --> 00:14:38.880]   then suddenly, actually they might not even find math
[00:14:38.880 --> 00:14:42.680]   to be that tiresomeness hard anymore,
[00:14:42.680 --> 00:14:45.440]   but that rewardingness hard of,
[00:14:45.440 --> 00:14:48.440]   I have the capability of looking at something
[00:14:48.440 --> 00:14:49.920]   which I don't know what to do
[00:14:49.920 --> 00:14:51.400]   and coming up with how to do it.
[00:14:51.400 --> 00:14:52.840]   I actually think we should be doing that,
[00:14:52.840 --> 00:14:55.040]   giving people that capability.
[00:14:55.040 --> 00:14:58.160]   - So hard in the same way that invention is hard,
[00:14:58.160 --> 00:14:59.520]   that is ultimately rewarding.
[00:14:59.520 --> 00:15:03.640]   So maybe you can dig in that a little bit longer,
[00:15:03.640 --> 00:15:08.640]   which is, do you see basically the way to teach math
[00:15:08.640 --> 00:15:14.840]   is to present a problem and to give a person a chance
[00:15:14.840 --> 00:15:17.000]   to try to invent a solution
[00:15:17.000 --> 00:15:21.080]   with minimum amount of information first?
[00:15:21.080 --> 00:15:22.840]   Is that basically,
[00:15:22.840 --> 00:15:26.400]   how do you build that muscle of invention in a student?
[00:15:26.400 --> 00:15:27.840]   - Yes, so the way that,
[00:15:27.840 --> 00:15:30.120]   I guess I have two different sort of ways
[00:15:30.120 --> 00:15:30.960]   that I try to teach.
[00:15:30.960 --> 00:15:32.960]   Actually, one of them is, in fact, this semester,
[00:15:32.960 --> 00:15:35.560]   because all my classes were remotely delivered.
[00:15:35.560 --> 00:15:37.200]   I even threw them all onto my YouTube channel.
[00:15:37.200 --> 00:15:39.960]   So you can see how I teach at Carnegie Mellon.
[00:15:39.960 --> 00:15:43.240]   But I'd often say, "Hey, everyone, let's try to do this.
[00:15:43.240 --> 00:15:44.680]   "Any ideas?"
[00:15:44.680 --> 00:15:47.760]   And that actually changes my role as a professor
[00:15:47.760 --> 00:15:50.040]   from a person who shows up for class
[00:15:50.040 --> 00:15:52.480]   with a script of what I want to talk through.
[00:15:52.480 --> 00:15:54.000]   I actually, I don't have a script.
[00:15:54.000 --> 00:15:55.680]   The way I show up for classes,
[00:15:55.680 --> 00:15:58.080]   there's something that we want to learn how to do,
[00:15:58.080 --> 00:16:00.120]   and we're going to do it by improv.
[00:16:00.120 --> 00:16:02.760]   I'm talking about the same method as improv comedy,
[00:16:02.760 --> 00:16:05.240]   which is where you tell me some ideas
[00:16:05.240 --> 00:16:07.040]   and I'll try to yes and them.
[00:16:07.040 --> 00:16:08.360]   (both laughing)
[00:16:08.360 --> 00:16:09.320]   You know what I mean?
[00:16:09.320 --> 00:16:11.880]   And then together, we're going to come up with a proof
[00:16:11.880 --> 00:16:15.000]   of this concept where you were deeply involved
[00:16:15.000 --> 00:16:16.360]   in creating the proof.
[00:16:16.360 --> 00:16:18.040]   Actually, every time I teach the class,
[00:16:18.040 --> 00:16:19.800]   we do every proof slightly differently
[00:16:19.800 --> 00:16:23.360]   because it's based on how the students came up with it.
[00:16:23.360 --> 00:16:25.760]   And that's how I do it when I'm in person.
[00:16:25.760 --> 00:16:27.880]   I also have another line of courses that we make
[00:16:27.880 --> 00:16:29.200]   that is delivered online.
[00:16:29.200 --> 00:16:31.640]   Those things are where I can't do it live,
[00:16:31.640 --> 00:16:34.560]   but the teaching method became also similar.
[00:16:34.560 --> 00:16:37.080]   It was just, "Here's an interesting question.
[00:16:37.080 --> 00:16:38.160]   "I know it's out of reach.
[00:16:38.160 --> 00:16:39.400]   "Why don't you think about it?"
[00:16:39.400 --> 00:16:42.240]   And then automatic hints, we feed automatically hints
[00:16:42.240 --> 00:16:46.720]   through the internet to go and let the person try to invent.
[00:16:47.560 --> 00:16:52.240]   So that's like a more rigorous prodding of invention.
[00:16:52.240 --> 00:16:56.000]   But you did mention disease and COVID
[00:16:56.000 --> 00:16:58.160]   and you've been doing some very interesting stuff
[00:16:58.160 --> 00:17:01.920]   from a mathematical, but also software engineering angle
[00:17:01.920 --> 00:17:04.520]   of coming up with ideas.
[00:17:04.520 --> 00:17:07.360]   It's back to the, "I see a problem.
[00:17:07.360 --> 00:17:08.720]   "I think I can help."
[00:17:08.720 --> 00:17:11.120]   So you stepped into this world.
[00:17:11.120 --> 00:17:13.840]   Can you tell me about your work there
[00:17:13.840 --> 00:17:18.840]   under the flag of Novid and both the software
[00:17:18.840 --> 00:17:21.640]   and the technical details of how the thing works?
[00:17:21.640 --> 00:17:22.480]   - Sure, sure.
[00:17:22.480 --> 00:17:24.480]   So first I want to make sure that I say,
[00:17:24.480 --> 00:17:25.960]   this is actually team effort.
[00:17:25.960 --> 00:17:27.440]   I happen to be the one speaking,
[00:17:27.440 --> 00:17:29.040]   but there's no way this would exist
[00:17:29.040 --> 00:17:30.560]   without an incredible team of people
[00:17:30.560 --> 00:17:33.120]   who inspire me every day to work on this.
[00:17:33.120 --> 00:17:34.560]   But I'll speak on behalf of them.
[00:17:34.560 --> 00:17:39.560]   So the idea was indeed that we stepped forward
[00:17:39.560 --> 00:17:41.400]   in March of last year,
[00:17:41.440 --> 00:17:43.320]   when the world started to become,
[00:17:43.320 --> 00:17:44.800]   our part of the world started to become,
[00:17:44.800 --> 00:17:46.360]   our part meaning the United States,
[00:17:46.360 --> 00:17:48.920]   started to become paralyzed by COVID.
[00:17:48.920 --> 00:17:50.760]   The shutdown started to happen.
[00:17:50.760 --> 00:17:54.280]   And at that time, it started as a figment of an idea,
[00:17:54.280 --> 00:17:57.160]   which was network theory,
[00:17:57.160 --> 00:17:59.520]   which is the area of math that I work in,
[00:17:59.520 --> 00:18:02.480]   could potentially be combined with smartphones
[00:18:02.480 --> 00:18:06.040]   and some kind of health information, anonymized.
[00:18:06.040 --> 00:18:07.080]   Exactly how?
[00:18:07.080 --> 00:18:07.960]   We didn't know yet.
[00:18:07.960 --> 00:18:09.440]   We tried to crystallize it.
[00:18:09.440 --> 00:18:11.400]   And many months into this work,
[00:18:11.400 --> 00:18:15.240]   we ended up accidentally discovering a new way
[00:18:15.240 --> 00:18:17.000]   to control diseases,
[00:18:17.000 --> 00:18:20.880]   which is now what is the main impetus of all of this work,
[00:18:20.880 --> 00:18:23.480]   is to take this idea and polish it
[00:18:23.480 --> 00:18:25.000]   and hopefully have it be useful,
[00:18:25.000 --> 00:18:27.440]   not only now, but for future pandemics.
[00:18:27.440 --> 00:18:29.720]   The idea is really simple to describe.
[00:18:29.720 --> 00:18:31.120]   Actually, my main thing in the world
[00:18:31.120 --> 00:18:33.760]   is I come up with obvious observations.
[00:18:33.760 --> 00:18:35.120]   That's, I'll explain it now.
[00:18:35.120 --> 00:18:36.920]   - Einstein did the same thing
[00:18:36.920 --> 00:18:38.520]   and he wrote a few short papers.
[00:18:38.960 --> 00:18:41.800]   - But so the idea is like this.
[00:18:41.800 --> 00:18:46.480]   If we describe how usually people control disease,
[00:18:46.480 --> 00:18:47.960]   for a lot of history,
[00:18:47.960 --> 00:18:51.000]   it was that you'd find out who was sick,
[00:18:51.000 --> 00:18:53.280]   you'd find out who they have been around,
[00:18:53.280 --> 00:18:56.120]   and you try to remove all of those people from society
[00:18:56.120 --> 00:18:57.200]   against their will.
[00:18:57.200 --> 00:18:58.040]   - Yes.
[00:18:58.040 --> 00:18:58.960]   - Now that's the problem.
[00:18:58.960 --> 00:19:00.880]   The against their will part
[00:19:00.880 --> 00:19:03.560]   gives you the wrong kind of a feedback loop,
[00:19:03.560 --> 00:19:05.520]   which makes it hard to control the disease
[00:19:05.520 --> 00:19:07.000]   because then the people you're trying to control
[00:19:07.000 --> 00:19:08.760]   keep getting other people sick.
[00:19:08.760 --> 00:19:10.120]   You can see already how I'm thinking
[00:19:10.120 --> 00:19:11.960]   and talking about this, feedback loops.
[00:19:11.960 --> 00:19:14.240]   This is actually related to something you said earlier
[00:19:14.240 --> 00:19:17.160]   about even like how skyscrapers stay in the air.
[00:19:17.160 --> 00:19:19.400]   The whole point is control theory.
[00:19:19.400 --> 00:19:22.640]   You actually want to, or even how an airplane stays,
[00:19:22.640 --> 00:19:24.920]   you need to have control loops
[00:19:24.920 --> 00:19:27.080]   which are feedbacking in the right way.
[00:19:27.080 --> 00:19:29.920]   And what we observed was that the feedback control loop
[00:19:29.920 --> 00:19:32.160]   for controlling disease by asking people
[00:19:32.160 --> 00:19:34.520]   to be removed from society against their will
[00:19:34.520 --> 00:19:35.600]   was not working.
[00:19:35.600 --> 00:19:37.640]   It was running against human incentives,
[00:19:37.640 --> 00:19:40.200]   and you suddenly are trying to control 7 billion,
[00:19:40.200 --> 00:19:43.640]   8 billion people in ways that they don't individually want
[00:19:43.640 --> 00:19:45.200]   to necessarily do.
[00:19:45.200 --> 00:19:46.160]   So here's the idea.
[00:19:46.160 --> 00:19:49.480]   And this is inspired by the fact that at the core of our team
[00:19:49.480 --> 00:19:51.280]   were user experience designers.
[00:19:51.280 --> 00:19:53.920]   That's actually, in fact, the first thing I knew we needed
[00:19:53.920 --> 00:19:57.160]   when we started was to bring user experience at the core.
[00:19:57.160 --> 00:19:58.160]   Okay.
[00:19:58.160 --> 00:20:03.160]   But so the idea was, suppose hypothetically,
[00:20:03.160 --> 00:20:05.320]   there was a pandemic.
[00:20:05.320 --> 00:20:07.040]   What would you want?
[00:20:07.040 --> 00:20:10.280]   You would want a way to be able to live your life
[00:20:10.280 --> 00:20:13.640]   as much as possible and avoid getting sick.
[00:20:13.640 --> 00:20:17.400]   Can we make an app to help you avoid getting sick?
[00:20:17.400 --> 00:20:19.680]   Notice how I've just articulated the problem.
[00:20:19.680 --> 00:20:21.840]   It is not, can we make an app
[00:20:21.840 --> 00:20:24.720]   so that after you are around somebody who's sick,
[00:20:24.720 --> 00:20:27.080]   you can be removed from society.
[00:20:27.080 --> 00:20:30.520]   It's, can we make an app so that you can avoid getting sick?
[00:20:30.520 --> 00:20:32.360]   That would run a positive,
[00:20:32.360 --> 00:20:35.360]   I don't know if I want to call it positive or negative,
[00:20:35.360 --> 00:20:36.880]   but it would run a good feedback loop.
[00:20:36.880 --> 00:20:37.720]   Okay.
[00:20:37.720 --> 00:20:38.880]   So then how would you do this?
[00:20:38.880 --> 00:20:41.520]   The only problem is that you don't know who's sick
[00:20:41.520 --> 00:20:44.160]   because especially with this disease,
[00:20:44.160 --> 00:20:47.000]   if I see somebody who looks perfectly healthy,
[00:20:47.000 --> 00:20:50.040]   the disease spreads two days before you have any symptoms.
[00:20:50.040 --> 00:20:52.400]   And so it's actually not possible.
[00:20:52.400 --> 00:20:54.800]   That's where the network theory comes in.
[00:20:54.800 --> 00:20:56.600]   You caught it from someone.
[00:20:56.600 --> 00:21:00.240]   What if we changed the paradigm and we said,
[00:21:00.240 --> 00:21:02.440]   whenever there's a sickness,
[00:21:02.440 --> 00:21:06.200]   tell everybody how many physical relationships
[00:21:06.200 --> 00:21:08.000]   separate them from the sickness.
[00:21:08.000 --> 00:21:09.680]   That is the trivial idea we added.
[00:21:09.680 --> 00:21:13.360]   The trivial idea was the distance between you and a disease
[00:21:13.360 --> 00:21:16.600]   is not measured in feet or seconds.
[00:21:16.600 --> 00:21:19.040]   It's measured in terms of how many
[00:21:19.040 --> 00:21:22.040]   close physical relationships separate you,
[00:21:22.040 --> 00:21:25.400]   like these six degrees of separation, like LinkedIn.
[00:21:25.400 --> 00:21:26.480]   Simple idea.
[00:21:26.480 --> 00:21:28.080]   What if we told everyone that?
[00:21:28.080 --> 00:21:30.200]   It turns out that actually unlocks
[00:21:30.200 --> 00:21:33.040]   some interesting behavioral feedback loops,
[00:21:33.040 --> 00:21:37.000]   which for example, let me now jump to a non-COVID example
[00:21:37.000 --> 00:21:39.240]   to show why this maybe could be useful.
[00:21:39.240 --> 00:21:40.920]   Actually, we think it could be quite useful.
[00:21:40.920 --> 00:21:44.080]   Imagine there was Ebola or some hemorrhagic fever.
[00:21:44.080 --> 00:21:47.040]   Imagine it spread through contact, through the air, in fact.
[00:21:47.040 --> 00:21:48.120]   Pretend, pretend.
[00:21:48.120 --> 00:21:52.720]   That's a disastrous disease.
[00:21:52.720 --> 00:21:54.680]   It has high fatality rate.
[00:21:54.680 --> 00:21:59.120]   And as you die, you're bleeding out of every orifice.
[00:21:59.120 --> 00:22:01.440]   Okay?
[00:22:01.440 --> 00:22:02.400]   - Yeah, not pleasant.
[00:22:02.400 --> 00:22:03.240]   - Not pleasant.
[00:22:03.240 --> 00:22:06.560]   So the question is, suppose that such a disease broke,
[00:22:06.560 --> 00:22:10.400]   who would want to install an app that would tell them
[00:22:10.400 --> 00:22:12.600]   how many relationships away from them
[00:22:12.600 --> 00:22:14.200]   this disease had struck?
[00:22:14.200 --> 00:22:16.240]   - A lot of people.
[00:22:16.240 --> 00:22:17.080]   - A lot of people.
[00:22:17.080 --> 00:22:20.480]   In fact, almost, I don't want to say almost everyone.
[00:22:20.480 --> 00:22:21.400]   That's a very strong statement,
[00:22:21.400 --> 00:22:23.200]   but a very large number of people.
[00:22:23.200 --> 00:22:24.600]   - That's fascinating framing.
[00:22:24.600 --> 00:22:28.400]   Like the more deadly and transmissible the disease,
[00:22:28.400 --> 00:22:32.520]   the stronger the incentive to install it in a positive sense,
[00:22:32.520 --> 00:22:36.400]   in the good feedback loop sense.
[00:22:36.400 --> 00:22:37.600]   That's a really good example.
[00:22:37.600 --> 00:22:38.920]   It's a really good way to frame it.
[00:22:38.920 --> 00:22:42.640]   'Cause with COVID, it was not as deadly
[00:22:42.640 --> 00:22:45.440]   as potential pandemics could have been,
[00:22:45.440 --> 00:22:46.320]   viruses could have been.
[00:22:46.320 --> 00:22:49.200]   So it's sometimes muddled with how we think about it.
[00:22:49.200 --> 00:22:50.840]   But yeah, this is a really good framing.
[00:22:50.840 --> 00:22:53.760]   If the virus was a lot more deadly,
[00:22:53.760 --> 00:22:56.320]   you want to create a system that has a set of incentives
[00:22:56.320 --> 00:22:59.440]   that it quickly spreads to the population
[00:22:59.440 --> 00:23:01.000]   where everybody is using it
[00:23:01.000 --> 00:23:04.240]   and is contributing in a positive way to the system.
[00:23:04.240 --> 00:23:05.080]   - Exactly.
[00:23:05.080 --> 00:23:06.120]   And actually that point you just made,
[00:23:06.120 --> 00:23:07.800]   I don't take credit for that observation.
[00:23:07.800 --> 00:23:09.760]   There was another person I talked to who pointed out
[00:23:09.760 --> 00:23:12.840]   that it's very interesting that this feedback loop
[00:23:12.840 --> 00:23:17.000]   is even more effective when the disease is worse.
[00:23:17.000 --> 00:23:19.400]   And that's actually not a bad characteristic
[00:23:19.400 --> 00:23:20.680]   to have in your feedback loop.
[00:23:20.680 --> 00:23:24.360]   If you're trying to help civilization keep running.
[00:23:24.360 --> 00:23:27.360]   - Yeah, it's really, it's dynamic.
[00:23:27.360 --> 00:23:29.360]   Like people figure out,
[00:23:29.360 --> 00:23:31.960]   they dynamically figure out how bad the disease is.
[00:23:31.960 --> 00:23:35.120]   The more it spreads and the deadlier it is
[00:23:35.120 --> 00:23:37.240]   as the people observe it,
[00:23:37.240 --> 00:23:39.680]   as long as the spread of information,
[00:23:39.680 --> 00:23:43.480]   like semantic information, natural language information,
[00:23:43.480 --> 00:23:46.080]   is closely aligned with the reality of the disease,
[00:23:46.080 --> 00:23:48.280]   which is a whole nother conversation, right?
[00:23:49.880 --> 00:23:51.040]   Maybe we'll chat about that,
[00:23:51.040 --> 00:23:53.840]   how we sort of make sure there's not misinformation
[00:23:53.840 --> 00:23:55.000]   where there's accurate information.
[00:23:55.000 --> 00:23:58.880]   But that aside, okay, so this is a really nice property.
[00:23:58.880 --> 00:23:59.720]   - Right.
[00:23:59.720 --> 00:24:00.920]   And just going on on that,
[00:24:00.920 --> 00:24:02.840]   actually just talking more about what that could do
[00:24:02.840 --> 00:24:04.480]   and why we're so excited about it,
[00:24:04.480 --> 00:24:07.400]   it's that not only would people want to install it,
[00:24:07.400 --> 00:24:09.720]   what would they do?
[00:24:09.720 --> 00:24:11.960]   If you start to see that this disease
[00:24:11.960 --> 00:24:13.160]   is getting closer and closer,
[00:24:13.160 --> 00:24:15.080]   we surveyed informally people,
[00:24:15.080 --> 00:24:18.600]   but they said as we saw it getting closer, we would hide.
[00:24:18.600 --> 00:24:21.840]   We would try to not have contacts.
[00:24:21.840 --> 00:24:24.120]   But now you notice what this has just achieved.
[00:24:24.120 --> 00:24:27.440]   The whole goal on this whole exercise was
[00:24:27.440 --> 00:24:29.760]   you got the people who might be sick
[00:24:29.760 --> 00:24:32.040]   and you got everyone else, set A and set B.
[00:24:32.040 --> 00:24:33.400]   Set A is the people who might be sick,
[00:24:33.400 --> 00:24:34.880]   set B is everyone else.
[00:24:34.880 --> 00:24:39.720]   And for the entirety of the past contact tracing approaches,
[00:24:39.720 --> 00:24:43.600]   you tried to get set A to do things that might not be
[00:24:43.600 --> 00:24:44.960]   to their liking or their will,
[00:24:44.960 --> 00:24:46.960]   because that's removing them from society.
[00:24:46.960 --> 00:24:47.800]   - Yes.
[00:24:47.800 --> 00:24:49.040]   - And we found out that there's two ways
[00:24:49.040 --> 00:24:51.160]   to separate set A from set B.
[00:24:51.160 --> 00:24:53.440]   You can also let the people at set B,
[00:24:53.440 --> 00:24:55.760]   at the fringe of set A,
[00:24:55.760 --> 00:24:58.640]   attempt to remove themselves from this interface.
[00:24:58.640 --> 00:25:01.600]   It's the symmetry of A and B separation.
[00:25:01.600 --> 00:25:04.560]   Everyone was looking at A, we look at B,
[00:25:04.560 --> 00:25:07.000]   and suddenly B is in their incentive to do so.
[00:25:07.000 --> 00:25:09.000]   - Beautiful.
[00:25:09.000 --> 00:25:12.000]   So there's a virus that jumps from human to human.
[00:25:12.000 --> 00:25:15.200]   So there's a network sometimes called graph
[00:25:16.280 --> 00:25:18.440]   of the spread of a virus.
[00:25:18.440 --> 00:25:21.680]   It hops from person to person to person to person.
[00:25:21.680 --> 00:25:25.800]   And each one of us individuals are sitting
[00:25:25.800 --> 00:25:28.240]   or plopped into that network.
[00:25:28.240 --> 00:25:31.720]   We have close friends and relations and so on.
[00:25:31.720 --> 00:25:33.000]   It's kind of fascinating to actually think
[00:25:33.000 --> 00:25:33.920]   about this network.
[00:25:33.920 --> 00:25:35.560]   And we can maybe talk about the shapes
[00:25:35.560 --> 00:25:36.760]   of this kind of network.
[00:25:36.760 --> 00:25:39.940]   'Cause I was trying to think exactly this,
[00:25:39.940 --> 00:25:41.440]   like how many people do I,
[00:25:41.440 --> 00:25:43.520]   also I'm kind of an introvert, not kind of,
[00:25:43.520 --> 00:25:45.200]   I'm very much an introvert.
[00:25:45.200 --> 00:25:48.240]   But so can I be explicit about the kind of people
[00:25:48.240 --> 00:25:50.080]   I meet in regular life?
[00:25:50.080 --> 00:25:52.120]   Is the same way it was completely opened up,
[00:25:52.120 --> 00:25:53.280]   there's no pandemic.
[00:25:53.280 --> 00:25:57.040]   There is a kind of network.
[00:25:57.040 --> 00:26:00.240]   Of course, and there's maybe in the graph,
[00:26:00.240 --> 00:26:02.960]   theoretic sense, there's some weights or something
[00:26:02.960 --> 00:26:06.960]   about how close that relationship is
[00:26:06.960 --> 00:26:08.840]   in terms of the frequency of visits,
[00:26:08.840 --> 00:26:11.600]   the duration of visits and all of those kinds of things.
[00:26:11.600 --> 00:26:14.840]   So you're saying we might want to be,
[00:26:14.840 --> 00:26:18.080]   to create on top of that network,
[00:26:18.080 --> 00:26:22.280]   a spread of information to let you know,
[00:26:22.280 --> 00:26:24.440]   as the virus travels through this network,
[00:26:24.440 --> 00:26:26.280]   how close is it getting to you?
[00:26:26.280 --> 00:26:29.280]   And the number of hops away it is on that network
[00:26:29.280 --> 00:26:31.360]   is really powerful information
[00:26:31.360 --> 00:26:34.000]   that creates a positive feedback loop
[00:26:34.000 --> 00:26:37.440]   where you can act essentially anonymously
[00:26:37.440 --> 00:26:41.240]   and on your own.
[00:26:41.240 --> 00:26:44.000]   Like nobody's telling you what to do,
[00:26:44.000 --> 00:26:46.320]   which is really important, is decentralized
[00:26:46.320 --> 00:26:52.240]   and not whatever the opposite of authoritarian is.
[00:26:52.240 --> 00:26:54.720]   But you get to sort of the American way,
[00:26:54.720 --> 00:26:56.400]   you get to choose to do it yourself,
[00:26:56.400 --> 00:26:58.480]   you have the freedom to do it yourself
[00:26:58.480 --> 00:27:00.200]   and you're incentivized to do it.
[00:27:00.200 --> 00:27:01.960]   And you're most likely going to do it
[00:27:01.960 --> 00:27:06.960]   to protect yourself against you getting the disease
[00:27:06.960 --> 00:27:10.040]   as the closer it gets to you
[00:27:10.040 --> 00:27:12.040]   based on the information that you have.
[00:27:12.040 --> 00:27:15.940]   But can you maybe elaborate, first of all, brilliant.
[00:27:15.940 --> 00:27:20.360]   Whenever I saw the thing you're working on,
[00:27:20.360 --> 00:27:21.640]   so forget for COVID,
[00:27:21.640 --> 00:27:25.140]   this is of course really relevant for COVID,
[00:27:25.140 --> 00:27:28.200]   but it's also probably relevant for future diseases as well.
[00:27:28.200 --> 00:27:30.440]   So that was the thing I'm nervous about,
[00:27:30.440 --> 00:27:31.840]   is like if this whole,
[00:27:31.840 --> 00:27:34.720]   if our society shut down because of COVID,
[00:27:34.720 --> 00:27:38.040]   like what the heck is gonna happen
[00:27:38.040 --> 00:27:40.480]   when there's a much deadlier disease?
[00:27:40.480 --> 00:27:43.560]   Like this is disappointing, the whole time,
[00:27:43.560 --> 00:27:45.960]   2020, the whole time I'm just sitting like this,
[00:27:45.960 --> 00:27:49.840]   like is the incompetence of everybody
[00:27:49.840 --> 00:27:53.000]   except the people developing vaccines.
[00:27:53.000 --> 00:27:54.400]   The biologists are the only ones
[00:27:54.400 --> 00:27:56.060]   that got their stuff together.
[00:27:56.060 --> 00:27:58.600]   But in terms of institutions and all that kind of stuff,
[00:27:58.600 --> 00:28:00.720]   it's just been terrible.
[00:28:00.720 --> 00:28:04.080]   But this is exactly the power of information
[00:28:04.080 --> 00:28:05.960]   and the power of information
[00:28:05.960 --> 00:28:08.080]   that doesn't limit personal freedom.
[00:28:08.080 --> 00:28:09.400]   So your idea is brilliant.
[00:28:09.400 --> 00:28:12.680]   Okay, mathematically, can you maybe elaborate
[00:28:12.680 --> 00:28:14.120]   what are we talking about?
[00:28:14.120 --> 00:28:16.480]   Like how do you actually make that work?
[00:28:16.480 --> 00:28:17.680]   What's involved?
[00:28:17.680 --> 00:28:19.720]   - Sure, first I'm gonna reply to something you said
[00:28:19.720 --> 00:28:22.400]   about the freedom inside this,
[00:28:22.400 --> 00:28:24.480]   because actually that was the idea.
[00:28:24.480 --> 00:28:27.320]   The idea is this is game theory, right?
[00:28:27.320 --> 00:28:29.600]   And effectively what we did is analogous
[00:28:29.600 --> 00:28:34.600]   to free market economy as opposed to central planning.
[00:28:34.880 --> 00:28:38.120]   If you just line up the set of incentives correctly
[00:28:38.120 --> 00:28:43.120]   so that people have in their purely selfish behavior
[00:28:43.120 --> 00:28:45.560]   are contributing to the optimization
[00:28:45.560 --> 00:28:47.720]   of the global function, that's it.
[00:28:47.720 --> 00:28:50.420]   And the point of what we do, I guess, in mathematics
[00:28:50.420 --> 00:28:52.800]   is we try to explore the search space
[00:28:52.800 --> 00:28:55.040]   to go and find out as many possibilities as there are.
[00:28:55.040 --> 00:28:58.080]   And in this case, it's an applied search space.
[00:28:58.080 --> 00:29:01.040]   That's why the inputs from design, user experience design
[00:29:01.040 --> 00:29:02.720]   and actual people are important.
[00:29:02.720 --> 00:29:05.760]   But you asked about, I guess, the mathematical
[00:29:05.760 --> 00:29:07.640]   or the technical things underpinning it.
[00:29:07.640 --> 00:29:09.800]   So I think the first thing I'll say is
[00:29:09.800 --> 00:29:11.480]   we wanted to make this thing
[00:29:11.480 --> 00:29:14.760]   not require your personal information.
[00:29:14.760 --> 00:29:17.840]   And so in order to do that, what gave me the confidence
[00:29:17.840 --> 00:29:20.560]   to, I guess, lead our team to run at the beginning
[00:29:20.560 --> 00:29:21.920]   is we saw that this could be done
[00:29:21.920 --> 00:29:23.800]   without using GPS information.
[00:29:23.800 --> 00:29:28.160]   So technically what's going on is if two smartphones,
[00:29:28.160 --> 00:29:29.040]   it's a smartphone app,
[00:29:29.040 --> 00:29:31.460]   if two smartphones have this thing installed,
[00:29:31.460 --> 00:29:34.520]   they just communicate with each other by Bluetooth
[00:29:34.520 --> 00:29:37.160]   to go and find out how far,
[00:29:37.160 --> 00:29:40.280]   they can detect nearby things by Bluetooth.
[00:29:40.280 --> 00:29:42.040]   And then they can find out that these two phones
[00:29:42.040 --> 00:29:44.880]   were approximately such and such distance apart.
[00:29:44.880 --> 00:29:47.660]   And that kind of relative proximity information
[00:29:47.660 --> 00:29:50.640]   is enough to construct this big network.
[00:29:50.640 --> 00:29:53.160]   - Okay, so the physical network is constructed
[00:29:53.160 --> 00:29:56.040]   based on proximity that's through Bluetooth
[00:29:56.040 --> 00:29:59.300]   and you don't have to specify your exact location,
[00:29:59.300 --> 00:30:01.200]   it's the proximity.
[00:30:01.200 --> 00:30:03.280]   - I'm not using the Pythagorean theorem basically.
[00:30:03.280 --> 00:30:05.520]   I mean, if I just knew the GPS coordinates,
[00:30:05.520 --> 00:30:07.280]   we could use the Pythagorean theorem too.
[00:30:07.280 --> 00:30:08.520]   Sorry, that's just how I call it.
[00:30:08.520 --> 00:30:10.480]   Distance formula, whatever you wanna call it.
[00:30:10.480 --> 00:30:13.720]   (both laughing)
[00:30:13.720 --> 00:30:16.760]   - Yeah, so we're not doing the old Pythagorean
[00:30:16.760 --> 00:30:18.740]   based violation of privacy, okay.
[00:30:18.740 --> 00:30:21.240]   (both laughing)
[00:30:21.240 --> 00:30:26.240]   But so is that enough to form,
[00:30:26.240 --> 00:30:28.600]   to give you enough information
[00:30:28.600 --> 00:30:32.880]   about physical connection to another human being?
[00:30:32.880 --> 00:30:35.240]   Is there a time element there?
[00:30:35.240 --> 00:30:37.400]   Is there, so, okay.
[00:30:37.400 --> 00:30:41.560]   That sounds like a really strong, like low hanging fruit.
[00:30:41.560 --> 00:30:42.480]   Like if you have that,
[00:30:42.480 --> 00:30:44.920]   you could probably go really, really far.
[00:30:44.920 --> 00:30:46.880]   My natural question is,
[00:30:46.880 --> 00:30:49.760]   is there extra information you can add on top of that?
[00:30:49.760 --> 00:30:53.520]   Like the duration of the physical proximity?
[00:30:53.520 --> 00:30:56.660]   - So first of all, we actually do estimate the duration,
[00:30:56.660 --> 00:30:58.340]   but the way we estimate the duration
[00:30:58.340 --> 00:31:00.440]   is like how a movie is filmed,
[00:31:00.440 --> 00:31:03.200]   in the sense that every so often, every few minutes,
[00:31:03.200 --> 00:31:04.640]   we check what's nearby.
[00:31:04.640 --> 00:31:06.240]   It's like how a movie is filmed.
[00:31:06.240 --> 00:31:07.960]   You take lots of snapshots.
[00:31:07.960 --> 00:31:11.280]   So there's no way in a battery efficient way
[00:31:11.280 --> 00:31:14.440]   to really keep track of that proximity.
[00:31:14.440 --> 00:31:17.120]   However, fortunately, we're using probability.
[00:31:17.120 --> 00:31:20.120]   The fact is, the paradigm that we're using
[00:31:20.120 --> 00:31:23.200]   is it's not super important if you run into that person
[00:31:23.200 --> 00:31:25.640]   only for 10 minutes at the grocery store.
[00:31:25.640 --> 00:31:27.640]   If that's a stranger that you run into 10 minutes
[00:31:27.640 --> 00:31:28.920]   in this grocery store,
[00:31:28.920 --> 00:31:30.880]   that's not going to be relevant for our paradigm
[00:31:30.880 --> 00:31:33.100]   because our paradigm is not telling you
[00:31:33.100 --> 00:31:35.000]   who were you around before
[00:31:35.000 --> 00:31:38.600]   and might therefore have gotten infected by already.
[00:31:38.600 --> 00:31:40.200]   Ours is about predicting the future.
[00:31:40.200 --> 00:31:42.360]   We change from, I mean, the standard paradigm
[00:31:42.360 --> 00:31:45.200]   was what already happened, quick damage control.
[00:31:45.200 --> 00:31:46.600]   Ours is predict the future.
[00:31:46.600 --> 00:31:49.320]   If you run into that person once in the grocery store today
[00:31:49.320 --> 00:31:50.400]   and never see them again,
[00:31:50.400 --> 00:31:52.540]   it's irrelevant for predicting the future.
[00:31:52.540 --> 00:31:54.820]   And therefore, for ours, what really matters
[00:31:54.820 --> 00:31:57.960]   is the many hours around the other person,
[00:31:57.960 --> 00:32:00.640]   at which point if you're scanning every five to eight minutes
[00:32:00.640 --> 00:32:02.040]   - That's going to come out in the,
[00:32:02.040 --> 00:32:03.240]   like statistically speaking,
[00:32:03.240 --> 00:32:05.400]   it's going to come out as a strong relationship
[00:32:05.400 --> 00:32:08.760]   and a person in the grocery store is going to wash out
[00:32:08.760 --> 00:32:11.120]   as not an important physical relationship.
[00:32:11.120 --> 00:32:13.200]   Okay, I mean, this is brilliant.
[00:32:13.200 --> 00:32:15.880]   What, how difficult is it to make work?
[00:32:15.880 --> 00:32:19.000]   So you said, one, there's the mathematical component
[00:32:19.000 --> 00:32:21.280]   that we just kind of talked about.
[00:32:21.280 --> 00:32:24.000]   And then there's the user experience component.
[00:32:24.000 --> 00:32:26.080]   So how difficult is it to go,
[00:32:26.080 --> 00:32:28.720]   just like you built the video game, "Alien Attack",
[00:32:28.720 --> 00:32:33.800]   from zero to completion, what's involved?
[00:32:33.800 --> 00:32:34.900]   How difficult is it?
[00:32:34.900 --> 00:32:36.720]   - So I'm going to answer that question
[00:32:36.720 --> 00:32:39.360]   in terms of building the product,
[00:32:39.360 --> 00:32:40.860]   but then I'm also going to acknowledge
[00:32:40.860 --> 00:32:44.720]   that just having an app doesn't make it useful
[00:32:44.720 --> 00:32:47.640]   because that's actually maybe the easy part.
[00:32:47.640 --> 00:32:49.400]   If you know what I mean,
[00:32:49.400 --> 00:32:50.300]   there's like all of this stuff
[00:32:50.300 --> 00:32:52.060]   about rollout adoption and awareness,
[00:32:52.060 --> 00:32:53.740]   but let's focus on the app part first.
[00:32:53.740 --> 00:32:56.320]   So that's again, why I said that the team is incredible.
[00:32:56.320 --> 00:32:58.840]   So we have a bunch of people who,
[00:32:58.840 --> 00:33:02.720]   let's just say that the technology that we use to make it
[00:33:02.720 --> 00:33:04.960]   is not the standard way you make an app.
[00:33:04.960 --> 00:33:08.660]   If you think about a standard iOS app or Android app,
[00:33:08.660 --> 00:33:12.080]   those are a user interface that contacts a web server
[00:33:12.080 --> 00:33:14.080]   and sends some information back and forth.
[00:33:14.080 --> 00:33:16.000]   We're doing some stuff that has to hook
[00:33:16.000 --> 00:33:17.880]   into the operating system of saying,
[00:33:17.880 --> 00:33:19.280]   let's go use Bluetooth for something
[00:33:19.280 --> 00:33:21.320]   it wasn't really meant for.
[00:33:21.320 --> 00:33:22.560]   Right, so there's that part.
[00:33:22.560 --> 00:33:24.500]   - And by the way, what is the app called?
[00:33:24.500 --> 00:33:27.500]   - Oh, it's called Novid, COVID with an N.
[00:33:27.500 --> 00:33:29.580]   - Very nice.
[00:33:29.580 --> 00:33:31.340]   So you have to hook into Bluetooth.
[00:33:31.340 --> 00:33:32.980]   You're saying you have to do that
[00:33:32.980 --> 00:33:37.180]   beyond the permissions that are like
[00:33:37.180 --> 00:33:40.660]   at the very surface level provided on the phone?
[00:33:40.660 --> 00:33:42.420]   - Well, I don't want to call them permissions.
[00:33:42.420 --> 00:33:43.260]   I just want to say
[00:33:43.260 --> 00:33:45.420]   that's not what you usually do with Bluetooth.
[00:33:45.420 --> 00:33:46.260]   - Gotcha.
[00:33:46.260 --> 00:33:47.660]   - Usually with Bluetooth, you say,
[00:33:47.660 --> 00:33:49.060]   do I have headphones nearby?
[00:33:49.060 --> 00:33:49.900]   - Yes.
[00:33:49.900 --> 00:33:50.720]   - Okay, I'm done.
[00:33:50.720 --> 00:33:53.140]   So I go and say, do I have headphones nearby?
[00:33:53.140 --> 00:33:55.500]   Or do I have another phone nearby, which is doing something?
[00:33:55.500 --> 00:33:56.340]   And then keep asking that same question.
[00:33:56.340 --> 00:33:58.340]   - Keep asking the question.
[00:33:58.340 --> 00:34:00.220]   - Right, so it's actually not easy.
[00:34:00.220 --> 00:34:02.180]   And I mean, there were some parts of it,
[00:34:02.180 --> 00:34:05.820]   which actually a lot of people had tried unsuccessfully.
[00:34:05.820 --> 00:34:07.960]   Actually, it's known that, for example,
[00:34:07.960 --> 00:34:11.580]   the UK was trying to do something similar.
[00:34:11.580 --> 00:34:13.620]   And the problem they ran into was
[00:34:13.620 --> 00:34:16.100]   when you program things on iOS,
[00:34:16.100 --> 00:34:19.300]   iOS is very good at making it hard
[00:34:19.300 --> 00:34:20.900]   to do things in the background.
[00:34:20.900 --> 00:34:23.780]   And so there was quite a lot of effort required
[00:34:23.780 --> 00:34:25.420]   to go and make this thing work.
[00:34:25.420 --> 00:34:28.180]   - So the whole point, this thing would run in the background
[00:34:28.180 --> 00:34:31.180]   and iOS, I mean, most,
[00:34:31.180 --> 00:34:33.740]   Android probably as well, right?
[00:34:33.740 --> 00:34:35.500]   But yeah, iOS certainly makes it difficult
[00:34:35.500 --> 00:34:36.900]   for something to run in the background,
[00:34:36.900 --> 00:34:40.200]   especially when it's eating up your battery, right?
[00:34:40.200 --> 00:34:41.300]   - Ah, well, we wanted to make sure
[00:34:41.300 --> 00:34:42.260]   we didn't eat up the battery.
[00:34:42.260 --> 00:34:44.940]   So that one, we actually are very proud of the fact
[00:34:44.940 --> 00:34:46.700]   that ours uses very little battery.
[00:34:47.780 --> 00:34:51.580]   Actually, even if compared to Apple's own system.
[00:34:51.580 --> 00:34:52.420]   - Beautiful.
[00:34:52.420 --> 00:34:54.500]   So what else is required to make this thing work?
[00:34:54.500 --> 00:34:56.860]   - Right, so the key was that you had to do
[00:34:56.860 --> 00:34:57.980]   a significant amount of work
[00:34:57.980 --> 00:35:00.180]   on the actual mobile app development,
[00:35:00.180 --> 00:35:02.140]   which fortunately the team that we brought
[00:35:02.140 --> 00:35:04.020]   was this kind of general thinkers
[00:35:04.020 --> 00:35:05.740]   where we would dig in deep
[00:35:05.740 --> 00:35:07.940]   into the operating system documentation
[00:35:07.940 --> 00:35:09.440]   and the API libraries.
[00:35:09.440 --> 00:35:10.620]   So we got that working.
[00:35:10.620 --> 00:35:12.300]   But there's another angle, which is,
[00:35:12.300 --> 00:35:14.980]   you also need the servers to be able to compute fast enough,
[00:35:14.980 --> 00:35:17.340]   which is tying back to this old school
[00:35:17.340 --> 00:35:20.020]   computer programming competitions and math Olympiads.
[00:35:20.020 --> 00:35:22.980]   In fact, our team that was working on the algorithm
[00:35:22.980 --> 00:35:25.440]   and backend side included several people
[00:35:25.440 --> 00:35:29.500]   who had been in these competitions from before,
[00:35:29.500 --> 00:35:30.420]   which I happen to know
[00:35:30.420 --> 00:35:33.340]   because I do coach the team for the math.
[00:35:33.340 --> 00:35:37.220]   And so we were able to bring people in to build servers,
[00:35:37.220 --> 00:35:40.100]   a server infrastructure in C++ actually,
[00:35:40.100 --> 00:35:43.060]   so that we could support significant numbers of people
[00:35:43.060 --> 00:35:45.340]   without needing tons of servers.
[00:35:45.340 --> 00:35:47.980]   - Is there some distributed algorithms working here
[00:35:47.980 --> 00:35:51.540]   or you basically have to keep in the same place
[00:35:51.540 --> 00:35:53.700]   the entire graph as it builds?
[00:35:53.700 --> 00:35:56.260]   'Cause especially the more and more people use it,
[00:35:56.260 --> 00:35:58.240]   the bigger, the bigger the graph gets.
[00:35:58.240 --> 00:36:02.300]   I mean, this is very difficult scaling problem, right?
[00:36:02.300 --> 00:36:04.100]   - Ah, so that's actually why
[00:36:04.100 --> 00:36:07.140]   this computer algorithm competition stuff was handy.
[00:36:07.140 --> 00:36:10.100]   It's because there are only about
[00:36:10.100 --> 00:36:12.900]   seven to eight giga people in the world.
[00:36:12.900 --> 00:36:14.020]   - Yeah.
[00:36:14.020 --> 00:36:15.140]   - That's not that many.
[00:36:15.140 --> 00:36:17.500]   So if you can make your algorithms linear time
[00:36:17.500 --> 00:36:22.300]   or almost linear time, a computer operates in gigahertz.
[00:36:22.300 --> 00:36:25.940]   I only need to do one run, one recalculation every hour
[00:36:25.940 --> 00:36:29.540]   in terms of telling people how far away these dangers are.
[00:36:29.540 --> 00:36:33.500]   So I'd suddenly have 3,600 seconds
[00:36:33.500 --> 00:36:36.460]   and my CPU cores are running in gigahertz
[00:36:36.460 --> 00:36:39.500]   and at most they're eight giga people.
[00:36:39.500 --> 00:36:42.020]   - Well, you're skipping over the fact that
[00:36:42.020 --> 00:36:45.980]   there's N squared potential connections between people.
[00:36:45.980 --> 00:36:51.380]   So how do you get around the fact that, you know,
[00:36:51.380 --> 00:36:54.420]   that we, you know, the potential set of relationship
[00:36:54.420 --> 00:36:56.140]   any one of us could have is 8 billion.
[00:36:56.140 --> 00:36:59.180]   So it's 8 billion times squared.
[00:36:59.180 --> 00:37:02.700]   That's the potential amount of data you have to be storing
[00:37:02.700 --> 00:37:05.260]   and computing over and constantly updating.
[00:37:05.260 --> 00:37:08.100]   - So the way we dealt with that is we actually expect
[00:37:08.100 --> 00:37:10.820]   that the typical network is very sparse.
[00:37:10.820 --> 00:37:14.820]   The technical term sparse would mean that the average degree
[00:37:14.820 --> 00:37:17.580]   or the average number of connections that a person has
[00:37:17.580 --> 00:37:21.100]   is going to be at most like a hundred strong connections
[00:37:21.100 --> 00:37:22.500]   that you care about.
[00:37:22.500 --> 00:37:25.500]   If you think of it almost in terms of the heavy hitters,
[00:37:25.500 --> 00:37:27.580]   actually in most people's lives,
[00:37:27.580 --> 00:37:32.420]   if we just kept track of their top hundred interactions,
[00:37:32.420 --> 00:37:34.180]   that's probably most of the signal.
[00:37:34.180 --> 00:37:37.660]   - Yeah, yeah.
[00:37:37.660 --> 00:37:40.340]   I'm saddened to think that I might not be even
[00:37:40.340 --> 00:37:41.980]   in a double digits, but...
[00:37:41.980 --> 00:37:44.660]   - Oh, I was intentionally giving a crazy number
[00:37:44.660 --> 00:37:46.260]   to account for college students.
[00:37:46.260 --> 00:37:48.900]   - You call, oh, those are the,
[00:37:48.900 --> 00:37:49.940]   who you call on the heavy hitters,
[00:37:49.940 --> 00:37:51.980]   the people who are like the social butterflies.
[00:37:51.980 --> 00:37:52.940]   Yeah. - Yeah, yeah.
[00:37:52.940 --> 00:37:56.260]   - I need to, I'd love to know that information
[00:37:56.260 --> 00:38:01.260]   about myself, by the way, that, do you expose the graph?
[00:38:01.260 --> 00:38:04.420]   Like how many, like about yourself,
[00:38:04.420 --> 00:38:06.020]   how many connections you have?
[00:38:06.020 --> 00:38:07.860]   - We do expose to each person
[00:38:07.860 --> 00:38:09.540]   how many direct connections they have.
[00:38:09.540 --> 00:38:10.380]   - That's great.
[00:38:10.380 --> 00:38:11.540]   - But for privacy purposes,
[00:38:11.540 --> 00:38:14.020]   we don't tell anybody who their connections,
[00:38:14.020 --> 00:38:15.940]   like how their connections are interconnected.
[00:38:15.940 --> 00:38:16.820]   - Yes, gotcha.
[00:38:16.820 --> 00:38:19.340]   - But at the same time, we do expose also to everyone
[00:38:19.340 --> 00:38:20.820]   an interesting chart that says,
[00:38:20.820 --> 00:38:22.740]   here's how many people you have
[00:38:22.740 --> 00:38:24.260]   that you're connected to directly.
[00:38:24.260 --> 00:38:27.780]   Here's how many at distance two, meaning via people.
[00:38:27.780 --> 00:38:29.540]   And then here's how many at distance three.
[00:38:29.540 --> 00:38:31.940]   And the reason we do that is that actually ends up
[00:38:31.940 --> 00:38:34.340]   being a dynamic that also boosts adoption.
[00:38:34.340 --> 00:38:36.260]   It drives another feedback loop.
[00:38:36.260 --> 00:38:38.020]   The reason is because we saw actually
[00:38:38.020 --> 00:38:40.460]   when we deployed this in some universities,
[00:38:40.460 --> 00:38:42.700]   that when people see on their app
[00:38:42.700 --> 00:38:45.940]   that they are indirectly connected to hundreds
[00:38:45.940 --> 00:38:48.180]   or thousands of other people, they get excited
[00:38:48.180 --> 00:38:49.020]   and they tell other people,
[00:38:49.020 --> 00:38:50.660]   "Hey, let's download this app."
[00:38:50.660 --> 00:38:52.860]   But you know, we also saw in those examples,
[00:38:52.860 --> 00:38:55.420]   especially looking at the screenshots people gave,
[00:38:55.420 --> 00:38:58.500]   that is hit as soon as the typical person
[00:38:58.500 --> 00:39:02.540]   has two or three other direct connections on the system,
[00:39:02.540 --> 00:39:05.700]   because that means that our app has reached a virality
[00:39:05.700 --> 00:39:07.620]   or not of two to three.
[00:39:07.620 --> 00:39:10.820]   The key is we were making a viral app to fight a virus
[00:39:10.820 --> 00:39:13.860]   spreading on the same network that the virus spreads on.
[00:39:13.860 --> 00:39:17.020]   - So you're trying to out-virus the virus.
[00:39:17.020 --> 00:39:17.860]   - That's right.
[00:39:17.860 --> 00:39:18.740]   (laughing)
[00:39:18.740 --> 00:39:20.220]   That's exactly right.
[00:39:20.220 --> 00:39:21.340]   - Okay, great.
[00:39:21.340 --> 00:39:23.580]   What have you learned from this whole experience
[00:39:23.580 --> 00:39:26.500]   in terms of, let's say for COVID,
[00:39:26.500 --> 00:39:28.740]   but for future pandemics as well,
[00:39:28.740 --> 00:39:33.700]   is it possible to use the power information here
[00:39:33.700 --> 00:39:37.100]   of networked information as the virus spreads
[00:39:37.100 --> 00:39:41.340]   and travels in order to basically keep the society open?
[00:39:41.340 --> 00:39:44.740]   Is it possible for people to protect themselves
[00:39:44.740 --> 00:39:46.100]   with this information?
[00:39:46.100 --> 00:39:48.820]   Or do you still have to have most,
[00:39:48.820 --> 00:39:51.100]   like in this overarching policy of everybody
[00:39:51.100 --> 00:39:53.580]   should stay at home, that kind of thing?
[00:39:53.580 --> 00:39:55.340]   - We are trying to answer that question right now.
[00:39:55.340 --> 00:39:57.500]   So the answer is we don't know yet,
[00:39:57.500 --> 00:39:59.220]   but that's actually why we're very happy
[00:39:59.220 --> 00:40:02.660]   that now the idea has started to become more widely known,
[00:40:02.660 --> 00:40:04.580]   and we're already starting to collaborate
[00:40:04.580 --> 00:40:06.420]   with epidemiologists.
[00:40:06.420 --> 00:40:08.780]   Again, I'm just a mathematician, right?
[00:40:08.780 --> 00:40:10.940]   And a mathematician should not be the person
[00:40:10.940 --> 00:40:13.620]   who is telling everybody, "This will definitely work."
[00:40:13.620 --> 00:40:17.580]   But because of the potential power of this approach,
[00:40:17.580 --> 00:40:21.060]   especially the potential power of this being an end game
[00:40:21.060 --> 00:40:26.060]   for COVID, we have gotten the interest of real researchers.
[00:40:26.060 --> 00:40:28.980]   And we're now working together to try to actually understand
[00:40:28.980 --> 00:40:30.140]   the answer to that question.
[00:40:30.140 --> 00:40:31.500]   Because you see, there's a theory.
[00:40:31.500 --> 00:40:34.020]   So what I can share is the mathematics of,
[00:40:34.020 --> 00:40:36.660]   "Here's why there's some hope that this would work."
[00:40:36.660 --> 00:40:39.420]   And that's because I'm talking about end game now.
[00:40:39.420 --> 00:40:41.540]   End game means you have very few cases.
[00:40:41.540 --> 00:40:43.540]   But everywhere, we're always thinking,
[00:40:43.540 --> 00:40:44.500]   "Once there's few cases,
[00:40:44.500 --> 00:40:46.500]   "then does that mean we now open up?"
[00:40:46.500 --> 00:40:48.020]   Once you open up in the past,
[00:40:48.020 --> 00:40:49.540]   then the cases go up again
[00:40:49.540 --> 00:40:51.460]   until you have to lock down again.
[00:40:51.460 --> 00:40:54.180]   And now when we talk about the dynamic process that makes,
[00:40:54.180 --> 00:40:55.860]   it's guaranteeing you always have cases
[00:40:55.860 --> 00:40:57.140]   until you have the great vaccines,
[00:40:57.140 --> 00:40:59.020]   which is, you know, we both got vaccinated.
[00:40:59.020 --> 00:41:00.700]   This is good.
[00:41:00.700 --> 00:41:02.500]   But at the same time, why I'm thinking
[00:41:02.500 --> 00:41:03.500]   this is still important
[00:41:03.500 --> 00:41:06.540]   is because we know that many vaccine makers have said
[00:41:06.540 --> 00:41:09.740]   they're preparing for the next dose next year.
[00:41:09.740 --> 00:41:11.700]   And if we have a perpetual thing
[00:41:11.700 --> 00:41:14.500]   where you just always need a new vaccine every year,
[00:41:14.500 --> 00:41:15.820]   it could actually be beneficial
[00:41:15.820 --> 00:41:18.820]   to make sure we have as many other techniques as possible
[00:41:18.820 --> 00:41:20.820]   for parts of the world that can't afford,
[00:41:20.820 --> 00:41:23.180]   for example, that kind of distribution.
[00:41:23.180 --> 00:41:26.380]   - Yeah, so actually, no matter how deadly the virus is,
[00:41:26.380 --> 00:41:27.740]   no matter how many things,
[00:41:27.740 --> 00:41:29.700]   whether you have a vaccine or not,
[00:41:29.700 --> 00:41:31.940]   it's still useful to be having this information.
[00:41:31.940 --> 00:41:32.780]   - Yes.
[00:41:32.780 --> 00:41:35.020]   - To stay home or not, depending on how risk,
[00:41:35.020 --> 00:41:37.380]   like I'm a big fan, just like you said,
[00:41:37.380 --> 00:41:40.260]   of having the freedom for you to decide
[00:41:40.260 --> 00:41:43.220]   how risk averse you want to be, right?
[00:41:43.220 --> 00:41:44.380]   Depending on your own conditions,
[00:41:44.380 --> 00:41:47.220]   but also in the state of like what you,
[00:41:47.220 --> 00:41:50.100]   just how dangerously you like to live.
[00:41:50.100 --> 00:41:51.940]   - So I think that actually makes a lot of sense.
[00:41:51.940 --> 00:41:54.940]   And I also think that since we're,
[00:41:54.940 --> 00:41:56.980]   when you think of disease spreading,
[00:41:56.980 --> 00:42:00.500]   it spreads in aggregate in the sense that
[00:42:00.500 --> 00:42:04.660]   if there are some people who maybe are more risk tolerant
[00:42:04.660 --> 00:42:06.460]   because of other things in their life,
[00:42:06.460 --> 00:42:08.060]   well, there might also be other people
[00:42:08.060 --> 00:42:09.820]   who are less risk tolerance.
[00:42:09.820 --> 00:42:12.740]   And then those people decide to isolate.
[00:42:12.740 --> 00:42:14.500]   But what matters is in the aggregate
[00:42:14.500 --> 00:42:17.660]   that this R naught of the infection spreading
[00:42:17.660 --> 00:42:18.980]   drops below one.
[00:42:18.980 --> 00:42:21.180]   And so the key is if you can empower people
[00:42:21.180 --> 00:42:23.460]   with that power to make that decision,
[00:42:23.460 --> 00:42:25.060]   you might actually still be able to drive
[00:42:25.060 --> 00:42:26.540]   that R naught down below one.
[00:42:26.540 --> 00:42:30.100]   - Yeah, and also, this is me talking,
[00:42:30.100 --> 00:42:33.700]   I, people get a little bit nervous, I think,
[00:42:33.700 --> 00:42:38.300]   with information somehow mapping to privacy violation.
[00:42:38.300 --> 00:42:42.280]   But I, first of all, in the approach you're describing,
[00:42:42.280 --> 00:42:44.640]   that's respecting anonymity.
[00:42:44.640 --> 00:42:49.260]   But I would love to have information
[00:42:49.260 --> 00:42:52.800]   from the very beginning, from March and April of last year,
[00:42:52.800 --> 00:42:59.060]   almost like a map of like where it's risky
[00:42:59.140 --> 00:43:01.420]   and where it's not to go.
[00:43:01.420 --> 00:43:05.220]   And not map based on sort of the exact location of people,
[00:43:05.220 --> 00:43:07.620]   but where people usually hang out kind of thing.
[00:43:07.620 --> 00:43:13.120]   And maybe not necessarily about actual location,
[00:43:13.120 --> 00:43:15.260]   but just maybe activities.
[00:43:15.260 --> 00:43:19.700]   Like just to have information about what is good to do
[00:43:19.700 --> 00:43:23.100]   and not, in terms of like safety.
[00:43:23.100 --> 00:43:25.460]   Is it okay to run outside and not,
[00:43:25.460 --> 00:43:27.780]   is it okay to go to a restaurant and not?
[00:43:27.780 --> 00:43:29.660]   I just feel like we're operating in the blind.
[00:43:29.660 --> 00:43:33.900]   And then what you had is a very imperfect signal,
[00:43:33.900 --> 00:43:36.180]   which is like basically politicians
[00:43:36.180 --> 00:43:38.700]   desperately trying to make statements
[00:43:38.700 --> 00:43:40.060]   about what is safe and not.
[00:43:40.060 --> 00:43:41.620]   They don't know what the heck they're doing.
[00:43:41.620 --> 00:43:44.140]   They have a bunch of smart scientists telling them stuff.
[00:43:44.140 --> 00:43:47.740]   And the scientists themselves, also, very important,
[00:43:47.740 --> 00:43:49.620]   don't always know what they're doing.
[00:43:49.620 --> 00:43:54.620]   Epidemiology is not, is as much an art as a science.
[00:43:54.620 --> 00:43:56.420]   You're desperately trying to predict the future,
[00:43:56.420 --> 00:43:57.980]   which nobody can do.
[00:43:57.980 --> 00:43:59.580]   And then you're trying to speak
[00:43:59.580 --> 00:44:01.260]   with some level of authority.
[00:44:01.260 --> 00:44:02.940]   I mean, if I were to criticize scientists,
[00:44:02.940 --> 00:44:04.460]   they spoke with too much authority.
[00:44:04.460 --> 00:44:06.500]   It's okay to say, I'm not sure.
[00:44:06.500 --> 00:44:10.700]   But then they think like, if I say I'm not sure,
[00:44:10.700 --> 00:44:12.420]   then there's going to be a distrust.
[00:44:12.420 --> 00:44:14.100]   What they realize is when you're wrong
[00:44:14.100 --> 00:44:16.880]   and you say, I'm sure, it's going to lead to more distrust.
[00:44:16.880 --> 00:44:19.780]   So there's this imperfect, like just chaotic,
[00:44:19.780 --> 00:44:23.600]   messy system of people trying to figure out
[00:44:23.600 --> 00:44:25.340]   with very little information.
[00:44:25.340 --> 00:44:27.860]   And what you're proposing is just a huge amount
[00:44:27.860 --> 00:44:31.100]   of information, and information is power.
[00:44:31.100 --> 00:44:33.700]   Is there challenges with adoption
[00:44:33.700 --> 00:44:36.260]   that you see in the future here?
[00:44:36.260 --> 00:44:38.660]   So there's, maybe we could speak to,
[00:44:38.660 --> 00:44:40.520]   there's approaches, I guess, from Google.
[00:44:40.520 --> 00:44:42.620]   There's different people that've tried
[00:44:42.620 --> 00:44:44.740]   similar kind of ideas.
[00:44:44.740 --> 00:44:49.620]   You have quite a novel idea, actually.
[00:44:49.620 --> 00:44:53.600]   But speaking the umbrella idea of contact tracing,
[00:44:54.780 --> 00:44:58.820]   is there something you can comment about
[00:44:58.820 --> 00:45:02.060]   why their approaches haven't been fully adopted?
[00:45:02.060 --> 00:45:03.220]   Is there challenges there?
[00:45:03.220 --> 00:45:06.400]   Is there reasons why Novid might be a better idea
[00:45:06.400 --> 00:45:09.260]   moving forward, in general, just about adoption?
[00:45:09.260 --> 00:45:10.700]   - Yeah, so first of all, I want to say,
[00:45:10.700 --> 00:45:13.300]   I always have respect for the methods that other people use.
[00:45:13.300 --> 00:45:16.180]   And so it's good to see that other people have been trying.
[00:45:16.180 --> 00:45:19.060]   But what we have noticed is that the difference
[00:45:19.060 --> 00:45:22.380]   between our value proposition to the user
[00:45:22.380 --> 00:45:23.900]   and the value proposition to the user
[00:45:23.900 --> 00:45:26.500]   delivered by everything that was made before,
[00:45:26.500 --> 00:45:30.500]   is that, unfortunately, the action of installing
[00:45:30.500 --> 00:45:34.500]   a standard contact tracing app will then tell you
[00:45:34.500 --> 00:45:37.740]   after you have already been exposed to the disease,
[00:45:37.740 --> 00:45:40.660]   so that you can protect other people from you.
[00:45:40.660 --> 00:45:43.640]   And what that does to your own direct probability
[00:45:43.640 --> 00:45:45.740]   of getting sick, if you think about it,
[00:45:45.740 --> 00:45:47.120]   suppose you were making the decision,
[00:45:47.120 --> 00:45:50.040]   should I or should I not install one of those apps?
[00:45:50.040 --> 00:45:53.100]   What does that do to your own probability of getting sick?
[00:45:53.100 --> 00:45:55.020]   (chuckles)
[00:45:55.020 --> 00:45:56.340]   It's close to zero.
[00:45:56.340 --> 00:46:00.020]   - This is the sad thing you're speaking to.
[00:46:00.020 --> 00:46:03.340]   Not sad, I suppose it's the way the world is.
[00:46:03.340 --> 00:46:06.100]   The only incentive there is to just help other people,
[00:46:06.100 --> 00:46:09.700]   I suppose, but a much stronger incentive
[00:46:09.700 --> 00:46:13.200]   is anything that allows you to help yourself.
[00:46:13.200 --> 00:46:15.580]   - Yes, so what I'm saying is that,
[00:46:15.580 --> 00:46:17.180]   let's just say free market capitalism
[00:46:17.180 --> 00:46:19.860]   was not based on altruism.
[00:46:19.860 --> 00:46:23.260]   I think it's based on, if you make a system of incentives
[00:46:23.260 --> 00:46:26.940]   so that everybody trying to maximize their own situation
[00:46:26.940 --> 00:46:28.740]   somehow contributes to the whole,
[00:46:28.740 --> 00:46:31.780]   that's a game theoretic solution to a very hard problem.
[00:46:31.780 --> 00:46:34.180]   And so this is actually basically mechanism design.
[00:46:34.180 --> 00:46:36.620]   Like we've basically come up with a different mechanism,
[00:46:36.620 --> 00:46:38.240]   different set of incentives,
[00:46:38.240 --> 00:46:40.920]   which incentivizes the adoption.
[00:46:40.920 --> 00:46:43.100]   Because actually, whenever we've been rolling it out,
[00:46:43.100 --> 00:46:45.220]   usually the first question we ask people,
[00:46:45.220 --> 00:46:48.140]   like say in a university is, do you know what Novavax does?
[00:46:48.140 --> 00:46:50.620]   And most of them have read about the other apps
[00:46:50.620 --> 00:46:51.900]   and they say, oh, Novavax will tell you
[00:46:51.900 --> 00:46:54.060]   after you've been around someone so you can quarantine.
[00:46:54.060 --> 00:46:55.380]   And we have to explain to them,
[00:46:55.380 --> 00:46:58.380]   actually, Novavax never wants to ask you to quarantine.
[00:46:58.380 --> 00:46:59.220]   That's not the principle.
[00:46:59.220 --> 00:47:01.180]   Our principle isn't based on that at all.
[00:47:01.180 --> 00:47:04.520]   We just want to let you know if something is coming close
[00:47:04.520 --> 00:47:06.180]   so that you can protect yourself.
[00:47:06.180 --> 00:47:08.140]   - If you want.
[00:47:08.140 --> 00:47:09.300]   - If you want, if you want, if you want.
[00:47:09.300 --> 00:47:11.260]   And then the quarantine is like, yes,
[00:47:11.260 --> 00:47:13.380]   in that case, if you're quarantining,
[00:47:13.380 --> 00:47:16.180]   it's because you're shutting the door from the inside,
[00:47:16.180 --> 00:47:17.020]   if that makes sense.
[00:47:17.020 --> 00:47:18.700]   - Yes, exactly, exactly.
[00:47:18.700 --> 00:47:20.100]   I mean, this is brilliant.
[00:47:20.100 --> 00:47:23.380]   So what do you think the future looks like
[00:47:23.380 --> 00:47:24.580]   for future pandemics?
[00:47:24.580 --> 00:47:26.700]   What's your plan with Novavax?
[00:47:26.700 --> 00:47:28.780]   What's your plan with these set of ideas?
[00:47:28.780 --> 00:47:31.200]   - I am actually still an academic and a researcher.
[00:47:31.200 --> 00:47:33.380]   So the biggest work I'm working on right now
[00:47:33.380 --> 00:47:35.580]   is to try to build as many collaborations
[00:47:35.580 --> 00:47:39.140]   with other public health researchers at other universities
[00:47:39.140 --> 00:47:42.180]   to actually work on pilot deployments together
[00:47:42.180 --> 00:47:43.060]   in various places.
[00:47:43.060 --> 00:47:44.100]   That's the goal.
[00:47:44.100 --> 00:47:46.060]   That's actually ongoing work right now.
[00:47:46.060 --> 00:47:47.820]   And so for example, if anyone's watching this
[00:47:47.820 --> 00:47:49.780]   and you happen to be a public health researcher
[00:47:49.780 --> 00:47:52.380]   and you want to be involved in something like this,
[00:47:52.380 --> 00:47:55.280]   I'm just gonna say, I'm still incentive thinking.
[00:47:55.280 --> 00:47:57.380]   There is something in it for the researchers too.
[00:47:57.380 --> 00:48:00.380]   This could open up an entire new way of controlling disease.
[00:48:00.380 --> 00:48:01.940]   That's my hope.
[00:48:01.940 --> 00:48:03.580]   I mean, it might actually be true.
[00:48:03.580 --> 00:48:06.380]   And people who are involved in figuring out
[00:48:06.380 --> 00:48:08.080]   how to make this work,
[00:48:08.080 --> 00:48:10.020]   well, it could actually be good for their careers too.
[00:48:10.020 --> 00:48:11.100]   I always have to think like,
[00:48:11.100 --> 00:48:12.720]   if a researcher was getting involved,
[00:48:12.720 --> 00:48:14.420]   what are they getting out of it?
[00:48:14.420 --> 00:48:16.660]   - So you mean like from a research perspective,
[00:48:16.660 --> 00:48:20.300]   you can like publications and sets of ideas
[00:48:20.300 --> 00:48:25.300]   about how to, from a sort of a network theory perspective,
[00:48:25.300 --> 00:48:30.120]   understand how we control the spread of a pandemic.
[00:48:30.120 --> 00:48:31.740]   - Yes, and what I'm doing right now
[00:48:31.740 --> 00:48:33.780]   is this is basically interdisciplinary research
[00:48:33.780 --> 00:48:36.020]   where maybe our side is bringing the technology
[00:48:36.020 --> 00:48:37.100]   and the network theory,
[00:48:37.100 --> 00:48:39.260]   and the missing parts are epidemiology
[00:48:39.260 --> 00:48:41.020]   and public health expertise.
[00:48:41.020 --> 00:48:42.900]   And if the two things start to join,
[00:48:42.900 --> 00:48:45.380]   also because everywhere that you deploy,
[00:48:45.380 --> 00:48:46.860]   let's just say that the world is different
[00:48:46.860 --> 00:48:49.460]   in the Philippines as it is in the United States.
[00:48:49.460 --> 00:48:52.100]   And just the natures of the locality
[00:48:52.100 --> 00:48:53.620]   would mean that someone like me
[00:48:53.620 --> 00:48:55.340]   should not be trying to figure out how to do that.
[00:48:55.340 --> 00:48:57.900]   But if we can work with the researchers who are based there,
[00:48:57.900 --> 00:48:59.780]   now suddenly we might come up with a solution
[00:48:59.780 --> 00:49:02.020]   that will help scale in parts of the world
[00:49:02.020 --> 00:49:03.240]   where they aren't all getting
[00:49:03.240 --> 00:49:04.740]   the Moderna and Pfizer vaccines,
[00:49:04.740 --> 00:49:07.460]   which cost like $20 a pop in the US.
[00:49:07.460 --> 00:49:09.300]   - So if they want to participate,
[00:49:09.300 --> 00:49:10.780]   who do they reach out to?
[00:49:10.780 --> 00:49:11.680]   - Oh, that would just be us.
[00:49:11.680 --> 00:49:13.620]   I mean, the nova.org website has--
[00:49:13.620 --> 00:49:14.460]   - Nova.org?
[00:49:14.460 --> 00:49:16.900]   - It has a feedback reach out form.
[00:49:16.900 --> 00:49:18.860]   And actually we are, I mean, again,
[00:49:18.860 --> 00:49:21.060]   this is the DNA of being a researcher.
[00:49:21.060 --> 00:49:23.340]   I am actually very excited by the idea
[00:49:23.340 --> 00:49:25.600]   that this could contribute knowledge
[00:49:25.600 --> 00:49:28.260]   that will outlast all of our generations,
[00:49:28.260 --> 00:49:29.980]   like all of our lifetimes.
[00:49:29.980 --> 00:49:30.820]   - There you go.
[00:49:30.820 --> 00:49:33.240]   Reach out to nova.org.
[00:49:33.240 --> 00:49:36.060]   What about individual people?
[00:49:36.060 --> 00:49:37.700]   Should they install the app and try it out?
[00:49:37.700 --> 00:49:40.100]   Or is this really geographically restricted?
[00:49:40.100 --> 00:49:41.520]   - Oh yeah, I didn't come on here
[00:49:41.520 --> 00:49:42.800]   to tell everyone to install the app.
[00:49:42.800 --> 00:49:44.780]   I did not come to tell everyone to install the app
[00:49:44.780 --> 00:49:48.240]   because it works best if your local health authority
[00:49:48.240 --> 00:49:49.400]   is working with us.
[00:49:49.400 --> 00:49:50.240]   - Gotcha.
[00:49:50.240 --> 00:49:51.060]   - There's a reason.
[00:49:51.060 --> 00:49:53.460]   It's because, this is back to the game theory.
[00:49:53.460 --> 00:49:57.220]   If anyone could just say, "I'm positive,"
[00:49:57.220 --> 00:50:01.480]   the high school senior prank would be to say
[00:50:01.480 --> 00:50:04.000]   that we have a massive outbreak on finals week.
[00:50:04.000 --> 00:50:05.280]   Let's not have final exams.
[00:50:05.280 --> 00:50:06.640]   So the way that our system works,
[00:50:06.640 --> 00:50:08.760]   it actually borrows some ideas, not borrows,
[00:50:08.760 --> 00:50:10.280]   we came up with them independently.
[00:50:10.280 --> 00:50:13.240]   But this idea is similar to what Google and Apple do,
[00:50:13.240 --> 00:50:14.880]   which is that if the local health authority
[00:50:14.880 --> 00:50:17.960]   is working with this, they can, for everyone who's positive,
[00:50:17.960 --> 00:50:20.680]   give them a passcode that expires in a short time.
[00:50:20.680 --> 00:50:23.600]   So for ours, if you're on the app and saying, "I'm positive,"
[00:50:23.600 --> 00:50:26.800]   you can either just say that, and that's called unverified,
[00:50:26.800 --> 00:50:28.360]   or you can enter in one of these codes
[00:50:28.360 --> 00:50:30.280]   that you got from the local health authority.
[00:50:30.280 --> 00:50:32.420]   So basically, for anyone who's watching this,
[00:50:32.420 --> 00:50:34.000]   it's not that you should just go and download it,
[00:50:34.000 --> 00:50:36.120]   unless you wanna go and look at it, that's cool.
[00:50:36.120 --> 00:50:37.480]   But if you, on the other hand,
[00:50:37.480 --> 00:50:39.840]   if you happen to know anyone at the local health authority
[00:50:39.840 --> 00:50:42.600]   which is trying to figure out how to handle COVID,
[00:50:42.600 --> 00:50:46.400]   well then, I mean, we'd be very happy to also work with you.
[00:50:46.400 --> 00:50:49.080]   - Gotcha, so the verified there is really important,
[00:50:49.080 --> 00:50:51.280]   because you're maintaining anonymity,
[00:50:51.280 --> 00:50:52.120]   and because of that,
[00:50:52.120 --> 00:50:54.560]   you have to have some source of verification
[00:50:54.560 --> 00:50:59.040]   in order to make sure that it's not possible to manipulate,
[00:50:59.040 --> 00:51:01.880]   because it's ultimately about trust and information,
[00:51:01.880 --> 00:51:02.960]   and so it could be,
[00:51:02.960 --> 00:51:06.080]   verification is really important there.
[00:51:06.080 --> 00:51:08.080]   - So basically, individual people should
[00:51:08.080 --> 00:51:11.240]   ask their local health authorities
[00:51:11.240 --> 00:51:13.780]   to sign up to contact you.
[00:51:13.780 --> 00:51:16.280]   I hope this spreads,
[00:51:16.280 --> 00:51:18.640]   I hope this spreads for future pandemics,
[00:51:18.640 --> 00:51:21.400]   'cause I'm really, it's the amount,
[00:51:21.400 --> 00:51:25.560]   the millions of people who are hurt by this,
[00:51:25.560 --> 00:51:30.000]   I think our response to the virus, economically speaking,
[00:51:30.000 --> 00:51:32.480]   the number of people who lost their dream,
[00:51:32.480 --> 00:51:35.080]   lost their jobs, but also lost their dream,
[00:51:35.080 --> 00:51:38.360]   entrepreneurs, jobs often give meaning,
[00:51:38.360 --> 00:51:41.040]   there's people who financially and psychologically
[00:51:41.040 --> 00:51:42.720]   are suffering because of our,
[00:51:42.720 --> 00:51:48.240]   I'll say incompetent response to the virus across the world,
[00:51:48.240 --> 00:51:49.720]   but certainly in the United States,
[00:51:49.720 --> 00:51:51.000]   that should be the beacon
[00:51:51.000 --> 00:51:54.360]   of entrepreneurial hope for the world.
[00:51:54.360 --> 00:51:59.360]   So, I hope that we'll be able to respond
[00:51:59.360 --> 00:52:02.720]   to these kinds of events much better in the future,
[00:52:02.720 --> 00:52:05.000]   and this is exactly the right kind of idea,
[00:52:05.000 --> 00:52:07.180]   and now's the time to do the investment.
[00:52:07.180 --> 00:52:13.000]   Let's step back to the beauty of mathematics.
[00:52:13.000 --> 00:52:16.000]   Maybe ask the big, silly question first,
[00:52:16.000 --> 00:52:19.740]   which is, what do you find beautiful about mathematics?
[00:52:19.740 --> 00:52:25.800]   - I think that being able to look at a complicated problem,
[00:52:25.800 --> 00:52:28.520]   which looks unsolvable,
[00:52:28.520 --> 00:52:30.760]   and then to be able to change the perspective
[00:52:30.760 --> 00:52:32.440]   to come from a different angle,
[00:52:32.440 --> 00:52:35.300]   and suddenly see that there's a nice solution.
[00:52:35.300 --> 00:52:37.860]   I don't mean that every problem in math
[00:52:37.860 --> 00:52:39.120]   is supposed to be this way,
[00:52:39.120 --> 00:52:40.880]   but I think that these reframings
[00:52:40.880 --> 00:52:42.120]   and changing of perspectives
[00:52:42.120 --> 00:52:44.600]   that cause difficult things to get simplified
[00:52:44.600 --> 00:52:48.560]   and crystallized and factored in certain ways is beautiful.
[00:52:48.560 --> 00:52:50.920]   Actually, that's related to what we were just talking about
[00:52:50.920 --> 00:52:52.560]   with even this fighting pandemics.
[00:52:52.560 --> 00:52:57.560]   The crystal idea was just quantify proximity
[00:52:57.560 --> 00:53:01.640]   by the number of relationships in the physical network,
[00:53:01.640 --> 00:53:03.920]   instead of just by the feet and meters.
[00:53:03.920 --> 00:53:07.320]   If you change that perspective,
[00:53:07.320 --> 00:53:09.200]   now all of these things follow.
[00:53:09.200 --> 00:53:12.240]   And so, mathematics, to me, is beautiful
[00:53:12.240 --> 00:53:14.960]   in the pure sense, just for that.
[00:53:14.960 --> 00:53:16.520]   - Yeah, it's quite interesting to see
[00:53:16.520 --> 00:53:20.000]   human civilization as a network, as a graph,
[00:53:20.000 --> 00:53:25.000]   and our relationships as kind of edges in that graph,
[00:53:25.000 --> 00:53:29.320]   and to then do, outside of just pandemic,
[00:53:29.320 --> 00:53:31.880]   do interesting inferences based on that.
[00:53:31.880 --> 00:53:36.920]   This is true for Twitter, social networks, and so on,
[00:53:36.920 --> 00:53:40.080]   how we expand the kind of things we talk about,
[00:53:40.080 --> 00:53:42.200]   think about, sort of politically,
[00:53:42.200 --> 00:53:44.680]   if you have this little bubble, quote-unquote,
[00:53:44.680 --> 00:53:46.880]   of ideas that you play with,
[00:53:46.880 --> 00:53:50.200]   it's nice from a recommender system perspective,
[00:53:50.200 --> 00:53:52.000]   how do you jump out of those bubbles?
[00:53:52.000 --> 00:53:53.600]   It's really fascinating.
[00:53:53.600 --> 00:53:57.520]   YouTube was working on that, Twitter's working on that,
[00:53:57.520 --> 00:53:59.680]   but not always so successfully.
[00:53:59.680 --> 00:54:02.680]   But there's a lot of interesting work
[00:54:02.680 --> 00:54:05.160]   from a mathematical and a psychological,
[00:54:05.160 --> 00:54:08.540]   sociological perspective there, within those graphs.
[00:54:08.540 --> 00:54:13.360]   But if we look at the cleanest formulation of that,
[00:54:13.360 --> 00:54:16.280]   of looking at a problem from a different perspective,
[00:54:16.280 --> 00:54:17.360]   you're also involved
[00:54:17.360 --> 00:54:20.200]   with the International Mathematics Olympiad,
[00:54:20.200 --> 00:54:24.200]   which takes small, clean problems
[00:54:26.220 --> 00:54:27.640]   that are really hard,
[00:54:27.640 --> 00:54:31.140]   but once you look at them differently, can become easy.
[00:54:31.140 --> 00:54:36.140]   But that little jump of innovation is the entire trick.
[00:54:36.140 --> 00:54:38.560]   So maybe at the high level,
[00:54:38.560 --> 00:54:41.480]   can you say what is the International Mathematical Olympiad?
[00:54:41.480 --> 00:54:44.600]   - Sure, so this is the competition
[00:54:44.600 --> 00:54:47.860]   for people who aren't yet in college, math competition,
[00:54:47.860 --> 00:54:50.720]   which is the most prestigious one in the entire world.
[00:54:50.720 --> 00:54:52.860]   It's the Olympics of mathematics,
[00:54:52.860 --> 00:54:55.040]   but only for people who aren't yet in college.
[00:54:55.040 --> 00:54:58.000]   Now, the kinds of questions that they ask you to do
[00:54:58.000 --> 00:54:59.600]   are not computational.
[00:54:59.600 --> 00:55:02.440]   Usually you're not supposed to find that the answer is 42.
[00:55:02.440 --> 00:55:03.800]   (both laughing)
[00:55:03.800 --> 00:55:07.300]   Instead, you're supposed to explain why something is true.
[00:55:07.300 --> 00:55:09.840]   And the problem is that at the beginning,
[00:55:09.840 --> 00:55:11.560]   when you look at each of the questions,
[00:55:11.560 --> 00:55:13.560]   first of all, you have four and a half hours
[00:55:13.560 --> 00:55:16.100]   to solve three questions, and this is one day,
[00:55:16.100 --> 00:55:16.940]   and then you have a second day,
[00:55:16.940 --> 00:55:19.400]   which is four and a half hours, three questions.
[00:55:19.400 --> 00:55:20.640]   But when you look at the questions,
[00:55:20.640 --> 00:55:21.480]   they're all asking you,
[00:55:21.480 --> 00:55:23.280]   explain why the following thing is true,
[00:55:23.280 --> 00:55:25.220]   which you've never seen before.
[00:55:25.220 --> 00:55:27.400]   And by the way, even though there are six questions,
[00:55:27.400 --> 00:55:29.160]   if you solve any one of them, you're a genius,
[00:55:29.160 --> 00:55:30.360]   and you get an honorable mention.
[00:55:30.360 --> 00:55:32.120]   So this is hard to solve.
[00:55:32.120 --> 00:55:32.960]   - Really hard problem.
[00:55:32.960 --> 00:55:35.360]   So what about, is it one person, is it a team?
[00:55:35.360 --> 00:55:38.760]   - Ah, so it's each country can send six people,
[00:55:38.760 --> 00:55:42.360]   and the score of the country is actually unofficial.
[00:55:42.360 --> 00:55:45.400]   There's not an official country versus country system,
[00:55:45.400 --> 00:55:47.500]   although everyone just adds up the point scores
[00:55:47.500 --> 00:55:48.800]   of the six people, and they say,
[00:55:48.800 --> 00:55:51.460]   well, now which country stacked up where?
[00:55:51.460 --> 00:55:53.420]   - Yeah, so maybe as a side comment,
[00:55:53.420 --> 00:55:56.580]   I should say that there's a bunch of countries,
[00:55:56.580 --> 00:55:59.500]   including the former Soviet Union and Russia,
[00:55:59.500 --> 00:56:03.500]   where I grew up, where this is one of the
[00:56:03.500 --> 00:56:08.380]   most important competitions that the country participates in.
[00:56:08.380 --> 00:56:11.920]   It was a source of pride for a lot of the country.
[00:56:11.920 --> 00:56:14.460]   You look at the Olympic sports,
[00:56:14.460 --> 00:56:17.140]   like wrestling, weightlifting,
[00:56:17.140 --> 00:56:20.340]   there's certain sports and hockey
[00:56:20.340 --> 00:56:25.020]   that Russia and the Soviet Union truly took pride in.
[00:56:25.020 --> 00:56:28.660]   And actually the Mathematical Olympiad,
[00:56:28.660 --> 00:56:32.620]   it was one of them for many years, is still one of them.
[00:56:32.620 --> 00:56:33.780]   And that's kind of fascinating.
[00:56:33.780 --> 00:56:36.740]   We don't think about it this way in the United States.
[00:56:36.740 --> 00:56:38.260]   Maybe you can correct me if I'm wrong,
[00:56:38.260 --> 00:56:42.420]   but it's not nearly as popular in the United States
[00:56:42.420 --> 00:56:45.580]   in terms of its integration into the culture,
[00:56:45.580 --> 00:56:49.100]   into just basic conversation, into the pride.
[00:56:49.100 --> 00:56:52.420]   Like, if you won an Olympic gold medal,
[00:56:52.420 --> 00:56:56.100]   or if you won the Superbowl, you can walk around proud.
[00:56:56.100 --> 00:56:57.100]   I think that was the case
[00:56:57.100 --> 00:56:59.260]   with the Mathematical Olympiad in Russia.
[00:56:59.260 --> 00:57:03.100]   Not as much the case in the United States, I think.
[00:57:03.100 --> 00:57:04.940]   So I just wanna give that a little aside
[00:57:04.940 --> 00:57:07.560]   because beating anybody from Russia,
[00:57:07.560 --> 00:57:09.420]   from the Eastern Republic, or from China
[00:57:09.420 --> 00:57:11.900]   is very, very difficult.
[00:57:11.900 --> 00:57:13.540]   Like if I remember correctly,
[00:57:13.540 --> 00:57:18.900]   there's people, this was a multi-year training process.
[00:57:18.900 --> 00:57:20.700]   They train hard.
[00:57:20.700 --> 00:57:25.060]   And this is everything that they're focused on.
[00:57:25.060 --> 00:57:29.340]   My dad was a participant in this.
[00:57:29.340 --> 00:57:33.140]   And it's, I mean, it's as serious as Olympic sports.
[00:57:33.140 --> 00:57:34.540]   You think about like gymnastics,
[00:57:34.540 --> 00:57:36.620]   like young athletes participating in gymnastics.
[00:57:36.620 --> 00:57:38.940]   This is as serious as that, if not more serious.
[00:57:38.940 --> 00:57:41.380]   So I just wanna give that a little bit of context
[00:57:41.380 --> 00:57:44.660]   'cause we're talking about serious, high-level math,
[00:57:44.660 --> 00:57:46.380]   athletics almost here.
[00:57:46.380 --> 00:57:49.820]   - Yeah, and actually I also think that it made sense
[00:57:49.820 --> 00:57:51.420]   from the Soviet Union's perspective.
[00:57:51.420 --> 00:57:55.460]   Because if you look at what these people do eventually,
[00:57:55.460 --> 00:57:58.820]   even though, let's look at the USSR's
[00:57:58.820 --> 00:58:00.620]   International Math Olympiad record.
[00:58:00.620 --> 00:58:03.100]   Even though they, I say, even though they won
[00:58:03.100 --> 00:58:05.260]   a lot of awards at the high school thing,
[00:58:05.260 --> 00:58:07.820]   many of them went on to do incredible things
[00:58:07.820 --> 00:58:10.580]   in research mathematics or research other things.
[00:58:10.580 --> 00:58:14.340]   And that's showing the generalization, generalizability
[00:58:14.340 --> 00:58:15.980]   of what they were working on.
[00:58:15.980 --> 00:58:20.180]   Because ultimately we're just playing with ideas
[00:58:20.180 --> 00:58:22.380]   of how to prove things.
[00:58:22.380 --> 00:58:26.060]   And if you get pretty good at inventing creative ways
[00:58:26.060 --> 00:58:29.020]   to turn problems apart, split them apart,
[00:58:29.020 --> 00:58:34.020]   observe neat ways to turn messy things into simple crystals.
[00:58:34.020 --> 00:58:36.180]   Well, if you're gonna try to solve any real problem
[00:58:36.180 --> 00:58:39.260]   in the real world, that could be a really handy tool too.
[00:58:39.260 --> 00:58:41.180]   So I don't think it was a bad investment.
[00:58:41.180 --> 00:58:44.940]   I think it clearly worked well for Soviet Union.
[00:58:44.940 --> 00:58:47.060]   - Yeah, so this is interesting.
[00:58:47.060 --> 00:58:50.960]   People sometimes ask me, you go up under communism,
[00:58:50.960 --> 00:58:54.100]   was there anything good about communism?
[00:58:54.100 --> 00:58:58.140]   And it's difficult for me to talk about it
[00:58:58.140 --> 00:59:00.820]   because it's not, communism is one of those things
[00:59:00.820 --> 00:59:02.940]   that's looked down on, like without,
[00:59:02.940 --> 00:59:05.380]   in absolutist terms currently.
[00:59:05.380 --> 00:59:07.340]   But you could still, in my perspective,
[00:59:07.340 --> 00:59:09.500]   talk about the actual, forget communism
[00:59:09.500 --> 00:59:13.680]   or whatever the actual term is, but certain,
[00:59:14.680 --> 00:59:16.760]   ways that the society functioned
[00:59:16.760 --> 00:59:18.120]   that we can learn lessons from.
[00:59:18.120 --> 00:59:20.280]   And one of the things in the Soviet Union
[00:59:20.280 --> 00:59:25.160]   that was highly prized is knowledge,
[00:59:25.160 --> 00:59:30.160]   not even knowledge, it's wisdom and the skill of invention,
[00:59:30.160 --> 00:59:34.140]   of innovation at a young age.
[00:59:34.140 --> 00:59:37.240]   So we're not talking about a selection process
[00:59:37.240 --> 00:59:40.440]   where you pick the best students in the school
[00:59:40.440 --> 00:59:44.120]   to do the mathematics or to read literature.
[00:59:44.120 --> 00:59:48.740]   It's like everybody did it, everybody.
[00:59:48.740 --> 00:59:51.640]   It was almost treated as if anyone
[00:59:51.640 --> 00:59:54.800]   could be the next Einstein, anybody could be the next,
[00:59:54.800 --> 00:59:56.880]   I don't know, Hemingway, James Joyce.
[00:59:56.880 --> 01:00:01.200]   And so you're forcing an education on the populace
[01:00:01.200 --> 01:00:03.960]   and a rigorous, deep education,
[01:00:03.960 --> 01:00:06.440]   like as opposed to kind of like,
[01:00:06.440 --> 01:00:10.320]   oh, we want to make sure we teach
[01:00:10.320 --> 01:00:12.420]   to the weakest student in the class,
[01:00:12.420 --> 01:00:16.960]   which American systems can sometimes do
[01:00:16.960 --> 01:00:19.200]   because we don't want to leave anyone behind.
[01:00:19.200 --> 01:00:25.040]   The Russian system was anyone can be the strongest student
[01:00:25.040 --> 01:00:26.880]   and we're going to teach you the strongest student
[01:00:26.880 --> 01:00:30.880]   and we're going to pretend or force everybody,
[01:00:30.880 --> 01:00:32.920]   even the weakest student to be strong.
[01:00:32.920 --> 01:00:35.240]   And what that results in, it's obviously,
[01:00:35.240 --> 01:00:36.520]   this is what people talk about
[01:00:36.520 --> 01:00:38.120]   is a huge amount of pressure.
[01:00:38.120 --> 01:00:40.640]   Like it's psychologically very difficult.
[01:00:40.640 --> 01:00:42.640]   This is why people struggle when they go to MIT,
[01:00:42.640 --> 01:00:44.400]   this very competitive environment.
[01:00:44.400 --> 01:00:46.100]   It can be very psychologically difficult,
[01:00:46.100 --> 01:00:47.360]   but at the same time,
[01:00:47.360 --> 01:00:49.800]   it's bringing out the best out of people.
[01:00:49.800 --> 01:00:53.240]   And that mathematics was certainly one of those things.
[01:00:53.240 --> 01:00:54.640]   And exactly what you're saying,
[01:00:54.640 --> 01:00:56.400]   which kind of clicked with me just now,
[01:00:56.400 --> 01:01:00.760]   as opposed to kind of a spelling bee in the United States,
[01:01:00.760 --> 01:01:03.360]   which I guess you spell, I'm horrible at this,
[01:01:03.360 --> 01:01:04.980]   but it's a competition about spelling,
[01:01:04.980 --> 01:01:07.200]   which I'm not sure, but you could argue,
[01:01:07.200 --> 01:01:10.020]   doesn't generalize well to the future skills.
[01:01:10.020 --> 01:01:13.320]   Mathematics, especially this kind of mathematics,
[01:01:13.320 --> 01:01:17.160]   is essentially formalized competition of invention,
[01:01:17.160 --> 01:01:21.780]   of creating new ideas.
[01:01:21.780 --> 01:01:23.980]   And that generalizes really, really well.
[01:01:23.980 --> 01:01:25.840]   So that's quite brilliantly put.
[01:01:25.840 --> 01:01:27.360]   I didn't really think about that.
[01:01:27.360 --> 01:01:29.200]   So this is not just about the competition.
[01:01:29.200 --> 01:01:31.960]   This is about developing minds
[01:01:31.960 --> 01:01:36.960]   that will come to do some incredible stuff in the future.
[01:01:36.960 --> 01:01:38.660]   - Yeah, actually, I want to respond
[01:01:38.660 --> 01:01:39.620]   to a couple of things there.
[01:01:39.620 --> 01:01:42.020]   The first one is one, which is this notion
[01:01:42.020 --> 01:01:43.800]   of whether or not that is possible
[01:01:43.800 --> 01:01:46.320]   in a non-authoritarian regime.
[01:01:46.320 --> 01:01:47.160]   I think it is.
[01:01:47.160 --> 01:01:49.540]   And that's actually why I spent some of my efforts
[01:01:49.540 --> 01:01:51.060]   before the COVID thing,
[01:01:51.060 --> 01:01:53.260]   actually trying to work towards there.
[01:01:53.260 --> 01:01:55.720]   The reason is because if you think about it,
[01:01:55.720 --> 01:01:57.420]   let's say in America,
[01:01:57.420 --> 01:01:58.860]   lots of people are pretty serious
[01:01:58.860 --> 01:02:01.940]   about training very hard for football or baseball,
[01:02:01.940 --> 01:02:04.020]   or basketball, basketball is very, very accessible,
[01:02:04.020 --> 01:02:05.820]   but lots of people are doing that.
[01:02:05.820 --> 01:02:06.660]   Why?
[01:02:06.660 --> 01:02:09.900]   Well, actually, I think that what was going on
[01:02:09.900 --> 01:02:13.540]   with the authoritarian thing was at least the message
[01:02:13.540 --> 01:02:17.860]   that was universally sent was being a good thinker
[01:02:17.860 --> 01:02:21.800]   and a creator of ideas is a good thing.
[01:02:21.800 --> 01:02:23.380]   - Yes, exactly.
[01:02:23.380 --> 01:02:25.740]   - There's no reason why that message can't be sent.
[01:02:25.740 --> 01:02:26.940]   - That's right. - Everywhere.
[01:02:26.940 --> 01:02:28.660]   And I think it actually should be.
[01:02:28.660 --> 01:02:29.740]   So that's the first thing.
[01:02:29.740 --> 01:02:31.900]   The second thing is what you commented about,
[01:02:31.900 --> 01:02:35.720]   this thing about the generalizable skill
[01:02:35.720 --> 01:02:37.960]   and what could people do with Olympiads afterwards.
[01:02:37.960 --> 01:02:40.340]   So that's actually my interest in the whole thing.
[01:02:40.340 --> 01:02:45.340]   I don't just coach students how to do problems.
[01:02:45.340 --> 01:02:47.140]   In fact, I'm not even the best person for that.
[01:02:47.140 --> 01:02:49.500]   I'm not the best at solving these problems.
[01:02:49.500 --> 01:02:50.820]   There are other people who are much better
[01:02:50.820 --> 01:02:53.300]   at making problems and teaching people how to solve problems.
[01:02:53.300 --> 01:02:57.140]   In fact, when the Mathematical Association of America,
[01:02:57.140 --> 01:02:58.640]   which is the group which is in charge
[01:02:58.640 --> 01:03:01.280]   of the US participation in these Olympiads,
[01:03:01.280 --> 01:03:04.300]   when they were deciding whether or not to put me in
[01:03:04.300 --> 01:03:06.900]   back in 2013 as the head coach,
[01:03:06.900 --> 01:03:09.260]   I had a conversation with their executive director
[01:03:09.260 --> 01:03:12.680]   where I commented that we might do worse
[01:03:12.680 --> 01:03:14.500]   because my position was,
[01:03:14.500 --> 01:03:17.660]   I actually didn't want to focus on winning.
[01:03:17.660 --> 01:03:19.840]   I said, if you're going to let me work
[01:03:19.840 --> 01:03:24.420]   with 60 very strong minds as picked through this system,
[01:03:24.420 --> 01:03:26.080]   'cause the coach works with these,
[01:03:26.080 --> 01:03:27.700]   gets to run a camp for these students,
[01:03:27.700 --> 01:03:30.420]   I said, I'm actually not going to define my success
[01:03:30.420 --> 01:03:33.100]   in terms of winning this contest.
[01:03:33.100 --> 01:03:36.060]   I said, I wanted to maximize the number of the students
[01:03:36.060 --> 01:03:39.160]   that I read about in the New York Times in 20 years.
[01:03:39.160 --> 01:03:41.540]   And the executive director
[01:03:41.540 --> 01:03:44.040]   of the Mathematical Association of America
[01:03:44.040 --> 01:03:45.860]   was fully in support of this
[01:03:45.860 --> 01:03:48.020]   because that's also how their philosophy is.
[01:03:48.020 --> 01:03:49.860]   So in America, the way we run this
[01:03:49.860 --> 01:03:52.940]   is we're actually not just training to win,
[01:03:52.940 --> 01:03:54.860]   even though the students are very good
[01:03:54.860 --> 01:03:56.460]   and they can win anyway.
[01:03:56.460 --> 01:03:57.580]   One reason, for example,
[01:03:57.580 --> 01:03:59.100]   I went and even did the COVID thing
[01:03:59.100 --> 01:04:00.540]   involving quite a few of them
[01:04:00.540 --> 01:04:04.260]   is so that hopefully some of them get ideas
[01:04:04.260 --> 01:04:05.480]   because in 20, 30 years,
[01:04:05.480 --> 01:04:08.500]   I won't have the energy or the insight to solve problems.
[01:04:08.500 --> 01:04:10.500]   We'll have another catastrophe.
[01:04:10.500 --> 01:04:13.180]   And hopefully some of these people will step up and do it.
[01:04:13.180 --> 01:04:14.980]   - And ultimately have that long-term impact.
[01:04:14.980 --> 01:04:17.300]   I wonder if this is scalable to,
[01:04:17.300 --> 01:04:20.340]   'cause that's such a great metric for education,
[01:04:20.340 --> 01:04:25.300]   not how to get an A on the test,
[01:04:27.140 --> 01:04:31.300]   but how to be on the cover of New York Times
[01:04:31.300 --> 01:04:32.740]   for inventing something new.
[01:04:32.740 --> 01:04:37.340]   Do you think that's generalizable to education
[01:04:37.340 --> 01:04:39.100]   beyond just this particular Olympia?
[01:04:39.100 --> 01:04:42.700]   Like even you saying this feels like a rare statement,
[01:04:42.700 --> 01:04:45.900]   almost like a radical statement as a goal for education.
[01:04:45.900 --> 01:04:48.740]   - So actually the way I teach my classes at Carnegie Mellon,
[01:04:48.740 --> 01:04:49.900]   which I will admit right away
[01:04:49.900 --> 01:04:52.420]   is not equivalent to the average in the world,
[01:04:52.420 --> 01:04:56.260]   but it's already not just the top 60 in the country
[01:04:56.260 --> 01:04:58.140]   has picked by something.
[01:04:58.140 --> 01:04:58.980]   Let me just explain.
[01:04:58.980 --> 01:05:01.500]   I have exams in my class, which are 90% of the grade.
[01:05:01.500 --> 01:05:02.820]   So the exams are the whole thing,
[01:05:02.820 --> 01:05:03.900]   or most of the whole thing.
[01:05:03.900 --> 01:05:06.620]   And the way that I let students prepare for the exams
[01:05:06.620 --> 01:05:08.860]   is I show them all the problems I've ever given
[01:05:08.860 --> 01:05:10.380]   on the previous exams.
[01:05:10.380 --> 01:05:12.660]   And the exam that they will take is open notes.
[01:05:12.660 --> 01:05:13.740]   They can take all the notes they want
[01:05:13.740 --> 01:05:14.820]   on the previous problems.
[01:05:14.820 --> 01:05:17.220]   And the guarantee is that the exam problems this time
[01:05:17.220 --> 01:05:18.780]   will have no overlap with anything
[01:05:18.780 --> 01:05:20.980]   you have seen me give in the past,
[01:05:20.980 --> 01:05:24.380]   as well as no overlap with anything I taught in the class.
[01:05:24.380 --> 01:05:26.060]   So the entire exam is invention.
[01:05:26.060 --> 01:05:28.580]   - Wow.
[01:05:28.580 --> 01:05:29.740]   - But that's how I go, right?
[01:05:29.740 --> 01:05:32.140]   My point is, I have explained to people,
[01:05:32.140 --> 01:05:35.340]   when I teach you, I don't want you to have remembered
[01:05:35.340 --> 01:05:36.700]   a method I showed you.
[01:05:36.700 --> 01:05:39.300]   I want you to have learned enough about this area
[01:05:39.300 --> 01:05:40.900]   that if you face a new question,
[01:05:40.900 --> 01:05:42.500]   which I came up with the night before,
[01:05:42.500 --> 01:05:44.620]   by thinking about like, what could I ask
[01:05:44.620 --> 01:05:46.180]   that I have never asked before?
[01:05:46.180 --> 01:05:47.020]   Oh, that's cute.
[01:05:47.020 --> 01:05:48.060]   I wonder what the answer is.
[01:05:48.060 --> 01:05:49.180]   Aha, that's an exam problem.
[01:05:49.180 --> 01:05:51.340]   That's exactly what I do before the exam.
[01:05:51.340 --> 01:05:53.860]   And then that's what I want them to learn.
[01:05:53.860 --> 01:05:56.100]   And the first exam, usually people have a rough time
[01:05:56.100 --> 01:05:58.420]   because it's like, what kind of crazy class is this?
[01:05:58.420 --> 01:06:01.940]   The professor doesn't teach you anything for the exam.
[01:06:01.940 --> 01:06:03.500]   But then by the second or third,
[01:06:03.500 --> 01:06:05.300]   and by the time they finish the class,
[01:06:05.300 --> 01:06:09.500]   they have learned how to solve anything in the area.
[01:06:09.500 --> 01:06:10.340]   - How to invent.
[01:06:10.340 --> 01:06:12.300]   - How to invent in that area, yeah.
[01:06:12.300 --> 01:06:15.540]   - Can we walk back to the Mathematical Olympiad?
[01:06:15.540 --> 01:06:17.580]   What's the scoring and format like?
[01:06:17.580 --> 01:06:20.860]   And also what does it take to win?
[01:06:20.860 --> 01:06:24.300]   - So the way it works is that each of the six students
[01:06:24.300 --> 01:06:27.860]   do the problems and there are six problems.
[01:06:27.860 --> 01:06:29.620]   All the problems are equally weighted.
[01:06:29.620 --> 01:06:31.540]   So each one's worth seven points.
[01:06:31.540 --> 01:06:33.420]   That means that your maximum score
[01:06:33.420 --> 01:06:35.060]   is six problems times seven points,
[01:06:35.060 --> 01:06:37.220]   which is the nice number of 42.
[01:06:37.220 --> 01:06:40.380]   And now the way that they're scored, by the way,
[01:06:40.380 --> 01:06:41.700]   is there's partial credit.
[01:06:41.700 --> 01:06:43.260]   So your question is asking you,
[01:06:43.260 --> 01:06:46.380]   explain why this weird fact is true.
[01:06:46.380 --> 01:06:48.740]   Okay, if you explain why, you get seven points.
[01:06:48.740 --> 01:06:51.300]   If you make minor mistake, maybe you get six points.
[01:06:51.300 --> 01:06:53.860]   But if you don't succeed in explaining why,
[01:06:53.860 --> 01:06:57.940]   but you explain some other true fact,
[01:06:57.940 --> 01:07:02.220]   which is along the way of proving it,
[01:07:02.220 --> 01:07:03.980]   then you get partial credit.
[01:07:03.980 --> 01:07:05.700]   And actually now this is tricky
[01:07:05.700 --> 01:07:07.620]   because how do you score such a thing?
[01:07:07.620 --> 01:07:12.340]   It's not like the answer was 72 and you wrote 71
[01:07:12.340 --> 01:07:13.180]   and it's close, right?
[01:07:13.180 --> 01:07:15.300]   The answer is 72 and you wrote 36.
[01:07:15.300 --> 01:07:17.700]   Oh, but that's pretty close because you were,
[01:07:17.700 --> 01:07:18.900]   maybe you were just off by,
[01:07:18.900 --> 01:07:20.420]   by the way, they're not numerical anyway,
[01:07:20.420 --> 01:07:22.700]   but I'm just giving some numerical analog
[01:07:22.700 --> 01:07:24.580]   to the way the scoring might work.
[01:07:24.580 --> 01:07:25.860]   They're all essays.
[01:07:25.860 --> 01:07:28.260]   And that's where I guess I have some role
[01:07:28.260 --> 01:07:29.340]   as well as some other people
[01:07:29.340 --> 01:07:32.380]   who helped me in the US delegation for coaches.
[01:07:32.380 --> 01:07:37.380]   We actually debate with the country which is organizing it.
[01:07:37.380 --> 01:07:39.500]   The country which is organizing the Olympiad
[01:07:39.500 --> 01:07:44.500]   brings about 50 people to help judge the written solutions.
[01:07:45.140 --> 01:07:48.380]   And you schedule these half hour appointments
[01:07:48.380 --> 01:07:50.500]   where the delegation from one country
[01:07:50.500 --> 01:07:52.340]   sits down at a table like this,
[01:07:52.340 --> 01:07:55.540]   opposite side is two or three people from the host country.
[01:07:55.540 --> 01:07:58.700]   And they're just looking over these exam papers saying,
[01:07:58.700 --> 01:08:00.620]   well, how many points is this worth
[01:08:00.620 --> 01:08:03.100]   based on some rubric that has been designed?
[01:08:03.100 --> 01:08:05.580]   And this is a negotiation process
[01:08:05.580 --> 01:08:07.740]   where we're not trying to bargain
[01:08:07.740 --> 01:08:09.340]   and get the best score we can.
[01:08:09.340 --> 01:08:11.660]   In fact, sometimes we go to this table and we will say,
[01:08:11.660 --> 01:08:13.980]   we think we want less than what you gave us.
[01:08:13.980 --> 01:08:16.260]   These are our principles.
[01:08:16.260 --> 01:08:18.780]   If you give us too much, we say, no, you gave us too much.
[01:08:18.780 --> 01:08:19.700]   We do that.
[01:08:19.700 --> 01:08:22.260]   However, the reason why this is an interesting process
[01:08:22.260 --> 01:08:24.180]   is because if you can imagine every country
[01:08:24.180 --> 01:08:26.740]   which is participating has its own language.
[01:08:26.740 --> 01:08:28.740]   And so if you're trying to grade the Mongolian scripts
[01:08:28.740 --> 01:08:31.020]   and they're written in Mongolian,
[01:08:31.020 --> 01:08:33.540]   if you don't read Mongolian, which most people don't,
[01:08:33.540 --> 01:08:36.700]   then the coaches are explaining to you,
[01:08:36.700 --> 01:08:38.740]   this is what the student has written.
[01:08:38.740 --> 01:08:40.460]   It's actually quite interesting process.
[01:08:40.460 --> 01:08:43.420]   - So it's almost like a jury.
[01:08:43.420 --> 01:08:44.260]   - Yes.
[01:08:44.260 --> 01:08:47.140]   - You have, in the American legal system,
[01:08:47.140 --> 01:08:49.860]   you have a jury that where they're deliberating,
[01:08:49.860 --> 01:08:53.620]   but unlike a jury, there's the members of the jury
[01:08:53.620 --> 01:08:55.780]   speaking different languages sometimes.
[01:08:55.780 --> 01:08:57.140]   - Yes. - That's fascinating.
[01:08:57.140 --> 01:09:01.660]   But I mean, it's hard to know what to do
[01:09:01.660 --> 01:09:04.540]   'cause it's probably really, really competitive,
[01:09:04.540 --> 01:09:09.400]   but your sense is that ultimately people,
[01:09:10.300 --> 01:09:15.220]   like how do you prevent manipulation here, right?
[01:09:15.220 --> 01:09:18.020]   - Well, we just hope that it's not happening.
[01:09:18.020 --> 01:09:20.260]   So we write in English,
[01:09:20.260 --> 01:09:23.740]   therefore everything that the US does, everyone can look at.
[01:09:23.740 --> 01:09:25.180]   So it's very hard for me.
[01:09:25.180 --> 01:09:26.980]   - It's very hard for you to manipulate.
[01:09:26.980 --> 01:09:28.580]   - We don't manipulate.
[01:09:28.580 --> 01:09:30.420]   We only hope that other people aren't,
[01:09:30.420 --> 01:09:32.260]   but at the same time, as you see,
[01:09:32.260 --> 01:09:34.300]   our philosophy was we want to use this
[01:09:34.300 --> 01:09:36.500]   as a way to develop general talent.
[01:09:36.500 --> 01:09:39.380]   And although we do this for the six people who go
[01:09:39.380 --> 01:09:41.460]   to the International Math Olympiad,
[01:09:41.460 --> 01:09:44.820]   we really want that everyone touched at any stage
[01:09:44.820 --> 01:09:46.980]   of this process gets some skills
[01:09:46.980 --> 01:09:48.980]   that can help to contribute more later.
[01:09:48.980 --> 01:09:52.340]   - So I don't know if you can say something insightful
[01:09:52.340 --> 01:09:54.820]   to this question, but what do you think
[01:09:54.820 --> 01:09:58.660]   makes a really hard math problem on this Olympiad,
[01:09:58.660 --> 01:10:01.940]   maybe in the courses you teach or in general,
[01:10:01.940 --> 01:10:04.220]   what makes for a hard problem?
[01:10:04.220 --> 01:10:07.060]   You've seen, I'm sure, a lot of really difficult problems.
[01:10:07.060 --> 01:10:08.620]   What makes a hard problem?
[01:10:08.620 --> 01:10:12.940]   - So I could quantify it by the number of leaps of insight,
[01:10:12.940 --> 01:10:15.220]   of changes of perspective that are along the way.
[01:10:15.220 --> 01:10:16.460]   And here's why.
[01:10:16.460 --> 01:10:18.300]   This is like a very theoretical computer science
[01:10:18.300 --> 01:10:19.300]   way of looking at it.
[01:10:19.300 --> 01:10:23.260]   Okay, it's that each reframing of the problem
[01:10:23.260 --> 01:10:24.580]   and using of some tool,
[01:10:24.580 --> 01:10:26.100]   I actually call that a leap of insight.
[01:10:26.100 --> 01:10:29.020]   When you say, oh, wow, now I see I should kind
[01:10:29.020 --> 01:10:32.620]   of put these plugs into those sockets, like so.
[01:10:32.620 --> 01:10:34.540]   And suddenly I get to use that machine.
[01:10:34.540 --> 01:10:35.780]   Oh, but I'm not done yet.
[01:10:35.780 --> 01:10:37.020]   Now I need to do it again.
[01:10:37.020 --> 01:10:39.820]   Each such step is a large possible,
[01:10:39.820 --> 01:10:41.900]   large fan out in the search space.
[01:10:41.900 --> 01:10:44.860]   The number of these tells you the exponent.
[01:10:44.860 --> 01:10:47.380]   The base of the exponent is like how big,
[01:10:47.380 --> 01:10:50.220]   how many different possibilities you could try.
[01:10:50.220 --> 01:10:51.940]   And that's actually why,
[01:10:51.940 --> 01:10:55.020]   like if you have a three insight problem,
[01:10:55.020 --> 01:10:58.380]   that is not three times as hard as a one insight problem,
[01:10:58.380 --> 01:10:59.900]   because after you've made the one insight,
[01:10:59.900 --> 01:11:03.740]   it's not clear that that was the right track necessarily.
[01:11:03.740 --> 01:11:04.580]   Well, unless you're-
[01:11:04.580 --> 01:11:07.180]   - It's a branching of possible, yeah.
[01:11:07.180 --> 01:11:09.260]   (laughs)
[01:11:09.260 --> 01:11:12.900]   You're saying there's problems like on the math Olympia
[01:11:12.900 --> 01:11:14.340]   that requires more than one insight?
[01:11:14.340 --> 01:11:15.700]   - Yes, those are the hard ones.
[01:11:15.700 --> 01:11:18.100]   And also I can tell you how you can tell.
[01:11:18.100 --> 01:11:20.300]   So this is how I also taught myself math
[01:11:20.300 --> 01:11:21.220]   when I was in college.
[01:11:21.220 --> 01:11:24.060]   So if you are taking a, not taught myself,
[01:11:24.060 --> 01:11:25.380]   I was taking classes, of course,
[01:11:25.380 --> 01:11:27.220]   but I was trying to read the textbook
[01:11:27.220 --> 01:11:29.980]   and I found out I was very bad at reading math textbooks.
[01:11:29.980 --> 01:11:33.260]   A math textbook has a long page of stuff that is all true,
[01:11:33.260 --> 01:11:34.540]   which after you read the page,
[01:11:34.540 --> 01:11:36.140]   you have no idea what you just read.
[01:11:36.140 --> 01:11:37.420]   - Yeah.
[01:11:37.420 --> 01:11:38.260]   - This is just-
[01:11:38.260 --> 01:11:39.660]   - A good summary of a math textbook.
[01:11:39.660 --> 01:11:42.700]   - Okay, yeah, because it's not clear
[01:11:42.700 --> 01:11:44.660]   why anything was done that way.
[01:11:44.660 --> 01:11:45.900]   And yes, everything is true,
[01:11:45.900 --> 01:11:47.860]   but how the heck did anyone think of that?
[01:11:47.860 --> 01:11:51.380]   So the way that I taught myself math eventually was,
[01:11:51.380 --> 01:11:54.580]   the way I read a math textbook is I would look at
[01:11:54.580 --> 01:11:56.140]   the theorem statement,
[01:11:56.140 --> 01:11:58.980]   I would look at the length of the proof,
[01:11:58.980 --> 01:12:00.060]   and then I would close the book
[01:12:00.060 --> 01:12:01.340]   and attempt to reprove it myself.
[01:12:01.340 --> 01:12:03.020]   - Yeah, that's brilliant.
[01:12:03.580 --> 01:12:04.980]   - The length of the proof
[01:12:04.980 --> 01:12:06.820]   is telling you the number of insights,
[01:12:06.820 --> 01:12:08.060]   because the length of the proof
[01:12:08.060 --> 01:12:10.820]   is linear in the number of insights.
[01:12:10.820 --> 01:12:12.220]   Each insight takes space.
[01:12:12.220 --> 01:12:13.060]   - Yeah.
[01:12:13.060 --> 01:12:14.660]   - And if I know that it's a short proof,
[01:12:14.660 --> 01:12:16.140]   I know that there's only one insight.
[01:12:16.140 --> 01:12:19.020]   So when I'm doing my own way of solving the problem,
[01:12:19.020 --> 01:12:20.540]   like finding the proof,
[01:12:20.540 --> 01:12:23.140]   I quit if I have to do too many plug-ins.
[01:12:23.140 --> 01:12:24.900]   It's equivalent to a math contest.
[01:12:24.900 --> 01:12:27.220]   In a math contest, I look, is it problem one, two, or three?
[01:12:27.220 --> 01:12:28.940]   That tells me how many insights there are.
[01:12:28.940 --> 01:12:29.980]   This is exactly what I did.
[01:12:29.980 --> 01:12:31.100]   - That's brilliant.
[01:12:31.100 --> 01:12:32.100]   Linear in the number.
[01:12:32.100 --> 01:12:32.940]   I don't know.
[01:12:32.940 --> 01:12:36.380]   I think, oh, it's possible that that's true.
[01:12:36.380 --> 01:12:37.220]   - Approximately, approximately.
[01:12:37.220 --> 01:12:38.500]   - Approximately, yeah.
[01:12:38.500 --> 01:12:39.780]   I don't know, it would be,
[01:12:39.780 --> 01:12:43.060]   somebody out there is gonna try to formally prove this.
[01:12:43.060 --> 01:12:44.180]   - Oh, no, I mean, you're right.
[01:12:44.180 --> 01:12:46.100]   There are cases where maybe it's not quite linear,
[01:12:46.100 --> 01:12:47.060]   but in general--
[01:12:47.060 --> 01:12:48.380]   - Well, some of it is notation too,
[01:12:48.380 --> 01:12:50.940]   and some of it is style, and all those kinds of things,
[01:12:50.940 --> 01:12:51.900]   but within a textbook.
[01:12:51.900 --> 01:12:52.780]   - Within the same book.
[01:12:52.780 --> 01:12:53.900]   - Within the same book with the same--
[01:12:53.900 --> 01:12:56.180]   - Yes, within the same book on the same subject.
[01:12:56.180 --> 01:12:57.020]   - Yeah.
[01:12:57.020 --> 01:12:57.860]   - This is what I was using.
[01:12:57.860 --> 01:12:58.780]   - That's hilarious.
[01:12:58.780 --> 01:13:00.420]   - Because you know, if it's a two-page proof,
[01:13:00.420 --> 01:13:02.780]   you just know this is gonna be insane, right?
[01:13:02.780 --> 01:13:06.940]   - That's the scary thing about insights.
[01:13:06.940 --> 01:13:08.220]   You look like Andrew Wiles
[01:13:08.220 --> 01:13:10.180]   working on the Fermat's Last Theorem,
[01:13:10.180 --> 01:13:13.620]   is you don't know.
[01:13:13.620 --> 01:13:16.220]   Something seems like a good idea,
[01:13:16.220 --> 01:13:17.300]   and you have that idea,
[01:13:17.300 --> 01:13:19.260]   and it feels like this is a leap,
[01:13:19.260 --> 01:13:22.300]   like a totally new way to see it,
[01:13:22.300 --> 01:13:25.780]   but you have no idea if it's at all useful.
[01:13:25.780 --> 01:13:27.020]   Even if you think it's correct,
[01:13:27.020 --> 01:13:30.140]   you have no idea if this is going to go down a path
[01:13:30.140 --> 01:13:32.500]   that's completely counterproductive
[01:13:32.500 --> 01:13:34.580]   or not productive at all.
[01:13:34.580 --> 01:13:37.860]   That's the crappy thing about invention,
[01:13:37.860 --> 01:13:41.140]   like I have, I'm sure you do,
[01:13:41.140 --> 01:13:44.740]   I have a lot of really good ideas every single day,
[01:13:44.740 --> 01:13:49.660]   but like, and I'll go inside my head along them,
[01:13:49.660 --> 01:13:52.100]   along that little trajectory,
[01:13:52.100 --> 01:13:54.700]   but it could be just a total waste.
[01:13:54.700 --> 01:13:57.220]   And it's, you know what that feels like?
[01:13:57.220 --> 01:13:59.500]   It just feels like patience is required,
[01:13:59.500 --> 01:14:01.820]   not to get excited at any one thing.
[01:14:01.820 --> 01:14:03.340]   - So I think this is interesting
[01:14:03.340 --> 01:14:04.820]   because you raised Andrew Wiles,
[01:14:04.820 --> 01:14:08.380]   he spent seven years attacking the same thing, right?
[01:14:08.380 --> 01:14:10.340]   And so I think that what attracts
[01:14:10.340 --> 01:14:12.300]   professional researchers to this
[01:14:12.300 --> 01:14:14.900]   is because even though it's very painful
[01:14:14.900 --> 01:14:16.700]   that you keep fighting with something,
[01:14:16.700 --> 01:14:19.500]   when you finally find the right insights
[01:14:19.500 --> 01:14:22.300]   and string them together, it feels really good.
[01:14:22.300 --> 01:14:23.140]   So-
[01:14:23.140 --> 01:14:26.060]   - Well, there's also like short-term,
[01:14:26.060 --> 01:14:31.060]   it feels good to, whether it's real or not,
[01:14:31.060 --> 01:14:33.540]   to pretend like you've solved something
[01:14:33.540 --> 01:14:35.660]   in the sense like you have an insight
[01:14:35.660 --> 01:14:37.940]   and there's a sense like this might be the insight
[01:14:37.940 --> 01:14:38.980]   that solves it.
[01:14:38.980 --> 01:14:43.980]   So at least for me, I just enjoy that rush of positivity,
[01:14:43.980 --> 01:14:46.460]   even though I know statistically speaking
[01:14:46.460 --> 01:14:48.500]   is probably going to be a dead end.
[01:14:48.500 --> 01:14:49.820]   - I'm the same way, I'm the same way.
[01:14:49.820 --> 01:14:52.460]   In fact, that's how I know whether I might want
[01:14:52.460 --> 01:14:54.340]   to keep thinking about this general problem.
[01:14:54.340 --> 01:14:57.300]   It's like, if I still see that I'm getting some insights,
[01:14:57.300 --> 01:14:59.020]   I'm not at a dead end yet.
[01:14:59.020 --> 01:15:00.660]   But that's also where I learned something
[01:15:00.660 --> 01:15:01.940]   from my PhD advisor.
[01:15:01.940 --> 01:15:04.260]   Actually, he was a real big inspiration on my life.
[01:15:04.260 --> 01:15:05.740]   His name is Benny Sudakov.
[01:15:05.740 --> 01:15:08.100]   In fact, he grew up in the former Soviet Union.
[01:15:08.100 --> 01:15:12.260]   He was from Georgia, but he's an incredible person.
[01:15:12.260 --> 01:15:16.660]   But one thing I learned was choose the problems to work on
[01:15:16.660 --> 01:15:21.100]   that might matter if you succeed.
[01:15:21.100 --> 01:15:23.420]   Because that's why, for example, we dug into COVID.
[01:15:23.420 --> 01:15:25.820]   It was just, well, suppose we succeed
[01:15:25.820 --> 01:15:27.860]   in finding some interesting insight here.
[01:15:27.860 --> 01:15:29.140]   Well, it actually matters.
[01:15:29.140 --> 01:15:31.020]   Then it's worthwhile.
[01:15:31.020 --> 01:15:36.020]   - Yeah, and I think COVID, the way you're approaching COVID
[01:15:36.020 --> 01:15:38.260]   has two interesting possibilities.
[01:15:38.260 --> 01:15:41.740]   One, it might help with COVID or another pandemic.
[01:15:41.740 --> 01:15:46.740]   But two, I mean, just this whole network theory space,
[01:15:46.740 --> 01:15:51.240]   you might unlock some deep understanding
[01:15:51.240 --> 01:15:53.100]   about the interaction with human beings
[01:15:53.100 --> 01:15:55.900]   that might have nothing to do with the pandemic.
[01:15:55.900 --> 01:15:58.380]   There's a space of possible impacts
[01:15:58.380 --> 01:16:00.460]   that may be direct or indirect.
[01:16:00.460 --> 01:16:03.300]   And the same thing is with Andrew Wiles' proof.
[01:16:03.300 --> 01:16:08.140]   I don't understand, but apparently the pieces of it
[01:16:08.140 --> 01:16:12.060]   are really impactful for mathematics,
[01:16:12.060 --> 01:16:14.900]   even if the main theorem is not.
[01:16:14.900 --> 01:16:18.300]   So along the way, the insights you have
[01:16:18.300 --> 01:16:22.960]   might be really powerful for unexpected reasons.
[01:16:22.960 --> 01:16:23.820]   - So I like what you said.
[01:16:23.820 --> 01:16:26.180]   This is something that I learned from another friend of mine
[01:16:26.180 --> 01:16:28.100]   who's also, he's a very famous researcher.
[01:16:28.100 --> 01:16:30.020]   All these people are more famous than I am.
[01:16:30.020 --> 01:16:30.980]   His name is Jacob Fox.
[01:16:30.980 --> 01:16:32.220]   He's Jacob Fox at Stanford.
[01:16:32.220 --> 01:16:33.820]   Also a very big inspiration for me.
[01:16:33.820 --> 01:16:36.060]   We were both grad students together at the same time.
[01:16:36.060 --> 01:16:36.880]   - Well, most importantly,
[01:16:36.880 --> 01:16:38.260]   you're good at selecting good friends.
[01:16:38.260 --> 01:16:39.940]   - Ah, yeah, well, that's the key.
[01:16:39.940 --> 01:16:41.980]   You gotta find good people to learn things from.
[01:16:41.980 --> 01:16:44.340]   But his thing was, he often said,
[01:16:44.340 --> 01:16:46.780]   if you solve a math problem and have this math proof,
[01:16:46.780 --> 01:16:48.900]   math problem for him is like a proof, right?
[01:16:48.900 --> 01:16:50.300]   So suppose you came up with this proof.
[01:16:50.300 --> 01:16:53.400]   He always asks, what have we learned from this
[01:16:53.400 --> 01:16:56.000]   that we could potentially use for something else?
[01:16:56.000 --> 01:16:58.040]   It's not just, did you solve the problem
[01:16:58.040 --> 01:16:59.400]   that was supposed to be famous?
[01:16:59.400 --> 01:17:01.520]   It was, and is there something new
[01:17:01.520 --> 01:17:04.560]   in the course of solving this that you had to invent
[01:17:04.560 --> 01:17:06.680]   that we could now use as a tool elsewhere?
[01:17:06.680 --> 01:17:08.880]   - Yeah, there's this funny effect
[01:17:08.880 --> 01:17:12.680]   where just looking at different fields
[01:17:12.680 --> 01:17:15.000]   where people discover parallels.
[01:17:15.000 --> 01:17:17.520]   They'll prove something, it'll be a totally new result,
[01:17:17.520 --> 01:17:19.040]   and then somebody later realizes
[01:17:19.040 --> 01:17:20.660]   this was already done 30 years ago
[01:17:20.660 --> 01:17:23.360]   in another discipline in another way.
[01:17:23.360 --> 01:17:25.080]   And it's really interesting.
[01:17:25.080 --> 01:17:30.220]   We did this offline in another illustration he showed to me.
[01:17:30.220 --> 01:17:33.900]   It's interesting to see the different perspectives
[01:17:33.900 --> 01:17:35.560]   on a problem.
[01:17:35.560 --> 01:17:40.560]   It kind of points like there's just very few novel ideas,
[01:17:40.560 --> 01:17:43.280]   that everything else, that most of us
[01:17:43.280 --> 01:17:47.200]   are just looking at different perspective on the same idea.
[01:17:47.200 --> 01:17:51.540]   And it makes you wonder this old silly question
[01:17:51.540 --> 01:17:53.840]   that I have to ask you is,
[01:17:53.840 --> 01:17:58.200]   do you think mathematics is discovered or invented?
[01:17:58.200 --> 01:18:02.560]   Do you think we're creating new idea,
[01:18:02.560 --> 01:18:05.160]   we're building a set of knowledge
[01:18:05.160 --> 01:18:09.180]   that's distinct from reality,
[01:18:09.180 --> 01:18:13.440]   or are we actually, is math almost like a shovel
[01:18:13.440 --> 01:18:16.800]   where we're digging to this core set of truths
[01:18:16.800 --> 01:18:19.960]   that were always there all along?
[01:18:19.960 --> 01:18:22.760]   - So I personally feel like it's discovered,
[01:18:22.760 --> 01:18:24.680]   but that's also because I guess the way
[01:18:24.680 --> 01:18:27.360]   that I like to choose what questions to work on
[01:18:27.360 --> 01:18:29.960]   are questions that maybe we'll get to learn something
[01:18:29.960 --> 01:18:32.160]   about why is this hard?
[01:18:32.160 --> 01:18:33.840]   I mean, I'm often attracted to questions
[01:18:33.840 --> 01:18:36.840]   that look simple, but are hard, right?
[01:18:36.840 --> 01:18:38.640]   And what could you possibly learn from that?
[01:18:38.640 --> 01:18:40.240]   Sort of like probably the attraction
[01:18:40.240 --> 01:18:42.640]   of Fermat's last theorem, as you mentioned,
[01:18:42.640 --> 01:18:44.920]   simple statement, why is it so hard?
[01:18:44.920 --> 01:18:47.480]   So I'm more on the discovered side.
[01:18:47.480 --> 01:18:49.320]   And I also feel like if we ever ran
[01:18:49.320 --> 01:18:53.060]   into an intelligent other species in the universe,
[01:18:53.060 --> 01:18:56.920]   probably if we compared notes,
[01:18:56.920 --> 01:18:58.880]   there might be some similarities
[01:18:58.880 --> 01:19:02.200]   between both of us realizing that pi is important.
[01:19:02.200 --> 01:19:03.560]   Because you might say, why?
[01:19:03.560 --> 01:19:06.000]   Why humans, do humans like circles more than others?
[01:19:06.000 --> 01:19:08.040]   I think stars also like circles.
[01:19:08.040 --> 01:19:09.800]   I think planets like circles.
[01:19:09.800 --> 01:19:10.840]   They're not perfect circles,
[01:19:10.840 --> 01:19:13.080]   but nevertheless, the concept of a circle
[01:19:13.080 --> 01:19:15.640]   is just point and constant distance.
[01:19:15.640 --> 01:19:17.280]   Doesn't get any simpler than that.
[01:19:17.280 --> 01:19:19.880]   - It's possible that like an alien species
[01:19:19.880 --> 01:19:23.160]   will have, depending on different cognitive capabilities
[01:19:23.160 --> 01:19:24.920]   and different perception systems,
[01:19:24.920 --> 01:19:28.080]   will be able to see things
[01:19:28.080 --> 01:19:30.320]   that are much different than circles.
[01:19:30.320 --> 01:19:34.600]   And so if it's discovered, it will still be pointing
[01:19:34.600 --> 01:19:37.200]   at a lot of same geometrical concepts,
[01:19:37.200 --> 01:19:42.200]   mathematical concepts, but it's interesting to think
[01:19:42.280 --> 01:19:45.680]   of how many things we would have to still align,
[01:19:45.680 --> 01:19:48.480]   not just based on notation, but based on understanding,
[01:19:48.480 --> 01:19:53.480]   like just the, like some basic mathematical concepts,
[01:19:53.480 --> 01:19:56.840]   like how much work is there going to be
[01:19:56.840 --> 01:19:59.200]   in trying to find a common language?
[01:19:59.200 --> 01:20:01.680]   I mean, this is, I think Stephen Wolfe,
[01:20:01.680 --> 01:20:04.560]   I mean, his son helped with the movie "Arrival,"
[01:20:04.560 --> 01:20:07.200]   like the developing an alien language,
[01:20:07.200 --> 01:20:09.500]   like how would aliens communicate with humans?
[01:20:10.600 --> 01:20:12.900]   It's fascinating 'cause like math seems
[01:20:12.900 --> 01:20:15.880]   to be the most promising thing, but even like math,
[01:20:15.880 --> 01:20:20.880]   like how do you visualize mathematical ideas?
[01:20:20.880 --> 01:20:24.620]   It feels like there has to be an interactive component,
[01:20:24.620 --> 01:20:26.520]   just like we have a conversation.
[01:20:26.520 --> 01:20:29.080]   There has to be, this is something we don't, I think,
[01:20:29.080 --> 01:20:31.420]   think about often, which is like,
[01:20:31.420 --> 01:20:33.840]   with somebody who doesn't know anything about math,
[01:20:33.840 --> 01:20:35.440]   doesn't know anything about English
[01:20:35.440 --> 01:20:40.080]   or any other natural language, how would we describe,
[01:20:40.080 --> 01:20:42.400]   we talked offline about visual proofs.
[01:20:42.400 --> 01:20:47.400]   How would we, through visual proofs, have a conversation
[01:20:47.400 --> 01:20:50.160]   where we say something, here's the concept,
[01:20:50.160 --> 01:20:53.780]   the way we see it, does that make sense to you?
[01:20:53.780 --> 01:20:57.400]   And like, can you mess with that concept
[01:20:57.400 --> 01:20:58.840]   to make it sense for you?
[01:20:58.840 --> 01:21:01.440]   And then go back and forth in this kind of way.
[01:21:01.440 --> 01:21:03.760]   So purely through mathematics, I'm sure it's possible
[01:21:03.760 --> 01:21:05.880]   to have those kinds of experiments with like tribes
[01:21:05.880 --> 01:21:08.400]   on earth that don't, there's no common language.
[01:21:08.400 --> 01:21:10.840]   Through math, like draw a circle
[01:21:10.840 --> 01:21:13.200]   and see what they do with it, right?
[01:21:13.200 --> 01:21:15.640]   Do some of these visual proofs,
[01:21:15.640 --> 01:21:19.720]   like the summation of the odds and adds up to the squares.
[01:21:19.720 --> 01:21:21.960]   Yes, I wonder how difficult that is
[01:21:21.960 --> 01:21:24.320]   before one or the other species murders.
[01:21:24.320 --> 01:21:26.120]   (all laughing)
[01:21:26.120 --> 01:21:27.720]   - That's a good question.
[01:21:27.720 --> 01:21:29.760]   - I hope that the curiosity for knowledge
[01:21:29.760 --> 01:21:31.480]   will overpower the greedy.
[01:21:31.480 --> 01:21:33.520]   This is back to our game theory thing,
[01:21:33.520 --> 01:21:37.260]   that the curiosity of like discovering math together
[01:21:37.260 --> 01:21:40.040]   will overpower the desire for resources
[01:21:40.040 --> 01:21:42.840]   and ultimately like, you know,
[01:21:42.840 --> 01:21:46.440]   willing to commit violence in order to gain those resources.
[01:21:46.440 --> 01:21:47.920]   I think as we progress,
[01:21:47.920 --> 01:21:50.080]   become more and more intelligent as a species,
[01:21:50.080 --> 01:21:53.320]   I'm hoping we would value more and more of the knowledge
[01:21:53.320 --> 01:21:54.880]   because we'll come up with clever ways
[01:21:54.880 --> 01:21:58.160]   to gain more resources so we won't be so resource starved.
[01:21:58.160 --> 01:21:59.000]   I don't know.
[01:21:59.000 --> 01:22:01.240]   That's a hopeful message for when we finally meet aliens.
[01:22:01.240 --> 01:22:02.080]   - Yeah, yeah.
[01:22:02.080 --> 01:22:05.740]   - See, the cool thing about the math Olympiad,
[01:22:07.100 --> 01:22:11.360]   I don't know if you know work from Francois Chollet
[01:22:11.360 --> 01:22:16.360]   from Google, he came up with this kind of IQ test slash,
[01:22:16.360 --> 01:22:20.920]   it kind of has a similar aspects to it
[01:22:20.920 --> 01:22:25.920]   that also the math Olympiad does for AI.
[01:22:25.920 --> 01:22:27.920]   So he came up with these tests
[01:22:27.920 --> 01:22:31.120]   where they're very simple for humans,
[01:22:31.120 --> 01:22:34.340]   but very difficult for AI to illustrate exactly
[01:22:34.340 --> 01:22:39.080]   why we're just not good at seeing a totally new problem.
[01:22:39.080 --> 01:22:45.120]   We, sorry, AI systems are not good at looking
[01:22:45.120 --> 01:22:48.720]   at a new problem that requires you to detect
[01:22:48.720 --> 01:22:50.560]   that there's a symmetry of some kind,
[01:22:50.560 --> 01:22:55.560]   or there's a pattern that hasn't seen before.
[01:22:55.560 --> 01:22:58.760]   The pattern is like obvious to us humans,
[01:22:58.760 --> 01:23:01.560]   but it's not so obvious to find that kind of,
[01:23:01.560 --> 01:23:04.260]   you're inventing a pattern that's there
[01:23:04.260 --> 01:23:08.500]   in order to then find a solution.
[01:23:08.500 --> 01:23:14.220]   I don't know if you can comment on,
[01:23:14.220 --> 01:23:16.280]   but from an AI perspective
[01:23:16.280 --> 01:23:19.420]   and from a math problem perspective,
[01:23:19.420 --> 01:23:22.140]   what do you think is intelligence?
[01:23:22.140 --> 01:23:24.380]   What do you think is the thing that allows us
[01:23:24.380 --> 01:23:25.740]   to solve that problem?
[01:23:25.740 --> 01:23:29.540]   And how hard is it to build a machine to do that?
[01:23:29.540 --> 01:23:30.580]   Asking for a friend.
[01:23:30.580 --> 01:23:33.000]   - Yeah, well, so I guess, you see,
[01:23:33.000 --> 01:23:35.920]   because if I just think of the raw search space, it's huge.
[01:23:35.920 --> 01:23:37.000]   That's why you can't do it.
[01:23:37.000 --> 01:23:38.960]   And if I think about what makes somebody good
[01:23:38.960 --> 01:23:42.320]   at doing these things, they have this heuristic sense.
[01:23:42.320 --> 01:23:44.320]   It's almost like a good chess player of saying,
[01:23:44.320 --> 01:23:45.960]   let's not keep analyzing down this way
[01:23:45.960 --> 01:23:47.600]   because there's some heuristic reason
[01:23:47.600 --> 01:23:49.240]   why that's a bad way to go.
[01:23:49.240 --> 01:23:50.520]   Where did they get that heuristic from?
[01:23:50.520 --> 01:23:51.760]   Now, that's a good question.
[01:23:51.760 --> 01:23:53.000]   I don't know.
[01:23:53.000 --> 01:23:56.680]   Because that, if you asked them to explain to you,
[01:23:56.680 --> 01:23:58.200]   they could probably say something in words
[01:23:58.200 --> 01:23:59.640]   that sounds like it makes sense,
[01:23:59.640 --> 01:24:01.260]   but I'm guessing that's only a part
[01:24:01.260 --> 01:24:03.020]   of what's really going on in their brain
[01:24:03.020 --> 01:24:04.780]   of evaluating that position.
[01:24:04.780 --> 01:24:05.620]   You know what I mean?
[01:24:05.620 --> 01:24:06.820]   If you ask Garry Kasparov, what is good,
[01:24:06.820 --> 01:24:08.620]   or why is this position good?
[01:24:08.620 --> 01:24:10.220]   He will say something.
[01:24:10.220 --> 01:24:12.540]   But probably not approximating everything
[01:24:12.540 --> 01:24:14.020]   that's going on inside.
[01:24:14.020 --> 01:24:16.900]   So there's basically a function being computed.
[01:24:16.900 --> 01:24:19.180]   But it's hard to articulate what that function is.
[01:24:19.180 --> 01:24:21.740]   Now, the question is, could a computer get as good
[01:24:21.740 --> 01:24:24.220]   at computing these kinds of heuristic functions?
[01:24:24.220 --> 01:24:25.060]   Maybe.
[01:24:25.060 --> 01:24:27.860]   I'm not enough of an expert to understand,
[01:24:27.860 --> 01:24:30.320]   but one bit of me has always been a little bit curious
[01:24:30.320 --> 01:24:34.180]   of whether or not the human brain has a particular tendency
[01:24:34.180 --> 01:24:37.480]   due to its wiring to come up with certain kinds of things,
[01:24:37.480 --> 01:24:39.520]   which is just natural due to the way
[01:24:39.520 --> 01:24:43.520]   that the topology of the neurons and whatever is there,
[01:24:43.520 --> 01:24:46.120]   for which if you tried to just build from scratch
[01:24:46.120 --> 01:24:47.280]   a computer to do it,
[01:24:47.280 --> 01:24:49.640]   would it naturally have different tendencies?
[01:24:49.640 --> 01:24:50.480]   I don't know.
[01:24:50.480 --> 01:24:52.240]   This is just me being completely ignorant
[01:24:52.240 --> 01:24:53.640]   and just saying a few ideas.
[01:24:53.640 --> 01:24:56.160]   - Well, this is a good thing that mathematics shows
[01:24:56.160 --> 01:24:59.600]   is we don't have to be, so math and physics
[01:24:59.600 --> 01:25:01.840]   or mathematical physics operates in a world
[01:25:01.840 --> 01:25:06.840]   that's different than our descendants of a brains operate in.
[01:25:06.840 --> 01:25:11.980]   So it allows us to have multiple, many, many dimensions.
[01:25:11.980 --> 01:25:15.520]   It allows us to work on weird surfaces.
[01:25:15.520 --> 01:25:20.040]   I would like topology as a discipline is just weird to me.
[01:25:20.040 --> 01:25:21.220]   It's really complicated,
[01:25:21.220 --> 01:25:23.600]   but it allows us to work in that space,
[01:25:23.600 --> 01:25:25.920]   differential geometry and all those kinds of things
[01:25:25.920 --> 01:25:30.640]   where it's totally outside of our natural day-to-day
[01:25:30.640 --> 01:25:33.360]   four-dimensional experience,
[01:25:33.360 --> 01:25:35.400]   3D dimensional with time experience.
[01:25:35.400 --> 01:25:40.080]   So math gives me hope that we can see,
[01:25:40.080 --> 01:25:46.320]   we can discover the processes of intelligence
[01:25:46.320 --> 01:25:52.000]   outside the limited nature of our own human experiences.
[01:25:52.000 --> 01:25:55.000]   But you said that you're not an expert.
[01:25:55.960 --> 01:25:57.240]   It's kind of funny.
[01:25:57.240 --> 01:26:02.240]   I find that we know so little about intelligence
[01:26:02.240 --> 01:26:06.800]   that I think, I honestly think like almost children
[01:26:06.800 --> 01:26:11.400]   are more expert at creating artificial intelligence systems
[01:26:11.400 --> 01:26:14.400]   than adults.
[01:26:14.400 --> 01:26:15.780]   I feel like we know so little,
[01:26:15.780 --> 01:26:18.200]   we really need to think outside the box.
[01:26:18.200 --> 01:26:22.120]   And those little, I found people should check out
[01:26:22.120 --> 01:26:24.640]   Francois Chollet's little exams,
[01:26:24.640 --> 01:26:27.080]   but even just solving math problems,
[01:26:27.080 --> 01:26:30.560]   I don't know if you've ever done this for yourself,
[01:26:30.560 --> 01:26:33.400]   but when you solve a math problem,
[01:26:33.400 --> 01:26:38.160]   you kind of then trace back and try to figure out
[01:26:38.160 --> 01:26:39.840]   where did that idea come from?
[01:26:39.840 --> 01:26:45.280]   Like, what was I visualizing in my head?
[01:26:45.280 --> 01:26:47.340]   How did I start visualizing it that way?
[01:26:47.340 --> 01:26:52.280]   Why did I start rotating that cube in my head in that way?
[01:26:52.280 --> 01:26:53.120]   Like, what is that?
[01:26:53.120 --> 01:26:55.520]   If I were to try to build a program that does that,
[01:26:55.520 --> 01:26:56.920]   where did that come from?
[01:26:56.920 --> 01:26:58.200]   - So this is interesting.
[01:26:58.200 --> 01:27:02.760]   So I tried to do this to teach middle school students
[01:27:02.760 --> 01:27:05.640]   how to learn how to create and think and invent.
[01:27:05.640 --> 01:27:07.360]   And the way I do it is there are
[01:27:07.360 --> 01:27:09.000]   these math competition problems,
[01:27:09.000 --> 01:27:10.600]   and I'm working in collaboration
[01:27:10.600 --> 01:27:12.080]   with the people who run those,
[01:27:12.080 --> 01:27:14.120]   and I will turn on my YouTube Live,
[01:27:14.120 --> 01:27:16.440]   and for the first time look at those questions
[01:27:16.440 --> 01:27:17.520]   and live solve them.
[01:27:17.520 --> 01:27:21.240]   The reason I do this is to let the middle school students
[01:27:21.240 --> 01:27:22.480]   and the high school students and the adults,
[01:27:22.480 --> 01:27:23.480]   whoever wants to watch,
[01:27:23.480 --> 01:27:27.440]   just see what exactly goes on through someone's head
[01:27:27.440 --> 01:27:30.480]   as they go and attempt to invent what they need to do
[01:27:30.480 --> 01:27:32.120]   to solve the question.
[01:27:32.120 --> 01:27:34.560]   So I've actually thought about that.
[01:27:34.560 --> 01:27:37.640]   I think that, first of all, as a teacher,
[01:27:37.640 --> 01:27:40.000]   I think about that because whenever I want to explain
[01:27:40.000 --> 01:27:42.080]   to a student how to do something,
[01:27:42.080 --> 01:27:44.160]   I want to explain how it made sense,
[01:27:44.160 --> 01:27:46.200]   why it's intuitive to do the following things,
[01:27:46.200 --> 01:27:48.720]   and why the wrong things are wrong,
[01:27:48.720 --> 01:27:51.900]   not just by this one short, fast way.
[01:27:51.900 --> 01:27:54.680]   But why this is the right way, if that makes sense.
[01:27:54.680 --> 01:27:57.280]   So my point is I'm actually always thinking about that.
[01:27:57.280 --> 01:27:58.960]   Like, how would you think about these things?
[01:27:58.960 --> 01:28:01.800]   And then I eventually decided the easiest way to expose this
[01:28:01.800 --> 01:28:05.200]   would just be to go live on YouTube and just say,
[01:28:05.200 --> 01:28:07.840]   I've never seen any of these questions before, here we go.
[01:28:07.840 --> 01:28:12.760]   - Don't you get, that's anxiety inducing for me.
[01:28:12.760 --> 01:28:16.200]   Don't you get trapped in a kind of like
[01:28:16.200 --> 01:28:18.760]   little dead ends of confusion,
[01:28:18.760 --> 01:28:20.400]   even on middle school problems?
[01:28:20.400 --> 01:28:22.020]   - Yes, that's what the comments are for.
[01:28:22.020 --> 01:28:24.640]   The live comments come in and students say, try this.
[01:28:24.640 --> 01:28:25.640]   - Oh, wow.
[01:28:25.640 --> 01:28:26.680]   - It's actually pretty good.
[01:28:26.680 --> 01:28:27.800]   And I'll never get stuck.
[01:28:27.800 --> 01:28:30.480]   I mean, I'm willing to go on camera and say,
[01:28:30.480 --> 01:28:33.180]   guess what, potion though can't do this, that's fine.
[01:28:33.180 --> 01:28:35.800]   But then what ends up happening is you will then see
[01:28:35.800 --> 01:28:37.360]   how maybe somebody's saying something,
[01:28:37.360 --> 01:28:39.360]   and I look at the chat and I say, aha,
[01:28:39.360 --> 01:28:40.680]   that actually looks useful.
[01:28:40.680 --> 01:28:44.080]   Now that also shows how not all ideas,
[01:28:44.080 --> 01:28:46.920]   not all suggestions are the same power, if that makes sense.
[01:28:46.920 --> 01:28:48.180]   Because if I actually do get stuck,
[01:28:48.180 --> 01:28:49.440]   I'll go fishing through the chat.
[01:28:49.440 --> 01:28:50.840]   - You haven't got any ideas.
[01:28:50.840 --> 01:28:53.340]   - I don't know if you can speak to this,
[01:28:53.340 --> 01:28:57.400]   but is there a moment for the middle school students,
[01:28:57.400 --> 01:28:59.720]   maybe high school as well,
[01:28:59.720 --> 01:29:04.400]   where there's like a turning point for them
[01:29:04.400 --> 01:29:07.860]   where they maybe fall in love with mathematics
[01:29:07.860 --> 01:29:09.800]   or they get it?
[01:29:09.800 --> 01:29:13.440]   Is there something to be said about like discovering
[01:29:13.440 --> 01:29:16.400]   that moment and trying to grab them,
[01:29:16.400 --> 01:29:19.960]   to get them to understand that mathematics is,
[01:29:19.960 --> 01:29:21.560]   so no matter what they want to do in life
[01:29:21.560 --> 01:29:23.120]   could be part of their life?
[01:29:23.120 --> 01:29:25.520]   - Yes, I actually do think that the middle school
[01:29:25.520 --> 01:29:26.840]   is exactly the right time,
[01:29:26.840 --> 01:29:29.280]   because that's the place where your mathematical
[01:29:29.280 --> 01:29:32.520]   understanding gets just sophisticated enough
[01:29:32.520 --> 01:29:34.720]   that you can start doing interesting things.
[01:29:34.720 --> 01:29:37.680]   Because if you're early on in counting,
[01:29:37.680 --> 01:29:40.760]   I'm honestly not very good at teaching you new insights.
[01:29:40.760 --> 01:29:41.960]   My wife is pretty good at that.
[01:29:41.960 --> 01:29:44.200]   But somehow once you get to this part
[01:29:44.200 --> 01:29:45.760]   where you know what a fraction is,
[01:29:45.760 --> 01:29:49.600]   and when you know how to add and how to multiply
[01:29:49.600 --> 01:29:51.240]   and what the area of a triangle is,
[01:29:51.240 --> 01:29:54.120]   at that point to me, the whole world opens up
[01:29:54.120 --> 01:29:55.240]   and you can start observing
[01:29:55.240 --> 01:29:57.360]   there are really nifty coincidences,
[01:29:57.360 --> 01:29:59.880]   the things that made the Greek mathematicians
[01:29:59.880 --> 01:30:02.120]   and the ancient mathematicians excited.
[01:30:02.120 --> 01:30:03.880]   Actually back then it was exciting
[01:30:03.880 --> 01:30:05.720]   to discover the Pythagorean theorem.
[01:30:05.720 --> 01:30:06.920]   It wasn't just homework.
[01:30:06.920 --> 01:30:11.800]   - So is there, which discipline do you think
[01:30:11.800 --> 01:30:14.120]   has the most exciting coincidences?
[01:30:14.120 --> 01:30:16.360]   So is it geometry?
[01:30:16.360 --> 01:30:17.960]   Is it algebra?
[01:30:17.960 --> 01:30:21.520]   Is it calculus?
[01:30:21.520 --> 01:30:22.680]   - Well, you see, you're asking me
[01:30:22.680 --> 01:30:24.520]   and I'm the guy who gets the most excited
[01:30:24.520 --> 01:30:27.280]   when the combinatorics shows up in the geometry.
[01:30:27.280 --> 01:30:28.480]   (laughs)
[01:30:28.480 --> 01:30:29.360]   - Is it?
[01:30:29.360 --> 01:30:33.080]   Okay, so it's the combinatorics in the geometry.
[01:30:33.080 --> 01:30:35.240]   So first of all, the nice thing about geometry,
[01:30:35.240 --> 01:30:37.880]   this is the same nice thing about computer vision,
[01:30:37.880 --> 01:30:39.120]   is it's visual.
[01:30:39.120 --> 01:30:42.720]   So geometry, you can draw circles and triangles and stuff.
[01:30:42.720 --> 01:30:47.720]   So it naturally presents itself to the visual proof.
[01:30:47.720 --> 01:30:51.160]   But also the nice thing about geometry,
[01:30:51.160 --> 01:30:56.160]   I think for me is the earliest class,
[01:30:56.160 --> 01:30:59.720]   the earliest discipline where there's,
[01:30:59.720 --> 01:31:02.600]   that's most amenable to the exploration,
[01:31:02.600 --> 01:31:04.960]   the invention, the proofs.
[01:31:04.960 --> 01:31:09.640]   The idea of proofs I think is most easily shown in geometry
[01:31:09.640 --> 01:31:11.200]   'cause it's so visual, I guess.
[01:31:12.280 --> 01:31:15.440]   So that to me is like, if I were to think about
[01:31:15.440 --> 01:31:18.340]   when I first fell in love with math, it would be geometry.
[01:31:18.340 --> 01:31:21.240]   And sadly enough, that's not used.
[01:31:21.240 --> 01:31:25.020]   Geometry only has a little, appears briefly
[01:31:25.020 --> 01:31:30.020]   in the journey of a student and it kind of disappears
[01:31:30.020 --> 01:31:32.280]   and not until much later,
[01:31:32.280 --> 01:31:36.560]   which there may be like differential geometry.
[01:31:36.560 --> 01:31:37.680]   I don't know where else it shows up.
[01:31:37.680 --> 01:31:39.760]   For me, in computer science,
[01:31:39.760 --> 01:31:43.520]   you could start to think about like computational geometry
[01:31:43.520 --> 01:31:45.520]   or even graph theory as a kind of geometry.
[01:31:45.520 --> 01:31:47.180]   You could start to think about it visually,
[01:31:47.180 --> 01:31:49.300]   although it's pretty tricky.
[01:31:49.300 --> 01:31:53.000]   But yeah, it was always, that was the most beautiful one.
[01:31:53.000 --> 01:31:56.200]   Everything else, I guess calculus can be kind of visual too.
[01:31:56.200 --> 01:31:57.800]   That can be pretty beautiful.
[01:31:57.800 --> 01:32:02.800]   But is there something you try to look for in the student
[01:32:05.360 --> 01:32:09.920]   to see like, how can I inspire them at this moment?
[01:32:09.920 --> 01:32:12.160]   Or is this like individual student to student?
[01:32:12.160 --> 01:32:13.880]   Is there something you could say there?
[01:32:13.880 --> 01:32:16.440]   - So first of all, I really think that every student
[01:32:16.440 --> 01:32:17.880]   can pick up all of this skill.
[01:32:17.880 --> 01:32:18.720]   I really do think so.
[01:32:18.720 --> 01:32:20.520]   I don't think it's something only for a few.
[01:32:20.520 --> 01:32:23.680]   And so if I'm looking for a student,
[01:32:23.680 --> 01:32:26.800]   actually oftentimes if I'm looking at a particular student,
[01:32:26.800 --> 01:32:30.320]   the question is, how can we help you feel
[01:32:30.320 --> 01:32:32.880]   like you have the power to invent also?
[01:32:32.880 --> 01:32:34.640]   Because I think a lot of people are used
[01:32:34.640 --> 01:32:36.080]   to thinking about math as something
[01:32:36.080 --> 01:32:37.960]   where the teacher will show you what to do
[01:32:37.960 --> 01:32:39.600]   and then you will do it.
[01:32:39.600 --> 01:32:42.120]   So I think that the key is to show that they have some,
[01:32:42.120 --> 01:32:44.240]   let them see that they have some power to invent.
[01:32:44.240 --> 01:32:45.960]   And at that point, it's often starting
[01:32:45.960 --> 01:32:48.720]   by trying to give a question that they don't know how to do.
[01:32:48.720 --> 01:32:49.860]   You want to find these questions
[01:32:49.860 --> 01:32:51.120]   that they don't know how to do,
[01:32:51.120 --> 01:32:54.480]   that they can think about and then they can solve.
[01:32:54.480 --> 01:32:57.800]   And then suddenly they say, my gosh, I've had a situation.
[01:32:57.800 --> 01:33:00.420]   I've had an experience where I didn't know what to do.
[01:33:00.420 --> 01:33:02.000]   And after a while I did.
[01:33:03.320 --> 01:33:07.800]   - Is there advice you can give on how to learn math
[01:33:07.800 --> 01:33:10.680]   for people, whether it's middle school,
[01:33:10.680 --> 01:33:14.480]   whether it's somebody as an adult
[01:33:14.480 --> 01:33:18.060]   kind of gave up on math maybe early on?
[01:33:18.060 --> 01:33:22.000]   - I actually think that these math competition problems,
[01:33:22.000 --> 01:33:23.760]   middle school and high school are really good.
[01:33:23.760 --> 01:33:25.040]   They're actually very hard.
[01:33:25.040 --> 01:33:29.120]   So if you haven't had this kind of experience before
[01:33:29.120 --> 01:33:32.920]   and you grab a middle school math competition problem
[01:33:32.920 --> 01:33:35.000]   from the state level, which is used to decide
[01:33:35.000 --> 01:33:37.000]   who represents the state in the country,
[01:33:37.000 --> 01:33:40.640]   in the United States, for example, those are pretty tricky.
[01:33:40.640 --> 01:33:43.540]   And even if you are a professional,
[01:33:43.540 --> 01:33:45.480]   maybe not doing mathematical things
[01:33:45.480 --> 01:33:48.260]   and you're not a middle school student, you'll struggle.
[01:33:48.260 --> 01:33:51.080]   So I find that these things really do teach you things
[01:33:51.080 --> 01:33:53.080]   by trying to work on these questions.
[01:33:53.080 --> 01:33:56.760]   - Is there a Googleable term that you can use
[01:33:56.760 --> 01:33:59.440]   for the organization for the state competitions?
[01:33:59.440 --> 01:34:00.260]   - Ah, yeah.
[01:34:00.260 --> 01:34:02.280]   So there are a number of different ones
[01:34:02.280 --> 01:34:03.600]   that are quite popular.
[01:34:03.600 --> 01:34:07.760]   One of them is called Math Counts, M-A-T-H-C-O-U-N-T-S.
[01:34:07.760 --> 01:34:08.880]   And that's a big tournament,
[01:34:08.880 --> 01:34:10.480]   which actually has a state level.
[01:34:10.480 --> 01:34:15.360]   There's also a mathleague.org, mathleague.org,
[01:34:15.360 --> 01:34:18.660]   also has this kind of tiered tournament structure.
[01:34:18.660 --> 01:34:22.600]   There's also the American Math Competitions, AMC8.
[01:34:22.600 --> 01:34:25.920]   AMC also has AMC10, that's for 10th grade and below,
[01:34:25.920 --> 01:34:27.240]   and AMC12.
[01:34:27.240 --> 01:34:30.260]   These are all run by the Mathematical Association of America.
[01:34:30.260 --> 01:34:32.880]   And these are all ways to find old questions.
[01:34:32.880 --> 01:34:35.160]   - What about the daily challenges that you run?
[01:34:35.160 --> 01:34:36.000]   What are those about?
[01:34:36.000 --> 01:34:36.820]   - We do that too.
[01:34:36.820 --> 01:34:39.920]   But I mean, the difference was, that one's not free.
[01:34:39.920 --> 01:34:42.080]   So I should actually probably be careful.
[01:34:42.080 --> 01:34:44.280]   The things that I've just mentioned are also not free.
[01:34:44.280 --> 01:34:46.760]   Not all of those things I mentioned just now are free either.
[01:34:46.760 --> 01:34:48.760]   - People can figure out what is free and what's not.
[01:34:48.760 --> 01:34:51.040]   But this is really nice to know what's out there.
[01:34:51.040 --> 01:34:53.720]   But can you speak a little bit to the daily challenges?
[01:34:53.720 --> 01:34:54.560]   - Sure, sure.
[01:34:54.560 --> 01:34:56.800]   So that's actually what we did when,
[01:34:56.800 --> 01:34:58.480]   I guess I was thinking about,
[01:34:58.480 --> 01:35:02.060]   how would I try to develop that skill in people
[01:35:02.060 --> 01:35:05.380]   if we had the power to architect the entire system ourselves?
[01:35:05.380 --> 01:35:07.420]   So that's called the daily challenge with Poch and Lo.
[01:35:07.420 --> 01:35:09.720]   It's not free because that's actually how I pay
[01:35:09.720 --> 01:35:11.240]   for everything else I do.
[01:35:11.240 --> 01:35:12.860]   So that was the idea.
[01:35:12.860 --> 01:35:16.500]   But the concept was, aha, now let's invent from scratch.
[01:35:16.500 --> 01:35:17.980]   So if we're going to go from scratch
[01:35:17.980 --> 01:35:19.700]   and we're going to use technology,
[01:35:19.700 --> 01:35:22.060]   what if we made every single lesson
[01:35:22.060 --> 01:35:24.700]   something where first I say,
[01:35:24.700 --> 01:35:25.820]   hey, here's an interesting question.
[01:35:25.820 --> 01:35:27.100]   Recorded, of course, not live.
[01:35:27.100 --> 01:35:28.660]   But it's like, I say, hey, here's an interesting question.
[01:35:28.660 --> 01:35:29.880]   Why don't we think about this?
[01:35:29.880 --> 01:35:32.000]   But I know you don't know how to do it.
[01:35:32.000 --> 01:35:33.740]   So now you think, and a minute later,
[01:35:33.740 --> 01:35:35.500]   a hint pops on the screen.
[01:35:35.500 --> 01:35:37.000]   But you still think, and a minute later,
[01:35:37.000 --> 01:35:39.260]   a big hint pops on the screen, and you still think.
[01:35:39.260 --> 01:35:41.260]   And then finally, after the three minutes,
[01:35:41.260 --> 01:35:43.700]   hopefully you got some ideas, you try to answer.
[01:35:43.700 --> 01:35:47.300]   And then suddenly there's this pretty extended explanation
[01:35:47.300 --> 01:35:50.300]   of, oh yeah, so here's multiple different ways
[01:35:50.300 --> 01:35:51.580]   that you can do the question.
[01:35:51.580 --> 01:35:54.660]   And by accident, you also just learned this other concept.
[01:35:54.660 --> 01:35:55.500]   That's what we did.
[01:35:55.500 --> 01:35:56.340]   So yeah.
[01:35:56.340 --> 01:35:58.140]   - Is it targeted towards middle school students,
[01:35:58.140 --> 01:35:59.500]   high school students?
[01:35:59.500 --> 01:36:01.340]   - It's targeted towards middle school students
[01:36:01.340 --> 01:36:04.060]   with competitions, but there's a lot of high school students
[01:36:04.060 --> 01:36:06.420]   who didn't do competitions in middle school,
[01:36:06.420 --> 01:36:07.860]   where they would also learn how to think.
[01:36:07.860 --> 01:36:09.820]   If you can see, the whole concept was,
[01:36:09.820 --> 01:36:11.700]   can we teach people how to think?
[01:36:11.700 --> 01:36:12.760]   How would you do that?
[01:36:12.760 --> 01:36:15.640]   You need to give people the chance to, on their own,
[01:36:15.640 --> 01:36:17.940]   invent without that kid in the front row
[01:36:17.940 --> 01:36:20.340]   answering every question in two seconds.
[01:36:20.340 --> 01:36:24.040]   - And people can find it, I think, what, daily.--
[01:36:24.040 --> 01:36:26.100]   - It's daily.potionload.com.
[01:36:26.100 --> 01:36:27.860]   But if you go to find my website,
[01:36:27.860 --> 01:36:29.220]   you'll be able to find it.
[01:36:29.220 --> 01:36:30.620]   - Beautiful.
[01:36:30.620 --> 01:36:31.940]   Can we zoom out a little bit?
[01:36:31.940 --> 01:36:36.260]   And so day to day, week to week, month to month,
[01:36:36.260 --> 01:36:41.260]   year to year, what does the lifelong educational process
[01:36:41.260 --> 01:36:42.820]   look like, do you think?
[01:36:42.820 --> 01:36:48.460]   For yourself, but for me, what would you recommend
[01:36:48.460 --> 01:36:50.260]   in the world of mathematics?
[01:36:50.260 --> 01:36:52.620]   Or sort of as opposed to studying for a test,
[01:36:52.620 --> 01:36:57.620]   but just like lifelong expanding of knowledge
[01:36:57.620 --> 01:37:02.100]   in that skill for invention?
[01:37:02.100 --> 01:37:05.020]   - I think I often articulate this as,
[01:37:05.020 --> 01:37:07.740]   can you always try to do more
[01:37:07.740 --> 01:37:09.480]   than you could do in the past?
[01:37:09.480 --> 01:37:11.660]   - Yeah.
[01:37:11.660 --> 01:37:13.660]   - But that comes in many ways.
[01:37:13.660 --> 01:37:16.620]   And I will say it's great if one wants to build that
[01:37:16.620 --> 01:37:19.300]   with mathematics, but it's also great to use
[01:37:19.300 --> 01:37:21.060]   that philosophy with all other things.
[01:37:21.060 --> 01:37:23.060]   In fact, if I just think of myself,
[01:37:23.060 --> 01:37:25.820]   I just think, what do I know now that I didn't know
[01:37:25.820 --> 01:37:28.500]   a year ago or a month ago or a week ago?
[01:37:28.500 --> 01:37:29.740]   And not just know, but like,
[01:37:29.740 --> 01:37:31.300]   what do I have the capability of doing?
[01:37:31.300 --> 01:37:32.140]   - Yes.
[01:37:32.140 --> 01:37:35.020]   - And if you just have that attitude, it brings more.
[01:37:35.020 --> 01:37:38.260]   - See, the thing is, there's also a habit,
[01:37:38.260 --> 01:37:43.020]   like it is a skill, like I've been using Anki,
[01:37:43.020 --> 01:37:46.640]   it's an app for helps you memorize things.
[01:37:46.640 --> 01:37:50.720]   And I've actually, a few months ago,
[01:37:50.720 --> 01:37:54.980]   started doing this daily of setting aside time
[01:37:54.980 --> 01:37:59.980]   to think about an idea that's outside of my work.
[01:37:59.980 --> 01:38:04.680]   Let's say, it's all over the place, by the way,
[01:38:04.680 --> 01:38:07.160]   but let's say politics, like gun control.
[01:38:07.160 --> 01:38:11.800]   Is it good to have a lot of guns or not in society?
[01:38:11.800 --> 01:38:15.020]   And just, I've set aside time every day.
[01:38:15.020 --> 01:38:17.640]   I do at least 10 minutes, but I try to do 30,
[01:38:17.640 --> 01:38:19.000]   where I think about a problem.
[01:38:19.000 --> 01:38:20.920]   And I kind of outline it for myself from scratch,
[01:38:20.920 --> 01:38:22.200]   from not looking anything up,
[01:38:22.200 --> 01:38:24.960]   just thinking about it using common sense.
[01:38:24.960 --> 01:38:29.120]   And I think the practice of that is really important.
[01:38:29.120 --> 01:38:31.040]   It's the daily routine of it.
[01:38:31.040 --> 01:38:32.560]   It's the discipline of it.
[01:38:32.560 --> 01:38:35.860]   It's not just that I figured something out
[01:38:35.860 --> 01:38:38.760]   from that thinking about gun control.
[01:38:38.760 --> 01:38:43.040]   It's more that that muscle is built too.
[01:38:43.040 --> 01:38:44.140]   It's that thinking muscle.
[01:38:44.140 --> 01:38:49.140]   So I'm kind of interested in, you know, math has,
[01:38:49.140 --> 01:38:52.040]   because especially 'cause I've gotten specialized
[01:38:52.040 --> 01:38:53.020]   into machine learning
[01:38:53.020 --> 01:38:55.320]   and because I love programming so much,
[01:38:55.320 --> 01:38:59.720]   I've lost touch with math a little bit
[01:38:59.720 --> 01:39:02.360]   to where I feel quite sad about it.
[01:39:02.360 --> 01:39:03.900]   And I want to fix that.
[01:39:03.900 --> 01:39:07.480]   Even just not math, like pure knowledge math,
[01:39:07.480 --> 01:39:10.160]   but math like these middle school problems,
[01:39:10.160 --> 01:39:11.600]   the challenges, right?
[01:39:13.320 --> 01:39:15.260]   Is that something you see a person be able to do
[01:39:15.260 --> 01:39:17.320]   every single day, kind of just practice
[01:39:17.320 --> 01:39:19.560]   every single day for years?
[01:39:19.560 --> 01:39:21.480]   - So I can give an answer to that
[01:39:21.480 --> 01:39:23.120]   that gives a practical way you could do it,
[01:39:23.120 --> 01:39:24.400]   assuming you have kids.
[01:39:24.400 --> 01:39:25.920]   (laughing)
[01:39:25.920 --> 01:39:26.760]   No, no, you can do it yourself.
[01:39:26.760 --> 01:39:27.960]   - Okay, step one, get kids.
[01:39:27.960 --> 01:39:29.600]   - No, no, I'm just saying this
[01:39:29.600 --> 01:39:31.720]   because I'm just thinking out loud right now.
[01:39:31.720 --> 01:39:32.560]   What could I do?
[01:39:32.560 --> 01:39:33.740]   Or what could I do to suggest?
[01:39:33.740 --> 01:39:36.000]   Because what I have noticed is that, for example,
[01:39:36.000 --> 01:39:37.800]   if you do have kids who are in elementary school
[01:39:37.800 --> 01:39:41.120]   or middle school, if you yourself go and look
[01:39:41.120 --> 01:39:43.120]   at those middle school math problems,
[01:39:43.120 --> 01:39:45.320]   to think about interesting ways that you can teach
[01:39:45.320 --> 01:39:48.200]   your elementary school or middle school kid, it works.
[01:39:48.200 --> 01:39:49.040]   That's what my wife did.
[01:39:49.040 --> 01:39:51.120]   She never did any of those contests before,
[01:39:51.120 --> 01:39:53.080]   but now she knows quite a lot about them.
[01:39:53.080 --> 01:39:53.960]   I didn't teach her anything.
[01:39:53.960 --> 01:39:55.200]   I don't do that.
[01:39:55.200 --> 01:39:57.360]   She just was messing around with them
[01:39:57.360 --> 01:39:59.640]   and taught herself all of that stuff.
[01:39:59.640 --> 01:40:01.440]   And that had the automatic daily.
[01:40:01.440 --> 01:40:03.880]   I'm always thinking, how do you make it practical, right?
[01:40:03.880 --> 01:40:06.240]   And the way to make it practical is if the timer
[01:40:06.240 --> 01:40:08.600]   on the automatically daily is that you are going
[01:40:08.600 --> 01:40:11.280]   to automatically daily do something with your own kids.
[01:40:11.280 --> 01:40:12.680]   Now it feeds back.
[01:40:12.680 --> 01:40:13.520]   - Okay.
[01:40:13.520 --> 01:40:14.800]   - And that includes the whole lesson
[01:40:14.800 --> 01:40:17.000]   that if you want to learn something, you should teach it.
[01:40:17.000 --> 01:40:18.160]   - Oh, I strongly believe that.
[01:40:18.160 --> 01:40:19.200]   - Yes.
[01:40:19.200 --> 01:40:21.240]   - I strongly believe that.
[01:40:21.240 --> 01:40:23.520]   - And so I currently don't have kids.
[01:40:23.520 --> 01:40:25.640]   So that's, maybe I should just get kids
[01:40:25.640 --> 01:40:27.080]   to help me with the math thing.
[01:40:27.080 --> 01:40:31.200]   But outside of that, I do want to integrate math
[01:40:31.200 --> 01:40:32.080]   into daily practice.
[01:40:32.080 --> 01:40:35.960]   So I'll definitely check out the daily challenges
[01:40:35.960 --> 01:40:39.240]   and see because, what is it?
[01:40:39.240 --> 01:40:41.120]   Grant Sanderson, we talked about offline,
[01:40:41.120 --> 01:40:42.720]   three blue, one brown.
[01:40:42.720 --> 01:40:44.920]   He speaks to this as well,
[01:40:44.920 --> 01:40:48.200]   that his videos aren't necessarily,
[01:40:48.200 --> 01:40:50.520]   that they don't speak to the thing that I'm referring to,
[01:40:50.520 --> 01:40:52.640]   which is the daily practice.
[01:40:52.640 --> 01:40:56.320]   They're more almost tools of inspiration.
[01:40:56.320 --> 01:41:01.320]   They kind of show you the beauty of a particular problem
[01:41:01.320 --> 01:41:05.760]   in mathematics, but they're not a daily ritual.
[01:41:05.760 --> 01:41:09.520]   And I'm in search of that daily ritual mathematics.
[01:41:09.520 --> 01:41:11.280]   It's not trivial to find,
[01:41:11.280 --> 01:41:16.880]   but I hope to find that.
[01:41:16.880 --> 01:41:20.960]   'Cause I think math gives you a perspective on the world
[01:41:20.960 --> 01:41:23.120]   that enriches everything else.
[01:41:23.120 --> 01:41:25.840]   - So I like what you said about the daily also,
[01:41:25.840 --> 01:41:27.400]   because that's also one reason
[01:41:27.400 --> 01:41:29.960]   why I put my Carnegie Mellon class online.
[01:41:29.960 --> 01:41:31.960]   It's not every day, it's every other day.
[01:41:31.960 --> 01:41:33.280]   Semester is almost over.
[01:41:33.280 --> 01:41:35.880]   But the idea was, I guess my philosophy was,
[01:41:35.880 --> 01:41:37.360]   if I'm already doing the class,
[01:41:37.360 --> 01:41:38.920]   let's just like put it there, right?
[01:41:38.920 --> 01:41:40.880]   But I do know that there are people
[01:41:40.880 --> 01:41:43.920]   who have been following it, who are not in my class at all,
[01:41:43.920 --> 01:41:45.920]   who have just been following it because,
[01:41:45.920 --> 01:41:47.560]   yes, it's combinatorics.
[01:41:47.560 --> 01:41:49.880]   And the value of that is you could,
[01:41:49.880 --> 01:41:51.800]   you don't really need to know calculus to follow it,
[01:41:51.800 --> 01:41:52.720]   if that makes sense.
[01:41:52.720 --> 01:41:54.600]   So it's actually something that people could follow.
[01:41:54.600 --> 01:41:56.000]   So again, and that one's free.
[01:41:56.000 --> 01:41:58.640]   So that one's just there on YouTube.
[01:41:58.640 --> 01:42:02.440]   - Well, speaking of combinatorics, what is it?
[01:42:02.440 --> 01:42:03.800]   What do you find interesting?
[01:42:03.800 --> 01:42:07.240]   What do you find beautiful about combinatorics?
[01:42:07.240 --> 01:42:11.480]   - So combinatorics to me is the study of things
[01:42:11.480 --> 01:42:16.480]   where they might be more finite and more discrete.
[01:42:16.480 --> 01:42:18.960]   What I mean is like, if I look at a network,
[01:42:18.960 --> 01:42:20.640]   actually a lot of times the combinatorics
[01:42:20.640 --> 01:42:21.840]   will boil down to something,
[01:42:21.840 --> 01:42:23.240]   and the combinatorics I think about
[01:42:23.240 --> 01:42:25.960]   might be something related to graphs or networks.
[01:42:25.960 --> 01:42:28.800]   And they're very discrete because if you have a node,
[01:42:28.800 --> 01:42:32.160]   it's not that you have 0.7 of a node
[01:42:32.160 --> 01:42:33.520]   and 0.3 of a node over there.
[01:42:33.520 --> 01:42:36.080]   It's like you got one node and then you jump one step
[01:42:36.080 --> 01:42:37.440]   to go to the next node.
[01:42:37.440 --> 01:42:39.840]   So that notion is different from say calculus,
[01:42:39.840 --> 01:42:42.800]   which is very continuous, where you go and say,
[01:42:42.800 --> 01:42:46.160]   I have this speed, which is changing over time.
[01:42:46.160 --> 01:42:47.760]   And now what's the distance I've traveled?
[01:42:47.760 --> 01:42:49.040]   That's the notion of an integral,
[01:42:49.040 --> 01:42:50.880]   where you have to think of subdividing time
[01:42:50.880 --> 01:42:52.600]   into very, very small pieces.
[01:42:52.600 --> 01:42:55.160]   So the kinds of things that you do when you reason
[01:42:55.160 --> 01:42:59.320]   about these finite discrete structures
[01:42:59.320 --> 01:43:03.240]   often might be iterative, algorithmic, inductive.
[01:43:03.240 --> 01:43:06.320]   These are ideas where I go from one step to the next step
[01:43:06.320 --> 01:43:08.160]   and so on and make progress.
[01:43:08.160 --> 01:43:11.280]   I guess I actually personally like all kinds of math.
[01:43:11.280 --> 01:43:13.520]   My area of research just ended up in here
[01:43:13.520 --> 01:43:17.120]   because I met a really interesting PhD advisor.
[01:43:17.120 --> 01:43:18.960]   Potentially, that's honestly the reason
[01:43:18.960 --> 01:43:20.280]   I went into that direction.
[01:43:20.280 --> 01:43:21.920]   I met a really interesting guy.
[01:43:21.920 --> 01:43:24.840]   He seemed like he did good stuff, interesting stuff,
[01:43:24.840 --> 01:43:26.640]   and he looked like he cared about students.
[01:43:26.640 --> 01:43:29.200]   And I said, let me just go and learn whatever you do.
[01:43:29.200 --> 01:43:32.200]   Even though my prior practice and preparation
[01:43:32.200 --> 01:43:34.240]   before my PhD was not combinatorics,
[01:43:34.240 --> 01:43:36.880]   but analysis, the continuous stuff.
[01:43:36.880 --> 01:43:40.560]   - So the annoying thing about combinatorics
[01:43:40.560 --> 01:43:45.560]   and discrete stuff is it's often really difficult to solve
[01:43:45.560 --> 01:43:51.200]   from a sort of running time complexity perspective.
[01:43:51.200 --> 01:43:56.240]   Is there, could you speak to the idea
[01:43:56.240 --> 01:44:00.640]   of complexity analysis of problems?
[01:44:00.640 --> 01:44:03.120]   Do you find it useful, do you find it interesting?
[01:44:03.120 --> 01:44:08.200]   Do you find that lens of studying the difficulty
[01:44:08.200 --> 01:44:11.560]   of how difficult the computer science problem
[01:44:11.560 --> 01:44:15.200]   is a useful lens onto the world?
[01:44:15.200 --> 01:44:16.160]   - Oh, very much so.
[01:44:16.160 --> 01:44:20.360]   Because if you want to make something practical,
[01:44:20.360 --> 01:44:22.720]   which has large numbers of people using it,
[01:44:22.720 --> 01:44:27.200]   the computational complexity to me is almost question one.
[01:44:27.200 --> 01:44:29.040]   And that's, again, that's at the origin
[01:44:29.040 --> 01:44:31.720]   of when we started doing this stuff with disease control.
[01:44:31.720 --> 01:44:33.440]   From the very beginning, the deep questions
[01:44:33.440 --> 01:44:35.360]   that were running through my mind were,
[01:44:35.360 --> 01:44:38.440]   would we be able to support a large population
[01:44:38.440 --> 01:44:39.640]   with only one server?
[01:44:39.640 --> 01:44:43.640]   And if the answer is no, we can't start
[01:44:43.640 --> 01:44:45.340]   because I don't have enough money.
[01:44:45.340 --> 01:44:51.960]   - Yeah, and there the question is very much linear time
[01:44:51.960 --> 01:44:56.960]   versus anything slower than linear time.
[01:44:58.320 --> 01:44:59.800]   As a very specific thing,
[01:44:59.800 --> 01:45:01.360]   you have a bunch of really interesting papers.
[01:45:01.360 --> 01:45:04.000]   If I could ask, maybe we could pull out some cool insights
[01:45:04.000 --> 01:45:05.240]   at the high level.
[01:45:05.240 --> 01:45:08.920]   Can you describe the data structure of a voting tree
[01:45:08.920 --> 01:45:11.240]   and what are some interesting results on it?
[01:45:11.240 --> 01:45:13.700]   You have a paper that I noticed on it.
[01:45:13.700 --> 01:45:17.380]   - Yeah, so this is an example of, I guess,
[01:45:17.380 --> 01:45:19.800]   how in math we might say,
[01:45:19.800 --> 01:45:22.240]   here's an interesting kind of a question
[01:45:22.240 --> 01:45:25.720]   that we just can't seem to understand enough about.
[01:45:25.720 --> 01:45:27.560]   Maybe there's something else going on here.
[01:45:27.560 --> 01:45:30.160]   And the way to describe this is,
[01:45:30.160 --> 01:45:32.740]   you could imagine trying to hold elections
[01:45:32.740 --> 01:45:35.880]   where if you have only two candidates, that's kind of easy.
[01:45:35.880 --> 01:45:37.160]   You just run them against each other
[01:45:37.160 --> 01:45:38.600]   and see who gets more votes.
[01:45:38.600 --> 01:45:40.680]   But as you know, once you have more candidates,
[01:45:40.680 --> 01:45:43.120]   it's very difficult to decide who wins the election.
[01:45:43.120 --> 01:45:46.320]   And there's an entire voting theory around this.
[01:45:46.320 --> 01:45:49.440]   So a theoretical question became,
[01:45:49.440 --> 01:45:53.560]   what if you made a system of runoffs,
[01:45:53.560 --> 01:45:57.160]   like a system of head-to-head contests,
[01:45:57.160 --> 01:45:58.600]   which is structured like a tree,
[01:45:58.600 --> 01:46:00.200]   almost looking like a circuit.
[01:46:00.200 --> 01:46:01.800]   I'm using that way of thinking
[01:46:01.800 --> 01:46:04.500]   because it's sort of like electrical engineering
[01:46:04.500 --> 01:46:05.680]   or computer science.
[01:46:05.680 --> 01:46:09.260]   You might imagine having a bunch of leads that carry signal,
[01:46:09.260 --> 01:46:11.600]   which are going through AND gates and OR gates and whatnot,
[01:46:11.600 --> 01:46:13.600]   and you've managed to compute beautiful things.
[01:46:13.600 --> 01:46:16.260]   This is just from a purely abstract point of view.
[01:46:16.260 --> 01:46:18.560]   What if the inputs are candidates?
[01:46:18.560 --> 01:46:20.200]   And for every two candidates,
[01:46:20.200 --> 01:46:21.760]   it is known which of the candidates
[01:46:21.760 --> 01:46:23.440]   is more popular than the other.
[01:46:23.440 --> 01:46:25.840]   Now can you build some kind of a circuit board,
[01:46:25.840 --> 01:46:28.000]   which says, first, candidate number four
[01:46:28.000 --> 01:46:31.560]   will play against five and see who wins and so on.
[01:46:31.560 --> 01:46:34.560]   Okay, so now what would be a nice outcome?
[01:46:34.560 --> 01:46:35.800]   This is a general question of,
[01:46:35.800 --> 01:46:39.120]   could I make a big circuit board to feed an election into?
[01:46:39.120 --> 01:46:40.640]   Like maybe one nice outcome would be,
[01:46:40.640 --> 01:46:45.200]   whoever wins at least is preferred over a lot of people.
[01:46:45.200 --> 01:46:48.480]   So for example, if you ran in 1,024 candidates,
[01:46:48.480 --> 01:46:51.080]   ideally we would like a guarantee that says
[01:46:51.080 --> 01:46:54.080]   that the winner beats a lot of people.
[01:46:54.080 --> 01:46:58.560]   Actually, in any system where there are 1,024 candidates,
[01:46:58.560 --> 01:46:59.880]   there's always a candidate
[01:46:59.880 --> 01:47:02.880]   who beats at least 512 of the others.
[01:47:02.880 --> 01:47:04.400]   This is a mathematical fact
[01:47:04.400 --> 01:47:05.800]   that there's actually always a person
[01:47:05.800 --> 01:47:08.040]   who beats at least half of the other people.
[01:47:08.040 --> 01:47:13.200]   - I'm trying to make sense of that mathematical fact.
[01:47:13.200 --> 01:47:15.040]   Is this supposed to be obvious?
[01:47:15.040 --> 01:47:17.000]   - No, but I can explain it.
[01:47:17.000 --> 01:47:17.840]   No, no, I can.
[01:47:17.840 --> 01:47:21.400]   The way it works is that, think of it this way.
[01:47:21.400 --> 01:47:24.320]   Every time, I think, imagine I have all these candidates
[01:47:24.320 --> 01:47:26.080]   and everyone is competing,
[01:47:26.080 --> 01:47:29.240]   everyone is like compared with everyone else at some point.
[01:47:29.240 --> 01:47:30.640]   Well, think of it this way.
[01:47:30.640 --> 01:47:34.240]   Whenever there's a comparison, somebody gets a point.
[01:47:34.240 --> 01:47:37.040]   That's the one who is better than the other one.
[01:47:37.040 --> 01:47:39.480]   My claim is there's somebody whose score
[01:47:39.480 --> 01:47:42.920]   is at least half of how many other people there are.
[01:47:42.920 --> 01:47:44.880]   - Yeah, I'm just trying to,
[01:47:44.880 --> 01:47:47.640]   like my intuition is very close to that being true,
[01:47:47.640 --> 01:47:48.720]   but it's beautiful.
[01:47:48.720 --> 01:47:50.400]   I didn't at first,
[01:47:50.400 --> 01:47:52.280]   that's not an obvious fact.
[01:47:52.280 --> 01:47:53.120]   - No, it's not.
[01:47:53.120 --> 01:47:55.800]   - And it feels like a beautiful fact.
[01:47:55.800 --> 01:47:57.160]   - Well, let me explain it this way.
[01:47:57.160 --> 01:48:00.560]   Imagine that for every match,
[01:48:00.560 --> 01:48:03.880]   you didn't give one point, but you gave two points.
[01:48:03.880 --> 01:48:05.960]   You gave one point to each person.
[01:48:05.960 --> 01:48:07.080]   Now that's not what we're really doing.
[01:48:07.080 --> 01:48:10.880]   We really want to give one point to the winner of the match,
[01:48:10.880 --> 01:48:12.280]   but instead we'll just give two.
[01:48:12.280 --> 01:48:15.920]   If you gave two points to everyone on every matchup,
[01:48:15.920 --> 01:48:18.440]   actually everyone has the same number of points.
[01:48:18.440 --> 01:48:19.720]   And the number of points they get
[01:48:19.720 --> 01:48:21.480]   is how many other people there are.
[01:48:21.480 --> 01:48:23.560]   Does that sort of make sense?
[01:48:23.560 --> 01:48:24.400]   I'm just like saying--
[01:48:24.400 --> 01:48:26.200]   - No, no, everything is same makes perfect sense.
[01:48:26.200 --> 01:48:29.480]   - Okay, so the point is if for every comparison
[01:48:29.480 --> 01:48:32.520]   between two people, which I'm doing for every two people,
[01:48:32.520 --> 01:48:34.440]   I gave one point to each person,
[01:48:34.440 --> 01:48:36.680]   your score, everyone's score is the same.
[01:48:36.680 --> 01:48:38.600]   It's how many other people there are.
[01:48:38.600 --> 01:48:40.240]   Now we only make one change.
[01:48:40.240 --> 01:48:44.360]   For each matchup, you give one point only to the winner.
[01:48:44.360 --> 01:48:46.000]   So we're awarding half the points.
[01:48:47.080 --> 01:48:50.280]   So now the deal is if in the original situation,
[01:48:50.280 --> 01:48:52.160]   everyone's score was equal,
[01:48:52.160 --> 01:48:54.880]   which is how many other people there are.
[01:48:54.880 --> 01:48:57.640]   Now there's only half the number of points to go around.
[01:48:57.640 --> 01:49:02.360]   So what ends up happening is that there's always going to be,
[01:49:02.360 --> 01:49:04.720]   like the average number of points per person
[01:49:04.720 --> 01:49:07.120]   is going to be half of how many other people there are.
[01:49:07.120 --> 01:49:08.600]   And somebody is going to be above average.
[01:49:08.600 --> 01:49:09.880]   - Somebody is going to be above that.
[01:49:09.880 --> 01:49:10.800]   - At least average.
[01:49:10.800 --> 01:49:13.240]   Yeah, this is this notion of expected value
[01:49:13.240 --> 01:49:14.560]   that if I have a random variable,
[01:49:14.560 --> 01:49:16.240]   which has an expected value,
[01:49:16.240 --> 01:49:17.840]   there's going to be some possibility
[01:49:17.840 --> 01:49:19.320]   in the probability space
[01:49:19.320 --> 01:49:21.600]   where you're at least as big as the expected value.
[01:49:21.600 --> 01:49:23.720]   - Yeah, when you describe it like that, it's obvious.
[01:49:23.720 --> 01:49:26.680]   But when you're first saying in this little circuit
[01:49:26.680 --> 01:49:31.040]   that there's going to be one candidate better than half,
[01:49:31.040 --> 01:49:33.400]   that's not obvious.
[01:49:33.400 --> 01:49:35.160]   - Yeah, it's not. - It's funny.
[01:49:35.160 --> 01:49:37.200]   Math, this is nice.
[01:49:37.200 --> 01:49:38.640]   Okay, so you have this,
[01:49:38.640 --> 01:49:42.820]   but ultimately you're trying to with a voting tree,
[01:49:42.820 --> 01:49:43.920]   I don't know if you're trying this,
[01:49:43.920 --> 01:49:48.400]   but to have a circuit that's like compact, that's small.
[01:49:48.400 --> 01:49:49.240]   - Well, you'd like it to be small.
[01:49:49.240 --> 01:49:53.960]   - That achieves the same kind of,
[01:49:53.960 --> 01:49:57.160]   I mean, the smaller it is,
[01:49:57.160 --> 01:49:59.080]   if we look at practically speaking,
[01:49:59.080 --> 01:50:01.600]   the lower the cost of running the election,
[01:50:01.600 --> 01:50:03.840]   of running through, of computing the circuit.
[01:50:03.840 --> 01:50:04.680]   - That is true.
[01:50:04.680 --> 01:50:05.840]   But actually at this point,
[01:50:05.840 --> 01:50:08.620]   the reason the question was interesting
[01:50:08.620 --> 01:50:12.800]   is because there was no good guarantee
[01:50:12.800 --> 01:50:15.440]   that the winner of that circuit
[01:50:15.440 --> 01:50:18.440]   would have beaten a lot of people.
[01:50:18.440 --> 01:50:19.680]   Let me give an example.
[01:50:19.680 --> 01:50:20.840]   The best known circuit,
[01:50:20.840 --> 01:50:22.420]   when we started thinking about this,
[01:50:22.420 --> 01:50:24.800]   was the circuit called candidate one
[01:50:24.800 --> 01:50:26.440]   plays against candidate two,
[01:50:26.440 --> 01:50:28.680]   candidate three plays against four,
[01:50:28.680 --> 01:50:30.520]   and then the winners play against each other.
[01:50:30.520 --> 01:50:32.560]   And then by the way, five plays against six,
[01:50:32.560 --> 01:50:34.680]   seven against eight, the winners play against each other.
[01:50:34.680 --> 01:50:36.440]   You understand, it's like a giant binary tree.
[01:50:36.440 --> 01:50:38.760]   - Yeah, it's a binary, like a balanced binary tree?
[01:50:38.760 --> 01:50:40.760]   - Yeah, it's a balanced binary tree.
[01:50:40.760 --> 01:50:42.720]   One, two, three, four, up to 1,024,
[01:50:42.720 --> 01:50:44.160]   everyone going up to find the winner.
[01:50:44.160 --> 01:50:45.000]   - Beautiful.
[01:50:45.000 --> 01:50:45.820]   - Well, you know what?
[01:50:45.820 --> 01:50:47.440]   There's a system in the world
[01:50:47.440 --> 01:50:49.760]   where it could just be
[01:50:49.760 --> 01:50:52.320]   that there's a candidate called number one
[01:50:52.320 --> 01:50:55.260]   that just beats like 10 other people,
[01:50:55.260 --> 01:50:59.820]   just the 10 that they need to beat on their way up,
[01:50:59.820 --> 01:51:01.360]   and they lose to everyone else.
[01:51:01.360 --> 01:51:04.760]   But somehow they would get all the way up.
[01:51:04.760 --> 01:51:09.760]   My point is it is possible to outsmart that circuit
[01:51:10.760 --> 01:51:13.780]   in one weird way of the world,
[01:51:13.780 --> 01:51:15.360]   which makes that circuit a bad one,
[01:51:15.360 --> 01:51:16.200]   because you want to say,
[01:51:16.200 --> 01:51:18.960]   I will use this circuit for all elections.
[01:51:18.960 --> 01:51:22.480]   And you might have a system of inputs that go in there
[01:51:22.480 --> 01:51:24.800]   where the winner only beat 10 other people,
[01:51:24.800 --> 01:51:26.720]   which is the people they had to beat on their way up.
[01:51:26.720 --> 01:51:29.720]   - So you want to have a circuit where there's as many,
[01:51:29.720 --> 01:51:33.160]   like the final result is as strong as possible.
[01:51:33.160 --> 01:51:34.200]   - Yes.
[01:51:34.200 --> 01:51:37.440]   - And so what ideas do you have for that?
[01:51:37.440 --> 01:51:40.480]   - So we actually only managed to improve it
[01:51:40.480 --> 01:51:41.800]   to square root of N.
[01:51:41.800 --> 01:51:43.680]   So if N is number of vertices,
[01:51:43.680 --> 01:51:46.080]   N over two would be the ideal.
[01:51:46.080 --> 01:51:48.320]   We got it to square root of N.
[01:51:48.320 --> 01:51:50.120]   - Versus log of N.
[01:51:50.120 --> 01:51:51.080]   - Yeah, exactly.
[01:51:51.080 --> 01:51:52.400]   - Yeah.
[01:51:52.400 --> 01:51:53.440]   Which is-
[01:51:53.440 --> 01:51:54.360]   - Well, that is halfway.
[01:51:54.360 --> 01:51:55.880]   - It could be a lot.
[01:51:55.880 --> 01:51:56.720]   - Yeah.
[01:51:56.720 --> 01:51:57.760]   - It could be a big improvement.
[01:51:57.760 --> 01:51:58.980]   So that's a, okay, cool.
[01:51:58.980 --> 01:52:01.600]   Is there something you can say with words
[01:52:01.600 --> 01:52:04.600]   about what kind of circuit, what that looks like?
[01:52:04.600 --> 01:52:07.520]   - I can give an idea of one of the tools inside.
[01:52:07.520 --> 01:52:08.360]   - Yeah.
[01:52:08.360 --> 01:52:10.560]   - But the actual execution ends up being more complicated.
[01:52:10.560 --> 01:52:12.800]   But one of the widgets inside this
[01:52:12.800 --> 01:52:16.960]   is building a system where you have like a candidate
[01:52:16.960 --> 01:52:20.720]   who plays like one part of the whole huge, huge tree
[01:52:20.720 --> 01:52:23.280]   is that that same candidate, let's call him seven.
[01:52:23.280 --> 01:52:25.560]   Seven plays against somebody.
[01:52:25.560 --> 01:52:26.720]   Let's make up some numbers.
[01:52:26.720 --> 01:52:27.920]   Let's call the others like letters.
[01:52:27.920 --> 01:52:29.320]   So seven plays against A.
[01:52:29.320 --> 01:52:33.720]   Seven's also going to play against B separately.
[01:52:33.720 --> 01:52:36.600]   And the winners of each of those will play each other.
[01:52:36.600 --> 01:52:38.440]   By the way, seven's also going to play C.
[01:52:38.440 --> 01:52:39.680]   Seven's going to play D.
[01:52:39.680 --> 01:52:41.080]   And the winners are going to play each other.
[01:52:41.080 --> 01:52:42.520]   And the winners are going to play each other.
[01:52:42.520 --> 01:52:45.000]   We call this seven against all.
[01:52:45.000 --> 01:52:47.720]   Well, seven against like everyone from a bunch of-
[01:52:47.720 --> 01:52:48.560]   - Got it.
[01:52:48.560 --> 01:52:50.880]   So there's some nice overlap between the matchups.
[01:52:50.880 --> 01:52:51.720]   - Yeah.
[01:52:51.720 --> 01:52:53.040]   - That somehow has a nice feature to it.
[01:52:53.040 --> 01:52:54.240]   - Yes. And I can tell you the nice feature
[01:52:54.240 --> 01:52:56.520]   because if at the base of this giant tree,
[01:52:56.520 --> 01:52:58.680]   at the base of this giant circuit, like this is a widget.
[01:52:58.680 --> 01:52:59.920]   You rebuild the things out of widgets.
[01:52:59.920 --> 01:53:01.360]   So I'm just describing one widget.
[01:53:01.360 --> 01:53:03.440]   But in the base of this widget,
[01:53:03.440 --> 01:53:05.640]   you have lots of things which are seven against someone,
[01:53:05.640 --> 01:53:07.400]   seven against someone, seven against someone.
[01:53:07.400 --> 01:53:09.880]   In fact, every matchup at the bottom
[01:53:09.880 --> 01:53:11.560]   is seven against someone.
[01:53:11.560 --> 01:53:12.880]   What that means is
[01:53:12.880 --> 01:53:17.360]   if seven actually beat everyone
[01:53:17.360 --> 01:53:18.440]   they were matched up against,
[01:53:18.440 --> 01:53:20.360]   well, seven would rise to the top.
[01:53:20.360 --> 01:53:22.920]   So one possibility is if you see a seven
[01:53:22.920 --> 01:53:24.040]   emerge from the top,
[01:53:24.040 --> 01:53:25.960]   you know that seven actually beat everyone
[01:53:25.960 --> 01:53:27.480]   they were against.
[01:53:27.480 --> 01:53:30.160]   On the other hand, if anyone else is on top,
[01:53:30.160 --> 01:53:31.320]   let's call it F.
[01:53:31.320 --> 01:53:33.600]   If F is on top, how did F get there?
[01:53:33.600 --> 01:53:36.360]   Well, F beat seven on the way at the beginning.
[01:53:36.360 --> 01:53:38.680]   So the point is the outcome of this circuit
[01:53:38.680 --> 01:53:40.160]   has a certain property.
[01:53:40.160 --> 01:53:41.320]   If you see a seven,
[01:53:41.320 --> 01:53:43.960]   you know that the seven actually beat a bazillion people.
[01:53:43.960 --> 01:53:47.040]   If you see anyone else, at least you know they beat seven.
[01:53:47.040 --> 01:53:49.880]   - Yeah. Then you can prove that it has a nice property.
[01:53:49.880 --> 01:53:50.880]   That's really interesting.
[01:53:50.880 --> 01:53:54.160]   Is there something you can say,
[01:53:54.160 --> 01:53:56.760]   perhaps going completely outside of what we're talking about
[01:53:56.760 --> 01:54:01.760]   is how we may have mathematical ideas
[01:54:01.760 --> 01:54:06.400]   of improving the electoral process?
[01:54:06.400 --> 01:54:07.240]   - That one, no.
[01:54:07.240 --> 01:54:09.080]   No, I can't give you that one.
[01:54:09.080 --> 01:54:11.720]   - I mean, is there, like, do you ever see as,
[01:54:11.720 --> 01:54:17.360]   as there be, do you see as there being a lot of opportunities
[01:54:17.360 --> 01:54:19.160]   for improving how we vote?
[01:54:19.160 --> 01:54:23.680]   Like from your, I don't know if you saw parallels,
[01:54:23.680 --> 01:54:27.680]   but, you know, it seems like if this actually kind of maps
[01:54:27.680 --> 01:54:29.640]   to your sort of COVID work,
[01:54:29.640 --> 01:54:32.200]   which is there's a network effect, right?
[01:54:32.200 --> 01:54:34.280]   It seems like we should be able to apply
[01:54:34.280 --> 01:54:38.560]   similar kind of effects of how we decide other things
[01:54:38.560 --> 01:54:39.400]   in our lives.
[01:54:39.400 --> 01:54:42.160]   And one of the big decisions we'll make
[01:54:42.160 --> 01:54:44.480]   is who represents us in government.
[01:54:44.480 --> 01:54:46.200]   Do you ever think about like mathematically
[01:54:46.200 --> 01:54:48.160]   about those kinds of systems?
[01:54:48.160 --> 01:54:49.520]   - I think a little bit about those
[01:54:49.520 --> 01:54:51.480]   because where I went to college,
[01:54:51.480 --> 01:54:53.200]   the way we voted for student government
[01:54:53.200 --> 01:54:56.080]   was based on this, is it called ranked choice
[01:54:56.080 --> 01:55:00.800]   where you eliminate the bottom and the runoff elections?
[01:55:00.800 --> 01:55:02.800]   So that was the first time I ever saw that.
[01:55:02.800 --> 01:55:04.440]   And I thought that made sense.
[01:55:04.440 --> 01:55:06.880]   The only problem is it doesn't seem so easy
[01:55:06.880 --> 01:55:08.520]   to get something that makes sense adopted
[01:55:08.520 --> 01:55:09.720]   as the new voting system.
[01:55:09.720 --> 01:55:12.720]   - That's a whole nother, that's not a math solution.
[01:55:12.720 --> 01:55:16.000]   That's a, well, it's math in the sense that it's game theory
[01:55:16.000 --> 01:55:17.280]   so you have to come up with incentives,
[01:55:17.280 --> 01:55:18.280]   it's mechanism design.
[01:55:18.280 --> 01:55:21.040]   You have to figure out how to trick us
[01:55:21.040 --> 01:55:24.280]   despite our basic human nature
[01:55:24.280 --> 01:55:27.160]   to adopt solutions that are better.
[01:55:27.160 --> 01:55:28.000]   - Yeah.
[01:55:28.000 --> 01:55:30.520]   - That's a whole nother conversation, I think.
[01:55:30.520 --> 01:55:33.240]   Can you just, 'cause it sounded really cool,
[01:55:33.240 --> 01:55:36.120]   talk a little bit about stochastic coalescence
[01:55:36.120 --> 01:55:39.440]   and you have a paper on showing that,
[01:55:39.440 --> 01:55:40.760]   something you could describe what it is,
[01:55:40.760 --> 01:55:44.760]   but I guess it's a super linear, super logarithmic time
[01:55:44.760 --> 01:55:47.680]   and you came up with some kind of trick that make it faster.
[01:55:47.680 --> 01:55:49.320]   Just, can you just talk about it a little bit?
[01:55:49.320 --> 01:55:51.720]   - Yeah, so this was something which came up
[01:55:51.720 --> 01:55:54.200]   when I was at Microsoft Research for a summer
[01:55:54.200 --> 01:55:56.720]   and I'm putting that context because that shows
[01:55:56.720 --> 01:55:59.600]   that it has some practical motivation at some point.
[01:55:59.600 --> 01:56:01.920]   Actually, I think it's still--
[01:56:01.920 --> 01:56:02.880]   - It doesn't need to.
[01:56:02.880 --> 01:56:03.720]   - Yeah.
[01:56:03.720 --> 01:56:05.240]   - It doesn't need to, it can be beautiful and it's all right.
[01:56:05.240 --> 01:56:07.400]   - Yeah, so the easiest way to describe this is,
[01:56:07.400 --> 01:56:10.000]   suppose you got like a big crowd of people
[01:56:10.000 --> 01:56:12.200]   and everybody knows how many hours of sleep
[01:56:12.200 --> 01:56:13.320]   they got last night.
[01:56:13.320 --> 01:56:15.320]   And you wanna know how many total hours of sleep
[01:56:15.320 --> 01:56:17.640]   were gotten by this big crowd of people.
[01:56:17.640 --> 01:56:18.840]   At the beginning, you might say,
[01:56:18.840 --> 01:56:21.160]   that sounds like a linear time algorithm of saying,
[01:56:21.160 --> 01:56:22.760]   hey, how many hours you got?
[01:56:22.760 --> 01:56:23.600]   How many you got?
[01:56:23.600 --> 01:56:24.440]   How many you got?
[01:56:24.440 --> 01:56:25.280]   Add, add, add.
[01:56:25.280 --> 01:56:26.120]   - Yes.
[01:56:26.120 --> 01:56:27.680]   - But there's a way to do this if you remember
[01:56:27.680 --> 01:56:30.440]   that there are people and they presumably know how to add.
[01:56:30.440 --> 01:56:33.480]   You could make a distributed algorithm to make this happen.
[01:56:33.480 --> 01:56:35.920]   For example, while we're thinking of these trees,
[01:56:35.920 --> 01:56:38.640]   imagine you had 1,024 people.
[01:56:38.640 --> 01:56:40.760]   If you could just say, hey, person number one
[01:56:40.760 --> 01:56:43.920]   and person number two, you will add your hours of sleep.
[01:56:43.920 --> 01:56:46.120]   Person number two will go away
[01:56:46.120 --> 01:56:48.400]   and person number one is gonna remember the sum.
[01:56:48.400 --> 01:56:50.960]   Person three and four add up
[01:56:50.960 --> 01:56:53.800]   and person three takes charge of remembering it.
[01:56:53.800 --> 01:56:54.880]   Person four goes away.
[01:56:54.880 --> 01:56:57.000]   Now this like person one knows the sum of these two,
[01:56:57.000 --> 01:56:58.920]   person three knows the sum of those two, they talk.
[01:56:58.920 --> 01:56:59.760]   You see what I mean?
[01:56:59.760 --> 01:57:02.200]   It's like you're going up this tree,
[01:57:02.200 --> 01:57:03.640]   same tree that we talked about earlier.
[01:57:03.640 --> 01:57:05.920]   - Built up a tree from the bottom up.
[01:57:05.920 --> 01:57:07.600]   - Yeah, built up a tree from the bottom up.
[01:57:07.600 --> 01:57:09.200]   And the beautiful thing is,
[01:57:09.200 --> 01:57:11.400]   since everyone's doing stuff in parallel,
[01:57:11.400 --> 01:57:14.600]   the amount of time it takes to get the total sum
[01:57:14.600 --> 01:57:17.360]   is actually just the number of layers in the tree,
[01:57:17.360 --> 01:57:18.960]   which is 10.
[01:57:18.960 --> 01:57:20.360]   So now that's logarithmic time
[01:57:20.360 --> 01:57:23.760]   to add up the number of hours that people slept today.
[01:57:23.760 --> 01:57:25.280]   Sounds fantastic.
[01:57:25.280 --> 01:57:26.400]   There's only one problem.
[01:57:26.400 --> 01:57:28.000]   How do you decide who's person number one
[01:57:28.000 --> 01:57:29.720]   and person number two?
[01:57:29.720 --> 01:57:30.560]   - Yes.
[01:57:30.560 --> 01:57:32.680]   - So if, for example, you just went out into downtown
[01:57:32.680 --> 01:57:34.760]   and said, hey, get these thousand people, go.
[01:57:34.760 --> 01:57:35.960]   Well, if you're gonna go and say,
[01:57:35.960 --> 01:57:37.720]   and by the way, you're one and you're two and you're three,
[01:57:37.720 --> 01:57:38.760]   that's linear time.
[01:57:38.760 --> 01:57:39.680]   - Yes.
[01:57:39.680 --> 01:57:40.520]   - That's cheating.
[01:57:40.520 --> 01:57:43.000]   So now the question is how to do this in a distributed way.
[01:57:43.000 --> 01:57:44.200]   And there were some people
[01:57:44.200 --> 01:57:47.320]   who proposed a very elegant algorithm.
[01:57:47.320 --> 01:57:48.840]   And they wanted to analyze it.
[01:57:48.840 --> 01:57:50.680]   So I came in onto the analyze side.
[01:57:50.680 --> 01:57:52.760]   But the elegant algorithm was like this.
[01:57:52.760 --> 01:57:55.720]   It was like, well, we don't actually know
[01:57:55.720 --> 01:57:57.600]   what this big tree is.
[01:57:57.600 --> 01:57:58.880]   There isn't any big tree.
[01:57:58.880 --> 01:58:01.000]   So what's gonna happen is first,
[01:58:01.000 --> 01:58:04.280]   everyone is going to decide right now.
[01:58:04.280 --> 01:58:05.640]   Oh, one important thing.
[01:58:05.640 --> 01:58:07.000]   Everyone is going to,
[01:58:07.000 --> 01:58:09.920]   at the very beginning of the whole game,
[01:58:09.920 --> 01:58:13.360]   they will have delegated responsibility to themselves
[01:58:13.360 --> 01:58:16.400]   as the one who knows the sum so far.
[01:58:16.400 --> 01:58:18.920]   So the point is there's gonna be,
[01:58:18.920 --> 01:58:20.760]   people are all gonna have like a pointer,
[01:58:20.760 --> 01:58:24.440]   which says you are the one who knows my,
[01:58:24.440 --> 01:58:26.680]   you've taken care of my ticket, my number.
[01:58:26.680 --> 01:58:28.280]   - Yeah, they select the representative
[01:58:28.280 --> 01:58:31.360]   for this particular piece of knowledge.
[01:58:31.360 --> 01:58:33.680]   - And at the very beginning, you're your own representative.
[01:58:33.680 --> 01:58:35.120]   The thing has to start simple, right?
[01:58:35.120 --> 01:58:36.440]   So at the beginning, you're your own representative.
[01:58:36.440 --> 01:58:38.040]   - You're pointing to yourself, got it.
[01:58:38.040 --> 01:58:41.560]   - Yep, and the way this works is that at every time step,
[01:58:41.560 --> 01:58:45.840]   someone blares a ding dong on the town clock or whatever.
[01:58:45.840 --> 01:58:48.720]   And each person flips a coin themselves to decide,
[01:58:48.720 --> 01:58:53.600]   am I going to hunt for somebody to give my number to
[01:58:53.600 --> 01:58:55.120]   and let them represent me?
[01:58:55.120 --> 01:58:58.960]   Or am I going to sit here and wait for someone to come?
[01:58:58.960 --> 01:59:02.640]   Okay, well, they flip their coin.
[01:59:02.640 --> 01:59:04.840]   Some of the people start asking other people saying,
[01:59:04.840 --> 01:59:08.600]   hey, I would like you to be my representative.
[01:59:08.600 --> 01:59:10.240]   Here is my number.
[01:59:10.240 --> 01:59:12.080]   But the problem is that there's limited bandwidth
[01:59:12.080 --> 01:59:13.280]   of the people who are getting asked.
[01:59:13.280 --> 01:59:16.720]   It's like you can't go out to prom with five people.
[01:59:16.720 --> 01:59:17.880]   That is not what we're doing.
[01:59:17.880 --> 01:59:19.200]   We're adding numbers, okay?
[01:59:19.200 --> 01:59:20.760]   But you can only add one number.
[01:59:20.760 --> 01:59:22.640]   So the person who has suddenly gotten asked
[01:59:22.640 --> 01:59:25.000]   by all these people, well, they'll have to decide
[01:59:25.000 --> 01:59:27.320]   who they're going to take it from.
[01:59:27.320 --> 01:59:29.480]   And they randomly just choose one.
[01:59:29.480 --> 01:59:31.920]   When they randomly choose one, all the others are rejected
[01:59:31.920 --> 01:59:34.960]   and they don't get to delegate anything in that round.
[01:59:34.960 --> 01:59:38.400]   But now if this person has absorbed this one who said,
[01:59:38.400 --> 01:59:40.720]   okay, here, you take charge of my number,
[01:59:40.720 --> 01:59:42.640]   this person now updates their pointer.
[01:59:42.640 --> 01:59:43.960]   You're in charge.
[01:59:43.960 --> 01:59:46.680]   And this person adds the two numbers.
[01:59:46.680 --> 01:59:48.920]   That was the first round.
[01:59:48.920 --> 01:59:52.880]   In the next round, when they do the coin flipping,
[01:59:52.880 --> 01:59:54.320]   this person doesn't flip anymore
[01:59:54.320 --> 01:59:56.160]   because they're just delegating.
[01:59:56.160 --> 01:59:59.040]   It's that anyone who has the pointers themselves,
[01:59:59.040 --> 02:00:01.640]   that's like a person who is in charge
[02:00:01.640 --> 02:00:03.320]   of some number of informations,
[02:00:03.320 --> 02:00:04.680]   they flip the coin to decide,
[02:00:04.680 --> 02:00:08.240]   should I find other people who are agents
[02:00:08.240 --> 02:00:10.040]   or should I wait for people to ask me?
[02:00:10.040 --> 02:00:11.640]   - Yes, brilliant.
[02:00:11.640 --> 02:00:12.840]   - This is somebody else's idea.
[02:00:12.840 --> 02:00:14.360]   And now the idea is, okay,
[02:00:14.360 --> 02:00:16.920]   if you just keep doing this process, what ends up happening?
[02:00:16.920 --> 02:00:18.680]   Oh yeah, and also, by the way,
[02:00:18.680 --> 02:00:21.040]   if you decide that you want to go reach out to other people,
[02:00:21.040 --> 02:00:23.120]   here's the catch.
[02:00:23.120 --> 02:00:24.680]   When you're one of these agents saying,
[02:00:24.680 --> 02:00:27.400]   okay, I'm going to go look for someone,
[02:00:27.400 --> 02:00:30.760]   you have no idea who in this crowd is an agent
[02:00:30.760 --> 02:00:33.400]   or somebody who delegated it to someone else.
[02:00:33.400 --> 02:00:35.640]   You just pick a random person.
[02:00:35.640 --> 02:00:37.040]   When you pick the random person,
[02:00:37.040 --> 02:00:38.880]   if it lands on someone and the person says,
[02:00:38.880 --> 02:00:41.840]   oh, I actually delegated it to someone,
[02:00:41.840 --> 02:00:43.800]   then you follow the point.
[02:00:43.800 --> 02:00:45.280]   - You walk up the delegation chain.
[02:00:45.280 --> 02:00:46.120]   - Walk up the delegation chain.
[02:00:46.120 --> 02:00:49.120]   And you can do like path compression in the algorithm
[02:00:49.120 --> 02:00:52.040]   to make it so you don't consistently do lots of walking up.
[02:00:52.040 --> 02:00:54.680]   But the bottom line is that what ends up happening
[02:00:54.680 --> 02:00:57.280]   is that you end up reaching out.
[02:00:57.280 --> 02:00:59.120]   Whenever you're one of the ones reaching out,
[02:00:59.120 --> 02:01:01.880]   you can think of it as each agent is responsible
[02:01:01.880 --> 02:01:03.360]   for some number of people.
[02:01:03.360 --> 02:01:05.520]   It's almost like they're the leader of a bunch.
[02:01:05.520 --> 02:01:07.200]   As the process is evolving,
[02:01:07.200 --> 02:01:09.960]   you have these lumps.
[02:01:09.960 --> 02:01:11.720]   Each lump has an agent.
[02:01:11.720 --> 02:01:13.400]   And when the agent reaches out,
[02:01:13.400 --> 02:01:15.720]   they reach out to another lump
[02:01:15.720 --> 02:01:18.160]   where the probability of them hitting that lump
[02:01:18.160 --> 02:01:20.160]   is proportional to the size of the lump.
[02:01:20.160 --> 02:01:25.480]   That is the one funny thing about this process.
[02:01:25.480 --> 02:01:27.400]   This is not that they can reach out
[02:01:27.400 --> 02:01:29.320]   to a uniformly random lump
[02:01:29.320 --> 02:01:30.960]   where every lump has the same chance
[02:01:30.960 --> 02:01:32.480]   of getting reached out to.
[02:01:32.480 --> 02:01:34.560]   The bigger the lump is,
[02:01:34.560 --> 02:01:37.280]   the more likely it is
[02:01:37.280 --> 02:01:38.760]   that you end up reaching that lump.
[02:01:38.760 --> 02:01:40.200]   - Which is a problem.
[02:01:40.200 --> 02:01:41.600]   - Let me explain why that's a problem.
[02:01:41.600 --> 02:01:42.800]   Because you see,
[02:01:42.800 --> 02:01:45.440]   you're hoping that this has a small number of steps.
[02:01:45.440 --> 02:01:47.720]   But here's a bad situation that could happen.
[02:01:47.720 --> 02:01:50.040]   Imagine if you had like,
[02:01:50.040 --> 02:01:52.040]   there are N people that you're adding up.
[02:01:52.040 --> 02:01:57.040]   Imagine that you have exactly square root of N lumps left
[02:01:57.040 --> 02:02:01.480]   of which almost all of them are just one person
[02:02:01.480 --> 02:02:04.360]   who's still their own boss, their own manager.
[02:02:04.360 --> 02:02:05.200]   - Except one giant one.
[02:02:05.200 --> 02:02:06.040]   - One giant one.
[02:02:06.040 --> 02:02:07.000]   Now what's gonna happen?
[02:02:07.000 --> 02:02:08.400]   It's gonna be a huge bottleneck
[02:02:08.400 --> 02:02:09.840]   because every round the giant one
[02:02:09.840 --> 02:02:11.960]   can only absorb one of the others.
[02:02:11.960 --> 02:02:13.640]   And now you suddenly have time
[02:02:13.640 --> 02:02:15.760]   which is about square root of N.
[02:02:15.760 --> 02:02:16.880]   The square root of N is chosen
[02:02:16.880 --> 02:02:20.320]   because that is one where the lumps are such
[02:02:20.320 --> 02:02:23.600]   that you really are limited by this large one
[02:02:23.600 --> 02:02:26.040]   slowly sucking up the rest of them.
[02:02:26.040 --> 02:02:28.200]   So the heart of the question became,
[02:02:28.200 --> 02:02:30.080]   well, but is that just so unusual
[02:02:30.080 --> 02:02:32.760]   that it doesn't usually happen?
[02:02:32.760 --> 02:02:34.680]   Because remember you start with everyone
[02:02:34.680 --> 02:02:36.080]   just being independent.
[02:02:36.080 --> 02:02:37.640]   It's like a lot of lumps of size one.
[02:02:37.640 --> 02:02:39.640]   - How naturally do the big lumps emerge?
[02:02:39.640 --> 02:02:40.480]   - Yes.
[02:02:40.480 --> 02:02:42.120]   And so what that heart of the proof was,
[02:02:42.120 --> 02:02:45.120]   was showing that that was a joint work with A.L. Lubezki.
[02:02:45.120 --> 02:02:49.080]   That one was showing that actually in that thing,
[02:02:49.080 --> 02:02:50.920]   the lumps do kind of get out of whack.
[02:02:50.920 --> 02:02:54.720]   And so it's not the purely logarithmic number of steps.
[02:02:54.720 --> 02:02:56.760]   But if you make one very slight change,
[02:02:56.760 --> 02:03:00.400]   which is if you are one of the agents
[02:03:00.400 --> 02:03:02.400]   and you have just been propositioned,
[02:03:02.400 --> 02:03:05.320]   possibly relayed along by a couple of different people,
[02:03:05.320 --> 02:03:07.640]   if you just say, don't take a random one,
[02:03:07.640 --> 02:03:10.400]   but accept the smallest lump,
[02:03:10.400 --> 02:03:14.320]   that actually does enough to even hold it up.
[02:03:14.320 --> 02:03:15.720]   - Distributes the lump size.
[02:03:15.720 --> 02:03:16.560]   - Yeah.
[02:03:16.560 --> 02:03:17.680]   - I mean, yeah, it's fascinating
[02:03:17.680 --> 02:03:19.000]   how with the distributed algorithms,
[02:03:19.000 --> 02:03:22.440]   a little adjustment can make all the difference in the world.
[02:03:22.440 --> 02:03:23.280]   Yeah.
[02:03:23.280 --> 02:03:24.200]   Actually, by the way,
[02:03:24.200 --> 02:03:26.920]   this does back to our voting conversation.
[02:03:26.920 --> 02:03:28.440]   This makes me think of like,
[02:03:28.440 --> 02:03:32.240]   these networking systems are so fascinating to study.
[02:03:32.240 --> 02:03:35.080]   They immediately spring to mind ideas
[02:03:35.080 --> 02:03:37.640]   of how to have representation.
[02:03:37.640 --> 02:03:42.240]   Like maybe as opposed to me voting for a president,
[02:03:42.240 --> 02:03:45.600]   I want to vote for like,
[02:03:45.600 --> 02:03:48.400]   for you Paul to represent me,
[02:03:48.400 --> 02:03:50.600]   maybe on a particular issue.
[02:03:50.600 --> 02:03:52.560]   And then you'll delegate that further.
[02:03:52.560 --> 02:03:55.120]   And then we naturally construct those kinds of networks
[02:03:55.120 --> 02:03:58.880]   because that feels like I can have a good conversation
[02:03:58.880 --> 02:04:00.760]   with you and figure out that you know what you're doing
[02:04:00.760 --> 02:04:01.800]   and I can delegate it to you.
[02:04:01.800 --> 02:04:05.560]   And in that way, construct a representative government,
[02:04:05.560 --> 02:04:08.400]   a representative decision-maker.
[02:04:08.400 --> 02:04:12.440]   That feels really nice as opposed to like us,
[02:04:12.440 --> 02:04:14.520]   like a tree of height one or something,
[02:04:14.520 --> 02:04:16.240]   where it's like, everybody's just,
[02:04:16.240 --> 02:04:19.560]   it feels like there's a lot of room
[02:04:19.560 --> 02:04:22.480]   for layers of representation to form organically
[02:04:22.480 --> 02:04:23.800]   from the bottom up.
[02:04:23.800 --> 02:04:25.360]   I wonder if there are systems like that.
[02:04:25.360 --> 02:04:27.040]   This is the cool thing about the internet
[02:04:27.040 --> 02:04:29.520]   and the digital space where we're so well connected,
[02:04:29.520 --> 02:04:34.040]   just like with the Novid app to distribute information
[02:04:34.040 --> 02:04:36.960]   about the spread of the disease,
[02:04:36.960 --> 02:04:39.200]   we can in the same way, in a distributed sense,
[02:04:39.200 --> 02:04:44.200]   form anything like any kind of knowledge bases
[02:04:44.200 --> 02:04:48.720]   that are formed in a decentralized way
[02:04:48.720 --> 02:04:51.440]   and in a hierarchical way,
[02:04:51.440 --> 02:04:54.280]   as opposed to sort of old way
[02:04:54.280 --> 02:04:56.800]   where there's no mechanism for large scale,
[02:04:56.800 --> 02:05:01.720]   fast distributed transaction information.
[02:05:01.720 --> 02:05:02.560]   This is really interesting.
[02:05:02.560 --> 02:05:06.760]   This is where almost like network graph theory
[02:05:06.760 --> 02:05:07.920]   becomes practical.
[02:05:07.920 --> 02:05:10.800]   Yeah, most of that exciting work was done
[02:05:10.800 --> 02:05:11.800]   in the 20th century,
[02:05:11.800 --> 02:05:14.040]   but most of the application will be in the 21st,
[02:05:14.040 --> 02:05:15.920]   which is cool to think about.
[02:05:15.920 --> 02:05:17.680]   Let me ask the most ridiculous question.
[02:05:17.680 --> 02:05:19.840]   You think P equals NP?
[02:05:19.840 --> 02:05:22.360]   - Wow, I don't know.
[02:05:22.360 --> 02:05:23.800]   I mean, I would say,
[02:05:23.800 --> 02:05:28.080]   I know there are enough people
[02:05:28.080 --> 02:05:31.480]   who have very strong interest in trying to show that it is.
[02:05:31.480 --> 02:05:34.600]   I'm talking about government agencies.
[02:05:34.600 --> 02:05:37.360]   (laughing)
[02:05:37.360 --> 02:05:38.440]   - For security purposes.
[02:05:38.440 --> 02:05:39.280]   - For security purposes.
[02:05:39.280 --> 02:05:40.520]   - And most computer scientists,
[02:05:40.520 --> 02:05:42.920]   which you'd say believe that P equals NP.
[02:05:42.920 --> 02:05:45.240]   My question almost like,
[02:05:45.240 --> 02:05:46.960]   this is back to our aliens discussion.
[02:05:46.960 --> 02:05:48.400]   You want to think outside the box,
[02:05:48.400 --> 02:05:50.880]   the low probability event.
[02:05:50.880 --> 02:05:53.120]   What is the world,
[02:05:53.120 --> 02:05:56.000]   what kind of discoveries would lead us
[02:05:56.000 --> 02:06:01.000]   to prove that P does not equal to NP?
[02:06:01.000 --> 02:06:05.440]   Like there could be giant misunderstandings
[02:06:05.440 --> 02:06:08.040]   or gaps in our knowledge about computer science,
[02:06:08.040 --> 02:06:09.480]   about theoretical computer science,
[02:06:09.480 --> 02:06:11.000]   about computation,
[02:06:11.000 --> 02:06:14.760]   which allow us to think like flatten all problems.
[02:06:14.760 --> 02:06:17.040]   - Yeah, so I don't know the answer to this question.
[02:06:17.040 --> 02:06:18.600]   I think it's very interesting,
[02:06:18.600 --> 02:06:20.160]   but I actually,
[02:06:20.160 --> 02:06:21.240]   let's put it this way.
[02:06:21.240 --> 02:06:22.520]   By being at Carnegie Mellon
[02:06:22.520 --> 02:06:24.880]   and being around the theoretical computer scientists,
[02:06:24.880 --> 02:06:27.160]   I know enough about what I don't know to say.
[02:06:27.160 --> 02:06:28.840]   I'm the wrong person. - To be humble.
[02:06:28.840 --> 02:06:31.000]   - I'm the wrong person to answer this question.
[02:06:31.000 --> 02:06:32.360]   - Yeah. - Yeah.
[02:06:32.360 --> 02:06:33.240]   It's a great one.
[02:06:33.240 --> 02:06:35.920]   - Well, Scott Aronson, who's now here at UT Austin,
[02:06:35.920 --> 02:06:37.800]   he used to be at MIT,
[02:06:37.800 --> 02:06:42.800]   puts the probability of P not equals to NP at 3%.
[02:06:42.800 --> 02:06:46.800]   He put, you know, I always love it.
[02:06:46.800 --> 02:06:51.040]   When you ask, it's very rare in science and academics,
[02:06:51.040 --> 02:06:53.720]   because most folks are humble
[02:06:53.720 --> 02:06:56.800]   in the face of the mystery,
[02:06:56.800 --> 02:06:59.360]   the uncertainty of everything around us,
[02:06:59.360 --> 02:07:02.800]   to have both the humor and the guts to say,
[02:07:02.800 --> 02:07:07.120]   like what are the chance that there's aliens in our galaxy,
[02:07:07.120 --> 02:07:09.400]   intelligent alien civilizations?
[02:07:09.400 --> 02:07:10.760]   As opposed to saying, I don't know,
[02:07:10.760 --> 02:07:12.280]   it could be zero,
[02:07:12.280 --> 02:07:13.640]   it could be, depending on the factors,
[02:07:13.640 --> 02:07:16.080]   saying it's 2.5%.
[02:07:16.080 --> 02:07:17.680]   (laughing)
[02:07:17.680 --> 02:07:20.280]   There's something very pleasant about just having,
[02:07:20.280 --> 02:07:22.440]   it's the number thing,
[02:07:22.440 --> 02:07:26.440]   it's power to the number, it's just like 42.
[02:07:26.440 --> 02:07:27.280]   It's like, why 40?
[02:07:27.280 --> 02:07:29.640]   I don't know, but it's a powerful number.
[02:07:29.640 --> 02:07:32.600]   And then everything, this is the power of human psychology,
[02:07:32.600 --> 02:07:34.760]   is once you have the number 42,
[02:07:34.760 --> 02:07:39.240]   it's not that the number has meaning,
[02:07:39.240 --> 02:07:43.920]   but because it's placed in a book with humor around it,
[02:07:43.920 --> 02:07:48.920]   it has the meme effect of actually creating reality.
[02:07:48.920 --> 02:07:53.480]   I mean, you could say that 42 has a strong contribution
[02:07:53.480 --> 02:07:55.920]   of helping us colonize Mars,
[02:07:55.920 --> 02:07:57.720]   because it created,
[02:07:57.720 --> 02:08:00.480]   it gave the whatever existential crisis to many of us,
[02:08:00.480 --> 02:08:03.160]   including Elon Musk when he was young,
[02:08:03.160 --> 02:08:04.280]   reading a book like that,
[02:08:04.280 --> 02:08:07.040]   and then now 42 is now part of his humor
[02:08:07.040 --> 02:08:08.880]   that he doesn't shut up about,
[02:08:08.880 --> 02:08:09.880]   he's constantly joking about,
[02:08:09.880 --> 02:08:12.320]   and that humor is spreading through our minds,
[02:08:12.320 --> 02:08:15.160]   and somehow this like silly number just had an effect.
[02:08:15.160 --> 02:08:19.360]   In that same way, after Scott told me the 3% chance,
[02:08:19.360 --> 02:08:20.680]   it's stuck in my head,
[02:08:20.680 --> 02:08:22.680]   and I think it's been having a ripple effect
[02:08:22.680 --> 02:08:23.720]   in everybody else.
[02:08:23.720 --> 02:08:27.720]   The believing that P is not equal to NP,
[02:08:27.720 --> 02:08:32.200]   Scott almost as a joke saying it's 3%,
[02:08:32.200 --> 02:08:34.920]   is actually motivating a large number of researchers
[02:08:34.920 --> 02:08:35.760]   to work on it.
[02:08:35.760 --> 02:08:37.080]   - Like 3% is high.
[02:08:37.080 --> 02:08:37.920]   - It's very high.
[02:08:37.920 --> 02:08:39.880]   - Because for the potential impact that that might have.
[02:08:39.880 --> 02:08:41.320]   (laughing)
[02:08:41.320 --> 02:08:43.480]   But then 3% is not that high,
[02:08:43.480 --> 02:08:44.320]   because it's only,
[02:08:44.320 --> 02:08:46.480]   you know, like we're not very good.
[02:08:46.480 --> 02:08:48.560]   I feel like humans are only able to really think
[02:08:48.560 --> 02:08:51.280]   about like 1%, 50%,
[02:08:51.280 --> 02:08:52.520]   and we kind of,
[02:08:52.520 --> 02:08:57.160]   I think a lot of people round 3% up to 50%,
[02:08:57.160 --> 02:08:58.800]   like in our minds,
[02:08:58.800 --> 02:09:00.120]   like 3%,
[02:09:00.120 --> 02:09:00.960]   like this--
[02:09:00.960 --> 02:09:01.800]   - It could happen.
[02:09:01.800 --> 02:09:02.640]   - It could happen.
[02:09:02.640 --> 02:09:03.480]   And it could happen,
[02:09:03.480 --> 02:09:04.720]   and it's like, yeah,
[02:09:04.720 --> 02:09:07.040]   like half the time it'll probably happen.
[02:09:07.040 --> 02:09:08.520]   So we're not very good at that.
[02:09:08.520 --> 02:09:10.240]   That's the other thing with the pandemic
[02:09:10.240 --> 02:09:13.560]   is we're not the exponential growth
[02:09:13.560 --> 02:09:15.800]   that we also talked about offline
[02:09:15.800 --> 02:09:20.200]   is something that we can't quite intuit.
[02:09:20.200 --> 02:09:22.680]   And that's something we probably should
[02:09:22.680 --> 02:09:24.120]   if we were to predict the future,
[02:09:24.120 --> 02:09:25.240]   to anticipate the future,
[02:09:25.240 --> 02:09:27.920]   and to understand how to create technologies
[02:09:27.920 --> 02:09:30.680]   that let us sort of control the future.
[02:09:30.680 --> 02:09:35.040]   Can I ask you for some recommendations,
[02:09:35.040 --> 02:09:38.240]   maybe for books or movies in your life?
[02:09:39.120 --> 02:09:42.080]   Long ago, when you were baby Poe,
[02:09:42.080 --> 02:09:43.680]   or today,
[02:09:43.680 --> 02:09:47.680]   that you found insightful
[02:09:47.680 --> 02:09:50.360]   or you learned a lot from,
[02:09:50.360 --> 02:09:52.040]   you would recommend to others?
[02:09:52.040 --> 02:09:53.880]   - Yeah, so I think,
[02:09:53.880 --> 02:09:56.600]   I don't necessarily have an exact name of these old things,
[02:09:56.600 --> 02:10:00.640]   but I was generally inspired by stories,
[02:10:00.640 --> 02:10:02.640]   true or fictional,
[02:10:02.640 --> 02:10:04.640]   of campaigns.
[02:10:04.640 --> 02:10:07.560]   For example, like the Lord of the Rings,
[02:10:07.560 --> 02:10:09.080]   that's a campaign, right?
[02:10:09.080 --> 02:10:11.360]   But the thing that always inspired me was
[02:10:11.360 --> 02:10:16.360]   it could be possible for somebody who's crazy enough
[02:10:16.360 --> 02:10:19.960]   to go up against adversity after adversity after adversity,
[02:10:19.960 --> 02:10:21.080]   and it succeeds.
[02:10:21.080 --> 02:10:23.920]   I mean, those are false, those are fictitious,
[02:10:23.920 --> 02:10:25.280]   but I also spent a lot of time, I guess,
[02:10:25.280 --> 02:10:26.600]   reading about, I don't know,
[02:10:26.600 --> 02:10:29.280]   I was interested somehow in like World War II history,
[02:10:29.280 --> 02:10:30.360]   for whatever reason.
[02:10:30.360 --> 02:10:32.360]   That's a campaign which is much more brutal,
[02:10:32.360 --> 02:10:37.240]   but nevertheless, the idea of difficulty, strategy,
[02:10:38.360 --> 02:10:40.600]   fighting even when things,
[02:10:40.600 --> 02:10:41.640]   in that case, it was really fighting,
[02:10:41.640 --> 02:10:44.520]   but just pushing on even when things are difficult.
[02:10:44.520 --> 02:10:47.760]   I guess these are the kinds of general stories
[02:10:47.760 --> 02:10:51.560]   that made me, I guess, want to work on things
[02:10:51.560 --> 02:10:53.080]   that would be hard,
[02:10:53.080 --> 02:10:55.600]   and where it could be a campaign.
[02:10:55.600 --> 02:10:58.160]   It could be that you work on something for a year,
[02:10:58.160 --> 02:10:59.280]   multiple years,
[02:10:59.280 --> 02:11:02.880]   because that was the point, I guess.
[02:11:02.880 --> 02:11:04.800]   - Yeah, it starts with a single person.
[02:11:04.800 --> 02:11:06.320]   That's the interesting thing.
[02:11:06.320 --> 02:11:09.560]   I've obviously been, don't shout about it recently,
[02:11:09.560 --> 02:11:10.720]   about World War II,
[02:11:10.720 --> 02:11:13.280]   especially on the Hitler side and the Stalin side.
[02:11:13.280 --> 02:11:16.240]   Some of that has really affected my own family,
[02:11:16.240 --> 02:11:18.760]   the roots of my family very much,
[02:11:18.760 --> 02:11:20.280]   but it's interesting to think
[02:11:20.280 --> 02:11:24.800]   that it was just an idea,
[02:11:24.800 --> 02:11:26.880]   and one person decided to do stuff,
[02:11:26.880 --> 02:11:29.480]   and it just builds and builds and builds,
[02:11:29.480 --> 02:11:31.840]   and you can truly have an impact on the world,
[02:11:31.840 --> 02:11:34.240]   both horrendous
[02:11:34.240 --> 02:11:40.960]   and exceptionally positive and inspiring.
[02:11:40.960 --> 02:11:46.320]   So yeah, it's agency of us individuals.
[02:11:46.320 --> 02:11:49.880]   Sometimes we think we're just reacting to the world,
[02:11:49.880 --> 02:11:53.040]   but we have the full power to actually change the world.
[02:11:53.040 --> 02:11:56.880]   Is there advice you can give to young folks?
[02:11:56.880 --> 02:11:57.960]   We give a bunch of advice
[02:11:57.960 --> 02:12:00.560]   on middle school, high school mathematics.
[02:12:00.560 --> 02:12:02.440]   Is there more general advice you would give
[02:12:02.440 --> 02:12:04.760]   about how to succeed in life,
[02:12:04.760 --> 02:12:07.400]   how to learn for high school students,
[02:12:07.400 --> 02:12:10.560]   for college students, career or life in general?
[02:12:10.560 --> 02:12:12.280]   - So I think the first one would be
[02:12:12.280 --> 02:12:14.680]   to make sure that you're learning to invent,
[02:12:14.680 --> 02:12:19.040]   and to make sure you're not just learning how to mimic,
[02:12:19.040 --> 02:12:21.840]   because a lot of times you learn how to do X
[02:12:21.840 --> 02:12:23.160]   by watching somebody do X,
[02:12:23.160 --> 02:12:26.360]   and then repeating X many times with different inputs.
[02:12:26.360 --> 02:12:28.520]   I've just been very generic in explaining this,
[02:12:28.520 --> 02:12:31.840]   but I guess this is just my own attitude towards the world.
[02:12:31.840 --> 02:12:34.960]   I didn't like ever following anyone's directions exactly.
[02:12:34.960 --> 02:12:37.680]   Even if you told me this is the way to do your homework
[02:12:37.680 --> 02:12:39.320]   is to write in pencil, I would say,
[02:12:39.320 --> 02:12:41.200]   "But I think pen is nice.
[02:12:41.200 --> 02:12:42.040]   "Let's try."
[02:12:42.040 --> 02:12:42.880]   (laughs)
[02:12:42.880 --> 02:12:45.680]   So I've been that kind of a funny person,
[02:12:45.680 --> 02:12:50.680]   but I do encourage that if you can learn how to invent
[02:12:50.680 --> 02:12:52.760]   as your core skill, then you can do a lot.
[02:12:52.760 --> 02:12:54.320]   But then the second piece that comes with that
[02:12:54.320 --> 02:12:56.320]   is something I learned from my PhD advisor,
[02:12:56.320 --> 02:12:59.880]   which was, "Well, make sure that what you're working on
[02:12:59.880 --> 02:13:01.280]   "is big enough."
[02:13:01.280 --> 02:13:03.760]   And so in that sense, I usually advise to people
[02:13:03.760 --> 02:13:05.680]   once they have learned how to invent,
[02:13:05.680 --> 02:13:08.840]   ideally, don't just try to settle
[02:13:08.840 --> 02:13:10.480]   for something comfortable.
[02:13:10.480 --> 02:13:14.000]   Try to see if you can aim for something which is hard,
[02:13:14.000 --> 02:13:15.760]   which might involve a campaign,
[02:13:15.760 --> 02:13:19.000]   which might be important, which might make a difference.
[02:13:19.000 --> 02:13:22.880]   And it's more of, I guess, rather than worrying,
[02:13:22.880 --> 02:13:25.800]   what if you didn't achieve that?
[02:13:25.800 --> 02:13:30.320]   There's also the regret of, what if I didn't try?
[02:13:30.320 --> 02:13:31.560]   See, that's how I operate.
[02:13:31.560 --> 02:13:33.680]   I don't operate based on, did I succeed or fail?
[02:13:33.680 --> 02:13:34.600]   It was hard anyway.
[02:13:34.600 --> 02:13:36.600]   If I did this novid thing and the whole thing failed,
[02:13:36.600 --> 02:13:37.600]   would I feel terrible?
[02:13:37.600 --> 02:13:39.440]   No, it's a very hard problem.
[02:13:39.440 --> 02:13:42.600]   But would I have had the regret of not jumping in?
[02:13:42.600 --> 02:13:44.040]   Yes.
[02:13:44.040 --> 02:13:45.520]   So it's that different mentality of,
[02:13:45.520 --> 02:13:48.640]   don't worry about the failing part as much of the,
[02:13:48.640 --> 02:13:50.720]   make sure you give yourself the shot
[02:13:50.720 --> 02:13:53.680]   at those potentially unbounded opportunities.
[02:13:55.160 --> 02:13:58.280]   - You almost make it sound like there's a meaning to it all.
[02:13:58.280 --> 02:13:59.880]   Let me ask the big, ridiculous question.
[02:13:59.880 --> 02:14:01.760]   What do you think is the meaning of life?
[02:14:01.760 --> 02:14:04.120]   Or maybe the easier version of that
[02:14:04.120 --> 02:14:06.040]   is what brings your life joy?
[02:14:06.040 --> 02:14:07.800]   - So I'll just answer that one personally.
[02:14:07.800 --> 02:14:10.000]   For me, I'm a little bit weird.
[02:14:10.000 --> 02:14:13.440]   I sort of, I guess you can tell by now.
[02:14:13.440 --> 02:14:15.880]   - See the pen and pencil discussion from earlier, yes.
[02:14:15.880 --> 02:14:16.840]   - Yeah, yeah.
[02:14:16.840 --> 02:14:20.280]   So, I mean, my thing is, I guess I personally
[02:14:20.280 --> 02:14:24.280]   just wanted to maximize a certain score,
[02:14:24.280 --> 02:14:28.080]   which was for how many person years
[02:14:28.080 --> 02:14:30.960]   after I'm no longer here anymore,
[02:14:30.960 --> 02:14:33.880]   did what I do mattered?
[02:14:33.880 --> 02:14:36.440]   And it didn't matter if it's necessarily attributed to me.
[02:14:36.440 --> 02:14:38.560]   It's just like, did it matter?
[02:14:38.560 --> 02:14:41.760]   And so that's what I wanted.
[02:14:41.760 --> 02:14:45.560]   I guess that is very inspired by how scientists work.
[02:14:45.560 --> 02:14:47.720]   It's like, why do we keep talking about Newton?
[02:14:47.720 --> 02:14:50.800]   It's because Newton discovered some interesting things.
[02:14:50.800 --> 02:14:52.600]   And so Newton's score is pretty high.
[02:14:53.800 --> 02:14:56.240]   It's going to be infinity, right?
[02:14:56.240 --> 02:14:58.520]   - Well, let's hope it's infinity, but pretty high.
[02:14:58.520 --> 02:15:00.080]   - Ah, yes, yes.
[02:15:00.080 --> 02:15:03.720]   - So you're going for, so person years,
[02:15:03.720 --> 02:15:05.440]   you're going for like triple digits.
[02:15:05.440 --> 02:15:08.880]   You're going for, so like Newton is like four digits,
[02:15:08.880 --> 02:15:13.160]   probably like a thousand years or a person lifetimes.
[02:15:13.160 --> 02:15:15.280]   Like, how do you like to think about, what are we?
[02:15:15.280 --> 02:15:17.440]   - Sorry, I meant people times years.
[02:15:17.440 --> 02:15:18.280]   - People times.
[02:15:18.280 --> 02:15:19.920]   - So then it's like, actually his is huge.
[02:15:19.920 --> 02:15:22.600]   His is like going to be billions or trillions, right?
[02:15:22.600 --> 02:15:26.360]   Trillions, but I guess for me,
[02:15:26.360 --> 02:15:28.320]   I actually changed the metric after a while.
[02:15:28.320 --> 02:15:30.040]   And the reason is because you may have seen,
[02:15:30.040 --> 02:15:33.600]   I found some simple way to solve quadratic equations
[02:15:33.600 --> 02:15:35.720]   that is easier than every textbook.
[02:15:35.720 --> 02:15:39.000]   So my score might already be not bad,
[02:15:39.000 --> 02:15:40.720]   which is why I decided then let's change it
[02:15:40.720 --> 02:15:44.600]   into the number of hours in the lifetimes as well.
[02:15:44.600 --> 02:15:48.400]   So the way I was doing it before is that
[02:15:49.400 --> 02:15:53.440]   if a person was sort of remembering or using
[02:15:53.440 --> 02:15:56.040]   or appreciating what I had done
[02:15:56.040 --> 02:16:01.040]   for like 10 years of their life, that would count as 10.
[02:16:01.040 --> 02:16:02.480]   - I see.
[02:16:02.480 --> 02:16:04.600]   - So if there was one person who for 10 years
[02:16:04.600 --> 02:16:06.200]   remembered or appreciated something I did,
[02:16:06.200 --> 02:16:09.360]   that counts as a score of 10 and we add up overall people.
[02:16:09.360 --> 02:16:13.480]   And then, and that was with the hypothesis
[02:16:13.480 --> 02:16:17.640]   that the score would be very finite in the sense that
[02:16:17.640 --> 02:16:19.040]   if I didn't come up with anything
[02:16:19.040 --> 02:16:21.360]   that might potentially help a lot of generations
[02:16:21.360 --> 02:16:23.840]   in a forever way, then your score will be finite
[02:16:23.840 --> 02:16:25.960]   because at some point it's not,
[02:16:25.960 --> 02:16:27.880]   people don't remember that you made
[02:16:27.880 --> 02:16:30.160]   like nice bottles or something, right?
[02:16:30.160 --> 02:16:33.040]   But then after the quadratic equation thing,
[02:16:33.040 --> 02:16:35.000]   it was that there's some chance
[02:16:35.000 --> 02:16:37.720]   that that actually might make it into textbooks.
[02:16:37.720 --> 02:16:39.080]   And if it makes it in textbooks,
[02:16:39.080 --> 02:16:40.960]   the chance that there'll be an easier way discovered
[02:16:40.960 --> 02:16:42.680]   is actually quite small.
[02:16:42.680 --> 02:16:46.240]   So in that case, then the score might get bigger.
[02:16:46.240 --> 02:16:47.760]   I was just saying the score might actually
[02:16:47.760 --> 02:16:51.240]   already have been achieved in a non-trivial way.
[02:16:51.240 --> 02:16:52.080]   - I see.
[02:16:52.080 --> 02:16:52.920]   - Because--
[02:16:52.920 --> 02:16:54.600]   - It's fun to think about, 'cause it could be different.
[02:16:54.600 --> 02:16:58.960]   You can achieve a high score by a small number of people
[02:16:58.960 --> 02:17:01.240]   using it for most of their lifetime
[02:17:01.240 --> 02:17:03.400]   and then generations and generations,
[02:17:03.400 --> 02:17:05.960]   or you can have, if we do dissipate,
[02:17:05.960 --> 02:17:10.120]   if we do spread, colonize, become multi-planetary species,
[02:17:10.120 --> 02:17:13.200]   you could have that little, a clever way
[02:17:13.200 --> 02:17:14.800]   to solve differential equations.
[02:17:15.160 --> 02:17:16.000]   - Yeah.
[02:17:16.000 --> 02:17:19.640]   - Spread through like trillions of people
[02:17:19.640 --> 02:17:21.600]   as they spread throughout the galaxy.
[02:17:21.600 --> 02:17:24.800]   And they would only use it each one
[02:17:24.800 --> 02:17:26.760]   a few hours in their lifetime,
[02:17:26.760 --> 02:17:28.280]   but their kids will use it,
[02:17:28.280 --> 02:17:30.080]   the kids of kids will use it, it will spread,
[02:17:30.080 --> 02:17:33.240]   and you'll have that impact in that kind of way.
[02:17:33.240 --> 02:17:34.920]   - Yes, so that's why I renormalized it,
[02:17:34.920 --> 02:17:36.440]   because I was like, well, that's kind of dumb,
[02:17:36.440 --> 02:17:37.720]   because what's the importance of that?
[02:17:37.720 --> 02:17:39.880]   That'll save people 15 minutes.
[02:17:39.880 --> 02:17:42.400]   But so what I meant is I didn't want to count that
[02:17:42.400 --> 02:17:43.240]   as the main score.
[02:17:43.240 --> 02:17:44.640]   (both laughing)
[02:17:44.640 --> 02:17:45.480]   So.
[02:17:45.480 --> 02:17:47.880]   - Well, I'm gonna have to try to come up
[02:17:47.880 --> 02:17:50.360]   with some kind of device that everyone would want to use,
[02:17:50.360 --> 02:17:51.520]   maybe to make coffee,
[02:17:51.520 --> 02:17:55.560]   'cause coffee seems to be the prevalent performance
[02:17:55.560 --> 02:17:57.160]   enhancing chemical that everyone uses.
[02:17:57.160 --> 02:17:59.880]   So I'll have to think about those kinds of metrics.
[02:17:59.880 --> 02:18:00.880]   - Yeah.
[02:18:00.880 --> 02:18:02.560]   But you see, that's just giving an idea
[02:18:02.560 --> 02:18:05.080]   of I guess what I found meaningful in general,
[02:18:05.080 --> 02:18:06.200]   like whether or not it's like,
[02:18:06.200 --> 02:18:08.320]   whether or not that quadratic thing is important or not.
[02:18:08.320 --> 02:18:10.720]   The general idea was I wanted to do things
[02:18:10.720 --> 02:18:11.840]   that would outlast me.
[02:18:11.840 --> 02:18:12.680]   - Yes.
[02:18:12.680 --> 02:18:13.520]   - And that was what inspired me.
[02:18:13.520 --> 02:18:15.720]   That's just how I choose what problems to work on.
[02:18:15.720 --> 02:18:17.240]   - And that's a kind of immortality,
[02:18:17.240 --> 02:18:22.240]   is ideas that you've invented living on long after you
[02:18:22.240 --> 02:18:24.960]   in the minds of others.
[02:18:24.960 --> 02:18:27.200]   And humans are ultimately not,
[02:18:27.200 --> 02:18:32.200]   are like meat vehicles that carry ideas for brief,
[02:18:32.200 --> 02:18:34.920]   for just a few years, may not be the important thing.
[02:18:34.920 --> 02:18:37.560]   It might be the ideas that we carry with us
[02:18:37.560 --> 02:18:38.760]   and invent new ones.
[02:18:38.760 --> 02:18:41.680]   Like we get a bunch of baby ideas in our head.
[02:18:41.680 --> 02:18:43.160]   We borrow them from others,
[02:18:43.160 --> 02:18:45.080]   and then maybe we invent a new one
[02:18:45.080 --> 02:18:47.960]   and then you one might have a life of its own.
[02:18:47.960 --> 02:18:49.560]   And it's fun.
[02:18:49.560 --> 02:18:51.200]   It's fun to think about that idea of living
[02:18:51.200 --> 02:18:54.960]   for many centuries to come, unless we destroy ourselves.
[02:18:54.960 --> 02:18:58.920]   But maybe AI will borrow it and we'll remember Poe
[02:18:58.920 --> 02:19:01.840]   as like that one human that helped us out
[02:19:01.840 --> 02:19:04.680]   before we of course killed him
[02:19:04.680 --> 02:19:06.760]   and the rest of human civilization.
[02:19:06.760 --> 02:19:09.840]   On that note, Poe, this is a huge honor.
[02:19:09.840 --> 02:19:11.780]   You're one of the great educators.
[02:19:12.880 --> 02:19:15.240]   I've ever gotten a chance to interact with.
[02:19:15.240 --> 02:19:18.520]   So it's truly an honor that you would talk with me today.
[02:19:18.520 --> 02:19:21.160]   It means especially a lot that you would travel out
[02:19:21.160 --> 02:19:22.480]   to Austin to talk to me.
[02:19:22.480 --> 02:19:23.480]   It really means a lot.
[02:19:23.480 --> 02:19:25.180]   So thank you so much.
[02:19:25.180 --> 02:19:26.480]   Keep on inspiring.
[02:19:26.480 --> 02:19:30.320]   And I'm one of your many, many students.
[02:19:30.320 --> 02:19:32.160]   Thank you so much for talking today.
[02:19:32.160 --> 02:19:32.980]   - Thank you.
[02:19:32.980 --> 02:19:33.820]   Thank you.
[02:19:33.820 --> 02:19:34.640]   It's actually a real honor for me to talk to you
[02:19:34.640 --> 02:19:36.680]   and to get this chance to have this
[02:19:36.680 --> 02:19:38.480]   really intellectual conversation
[02:19:38.480 --> 02:19:39.800]   through all of these topics.
[02:19:39.800 --> 02:19:40.640]   - Thanks, Poe.
[02:19:41.440 --> 02:19:43.040]   Thanks for listening to this conversation
[02:19:43.040 --> 02:19:44.240]   with Poe Shen Lowe.
[02:19:44.240 --> 02:19:47.040]   And thank you to Jordan Harbour to show,
[02:19:47.040 --> 02:19:51.400]   Onnit, BetterHelp, Eight Sleep, and Element.
[02:19:51.400 --> 02:19:54.480]   Check them out in the description to support this podcast.
[02:19:54.480 --> 02:19:58.320]   And now let me leave you with some words from Isaac Newton.
[02:19:58.320 --> 02:20:01.280]   I can calculate the motion of heavenly bodies,
[02:20:01.280 --> 02:20:03.700]   but not the madness of people.
[02:20:03.700 --> 02:20:04.640]   Thank you for listening.
[02:20:04.640 --> 02:20:06.360]   I hope to see you next time.
[02:20:06.360 --> 02:20:08.940]   (upbeat music)
[02:20:08.940 --> 02:20:11.520]   (upbeat music)
[02:20:11.520 --> 02:20:21.520]   [BLANK_AUDIO]

