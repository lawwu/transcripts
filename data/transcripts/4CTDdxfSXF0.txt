
[00:00:00.000 --> 00:00:07.960]   [MUSIC]
[00:00:07.960 --> 00:00:11.040]   >> What advice do you have for
[00:00:11.040 --> 00:00:15.040]   someone who wants to get started in deep learning?
[00:00:15.040 --> 00:00:17.240]   >> Train lots of models.
[00:00:17.240 --> 00:00:20.280]   That's how you learn it.
[00:00:20.280 --> 00:00:24.760]   So I think, it's not just me,
[00:00:24.760 --> 00:00:26.520]   I think our course is very good,
[00:00:26.520 --> 00:00:27.960]   but also lots of people independently,
[00:00:27.960 --> 00:00:28.760]   is that it's very good.
[00:00:28.760 --> 00:00:30.920]   It recently won the COGX award for
[00:00:30.920 --> 00:00:33.160]   AI courses as being the best in the world.
[00:00:33.160 --> 00:00:36.040]   I'd say come to our course, course.fast.ai.
[00:00:36.040 --> 00:00:39.040]   The thing I keep on hopping on in my lessons is,
[00:00:39.040 --> 00:00:42.320]   train models, print out the inputs to the models,
[00:00:42.320 --> 00:00:44.440]   print out to the outputs to the models,
[00:00:44.440 --> 00:00:48.280]   study, change the inputs a bit,
[00:00:48.280 --> 00:00:50.360]   look at how the outputs vary,
[00:00:50.360 --> 00:00:52.080]   just run lots of experiments to get
[00:00:52.080 --> 00:00:58.120]   an intuitive understanding of what's going on.
[00:00:58.120 --> 00:01:02.120]   >> To get hooked, you mentioned training,
[00:01:02.120 --> 00:01:06.000]   do you think just running the models inference?
[00:01:06.000 --> 00:01:08.560]   If we talk about getting started.
[00:01:08.560 --> 00:01:10.600]   >> No, you've got to fine-tune the models.
[00:01:10.600 --> 00:01:12.680]   So that's the critical thing,
[00:01:12.680 --> 00:01:14.040]   because at that point, you now have
[00:01:14.040 --> 00:01:16.320]   a model that's in your domain area.
[00:01:16.320 --> 00:01:18.800]   So there's no point running
[00:01:18.800 --> 00:01:21.280]   somebody else's model because it's not your model.
[00:01:21.280 --> 00:01:23.280]   It only takes five minutes to fine-tune
[00:01:23.280 --> 00:01:25.120]   a model for the data you care about.
[00:01:25.120 --> 00:01:26.720]   In lesson two of the course,
[00:01:26.720 --> 00:01:29.000]   we teach you how to create your own dataset from
[00:01:29.000 --> 00:01:31.960]   scratch by scripting Google Image Search.
[00:01:31.960 --> 00:01:34.000]   We show you how to actually
[00:01:34.000 --> 00:01:36.040]   create a web application running online.
[00:01:36.040 --> 00:01:37.680]   So I create one in the course that
[00:01:37.680 --> 00:01:39.440]   differentiates between a teddy bear,
[00:01:39.440 --> 00:01:41.200]   a grizzly bear, and a brown bear.
[00:01:41.200 --> 00:01:44.040]   It does it with basically 100 percent accuracy.
[00:01:44.040 --> 00:01:45.960]   Took me about four minutes to scrape
[00:01:45.960 --> 00:01:48.040]   the images from Google Search in the script.
[00:01:48.040 --> 00:01:50.960]   There's a little graphical widgets we
[00:01:50.960 --> 00:01:54.280]   have in the notebook that help you clean up the dataset.
[00:01:54.280 --> 00:01:56.680]   There's other widgets that help you study
[00:01:56.680 --> 00:01:59.440]   the results to see where the errors are happening.
[00:01:59.440 --> 00:02:03.280]   So now we've got over 1,000 replies in our share
[00:02:03.280 --> 00:02:05.880]   your work here thread of students saying,
[00:02:05.880 --> 00:02:07.440]   here's the thing I built.
[00:02:07.440 --> 00:02:08.960]   So there's people who like,
[00:02:08.960 --> 00:02:10.720]   and a lot of them are state of the art.
[00:02:10.720 --> 00:02:12.280]   Like somebody said, "Oh, I tried looking at
[00:02:12.280 --> 00:02:14.320]   Devan Garey characters and I couldn't believe it.
[00:02:14.320 --> 00:02:16.640]   The thing that came out was more accurate than
[00:02:16.640 --> 00:02:19.600]   the best academic paper after lesson one."
[00:02:19.600 --> 00:02:21.720]   Then there's others which are just more fun,
[00:02:21.720 --> 00:02:26.280]   like somebody who's doing Trinidad and Tobago hummingbirds.
[00:02:26.280 --> 00:02:28.800]   She said that's their national bird and she's got
[00:02:28.800 --> 00:02:30.160]   something that can now classify
[00:02:30.160 --> 00:02:31.880]   Trinidad and Tobago hummingbirds.
[00:02:31.880 --> 00:02:33.440]   So yeah, train models,
[00:02:33.440 --> 00:02:35.640]   fine-tune models with your dataset,
[00:02:35.640 --> 00:02:37.960]   and then study their inputs and outputs.
[00:02:37.960 --> 00:02:40.320]   >> How much is Fast.ai courses?
[00:02:40.320 --> 00:02:43.400]   >> Free. Everything we do is free.
[00:02:43.400 --> 00:02:45.920]   We have no revenue sources of any kind.
[00:02:45.920 --> 00:02:48.160]   It's just a service to the community.
[00:02:48.160 --> 00:02:50.120]   >> You're a saint.
[00:02:50.120 --> 00:02:53.120]   Once a person understands the basics,
[00:02:53.120 --> 00:02:55.320]   trains a bunch of models,
[00:02:55.320 --> 00:02:59.040]   if we look at the scale of years,
[00:02:59.040 --> 00:03:00.440]   what advice do you have for someone
[00:03:00.440 --> 00:03:03.200]   wanting to eventually become an expert?
[00:03:03.200 --> 00:03:05.640]   >> Train lots of models.
[00:03:05.640 --> 00:03:08.520]   Specifically, train lots of models in your domain area.
[00:03:08.520 --> 00:03:09.920]   So an expert what?
[00:03:09.920 --> 00:03:12.240]   We don't need more expert,
[00:03:12.240 --> 00:03:18.200]   like create slightly evolutionary research
[00:03:18.200 --> 00:03:19.760]   in areas that everybody's studying.
[00:03:19.760 --> 00:03:25.800]   We need experts at using deep learning to diagnose malaria,
[00:03:25.800 --> 00:03:29.440]   or we need experts at using deep learning to
[00:03:29.440 --> 00:03:34.280]   analyze language to study media bias,
[00:03:34.280 --> 00:03:40.680]   or we need experts in analyzing
[00:03:40.680 --> 00:03:44.880]   fisheries to identify problem areas in the ocean.
[00:03:44.880 --> 00:03:46.480]   That's what we need.
[00:03:46.480 --> 00:03:51.280]   So become the expert in your passion area.
[00:03:51.280 --> 00:03:54.400]   This is a tool which you can use for just about anything,
[00:03:54.400 --> 00:03:57.520]   and you'll be able to do that thing better than other people,
[00:03:57.520 --> 00:04:00.680]   particularly by combining it with your passion and domain expertise.
[00:04:00.680 --> 00:04:02.760]   >> So that's really interesting. Even if you do want to
[00:04:02.760 --> 00:04:05.680]   innovate on transfer learning or active learning,
[00:04:05.680 --> 00:04:07.440]   your thought is, I mean,
[00:04:07.440 --> 00:04:09.240]   it's one I certainly share,
[00:04:09.240 --> 00:04:11.360]   is you also need to find
[00:04:11.360 --> 00:04:14.920]   a domain or a dataset that you actually really care for.
[00:04:14.920 --> 00:04:18.200]   If you're not working on a real problem that you understand,
[00:04:18.200 --> 00:04:21.000]   how do you know if you're doing it any good?
[00:04:21.000 --> 00:04:22.520]   How do you know if your results are good?
[00:04:22.520 --> 00:04:24.000]   How do you know if you're getting bad results?
[00:04:24.000 --> 00:04:25.240]   Why are you getting bad results?
[00:04:25.240 --> 00:04:27.280]   Is it a problem with the data?
[00:04:27.280 --> 00:04:30.200]   How do you know you're doing anything useful?
[00:04:30.200 --> 00:04:33.960]   Yeah, to me, the only really interesting research is,
[00:04:33.960 --> 00:04:36.720]   not the only, but the vast majority of interesting research is
[00:04:36.720 --> 00:04:41.080]   like try and solve an actual problem and solve it really well.
[00:04:41.680 --> 00:04:43.320]   >> Yeah, I think that's really interesting.
[00:04:43.320 --> 00:04:44.840]   I mean, I think that's really interesting.
[00:04:44.840 --> 00:04:46.120]   I think that's really interesting.
[00:04:46.120 --> 00:04:51.040]   I think it's really interesting to see how the world has evolved.
[00:04:51.040 --> 00:04:53.720]   I think it's really interesting to see how the world has evolved.
[00:04:53.720 --> 00:04:55.920]   I think it's really interesting to see how the world has evolved.
[00:04:55.920 --> 00:04:58.720]   I think it's really interesting to see how the world has evolved.
[00:04:58.720 --> 00:05:01.520]   I think it's really interesting to see how the world has evolved.

