
[00:00:00.000 --> 00:00:04.000]   My first time. I can't believe how incredibly nervous I am.
[00:00:04.000 --> 00:00:07.000]   What can possibly go wrong?
[00:00:07.000 --> 00:00:11.000]   It's kind of funny, the kind of things we get nervous about in this world.
[00:00:11.000 --> 00:00:15.000]   As if we're not hurling through space at some incredible speed.
[00:00:15.000 --> 00:00:18.000]   As if something actually matters.
[00:00:18.000 --> 00:00:21.000]   Well, okay. Here I am talking to myself, alone in a room.
[00:00:21.000 --> 00:00:24.000]   And I feel naked before a large audience.
[00:00:24.000 --> 00:00:29.000]   So, first time. Just living up to the New Year's resolution of
[00:00:29.000 --> 00:00:32.000]   having a bit more fun.
[00:00:32.000 --> 00:00:35.000]   And I guess this is what one version of fun looks like.
[00:00:35.000 --> 00:00:38.000]   Okay, today the chat is going nuts.
[00:00:38.000 --> 00:00:43.000]   I'm not going to be able to at all pay attention.
[00:00:43.000 --> 00:00:47.000]   But there's an amazing team of folks that I'm now working with.
[00:00:47.000 --> 00:00:50.000]   They're helping me out. I mean, they inspire me every day.
[00:00:50.000 --> 00:00:55.000]   I love working with those guys and they're monitoring the chats for questions.
[00:00:55.000 --> 00:01:00.000]   As if I can do a good job of answering any of them.
[00:01:00.000 --> 00:01:05.000]   Still nervous. Okay. So I did a podcast conversation with Elon a few days ago.
[00:01:05.000 --> 00:01:08.000]   If you haven't gotten a chance to watch it, please do.
[00:01:08.000 --> 00:01:14.000]   I thought I would do this kind of live stream to answer any questions that folks have.
[00:01:14.000 --> 00:01:17.000]   Hopefully the audio is okay.
[00:01:17.000 --> 00:01:20.000]   If it's not, I don't know what we're going to do. I'll figure this out.
[00:01:20.000 --> 00:01:26.000]   Okay. And I'll probably do these kinds of live streams on occasion.
[00:01:26.000 --> 00:01:30.000]   Try to keep them short. Try to have a bit of fun.
[00:01:30.000 --> 00:01:34.000]   Answer whatever questions. If you have questions about the Elon Musk conversation,
[00:01:34.000 --> 00:01:36.000]   I'd love to answer them now.
[00:01:36.000 --> 00:01:40.000]   And maybe I'll do a quick recap first before I answer questions.
[00:01:40.000 --> 00:01:48.000]   And if you donate like super chats or whatever the heck those are called,
[00:01:48.000 --> 00:01:52.000]   please don't donate a lot of money.
[00:01:52.000 --> 00:01:56.000]   But let's say nothing more than $42. Let's set the limit there.
[00:01:56.000 --> 00:01:58.000]   I don't need the money. I got so much love from you guys.
[00:01:58.000 --> 00:02:04.000]   I really appreciate the support. I'm forever grateful and really humbled by that.
[00:02:04.000 --> 00:02:09.000]   Okay. Let's see. So one thing maybe get the news out of the way,
[00:02:09.000 --> 00:02:12.000]   even after the conversation is the deliveries.
[00:02:12.000 --> 00:02:22.000]   So we've been going through a couple of years of obviously a turmoil and I would even say suffering economic and otherwise.
[00:02:22.000 --> 00:02:25.000]   And one of the incredible things is on the supply chain,
[00:02:25.000 --> 00:02:32.000]   despite all those challenges that Tesla and Elon were still able to deliver in large number of vehicles.
[00:02:32.000 --> 00:02:38.000]   I don't these days pay as close of attention as I used to in terms of the deliveries.
[00:02:38.000 --> 00:02:44.000]   I used to be fascinated by sort of the number of semi-autonomous robots that are out there,
[00:02:44.000 --> 00:02:47.000]   the hundreds of thousands, which is still incredible to me.
[00:02:47.000 --> 00:02:57.000]   So I think they were able to set another record with 308,000 vehicles delivered in quarter four of this year,
[00:02:57.000 --> 00:03:03.000]   making that a total of almost a million vehicles for this year, 936,000.
[00:03:03.000 --> 00:03:09.000]   So 936,000 vehicles delivered by Tesla.
[00:03:09.000 --> 00:03:15.000]   I missed all the supply chain difficulties amongst all the growth they're going through amongst all the doubters.
[00:03:15.000 --> 00:03:21.000]   I think you'll listen to the podcast and you can you can listen to what Elon says about the doubters,
[00:03:21.000 --> 00:03:27.000]   includes the letters FCK that and you can fill in the blank.
[00:03:27.000 --> 00:03:31.000]   Anyway, on the conversation itself, there's so much I could say.
[00:03:31.000 --> 00:03:33.000]   Maybe people have questions specifically to that.
[00:03:33.000 --> 00:03:38.000]   I just want to kind of comment on as a human being, as an interviewer,
[00:03:38.000 --> 00:03:45.000]   as a researcher and a fan of the ideas in the field of artificial intelligence.
[00:03:45.000 --> 00:03:48.000]   I took a lot away from that conversation was really inspiring.
[00:03:48.000 --> 00:04:03.000]   One of the things is the real gift that Elon gave me of, I would say, trust and friendship in just sitting there and thinking.
[00:04:03.000 --> 00:04:10.000]   So the silence to me was really powerful that he would trust me, that I wouldn't interrupt him,
[00:04:10.000 --> 00:04:14.000]   that I would just sit there and really listen. And then he could sit there.
[00:04:14.000 --> 00:04:21.000]   We could sit there in silence and think. I think silence is one of the most intimate things that two people can share with each other,
[00:04:21.000 --> 00:04:29.000]   because it's having a trust that like you're on the same page, like with friends, with that in relationships, just silence can be beautiful.
[00:04:29.000 --> 00:04:35.000]   And in a podcast conversation, especially when there's nerves, where there's so much uncertainty,
[00:04:35.000 --> 00:04:43.000]   the mics are recording. Silence is a real gift. And it's a, I don't know, like I said, trust and friendship.
[00:04:43.000 --> 00:04:48.000]   And also it made me realize as a fan of podcast how much I love the silence.
[00:04:48.000 --> 00:04:56.000]   I used to think actually the first time we talked, I asked him, what one question would you ask for an AGI system,
[00:04:56.000 --> 00:05:01.000]   an artificial general intelligence system? And so he took a long time to answer that.
[00:05:01.000 --> 00:05:05.000]   That's so we got more comfortable through the span of that conversation.
[00:05:05.000 --> 00:05:10.000]   And I actually one of the only things I edited in that conversation was the length of the pause.
[00:05:10.000 --> 00:05:18.000]   I actually made it shorter than it was. And later I realized that that's not you know, you don't need to.
[00:05:18.000 --> 00:05:27.000]   People can wait. It's OK if the pause is 15 seconds. It's good to see a man, a human being think.
[00:05:27.000 --> 00:05:36.000]   And that's one of the beautiful things about long form is you have as much time as you need to think.
[00:05:36.000 --> 00:05:41.000]   Oh, do I click on these super chats? Let me wrap up. Let me just finish.
[00:05:41.000 --> 00:05:45.000]   Talking about a couple of thoughts I had about that interview.
[00:05:45.000 --> 00:05:51.000]   So the other thing is offline and on mic, we talked a lot. We talked a lot offline, actually.
[00:05:51.000 --> 00:06:00.000]   And he sung praises to the engineers and that the engineers, especially like the low level software engineers,
[00:06:00.000 --> 00:06:06.000]   are the, as he said in the podcast, unsung heroes. And they are to me, too.
[00:06:06.000 --> 00:06:11.000]   The people that make the compute infrastructure happen, the admins, the DevOps people.
[00:06:11.000 --> 00:06:16.000]   When I worked at Google, that was the case, too. Yes, the machine learning stuff is the sexy stuff.
[00:06:16.000 --> 00:06:21.000]   That's what I worked on. But the people that actually do the distributed compute,
[00:06:21.000 --> 00:06:25.000]   they're able to train the networks across a large number of computers.
[00:06:25.000 --> 00:06:30.000]   They're able to even just like the low level stuff, even the security stuff, everything, the whole thing,
[00:06:30.000 --> 00:06:35.000]   low level software engineering, building a compiler from scratch.
[00:06:35.000 --> 00:06:44.000]   So doing the on board, so on vehicle computation, making that efficient, making that reliable,
[00:06:44.000 --> 00:06:48.000]   because it's a safety critical system. So that's incredibly difficult.
[00:06:48.000 --> 00:06:54.000]   And that's machine learning is in that situation, honestly, is the icing on the cake.
[00:06:54.000 --> 00:07:01.000]   It's the cherry on the cake. The bulk of the work and the incredible work that's being done is on the low level software engineers.
[00:07:01.000 --> 00:07:08.000]   So he sung praises to them. And even just the hardware. I mean, obviously the hardware.
[00:07:08.000 --> 00:07:15.000]   Hardware is where the magic is and also on the manufacture side. So all the way down to the raw materials.
[00:07:15.000 --> 00:07:19.000]   Going from raw materials to the manufacturers, through the supply chain,
[00:07:19.000 --> 00:07:26.000]   especially when the resilience of the supply chain is tested. That's engineers all the way down.
[00:07:26.000 --> 00:07:29.000]   It's like turtles all the way down. It's engineers all the way down.
[00:07:29.000 --> 00:07:37.000]   Hopefully I'm not rambling way too long. The other thing, obviously, I didn't know how to ask this.
[00:07:37.000 --> 00:07:42.000]   So, of course, my usual mumbling way I rambled on for a while and asking this question.
[00:07:42.000 --> 00:07:56.000]   But Elon Musk seems, and it's sad to me to see, but seems to have a non-zero, non-empty set of doubters in this world.
[00:07:56.000 --> 00:08:02.000]   And yeah, you could say maybe it's because of financial, because of shorting stocks and all those kinds of things.
[00:08:02.000 --> 00:08:07.000]   But I know people that aren't shorting the stock and they're still full of doubt.
[00:08:07.000 --> 00:08:13.000]   First of all, to me as a human being, that breaks my heart. I think optimism is just fun.
[00:08:13.000 --> 00:08:17.000]   And also optimism is the thing that creates the change.
[00:08:17.000 --> 00:08:25.000]   But when I talk about them, I think the more interesting doubt is Elon Musk's own self-doubt.
[00:08:25.000 --> 00:08:31.000]   And the doubt from people that are in the field of battle.
[00:08:31.000 --> 00:08:36.000]   So these aren't just critics, but the legit engineers that doubt whether something is possible.
[00:08:36.000 --> 00:08:42.000]   When there's all that kind of doubt, like you have with Starship now, like you had when building Autopilot from scratch,
[00:08:42.000 --> 00:08:45.000]   throughout the history of Autopilot, what do you do?
[00:08:45.000 --> 00:08:47.000]   And that's when he said, "Fuck that, we'll get it done."
[00:08:47.000 --> 00:08:52.000]   I don't care about optimism or pessimism. Fuck that, we'll get it done.
[00:08:52.000 --> 00:08:58.000]   I mean, I'm gonna, I don't know. I feel like I'm gonna take that little clip and just play it every morning for myself.
[00:08:58.000 --> 00:09:01.000]   Because you can get so lost into overthinking stuff.
[00:09:01.000 --> 00:09:08.000]   The reality is, just get it done. And don't quit until it's done. That's it. It's simple.
[00:09:08.000 --> 00:09:14.000]   And New Year's resolutions, last thing I'll say.
[00:09:14.000 --> 00:09:21.000]   Off mic and on mic and afterwards, we also hung out together for New Year's.
[00:09:21.000 --> 00:09:30.000]   I think from the company perspective, just overall, first of all, there's an excitement for the future.
[00:09:30.000 --> 00:09:34.000]   And like he tweeted today, I think, "Let's make this the Roaring 20s."
[00:09:34.000 --> 00:09:43.000]   I think there's an optimism that coming out of this pandemic, we'll build our way out of it.
[00:09:43.000 --> 00:09:48.000]   We will innovate our way out of it. And that means both the software and the hardware.
[00:09:48.000 --> 00:09:51.000]   It's again, the "Fuck that, we'll get it done."
[00:09:51.000 --> 00:09:57.000]   And that's, I don't know, that optimism about the New Year's definitely just permeates everything.
[00:09:57.000 --> 00:10:00.000]   So on Neuralink, there's a lot of really ambitious goals.
[00:10:00.000 --> 00:10:07.000]   So on the Neuralink side, it's implanting into humans, pending FDA approval, all that kind of stuff.
[00:10:07.000 --> 00:10:09.000]   They're full steam ahead there.
[00:10:09.000 --> 00:10:17.000]   Tesla Autopilot, like he said in the podcast, solving level 4 full self-driving this year.
[00:10:17.000 --> 00:10:23.000]   I think he said, likely this year, 2022.
[00:10:23.000 --> 00:10:30.000]   Of course, I could talk for a long time, I probably will about each words in that sentence.
[00:10:30.000 --> 00:10:34.000]   Like what is level 4 exactly? What does solve exactly mean?
[00:10:34.000 --> 00:10:37.000]   And what are the sort of the stages of solution?
[00:10:37.000 --> 00:10:43.000]   Because one is the technological, two is the deployment and the human interactions, the human factor side of it.
[00:10:43.000 --> 00:10:46.000]   Three is the policy, like, is this going to get approved?
[00:10:46.000 --> 00:10:49.000]   Like, is NHTSA going to freak out? All those kinds of things.
[00:10:49.000 --> 00:10:55.000]   And then social acceptance of the technology, all that, you know, in interaction with vehicles that don't have Autopilot,
[00:10:55.000 --> 00:10:57.000]   other Tesla vehicles and then other vehicles in general.
[00:10:57.000 --> 00:11:03.000]   So solve is almost like, like Wittgenstein would lose his shit over the word solve.
[00:11:03.000 --> 00:11:07.000]   Like, you know, what does it exactly mean? And what does level 4 mean?
[00:11:07.000 --> 00:11:10.000]   Is it under certain geographic locations and so on?
[00:11:10.000 --> 00:11:16.000]   But the big point is that in 2022, there's going to be big leaps of improvement.
[00:11:16.000 --> 00:11:20.000]   And that is the way I hear that message. And there's full steam ahead there.
[00:11:20.000 --> 00:11:24.000]   So much exciting stuff going on. Most of it, which is already made public.
[00:11:24.000 --> 00:11:27.000]   And I don't know, I'm really excited as an AI person.
[00:11:27.000 --> 00:11:33.000]   And of course, as a person, you know, who grew up in the Soviet Union,
[00:11:33.000 --> 00:11:37.000]   will he shut up about the Soviet Union already? I'm sorry.
[00:11:37.000 --> 00:11:41.000]   I love my dad as a physicist. I love space exploration.
[00:11:41.000 --> 00:11:47.000]   To me, Starship and just the number of launches that are planned for 2022 on the SpaceX side,
[00:11:47.000 --> 00:11:52.000]   NASA and everybody else is just like pushing straight ahead into space,
[00:11:52.000 --> 00:11:58.000]   hopefully putting a human back on the moon and hopefully soon enough.
[00:11:58.000 --> 00:12:04.000]   Let me take that 20 second pause as well. Putting a human on Mars, maybe this decade.
[00:12:04.000 --> 00:12:08.000]   I mean, to me, that's exciting. I'll go. I'll be the first human.
[00:12:08.000 --> 00:12:14.000]   That's why I'm training with David Goggins, to be the first human on Mars.
[00:12:14.000 --> 00:12:21.000]   And my own New Year's resolutions in general, I've been working a lot on robots,
[00:12:21.000 --> 00:12:25.000]   but I haven't released anything yet. And this is for fun.
[00:12:25.000 --> 00:12:28.000]   This is not for the startup and the business side of things.
[00:12:28.000 --> 00:12:31.000]   This is just I love robots. I love legged robots.
[00:12:31.000 --> 00:12:36.000]   And I love exploring the problem human robot interaction, both in research
[00:12:36.000 --> 00:12:41.000]   and there's almost like philosophical art in movement.
[00:12:41.000 --> 00:12:46.000]   There's something that robots make us feel. And I want to understand that.
[00:12:46.000 --> 00:12:50.000]   I want to explore it together with people by shooting a bunch of videos with robots,
[00:12:50.000 --> 00:12:56.000]   having robots hang out with me in Austin in public, walking around with them, inspire people.
[00:12:56.000 --> 00:13:02.000]   If people are scared to just sort of use that fragility to try to understand where's the fear
[00:13:02.000 --> 00:13:04.000]   and try to educate people grounded in that.
[00:13:04.000 --> 00:13:10.000]   So I definitely want to build a bunch of robots. Do a bunch of difficult interviews.
[00:13:10.000 --> 00:13:15.000]   They're coming up. You know, I do see myself as an idiot.
[00:13:15.000 --> 00:13:27.000]   I do see myself as somebody who. Relative to.
[00:13:27.000 --> 00:13:36.000]   How little I know, any anything that I do know, even things I spent several years on just feel so minuscule.
[00:13:36.000 --> 00:13:44.000]   So I think I just lead with humility in these conversations, which I think can get me in trouble.
[00:13:44.000 --> 00:13:48.000]   But I would I would like to err on the side of humility and love.
[00:13:48.000 --> 00:13:56.000]   But at the same time. There's going to be a lot of people that criticize me, often rightfully so.
[00:13:56.000 --> 00:14:04.000]   And I have to walk gracefully through that fire, not not not let the ego flare up to where you start to pay.
[00:14:04.000 --> 00:14:07.000]   We start to be defensive and all those kinds of things.
[00:14:07.000 --> 00:14:10.000]   Instead, sort of calmly take the criticism, learn from it, grow from it.
[00:14:10.000 --> 00:14:17.000]   And I've already had a few in the space of coronavirus, a few difficult conversations, and I'll have several more.
[00:14:17.000 --> 00:14:22.000]   There's some other very difficult conversations coming up, some of them in Russian.
[00:14:22.000 --> 00:14:31.000]   So I've been also practicing Russian. I'll take if travel allows, I will take a trip to Russia for maybe two or three months.
[00:14:31.000 --> 00:14:43.000]   Take a take a journey of sorts to to explore the language, the people, the struggles, the history, the the future, the powerful and the brilliant.
[00:14:43.000 --> 00:14:52.000]   From the science and the technology world to the geopolitical world. And also Khabib.
[00:14:52.000 --> 00:14:57.000]   He's definitely going to be on the podcast, but not until I wrestle him.
[00:14:57.000 --> 00:15:03.000]   By the way, I love wrestling and there's going to be a bunch of wrestling videos coming out.
[00:15:03.000 --> 00:15:13.000]   I love Khabib. I love the Dagestanis. Vysotsky is definitely somebody I want to talk to in Russian.
[00:15:13.000 --> 00:15:18.000]   One of the greatest wrestlers, if not the greatest wrestlers of all time.
[00:15:18.000 --> 00:15:24.000]   Alexander Karelin. That's another part of my life that I just keep to the side.
[00:15:24.000 --> 00:15:30.000]   I just am inspired by sport. I'm a scientist first, but sport challenges the body.
[00:15:30.000 --> 00:15:34.000]   To me, science and philosophy challenges the mind. And I love doing both.
[00:15:34.000 --> 00:15:39.000]   And they both are a source of humility. I'm going to I'm still at MIT.
[00:15:39.000 --> 00:15:47.000]   I will teach. I will give a bunch of lectures there. I'll teach courses there in 2022.
[00:15:47.000 --> 00:15:52.000]   I really refuse to teach remotely. So there's I'll speak about this later.
[00:15:52.000 --> 00:16:00.000]   There's been a few challenges because of Omicron. So I may release a few lectures on video.
[00:16:00.000 --> 00:16:06.000]   But unfortunately, given how many people signed up to the MIT lectures, it's just an insane number of people.
[00:16:06.000 --> 00:16:10.000]   And MIT is very nervous about what's going to happen. They might be closing their doors.
[00:16:10.000 --> 00:16:19.000]   Harvard and Stanford is going remote. And given that situation, I think I would love to sort of hug people with open arms.
[00:16:19.000 --> 00:16:26.000]   And meet them and not be so concerned about masks and all those kinds of things.
[00:16:26.000 --> 00:16:31.000]   I would love to give the lecture when we open back up fully. And publishing papers.
[00:16:31.000 --> 00:16:36.000]   I want to continue doing research at MIT. I have so many incredible colleagues there.
[00:16:36.000 --> 00:16:41.000]   So many friends, so many people that inspire me. I still love MIT. I still love Boston.
[00:16:41.000 --> 00:16:51.000]   Most of the time I currently spend in Austin. Like I said, I challenge myself physically and mentally.
[00:16:51.000 --> 00:16:56.000]   We've been talking with David a lot. He's dealing with some injuries. I was dealing with some injuries.
[00:16:56.000 --> 00:17:00.000]   But we're getting close to 100%. And we're going to do something insane together physically.
[00:17:00.000 --> 00:17:06.000]   That was a precondition, I would say, for a podcast. I don't want to just talk to David Goggins on a podcast.
[00:17:06.000 --> 00:17:13.000]   You've got to do something crazy together first. And then do a podcast. Survive or die trying.
[00:17:13.000 --> 00:17:21.000]   Try. Okay, let's see. Have fun. Like what I'm doing here. I did a podcast with Tim Dillon.
[00:17:21.000 --> 00:17:27.000]   The Great, The Powerful. One of the greatest living comedians. Tim Dillon. That's part of having fun.
[00:17:27.000 --> 00:17:34.000]   And doing this is part of having fun. If you guys have questions about the Tim Dillon conversation, I'm happy to answer.
[00:17:34.000 --> 00:17:43.000]   He's just so awesome. And he's yet another way I humble myself. Because he makes fun of me. And I deserve all of it.
[00:17:43.000 --> 00:17:50.000]   And like Elon said, try to be useful to others. I really don't care about personal career success.
[00:17:50.000 --> 00:18:01.000]   About any kind of "success", financial or otherwise. I think about how can I build stuff. How can I do things that help others.
[00:18:01.000 --> 00:18:08.000]   One, it's just fun. And I think it also directs your mind in the proper direction.
[00:18:08.000 --> 00:18:13.000]   And in the end, love. Add a bit of love to the world.
[00:18:13.000 --> 00:18:20.000]   That's the "help others". I'm a big fan of helping people move. I like lifting heavy things.
[00:18:20.000 --> 00:18:28.000]   But in the end, the way I want to help others is just by adding love to their life in whatever way I can.
[00:18:28.000 --> 00:18:34.000]   Alright, that's it for New Year's Resolutions. I can say a lot more, but let me just answer a few questions.
[00:18:34.000 --> 00:18:40.000]   I wonder if I can just keep clicking on... Do these superchats disappear? I don't know what I'm doing.
[00:18:40.000 --> 00:18:47.000]   I don't know what I'm doing. What does it mean when there's different letters before the dollar sign?
[00:18:47.000 --> 00:18:59.000]   Okay, how do I make a superchat sticky? Wait, I'll just read it.
[00:18:59.000 --> 00:19:04.000]   This is not going to work, is it? I'm also slow at reading.
[00:19:04.000 --> 00:19:09.000]   This robot is operating at subpar performance.
[00:19:09.000 --> 00:19:22.000]   What's the most important book to you or top 10? Question from Joseph. Do you agree with Elon that the best way to learn something is to talk to people and read?
[00:19:22.000 --> 00:19:35.000]   I don't know. Hey guys, is that superchat visible on the YouTube stream? From Joseph? When I click on it?
[00:19:35.000 --> 00:19:43.000]   Loading, loading. I have a team of robots, all of which are superior to me. Nope, it's not appearing. I see the no.
[00:19:43.000 --> 00:19:51.000]   Wow, the internet works. No, thank you. Alright, how do I make it appear? Double click, put user in time.
[00:19:51.000 --> 00:20:03.000]   Put user in time. Report, add moderator. No. Double click. No. Put user in... Oh, timeout. I don't want to put Joseph in timeout.
[00:20:03.000 --> 00:20:11.000]   Alright, well, whatever. I'm just going to read it and we're going to have to deal with it. This boomer is going to have to read some manuals tonight.
[00:20:11.000 --> 00:20:16.000]   Yeah, my top books. I'll probably talk about this more in the future.
[00:20:16.000 --> 00:20:24.000]   I'm such a sucker for Animal Farm. I love Animal Farm. I've read it many, many, many, many times. It just connects to something deep.
[00:20:24.000 --> 00:20:36.000]   I love people that are able to, through minimum amount of words, convey something deeply honest about the human condition, about human nature, whether it's the dark side or the beautiful aspect.
[00:20:36.000 --> 00:20:44.000]   I love The Stranger by Camus. Despite what Michael Malice said in a recent conversation, I love The Plague by Camus as well.
[00:20:44.000 --> 00:21:03.000]   It's very relevant to today. Dostoevsky's The Idiot by a far my favorite Dostoevsky novel. It could be one of my favorite novels, but I don't usually recommend it because maybe you're not into memorizing 1,000 Russian names and keeping track of a bunch of weaving narratives.
[00:21:03.000 --> 00:21:20.000]   I just aspire to be philosophically somebody like the main character, which is Prince Mishkin, aka The Idiot. The naive nature of his optimism is something I aspire to, and a lot of people in the book criticize it.
[00:21:20.000 --> 00:21:35.000]   He's the one that says beauty will save the world, and the characters criticize that. I think it's unclear whether the naivety that he has is supposed to be positive or negative.
[00:21:35.000 --> 00:21:53.000]   That's the struggle of the book. To me, I would err on the side of the naive positivity, appreciation of beauty, and longing for love. I agree with Dilan very much that reading is a superpower.
[00:21:53.000 --> 00:22:14.000]   I've talked to Jim Keller a bunch of times, and every time I've talked to him, I've learned 10x more than I would ever learn about him in any other way. Engineering discussions with experts is just incredible.
[00:22:14.000 --> 00:22:35.000]   Are you a robot? Would you take no for an answer? For me, reading is definitely a shortcut to learning. I'm a huge believer in reading. There are so many different paths and trajectories you can take through the reading space.
[00:22:35.000 --> 00:23:02.000]   You can learn about human nature through reading history. You can read business books, which are full of cliches and advice books. But when you cut through all the bullshit, there are kernels of advice that can shake up your mind and truly help you discover yourself.
[00:23:02.000 --> 00:23:19.000]   Sorry, I get a little bit distracted every once in a while. There are also just technical books, or popular versions of technical books like something by Sean Carroll, or even sapiens, like looking at evolutionary biology view of life, or anything by Richard Dawkins.
[00:23:19.000 --> 00:23:41.000]   Those kinds of things give you another perspective on humanity, and somehow that kind of percolates down to your own life as well. Lex, maybe you can turn on the slow chat mode? That's one of the folks from our team. I don't even know how to do that, man.
[00:23:41.000 --> 00:23:55.000]   I'm barely hanging on here and I'm still scared shitless. Okay. Favorite book? I don't know, I keep changing. I would say The Idiot, number one. Animal Farm, number two.
[00:23:55.000 --> 00:24:08.000]   Right, so let me click on Super Chats.
[00:24:08.000 --> 00:24:22.000]   You know what, I'm just going to trust my team of incredible folks. I don't know if they want me to call them out by name. One of them is Russian, has a strong Russian accent. I'm not going to do a Russian accent.
[00:24:22.000 --> 00:24:30.000]   So sorry, they're paying attention to the Super Chats. They'll grab them.
[00:24:30.000 --> 00:24:38.000]   I'm getting some Russian emojis from them. All right, cool.
[00:24:38.000 --> 00:25:04.000]   Lessons from Elon. Matt Affronti asks, "Love all the work, Lex. Keep crushing it, brother." Thank you, man. "What is the biggest lessons you've learned through talking with Elon Musk?"
[00:25:04.000 --> 00:25:14.000]   As I take a 20 second silent pause. I apologize, I'm thinking.
[00:25:14.000 --> 00:25:34.000]   In many ways, don't listen to anybody when it contradicts the careful, rigorous, first principles, conclusions of your mind.
[00:25:34.000 --> 00:25:52.000]   So your parents, society, friends, loved ones, school, don't listen to anybody. They have learned the ways of the past. If you want to define the future, you have to think on your own and take big risks with the thoughts you take.
[00:25:52.000 --> 00:26:06.000]   It's not necessarily a lesson I learned from him through words, but through actions. Just the way we talk about anything, he refuses to be weighed down by the ways things were done in the past.
[00:26:06.000 --> 00:26:18.000]   That's a superpower. Listen to no one when it comes to following some kind of hunger to create the new thing that you have.
[00:26:18.000 --> 00:26:38.000]   It's not just about listening to the person, it's about spending time in that space around them.
[00:26:38.000 --> 00:26:48.000]   "What are your thoughts on the flaws of Elon Musk?"
[00:26:48.000 --> 00:26:58.000]   Elon's flaws. "Don't touch me, I'm crazy," says... I love the internet and your username, dear sir or madam.
[00:26:58.000 --> 00:27:08.000]   "What are your thoughts on Elon Musk's individual, aside from his career accomplishments?"
[00:27:08.000 --> 00:27:24.000]   He has flaws. He has many flaws. That's what makes us human. It's the Robin Williams from Good Will Hunting. That speech he makes about himself and his wife, that they're flawed.
[00:27:24.000 --> 00:27:36.000]   He tells that story about her farting in the night and she wakes herself up. I think that was improvised actually. That whole story just shows that's the good stuff.
[00:27:36.000 --> 00:27:46.000]   That's what makes us who we are, that's what we fall in love with. That's the kind of perturbation that results in progress.
[00:27:46.000 --> 00:28:00.000]   If you're perfect things, perfect people don't make progress. Fucked up people make progress. It's the whole Kerouac thing. It's the mad ones. The ones for me are the mad ones.
[00:28:00.000 --> 00:28:20.000]   I can list a bunch of flaws. The very thing I said that's the great advice, the flaw of being unwilling to fit in, which makes him difficult to talk to because he's constantly challenging the small talk of our daily existence.
[00:28:20.000 --> 00:28:38.000]   Love, of course. I talk about love so much. He's so focused on engineering problems that sometimes, like I asked him in several ways. I tried to ask him about love, romantic love, friendship and family.
[00:28:38.000 --> 00:28:52.000]   You could tell how uncomfortable he was with that. He said, "Now that is a truly peculiar question." I think is what he said. Then he went on to quote, "What is love? Baby, don't hurt me."
[00:28:52.000 --> 00:29:18.000]   I don't know if it's a flaw. To me, it's a flaw because allowing yourself to be fragile, to the ups and downs of attachment to others, to love, I think is truly fulfilling and makes you a better engineer and better entrepreneur.
[00:29:18.000 --> 00:29:36.000]   The problem is when you feel the world heavily, when you feel the connection to others, when that ultimately is lost or is damaged or is hurt, again, the ups and downs of love, that's going to really hurt.
[00:29:36.000 --> 00:29:56.000]   That pain is not productive in terms of launching rockets to space. I think one of the things that Elon is better than anybody I've ever met is whenever there's tragic events, whenever there's difficult events, whenever there's emergencies, he's able to think clearly and say, "Okay, well, this happened. What is the right next step to take to solve this problem?"
[00:29:56.000 --> 00:30:16.000]   It's not meandering about the negativity around, "Oh, why did this happen?" in terms of the unproductive why. It's the, "Oh, why did bad things happen to good people?" That kind of stuff. Nope. This happened. That's the way it is. What is the best thing we could do? Let's make that action.
[00:30:16.000 --> 00:30:25.000]   I can continue, but let's leave it there.
[00:30:25.000 --> 00:30:33.000]   Ultra marathons, plans on competing, any...
[00:30:33.000 --> 00:30:42.000]   Sorry, just so many questions. Plans on competing in any ultra marathons. I don't...
[00:30:42.000 --> 00:31:04.000]   Perhaps, but I really hate running. That's why I love running. I hate running. It tests my mind. I get on the road, and one mile in, all the demons I have, "Why aren't you having you done this and that and all the things that you said you're going to do, you told yourself you're going to do, you haven't done it yet. Why are you still single?
[00:31:04.000 --> 00:31:23.000]   Why are you... Why is your... Where are the robots? You love robots. Let's get them running around Austin." All the productivity questions, all that is just, "What are you doing with your life?" And then the questions of mortality, all that comes out one mile in. If we're being honest, it's a half a mile in.
[00:31:23.000 --> 00:31:40.000]   And so that process, that's why I love... I'm pooping, Lex. Congratulations, sir or madam. I congratulate you. I hope it goes well for you. That's why I both love and hate running. And so for me, the race itself is not important, the ultra marathon race.
[00:31:40.000 --> 00:31:59.000]   But David Goggins, whatever we do, whether it's on road, I don't want to do a treadmill thing with him. I just love nature. So I want to go out outside. Whatever we do, I think I can break him or break myself in the process.
[00:31:59.000 --> 00:32:19.000]   When I was out in Vegas doing pushups with him, I think I legitimately thought I could do more pushups in my drunk madness than David Goggins. So I'm excited for the possibility of facing him and running. Not really a competition with David, of course. It's a competition with myself and seeing how far I can go.
[00:32:19.000 --> 00:32:46.000]   The longest I've ever run is 22 miles in one take. I've done the 4x4x48, but one take is 22 miles. And that actually I had to quit because I didn't get enough salt and water. It's just I started shivering. And yeah, I want to see how far I can go, how much pain I can take. So definitely will happen this year. And we'll do a podcast before and after.
[00:32:46.000 --> 00:33:10.000]   Hey Lex, if you want to turn on slow mode, just go to settings, live chat, toggle on slow mode. I thought me speaking slowly is already activating slow mode. You get it? I don't know where the settings button is, bro. Okay, let's just leave it at this. We'll do slow mode next time if that's a beneficial thing.
[00:33:10.000 --> 00:33:23.000]   All right.
[00:33:23.000 --> 00:33:46.000]   David Fravor. Leah asks, you're amazing Lex. Love you. Love you too. Thanks for this interview. In interview number four, are you going to talk about David Fravor's UFOs? Thanks for the 42 question.
[00:33:46.000 --> 00:34:02.000]   I'm a little puzzled by you and your question, Leah27. But anyway, I will talk about UFOs a bunch more. I just want to, you know, I honestly want to talk to Bob Lazar. I haven't really reached out. He was interested. I like the human side of things too.
[00:34:02.000 --> 00:34:23.000]   It's the thing I'm interested with Alex Jones too. It's not so much the conspiracy theories and all those kinds of things. It's how does this affect your mind? Having these ideas in your head, how does it affect your mind? How are you able to still have compassion for other human beings? Still have an inkling of optimism about the world?
[00:34:23.000 --> 00:34:40.000]   And the same with Bob Lazar. David Fravor, probably we'll talk again. Alex, I forgot her name. I apologize. I'm so bad with names, but she's another pilot that saw what David saw. I'll definitely do a podcast with her.
[00:34:40.000 --> 00:34:56.000]   And in general, I just, right. In general, I just love, obviously I love UFOs. So it inspires me. I don't think a lot of people have a conversation about it. Like it's a cynical thing about government.
[00:34:56.000 --> 00:35:14.000]   But for me, I love UFOs because it inspires me of the possibilities of both the intelligent life that's out there, all the possible things we can understand about ourselves and about the world and about the universe from interacting with them, for searching for them, for trying to communicate with them.
[00:35:14.000 --> 00:35:24.000]   And then very practical engineering aspects of just knowing that something is possible. It would allow us to engineer propulsion systems that can move much faster.
[00:35:24.000 --> 00:35:31.000]   So on this topic, Lex Xylex asks, there's so many X's in this.
[00:35:31.000 --> 00:35:42.000]   Xylex asks, Lex, do you think Elon has witnessed any high forms of technology he cannot publicly disclose through SpaceX?
[00:35:42.000 --> 00:35:56.000]   It's possible. And it's also possible that I know the answer to this question. But if I told you, Xylex, I would have to kill you.
[00:35:56.000 --> 00:36:05.000]   Let me take a sip of this before I read a question about Jordan Peterson.
[00:36:05.000 --> 00:36:14.000]   Big fan of caffeine, caffeine all the way. The one drug I truly, truly appreciate and partake in.
[00:36:14.000 --> 00:36:20.000]   Vodka every once in a while, caffeine every day.
[00:36:20.000 --> 00:36:27.000]   Okay, Jordan Peterson, Scott McBlane asks, hey Lex, smiley face, will you ever have Jordan Peterson on the podcast?
[00:36:27.000 --> 00:36:32.000]   Thanks for all your work. You make my life better. Thank you, brother. Thank you, Scott.
[00:36:32.000 --> 00:36:41.000]   Yeah, definitely. I've talked to Jordan offline a bunch of times. We'll definitely do a podcast together. I think it'll be epic. There's no rush.
[00:36:41.000 --> 00:36:50.000]   I think my concern with Jordan always is to make sure that he's healthy, happy and just like all people.
[00:36:50.000 --> 00:36:56.000]   And he's had a difficult year. And I don't know, who cares about podcasts?
[00:36:56.000 --> 00:37:06.000]   Well being, health is more important than anything else. And I think he has a like a heck of a crazy tour coming up this year.
[00:37:06.000 --> 00:37:17.000]   I actually have tickets to see him. I'm sure he'll do a few podcasts. But you know, with a tour like that, I wish him Godspeed and the best of luck and just stay healthy.
[00:37:17.000 --> 00:37:27.000]   Stay focused. Stay optimistic. And just, I mean, he could do so much good in this world by thinking through the problems of the world.
[00:37:27.000 --> 00:37:36.000]   And walking again, gracefully through the fire. And I wish him the best of luck. I think we'll have a conversation unlike the others he's had.
[00:37:36.000 --> 00:37:41.000]   I think I'd like to have a very long one with him, three, four hours, probably several times in our lives.
[00:37:41.000 --> 00:37:51.000]   One, I wanted to be a psychiatrist. I'm fascinated by the psychology side of things. So a real psychology conversation. Carl Jung. I have trouble speaking.
[00:37:51.000 --> 00:38:06.000]   So on the psychology side, from Freud to Jung and all those kinds of things to the philosopher side, to the communist question of Gulags and Solzhenitsyn to Stalin to Hitler.
[00:38:06.000 --> 00:38:16.000]   It's like history, human nature, human condition discussion. I'm not interested in identity politics of the day. I'm not interested in that bickering.
[00:38:16.000 --> 00:38:25.000]   I let other people are much better than me at this and at most things, but this certainly. And wokeism, all those kinds of things.
[00:38:25.000 --> 00:38:35.000]   I'm not, I think those are the battles of the day that will pass. And what will remain are the same lessons of history that we can learn today by thinking about history.
[00:38:35.000 --> 00:38:45.000]   And to me, with Jordan Peterson, the interesting discussion is about communism, about what went wrong. Why? What can go wrong again?
[00:38:45.000 --> 00:39:00.000]   Also, the interesting tension is between the man's search for meaning, because for him, that journey, that search, in part goes through religious thought, religious exploration.
[00:39:00.000 --> 00:39:11.000]   And that's really interesting because I don't even know what religion and spirituality means. It's such a beautiful space.
[00:39:11.000 --> 00:39:20.000]   And I never liked sort of hardcore atheism or obviously hardcore religious thought.
[00:39:20.000 --> 00:39:30.000]   But there's something in the middle there in that gray area, in that fog of where many people find meaning.
[00:39:30.000 --> 00:39:39.000]   There's a lot to be discovered. And I love the conversation he had with Sam Harris about the topic, the tension, through the tension over that discussion, you could discover something new together.
[00:39:39.000 --> 00:39:59.000]   And that's actually the best of conversations. Jordan 15396, ah, that Jordan, asks, "What would you do with a week left to live?"
[00:39:59.000 --> 00:40:16.000]   I meditate on death a lot. So I often think I'm going to die today. I enjoy that. I'm truly happy that this live stream I could do with today and die right after. I'm happy.
[00:40:16.000 --> 00:40:35.000]   I can genuinely say that I prefer to not die mid-sentence. People can quote me on the last thing I said in the last stream. I hope that live stream wasn't me quoting the person that was pooping and complimenting on them.
[00:40:35.000 --> 00:40:51.000]   But other than that, I just, every day I contemplate if this is the last day of my life, am I happy? And the answer to that has been unequivocally yes for the longest time.
[00:40:51.000 --> 00:41:15.000]   So with a week left to live, I would probably spend it in silence with the people I love. Yeah.
[00:41:15.000 --> 00:41:31.000]   I would also spend it thinking, because unlike the thought experiment of dying today, this is reality. So it's going to hit even harder.
[00:41:31.000 --> 00:41:48.000]   I would see what are the thoughts, sort of introspect. What are the thoughts, possibly with the help of psychedelics. That would be interesting actually. DMT, definitely. Pretty Girl. Elon Musk says Pretty Girl. Fake Elon Musk says Pretty Girl.
[00:41:48.000 --> 00:42:00.000]   Pretty Girl and the Hood of a Cadillac. Yeah, that's the office song. Free Love, Freeway. You guys should check it out. It's the most ridiculous song.
[00:42:00.000 --> 00:42:11.000]   I definitely, probably with the Pretty Girl I love, hopefully I would be in a relationship at that point. But if I die today, there's plenty of people I love in my life. I would spend time with them.
[00:42:11.000 --> 00:42:27.000]   Sergey, who's on the team, he's the Russian guy, says the right answer is edit the fucking podcast. That's right, Sergey. Edit the podcast is what you would do when there's only one week left. That's called dedication. I love you, brother.
[00:42:27.000 --> 00:42:47.000]   Okay. I'll wrap up soon. So I had a few questions about Tim Dillon. Let me say I think there's a podcast coming out with Tim Dillon on the Tim Dillon show on Monday.
[00:42:47.000 --> 00:43:00.000]   So he said he came down to my place. We recorded a conversation together. And I'm a huge fan of his. I did a podcast. He was on the Lex podcast that I do. I really enjoyed that.
[00:43:00.000 --> 00:43:20.000]   I think the reason I wanted to do a conversation with him, first of all, he's a friend. He's somebody who inspires me. I disagree with him, obviously, on a lot of things. But he masterfully puts my ego in check and the ego of a ton of people.
[00:43:20.000 --> 00:43:38.000]   The powerful. And that's really important. And to do it with grace, with mastery of comedy, it's really good. I, in general, like I said on the podcast, smart people that act silly versus silly people that act smart.
[00:43:38.000 --> 00:44:02.000]   And again, I don't know if I'm smart, but I will always err on the side of the silly. And to me, just being silly, not taking myself seriously, not ever taking myself seriously, being able to take a joke is essential for to see clearly through the fog of all the uncertainty that is around us.
[00:44:02.000 --> 00:44:17.000]   It's easy to delude yourself to think you really understand things, that you can see the truth. You have to have humility that you will never be in possession of the truth. You can only get closer and closer. And that humility, to me, is an essential element of that.
[00:44:17.000 --> 00:44:38.000]   So the moment you start taking yourself seriously, you start liking the sound of your own voice, as I say on a freaking live stream. The moment you start to fall in love with yourself in a way that just deludes you is the moment you become arrogant and are no longer to be able to discover the truth.
[00:44:38.000 --> 00:44:57.000]   Again, Tim Dillon is essential for that. He was pretty rough on me in a few spots. I'm sure people are going to make fun of me, of the silly things I said on there, but I deserve it all. I will always deserve it. And bring it on, internet. That's why I love the internet. Hold truth to power.
[00:44:57.000 --> 00:45:18.000]   And I will always err on the side of silly. In fact, one of the things that I've been able to do more and more lately, and one of the things that Elon inspires me to do is be silly. Don't take yourself or the world seriously. Laugh. Laugh at the whole thing, at the whole absurdity of it. It'll be over before you know it.
[00:45:18.000 --> 00:45:33.000]   Fuck, it's going to be over before you know it. Who's your favorite comedian? Am Johnson asks, who is your favorite comedian? Oh, yeah, Sergey says it's on topic.
[00:45:33.000 --> 00:45:58.000]   I have so many, obviously you don't want to pick. Each one has... I just love comedy. There's so many amazing... it's really unfair. So I can pick a favorite book, I can pick a favorite song even. It'd be tough, but I can do it.
[00:45:58.000 --> 00:46:15.000]   With comedians, it's very difficult. So obviously since I'm appearing on Tim Dillon's show, he is by far the greatest comedian of all time. So we're really saying who's the number two. Because by far, Tim Dillon is the greatest comedian of all time.
[00:46:15.000 --> 00:46:31.000]   And the most valuable person of all time is Ben, his producer. Tim Dillon does zero work, contributes nothing to the show really. The most important person ever, arguably. So you have Gandhi and so on. But above that is Ben, the producer for the Tim Dillon show.
[00:46:31.000 --> 00:46:50.000]   Aside from that, obviously Joe Rogan has been a huge inspiration to me in a million ways. And I've talked about it endlessly. Mitch Hedberg in terms of one-liners, just fucking genius. Just... and we lose him too early.
[00:46:50.000 --> 00:47:15.000]   I'm gonna get emotional here. Louis CK, just like... the dark humor of Louis CK, unparalleled. I just... I mean, it reminds me of the Russian humor. It's the darkness, but done so masterfully that it brings out somehow an optimism.
[00:47:15.000 --> 00:47:27.000]   Mark Norman is actually an example of somebody like that. We just had a podcast together. He's got that Mitch Hedberg vibe, but he goes even darker, which I love.
[00:47:27.000 --> 00:47:43.000]   Yeah, and I think Norm MacDonald, somebody... so there's like stand-up comedy and there's what those stand-up comics do outside of that. Because you can't just take in one. Norm MacDonald is just a genius.
[00:47:43.000 --> 00:48:06.000]   Somebody actually made a comment about the Michael Malice conversation about Norm MacDonald. Maybe I can try to find the quote. He tweeted this in 2018. God damn it. Like, just the grace with which he left this world, telling no one. The genius.
[00:48:06.000 --> 00:48:24.000]   Anyway, he tweeted, "The idiot sees the world as good versus evil. The cynic sees the world as evil versus evil. The truth that no one seems able to see is that the world is and always has been a battle of good versus good."
[00:48:24.000 --> 00:48:39.000]   Norm MacDonald, ladies and gentlemen. So the brilliance of that statement is that... I mean, the idiot is a word I like because I think it fills me with humility, so setting that aside.
[00:48:39.000 --> 00:48:55.000]   But we often frame things, you know, when we beat the drums of war, it's good versus evil. We're the good guys and we have to fight the words of the evil, the actions of the evil, the Nazis, the terrorists, whatever.
[00:48:55.000 --> 00:49:11.000]   You can go on. And those drums of war are beating now with Russia, with China. And again, I think we should lead with humility and compassion first, even in the face of atrocities.
[00:49:11.000 --> 00:49:21.000]   Anyway, the cynic just gives up and saying it's basically the powerful, the evil versus evil, the power centers of the world battling each other.
[00:49:21.000 --> 00:49:35.000]   But I think Norm is absolutely correct that it is good versus good because the truth behind that statement is that each of the individual centers of power and the leaders think that they're doing the right thing for the world.
[00:49:35.000 --> 00:49:41.000]   Hitler thought he was doing the good, the right thing for the world. Stalin thought he was doing the good, the right thing for the world.
[00:49:41.000 --> 00:49:50.000]   We Americans, when we go to war, think we're doing the right thing. Israel-Palestine conflict, both sides think they're doing the good thing for the world.
[00:49:50.000 --> 00:50:04.000]   It's good versus good. And all the atrocities of the world, I think, have been committed in part as a battle of good versus good.
[00:50:04.000 --> 00:50:24.000]   And that's the tragic, the difficult aspect that we have to acknowledge about human nature, is that all of us think we're the good guys and we're doing the good thing. But we have to have the humility to question, are we truly doing the good thing?
[00:50:24.000 --> 00:50:33.000]   All right, maybe a couple more questions and I'll cut it off at an hour and we'll do this again another time.
[00:50:33.000 --> 00:50:37.000]   Would you get drunk with Elon? How do you know it hasn't already happened?
[00:50:37.000 --> 00:50:41.000]   A conversation with a historical figure.
[00:50:41.000 --> 00:50:50.000]   Emkata7 asks, "If Elon could talk to one person in the past for one hour, who would that person be? The same goes for you, Lex."
[00:50:50.000 --> 00:51:01.000]   So, by the way, I don't know how to do this live stream thing. And I'm sure Elon and folks like that would join live streams like these for a few minutes.
[00:51:01.000 --> 00:51:11.000]   I don't want to take up a long time. That's better for a long-form podcast. But it would be fun to have Elon roll in for like 5-10 minutes just to do some fun stuff.
[00:51:11.000 --> 00:51:23.000]   Elon, Joe Rogan, Tim Dillon even. I love that idea. Just roll in. Michael Malice, like literally he lives close to me. He could be under the table right now.
[00:51:23.000 --> 00:51:26.000]   And you wouldn't know.
[00:51:26.000 --> 00:51:34.000]   So I definitely want to do that in the future. I just have to figure out how to pull, how to bring in guests. I barely know what I'm doing with this live stream.
[00:51:34.000 --> 00:51:42.000]   So anyway, "If Elon could talk to one person in the past for one hour, who would that person be? The same goes for you, Lex."
[00:51:42.000 --> 00:51:49.000]   So he actually answered this similar question on a recent podcast he had. We talked about this also offline.
[00:51:49.000 --> 00:52:04.000]   I think for him it's Albert Einstein, Isaac Newton, all those kinds of almost engineering people. I get it. I get it.
[00:52:04.000 --> 00:52:17.000]   For me, in that vein, it would be Alan Turing probably. There's so little content from him, relatively speaking, that I would like to talk to Alan Turing for an hour.
[00:52:17.000 --> 00:52:21.000]   But then again, an hour is not enough. It's got to be a weekend because we got to get drunk.
[00:52:21.000 --> 00:52:28.000]   Richard Feynman is a good example. Somebody I would really enjoy the hell out of that hour, but I wouldn't get new information. It would just be fun.
[00:52:28.000 --> 00:52:33.000]   So is it about having fun or is it about getting new information?
[00:52:33.000 --> 00:52:36.000]   "Are you single?" Lex, yes, I am, unfortunately.
[00:52:36.000 --> 00:52:43.000]   Nikola Tesla, no. I would err on the side of evil. That's going to be a clip taken out of context.
[00:52:43.000 --> 00:52:55.000]   I would talk to somebody that... I would probably talk to Hitler. I would probably talk to Hitler.
[00:52:55.000 --> 00:53:05.000]   So the problem is it's a German thing. If he somehow magically could speak English or Russian, because I don't speak German, so it would be lost in translation.
[00:53:05.000 --> 00:53:26.000]   And so then Stalin. Stalin in early... when Lenin was still alive. Maybe doing a room together with Lenin and Stalin to understand what is in the mind of the people that led to the suffering, the death of tens of millions and the suffering of hundreds of millions.
[00:53:26.000 --> 00:53:41.000]   What is this? Because I feel like if I talk to them and take it back to the present time, the lessons will reverberate in a way that I'll be able to help prevent it in a way that I can't just by reading their works.
[00:53:41.000 --> 00:53:46.000]   I feel like stuff from Einstein, all those kinds of things are captured within their written work.
[00:53:46.000 --> 00:54:05.000]   Some of these impactful leaders that caused suffering in the world, I think most of their evil is not put down on paper. Chairman Mao, yeah. Genghis Khan, sure. All those are interesting.
[00:54:05.000 --> 00:54:13.000]   But Richard Feynman, Alan Turing. Richard Feynman, Alan Turing. Just because I can update them on the whole neural networks.
[00:54:13.000 --> 00:54:38.000]   Richard Feynman, Alan Turing, and Einstein in a Tesla plaid with FSD autopilot flooring it. I want to see the look on Turing's face.
[00:54:38.000 --> 00:54:46.000]   All of their faces. But Turing's face, this is neural networks. This is AI, motherfucker.
[00:54:46.000 --> 00:54:59.000]   He would be proud. Although he thought we're going to solve intelligence by year 2000. Anyway, he'd be kind of impressed by the whole thing.
[00:54:59.000 --> 00:55:11.000]   And Einstein would be disappointed. You know what? If Einstein's in the car, I'm also going to stop by in that Tesla plaid and pick up Eric Weinstein on the way.
[00:55:11.000 --> 00:55:20.000]   I want to have those two have a conversation. I feel like they'd figure something out. Like, why haven't we come up with a theory of everything yet?
[00:55:20.000 --> 00:55:35.000]   And make it a podcast. This is getting way too exciting. Final question. Let's see. What should we make the final question?
[00:55:35.000 --> 00:55:50.000]   Would you talk to Jesus? Yes. Jesus. Let's say... Maybe one more question before the final question.
[00:55:50.000 --> 00:56:08.000]   Oh, I see a good final question. Non-final question. Second to last question. From Paulo Turao. Who would you want most to have on your podcast in 2022?
[00:56:08.000 --> 00:56:22.000]   So, I think the names like Putin, Elon, again, Barack Obama, Donald Trump. These are all people that fascinate me.
[00:56:22.000 --> 00:56:32.000]   I would also love to talk to the chairman, the president of China. There's a lot of people I would like to talk to of that level.
[00:56:32.000 --> 00:56:46.000]   Yes, Guguru Pearlman and so on. But I think who I want to be on the podcast, it takes it back to that person I talked to.
[00:56:46.000 --> 00:56:56.000]   I think it was on Memorial Day. I had a conversation with a guy. He said he was a fan. He's wearing American flags everywhere.
[00:56:56.000 --> 00:57:09.000]   He said, "I'm a fan of the podcast. I listen to you. I listen to Joe. You guys talk to some of the most brilliant people, some of the funniest people, and just these celebrities and so on.
[00:57:09.000 --> 00:57:30.000]   Why don't you ever talk to us regular folk?" That stuck with me. I'd like to talk to "regular folk." What Tim Dillon made fun of me for saying, "I think I'm a simple man."
[00:57:30.000 --> 00:57:44.000]   I'd like to talk to other simple men and women because they're not that simple. They're not regular folk. They're not less special. They're as special.
[00:57:44.000 --> 00:57:51.000]   They have a story, and I want to learn about those stories. That's what I want to do more in 2022.
[00:57:51.000 --> 00:58:00.000]   Final question from Andre. All right. We'll do this again. I'm really, really sorry. I don't know what the heck I'm doing.
[00:58:00.000 --> 00:58:10.000]   I had this idea real quick before I read the final question. I love Skyrim. I love video games in general. I don't get a chance to play them, but I love Skyrim.
[00:58:10.000 --> 00:58:23.000]   I saw somebody had this video where they just walk around Skyrim for a couple hours, just enjoying nature. I would love that.
[00:58:23.000 --> 00:58:36.000]   I would just walk around, maybe answer some questions, but just the calmness of that. I feel that fits. That's a place where I could be happy in the digital space, is Skyrim.
[00:58:36.000 --> 00:58:42.000]   Just to take a little stroll in the woods. A Walk in the Woods by Bill Bryson.
[00:58:42.000 --> 00:58:50.000]   Oh, and another person. You know who I'd really want to have on the podcast? This comes back. Okay, I'll put it out there.
[00:58:50.000 --> 00:58:56.000]   Definitely people with great stories, but not celebrities, just regular folk.
[00:58:56.000 --> 00:59:09.000]   But if there is one quote unquote celebrity I would love to talk to, not Alex Jones. Alex. Love Alex. Send him all my love. Maybe one day. We'll see.
[00:59:09.000 --> 00:59:18.000]   I would say Satoshi Nakamoto.
[00:59:18.000 --> 00:59:28.000]   Yeah, Satoshi. Yes, Magnus Carlsen, all those people. I would love to somehow definitively...
[00:59:28.000 --> 00:59:36.000]   At least I know that I'm talking to him or her or them. Somehow I would know for sure.
[00:59:36.000 --> 00:59:42.000]   And maybe it would have to be blurred out, all those kinds of things. I would love to...
[00:59:42.000 --> 00:59:49.000]   To pierce the veil of anonymity, at least for me. To peek behind the curtain.
[00:59:49.000 --> 00:59:54.000]   For no reason. I would tell nobody. I would take that to my death.
[00:59:54.000 --> 00:59:58.000]   I don't know how that's possible, but I'm going to put that out there. Okay?
[00:59:58.000 --> 01:00:04.000]   As a thing that I would love to do. There's something I just deeply appreciate about...
[01:00:04.000 --> 01:00:13.000]   The humility and the power of anonymity, of releasing a technology that can change the world and still not putting your name publicly behind it.
[01:00:13.000 --> 01:00:19.000]   Yeah, it's like Banksy.
[01:00:19.000 --> 01:00:25.000]   Yeah, I would love to talk to him. Anyway, last question from Andre.
[01:00:25.000 --> 01:00:34.000]   That'd be funny if it was Andre Karpathy. Are we living in a simulation?
[01:00:34.000 --> 01:00:43.000]   It's a good question. The answer is yes. And it's powered by love.
[01:00:43.000 --> 01:00:48.000]   I love you all. This was really fun. I hope to do it again soon. Thank you so much.
[01:00:48.000 --> 01:00:53.520]   Thanks for watching.

