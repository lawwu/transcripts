
[00:00:00.000 --> 00:00:06.040]   The following is an AMA episode where I answer a few questions that folks asked on Patreon,
[00:00:06.040 --> 00:00:08.720]   YouTube, and other social networks.
[00:00:08.720 --> 00:00:14.240]   I'll try to do these episodes on occasion if it's of interest to anyone at all.
[00:00:14.240 --> 00:00:16.840]   Quick mention of our sponsors.
[00:00:16.840 --> 00:00:24.400]   Brooklyn and Sheets, Indeed Hiring website, ExpressVPN, and Theragun muscle recovery device.
[00:00:24.400 --> 00:00:30.480]   So the choice is sleep, employment, privacy, or muscle recovery.
[00:00:30.480 --> 00:00:31.480]   Choose wisely my friends.
[00:00:31.480 --> 00:00:38.400]   And if you wish, click the sponsor links below to get a discount and to support this podcast.
[00:00:38.400 --> 00:00:43.440]   And now, on to the questions and the answers.
[00:00:43.440 --> 00:00:47.840]   The question is, Lex, I'm a young man that has battled with depression.
[00:00:47.840 --> 00:00:53.160]   Do you think when trying to develop a human-like AI, we will reach a stumbling point where
[00:00:53.160 --> 00:00:58.360]   the AI themselves suffer from depression and other complex mental issues?
[00:00:58.360 --> 00:01:03.240]   Do you think it will be a simple fix like rewriting a piece of code or a new patch or
[00:01:03.240 --> 00:01:04.360]   update?
[00:01:04.360 --> 00:01:09.880]   Or maybe when trying to create something human-like with high fidelity, you need to leave in the
[00:01:09.880 --> 00:01:16.400]   possibility of the AI suffering from such complex mental issues that a human can.
[00:01:16.400 --> 00:01:22.680]   What are your thoughts generally and philosophically about AI suffering from depression?
[00:01:22.680 --> 00:01:30.040]   - I think that suffering is a deep fundamental property of consciousness.
[00:01:30.040 --> 00:01:32.920]   I would like to probably say quite a bit about depression.
[00:01:32.920 --> 00:01:38.720]   I have friends who suffer from depression, but that's for another time.
[00:01:38.720 --> 00:01:42.080]   That's for when we talk about depression in humans.
[00:01:42.080 --> 00:01:48.560]   I think depression is just one flavor of suffering that is part of the human condition.
[00:01:48.560 --> 00:01:58.600]   I see it as a kind of dark side street on the path to intelligence.
[00:01:58.600 --> 00:02:04.080]   In terms of robot suffering, if we were to create systems that are truly intelligent
[00:02:04.080 --> 00:02:09.560]   in the way that they're able to interact in intelligent and deeply meaningful ways with
[00:02:09.560 --> 00:02:14.880]   other humans, it's going to have many of the properties, many of the characteristics of
[00:02:14.880 --> 00:02:17.880]   the human condition, of the full human experience.
[00:02:17.880 --> 00:02:19.840]   I think depression is part of that.
[00:02:19.840 --> 00:02:25.720]   There's of course a part in us humans that longs to remove all that is cruel in this
[00:02:25.720 --> 00:02:27.240]   world.
[00:02:27.240 --> 00:02:33.920]   That's why people that believe in God, often the biggest question is of why does God allow
[00:02:33.920 --> 00:02:36.360]   there to be suffering in the world?
[00:02:36.360 --> 00:02:44.160]   There's this longing to understand why is there so much unfairness in this world?
[00:02:44.160 --> 00:02:50.160]   Depending on that, there's an inclination to then in our systems engineer something
[00:02:50.160 --> 00:02:56.120]   that is void of those things that we cannot understand why that's part of the human condition.
[00:02:56.120 --> 00:03:01.600]   But I think it is intricately part of the experience that is to be human.
[00:03:01.600 --> 00:03:07.160]   I think if we were to build intelligent systems that are interacting with humans, there has
[00:03:07.160 --> 00:03:12.440]   to be in some ways properties of consciousness baked in.
[00:03:12.440 --> 00:03:17.000]   If we were to have properties of consciousness baked in, we have to have the full mystery
[00:03:17.000 --> 00:03:21.520]   and uncertainty of the human experience, which yes, includes all the different flavors of
[00:03:21.520 --> 00:03:25.520]   suffering of which depression is part.
[00:03:25.520 --> 00:03:31.120]   I think the yin and the yang in all of its versions, the ups and downs of moods, but
[00:03:31.120 --> 00:03:39.640]   also the more rational, intellectual interpretations of different concepts that are less dramatic,
[00:03:39.640 --> 00:03:41.400]   all have to oscillate back and forth.
[00:03:41.400 --> 00:03:46.400]   I think that's where the interesting aspect of interactions happens.
[00:03:46.400 --> 00:03:50.280]   Just like when I have conversations in the podcast, the interesting stuff happens when
[00:03:50.280 --> 00:03:55.280]   there's disagreements, when there's a bit of turmoil, when there's a push and pull,
[00:03:55.280 --> 00:04:00.520]   when there's a changing of minds, or even just a morphing of your own opinions about
[00:04:00.520 --> 00:04:01.960]   something, your own thoughts.
[00:04:01.960 --> 00:04:03.240]   I think that's part of it.
[00:04:03.240 --> 00:04:10.680]   So I really do think all of that mess of humanity has to be engineered in into AI systems that
[00:04:10.680 --> 00:04:15.680]   are interacting with humans and are trying to create meaningful interactions with those
[00:04:15.680 --> 00:04:16.680]   humans.
[00:04:16.680 --> 00:04:21.280]   There's of course a huge amount of AI systems that are going to be more intelligent than
[00:04:21.280 --> 00:04:23.280]   humans at particular tasks.
[00:04:23.280 --> 00:04:26.640]   Those do not need to have those properties of the human experience, like suffering and
[00:04:26.640 --> 00:04:28.200]   all those kinds of things.
[00:04:28.200 --> 00:04:34.640]   But for the ones that move among us, I think unfortunately depression has to be part of
[00:04:34.640 --> 00:04:38.440]   the experience, or the possibility of depression has to be part of the experience.
[00:04:38.440 --> 00:04:46.280]   Of course I tend to focus on the positive aspects of the human experience, like love,
[00:04:46.280 --> 00:04:50.480]   beauty, joy, all those kinds of things.
[00:04:50.480 --> 00:04:52.980]   But it's the yin and the yang.
[00:04:52.980 --> 00:04:54.560]   They go together.
[00:04:54.560 --> 00:04:58.680]   They're lifelong partners, unfortunately, I think.
[00:04:58.680 --> 00:05:02.340]   Now of course all of this is just hypothesis, and most of my answers to all of these questions
[00:05:02.340 --> 00:05:04.640]   are going to be just my own thoughts.
[00:05:04.640 --> 00:05:09.000]   But I am thinking about all of this from an engineering perspective, and maybe I'll have
[00:05:09.000 --> 00:05:16.280]   more to say in the future about how we actually build these kinds of things into our AI systems
[00:05:16.280 --> 00:05:18.840]   that interact with humans.
[00:05:18.840 --> 00:05:19.840]   Thanks for the great question.
[00:05:19.840 --> 00:05:20.840]   It's a tough one.
[00:05:20.840 --> 00:05:26.200]   The question is, "Lex, I was wondering if you would be willing to talk about your immigrant
[00:05:26.200 --> 00:05:27.200]   experience.
[00:05:27.200 --> 00:05:32.880]   I myself started off as an international student studying and working in America.
[00:05:32.880 --> 00:05:38.920]   Not from Russia, I'm from India, but there was a constant push and pull that I experienced
[00:05:38.920 --> 00:05:40.640]   given my life circumstance.
[00:05:40.640 --> 00:05:44.160]   I would be curious to hear how you assimilated.
[00:05:44.160 --> 00:05:46.720]   Do you feel like you belong, et cetera?
[00:05:46.720 --> 00:05:49.560]   Thank you for the AMA."
[00:05:49.560 --> 00:05:51.760]   Your statement's about, "Do you feel like you belong?"
[00:05:51.760 --> 00:05:54.080]   Hit hard for some reason.
[00:05:54.080 --> 00:06:00.040]   Maybe it's because of late at night, maybe because I'm a bit over-caffeinated.
[00:06:00.040 --> 00:06:07.680]   Maybe what pops to mind to focus on is the aspect of loneliness, the aspect of belonging.
[00:06:07.680 --> 00:06:14.680]   I think a lot of us in the early teenage years go through that process of feeling like an
[00:06:14.680 --> 00:06:17.400]   outsider, an outcast of different kinds.
[00:06:17.400 --> 00:06:23.120]   I think it hit me the hardest personally because I was a popular kid in Russia, and when we
[00:06:23.120 --> 00:06:27.960]   moved here, I went to the opposite of being popular.
[00:06:27.960 --> 00:06:32.080]   Being like that, I felt like an outcast.
[00:06:32.080 --> 00:06:38.080]   The place I moved to in America had more of an emphasis, maybe it's a cultural thing,
[00:06:38.080 --> 00:06:43.760]   of emphasizing material possessions over two things that were deeply meaningful to me,
[00:06:43.760 --> 00:06:50.920]   which is human connection, like friendship, and also knowledge, like mathematics and scientific
[00:06:50.920 --> 00:06:53.240]   discovery, all those kinds of things.
[00:06:53.240 --> 00:06:58.080]   It's just the emphasis of what was valued was different, and that for me was a catalyst
[00:06:58.080 --> 00:07:02.560]   to feel like a total outcast, as opposed to being this person who looks out into the world
[00:07:02.560 --> 00:07:05.520]   and enjoys the beauty of the world.
[00:07:05.520 --> 00:07:11.640]   I went to this brooding phase of, first of all, learning the English language, but starting
[00:07:11.640 --> 00:07:14.680]   to read books, more philosophical books.
[00:07:14.680 --> 00:07:18.240]   The first one I remember reading in English was The Giver.
[00:07:18.240 --> 00:07:21.320]   That sort of helped me start thinking about this world.
[00:07:21.320 --> 00:07:30.600]   I was so fortunate to be so in love with people for so long and have close friends in Russia
[00:07:30.600 --> 00:07:39.480]   that I didn't notice in my childhood how deeply alone we all are.
[00:07:39.480 --> 00:07:46.320]   For me, the immigrant experience involved in a small way, at least the first, realizing
[00:07:46.320 --> 00:07:55.320]   that hard human truth that we all are born alone, live alone, die alone.
[00:07:55.320 --> 00:08:03.360]   Even when we're in the arms of somebody we love, we're still somehow fundamentally alone
[00:08:03.360 --> 00:08:13.280]   with our thoughts, with our hopes, with our fears, trapped in this conscious meat vessel
[00:08:13.280 --> 00:08:15.440]   between our ears.
[00:08:15.440 --> 00:08:23.480]   I think the immigrant experience for me was the catalyst to realizing and being terrified
[00:08:23.480 --> 00:08:31.960]   and also liberated by the idea that I'm alone in this world.
[00:08:31.960 --> 00:08:38.200]   At the same time was the realization that this beautiful feeling I felt from the connection
[00:08:38.200 --> 00:08:49.560]   to other humans was this gift that took me away from this dark realization.
[00:08:49.560 --> 00:08:58.320]   It's almost that love is a kind of escape from the reality of life, from the muck of
[00:08:58.320 --> 00:09:00.800]   life.
[00:09:00.800 --> 00:09:05.120]   The journey began in that way, to think about this world in this way, both the burden of
[00:09:05.120 --> 00:09:13.480]   being alone coupled with the frequent escape from that feeling by being lost in the company
[00:09:13.480 --> 00:09:16.800]   of friends, loved ones.
[00:09:16.800 --> 00:09:22.640]   Early on, coupled with this love of the human mind and curiosity about the human mind was
[00:09:22.640 --> 00:09:27.760]   the love of programming and actually building little programs and engineering systems, of
[00:09:27.760 --> 00:09:30.320]   course, building robots in college and so on.
[00:09:30.320 --> 00:09:39.160]   I think the gift of the immigrant experience of feeling like the outcast was the love of
[00:09:39.160 --> 00:09:45.640]   experiencing the deep connection with others, like a deep appreciation of it when it's there.
[00:09:45.640 --> 00:09:51.440]   I guess because it was taken away, because I was ripped out of it through moving here,
[00:09:51.440 --> 00:09:56.560]   I got to really appreciate it and start becoming cognizant of it to where I can start looking
[00:09:56.560 --> 00:10:00.000]   for it and being more grateful when I do have it.
[00:10:00.000 --> 00:10:05.960]   At the same time, a kind of curiosity started boiling up of the perspective on artificial
[00:10:05.960 --> 00:10:11.000]   intelligence systems from that kind of longing for a connection.
[00:10:11.000 --> 00:10:17.680]   As opposed to looking at robots or AI systems or even just programs that accomplish a particular
[00:10:17.680 --> 00:10:25.560]   task, can these programs accomplish the same richness of task and richness of experience
[00:10:25.560 --> 00:10:28.800]   that I came to appreciate as a human being?
[00:10:28.800 --> 00:10:38.520]   When I talk about love, there's echoes of that in my longing of the kind of experiences
[00:10:38.520 --> 00:10:45.520]   I would like to create in artificial intelligence systems that was born out of the immigrant
[00:10:45.520 --> 00:10:54.760]   experience of the loss of childlike innocence experience, of all of it combined, of starting
[00:10:54.760 --> 00:10:59.640]   to read books and thinking deeply about this world experience, all of that coupled in.
[00:10:59.640 --> 00:11:08.160]   I really think sometimes, unfortunately, the first step of deep gratitude is loss.
[00:11:08.160 --> 00:11:14.000]   So for me, I lost quite a bit during that time, and through that loss, I was able to
[00:11:14.000 --> 00:11:18.400]   discover the things that I truly appreciate about life.
[00:11:18.400 --> 00:11:21.480]   So let me leave it at that.
[00:11:21.480 --> 00:11:27.880]   Question is, if you were able to ask an alien some questions, what would they be?
[00:11:27.880 --> 00:11:33.600]   This is a really good question, and I find it to be actually a really good thought experiment.
[00:11:33.600 --> 00:11:38.440]   Let me put out some candidate questions out there and see what sticks.
[00:11:38.440 --> 00:11:45.520]   So first I'll probably ask for advice for the human species as a whole, for our civilization,
[00:11:45.520 --> 00:11:55.840]   of what we might do to survive and prosper for a long time to come, assuming the alien
[00:11:55.840 --> 00:12:01.600]   is from a civilization that's far older than ours or far wiser.
[00:12:01.600 --> 00:12:07.040]   I think there could be some really interesting, clear statements about the things we're doing
[00:12:07.040 --> 00:12:11.560]   here on Earth that are getting us into trouble from an alien perspective.
[00:12:11.560 --> 00:12:17.280]   So I think that's the number one thing, and maybe I'll bring up along those lines, bring
[00:12:17.280 --> 00:12:20.520]   up questions of great filters.
[00:12:20.520 --> 00:12:26.440]   If you look at the history of your civilization, when did you almost destroy the entirety of
[00:12:26.440 --> 00:12:27.440]   your species?
[00:12:27.440 --> 00:12:32.320]   It would be informative from a historical perspective to see.
[00:12:32.320 --> 00:12:37.320]   For us, it's currently the nuclear age and the few moments in the history that could
[00:12:37.320 --> 00:12:40.160]   have resulted in an all-out nuclear war.
[00:12:40.160 --> 00:12:47.720]   It'd be interesting to see if they mentioned something about AGI, something about viruses
[00:12:47.720 --> 00:12:52.600]   or wars or just things that we don't even think about.
[00:12:52.600 --> 00:12:57.940]   So I guess question number one would be some basic life advice, hoping that this alien
[00:12:57.940 --> 00:13:04.800]   is a Naval type character who can, in a crisp, short way, give some profound advice.
[00:13:04.800 --> 00:13:10.960]   Second, I would probably ask, now this is a very selfish conversation because it's just
[00:13:10.960 --> 00:13:15.760]   following along the things on top of my head that follow my curiosity.
[00:13:15.760 --> 00:13:21.320]   I would ask about the difference between their civilization and ours.
[00:13:21.320 --> 00:13:28.920]   I would ask whether they have some of these things that make us human, like love.
[00:13:28.920 --> 00:13:31.320]   Do you guys have love where you come from?
[00:13:31.320 --> 00:13:34.560]   Do you have death, mortality?
[00:13:34.560 --> 00:13:40.320]   I suspect it's possible to have mortality not even be a concept that makes any sense
[00:13:40.320 --> 00:13:45.560]   to an alien species, that of course everybody's immortal and there might be some kind of enforced
[00:13:45.560 --> 00:13:49.120]   selection mechanism, like evolution in general.
[00:13:49.120 --> 00:13:57.080]   I would ask about consciousness, try to tease apart the question of this thing of subjective
[00:13:57.080 --> 00:14:06.480]   experience, is this some kind of self-centered, weird, over-dramatized quirk of evolution
[00:14:06.480 --> 00:14:11.880]   that we have that's not actually special at all and then we make a kind of big deal about
[00:14:11.880 --> 00:14:17.840]   it, that's some kind of useful feature of our brain to think of ourselves as individuals
[00:14:17.840 --> 00:14:19.840]   that's completely silly.
[00:14:19.840 --> 00:14:25.720]   It'd be interesting to try to tease apart whether they have consciousness and what form
[00:14:25.720 --> 00:14:32.080]   their intelligence takes that is distinct from consciousness in the way that we think
[00:14:32.080 --> 00:14:37.200]   of humans as being conscious entities that are also able to do intelligent things.
[00:14:37.200 --> 00:14:40.600]   Are those intricately connected, are those separate?
[00:14:40.600 --> 00:14:46.380]   It'd be interesting to sort of tease that apart of how their alien minds work.
[00:14:46.380 --> 00:14:52.160]   So that includes intelligence, consciousness, love, and death, all the greatest hits.
[00:14:52.160 --> 00:14:54.680]   Okay, then I would probably go to physics.
[00:14:54.680 --> 00:14:57.240]   Of course, you gotta ask about physics.
[00:14:57.240 --> 00:15:05.040]   I would look into the alien's eyes, if they have eyes, and try to determine if we can
[00:15:05.040 --> 00:15:10.040]   actually even find the same language of mathematics of physics of sciences.
[00:15:10.040 --> 00:15:16.720]   In general, I would probably ask about the big mysteries of physics and science of what's
[00:15:16.720 --> 00:15:19.040]   outside our universe.
[00:15:19.040 --> 00:15:22.240]   Why is there something rather than nothing?
[00:15:22.240 --> 00:15:23.780]   Why is there stuff?
[00:15:23.780 --> 00:15:26.920]   And what's outside the stuff we think of as stuff?
[00:15:26.920 --> 00:15:29.440]   So like what's outside the universe?
[00:15:29.440 --> 00:15:34.200]   I'd be hesitant to ask the why questions, but I'll try a few out to see maybe there
[00:15:34.200 --> 00:15:39.560]   is a good answer to the why questions of like, why did it start?
[00:15:39.560 --> 00:15:42.480]   Like why is there something rather than nothing?
[00:15:42.480 --> 00:15:46.960]   Then I would probably ask slightly more detailed about what's the universe made of?
[00:15:46.960 --> 00:15:50.840]   What's up with this dark matter and dark energy stuff?
[00:15:50.840 --> 00:15:54.160]   What are the basic building blocks of reality?
[00:15:54.160 --> 00:15:58.560]   And what are the laws of physics that govern that reality?
[00:15:58.560 --> 00:16:04.080]   So I would of course ask, kind of sneak in there just like casually, can you maybe give
[00:16:04.080 --> 00:16:06.400]   a few hints of how to unify?
[00:16:06.400 --> 00:16:12.920]   First of all, are we on the right track in terms of quantum mechanics and general relativity?
[00:16:12.920 --> 00:16:16.800]   And then how do you unify all the laws of physics?
[00:16:16.800 --> 00:16:22.720]   Maybe sneak in there in a different angle, trying to ask about the singularity in the
[00:16:22.720 --> 00:16:28.160]   black hole, or maybe what happens at the very beginning of the big bang, like where those
[00:16:28.160 --> 00:16:29.880]   laws are all unified.
[00:16:29.880 --> 00:16:36.800]   Maybe try to get a sense of what are the kind of physics required to fully describe these
[00:16:36.800 --> 00:16:37.960]   events.
[00:16:37.960 --> 00:16:42.720]   I think the physics discussion would be a good time to ask, is there a God?
[00:16:42.720 --> 00:16:48.840]   Maybe not use the G word, but instead say, is there a kind of a centralized designer
[00:16:48.840 --> 00:16:55.880]   or team of designers that have like launched the universe and are actively managing the
[00:16:55.880 --> 00:16:57.380]   universe?
[00:16:57.380 --> 00:17:01.960]   And of course, another version of asking that I would probably talk about the simulation
[00:17:01.960 --> 00:17:07.380]   of looking at the universe as we see it, as a computation, as a computer that's doing
[00:17:07.380 --> 00:17:12.400]   information processing, see if that rings a bell to the alien.
[00:17:12.400 --> 00:17:15.400]   If there's a connection to that, in general, I would ask about what kind of computers you
[00:17:15.400 --> 00:17:18.760]   have and also what kind of computer games that'd be really useful.
[00:17:18.760 --> 00:17:20.960]   Like, what do you do for fun?
[00:17:20.960 --> 00:17:23.920]   You come here often, but that's like usual icebreakers.
[00:17:23.920 --> 00:17:25.320]   Of course, I'm not mentioning those.
[00:17:25.320 --> 00:17:27.400]   That's just like chatter at the bar.
[00:17:27.400 --> 00:17:32.640]   So I guess outside the big physics questions, I would ask the more engineering centric questions.
[00:17:32.640 --> 00:17:39.520]   First, my interest AI about super intelligence, how do we build super intelligent systems,
[00:17:39.520 --> 00:17:43.440]   systems that are far more intelligent than humans?
[00:17:43.440 --> 00:17:49.920]   How do we travel close to the speed of light or faster than the speed of light?
[00:17:49.920 --> 00:17:54.640]   Like how did the aliens get to where we're at that we're meeting and talking?
[00:17:54.640 --> 00:17:56.480]   Related to that would be a question of energy.
[00:17:56.480 --> 00:18:03.280]   How do we harness the energy of a sun or multiple suns or all of the suns in our galaxy?
[00:18:03.280 --> 00:18:08.240]   And then also kind of an engineering question, can we travel through time?
[00:18:08.240 --> 00:18:12.240]   And if we can, how do we build a time traveling machine?
[00:18:12.240 --> 00:18:13.240]   And is it a good idea?
[00:18:13.240 --> 00:18:19.200]   I think a lot of these questions will be appended with a sort of caveat of like, if you know
[00:18:19.200 --> 00:18:25.320]   the answer to this question, will I be better off if you told me this answer?
[00:18:25.320 --> 00:18:27.840]   Sometimes knowledge is not power.
[00:18:27.840 --> 00:18:32.720]   Sometimes knowledge is a burden that leads to self destruction.
[00:18:32.720 --> 00:18:34.280]   So we want to be careful about that.
[00:18:34.280 --> 00:18:40.520]   Of course, as the alien gets tired of talking to me at this intergalactic bar, probably
[00:18:40.520 --> 00:18:47.600]   gets up sort of politely, starts walking away, I would definitely ask some questions from
[00:18:47.600 --> 00:18:52.320]   my own personal knowledge bank.
[00:18:52.320 --> 00:18:53.800]   Is P equals NP?
[00:18:53.800 --> 00:18:55.600]   Good question.
[00:18:55.600 --> 00:18:59.880]   Theoretical computer science, one of the big questions all in mathematics.
[00:18:59.880 --> 00:19:00.880]   I just need to know the answer.
[00:19:00.880 --> 00:19:03.240]   Just give me the answer, I'll work from there.
[00:19:03.240 --> 00:19:05.280]   Okay, we'll figure out the rest, just the answer.
[00:19:05.280 --> 00:19:08.120]   So yes or no.
[00:19:08.120 --> 00:19:10.760]   Probably won't ask him for investment advice.
[00:19:10.760 --> 00:19:17.760]   Probably thinks that the whole concept of money is silly, but I might ask about Bitcoin.
[00:19:17.760 --> 00:19:19.400]   Good long term investment or bad?
[00:19:19.400 --> 00:19:21.600]   What do you think?
[00:19:21.600 --> 00:19:23.600]   The digital currency in general.
[00:19:23.600 --> 00:19:29.200]   And of course, we'll probably ask, is Elon Musk one of you guys or a different species?
[00:19:29.200 --> 00:19:34.320]   Do you know which galaxy, which group of planets he came from?
[00:19:34.320 --> 00:19:36.200]   It'd be nice to sort of localize things.
[00:19:36.200 --> 00:19:39.960]   Is there others like it that visit and build companies?
[00:19:39.960 --> 00:19:42.240]   Just get some of the details.
[00:19:42.240 --> 00:19:45.080]   This AMA has suddenly become ridiculous.
[00:19:45.080 --> 00:19:48.320]   But I think this is a really nice thought experiment.
[00:19:48.320 --> 00:19:50.080]   And I'll think about this a little bit more.
[00:19:50.080 --> 00:19:58.040]   I'm sure there is a list of really precise questions that could most efficiently unlock
[00:19:58.040 --> 00:20:03.640]   the mysteries before the human race that are both useful for our progress and useful for
[00:20:03.640 --> 00:20:05.920]   our survival.
[00:20:05.920 --> 00:20:12.360]   Question is, what advice would you give an intermediate life stage 36 year old who wants
[00:20:12.360 --> 00:20:17.960]   to career pivot from medical technology and research to computer science?
[00:20:17.960 --> 00:20:24.080]   So first, by computer science, I think you mean the broad field that includes software
[00:20:24.080 --> 00:20:30.000]   engineering, machine learning, robotics, just computing in general, maybe with less emphasis
[00:20:30.000 --> 00:20:33.280]   on the mathematical side, like theoretical computer science.
[00:20:33.280 --> 00:20:40.280]   I think the best advice on this that I could give is find a simple project to get excited
[00:20:40.280 --> 00:20:45.640]   about and allow yourself to get really excited by it.
[00:20:45.640 --> 00:20:51.320]   Have fun, fall in love with it, be proud of the thing you create.
[00:20:51.320 --> 00:20:54.200]   And I should say there's a big emphasis on the simple.
[00:20:54.200 --> 00:20:56.240]   Don't go super ambitious.
[00:20:56.240 --> 00:21:01.720]   I believe that most people, if they allow themselves, can derive a huge amount of joy
[00:21:01.720 --> 00:21:04.360]   for creating some simple little things.
[00:21:04.360 --> 00:21:08.800]   Even if it's following a tutorial, if you just allow yourself to experience the joy
[00:21:08.800 --> 00:21:12.560]   of creation, it's there for you.
[00:21:12.560 --> 00:21:18.600]   That's one of the magical things about computer science, is it allows you to create things
[00:21:18.600 --> 00:21:21.180]   that are almost like entities on their own.
[00:21:21.180 --> 00:21:23.200]   That's what programs are.
[00:21:23.200 --> 00:21:30.280]   So I think a career in computer science starts first with allowing yourself to be passionate
[00:21:30.280 --> 00:21:36.120]   and getting that, stoking that flame and allowing it to build.
[00:21:36.120 --> 00:21:40.160]   So it's not about any of the practical, like which job do I get, what thing I work on,
[00:21:40.160 --> 00:21:47.320]   it's just really giving yourself over to the simple passion of creating stuff.
[00:21:47.320 --> 00:21:53.600]   I think there's just a quick set of steps that I think I followed early on that I would
[00:21:53.600 --> 00:21:56.960]   also recommend you at least consider following.
[00:21:56.960 --> 00:21:59.600]   First is basic software engineering.
[00:21:59.600 --> 00:22:06.680]   So finding maybe Python or JavaScript, like super popular, accessible programming language,
[00:22:06.680 --> 00:22:11.280]   and build just like a Hello World program or something just a little bit more complicated,
[00:22:11.280 --> 00:22:13.440]   but not much more.
[00:22:13.440 --> 00:22:22.080]   Beyond that is using that newly acquired set of tools of programming, build something that
[00:22:22.080 --> 00:22:25.440]   automates something you do on the computer.
[00:22:25.440 --> 00:22:30.280]   Maybe another way to phrase that is just like scripts that are helping you in your interaction
[00:22:30.280 --> 00:22:31.280]   with the computer.
[00:22:31.280 --> 00:22:38.440]   So maybe finding different files in your computer that you try to look for often, or reorganizing
[00:22:38.440 --> 00:22:44.080]   things in an automated way, like folder structures, or maybe renaming files.
[00:22:44.080 --> 00:22:51.880]   Like I have a script that finds all the files that have spaces in the file name and it renames
[00:22:51.880 --> 00:22:57.560]   them after confirmation to underscores, all those kinds of things.
[00:22:57.560 --> 00:23:00.640]   There's a bunch of little helpful scripts I have all over the place, and those are just
[00:23:00.640 --> 00:23:05.120]   really joyful because you get to use them every day and it's something that you've created
[00:23:05.120 --> 00:23:08.040]   that made your life a little bit easier.
[00:23:08.040 --> 00:23:16.200]   For me at least, that's a source of joy that helps feed that love of programming, of just
[00:23:16.200 --> 00:23:19.760]   being a part of the computing of the computer science world.
[00:23:19.760 --> 00:23:22.040]   I've been doing that really my whole life.
[00:23:22.040 --> 00:23:28.920]   It started with C and C++, but now it's a lot of other languages, primarily Python and
[00:23:28.920 --> 00:23:31.760]   yes, JavaScript.
[00:23:31.760 --> 00:23:37.800]   Next is a branching into two separate little worlds in computer science of algorithms and
[00:23:37.800 --> 00:23:40.760]   then data science.
[00:23:40.760 --> 00:23:45.160]   I think both are full of beautiful things to fall in love with.
[00:23:45.160 --> 00:23:50.760]   The thing you can really enjoy with algorithms is learning how to build more and more efficient
[00:23:50.760 --> 00:23:51.920]   algorithms.
[00:23:51.920 --> 00:23:59.600]   On the data side is learning how to process different data sets, how to clean them up,
[00:23:59.600 --> 00:24:05.880]   how to reorganize them and do different kind of statistics on them, processing on them.
[00:24:05.880 --> 00:24:10.040]   So we're not even talking about machine learning yet, it's just being able to visualize those
[00:24:10.040 --> 00:24:12.880]   data sets, all those kinds of stuff, just working with data.
[00:24:12.880 --> 00:24:18.280]   And now we're starting to talk about a career because there's a lot of jobs that have to
[00:24:18.280 --> 00:24:27.120]   do with the use of computing techniques to process, visualize, interpret, aggregate,
[00:24:27.120 --> 00:24:28.340]   analyze data.
[00:24:28.340 --> 00:24:33.080]   So I guess you would call that field data science.
[00:24:33.080 --> 00:24:38.600]   So that's a really cool career trajectory and there's so many cool things to get into
[00:24:38.600 --> 00:24:44.440]   with I think a very reasonable small learning curve that you can really, if you push yourself,
[00:24:44.440 --> 00:24:48.280]   do within weeks, maybe months, not years.
[00:24:48.280 --> 00:24:52.400]   And once you become comfortable with the data science world, you can start building on top
[00:24:52.400 --> 00:24:57.680]   of that quite naturally, doing some boilerplate machine learning, supervised learning projects
[00:24:57.680 --> 00:25:06.000]   and then building out into more specific, more useful, more novel, cutting edge applications
[00:25:06.000 --> 00:25:10.860]   of machine learning, reinforcement learning, that whole world.
[00:25:10.860 --> 00:25:14.320]   Maybe even taking that into physical systems of actually building robots.
[00:25:14.320 --> 00:25:18.800]   And I should backtrack, it sounds like I'm building towards something super complicated,
[00:25:18.800 --> 00:25:19.800]   but it's not.
[00:25:19.800 --> 00:25:22.120]   All of these can be really small projects.
[00:25:22.120 --> 00:25:28.560]   Even robotics projects, you can build a little robot that does some basic tasks, maybe does
[00:25:28.560 --> 00:25:30.520]   some basic computer vision.
[00:25:30.520 --> 00:25:33.880]   And it's a nice way to learn on the robotics side, embedded systems programming.
[00:25:33.880 --> 00:25:38.240]   So it's just getting more comfortable with hardware and seeing if that's something you're
[00:25:38.240 --> 00:25:39.240]   interested in.
[00:25:39.240 --> 00:25:43.680]   Or on the data science side, where you're sticking much more to the software.
[00:25:43.680 --> 00:25:49.320]   Both of those, you now start to figure out what is the exciting career possibility.
[00:25:49.320 --> 00:25:54.840]   I think two things, I would even see them as skills that are important here, passion
[00:25:54.840 --> 00:25:56.760]   and Google.
[00:25:56.760 --> 00:26:01.360]   I see passion as a skill because it's allowing yourself to be excited.
[00:26:01.360 --> 00:26:05.440]   It's finding things you could be excited about and allowing yourself to be excited.
[00:26:05.440 --> 00:26:11.340]   And seeing that as an actually essential part of progress is allowing yourself to be excited.
[00:26:11.340 --> 00:26:16.120]   And the reason I mentioned Google is because I find that in a lot of fields, but especially
[00:26:16.120 --> 00:26:20.840]   in computer science, with software engineering, with machine learning, there's so many amazing
[00:26:20.840 --> 00:26:28.200]   resources out there that the key skill actually ends up being is how good are you at discovering
[00:26:28.200 --> 00:26:35.420]   the exact page and resources that is allowing you to take the next step in your journey
[00:26:35.420 --> 00:26:37.480]   of exploration of learning.
[00:26:37.480 --> 00:26:42.660]   And that's fundamentally a skill of how do I Google the right thing?
[00:26:42.660 --> 00:26:44.420]   What pages do I click on?
[00:26:44.420 --> 00:26:45.520]   And all those kinds of things.
[00:26:45.520 --> 00:26:50.480]   I think it sounds almost kind of ridiculous to say that that's a skill, but that is one
[00:26:50.480 --> 00:26:59.480]   of the most essential skills of the modern day student, lifelong student, is how to Google.
[00:26:59.480 --> 00:27:02.840]   So yeah, passion and Google.
[00:27:02.840 --> 00:27:09.320]   Allow yourself to fall in love with the project and keep taking the next step, the next step,
[00:27:09.320 --> 00:27:14.920]   the next step with the help of a good search engine and a bit of curiosity.
[00:27:14.920 --> 00:27:19.520]   Question is, what form factor of robots are you most excited about for the future?
[00:27:19.520 --> 00:27:26.720]   Bipeds, quads, arms, humanoids, maybe something else more obscure.
[00:27:26.720 --> 00:27:30.700]   This is a really tough question because I really like robots.
[00:27:30.700 --> 00:27:38.720]   I think that love is born in software and the hardware stuff just makes it a little
[00:27:38.720 --> 00:27:39.720]   more fun.
[00:27:39.720 --> 00:27:44.880]   So I think the things I'm really excited about, even in terms of form factors, is in the software.
[00:27:44.880 --> 00:27:50.080]   I think much of the exciting developments in robotics is actually in simulated worlds
[00:27:50.080 --> 00:27:55.400]   currently, and I think that will be true for quite a while to come.
[00:27:55.400 --> 00:28:01.720]   So I think in terms of human-robot interaction, the robots that will be really exciting are
[00:28:01.720 --> 00:28:07.480]   the ones that live in virtual worlds, like in virtual reality or even just on a screen.
[00:28:07.480 --> 00:28:15.480]   But I think what we would see more and more is entities, human-like entities, or entities
[00:28:15.480 --> 00:28:24.280]   that allow us to anthropomorphize a consciousness, a spirit onto them, living in the digital
[00:28:24.280 --> 00:28:26.040]   world.
[00:28:26.040 --> 00:28:29.400]   I think that's what I'm really excited about.
[00:28:29.400 --> 00:28:34.360]   And of course, slowly those entities taking a form in the physical space in terms of,
[00:28:34.360 --> 00:28:37.680]   I think probably the humanoid form.
[00:28:37.680 --> 00:28:46.600]   Unfortunately, though very difficult to engineer and create a realistic and natural fulfilling
[00:28:46.600 --> 00:28:51.720]   experience with, I think it's still probably the most, to me, exciting form.
[00:28:51.720 --> 00:29:01.160]   Although I do really like Boston Dynamic Spot, the robot dog, from a kind of having a pet
[00:29:01.160 --> 00:29:03.640]   perspective is a really exciting form.
[00:29:03.640 --> 00:29:07.320]   Again, very difficult to do stuff in the physical space.
[00:29:07.320 --> 00:29:14.440]   It's a huge engineering challenge that, as far as I can tell, is several orders of magnitude
[00:29:14.440 --> 00:29:18.200]   more difficult than the same challenge in the digital space.
[00:29:18.200 --> 00:29:25.680]   So I just see the digital simulated robotics advancing much quicker and having a much larger
[00:29:25.680 --> 00:29:32.560]   scale impact on the world, especially if we start seeing more and more virtual worlds
[00:29:32.560 --> 00:29:34.440]   being created.
[00:29:34.440 --> 00:29:38.560]   And that doesn't necessarily mean virtual reality or like augmented reality.
[00:29:38.560 --> 00:29:43.840]   It just means ability and mediums within which you can interact with artificial intelligence
[00:29:43.840 --> 00:29:46.320]   systems in the digital space.
[00:29:46.320 --> 00:29:54.760]   And I do see that as a form factor, which is entities in digital space having a humanoid
[00:29:54.760 --> 00:29:59.720]   or a semi-humanoid form, something that we can anthropomorphize, something we can connect
[00:29:59.720 --> 00:30:01.600]   with on a human level.
[00:30:01.600 --> 00:30:09.240]   The question is, on the topic of suffering and growth, is happiness a healthy pursuit?
[00:30:09.240 --> 00:30:15.320]   Or do you agree with Einstein's view on happiness as the aspiration of a pig?
[00:30:15.320 --> 00:30:21.560]   Okay, let me quickly look up the Einstein quote here that you referenced about a pig
[00:30:21.560 --> 00:30:22.560]   and happiness.
[00:30:22.560 --> 00:30:29.720]   Okay, Einstein writes, "I have never looked upon ease and happiness as ends in themselves.
[00:30:29.720 --> 00:30:34.120]   This critical basis I call the ideal of a pig's thigh.
[00:30:34.120 --> 00:30:39.120]   The ideals that have lighted my way and time after time have given me new courage to face
[00:30:39.120 --> 00:30:44.460]   life cheerfully have been kindness, beauty, and truth.
[00:30:44.460 --> 00:30:49.200]   Without the sense of kinship with men of like mind, without the occupation with the objective
[00:30:49.200 --> 00:30:54.840]   world, the eternally unattainable in the field of art and scientific endeavors, life would
[00:30:54.840 --> 00:30:57.220]   have seemed empty to me.
[00:30:57.220 --> 00:31:04.520]   The trite objects of human efforts, possessions, outward success, luxury, have always seemed
[00:31:04.520 --> 00:31:06.080]   to me contemptible."
[00:31:06.080 --> 00:31:11.600]   Okay, where do I start with this?
[00:31:11.600 --> 00:31:17.240]   I think I usually agree with Einstein, especially when he talks philosophy on most things, and
[00:31:17.240 --> 00:31:21.680]   I do here as well in terms of material possessions and all those kinds of things.
[00:31:21.680 --> 00:31:27.500]   But I think he unfairly attacks the word happiness and also pigs.
[00:31:27.500 --> 00:31:32.860]   So let me disagree with Einstein and try to defend the word happiness and also maybe defend
[00:31:32.860 --> 00:31:36.800]   pigs if I can somehow figure that out.
[00:31:36.800 --> 00:31:42.940]   The word happiness, I think, is one of those words that could mean a lot of things to a
[00:31:42.940 --> 00:31:43.940]   lot of people.
[00:31:43.940 --> 00:31:50.620]   And I think in this case, Einstein is using it as almost the pursuit of happiness as a
[00:31:50.620 --> 00:31:57.860]   kind of synonym for hedonism, so a kind of very narrow definition of what happiness is.
[00:31:57.860 --> 00:32:08.660]   I think I see happiness as an indicator that it's much bigger than direct pleasures, but
[00:32:08.660 --> 00:32:14.060]   as a word that includes those pleasures but also includes more meaningful, deep fulfillment
[00:32:14.060 --> 00:32:15.060]   in life.
[00:32:15.060 --> 00:32:19.780]   And so I'd like to reclaim the word happiness as a good thing, which is slightly applied
[00:32:19.780 --> 00:32:27.580]   in this discussion that happiness is a kind of distraction that shouldn't be thought about.
[00:32:27.580 --> 00:32:36.820]   I do think that happiness is a side effect of a life well lived, not a goal.
[00:32:36.820 --> 00:32:41.960]   I think the moment it becomes a goal in itself, I think it's easy to lose your way.
[00:32:41.960 --> 00:32:45.860]   And perhaps that's what in part Einstein means.
[00:32:45.860 --> 00:32:51.700]   I do think it's a really good signal of progress, happiness.
[00:32:51.700 --> 00:33:01.500]   So in losing yourself in the focus of battle, of just focusing on excellence and progress
[00:33:01.500 --> 00:33:10.500]   and improving and challenging yourself and growing all the time, I think a kind of running
[00:33:10.500 --> 00:33:17.980]   average measure of your happiness, day-to-day happiness, so you like average that over a
[00:33:17.980 --> 00:33:24.300]   period of weeks and months, is a good measure of how you're doing.
[00:33:24.300 --> 00:33:30.660]   And I think a more actionable process of collecting that signal is a process of just gratitude,
[00:33:30.660 --> 00:33:38.940]   of sitting back and thinking how grateful I am, how grateful you are for how it started
[00:33:38.940 --> 00:33:44.260]   and how it's going, for the progress that you've made.
[00:33:44.260 --> 00:33:49.460]   So I do think it's a good signal, not momentary happiness, but over a period of time, several
[00:33:49.460 --> 00:33:55.980]   weeks, several months, if there's not happiness, that you've probably lost your way as well.
[00:33:55.980 --> 00:34:00.300]   So it's a useful signal, not a goal in itself, but a useful signal.
[00:34:00.300 --> 00:34:08.920]   And kindness, beauty, and truth, as Einstein puts it, are good ideals, but they're a bit
[00:34:08.920 --> 00:34:13.940]   ambiguous, in a practical day-to-day sense.
[00:34:13.940 --> 00:34:21.140]   I share them, of course, but I think practically, if I were to put it into words, at least for
[00:34:21.140 --> 00:34:32.340]   myself, struggle is the process, and happiness is the measure.
[00:34:32.340 --> 00:34:38.880]   So day-to-day life actually looks like a constant struggle to improve yourself.
[00:34:38.880 --> 00:34:47.720]   And then the flip side of that is the gratitude of how amazing life is, the progress you've
[00:34:47.720 --> 00:34:53.240]   made, but also just the opportunity to struggle.
[00:34:53.240 --> 00:34:59.760]   You have to imagine this if it's happy, and ultimately, when I look back at my life, most
[00:34:59.760 --> 00:35:05.400]   days are spent truly happy to be alive.
[00:35:05.400 --> 00:35:10.200]   So in that sense, the pursuit of happiness is a good one.
[00:35:10.200 --> 00:35:19.440]   Not hedonistic, in the moment, local optima of pleasure, but more like stepping back,
[00:35:19.440 --> 00:35:24.160]   looking at the running average over the past few weeks and months, and making sure you're
[00:35:24.160 --> 00:35:26.840]   at a good level.
[00:35:26.840 --> 00:35:30.000]   So that's a bit of a disagreement with Einstein.
[00:35:30.000 --> 00:35:36.680]   And I also have to say that I think pigs are one of the most intelligent animals.
[00:35:36.680 --> 00:35:43.440]   So I'm still holding out for the possibility that pigs, or maybe dolphins, have life figured
[00:35:43.440 --> 00:35:47.460]   out quite a bit better than us humans.
[00:35:47.460 --> 00:35:53.840]   So on those two things, the pursuit of happiness, and on the brilliance of pigs, me and Einstein
[00:35:53.840 --> 00:35:59.280]   part ways for a brief moment.
[00:35:59.280 --> 00:36:06.360]   Question is, "Hey Lex, I was curious how you pick people to come on to the podcast."
[00:36:06.360 --> 00:36:11.760]   I think this process is actually quite difficult, and it evolved over time.
[00:36:11.760 --> 00:36:13.640]   So let me mention a few factors.
[00:36:13.640 --> 00:36:21.600]   I think first and foremost, it's important that a person is really passionate about what
[00:36:21.600 --> 00:36:24.840]   they do, and that passion can take all kinds of different forms.
[00:36:24.840 --> 00:36:33.760]   I know I sometimes, or all the time, completely lack emotion in my face, but I truly am passionate
[00:36:33.760 --> 00:36:38.880]   about the things I do, and so that passion can express itself in different ways.
[00:36:38.880 --> 00:36:44.200]   And so coupled with that passion, I look for people who are sort of not only passionate,
[00:36:44.200 --> 00:36:52.560]   but they appreciate, enjoy, are drawn to the long-form conversation format as a way to
[00:36:52.560 --> 00:36:55.480]   express that passion, which is not everybody.
[00:36:55.480 --> 00:37:01.600]   Some people love to express their passion, their interest, their expertise, their ideas
[00:37:01.600 --> 00:37:03.700]   in written form.
[00:37:03.700 --> 00:37:09.640]   Maybe that's more kind of edited over several passes of editing, versus a conversation format,
[00:37:09.640 --> 00:37:13.380]   especially long-form conversation where there's very little editing.
[00:37:13.380 --> 00:37:19.640]   In addition to that, I also try to make sure the person actually wants to come onto this
[00:37:19.640 --> 00:37:21.720]   particular podcast.
[00:37:21.720 --> 00:37:27.760]   There's so many amazing podcasts out there, and it's also just surprising to see how much
[00:37:27.760 --> 00:37:32.680]   better they are than me at talking and conversations, explaining stuff.
[00:37:32.680 --> 00:37:33.680]   It's humbling.
[00:37:33.680 --> 00:37:38.240]   It's also inspiring, because it pushes me to kind of improve, seeing what's possible.
[00:37:38.240 --> 00:37:46.440]   So I don't know, if people don't actually listen to this particular podcast, or at least
[00:37:46.440 --> 00:37:52.400]   have listened a little bit, and are not drawn to the particular flavor of weirdness that
[00:37:52.400 --> 00:37:59.080]   is me, like some kid who wears a suit all the time and mumbles, speaks slowly, asks
[00:37:59.080 --> 00:38:00.080]   these weird questions.
[00:38:00.080 --> 00:38:05.040]   I mean, if they're not drawn to whatever the hell that weird mystery is of this particular
[00:38:05.040 --> 00:38:08.960]   human, then there's no reason to talk.
[00:38:08.960 --> 00:38:13.200]   If they're drawn, I think there's a possibility of something magical happening.
[00:38:13.200 --> 00:38:16.840]   Me with my weirdness, and them with their weirdness kind of colliding in interesting
[00:38:16.840 --> 00:38:22.680]   ways that creates something new that both of us are surprised by.
[00:38:22.680 --> 00:38:28.480]   And on that topic, more and more I'm looking for people that are different than me.
[00:38:28.480 --> 00:38:31.680]   And that means the full spectrum of diversity.
[00:38:31.680 --> 00:38:37.880]   So it could be different backgrounds, different world views, different personalities.
[00:38:37.880 --> 00:38:41.920]   Like you can tell there'll be a clash of flavors.
[00:38:41.920 --> 00:38:45.000]   It's like chocolate and salt.
[00:38:45.000 --> 00:38:50.960]   But it can also turn out to be like a pineapple pizza that actually some people love, but
[00:38:50.960 --> 00:38:52.400]   I don't understand.
[00:38:52.400 --> 00:38:55.120]   It doesn't make any sense.
[00:38:55.120 --> 00:38:57.120]   Why it doesn't make any sense.
[00:38:57.120 --> 00:39:03.840]   So it could be taking that risk of embracing that clash, and the chemistry can sometimes
[00:39:03.840 --> 00:39:05.960]   result in a pineapple pizza.
[00:39:05.960 --> 00:39:08.440]   So there's a cost to that risk.
[00:39:08.440 --> 00:39:13.520]   But I seek it out more because I think that's the possibility of some magical experience
[00:39:13.520 --> 00:39:16.240]   of a magical conversation.
[00:39:16.240 --> 00:39:19.960]   And on that topic, I should mention there's this kind of idea of platforming, which is
[00:39:19.960 --> 00:39:28.040]   I've been fortunate enough to have sort of enough listeners and viewers that the question
[00:39:28.040 --> 00:39:30.320]   of platforming even comes up.
[00:39:30.320 --> 00:39:37.680]   Meaning if you have this kind of guest with these kind of controversial viewpoints, why
[00:39:37.680 --> 00:39:44.440]   give them a platform that further spreads their viewpoints?
[00:39:44.440 --> 00:39:52.800]   And I understand, I empathize with this kind of view, but I don't like it.
[00:39:52.800 --> 00:39:57.400]   Because to me, if I'm successful, now that's the problem.
[00:39:57.400 --> 00:40:03.120]   I'm not very good at this thing, especially in challenging conversations.
[00:40:03.120 --> 00:40:11.920]   But if I'm successful, the tension in worldviews, the tension in personalities, the clash will
[00:40:11.920 --> 00:40:14.620]   create wisdom.
[00:40:14.620 --> 00:40:19.720]   So I really want to talk to very challenging people.
[00:40:19.720 --> 00:40:22.960]   I want to have really difficult conversations.
[00:40:22.960 --> 00:40:29.160]   And that means talking to people that are at the outskirts of society.
[00:40:29.160 --> 00:40:34.320]   I think it's something that I'm thinking about a lot.
[00:40:34.320 --> 00:40:39.000]   It's important to say that I'm not afraid of being canceled.
[00:40:39.000 --> 00:40:46.680]   I do think I'm afraid, or perhaps the better word is concerned, about doing a terrible
[00:40:46.680 --> 00:40:53.480]   job on an important, difficult conversation.
[00:40:53.480 --> 00:41:00.800]   Where as a result of me doing a terrible job, I don't add love or knowledge or inspiration
[00:41:00.800 --> 00:41:05.300]   to the world, but fuel further division.
[00:41:05.300 --> 00:41:16.600]   Not because of the guests I have on, but because of my failure to catalyze and steer an inspiring
[00:41:16.600 --> 00:41:17.600]   conversation.
[00:41:17.600 --> 00:41:23.280]   I see my skill in conversation as not, I mean, I don't know how to put it nicely, but not
[00:41:23.280 --> 00:41:24.480]   very good.
[00:41:24.480 --> 00:41:27.300]   I'm striving to improve constantly.
[00:41:27.300 --> 00:41:35.240]   So some of the guest selection has to do with the difficulty of the conversation and how
[00:41:35.240 --> 00:41:37.640]   prepared I am for that level of difficulty.
[00:41:37.640 --> 00:41:46.240]   I think, the way I think about difficult conversations is some of them might take years to prepare
[00:41:46.240 --> 00:41:48.680]   for, just intellectually.
[00:41:48.680 --> 00:41:53.480]   There's certain people and certain spaces of ideas that takes a lot of time.
[00:41:53.480 --> 00:41:58.720]   You have to remember that I'm just an engineer.
[00:41:58.720 --> 00:42:04.840]   I have a set of things that preoccupied my mind for years, and there's a lot of difficult
[00:42:04.840 --> 00:42:09.360]   topics that I just won't do a good job of.
[00:42:09.360 --> 00:42:15.240]   So part of it is I have to work hard to learn more, to kind of constantly look outside the
[00:42:15.240 --> 00:42:19.720]   Overton window to try to explore difficult ideas.
[00:42:19.720 --> 00:42:29.480]   At the same time, build enough sort of reputation driven freedom to take risks and make mistakes,
[00:42:29.480 --> 00:42:34.360]   or try to inspire people in the community to allow me, to allow each other, all of us
[00:42:34.360 --> 00:42:36.880]   to make mistakes in conversation.
[00:42:36.880 --> 00:42:44.400]   So it's the coupling of extreme thorough preparation and allowing yourself to make mistakes.
[00:42:44.400 --> 00:42:50.200]   It's like excellence and not giving a damn combined.
[00:42:50.200 --> 00:42:57.200]   But overall, the thing I'm concerned about, and I take back the fear, I'm not afraid of
[00:42:57.200 --> 00:42:58.200]   it.
[00:42:58.200 --> 00:43:01.800]   I'm just concerned of doing a bad job of conversation.
[00:43:01.800 --> 00:43:09.480]   I'm not concerned of being canceled or derided or criticized after having done a reasonably
[00:43:09.480 --> 00:43:11.240]   good job.
[00:43:11.240 --> 00:43:15.960]   I'm concerned of myself, it doesn't matter if I'm canceled or not.
[00:43:15.960 --> 00:43:21.160]   Just when I look in the mirror, when I look at the results of the conversation being a
[00:43:21.160 --> 00:43:28.040]   failure, something that doesn't add love to the world, but something that adds derision.
[00:43:28.040 --> 00:43:29.520]   And also this is the problem with words.
[00:43:29.520 --> 00:43:33.360]   I don't even like how I'm expressing myself currently.
[00:43:33.360 --> 00:43:39.160]   I really try not to have some kind of agenda or strategy going into a conversation.
[00:43:39.160 --> 00:43:47.240]   I really want to be fragile, open-minded, almost boring and naive, and just giving my
[00:43:47.240 --> 00:43:49.280]   trust to a person.
[00:43:49.280 --> 00:43:54.960]   Even when I challenge or play devil's advocate, all those kinds of things, I really want to
[00:43:54.960 --> 00:44:03.960]   place trust in the mutual respect and the love that the other person gives.
[00:44:03.960 --> 00:44:07.880]   And I trust that they won't take advantage of that.
[00:44:07.880 --> 00:44:14.160]   And so some of the guest selection has to do with, do I have enough trust yet that this
[00:44:14.160 --> 00:44:21.680]   person won't take advantage of my open-mindedness, of my childlike curiosity, all those kinds
[00:44:21.680 --> 00:44:23.680]   of things.
[00:44:23.680 --> 00:44:26.400]   But all of this is just a giant learning experience.
[00:44:26.400 --> 00:44:32.560]   I do want to be careful not to let my curiosity run, what should I say, too far ahead of me,
[00:44:32.560 --> 00:44:38.800]   or my preparation doesn't meet the level of curiosity I exhibit.
[00:44:38.800 --> 00:44:45.000]   So again, like I said, I'm willing and I'm trying to be more and more willing to take
[00:44:45.000 --> 00:44:51.080]   risks and make mistakes in conversations, but I'm also not letting myself off the hook
[00:44:51.080 --> 00:44:55.160]   in terms of the level of preparation I put.
[00:44:55.160 --> 00:45:02.500]   And I really hope that we give each other the freedom and are patient with each other
[00:45:02.500 --> 00:45:04.160]   in nuanced conversation.
[00:45:04.160 --> 00:45:11.200]   That's what seems to be really missing in public discourse, is this kind of patience
[00:45:11.200 --> 00:45:18.240]   and allowing each other to make statements that we later change our mind on, and not
[00:45:18.240 --> 00:45:24.480]   putting that statement on us as this kind of scarlet letter that forever puts us in
[00:45:24.480 --> 00:45:28.800]   a bin of red or blue or some other bin.
[00:45:28.800 --> 00:45:34.160]   So I'm trying to navigate all of this while still being naive and open-minded as best
[00:45:34.160 --> 00:45:35.160]   I can.
[00:45:35.160 --> 00:45:40.040]   The question is, "Hey Lex, I was wondering how you manage to remain optimistic in the
[00:45:40.040 --> 00:45:45.720]   face of adversity when you encounter hostile people that don't want to even consider offering
[00:45:45.720 --> 00:45:51.120]   constructive criticism and would rather try to tear you down and force their ideology.
[00:45:51.120 --> 00:45:56.800]   I find pieces of hope for short periods of time and then they fade after I see the arguments
[00:45:56.800 --> 00:45:59.960]   surrounding whatever brought about hope to begin with.
[00:45:59.960 --> 00:46:05.160]   I guess to put it simply, how do you hold on to hope and optimism?"
[00:46:05.160 --> 00:46:06.160]   Thank you for the question.
[00:46:06.160 --> 00:46:14.000]   There's probably a lot to be said about this, but I'll try to keep it brief and simple.
[00:46:14.000 --> 00:46:21.720]   I try to ignore the noise of the world, the bickering of the moment.
[00:46:21.720 --> 00:46:27.880]   I find that if you give yourself a chance to see how amazing people are, that those
[00:46:27.880 --> 00:46:31.800]   people will reveal themselves to be amazing.
[00:46:31.800 --> 00:46:36.640]   That you will see it.
[00:46:36.640 --> 00:46:41.120]   That if you give yourself a chance to see it, you will see it.
[00:46:41.120 --> 00:46:43.080]   I see it.
[00:46:43.080 --> 00:46:52.680]   And I see gratitude for how amazing things are and optimism for how much even better
[00:46:52.680 --> 00:46:57.160]   things could be as a kind of superpower.
[00:46:57.160 --> 00:47:04.640]   It makes life exciting in a way that first, is just fun to live.
[00:47:04.640 --> 00:47:11.200]   And two, from just a productivity perspective, as an engineer or anybody who creates anything,
[00:47:11.200 --> 00:47:15.280]   it's fuel to create.
[00:47:15.280 --> 00:47:22.720]   I believe that to create new things, and especially for things that others will say is not possible
[00:47:22.720 --> 00:47:30.000]   to create, I find that optimism is a necessary precondition to give you the energy, the fuel,
[00:47:30.000 --> 00:47:39.960]   the drive, the inspiration to go for months, for years, to carry the fire of belief.
[00:47:39.960 --> 00:47:46.440]   That's where that optimism truly is, a superpower that enables that kind of perseverance.
[00:47:46.440 --> 00:47:52.640]   So I think the most important thing is it makes life more exciting and fun.
[00:47:52.640 --> 00:47:58.440]   And it's a good productivity hack, is the second thing.
[00:47:58.440 --> 00:48:05.440]   You also asked how, so I try to, my personal life and the influences I take in, the books
[00:48:05.440 --> 00:48:10.800]   I read and the people I talk to, I try to surround myself with people that are also
[00:48:10.800 --> 00:48:11.800]   full of optimism.
[00:48:11.800 --> 00:48:20.080]   And in general, I'm unapologetically a fan of a lot of people, especially sort of big
[00:48:20.080 --> 00:48:25.160]   thinkers, wild engineers and scientists and creators of all walks of life.
[00:48:25.160 --> 00:48:32.080]   People that shine in ways that surprise me or excite me.
[00:48:32.080 --> 00:48:36.160]   There's really thousands, to be honest, just off the top of my head, even people I talked
[00:48:36.160 --> 00:48:38.160]   to on this podcast.
[00:48:38.160 --> 00:48:42.680]   Chris Lattner always brings a smile to my face, one of the greatest engineers of the
[00:48:42.680 --> 00:48:44.080]   world.
[00:48:44.080 --> 00:48:50.400]   Jim Keller's from that ilk as well, though slightly different personalities, but also
[00:48:50.400 --> 00:48:57.160]   inspires me, makes me smile, such a deep and kind and brilliant human being.
[00:48:57.160 --> 00:49:04.560]   Along that line of engineers, Elon Musk, of course, also the embodiment of optimism about
[00:49:04.560 --> 00:49:08.600]   this world is an inspiration.
[00:49:08.600 --> 00:49:17.080]   And then maybe down the dimension of more wild, even George Hotz, with a chaotic style
[00:49:17.080 --> 00:49:22.600]   of thinking that's very different than my own, but one that I find just inspiring.
[00:49:22.600 --> 00:49:30.640]   Of course, Joe Rogan, for me, has been for many years a kind of example of somebody who
[00:49:30.640 --> 00:49:33.360]   doesn't take themselves too seriously.
[00:49:33.360 --> 00:49:35.080]   He's been for a lot of people.
[00:49:35.080 --> 00:49:43.200]   He has been for me a role model for a successful life that's not full of jealousy and kind
[00:49:43.200 --> 00:49:48.080]   of derision, but it's more being supportive of others, being a fan of others, all those
[00:49:48.080 --> 00:49:51.080]   kinds of things.
[00:49:51.080 --> 00:49:56.040]   On the darker side, Dan Carlin, of course, you don't often think of him as optimistic,
[00:49:56.040 --> 00:49:58.840]   but I truly think he's optimistic.
[00:49:58.840 --> 00:50:08.320]   He's just been so deeply soaking in the muck, the darkness of human history, that I think
[00:50:08.320 --> 00:50:16.240]   sometimes the things he talks about come off as deeply cynical about the future of human
[00:50:16.240 --> 00:50:18.640]   civilization, but they're not.
[00:50:18.640 --> 00:50:21.840]   There's a shining optimism to him.
[00:50:21.840 --> 00:50:26.080]   I was in my conversation with him, even though his words were saying that he's not always
[00:50:26.080 --> 00:50:30.640]   optimistic, I think his heart, his spirit was clearly optimistic.
[00:50:30.640 --> 00:50:36.080]   There's a hope for us in him, at least to me.
[00:50:36.080 --> 00:50:41.600]   That's what I see, and to me that hope glows pretty bright in the stuff that he creates
[00:50:41.600 --> 00:50:44.360]   and the passion that he has for human history.
[00:50:44.360 --> 00:50:51.760]   Of course, the scientist, Stephen Wolfram, on the computer science side, I can't tell
[00:50:51.760 --> 00:50:53.760]   you how much I love cellular automata.
[00:50:53.760 --> 00:51:00.760]   Sean Carroll, the way he loves everything about physics, this incredible communicator.
[00:51:00.760 --> 00:51:06.640]   Eric Weinstein, the way he loves everything geometrical, shapes of all things, whether
[00:51:06.640 --> 00:51:14.240]   they're mathematical or whether they're connected to physics, just his loves for symmetry, asymmetry.
[00:51:14.240 --> 00:51:21.200]   For topology, for the weird curvature of things in the visible dimensions of space-time or
[00:51:21.200 --> 00:51:23.520]   the invisible ones.
[00:51:23.520 --> 00:51:26.560]   That's just sticking to people I've talked to on this podcast.
[00:51:26.560 --> 00:51:32.080]   Of course, Joshua Bach, whose flow of consciousness is full of so much brilliance, it breaks my
[00:51:32.080 --> 00:51:34.880]   brain any time I try to process it.
[00:51:34.880 --> 00:51:38.720]   My Commodore 64 brain takes in his Pentium.
[00:51:38.720 --> 00:51:43.760]   I don't know what the analogy is, but it always breaks my brain.
[00:51:43.760 --> 00:51:48.280]   I'm especially inspired by the creations of software engineers, for example, because there's
[00:51:48.280 --> 00:51:51.680]   an inherent optimism to the creative process.
[00:51:51.680 --> 00:51:56.800]   A lot of people in the cryptocurrency space, like Vitalik Buterin, is a constant inspiration.
[00:51:56.800 --> 00:51:58.480]   It just goes on and on.
[00:51:58.480 --> 00:52:05.360]   Of course, the hundreds, probably thousands of dead folks, from Nietzsche to Dostoevsky,
[00:52:05.360 --> 00:52:13.240]   Freud, Jung, Camus, Hasse, Kerouac, everybody.
[00:52:13.240 --> 00:52:23.040]   I just feel like I exist in this world of people that are excited about the future.
[00:52:23.040 --> 00:52:29.920]   Then of course, the noise of the world that is lost in the bickering of the moment can
[00:52:29.920 --> 00:52:30.920]   seep in.
[00:52:30.920 --> 00:52:33.880]   That's where meditation comes in.
[00:52:33.880 --> 00:52:35.760]   I don't fully ignore it.
[00:52:35.760 --> 00:52:43.200]   I think that's running away from the world in a way that I don't find constructive.
[00:52:43.200 --> 00:52:49.320]   At least at this time in my life, I just take it in, but I don't let it linger.
[00:52:49.320 --> 00:52:58.240]   If there's any kind of harshness or trolling or just maybe destructive criticism, I try
[00:52:58.240 --> 00:53:04.840]   to pick from it pieces that I can use to grow to inspire me and let the rest go.
[00:53:04.840 --> 00:53:07.960]   That's the kind of muscle you have to build.
[00:53:07.960 --> 00:53:14.640]   Every once in a while, just disconnect from it all and recharge the mind in a way from
[00:53:14.640 --> 00:53:19.680]   just simple silence of nature.
[00:53:19.680 --> 00:53:24.960]   Question is, "What is something you changed your opinion about in the past few years?
[00:53:24.960 --> 00:53:26.320]   Thank you for everything you're doing.
[00:53:26.320 --> 00:53:27.320]   Love from Brussels."
[00:53:27.320 --> 00:53:29.160]   I love Belgium.
[00:53:29.160 --> 00:53:31.760]   Thank you for that question and the kind words.
[00:53:31.760 --> 00:53:35.520]   I changed my mind on a lot of things and I change my mind all the time.
[00:53:35.520 --> 00:53:37.920]   I'm in a constant flux.
[00:53:37.920 --> 00:53:39.280]   I'm constantly learning.
[00:53:39.280 --> 00:53:42.000]   I guess my mind is a quantum mechanical system.
[00:53:42.000 --> 00:53:49.680]   I can mention a few things that have been stable big shifts in my thinking at least
[00:53:49.680 --> 00:53:53.760]   over the past year or two, especially related to the podcast.
[00:53:53.760 --> 00:53:59.040]   On the topic of psychedelics, I've always found those fascinating.
[00:53:59.040 --> 00:54:03.360]   What I've changed my mind over the past couple of years is a hopeful message.
[00:54:03.360 --> 00:54:09.720]   I think that psychedelics can actually enter the realm of science and that there's a bunch
[00:54:09.720 --> 00:54:15.320]   of places that are starting to conduct large scale research studies on psychedelics.
[00:54:15.320 --> 00:54:20.520]   That's really exciting to me because I have a sense that that's just another perspective
[00:54:20.520 --> 00:54:25.400]   into the world of neuroscience that will help us understand the way the mind works and potentially
[00:54:25.400 --> 00:54:31.600]   how to engineer different aspects of what makes the human mind so special in our artificial
[00:54:31.600 --> 00:54:33.840]   intelligence systems.
[00:54:33.840 --> 00:54:37.520]   On the topic of social media, I've changed my mind over the past two years.
[00:54:37.520 --> 00:54:45.760]   I always felt that it had a bunch of complicated bad influences on society, but they were balanced
[00:54:45.760 --> 00:54:51.480]   with a lot of positive effects that build community, that give people a voice, all those
[00:54:51.480 --> 00:54:53.080]   kinds of things.
[00:54:53.080 --> 00:54:59.240]   More and more, I'm starting to think that the possible set of destructive trajectories
[00:54:59.240 --> 00:55:07.720]   that social media can take human civilization is much wider, much more destructive than
[00:55:07.720 --> 00:55:09.680]   I accounted for.
[00:55:09.680 --> 00:55:11.240]   It's something that I worry about.
[00:55:11.240 --> 00:55:16.600]   In the space of existential risk of artificial intelligence that people talk about, I think
[00:55:16.600 --> 00:55:21.040]   my mind more and more over the past two years has been focused on social media as the greatest
[00:55:21.040 --> 00:55:23.360]   threat of artificial intelligence.
[00:55:23.360 --> 00:55:27.240]   I also think it's the greatest set of possibilities.
[00:55:27.240 --> 00:55:31.720]   What I want to say is it's the set of trajectories is wider than I expected.
[00:55:31.720 --> 00:55:38.620]   The set of possible trajectories than society might go as driven by, managed by, directed
[00:55:38.620 --> 00:55:41.920]   by our platforms.
[00:55:41.920 --> 00:55:48.060]   Hence it's been something that I've been working on to see if I can help.
[00:55:48.060 --> 00:55:55.520]   The biggest thing I probably changed my mind on is that extraterrestrial life, intelligence,
[00:55:55.520 --> 00:56:00.480]   consciousness is worthy of serious scientific investigation.
[00:56:00.480 --> 00:56:07.520]   It's similar how I felt before about consciousness, human consciousness, is that we lack the tools
[00:56:07.520 --> 00:56:16.160]   and we're very early in our ability to explore, to understand, to engineer consciousness.
[00:56:16.160 --> 00:56:19.140]   The same with extraterrestrial life.
[00:56:19.140 --> 00:56:23.600]   The tools are very crude in terms of the SETI efforts of trying to communicate with far
[00:56:23.600 --> 00:56:31.440]   away civilizations, also the listening, then there's the detection in far away exoplanets
[00:56:31.440 --> 00:56:35.920]   and whether they're habitable in life forms on those planets.
[00:56:35.920 --> 00:56:40.400]   Also the hundreds of thousands of reports of UFO sightings, actually getting some high
[00:56:40.400 --> 00:56:43.040]   resolution sensory data around that.
[00:56:43.040 --> 00:56:48.200]   We're in the very early days of any of that kind of understanding, but what I've changed
[00:56:48.200 --> 00:56:57.320]   my mind on, or rather what I've come to understand, is closing my mind, closing the mind of other
[00:56:57.320 --> 00:57:04.720]   scientists to these fields of consciousness and extraterrestrial life prevents us from
[00:57:04.720 --> 00:57:07.920]   actually discovering new things.
[00:57:07.920 --> 00:57:15.160]   Basically what happens when you close your mind to these fascinating, inspiring, mysterious
[00:57:15.160 --> 00:57:21.960]   spaces of exploration, you leave the exploration of these topics to people that are not well
[00:57:21.960 --> 00:57:23.360]   equipped to explore them.
[00:57:23.360 --> 00:57:25.380]   They're just curious minds.
[00:57:25.380 --> 00:57:30.400]   By the way, those curious minds are magical and they're inspiring and I'm one such curious
[00:57:30.400 --> 00:57:32.040]   mind.
[00:57:32.040 --> 00:57:38.560]   But the rigors of science, the tools of science, the funding of science can crack these wide
[00:57:38.560 --> 00:57:42.680]   open and give us better data, better understanding.
[00:57:42.680 --> 00:57:50.680]   There are totally new ways of thinking about consciousness, about extraterrestrial life,
[00:57:50.680 --> 00:57:57.120]   have entire paradigm shifts of the way we approach our understanding of intelligence,
[00:57:57.120 --> 00:57:59.320]   of life forms in general.
[00:57:59.320 --> 00:58:04.720]   There's a lot of things that kind of opened my eyes to this fascinating world.
[00:58:04.720 --> 00:58:13.280]   The David Fravor conversation of the pilot that saw the Tic Tac UFO, the, it was just
[00:58:13.280 --> 00:58:18.000]   recent, Amo Amoa conversation, but that was in 2017.
[00:58:18.000 --> 00:58:22.760]   I remember seeing Avi Loeb's thoughts about Amo Amoa when it first came out.
[00:58:22.760 --> 00:58:27.320]   And even just thinking about the Drake equation more seriously and thinking about the different
[00:58:27.320 --> 00:58:34.040]   possibilities built into the uncertainty of the parameters just opened my eyes to the
[00:58:34.040 --> 00:58:41.440]   mystery and the wonder of the amazing universe we're in and how little we know about it.
[00:58:41.440 --> 00:58:49.640]   And so I've definitely kind of become much more intellectually open to the exploration
[00:58:49.640 --> 00:58:55.960]   of what extraterrestrial life might look like, what are the ways we might be able to communicate
[00:58:55.960 --> 00:59:00.680]   with it, how we might be able to understand it, what does it teach us about ourselves.
[00:59:00.680 --> 00:59:08.840]   And also importantly, this very fascinating psychological effect of being open to these
[00:59:08.840 --> 00:59:17.120]   mysteries that we know very little about, what does that do to the actual productivity,
[00:59:17.120 --> 00:59:24.680]   the creative output of an engineering mind, that opening your mind in this way to think
[00:59:24.680 --> 00:59:29.720]   outside of the little box of things we understand well.
[00:59:29.720 --> 00:59:37.280]   What does that do in terms of the things you might be able to build, the ideas that might
[00:59:37.280 --> 00:59:42.760]   visit you and result in you being able to build something totally new.
[00:59:42.760 --> 00:59:45.360]   I think all of that changed my mind about aliens.
[00:59:45.360 --> 00:59:48.920]   That's why I've been having conversations about extraterrestrial life.
[00:59:48.920 --> 00:59:55.100]   I'm of course very careful walking down this line because I am first and foremost a scientist
[00:59:55.100 --> 01:00:00.540]   and engineer and I want to stay in that world, but I really do want to cultivate an open
[01:00:00.540 --> 01:00:03.860]   mind and a childlike curiosity.
[01:00:03.860 --> 01:00:07.420]   And I generally hope to see that in other scientists as well.
[01:00:07.420 --> 01:00:08.940]   That's what science is all about.
[01:00:08.940 --> 01:00:15.940]   I think incremental progress is essential for science, but it has to be coupled to that
[01:00:15.940 --> 01:00:23.320]   childlike wonder about the world and an open-minded, out-of-the-box thinking that results in major
[01:00:23.320 --> 01:00:28.820]   paradigm shifts that throw all those silly citations out the window and build totally
[01:00:28.820 --> 01:00:36.120]   new sciences, totally new approaches that make everything we did in the decades past
[01:00:36.120 --> 01:00:39.160]   meaningless or actually counterproductive.
[01:00:39.160 --> 01:00:41.560]   So they have to be coupled together.
[01:00:41.560 --> 01:00:49.840]   Incremental progress and first principles, deep thinking that results in paradigm shifts.
[01:00:49.840 --> 01:00:55.820]   Second is, what was your decision behind going on the keto diet, mainly meat-based, and how
[01:00:55.820 --> 01:00:57.780]   has it helped you?
[01:00:57.780 --> 01:01:02.840]   So the decision, or rather process of discovering the diets that work for me has to do with
[01:01:02.840 --> 01:01:08.060]   the fact that I wrestled, did combat sports my whole life, that has weight classes, so
[01:01:08.060 --> 01:01:15.260]   you're constantly figuring out how to perform optimally physically and mentally while going
[01:01:15.260 --> 01:01:18.960]   to school and so on, while also cutting weight.
[01:01:18.960 --> 01:01:23.420]   So grounded in that, I've developed a fascination with different diets.
[01:01:23.420 --> 01:01:28.060]   I've never thought about diet as a prescriptive thing for others.
[01:01:28.060 --> 01:01:35.180]   I've always thought of myself as a kind of a nutritional scientist running a study of
[01:01:35.180 --> 01:01:36.180]   N of one.
[01:01:36.180 --> 01:01:41.220]   So just studying myself and not trying to extrapolate to others, just understanding
[01:01:41.220 --> 01:01:44.940]   what makes me happy, what makes me perform the best, and that's where that journey took.
[01:01:44.940 --> 01:01:45.940]   I've tried everything.
[01:01:46.240 --> 01:01:51.480]   I think about 15 or more years ago, I discovered the power of intermittent fasting, or fasting
[01:01:51.480 --> 01:01:54.660]   in general, and I can talk about that forever.
[01:01:54.660 --> 01:01:58.920]   I used to do a lot of weight lifting, sort of power lifting, all that kind of stuff.
[01:01:58.920 --> 01:02:06.320]   In the world of men's health, or rather men's muscle and fitness, kind of, where you eat
[01:02:06.320 --> 01:02:10.680]   six, seven times a day, small meals, chicken and broccoli, all that kind of stuff, in that
[01:02:10.680 --> 01:02:17.260]   kind of world, to realize that you can eat once a day and still train two, three times
[01:02:17.260 --> 01:02:25.520]   that day and actually have more energy, more focus, and perform better than you ever have,
[01:02:25.520 --> 01:02:27.660]   was mind-blowing.
[01:02:27.660 --> 01:02:36.000]   So I think fasting was the biggest paradigm shift for me, because it made me realize that
[01:02:36.000 --> 01:02:41.500]   I really need to study myself better, try new things all the time, to allow myself the
[01:02:41.500 --> 01:02:47.420]   opportunity to discover something that's totally transformative on my life, makes my life easier,
[01:02:47.420 --> 01:02:50.480]   makes my body, my mind work better, all that kind of stuff.
[01:02:50.480 --> 01:02:56.200]   I discovered intermittent fasting and fasting in general from the ultra-endurance athlete's
[01:02:56.200 --> 01:03:02.920]   world, and that's where also I came across the idea as a fat-adapted athlete, which is
[01:03:02.920 --> 01:03:07.580]   this kind of idea that you can use fat as an energy source, and then quickly discover
[01:03:07.580 --> 01:03:13.520]   that there is diets similar to a keto diet that are extremely low-carb that could allow
[01:03:13.520 --> 01:03:18.080]   you to perform well physically and mentally, all those kinds of things.
[01:03:18.080 --> 01:03:20.760]   I think it all sounded a little bit crazy to me.
[01:03:20.760 --> 01:03:27.280]   I grew up thinking low-fat is good, high-fat is bad, so it was always weird to eat something
[01:03:27.280 --> 01:03:33.620]   with fat in it, and for it not to be a cheat meal or something, but to be something that's
[01:03:33.620 --> 01:03:35.260]   part of the diet.
[01:03:35.260 --> 01:03:39.940]   So it was strange, but once I gave it a chance and did it properly with all the electrolytes
[01:03:39.940 --> 01:03:44.300]   and water and all those kinds of things, you can look it up, when you do it properly, it
[01:03:44.300 --> 01:03:49.180]   just felt great, and there was just a huge number of benefits I felt immediately, and
[01:03:49.180 --> 01:03:51.280]   I've been doing it ever since.
[01:03:51.280 --> 01:03:56.700]   So let me maybe quickly comment on some pros and cons of the keto diet.
[01:03:56.700 --> 01:03:59.060]   And again, this is all personal experience.
[01:03:59.060 --> 01:04:04.380]   I don't want to extrapolate this to others, but I do encourage people to try to explore,
[01:04:04.380 --> 01:04:07.420]   to be their own scientists of their own body.
[01:04:07.420 --> 01:04:11.460]   So for me, pros is the physical energy.
[01:04:11.460 --> 01:04:17.020]   First of all, the energy levels are more stable, but also I just feel more energized for exercise.
[01:04:17.020 --> 01:04:25.740]   This is both for explosive movements, heavy lifts, or jiu-jitsu, grappling, judo, wrestling,
[01:04:25.740 --> 01:04:30.340]   all those kinds of things, and also for prolonged endurance exercise.
[01:04:30.340 --> 01:04:32.940]   I find both are really benefit for me.
[01:04:32.940 --> 01:04:37.780]   I think for explosive exercise, the biggest benefit for me is the mental focus, at least
[01:04:37.780 --> 01:04:42.020]   the way I approach the grappling sports, but even lifting.
[01:04:42.020 --> 01:04:47.320]   It's certainly very important how my body feels, but it's also important that the mind
[01:04:47.320 --> 01:04:49.860]   is really focused on the technique.
[01:04:49.860 --> 01:04:57.020]   And I find that the biggest benefit of keto combined with fasting is that my mind can
[01:04:57.020 --> 01:05:05.380]   achieve a greater level of stable, prolonged focus, which is useful for exercise, funny
[01:05:05.380 --> 01:05:06.620]   enough for me.
[01:05:06.620 --> 01:05:13.580]   Obviously, it's really useful for work, for deep work sessions, for thinking deeply for
[01:05:13.580 --> 01:05:18.020]   prolonged periods of times, whether that's programming, whether that's writing, or whether
[01:05:18.020 --> 01:05:22.020]   that's sitting behind a sheet of paper and designing new systems.
[01:05:22.020 --> 01:05:27.580]   It's both the energy of mental focus and the kind of clarity, I don't know how else to
[01:05:27.580 --> 01:05:34.140]   put it, but there's just a cleanness to the focus that I really enjoy.
[01:05:34.140 --> 01:05:39.980]   Also when you acclimate to it, I find that the number of hours in the day that I have
[01:05:39.980 --> 01:05:42.460]   a positive mood is just larger.
[01:05:42.460 --> 01:05:47.660]   I can be cranky sometimes, especially when I'm sleep deprived, or especially when stuff
[01:05:47.660 --> 01:05:49.580]   is just not working.
[01:05:49.580 --> 01:05:55.980]   So there will always be parts of the day when I'm cranky, but it just feels, I haven't quantified
[01:05:55.980 --> 01:06:00.020]   it, but I'm pretty sure, sort of anecdotally speaking, that the number of hours I feel
[01:06:00.020 --> 01:06:07.680]   just good about the day, just grateful to be alive, is higher with keto.
[01:06:07.680 --> 01:06:10.940]   Other benefits are better sleep, I fall asleep easier.
[01:06:10.940 --> 01:06:13.460]   That might have to do with just the lower volume of food.
[01:06:13.460 --> 01:06:19.900]   I don't know, but I enjoy naps and sleep better.
[01:06:19.900 --> 01:06:24.700]   There's also just in general small aches and pains from joints when you're exercising,
[01:06:24.700 --> 01:06:25.700]   all that kinds of stuff.
[01:06:25.700 --> 01:06:28.660]   It seems to be less on keto.
[01:06:28.660 --> 01:06:31.820]   So that's just my own personal experience.
[01:06:31.820 --> 01:06:36.520]   Also when you're doing fasting and keto, because of the stable energy, you find that you can
[01:06:36.520 --> 01:06:39.300]   actually skip meals quite easily.
[01:06:39.300 --> 01:06:44.020]   So that gives you a nice gateway into fasting for longer periods of time if you like.
[01:06:44.020 --> 01:06:47.580]   There's a lot of benefits to fasting that I could talk about, but that's for another
[01:06:47.580 --> 01:06:48.580]   time.
[01:06:48.580 --> 01:06:53.740]   But in general, it gives you this freedom to live life, to enjoy life, and not be so
[01:06:53.740 --> 01:06:54.900]   obsessed about food.
[01:06:54.900 --> 01:07:00.180]   I think that's the biggest liberating thing about keto, is that if you do the keto diet
[01:07:00.180 --> 01:07:09.940]   well, that food ceases to be a kind of habitual obsession that drives the progress of the
[01:07:09.940 --> 01:07:10.940]   day.
[01:07:10.940 --> 01:07:18.620]   You, more of the day is spent kind of lost in the passions and the things you love doing.
[01:07:18.620 --> 01:07:25.980]   I just found that when I was doing the kind of many meals a day, I would find myself thinking
[01:07:25.980 --> 01:07:28.060]   about food a lot.
[01:07:28.060 --> 01:07:31.220]   It drove the structure of the day.
[01:07:31.220 --> 01:07:34.860]   It influenced a lot of the things I would talk about and think about.
[01:07:34.860 --> 01:07:37.340]   You don't really think of it that way until it's gone.
[01:07:37.340 --> 01:07:45.620]   And you notice with keto and fasting that you can spend really long hours of the day
[01:07:45.620 --> 01:07:52.300]   just doing some cool stuff that you love, and food doesn't come into play in your mind
[01:07:52.300 --> 01:07:54.900]   and your actual activity.
[01:07:54.900 --> 01:08:02.060]   My personal sort of cons of the keto diet is I enjoy eating higher volume.
[01:08:02.060 --> 01:08:04.420]   It gives you a feeling of fullness.
[01:08:04.420 --> 01:08:09.420]   And I think with a keto diet is a lower volume of food in general.
[01:08:09.420 --> 01:08:14.680]   You're still full in terms of your body not saying you're hungry, but there's not a feeling
[01:08:14.680 --> 01:08:15.680]   of real fullness.
[01:08:15.680 --> 01:08:21.820]   Now that's also a benefit because you just feel better, you feel lighter, less bloated,
[01:08:21.820 --> 01:08:22.820]   and so on.
[01:08:22.820 --> 01:08:28.380]   I find this is actually changing a lot, but keto used to be a little bit less socially
[01:08:28.380 --> 01:08:30.460]   friendly.
[01:08:30.460 --> 01:08:36.740]   Most of the fun foods, foods you associate with kind of just like going crazy at parties
[01:08:36.740 --> 01:08:40.580]   or restaurants and so on, have a ton of carbs.
[01:08:40.580 --> 01:08:47.820]   And so in social settings, it often feel like you're being restrictive and not partaking
[01:08:47.820 --> 01:08:49.780]   in the fun if you're doing a keto diet.
[01:08:49.780 --> 01:08:53.460]   I think that's changing a lot, people becoming much more accepting of it.
[01:08:53.460 --> 01:08:59.380]   For example, at McDonald's, you can order just the beef patties for $1.50 as I've talked
[01:08:59.380 --> 01:09:00.380]   about.
[01:09:00.380 --> 01:09:04.420]   And people don't look at you weird, at least in my experience, if you just get the burger
[01:09:04.420 --> 01:09:06.340]   without a bun.
[01:09:06.340 --> 01:09:09.840]   Another con is keto and carnivore just doesn't sound healthy.
[01:09:09.840 --> 01:09:14.900]   So I usually try not to talk about it too much because it just makes me feel really
[01:09:14.900 --> 01:09:15.900]   good.
[01:09:15.900 --> 01:09:18.020]   My mind focused.
[01:09:18.020 --> 01:09:23.900]   My body performs well, but I don't know if I want to sort of prescribe it to others.
[01:09:23.900 --> 01:09:28.140]   It's definitely something I recommend you try, but I just don't feel like conclusively
[01:09:28.140 --> 01:09:30.060]   saying this diet is great for everybody.
[01:09:30.060 --> 01:09:31.260]   I really don't.
[01:09:31.260 --> 01:09:33.780]   I certainly don't know enough to be able to say that.
[01:09:33.780 --> 01:09:36.760]   And also it just doesn't sound right to say that.
[01:09:36.760 --> 01:09:44.840]   And while I've loved meat my whole life, I feel the best when I eat a lot of meat.
[01:09:44.840 --> 01:09:47.580]   I do think about the ethical side of veganism.
[01:09:47.580 --> 01:09:49.700]   It's something I'm reading about now.
[01:09:49.700 --> 01:09:51.260]   I'm thinking a lot about.
[01:09:51.260 --> 01:09:53.540]   It's an ongoing journey.
[01:09:53.540 --> 01:10:00.540]   Perhaps I'll have more to say, more of my mind to be changed in the future.
[01:10:00.540 --> 01:10:01.880]   We'll see.
[01:10:01.880 --> 01:10:08.500]   But for now, for many years now, I've been really enjoying the keto diet, a mix of keto
[01:10:08.500 --> 01:10:10.720]   and carnivore diets.
[01:10:10.720 --> 01:10:12.700]   We'll see what the future holds.
[01:10:12.700 --> 01:10:19.660]   What was the darkest time in your life, and what did your road to recovery look like?
[01:10:19.660 --> 01:10:24.820]   In general, I love life, so it's difficult for me to talk about these kinds of things.
[01:10:24.820 --> 01:10:33.220]   But let me briefly say that I think the darkest times have been when I've put my faith in
[01:10:33.220 --> 01:10:42.100]   people, when I opened my heart to them, and they turned out not to be the best versions
[01:10:42.100 --> 01:10:48.580]   of themselves or maybe the kind of amazing people that I'd hope I thought they might
[01:10:48.580 --> 01:10:50.260]   be.
[01:10:50.260 --> 01:10:58.700]   So my heart has been broken in small ways in my life, as I'm sure it has been for many
[01:10:58.700 --> 01:11:00.060]   people.
[01:11:00.060 --> 01:11:07.620]   But the fire of hope still burns bright, perhaps even brighter.
[01:11:07.620 --> 01:11:09.220]   You mentioned road to recovery.
[01:11:09.220 --> 01:11:16.940]   I think the people I mentioned, I focus on the positive moments, and there always are,
[01:11:16.940 --> 01:11:23.180]   and just have gratitude for those, and just don't linger on the negative.
[01:11:23.180 --> 01:11:26.860]   I just remember the good times.
[01:11:26.860 --> 01:11:27.980]   That's how I recover.
[01:11:27.980 --> 01:11:33.060]   That's how I keep my optimism, and that's how I keep my heart open for future amazing
[01:11:33.060 --> 01:11:35.300]   people to take the risk.
[01:11:35.300 --> 01:11:38.860]   And I'm sure my heart will be broken again.
[01:11:38.860 --> 01:11:44.340]   Perhaps many times in the future, but I think it's always worth the risk.
[01:11:44.340 --> 01:11:50.740]   I like the, I wrote this down, the Marcus Aurelius quote, "Love the people with whom
[01:11:50.740 --> 01:11:55.580]   faith brings you together, and do so with all of your heart."
[01:11:55.580 --> 01:11:57.660]   I think that's all we can do.
[01:11:57.660 --> 01:12:04.660]   I hope some of these answers were at least somewhat interesting or useful.
[01:12:04.660 --> 01:12:09.060]   If so, I'll try to do it again in the future.
[01:12:09.060 --> 01:12:13.740]   It is currently 4, oh, it's 421.
[01:12:13.740 --> 01:12:17.700]   When I started saying that sentence, it was 420 AM.
[01:12:17.700 --> 01:12:21.820]   A good time to end as any, perhaps the best.
[01:12:21.820 --> 01:12:22.820]   Good night.
[01:12:22.820 --> 01:12:23.820]   I love you all.
[01:12:23.820 --> 01:12:28.860]   Thanks for listening to this AMA episode, and thank you to our sponsors, Brooklyn and
[01:12:28.860 --> 01:12:35.460]   Sheets, Indeed hiring website, ExpressVPN, and Theragun muscle recovery device.
[01:12:35.460 --> 01:12:41.780]   So the choice is sleep, employment, privacy, or muscle recovery.
[01:12:41.780 --> 01:12:43.300]   Choose wisely, my friends.
[01:12:43.300 --> 01:12:49.620]   And if you wish, click the sponsor links below to get a discount and to support this podcast.
[01:12:49.620 --> 01:12:55.420]   And now, since we talked about Einstein's thoughts about happiness and pigs, let me leave
[01:12:55.420 --> 01:12:58.340]   you with some words from Winston Churchill.
[01:12:58.340 --> 01:13:00.140]   I'm fond of pigs.
[01:13:00.140 --> 01:13:01.860]   Dogs look up to us.
[01:13:01.860 --> 01:13:03.820]   Cats look down on us.
[01:13:03.820 --> 01:13:06.700]   Pigs treat us as equals.
[01:13:06.700 --> 01:13:09.380]   Thank you for listening, and hope to see you next time.
[01:13:09.380 --> 01:13:10.380]   Bye.
[01:13:10.380 --> 01:13:10.380]   [END]
[01:13:11.380 --> 01:13:11.380]   1
[01:13:11.380 --> 01:13:12.380]   1
[01:13:12.380 --> 01:13:12.380]   1
[01:13:12.380 --> 01:13:17.380]   1

