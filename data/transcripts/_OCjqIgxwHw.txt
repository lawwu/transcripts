
[00:00:00.000 --> 00:00:03.000]   Welcome back to 6S094
[00:00:03.000 --> 00:00:05.000]   Deep Learning for Self-Driving Cars
[00:00:05.000 --> 00:00:13.000]   Today we will talk about autonomous vehicles
[00:00:13.000 --> 00:00:18.500]   Also referred to as driverless cars,
[00:00:18.500 --> 00:00:21.000]   autonomous cars, robo cars
[00:00:21.000 --> 00:00:24.200]   First, the utopian view
[00:00:27.300 --> 00:00:30.400]   where for many autonomous vehicles
[00:00:30.400 --> 00:00:32.900]   have the opportunity to transform our society
[00:00:32.900 --> 00:00:35.100]   into a positive direction
[00:00:35.100 --> 00:00:38.900]   1.3 million people die every year
[00:00:38.900 --> 00:00:40.700]   in automobile crashes
[00:00:40.700 --> 00:00:42.400]   globally
[00:00:42.400 --> 00:00:47.000]   35, 38, 40,000 die every year in the United States
[00:00:47.000 --> 00:00:50.700]   So the one opportunity that's huge
[00:00:50.700 --> 00:00:53.300]   that's one of the biggest focus for us here
[00:00:53.300 --> 00:00:55.100]   at MIT
[00:00:55.400 --> 00:00:57.300]   for people who truly care about this
[00:00:57.300 --> 00:00:59.900]   is to design autonomous systems
[00:00:59.900 --> 00:01:02.700]   artificial intelligence systems that saves lives
[00:01:02.700 --> 00:01:08.100]   And those systems help work with,
[00:01:08.100 --> 00:01:10.700]   deal with, or take away
[00:01:10.700 --> 00:01:14.500]   what NHTSA calls the four D's of human folly
[00:01:14.500 --> 00:01:19.600]   Drunk, drugged, distracted, and drowsy driving
[00:01:19.600 --> 00:01:24.100]   Autonomous vehicles have the ability to take away
[00:01:24.100 --> 00:01:25.200]   drunk driving
[00:01:26.200 --> 00:01:29.500]   distracted, drowsy, and drugged
[00:01:29.500 --> 00:01:32.000]   Eliminate car ownership
[00:01:32.000 --> 00:01:35.500]   So taking shared mobility to another level
[00:01:35.500 --> 00:01:41.600]   Eliminating car ownership from the business side
[00:01:41.600 --> 00:01:45.500]   is the opportunity to save people money
[00:01:45.500 --> 00:01:50.400]   and increase mobility and access
[00:01:50.400 --> 00:01:54.100]   Making vehicles, removing ownership
[00:01:54.100 --> 00:01:57.200]   makes vehicles more accessible
[00:01:57.200 --> 00:02:00.600]   because the cost of getting from point A to point B
[00:02:00.600 --> 00:02:04.100]   drops an order to magnitude
[00:02:04.100 --> 00:02:10.300]   And the insertion of software and intelligence
[00:02:10.300 --> 00:02:11.400]   into vehicles
[00:02:11.400 --> 00:02:13.800]   makes those vehicles,
[00:02:13.800 --> 00:02:15.900]   makes the idea of transportation
[00:02:15.900 --> 00:02:18.900]   makes the way we see moving from A to point B
[00:02:18.900 --> 00:02:20.800]   a totally different experience
[00:02:20.800 --> 00:02:23.000]   Much like with our smartphone
[00:02:23.300 --> 00:02:26.100]   it makes it a personalized, efficient,
[00:02:26.100 --> 00:02:27.800]   and reliable experience
[00:02:27.800 --> 00:02:31.400]   Now for the negative view
[00:02:31.400 --> 00:02:32.700]   for the dystopian view
[00:02:32.700 --> 00:02:36.500]   Eliminate jobs
[00:02:36.500 --> 00:02:40.400]   Any technology throughout its history
[00:02:40.400 --> 00:02:42.500]   throughout our history of human civilization
[00:02:42.500 --> 00:02:44.700]   has always created fear
[00:02:44.700 --> 00:02:48.100]   that jobs that rely on the prior technology
[00:02:48.100 --> 00:02:49.100]   will be lost
[00:02:49.100 --> 00:02:51.100]   This is a huge fear
[00:02:52.000 --> 00:02:54.000]   especially in trucking
[00:02:54.000 --> 00:02:57.300]   because so many people
[00:02:57.300 --> 00:02:59.300]   in the United States and across the world
[00:02:59.300 --> 00:03:02.300]   rely, work in the transportation industry
[00:03:02.300 --> 00:03:03.700]   transportation sector
[00:03:03.700 --> 00:03:06.400]   and the possibility that
[00:03:06.400 --> 00:03:08.400]   AI will remove those jobs
[00:03:08.400 --> 00:03:11.800]   has potential catastrophic consequences
[00:03:11.800 --> 00:03:17.800]   The idea
[00:03:18.900 --> 00:03:20.700]   one that we have to struggle with
[00:03:20.700 --> 00:03:22.200]   in the 21st century
[00:03:22.200 --> 00:03:25.200]   of the role of intelligence systems
[00:03:25.200 --> 00:03:26.900]   that aren't human beings
[00:03:26.900 --> 00:03:30.400]   being further and further integrated into our lives
[00:03:30.400 --> 00:03:33.900]   is the idea that a failure of an autonomous vehicle
[00:03:33.900 --> 00:03:35.900]   even if they're much rarer
[00:03:35.900 --> 00:03:37.700]   if they're, even if they're much safer
[00:03:37.700 --> 00:03:39.800]   that there is a possibility for
[00:03:39.800 --> 00:03:41.600]   an AI algorithm
[00:03:41.600 --> 00:03:44.700]   designed by probably one of the engineers in this room
[00:03:44.700 --> 00:03:46.400]   will kill a person
[00:03:47.500 --> 00:03:50.800]   where that person would not have died
[00:03:50.800 --> 00:03:52.900]   if they were in control of the vehicle
[00:03:52.900 --> 00:03:55.400]   The idea of an intelligence system
[00:03:55.400 --> 00:03:58.100]   one in direct interaction with a human being
[00:03:58.100 --> 00:04:00.000]   killing that human being
[00:04:00.000 --> 00:04:02.000]   is one that we have to struggle with
[00:04:02.000 --> 00:04:05.200]   on a philosophical, ethical and technological level
[00:04:05.200 --> 00:04:09.600]   Artificial intelligence systems
[00:04:09.600 --> 00:04:12.600]   in popular culture
[00:04:12.600 --> 00:04:15.800]   less so in engineering concerns
[00:04:17.000 --> 00:04:18.700]   may not be grounded
[00:04:18.700 --> 00:04:20.500]   ethically grounded
[00:04:20.500 --> 00:04:24.000]   At this time, much of the focus of building these systems
[00:04:24.000 --> 00:04:25.400]   as we'll talk about today
[00:04:25.400 --> 00:04:26.900]   and throughout this course
[00:04:26.900 --> 00:04:28.900]   the focus is on the technology
[00:04:28.900 --> 00:04:30.400]   How do we make these things work?
[00:04:30.400 --> 00:04:33.500]   But of course, decades out
[00:04:33.500 --> 00:04:35.100]   years or decades out
[00:04:35.100 --> 00:04:37.700]   the ethical concerns start arising
[00:04:37.700 --> 00:04:42.100]   For Rodney Brooks
[00:04:42.100 --> 00:04:44.900]   one of the seminal people from MIT
[00:04:45.100 --> 00:04:46.900]   those ethical concerns will not be
[00:04:46.900 --> 00:04:49.800]   an issue for another several decades
[00:04:49.800 --> 00:04:51.300]   at least five decades
[00:04:51.300 --> 00:04:53.700]   But they're still important
[00:04:53.700 --> 00:04:55.800]   It continues the thought
[00:04:55.800 --> 00:04:58.600]   the idea of what is the role of AI in our society
[00:04:58.600 --> 00:05:02.700]   When that car gets to make a decision about human life
[00:05:02.700 --> 00:05:05.700]   what is it making that decision based on?
[00:05:05.700 --> 00:05:07.800]   Especially when it's a black box
[00:05:07.800 --> 00:05:10.300]   what is the ethical grounding of that system?
[00:05:10.300 --> 00:05:12.700]   Does it conform with our social norms?
[00:05:14.000 --> 00:05:15.600]   Does it go against them?
[00:05:15.600 --> 00:05:18.300]   And there's many other concerns
[00:05:18.300 --> 00:05:21.300]   Security is definitely a big one
[00:05:21.300 --> 00:05:23.400]   A car that's
[00:05:23.400 --> 00:05:26.400]   not even artificial intelligence based
[00:05:26.400 --> 00:05:27.700]   the car that's software based
[00:05:27.700 --> 00:05:29.800]   as they're becoming more and more
[00:05:29.800 --> 00:05:32.300]   Millions, most of the cars on road today
[00:05:32.300 --> 00:05:35.400]   are run by millions of lines of source code
[00:05:35.400 --> 00:05:40.200]   The idea that those lines of source code
[00:05:40.200 --> 00:05:43.000]   written again by some of the engineers in this room
[00:05:44.000 --> 00:05:46.300]   get to decide the life of a human being
[00:05:46.300 --> 00:05:49.900]   means then a hacker from outside of the car
[00:05:49.900 --> 00:05:53.400]   can manipulate that code
[00:05:53.400 --> 00:05:56.900]   to also decide the fate of that human being
[00:05:56.900 --> 00:05:58.300]   That's a huge concern
[00:05:58.300 --> 00:06:01.000]   For us
[00:06:01.000 --> 00:06:03.500]   from the engineering perspective
[00:06:03.500 --> 00:06:06.500]   the truth is somewhere in the middle
[00:06:06.500 --> 00:06:08.700]   We want to find what is the best
[00:06:08.700 --> 00:06:11.300]   positive way we can build these systems
[00:06:11.700 --> 00:06:13.300]   to transform our society
[00:06:13.300 --> 00:06:15.100]   to improve the quality of life
[00:06:15.100 --> 00:06:17.300]   of everyone amongst us
[00:06:17.300 --> 00:06:22.900]   But there's a grain of salt
[00:06:22.900 --> 00:06:25.300]   to the hype of autonomous vehicles
[00:06:25.300 --> 00:06:27.300]   We have to remember
[00:06:27.300 --> 00:06:29.000]   as we discussed in the previous lecture
[00:06:29.000 --> 00:06:30.500]   and it will come up again and again
[00:06:30.500 --> 00:06:33.200]   our intuition about what is difficult
[00:06:33.200 --> 00:06:36.300]   and what is easy for deep learning
[00:06:36.300 --> 00:06:40.900]   for autonomous systems is flawed
[00:06:41.900 --> 00:06:42.900]   If we use our
[00:06:42.900 --> 00:06:45.300]   if you use ourselves in this example
[00:06:45.300 --> 00:06:48.600]   human beings are extremely good at driving
[00:06:48.600 --> 00:06:50.900]   This will come up again and again
[00:06:50.900 --> 00:06:54.200]   Our intuition has to be grounded
[00:06:54.200 --> 00:06:57.200]   in understanding of what is the source of data
[00:06:57.200 --> 00:06:58.700]   what is the annotation
[00:06:58.700 --> 00:07:00.100]   and what is the approach
[00:07:00.100 --> 00:07:01.300]   what is the algorithm
[00:07:01.300 --> 00:07:04.300]   So you have to be careful about using our intuition
[00:07:04.300 --> 00:07:05.900]   extending it decades out
[00:07:05.900 --> 00:07:07.200]   and making predictions
[00:07:07.200 --> 00:07:10.100]   whether it's towards the utopian or the dystopian view
[00:07:11.100 --> 00:07:13.700]   And as we'll talk about
[00:07:13.700 --> 00:07:15.700]   some of the advancements of companies
[00:07:15.700 --> 00:07:17.100]   working in the space today
[00:07:17.100 --> 00:07:19.800]   You have to take
[00:07:19.800 --> 00:07:22.000]   what people say in the media
[00:07:22.000 --> 00:07:23.600]   what the companies say
[00:07:23.600 --> 00:07:24.900]   some of the speakers
[00:07:24.900 --> 00:07:26.800]   that will be speaking at this class say
[00:07:26.800 --> 00:07:29.200]   about their plans for the future
[00:07:29.200 --> 00:07:30.800]   and their current capabilities
[00:07:30.800 --> 00:07:34.300]   I think a guide I can provide
[00:07:34.300 --> 00:07:37.600]   is when there's a promise
[00:07:37.600 --> 00:07:39.200]   of a future technology
[00:07:40.000 --> 00:07:41.100]   future vehicles
[00:07:41.100 --> 00:07:43.100]   that are two years out or more
[00:07:43.100 --> 00:07:45.300]   that has to be
[00:07:45.300 --> 00:07:48.000]   that's a very doubtful prediction
[00:07:48.000 --> 00:07:51.300]   One that is within a year
[00:07:51.300 --> 00:07:53.900]   as we'll give a few examples today
[00:07:53.900 --> 00:07:55.300]   is skeptical
[00:07:55.300 --> 00:07:58.500]   The real proof
[00:07:58.500 --> 00:07:59.600]   comes
[00:07:59.600 --> 00:08:03.500]   in actual testing on public roads
[00:08:03.500 --> 00:08:06.400]   or in the most impressive
[00:08:06.400 --> 00:08:07.900]   the most amazing
[00:08:08.700 --> 00:08:10.500]   the reality of it is when
[00:08:10.500 --> 00:08:12.700]   it's available to consumer purchase
[00:08:12.700 --> 00:08:17.100]   I would like to use Rodney Brooks
[00:08:17.100 --> 00:08:18.400]   as a
[00:08:18.400 --> 00:08:21.000]   so it doesn't come from my mouth
[00:08:21.000 --> 00:08:22.300]   but I happen to agree
[00:08:22.300 --> 00:08:28.000]   His prediction is no earlier than 2032
[00:08:28.000 --> 00:08:31.900]   a driver's taxi service in a major US city
[00:08:31.900 --> 00:08:35.500]   will provide arbitrary pickup and drop-off locations
[00:08:35.500 --> 00:08:36.500]   fully autonomously
[00:08:38.300 --> 00:08:39.700]   That's 14 years away
[00:08:39.700 --> 00:08:45.200]   and by 2045
[00:08:45.200 --> 00:08:46.800]   it will do so in multiple cities
[00:08:46.800 --> 00:08:48.000]   across the United States
[00:08:48.000 --> 00:08:49.700]   So think about that
[00:08:49.700 --> 00:08:51.700]   that a lot of the engineers
[00:08:51.700 --> 00:08:52.700]   work in this space
[00:08:52.700 --> 00:08:53.700]   a lot of folks
[00:08:53.700 --> 00:08:55.300]   who are actually building these systems
[00:08:55.300 --> 00:08:56.500]   agree with this idea
[00:08:56.500 --> 00:08:59.500]   and that is the earliest
[00:08:59.500 --> 00:09:02.000]   I believe this will happen
[00:09:02.000 --> 00:09:03.100]   and Rodney believes
[00:09:03.100 --> 00:09:05.100]   but
[00:09:08.100 --> 00:09:10.100]   as all technophobes have been wrong
[00:09:10.100 --> 00:09:11.100]   who could be wrong
[00:09:11.100 --> 00:09:15.300]   This is a map on the x-axis
[00:09:15.300 --> 00:09:17.600]   a plot on the x-axis of time
[00:09:17.600 --> 00:09:19.600]   throughout the 20th century
[00:09:19.600 --> 00:09:21.800]   and the adoption rate on the y-axis
[00:09:21.800 --> 00:09:23.500]   from 0 to 100%
[00:09:23.500 --> 00:09:25.100]   of the various technologies
[00:09:25.100 --> 00:09:26.400]   from electricity to cars
[00:09:26.400 --> 00:09:28.700]   to radio to telephone and so on
[00:09:28.700 --> 00:09:31.000]   and as we get closer to today
[00:09:31.000 --> 00:09:33.100]   the technology adoption rate
[00:09:33.100 --> 00:09:35.800]   when it goes from 0 to 100%
[00:09:36.400 --> 00:09:38.200]   the number of years it takes
[00:09:38.200 --> 00:09:39.600]   to adopt that technology
[00:09:39.600 --> 00:09:42.100]   is getting shorter and shorter and shorter
[00:09:42.100 --> 00:09:44.300]   as a society we're better
[00:09:44.300 --> 00:09:46.700]   at throwing away the technology of old
[00:09:46.700 --> 00:09:48.400]   and accepting a technology of new
[00:09:48.400 --> 00:09:52.200]   So if a brilliant idea
[00:09:52.200 --> 00:09:53.900]   to solve some of the problems we're discussing
[00:09:53.900 --> 00:09:54.600]   comes along
[00:09:54.600 --> 00:09:55.800]   it could change everything
[00:09:55.800 --> 00:09:57.000]   overnight
[00:09:57.000 --> 00:10:02.000]   So let's talk about
[00:10:02.000 --> 00:10:03.400]   different approaches to autonomy
[00:10:05.300 --> 00:10:07.500]   We'll talk about sensors afterwards
[00:10:07.500 --> 00:10:09.500]   We'll talk about companies
[00:10:09.500 --> 00:10:10.900]   players in this space
[00:10:10.900 --> 00:10:13.500]   and then we'll talk about AI
[00:10:13.500 --> 00:10:17.700]   and the actual algorithms
[00:10:17.700 --> 00:10:19.600]   and how they can help
[00:10:19.600 --> 00:10:22.300]   solve some of the problems of autonomous vehicles
[00:10:22.300 --> 00:10:25.200]   Levels of autonomy
[00:10:25.200 --> 00:10:27.800]   Here's a useful
[00:10:27.800 --> 00:10:31.800]   taxonomization
[00:10:31.800 --> 00:10:35.100]   of levels of autonomy
[00:10:35.800 --> 00:10:37.600]   useful for initial discussion
[00:10:37.600 --> 00:10:39.600]   for legal discussion
[00:10:39.600 --> 00:10:41.300]   and for policymaking
[00:10:41.300 --> 00:10:44.700]   and for blog posts and media reports
[00:10:44.700 --> 00:10:46.800]   but it's not useful
[00:10:46.800 --> 00:10:49.100]   I would argue for design and engineering
[00:10:49.100 --> 00:10:50.700]   of the underlying intelligence
[00:10:50.700 --> 00:10:53.400]   and the system viewed
[00:10:53.400 --> 00:10:54.800]   from a holistic perspective
[00:10:54.800 --> 00:10:56.000]   the entire thing
[00:10:56.000 --> 00:10:57.700]   creating an experience
[00:10:57.700 --> 00:10:58.900]   that's safe and enjoyable
[00:10:58.900 --> 00:11:00.600]   So let's go over those levels
[00:11:00.600 --> 00:11:03.200]   The five, the six levels
[00:11:04.200 --> 00:11:09.000]   This is presented by SAE report J3016
[00:11:09.000 --> 00:11:10.700]   the most widely accepted
[00:11:10.700 --> 00:11:12.700]   taxonomization of autonomy
[00:11:12.700 --> 00:11:15.300]   No automation at level zero
[00:11:15.300 --> 00:11:17.100]   Level one and level two
[00:11:17.100 --> 00:11:18.700]   is increasing levels automation
[00:11:18.700 --> 00:11:19.900]   Level one is
[00:11:19.900 --> 00:11:21.200]   cruise control
[00:11:21.200 --> 00:11:23.300]   Level two is adaptive cruise control
[00:11:23.300 --> 00:11:24.200]   lane keeping
[00:11:24.200 --> 00:11:25.700]   Level three
[00:11:25.700 --> 00:11:28.200]   I don't know what level three is
[00:11:28.200 --> 00:11:29.900]   There's a lot of people that will explain
[00:11:29.900 --> 00:11:32.800]   that level three is conditional automation
[00:11:32.800 --> 00:11:34.200]   meaning it's constrained
[00:11:34.200 --> 00:11:35.900]   to certain geographic location
[00:11:35.900 --> 00:11:37.400]   I will explain that
[00:11:37.400 --> 00:11:38.900]   from an engineering perspective
[00:11:38.900 --> 00:11:41.300]   I'm personally a little bit
[00:11:41.300 --> 00:11:44.500]   confused of where that stands
[00:11:44.500 --> 00:11:46.800]   I'll try to redefine
[00:11:46.800 --> 00:11:48.400]   how we should view automation
[00:11:48.400 --> 00:11:50.500]   Level four and level five
[00:11:50.500 --> 00:11:53.300]   is high full level automation
[00:11:53.300 --> 00:11:55.600]   Level four is when the vehicle
[00:11:55.600 --> 00:11:57.800]   can drive itself fully
[00:11:57.800 --> 00:11:59.700]   for part of the time
[00:11:59.700 --> 00:12:00.800]   There's certain areas
[00:12:00.800 --> 00:12:02.200]   in which you can take care of
[00:12:02.200 --> 00:12:03.600]   everything no matter what
[00:12:03.600 --> 00:12:06.100]   no human interaction
[00:12:06.100 --> 00:12:07.400]   input
[00:12:07.400 --> 00:12:09.600]   safekeeping is required
[00:12:09.600 --> 00:12:11.800]   Level five automation
[00:12:11.800 --> 00:12:13.200]   is the car does everything
[00:12:13.200 --> 00:12:15.600]   Everything
[00:12:15.600 --> 00:12:19.800]   I would argue that those levels
[00:12:19.800 --> 00:12:21.600]   aren't useful
[00:12:21.600 --> 00:12:23.600]   for designing systems
[00:12:23.600 --> 00:12:25.300]   that actually work in the real world
[00:12:25.300 --> 00:12:27.400]   I would argue that there's two systems
[00:12:27.400 --> 00:12:29.800]   But first a starting point
[00:12:29.800 --> 00:12:31.000]   that every system
[00:12:31.900 --> 00:12:34.200]   to some degree involves a human
[00:12:34.200 --> 00:12:37.400]   It starts with manual control
[00:12:37.400 --> 00:12:38.200]   from a human
[00:12:38.200 --> 00:12:40.800]   Human getting in the car
[00:12:40.800 --> 00:12:43.800]   and a human electing to do something
[00:12:43.800 --> 00:12:46.100]   So that's the manual control
[00:12:46.100 --> 00:12:47.600]   What we're talking about
[00:12:47.600 --> 00:12:49.600]   when the human engages the system
[00:12:49.600 --> 00:12:52.800]   when the system is first available
[00:12:52.800 --> 00:12:55.600]   and the human chooses to turn it on
[00:12:55.600 --> 00:12:59.100]   That's when we have two AI systems
[00:12:59.100 --> 00:13:01.400]   Human-centered autonomy
[00:13:01.900 --> 00:13:04.000]   when the human is needed
[00:13:04.000 --> 00:13:05.000]   is involved
[00:13:05.000 --> 00:13:06.900]   and full autonomy
[00:13:06.900 --> 00:13:09.000]   when AI is fully responsible
[00:13:09.000 --> 00:13:09.800]   for everything
[00:13:09.800 --> 00:13:11.300]   from the legal perspective
[00:13:11.300 --> 00:13:12.200]   that means
[00:13:12.200 --> 00:13:14.600]   A2 full autonomy
[00:13:14.600 --> 00:13:15.900]   means the car
[00:13:15.900 --> 00:13:17.600]   the designer the AI system
[00:13:17.600 --> 00:13:18.700]   is liable
[00:13:18.700 --> 00:13:20.200]   is responsible
[00:13:20.200 --> 00:13:22.800]   and for the human-centered autonomy
[00:13:22.800 --> 00:13:24.300]   the human is responsible
[00:13:24.300 --> 00:13:28.700]   What does this practically mean?
[00:13:30.300 --> 00:13:31.800]   For human-centered autonomy
[00:13:31.800 --> 00:13:34.900]   and we'll discuss examples of all of these
[00:13:34.900 --> 00:13:38.400]   when a human interaction is necessary
[00:13:38.400 --> 00:13:41.800]   The question then becomes
[00:13:41.800 --> 00:13:43.400]   is how often
[00:13:43.400 --> 00:13:46.100]   is the system available?
[00:13:46.100 --> 00:13:48.100]   Is it available on
[00:13:48.100 --> 00:13:50.200]   in traffic conditions?
[00:13:50.200 --> 00:13:52.300]   So for traffic bumper to bumper
[00:13:52.300 --> 00:13:53.600]   is available on the highway
[00:13:53.600 --> 00:13:54.900]   Is it sensor based?
[00:13:54.900 --> 00:13:56.200]   Like in the Tesla vehicle
[00:13:56.200 --> 00:13:58.700]   meaning based on the visual characteristics
[00:13:58.700 --> 00:13:59.500]   of the scene
[00:13:59.800 --> 00:14:01.100]   the vehicle is confident enough
[00:14:01.100 --> 00:14:02.400]   to be able to control
[00:14:02.400 --> 00:14:04.100]   to make control decisions
[00:14:04.100 --> 00:14:06.100]   perception control decisions
[00:14:06.100 --> 00:14:08.700]   The other factor
[00:14:08.700 --> 00:14:12.200]   not discussed enough
[00:14:12.200 --> 00:14:14.300]   and I think poorly
[00:14:14.300 --> 00:14:16.900]   imprecisely discussed when it is
[00:14:16.900 --> 00:14:19.100]   is the number of seconds
[00:14:19.100 --> 00:14:21.700]   given to the driver
[00:14:21.700 --> 00:14:23.400]   not guaranteed
[00:14:23.400 --> 00:14:24.800]   but provided
[00:14:24.800 --> 00:14:26.200]   as a sort of feature
[00:14:26.200 --> 00:14:27.600]   to the driver to take over
[00:14:27.600 --> 00:14:29.300]   In the Tesla vehicle
[00:14:29.300 --> 00:14:31.100]   in all vehicles on the road today
[00:14:31.100 --> 00:14:32.800]   that time is zero
[00:14:32.800 --> 00:14:34.400]   zero seconds are guaranteed
[00:14:34.400 --> 00:14:36.000]   zero seconds are provided
[00:14:36.000 --> 00:14:37.100]   There is some
[00:14:37.100 --> 00:14:38.600]   there's some room
[00:14:38.600 --> 00:14:39.600]   sometimes it's
[00:14:39.600 --> 00:14:40.900]   hundreds of milliseconds
[00:14:40.900 --> 00:14:42.200]   sometimes it's multiple seconds
[00:14:42.200 --> 00:14:44.100]   but really there's no standard
[00:14:44.100 --> 00:14:45.400]   of how many seconds
[00:14:45.400 --> 00:14:47.300]   you get to say
[00:14:47.300 --> 00:14:49.600]   wake up, take control
[00:14:49.600 --> 00:14:52.000]   Then
[00:14:52.000 --> 00:14:54.600]   tele-operation
[00:14:54.600 --> 00:14:56.700]   something that some of the companies
[00:14:56.700 --> 00:14:58.200]   will mention or playing with
[00:14:58.500 --> 00:15:00.400]   is when a human being is involved
[00:15:00.400 --> 00:15:01.200]   remotely
[00:15:01.200 --> 00:15:02.800]   controlling the vehicle remotely
[00:15:02.800 --> 00:15:04.300]   so being able to take over
[00:15:04.300 --> 00:15:05.600]   control of the vehicle
[00:15:05.600 --> 00:15:06.800]   when you're
[00:15:06.800 --> 00:15:09.600]   when you're not able to control it
[00:15:09.600 --> 00:15:11.600]   So support by a human
[00:15:11.600 --> 00:15:13.000]   that's not inside the car
[00:15:13.000 --> 00:15:15.500]   That's a very interesting idea to explore
[00:15:15.500 --> 00:15:19.400]   But for the human-centered autonomy side
[00:15:19.400 --> 00:15:22.700]   all of those features are not required
[00:15:22.700 --> 00:15:23.900]   they're not guaranteed
[00:15:23.900 --> 00:15:25.100]   the human driver
[00:15:25.100 --> 00:15:25.900]   the human
[00:15:25.900 --> 00:15:27.500]   inside the car
[00:15:27.500 --> 00:15:28.800]   is always responsible
[00:15:28.800 --> 00:15:29.700]   at the end of the day
[00:15:29.700 --> 00:15:31.100]   they must pay attention
[00:15:31.100 --> 00:15:32.700]   to a degree that's required
[00:15:32.700 --> 00:15:34.600]   to take over when the system fails
[00:15:34.600 --> 00:15:36.100]   And no matter
[00:15:36.100 --> 00:15:37.700]   under this consideration
[00:15:37.700 --> 00:15:38.500]   under this
[00:15:38.500 --> 00:15:40.300]   level of autonomy
[00:15:40.300 --> 00:15:42.100]   the system will fail
[00:15:42.100 --> 00:15:43.500]   at some point
[00:15:43.500 --> 00:15:44.200]   That is the
[00:15:44.200 --> 00:15:45.200]   that is the point
[00:15:45.200 --> 00:15:46.200]   that is the collaboration
[00:15:46.200 --> 00:15:47.400]   between human and robot
[00:15:47.400 --> 00:15:48.900]   is the system will fail
[00:15:48.900 --> 00:15:50.400]   and the human has to catch
[00:15:50.400 --> 00:15:51.900]   it when it does
[00:15:51.900 --> 00:15:54.800]   And then full autonomy
[00:15:56.300 --> 00:15:58.200]   is AI is fully responsible
[00:15:58.200 --> 00:16:00.200]   Now that doesn't
[00:16:00.200 --> 00:16:02.800]   again as we'll present some companies
[00:16:02.800 --> 00:16:04.100]   in the marketing material
[00:16:04.100 --> 00:16:05.800]   and the PR side of things
[00:16:05.800 --> 00:16:07.100]   they might present that
[00:16:07.100 --> 00:16:09.300]   there is significant degrees of autonomy
[00:16:09.300 --> 00:16:10.900]   If you're talking about L3
[00:16:10.900 --> 00:16:12.000]   or L4
[00:16:12.000 --> 00:16:13.800]   or L5
[00:16:13.800 --> 00:16:16.200]   you have to read between the lines
[00:16:16.200 --> 00:16:19.100]   You're not allowed to have
[00:16:19.100 --> 00:16:20.500]   teleoperation
[00:16:20.500 --> 00:16:25.400]   If a human is remotely operating the vehicle
[00:16:25.700 --> 00:16:27.600]   a human is still in the loop
[00:16:27.600 --> 00:16:29.600]   a human is still evolved
[00:16:29.600 --> 00:16:32.100]   It's still a human-centered autonomy system
[00:16:32.100 --> 00:16:35.300]   You don't get the 10-second rule
[00:16:35.300 --> 00:16:36.600]   which is
[00:16:36.600 --> 00:16:40.800]   just because you give the driver
[00:16:40.800 --> 00:16:42.600]   10 seconds to take control
[00:16:42.600 --> 00:16:45.400]   that somehow removes liability for you
[00:16:45.400 --> 00:16:46.500]   If you say that
[00:16:46.500 --> 00:16:47.800]   that's it
[00:16:47.800 --> 00:16:48.900]   as an AI system
[00:16:48.900 --> 00:16:49.700]   I can't take
[00:16:49.700 --> 00:16:52.800]   can't resolve
[00:16:52.800 --> 00:16:53.500]   can't deal
[00:16:53.500 --> 00:16:55.500]   can't control the vehicle in this situation
[00:16:56.000 --> 00:16:57.500]   and you have 10 seconds to take over
[00:16:57.500 --> 00:16:58.600]   that's not good enough
[00:16:58.600 --> 00:17:00.000]   The driver might be sleeping
[00:17:00.000 --> 00:17:01.700]   that driver may have had a heart attack
[00:17:01.700 --> 00:17:03.400]   they're not able to control the vehicle
[00:17:03.400 --> 00:17:06.100]   Full autonomous systems
[00:17:06.100 --> 00:17:08.400]   must find safe harbor
[00:17:08.400 --> 00:17:10.000]   They must get you
[00:17:10.000 --> 00:17:11.700]   full stop
[00:17:11.700 --> 00:17:13.600]   from point A to point B
[00:17:13.600 --> 00:17:16.000]   that point B might be your desired destination
[00:17:16.000 --> 00:17:18.100]   or might be a safe parking lot
[00:17:18.100 --> 00:17:21.500]   but it has to bring you to a safe location
[00:17:21.500 --> 00:17:24.200]   This is a clear definition of the two systems
[00:17:25.200 --> 00:17:26.500]   and the human of course
[00:17:26.500 --> 00:17:28.500]   as far as our certain
[00:17:28.500 --> 00:17:30.000]   current conception
[00:17:30.000 --> 00:17:32.500]   of artificial intelligence and cars today
[00:17:32.500 --> 00:17:35.900]   is a human always overrides the AI system
[00:17:35.900 --> 00:17:37.400]   So we should
[00:17:37.400 --> 00:17:38.900]   for the
[00:17:38.900 --> 00:17:40.400]   in the general case
[00:17:40.400 --> 00:17:43.100]   the human
[00:17:43.100 --> 00:17:46.000]   gets to choose to take control
[00:17:46.000 --> 00:17:48.500]   The AI can't take control of the human
[00:17:48.500 --> 00:17:50.500]   except when danger is imminent
[00:17:50.500 --> 00:17:53.800]   meaning sudden crashes like in AAB events
[00:17:54.300 --> 00:17:57.200]   We're not yet ready for the AI systems to say
[00:17:57.200 --> 00:17:59.200]   as a society to say
[00:17:59.200 --> 00:18:00.800]   no no no you're drunk
[00:18:00.800 --> 00:18:02.300]   you can't drive
[00:18:02.300 --> 00:18:08.900]   So beyond the traditional levels
[00:18:08.900 --> 00:18:11.000]   from level 0 to level 5
[00:18:11.000 --> 00:18:13.100]   the starting point is level 0
[00:18:13.100 --> 00:18:14.000]   no automation
[00:18:14.000 --> 00:18:15.200]   all cars start here
[00:18:15.200 --> 00:18:17.800]   Level 1, level 2 and level 3
[00:18:17.800 --> 00:18:22.200]   I would argue fall into human-centered autonomy systems
[00:18:22.200 --> 00:18:23.400]   A1
[00:18:24.400 --> 00:18:28.100]   because they involve some degree of a human
[00:18:28.100 --> 00:18:30.100]   Then L4, L5
[00:18:30.100 --> 00:18:31.900]   to some degree
[00:18:31.900 --> 00:18:33.000]   there's some crossover
[00:18:33.000 --> 00:18:34.500]   fall into full autonomy
[00:18:34.500 --> 00:18:36.900]   Even though with L4
[00:18:36.900 --> 00:18:38.100]   with Waymo
[00:18:38.100 --> 00:18:39.900]   as you can ask on Friday
[00:18:39.900 --> 00:18:42.500]   and anyone cruise
[00:18:42.500 --> 00:18:44.700]   Uber playing in this space
[00:18:44.700 --> 00:18:47.800]   there's very often a human driver involved
[00:18:47.800 --> 00:18:52.000]   One of the huge accomplishments of Waymo
[00:18:52.900 --> 00:18:54.100]   over the past month
[00:18:54.100 --> 00:18:55.800]   incredible accomplishment
[00:18:55.800 --> 00:18:57.200]   where in Phoenix, Arizona
[00:18:57.200 --> 00:18:58.400]   they drove without
[00:18:58.400 --> 00:19:01.000]   the car drove without a driver
[00:19:01.000 --> 00:19:06.000]   meaning there was no safety driver to catch
[00:19:06.000 --> 00:19:07.900]   there's no engineer staff member
[00:19:07.900 --> 00:19:10.200]   there to catch the car
[00:19:10.200 --> 00:19:13.900]   A human being that doesn't work for Google or Waymo
[00:19:13.900 --> 00:19:15.500]   got into that car
[00:19:15.500 --> 00:19:18.400]   and got from A to point B without a safety driver
[00:19:18.400 --> 00:19:20.700]   That's an incredible accomplishment
[00:19:21.100 --> 00:19:22.900]   and that particular trip
[00:19:22.900 --> 00:19:25.500]   was a fully autonomous trip
[00:19:25.500 --> 00:19:28.000]   That is full autonomy
[00:19:28.000 --> 00:19:31.100]   when there's no human to catch the car
[00:19:31.100 --> 00:19:38.700]   No AI presentation is good without cats
[00:19:38.700 --> 00:19:41.900]   So full autonomy A2 system
[00:19:41.900 --> 00:19:47.000]   is when you do nothing but ride along
[00:19:47.000 --> 00:19:49.800]   human-centered autonomy system
[00:19:50.800 --> 00:19:52.800]   is when you have some control
[00:19:52.800 --> 00:19:55.500]   I'm sorry I had to
[00:19:55.500 --> 00:20:00.500]   So the two paths for autonomous systems
[00:20:00.500 --> 00:20:01.600]   A1 and A2
[00:20:01.600 --> 00:20:05.200]   In blue on the left is A1 human-centered
[00:20:05.200 --> 00:20:07.600]   on the right is A2 full autonomy
[00:20:07.600 --> 00:20:10.900]   And then blue
[00:20:10.900 --> 00:20:13.700]   is from the artificial intelligence perspective
[00:20:13.700 --> 00:20:17.900]   is easy
[00:20:17.900 --> 00:20:19.300]   easier
[00:20:19.600 --> 00:20:21.100]   and then red is harder
[00:20:21.100 --> 00:20:23.300]   easier meaning
[00:20:23.300 --> 00:20:27.100]   we do not have to achieve a hundred percent accuracy
[00:20:27.100 --> 00:20:29.000]   harder means
[00:20:29.000 --> 00:20:32.900]   everything that's off of a hundred percent accuracy
[00:20:32.900 --> 00:20:35.100]   no matter how small
[00:20:35.100 --> 00:20:37.300]   has a potential of costing
[00:20:37.300 --> 00:20:38.900]   human lives
[00:20:38.900 --> 00:20:43.300]   and huge amounts of money for companies
[00:20:43.300 --> 00:20:48.400]   So let's discuss
[00:20:49.300 --> 00:20:51.800]   we'll discuss later in the lecture
[00:20:51.800 --> 00:20:54.300]   about the algorithms behind each of these methods
[00:20:54.300 --> 00:20:55.500]   on the left and the right
[00:20:55.500 --> 00:20:59.400]   But this summarizes the two approaches
[00:20:59.400 --> 00:21:01.100]   the localization mapping
[00:21:01.100 --> 00:21:03.400]   for the car to determine where it's located
[00:21:03.400 --> 00:21:06.600]   for the human-centered autonomy
[00:21:06.600 --> 00:21:07.600]   It's easy
[00:21:07.600 --> 00:21:09.900]   It still has to do the perception
[00:21:09.900 --> 00:21:12.300]   It has to localize itself within the lane
[00:21:12.300 --> 00:21:15.100]   It has to find all the neighboring pedestrians
[00:21:15.100 --> 00:21:16.000]   and the vehicles
[00:21:16.000 --> 00:21:17.500]   in order to be able to
[00:21:17.700 --> 00:21:19.400]   control the vehicle to some degree
[00:21:19.400 --> 00:21:21.500]   But because a human is there
[00:21:21.500 --> 00:21:23.100]   it doesn't have to do so perfectly
[00:21:23.100 --> 00:21:25.400]   When it fails a human is there to catch it
[00:21:25.400 --> 00:21:27.400]   Scene understanding
[00:21:27.400 --> 00:21:29.300]   perceiving everything in the environment
[00:21:29.300 --> 00:21:30.100]   from the camera
[00:21:30.100 --> 00:21:32.700]   from whether it's LiDAR, radar, ultrasonic
[00:21:32.700 --> 00:21:35.300]   The planning of the vehicle
[00:21:35.300 --> 00:21:37.900]   whether it's just staying within lane
[00:21:37.900 --> 00:21:39.500]   or for adaptive cruise control
[00:21:39.500 --> 00:21:42.100]   controlling the longitudinal movement of the vehicle
[00:21:42.100 --> 00:21:43.600]   or it's changing lanes
[00:21:43.600 --> 00:21:44.800]   as the Tesla autopilot
[00:21:44.800 --> 00:21:46.500]   or higher degrees of automation
[00:21:46.800 --> 00:21:48.900]   All of those movement planning decisions
[00:21:48.900 --> 00:21:50.200]   can be made autonomously
[00:21:50.200 --> 00:21:51.600]   when the human is there to catch
[00:21:51.600 --> 00:21:53.000]   It's easier
[00:21:53.000 --> 00:21:55.000]   because you're allowed to be wrong
[00:21:55.000 --> 00:21:56.600]   rarely but wrong
[00:21:56.600 --> 00:21:58.600]   The hard part
[00:21:58.600 --> 00:22:01.300]   is getting the human-robot interaction piece right
[00:22:01.300 --> 00:22:03.200]   That's
[00:22:03.200 --> 00:22:07.100]   next Wednesday lecture
[00:22:07.100 --> 00:22:09.100]   as we'll discuss about
[00:22:09.100 --> 00:22:11.600]   how deep learning can be used to interact
[00:22:11.600 --> 00:22:14.000]   first perceive everything about the driver
[00:22:14.000 --> 00:22:16.100]   and second to interact with the driver
[00:22:17.100 --> 00:22:18.400]   That part is hard
[00:22:18.400 --> 00:22:20.800]   because you can't screw up on that part
[00:22:20.800 --> 00:22:23.300]   You have to make sure you help the driver
[00:22:23.300 --> 00:22:25.100]   know where your flaws are
[00:22:25.100 --> 00:22:26.200]   so they can take over
[00:22:26.200 --> 00:22:28.000]   If the driver is not paying attention
[00:22:28.000 --> 00:22:29.900]   you have to bring their attention back to the road
[00:22:29.900 --> 00:22:31.600]   back to the interaction
[00:22:31.600 --> 00:22:33.400]   You have to get that piece right
[00:22:33.400 --> 00:22:35.400]   because for a flawed system
[00:22:35.400 --> 00:22:37.500]   one that's rarely flawed
[00:22:37.500 --> 00:22:40.000]   the rarity is the challenge in fact
[00:22:40.000 --> 00:22:42.400]   has to get the interaction right
[00:22:42.400 --> 00:22:45.900]   And then the final piece communication
[00:22:46.900 --> 00:22:48.400]   Autonomous vehicle
[00:22:48.400 --> 00:22:49.500]   a fully autonomous vehicle
[00:22:49.500 --> 00:22:52.600]   must communicate extremely well
[00:22:52.600 --> 00:22:54.400]   with the external world
[00:22:54.400 --> 00:22:56.600]   with the pedestrians, the jaywalkers
[00:22:56.600 --> 00:22:58.900]   the humans in this world, the cyclists
[00:22:58.900 --> 00:23:01.300]   That communication piece
[00:23:01.300 --> 00:23:03.800]   one at least that is part of a safe
[00:23:03.800 --> 00:23:06.200]   and enjoyable driving experience
[00:23:06.200 --> 00:23:07.800]   is extremely difficult
[00:23:07.800 --> 00:23:10.100]   A way more vehicle
[00:23:10.100 --> 00:23:12.400]   I wish them luck if they come to Boston
[00:23:12.400 --> 00:23:14.900]   from getting from point A to point B
[00:23:15.400 --> 00:23:17.900]   because pedestrians will take advantage
[00:23:17.900 --> 00:23:21.100]   A vehicle must assert itself
[00:23:21.100 --> 00:23:24.400]   in order to be able to navigate Boston streets
[00:23:24.400 --> 00:23:28.100]   And that assertion is communication
[00:23:28.100 --> 00:23:31.000]   That piece is extremely difficult
[00:23:31.000 --> 00:23:33.600]   For a Tesla vehicle
[00:23:33.600 --> 00:23:37.800]   for a human-centered autonomy vehicle
[00:23:37.800 --> 00:23:39.500]   L2, L3
[00:23:39.500 --> 00:23:43.700]   The way you deal with Boston pedestrians
[00:23:43.700 --> 00:23:44.800]   is you take over
[00:23:45.800 --> 00:23:47.500]   roll down the window, yell something
[00:23:47.500 --> 00:23:48.500]   and then speed up
[00:23:48.500 --> 00:23:52.400]   Getting the piece
[00:23:52.400 --> 00:23:54.000]   for an artificial intelligence system
[00:23:54.000 --> 00:23:55.600]   to actually be able to accomplish
[00:23:55.600 --> 00:23:56.400]   something like that
[00:23:56.400 --> 00:23:57.300]   as we'll discuss
[00:23:57.300 --> 00:23:59.100]   on the ethics side
[00:23:59.100 --> 00:24:00.100]   and the engineering side
[00:24:00.100 --> 00:24:01.300]   is extremely difficult
[00:24:01.300 --> 00:24:03.900]   That said
[00:24:03.900 --> 00:24:05.400]   most of the literature
[00:24:05.400 --> 00:24:06.700]   in the human factors field
[00:24:06.700 --> 00:24:08.900]   in the autonomous vehicle field
[00:24:08.900 --> 00:24:11.900]   Anyone that studied autonomy in aviation
[00:24:11.900 --> 00:24:14.300]   and in vehicles
[00:24:14.400 --> 00:24:15.900]   is extremely skeptical
[00:24:15.900 --> 00:24:17.400]   about the human-centered approach
[00:24:17.400 --> 00:24:19.400]   They think it's deeply irresponsible
[00:24:19.400 --> 00:24:21.600]   It's deeply irresponsible
[00:24:21.600 --> 00:24:24.600]   because, as argued
[00:24:24.600 --> 00:24:25.700]   because
[00:24:25.700 --> 00:24:28.100]   human beings
[00:24:28.100 --> 00:24:29.300]   when you give them
[00:24:29.300 --> 00:24:31.200]   a technology
[00:24:31.200 --> 00:24:34.200]   which will take control part of the time
[00:24:34.200 --> 00:24:35.300]   they will get lazy
[00:24:35.300 --> 00:24:37.000]   they will take advantage of that technology
[00:24:37.000 --> 00:24:38.800]   they will over trust that technology
[00:24:38.800 --> 00:24:41.300]   they'll assume it'll work perfectly always
[00:24:41.300 --> 00:24:43.400]   This is the idea
[00:24:44.400 --> 00:24:45.900]   that this
[00:24:45.900 --> 00:24:49.600]   this idea extended beyond
[00:24:49.600 --> 00:24:50.700]   further and further
[00:24:50.700 --> 00:24:52.000]   means that
[00:24:52.000 --> 00:24:53.500]   the better the system gets
[00:24:53.500 --> 00:24:55.800]   the better the car gets at driving itself
[00:24:55.800 --> 00:24:57.800]   the more the humans will sit back
[00:24:57.800 --> 00:24:59.500]   and be completely distracted
[00:24:59.500 --> 00:25:01.700]   It will not be able to re-engage themselves
[00:25:01.700 --> 00:25:03.300]   in order to safely catch
[00:25:03.300 --> 00:25:04.600]   when the system fails
[00:25:04.600 --> 00:25:06.700]   This is Chris Urmson
[00:25:06.700 --> 00:25:09.100]   the founder of the Google self-driving cars program
[00:25:09.100 --> 00:25:11.200]   and
[00:25:11.500 --> 00:25:14.000]   now the co-founder of one
[00:25:14.000 --> 00:25:16.400]   the other co-founder is the speaker of this class
[00:25:16.400 --> 00:25:18.200]   on next Friday Sterling Anderson
[00:25:18.200 --> 00:25:20.500]   of a company called Aurora
[00:25:20.500 --> 00:25:21.500]   a startup
[00:25:21.500 --> 00:25:24.500]   He was one of the big proponents
[00:25:24.500 --> 00:25:28.800]   or the
[00:25:28.800 --> 00:25:29.800]   I should say
[00:25:29.800 --> 00:25:31.400]   opponents
[00:25:31.400 --> 00:25:34.200]   of the idea that human-centered autonomy could work
[00:25:34.200 --> 00:25:36.200]   They tried it
[00:25:36.200 --> 00:25:39.000]   Publicly is spoken about
[00:25:39.000 --> 00:25:40.200]   the fact that Google
[00:25:40.400 --> 00:25:42.500]   as in the early self-driving car program
[00:25:42.500 --> 00:25:45.100]   they've tried shared autonomy
[00:25:45.100 --> 00:25:46.600]   they've tried L2
[00:25:46.600 --> 00:25:48.500]   and it failed
[00:25:48.500 --> 00:25:49.800]   because their engineers
[00:25:49.800 --> 00:25:51.800]   the people driving their vehicles fell asleep
[00:25:51.800 --> 00:25:56.100]   and that's the belief that people have
[00:25:56.100 --> 00:25:59.600]   and we'll talk about why that may not be true
[00:25:59.600 --> 00:26:02.200]   There's a fascinating truth in the way
[00:26:02.200 --> 00:26:06.300]   human beings can interact with artificial intelligence systems
[00:26:06.300 --> 00:26:08.900]   that may work in this case
[00:26:09.400 --> 00:26:11.700]   as I mentioned it's the human-robot interaction
[00:26:11.700 --> 00:26:15.200]   building that deep connection between human and machine
[00:26:15.200 --> 00:26:16.500]   of understanding
[00:26:16.500 --> 00:26:18.500]   of communication
[00:26:18.500 --> 00:26:22.800]   This is what we believe happens
[00:26:22.800 --> 00:26:24.700]   so there's a lot of videos like this
[00:26:24.700 --> 00:26:26.300]   it's fun
[00:26:26.300 --> 00:26:28.500]   but it's also representative of
[00:26:28.500 --> 00:26:33.200]   what society believes happens when automation
[00:26:33.200 --> 00:26:38.100]   is allowed to enter the human experience
[00:26:38.600 --> 00:26:41.300]   and driving where human life is at stake
[00:26:41.300 --> 00:26:45.300]   that you can become completely disengaged
[00:26:45.300 --> 00:26:52.800]   It's kind of
[00:26:52.800 --> 00:26:57.500]   it's kind of a natural thing to think
[00:26:57.500 --> 00:26:59.300]   but the question is
[00:26:59.300 --> 00:27:01.600]   does this actually happen?
[00:27:01.600 --> 00:27:05.500]   What actually happens on public roads?
[00:27:06.300 --> 00:27:09.300]   The amazing thing that people don't often talk about
[00:27:09.300 --> 00:27:13.400]   is that there is
[00:27:13.400 --> 00:27:18.700]   hundreds of thousands of vehicles on the road today
[00:27:18.700 --> 00:27:21.600]   equipped with autopilot
[00:27:21.600 --> 00:27:24.000]   Tesla autopilot
[00:27:24.000 --> 00:27:27.400]   that have a significant degree of autonomy
[00:27:27.400 --> 00:27:29.500]   that's data
[00:27:29.500 --> 00:27:30.700]   that's information
[00:27:30.700 --> 00:27:33.800]   so we can answer the question what actually happens
[00:27:35.000 --> 00:27:37.100]   so many of the people behind this team
[00:27:37.100 --> 00:27:38.300]   have instrumented
[00:27:38.300 --> 00:27:40.500]   25 vehicles
[00:27:40.500 --> 00:27:43.000]   21 of which are Tesla autopilot vehicles
[00:27:43.000 --> 00:27:44.900]   now with over collected
[00:27:44.900 --> 00:27:47.500]   recording everything about the driver
[00:27:47.500 --> 00:27:50.200]   two cameras, two HD cameras on the driver
[00:27:50.200 --> 00:27:52.000]   two cameras on the
[00:27:52.000 --> 00:27:54.100]   one camera on the external roadway
[00:27:54.100 --> 00:27:56.100]   and collecting everything about the car
[00:27:56.100 --> 00:27:57.600]   including audio
[00:27:57.600 --> 00:28:00.200]   the state, the pulling everything from the cam bus
[00:28:00.200 --> 00:28:01.900]   the kinematics of the vehicle
[00:28:01.900 --> 00:28:03.900]   IMU, GPS
[00:28:04.500 --> 00:28:05.900]   all of that information
[00:28:05.900 --> 00:28:08.500]   over now over 300,000 miles
[00:28:08.500 --> 00:28:10.100]   over 5 billion
[00:28:10.100 --> 00:28:11.900]   video frames
[00:28:11.900 --> 00:28:12.900]   all
[00:28:12.900 --> 00:28:16.000]   as we'll talk about analyzed computer vision
[00:28:16.000 --> 00:28:18.600]   you extract from that video of the driver
[00:28:18.600 --> 00:28:20.500]   of everything they're doing
[00:28:20.500 --> 00:28:22.800]   the level of distraction
[00:28:22.800 --> 00:28:24.300]   the allocation of attention
[00:28:24.300 --> 00:28:28.000]   the drowsiness, emotional states
[00:28:28.000 --> 00:28:32.000]   the hands-on wheel, hands-off wheel, body pose
[00:28:32.500 --> 00:28:34.800]   activity, smartphone usage
[00:28:34.800 --> 00:28:36.000]   all of these factors
[00:28:36.000 --> 00:28:39.200]   all of these things that you would think would fall apart
[00:28:39.200 --> 00:28:40.700]   when you start
[00:28:40.700 --> 00:28:42.900]   letting autonomy into your life
[00:28:42.900 --> 00:28:45.000]   we'll talk about what the initial
[00:28:45.000 --> 00:28:46.600]   reality is
[00:28:46.600 --> 00:28:49.300]   that should be inspiring and thought-provoking
[00:28:49.300 --> 00:28:53.000]   as I said three cameras
[00:28:53.000 --> 00:28:56.300]   single board computer recording all the data
[00:28:56.300 --> 00:29:00.000]   over a thousand machines in Holyoke
[00:29:01.000 --> 00:29:02.700]   in distributed computation
[00:29:02.700 --> 00:29:05.100]   running the deep learning algorithms
[00:29:05.100 --> 00:29:06.200]   that I've mentioned
[00:29:06.200 --> 00:29:09.200]   on these five plus billion video frames
[00:29:09.200 --> 00:29:11.700]   going from the raw data
[00:29:11.700 --> 00:29:14.300]   to the actionable useful information
[00:29:14.300 --> 00:29:16.700]   the slides are up online
[00:29:16.700 --> 00:29:18.000]   if you'd like to look through them
[00:29:18.000 --> 00:29:20.000]   I'll fly through some of them
[00:29:20.000 --> 00:29:22.400]   and this is the video
[00:29:22.400 --> 00:29:25.900]   of one of thousands of trips we have
[00:29:25.900 --> 00:29:28.100]   in autopilot in our data
[00:29:28.100 --> 00:29:29.700]   a car driving
[00:29:30.400 --> 00:29:31.400]   autonomously
[00:29:31.400 --> 00:29:34.200]   a large fraction of the time on highways
[00:29:34.200 --> 00:29:35.600]   from here to California
[00:29:35.600 --> 00:29:37.000]   from here to Chicago
[00:29:37.000 --> 00:29:38.700]   to Florida
[00:29:38.700 --> 00:29:40.600]   and all across the United States
[00:29:40.600 --> 00:29:44.900]   we take that data
[00:29:44.900 --> 00:29:47.500]   and using
[00:29:47.500 --> 00:29:50.100]   the supervised learning algorithms
[00:29:50.100 --> 00:29:51.400]   semi-supervised
[00:29:51.400 --> 00:29:54.400]   the number of frames here is huge
[00:29:54.400 --> 00:29:56.800]   for those that work in computer vision
[00:29:56.800 --> 00:29:58.500]   five billion frames
[00:29:58.500 --> 00:30:01.600]   is several orders of magnitude larger
[00:30:01.600 --> 00:30:04.200]   than any data set that people are working with
[00:30:04.200 --> 00:30:05.800]   in computer vision
[00:30:05.800 --> 00:30:09.800]   actively annotated
[00:30:09.800 --> 00:30:14.600]   so we want to use that data
[00:30:14.600 --> 00:30:15.600]   for
[00:30:15.600 --> 00:30:17.500]   understanding the behavior
[00:30:17.500 --> 00:30:19.600]   of what people actually doing in the cars
[00:30:19.600 --> 00:30:21.900]   and we want to train the algorithms
[00:30:21.900 --> 00:30:23.400]   that do perception and control
[00:30:23.400 --> 00:30:25.700]   a quick summary
[00:30:25.700 --> 00:30:27.900]   over 300,000 miles
[00:30:28.200 --> 00:30:29.500]   25 vehicles
[00:30:29.500 --> 00:30:32.500]   the colors are true to the actual colors of the vehicles
[00:30:32.500 --> 00:30:35.100]   little fun fact
[00:30:35.100 --> 00:30:38.000]   Tesla, Model X, Model S
[00:30:38.000 --> 00:30:39.400]   and now Model 3
[00:30:39.400 --> 00:30:42.700]   500,000
[00:30:42.700 --> 00:30:44.300]   500 plus
[00:30:44.300 --> 00:30:46.200]   sorry miles a day and growing
[00:30:46.200 --> 00:30:48.400]   now most days
[00:30:48.400 --> 00:30:50.200]   in 2018
[00:30:50.200 --> 00:30:53.000]   are over a thousand miles a day
[00:30:53.000 --> 00:30:55.800]   this is a quick GPS map
[00:30:56.000 --> 00:30:58.900]   in red is manual driving across the Boston area
[00:30:58.900 --> 00:30:59.800]   in blue
[00:30:59.800 --> 00:31:02.300]   cyan is autonomous driving
[00:31:02.300 --> 00:31:05.600]   this is giving you the sense of just the scope of this data
[00:31:05.600 --> 00:31:07.900]   this is a huge number of miles
[00:31:07.900 --> 00:31:10.900]   with automated driving
[00:31:10.900 --> 00:31:13.600]   several orders of magnitude larger
[00:31:13.600 --> 00:31:15.900]   than what Waymo is doing
[00:31:15.900 --> 00:31:17.700]   that what Cruze is doing
[00:31:17.700 --> 00:31:19.100]   and what Uber is doing
[00:31:24.800 --> 00:31:26.300]   the miles driven
[00:31:26.300 --> 00:31:27.800]   in this data
[00:31:27.800 --> 00:31:29.400]   with autopilot
[00:31:29.400 --> 00:31:33.400]   confirming what Elon Musk has stated
[00:31:33.400 --> 00:31:38.400]   is 33% of miles are driven autonomously
[00:31:38.400 --> 00:31:41.500]   this is a remarkable number for those of you who
[00:31:41.500 --> 00:31:42.700]   drive
[00:31:42.700 --> 00:31:45.600]   and for those of you who are familiar with these technologies
[00:31:45.600 --> 00:31:48.000]   that is remarkable adoption rate
[00:31:48.000 --> 00:31:51.900]   that 33% of the miles are driven in autopilot
[00:31:51.900 --> 00:31:53.000]   that means these
[00:31:53.700 --> 00:31:56.200]   drivers are getting use out of the system
[00:31:56.200 --> 00:31:57.900]   it's working for them
[00:31:57.900 --> 00:31:59.500]   that's an incredible number
[00:31:59.500 --> 00:32:03.300]   it's also incredible
[00:32:03.300 --> 00:32:04.700]   because under
[00:32:04.700 --> 00:32:07.600]   the decades of literature
[00:32:07.600 --> 00:32:10.300]   from aviation to automation and vehicles
[00:32:10.300 --> 00:32:12.800]   to Chris Urmson and Waymo
[00:32:12.800 --> 00:32:16.000]   the belief is such high numbers
[00:32:16.000 --> 00:32:17.900]   are likely to lead
[00:32:17.900 --> 00:32:20.500]   to crashes to fatalities
[00:32:20.500 --> 00:32:21.100]   to
[00:32:21.500 --> 00:32:24.300]   at the very least highly responsible behavior
[00:32:24.300 --> 00:32:28.700]   drivers over trusting the systems and getting in trouble
[00:32:28.700 --> 00:32:32.900]   we can run the glance classification algorithms
[00:32:32.900 --> 00:32:34.600]   again this is
[00:32:34.600 --> 00:32:37.400]   for next Wednesday discussion to the actual algorithm
[00:32:37.400 --> 00:32:39.900]   it's the algorithm that tells you the region
[00:32:39.900 --> 00:32:41.400]   that the driver is looking at
[00:32:41.400 --> 00:32:44.400]   and it's comparing road instrument cluster left
[00:32:44.400 --> 00:32:46.500]   rearview center stack and right
[00:32:46.500 --> 00:32:49.800]   does the allocation of glance change with autopilot
[00:32:49.800 --> 00:32:51.000]   or
[00:32:51.400 --> 00:32:52.200]   with
[00:32:52.200 --> 00:32:53.400]   manual driving
[00:32:53.400 --> 00:32:55.300]   it does not appear to
[00:32:55.300 --> 00:32:57.800]   in any significant noticeable way
[00:32:57.800 --> 00:33:00.200]   meaning you don't start playing chess
[00:33:00.200 --> 00:33:01.400]   you don't start
[00:33:01.400 --> 00:33:03.500]   you don't get in the backseat to sleep
[00:33:03.500 --> 00:33:08.400]   you don't start texting in your smartphone watching a movie
[00:33:08.400 --> 00:33:10.100]   at least in this data set
[00:33:10.100 --> 00:33:11.800]   there's promise here
[00:33:11.800 --> 00:33:14.300]   for the human-centered approach
[00:33:14.300 --> 00:33:18.300]   the observation to summarize
[00:33:18.900 --> 00:33:21.800]   this particular data is that people are using it a lot
[00:33:21.800 --> 00:33:24.300]   the percentage of miles a percentage hours
[00:33:24.300 --> 00:33:25.700]   is incredibly high
[00:33:25.700 --> 00:33:27.800]   at least relative to what was
[00:33:27.800 --> 00:33:29.200]   will be expected
[00:33:29.200 --> 00:33:30.400]   from these systems
[00:33:30.400 --> 00:33:33.000]   and given that there's no crashes
[00:33:33.000 --> 00:33:34.900]   there's no near crashes
[00:33:34.900 --> 00:33:36.000]   in autopilot
[00:33:36.000 --> 00:33:38.000]   the
[00:33:38.000 --> 00:33:40.400]   road type is mostly highway
[00:33:40.400 --> 00:33:42.300]   traveling at high speeds
[00:33:42.300 --> 00:33:46.200]   the mental engagement looked at
[00:33:47.800 --> 00:33:51.000]   8,000 transfer of control from machine to human
[00:33:51.000 --> 00:33:53.200]   so human beings taking control of the vehicle
[00:33:53.200 --> 00:33:54.500]   saying you know what
[00:33:54.500 --> 00:33:56.300]   I'm going to take control now
[00:33:56.300 --> 00:33:57.800]   I'm not comfortable with the situation
[00:33:57.800 --> 00:33:58.800]   for whatever reason
[00:33:58.800 --> 00:34:00.200]   either not comfortable
[00:34:00.200 --> 00:34:03.500]   or electing to do something that the vehicle is not able to
[00:34:03.500 --> 00:34:04.800]   like turn off the highway
[00:34:04.800 --> 00:34:07.000]   make a right or left turn
[00:34:07.000 --> 00:34:08.500]   stop for a stop sign
[00:34:08.500 --> 00:34:09.400]   these kinds of things
[00:34:09.400 --> 00:34:12.200]   physical engagement
[00:34:12.200 --> 00:34:14.300]   as I said glance remains the same
[00:34:14.300 --> 00:34:17.000]   and what do we take from this
[00:34:17.500 --> 00:34:19.800]   it's just something that I'd like to really emphasize
[00:34:19.800 --> 00:34:20.600]   as we talked
[00:34:20.600 --> 00:34:23.500]   as we talk about autonomous vehicles in this class
[00:34:23.500 --> 00:34:25.100]   and the guest speakers
[00:34:25.100 --> 00:34:26.600]   who are all on the other side
[00:34:26.600 --> 00:34:29.500]   so I'm representing the human center side
[00:34:29.500 --> 00:34:33.700]   all our speakers are focused on the full autonomy side
[00:34:33.700 --> 00:34:35.900]   because that's the side
[00:34:35.900 --> 00:34:37.600]   roboticists know how to solve
[00:34:37.600 --> 00:34:41.100]   that's the fascinating algorithm nerd side
[00:34:41.100 --> 00:34:43.800]   and that's the side I love as well
[00:34:43.800 --> 00:34:46.000]   it's just my belief stands
[00:34:46.200 --> 00:34:48.600]   that the solving the perception control problem
[00:34:48.600 --> 00:34:50.000]   is extremely difficult
[00:34:50.000 --> 00:34:51.700]   and two three decades away
[00:34:51.700 --> 00:34:53.200]   so in the meantime
[00:34:53.200 --> 00:34:55.900]   we have to utilize the human robot interaction
[00:34:55.900 --> 00:34:58.700]   to actually bring these AI systems onto the road
[00:34:58.700 --> 00:35:00.100]   to successfully operate
[00:35:00.100 --> 00:35:02.900]   and the way we do that counterintuitively
[00:35:02.900 --> 00:35:04.700]   is
[00:35:04.700 --> 00:35:07.800]   we have to have
[00:35:07.800 --> 00:35:11.400]   we have to let the artificial intelligence systems
[00:35:11.400 --> 00:35:13.000]   reveal their flaws
[00:35:14.300 --> 00:35:17.200]   one of the most endearing things to human beings
[00:35:17.200 --> 00:35:19.200]   can do to each other
[00:35:19.200 --> 00:35:20.000]   friends
[00:35:20.000 --> 00:35:23.500]   is reveal their flaws to each other
[00:35:23.500 --> 00:35:26.500]   now from a automotive perspective
[00:35:26.500 --> 00:35:28.000]   from a company perspective
[00:35:28.000 --> 00:35:29.700]   it's perhaps not
[00:35:29.700 --> 00:35:34.000]   appealing for an AI system to reveal
[00:35:34.000 --> 00:35:35.600]   what it sees about the world
[00:35:35.600 --> 00:35:37.600]   and what it doesn't see about the world
[00:35:37.600 --> 00:35:40.500]   where it succeeds and where it fails
[00:35:42.000 --> 00:35:45.100]   but that is perhaps exactly what it needs to do
[00:35:45.100 --> 00:35:47.300]   in the case of autopilot
[00:35:47.300 --> 00:35:49.600]   the way the very limited
[00:35:49.600 --> 00:35:51.600]   but I believe successful way
[00:35:51.600 --> 00:35:52.600]   is currently doing that
[00:35:52.600 --> 00:35:55.400]   is allowing you to use autopilot basically anywhere
[00:35:55.400 --> 00:35:57.000]   so what people are doing
[00:35:57.000 --> 00:35:58.600]   is they're trying to engage
[00:35:58.600 --> 00:36:00.700]   their turn on autopilot
[00:36:00.700 --> 00:36:02.900]   in places where they really shouldn't
[00:36:02.900 --> 00:36:06.400]   rural roads, curvy
[00:36:06.400 --> 00:36:09.300]   with terrible road markings
[00:36:09.500 --> 00:36:13.300]   with in heavy rain conditions
[00:36:13.300 --> 00:36:14.200]   with snow
[00:36:14.200 --> 00:36:18.000]   with lots of cars driving at high speeds all around
[00:36:18.000 --> 00:36:19.700]   they turn autopilot on
[00:36:19.700 --> 00:36:22.900]   to understand to experience the limitations of the system
[00:36:22.900 --> 00:36:26.400]   to interact that human robot interaction
[00:36:26.400 --> 00:36:30.000]   is through its tactile
[00:36:30.000 --> 00:36:32.400]   by turning it on and seeing
[00:36:32.400 --> 00:36:33.300]   is it going to work here?
[00:36:33.300 --> 00:36:34.300]   How is it going to fail?
[00:36:34.300 --> 00:36:36.000]   And the human is always there to catch it
[00:36:36.000 --> 00:36:37.400]   that interaction
[00:36:37.400 --> 00:36:39.100]   that's communication
[00:36:39.500 --> 00:36:41.400]   that intimate understanding
[00:36:41.400 --> 00:36:44.600]   is what creates successful integration of AI in the car
[00:36:44.600 --> 00:36:47.000]   before we're able to solve the full autonomy puzzle
[00:36:47.000 --> 00:36:50.700]   learn the limitations by exploring
[00:36:50.700 --> 00:36:53.000]   it starts with this guy
[00:36:53.000 --> 00:36:54.900]   and hundreds of others
[00:36:54.900 --> 00:36:56.700]   if you search on YouTube
[00:36:56.700 --> 00:36:58.000]   first time with autopilot
[00:36:58.000 --> 00:37:01.300]   the amazing experience
[00:37:01.300 --> 00:37:04.600]   of direct transfer of control of your life
[00:37:04.600 --> 00:37:06.600]   to an artificial intelligence system
[00:37:06.600 --> 00:37:07.900]   in this case
[00:37:08.000 --> 00:37:10.300]   giving control to Tesla autopilot system
[00:37:10.300 --> 00:37:11.900]   this is why
[00:37:11.900 --> 00:37:14.600]   in the human center camp of autonomy
[00:37:14.600 --> 00:37:16.300]   I believe that
[00:37:16.300 --> 00:37:18.500]   autonomous vehicles
[00:37:18.500 --> 00:37:20.700]   can be viewed as personal robots
[00:37:20.700 --> 00:37:23.400]   with which you build a relationship
[00:37:23.400 --> 00:37:26.500]   where the human robot interaction is the key problem
[00:37:26.500 --> 00:37:28.300]   not the perception control
[00:37:28.300 --> 00:37:36.400]   and there
[00:37:36.400 --> 00:37:37.700]   the flaws
[00:37:38.200 --> 00:37:39.800]   of both humans and machines
[00:37:39.800 --> 00:37:42.600]   must be clearly communicated and perceived
[00:37:42.600 --> 00:37:47.000]   perceived because we use the computer vision algorithms
[00:37:47.000 --> 00:37:48.700]   to detect everything about the human
[00:37:48.700 --> 00:37:50.100]   and communicated
[00:37:50.100 --> 00:37:52.200]   because on the displays of the car
[00:37:52.200 --> 00:37:54.000]   or even through voice
[00:37:54.000 --> 00:37:56.000]   it has to be able to reveal
[00:37:56.000 --> 00:37:57.200]   when it doesn't see
[00:37:57.200 --> 00:37:59.400]   different aspects of the scene
[00:37:59.400 --> 00:38:05.700]   from the human centered approach then
[00:38:06.900 --> 00:38:08.500]   we can focus on the left
[00:38:08.500 --> 00:38:10.400]   the perception and control side
[00:38:10.400 --> 00:38:13.000]   perceiving everything about the external environment
[00:38:13.000 --> 00:38:14.500]   and controlling the vehicle
[00:38:14.500 --> 00:38:19.600]   without having to worry about being 99.99999% correct
[00:38:19.600 --> 00:38:22.600]   approaching a hundred percent correct
[00:38:22.600 --> 00:38:25.800]   because in the cases where it's extremely difficult
[00:38:25.800 --> 00:38:28.700]   we can let the human catch the system
[00:38:28.700 --> 00:38:31.800]   we can reveal the flaws
[00:38:31.800 --> 00:38:33.200]   and let the human take over
[00:38:33.200 --> 00:38:35.100]   when the system can't
[00:38:36.400 --> 00:38:38.700]   so let's get to the sensors
[00:38:38.700 --> 00:38:44.500]   the sources of raw data that we get to work with
[00:38:44.500 --> 00:38:49.800]   there's three
[00:38:49.800 --> 00:38:52.000]   there's cameras
[00:38:52.000 --> 00:38:53.500]   so image sensors
[00:38:53.500 --> 00:38:55.700]   RGB infrared
[00:38:55.700 --> 00:38:59.000]   visual data
[00:38:59.000 --> 00:39:00.500]   there's radar
[00:39:00.500 --> 00:39:03.100]   and ultrasonic
[00:39:03.100 --> 00:39:05.500]   and there's LiDAR
[00:39:05.600 --> 00:39:09.000]   let's discuss the strengths
[00:39:09.000 --> 00:39:12.200]   first discuss really what these sensors are
[00:39:12.200 --> 00:39:13.600]   the strength and weaknesses
[00:39:13.600 --> 00:39:14.800]   and how they can be
[00:39:14.800 --> 00:39:16.900]   integrated together
[00:39:16.900 --> 00:39:18.300]   through sensor fusion
[00:39:18.300 --> 00:39:20.400]   so radar
[00:39:20.400 --> 00:39:21.900]   is the trusted
[00:39:21.900 --> 00:39:23.500]   the old trusted friend
[00:39:23.500 --> 00:39:26.700]   the sensor that's commonly available in most vehicles
[00:39:26.700 --> 00:39:29.100]   that have any degree of autonomy
[00:39:29.100 --> 00:39:32.800]   on the left is a visualization of the kind of data
[00:39:32.800 --> 00:39:34.600]   on high-resolution radar
[00:39:34.600 --> 00:39:36.700]   that's able to be extracted
[00:39:36.700 --> 00:39:39.700]   it's cheap
[00:39:39.700 --> 00:39:41.900]   both radar
[00:39:41.900 --> 00:39:44.800]   which works with electromagnetic waves
[00:39:44.800 --> 00:39:49.300]   and ultrasonic which works with sound waves
[00:39:49.300 --> 00:39:50.800]   sending a wave
[00:39:50.800 --> 00:39:52.800]   letting it bounce off the obstacles
[00:39:52.800 --> 00:39:55.000]   knowing the speed of that wave
[00:39:55.000 --> 00:39:58.300]   being able to calculate the distance to the obstacle
[00:39:58.300 --> 00:39:59.100]   based on that
[00:39:59.100 --> 00:40:02.800]   it does extremely well
[00:40:03.800 --> 00:40:05.800]   in challenging weather
[00:40:05.800 --> 00:40:07.300]   rain, snow
[00:40:07.300 --> 00:40:13.300]   the downside is a slow resolution
[00:40:13.300 --> 00:40:15.700]   compared to the other sensors we'll discuss
[00:40:15.700 --> 00:40:18.300]   but it is the one that's most reliable
[00:40:18.300 --> 00:40:20.200]   and used in automotive industry today
[00:40:20.200 --> 00:40:21.500]   and it's the one that's
[00:40:21.500 --> 00:40:23.500]   in sensor fusion is always there
[00:40:23.500 --> 00:40:26.200]   LiDAR
[00:40:26.200 --> 00:40:28.200]   visualized on the right
[00:40:28.200 --> 00:40:32.000]   the downsides it's expensive
[00:40:33.000 --> 00:40:35.200]   but it produces an extremely accurate
[00:40:35.200 --> 00:40:39.000]   depth information and a high-resolution map of the environment
[00:40:39.000 --> 00:40:43.200]   that has 360 degrees of visibility
[00:40:43.200 --> 00:40:48.500]   it has some of the
[00:40:48.500 --> 00:40:52.200]   big strengths of radar in terms of reliability
[00:40:52.200 --> 00:40:55.300]   but with much higher resolution and accuracy
[00:40:55.300 --> 00:40:58.000]   the downside is cost
[00:40:58.000 --> 00:41:02.500]   here's a quick visualization comparing the two
[00:41:02.600 --> 00:41:04.700]   of the kind of information you get to work with
[00:41:04.700 --> 00:41:08.100]   the density
[00:41:08.100 --> 00:41:11.500]   and the quality of information with LiDAR is much higher
[00:41:11.500 --> 00:41:15.700]   and LiDAR has been the successful
[00:41:15.700 --> 00:41:17.400]   source of ground truth
[00:41:17.400 --> 00:41:19.700]   the reliable sensor
[00:41:19.700 --> 00:41:22.900]   relied upon on vehicles that don't care about cost
[00:41:22.900 --> 00:41:27.300]   and camera
[00:41:27.300 --> 00:41:30.300]   the thing that most people here should be passionate about
[00:41:30.300 --> 00:41:32.000]   because machine learning
[00:41:32.300 --> 00:41:34.900]   deep learning has the most ability
[00:41:34.900 --> 00:41:36.700]   to have a significant impact there
[00:41:36.700 --> 00:41:37.600]   why?
[00:41:37.600 --> 00:41:39.000]   first is cheap
[00:41:39.000 --> 00:41:40.200]   so it's everywhere
[00:41:40.200 --> 00:41:42.200]   second is the highest resolution
[00:41:42.200 --> 00:41:43.300]   so there's the most
[00:41:43.300 --> 00:41:46.200]   the most highly dense amount of information
[00:41:46.200 --> 00:41:48.300]   which means
[00:41:48.300 --> 00:41:51.800]   information is something that could be learned
[00:41:51.800 --> 00:41:53.100]   and inferred
[00:41:53.100 --> 00:41:54.500]   to interpret
[00:41:54.500 --> 00:41:55.900]   the external scene
[00:41:55.900 --> 00:41:59.200]   that's why it's the best source of data
[00:41:59.200 --> 00:42:01.200]   for understanding the scene
[00:42:02.100 --> 00:42:03.200]   and the other reason
[00:42:03.200 --> 00:42:04.900]   it's awesome for deep learning
[00:42:04.900 --> 00:42:05.900]   is because of the
[00:42:05.900 --> 00:42:09.100]   hugeness of data involved
[00:42:09.100 --> 00:42:13.700]   the, it's many orders of magnitude more data available
[00:42:13.700 --> 00:42:14.500]   for driving
[00:42:14.500 --> 00:42:17.500]   in camera, visible light or infrared
[00:42:17.500 --> 00:42:19.200]   than it is in LiDAR
[00:42:19.200 --> 00:42:22.700]   the
[00:42:22.700 --> 00:42:26.700]   and our world is designed
[00:42:26.700 --> 00:42:28.800]   for visible light
[00:42:28.800 --> 00:42:31.700]   our eyes work in similar ways the cameras
[00:42:32.700 --> 00:42:34.200]   at least crudely so
[00:42:34.200 --> 00:42:36.000]   the source data is similar
[00:42:36.000 --> 00:42:38.200]   the lane markings
[00:42:38.200 --> 00:42:40.400]   the traffic signs, the traffic lights
[00:42:40.400 --> 00:42:41.600]   the other vehicles
[00:42:41.600 --> 00:42:44.100]   the other pedestrians all operate
[00:42:44.100 --> 00:42:46.700]   with each other in this RGB space
[00:42:46.700 --> 00:42:49.700]   in terms of visual characteristics
[00:42:49.700 --> 00:42:52.300]   the downside is cameras are
[00:42:52.300 --> 00:42:54.800]   bad at depth estimation
[00:42:54.800 --> 00:42:58.300]   it's noisy and difficult even with stereo vision cameras
[00:42:58.300 --> 00:43:00.800]   to estimate depth relative to LiDAR
[00:43:01.800 --> 00:43:04.000]   and they're not good in extreme weather
[00:43:04.000 --> 00:43:05.500]   and they're not good
[00:43:05.500 --> 00:43:07.400]   at least visible light cameras at night
[00:43:07.400 --> 00:43:11.900]   so let's compare the ranges
[00:43:11.900 --> 00:43:14.400]   here's a plot in meters
[00:43:14.400 --> 00:43:16.700]   on the x-axis of the range
[00:43:16.700 --> 00:43:20.200]   and acuity
[00:43:20.200 --> 00:43:22.500]   on the y-axis
[00:43:22.500 --> 00:43:26.800]   with ultrasonic, LiDAR, radar
[00:43:26.800 --> 00:43:27.800]   and
[00:43:28.700 --> 00:43:30.900]   camera passive visual sensor
[00:43:30.900 --> 00:43:31.900]   plotted
[00:43:31.900 --> 00:43:35.200]   the range of cameras
[00:43:35.200 --> 00:43:36.800]   is the greatest
[00:43:36.800 --> 00:43:38.600]   this is looking at
[00:43:38.600 --> 00:43:41.700]   we're going to look at several different conditions
[00:43:41.700 --> 00:43:44.200]   this is for clear well-lit conditions
[00:43:44.200 --> 00:43:45.700]   so during the day
[00:43:45.700 --> 00:43:47.300]   no rain
[00:43:47.300 --> 00:43:49.500]   no fog
[00:43:49.500 --> 00:43:52.400]   LiDAR and radar have a smaller range
[00:43:52.400 --> 00:43:53.600]   under 200 meters
[00:43:53.600 --> 00:43:57.400]   and ultrasonic sensors used mostly for park assistance
[00:43:57.400 --> 00:43:58.600]   and these kinds of things
[00:43:58.600 --> 00:44:00.200]   and blind spot warning
[00:44:00.200 --> 00:44:02.000]   has terrible range
[00:44:02.000 --> 00:44:04.400]   is designed for extremely close
[00:44:04.400 --> 00:44:05.900]   as high resolution
[00:44:05.900 --> 00:44:08.600]   distance estimation for extremely close distances
[00:44:08.600 --> 00:44:12.600]   here a little bit small
[00:44:12.600 --> 00:44:13.700]   but looking at
[00:44:13.700 --> 00:44:15.900]   up top is clear well-lit conditions
[00:44:15.900 --> 00:44:17.000]   the plot we just looked at
[00:44:17.000 --> 00:44:19.300]   and on bottom is clear dark conditions
[00:44:19.300 --> 00:44:21.600]   so just a clear night day
[00:44:21.600 --> 00:44:22.800]   no rain
[00:44:22.800 --> 00:44:25.100]   but it's night
[00:44:25.600 --> 00:44:28.900]   and on the bottom right is heavy rain, snow or fog
[00:44:28.900 --> 00:44:31.600]   vision falls apart
[00:44:31.600 --> 00:44:34.000]   in terms of range and accuracy
[00:44:34.000 --> 00:44:36.700]   under dark conditions
[00:44:36.700 --> 00:44:38.900]   and in rain, snow or fog
[00:44:38.900 --> 00:44:42.700]   radar, our old trusted friend
[00:44:42.700 --> 00:44:44.100]   stays strong
[00:44:44.100 --> 00:44:46.100]   the same range
[00:44:46.100 --> 00:44:47.700]   just under 200 meters
[00:44:47.700 --> 00:44:49.300]   and at the same acuity
[00:44:49.300 --> 00:44:52.200]   same with sonar
[00:44:53.600 --> 00:44:55.900]   LiDAR works well at night
[00:44:55.900 --> 00:44:59.400]   but it does not do well with rain or fog or snow
[00:44:59.400 --> 00:45:03.700]   one of the biggest downsides of LiDAR
[00:45:03.700 --> 00:45:06.000]   other than cost
[00:45:06.000 --> 00:45:08.600]   so here's another interesting way to visualize this
[00:45:08.600 --> 00:45:10.000]   that I think is productive
[00:45:10.000 --> 00:45:11.400]   for our discussion
[00:45:11.400 --> 00:45:13.300]   of which sensor will win out
[00:45:13.300 --> 00:45:16.800]   is it the Elon Musk prediction of camera
[00:45:16.800 --> 00:45:20.200]   or is it the Waymo prediction of LiDAR
[00:45:23.000 --> 00:45:23.800]   for LiDAR
[00:45:23.800 --> 00:45:26.900]   in this kind of plot that will look for every single sensor
[00:45:26.900 --> 00:45:31.600]   the greater the radius of the blue
[00:45:31.600 --> 00:45:35.100]   the more successful that sensor is
[00:45:35.100 --> 00:45:36.400]   at accomplishing that feature
[00:45:36.400 --> 00:45:37.600]   with a bunch of features
[00:45:37.600 --> 00:45:40.600]   lined up around the circle
[00:45:40.600 --> 00:45:43.200]   so range for LiDAR is pretty good
[00:45:43.200 --> 00:45:44.800]   not great but pretty good
[00:45:44.800 --> 00:45:47.100]   resolution is also pretty good
[00:45:47.100 --> 00:45:48.900]   it works in the dark
[00:45:48.900 --> 00:45:50.500]   it works in bright light
[00:45:51.100 --> 00:45:53.100]   but it falls apart in the snow
[00:45:53.100 --> 00:45:55.900]   it does not provide
[00:45:55.900 --> 00:45:58.900]   color information, texture information, contrast
[00:45:58.900 --> 00:46:01.100]   it's able to detect speed
[00:46:01.100 --> 00:46:03.800]   but the sensor size at least to date
[00:46:03.800 --> 00:46:04.900]   is huge
[00:46:04.900 --> 00:46:07.400]   the sensor cost at least to date
[00:46:07.400 --> 00:46:08.900]   is extremely expensive
[00:46:08.900 --> 00:46:11.700]   and it doesn't do well
[00:46:11.700 --> 00:46:13.000]   in proximity
[00:46:13.000 --> 00:46:15.100]   where ultrasonic shines
[00:46:15.100 --> 00:46:17.400]   speaking of which
[00:46:17.400 --> 00:46:19.900]   ultrasonic is a very important feature
[00:46:19.900 --> 00:46:21.900]   ultrasonic same kind of plot
[00:46:21.900 --> 00:46:24.000]   does well in proximity detection
[00:46:24.000 --> 00:46:26.400]   it's cheap, the cheapest sensor of the four
[00:46:26.400 --> 00:46:29.800]   and sensor size you can get it to be tiny
[00:46:29.800 --> 00:46:33.400]   it works in snow, fog and rain
[00:46:33.400 --> 00:46:36.300]   but its resolution is terrible
[00:46:36.300 --> 00:46:38.100]   its range is non-existent
[00:46:38.100 --> 00:46:41.100]   and it's not able to detect speed
[00:46:41.100 --> 00:46:44.300]   that's where radar steps up
[00:46:44.300 --> 00:46:45.700]   it's able to detect speed
[00:46:45.700 --> 00:46:47.000]   it's also cheap
[00:46:47.000 --> 00:46:49.300]   it's also small
[00:46:49.800 --> 00:46:53.900]   but the resolution is very low
[00:46:53.900 --> 00:46:55.800]   and it's just like LIDAR
[00:46:55.800 --> 00:46:57.900]   is not able to provide texture information
[00:46:57.900 --> 00:46:58.800]   color information
[00:46:58.800 --> 00:47:00.900]   camera
[00:47:00.900 --> 00:47:04.800]   the sensor cost is cheap
[00:47:04.800 --> 00:47:06.700]   the sensor size is small
[00:47:06.700 --> 00:47:09.500]   not good up close proximity
[00:47:09.500 --> 00:47:12.100]   the range is the longest of all of them
[00:47:12.100 --> 00:47:14.800]   resolution is the best of all of them
[00:47:14.800 --> 00:47:16.600]   it doesn't work in the dark
[00:47:17.300 --> 00:47:19.500]   it works in bright light
[00:47:19.500 --> 00:47:20.600]   but not always
[00:47:20.600 --> 00:47:23.000]   one of the biggest downfalls of camera sensors
[00:47:23.000 --> 00:47:25.400]   is the sensitivity to lighting variation
[00:47:25.400 --> 00:47:27.000]   it works
[00:47:27.000 --> 00:47:29.700]   it doesn't work in the snow, fog, rain
[00:47:29.700 --> 00:47:32.900]   so suffers much like LIDAR from that
[00:47:32.900 --> 00:47:35.200]   but it provides rich
[00:47:35.200 --> 00:47:38.400]   interesting textural information
[00:47:38.400 --> 00:47:40.800]   the very kind that deep learning needs
[00:47:40.800 --> 00:47:42.000]   to make sense of this world
[00:47:42.000 --> 00:47:44.400]   so let's
[00:47:45.300 --> 00:47:47.500]   look at the cheap sensors
[00:47:47.500 --> 00:47:50.700]   ultrasonic radar
[00:47:50.700 --> 00:47:52.700]   and cameras
[00:47:52.700 --> 00:47:54.100]   which is one approach
[00:47:54.100 --> 00:47:56.900]   putting a bunch of those in a car
[00:47:56.900 --> 00:47:58.000]   and fusing them together
[00:47:58.000 --> 00:48:01.200]   the cost there is low
[00:48:01.200 --> 00:48:05.000]   one of the nice ways to visualize
[00:48:05.000 --> 00:48:06.700]   using this visualization technique
[00:48:06.700 --> 00:48:09.700]   when they're fused together on the bottom
[00:48:09.700 --> 00:48:11.400]   it gives you a sense
[00:48:11.400 --> 00:48:14.400]   of them working together
[00:48:14.600 --> 00:48:16.500]   to complement each other's strengths
[00:48:16.500 --> 00:48:21.600]   and the question is
[00:48:21.600 --> 00:48:23.900]   whether camera or LIDAR will win out
[00:48:23.900 --> 00:48:27.100]   for partial autonomy or full autonomy
[00:48:27.100 --> 00:48:29.900]   on the bottom showing
[00:48:29.900 --> 00:48:32.400]   this kind of visualization for a
[00:48:32.400 --> 00:48:33.800]   LIDAR sensor
[00:48:33.800 --> 00:48:36.500]   and on top showing this kind of visualization
[00:48:36.500 --> 00:48:37.700]   for fused
[00:48:37.700 --> 00:48:40.600]   radar, ultrasonic and camera
[00:48:42.900 --> 00:48:45.200]   at least under these considerations
[00:48:45.200 --> 00:48:48.500]   the fusion of the cheap sensors
[00:48:48.500 --> 00:48:50.400]   can do as well as LIDAR
[00:48:50.400 --> 00:48:53.600]   now the open question is whether LIDAR
[00:48:53.600 --> 00:48:55.200]   in the future of this technology
[00:48:55.200 --> 00:48:56.500]   can become cheap
[00:48:56.500 --> 00:48:57.800]   and its range can increase
[00:48:57.800 --> 00:48:59.700]   because then LIDAR can win out
[00:48:59.700 --> 00:49:02.100]   solid-state LIDAR
[00:49:02.100 --> 00:49:03.400]   and a lot of developments
[00:49:03.400 --> 00:49:06.200]   with a lot of startup LIDAR companies
[00:49:06.200 --> 00:49:08.300]   are promising to decrease the cost
[00:49:08.300 --> 00:49:10.500]   and increase the range of these sensors
[00:49:10.500 --> 00:49:12.600]   but for now
[00:49:13.100 --> 00:49:14.300]   we plow along
[00:49:14.300 --> 00:49:18.000]   dedication on the camera front
[00:49:18.000 --> 00:49:21.400]   the annotated driving data grows
[00:49:21.400 --> 00:49:23.000]   exponentially
[00:49:23.000 --> 00:49:25.500]   more and more people
[00:49:25.500 --> 00:49:27.100]   are beginning to annotate
[00:49:27.100 --> 00:49:29.000]   and study
[00:49:29.000 --> 00:49:31.000]   the particular driving
[00:49:31.000 --> 00:49:33.500]   perception and control problems
[00:49:33.500 --> 00:49:36.900]   and the very algorithms
[00:49:36.900 --> 00:49:39.900]   for the supervised and semi-supervised
[00:49:39.900 --> 00:49:41.900]   and generative networks that we use
[00:49:41.900 --> 00:49:43.000]   to work with this data
[00:49:43.000 --> 00:49:44.200]   are improving
[00:49:44.200 --> 00:49:45.800]   so it's a race
[00:49:45.800 --> 00:49:48.700]   and of course radar and ultrasonic
[00:49:48.700 --> 00:49:50.000]   are always there to help
[00:49:50.000 --> 00:49:51.900]   so
[00:49:51.900 --> 00:49:55.000]   companies that are playing in the space
[00:49:55.000 --> 00:49:57.900]   some of them are speaking here
[00:49:57.900 --> 00:50:02.000]   Waymo
[00:50:02.000 --> 00:50:05.500]   in April 2017
[00:50:05.500 --> 00:50:08.500]   they exited their testing
[00:50:08.500 --> 00:50:09.700]   their extensive
[00:50:09.700 --> 00:50:11.000]   impressive
[00:50:11.400 --> 00:50:12.500]   testing process
[00:50:12.500 --> 00:50:15.800]   and allowed a first rider in Phoenix
[00:50:15.800 --> 00:50:16.700]   public rider
[00:50:16.700 --> 00:50:20.000]   in November 2017
[00:50:20.000 --> 00:50:22.900]   it's an incredible accomplishment
[00:50:22.900 --> 00:50:23.900]   for a company
[00:50:23.900 --> 00:50:26.400]   and for an artificial intelligence system
[00:50:26.400 --> 00:50:28.100]   in November 2017
[00:50:28.100 --> 00:50:29.800]   no safety driver
[00:50:29.800 --> 00:50:33.100]   so the car truly achieved full autonomy
[00:50:33.100 --> 00:50:35.600]   under a lot of constraints
[00:50:35.600 --> 00:50:37.700]   but it's full autonomy
[00:50:37.700 --> 00:50:38.700]   it's a step
[00:50:38.700 --> 00:50:40.800]   it's a amazing step
[00:50:40.800 --> 00:50:43.100]   in the direction towards full autonomy
[00:50:43.100 --> 00:50:45.700]   much sooner than people would otherwise predict
[00:50:45.700 --> 00:50:47.700]   and the miles
[00:50:47.700 --> 00:50:50.300]   4 million miles driven autonomously
[00:50:50.300 --> 00:50:51.900]   by November 2017
[00:50:51.900 --> 00:50:52.900]   and growing
[00:50:52.900 --> 00:50:54.100]   quickly growing
[00:50:54.100 --> 00:50:56.300]   in terms of full autonomous driving
[00:50:56.300 --> 00:50:59.300]   if I can say so cautiously
[00:50:59.300 --> 00:51:01.700]   because most of those miles have
[00:51:01.700 --> 00:51:03.500]   a safety driver
[00:51:03.500 --> 00:51:05.400]   so I would argue it's not full autonomy
[00:51:05.400 --> 00:51:08.300]   but however they define full autonomy
[00:51:08.300 --> 00:51:10.100]   it's 4 million miles driven
[00:51:11.000 --> 00:51:11.700]   incredible
[00:51:11.700 --> 00:51:13.700]   Uber
[00:51:13.700 --> 00:51:16.700]   in terms of miles second on that list
[00:51:16.700 --> 00:51:19.700]   they have driven 2 million miles autonomously
[00:51:19.700 --> 00:51:22.100]   by December of this
[00:51:22.100 --> 00:51:23.200]   of last year
[00:51:23.200 --> 00:51:24.400]   2017
[00:51:24.400 --> 00:51:29.000]   the quiet player here
[00:51:29.000 --> 00:51:33.100]   in terms of not making any declarations
[00:51:33.100 --> 00:51:34.500]   of being fully autonomous
[00:51:34.500 --> 00:51:38.100]   just quietly driving in a human-centered way
[00:51:38.100 --> 00:51:38.900]   L2
[00:51:39.900 --> 00:51:42.700]   over 1 billion miles in autopilot
[00:51:42.700 --> 00:51:46.400]   over 300,000 vehicles
[00:51:46.400 --> 00:51:48.000]   today are equipped
[00:51:48.000 --> 00:51:50.200]   with autopilot technology
[00:51:50.200 --> 00:51:51.700]   with ability to drive
[00:51:51.700 --> 00:51:53.200]   control the car
[00:51:53.200 --> 00:51:55.100]   laterally and longitudinally
[00:51:55.100 --> 00:51:57.400]   and if
[00:51:57.400 --> 00:51:59.400]   anyone believes
[00:51:59.400 --> 00:52:02.800]   the CEO of Tesla
[00:52:02.800 --> 00:52:06.100]   there will be over 1 million such vehicles
[00:52:06.100 --> 00:52:08.100]   by the end of 2018
[00:52:08.200 --> 00:52:12.700]   but no matter what
[00:52:12.700 --> 00:52:16.000]   the 300,000 is an incredible number
[00:52:16.000 --> 00:52:17.700]   and the 1 billion miles
[00:52:17.700 --> 00:52:19.100]   is an incredible number
[00:52:19.100 --> 00:52:23.900]   autopilot was first released in September 2014
[00:52:23.900 --> 00:52:25.800]   one of the first systems
[00:52:25.800 --> 00:52:27.400]   on the road to do so
[00:52:27.400 --> 00:52:29.300]   autopilot
[00:52:29.300 --> 00:52:32.700]   and I call myself as one of the skeptics
[00:52:32.700 --> 00:52:36.300]   in October 2016
[00:52:36.300 --> 00:52:38.900]   autopilot decided to let go
[00:52:38.900 --> 00:52:40.500]   of an incredible
[00:52:40.500 --> 00:52:44.100]   work done by Mobileye now Intel
[00:52:44.100 --> 00:52:48.700]   with designing their perception control system
[00:52:48.700 --> 00:52:50.500]   they decided to let go of it completely
[00:52:50.500 --> 00:52:51.700]   and start from scratch
[00:52:51.700 --> 00:52:54.600]   using mostly deep learning methods
[00:52:54.600 --> 00:52:56.600]   the dry PX2 system from
[00:52:56.600 --> 00:52:57.800]   NVIDIA
[00:52:57.800 --> 00:52:59.900]   and eight cameras
[00:52:59.900 --> 00:53:02.200]   they decided to start from scratch
[00:53:02.200 --> 00:53:05.300]   that's the kind of boldness
[00:53:06.300 --> 00:53:07.900]   the kind of risk-taking
[00:53:07.900 --> 00:53:10.100]   that can come with naivety
[00:53:10.100 --> 00:53:12.600]   but in this case it worked
[00:53:12.600 --> 00:53:14.700]   incredible
[00:53:14.700 --> 00:53:17.700]   Audi A8 system
[00:53:17.700 --> 00:53:20.800]   is going to be released at the end of 2018
[00:53:20.800 --> 00:53:22.400]   and it's promising
[00:53:22.400 --> 00:53:23.400]   one of the first vehicles
[00:53:23.400 --> 00:53:25.400]   that's promising what they're calling L3
[00:53:25.400 --> 00:53:29.500]   and the definition of L3
[00:53:29.500 --> 00:53:34.600]   according to Thorsten Lionheart
[00:53:34.600 --> 00:53:36.100]   the head of the automated driving
[00:53:36.100 --> 00:53:37.200]   in Audi
[00:53:37.200 --> 00:53:38.700]   in Audi
[00:53:38.700 --> 00:53:42.400]   is when the function is operate as intended
[00:53:42.400 --> 00:53:45.800]   if the customer turns the traffic jam pilot on
[00:53:45.800 --> 00:53:46.800]   now
[00:53:46.800 --> 00:53:49.500]   this L3 system is designed
[00:53:49.500 --> 00:53:50.700]   only for traffic jams
[00:53:50.700 --> 00:53:52.000]   bump into bumper traffic
[00:53:52.000 --> 00:53:53.900]   under
[00:53:53.900 --> 00:53:56.300]   60 kilometers an hour
[00:53:56.300 --> 00:54:00.400]   if the customer turns the traffic jam pilot on
[00:54:00.400 --> 00:54:01.800]   and uses it as intended
[00:54:01.800 --> 00:54:02.700]   and the car was
[00:54:03.200 --> 00:54:05.500]   in control at the time of the accident
[00:54:05.500 --> 00:54:07.500]   the driver goes to the insurance company
[00:54:07.500 --> 00:54:09.000]   and the insurance company will
[00:54:09.000 --> 00:54:11.200]   compensate the victims of the accident
[00:54:11.200 --> 00:54:12.200]   and an aftermath
[00:54:12.200 --> 00:54:13.600]   they come to us
[00:54:13.600 --> 00:54:15.100]   we will pay them
[00:54:15.100 --> 00:54:18.200]   so that means the car is liable
[00:54:18.200 --> 00:54:20.700]   the problem is
[00:54:20.700 --> 00:54:25.000]   under the definition of L2 L3
[00:54:25.000 --> 00:54:27.000]   perhaps there is some truth to this
[00:54:27.000 --> 00:54:28.300]   being an L3 system
[00:54:28.300 --> 00:54:31.200]   the important thing here is
[00:54:31.200 --> 00:54:34.600]   it's nevertheless deeply and fundamentally human-centered
[00:54:34.600 --> 00:54:37.700]   because even as you see here in this demonstration video
[00:54:37.700 --> 00:54:39.100]   with a reporter
[00:54:39.100 --> 00:54:40.400]   the car
[00:54:40.400 --> 00:54:43.500]   for a poorly understood reason
[00:54:43.500 --> 00:54:45.100]   transfer control to the driver
[00:54:45.100 --> 00:54:46.100]   says that's it
[00:54:46.100 --> 00:54:48.700]   I can't take care of the situation
[00:54:48.700 --> 00:54:49.900]   you take control
[00:54:49.900 --> 00:54:51.300]   how
[00:54:51.300 --> 00:54:54.800]   how much time do you have
[00:54:54.800 --> 00:54:58.200]   in terms of seconds before you really need to know to take over
[00:54:58.200 --> 00:55:00.900]   well this is the new thing about L3
[00:55:01.200 --> 00:55:02.500]   with L3
[00:55:02.500 --> 00:55:04.700]   the system allows the driver
[00:55:04.700 --> 00:55:06.700]   to give the prompt
[00:55:06.700 --> 00:55:08.300]   to take over vehicle control
[00:55:08.300 --> 00:55:09.600]   again ahead of time
[00:55:09.600 --> 00:55:10.100]   which is
[00:55:10.100 --> 00:55:13.600]   in this case up to 10 seconds
[00:55:13.600 --> 00:55:14.200]   okay
[00:55:14.200 --> 00:55:15.100]   so
[00:55:15.100 --> 00:55:18.600]   if the traffic jam situation clears up or
[00:55:18.600 --> 00:55:21.500]   any failure in the system occurs
[00:55:21.500 --> 00:55:22.800]   everything you might think of
[00:55:22.800 --> 00:55:25.400]   the system still needs to be able to drive
[00:55:25.400 --> 00:55:26.300]   automatically
[00:55:26.300 --> 00:55:28.700]   because the driver has this time
[00:55:28.700 --> 00:55:30.000]   to take over
[00:55:31.000 --> 00:55:32.000]   you might ask
[00:55:32.000 --> 00:55:33.500]   what is new about this
[00:55:33.500 --> 00:55:35.800]   so why is Audi saying
[00:55:35.800 --> 00:55:37.800]   this is the first L3 system
[00:55:37.800 --> 00:55:39.300]   worldwide on the market
[00:55:39.300 --> 00:55:43.900]   when talking about these levels of automation
[00:55:43.900 --> 00:55:45.200]   there's a classification
[00:55:45.200 --> 00:55:46.800]   which starts at level 0
[00:55:46.800 --> 00:55:49.300]   which is basically the driver is doing everything
[00:55:49.300 --> 00:55:50.800]   there's no assistance
[00:55:50.800 --> 00:55:51.300]   nothing
[00:55:51.300 --> 00:55:54.800]   and then it gradually becomes
[00:55:54.800 --> 00:55:56.900]   into partly automation
[00:55:56.900 --> 00:55:59.600]   and when we're talking about these assistance functions
[00:55:59.900 --> 00:56:02.000]   like lane keeping and distance keeping
[00:56:02.000 --> 00:56:05.000]   we're talking about level 2 assistance functions
[00:56:05.000 --> 00:56:05.500]   okay
[00:56:05.500 --> 00:56:06.200]   which is
[00:56:06.200 --> 00:56:10.200]   meaning that the driver is
[00:56:10.200 --> 00:56:12.100]   obliged
[00:56:12.100 --> 00:56:15.000]   to permanently monitor the traffic situation
[00:56:15.000 --> 00:56:16.900]   to keep the hands on the wheel
[00:56:16.900 --> 00:56:19.400]   even though there's a support and an assistance
[00:56:19.400 --> 00:56:21.800]   and to intervene immediately
[00:56:21.800 --> 00:56:24.000]   if anything is not quite right
[00:56:24.000 --> 00:56:26.900]   so you know that from lane assistance systems
[00:56:26.900 --> 00:56:28.400]   when the steering is not
[00:56:28.800 --> 00:56:30.700]   perfectly in the right lane
[00:56:30.700 --> 00:56:33.100]   you have to intervene and correct immediately
[00:56:33.100 --> 00:56:35.100]   and that is the main difference
[00:56:35.100 --> 00:56:37.800]   now we got a takeover request
[00:56:37.800 --> 00:56:38.600]   so what
[00:56:38.600 --> 00:56:39.500]   so let's
[00:56:39.500 --> 00:56:40.900]   let's talk about what
[00:56:40.900 --> 00:56:44.400]   that means this is
[00:56:44.400 --> 00:56:46.200]   still a human-centered system
[00:56:46.200 --> 00:56:47.600]   it still struggles
[00:56:47.600 --> 00:56:50.300]   it still must solve the human-robot interaction problem
[00:56:50.300 --> 00:56:54.400]   and there's many others playing in the space
[00:56:54.400 --> 00:56:56.100]   on the on the full autonomy side
[00:56:56.100 --> 00:56:57.200]   Waymo, Uber
[00:56:58.000 --> 00:57:00.200]   GM Cruise, Newtonomy
[00:57:00.200 --> 00:57:03.800]   the CTO of which will speak here on Tuesday
[00:57:03.800 --> 00:57:05.500]   Optimus Ride
[00:57:05.500 --> 00:57:07.200]   Zenuity
[00:57:07.200 --> 00:57:08.500]   Voyage
[00:57:08.500 --> 00:57:12.700]   the CEO of which will speak here next Thursday
[00:57:12.700 --> 00:57:15.300]   and Aurora
[00:57:15.300 --> 00:57:17.200]   not listed
[00:57:17.200 --> 00:57:20.600]   the founder of which will speak here next Friday
[00:57:20.600 --> 00:57:24.000]   and the human-centered autonomy side
[00:57:24.000 --> 00:57:25.100]   the reason I am
[00:57:26.600 --> 00:57:28.000]   speaking about it so much today
[00:57:28.000 --> 00:57:29.400]   is we don't have any speakers
[00:57:29.400 --> 00:57:30.500]   I'm the speaker
[00:57:30.500 --> 00:57:33.400]   the Tesla Autopilot
[00:57:33.400 --> 00:57:35.000]   is for several years now
[00:57:35.000 --> 00:57:36.900]   doing incredible work on that side
[00:57:36.900 --> 00:57:40.000]   we're also working with Volvo Pilot Assist
[00:57:40.000 --> 00:57:43.000]   as a lot of different approaches there
[00:57:43.000 --> 00:57:44.100]   more conservative
[00:57:44.100 --> 00:57:45.200]   interesting
[00:57:45.200 --> 00:57:48.200]   the Audi Traffic Jam Assist
[00:57:48.200 --> 00:57:50.200]   as I mentioned the A8 being released
[00:57:50.200 --> 00:57:51.500]   at the end of this year
[00:57:51.500 --> 00:57:54.200]   the Mercedes Drive Pilot Assist
[00:57:54.200 --> 00:57:55.200]   and the E-Class
[00:57:55.800 --> 00:57:58.000]   an interesting vehicle that I got to drive
[00:57:58.000 --> 00:58:00.400]   quite a bit is the Cadillac Super Cruise
[00:58:00.400 --> 00:58:01.500]   the CT6
[00:58:01.500 --> 00:58:04.100]   which is very much constrained
[00:58:04.100 --> 00:58:05.900]   geographically to highway driving
[00:58:05.900 --> 00:58:07.700]   and
[00:58:07.700 --> 00:58:10.800]   the loudest proudest of them all
[00:58:10.800 --> 00:58:14.200]   George Hotz of the ComAi OpenPilot
[00:58:14.200 --> 00:58:16.200]   I'll just leave that there
[00:58:16.200 --> 00:58:20.100]   So
[00:58:20.100 --> 00:58:22.300]   where can AI help?
[00:58:22.300 --> 00:58:28.700]   We'll get into the details of the coming lectures
[00:58:28.700 --> 00:58:30.200]   on each individual component
[00:58:30.200 --> 00:58:32.000]   I'd like to give some examples
[00:58:32.000 --> 00:58:36.700]   the key areas, problem spaces
[00:58:36.700 --> 00:58:39.500]   that we can use machine learning
[00:58:39.500 --> 00:58:40.600]   to solve from data
[00:58:40.600 --> 00:58:42.800]   is localization and mapping
[00:58:42.800 --> 00:58:45.600]   so being able to localize yourself in the space
[00:58:45.600 --> 00:58:48.300]   the very first question that a robot needs to answer
[00:58:48.300 --> 00:58:49.600]   where am I?
[00:58:51.200 --> 00:58:52.400]   Scene understanding
[00:58:52.400 --> 00:58:54.900]   taking the scene in and interpreting that scene
[00:58:54.900 --> 00:58:57.100]   detecting all the entities in the scene
[00:58:57.100 --> 00:59:01.100]   detecting the class of those entities
[00:59:01.100 --> 00:59:04.100]   in order to then do movement planning
[00:59:04.100 --> 00:59:05.700]   to move around those entities
[00:59:05.700 --> 00:59:07.700]   and finally driver state
[00:59:07.700 --> 00:59:10.400]   essential element for the human-robot interaction
[00:59:10.400 --> 00:59:12.200]   perceive everything about the driver
[00:59:12.200 --> 00:59:14.300]   everything about the pedestrian and the cyclist
[00:59:14.300 --> 00:59:15.600]   and the cars outside
[00:59:15.600 --> 00:59:17.500]   the human element of those
[00:59:17.500 --> 00:59:21.000]   the human perception side
[00:59:22.000 --> 00:59:23.500]   so first the where am I?
[00:59:23.500 --> 00:59:25.000]   visual odometry
[00:59:25.000 --> 00:59:26.900]   using camera sensors
[00:59:26.900 --> 00:59:29.700]   which is really where
[00:59:29.700 --> 00:59:31.900]   once again deep learning is most
[00:59:31.900 --> 00:59:35.300]   the vision sensor is the most amenable
[00:59:35.300 --> 00:59:36.800]   to learning based approaches
[00:59:36.800 --> 00:59:38.700]   and visual odometry
[00:59:38.700 --> 00:59:41.100]   is using camera to localize yourself
[00:59:41.100 --> 00:59:42.700]   to answer the where am I question
[00:59:42.700 --> 00:59:47.000]   the traditional approaches of SLAM
[00:59:49.200 --> 00:59:51.400]   detect features in the scene
[00:59:51.400 --> 00:59:54.000]   and track them through time
[00:59:54.000 --> 00:59:55.100]   from frame to frame
[00:59:55.100 --> 00:59:56.700]   and from the movement
[00:59:56.700 --> 00:59:58.300]   of those features
[00:59:58.300 --> 01:00:00.000]   are able to estimate
[01:00:00.000 --> 01:00:01.900]   thousands of features
[01:00:01.900 --> 01:00:02.900]   tracking
[01:00:02.900 --> 01:00:04.500]   estimate the location
[01:00:04.500 --> 01:00:06.900]   the orientation of the vehicle
[01:00:06.900 --> 01:00:07.900]   or the camera
[01:00:07.900 --> 01:00:13.400]   those methods with stereo vision
[01:00:13.400 --> 01:00:16.600]   first requires taking two camera streams
[01:00:16.600 --> 01:00:17.900]   on distorting them
[01:00:18.100 --> 01:00:19.500]   computing disparity map
[01:00:19.500 --> 01:00:21.900]   from the different perspectives of the two camera
[01:00:21.900 --> 01:00:24.400]   computing the matching between the two
[01:00:24.400 --> 01:00:27.000]   the feature detection
[01:00:27.000 --> 01:00:28.900]   the sift and fast
[01:00:28.900 --> 01:00:31.000]   or any of the methods of extracting
[01:00:31.000 --> 01:00:32.900]   non deep learning methods of this
[01:00:32.900 --> 01:00:34.300]   extracting features
[01:00:34.300 --> 01:00:36.500]   strong detectable features
[01:00:36.500 --> 01:00:37.500]   that can be tracked through
[01:00:37.500 --> 01:00:38.700]   from frame to frame
[01:00:38.700 --> 01:00:40.100]   tracking those features
[01:00:40.100 --> 01:00:42.200]   and estimating the trajectory
[01:00:42.200 --> 01:00:44.500]   the orientation of the camera
[01:00:44.500 --> 01:00:47.200]   that's the traditional approach to visual odometry
[01:00:48.200 --> 01:00:51.400]   in the recent years since 2015
[01:00:51.400 --> 01:00:54.800]   but most success in the last year
[01:00:54.800 --> 01:00:58.300]   has been the end-to-end deep learning approaches
[01:00:58.300 --> 01:01:00.700]   either stereo or monocular cameras
[01:01:00.700 --> 01:01:02.300]   DeepVO
[01:01:02.300 --> 01:01:05.100]   is one of the most successful
[01:01:05.100 --> 01:01:08.500]   the end-to-end method is taking a sequence of images
[01:01:08.500 --> 01:01:10.300]   extracting with a CNN
[01:01:10.300 --> 01:01:11.800]   from each image
[01:01:11.800 --> 01:01:14.400]   essential features from each image
[01:01:14.400 --> 01:01:16.100]   and then using RNN
[01:01:16.100 --> 01:01:17.200]   recurrent neural network
[01:01:17.200 --> 01:01:18.900]   to track over time
[01:01:18.900 --> 01:01:20.800]   the trajectory the pose of the camera
[01:01:20.800 --> 01:01:25.300]   image to pose
[01:01:25.300 --> 01:01:26.300]   end-to-end
[01:01:26.300 --> 01:01:29.500]   here's the visualization on a KITTI dataset
[01:01:29.500 --> 01:01:31.600]   using DeepVO
[01:01:31.600 --> 01:01:35.200]   again taking the video up on the top right
[01:01:35.200 --> 01:01:36.400]   as an input
[01:01:36.400 --> 01:01:38.500]   and estimating what's visualized
[01:01:38.500 --> 01:01:41.500]   is the position of the vehicle
[01:01:41.500 --> 01:01:44.000]   in red is the estimate
[01:01:44.600 --> 01:01:46.500]   based again end-to-end
[01:01:46.500 --> 01:01:48.100]   with a CNN and RNN
[01:01:48.100 --> 01:01:50.600]   the in red is the estimate
[01:01:50.600 --> 01:01:52.500]   in blue is the ground truth
[01:01:52.500 --> 01:01:53.700]   in the KITTI dataset
[01:01:53.700 --> 01:01:59.400]   so this removes a lot of the modular parts of SLAM
[01:01:59.400 --> 01:02:01.700]   a visual odometry
[01:02:01.700 --> 01:02:04.200]   and allows it to be end-to-end
[01:02:04.200 --> 01:02:06.000]   which means it's learnable
[01:02:06.000 --> 01:02:07.800]   which means it gets better with data
[01:02:07.800 --> 01:02:10.100]   that's huge
[01:02:10.100 --> 01:02:13.000]   and that's vision alone
[01:02:14.100 --> 01:02:16.700]   this is one of the exciting opportunities for AI
[01:02:16.700 --> 01:02:18.800]   or people working in AI
[01:02:18.800 --> 01:02:21.200]   is the ability to
[01:02:21.200 --> 01:02:23.100]   use a single sensor
[01:02:23.100 --> 01:02:25.000]   and perhaps the most inspiring
[01:02:25.000 --> 01:02:27.700]   because that sensor is similar to our own
[01:02:27.700 --> 01:02:30.600]   the sensor that we ourselves use
[01:02:30.600 --> 01:02:32.100]   of our eyes
[01:02:32.100 --> 01:02:34.200]   to use that alone
[01:02:34.200 --> 01:02:36.400]   as the primary sensor to control a vehicle
[01:02:36.400 --> 01:02:38.300]   that's really exciting
[01:02:38.300 --> 01:02:40.100]   and the fact that deep learning
[01:02:40.100 --> 01:02:41.300]   that the vision
[01:02:41.300 --> 01:02:42.500]   visible light
[01:02:42.500 --> 01:02:44.700]   is the most amenable to deep learning approaches
[01:02:44.700 --> 01:02:45.900]   makes this
[01:02:45.900 --> 01:02:48.700]   particularly an exciting area for deep learning research
[01:02:48.700 --> 01:02:50.900]   scene understanding of course
[01:02:50.900 --> 01:02:52.900]   we can do a thousand slides on this
[01:02:52.900 --> 01:02:55.000]   traditionally object detection
[01:02:55.000 --> 01:02:56.500]   pedestrians, vehicles
[01:02:56.500 --> 01:02:59.300]   there is a bunch of different types of classifiers
[01:02:59.300 --> 01:03:00.400]   and feature extractors
[01:03:00.400 --> 01:03:01.500]   heart-like features
[01:03:01.500 --> 01:03:03.100]   and deep learning
[01:03:03.100 --> 01:03:04.900]   has basically taken over
[01:03:04.900 --> 01:03:06.700]   and dominated every aspect
[01:03:06.700 --> 01:03:08.900]   of scene interpretation
[01:03:08.900 --> 01:03:10.100]   perception
[01:03:10.100 --> 01:03:11.200]   understanding
[01:03:11.200 --> 01:03:12.000]   tracking
[01:03:12.500 --> 01:03:14.900]   recognition classification detection problems
[01:03:14.900 --> 01:03:17.000]   and audio
[01:03:17.000 --> 01:03:18.300]   can't forget audio
[01:03:18.300 --> 01:03:22.900]   that we can use audio
[01:03:22.900 --> 01:03:24.900]   as source of information
[01:03:24.900 --> 01:03:27.400]   whether that's detecting honks or in this case
[01:03:27.400 --> 01:03:29.600]   using the audio of the tires
[01:03:29.600 --> 01:03:31.000]   microphones on the tires
[01:03:31.000 --> 01:03:34.100]   to determine visualize there's a spectrogram
[01:03:34.100 --> 01:03:35.200]   of the audio coming in
[01:03:40.600 --> 01:03:42.700]   for those of you who are particularly have a
[01:03:42.700 --> 01:03:45.300]   particularly tuned ear can listen
[01:03:45.300 --> 01:03:46.700]   to the different
[01:03:46.700 --> 01:03:48.500]   audio coming in here
[01:03:48.500 --> 01:03:53.300]   of wet road and dry road after the rain
[01:03:53.300 --> 01:03:56.100]   so there's no rain but the road is nevertheless wet
[01:03:56.100 --> 01:03:59.600]   and detecting that is extremely important for vehicles
[01:03:59.600 --> 01:04:01.700]   because they still don't have traction control
[01:04:01.700 --> 01:04:03.300]   is that have poor control
[01:04:03.300 --> 01:04:06.000]   in road to road surface
[01:04:06.000 --> 01:04:07.600]   tire road surface connection
[01:04:07.600 --> 01:04:10.100]   and being able to detect that from just audio
[01:04:10.500 --> 01:04:12.000]   is a very interesting approach
[01:04:12.000 --> 01:04:16.200]   finally
[01:04:16.200 --> 01:04:17.800]   or not finally next
[01:04:17.800 --> 01:04:19.800]   for the perception control side finally
[01:04:19.800 --> 01:04:21.600]   is the movement planning
[01:04:21.600 --> 01:04:22.900]   getting from A to point
[01:04:22.900 --> 01:04:24.200]   from point A to point B
[01:04:24.200 --> 01:04:25.800]   traditional approaches
[01:04:25.800 --> 01:04:28.800]   the optimization based approach
[01:04:28.800 --> 01:04:31.100]   determine the optimal control
[01:04:31.100 --> 01:04:33.400]   try to reduce the problem
[01:04:33.400 --> 01:04:35.200]   formalize the problem in a way
[01:04:35.200 --> 01:04:37.700]   that's amenable to optimization
[01:04:37.700 --> 01:04:39.200]   based approaches
[01:04:39.300 --> 01:04:43.200]   there's a lot of assumptions that need to be made
[01:04:43.200 --> 01:04:45.900]   but once those assumptions are made
[01:04:45.900 --> 01:04:47.400]   you're able to determine
[01:04:47.400 --> 01:04:48.900]   generate
[01:04:48.900 --> 01:04:52.400]   thousands or millions of possible trajectories
[01:04:52.400 --> 01:04:53.800]   and have an objective function
[01:04:53.800 --> 01:04:55.800]   would determine which of the trajectories to take
[01:04:55.800 --> 01:04:57.700]   here's a race car optimizing
[01:04:57.700 --> 01:05:00.300]   how to take a turn at high speed
[01:05:00.300 --> 01:05:03.500]   with deep learning
[01:05:03.500 --> 01:05:05.600]   reinforcement learning
[01:05:07.800 --> 01:05:10.100]   the application neural networks to reinforcement learning
[01:05:10.100 --> 01:05:12.000]   is particularly exciting
[01:05:12.000 --> 01:05:15.400]   for both the control and the planning side
[01:05:15.400 --> 01:05:19.300]   so that's where
[01:05:19.300 --> 01:05:22.100]   the two of the competitions we're doing in this class
[01:05:22.100 --> 01:05:22.900]   coming to play
[01:05:22.900 --> 01:05:26.500]   the simplistic two-dimensional world of deep traffic
[01:05:26.500 --> 01:05:31.000]   and the high speed moving
[01:05:31.000 --> 01:05:32.900]   high risk
[01:05:32.900 --> 01:05:35.500]   world of deep crash
[01:05:36.500 --> 01:05:38.600]   (car crash)
[01:05:38.600 --> 01:05:40.400]   we'll explore those tomorrow
[01:05:40.400 --> 01:05:44.900]   tomorrow's lectures on deep reinforcement learning
[01:05:44.900 --> 01:05:47.800]   and finally driver state
[01:05:47.800 --> 01:05:50.600]   detecting everything about the driver
[01:05:50.600 --> 01:05:52.500]   and then interacting with them
[01:05:52.500 --> 01:05:53.900]   on the left and green
[01:05:53.900 --> 01:05:55.200]   are the easier problems
[01:05:55.200 --> 01:05:57.300]   on the right and red are the harder problems
[01:05:57.300 --> 01:05:58.700]   in terms of perception
[01:05:58.700 --> 01:05:59.400]   in terms of
[01:05:59.400 --> 01:06:02.400]   how amenable they are to deep learning methods
[01:06:02.400 --> 01:06:04.300]   body pose estimation
[01:06:04.500 --> 01:06:06.000]   is a very well studied
[01:06:06.000 --> 01:06:08.100]   problem
[01:06:08.100 --> 01:06:10.300]   we have extremely good detectors
[01:06:10.300 --> 01:06:11.700]   for estimating the pose
[01:06:11.700 --> 01:06:14.400]   the hands, the elbows, the shoulders
[01:06:14.400 --> 01:06:16.900]   every aspect, visible aspect of the body
[01:06:16.900 --> 01:06:20.100]   head pose, the orientation of the head
[01:06:20.100 --> 01:06:22.000]   we're extremely good at that
[01:06:22.000 --> 01:06:25.700]   and as we get smaller and smaller in terms of size
[01:06:25.700 --> 01:06:26.800]   blink rate
[01:06:26.800 --> 01:06:28.400]   blink duration
[01:06:28.400 --> 01:06:29.700]   eye pose
[01:06:29.700 --> 01:06:30.900]   and blink dynamics
[01:06:30.900 --> 01:06:32.400]   start getting more and more difficult
[01:06:32.400 --> 01:06:34.200]   all of these metrics
[01:06:34.300 --> 01:06:36.600]   all of these metrics extremely important
[01:06:36.600 --> 01:06:38.400]   for detecting things like drowsiness
[01:06:38.400 --> 01:06:40.700]   or as components of detecting emotion
[01:06:40.700 --> 01:06:42.700]   or where people are looking
[01:06:42.700 --> 01:06:45.700]   in driving where your head is turned
[01:06:45.700 --> 01:06:47.800]   is not necessarily where you're looking
[01:06:47.800 --> 01:06:50.500]   in regular life
[01:06:50.500 --> 01:06:53.100]   non-driving life
[01:06:53.100 --> 01:06:54.200]   when you look somewhere
[01:06:54.200 --> 01:06:55.700]   you usually turn your head
[01:06:55.700 --> 01:06:58.800]   to look with your eyes
[01:06:58.800 --> 01:07:02.800]   in driving your head often stays still
[01:07:02.800 --> 01:07:04.000]   or moves very subtly
[01:07:04.200 --> 01:07:05.800]   your eyes do a lot more moving
[01:07:05.800 --> 01:07:07.500]   it's the kind of
[01:07:07.500 --> 01:07:11.200]   effect that we described as the lizard owl effect
[01:07:11.200 --> 01:07:15.100]   some fraction of people a small fraction are owls
[01:07:15.100 --> 01:07:17.100]   meaning they move their head a lot
[01:07:17.100 --> 01:07:19.900]   and some people
[01:07:19.900 --> 01:07:21.700]   most people are lizards
[01:07:21.700 --> 01:07:24.000]   moving eyes to allocate their attention
[01:07:24.000 --> 01:07:25.800]   the problem with eyes
[01:07:25.800 --> 01:07:27.800]   is from the computer vision perspective
[01:07:27.800 --> 01:07:29.500]   they're much harder to detect in
[01:07:29.500 --> 01:07:31.700]   lighting variation in real-world conditions
[01:07:32.200 --> 01:07:34.300]   they get harder and we'll discuss how to deal with it
[01:07:34.300 --> 01:07:35.800]   of course
[01:07:35.800 --> 01:07:37.300]   that's where deep learning steps up
[01:07:37.300 --> 01:07:39.100]   and really helps with real-world data
[01:07:39.100 --> 01:07:42.300]   cognitive load we'll discuss as well
[01:07:42.300 --> 01:07:44.300]   estimating the cognitive load of the driver
[01:07:44.300 --> 01:07:47.300]   to give a quick clip
[01:07:47.300 --> 01:07:49.900]   is this is the driver glance we've seen before
[01:07:49.900 --> 01:07:51.500]   estimating the very
[01:07:51.500 --> 01:07:55.500]   most important problem on driver state side
[01:07:55.500 --> 01:07:58.000]   is
[01:07:58.000 --> 01:08:00.500]   determining whether they're looking on road
[01:08:00.500 --> 01:08:01.400]   or off-road
[01:08:02.100 --> 01:08:03.700]   it's the dumbest simplest
[01:08:03.700 --> 01:08:05.500]   but most important aspect
[01:08:05.500 --> 01:08:06.400]   are they looking at
[01:08:06.400 --> 01:08:07.400]   are they in the seat
[01:08:07.400 --> 01:08:08.500]   and looking on the road
[01:08:08.500 --> 01:08:09.600]   or are they not
[01:08:09.600 --> 01:08:13.600]   that's driver glance classification
[01:08:13.600 --> 01:08:17.200]   not estimating the XYZ geometric orientation
[01:08:17.200 --> 01:08:18.000]   where they're looking
[01:08:18.000 --> 01:08:21.300]   but actually binary class classification
[01:08:21.300 --> 01:08:22.800]   on road or off-road
[01:08:22.800 --> 01:08:24.800]   body pose estimation
[01:08:24.800 --> 01:08:27.400]   determining of the hands are on wheel
[01:08:27.400 --> 01:08:28.600]   or not
[01:08:28.600 --> 01:08:30.600]   determining if the body alignment
[01:08:30.600 --> 01:08:32.300]   is standard is good
[01:08:32.300 --> 01:08:34.200]   for seat belt
[01:08:34.200 --> 01:08:35.200]   for safety
[01:08:35.200 --> 01:08:37.300]   this is one of the important things
[01:08:37.300 --> 01:08:38.500]   for autonomous vehicles
[01:08:38.500 --> 01:08:41.200]   if there's an imminent danger to the driver
[01:08:41.200 --> 01:08:44.400]   the driver should be asked to return to a position
[01:08:44.400 --> 01:08:45.400]   that is safe for them
[01:08:45.400 --> 01:08:47.100]   in a case of a crash
[01:08:47.100 --> 01:08:49.100]   driver in motion
[01:08:49.100 --> 01:08:55.500]   on the top is a satisfied
[01:08:55.500 --> 01:08:58.100]   on the bottom is a frustrated driver
[01:08:58.900 --> 01:09:00.700]   they self-reported satisfied
[01:09:00.700 --> 01:09:02.400]   this is with a voice-based navigation
[01:09:02.400 --> 01:09:03.300]   one of the biggest
[01:09:03.300 --> 01:09:05.900]   sources of frustrations for people in cars
[01:09:05.900 --> 01:09:07.200]   is voice-based navigation
[01:09:07.200 --> 01:09:09.900]   trying to tell an artificial intelligence system
[01:09:09.900 --> 01:09:11.500]   using your voice alone
[01:09:11.500 --> 01:09:12.600]   where you would like to go
[01:09:12.600 --> 01:09:15.000]   huge source of frustration
[01:09:15.000 --> 01:09:17.400]   one of the interesting things
[01:09:17.400 --> 01:09:19.200]   in our large data set that we have
[01:09:19.200 --> 01:09:20.900]   from the effective computing
[01:09:20.900 --> 01:09:22.300]   perspective is determining
[01:09:22.300 --> 01:09:23.400]   which of the features
[01:09:23.400 --> 01:09:26.800]   are most commonly associated with frustrated
[01:09:26.800 --> 01:09:28.100]   voice-based interaction
[01:09:28.300 --> 01:09:29.500]   and that's a smile
[01:09:29.500 --> 01:09:30.300]   shown there
[01:09:30.300 --> 01:09:32.400]   it's the counterintuitive notion
[01:09:32.400 --> 01:09:34.000]   that emotion
[01:09:34.000 --> 01:09:35.900]   in particular emotion in the car
[01:09:35.900 --> 01:09:37.400]   is very context dependent
[01:09:37.400 --> 01:09:39.500]   that smiling is not necessarily
[01:09:39.500 --> 01:09:40.500]   a sign of happiness
[01:09:40.500 --> 01:09:41.600]   and
[01:09:41.600 --> 01:09:43.000]   the stoic
[01:09:43.000 --> 01:09:44.900]   bored look
[01:09:44.900 --> 01:09:46.800]   of the driver up top
[01:09:46.800 --> 01:09:50.300]   is not necessarily a reflection of unhappiness
[01:09:50.300 --> 01:09:52.000]   he is indeed
[01:09:52.000 --> 01:09:53.600]   a 10 out of 10
[01:09:53.600 --> 01:09:56.400]   on terms of satisfaction with the experience
[01:09:56.500 --> 01:10:00.500]   if he has ever been satisfied with anything
[01:10:00.500 --> 01:10:04.100]   happens to be Dan Brown
[01:10:04.100 --> 01:10:06.200]   one of the amazing engineers in our team
[01:10:06.200 --> 01:10:08.200]   cognitive load
[01:10:08.200 --> 01:10:10.400]   estimating from the eye region
[01:10:10.400 --> 01:10:12.000]   and sequences of images
[01:10:12.000 --> 01:10:14.100]   3D convolutional neural networks
[01:10:14.100 --> 01:10:17.200]   taking in a sequence of images from the eye
[01:10:17.200 --> 01:10:19.800]   looking at the blink dynamics in the eye position
[01:10:19.800 --> 01:10:21.400]   to determine the cognitive load
[01:10:21.400 --> 01:10:22.800]   from zero to two
[01:10:22.800 --> 01:10:24.600]   how deep in thought you are
[01:10:25.500 --> 01:10:27.600]   two paths to autonomous future
[01:10:27.600 --> 01:10:28.900]   again
[01:10:28.900 --> 01:10:31.200]   I would like to
[01:10:31.200 --> 01:10:32.200]   maybe
[01:10:32.200 --> 01:10:33.600]   for the last time
[01:10:33.600 --> 01:10:35.500]   but probably not
[01:10:35.500 --> 01:10:37.300]   argue for the one on the left
[01:10:37.300 --> 01:10:39.000]   because our brilliant
[01:10:39.000 --> 01:10:40.300]   much smarter than me
[01:10:40.300 --> 01:10:42.800]   guest speakers will argue for the one on the right
[01:10:42.800 --> 01:10:46.300]   the human centered approach
[01:10:46.300 --> 01:10:49.600]   allows us to solve the problems of 99% accuracy
[01:10:49.600 --> 01:10:52.000]   of localization scene understanding movement planning
[01:10:52.000 --> 01:10:54.300]   those are the problems we're taking on this class
[01:10:54.600 --> 01:10:56.900]   the scene segmentation that we'll talk about on Thursday
[01:10:56.900 --> 01:10:58.500]   the control
[01:10:58.500 --> 01:10:59.900]   that we'll talk about tomorrow
[01:10:59.900 --> 01:11:02.500]   and the driver state that we'll talk about next Wednesday
[01:11:02.500 --> 01:11:03.600]   these problems
[01:11:03.600 --> 01:11:04.800]   can be solved
[01:11:04.800 --> 01:11:06.200]   with deep learning today
[01:11:06.200 --> 01:11:08.000]   the problems on the right
[01:11:08.000 --> 01:11:10.400]   solving them to close to 100% accuracy
[01:11:10.400 --> 01:11:13.100]   are extremely difficult and maybe decades away
[01:11:13.100 --> 01:11:15.100]   because for full autonomy
[01:11:15.100 --> 01:11:18.300]   to be here
[01:11:18.300 --> 01:11:20.000]   we have to solve this situation
[01:11:20.000 --> 01:11:22.400]   I've shown this many times Arctic Triumph
[01:11:23.200 --> 01:11:24.800]   we have to solve this situation
[01:11:24.800 --> 01:11:28.500]   I give you just a few examples
[01:11:28.500 --> 01:11:34.300]   what do you do?
[01:11:34.300 --> 01:11:37.100]   you have to solve this situation
[01:11:37.100 --> 01:11:47.500]   a sort of subtler situation here
[01:11:47.500 --> 01:11:48.400]   is a
[01:11:48.400 --> 01:11:51.400]   is a busy crosswalk
[01:11:52.100 --> 01:11:55.600]   where no autonomous vehicle will ever have a hope of getting through
[01:11:55.600 --> 01:11:57.200]   unless it asserts itself
[01:11:57.200 --> 01:12:00.600]   and there's a couple of vehicles here that kind of
[01:12:00.600 --> 01:12:02.200]   nudge themselves through
[01:12:02.200 --> 01:12:03.800]   or at least
[01:12:03.800 --> 01:12:06.200]   when they have the right of way don't necessarily nudge
[01:12:06.200 --> 01:12:08.600]   but don't hesitate when a pedestrian is present
[01:12:08.600 --> 01:12:10.800]   an ambulance flying by even though
[01:12:10.800 --> 01:12:12.300]   if you use a
[01:12:12.300 --> 01:12:14.200]   trajectory so
[01:12:14.200 --> 01:12:16.900]   pedestrian intent modeling algorithm
[01:12:16.900 --> 01:12:19.400]   to predict the momentum of the pedestrian
[01:12:20.400 --> 01:12:22.400]   to estimate where they can possibly go
[01:12:22.400 --> 01:12:24.800]   you would then autonomous vehicle will stop
[01:12:24.800 --> 01:12:26.700]   but these vehicles don't stop
[01:12:26.700 --> 01:12:28.600]   they assert themselves they move forward
[01:12:28.600 --> 01:12:32.300]   now
[01:12:32.300 --> 01:12:34.400]   for a full autonomy system
[01:12:34.400 --> 01:12:38.100]   this may not be the last time I show this video
[01:12:38.100 --> 01:12:41.100]   but because
[01:12:41.100 --> 01:12:42.800]   it's taking full control
[01:12:42.800 --> 01:12:46.800]   it's following a reward function and objective function
[01:12:46.800 --> 01:12:49.800]   and all of the problems the ethical
[01:12:50.400 --> 01:12:52.900]   and the AI problems that arise
[01:12:52.900 --> 01:12:55.500]   like this coast runner problem
[01:12:55.500 --> 01:12:57.200]   will arise
[01:12:57.200 --> 01:12:59.400]   so we have to solve those problems
[01:12:59.400 --> 01:13:01.100]   we have to design that objective function
[01:13:01.100 --> 01:13:03.100]   so
[01:13:03.100 --> 01:13:04.100]   with that
[01:13:04.100 --> 01:13:06.700]   I'd like to thank you
[01:13:06.700 --> 01:13:09.500]   and encourage you to come tomorrow
[01:13:09.500 --> 01:13:11.600]   because you get a chance to participate
[01:13:11.600 --> 01:13:14.400]   in deep traffic, deep reinforcement learning competition
[01:13:14.400 --> 01:13:15.300]   thank you very much
[01:13:15.300 --> 01:13:17.540]   (applause)

