
[00:00:00.000 --> 00:00:04.680]   Like big picture, these next couple of decades, what's happening with AI?
[00:00:04.680 --> 00:00:08.540]   Does it feel like another technology, like metaverse or social, or does it feel like
[00:00:08.540 --> 00:00:11.280]   a fundamentally different thing in the course of human history?
[00:00:11.280 --> 00:00:13.400]   I think it's going to be pretty fundamental.
[00:00:13.400 --> 00:00:19.100]   I think it's going to be more like the creation of computing in the first place, right?
[00:00:19.100 --> 00:00:26.520]   So you'll get all these new apps in the same way that when you got the web or you got mobile
[00:00:26.520 --> 00:00:31.320]   phones, you got people basically rethought all these experiences and a lot of things
[00:00:31.320 --> 00:00:33.240]   that weren't possible before now became possible.
[00:00:33.240 --> 00:00:38.780]   So I think that will happen, but I think it's a much lower level innovation.
[00:00:38.780 --> 00:00:44.000]   It's going to be more like going from people didn't have computers to people have computers.
[00:00:44.000 --> 00:00:49.600]   The cosmic scale, obviously, it'll happen quickly over a couple of decades or something.
[00:00:49.600 --> 00:00:55.160]   But I do think that there is some set of people who are afraid of like, it really just kind
[00:00:55.160 --> 00:00:58.920]   of spins and goes from being like somewhat intelligent to extremely intelligent overnight.
[00:00:58.920 --> 00:01:02.620]   And I just think that there's all these physical constraints that make that, so that that's
[00:01:02.620 --> 00:01:04.480]   unlikely to happen.
[00:01:04.480 --> 00:01:07.820]   I just don't really see that playing out.
[00:01:07.820 --> 00:01:11.880]   So I think you'll have, I think we'll have time to kind of acclimate a bit, but it will
[00:01:11.880 --> 00:01:17.160]   really change the way that we work and give people all these creative tools to do different
[00:01:17.160 --> 00:01:22.960]   things that they, yeah, I think it's going to be, it's going to really enable people
[00:01:22.960 --> 00:01:25.960]   to do the things that they want a lot more is my view.
[00:01:25.960 --> 00:01:30.360]   Is it your view that like on a cosmic scale, if you think like humans evolved and then
[00:01:30.360 --> 00:01:35.000]   like AI happened and then they like went out through the galaxy or maybe it takes many
[00:01:35.000 --> 00:01:40.260]   decades, maybe it takes a century, but like, is that like the grand scheme of what's happening
[00:01:40.260 --> 00:01:41.440]   right now in history?
[00:01:41.440 --> 00:01:43.360]   I think that's tricky.
[00:01:43.360 --> 00:01:49.080]   I think people like to, I mean, the history of humanity, I think has been people basically,
[00:01:49.080 --> 00:01:55.680]   you know, thinking that certain aspects of humanity are like really unique in different
[00:01:55.680 --> 00:02:01.960]   ways and then coming to grips with the fact that that's not true, but humanity is actually
[00:02:01.960 --> 00:02:03.720]   still super special, right?
[00:02:03.720 --> 00:02:09.160]   So it's, it's like, we thought that the earth was the center of the universe and it's like,
[00:02:09.160 --> 00:02:12.720]   it's not, but like, it's like humans are still pretty awesome, right?
[00:02:12.720 --> 00:02:14.240]   And pretty unique.
[00:02:14.240 --> 00:02:20.440]   I think that another bias that people tend to have is thinking that intelligence is somehow
[00:02:20.440 --> 00:02:24.120]   kind of fundamentally connected to life.
[00:02:24.120 --> 00:02:26.720]   And it's not actually clear that it is.
[00:02:26.720 --> 00:02:32.080]   I mean, I don't know that we have a clear enough definition of consciousness or life
[00:02:32.080 --> 00:02:38.080]   to kind of fully interrogate this, but I know there's all this science fiction about, okay,
[00:02:38.080 --> 00:02:44.360]   you create intelligence and now it like starts taking on all these human like behaviors and
[00:02:44.360 --> 00:02:45.360]   things like that.
[00:02:45.360 --> 00:02:48.860]   But I actually think that the current incarnation of all this stuff, at least kind of feels
[00:02:48.860 --> 00:02:53.280]   like it's going in a direction where intelligence can be pretty separated from consciousness
[00:02:53.280 --> 00:02:59.360]   and agency and things like that, that I think just makes it a super valuable tool.
[00:02:59.360 --> 00:03:00.360]   So I don't know.
[00:03:00.360 --> 00:03:04.600]   I mean, obviously it's very difficult to predict what direction this stuff goes in over time,
[00:03:04.600 --> 00:03:10.680]   which is why I don't think anyone should be dogmatic about how they plan to develop it
[00:03:10.680 --> 00:03:11.680]   or what they plan to do.
[00:03:11.680 --> 00:03:13.880]   I think you want to kind of look at like each release.
[00:03:13.880 --> 00:03:14.880]   I think you want to kind of look at like each release.
[00:03:14.880 --> 00:03:15.880]   I think you want to kind of look at like each release.
[00:03:15.880 --> 00:03:16.880]   I think you want to kind of look at like each release.
[00:03:16.880 --> 00:03:17.880]   I think you want to kind of look at like each release.
[00:03:17.880 --> 00:03:18.880]   I think you want to kind of look at like each release.

