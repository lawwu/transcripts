
[00:00:00.000 --> 00:00:02.360]   All right, welcome back everyone.
[00:00:02.360 --> 00:00:05.900]   As I promised in the first week,
[00:00:05.900 --> 00:00:09.400]   the goal of this class is not for me
[00:00:09.400 --> 00:00:11.520]   to talk to you the entire time.
[00:00:11.520 --> 00:00:13.880]   Today we're actually gonna start with someone
[00:00:13.880 --> 00:00:17.560]   who's much better at explaining this topic than I am.
[00:00:17.560 --> 00:00:21.260]   So I'd like to welcome Sergei Kerev.
[00:00:21.260 --> 00:00:24.280]   Sergei was an AI PhD at Berkeley
[00:00:24.280 --> 00:00:26.760]   and then he started a company called Gradescope.
[00:00:26.760 --> 00:00:29.560]   Gradescope is sort of an automated grading platform
[00:00:29.560 --> 00:00:33.000]   and I first encountered it when I was in my first semester
[00:00:33.000 --> 00:00:36.080]   at Berkeley teaching a 400% calculus class
[00:00:36.080 --> 00:00:40.600]   and Gradescope was kind of a lifesaver in that setting.
[00:00:40.600 --> 00:00:45.160]   Gradescope recently was sold to Turnitin
[00:00:45.160 --> 00:00:49.040]   and Sergei is now the head of AI for STEM there.
[00:00:49.040 --> 00:00:51.240]   So he's gonna talk to you about some of the work
[00:00:51.240 --> 00:00:54.300]   they do there more broadly and then also
[00:00:54.300 --> 00:00:56.000]   some of the topic of the lecture that you watched
[00:00:56.000 --> 00:00:58.280]   on AI and on infrastructure.
[00:00:58.280 --> 00:00:59.200]   So welcome Sergei.
[00:00:59.200 --> 00:01:00.040]   - Thank you.
[00:01:00.040 --> 00:01:00.800]   (audience applauding)
[00:01:00.800 --> 00:01:01.640]   - Thank you.
[00:01:01.640 --> 00:01:07.400]   So I'm actually gonna start with a talk
[00:01:07.400 --> 00:01:11.760]   that is kind of new to me but it's this concept
[00:01:11.760 --> 00:01:14.360]   that when you're building AI applications
[00:01:14.360 --> 00:01:16.160]   or as an investor people pitch you
[00:01:16.160 --> 00:01:20.360]   on whatever they wanna build or maybe as someone
[00:01:20.360 --> 00:01:23.400]   in a company you're considering implementing something
[00:01:23.400 --> 00:01:26.200]   that someone has developed as a product.
[00:01:26.200 --> 00:01:29.280]   How do you actually know whether it's a good thing
[00:01:29.280 --> 00:01:32.960]   to build, fund or deploy at your company?
[00:01:32.960 --> 00:01:37.760]   So since my background is in I guess the company
[00:01:37.760 --> 00:01:40.800]   I started is about grading, I thought a nice lens
[00:01:40.800 --> 00:01:42.960]   to look at it through would be a grading rubric.
[00:01:42.960 --> 00:01:45.840]   Like if you had to grade a potential AI application
[00:01:45.840 --> 00:01:49.080]   what would you look for, what are the dimensions?
[00:01:49.080 --> 00:01:52.480]   So before I get into that, briefly about me,
[00:01:52.480 --> 00:01:53.520]   just gonna move this,
[00:01:54.560 --> 00:01:58.360]   is currently I work on AI specifically
[00:01:58.360 --> 00:02:03.360]   for science technology engineering math at Turnitin.
[00:02:03.360 --> 00:02:06.600]   Turnitin is a pretty big tech company,
[00:02:06.600 --> 00:02:07.840]   actually one of the largest.
[00:02:07.840 --> 00:02:11.040]   We have 35 million students under contract
[00:02:11.040 --> 00:02:13.080]   at over 150 countries.
[00:02:13.080 --> 00:02:16.600]   The way I got there, we're also based in Oakland
[00:02:16.600 --> 00:02:19.120]   so we're neighbors, the way I got there was
[00:02:19.120 --> 00:02:22.080]   through co-founding a company called Gradescope
[00:02:22.080 --> 00:02:24.720]   and Gradescope was as Josh described,
[00:02:24.720 --> 00:02:27.480]   essentially software for grading kind of STEM work.
[00:02:27.480 --> 00:02:30.120]   Turnitin is software for grading and checking
[00:02:30.120 --> 00:02:32.960]   for plagiarism of writing work, so essays
[00:02:32.960 --> 00:02:34.240]   and stuff like that.
[00:02:34.240 --> 00:02:37.560]   So it was a natural kind of match for us to work together.
[00:02:37.560 --> 00:02:43.520]   We found the Gradescope in 2014 and we got acquired
[00:02:43.520 --> 00:02:46.280]   in the fall of 2018, so it's pretty recent to me
[00:02:46.280 --> 00:02:47.800]   to be at Turnitin.
[00:02:47.800 --> 00:02:50.080]   I'm also one of the co-organizers of Full Stack
[00:02:50.080 --> 00:02:53.960]   Deep Learning, which Josh also organized
[00:02:53.960 --> 00:02:55.680]   and some of you I recognize from that,
[00:02:55.680 --> 00:02:57.680]   so thanks for coming.
[00:02:57.680 --> 00:02:59.880]   And then before that I was a PhD at UC Berkeley.
[00:02:59.880 --> 00:03:01.520]   I was working in computer vision.
[00:03:01.520 --> 00:03:05.200]   I was working on using methods from reinforcement learning
[00:03:05.200 --> 00:03:08.840]   for computer vision tasks and towards the end
[00:03:08.840 --> 00:03:11.540]   of my PhD, deep learning started kind of becoming
[00:03:11.540 --> 00:03:12.940]   a thing that you had to do.
[00:03:12.940 --> 00:03:15.040]   So we actually had a deep learning framework
[00:03:15.040 --> 00:03:18.200]   called CAFE that we developed in our lab.
[00:03:18.200 --> 00:03:19.880]   I'm one of the authors in that paper.
[00:03:19.880 --> 00:03:21.880]   It was a fun ride kind of in the last couple of years
[00:03:21.880 --> 00:03:24.440]   of my PhD to really see that take off
[00:03:24.440 --> 00:03:27.480]   and the community grow and CAFE become kind of
[00:03:27.480 --> 00:03:29.920]   the industrial de facto deep learning framework.
[00:03:29.920 --> 00:03:31.500]   Then I graduated and kind of shifted gears
[00:03:31.500 --> 00:03:33.240]   into education technology.
[00:03:33.240 --> 00:03:36.900]   So my goal for these slides here today,
[00:03:36.900 --> 00:03:41.160]   and I'll get to the infrastructure lecture after this,
[00:03:41.160 --> 00:03:44.120]   which I understand you've seen on your own time at home,
[00:03:44.120 --> 00:03:46.800]   so we'll just kind of do mostly Q&A for that.
[00:03:46.800 --> 00:03:49.200]   But my goal for this lecture right now
[00:03:49.200 --> 00:03:51.440]   is to get criteria for evaluating AI projects
[00:03:51.440 --> 00:03:55.160]   and applications, funding, deployment, development.
[00:03:55.160 --> 00:03:59.580]   And this will be with a particular focus on education
[00:03:59.580 --> 00:04:03.740]   because I'm about to give these slides at a conference
[00:04:03.740 --> 00:04:06.120]   for the UN, which is kind of cool,
[00:04:06.120 --> 00:04:07.720]   specifically in the education track.
[00:04:07.720 --> 00:04:10.600]   It's called the UN AI for Good Conference.
[00:04:10.600 --> 00:04:11.580]   So good PR.
[00:04:11.580 --> 00:04:14.640]   So the first thing that I want to convey to you guys
[00:04:14.640 --> 00:04:18.240]   is that it's early days for actually deploying AI
[00:04:18.240 --> 00:04:19.720]   in your product.
[00:04:19.720 --> 00:04:23.900]   So there was a 2018 survey of 300 people or more
[00:04:23.900 --> 00:04:25.960]   that actually worked on machine learning,
[00:04:25.960 --> 00:04:28.600]   kind of as their job from all kinds of industries,
[00:04:28.600 --> 00:04:33.160]   from education to FinTech to developer tools,
[00:04:33.160 --> 00:04:34.400]   all kinds of stuff.
[00:04:34.400 --> 00:04:35.480]   And one of the questions was,
[00:04:35.480 --> 00:04:37.320]   what phase are your AI projects today?
[00:04:37.320 --> 00:04:41.600]   And so production rollout is a small minority
[00:04:41.600 --> 00:04:43.660]   of what people are actually doing with AI.
[00:04:43.660 --> 00:04:46.140]   Most people are still in the feasibility study
[00:04:46.140 --> 00:04:47.560]   or the architecture planning
[00:04:47.560 --> 00:04:50.320]   or the kind of application development phase.
[00:04:50.320 --> 00:04:55.120]   So I think we shouldn't feel bad
[00:04:55.120 --> 00:04:58.360]   that we're not all deploying AI to production if we're not.
[00:04:58.360 --> 00:05:00.880]   And we should feel good about the opportunity that's there
[00:05:00.880 --> 00:05:02.640]   because it's very greenfield still.
[00:05:02.640 --> 00:05:06.000]   But when you start working on it,
[00:05:06.000 --> 00:05:08.520]   you should consider certain criteria
[00:05:08.520 --> 00:05:10.240]   when you decide what to work on.
[00:05:10.240 --> 00:05:13.760]   And the categories I want to suggest are,
[00:05:13.760 --> 00:05:15.500]   one, task formulation.
[00:05:15.500 --> 00:05:19.820]   And the kind of the grading rubrics will be an X,
[00:05:19.820 --> 00:05:22.300]   which means like, you're doing a bad job.
[00:05:22.300 --> 00:05:24.620]   A check minus, which is better, but not perfect.
[00:05:24.620 --> 00:05:26.820]   And then a check plus, which would be like,
[00:05:26.820 --> 00:05:29.660]   that's kind of where you want to be.
[00:05:29.660 --> 00:05:33.880]   User interface/performance requirements.
[00:05:33.880 --> 00:05:36.820]   The difficulty of the technical problem.
[00:05:36.820 --> 00:05:39.460]   The data mode that you initially start with.
[00:05:39.460 --> 00:05:42.820]   And then the flywheel that you can get spinning
[00:05:42.820 --> 00:05:44.520]   as your product is actually shipped.
[00:05:44.520 --> 00:05:47.620]   How does data kind of help your product become better?
[00:05:47.620 --> 00:05:51.580]   So to start with, we can do task formulation.
[00:05:51.580 --> 00:05:55.600]   And what I mean by that is really,
[00:05:55.600 --> 00:05:57.440]   is the problem well-defined?
[00:05:57.440 --> 00:06:00.580]   Can you formulate metrics for it that people can agree on,
[00:06:00.580 --> 00:06:04.020]   that are clear to everyone, and that you can measure?
[00:06:04.020 --> 00:06:07.200]   This is really the foundation of the whole project.
[00:06:07.200 --> 00:06:08.920]   You're not supposed to build a house on sand.
[00:06:08.920 --> 00:06:11.560]   So if you build your whole AI application
[00:06:11.560 --> 00:06:15.900]   on a premise that's flawed, then what are you doing?
[00:06:15.900 --> 00:06:18.940]   So I think the worst thing you can do is develop AI,
[00:06:18.940 --> 00:06:20.940]   or if someone's pitching you as an investor
[00:06:20.940 --> 00:06:23.300]   or a potential employer at a startup,
[00:06:23.300 --> 00:06:26.060]   they're selling AI as just a magical solution
[00:06:26.060 --> 00:06:28.500]   to a problem that hasn't been solved in any way,
[00:06:28.500 --> 00:06:32.340]   and is kind of hard to measure, or potentially unmeasurable.
[00:06:32.340 --> 00:06:35.740]   So what I could give as an example is like,
[00:06:35.740 --> 00:06:39.100]   I'm working on AI for achieving human happiness, right?
[00:06:39.100 --> 00:06:42.840]   Like, I have many questions about that.
[00:06:42.840 --> 00:06:45.220]   How do you achieve happiness without AI?
[00:06:45.220 --> 00:06:46.960]   We don't really know, you know, different,
[00:06:46.960 --> 00:06:49.360]   we can't even agree on a definition of happiness.
[00:06:49.360 --> 00:06:51.280]   How are you gonna measure progress on it?
[00:06:51.280 --> 00:06:53.060]   What is the AI supposed to do?
[00:06:53.060 --> 00:06:55.340]   So I would give this, you know, zero marks.
[00:06:55.340 --> 00:06:57.160]   What?
[00:06:57.160 --> 00:06:59.040]   What's that?
[00:06:59.040 --> 00:07:03.360]   AI, yeah, yeah.
[00:07:03.360 --> 00:07:05.760]   Yeah, build AI, question mark, profit.
[00:07:08.960 --> 00:07:12.360]   A better task formulation is a task that's complicated.
[00:07:12.360 --> 00:07:15.720]   So it's not, you know, very clear how it should be done.
[00:07:15.720 --> 00:07:18.020]   It's complicated, and people have trouble doing it.
[00:07:18.020 --> 00:07:19.920]   But we do know that some people can do it,
[00:07:19.920 --> 00:07:21.640]   and it's possible for us to agree
[00:07:21.640 --> 00:07:23.880]   that someone's doing a good job or not on it.
[00:07:23.880 --> 00:07:28.000]   And here, I think it's very important to have experts,
[00:07:28.000 --> 00:07:30.580]   like subject matter experts in this particular task
[00:07:30.580 --> 00:07:33.540]   involved from day zero, like designing the product,
[00:07:33.540 --> 00:07:38.740]   thinking how it should be deployed, what data you need.
[00:07:38.740 --> 00:07:40.340]   And so an example that I can give
[00:07:40.340 --> 00:07:43.180]   from kind of my current company
[00:07:43.180 --> 00:07:45.840]   is giving students feedback on their writing, right?
[00:07:45.840 --> 00:07:50.000]   So a student submits a piece of writing to a specific topic,
[00:07:50.000 --> 00:07:52.480]   and then what they can get from it
[00:07:52.480 --> 00:07:55.960]   is high-dimensional kind of feedback,
[00:07:55.960 --> 00:07:59.360]   high-quality, high-dimensional feedback on four dimensions.
[00:07:59.360 --> 00:08:02.320]   So how developed are your ideas?
[00:08:02.320 --> 00:08:05.680]   How organized are your thoughts in support of those ideas?
[00:08:05.680 --> 00:08:08.400]   How clear is the language that you're using?
[00:08:08.400 --> 00:08:12.140]   And then the mechanics of the language,
[00:08:12.140 --> 00:08:14.440]   like are you making grammatical mistakes and such?
[00:08:14.440 --> 00:08:17.900]   And this task is definitely hard, right?
[00:08:17.900 --> 00:08:21.520]   And in human worlds, you tend to go and get a master's
[00:08:21.520 --> 00:08:22.520]   to be able to do it.
[00:08:22.520 --> 00:08:24.640]   But we can agree that some people
[00:08:24.640 --> 00:08:25.840]   are better than others at it,
[00:08:25.840 --> 00:08:28.220]   and we can agree that you can do a good job on it.
[00:08:28.220 --> 00:08:30.320]   So if someone gives me an essay,
[00:08:30.320 --> 00:08:33.300]   and I just scribble randomly on it and hand it back to them,
[00:08:33.300 --> 00:08:34.500]   that's bad feedback.
[00:08:34.500 --> 00:08:36.140]   But if I actually take the time to read it,
[00:08:36.140 --> 00:08:37.740]   I highlight certain things.
[00:08:37.740 --> 00:08:38.660]   Someone else reads it,
[00:08:38.660 --> 00:08:40.060]   and they would agree with what I say.
[00:08:40.060 --> 00:08:40.960]   That's good feedback.
[00:08:40.960 --> 00:08:42.400]   So can we replicate that?
[00:08:42.400 --> 00:08:47.180]   And an even better formulation of a task
[00:08:47.180 --> 00:08:49.660]   is something that's so well-defined,
[00:08:49.660 --> 00:08:51.980]   and there's potentially even a good baseline solution for it
[00:08:51.980 --> 00:08:54.060]   that doesn't really use much AI.
[00:08:54.060 --> 00:08:57.700]   That could be just, you can hire anyone in the world,
[00:08:57.700 --> 00:09:00.820]   anyone of six billion people to do it for a cent.
[00:09:00.820 --> 00:09:03.700]   That would be a good baseline to start with.
[00:09:03.700 --> 00:09:06.740]   And so an example could be Facebook face recognition.
[00:09:06.740 --> 00:09:10.140]   So we can all agree, is this the same person or not?
[00:09:10.140 --> 00:09:12.220]   It's a binary kind of prediction that you're making,
[00:09:12.220 --> 00:09:14.120]   like it is this person or not.
[00:09:14.120 --> 00:09:17.900]   And so this would be a really clear task formulation.
[00:09:17.900 --> 00:09:21.040]   The next thing you should think about
[00:09:21.040 --> 00:09:23.800]   is user interface/performance requirements.
[00:09:23.800 --> 00:09:28.320]   The first question is, is the AI entirely autonomous,
[00:09:28.320 --> 00:09:30.420]   or is its goal to assist the user?
[00:09:30.420 --> 00:09:34.180]   Sometimes this is called AI versus IA,
[00:09:34.180 --> 00:09:39.180]   like artificial intelligence is kind of off by itself,
[00:09:39.180 --> 00:09:43.020]   and IA is intelligence augmentation.
[00:09:43.020 --> 00:09:44.680]   So this is like human intelligence,
[00:09:44.680 --> 00:09:46.540]   but augmented by a computer.
[00:09:46.540 --> 00:09:50.760]   And we call this like autonomous or assistance.
[00:09:50.760 --> 00:09:52.700]   What percentage of the time does the AI
[00:09:52.700 --> 00:09:54.340]   need to make a prediction at all?
[00:09:54.340 --> 00:09:58.280]   And if it makes a prediction and the prediction is mistaken,
[00:09:58.280 --> 00:10:01.720]   how bad is that for the situation?
[00:10:01.720 --> 00:10:03.120]   So this is a slide from Josh.
[00:10:03.120 --> 00:10:04.700]   The reason this is kind of important
[00:10:04.700 --> 00:10:08.840]   is because if you wanna get to really good performance,
[00:10:08.840 --> 00:10:11.660]   that might be 10x or 100x as difficult
[00:10:11.660 --> 00:10:14.480]   as getting to like a decent level of performance.
[00:10:14.480 --> 00:10:18.620]   So the worst marks are for a situation
[00:10:18.620 --> 00:10:21.120]   where AI has to be 100% autonomous,
[00:10:21.120 --> 00:10:22.620]   has to predict all the time,
[00:10:22.620 --> 00:10:25.060]   and if it makes any mistake, people die.
[00:10:25.060 --> 00:10:27.760]   And an example of that is a self-driving car, right?
[00:10:27.760 --> 00:10:31.580]   It's like, that's the purpose of it is to be self-driving,
[00:10:31.580 --> 00:10:33.060]   so you're not involved at all.
[00:10:33.060 --> 00:10:35.880]   But if it screws up, then you personally might die.
[00:10:35.880 --> 00:10:39.020]   So the reason it gets low marks,
[00:10:39.020 --> 00:10:41.220]   obviously it's a very enticing application to work on
[00:10:41.220 --> 00:10:43.220]   and the reward is very great,
[00:10:43.220 --> 00:10:44.540]   but the risk is also very great.
[00:10:44.540 --> 00:10:46.340]   It's a difficult problem.
[00:10:46.340 --> 00:10:49.940]   What's a little bit better for you to consider working on
[00:10:49.940 --> 00:10:53.720]   is something where, sure, the AI has to make a prediction
[00:10:53.720 --> 00:10:56.940]   for every input, but it's not so bad
[00:10:56.940 --> 00:10:57.980]   when it makes a mistake
[00:10:57.980 --> 00:11:00.240]   and the user actually can correct the mistake,
[00:11:00.240 --> 00:11:01.880]   but maybe they're annoyed by it.
[00:11:01.880 --> 00:11:04.020]   So an example could be a speech to text transcription
[00:11:04.020 --> 00:11:05.740]   on my phone, right?
[00:11:05.740 --> 00:11:06.760]   I use it often.
[00:11:06.760 --> 00:11:08.740]   It's useful enough for me, but oftentimes,
[00:11:08.740 --> 00:11:10.980]   almost every time, it makes some kind of mistake.
[00:11:10.980 --> 00:11:13.420]   And so here, it's very important to think about the UX
[00:11:13.420 --> 00:11:17.940]   of the product and build in kind of nice user interfaces
[00:11:17.940 --> 00:11:20.180]   for the user to be able to correct the mistakes.
[00:11:20.180 --> 00:11:23.820]   So here, like the last word, I was trying to say trying out,
[00:11:23.820 --> 00:11:26.180]   but it, for some reason, perceived that as trying to,
[00:11:26.180 --> 00:11:28.700]   but it gave me a little button that I could just press
[00:11:28.700 --> 00:11:31.000]   and then one-click correct it.
[00:11:31.000 --> 00:11:34.340]   What's even better is a situation where the AI
[00:11:34.340 --> 00:11:35.940]   doesn't even have to predict every time,
[00:11:35.940 --> 00:11:37.420]   so it's just kind of assisting you,
[00:11:37.420 --> 00:11:39.240]   not automating something.
[00:11:39.240 --> 00:11:41.220]   And actually, maybe the user doesn't even mind
[00:11:41.220 --> 00:11:43.060]   correcting the mistake so much.
[00:11:43.060 --> 00:11:46.360]   And I like to think that that's where we sit at Gradescope.
[00:11:46.360 --> 00:11:49.100]   So what we do is we assist the instructor
[00:11:49.100 --> 00:11:51.260]   in grading student answers,
[00:11:51.260 --> 00:11:53.940]   but we don't actually grade the answers for the instructor.
[00:11:53.940 --> 00:11:57.580]   What we do is we group the answers by content
[00:11:57.580 --> 00:12:00.220]   and then the instructor can decide how to grade them.
[00:12:00.220 --> 00:12:03.300]   So let's say you have all these answers to a given question.
[00:12:03.300 --> 00:12:06.220]   They go through our machine learning processing
[00:12:06.220 --> 00:12:07.820]   and we spit out groups.
[00:12:07.820 --> 00:12:10.860]   The user, and we built a really nice interface
[00:12:10.860 --> 00:12:12.340]   for the user to correct the groups.
[00:12:12.340 --> 00:12:15.500]   So if we made a mistake, they can correct the groups,
[00:12:15.500 --> 00:12:17.800]   they can merge groups, they can delete groups.
[00:12:17.800 --> 00:12:20.860]   They can, they also have to go through all of the groups
[00:12:20.860 --> 00:12:23.180]   to confirm that the answers actually belong in them.
[00:12:23.180 --> 00:12:26.780]   And then they decide how to grade the resulting group.
[00:12:27.820 --> 00:12:30.820]   And the best part of this is the instructors love it
[00:12:30.820 --> 00:12:32.780]   because it saves them a lot of time.
[00:12:32.780 --> 00:12:34.540]   Like even though it's not perfect,
[00:12:34.540 --> 00:12:36.940]   let's say we grouped 80% of the answers,
[00:12:36.940 --> 00:12:39.100]   we still save them like four fifth of the time
[00:12:39.100 --> 00:12:40.580]   that they would have spent.
[00:12:40.580 --> 00:12:44.780]   And so it was important to us to find a way
[00:12:44.780 --> 00:12:47.160]   to start introducing AI into our product
[00:12:47.160 --> 00:12:49.460]   that was like this, where like the AI
[00:12:49.460 --> 00:12:50.860]   didn't have to be perfect,
[00:12:50.860 --> 00:12:52.940]   but the user still found value in it.
[00:12:52.940 --> 00:12:56.920]   So for education applications specifically,
[00:12:57.920 --> 00:13:00.280]   if you kind of think of like performance requirements,
[00:13:00.280 --> 00:13:03.120]   so this could be like accuracy requirements,
[00:13:03.120 --> 00:13:05.400]   going from lower to higher.
[00:13:05.400 --> 00:13:07.360]   If you're aiding the instructor,
[00:13:07.360 --> 00:13:08.960]   the performance requirements was lower
[00:13:08.960 --> 00:13:10.520]   because the instructor is an expert.
[00:13:10.520 --> 00:13:13.200]   So you can kind of save them some time,
[00:13:13.200 --> 00:13:16.840]   but they still take responsibility for the final decisions.
[00:13:16.840 --> 00:13:18.780]   If you're aiding the student directly,
[00:13:18.780 --> 00:13:20.600]   then that's a higher bar to clear
[00:13:20.600 --> 00:13:22.600]   because they don't necessarily know
[00:13:22.600 --> 00:13:24.720]   when the AI is making a mistake or not,
[00:13:24.720 --> 00:13:27.160]   because by definition, they're trying to learn something.
[00:13:27.160 --> 00:13:29.600]   If you're trying to like tell them something that's wrong,
[00:13:29.600 --> 00:13:30.920]   they might learn something that's wrong
[00:13:30.920 --> 00:13:32.400]   that could be very harmful.
[00:13:32.400 --> 00:13:33.880]   And the most harmful yet
[00:13:33.880 --> 00:13:35.840]   is actually replacing the instructor.
[00:13:35.840 --> 00:13:39.160]   So if you start grading student work instead of a human,
[00:13:39.160 --> 00:13:41.080]   then you better be 100% correct
[00:13:41.080 --> 00:13:43.360]   because someone might not get a scholarship
[00:13:43.360 --> 00:13:45.280]   or get into college or something like that
[00:13:45.280 --> 00:13:47.860]   because your AI is not perfect.
[00:13:47.860 --> 00:13:54.400]   The third dimension is technical difficulties.
[00:13:55.400 --> 00:13:57.320]   And so what I mean by this is like,
[00:13:57.320 --> 00:13:58.920]   what do you actually need kind of technically
[00:13:58.920 --> 00:14:00.880]   to solve the problem that you wanna solve?
[00:14:00.880 --> 00:14:03.080]   And you look at analogous solutions,
[00:14:03.080 --> 00:14:05.960]   whether products or open source,
[00:14:05.960 --> 00:14:08.280]   look at the research papers that have been published
[00:14:08.280 --> 00:14:09.720]   and talk to experts.
[00:14:09.720 --> 00:14:12.160]   And the worst place you could be is,
[00:14:12.160 --> 00:14:14.920]   the problem that you wanna solve is like not just one,
[00:14:14.920 --> 00:14:17.880]   but several steps away from what you see working today
[00:14:17.880 --> 00:14:20.120]   or what you've seen working in research.
[00:14:20.120 --> 00:14:22.800]   And this will require like a world-class research team
[00:14:22.800 --> 00:14:25.240]   and just kind of an uncertain timeline.
[00:14:25.240 --> 00:14:28.760]   So an example in education would be a tutor
[00:14:28.760 --> 00:14:31.900]   that can tutor students in all subjects at all grade levels.
[00:14:31.900 --> 00:14:35.560]   We don't really have that for a single subject
[00:14:35.560 --> 00:14:37.080]   or for a single grade level.
[00:14:37.080 --> 00:14:40.300]   So that's several steps removed from where we are today.
[00:14:40.300 --> 00:14:43.400]   What's better is like,
[00:14:43.400 --> 00:14:45.400]   you have reason to believe the problem is solvable,
[00:14:45.400 --> 00:14:48.940]   but you haven't seen it working in production just yet.
[00:14:48.940 --> 00:14:51.540]   So this will require a research team
[00:14:51.540 --> 00:14:54.200]   because it'll require adopting a known solution
[00:14:54.200 --> 00:14:55.880]   to kind of an unknown domain.
[00:14:55.880 --> 00:14:58.520]   And you might not actually get it working,
[00:14:58.520 --> 00:15:02.040]   but it'll at least have a shot.
[00:15:02.040 --> 00:15:04.160]   And an example I could come up with is like,
[00:15:04.160 --> 00:15:07.200]   a robot that can teach infants a second language.
[00:15:07.200 --> 00:15:10.400]   So oftentimes people get a caretaker
[00:15:10.400 --> 00:15:12.200]   that speaks a second language to a baby
[00:15:12.200 --> 00:15:14.380]   'cause babies are really good at picking up language.
[00:15:14.380 --> 00:15:17.240]   We have little cute robots, we have Google Translate,
[00:15:17.240 --> 00:15:20.600]   it feels like we have the right technology,
[00:15:20.600 --> 00:15:22.080]   we just have to kind of put it together
[00:15:22.080 --> 00:15:24.200]   and address this new domain.
[00:15:24.200 --> 00:15:27.260]   And probably what's easiest is like,
[00:15:27.260 --> 00:15:29.560]   you've seen clear analogs that work,
[00:15:29.560 --> 00:15:31.160]   but it's not yet mainstream.
[00:15:31.160 --> 00:15:32.560]   So there's still a barrier to entry,
[00:15:32.560 --> 00:15:34.760]   but at least you're certain that you'll succeed.
[00:15:34.760 --> 00:15:37.000]   And so this doesn't actually need researchers, they feel.
[00:15:37.000 --> 00:15:39.160]   I think it just needs good engineers
[00:15:39.160 --> 00:15:41.420]   and you can kind of put a time bound on it.
[00:15:41.420 --> 00:15:44.620]   So an example could be like,
[00:15:44.620 --> 00:15:47.000]   you've seen that you can recognize handwriting
[00:15:47.000 --> 00:15:49.880]   and math is like a special type of handwriting.
[00:15:49.880 --> 00:15:51.840]   It's more difficult because it's like two dimensional
[00:15:51.840 --> 00:15:54.440]   instead of, it's not just down a line,
[00:15:54.440 --> 00:15:56.560]   it's also like fractions and stuff like that.
[00:15:56.560 --> 00:15:58.680]   But it seems like it's basically the same problem,
[00:15:58.680 --> 00:16:00.800]   but it hasn't been done until just a couple of years ago.
[00:16:00.800 --> 00:16:02.120]   So that's a great problem.
[00:16:02.120 --> 00:16:05.900]   When you start working on something,
[00:16:05.900 --> 00:16:07.620]   a very good thing to consider is like,
[00:16:07.620 --> 00:16:09.840]   what data are you gonna use initially?
[00:16:09.840 --> 00:16:12.680]   And the reason for that is like,
[00:16:12.680 --> 00:16:16.340]   when you're working on defensible AI company or product,
[00:16:16.340 --> 00:16:19.220]   that usually means you're assembling a defensible data set.
[00:16:19.220 --> 00:16:21.560]   Some proprietary data that no one else can get,
[00:16:21.560 --> 00:16:25.200]   or at least we'll have trouble getting.
[00:16:25.200 --> 00:16:27.240]   And this is why we see TensorFlow and PyTorch
[00:16:27.240 --> 00:16:29.240]   and a bunch of research come out of Google and Facebook
[00:16:29.240 --> 00:16:31.640]   and Uber and stuff like that,
[00:16:31.640 --> 00:16:33.460]   because the data is the actual thing
[00:16:33.460 --> 00:16:37.000]   that they hold proprietary, the methods are not.
[00:16:37.000 --> 00:16:39.440]   So for you, you should look at,
[00:16:39.440 --> 00:16:41.920]   is the raw data that you need available?
[00:16:41.920 --> 00:16:43.800]   How expensive would it be to label the data
[00:16:43.800 --> 00:16:45.200]   once you have the raw?
[00:16:45.200 --> 00:16:47.620]   And then could someone else come along and get it?
[00:16:47.620 --> 00:16:50.220]   So the worst part to be in is,
[00:16:50.220 --> 00:16:53.520]   the data is super expensive to obtain or label or both,
[00:16:53.520 --> 00:16:54.700]   but when you're done,
[00:16:54.700 --> 00:16:57.440]   someone else can just come and do the same thing.
[00:16:57.440 --> 00:16:59.500]   So an example could be satellite data.
[00:16:59.500 --> 00:17:03.460]   Like anyone can just buy terabytes of satellite data,
[00:17:03.460 --> 00:17:05.680]   pay the millions of dollars to label it,
[00:17:05.680 --> 00:17:07.600]   and now you're playing the same game.
[00:17:07.600 --> 00:17:09.800]   What could be better is if you get
[00:17:09.800 --> 00:17:12.240]   something that is expensive to label
[00:17:12.240 --> 00:17:13.960]   and difficult to obtain,
[00:17:13.960 --> 00:17:16.320]   but once you do, there's some kind of exclusivity.
[00:17:16.320 --> 00:17:17.680]   So like DeepMind, I think,
[00:17:17.680 --> 00:17:20.560]   partnered with the National Health Services
[00:17:20.560 --> 00:17:24.480]   in the UK recently to do like DeepMind Health
[00:17:24.480 --> 00:17:25.560]   or something like that.
[00:17:25.560 --> 00:17:30.480]   And so the data they got is for like the entirety of the UK.
[00:17:30.480 --> 00:17:31.400]   No one else could get it
[00:17:31.400 --> 00:17:33.360]   'cause it's an exclusive partnership
[00:17:33.360 --> 00:17:35.000]   and it'll be an expensive project,
[00:17:35.000 --> 00:17:36.160]   but by the time they're done,
[00:17:36.160 --> 00:17:38.460]   at least no one else can kind of unseat them.
[00:17:38.460 --> 00:17:43.520]   And best yet, the data is exclusive to your company
[00:17:43.520 --> 00:17:45.120]   and you already have it labeled.
[00:17:46.000 --> 00:17:49.000]   So for example, the nation of Singapore
[00:17:49.000 --> 00:17:51.840]   has detailed educational records
[00:17:51.840 --> 00:17:54.400]   for every citizen from kindergarten
[00:17:54.400 --> 00:17:56.080]   up until they enter college.
[00:17:56.080 --> 00:17:58.280]   No one else has it, no one else can get it,
[00:17:58.280 --> 00:17:59.800]   and it's already kind of labeled,
[00:17:59.800 --> 00:18:02.560]   like all the grades, all the demographic information.
[00:18:02.560 --> 00:18:05.620]   So that would be a great data set to start working on.
[00:18:05.620 --> 00:18:09.400]   Once you build your initial application,
[00:18:09.400 --> 00:18:13.200]   you should consider how you're gonna handle
[00:18:13.200 --> 00:18:14.740]   new predictions, right?
[00:18:14.740 --> 00:18:16.640]   Are you gonna monitor the predictions you're making
[00:18:16.640 --> 00:18:18.280]   on data you've never seen before?
[00:18:18.280 --> 00:18:21.160]   Will you be able to correct predictions
[00:18:21.160 --> 00:18:22.800]   that you make wrongly?
[00:18:22.800 --> 00:18:25.320]   And will you be able to easily retrain your whole system
[00:18:25.320 --> 00:18:27.060]   with the corrections?
[00:18:27.060 --> 00:18:29.320]   And best of all,
[00:18:29.320 --> 00:18:31.720]   could you just have your users do that for you?
[00:18:31.720 --> 00:18:36.760]   So ZeroMarkz is for predictions not being monitored
[00:18:36.760 --> 00:18:38.260]   and not being corrected.
[00:18:38.260 --> 00:18:41.160]   And I'd say as an example, most AI products,
[00:18:41.160 --> 00:18:44.160]   this would be the situation.
[00:18:44.160 --> 00:18:45.680]   And you're really kind of flying blind, right?
[00:18:45.680 --> 00:18:47.940]   So you train your first model,
[00:18:47.940 --> 00:18:50.400]   and then you start serving up predictions
[00:18:50.400 --> 00:18:52.480]   in your production environment,
[00:18:52.480 --> 00:18:55.140]   but you don't actually ever look at what's happening.
[00:18:55.140 --> 00:18:59.320]   So maybe at some point, the data format
[00:18:59.320 --> 00:19:01.520]   that your users are sending changes a little bit,
[00:19:01.520 --> 00:19:03.460]   and your predictions are all wrong.
[00:19:03.460 --> 00:19:05.920]   Most companies wouldn't actually even notice that,
[00:19:05.920 --> 00:19:09.360]   and certainly wouldn't retrain kind of on a regular basis.
[00:19:09.360 --> 00:19:13.560]   What would be better is if you monitored your predictions,
[00:19:13.560 --> 00:19:15.440]   and then potentially the low confidence ones,
[00:19:15.440 --> 00:19:18.040]   so the ones your models wasn't certain about,
[00:19:18.040 --> 00:19:22.260]   went through a manual QA process with a team of annotators.
[00:19:22.260 --> 00:19:26.320]   And if you do that, then, oops.
[00:19:26.320 --> 00:19:28.840]   If you do that, then you can get this kind of data flywheel
[00:19:28.840 --> 00:19:30.080]   starting to spin.
[00:19:30.080 --> 00:19:34.020]   And the idea is that when you first build your model,
[00:19:34.020 --> 00:19:36.560]   let's say you trained on like a million examples, right?
[00:19:36.560 --> 00:19:38.320]   And then that's enough to get something
[00:19:38.320 --> 00:19:41.040]   that's 80% accurate, so you ship it.
[00:19:41.040 --> 00:19:42.640]   And now your users are using it,
[00:19:42.640 --> 00:19:45.680]   and they're sending you a million of examples a month.
[00:19:45.680 --> 00:19:47.980]   So you could be doubling the size of your dataset
[00:19:47.980 --> 00:19:49.360]   every month or so, right?
[00:19:49.360 --> 00:19:53.840]   And so the more users you have, the more data you have.
[00:19:53.840 --> 00:19:55.720]   So now when you have two million examples,
[00:19:55.720 --> 00:19:57.840]   maybe you're at 85% accuracy.
[00:19:57.840 --> 00:19:59.680]   Now all of a sudden, your product is even better
[00:19:59.680 --> 00:20:02.400]   than it used to be, and so more users come on board,
[00:20:02.400 --> 00:20:03.520]   and they give you more data,
[00:20:03.520 --> 00:20:06.080]   and so you kind of keep doubling that.
[00:20:06.080 --> 00:20:08.020]   And that's the idea of the data flywheel.
[00:20:08.020 --> 00:20:12.260]   Now, sending predictions through a manual QA process
[00:20:12.260 --> 00:20:14.500]   is great, it's better than not doing that,
[00:20:14.500 --> 00:20:15.700]   but it's very expensive.
[00:20:15.700 --> 00:20:19.520]   And the kind of highest marks here
[00:20:19.520 --> 00:20:21.620]   are for monitoring your predictions
[00:20:21.620 --> 00:20:23.540]   for like data skew and stuff like that,
[00:20:23.540 --> 00:20:26.420]   but then also letting your users actually let you know
[00:20:26.420 --> 00:20:28.660]   how to improve the predictions you're making.
[00:20:28.660 --> 00:20:31.580]   So an example I like to give here is Google Photos,
[00:20:31.580 --> 00:20:35.440]   where Google trained something on a fixed dataset,
[00:20:35.440 --> 00:20:36.500]   but then they released it,
[00:20:36.500 --> 00:20:39.020]   and then they keep asking their users,
[00:20:39.020 --> 00:20:41.300]   are these two faces the same when they're not certain?
[00:20:41.300 --> 00:20:43.940]   And I always, I don't know about you guys,
[00:20:43.940 --> 00:20:45.760]   but I always answer these questions,
[00:20:45.760 --> 00:20:49.380]   because I actually don't want people's faces in,
[00:20:49.380 --> 00:20:50.560]   I don't want a stranger's face
[00:20:50.560 --> 00:20:53.800]   when I'm looking at my friend's kind of photo album.
[00:20:53.800 --> 00:20:55.500]   And also I do want my friend's face
[00:20:55.500 --> 00:20:58.560]   in my friend's photo album, so I'll answer yes and no,
[00:20:58.560 --> 00:21:00.840]   and that's very useful data for Google.
[00:21:00.840 --> 00:21:04.220]   Here's another thing that Google Photos does.
[00:21:04.220 --> 00:21:07.060]   I guess like the thing to convey here
[00:21:07.060 --> 00:21:09.040]   is this takes design thinking, right?
[00:21:09.040 --> 00:21:11.860]   So if you've already built your whole product,
[00:21:11.860 --> 00:21:13.540]   and then you trained your AI,
[00:21:13.540 --> 00:21:15.580]   and now you wanna like get the flywheel going,
[00:21:15.580 --> 00:21:17.500]   it's probably too late at that point.
[00:21:17.500 --> 00:21:19.460]   You should have thought about how to build the product
[00:21:19.460 --> 00:21:22.140]   in such a way that you build in the hooks
[00:21:22.140 --> 00:21:24.060]   for the user to give you good data.
[00:21:24.060 --> 00:21:26.660]   And Google Photos, I think, is a great example of it,
[00:21:26.660 --> 00:21:29.020]   both with this user interface,
[00:21:29.020 --> 00:21:32.740]   but also with this other thing, which is search by content.
[00:21:32.740 --> 00:21:35.780]   So if I search my photo collection for dogs,
[00:21:35.780 --> 00:21:39.340]   I do get a bunch of images of dogs, and that's great.
[00:21:39.340 --> 00:21:42.460]   If I search my photo collection for cats, I get some cats,
[00:21:42.460 --> 00:21:44.740]   but then I also get some dogs, right?
[00:21:44.740 --> 00:21:46.020]   These things are dogs.
[00:21:46.020 --> 00:21:47.980]   So Google Photos made a mistake here.
[00:21:47.980 --> 00:21:51.900]   And maybe I find that annoying, I'm a little OCD,
[00:21:51.900 --> 00:21:55.340]   so I'll actually find the user interface hook
[00:21:55.340 --> 00:21:59.940]   that they have, which is you click on the sandwich menu,
[00:21:59.940 --> 00:22:02.060]   and it shows a little thing that says
[00:22:02.060 --> 00:22:04.620]   you can edit date and time, you can download the photos,
[00:22:04.620 --> 00:22:06.300]   or you can remove the results.
[00:22:06.300 --> 00:22:08.060]   So when I click remove the results,
[00:22:08.060 --> 00:22:10.940]   I'm letting Google know that these things are not cats.
[00:22:10.940 --> 00:22:11.980]   They don't know they're dogs,
[00:22:11.980 --> 00:22:13.780]   but at least they know they're not cats.
[00:22:13.780 --> 00:22:16.420]   And they can infer that all the other photos
[00:22:16.420 --> 00:22:19.180]   I didn't click on actually are cats.
[00:22:19.180 --> 00:22:21.460]   And so very rapidly, they can improve the size
[00:22:21.460 --> 00:22:23.600]   of their content data set also.
[00:22:23.600 --> 00:22:26.380]   So I have a little transition here,
[00:22:26.380 --> 00:22:28.620]   which is you got the cats and the not cats.
[00:22:29.580 --> 00:22:33.180]   Now that's gonna feed into the machine learning model.
[00:22:33.180 --> 00:22:37.140]   But the machine learning model is just kind of a part
[00:22:37.140 --> 00:22:39.380]   of the overall code base that we're developing.
[00:22:39.380 --> 00:22:41.220]   And there's a lot of stuff around it.
[00:22:41.220 --> 00:22:44.060]   This is the figure from the paper,
[00:22:44.060 --> 00:22:48.020]   hidden technical debt, or machine learning,
[00:22:48.020 --> 00:22:51.060]   the high interest credit card of technical debt.
[00:22:51.060 --> 00:22:53.940]   So the machine learning code, the cool neural network
[00:22:53.940 --> 00:22:56.460]   is just part of the code base,
[00:22:56.460 --> 00:22:58.420]   but then you got all the stuff around it, right?
[00:22:58.420 --> 00:23:02.220]   And it actually requires many roles to do these tasks.
[00:23:02.220 --> 00:23:04.780]   So in a big org, when you're actually splitting up the roles
[00:23:04.780 --> 00:23:07.300]   instead of just hiring one person or doing it all yourself,
[00:23:07.300 --> 00:23:08.780]   you got data engineers,
[00:23:08.780 --> 00:23:11.460]   you got machine learning researchers thinking
[00:23:11.460 --> 00:23:14.580]   about what features, what architecture to do.
[00:23:14.580 --> 00:23:16.060]   You got machine learning engineers thinking
[00:23:16.060 --> 00:23:17.620]   about how to productize it,
[00:23:17.620 --> 00:23:20.780]   how to distribute training onto multiple GPUs
[00:23:20.780 --> 00:23:22.500]   or distribute feature extraction
[00:23:22.500 --> 00:23:24.900]   onto multiple machines in a cluster,
[00:23:24.900 --> 00:23:27.820]   how to monitor your running model,
[00:23:27.820 --> 00:23:30.500]   how to analyze, maybe reduce the size of the model
[00:23:30.500 --> 00:23:31.660]   once you trained it.
[00:23:31.660 --> 00:23:35.380]   And you got DevOps people providing the GPUs for you
[00:23:35.380 --> 00:23:37.860]   and then being responsible for the model serving
[00:23:37.860 --> 00:23:40.460]   up predictions at a reasonable speed.
[00:23:40.460 --> 00:23:44.780]   And so all of that is infrastructure and tooling.
[00:23:44.780 --> 00:23:47.340]   So how am I doing on time?
[00:23:47.340 --> 00:23:51.100]   So what, like, when should I end?
[00:23:51.100 --> 00:23:52.140]   I kind of don't know.
[00:23:52.140 --> 00:23:56.940]   (man speaking indistinctly)
[00:23:56.940 --> 00:24:00.780]   Okay, so here, I assume you guys kind of watched
[00:24:00.780 --> 00:24:03.780]   the lecture at home, the infrastructure and tooling lecture.
[00:24:03.780 --> 00:24:09.900]   I think there's really not too much I wanna cover.
[00:24:09.900 --> 00:24:12.940]   I think maybe just as a review,
[00:24:12.940 --> 00:24:15.740]   I'll kind of rebuild this slide.
[00:24:15.740 --> 00:24:18.660]   And then I will highlight a few slides
[00:24:18.660 --> 00:24:19.740]   that are recently changed
[00:24:19.740 --> 00:24:22.180]   because some companies went out of business
[00:24:22.180 --> 00:24:24.140]   and some new tools kind of became mature enough
[00:24:24.140 --> 00:24:25.420]   to include here.
[00:24:25.420 --> 00:24:27.020]   And then I'll just take questions.
[00:24:27.020 --> 00:24:29.700]   So I think this will just take five minutes.
[00:24:29.700 --> 00:24:32.020]   But I break down infrastructure and tooling
[00:24:32.020 --> 00:24:33.460]   into kind of three sections.
[00:24:33.460 --> 00:24:38.060]   So you got data, development, training,
[00:24:38.060 --> 00:24:39.660]   evaluation, and deployment.
[00:24:39.660 --> 00:24:42.460]   So data, there's a whole lecture about that,
[00:24:42.460 --> 00:24:44.300]   but this is kind of also the infrastructure
[00:24:44.300 --> 00:24:45.900]   and the tooling that you need.
[00:24:45.900 --> 00:24:47.100]   This is kind of the contents
[00:24:47.100 --> 00:24:49.220]   of the infrastructure and tooling lecture,
[00:24:49.220 --> 00:24:51.780]   software engineering, machine learning frameworks,
[00:24:51.780 --> 00:24:53.740]   how do you manage resources,
[00:24:53.740 --> 00:24:55.940]   how do you do experiment management,
[00:24:55.940 --> 00:24:57.460]   how do you do distributed training,
[00:24:57.460 --> 00:25:01.020]   how do you maybe do like kind of smarter model training,
[00:25:01.020 --> 00:25:03.220]   hyper parameter optimization.
[00:25:03.220 --> 00:25:04.260]   On the deployment side,
[00:25:04.260 --> 00:25:06.100]   how do you do a continuous integration,
[00:25:06.100 --> 00:25:07.700]   continuous delivery,
[00:25:07.700 --> 00:25:09.580]   how do you specifically deploy to the web,
[00:25:09.580 --> 00:25:11.780]   monitor your predictions,
[00:25:11.780 --> 00:25:15.660]   maybe get them working on embedded systems or on mobile.
[00:25:15.660 --> 00:25:20.260]   And then all in one is this trend of like Google,
[00:25:20.260 --> 00:25:24.420]   Facebook, Uber, Amazon, and then a bunch of startups
[00:25:24.420 --> 00:25:28.660]   noticing that all these things are kind of have to be done
[00:25:28.660 --> 00:25:31.060]   together in a certain sequence.
[00:25:31.060 --> 00:25:33.500]   And everyone's kind of figuring out the parts
[00:25:33.500 --> 00:25:36.100]   of that sequence for themselves.
[00:25:36.100 --> 00:25:38.780]   So could we just get like a best of breed
[00:25:38.780 --> 00:25:40.020]   all in one solution?
[00:25:40.020 --> 00:25:43.420]   So this is the infrastructure
[00:25:43.420 --> 00:25:45.180]   and tooling lecture content here.
[00:25:45.180 --> 00:25:49.620]   The things I wanna highlight that recently changed
[00:25:50.380 --> 00:25:51.220]   are,
[00:25:51.220 --> 00:25:55.820]   maybe I'll just kind of quickly go through it
[00:25:55.820 --> 00:25:56.660]   if that's cool.
[00:25:56.660 --> 00:25:58.940]   Like I'm not gonna read the slides,
[00:25:58.940 --> 00:26:00.860]   but I'll just click through the slides.
[00:26:00.860 --> 00:26:03.500]   Software engineering, frameworks.
[00:26:03.500 --> 00:26:07.020]   Yeah, so the idea here is frameworks
[00:26:07.020 --> 00:26:11.140]   are converging on something that's both defined by run.
[00:26:11.140 --> 00:26:12.700]   So you can just write code and then run it
[00:26:12.700 --> 00:26:14.820]   and then it figures out the graph automatically
[00:26:14.820 --> 00:26:17.740]   and able to have a nice optimized graph.
[00:26:17.740 --> 00:26:20.300]   So both TensorFlow 2.0 and PyTorch 1.0
[00:26:20.300 --> 00:26:21.820]   are like both of those.
[00:26:21.820 --> 00:26:24.100]   So people have a good time with PyTorch,
[00:26:24.100 --> 00:26:25.700]   but TensorFlow is just as good.
[00:26:25.700 --> 00:26:27.700]   TensorFlow is likelier to get you a job.
[00:26:27.700 --> 00:26:33.060]   I make a distinction between like just developing
[00:26:33.060 --> 00:26:35.620]   on your own machine or just on a desktop machine
[00:26:35.620 --> 00:26:37.860]   with a couple of GPUs where you can actually
[00:26:37.860 --> 00:26:41.660]   open up images easily, just use your code editor
[00:26:41.660 --> 00:26:43.220]   that you're most familiar with,
[00:26:43.220 --> 00:26:45.380]   maybe use like a GUI for other tasks.
[00:26:45.380 --> 00:26:48.300]   And then also being able to train at scale.
[00:26:48.300 --> 00:26:49.660]   So that's kind of like the development,
[00:26:49.660 --> 00:26:51.500]   training, and evaluation phases.
[00:26:51.500 --> 00:26:56.420]   And the infrastructure needs might be different for those.
[00:26:56.420 --> 00:26:58.860]   So to get those, we cover GPU basics.
[00:26:58.860 --> 00:27:03.420]   Just gonna click through this.
[00:27:03.420 --> 00:27:09.460]   Yeah, basically 2080 TIs are like the sweet spot right now.
[00:27:09.460 --> 00:27:11.100]   This is what I recommend getting.
[00:27:12.220 --> 00:27:15.460]   (man speaking faintly)
[00:27:15.460 --> 00:27:21.780]   Yeah, so a couple of machines are 1080 TIs
[00:27:21.780 --> 00:27:24.940]   and a couple of machines are 2080 TIs
[00:27:24.940 --> 00:27:28.580]   and then a Titan RTX for like big NLP models
[00:27:28.580 --> 00:27:32.620]   that don't fit into the 11 gigs of memory
[00:27:32.620 --> 00:27:34.420]   that the 2080 TI gives you.
[00:27:34.420 --> 00:27:41.660]   And then another team uses cloud GPUs,
[00:27:41.660 --> 00:27:44.620]   but I still prefer on-prem GPUs
[00:27:44.620 --> 00:27:47.300]   because it's just so much more cost effective.
[00:27:47.300 --> 00:27:51.100]   And especially for these like 24 gig GPUs,
[00:27:51.100 --> 00:27:53.260]   it's just crazy expensive in the cloud.
[00:27:53.260 --> 00:27:54.900]   (man speaking faintly)
[00:27:54.900 --> 00:27:55.940]   No.
[00:27:55.940 --> 00:28:00.940]   So yeah, the choices you have are for on-prem options,
[00:28:00.940 --> 00:28:05.260]   you can build it yourself, which I think everyone should do
[00:28:05.260 --> 00:28:07.300]   if you haven't done it ever in your life,
[00:28:07.300 --> 00:28:10.140]   because it's just a cool experience
[00:28:10.140 --> 00:28:13.180]   and you get hacker cred for doing it.
[00:28:13.180 --> 00:28:15.460]   And it's actually not that hard.
[00:28:15.460 --> 00:28:16.900]   And you get to save a couple of grand
[00:28:16.900 --> 00:28:19.820]   if it's like your own money, it's actually meaningful.
[00:28:19.820 --> 00:28:23.100]   And up to four GPUs is nice and easy.
[00:28:23.100 --> 00:28:27.820]   Going beyond four GPUs, you need like server rack mounts
[00:28:27.820 --> 00:28:29.780]   and stuff and you don't wanna do that.
[00:28:29.780 --> 00:28:32.340]   Or you can buy prebuilt and the two choices there are
[00:28:32.340 --> 00:28:36.460]   NVIDIA if you wanna satisfy their end user license agreement
[00:28:36.460 --> 00:28:39.580]   or Lambda Labs if you don't care about the NVIDIA
[00:28:39.580 --> 00:28:40.980]   end user license agreement.
[00:28:40.980 --> 00:28:44.260]   And it's actually not a 75% premium,
[00:28:44.260 --> 00:28:47.220]   it's only a 25% premium, I should have changed this,
[00:28:47.220 --> 00:28:49.420]   over building the same machine yourself.
[00:28:49.420 --> 00:28:51.780]   So we've done that now also.
[00:28:51.780 --> 00:28:53.900]   And this is a good solution that I would recommend,
[00:28:53.900 --> 00:28:55.780]   Lambda Labs, and they might be willing
[00:28:55.780 --> 00:28:58.500]   to give you guys a discount 'cause we know the founder,
[00:28:58.500 --> 00:28:59.340]   right?
[00:28:59.340 --> 00:29:00.460]   I don't know.
[00:29:00.460 --> 00:29:01.500]   We'll have to ask him.
[00:29:01.500 --> 00:29:04.020]   (man speaking faintly)
[00:29:04.020 --> 00:29:04.980]   Oh, really?
[00:29:04.980 --> 00:29:05.820]   Dang it.
[00:29:05.820 --> 00:29:08.660]   So anyway, if you analyze the costs,
[00:29:08.660 --> 00:29:10.700]   it's like much better to build your own machine
[00:29:10.700 --> 00:29:12.020]   than to be in the cloud.
[00:29:12.020 --> 00:29:18.860]   So they use the 2080 TIs and the Titan RTXs also.
[00:29:18.860 --> 00:29:22.780]   So you got 2080 TI and you got the Titan RTX.
[00:29:22.780 --> 00:29:25.940]   These are NVIDIA GPUs, yeah.
[00:29:25.940 --> 00:29:29.740]   And then I think they still have the 1080 TI machines,
[00:29:29.740 --> 00:29:30.580]   but I'm not sure.
[00:29:30.580 --> 00:29:37.300]   If you wanna build a machine with 2080 TIs yourself,
[00:29:37.300 --> 00:29:39.460]   it would be like $7,000.
[00:29:39.460 --> 00:29:42.620]   If you buy it from Lambda Labs, it would be like $9,000.
[00:29:42.620 --> 00:29:47.060]   Kind of depends on exactly what GPU you want.
[00:29:47.060 --> 00:29:50.340]   (man speaking faintly)
[00:29:50.340 --> 00:29:52.500]   I think that's for two, that's right, yeah.
[00:29:52.500 --> 00:29:55.820]   So anyway, if you like run the math on,
[00:29:55.820 --> 00:29:58.820]   if I built this machine and then ran it for like four months
[00:29:58.820 --> 00:30:03.580]   that would pay for itself in terms of paying
[00:30:03.580 --> 00:30:05.740]   for an equivalent amount of compute in the cloud.
[00:30:05.740 --> 00:30:07.700]   So if you expect to do more than like four months
[00:30:07.700 --> 00:30:10.420]   roughly of compute, you should build it yourself.
[00:30:10.420 --> 00:30:12.740]   If you expect to do less,
[00:30:12.740 --> 00:30:16.900]   then I don't think you should expect to do any less,
[00:30:16.900 --> 00:30:18.700]   but then maybe the cloud could make sense.
[00:30:18.700 --> 00:30:21.680]   Or if you just wanna run 100 experiments all at once,
[00:30:21.680 --> 00:30:24.500]   then you pretty much have to do it in the cloud.
[00:30:24.500 --> 00:30:27.940]   Or if you have, if you're doing reinforcement learning,
[00:30:27.940 --> 00:30:31.400]   like OpenAI does a lot of massive experiments,
[00:30:31.400 --> 00:30:33.540]   at least they used to.
[00:30:33.540 --> 00:30:36.420]   And a lot of them were CPU bound, non-GPU bound.
[00:30:36.420 --> 00:30:39.400]   So that, then being in the cloud makes more sense.
[00:30:39.400 --> 00:30:43.260]   So let's see.
[00:30:43.260 --> 00:30:47.540]   Yeah, resource management is the idea that like, all right,
[00:30:47.540 --> 00:30:49.660]   if you have a few machines with GPUs,
[00:30:49.660 --> 00:30:50.740]   or maybe you have your machine,
[00:30:50.740 --> 00:30:52.940]   then you also have like a cloud environment.
[00:30:52.940 --> 00:30:55.780]   Or you have five developers
[00:30:55.780 --> 00:30:57.140]   and they each have a desktop machine,
[00:30:57.140 --> 00:31:00.080]   but they're not each running an experiment at the same time.
[00:31:00.080 --> 00:31:01.820]   They kind of stagger experiments.
[00:31:01.820 --> 00:31:03.460]   How do you actually get the resources
[00:31:03.460 --> 00:31:06.360]   from the multiple GPUs accessible
[00:31:06.360 --> 00:31:09.260]   through a single kind of job push?
[00:31:09.260 --> 00:31:12.300]   And so the oldest idea is spreadsheets.
[00:31:12.300 --> 00:31:13.700]   Don't recommend that.
[00:31:13.700 --> 00:31:16.180]   Scripts could actually be pretty good.
[00:31:16.180 --> 00:31:19.480]   And just like simple script just asks the GPU if it's busy.
[00:31:19.480 --> 00:31:21.220]   And if it's not, then it puts a job on it.
[00:31:21.220 --> 00:31:22.580]   And if it is, then it waits.
[00:31:22.580 --> 00:31:27.860]   Slurm is the kind of industrialization of that.
[00:31:27.860 --> 00:31:30.940]   So it's really just a script that you say,
[00:31:30.940 --> 00:31:32.260]   okay, I'm trying to run a job.
[00:31:32.260 --> 00:31:35.300]   It needs eight CPU cores and two GPUs.
[00:31:35.300 --> 00:31:40.300]   And I have a cluster of 16 GPUs and 86 CPUs.
[00:31:40.300 --> 00:31:42.740]   So like figure it out.
[00:31:42.740 --> 00:31:44.580]   And it gives you the right resources.
[00:31:44.580 --> 00:31:48.080]   Docker and Kubernetes is what these guys do.
[00:31:48.080 --> 00:31:53.080]   And the idea is that if you can package up your job
[00:31:53.080 --> 00:31:55.300]   as a Docker container,
[00:31:55.300 --> 00:31:57.900]   then you might have some jobs that only need CPUs,
[00:31:57.900 --> 00:31:59.720]   like you're extracting features.
[00:31:59.720 --> 00:32:02.260]   You might have some jobs that take those extracted features
[00:32:02.260 --> 00:32:04.220]   and run GPU training on them.
[00:32:04.220 --> 00:32:06.860]   So you have different kind of Docker images
[00:32:06.860 --> 00:32:10.700]   and you have a disparate compute cluster.
[00:32:10.700 --> 00:32:15.540]   So how do you schedule the different types of images
[00:32:15.540 --> 00:32:18.220]   onto the underlying hardware?
[00:32:18.220 --> 00:32:21.660]   Kubernetes is the answer to that.
[00:32:21.660 --> 00:32:24.540]   It's able to take different Docker images
[00:32:24.540 --> 00:32:25.780]   and the underlying hardware
[00:32:25.780 --> 00:32:28.540]   and just kind of distribute things correctly.
[00:32:28.540 --> 00:32:30.080]   And the idea is great,
[00:32:30.080 --> 00:32:33.040]   but it has been pretty hard to actually get it working
[00:32:33.040 --> 00:32:34.960]   and just a lot of boilerplate code.
[00:32:34.960 --> 00:32:36.720]   And if something breaks, like all of a sudden,
[00:32:36.720 --> 00:32:40.220]   you're deep into the documentation, trying to fix it.
[00:32:40.220 --> 00:32:44.840]   Rizoml used to be a startup that promised to make it easy.
[00:32:44.840 --> 00:32:47.560]   And so it was basically something on top of Kubernetes
[00:32:47.560 --> 00:32:49.200]   that was specifically for machine learning.
[00:32:49.200 --> 00:32:51.400]   So you could just write a YAML file that said like,
[00:32:51.400 --> 00:32:52.560]   I'm trying to run these experiments.
[00:32:52.560 --> 00:32:55.400]   They need these resources.
[00:32:55.400 --> 00:32:57.920]   And then just hit, you know, Rizoml train
[00:32:57.920 --> 00:33:00.020]   and then have it figured out using Kubernetes.
[00:33:00.020 --> 00:33:03.580]   Unfortunately, they shut down just a couple of months ago.
[00:33:03.580 --> 00:33:06.980]   So I think what I would advise to replace that with now
[00:33:06.980 --> 00:33:10.220]   is Kubeflow, which is something that's a project from Google
[00:33:10.220 --> 00:33:14.260]   that was, you know, started.
[00:33:14.260 --> 00:33:16.500]   So Kubernetes is also from Google, by the way,
[00:33:16.500 --> 00:33:20.060]   but Kubeflow is this idea of Kubernetes and TensorFlow
[00:33:20.060 --> 00:33:24.500]   in a nice kind of easy to use package.
[00:33:24.500 --> 00:33:27.600]   And it's supposedly based on Google's
[00:33:27.600 --> 00:33:29.640]   internal machine learning pipelines.
[00:33:29.640 --> 00:33:31.720]   But what it basically is, is it makes it easy
[00:33:31.720 --> 00:33:34.080]   for you to have a notebook that runs in Kubernetes.
[00:33:34.080 --> 00:33:37.120]   It supports TensorFlow, PyTorch, Chainer,
[00:33:37.120 --> 00:33:38.660]   and some other stuff.
[00:33:38.660 --> 00:33:41.340]   And then it also supports TensorRT
[00:33:41.340 --> 00:33:43.660]   and this thing called Selden for optimized production,
[00:33:43.660 --> 00:33:45.000]   which would be in the deployment lecture.
[00:33:45.000 --> 00:33:47.100]   So I'm not gonna talk too much about it.
[00:33:47.100 --> 00:33:49.200]   But yeah, Kubeflow seems to be the way to do
[00:33:49.200 --> 00:33:52.000]   like machine learning on Kubernetes right now.
[00:33:52.000 --> 00:33:54.120]   But it also seems to be mostly about production
[00:33:54.120 --> 00:33:55.420]   and not actually training.
[00:33:55.420 --> 00:33:59.600]   So for distributed training,
[00:33:59.600 --> 00:34:02.280]   the idea is that you can use multiple GPUs,
[00:34:02.280 --> 00:34:04.480]   not only to just run multiple experiments in parallel,
[00:34:04.480 --> 00:34:09.480]   but to actually train a single model on multiple GPUs.
[00:34:09.480 --> 00:34:13.040]   Frameworks are getting better at doing it.
[00:34:13.040 --> 00:34:14.960]   The two things that you might hear
[00:34:14.960 --> 00:34:17.760]   is like data parallelism versus model parallelism.
[00:34:17.760 --> 00:34:22.480]   So data parallelism is essentially
[00:34:23.440 --> 00:34:25.680]   just partitioning your training data.
[00:34:25.680 --> 00:34:29.960]   And so it's the same model parameters on every GPU,
[00:34:29.960 --> 00:34:31.800]   but a different slice of the data
[00:34:31.800 --> 00:34:33.520]   going through the different GPUs.
[00:34:33.520 --> 00:34:35.720]   And then when you're doing back propagation,
[00:34:35.720 --> 00:34:40.120]   at every layer, the different GPUs
[00:34:40.120 --> 00:34:42.640]   essentially just exchange parameters and average them out
[00:34:42.640 --> 00:34:45.040]   and then continue down with their data.
[00:34:45.040 --> 00:34:50.600]   Model parallelism is way more complicated
[00:34:50.600 --> 00:34:52.700]   and it's actually distributing the parameters
[00:34:52.700 --> 00:34:54.240]   onto different GPUs.
[00:34:54.240 --> 00:34:56.420]   So if you have like an 80 layer network,
[00:34:56.420 --> 00:34:58.440]   the first 40 layers might be on GPU one,
[00:34:58.440 --> 00:35:01.160]   the second 40 layers might be on GPU two.
[00:35:01.160 --> 00:35:03.600]   That's super complicated to code up
[00:35:03.600 --> 00:35:06.720]   and the speed up tends to be not as good as data parallelism.
[00:35:06.720 --> 00:35:08.080]   So don't even worry about that.
[00:35:08.080 --> 00:35:10.080]   But data parallelism seems to be pretty good.
[00:35:10.080 --> 00:35:14.300]   And you get like pretty close to linear speed ups
[00:35:14.300 --> 00:35:17.100]   using modern frameworks like PyTorch and TensorFlow now.
[00:35:18.240 --> 00:35:20.400]   So TensorFlow distributed,
[00:35:20.400 --> 00:35:26.020]   Horovod is like Uber's answer to TensorFlow distributed,
[00:35:26.020 --> 00:35:29.220]   which is, I guess also supports PyTorch now,
[00:35:29.220 --> 00:35:30.740]   but basically it uses MPI,
[00:35:30.740 --> 00:35:33.420]   which is like this thing from the 80s
[00:35:33.420 --> 00:35:36.380]   that is just a really good way to pass messages
[00:35:36.380 --> 00:35:39.620]   between different computer resources
[00:35:39.620 --> 00:35:42.140]   instead of like coding that stuff into TensorFlow,
[00:35:42.140 --> 00:35:43.940]   which is what TensorFlow distributed is.
[00:35:43.940 --> 00:35:45.420]   So I would recommend that.
[00:35:45.420 --> 00:35:46.540]   For experiment management,
[00:35:46.540 --> 00:35:48.440]   Lucas is gonna talk about it right after me.
[00:35:48.440 --> 00:35:49.980]   So I'm not even gonna touch it.
[00:35:49.980 --> 00:35:53.940]   - Can you go back to why TensorFlow distributed
[00:35:53.940 --> 00:35:55.780]   is such a complicated?
[00:35:55.780 --> 00:35:59.860]   - Yeah, so TensorFlow distributed is,
[00:35:59.860 --> 00:36:03.040]   so yeah, TensorFlow is this huge collection of things.
[00:36:03.040 --> 00:36:05.460]   It was huge at the start and it keeps growing
[00:36:05.460 --> 00:36:07.860]   and they're like trying to compress some things
[00:36:07.860 --> 00:36:09.320]   and make it more sane,
[00:36:09.320 --> 00:36:11.300]   but it's still a lot of different things
[00:36:11.300 --> 00:36:13.620]   that all have the name TensorFlow in it.
[00:36:13.620 --> 00:36:17.300]   TensorFlow distributed is the way to do distributed training
[00:36:17.300 --> 00:36:20.540]   for both data and model parallelism in TensorFlow.
[00:36:20.540 --> 00:36:25.140]   And the way they achieve that is with like TensorFlow code.
[00:36:25.140 --> 00:36:27.340]   So let's say you wanna share parameters.
[00:36:27.340 --> 00:36:30.100]   If you're doing data parallel computation,
[00:36:30.100 --> 00:36:31.780]   the different GPUs have to share parameters
[00:36:31.780 --> 00:36:34.980]   between at every step in the back prop.
[00:36:34.980 --> 00:36:39.260]   So TensorFlow distributed is like code
[00:36:39.260 --> 00:36:42.000]   that TensorFlow has for doing that sharing
[00:36:42.000 --> 00:36:46.980]   versus Horovod is kind of one,
[00:36:46.980 --> 00:36:49.820]   it's like on top of TensorFlow or PyTorch
[00:36:49.820 --> 00:36:53.760]   and it uses MPI, which is a standard way
[00:36:53.760 --> 00:36:57.620]   to get information between GPUs or between CPUs
[00:36:57.620 --> 00:36:59.140]   or between computers.
[00:36:59.140 --> 00:37:02.140]   And so basically it's like way more simple
[00:37:02.140 --> 00:37:04.500]   to implement than TensorFlow distributed.
[00:37:04.500 --> 00:37:06.340]   - Do you have a leader in TensorFlow
[00:37:06.340 --> 00:37:08.500]   that you can compile that?
[00:37:10.540 --> 00:37:12.440]   - From my experience,
[00:37:12.440 --> 00:37:14.380]   TensorFlow distributed was not like a drop
[00:37:14.380 --> 00:37:15.520]   and change to make.
[00:37:15.520 --> 00:37:18.080]   It's usually requires re-architecting some,
[00:37:18.080 --> 00:37:20.280]   you know, your TensorFlow code.
[00:37:20.280 --> 00:37:22.640]   I haven't personally experienced Horovod,
[00:37:22.640 --> 00:37:25.240]   but I heard it's a lot easier to implement.
[00:37:25.240 --> 00:37:29.040]   And so, and then these things are always getting better,
[00:37:29.040 --> 00:37:30.760]   I think with every release as well.
[00:37:30.760 --> 00:37:32.440]   So it might be, TensorFlow distributed
[00:37:32.440 --> 00:37:34.280]   might be more of a drop and change at this point
[00:37:34.280 --> 00:37:35.320]   than when I tried it.
[00:37:35.320 --> 00:37:39.600]   So yeah, experiment management.
[00:37:40.580 --> 00:37:43.260]   So hyperparameter optimization.
[00:37:43.260 --> 00:37:46.920]   When I had the slides, I suggested Talos and Hyperus
[00:37:46.920 --> 00:37:49.200]   and there's a new one called Keras Tuner,
[00:37:49.200 --> 00:37:51.920]   which you have to sign up for early access,
[00:37:51.920 --> 00:37:53.640]   but this one's actually from Google
[00:37:53.640 --> 00:37:55.920]   and I don't know, it looks really good.
[00:37:55.920 --> 00:37:59.000]   So I would recommend this one, Keras Tuner.
[00:37:59.000 --> 00:38:01.240]   So basically the idea here is like,
[00:38:01.240 --> 00:38:03.560]   if you wanna, so here the learning rate
[00:38:03.560 --> 00:38:08.560]   is just gonna be either 0.001 or 0.005 or 0.001.
[00:38:09.560 --> 00:38:12.920]   And that'll be part of like a grid of parameters
[00:38:12.920 --> 00:38:15.200]   and Keras Tuner will sample randomly from it
[00:38:15.200 --> 00:38:17.440]   to get like the best things.
[00:38:17.440 --> 00:38:21.680]   And weights and biases as solution.
[00:38:21.680 --> 00:38:25.400]   And then for all in one, there's, you know,
[00:38:25.400 --> 00:38:27.480]   that's kind of the idea is that there's a single system
[00:38:27.480 --> 00:38:29.780]   for everything started from a hosted notebook
[00:38:29.780 --> 00:38:32.460]   to extracting features, to training the model,
[00:38:32.460 --> 00:38:35.620]   to potentially even deploying the trained model.
[00:38:35.620 --> 00:38:38.720]   Facebook Learner is like the internal solution.
[00:38:38.720 --> 00:38:40.780]   Michelangelo's internal solution at Uber.
[00:38:40.780 --> 00:38:44.000]   So Google is very confusing.
[00:38:44.000 --> 00:38:46.880]   They have the Cloud ML Engine, which is kind of like that,
[00:38:46.880 --> 00:38:48.760]   except not for all steps.
[00:38:48.760 --> 00:38:49.720]   Then they also have something
[00:38:49.720 --> 00:38:53.160]   that they call TensorFlow Extended.
[00:38:53.160 --> 00:38:55.620]   And so at first it was just a paper.
[00:38:55.620 --> 00:38:57.940]   It was like a paper from 2017.
[00:38:57.940 --> 00:39:00.920]   And they said, you know, we at Google found
[00:39:00.920 --> 00:39:04.320]   the best procedure for training machine learning models.
[00:39:04.320 --> 00:39:06.780]   It involves, you know, these steps, data ingestion,
[00:39:06.780 --> 00:39:10.080]   analysis, transformation, validation, then training,
[00:39:10.080 --> 00:39:12.800]   then model validation, then serving.
[00:39:12.800 --> 00:39:14.260]   But they didn't publish any code,
[00:39:14.260 --> 00:39:16.600]   even though they called it TensorFlow Extended.
[00:39:16.600 --> 00:39:18.720]   But recently they started publishing codes.
[00:39:18.720 --> 00:39:21.360]   And now if you go to like, I forget the website,
[00:39:21.360 --> 00:39:24.520]   but I think it's like, if you search TensorFlow Extended,
[00:39:24.520 --> 00:39:26.380]   now it's more of a thing,
[00:39:26.380 --> 00:39:28.640]   but I feel like it's still very confusing.
[00:39:28.640 --> 00:39:30.400]   But they made modules available
[00:39:30.400 --> 00:39:34.440]   for TensorFlow data validation, data transformations,
[00:39:34.440 --> 00:39:36.760]   model analysis, and then serving.
[00:39:36.760 --> 00:39:39.080]   And then in the middle is just like vanilla TensorFlow,
[00:39:39.080 --> 00:39:40.720]   which actually trains your model.
[00:39:40.720 --> 00:39:43.280]   So.
[00:39:43.280 --> 00:39:48.200]   - Do you use something like TensorFlow Extended or Qflow?
[00:39:48.200 --> 00:39:51.120]   - No, no.
[00:39:51.120 --> 00:39:52.720]   I don't, yeah, I haven't.
[00:39:52.720 --> 00:39:56.560]   - I'm saying like, compared to Qflow and TensorFlow Extended
[00:39:57.440 --> 00:39:59.280]   in their growth of platform,
[00:39:59.280 --> 00:40:02.760]   what would be a better way to transcribe?
[00:40:02.760 --> 00:40:04.880]   - I think TensorFlow Extended is slightly different.
[00:40:04.880 --> 00:40:08.320]   It's just extending the range of what TensorFlow covers.
[00:40:08.320 --> 00:40:11.640]   So TensorFlow started as a way to like do,
[00:40:11.640 --> 00:40:13.940]   essentially, you know, computational models.
[00:40:13.940 --> 00:40:18.220]   So that starts from formatted data and ends at,
[00:40:18.220 --> 00:40:19.680]   you know, output.
[00:40:19.680 --> 00:40:21.680]   And TensorFlow Extended is,
[00:40:21.680 --> 00:40:23.360]   potentially starts from like raw data.
[00:40:23.360 --> 00:40:25.560]   So maybe like SQL rows or something.
[00:40:25.560 --> 00:40:28.080]   And then has code to transform that data
[00:40:28.080 --> 00:40:30.160]   into something that's trainable.
[00:40:30.160 --> 00:40:32.680]   And just like optimize code for all of that.
[00:40:32.680 --> 00:40:37.360]   And then doesn't stop at a trained model
[00:40:37.360 --> 00:40:38.880]   that's able to make predictions,
[00:40:38.880 --> 00:40:41.880]   but also potentially optimizes the model.
[00:40:41.880 --> 00:40:43.920]   So one optimization could be to like prune
[00:40:43.920 --> 00:40:46.280]   the number of connections in the model.
[00:40:46.280 --> 00:40:50.440]   So if like the different, you know,
[00:40:50.440 --> 00:40:51.880]   from layer to layer, if there's not,
[00:40:51.880 --> 00:40:53.360]   if there's a zero connection,
[00:40:53.360 --> 00:40:54.960]   you could potentially just remove it
[00:40:54.960 --> 00:40:57.600]   and not even go through a computational path.
[00:40:57.600 --> 00:41:02.600]   So I think TensorFlow Extended has that model validation,
[00:41:02.600 --> 00:41:06.140]   optimization, so as a module.
[00:41:06.140 --> 00:41:10.720]   But Kubeflow is just saying like,
[00:41:10.720 --> 00:41:12.360]   fine, you're trying to do all these things,
[00:41:12.360 --> 00:41:14.520]   but where are you actually trying to run them?
[00:41:14.520 --> 00:41:18.140]   So if you have some underlying hardware, you know,
[00:41:18.140 --> 00:41:20.160]   and Kubernetes running on top of that hardware,
[00:41:20.160 --> 00:41:22.040]   then Kubeflow makes it possible
[00:41:22.040 --> 00:41:24.720]   to distribute the jobs you want onto that.
[00:41:24.720 --> 00:41:27.600]   And then the last thing I wanted to cover is MLflow,
[00:41:27.600 --> 00:41:30.160]   which is something from Databricks,
[00:41:30.160 --> 00:41:32.940]   which is the company behind Spark, Apache Spark.
[00:41:32.940 --> 00:41:36.680]   So they sell MLflow as an open source platform
[00:41:36.680 --> 00:41:38.360]   for the machine learning life cycle.
[00:41:38.360 --> 00:41:41.060]   And what they try to do is they kind of have three things.
[00:41:41.060 --> 00:41:43.660]   They have a project format.
[00:41:43.660 --> 00:41:44.920]   So they say packaging format
[00:41:44.920 --> 00:41:47.140]   for reproducible runs on any platform.
[00:41:47.140 --> 00:41:49.080]   All it is is like a YAML file
[00:41:49.080 --> 00:41:51.080]   that conforms to their specification.
[00:41:52.360 --> 00:41:55.760]   MLflow model is the idea that like,
[00:41:55.760 --> 00:41:57.840]   if you follow the format,
[00:41:57.840 --> 00:41:59.600]   then the weights will be saved in such a way
[00:41:59.600 --> 00:42:02.000]   that you can use them with TensorFlow,
[00:42:02.000 --> 00:42:05.320]   or you can use them with Apache Spark, whatever they have,
[00:42:05.320 --> 00:42:09.520]   or just kind of a common way to save weights, right?
[00:42:09.520 --> 00:42:12.600]   Or save the artifacts
[00:42:12.600 --> 00:42:14.640]   that you need to actually make predictions.
[00:42:14.640 --> 00:42:17.160]   And then MLflow tracking is a user interface
[00:42:17.160 --> 00:42:20.380]   for recording the experiments that you run,
[00:42:20.380 --> 00:42:22.900]   which includes the code, the data, the config, and results,
[00:42:22.900 --> 00:42:27.060]   with like an open source interface to review that stuff.
[00:42:27.060 --> 00:42:29.060]   From what I've seen, it doesn't seem very good to me.
[00:42:29.060 --> 00:42:32.080]   Like people on Hacker News don't think it's very good,
[00:42:32.080 --> 00:42:35.020]   but people in the bootcamp mentioned it
[00:42:35.020 --> 00:42:36.540]   when I was talking about this stuff.
[00:42:36.540 --> 00:42:38.540]   So I thought I'd just mention it, MLflow.
[00:42:38.540 --> 00:42:41.380]   And then there's other stuff, Polyaxon.
[00:42:41.380 --> 00:42:45.820]   So there's way too many solutions here.
[00:42:45.820 --> 00:42:48.240]   There's Domino Data Lab, Polyaxon.
[00:42:48.240 --> 00:42:53.240]   You know, all the, Determine AI,
[00:42:53.240 --> 00:42:56.520]   PaperSpace, Floyd, Neptune, all these things.
[00:42:56.520 --> 00:42:57.360]   I think the right thing to,
[00:42:57.360 --> 00:42:59.560]   and this is what I said in the lecture last time,
[00:42:59.560 --> 00:43:02.280]   I think the way to understand, to like stay sane,
[00:43:02.280 --> 00:43:04.920]   is to understand the parts that they're trying to do,
[00:43:04.920 --> 00:43:07.920]   and then just find your own solution
[00:43:07.920 --> 00:43:09.360]   to each one of those parts.
[00:43:09.360 --> 00:43:11.440]   So one of those parts is experiment management,
[00:43:11.440 --> 00:43:13.000]   and I think that's a very important part.
[00:43:13.000 --> 00:43:15.360]   And I would say probably the most important part.
[00:43:15.360 --> 00:43:18.440]   And really the only part that doesn't have
[00:43:18.440 --> 00:43:23.520]   a non-machine learning specific solution, right?
[00:43:23.520 --> 00:43:25.220]   'Cause people have been developing software
[00:43:25.220 --> 00:43:28.640]   and like packaging up deployment artifacts for decades.
[00:43:28.640 --> 00:43:31.000]   Like it's pretty, or yeah, it's,
[00:43:31.000 --> 00:43:32.240]   every time you deploy a website,
[00:43:32.240 --> 00:43:36.360]   you have to compile a whole bunch of like HTML and CSS code
[00:43:36.360 --> 00:43:37.920]   and upload it somewhere.
[00:43:37.920 --> 00:43:39.420]   Training a model is not so different.
[00:43:39.420 --> 00:43:41.120]   It's like you just run your training thing,
[00:43:41.120 --> 00:43:43.380]   you save your model, you upload it somewhere.
[00:43:43.380 --> 00:43:47.280]   But the one part of the machine learning lifecycle
[00:43:47.280 --> 00:43:49.760]   that doesn't exist in the rest of software development
[00:43:49.760 --> 00:43:52.300]   is the fact that you've run multiple experiments,
[00:43:52.300 --> 00:43:54.140]   and you have to keep track of them.
[00:43:54.140 --> 00:43:56.100]   So I think that's the most important part.
[00:43:56.100 --> 00:43:58.060]   Luke is gonna talk about that.
[00:43:58.060 --> 00:43:59.060]   Do you guys have any questions
[00:43:59.060 --> 00:44:03.240]   about the infrastructure stuff before we switch over?
[00:44:03.240 --> 00:44:05.820]   Yep.
[00:44:05.820 --> 00:44:09.800]   - With the hosted machines, hosted GPUs on them,
[00:44:12.000 --> 00:44:15.500]   how do you handle the changing requirements
[00:44:15.500 --> 00:44:16.940]   over the course of the project?
[00:44:16.940 --> 00:44:18.540]   So at the beginning, you might have one person
[00:44:18.540 --> 00:44:21.660]   prototyping and then you might have a bunch of interns,
[00:44:21.660 --> 00:44:24.380]   and then you might wanna do hyperparameter tuning
[00:44:24.380 --> 00:44:26.420]   or train like really large models.
[00:44:26.420 --> 00:44:28.220]   - You gotta buy more machines.
[00:44:28.220 --> 00:44:31.380]   - It's not just, it's like the needs might change.
[00:44:31.380 --> 00:44:33.460]   Like you might need more memory at some point
[00:44:33.460 --> 00:44:35.900]   versus more GPUs at another point.
[00:44:35.900 --> 00:44:37.220]   So.
[00:44:37.220 --> 00:44:40.420]   - So I don't think in the project lifecycle,
[00:44:40.420 --> 00:44:45.420]   the needs change, but I do think in a single training run,
[00:44:45.420 --> 00:44:49.140]   the computational needs do change.
[00:44:49.140 --> 00:44:51.940]   So for example, if you're training something
[00:44:51.940 --> 00:44:56.940]   on a large dataset where you have like a bunch of,
[00:44:56.940 --> 00:45:00.960]   let's say images, and you're trying to extract something
[00:45:00.960 --> 00:45:03.260]   from like, let's say you're just trying to crop out
[00:45:03.260 --> 00:45:06.620]   a part of an image and then use that crop,
[00:45:06.620 --> 00:45:08.860]   and that's all you're gonna use for training.
[00:45:08.860 --> 00:45:11.740]   So maybe you have like a million images.
[00:45:11.740 --> 00:45:14.820]   So you have a million crop operations that you gotta do.
[00:45:14.820 --> 00:45:16.620]   Now those things are not GPU bound.
[00:45:16.620 --> 00:45:19.500]   Like you could just distribute them onto a bunch of CPUs
[00:45:19.500 --> 00:45:21.100]   and it would be just fine.
[00:45:21.100 --> 00:45:25.820]   But when you do those crops, at that point,
[00:45:25.820 --> 00:45:28.380]   you wanna start, you wanna send them into the GPU.
[00:45:28.380 --> 00:45:31.420]   So I think the problem that I faced is,
[00:45:31.420 --> 00:45:33.360]   like you have a task that's CPU bound,
[00:45:33.360 --> 00:45:36.860]   but then the output of that task has to be,
[00:45:37.100 --> 00:45:39.100]   data local to the GPU.
[00:45:39.100 --> 00:45:42.060]   So I don't have like a great solution to that.
[00:45:42.060 --> 00:45:46.820]   But I think that's where a cloud solution could be better,
[00:45:46.820 --> 00:45:49.460]   particularly like Google Cloud, I think is very good,
[00:45:49.460 --> 00:45:53.100]   because they allow you to like mix and match CPU.
[00:45:53.100 --> 00:45:55.260]   Like you can take any of their machines
[00:45:55.260 --> 00:45:58.020]   and then link up any of their GPUs to it.
[00:45:58.020 --> 00:45:59.500]   And so I think that could be very powerful.
[00:45:59.500 --> 00:46:02.580]   You could have like a machine with a bunch of CPUs,
[00:46:02.580 --> 00:46:05.180]   and then do your pre-processing on that,
[00:46:05.180 --> 00:46:07.500]   and then maybe link up GPUs to it at that point,
[00:46:07.500 --> 00:46:09.340]   and only pay for GPUs at that point.
[00:46:09.340 --> 00:46:13.840]   So I'd say it is a problem, but it doesn't,
[00:46:13.840 --> 00:46:15.380]   I think as you hire more people,
[00:46:15.380 --> 00:46:19.140]   you just buy more machines and it tends to scale.
[00:46:19.140 --> 00:46:19.980]   Yeah.
[00:46:19.980 --> 00:46:22.460]   - Basically how you said in the lecture,
[00:46:22.460 --> 00:46:25.360]   I think five days a week, 10 hours a day or whatever.
[00:46:25.360 --> 00:46:27.880]   - Yeah, so I have like slides in here
[00:46:27.880 --> 00:46:29.560]   that just have some kind of
[00:46:29.560 --> 00:46:32.080]   back of the envelope calculations,
[00:46:32.080 --> 00:46:34.380]   which is basically like if you have a person working,
[00:46:34.380 --> 00:46:36.260]   like a work week, like 40 hours,
[00:46:36.260 --> 00:46:37.940]   and then running experiments maybe overnight,
[00:46:37.940 --> 00:46:39.420]   every now and then,
[00:46:39.420 --> 00:46:43.180]   how many months of that person's time, right,
[00:46:43.180 --> 00:46:45.740]   would a physical machine pay for itself in?
[00:46:45.740 --> 00:46:47.900]   And I think the answer was like six or something, so.
[00:46:47.900 --> 00:46:49.100]   - My question is in practice,
[00:46:49.100 --> 00:46:50.780]   how do you actually,
[00:46:50.780 --> 00:46:54.020]   are you guys able to keep the machine busy at that pace?
[00:46:54.020 --> 00:46:57.100]   - No, there's definitely, yeah, it's not busy all the time.
[00:46:57.100 --> 00:46:59.900]   It is spiking, but the,
[00:47:01.780 --> 00:47:06.260]   so one answer is if you get that data flywheel going,
[00:47:06.260 --> 00:47:08.820]   where essentially you have,
[00:47:08.820 --> 00:47:13.420]   like if you're able to train on fresh data every week,
[00:47:13.420 --> 00:47:17.780]   then every week you have a workload.
[00:47:17.780 --> 00:47:19.780]   And if you can get that down to a day,
[00:47:19.780 --> 00:47:20.980]   then that's even better.
[00:47:20.980 --> 00:47:23.700]   And if you have seven models that you have in production,
[00:47:23.700 --> 00:47:24.940]   you train each one a week,
[00:47:24.940 --> 00:47:27.100]   now you got a machine like working pretty much all the time.
[00:47:27.100 --> 00:47:28.680]   So that's actually what we do.
[00:47:28.680 --> 00:47:30.660]   But for a machine that's only for development,
[00:47:30.660 --> 00:47:33.980]   like no, experiments don't run all the time on it, right.
[00:47:33.980 --> 00:47:36.940]   - Sorry, after this question,
[00:47:36.940 --> 00:47:39.860]   you might have to take the rest for after class.
[00:47:39.860 --> 00:47:41.020]   - As you see the whole spectrum,
[00:47:41.020 --> 00:47:44.100]   I think what is really important is the whole
[00:47:44.100 --> 00:47:46.020]   the common task, like the quantization,
[00:47:46.020 --> 00:47:48.220]   and everything, something like Q flow,
[00:47:48.220 --> 00:47:50.100]   and then the entire process of,
[00:47:50.100 --> 00:47:50.940]   like, you know,
[00:47:50.940 --> 00:47:52.140]   from raw data to the modeling,
[00:47:52.140 --> 00:47:54.300]   like something like TensorFlow extended,
[00:47:54.300 --> 00:47:55.900]   and for the whole experimentation set up,
[00:47:55.900 --> 00:47:57.420]   something like weights and passes.
[00:47:57.420 --> 00:48:00.460]   Like, is that like a good combination of all this
[00:48:00.460 --> 00:48:03.340]   to kind of set up this environment and (indistinct)
[00:48:03.340 --> 00:48:05.300]   - Yeah, so that's what these things promise,
[00:48:05.300 --> 00:48:07.340]   like Neptune is a startup,
[00:48:07.340 --> 00:48:09.220]   Floyd is a startup that does this,
[00:48:09.220 --> 00:48:13.420]   Amazon SageMaker is an Amazon product that promises this.
[00:48:13.420 --> 00:48:16.180]   Determine AI is a startup that will do this stuff
[00:48:16.180 --> 00:48:18.520]   for you on-prem, like on your own machines.
[00:48:18.520 --> 00:48:21.220]   But...
[00:48:21.220 --> 00:48:23.640]   (indistinct)
[00:48:23.640 --> 00:48:28.580]   Yeah, so what I suggest is just understanding the workflows,
[00:48:28.580 --> 00:48:30.660]   like, okay, the notebook step is easy,
[00:48:30.660 --> 00:48:32.620]   and that's just running a notebook.
[00:48:32.620 --> 00:48:36.260]   Distributing stuff onto GPUs is actually pretty easy,
[00:48:36.260 --> 00:48:37.920]   like depends on what you're trying to do,
[00:48:37.920 --> 00:48:39.940]   but like, it's not that hard.
[00:48:39.940 --> 00:48:41.340]   Then you gotta do experiment management,
[00:48:41.340 --> 00:48:43.180]   that's the part that I don't have a good solution for
[00:48:43.180 --> 00:48:46.700]   outside of things like weights and biases.
[00:48:46.700 --> 00:48:47.780]   And then you gotta deploy it,
[00:48:47.780 --> 00:48:51.420]   I think it's perfectly fine to deploy on just CPU hardware,
[00:48:51.420 --> 00:48:54.020]   or, you know, sorry, CPU cloud instances.
[00:48:54.020 --> 00:48:56.140]   And we actually use Amazon Lambda.
[00:48:56.140 --> 00:48:59.220]   So, yeah, my recommendation is not to buy
[00:48:59.220 --> 00:49:00.980]   into these all-in-one things,
[00:49:00.980 --> 00:49:03.460]   but to just kind of understand what they do,
[00:49:03.460 --> 00:49:06.420]   and then just decide what you're gonna do for each part.
[00:49:06.420 --> 00:49:11.000]   But the one part that I advise against coding yourself
[00:49:11.000 --> 00:49:12.940]   is the experiment management part,
[00:49:12.940 --> 00:49:15.780]   'cause that's just a lot of code that, yeah.
[00:49:15.780 --> 00:49:19.500]   Well, I think that was the last question, sorry.
[00:49:19.500 --> 00:49:21.640]   All right, well, thank you.
[00:49:21.640 --> 00:49:22.940]   If you have any questions,
[00:49:24.500 --> 00:49:26.300]   Josh will tell you how to find me.
[00:49:26.300 --> 00:49:29.300]   (audience applauds)

