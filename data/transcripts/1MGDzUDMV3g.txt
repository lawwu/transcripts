
[00:00:00.000 --> 00:00:04.240]   Hey everybody, thank you for clicking on this link.
[00:00:04.240 --> 00:00:10.580]   Uh, this is a recording of an ask me anything with the creator of Keras
[00:00:10.580 --> 00:00:14.800]   himself, software engineer at Google, Franscho Chollet.
[00:00:14.800 --> 00:00:18.240]   This is a part of, sorry for the table shake.
[00:00:18.240 --> 00:00:21.400]   This is a part of our reading group at Weitz and Basses.
[00:00:21.400 --> 00:00:25.360]   We will be going over the book, deep learning with Python second edition,
[00:00:25.360 --> 00:00:27.880]   which also has been written by Franscho.
[00:00:28.760 --> 00:00:32.160]   It's such an honor to kick off the series within ask me anything.
[00:00:32.160 --> 00:00:37.540]   Uh, we did this on a Saturday and over the next few weeks, we'll be going
[00:00:37.540 --> 00:00:39.920]   over the chapters in sequential order.
[00:00:39.920 --> 00:00:44.240]   With this recording, you can find the signup link in the description.
[00:00:44.240 --> 00:00:47.760]   If you want to join the future sessions, we're still in the early stages and I
[00:00:47.760 --> 00:00:51.620]   invite all of you to join if you're interested in learning Keras and I look
[00:00:51.620 --> 00:00:56.600]   forward to seeing you all in this meetup series, here's an intervention by editor.
[00:00:56.600 --> 00:01:00.680]   So I wanted to mention in an effort to invite everyone to spend more time
[00:01:00.680 --> 00:01:06.080]   learning Keras with kicking off 27 days of Keras, the only requirement to join
[00:01:06.080 --> 00:01:13.040]   is spend 15 minutes to 24 hours every day learning Keras, write about it.
[00:01:13.040 --> 00:01:20.100]   Share a notebook, share a blog post, use the hashtag 27 days of Keras and tag
[00:01:20.100 --> 00:01:22.560]   either me or Weitz and Basses on Twitter.
[00:01:24.120 --> 00:01:26.960]   And every single week we'll be sending out swag to people.
[00:01:26.960 --> 00:01:31.800]   Uh, this is to encourage everyone to first of all, spend time learning Keras.
[00:01:31.800 --> 00:01:33.920]   And second of all, also share their work.
[00:01:33.920 --> 00:01:38.400]   I'm quite biased as someone who creates content, but I think there's a lot of
[00:01:38.400 --> 00:01:41.280]   learning that goes on there and it's also useful for your career.
[00:01:41.280 --> 00:01:45.320]   And if you'd like to learn Keras, I hope this, uh, excites you.
[00:01:51.240 --> 00:01:51.840]   Hey everybody.
[00:01:51.840 --> 00:01:54.320]   Thank you for joining us on a Saturday.
[00:01:54.320 --> 00:01:58.520]   I have been asking stupid questions to really smart people for a long time,
[00:01:58.520 --> 00:02:03.840]   but it's been a long while since I've gotten these shakes because, uh, today
[00:02:03.840 --> 00:02:06.240]   I get to interview on your behalf.
[00:02:06.240 --> 00:02:10.880]   Franscho Chole, uh, we'll be reading his incredible books, second version,
[00:02:10.880 --> 00:02:14.600]   deep learning with Python, uh, which is by Manning publication.
[00:02:14.600 --> 00:02:19.600]   And this is an AMA session that Franscho kindly agreed to join, uh, to answer
[00:02:19.600 --> 00:02:23.560]   any of your questions around Keras, uh, deep learning or otherwise.
[00:02:23.560 --> 00:02:26.600]   Uh, Franscho, thank you so much again for joining us today.
[00:02:26.600 --> 00:02:28.680]   Yeah.
[00:02:28.680 --> 00:02:30.440]   Thank you for the, for the very nice intro.
[00:02:30.440 --> 00:02:34.400]   And yeah, it's, it's my pleasure to be, to be here with you today, early
[00:02:34.400 --> 00:02:36.800]   morning and to answer any question you might have.
[00:02:36.800 --> 00:02:40.120]   And, um, if you're reading the book, please, uh, please enjoy the book.
[00:02:40.120 --> 00:02:45.320]   I, I wish I would have been able to flip the pages, but I've littered all
[00:02:45.320 --> 00:02:46.840]   over the pages with my notes.
[00:02:46.840 --> 00:02:51.720]   So I won't do that because I think that makes the book a little bit bad.
[00:02:51.720 --> 00:02:56.120]   Um, to the audience, please keep asking any questions and I'll be
[00:02:56.120 --> 00:02:57.560]   picking them from the portal.
[00:02:57.560 --> 00:03:01.600]   The ask me anything will go on for 20 minutes and past that I'll start going
[00:03:01.600 --> 00:03:03.640]   through the chapters in sequential order.
[00:03:03.640 --> 00:03:07.240]   Um, Franscho, I want to start by asking a stupid question.
[00:03:07.240 --> 00:03:10.760]   How does, uh, someone at your level continue learning today?
[00:03:10.760 --> 00:03:12.600]   What techniques do you follow today?
[00:03:12.600 --> 00:03:15.040]   Uh, how do you go about learning any new topic?
[00:03:16.720 --> 00:03:17.800]   Learning a new topic.
[00:03:17.800 --> 00:03:18.200]   Okay.
[00:03:18.200 --> 00:03:22.840]   So first of all, I'm not sure there's really like a universal
[00:03:22.840 --> 00:03:24.720]   technique for learning any topic.
[00:03:24.720 --> 00:03:27.880]   Uh, every topic and a course for a different strategy.
[00:03:27.880 --> 00:03:30.480]   Like if you're learning a new language, that's not the same.
[00:03:30.480 --> 00:03:33.920]   If you're, if you're learning music production, it's not the same as if
[00:03:33.920 --> 00:03:36.840]   you're learning history on your psychology or something.
[00:03:36.840 --> 00:03:41.360]   So I guess the first thing to do is identify what's the best learning
[00:03:41.360 --> 00:03:42.720]   technique for that specific.
[00:03:42.720 --> 00:03:45.520]   Uh, topic is going to be like, for instance, what are the best
[00:03:45.520 --> 00:03:46.840]   language learning techniques or something.
[00:03:46.840 --> 00:03:50.640]   Um, so now if you're talking about academic topics, like if you're
[00:03:50.640 --> 00:03:52.960]   talking about deep learning, for instance, or physics or something,
[00:03:52.960 --> 00:03:57.040]   uh, I really liked the Feynman, uh, method.
[00:03:57.040 --> 00:04:01.280]   Uh, and you, you probably, you know, already know about it, but the gist of
[00:04:01.280 --> 00:04:06.520]   it is, uh, trying to learn a topic by pretending to explain it to a child.
[00:04:06.520 --> 00:04:10.200]   So first you should figure out, you know, what's the highest quality resource,
[00:04:10.200 --> 00:04:14.200]   uh, for learning like a specific textbook or maybe a specific set of
[00:04:14.200 --> 00:04:17.480]   online lectures and so on, and then you go through the materials.
[00:04:17.480 --> 00:04:22.600]   And, uh, once you, once you've done that, uh, for each chapter, for each
[00:04:22.600 --> 00:04:27.080]   part, you try to summarize, uh, to yourself, what you just learned, you
[00:04:27.080 --> 00:04:33.200]   try to organize and simplify the mental model that you just built, uh, uh,
[00:04:33.200 --> 00:04:34.440]   with, uh, which we just learned.
[00:04:34.440 --> 00:04:36.400]   And you can, you can do that.
[00:04:36.400 --> 00:04:38.080]   You know, that's the, that's the Feynman technique.
[00:04:38.080 --> 00:04:41.760]   You can do that by pretending that you're teaching the topic to a friend
[00:04:41.760 --> 00:04:46.480]   or, or to a child, because you want to be able to explain, uh, in very simple
[00:04:46.480 --> 00:04:49.920]   terms, you want to break it down to a level where you're really sure that you
[00:04:49.920 --> 00:04:51.320]   actually know what you're talking about.
[00:04:51.320 --> 00:04:55.480]   If you're not, uh, you're not fooling yourself into thinking you understand
[00:04:55.480 --> 00:05:00.800]   the words, um, and that process of introspection of your mental model,
[00:05:00.800 --> 00:05:02.400]   which is very fresh in your mind.
[00:05:02.400 --> 00:05:06.600]   Um, that will lead you to better organize things in your mind.
[00:05:06.600 --> 00:05:10.800]   It will also lead you to identify flows or like inconsistencies, things you
[00:05:10.800 --> 00:05:15.400]   don't really understand, things you're not able, uh, to, to explain, to articulate.
[00:05:15.400 --> 00:05:18.440]   And then you can go back to the materials with that in mind.
[00:05:18.440 --> 00:05:22.360]   Uh, so don't just like read up on something, like create a book chapter
[00:05:22.360 --> 00:05:25.840]   and assume that, yeah, like the, you know, that was easy.
[00:05:25.840 --> 00:05:26.960]   I just, I just said everything.
[00:05:26.960 --> 00:05:29.160]   Go back to your mental model, right.
[00:05:29.160 --> 00:05:31.760]   And try, try to articulate what I just learned.
[00:05:31.760 --> 00:05:35.280]   Um, you know, what, what, what, what, what does this thing about?
[00:05:35.280 --> 00:05:39.840]   So always try to probe, uh, your understanding inspect, inspect that
[00:05:39.840 --> 00:05:42.880]   mental model, because it's by inspecting it, that you're going to be able to
[00:05:42.880 --> 00:05:45.200]   find flaws in it and improve it.
[00:05:45.200 --> 00:05:48.720]   And, uh, a rated technique is a mind mapping.
[00:05:48.720 --> 00:05:51.800]   I know if you, if you know about mind mapping, it's very similar, right?
[00:05:51.800 --> 00:05:54.640]   It's about trying to write down.
[00:05:54.640 --> 00:05:59.520]   But your current mental model of something is in a very visual fashion by just
[00:05:59.520 --> 00:06:02.560]   connecting, uh, concepts and doodling and so on.
[00:06:02.560 --> 00:06:07.640]   Uh, so you can see it's, uh, it's almost the same thing as, as trying to explain
[00:06:07.640 --> 00:06:10.040]   that topic, uh, but more, more visually.
[00:06:10.040 --> 00:06:13.880]   And the visual aspect is actually interesting because I think, you know,
[00:06:13.880 --> 00:06:17.760]   information in your mind is, is kind of organized as a, as a graph.
[00:06:17.760 --> 00:06:22.960]   So making that graph explicit actually helps basically by, by drawing something
[00:06:22.960 --> 00:06:29.560]   on paper, it's almost as if you're editing your, your literal mental model, uh, in
[00:06:29.560 --> 00:06:30.080]   your brain.
[00:06:30.080 --> 00:06:32.360]   So I think it's also a very powerful technique.
[00:06:32.360 --> 00:06:34.640]   That's such a powerful answer.
[00:06:34.640 --> 00:06:38.720]   Active recall and explaining to someone, I know you're very vocal on Twitter, but
[00:06:38.720 --> 00:06:42.320]   the care is common communities, contribution about blog posts and everything.
[00:06:42.320 --> 00:06:46.760]   Those to the audience as a solution, writing blog posts is also a great way
[00:06:46.760 --> 00:06:48.160]   of following this.
[00:06:48.160 --> 00:06:55.000]   Um, if I may, for someone who's studying your book, uh, what would be a suggested
[00:06:55.000 --> 00:06:55.440]   homework?
[00:06:55.440 --> 00:06:57.880]   Who would you call a successful student?
[00:06:57.880 --> 00:07:01.360]   What, what, what can we do to become successful students?
[00:07:01.360 --> 00:07:04.120]   All right.
[00:07:04.120 --> 00:07:10.600]   So I guess the main thing in mind is, you know, uh, that's usually the book.
[00:07:10.600 --> 00:07:13.280]   That's like the first step, but that's, that's not, that's not nearly enough.
[00:07:13.280 --> 00:07:17.400]   Like the book gives you, uh, the knowledge, like the mental models and
[00:07:17.400 --> 00:07:20.520]   gives you a starting points for your intuition, but it does not give you the
[00:07:20.520 --> 00:07:25.000]   practical experience and the practical, uh, intuition, uh, that you're going to
[00:07:25.000 --> 00:07:25.280]   need.
[00:07:25.280 --> 00:07:28.600]   And to do that, you need a, you need hands on experience.
[00:07:28.600 --> 00:07:30.080]   So make it hands on, right?
[00:07:30.080 --> 00:07:34.400]   Like, instead of just finding the core examples I give you, try to modify
[00:07:34.400 --> 00:07:38.120]   things, try to come up with your, your, your, your own ideas.
[00:07:38.120 --> 00:07:41.640]   Like, Hey, maybe I should, you know, run this image classification model on
[00:07:41.640 --> 00:07:45.840]   different data sets with different properties, or, Hey, maybe I can use
[00:07:45.840 --> 00:07:46.800]   different kind of layer.
[00:07:46.800 --> 00:07:49.080]   Maybe I can use different kinds of regularization and so on.
[00:07:49.080 --> 00:07:50.480]   And then you just see what happens.
[00:07:50.480 --> 00:07:53.920]   And by, by doing this, you know, repeatedly, like coming up with ideas,
[00:07:53.920 --> 00:07:58.040]   like what if, and trying to implement it and seeing what happens, that's how you
[00:07:58.040 --> 00:07:59.080]   actually build your intuition.
[00:07:59.080 --> 00:08:03.440]   It's also how you build kind of your, your understanding of where things are
[00:08:03.440 --> 00:08:05.560]   in GPI, how to go to things and so on.
[00:08:05.560 --> 00:08:10.240]   And, uh, and once you're like, Towards the end of the book, you've read through
[00:08:10.240 --> 00:08:14.160]   everything, you feel like, you know, everything, then you should start
[00:08:14.160 --> 00:08:17.120]   practicing on some end to end, uh, problems.
[00:08:17.120 --> 00:08:21.240]   And that's where, so the, the, the Kaggle, uh, competition websites, right.
[00:08:21.240 --> 00:08:24.800]   The machine and competition website is the great resource because it's a, it's
[00:08:24.800 --> 00:08:30.560]   a, basically a great database of different problems and data sets covering, you know,
[00:08:30.560 --> 00:08:33.080]   uh, all kinds of, uh, practical topics.
[00:08:33.080 --> 00:08:36.040]   Um, so that's, that's something you can work on.
[00:08:36.040 --> 00:08:39.400]   Like the fuller homework would be, you know, try doing some Kaggle competitions.
[00:08:39.400 --> 00:08:44.400]   Maybe also try, uh, teaming up with someone, uh, on Kaggle and learning
[00:08:44.400 --> 00:08:45.320]   from that person and so on.
[00:08:45.320 --> 00:08:47.200]   I'm quite biased.
[00:08:47.200 --> 00:08:52.520]   I'm also drinking my chai from my Kaggle mug today, but I think it's one of the
[00:08:52.520 --> 00:08:54.040]   most powerful communities.
[00:08:54.600 --> 00:09:00.960]   Uh, this is, uh, so I, I spoke about the Keras ecosystem where people contribute
[00:09:00.960 --> 00:09:03.480]   incredible, uh, open source examples.
[00:09:03.480 --> 00:09:08.840]   Uh, this question is by Ankit and I think many of us suffer imposter syndrome.
[00:09:08.840 --> 00:09:10.440]   We're too scared to contribute.
[00:09:10.440 --> 00:09:15.920]   Any tips on how we can contribute, uh, or go past the imposter syndrome to
[00:09:15.920 --> 00:09:18.000]   contribute to the open source ecosystem?
[00:09:18.000 --> 00:09:19.880]   Right.
[00:09:20.040 --> 00:09:26.160]   Um, so I don't think it's that difficult to contribute to Keras.
[00:09:26.160 --> 00:09:29.480]   Like if you have, if you have the knowledge how to use Keras, then you're,
[00:09:29.480 --> 00:09:32.680]   you're, you're probably able to also contribute to Keras and that, you know,
[00:09:32.680 --> 00:09:34.720]   there are different levels at which you can contribute.
[00:09:34.720 --> 00:09:40.280]   Um, and my recommendation is basically, you know, you should scratch your own
[00:09:40.280 --> 00:09:40.800]   itch.
[00:09:40.800 --> 00:09:44.760]   Like if there's something about the Keras API, for instance, that's been
[00:09:44.760 --> 00:09:49.040]   bothering you, maybe like a useless warning somewhere or a bug or a missing
[00:09:49.040 --> 00:09:50.760]   feature, then that's where you should start.
[00:09:50.760 --> 00:09:54.880]   And if you don't know what you can do about it, then you can just start by
[00:09:54.880 --> 00:09:56.960]   describing, uh, what you want.
[00:09:56.960 --> 00:10:01.360]   I can just open an issue, find a bug report and so on and make it, you know,
[00:10:01.360 --> 00:10:03.000]   make it actionable, make it high quality.
[00:10:03.000 --> 00:10:04.240]   That's like the first step.
[00:10:04.240 --> 00:10:09.920]   And then the second step is you can basically start diving into the code
[00:10:09.920 --> 00:10:13.600]   base and start figuring out, you know, what, what would it take to actually
[00:10:13.600 --> 00:10:14.200]   make a change?
[00:10:14.200 --> 00:10:16.600]   And we can actually guide you, uh, right.
[00:10:16.600 --> 00:10:18.320]   If you, if you, if you ask us questions.
[00:10:19.200 --> 00:10:23.520]   And, um, if, and you know, if there's, if there's not like any specific
[00:10:23.520 --> 00:10:26.800]   feature that you're thinking about, if there's not a specific bug that you run
[00:10:26.800 --> 00:10:32.240]   into, uh, the other thing you can do is just a code example contributions, like
[00:10:32.240 --> 00:10:33.720]   are improving the docs.
[00:10:33.720 --> 00:10:36.760]   Like, Hey, you were, you were ringing up on some symbol and you found like,
[00:10:36.760 --> 00:10:40.800]   there's, there's some short explanation, but there's no code example.
[00:10:40.800 --> 00:10:43.200]   So like you didn't really understand what you'd been saying.
[00:10:43.200 --> 00:10:45.600]   So you want, you want to rephrase it, something like this.
[00:10:45.600 --> 00:10:48.840]   This is actually a super helpful because any sort of change you're making, like
[00:10:48.840 --> 00:10:52.920]   to the docs or code examples on the, on the code base itself, that's going to be,
[00:10:52.920 --> 00:10:55.960]   you know, reread, reused by like thousands of people.
[00:10:55.960 --> 00:10:58.920]   So you actually, you're, you're, you're actually making a big impact with
[00:10:58.920 --> 00:10:59.520]   small changes.
[00:10:59.520 --> 00:11:03.480]   So anything that you feel would have been useful to you, that's actually going to
[00:11:03.480 --> 00:11:05.240]   be useful to thousands of people after you.
[00:11:05.240 --> 00:11:08.360]   And that's why, that's why, you know, that should be your motivation to actually.
[00:11:08.360 --> 00:11:10.840]   Try, try to dive in and make change.
[00:11:11.920 --> 00:11:16.000]   I know you spend a lot of time personally as well, mentoring the incoming
[00:11:16.000 --> 00:11:16.920]   contributions.
[00:11:16.920 --> 00:11:22.000]   Do you have any favorite resources that the community has contributed to the
[00:11:22.000 --> 00:11:23.320]   Keras.io website?
[00:11:23.320 --> 00:11:25.120]   Yeah.
[00:11:25.120 --> 00:11:31.120]   I mean I would say so in the, in the, in the, in the classic with this, I mean,
[00:11:31.120 --> 00:11:32.800]   it's a, it's very much community projects.
[00:11:32.800 --> 00:11:35.520]   So lots of things have been given to me, contributed by the community.
[00:11:35.520 --> 00:11:40.240]   In terms of the Keras.io examples, I mean, they're, they're, they're fantastic
[00:11:40.240 --> 00:11:40.640]   resource.
[00:11:40.640 --> 00:11:44.120]   Like we've got something like 130 different examples.
[00:11:44.120 --> 00:11:48.520]   More than that actually now I think it's like 132 or something.
[00:11:48.520 --> 00:11:52.880]   And they've almost all been community contributed.
[00:11:52.880 --> 00:11:54.400]   Like I've met very few of them.
[00:11:54.400 --> 00:11:57.320]   I've met like the first like maybe 20 or so or 15.
[00:11:57.320 --> 00:12:03.080]   And yeah, I mean this is like one of the, one of the best resources to learn
[00:12:03.080 --> 00:12:04.040]   deep learning in practice.
[00:12:04.040 --> 00:12:08.080]   Like it's super high quality content and it's, it's like, it's made, made by you.
[00:12:08.080 --> 00:12:08.320]   Right.
[00:12:08.400 --> 00:12:10.520]   It's, it's yeah.
[00:12:10.520 --> 00:12:13.360]   So that's, that's been an incredible effort and it's only been like less than
[00:12:13.360 --> 00:12:13.840]   two years.
[00:12:13.840 --> 00:12:17.640]   So hopefully, you know, in another two years we're going to have 500.
[00:12:17.640 --> 00:12:24.600]   I'm sure the community really loves Keras and these are, as you mentioned, quite
[00:12:24.600 --> 00:12:25.440]   high quality.
[00:12:25.440 --> 00:12:28.920]   Each of the individual examples, the code, the pros.
[00:12:28.920 --> 00:12:32.120]   There's a question by Jackie Bosher.
[00:12:32.120 --> 00:12:36.080]   Do you plan to include transformers into Keras in the near future?
[00:12:36.080 --> 00:12:38.160]   Right.
[00:12:38.160 --> 00:12:38.880]   Great question.
[00:12:38.880 --> 00:12:40.360]   Yes.
[00:12:40.360 --> 00:12:43.840]   So there are several things we want to build in 2022.
[00:12:43.840 --> 00:12:50.840]   And one big thing is we want to work on domain specific extension packages of the
[00:12:50.840 --> 00:12:51.520]   Keras API.
[00:12:51.520 --> 00:12:54.560]   So one for computer vision and one for NLP.
[00:12:54.560 --> 00:12:56.560]   So Keras-CV and Keras-NLP.
[00:12:56.560 --> 00:12:59.720]   And in the Keras-NLP part, there's going to be transformers.
[00:12:59.720 --> 00:13:04.040]   So specifically there's going to be like high level building blocks, like Keras
[00:13:04.040 --> 00:13:09.200]   level building blocks that you can use to quickly assemble any sort of like modern
[00:13:09.200 --> 00:13:10.680]   transform architecture that you want.
[00:13:10.680 --> 00:13:20.160]   And we also want to kind of use that as a basis to kind of build an extended version
[00:13:20.160 --> 00:13:21.240]   of Keras applications.
[00:13:21.240 --> 00:13:25.600]   Like currently Keras applications, it's like, you know, it's pre-trained image
[00:13:25.600 --> 00:13:26.760]   classification models.
[00:13:26.760 --> 00:13:31.840]   And that's like useful, but that's very narrow, right?
[00:13:32.120 --> 00:13:36.800]   We could actually cover so many more tasks, like, you know, orientation and object
[00:13:36.800 --> 00:13:41.640]   detection and also NLP tasks like summarization, text generation, question
[00:13:41.640 --> 00:13:42.080]   answering.
[00:13:42.080 --> 00:13:46.000]   And we should actually, like we should, we should have a much bigger set of
[00:13:46.000 --> 00:13:50.600]   applications covering many more tasks in the pre-trained ways as well.
[00:13:50.600 --> 00:13:55.280]   There's a follow up question along those lines.
[00:13:55.280 --> 00:13:59.240]   I know you like to think in generally about broader topics as well.
[00:13:59.520 --> 00:14:03.280]   In your opinion, do you see machine learning converging to just transformers in
[00:14:03.280 --> 00:14:03.800]   the future?
[00:14:03.800 --> 00:14:07.520]   No, I think that's not super likely.
[00:14:07.520 --> 00:14:13.120]   I think so transformers actually a very interesting invest time.
[00:14:13.120 --> 00:14:18.960]   But, and I think so one trend that's definitely going to carry on is that we're
[00:14:18.960 --> 00:14:24.400]   going to see the application of transformer building blocks in many more domains and
[00:14:24.400 --> 00:14:25.600]   too many more problems.
[00:14:26.040 --> 00:14:31.360]   I don't think we're going to converge to one universal architecture that kind of
[00:14:31.360 --> 00:14:38.600]   runs against what we know with machine learning where for each domain, there's
[00:14:38.600 --> 00:14:44.760]   actually a specific set of kind of like prior knowledge that you already have about
[00:14:44.760 --> 00:14:48.880]   the domain that the model would benefit from.
[00:14:48.880 --> 00:14:55.360]   So if you know about the structure of the visual space, you can leverage that to be
[00:14:55.360 --> 00:14:56.200]   the better architecture.
[00:14:56.200 --> 00:15:01.880]   And in fact, today, some of the best computer vision architectures, they are not
[00:15:01.880 --> 00:15:05.160]   pure like transformers from the NLP world.
[00:15:05.160 --> 00:15:09.160]   They've been combined with convolution, they've been very heavily modified.
[00:15:09.160 --> 00:15:11.480]   So I think that's kind of like the trend you're going to see.
[00:15:11.480 --> 00:15:17.480]   We're going to put multi-head attention in more and more architectures.
[00:15:17.480 --> 00:15:21.160]   We're going to reuse what we've learned from transformers to improve all these
[00:15:21.160 --> 00:15:25.840]   architectures, but we are not going to converge on to basically the original
[00:15:25.840 --> 00:15:28.080]   transformer formulation from NLP.
[00:15:28.080 --> 00:15:29.880]   Makes sense.
[00:15:29.880 --> 00:15:33.720]   I have an unrelated question to continue.
[00:15:33.720 --> 00:15:36.320]   I'm sure you might have thoughts around JAX.
[00:15:36.320 --> 00:15:42.280]   So any things you could say about the JAX ecosystem and any interesting ideas you
[00:15:42.280 --> 00:15:46.000]   like there that we might see being migrated into Keras in the future?
[00:15:46.000 --> 00:15:48.160]   Right.
[00:15:48.160 --> 00:15:50.200]   So that's a deep question.
[00:15:50.200 --> 00:15:57.720]   Like I think JAX is very nice and it's been adopted by the research community as
[00:15:57.720 --> 00:15:58.040]   well.
[00:15:58.040 --> 00:16:00.560]   And I like it.
[00:16:00.560 --> 00:16:06.280]   I think it's I like the fact that it's very simple and minimalistic and it's a very
[00:16:06.280 --> 00:16:08.400]   simple functional stateless mental model.
[00:16:08.400 --> 00:16:10.920]   That's very easy to make sense of.
[00:16:10.920 --> 00:16:19.640]   And I do kind of want to try to see what we can do at the intersection of Keras and
[00:16:19.640 --> 00:16:20.000]   JAX.
[00:16:20.000 --> 00:16:25.760]   And that's actually an area where I would appreciate community feedback about what
[00:16:25.760 --> 00:16:27.280]   folks want to see.
[00:16:27.280 --> 00:16:32.480]   Like very often I would hear something like, hey, you know, why don't we build a
[00:16:32.480 --> 00:16:33.720]   JAX backend for Keras?
[00:16:33.720 --> 00:16:37.960]   But of course, the reality is not quite so simple.
[00:16:37.960 --> 00:16:38.280]   Right.
[00:16:38.280 --> 00:16:41.680]   So there are roughly three things we could be doing about JAX.
[00:16:41.720 --> 00:16:50.120]   So one is, so you know, Keras used to have a multi-backend architecture, right?
[00:16:50.120 --> 00:16:55.240]   Where basically everything in the Keras code base would eventually boil down to a set
[00:16:55.240 --> 00:17:03.400]   of calls to this backend API, which was a wrapper around either Tiana or TensorFlow or
[00:17:03.400 --> 00:17:05.960]   MXNet or CNTK and so on.
[00:17:06.360 --> 00:17:12.600]   And that had some interesting properties.
[00:17:12.600 --> 00:17:14.080]   It also had some downsides.
[00:17:14.080 --> 00:17:21.880]   And one path we could take is try to refactor Keras to adopt a multi-backend
[00:17:21.880 --> 00:17:25.640]   architecture again and do so in a background compatible way.
[00:17:25.640 --> 00:17:32.200]   So that current users of the TensorFlow backend end up with still the same code, the
[00:17:32.200 --> 00:17:32.840]   same code base.
[00:17:34.280 --> 00:17:40.040]   And this would actually be quite difficult, not just in terms of being a lot of work,
[00:17:40.040 --> 00:17:45.800]   but in terms that, you know, most things we do in Keras today would not be supported in
[00:17:45.800 --> 00:17:48.360]   JAX, like pre-processing layers, for instance.
[00:17:48.360 --> 00:17:53.760]   We're using basically hash tables or where we have like text input.
[00:17:53.760 --> 00:17:57.640]   So that doesn't run using XLA, right?
[00:17:57.640 --> 00:18:03.200]   Or distribution strategies, we would have to have an entirely different API for
[00:18:03.200 --> 00:18:03.880]   distribution.
[00:18:04.600 --> 00:18:10.680]   So we could do something, but it would not really be feature complete because we
[00:18:10.680 --> 00:18:15.680]   specialized in the features of TensorFlow to such a heavy extent.
[00:18:15.680 --> 00:18:20.760]   And of course, you know, all the related, like what makes the value of Keras models is
[00:18:20.760 --> 00:18:28.360]   not just the model itself and the Keras API itself, it's all the surrounding ecosystem.
[00:18:28.360 --> 00:18:29.040]   Right?
[00:18:29.040 --> 00:18:32.600]   Like, hey, if you have a Keras model, you can use the TensorFlow model optimization
[00:18:32.600 --> 00:18:36.560]   toolkits to optimize it to be a mobile device and you can use TF Lite and so on.
[00:18:36.560 --> 00:18:42.920]   And like, if we just start writing Keras models in JAX, you actually lose all of
[00:18:42.920 --> 00:18:43.280]   this.
[00:18:43.280 --> 00:18:51.440]   So another thing we could do is more like trying to build kind of bridges between
[00:18:51.440 --> 00:18:52.240]   JAX and Keras.
[00:18:52.240 --> 00:18:59.120]   Like what if we kept all of the existing TensorFlow Keras stuff, but we also
[00:18:59.120 --> 00:19:05.240]   enabled you to start writing Keras layers in JAX, but then you can still use them in a
[00:19:05.240 --> 00:19:06.760]   TensorFlow centric workflow.
[00:19:06.760 --> 00:19:07.360]   Right?
[00:19:07.360 --> 00:19:10.160]   Because ultimately they compile to XLA, right?
[00:19:10.160 --> 00:19:12.520]   So they actually compatible with TensorFlow.
[00:19:12.520 --> 00:19:15.600]   So that's an option I'm currently looking at.
[00:19:15.600 --> 00:19:23.000]   What if you could just drop JAX code into a Keras layer or Keras loss function, maybe a
[00:19:23.000 --> 00:19:26.920]   Keras train step, and that would just work.
[00:19:28.160 --> 00:19:29.520]   So that's another option.
[00:19:29.520 --> 00:19:37.400]   And a third option is like just trying to reimplement the Keras API from scratch in a
[00:19:37.400 --> 00:19:39.440]   very simple way on top of JAX.
[00:19:39.440 --> 00:19:41.200]   And that would be like a fresh start.
[00:19:41.200 --> 00:19:46.000]   It wouldn't really be fully compatible with the old Keras because the old Keras has all
[00:19:46.000 --> 00:19:47.800]   these features which are TensorFlow specific.
[00:19:47.800 --> 00:19:54.440]   And that would actually be relatively easy to do with the downside that it may lead to
[00:19:54.440 --> 00:19:55.920]   fragmentation, right?
[00:19:55.920 --> 00:19:59.080]   Because then you start having two slightly different versions of the Keras API.
[00:19:59.080 --> 00:20:06.640]   And also the downside that, you know, Keras is really an object oriented framework and
[00:20:06.640 --> 00:20:07.600]   JAX is functional.
[00:20:07.600 --> 00:20:10.240]   And so this is like very different philosophy.
[00:20:10.240 --> 00:20:14.520]   So if you implement Keras on top of JAX, you still end up with an object oriented
[00:20:14.520 --> 00:20:15.560]   framework, right?
[00:20:15.560 --> 00:20:21.000]   You can lose, by design, you're going to lose the functional aspect.
[00:20:21.040 --> 00:20:25.400]   So and at that point, you know, you might as well be writing your layers using the
[00:20:25.400 --> 00:20:29.840]   TensorFlow NumPy API and it would look almost exactly the same and compile them to
[00:20:29.840 --> 00:20:30.440]   Excellent, right?
[00:20:30.440 --> 00:20:33.320]   Then it would look almost exactly the same as the JAX.
[00:20:33.320 --> 00:20:41.560]   So again, like this is a super interesting problem and I would really appreciate that
[00:20:41.560 --> 00:20:45.560]   community feedback on what do you want us to do?
[00:20:45.560 --> 00:20:47.600]   What would be your use case?
[00:20:47.720 --> 00:20:50.360]   Why would you want to use Keras on JAX?
[00:20:50.360 --> 00:20:53.400]   Because once we understand that, we can make better decisions.
[00:20:53.400 --> 00:20:54.680]   Thanks.
[00:20:54.680 --> 00:20:55.760]   Thanks for that answer.
[00:20:55.760 --> 00:21:00.040]   The next question is by Akash Nann, who is to me one of the Keras heroes.
[00:21:00.040 --> 00:21:02.000]   He's contributed a lot to the community.
[00:21:02.000 --> 00:21:06.800]   If you were to rewrite Keras today from scratch, what would you do?
[00:21:06.800 --> 00:21:09.280]   Right.
[00:21:09.280 --> 00:21:13.400]   I mean, this is something we've actually kind of looked at in practice in the context
[00:21:13.400 --> 00:21:14.000]   of JAX.
[00:21:14.720 --> 00:21:18.840]   And there are actually lots of things we can change or simplify.
[00:21:18.840 --> 00:21:25.600]   Things that we are kind of design choices that we are constrained by the original
[00:21:25.600 --> 00:21:29.080]   Theano and then TensorFlow backends.
[00:21:29.080 --> 00:21:29.400]   Right.
[00:21:29.400 --> 00:21:33.600]   And so that's like a pretty long list of them, actually.
[00:21:33.600 --> 00:21:39.960]   So you would end up with a code base that would be significantly smaller and simpler
[00:21:39.960 --> 00:21:42.080]   and that would be a good thing.
[00:21:42.080 --> 00:21:49.680]   But at the same time, if you were, for instance, to write it from scratch in JAX, you
[00:21:49.680 --> 00:21:53.800]   would not really end up with something fully compatible or something fully feature
[00:21:53.800 --> 00:21:54.320]   complete.
[00:21:54.320 --> 00:22:00.160]   And so a lot of the existing behaviors of Keras are actually there for backwards
[00:22:00.160 --> 00:22:01.040]   compatibility reasons.
[00:22:01.040 --> 00:22:04.280]   And that's a feature.
[00:22:04.280 --> 00:22:09.520]   Like I think Keras is very much this infrastructure layer that other people build on
[00:22:09.520 --> 00:22:13.760]   top of and stability is a super important property of an infrastructure layer.
[00:22:13.760 --> 00:22:17.600]   Like you don't want to make changes that end up simplifying the code base, but that
[00:22:17.600 --> 00:22:21.320]   also break existing code that's relying on your framework.
[00:22:21.320 --> 00:22:21.640]   Right.
[00:22:21.640 --> 00:22:24.760]   So that's something that happened, for instance, in the transition from TensorFlow 1,
[00:22:24.760 --> 00:22:25.400]   TensorFlow 2.
[00:22:25.400 --> 00:22:27.680]   And I disagree with that person.
[00:22:27.680 --> 00:22:29.400]   Like, I think that's bad.
[00:22:29.400 --> 00:22:32.960]   I think, you know, you should aim for as much stability as possible.
[00:22:32.960 --> 00:22:35.840]   And if you want to break things, that's OK.
[00:22:35.840 --> 00:22:39.800]   But you should do so in a very careful and incremental fashion.
[00:22:39.800 --> 00:22:40.160]   Right.
[00:22:40.160 --> 00:22:44.720]   You should not basically invalidate people's code bases out there because it's like
[00:22:44.720 --> 00:22:47.200]   millions of hours of engineering time.
[00:22:47.200 --> 00:22:48.720]   And that's precious.
[00:22:48.720 --> 00:22:48.960]   Right.
[00:22:48.960 --> 00:22:50.080]   You should take care of it.
[00:22:50.080 --> 00:22:51.880]   Thanks.
[00:22:51.880 --> 00:22:56.200]   I know we're almost out of time, but is it OK if I squeeze in another question?
[00:22:56.200 --> 00:22:57.720]   Yeah, absolutely.
[00:22:57.720 --> 00:23:01.440]   Any, so this is by Ido Ben.
[00:23:01.440 --> 00:23:03.160]   I'm sorry if I mispronounce your name.
[00:23:03.960 --> 00:23:09.720]   What are the most interesting theoretical directions in ML or DL research, according
[00:23:09.720 --> 00:23:11.280]   to you, in the horizon?
[00:23:11.280 --> 00:23:16.400]   So, I mean, there's a lot of really interesting stuff going on.
[00:23:16.400 --> 00:23:22.640]   So one topic I'm really passionate about is, in general, discrete reasoning and
[00:23:22.640 --> 00:23:26.120]   figuring out how to leverage.
[00:23:26.120 --> 00:23:28.920]   So deep learning models, you know, they're very much curves.
[00:23:28.920 --> 00:23:32.480]   So they're very good at doing things like, you know, intuition, perception,
[00:23:32.680 --> 00:23:35.920]   interpolation, type of information processing.
[00:23:35.920 --> 00:23:39.520]   And discrete reasoning is kind of like at the other end of the spectrum.
[00:23:39.520 --> 00:23:45.200]   But I think we can really kind of like bridge both worlds and create systems that
[00:23:45.200 --> 00:23:49.560]   we leverage the strength of each side, like the strength of deep learning models, the
[00:23:49.560 --> 00:23:55.240]   strength of a more discrete systems, like for instance, program synthesis algorithms,
[00:23:55.240 --> 00:23:59.960]   like how you can use deep learning to guide the program synthesis system, how you can
[00:23:59.960 --> 00:24:03.160]   use program synthesis to enhance deep learning architectures and so on.
[00:24:03.160 --> 00:24:06.400]   So that's an area I'm very passionate about.
[00:24:06.400 --> 00:24:07.840]   There are many other things.
[00:24:07.840 --> 00:24:15.680]   So another, you know, there's lots of things we can do in general to address the
[00:24:15.680 --> 00:24:19.680]   weaknesses of deep learning models, like for instance, deep learning is not really
[00:24:19.680 --> 00:24:23.120]   able to do out of distribution generalization, right?
[00:24:23.120 --> 00:24:29.600]   Well, that's also an area where there's lots of interesting markets that's
[00:24:29.600 --> 00:24:30.320]   currently going on.
[00:24:30.320 --> 00:24:36.200]   And this is actually something we can we can probably do without involving too much
[00:24:36.200 --> 00:24:39.880]   discretism. Just by staying in the deep learning framework.
[00:24:39.880 --> 00:24:46.360]   I think in your interview on MLST podcast, which is an awesome podcast, and also with
[00:24:46.360 --> 00:24:50.840]   the Lex Friedman podcast, you went into depth in these topics, I would encourage
[00:24:50.840 --> 00:24:52.040]   the audience to check those out.
[00:24:55.240 --> 00:24:58.280]   Awesome. We're almost actually we're over time.
[00:24:58.280 --> 00:25:02.320]   So I'll quickly mention to our audience, please connect with Fransjo on Twitter.
[00:25:02.320 --> 00:25:05.440]   He is FCHOLLED on Twitter.
[00:25:05.440 --> 00:25:10.600]   On there, you can find the link to his book that we'll be reading and also his
[00:25:10.600 --> 00:25:12.760]   website where you'll find all of his links.
[00:25:12.760 --> 00:25:17.680]   Fransjo, any final words to the audience that will be going through your book over
[00:25:17.680 --> 00:25:18.520]   the next few weeks?
[00:25:20.000 --> 00:25:22.720]   Yeah, I just want to say, you know, thank you.
[00:25:22.720 --> 00:25:26.080]   Thanks for having me on the on the call.
[00:25:26.080 --> 00:25:29.960]   It's it's it's been great answering questions from everyone.
[00:25:29.960 --> 00:25:32.320]   And yeah, and you know, please enjoy the book.
[00:25:32.320 --> 00:25:37.600]   Like it's not it's not just meant to be a book that gives you some some specific
[00:25:37.600 --> 00:25:39.040]   piece of specialized knowledge.
[00:25:39.040 --> 00:25:40.960]   It's also meant to be a fun read.
[00:25:40.960 --> 00:25:43.200]   So I hope it will be fun.
[00:25:43.200 --> 00:25:46.360]   Thank you so much. And thank you so much again for your time.
[00:25:46.360 --> 00:25:48.680]   It's an honor to kick off the reading series with you.
[00:25:49.720 --> 00:25:51.040]   My pleasure. Thank you.
[00:25:51.560 --> 00:25:52.560]   Thank you.
[00:25:52.560 --> 00:25:53.560]   Thank you.
[00:25:53.560 --> 00:25:54.560]   Thank you.
[00:25:54.560 --> 00:25:55.560]   Thank you.
[00:25:55.560 --> 00:25:56.560]   Thank you.
[00:25:56.560 --> 00:25:57.560]   Thank you.
[00:25:57.560 --> 00:25:58.560]   Thank you.
[00:25:58.560 --> 00:25:59.560]   Thank you.
[00:25:59.560 --> 00:26:00.560]   Thank you.
[00:26:00.560 --> 00:26:01.560]   Thank you.
[00:26:01.560 --> 00:26:02.560]   Thank you.
[00:26:02.560 --> 00:26:03.560]   Thank you.
[00:26:03.560 --> 00:26:04.560]   Thank you.
[00:26:04.560 --> 00:26:05.560]   Thank you.
[00:26:05.560 --> 00:26:06.560]   Thank you.
[00:26:06.560 --> 00:26:07.560]   Thank you.
[00:26:07.560 --> 00:26:08.560]   Thank you.
[00:26:08.560 --> 00:26:09.560]   Thank you.
[00:26:09.560 --> 00:26:10.560]   Thank you.
[00:26:10.560 --> 00:26:11.560]   Thank you.

