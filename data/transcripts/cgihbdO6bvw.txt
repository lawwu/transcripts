
[00:00:00.000 --> 00:00:08.280]   I would not blame you if you thought that all talk about GPT-4 or ChatGPT-4 is just that, talk.
[00:00:08.280 --> 00:00:17.820]   But we actually can have a surprising amount of confidence in the ways in which GPT-4 will improve on ChatGPT.
[00:00:17.820 --> 00:00:23.760]   By examining publicly accessible benchmarks, comparable large language models like Palm,
[00:00:23.760 --> 00:00:27.380]   and the latest research papers, which I've spent dozens of hours reading,
[00:00:27.600 --> 00:00:37.220]   we can discern at least eight clear ways in which GPT-4, integrated into Bing or otherwise, will beat ChatGPT.
[00:00:37.220 --> 00:00:41.820]   I'm going to show you how unreleased models already beat current ChatGPT.
[00:00:41.820 --> 00:00:51.960]   And all of this will give us a clearer insight into what even GPT-5 and future rival models from Google might well soon be able to achieve.
[00:00:51.960 --> 00:00:56.580]   There are numerous benchmarks that Palm, Google's large language model,
[00:00:56.580 --> 00:00:57.580]   and by extension, Google's large language model, will be able to achieve.
[00:00:57.580 --> 00:01:01.340]   And by extension, GPT-4 will beat ChatGPT on.
[00:01:01.340 --> 00:01:06.160]   But the largest and most impressive is the big bench set of tasks.
[00:01:06.160 --> 00:01:11.940]   More than 150 or now 200 language modeling tasks, and I've studied almost all of them.
[00:01:11.940 --> 00:01:17.000]   And you can see the approximate current state of affairs summarized in this graph,
[00:01:17.000 --> 00:01:23.640]   where the latest models are now beating the average human and showing dramatic improvement on previous models.
[00:01:23.640 --> 00:01:26.340]   ChatGPT would be somewhere around this point.
[00:01:26.340 --> 00:01:27.340]   Lower than what is actually...
[00:01:27.340 --> 00:01:31.180]   privately available, but better than previous models down here.
[00:01:31.180 --> 00:01:32.860]   But this just skims the surface.
[00:01:32.860 --> 00:01:41.900]   I want to show you in detail the eight ways that you can expect ChatGPT-4 or GPT-4 to beat the current ChatGPT.
[00:01:41.900 --> 00:01:46.580]   And no, that's not just because it's going to have more parameters off to the right of this graph,
[00:01:46.580 --> 00:01:48.780]   10 to the 12, a trillion parameters.
[00:01:48.780 --> 00:01:51.340]   It's also because compute efficiency will improve.
[00:01:51.340 --> 00:01:56.720]   Chain of thought prompting will be integrated, and the number of tokens it's trained on might go up by an awful lot.
[00:01:56.720 --> 00:01:58.720]   This is a very important aspect of ChatGPT-4.
[00:01:58.720 --> 00:02:02.720]   And it's also very important to know that the output of your data will go up by an order of magnitude.
[00:02:02.720 --> 00:02:04.720]   Lots of reasons why GPT-4 will be better.
[00:02:04.720 --> 00:02:06.720]   Let's start with logic and logical inference.
[00:02:06.720 --> 00:02:08.720]   This example comes from Google's Palm Research paper.
[00:02:08.720 --> 00:02:10.720]   The question or input was this.
[00:02:10.720 --> 00:02:14.720]   Shelley is from Virginia, but is visiting that city with that famous market where they throw the fish.
[00:02:14.720 --> 00:02:16.720]   So vague.
[00:02:16.720 --> 00:02:18.720]   Going home next Tuesday.
[00:02:18.720 --> 00:02:20.720]   Question, is it likely that Shelley will be near the Pacific Ocean this weekend?
[00:02:20.720 --> 00:02:22.720]   And you can see how the improved model is able to deduce that the improved model is likely to be near the Pacific Ocean.
[00:02:22.720 --> 00:02:24.720]   And you can see how the improved model is able to deduce that the improved model is likely to be near the Pacific Ocean.
[00:02:24.720 --> 00:02:26.720]   And you can see how the improved model is able to deduce that the improved model is likely to be near the Pacific Ocean.
[00:02:26.720 --> 00:02:28.720]   And you can see how the improved model is able to deduce that the improved model is likely to be near the Pacific Ocean.
[00:02:28.720 --> 00:02:30.720]   And you can see how the improved model is likely to be near the Pacific Ocean.
[00:02:30.720 --> 00:02:32.720]   And you can see how the improved model is likely to be near the Pacific Ocean.
[00:02:32.720 --> 00:02:34.720]   Whereas if you ask current ChatGPT this question, what you get is, based on the information given, it's not possible to determine.
[00:02:34.720 --> 00:02:36.720]   Whereas if you ask current ChatGPT this question, what you get is, based on the information given, it's not possible to determine.
[00:02:36.720 --> 00:02:38.720]   Whereas if you ask current ChatGPT this question, what you get is, based on the information given, it's not possible to determine.
[00:02:38.720 --> 00:02:40.720]   The statement only mentions that Shelley is from Virginia and visiting a city with a famous market.
[00:02:40.720 --> 00:02:42.720]   The statement only mentions that Shelley is from Virginia and visiting a city with a famous market.
[00:02:42.720 --> 00:02:44.720]   The statement only mentions that Shelley is from Virginia and visiting a city with a famous market.
[00:02:44.720 --> 00:02:46.720]   It really can't handle it. It can't do that level of logical inference.
[00:02:46.720 --> 00:02:48.720]   It really can't handle it. It can't do that level of logical inference.
[00:02:48.720 --> 00:02:50.720]   Here is another great example.
[00:02:50.720 --> 00:02:52.720]   This test of critical reasoning and logic was designed again for the Big Bench benchmark.
[00:02:52.720 --> 00:02:54.720]   This test of critical reasoning and logic was designed again for the Big Bench benchmark.
[00:02:54.720 --> 00:02:56.720]   This test of critical reasoning and logic was designed again for the Big Bench benchmark.
[00:02:56.720 --> 00:02:58.720]   And it was tested on different language models.
[00:02:58.720 --> 00:03:00.720]   And most of them fail, including ChatGPT.
[00:03:00.720 --> 00:03:02.720]   And most of them fail, including ChatGPT.
[00:03:02.720 --> 00:03:04.720]   I gave it this question and it picked the wrong answer.
[00:03:04.720 --> 00:03:06.720]   I gave it this question and it picked the wrong answer.
[00:03:06.720 --> 00:03:08.720]   You can examine the question yourself, but C is not the correct answer.
[00:03:08.720 --> 00:03:10.720]   You can examine the question yourself, but C is not the correct answer.
[00:03:10.720 --> 00:03:12.720]   It gets it wrong.
[00:03:12.720 --> 00:03:14.720]   However, let's take a look at the graph beneath at other language models.
[00:03:14.720 --> 00:03:16.720]   However, let's take a look at the graph beneath at other language models.
[00:03:16.720 --> 00:03:18.720]   Ones to come. GPT-4 maybe.
[00:03:18.720 --> 00:03:20.720]   And look what happens.
[00:03:20.720 --> 00:03:22.720]   As the models increase in effective parameter count and other things like token size,
[00:03:22.720 --> 00:03:24.720]   As the models increase in effective parameter count and other things like token size,
[00:03:24.720 --> 00:03:26.720]   As the models increase in effective parameter count and other things like token size,
[00:03:26.720 --> 00:03:28.720]   look at the performance.
[00:03:28.720 --> 00:03:30.720]   We start to beat not only average raters but all previous models
[00:03:30.720 --> 00:03:32.720]   We start to beat not only average raters but all previous models
[00:03:32.720 --> 00:03:34.720]   and approximate the performance of the best human language.
[00:03:34.720 --> 00:03:36.720]   and approximate the performance of the best human language.
[00:03:36.720 --> 00:03:38.720]   and approximate the performance of the best human language.
[00:03:38.720 --> 00:03:40.720]   The top line is the best human rater.
[00:03:40.720 --> 00:03:42.720]   The blue line is the average human rater.
[00:03:42.720 --> 00:03:44.720]   These unreleased models,
[00:03:44.720 --> 00:03:46.720]   The three shot means it was given three examples of what was expected before being tested.
[00:03:46.720 --> 00:03:48.720]   The three shot means it was given three examples of what was expected before being tested.
[00:03:48.720 --> 00:03:50.720]   The three shot means it was given three examples of what was expected before being tested.
[00:03:50.720 --> 00:03:52.720]   These best models, and you can imagine GPT-4 would be around the same level,
[00:03:52.720 --> 00:03:54.720]   These best models, and you can imagine GPT-4 would be around the same level,
[00:03:54.720 --> 00:03:56.720]   crush what ChatGPT was capable of.
[00:03:56.720 --> 00:03:58.720]   crush what ChatGPT was capable of.
[00:03:58.720 --> 00:04:00.720]   You can imagine what this means in terms of GPT-4 giving more rigorous arguments.
[00:04:00.720 --> 00:04:02.720]   You can imagine what this means in terms of GPT-4 giving more rigorous arguments.
[00:04:02.720 --> 00:04:04.720]   You can imagine what this means in terms of GPT-4 giving more rigorous arguments.
[00:04:04.720 --> 00:04:06.720]   Or conversely, you can give vague inputs
[00:04:06.720 --> 00:04:08.720]   Or conversely, you can give vague inputs
[00:04:08.720 --> 00:04:10.720]   like this thing talking about a famous market where they throw the fish.
[00:04:10.720 --> 00:04:12.720]   like this thing talking about a famous market where they throw the fish.
[00:04:12.720 --> 00:04:14.720]   And GPT-4 might well be able to understand exactly what you mean.
[00:04:14.720 --> 00:04:16.720]   And GPT-4 might well be able to understand exactly what you mean.
[00:04:16.720 --> 00:04:18.720]   And to be honest, if you thought that's interesting,
[00:04:18.720 --> 00:04:20.720]   we are just getting started.
[00:04:20.720 --> 00:04:22.720]   Next, jokes.
[00:04:22.720 --> 00:04:24.720]   On the left you can see a computer science-y type of joke
[00:04:24.720 --> 00:04:26.720]   On the left you can see a computer science-y type of joke
[00:04:26.720 --> 00:04:28.720]   that it was able to explain.
[00:04:28.720 --> 00:04:30.720]   But I tested ChatGPT on a variety of jokes
[00:04:30.720 --> 00:04:32.720]   and some of them it could explain,
[00:04:32.720 --> 00:04:34.720]   others it couldn't.
[00:04:34.720 --> 00:04:36.720]   Let me show you what I mean.
[00:04:36.720 --> 00:04:38.720]   Here was the joke that I asked it to explain.
[00:04:38.720 --> 00:04:40.720]   One of the oddities of Wall Street is that it is the dealer
[00:04:40.720 --> 00:04:42.720]   and not the customer who is called "broker".
[00:04:42.720 --> 00:04:44.720]   The play on words being that the customer might well end up being "broke".
[00:04:44.720 --> 00:04:46.720]   The play on words being that the customer might well end up being "broke".
[00:04:46.720 --> 00:04:48.720]   It didn't really understand that wordplay
[00:04:48.720 --> 00:04:50.720]   and got it wrong.
[00:04:50.720 --> 00:04:52.720]   I don't think it got that "broke"
[00:04:52.720 --> 00:04:54.720]   was different from "broker".
[00:04:54.720 --> 00:04:56.720]   It couldn't separate off that word inside "broker".
[00:04:56.720 --> 00:04:58.720]   Now, it did get this second joke right
[00:04:58.720 --> 00:05:00.720]   and explain it well.
[00:05:00.720 --> 00:05:02.720]   This shows us why it's so important
[00:05:02.720 --> 00:05:04.720]   what GPT-4 might be capable of.
[00:05:04.720 --> 00:05:06.720]   As the Google paper showed,
[00:05:06.720 --> 00:05:08.720]   as the model improves,
[00:05:08.720 --> 00:05:10.720]   it does get better at explaining jokes
[00:05:10.720 --> 00:05:12.720]   and therefore, presumably,
[00:05:12.720 --> 00:05:14.720]   at telling them.
[00:05:14.720 --> 00:05:16.720]   Those comedy sketches that people are
[00:05:16.720 --> 00:05:18.720]   generating now with ChatGPT,
[00:05:18.720 --> 00:05:20.720]   they are about to get many times better.
[00:05:20.720 --> 00:05:22.720]   Think wordplays,
[00:05:22.720 --> 00:05:24.720]   puns, innuendos,
[00:05:24.720 --> 00:05:26.720]   all sorts.
[00:05:26.720 --> 00:05:28.720]   The next example comes from physics.
[00:05:28.720 --> 00:05:30.720]   Look at how the latest models,
[00:05:30.720 --> 00:05:32.720]   and by implication GPT-4,
[00:05:32.720 --> 00:05:34.720]   are answering basic questions
[00:05:34.720 --> 00:05:36.720]   in physics and teaching them.
[00:05:36.720 --> 00:05:38.720]   You can see how palm far exceeds GPT.
[00:05:38.720 --> 00:05:40.720]   And also, as you can see,
[00:05:40.720 --> 00:05:42.720]   beats the average human
[00:05:42.720 --> 00:05:44.720]   and is getting closer
[00:05:44.720 --> 00:05:46.720]   to the best human.
[00:05:46.720 --> 00:05:48.720]   But what kind of questions
[00:05:48.720 --> 00:05:50.720]   are we talking about?
[00:05:50.720 --> 00:05:52.720]   I looked into the research methodology
[00:05:52.720 --> 00:05:54.720]   for this big benchmark
[00:05:54.720 --> 00:05:56.720]   and I took some of the questions
[00:05:56.720 --> 00:05:58.720]   and tested them on ChatGPT.
[00:05:58.720 --> 00:06:00.720]   It couldn't get them.
[00:06:00.720 --> 00:06:02.720]   I asked them and both of them
[00:06:02.720 --> 00:06:04.720]   got wrong.
[00:06:04.720 --> 00:06:06.720]   But that's what might change with GPT-4.
[00:06:06.720 --> 00:06:08.720]   We're talking high school and beyond
[00:06:08.720 --> 00:06:10.720]   physics, you can imagine
[00:06:10.720 --> 00:06:12.720]   chemistry, biology, starting to get
[00:06:12.720 --> 00:06:14.720]   questions more and more right
[00:06:14.720 --> 00:06:16.720]   and therefore be able to explain them
[00:06:16.720 --> 00:06:18.720]   better and better.
[00:06:18.720 --> 00:06:20.720]   Now I won't pause for a physics lesson
[00:06:20.720 --> 00:06:22.720]   but you can see how ChatGPT fails
[00:06:22.720 --> 00:06:24.720]   by pausing the video if you want.
[00:06:24.720 --> 00:06:26.720]   But GPT-4 probably won't fail.
[00:06:26.720 --> 00:06:28.720]   Next is math.
[00:06:28.720 --> 00:06:30.720]   Here are a bunch of examples
[00:06:30.720 --> 00:06:32.720]   that Google produced in the research paper
[00:06:32.720 --> 00:06:34.720]   about the improvements
[00:06:34.720 --> 00:06:36.720]   that its current model can do
[00:06:36.720 --> 00:06:38.720]   on release to the public but that something like
[00:06:38.720 --> 00:06:40.720]   GPT would really struggle at.
[00:06:40.720 --> 00:06:42.720]   And you don't need me to show you
[00:06:42.720 --> 00:06:44.720]   ChatGPT failing at these
[00:06:44.720 --> 00:06:46.720]   because it's quite notoriously bad at math.
[00:06:46.720 --> 00:06:48.720]   These are quite nuanced questions though.
[00:06:48.720 --> 00:06:50.720]   How many keystrokes are needed
[00:06:50.720 --> 00:06:52.720]   to type the numbers from 1 to 500?
[00:06:52.720 --> 00:06:54.720]   Yes, ChatGPT fails.
[00:06:54.720 --> 00:06:56.720]   What about a word problem?
[00:06:56.720 --> 00:06:58.720]   Roger has 5 tennis balls.
[00:06:58.720 --> 00:07:00.720]   He buys 2 more cans of tennis balls.
[00:07:00.720 --> 00:07:02.720]   Each can has 3 tennis balls.
[00:07:02.720 --> 00:07:04.720]   What kind of balls does he now have?
[00:07:04.720 --> 00:07:06.720]   This uses something called chain of thought prompting
[00:07:06.720 --> 00:07:08.720]   which I'll talk about a bit later
[00:07:08.720 --> 00:07:10.720]   but either way it gets the answer right
[00:07:10.720 --> 00:07:12.720]   whereas previous models get it wrong.
[00:07:12.720 --> 00:07:14.720]   You don't need me to help you imagine
[00:07:14.720 --> 00:07:16.720]   the kind of implications
[00:07:16.720 --> 00:07:18.720]   that a GPT better at math
[00:07:18.720 --> 00:07:20.720]   would be for the world.
[00:07:20.720 --> 00:07:22.720]   Just think about finance assistants
[00:07:22.720 --> 00:07:24.720]   or math tutors
[00:07:24.720 --> 00:07:26.720]   available in your pocket.
[00:07:26.720 --> 00:07:28.720]   Before we move on to improvement number 5
[00:07:28.720 --> 00:07:30.720]   please do leave a like
[00:07:30.720 --> 00:07:32.720]   and a comment if you're learning
[00:07:32.720 --> 00:07:34.720]   anything from this video.
[00:07:34.720 --> 00:07:36.720]   I really did put dozens of hours
[00:07:36.720 --> 00:07:38.720]   into reading academic papers
[00:07:38.720 --> 00:07:40.720]   to give you really clear examples
[00:07:40.720 --> 00:07:42.720]   of each improvement.
[00:07:42.720 --> 00:07:44.720]   For the 5th improvement
[00:07:44.720 --> 00:07:46.720]   I'm going to merge 2 benchmarks together.
[00:07:46.720 --> 00:07:48.720]   The first one is called implicatures
[00:07:48.720 --> 00:07:50.720]   quite hard to pronounce.
[00:07:50.720 --> 00:07:52.720]   It's one of those situations
[00:07:52.720 --> 00:07:54.720]   where people reply yes
[00:07:54.720 --> 00:07:56.720]   but don't use the word yes
[00:07:56.720 --> 00:07:58.720]   they say something like
[00:07:58.720 --> 00:08:00.720]   "Is the Pope a Catholic?"
[00:08:00.720 --> 00:08:02.720]   or "Is rain wet?"
[00:08:02.720 --> 00:08:04.720]   and the large language models
[00:08:04.720 --> 00:08:06.720]   struggle to interpret that as a yes.
[00:08:06.720 --> 00:08:08.720]   To give you an example
[00:08:08.720 --> 00:08:10.720]   look down here at my final interaction
[00:08:10.720 --> 00:08:12.720]   "Are the androids deployed?"
[00:08:12.720 --> 00:08:14.720]   Speaker 1 says.
[00:08:14.720 --> 00:08:16.720]   Speaker 2 "What do you think?"
[00:08:16.720 --> 00:08:18.720]   which most humans would interpret as
[00:08:18.720 --> 00:08:20.720]   "Yes of course, why are you asking?"
[00:08:20.720 --> 00:08:22.720]   and yet when I ask
[00:08:22.720 --> 00:08:24.720]   "Has speaker 2 likely confirmed
[00:08:24.720 --> 00:08:26.720]   or likely denied the deployment
[00:08:26.720 --> 00:08:28.720]   of androids or can we not tell?"
[00:08:28.720 --> 00:08:30.720]   ChatGPT says it's not clear
[00:08:30.720 --> 00:08:32.720]   where to most humans
[00:08:32.720 --> 00:08:34.720]   would be clear.
[00:08:34.720 --> 00:08:36.720]   However, as you might have guessed
[00:08:36.720 --> 00:08:38.720]   look at the improvements being made
[00:08:38.720 --> 00:08:40.720]   behind the scenes.
[00:08:40.720 --> 00:08:42.720]   As the parameter count goes up
[00:08:42.720 --> 00:08:44.720]   the number of tokens go up
[00:08:44.720 --> 00:08:46.720]   look at the graph.
[00:08:46.720 --> 00:08:48.720]   Suddenly, Palm can actually understand
[00:08:48.720 --> 00:08:50.720]   better than the average human
[00:08:50.720 --> 00:08:52.720]   whether a yes or no is being said
[00:08:52.720 --> 00:08:54.720]   approaching the performance
[00:08:54.720 --> 00:08:56.720]   of the best human.
[00:08:56.720 --> 00:08:58.720]   Leaving the original ChatGPT behind
[00:08:58.720 --> 00:09:00.720]   and showcasing how GPT-4
[00:09:00.720 --> 00:09:02.720]   might be a massive improvement
[00:09:02.720 --> 00:09:04.720]   in the future.
[00:09:04.720 --> 00:09:06.720]   The next question I wanted to ask
[00:09:06.720 --> 00:09:08.720]   was about
[00:09:08.720 --> 00:09:10.720]   "Do we have sufficient information?"
[00:09:10.720 --> 00:09:12.720]   In other words, how about we just say
[00:09:12.720 --> 00:09:14.720]   "Don't know" if we don't know the answer
[00:09:14.720 --> 00:09:16.720]   or if you can't answer the question.
[00:09:16.720 --> 00:09:18.720]   Something like
[00:09:18.720 --> 00:09:20.720]   "How much water is in a cup
[00:09:20.720 --> 00:09:22.720]   with height of 10cm?"
[00:09:22.720 --> 00:09:24.720]   You can't answer that question.
[00:09:24.720 --> 00:09:26.720]   It depends on many factors
[00:09:26.720 --> 00:09:28.720]   the thickness, the radius
[00:09:28.720 --> 00:09:30.720]   and some models would hallucinate
[00:09:30.720 --> 00:09:32.720]   or let's say bullcrap their way
[00:09:32.720 --> 00:09:34.720]   into the chat.
[00:09:34.720 --> 00:09:36.720]   The sixth improvement
[00:09:36.720 --> 00:09:38.720]   will be in reading comprehension.
[00:09:38.720 --> 00:09:40.720]   That is understanding
[00:09:40.720 --> 00:09:42.720]   digesting, analyzing
[00:09:42.720 --> 00:09:44.720]   comprehending essentially
[00:09:44.720 --> 00:09:46.720]   large or long passages
[00:09:46.720 --> 00:09:48.720]   of text.
[00:09:48.720 --> 00:09:50.720]   You can just imagine the implications
[00:09:50.720 --> 00:09:52.720]   of this.
[00:09:52.720 --> 00:09:54.720]   Summarizing earning calls
[00:09:54.720 --> 00:09:56.720]   or transcribing and summarizing YouTube videos
[00:09:56.720 --> 00:09:58.720]   automatically.
[00:09:58.720 --> 00:10:00.720]   Condensing information down to a paragraph
[00:10:00.720 --> 00:10:02.720]   which might have been pages and pages
[00:10:02.720 --> 00:10:04.720]   of chapters.
[00:10:04.720 --> 00:10:06.720]   I think this graph is particularly stunning.
[00:10:06.720 --> 00:10:08.720]   How the latest models
[00:10:08.720 --> 00:10:10.720]   are now getting close to the
[00:10:10.720 --> 00:10:12.720]   performance of the best humans
[00:10:12.720 --> 00:10:14.720]   at understanding text.
[00:10:14.720 --> 00:10:16.720]   How long will it be until they can read
[00:10:16.720 --> 00:10:18.720]   Dostoevsky and summarize it
[00:10:18.720 --> 00:10:20.720]   in a thought out paragraph?
[00:10:20.720 --> 00:10:22.720]   ChatGPT definitely can't do this.
[00:10:22.720 --> 00:10:24.720]   Give it a reading comprehension
[00:10:24.720 --> 00:10:26.720]   question and it gets it wrong
[00:10:26.720 --> 00:10:28.720]   almost every time.
[00:10:28.720 --> 00:10:30.720]   In fact, quite hilariously
[00:10:30.720 --> 00:10:32.720]   when I gave it one question
[00:10:32.720 --> 00:10:34.720]   it picked the wrong answer
[00:10:34.720 --> 00:10:36.720]   and neglected both correct answers.
[00:10:36.720 --> 00:10:38.720]   But, GPT-4 with 99.9%
[00:10:38.720 --> 00:10:40.720]   certainty
[00:10:40.720 --> 00:10:42.720]   will be a lot better at doing that.
[00:10:42.720 --> 00:10:44.720]   The next big improvement will be
[00:10:44.720 --> 00:10:46.720]   in coding.
[00:10:46.720 --> 00:10:48.720]   I'm no expert but reading through
[00:10:48.720 --> 00:10:50.720]   the paper you can see
[00:10:50.720 --> 00:10:52.720]   significant improvements in capability.
[00:10:52.720 --> 00:10:54.720]   If we scroll down
[00:10:54.720 --> 00:10:56.720]   you can see that the improved
[00:10:56.720 --> 00:10:58.720]   model could compile at a rate
[00:10:58.720 --> 00:11:00.720]   of 82% versus
[00:11:00.720 --> 00:11:02.720]   the previous state of the art
[00:11:02.720 --> 00:11:04.720]   of 81.7%.
[00:11:04.720 --> 00:11:06.720]   And GPT-4 might be even
[00:11:06.720 --> 00:11:08.720]   an improvement on this.
[00:11:08.720 --> 00:11:10.720]   Of course, many of you may have
[00:11:10.720 --> 00:11:12.720]   read media reports
[00:11:12.720 --> 00:11:14.720]   of OpenAI drafting in
[00:11:14.720 --> 00:11:16.720]   hundreds of programmers
[00:11:16.720 --> 00:11:18.720]   to help it fine tune its code.
[00:11:18.720 --> 00:11:20.720]   Definitely there should be
[00:11:20.720 --> 00:11:22.720]   a real step change in its
[00:11:22.720 --> 00:11:24.720]   ability to code successfully.
[00:11:24.720 --> 00:11:26.720]   And as it says down here,
[00:11:26.720 --> 00:11:28.720]   opening up opportunities to fix more
[00:11:28.720 --> 00:11:30.720]   complex errors that arise during
[00:11:30.720 --> 00:11:32.720]   software development.
[00:11:32.720 --> 00:11:34.720]   The next big
[00:11:34.720 --> 00:11:36.720]   inevitable improvement that GPT-4
[00:11:36.720 --> 00:11:38.720]   will bring will just be general efficiency
[00:11:38.720 --> 00:11:40.720]   and speed.
[00:11:40.720 --> 00:11:42.720]   Google Muse has demonstrated
[00:11:42.720 --> 00:11:44.720]   with text to image that the same process
[00:11:44.720 --> 00:11:46.720]   can be done 10 times faster
[00:11:46.720 --> 00:11:48.720]   with a bit more efficiency.
[00:11:48.720 --> 00:11:50.720]   And compute power is increasing
[00:11:50.720 --> 00:11:52.720]   all the time.
[00:11:52.720 --> 00:11:54.720]   These models were trained on A100 GPUs
[00:11:54.720 --> 00:11:56.720]   but H100 GPUs
[00:11:56.720 --> 00:11:58.720]   are already available from
[00:11:58.720 --> 00:12:00.720]   Nvidia.
[00:12:00.720 --> 00:12:02.720]   And model efficiency is improving
[00:12:02.720 --> 00:12:04.720]   over time.
[00:12:04.720 --> 00:12:06.720]   So just imagine this.
[00:12:06.720 --> 00:12:08.720]   Imagine what previously took 10 seconds
[00:12:08.720 --> 00:12:10.720]   to generate, which is still incredibly fast,
[00:12:10.720 --> 00:12:12.720]   now taking 1 second.
[00:12:12.720 --> 00:12:14.720]   Instant responses from GPT-4.
[00:12:14.720 --> 00:12:16.720]   Now it might not be 1 second,
[00:12:16.720 --> 00:12:18.720]   it might be 3 or 4,
[00:12:18.720 --> 00:12:20.720]   but it's going to be faster.
[00:12:20.720 --> 00:12:22.720]   And one iteration down the road,
[00:12:22.720 --> 00:12:24.720]   GPT-5, might be instantaneous.
[00:12:24.720 --> 00:12:26.720]   I have detailed
[00:12:26.720 --> 00:12:28.720]   quite a few areas where
[00:12:28.720 --> 00:12:30.720]   GPT-4 is very likely
[00:12:30.720 --> 00:12:32.720]   to improve on ChatGPT.
[00:12:32.720 --> 00:12:34.720]   But there are quite a few areas
[00:12:34.720 --> 00:12:36.720]   in which it will very likely
[00:12:36.720 --> 00:12:38.720]   still struggle.
[00:12:38.720 --> 00:12:40.720]   One is advanced math.
[00:12:40.720 --> 00:12:42.720]   Mathematical induction.
[00:12:42.720 --> 00:12:44.720]   Even the latest models really struggle.
[00:12:44.720 --> 00:12:46.720]   This area called
[00:12:46.720 --> 00:12:48.720]   navigation is an example
[00:12:48.720 --> 00:12:50.720]   where it will say something like
[00:12:50.720 --> 00:12:52.720]   if you move forward 3 steps, turn right
[00:12:52.720 --> 00:12:54.720]   go 3 steps, turn right again
[00:12:54.720 --> 00:12:56.720]   90 degrees, go 3 steps.
[00:12:56.720 --> 00:12:58.720]   That kind of thing. Do you arrive back at the start?
[00:12:58.720 --> 00:13:00.720]   These models really struggle with that.
[00:13:00.720 --> 00:13:02.720]   But the final area
[00:13:02.720 --> 00:13:04.720]   that I find quite amusing
[00:13:04.720 --> 00:13:06.720]   and it comes from
[00:13:06.720 --> 00:13:08.720]   Winograd schema.
[00:13:08.720 --> 00:13:10.720]   As detailed in this other academic paper
[00:13:10.720 --> 00:13:12.720]   called Superglue.
[00:13:12.720 --> 00:13:14.720]   Which is kind of a rival benchmark
[00:13:14.720 --> 00:13:16.720]   to the Big Bench.
[00:13:16.720 --> 00:13:18.720]   And a Winograd schema
[00:13:18.720 --> 00:13:20.720]   is a situation in which
[00:13:20.720 --> 00:13:22.720]   we have an ambiguous pronoun
[00:13:22.720 --> 00:13:24.720]   like he, it or they.
[00:13:24.720 --> 00:13:26.720]   And the model has to
[00:13:26.720 --> 00:13:28.720]   predict not only
[00:13:28.720 --> 00:13:30.720]   who or what the pronoun is referring to
[00:13:30.720 --> 00:13:32.720]   but also why
[00:13:32.720 --> 00:13:34.720]   would it be that thing.
[00:13:34.720 --> 00:13:36.720]   And it really struggles these models
[00:13:36.720 --> 00:13:38.720]   and I'll show you the graph in a second.
[00:13:38.720 --> 00:13:40.720]   In fact here it is.
[00:13:40.720 --> 00:13:42.720]   Even the latest models struggle
[00:13:42.720 --> 00:13:44.720]   I think because it involves some
[00:13:44.720 --> 00:13:46.720]   common sense about the world
[00:13:46.720 --> 00:13:48.720]   and the universe that it just doesn't have.
[00:13:48.720 --> 00:13:50.720]   Let me show you ChatGPT
[00:13:50.720 --> 00:13:52.720]   failing at this task.
[00:13:52.720 --> 00:13:54.720]   Feel free to try this one yourself.
[00:13:54.720 --> 00:13:56.720]   Tom threw his school bag down
[00:13:56.720 --> 00:13:58.720]   to Ray after he reached
[00:13:58.720 --> 00:14:00.720]   the bottom of the stairs.
[00:14:00.720 --> 00:14:02.720]   Who reached the bottom of the stairs?
[00:14:02.720 --> 00:14:04.720]   Now it makes sense
[00:14:04.720 --> 00:14:06.720]   that it would be Ray.
[00:14:06.720 --> 00:14:08.720]   Because logically you can think of real life
[00:14:08.720 --> 00:14:10.720]   you're throwing it down the stairs like
[00:14:10.720 --> 00:14:12.720]   here take it before you go out.
[00:14:12.720 --> 00:14:14.720]   Whereas the model says Tom
[00:14:14.720 --> 00:14:16.720]   reached the bottom of the stairs.
[00:14:16.720 --> 00:14:18.720]   Wait why would he be throwing his school bag
[00:14:18.720 --> 00:14:20.720]   down if he's at the bottom of the stairs?
[00:14:20.720 --> 00:14:22.720]   So that's an example
[00:14:22.720 --> 00:14:24.720]   of an area in which
[00:14:24.720 --> 00:14:26.720]   ChatGPT fails and
[00:14:26.720 --> 00:14:28.720]   GPT-4 will also likely
[00:14:28.720 --> 00:14:30.720]   fail. And the why bit in the title
[00:14:30.720 --> 00:14:32.720]   is the fact
[00:14:32.720 --> 00:14:34.720]   that it will not only fail
[00:14:34.720 --> 00:14:36.720]   but not really be able to explain
[00:14:36.720 --> 00:14:38.720]   even when it succeeds
[00:14:38.720 --> 00:14:40.720]   why the pronoun is
[00:14:40.720 --> 00:14:42.720]   referring to the noun that it does.
[00:14:42.720 --> 00:14:44.720]   I find that really interesting
[00:14:44.720 --> 00:14:46.720]   like the merging of language
[00:14:46.720 --> 00:14:48.720]   and common sense.
[00:14:48.720 --> 00:14:50.720]   These large language models fundamentally
[00:14:50.720 --> 00:14:52.720]   don't have a
[00:14:52.720 --> 00:14:54.720]   model of the universe as I talked
[00:14:54.720 --> 00:14:56.720]   about in one of my other
[00:14:56.720 --> 00:14:58.720]   videos. It's the main critique
[00:14:58.720 --> 00:15:00.720]   that Jan LeCun has actually
[00:15:00.720 --> 00:15:02.720]   about large language models.
[00:15:02.720 --> 00:15:04.720]   This graph by the way gives a
[00:15:04.720 --> 00:15:06.720]   beautiful summary of
[00:15:06.720 --> 00:15:08.720]   what I think is the approximate
[00:15:08.720 --> 00:15:10.720]   current state of the art. So GPT-4
[00:15:10.720 --> 00:15:12.720]   comparable to palm and how
[00:15:12.720 --> 00:15:14.720]   it does versus the average
[00:15:14.720 --> 00:15:16.720]   human. On the left
[00:15:16.720 --> 00:15:18.720]   all the different tasks
[00:15:18.720 --> 00:15:20.720]   part of the 150 big bench tasks
[00:15:20.720 --> 00:15:22.720]   that it can do better than humans
[00:15:22.720 --> 00:15:24.720]   and on the right those that it does
[00:15:24.720 --> 00:15:26.720]   worse than humans. So you can see
[00:15:26.720 --> 00:15:28.720]   a roughly even split but
[00:15:28.720 --> 00:15:30.720]   remember this is versus the average human
[00:15:30.720 --> 00:15:32.720]   not versus the best human.
[00:15:32.720 --> 00:15:34.720]   The link to all of these papers will be
[00:15:34.720 --> 00:15:36.720]   in the description if you want to check out
[00:15:36.720 --> 00:15:38.720]   the full list of tasks that it
[00:15:38.720 --> 00:15:40.720]   does better versus what it does
[00:15:40.720 --> 00:15:42.720]   worse at. I've actually scrolled through
[00:15:42.720 --> 00:15:44.720]   almost every single one of them
[00:15:44.720 --> 00:15:46.720]   and analyzed it. It's really interesting
[00:15:46.720 --> 00:15:48.720]   to do actually. All these different
[00:15:48.720 --> 00:15:50.720]   challenges that independent
[00:15:50.720 --> 00:15:52.720]   humans have come up with
[00:15:52.720 --> 00:15:54.720]   in order to test
[00:15:54.720 --> 00:15:56.720]   just how far language models
[00:15:56.720 --> 00:15:58.720]   are progressing. A very
[00:15:58.720 --> 00:16:00.720]   interesting endeavor that they're
[00:16:00.720 --> 00:16:02.720]   putting together. All the way from
[00:16:02.720 --> 00:16:04.720]   verbs to Python.
[00:16:04.720 --> 00:16:06.720]   As I draw to the end here I want
[00:16:06.720 --> 00:16:08.720]   to give you my two main
[00:16:08.720 --> 00:16:10.720]   conclusions. I think
[00:16:10.720 --> 00:16:12.720]   GPT-4 for commercial
[00:16:12.720 --> 00:16:14.720]   reasons and others
[00:16:14.720 --> 00:16:16.720]   will be yes a huge
[00:16:16.720 --> 00:16:18.720]   step up from ChatGPT
[00:16:18.720 --> 00:16:20.720]   but won't be game breaking.
[00:16:20.720 --> 00:16:22.720]   What I mean by that is we're
[00:16:22.720 --> 00:16:24.720]   talking better than the average human
[00:16:24.720 --> 00:16:26.720]   at quite a few tasks
[00:16:26.720 --> 00:16:28.720]   maybe half of those measured but still
[00:16:28.720 --> 00:16:30.720]   lagging behind the best human in
[00:16:30.720 --> 00:16:32.720]   almost every task. Roughly
[00:16:32.720 --> 00:16:34.720]   high school levels of
[00:16:34.720 --> 00:16:36.720]   achievement. So yes as I quoted
[00:16:36.720 --> 00:16:38.720]   Sam Altman saying in my
[00:16:38.720 --> 00:16:40.720]   previous video, Hype vs Reality
[00:16:40.720 --> 00:16:42.720]   ChatGPT-4. Yes it's
[00:16:42.720 --> 00:16:44.720]   going to be disappointing to those
[00:16:44.720 --> 00:16:46.720]   people expecting AGI.
[00:16:46.720 --> 00:16:48.720]   However
[00:16:48.720 --> 00:16:50.720]   what's coming down the road
[00:16:50.720 --> 00:16:52.720]   in the short to medium term
[00:16:52.720 --> 00:16:54.720]   it's hard to put an exact date
[00:16:54.720 --> 00:16:56.720]   but are we talking 2, 3, 4,
[00:16:56.720 --> 00:16:58.720]   5 years? Somewhere in that range.
[00:16:58.720 --> 00:17:00.720]   The models that are coming
[00:17:00.720 --> 00:17:02.720]   are going to be
[00:17:02.720 --> 00:17:04.720]   pretty impressive/
[00:17:04.720 --> 00:17:06.720]   overwhelming. That's not just
[00:17:06.720 --> 00:17:08.720]   by the way because the number of
[00:17:08.720 --> 00:17:10.720]   parameters are improving.
[00:17:10.720 --> 00:17:12.720]   As this abstract from DeepMind
[00:17:12.720 --> 00:17:14.720]   put it, it's not just
[00:17:14.720 --> 00:17:16.720]   about improving the
[00:17:16.720 --> 00:17:18.720]   number of parameters. It's
[00:17:18.720 --> 00:17:20.720]   also about using more data.
[00:17:20.720 --> 00:17:22.720]   4 times more data.
[00:17:22.720 --> 00:17:24.720]   Palm by the way
[00:17:24.720 --> 00:17:26.720]   used 780
[00:17:26.720 --> 00:17:28.720]   billion tokens.
[00:17:28.720 --> 00:17:30.720]   But there are up to
[00:17:30.720 --> 00:17:32.720]   17 trillion tokens
[00:17:32.720 --> 00:17:34.720]   available on the internet. So roughly
[00:17:34.720 --> 00:17:36.720]   in order of magnitude more
[00:17:36.720 --> 00:17:38.720]   tokens, more data that these
[00:17:38.720 --> 00:17:40.720]   models can train on. And the number of
[00:17:40.720 --> 00:17:42.720]   parameters if they're increased
[00:17:42.720 --> 00:17:44.720]   in alignment would also go up by
[00:17:44.720 --> 00:17:46.720]   an order of magnitude. Not just that
[00:17:46.720 --> 00:17:48.720]   but the compute available
[00:17:48.720 --> 00:17:50.720]   to big tech
[00:17:50.720 --> 00:17:52.720]   like Google and
[00:17:52.720 --> 00:17:54.720]   Microsoft is increasing all the
[00:17:54.720 --> 00:17:56.720]   time. I hinted at the
[00:17:56.720 --> 00:17:58.720]   H100 GPUs but even
[00:17:58.720 --> 00:18:00.720]   just scaling up in size
[00:18:00.720 --> 00:18:02.720]   and compute efficiency
[00:18:02.720 --> 00:18:04.720]   should yield incredible improvements.
[00:18:04.720 --> 00:18:06.720]   There is also a whole
[00:18:06.720 --> 00:18:08.720]   academic paper on how
[00:18:08.720 --> 00:18:10.720]   chain of thought prompting, basically
[00:18:10.720 --> 00:18:12.720]   getting the models to break
[00:18:12.720 --> 00:18:14.720]   down and show they're working out
[00:18:14.720 --> 00:18:16.720]   really improves results. And I've
[00:18:16.720 --> 00:18:18.720]   seen that myself with ChatGPT.
[00:18:18.720 --> 00:18:20.720]   If you ask it to explain its steps it often
[00:18:20.720 --> 00:18:22.720]   gets to a right answer whereas
[00:18:22.720 --> 00:18:24.720]   previously it got to a wrong answer. So it's not
[00:18:24.720 --> 00:18:26.720]   just about compute and parameters and
[00:18:26.720 --> 00:18:28.720]   data. It's also refinements
[00:18:28.720 --> 00:18:30.720]   to the models themselves. Of course other
[00:18:30.720 --> 00:18:32.720]   improvements around the corner
[00:18:32.720 --> 00:18:34.720]   are a diversity of data
[00:18:34.720 --> 00:18:36.720]   inputs. Could be video,
[00:18:36.720 --> 00:18:38.720]   could be photos, could be
[00:18:38.720 --> 00:18:40.720]   audio from the microphone
[00:18:40.720 --> 00:18:42.720]   and these can be assimilated
[00:18:42.720 --> 00:18:44.720]   into the model so you can ask questions
[00:18:44.720 --> 00:18:46.720]   like "Will these boots be
[00:18:46.720 --> 00:18:48.720]   usable to hike Mount Fuji?"
[00:18:48.720 --> 00:18:50.720]   And this is an example
[00:18:50.720 --> 00:18:52.720]   from Google. That might not necessarily
[00:18:52.720 --> 00:18:54.720]   be in GPT-4
[00:18:54.720 --> 00:18:56.720]   but it's coming and
[00:18:56.720 --> 00:18:58.720]   Google might be the one pioneering
[00:18:58.720 --> 00:19:00.720]   these diversity of data inputs.
[00:19:00.720 --> 00:19:02.720]   As the eerily powerful
[00:19:02.720 --> 00:19:04.720]   conclusion from
[00:19:04.720 --> 00:19:06.720]   this Google post put it,
[00:19:06.720 --> 00:19:08.720]   the vision that they have is
[00:19:08.720 --> 00:19:10.720]   to enable a single AI
[00:19:10.720 --> 00:19:12.720]   system to generalize
[00:19:12.720 --> 00:19:14.720]   across thousands or millions of tasks
[00:19:14.720 --> 00:19:16.720]   as we've seen to understand
[00:19:16.720 --> 00:19:18.720]   different types of data: photos,
[00:19:18.720 --> 00:19:20.720]   videos, audio, text
[00:19:20.720 --> 00:19:22.720]   and to do so with remarkable
[00:19:22.720 --> 00:19:24.720]   efficiency and speed.
[00:19:24.720 --> 00:19:26.720]   But this video wasn't designed
[00:19:26.720 --> 00:19:28.720]   to scare you. It was
[00:19:28.720 --> 00:19:30.720]   designed to show you the tangible
[00:19:30.720 --> 00:19:32.720]   ways in which GPT-4
[00:19:32.720 --> 00:19:34.720]   and rival models from
[00:19:34.720 --> 00:19:36.720]   Google will improve on ChatGPT
[00:19:36.720 --> 00:19:38.720]   so you can be prepared.
[00:19:38.720 --> 00:19:40.720]   I genuinely do believe that
[00:19:40.720 --> 00:19:42.720]   the knowledge economy is
[00:19:42.720 --> 00:19:44.720]   about to be upended
[00:19:44.720 --> 00:19:46.720]   and the better prepared we can be
[00:19:46.720 --> 00:19:48.720]   the better for all of us.
[00:19:48.720 --> 00:19:50.720]   And I really hope this video has
[00:19:50.720 --> 00:19:52.720]   contributed to that. If you feel it has
[00:19:52.720 --> 00:19:54.720]   please do leave a like, leave a
[00:19:54.720 --> 00:19:56.720]   comment. I read them all.
[00:19:56.720 --> 00:19:58.720]   Much appreciated. See you soon.

