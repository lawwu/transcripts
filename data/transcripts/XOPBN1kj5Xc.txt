
[00:00:00.000 --> 00:00:05.000]   Can we make learning as addictive as social media?
[00:00:05.000 --> 00:00:09.060]   Last week, I talked briefly on the show
[00:00:09.060 --> 00:00:13.200]   about a TED talk that has been going viral recently.
[00:00:13.200 --> 00:00:18.200]   It was done by Louis Von Ahn, the co-founder of Duolingo.
[00:00:18.200 --> 00:00:21.460]   Today, I wanna take a deeper look at this question.
[00:00:21.460 --> 00:00:24.380]   I wanna draw from the science of motivation and distraction
[00:00:24.380 --> 00:00:29.220]   to argue number one, Von Ahn's specific claims
[00:00:29.220 --> 00:00:33.100]   about making learning as addictive as social media
[00:00:33.100 --> 00:00:35.020]   are doomed to failure, but number two,
[00:00:35.020 --> 00:00:39.060]   if we look more closely at how the brain actually functions,
[00:00:39.060 --> 00:00:41.980]   we can find there is a lasting and effective way
[00:00:41.980 --> 00:00:44.800]   to make learning more appealing,
[00:00:44.800 --> 00:00:46.780]   and yes, even more appealing to social media.
[00:00:46.780 --> 00:00:50.940]   It's just gonna be different than the Duolingo approach.
[00:00:50.940 --> 00:00:52.660]   In the second argument, we are gonna see
[00:00:52.660 --> 00:00:54.980]   a more general playbook for cultivating
[00:00:54.980 --> 00:00:57.200]   a deeper life in general.
[00:00:58.500 --> 00:00:59.620]   All right, so let's jump into this.
[00:00:59.620 --> 00:01:01.180]   I wanna start with the video.
[00:01:01.180 --> 00:01:02.940]   I'll put it up here on the screen.
[00:01:02.940 --> 00:01:04.060]   For those who are watching,
[00:01:04.060 --> 00:01:09.060]   you can see this is Louis Von Ahn giving his talk.
[00:01:09.060 --> 00:01:11.920]   I wrote down here the main points from his talk
[00:01:11.920 --> 00:01:15.260]   so that we can be on the same page here.
[00:01:15.260 --> 00:01:17.260]   So what does he argue in this?
[00:01:17.260 --> 00:01:19.140]   Well, he argues that Duolingo wants to give
[00:01:19.140 --> 00:01:22.540]   equal access to education for everyone.
[00:01:22.540 --> 00:01:26.380]   This is why they're moving language learning
[00:01:26.380 --> 00:01:27.980]   onto mobile phones.
[00:01:27.980 --> 00:01:30.220]   They use a freemium model.
[00:01:30.220 --> 00:01:32.460]   Some people pay for it, or you can watch the ads.
[00:01:32.460 --> 00:01:34.280]   The people paying for it help subsidize
[00:01:34.280 --> 00:01:35.680]   the people who can't afford to pay to it
[00:01:35.680 --> 00:01:37.300]   so you get more people to see it.
[00:01:37.300 --> 00:01:38.700]   To make learning more engaging,
[00:01:38.700 --> 00:01:41.420]   Duolingo uses techniques like streaks,
[00:01:41.420 --> 00:01:44.180]   notifications, and a fun mascot
[00:01:44.180 --> 00:01:47.700]   that game and social media apps use to hook users
[00:01:47.700 --> 00:01:49.860]   to make the learning more addictive.
[00:01:49.860 --> 00:01:52.700]   They're showing you can use addictive techniques for good.
[00:01:52.700 --> 00:01:54.980]   Millions use the apps to learn languages
[00:01:54.980 --> 00:01:58.320]   more than in all US high schools combined.
[00:01:58.320 --> 00:02:00.980]   Von Ahn hopes that these techniques can be applied
[00:02:00.980 --> 00:02:05.980]   to teaching other subjects like math on phones.
[00:02:05.980 --> 00:02:08.740]   So we can even take a closer look.
[00:02:08.740 --> 00:02:10.940]   I'm gonna switch to another video here
[00:02:10.940 --> 00:02:15.660]   that will just show us some actual app usage
[00:02:15.660 --> 00:02:18.500]   of Duolingo in progress.
[00:02:18.500 --> 00:02:20.660]   So I have it up here on the screen now.
[00:02:20.660 --> 00:02:22.340]   You can see, if you're watching this
[00:02:22.340 --> 00:02:24.060]   as opposed to just listening, I'll narrate it to you.
[00:02:24.060 --> 00:02:25.860]   I'll narrate if you're just listening,
[00:02:25.860 --> 00:02:29.900]   you'll see you're selecting avatars,
[00:02:29.900 --> 00:02:33.180]   you're clicking on things, questions are coming up,
[00:02:33.180 --> 00:02:37.500]   quick, bright graphics so you can see what's happening.
[00:02:37.500 --> 00:02:39.960]   There's an avatar that looks nice.
[00:02:39.960 --> 00:02:42.180]   There's an owl that looks really fun.
[00:02:42.180 --> 00:02:45.260]   Things are moving around, questions are coming up.
[00:02:45.260 --> 00:02:47.900]   So it does really look like a really sort of
[00:02:47.900 --> 00:02:51.300]   friendly, colorful app.
[00:02:51.300 --> 00:02:53.060]   And so it's supposed to have this addictive feel
[00:02:53.060 --> 00:02:54.940]   so that when you feel that urge
[00:02:54.940 --> 00:02:57.080]   to pull your phone out of your pocket
[00:02:57.080 --> 00:02:58.700]   instead of going to TikTok,
[00:02:58.700 --> 00:03:00.180]   so what we're gonna do Duolingo.
[00:03:00.180 --> 00:03:01.340]   There's an owl with glasses.
[00:03:01.340 --> 00:03:03.300]   We're gonna have fun with this, let's go.
[00:03:03.300 --> 00:03:04.720]   All right, so let me start by saying a couple things
[00:03:04.720 --> 00:03:06.020]   I like about Duolingo.
[00:03:06.020 --> 00:03:08.300]   I wanna give credit where credit is due.
[00:03:08.300 --> 00:03:10.100]   Using applications on the internet
[00:03:10.100 --> 00:03:12.380]   to make information more accessible,
[00:03:12.380 --> 00:03:15.440]   especially information you can use to better yourself
[00:03:15.440 --> 00:03:19.140]   in terms of learning is a really good idea.
[00:03:19.140 --> 00:03:20.100]   I think it was a really good idea
[00:03:20.100 --> 00:03:22.620]   when Khan Academy did this, for example,
[00:03:22.620 --> 00:03:26.060]   having a very easy to grok visual format
[00:03:26.060 --> 00:03:27.140]   for teaching mathematics
[00:03:27.140 --> 00:03:29.900]   and then making those mathematic lessons widely available.
[00:03:29.900 --> 00:03:31.020]   That did a lot of good.
[00:03:31.020 --> 00:03:35.900]   That is the internet being used towards its full potential.
[00:03:35.900 --> 00:03:38.460]   We're gonna see similar leaps in the ability
[00:03:38.460 --> 00:03:41.240]   for people to teach themselves material
[00:03:41.240 --> 00:03:42.220]   delivered through the internet.
[00:03:42.220 --> 00:03:44.140]   Similar leaps are about to happen
[00:03:44.140 --> 00:03:47.240]   due to the integration of large language models
[00:03:47.240 --> 00:03:48.860]   like ChatGPT in learning.
[00:03:48.860 --> 00:03:52.260]   They're actually very good at this.
[00:03:52.260 --> 00:03:55.580]   ChatGPT and related language model-based chat tools
[00:03:55.580 --> 00:03:56.420]   are really good.
[00:03:56.420 --> 00:03:58.500]   You can go back and forth and ask it questions,
[00:03:58.500 --> 00:04:00.440]   for example, about a mathematics technique.
[00:04:00.440 --> 00:04:01.740]   Well, can you give me an example of this?
[00:04:01.740 --> 00:04:03.020]   Why did you do this here?
[00:04:03.020 --> 00:04:04.740]   We are gonna see big changes happening
[00:04:04.740 --> 00:04:07.100]   in terms of tutoring and education with those tools as well.
[00:04:07.100 --> 00:04:08.660]   This is all great.
[00:04:08.660 --> 00:04:11.780]   The internet bringing more information to more people.
[00:04:11.780 --> 00:04:16.660]   But what about this idea that we can make a learning app
[00:04:16.660 --> 00:04:18.900]   as addictive as social media
[00:04:18.900 --> 00:04:21.380]   so that people will pull out this app
[00:04:21.380 --> 00:04:23.060]   instead of something else and over time
[00:04:23.060 --> 00:04:25.780]   will essentially addict people to learning
[00:04:25.780 --> 00:04:29.740]   and increase the level of learning in the world?
[00:04:29.740 --> 00:04:32.180]   Well, here is where I think we need to get
[00:04:32.180 --> 00:04:35.460]   a little bit more wary.
[00:04:35.460 --> 00:04:37.400]   And to understand my wariness here,
[00:04:37.400 --> 00:04:39.380]   we actually are gonna have to look a little bit deeper
[00:04:39.380 --> 00:04:41.840]   about how the brain gets motivated to do things.
[00:04:41.840 --> 00:04:44.620]   There are two separate types of motivational systems
[00:04:44.620 --> 00:04:47.540]   that are relevant to this discussion.
[00:04:47.540 --> 00:04:50.340]   If we're gonna understand the problem with Vaughn On Strategy
[00:04:50.340 --> 00:04:51.740]   and if we're gonna understand an alternative
[00:04:51.740 --> 00:04:52.860]   that might work better,
[00:04:52.860 --> 00:04:55.580]   we have to understand these systems.
[00:04:55.580 --> 00:04:57.460]   And so to help us understand the first system,
[00:04:57.460 --> 00:05:00.100]   I'm bringing an article up here on my screen.
[00:05:00.100 --> 00:05:02.460]   The title is "Dopamine Smartphones and You,
[00:05:02.460 --> 00:05:03.940]   A Battle for Your Time."
[00:05:03.940 --> 00:05:07.380]   This is written by Trevor Haynes.
[00:05:07.380 --> 00:05:08.660]   And what I like about this article
[00:05:08.660 --> 00:05:12.500]   is that it does a good job of explaining the dopamine system
[00:05:12.500 --> 00:05:15.740]   which is gonna be the relevant system
[00:05:15.740 --> 00:05:19.100]   when we think about the urge to pull out a phone
[00:05:19.100 --> 00:05:20.460]   and do something on the phone.
[00:05:20.460 --> 00:05:22.100]   So when we think about addictiveness,
[00:05:22.100 --> 00:05:24.540]   quote unquote, surrounding apps,
[00:05:24.540 --> 00:05:27.180]   this is the system that's at play.
[00:05:27.180 --> 00:05:29.020]   I'm gonna read a couple of quotes from this article
[00:05:29.020 --> 00:05:31.220]   that'll be relevant for our purpose here.
[00:05:31.220 --> 00:05:34.620]   Here's the first quote that I wanna read.
[00:05:34.620 --> 00:05:38.220]   Dopamine is a chemical produced by our brains
[00:05:38.220 --> 00:05:41.260]   that plays a starring role in motivating behavior.
[00:05:41.260 --> 00:05:43.740]   It gets released when we take a bite of delicious food,
[00:05:43.740 --> 00:05:45.980]   when we have sex, after we exercise,
[00:05:45.980 --> 00:05:50.100]   and importantly, when we have successful social interactions.
[00:05:50.100 --> 00:05:51.740]   If you can do all four of those things at the same time,
[00:05:51.740 --> 00:05:53.220]   you're really winning.
[00:05:53.220 --> 00:05:54.580]   In an evolutionary context,
[00:05:54.580 --> 00:05:56.180]   it rewards us for beneficial behaviors
[00:05:56.180 --> 00:05:58.260]   and motivates us to repeat them.
[00:05:58.260 --> 00:06:00.820]   So this is sort of what we've heard about dopamine.
[00:06:00.820 --> 00:06:03.020]   It's kind of the layman's understanding.
[00:06:03.020 --> 00:06:04.340]   It has something to do with motivating us
[00:06:04.340 --> 00:06:06.820]   to do pleasurable behaviors.
[00:06:06.820 --> 00:06:09.220]   Let's look a little bit deeper here.
[00:06:09.220 --> 00:06:14.220]   Every time a response to a stimulus results in a reward,
[00:06:15.820 --> 00:06:19.620]   every time a response to a stimulus results in a reward,
[00:06:19.620 --> 00:06:21.460]   these associations,
[00:06:21.460 --> 00:06:24.540]   so the associations mediated by the dopamine system,
[00:06:24.540 --> 00:06:26.660]   become stronger through a process
[00:06:26.660 --> 00:06:30.340]   called long-term potentiation.
[00:06:30.340 --> 00:06:32.860]   This process strengthens frequently used connections
[00:06:32.860 --> 00:06:34.700]   between brain cells called neurons
[00:06:34.700 --> 00:06:36.140]   by increasing the intensity
[00:06:36.140 --> 00:06:38.020]   at which they respond to particular stimuli.
[00:06:38.020 --> 00:06:39.860]   Now, this is really important.
[00:06:39.860 --> 00:06:43.920]   When we look closer at the mechanisms of the dopamine system,
[00:06:43.920 --> 00:06:46.780]   we see a Pavlovian aspect to it.
[00:06:46.780 --> 00:06:49.500]   There's a response, some sort of stimuli,
[00:06:49.500 --> 00:06:53.380]   and there's a response to that stimuli that feels good.
[00:06:53.380 --> 00:06:55.500]   So this is an immediate thing.
[00:06:55.500 --> 00:06:57.500]   Stimuli response, stimuli response.
[00:06:57.500 --> 00:06:58.980]   So what's building up here in neurons
[00:06:58.980 --> 00:07:01.340]   is this immediate connection.
[00:07:01.340 --> 00:07:03.900]   I pull out this app and almost right away,
[00:07:03.900 --> 00:07:06.300]   I'm seeing something that triggers an emotional reaction,
[00:07:06.300 --> 00:07:08.700]   be it an outrage if I'm looking at
[00:07:08.700 --> 00:07:10.700]   a sort of outrage peddler on Twitter,
[00:07:10.700 --> 00:07:14.080]   or amusement if I'm looking at TikTok videos
[00:07:14.080 --> 00:07:16.520]   from a curated list that's towards funny videos,
[00:07:16.520 --> 00:07:20.040]   and your brain builds this stimuli response,
[00:07:20.040 --> 00:07:23.300]   stimuli response type of connection.
[00:07:23.300 --> 00:07:28.300]   The dopamine system then plays off of this
[00:07:28.300 --> 00:07:31.080]   and says, "Let's go do this behavior right now
[00:07:31.080 --> 00:07:32.520]   to get the response right away."
[00:07:32.520 --> 00:07:35.360]   So there's a real immediacy there.
[00:07:35.360 --> 00:07:37.460]   I have one more quote here.
[00:07:37.460 --> 00:07:38.880]   Just to give us another technical term,
[00:07:38.880 --> 00:07:40.680]   "Research and reward learning and addiction
[00:07:40.680 --> 00:07:43.080]   have recently focused on a feature of our dopamine neurons
[00:07:43.080 --> 00:07:46.520]   called reward prediction error encoding.
[00:07:46.520 --> 00:07:48.480]   These prediction errors serve as dopamine-mediated
[00:07:48.480 --> 00:07:49.720]   feedback signals in our brains."
[00:07:49.720 --> 00:07:52.360]   So we're constantly, the system is constantly monitoring
[00:07:52.360 --> 00:07:54.160]   this very tight feedback loop.
[00:07:54.160 --> 00:07:55.360]   There's a particular stimulus
[00:07:55.360 --> 00:07:57.120]   and what type of response do we get,
[00:07:57.120 --> 00:07:59.960]   and where it has learned that a stimulus
[00:07:59.960 --> 00:08:02.340]   gives you often a positive response,
[00:08:02.340 --> 00:08:04.080]   then it really drives you to do it.
[00:08:04.080 --> 00:08:08.240]   Now, this was the effect, all of this was unlocked.
[00:08:08.240 --> 00:08:11.600]   When this effect was uncovered in the context of apps
[00:08:11.600 --> 00:08:15.580]   on phones accidentally by Facebook.
[00:08:15.580 --> 00:08:18.680]   This happened about a decade ago.
[00:08:18.680 --> 00:08:20.800]   Facebook engineers, we've talked about this before,
[00:08:20.800 --> 00:08:21.680]   but it's worth repeating.
[00:08:21.680 --> 00:08:25.160]   Facebook engineers had this very pragmatic idea
[00:08:25.160 --> 00:08:28.080]   that we are gonna add the like button
[00:08:28.080 --> 00:08:30.120]   to our Facebook mobile app,
[00:08:30.120 --> 00:08:32.800]   because it is highly inefficient
[00:08:32.800 --> 00:08:37.000]   when a Facebook post is generating lots of simple,
[00:08:37.000 --> 00:08:38.920]   positive, affirmative responses,
[00:08:38.920 --> 00:08:40.000]   don't have much information,
[00:08:40.000 --> 00:08:42.320]   lots of congrats, great, that's awesome.
[00:08:42.320 --> 00:08:44.480]   And the Facebook engineers were very pragmatic
[00:08:44.480 --> 00:08:45.600]   and they said, "Here's the problem.
[00:08:45.600 --> 00:08:48.120]   I post a triumph, everyone's saying great
[00:08:48.120 --> 00:08:49.580]   and congratulations,
[00:08:49.580 --> 00:08:52.440]   that buries the more meaningful comments."
[00:08:52.440 --> 00:08:56.160]   So I post the picture of myself with my diploma
[00:08:56.160 --> 00:08:57.640]   and everyone's saying, "Great, congratulations."
[00:08:57.640 --> 00:09:00.760]   And you have 30 or 40 of these short exclamatory comments.
[00:09:00.760 --> 00:09:03.420]   You don't realize that three pages into those comments
[00:09:03.420 --> 00:09:05.760]   is the guy who's saying, "Hey, in the background,
[00:09:05.760 --> 00:09:08.120]   there's a Yeti stealing your Jeep."
[00:09:08.120 --> 00:09:09.360]   And that's like the interesting comment
[00:09:09.360 --> 00:09:10.360]   probably about this picture,
[00:09:10.360 --> 00:09:11.640]   but you don't find out about the Yeti
[00:09:11.640 --> 00:09:13.600]   stealing the Jeep in the background 'cause it's buried.
[00:09:13.600 --> 00:09:14.800]   So I said, "Oh, we'll add a like button."
[00:09:14.800 --> 00:09:16.560]   So if all you're gonna do is say, "That's great."
[00:09:16.560 --> 00:09:18.600]   You click the like button and we can save the comments
[00:09:18.600 --> 00:09:20.320]   for more meaningful information,
[00:09:20.320 --> 00:09:21.320]   like letting people know
[00:09:21.320 --> 00:09:23.120]   there's a Yeti stealing their Jeep.
[00:09:23.120 --> 00:09:24.720]   This was the idea behind the like button.
[00:09:24.720 --> 00:09:27.040]   They turn it on, almost immediately they noticed,
[00:09:27.040 --> 00:09:29.340]   "My God, people are using the app a lot more."
[00:09:29.340 --> 00:09:34.980]   And the reason was, is that the accumulation of likes
[00:09:34.980 --> 00:09:37.160]   was a positive reward signal.
[00:09:37.160 --> 00:09:38.760]   The clicking of the app,
[00:09:38.760 --> 00:09:41.680]   that little white F in the blue box on your phone,
[00:09:41.680 --> 00:09:44.940]   was a very clear stimulus, boom.
[00:09:44.940 --> 00:09:50.240]   You press that stimulus and often you get this nice reward
[00:09:50.240 --> 00:09:52.120]   of people liked what I did.
[00:09:52.120 --> 00:09:52.960]   Hey, it's Cal here.
[00:09:52.960 --> 00:09:54.560]   I just wanted to mention,
[00:09:54.560 --> 00:09:57.200]   if you wanna have help taking action
[00:09:57.200 --> 00:09:59.800]   on the type of ideas we talk about in this show,
[00:09:59.800 --> 00:10:02.200]   sign up for my email newsletter.
[00:10:02.200 --> 00:10:04.980]   The link is right here below in the description.
[00:10:04.980 --> 00:10:06.540]   Two to four times a month,
[00:10:06.540 --> 00:10:08.580]   I send out detailed articles
[00:10:08.580 --> 00:10:11.740]   about the types of ideas we discuss here.
[00:10:11.740 --> 00:10:14.700]   It's the best way to stay connected
[00:10:14.700 --> 00:10:17.020]   to me and my audience's quest to live a deeper life.
[00:10:17.020 --> 00:10:18.000]   So sign up below.
[00:10:18.000 --> 00:10:22.300]   That created a association.
[00:10:22.300 --> 00:10:24.140]   So now we get these reward prediction error
[00:10:24.140 --> 00:10:25.840]   encoding neurons involved.
[00:10:25.840 --> 00:10:27.580]   Once that association was very strong,
[00:10:27.580 --> 00:10:30.780]   your dopamine system is like, "Click that button.
[00:10:30.780 --> 00:10:31.940]   Click that button."
[00:10:31.940 --> 00:10:33.660]   And people would click it more and more and more.
[00:10:33.660 --> 00:10:35.960]   That was the birth of the attention engineering
[00:10:35.960 --> 00:10:38.700]   era that we're in now.
[00:10:38.700 --> 00:10:41.400]   That was the realization among attention economy platforms
[00:10:41.400 --> 00:10:43.220]   that if we hack the dopamine system,
[00:10:43.220 --> 00:10:46.460]   we can 5X, 6X, now in the case of TikTok,
[00:10:46.460 --> 00:10:48.380]   probably 10X engagement on these apps.
[00:10:48.380 --> 00:10:51.380]   And that's just more data, more ads to sell.
[00:10:51.380 --> 00:10:52.820]   So that is the system that's at play
[00:10:52.820 --> 00:10:54.360]   when you keep pulling out your phone.
[00:10:54.360 --> 00:10:57.500]   So what Vaughn is saying in his TED Talk
[00:10:57.500 --> 00:10:59.140]   is let's try to win at that game.
[00:11:00.220 --> 00:11:02.740]   You know, let's make this sort of fun
[00:11:02.740 --> 00:11:05.060]   and there'll be a nice reward
[00:11:05.060 --> 00:11:06.640]   because when you click on the app,
[00:11:06.640 --> 00:11:09.940]   there's an owl wearing glasses and stars fly around
[00:11:09.940 --> 00:11:12.400]   and you have streaks and that dopamine system will say,
[00:11:12.400 --> 00:11:14.940]   "Hey, let's take out this app and let's play it."
[00:11:14.940 --> 00:11:16.260]   All right, here's the problem about that.
[00:11:16.260 --> 00:11:18.180]   If you had nothing else going on on your phone,
[00:11:18.180 --> 00:11:20.740]   if it was your phone had the weather app and Duolingo,
[00:11:20.740 --> 00:11:22.860]   that's a nice reward and you might feel compelled
[00:11:22.860 --> 00:11:25.420]   to pull out the Duolingo and play with it.
[00:11:25.420 --> 00:11:30.420]   The problem is, is that you are competing with TikTok,
[00:11:30.420 --> 00:11:33.980]   Instagram, Twitter, mobile games.
[00:11:33.980 --> 00:11:35.860]   You're competing with applications
[00:11:35.860 --> 00:11:38.340]   that are also trying to hack the dopamine system.
[00:11:38.340 --> 00:11:40.940]   So now you need to out-reward them.
[00:11:40.940 --> 00:11:43.540]   You want your dopamine neurons associated with Duolingo
[00:11:43.540 --> 00:11:45.980]   to have a stronger reward response,
[00:11:45.980 --> 00:11:47.420]   a notably stronger reward response
[00:11:47.420 --> 00:11:50.300]   than these other attention engineered applications.
[00:11:50.300 --> 00:11:52.800]   And the reason why I think that is almost likely
[00:11:52.800 --> 00:11:55.880]   not going to happen is because you cannot engineer
[00:11:55.880 --> 00:11:58.960]   the reality, cannot engineer out the reality
[00:11:58.960 --> 00:12:00.480]   that learning requires strain.
[00:12:00.480 --> 00:12:03.860]   Learning is hard.
[00:12:03.860 --> 00:12:06.240]   This is something I've talked about first in my book,
[00:12:06.240 --> 00:12:08.040]   "So Good They Can't Ignore You."
[00:12:08.040 --> 00:12:09.920]   I think this also comes up in deep work.
[00:12:09.920 --> 00:12:12.260]   I think this also comes up in my book, "Digital Minimalism."
[00:12:12.260 --> 00:12:13.560]   This comes up time and again,
[00:12:13.560 --> 00:12:15.020]   this notion that how do you learn
[00:12:15.020 --> 00:12:16.980]   a complicated new procedure?
[00:12:16.980 --> 00:12:20.700]   It's through a process known as deliberate practice.
[00:12:20.700 --> 00:12:23.660]   Deliberate practice forces you to strain yourself
[00:12:23.660 --> 00:12:26.500]   with the activity at hand, be it conceptual or physical,
[00:12:26.500 --> 00:12:28.560]   past where you're comfortable.
[00:12:28.560 --> 00:12:30.860]   And it's in that strain past where you're comfortable
[00:12:30.860 --> 00:12:33.860]   that you're able to actually move forward your capabilities.
[00:12:33.860 --> 00:12:37.920]   If you want to play a guitar lick faster,
[00:12:37.920 --> 00:12:39.560]   you have to actually push yourself past
[00:12:39.560 --> 00:12:41.040]   where you can comfortably play that guitar lick.
[00:12:41.040 --> 00:12:42.960]   And at first you have to concentrate
[00:12:42.960 --> 00:12:44.880]   on that playing that guitar lick faster
[00:12:44.880 --> 00:12:46.560]   with your full concentration,
[00:12:46.560 --> 00:12:47.640]   really stretching yourself.
[00:12:47.640 --> 00:12:49.180]   And it's really hard, you're making mistakes.
[00:12:49.180 --> 00:12:50.280]   You're giving it your full attention
[00:12:50.280 --> 00:12:51.160]   not to make mistakes.
[00:12:51.160 --> 00:12:52.720]   You know what happens?
[00:12:52.720 --> 00:12:53.840]   You get better at it,
[00:12:53.840 --> 00:12:55.880]   and eventually that speed becomes easier.
[00:12:55.880 --> 00:12:58.740]   I know that analogy 'cause I actually captured that
[00:12:58.740 --> 00:13:00.320]   in my book, "So Good They Can't Ignore You,"
[00:13:00.320 --> 00:13:02.320]   where I talked about deliberate practice.
[00:13:02.320 --> 00:13:04.440]   I spent time with a professional guitar player,
[00:13:04.440 --> 00:13:06.840]   and I documented, journalistically,
[00:13:06.840 --> 00:13:10.600]   the amount of strain this guy had practicing.
[00:13:10.600 --> 00:13:13.220]   Trying to move the speed of his fingers
[00:13:13.220 --> 00:13:16.600]   on guitar picking faster, he would concentrate so hard
[00:13:16.600 --> 00:13:18.880]   that he would forget to take a breath.
[00:13:18.880 --> 00:13:20.480]   And then after a while, he would have
[00:13:20.480 --> 00:13:23.520]   the savage intake gas as his body was trying
[00:13:23.520 --> 00:13:26.920]   to stave off him going unconscious from lack of oxygen.
[00:13:26.920 --> 00:13:28.640]   That's how hard he was concentrating,
[00:13:28.640 --> 00:13:30.620]   but that's what actually makes you better.
[00:13:30.620 --> 00:13:33.280]   Same thing applies for conceptual goals,
[00:13:33.280 --> 00:13:35.880]   be it learning Spanish or calculus.
[00:13:35.880 --> 00:13:38.240]   You have to stretch yourself past where you're comfortable
[00:13:38.240 --> 00:13:40.280]   to make a higher level comfortable.
[00:13:40.280 --> 00:13:43.400]   Now, I used to have this debate all the time
[00:13:43.400 --> 00:13:45.020]   on my website at calnewport.com
[00:13:45.020 --> 00:13:47.000]   with my articles and on my newsletter,
[00:13:47.000 --> 00:13:49.920]   because people would often take these type of activities
[00:13:49.920 --> 00:13:52.880]   and say, "Yeah, yeah, yeah, you gotta get in a flow state."
[00:13:52.880 --> 00:13:53.880]   And I had to keep coming back and saying,
[00:13:53.880 --> 00:13:55.300]   "This isn't a flow state."
[00:13:55.300 --> 00:14:00.080]   The flow state, a concept that was invented
[00:14:00.080 --> 00:14:02.800]   and studied by the late great performance psychologist,
[00:14:02.800 --> 00:14:04.560]   Anders, no, it's not Anders Ericsson,
[00:14:04.560 --> 00:14:06.720]   this was Mihaly Csikszentmihalyi,
[00:14:06.720 --> 00:14:09.480]   who I had corresponded some with, actually.
[00:14:09.480 --> 00:14:14.000]   Flow states, you lose yourself in the activity.
[00:14:14.000 --> 00:14:17.040]   Flow states, time seems to disappear.
[00:14:17.040 --> 00:14:20.440]   It's the downhill skier just getting lost
[00:14:20.440 --> 00:14:22.040]   in executing the ski route,
[00:14:22.040 --> 00:14:24.120]   and you're completely lost in the activity.
[00:14:24.120 --> 00:14:26.240]   Flow states are very pleasurable.
[00:14:26.240 --> 00:14:28.340]   Deliberate practice is not.
[00:14:28.340 --> 00:14:30.820]   You can get lost playing a song you really know well
[00:14:30.820 --> 00:14:32.720]   on stage and get lost in the music.
[00:14:32.720 --> 00:14:34.600]   You never get lost when you're practicing a song
[00:14:34.600 --> 00:14:36.340]   because you're pushing yourself so damn hard
[00:14:36.340 --> 00:14:38.560]   that you're like, "Oh my God, this is miserable."
[00:14:38.560 --> 00:14:39.660]   So learning is hard.
[00:14:39.660 --> 00:14:41.560]   It requires strain.
[00:14:41.560 --> 00:14:43.740]   To try to learn without strain would be like saying,
[00:14:43.740 --> 00:14:44.640]   "I wanna grow a muscle
[00:14:44.640 --> 00:14:46.640]   without ever having to tire my muscles."
[00:14:46.640 --> 00:14:48.360]   Isn't there a way I could grow my biceps bigger
[00:14:48.360 --> 00:14:50.320]   without having to actually lift heavy things
[00:14:50.320 --> 00:14:52.280]   in a way that's heavier than I'm used to?
[00:14:52.280 --> 00:14:54.440]   No, you have to actually overload your muscle
[00:14:54.440 --> 00:14:55.400]   before it can grow.
[00:14:55.400 --> 00:14:57.080]   The same thing happens cognitively.
[00:14:57.080 --> 00:14:59.320]   So learning is always gonna have that strain.
[00:14:59.320 --> 00:15:01.420]   It's not pleasant.
[00:15:01.420 --> 00:15:05.240]   And so you can add as many owls with glasses and streaks
[00:15:05.240 --> 00:15:06.360]   as you want around it,
[00:15:06.360 --> 00:15:08.720]   but TikTok doesn't have the unpleasant strain.
[00:15:08.720 --> 00:15:12.160]   It's just like saying, "If I want you to eat more broccoli,
[00:15:12.160 --> 00:15:14.820]   I can put it in a Happy Meal box.
[00:15:14.820 --> 00:15:16.640]   It could be in like a fun wrapper
[00:15:16.640 --> 00:15:19.180]   where confetti flies open when you open the wrapper.
[00:15:19.180 --> 00:15:20.140]   But when you get down to it,
[00:15:20.140 --> 00:15:21.780]   the broccoli is still gonna be pretty bitter
[00:15:21.780 --> 00:15:24.060]   and the french fries are gonna taste much better.
[00:15:24.060 --> 00:15:26.900]   And in the end, I'm gonna eat the french fries
[00:15:26.900 --> 00:15:30.180]   if it's just they're both sitting there in front of me."
[00:15:30.180 --> 00:15:33.820]   So I'm not sure that when you take an activity,
[00:15:33.820 --> 00:15:35.380]   meaningful as it is,
[00:15:35.380 --> 00:15:38.900]   that has an inherent cognitive strain to it
[00:15:38.900 --> 00:15:40.220]   as part of its character,
[00:15:40.220 --> 00:15:43.400]   that you are gonna be able to win in the dopamine neuron game
[00:15:43.400 --> 00:15:46.160]   against other types of stimulus reward pairings
[00:15:46.160 --> 00:15:47.080]   that don't have that strain.
[00:15:47.080 --> 00:15:50.360]   The reward is simply much more pure with TikTok.
[00:15:50.360 --> 00:15:55.760]   Just like if you wanted to compare TikTok to meth,
[00:15:55.760 --> 00:15:59.680]   the reward for meth is probably much stronger than TikTok
[00:15:59.680 --> 00:16:00.880]   because now you have a substance
[00:16:00.880 --> 00:16:03.520]   that is crossing the blood brain barrier, right?
[00:16:03.520 --> 00:16:05.720]   So if I'm a meth addict, I'm like, "Well, I like TikTok,
[00:16:05.720 --> 00:16:07.560]   but what I really like is some meth."
[00:16:07.560 --> 00:16:09.320]   Just like if I'm using TikTok, I might say,
[00:16:09.320 --> 00:16:10.400]   "Well, I really like Duolingo,
[00:16:10.400 --> 00:16:13.000]   but my God, I wanna use some TikTok."
[00:16:13.000 --> 00:16:15.160]   So if it's just an apples to apples comparison
[00:16:15.160 --> 00:16:17.000]   of reward stimulus game,
[00:16:17.000 --> 00:16:20.280]   these attention engineered applications
[00:16:20.280 --> 00:16:21.960]   that we think of as modern social media
[00:16:21.960 --> 00:16:25.700]   just have the upper hand on any type of learning app.
[00:16:25.700 --> 00:16:29.040]   Okay, so does that mean that we're out of luck,
[00:16:29.040 --> 00:16:31.960]   that basically social media is gonna take all of our time?
[00:16:31.960 --> 00:16:33.160]   No, we're not out of luck.
[00:16:33.160 --> 00:16:36.520]   And the reason why is because there are other systems,
[00:16:36.520 --> 00:16:38.100]   and in particular, one other system
[00:16:38.100 --> 00:16:40.960]   that our brain uses to motivate behavior
[00:16:40.960 --> 00:16:44.640]   that is not built off of this near term stimulus reward
[00:16:44.640 --> 00:16:46.360]   dopamine neuron mediated system.
[00:16:46.360 --> 00:16:50.200]   We have another system that is at the core
[00:16:50.200 --> 00:16:53.080]   of how humans have done what we have done.
[00:16:53.080 --> 00:16:55.240]   It's at the core of what defines humans
[00:16:55.240 --> 00:16:56.960]   versus almost any other species.
[00:16:56.960 --> 00:16:59.520]   It helps explains why humans are so successful
[00:16:59.520 --> 00:17:01.280]   in a way that other smart animals
[00:17:01.280 --> 00:17:03.400]   like ravens or dolphins are not.
[00:17:03.400 --> 00:17:06.200]   And that's gonna be our ability
[00:17:07.360 --> 00:17:11.680]   to build motivation based off of future predictions.
[00:17:11.680 --> 00:17:12.520]   So let me tell you what I mean here.
[00:17:12.520 --> 00:17:13.440]   I'm gonna bring up an article
[00:17:13.440 --> 00:17:15.280]   for those who are watching instead of listening.
[00:17:15.280 --> 00:17:16.820]   I'm gonna bring up an article
[00:17:16.820 --> 00:17:18.680]   that'll help us make sense of this.
[00:17:18.680 --> 00:17:19.980]   This was an article that was written
[00:17:19.980 --> 00:17:23.320]   by Jane McGonigal for TED.
[00:17:23.320 --> 00:17:24.600]   It's called "Mental Time Travel
[00:17:24.600 --> 00:17:26.520]   is a Great Decision-Making Tool.
[00:17:26.520 --> 00:17:28.020]   This is How to Use It."
[00:17:28.020 --> 00:17:31.860]   I like this article because it has a good summary
[00:17:31.860 --> 00:17:35.400]   of the otherwise complicated neuroscience.
[00:17:35.400 --> 00:17:37.300]   So I'm gonna skip way ahead here
[00:17:37.300 --> 00:17:40.080]   and to what I think is the relevant portion.
[00:17:40.080 --> 00:17:42.600]   All right, I'm reading now from the article.
[00:17:42.600 --> 00:17:45.480]   Scientists call this form of imagination
[00:17:45.480 --> 00:17:49.500]   episodic future thinking or EFT.
[00:17:49.500 --> 00:17:53.680]   EFT is often described as a kind of mental time travel
[00:17:53.680 --> 00:17:56.480]   because your brain is working to help you see
[00:17:56.480 --> 00:17:58.860]   and feel the future as clearly and vividly
[00:17:58.860 --> 00:18:00.380]   as if you were already there.
[00:18:00.380 --> 00:18:04.960]   EFT is not an escape from reality.
[00:18:04.960 --> 00:18:08.140]   It is a way of playing with reality
[00:18:08.140 --> 00:18:10.580]   to discover risks and opportunities
[00:18:10.580 --> 00:18:12.540]   you might not have considered.
[00:18:12.540 --> 00:18:16.020]   EFT is not a daydream in which you fantasize
[00:18:16.020 --> 00:18:17.100]   about waking up in a world
[00:18:17.100 --> 00:18:18.600]   where your problems are magically solved.
[00:18:18.600 --> 00:18:21.660]   It is a way of connecting who you are today
[00:18:21.660 --> 00:18:25.000]   with what you might really feel and do in the future.
[00:18:25.000 --> 00:18:27.900]   More quotes.
[00:18:27.900 --> 00:18:30.900]   Because EFT allows us to pre-feel
[00:18:30.900 --> 00:18:34.060]   different possible futures,
[00:18:34.060 --> 00:18:35.600]   it's a powerful decision-making,
[00:18:35.600 --> 00:18:37.200]   planning, and motivational tool.
[00:18:37.200 --> 00:18:42.560]   It helps us decide, is this a world I wanna wake up in?
[00:18:42.560 --> 00:18:44.160]   What do I need to do to be ready for it?
[00:18:44.160 --> 00:18:47.020]   Should I change what I'm doing today
[00:18:47.020 --> 00:18:50.460]   to make this future more or less likely?
[00:18:50.460 --> 00:18:55.120]   According to fMRI studies, EFT involves heightened activity
[00:18:55.120 --> 00:18:56.140]   and increased connectivity
[00:18:56.140 --> 00:18:58.940]   between 11 distinct brain regions.
[00:18:58.940 --> 00:19:01.420]   Compare this to simply remembering a past event
[00:19:01.420 --> 00:19:04.960]   which activates just six of those 11 regions of the brain.
[00:19:04.960 --> 00:19:06.280]   To get a little more technical here,
[00:19:06.280 --> 00:19:08.200]   during EFT, your brain goes on a hunt
[00:19:08.200 --> 00:19:10.480]   for realistic details and plausible ideas.
[00:19:10.480 --> 00:19:12.840]   To do this, it activates the hippocampus,
[00:19:12.840 --> 00:19:14.440]   the seat of memory and learning,
[00:19:14.440 --> 00:19:15.560]   and digs through your memories
[00:19:15.560 --> 00:19:18.600]   plus any other facts and ideas you've stored away.
[00:19:18.600 --> 00:19:20.240]   Depending on what kind of future you're imagining,
[00:19:20.240 --> 00:19:22.320]   the hippocampus identifies the most relevant stuff
[00:19:22.320 --> 00:19:25.500]   and retrieves and recombines it into a new scene.
[00:19:25.500 --> 00:19:27.200]   One last thing to say about that,
[00:19:27.200 --> 00:19:30.360]   those are called clues to the future.
[00:19:30.360 --> 00:19:35.360]   Your brain fires up the ventromedial prefrontal cortex,
[00:19:35.360 --> 00:19:39.740]   otherwise known by the catchy acronym, VMPFC,
[00:19:39.740 --> 00:19:42.680]   a region that's heavily used
[00:19:42.680 --> 00:19:45.060]   whenever you set goals and track your progress.
[00:19:45.060 --> 00:19:48.320]   Like the hippocampus, the VMPFC can suggest any goals
[00:19:48.320 --> 00:19:51.280]   you've had or previously considered.
[00:19:51.280 --> 00:19:53.160]   One of the most interesting things about the EFT
[00:19:53.160 --> 00:19:56.180]   is that the motivations that pop into your mind first
[00:19:56.180 --> 00:19:58.380]   are likely to be closely linked to your deepest values
[00:19:58.380 --> 00:20:00.020]   and most essential needs,
[00:20:00.020 --> 00:20:03.440]   like always learning something new,
[00:20:03.440 --> 00:20:05.500]   helping others, pushing yourself to do brave things,
[00:20:05.500 --> 00:20:07.000]   taking care of your family, being creative,
[00:20:07.000 --> 00:20:09.760]   or putting new ideas or art into the world.
[00:20:09.760 --> 00:20:12.120]   You still have to figure out the best way
[00:20:12.120 --> 00:20:14.560]   for your future you to achieve these future goals.
[00:20:14.560 --> 00:20:18.160]   So then the putamen, P-U-T-A-M-E-N,
[00:20:18.160 --> 00:20:21.320]   also part of the motivation and reward system kicks in.
[00:20:21.320 --> 00:20:23.420]   The putamen, which I'm almost certainly saying wrong,
[00:20:23.420 --> 00:20:25.840]   helps keep track of what specific actions and behaviors
[00:20:25.840 --> 00:20:27.680]   typically lead to positive results for you.
[00:20:27.680 --> 00:20:29.520]   It's the part of the brain that knows things like,
[00:20:29.520 --> 00:20:32.040]   I feel better when I get some fresh air.
[00:20:32.040 --> 00:20:35.280]   Okay, I read all those technical details
[00:20:35.280 --> 00:20:36.680]   so you could get a lay of the land
[00:20:36.680 --> 00:20:39.540]   that this is a different type of motivational system.
[00:20:39.540 --> 00:20:44.000]   It is based on you projecting yourself into the future,
[00:20:44.000 --> 00:20:47.020]   imagining a result in the future that is very positive
[00:20:47.020 --> 00:20:50.200]   because you have evidence from your past it will be positive
[00:20:50.200 --> 00:20:53.320]   and it connects to your deeply held values and goals.
[00:20:53.320 --> 00:20:57.460]   This then fires up other parts of your brain
[00:20:57.460 --> 00:20:59.920]   that gives you motivation to do the thing right now
[00:20:59.920 --> 00:21:02.220]   that's gonna help lead you to that future state.
[00:21:02.220 --> 00:21:06.000]   EFT is a different motivational system
[00:21:06.000 --> 00:21:07.480]   than the dopamine system.
[00:21:07.480 --> 00:21:11.380]   It is a system that can beat the dopamine system.
[00:21:11.380 --> 00:21:16.040]   This is critical to human survival.
[00:21:16.040 --> 00:21:21.040]   This is why you can have in the caveman times
[00:21:21.040 --> 00:21:23.520]   some nice looking food.
[00:21:23.520 --> 00:21:27.020]   Okay, there's honey on the ground and I really want honey.
[00:21:27.020 --> 00:21:28.700]   I like honey, I need sugar.
[00:21:28.700 --> 00:21:30.680]   My dopamine neurons say, eat that honey.
[00:21:30.680 --> 00:21:33.240]   My God, eat that honey, that's gonna feel good.
[00:21:33.240 --> 00:21:35.240]   But also I know there's a bear nearby
[00:21:35.240 --> 00:21:36.560]   'cause there's honey on the ground.
[00:21:36.560 --> 00:21:39.000]   And the EFT system says, the thing about bears
[00:21:39.000 --> 00:21:42.000]   is they tend to eat you and that's not good.
[00:21:42.000 --> 00:21:44.500]   And so we're gonna override the dopamine system
[00:21:44.500 --> 00:21:46.800]   that says, go get that honey
[00:21:46.800 --> 00:21:48.660]   because we don't wanna be eaten by a bear,
[00:21:48.660 --> 00:21:50.460]   which is something that might happen here.
[00:21:50.460 --> 00:21:52.320]   The EFT system is what allows us
[00:21:52.320 --> 00:21:55.320]   to rise above our base instincts and say,
[00:21:55.320 --> 00:21:59.800]   let's invent the ax, let's invent the wheel,
[00:21:59.800 --> 00:22:02.620]   let's invent systems of philosophy.
[00:22:02.620 --> 00:22:05.160]   It's what allows us to do human flourishing
[00:22:05.160 --> 00:22:06.480]   and creative actions.
[00:22:06.480 --> 00:22:09.160]   The ideas, the leaps of creative thinking
[00:22:09.160 --> 00:22:12.440]   that Yuval Harari in "Sapiens" identifies as the crux
[00:22:12.440 --> 00:22:13.600]   that makes humans humans,
[00:22:13.600 --> 00:22:15.320]   what makes our species what they are.
[00:22:15.320 --> 00:22:17.940]   So this EFT style motivation is more powerful
[00:22:17.940 --> 00:22:21.240]   because it's what allows us to do big and great things.
[00:22:21.240 --> 00:22:23.200]   It's what allows us to rise above our base instincts
[00:22:23.200 --> 00:22:25.760]   in a way that a tiger cannot or a house cat cannot.
[00:22:25.760 --> 00:22:31.520]   So when we think about, hey, how do we learn more?
[00:22:31.520 --> 00:22:34.600]   We don't wanna play the dopamine game.
[00:22:34.600 --> 00:22:38.480]   We don't wanna say, how do I make learning feel the same
[00:22:38.480 --> 00:22:40.720]   as checking Facebook to see if I get those likes.
[00:22:40.720 --> 00:22:43.800]   We instead wanna master our EFT system,
[00:22:43.800 --> 00:22:45.940]   the episodic future thinking system.
[00:22:45.940 --> 00:22:50.920]   And what this means is we have to fill up that hippocampus
[00:22:50.920 --> 00:22:53.840]   with all sorts of concrete details and experiences
[00:22:53.840 --> 00:22:57.000]   and memories that allow us to connect,
[00:22:57.000 --> 00:22:58.560]   allow us to connect this behavior
[00:22:58.560 --> 00:23:00.680]   with very positive futures.
[00:23:00.680 --> 00:23:03.280]   It requires us to have really deeply instilled values
[00:23:03.280 --> 00:23:06.640]   about what we care about so that we can then say,
[00:23:06.640 --> 00:23:08.760]   this activity that I know a lot about now
[00:23:08.760 --> 00:23:12.100]   leads me to something that I feel really strongly about.
[00:23:12.100 --> 00:23:15.480]   Now, I talk about this a lot in the context of the deep life
[00:23:15.480 --> 00:23:18.020]   as lifestyle-centric planning,
[00:23:18.020 --> 00:23:19.440]   where you start with this clear vision
[00:23:19.440 --> 00:23:20.860]   of what you want your life to look like
[00:23:20.860 --> 00:23:22.640]   and use that to work backwards to build plans.
[00:23:22.640 --> 00:23:23.840]   This is no accident.
[00:23:23.840 --> 00:23:26.640]   This is no mere contrivance.
[00:23:26.640 --> 00:23:31.400]   This is a instruction manual to fully leveraging your EFT.
[00:23:31.400 --> 00:23:33.260]   So if you wanna learn more,
[00:23:33.260 --> 00:23:36.280]   you have to expose yourself
[00:23:36.280 --> 00:23:39.200]   to as many resonant examples as possible
[00:23:39.200 --> 00:23:43.340]   of people who have learned and you admire,
[00:23:43.340 --> 00:23:45.000]   people who are really well-learned
[00:23:45.000 --> 00:23:46.200]   and what they do in their life
[00:23:46.200 --> 00:23:47.240]   or how they approach the world
[00:23:47.240 --> 00:23:49.720]   resonates with you on a deep level.
[00:23:49.720 --> 00:23:52.240]   You need to watch these documentaries, read these profiles,
[00:23:52.240 --> 00:23:54.720]   read the biographies, look for these types of videos,
[00:23:54.720 --> 00:23:57.440]   meet these people in real life, go to their talks,
[00:23:57.440 --> 00:23:59.080]   go to see their presentations.
[00:23:59.080 --> 00:24:01.800]   You need to surround yourself in examples
[00:24:01.800 --> 00:24:05.920]   of people who have converted a love of learning
[00:24:05.920 --> 00:24:08.240]   into a life that really resonates with you.
[00:24:08.240 --> 00:24:10.280]   And then you need to clarify your values
[00:24:10.280 --> 00:24:12.280]   of what is the value here that's at stake
[00:24:12.280 --> 00:24:14.120]   and make that a big part of your vision
[00:24:14.120 --> 00:24:15.280]   for yourself and your life.
[00:24:15.280 --> 00:24:17.640]   It'd be engaging ideas in a way
[00:24:17.640 --> 00:24:20.520]   that is above base rancor,
[00:24:20.520 --> 00:24:22.140]   or maybe about taking your mind
[00:24:22.140 --> 00:24:23.520]   and pushing to its fullest potential
[00:24:23.520 --> 00:24:25.280]   so you can have impact on the world.
[00:24:25.280 --> 00:24:27.080]   Maybe there's a religious impulse here,
[00:24:27.080 --> 00:24:28.720]   a sort of Newtonian interest
[00:24:28.720 --> 00:24:32.480]   in trying to uncover the workings of God.
[00:24:32.480 --> 00:24:34.200]   You know that there's almost a religious impulse
[00:24:34.200 --> 00:24:36.360]   to be able to understand things better.
[00:24:36.360 --> 00:24:39.780]   Maybe it's, I want to support my family
[00:24:39.780 --> 00:24:42.080]   and my brain is gonna be one way I can do this.
[00:24:42.080 --> 00:24:44.040]   There's whatever it is, you have a clear value
[00:24:44.040 --> 00:24:46.120]   and you expose yourself to example after example
[00:24:46.120 --> 00:24:49.440]   that resonates about people who have pursued this value.
[00:24:49.440 --> 00:24:51.840]   And they're showing you tangibly in their example,
[00:24:51.840 --> 00:24:53.960]   something you really want.
[00:24:53.960 --> 00:24:56.040]   You do these things, your EFT system
[00:24:56.040 --> 00:24:57.880]   can kick your dopamine system's butt.
[00:24:57.880 --> 00:25:02.040]   And you say, yeah, there's a TikTok is there
[00:25:02.040 --> 00:25:05.920]   and it's gonna give me a little reward in the moment.
[00:25:05.920 --> 00:25:06.960]   It's gonna feel good.
[00:25:06.960 --> 00:25:10.540]   But this future I'm projecting feels even better.
[00:25:10.540 --> 00:25:15.120]   And so you know what, I'm not gonna take out TikTok.
[00:25:15.120 --> 00:25:19.120]   I'm gonna read, I'm going to go watch this movie.
[00:25:19.120 --> 00:25:21.080]   I am going to go through the discomfort
[00:25:21.080 --> 00:25:23.400]   of stretching my mind past what it can do or not,
[00:25:23.400 --> 00:25:25.540]   whether or not there's an owl wearing glasses
[00:25:25.540 --> 00:25:28.460]   or an avatar stars a shootout when I do it.
[00:25:28.460 --> 00:25:32.720]   So, I mean, I think Vaughn is on to something
[00:25:32.720 --> 00:25:35.840]   when he says, we shouldn't just take learning for granted
[00:25:35.840 --> 00:25:37.760]   and say, learning is good, you should learn more.
[00:25:37.760 --> 00:25:39.000]   Here's a workbook.
[00:25:39.000 --> 00:25:40.480]   We really should think about
[00:25:40.480 --> 00:25:42.000]   how do you make learning desirable?
[00:25:42.000 --> 00:25:44.520]   And I think it's fantastic that he is thinking about that,
[00:25:44.520 --> 00:25:47.000]   that he is identifying learning
[00:25:47.000 --> 00:25:48.600]   as this sort of tier one activity
[00:25:48.600 --> 00:25:50.320]   that can improve people's situation,
[00:25:50.320 --> 00:25:53.040]   that can improve the world in so many different ways.
[00:25:53.040 --> 00:25:54.840]   I'm arguing though, the right way to spread that
[00:25:54.840 --> 00:25:56.520]   is less about playing the dopamine game
[00:25:56.520 --> 00:25:58.360]   and more about playing the EFT game.
[00:25:58.360 --> 00:25:59.900]   And this applies not just to learning,
[00:25:59.900 --> 00:26:01.680]   but almost to any type of activity
[00:26:01.680 --> 00:26:04.320]   that will take a shallow life and make it deeper.
[00:26:04.320 --> 00:26:06.040]   So when we understand the brain,
[00:26:06.040 --> 00:26:08.440]   we get a more nuanced playbook
[00:26:08.440 --> 00:26:11.600]   for how we convince ourselves to work towards
[00:26:11.600 --> 00:26:13.440]   the best vision of our future
[00:26:13.440 --> 00:26:16.040]   and not just the most desirable understanding
[00:26:16.040 --> 00:26:18.220]   of what could happen right now.
[00:26:18.220 --> 00:26:23.680]   There you go, Jesse, that's my take on that video.
[00:26:23.680 --> 00:26:24.520]   - Yeah, I like it.
[00:26:24.520 --> 00:26:25.840]   - EFT.
[00:26:25.840 --> 00:26:27.840]   There's some pretty long acronyms.
[00:26:27.840 --> 00:26:31.140]   Neuroscientists have their acronym game on point.
[00:26:31.140 --> 00:26:35.240]   Not catchy, no vowels in a way
[00:26:35.240 --> 00:26:36.560]   that it sounds like a real word.
[00:26:36.560 --> 00:26:37.880]   And what I really loved was,
[00:26:37.880 --> 00:26:40.280]   if you're watching instead of just listening,
[00:26:40.280 --> 00:26:43.520]   the mix of lowercase and capital letters in an acronym.
[00:26:43.520 --> 00:26:46.060]   So like, it really makes it confusing.
[00:26:46.060 --> 00:26:48.580]   So way to go neuroscientists.
[00:26:48.580 --> 00:26:50.560]   So I got a bunch of questions,
[00:26:50.560 --> 00:26:52.980]   all roughly about learning and these types of things.
[00:26:52.980 --> 00:26:55.080]   We have a call in there, we have a case study in there,
[00:26:55.080 --> 00:26:57.800]   but first let us hear from some of the sponsors
[00:26:57.800 --> 00:26:59.460]   that makes this show possible.
[00:26:59.460 --> 00:27:02.600]   Love that sound effect.
[00:27:02.600 --> 00:27:05.360]   Let's talk about ZocDoc, a free app
[00:27:05.360 --> 00:27:06.920]   where you can find amazing doctors
[00:27:06.920 --> 00:27:09.760]   and book appointments online.
[00:27:10.280 --> 00:27:11.480]   We're talking about booking appointments
[00:27:11.480 --> 00:27:13.880]   with thousands of top rated patient review doctors
[00:27:13.880 --> 00:27:14.720]   and specialists.
[00:27:14.720 --> 00:27:16.000]   You can filter specifically for ones
[00:27:16.000 --> 00:27:17.960]   who take your insurance or are located near you
[00:27:17.960 --> 00:27:20.680]   and treat almost any condition you're searching for.
[00:27:20.680 --> 00:27:23.040]   ZocDoc is the way you find a medical provider.
[00:27:23.040 --> 00:27:26.520]   I mean, it really is barbaric
[00:27:26.520 --> 00:27:29.640]   the way that we typically do this in the modern world
[00:27:29.640 --> 00:27:31.480]   where we're just asking around.
[00:27:31.480 --> 00:27:34.480]   Hey, do you know a foot guy?
[00:27:34.480 --> 00:27:35.620]   Is he any good?
[00:27:35.620 --> 00:27:37.120]   I don't know, let me go to his office
[00:27:37.120 --> 00:27:41.000]   and find out that he only takes payment in chickens
[00:27:41.000 --> 00:27:42.320]   and doesn't take your insurance.
[00:27:42.320 --> 00:27:44.400]   It's so random and time consuming.
[00:27:44.400 --> 00:27:46.200]   Of course, there should be an app for this.
[00:27:46.200 --> 00:27:47.760]   Of course, I should be able to say,
[00:27:47.760 --> 00:27:49.680]   I'm looking for a foot doctor.
[00:27:49.680 --> 00:27:51.480]   Show me foot doctors nearby.
[00:27:51.480 --> 00:27:54.120]   Okay, now show me foot doctors nearby
[00:27:54.120 --> 00:27:56.900]   that take my insurance and are taking new patients.
[00:27:56.900 --> 00:27:58.960]   Okay, now let me look at the reviews.
[00:27:58.960 --> 00:28:01.280]   Oh, people really like this particular foot doctor
[00:28:01.280 --> 00:28:04.000]   who's nearby and takes my insurance.
[00:28:04.000 --> 00:28:07.880]   Let me book an appointment right now from the app.
[00:28:07.880 --> 00:28:09.860]   It just makes so much sense.
[00:28:09.860 --> 00:28:11.440]   Why do this any other way?
[00:28:11.440 --> 00:28:15.640]   ZocDoc is the best way to actually find medical providers.
[00:28:15.640 --> 00:28:17.440]   I have multiple medical providers
[00:28:17.440 --> 00:28:20.640]   who not only can be found on ZocDoc,
[00:28:20.640 --> 00:28:24.040]   but actually use ZocDoc to manage their intake forms
[00:28:24.040 --> 00:28:25.000]   and send reminders.
[00:28:25.000 --> 00:28:26.800]   So now that I'm their patient,
[00:28:26.800 --> 00:28:29.320]   I can, for example, fill out my paperwork ahead of time
[00:28:29.320 --> 00:28:31.140]   so that when I show up, we're just ready to go,
[00:28:31.140 --> 00:28:32.520]   no clipboards involved.
[00:28:32.520 --> 00:28:36.360]   It's a no brainer of an application.
[00:28:36.360 --> 00:28:41.160]   This is sort of internet apps at their most useful best.
[00:28:41.160 --> 00:28:43.080]   So go to ZocDoc.com/deep
[00:28:43.080 --> 00:28:45.860]   and download the ZocDoc app for free.
[00:28:45.860 --> 00:28:49.860]   You can find and book a top rated doctor today.
[00:28:49.860 --> 00:28:54.860]   That's Z-O-C-D-O-C.com/deep, ZocDoc.com/deep.
[00:28:54.860 --> 00:29:02.060]   I also wanna talk about my friends at Hinson Shaving.
[00:29:02.060 --> 00:29:06.260]   They make the razor that I use.
[00:29:06.260 --> 00:29:07.540]   Here's what I like about Hinson Shaving.
[00:29:07.540 --> 00:29:12.340]   What they do is build this beautiful razor.
[00:29:12.340 --> 00:29:13.260]   It's out of aluminum.
[00:29:13.260 --> 00:29:16.140]   They use these high precision milling machines.
[00:29:16.140 --> 00:29:17.420]   Because the thing to know about Hinson
[00:29:17.420 --> 00:29:19.740]   is that the other stuff they do
[00:29:19.740 --> 00:29:22.480]   is making precision parts for the aerospace industry.
[00:29:22.480 --> 00:29:24.160]   So they got these high precision milling machines,
[00:29:24.160 --> 00:29:26.540]   which they use to make these beautiful aluminum razors.
[00:29:26.540 --> 00:29:28.480]   And the reason why precision matters
[00:29:28.480 --> 00:29:30.980]   is because they can make the spacing
[00:29:30.980 --> 00:29:34.920]   of the header on their razor so exact
[00:29:34.920 --> 00:29:39.060]   that if you put just a standard 10 cent safety razor blade
[00:29:39.060 --> 00:29:41.100]   and screw it into their razor body,
[00:29:41.100 --> 00:29:43.660]   you have just the minimal edge of the razor
[00:29:43.660 --> 00:29:45.400]   peeking beyond the edge.
[00:29:45.400 --> 00:29:47.780]   And what you get with just the bare minimum
[00:29:47.780 --> 00:29:51.320]   of the blade peeking beyond the edge of the razor head
[00:29:51.320 --> 00:29:53.380]   is no diving board effect.
[00:29:53.380 --> 00:29:55.260]   No wobbling up and down of the blade
[00:29:55.260 --> 00:29:57.260]   that's gonna cause claws or gonna cause nicks.
[00:29:57.260 --> 00:30:00.420]   And so what you do is you get a beautiful smooth shave
[00:30:00.420 --> 00:30:01.500]   with a 10 cent blade.
[00:30:01.500 --> 00:30:03.780]   So I love the economics of this
[00:30:03.780 --> 00:30:05.140]   because you pay a little bit more upfront
[00:30:05.140 --> 00:30:06.740]   for this beautiful artifact.
[00:30:06.740 --> 00:30:08.700]   And then once you have this,
[00:30:08.700 --> 00:30:11.060]   you can just use standard 10 cent blades,
[00:30:11.060 --> 00:30:12.940]   swap them out every week to get your shave.
[00:30:12.940 --> 00:30:15.560]   So the cost of using a Hinson's razor
[00:30:15.560 --> 00:30:18.820]   very quickly becomes much cheaper aggregate
[00:30:18.820 --> 00:30:20.880]   than using a subscription service
[00:30:20.880 --> 00:30:22.020]   or going to the drug store
[00:30:22.020 --> 00:30:23.940]   to buy those plastic monstrosities
[00:30:23.940 --> 00:30:27.700]   with the 19 blades and the chainsaw attachment
[00:30:27.700 --> 00:30:29.580]   that vibrate and play MP3s
[00:30:29.580 --> 00:30:31.840]   or whatever's going on now with those blades.
[00:30:31.840 --> 00:30:35.100]   So you get a beautiful piece of tools.
[00:30:35.100 --> 00:30:36.740]   It's almost like a piece of art.
[00:30:36.740 --> 00:30:39.800]   I actually have, they sent me an aluminum stand
[00:30:39.800 --> 00:30:43.140]   for my Hinson razor that's also sort of beautifully made.
[00:30:43.140 --> 00:30:44.340]   So I've got my blade.
[00:30:44.340 --> 00:30:46.340]   I feel like I should put a little spotlight on it
[00:30:46.340 --> 00:30:49.540]   and maybe it should like rotate slowly.
[00:30:49.540 --> 00:30:51.140]   But anyways, it's a way to get a great shave
[00:30:51.140 --> 00:30:55.140]   with a great tool supporting a great small business company
[00:30:55.140 --> 00:30:59.560]   and it's a cheaper way over time to maintain a close shave.
[00:30:59.560 --> 00:31:01.000]   So it's time to say no to subscriptions
[00:31:01.000 --> 00:31:03.100]   and yes to a razor that'll last you a lifetime.
[00:31:03.100 --> 00:31:06.260]   Visit hinsonshaving.com/cal,
[00:31:06.260 --> 00:31:08.420]   they picked a razor for you and use code CAL
[00:31:08.420 --> 00:31:09.980]   and you'll get two years worth of blades
[00:31:09.980 --> 00:31:11.300]   for free with your razor.
[00:31:11.300 --> 00:31:13.340]   Just add the two years of blades to your cart
[00:31:13.340 --> 00:31:15.440]   and when you use my promo code CAL later,
[00:31:15.440 --> 00:31:17.460]   the price of the blades will fall to zero.
[00:31:17.460 --> 00:31:21.860]   That's 100 free blades when you head to H-E-N-S-O-N
[00:31:21.860 --> 00:31:26.860]   S-H-A-V-I-N-G.com/cal and use that code CAL.
[00:31:28.380 --> 00:31:30.600]   All right, so let's do some questions.
[00:31:30.600 --> 00:31:34.220]   Liking the sound effect.
[00:31:34.220 --> 00:31:35.740]   - I like it too. - Yeah, there we go.
[00:31:35.740 --> 00:31:36.580]   There we go.
[00:31:36.580 --> 00:31:37.400]   All right, what do we got Jesse?
[00:31:37.400 --> 00:31:38.240]   What's our first question?
[00:31:38.240 --> 00:31:39.580]   - First question's from Matt.
[00:31:39.580 --> 00:31:42.840]   I believe my curiosity is my strongest quality
[00:31:42.840 --> 00:31:45.540]   and I read and learn constantly about all kinds of topics.
[00:31:45.540 --> 00:31:47.340]   The problem is my company's core business
[00:31:47.340 --> 00:31:50.300]   is exceedingly uninteresting to me.
[00:31:50.300 --> 00:31:51.880]   I like being an attorney,
[00:31:51.880 --> 00:31:53.880]   but learning as much as I can about law stuff
[00:31:53.880 --> 00:31:55.660]   makes me want to chug Drano.
[00:31:55.660 --> 00:31:57.960]   Does your advice against follow your passion
[00:31:57.960 --> 00:32:00.680]   have room for a need to be interested
[00:32:00.680 --> 00:32:02.320]   in the subject of one's work?
[00:32:02.320 --> 00:32:05.480]   - I'm gonna be careful here, Matt.
[00:32:05.480 --> 00:32:08.900]   I'm gonna be careful and a little bit 50% curmudgeonly
[00:32:08.900 --> 00:32:13.700]   and 50% skeptical because there is a danger
[00:32:13.700 --> 00:32:15.380]   that we might be wandering close towards,
[00:32:15.380 --> 00:32:20.380]   which is a standard notion in our current world
[00:32:20.380 --> 00:32:25.620]   in which we want our work to be everything.
[00:32:26.800 --> 00:32:30.020]   I think this is an outgrowth of this idea
[00:32:30.020 --> 00:32:32.720]   that first arose in the 1990s,
[00:32:32.720 --> 00:32:36.180]   this follow your passion idea that really became
[00:32:36.180 --> 00:32:41.180]   a mimetic vector that spread widely starting in the 1990s
[00:32:41.180 --> 00:32:44.660]   and beyond that your work is gonna be your main source
[00:32:44.660 --> 00:32:46.980]   of passion and meaning and identity.
[00:32:46.980 --> 00:32:48.460]   This is something I've written about.
[00:32:48.460 --> 00:32:49.980]   I would point people, for example,
[00:32:49.980 --> 00:32:52.260]   towards my New Yorker piece from,
[00:32:52.260 --> 00:32:55.220]   I guess probably last January about quiet quitting
[00:32:55.220 --> 00:32:58.340]   where I get into the ways different generations grappled
[00:32:58.340 --> 00:33:00.180]   with work and meaning and how this idea
[00:33:00.180 --> 00:33:03.680]   of the baby boomers invented for their kids this idea
[00:33:03.680 --> 00:33:07.860]   of well, you need to work like a normal job, right?
[00:33:07.860 --> 00:33:09.580]   Because the baby boomers tried counterculture
[00:33:09.580 --> 00:33:10.420]   and that didn't work.
[00:33:10.420 --> 00:33:11.460]   So you need to work a normal job
[00:33:11.460 --> 00:33:13.580]   but make the job still a source of passion.
[00:33:13.580 --> 00:33:15.300]   So for the baby boomers,
[00:33:15.300 --> 00:33:17.260]   they had this countercultural idea,
[00:33:17.260 --> 00:33:22.260]   leave the world of work and find passion in other things
[00:33:22.260 --> 00:33:24.900]   like hemp seed oil.
[00:33:24.900 --> 00:33:26.900]   And that kind of didn't work because it turns out
[00:33:26.900 --> 00:33:28.060]   you need money to buy things.
[00:33:28.060 --> 00:33:29.740]   And so they sort of shifted and said, okay,
[00:33:29.740 --> 00:33:31.660]   well, you need to work and pay for your mortgage
[00:33:31.660 --> 00:33:34.460]   but your work itself maybe should be a source of passion.
[00:33:34.460 --> 00:33:36.140]   We've really internalized that.
[00:33:36.140 --> 00:33:38.780]   So we want our work to be everything.
[00:33:38.780 --> 00:33:40.580]   Should be interesting, it should be engaging,
[00:33:40.580 --> 00:33:41.660]   it should make me feel good,
[00:33:41.660 --> 00:33:43.380]   it should be my main source of community,
[00:33:43.380 --> 00:33:45.720]   it should be like everything needs to come from my work,
[00:33:45.720 --> 00:33:48.660]   which is this impossibly high bar to meet,
[00:33:48.660 --> 00:33:52.300]   especially if you think about what work was like
[00:33:52.300 --> 00:33:54.860]   until basically a minute ago.
[00:33:54.860 --> 00:33:57.300]   So it's not necessary.
[00:33:57.300 --> 00:33:58.380]   I'm not saying it's a bad thing,
[00:33:58.380 --> 00:34:01.440]   but it's not in any ways necessary
[00:34:01.440 --> 00:34:03.540]   that your job has to be day-to-day,
[00:34:03.540 --> 00:34:05.180]   very exciting and novel.
[00:34:05.180 --> 00:34:08.000]   There's other major sources of meaning
[00:34:08.000 --> 00:34:09.980]   that your job can provide.
[00:34:09.980 --> 00:34:13.260]   A connection to people, impact on the world,
[00:34:13.260 --> 00:34:17.100]   a sense of mastery, a foundation of being
[00:34:17.100 --> 00:34:20.280]   a reputable member of the communities that you care about.
[00:34:21.180 --> 00:34:23.060]   This is where like in the mid 20th century,
[00:34:23.060 --> 00:34:24.300]   jobs were much more boring.
[00:34:24.300 --> 00:34:26.500]   You sold insurance or maybe you were a farmer, right?
[00:34:26.500 --> 00:34:29.540]   These weren't jobs where the things you were doing every day
[00:34:29.540 --> 00:34:32.500]   was super exciting, you were learning all this novel stuff.
[00:34:32.500 --> 00:34:34.380]   But you could be as the farmer,
[00:34:34.380 --> 00:34:37.720]   also head of the local agricultural union
[00:34:37.720 --> 00:34:39.160]   and a deacon at your church
[00:34:39.160 --> 00:34:40.640]   and you're providing for your family
[00:34:40.640 --> 00:34:41.980]   and you know the other farmers
[00:34:41.980 --> 00:34:44.780]   and you're involved in coaching the football team
[00:34:44.780 --> 00:34:46.780]   and it's just part of your identity
[00:34:46.780 --> 00:34:49.000]   and an important part of what you do.
[00:34:49.000 --> 00:34:52.280]   The insurance salesman is also at the rotary club
[00:34:52.280 --> 00:34:56.240]   and it's just a piece, you're supporting your family,
[00:34:56.240 --> 00:34:58.720]   you're a productive member of your community,
[00:34:58.720 --> 00:35:01.280]   you're giving back to these various causes.
[00:35:01.280 --> 00:35:02.960]   So the job itself has to be,
[00:35:02.960 --> 00:35:04.760]   this is what has to be exciting and interesting,
[00:35:04.760 --> 00:35:05.760]   that's a new notion.
[00:35:05.760 --> 00:35:09.640]   So I say that first just to lay the foundation
[00:35:09.640 --> 00:35:11.800]   that like let's come off the ledge a little bit, Matt,
[00:35:11.800 --> 00:35:13.200]   we'll look at this a little bit more closely,
[00:35:13.200 --> 00:35:14.560]   but let's come off the ledge of,
[00:35:14.560 --> 00:35:17.440]   oh my God, this is a crisis, something has to change.
[00:35:17.440 --> 00:35:18.520]   This is not a crisis.
[00:35:18.520 --> 00:35:20.280]   Yeah, lawyers have boring jobs.
[00:35:20.280 --> 00:35:23.120]   It doesn't mean that we shouldn't have lawyers.
[00:35:23.120 --> 00:35:25.600]   All right, does that mean though
[00:35:25.600 --> 00:35:26.920]   you definitely shouldn't try to change something?
[00:35:26.920 --> 00:35:28.560]   Well, no, maybe.
[00:35:28.560 --> 00:35:30.240]   Now that we're off the ledge,
[00:35:30.240 --> 00:35:31.840]   we've calmed down a little bit,
[00:35:31.840 --> 00:35:34.240]   we had a couple of drinks, now we're relaxed.
[00:35:34.240 --> 00:35:35.960]   I'm gonna say, okay, look, I mean,
[00:35:35.960 --> 00:35:40.120]   having something interesting in your job is good too.
[00:35:40.120 --> 00:35:41.700]   There's a way to make a lateral move
[00:35:41.700 --> 00:35:44.200]   in terms of career capital stores.
[00:35:44.200 --> 00:35:46.520]   So if you're a lawyer, something that makes use of the fact
[00:35:46.520 --> 00:35:48.120]   you trained so long to become a lawyer,
[00:35:48.120 --> 00:35:49.920]   but maybe it's more interesting lawyer work,
[00:35:49.920 --> 00:35:51.440]   I find consider that.
[00:35:51.440 --> 00:35:52.960]   Don't throw everything out.
[00:35:52.960 --> 00:35:55.000]   Don't throw out your career capital.
[00:35:55.000 --> 00:35:58.360]   Don't say, I'm gonna become someone
[00:35:58.360 --> 00:36:01.000]   who dresses up as pirates for kids' birthday parties
[00:36:01.000 --> 00:36:02.160]   because that just sounds more interesting
[00:36:02.160 --> 00:36:03.000]   than being a lawyer
[00:36:03.000 --> 00:36:05.560]   because you're starting with no career capital.
[00:36:05.560 --> 00:36:07.280]   There's people who I suppose are very good
[00:36:07.280 --> 00:36:09.360]   at dressing up as pirates for kids' birthday parties
[00:36:09.360 --> 00:36:11.800]   and you're not, and it's gonna be hard to make a living.
[00:36:11.800 --> 00:36:14.160]   So it's a completely reasonable move
[00:36:14.160 --> 00:36:16.640]   to redeploy your career capital
[00:36:16.640 --> 00:36:18.360]   towards some new challenges
[00:36:18.360 --> 00:36:20.440]   or more interesting aspect of your work.
[00:36:20.440 --> 00:36:23.680]   But I don't want you to fixate on this idea
[00:36:23.680 --> 00:36:25.680]   that your work has to be the source of that.
[00:36:25.680 --> 00:36:27.580]   So the best thing you can do here, Matt,
[00:36:27.580 --> 00:36:28.880]   and this is such a broken record
[00:36:28.880 --> 00:36:30.220]   in everything I say on this show,
[00:36:30.220 --> 00:36:32.680]   is gonna be some lifestyle-centric career planning.
[00:36:32.680 --> 00:36:34.840]   Fix the full vision of what you want your life to be
[00:36:34.840 --> 00:36:37.040]   like five years, 10 years, and 15 years from now,
[00:36:37.040 --> 00:36:39.520]   all aspects of your life, not just your job,
[00:36:39.520 --> 00:36:40.880]   where you are, what you're doing,
[00:36:40.880 --> 00:36:42.820]   the character of the day, the people you're around,
[00:36:42.820 --> 00:36:44.640]   how the day unfolds, your surroundings,
[00:36:44.640 --> 00:36:46.840]   how it looks, how it smells, how it feels,
[00:36:46.840 --> 00:36:48.400]   this visceral, resonant image
[00:36:48.400 --> 00:36:50.200]   of what all the aspects of your life.
[00:36:50.200 --> 00:36:52.200]   And then you work backwards from that and say,
[00:36:52.200 --> 00:36:54.800]   what changes do I make to progress closer
[00:36:54.800 --> 00:36:55.720]   towards that vision?
[00:36:55.720 --> 00:36:57.840]   And that will give you a lot more confidence.
[00:36:57.840 --> 00:37:01.480]   And you might find that actually, my job is just fine.
[00:37:01.480 --> 00:37:03.360]   There's other parts of my life I need to update.
[00:37:03.360 --> 00:37:05.160]   Or you might say, no, no, actually,
[00:37:05.160 --> 00:37:07.720]   I need to use my job as the main leverage
[00:37:07.720 --> 00:37:09.360]   for getting this new vision.
[00:37:09.360 --> 00:37:11.280]   But at least now you're changing things
[00:37:11.280 --> 00:37:13.320]   as part of a more coherent vision
[00:37:13.320 --> 00:37:17.360]   and not a sort of more primal or spasmatic switch
[00:37:17.360 --> 00:37:19.040]   between, I don't know, this seems boring,
[00:37:19.040 --> 00:37:21.080]   let's do something else.
[00:37:21.080 --> 00:37:22.680]   So maybe you're a lawyer in the city,
[00:37:22.680 --> 00:37:24.880]   in the suburb of a city, and you're in, you know,
[00:37:24.880 --> 00:37:26.360]   whatever, you're in Northern Virginia,
[00:37:26.360 --> 00:37:28.080]   and you're a lawyer for whatever,
[00:37:28.080 --> 00:37:30.240]   and it's the commute, and it's boring,
[00:37:30.240 --> 00:37:33.180]   and things are expensive, and you have this vision
[00:37:33.180 --> 00:37:36.660]   that, you know, it's a mix between the Gilmore Girls,
[00:37:36.660 --> 00:37:39.320]   but you're near the ocean, and you're walking in the woods
[00:37:39.320 --> 00:37:40.160]   or something like this.
[00:37:40.160 --> 00:37:41.680]   And so then maybe as you're like working
[00:37:41.680 --> 00:37:43.440]   through all the details of this vision,
[00:37:43.440 --> 00:37:45.080]   you realize like I could be an estate,
[00:37:45.080 --> 00:37:49.600]   wills and trust lawyer in a town up in Cape Ann,
[00:37:49.600 --> 00:37:51.920]   you know, north of Boston,
[00:37:51.920 --> 00:37:55.160]   and small town kind of near the water, we live cheaper.
[00:37:55.160 --> 00:37:57.060]   This work is, it's not that the work is more interesting
[00:37:57.060 --> 00:38:02.060]   here, but having a small shingle out up near Newberry Port
[00:38:02.060 --> 00:38:03.800]   allows us to be in this better location
[00:38:03.800 --> 00:38:05.800]   and have more flexibility, and it's near the woods.
[00:38:05.800 --> 00:38:08.000]   And so when you're working from a lifestyle image,
[00:38:08.000 --> 00:38:09.320]   this lifestyle-centric career plan,
[00:38:09.320 --> 00:38:12.080]   you can make these really targeted changes.
[00:38:12.080 --> 00:38:14.200]   'Cause I really, as long-time listeners know,
[00:38:14.200 --> 00:38:17.360]   get very nervous about random or obsessive changes.
[00:38:17.360 --> 00:38:19.560]   I'm just obsessed on this piece, my work's boring.
[00:38:19.560 --> 00:38:20.800]   If I made my work less interesting,
[00:38:20.800 --> 00:38:22.480]   everything's gonna be better.
[00:38:22.480 --> 00:38:24.400]   You gotta have the whole lifestyle image in place.
[00:38:24.400 --> 00:38:25.880]   And when you're fixing this lifestyle image,
[00:38:25.880 --> 00:38:27.680]   keep in mind your job's not supposed
[00:38:27.680 --> 00:38:29.520]   to do everything for you.
[00:38:29.520 --> 00:38:32.040]   Now most of history's people's jobs were boring,
[00:38:32.040 --> 00:38:35.120]   but a lot of people had interesting, meaningful lives.
[00:38:35.120 --> 00:38:37.440]   So you gotta open up the window to the full part
[00:38:37.440 --> 00:38:39.080]   of your life once you start making your plan,
[00:38:39.080 --> 00:38:41.240]   and then you can actually work with the full set of tools
[00:38:41.240 --> 00:38:43.400]   that you have in crafting something deeper.
[00:38:43.400 --> 00:38:46.520]   All right, what do we got next, Jesse?
[00:38:46.520 --> 00:38:48.520]   - Next question's from Dylan.
[00:38:48.520 --> 00:38:49.600]   When it comes to learning,
[00:38:49.600 --> 00:38:52.400]   I often fall victim to deep procrastination.
[00:38:52.400 --> 00:38:55.080]   As a medical student, when I'm revising a topic,
[00:38:55.080 --> 00:38:57.280]   I tend to spend way too much time on a topic.
[00:38:57.280 --> 00:39:00.400]   I feel the urge to read a condition from many sources.
[00:39:00.400 --> 00:39:03.120]   Instead of covering a module in one day,
[00:39:03.120 --> 00:39:05.920]   I end up covering one topic in that entire day.
[00:39:05.920 --> 00:39:08.200]   A few days later, it appears like I haven't retained
[00:39:08.200 --> 00:39:09.600]   any of it very well.
[00:39:09.600 --> 00:39:11.560]   It feels uncomfortable moving on from topic
[00:39:11.560 --> 00:39:13.360]   when my mind still has more questions.
[00:39:13.360 --> 00:39:15.240]   How do I remedy this?
[00:39:15.240 --> 00:39:17.840]   - Well, Dylan, I got good news and bad news.
[00:39:17.840 --> 00:39:21.280]   The good news is what I'm about to tell you is fixable,
[00:39:21.280 --> 00:39:24.400]   and in fact, just knowing it's a problem is half the battle.
[00:39:24.400 --> 00:39:26.600]   The bad news is you're very bad at learning.
[00:39:26.600 --> 00:39:29.440]   I think this is an important point to make
[00:39:29.440 --> 00:39:34.400]   because we don't often contextualize learning
[00:39:34.400 --> 00:39:37.640]   as a skill that has a spectrum of proficiency.
[00:39:38.640 --> 00:39:40.600]   We too often think of learning or studying
[00:39:40.600 --> 00:39:43.720]   as this abstract verb that all that matters
[00:39:43.720 --> 00:39:46.200]   is the quantity of it that you do.
[00:39:46.200 --> 00:39:47.920]   I gotta go study.
[00:39:47.920 --> 00:39:49.600]   I'm gonna study more than this other person.
[00:39:49.600 --> 00:39:52.800]   I'm gonna stay up a couple more hours studying.
[00:39:52.800 --> 00:39:53.920]   And so we just think about this generic thing
[00:39:53.920 --> 00:39:56.600]   that we all do, it's just a matter of how much we do it,
[00:39:56.600 --> 00:39:58.720]   but that's not the case.
[00:39:58.720 --> 00:40:00.680]   You know, I wrote some books about this back in the day,
[00:40:00.680 --> 00:40:03.280]   in particular, "How to Win at College,"
[00:40:03.280 --> 00:40:05.760]   "How to Become a Straight-A Student."
[00:40:05.760 --> 00:40:10.760]   Those books have been out there for 15 years now,
[00:40:10.760 --> 00:40:13.280]   at least, 2006, 2005.
[00:40:13.280 --> 00:40:15.960]   So I used to think a lot about how students actually learn.
[00:40:15.960 --> 00:40:18.560]   And in fact, Jesse, I just got the royalty statements.
[00:40:18.560 --> 00:40:22.280]   Those books are quietly, they quietly move on.
[00:40:22.280 --> 00:40:23.880]   - That's good. - Those three student books,
[00:40:23.880 --> 00:40:28.400]   400,000 copies all in, almost like 275,000,
[00:40:28.400 --> 00:40:30.520]   275,000 on "How to Become a Straight-A Student."
[00:40:30.520 --> 00:40:31.440]   - I mean, they're great books.
[00:40:31.440 --> 00:40:33.560]   - It just sort of trickle, trickle, trickles,
[00:40:33.560 --> 00:40:34.400]   you know, word 'em out.
[00:40:34.400 --> 00:40:37.240]   So you know the stuff is actually right in there.
[00:40:37.240 --> 00:40:38.840]   But what I learned working on those books
[00:40:38.840 --> 00:40:39.800]   is studying is a skill,
[00:40:39.800 --> 00:40:42.760]   and the better you get at it, the better you do.
[00:40:42.760 --> 00:40:46.500]   And so you need to be super specific about how you learn.
[00:40:46.500 --> 00:40:49.000]   And this is probably gonna require
[00:40:49.000 --> 00:40:50.880]   some learning about learning.
[00:40:50.880 --> 00:40:52.080]   So you could read something like my book,
[00:40:52.080 --> 00:40:53.440]   "How to Become a Straight-A Student,"
[00:40:53.440 --> 00:40:56.240]   but it's also going to involve a lot of experimentation.
[00:40:56.240 --> 00:41:00.120]   We talked about this in episode 272.
[00:41:00.120 --> 00:41:02.760]   If you go to the Q&A in that episode,
[00:41:02.760 --> 00:41:04.800]   the number one "New York Times" bestselling author,
[00:41:04.800 --> 00:41:07.760]   David Epstein, joined me in the Q&A
[00:41:07.760 --> 00:41:09.760]   and had some really good ideas
[00:41:09.760 --> 00:41:12.080]   about actually keeping a journal
[00:41:12.080 --> 00:41:14.040]   about all of the various experiments
[00:41:14.040 --> 00:41:15.320]   that you're running in your life
[00:41:15.320 --> 00:41:17.400]   so that you can see what works and what doesn't.
[00:41:17.400 --> 00:41:20.000]   You have to do that with your learning, Dylan.
[00:41:20.000 --> 00:41:22.240]   How do I study cardiology?
[00:41:22.240 --> 00:41:24.440]   How do I break up the work?
[00:41:24.440 --> 00:41:25.760]   Do I copy notes over here?
[00:41:25.760 --> 00:41:26.600]   Do I read things?
[00:41:26.600 --> 00:41:29.000]   Do I go on, like you said in your extended answer,
[00:41:29.000 --> 00:41:31.920]   on the YouTube and start watching videos about it?
[00:41:31.920 --> 00:41:34.360]   Take notes, what works, what didn't?
[00:41:34.360 --> 00:41:37.920]   And then after each exam, go back and do a post-mortem,
[00:41:37.920 --> 00:41:39.520]   what I used to call in the early days
[00:41:39.520 --> 00:41:41.560]   of my calnewport.com newsletter,
[00:41:41.560 --> 00:41:44.480]   a post-exam post-mortem.
[00:41:44.480 --> 00:41:46.440]   Go back and say, what activities did I do
[00:41:46.440 --> 00:41:49.280]   preparing for this exam that mattered?
[00:41:49.280 --> 00:41:50.760]   What didn't help at all?
[00:41:50.760 --> 00:41:52.520]   What was a waste of time?
[00:41:52.520 --> 00:41:53.520]   What should I have done?
[00:41:53.520 --> 00:41:55.160]   What could I have done that would have led
[00:41:55.160 --> 00:41:57.520]   to a larger, better performance that I didn't do?
[00:41:57.520 --> 00:42:00.680]   And you use that feedback to refine your study plan
[00:42:00.680 --> 00:42:02.240]   for the next time around.
[00:42:02.240 --> 00:42:06.160]   Evidence-based evolution of how you actually do this work.
[00:42:06.160 --> 00:42:07.760]   When I read your extended answer, Dylan,
[00:42:07.760 --> 00:42:09.280]   what I see is that you're just doing
[00:42:09.280 --> 00:42:11.560]   all sorts of random stuff for no real reason.
[00:42:11.560 --> 00:42:15.440]   You study like Darwin,
[00:42:15.440 --> 00:42:17.920]   so in an evolution, natural selection type style,
[00:42:17.920 --> 00:42:21.080]   you're gonna get better, better, better really fast.
[00:42:21.080 --> 00:42:23.160]   And you're gonna stop spending all day on a topic
[00:42:23.160 --> 00:42:24.720]   and look at YouTube videos,
[00:42:24.720 --> 00:42:26.720]   and you're gonna get it down to a science.
[00:42:26.720 --> 00:42:27.800]   Here's how you study it.
[00:42:27.800 --> 00:42:28.960]   You make five flashcards,
[00:42:28.960 --> 00:42:30.680]   you wait till you get the flashcards once,
[00:42:30.680 --> 00:42:33.040]   you do one out loud lecture of each topic
[00:42:33.040 --> 00:42:34.280]   in a way that makes sense,
[00:42:34.280 --> 00:42:35.800]   you check it off, you put it in another folder,
[00:42:35.800 --> 00:42:36.800]   you take out the next topic,
[00:42:36.800 --> 00:42:38.680]   we could do seven topics in an hour.
[00:42:38.680 --> 00:42:40.080]   You figure out what works.
[00:42:40.080 --> 00:42:41.400]   And this really is the secret
[00:42:41.400 --> 00:42:42.720]   of the top performing students.
[00:42:42.720 --> 00:42:45.960]   And I know this because I was one of those students.
[00:42:45.960 --> 00:42:48.480]   I started college as a average
[00:42:48.480 --> 00:42:50.720]   or slightly above average student,
[00:42:50.720 --> 00:42:53.160]   freshman at Dartmouth College coming out of public school.
[00:42:53.160 --> 00:42:56.360]   I didn't know how to study with the intensity
[00:42:56.360 --> 00:42:57.600]   of all these private school kids.
[00:42:57.600 --> 00:42:59.840]   I didn't have the background in the math and science
[00:42:59.840 --> 00:43:01.920]   as all these private school kids.
[00:43:01.920 --> 00:43:04.360]   So I was like an average or above average student.
[00:43:04.360 --> 00:43:05.280]   Into my freshman year,
[00:43:05.280 --> 00:43:09.720]   I got very serious about studying how I studied,
[00:43:09.720 --> 00:43:10.680]   taking notes.
[00:43:10.680 --> 00:43:12.760]   Let's try this, let's try that for this type of test.
[00:43:12.760 --> 00:43:14.840]   Let's do this for problem sets, let's try that.
[00:43:14.840 --> 00:43:16.640]   Seeing what worked, seeing what didn't work,
[00:43:16.640 --> 00:43:18.760]   evolving my study habits.
[00:43:18.760 --> 00:43:21.960]   Result of that, four-year GPA,
[00:43:21.960 --> 00:43:23.000]   every quarter sophomore year,
[00:43:23.000 --> 00:43:24.360]   every quarter junior year,
[00:43:24.360 --> 00:43:25.440]   every quarter senior year,
[00:43:25.440 --> 00:43:28.880]   except for my senior spring where I got one A minus.
[00:43:28.880 --> 00:43:31.480]   3.96 or something GPA.
[00:43:31.480 --> 00:43:34.800]   I mean, I was like an A away from being the valedictorian
[00:43:34.800 --> 00:43:38.840]   of the entire graduating class of my Ivy League college.
[00:43:38.840 --> 00:43:41.640]   I didn't get smarter between my freshman year
[00:43:41.640 --> 00:43:43.120]   and the three years that followed.
[00:43:43.120 --> 00:43:44.840]   I got better at studying.
[00:43:44.840 --> 00:43:45.680]   And I'll tell you what,
[00:43:45.680 --> 00:43:47.640]   when I got really professional about this,
[00:43:47.640 --> 00:43:50.200]   the time it took me to study plummeted.
[00:43:50.200 --> 00:43:51.680]   I didn't do all-nighters.
[00:43:51.680 --> 00:43:53.640]   I didn't like studying past 8 p.m.
[00:43:53.640 --> 00:43:55.360]   I would be bored during exam periods
[00:43:55.360 --> 00:43:57.120]   because everyone else was in the library
[00:43:57.120 --> 00:43:58.400]   and I didn't have anything else to do.
[00:43:58.400 --> 00:44:00.520]   It's like one of the reasons why I started writing books.
[00:44:00.520 --> 00:44:02.720]   And what were my initial books about?
[00:44:02.720 --> 00:44:03.880]   How to do what I did.
[00:44:03.880 --> 00:44:05.040]   How do you study like this?
[00:44:05.040 --> 00:44:06.200]   Why are people studying so much?
[00:44:06.200 --> 00:44:07.240]   They need to be better about it.
[00:44:07.240 --> 00:44:08.840]   So I'm really passionate about this, Dylan.
[00:44:08.840 --> 00:44:10.000]   You're bad at learning,
[00:44:10.000 --> 00:44:13.360]   that's tough love, you're bad at it.
[00:44:13.360 --> 00:44:14.360]   But if you get better at it,
[00:44:14.360 --> 00:44:16.720]   your life is gonna get so much better.
[00:44:16.720 --> 00:44:19.480]   And it's not that hard, it's not that hard to learn.
[00:44:19.480 --> 00:44:21.280]   So I have faith that things are gonna get better for you
[00:44:21.280 --> 00:44:22.880]   if you just take your learning more seriously
[00:44:22.880 --> 00:44:25.240]   and stop just in a self-flagellating manner,
[00:44:25.240 --> 00:44:28.360]   just studying until you sort of feel
[00:44:28.360 --> 00:44:29.800]   your guilt has been absolved.
[00:44:29.800 --> 00:44:31.800]   That's not the right way to do it.
[00:44:31.800 --> 00:44:33.240]   So get better at learning, Dylan,
[00:44:33.240 --> 00:44:36.840]   and you're gonna find it's not nearly as hard as you feared.
[00:44:36.840 --> 00:44:38.120]   - What was the A minus in?
[00:44:38.120 --> 00:44:40.360]   - Political philosophy.
[00:44:40.360 --> 00:44:42.600]   I don't hold grudges, but.
[00:44:42.600 --> 00:44:44.200]   (Dylan laughs)
[00:44:44.200 --> 00:44:47.640]   See, I was safe, I was taking a lot of math and science
[00:44:47.640 --> 00:44:50.480]   and computer science courses where it was just,
[00:44:50.480 --> 00:44:52.080]   you could know you were gonna get an A
[00:44:52.080 --> 00:44:53.320]   if you just blew everyone away.
[00:44:53.320 --> 00:44:54.920]   Like I just got more points than everyone else.
[00:44:54.920 --> 00:44:55.760]   - Mm-hmm. - Yeah,
[00:44:55.760 --> 00:44:56.840]   you get to the philosophy course
[00:44:56.840 --> 00:44:58.120]   and it could just be like,
[00:44:58.120 --> 00:45:00.760]   eh, no one should have an A, you know?
[00:45:00.760 --> 00:45:01.720]   It gets a little trickier.
[00:45:01.720 --> 00:45:04.000]   - Yeah. - It's a little trickier.
[00:45:04.000 --> 00:45:05.600]   All right, what do we got next?
[00:45:05.600 --> 00:45:07.440]   - Next question is from Nicole.
[00:45:07.440 --> 00:45:09.000]   Our child is in the sixth grade.
[00:45:09.000 --> 00:45:10.640]   He has no struggles academically.
[00:45:10.640 --> 00:45:12.040]   He's well-adjusted socially,
[00:45:12.040 --> 00:45:13.640]   and he has plenty of friends of all ages
[00:45:13.640 --> 00:45:17.680]   and a sense of community inside and outside of school.
[00:45:17.680 --> 00:45:20.200]   We wanna put him on a path to cultivate the skills required
[00:45:20.200 --> 00:45:22.400]   to later be able to do deep work.
[00:45:22.400 --> 00:45:24.580]   What do you recommend we look for in schools?
[00:45:24.580 --> 00:45:26.280]   We were visiting for middle school,
[00:45:26.280 --> 00:45:28.480]   but also in the future, like in high school.
[00:45:28.480 --> 00:45:31.280]   - I would care less about the school
[00:45:31.280 --> 00:45:35.360]   than I would care about what you are modeling
[00:45:35.360 --> 00:45:36.960]   in your own life.
[00:45:36.960 --> 00:45:39.140]   Now, I don't mean don't care about the school at all,
[00:45:39.140 --> 00:45:41.380]   but when it comes to choosing the school for your kid,
[00:45:41.380 --> 00:45:43.580]   just use the normal common sense stuff
[00:45:43.580 --> 00:45:45.960]   that anyone would think about when choosing a school.
[00:45:45.960 --> 00:45:49.000]   Is it convenient where the location is?
[00:45:49.000 --> 00:45:52.120]   Is his friends there?
[00:45:52.120 --> 00:45:54.860]   Do we like the philosophy?
[00:45:54.860 --> 00:45:56.260]   Does it look like good people?
[00:45:56.260 --> 00:45:57.740]   They run the school well.
[00:45:57.740 --> 00:46:00.060]   Do they have good programs, like stuff he's interested in?
[00:46:00.060 --> 00:46:01.020]   Do they have those programs?
[00:46:01.020 --> 00:46:02.920]   The normal stuff anyone would think about
[00:46:02.920 --> 00:46:05.700]   if they're choosing a school, that's fine.
[00:46:05.700 --> 00:46:07.420]   But when it comes to this more advanced stuff,
[00:46:07.420 --> 00:46:10.980]   like, well, we want him to be a deep thinker,
[00:46:10.980 --> 00:46:14.180]   an intellectual, someone who can really succeed
[00:46:14.180 --> 00:46:15.240]   in an intellectual standpoint,
[00:46:15.240 --> 00:46:17.240]   there your modeling's gonna matter more.
[00:46:17.240 --> 00:46:20.020]   They see that you prioritize this.
[00:46:20.020 --> 00:46:22.080]   They see that you have a life of the mind.
[00:46:22.080 --> 00:46:25.060]   They see you're engaged with books and ideas.
[00:46:25.060 --> 00:46:27.420]   They see that you're not on your phone all the time.
[00:46:27.420 --> 00:46:29.380]   This stuff makes a big difference.
[00:46:29.380 --> 00:46:31.140]   The other thing that matters at home here
[00:46:31.140 --> 00:46:32.480]   is just more pragmatically,
[00:46:32.480 --> 00:46:35.500]   making sure that your sixth grader going on seventh grader,
[00:46:35.500 --> 00:46:38.140]   that they do not have unrestricted access
[00:46:38.140 --> 00:46:39.640]   to these dopamine hacking,
[00:46:39.640 --> 00:46:41.900]   smartphone delivered,
[00:46:41.900 --> 00:46:43.700]   attention economy platform applications,
[00:46:43.700 --> 00:46:46.140]   like we talked about in the deep dive.
[00:46:46.140 --> 00:46:46.980]   That's just like saying,
[00:46:46.980 --> 00:46:48.700]   make sure that my aspiring athlete
[00:46:48.700 --> 00:46:50.020]   doesn't get a smoking habit.
[00:46:50.020 --> 00:46:51.820]   So yes, you do wanna make sure that you're not,
[00:46:51.820 --> 00:46:53.640]   you could short circuit everything
[00:46:53.640 --> 00:46:57.600]   by giving your 12 year old unrestricted access
[00:46:57.600 --> 00:46:59.620]   to the internet through a phone.
[00:46:59.620 --> 00:47:00.980]   When they say all my friends are doing it,
[00:47:00.980 --> 00:47:03.180]   you say that you're unlucky.
[00:47:03.180 --> 00:47:04.580]   Your parents listen to Cal Newport.
[00:47:04.580 --> 00:47:06.180]   You don't get a smartphone.
[00:47:06.180 --> 00:47:07.840]   And that's just gonna have to be that.
[00:47:07.840 --> 00:47:09.660]   So yes, keep them away from
[00:47:09.660 --> 00:47:12.020]   complete brain short circuiting distraction
[00:47:12.020 --> 00:47:14.860]   that a sixth or seventh grader cannot handle.
[00:47:14.860 --> 00:47:16.620]   Model a life of the mind,
[00:47:16.620 --> 00:47:19.040]   of respect for deep work and intellectualism.
[00:47:19.900 --> 00:47:22.540]   And then beyond that, just choose a good school.
[00:47:22.540 --> 00:47:24.180]   This stuff really makes a big difference.
[00:47:24.180 --> 00:47:26.140]   Like for example, in my own life,
[00:47:26.140 --> 00:47:28.460]   for whatever reason,
[00:47:28.460 --> 00:47:33.160]   growing up my dad really admired mathematicians
[00:47:33.160 --> 00:47:36.100]   and theoretical physicists of extreme intellect.
[00:47:36.100 --> 00:47:39.080]   So we heard a lot growing up about Richard Feynman.
[00:47:39.080 --> 00:47:41.940]   We heard a lot growing up about John von Neumann.
[00:47:41.940 --> 00:47:44.080]   This idea of just these like big brains
[00:47:44.080 --> 00:47:45.820]   that could manipulate ideas in their heads
[00:47:45.820 --> 00:47:46.660]   and just produce ideas.
[00:47:46.660 --> 00:47:48.340]   We just heard a lot about it.
[00:47:48.340 --> 00:47:50.300]   My dad was really interested in all that.
[00:47:50.300 --> 00:47:51.220]   And it really made a difference.
[00:47:51.220 --> 00:47:56.220]   So when I was going to MIT out of college,
[00:47:56.220 --> 00:47:58.380]   I was not known as a math person.
[00:47:58.380 --> 00:47:59.900]   I was not known as a theory person.
[00:47:59.900 --> 00:48:03.060]   I was being recruited to work in systems groups.
[00:48:03.060 --> 00:48:06.000]   And I sort of tricked my way into a theory group
[00:48:06.000 --> 00:48:08.300]   because I had just grown up with this idea
[00:48:08.300 --> 00:48:09.660]   that is there anything cooler to do
[00:48:09.660 --> 00:48:10.760]   if you're capable of doing it
[00:48:10.760 --> 00:48:13.100]   than staring at a whiteboard and solving math equations.
[00:48:13.100 --> 00:48:15.300]   And so I tricked my way into a theory group by saying,
[00:48:15.300 --> 00:48:16.940]   I'll do systems work for you.
[00:48:16.940 --> 00:48:18.420]   And then as soon as I got to the theory group,
[00:48:18.420 --> 00:48:19.660]   I said, nevermind, I'm gonna do theory.
[00:48:19.660 --> 00:48:21.820]   And I just made myself into a theoretician.
[00:48:21.820 --> 00:48:23.180]   It's because of what I grew up with,
[00:48:23.180 --> 00:48:24.980]   what I was surrounded by.
[00:48:24.980 --> 00:48:27.260]   So model a life of the mind.
[00:48:27.260 --> 00:48:29.660]   Model a life that respects the mind
[00:48:29.660 --> 00:48:31.220]   and isn't staring at screens all day.
[00:48:31.220 --> 00:48:33.280]   Model a life that's engaged and that's reads.
[00:48:33.280 --> 00:48:34.960]   Have a house full of books.
[00:48:34.960 --> 00:48:37.540]   Talk about people you admire in the different types of,
[00:48:37.540 --> 00:48:38.940]   it doesn't have to be professors,
[00:48:38.940 --> 00:48:41.200]   it could be artists or filmmakers or poets,
[00:48:41.200 --> 00:48:43.200]   but these great thinkers that you admire,
[00:48:43.200 --> 00:48:47.520]   let your kids see that and keep them away from TikTok.
[00:48:47.520 --> 00:48:51.520]   Do those two things and give them a fine school.
[00:48:51.520 --> 00:48:53.080]   Don't overthink that.
[00:48:53.080 --> 00:48:55.400]   You're doing everything you can.
[00:48:55.400 --> 00:48:57.800]   You're not gonna be able to engineer your kid.
[00:48:57.800 --> 00:48:58.640]   We see a lot of that.
[00:48:58.640 --> 00:49:00.040]   This is a real DC suburb thing.
[00:49:00.040 --> 00:49:03.020]   That if I just get the right supplemental activities
[00:49:03.020 --> 00:49:04.600]   and tutoring and do all these things,
[00:49:04.600 --> 00:49:07.160]   I can engineer my kid into a great brain.
[00:49:07.160 --> 00:49:09.160]   But if I don't do that, they're not gonna get there.
[00:49:09.160 --> 00:49:10.540]   And it's like, here's the spoiler alert.
[00:49:10.540 --> 00:49:12.000]   If your kid's gonna be an intellect
[00:49:12.000 --> 00:49:13.680]   and have a career as an intellectual,
[00:49:13.680 --> 00:49:17.660]   it's not gonna be because you got them in Russian math.
[00:49:17.660 --> 00:49:20.560]   And so you doing that or not doing it
[00:49:20.560 --> 00:49:22.240]   is not gonna make a difference.
[00:49:22.240 --> 00:49:25.400]   If they're seeing that, they have the right brain for it,
[00:49:25.400 --> 00:49:27.040]   that's where they'll end up.
[00:49:27.040 --> 00:49:28.260]   And if they don't, there's nothing you can do
[00:49:28.260 --> 00:49:30.120]   that's gonna make that happen.
[00:49:30.120 --> 00:49:31.560]   So you could just relax a little bit.
[00:49:31.560 --> 00:49:34.200]   Model what's important to you.
[00:49:34.200 --> 00:49:36.480]   Keep them away from brain melting stuff.
[00:49:36.480 --> 00:49:37.560]   And then you're gonna have to let the kid do
[00:49:37.560 --> 00:49:39.280]   what the kid's gonna do.
[00:49:41.360 --> 00:49:43.000]   - All right, what do we got next?
[00:49:43.000 --> 00:49:44.760]   - Next question's from Mara.
[00:49:44.760 --> 00:49:48.240]   I'm a junior UX designer working at a consultant agency.
[00:49:48.240 --> 00:49:49.560]   And I would like to hear your opinion
[00:49:49.560 --> 00:49:51.180]   on balancing time after work
[00:49:51.180 --> 00:49:52.920]   and taking time to reflect on things
[00:49:52.920 --> 00:49:55.080]   that happened during the working day.
[00:49:55.080 --> 00:49:58.080]   After I finished my day, I'm usually pretty done mentally.
[00:49:58.080 --> 00:49:59.420]   And I just wanna close everything
[00:49:59.420 --> 00:50:01.260]   and not be in a seat anymore.
[00:50:01.260 --> 00:50:04.160]   If I come back later to reflect on work or learning,
[00:50:04.160 --> 00:50:06.740]   I often end up feeling like I need to check something,
[00:50:06.740 --> 00:50:08.200]   then I end up doing work.
[00:50:08.200 --> 00:50:10.880]   Do you have any suggestions or practices
[00:50:10.880 --> 00:50:13.160]   to incorporate time to reflect on learnings
[00:50:13.160 --> 00:50:16.960]   and feelings and ideas that are not strictly work output,
[00:50:16.960 --> 00:50:18.840]   but are work-related?
[00:50:18.840 --> 00:50:20.720]   - Mara, I've got two suggestions.
[00:50:20.720 --> 00:50:24.080]   One, integrate the reflection, the closing of loops,
[00:50:24.080 --> 00:50:27.060]   the engagement with how you feel about things.
[00:50:27.060 --> 00:50:28.120]   You need to integrate that
[00:50:28.120 --> 00:50:30.920]   into the work you do throughout the day.
[00:50:30.920 --> 00:50:35.060]   So what a lot of people do is calendar filling.
[00:50:35.060 --> 00:50:37.760]   Let me try to fill every minute of my day.
[00:50:37.760 --> 00:50:39.360]   And I rush through it full speed
[00:50:39.360 --> 00:50:41.200]   from meeting in the meeting, jumping over here,
[00:50:41.200 --> 00:50:42.040]   jumping over there.
[00:50:42.040 --> 00:50:43.460]   It's like this adrenaline high day.
[00:50:43.460 --> 00:50:44.520]   And you get to the end of the day and say,
[00:50:44.520 --> 00:50:46.400]   "My God, how do I make sense of all this?"
[00:50:46.400 --> 00:50:48.200]   And then you get just lost.
[00:50:48.200 --> 00:50:49.920]   You're exhausted.
[00:50:49.920 --> 00:50:51.280]   And then you get lost just trying to like
[00:50:51.280 --> 00:50:52.120]   make sense of everything.
[00:50:52.120 --> 00:50:54.880]   You're in email and it just spirals out of control.
[00:50:54.880 --> 00:50:56.080]   And either you abandon it,
[00:50:56.080 --> 00:50:57.600]   or like a lot of people these days,
[00:50:57.600 --> 00:50:59.560]   you have the second shift where you're spending hours
[00:50:59.560 --> 00:51:00.640]   on your computer at night.
[00:51:00.640 --> 00:51:01.480]   And that's how you're even just
[00:51:01.480 --> 00:51:02.880]   trying to grapple these things.
[00:51:02.880 --> 00:51:05.160]   The solution is to deal with things each day
[00:51:05.160 --> 00:51:06.200]   as they come up,
[00:51:06.200 --> 00:51:08.800]   which means you have to put aside the time to do that.
[00:51:09.640 --> 00:51:12.200]   So if I'm scheduling a meeting,
[00:51:12.200 --> 00:51:15.000]   we have a Zoom call, I'm putting an hour on my calendar.
[00:51:15.000 --> 00:51:16.520]   I'm adding another 15 minutes
[00:51:16.520 --> 00:51:18.520]   to the end of that appointment for processing.
[00:51:18.520 --> 00:51:20.440]   That time is now protected.
[00:51:20.440 --> 00:51:21.960]   So after this meeting is over,
[00:51:21.960 --> 00:51:24.240]   there's a 15 minutes of protected time
[00:51:24.240 --> 00:51:26.520]   to process everything from that meeting.
[00:51:26.520 --> 00:51:28.560]   Let me update my to-do list on my calendar.
[00:51:28.560 --> 00:51:30.800]   Let me walk around the block and think about this.
[00:51:30.800 --> 00:51:33.460]   Okay, now I am gonna send my response email.
[00:51:33.460 --> 00:51:35.000]   I know how to deal with this.
[00:51:35.000 --> 00:51:36.660]   Now I can close the loop on that
[00:51:36.660 --> 00:51:38.640]   before I move on to the next thing.
[00:51:38.640 --> 00:51:42.720]   Do the same type of post session loop closing session
[00:51:42.720 --> 00:51:44.880]   after long deep work blocks as well.
[00:51:44.880 --> 00:51:46.560]   You know, I'm working on this project
[00:51:46.560 --> 00:51:47.480]   for the next two hours.
[00:51:47.480 --> 00:51:49.440]   Well, what I'm gonna do is put 30 minutes
[00:51:49.440 --> 00:51:51.240]   or 20 minutes at the end of that,
[00:51:51.240 --> 00:51:53.400]   not to keep working,
[00:51:53.400 --> 00:51:56.040]   but to wrap up what I was working on.
[00:51:56.040 --> 00:51:57.800]   Figure out what I'm gonna work on next,
[00:51:57.800 --> 00:51:59.440]   send out the request I need
[00:51:59.440 --> 00:52:01.120]   for the information I didn't have,
[00:52:01.120 --> 00:52:02.280]   schedule on my calendar
[00:52:02.280 --> 00:52:04.080]   when I'm gonna return to this again,
[00:52:04.080 --> 00:52:05.160]   close that loop,
[00:52:05.160 --> 00:52:06.720]   maybe have an extra five minutes left
[00:52:06.720 --> 00:52:07.840]   just to go for a walk
[00:52:07.840 --> 00:52:09.440]   or just completely clear my mind.
[00:52:09.440 --> 00:52:12.120]   So you need to close the loops on things
[00:52:12.120 --> 00:52:13.620]   as they go throughout the day.
[00:52:13.620 --> 00:52:15.680]   You do not get a prize
[00:52:15.680 --> 00:52:17.400]   for squeezing in these extra things.
[00:52:17.400 --> 00:52:19.400]   In the long run, it doesn't mean you get more done.
[00:52:19.400 --> 00:52:20.240]   It just exhausts you
[00:52:20.240 --> 00:52:22.160]   and makes you less productive anyways.
[00:52:22.160 --> 00:52:24.260]   So spend more time on the things
[00:52:24.260 --> 00:52:26.600]   that you're gonna spend time on.
[00:52:26.600 --> 00:52:28.080]   Give yourself time to close down.
[00:52:28.080 --> 00:52:29.120]   All right, so what's the second thing
[00:52:29.120 --> 00:52:30.980]   I'm gonna recommend?
[00:52:30.980 --> 00:52:32.180]   Have a good shutdown ritual.
[00:52:32.180 --> 00:52:34.640]   It sounds like you don't have a good shutdown ritual.
[00:52:34.640 --> 00:52:37.800]   If thinking about your work as you say,
[00:52:37.800 --> 00:52:39.640]   thinking about your work at the end of the day
[00:52:39.640 --> 00:52:41.220]   leads you back into work and email,
[00:52:41.220 --> 00:52:43.440]   you're not really shutting down.
[00:52:43.440 --> 00:52:45.660]   So you need a good shutdown ritual.
[00:52:45.660 --> 00:52:47.400]   You close enough loops to be confident
[00:52:47.400 --> 00:52:48.580]   you're not forgetting anything.
[00:52:48.580 --> 00:52:51.120]   Even if it's just you frantically writing down things
[00:52:51.120 --> 00:52:52.620]   on a piece of paper to get back to
[00:52:52.620 --> 00:52:54.720]   and putting a half hour appointment in your morning
[00:52:54.720 --> 00:52:56.160]   the next day to process it,
[00:52:56.160 --> 00:52:58.420]   you're making sure that nothing is floating out there
[00:52:58.420 --> 00:53:00.040]   that you have to remember.
[00:53:00.040 --> 00:53:03.040]   And then you have some sort of shutdown routine,
[00:53:03.040 --> 00:53:04.600]   a phrase you say,
[00:53:04.600 --> 00:53:06.560]   the shutdown complete checkbox
[00:53:06.560 --> 00:53:09.400]   on the top of every day in my time block plan
[00:53:09.400 --> 00:53:10.480]   or however you wanna do it.
[00:53:10.480 --> 00:53:12.760]   And when you're shut down, you're shut down.
[00:53:12.760 --> 00:53:14.320]   There is no wandering back in the email
[00:53:14.320 --> 00:53:16.480]   when you're shut down, you're shut down.
[00:53:16.480 --> 00:53:18.560]   So close loops after the things,
[00:53:18.560 --> 00:53:20.520]   right after they happen during your day
[00:53:20.520 --> 00:53:22.900]   and close your day with a better shutdown routine.
[00:53:22.900 --> 00:53:24.160]   I think you're gonna be less stressed.
[00:53:24.160 --> 00:53:25.000]   You're gonna work less.
[00:53:25.000 --> 00:53:27.760]   Your brain's gonna be better and you're gonna be happier.
[00:53:27.760 --> 00:53:29.620]   All right, let's keep rolling.
[00:53:29.620 --> 00:53:31.120]   What do we got next, Jesse?
[00:53:31.120 --> 00:53:32.960]   - All right, next question's from Brian.
[00:53:32.960 --> 00:53:35.440]   I just finished reading Scott Young's book,
[00:53:35.440 --> 00:53:37.840]   "Ultra Learning" and wondered what your thoughts were
[00:53:37.840 --> 00:53:39.440]   on how the concepts in that book
[00:53:39.440 --> 00:53:41.800]   interact with slow productivity.
[00:53:41.800 --> 00:53:43.880]   I wanna get up to speed as quickly as possible
[00:53:43.880 --> 00:53:46.160]   on my new career while keeping the concepts
[00:53:46.160 --> 00:53:49.400]   and practices of slow productivity in mind.
[00:53:49.400 --> 00:53:51.320]   - Well, I was just talking to Scott yesterday, Brian.
[00:53:51.320 --> 00:53:54.080]   So this is a timely question.
[00:53:54.080 --> 00:53:56.720]   There's zero conflict
[00:53:56.720 --> 00:54:01.080]   between ultra learning and slow productivity.
[00:54:01.080 --> 00:54:03.400]   I think what might be happening is
[00:54:03.720 --> 00:54:06.520]   you're changing the definition of ultra productivity
[00:54:06.520 --> 00:54:08.360]   to somehow, or ultra learning
[00:54:08.360 --> 00:54:10.680]   to somehow mean super fast learning
[00:54:10.680 --> 00:54:13.800]   or learning all day long.
[00:54:13.800 --> 00:54:17.280]   But if you read "Ultra Learning," a book I really enjoy,
[00:54:17.280 --> 00:54:19.120]   what you'll see is it's about
[00:54:19.120 --> 00:54:21.780]   how do you learn really hard things,
[00:54:21.780 --> 00:54:23.240]   things you might've thought like,
[00:54:23.240 --> 00:54:25.480]   this is harder than I would be able to do.
[00:54:25.480 --> 00:54:28.920]   How do you raise your ambition for learning?
[00:54:28.920 --> 00:54:30.640]   And the answer is it has to do with the techniques
[00:54:30.640 --> 00:54:32.520]   you use to actually learn.
[00:54:32.520 --> 00:54:35.760]   You have to learn how people who learn really hard things
[00:54:35.760 --> 00:54:36.820]   or really ambitious things,
[00:54:36.820 --> 00:54:38.320]   how do they approach this task?
[00:54:38.320 --> 00:54:39.780]   You can't just go at it randomly
[00:54:39.780 --> 00:54:41.200]   like we had in a previous question.
[00:54:41.200 --> 00:54:42.920]   In ultra learning, Scott says,
[00:54:42.920 --> 00:54:45.200]   here are these principles you need
[00:54:45.200 --> 00:54:47.080]   that people who learn hard things use.
[00:54:47.080 --> 00:54:50.640]   Now, the pace at which you learn hard things is up to you.
[00:54:50.640 --> 00:54:54.620]   The quantity of hard things you learn, that's up to you.
[00:54:54.620 --> 00:54:56.640]   If anything, ultra learning is a type of skill
[00:54:56.640 --> 00:54:59.840]   you would see a slow productivity practitioner deploying.
[00:55:00.940 --> 00:55:03.940]   They're saying, okay, I'm going to, over time,
[00:55:03.940 --> 00:55:06.540]   in my obsession over quality,
[00:55:06.540 --> 00:55:07.820]   principle three of slow productivity,
[00:55:07.820 --> 00:55:10.060]   master this really complicated thing.
[00:55:10.060 --> 00:55:12.280]   Because once I've mastered this really complicated thing,
[00:55:12.280 --> 00:55:14.620]   it's gonna open up way more possibilities.
[00:55:14.620 --> 00:55:15.460]   It could be, if anything,
[00:55:15.460 --> 00:55:17.380]   like a classic slow productivity move,
[00:55:17.380 --> 00:55:19.440]   whereas a fast productivity practitioner would say,
[00:55:19.440 --> 00:55:21.180]   I don't have time for that.
[00:55:21.180 --> 00:55:23.220]   I just need to be frenetic all day.
[00:55:23.220 --> 00:55:24.940]   I need to be emailing and jumping around in meetings.
[00:55:24.940 --> 00:55:25.780]   That's too slow.
[00:55:25.780 --> 00:55:26.700]   Ultra learning is too slow.
[00:55:26.700 --> 00:55:28.340]   I don't have time to master
[00:55:28.340 --> 00:55:31.580]   this really difficult new body of mathematics
[00:55:31.580 --> 00:55:33.820]   that's gonna help me in my career.
[00:55:33.820 --> 00:55:36.820]   I'm gonna send emails and do TikTok videos.
[00:55:36.820 --> 00:55:39.760]   So ultra learning, I think, is one of the key tools
[00:55:39.760 --> 00:55:42.840]   in the toolkit of the slow productivity practitioner,
[00:55:42.840 --> 00:55:44.900]   not something that sits contrary to it.
[00:55:44.900 --> 00:55:46.900]   It's a really cool book,
[00:55:46.900 --> 00:55:48.780]   and I recommend that you check it out.
[00:55:48.780 --> 00:55:51.100]   Should we try a call, Jesse?
[00:55:51.100 --> 00:55:51.940]   - Yeah. - All right.
[00:55:51.940 --> 00:55:53.140]   Let's see if this works.
[00:55:53.140 --> 00:55:53.980]   - All right.
[00:55:53.980 --> 00:55:56.260]   - Hi, Cal.
[00:55:56.260 --> 00:55:57.660]   What would you recommend for someone
[00:55:57.660 --> 00:56:02.140]   who's seriously learning and pursuing multiple avenues,
[00:56:02.140 --> 00:56:06.460]   in my case, music, graphic design, and copywriting,
[00:56:06.460 --> 00:56:08.880]   while working a full-time job?
[00:56:08.880 --> 00:56:14.300]   I'm a delivery driver, and I work 40 to 50 hours a week.
[00:56:14.300 --> 00:56:15.120]   Thank you.
[00:56:15.120 --> 00:56:19.460]   - Well, Randall, I'm gonna differentiate here,
[00:56:19.460 --> 00:56:23.020]   or ask for you to differentiate between hobbies
[00:56:24.020 --> 00:56:27.900]   and a systematic plan to learn a skill
[00:56:27.900 --> 00:56:30.820]   as part of a bigger picture, vision, or strategy you have.
[00:56:30.820 --> 00:56:33.260]   So if there's something that's a hobby,
[00:56:33.260 --> 00:56:36.140]   I'm interested in music, I like playing music,
[00:56:36.140 --> 00:56:39.140]   the key there is you wanna integrate this into your life,
[00:56:39.140 --> 00:56:41.460]   but give yourself grace.
[00:56:41.460 --> 00:56:42.660]   Now, there's busier periods
[00:56:42.660 --> 00:56:43.780]   where I'm not able to do it as much,
[00:56:43.780 --> 00:56:45.260]   but I try to play most evenings,
[00:56:45.260 --> 00:56:47.060]   and I've set myself up for success.
[00:56:47.060 --> 00:56:49.980]   And I talk about this in "Digital Minimalism," by the way,
[00:56:49.980 --> 00:56:52.240]   how to build plans for leisure activities
[00:56:52.240 --> 00:56:55.060]   where you, instead of just randomly do it,
[00:56:55.060 --> 00:56:56.020]   you say, "Okay, I'm not just gonna
[00:56:56.020 --> 00:56:57.820]   "randomly noodle on my guitar.
[00:56:57.820 --> 00:57:00.800]   "I'm gonna learn all the songs from this album
[00:57:00.800 --> 00:57:02.420]   "to play at this party in six months."
[00:57:02.420 --> 00:57:04.100]   So you might build up some structure,
[00:57:04.100 --> 00:57:06.180]   and I call it structured leisure.
[00:57:06.180 --> 00:57:07.820]   But you give yourself some grace.
[00:57:07.820 --> 00:57:11.060]   I do this 'cause I enjoy it, I listen to music,
[00:57:11.060 --> 00:57:13.420]   and so I feel more meaningful when I'm learning music,
[00:57:13.420 --> 00:57:15.500]   I'm immersing myself in it, but if I have a busy,
[00:57:15.500 --> 00:57:17.420]   I'm taking two shifts, and it's a busy week,
[00:57:17.420 --> 00:57:19.480]   and I just don't get to it, who cares?
[00:57:19.480 --> 00:57:21.820]   It's there to make my life better,
[00:57:21.820 --> 00:57:23.000]   not to make my life harder.
[00:57:23.000 --> 00:57:24.080]   Now let's say there's something in here
[00:57:24.080 --> 00:57:26.600]   that's part of a structured strategy
[00:57:26.600 --> 00:57:31.140]   for improving or changing your life in a very specific way.
[00:57:31.140 --> 00:57:35.740]   I'm learning graphic design 'cause this job,
[00:57:35.740 --> 00:57:37.800]   which I've convinced myself would be available to me
[00:57:37.800 --> 00:57:40.560]   if I built these skills, would allow me to implement this.
[00:57:40.560 --> 00:57:43.380]   I could reduce my delivery hours and do this consulting.
[00:57:43.380 --> 00:57:44.460]   It's part of this bigger strategy
[00:57:44.460 --> 00:57:46.920]   that gets me closer to my ideal lifestyle vision.
[00:57:46.920 --> 00:57:51.620]   In that case, you do need to be a little bit more systematic.
[00:57:51.620 --> 00:57:54.340]   You schedule time like that, like you would with the doctor.
[00:57:54.340 --> 00:57:56.180]   I do it first thing in the morning,
[00:57:56.180 --> 00:57:57.540]   Fridays after my half shift.
[00:57:57.540 --> 00:57:59.020]   You have to be very systematic
[00:57:59.020 --> 00:58:01.780]   about where that work happens, how I do that work,
[00:58:01.780 --> 00:58:03.400]   how I make sure I'm making progress.
[00:58:03.400 --> 00:58:04.460]   There might be some nights there,
[00:58:04.460 --> 00:58:06.300]   there might be some early mornings there.
[00:58:06.300 --> 00:58:08.700]   It might be some pain that you're going through
[00:58:08.700 --> 00:58:10.960]   because you know it's gonna deliver something good.
[00:58:10.960 --> 00:58:13.160]   Just don't mix those two things up.
[00:58:13.160 --> 00:58:15.820]   Don't mix up the leisure that's giving you
[00:58:15.820 --> 00:58:18.580]   release or relaxation from the systematic acquisition
[00:58:18.580 --> 00:58:19.580]   of a new skill that's gonna get you
[00:58:19.580 --> 00:58:21.620]   closer to your lifestyle.
[00:58:21.620 --> 00:58:22.700]   And just treat those differently.
[00:58:22.700 --> 00:58:25.060]   'Cause if you make everything a necessity,
[00:58:25.060 --> 00:58:27.020]   it becomes impossible and you beat yourself up
[00:58:27.020 --> 00:58:28.780]   and you might stop doing everything.
[00:58:28.780 --> 00:58:31.080]   To be very reasonable about,
[00:58:31.080 --> 00:58:33.480]   these are the things I'm systematically pursuing.
[00:58:33.480 --> 00:58:36.320]   And don't have too much of those.
[00:58:36.320 --> 00:58:39.580]   You know, just only be realistic about your capacity
[00:58:39.580 --> 00:58:41.860]   and keep everything else a little bit looser.
[00:58:41.860 --> 00:58:45.180]   I think that's gonna be the best way to balance those.
[00:58:45.180 --> 00:58:46.900]   I wanna read a quick case study
[00:58:48.060 --> 00:58:50.220]   that was sent in by Cage,
[00:58:50.220 --> 00:58:52.060]   who says the following.
[00:58:52.060 --> 00:58:54.900]   Cage says, "I bought 'How to Become a Straight A Student'
[00:58:54.900 --> 00:58:58.860]   "and 'Deep Work'," reading the former multiple times over.
[00:58:58.860 --> 00:58:59.840]   "Through techniques in the book,
[00:58:59.840 --> 00:59:01.380]   "I have fully recovered my GPA
[00:59:01.380 --> 00:59:03.480]   "into Magna Summa Cum Laude Condition
[00:59:03.480 --> 00:59:06.240]   "and have been on the Dean's List
[00:59:06.240 --> 00:59:08.100]   "since coming back to school,
[00:59:08.100 --> 00:59:09.460]   "while managing a research position
[00:59:09.460 --> 00:59:11.680]   "in two internships in conjunction with my schooling.
[00:59:11.680 --> 00:59:12.900]   "One thing I would like to highlight
[00:59:12.900 --> 00:59:17.100]   "is the benefit I've found in the quantification of goals
[00:59:17.100 --> 00:59:20.260]   "in regards to their estimated time.
[00:59:20.260 --> 00:59:22.380]   "I have created a task planner in Excel
[00:59:22.380 --> 00:59:24.520]   "that I will readily admit is both over-engineered
[00:59:24.520 --> 00:59:27.060]   "and integral to my daily life.
[00:59:27.060 --> 00:59:30.360]   "It contains rows for all my projects, school or otherwise.
[00:59:30.360 --> 00:59:32.740]   "The first column is the day I put into the planner.
[00:59:32.740 --> 00:59:34.360]   "The second is the project name.
[00:59:34.360 --> 00:59:35.980]   "The third is the due date.
[00:59:35.980 --> 00:59:38.460]   "The fourth is the days left."
[00:59:38.460 --> 00:59:40.660]   So the current date minus the due date.
[00:59:40.660 --> 00:59:43.200]   "The fifth is the class or job it is for,
[00:59:43.200 --> 00:59:46.420]   "and the sixth is the estimated time it will take.
[00:59:46.420 --> 00:59:48.200]   "The seventh is the percentage complete,
[00:59:48.200 --> 00:59:52.180]   "and the eighth is the time left in the project."
[00:59:52.180 --> 00:59:54.020]   Cage gives an equation for this.
[00:59:54.020 --> 00:59:56.420]   Estimated time minus quantity,
[00:59:56.420 --> 00:59:58.720]   estimated time times percentage complete.
[00:59:58.720 --> 01:00:01.620]   And the eighth, well, there's eight columns.
[01:00:01.620 --> 01:00:03.660]   "And the eighth is the time left per day.
[01:00:03.660 --> 01:00:06.100]   "When I designed this system,
[01:00:06.100 --> 01:00:07.760]   "I had no idea how much the estimated time
[01:00:07.760 --> 01:00:09.820]   "and time left per day would change my life.
[01:00:09.820 --> 01:00:12.580]   "Though not perfect, I can usually guess within an hour
[01:00:12.580 --> 01:00:14.660]   "how extensive a project is going to be.
[01:00:14.660 --> 01:00:17.800]   "Through this system, I am able to flag projects due in a day
[01:00:17.800 --> 01:00:20.820]   "and with the exception of those,
[01:00:20.820 --> 01:00:23.400]   "tackle problems based on the time left per day.
[01:00:23.400 --> 01:00:25.520]   "This keeps big research papers from distracting me
[01:00:25.520 --> 01:00:27.300]   "from smaller projects that are coming up fast,
[01:00:27.300 --> 01:00:29.080]   "while still allowing me to ensure I attack them
[01:00:29.080 --> 01:00:31.480]   "in a timely manner without procrastinating.
[01:00:31.480 --> 01:00:33.660]   "This triaging has been essential to my life,
[01:00:33.660 --> 01:00:35.220]   "and now this Excel project
[01:00:35.220 --> 01:00:37.460]   "has essentially become my time block planner.
[01:00:37.460 --> 01:00:39.700]   "Additionally, I can see exactly how many hours per day
[01:00:39.700 --> 01:00:41.980]   "I have work in total I have done,
[01:00:41.980 --> 01:00:43.520]   "how many projects I have open,
[01:00:43.520 --> 01:00:45.740]   "how many I've completed, and much more.
[01:00:45.740 --> 01:00:47.400]   "The reason I bring this up is because I think that
[01:00:47.400 --> 01:00:48.620]   "this sort of quantification
[01:00:48.620 --> 01:00:50.360]   "allows for major stress reduction
[01:00:50.360 --> 01:00:54.060]   "and preventing things from creeping up."
[01:00:54.060 --> 01:00:56.860]   It's a very complicated system,
[01:00:56.860 --> 01:00:58.740]   probably more complicated than I would recommend
[01:00:58.740 --> 01:01:01.340]   for most people, unless that's the type of thing you like.
[01:01:01.340 --> 01:01:04.540]   But what I wanna highlight about Cage's approach
[01:01:04.540 --> 01:01:07.260]   is he's controlling his time
[01:01:07.260 --> 01:01:11.060]   by being realistic about what's on his plate,
[01:01:11.060 --> 01:01:12.100]   how long it takes.
[01:01:13.040 --> 01:01:15.440]   You don't necessarily have to have eight columns
[01:01:15.440 --> 01:01:17.920]   with equations to get there, though that's one way to do it.
[01:01:17.920 --> 01:01:20.000]   People who just use basic time blocking,
[01:01:20.000 --> 01:01:22.160]   so people who use my time block planner
[01:01:22.160 --> 01:01:24.020]   just in its basic form, for example,
[01:01:24.020 --> 01:01:25.660]   get 80% of that benefit,
[01:01:25.660 --> 01:01:28.400]   because when you're blocking off time for things
[01:01:28.400 --> 01:01:30.440]   and having to adjust your schedule,
[01:01:30.440 --> 01:01:34.240]   every time something goes past the block you gave it,
[01:01:34.240 --> 01:01:37.000]   you begin to get a realistic feel for your timing.
[01:01:37.000 --> 01:01:38.800]   It's why if you do weekly planning,
[01:01:38.800 --> 01:01:41.500]   over time this feedback tells you,
[01:01:41.500 --> 01:01:43.880]   "Oh, I thought I would just edit this article this week.
[01:01:43.880 --> 01:01:45.380]   "I didn't get anywhere near finishing it.
[01:01:45.380 --> 01:01:47.640]   "This is really a month-long project."
[01:01:47.640 --> 01:01:49.480]   So when you quantify, you get this feedback
[01:01:49.480 --> 01:01:51.240]   on how long things actually take,
[01:01:51.240 --> 01:01:52.360]   because you're being specific
[01:01:52.360 --> 01:01:53.700]   about when you're gonna do things
[01:01:53.700 --> 01:01:55.480]   and how long you think they'll take.
[01:01:55.480 --> 01:01:57.480]   This gives you, like Cage talks about,
[01:01:57.480 --> 01:01:59.600]   this more realistic understanding
[01:01:59.600 --> 01:02:01.680]   of what things really require.
[01:02:01.680 --> 01:02:02.920]   And with realistic understanding,
[01:02:02.920 --> 01:02:05.760]   you can move around the chess pieces of your schedule
[01:02:05.760 --> 01:02:06.920]   and be in the driver's seat.
[01:02:06.920 --> 01:02:10.080]   That's a weird mixed metaphor, but let's just go with it.
[01:02:10.080 --> 01:02:12.900]   You know what's on your plate, what's realistic.
[01:02:12.900 --> 01:02:14.700]   You know when to say no, you know when to say yes.
[01:02:14.700 --> 01:02:16.660]   You know how to make sure the things that need to get done
[01:02:16.660 --> 01:02:18.900]   get done in early enough time that you don't have pileups,
[01:02:18.900 --> 01:02:20.020]   you don't have that stress.
[01:02:20.020 --> 01:02:21.200]   It does reduce stress.
[01:02:21.200 --> 01:02:23.060]   It does help you feel more in control.
[01:02:23.060 --> 01:02:25.040]   It does help you get more of a return
[01:02:25.040 --> 01:02:27.320]   for the hours you have available to invest.
[01:02:27.320 --> 01:02:30.500]   So I like this case study because it tells you
[01:02:30.500 --> 01:02:33.680]   if you don't have control over what's going on in your life,
[01:02:33.680 --> 01:02:35.460]   it has control over you.
[01:02:35.460 --> 01:02:38.920]   And it's not gonna drive you and your chess pieces
[01:02:38.920 --> 01:02:41.860]   in the direction most likely that you wanna actually go.
[01:02:41.860 --> 01:02:43.100]   So it's a cool principle.
[01:02:43.100 --> 01:02:47.120]   So I would say just multi-scale plan,
[01:02:47.120 --> 01:02:49.060]   quarterly, weekly, daily, time blocking,
[01:02:49.060 --> 01:02:51.260]   that's probably gonna get you half, most of the way there.
[01:02:51.260 --> 01:02:53.460]   Have a good task capture system that you review
[01:02:53.460 --> 01:02:56.380]   where things have statuses and you have different lists
[01:02:56.380 --> 01:02:57.900]   or boards for different contexts.
[01:02:57.900 --> 01:02:59.020]   All the stuff we talk about
[01:02:59.020 --> 01:03:00.860]   gets you towards the same place,
[01:03:00.860 --> 01:03:03.960]   but it's why control is a key layer in my deep life stack
[01:03:03.960 --> 01:03:06.140]   because if you don't control all the stuff on your plate,
[01:03:06.140 --> 01:03:08.300]   it's very hard for you to actually control your life
[01:03:08.300 --> 01:03:10.000]   and the direction that it's going.
[01:03:10.000 --> 01:03:14.180]   All right, so I wanna move on to our final segment,
[01:03:14.180 --> 01:03:15.020]   but before I do,
[01:03:15.020 --> 01:03:17.520]   I have a couple other sponsors I want to mention.
[01:03:17.520 --> 01:03:24.140]   Our first is Blinkist, our longtime friends at Blinkist,
[01:03:24.140 --> 01:03:26.420]   which is an app that enables you to understand
[01:03:26.420 --> 01:03:28.420]   the most important ideas or things
[01:03:28.420 --> 01:03:32.500]   from over 5,500 nonfiction books and podcasts.
[01:03:32.500 --> 01:03:34.780]   The short summaries it provides, which they call Blinks,
[01:03:34.780 --> 01:03:38.520]   take just 15 minutes to read or to listen to.
[01:03:38.520 --> 01:03:42.780]   The way I use Blinkist, the way Jesse uses Blinkist,
[01:03:42.780 --> 01:03:45.960]   is as a triage mechanism for the reading life.
[01:03:45.960 --> 01:03:48.320]   You have a book you're thinking about,
[01:03:48.320 --> 01:03:50.460]   I'm interested in this topic, I've heard about this book.
[01:03:50.460 --> 01:03:52.260]   Before you just buy it,
[01:03:52.260 --> 01:03:54.660]   you instead, if you're a Blinkist subscriber,
[01:03:54.660 --> 01:03:56.580]   quickly read the Blink for that book,
[01:03:56.580 --> 01:03:57.940]   and you can just read it on your phone
[01:03:57.940 --> 01:03:59.460]   or you can play the audio Blink
[01:03:59.460 --> 01:04:01.500]   when you're doing something else.
[01:04:01.500 --> 01:04:04.500]   This really tells you what you need to know.
[01:04:04.500 --> 01:04:05.860]   If you've been reading for a little while,
[01:04:05.860 --> 01:04:08.460]   this 15-minute summary is usually what you need to know
[01:04:08.460 --> 01:04:10.020]   if this book is for you or not.
[01:04:10.020 --> 01:04:13.140]   It's eerie how effective this is.
[01:04:13.140 --> 01:04:15.580]   It's eerie how well you can pin down really quickly,
[01:04:15.580 --> 01:04:18.680]   uh-oh, this book is a brochure
[01:04:18.680 --> 01:04:20.620]   that's been padded out to 300 words.
[01:04:20.620 --> 01:04:23.860]   Yeah, I'm good, versus, ooh, this sounds fascinating.
[01:04:23.860 --> 01:04:25.380]   I really want to find out more
[01:04:25.380 --> 01:04:26.880]   about this framework being summarized here.
[01:04:26.880 --> 01:04:28.220]   I have to buy it.
[01:04:28.220 --> 01:04:29.580]   So it will make your hit rate
[01:04:29.580 --> 01:04:32.220]   on nonfiction books much higher.
[01:04:33.300 --> 01:04:35.340]   By hit rate, I mean the fraction of books you buy
[01:04:35.340 --> 01:04:37.860]   that you love is gonna be much, much higher
[01:04:37.860 --> 01:04:39.100]   if you first triage with Blinkist.
[01:04:39.100 --> 01:04:40.820]   Now, people use it for other ways as well,
[01:04:40.820 --> 01:04:42.700]   to quickly learn a field,
[01:04:42.700 --> 01:04:44.980]   to learn a lot of big ideas about a topic,
[01:04:44.980 --> 01:04:46.940]   to get a lay of the land of various authors
[01:04:46.940 --> 01:04:47.780]   and what they write about.
[01:04:47.780 --> 01:04:49.420]   There's a lot of uses for Blinkist,
[01:04:49.420 --> 01:04:51.500]   but the book triaging is just one in particular
[01:04:51.500 --> 01:04:53.780]   that I really like.
[01:04:53.780 --> 01:04:55.900]   So this is a tool for people
[01:04:55.900 --> 01:04:57.700]   who take an intellectual life seriously
[01:04:57.700 --> 01:05:00.660]   to seriously consider.
[01:05:00.660 --> 01:05:02.420]   Now, right now, Blinkist has a special offer
[01:05:02.420 --> 01:05:04.540]   just for our audience.
[01:05:04.540 --> 01:05:07.380]   If you go to blinkist.com/deep
[01:05:07.380 --> 01:05:08.720]   to start your seven-day free trial,
[01:05:08.720 --> 01:05:11.460]   you'll get 25% off a Blinkist premium membership.
[01:05:11.460 --> 01:05:15.220]   That's Blinkist, spelled B-L-I-N-K-I-S-T,
[01:05:15.220 --> 01:05:19.580]   blinkist.com/deep to get 25% off in a seven-day free trial.
[01:05:19.580 --> 01:05:21.380]   That's blinkist.com/deep.
[01:05:21.380 --> 01:05:23.180]   And right now, for a limited time,
[01:05:23.180 --> 01:05:26.420]   you can use their Blinkist Connect promotion
[01:05:26.420 --> 01:05:29.100]   to share your premium account.
[01:05:29.100 --> 01:05:30.820]   You will get two premium subscriptions
[01:05:30.820 --> 01:05:32.440]   for the price of one.
[01:05:32.440 --> 01:05:36.620]   Let's also talk about our friends at ExpressVPN.
[01:05:36.620 --> 01:05:41.780]   If you use the internet, you need a VPN.
[01:05:41.780 --> 01:05:42.620]   Here's why.
[01:05:42.620 --> 01:05:47.300]   People can see what sites and services you're accessing.
[01:05:47.300 --> 01:05:48.500]   So if you're in a coffee shop,
[01:05:48.500 --> 01:05:51.600]   anyone in that coffee shop can listen to your packets
[01:05:51.600 --> 01:05:53.900]   being sent over the radio waves to the access point
[01:05:53.900 --> 01:05:56.500]   and see what sites and services you're talking to.
[01:05:56.500 --> 01:06:00.140]   Yes, the content of your messages might be encrypted,
[01:06:00.140 --> 01:06:02.100]   but not the destination.
[01:06:02.100 --> 01:06:04.260]   So they can say, aha,
[01:06:04.260 --> 01:06:06.340]   you are spending an inordinate amount of time
[01:06:06.340 --> 01:06:09.640]   going to jessyskeleton.com or sending the authorities.
[01:06:09.640 --> 01:06:13.260]   Same thing with using the internet at home.
[01:06:13.260 --> 01:06:14.780]   You might say, I live in the middle of nowhere.
[01:06:14.780 --> 01:06:16.140]   No one knows who I'm using on the internet.
[01:06:16.140 --> 01:06:16.980]   Well, you know who does?
[01:06:16.980 --> 01:06:18.620]   Your internet service provider.
[01:06:18.620 --> 01:06:20.100]   They can see, aha,
[01:06:20.100 --> 01:06:22.940]   this guy spends a lot of time on jessyskeleton.com
[01:06:22.940 --> 01:06:25.780]   and they can sell that information to advertisers
[01:06:25.780 --> 01:06:28.380]   or in this case, to the Department of Homeland Security
[01:06:28.380 --> 01:06:30.180]   because you are a security threat.
[01:06:30.180 --> 01:06:33.260]   A VPN gets you around that type of surveillance.
[01:06:33.260 --> 01:06:35.260]   The way it works is instead of talking directly
[01:06:35.260 --> 01:06:36.860]   to jessyskeleton.com,
[01:06:36.860 --> 01:06:39.100]   you make a connection to a VPN server.
[01:06:39.100 --> 01:06:43.220]   You then send an encrypted message to the server saying,
[01:06:43.220 --> 01:06:45.940]   who I really wanna talk to is jessyskeleton.com.
[01:06:45.940 --> 01:06:48.300]   The server talks to the website on your behalf,
[01:06:48.300 --> 01:06:51.180]   encrypts the response, sends it back to you,
[01:06:51.180 --> 01:06:53.060]   you unencrypt it and see those beautiful
[01:06:53.060 --> 01:06:54.780]   jessyskeleton clips.
[01:06:54.780 --> 01:06:56.700]   What does your internet service provider learn?
[01:06:56.700 --> 01:06:58.740]   What does the guy with the antenna sniffing your packets
[01:06:58.740 --> 01:06:59.580]   learn?
[01:06:59.580 --> 01:07:00.420]   Nothing.
[01:07:00.420 --> 01:07:03.340]   You're talking through a VPN server to somewhere.
[01:07:03.340 --> 01:07:04.860]   So you get that privacy back.
[01:07:04.860 --> 01:07:06.300]   If you're gonna use a VPN,
[01:07:06.300 --> 01:07:10.100]   I would recommend the VPN I use, which is ExpressVPN.
[01:07:10.100 --> 01:07:11.820]   They've got servers all around the world.
[01:07:11.820 --> 01:07:15.100]   So wherever you are, there's probably one nearby.
[01:07:15.100 --> 01:07:17.700]   An added benefit of that is you can also connect
[01:07:17.700 --> 01:07:20.540]   to a VPN server in another country and get around
[01:07:20.540 --> 01:07:22.380]   and don't tell them I told you this,
[01:07:22.380 --> 01:07:24.100]   regional restrictions.
[01:07:24.100 --> 01:07:27.100]   So I can connect to a VPN server in England
[01:07:27.100 --> 01:07:29.260]   and then through there, talk to bbc.com
[01:07:29.260 --> 01:07:31.420]   and be able to play the videos that I wouldn't otherwise
[01:07:31.420 --> 01:07:33.100]   have access to outside of England.
[01:07:33.100 --> 01:07:34.340]   So there's an added benefit.
[01:07:34.340 --> 01:07:35.780]   They have a lot of bandwidth as well.
[01:07:35.780 --> 01:07:37.300]   The tech is very easy to use.
[01:07:37.300 --> 01:07:39.380]   You install it on the devices you already access
[01:07:39.380 --> 01:07:41.580]   the internet from, you press a button, it turns on
[01:07:41.580 --> 01:07:43.420]   and you use everything like normal.
[01:07:43.420 --> 01:07:48.780]   So if you wanna protect your shameful, shameful
[01:07:48.780 --> 01:07:51.180]   jessyskeleton addiction from other people
[01:07:51.180 --> 01:07:52.340]   or whatever else you're doing,
[01:07:52.340 --> 01:07:55.140]   or just gain some privacy back in your life,
[01:07:55.140 --> 01:07:58.420]   go to expressvpn.com/deep and you will get
[01:07:58.420 --> 01:08:00.920]   an extra three months of ExpressVPN for free.
[01:08:00.920 --> 01:08:03.660]   That's expressvpn.com/deep,
[01:08:03.660 --> 01:08:07.160]   expressvpn.com/deep to learn more.
[01:08:07.160 --> 01:08:10.020]   All right, Jesse, our final segment,
[01:08:10.020 --> 01:08:13.260]   books I read in October, 2023.
[01:08:13.260 --> 01:08:16.500]   All right, so as I do each month,
[01:08:16.500 --> 01:08:19.740]   I summarize the books I read in the month previous.
[01:08:19.740 --> 01:08:23.460]   I should be clear, it's the books I finished
[01:08:23.460 --> 01:08:24.500]   in the month previous.
[01:08:24.500 --> 01:08:27.300]   So it gets kind of complicated, but whatever.
[01:08:27.300 --> 01:08:32.100]   All right, so what books did I finish in October, 2023?
[01:08:32.100 --> 01:08:34.780]   The first one was "Build the Life You Want"
[01:08:34.780 --> 01:08:38.960]   by Arthur Brooks and Oprah Winfrey.
[01:08:38.960 --> 01:08:42.140]   This was a very successful book.
[01:08:42.140 --> 01:08:44.780]   I read it because it reminds me of the type of things
[01:08:44.780 --> 01:08:46.800]   we talk about here about the deep life.
[01:08:46.800 --> 01:08:50.540]   It's a book about engineering your life to be better.
[01:08:50.540 --> 01:08:53.500]   So being systematic about how you do that.
[01:08:53.500 --> 01:08:55.540]   I don't wanna say too much about it now
[01:08:55.540 --> 01:08:57.420]   because Arthur is actually gonna join us on the show,
[01:08:57.420 --> 01:08:58.420]   Jesse, so I don't know if you know that,
[01:08:58.420 --> 01:09:00.720]   but Arthur Brooks next month is gonna join us on the show
[01:09:00.720 --> 01:09:03.340]   and we'll learn about engineering your life.
[01:09:03.340 --> 01:09:05.340]   We'll also learn about working with Oprah.
[01:09:05.340 --> 01:09:06.840]   Should be a good one. - Yeah.
[01:09:06.840 --> 01:09:11.340]   - I also read "Meditations" by Marcus Aurelius.
[01:09:11.340 --> 01:09:12.780]   So if you're a listener to the show, you know this
[01:09:12.780 --> 01:09:14.820]   because I did an earlier episode,
[01:09:14.820 --> 01:09:19.160]   I did a segment about ideas from "Meditations,"
[01:09:19.160 --> 01:09:22.020]   but I don't think I'd ever read it before.
[01:09:22.020 --> 01:09:25.160]   I told you about this, Jesse, but it was amazing
[01:09:25.160 --> 01:09:28.120]   when I bought this book, a translation,
[01:09:28.120 --> 01:09:31.880]   we looked this up, it was from like 2004
[01:09:31.880 --> 01:09:32.720]   or something like this.
[01:09:32.720 --> 01:09:34.340]   It's not like it's a new translation.
[01:09:34.340 --> 01:09:36.120]   Top 100 on Amazon. - Yeah.
[01:09:36.120 --> 01:09:37.380]   - Yeah, that thing sells.
[01:09:37.380 --> 01:09:42.220]   Then I read "Dr. No" by Ian Leeming,
[01:09:43.360 --> 01:09:45.420]   one of the original James Bond's books.
[01:09:45.420 --> 01:09:48.180]   I just needed a something fun.
[01:09:48.180 --> 01:09:52.220]   It's a good one, "Dr. No," early James Bond.
[01:09:52.220 --> 01:09:55.020]   One flaw with that, I mean, I'm a thriller aficionado,
[01:09:55.020 --> 01:09:57.220]   I'm an adventure book aficionado.
[01:09:57.220 --> 01:09:58.460]   The one flaw with that book,
[01:09:58.460 --> 01:10:00.660]   and I don't wanna spoil this too much,
[01:10:00.660 --> 01:10:05.660]   is "Dr. No," Bond is escaping from the torture tunnel.
[01:10:05.660 --> 01:10:09.020]   So "Dr. No" puts him in a torture tunnel.
[01:10:09.020 --> 01:10:12.180]   He puts Bond in a torture tunnel
[01:10:12.180 --> 01:10:16.860]   and the woman he's with, they stake down outside
[01:10:16.860 --> 01:10:20.980]   on a path where Jamaican black crabs every day migrate
[01:10:20.980 --> 01:10:23.560]   with the idea that the crabs are gonna eat you,
[01:10:23.560 --> 01:10:24.880]   eat you alive.
[01:10:24.880 --> 01:10:26.640]   So big setup, real thriller.
[01:10:26.640 --> 01:10:30.720]   You can tell by the way this is grade A literature here.
[01:10:30.720 --> 01:10:33.480]   Here's my problem, two problems.
[01:10:33.480 --> 01:10:36.520]   One, how did she get out of it?
[01:10:36.520 --> 01:10:38.440]   They were just like, oh, it turns out "Dr. No"
[01:10:38.440 --> 01:10:40.200]   didn't really understand much about crabs.
[01:10:40.200 --> 01:10:42.120]   Crabs have no interest in eating people.
[01:10:42.120 --> 01:10:43.920]   So she just sort of waited till the crabs were gone
[01:10:43.920 --> 01:10:45.480]   and got up.
[01:10:45.480 --> 01:10:49.000]   So that's not really a fulfilling way to get out of that.
[01:10:49.000 --> 01:10:51.240]   Bond gets out of the torture tunnel, that's fine.
[01:10:51.240 --> 01:10:54.040]   The issue is, so now he has to kind of escape the island.
[01:10:54.040 --> 01:10:56.560]   He kills "Dr. No" halfway through the escape.
[01:10:56.560 --> 01:11:00.520]   It should be the climax of the escape
[01:11:00.520 --> 01:11:03.080]   is finally killing the main villain,
[01:11:03.080 --> 01:11:05.560]   but instead it's like he's on his way,
[01:11:05.560 --> 01:11:09.600]   he takes over a crane and just dumps a bunch of bird guano
[01:11:09.600 --> 01:11:11.360]   on top of "Dr. No."
[01:11:11.360 --> 01:11:13.080]   And like goes on and kills 10 more people
[01:11:13.080 --> 01:11:14.600]   and there's chases that happen.
[01:11:14.600 --> 01:11:16.580]   It's like almost anticlimactic.
[01:11:16.580 --> 01:11:18.560]   It's like, this is this big villain they've set up
[01:11:18.560 --> 01:11:19.720]   and they're just like in the middle of escape,
[01:11:19.720 --> 01:11:20.560]   like, oh, I just killed him.
[01:11:20.560 --> 01:11:22.520]   And they like keep going with like the rest of the stuff.
[01:11:22.520 --> 01:11:24.360]   It should be like the final person you kill.
[01:11:24.360 --> 01:11:26.600]   I think this is like thriller 101.
[01:11:26.600 --> 01:11:29.440]   So those are my two issues with "Dr. No."
[01:11:29.440 --> 01:11:31.120]   These are not the type of analysis you'll hear
[01:11:31.120 --> 01:11:32.840]   from someone who's talking about their experience
[01:11:32.840 --> 01:11:36.580]   having read "Ulysses" by James Joyce.
[01:11:37.840 --> 01:11:41.600]   I read "Awe" by Docker Keltner.
[01:11:41.600 --> 01:11:42.580]   So sort of the buzzy,
[01:11:42.580 --> 01:11:44.360]   one of the buzzy new popular science books
[01:11:44.360 --> 01:11:45.320]   from the last six months.
[01:11:45.320 --> 01:11:48.960]   So Docker is at, I think Berkeley.
[01:11:48.960 --> 01:11:51.440]   Anyways, he's a psychologist who has innovated
[01:11:51.440 --> 01:11:55.740]   the scientific study of awe, A-W-E, as a feeling.
[01:11:55.740 --> 01:11:56.580]   So it's a book that was,
[01:11:56.580 --> 01:11:58.580]   hey, let me get into my research and how this works.
[01:11:58.580 --> 01:11:59.780]   And so it's interesting.
[01:11:59.780 --> 01:12:04.700]   The final book I read was "Israel" by Noah Tisby.
[01:12:05.860 --> 01:12:09.420]   So this is actually one of three books
[01:12:09.420 --> 01:12:11.380]   I'm reading on Israel right now.
[01:12:11.380 --> 01:12:14.620]   Because I'm a real believer in,
[01:12:14.620 --> 01:12:18.420]   let's say there's a big thing happens
[01:12:18.420 --> 01:12:23.420]   and it's traumatic or scary or whatever.
[01:12:23.420 --> 01:12:25.780]   You got a couple options.
[01:12:25.780 --> 01:12:27.820]   You can turtle, like, okay,
[01:12:27.820 --> 01:12:31.060]   let's just watch reality shows on Macs.
[01:12:31.060 --> 01:12:34.840]   You can go to social media and say, get me mad.
[01:12:34.840 --> 01:12:37.100]   Like I need a team and I need to yell
[01:12:37.100 --> 01:12:38.900]   and just like get chemicals.
[01:12:38.900 --> 01:12:39.880]   Or you can read.
[01:12:39.880 --> 01:12:42.460]   And so what I did after October 7th
[01:12:42.460 --> 01:12:44.820]   is I talked to a rabbi and said,
[01:12:44.820 --> 01:12:46.820]   I want you to recommend me books.
[01:12:46.820 --> 01:12:48.420]   I wanna learn about Israel.
[01:12:48.420 --> 01:12:51.980]   I want you to cover the political spectrum
[01:12:51.980 --> 01:12:54.180]   in Israel in terms of perspectives.
[01:12:54.180 --> 01:12:58.100]   So the three books, so the Noah Tisby's book,
[01:12:58.100 --> 01:12:59.560]   this is, you could think of this as coming
[01:12:59.560 --> 01:13:02.140]   from like "Riot of Sin" or Israeli politics.
[01:13:02.140 --> 01:13:05.200]   It's sort of more, not apologia,
[01:13:05.200 --> 01:13:10.200]   but it's more like "Riot of Sin" or pro-Israel.
[01:13:10.200 --> 01:13:14.280]   For the center book, and I just finished this,
[01:13:14.280 --> 01:13:15.960]   but it's November now, so it's not on this list,
[01:13:15.960 --> 01:13:20.280]   is Martin Gilbert's epic history of Israel, 650 pages.
[01:13:20.280 --> 01:13:23.080]   I thought I could do it in a week, took me two weeks.
[01:13:23.080 --> 01:13:25.280]   He's a British historian, sort of,
[01:13:25.280 --> 01:13:26.680]   look, I don't have a dog in this fight.
[01:13:26.680 --> 01:13:31.080]   Just this is the history starting mid 19th century
[01:13:31.080 --> 01:13:34.780]   to late 1990s, right, just like TikTok history,
[01:13:34.780 --> 01:13:35.620]   finished that.
[01:13:35.620 --> 01:13:41.780]   And now I've just ordered Yusuf HaLevi's letter
[01:13:41.780 --> 01:13:44.960]   to my Palestinian neighbor to cover the perspective
[01:13:44.960 --> 01:13:48.120]   from left of center Israeli politics.
[01:13:48.120 --> 01:13:50.000]   HaLevi is someone who had started
[01:13:50.000 --> 01:13:53.600]   as a right-wing Israeli politics
[01:13:53.600 --> 01:13:56.920]   and changed over to being a progressive
[01:13:56.920 --> 01:13:59.360]   in terms of thinking about on the left of Israel.
[01:13:59.360 --> 01:14:01.120]   So I'm reading all three of these books.
[01:14:01.120 --> 01:14:03.320]   Let's boom, right, boom, center,
[01:14:03.320 --> 01:14:06.260]   sort of outside of Israel history,
[01:14:06.260 --> 01:14:09.000]   boom, someone who's coming more from the Israeli left.
[01:14:09.000 --> 01:14:10.400]   So I'm reading.
[01:14:10.400 --> 01:14:11.240]   - Yeah.
[01:14:11.240 --> 01:14:15.240]   - I'll tell you, it feels like a more productive,
[01:14:15.240 --> 01:14:19.320]   calming, just focused response to things
[01:14:19.320 --> 01:14:24.240]   than I gotta tweet about somebody.
[01:14:24.240 --> 01:14:28.040]   I don't know who, but someone I gotta get on there
[01:14:28.040 --> 01:14:30.720]   or I need to just start yelling.
[01:14:30.720 --> 01:14:35.640]   Sometimes reading, at least for me, let me learn.
[01:14:35.640 --> 01:14:38.320]   It's a calming effect, but like a determined way.
[01:14:38.320 --> 01:14:39.160]   It's not an avoidance.
[01:14:39.160 --> 01:14:41.240]   It's like, let me figure out what's going on.
[01:14:41.240 --> 01:14:43.480]   So I am learning more about the history of Israel
[01:14:43.480 --> 01:14:46.800]   in this very short period than I thought I would be,
[01:14:46.800 --> 01:14:48.160]   but that's what I'm up to.
[01:14:48.160 --> 01:14:50.760]   - David Remnick just had a awesome article
[01:14:50.760 --> 01:14:53.360]   on the November 6th issue of "The Yorker 2."
[01:14:53.360 --> 01:14:54.360]   I just finished that.
[01:14:54.360 --> 01:14:55.200]   - So how'd you like it?
[01:14:55.200 --> 01:14:56.360]   I haven't read it yet.
[01:14:56.360 --> 01:14:57.520]   - It was very detailed.
[01:14:57.520 --> 01:14:59.320]   It explained a lot of the history
[01:14:59.320 --> 01:15:01.480]   that I wasn't really aware of.
[01:15:01.480 --> 01:15:03.000]   - Yeah, and David went.
[01:15:03.000 --> 01:15:03.840]   - He was there.
[01:15:03.840 --> 01:15:05.680]   - He went over there right away after October 7th.
[01:15:05.680 --> 01:15:10.200]   I think he's back now, but he reported from there for weeks.
[01:15:10.200 --> 01:15:11.200]   - Mm-hmm. - Yeah.
[01:15:11.200 --> 01:15:13.720]   Yeah, you never wanna not read something
[01:15:13.720 --> 01:15:16.320]   David Remnick writes about a political situation.
[01:15:16.320 --> 01:15:19.680]   I mean, this is one of the preeminent writers
[01:15:19.680 --> 01:15:23.280]   of geopolitical nonfiction journalism
[01:15:23.280 --> 01:15:24.720]   of the last few generations.
[01:15:24.720 --> 01:15:27.000]   He has a Pulitzer Prize for his reporting on Russia.
[01:15:27.000 --> 01:15:28.720]   He really knows his game.
[01:15:28.720 --> 01:15:30.720]   He's made a few missteps in his life.
[01:15:30.720 --> 01:15:34.440]   Like his magazine allowed this guy
[01:15:34.440 --> 01:15:37.680]   who blogs about productivity to write for them sometimes.
[01:15:37.680 --> 01:15:39.320]   Like that was a clear mistake.
[01:15:39.320 --> 01:15:43.040]   But you know, you're not gonna bat 100.
[01:15:43.040 --> 01:15:43.880]   Not gonna bat 100.
[01:15:43.880 --> 01:15:45.600]   You're gonna eventually, you're gonna occasionally,
[01:15:45.600 --> 01:15:48.680]   accidentally get people writing about getting things done,
[01:15:48.680 --> 01:15:50.200]   the pages of "The New Yorker."
[01:15:50.200 --> 01:15:52.600]   But yeah, other than that,
[01:15:52.600 --> 01:15:55.240]   other than that, I think it was a pretty high hit rate.
[01:15:55.240 --> 01:15:56.560]   But I think there's bigger lesson in that.
[01:15:56.560 --> 01:15:59.440]   Like outside of any particular issues going on, read.
[01:15:59.440 --> 01:16:01.200]   Read.
[01:16:01.200 --> 01:16:02.040]   What happens when you read a book
[01:16:02.040 --> 01:16:03.680]   is you're taking another human mind
[01:16:03.680 --> 01:16:06.760]   who has spent years, if not a lifetime,
[01:16:06.760 --> 01:16:07.960]   thinking about something,
[01:16:07.960 --> 01:16:10.160]   and then years trying to get their thoughts
[01:16:10.160 --> 01:16:11.680]   as clear as possible.
[01:16:11.680 --> 01:16:15.520]   And you mind meld with someone when you read a book.
[01:16:15.520 --> 01:16:17.120]   You mind meld with them.
[01:16:17.120 --> 01:16:20.720]   And really get to understand these nuances
[01:16:20.720 --> 01:16:21.560]   and their perspective.
[01:16:21.560 --> 01:16:23.680]   I mean, it is the way that as like heightened
[01:16:23.680 --> 01:16:25.880]   intellectual beings, we should engage with the world.
[01:16:25.880 --> 01:16:27.160]   And you mind meld with people
[01:16:27.160 --> 01:16:28.360]   who are from different backgrounds
[01:16:28.360 --> 01:16:30.120]   and have different views on things.
[01:16:30.120 --> 01:16:35.120]   It's why I, the one, like charity cause
[01:16:35.120 --> 01:16:36.600]   I really push often on this podcast,
[01:16:36.600 --> 01:16:38.200]   I do this auction every year,
[01:16:38.200 --> 01:16:39.840]   this authors of color auction,
[01:16:39.840 --> 01:16:42.920]   is because I really like what they do
[01:16:42.920 --> 01:16:44.640]   is they give scholarships to help people
[01:16:44.640 --> 01:16:46.800]   from more diverse backgrounds get into publishing.
[01:16:46.800 --> 01:16:49.400]   Because there's often, it can be hard
[01:16:49.400 --> 01:16:51.280]   to get onto the track to be in publishing
[01:16:51.280 --> 01:16:54.040]   because there might be these like very low paid jobs
[01:16:54.040 --> 01:16:54.880]   or internships.
[01:16:54.880 --> 01:16:56.920]   If you don't have other sources of money,
[01:16:56.920 --> 01:16:58.360]   you can't get on this track.
[01:16:58.360 --> 01:16:59.840]   But since books are everything
[01:16:59.840 --> 01:17:01.760]   and it's the portal to other people's minds,
[01:17:01.760 --> 01:17:04.400]   it's the portal to understanding ideas and experiences,
[01:17:04.400 --> 01:17:06.720]   the more interesting books we have,
[01:17:06.720 --> 01:17:07.840]   the more things we cover,
[01:17:07.840 --> 01:17:09.680]   the more people can understand the world.
[01:17:09.680 --> 01:17:10.960]   So I really love that cause.
[01:17:10.960 --> 01:17:13.320]   It's like, if we can get different people,
[01:17:13.320 --> 01:17:15.120]   a bigger variety of people in the publishing,
[01:17:15.120 --> 01:17:17.120]   they will bring in a bigger variety of books,
[01:17:17.120 --> 01:17:18.360]   which means we, the readers,
[01:17:18.360 --> 01:17:20.680]   can get a bigger variety of understanding
[01:17:20.680 --> 01:17:21.520]   about other people.
[01:17:21.520 --> 01:17:24.440]   So I'm just such a huge believer of books and reading.
[01:17:24.440 --> 01:17:28.160]   It really is the right approach to almost everything.
[01:17:28.160 --> 01:17:33.160]   So I'm now 800, 900 pages in my Israeli reading.
[01:17:33.160 --> 01:17:35.560]   I have a three or 400 more, but I'm there.
[01:17:35.560 --> 01:17:37.920]   By next week, I'll have finished my reading assignment.
[01:17:37.920 --> 01:17:41.960]   So we'll have to like ask the fake rabbi segment
[01:17:41.960 --> 01:17:43.800]   where I'll just very knowledgeably
[01:17:43.800 --> 01:17:45.520]   kind of get slightly wrong questions
[01:17:45.520 --> 01:17:46.480]   about the history of Israel.
[01:17:46.480 --> 01:17:47.320]   - We'll be great.
[01:17:47.320 --> 01:17:49.480]   - You get some new music and the--
[01:17:49.480 --> 01:17:50.520]   - Sound effects. - Yeah.
[01:17:50.520 --> 01:17:51.640]   - Everything, man.
[01:17:51.640 --> 01:17:54.240]   I want, we have eight sound effects on there.
[01:17:54.240 --> 01:17:55.960]   We have pads, room on there for eight sound effects.
[01:17:55.960 --> 01:17:57.200]   I want eight sound effects.
[01:17:57.200 --> 01:17:59.560]   We wanna, we got just rock and roll.
[01:17:59.560 --> 01:18:01.800]   I want wacky car horns.
[01:18:01.800 --> 01:18:04.720]   I want applause for sure.
[01:18:04.720 --> 01:18:05.560]   - Yeah.
[01:18:05.560 --> 01:18:06.560]   - I don't think this is pretentious.
[01:18:06.560 --> 01:18:08.860]   I think like whenever I say something particularly smart,
[01:18:08.860 --> 01:18:10.280]   I want, and let's not be crazy,
[01:18:10.280 --> 01:18:12.840]   but like 30 seconds of sustained applause.
[01:18:12.840 --> 01:18:14.920]   (laughing)
[01:18:14.920 --> 01:18:16.800]   And I'll just blow kisses to the camera.
[01:18:16.800 --> 01:18:17.880]   You know, I don't think it's crazy,
[01:18:17.880 --> 01:18:19.520]   but just so people know,
[01:18:19.520 --> 01:18:20.360]   they don't always know,
[01:18:20.360 --> 01:18:22.840]   like this was really smart what I just said.
[01:18:22.840 --> 01:18:25.280]   And then we can have like enthusiastic applause
[01:18:25.280 --> 01:18:26.120]   could be a different one.
[01:18:26.120 --> 01:18:26.960]   It was a really good point
[01:18:26.960 --> 01:18:30.560]   where the applause then crescendos into cheering
[01:18:30.560 --> 01:18:34.120]   and just bravo, bravo, bravo, bravo, bravo, bravo,
[01:18:34.120 --> 01:18:34.960]   and like whistles.
[01:18:34.960 --> 01:18:36.160]   And then I'll be like, "Oh, come on, please.
[01:18:36.160 --> 01:18:37.000]   "It'll be great."
[01:18:37.000 --> 01:18:39.520]   (laughing)
[01:18:39.520 --> 01:18:40.760]   Feigned applause, that's the secret.
[01:18:40.760 --> 01:18:41.880]   All right, enough of this nonsense.
[01:18:41.880 --> 01:18:43.920]   That's all the time we have for today.
[01:18:43.920 --> 01:18:46.720]   Thank you for listening.
[01:18:46.720 --> 01:18:47.720]   If you liked it, by the way,
[01:18:47.720 --> 01:18:48.920]   you leave a review, subscribe,
[01:18:48.920 --> 01:18:50.440]   that type of stuff really helps other people
[01:18:50.440 --> 01:18:51.840]   get in on this nonsense.
[01:18:51.840 --> 01:18:55.960]   We'll be back next week with another episode of the show.
[01:18:55.960 --> 01:18:58.340]   And until then, as always, stay deep.
[01:18:58.340 --> 01:19:01.440]   Hey, so if you liked today's discussion
[01:19:01.440 --> 01:19:04.600]   about how to make learning as appealing
[01:19:04.600 --> 01:19:07.080]   as the distractions that you can find on your phone,
[01:19:07.080 --> 01:19:10.680]   you might also like episode 270,
[01:19:10.680 --> 01:19:14.840]   which is called "Depth Versus Distraction."
[01:19:14.840 --> 01:19:16.000]   Check it out.
[01:19:16.000 --> 01:19:20.080]   About struggling to take back control of their life
[01:19:20.080 --> 01:19:22.960]   from powerful sources of distraction.

