
[00:00:00.000 --> 00:00:04.640]   Today, we're going to take a look at a ChatGPT plugin
[00:00:04.640 --> 00:00:08.700]   that is going to let us search through podcast episodes
[00:00:08.700 --> 00:00:13.360]   and basically answer questions based on those episodes
[00:00:13.360 --> 00:00:15.440]   and a few other things.
[00:00:15.440 --> 00:00:19.000]   So let me show you what we have so far.
[00:00:19.000 --> 00:00:21.160]   So here we're in ChatGPT.
[00:00:21.160 --> 00:00:26.160]   You can see up here, we have a little Lex Friedman logo.
[00:00:26.200 --> 00:00:30.360]   That's because we are going to ask Lex some questions.
[00:00:30.360 --> 00:00:35.360]   So we're going to ask Lex about the future of AI.
[00:00:35.360 --> 00:00:37.360]   So ChatGPT is thinking.
[00:00:37.360 --> 00:00:41.200]   It decides that it needs to use the AskLex plugin.
[00:00:41.200 --> 00:00:43.120]   And then it's kind of just giving us a summary
[00:00:43.120 --> 00:00:46.040]   from a few different episodes here.
[00:00:46.040 --> 00:00:47.720]   Okay, so we can see that it's also included
[00:00:47.720 --> 00:00:50.580]   the source of these episodes, which is pretty nice.
[00:00:50.580 --> 00:00:52.480]   And it's given us a few options.
[00:00:52.480 --> 00:00:54.760]   Okay, and then we also get this nice little,
[00:00:54.760 --> 00:00:56.320]   these cards at the bottom
[00:00:56.320 --> 00:00:58.720]   showing us where these are coming from.
[00:00:58.720 --> 00:01:03.480]   So we get a pretty good summary of AI being discussed
[00:01:03.480 --> 00:01:05.660]   in Lex Friedman podcast episodes.
[00:01:05.660 --> 00:01:06.720]   And also this as well.
[00:01:06.720 --> 00:01:11.620]   This is, I think, one of the courses he did at MIT, right?
[00:01:11.620 --> 00:01:13.800]   So that's pretty cool.
[00:01:13.800 --> 00:01:17.320]   Now, what if I, maybe I want a little more information
[00:01:17.320 --> 00:01:20.440]   from a particular one of these episodes.
[00:01:20.440 --> 00:01:22.280]   Okay, so let's come down here.
[00:01:22.280 --> 00:01:26.680]   And I'm going to say, can you tell me more
[00:01:26.680 --> 00:01:31.680]   about the Eric Brian Jolson episode?
[00:01:31.680 --> 00:01:34.460]   Okay, see what comes up.
[00:01:34.460 --> 00:01:37.200]   So it's again, referring to the plugin,
[00:01:37.200 --> 00:01:39.120]   even though I didn't say AskLex this time,
[00:01:39.120 --> 00:01:41.640]   it knows that I still want to use this plugin.
[00:01:41.640 --> 00:01:42.480]   Okay, cool.
[00:01:42.480 --> 00:01:46.400]   Okay, so there's a lot more information
[00:01:46.400 --> 00:01:51.400]   in this kind of summary of that particular episode.
[00:01:51.400 --> 00:01:53.360]   Right, that is really interesting.
[00:01:53.360 --> 00:01:55.680]   And basically what it's doing there
[00:01:55.680 --> 00:01:58.920]   is searching through our entire database
[00:01:58.920 --> 00:02:01.120]   for that particular episode,
[00:02:01.120 --> 00:02:02.800]   rather than up here where we were searching
[00:02:02.800 --> 00:02:03.920]   for a particular topic,
[00:02:03.920 --> 00:02:06.040]   now it's searching for a particular episode,
[00:02:06.040 --> 00:02:07.240]   which is pretty cool.
[00:02:07.240 --> 00:02:11.160]   Now, let's just continue this conversation a little bit.
[00:02:11.160 --> 00:02:16.160]   So interesting, just let's talk about space exploration.
[00:02:16.160 --> 00:02:19.080]   That's all.
[00:02:20.000 --> 00:02:21.120]   Let's see what we get.
[00:02:21.120 --> 00:02:23.640]   Okay, cool.
[00:02:23.640 --> 00:02:27.600]   Getting a few summaries like we did the other time.
[00:02:27.600 --> 00:02:30.960]   So we get, so it's two here.
[00:02:30.960 --> 00:02:35.960]   One with Darwin Newman and the other one with Ariel Ekblor.
[00:02:35.960 --> 00:02:38.960]   Now, that looks pretty cool.
[00:02:38.960 --> 00:02:42.360]   So this one's interesting talking about
[00:02:42.360 --> 00:02:45.520]   building space megastructures, that sounds interesting.
[00:02:45.520 --> 00:02:48.560]   Let's ask about this.
[00:02:48.560 --> 00:02:53.560]   Can you tell me more about building space megastructures?
[00:02:53.560 --> 00:02:57.680]   Okay, and then it's kind of honing in
[00:02:57.680 --> 00:02:59.720]   on that specific episode.
[00:02:59.720 --> 00:03:01.760]   So it's seen, we haven't specified
[00:03:01.760 --> 00:03:04.080]   that we want to talk about that,
[00:03:04.080 --> 00:03:07.200]   but it's seen the previous interactions
[00:03:07.200 --> 00:03:10.000]   and decided that, yeah, we're probably talking
[00:03:10.000 --> 00:03:12.000]   about this particular episode,
[00:03:12.000 --> 00:03:15.080]   or at least this information can be found
[00:03:15.080 --> 00:03:17.120]   in that particular episode.
[00:03:17.120 --> 00:03:19.920]   So again, it's kind of filtered down there,
[00:03:19.920 --> 00:03:22.600]   or maybe just from search, I'm not sure,
[00:03:22.600 --> 00:03:25.680]   but we definitely get a very interesting
[00:03:25.680 --> 00:03:28.160]   and relevant answer here.
[00:03:28.160 --> 00:03:32.000]   Now, that is just kind of a glimpse
[00:03:32.000 --> 00:03:35.200]   of what this sort of plugin can do.
[00:03:35.200 --> 00:03:36.680]   And naturally we can apply this
[00:03:36.680 --> 00:03:39.960]   to a ton of different podcasts, videos,
[00:03:39.960 --> 00:03:42.440]   or just anything you want really.
[00:03:43.400 --> 00:03:48.400]   Let's kind of dive into how I actually built this
[00:03:48.400 --> 00:03:50.560]   and what is actually happening
[00:03:50.560 --> 00:03:55.560]   when ChatGPT is deciding to use the AskElects plugin.
[00:03:55.560 --> 00:03:58.600]   So let's come up to the top here
[00:03:58.600 --> 00:04:01.400]   and we have our first question, okay?
[00:04:01.400 --> 00:04:03.120]   AskElects about the future of AI.
[00:04:03.120 --> 00:04:06.960]   We can open this to see what is being sent to this plugin.
[00:04:06.960 --> 00:04:08.440]   And we see that there's these queries,
[00:04:08.440 --> 00:04:10.840]   query the future of AI.
[00:04:10.840 --> 00:04:11.880]   All right, that's cool.
[00:04:11.880 --> 00:04:14.400]   So we're querying the future of AI.
[00:04:14.400 --> 00:04:16.760]   This is a semantic search.
[00:04:16.760 --> 00:04:19.080]   So we're using a vector database here.
[00:04:19.080 --> 00:04:21.640]   If that doesn't make sense, I'm going to explain it.
[00:04:21.640 --> 00:04:24.920]   But essentially you can think of this as being our question.
[00:04:24.920 --> 00:04:29.160]   And these are the parts or the chunks
[00:04:29.160 --> 00:04:33.960]   of transcribed audio from Deluxe Freeman podcasts
[00:04:33.960 --> 00:04:36.400]   that are the most relevant
[00:04:36.400 --> 00:04:40.080]   or the most semantically meaningful
[00:04:40.080 --> 00:04:42.880]   to our particular question, okay?
[00:04:42.880 --> 00:04:47.320]   These are pretty big, but if we go through,
[00:04:47.320 --> 00:04:48.680]   we should be able to find somewhere
[00:04:48.680 --> 00:04:51.640]   where they're talking about AI, right?
[00:04:51.640 --> 00:04:55.520]   You see there's a ton of things being spoken about here,
[00:04:55.520 --> 00:04:59.120]   but ChatGPT is actually managing to kind of find,
[00:04:59.120 --> 00:05:01.360]   okay, here, like when you start again,
[00:05:01.360 --> 00:05:04.200]   truly superhuman artificial intelligence,
[00:05:04.200 --> 00:05:06.360]   kind of by definition,
[00:05:06.360 --> 00:05:07.880]   I'll be able to do a ton of things
[00:05:07.880 --> 00:05:09.760]   that I couldn't have thought of in a greater world
[00:05:09.760 --> 00:05:12.040]   I couldn't imagine, you know, all this sort of stuff, right?
[00:05:12.040 --> 00:05:13.720]   So that's the way it's getting that information
[00:05:13.720 --> 00:05:18.720]   from it then summarizes and gives us in that answer, okay?
[00:05:18.720 --> 00:05:22.480]   And we can see that there's three entries there, right?
[00:05:22.480 --> 00:05:27.080]   So we have that the Eric Brian Jolson episode,
[00:05:27.080 --> 00:05:28.720]   the Deep Learning State of the Art
[00:05:28.720 --> 00:05:32.040]   and the Andrew Ng episode, okay?
[00:05:32.040 --> 00:05:34.280]   Which is what we see down there.
[00:05:34.280 --> 00:05:35.120]   And then there's this one.
[00:05:35.120 --> 00:05:36.760]   So I'm saying, can you tell me more
[00:05:36.760 --> 00:05:39.280]   about the Eric Brian Jolson episode?
[00:05:39.280 --> 00:05:41.080]   Here, if we take a look,
[00:05:41.080 --> 00:05:42.960]   you can see that the query has changed slightly.
[00:05:42.960 --> 00:05:44.360]   So I'm saying I want to know more
[00:05:44.360 --> 00:05:46.240]   about this specific episode.
[00:05:46.240 --> 00:05:51.240]   And what we have done is actually given specific instructions
[00:05:51.240 --> 00:05:55.120]   to ChatGPT saying, you know,
[00:05:55.120 --> 00:05:57.960]   if someone wants to know more about a particular episode,
[00:05:57.960 --> 00:06:00.640]   you can search for that particular episode
[00:06:00.640 --> 00:06:03.120]   by adding in this filter
[00:06:03.160 --> 00:06:06.800]   and then filtering based on the title, okay?
[00:06:06.800 --> 00:06:08.800]   So the title, it actually knows the title
[00:06:08.800 --> 00:06:11.720]   from the previous interaction, okay?
[00:06:11.720 --> 00:06:15.360]   So up here, it got the title here
[00:06:15.360 --> 00:06:18.520]   in the metadata of that result, right?
[00:06:18.520 --> 00:06:20.280]   So then it can search
[00:06:20.280 --> 00:06:24.880]   for that particular podcast episode, right?
[00:06:24.880 --> 00:06:27.840]   So I think that that is pretty cool.
[00:06:27.840 --> 00:06:29.880]   And you can see that the results here,
[00:06:29.880 --> 00:06:32.920]   then we're only returning chunks of texts
[00:06:32.920 --> 00:06:34.800]   from that particular episode.
[00:06:34.800 --> 00:06:36.200]   And that's basically what is happening
[00:06:36.200 --> 00:06:38.000]   as we go through the rest of this.
[00:06:38.000 --> 00:06:41.120]   So here, it will just be a search, the query.
[00:06:41.120 --> 00:06:45.440]   And then down here, I'm not sure what it's doing actually.
[00:06:45.440 --> 00:06:47.680]   So, okay, so it's doing a search
[00:06:47.680 --> 00:06:49.800]   and it's also filtering for that particular episode
[00:06:49.800 --> 00:06:52.400]   because it knows the information is in there.
[00:06:52.400 --> 00:06:54.800]   All right, so you can see a little bit
[00:06:54.800 --> 00:06:57.000]   of how this is working,
[00:06:57.000 --> 00:07:01.080]   but let's maybe dive into it a little more detail
[00:07:01.080 --> 00:07:03.680]   on how I actually built this.
[00:07:03.680 --> 00:07:05.680]   Okay, so let's just try
[00:07:05.680 --> 00:07:09.360]   and visualize what we have actually built here.
[00:07:09.360 --> 00:07:12.680]   So you just saw the chat GPT,
[00:07:12.680 --> 00:07:14.880]   you can think of it as almost like front end
[00:07:14.880 --> 00:07:16.600]   of this whole thing.
[00:07:16.600 --> 00:07:19.920]   So we have chat GPT over here.
[00:07:19.920 --> 00:07:24.160]   Now, chat GPT, now these plugins
[00:07:24.160 --> 00:07:27.720]   that you can connect to chat GPT
[00:07:27.720 --> 00:07:29.480]   and the way that I think they work
[00:07:29.480 --> 00:07:33.280]   because the code for that isn't actually public
[00:07:33.280 --> 00:07:38.280]   is that you are basically passing your plugin,
[00:07:38.280 --> 00:07:43.960]   which is like a tool for your chat GPT instance to use.
[00:07:43.960 --> 00:07:47.080]   You're basically passing that into the prompt
[00:07:47.080 --> 00:07:49.200]   or the initial prompt of chat GPT,
[00:07:49.200 --> 00:07:51.920]   maybe even like every prompt that is,
[00:07:51.920 --> 00:07:54.480]   maybe it's reformatted on its way to chat GPT,
[00:07:54.480 --> 00:07:57.280]   I'm not sure, but basically somewhere in the prompts,
[00:07:57.280 --> 00:07:59.280]   there is something that says,
[00:07:59.280 --> 00:08:04.160]   hey, chat GPT, you can use these plugins.
[00:08:04.160 --> 00:08:06.240]   Okay, and then it will list each of these plugins
[00:08:06.240 --> 00:08:09.920]   with a little description about each one of these plugins,
[00:08:09.920 --> 00:08:13.160]   which we actually do write ourselves.
[00:08:13.160 --> 00:08:16.200]   Okay, so in our prompt,
[00:08:16.200 --> 00:08:19.280]   you know, may say whatever it normally says,
[00:08:19.280 --> 00:08:20.600]   and then it says, you can, by the way,
[00:08:20.600 --> 00:08:24.680]   you can use the Lex Friedman,
[00:08:24.680 --> 00:08:27.320]   I'm just gonna put Lex F database,
[00:08:27.320 --> 00:08:31.920]   and it will help you answer questions
[00:08:31.920 --> 00:08:34.640]   about the Lex Friedman podcast.
[00:08:34.640 --> 00:08:39.240]   And when you see the words, ask Lex in the user's prompt,
[00:08:39.240 --> 00:08:41.880]   you should 100% use this.
[00:08:41.880 --> 00:08:44.120]   All right, that's basically what we wrote.
[00:08:44.120 --> 00:08:47.840]   So chat GPT sees this, sees your question,
[00:08:47.840 --> 00:08:50.560]   and it will sometimes decide that it needs to use this.
[00:08:50.560 --> 00:08:52.200]   If it does decide to use this,
[00:08:52.200 --> 00:08:55.120]   it is going to create a prompt
[00:08:55.120 --> 00:08:58.880]   to send to the Lex Friedman database.
[00:08:58.880 --> 00:09:01.680]   Okay, and that prompt is going to be like,
[00:09:01.680 --> 00:09:04.600]   actually, you already saw it, it contains queries.
[00:09:04.600 --> 00:09:08.760]   And then within that, you have like a list of queries.
[00:09:08.760 --> 00:09:11.800]   Okay, so it can actually pass multiple queries in there,
[00:09:11.800 --> 00:09:14.200]   but we just have one query here.
[00:09:14.200 --> 00:09:17.240]   It's just how the thing is built.
[00:09:17.240 --> 00:09:19.360]   And I'll explain that later.
[00:09:19.400 --> 00:09:22.280]   And yeah, so that is actually being passed
[00:09:22.280 --> 00:09:26.120]   to this ask Lex endpoint or plugin.
[00:09:26.120 --> 00:09:30.120]   And then we have this response from the plugin.
[00:09:30.120 --> 00:09:32.080]   Now, how do we get that response?
[00:09:32.080 --> 00:09:34.320]   That's probably the more complex bit
[00:09:34.320 --> 00:09:36.320]   that we will need to figure out here.
[00:09:36.320 --> 00:09:40.680]   So once we pass that query, okay,
[00:09:40.680 --> 00:09:44.840]   so we pass the query from chat GPT into our plugin,
[00:09:44.840 --> 00:09:47.240]   we are now in a space
[00:09:47.240 --> 00:09:50.720]   that is not necessarily anything to do with chat GPT.
[00:09:50.720 --> 00:09:55.360]   Okay, so in this space is our own code or API,
[00:09:55.360 --> 00:09:56.960]   whatever that we have set up.
[00:09:56.960 --> 00:10:00.040]   The API that I've set up here
[00:10:00.040 --> 00:10:05.040]   is based on the chat GPT retrieval plugin API
[00:10:05.040 --> 00:10:09.160]   that was created by OpenAI.
[00:10:09.160 --> 00:10:10.720]   And you can actually see that here.
[00:10:10.720 --> 00:10:15.720]   So we go to github.com/openai/chat-gpt-retrieval-plugin.
[00:10:16.560 --> 00:10:19.240]   And what kind of tells you here
[00:10:19.240 --> 00:10:22.280]   that chat GPT retrieval plugin lets you easily search
[00:10:22.280 --> 00:10:24.400]   and find personal or work documents
[00:10:24.400 --> 00:10:27.960]   by asking questions in everyday language, right?
[00:10:27.960 --> 00:10:30.920]   Sounds pretty familiar to what we have done.
[00:10:30.920 --> 00:10:32.960]   It's just rather than personal work documents,
[00:10:32.960 --> 00:10:37.640]   we've used Lex Friedman transcribed text.
[00:10:37.640 --> 00:10:41.160]   Cool, so we have that retrieval plugin,
[00:10:41.160 --> 00:10:46.160]   we'll call it the chat GPT retrieval plugin.
[00:10:46.480 --> 00:10:49.360]   CRP, okay, right?
[00:10:49.360 --> 00:10:54.000]   We've set it up to use OpenAI's text embedding model,
[00:10:54.000 --> 00:10:57.000]   ARDA002, okay?
[00:10:57.000 --> 00:11:01.120]   So ARDA002, and you can basically think of this
[00:11:01.120 --> 00:11:04.800]   as the same as the GPT models that you've seen,
[00:11:04.800 --> 00:11:06.920]   but rather than generating text,
[00:11:06.920 --> 00:11:11.280]   this one actually generates numerical vectors
[00:11:11.280 --> 00:11:16.240]   based on the semantic meaning of the text
[00:11:16.240 --> 00:11:18.720]   that you're giving it, okay?
[00:11:18.720 --> 00:11:20.880]   So what I mean by that is,
[00:11:20.880 --> 00:11:24.040]   you're basically creating these vectors
[00:11:24.040 --> 00:11:26.160]   that go into this vector space here,
[00:11:26.160 --> 00:11:30.560]   and this vector and this vector here
[00:11:30.560 --> 00:11:32.240]   will have a similar meaning,
[00:11:32.240 --> 00:11:34.280]   whereas this vector all the way over here,
[00:11:34.280 --> 00:11:36.200]   because of this distance,
[00:11:36.200 --> 00:11:39.160]   this space between this vector and the others,
[00:11:39.160 --> 00:11:44.000]   this one will have some different meaning, okay?
[00:11:44.000 --> 00:11:48.960]   So it's like we are mapping human meaning
[00:11:48.960 --> 00:11:53.320]   into numerical representations
[00:11:53.320 --> 00:11:58.120]   that we can then use to perform searches.
[00:11:58.120 --> 00:12:00.600]   So how do we perform searches through this space?
[00:12:00.600 --> 00:12:04.840]   Okay, so imagine we have our user query over here,
[00:12:04.840 --> 00:12:07.040]   it's going to be, what was our question?
[00:12:07.040 --> 00:12:11.280]   It was, ask Lex about the future of AI, right?
[00:12:11.280 --> 00:12:14.760]   So the future of AI is basically our query.
[00:12:14.760 --> 00:12:17.720]   It's going to go into this R002 model,
[00:12:17.720 --> 00:12:19.880]   and that is going to create an embedding, right?
[00:12:19.880 --> 00:12:23.880]   And it's going to maybe place it over here, right?
[00:12:23.880 --> 00:12:28.040]   So then we know that these two items,
[00:12:28.040 --> 00:12:32.440]   these two documents that we already embedded,
[00:12:32.440 --> 00:12:35.600]   that they are very similar,
[00:12:35.600 --> 00:12:38.840]   and therefore probably highly likely
[00:12:38.840 --> 00:12:41.880]   to be relevant to our particular query, okay?
[00:12:41.880 --> 00:12:43.560]   And all of this,
[00:12:43.560 --> 00:12:46.040]   this whole thing that you have going on here,
[00:12:46.040 --> 00:12:47.480]   where you have all these vectors
[00:12:47.480 --> 00:12:49.040]   and you're searching through them,
[00:12:49.040 --> 00:12:51.920]   all of that is handled by another service,
[00:12:51.920 --> 00:12:56.160]   which is the Pinecone Vector Database, okay?
[00:12:56.160 --> 00:12:58.440]   So the Pinecone Vector Database
[00:12:58.440 --> 00:13:03.080]   is basically a way of searching
[00:13:03.080 --> 00:13:04.920]   through this numerical vector space
[00:13:04.920 --> 00:13:07.680]   in a very efficient way at scale, right?
[00:13:07.680 --> 00:13:11.400]   So you can have like hundreds of millions of these vectors
[00:13:11.400 --> 00:13:13.280]   or basically documents in there,
[00:13:13.280 --> 00:13:17.040]   and you'll be able to retrieve relevant items
[00:13:17.040 --> 00:13:19.280]   within around a 10th of a second
[00:13:19.280 --> 00:13:22.360]   or something super fast, right?
[00:13:22.360 --> 00:13:24.080]   So that is all handled
[00:13:24.080 --> 00:13:27.760]   by the Vector Database component there, okay?
[00:13:27.760 --> 00:13:32.760]   So we are then going to return those items out here, okay?
[00:13:32.760 --> 00:13:36.840]   So we bring those here,
[00:13:36.840 --> 00:13:38.960]   and we'll see these are our,
[00:13:38.960 --> 00:13:40.320]   we'll say that we're going to return
[00:13:40.320 --> 00:13:43.240]   the top three most relevant items, okay?
[00:13:43.240 --> 00:13:46.880]   So let's say that was another item over here, right?
[00:13:46.880 --> 00:13:48.720]   So we're going to return those,
[00:13:48.720 --> 00:13:51.440]   and that is basically,
[00:13:51.440 --> 00:13:56.360]   this is going to be the output of our CRP,
[00:13:56.360 --> 00:14:00.320]   so our chat GPT retrieval plugin, okay?
[00:14:00.320 --> 00:14:05.120]   So they go into here and they go back to chat GPT.
[00:14:05.120 --> 00:14:08.200]   Now, chat GPT has more information
[00:14:08.200 --> 00:14:09.800]   to answer the question, right?
[00:14:09.800 --> 00:14:12.720]   And it also, as well as the original text
[00:14:12.720 --> 00:14:14.440]   that we have over here, right?
[00:14:14.440 --> 00:14:17.160]   It also has where this text has come from.
[00:14:17.160 --> 00:14:18.960]   So it has the podcast episode titles
[00:14:18.960 --> 00:14:22.440]   and the URL to the podcast episode and everything else,
[00:14:22.440 --> 00:14:25.080]   which is exactly what you can see in here, right?
[00:14:25.080 --> 00:14:27.480]   So these results, we have the original query,
[00:14:27.480 --> 00:14:30.400]   and then we have the things that we returned, right?
[00:14:30.400 --> 00:14:33.920]   So we have that text and the metadata title
[00:14:33.920 --> 00:14:37.600]   and the video ID here,
[00:14:37.600 --> 00:14:40.680]   which I think is actually being used for the URL.
[00:14:40.680 --> 00:14:42.320]   But that's something we should actually fix.
[00:14:42.320 --> 00:14:44.120]   So in the source here, we should add,
[00:14:44.120 --> 00:14:49.120]   or in the URL, we should actually add the actual URL
[00:14:49.120 --> 00:14:51.280]   for the video.
[00:14:51.280 --> 00:14:52.960]   But that's something we can do another time.
[00:14:52.960 --> 00:14:55.280]   So what we have so far is,
[00:14:55.280 --> 00:14:59.600]   we've just basically augmented our original query
[00:14:59.600 --> 00:15:02.200]   with all of this other relevant information
[00:15:02.200 --> 00:15:04.480]   from the Lex Friedman podcast, right?
[00:15:04.480 --> 00:15:08.280]   So now, our query is going to be a ton of text
[00:15:08.280 --> 00:15:10.960]   based on all that stuff,
[00:15:10.960 --> 00:15:14.920]   and we've just returned it to JetGPT over here,
[00:15:14.920 --> 00:15:17.320]   and we're saying, okay,
[00:15:17.320 --> 00:15:21.560]   I want you to answer the user's question
[00:15:21.560 --> 00:15:23.800]   based on all of this information here.
[00:15:23.800 --> 00:15:27.760]   The user's question is, and then it's whatever you,
[00:15:27.760 --> 00:15:29.560]   whatever you put in here, right?
[00:15:31.400 --> 00:15:33.360]   So that gets fed into there.
[00:15:33.360 --> 00:15:37.400]   And then, JetGPT is going to answer your question,
[00:15:37.400 --> 00:15:39.320]   and we saw that, right?
[00:15:39.320 --> 00:15:41.560]   So we got this kind of response
[00:15:41.560 --> 00:15:44.920]   where it's telling you a ton of stuff, right?
[00:15:44.920 --> 00:15:46.760]   And it's sourcing the information.
[00:15:46.760 --> 00:15:49.400]   Look, we can actually click on here,
[00:15:49.400 --> 00:15:53.080]   and it's going to take us through to that episode, right?
[00:15:53.080 --> 00:15:57.800]   So this is, yeah, the Eric Brian Jolson episode.
[00:15:58.800 --> 00:16:03.520]   But there is still a little more to this whole thing
[00:16:03.520 --> 00:16:05.400]   than what I've just described.
[00:16:05.400 --> 00:16:09.320]   I mean, Wanda is actually the code to do all of this,
[00:16:09.320 --> 00:16:12.840]   which you can actually find if you go to GitHub.
[00:16:12.840 --> 00:16:17.640]   The plugin code itself is actually all here, right?
[00:16:17.640 --> 00:16:22.440]   So this is the forked JetGPT repo.
[00:16:22.440 --> 00:16:25.600]   And yeah, I mean, this is,
[00:16:25.600 --> 00:16:27.760]   it basically contains the same code
[00:16:27.760 --> 00:16:32.200]   as what you would find in the JetGPT retrieval plugin.
[00:16:32.200 --> 00:16:34.960]   It's just I've modified it a little bit
[00:16:34.960 --> 00:16:37.280]   for our particular use case.
[00:16:37.280 --> 00:16:40.480]   So for example, if you go to the well-known here,
[00:16:40.480 --> 00:16:43.680]   this is basically where you sell the instructions
[00:16:43.680 --> 00:16:47.880]   for JetGPT to understand your plugin.
[00:16:47.880 --> 00:16:50.760]   And you go to the AI plugin here, right?
[00:16:50.760 --> 00:16:53.640]   So I've changed the name for the model, okay?
[00:16:53.640 --> 00:16:58.520]   So the name that JetGPT we use to understand this model,
[00:16:58.520 --> 00:17:01.360]   the name that we understand it with, right?
[00:17:01.360 --> 00:17:04.400]   We also have, okay, you can use this tool
[00:17:04.400 --> 00:17:07.800]   to answer user questions using Lex Friedman podcast.
[00:17:07.800 --> 00:17:10.040]   If the user says, "Ask Lex," okay?
[00:17:10.040 --> 00:17:12.760]   So we saw that "Ask Lex" earlier on.
[00:17:12.760 --> 00:17:14.840]   Use this tool to get the answer.
[00:17:14.840 --> 00:17:17.000]   This tool can also be used to follow up questions
[00:17:17.000 --> 00:17:19.560]   from the user and filters can be used
[00:17:19.560 --> 00:17:23.440]   to grab more information from specific podcasts
[00:17:23.440 --> 00:17:26.960]   like by filtering for a specific podcast title, right?
[00:17:26.960 --> 00:17:29.200]   So that's the primary context,
[00:17:29.200 --> 00:17:31.560]   the primary instructions I've given JetGPT
[00:17:31.560 --> 00:17:34.560]   on how to use this plugin, which is they're pretty light.
[00:17:34.560 --> 00:17:36.920]   And then down here,
[00:17:36.920 --> 00:17:41.000]   we've just set up where our API is hosted, right?
[00:17:41.000 --> 00:17:44.760]   So we need to include that so that JetGPT knows
[00:17:44.760 --> 00:17:48.720]   where to find the opening API spec for our app.
[00:17:48.720 --> 00:17:51.440]   So these are basically going to be the instructions
[00:17:51.440 --> 00:17:53.880]   that JetGPT will use in order to understand
[00:17:53.880 --> 00:17:57.240]   how to actually programmatically interact
[00:17:57.240 --> 00:18:00.920]   with our API or our plugin, okay?
[00:18:00.920 --> 00:18:03.480]   And there were some changes made there as well.
[00:18:03.480 --> 00:18:06.880]   Nothing significant, okay?
[00:18:06.880 --> 00:18:11.120]   So just put in the server, you have to do this.
[00:18:11.120 --> 00:18:14.160]   And then there are some instructions
[00:18:14.160 --> 00:18:18.720]   around how JetGPT can use this again.
[00:18:18.720 --> 00:18:22.840]   So say this is an array of search query objects,
[00:18:22.840 --> 00:18:25.560]   each contain natural language query string, query,
[00:18:25.560 --> 00:18:29.680]   and an optional metadata filter, filter, okay?
[00:18:29.680 --> 00:18:33.120]   So we also say here filters can help refine search results
[00:18:33.120 --> 00:18:36.440]   based on criteria such as document title or time period.
[00:18:36.440 --> 00:18:38.560]   So we can say these are particularly useful
[00:18:38.560 --> 00:18:40.080]   when a user asks for more information
[00:18:40.080 --> 00:18:41.400]   about a particular record.
[00:18:41.400 --> 00:18:44.040]   For example, the user may ask for more information
[00:18:44.040 --> 00:18:46.400]   after being provided with information
[00:18:46.400 --> 00:18:49.680]   from a specific podcast with the title,
[00:18:49.680 --> 00:18:52.000]   Our AI Future with JetGPT, right?
[00:18:52.000 --> 00:18:53.640]   So I'm using an example here
[00:18:53.640 --> 00:18:57.680]   so that JetGPT knows exactly what to do.
[00:18:57.680 --> 00:19:00.280]   In that case, the filter field can then be used
[00:19:00.280 --> 00:19:03.400]   to return more information by using title,
[00:19:03.400 --> 00:19:05.960]   Our AI Future with JetGPT, right?
[00:19:05.960 --> 00:19:10.520]   So we've been very specific and explicit
[00:19:10.520 --> 00:19:13.760]   on how JetGPT can use this.
[00:19:13.760 --> 00:19:15.960]   Okay, so we build that.
[00:19:15.960 --> 00:19:18.880]   Let me show you some very quick code
[00:19:18.880 --> 00:19:21.240]   that just shows how I actually populated
[00:19:21.240 --> 00:19:23.760]   our database with all this stuff.
[00:19:23.760 --> 00:19:25.760]   So there'll be a link to this.
[00:19:25.760 --> 00:19:27.400]   You'll be able to, in fact,
[00:19:27.400 --> 00:19:30.280]   it will be somewhere around the top of the video right now.
[00:19:30.280 --> 00:19:32.400]   To this notebook, you'll just be able to run it through
[00:19:32.400 --> 00:19:34.720]   and do exactly what I'm doing here.
[00:19:34.720 --> 00:19:38.120]   Okay, so there are a few items that you need,
[00:19:38.120 --> 00:19:39.480]   and we need this in general
[00:19:39.480 --> 00:19:42.720]   for the rest of the plugin as well.
[00:19:42.720 --> 00:19:44.720]   So there's the open AI API key,
[00:19:44.720 --> 00:19:48.960]   which we get from platform.openai.com,
[00:19:48.960 --> 00:19:50.720]   the Pinecone API key,
[00:19:50.720 --> 00:19:54.400]   which we get from app.pinecone.io,
[00:19:54.400 --> 00:19:56.080]   and these other things as well.
[00:19:56.080 --> 00:19:58.040]   So we run through this.
[00:19:58.040 --> 00:20:01.240]   We're using a pre-built dataset in this example,
[00:20:01.240 --> 00:20:04.080]   but actually, if you wanted to do the download
[00:20:04.080 --> 00:20:07.000]   and transcribing yourself, you just open this,
[00:20:07.000 --> 00:20:10.520]   and you can actually see all of the code that I use there.
[00:20:10.520 --> 00:20:15.520]   So I actually built this PodGPT library to help with that.
[00:20:15.520 --> 00:20:18.160]   It's just easier, okay?
[00:20:18.160 --> 00:20:22.320]   So in reality, there's just a few lines of code, okay?
[00:20:22.320 --> 00:20:23.840]   Cool.
[00:20:23.840 --> 00:20:25.880]   But that takes some time, right?
[00:20:25.880 --> 00:20:29.000]   Downloading all of these, like, mp3 files
[00:20:29.000 --> 00:20:31.360]   from the YouTube videos
[00:20:31.360 --> 00:20:34.800]   and then transcribing them using OpenAI's Whisper,
[00:20:34.800 --> 00:20:35.760]   you know, it takes a while.
[00:20:35.760 --> 00:20:39.280]   So there's also this option, right?
[00:20:39.280 --> 00:20:42.040]   So I've already done all of this, obviously,
[00:20:42.040 --> 00:20:43.440]   for the Lex Rubin podcast.
[00:20:43.440 --> 00:20:46.480]   So you can actually just use my dataset here.
[00:20:46.480 --> 00:20:49.400]   This is hosted on HuggingFace datasets.
[00:20:49.400 --> 00:20:53.200]   There's 499 videos in there, okay?
[00:20:53.200 --> 00:20:55.800]   But they've already been transcribed.
[00:20:55.800 --> 00:21:00.320]   So then all you need to do is you initialize your --
[00:21:00.320 --> 00:21:03.160]   this is your Pinecone index
[00:21:03.160 --> 00:21:07.440]   and also the embedding model that you're going to be using
[00:21:07.440 --> 00:21:10.640]   to actually create those embeddings
[00:21:10.640 --> 00:21:12.920]   and store everything in Pinecone, all right?
[00:21:12.920 --> 00:21:16.920]   So that is going to be using OpenAI
[00:21:16.920 --> 00:21:21.520]   and specifically the OpenAI text embedding R002 model, okay?
[00:21:21.520 --> 00:21:24.520]   And then here, I'm just looping through all of the podcasts.
[00:21:24.520 --> 00:21:28.480]   We're indexing everything, and that is actually it, okay?
[00:21:28.480 --> 00:21:32.480]   That's all I did in order to index all of this text.
[00:21:32.480 --> 00:21:35.080]   Then from there, I just went over to DigitalOcean.
[00:21:35.080 --> 00:21:38.360]   So DigitalOcean is just like a service
[00:21:38.360 --> 00:21:40.560]   where we can host APIs,
[00:21:40.560 --> 00:21:43.440]   which is pretty ideal for what we have, right?
[00:21:43.440 --> 00:21:49.120]   So we have this James Callum AskLex plugin.
[00:21:49.120 --> 00:21:52.520]   I basically just went over here,
[00:21:52.520 --> 00:21:57.400]   went to Create, Use, which one, Apps, okay?
[00:21:57.400 --> 00:22:01.240]   Clicked on Apps, clicked on Deploy from GitHub,
[00:22:01.240 --> 00:22:03.520]   and just deployed from this repo.
[00:22:03.520 --> 00:22:06.400]   And then it deploys, and I end up with this, right?
[00:22:06.400 --> 00:22:08.200]   So I have the AskLex app here.
[00:22:08.200 --> 00:22:09.600]   You can click on there.
[00:22:09.600 --> 00:22:13.840]   This gives you the URL for your app.
[00:22:13.840 --> 00:22:15.520]   So you can copy that.
[00:22:15.520 --> 00:22:20.520]   You can open it, and we will probably see this, okay?
[00:22:20.520 --> 00:22:22.400]   So detail not found, right?
[00:22:22.400 --> 00:22:23.520]   That's fine.
[00:22:23.520 --> 00:22:26.920]   It's just like the URL of the API.
[00:22:26.920 --> 00:22:30.040]   Without the endpoints or without any file extensions,
[00:22:30.040 --> 00:22:32.520]   you're going to find this, okay?
[00:22:32.520 --> 00:22:35.960]   So then I took that.
[00:22:35.960 --> 00:22:42.000]   I went over to -- let's go to New Chat.
[00:22:42.000 --> 00:22:45.520]   I went to Plugin Store.
[00:22:45.520 --> 00:22:47.680]   I said, "Develop your own plugin."
[00:22:47.680 --> 00:22:49.400]   My manifest is ready.
[00:22:49.400 --> 00:22:54.080]   So this is the -- we saw this, the AIPlugin.json file.
[00:22:54.080 --> 00:22:57.800]   And then I just pasted in the URL, okay?
[00:22:57.800 --> 00:23:01.360]   So from there, we can see, okay, we've got ValidateManifest,
[00:23:01.360 --> 00:23:04.080]   ValidateOpenAPISpec.
[00:23:04.080 --> 00:23:06.160]   And then you can see, okay, we have, like,
[00:23:06.160 --> 00:23:10.760]   all the information that I include in there.
[00:23:10.760 --> 00:23:11.920]   Okay, so I've already installed it.
[00:23:11.920 --> 00:23:13.600]   I'm not going to install it again.
[00:23:13.600 --> 00:23:16.640]   But then from there, all you do is you go to your Plugin Store.
[00:23:16.640 --> 00:23:18.560]   You go to Unverified Plugins,
[00:23:18.560 --> 00:23:22.440]   and you have your actual plugin here.
[00:23:22.440 --> 00:23:25.480]   And then you just go ahead and use it, right?
[00:23:25.480 --> 00:23:31.320]   So it's incredibly easy to pull this together.
[00:23:31.320 --> 00:23:32.520]   Obviously, there are a few steps.
[00:23:32.520 --> 00:23:35.800]   It's not the most straightforward thing
[00:23:35.800 --> 00:23:37.280]   in the entire world,
[00:23:37.280 --> 00:23:38.800]   but it's definitely not the most complex.
[00:23:38.800 --> 00:23:41.080]   And given what you can do, it's pretty cool.
[00:23:41.080 --> 00:23:43.560]   So now I can just ask about random things.
[00:23:43.560 --> 00:23:45.960]   Like, you know, I can ask Lex.
[00:23:45.960 --> 00:23:53.880]   I want to know what he thinks about World War II, right?
[00:23:53.880 --> 00:23:57.160]   I know this is, like, a favorite talking point of him,
[00:23:57.160 --> 00:24:03.600]   so there's probably plenty of things to talk about there.
[00:24:03.600 --> 00:24:05.920]   Okay, so, yeah, we get all this information.
[00:24:05.920 --> 00:24:10.640]   We're getting, like, pretty similar thing to before.
[00:24:10.640 --> 00:24:13.000]   And then we can kind of, like, draw down.
[00:24:13.000 --> 00:24:15.640]   We can ask, okay, cool, who's, like, this guy?
[00:24:15.640 --> 00:24:16.960]   I have no idea.
[00:24:16.960 --> 00:24:19.000]   So we can ask about that.
[00:24:19.000 --> 00:24:23.200]   Like, tell me more about the thingy episode,
[00:24:23.200 --> 00:24:27.120]   this episode, and it will actually be able to do this.
[00:24:27.120 --> 00:24:28.840]   You know, it's just going to refer back.
[00:24:28.840 --> 00:24:31.080]   And we can also just use this.
[00:24:31.080 --> 00:24:33.480]   Like, we don't have to use it as Lex plug-in
[00:24:33.480 --> 00:24:35.680]   every single time, right?
[00:24:35.680 --> 00:24:39.240]   So maybe I'll let this generate,
[00:24:39.240 --> 00:24:41.800]   and then we can ask another question.
[00:24:41.800 --> 00:24:45.440]   Maybe, you know, something about this makes us think,
[00:24:45.440 --> 00:24:48.000]   oh, I kind of want to know a little more about that.
[00:24:48.000 --> 00:24:49.760]   So maybe we can say,
[00:24:49.760 --> 00:24:53.760]   so there's this Ian Kershaw biography on Adolf Hitler.
[00:24:53.760 --> 00:24:56.880]   We can search that, see what it is.
[00:24:56.880 --> 00:25:04.560]   So what do you know about that?
[00:25:04.560 --> 00:25:07.640]   Now, I'm not sure if it's going to use the SLX plug-in.
[00:25:07.640 --> 00:25:10.200]   Okay, so here it's not using the SLX plug-in
[00:25:10.200 --> 00:25:11.120]   because it doesn't need to.
[00:25:11.120 --> 00:25:14.280]   It already probably knows some stuff about this.
[00:25:14.280 --> 00:25:17.680]   Now, my internet isn't great, so it just cut out,
[00:25:17.680 --> 00:25:25.200]   but maybe I can try and regenerate that.
[00:25:25.200 --> 00:25:26.920]   Okay, so we get a ton of information
[00:25:26.920 --> 00:25:30.880]   about this particular book that was kind of inspired
[00:25:30.880 --> 00:25:35.240]   by us reading through the Lex Friedman information.
[00:25:35.240 --> 00:25:38.920]   But this, in particular, we didn't need that
[00:25:38.920 --> 00:25:40.720]   in order to talk about this book.
[00:25:40.720 --> 00:25:43.920]   So Chad G. Petit knows this and has decided,
[00:25:43.920 --> 00:25:47.840]   okay, I don't need to ask Lex this question.
[00:25:47.840 --> 00:25:50.960]   I can actually just give you all this information
[00:25:50.960 --> 00:25:54.360]   from my training memory, essentially.
[00:25:54.360 --> 00:25:58.440]   So, I mean, I think that is all fascinating
[00:25:58.440 --> 00:26:01.400]   and it's really cool how quickly
[00:26:01.400 --> 00:26:04.320]   we can just build something like this.
[00:26:04.320 --> 00:26:06.000]   It doesn't take that much.
[00:26:06.000 --> 00:26:08.200]   Now, I haven't dived super deep
[00:26:08.200 --> 00:26:11.960]   into the technical side of things here.
[00:26:11.960 --> 00:26:13.520]   I showed you some of the things
[00:26:13.520 --> 00:26:15.120]   or I showed you some of the code.
[00:26:15.120 --> 00:26:18.600]   I showed you the GitHub repo.
[00:26:18.600 --> 00:26:22.400]   I think with that, you can pretty much do all of this.
[00:26:22.400 --> 00:26:26.240]   But if you are struggling to kind of follow along
[00:26:26.240 --> 00:26:28.600]   or you just want a bit more of a technical deep dive,
[00:26:28.600 --> 00:26:33.480]   I do actually have another video on Chad G. Petit plugins
[00:26:33.480 --> 00:26:38.480]   and specifically the OpenAI retrieval plugin
[00:26:38.480 --> 00:26:41.080]   that we saw at the start of this video.
[00:26:41.080 --> 00:26:45.240]   So if you like and you want to go into technical details,
[00:26:45.240 --> 00:26:48.520]   I would definitely recommend following along with that video
[00:26:48.520 --> 00:26:51.680]   as I actually go through, like from start to finish,
[00:26:51.680 --> 00:26:56.680]   building a plugin, not specifically for podcasts,
[00:26:56.680 --> 00:27:00.360]   but for basically online code docs.
[00:27:00.360 --> 00:27:03.320]   But yeah, for now, that's it for this video.
[00:27:03.320 --> 00:27:07.080]   I hope this has been interesting and insightful
[00:27:07.080 --> 00:27:08.920]   as to the sort of things that you can build
[00:27:08.920 --> 00:27:11.280]   with these Chad G. Petit plugins.
[00:27:11.280 --> 00:27:16.280]   If you are right now looking at where to find these plugins,
[00:27:16.280 --> 00:27:21.400]   there is right now still a wait list to get access to those.
[00:27:21.400 --> 00:27:24.480]   So I will make sure that the wait list link
[00:27:24.480 --> 00:27:26.520]   is somewhere in either the description of the video
[00:27:26.520 --> 00:27:29.600]   or even at the top of the video right now.
[00:27:29.600 --> 00:27:31.800]   So you can go and sign up for that
[00:27:31.800 --> 00:27:33.880]   if you don't have access already.
[00:27:33.880 --> 00:27:35.640]   For now, I will leave it there.
[00:27:35.640 --> 00:27:38.560]   Thank you very much for watching the video.
[00:27:38.560 --> 00:27:41.040]   I hope this has been helpful
[00:27:41.040 --> 00:27:43.720]   and I will see you again in the next one.
[00:27:43.720 --> 00:27:44.560]   Bye.
[00:27:44.560 --> 00:27:47.140]   (gentle music)
[00:27:47.980 --> 00:27:50.560]   (gentle music)
[00:27:50.560 --> 00:27:53.140]   (gentle music)
[00:27:53.140 --> 00:27:55.720]   (gentle music)
[00:27:55.720 --> 00:27:58.300]   (gentle music)
[00:27:58.300 --> 00:28:00.360]   you

