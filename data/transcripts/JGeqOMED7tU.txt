
[00:00:00.000 --> 00:00:01.960]   Hey there, thank you for clicking on this video.
[00:00:01.960 --> 00:00:04.880]   This might be an abrupt start to this video because this was a
[00:00:04.880 --> 00:00:08.720]   continuation for from the ask me anything with Franchois Chollet,
[00:00:08.720 --> 00:00:10.360]   the creator of Keras himself.
[00:00:10.360 --> 00:00:12.560]   The video was done in one go.
[00:00:12.560 --> 00:00:13.600]   It was one live stream.
[00:00:13.600 --> 00:00:15.000]   Hence there's an abrupt starting.
[00:00:15.000 --> 00:00:16.920]   Hence I'm recording a separate intro.
[00:00:16.920 --> 00:00:21.320]   This video goes over the first three chapters, two or three chapters of the
[00:00:21.320 --> 00:00:25.560]   book, and if you'd like to be a part of this series, you can find the link in
[00:00:25.560 --> 00:00:28.480]   the description where you can sign up for the meetup.
[00:00:28.480 --> 00:00:29.520]   All are recorded.
[00:00:29.600 --> 00:00:30.760]   Everyone is welcome.
[00:00:30.760 --> 00:00:34.840]   Uh, you need to own a copy of deep learning with Python.
[00:00:34.840 --> 00:00:36.680]   Second edition to join the group.
[00:00:36.680 --> 00:00:39.120]   Apart from that, anyone and everyone is welcome.
[00:00:39.120 --> 00:00:42.160]   We'll be going through an understanding concepts in sequential order.
[00:00:42.160 --> 00:00:45.360]   And for now, I'll let you watch the video.
[00:00:45.360 --> 00:00:50.120]   Awesome.
[00:00:50.120 --> 00:00:57.120]   I'll assume everyone can see my screen and, uh, I've already gone to the first
[00:00:57.320 --> 00:01:00.920]   half of the exciting bit, which was the ask me anything with Franchois.
[00:01:00.920 --> 00:01:03.480]   Uh, but I'll still remind everyone of the agenda.
[00:01:03.480 --> 00:01:06.360]   We're reading this incredible book.
[00:01:06.360 --> 00:01:09.360]   I took a really long trip to get that picture clicked.
[00:01:09.360 --> 00:01:12.240]   Uh, this is from my home state.
[00:01:12.240 --> 00:01:14.440]   So I hope everyone likes this picture a bit.
[00:01:14.440 --> 00:01:16.560]   Uh, sorry for the nerdy details.
[00:01:16.560 --> 00:01:19.840]   Uh, but here are the, here's the agenda for today.
[00:01:19.840 --> 00:01:22.520]   We'll be going through the book title deep learning with Python.
[00:01:22.520 --> 00:01:26.880]   I'll, uh, as an honor code to everyone joining these sessions, the future
[00:01:26.880 --> 00:01:28.720]   ones will be live streamed to YouTube.
[00:01:28.720 --> 00:01:31.960]   And I would request everyone to purchase a copy.
[00:01:31.960 --> 00:01:36.160]   Any, uh, sharing of the book will not be tolerated in the group.
[00:01:36.160 --> 00:01:39.160]   I will be going through the chapters in sequential order,
[00:01:39.160 --> 00:01:41.640]   summarizing different concepts.
[00:01:41.640 --> 00:01:45.480]   And, uh, for today we'll aim for chapter one to five.
[00:01:45.480 --> 00:01:49.720]   I'll try to summarize the different concepts in there and do a
[00:01:49.720 --> 00:01:51.280]   code walkthrough of the chapters.
[00:01:55.640 --> 00:01:59.240]   So here is the outline of the entire book.
[00:01:59.240 --> 00:02:02.160]   And as you can see, it's about 14 chapters.
[00:02:02.160 --> 00:02:08.480]   I want to remind everyone that, uh, our sessions are open to everyone.
[00:02:08.480 --> 00:02:13.280]   Anyone and everyone is welcome to join, which also means that I will
[00:02:13.280 --> 00:02:18.320]   paste this according to an intermediate practitioner, which means I will going
[00:02:18.320 --> 00:02:24.080]   be, I'll be going over a few details that are introductory and I'll slow
[00:02:24.080 --> 00:02:27.120]   down at places where I take longer to read something.
[00:02:27.120 --> 00:02:30.560]   So if I take 15 minutes to read something, I'll assume the audience would require
[00:02:30.560 --> 00:02:33.240]   five at that point, I'll highlight a concept.
[00:02:33.240 --> 00:02:39.720]   And I mentioned this point because, um, I'm not sure if you can see any
[00:02:39.720 --> 00:02:44.960]   similarities with me holding up my cup, but I am not a Keras expert.
[00:02:44.960 --> 00:02:50.040]   I have been spending a lot of time in PyTorch, but I always wanted to pick up
[00:02:50.040 --> 00:02:56.360]   Keras and I'm using this as an excuse to learn Keras myself, Franchot mentioned
[00:02:56.360 --> 00:03:01.440]   the technique of, uh, Feynman to teach something that you've just learned.
[00:03:01.440 --> 00:03:06.920]   I take that quite to my heart and seal this opportunity at my work also to
[00:03:06.920 --> 00:03:09.480]   teach everyone of things I'm learning.
[00:03:09.480 --> 00:03:14.080]   Uh, and I'm sure I see, I saw a lot of familiar names in the question and answers.
[00:03:14.080 --> 00:03:19.080]   Uh, I'm sure all of you would understand that I'm mad passionate about this and I
[00:03:19.080 --> 00:03:23.400]   bring these topics to you because, uh, I would absolutely love any feedback and
[00:03:23.400 --> 00:03:26.080]   I'm always happy to answer any questions.
[00:03:26.080 --> 00:03:30.440]   So if you think I skip any details, if I don't know any answer, I'll come
[00:03:30.440 --> 00:03:32.080]   back and answer it in the next session.
[00:03:32.080 --> 00:03:37.200]   But I really, really encourage you to please ask any or all of your
[00:03:37.200 --> 00:03:38.320]   questions that you might have.
[00:03:38.320 --> 00:03:39.560]   I'm happy to go into them.
[00:03:39.560 --> 00:03:43.520]   So here's how I'll structure this reading group.
[00:03:43.520 --> 00:03:48.920]   We'll be going through all of these chapters in sequential order and
[00:03:48.920 --> 00:03:54.480]   the first five or actually the first seven are quite introductory and they're self-paced.
[00:03:54.480 --> 00:03:58.600]   So I would encourage you all to spend some time reading the theory.
[00:03:58.600 --> 00:04:02.280]   I'll try to summarize the essential amounts of theory.
[00:04:02.280 --> 00:04:07.080]   The one that needs some explanation and the one that self-explanatory I'll glance over it.
[00:04:07.080 --> 00:04:11.240]   And after that, we'll be going through the Colab notebooks.
[00:04:11.240 --> 00:04:17.960]   Actually the GitHub repository has been open source by Franscho in the Keras repo, I believe.
[00:04:18.640 --> 00:04:21.760]   And I'll be doing a code walkthrough of individual cells for every single
[00:04:21.760 --> 00:04:23.760]   chapter and explaining different concepts.
[00:04:23.760 --> 00:04:27.680]   I also, as I mentioned earlier, love the Kaggle world.
[00:04:27.680 --> 00:04:31.360]   We'll be also looking at a few Kaggle examples and I've been
[00:04:31.360 --> 00:04:33.200]   reaching out to a few Keras experts.
[00:04:33.200 --> 00:04:38.920]   Akash and Sayag, I'm sure the people from the Keras world will recognize their
[00:04:38.920 --> 00:04:41.720]   names will be joining us in future sessions to teach us more.
[00:04:41.720 --> 00:04:45.800]   So a lot of exciting things are going to happen in the next few weeks.
[00:04:46.480 --> 00:04:51.400]   That is to brace all of you and also remind you that if you ever have
[00:04:51.400 --> 00:04:53.400]   any feedback, it's most welcomed.
[00:04:53.400 --> 00:05:01.400]   So I was trying to think of the prerequisites in my preparation.
[00:05:01.400 --> 00:05:07.440]   I spent my time over the holidays going through the book and I've made it around
[00:05:07.440 --> 00:05:13.880]   to the 10th or 11th chapter, I think it's fair to say that some Python knowledge is
[00:05:13.880 --> 00:05:18.960]   sufficient, which means if you spent any amount of time, that's more than five
[00:05:18.960 --> 00:05:21.440]   hours coding in Python, you would be good.
[00:05:21.440 --> 00:05:24.040]   A GPU environment is helpful.
[00:05:24.040 --> 00:05:26.880]   You don't need to set up a new one.
[00:05:26.880 --> 00:05:29.040]   I really like ranting about this.
[00:05:29.040 --> 00:05:31.600]   So I'm going to emphasize by stopping sharing my screen.
[00:05:31.600 --> 00:05:38.960]   It's really easy to become a system administrator as a machine learning engineer.
[00:05:39.000 --> 00:05:43.360]   I have this box of three graphic cards here that I've set up
[00:05:43.360 --> 00:05:45.240]   aspiring to become a good calculator.
[00:05:45.240 --> 00:05:51.480]   And it takes a huge pain to maintain all of these libraries.
[00:05:51.480 --> 00:05:58.200]   If you've ever installed any dependencies, it is, it is quite painful to maintain it.
[00:05:58.200 --> 00:05:59.600]   Uh, keep it updated.
[00:05:59.600 --> 00:06:01.000]   There are a lot of errors.
[00:06:01.000 --> 00:06:06.400]   So the reason why I mentioned this, you want to learn Keras or I'm
[00:06:06.400 --> 00:06:09.800]   assuming if you're part of the session, you want to become better at machine
[00:06:09.800 --> 00:06:11.480]   learning, become better at deep learning.
[00:06:11.480 --> 00:06:17.560]   I feel like this because of becoming a better system administrator, where I do
[00:06:17.560 --> 00:06:24.480]   not go away, uh, try how to install something inside of a Docker container
[00:06:24.480 --> 00:06:26.600]   and try how to update my code environment.
[00:06:26.600 --> 00:06:32.800]   And in that process, I was going away from writing code in Keras or
[00:06:32.800 --> 00:06:35.200]   PyTorch, which was my true end goal.
[00:06:36.320 --> 00:06:39.400]   So my reminder to you all is please don't be a Siam.
[00:06:39.400 --> 00:06:41.480]   Please don't spend time doing that.
[00:06:41.480 --> 00:06:45.120]   Remember the path of least resistance is really helpful.
[00:06:45.120 --> 00:06:48.760]   People debate a lot about different paid options.
[00:06:48.760 --> 00:06:53.040]   Should you spend $50 per month on a provider?
[00:06:53.040 --> 00:06:54.880]   Should you spend $200?
[00:06:54.880 --> 00:06:57.880]   200 is a little high, let's say a hundred.
[00:06:57.880 --> 00:07:03.480]   If you want to learn something, and if you aspire to be in this field, I
[00:07:03.480 --> 00:07:06.000]   think that's a small price that's totally fine to pay.
[00:07:06.000 --> 00:07:11.480]   So instead of setting that up or instead of fighting with yourself, what option
[00:07:11.480 --> 00:07:15.080]   to get, uh, this was a long winded trying to encourage you to settle
[00:07:15.080 --> 00:07:16.560]   on one option and stick with that.
[00:07:16.560 --> 00:07:19.240]   So start with Colab.
[00:07:19.240 --> 00:07:20.080]   It's for free.
[00:07:20.080 --> 00:07:24.080]   Um, go to just look up Colab and you should head over there.
[00:07:24.080 --> 00:07:28.760]   It gives you, I think a good amount of compute for 12 hours, uh, that
[00:07:28.760 --> 00:07:32.560]   should keep you going for at least the first few chapters.
[00:07:34.040 --> 00:07:37.880]   My pro-chai tip is to spend twice as much time playing with
[00:07:37.880 --> 00:07:39.680]   code as compared to reading.
[00:07:39.680 --> 00:07:43.880]   I used to always be the kid that would at least in the
[00:07:43.880 --> 00:07:45.400]   classroom, raise my hand.
[00:07:45.400 --> 00:07:49.080]   So ma'am, why is this like, so what is this like?
[00:07:49.080 --> 00:07:52.160]   So how is it like, so I like being that with code and that's one
[00:07:52.160 --> 00:07:53.520]   thing I would encourage everyone.
[00:07:53.520 --> 00:07:56.880]   Please play around with code as much as you can.
[00:08:00.680 --> 00:08:06.200]   So I'll try to summarize two key concepts from the first chapter and
[00:08:06.200 --> 00:08:07.960]   the rest are quite self-explanatory.
[00:08:07.960 --> 00:08:11.040]   This is a screenshot from the incredible deep learning
[00:08:11.040 --> 00:08:12.480]   book by Ian Goodfellow.
[00:08:12.480 --> 00:08:18.200]   But whenever someone mentions AI, it's this broader overlook
[00:08:18.200 --> 00:08:19.720]   of quite a bit of techniques.
[00:08:19.720 --> 00:08:24.760]   And as you can see, deep learning is a very small subset of that.
[00:08:24.760 --> 00:08:29.320]   I'll take my sip of chai while I'll let everyone look at this.
[00:08:30.040 --> 00:08:30.040]   Okay.
[00:08:30.040 --> 00:08:46.000]   My strategy of staying hydrated is to drink chai every few minutes.
[00:08:46.000 --> 00:08:48.040]   Uh, not the best in the world.
[00:08:48.040 --> 00:08:48.560]   I'll admit.
[00:08:48.560 --> 00:08:54.840]   So in the first few chapters or in the first two chapters, uh, the
[00:08:54.840 --> 00:08:58.640]   author Franchois explains different techniques inside of AI.
[00:08:58.720 --> 00:09:02.840]   Machine learning broadly also encompasses or goes beyond
[00:09:02.840 --> 00:09:03.960]   deep learning itself.
[00:09:03.960 --> 00:09:08.960]   Deep learning primarily consists of neural networks that are a
[00:09:08.960 --> 00:09:10.800]   form of representation learning.
[00:09:10.800 --> 00:09:16.000]   Uh, there is a neat explanation where in one of the chapters it's
[00:09:16.000 --> 00:09:21.640]   explained like every layer transforms the understanding of what is
[00:09:21.640 --> 00:09:24.200]   happening inside of a neural network.
[00:09:24.640 --> 00:09:31.280]   For that, I'd like to point everyone to a paper by Zeiler and Fergus.
[00:09:31.280 --> 00:09:38.840]   I'm trying to, again, as a reminder, I'm trying to summarize the key points
[00:09:38.840 --> 00:09:40.400]   from the first few chapters here.
[00:09:40.400 --> 00:10:01.560]   So I'll give this a minute to load, but this paper shows you what is
[00:10:01.560 --> 00:10:04.200]   being learned inside of CNN.
[00:10:04.200 --> 00:10:08.280]   If you don't know what a CNN is, it's a form of deep learning model.
[00:10:08.560 --> 00:10:11.360]   I'll use the word model here very vaguely to describe
[00:10:11.360 --> 00:10:14.080]   things beyond and everywhere.
[00:10:14.080 --> 00:10:17.760]   But it's a model that works with images and it's low.
[00:10:17.760 --> 00:10:19.720]   It learns what's inside of an image.
[00:10:19.720 --> 00:10:23.960]   It helps you classify if an image has tie or not tie hot dog or not hot dog.
[00:10:23.960 --> 00:10:28.600]   It can tell you where inside of the image, there's a cup or a human, for example,
[00:10:28.600 --> 00:10:32.960]   that is a class of problem inside of image classification.
[00:10:32.960 --> 00:10:37.000]   Uh, it's called object detection, object localization.
[00:10:37.000 --> 00:10:38.480]   If you want to dive into that.
[00:10:39.040 --> 00:10:43.000]   If you don't know these terms, I'm just throwing these out there to seed in your
[00:10:43.000 --> 00:10:47.960]   heads, different topics that will keep coming back to, I like the form of, uh,
[00:10:47.960 --> 00:10:50.960]   spaced repetition and coming back to different topics.
[00:10:50.960 --> 00:10:53.800]   And I also like throwing jargon around, waving my hands.
[00:10:53.800 --> 00:10:56.160]   So that is why I'm doing that right now.
[00:10:56.160 --> 00:10:58.840]   And this is still loading.
[00:10:58.840 --> 00:11:05.480]   So I'll resort to Google images where I saw image that could make my job easy.
[00:11:05.480 --> 00:11:07.320]   There we go.
[00:11:07.760 --> 00:11:13.120]   So inside of a neural network, uh, this point was made in one of the chapters,
[00:11:13.120 --> 00:11:21.240]   but every little transforms the previous input a bit and inside of a deep learning
[00:11:21.240 --> 00:11:23.120]   model, you have a lot of layers.
[00:11:23.120 --> 00:11:29.560]   So this model is a CNN, which as I mentioned, works with images.
[00:11:29.560 --> 00:11:33.280]   And here we're trying to, let's say work with the image data set, which is one of
[00:11:33.280 --> 00:11:36.600]   the most recognized data sets in computer vision.
[00:11:37.000 --> 00:11:41.400]   Our end goal is to be able to tell what is inside of the image and classify it
[00:11:41.400 --> 00:11:43.960]   with one of the classes that is there.
[00:11:43.960 --> 00:11:45.240]   What is a class?
[00:11:45.240 --> 00:11:48.680]   Uh, it's inside of a data set.
[00:11:48.680 --> 00:11:50.960]   Uh, there are different options that exist.
[00:11:50.960 --> 00:11:52.720]   It could be a dog, cat, car.
[00:11:52.720 --> 00:11:56.960]   There are all of these labels that are classes and our end goal is to
[00:11:56.960 --> 00:11:58.480]   detect what's inside of this image.
[00:11:58.480 --> 00:12:05.160]   So the earlier layers learn edges of the objects.
[00:12:06.160 --> 00:12:10.960]   And as you start going into depth, they start learning about the shapes.
[00:12:10.960 --> 00:12:14.720]   I'm sorry, I'm zooming in and it's not being useful here, but
[00:12:14.720 --> 00:12:16.760]   I'll share this link afterwards.
[00:12:16.760 --> 00:12:23.120]   Afterwards, the model starts to learn shapes.
[00:12:23.120 --> 00:12:29.200]   So first it's just edges later in layer three and four, it becomes circles,
[00:12:29.200 --> 00:12:35.120]   rectangles, and furthermore, it gets closer and closer to objects.
[00:12:35.320 --> 00:12:41.840]   So inside of a deep learning model, we're learning all of these representations.
[00:12:41.840 --> 00:12:45.520]   Not we are models learning all of these representations.
[00:12:45.520 --> 00:12:54.760]   So when we mentioned deep learning, it's this process of learning these details.
[00:12:54.760 --> 00:13:00.160]   There are also different formats or different models that you'll come across.
[00:13:00.200 --> 00:13:05.120]   Machine learning also consists of decision trees, gradient boosted trees.
[00:13:05.120 --> 00:13:07.640]   If you'd like to check those out, uh, I would highly
[00:13:07.640 --> 00:13:09.480]   encourage you to go to kaggle.com.
[00:13:09.480 --> 00:13:20.960]   Go to the code section and you can look up XGBoost and I'm sure you'll find a lot
[00:13:20.960 --> 00:13:25.160]   of good examples that you can start playing around with, or you can look up
[00:13:25.240 --> 00:13:29.080]   L light GBM and you'll find good examples.
[00:13:29.080 --> 00:13:34.120]   One thing that Kaggle does really well is these are sorted or these
[00:13:34.120 --> 00:13:37.160]   return with a number of upwards.
[00:13:37.160 --> 00:13:41.400]   Usually a number of upwards also reflects how good is a tutorial.
[00:13:41.400 --> 00:13:43.800]   So please head over here.
[00:13:43.800 --> 00:13:46.880]   If you want to check any of these out, start playing around with it.
[00:13:46.880 --> 00:13:52.560]   And, uh, that's how you can get a taste of light GBM XGBoost.
[00:13:53.360 --> 00:13:57.560]   These are the quote unquote traditional learning techniques of machine learning.
[00:13:57.560 --> 00:14:00.080]   Deep learning consists of mostly neural networks.
[00:14:00.080 --> 00:14:05.200]   I'm sorry to anyone who already knew that, but this is for anyone who's
[00:14:05.200 --> 00:14:09.120]   totally new to deep learning, which is also part of the target
[00:14:09.120 --> 00:14:10.800]   audience of this incredible book.
[00:14:10.800 --> 00:14:16.640]   The main thing that sets about sets about deep learning from
[00:14:16.640 --> 00:14:18.720]   traditional machine learning is.
[00:14:18.720 --> 00:14:22.200]   You need to handcraft a lot of features.
[00:14:22.800 --> 00:14:24.480]   So we just looked at this image.
[00:14:24.480 --> 00:14:31.800]   The key thing is we just set one metric, which is the loss.
[00:14:31.800 --> 00:14:32.880]   Sorry.
[00:14:32.880 --> 00:14:37.200]   I'm I'm mixing the jargon here, but inside of the neural network, we tell
[00:14:37.200 --> 00:14:44.400]   the neural network, please minimize your loss and by itself, it's quite a
[00:14:44.400 --> 00:14:50.360]   painful process, but simplified enough by itself with just one loss to optimize.
[00:14:52.080 --> 00:14:54.480]   The neural network starts learning all of these techniques.
[00:14:54.480 --> 00:14:59.040]   That's what makes deep learning so powerful compared to
[00:14:59.040 --> 00:15:00.320]   traditional machine learning.
[00:15:00.320 --> 00:15:03.360]   You had a lot of features that you would be required to handcraft.
[00:15:03.360 --> 00:15:06.680]   You're required to detect edges by yourself.
[00:15:06.680 --> 00:15:11.040]   Uh, anyone who's worked with open CV can tell you, you need to do, uh, edge
[00:15:11.040 --> 00:15:13.360]   extraction, you need to do caution blurring.
[00:15:13.360 --> 00:15:18.160]   You need to, from there, run a PC on top of it to do something similar.
[00:15:18.240 --> 00:15:25.160]   And the reason why that's not as effective anymore is because, uh, it
[00:15:25.160 --> 00:15:27.200]   fails with a huge number of classes.
[00:15:27.200 --> 00:15:34.400]   So if you look at Tesla's autopilot that has possibly hundreds of thousands of
[00:15:34.400 --> 00:15:39.840]   classes, right, that it could understand on the road and that's where
[00:15:39.840 --> 00:15:41.480]   deep learning really shines.
[00:15:41.480 --> 00:15:45.080]   So it's really good with a huge number of examples.
[00:15:47.160 --> 00:15:51.880]   And, uh, I think from here, these, these are the two theoretical points I wanted
[00:15:51.880 --> 00:15:53.400]   to cover from the first three chapter.
[00:15:53.400 --> 00:15:57.160]   I'll switch over to sharing my screen again and going through the colab.
[00:15:57.160 --> 00:16:01.200]   In the meantime, I look at the questions to see if there's any
[00:16:01.200 --> 00:16:03.000]   questions in regards to this.
[00:16:03.120 --> 00:16:03.360]   Awesome.
[00:16:03.360 --> 00:16:09.240]   I'll just quickly connect my writing pad to explain concepts and the shared screen.
[00:16:09.240 --> 00:16:10.240]   I don't see any questions.
[00:16:10.240 --> 00:16:11.840]   So we'll continue in one second.
[00:16:11.840 --> 00:16:12.040]   Okay.
[00:16:12.040 --> 00:16:17.360]   So I'll just quickly connect my writing pad to explain concepts and the shared screen.
[00:16:17.360 --> 00:16:18.360]   I don't see any questions.
[00:16:18.360 --> 00:16:19.840]   So we'll continue in one second.
[00:16:19.840 --> 00:16:19.920]   Okay.
[00:16:19.920 --> 00:16:24.920]   So I'll just quickly connect my writing pad to explain concepts and the shared screen.
[00:16:24.920 --> 00:16:25.920]   I don't see any questions.
[00:16:25.920 --> 00:16:27.440]   So we'll continue in one second.
[00:16:27.440 --> 00:16:27.520]   Okay.
[00:16:27.520 --> 00:16:32.520]   So I'll just quickly connect my writing pad to explain concepts and the shared screen.
[00:16:32.520 --> 00:16:33.520]   I don't see any questions.
[00:16:33.520 --> 00:16:35.000]   So we'll continue in one second.
[00:16:35.000 --> 00:16:35.000]   Okay.
[00:16:35.000 --> 00:16:38.000]   So I'll just quickly connect my writing pad to explain concepts and the shared screen.
[00:16:38.000 --> 00:16:39.000]   I don't see any questions.
[00:16:39.000 --> 00:17:00.700]   I also want to point everyone to an interesting clip that I found, uh,
[00:17:00.700 --> 00:17:06.200]   El E net by Yann LeCun was the first architecture that
[00:17:06.720 --> 00:17:10.560]   revolutionized, uh, convolutional neural networks, again, a type
[00:17:10.560 --> 00:17:12.520]   of deep learning models.
[00:17:12.520 --> 00:17:18.760]   I saw this clip on Twitter, uh, where Yann LeCun was demoing the first, uh,
[00:17:18.760 --> 00:17:21.120]   uh, CNN model.
[00:17:21.120 --> 00:17:39.000]   That does look like him.
[00:17:39.000 --> 00:17:44.040]   Uh, this was one of the revolutionary moments, honestly, in the field of deep
[00:17:44.040 --> 00:17:49.480]   learning and CNN took off about 30 years later or 20 years later.
[00:17:49.840 --> 00:17:53.640]   So, uh, you can go through the details in the book from here.
[00:17:53.640 --> 00:17:57.800]   Uh, but that's all of the history I wanted to cover, uh, before
[00:17:57.800 --> 00:17:59.160]   starting with the examples.
[00:17:59.160 --> 00:18:02.740]   I want to point everyone to the incredible keras.io website.
[00:18:02.740 --> 00:18:04.020]   It's quite simple to remember.
[00:18:04.020 --> 00:18:10.280]   So you all can head over to keras.io where you can find all of the details.
[00:18:10.280 --> 00:18:14.620]   Uh, I would encourage you to going to go through these examples and
[00:18:14.620 --> 00:18:17.040]   also guides to get started.
[00:18:17.140 --> 00:18:24.700]   Uh, and eventually we'll also be looking at different applications through here.
[00:18:24.700 --> 00:18:28.280]   This is quite thorough and detailed, and I would highly encourage everyone
[00:18:28.280 --> 00:18:29.700]   to spend a lot of time on here.
[00:18:29.700 --> 00:18:35.300]   So from there, I want to start by covering chapter two, three, four,
[00:18:35.300 --> 00:18:36.860]   and hopefully five as well today.
[00:18:36.860 --> 00:18:40.180]   I'll run through the code and explain any blocks that are of importance.
[00:18:40.180 --> 00:18:44.680]   So, uh, the first bit in chapter two is creating a model and we look
[00:18:44.680 --> 00:18:46.300]   at what's happening inside of it.
[00:18:47.300 --> 00:18:52.060]   So Keras has this nice datasets functionality.
[00:18:52.060 --> 00:18:54.260]   And from there we'll quickly import MNIST.
[00:18:54.260 --> 00:18:59.280]   What I do I'm doing here is, and can anyone please quickly reply in the
[00:18:59.280 --> 00:19:01.940]   chart, if this is clear to everyone or should I zoom in?
[00:19:01.940 --> 00:19:09.380]   Is the text size good enough for everyone?
[00:19:09.380 --> 00:19:09.900]   I'm sorry.
[00:19:09.900 --> 00:19:12.540]   I'm using a monitor, so I can't be a hundred percent sure.
[00:19:12.540 --> 00:19:27.460]   I didn't get any responses, but I'll check again.
[00:19:27.460 --> 00:19:29.340]   Um, I'll assume it's good.
[00:19:29.340 --> 00:19:35.660]   So, uh, to look at what all datasets are available inside of this, I
[00:19:35.660 --> 00:19:38.900]   quickly did a DIR by importing it.
[00:19:39.500 --> 00:19:42.680]   This is a way to print what's inside of a function.
[00:19:42.680 --> 00:19:47.580]   And remember if you ever want to look at what's happening inside of a
[00:19:47.580 --> 00:19:49.220]   function or what does a function do?
[00:19:49.220 --> 00:19:54.580]   Colab is similar to Jupyter notebooks in some sense, not similar in some ways.
[00:19:54.580 --> 00:19:59.340]   If you put a question mark before a function, it should give you
[00:19:59.340 --> 00:20:00.660]   the doc string of the function.
[00:20:00.660 --> 00:20:04.040]   And if you want to look at the source code, if you're feeling brave that day,
[00:20:04.040 --> 00:20:07.220]   you can put two question marks, which will give you the source
[00:20:07.220 --> 00:20:09.860]   code, uh, of the function.
[00:20:09.860 --> 00:20:11.260]   A lot of people have replied.
[00:20:11.260 --> 00:20:12.220]   The text is looking good.
[00:20:12.220 --> 00:20:12.700]   Thank you.
[00:20:12.700 --> 00:20:14.820]   I'm sorry for the awkward pause.
[00:20:14.820 --> 00:20:17.900]   The live stream takes a bit of delay to show you guys.
[00:20:17.900 --> 00:20:21.060]   So I, uh, that's why I had to pause there, but thank you
[00:20:21.060 --> 00:20:22.900]   all for the confirmation there.
[00:20:22.900 --> 00:20:29.020]   Um, so whenever you're working with code, I mentioned earlier, I used to be the kid
[00:20:29.020 --> 00:20:32.580]   who used to always ask questions inside of a class, why are we doing this?
[00:20:32.580 --> 00:20:36.940]   Why are we doing like, so I would encourage you to try that with code.
[00:20:37.140 --> 00:20:40.140]   So if this is the first time you're playing around with any deep learning
[00:20:40.140 --> 00:20:45.940]   framework, change everything, change every single value, look, look,
[00:20:45.940 --> 00:20:47.900]   what does mnist.loaddata do?
[00:20:47.900 --> 00:20:50.660]   Look at the functional arguments.
[00:20:50.660 --> 00:20:51.580]   How does this work?
[00:20:51.580 --> 00:20:53.140]   Okay.
[00:20:53.140 --> 00:20:57.140]   So this is, this takes me to the mnist homepage.
[00:20:57.140 --> 00:21:00.860]   It's a part of Keras dataset and it has a bunch of assert statements.
[00:21:02.260 --> 00:21:07.340]   If you are also, if you also feel that assert is a daunting statement,
[00:21:07.340 --> 00:21:12.780]   start by looking that up instead of focusing your time, which has been one
[00:21:12.780 --> 00:21:17.300]   of my mistakes of my career of looking at papers, looking at theory,
[00:21:17.300 --> 00:21:19.100]   spend more time playing with code.
[00:21:19.100 --> 00:21:23.780]   I will, uh, and any one of you who's joined my previous sessions with
[00:21:23.780 --> 00:21:26.140]   PyTorch or otherwise would remember.
[00:21:26.140 --> 00:21:30.540]   I always keep coming back to this point because I personally, and I've seen
[00:21:30.540 --> 00:21:35.700]   this many times with people have failed repeatedly to code more and
[00:21:35.700 --> 00:21:37.300]   end up always looking at theory.
[00:21:37.300 --> 00:21:39.740]   So please don't be like me in that way.
[00:21:39.740 --> 00:21:43.260]   So here I print out all of the datasets.
[00:21:43.260 --> 00:21:47.420]   If you're new to machine, machine learning, CIFAR 10 and 100 are also
[00:21:47.420 --> 00:21:49.820]   one of the most widely used datasets.
[00:21:49.820 --> 00:21:55.860]   Boston housing was from a Kaggle competition that displayed, uh, the
[00:21:55.860 --> 00:21:59.340]   houses inside of Boston area and their prices.
[00:21:59.380 --> 00:22:01.940]   This used to be a competition on Kaggle.
[00:22:01.940 --> 00:22:05.060]   Now it's just a hello world of deep learning.
[00:22:05.060 --> 00:22:07.700]   Let's look that up and see if we can find that.
[00:22:07.700 --> 00:22:16.100]   Not comments.
[00:22:16.100 --> 00:22:17.340]   I want to find the
[00:22:17.340 --> 00:22:28.700]   I'm trying to find the competition.
[00:22:29.380 --> 00:22:32.060]   Um, let's see.
[00:22:32.060 --> 00:22:42.420]   I see a lot of house prediction competition that might have put, uh,
[00:22:42.420 --> 00:22:46.980]   the status it, but Kaggle had hosted this competition a long time ago.
[00:22:46.980 --> 00:22:49.100]   And the status it's come from comes from there.
[00:22:49.100 --> 00:22:56.100]   Fashion MNIST, uh, is similar to the classic MNIST dataset that we have just
[00:22:56.100 --> 00:22:59.740]   imported, but it has a fashionable objects.
[00:22:59.740 --> 00:23:02.660]   IMDB consists of movie reviews.
[00:23:02.660 --> 00:23:05.420]   And that's an example of collaborative filtering where we
[00:23:05.420 --> 00:23:07.020]   create a recommender system.
[00:23:07.020 --> 00:23:10.940]   And you can also look up routers dataset.
[00:23:10.940 --> 00:23:14.700]   Uh, if you try to print any dataset detail inside of the API,
[00:23:14.700 --> 00:23:16.020]   it should give you the details.
[00:23:16.020 --> 00:23:21.500]   I see a few comments around.
[00:23:21.500 --> 00:23:23.900]   They can't see the live stream.
[00:23:25.100 --> 00:23:28.380]   I'm assuming it's visible to everyone, but the only requirement
[00:23:28.380 --> 00:23:30.500]   we have is to use Chrome.
[00:23:30.500 --> 00:23:31.580]   I'm sorry.
[00:23:31.580 --> 00:23:32.660]   This is a side note.
[00:23:32.660 --> 00:23:37.820]   We using this platform for our events because we've had issues with zoom and
[00:23:37.820 --> 00:23:40.660]   sometimes, uh, you all wouldn't get a notification.
[00:23:40.660 --> 00:23:45.860]   So I know it's quite different to use, but, uh, sorry about the troubles here.
[00:23:52.740 --> 00:23:57.420]   So the thing you should always do after importing any dataset and what's going
[00:23:57.420 --> 00:24:03.260]   on here is we've called MNIST dot load function, load data function.
[00:24:03.260 --> 00:24:06.060]   And this has done something magical.
[00:24:06.060 --> 00:24:11.980]   It's returned train images and train labels and test images and test labels.
[00:24:11.980 --> 00:24:17.100]   So MNIST is a dataset that consists of handwritten characters from zero to nine.
[00:24:19.180 --> 00:24:24.380]   And we need to be able to find a way to load these into a computer and hand
[00:24:24.380 --> 00:24:30.060]   that off to Keras to be able to do black magic or machine learning.
[00:24:30.060 --> 00:24:34.780]   So, uh, one good thing to do is always look at the shape
[00:24:34.780 --> 00:24:37.260]   of tensors after importing them.
[00:24:37.260 --> 00:24:40.580]   So this becomes a tensor and we'll quickly look at what is a tensor.
[00:24:40.580 --> 00:24:44.420]   After this example, it is kind of a chicken and egg problem.
[00:24:44.420 --> 00:24:47.220]   If you're new to this concepts, you need to understand what it's
[00:24:47.220 --> 00:24:48.820]   doing to understand its definition.
[00:24:48.820 --> 00:24:52.900]   So we'll come back to the definition in one minute, but it looks like this
[00:24:52.900 --> 00:24:55.980]   has a size of 60,000 by 28 by 28.
[00:24:55.980 --> 00:25:02.220]   So what's going on here is, uh, all of us hopefully have HD screens right now.
[00:25:02.220 --> 00:25:06.380]   They are one nine two zero by one zero eight zero in size.
[00:25:06.380 --> 00:25:09.580]   These images are quite old from the nineties.
[00:25:09.580 --> 00:25:12.220]   So they have just the size of 28 by 28.
[00:25:12.220 --> 00:25:17.740]   So the training images are of this size and there's about 60,000 of them.
[00:25:17.780 --> 00:25:21.980]   If we print the length of the labels, it should match with
[00:25:21.980 --> 00:25:23.420]   the images and yes, it does.
[00:25:23.420 --> 00:25:26.260]   So it's always good to run such tests inside of your code.
[00:25:26.260 --> 00:25:29.820]   And we can take a look at the labels as well.
[00:25:29.820 --> 00:25:33.540]   So the first image is five.
[00:25:33.540 --> 00:25:38.300]   The second images is second image is zero.
[00:25:38.300 --> 00:25:40.940]   Third image is number four.
[00:25:40.940 --> 00:25:43.620]   Looks like these are from zero to nine.
[00:25:44.140 --> 00:25:47.620]   If you like, you can also investigate further, try to
[00:25:47.620 --> 00:25:48.900]   print out different values.
[00:25:48.900 --> 00:25:53.260]   Looks, look at what's going on inside of there, two different things, but I won't
[00:25:53.260 --> 00:26:00.780]   do that, but again, some suggested work for you at this point, the old Siam would
[00:26:00.780 --> 00:26:02.900]   look up and start reading the paper.
[00:26:02.900 --> 00:26:07.500]   Instead of doing that, print these things, see what's happening inside of the dataset.
[00:26:07.500 --> 00:26:13.220]   Remember as your job of a machine learning engineer, you need to spend
[00:26:13.220 --> 00:26:18.420]   time coding in Python and producing things that are of interest to stakeholders
[00:26:18.420 --> 00:26:24.940]   and not always processing academic work, which is important, but not in the
[00:26:24.940 --> 00:26:28.420]   first few milestones of your career.
[00:26:28.420 --> 00:26:29.140]   I'm sorry.
[00:26:29.140 --> 00:26:32.620]   I'll always prefix this warning to everyone, at least for the first two, three
[00:26:32.620 --> 00:26:33.260]   live streams.
[00:26:33.260 --> 00:26:37.500]   So sorry if it gets annoying to everyone, but I really want you all to avoid this.
[00:26:37.500 --> 00:26:41.860]   The next thing we do is we need to create a model.
[00:26:42.260 --> 00:26:47.020]   So we import Keras from TensorFlow and from there we import layers as well.
[00:26:47.020 --> 00:26:52.940]   Let's see what all layers exist inside of Keras.
[00:26:52.940 --> 00:26:56.540]   So if I do dir layers, would that give me all of the layers?
[00:26:56.540 --> 00:26:57.340]   Should?
[00:26:57.340 --> 00:26:58.420]   Yes, it does.
[00:26:58.420 --> 00:27:02.220]   Now, these are the things you should be trying.
[00:27:02.220 --> 00:27:06.460]   Here we're creating a simple neural network on the simple dataset, which
[00:27:06.460 --> 00:27:07.420]   will perform really well.
[00:27:07.420 --> 00:27:08.420]   I'm giving you a spoiler.
[00:27:08.420 --> 00:27:09.100]   Sorry.
[00:27:10.500 --> 00:27:12.220]   But it will perform really well here.
[00:27:12.220 --> 00:27:18.380]   Try changing the layers.
[00:27:18.380 --> 00:27:22.580]   What is, uh, I'm curious.
[00:27:22.580 --> 00:27:26.140]   What is global max pooling 1D?
[00:27:26.140 --> 00:27:29.180]   Let's head over to Keras.io.
[00:27:29.180 --> 00:27:35.260]   And, uh, I'm on the search documentation part.
[00:27:35.260 --> 00:27:37.900]   I'll search global max pooling 1D.
[00:27:37.900 --> 00:27:38.900]   Let's see what it says.
[00:27:38.900 --> 00:27:40.460]   Global max pooling 1D.
[00:27:40.460 --> 00:27:41.940]   Let's see what does that give me?
[00:27:41.940 --> 00:27:43.420]   Okay.
[00:27:43.420 --> 00:27:45.260]   That gives me details of the API.
[00:27:45.260 --> 00:27:47.180]   Takes me to this page.
[00:27:47.180 --> 00:27:51.460]   So global max pooling operation for 1D temporal data.
[00:27:51.460 --> 00:27:56.060]   Down samples, the input representation by taking the
[00:27:56.060 --> 00:27:58.060]   maximum value over time dimension.
[00:27:58.060 --> 00:28:02.820]   This doesn't make sense to me right now.
[00:28:02.820 --> 00:28:07.340]   So from here, what I would do is copy this example and run it
[00:28:07.340 --> 00:28:08.820]   and see if it makes sense.
[00:28:09.820 --> 00:28:09.900]   Okay.
[00:28:09.900 --> 00:28:13.580]   After doing that and after playing around with a bit, you
[00:28:13.580 --> 00:28:17.500]   start forming these mental maps, spend more time inside of the
[00:28:17.500 --> 00:28:19.820]   documentation, try changing values.
[00:28:19.820 --> 00:28:24.420]   Let's also take another example that would be relevant and
[00:28:24.420 --> 00:28:26.780]   would make me look like an idiot.
[00:28:26.780 --> 00:28:28.540]   So let me see if I can pick that one.
[00:28:28.540 --> 00:28:35.820]   Um, let's see, let's look at dense.
[00:28:35.820 --> 00:28:38.700]   Let me try searching dense.
[00:28:38.700 --> 00:28:47.500]   I see the dense layer of top.
[00:28:47.500 --> 00:28:52.700]   Just your regular densely connected neural network.
[00:28:52.700 --> 00:28:53.820]   This makes sense to me.
[00:28:53.820 --> 00:28:55.420]   I'll wave my hands to confirm.
[00:28:55.420 --> 00:28:56.940]   I wave my hand strongly.
[00:28:56.940 --> 00:28:58.340]   So I know this.
[00:28:58.340 --> 00:29:02.820]   Then simply means that the operation output is equal to activation.
[00:29:02.820 --> 00:29:08.140]   So we're passing a dot product of the input with the kernel, adding
[00:29:08.140 --> 00:29:12.060]   a bias to it and passing it through an activation function.
[00:29:12.060 --> 00:29:14.940]   That is what a dense layer does.
[00:29:14.940 --> 00:29:19.580]   From there, I'd like to run the example and see what does that do?
[00:29:19.580 --> 00:29:24.060]   So that is another suggestion for you all to try, but I
[00:29:24.060 --> 00:29:25.220]   really like this approach.
[00:29:25.220 --> 00:29:34.460]   So what do we do here?
[00:29:34.460 --> 00:29:36.340]   We create a sequential model.
[00:29:36.500 --> 00:29:39.660]   So these layers, uh, any input that goes through passes
[00:29:39.660 --> 00:29:40.820]   through these sequentially.
[00:29:40.820 --> 00:29:46.460]   We create a dense layer of five and two neurons, and we create
[00:29:46.460 --> 00:29:48.340]   an activation function value.
[00:29:48.340 --> 00:29:50.260]   We call activation function value here.
[00:29:50.260 --> 00:29:53.980]   I had a interesting slide on this.
[00:29:53.980 --> 00:29:56.300]   Let me see if I can bring that up.
[00:29:56.300 --> 00:30:05.100]   This is one easy way.
[00:30:05.100 --> 00:30:06.900]   I had this printed a long time ago.
[00:30:06.900 --> 00:30:11.740]   After time I was able to memorize all of these, but this is from
[00:30:11.740 --> 00:30:15.820]   civics.com and, uh, these are all of the activation functions.
[00:30:15.820 --> 00:30:22.420]   If I remember Sebastian Truder had a nice blog around activation function.
[00:30:22.420 --> 00:30:28.460]   Sorry, it was around optimization algorithms, uh, which we'll also look at.
[00:30:28.460 --> 00:30:32.260]   Uh, but if you want to remember activation functions, this is a nice
[00:30:32.260 --> 00:30:37.700]   picture to probably download or take a print out of, uh, that's how I remember
[00:30:37.700 --> 00:30:40.900]   these, this is the graph that's being shown.
[00:30:40.900 --> 00:30:45.620]   So value is defined like, so if anything is negative, set it to zero.
[00:30:45.620 --> 00:30:50.340]   If anything is more than that, it remains like, so, uh, so on and so forth.
[00:30:50.340 --> 00:30:56.500]   I would encourage you to look at this picture for remembering the details.
[00:31:01.780 --> 00:31:02.180]   I'm sorry.
[00:31:02.180 --> 00:31:06.820]   It always takes me too long and I feel nervous while switching sharing screens.
[00:31:06.820 --> 00:31:09.620]   I'm also embarrassed of sharing inappropriate things.
[00:31:09.620 --> 00:31:16.460]   Uh, so we set a sequential model and the first activation function is ReLU.
[00:31:16.460 --> 00:31:18.580]   The second one is Softmax.
[00:31:18.580 --> 00:31:22.780]   Inside of the book, Franchois talks about why do we need activation
[00:31:22.780 --> 00:31:24.660]   functions and why are these required?
[00:31:24.660 --> 00:31:27.620]   It's proven in the chapter.
[00:31:27.620 --> 00:31:29.180]   I'll leave you to trying it.
[00:31:30.020 --> 00:31:33.820]   But if you don't add any activation function, no matter how many dense
[00:31:33.820 --> 00:31:39.740]   layers you sit with some mathematical magic, they can be changed to one single
[00:31:39.740 --> 00:31:40.380]   dense layer.
[00:31:40.380 --> 00:31:43.260]   So that's why we require activation function.
[00:31:43.260 --> 00:31:46.540]   And in the end, we're trying to predict from 10 classes.
[00:31:46.540 --> 00:31:48.420]   So we set it to 10.
[00:31:48.420 --> 00:31:55.740]   I shared the, I pointed you all to the blog post by Sebastian on optimization
[00:31:55.740 --> 00:31:59.140]   algorithms and RMS prop is one of them.
[00:31:59.540 --> 00:32:03.700]   So to train our model, first of all, we need to tell it what loss it needs to
[00:32:03.700 --> 00:32:11.540]   minimize and the thing we care about our imaginary job has asked us to create a
[00:32:11.540 --> 00:32:18.340]   model that is of the highest accuracy and to earn a fictional amount of $20,000.
[00:32:18.340 --> 00:32:23.180]   We need an high accuracy on this high is defined as more than 90%.
[00:32:23.180 --> 00:32:25.820]   So we tell our model.
[00:32:25.820 --> 00:32:27.940]   We care about the accuracy.
[00:32:28.300 --> 00:32:35.980]   We set the losses, categorical cross entropy, and we said the optimizer as RMS
[00:32:35.980 --> 00:32:37.740]   prop, and we compile the model.
[00:32:37.740 --> 00:32:39.580]   What does compile do?
[00:32:39.580 --> 00:32:40.900]   Let's take a look.
[00:32:40.900 --> 00:32:45.180]   So I again go over to the Keras documentation.
[00:32:45.180 --> 00:32:47.420]   This looks like the link to it.
[00:32:47.420 --> 00:32:51.340]   So it says it configures the model for training.
[00:32:51.340 --> 00:32:52.060]   That makes sense.
[00:32:52.060 --> 00:32:53.940]   We're configuring our model for training.
[00:32:53.940 --> 00:32:57.460]   We are passing it the optimizer, passing it to the optimizer.
[00:32:57.460 --> 00:33:00.420]   We can also pass matrix.
[00:33:00.420 --> 00:33:05.500]   We can also do other things that we'll come back and take a look at.
[00:33:05.500 --> 00:33:09.340]   So right now we pass an optimizer.
[00:33:09.340 --> 00:33:12.620]   We pass a loss function and you can read these details to understand what
[00:33:12.620 --> 00:33:14.100]   they are or what the options are.
[00:33:23.740 --> 00:33:32.020]   Now, one thing we need to do here is our original train underscore images.
[00:33:32.020 --> 00:33:32.780]   Yes.
[00:33:32.780 --> 00:33:41.300]   It's data type was integer to be able to do deep learning.
[00:33:41.300 --> 00:33:48.180]   We need to perform some matrix magic and also some calculus magic.
[00:33:48.180 --> 00:33:49.940]   We need to take derivatives.
[00:33:49.940 --> 00:33:51.820]   We'll take a look at that in just a moment.
[00:33:52.780 --> 00:33:57.100]   And we need to able to differentiate these, these values usually
[00:33:57.100 --> 00:33:59.340]   become or come under decimal.
[00:33:59.340 --> 00:34:02.860]   So for that reason, we want this to be of a floating data type.
[00:34:02.860 --> 00:34:06.740]   And also we need to normalize this.
[00:34:06.740 --> 00:34:12.300]   So we need to present this in a format that our computer can really work with.
[00:34:12.300 --> 00:34:19.980]   For that reason, we perform these changes and now we're good to fit our model.
[00:34:20.620 --> 00:34:29.820]   So what we do here is let's take a look first, but this fit to another,
[00:34:29.820 --> 00:34:36.900]   instead of doing this, you could also press A which are the cell here.
[00:34:36.900 --> 00:34:38.500]   Put a question mark.
[00:34:38.500 --> 00:34:40.500]   No, sorry.
[00:34:40.500 --> 00:34:44.580]   This wouldn't work because it's tied to this function, but let me give it a try.
[00:34:44.580 --> 00:34:49.260]   This would give up the arguments.
[00:34:49.260 --> 00:34:53.940]   Yes, it does.
[00:34:53.940 --> 00:34:56.580]   So we'll, we can look at the signature here.
[00:34:56.580 --> 00:35:02.540]   Um, trains the model for a fixed number of epochs, iterations on a dataset.
[00:35:02.540 --> 00:35:06.660]   And it tells us what all can it accept as an input, this function.
[00:35:06.660 --> 00:35:13.420]   So I leave you to checking that out, but we pass our images, labels, request a model.
[00:35:13.420 --> 00:35:15.340]   Please take a look at this for five times.
[00:35:15.340 --> 00:35:18.340]   We'd like a batch size of 128, please.
[00:35:19.340 --> 00:35:20.140]   And we run this.
[00:35:20.140 --> 00:35:45.340]   Looks like we just got that good promotion at our fictional job because
[00:35:45.340 --> 00:35:51.140]   we got a 98% accuracy on the training dataset or did we?
[00:35:51.140 --> 00:36:00.140]   So this accuracy is on the dataset on which we have trained to
[00:36:00.140 --> 00:36:02.020]   judge how good of a model this is.
[00:36:02.020 --> 00:36:08.860]   We need to look at the test dataset where we'll surprise test our accuracy.
[00:36:09.620 --> 00:36:17.780]   So for that, we evaluate our model and, uh, take a look at what to start to
[00:36:17.780 --> 00:36:21.620]   question mark model.evaluate.
[00:36:21.620 --> 00:36:29.940]   Returns a loss in value for the model in test mode.
[00:36:29.940 --> 00:36:33.820]   So now we've trained the model and we've put it in a test mode.
[00:36:33.820 --> 00:36:39.180]   Unsurprisingly, we evaluated on the test images and test labels.
[00:36:40.180 --> 00:36:44.500]   It's slightly lesser accurate and we can say it's being over fit a bit.
[00:36:44.500 --> 00:36:46.500]   You can read in the book.
[00:36:46.500 --> 00:36:48.260]   This is described in quite detail.
[00:36:48.260 --> 00:36:50.220]   What is overfitting versus underfitting.
[00:36:50.220 --> 00:36:55.940]   Overfitting happens when your model just remembers the example it's been shown and
[00:36:55.940 --> 00:37:01.140]   doesn't work in the real world or examples outside of the ones it's
[00:37:01.140 --> 00:37:02.940]   seen in the training dataset.
[00:37:02.940 --> 00:37:05.460]   So that is one thing that you should always watch out for.
[00:37:07.780 --> 00:37:13.020]   But this was a 101 introduction to creating deep learning models.
[00:37:13.020 --> 00:37:19.420]   From here, the book goes into details of representation for neural networks.
[00:37:19.420 --> 00:37:22.900]   So I'll start taking a look at that and let me see if there are any questions.
[00:37:23.900 --> 00:37:24.180]   Awesome.
[00:37:24.180 --> 00:37:24.940]   I've run out of time.
[00:37:24.940 --> 00:37:27.460]   So now I've resorted to water for staying hydrated.
[00:37:27.460 --> 00:37:29.620]   I'll just go ahead and run through the slides.
[00:37:29.620 --> 00:37:30.620]   I'll just go through the slides.
[00:37:30.620 --> 00:37:31.580]   I'll just go through the slides.
[00:37:31.580 --> 00:37:32.380]   I'll just go through the slides.
[00:37:32.380 --> 00:37:33.340]   I'll just go through the slides.
[00:37:33.340 --> 00:37:34.140]   I'll just go through the slides.
[00:37:34.140 --> 00:37:34.940]   I'll just go through the slides.
[00:37:34.940 --> 00:37:35.940]   I'll just go through the slides.
[00:37:35.940 --> 00:37:36.780]   I'll just go through the slides.
[00:37:36.780 --> 00:37:37.580]   I'll just go through the slides.
[00:37:37.580 --> 00:37:38.380]   I'll just go through the slides.
[00:37:38.380 --> 00:37:39.140]   I'll just go through the slides.
[00:37:39.140 --> 00:37:39.940]   I'll just go through the slides.
[00:37:39.940 --> 00:37:40.740]   I'll just go through the slides.
[00:37:40.740 --> 00:37:41.540]   I'll just go through the slides.
[00:37:41.540 --> 00:37:42.340]   I'll just go through the slides.
[00:37:42.340 --> 00:37:43.140]   I'll just go through the slides.
[00:37:43.140 --> 00:37:43.940]   I'll just go through the slides.
[00:37:43.940 --> 00:37:44.820]   I'll just go through the slides.
[00:37:44.820 --> 00:37:45.820]   I'll just go through the slides.
[00:37:45.820 --> 00:37:46.820]   I'll just go through the slides.
[00:37:46.820 --> 00:37:47.820]   I'll just go through the slides.
[00:37:47.820 --> 00:37:48.820]   I'll just go through the slides.
[00:37:48.820 --> 00:37:49.820]   I'll just go through the slides.
[00:37:49.820 --> 00:37:50.820]   I'll just go through the slides.
[00:37:50.820 --> 00:37:51.820]   I'll just go through the slides.
[00:37:51.820 --> 00:37:52.820]   I'll just go through the slides.
[00:37:52.820 --> 00:37:53.820]   I'll just go through the slides.
[00:37:53.820 --> 00:37:54.820]   I'll just go through the slides.
[00:37:54.820 --> 00:37:55.820]   I'll just go through the slides.
[00:37:55.820 --> 00:37:56.820]   I'll just go through the slides.
[00:37:56.820 --> 00:37:57.820]   I'll just go through the slides.
[00:37:57.820 --> 00:37:58.820]   I'll just go through the slides.
[00:37:58.820 --> 00:37:59.820]   I'll just go through the slides.
[00:37:59.820 --> 00:38:00.820]   I'll just go through the slides.
[00:38:00.820 --> 00:38:01.820]   I'll just go through the slides.
[00:38:01.820 --> 00:38:02.820]   I'll just go through the slides.
[00:38:02.820 --> 00:38:03.820]   I'll just go through the slides.
[00:38:03.820 --> 00:38:04.820]   I'll just go through the slides.
[00:38:04.820 --> 00:38:05.820]   I'll just go through the slides.
[00:38:05.820 --> 00:38:06.820]   I'll just go through the slides.
[00:38:07.820 --> 00:38:08.820]   I'll just go through the slides.
[00:38:08.820 --> 00:38:09.820]   I'll just go through the slides.
[00:38:09.820 --> 00:38:10.820]   I'll just go through the slides.
[00:38:10.820 --> 00:38:11.820]   I'll just go through the slides.
[00:38:11.820 --> 00:38:12.820]   I'll just go through the slides.
[00:38:12.820 --> 00:38:13.820]   I'll just go through the slides.
[00:38:13.820 --> 00:38:14.820]   I'll just go through the slides.
[00:38:14.820 --> 00:38:15.820]   I'll just go through the slides.
[00:38:15.820 --> 00:38:16.820]   I'll just go through the slides.
[00:38:16.820 --> 00:38:17.820]   I'll just go through the slides.
[00:38:17.820 --> 00:38:18.820]   I'll just go through the slides.
[00:38:18.820 --> 00:38:19.820]   I'll just go through the slides.
[00:38:19.820 --> 00:38:20.820]   I'll just go through the slides.
[00:38:20.820 --> 00:38:21.820]   I'll just go through the slides.
[00:38:21.820 --> 00:38:22.820]   I'll just go through the slides.
[00:38:22.820 --> 00:38:23.820]   I'll just go through the slides.
[00:38:23.820 --> 00:38:24.820]   I'll just go through the slides.
[00:38:24.820 --> 00:38:25.820]   I'll just go through the slides.
[00:38:25.820 --> 00:38:26.820]   I'll just go through the slides.
[00:38:26.820 --> 00:38:27.820]   I'll just go through the slides.
[00:38:27.820 --> 00:38:28.820]   I'll just go through the slides.
[00:38:28.820 --> 00:38:29.820]   I'll just go through the slides.
[00:38:30.820 --> 00:38:31.820]   So this is a matrix, right?
[00:38:31.820 --> 00:38:32.820]   So this is a matrix, right?
[00:38:32.820 --> 00:38:33.820]   So this is a matrix, right?
[00:38:33.820 --> 00:38:34.820]   So this is a matrix, right?
[00:38:34.820 --> 00:38:35.820]   So this is a matrix, right?
[00:38:35.820 --> 00:38:36.820]   So this is a matrix, right?
[00:38:36.820 --> 00:38:37.820]   So this is a matrix, right?
[00:38:37.820 --> 00:38:38.820]   So this is a matrix, right?
[00:38:38.820 --> 00:38:39.820]   So this is a matrix, right?
[00:38:39.820 --> 00:38:40.820]   So this is a matrix, right?
[00:38:40.820 --> 00:38:41.820]   So this is a matrix, right?
[00:38:41.820 --> 00:38:42.820]   So this is a matrix, right?
[00:38:42.820 --> 00:38:43.820]   So this is a matrix, right?
[00:38:43.820 --> 00:38:44.820]   So this is a matrix, right?
[00:38:44.820 --> 00:38:45.820]   So this is a matrix, right?
[00:38:45.820 --> 00:38:46.820]   So this is a matrix, right?
[00:38:46.820 --> 00:38:47.820]   So this is a matrix, right?
[00:38:47.820 --> 00:38:48.820]   So this is a matrix, right?
[00:38:48.820 --> 00:38:49.820]   So this is a matrix, right?
[00:38:49.820 --> 00:38:50.820]   So this is a matrix, right?
[00:38:50.820 --> 00:38:51.820]   So this is a matrix, right?
[00:38:51.820 --> 00:38:52.820]   So this is a matrix, right?
[00:38:52.820 --> 00:38:53.820]   So this is a matrix, right?
[00:38:53.820 --> 00:38:54.820]   So this is a matrix, right?
[00:38:54.820 --> 00:38:55.820]   So this is a matrix, right?
[00:38:55.820 --> 00:38:56.820]   So this is a matrix, right?
[00:38:56.820 --> 00:38:57.820]   So this is a matrix, right?
[00:38:57.820 --> 00:38:58.820]   So this is a matrix, right?
[00:38:58.820 --> 00:38:59.820]   So this is a matrix, right?
[00:38:59.820 --> 00:39:00.820]   So this is a matrix, right?
[00:39:00.820 --> 00:39:01.820]   So this is a matrix, right?
[00:39:01.820 --> 00:39:02.820]   So this is a matrix, right?
[00:39:02.820 --> 00:39:03.820]   So this is a matrix, right?
[00:39:03.820 --> 00:39:04.820]   So this is a matrix, right?
[00:39:04.820 --> 00:39:05.820]   So this is a matrix, right?
[00:39:05.820 --> 00:39:06.820]   So this is a matrix, right?
[00:39:06.820 --> 00:39:07.820]   So this is a matrix, right?
[00:39:07.820 --> 00:39:08.820]   So this is a matrix, right?
[00:39:08.820 --> 00:39:09.820]   So this is a matrix, right?
[00:39:09.820 --> 00:39:10.820]   So this is a matrix, right?
[00:39:10.820 --> 00:39:11.820]   So this is a matrix, right?
[00:39:11.820 --> 00:39:12.820]   So this is a matrix, right?
[00:39:12.820 --> 00:39:13.820]   So this is a matrix, right?
[00:39:13.820 --> 00:39:14.820]   So this is a matrix, right?
[00:39:14.820 --> 00:39:15.820]   So this is a matrix, right?
[00:39:15.820 --> 00:39:16.820]   So this is a matrix, right?
[00:39:16.820 --> 00:39:17.820]   So this is a matrix, right?
[00:39:17.820 --> 00:39:18.820]   So this is a matrix, right?
[00:39:18.820 --> 00:39:19.820]   So this is a matrix, right?
[00:39:19.820 --> 00:39:20.820]   So this is a matrix, right?
[00:39:20.820 --> 00:39:21.820]   So this is a matrix, right?
[00:39:21.820 --> 00:39:22.820]   So this is a matrix, right?
[00:39:22.820 --> 00:39:23.820]   So this is a matrix, right?
[00:39:23.820 --> 00:39:24.820]   So this is a matrix, right?
[00:39:24.820 --> 00:39:25.820]   So this is a matrix, right?
[00:39:25.820 --> 00:39:26.820]   So this is a matrix, right?
[00:39:26.820 --> 00:39:27.820]   So this is a matrix, right?
[00:39:27.820 --> 00:39:28.820]   So this is a matrix, right?
[00:39:28.820 --> 00:39:29.820]   So this is a matrix, right?
[00:39:29.820 --> 00:39:30.820]   So this is a matrix, right?
[00:39:30.820 --> 00:39:31.820]   So this is a matrix, right?
[00:39:31.820 --> 00:39:32.820]   So this is a matrix, right?
[00:39:32.820 --> 00:39:33.820]   So this is a matrix, right?
[00:39:33.820 --> 00:39:34.820]   So this is a matrix, right?
[00:39:34.820 --> 00:39:35.820]   So this is a matrix, right?
[00:39:35.820 --> 00:39:36.820]   So this is a matrix, right?
[00:39:37.820 --> 00:39:45.020]   But this has a length, a height, and three channels.
[00:39:45.020 --> 00:39:46.020]   Images are RGB.
[00:39:46.020 --> 00:39:51.060]   Those are three defining characteristics.
[00:39:51.060 --> 00:39:56.300]   You can define any color with a combination of RGB values.
[00:39:56.300 --> 00:40:01.260]   If you've ever worked on a website, you can define a hex value that'll take care of things.
[00:40:01.260 --> 00:40:07.540]   But the point being, if you're working with images, they would have a rank of three.
[00:40:07.540 --> 00:40:12.140]   And if you are passing on an image to a neural network, it will have a rank of four.
[00:40:12.140 --> 00:40:13.140]   Why is that?
[00:40:13.140 --> 00:40:19.020]   Let me bring up one node to make a point here.
[00:40:19.020 --> 00:40:27.260]   And I'll write here to make a point.
[00:40:27.260 --> 00:40:37.700]   Sorry, I'm quickly switching my screen and launching one node.
[00:40:37.700 --> 00:40:40.500]   Pick up, draw, find a pen.
[00:40:40.500 --> 00:40:46.140]   So an image would be length by width by channels.
[00:40:46.140 --> 00:40:52.780]   Let's say in an ideal world where the internet is working really well.
[00:40:52.780 --> 00:41:06.020]   This is the size of the matrix or vector or tensor that your computer is processing.
[00:41:06.020 --> 00:41:12.060]   If you want to pass this to your neural network, we would ideally, let's say you're trying
[00:41:12.060 --> 00:41:18.260]   to train on a bunch of images and you want to find out in which one a human exists or
[00:41:18.260 --> 00:41:19.260]   not.
[00:41:19.260 --> 00:41:22.100]   Ideally, you would create a batch of these.
[00:41:22.100 --> 00:41:25.000]   So let's you decide on 128.
[00:41:25.000 --> 00:41:36.220]   So you would pass an array of 128 images of 1920 by 1080 having three channels in it.
[00:41:36.220 --> 00:41:37.580]   So notice what's happening here.
[00:41:37.580 --> 00:41:43.440]   This is the channel.
[00:41:43.440 --> 00:41:45.100]   This is the height.
[00:41:45.100 --> 00:41:48.340]   Sorry, I'm mixing up the terminology.
[00:41:48.340 --> 00:41:54.540]   This is the length and these are the number of examples inside of a batch.
[00:41:54.540 --> 00:41:56.660]   This is known as the channel last notation.
[00:41:56.660 --> 00:42:01.700]   Keras works with both some libraries also like the channel first notation.
[00:42:01.700 --> 00:42:08.500]   So you would have the channel by batch by length by width.
[00:42:08.500 --> 00:42:10.100]   This is how you would do it.
[00:42:10.100 --> 00:42:18.260]   Pardon my handwriting, but this is how you would denote a tensor to Keras.
[00:42:18.260 --> 00:42:26.140]   It's important to look at this because a large part of deep learning is a lot of matrix or
[00:42:26.140 --> 00:42:28.980]   tensor operations.
[00:42:28.980 --> 00:42:33.020]   So that point being made, let me switch back to the notebook.
[00:42:33.020 --> 00:42:36.140]   And as a reminder, I know I'll get this question in the future.
[00:42:36.140 --> 00:42:43.580]   So to say myself, this is from the books GitHub repository.
[00:42:43.580 --> 00:42:53.940]   And if you want to find the link to it, I'll just look up GitHub, learning with Python.
[00:42:53.940 --> 00:42:56.260]   The first link is the one you want.
[00:42:56.260 --> 00:43:00.540]   So fchuli/deeplearningwithpythonnotebooks.
[00:43:00.540 --> 00:43:12.220]   These are the notebooks I've uploaded to my Colab and those are the ones I'm working with.
[00:43:12.220 --> 00:43:21.460]   So now we know all about tensors and let's see if you want to check out any other details.
[00:43:21.460 --> 00:43:27.700]   One thing of importance here is NumPy makes it really easy to work with tensors because
[00:43:27.700 --> 00:43:30.700]   you have these functions that you can perform.
[00:43:30.700 --> 00:43:36.220]   One of those is slicing a tensor where you can grab the examples from 10 to 100 like
[00:43:36.220 --> 00:43:37.540]   so.
[00:43:37.540 --> 00:43:46.100]   So my slice would have 90 examples and these would be from 10 to 90.
[00:43:46.100 --> 00:43:50.060]   This would do the same and a colon would tell you, Hey, I just want all of the stuff in
[00:43:50.060 --> 00:43:51.060]   here.
[00:43:51.060 --> 00:43:52.060]   That's all.
[00:43:52.060 --> 00:43:57.580]   If you don't pass any values before or after, I remember it as a stopper on either end.
[00:43:57.580 --> 00:44:00.100]   So please stop or start with 10.
[00:44:00.100 --> 00:44:02.780]   So these are the boundaries 10 to a hundred.
[00:44:02.780 --> 00:44:05.980]   If there's no number here, that means no boundary.
[00:44:05.980 --> 00:44:06.980]   It's everything.
[00:44:06.980 --> 00:44:10.860]   If you pass a simple colon, it'll return everything.
[00:44:10.860 --> 00:44:13.340]   So this is how we can grab the same.
[00:44:13.340 --> 00:44:14.820]   This is also another technique.
[00:44:14.820 --> 00:44:22.740]   So if the boundaries are the first and last number, you get the same.
[00:44:22.740 --> 00:44:25.100]   Few more interesting ways of slicing.
[00:44:25.100 --> 00:44:27.380]   So you can just mention one boundary as well.
[00:44:27.380 --> 00:44:28.980]   That works too.
[00:44:28.980 --> 00:44:33.540]   You can have a negative number here as well, which means this will start from here and
[00:44:33.540 --> 00:44:35.380]   move back seven numbers.
[00:44:35.380 --> 00:44:41.100]   So the boundaries would be defined like so.
[00:44:41.100 --> 00:44:46.700]   And in the book, it basically, this is a method of grabbing the middle 14 pixels inside of
[00:44:46.700 --> 00:44:47.700]   an image.
[00:44:47.700 --> 00:44:53.140]   That's how it's defined.
[00:44:53.140 --> 00:44:57.060]   We can grab a batch of the training images like so.
[00:44:57.060 --> 00:45:02.420]   So we, our first batch is from zero to 128.
[00:45:02.420 --> 00:45:06.160]   Second batch could be from 128 to 256.
[00:45:06.160 --> 00:45:08.860]   And that's how we can grab all of the batches.
[00:45:08.860 --> 00:45:15.060]   So I just told you how can you represent a tensor for images?
[00:45:15.060 --> 00:45:17.140]   This can be extended to video as well.
[00:45:17.140 --> 00:45:23.980]   Let me go back to my wonderful OneNote to continue elaboration with my poor handwriting.
[00:45:23.980 --> 00:45:29.180]   And I apologize in advance for the pain you all have to go through to read my handwriting.
[00:45:29.180 --> 00:45:40.160]   So a video.
[00:45:40.160 --> 00:45:44.780]   And the question here is how do we represent a video to a neural network?
[00:45:44.780 --> 00:45:46.060]   Let's say what does a video have?
[00:45:46.060 --> 00:45:47.940]   A video is a set of images, right?
[00:45:47.940 --> 00:45:49.980]   So what does the image have?
[00:45:49.980 --> 00:45:52.940]   It's a 1920.
[00:45:52.940 --> 00:45:55.300]   I hope aliens can't read this.
[00:45:55.300 --> 00:45:58.700]   That's why my handwriting is so messed up.
[00:45:58.700 --> 00:46:02.060]   The image you see right now has a width.
[00:46:02.060 --> 00:46:06.940]   This time I'm correct with the notation of 1920.
[00:46:06.940 --> 00:46:11.940]   A length or a height of 1080.
[00:46:11.940 --> 00:46:13.960]   And three channels.
[00:46:13.960 --> 00:46:15.760]   But this is just an image, right?
[00:46:15.760 --> 00:46:17.460]   As you can see, I'm moving around.
[00:46:17.460 --> 00:46:18.980]   So this is a sequence of images.
[00:46:18.980 --> 00:46:19.980]   What is that?
[00:46:19.980 --> 00:46:21.460]   Those are frames.
[00:46:21.460 --> 00:46:23.140]   So it's a collection of images.
[00:46:23.140 --> 00:46:34.140]   Let's say in every second, if you're on a good connection, you're getting 60 frames.
[00:46:34.140 --> 00:46:39.420]   So this is one second of the video.
[00:46:39.420 --> 00:46:52.700]   And let's say you want to train your model on, I don't know, four seconds of the video.
[00:46:52.700 --> 00:47:00.500]   So this is the batch size.
[00:47:00.500 --> 00:47:03.340]   Why do we need a batch?
[00:47:03.340 --> 00:47:08.300]   And as you multiply this, I think this becomes 1, 2, 3.
[00:47:08.300 --> 00:47:13.780]   This goes on to the order of a million numbers.
[00:47:13.780 --> 00:47:23.260]   And a few, or even if a few hundred thousand numbers represented as float 32 would become
[00:47:23.260 --> 00:47:27.340]   in the order of half a GB.
[00:47:27.340 --> 00:47:34.180]   So modern graphic cards go from 10 GB to 24 GB.
[00:47:34.180 --> 00:47:41.340]   Beyond that, if you've seen cards bigger than that, you have a lot of money.
[00:47:41.340 --> 00:47:44.180]   Modern cards have this range.
[00:47:44.180 --> 00:47:51.220]   And if you want to fit an entire video or a set of images, you would probably have to
[00:47:51.220 --> 00:47:54.820]   select a few portions of them to be able to work with them.
[00:47:54.820 --> 00:47:59.580]   Your models aren't trained on the graphic card and their memory is a limiter of what
[00:47:59.580 --> 00:48:01.220]   you can work with.
[00:48:01.220 --> 00:48:07.260]   So to limit what we can work with, we create a batch size that can fill whatever memory
[00:48:07.260 --> 00:48:17.180]   we have, if it could also be 320 GB, where you have four graphic cards of 80 GB.
[00:48:17.180 --> 00:48:19.860]   That sounds about right each.
[00:48:19.860 --> 00:48:22.260]   And you could have a really large batch size.
[00:48:22.260 --> 00:48:27.660]   So going back to the initial point, this is how video is represented in memory.
[00:48:27.660 --> 00:48:30.460]   That's another example.
[00:48:30.460 --> 00:48:34.020]   Switching back to the Colab.
[00:48:34.020 --> 00:48:38.580]   Inside of the chapter, they also go through how can you represent time series data and
[00:48:38.580 --> 00:48:39.580]   vector data.
[00:48:39.580 --> 00:48:46.620]   I'll leave you all to check those out.
[00:48:46.620 --> 00:48:52.740]   Now to emphasize on the point how powerful is NumPy.
[00:48:52.740 --> 00:48:56.420]   If you want to add a number to a matrix, right?
[00:48:56.420 --> 00:49:07.940]   Let's say...
[00:49:07.940 --> 00:49:17.340]   So this is your matrix A.
[00:49:17.340 --> 00:49:19.860]   And this would be a type.
[00:49:19.860 --> 00:49:24.620]   This has no type because it's a Python list right now.
[00:49:24.620 --> 00:49:44.220]   But if we make this as a NumPy array.
[00:49:44.220 --> 00:49:45.220]   It's a NumPy.
[00:49:45.220 --> 00:49:46.220]   I'm forgetting the...
[00:49:46.220 --> 00:49:50.820]   Quite embarrassingly, I'm forgetting how to print the D type.
[00:49:50.820 --> 00:49:55.540]   But I want to make a point if you want to add one number to all of these elements, you
[00:49:55.540 --> 00:49:58.660]   can simply do A + 1.
[00:49:58.660 --> 00:50:02.740]   And it gets added to all of the elements.
[00:50:02.740 --> 00:50:11.260]   If we live in a dark world where we don't have this, we'll get an error because we can't
[00:50:11.260 --> 00:50:12.980]   do this operation.
[00:50:12.980 --> 00:50:15.180]   This is known as broadcasting.
[00:50:15.180 --> 00:50:24.540]   So NumPy has something known as BLAS, which I'll encourage you to look up, but not go
[00:50:24.540 --> 00:50:26.020]   into a lot of details.
[00:50:26.020 --> 00:50:33.580]   With a lot of C magic, C language magic.
[00:50:33.580 --> 00:50:38.380]   All of these operations are taken care of in a very fast manner.
[00:50:38.380 --> 00:50:42.100]   And if you're working with Keras, these can be done on the GPU.
[00:50:42.100 --> 00:50:43.820]   That's what makes it really powerful.
[00:50:43.820 --> 00:50:46.060]   These abstractions.
[00:50:46.060 --> 00:50:50.020]   So the point being proven here is this is known as broadcasting.
[00:50:50.020 --> 00:50:56.060]   And here we compare how tedious, sorry, how annoying our code would be if we don't have
[00:50:56.060 --> 00:50:57.740]   broadcasting.
[00:50:57.740 --> 00:51:03.460]   So later in the chapter, we defined a naive ReLU, which basically does ReLU, but quite
[00:51:03.460 --> 00:51:10.140]   naively and you have to loop over all of the elements and perform a ReLU.
[00:51:10.140 --> 00:51:17.180]   So we loop over the entire range of X and we get the max and then return it.
[00:51:17.180 --> 00:51:26.020]   Unlike the very convenient way of simply calling ReLU on X like so.
[00:51:26.020 --> 00:51:31.060]   We also define a naive add and we take a look later on, on which is faster.
[00:51:31.060 --> 00:51:36.640]   Quite unsurprisingly, the NumPy ones are faster because of something known as BLAS, which
[00:51:36.640 --> 00:51:39.940]   makes everything optimized and works really well.
[00:51:39.940 --> 00:51:48.900]   Outside of your compiler, some matrix magic is happening and this code is being vectorized.
[00:51:48.900 --> 00:51:52.700]   But for the simplicity, you can remember this as broadcasting.
[00:51:52.700 --> 00:51:58.860]   So these operations are broadcasting.
[00:51:58.860 --> 00:52:05.980]   Further, this point is shown by dot products.
[00:52:05.980 --> 00:52:07.700]   We define different functions.
[00:52:07.700 --> 00:52:11.820]   I'm glancing over them because they're quite straightforward.
[00:52:11.820 --> 00:52:15.020]   We also look at how can we reshape tensors.
[00:52:15.020 --> 00:52:20.780]   So let's say if you have an array like so, and if you want to reshape it to an array
[00:52:20.780 --> 00:52:26.220]   of six by one dimension, you can simply pass it to reshape and it'll basically transform
[00:52:26.220 --> 00:52:30.140]   this into the same.
[00:52:30.140 --> 00:52:34.300]   In the book, they also discuss of how can you change the image?
[00:52:34.300 --> 00:52:36.380]   How can you rotate the image?
[00:52:36.380 --> 00:52:38.700]   How can you move the image around?
[00:52:38.700 --> 00:52:40.620]   I'll encourage you to check that out.
[00:52:40.620 --> 00:52:41.620]   That is quite straightforward.
[00:52:41.620 --> 00:52:43.260]   Strong headway argument here again.
[00:52:43.260 --> 00:52:50.300]   Sorry, if you're new to the field of deep learning, feel free to follow up with these
[00:52:50.300 --> 00:52:55.460]   questions, but I'm assuming it's familiar with everyone.
[00:52:55.460 --> 00:53:00.180]   Now we come to the crux of what makes neural networks work.
[00:53:00.180 --> 00:53:08.460]   Let me find my presentation if I can in a short minute.
[00:53:08.460 --> 00:53:21.700]   I did manage to find it and let me pull up the correct slide.
[00:53:21.700 --> 00:53:26.620]   So the power of deep learning is summarized in these five steps, just these five steps
[00:53:26.620 --> 00:53:27.620]   that we need to do.
[00:53:27.620 --> 00:53:34.260]   Once we have the dataset, we can simply visualize it, start with a simple model, split it and
[00:53:34.260 --> 00:53:39.740]   iterate till the first model fits without tampering with the model at all.
[00:53:39.740 --> 00:53:50.360]   The magic of how a model learns lies inside of a lot of calculus magic and matrix multiplication.
[00:53:50.360 --> 00:53:54.820]   So we've looked at matrix multiplication and operations we can perform with that.
[00:53:54.820 --> 00:54:03.700]   Now we need to look at derivatives and how do we operate on the same.
[00:54:03.700 --> 00:54:11.100]   So usually when you're working with numbers, usually you would have a graph in a high dimensional
[00:54:11.100 --> 00:54:12.100]   space.
[00:54:12.100 --> 00:54:13.100]   This is 2D obviously.
[00:54:13.100 --> 00:54:19.860]   To be able to operate on this or to be able to correct your loss.
[00:54:19.860 --> 00:54:27.300]   So remember our model, let me create a new page.
[00:54:27.300 --> 00:54:34.700]   So our model gets some input and gives an output.
[00:54:34.700 --> 00:54:37.940]   Initially these outputs would be garbage because our model would be bad.
[00:54:37.940 --> 00:54:48.960]   To improve our model, we pass back a loss and this is updated using an optimizer.
[00:54:48.960 --> 00:54:58.900]   So when we said Keras, please compile a model and we passed the loss and optimizer, we were
[00:54:58.900 --> 00:55:09.620]   basically defining this image.
[00:55:09.620 --> 00:55:13.460]   After doing this a bunch of times, we get a good model.
[00:55:13.460 --> 00:55:17.680]   But we need to understand how does this happen.
[00:55:17.680 --> 00:55:20.900]   So how do we adjust the loss?
[00:55:20.900 --> 00:55:25.060]   Let's say this is our loss and we want to minimize it.
[00:55:25.060 --> 00:55:29.560]   So we calculate the slope at this point.
[00:55:29.560 --> 00:55:37.180]   And if you paid attention, unlike in calculus 101, you can do so by, let's say this is Y
[00:55:37.180 --> 00:55:41.060]   and X and this is the point X dash.
[00:55:41.060 --> 00:55:49.940]   You can find the slope there by doing dy by dx, taking a derivative at the point X dash.
[00:55:49.940 --> 00:55:51.940]   So what do we do?
[00:55:51.940 --> 00:56:08.960]   We update our model weights with a learning rate from the gradient of the loss.
[00:56:08.960 --> 00:56:12.620]   And we set how aggressively do we want to update it.
[00:56:12.620 --> 00:56:18.920]   So for that, you need to be able to get the loss and get the gradient of it at a certain
[00:56:18.920 --> 00:56:21.160]   point.
[00:56:21.160 --> 00:56:25.240]   Inside of Keras, this is done with gradient tape.
[00:56:25.240 --> 00:56:30.600]   And if you look on the API, you can find details over here.
[00:56:30.600 --> 00:56:33.840]   It records the operations for automatic differentiation.
[00:56:33.840 --> 00:56:37.360]   So we don't have to do the painful process of differentiating manually.
[00:56:37.360 --> 00:56:42.080]   It is automatically taken care of.
[00:56:42.080 --> 00:56:45.680]   And operations are recorded when they are executed.
[00:56:45.680 --> 00:56:50.440]   So further in the chapter, gradient tape is defined.
[00:56:50.440 --> 00:56:56.580]   And we define a simple function Y is equal to 2 multiplied by X plus 3.
[00:56:56.580 --> 00:57:01.960]   If we want to calculate the gradient at this point, we can simply call tape dot gradient
[00:57:01.960 --> 00:57:04.480]   by comma X.
[00:57:04.480 --> 00:57:11.640]   And this would calculate the derivative of Y with respect to X.
[00:57:11.640 --> 00:57:14.920]   You can look furthermore into this example from the book.
[00:57:14.920 --> 00:57:17.620]   That's what I wanted to point out.
[00:57:17.620 --> 00:57:24.200]   And then we go back and take another look at our initial example.
[00:57:24.200 --> 00:57:30.400]   We do something exciting afterwards, which is we re-implement what we did earlier from
[00:57:30.400 --> 00:57:33.120]   scratch in TensorFlow.
[00:57:33.120 --> 00:57:35.740]   And this time we define a naive tense class.
[00:57:35.740 --> 00:57:42.520]   So we don't have the convenience of simply calling from Keras dot layers.
[00:57:42.520 --> 00:57:46.240]   We don't have that convenience anymore.
[00:57:46.240 --> 00:57:50.600]   So we will have to define it manually.
[00:57:50.600 --> 00:57:58.080]   And this time, instead of using all of the goodness, we define the shape of our weights,
[00:57:58.080 --> 00:58:02.160]   their initial value, which comes from tf.random.uniform.
[00:58:02.160 --> 00:58:06.200]   Let's take a look at what that is.
[00:58:06.200 --> 00:58:26.280]   Copy paste not found.
[00:58:26.280 --> 00:58:30.720]   This outputs random values from a uniform distribution.
[00:58:30.720 --> 00:58:35.280]   If you want to look up what is uniform distribution, you can continue down that rabbit hole, but
[00:58:35.280 --> 00:58:38.800]   we initialize our vector randomly.
[00:58:38.800 --> 00:58:46.480]   We set the weights to a variable with the initial value and we set the bias like so.
[00:58:46.480 --> 00:58:48.720]   From there we define a call.
[00:58:48.720 --> 00:58:56.360]   So whenever we call naive dense, it would return a matrix multiplication of the weights
[00:58:56.360 --> 00:59:03.200]   at the bias and pass it through an activation layer.
[00:59:03.200 --> 00:59:10.520]   From there we define a nice sequential class and now we can define our model similarly.
[00:59:10.520 --> 00:59:14.480]   Furthermore, we also define a batch generator.
[00:59:14.480 --> 00:59:19.720]   So we don't have the convenience of calling model.compile anymore and we can continue
[00:59:19.720 --> 00:59:24.160]   like so.
[00:59:24.160 --> 00:59:33.280]   And then we define all of the ways of updating the weights, a single training step.
[00:59:33.280 --> 00:59:40.280]   How do we perform the update using the optimizer and how do we apply the gradients and finally
[00:59:40.280 --> 00:59:42.160]   fit the model.
[00:59:42.160 --> 00:59:47.600]   So creating this from scratch, and I would encourage you to spend more time here, it's
[00:59:47.600 --> 00:59:48.600]   quite self-explanatory.
[00:59:48.600 --> 00:59:51.000]   I'm glancing over it.
[00:59:51.000 --> 00:59:55.520]   Would help you appreciate how simplified Keras makes our lives.
[00:59:55.520 --> 01:00:01.320]   So you don't have to go through all of this process manually and we'd still get to a similar
[01:00:01.320 --> 01:00:05.440]   accuracy after doing the same.
[01:00:05.440 --> 01:00:09.900]   Actually we don't and that is a good homework to evaluate on why don't we get a similar
[01:00:09.900 --> 01:00:15.740]   accuracy when doing the same thing.
[01:00:15.740 --> 01:00:20.520]   But inside of the second chapter, the first chapter is more about the theoretical background
[01:00:20.520 --> 01:00:22.040]   of machine learning and deep learning.
[01:00:22.040 --> 01:00:28.440]   The second chapter gives you the building blocks mathematically and also the details
[01:00:28.440 --> 01:00:33.280]   around deep learning.
[01:00:33.280 --> 01:00:39.160]   The third chapter is an introduction to Keras and TensorFlow and noticing that we're four
[01:00:39.160 --> 01:00:41.240]   minutes away from the deadline.
[01:00:41.240 --> 01:00:43.440]   I don't want to go overboard.
[01:00:43.440 --> 01:00:49.400]   I would again encourage everyone to run these notebooks ahead of time.
[01:00:49.400 --> 01:00:52.360]   We'll continue from here next week.
[01:00:52.360 --> 01:00:57.400]   So the third chapter is an introduction to Keras and TensorFlow.
[01:00:57.400 --> 01:01:04.320]   And next week we'll aim to finish up until chapter seven, where we'll actually start
[01:01:04.320 --> 01:01:08.600]   working in Keras.
[01:01:08.600 --> 01:01:14.880]   So let me stop sharing my screen and announce something exciting.
[01:01:14.880 --> 01:01:20.320]   With the most monotone, if I may, but this is quite interesting and I hope everyone is
[01:01:20.320 --> 01:01:21.960]   as excited about this.
[01:01:21.960 --> 01:01:24.560]   I want to announce 27 days of Keras.
[01:01:24.560 --> 01:01:28.540]   I have always wanted to make my own dent in the universe.
[01:01:28.540 --> 01:01:34.400]   So instead of using 30 days of Keras, I'm doing something really innovative.
[01:01:34.400 --> 01:01:36.320]   27 days of Keras.
[01:01:36.320 --> 01:01:42.440]   Where if you want, I would invite you to spend 15 minutes to 24 hours every single day for
[01:01:42.440 --> 01:01:44.600]   the next 27 days.
[01:01:44.600 --> 01:01:48.720]   I say playing with Keras because it should be like playing to you.
[01:01:48.720 --> 01:01:49.720]   This is not work.
[01:01:49.720 --> 01:01:52.200]   This is what we'll do for enjoyment.
[01:01:52.200 --> 01:01:54.600]   And I invite you to share what you learn.
[01:01:54.600 --> 01:01:59.360]   So I'm sorry to everyone who knows deep learning this session, I'm assuming wouldn't have given
[01:01:59.360 --> 01:02:00.760]   you much knowledge.
[01:02:00.760 --> 01:02:06.520]   But if this was your first introduction to deep learning, I hope this made sense first
[01:02:06.520 --> 01:02:11.280]   of all to you, but I would invite you to share anything that you might have learned here.
[01:02:11.280 --> 01:02:16.480]   We all start from somewhere and we all have a lot of things to learn.
[01:02:16.480 --> 01:02:22.040]   Share it, share it on Twitter, write a blog around it and tweet with the hashtag 27 days
[01:02:22.040 --> 01:02:23.040]   of Keras.
[01:02:23.040 --> 01:02:26.320]   Tag me or tag @batesinbiases.
[01:02:26.320 --> 01:02:31.920]   And every single week to encourage all of you, we'll be sending over swag and a few
[01:02:31.920 --> 01:02:38.640]   more things, GPU credits to the best submissions.
[01:02:38.640 --> 01:02:44.240]   So in an effort to encourage you all to first of all learn Keras and to get comfortable
[01:02:44.240 --> 01:02:48.780]   sharing your work, we'll have more stuff to share starting next week.
[01:02:48.780 --> 01:02:52.000]   I would really invite you to do this.
[01:02:52.000 --> 01:02:55.280]   And here are a few homework suggestions for you.
[01:02:55.280 --> 01:02:58.840]   Please consider checking out different data sets inside of the class, playing around with
[01:02:58.840 --> 01:03:00.040]   them.
[01:03:00.040 --> 01:03:01.040]   Go to Keras.io.
[01:03:01.040 --> 01:03:05.440]   It's an incredible, quite clean website.
[01:03:05.440 --> 01:03:07.240]   Try to understand what gradient tape is.
[01:03:07.240 --> 01:03:09.840]   It took me a little bit longer.
[01:03:09.840 --> 01:03:13.640]   It's quite different from Autograd, which I know quite intuitively by now.
[01:03:13.640 --> 01:03:16.000]   So please try to understand that.
[01:03:16.000 --> 01:03:17.760]   Try all the parameters.
[01:03:17.760 --> 01:03:24.840]   I was doing a DIR where I was listing different options inside of Keras function.
[01:03:24.840 --> 01:03:26.880]   Try printing those, try playing around with those.
[01:03:26.880 --> 01:03:29.320]   And most importantly, write about these.
[01:03:29.320 --> 01:03:31.720]   Tag me, share it.
[01:03:31.720 --> 01:03:34.520]   We would love to share your work with the world.
[01:03:34.520 --> 01:03:40.160]   We don't have any ask from you here at Batesin Biases.
[01:03:40.160 --> 01:03:44.320]   We genuinely want to create a community where we can provide the best learning materials
[01:03:44.320 --> 01:03:46.640]   for everyone.
[01:03:46.640 --> 01:03:51.520]   And hopefully I'm getting a little better at it with all of the lectures, but we sincerely
[01:03:51.520 --> 01:03:56.480]   want you to get better at sharing, learning and sharing your work with the world.
[01:03:56.480 --> 01:04:00.080]   So I highly encourage you to do this.
[01:04:00.080 --> 01:04:02.160]   And I'll take a look at any of the questions.
[01:04:02.160 --> 01:04:07.160]   If not, I'll mention what we'll be learning next week.
[01:04:07.160 --> 01:04:08.760]   We've gone through the first two chapters.
[01:04:08.760 --> 01:04:12.680]   For the next session, we'll aim for chapter three to seven.
[01:04:12.680 --> 01:04:16.080]   And from there, we'll cover two chapters every week.
[01:04:16.080 --> 01:04:21.680]   So this will be a four or five week adventure that I hope everyone will join me on.
[01:04:21.680 --> 01:04:27.360]   Again, as a reminder, please consider doing these homeworks, consider joining 27 days
[01:04:27.360 --> 01:04:28.360]   of Keras.
[01:04:28.360 --> 01:04:30.080]   And thanks again, everyone for joining.
[01:04:30.080 --> 01:04:31.320]   I'll see you next week.
[01:04:31.320 --> 01:04:36.920]   At the same time, also huge thanks to Fransuha for joining us earlier.
[01:04:36.920 --> 01:04:40.880]   Anyone who's watching right now, yes, we are recording this session and the recording will
[01:04:40.880 --> 01:04:46.760]   be made available in four or five days earlier than that if I decide not to sleep.
[01:04:46.760 --> 01:04:47.760]   Thanks for joining.
[01:04:47.760 --> 01:04:51.200]   I'll end the session here and I look forward to learning with you all next week.
[01:04:51.200 --> 01:05:01.020]   [BLANK_AUDIO]
[01:05:01.020 --> 01:05:11.020]   [BLANK_AUDIO]
[01:05:11.020 --> 01:05:13.080]   you

