
[00:00:00.000 --> 00:00:04.840]   it go live. So when I hit go live, I have to like wait for a
[00:00:04.840 --> 00:00:07.800]   minute to make sure it's like sometimes there's like a issue
[00:00:07.800 --> 00:00:09.960]   that happens and it doesn't go live and doing that while like
[00:00:09.960 --> 00:00:14.000]   I'm looking around this screen like a complete idiot. I'm
[00:00:14.000 --> 00:00:17.720]   surprised someday someone will come and buy this guy looking in
[00:00:17.720 --> 00:00:18.560]   all directions.
[00:00:18.560 --> 00:00:21.800]   It's fine. No worries.
[00:00:21.800 --> 00:00:27.720]   Awesome. We are live I can hear myself speak which means we are
[00:00:27.720 --> 00:00:30.040]   live I'll quickly share my screen and get started.
[00:00:30.040 --> 00:00:34.560]   Everybody, thank you for joining us on a Saturday afternoon,
[00:00:34.560 --> 00:00:37.680]   evening or morning depending on where the world you're joining
[00:00:37.680 --> 00:00:41.800]   us from. I'm super excited to be hosting Jill today. We'll be
[00:00:41.800 --> 00:00:45.400]   learning about the team's first position first. So this is not
[00:00:45.400 --> 00:00:48.400]   just cool. This is not somewhere in the upper portion of the
[00:00:48.400 --> 00:00:51.920]   leaderboard. This is the top of the leaderboard. And this is
[00:00:51.920 --> 00:00:55.720]   CTDS 2.0. So I'm super excited to host Jill. Thanks. Thanks for
[00:00:55.720 --> 00:00:56.560]   joining me today.
[00:00:57.120 --> 00:01:00.000]   Thank you so much for having me. So I mean, it's an honor to be
[00:01:00.000 --> 00:01:04.000]   I'm super excited and can't wait to dive into a journey. I'll
[00:01:04.000 --> 00:01:06.720]   quickly give the audience an outline of what we're talking
[00:01:06.720 --> 00:01:09.520]   about and then start by asking you about your journey.
[00:01:09.520 --> 00:01:10.720]   Sure thing.
[00:01:10.720 --> 00:01:16.040]   So a quick reminder to everybody joining us on YouTube has the
[00:01:16.040 --> 00:01:19.200]   link to ask any questions. If I head over to this link, it
[00:01:19.200 --> 00:01:20.720]   should take you to our forums.
[00:01:20.720 --> 00:01:25.800]   And you can ask any question here as a reply and I'll keep an
[00:01:25.800 --> 00:01:35.680]   eye out for any questions. So please keep the questions coming
[00:01:35.680 --> 00:01:39.600]   on here. And we'll keep checking from time to time I'll post this
[00:01:39.600 --> 00:01:42.640]   link in the YouTube chat real quick so that everyone can ask
[00:01:42.640 --> 00:01:43.240]   questions here.
[00:01:54.240 --> 00:01:56.760]   Awesome. I think I just saw a message from one of your
[00:01:56.760 --> 00:01:59.280]   teammates was also there in the chat. So that's awesome to see.
[00:01:59.280 --> 00:01:59.560]   Thanks.
[00:01:59.560 --> 00:02:03.320]   That's great. Whoever's there because I can't see it. Welcome
[00:02:03.320 --> 00:02:04.920]   and thank you for being here to my team.
[00:02:04.920 --> 00:02:09.040]   Awesome. Now that the logistical stuff is out of the way, I'll
[00:02:09.040 --> 00:02:12.080]   another take another boring minute to explain why is this
[00:02:12.080 --> 00:02:16.480]   happening. This is Chai Time Data Science 2.0. And
[00:02:16.480 --> 00:02:20.840]   essentially, it's a version two of what I've been doing for a
[00:02:20.840 --> 00:02:23.560]   long time, but I also learn about the guest journey and also
[00:02:23.560 --> 00:02:26.800]   understand their solution walkthrough. I really believe
[00:02:26.800 --> 00:02:30.560]   and to anyone who spent any time on Kaggle would know that
[00:02:30.560 --> 00:02:33.120]   whenever we go through a solution in depth, you learn so
[00:02:33.120 --> 00:02:37.080]   so so much. And that's why I try to reach out to awesome people
[00:02:37.080 --> 00:02:40.760]   like Jill himself and try to learn from the not this not just
[00:02:40.760 --> 00:02:43.600]   the journey, but also the solution. So that's what that's
[00:02:43.600 --> 00:02:49.040]   what we'll be doing today. A few a very small intro to Jill I
[00:02:49.040 --> 00:02:51.640]   know it's not it's not enough because you can see on his
[00:02:51.640 --> 00:02:54.600]   Kaggle profile here there are four gold medals, three silver
[00:02:54.600 --> 00:02:58.800]   medals and two bronze medals. These are incredibly hard and I
[00:02:58.800 --> 00:03:01.720]   suppose if Jill ever comes back on the show, he should be a
[00:03:01.720 --> 00:03:07.040]   grandmaster by then. Currently he's a he's a Kaggle competition
[00:03:07.040 --> 00:03:10.480]   master and a postdoc researcher at Kent University. You can
[00:03:10.480 --> 00:03:16.000]   find him on Twitter at Jill V D W I E L E. So please make sure
[00:03:16.000 --> 00:03:21.160]   to check his profile there. So I'll stop sharing my screen and
[00:03:21.160 --> 00:03:24.920]   now go back to the classical model. Thanks again for joining
[00:03:24.920 --> 00:03:27.520]   me. I would love to start by asking about how did you
[00:03:27.520 --> 00:03:30.720]   discover the world of machine learning? And how did you get
[00:03:30.720 --> 00:03:32.760]   started on started on Kaggle?
[00:03:32.760 --> 00:03:38.440]   Yeah, so I think they actually quite coincide very well,
[00:03:38.440 --> 00:03:43.000]   because I got introduced to both machine learning and Kaggle
[00:03:43.000 --> 00:03:47.000]   during a course at university. It was in my first master's I
[00:03:47.000 --> 00:03:50.760]   believed. And that was basically the first time I ever got to
[00:03:50.760 --> 00:03:53.640]   experience what machine learning actually is. I did have like
[00:03:53.640 --> 00:03:57.160]   some courses on statistics, but those were not really machine
[00:03:57.160 --> 00:04:02.360]   learning oriented, I would say. And so one of these things
[00:04:02.360 --> 00:04:05.400]   within these courses is a project and that is hosted on
[00:04:05.400 --> 00:04:10.480]   Kaggle. So during my year, we had to like, recognize traffic
[00:04:10.480 --> 00:04:13.560]   signs. So Belgian traffic signs, we have a whole bunch of them on
[00:04:13.560 --> 00:04:16.840]   the Belgium roads, and we were given images. And so we had to
[00:04:17.360 --> 00:04:21.600]   say which of the 60 I believe traffic signs were in that
[00:04:21.600 --> 00:04:24.600]   image. I didn't do that. Well, I remember as well on that first
[00:04:24.600 --> 00:04:29.480]   competition, probably top 60% or something, but I was straight
[00:04:29.480 --> 00:04:34.960]   away the competitive drive that I typically have really aligned
[00:04:34.960 --> 00:04:37.920]   well with how Kaggle works. And it was also just a great
[00:04:37.920 --> 00:04:42.040]   learning experience. So that's how I got introduced to Kaggle.
[00:04:42.040 --> 00:04:45.400]   And this was during your master's?
[00:04:46.200 --> 00:04:49.360]   Yes, so that was during my first master. So now I would have to
[00:04:49.360 --> 00:04:56.440]   calculate how much back in time that is it probably is 2015 2016
[00:04:56.440 --> 00:04:59.840]   somewhere around that. So it's five to six years ago that I
[00:04:59.840 --> 00:05:02.440]   made my first steps on Kaggle, I would say.
[00:05:02.440 --> 00:05:07.520]   So you've followed the traditional path in academia, if
[00:05:07.520 --> 00:05:10.760]   I may, when you signed up for a bachelor's, a master's and a
[00:05:10.760 --> 00:05:14.720]   PhD. People assume this is very disconnected from
[00:05:14.720 --> 00:05:17.760]   competitiveness. How did you find the world of Kaggle as
[00:05:17.760 --> 00:05:21.360]   compared to the academic life? And how did you improve on
[00:05:21.360 --> 00:05:22.480]   Kaggle once you signed up?
[00:05:22.480 --> 00:05:28.720]   That's true. That's actually Yeah, well, maybe there is some
[00:05:28.720 --> 00:05:32.280]   competitiveness in the academic world, I would say as well, like
[00:05:32.280 --> 00:05:35.360]   people, like, for example, in the deep learning community,
[00:05:35.360 --> 00:05:39.280]   people are continuously improving. Yeah, just
[00:05:39.280 --> 00:05:42.080]   fundamental research, and they typically do it on these
[00:05:42.080 --> 00:05:45.840]   benchmark data sets. And this being the most typical one with
[00:05:45.840 --> 00:05:50.280]   its many flaws, though. But people just work on those data
[00:05:50.280 --> 00:05:53.480]   sets. And so their goal is to improve the scores that are
[00:05:53.480 --> 00:05:57.360]   published as of today. So some you can somewhat draw an
[00:05:57.360 --> 00:06:01.600]   analogy with the Kaggle leaderboards there. On the other
[00:06:01.600 --> 00:06:06.120]   hand, there, everyone is setting up their own evaluation, while
[00:06:06.120 --> 00:06:10.560]   Kaggle has a standardized fixed evaluation procedure for all of
[00:06:10.560 --> 00:06:14.800]   the models. So that makes it a bit of a more fair comparison, I
[00:06:14.800 --> 00:06:19.120]   would say. But so I think they align well. So the competitive
[00:06:19.120 --> 00:06:24.000]   aspect of Kaggle can work pretty well with within academics as
[00:06:24.000 --> 00:06:29.120]   well, I would say. Yeah, many of the many of the competitors and
[00:06:29.120 --> 00:06:32.560]   organizers on Kaggle are often academics as well, like the
[00:06:32.560 --> 00:06:35.200]   research category of competitions are mostly
[00:06:35.200 --> 00:06:39.520]   organized by by universities as well. So I don't think it's a
[00:06:39.520 --> 00:06:40.720]   complete mismatch.
[00:06:40.720 --> 00:06:45.240]   That makes sense. And we were just just talking offline about
[00:06:45.240 --> 00:06:50.640]   conferences. And I know, like, even I know, just from talking
[00:06:50.640 --> 00:06:53.920]   to people, I'm under qualified to speak about it, I don't just
[00:06:53.920 --> 00:06:57.400]   to get a disclaimer. But I know, like this, such a competitive
[00:06:57.400 --> 00:07:02.280]  iveness, the CVPR deadline just passed. And it's so much work
[00:07:02.280 --> 00:07:05.160]   that many people maybe, maybe I'm the only one, but many
[00:07:05.160 --> 00:07:08.520]   people don't realize how much competitiveness is also there
[00:07:08.520 --> 00:07:09.720]   in just research.
[00:07:09.720 --> 00:07:15.400]   Yeah, it's mad, like getting a paper on the main track and
[00:07:15.400 --> 00:07:20.000]   NIPS is probably at least as difficult as getting a gold
[00:07:20.000 --> 00:07:24.560]   medal on Kaggle, I would say the acceptance rate is like only I
[00:07:24.560 --> 00:07:27.920]   don't know by heart, but it is a low number, like 10 to 20%,
[00:07:27.920 --> 00:07:30.440]   probably something like that. And just the amount of effort
[00:07:30.440 --> 00:07:34.400]   that you have to put in a paper, just to make like a small chance
[00:07:34.400 --> 00:07:39.160]   on actually being able to present it is indeed somewhat
[00:07:39.160 --> 00:07:43.880]   demotivating. But then again, if you ever are able to publish on
[00:07:43.880 --> 00:07:46.640]   this main track, that is really a prestigious achievement, I
[00:07:46.640 --> 00:07:50.760]   would say. And that's what makes it a bit more nice to chase if
[00:07:50.760 --> 00:07:53.840]   it was too easy, then it probably wouldn't have been as
[00:07:53.840 --> 00:07:58.200]   prestigious as it is today. And there are also like, you don't
[00:07:58.200 --> 00:08:01.080]   per se have to submit to these main tracks that are often like
[00:08:01.080 --> 00:08:04.320]   workshops, which are more tailored towards a very specific
[00:08:04.320 --> 00:08:07.280]   sub domain. And there the acceptance rates are typically a
[00:08:07.280 --> 00:08:10.920]   lot higher. So that's a great starting point. If you're
[00:08:10.920 --> 00:08:14.200]   interested or a starting academic to like, go to
[00:08:14.200 --> 00:08:18.240]   conferences as well, just try to submit to these workshops. And
[00:08:18.240 --> 00:08:21.520]   like that you can secure a spot in the conference as well and
[00:08:21.520 --> 00:08:23.360]   have a good discussion that week.
[00:08:23.360 --> 00:08:29.960]   Acceptance rate sounds like an easier than sounds easier than
[00:08:29.960 --> 00:08:34.840]   getting a gold medal. Just just to say something spicy. Coming
[00:08:34.840 --> 00:08:38.440]   coming back to Kaggle. How did after starting your journey? How
[00:08:38.440 --> 00:08:41.080]   did you improve on your position? You've you've had
[00:08:41.080 --> 00:08:44.400]   great achievements, both solo and both with teams. How did you
[00:08:44.400 --> 00:08:47.080]   approach Kaggle? How did you improve as a conscious effort?
[00:08:47.080 --> 00:08:52.080]   Yeah, that's a good question. Because actually, after that
[00:08:52.080 --> 00:08:56.040]   machine learning project, my activity on Kaggle was quite
[00:08:56.040 --> 00:09:01.920]   low. I think I only participated like in one competition every
[00:09:01.920 --> 00:09:08.240]   16 months, so not even on an annual basis, I would say. And I
[00:09:08.240 --> 00:09:11.360]   think that was probably because I was too competitive. And that
[00:09:11.360 --> 00:09:14.280]   would be a piece of advice that I would always give to people
[00:09:14.280 --> 00:09:17.280]   today is to not focus too much on those ranks on the leader
[00:09:17.280 --> 00:09:20.520]   board, you should go for it for the learning experience in the
[00:09:20.520 --> 00:09:27.520]   first place. And whatever your rank is, is subordinal to it to
[00:09:27.520 --> 00:09:29.880]   just the learning experience that you'll get. And so that is
[00:09:29.880 --> 00:09:33.600]   actually what pushed me kind of away because I wanted to do
[00:09:33.600 --> 00:09:36.200]   really, really well in all of the competitions that I
[00:09:36.200 --> 00:09:44.160]   participated in. And I still do. But so that's why I did put it a
[00:09:44.160 --> 00:09:47.840]   bit on the downside for some years. But then, I think it was
[00:09:47.840 --> 00:09:52.000]   three years ago, I don't know which competition it exactly
[00:09:52.000 --> 00:09:55.640]   was. But that's when I started to compete on a more active
[00:09:55.640 --> 00:09:59.440]   basis. I think it was together with the career competition back
[00:09:59.440 --> 00:10:03.240]   in that day. And I managed to obtain like the sixth place on
[00:10:03.240 --> 00:10:05.560]   the leaderboard there as well. It was just a playground
[00:10:05.560 --> 00:10:09.600]   competition. So there were no real medals. That's very useful.
[00:10:09.600 --> 00:10:13.040]   Thank you. So indeed, I think, like you can see, the traffic
[00:10:13.040 --> 00:10:16.200]   sign recognition was like the machine learning project, but
[00:10:16.200 --> 00:10:19.840]   then the Don't Overfit Too and career competition, I
[00:10:19.840 --> 00:10:24.160]   participated in those two in parallel, three years ago. And I
[00:10:24.160 --> 00:10:26.840]   think from that moment on, you can basically say that I was
[00:10:26.840 --> 00:10:31.280]   involved in one competition at each point in time, I did have
[00:10:31.280 --> 00:10:34.120]   like a few breaks of a few months in between, especially
[00:10:34.120 --> 00:10:37.920]   like in these competitions where I went all in and spent days and
[00:10:37.920 --> 00:10:42.240]   nights coding, then I do kind of need to take a break after that.
[00:10:42.240 --> 00:10:44.960]   So that's where I have some small breaks. But other than
[00:10:44.960 --> 00:10:48.240]   that, I try to always be involved in one competition.
[00:10:48.240 --> 00:10:52.440]   That's also something I focus at just participating in one
[00:10:52.440 --> 00:10:55.560]   because I can't divide my attention to multiple
[00:10:55.560 --> 00:10:58.320]   competitions. That's just not how I work. Some people
[00:10:58.320 --> 00:11:01.480]   definitely work better like that. But I focus on one
[00:11:01.480 --> 00:11:05.240]   competition at a time. And then in terms of which one to pick?
[00:11:05.240 --> 00:11:08.720]   Well, then I think you typically have like to draw an analogy
[00:11:08.720 --> 00:11:12.760]   with reinforcement learning, the explore versus exploit trade
[00:11:12.760 --> 00:11:15.760]   off, right? You can go for the competitions that you know,
[00:11:15.760 --> 00:11:19.000]   that you're familiar with, with the data format, for example. So
[00:11:19.000 --> 00:11:22.240]   for my case, that would be time series competitions. That's
[00:11:22.240 --> 00:11:25.160]   where many of my gold medals come from. But on the other
[00:11:25.160 --> 00:11:27.640]   hand, I'm still on Kaggle to learn. And for example, when it
[00:11:27.640 --> 00:11:31.280]   comes to deep learning, I'm far from an expert in it. And so
[00:11:31.280 --> 00:11:34.920]   that's why I try to once in a while participate in like, just
[00:11:34.920 --> 00:11:38.120]   a real computer vision or natural language processing
[00:11:38.120 --> 00:11:41.800]   competition. But then again, yeah, I do kind of switch
[00:11:41.800 --> 00:11:44.560]   between the exploits and the explore parts.
[00:11:44.560 --> 00:11:51.160]   You've recently graduated from your PhD as well. How do how
[00:11:51.160 --> 00:11:54.400]   does experimentation in a research setting compare against
[00:11:54.400 --> 00:11:58.040]   Kaggle? Do you see similarities? Because people complain there's
[00:11:58.040 --> 00:12:00.880]   not an overlap. I'm sure you would agree there's a nice
[00:12:00.880 --> 00:12:03.920]   overlap. Do you think there's a difference? Do you see any
[00:12:03.920 --> 00:12:04.800]   similarities?
[00:12:06.680 --> 00:12:12.240]   Yeah, so in, in rough terms, they are kind of the same. But
[00:12:12.240 --> 00:12:17.120]   the optimizations you do on Kaggle are much more detailed
[00:12:17.120 --> 00:12:20.440]   than what you would do in research like hyper parameter
[00:12:20.440 --> 00:12:24.240]   tuning, for instance, is something we won't quickly do in
[00:12:24.240 --> 00:12:27.960]   academic research, we're having a new fundamental idea of this
[00:12:27.960 --> 00:12:31.360]   kind of modification to what is already out there. And we just
[00:12:31.360 --> 00:12:35.720]   want to kind of test that in isolation. While on Kaggle, you
[00:12:35.720 --> 00:12:40.800]   will, yeah, you will go for any micro percentage that you can
[00:12:40.800 --> 00:12:45.280]   get from it, right. So you'll be tuning a lot more, a lot more.
[00:12:45.280 --> 00:12:48.160]   So like the hyper parameters, feature selection, all that kind
[00:12:48.160 --> 00:12:51.440]   of stuff. But yeah, then in terms of how to manage these
[00:12:51.440 --> 00:12:54.560]   experiments, it's the same, right. So you have to keep like
[00:12:54.560 --> 00:12:59.320]   a structured overview of what have I done? And what did I not
[00:12:59.320 --> 00:13:02.280]   yet do? Or what are promising avenues that I should further
[00:13:02.280 --> 00:13:06.640]   pursue? So yeah, both in academics and Kaggle is the same
[00:13:06.640 --> 00:13:09.520]   while on in the academic world, I would put my experiments on
[00:13:09.520 --> 00:13:12.600]   some server here at the university and let it run on
[00:13:12.600 --> 00:13:15.240]   Kaggle. I'll put it in some notebook or in a call app
[00:13:15.240 --> 00:13:18.920]   notebook, and I'll let it run just like that. And then back
[00:13:18.920 --> 00:13:22.000]   when the experimentations are done, I tried to take note of
[00:13:22.000 --> 00:13:26.240]   it. I should do this in a more structured manner. So I'm a bit
[00:13:26.240 --> 00:13:29.480]   of a chaotic person. So most of my notes I've taken in my head.
[00:13:29.480 --> 00:13:31.840]   So I just try to keep remembering, I try to remember
[00:13:31.840 --> 00:13:35.040]   all of the things I did, and which things worked well, and
[00:13:35.040 --> 00:13:38.840]   which things didn't work well. But once you start being
[00:13:38.840 --> 00:13:41.880]   involved in multiple projects at the same time, that's when you
[00:13:41.880 --> 00:13:44.640]   start realizing like, I can't keep track of this in my head
[00:13:44.640 --> 00:13:48.120]   anymore. And so it's something I'm trying to improve myself on
[00:13:48.120 --> 00:13:50.960]   like having a more structured overview. And that's probably
[00:13:50.960 --> 00:13:54.280]   where tools like weights and biases come come into play.
[00:13:54.280 --> 00:13:58.280]   They're perfect for these and tracking of experimentations.
[00:13:59.320 --> 00:14:02.160]   Yeah, thanks. Thanks for the shout out. Even though this is
[00:14:02.160 --> 00:14:04.640]   on the Weights and Biases channel, we don't try to push
[00:14:04.640 --> 00:14:08.160]   too much about weights and biases. But happy, happy to hear
[00:14:08.160 --> 00:14:13.560]   your, your feedback on it. So coming to the competition, I'd
[00:14:13.560 --> 00:14:16.880]   have to start diving into what the problem statement was about.
[00:14:16.880 --> 00:14:19.480]   But even before that, what made you sign up for this? This was
[00:14:19.480 --> 00:14:23.120]   a time series problem of sorts as I understood. But why did you
[00:14:23.120 --> 00:14:27.240]   sign up? How did you decide to team up? Because usually for the
[00:14:27.240 --> 00:14:30.160]   audience Kaggle competitions last from three sometimes to
[00:14:30.160 --> 00:14:33.400]   six months. In real cases, this was a one month competition.
[00:14:33.400 --> 00:14:36.320]   When did you team up with people? How did you team up? I'd
[00:14:36.320 --> 00:14:37.560]   love to know the story as well.
[00:14:37.560 --> 00:14:42.360]   Yeah, so exactly. You already mentioned two of the key
[00:14:42.360 --> 00:14:45.680]   properties as to why I joined the first one, it was a time
[00:14:45.680 --> 00:14:49.200]   series competition and the data was temporal. So I'm quite
[00:14:49.200 --> 00:14:52.280]   familiar with that kind of data. But then the fact that it only
[00:14:52.280 --> 00:14:56.680]   lasted for one month is something I prefer than to three
[00:14:56.680 --> 00:15:00.320]   months, actually. Especially when to when you want to start
[00:15:00.320 --> 00:15:03.840]   that at the start of the competitions, three months can
[00:15:03.840 --> 00:15:06.800]   feel rather long, you can be like a little bit burned out on
[00:15:06.800 --> 00:15:11.680]   that specific problem in the last or last two weeks of the
[00:15:11.680 --> 00:15:16.040]   competition. And so I also think one of my strengths is that I'm
[00:15:16.040 --> 00:15:21.240]   able to prototype and experiment rather quickly. While in these
[00:15:21.240 --> 00:15:24.760]   three months competitions, the details really start to matter.
[00:15:25.480 --> 00:15:29.440]   The winners will have everything perfectly optimized within the
[00:15:29.440 --> 00:15:32.920]   pipeline, right? While in those one month competitions, you can
[00:15:32.920 --> 00:15:37.520]   cut some corners because no one will be able to produce like a
[00:15:37.520 --> 00:15:40.880]   full blown solution by the end of the month. And so that's why
[00:15:40.880 --> 00:15:44.680]   I tried to choose those as well. Now, how did I get into this
[00:15:44.680 --> 00:15:47.960]   specific one? Well, I was rolled into it because I just got an
[00:15:47.960 --> 00:15:52.280]   email from Ka, who was a teammate of mine in the
[00:15:52.280 --> 00:15:55.400]   Liverpool competition and also the Halleit competition where we
[00:15:55.400 --> 00:16:01.080]   both got called. And so he contacted me and Yves, who is
[00:16:01.080 --> 00:16:05.240]   called Sidney on Kaggle. And he said, yeah, like, there's this
[00:16:05.240 --> 00:16:08.120]   interesting problem, would you be interested in teaming up? And
[00:16:08.120 --> 00:16:11.080]   so at that time, I was still busy in real life. But Yves and
[00:16:11.080 --> 00:16:13.880]   Ka already started working on the problem. And I was like, I
[00:16:13.880 --> 00:16:16.960]   will join up with you guys in like two weeks, I first need to
[00:16:16.960 --> 00:16:21.600]   take care of some stuff. And so yeah, two weeks later, I joined
[00:16:21.600 --> 00:16:24.280]   them and they already made some nice progress and had some nice
[00:16:24.280 --> 00:16:29.600]   insights. And from there on, we, yeah, us three continued, but we
[00:16:29.600 --> 00:16:35.000]   quickly noticed that we weren't gonna get the gold. Because our
[00:16:35.000 --> 00:16:37.920]   deep learning experiences was somewhat lacking. And this was
[00:16:37.920 --> 00:16:41.800]   clearly a deep learning competition. And so first, we
[00:16:41.800 --> 00:16:47.360]   we messaged Shuyun, who joined us and he had like, but I'll go
[00:16:47.360 --> 00:16:50.840]   more in depth on the solution, but he had a nice deep learning
[00:16:50.840 --> 00:16:54.760]   architecture up and running. And somewhat later, we also
[00:16:54.760 --> 00:16:59.320]   messaged B or Ricardo to join us, and he joined us as well.
[00:16:59.320 --> 00:17:03.160]   And so like the blend, or just the simple combination of us
[00:17:03.160 --> 00:17:06.680]   five already gave us a high spot. And then in the end, us
[00:17:06.680 --> 00:17:10.800]   five really cracked the puzzle. But I'll go into that later.
[00:17:10.800 --> 00:17:14.880]   It was B in the chat now, I couldn't understand who they
[00:17:14.880 --> 00:17:17.200]   were, because they gave me the acronym. But now I know.
[00:17:17.960 --> 00:17:18.880]   All right. Hey, B.
[00:17:18.880 --> 00:17:23.960]   I'm sorry, I have had a power cut. So my monitor is off right
[00:17:23.960 --> 00:17:27.600]   now. I just need a minute to turn my laptop around. My web
[00:17:27.600 --> 00:17:31.160]   cam is on but my laptop is gone. And I didn't want to interrupt
[00:17:31.160 --> 00:17:34.960]   you. So people now know that this is live and I'm trying to
[00:17:34.960 --> 00:17:36.080]   fix this issue live.
[00:17:36.080 --> 00:17:38.280]   Yeah, sure. No worries.
[00:17:38.280 --> 00:17:47.040]   Awesome. So I'll have to probably look down now. My web
[00:17:47.040 --> 00:17:49.720]   cam's up there and I'll be looking at my laptop screen. So
[00:17:49.720 --> 00:17:51.120]   Jill, I'm sorry, it'll look a little
[00:17:51.120 --> 00:17:51.880]   No worries.
[00:17:51.880 --> 00:17:55.960]   off to you. But I'm trying to fix this issue. I didn't know my
[00:17:55.960 --> 00:18:00.600]   monitor isn't on power backup. My PC is but my monitor isn't.
[00:18:00.600 --> 00:18:10.880]   Just one moment. Oh, powers back. Sorry. Now. Now I don't
[00:18:10.880 --> 00:18:13.480]   have to worry. I'll just put this back. Sorry about that.
[00:18:13.480 --> 00:18:15.960]   No problem.
[00:18:16.840 --> 00:18:21.920]   This was partly the reason why I was always so terrified to do
[00:18:21.920 --> 00:18:25.080]   chai time live. Because of these issues.
[00:18:25.080 --> 00:18:26.480]   Technical issues. Yeah.
[00:18:26.480 --> 00:18:29.920]   I'm sorry. The first time the first time this happened was
[00:18:29.920 --> 00:18:32.360]   during an interview with you. Sorry about that.
[00:18:32.360 --> 00:18:34.760]   No worries at all.
[00:18:34.760 --> 00:18:40.240]   Awesome. So I'm sharing my screen on the ventilator homepage
[00:18:40.240 --> 00:18:43.680]   and I'd love to so for this part, Jill, I'll probably just
[00:18:43.680 --> 00:18:46.400]   walk everyone through the solution as an outsider just
[00:18:46.400 --> 00:18:48.960]   about the data set and everything. Please interrupt me
[00:18:48.960 --> 00:18:51.680]   anytime you feel I'm glancing over any details.
[00:18:51.680 --> 00:18:52.880]   Okay.
[00:18:52.880 --> 00:18:59.600]   So, as I did a lot of googling around this stuff, and I hope no
[00:18:59.600 --> 00:19:02.440]   one knows as much about ventilators because they're
[00:19:02.440 --> 00:19:05.600]   quite a serious thing. But from what I understood, these are
[00:19:05.600 --> 00:19:09.120]   used to provide help to people who can't breathe naturally.
[00:19:09.120 --> 00:19:12.160]   They're in such a position where they can't breathe. So I'm
[00:19:12.160 --> 00:19:14.760]   actually they're in such a position that they need help
[00:19:14.760 --> 00:19:18.160]   from a machine. And that's why this is being provided to them.
[00:19:18.160 --> 00:19:26.160]   The goal was here to simulate a ventilator. And the target was
[00:19:26.160 --> 00:19:29.880]   to reduce the cost barrier of developing methods. So quite
[00:19:29.880 --> 00:19:33.160]   literally, there was human life somewhat related to this
[00:19:33.160 --> 00:19:39.920]   competition. The evaluation criteria is, I don't need to go
[00:19:39.920 --> 00:19:43.680]   into this, it was mean absolute errors, just the difference and
[00:19:43.680 --> 00:19:47.080]   taking the absolute value, which means it can't be negative, you
[00:19:47.080 --> 00:19:51.160]   just turn it into a positive number, and you'd have to
[00:19:51.160 --> 00:19:53.240]   submit the ID and pressure variable here.
[00:19:53.240 --> 00:19:59.160]   What I've done here is I've shamelessly been, no one would
[00:19:59.160 --> 00:20:02.920]   want to watch my EDA stuff. So I've used the famous ones here.
[00:20:02.920 --> 00:20:06.880]   This one gives a good outline of how a ventilator works. This is
[00:20:06.880 --> 00:20:12.360]   called ventilator pressure slash LSTM starter kernel. And inside
[00:20:12.360 --> 00:20:15.240]   of a ventilator, there are two different parts as I understood
[00:20:15.240 --> 00:20:17.880]   there's an inspiratory and expiratory. This would come up
[00:20:17.880 --> 00:20:21.640]   in the data set also as you in and you out. Different things
[00:20:21.640 --> 00:20:25.680]   happen inside of it. And these connect to your lung like so. So
[00:20:25.680 --> 00:20:28.080]   you pass the air into the inspiratory that goes to your
[00:20:28.080 --> 00:20:31.080]   lung and you expire the air out to the environment.
[00:20:35.680 --> 00:20:38.760]   shamelessly stealing from a Sean through his kernel ventilator
[00:20:38.760 --> 00:20:44.080]   EDA. I'll point out what columns were the in the data set.
[00:20:44.080 --> 00:20:50.400]   So the following and this is from what in my experience, I
[00:20:50.400 --> 00:20:52.800]   know it's it's a really tough competition, but the data was
[00:20:52.800 --> 00:20:55.440]   really simple to wrap my head around. So I'll rush through it.
[00:20:55.440 --> 00:21:01.760]   You had the ID across the entire file, and each bread was given a
[00:21:01.760 --> 00:21:07.600]   unique ID. For every time step, there was a different ID. Our
[00:21:07.600 --> 00:21:11.140]   measures how restricted the airway in the lung was as I
[00:21:11.140 --> 00:21:14.360]   googled I found this is one of the standard metrics. So shouldn
[00:21:14.360 --> 00:21:18.440]   be too surprising if you're familiar to the field. C
[00:21:18.440 --> 00:21:22.760]   indicates how compliant the lung is. And again, one of the
[00:21:22.760 --> 00:21:27.160]   standard metrics, you get the timestamp. And if you remember
[00:21:27.160 --> 00:21:33.160]   the diagram I just shared, you in measures the control input,
[00:21:33.160 --> 00:21:37.200]   and you out measures the control input for the exploratory
[00:21:37.200 --> 00:21:39.560]   solenoid world, which is basically when you're expiring
[00:21:39.560 --> 00:21:44.520]   gear. And pressure measures how much airway pressure is
[00:21:44.520 --> 00:21:47.240]   happening in the circuit. Did I miss anything?
[00:21:47.240 --> 00:21:52.560]   No, just like to draw an analogy like air is for resistance and
[00:21:52.560 --> 00:21:56.520]   C is for capacity. So you can see or draw an analogy with like
[00:21:56.520 --> 00:22:00.280]   electric circuits, like resistors and capacitors. And
[00:22:00.280 --> 00:22:03.480]   that's what the semantics are for the for these long
[00:22:03.480 --> 00:22:04.320]   properties. Yeah.
[00:22:04.320 --> 00:22:11.320]   Awesome. So continuing further. Sean has plotted some really
[00:22:11.320 --> 00:22:14.480]   nice graphs. And I'd probably just shamelessly use these to
[00:22:14.480 --> 00:22:19.440]   explain the analogy. This plots are against density, what was
[00:22:19.440 --> 00:22:19.920]   our
[00:22:19.920 --> 00:22:22.200]   resistance?
[00:22:23.120 --> 00:22:27.440]   Yep. As you can tell, I've not computed. I've just read
[00:22:27.440 --> 00:22:31.040]   through solutions, which is I'm blanking out through different
[00:22:31.040 --> 00:22:35.440]   portions. And this looks like an equal distribution across these
[00:22:35.440 --> 00:22:36.280]   values to me.
[00:22:36.280 --> 00:22:40.360]   Three unique values in the 10, 20 and 50.
[00:22:40.360 --> 00:22:45.720]   For compliance, it's the same case. These would be similar
[00:22:45.720 --> 00:22:49.040]   because if we looked at the definition, the scale was
[00:22:49.040 --> 00:22:53.680]   similar as well. And that's why the for people who are not
[00:22:53.680 --> 00:22:57.000]   experts at Kaggling, you'd want to spend time in the data
[00:22:57.000 --> 00:23:00.800]   because you'd want to understand if it's not standardly
[00:23:00.800 --> 00:23:04.080]   distributed, or if some values are missing out of this, let's
[00:23:04.080 --> 00:23:07.800]   say every single R value was, let's say you had 99% values
[00:23:07.800 --> 00:23:12.400]   around 10, you'd just replace everything with 10 and just skip
[00:23:12.400 --> 00:23:14.960]   the column. So that's one of the stupid ways of dealing with it.
[00:23:14.960 --> 00:23:16.560]   Just just letting everyone know.
[00:23:17.280 --> 00:23:22.640]   For you, and it was just around these two values, as I
[00:23:22.640 --> 00:23:27.760]   understood, and this is because input can't be of a very high
[00:23:27.760 --> 00:23:30.440]   density, as I understood. So that's where it will stay around
[00:23:30.440 --> 00:23:31.280]   these values.
[00:23:31.280 --> 00:23:35.760]   Yeah, so this UN is basically it's a percentage, how much is
[00:23:35.760 --> 00:23:40.160]   the valve opens. So from zero to 100%, it can be opened. And
[00:23:40.160 --> 00:23:44.360]   maybe one little detail is that there's also like a very, very
[00:23:44.360 --> 00:23:48.920]   small bump at 100 as well in this distribution plot. So they
[00:23:48.920 --> 00:23:52.760]   were also clipped these values at zero and 100 like on the on
[00:23:52.760 --> 00:23:57.280]   the right on the x axis, you see a small bump in the density as
[00:23:57.280 --> 00:24:00.160]   well. So that's because of the clipping that they did.
[00:24:00.160 --> 00:24:06.120]   Yeah, but one of the fascinating things is, I'm like a total
[00:24:06.120 --> 00:24:10.200]   outsider to all of these things. And now that like I've spent not
[00:24:10.200 --> 00:24:13.760]   not as much time as you but probably 1020 hours, I'm like
[00:24:13.760 --> 00:24:17.360]   1020 hours understanding this. I know much more about ventilators
[00:24:17.360 --> 00:24:20.280]   and all of this jargon that I'm able to wrap my head around
[00:24:20.280 --> 00:24:23.800]   this. And that's one thing that Kaggle also teaches you I feel.
[00:24:23.800 --> 00:24:32.360]   So for the output, outputs control input, this means
[00:24:32.360 --> 00:24:35.720]   whenever you're exhaling, there's also a factor that goes
[00:24:35.720 --> 00:24:39.120]   into the ventilator, the density basically revolves around two
[00:24:39.120 --> 00:24:42.560]   different values. And if you were to plot the timestamps,
[00:24:42.560 --> 00:24:47.200]   there was also an overlap with the different inputs going in,
[00:24:47.200 --> 00:24:51.400]   because probably the breaths weren't in sync with the
[00:24:51.400 --> 00:24:53.280]   patient as I understood.
[00:24:53.280 --> 00:24:55.280]   Yeah.
[00:24:55.280 --> 00:25:02.640]   Continuing further, pressure versus density had a spike
[00:25:02.640 --> 00:25:06.680]   around, I think this would be five, maybe.
[00:25:06.680 --> 00:25:10.480]   Yes, something like that five to six, that would be like the
[00:25:10.480 --> 00:25:13.920]   typical first value of your breath as well. But yeah, those
[00:25:13.920 --> 00:25:16.280]   are all details, but it's somewhere around that the mode.
[00:25:16.280 --> 00:25:21.520]   Thanks, thanks for confirming that and quickly looking at
[00:25:21.520 --> 00:25:25.160]   different distributions, of course, test and train, it looks
[00:25:25.160 --> 00:25:29.800]   like there was a quite similar distribution. So there no shake
[00:25:29.800 --> 00:25:32.320]   up would have been expected from this competition of sorts.
[00:25:32.320 --> 00:25:38.600]   Awesome. I think these are the values I wanted to cover for the
[00:25:38.640 --> 00:25:41.520]   ED a bit. Anything I missed, or anything you'd like to add?
[00:25:41.520 --> 00:25:46.400]   No, no, I think it was a great introduction. And I also have
[00:25:46.400 --> 00:25:49.880]   like, in my slides that coming up in a bit, another way of
[00:25:49.880 --> 00:25:53.400]   looking at like a typical data sample. And that may might make
[00:25:53.400 --> 00:25:56.160]   it a bit clear as well. But I think this was great to
[00:25:56.160 --> 00:25:57.200]   introduce the problem.
[00:25:57.200 --> 00:26:00.720]   Thank you. Let me see if there are any questions so far by the
[00:26:00.720 --> 00:26:04.600]   audience. No, I don't see any questions. Awesome. I'll
[00:26:04.600 --> 00:26:08.600]   probably point one more thing out before handing it to you. So
[00:26:08.600 --> 00:26:11.080]   why are we if you're just joining us, why are we learning
[00:26:11.080 --> 00:26:14.360]   from Jill, because first of all, he's a Kaggle master and he has
[00:26:14.360 --> 00:26:17.640]   amazing achievements. If you go to this competition, you don't
[00:26:17.640 --> 00:26:20.560]   even have to scroll, you can find the team right up on the
[00:26:20.560 --> 00:26:25.040]   top. And I'd also love to point out that there's such a huge gap
[00:26:25.040 --> 00:26:27.480]   between the first and second position because they had this
[00:26:27.480 --> 00:26:31.560]   really innovative idea that we'll just learn about. So with
[00:26:31.560 --> 00:26:33.520]   that, I'd like to hand it back to you, Jill.
[00:26:34.040 --> 00:26:39.960]   Okay, let me see if I can share my screen. Is it visible?
[00:26:39.960 --> 00:26:41.960]   I can see the architect is late.
[00:26:41.960 --> 00:26:44.880]   All right. Yeah, that wasn't the first slide. So a bit of a
[00:26:44.880 --> 00:26:50.120]   spoiler ahead already, but no worries. So I'll first quickly
[00:26:50.120 --> 00:26:54.160]   sketch the context because I will be zooming in mostly on one
[00:26:54.160 --> 00:26:57.720]   part of our solution, the part that I was actually to give us
[00:26:57.720 --> 00:27:00.600]   that gap that Sajam just discussed to the other
[00:27:00.600 --> 00:27:05.800]   competitors. But first, let me start off this talk or this
[00:27:05.800 --> 00:27:08.480]   small part of the talk with first acknowledging my
[00:27:08.480 --> 00:27:11.760]   teammates. So this victory would not have been possible without
[00:27:11.760 --> 00:27:15.960]   them. So here's an overview of them. And as you can see, we
[00:27:15.960 --> 00:27:18.480]   were kind of scattered all around the world. We had
[00:27:18.480 --> 00:27:21.880]   someone from the US, someone from Australia, and then three
[00:27:21.880 --> 00:27:26.760]   Europeans working around the clock on this competition, as to
[00:27:26.760 --> 00:27:32.320]   say. And maybe let's quickly look at how does one specific
[00:27:32.320 --> 00:27:37.320]   data sample look like this plot basically visualizes all of the
[00:27:37.320 --> 00:27:41.160]   important properties of a single breath. So many of them were
[00:27:41.160 --> 00:27:45.160]   covered in the EDA we just went through. So as you can see, this
[00:27:45.160 --> 00:27:49.800]   breath was recorded in the lung with a certain resistance of 20
[00:27:49.800 --> 00:27:55.360]   and a capacity of 50. And then the breath, so we are working on
[00:27:55.360 --> 00:27:59.480]   breath levels, we have about 50,000 breaths in the test set
[00:27:59.480 --> 00:28:03.800]   and 70,000 breaths in the train sets to train our models on. So
[00:28:03.800 --> 00:28:07.760]   each breath first consists of an inspiratory phase, and is
[00:28:07.760 --> 00:28:12.160]   followed by an expiratory phase. And we were or our models were
[00:28:12.160 --> 00:28:16.280]   only evaluated on the inspiratory part. So typically,
[00:28:16.280 --> 00:28:20.880]   this inspiratory part is around one second or 30 time steps
[00:28:20.880 --> 00:28:23.640]   long, there was a bit of variation on that it could be
[00:28:23.640 --> 00:28:28.000]   28 to 35, but the mean was around 30. And so the remaining
[00:28:28.000 --> 00:28:32.280]   50 ish values were expiratory, and were actually not even
[00:28:32.280 --> 00:28:35.920]   scored. But many of the models are it was clear from the public
[00:28:35.920 --> 00:28:40.640]   notebooks, these expiratory values were very important to
[00:28:40.640 --> 00:28:45.040]   predict the inspiratory values, which is quite remarkable, like
[00:28:45.040 --> 00:28:48.960]   how could something from the future in a physical process be
[00:28:49.120 --> 00:28:54.120]   indicative of this present value. And it was kind of a
[00:28:54.120 --> 00:28:59.200]   slight, a slight hint towards what we found indeed. And so the
[00:28:59.200 --> 00:29:02.040]   blue one is the one we're going to be focusing on, you can see
[00:29:02.040 --> 00:29:06.360]   it as a one dimensional problem almost. So we want to map this
[00:29:06.360 --> 00:29:10.680]   blue line to the green line as accurately as possible in this
[00:29:10.680 --> 00:29:11.720]   competition.
[00:29:11.720 --> 00:29:15.800]   So, because we're trying to predict the pressure based on
[00:29:15.800 --> 00:29:19.120]   the input values, that's why this, that's what we aim for,
[00:29:19.120 --> 00:29:19.480]   correct?
[00:29:19.480 --> 00:29:24.760]   Correctly. So indeed, we want to use the uin values to predict
[00:29:24.760 --> 00:29:28.600]   what the pressure will be in the lung at any point in time. And
[00:29:28.600 --> 00:29:33.520]   so as soon as this orange function steps to one, we no
[00:29:33.520 --> 00:29:35.760]   longer interested in our predictions, they can be as
[00:29:35.760 --> 00:29:41.600]   faulty as, as we want, because it's not scored anyway. So this
[00:29:41.600 --> 00:29:45.720]   summarizes a sample. So we have 70,000 of these plots. That's
[00:29:45.720 --> 00:29:46.720]   what we are working on.
[00:29:46.720 --> 00:29:50.400]   And also, sorry, this is like a side note here. But I wonder if
[00:29:50.400 --> 00:29:53.360]   you've gone down the rabbit hole so much where I was like also
[00:29:53.360 --> 00:29:56.640]   reading through papers that show how you inhale and exhale. And I
[00:29:56.640 --> 00:29:59.360]   was like mentally trying to check if my patterns are the
[00:29:59.360 --> 00:30:03.280]   similar. So just like geeking out over how much Kaggle teaches
[00:30:03.280 --> 00:30:05.360]   you outside of just deep learning.
[00:30:05.360 --> 00:30:08.760]   Exactly. Yeah, definitely. Rabbits hole, rabbit holes is
[00:30:08.760 --> 00:30:11.560]   what you are chasing off and on Kaggle. And you can learn a lot,
[00:30:11.560 --> 00:30:14.760]   a lot from chasing those rabbit holes. That's for sure. But I
[00:30:14.760 --> 00:30:17.720]   didn't pursue that one specifically. But we chased many
[00:30:17.720 --> 00:30:23.240]   rabbit holes here in this one for sure. And then maybe very
[00:30:23.240 --> 00:30:27.640]   briefly on our deep learning architecture. So we used two
[00:30:27.640 --> 00:30:31.560]   architectures and their kudos go to my team members Shuyun and B
[00:30:31.560 --> 00:30:36.480]   or Ricardo. So on the left, we have probably the most complex
[00:30:36.480 --> 00:30:39.280]   architecture, I would say, and the one on the right is just a
[00:30:39.280 --> 00:30:42.040]   very simplification of the one on the left. But the one on the
[00:30:42.040 --> 00:30:46.960]   left basically consists of a few LSTM layers, which is on the
[00:30:46.960 --> 00:30:50.200]   left, the left block. And we also added some skip connections
[00:30:50.200 --> 00:30:55.320]   to it, and an extra forward feed forward layer. And so we had
[00:30:55.320 --> 00:30:58.320]   four of these, if I'm not mistaken, but this was a hyper
[00:30:58.320 --> 00:31:01.800]   parameter, let's call it NL in this case. And then the
[00:31:01.800 --> 00:31:06.080]   representations learned by this part were further given to like
[00:31:06.080 --> 00:31:11.880]   a transformer encoder consisting of some 1d convolutions. Again,
[00:31:11.880 --> 00:31:16.080]   these skip connections were added to, to each of the layers.
[00:31:16.080 --> 00:31:21.600]   And so this model on the left, did leverage features. So when
[00:31:21.600 --> 00:31:27.040]   we added features to, to our inputs, then we did notice quite
[00:31:27.040 --> 00:31:31.360]   some improvements. And so we did chase feature engineering or
[00:31:31.360 --> 00:31:35.160]   pursue feature engineering a lot during this competition. But
[00:31:35.160 --> 00:31:38.480]   more towards the end, Ricardo joined us, and he had the model
[00:31:38.480 --> 00:31:41.840]   on the right. And surprisingly, this model on the right worked
[00:31:41.840 --> 00:31:45.480]   a lot better. No, not a lot better. But it worked better on
[00:31:45.480 --> 00:31:50.040]   the leaderboards than the one on the left. Maybe one side note is
[00:31:50.040 --> 00:31:53.400]   that the one on the left converged a lot a lot quicker
[00:31:53.400 --> 00:31:54.680]   than the one on the right.
[00:31:54.680 --> 00:32:00.400]   And so the main, the main difference is that the one on
[00:32:00.400 --> 00:32:03.520]   the right is just being fed the raw data. And apart from that
[00:32:03.520 --> 00:32:04.480]   architecture is here.
[00:32:04.480 --> 00:32:08.760]   Exactly. And the architecture is much more simple as well. So we
[00:32:08.760 --> 00:32:10.760]   don't have these skip connections, we don't have a
[00:32:10.760 --> 00:32:15.680]   transformer part, we just have some stacked LSTM layers. So I
[00:32:15.680 --> 00:32:19.320]   I cut everything away from the architectures, except from the
[00:32:19.320 --> 00:32:22.600]   LSTM block, that makes it a bit confusing, there's, this should
[00:32:22.600 --> 00:32:26.280]   just go a narrow from this by LSTM block to the output
[00:32:26.280 --> 00:32:29.960]   pressure, because that's how it kind of worked. So it was raw
[00:32:29.960 --> 00:32:36.240]   data, for LSTM layers, and then a whole lot of a box on the raw
[00:32:36.240 --> 00:32:42.800]   data. And it also required some Yeah, how do you say it? special
[00:32:42.800 --> 00:32:46.280]   learning rate schedules, I would say. So that was the thing where
[00:32:46.280 --> 00:32:50.360]   the breakthrough as to why this specific network converged. So B
[00:32:50.360 --> 00:32:54.800]   had some cosine annealing in there, and it was with a very
[00:32:54.800 --> 00:32:58.520]   low learning rate, I believe. And that's how he made it to
[00:32:58.520 --> 00:33:03.320]   converge really well on the leaderboards. And so a note,
[00:33:03.720 --> 00:33:08.640]   these two architectures, if you train them over multiple folds,
[00:33:08.640 --> 00:33:12.520]   let's say 15 to 20 fold cross validation, and you do that
[00:33:12.520 --> 00:33:16.240]   multiple times as well, just with different seats, then you
[00:33:16.240 --> 00:33:20.240]   would end up with a whole bunch of models. For every fold and
[00:33:20.240 --> 00:33:22.920]   every seat, you would have a model. And so we have these two
[00:33:22.920 --> 00:33:28.360]   architectures. And so a blend of about 60 of these models would,
[00:33:28.360 --> 00:33:32.560]   I can't say with certainty if it would obtain you in a gold
[00:33:32.560 --> 00:33:35.680]   medal, but it would be on the edge of getting it. So it
[00:33:35.680 --> 00:33:37.880]   wouldn't be top 25 for sure.
[00:33:37.880 --> 00:33:43.720]   I'm sorry, I'm sorry to keep interrupting you. But I also
[00:33:43.720 --> 00:33:47.440]   love to understand how do you arrive at such architectures
[00:33:47.440 --> 00:33:49.680]   because we see research papers and we know that to like
[00:33:49.680 --> 00:33:53.880]   experiments. So to me, I'll just speak out my thoughts and please
[00:33:53.880 --> 00:33:57.840]   correct me. LSTM are helpful because this is a time series
[00:33:57.840 --> 00:34:02.600]   problem. And LSTMs are quite good at that. Let's see the FFN
[00:34:02.600 --> 00:34:05.240]   from their health connect the layers, the skip connection is
[00:34:05.240 --> 00:34:08.880]   useful in missing out in connecting the transformer from
[00:34:08.880 --> 00:34:12.080]   there or any details that the bi LSTM would encode to something
[00:34:12.080 --> 00:34:14.800]   else. I know it's just numbers, but I'm trying to get the
[00:34:14.800 --> 00:34:15.600]   intuition here.
[00:34:15.600 --> 00:34:19.640]   Sure. Yeah, it's indeed like that. So the skip connections
[00:34:19.640 --> 00:34:24.120]   help a lot with convergence. And so the reason why LSTMs are so
[00:34:24.120 --> 00:34:27.240]   useful here is because of their long term memory. So they are
[00:34:27.240 --> 00:34:32.320]   able to remember information from very early in the signal.
[00:34:32.320 --> 00:34:35.800]   And if you because they were bi directional, they're also able
[00:34:35.800 --> 00:34:39.600]   to carry over information from the entire end of the breath as
[00:34:39.600 --> 00:34:43.680]   well. So that turned out to be very important. So information
[00:34:43.680 --> 00:34:47.640]   from the expiratory phase could really predict the inspiratory
[00:34:47.640 --> 00:34:51.080]   phase well, and that is just because of the PID controllers,
[00:34:51.080 --> 00:34:54.000]   we will be discussing in quite a bit. So the reason why these
[00:34:54.000 --> 00:34:59.120]   CNNs are here is just to like take some more or do some local
[00:34:59.120 --> 00:35:02.320]   learning. So they work with a window over your time series,
[00:35:02.320 --> 00:35:05.600]   and they will take some aggregate on that window, they
[00:35:05.600 --> 00:35:10.160]   learn it. And so that's why the combination of these two really
[00:35:10.160 --> 00:35:13.240]   helped well for the one on the left. But then the LSTM is
[00:35:13.240 --> 00:35:17.200]   probably the most important technique, I would say here for
[00:35:17.200 --> 00:35:20.400]   this specific type of data. So that's why it's the only one
[00:35:20.400 --> 00:35:22.480]   that's present in the one on the right.
[00:35:23.080 --> 00:35:25.960]   That makes sense. I'm also curious, why did you use the
[00:35:25.960 --> 00:35:29.680]   decon layer? Because I was looking at the fifth team's
[00:35:29.680 --> 00:35:32.720]   solution, and I just interviewed them a few hours ago, they just
[00:35:32.720 --> 00:35:38.320]   use con 1D as a feature. Any, any extra thoughts on why did
[00:35:38.320 --> 00:35:40.840]   you use decon when how that was helpful?
[00:35:40.840 --> 00:35:45.920]   So great question. I can't really accurately answer that at
[00:35:45.920 --> 00:35:49.560]   the moment. But I can think back to Shuyun who worked intensively
[00:35:49.560 --> 00:35:53.520]   on this one on the left, and I can post it on the forum on the
[00:35:53.520 --> 00:35:55.120]   Weights and Biases forum.
[00:35:55.120 --> 00:35:58.120]   Thank you. Sorry for so many side notes.
[00:35:58.120 --> 00:35:58.960]   No worries.
[00:35:58.960 --> 00:36:01.720]   I didn't compete. I'm just trying to understand greatness
[00:36:01.720 --> 00:36:04.240]   from you. So that's why these stupid questions pop up.
[00:36:04.240 --> 00:36:07.080]   Yeah, I'm sure your questions are very useful for the audience
[00:36:07.080 --> 00:36:09.440]   as well. So no worries, interrupt me at any time you
[00:36:09.440 --> 00:36:16.720]   want. So the part that we'll be zooming in, that probably gave
[00:36:16.720 --> 00:36:21.280]   us about 50% of a score to reduce the error by more than
[00:36:21.280 --> 00:36:27.240]   50% in the end, which is why we have such a gap is PID
[00:36:27.240 --> 00:36:30.880]   controllers. And so it's an acronym, and it stands for
[00:36:30.880 --> 00:36:35.280]   proportional, integral and derivative controllers. And that
[00:36:35.280 --> 00:36:38.960]   sounds very complicated, but it's definitely not, you'll see
[00:36:38.960 --> 00:36:43.400]   it's quite simple equations. But you can kind of think of this as
[00:36:44.760 --> 00:36:49.400]   a controlling system that takes three pieces of information into
[00:36:49.400 --> 00:36:52.440]   account. And that's what anyone probably would take into account
[00:36:52.440 --> 00:36:55.320]   if you would make an informed decision. That's the present,
[00:36:55.320 --> 00:36:59.480]   which is the proportional term of it, the past, the integral
[00:36:59.480 --> 00:37:02.600]   term, which is typically a cumulative sum, and the
[00:37:02.600 --> 00:37:05.880]   derivative, which is the future, which is basically the
[00:37:05.880 --> 00:37:09.160]   difference of the current value and the previous value. And you
[00:37:09.160 --> 00:37:11.520]   can kind of, that's the gradient. So you can kind of
[00:37:11.520 --> 00:37:16.120]   extrapolate that to the future. And so what are these used for?
[00:37:16.120 --> 00:37:19.720]   Well, it's probably used in everyone's house, for example,
[00:37:19.720 --> 00:37:24.160]   it's to control the controllable variable in order to keep a
[00:37:24.160 --> 00:37:27.880]   measurable, measurable variable around a certain set point and
[00:37:27.880 --> 00:37:30.720]   to draw the analogy with something that's working in your
[00:37:30.720 --> 00:37:34.320]   house, your temperature control in your house is probably
[00:37:34.320 --> 00:37:38.800]   governed by a PID controller. So there are some valves that,
[00:37:38.840 --> 00:37:43.080]   valves here as well, that probably blast heat into the
[00:37:43.080 --> 00:37:47.160]   room. But of course, it's not a direct effect that this heat
[00:37:47.160 --> 00:37:52.240]   has, it's probably there goes some time as to when the impact
[00:37:52.240 --> 00:37:56.680]   of this blasting of heat is actually visual, visual, visual,
[00:37:56.680 --> 00:37:57.240]   sorry.
[00:37:57.240 --> 00:38:01.440]   So, may I add another simple example?
[00:38:01.440 --> 00:38:02.440]   Sure.
[00:38:02.440 --> 00:38:06.480]   So I worked, sorry, when I say worked, it was a student lab
[00:38:06.480 --> 00:38:09.440]   where we were just geeking around on evenings that's not
[00:38:09.440 --> 00:38:14.240]   work that was just hacking. But this was a PID controller where
[00:38:14.240 --> 00:38:17.120]   we were trying to create a submarine. And from what I
[00:38:17.120 --> 00:38:19.200]   understood, it's just really helpful whenever something
[00:38:19.200 --> 00:38:21.680]   digital is trying to interact with something analog. So
[00:38:21.680 --> 00:38:24.520]   temperature is something analog and you're trying to connect it
[00:38:24.520 --> 00:38:28.160]   with digital circuit. That's where PID circuits come in
[00:38:28.160 --> 00:38:28.680]   useful.
[00:38:28.680 --> 00:38:34.000]   Yeah, that's a great analogy, actually. And so ZipMe from our
[00:38:34.000 --> 00:38:36.800]   team is super familiar with all of these because he has a
[00:38:36.800 --> 00:38:41.560]   physical engineering background. And so he probably uses or comes
[00:38:41.560 --> 00:38:46.280]   into contact with these on an almost daily basis. So here, we
[00:38:46.280 --> 00:38:50.240]   have like this inspiratory valve and based on how much you open
[00:38:50.240 --> 00:38:54.040]   that, the pressure is going to change in some time or
[00:38:54.040 --> 00:38:58.960]   immediately. That's something that is tunable. And this
[00:38:58.960 --> 00:39:02.000]   pressure is going to change in the lung. So this is how this PID
[00:39:02.080 --> 00:39:09.080]   kind of fits in. So if you think about like, how was this data
[00:39:09.080 --> 00:39:12.880]   generated by the organizers of the competition? Well, they had
[00:39:12.880 --> 00:39:16.800]   this mechanical lung, and there was a ventilator strapped onto
[00:39:16.800 --> 00:39:22.520]   that mechanical lung. And so they were either pumping up a
[00:39:22.520 --> 00:39:25.640]   lot of air with this ventilator or were not doing that they
[00:39:25.640 --> 00:39:30.280]   simulated many trajectories of this inspiratory valve, I must
[00:39:30.320 --> 00:39:33.840]   I have to say, and then they measured the pressure on the
[00:39:33.840 --> 00:39:39.200]   output side. At least, maybe to quickly show like, how does this
[00:39:39.200 --> 00:39:42.200]   lung look like? Well, it's basically this, this is the one
[00:39:42.200 --> 00:39:45.320]   they used. So you can see like this plastic thing, that's
[00:39:45.320 --> 00:39:48.800]   probably where you plug in the ventilator as well. And so you
[00:39:48.800 --> 00:39:52.000]   can probably read out the pressure here somewhere as well.
[00:39:52.000 --> 00:39:55.480]   And so they made many trajectories and they read out
[00:39:55.480 --> 00:39:59.200]   the pressure. And so that's basically the data. And so many
[00:39:59.200 --> 00:40:02.760]   people believe so that they just went nuts or wild with this
[00:40:02.760 --> 00:40:05.920]   inspiratory valve, they made some random walks or really
[00:40:05.920 --> 00:40:11.120]   exposed this lung to an exotic range of possible trajectories
[00:40:11.120 --> 00:40:15.360]   that this inspiratory valve can carry. And that would be optimal
[00:40:15.360 --> 00:40:19.280]   for the model, because then it basically sees every sequence of
[00:40:19.280 --> 00:40:23.120]   possible inspiratory valve values. But as it turns out,
[00:40:23.120 --> 00:40:27.560]   that was not the case at all. So this entire data generating
[00:40:27.560 --> 00:40:30.840]   process was governed or regulated by this PID
[00:40:30.840 --> 00:40:36.640]   controller. So I don't know if they forgot to disable it or why
[00:40:36.640 --> 00:40:42.080]   it was done like that. But so the inspiratory valves and the
[00:40:42.080 --> 00:40:45.480]   pressures that correspond to it were basically deterministic
[00:40:45.480 --> 00:40:50.560]   based on the PID configuration that was used in that breath.
[00:40:50.560 --> 00:40:55.840]   So yeah, our goal or what we did was we reverted this so we were
[00:40:55.840 --> 00:41:00.960]   able to switch around the arrows and basically for 66% of the
[00:41:00.960 --> 00:41:05.640]   data perfectly predict what the pressure would be. Because if
[00:41:05.640 --> 00:41:09.920]   you plugged in the those candidate pressure values into
[00:41:09.920 --> 00:41:15.240]   our PID formulas, they exactly evaluated to these inspiratory
[00:41:15.240 --> 00:41:19.880]   valve values. And so they had to be exactly that. And so that's
[00:41:19.880 --> 00:41:23.760]   where I'll probably I'll zoom in now. I'll quickly go through my
[00:41:23.760 --> 00:41:27.920]   notebook. I'll try to make it rather brief. So I probably will
[00:41:27.920 --> 00:41:32.200]   skip part four, because that's a bit more technical, I would say,
[00:41:32.200 --> 00:41:35.200]   but it is in there. It's in this notebook, so you can definitely
[00:41:35.200 --> 00:41:38.240]   check up on it. And if you have any questions about it,
[00:41:38.240 --> 00:41:42.680]   definitely feel free to shoot out to me. Maybe before I go
[00:41:42.680 --> 00:41:45.560]   into that, there's like all of this code is also available on
[00:41:45.560 --> 00:41:49.560]   GitHub. So this will fully reproduce our solution. And from
[00:41:49.560 --> 00:41:54.600]   this repository, you can also go to the repos of Ricardo and
[00:41:54.600 --> 00:42:00.600]   Shuyun with their deep learning models in there. Okay, so let's
[00:42:00.600 --> 00:42:03.600]   zoom in on this PID controller matching.
[00:42:03.600 --> 00:42:07.240]   Sorry, I just want to remind the audience people watching live
[00:42:07.240 --> 00:42:10.600]   this link in the chat on there, I'll make sure to post this link.
[00:42:10.600 --> 00:42:13.720]   If you're watching a recording on YouTube later, that's fine.
[00:42:13.720 --> 00:42:16.760]   The description will be updated with these links. If it's not,
[00:42:16.760 --> 00:42:19.640]   that's my fault. Just leave a comment and I'll leave the link
[00:42:19.640 --> 00:42:23.320]   there so that I really feel these notebooks have so many
[00:42:23.320 --> 00:42:26.200]   tiny details that you only learn when you're trying to go through
[00:42:26.200 --> 00:42:28.520]   them. So I would highly encourage you if you're watching
[00:42:28.520 --> 00:42:31.000]   right now or watching later, please, please do read through
[00:42:31.000 --> 00:42:32.600]   if not try to re implement this.
[00:42:32.600 --> 00:42:38.960]   That's a great suggestion. No worries. Great suggestion. So
[00:42:38.960 --> 00:42:42.000]   here is basically there's going to be a bit of math involved
[00:42:42.000 --> 00:42:46.440]   here, but it's not going to be difficult, I must say. But it's
[00:42:46.440 --> 00:42:50.000]   kind of essential to get to the case. But this is like the
[00:42:50.000 --> 00:42:54.280]   vanilla form of a PID controller. So we have an error
[00:42:54.280 --> 00:42:57.680]   term, let me see, which is this epsilon, by the way, in the
[00:42:57.680 --> 00:43:01.120]   equation, I'm selecting it. And this is basically equal to the
[00:43:01.120 --> 00:43:05.680]   target minus what we measured. So again, target is the set
[00:43:05.680 --> 00:43:08.600]   point that is like, what is the temperature I want in the room,
[00:43:08.600 --> 00:43:11.560]   or in this case, what is the ideal pressure that I want to
[00:43:11.560 --> 00:43:15.560]   have in this lung. So at any point in time, we are having a
[00:43:15.560 --> 00:43:17.880]   certain pressure within this lung. And so that's how we
[00:43:17.880 --> 00:43:22.040]   calculate this epsilon, we just subtract or measure pressure,
[00:43:22.040 --> 00:43:28.080]   pressure from the set point that we want to reach. And so yeah,
[00:43:28.080 --> 00:43:31.080]   once we have these epsilons, we can calculate the integral with
[00:43:31.080 --> 00:43:34.080]   it, it's in this case, a cumulative sum, but later, we
[00:43:34.080 --> 00:43:37.680]   will see that it was not exactly a cumulative sum that was used
[00:43:37.680 --> 00:43:42.600]   in this specific data generating process. And on the third term
[00:43:42.600 --> 00:43:45.720]   is the derivative term. And as I said, that's basically just the
[00:43:45.720 --> 00:43:49.960]   epsilon of this time step minus the epsilon of the previous
[00:43:49.960 --> 00:43:53.160]   time step. And so then we have also these alpha, beta and
[00:43:53.160 --> 00:43:55.960]   gamma. And these are just parameters of this model, these
[00:43:55.960 --> 00:43:59.520]   are tunable, these are just floating points, you can set
[00:43:59.520 --> 00:44:05.360]   them as to fit the data as good as possible. Here, I just load
[00:44:05.360 --> 00:44:08.840]   in some data. So that's probably very boilerplate. But one thing
[00:44:08.840 --> 00:44:12.840]   I do want to note is, and it was really key to our solution is
[00:44:12.840 --> 00:44:17.360]   that the pressure is not continuous, it is quite it is
[00:44:17.360 --> 00:44:23.920]   discretized. So there's only 950 unique values of this pressure,
[00:44:23.920 --> 00:44:31.760]   and they range from mine, this value minus 1.89 until 46.82.
[00:44:31.920 --> 00:44:40.000]   And they take steps of 0.07. So you can do this plus i times
[00:44:40.000 --> 00:44:44.760]   this, and then i takes the value zero to 949. And just like that,
[00:44:44.760 --> 00:44:49.360]   you construct all the possible pressure values. What code is
[00:44:49.360 --> 00:44:52.960]   matching code, so it won't be able to match all of the data.
[00:44:52.960 --> 00:44:57.400]   And so it needs a submission baseline submission to work on.
[00:44:57.400 --> 00:45:00.360]   So it will try to match as much as possible. And when it finds
[00:45:00.360 --> 00:45:03.520]   a match, it replaces the predictions, but where it cannot
[00:45:03.520 --> 00:45:06.520]   find a match, it keeps the original predictions. So we'll
[00:45:06.520 --> 00:45:12.760]   load in a notebook here. So let's focus on the simplest part,
[00:45:12.760 --> 00:45:17.360]   and which is P controllers. And so that basically means that the
[00:45:17.360 --> 00:45:22.720]   integral and the derivative term are set to zero. So the beta and
[00:45:22.720 --> 00:45:25.880]   the gamma parameter, which was that weight that corresponded to
[00:45:25.880 --> 00:45:30.080]   those terms are just equal to zero. And so if you just write
[00:45:30.080 --> 00:45:34.480]   out that equation, it's pretty simple. It's just alpha times
[00:45:34.480 --> 00:45:40.120]   epsilon, that's equal to your u n value. So if you just write
[00:45:40.120 --> 00:45:43.200]   this out, like I said, the epsilon is target minus the
[00:45:43.200 --> 00:45:47.160]   pressure. So you can kind of rework this equation to be in
[00:45:47.160 --> 00:45:51.840]   function of the pressure. And that's probably maybe one I've
[00:45:51.840 --> 00:45:54.880]   already noticed, this is completely analogous to a linear
[00:45:54.880 --> 00:45:58.840]   regression model. So you have one feature, the epsilon, and you
[00:45:58.840 --> 00:46:03.240]   have one weight, the alpha, and like that you try to predict the
[00:46:03.240 --> 00:46:08.000]   u n. Maybe important, we are kind of reverting the logic at
[00:46:08.000 --> 00:46:12.080]   the moment. So we are trying to predict u n from the pressure,
[00:46:12.080 --> 00:46:17.120]   instead of what is given to us, u n, you're given u n's, you need
[00:46:17.120 --> 00:46:20.200]   to predict the pressure. But for the training set, we are given
[00:46:20.200 --> 00:46:23.080]   both of them because we need to train supervised models with it.
[00:46:23.080 --> 00:46:26.400]   So we are first working in the reverse order to get the
[00:46:26.400 --> 00:46:30.600]   insights, and then we'll swap it back and apply some tricks in
[00:46:30.600 --> 00:46:35.680]   order to apply this on the test set. And so these are indeed the
[00:46:35.680 --> 00:46:39.040]   parameters or the sorry, the equation in function of the
[00:46:39.040 --> 00:46:41.880]   pressure, but there's two parameters in this equation, the
[00:46:41.880 --> 00:46:46.720]   target and the alpha. And so how to find these parameters? Well,
[00:46:46.720 --> 00:46:49.960]   there were two ways. The easiest way is just to read the paper
[00:46:49.960 --> 00:46:53.560]   from the organizers, it's nicely in there in the appendix,
[00:46:53.720 --> 00:46:58.240]   there's about 20 possible values for alpha, and there's about six
[00:46:58.240 --> 00:47:01.640]   possible values for target, but you didn't even need that paper,
[00:47:01.640 --> 00:47:04.440]   you can just fit linear regression models, because
[00:47:04.440 --> 00:47:07.520]   that's what they are. And you can whenever you find like a
[00:47:07.520 --> 00:47:12.440]   nearly perfect fit, you can kind of store the parameters of your
[00:47:12.440 --> 00:47:15.880]   model. And so this code snippet, which is commented out will do
[00:47:15.880 --> 00:47:21.000]   exactly that it will fit 1D models, this time from u into
[00:47:21.000 --> 00:47:25.360]   pressure, as you can see here. And once it finds a fit that is
[00:47:25.360 --> 00:47:29.320]   like nearly perfect, it will print out the intercept or bias
[00:47:29.320 --> 00:47:32.880]   term of the linear regression model, and the single coefficient
[00:47:32.880 --> 00:47:35.760]   that we learned. And so these correspond to target and alpha.
[00:47:35.760 --> 00:47:39.920]   But as I said, that would be the hard way just just taken from
[00:47:39.920 --> 00:47:42.480]   the paper, that's the easiest way. Because here they are,
[00:47:42.480 --> 00:47:46.120]   that's the 20 possible alpha values. And here are the six
[00:47:46.120 --> 00:47:50.920]   possible pressure values. And so let's do like, for example, a
[00:47:50.920 --> 00:47:54.640]   grid search with these parameters on our UN and
[00:47:54.640 --> 00:47:58.920]   pressure data for one single breath, the one with ID two in
[00:47:58.920 --> 00:48:02.800]   this case, and let's see how good or matching is. So this is
[00:48:02.800 --> 00:48:06.600]   basically the formula I just explained. And whenever, go
[00:48:06.600 --> 00:48:06.880]   ahead.
[00:48:06.880 --> 00:48:10.680]   So sorry to interrupt. So just for my own understanding, we're
[00:48:10.680 --> 00:48:14.600]   trying to find the values for P ID separately. And that is
[00:48:14.600 --> 00:48:18.000]   because we're trying to do matching with the same that's
[00:48:18.000 --> 00:48:22.000]   why we're trying to do this grid search, because first we'd find
[00:48:22.000 --> 00:48:24.520]   the value for just a P controller and then we'll do the
[00:48:24.520 --> 00:48:25.600]   same for the remaining two.
[00:48:25.600 --> 00:48:29.760]   Exactly. So in the next section, so here we make an assumption
[00:48:29.760 --> 00:48:33.120]   that there is no integral and derivative part toward PID
[00:48:33.120 --> 00:48:36.680]   controller. So the beta and gamma, which were the two
[00:48:36.680 --> 00:48:41.240]   weights corresponding to those terms are set to zero. And so we
[00:48:41.240 --> 00:48:45.080]   are first focusing on on this part, because it's a lot easier
[00:48:45.080 --> 00:48:48.400]   because you don't have that integral term. And so that's
[00:48:48.400 --> 00:48:51.440]   why we focused on this first, and this was actually already
[00:48:51.440 --> 00:48:55.120]   discovered by us very, very early in the competition. This
[00:48:55.120 --> 00:49:00.760]   was a post processing technique we use to give us like a 0.005
[00:49:00.760 --> 00:49:04.400]   boost, which was quite significant on the leaderboard.
[00:49:04.400 --> 00:49:07.000]   But little did we know that there was much, much more to
[00:49:07.000 --> 00:49:10.120]   discover back in those days, it was only at the end of the
[00:49:10.120 --> 00:49:13.760]   competition that we made a huge breakthrough. But I'll sketch
[00:49:13.760 --> 00:49:16.360]   some context for that. It's good that you bring it up.
[00:49:16.360 --> 00:49:18.960]   Thank you. You were talking about the grid search.
[00:49:18.960 --> 00:49:22.600]   Yeah, exactly. So here we're doing that grid search. So we're
[00:49:22.600 --> 00:49:27.880]   basically trying out all of the 120 possible combinations of
[00:49:27.880 --> 00:49:32.280]   these two parameters, we plug them into a formula. And once we
[00:49:32.280 --> 00:49:38.320]   found like a match, that's like, almost zero, we'll say, we'll
[00:49:38.320 --> 00:49:41.960]   print out the two parameters. And so this is basically it on
[00:49:41.960 --> 00:49:46.560]   graph ID two, we have a target of 25. And this alpha parameter
[00:49:46.560 --> 00:49:51.600]   corresponds to 0.8. And if we then plug in these two
[00:49:51.600 --> 00:49:56.680]   parameters, and we, if we plug it in, let's me scroll up. If we
[00:49:56.680 --> 00:49:59.600]   plug in these two parameters on the equation here on the right
[00:49:59.600 --> 00:50:02.800]   or the equation of the left, we are left with these two plots.
[00:50:02.800 --> 00:50:06.400]   So these are the results. This is the one on the left. So we go
[00:50:06.400 --> 00:50:09.320]   from pressure to u in that equation. And this is the one
[00:50:09.320 --> 00:50:13.640]   from u into pressure. So the equation on the right, so they
[00:50:13.640 --> 00:50:16.680]   are blue and red lines, but it's a single purple line. So they're
[00:50:16.680 --> 00:50:19.680]   really, really matching. Well, as you can see, it's a it's a
[00:50:19.680 --> 00:50:25.440]   perfect match. But for this, we will keep we're constantly using
[00:50:25.440 --> 00:50:29.000]   both pressure and u in we're fitting a linear regression
[00:50:29.000 --> 00:50:34.880]   model. And only when the fit is perfect, we we keep the
[00:50:34.880 --> 00:50:38.000]   parameters, but we don't have pressure values for the test
[00:50:38.000 --> 00:50:41.720]   set. So how does one go about applying this to the test set?
[00:50:41.720 --> 00:50:45.400]   Well, here, we'll make use of that property of the pressures
[00:50:45.400 --> 00:50:50.800]   I discussed earlier, there are only 950 unique pressure values,
[00:50:50.800 --> 00:50:56.360]   and they have a fixed step in between them. So if we find two
[00:50:56.360 --> 00:51:00.080]   parameters, this step and this alpha, and we plug it into the
[00:51:00.080 --> 00:51:06.080]   formula that predicts pressure from u in. And we have a result
[00:51:06.080 --> 00:51:10.760]   such that all of our calculated pressure values perfectly align
[00:51:10.760 --> 00:51:15.560]   with those 950 possible unique values of the pressure, well,
[00:51:15.560 --> 00:51:19.960]   then we find a match, it's very unlikely to find for the breath,
[00:51:19.960 --> 00:51:24.000]   which is the inspiratory part of the breath, which is 30 long to
[00:51:24.000 --> 00:51:28.240]   find, how do you say it hash collisions, something like that.
[00:51:28.240 --> 00:51:32.240]   So it had to be a perfect match if it aligned perfectly with
[00:51:32.240 --> 00:51:34.600]   these 950 values.
[00:51:34.600 --> 00:51:39.640]   And Jill says only 950 because just to remind audience, there
[00:51:39.640 --> 00:51:43.000]   are 70,000 values. And out of that, there are only 950
[00:51:43.000 --> 00:51:44.920]   different values that you can move through.
[00:51:44.920 --> 00:51:50.000]   Exactly, even more than 70,000. So 70,000 breaths and each breath
[00:51:50.000 --> 00:51:54.400]   consists of 80 values. So some of them are expiratory and not
[00:51:54.400 --> 00:51:57.160]   used. But so we have in the range of a few millions.
[00:51:57.160 --> 00:51:58.280]   Half. Yeah.
[00:51:58.280 --> 00:52:00.160]   Yeah. Okay. Yeah.
[00:52:00.640 --> 00:52:03.200]   I was thinking half a million, maybe my math is correct.
[00:52:03.200 --> 00:52:10.400]   That's correct. No, no 5.6 million. Sorry. 5.6 million. And
[00:52:10.400 --> 00:52:15.560]   then yeah, so here we do that grid search. And so the only
[00:52:15.560 --> 00:52:21.600]   addition we do is here this specific error. So we calculate
[00:52:21.600 --> 00:52:25.120]   our predictions with that very simple equation I already
[00:52:25.120 --> 00:52:30.840]   discussed, then we round the predictions to integers based on
[00:52:30.840 --> 00:52:35.080]   this step value. So if Pratt's round contains an integer, then
[00:52:35.080 --> 00:52:39.000]   it was perfectly aligned with this pressure step, or this diff
[00:52:39.000 --> 00:52:43.280]   pressure as it is called in the code. So that's what we want. We
[00:52:43.280 --> 00:52:47.040]   want Pratt's round to contain integers and not floating points,
[00:52:47.040 --> 00:52:51.200]   or at least something close to an integer, it can contain like
[00:52:51.200 --> 00:52:55.840]   some decimals 12 positions after the comma, but it had to be
[00:52:55.840 --> 00:52:59.280]   close to an integer. And so that's what our tune error is. So
[00:52:59.280 --> 00:53:04.440]   we'll basically round this to the closest integer, and then we
[00:53:04.440 --> 00:53:07.720]   we subtract it from the actual values. And so with that, we're
[00:53:07.720 --> 00:53:11.360]   basically expressing how close are all these values to
[00:53:11.360 --> 00:53:15.520]   integers. So if it's really, really close for all of these
[00:53:15.520 --> 00:53:20.320]   values to an integer, the sum is smaller than one, e minus six.
[00:53:20.560 --> 00:53:24.600]   Yeah, well, then then we find a match. So we just return the
[00:53:24.600 --> 00:53:30.640]   predictions and our parameters. And so we can do this again, for
[00:53:30.640 --> 00:53:34.200]   our breath that we just discussed when we both had
[00:53:34.200 --> 00:53:39.440]   pressure and u in, but now we'll just use the u in. So here I use
[00:53:39.440 --> 00:53:43.120]   pressure, but you can see it's not somewhere in that function.
[00:53:43.120 --> 00:53:48.520]   So I only use u in as you can see in this function. So with
[00:53:48.520 --> 00:53:51.880]   the u in, if you compare that to the actual pressure or
[00:53:51.880 --> 00:53:55.800]   predictions, well, we have this mean absolute error. And so
[00:53:55.800 --> 00:53:59.480]   yeah, there is an e minus 16. In the end, do take note of that
[00:53:59.480 --> 00:54:05.200]   it's basically zero here, just like some precision errors. So
[00:54:05.200 --> 00:54:09.760]   yeah, we can do this now for our entire training and testing set.
[00:54:09.760 --> 00:54:13.480]   It's a good exercise to do this on the training set first and
[00:54:13.480 --> 00:54:17.240]   see whether everything works. So we do that here. And so we
[00:54:17.240 --> 00:54:20.480]   started off with a mean absolute error, we loaded in a submission
[00:54:20.480 --> 00:54:32.080]   of 0.1405. And so here we have 136, roughly, so that's a 0.004
[00:54:32.080 --> 00:54:36.920]   closer actually to 005 boost. And so that's very significant.
[00:54:36.920 --> 00:54:41.560]   And you can do this on the test set as well. And actually, a
[00:54:41.560 --> 00:54:46.280]   nice thing is that you don't need to submit the thing you did
[00:54:46.280 --> 00:54:49.240]   on the test set to the leaderboard to see how well it
[00:54:49.240 --> 00:54:54.760]   works, you can calculate your score locally as well. And if
[00:54:54.760 --> 00:54:57.080]   you have the leaderboard score of the submission you're
[00:54:57.080 --> 00:55:01.240]   starting from, you can basically just calculate the mean absolute
[00:55:01.240 --> 00:55:03.680]   error between your new submission and the old
[00:55:03.680 --> 00:55:08.440]   submission. And that difference, minus your old leaderboard score
[00:55:08.440 --> 00:55:12.440]   is going to be your new leaderboard score. So here, I
[00:55:12.440 --> 00:55:17.800]   show this. So if we calculate the mean absolute error by the
[00:55:17.800 --> 00:55:22.800]   formula, we obtain this value, I believe in the bottom, it's
[00:55:22.800 --> 00:55:26.160]   quite irrelevant which one is which I think, but this one is
[00:55:26.160 --> 00:55:30.000]   just calculating the mean differences between the new and
[00:55:30.000 --> 00:55:34.240]   the old submission as well. And you see, those two values match
[00:55:34.240 --> 00:55:41.680]   very, very well. Okay, so that was the easier part, I would
[00:55:41.680 --> 00:55:44.840]   say. And so that's something we discovered rather early on in
[00:55:44.840 --> 00:55:48.680]   the in the competition. And that gave us like a nice boost on the
[00:55:48.680 --> 00:55:51.840]   leaderboard, but not the boost we managed to obtain in the end.
[00:55:51.840 --> 00:55:56.880]   And the reason why we got to that boost is we got PI
[00:55:56.880 --> 00:56:02.600]   controllers working as well. So in my initial formula, maybe
[00:56:02.600 --> 00:56:06.800]   let's, I'll scroll to it. Oh, no, it's right here. And we had
[00:56:06.800 --> 00:56:11.240]   this, just a summation of these epsilon terms starting from
[00:56:11.280 --> 00:56:15.200]   value zero up until where we are in time at this point. So it's,
[00:56:15.200 --> 00:56:20.000]   it's a cumulative sum, in other words. And that is a valid way
[00:56:20.000 --> 00:56:23.720]   to calculate an integral, but it's not how it was exactly done
[00:56:23.720 --> 00:56:28.800]   in this data process. And so there are some resources online
[00:56:28.800 --> 00:56:31.240]   that you can check. And there are many different ways to
[00:56:31.240 --> 00:56:35.800]   calculate these integral terms. Often they are used to avoid
[00:56:35.800 --> 00:56:40.600]   numerical issues and that kind of stuff. But what we did was
[00:56:40.600 --> 00:56:45.120]   just trial and error with all of the possible flavors of this
[00:56:45.120 --> 00:56:49.760]   integral term. And after a while, we did find a match. So
[00:56:49.760 --> 00:56:53.840]   this integral term was not exactly a cumulative sum, but it
[00:56:53.840 --> 00:57:00.920]   was more of a weight decay. So it would add the newest value,
[00:57:00.920 --> 00:57:03.880]   but first it would kind of multiply the old values with
[00:57:03.880 --> 00:57:07.880]   some, with some weight. And so there would be memory in there,
[00:57:07.880 --> 00:57:12.480]   but the older values would, their importance to the sum
[00:57:12.480 --> 00:57:19.640]   would dissipate over time as, as we go further. So these, how
[00:57:19.640 --> 00:57:23.120]   many lines is it? Six, seven, eight, something like that is
[00:57:23.120 --> 00:57:27.920]   basically all there is to it. So this is the data generating
[00:57:27.920 --> 00:57:33.280]   process. You give it some pressure, and it generates the
[00:57:33.280 --> 00:57:39.400]   U-in for it. However, it needs a certain initial integral term.
[00:57:39.400 --> 00:57:43.040]   And that's something that is extremely hard to brute force.
[00:57:43.040 --> 00:57:46.920]   Luckily, there were some in there with the integral term set
[00:57:46.920 --> 00:57:52.320]   initially to zero, and one of them was brevide1. So let's just
[00:57:52.320 --> 00:57:57.160]   apply this little function on the pressure of brevide1. And
[00:57:57.160 --> 00:58:01.760]   what we see is this kind of match. So, and blue is the
[00:58:01.760 --> 00:58:06.600]   original U-in, and in orange is the U-in hat. And we see very
[00:58:06.600 --> 00:58:10.640]   good matches, except for the first value, and these values in
[00:58:10.640 --> 00:58:13.320]   the end. These values in the end is just because of the
[00:58:13.320 --> 00:58:16.800]   expiratory phase that has already started. So we're not
[00:58:16.800 --> 00:58:19.960]   very interested in that. And then these first values, well,
[00:58:19.960 --> 00:58:22.920]   that's something we haven't been able to crack. We believe that
[00:58:22.920 --> 00:58:26.560]   this is just noise or random. So they, the first value was always
[00:58:26.560 --> 00:58:31.080]   random. And from there on, it wasn't that random anymore.
[00:58:31.600 --> 00:58:32.000]   Makes sense.
[00:58:32.000 --> 00:58:38.640]   So this, yeah, so this matching algorithm, yeah, it's really
[00:58:38.640 --> 00:58:42.800]   nice. But again, it takes us input the pressure. And so we
[00:58:42.800 --> 00:58:47.240]   kind of need to revert all of the logics again. And one very
[00:58:47.240 --> 00:58:53.400]   pesky thing about this function is this kind of integral term
[00:58:53.400 --> 00:58:58.160]   that is calculated in a for loop. So you basically need all
[00:58:58.160 --> 00:59:03.120]   32 values, or you need to try 32 values, see if this for loop
[00:59:03.120 --> 00:59:07.200]   calculates exactly to all of your U-ins. So that's a big
[00:59:07.200 --> 00:59:12.360]   problem. But luckily, we are able to isolate this integral
[00:59:12.360 --> 00:59:17.360]   term. So if we take a look at how the equation looks like,
[00:59:17.360 --> 00:59:20.920]   this is again, just a simple equation we started with, I just
[00:59:20.920 --> 00:59:24.680]   replaced like this summation of epsilons by just the letter I.
[00:59:25.040 --> 00:59:29.040]   So we have a proportional term plus an integral term, and they
[00:59:29.040 --> 00:59:32.840]   are multiplied by their weights. Well, we can again, rework this
[00:59:32.840 --> 00:59:38.080]   equation to be in function of the integral term. And just like
[00:59:38.080 --> 00:59:43.200]   that, we are able to calculate the integral term for any point
[00:59:43.200 --> 00:59:48.960]   in time. And so let's get into the matching algorithm. So what
[00:59:48.960 --> 00:59:50.000]   we did is basically...
[00:59:50.000 --> 00:59:53.440]   I would, sorry, sorry to keep interrupting you, I would just
[00:59:53.440 --> 00:59:56.240]   interrupt to remind the audience, I've gone through this
[00:59:56.240 --> 00:59:59.880]   notebook a few times before this interview, which is why I'm able
[00:59:59.880 --> 01:00:03.240]   to understand it so fast. If you're watching it live, please
[01:00:03.240 --> 01:00:05.840]   pause it if you don't understand it, because personally, I'm
[01:00:05.840 --> 01:00:09.240]   really slow at math. So it took me a few passes. If you don't
[01:00:09.240 --> 01:00:12.800]   understand it, I would encourage you to pause the video, go back,
[01:00:12.800 --> 01:00:15.320]   play it again, even if you're watching that you can pause and
[01:00:15.320 --> 01:00:19.280]   replay it. Or if you go to the notebook, it really clarifies a
[01:00:19.280 --> 01:00:21.960]   lot of things. So if you if you feel like all of this math
[01:00:22.000 --> 01:00:25.960]   jargon isn't clear to you, maybe it's just me, but for me, it
[01:00:25.960 --> 01:00:29.200]   took a few passes. So you're not the only one if that's for you.
[01:00:29.200 --> 01:00:32.880]   Yeah, I can definitely understand that for sure. It can
[01:00:32.880 --> 01:00:36.360]   indeed maybe be a bit overwhelming. So Siam's advice
[01:00:36.360 --> 01:00:40.360]   is great. Take a piece of paper and rework those equations.
[01:00:40.360 --> 01:00:44.360]   You'll see it is basically high school math. There's no real
[01:00:44.360 --> 01:00:47.080]   integrals in there. We're not analytically calculating
[01:00:47.080 --> 01:00:52.560]   integrals in here or something like that. So you just need that
[01:00:52.560 --> 01:00:55.280]   piece of paper. I can imagine it's very overwhelming here at
[01:00:55.280 --> 01:00:59.640]   the start. And also it often helps to just really analyze
[01:00:59.640 --> 01:01:03.000]   this simple function because this is the bread and butter of
[01:01:03.000 --> 01:01:06.640]   our entire solution. And if you can really understand this one
[01:01:06.640 --> 01:01:09.680]   well, you'll probably have a better understanding of how we
[01:01:09.680 --> 01:01:11.720]   derived all these equations as well.
[01:01:11.720 --> 01:01:16.040]   So you just going to talk about the algorithm?
[01:01:16.040 --> 01:01:22.960]   Yeah, exactly. So yeah, we basically came to a whole lot of
[01:01:22.960 --> 01:01:26.720]   equations, we mathematically derive them. And so what we now
[01:01:26.720 --> 01:01:31.600]   do is, well, we have equations and they are in function of two
[01:01:31.600 --> 01:01:36.640]   pressure values, the P0 and the P0, P0, sorry, that's the
[01:01:36.640 --> 01:01:42.480]   English thing, and P1. And so what we will do is we basically
[01:01:42.480 --> 01:01:46.200]   brute force all of these possible combinations of P0 and
[01:01:46.200 --> 01:01:49.800]   P1. And when we plug them into our equations, and they
[01:01:49.800 --> 01:01:53.280]   perfectly calculated, or perfectly calculate to our new
[01:01:53.280 --> 01:01:57.680]   n values, well, then we have a match, then we know those P0 and
[01:01:57.680 --> 01:02:03.920]   P1 values have to be the ones at that time step. And so that's
[01:02:03.920 --> 01:02:07.880]   basically what we do. So we take a random P0, again, we have 950
[01:02:07.880 --> 01:02:11.680]   of them, we take a random P1, we have 950 of those. So we already
[01:02:11.680 --> 01:02:19.280]   have 950 times 950 combinations. We also take three or we take
[01:02:19.280 --> 01:02:22.880]   possible parameter values, we have one extra parameter in the
[01:02:22.880 --> 01:02:27.080]   P controller, we had our target and the alpha here, the beta is
[01:02:27.080 --> 01:02:30.240]   here as well, which is the weight of the integral term. And
[01:02:30.240 --> 01:02:33.680]   the beta term, I didn't mention that can take the same values as
[01:02:33.680 --> 01:02:37.640]   the alpha term. So it's a 20 possible values for the beta as
[01:02:37.640 --> 01:02:41.040]   well. That can also be derived from the paper, I haven't thought
[01:02:41.040 --> 01:02:44.160]   about how you would find them actually on yourself. But again,
[01:02:44.160 --> 01:02:46.920]   they were on the paper. So it's not something to really think
[01:02:46.920 --> 01:02:54.160]   about. So yeah, that gives us another 2400 combinations. So
[01:02:54.160 --> 01:02:57.800]   you can actually multiply that with the 950 times 950. And
[01:02:57.800 --> 01:03:02.160]   that's the amount of possible or grid search we are doing here.
[01:03:02.160 --> 01:03:05.880]   So yeah, I can't say the number, it's it's a big number, that's
[01:03:05.880 --> 01:03:11.880]   for sure. And so here are the equations I spoke about. So we
[01:03:11.880 --> 01:03:17.080]   plug in or P zero, which you can see right here to calculate this
[01:03:17.080 --> 01:03:21.240]   integral term at time step t. And because we don't want to
[01:03:21.240 --> 01:03:24.160]   propagate our integral term from the start of the signal, we
[01:03:24.160 --> 01:03:28.960]   really want to calculate it at any point in time. And once we
[01:03:28.960 --> 01:03:34.480]   have isolated this integral term, we can calculate the next
[01:03:34.480 --> 01:03:40.080]   integral term, which will be based on the previous integral
[01:03:40.080 --> 01:03:44.720]   term. So this is where the P1 comes into place. So this is the
[01:03:44.720 --> 01:03:48.520]   target minus the P1 minus the integral. That's how this
[01:03:48.520 --> 01:03:53.840]   weighted decay formula works. So here's another P1. But so these
[01:03:53.840 --> 01:03:57.400]   are just the four or three equations because this is just a
[01:03:57.400 --> 01:04:01.480]   derivative of your inputs. It's the depth of your time steps. So
[01:04:01.480 --> 01:04:06.000]   these three equations, if they perfectly align, so if your u in
[01:04:06.000 --> 01:04:10.160]   hat corresponds to your u in, you have a match, then you know
[01:04:10.160 --> 01:04:14.680]   P1. Well, P0 is actually a risky one. I'll get into that later.
[01:04:14.680 --> 01:04:19.960]   But P1 for sure is a good match. P0 is in 90% of the cases also
[01:04:19.960 --> 01:04:23.360]   a good match. But since we're doing this for any time step in
[01:04:23.360 --> 01:04:26.800]   the breath anyway, you can just remove the P0s and just keep the
[01:04:26.800 --> 01:04:30.240]   P1s as soon as you find a match. And like that you can kind of
[01:04:30.240 --> 01:04:31.640]   match the entire breath.
[01:04:31.640 --> 01:04:32.600]   Makes sense.
[01:04:32.600 --> 01:04:38.320]   And so here we will do this for one specific time step. And we
[01:04:38.320 --> 01:04:41.960]   will already fix the parameters. We knew them because we already
[01:04:41.960 --> 01:04:44.880]   did the entire grid search. But so we'll get into some
[01:04:44.880 --> 01:04:47.920]   optimization as well first because you can't run this code.
[01:04:47.920 --> 01:04:54.400]   It's like I said, 2,400 by 950 times 950. So yeah, it's a big,
[01:04:54.400 --> 01:04:58.000]   big number. And you have 70,000 breaths. So you can throw that
[01:04:58.000 --> 01:05:02.600]   into a multiplication as well. So yeah, it's a lot and the time
[01:05:02.600 --> 01:05:07.840]   steps another 30. But let's just focus on one time step and
[01:05:07.840 --> 01:05:10.840]   already fixed parameters. And let's already see how long it
[01:05:10.840 --> 01:05:15.400]   takes to just brute force or two pressure values. So 950 times
[01:05:15.400 --> 01:05:20.480]   950. And as you can see, if you brute force this, this is
[01:05:20.480 --> 01:05:24.840]   basically the algorithm I just discussed. Then we find a match
[01:05:24.880 --> 01:05:28.440]   after about three seconds. So you have to multiply this by
[01:05:28.440 --> 01:05:34.560]   2400. And the time steps and so on to do it on one breath. And
[01:05:34.560 --> 01:05:41.000]   that's way too much. But as one could notice is if you just put
[01:05:41.000 --> 01:05:44.960]   a print in this function, and you print basically this error
[01:05:44.960 --> 01:05:47.800]   that we're calculating, so the absolute value between your
[01:05:47.800 --> 01:05:51.360]   prediction and the actual you in, then you will see that this
[01:05:51.400 --> 01:05:56.880]   error grows linearly linearly in function of the inner for loop.
[01:05:56.880 --> 01:06:00.960]   So you will see that the differences between the prints
[01:06:00.960 --> 01:06:05.760]   is always equal if you subtract the one print minus its previous
[01:06:05.760 --> 01:06:09.400]   print, that will always give you the same value. So it's a linear
[01:06:09.400 --> 01:06:17.520]   line that is growing. And so when do we find a match? Well,
[01:06:17.520 --> 01:06:21.360]   that is indeed when this for a specific p1 value, this
[01:06:21.360 --> 01:06:26.360]   evaluates to something close to zero. But if we draw this out as
[01:06:26.360 --> 01:06:30.480]   a linear line, maybe I have this actually in a very nice plot,
[01:06:30.480 --> 01:06:34.480]   that we can actually find the intersection at zero. So for
[01:06:34.480 --> 01:06:40.360]   what p1 value, would I get a zero error, so we can calculate
[01:06:40.360 --> 01:06:43.760]   this intersection. And so what we want is that this
[01:06:43.760 --> 01:06:47.680]   intersection occurs at an integer, because then it again
[01:06:47.680 --> 01:06:50.840]   would have happened in an iteration of the for loop, if it
[01:06:50.840 --> 01:06:55.480]   would be like this on the right, when 210.5, they would have
[01:06:55.480 --> 01:07:00.640]   happened in between the 210th and 211th iteration, so we would
[01:07:00.640 --> 01:07:04.200]   never have the match, we wouldn't be able to see it. So
[01:07:04.200 --> 01:07:08.640]   this is basically the first optimization, instead of rolling
[01:07:08.640 --> 01:07:13.800]   out this inner for loop across 950 values, you just calculate
[01:07:13.800 --> 01:07:18.200]   the first two values, and then you draw a linear line. And
[01:07:18.200 --> 01:07:23.120]   across those two values, you calculate the intersection and
[01:07:23.120 --> 01:07:28.320]   with the x axis. And then from there on, you check if it's an
[01:07:28.320 --> 01:07:32.600]   integer. So that speeds it up by a factor of 950 already,
[01:07:32.600 --> 01:07:37.680]   because that inner for loop has just been thrown away. So if we
[01:07:37.680 --> 01:07:41.080]   time this, we go from three seconds to 10 milliseconds
[01:07:41.080 --> 01:07:45.720]   already. So that's already pretty nice. Another thing is
[01:07:45.720 --> 01:07:52.600]   that we are constantly isolating this integral terms, but
[01:07:52.600 --> 01:07:55.960]   actually, once we calculated it once, and we have it correctly,
[01:07:55.960 --> 01:08:00.000]   we can do the propagation. And so that's another possible
[01:08:00.000 --> 01:08:03.200]   optimization that is done here. Basically, if you already have a
[01:08:03.200 --> 01:08:07.320]   prediction in the previous time step of a match, well, then
[01:08:07.320 --> 01:08:10.720]   don't try to brute force this previous pressure, because it's
[01:08:10.720 --> 01:08:14.040]   already known we have that match, just fill it in. So
[01:08:14.040 --> 01:08:19.560]   that's a 950 to the power of two optimization, if you do this,
[01:08:19.560 --> 01:08:24.000]   that's already a million times faster, roughly. So that's quite
[01:08:24.000 --> 01:08:30.560]   significant. So this entire match, matching goes in about a
[01:08:30.560 --> 01:08:33.920]   millisecond now for an entire breath and for all of the time
[01:08:33.920 --> 01:08:37.360]   steps with and that's important with the parameters already
[01:08:37.360 --> 01:08:42.000]   filled in. So you basically have to multiply this again by 2400
[01:08:42.000 --> 01:08:45.880]   to do the grid search, but that's only 2.4 seconds. That's
[01:08:45.880 --> 01:08:50.440]   quite acceptable. And you can multi process this stuff. So
[01:08:50.440 --> 01:08:54.720]   that's basically the order of magnitude where our code was
[01:08:54.720 --> 01:09:00.560]   during the competition. Okay, and so here is basically the
[01:09:00.560 --> 01:09:03.160]   output of our matching algorithm. So in blue are the
[01:09:03.160 --> 01:09:06.600]   actual pressure and in orange are matches. And as you can see,
[01:09:06.600 --> 01:09:10.880]   we are not able to match the first value that will almost
[01:09:10.880 --> 01:09:13.880]   always be the case. But that's a detail we found some graphs
[01:09:13.880 --> 01:09:17.040]   where we were able to match this first value as well. But we're
[01:09:17.040 --> 01:09:20.880]   not even sure as to how we were able to match those. And then
[01:09:20.880 --> 01:09:24.200]   here, it stops matching as well. But this this is the expiratory
[01:09:24.200 --> 01:09:28.920]   phase. So we're not really interested in this. And again,
[01:09:28.920 --> 01:09:32.960]   that also makes sense. Because when you're expiring, expiring
[01:09:32.960 --> 01:09:36.480]   air, usually you really don't need the ventilator for that you
[01:09:36.480 --> 01:09:39.320]   need the ventilator just to pump air into the lungs.
[01:09:39.320 --> 01:09:45.200]   Yeah, indeed, I think you can only but maybe I'm wrong here.
[01:09:45.200 --> 01:09:47.960]   I'm not an expert in this, but you can only lower the pressure
[01:09:47.960 --> 01:09:51.840]   right by expiring your breath, you can't really increase it. So
[01:09:51.840 --> 01:09:55.360]   there's not much value of a model predicting pressure there.
[01:09:55.360 --> 01:09:58.320]   It's only when you're really pumping in air that you can like
[01:09:58.320 --> 01:10:02.040]   increase the pressure too much and that could like explode or
[01:10:02.040 --> 01:10:05.040]   implode the lung maybe. So that's where it's really
[01:10:05.040 --> 01:10:08.600]   important to like have a control system on top of it.
[01:10:08.600 --> 01:10:10.680]   Yeah, that that was my thought as well.
[01:10:10.680 --> 01:10:17.520]   Okay, yeah. So yeah, or error is basically zero. And we were able
[01:10:17.520 --> 01:10:22.240]   to match 29 of the values in this breath. And so one very
[01:10:22.240 --> 01:10:25.400]   corner case of this, let me check the time actually. Well,
[01:10:25.400 --> 01:10:28.640]   well, let me just quickly briefly go over this because I
[01:10:28.640 --> 01:10:31.200]   see where that I've been talking for quite some time already.
[01:10:31.400 --> 01:10:32.320]   And it's when this
[01:10:32.320 --> 01:10:35.840]   please, please feel free to continue on. But I also want to
[01:10:35.840 --> 01:10:37.200]   be respectful of your time. So
[01:10:37.200 --> 01:10:43.600]   no worries. Yeah. And so there are some corner cases this I
[01:10:43.600 --> 01:10:49.680]   showed the grid of alpha. Let me quickly show it again. It's
[01:10:49.680 --> 01:10:54.320]   quite far up. Here it is. It's the same for beta. But so the
[01:10:54.320 --> 01:10:59.560]   corner case is when this alpha value takes up the value zero.
[01:10:59.680 --> 01:11:02.960]   So that's a very specific case, the proportional term of our
[01:11:02.960 --> 01:11:07.160]   model would be discarded or cancelled out. And so that gave
[01:11:07.160 --> 01:11:13.600]   us gave us some numerical issues. I only briefly let me go
[01:11:13.600 --> 01:11:17.120]   to the Yeah, I only briefly discuss why it happened. So I
[01:11:17.120 --> 01:11:21.680]   explain here why these issues arise. But basically, in a
[01:11:21.680 --> 01:11:26.920]   nutshell, for any possible P no, so all of the 950 and the
[01:11:26.920 --> 01:11:30.800]   correct P one, we would be able to find the match. So this P no
[01:11:30.800 --> 01:11:33.920]   can take any of the possible values and the matching will
[01:11:33.920 --> 01:11:37.160]   still work somehow. But of course, this P zero isn't the
[01:11:37.160 --> 01:11:41.680]   correct one. It's, it's an arbitrary one. So that's
[01:11:41.680 --> 01:11:45.080]   basically the issue we had. And I demonstrate that here. So you
[01:11:45.080 --> 01:11:47.600]   see these three points, they look like they're zero, but
[01:11:47.600 --> 01:11:50.400]   they're not zero, they're the minimal pressure value, they're
[01:11:50.400 --> 01:11:54.960]   minus one and a bit. And so yeah, it's basically because it
[01:11:54.960 --> 01:11:57.920]   was the first iteration of that for loop. And as I said, the
[01:11:57.920 --> 01:12:01.560]   matches arbitrary, so it found a match there, it fills it in, but
[01:12:01.560 --> 01:12:05.160]   it's definitely far from correct, as you can see. So if
[01:12:05.160 --> 01:12:09.600]   you would deploy this model from the previous section, as is to
[01:12:09.600 --> 01:12:12.200]   the data, you would have some graphs in there with a mean
[01:12:12.200 --> 01:12:15.720]   absolute error of more than five. And that's, that's huge.
[01:12:15.720 --> 01:12:20.520]   That's huge on the leaderboard, we were working on 0.1 level. So
[01:12:20.520 --> 01:12:24.720]   you don't want these kind of errors in there. And we were
[01:12:24.720 --> 01:12:29.000]   never able to crack this fully as well. Maybe just a small note
[01:12:29.000 --> 01:12:32.280]   here is we were never able to fully crack the puzzle. So if
[01:12:32.280 --> 01:12:36.600]   someone is able to improve upon this matching algorithm, or find
[01:12:36.600 --> 01:12:39.640]   some further insights, I would be very, very interested in
[01:12:39.640 --> 01:12:43.880]   hearing them. So we believe that there is much, much more to
[01:12:43.880 --> 01:12:48.040]   match and that an error close to zero could possibly be achieved.
[01:12:48.040 --> 01:12:52.560]   So if anyone feels like going for that, and is able to do
[01:12:52.560 --> 01:12:55.280]   achieve that, I would be very interested in in hearing that.
[01:12:55.280 --> 01:13:00.400]   But we went for the quick and dirty solution. So as soon as
[01:13:00.400 --> 01:13:08.360]   we found KP zeros, we would basically clip or reset or not
[01:13:08.360 --> 01:13:11.840]   match all of the values at the start of a sequence. So we
[01:13:11.840 --> 01:13:16.760]   would just unmatch all of these bad ones basically, and leave
[01:13:16.760 --> 01:13:20.840]   them or leave the matching away, we wouldn't try it even. So
[01:13:20.840 --> 01:13:23.600]   that's what we did there. It's quick and dirty. So that's one
[01:13:23.600 --> 01:13:26.680]   possible improvement already, you can actually try and match
[01:13:26.680 --> 01:13:31.160]   those. And then in the end, we also removed some noise, I'll
[01:13:31.160 --> 01:13:35.240]   quickly just show how the noise looks like. But it was actually
[01:13:35.240 --> 01:13:38.360]   discussed in the paper. Sorry, I'm hopping from one link to the
[01:13:38.360 --> 01:13:42.960]   other here. But I'll zoom into this paper here. And that was
[01:13:42.960 --> 01:13:46.880]   what it gave us like the remaining 6%. It's section 4.2.
[01:13:46.880 --> 01:13:49.520]   Sorry. Yeah, here it is.
[01:13:49.520 --> 01:13:54.280]   So they discussed two kinds of noise that they add to the data.
[01:13:54.280 --> 01:13:58.160]   They add boundary exploration, but that's basically a linear
[01:13:58.160 --> 01:14:01.920]   line added to the very beginning of the inhalation. So from
[01:14:01.920 --> 01:14:06.120]   timestamp zero, up until some timestamp, this timestamp was
[01:14:06.120 --> 01:14:09.960]   random and was in between these two values, they are in the
[01:14:09.960 --> 01:14:13.000]   appendix, if you want the actual numbers. And then the other one
[01:14:13.000 --> 01:14:16.760]   is the triangular noise. So they would add triangles. So this
[01:14:16.760 --> 01:14:20.520]   could be this triangle or such a triangle, they would add that
[01:14:20.520 --> 01:14:25.960]   to the UIN. And so we were able to actually match data with that
[01:14:25.960 --> 01:14:30.920]   noise in there as well. And so we reuse the generate UIN
[01:14:30.920 --> 01:14:34.440]   function I quickly discussed, or briefly discussed before where
[01:14:34.440 --> 01:14:37.720]   we could plug in the pressure value and get the actual UIN
[01:14:37.720 --> 01:14:42.800]   values. And so what we did is we plug in our pressure values, we
[01:14:42.800 --> 01:14:46.080]   subtract that from the UIN values that we are given. And
[01:14:46.080 --> 01:14:50.560]   what we are given or left over with is this kind of noise. And
[01:14:50.560 --> 01:14:53.680]   so as you can see, the noise is close to zero for most of the
[01:14:53.680 --> 01:14:57.640]   time steps. But for some time steps, we can see this triangle
[01:14:57.640 --> 01:15:01.400]   popping up here. And so it's not a perfect triangle. That's
[01:15:01.400 --> 01:15:04.800]   something that still puzzles us as of today as well. So like
[01:15:04.800 --> 01:15:09.480]   here, this is kind of weird. It's not a nice triangle, as you
[01:15:09.480 --> 01:15:13.960]   would expect. But on the edges of the triangle, it really fits
[01:15:13.960 --> 01:15:17.960]   the property of a triangle, it's on a straight line, or the slope
[01:15:17.960 --> 01:15:21.040]   is the same between consecutive values. And so you can really
[01:15:21.040 --> 01:15:24.400]   see that here I calculate the slope, and you can see they are
[01:15:24.400 --> 01:15:28.560]   exactly the same. And that's the key insight we were able to use
[01:15:28.560 --> 01:15:31.960]   to kind of match the data. I will not go over how we did it,
[01:15:31.960 --> 01:15:35.640]   but I will show the impact of it. So oh, I accidentally pressed
[01:15:35.640 --> 01:15:41.320]   the button of my mouse. This was, this was sorry, this was
[01:15:41.320 --> 01:15:44.840]   one of the breaths with noise in there. And this is the output of
[01:15:44.840 --> 01:15:47.480]   the algorithm I discussed up until that point in the
[01:15:47.480 --> 01:15:50.280]   notebook. And so you could see here in the middle, there's a
[01:15:50.280 --> 01:15:55.960]   some values unmatched. And so we wrote two parts of the code one
[01:15:55.960 --> 01:16:00.640]   to do the first half of the triangle and another part to do
[01:16:00.640 --> 01:16:03.840]   the second half of the triangle, one went forward and the other
[01:16:03.840 --> 01:16:07.800]   one went backwards. And so with the forward matching algorithm,
[01:16:07.960 --> 01:16:11.600]   this is the same breath, we had nine unmatched values before.
[01:16:11.600 --> 01:16:14.640]   Now we have only six unmatched values here in the middle,
[01:16:14.640 --> 01:16:17.680]   because of that forward matching algorithm. And then with the
[01:16:17.680 --> 01:16:20.560]   backward matching algorithm added on top of it, it's
[01:16:20.560 --> 01:16:23.440]   discussed here. And it's quite a bit of code, which is why I'm
[01:16:23.440 --> 01:16:26.720]   kind of skipping it. So now, you can really see that we were able
[01:16:26.720 --> 01:16:30.200]   to match almost all of it. And so these two points are just
[01:16:30.200 --> 01:16:33.760]   where I showed that the triangle is really doing weird stuff. And
[01:16:33.760 --> 01:16:37.560]   that's where we're still not able to match it. And so I also
[01:16:37.560 --> 01:16:41.320]   just want to point out to the audience, this is like very
[01:16:41.320 --> 01:16:44.760]   readable code, if at least in the world of Kaggle kernels.
[01:16:44.760 --> 01:16:49.080]   This is very readable. So even though we're rushing through it,
[01:16:49.080 --> 01:16:51.760]   that's because I also want to respect Jill's time, this was a
[01:16:51.760 --> 01:16:55.200]   90 minute session, if you literally read through every
[01:16:55.200 --> 01:16:59.040]   single cell, to me, like I was able to understand this. So I'm
[01:16:59.040 --> 01:17:02.680]   sure anyone from the audience can understand this. Sorry,
[01:17:02.680 --> 01:17:03.600]   sorry, please continue.
[01:17:03.600 --> 01:17:06.320]   No worries. It's a great suggestion again. And so like a
[01:17:06.320 --> 01:17:09.120]   nice thing about Kaggle here as well is that there is this
[01:17:09.120 --> 01:17:12.200]   comments section as well in this notebook, and I do closely
[01:17:12.200 --> 01:17:15.680]   follow this. So if there's anything unclear, or you want
[01:17:15.680 --> 01:17:19.960]   more explanation about why I wrote this certain line of code,
[01:17:19.960 --> 01:17:23.360]   please feel free, don't even hesitate to leave a comment, and
[01:17:23.360 --> 01:17:27.040]   I'll gladly clear it up for you. Great pleasure. Thank you.
[01:17:27.040 --> 01:17:32.120]   Yeah, and I think that kind of wraps it up. So with all of
[01:17:32.120 --> 01:17:36.280]   these insights combined, we were able to match like 66% of the
[01:17:36.280 --> 01:17:41.240]   data. And so we I think we had like a model that scored close
[01:17:41.240 --> 01:17:47.080]   to like 0.15 on the leaderboard. And so we were able to almost
[01:17:47.080 --> 01:17:50.320]   perfectly match there were some errors in there, but two thirds
[01:17:50.320 --> 01:17:55.640]   of that data and so whatever was reduced to 0.05, roughly. And
[01:17:55.640 --> 01:17:58.080]   there were only two teams that were able to do this, which
[01:17:58.080 --> 01:18:02.880]   explains the big, big gap in between numbers one and two and
[01:18:02.880 --> 01:18:05.960]   the others and even a bigger gap in between number one and two.
[01:18:05.960 --> 01:18:08.360]   And that's because because we discussed this after the
[01:18:08.360 --> 01:18:12.560]   competition with Dombros, the number two, and he didn't try to
[01:18:12.560 --> 01:18:16.240]   match this noise. And so this noise matching gave us the edge
[01:18:16.240 --> 01:18:20.440]   on the number two. And I think that kind of wraps it up. So
[01:18:20.440 --> 01:18:24.320]   maybe just a small disclaimer, like this notebook is readable
[01:18:24.320 --> 01:18:27.960]   code and kind of well, I tried to make it as readable as
[01:18:27.960 --> 01:18:31.240]   possible, at least. And it explains the concepts very well,
[01:18:31.240 --> 01:18:34.000]   but it won't be able to fully reproduce what we have done. If
[01:18:34.000 --> 01:18:37.400]   you want to do that, then you will have to work with this
[01:18:37.400 --> 01:18:41.960]   monstrosity of code that is available in the GitHub repo.
[01:18:41.960 --> 01:18:45.240]   But like I said, this is hacked together and added on top of
[01:18:45.240 --> 01:18:47.880]   each other during the competition. I guess you know
[01:18:47.880 --> 01:18:51.720]   how it goes sometimes. And so this will fully reproduce our
[01:18:51.720 --> 01:18:55.640]   solution. But I wouldn't advise anyone it will hurt your sanity
[01:18:55.640 --> 01:18:58.880]   a lot, I believe, to read this code, I would just go for the
[01:18:58.880 --> 01:19:01.880]   notebook and get the concepts from there if you want to ever
[01:19:01.880 --> 01:19:05.640]   try to reproduce this. I will that I'll wrap it up and stop
[01:19:05.640 --> 01:19:06.600]   sharing my screen.
[01:19:06.600 --> 01:19:11.080]   Thank you. Thank you. This is really helpful. And also just to
[01:19:11.080 --> 01:19:14.360]   point out, I was going to the other repositories and those are
[01:19:14.360 --> 01:19:17.680]   those are models that were cleverly engineered, but those
[01:19:17.680 --> 01:19:21.440]   are easy to somewhat wrap your head around. This was really
[01:19:21.440 --> 01:19:25.640]   helpful to understand how did you reverse engineer the PID to
[01:19:25.640 --> 01:19:30.280]   some extent. I know there was a debate on Kaggle about this in
[01:19:30.280 --> 01:19:34.680]   the Kaggle circles, but I think it was really innovative. I just
[01:19:34.680 --> 01:19:37.880]   interviewed the fifth position team and they also agreed this
[01:19:37.880 --> 01:19:39.600]   was really, really innovative.
[01:19:39.600 --> 01:19:44.320]   Yeah, I agree. It's definitely a bit cheeky. What we did, it's
[01:19:44.320 --> 01:19:48.720]   indeed reverse engineering. And indeed, that probably defeats a
[01:19:48.720 --> 01:19:51.480]   bit the usefulness of our solution to be applied to the
[01:19:51.480 --> 01:19:55.520]   real world. But the mistake is more in the data generating
[01:19:55.520 --> 01:19:58.520]   process here, right? I don't think this any of the models
[01:19:58.600 --> 01:20:01.600]   would have been able to apply to the real world because they were
[01:20:01.600 --> 01:20:05.120]   governed by this PID controller. If you take the PID controller
[01:20:05.120 --> 01:20:08.360]   away from the lung, I don't know what would happen to the models
[01:20:08.360 --> 01:20:11.280]   that were trained in this Kaggle competition. And there were some
[01:20:11.280 --> 01:20:16.520]   flaws to it. Fundamentally, I believe, like the fact that it
[01:20:16.520 --> 01:20:19.480]   was not a time series or code competition, and we were given
[01:20:19.480 --> 01:20:24.400]   full breaths and people were actually using information from
[01:20:24.400 --> 01:20:28.360]   the future to predict the current pressure, kind of already
[01:20:28.360 --> 01:20:31.440]   defeats the purpose of a real time controller, right? If it
[01:20:31.440 --> 01:20:35.720]   has to wait two seconds in order to do something, it could already
[01:20:35.720 --> 01:20:36.840]   go very, very wrong.
[01:20:36.840 --> 01:20:37.960]   That could be fatal.
[01:20:37.960 --> 01:20:42.560]   And yeah, maybe a small note is like the typical way to achieve
[01:20:42.560 --> 01:20:45.800]   this is indeed thinking about this data generating process.
[01:20:45.800 --> 01:20:49.480]   And that's what Bayesian people do all the time, they will first
[01:20:49.480 --> 01:20:52.200]   think of a data generating process and what are the
[01:20:52.200 --> 01:20:55.600]   distributions underlying this data, and then they'll try
[01:20:55.600 --> 01:20:59.200]   fitting the parameters to that equation. So it's just another
[01:20:59.200 --> 01:21:01.440]   way of thinking about the data. I'm not gonna say I'm not
[01:21:01.440 --> 01:21:06.240]   Bayesian at all, but it is one way to think about it.
[01:21:06.240 --> 01:21:11.200]   This is incredible to learn. And also, I think the fifth
[01:21:11.200 --> 01:21:14.040]   position team had this incredible transformer model.
[01:21:14.040 --> 01:21:16.320]   Yeah, I watched it this morning.
[01:21:16.320 --> 01:21:20.240]   Thanks. Thanks for joining. And it was also really fascinating
[01:21:20.240 --> 01:21:23.400]   to learn about how you can fit a transformer model on such a
[01:21:23.400 --> 01:21:26.680]   tabular and time series problem. Listening to you right now, I'm
[01:21:26.680 --> 01:21:31.360]   thinking maybe, maybe like because they created a 128 head
[01:21:31.360 --> 01:21:34.560]   transformer model, and that's like multitudes larger than
[01:21:34.560 --> 01:21:37.720]   what, maybe that was just learning the PID values
[01:21:37.720 --> 01:21:40.720]   internally somewhere in the way it's, it's hard to interpret,
[01:21:40.720 --> 01:21:44.040]   but that could have been a possibility as well.
[01:21:44.040 --> 01:21:48.680]   Yeah, because and I believe that's why the expiratory phase
[01:21:48.680 --> 01:21:52.360]   and all of the breadth, all the information was so important to
[01:21:52.360 --> 01:21:55.120]   predict one single time step. Because if you look at the
[01:21:55.120 --> 01:21:58.520]   global shape of the breadth, so the entire breadth, you can kind
[01:21:58.520 --> 01:22:02.680]   of see what the PID parameters are. I mean, just based on what
[01:22:02.680 --> 01:22:07.640]   values these U-ins go in, you can kind of derive the set
[01:22:07.640 --> 01:22:12.640]   point from that. If you see many waves in the U-in, that means
[01:22:12.640 --> 01:22:15.560]   the integral term was really high there. If it's more of a
[01:22:15.560 --> 01:22:19.320]   flat line, there was no integral term. So yeah, I think most of
[01:22:19.320 --> 01:22:23.320]   the models implicitly picked up on this PID controllers. Many of
[01:22:23.320 --> 01:22:25.960]   the top solutions did multi-target learning, it was
[01:22:25.960 --> 01:22:28.800]   discussed briefly this morning as well. But so what helped
[01:22:28.800 --> 01:22:32.680]   really well, apparently was just instead of only predicting
[01:22:32.680 --> 01:22:37.080]   pressure, also try to predict the cumulative sum of the
[01:22:37.080 --> 01:22:39.840]   pressure. And that's, that's just the integral term, right?
[01:22:39.840 --> 01:22:45.080]   So by implicitly kind of incorporating these PID insights
[01:22:45.080 --> 01:22:48.960]   into the models, big achievements or boosts could
[01:22:48.960 --> 01:22:50.720]   have been gained on the leaderboards. Yeah.
[01:22:50.720 --> 01:22:55.360]   Sanyam Bhutani: Yeah, thanks. Thanks for those thoughts as
[01:22:55.360 --> 01:22:58.360]   well. I usually try to wrap up and just to be respectful of
[01:22:58.360 --> 01:23:02.920]   your time, I'll probably just ask one or two questions. This
[01:23:02.920 --> 01:23:05.280]   is a common question from all Chai time, you would know it.
[01:23:05.280 --> 01:23:08.240]   What's your best advice for someone just starting on their
[01:23:08.240 --> 01:23:09.160]   Kaggle journey?
[01:23:09.160 --> 01:23:12.720]   Martin Henzelmann: Yeah, so I maybe gave a small tip already
[01:23:12.720 --> 01:23:15.480]   in the beginning, but that's probably more relevant to if
[01:23:15.480 --> 01:23:18.920]   you like me, if you're like too competitive, and that is to not
[01:23:18.920 --> 01:23:22.960]   focus on the results, but to focus on the learning experience
[01:23:22.960 --> 01:23:25.680]   that you're going to get from it. And I can guarantee you that
[01:23:25.680 --> 01:23:28.400]   you're going to get a huge learning experience from it. And
[01:23:28.400 --> 01:23:31.280]   you can have all kinds of backgrounds and all kinds of
[01:23:31.280 --> 01:23:35.440]   experience. You'll get something from Kaggle. It's always
[01:23:35.440 --> 01:23:41.440]   learning experience. And then, yeah, maybe tips in general, it
[01:23:41.440 --> 01:23:46.200]   was, yeah, maybe try a variety of competitions in the beginning
[01:23:46.200 --> 01:23:49.560]   at first to see what your strengths are and what kind of
[01:23:49.560 --> 01:23:52.400]   data formats you really like the most. Maybe you don't like deep
[01:23:52.400 --> 01:23:55.840]   learning that much as I do. And then you can stay away from the
[01:23:55.840 --> 01:23:59.320]   computer vision and natural language competitions, or you're
[01:23:59.320 --> 01:24:03.560]   really into that stuff. And kudos if you are. And then you
[01:24:03.560 --> 01:24:06.920]   can go for these kinds of competitions, but it's hard to
[01:24:06.920 --> 01:24:10.640]   already decide in advance, just by reading some books or theory
[01:24:10.640 --> 01:24:13.480]   books like this is what I'm going to do now. Just try to get
[01:24:13.480 --> 01:24:17.000]   your hands dirty on each kind of problem, and then really decide
[01:24:17.000 --> 01:24:22.040]   what am I going to specialize in. And then once in a while, do
[01:24:22.040 --> 01:24:25.720]   go for the learning experience and take like the exotic
[01:24:25.720 --> 01:24:29.080]   competition that you wouldn't have picked otherwise.
[01:24:29.080 --> 01:24:34.920]   Since you mentioned books and courses, any favorite resource
[01:24:34.920 --> 01:24:38.360]   if you were to name just one resource where people can learn
[01:24:38.360 --> 01:24:40.960]   machine learning? What would you tell them?
[01:24:41.680 --> 01:24:45.960]   Yeah, well, it's gonna be so cliche. But yeah, Andrew Ng's
[01:24:45.960 --> 01:24:49.440]   courses are really good, because they're not that math heavy or
[01:24:49.440 --> 01:24:52.720]   theory heavy. They're a great way to get a good understanding
[01:24:52.720 --> 01:24:55.480]   of what is in there in the machine learning domain. And to
[01:24:55.480 --> 01:24:59.600]   be honest, you don't even need all of those math books today to
[01:24:59.600 --> 01:25:03.120]   start on Kaggle, because everything is implemented in
[01:25:03.120 --> 01:25:07.320]   nice and easy to use libraries today. Scikit-learns and all of
[01:25:07.320 --> 01:25:10.600]   the other libraries make your life a lot easier. I'm not
[01:25:10.600 --> 01:25:13.600]   saying that you will never have to read a book. But just to get
[01:25:13.600 --> 01:25:17.600]   started with Kaggle, you don't have to study all of the books
[01:25:17.600 --> 01:25:20.480]   that are out there, you can already start today and read
[01:25:20.480 --> 01:25:24.000]   some books on the site. But I always say if it comes to
[01:25:24.000 --> 01:25:27.000]   computer science, there's only so much that you can learn from
[01:25:27.000 --> 01:25:29.960]   a book. And that applies for everything. If you're starting
[01:25:29.960 --> 01:25:33.800]   to code, well, reading a book won't help you much, you need to
[01:25:33.800 --> 01:25:36.760]   actually code the stuff and that will be the greatest learning
[01:25:36.760 --> 01:25:37.560]   experience.
[01:25:38.960 --> 01:25:41.520]   Or if you're like me, you put them in the background and try
[01:25:41.520 --> 01:25:44.360]   to pretend you're smart and never, never really get around
[01:25:44.360 --> 01:25:45.000]   to reading.
[01:25:45.000 --> 01:25:49.240]   Or you hope that it's somehow, I don't know, free air goes into
[01:25:49.240 --> 01:25:53.160]   your brain or something. In a subconscious level. Yeah, that's
[01:25:53.160 --> 01:25:54.600]   a possibility as well. Yeah.
[01:25:54.600 --> 01:25:59.240]   That's that's very practical advice. I don't see I don't see
[01:25:59.240 --> 01:26:02.440]   any questions from the audience. I'll give them a minute to ask
[01:26:02.440 --> 01:26:08.080]   anything. In the meantime, I'll point out Jill's Kaggle profile,
[01:26:08.160 --> 01:26:11.880]   you can find him on Kaggle. Shouldn't be too hard if you go
[01:26:11.880 --> 01:26:14.440]   to the ventilator competition. Just just look at the top of the
[01:26:14.440 --> 01:26:18.680]   leaderboard. Easy peasy. No worries. He's also on Twitter.
[01:26:18.680 --> 01:26:22.760]   I'll again post these links, but you can zoom in so that you can
[01:26:22.760 --> 01:26:29.000]   see his handle. It's G I l l e s p d w i e l e. That's his
[01:26:29.000 --> 01:26:33.120]   Twitter handle. You can find him on Twitter. He's also on
[01:26:33.120 --> 01:26:36.880]   LinkedIn. And on his Kaggle profile, you can also find his
[01:26:36.880 --> 01:26:40.280]   website. Any other links that you want to point the audience?
[01:26:40.280 --> 01:26:43.480]   No, I think you covered them all. Yeah. So I'm pretty I try
[01:26:43.480 --> 01:26:48.200]   to be quite present on social media. But those are the
[01:26:48.200 --> 01:26:51.480]   professional ones. At least. I'm on Facebook, but that's more for
[01:26:51.480 --> 01:26:55.040]   private. So yeah, you covered it. Twitter, LinkedIn, and my
[01:26:55.040 --> 01:26:59.120]   website. And of course, my Kaggle profile, the most important to
[01:26:59.120 --> 01:26:59.920]   me at least.
[01:26:59.920 --> 01:27:04.280]   Jill, I'll be I'll be really honest. This really felt like I
[01:27:04.280 --> 01:27:08.120]   was learning from another version of Chris Diot himself,
[01:27:08.120 --> 01:27:13.240]   I got the opportunity to learn him, learn from him twice. And I
[01:27:13.240 --> 01:27:16.720]   think it's, it was the same learning experience for me. So I
[01:27:16.720 --> 01:27:19.160]   speak for the audience, because I'm probably the dumbest person
[01:27:19.160 --> 01:27:23.080]   from the audience myself. But thanks for such an educational
[01:27:23.080 --> 01:27:26.400]   and such a huge compliment, actually, because Chris Diot is
[01:27:26.400 --> 01:27:29.960]   someone I really look up to. And he's one of my idols, the way he
[01:27:29.960 --> 01:27:33.560]   can explain stuff. I'm still far from that, I have to say, to be
[01:27:33.560 --> 01:27:36.520]   honest, but it's a huge compliment. So thank you for
[01:27:36.520 --> 01:27:39.840]   that. And Chris, if you're ever watching, you're the you're the
[01:27:39.840 --> 01:27:40.360]   man.
[01:27:40.360 --> 01:27:46.280]   He's he's our legend. Thanks. Thanks so much again for your
[01:27:46.280 --> 01:27:48.920]   time and for sharing your journey and your solution.
[01:27:48.920 --> 01:27:52.520]   Thank you so much for having me. So have a good one.
[01:27:52.520 --> 01:27:56.480]   Thanks, everyone for joining in the live stream here.
[01:27:56.480 --> 01:28:06.480]   [BLANK_AUDIO]

