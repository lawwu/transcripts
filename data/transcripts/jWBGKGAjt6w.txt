
[00:00:00.000 --> 00:00:02.240]   Hey friends, I'm Charles from Weights & Biases.
[00:00:02.240 --> 00:00:06.360]   In this video, I'm going to show you how to use WNB to write short reports.
[00:00:06.360 --> 00:00:11.040]   In a short report workflow, we use the Reports feature of Weights & Biases to simultaneously
[00:00:11.040 --> 00:00:15.880]   visualize the results of our experiments, draw conclusions from those results, and share
[00:00:15.880 --> 00:00:18.440]   those conclusions with our teammates.
[00:00:18.440 --> 00:00:23.120]   The WNB gallery features curated examples of reports, which read like something between
[00:00:23.120 --> 00:00:26.080]   a thorough blog post and a short paper.
[00:00:26.080 --> 00:00:30.600]   This report by WNB deep learning engineer Stacy Svetlich-Nayev is a great example of
[00:00:30.600 --> 00:00:33.920]   how to use reports to communicate polished results and complete stories.
[00:00:33.920 --> 00:00:36.360]   But reports aren't just for describing entire projects.
[00:00:36.360 --> 00:00:39.400]   They can be used for smaller, bite-sized insights too.
[00:00:39.400 --> 00:00:41.880]   The results of a single run or a single sweep.
[00:00:41.880 --> 00:00:43.760]   That's what short reports are all about.
[00:00:43.760 --> 00:00:45.540]   Let's dive in.
[00:00:45.540 --> 00:00:48.120]   With any WNB project, we start with the workspace.
[00:00:48.120 --> 00:00:50.920]   This is where the results of all of our runs get uploaded.
[00:00:50.920 --> 00:00:53.680]   I think of the workspace like I think of the Python interpreter.
[00:00:53.680 --> 00:00:57.480]   It's an active place where things can be over or rewritten at any time.
[00:00:57.480 --> 00:01:01.600]   Because it's interactive, it can also be used as a live dashboard for ML projects.
[00:01:01.600 --> 00:01:06.220]   Of course, instead of allowing you to execute code, WNB workspaces allow you to query a
[00:01:06.220 --> 00:01:09.980]   database of runs in order to visualize your experiments.
[00:01:09.980 --> 00:01:12.720]   I think of reports as being like Jupyter notebooks.
[00:01:12.720 --> 00:01:16.240]   That is, they allow me to combine the power of Markdown with an interactive kernel.
[00:01:16.240 --> 00:01:20.800]   In this case, the kernel is a WNB workspace instead of a Python interpreter.
[00:01:20.800 --> 00:01:23.920]   This is the workspace for a hyperparameter sweep.
[00:01:23.920 --> 00:01:30.360]   Every single line in this plot corresponds to a single run with some collection of hyperparameters.
[00:01:30.360 --> 00:01:33.900]   The first thing I notice is that for some collections of hyperparameters, my run is
[00:01:33.900 --> 00:01:36.560]   producing really high values of the loss.
[00:01:36.560 --> 00:01:42.200]   For other collections of hyperparameters, the runs are producing NAN and NULL values.
[00:01:42.200 --> 00:01:46.120]   I'd really like to drill down and figure out what's causing these runs to fail so that
[00:01:46.120 --> 00:01:47.120]   I can fix it.
[00:01:47.120 --> 00:01:50.800]   In order to do so, I'm going to start by taking this panel and putting it out of the
[00:01:50.800 --> 00:01:52.440]   workspace and into a report.
[00:01:52.440 --> 00:01:56.720]   I do that by clicking the drop-down menu in the top right, clicking "Add to Report"
[00:01:56.720 --> 00:01:59.120]   and creating a new report.
[00:01:59.120 --> 00:02:02.560]   Now our visualization is inside a report as a panel.
[00:02:02.560 --> 00:02:05.040]   Panels are organized into panel grids.
[00:02:05.040 --> 00:02:07.440]   Panel grids let us spatially organize our panels.
[00:02:07.440 --> 00:02:09.480]   But they aren't just for spacing.
[00:02:09.480 --> 00:02:11.760]   Panel grids are connected to run sets.
[00:02:11.760 --> 00:02:15.720]   Run sets determine which runs are visualized in the attached panels.
[00:02:15.720 --> 00:02:18.160]   Run sets are made by filtering and grouping.
[00:02:18.160 --> 00:02:23.880]   Let's make a run set by filtering to only those runs which produce NAN or NULL values.
[00:02:23.880 --> 00:02:28.200]   Right away we can see that "High Learning Rate" and "Low Batch Size" is a bad combo.
[00:02:28.200 --> 00:02:32.320]   Once we have a run set we're interested in, we should give it a descriptive name.
[00:02:32.320 --> 00:02:34.480]   Note that run sets are not static.
[00:02:34.480 --> 00:02:37.720]   As you run additional experiments, if they pass all the filters, they'll be added to
[00:02:37.720 --> 00:02:40.560]   the run set and so show up in the visualizations.
[00:02:40.560 --> 00:02:43.960]   If you don't want this behavior, simply add a filter that removes all experiments after
[00:02:43.960 --> 00:02:47.640]   a specific date, say the date that you wrote the report.
[00:02:47.640 --> 00:02:51.920]   Let's also create a run set for runs without NANs and NULLs, so that we and our readers
[00:02:51.920 --> 00:02:53.720]   can compare and contrast.
[00:02:53.720 --> 00:03:03.280]   To do this, we clone the previous run set, and then we adjust the filters.
[00:03:03.280 --> 00:03:06.900]   Let's not forget to give it a descriptive name.
[00:03:06.900 --> 00:03:12.000]   By changing which run sets are active by clicking the checkbox, we can change which runs get
[00:03:12.000 --> 00:03:16.320]   visualized in our panel grid.
[00:03:16.320 --> 00:03:19.400]   We should also add some descriptive text, so that our reader knows what our charts are
[00:03:19.400 --> 00:03:20.400]   trying to convey.
[00:03:20.400 --> 00:03:24.040]   This is also the case even if it's just a report for ourselves, because sometimes the
[00:03:24.040 --> 00:03:27.320]   most confused reader is yourself six months down the line.
[00:03:27.320 --> 00:03:31.400]   Note that this text is actually markdown, which means you can include formatting, links,
[00:03:31.400 --> 00:03:33.240]   images, things like that.
[00:03:33.240 --> 00:03:37.960]   You can also include LaTeX for typesetting math.
[00:03:37.960 --> 00:03:42.080]   We're almost ready to share our report with our friends, our team, even the whole world.
[00:03:42.080 --> 00:03:45.040]   We just need to give it a title and then save it.
[00:03:45.040 --> 00:03:49.080]   Once that's done, we can share our report with anyone we want by clicking the share
[00:03:49.080 --> 00:03:52.560]   button and creating a link.
[00:03:52.560 --> 00:03:54.760]   So that's how the short report workflow works.
[00:03:54.760 --> 00:03:58.760]   This is just one way among many to use Weights & Biases tools in ML projects.
[00:03:58.760 --> 00:04:02.680]   If you've got a workflow that you like, we'd love to hear about it in the comments.
[00:04:02.680 --> 00:04:06.560]   Short reports work best for communicating small nuggets of insight.
[00:04:06.560 --> 00:04:10.120]   Then when you have enough nuggets, you can smelt them together into an ingot, a longer
[00:04:10.120 --> 00:04:13.640]   report designed to be read by folks outside the team or even the broader public.
[00:04:13.640 --> 00:04:18.440]   If you've got a report you're proud of, contact us to be featured in our gallery.
[00:04:18.440 --> 00:04:19.960]   Until then, happy learning.
[00:04:20.960 --> 00:04:32.960]   [MUSIC]

