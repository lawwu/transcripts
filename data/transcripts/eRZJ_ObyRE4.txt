
[00:00:00.000 --> 00:00:02.000]   Freeberg, Freeberg. What's up?
[00:00:02.000 --> 00:00:05.680]   It seems like you have a piece of shit on the side of your mouth. Or is that a birthmark?
[00:00:05.680 --> 00:00:07.280]   It's a- Oh, no. That's a birthmark. Gotcha.
[00:00:07.280 --> 00:00:09.600]   Oh my god. Sorry. Sorry.
[00:00:09.600 --> 00:00:10.720]   Jesus.
[00:00:10.720 --> 00:00:12.080]   Did you record that?
[00:00:12.080 --> 00:00:13.200]   Yeah, absolutely.
[00:00:13.200 --> 00:00:13.840]   Jesus.
[00:00:13.840 --> 00:00:18.400]   Look at this guy. He takes his shirt off for one fucking selfie and now everybody
[00:00:18.400 --> 00:00:23.200]   who's fat and pale on the show, the other three of us, is gonna be ridiculed.
[00:00:23.200 --> 00:00:26.480]   I'm having steak tonight. S-T-E-A-K tonight.
[00:00:26.480 --> 00:00:32.240]   I'm lifting twice a week now. Come on, Sax. Come get some. Let's fucking go. Three, two-
[00:00:32.240 --> 00:00:35.040]   Let your winners ride.
[00:00:35.040 --> 00:00:37.920]   Rain Man, David Sax.
[00:00:37.920 --> 00:00:40.960]   I'm going all in.
[00:00:40.960 --> 00:00:41.600]   And instead-
[00:00:41.600 --> 00:00:44.800]   We open sourced it to the fans and they've just gone crazy with it.
[00:00:44.800 --> 00:00:45.360]   Love you, man.
[00:00:45.360 --> 00:00:46.960]   I'm the queen of quinoa.
[00:00:46.960 --> 00:00:49.440]   I'm going all in.
[00:00:49.440 --> 00:00:54.960]   Hey, everybody. Hey, everybody. Welcome to another episode of the All In Podcast with me again,
[00:00:54.960 --> 00:00:56.080]   the dictator,
[00:00:56.080 --> 00:00:56.480]   Hemsworth.
[00:00:56.480 --> 00:00:58.720]   Myself, Chamath Pali, Hapatia.
[00:00:58.720 --> 00:01:02.720]   Rain Man, David Sax, definitely with us. Definitely a great driver.
[00:01:02.720 --> 00:01:04.320]   His dad lets him drive in the driveway.
[00:01:04.320 --> 00:01:11.280]   And of course, everybody's favorite, the queen of quinoa, the science conductor himself,
[00:01:11.280 --> 00:01:13.920]   David Freiburg.
[00:01:13.920 --> 00:01:14.960]   Queen. Queen.
[00:01:14.960 --> 00:01:15.760]   The queen.
[00:01:15.760 --> 00:01:16.400]   Queen. Queen.
[00:01:16.400 --> 00:01:21.200]   A lot of activity online. It's been a little bit of chaos since we all got together here.
[00:01:21.200 --> 00:01:25.680]   I guess we should talk about this Apple story with
[00:01:26.080 --> 00:01:34.560]   Antonio Garcia Martinez. You may have heard that he was hired by Apple to, I guess, run their ad
[00:01:34.560 --> 00:01:39.920]   efforts. And I have a little bit of information on kind of what he was going to do there in terms
[00:01:39.920 --> 00:01:43.280]   of ads, which is really interesting. But-
[00:01:43.280 --> 00:01:44.960]   Tell us. Tell us. Tell us. Tell us.
[00:01:44.960 --> 00:01:48.080]   Okay. Well, anyway, you know how we're basically-
[00:01:48.080 --> 00:01:51.280]   Start at the beginning and assume people don't know who Antonio Garcia Martinez is.
[00:01:51.280 --> 00:01:55.920]   Okay. So Antonio Garcia Martinez was a Facebook developer. He is,
[00:01:55.920 --> 00:02:01.040]   some really smart guy who uses a lot of big words and wrote a book called Chaos Monkeys,
[00:02:01.040 --> 00:02:09.760]   which is a great book, where he takes a very Jack Kerouac kind of, you know, a lot of prose.
[00:02:09.760 --> 00:02:13.120]   And he wrote this book about his time at Facebook.
[00:02:13.120 --> 00:02:19.920]   The problem is he said some things in the book that would be five years later problematic.
[00:02:19.920 --> 00:02:25.520]   At the time, they were actually considered problematic by some folks. And in the full
[00:02:25.520 --> 00:02:34.000]   quote, maybe less problematic, but he was essentially ousted because of the following
[00:02:34.000 --> 00:02:42.240]   problematic quote. The quote is, "Most women in the Bay Area are soft and weak, cosseted and naive
[00:02:42.240 --> 00:02:46.880]   despite their claims of worldliness and generally full of shit. They have their self-regarding
[00:02:46.880 --> 00:02:55.120]   entitlement, feminism, and ceaselessly vaunt their independence. But the reality is, come the epidemic,
[00:02:55.120 --> 00:02:59.040]   plague, or foreign invasion, they become precisely the sort of useless baggage you
[00:02:59.040 --> 00:03:03.360]   trade for a box of shotgun shells or a jerry can of diesel."
[00:03:03.360 --> 00:03:08.640]   And they shorten that quote to be that most women are soft and weak
[00:03:08.640 --> 00:03:18.080]   and full of shit. So in context, in this book, he was contrasting the Bay Area women he had
[00:03:18.080 --> 00:03:24.240]   dated with the mother of his kids, who he describes as strong and tall and tough and
[00:03:24.240 --> 00:03:28.880]   amazing. But still, the quotes a little gnarly and the quote out of, you know,
[00:03:28.880 --> 00:03:32.400]   when it's out of context becomes particularly gnarly. And of course,
[00:03:32.400 --> 00:03:38.560]   this led to a petition at Apple, which then led to him being fired,
[00:03:38.560 --> 00:03:46.640]   which now is going to lead to him probably getting a $10 million settlement. Of course, there's a lot
[00:03:46.640 --> 00:03:54.080]   of hypocrisy being brought up here, because Apple has allegedly been using or Apple supply chain has
[00:03:54.080 --> 00:04:01.360]   slave labor in it from the Uyghurs and other ethnic minorities. And obviously, Apple gave Dr.
[00:04:01.360 --> 00:04:14.960]   Dre billions of dollars for beats by Dre and he has even more misogynistic series of lyrics and
[00:04:14.960 --> 00:04:21.920]   was also accused of physically assaulting I believe his wife and other people he dated.
[00:04:21.920 --> 00:04:23.040]   Who Dr. Dre?
[00:04:23.040 --> 00:04:23.840]   Dr. Dre. Yeah.
[00:04:23.840 --> 00:04:29.120]   Dr. Dre. So anyway, what do you think?
[00:04:29.120 --> 00:04:33.520]   Okay, there you go. Next story.
[00:04:33.520 --> 00:04:38.800]   No, I'm happy to jump into this. I think, Jason, I think you're you're you focus a little
[00:04:38.800 --> 00:04:43.520]   bit too much. And I saw your your pod with Zach Collius on this. A lot of good takes,
[00:04:43.520 --> 00:04:48.160]   but I think you're a little too focused on what AGM as I think it's easier to call him by his
[00:04:48.160 --> 00:04:53.600]   initials, what he did as opposed to what the employees at Apple did. And there's,
[00:04:53.600 --> 00:04:59.440]   at least four things that Apple did, or five things that Apple did wrong. I mean, number one,
[00:04:59.440 --> 00:05:03.120]   I think there was a very good reason not to hire this guy, which is that he wrote
[00:05:03.120 --> 00:05:09.040]   a best selling tell all book about the last big tech company he worked at. So why if you're a big
[00:05:09.040 --> 00:05:13.360]   tech company, why in the world would you hire him? So that was stupid decision number one,
[00:05:13.360 --> 00:05:16.880]   but they did decide to hire him. And once they hire him, they got to treat him like any other
[00:05:16.880 --> 00:05:20.960]   employee and give him a chance to show what he can do. And so that leads to mistake number two,
[00:05:20.960 --> 00:05:23.440]   which is these 2000 employees who signed this.
[00:05:23.440 --> 00:05:29.600]   Petition really distorted and took out of context that passage. And I know the passages cringe,
[00:05:29.600 --> 00:05:34.960]   okay? And gnarly and it could, you know, certainly appear sexist, but you have to put it in its
[00:05:34.960 --> 00:05:42.080]   context and the the larger con this is a work of literature. This is a best selling book. It's 150,000
[00:05:42.080 --> 00:05:47.840]   words. They're taking 150 words out of context. And the context was like you said, he's describing
[00:05:47.840 --> 00:05:53.280]   the mother of his children, the love of his life in as this sort of Linda Hamilton esque in Terminator,
[00:05:53.280 --> 00:06:01.200]   type figure or Charlize Theron in Mad Max. And this passage is not in there to describe all women.
[00:06:01.200 --> 00:06:08.080]   It's just basically a literary flourish to contrast the woman that he loves being such
[00:06:08.080 --> 00:06:13.360]   a badass compared to every other woman. And, you know, when Kara Swisher interviewed AGM five years
[00:06:13.360 --> 00:06:18.640]   ago, she brought this passage, she explained it and she said, yeah, okay, I get it. So, you know,
[00:06:18.640 --> 00:06:23.120]   it's certainly the case that people can understand the context,
[00:06:23.120 --> 00:06:28.080]   if they choose to, and they simply are not choosing to understand the context,
[00:06:28.080 --> 00:06:31.920]   which brings me to mistake number three, which is these 2000 employees
[00:06:31.920 --> 00:06:39.120]   lied in their petition by claiming that their safety is threatened by Apple hiring AGM.
[00:06:39.120 --> 00:06:44.000]   That is simply untrue. It's physically impossible in the era of Zoom when everyone's
[00:06:44.000 --> 00:06:49.520]   working from home, but this guy is not a threat to anyone's safety, but they use that claim.
[00:06:49.520 --> 00:06:52.960]   They make that claim because they know that if you accuse
[00:06:52.960 --> 00:06:57.920]   someone of threatening your safety, it will trigger the machinery of HR to remove that
[00:06:57.920 --> 00:07:04.320]   person from the workplace. This is the language of safetyism and it's a specific tactic to basically
[00:07:04.320 --> 00:07:09.200]   get somebody canceled and removed from the workplace. Okay. And then that leads to the,
[00:07:09.200 --> 00:07:14.160]   the, the next mistake, I think mistake number four, which is the bosses of the Apple caved
[00:07:14.160 --> 00:07:19.120]   into this pressure. They were total cowards. They never even gave AGM the chance to explain
[00:07:19.120 --> 00:07:22.800]   himself. They never asked him, what did you intend by this passage? What were you trying to
[00:07:22.800 --> 00:07:25.600]   do? And by the way, they knew about this book when they hired him.
[00:07:25.600 --> 00:07:29.520]   I was about to say it's even worse. They knew about the book they had vetted and they talked
[00:07:29.520 --> 00:07:34.960]   to many people as when a big time, when a big tech company hires somebody for a major position like
[00:07:34.960 --> 00:07:39.440]   this, they call all the references and all of this is uncovered and dealt with.
[00:07:39.440 --> 00:07:44.240]   Of course they knew about it. And then when the mob complains, they fire him summarily without
[00:07:44.240 --> 00:07:49.680]   subjecting the decision to proper HR processes. This is HR by mob rule. It's totally unacceptable.
[00:07:49.680 --> 00:07:52.640]   No company should be run this way. And then finally that brings us to number five,
[00:07:52.640 --> 00:07:57.280]   which is number five is that in explaining their decision and trying to justify their
[00:07:57.280 --> 00:08:02.000]   cowardice and giving it to the mob, they said that they fired him because of his behavior.
[00:08:02.000 --> 00:08:06.880]   AGM never had a chance to engage in any behavior. He barely started at the job. This wasn't because
[00:08:06.880 --> 00:08:11.600]   of his behavior. This is because of the book that he wrote five years ago. So what they're saying is
[00:08:11.600 --> 00:08:17.680]   that if you ever publish a written work at any time in your life, years and years ago,
[00:08:17.680 --> 00:08:22.480]   that that could somehow constitute present day behavior and that other people in the workplace
[00:08:22.480 --> 00:08:27.760]   can have a problem with that. This is not behavior. And this is why he's going to have a giant
[00:08:27.760 --> 00:08:34.880]   defamation suit and settlement because they are making him unemployable in the tech industry by
[00:08:34.880 --> 00:08:39.360]   claiming that he was fired for some sexist behavior. He was not.
[00:08:39.360 --> 00:08:41.120]   What do you think he'll get paid in a settlement?
[00:08:41.120 --> 00:08:42.640]   I put it at 10.
[00:08:42.640 --> 00:08:44.080]   10 million?
[00:08:44.080 --> 00:08:47.600]   Well, I was just thinking he's a half million dollar a year employee
[00:08:47.600 --> 00:08:52.320]   to a million with his RSU. So let's just put it at a million unemployed for 10 to 20
[00:08:52.320 --> 00:08:54.960]   years because of this or the damages to his reputation.
[00:08:54.960 --> 00:08:57.360]   And present value that back. Yeah.
[00:08:57.360 --> 00:08:59.360]   So and yeah, so I think 10 million is the number.
[00:08:59.360 --> 00:09:06.960]   My curiosity in this was just did those 2000 employees feel the same way about Dr. Dre?
[00:09:06.960 --> 00:09:08.320]   Of course not.
[00:09:08.320 --> 00:09:14.880]   Or do they do they feel the same way about some of the movies that they sell in the iTunes store?
[00:09:14.880 --> 00:09:20.400]   Or do they feel the same way about some of the games that they enable?
[00:09:22.160 --> 00:09:23.360]   App Store?
[00:09:23.360 --> 00:09:25.520]   Or some of the subscriptions that are sold?
[00:09:25.520 --> 00:09:27.760]   Right?
[00:09:27.760 --> 00:09:31.520]   Do they care? Do they care that much about what's happening in their Chinese supply chain?
[00:09:31.520 --> 00:09:38.080]   I mean, I think it seems at least on the outside, the answer is no. But it would be interesting to
[00:09:38.080 --> 00:09:42.880]   get an explanation of that from the same HR people. I don't know whether the guy should
[00:09:42.880 --> 00:09:47.200]   have been fired or not. But I do think that you should have a predictable standard and every
[00:09:47.200 --> 00:09:52.000]   company is allowed to do what they want. If the standard at Apple is that we are going to hold you
[00:09:52.000 --> 00:09:56.800]   accountable for everything you've done in the past, irrespective of whether you disavowed it or
[00:09:56.800 --> 00:10:01.520]   not, so be it. That's their right. And I think that the employees of that company have a right
[00:10:01.520 --> 00:10:07.200]   to do that. I think they said if you start to arbitrarily enforce it, you go down this weird
[00:10:07.200 --> 00:10:12.560]   place, which is like, basically, I think what they're saying is, if it's good for business,
[00:10:12.560 --> 00:10:17.440]   we're going to ignore it. If it's not obvious that it's good for business, we'll act because
[00:10:17.440 --> 00:10:21.840]   it's a low cost way of keeping the masses. You know, that's the way it is. And so I think that's
[00:10:21.840 --> 00:10:24.640]   the way it is. And I think that's the way it is. And I think that's the way it is. And I think that's
[00:10:24.640 --> 00:10:29.040]   what's even scarier to the 2000 people. It's not that you know, maybe they should feel proud that
[00:10:29.040 --> 00:10:34.000]   they got their pound of flesh. But they really should figure out how they want to stand on all
[00:10:34.000 --> 00:10:39.040]   these other points because to cherry pick puts, puts the whole company in just a weird posture.
[00:10:39.040 --> 00:10:45.600]   That's that's not scalable. Freeberg. I'm less interested in the hypocrisy
[00:10:45.600 --> 00:10:51.680]   in the values debate, which is obvious. That's kind of the first order point with
[00:10:51.680 --> 00:10:55.920]   all this stuff. It's like, do the employees have the right values? Is there hypocrisy by management
[00:10:55.920 --> 00:11:02.320]   is there hypocrisy by the employees? What strikes me though, is a failure of leadership
[00:11:02.320 --> 00:11:07.760]   at these organizations. You know, you guys think back to Brian Armstrong's kind of purging of the
[00:11:07.760 --> 00:11:11.280]   woke mob and the political discourse that was happening at Coinbase a few months ago.
[00:11:11.280 --> 00:11:18.240]   He took a point of strong leadership to a new level. And I think it highlighted when the leader
[00:11:18.240 --> 00:11:21.520]   steps up and says, this is how we're going to operate. These are how we're going to make decisions
[00:11:21.520 --> 00:11:27.520]   and puts his foot down. People will leave and you evolve the culture. And I think it indicates to me
[00:11:27.520 --> 00:11:33.680]   that certain companies as they've gotten really big, and really successful, like Apple, and even
[00:11:33.680 --> 00:11:40.400]   Alphabet, and various other kind of large tech companies, the leaders no longer lead the employees
[00:11:40.400 --> 00:11:47.200]   lead the narrative on culture and the narrative on values. And, you know, it speaks to two things.
[00:11:47.200 --> 00:11:51.360]   One is that there perhaps aren't founder leaders
[00:11:51.360 --> 00:11:55.760]   running those organizations anymore, that there are managers, whose job is critically important,
[00:11:55.760 --> 00:12:00.080]   whose job is to keep the wheels on and keep the wheels from falling off. So they have more to lose.
[00:12:00.080 --> 00:12:04.880]   And they are constantly trying to protect the downside than they are trying to be aggressive
[00:12:04.880 --> 00:12:10.400]   about growing to the upside. And then I think it's just, you know, secondly, this kind of,
[00:12:10.400 --> 00:12:17.680]   you know, failure to kind of define what your values are from a leadership perspective,
[00:12:17.680 --> 00:12:21.200]   and the void gets filled by the employees, the void gets filled
[00:12:21.200 --> 00:12:25.840]   by the mob. And so while it's this one kind of, you know, debatable point today, and this one kind
[00:12:25.840 --> 00:12:31.120]   of hypocritical point today, it's really interesting to see that this isn't happening at other companies
[00:12:31.120 --> 00:12:35.040]   that are founder led. And if it is, the, you know, the culture gets reset.
[00:12:35.040 --> 00:12:37.200]   Steve Jobs would have handled this completely differently.
[00:12:37.200 --> 00:12:40.080]   Steve Jobs would not have let his employees tell him who or shouldn't be hired.
[00:12:40.080 --> 00:12:41.600]   No, he would have stopped and said, let's have a discussion about this.
[00:12:41.600 --> 00:12:45.120]   He would have had a really clear point of view about who we hire, why we hire them,
[00:12:45.120 --> 00:12:50.480]   and how we make decisions and not let the democratic kind of rule or the, you know,
[00:12:51.040 --> 00:12:52.240]   employee rule.
[00:12:52.240 --> 00:12:56.240]   It's not like all employees took a vote. How much of this Chamath has to do with
[00:12:56.240 --> 00:12:59.520]   the coddling of Silicon Valley employees for two decades vis-a-vis,
[00:12:59.520 --> 00:13:05.280]   you know, you get driven to school on your school bus, you sit on, you know, you get your lunch
[00:13:05.280 --> 00:13:09.680]   prepared for you, we do your dry cleaning, every Friday, you get to come and ask challenging
[00:13:09.680 --> 00:13:16.160]   questions to the leaders and this concept of like, you know, everybody has a voice at work as opposed
[00:13:16.160 --> 00:13:20.880]   to this is a company controlled by shareholders and or a founder and you work for it, and they
[00:13:20.880 --> 00:13:26.080]   were saying trade of services here, vis-a-vis what Toby had to say at Shopify, which is,
[00:13:26.080 --> 00:13:31.200]   this is not a family, this is a sports team, you are here to perform, we are here to perform for
[00:13:31.200 --> 00:13:32.560]   our customers the end.
[00:13:32.560 --> 00:13:37.120]   So the, in fact, if you if you had a chance, and maybe Nick, we can post it in the show notes, but
[00:13:37.120 --> 00:13:43.920]   the email that Toby Lutke wrote to Shopify employees was unbelievable. That to me is like,
[00:13:43.920 --> 00:13:49.600]   that's a tour de force. That should be basically like, that should be minted and sold as an NFT.
[00:13:50.720 --> 00:13:52.480]   What's an NFT? We forgot about those.
[00:13:52.480 --> 00:13:56.960]   And it was it was it was just an incredible email, Jason, to your point. And the way that that
[00:13:56.960 --> 00:14:04.560]   started, if I may be getting these facts wrong, but there was an emoji of a noose inside of a Slack
[00:14:04.560 --> 00:14:11.840]   channel. And then and then folks got quite upset with it. And so I think Toby's response was to
[00:14:11.840 --> 00:14:18.000]   basically shut down the whole channel and say, Hey, guys, you know, we're losing the script about
[00:14:18.000 --> 00:14:18.640]   why we're here.
[00:14:18.640 --> 00:14:19.200]   Yeah.
[00:14:19.200 --> 00:14:19.680]   Yeah.
[00:14:19.680 --> 00:14:20.080]   Yeah.
[00:14:20.080 --> 00:14:20.560]   Yeah.
[00:14:20.560 --> 00:14:25.680]   And, you know, I think Bryan Armstrong's essay was a version of that. The question is, why are
[00:14:25.680 --> 00:14:30.400]   we here? If I had to guess, I think it's because we've pumped so much money into Silicon Valley
[00:14:30.400 --> 00:14:36.160]   companies. They didn't know where to spend it. And so I actually think that what we've really
[00:14:36.160 --> 00:14:40.880]   done is over hired far too many people into many of these companies. And so they kind of are very
[00:14:40.880 --> 00:14:45.440]   smart people, sitting around twiddling their thumbs. And so obviously, they're just going to
[00:14:45.440 --> 00:14:50.400]   get distracted. Meaning, I remember like, you know, at Facebook,
[00:14:50.400 --> 00:14:55.920]   there was barely enough people to keep the lights on for a while. Then I remember by the time I was
[00:14:55.920 --> 00:14:59.920]   leaving, I was like, wow, there's way too many people here. A lot of them and most of them are
[00:14:59.920 --> 00:15:05.280]   all really, really smart. But it wasn't obvious to me what many of them did. And you know, people
[00:15:05.280 --> 00:15:08.960]   would look at me and then say, Oh, you know, that's a really arrogant thing to say. And that's
[00:15:08.960 --> 00:15:14.720]   not true. And everybody's valuable. I don't know. You know, if you look at Google, I've always
[00:15:14.720 --> 00:15:19.920]   thought like that company could probably run by 2000 people. But you know, there's 200,000 people.
[00:15:19.920 --> 00:15:20.240]   So the whole company is probably run by 2000 people. But you know, there's 200,000 people. So the
[00:15:20.240 --> 00:15:25.680]   198 other 1000 of them need to find something to do. It's probably the same at Apple, it's probably
[00:15:25.680 --> 00:15:29.600]   the same at all these big tech companies. And that's the leverage that you get from technology,
[00:15:29.600 --> 00:15:36.480]   it's naturally, massively deflationary. So but if you keep pumping billions and billions and billions
[00:15:36.480 --> 00:15:42.640]   of dollars into these companies, where the app experience is written by 50 or 100 critical people
[00:15:42.640 --> 00:15:50.080]   or managed by 500 or 1000 critical people. This is the natural byproduct, I think, which all of that,
[00:15:50.080 --> 00:15:54.320]   which is the way freeberg said organizations want to grow, right? Like, how many organizations say,
[00:15:54.320 --> 00:15:58.320]   you know, we should be smaller, we don't know, you're saying something really important.
[00:15:58.320 --> 00:16:04.160]   Not enough founders and boards understand the difference between growing a business and growing
[00:16:04.160 --> 00:16:09.600]   an org. Those are two totally different things. And the reason is because we've lost sight of
[00:16:09.600 --> 00:16:14.400]   very simple financial metrics in Silicon Valley, meaning if you go to any other industry,
[00:16:14.400 --> 00:16:19.920]   where there is a cost of capital, people understand what return on invested capital means,
[00:16:19.920 --> 00:16:24.000]   they know how to measure it. Yeah, they know what operating leverage means. They know what margin
[00:16:24.000 --> 00:16:29.760]   expansion means, we only have valuation. And they seek that out. Here, we think about exactly as you
[00:16:29.760 --> 00:16:36.320]   said, valuation. And so this idea that having 100 people do the work and see margins lift is
[00:16:36.320 --> 00:16:40.720]   antithetical to the Silicon Valley culture. It's Oh, as margins go up, let's just keep running the
[00:16:40.720 --> 00:16:44.400]   same profitable business, but instead have a 500 people, 1000. What do you think you're
[00:16:44.400 --> 00:16:49.760]   an operations machine, people would say, on a COO basis, you're one of the top three to
[00:16:49.760 --> 00:16:52.560]   five in the history of the valley? What do you say COO man?
[00:16:52.560 --> 00:16:59.040]   Yeah, I mean, look, Chamath is right that in a company that's well run and well led,
[00:16:59.040 --> 00:17:03.120]   where people, people don't have time on their hands to engage in these shenanigans.
[00:17:03.120 --> 00:17:08.080]   So yeah, I mean, I think I think that's absolutely right. I think companies
[00:17:08.080 --> 00:17:13.520]   startups are increasingly have to choose whether they want to be Apple or whether they want to be
[00:17:13.520 --> 00:17:19.600]   Coinbase or Shopify for that matter. And just this this week at Apple,
[00:17:19.600 --> 00:17:24.720]   there's a new petition circling now there's a petition called by 1000 employees calling for
[00:17:24.720 --> 00:17:30.080]   Tim Cook to denounce the Israelis and endorse the Palestinian side of the conflict. Yeah.
[00:17:30.080 --> 00:17:31.440]   How's that gonna work?
[00:17:31.440 --> 00:17:32.640]   Well, of course,
[00:17:32.640 --> 00:17:36.080]   Does he have a position on abortion? Is there an abortion position at Apple yet?
[00:17:36.080 --> 00:17:40.640]   Well, but now that they've given into the woke mob, there's no reason for the mob to stop,
[00:17:40.640 --> 00:17:44.080]   they're gonna be circulating a petition every week. And that's kind of the point is,
[00:17:44.080 --> 00:17:48.880]   so and actually AGM himself had a really good quote about this. He did a great interview with
[00:17:49.440 --> 00:17:55.440]   Matt Taibbi. And he laid out the choice that companies face like this. He said it's interjected
[00:17:55.440 --> 00:18:00.800]   this is Antonio Garcia Martinez saying is interjecting the whole fucking Twitter cesspool
[00:18:00.800 --> 00:18:05.360]   with all the dog piles and all the performance of signaling and all that crap into a corporate
[00:18:05.360 --> 00:18:10.960]   setting and replicating those dynamics and calling it work. That's basically what happened is what's
[00:18:10.960 --> 00:18:19.040]   happening is you're these employees are performing Twitter at work on on Slack, and they're pretending
[00:18:19.040 --> 00:18:19.280]   Yes. like it's working. And they're pretending like it's working. And they're pretending like it's
[00:18:19.280 --> 00:18:24.400]   really work and it's not. And I think you know, founders are going to have to make a decision. Do
[00:18:24.400 --> 00:18:30.640]   you stand up and take a Brian Armstrong like position or a Toby position? Or do you eventually
[00:18:30.640 --> 00:18:36.720]   degenerate into some sort of or a base camp by the way, or even base camp the most woke virtual
[00:18:36.720 --> 00:18:43.280]   signaling founders on Twitter decided to take that's right the most libertarian or
[00:18:43.280 --> 00:18:49.120]   Spartan approach, you know, stoic approach of Toby to give you Toby's quote.
[00:18:49.120 --> 00:18:52.320]   Well, base camp just to finish the base camp thought so to base camp
[00:18:52.320 --> 00:18:57.760]   try to accommodate this sort of like woke mentality. And what they found is that they
[00:18:57.760 --> 00:19:03.360]   got pushed so far, it became so distracting, they eventually had to move to the Armstrong position.
[00:19:03.360 --> 00:19:06.480]   And that's kind of my point is once you get everybody's gonna move to that.
[00:19:06.480 --> 00:19:10.720]   Yeah, that's my point. I mean, and if you don't believe what I what I said was like, listen,
[00:19:10.720 --> 00:19:17.520]   if you believe that organization that allows political speech and this kind of stuff as a
[00:19:17.520 --> 00:19:18.960]   primary function inside the company, you're going to be a little bit more likely to get a job.
[00:19:18.960 --> 00:19:22.480]   Right? But if you're a big company, well, then go build a competitor to base camp and show that that
[00:19:22.480 --> 00:19:26.880]   system works better. Here's Toby's quote. To help you make this more clear to team members,
[00:19:26.880 --> 00:19:32.800]   here are some pointers about what Shopify is not Shopify, like any for profit company is not a
[00:19:32.800 --> 00:19:38.000]   family. The very idea is preposterous, you are born into a family, you never choose it,
[00:19:38.000 --> 00:19:43.440]   and they can unfamily you, it should be massively obvious that Shopify is not a family. But I see
[00:19:43.440 --> 00:19:48.800]   people even leaders casually use the term like shoppy fam, which will cause the members of our
[00:19:48.800 --> 00:19:53.600]   teams, especially junior ones that have never worked anywhere else. To get the wrong impression,
[00:19:53.600 --> 00:19:58.640]   the dangers of family thinking in quotes, or that it becomes incredibly hard to let poor performers
[00:19:58.640 --> 00:20:05.600]   go. Shopify is a team italicized, not a family, we literally only want the best people in the world.
[00:20:05.600 --> 00:20:10.880]   The reason why you joined Shopify is because I hope all other people you met during the
[00:20:10.880 --> 00:20:14.320]   interview process were really smart, caring and committed. This is magic,
[00:20:14.320 --> 00:20:18.640]   and it creates a virtuous magnetism on talented people because very few people in
[00:20:18.640 --> 00:20:23.360]   the world have this in themselves. People who don't should not be part of this team.
[00:20:23.360 --> 00:20:29.920]   I mean, when I was, when I was a strong, when I was a Facebook, we used to convene the senior team.
[00:20:29.920 --> 00:20:35.520]   And, you know, I was like, I want I really want to fire the bottom five or 10% of the company
[00:20:35.520 --> 00:20:39.120]   of you and we would force stack rank and we did it for about three or four years. And then
[00:20:39.120 --> 00:20:43.280]   the excuse was, it's too big. And there are too many people and the roles are too diverse,
[00:20:43.280 --> 00:20:48.480]   and you can't rank. I actually don't believe that even to this day, I think it's pretty obvious,
[00:20:48.480 --> 00:20:53.760]   who the real 1000x kind of employee contributors are. And by the way, they exist in every function,
[00:20:53.760 --> 00:20:58.320]   there's 1000x salespeople, there's 1000x, you know, product managers, there's, there's the
[00:20:58.320 --> 00:21:03.760]   1000x people that work in facilities, they exist in every job function. And companies,
[00:21:03.760 --> 00:21:08.240]   I don't think do a good enough job of figuring out who they are. And so instead, what happens
[00:21:08.240 --> 00:21:13.760]   is people that are not even 100x or not even a 10x are really more like a one or 1.1x can
[00:21:13.760 --> 00:21:18.320]   basically hide in all of that noise. And I think that if you could separate that,
[00:21:18.320 --> 00:21:23.360]   you know, you can separate HR into two things. But there's really three things. One is like
[00:21:23.360 --> 00:21:29.440]   benefits, which is critical. The second is actually like safety, and the ability to
[00:21:29.440 --> 00:21:34.400]   whistleblow if there's something really nefarious or bad that's happened. And then the third that's
[00:21:34.400 --> 00:21:38.800]   really valuable, I think is organizational design, right? How do you put people in good jobs? And how
[00:21:38.800 --> 00:21:43.440]   do you allow them to have a huge amount of autonomy to run and build a career. But all
[00:21:43.440 --> 00:21:48.160]   of this other policing stuff, to me just seems like it coddles
[00:21:48.160 --> 00:21:51.220]   lowest 25% I don't know if that and this is my intuition the to
[00:21:51.220 --> 00:21:53.800]   the lowest 25% performers of the course.
[00:21:53.800 --> 00:21:57.140]   Of course it does. And just to close this story up and wrap to
[00:21:57.140 --> 00:22:01.540]   our next in tone a GM announced that he is going to Take a year
[00:22:01.540 --> 00:22:05.680]   wait for it to write for sub stack. So he is going to get
[00:22:05.680 --> 00:22:10.600]   paid $10 million I would guesstimate in a settlement by
[00:22:10.600 --> 00:22:13.220]   Apple, he's going to get a half million dollar I'll take you
[00:22:13.220 --> 00:22:19.920]   over. I'll take you over. I said such a good line. We can bet on
[00:22:19.920 --> 00:22:22.940]   it. We can bet on it. I'll take the over the line of 10. Anybody
[00:22:22.940 --> 00:22:25.640]   want the under? I'll take you take the
[00:22:25.640 --> 00:22:28.980]   well go give it a give a different bet. Not then I'll
[00:22:28.980 --> 00:22:31.160]   figure out a different line. You could set a different line set a
[00:22:31.160 --> 00:22:33.080]   different line. I think Ted's a good line.
[00:22:33.080 --> 00:22:37.040]   Because you gotta think if they offer him seven or eight million.
[00:22:37.040 --> 00:22:40.520]   I mean, it's gonna be something like that. I don't know what the
[00:22:40.520 --> 00:22:42.080]   big what the number is. But
[00:22:42.080 --> 00:22:42.900]   we'll never know.
[00:22:42.900 --> 00:22:43.120]   I'll
[00:22:43.120 --> 00:22:47.060]   I'll make a line. 15.6. Take the under I'll take the under
[00:22:47.060 --> 00:22:51.200]   Wow. Yeah, 15 is way too David. David's quite
[00:22:51.200 --> 00:22:54.640]   sad. I'd say under 15. Yeah, that's not a good line. Good.
[00:22:54.640 --> 00:23:00.220]   11.5 is a good line. Okay, let me do 11.5. What do you take
[00:23:00.220 --> 00:23:02.240]   tomorrow can afford the book against all three of us. Okay,
[00:23:02.240 --> 00:23:06.860]   11.5. Tramont takes the over 11.5. Freeberg sacks. Yeah, I
[00:23:06.860 --> 00:23:07.660]   don't know under.
[00:23:07.660 --> 00:23:10.420]   Let's tell you why if you look at the last four year
[00:23:10.420 --> 00:23:13.020]   compounding of Apple stock, right and so if you
[00:23:13.020 --> 00:23:15.480]   think about reasonable number of grants as his level of
[00:23:15.480 --> 00:23:19.200]   seniority plus compounding, plus whatever he would have, you
[00:23:19.200 --> 00:23:21.900]   should be part of his team. Somebody said in this clip,
[00:23:21.900 --> 00:23:25.860]   because that's the argument is I do think you end up getting to
[00:23:25.860 --> 00:23:29.520]   probably show you got to include the appreciation. Yeah, you get
[00:23:29.520 --> 00:23:30.960]   to buy it now price at 15. And
[00:23:30.960 --> 00:23:33.760]   call it and they've also also you could make the argument
[00:23:33.760 --> 00:23:36.100]   they've rendered him unemployable in the industry. So
[00:23:36.100 --> 00:23:37.120]   there's foregone
[00:23:37.120 --> 00:23:37.920]   income.
[00:23:37.920 --> 00:23:42.200]   Then it could be 20 mental suffering. What about suffering?
[00:23:42.200 --> 00:23:42.920]   He is going to be in a position where he's going to be in a
[00:23:42.920 --> 00:23:44.460]   position where he's going to suffer, he's going to need to be
[00:23:44.460 --> 00:23:48.900]   on meds. My client is suffering. He's in therapy twice a week. He
[00:23:48.900 --> 00:23:51.260]   can't get out of bed, he's not going to be able to be in
[00:23:51.260 --> 00:23:53.920]   functional relationships. And he's too scared to leave the
[00:23:53.920 --> 00:23:54.380]   house.
[00:23:54.380 --> 00:23:56.540]   He should wait on the substack because he's gonna make so much
[00:23:56.540 --> 00:23:59.180]   money on substack. It's gonna mitigate his damages.
[00:23:59.180 --> 00:24:00.260]   Yeah, don't take
[00:24:00.260 --> 00:24:02.540]   away. Just wait on the
[00:24:02.540 --> 00:24:07.420]   you guys know what Apple's market cap divided by employees
[00:24:07.420 --> 00:24:11.780]   is. Apple is Apple's market 7 million and employee.
[00:24:12.660 --> 00:24:16.080]   Anyone else? Wait a second. There's 100,000 employees and
[00:24:16.080 --> 00:24:17.340]   it's worth 2 trillion.
[00:24:17.340 --> 00:24:22.920]   Okay, there's 150,000 employees 2.1 trillion. So it's 14 million
[00:24:22.920 --> 00:24:26.100]   an employee. So the other way to think about it is if Apple's
[00:24:26.100 --> 00:24:29.900]   like gonna lose one or two good employees over this. You know,
[00:24:29.900 --> 00:24:34.160]   they'd happily pay up to get to get the guy to be quiet. So it's
[00:24:34.160 --> 00:24:37.140]   worth one employee to pay $14 million.
[00:24:37.140 --> 00:24:40.940]   Well, no, I mean, well, you're not dividing by all the slave
[00:24:40.940 --> 00:24:41.760]   labor in China.
[00:24:41.760 --> 00:24:45.840]   And I'll recalc I'll recalc. Well, they cause they actually
[00:24:45.840 --> 00:24:50.220]   cost zero. That was bad. Sorry.
[00:24:50.220 --> 00:24:54.480]   All the time. It's dark, but it's true. I mean, this is the
[00:24:54.480 --> 00:24:58.680]   hypocrisy of Apple. They've literally got slave labor in
[00:24:58.680 --> 00:25:01.020]   their supply chain. Not that they wanted in their supply
[00:25:01.020 --> 00:25:05.220]   chain. How do you know that? How do you know that? Let's just go
[00:25:05.220 --> 00:25:07.680]   through this because like this is a common narrative. But has
[00:25:07.680 --> 00:25:10.440]   anyone actually like gotten to the bottom of that's why I said
[00:25:10.440 --> 00:25:10.980]   report.
[00:25:11.500 --> 00:25:16.540]   Yeah, yeah, it is it is known again, like I don't like I don't
[00:25:16.540 --> 00:25:17.620]   like pushing narratives.
[00:25:17.620 --> 00:25:20.740]   Why? I actually I tweeted something that I'm well, I
[00:25:20.740 --> 00:25:24.100]   retweeted something that came from I think a pretty valid
[00:25:24.100 --> 00:25:28.940]   source, that author from the Atlantic, who I think is pretty
[00:25:28.940 --> 00:25:29.500]   legit.
[00:25:29.500 --> 00:25:32.180]   Also, I just think just in terms of his quote, if he had taken
[00:25:32.180 --> 00:25:35.260]   the word woman out of the quote, most people in the Bay Area are
[00:25:35.260 --> 00:25:38.560]   soft and weak. In a zombie apocalypse. I don't think
[00:25:38.560 --> 00:25:41.240]   you're recruiting from the Bay Area. But related to this, I'm
[00:25:41.240 --> 00:25:43.280]   going to go back to the story. And I'm going to go back to this
[00:25:43.280 --> 00:25:48.380]   story. In terms of Chamath point about, you know, 1000 X
[00:25:48.380 --> 00:25:53.720]   performers. America is really doing a bad job at math and Gary
[00:25:53.720 --> 00:25:57.860]   Tan, the venture capitalist retweeted and participated in a
[00:25:57.860 --> 00:26:02.300]   tweet thread about immigrants. Who know that standardized test
[00:26:02.300 --> 00:26:04.880]   is probably your best shot at getting somewhere. Your money
[00:26:04.880 --> 00:26:08.240]   social size can take you the rules are well standardized. And
[00:26:08.240 --> 00:26:10.980]   he tells this story about this. But there was a persuasion
[00:26:10.980 --> 00:26:14.100]   about us failing math and that they're going to be in
[00:26:14.100 --> 00:26:18.940]   California, getting rid of the gifted programs for math, because
[00:26:18.940 --> 00:26:23.520]   it's unfair to the kids who are not gifted as a kid who is was
[00:26:23.520 --> 00:26:28.080]   not gifted. And to the three kids on the program who were in
[00:26:28.080 --> 00:26:30.960]   gifted programs, or at least two of you were, I have no problem
[00:26:30.960 --> 00:26:33.180]   with there being a gifted program. But any thoughts on
[00:26:33.180 --> 00:26:33.540]   this?
[00:26:33.540 --> 00:26:36.500]   I think it's shameful. Yeah,
[00:26:36.500 --> 00:26:40.080]   it really is. I mean, like we are we are really doing our level
[00:26:40.080 --> 00:26:40.740]   best to just
[00:26:40.740 --> 00:26:46.380]   completely fuck our population. Why? I mean, why is this even?
[00:26:46.380 --> 00:26:50.460]   How could this even be possible? It's like, like, just like it's
[00:26:50.460 --> 00:26:53.160]   it's kind of like the equivalent. It's the moral
[00:26:53.160 --> 00:26:55.300]   equivalent of actually saying, you know what, we're going to
[00:26:55.300 --> 00:27:01.800]   eliminate welfare for the bottom 5%. Like, our job as a society
[00:27:01.800 --> 00:27:06.100]   is to kind of like find the broadest set of solutions for
[00:27:06.100 --> 00:27:09.980]   the most number of people and solve for both extremes.
[00:27:10.500 --> 00:27:13.380]   So when you're dealing with education, you both need to
[00:27:13.380 --> 00:27:16.620]   understand that there are folks that need some kind of
[00:27:16.620 --> 00:27:20.160]   structural support. Look, when I came to Canada, I had ESL, right
[00:27:20.160 --> 00:27:22.560]   English as a second language, you take that so that you can
[00:27:22.560 --> 00:27:25.180]   learn the native language of a country. It didn't mean that I
[00:27:25.180 --> 00:27:28.480]   was stupid. It just meant that I was behind. You know, if I had
[00:27:28.480 --> 00:27:31.480]   dyslexia or something else, I would need some kind of support.
[00:27:31.480 --> 00:27:33.900]   One of my children had a speech impediment, we had a speech
[00:27:33.900 --> 00:27:37.020]   therapist, this is what you do. But on the other side, if you
[00:27:37.020 --> 00:27:39.420]   have a kid who's an incredibly high performer who has a
[00:27:39.420 --> 00:27:40.140]   potential to just
[00:27:40.260 --> 00:27:44.820]   completely crush, hey, like you should be able to give that kid
[00:27:44.820 --> 00:27:48.300]   a pathway to achieve and give back. So the idea that you
[00:27:48.300 --> 00:27:51.420]   would eliminate anything at the extremes is kind of completely
[00:27:51.420 --> 00:27:55.020]   uncompassionate and stupid, just totally fucking stupid.
[00:27:55.020 --> 00:27:58.920]   Well, it's in the name of having a more equitable math class.
[00:27:58.920 --> 00:28:02.220]   Again, I hate that word. Please don't use that word. Please
[00:28:02.220 --> 00:28:04.980]   don't use that word. That is that is the least
[00:28:04.980 --> 00:28:07.320]   way this this I mean, this goes back to the point I made a few
[00:28:07.320 --> 00:28:10.020]   episodes ago that you know, you can have progress or you can have
[00:28:10.020 --> 00:28:12.840]   equality, but it's very difficult to have both. And you
[00:28:12.840 --> 00:28:15.120]   know, if you want to try and make everyone equal and give no
[00:28:15.120 --> 00:28:18.720]   one the opportunity to have more or get more than anyone else
[00:28:18.720 --> 00:28:20.940]   because of whatever the circumstance may be, whether it's
[00:28:20.940 --> 00:28:25.960]   earned No, no, but this is my point. Like, you know, you limit
[00:28:25.960 --> 00:28:28.980]   the ability for everyone to progress as a group because
[00:28:28.980 --> 00:28:31.380]   we're now limiting the ability for folks to take calculus.
[00:28:31.380 --> 00:28:34.780]   I know equality. Look, I'll use a video game example. Equality
[00:28:34.780 --> 00:28:37.980]   means we all get to play Grand Theft Auto. Not that we have
[00:28:37.980 --> 00:28:39.780]   somebody who actually plays for us.
[00:28:39.780 --> 00:28:42.600]   And gets to the same answer and just gives you a ticket that says
[00:28:42.600 --> 00:28:46.440]   we don't get the same score on the same score. Yeah. So so the
[00:28:46.440 --> 00:28:49.500]   so that's that is what equality means is that we all get to play.
[00:28:49.500 --> 00:28:52.440]   And we all get a chance versus equity, which is leveling
[00:28:52.440 --> 00:28:55.380]   everyone. Equity is leveling everybody and saying here's your
[00:28:55.380 --> 00:28:57.780]   result, right? By the way, it's the same as this other person,
[00:28:57.780 --> 00:29:00.360]   whatever the misnomer is, but the notion of leveling everyone
[00:29:00.360 --> 00:29:02.940]   where no one can be ahead of anyone else by too far,
[00:29:02.940 --> 00:29:07.380]   obviously limits as a group, our ability for the top decile to
[00:29:07.380 --> 00:29:09.360]   increment or the top quartile to increment.
[00:29:09.540 --> 00:29:12.840]   I got to think, look, let's, let's again, use, let's again,
[00:29:12.840 --> 00:29:15.900]   use our friends because instead of ours, but, you know, we know a
[00:29:15.900 --> 00:29:20.880]   lot of really smart people who have really, really smart kids.
[00:29:20.880 --> 00:29:25.440]   We also know people in general that are in tough circumstances
[00:29:25.440 --> 00:29:30.000]   who also probably have really smart kids. Just purely
[00:29:30.000 --> 00:29:34.380]   selfishly for me, I want those kids doing the best they can to
[00:29:34.380 --> 00:29:36.660]   figure out what the hell they can invent for us in the future.
[00:29:36.660 --> 00:29:39.300]   Why would you slow those kids down?
[00:29:39.300 --> 00:29:42.600]   You know, it's kind of like saying, you know what, like, how
[00:29:42.600 --> 00:29:45.660]   about a black athlete? Would you would it be preposterous to say,
[00:29:45.660 --> 00:29:49.140]   you know what, you don't have a right to go to the NBA and make
[00:29:49.140 --> 00:29:52.140]   money for your family. I'm going to slow you down. Because
[00:29:52.140 --> 00:29:54.240]   there's another white kid that's going to go through four years
[00:29:54.240 --> 00:29:55.860]   of college. So you know what, you're going to have to go
[00:29:55.860 --> 00:29:57.660]   through four years of college and you're going to have to pay
[00:29:57.660 --> 00:29:57.900]   for it.
[00:29:57.900 --> 00:30:02.460]   Well, actually, what I would propose is when I go up to dunk
[00:30:02.460 --> 00:30:05.220]   that we just the rim automatically lowers two feet.
[00:30:05.220 --> 00:30:06.240]   Yeah, I like that.
[00:30:06.240 --> 00:30:09.060]   So I can dunk and then when you go for a layup, we'll just raise
[00:30:09.060 --> 00:30:11.340]   six inches, it'd be more equitable for me.
[00:30:11.340 --> 00:30:12.000]   That's more equitable.
[00:30:12.000 --> 00:30:13.200]   Yes, more equitable.
[00:30:13.200 --> 00:30:16.320]   Let me let me let me add another layer to this. So I agree with
[00:30:16.320 --> 00:30:18.780]   you with you guys that what we should be thinking about is
[00:30:18.780 --> 00:30:21.240]   opportunity, we should always be asking what increases
[00:30:21.240 --> 00:30:23.820]   opportunity for the most people. And that's how we should measure
[00:30:23.820 --> 00:30:27.660]   political programs. And we're not doing that here. We are sort
[00:30:27.660 --> 00:30:29.820]   of leveling down. But I would say it's even more nefarious
[00:30:29.820 --> 00:30:33.240]   than that. Which is I think what's happening is that the
[00:30:33.240 --> 00:30:36.900]   education establishment is completely failing our kids and
[00:30:36.900 --> 00:30:38.820]   our schools. And what they're trying to do is
[00:30:38.820 --> 00:30:43.320]   destroy the evidence of that failure. And so they're hiding,
[00:30:43.320 --> 00:30:47.580]   they're hiding the results. Now, this persuasion piece, yes,
[00:30:47.580 --> 00:30:51.240]   this persuasion piece lays out the statistics, which are pretty
[00:30:51.240 --> 00:30:54.240]   grim. Okay. So according to these like global measurements
[00:30:54.240 --> 00:31:00.120]   by OECD, okay, math proficiency in the US, we rank 37 in the
[00:31:00.120 --> 00:31:03.720]   world. Okay, and there's only 37 developed nations in the world,
[00:31:03.720 --> 00:31:06.420]   according to the developed. So we're last among developed
[00:31:06.420 --> 00:31:08.580]   countries, China, which is our main global
[00:31:08.580 --> 00:31:12.420]   competitor is number one. Okay. And we achieved these horrible
[00:31:12.420 --> 00:31:15.180]   results despite ranking fifth in the world in per pupil spending.
[00:31:15.180 --> 00:31:20.700]   So it's not a spending problem. Okay. And as we know, to the
[00:31:20.700 --> 00:31:22.380]   extent we do have high performing math students in the
[00:31:22.380 --> 00:31:26.460]   US, a huge majority of them are actually foreign born. And so
[00:31:26.460 --> 00:31:29.160]   we're actually kind of cheating our numbers a little bit. It's
[00:31:29.160 --> 00:31:32.100]   even worse than it appears. Now, what is the education
[00:31:32.100 --> 00:31:34.860]   establishment doing about this? How are they hiding the failure?
[00:31:34.860 --> 00:31:38.340]   Well, when school comes back in the fall, they're planning to
[00:31:38.340 --> 00:31:41.340]   eliminate accelerated math. Okay. That means that there's no more
[00:31:41.340 --> 00:31:44.280]   algebra for eighth graders who are ready to take it on. There's
[00:31:44.280 --> 00:31:47.820]   no more calculus for high schoolers who want to, you know,
[00:31:47.820 --> 00:31:51.480]   do like the AP classes and get a jump on STEM, you know, for
[00:31:51.480 --> 00:31:55.080]   college. The entire idea of gifted students is now under
[00:31:55.080 --> 00:31:58.140]   attack. Like we talked about in the name of equity, it's become
[00:31:58.140 --> 00:32:01.860]   a catchall for every bad idea. And the University of California
[00:32:01.860 --> 00:32:05.160]   system has now abandoned the SAT and ACT.
[00:32:05.160 --> 00:32:08.100]   So they temporarily got rid of those requirements during the
[00:32:08.100 --> 00:32:12.000]   pandemic. But now they've used it as an excuse. They've never
[00:32:12.000 --> 00:32:14.280]   wasted a crisis. And now they say they're not bringing back
[00:32:14.280 --> 00:32:18.780]   the requirements until at least 2025. And you can bet it's never
[00:32:18.780 --> 00:32:21.540]   going to return at all. And so here's the thing. They're trying
[00:32:21.540 --> 00:32:25.260]   to get rid of measuring how bad we are at math. So we won't have
[00:32:25.260 --> 00:32:27.900]   to think about it. They just want to give everyone a gold
[00:32:27.900 --> 00:32:30.420]   star and a pat on the back and say how equitable we are.
[00:32:30.420 --> 00:32:32.520]   You know what this reminds me of, Sax, is when you threw
[00:32:32.520 --> 00:32:35.640]   away the digital scale I got you.
[00:32:35.640 --> 00:32:37.860]   Right.
[00:32:37.860 --> 00:32:41.820]   I'm not fat because I'm not measuring it. Great.
[00:32:41.820 --> 00:32:42.960]   Perfect.
[00:32:42.960 --> 00:32:51.120]   Oh my God. It's like, we really, it's the movie Idiocracy. Literally,
[00:32:51.120 --> 00:32:53.880]   we are doing the movie Idiocracy. Have you guys seen Idiocracy?
[00:32:53.880 --> 00:32:58.080]   Why don't we just eliminate all admissions programs at every
[00:32:58.080 --> 00:33:03.060]   university and just have one global admissions board where every campus is the same? What is
[00:33:03.060 --> 00:33:07.620]   the difference between MIT and Stanford and Caltech and the
[00:33:07.620 --> 00:33:10.980]   University of Arkansas? In my opinion, there shouldn't be. It's more equitable
[00:33:10.980 --> 00:33:14.460]   to just have somebody go close to home because you can save money.
[00:33:14.460 --> 00:33:18.840]   You know, carbon emissions are lower, right? You can just take the bus to the local school.
[00:33:18.840 --> 00:33:19.560]   Also, competition is unfair.
[00:33:19.560 --> 00:33:24.840]   You can have one centralized place teach you a few basic course. I mean, if I said this,
[00:33:24.840 --> 00:33:28.920]   you'd think that I was a crazy person. Except that's basically what we're now telling all of
[00:33:28.920 --> 00:33:31.440]   our high school and middle school kids. I'm also getting rid of Michelin stars and I'd
[00:33:31.440 --> 00:33:37.380]   like Yelp to take off their review system because it's not equitable. Like, we should not have Michelin
[00:33:37.380 --> 00:33:39.600]   stars anymore. Every chef should just get-- Every restaurant's the same.
[00:33:39.600 --> 00:33:41.520]   Every restaurant should get three quarters of a star.
[00:33:41.520 --> 00:33:46.080]   We should not-- the health department should not give ranks of letters and they should not
[00:33:46.080 --> 00:33:48.660]   be forced to post it because that's inequitable. Absolutely.
[00:33:48.660 --> 00:33:50.220]   You know? Yeah.
[00:33:50.220 --> 00:33:54.240]   Also, you can game the health test. You could literally just follow the rules.
[00:33:54.240 --> 00:34:00.780]   So, let me just ask the counterpoint question, which is standardized testing,
[00:34:00.780 --> 00:34:07.140]   for example, benefits people that can afford tutors and special classes to get
[00:34:07.140 --> 00:34:09.060]   ahead and therefore-- Provide more tutors.
[00:34:09.060 --> 00:34:10.200]   Yeah, therefore-- For free.
[00:34:10.200 --> 00:34:13.740]   Well, therefore, it's higher income people that can always-- Well, the point is they can always
[00:34:13.740 --> 00:34:17.460]   layer on additional tutoring. They can always layer on additional classes and therefore, they
[00:34:17.460 --> 00:34:18.720]   can always-- There's a finite number of math.
[00:34:18.720 --> 00:34:22.380]   It's a finite score, Friedberg. You can only get 800 on the math SATs.
[00:34:22.380 --> 00:34:29.160]   I'll be somewhat flip-floppy here. I don't believe in standardized tests that much. I
[00:34:29.160 --> 00:34:32.880]   never did well particularly in standardized tests. I do think that they can be gamed,
[00:34:32.880 --> 00:34:36.900]   but that's different from what we're talking about. What we're saying is if kids
[00:34:36.900 --> 00:34:43.080]   show aptitude, we are explicitly choosing to not give them a chance to develop at their potential.
[00:34:43.080 --> 00:34:50.460]   And the problem is we do this in other areas. We do it in athletics. We do it in music. We do it
[00:34:50.460 --> 00:34:55.560]   in the arts, but we're not going to do it in STEM. That's what we're choosing to do. That is what's
[00:34:55.560 --> 00:35:00.600]   crazy. So, choose to get rid of the SAT or ACT, whatever you want. I don't care.
[00:35:00.600 --> 00:35:06.660]   But if you are the LeBron James of physics, Jesus Christ, like let that kid become
[00:35:06.660 --> 00:35:12.000]   the LeBron James of physics. I'll tell you, I got into UC Berkeley because I had great standardized
[00:35:12.000 --> 00:35:17.400]   test scores because I had an aptitude for- What was your SAT, Friedberg? Let's do this.
[00:35:17.400 --> 00:35:20.400]   I got a- Let's do this.
[00:35:20.400 --> 00:35:27.360]   An 800 math and I think it was a 720 verbal. Okay. So, you got a 1520 out of 1600 at the time.
[00:35:27.360 --> 00:35:30.360]   I got an 1160. Yeah, and I got an 800 on the math.
[00:35:30.360 --> 00:35:34.500]   Sacks. I'm last, obviously. Sacks, go ahead.
[00:35:34.500 --> 00:35:41.700]   I was 750 math, 720 verbal. 1470.
[00:35:41.700 --> 00:35:46.980]   Are you writing this down? This was pre the inflation. There was a big SAT inflation.
[00:35:46.980 --> 00:35:52.680]   I was 1510 on the SAT. Oh, we were- Okay. So, I woke up 400 points,
[00:35:52.680 --> 00:35:56.220]   500 points behind each of you. In Canada, it was just kind of like,
[00:35:56.220 --> 00:35:58.800]   we didn't even write it, but I went and I wrote it just for shits and giggles.
[00:35:58.800 --> 00:36:01.140]   I didn't do well. I didn't do well like-
[00:36:01.140 --> 00:36:03.600]   You just said you weren't good at standardized tests. So, what are you talking about?
[00:36:03.600 --> 00:36:05.700]   You're in the top 3%. Yeah.
[00:36:05.700 --> 00:36:09.600]   Yeah, I know. But generally, I wasn't a good test taker. I was in probation in college,
[00:36:09.600 --> 00:36:13.560]   academic probation. I'm not a good test taker. Yeah, but look, the reason why these tests got
[00:36:13.560 --> 00:36:18.540]   invented was actually to prevent discrimination. I think it was back in the '50s.
[00:36:18.540 --> 00:36:20.220]   Right. I think it was like,
[00:36:20.220 --> 00:36:24.300]   and at that time, it was Jews being kept out of the Ivy League. And one of the ways that
[00:36:24.300 --> 00:36:27.900]   they corrected for that was they made everyone take the same test. And so, you could see the
[00:36:27.900 --> 00:36:33.360]   scores and it would shine some light on making sure that people didn't just get in because they
[00:36:33.360 --> 00:36:40.200]   had their legacies, that they got in because they had good scores. And there's been decades
[00:36:40.200 --> 00:36:46.320]   of work since then to try and eliminate bias in the test. And so, the claims of bias now in the
[00:36:46.320 --> 00:36:51.420]   test really aren't supported. Now, to Freberg's point, obviously,
[00:36:51.420 --> 00:36:58.380]   that if you take some rich kid who lives in the suburbs who gets a 1400 and you compare that to
[00:36:58.380 --> 00:37:03.120]   a kid in the inner city who doesn't have, who grew up poor, doesn't have the advantages, and
[00:37:03.120 --> 00:37:09.300]   that kid gets a 1300, well, which score is better? Probably the 1300. And so, you can take that into
[00:37:09.300 --> 00:37:15.420]   account, in my view, in the admissions process. But eliminating the scores altogether, why would
[00:37:15.420 --> 00:37:19.260]   you want to have less information to make a decision? Yeah, there's no reason not to get
[00:37:19.260 --> 00:37:23.520]   rid of these. I would just think more holistically about how you accept students. And I mean,
[00:37:23.520 --> 00:37:28.740]   is it more competition and having better teachers, what we should be focusing on here,
[00:37:28.740 --> 00:37:32.880]   as opposed to even standardized testing or, God forbid, canceling programs? Let's
[00:37:32.880 --> 00:37:37.260]   invest in more competition for schools. Well, so in Canada, we had this thing
[00:37:37.260 --> 00:37:42.480]   where when I was graduating, we had specific different kinds of math contests and computer
[00:37:42.480 --> 00:37:48.060]   science contests and other things that you could write, the Putnam, et cetera. And
[00:37:48.060 --> 00:37:53.100]   those things were actually really instructive because they were purely verticalized things
[00:37:53.100 --> 00:37:57.420]   that could test your aptitude. And the school that I went to, University of Waterloo,
[00:37:57.420 --> 00:38:02.640]   would look at a lot of those things and adjust for it because my grades were decent. But my,
[00:38:02.640 --> 00:38:07.620]   some of those, this one specific math test I took was pretty good, I remember. And then they would
[00:38:07.620 --> 00:38:12.360]   adjust it exactly as David said to what is this kid's background and his circumstances, and they
[00:38:12.360 --> 00:38:16.860]   called it a French factor. They would just adjust my marks. And that's how I got into Waterloo,
[00:38:16.860 --> 00:38:21.840]   and I didn't think I was going to. So there's all kinds of ways where you can be smart about it. But
[00:38:21.840 --> 00:38:26.340]   again, we're talking about, guys, don't lose sight of what you're saying. We are actually going to
[00:38:26.340 --> 00:38:30.900]   cut all these kids off at the knees starting in grade eight. So forget about all of this stuff.
[00:38:30.900 --> 00:38:32.400]   Right. By the time that these kids graduate,
[00:38:32.400 --> 00:38:35.640]   they're going to be, I honestly, they're going to be like, really dumb.
[00:38:35.640 --> 00:38:40.140]   Right. The problem ultimately isn't just measurement, it's the denial of opportunity
[00:38:40.140 --> 00:38:45.540]   to learn. It's about getting rid of the learning and the classes. That's the biggest problem.
[00:38:45.540 --> 00:38:49.260]   You have to move to a state with a gifted program now, if your kid is really smart.
[00:38:49.260 --> 00:38:54.900]   Or opt out of public education, which doesn't help anybody. I mean, literally, schools don't have to
[00:38:54.900 --> 00:39:00.660]   teach. We've now designed a system to summarize. Schools don't have to compete for students.
[00:39:00.660 --> 00:39:02.160]   Teachers don't
[00:39:02.160 --> 00:39:06.600]   have to compete for jobs or for their employment. And now we're saying students don't have to
[00:39:06.600 --> 00:39:12.780]   compete. So if you remove competition from the human condition, you're just not going to have
[00:39:12.780 --> 00:39:18.420]   any performance. There's going to be no progress. And as a species, we need progress. We need to
[00:39:18.420 --> 00:39:23.820]   solve global warming. We need to solve a lot of issues. And don't we want to live longer and
[00:39:23.820 --> 00:39:31.920]   better lives? Like where is the optimistic nature of the human species? Competition is at the core of
[00:39:31.920 --> 00:39:36.240]   excellence. And to just take it out of everything, the whole stack.
[00:39:36.240 --> 00:39:40.380]   J. Cal, that's the smartest thing you've ever said. Way smarter than an 1120 SAT score.
[00:39:40.380 --> 00:39:42.480]   Thank you. Thank you.
[00:39:42.480 --> 00:39:47.880]   Are you sure it was only 1120? How lame is it that we're still talking about our SAT scores
[00:39:47.880 --> 00:39:50.100]   like 30 years later? 800 was the average. So in Brooklyn,
[00:39:50.100 --> 00:39:53.820]   when you're 320 points above average, David, it's a BFD.
[00:39:53.820 --> 00:39:58.740]   What's lame is the four of us all remember, down to the number of what our score is. That's what's
[00:39:58.740 --> 00:40:01.680]   lame. I think I was 1120, 1150. I got to look it up.
[00:40:01.680 --> 00:40:07.680]   All right. Do we want to go to the crypto meltdown or talk about inflation? Or do we
[00:40:07.680 --> 00:40:10.140]   should we dovetail those together? Or just want to go straight to UFOs?
[00:40:10.140 --> 00:40:15.660]   Well, bright Biden just they just a press release just hit the wire and they just cut the
[00:40:15.660 --> 00:40:19.260]   infrastructure bill from 2.3 trillion to 1.7 trillion.
[00:40:19.260 --> 00:40:22.560]   Oh, we're doing our job here at the podcast.
[00:40:22.560 --> 00:40:29.940]   And I had heard from somebody that there just is not the broad based support for
[00:40:31.440 --> 00:40:36.600]   capital gains tax. So that's not going to happen. And it looks like the corporate tax
[00:40:36.600 --> 00:40:43.860]   will probably go to 25%. Not even up to 28%. And interestingly, I didn't realize this. But one of
[00:40:43.860 --> 00:40:47.520]   the biggest features of the bill that has the most popularity is that they're closing this
[00:40:47.520 --> 00:40:53.700]   loophole around IP that sits outside the United States. And that more than the corporate taxes
[00:40:53.700 --> 00:40:57.600]   will raise almost a trillion dollars of revenue. I agree with that one. Why should you put your
[00:40:57.600 --> 00:41:01.200]   why is Apple I mean, you want to talk about hypocrisy, putting their IP in Ireland, so
[00:41:01.200 --> 00:41:05.940]   you don't pay taxes. It was everybody's doing that. Why does that exist? It's so un-American.
[00:41:05.940 --> 00:41:11.820]   Well, it's a subsidiary that has different taxation on it. And you know, to kind of
[00:41:11.820 --> 00:41:16.800]   that capital and that and that earnings sits outside the US
[00:41:16.800 --> 00:41:23.700]   that IP was made in California. It was not made in Dublin. No offense to you know, my home country.
[00:41:23.700 --> 00:41:29.940]   I remember Facebook, we did that we did this exact thing. We signed over all the IP. And then the IRS
[00:41:29.940 --> 00:41:30.960]   sued Facebook. And I remember Facebook was the first company to do that. And then the IRS sued
[00:41:30.960 --> 00:41:35.520]   Facebook. And I remember like I was called either to I was subpoenaed. And we went through like a
[00:41:35.520 --> 00:41:39.840]   whole multi year trial, it may still be going on. And it was around this issue, which was the IRS
[00:41:39.840 --> 00:41:45.300]   said, Hey, Facebook, how come you, you know, you ported this over there? And I think Facebook's
[00:41:45.300 --> 00:41:48.900]   answer was, yeah, we paid the tax. And I think they did. They don't think they did anything wrong
[00:41:48.900 --> 00:41:53.700]   because the laws allowed it. But it effectively helped shield then 10s of billions of dollars of
[00:41:53.700 --> 00:41:59.160]   future taxes. I mean, I remember reading about this. And I'm like, how does this pass the sniff
[00:41:59.160 --> 00:42:04.500]   test? Well, it's where the revenue is recognized J Cal. So you basically can produce the IP here and
[00:42:04.500 --> 00:42:09.240]   then transfer it to your subsidiary. When you transfer to your subsidiary, you can recognize
[00:42:09.240 --> 00:42:15.480]   the earnings in that subsidiary and that subsidiary pays taxes in its local jurisdiction. The I think
[00:42:15.480 --> 00:42:21.780]   the issue Facebook had was that they transferred the IP and they undervalued what the future value
[00:42:21.780 --> 00:42:26.820]   would be from that IP transfer. And that's why the IRS sued them is this accounting snafu in terms of
[00:42:26.820 --> 00:42:28.920]   like, what did you value it out at the moment you transferred it?
[00:42:28.920 --> 00:42:35.160]   Here's another idea. Why doesn't Why don't they look at as part of this IP licensing? Where does
[00:42:35.160 --> 00:42:41.100]   the consumption of that IP occur? And where do the employees who maintain that IP live?
[00:42:41.100 --> 00:42:45.060]   J Cal, it's a very smart idea. The problem is that's the slippery slope that then gets
[00:42:45.060 --> 00:42:49.080]   to local taxation. You know, the thing is, we have all these global tax treaties where
[00:42:49.080 --> 00:42:54.120]   these large corporate entities can basically play this game, and they're not subject to local tax.
[00:42:54.120 --> 00:42:58.680]   But that's the thing that's going to really start the undoing of the big monopoly.
[00:42:58.680 --> 00:43:04.380]   Please, because if you start to abandon these global tax treaties, and you're starting to see
[00:43:04.380 --> 00:43:10.080]   it, France is trying to do some stuff, the UK is trying to do some stuff, states individually in
[00:43:10.080 --> 00:43:14.820]   the United States are trying to sue these companies or tax them more. That's the that's the first way
[00:43:14.820 --> 00:43:19.560]   to chip away at these monopolies is to basically say, fuck your global tax treaty, you need to pay
[00:43:19.560 --> 00:43:25.140]   x amount of dollars to be here. And it already exists because of these, you know, realist,
[00:43:25.140 --> 00:43:28.440]   sorry, the retail tax nexus is and how ecommerce can be used.
[00:43:28.440 --> 00:43:51.740]   And then you have the
[00:43:51.740 --> 00:43:58.200]   commerce companies have to pay local tax in the areas. But once it sort of touches a whole bunch
[00:43:58.200 --> 00:44:03.540]   of these companies, you know, that country doesn't care what the taxation is in Zimbabwe, right, or
[00:44:03.540 --> 00:44:08.220]   Canada, they're like, if I'm the UK or France, I'm like, I look at the top 20 apps in my country. And
[00:44:08.220 --> 00:44:12.840]   I'm like, wait a minute, these guys would be paying me $50 billion a year in tax. It's hard
[00:44:12.840 --> 00:44:15.720]   to get away from the incentive to not want to tax these companies right now.
[00:44:15.720 --> 00:44:17.640]   Sax. Any thoughts?
[00:44:17.640 --> 00:44:22.920]   Yeah, I don't have a huge thought on the IP issue. It seems like I know
[00:44:22.920 --> 00:44:26.820]   the the Republican proposal on the infrastructure was six to 800 billion.
[00:44:27.960 --> 00:44:34.200]   Biden's proposal initially was 2.3. Chamath is right now they're down to 1.7. I think the markets
[00:44:34.200 --> 00:44:40.800]   have been choking on the size of all of this tax and spend. And the there's been all these reports
[00:44:40.800 --> 00:44:47.100]   of inflation spiking. And so the growth stocks have just been hammered. Because we're all
[00:44:47.100 --> 00:44:51.600]   expecting big interest rate increases to control this future inflation. So
[00:44:51.600 --> 00:44:57.720]   Biden's been horrible for growth stocks so far. And it really I guess that what it shows is that
[00:44:57.720 --> 00:45:02.460]   you know, what are growth stocks, growth stocks are future investment. And it shows the way that
[00:45:02.460 --> 00:45:07.920]   the government can crowd out when you have excess government spending. I guess you can call it an
[00:45:07.920 --> 00:45:13.320]   investment if you want. But when you have excess government spending, it starts to crowd out private
[00:45:13.320 --> 00:45:19.680]   investment, because it raises interest rates. And that, you know, decreases the value of growth
[00:45:19.680 --> 00:45:25.980]   stocks. And there's less money that flows into that. Yeah, it does seem like the market reaction
[00:45:25.980 --> 00:45:34.680]   to the infrastructure bill, and to inflation has made Biden reconsider his approach. And maybe he
[00:45:34.680 --> 00:45:39.420]   just came out too hot. I don't think Biden's reconsidering. I think it's people like Joe
[00:45:39.420 --> 00:45:45.240]   Manchin. Remember, it's a 50s Warner, Mark Warner, Kristen cinema, the moderate, there's three or four
[00:45:45.240 --> 00:45:50.820]   moderate Democrats in the Senate, who I think are receiving the message. I'm not putting it really
[00:45:50.820 --> 00:45:55.560]   well, the last pod that the markets are sending a message to Washington. I think some of those
[00:45:55.560 --> 00:46:00.420]   centrist Democrats read the message. I don't think Biden's aware of it. I don't know what he's aware
[00:46:00.420 --> 00:46:04.080]   of. He doesn't seem too aware of anything to me. But I think the moderate Democrats are getting a
[00:46:04.080 --> 00:46:08.460]   message. And they're telling they're telling the White House the package is too big. And they're,
[00:46:08.460 --> 00:46:09.780]   and I think that's why it's coming.
[00:46:09.780 --> 00:46:14.520]   The other thing that I think people may be getting their heads around, here's what's changed since
[00:46:14.520 --> 00:46:20.280]   last week. There's a growing body if I had to say like, you know, the beautiful thing about the markets
[00:46:20.580 --> 00:46:25.680]   is it is an extremely elegant voting mechanism in the short term, right? I mean, Buffett says it's,
[00:46:25.680 --> 00:46:30.120]   it's a voting machine in the short term and a weighing machine in the long term. But if you
[00:46:30.120 --> 00:46:36.660]   look at sentiment and how things are voted on in the public markets in real time, it's incredibly
[00:46:36.660 --> 00:46:43.080]   illustrative. So there's a body of people now that are voting a very different scenario than inflation.
[00:46:43.080 --> 00:46:50.340]   What they're voting for now is this idea that by the fall, a lot of this short term pent up demand will have
[00:46:50.340 --> 00:46:54.960]   worked its way through the system. And instead, we'll be back to this realization that we've had
[00:46:54.960 --> 00:46:59.160]   for the last 20 years, which is, hey, wait a minute, people don't actually want to buy more
[00:46:59.160 --> 00:47:03.240]   of these physical goods, they're going to go back to consuming the way they did before, it's going
[00:47:03.240 --> 00:47:07.800]   to reflexively push towards technology companies again, and we're going to have this rebirth of
[00:47:07.800 --> 00:47:13.500]   growth. And you would say, Well, how would you know that that vote is likely? And this one
[00:47:13.500 --> 00:47:17.940]   incredible thing happened this last week, which I just want to throw out here. One thing that I look
[00:47:17.940 --> 00:47:20.100]   at is this thing called 10 year break evens,
[00:47:20.100 --> 00:47:24.240]   which is basically a thing that the Federal Reserve of St. Louis publishes.
[00:47:24.240 --> 00:47:30.240]   And what it basically shows is like what people think collectively trillions of dollars, what the
[00:47:30.240 --> 00:47:37.680]   10 year break even interest rates going to be. And it peaked last week at 2.54%. And it's fallen 13
[00:47:37.680 --> 00:47:43.920]   basis points just in the last week down to 241. And I don't know whether it's sustained or whatever,
[00:47:43.920 --> 00:47:49.860]   but there is a growing idea that the worst may be behind us. And if you layer on top of this
[00:47:49.860 --> 00:47:58.440]   right now, Biden pulling back, right on stimulus, because he's can't get it done, pulling back on
[00:47:58.440 --> 00:48:04.680]   cap gains, pulling back on corporate taxation, and a more measured policy of investment.
[00:48:04.680 --> 00:48:07.020]   We could all be back.
[00:48:07.020 --> 00:48:12.240]   So we're basically taking the medicine and getting back to where we were. But we still
[00:48:12.240 --> 00:48:16.020]   have massive asset inflation, we're seeing in houses, cars and other things.
[00:48:16.020 --> 00:48:19.620]   Well, we may have just pulled forward demand, meaning, you know, people are like,
[00:48:19.620 --> 00:48:23.040]   okay, I'm flush with money, the savings rate in the United States has been, you know,
[00:48:23.040 --> 00:48:27.360]   going at an incredible clip, people may pull forward all that spending and say,
[00:48:27.360 --> 00:48:32.040]   I was going to buy a car 18 months from now, or I was going to buy a house two years from now.
[00:48:32.040 --> 00:48:36.720]   Fuck it, I'm going to do it now because prices are going up too fast, I don't want to miss out.
[00:48:36.720 --> 00:48:41.040]   But then they're out of the market now for the next many number of years. And this is
[00:48:41.040 --> 00:48:45.600]   what I'm saying where you see this short term spike of demand, and then things get back to
[00:48:45.600 --> 00:48:49.380]   normal. If that's what we see, good times are back in growth stock.
[00:48:49.380 --> 00:49:01.560]   I literally I did like two or three early stage deals recently. And I had members of my syndicate
[00:49:01.560 --> 00:49:06.420]   say like, how does this valuation make sense? And I said to them, you know, it actually doesn't make
[00:49:06.420 --> 00:49:11.460]   sense. If you're looking at it with the traditional metrics, but all valuations are higher at all
[00:49:11.460 --> 00:49:17.760]   stages. So I'm going to selectively you know, overpay compared to what we were paying a year or
[00:49:17.760 --> 00:49:18.260]   two ago.
[00:49:18.260 --> 00:49:23.900]   You know, if I really love a company, but I will sit out a lot of I'm sitting out a lot of rounds
[00:49:23.900 --> 00:49:28.340]   right now that I just can't get my head around the valuation. So hopefully some
[00:49:28.340 --> 00:49:32.600]   well, there's always a trickle down, there's always a trickle down from growth stocks in
[00:49:32.600 --> 00:49:38.060]   the public markets to venture, right? Because the last private investors like the big funds,
[00:49:38.060 --> 00:49:43.100]   who do the super late stage stuff, they're just doing an arbitrage on what they pay versus what
[00:49:43.100 --> 00:49:47.480]   the company is going to list for publicly. So when they see those valuations go down, they adjust,
[00:49:47.480 --> 00:49:48.020]   and then it works.
[00:49:48.020 --> 00:49:53.360]   It's way all the way down the stack. So you know, growth stocks have just been hammered,
[00:49:53.360 --> 00:49:58.820]   and especially all the recent listings, the IPOs and SPACs and everything. And,
[00:49:58.820 --> 00:50:02.060]   and that's going to trickle its way down, I think, to venture system.
[00:50:02.060 --> 00:50:05.960]   I think we have the Yeah, I think we have the lead indicator on that as Clubhouse,
[00:50:05.960 --> 00:50:09.920]   right, which will be the canary in the coal mine. I don't know how you guys reconcile
[00:50:09.920 --> 00:50:13.580]   explain, explain what's going on with clubhouse just for those of us explain what it is.
[00:50:13.580 --> 00:50:17.240]   Okay, so clubhouse is a casual audio space, you go into a room,
[00:50:17.240 --> 00:50:17.780]   and you're going to be able to get a lot of money out of it.
[00:50:17.780 --> 00:50:21.920]   And you're immediately taken to a live conversation with people speaking on stage
[00:50:21.920 --> 00:50:25.880]   and an audience audience members can be promoted to the stage and start talking.
[00:50:25.880 --> 00:50:30.380]   In a way, hold on, it's in an app. And it's an audio. So there's an audio,
[00:50:30.380 --> 00:50:32.420]   there's an app you go in, and it's all audio. Yes.
[00:50:32.420 --> 00:50:35.120]   So it's like amateur night at a strip club, but for words,
[00:50:35.120 --> 00:50:38.660]   or more comedy club, or whatever, you just bring public on stage. Yeah,
[00:50:38.660 --> 00:50:43.520]   it's kind of like a champagne room, but a little different. So anyway,
[00:50:43.520 --> 00:50:47.060]   there we go. More like the pod.
[00:50:47.060 --> 00:50:47.540]   Yeah.
[00:50:47.540 --> 00:50:52.640]   Apple 2000 signatures from Apple to remove all in from the podcasting app.
[00:50:52.640 --> 00:50:56.000]   We just lost three ranks in the Apple podcasting app.
[00:50:56.000 --> 00:51:03.380]   So what's very interesting about this app is that it had a massive number of downloads during the
[00:51:03.380 --> 00:51:06.860]   pandemic because people were home and people were not doing anything at night because they
[00:51:06.860 --> 00:51:13.880]   were sheltering in place. And they had in you know, 2 million downloads in January 9.5 million
[00:51:13.880 --> 00:51:17.300]   in February of this year and then came crashing down 2.7 million in in in the fall.
[00:51:17.300 --> 00:51:24.980]   And then in March and 922 in April, but at the same time, their valuation over 18 months went
[00:51:24.980 --> 00:51:31.160]   from 100 million in their seed when they had like three or 4000 users to a billion to 4 billion in
[00:51:31.160 --> 00:51:37.520]   the last round of financing for a company with zero revenue. And let's call it a couple of
[00:51:37.520 --> 00:51:42.140]   million people using the app. And what's really interesting is the same venture firm led all
[00:51:42.140 --> 00:51:46.400]   three rounds Allah Sequoia is investment in WhatsApp where they did all the private funding.
[00:51:46.400 --> 00:51:52.700]   So you have no outside capital marking this valuation a $4 billion valuation $4 billion.
[00:51:52.700 --> 00:51:57.680]   Well, they got a they got an acquisition offer from Twitter for 4 billion. And they they turned
[00:51:57.680 --> 00:52:04.040]   they confirmed I've heard it was real. So, so but so basically, the reason why the 4 billion private
[00:52:04.040 --> 00:52:08.540]   round happened was so that we keep going as an independent company. They could basically take
[00:52:08.540 --> 00:52:12.800]   some chips off the table through secondary and kind of go for the bigger outcome. But yeah,
[00:52:12.800 --> 00:52:16.160]   they could have just sold to Twitter for 4 billion. So, they may.
[00:52:16.160 --> 00:52:17.360]   They end up regretting that.
[00:52:17.360 --> 00:52:25.580]   But like, is this really a function of a broader inflation valuation inflation? Or is this just a
[00:52:25.580 --> 00:52:30.080]   function of there was a company that was a social network with hyper growth. And then it turns out
[00:52:30.080 --> 00:52:32.420]   that the product had no stickiness and the hyper growth went away.
[00:52:32.420 --> 00:52:33.920]   The souffle collapsed.
[00:52:33.920 --> 00:52:35.120]   The souffle collapsed.
[00:52:35.120 --> 00:52:40.640]   Can I can I can I just point out like and forgive me if any, any of you guys are investors in this
[00:52:40.640 --> 00:52:45.920]   company or anyone that's listening cares. But like if this thing came out before,
[00:52:45.920 --> 00:52:51.380]   YouTube, people would say, you know, this is interesting, but it needs an asynchronous killer.
[00:52:51.380 --> 00:52:55.280]   It needs a thing where you can like record a conversation posted online, and people can come
[00:52:55.280 --> 00:52:59.540]   and watch it and listen to it when they want. It was always so crazy to me that you had to be logged
[00:52:59.540 --> 00:53:03.500]   into the app to listen to what was going on. And if you didn't, you missed the conversation. And
[00:53:03.500 --> 00:53:07.880]   there was no way to like, go watch the recording of the conversation. Like, am I crazy to think
[00:53:07.880 --> 00:53:12.740]   that this was just like, I think you nailed it that they don't have a sink in there. And actually,
[00:53:12.740 --> 00:53:15.680]   I've got a little disclosure to make here. Oh,
[00:53:15.680 --> 00:53:21.020]   what? What? The beat got wet. But it's
[00:53:21.020 --> 00:53:29.840]   breaking news story. Okay, so I think I understand what clubhouse did wrong. Async is a huge part of
[00:53:29.840 --> 00:53:35.000]   it. But rather than tell you exactly I'm going to show you because I've been incubating a new
[00:53:35.000 --> 00:53:44.720]   lot that we're on test flight right now. And you guys after this pod, I can I can demo it for you.
[00:53:44.720 --> 00:53:49.280]   And if you guys if you guys want to invest, I'm going to close around this week for
[00:53:49.280 --> 00:53:53.540]   each getting wet. And so if you guys want to evaluate what's the value? What's our insider
[00:53:53.540 --> 00:53:57.500]   all in? What's the bestie Val? Yeah, what's the bestie? I'll talk to you guys offline.
[00:53:57.500 --> 00:53:59.360]   How much? How much money do you want to raise?
[00:53:59.360 --> 00:54:03.860]   We're already we're raising 10 million bucks and we already have commitments and but I'm creating
[00:54:03.860 --> 00:54:11.420]   room for you guys. Yeah. 500k each. Sounds like 500k each. Where is it? Let's talk about it offline.
[00:54:11.420 --> 00:54:14.480]   But but the apps on test flight, I think we'll be ready to launch in a few weeks.
[00:54:14.480 --> 00:54:16.640]   Can I can I say what's it called?
[00:54:16.640 --> 00:54:20.840]   Can you say? Yeah, no, I'll say it. It's called call in.
[00:54:20.840 --> 00:54:21.980]   Call in.
[00:54:21.980 --> 00:54:22.760]   Call in.
[00:54:22.760 --> 00:54:25.940]   I thought it was I thought it was going to be called glove mouse.
[00:54:25.940 --> 00:54:30.920]   Does this have a podcast?
[00:54:30.920 --> 00:54:33.860]   Yeah. Like are we going to do the podcast on it?
[00:54:33.860 --> 00:54:38.180]   We absolutely could do the podcast on it. And it would be awesome. Nick would be out of a job. So
[00:54:38.180 --> 00:54:41.840]   I don't think he would like that too much. But I think it's good for call ins. If we wanted to do
[00:54:41.840 --> 00:54:44.240]   a call in show, it would be good for that. Yes. It'd be great. It'd be great. It'd be great.
[00:54:44.240 --> 00:54:48.980]   It'd be great to do exactly. That's why it's called call in is because the ability for you
[00:54:48.980 --> 00:54:54.860]   to take callers is obviously a huge feature. But also like we could host after parties for
[00:54:54.860 --> 00:54:58.820]   our fans to like, you know, chop up the latest episode and talk about it.
[00:54:58.820 --> 00:55:03.020]   Yeah, these fans are getting crazy. Do you guys see the all in stats, Twitter handle?
[00:55:03.020 --> 00:55:07.100]   I don't know the Twitter handle off the top of my head. But somebody's these kids are doing
[00:55:07.100 --> 00:55:14.000]   they're using machine learning or something to know what percentage
[00:55:14.000 --> 00:55:18.140]   of time we each speak on the pod and how many monologues and they're doing all these statistics.
[00:55:18.140 --> 00:55:23.600]   It's crazy. That's really cool. I was gonna say, in defense of clubhouse for a second,
[00:55:23.600 --> 00:55:28.760]   I don't I don't know the app per se. But I think like, why Andreessen did all of that,
[00:55:28.760 --> 00:55:33.020]   in my opinion, is because they're pressing a hot hand, which makes a ton of sense from
[00:55:33.020 --> 00:55:36.620]   their perspective. It's like, you know, I think that they're going for the kill shot,
[00:55:36.620 --> 00:55:42.380]   because I think they're basically set up. They're basically set up to become Sequoia if they really,
[00:55:42.380 --> 00:55:43.760]   I mean, I think, if you think about it, I think they're going for the kill shot, because I think,
[00:55:43.760 --> 00:55:48.740]   if you think about like, which two firms are really crushing on all cylinders right now,
[00:55:48.740 --> 00:55:53.840]   obviously, Sequoia has always been the perennial number one. But if you think about the heater
[00:55:53.840 --> 00:55:59.180]   that Andreessen is on, it's incredible. And so from their perspective, the $4 billion valuation
[00:55:59.180 --> 00:56:03.800]   is less important than what is their real capital at risk. And that's probably 100 or 150 million,
[00:56:03.800 --> 00:56:09.020]   which in the grand scheme of having 40 or $50 billion of AUM, if you consider the value of
[00:56:09.020 --> 00:56:13.520]   all their public positions as well, that's a really reasonable risk to take. So I think
[00:56:13.520 --> 00:56:17.180]   that's a really good view. And that way, it's kind of like, they're taking a shot to try to just,
[00:56:17.180 --> 00:56:21.020]   you know, go for it. If it does become worth 10 billion or 50 billion. Also,
[00:56:21.020 --> 00:56:26.000]   if it only gets sold for 500 million, they get their money out first. So what does it matter?
[00:56:26.000 --> 00:56:28.760]   What does it matter? They're going for the $100 billion outcome. I mean,
[00:56:28.760 --> 00:56:33.680]   they've seen that Instagram sold too soon. They saw that Snap turned down a $3 billion
[00:56:33.680 --> 00:56:37.520]   offer from Facebook, and now it's worth 80 billion. So they're going for the $100 billion.
[00:56:37.520 --> 00:56:38.900]   YouTube, 1.6 billion.
[00:56:38.900 --> 00:56:42.620]   Yeah, and now it's worth hundreds of billions. So they're hoping it's going to be like that.
[00:56:43.280 --> 00:56:48.380]   But Chamath is right. Look, if they had taken, what, say 20% of a $4 billion outcome,
[00:56:48.380 --> 00:56:53.360]   800 million, that doesn't even pay back their fund, right? But if it ends up being $100 billion
[00:56:53.360 --> 00:56:56.960]   outcome, they make 20 billion. Now it's like a Coinbase for them.
[00:56:56.960 --> 00:56:59.480]   What do you think they gave to the founders?
[00:56:59.480 --> 00:57:00.980]   Well, who knows?
[00:57:00.980 --> 00:57:04.040]   To keep them in the game, because 4 billion, if they owned 80%.
[00:57:04.040 --> 00:57:07.940]   Yeah, they took chips off the table. But here's the thing,
[00:57:07.940 --> 00:57:13.040]   all those decisions were made before the recent collapse and engagement at Clubhouse. I'm
[00:57:13.040 --> 00:57:18.860]   not sure anybody would be paying 4 billion for it now, given everything that's gone wrong. But
[00:57:18.860 --> 00:57:20.900]   you know, who knows? It's still pretty early.
[00:57:20.900 --> 00:57:27.980]   And just for people who are curious, there is a Twitter handle, allin_stats. And yeah,
[00:57:27.980 --> 00:57:34.460]   it's allinstats.com. I don't know. We're not affiliated with these maniacs, but we love the
[00:57:34.460 --> 00:57:39.020]   stands, and we're going to do something in person in September. Congratulations to the stands for
[00:57:39.020 --> 00:57:42.800]   losing their minds. I think it's a pretty good way for them to capture
[00:57:42.800 --> 00:57:52.220]   a bunch of attention on the Twitter. All right. Crypto is getting absolutely hammered. And the
[00:57:52.220 --> 00:57:57.440]   Chinese have once again said that they're basically saber rattling about cryptocurrency.
[00:57:57.440 --> 00:57:59.180]   They're obviously going to do their own crypto.
[00:57:59.180 --> 00:58:05.420]   Jason, I think you have to talk about China in a slightly broader lens than just what's happening
[00:58:05.420 --> 00:58:11.720]   in crypto, because this is the same week where they basically forced Zhang Yiming to resign from
[00:58:12.560 --> 00:58:17.720]   the dance. I mean, you know, last week, it was or last month, it was the CEO pin duo duo.
[00:58:17.720 --> 00:58:19.340]   And Jack Ma's MIA.
[00:58:19.340 --> 00:58:21.800]   They're going for the jugular. I mean, it's like,
[00:58:21.800 --> 00:58:26.780]   we're what why are they taking out all their top CEOs? This would be like putting Elon and
[00:58:26.780 --> 00:58:30.920]   Jeff Bezos on the bench? Is it they just don't want any heroes?
[00:58:30.920 --> 00:58:34.580]   I don't know. I mean, I guess maybe the speculative part of me would say,
[00:58:34.580 --> 00:58:37.460]   they're showing them who's really in charge of these companies.
[00:58:37.460 --> 00:58:42.320]   I mean, it would be crazy to your point, if the government of the United
[00:58:42.320 --> 00:58:49.460]   States forced Sundar Pichai and Tim Cook and Mark Zuckerberg and Elon Musk to resign. It's like,
[00:58:49.460 --> 00:58:54.440]   hey, sorry, I'm sorry, you need to leave right now and put somebody else in and deactivate their
[00:58:54.440 --> 00:58:54.800]   badges.
[00:58:54.800 --> 00:58:59.540]   Yeah, we just we just relentlessly criticize them. Right. But But yeah,
[00:58:59.540 --> 00:59:02.960]   we just demonize them. Just try to cancel them.
[00:59:02.960 --> 00:59:06.740]   But look, but they deserve that level of scrutiny because the amount of power they have. But But
[00:59:06.740 --> 00:59:11.360]   yeah, that we don't we don't put them in jail or house arrest or drive them out of their companies.
[00:59:11.360 --> 00:59:12.080]   And that is a
[00:59:12.080 --> 00:59:13.580]   big advantage for the US economy.
[00:59:13.580 --> 00:59:18.140]   The Treasury Department here in the United States is doing a little saber rattling,
[00:59:18.140 --> 00:59:24.860]   they want to know anytime there is a $10,000 transaction in any kind of digital token. And
[00:59:24.860 --> 00:59:30.380]   they're talking about a CBDC to do their own cryptocurrency. So they're putting out a white
[00:59:30.380 --> 00:59:40.880]   paper for feedback this summer. And we are now seeing a pullback on Bitcoin from mid 60s to now
[00:59:40.880 --> 00:59:41.840]   into the 36 36.
[00:59:41.840 --> 00:59:47.780]   37,000 per Bitcoin. Do you think this is the end of the beginning beginning of the end?
[00:59:47.780 --> 00:59:54.800]   It's the beginning of the beginning. David Rubenstein was on CNBC today. And David Rubenstein,
[00:59:54.800 --> 00:59:59.240]   for those you guys don't know, is was a co founder of Carlisle group, you know,
[00:59:59.240 --> 01:00:05.000]   more blue chip and blue blooded, you cannot get and very connected in Washington. And you know,
[01:00:05.000 --> 01:00:10.580]   he said it best where he said, you know, effectively, people want this, and the government
[01:00:10.580 --> 01:00:11.240]   will,
[01:00:11.240 --> 01:00:11.600]   uh,
[01:00:11.600 --> 01:00:16.940]   have no choice except to support it, because you can't take something like this with this much
[01:00:16.940 --> 01:00:23.660]   institutional and retail demand away. So we have to go to the place where now crypto needs to be
[01:00:23.660 --> 01:00:27.500]   like everything else. And maybe the crypto stands get upset with that, because they don't like it,
[01:00:27.500 --> 01:00:31.400]   that, you know, a bunch of their parents are all of a sudden going to be buying tokens and stuff,
[01:00:31.400 --> 01:00:36.200]   but they got to get over it, then this stuff should be, you know, transacted in the same
[01:00:36.200 --> 01:00:40.820]   way you transact anything else, you buy it, you sell it, you get a tax return, you pay your taxes,
[01:00:40.820 --> 01:00:41.360]   and you move on.
[01:00:41.360 --> 01:00:45.500]   This reminds me of the transition that we all went through with I don't know,
[01:00:45.500 --> 01:00:52.520]   if you remember Kazaa and Napster and BitTorrent, like, everybody, all the we, a lot of our
[01:00:52.520 --> 01:00:57.260]   contemporaries in their 30s, you know, whatever, 1020 years ago, we're like, you can't stop it,
[01:00:57.260 --> 01:01:01.640]   you can't stop it. And it got stopped. You know, like you made it illegal,
[01:01:01.640 --> 01:01:06.260]   and you prosecuted people. And then you came up with solutions that were regulated,
[01:01:06.260 --> 01:01:11.120]   like Spotify, or, you know, Netflix, and you gave the consumers what they wanted. So,
[01:01:11.120 --> 01:01:15.380]   David, do you think this is a similar path right now that we're going through,
[01:01:15.380 --> 01:01:22.460]   which is the crypto zealots and the and the and the stands are gonna basically have to get used
[01:01:22.460 --> 01:01:26.420]   to as Chamath saying their parents buying it and crypto not being this underground thing,
[01:01:26.420 --> 01:01:30.080]   but being regulated in a major way in the United States? And is that a good or bad thing?
[01:01:30.080 --> 01:01:34.340]   I think the thing that that's happening quietly behind the scenes is that major
[01:01:34.340 --> 01:01:40.880]   Wall Street players, institutions, endowments, and so forth, over the past year have decided that
[01:01:40.880 --> 01:01:46.340]   Bitcoin and crypto is a legitimate asset class, and they've been allocating to it. Huge, huge
[01:01:46.340 --> 01:01:51.560]   pools of capital balance sheet capital have been allocating into it. I don't think that's gonna
[01:01:51.560 --> 01:01:56.840]   change. This is probably a pretty good buying opportunity. We've seen these crashes and Bitcoin
[01:01:56.840 --> 01:02:02.600]   many, many times over the years, it plummets down, and then it goes back up, and it eventually goes
[01:02:02.600 --> 01:02:06.620]   back up reaches a new peak. So this is probably a pretty good entry point for the next rally.
[01:02:06.620 --> 01:02:10.160]   We don't know when that's going to be. But the whole point of Bitcoin is that,
[01:02:10.640 --> 01:02:16.340]   it's censorship resistant. And China can do its best to try and stamp it out. But I don't think
[01:02:16.340 --> 01:02:22.220]   they'll be successful at that. You don't? You're so wrong about that. That is the most naive take,
[01:02:22.220 --> 01:02:24.980]   worst take you've ever had. How's China going to stop Bitcoin?
[01:02:24.980 --> 01:02:28.940]   How do they stop VPNs? They put people in jail. How do they stop religion? They put people in
[01:02:28.940 --> 01:02:34.040]   jail. They may make it incredibly hard for Chinese citizens to get a hold of Bitcoin. I agree with
[01:02:34.040 --> 01:02:38.300]   that. But they're not gonna be able to stop Bitcoin. They're not going to stop Bitcoin in
[01:02:38.300 --> 01:02:40.400]   the West, but they will stop it in China. Yeah.
[01:02:40.400 --> 01:02:45.500]   They will. 100% full stop. And you know how many servers are in China? I mean,
[01:02:45.500 --> 01:02:48.500]   go talk to the people who were in Tiananmen Square about what happened.
[01:02:48.500 --> 01:02:50.540]   The miners will have to move out. The miners will have to move out.
[01:02:50.540 --> 01:02:54.440]   Miners are done. And then it'll be an underground thing. It'll be like having a VPN,
[01:02:54.440 --> 01:02:59.180]   which is five years in jail for selling VPNs. What do you think about the IRS requirement
[01:02:59.180 --> 01:03:04.700]   that you have to report any Bitcoin transaction over $10,000? Do you think that that, and
[01:03:04.700 --> 01:03:10.160]   Americans can be prosecuted for not reporting, right? So I don't know how much.
[01:03:10.160 --> 01:03:11.660]   Good. Fine. Good. So what?
[01:03:11.660 --> 01:03:12.500]   Do it. So what?
[01:03:12.500 --> 01:03:17.420]   Yes. Get over it. But I do think that will get rid of 20% of the transactions that might have been
[01:03:17.420 --> 01:03:23.300]   nefarious. No, this is the Silk Road fallacy that the only legitimate use for crypto or.
[01:03:23.300 --> 01:03:24.920]   Well, I said 20%. I didn't say only.
[01:03:24.920 --> 01:03:30.620]   Okay, fine. But so maybe it makes that small fraction of illegitimate or illicit use cases.
[01:03:30.620 --> 01:03:31.700]   Yeah. Hard to define.
[01:03:31.700 --> 01:03:35.660]   No, Sax, I think the point is that they're trying to chase down. It's
[01:03:35.660 --> 01:03:39.920]   not about illegal use cases. It's about not reporting a taxable gain on your Bitcoin,
[01:03:39.920 --> 01:03:42.020]   before you use that money to buy something.
[01:03:42.020 --> 01:03:48.080]   Sure, of course, it's about tax evasion. But look, but that's not going to stop Bitcoin usage.
[01:03:48.080 --> 01:03:54.620]   Smart people who've been trading Bitcoin have been paying taxes on it for years. I don't think
[01:03:54.620 --> 01:03:58.700]   that's really an issue. If you were in China and you had created your wealth in China or many,
[01:03:58.700 --> 01:04:02.660]   many other countries all over the world, and there were currency restrictions and controls,
[01:04:02.660 --> 01:04:04.640]   and the government was asserting more and more power,
[01:04:04.640 --> 01:04:09.680]   and we're putting business leaders under house arrest and seeking to put them under
[01:04:09.680 --> 01:04:14.480]   their thumb, you'd be trying to convert as much of your net worth into Bitcoin as possible,
[01:04:14.480 --> 01:04:20.060]   so that all you have to do is if you ever had to flee the country, you wouldn't have to have dollars
[01:04:20.060 --> 01:04:25.040]   in your suitcase or gold bricks or diamonds. You'd simply have to have a password in your
[01:04:25.040 --> 01:04:29.360]   brain that you could access at any computer terminal when you got out of the country.
[01:04:29.360 --> 01:04:35.660]   And so that I think that sort of digital gold is a phenomenal use case of Bitcoin.
[01:04:35.660 --> 01:04:39.440]   And the more oppressive all these countries become, the more they
[01:04:39.440 --> 01:04:42.980]   increase the value of that use case. What do you think is the black swan event
[01:04:42.980 --> 01:04:49.280]   in crypto, in Bitcoin in particular? Taxation in the United States.
[01:04:49.280 --> 01:04:50.420]   There's a negative.
[01:04:50.420 --> 01:04:55.220]   Additional taxation like you do on cigarettes, that would be for me. The United States putting
[01:04:55.220 --> 01:05:01.340]   a tax on it that makes it less competitive with our national coming cryptocurrency,
[01:05:01.340 --> 01:05:04.880]   the CBDC that the United States will launch in the next two or three years.
[01:05:04.880 --> 01:05:09.200]   They're going to say, "If you want to use any of these other currencies, there's a 10% tax
[01:05:09.200 --> 01:05:12.260]   on them. We want you using ours, the legitimate one."
[01:05:12.260 --> 01:05:18.380]   There's a very negative black swan that obviously has never occurred. But if anyone
[01:05:18.380 --> 01:05:22.820]   ever manages to counterfeit a Bitcoin, or this is the double spend problem,
[01:05:22.820 --> 01:05:28.880]   right? If you could ever double spend or figure out a way to create Bitcoins or counterfeit them,
[01:05:28.880 --> 01:05:32.780]   whatever, that weren't in the blockchain, if the number of Bitcoins ever grew beyond the
[01:05:32.780 --> 01:05:38.720]   21 million that's just built into the way that the whole thing works, if that ever happened, Bitcoin is
[01:05:38.720 --> 01:05:38.960]   instantly worth it. Yeah.
[01:05:38.960 --> 01:05:43.880]   That would be the black swan on the negative side. I think the black swan on the positive.
[01:05:43.880 --> 01:05:47.780]   If it didn't happen in the first 11 years, what do you think the like is it on a percentage basis
[01:05:47.780 --> 01:05:50.120]   that it happens in the 20th? Exactly.
[01:05:50.120 --> 01:05:54.680]   It's too expensive now. And it's too visible. The way that it would have happened,
[01:05:54.680 --> 01:05:56.420]   it would have happened in the first two or three years.
[01:05:56.420 --> 01:05:59.660]   Or the argument could be maybe opposite, that now it's so valuable that it's worth
[01:05:59.660 --> 01:06:01.280]   investing to figure out how to- It's a bigger target.
[01:06:01.280 --> 01:06:01.580]   Yeah.
[01:06:01.580 --> 01:06:05.780]   Yeah. And rather than have it be about a diminishing probability,
[01:06:05.780 --> 01:06:08.720]   it could be an increasing probability over time, which is,
[01:06:08.720 --> 01:06:13.640]   is that the pathways to get there start to get resolved. Whereas in the past,
[01:06:13.640 --> 01:06:15.740]   you didn't have enough time to resolve those pathways.
[01:06:15.740 --> 01:06:17.120]   It would have to be- And I'm speaking highly
[01:06:17.120 --> 01:06:19.040]   theoretical here, but like certainly there's a lot of technical-
[01:06:19.040 --> 01:06:22.940]   That doesn't take into account that it's open source and that everybody can see it. So
[01:06:22.940 --> 01:06:26.840]   you would think that everybody would discover the vulnerability at the same time, right? In
[01:06:26.840 --> 01:06:29.600]   an open source project? Well, no, I think the issue,
[01:06:29.600 --> 01:06:34.220]   practically speaking, in this would be that you would see those resources getting organized,
[01:06:34.220 --> 01:06:38.480]   meaning you'd see silicon being bought in volume by some,
[01:06:38.480 --> 01:06:42.980]   centralized player, and then you'd have to see water and power come together as well.
[01:06:42.980 --> 01:06:48.140]   And this is where I think it's just not realistic, where today that I think the horse has left the
[01:06:48.140 --> 01:06:52.880]   barn because if you try to basically capture enough hash rate to kind of like overpower this
[01:06:52.880 --> 01:07:00.680]   network, it's like the scene in Austin Powers where he's screaming in front of a steamroller,
[01:07:00.680 --> 01:07:03.620]   but the steamroller is moving at like one foot a minute.
[01:07:03.620 --> 01:07:04.820]   Right. You'd see it coming.
[01:07:04.820 --> 01:07:06.740]   It's just like, you just see it coming.
[01:07:06.740 --> 01:07:08.240]   Well, would you have a black Swan, Friedberg?
[01:07:08.240 --> 01:07:10.400]   You asked a lot of questions. So do you have one?
[01:07:10.400 --> 01:07:15.020]   I think about it a lot. I don't really, I mean, it's a black Swan. It's because it's a black Swan,
[01:07:15.020 --> 01:07:20.180]   so you don't really see it coming. But like, you know, the thing about Bitcoin,
[01:07:20.180 --> 01:07:24.200]   which has always given me pause,
[01:07:24.200 --> 01:07:32.000]   is the fact that the only way it works is if everyone believes that more people are going
[01:07:32.000 --> 01:07:35.960]   to believe in it tomorrow than believe in it today. Well, that's the only way it appreciates.
[01:07:35.960 --> 01:07:38.000]   Yeah. But
[01:07:38.000 --> 01:07:42.920]   for a variety of reasons, it's also the only way that it works because
[01:07:42.920 --> 01:07:48.860]   if it starts to depreciate, it becomes almost like this unwinding circumstance. And there
[01:07:48.860 --> 01:07:51.380]   are moments where it unwinds, but then people kind of say, well, you know what,
[01:07:51.380 --> 01:07:54.680]   more people are going to get on this. There's the Chinese argument. There's the Argentinian argument.
[01:07:54.680 --> 01:08:00.680]   There's all the reasons why people will try and store wealth in this system. And that becomes a
[01:08:00.680 --> 01:08:06.320]   rationale for continuing to bet on it. And my observation is so many people that are active in
[01:08:06.320 --> 01:08:07.760]   Bitcoin compare Bitcoin to Bitcoin. And I think that's a very important thing. And I think that's
[01:08:07.760 --> 01:08:12.540]   Bitcoin to the price of the dollar, which to me seems like it doesn't make sense relative
[01:08:12.540 --> 01:08:18.120]   to the intention of Bitcoin, which is to not be part of the monetary system that uses the
[01:08:18.120 --> 01:08:24.680]   dollar. It's kind of a de facto, you know, system of value. And so why have the comparison
[01:08:24.680 --> 01:08:30.400]   to the dollar? As the objective for Bitcoin? Why is the objective not transactions, use
[01:08:30.400 --> 01:08:34.180]   cases, number of people that are active on the network, etc, etc.
[01:08:34.180 --> 01:08:38.420]   And nobody buying it is buying it as a substitute for dollars. They're buying it as a lottery
[01:08:38.420 --> 01:08:38.680]   ticket.
[01:08:38.680 --> 01:08:42.740]   So yeah, that's, that's right. And so then it becomes this rationale that it's like it's
[01:08:42.740 --> 01:08:48.020]   an investment that you put money in, in the form of dollars or your local currency, with
[01:08:48.020 --> 01:08:51.740]   the intention that you will be able to get more of your local currency out at some point
[01:08:51.740 --> 01:08:54.740]   in the future. And the only way that works is if you expect someone else will buy it
[01:08:54.740 --> 01:08:58.900]   from you at a higher price in the future. Therefore, it's all about propagating the,
[01:08:58.900 --> 01:09:03.000]   you know, the marketing around the Bitcoin. Whereas if your objective was really about
[01:09:03.000 --> 01:09:03.900]   making this become a replacement.
[01:09:03.900 --> 01:09:09.340]   A replacement currency system or replacement monetary system, you would ultimately care
[01:09:09.340 --> 01:09:12.880]   less about, you know, what's the dollar value per coin, and you would care more about how
[01:09:12.880 --> 01:09:15.120]   many people are using it, you know, how active
[01:09:15.120 --> 01:09:23.140]   let me build on that question. So sacks or Chamath, if the CBDC, and Americans currency,
[01:09:23.140 --> 01:09:28.600]   you know, starts to move towards a Bitcoin blockchain like experience, what would America
[01:09:28.600 --> 01:09:33.800]   start to look like if 10 or 20% of your dollars, instead of being held in a bank, we're on
[01:09:33.800 --> 01:09:35.800]   a blockchain with an American
[01:09:35.800 --> 01:09:41.220]   government, a government backed blockchain doesn't accomplish anything, it's still that
[01:09:41.220 --> 01:09:46.400]   people are it centralized, and not only is it centralized, but also, it's still prone
[01:09:46.400 --> 01:09:52.860]   to debasement. Right? Yeah. And so look, human beings have used everything from gold coins
[01:09:52.860 --> 01:09:57.960]   to seashells as money, we can make anything money that's easy to transact if we all agree
[01:09:57.960 --> 01:10:02.260]   on it. That's the sense in which Bitcoin is the bubble that becomes true. If everyone
[01:10:02.260 --> 01:10:07.060]   believes in it, provided provided the number of bitcoins today 21 million, and that the
[01:10:07.060 --> 01:10:12.120]   technology enforces the scarcity. The problem we have with the US dollar is the government
[01:10:12.120 --> 01:10:13.720]   can just print as many of them as they want.
[01:10:13.720 --> 01:10:19.320]   Yeah, you can nominate her. Yeah. And so I think there's a positive black swan as well
[01:10:19.320 --> 01:10:24.800]   for positive for Bitcoin, which is Stanley Druckenmiller thinks in the next 15 years,
[01:10:24.800 --> 01:10:27.160]   the US dollar will no longer be the world's reserve currency. Well, what's going to replace it?
[01:10:27.160 --> 01:10:35.320]   The positive black swan would be that Bitcoin becomes, if not the a world reserve currency,
[01:10:35.320 --> 01:10:42.100]   an unofficial world reserve currency. Why? Because people trust it. They trust the decentralization
[01:10:42.100 --> 01:10:46.280]   more than they trust any government. And that would that would be a big flip.
[01:10:46.280 --> 01:10:52.020]   Is that in is the United States and China? Are they going to let Bitcoin become the world's
[01:10:52.020 --> 01:10:57.160]   reserve currency? Well, it's not a choice that they have. You sure? So, yeah, I'm not
[01:10:57.160 --> 01:11:02.200]   Yeah. There's nothing they can do. What about the law? And guns
[01:11:02.200 --> 01:11:03.520]   and jail and tax?
[01:11:03.520 --> 01:11:06.040]   I don't I don't know what that means. There's there's nothing
[01:11:06.040 --> 01:11:07.900]   that they could there was nothing that they could do to
[01:11:07.900 --> 01:11:10.120]   stop it before there's nothing that they can do to stop it
[01:11:10.120 --> 01:11:10.540]   now.
[01:11:10.540 --> 01:11:13.820]   Well, you can't get the New York Times in China and you can't
[01:11:13.820 --> 01:11:15.820]   practice religion there. So they have a pretty easy system.
[01:11:15.820 --> 01:11:18.080]   They put you in jail, they want to stop Bitcoin, they could just
[01:11:18.080 --> 01:11:23.200]   put you in jail. How, by finding out that you have Bitcoin? And
[01:11:23.260 --> 01:11:27.740]   how just well, because they have 100% view into the internet
[01:11:27.740 --> 01:11:30.820]   there. They have how on because they have routers. That's how
[01:11:30.820 --> 01:11:33.940]   they capture all the Uyghurs is they know their location,
[01:11:33.940 --> 01:11:36.400]   because they have mobile phones. And when they use signal or any
[01:11:36.400 --> 01:11:39.400]   other encrypted technology, they catch them. No, I don't I don't
[01:11:39.400 --> 01:11:41.840]   think that's how it works. But that's how they catch all the
[01:11:41.840 --> 01:11:44.840]   dissidents there is they they have them. And they also have
[01:11:44.840 --> 01:11:48.520]   Apple's entire center is controlled by the Chinese
[01:11:48.520 --> 01:11:49.060]   government.
[01:11:49.060 --> 01:11:52.480]   There's no ledger somewhere that says this specific wallet
[01:11:52.480 --> 01:11:53.020]   address.
[01:11:53.020 --> 01:11:53.080]   Equal.
[01:11:53.080 --> 01:11:55.960]   Equals David Sachs, and there's not going to be one anytime
[01:11:55.960 --> 01:12:00.040]   soon. And so you'll have these centralized wallet authorities
[01:12:00.040 --> 01:12:03.220]   that actually, you know, have a lot of account information. But
[01:12:03.220 --> 01:12:07.420]   the reality is the sophisticated actors, you know, use tumblers,
[01:12:07.420 --> 01:12:11.080]   they they wash sort of like their, their paths in a way
[01:12:11.080 --> 01:12:13.000]   where it's very difficult to figure out who these people are.
[01:12:13.000 --> 01:12:16.300]   Now, if you if you don't, if you use a site that doesn't have
[01:12:16.300 --> 01:12:19.600]   KYC, that's always going to be the case. And, you know, people
[01:12:19.600 --> 01:12:22.540]   with huge amounts of Bitcoin are sophisticated enough to know how
[01:12:22.540 --> 01:12:23.040]   to stay anonymous.
[01:12:23.040 --> 01:12:26.880]   If they want to, for everybody else who doesn't care, because
[01:12:26.880 --> 01:12:29.580]   for them, it's sort of an investment asset class, and an,
[01:12:29.580 --> 01:12:33.900]   you know, a hedge, then they're not going to care either. And
[01:12:33.900 --> 01:12:37.320]   the point is, when enough people own it, governments aren't in a
[01:12:37.320 --> 01:12:40.440]   position to track record of them just waking up one day and
[01:12:40.440 --> 01:12:43.680]   pulling the plug on anything is zero. That's not how people do
[01:12:43.680 --> 01:12:47.040]   things. You have to have like centralized policy and support.
[01:12:47.040 --> 01:12:50.340]   And I don't see it one way or the other of all the things that
[01:12:50.340 --> 01:12:52.860]   China and the United States will face over the next 30 or 40 years
[01:12:52.860 --> 01:12:55.560]   this is like 50th on the list.
[01:12:55.560 --> 01:12:59.940]   Sachs, what do you think? Any closing thoughts?
[01:12:59.940 --> 01:13:05.520]   I mean, I think we've said it. So yeah, I mean, look, I think I
[01:13:05.520 --> 01:13:07.320]   think if you're going to stay in a place like the United States,
[01:13:07.320 --> 01:13:09.600]   you need to comply with tax law, you're absolutely going to
[01:13:09.600 --> 01:13:12.240]   report your Bitcoin holdings if it's required. But if the reason
[01:13:12.240 --> 01:13:15.540]   you're buying Bitcoin is because you're fleeing a country, or
[01:13:15.540 --> 01:13:17.760]   you're worried about fleeing a country, you're obviously not
[01:13:17.760 --> 01:13:21.600]   going to report it. And that's the advantage of it is that it's
[01:13:21.600 --> 01:13:22.200]   a portable
[01:13:22.200 --> 01:13:27.540]   money supply. That again, you can just, you don't have to carry
[01:13:27.540 --> 01:13:30.480]   anything with you. You just put a password in your brain wallet.
[01:13:30.480 --> 01:13:33.000]   Tell me about UFOs before we leave. I mean, can you believe
[01:13:33.000 --> 01:13:36.300]   this thing? This is the craziest thing I read.
[01:13:36.300 --> 01:13:39.660]   Yeah, there's a 60 minutes episode that just happened.
[01:13:39.660 --> 01:13:43.140]   Deputy Assistant Secretary of Defense for intelligence literally
[01:13:43.140 --> 01:13:46.440]   said, the crafts we're seeing are and then in quotes, far
[01:13:46.440 --> 01:13:49.260]   beyond anything that we're capable of. There's nothing we
[01:13:49.260 --> 01:13:52.020]   could build that would be strong enough to endure the amount of
[01:13:52.020 --> 01:13:55.260]   force and acceleration. Imagine a technology that can do 700 g
[01:13:55.260 --> 01:13:59.820]   forces flight 13 miles per hour, evade radar, and has every no
[01:13:59.820 --> 01:14:03.120]   obvious signs of propulsion and yet can clearly defy the effects
[01:14:03.120 --> 01:14:05.760]   of Earth's gravity. That's precisely what we're seeing from
[01:14:05.760 --> 01:14:07.860]   the director of advanced aerospace threat identification
[01:14:07.860 --> 01:14:11.160]   program. I mean, is this real? Like how is what what are we
[01:14:11.160 --> 01:14:14.640]   doing? What? Our government says there are crafts that out trip
[01:14:14.640 --> 01:14:17.460]   our arsenal by at least 100 years to 1000 years at the
[01:14:17.460 --> 01:14:21.240]   moment. And we're like, man, what do you think Friedberg?
[01:14:21.240 --> 01:14:21.840]   You're the scientist.
[01:14:21.840 --> 01:14:24.900]   I'm the scientist here. There's a if you read the original
[01:14:24.900 --> 01:14:31.320]   treatment written by Arthur Clark for the movie 2001, a space Odyssey,
[01:14:31.320 --> 01:14:34.740]   which was written before the movie, and then the book was written after the movie.
[01:14:34.740 --> 01:14:43.200]   He makes a really compelling point. And the point he makes is that when civilizations achieve
[01:14:43.200 --> 01:14:46.980]   a sophisticated enough level of technology,
[01:14:46.980 --> 01:14:51.660]   there's no longer a need to physically transport yourself from star to star.
[01:14:51.660 --> 01:14:55.560]   And transport yourself around the universe. Think about this for a second.
[01:14:55.560 --> 01:15:02.520]   Take what we have from virtual reality today, and fast forward 200 years. And then take what
[01:15:02.520 --> 01:15:06.780]   we have in terms of you know, the ability to print and create anything we want on demand
[01:15:06.780 --> 01:15:12.780]   and fast forward two or 300 years. Those two conditions alone might give us the ability to
[01:15:12.780 --> 01:15:18.840]   strap on something to our brain. And literally, remember, our brain is simply sensing what our
[01:15:18.840 --> 01:15:21.480]   body is given. And if you can control what your brain is sensing, you can control what your brain
[01:15:21.480 --> 01:15:25.380]   is sensing through some strap on device or whatever, you don't actually need to physically
[01:15:25.380 --> 01:15:29.940]   be in the place where that happens. So if we can remotely sense what's going on somewhere
[01:15:29.940 --> 01:15:34.560]   else in the universe or some other part of our planet, and we can remotely pick up those signals
[01:15:34.560 --> 01:15:38.940]   and view them or experience them, you don't need to physically be there. And then secondly,
[01:15:38.940 --> 01:15:40.920]   all this, sorry, all this via strap on.
[01:15:40.920 --> 01:15:46.200]   Okay, yeah. And then secondly, I shouldn't use the term. And then secondly, if you could print
[01:15:46.200 --> 01:15:51.300]   it, you can wearable. Yeah. But think about if you guys ever watched the TV show Star Trek Next
[01:15:51.300 --> 01:15:55.620]   Generation, which I would guess maybe one of the replicator or the replicator or the holodeck,
[01:15:55.620 --> 01:16:00.600]   and you could walk in there number three on my list of Star Trek series, if you walk in and you
[01:16:00.600 --> 01:16:04.860]   could literally recreate the physical space that you want to be in to accomplish anything, the
[01:16:04.860 --> 01:16:09.360]   holodeck and then you could print anything, why would you use all the energy and all of this work
[01:16:09.360 --> 01:16:14.400]   to transport physical matter from one part of the universe to the other when all matter is
[01:16:14.400 --> 01:16:18.120]   transmutable. And the only thing that differentiates things is the photons coming
[01:16:18.120 --> 01:16:21.120]   off that matter, which is just to sense it. So if you can sense things
[01:16:21.120 --> 01:16:25.080]   remotely, while you're physically here, I go through the trouble, why go through the trouble.
[01:16:25.080 --> 01:16:29.820]   And so the argument is the same reason that we go to Hawaii and not just watch a movie.
[01:16:29.820 --> 01:16:35.280]   No, because we don't have enough of the sensing capabilities today to truly recreate being in
[01:16:35.280 --> 01:16:40.980]   Hawaii. But imagine if we did, and we are very much on the path to doing that. And in 2300 years,
[01:16:40.980 --> 01:16:45.300]   we have the ability to physically recreate what it's like for our body to be in Hawaii in every
[01:16:45.300 --> 01:16:50.460]   form, smell, taste, color, everything about being there physically in our body experiences it, why
[01:16:50.460 --> 01:16:50.940]   the hell would you fly?
[01:16:50.940 --> 01:16:54.600]   You could fly to Hawaii, you could meet people, you could socialize. So in a world,
[01:16:54.600 --> 01:16:58.440]   short Hawaii in a world where that technology exists, which could, by the way, be neural link,
[01:16:58.440 --> 01:17:02.520]   right, where you can, you know, put these signals directly into the brain, etc. Moving physical
[01:17:02.520 --> 01:17:06.540]   matter from one part of the universe to the other makes zero sense. All matter is transmutable,
[01:17:06.540 --> 01:17:11.100]   you can convert one atom to another using technology locally. So you wouldn't do that. And
[01:17:11.100 --> 01:17:16.080]   so that's the premise of 2001 is that you've got these local communication pods that just transmit
[01:17:16.080 --> 01:17:20.760]   information from different parts of the universe, you don't need to physically transport yourself. So
[01:17:20.760 --> 01:17:26.460]   that's the the macro kind of argument against this notion that UFOs or aliens are in a physical
[01:17:26.460 --> 01:17:31.680]   spacecraft visiting, it's so old school technology, that it makes no sense. It's like saying, you know,
[01:17:31.680 --> 01:17:35.340]   oh, my gosh, all these people are coming over to the United States on horses from Europe,
[01:17:35.340 --> 01:17:40.200]   you know, like it just like, why would they do that? Why would they use a horse? So So I think
[01:17:40.200 --> 01:17:44.940]   that's the argument against UFOs being aliens and spacecraft. Now, is there a really cool technology
[01:17:44.940 --> 01:17:50.160]   that has this advanced capability, and there are these crafts that are in our sky, and someone has
[01:17:50.160 --> 01:17:55.980]   that technology, maybe. But I'm not sure about this general pieces. I mean, you blew my mind with
[01:17:55.980 --> 01:18:06.180]   that. So yeah, sacks. I you obviously don't care. So we have no way for this to increase the IRR of
[01:18:06.180 --> 01:18:12.660]   my fund, or to get me another home. Beep, boop, bop, boop on planet Earth. Why would I want to go?
[01:18:12.660 --> 01:18:18.000]   I just somehow feel like if they're really UFOs, it'd be like an even bigger story. Like we'd all
[01:18:18.000 --> 01:18:19.980]   know it. You know, it's not going to be some,
[01:18:19.980 --> 01:18:25.200]   like weird friends conspiracy thing. Here's the here's the thing. I do not care about emotions.
[01:18:25.200 --> 01:18:28.440]   I can tell you why this is bullshit. The emotions of others.
[01:18:28.440 --> 01:18:37.320]   Every single photograph that's been taken in the last year is absolutely recognizably better than
[01:18:37.320 --> 01:18:44.520]   the one taken 10 years ago. And every single photo or video of these aliens looks like it was shot in
[01:18:44.520 --> 01:18:49.800]   a on a camera from 1950 on film that was left in somebody's basement. And meanwhile, pick, meanwhile,
[01:18:49.800 --> 01:18:55.500]   Pixar movies can recreate literally the ocean. We're recording this on Zoom. Why can't I get me
[01:18:55.500 --> 01:19:01.200]   a clear shot? There's not one clear shot of this. Show me the alien in 4K high def. And then I'll
[01:19:01.200 --> 01:19:07.140]   believe it. I mean, if you do, it's probably a camera by the engine and we can see the engine.
[01:19:07.140 --> 01:19:14.100]   Like why can't we get a shot of the until then I will be traveling between my homes. I am living
[01:19:14.100 --> 01:19:17.940]   my best life not in San Francisco. We will get Chessa Boudin recalled.
[01:19:17.940 --> 01:19:22.560]   I will tell you, Sax, I don't think you need to harp on the Chessa point anymore because I don't
[01:19:22.560 --> 01:19:27.600]   hear anyone making the case on the other side anymore. Dustin Moskovitz. He does it publicly.
[01:19:27.600 --> 01:19:33.960]   Yes. What from a sauna? Yes. Yes. Nick pull up the tweet. So, you know, I've been basically because
[01:19:33.960 --> 01:19:38.520]   look there. Oh, we fired him up. Here we go. No, let me get this in and then we can take off. So
[01:19:38.520 --> 01:19:40.560]   insert quarter here.
[01:19:40.560 --> 01:19:54.480]   No, look, we're taking all this heat from these stupid reporters are talking about our donations,
[01:19:54.480 --> 01:20:00.420]   you know, like asking what are we up to? Look, we're very public about what we're up to. But
[01:20:00.420 --> 01:20:04.980]   this is a terrible tweet from Dustin. There there have been these tech billionaires,
[01:20:04.980 --> 01:20:10.500]   Dustin Moskovitz, Reed Hastings and Mike Krieger, and they've been donating money.
[01:20:10.500 --> 01:20:11.640]   To what?
[01:20:11.640 --> 01:20:14.100]   To Chessa Boudin and Gascona.
[01:20:14.100 --> 01:20:15.240]   That's disappointing.
[01:20:15.240 --> 01:20:20.100]   Yeah, horrible. So I asked, I just said, why are you donating money to this insanity? And
[01:20:20.100 --> 01:20:25.440]   Dustin's still defending it. And then he said, I'm going to mute you now because you know,
[01:20:25.440 --> 01:20:27.180]   you didn't want to you didn't want to wait.
[01:20:27.180 --> 01:20:31.500]   Just in fairness, let me pull this up. Dustin's quote is I live in the city and I'm not going
[01:20:31.500 --> 01:20:36.720]   anywhere. Crime happens to me too. Trust me. We write extensively about why of our grants here.
[01:20:36.720 --> 01:20:39.840]   You know, here's the thing. I think Dustin Reed Hastings,
[01:20:39.840 --> 01:20:47.040]   and their spouses are very involved in criminal justice reform. And what we have to do is give
[01:20:47.040 --> 01:20:51.000]   somebody like Dustin or Reed Hastings the benefit of the doubt here and say, we understand your
[01:20:51.000 --> 01:20:58.500]   donations were meaningful to you. And you wanted to maybe lower the incarceration of black people
[01:20:58.500 --> 01:21:05.580]   in jail for crimes that were not violent. And we agree. Let's parse this conversation.
[01:21:05.580 --> 01:21:09.780]   No, I'm not giving them the benefit of the doubt. Let me explain why. Okay, so Reed, so this is a
[01:21:09.780 --> 01:21:13.740]   good example. This Reed Hastings thing is a good example. By the way, just today it was announced
[01:21:13.740 --> 01:21:20.700]   that he donated 3 million to Gavin Newsom. In any event, so, you know, he keep he look, he's on that
[01:21:20.700 --> 01:21:24.000]   side of the spectrum. By the way, there's a little backstory there. I don't know if you guys remember
[01:21:24.000 --> 01:21:30.240]   when there was pressure on the Facebook board to kick Peter Thiel off. But back in 2016, it was
[01:21:30.240 --> 01:21:34.200]   Reed Hastings. That was from Reed Hastings. Okay, so the guy is very close minded.
[01:21:34.200 --> 01:21:36.360]   I think it's his wife is actually handling this.
[01:21:36.360 --> 01:21:39.720]   Well, he was the board member who pushed to get Peter off because he couldn't
[01:21:39.720 --> 01:21:43.980]   handle the fact that there might be another board member who disagree with him politically.
[01:21:43.980 --> 01:21:49.080]   So it's a very close minded point of view. But let's take let's take this example of crime in
[01:21:49.080 --> 01:21:56.220]   LA. Okay, so we had this election, where George Gascon, who was a failure as DA in San Francisco,
[01:21:56.220 --> 01:22:02.640]   he goes down to LA and runs against the the veteran DA down there, Jackie Lacey,
[01:22:02.640 --> 01:22:09.660]   who happens to be a black woman, a veteran seasoned DA, competent, nobody had a problem with
[01:22:09.660 --> 01:22:14.220]   her. I think she's a Democrat. Okay, it's not like this is a right wing person. And so George
[01:22:14.220 --> 01:22:19.260]   Gascon basically fails his way out of San Francisco goes down to LA. And he basically
[01:22:19.260 --> 01:22:25.620]   dislodges her from that seat with $15 million, an unprecedented amount spent in a DA election.
[01:22:25.620 --> 01:22:30.300]   Where did that money come from? 5 million came from source 5 million came for Reed Hastings.
[01:22:30.300 --> 01:22:38.280]   5 million came from BLM. Now, you know, in any other context, the idea that you're going to fire
[01:22:39.600 --> 01:22:46.680]   a talented, competent seasoned veteran black woman and replace her with an incompetent white male,
[01:22:46.680 --> 01:22:52.740]   that would be seen as institutional racism. But nobody complained about it at all. But it's
[01:22:52.740 --> 01:22:58.560]   outrageous. And what is the most charitable was behind that? What is the most charitable
[01:22:58.560 --> 01:23:03.420]   view of why they're supporting Gascon and Chesa?
[01:23:03.420 --> 01:23:09.540]   Well, there's this decarcerationist agenda. And so yes, you're right that they see
[01:23:09.540 --> 01:23:15.480]   mass incarceration as a problem. But the problem is it is but the solution is not mass decarceration
[01:23:15.480 --> 01:23:21.540]   that we need something in between. And the problem with Gascon and Chesa Boudin, they just want to let
[01:23:21.540 --> 01:23:25.260]   everybody out. They don't want to put me on. I don't want to add anybody. So I think if their
[01:23:25.260 --> 01:23:30.120]   agenda is to lower the number adding people is against that. There are people who need to go to
[01:23:30.120 --> 01:23:38.280]   jail murderers to go to jail people dying every day in San Francisco by at the hands of repeat offenders
[01:23:39.480 --> 01:23:45.180]   Chesa Boudin has made the decision to let them out of jail even though they should be in jail. These
[01:23:45.180 --> 01:23:49.980]   are dangerous violent felons. The problem with this is I think Chamath I would like to get your
[01:23:49.980 --> 01:23:55.320]   feedback on it is, you know, you when a person gives these kind of donations and they make it
[01:23:55.320 --> 01:24:06.420]   their public persona, and it doesn't go well, how does one you know, I don't know disentangle or
[01:24:06.420 --> 01:24:08.580]   reconcile they made a bet.
[01:24:08.580 --> 01:24:08.880]   Yeah,
[01:24:08.880 --> 01:24:09.420]   yeah.
[01:24:09.420 --> 01:24:15.960]   That had a bad outcome, because this is obviously a bad outcome. You don't want the city to devolve
[01:24:15.960 --> 01:24:16.500]   into chaos.
[01:24:16.500 --> 01:24:23.340]   I don't particularly care about San Francisco. And I think the two of you guys can talk about it on
[01:24:23.340 --> 01:24:23.640]   Colin.
[01:24:23.640 --> 01:24:25.380]   No, I'm done. I'm going to get rid of my place in the city.
[01:24:25.380 --> 01:24:28.560]   On Colin, but I couldn't care less about how that city is going to be.
[01:24:28.560 --> 01:24:28.860]   I think I'm done too.
[01:24:28.860 --> 01:24:30.120]   Any closing thoughts, Freiburg?
[01:24:30.120 --> 01:24:32.280]   I got nothing to say.
[01:24:32.280 --> 01:24:36.780]   Okay, I want to add just one thing. Look, so I care because I live there. But this trend,
[01:24:36.780 --> 01:24:39.360]   this is not just San Francisco, this whole idea of these
[01:24:39.360 --> 01:24:45.240]   radical decarcerationists, they are running for DA in every major city. This is going to
[01:24:45.240 --> 01:24:51.480]   be a national trend. And they're going to cause a lot of carnage, a lot of death and destruction
[01:24:51.480 --> 01:24:58.680]   until the people realize and there will inevitably be a backlash to this. And hopefully just not too
[01:24:58.680 --> 01:24:59.280]   many people die.
[01:24:59.280 --> 01:25:03.420]   Fair enough. I don't want to be too flippant. My point is, it's a really important debate. It's
[01:25:03.420 --> 01:25:08.700]   going to happen in every city. But folks need to get engaged in those cities and do something about
[01:25:08.700 --> 01:25:09.300]   it.
[01:25:09.300 --> 01:25:14.520]   If you want to hear the argument of why this is happening, you can go watch the TED Talk on
[01:25:14.520 --> 01:25:21.780]   YouTube of Adam Foss, F-O-S-S. He was the original proponent of the DAs coming in to drive the
[01:25:21.780 --> 01:25:28.620]   decarceration movements. And I just think it's important to be informed of the other perspective
[01:25:28.620 --> 01:25:33.720]   in evaluating where folks are coming from that are proponents for this movement.
[01:25:33.720 --> 01:25:39.240]   Yeah, I'm trying to be charitable towards their position, Dustin and Reid, if you want to come on
[01:25:39.240 --> 01:25:41.700]   the pod and be a bestie guestie, I guess, maybe.
[01:25:41.700 --> 01:25:45.480]   Dustin, Dustin responded to me and said, Listen, we don't know what the counterfactual is. If we
[01:25:45.480 --> 01:25:48.300]   had a more aggressive DA. That was his argument. We don't know the counterfactual.
[01:25:48.300 --> 01:25:48.660]   That's ridiculous.
[01:25:48.660 --> 01:25:55.560]   So I, of course, so I posted a list of people of innocent victims who've died. Okay. Because
[01:25:55.560 --> 01:26:00.660]   directly because of a decision that Chase Abudin made. That's your counterfactual.
[01:26:00.660 --> 01:26:01.200]   Yeah.
[01:26:01.200 --> 01:26:02.520]   That's your counterfactual.
[01:26:02.520 --> 01:26:09.180]   All right. Listen, it's been an amazing episode and no plugs, no ads, no nothing.
[01:26:09.180 --> 01:26:14.520]   If you like the show, great. And if you don't like it, how the hell did you make it to the minute 75
[01:26:14.520 --> 01:26:19.320]   for the Queen of Quinoa, the dictator himself, Jamali Papatia.
[01:26:19.320 --> 01:26:20.760]   I'm having steak tonight.
[01:26:20.760 --> 01:26:22.140]   He's having steak tonight.
[01:26:22.140 --> 01:26:27.540]   If you're vegan, David Friedberg, you're not invited to steak tonight.
[01:26:27.540 --> 01:26:30.240]   I'm having beers tonight. I'm having beers tonight.
[01:26:30.240 --> 01:26:36.780]   You're having beers and roasted eggplant tonight. You've never eaten fish in your life. Never had
[01:26:36.780 --> 01:26:38.400]   sushi and sacks.
[01:26:38.400 --> 01:26:39.120]   By the way, that's true. I don't know if you're a fan of the show.
[01:26:39.120 --> 01:26:41.580]   I don't know if our listeners are eating tonight.
[01:26:41.580 --> 01:26:46.680]   Sacks, can we talk about Sacks' health? Where's your first, second and third dinner tonight?
[01:26:46.680 --> 01:26:49.740]   I'm on a seafood diet. I see the food and I eat it.
[01:26:49.740 --> 01:26:57.300]   Sacks, if we take out your Postmates/Race account right now, how long is it going to be?
[01:26:57.300 --> 01:26:59.160]   Eat it out. Eat it out.
[01:26:59.160 --> 01:27:00.540]   What's happening? What's happening?
[01:27:00.540 --> 01:27:05.700]   Oh my gosh. How do I get to be the fat guy on this pod? I don't get it. This is not,
[01:27:05.700 --> 01:27:06.540]   this can't be happening.
[01:27:06.540 --> 01:27:07.380]   I just bought my third machine.
[01:27:07.380 --> 01:27:08.580]   This can't be happening.
[01:27:08.580 --> 01:27:09.060]   It's happening.
[01:27:09.060 --> 01:27:14.100]   This is your Twilight Zone episode. I just bought, I decided I'm going twice a week with
[01:27:14.100 --> 01:27:20.640]   the trainer and I just bought the Hydro. So now I have Tonal, Peloton Tread and I got the Hydro.
[01:27:20.640 --> 01:27:24.000]   I'm going from smart machine to smart machine. Hey, are you spack?
[01:27:24.000 --> 01:27:26.280]   Oh, I got to . Oh, good question.
[01:27:26.280 --> 01:27:28.560]   No, no, no.
[01:27:28.560 --> 01:27:29.280]   No comment?
[01:27:29.280 --> 01:27:29.640]   No comment.
[01:27:29.640 --> 01:27:31.980]   Okay. Sorry. I just saw some tweet.
[01:27:31.980 --> 01:27:33.720]   People have other things to do.
[01:27:33.720 --> 01:27:34.500]   Guys, I got to call.
[01:27:34.500 --> 01:27:35.040]   We know you don't.
[01:27:35.040 --> 01:27:35.640]   We got things to do.
[01:27:35.640 --> 01:27:36.120]   I got to go.
[01:27:36.120 --> 01:27:38.520]   All right, everybody. Love you besties. Love you, Sasha.
[01:27:38.520 --> 01:27:39.000]   Love you. Love you.
[01:27:39.000 --> 01:27:43.620]   Yeah. Get a salad. Okay. We love you. Bye besties. Eat a salad.
[01:27:43.620 --> 01:27:45.300]   And of course the dictator here.
[01:27:45.300 --> 01:27:46.500]   The absolute dictator.
[01:27:46.500 --> 01:27:47.520]   The dictator himself.
[01:27:47.520 --> 01:27:49.860]   The spack master himself.
[01:27:49.860 --> 01:27:51.420]   The dictator.
[01:27:51.420 --> 01:27:54.660]   Shout out to all my haters.
[01:27:54.660 --> 01:27:56.700]   I write a minimum of a hundred million dollars personal.
[01:27:56.700 --> 01:27:58.920]   Spack daddy, you respect this paper.
[01:27:58.920 --> 01:28:00.240]   I get thousands of millions confused.
[01:28:00.240 --> 01:28:01.140]   I'm the dictator.
[01:28:01.140 --> 01:28:03.420]   Let the court side when you see me after four years.
[01:28:03.420 --> 01:28:05.820]   It's hard to make good investments. It's hard to build a company.
[01:28:05.820 --> 01:28:07.740]   Big waves and I hit the gym later.
[01:28:08.940 --> 01:28:10.940]   I'm the dictator.
[01:28:10.940 --> 01:28:12.940]   I'm the dictator.
[01:28:12.940 --> 01:28:14.940]   I'm the dictator.
[01:28:14.940 --> 01:28:18.940]   I am a complete byproduct of a social safety net.
[01:28:18.940 --> 01:28:20.940]   I'm the dictator.
[01:28:20.940 --> 01:28:22.940]   I'm the dictator.
[01:28:22.940 --> 01:28:26.940]   And at some point you have to figure out whether you actually want your kids to have asthma or not.
[01:28:26.940 --> 01:28:28.940]   Or you care more about the land gross.
[01:28:28.940 --> 01:28:30.940]   I'm the dictator.
[01:28:30.940 --> 01:28:32.940]   I'm king of the spack.
[01:28:32.940 --> 01:28:34.940]   People take money is free.
[01:28:34.940 --> 01:28:36.940]   And it's not.
[01:28:36.940 --> 01:28:38.880]   I pick up the slack.
[01:28:38.880 --> 01:28:39.880]   I'm just frank.
[01:28:39.880 --> 01:28:40.880]   But it's fine.
[01:28:40.880 --> 01:28:41.880]   I'm secure in the bed.
[01:28:41.880 --> 01:28:43.880]   I get thousands of millions confused.
[01:28:43.880 --> 01:28:45.880]   I get thousands of millions confused.
[01:28:45.880 --> 01:28:47.880]   I get thousands of millions confused.
[01:28:47.880 --> 01:28:48.880]   Firing on all cylinders.
[01:28:48.880 --> 01:28:50.880]   Shout out to all my haters.
[01:28:50.880 --> 01:28:53.880]   Ultra-launched billionaire has bought the French Monde.
[01:28:53.880 --> 01:28:55.880]   Spack daddy, you respect this paper.
[01:28:55.880 --> 01:28:56.880]   I just want to be called king.
[01:28:56.880 --> 01:28:57.880]   I'm the dictator.
[01:28:57.880 --> 01:28:59.880]   Let the court side when you see me after four years.
[01:28:59.880 --> 01:29:01.880]   The little guy getting run over.
[01:29:01.880 --> 01:29:02.880]   I just can't stand that.
[01:29:02.880 --> 01:29:04.880]   Big waves and I hit the gym later.
[01:29:04.880 --> 01:29:05.880]   I'm the dictator.
[01:29:05.880 --> 01:29:07.880]   Hang up, hang up, hang up.
[01:29:07.880 --> 01:29:09.880]   I'm the dictator.
[01:29:09.880 --> 01:29:10.880]   I'm the dictator.
[01:29:10.880 --> 01:29:11.880]   It's hard to make it.
[01:29:11.880 --> 01:29:12.880]   It's hard to make good investments.
[01:29:12.880 --> 01:29:13.880]   It's hard to build a company.
[01:29:13.880 --> 01:29:19.880]   Because if it was easy, everybody would be doing it all the time.
[01:29:19.880 --> 01:29:21.880]   This one man for yourself, it's all about you.
[01:29:21.880 --> 01:29:23.880]   You can figure it out.
[01:29:23.880 --> 01:29:25.880]   The rugged individualism.
[01:29:25.880 --> 01:29:27.880]   That's just not realistic.
[01:29:27.880 --> 01:29:31.880]   Anybody who wants, who's listening to this, who wants to go to the French Laundry, stay
[01:29:31.880 --> 01:29:35.880]   at home, pour a bunch of salt on whatever you're going to eat.
[01:29:35.880 --> 01:29:36.880]   Okay?
[01:29:37.140 --> 01:29:38.400]   Melt a stick of butter in the microwave?
[01:29:38.400 --> 01:29:40.180]   Melt a stick of butter in the microwave, drink it,
[01:29:40.180 --> 01:29:42.400]   and then basically take it for $1,500,
[01:29:42.400 --> 01:29:44.640]   light it on fire, and you've been to the punchline.
[01:29:44.640 --> 01:29:51.480]   It's hard to make it.
[01:29:51.480 --> 01:29:52.740]   It's hard to make good investments.
[01:29:52.740 --> 01:29:53.780]   It's hard to build a company.
[01:29:53.780 --> 01:29:55.140]   Because if it was easy,
[01:29:55.140 --> 01:29:56.800]   everybody would be doing it all the time.
[01:29:56.800 --> 01:30:01.640]   This one man for yourself, it's all about you.
[01:30:01.640 --> 01:30:02.640]   You can figure it out.
[01:30:02.640 --> 01:30:06.280]   The rugged individualism, that's just not realistic.
[01:30:06.540 --> 01:30:07.700]   It's a real joke.
[01:30:07.700 --> 01:30:08.200]   Bye!
[01:30:08.200 --> 01:30:10.260]   you

