
[00:00:00.000 --> 00:00:04.080]   The following is a conversation with Albert Bourla, CEO of Pfizer.
[00:00:04.080 --> 00:00:09.200]   If you'd like to skip ahead to our conversation, the timestamps as always are below.
[00:00:09.200 --> 00:00:14.880]   But if not, please allow me to say a few words about truth and human nature,
[00:00:14.880 --> 00:00:20.920]   specifically about two groups of people throughout history that seek to lay claim to the truth.
[00:00:20.920 --> 00:00:25.300]   The first group will tell you that only they possess the truth,
[00:00:25.300 --> 00:00:28.760]   that the government will save you, the company will save you,
[00:00:28.920 --> 00:00:32.160]   the science, the authorities, the experts, the institutions will save you.
[00:00:32.160 --> 00:00:36.960]   The second group, too, will tell you that only they possess the truth,
[00:00:36.960 --> 00:00:40.300]   that the government will hurt you, the company will hurt you,
[00:00:40.300 --> 00:00:43.680]   the science, the authorities, the experts, the institutions will hurt you.
[00:00:43.680 --> 00:00:50.340]   Both groups have the benevolent and the malevolent, their heroes and their charlatans.
[00:00:50.340 --> 00:00:57.120]   And I think the hard truth is that no one in this world can tell you with absolute certainty which is which.
[00:00:57.680 --> 00:00:59.040]   You have to use your mind.
[00:00:59.040 --> 00:01:03.040]   This is the burden of being human, of being free.
[00:01:03.040 --> 00:01:10.680]   Don't blindly follow any leader, neither the emperor nor the martyr who points out that the emperor has no clothes.
[00:01:10.680 --> 00:01:13.960]   And then there's the lessons of history.
[00:01:13.960 --> 00:01:19.040]   Vaccines have saved hundreds of millions of lives in the past century.
[00:01:19.040 --> 00:01:22.920]   And in general, the advance of medicine has saved billions of lives.
[00:01:22.920 --> 00:01:27.640]   If you ignore the power of science, you're not being honest with the lessons of history.
[00:01:28.260 --> 00:01:32.760]   And if you ignore the corrupting nature of power and money within institutions,
[00:01:32.760 --> 00:01:39.300]   including governments and companies that led to the suffering and death of hundreds of millions in the past century,
[00:01:39.300 --> 00:01:43.960]   you are once again not being honest with the lessons of history.
[00:01:43.960 --> 00:01:51.380]   I announced that I will be having this conversation with Albert Bourla, Pfizer CEO, and a lot of people wrote to me.
[00:01:52.000 --> 00:01:59.160]   I would like to say that I was and am and always will be listening and learning with an open mind from everyone.
[00:01:59.160 --> 00:02:08.160]   My own opinion, worth little as it is, is that the development of the COVID vaccines is one of the greatest accomplishments of science in recent history.
[00:02:08.160 --> 00:02:17.200]   For the rest, from safety and efficacy to policy and economics, I stand humbled before a complicated world full of fear and anger.
[00:02:18.160 --> 00:02:24.160]   A small number of malicious people from all walks of life will use that fear and anger to divide us,
[00:02:24.160 --> 00:02:28.120]   because the division makes them money and gives them power.
[00:02:28.120 --> 00:02:32.400]   I took two shots of the Pfizer vaccine. This was my decision.
[00:02:32.400 --> 00:02:35.360]   I don't ever want to force this on anyone.
[00:02:35.360 --> 00:02:42.280]   And I certainly don't want to dismiss your concerns or worse, you as a person, if you choose not to get vaccinated.
[00:02:43.040 --> 00:02:52.040]   I can assure you one thing, in this conversation, and in any conversation, the choice of questions I ask and words I say is mine and mine alone.
[00:02:52.040 --> 00:02:59.700]   When my words fall short, as they often do, it is only because of the limitations of my mind and of my speaking ability.
[00:02:59.700 --> 00:03:02.380]   It is not due to pressure or fear.
[00:03:02.380 --> 00:03:04.740]   I'm not afraid of anyone.
[00:03:04.740 --> 00:03:08.380]   I cannot be bought by anyone with money, power, or fame.
[00:03:08.380 --> 00:03:12.320]   I hope to prove this to you and to myself in the coming years.
[00:03:13.320 --> 00:03:18.320]   This life is short. And to me, without integrity, it is not worth living.
[00:03:18.320 --> 00:03:21.980]   People sometimes talk down to me, call me naive.
[00:03:21.980 --> 00:03:26.060]   Perhaps they are right. But it is who I am.
[00:03:26.060 --> 00:03:31.780]   I think this life, this world, this, our human civilization is beautiful.
[00:03:31.780 --> 00:03:36.140]   And as Dostoevsky said, beauty will save the world.
[00:03:37.400 --> 00:03:42.560]   This is the Lex Friedman Podcast, and here's my conversation with Albert Bourla.
[00:03:42.560 --> 00:03:50.440]   The development of the COVID-19 vaccine was one of the greatest accomplishments of science in recent history.
[00:03:50.440 --> 00:03:53.800]   No matter what, this should give people hope for the future.
[00:03:53.800 --> 00:03:56.600]   And yet it is more of a source of division.
[00:03:56.600 --> 00:04:05.600]   I hope we can discuss both the inspiring and the difficult ideas in this conversation so that we can do our small part in healing this division.
[00:04:06.320 --> 00:04:07.320]   I hope so.
[00:04:07.320 --> 00:04:13.860]   Take me through the day of November 8th, 2020, when the Pfizer team were waiting for the results of the phase three clinical trials.
[00:04:13.860 --> 00:04:18.600]   We had assembled in a very small office that we are having in Connecticut.
[00:04:18.600 --> 00:04:21.440]   Very few people. There were five, I think.
[00:04:21.440 --> 00:04:31.720]   And in another place, what we call the Data Monitoring Committee, which is a group of experts, independent experts, they're on Pfizer.
[00:04:32.180 --> 00:04:43.220]   We're going to have the opportunity to unblind the data and then tell us if the study needs to continue or if it is successful or if it fails.
[00:04:43.220 --> 00:04:45.460]   And we were waiting for their call.
[00:04:45.460 --> 00:04:54.920]   So the call came a little bit later than what we expected, which created a lot of anxiety to all of us, but came around, I think, two o'clock.
[00:04:54.920 --> 00:04:56.340]   You're just sitting there waiting.
[00:04:56.340 --> 00:04:57.420]   What were you feeling?
[00:04:57.500 --> 00:05:03.320]   Sitting there waiting and teasing one another, drinking coffee, making jokes.
[00:05:03.320 --> 00:05:09.820]   So how did you feel like when you heard the results, the successful results?
[00:05:09.820 --> 00:05:14.320]   Free, liberated, happy.
[00:05:14.320 --> 00:05:22.580]   Like if a huge weight that was on my shoulders was lifted.
[00:05:22.580 --> 00:05:26.580]   I heard you said I love you to the team.
[00:05:27.580 --> 00:05:28.280]   I did.
[00:05:28.280 --> 00:05:32.900]   This is how we speak in Mediterranean.
[00:05:32.900 --> 00:05:34.580]   Listen, maybe it's the Russian thing, too.
[00:05:34.580 --> 00:05:36.660]   I love love.
[00:05:36.660 --> 00:05:40.440]   So I appreciate that kind of celebration.
[00:05:40.440 --> 00:05:47.360]   So looking back from that moment to before, how much did it cost to develop the Pfizer BioNTech vaccine?
[00:05:47.360 --> 00:05:55.160]   What was it like making the decision to make that investment when the risk is very high and you don't know if it's going to be successful?
[00:05:56.080 --> 00:05:58.040]   You know, we do a lot of that anyway.
[00:05:58.040 --> 00:06:00.740]   This is what we do in our daily work.
[00:06:00.740 --> 00:06:05.320]   We are putting money, we are investing in research, which is highly risky.
[00:06:05.320 --> 00:06:09.160]   The difference in that case was that we didn't risk at all.
[00:06:09.160 --> 00:06:10.240]   We put it all in.
[00:06:10.240 --> 00:06:14.620]   We put everything in one go so that we don't lose time.
[00:06:14.620 --> 00:06:17.500]   Usually we'll spend 50 million.
[00:06:17.500 --> 00:06:20.320]   And then if that goes well, then we will spend another 50.
[00:06:20.320 --> 00:06:21.700]   And then if it goes well, then 100.
[00:06:22.280 --> 00:06:28.240]   Here we put all together a little bit more than $2 billion, $2.3 billion.
[00:06:28.240 --> 00:06:39.060]   And it was a significant decision, but it was a very easy decision to make in the context of what we were living at that time.
[00:06:39.060 --> 00:06:40.980]   It was a pandemic.
[00:06:40.980 --> 00:06:41.980]   People were scared.
[00:06:41.980 --> 00:06:42.860]   We were scared.
[00:06:42.860 --> 00:06:44.980]   We didn't know how tomorrow would look like.
[00:06:44.980 --> 00:06:48.560]   We were living unprecedented situations.
[00:06:49.140 --> 00:06:53.840]   And we knew that we have capabilities that may help.
[00:06:53.840 --> 00:06:57.220]   So there was not a second question or choice.
[00:06:57.220 --> 00:06:58.420]   We go all in.
[00:06:58.420 --> 00:07:12.000]   When you make decisions like that, you're the CEO of a company that needs to make money and that hopes to do a lot of good in the world.
[00:07:12.000 --> 00:07:16.460]   How much of both of those things are part of the calculation?
[00:07:17.220 --> 00:07:29.920]   So when you said it was an obvious choice, I think you've said a bunch of things of the kind of saying we need to go all in, sort of very boldly diving in.
[00:07:29.920 --> 00:07:44.840]   How much was that that the world is facing uncertainty and fear and potentially destructive pandemic in the early days, just when you're seeing the full uncertainty before us, don't know how it's going to unroll.
[00:07:45.260 --> 00:07:50.800]   And how much of it is this may also be a good financial decision to take this risk?
[00:07:50.800 --> 00:07:53.220]   Yeah, I think about it all the time.
[00:07:53.220 --> 00:07:57.640]   And I know very well that if you focus too much on making money, you will never make.
[00:07:57.640 --> 00:08:02.680]   You should focus in what is the real value driver.
[00:08:02.680 --> 00:08:08.340]   And the real value driver, it is to make breakthroughs that change patients' lives.
[00:08:08.340 --> 00:08:10.680]   If you don't do that, you will never make money.
[00:08:10.680 --> 00:08:13.120]   If you do that, don't worry.
[00:08:13.300 --> 00:08:15.760]   Things will fall into place and also money will follow.
[00:08:15.760 --> 00:08:19.840]   But the mentality of the company is to be how to help the patient.
[00:08:19.840 --> 00:08:25.960]   And that's what the management was that the shareholders want, because that's the only way that we can create value.
[00:08:25.960 --> 00:08:41.420]   In this particular case, we're not thinking at all about what are we going to make when we sell it or if not sell it, because what we were focusing 100% was how to bring a solution to the world that will help all of us.
[00:08:42.620 --> 00:08:45.920]   Change the way, the fear that was bring hope to the world.
[00:08:45.920 --> 00:08:51.580]   And as always, when you do that, you will have good returns as well.
[00:08:51.580 --> 00:09:07.960]   On a philosophical level, on a human level, do you ever worry that the pressure to cover the costs that were invested to develop a new drug, to develop this vaccine harms your ability to conduct unbiased studies?
[00:09:07.960 --> 00:09:12.040]   Not at all, because the studies are highly regulated.
[00:09:12.880 --> 00:09:29.500]   Everybody knows what regulators, and when I say regulators, FDA, European authorities, UK authorities, Israeli authorities, Japanese authorities, Canadian authorities, want to see how the study needs to be conducted and what exactly they need to see to approve it or not.
[00:09:29.500 --> 00:09:38.380]   So clearly, everybody takes into consideration how much money I'm going to invest and what is the chances that I'm going to lose them.
[00:09:38.920 --> 00:09:44.180]   But what you can do is to change the rules of the game so that you won't lose the money.
[00:09:44.180 --> 00:09:54.340]   There are very well established methodologies that would say with very high precision if your medicine is effective, if your medicine is safe.
[00:09:54.340 --> 00:09:58.220]   And those are there for all and all playing with the same rules.
[00:09:59.680 --> 00:10:07.940]   Do you have an intuition about why is the FDA trying to get 75 years to release the Pfizer data?
[00:10:07.940 --> 00:10:11.900]   They're trying to request that it will not be released for 75 years.
[00:10:11.900 --> 00:10:22.720]   And then maybe the broader version of that question is, do you think people should have sort of full transparency and immediate access to the data?
[00:10:22.720 --> 00:10:25.760]   Immediate, you know, on the scale of weeks, not years?
[00:10:27.260 --> 00:10:32.060]   I think the relations with regulators, they have been always very transparent.
[00:10:32.060 --> 00:10:44.100]   And there are a lot of laws that they are forcing regulators and companies to put out there their interactions and what exactly was discussed.
[00:10:44.100 --> 00:10:53.180]   Now, to go into specific details of some discussions, I don't know what is the reason that the FDA wants to take that time.
[00:10:53.180 --> 00:10:55.480]   And I'm sure they have very good reasons.
[00:10:56.800 --> 00:10:58.940]   Well, let me just say my side of it.
[00:10:58.940 --> 00:11:01.640]   It doesn't look like a good reason.
[00:11:01.640 --> 00:11:04.680]   It looks like maybe it's because I come from the Soviet Union.
[00:11:04.680 --> 00:11:06.860]   Now, this is not you saying this.
[00:11:06.860 --> 00:11:13.400]   This is me saying this is there seems to be a bureaucracy that gets in the way of transparency.
[00:11:13.400 --> 00:11:14.980]   That's always the challenge with government.
[00:11:14.980 --> 00:11:21.060]   So government is very good at setting rules and making sure there's oversight of companies and people and so on.
[00:11:21.060 --> 00:11:25.720]   But they create they slow things down, which is a feature and a bug.
[00:11:26.300 --> 00:11:28.800]   And in this case, they slowed down so much.
[00:11:28.800 --> 00:11:38.180]   I think the reason they said it's 75 years is because they set a rate of being able to only review 500 pages of data a day or something like that.
[00:11:38.180 --> 00:11:43.980]   And it's a very kind of bureaucratic thing where in reality, you could just show the data.
[00:11:43.980 --> 00:11:46.780]   And it's not like something is being hidden.
[00:11:46.780 --> 00:11:54.480]   But in the battle to win people's trust, to inspire them with science, it feels like transparency is one of the most beautiful things.
[00:11:54.900 --> 00:11:57.200]   One of the most powerful things that the FDA has.
[00:11:57.200 --> 00:12:02.080]   FDA has the potential to be one of the great institutions of our country.
[00:12:02.080 --> 00:12:06.580]   And this is one example that it feels to me like a failure.
[00:12:06.580 --> 00:12:09.780]   So in your perspective, you're saying I'm sure they have a good reason.
[00:12:09.780 --> 00:12:16.460]   So to you, the FDA is this black box that you submit things to once they approve.
[00:12:16.460 --> 00:12:19.800]   You know that those are the rules.
[00:12:19.800 --> 00:12:21.640]   It's approved. That's it.
[00:12:21.640 --> 00:12:23.840]   But this is not a black box.
[00:12:24.380 --> 00:12:27.800]   We know very well what is the process.
[00:12:27.800 --> 00:12:30.340]   Everybody knows very well what are the processes.
[00:12:30.340 --> 00:12:35.600]   The review process also, it is very detailed.
[00:12:35.600 --> 00:12:37.860]   They have scientists of very, very high caliber.
[00:12:37.860 --> 00:12:50.040]   Not every regulator in the world, but the Europeans, the Brits, the FDA, clearly, they have very, very high caliber of scientists that they are going into a lot of details.
[00:12:50.040 --> 00:13:00.580]   And also, basically everything for a study is really released by law in the specifications of the product.
[00:13:00.580 --> 00:13:06.380]   But it's a very detailed document that it is issued and has basically the essence of everything was discussed.
[00:13:06.380 --> 00:13:15.680]   I don't know about specific documents if it takes them time to release, but clearly this is not a black box type of process.
[00:13:15.940 --> 00:13:24.180]   A lot of this stuff is how do you effectively communicate to the world about the incredible science that's been done, about the processes that were followed.
[00:13:24.180 --> 00:13:25.260]   I agree with you.
[00:13:25.260 --> 00:13:28.980]   And sometimes it's just ineloquence in communication.
[00:13:28.980 --> 00:13:31.360]   It's not that there's a failure process.
[00:13:31.360 --> 00:13:33.940]   It's ineloquence of communication and silence.
[00:13:33.940 --> 00:13:39.400]   Silence in the moment when clearly a lot of people are bothered and have questions.
[00:13:40.120 --> 00:13:49.700]   This is when you speak out and you explain exactly why, as opposed to letting the sort of distrust build up and linger.
[00:13:49.700 --> 00:13:57.860]   Because the result is there's a very large percentage of the population that just, I mean, it divides people.
[00:13:57.860 --> 00:14:00.340]   And science suffers, I think.
[00:14:00.340 --> 00:14:06.220]   And also the effectiveness of solutions suffers, like the vaccine and so on.
[00:14:08.540 --> 00:14:12.240]   I asked a few folks I know if they had challenging questions for you.
[00:14:12.240 --> 00:14:16.160]   I'm sure many of them answered your call.
[00:14:16.160 --> 00:14:17.440]   Yeah.
[00:14:17.440 --> 00:14:20.620]   Many friendly folks out there.
[00:14:20.620 --> 00:14:27.540]   By the way, I'm sweating, not because this is a difficult conversation, it is, but it's also hot in here for the record.
[00:14:27.540 --> 00:14:32.320]   So one of the folks is Mr. Jordan Peterson.
[00:14:32.320 --> 00:14:34.840]   I don't know if you know who that is.
[00:14:34.840 --> 00:14:37.840]   He's a psychologist and intellectual and author.
[00:14:38.480 --> 00:14:45.140]   He suggested to me that I raise the concern that there's a close working relationship between Pfizer, FDA, and CDC.
[00:14:45.140 --> 00:14:47.440]   So we talked about FDA.
[00:14:47.440 --> 00:14:56.160]   Do you worry that this affects both positive and negative Pfizer's chances of getting drugs approved?
[00:14:56.160 --> 00:15:03.280]   The fact that there's people that worked at the FDA that now work at Pfizer, Pfizer FDA, that there's a kind of pipeline.
[00:15:04.120 --> 00:15:11.560]   Does this worry you that it affects your ability to do great unbiased work?
[00:15:11.560 --> 00:15:20.400]   I have zero doubts that this is not affecting at all their ability to be unbiased and regulate.
[00:15:20.400 --> 00:15:27.760]   And in order to, for the system also reinforces that by creating significant time barriers.
[00:15:27.800 --> 00:15:40.240]   If someone moves from an industry to FDA, he won't be able to deal with topics for a period of time and then for even an enhanced period of time with topics that are related with a company he or she may come from.
[00:15:40.240 --> 00:15:45.600]   I think these regulators, they are really very strict.
[00:15:45.600 --> 00:15:47.520]   Rightly so.
[00:15:48.360 --> 00:16:03.440]   If anything, I feel sometimes that maybe they should be a little bit more open minded, particularly when it comes to new technologies, rather than trying to judge and implement the same framework of variation of new technologies to all.
[00:16:03.440 --> 00:16:06.840]   They are always, as regulators, on the conservative side.
[00:16:06.840 --> 00:16:13.640]   But always, always, they are unbiased and they are trying the best.
[00:16:13.640 --> 00:16:15.400]   And it's not only one or two people.
[00:16:15.960 --> 00:16:23.760]   They have processes to make sure that there are self checks and balances within the agencies, both in CDC and in the FDA.
[00:16:23.760 --> 00:16:27.560]   Difficult decisions, they bring external experts that they should express.
[00:16:27.560 --> 00:16:31.120]   Easy decisions, there are internal experts that they are debating a lot.
[00:16:31.120 --> 00:16:33.040]   And if there are disagreements, they elevate them.
[00:16:33.040 --> 00:16:38.760]   So I think we are lucky to have good regulators.
[00:16:38.760 --> 00:16:42.000]   I think I agree with what you said before.
[00:16:42.720 --> 00:16:49.160]   As with all governmental agencies, there is bureaucracy and the bureaucracy needs to be addressed.
[00:16:49.160 --> 00:16:54.560]   And by saying bureaucracy is not relaxing the bar.
[00:16:54.560 --> 00:17:03.480]   The bar needs to remain high, but focusing on what matters rather than on the detail.
[00:17:04.440 --> 00:17:08.960]   So you don't, you know, I've been reading quite a bit about history.
[00:17:08.960 --> 00:17:13.120]   You don't worry about human nature and corruption that can seep in.
[00:17:13.120 --> 00:17:16.680]   You're saying institutionally there's protections against this.
[00:17:16.680 --> 00:17:23.520]   I think there is always the fear of corruption, particularly when you speak about public servants.
[00:17:23.520 --> 00:17:27.800]   But clearly the risk is very different country by country.
[00:17:27.800 --> 00:17:31.480]   And speaking about an agency by agency.
[00:17:31.960 --> 00:17:39.400]   I think the regulatory agencies have a very good track record and history of the US, of Europe, of England.
[00:17:39.400 --> 00:17:43.040]   Of very, very good track record of integrity.
[00:17:43.040 --> 00:17:46.160]   It's something I think about.
[00:17:46.160 --> 00:17:53.080]   So I grew up in the Soviet Union and I need to perhaps introspect this a little bit.
[00:17:53.080 --> 00:18:01.040]   But when I was growing up, ethically, there was a sense that bribery is the only way you can get stuff done.
[00:18:01.600 --> 00:18:03.440]   That was the system of the time.
[00:18:03.440 --> 00:18:08.400]   Like you get pulled over by a police officer, like obviously you need to bribe them.
[00:18:08.400 --> 00:18:10.800]   It was like the way of life.
[00:18:10.800 --> 00:18:16.600]   And then so coming to this country, it was beautiful to see that the rule of law has so much power.
[00:18:16.600 --> 00:18:28.280]   And ultimately, the rule of law, when enacted, when it holds up, it gives people freedom to do the best work of their lives.
[00:18:28.280 --> 00:18:30.240]   But there's still human nature.
[00:18:30.640 --> 00:18:32.280]   And that worries me a lot here.
[00:18:32.280 --> 00:18:35.440]   And again, it goes back to the perception, the communication.
[00:18:35.440 --> 00:18:44.640]   When there's people that have worked at Pfizer and at FDA, at the CDC, you know, you look at their resume, they have those things on their resume.
[00:18:44.640 --> 00:18:45.760]   It worries people.
[00:18:45.760 --> 00:18:53.920]   Are these great leaders that we are supposed to see as authorities, are they playing a game on us?
[00:18:54.640 --> 00:19:07.240]   I would say that I recognize what you said about what happened in or what I'm sure that what you describe in the country that you're coming from, it was how you experienced it.
[00:19:07.240 --> 00:19:12.640]   And I know that there are other countries that you need to do these things to do your job.
[00:19:12.640 --> 00:19:20.240]   I don't think is the case in this country, particularly when it comes to those agencies that you mentioned.
[00:19:20.240 --> 00:19:23.720]   I think they have a very high track record.
[00:19:23.760 --> 00:19:28.800]   And also, I don't think that there are a lot of people that they are worried about it or doubt it.
[00:19:28.800 --> 00:19:46.080]   I'm sure like everywhere, there will be a minority, but the vast majority of the Americans, the vast majority of the Europeans, the vast majority of the Brits, the vast majority of the Israelis, they trust what FDA or EMA or CDC or any HRA will say.
[00:19:46.080 --> 00:19:51.480]   Still, there's currently a distrust of big pharma in the public.
[00:19:51.520 --> 00:19:54.040]   Maybe this is something I'd love to hear your comment on.
[00:19:54.040 --> 00:20:01.120]   There's distrust of science when it's tangled up with corporations and government institutions like we've talked about.
[00:20:01.120 --> 00:20:11.120]   But you have, they have to be entangled to achieve scale, oversight and to achieve the kind of scale that Pfizer has been able to accomplish.
[00:20:11.120 --> 00:20:16.080]   How can Pfizer regain the public trust?
[00:20:16.080 --> 00:20:18.920]   How can you regain the public trust, do you think?
[00:20:19.000 --> 00:20:23.440]   Not regain, but sort of take steps to increase the public trust?
[00:20:23.440 --> 00:20:31.720]   Reputation is something that you can lose in buckets, but you can earn it back in drops.
[00:20:31.720 --> 00:20:39.680]   And once you lost it, you are going to take a lot of effort to bring it back.
[00:20:39.680 --> 00:20:42.080]   And the pharmaceutical industry lost it.
[00:20:42.400 --> 00:20:52.280]   It's clear that the reputation of the industry in the last decade was on the lowest that we have seen ever.
[00:20:52.280 --> 00:20:56.080]   And there are many reasons for that.
[00:20:56.080 --> 00:21:00.760]   But clearly, there are reasons that are related also with the behavior of the industry.
[00:21:00.760 --> 00:21:10.920]   That needed to change, and I'm hopeful that very few will disagree that the industry is a very different industry right now.
[00:21:12.200 --> 00:21:22.920]   That being said, I truly believe that if there is one lesson that stands out from the many lessons that we learned during COVID,
[00:21:22.920 --> 00:21:27.320]   is the power of science in the hands of the private sector.
[00:21:27.320 --> 00:21:37.560]   I think it was the private sector that came with solutions with diagnostic tests, when we didn't have,
[00:21:38.280 --> 00:21:44.360]   solutions with respirators, when we didn't have, solutions with treatments, solutions with vaccines.
[00:21:44.360 --> 00:21:56.680]   And I think that demonstrated very clearly to the world the value of a thriving life sciences sector,
[00:21:56.680 --> 00:21:58.840]   private life sciences sector to society.
[00:21:58.840 --> 00:22:06.800]   That also affected very positively the reputation, both of the sector and of Pfizer.
[00:22:08.080 --> 00:22:10.800]   I'm not going to make the mistake to consider given.
[00:22:10.800 --> 00:22:16.960]   I'm not to make the mistake that because our reputation is high, that will remain so.
[00:22:16.960 --> 00:22:19.520]   We need to earn it every day.
[00:22:19.520 --> 00:22:24.320]   Every day with everything we do, with everything we say, with the way we behave.
[00:22:24.320 --> 00:22:28.800]   And I hope that we'll rise to this occasion and we will do that.
[00:22:28.800 --> 00:22:32.120]   You've been at Pfizer for 28 years.
[00:22:32.120 --> 00:22:33.720]   Time flies when you're having fun.
[00:22:33.720 --> 00:22:37.000]   And you've become CEO in 2019.
[00:22:37.720 --> 00:22:41.000]   It is a company you love, a company you believe in.
[00:22:41.000 --> 00:22:45.560]   It's a company that has developed drugs that has helped millions of people.
[00:22:45.560 --> 00:22:51.720]   So let me ask yet another hard question on this topic of reputation.
[00:22:51.720 --> 00:23:00.480]   In 2009, Pfizer pleaded guilty to the illegal marketing of arthritis drug Bextra and agreed to a $2.3 billion settlement.
[00:23:00.480 --> 00:23:07.280]   How do you make sense of the fact that this happened to a company you love and that you believe in?
[00:23:07.880 --> 00:23:08.400]   Yes.
[00:23:08.400 --> 00:23:15.240]   The Bextra case in 2009 was related to things that happened in 2003.
[00:23:15.240 --> 00:23:23.280]   And the things that happened in 2003 were things that basically several of our reps did off-label promotion.
[00:23:23.280 --> 00:23:29.400]   So they spoke about, with the physicians, about off-label use of the product.
[00:23:29.400 --> 00:23:30.360]   And they shouldn't.
[00:23:30.360 --> 00:23:32.560]   Can you clarify?
[00:23:32.560 --> 00:23:36.520]   So off-label are things that the FDA didn't approve, extra stuff.
[00:23:37.040 --> 00:23:40.680]   You basically say this drug does extra stuff that the FDA never approved.
[00:23:40.680 --> 00:23:41.160]   Correct.
[00:23:41.160 --> 00:23:45.360]   And this is something that is allowed when physicians are speaking to physicians.
[00:23:45.360 --> 00:23:52.360]   But it is not allowed for the pharmaceutical companies to refer to these studies, because usually are studies that are happening off-label.
[00:23:52.360 --> 00:23:56.720]   And apparently several of our reps in 2003, they did it.
[00:23:56.720 --> 00:24:02.440]   And we had to settle in 2009.
[00:24:02.440 --> 00:24:04.680]   And we paid a very big fine, as you said.
[00:24:05.200 --> 00:24:09.960]   The fine was related not to the severity of the conduct, but the size of the revenues.
[00:24:09.960 --> 00:24:14.440]   So the fines are, if Bextra was a small product, we would get a small fine.
[00:24:14.440 --> 00:24:15.600]   Bextra was a very big product.
[00:24:15.600 --> 00:24:17.080]   And we got a very large fine.
[00:24:17.080 --> 00:24:20.520]   Very bad, what happened in 2003.
[00:24:20.520 --> 00:24:26.160]   I don't think that these things happened since then.
[00:24:26.160 --> 00:24:34.640]   We have a stellar record from 2009 until now of complying with every single regulation and rule.
[00:24:35.080 --> 00:24:41.480]   We have internal processes to make sure that these are not happening by individuals that may have an interest.
[00:24:41.480 --> 00:24:46.680]   For example, to get a promotion, they may try and do things that are not the right things.
[00:24:46.680 --> 00:24:55.960]   And we have, more importantly, a culture in this company that really sets aside people that they think differently.
[00:24:55.960 --> 00:25:00.120]   So I didn't like what happened in 2003.
[00:25:00.120 --> 00:25:04.960]   But I believe a lot has changed in the 20 years that followed.
[00:25:05.640 --> 00:25:06.760]   Or almost 20 years.
[00:25:06.760 --> 00:25:13.880]   - So you're developing drugs, you're developing solutions to help millions of people, but there's risk involved.
[00:25:13.880 --> 00:25:23.920]   And so there would be lawsuits heading back your way, because there's a lot of lawyers in the world, partially.
[00:25:23.920 --> 00:25:32.760]   How do you put that into the calculation of how you try to do good in the world?
[00:25:33.760 --> 00:25:37.560]   That some of the cost is the lawsuits.
[00:25:37.560 --> 00:25:44.280]   How do you not fall victim to thinking that it's just the cost of doing business,
[00:25:44.280 --> 00:25:48.960]   and that some of the lawsuits might actually represent real pain that people are going through?
[00:25:48.960 --> 00:25:52.280]   - I think that we try always to do the right thing.
[00:25:52.280 --> 00:25:56.480]   And that's, as I said, very well embedded into our culture.
[00:25:56.480 --> 00:26:00.520]   If you don't do the right thing, sooner or later you will pay for it.
[00:26:00.520 --> 00:26:02.280]   One way or another.
[00:26:03.080 --> 00:26:10.600]   And right now, for us doing the right thing, it is being able to find innovations to issues that are real.
[00:26:10.600 --> 00:26:17.000]   Diseases that they do not have good coverage, good treatments right now.
[00:26:17.000 --> 00:26:24.880]   We try to find treatments that significantly surpass the current standards of care.
[00:26:24.880 --> 00:26:30.240]   And we try not only to comply with what regulators are asking us to do.
[00:26:30.240 --> 00:26:33.160]   This is what you need to do to prove the safety or the efficacy.
[00:26:33.160 --> 00:26:34.880]   But exceed them.
[00:26:34.880 --> 00:26:39.480]   No matter what we do on that, I'm sure that people will find opportunity,
[00:26:39.480 --> 00:26:42.680]   because as you said, there are a lot of lawyers, to sue us.
[00:26:42.680 --> 00:26:44.440]   But we believe in the justice system.
[00:26:44.440 --> 00:26:49.800]   And we believe that eventually, if you are doing the right thing,
[00:26:49.800 --> 00:26:53.120]   you will be on the right side of the history.
[00:26:53.120 --> 00:26:59.400]   - I'm really glad you say that, because focusing on doing the right thing,
[00:26:59.400 --> 00:27:03.360]   no matter the money, I believe is the best way to make money.
[00:27:03.360 --> 00:27:04.880]   - That's exactly what I said.
[00:27:04.880 --> 00:27:08.600]   - And also, in another way, in other realms,
[00:27:08.600 --> 00:27:11.760]   creating a product that people love is the best way to make money.
[00:27:11.760 --> 00:27:16.640]   So focusing on the core of the thing that makes people feel good,
[00:27:16.640 --> 00:27:18.240]   that brings value to people's lives.
[00:27:18.240 --> 00:27:22.160]   So I'm now in Austin, Texas.
[00:27:22.160 --> 00:27:27.200]   My good friend Joe Rogan, he's been highlighting to me
[00:27:27.200 --> 00:27:32.320]   this aggressive marketing on mainstream media channels by Pfizer.
[00:27:32.320 --> 00:27:35.320]   So let me ask a general marketing question.
[00:27:35.320 --> 00:27:37.400]   Do you see this as a conflict of interest?
[00:27:37.400 --> 00:27:40.560]   Is it my bias, the reporting of news?
[00:27:40.560 --> 00:27:44.320]   That a lot of us, a lot of people, me included,
[00:27:44.320 --> 00:27:48.800]   look to these mainstream channels of news for kind of authority,
[00:27:48.800 --> 00:27:51.560]   of like, what the heck's going on in the world?
[00:27:51.560 --> 00:28:00.240]   And if Pfizer is sponsoring many of these shows,
[00:28:00.240 --> 00:28:03.360]   there's a worry, it may be a perception thing,
[00:28:03.360 --> 00:28:06.040]   but there's also a natural worry that it would influence
[00:28:06.040 --> 00:28:07.120]   what they're talking about,
[00:28:07.120 --> 00:28:08.960]   'cause they're afraid of losing the sponsorship.
[00:28:08.960 --> 00:28:12.880]   It's subtle, but at scale, it might have a serious impact.
[00:28:12.880 --> 00:28:14.760]   Do you worry about this?
[00:28:14.760 --> 00:28:17.960]   - I think people could go one way or another
[00:28:17.960 --> 00:28:21.360]   because of multiple reasons.
[00:28:21.360 --> 00:28:23.040]   From our perspective,
[00:28:23.040 --> 00:28:28.760]   I don't think we have aggressive marketing.
[00:28:28.760 --> 00:28:33.480]   What we do, we go on TV and we are having ads
[00:28:33.480 --> 00:28:38.240]   about our products and they're highly regulated.
[00:28:38.240 --> 00:28:41.440]   I think it is the right of people to know, to learn,
[00:28:41.440 --> 00:28:43.760]   that if there is a product like that,
[00:28:43.760 --> 00:28:47.280]   it's very clearly that we cannot say things
[00:28:47.280 --> 00:28:49.640]   that they are off-label, that have not been approved.
[00:28:49.640 --> 00:28:52.600]   We need to have, every time we go on TV, as you know,
[00:28:52.600 --> 00:28:55.760]   FDA is forcing us to say also the bad things
[00:28:55.760 --> 00:28:57.400]   that can happen for a medicine.
[00:28:57.400 --> 00:29:01.360]   Sometimes that takes more time than the good things.
[00:29:01.360 --> 00:29:04.680]   And I don't think that we are doing aggressive marketing.
[00:29:04.680 --> 00:29:09.600]   Now, people could be influenced and can be biased
[00:29:09.600 --> 00:29:13.480]   in the podcasts or in the other type of media activities
[00:29:13.480 --> 00:29:17.520]   that they have for multiple different reasons.
[00:29:17.520 --> 00:29:20.040]   - Yeah, I know, but it's still, it's pressure.
[00:29:20.040 --> 00:29:20.880]   It's human nature.
[00:29:20.880 --> 00:29:24.520]   I mean, one of it is perception, but I worry about it too.
[00:29:24.520 --> 00:29:27.520]   I have a ton of sponsors for this podcast, for example,
[00:29:27.520 --> 00:29:30.400]   and none of them ever ask me to anything.
[00:29:30.400 --> 00:29:33.880]   They're just, you know, I think likely that kind
[00:29:33.880 --> 00:29:36.320]   of pressure is not happening for Pfizer,
[00:29:36.320 --> 00:29:39.400]   but there's implied pressure sometimes.
[00:29:39.400 --> 00:29:43.120]   And I worry about that a lot because, you know,
[00:29:43.120 --> 00:29:44.720]   I look at academia.
[00:29:45.560 --> 00:29:48.360]   Like I look for the good in people.
[00:29:48.360 --> 00:29:50.160]   I tend to believe most people are good
[00:29:50.160 --> 00:29:54.760]   or have the capacity to be good and desire to be good.
[00:29:54.760 --> 00:29:59.760]   When I came to MIT, I was a little bit disappointed,
[00:29:59.760 --> 00:30:03.240]   maybe heartbroken.
[00:30:03.240 --> 00:30:10.880]   How much pressure, I think unjustified pressure
[00:30:10.880 --> 00:30:15.200]   people felt from financial constraints,
[00:30:15.200 --> 00:30:18.000]   especially at MIT when there's, I think, a lot of money.
[00:30:18.000 --> 00:30:22.680]   People still felt constraints and they weren't,
[00:30:22.680 --> 00:30:24.480]   it wasn't bringing out the best in them.
[00:30:24.480 --> 00:30:25.640]   They weren't supporting each other.
[00:30:25.640 --> 00:30:26.920]   They weren't loving each other,
[00:30:26.920 --> 00:30:30.000]   like celebrating each other's successes.
[00:30:30.000 --> 00:30:32.000]   I don't want to blame money on everything,
[00:30:32.000 --> 00:30:35.440]   money constraints, but when you have sponsors,
[00:30:35.440 --> 00:30:39.320]   it just, I personally worry that it doesn't bring
[00:30:39.320 --> 00:30:41.320]   the best out of people.
[00:30:41.320 --> 00:30:44.800]   And so I feel like I want to put some responsibility
[00:30:44.800 --> 00:30:49.440]   on sponsors and great big companies like Pfizer
[00:30:49.440 --> 00:30:54.440]   to kind of not get in the way of the best of human nature,
[00:30:54.440 --> 00:31:01.680]   whether it's sponsoring podcasts, mainstream media,
[00:31:01.680 --> 00:31:05.160]   like, I don't know, athletes, whatever.
[00:31:05.160 --> 00:31:08.000]   - You need to know that we are so, so careful
[00:31:08.000 --> 00:31:09.240]   with sponsorships.
[00:31:09.240 --> 00:31:12.120]   First of all, we have very few, very, very few.
[00:31:12.120 --> 00:31:14.640]   We have a team that for every single one
[00:31:14.640 --> 00:31:16.800]   could be $2,000.
[00:31:16.800 --> 00:31:19.240]   They will try to see if there is a conflict of interest
[00:31:19.240 --> 00:31:20.400]   in the way we do it.
[00:31:20.400 --> 00:31:25.400]   And also what is the reputation of the persons
[00:31:25.400 --> 00:31:27.840]   or the programs that we are sponsoring.
[00:31:27.840 --> 00:31:32.560]   So I don't think, our friend, I think was from Texas.
[00:31:32.560 --> 00:31:33.480]   - Yes. - Yeah.
[00:31:33.480 --> 00:31:35.840]   - Mr. Jarogan, yes. - Yes.
[00:31:35.840 --> 00:31:39.280]   I don't think he got it right that we do
[00:31:39.280 --> 00:31:40.360]   those type of things.
[00:31:40.360 --> 00:31:42.160]   We don't.
[00:31:42.160 --> 00:31:44.400]   - Oh, in terms of like having a negative effect
[00:31:44.400 --> 00:31:45.360]   on-- - Not even having
[00:31:45.360 --> 00:31:46.560]   aggressive sponsorships.
[00:31:46.560 --> 00:31:48.040]   We have very few.
[00:31:48.040 --> 00:31:49.880]   - Yeah, when you clip them all together.
[00:31:49.880 --> 00:31:51.480]   - And most of the sponsorships that we have,
[00:31:51.480 --> 00:31:55.000]   it is more on patient-related organizations.
[00:31:55.000 --> 00:31:56.360]   - Right. - Rather than,
[00:31:56.360 --> 00:31:58.840]   we are very careful not to sponsor other things
[00:31:58.840 --> 00:32:02.320]   that can be perceived, not even influenced,
[00:32:02.320 --> 00:32:03.720]   but perceived that we may influence.
[00:32:03.720 --> 00:32:05.320]   So we are very, very careful on that.
[00:32:05.320 --> 00:32:07.440]   This is not the case with us.
[00:32:07.440 --> 00:32:11.900]   - So with the incredibly fast development of the vaccine,
[00:32:13.360 --> 00:32:16.840]   could you tell me the story from the engineering
[00:32:16.840 --> 00:32:19.320]   to the science to the human story
[00:32:19.320 --> 00:32:21.820]   of how you could do it so fast?
[00:32:21.820 --> 00:32:26.360]   By November, you even had the ambition to do it by October.
[00:32:26.360 --> 00:32:28.520]   It was in the initial days.
[00:32:28.520 --> 00:32:31.140]   How do you-- - Eight days later.
[00:32:31.140 --> 00:32:33.480]   - In that time, how do you show
[00:32:33.480 --> 00:32:35.740]   that the vaccine is safe and effective,
[00:32:35.740 --> 00:32:38.800]   given that I think previous vaccines
[00:32:38.800 --> 00:32:40.280]   have taken years to do that?
[00:32:40.280 --> 00:32:41.440]   - Yeah.
[00:32:41.440 --> 00:32:43.200]   The vaccines take years to do that.
[00:32:43.200 --> 00:32:46.560]   And the time that it takes,
[00:32:46.560 --> 00:32:50.280]   it is basically the vast majority of the time
[00:32:50.280 --> 00:32:53.120]   to conduct the final phase three study,
[00:32:53.120 --> 00:32:55.440]   if that is the confirmatory study.
[00:32:55.440 --> 00:32:57.120]   And you do that because the phase three study
[00:32:57.120 --> 00:32:57.960]   cost a lot of money.
[00:32:57.960 --> 00:33:00.660]   In our case, it cost almost a billion.
[00:33:00.660 --> 00:33:03.760]   So you don't want to go and risk a billion
[00:33:03.760 --> 00:33:05.860]   in blinded data normally,
[00:33:05.860 --> 00:33:08.720]   before you do a lot of experiments
[00:33:08.720 --> 00:33:10.920]   to make sure that the product that you're putting
[00:33:10.920 --> 00:33:13.020]   in the phase three is the right one.
[00:33:13.020 --> 00:33:15.080]   We didn't have that time.
[00:33:15.080 --> 00:33:17.520]   So we risk all the money.
[00:33:17.520 --> 00:33:21.760]   So we went into, we condensed all the time
[00:33:21.760 --> 00:33:23.120]   towards this phase three.
[00:33:23.120 --> 00:33:27.120]   But the phase three study had to follow all the rules
[00:33:27.120 --> 00:33:31.600]   that any study follows when you do this trial.
[00:33:31.600 --> 00:33:34.840]   - Could you just briefly describe the basics
[00:33:34.840 --> 00:33:37.040]   of what is phase one, what is phase two,
[00:33:37.040 --> 00:33:37.880]   what is phase three?
[00:33:37.880 --> 00:33:39.920]   - Let's say that there are so many phases
[00:33:39.920 --> 00:33:41.480]   when you try, first of all,
[00:33:41.480 --> 00:33:43.620]   to find what is the right vaccine.
[00:33:43.620 --> 00:33:45.980]   We tried from 20 different vaccines,
[00:33:45.980 --> 00:33:47.760]   we nailed down to four.
[00:33:47.760 --> 00:33:50.360]   And for those four, we selected eventually two,
[00:33:50.360 --> 00:33:52.360]   and then eventually one.
[00:33:52.360 --> 00:33:55.400]   Once you have those selections,
[00:33:55.400 --> 00:33:57.140]   what is the dose you're going to use?
[00:33:57.140 --> 00:34:00.000]   And then we tried multiple different doses
[00:34:00.000 --> 00:34:02.440]   to see which one we think is the best.
[00:34:02.440 --> 00:34:05.200]   - What does trying entail in those early days?
[00:34:05.200 --> 00:34:10.200]   - You go, first of all, with smaller doses in humans.
[00:34:11.380 --> 00:34:13.960]   And then after you have done a lot of experiments
[00:34:13.960 --> 00:34:17.320]   in animals so that you can feel that it is safe enough
[00:34:17.320 --> 00:34:20.500]   to go to humans and then go with very low dose.
[00:34:20.500 --> 00:34:22.200]   And then you gradually increase the dose
[00:34:22.200 --> 00:34:24.800]   and then you monitor those humans to make sure
[00:34:24.800 --> 00:34:28.360]   that there are not any, let's say, reactogenicity
[00:34:28.360 --> 00:34:29.760]   to what you are giving them.
[00:34:29.760 --> 00:34:32.040]   At the same time, you start to measure what is doing
[00:34:32.040 --> 00:34:34.520]   in terms of immune responses.
[00:34:34.520 --> 00:34:36.160]   So you do that with multiple vaccines
[00:34:36.160 --> 00:34:37.800]   and you do that with multiple doses
[00:34:37.800 --> 00:34:40.560]   and you do that with multiple ages of people,
[00:34:40.560 --> 00:34:42.520]   young people, old people.
[00:34:42.520 --> 00:34:47.060]   And eventually, from the 20 vaccines to multiple doses,
[00:34:47.060 --> 00:34:50.000]   to multiple schedules, is it after three weeks,
[00:34:50.000 --> 00:34:52.000]   the second dose, or is it after four weeks
[00:34:52.000 --> 00:34:53.840]   or after six months?
[00:34:53.840 --> 00:34:58.840]   All of that will inform you that I think this is the vaccine,
[00:34:58.840 --> 00:35:02.420]   this is the dose, this is the scheme
[00:35:02.420 --> 00:35:05.560]   that I believe will give me the best results.
[00:35:05.560 --> 00:35:06.560]   And when you have that,
[00:35:06.560 --> 00:35:09.880]   then you go to do what we call the phase three.
[00:35:09.880 --> 00:35:14.160]   This is a very big study, thousands of people,
[00:35:14.160 --> 00:35:17.400]   where you use the vaccine that you think is the right one,
[00:35:17.400 --> 00:35:19.640]   and a placebo.
[00:35:19.640 --> 00:35:22.560]   The placebo and the vaccine, they look identical.
[00:35:22.560 --> 00:35:26.640]   Nobody knows if he's injected a placebo or a vaccine.
[00:35:26.640 --> 00:35:29.200]   The physician that makes the injection,
[00:35:29.200 --> 00:35:32.920]   the doctor doesn't know if he's injecting placebo or vaccine.
[00:35:32.920 --> 00:35:35.320]   He knows a barcode.
[00:35:35.320 --> 00:35:37.400]   Only the computer knows.
[00:35:37.400 --> 00:35:39.000]   In order to go into this computer,
[00:35:39.000 --> 00:35:41.400]   there are keys, and there are at least two people
[00:35:41.400 --> 00:35:42.840]   that needs to put their keys
[00:35:42.840 --> 00:35:44.960]   so that someone can see the data.
[00:35:44.960 --> 00:35:48.320]   And those people, they have legal obligations
[00:35:48.320 --> 00:35:49.860]   never to do that, right?
[00:35:49.860 --> 00:35:52.240]   So before a certain point.
[00:35:52.240 --> 00:35:53.920]   So all of that is blind.
[00:35:53.920 --> 00:35:58.200]   The idea is that when you go into this study,
[00:35:58.200 --> 00:36:00.640]   you need to make sure that you are going with the right one.
[00:36:00.640 --> 00:36:02.760]   That's why it takes so much time.
[00:36:02.760 --> 00:36:04.380]   But the study is the study.
[00:36:04.380 --> 00:36:07.280]   You need to have a significant number of people
[00:36:07.280 --> 00:36:09.040]   that will give the two,
[00:36:09.040 --> 00:36:10.880]   and then you let them live their lives.
[00:36:10.880 --> 00:36:13.400]   And then you see how many of them will get the disease.
[00:36:13.400 --> 00:36:16.040]   And then you see if there are differences
[00:36:16.040 --> 00:36:19.000]   in percentage of infections for the vaccinated
[00:36:19.000 --> 00:36:20.440]   compared to the non-vaccinated.
[00:36:20.440 --> 00:36:22.440]   At the same time, you're monitoring all of them
[00:36:22.440 --> 00:36:25.160]   to see if there are differences in the safety profile.
[00:36:25.160 --> 00:36:27.160]   If those that they go to placebo have the same,
[00:36:27.160 --> 00:36:30.840]   let's say, heart attacks with those that they didn't.
[00:36:30.840 --> 00:36:33.280]   They got the vaccine because heart attacks will happen
[00:36:33.280 --> 00:36:37.340]   if you have 50,000 people, because it's part of life.
[00:36:37.340 --> 00:36:43.560]   All these processes are very well established since years.
[00:36:43.560 --> 00:36:46.000]   What we did the last one was exactly the same
[00:36:46.000 --> 00:36:47.080]   as we did always.
[00:36:47.080 --> 00:36:48.580]   We just didn't lose time.
[00:36:48.580 --> 00:36:51.740]   We're not careful with money.
[00:36:51.740 --> 00:36:56.740]   Instead of recruiting 50,000 people over a year,
[00:36:56.740 --> 00:37:00.120]   because we had, let's say, 30 hospitals
[00:37:00.120 --> 00:37:01.760]   doing the recruitment,
[00:37:01.760 --> 00:37:04.280]   we went with 150 hospitals doing the recruitment.
[00:37:04.280 --> 00:37:05.720]   That cost a lot of money.
[00:37:05.720 --> 00:37:07.880]   But instead of recruiting them in a year,
[00:37:07.880 --> 00:37:10.000]   we recruited them in three, four months.
[00:37:10.000 --> 00:37:12.140]   So I did these type of things
[00:37:12.140 --> 00:37:15.120]   by taking return on investment,
[00:37:15.120 --> 00:37:17.200]   taking cost out of the equation,
[00:37:17.200 --> 00:37:19.120]   and we were able to achieve this result.
[00:37:19.120 --> 00:37:22.460]   But it's not the process, believe me.
[00:37:22.460 --> 00:37:24.200]   It is the heart of the people.
[00:37:24.200 --> 00:37:29.400]   People don't know what they can and what they cannot do.
[00:37:29.400 --> 00:37:32.440]   And if anything, they have a serious tendency
[00:37:32.440 --> 00:37:35.240]   to underestimate what they can do.
[00:37:35.240 --> 00:37:38.300]   And always, when you ask them something
[00:37:38.300 --> 00:37:40.600]   that is seemingly impossible,
[00:37:40.600 --> 00:37:43.540]   they will think out of the box to be able to deliver.
[00:37:43.540 --> 00:37:45.840]   We discussed about the timing.
[00:37:45.840 --> 00:37:49.440]   Instead of eight years, we didn't ask them to do it in six.
[00:37:49.440 --> 00:37:51.400]   We asked them to do it in eight months.
[00:37:51.400 --> 00:37:57.680]   Our normal manufacturing yearly production of Pfizer
[00:37:57.680 --> 00:38:00.200]   was 200 million doses of vaccines every year.
[00:38:00.200 --> 00:38:03.000]   That's what we are doing in the last 10 years.
[00:38:03.000 --> 00:38:05.280]   We didn't ask them to make 300 million doses
[00:38:05.280 --> 00:38:06.380]   for a new vaccine.
[00:38:06.380 --> 00:38:11.040]   We asked them to make 3 billion doses for a new vaccine.
[00:38:11.040 --> 00:38:13.740]   The discovery phase of a new molecule,
[00:38:13.740 --> 00:38:15.040]   like the treatment that we have now,
[00:38:15.040 --> 00:38:18.280]   the pill against COVID, takes four years.
[00:38:18.280 --> 00:38:19.640]   We didn't ask them to do it in three.
[00:38:19.640 --> 00:38:20.960]   We asked them to do it in four months,
[00:38:20.960 --> 00:38:22.540]   which is what they did.
[00:38:22.540 --> 00:38:25.820]   When you're setting this type of goals,
[00:38:25.820 --> 00:38:28.640]   they know immediately, they cannot
[00:38:28.640 --> 00:38:30.280]   just think within the box.
[00:38:30.280 --> 00:38:32.640]   And immediately, this is where the human ingenuity
[00:38:32.640 --> 00:38:34.320]   and the heart comes.
[00:38:34.320 --> 00:38:36.400]   And this is how they surprised all of us.
[00:38:36.400 --> 00:38:39.360]   - So there's incredible science
[00:38:39.360 --> 00:38:40.800]   and engineering going on here.
[00:38:40.800 --> 00:38:41.640]   - Absolutely.
[00:38:41.640 --> 00:38:45.120]   - This is what's bothering me,
[00:38:45.120 --> 00:38:50.120]   that the conversation in public is often not about that.
[00:38:50.120 --> 00:38:53.480]   - It's about politics, unfortunately.
[00:38:53.480 --> 00:38:54.320]   - Politics.
[00:38:54.320 --> 00:38:56.880]   So I spent the day with Elon Musk yesterday.
[00:38:56.880 --> 00:38:59.360]   He works with rockets.
[00:38:59.360 --> 00:39:02.460]   Similar situation is with Pfizer,
[00:39:02.460 --> 00:39:04.580]   in the sense that there's NASA
[00:39:04.580 --> 00:39:07.060]   and then there's this private company.
[00:39:07.060 --> 00:39:10.680]   And that's a source of incredible inspiration to people.
[00:39:10.680 --> 00:39:13.540]   No politics, very little politics.
[00:39:13.540 --> 00:39:18.820]   So this is part of the thing I'm trying to,
[00:39:18.820 --> 00:39:22.420]   I'm hoping to do our little part in this conversation
[00:39:22.420 --> 00:39:25.720]   to help untangle a little bit,
[00:39:25.720 --> 00:39:29.480]   just reveal the beauty and the power
[00:39:29.480 --> 00:39:31.240]   of the thing that was done here,
[00:39:31.240 --> 00:39:32.320]   especially with the vaccine,
[00:39:32.320 --> 00:39:33.560]   but other things that are being done
[00:39:33.560 --> 00:39:35.260]   with the antiviral drug.
[00:39:35.260 --> 00:39:40.020]   Let me just kind of linger on the safety.
[00:39:40.020 --> 00:39:43.600]   What can you say, there's a lot of people
[00:39:43.600 --> 00:39:48.600]   that are concerned that the Pfizer vaccine,
[00:39:48.600 --> 00:39:51.440]   by the way, of which I took two shots,
[00:39:51.440 --> 00:39:55.780]   no booster yet, is unsafe.
[00:39:55.780 --> 00:40:00.000]   What do you say to people that say that?
[00:40:00.000 --> 00:40:03.320]   - No, they should not fear something like that.
[00:40:03.320 --> 00:40:04.640]   It's completely wrong.
[00:40:04.640 --> 00:40:09.520]   There is no medical product in the history of humanity
[00:40:09.520 --> 00:40:12.720]   that have been tested as much as this vaccine
[00:40:12.720 --> 00:40:16.920]   has been administered to hundreds of millions of people.
[00:40:16.920 --> 00:40:20.000]   And because of the importance of COVID,
[00:40:20.000 --> 00:40:24.240]   they have been scrutinized, those people, constantly.
[00:40:24.240 --> 00:40:27.120]   Right now, healthcare authorities are looking
[00:40:27.120 --> 00:40:30.360]   for every single signal around the world
[00:40:30.360 --> 00:40:31.520]   of people that they got the vaccine
[00:40:31.520 --> 00:40:34.460]   and try to see if it is vaccine related or not.
[00:40:34.460 --> 00:40:36.960]   There are electronic medical records
[00:40:36.960 --> 00:40:40.600]   that will tell us when and what happened
[00:40:40.600 --> 00:40:43.540]   to a person when he did got the vaccine.
[00:40:43.540 --> 00:40:48.540]   And we know now, we have so high certainty
[00:40:49.120 --> 00:40:54.120]   that it is so safe, exactly as the data sheet says
[00:40:54.120 --> 00:40:59.160]   about this vaccine, more than any other product.
[00:40:59.160 --> 00:41:01.480]   They should not be afraid of something like that,
[00:41:01.480 --> 00:41:06.360]   and they should not listen to information
[00:41:06.360 --> 00:41:09.240]   that it is misinformation, that it is spread on purpose.
[00:41:09.240 --> 00:41:13.880]   - Well, I don't like the word misinformation,
[00:41:13.880 --> 00:41:18.880]   because, you know, again, back to the Soviet Union,
[00:41:19.160 --> 00:41:24.160]   anyone who opposes the state is spreading misinformation.
[00:41:24.160 --> 00:41:27.440]   So you can basically call anything misinformation.
[00:41:27.440 --> 00:41:29.880]   That's the unfortunate times we live in,
[00:41:29.880 --> 00:41:34.480]   is you can basically call anybody a liar
[00:41:34.480 --> 00:41:37.240]   and say I'm the sole possessor of the truth.
[00:41:37.240 --> 00:41:40.080]   And just, no offense to me, just because you wear a tie,
[00:41:40.080 --> 00:41:42.760]   it doesn't mean you're any more likely
[00:41:42.760 --> 00:41:45.640]   to be in the possession of the truth than anyone else.
[00:41:45.640 --> 00:41:47.000]   So-- - I wouldn't disagree
[00:41:47.000 --> 00:41:47.840]   with that at all.
[00:41:47.840 --> 00:41:49.280]   I don't think that-- - As somebody
[00:41:49.280 --> 00:41:50.480]   who's not wearing a tie.
[00:41:50.480 --> 00:41:53.360]   - And as people can see that I'm not wearing a tie,
[00:41:53.360 --> 00:41:54.480]   and you are.
[00:41:54.480 --> 00:41:58.800]   But it's not about being able,
[00:41:58.800 --> 00:42:03.800]   those that they have the power to impose on the others
[00:42:03.800 --> 00:42:09.320]   the stigma that what you are saying is misinformation.
[00:42:09.320 --> 00:42:12.180]   But there are a few things that as a society
[00:42:12.180 --> 00:42:15.480]   we have accomplished, and science is one of them.
[00:42:15.480 --> 00:42:20.480]   And data is, and analytics of data is another one.
[00:42:20.480 --> 00:42:26.320]   And to say that something which is highly scientific
[00:42:26.320 --> 00:42:29.020]   by people that they are not scientists,
[00:42:29.020 --> 00:42:35.520]   I think that it is not what you are describing
[00:42:35.520 --> 00:42:37.500]   what used to happen in the Soviet Union,
[00:42:37.500 --> 00:42:42.300]   or in any other autocratic regime in the world right now.
[00:42:42.300 --> 00:42:47.300]   But I definitely do think that the scientists,
[00:42:47.300 --> 00:42:49.900]   the public science communicators I've listened to
[00:42:49.900 --> 00:42:52.380]   over COVID have really disappointed me
[00:42:52.380 --> 00:42:56.780]   because they have not spoken with empathy.
[00:42:56.780 --> 00:42:58.740]   They haven't sufficiently in my view
[00:42:58.740 --> 00:43:02.140]   have put their ego aside and really listened to people.
[00:43:02.140 --> 00:43:03.980]   Yes, people that don't have a PhD,
[00:43:03.980 --> 00:43:06.320]   people who have not really,
[00:43:06.320 --> 00:43:10.460]   maybe you've not even taken a biology course in college
[00:43:10.460 --> 00:43:11.340]   or something like that.
[00:43:11.340 --> 00:43:16.340]   But still they have children, they worry, they fear,
[00:43:16.340 --> 00:43:19.000]   they don't know who to trust,
[00:43:19.000 --> 00:43:23.740]   they don't know if they should listen to the CEO of Pfizer
[00:43:23.740 --> 00:43:26.060]   who might have other incentives in mind,
[00:43:26.060 --> 00:43:29.060]   who might just care about money and nothing else.
[00:43:29.060 --> 00:43:32.580]   And so they just use common sense and they ask questions.
[00:43:32.580 --> 00:43:35.180]   And I think to them, talking down to them
[00:43:35.180 --> 00:43:36.780]   as if they're not intelligent and so on
[00:43:36.780 --> 00:43:39.540]   is something scientists have done,
[00:43:39.540 --> 00:43:40.660]   almost like rolled their eyes.
[00:43:40.660 --> 00:43:42.900]   And that disappoints me because I think
[00:43:42.900 --> 00:43:45.660]   that's kind of what is the source of division.
[00:43:45.660 --> 00:43:47.500]   - Look, humility is a virtue.
[00:43:47.500 --> 00:43:48.340]   - Yes, yes.
[00:43:48.340 --> 00:43:51.580]   - And the fact that you are educated
[00:43:51.580 --> 00:43:56.060]   doesn't mean that you are having either humility or empathy
[00:43:56.060 --> 00:43:58.660]   or you have good human qualities.
[00:43:58.660 --> 00:44:03.340]   This was never and will never be a metric
[00:44:03.340 --> 00:44:05.140]   of judging this type of virtues.
[00:44:05.140 --> 00:44:09.500]   Those that they do this, they're wrong.
[00:44:09.500 --> 00:44:13.900]   And actually they are not doing good service
[00:44:13.900 --> 00:44:15.860]   to the public health because they're undermining.
[00:44:15.860 --> 00:44:17.100]   People are not stupid.
[00:44:17.100 --> 00:44:21.300]   They see if you're not be respecting them.
[00:44:21.300 --> 00:44:23.980]   And if you're not respecting their need to learn
[00:44:23.980 --> 00:44:25.220]   because that affects their health,
[00:44:25.220 --> 00:44:27.100]   the health of the mother or the kids.
[00:44:27.100 --> 00:44:31.540]   So I fully agree with you that we should be very patient
[00:44:31.540 --> 00:44:36.100]   to explain again and again and again what is happening.
[00:44:36.100 --> 00:44:37.900]   And the vast majority of the people
[00:44:37.900 --> 00:44:39.740]   that they don't get vaccinations right now
[00:44:39.740 --> 00:44:41.140]   is because they're afraid.
[00:44:41.140 --> 00:44:42.540]   It's not for any other reason.
[00:44:42.540 --> 00:44:44.900]   It's not that they have an agenda.
[00:44:44.900 --> 00:44:48.820]   What I'm saying it is there is a small number of people
[00:44:48.820 --> 00:44:52.780]   that they have make business for them
[00:44:52.780 --> 00:44:56.820]   to profit from this anxiety.
[00:44:56.820 --> 00:44:58.060]   I'll give you an example.
[00:44:58.060 --> 00:45:00.900]   I have been arrested by FBI.
[00:45:00.900 --> 00:45:03.620]   This is what someone wrote.
[00:45:03.620 --> 00:45:05.460]   I read it, I laughed.
[00:45:05.460 --> 00:45:08.900]   I mean, okay, this is where they take it.
[00:45:08.900 --> 00:45:11.180]   There was a reason why they wrote it down.
[00:45:11.180 --> 00:45:13.060]   The Pfizer CEO was arrested by FBI
[00:45:13.060 --> 00:45:15.180]   because they want to create doubts
[00:45:15.180 --> 00:45:18.020]   in the minds of the people that they're afraid
[00:45:18.020 --> 00:45:19.660]   and say, look, if the FBI arrested him,
[00:45:19.660 --> 00:45:21.460]   likely I will not do the vaccine.
[00:45:21.460 --> 00:45:22.900]   But I laughed.
[00:45:22.900 --> 00:45:27.900]   A week later, the wife of the Pfizer CEO died.
[00:45:27.900 --> 00:45:32.340]   There is a picture in this website of my wife.
[00:45:34.060 --> 00:45:38.540]   Someone sends to me, now I'm pissed, I'm not laughing.
[00:45:38.540 --> 00:45:41.020]   I try to find my kids to tell them,
[00:45:41.020 --> 00:45:44.140]   if you read something, mom is fine, don't worry.
[00:45:44.140 --> 00:45:49.140]   Then I remember that she has very old parents back in Greece.
[00:45:49.140 --> 00:45:51.340]   We start calling them to making sure
[00:45:51.340 --> 00:45:53.060]   because we know that that will be picked up
[00:45:53.060 --> 00:45:56.100]   by Greek newspapers and they will publish it, okay?
[00:45:56.100 --> 00:45:58.380]   They are those people that wrote these things.
[00:45:58.380 --> 00:46:01.060]   They know very well that my wife didn't die
[00:46:01.060 --> 00:46:04.860]   and died because she was vaccinated, right?
[00:46:04.860 --> 00:46:09.860]   So this is the narratives that they are on purpose forming
[00:46:09.860 --> 00:46:14.260]   to profit from the stress
[00:46:14.260 --> 00:46:18.500]   and the anxiety of good people.
[00:46:18.500 --> 00:46:20.420]   - And that's something I have to,
[00:46:20.420 --> 00:46:23.520]   people that listen to this, that kind of doubt institutions,
[00:46:23.520 --> 00:46:29.180]   I do also want to say that there's quite a few folks
[00:46:29.180 --> 00:46:34.180]   who realize they can make money from saying,
[00:46:34.180 --> 00:46:40.260]   the man is lying to you, the government is lying to you,
[00:46:40.260 --> 00:46:43.840]   it's all corrupt, it's all a scam,
[00:46:43.840 --> 00:46:48.340]   big pharma is lying to you, they're manipulating you.
[00:46:48.340 --> 00:46:51.660]   I'm surprised at how much money can be made with that.
[00:46:51.660 --> 00:46:52.660]   And it's sad.
[00:46:52.660 --> 00:46:56.540]   So you have to, just as people use their common sense
[00:46:56.540 --> 00:47:00.380]   to be skeptical when listening to politicians
[00:47:00.380 --> 00:47:03.300]   and powerful figures, they should be skeptical
[00:47:03.300 --> 00:47:06.940]   to also when listening to sort of the conspiracy theorists
[00:47:06.940 --> 00:47:08.700]   or not even the conspiracy theorists,
[00:47:08.700 --> 00:47:11.780]   but people who raise questions about institutions.
[00:47:11.780 --> 00:47:16.420]   Think on your own, think critically with an open mind
[00:47:16.420 --> 00:47:19.620]   that everyone could be manipulating you,
[00:47:19.620 --> 00:47:22.760]   but also everybody has the capacity to do good.
[00:47:22.760 --> 00:47:26.180]   And I think science in its pure form,
[00:47:26.180 --> 00:47:31.180]   not when entangled with institutions is a beautiful thing.
[00:47:31.180 --> 00:47:33.180]   And in the hands of many companies,
[00:47:33.180 --> 00:47:35.280]   it is a beautiful thing at scale.
[00:47:35.280 --> 00:47:39.500]   Still, you have a lot of incentive
[00:47:39.500 --> 00:47:42.740]   as having created the vaccine at Pfizer,
[00:47:42.740 --> 00:47:47.740]   this incredible technology to sing it praises.
[00:47:47.740 --> 00:47:53.700]   So there's a kind of, people are skeptical,
[00:47:53.700 --> 00:47:57.460]   like how much do we trust how excited Albert
[00:47:57.460 --> 00:48:00.740]   is about this vaccine?
[00:48:00.740 --> 00:48:04.660]   So for example, not to do a Shakespearean analysis
[00:48:04.660 --> 00:48:07.220]   of you Twitter, but I think you tweeted something
[00:48:07.220 --> 00:48:11.760]   about a study with 100% efficacy of the vaccine
[00:48:11.760 --> 00:48:14.640]   or in stopping the transmission or something like that.
[00:48:14.640 --> 00:48:20.860]   Do you regret sort of being, like over-representing
[00:48:23.520 --> 00:48:24.900]   the effectiveness of the vaccine,
[00:48:24.900 --> 00:48:27.600]   technically saying correct things,
[00:48:27.600 --> 00:48:32.600]   but just kind of like highlighting the super positive things
[00:48:32.600 --> 00:48:36.380]   that may be misinterpreted, you know, saying 100%?
[00:48:36.380 --> 00:48:38.380]   - No, I never said something 100%.
[00:48:38.380 --> 00:48:41.500]   Every time I speak, if a number is 100%,
[00:48:41.500 --> 00:48:44.580]   I rush to say that in biology, there is nothing 100%,
[00:48:44.580 --> 00:48:47.560]   because always there will be when you go to the millions.
[00:48:47.560 --> 00:48:50.140]   There were in the study things that were 100%,
[00:48:50.140 --> 00:48:52.740]   for example, deaths, or in South Africa.
[00:48:52.740 --> 00:48:56.500]   When we tried, there was 100% efficacy.
[00:48:56.500 --> 00:48:58.180]   Clearly, it's more numbers.
[00:48:58.180 --> 00:49:00.940]   When the numbers will become much bigger,
[00:49:00.940 --> 00:49:04.880]   the 100% will not hold, but will be 95, 96.
[00:49:04.880 --> 00:49:07.300]   So still, the direction of this is the point.
[00:49:07.300 --> 00:49:11.460]   So I'm very, very careful what I tweet.
[00:49:11.460 --> 00:49:15.660]   And in addition to how careful I am,
[00:49:15.660 --> 00:49:18.180]   I have people that they are looking at
[00:49:18.180 --> 00:49:20.460]   and they're having second or third opinions
[00:49:20.460 --> 00:49:21.580]   to make sure that we don't put.
[00:49:21.580 --> 00:49:22.540]   Why?
[00:49:22.540 --> 00:49:24.900]   Because I know that people are listening to me right now,
[00:49:24.900 --> 00:49:26.300]   everything I say.
[00:49:26.300 --> 00:49:29.260]   And I want to make sure that they continue
[00:49:29.260 --> 00:49:34.220]   not only being clear as to what I want to say,
[00:49:34.220 --> 00:49:35.980]   so there are no misunderstandings,
[00:49:35.980 --> 00:49:38.620]   but also I maintain the trust of the people.
[00:49:38.620 --> 00:49:43.140]   I don't think that someone who only cherry-picks information
[00:49:43.140 --> 00:49:45.940]   and only emphasizes positive things,
[00:49:45.940 --> 00:49:48.380]   it's someone that it is the one to be trusted.
[00:49:48.380 --> 00:49:51.140]   And I want me and Pfizer to be trusted.
[00:49:52.060 --> 00:49:55.660]   - So many felt the vaccine was presented as a cure
[00:49:55.660 --> 00:49:58.780]   that wouldn't require regular booster shots.
[00:49:58.780 --> 00:50:00.940]   Was that something you believed early on?
[00:50:00.940 --> 00:50:02.900]   Did you always believe that many regular shots
[00:50:02.900 --> 00:50:04.220]   would be required?
[00:50:04.220 --> 00:50:07.100]   And maybe in a bigger picture, how many,
[00:50:07.100 --> 00:50:10.160]   do you think this will, for the Pfizer vaccine,
[00:50:10.160 --> 00:50:13.120]   is it something you see that's taking a booster shot
[00:50:13.120 --> 00:50:15.100]   regularly, like annually?
[00:50:15.100 --> 00:50:17.940]   - Yes, in the beginning when we had the first months
[00:50:17.940 --> 00:50:19.900]   with the vaccine, people would ask me,
[00:50:19.900 --> 00:50:20.900]   do we need another one?
[00:50:20.900 --> 00:50:22.460]   And I said, we don't know.
[00:50:22.460 --> 00:50:24.220]   I was very clear about it.
[00:50:24.220 --> 00:50:27.020]   Then around April, May, I start seeing the first data
[00:50:27.020 --> 00:50:31.740]   and I made statements that I think we will need a booster
[00:50:31.740 --> 00:50:34.860]   around eight to 12 months after the second dose.
[00:50:34.860 --> 00:50:37.380]   And then after that, annual revaccinations,
[00:50:37.380 --> 00:50:38.980]   this is what I said,
[00:50:38.980 --> 00:50:41.340]   believe is one of the most likely scenarios.
[00:50:41.340 --> 00:50:44.380]   And it was based on the data that I had,
[00:50:44.380 --> 00:50:46.180]   but then Delta came.
[00:50:46.180 --> 00:50:48.940]   And because I always making the caveat
[00:50:48.940 --> 00:50:52.820]   that with absent a new variant, with everything we know.
[00:50:52.820 --> 00:50:55.460]   With Delta, it was proven that we need the booster
[00:50:55.460 --> 00:50:58.060]   to move to the six months.
[00:50:58.060 --> 00:51:00.620]   And this is what happened.
[00:51:00.620 --> 00:51:05.340]   And I still said, I think the booster is a six months,
[00:51:05.340 --> 00:51:08.180]   and then I think it will be an annual revaccination.
[00:51:08.180 --> 00:51:10.780]   Likely, we have to monitor to see the data,
[00:51:10.780 --> 00:51:12.820]   but this is the likely scenario.
[00:51:12.820 --> 00:51:14.980]   Now we have Omicron.
[00:51:14.980 --> 00:51:18.980]   And Omicron says that two doses might be challenging.
[00:51:18.980 --> 00:51:22.700]   We don't know exactly yet, but three doses work.
[00:51:22.700 --> 00:51:26.140]   So clearly a lot of countries already started moving now
[00:51:26.140 --> 00:51:29.700]   the third dose, not from six months to three.
[00:51:29.700 --> 00:51:33.100]   So that they will reduce the period
[00:51:33.100 --> 00:51:38.100]   that people will not be protected with the third dose.
[00:51:38.100 --> 00:51:44.620]   I don't know with Omicron, if how long this will last.
[00:51:44.620 --> 00:51:47.020]   And frankly, I don't know if we will need a new vaccine
[00:51:47.020 --> 00:51:48.820]   tailor-made to Omicron,
[00:51:48.820 --> 00:51:51.020]   based on everything we know so far.
[00:51:51.020 --> 00:51:53.180]   We are monitoring and we will know way more
[00:51:53.180 --> 00:51:54.660]   in the weeks to come.
[00:51:54.660 --> 00:51:58.140]   If there is a need for a new vaccine, we will have it.
[00:51:58.140 --> 00:52:00.580]   And if there is a need for mass production
[00:52:00.580 --> 00:52:04.100]   of this new vaccine, I can also feel very comfortable
[00:52:04.100 --> 00:52:06.620]   that we will not lose any of our capacity
[00:52:06.620 --> 00:52:08.020]   that we have developed.
[00:52:08.020 --> 00:52:10.500]   Right now we are running at 1 billion,
[00:52:10.500 --> 00:52:14.060]   almost approximately, doses per quarter,
[00:52:14.060 --> 00:52:15.740]   four per year.
[00:52:15.740 --> 00:52:18.780]   And if we have to switch and have half of that
[00:52:18.780 --> 00:52:20.060]   in the new, half of that in the old,
[00:52:20.060 --> 00:52:21.980]   we will do still 4 billion doses.
[00:52:21.980 --> 00:52:26.220]   So I think the world should feel very, very comfortable
[00:52:26.220 --> 00:52:29.940]   that if there is a need, we will be ahead of the virus.
[00:52:29.940 --> 00:52:32.380]   - Yeah, you did, you delivered or produced
[00:52:32.380 --> 00:52:34.340]   3 billion this year vaccines.
[00:52:34.340 --> 00:52:37.460]   And you're on track to do 4 billion next year.
[00:52:37.460 --> 00:52:41.620]   I mean, if we had a lot more time,
[00:52:41.620 --> 00:52:43.260]   we would talk about how the heck you achieve
[00:52:43.260 --> 00:52:44.100]   that kind of scale.
[00:52:44.100 --> 00:52:46.060]   It's truly incredible.
[00:52:46.060 --> 00:52:47.940]   Let me ask the policy question.
[00:52:47.940 --> 00:52:51.060]   What are your feelings about vaccine mandates
[00:52:51.060 --> 00:52:56.380]   in terms of, do you think the most effective way
[00:52:56.380 --> 00:53:00.220]   to vaccinate the population is to require it?
[00:53:00.220 --> 00:53:04.780]   Or do you go with the American way
[00:53:04.780 --> 00:53:07.380]   and give people the freedom to choose?
[00:53:07.380 --> 00:53:11.780]   - I think it is a very difficult topic
[00:53:11.780 --> 00:53:15.020]   and a very difficult decision for whoever needs to make it.
[00:53:15.020 --> 00:53:16.580]   And clearly it's not me.
[00:53:16.580 --> 00:53:18.980]   It is the public health officials of every country
[00:53:18.980 --> 00:53:21.180]   that they have to make this decision.
[00:53:21.180 --> 00:53:24.660]   I have to make the decision for Pfizer employees.
[00:53:24.660 --> 00:53:29.660]   And I had to balance the fear of those that they work,
[00:53:29.660 --> 00:53:34.940]   that they want to feel that the others are vaccinated
[00:53:34.940 --> 00:53:36.660]   and the fear of those that they don't want
[00:53:36.660 --> 00:53:37.940]   to get the vaccine.
[00:53:37.940 --> 00:53:40.580]   And eventually I came to the decision
[00:53:40.580 --> 00:53:42.860]   that we will mandate it at Pfizer.
[00:53:42.860 --> 00:53:43.780]   We are flexible.
[00:53:43.780 --> 00:53:45.820]   We are giving exceptions, of course, for health,
[00:53:45.820 --> 00:53:50.820]   maybe some religions, but we decided to mandate it.
[00:53:50.820 --> 00:53:54.940]   Now at Pfizer, when we did this decision,
[00:53:54.940 --> 00:53:57.260]   we were at 90% vaccination rates
[00:53:57.260 --> 00:53:59.660]   when we said we are going to mandate it.
[00:53:59.660 --> 00:54:02.860]   And that took it up to 96.
[00:54:02.860 --> 00:54:05.460]   It works, right?
[00:54:05.460 --> 00:54:10.180]   This 10% was never going to move, I felt,
[00:54:10.180 --> 00:54:12.660]   because no matter what, you have a small number of people
[00:54:12.660 --> 00:54:14.580]   that really are scared
[00:54:14.580 --> 00:54:17.340]   and they don't feel comfortable to do it.
[00:54:17.340 --> 00:54:18.700]   It worked in our case.
[00:54:18.700 --> 00:54:20.420]   We took it to 96%.
[00:54:20.420 --> 00:54:22.260]   I'm happy for those people.
[00:54:22.260 --> 00:54:25.460]   A lot will not disease and some will not die
[00:54:25.460 --> 00:54:26.580]   of those people.
[00:54:26.580 --> 00:54:29.900]   But it's not to me to say, because the debate,
[00:54:29.900 --> 00:54:32.700]   it's serious debate.
[00:54:32.700 --> 00:54:34.500]   And there are a lot of pros and cons
[00:54:34.500 --> 00:54:35.740]   if you need to push people,
[00:54:35.740 --> 00:54:38.460]   if you need to give them the freedom.
[00:54:38.460 --> 00:54:42.620]   And it comes with the territory.
[00:54:42.620 --> 00:54:45.420]   If you are elected to run a country,
[00:54:45.420 --> 00:54:47.660]   you should be ready to make difficult decisions.
[00:54:47.660 --> 00:54:49.100]   - And no matter what decision you make,
[00:54:49.100 --> 00:54:50.700]   there will be fake stories written about you
[00:54:50.700 --> 00:54:51.540]   as we talked about.
[00:54:51.540 --> 00:54:53.860]   - You will not be able to please everyone.
[00:54:53.860 --> 00:54:54.700]   - Yes.
[00:54:54.700 --> 00:54:58.300]   Well, let me just say that I think, again,
[00:54:58.300 --> 00:54:59.620]   coming from the Soviet Union,
[00:54:59.620 --> 00:55:01.980]   I think at the public level, at the federal level,
[00:55:01.980 --> 00:55:06.740]   mandates is a really bad idea,
[00:55:06.740 --> 00:55:09.900]   even if it's good for the health of the populace.
[00:55:09.900 --> 00:55:12.260]   There's something about preserving the freedom
[00:55:12.260 --> 00:55:14.580]   is really powerful about this country.
[00:55:14.580 --> 00:55:17.020]   Like doing the hard work of convincing people
[00:55:17.020 --> 00:55:21.500]   to get vaccinated, to choose to get vaccinated if they want,
[00:55:21.500 --> 00:55:23.540]   but still have the freedom not to.
[00:55:23.540 --> 00:55:25.740]   That's a really powerful freedom.
[00:55:25.740 --> 00:55:28.420]   To me, it's super lazy to mandate.
[00:55:28.420 --> 00:55:31.100]   People should understand the science
[00:55:31.100 --> 00:55:32.700]   and want to get vaccinated.
[00:55:32.980 --> 00:55:34.980]   (sighs)
[00:55:34.980 --> 00:55:41.540]   - Do you think children need to get vaccinated?
[00:55:41.540 --> 00:55:42.380]   - I do.
[00:55:42.380 --> 00:55:44.580]   I do think that they need to get vaccinated.
[00:55:44.580 --> 00:55:47.820]   - So age ranges five to 16,
[00:55:47.820 --> 00:55:50.780]   there's a lot of parents
[00:55:50.780 --> 00:55:56.180]   that fear for the wellbeing of their children.
[00:55:56.180 --> 00:55:57.940]   Can you empathize with those parents?
[00:55:57.940 --> 00:56:02.500]   Can you steel man their arguments against the vaccine
[00:56:02.500 --> 00:56:04.100]   for their children?
[00:56:04.100 --> 00:56:06.140]   - You know, because people know who I am.
[00:56:06.140 --> 00:56:11.140]   I had the opportunity to interact with parents
[00:56:11.140 --> 00:56:15.340]   before that was, let's say, approved.
[00:56:15.340 --> 00:56:18.860]   And there were so many, way more,
[00:56:18.860 --> 00:56:21.780]   that I had a lot of empathy
[00:56:21.780 --> 00:56:24.140]   because they were afraid for their kids
[00:56:24.140 --> 00:56:25.900]   because they didn't have a vaccine.
[00:56:25.900 --> 00:56:30.300]   And they were the ones that were speaking at that time.
[00:56:30.300 --> 00:56:31.180]   Bring me a vaccine.
[00:56:31.180 --> 00:56:32.780]   When are you going to bring me a vaccine?
[00:56:32.780 --> 00:56:35.460]   I really fear, I feel that this is unfair,
[00:56:35.460 --> 00:56:36.660]   but I'm protected.
[00:56:36.660 --> 00:56:38.460]   My husband is protected.
[00:56:38.460 --> 00:56:39.740]   My old son is protected.
[00:56:39.740 --> 00:56:41.780]   And my little sweetheart,
[00:56:41.780 --> 00:56:44.460]   because she's below the age, is not protected.
[00:56:44.460 --> 00:56:47.460]   Now that we have the vaccines,
[00:56:47.460 --> 00:56:50.580]   I'm sure that those that they are afraid of the vaccine,
[00:56:50.580 --> 00:56:54.460]   not of the disease, which are smaller number, admittedly.
[00:56:54.460 --> 00:56:57.500]   Also, they will have, if they are afraid of them,
[00:56:57.500 --> 00:57:00.100]   I'm sure that they will afraid even more about their kids
[00:57:00.100 --> 00:57:02.260]   because they love, I would say,
[00:57:02.260 --> 00:57:04.060]   more than they love themselves.
[00:57:04.060 --> 00:57:06.380]   So it's going to be this situation.
[00:57:06.380 --> 00:57:08.860]   And again, the same.
[00:57:08.860 --> 00:57:12.260]   How can we do to demonstrate, to convince people,
[00:57:12.260 --> 00:57:14.060]   to win the minds and the hearts of the people
[00:57:14.060 --> 00:57:15.300]   that this is the right thing to do?
[00:57:15.300 --> 00:57:16.780]   - What do you think about that calculation?
[00:57:16.780 --> 00:57:19.540]   'Cause the risk for kids is very low.
[00:57:19.540 --> 00:57:20.900]   Kids do die.
[00:57:20.900 --> 00:57:22.940]   Kids do go to the hospital from COVID.
[00:57:22.940 --> 00:57:23.900]   - Yes.
[00:57:23.900 --> 00:57:25.620]   - But the rate is very low.
[00:57:25.620 --> 00:57:30.020]   - The rate is lower, but kids, they do die.
[00:57:30.020 --> 00:57:34.580]   And how can you say that I'm not going to protect a kid
[00:57:34.580 --> 00:57:36.980]   for something that it is likely to happen?
[00:57:36.980 --> 00:57:38.460]   And it is not only that.
[00:57:38.460 --> 00:57:39.820]   What happens in the school
[00:57:39.820 --> 00:57:42.620]   when they stop the education process
[00:57:42.620 --> 00:57:44.860]   because a kid got the disease
[00:57:44.860 --> 00:57:48.340]   and they don't have vaccines so that they can control.
[00:57:48.340 --> 00:57:52.460]   It is such a big disruption and such a big risk
[00:57:52.460 --> 00:57:57.460]   for the health of the kids
[00:57:57.460 --> 00:57:59.740]   that it shouldn't be a debate.
[00:57:59.740 --> 00:58:03.900]   Look, how many kids are having polio right now?
[00:58:03.900 --> 00:58:08.460]   Way fewer number than those
[00:58:08.460 --> 00:58:11.500]   that they're having COVID in the hospital.
[00:58:11.500 --> 00:58:13.300]   But everybody's getting the vaccine.
[00:58:13.300 --> 00:58:17.140]   - Well, polio was deadlier for kids.
[00:58:17.140 --> 00:58:18.300]   - But it's not now.
[00:58:18.300 --> 00:58:20.540]   So why a kid to do it now?
[00:58:20.540 --> 00:58:23.620]   Because it needs to be protected.
[00:58:23.620 --> 00:58:26.060]   - Well, the unique thing about the COVID vaccine
[00:58:26.060 --> 00:58:28.260]   is a new type of technology too.
[00:58:28.260 --> 00:58:30.780]   So there's an extra concern.
[00:58:30.780 --> 00:58:33.440]   Choosing to vaccinate a child,
[00:58:33.440 --> 00:58:36.560]   you're making a choice that can potentially hurt them.
[00:58:36.560 --> 00:58:38.820]   That's the way parents
[00:58:38.820 --> 00:58:41.660]   that are hesitant about the vaccine think.
[00:58:41.660 --> 00:58:46.660]   - I think choosing to vaccinate children makes a choice
[00:58:46.660 --> 00:58:49.300]   so that something could not potentially hurt them,
[00:58:49.300 --> 00:58:50.260]   which is the disease.
[00:58:50.260 --> 00:58:53.980]   That's why we are doing vaccinations since ever.
[00:58:53.980 --> 00:58:57.340]   I know that there are people
[00:58:57.340 --> 00:59:00.340]   that they're concerned for themselves and for their kids.
[00:59:00.340 --> 00:59:05.340]   What I know it is that I'm a scientist and I'm a parent.
[00:59:05.340 --> 00:59:09.140]   And I am telling you that vaccines
[00:59:09.140 --> 00:59:10.420]   is a very good thing for kids.
[00:59:10.420 --> 00:59:12.580]   And thank God we were able to develop them.
[00:59:12.580 --> 00:59:16.900]   - So we've talked quite a bit about the vaccine,
[00:59:16.900 --> 00:59:18.460]   but there's an incredible new technology
[00:59:18.460 --> 00:59:20.060]   that Pfizer is developing
[00:59:20.060 --> 00:59:23.980]   with the PaxLovid antiviral for COVID.
[00:59:23.980 --> 00:59:26.260]   Where does that stand?
[00:59:26.260 --> 00:59:28.060]   How does that work?
[00:59:28.060 --> 00:59:33.380]   And how are you able to develop it in four months?
[00:59:33.380 --> 00:59:36.340]   Like you said, and all of that in just a few minutes.
[00:59:36.340 --> 00:59:39.300]   - First of all, what this is about,
[00:59:39.300 --> 00:59:41.860]   this is a real game changer.
[00:59:41.860 --> 00:59:44.060]   This is a course of treatment
[00:59:44.060 --> 00:59:46.980]   that you get only if you get the disease, you get COVID.
[00:59:46.980 --> 00:59:51.900]   Then what happens is that you will take for five days,
[00:59:51.900 --> 00:59:56.580]   pills day and night and twice a day for five days.
[00:59:56.580 --> 00:59:57.900]   And instead of 10 people
[00:59:57.900 --> 01:00:00.460]   from those that disease to go to hospital,
[01:00:00.460 --> 01:00:01.380]   only one will go.
[01:00:01.380 --> 01:00:06.060]   This is an end with all the caveats
[01:00:06.060 --> 01:00:08.420]   that the numbers are small, no one died.
[01:00:08.420 --> 01:00:11.260]   It was 100% efficacy on deaths.
[01:00:11.260 --> 01:00:14.740]   Of course, I'm sure that in real world
[01:00:14.740 --> 01:00:16.060]   when the numbers are getting very high,
[01:00:16.060 --> 01:00:18.740]   we may have 99 instead of 100.
[01:00:18.740 --> 01:00:23.180]   But these are spectacular results
[01:00:23.180 --> 01:00:25.820]   for something that you can take home and stay home.
[01:00:25.820 --> 01:00:29.100]   The biggest problem right now in Europe, in the US,
[01:00:29.100 --> 01:00:30.300]   when we have surges,
[01:00:30.300 --> 01:00:34.140]   every time that we have a surge of COVID,
[01:00:34.140 --> 01:00:36.860]   it is that the ICUs are full,
[01:00:36.860 --> 01:00:39.220]   the hospitals are paralyzed.
[01:00:39.220 --> 01:00:41.860]   They have to postpone elective surgeries.
[01:00:41.860 --> 01:00:43.380]   They have to postpone other operations
[01:00:43.380 --> 01:00:46.940]   because they don't have the capacity because of that.
[01:00:46.940 --> 01:00:50.500]   Keeping people out of the hospitals, home,
[01:00:50.500 --> 01:00:54.660]   keeping people without dying,
[01:00:54.660 --> 01:00:57.940]   it is something that we didn't have before.
[01:00:57.940 --> 01:01:02.700]   And this is a significant, significant game changer.
[01:01:02.700 --> 01:01:08.100]   - I have to ask a controversial, difficult question.
[01:01:08.100 --> 01:01:11.700]   What are your thoughts about ivermectin?
[01:01:11.700 --> 01:01:14.140]   Has it sufficiently been studied?
[01:01:14.140 --> 01:01:15.980]   Has Pfizer considered it?
[01:01:15.980 --> 01:01:17.180]   And it's, like I said,
[01:01:17.180 --> 01:01:19.340]   incredible development of the antiviral
[01:01:19.340 --> 01:01:22.900]   as a comparator, that kind of thing,
[01:01:22.900 --> 01:01:25.020]   just investigated in general.
[01:01:25.020 --> 01:01:26.820]   The reason I bring it up,
[01:01:26.820 --> 01:01:30.420]   'cause I've read quite a few criticisms of people.
[01:01:30.420 --> 01:01:33.500]   There's been some comparisons of Paxilovir to the ivermectin
[01:01:33.500 --> 01:01:36.180]   and I think people should look up.
[01:01:36.180 --> 01:01:39.500]   There is Dr. John Campbell that describes that comparison
[01:01:39.500 --> 01:01:40.460]   and makes that claim.
[01:01:40.460 --> 01:01:42.820]   And there's quite a lot of people that debunk
[01:01:42.820 --> 01:01:44.540]   or argue against that.
[01:01:44.540 --> 01:01:46.260]   You can do your own research.
[01:01:46.260 --> 01:01:51.020]   But there is a lot of people that kind of see this free drug
[01:01:51.020 --> 01:01:54.260]   without patents on it and say, "This could be the savior."
[01:01:54.260 --> 01:01:56.900]   So can you just speak to that comparison?
[01:01:56.900 --> 01:01:58.140]   - It's not the first time.
[01:01:58.140 --> 01:02:00.580]   If you remember, there were other compounds
[01:02:00.580 --> 01:02:05.580]   that were claimed that they are the solution to COVID.
[01:02:05.580 --> 01:02:12.540]   And clearly, they were proven that they're not.
[01:02:12.540 --> 01:02:13.940]   There are compounds that there are solutions
[01:02:13.940 --> 01:02:15.380]   and compounds that they're not.
[01:02:15.380 --> 01:02:19.060]   I, as a scientist, and I discussed with our scientists,
[01:02:19.060 --> 01:02:24.060]   they don't see any reason why a medicine like ivermectin,
[01:02:24.060 --> 01:02:28.620]   which is a parasitic site, to be able to act on COVID.
[01:02:28.620 --> 01:02:31.660]   And so they don't seem that there's any connection.
[01:02:31.660 --> 01:02:35.660]   And they haven't seen any paper that describes someone
[01:02:35.660 --> 01:02:37.860]   that used it that it had any results.
[01:02:37.860 --> 01:02:40.780]   I'm sure that there will be some people that will claim
[01:02:40.780 --> 01:02:42.940]   because people are claiming anything.
[01:02:42.940 --> 01:02:46.700]   But I don't think that there was any paper
[01:02:46.700 --> 01:02:49.180]   in any peer review magazine,
[01:02:49.180 --> 01:02:51.620]   I mean, a reliable scientific magazine,
[01:02:51.620 --> 01:02:52.860]   to support this claim.
[01:02:52.860 --> 01:02:56.620]   So we are focusing on saving people's lives.
[01:02:56.620 --> 01:03:01.620]   We are not focusing on craziness.
[01:03:01.620 --> 01:03:06.540]   - Well, to push back, there is quite a lot of papers,
[01:03:06.540 --> 01:03:07.980]   but the studies are small,
[01:03:07.980 --> 01:03:09.860]   so there's no conclusive evidence.
[01:03:09.860 --> 01:03:11.500]   And that's the point. - I haven't seen any
[01:03:11.500 --> 01:03:12.660]   that it is reliable.
[01:03:12.660 --> 01:03:13.500]   - Right. - I don't know
[01:03:13.500 --> 01:03:16.820]   where are these, small or big, reliable.
[01:03:16.820 --> 01:03:18.300]   I haven't seen any.
[01:03:18.300 --> 01:03:21.420]   - Well, some of the big ones have been retracted,
[01:03:21.420 --> 01:03:24.020]   which means they weren't legitimate.
[01:03:24.020 --> 01:03:25.260]   Yes. - Yeah, so?
[01:03:25.260 --> 01:03:27.940]   - You know, this is definitely something
[01:03:27.940 --> 01:03:29.180]   that people need to look into,
[01:03:29.180 --> 01:03:31.900]   the people that kinda question
[01:03:31.900 --> 01:03:33.300]   all the effectiveness of ivermectin,
[01:03:33.300 --> 01:03:35.580]   definitely something to think about.
[01:03:35.580 --> 01:03:37.540]   And I think is the reason that--
[01:03:37.540 --> 01:03:40.300]   - It was chloroquine before. - Yes.
[01:03:40.300 --> 01:03:42.180]   - For God's sake. - That's why--
[01:03:42.180 --> 01:03:44.180]   - How many people died because of that?
[01:03:44.180 --> 01:03:48.580]   - Yeah, this is the dangerous thing.
[01:03:48.580 --> 01:03:50.220]   This is the sad thing. - Yeah.
[01:03:50.220 --> 01:03:52.900]   - But-- - SLOVID has been studying
[01:03:52.900 --> 01:03:55.820]   thousands of people and will be under the scrutiny,
[01:03:55.820 --> 01:03:58.180]   not only of regulators,
[01:03:58.180 --> 01:04:00.940]   but as we will go into the implementation,
[01:04:00.940 --> 01:04:02.620]   as it happened in many countries,
[01:04:02.620 --> 01:04:04.820]   they will monitor to see what's happened.
[01:04:04.820 --> 01:04:06.300]   Let's say that whatever we do,
[01:04:06.300 --> 01:04:08.940]   once it is out there, within a few weeks,
[01:04:08.940 --> 01:04:11.300]   they will know all hospitals, if it works or not,
[01:04:11.300 --> 01:04:13.820]   because they will see the statistics.
[01:04:13.820 --> 01:04:18.380]   - We've gone through one of the more difficult periods
[01:04:18.380 --> 01:04:21.740]   in recent human history over the past few years,
[01:04:21.740 --> 01:04:23.220]   like as a society.
[01:04:23.220 --> 01:04:26.340]   What gives you hope about the future
[01:04:26.340 --> 01:04:28.100]   for human civilization?
[01:04:28.100 --> 01:04:31.740]   You look into the next few years.
[01:04:31.740 --> 01:04:34.060]   - I think the human ingenuity.
[01:04:34.060 --> 01:04:36.900]   I think although there is,
[01:04:36.900 --> 01:04:39.140]   the world always is progressing.
[01:04:39.140 --> 01:04:42.740]   Although there are a lot of things that need to be fixed
[01:04:42.740 --> 01:04:44.620]   in the society of 2020.
[01:04:44.620 --> 01:04:49.780]   The society of 2020 is better at large
[01:04:49.780 --> 01:04:53.140]   than things 50 years back, 100 years back,
[01:04:53.140 --> 01:04:54.980]   in all different aspects,
[01:04:54.980 --> 01:04:58.060]   from poverty, for human rights,
[01:04:58.060 --> 01:05:03.060]   from science, from quality of life, from any aspect.
[01:05:03.060 --> 01:05:07.860]   I am positive that humans
[01:05:07.860 --> 01:05:11.180]   can create and always create a better future,
[01:05:11.180 --> 01:05:12.580]   and we'll continue doing so.
[01:05:12.580 --> 01:05:17.740]   - You have helped save the lives of millions of people,
[01:05:17.740 --> 01:05:20.020]   helped improve the quality of their lives,
[01:05:20.020 --> 01:05:24.140]   but you yourself are just one biological organism
[01:05:24.140 --> 01:05:26.020]   with an expiration date.
[01:05:26.020 --> 01:05:28.100]   Do you ponder your mortality?
[01:05:28.100 --> 01:05:30.380]   Do you think about your death?
[01:05:30.380 --> 01:05:31.580]   Are you afraid of death?
[01:05:31.580 --> 01:05:35.300]   - That's a very interesting question.
[01:05:35.300 --> 01:05:37.140]   I was discussing with a lot of people
[01:05:37.140 --> 01:05:38.500]   that I was fearless of death.
[01:05:38.500 --> 01:05:41.940]   I couldn't care less when I was young.
[01:05:41.940 --> 01:05:44.260]   The first thing, the first time
[01:05:44.260 --> 01:05:48.220]   that I start feeling that I want to be around
[01:05:48.220 --> 01:05:49.980]   was when I had kids.
[01:05:49.980 --> 01:05:52.100]   And then I started feeling that,
[01:05:52.100 --> 01:05:55.020]   oh gosh, is it, I hope I will be around
[01:05:55.020 --> 01:05:56.380]   to see their wedding.
[01:05:56.380 --> 01:05:59.700]   I hope they will be around to see their children.
[01:05:59.700 --> 01:06:02.260]   So if there is something that scares me,
[01:06:02.260 --> 01:06:04.140]   it's the possibility I will not be part
[01:06:04.140 --> 01:06:05.540]   of their lives anymore,
[01:06:05.540 --> 01:06:06.700]   and I will not be watching.
[01:06:06.700 --> 01:06:08.940]   I hope there is life upstairs,
[01:06:08.940 --> 01:06:11.660]   so I will be able to watch them from there.
[01:06:11.660 --> 01:06:13.960]   - From upstairs, get a nice overview.
[01:06:13.960 --> 01:06:17.660]   Let me ask the big ridiculous question.
[01:06:17.660 --> 01:06:22.900]   And you only have two minutes or less to answer it.
[01:06:22.900 --> 01:06:24.260]   What is the meaning of life?
[01:06:24.260 --> 01:06:25.940]   What's the meaning of this whole thing?
[01:06:25.940 --> 01:06:28.940]   You said ingenuity is the thing that gives you hope.
[01:06:28.940 --> 01:06:31.260]   We seem to be all busy trying to help each other,
[01:06:31.260 --> 01:06:32.980]   trying to build a better world.
[01:06:32.980 --> 01:06:34.100]   Why are we doing that?
[01:06:34.100 --> 01:06:38.660]   - I would repeat something that Steve Jobs has said.
[01:06:38.660 --> 01:06:41.480]   Death is life's biggest invention.
[01:06:41.480 --> 01:06:46.300]   It eliminates the old and gives place to the new.
[01:06:46.300 --> 01:06:50.620]   Life is all about moving forward.
[01:06:50.620 --> 01:06:56.500]   Life is all about creating new things.
[01:06:56.500 --> 01:07:00.060]   Maybe everyone is a contributor,
[01:07:00.060 --> 01:07:01.540]   but no one is the owner.
[01:07:02.940 --> 01:07:05.180]   - And always creating something new.
[01:07:05.180 --> 01:07:06.260]   - Always.
[01:07:06.260 --> 01:07:08.020]   - Adding something beautiful into the world,
[01:07:08.020 --> 01:07:09.380]   maybe a little bit of love.
[01:07:09.380 --> 01:07:11.660]   - Hopefully.
[01:07:11.660 --> 01:07:12.800]   - Albert, thank you so much.
[01:07:12.800 --> 01:07:15.620]   It's a huge honor that you will go through
[01:07:15.620 --> 01:07:18.180]   some of these difficult questions with me today,
[01:07:18.180 --> 01:07:20.780]   and that you give your extremely valuable time
[01:07:20.780 --> 01:07:21.780]   for this conversation.
[01:07:21.780 --> 01:07:22.940]   Thank you so much for talking today.
[01:07:22.940 --> 01:07:24.140]   - Thank you for your interest,
[01:07:24.140 --> 01:07:26.620]   and I'm happy, as I was telling you before,
[01:07:26.620 --> 01:07:31.620]   but I can brag with my kids that I was in your podcast
[01:07:31.660 --> 01:07:33.340]   because you are their hero.
[01:07:33.340 --> 01:07:34.180]   - You made it.
[01:07:34.180 --> 01:07:35.700]   - I made it.
[01:07:35.700 --> 01:07:36.540]   - Thank you.
[01:07:36.540 --> 01:07:37.700]   - Thank you.
[01:07:37.700 --> 01:07:39.180]   - Thanks for listening to this conversation
[01:07:39.180 --> 01:07:40.620]   with Albert Bourla.
[01:07:40.620 --> 01:07:41.900]   To support this podcast,
[01:07:41.900 --> 01:07:44.460]   please check out our sponsors in the description.
[01:07:44.460 --> 01:07:48.380]   And now, let me leave you with some words from Oscar Wilde.
[01:07:48.380 --> 01:07:52.340]   The truth is rarely pure and never simple.
[01:07:52.340 --> 01:07:55.100]   Thank you for listening, and hope to see you next time.
[01:07:55.100 --> 01:07:57.680]   (upbeat music)
[01:07:57.680 --> 01:08:00.260]   (upbeat music)
[01:08:00.260 --> 01:08:10.260]   [BLANK_AUDIO]

