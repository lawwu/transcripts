
[00:00:00.000 --> 00:00:03.000]   We'll check if we're live or not. And during that duration,
[00:00:03.000 --> 00:00:06.000]   I'm always freaking out because I find out new ways of messing
[00:00:06.000 --> 00:00:06.200]   up.
[00:00:06.200 --> 00:00:17.440]   I can hear an echo, which means things are good. Thankfully.
[00:00:17.440 --> 00:00:21.480]   Awesome. I'll quickly introduce Daniel and what he'll be talking
[00:00:21.480 --> 00:00:24.960]   about and hand it over to him. Let me mute the other tab so
[00:00:24.960 --> 00:00:28.080]   you don't hear that. Hey, everybody. Thanks for joining us
[00:00:28.120 --> 00:00:31.600]   again on a Sunday. Super excited to bring back the Jackstalks.
[00:00:31.600 --> 00:00:36.120]   Today we're joined by Daniel Freeman, who's a senior software
[00:00:36.120 --> 00:00:38.720]   engineer at Google Research. He spends most of his time trying
[00:00:38.720 --> 00:00:41.600]   to do cool things with reinforcement learning. And
[00:00:41.600 --> 00:00:43.720]   before the call, he was telling me he wouldn't be doing this
[00:00:43.720 --> 00:00:49.640]   stuff if it was as fun to him as it is. Prior to Google, he got
[00:00:49.640 --> 00:00:52.480]   his PhD at UC Berkeley in physics studying quantum
[00:00:52.480 --> 00:00:56.400]   information theory. And he'll be talking about the Prax
[00:00:56.440 --> 00:00:59.960]   framework, which also is a physics engine. It's a new
[00:00:59.960 --> 00:01:03.760]   differentiable physics engine built on top of Jacks. And he'll
[00:01:03.760 --> 00:01:07.600]   be showing us an interactive demo, accelerating training on
[00:01:07.600 --> 00:01:11.680]   accelerators. That's quite a mouthful. So I'm excited. Last
[00:01:11.680 --> 00:01:15.720]   time we destroyed a sandcastle. Let's see what Daniel teaches us
[00:01:15.720 --> 00:01:18.160]   this time. Thanks for joining us, Daniel.
[00:01:18.160 --> 00:01:24.040]   Awesome. Thanks so much. Yeah, so this is Prax. Here's some
[00:01:24.040 --> 00:01:26.480]   environments in Prax. They actually have even more than
[00:01:26.480 --> 00:01:29.720]   this now. This is just a slice of fun stuff happening in Prax.
[00:01:29.720 --> 00:01:35.440]   So this first link here has a bunch of neat interactive
[00:01:35.440 --> 00:01:39.680]   collabs that one can run in one's browser if one so wishes.
[00:01:39.680 --> 00:01:43.080]   Today, I actually wanted to show off our training collab because
[00:01:43.080 --> 00:01:47.080]   it's pretty slick. So let me do some rapid fire tab switching
[00:01:47.080 --> 00:01:53.520]   here. All right, can you see this tab? Okay.
[00:01:53.840 --> 00:01:55.160]   I can see training in Prax.
[00:01:55.160 --> 00:01:58.960]   Great. All right. So this is training in Prax. So I'm using a
[00:01:58.960 --> 00:02:03.200]   free public collab runtime. So anyone can start one of these if
[00:02:03.200 --> 00:02:05.840]   they just navigate to that link that I was showing that you
[00:02:05.840 --> 00:02:10.000]   can't see now. But make sure you don't forget to attach a TPU by
[00:02:10.000 --> 00:02:14.880]   going to change runtime. Make sure your runtime is a TPU. It
[00:02:14.880 --> 00:02:17.800]   also has instructions right here. So let me kick off a few
[00:02:17.840 --> 00:02:21.760]   cells really quick. Let run while I talk.
[00:02:21.760 --> 00:02:29.160]   Alright, so they're launched. Go back up the top. Alrighty. So
[00:02:29.160 --> 00:02:32.560]   this collab showcases how we can use Prax to train policies
[00:02:32.560 --> 00:02:36.280]   really fast from a browser. We have this in collab JavaScript
[00:02:36.280 --> 00:02:39.960]   based rendering that's powering this visualization here makes it
[00:02:39.960 --> 00:02:44.120]   easy to prototype a new Prax system, or just visualize your
[00:02:44.120 --> 00:02:46.400]   policies of these little creatures actually doing things
[00:02:46.400 --> 00:02:49.360]   which we'll see in a moment. These notebooks have some
[00:02:49.360 --> 00:02:52.120]   drop-down menus that actually let you visualize a couple of
[00:02:52.120 --> 00:02:54.880]   different systems that are released. Because it's doing
[00:02:54.880 --> 00:02:57.480]   something in another slide, I can't or doing something in
[00:02:57.480 --> 00:02:59.880]   another cell, I can't switch between these quickly. But we
[00:02:59.880 --> 00:03:01.640]   have a handful of different environments here. There's the
[00:03:01.640 --> 00:03:05.160]   Mojoco likes which are like ants, and humanoid and half
[00:03:05.160 --> 00:03:09.160]   cheetah and reacher. We also have like Walker 2d and swimmer
[00:03:09.160 --> 00:03:13.800]   and other stuff which aren't updated yet on this slide. As
[00:03:13.800 --> 00:03:15.680]   well as our dexterous manipulation environment called
[00:03:15.680 --> 00:03:19.120]   grasp, and then a goal directed locomotion test task called
[00:03:19.120 --> 00:03:26.160]   fetch. And finally, a kind of 3d reacher like task using a your
[00:03:26.160 --> 00:03:30.840]   fivee arm called your fivee. Under the hood, these system
[00:03:30.840 --> 00:03:33.440]   definitions are really simple protobuf specifications of how
[00:03:33.440 --> 00:03:36.320]   rigid bodies are connected to each other. So that's like how
[00:03:36.320 --> 00:03:39.760]   these joints are connected, how they're actuated, which things
[00:03:39.760 --> 00:03:43.720]   are allowed to collide reminiscent of Mojoco XML or
[00:03:43.720 --> 00:03:47.680]   just your df files, we actually have some support for conversion
[00:03:47.680 --> 00:03:51.480]   of Mojoco and your df files into Brax. But it usually requires a
[00:03:51.480 --> 00:03:53.920]   little bit of extra massaging because of some fundamental
[00:03:53.920 --> 00:03:56.720]   engine differences. We're actually working on making this
[00:03:56.720 --> 00:03:59.280]   less painful right now with an upcoming upgrade to the
[00:03:59.280 --> 00:04:02.280]   internals of Brax, which I might talk about a little bit later.
[00:04:02.280 --> 00:04:07.040]   So sorry, I have a new question. The Mojoco file formats and the
[00:04:07.040 --> 00:04:09.680]   other ones you mentioned, these are, I believe, environment
[00:04:09.680 --> 00:04:12.800]   files that are standard in the world of heart. Okay. Yeah,
[00:04:12.800 --> 00:04:19.040]   yeah. Yeah, thanks. So you can you can explore the structure of
[00:04:19.040 --> 00:04:22.960]   like how we define these things in our one of our other collabs
[00:04:22.960 --> 00:04:26.760]   called basics, which is a previous one. So these these
[00:04:26.760 --> 00:04:29.360]   protobuf files are really just like half of the RL environment.
[00:04:29.360 --> 00:04:32.640]   The other half are you usual gym like methods, things for
[00:04:32.640 --> 00:04:35.800]   observing the world, defining a reward defining how the system
[00:04:35.800 --> 00:04:38.680]   steps that we all expect from our favorite wrappers around
[00:04:38.680 --> 00:04:41.680]   Markov decision processes. And these are all defined in the
[00:04:41.680 --> 00:04:45.080]   Python system files in our repo in Jacksy Python. So and they're
[00:04:45.080 --> 00:04:48.480]   also written so as to leverage Jackson's compilation and
[00:04:48.480 --> 00:04:53.120]   vectorization primitives. So while I've been talking, our ant
[00:04:53.120 --> 00:04:56.040]   environment has been initialized, has been evaluating
[00:04:56.040 --> 00:05:01.960]   in 2048 environments in parallel. And it's generated
[00:05:01.960 --> 00:05:04.920]   experience for our custom implementation of PPO. And
[00:05:04.920 --> 00:05:08.920]   because the end of MPPO compile alongside each other, on the
[00:05:08.920 --> 00:05:11.720]   same TPU, everything goes blazingly fast. In fact, while I
[00:05:11.720 --> 00:05:16.160]   was talking, this ant already experienced 50 million frames of
[00:05:16.160 --> 00:05:20.720]   experience. So it learned to walk. And let's keep going down
[00:05:20.720 --> 00:05:24.840]   here. Like I mentioned a minute ago, we can visualize this
[00:05:24.840 --> 00:05:30.200]   policy. So here's, here's our ant running. So it's generating a
[00:05:30.200 --> 00:05:34.480]   little trajectory for our ant. And give it a couple more
[00:05:34.480 --> 00:05:39.520]   seconds. So the output of this whole training process is
[00:05:39.520 --> 00:05:43.040]   really just a flax neural network. So it's like NumPy
[00:05:43.040 --> 00:05:45.920]   weights that you can kind of immediately have in your hands
[00:05:45.920 --> 00:05:48.360]   and do whatever you want with. So it's pretty straightforward
[00:05:48.360 --> 00:05:51.920]   to just take it and do whatever. So here's our little ant
[00:05:51.920 --> 00:05:56.320]   running furiously rightwards in pursuit of ever greater rewards.
[00:05:56.880 --> 00:06:06.720]   Just gonna look at our ant here. Looking to run. Do. Alright, so
[00:06:06.720 --> 00:06:13.800]   that concludes the live demo. Happy to answer any questions
[00:06:13.800 --> 00:06:17.280]   about this. Talk more about training things if there
[00:06:17.280 --> 00:06:17.760]   anything.
[00:06:17.760 --> 00:06:24.040]   Otherwise, I'm just fascinated and looking staring at the
[00:06:25.600 --> 00:06:29.000]   Yeah, I mean, it's it is sort of mesmerizing. Like, like, really,
[00:06:29.000 --> 00:06:31.560]   my day job is just training a lot of these creatures and like
[00:06:31.560 --> 00:06:34.440]   watching them move when testing different physics things. So
[00:06:34.440 --> 00:06:40.720]   it's, it's fun. Maybe I'll watch a I can watch like a humanoid
[00:06:40.720 --> 00:06:43.960]   while I'm talking. Look at that in a bit because humanoid is fun
[00:06:43.960 --> 00:06:44.400]   to watch.
[00:06:44.400 --> 00:06:47.360]   Sanyam Bhutani: For the audience. I wanted to mention
[00:06:47.360 --> 00:06:50.160]   Christian unfortunately isn't able to make it today. He'll be
[00:06:50.160 --> 00:06:52.880]   hanging out in the YouTube chat if anyone wants to talk to him.
[00:06:52.880 --> 00:06:57.760]   I'm gonna fire this off and then maybe we can look at this
[00:06:57.760 --> 00:07:03.200]   after I finish the rest of my talk. Alright, so let's hop back
[00:07:03.200 --> 00:07:11.400]   over to the talk portion. And again, so this this GitHub link
[00:07:11.400 --> 00:07:14.360]   is where a bunch of other notebooks are as well like our
[00:07:14.360 --> 00:07:19.880]   basics collab, multi agent collab. Just all collabs that
[00:07:19.880 --> 00:07:22.840]   can be interacted with if you just take kind of the GitHub
[00:07:22.840 --> 00:07:28.960]   part of the URL and go to just a collab window with them. So
[00:07:28.960 --> 00:07:32.640]   this is like how you load this collab. There used to be a slick
[00:07:32.640 --> 00:07:36.080]   button that you could press but then GitHub like broke the way
[00:07:36.080 --> 00:07:38.720]   those links worked. So it's not quite as easy as it used to be.
[00:07:38.720 --> 00:07:44.040]   Anyway, so I like this figure because it's sort of a bridged
[00:07:44.040 --> 00:07:47.840]   version of Brax's life story in one slide. Early in our project,
[00:07:47.840 --> 00:07:50.680]   we started training locomotion policies on BP CPU cloud
[00:07:50.680 --> 00:07:55.080]   machines, and we usually kick off these locomotion policy
[00:07:55.080 --> 00:07:57.880]   training runs to run overnight so that we can look at them in
[00:07:57.880 --> 00:08:01.120]   the morning, and this would take hours to train. And then we
[00:08:01.120 --> 00:08:03.040]   spent a good chunk of time spending up distributed
[00:08:03.040 --> 00:08:05.080]   reinforcement learning infrastructure to get training
[00:08:05.080 --> 00:08:07.480]   time down to minutes, because it's, you know, you just need
[00:08:07.480 --> 00:08:10.920]   more experience more more quickly, and you can do it. But
[00:08:10.920 --> 00:08:14.920]   this required running 1000s of simultaneous CPU jobs to be able
[00:08:14.920 --> 00:08:18.000]   to generate experience fast enough. And finally, because
[00:08:18.000 --> 00:08:21.600]   that's kind of completely insane to expend that much resource to
[00:08:21.600 --> 00:08:24.440]   generate a locomotion policy, we built this minimal rigid body
[00:08:24.440 --> 00:08:26.280]   physics engine that could compress all of those
[00:08:26.280 --> 00:08:28.760]   computations happening across that cluster down to just one
[00:08:28.760 --> 00:08:32.200]   accelerator. And it's it's not quite as insane as it looked
[00:08:32.200 --> 00:08:35.320]   like this, this picture in the middle here, like each one of
[00:08:35.320 --> 00:08:39.200]   these CPUs was like running one copy of ant more or less. So
[00:08:39.200 --> 00:08:43.400]   there's, there's just a ton of a ton of room to actually
[00:08:43.400 --> 00:08:45.920]   accelerate this process when you vectorize over things when you
[00:08:45.920 --> 00:08:49.400]   don't have to deal with network latency for sending data, you
[00:08:49.400 --> 00:08:52.760]   know, across the wire to some central server. This this this
[00:08:52.760 --> 00:08:58.440]   sort of, this was a an easy opportunity, I would say. All
[00:08:58.440 --> 00:09:02.000]   right. So here's a kind of a landscape of other
[00:09:02.000 --> 00:09:04.480]   differentiable engines. We were not, of course, the first people
[00:09:04.480 --> 00:09:08.680]   to put together a differentiable physics engine. So probably the
[00:09:08.680 --> 00:09:11.800]   two closest engines in terms of feature coverage and
[00:09:11.800 --> 00:09:15.120]   implementations are diff Taichi and tiny differentiable
[00:09:15.120 --> 00:09:18.000]   simulator, which we took a ton of inspiration from and design
[00:09:18.000 --> 00:09:21.760]   your engine. In fact, like very, very first 2d proto version of
[00:09:21.760 --> 00:09:27.040]   Brax was a heavily, heavily inspired by diff Taichi. And
[00:09:27.040 --> 00:09:29.080]   you're free to look at this chart and then reasonably ask
[00:09:29.080 --> 00:09:32.080]   why make another one? Well, for our own purposes, it wasn't
[00:09:32.080 --> 00:09:35.040]   really that we actually need a different ability. It was more
[00:09:35.040 --> 00:09:38.040]   that we found the impedance mismatch between any existing
[00:09:38.040 --> 00:09:41.480]   physics engine and modern RL to be too inefficient for our
[00:09:41.480 --> 00:09:45.800]   particular product needs. But when one builds on top of jacks,
[00:09:45.800 --> 00:09:49.160]   one kind of automatically inherits a lot of the wonderful
[00:09:49.160 --> 00:09:51.760]   things about jacks like bedrocks primitives for
[00:09:51.760 --> 00:09:54.800]   vectorization, device parallelism, and of course,
[00:09:54.800 --> 00:10:01.040]   different ability. So note that we're also exploring some new
[00:10:01.040 --> 00:10:06.360]   features and Brax that will actually make this contact
[00:10:06.360 --> 00:10:09.440]   physics a bit more exciting. We're also exploring reduced
[00:10:09.440 --> 00:10:13.240]   states for how the joints work if you're familiar with the
[00:10:13.240 --> 00:10:17.200]   lingo of physics engines. So this is coming to a Brax near
[00:10:17.200 --> 00:10:24.600]   you soon. Right. So how does Brax actually work? I'm going
[00:10:24.600 --> 00:10:27.960]   to be pretty high level here. But this is all the ingredients
[00:10:27.960 --> 00:10:31.760]   that let our little ant here tumble rightwards forever. So we
[00:10:31.760 --> 00:10:36.880]   have actuator forces that torque rigid bodies around joints. This
[00:10:36.880 --> 00:10:40.160]   is what people like actually use when you want your creature to
[00:10:40.160 --> 00:10:44.520]   do something, you have to tell it how to move its limbs. We have
[00:10:44.520 --> 00:10:46.680]   joint forces which limit the degrees of freedom between two
[00:10:46.680 --> 00:10:51.320]   rigid bodies. We have contact forces which try to keep rigid
[00:10:51.320 --> 00:10:55.840]   bodies from penetrating walls or each other. And all of these
[00:10:55.840 --> 00:10:58.240]   forces are separately calculated, and then applied to
[00:10:58.240 --> 00:11:01.640]   the fundamental state data, which we call QP. And this QP
[00:11:01.640 --> 00:11:05.200]   holds positions, quaternions, velocities, and angular
[00:11:05.200 --> 00:11:08.000]   velocities of all the different bodies in the scene. And that's
[00:11:08.000 --> 00:11:09.960]   really the only dynamic information. So it's sort of
[00:11:09.960 --> 00:11:14.680]   QPs in, QPs out for this physics step function. And then looking
[00:11:14.680 --> 00:11:18.360]   at the pseudocode for this physics step here, we see these
[00:11:18.360 --> 00:11:21.040]   integrator updates state data, and then we calculate impulses
[00:11:21.040 --> 00:11:24.000]   for the actuators, joints, and contacts. And then we complete
[00:11:24.000 --> 00:11:28.400]   the integration step. And then this is kind of a split step for
[00:11:28.400 --> 00:11:31.840]   technical reasons. And then simulation really is just doing
[00:11:31.840 --> 00:11:34.720]   this over and over and over for, you know, hundreds of steps or
[00:11:34.720 --> 00:11:37.680]   something. And that's about all the detail I was going to go
[00:11:37.680 --> 00:11:41.000]   into. This really is about as complicated as it is. And if
[00:11:41.000 --> 00:11:44.080]   you want to see the step in more detail, I encourage you to
[00:11:44.080 --> 00:11:44.800]   check out the repo.
[00:11:44.800 --> 00:11:53.800]   All righty. But how does it scale? So first of a handful of
[00:11:53.800 --> 00:11:57.320]   plots, on the left, we have the training steps per second of
[00:11:57.320 --> 00:12:02.160]   Brax on a 4x2 TPUv3 versus the different environments in the
[00:12:02.160 --> 00:12:05.120]   initial release. One major takeaway here is that we can
[00:12:05.120 --> 00:12:07.360]   pretty comfortably scale up to thousands of parallel
[00:12:07.360 --> 00:12:09.680]   environments before we start seeing diminishing returns on
[00:12:09.680 --> 00:12:14.120]   the accelerator. So this is like, this is about 1000, 10,000,
[00:12:14.120 --> 00:12:17.280]   100,000, somewhere in the 10,000 range, you start seeing this
[00:12:17.280 --> 00:12:23.200]   kind of elbow of diminishing returns. And then on the right
[00:12:23.200 --> 00:12:26.560]   hand side, we have the training steps per second on the Ant
[00:12:26.560 --> 00:12:29.440]   environment, which is kind of our workhorse, not too simple,
[00:12:29.480 --> 00:12:32.440]   not too complicated, typical case for several different
[00:12:32.440 --> 00:12:35.520]   accelerators as a function of number of vectorized
[00:12:35.520 --> 00:12:39.680]   environments. So now the x axis is still number of parallel
[00:12:39.680 --> 00:12:41.680]   environments, y axis is still number of steps, but now the
[00:12:41.680 --> 00:12:46.440]   colors are like a P100 GPU, a V100 GPU, several different
[00:12:46.440 --> 00:12:51.000]   topologies of TPU. And this is not really too surprising here,
[00:12:51.000 --> 00:12:53.280]   I'm just showing kind of how different accelerators saturate.
[00:12:53.280 --> 00:12:57.800]   So GPUs typically saturate earlier because they're, and
[00:12:57.920 --> 00:13:01.480]   slightly slower just because they don't quite have the rough
[00:13:01.480 --> 00:13:04.800]   horsepower of TPUs, especially when you're stacking a bunch of
[00:13:04.800 --> 00:13:07.880]   TPUs. Here's just, this is like eight by eight, this is like 64
[00:13:07.880 --> 00:13:11.400]   TPU chips. So it's like kind of an insane number of TPUs. But
[00:13:11.400 --> 00:13:13.720]   it's a fun plot to see because it's like, yeah, just number
[00:13:13.720 --> 00:13:20.600]   keeps going up. So that's nice. Now for my favorite plot, this
[00:13:20.600 --> 00:13:24.760]   is the reward on the Ant task versus training time on several
[00:13:24.760 --> 00:13:29.240]   different accelerators. Every curve that says Brax is using
[00:13:29.240 --> 00:13:32.160]   our version of the Ant environment, and the blue curve
[00:13:32.160 --> 00:13:37.360]   is using OpenAI's Mojoco gem Ant environment. And the first
[00:13:37.360 --> 00:13:40.800]   major takeaway here is that training OpenAI's Mojoco Ant the
[00:13:40.800 --> 00:13:44.320]   standard way is fairly slow, but I think people in the community
[00:13:44.320 --> 00:13:48.680]   were kind of used to this, kind of expecting about an hour plus
[00:13:48.680 --> 00:13:51.960]   or multiple hours before getting a reasonable locomotion policy.
[00:13:53.480 --> 00:13:56.520]   But the second major takeaway here is that Brax is really
[00:13:56.520 --> 00:14:00.120]   fast. So we can we can get Ant policies as you saw in tens of
[00:14:00.120 --> 00:14:02.840]   seconds, it's actually a little bit slower than it needs to be
[00:14:02.840 --> 00:14:06.160]   on this kind of public colab. There's some network interconnect
[00:14:06.160 --> 00:14:08.320]   that adds about a minute that doesn't even need to be there.
[00:14:08.320 --> 00:14:11.520]   So like when I'm training policies on my production
[00:14:11.520 --> 00:14:15.040]   machine, everything's about a minute faster for me. But this
[00:14:15.040 --> 00:14:20.120]   is this is very nice. Very nice to have training turnaround time
[00:14:20.120 --> 00:14:24.600]   in minutes for locomotion policies. You might worry that
[00:14:24.600 --> 00:14:28.080]   our version of Brax is like much easier than OpenAI's or
[00:14:28.080 --> 00:14:31.240]   something. For some nefarious reason, here I have training
[00:14:31.240 --> 00:14:36.640]   curves for like one fixed set of ACME PPO hyper parameters. So
[00:14:36.640 --> 00:14:38.440]   that is this is like a completely different PPO
[00:14:38.440 --> 00:14:42.000]   implementation. It's not ours. All I've done is I'm kind of
[00:14:42.000 --> 00:14:46.520]   comparing apples to apples here when I'm training a policy for
[00:14:47.320 --> 00:14:51.000]   the Majoco Ant environment, and then I'm also training it for
[00:14:51.000 --> 00:14:54.720]   the Brax Ant environment, not making use of any of Brax's
[00:14:54.720 --> 00:14:58.320]   like vectorization or anything just like trying to see you
[00:14:58.320 --> 00:15:00.680]   know, what what does the exact same training algorithm do for
[00:15:00.680 --> 00:15:03.120]   these two things if we just switch out the step function.
[00:15:03.120 --> 00:15:06.240]   And here it's clear that like, you know, these training curves
[00:15:06.240 --> 00:15:09.840]   are almost on top of each other. Like, it's not like our version
[00:15:09.840 --> 00:15:14.120]   is like way, way easier to learn than Majoco's. It's just ours
[00:15:14.120 --> 00:15:15.280]   really does go a lot faster.
[00:15:15.280 --> 00:15:24.200]   All right. So up until this point, I've only really talked
[00:15:24.200 --> 00:15:28.640]   about how Brax is really great for running large parallel
[00:15:28.640 --> 00:15:32.640]   simulation on accelerators. But Brax is in JAX and we were a
[00:15:32.640 --> 00:15:35.600]   little careful how we wrote our physics parameters. So it's also
[00:15:35.600 --> 00:15:39.280]   differentiable. And it turns out that even when you can
[00:15:39.280 --> 00:15:42.680]   differentiate through trajectories, those derivatives
[00:15:42.680 --> 00:15:45.680]   can be pretty noisy, which I'll talk about a bit more in a
[00:15:45.680 --> 00:15:49.600]   second. So these plots concern a really simple reacher like task
[00:15:49.600 --> 00:15:52.440]   where you can show a pretty clear win in sample efficiency.
[00:15:52.440 --> 00:15:56.960]   And to be clear, this isn't even the reacher that's people are
[00:15:56.960 --> 00:15:58.800]   familiar with. This is like a reacher where you give it an
[00:15:58.800 --> 00:16:01.680]   angle and then it just moves towards that angle with kind of
[00:16:01.680 --> 00:16:04.280]   like a PD controller, if you know what that is. It's like the
[00:16:04.280 --> 00:16:07.480]   simplest possible task one can imagine where it just needs to
[00:16:07.920 --> 00:16:12.520]   go to some angle. It's very, very simple optimization
[00:16:12.520 --> 00:16:12.920]   problem.
[00:16:12.920 --> 00:16:15.960]   So is it chasing the laser?
[00:16:15.960 --> 00:16:21.520]   Yeah, it's it's the the red here, the like little red dot is
[00:16:21.520 --> 00:16:25.160]   what it needs to actuate to so like it gets it gets a reward
[00:16:25.160 --> 00:16:27.840]   for putting the tip of its little reacher arm on that dot.
[00:16:27.840 --> 00:16:30.920]   Does that make sense?
[00:16:30.920 --> 00:16:32.440]   Yep, that makes sense. Thank you.
[00:16:32.440 --> 00:16:36.520]   Cool. All right. So both these plots are the same data, but
[00:16:36.520 --> 00:16:40.040]   with slightly different x axes. On the left, we have reward on
[00:16:40.040 --> 00:16:45.040]   this reacher task versus wall clock training time for PPO. And
[00:16:45.040 --> 00:16:47.480]   then also for a simple gradient based algorithm called
[00:16:47.480 --> 00:16:50.520]   analytical policy gradients, which is literally just back
[00:16:50.520 --> 00:16:54.160]   propagation through the task reward. And on the left, we see
[00:16:54.160 --> 00:16:56.960]   both of these tasks, both these algorithms solve the task, and
[00:16:56.960 --> 00:17:00.920]   about the same amount of wall clock time, though PPO is a bit
[00:17:00.920 --> 00:17:06.440]   faster, tiny bit faster and a lot lower variance. On the
[00:17:06.440 --> 00:17:09.600]   right, however, I'm applying performance on this task versus
[00:17:09.600 --> 00:17:12.880]   the number of frames of experience used. So this is like
[00:17:12.880 --> 00:17:18.160]   actual, like, actual reacher environment scene, steps of
[00:17:18.160 --> 00:17:21.880]   reacher environment seen by the algorithm. And here, this APG
[00:17:21.880 --> 00:17:24.200]   clearly dominates PPO is about an order of magnitude more
[00:17:24.200 --> 00:17:27.440]   sample efficient. And that makes sense because when you're
[00:17:27.440 --> 00:17:30.040]   estimating a gradient via the policy gradient algorithm,
[00:17:30.040 --> 00:17:33.760]   that's manifestly less efficient than just using the gradient,
[00:17:33.760 --> 00:17:36.080]   because if you just have the gradient, you don't have to
[00:17:36.080 --> 00:17:40.960]   estimate it. Or is it? You might rightly ask Daniel, you have
[00:17:40.960 --> 00:17:43.200]   this differentiable simulator, why are you only showing me a
[00:17:43.200 --> 00:17:45.840]   gradient based algorithm for the simplest possible environment?
[00:17:45.840 --> 00:17:48.480]   Why don't you just directly optimize, say, an ant policy,
[00:17:48.480 --> 00:17:51.840]   you know, with the gradients that you have. So quick little
[00:17:51.840 --> 00:17:56.960]   sidebar here, for analytical policy gradients for ant. So
[00:17:56.960 --> 00:18:00.880]   just to be like, extremely clear about what's going on here, we
[00:18:00.880 --> 00:18:04.000]   have some reward function. This reward function is a function of
[00:18:04.000 --> 00:18:07.880]   the state and the state of the ants at each time step and the
[00:18:07.880 --> 00:18:13.200]   action taken by the ant. The state of the system is controlled
[00:18:13.200 --> 00:18:17.040]   by deterministic transition function T, where you this
[00:18:17.040 --> 00:18:19.520]   transition function is also deterministic as it's function
[00:18:19.520 --> 00:18:22.880]   of the state of the system and the action taken by the ant. So
[00:18:22.880 --> 00:18:25.240]   calling this transition function, this is just like the
[00:18:25.240 --> 00:18:28.240]   physics stuff, you know, given the state given an action brings
[00:18:28.240 --> 00:18:32.160]   you to the next state. And then finally, this pi, which is a
[00:18:32.160 --> 00:18:34.760]   function of the state of the system and the control
[00:18:34.760 --> 00:18:37.160]   parameters theta is also deterministic. So we have all
[00:18:37.160 --> 00:18:40.080]   these deterministic functions, the full reward of the problem
[00:18:40.080 --> 00:18:44.080]   is the little r reward at each step. Because all these things
[00:18:44.080 --> 00:18:47.680]   are deterministic, one can just do gradient ascent on theta to
[00:18:47.680 --> 00:18:50.720]   find the best reward. Because this is just a fully
[00:18:50.720 --> 00:18:53.000]   deterministic function, and you can use jacks to take gradients
[00:18:53.000 --> 00:18:57.280]   with respect to theta. So why don't we just do this, we take
[00:18:57.280 --> 00:19:01.520]   ants, we write down this reward function, we use jacks to take
[00:19:01.520 --> 00:19:05.000]   the gradient. Here's what happens. So here's a training
[00:19:05.000 --> 00:19:10.560]   curve for ant as a function of number of like gradient updates.
[00:19:10.560 --> 00:19:14.880]   And you can see that it is not doing anything. This is our
[00:19:14.880 --> 00:19:17.600]   little ant wiggling around. I don't know. I don't know what he
[00:19:17.600 --> 00:19:20.440]   wants. He kind of going forward kind of going backwards,
[00:19:20.440 --> 00:19:24.120]   wiggling. And the reward curve is clearly not doing anything
[00:19:24.120 --> 00:19:26.720]   that makes any sense. It's not going up really, it's not even
[00:19:26.720 --> 00:19:30.600]   really going down, it's just kind of going up and down. And
[00:19:30.600 --> 00:19:33.640]   that's, that's no good. So what's what's going on here? Why
[00:19:33.640 --> 00:19:37.960]   can't we just take this fully differentiable problem and take
[00:19:37.960 --> 00:19:40.480]   the gradient because we have it and use it in a way that's
[00:19:40.480 --> 00:19:46.480]   useful. So here's a little hint of intuition for what's going on
[00:19:46.480 --> 00:19:50.560]   here I have to kind of explain this confusing cartoon. I have a
[00:19:50.560 --> 00:19:55.120]   ball, and I'm, I'm taking this ball, and I'm shooting it at
[00:19:55.120 --> 00:19:59.280]   some direct some initial direction theta. And this theta
[00:19:59.280 --> 00:20:04.240]   is the x axis on this confusing plot over here. And then the the
[00:20:04.240 --> 00:20:09.360]   y coordinate on this plot is the position of the ball after some
[00:20:09.360 --> 00:20:12.560]   amount of time where the amount of time is kind of increasing.
[00:20:12.560 --> 00:20:16.200]   So, you know, one one relevant data point on this plot is this
[00:20:16.200 --> 00:20:20.120]   very middle value. That's when this angle, oops. So that's when
[00:20:20.120 --> 00:20:24.720]   this angle is like, you know, exactly horizontal, and it's
[00:20:24.720 --> 00:20:27.480]   just this, this is just showing the ball bouncing back and forth
[00:20:27.520 --> 00:20:31.040]   across the, the wall. And then if you if you look at a slightly
[00:20:31.040 --> 00:20:33.640]   different angle, slightly different locking launch angle,
[00:20:33.640 --> 00:20:37.320]   like, you know, a few radians, that means it's the ball is just
[00:20:37.320 --> 00:20:41.160]   kind of bouncing back and forth along the wall. So this, this,
[00:20:41.160 --> 00:20:43.360]   the structure of this plot is clearly getting more complicated
[00:20:43.360 --> 00:20:47.120]   in time, right? It's getting a little bit more jagged. But, you
[00:20:47.120 --> 00:20:49.160]   know, at any given moment, there's still a gradient that
[00:20:49.160 --> 00:20:52.640]   you can follow like this, this, this is a, you know, there's,
[00:20:52.640 --> 00:20:55.000]   there's like a finite set of points that are maybe a little
[00:20:55.000 --> 00:20:58.440]   bit problematic, but whatever, like there's, this is a function
[00:20:58.440 --> 00:21:01.120]   that is differentiable. And it's, it's getting a little bit
[00:21:01.120 --> 00:21:03.600]   more complicated as a function of time, but it's not too bad.
[00:21:03.600 --> 00:21:07.000]   All right, let's see what happens when we add one extra
[00:21:07.000 --> 00:21:10.280]   ball to the problem. So we're adding just I literally put
[00:21:10.280 --> 00:21:12.640]   another ball that's initially stationary, and then I shoot
[00:21:12.640 --> 00:21:15.880]   this guy. And then as a function of theta, I see what happens.
[00:21:15.880 --> 00:21:19.600]   And you can see that the distribution of the ball
[00:21:19.600 --> 00:21:22.880]   position gets extremely messy as a function of time. And it's
[00:21:22.880 --> 00:21:25.320]   actually exponentially noisy to the point that calculating
[00:21:25.320 --> 00:21:28.320]   gradient of this function after 10 seconds of simulation results
[00:21:28.320 --> 00:21:33.560]   in this messy, spiky object, which is essentially completely
[00:21:33.560 --> 00:21:35.920]   non informative of anything about your problem. Like you
[00:21:35.920 --> 00:21:39.320]   could zoom in a bunch, maybe, maybe, and take like really tiny
[00:21:39.320 --> 00:21:41.840]   time steps and get get good gradient information. But it's
[00:21:41.840 --> 00:21:44.280]   like, this is this terrible, this is a, this is not a
[00:21:44.280 --> 00:21:46.600]   function you would ever want to try to differentiate and use
[00:21:46.600 --> 00:21:53.560]   because it's an enormous mess. So this just to kind of
[00:21:53.560 --> 00:21:56.680]   illustrate that this isn't unique to contact physics.
[00:21:56.680 --> 00:22:00.840]   Here's an example of a little toy called a magnetic pendulum,
[00:22:00.840 --> 00:22:04.040]   where you drop a magnet and it wiggles around for a while and
[00:22:04.040 --> 00:22:06.160]   eventually settles into some basin. Here's here's a more
[00:22:06.160 --> 00:22:08.920]   complicated version of a magnetic pendulum in action
[00:22:08.920 --> 00:22:11.560]   where it's, these are all like magnets on the bottom of this
[00:22:11.560 --> 00:22:14.040]   thing. And this also has a magnet and it's just bouncing
[00:22:14.040 --> 00:22:19.120]   around. So the right here is actually a phase space plot
[00:22:19.120 --> 00:22:23.000]   showing a five magnet version. So imagine this toy on the left,
[00:22:23.000 --> 00:22:27.240]   but there's like only five magnets. And it's showing based
[00:22:27.240 --> 00:22:31.480]   on like where you drop the pendulum, where does it end up
[00:22:31.480 --> 00:22:35.200]   where one of these basins is like one of the magnets. So
[00:22:35.200 --> 00:22:39.560]   probably, hopefully it is clear that the where you drop the
[00:22:39.560 --> 00:22:43.240]   magnet is a, it's like which which basin you end up in is an
[00:22:43.240 --> 00:22:47.040]   extremely sensitive function of where you start by like letting
[00:22:47.040 --> 00:22:52.360]   go of the pendulum bop. So yeah, this is this is sort of just
[00:22:52.360 --> 00:22:57.480]   physics is really chaotic in a in one picture. And these these
[00:22:57.480 --> 00:22:59.800]   kind of simple systems are actually in some sense simpler
[00:22:59.800 --> 00:23:05.480]   than the dynamics at play with our ant model. So with all that
[00:23:05.480 --> 00:23:12.000]   said, there actually is a bit of a longer story about this. But
[00:23:12.000 --> 00:23:14.440]   long story short, you can get around a lot of this difficulty
[00:23:14.440 --> 00:23:16.960]   by using an optimization technique called truncated
[00:23:16.960 --> 00:23:20.960]   backpropagation through time. But the gradients of systems
[00:23:20.960 --> 00:23:24.280]   that have contacts are just exceptionally poorly behaved. We
[00:23:24.280 --> 00:23:27.320]   explore this in a lot more detail and in a bunch of other
[00:23:27.320 --> 00:23:30.240]   systems as well. And our recent preprint called gradients are
[00:23:30.240 --> 00:23:34.280]   not all you need, which is at archive at this link. And
[00:23:34.280 --> 00:23:37.720]   really, this this technique is kind of the long and short of
[00:23:37.720 --> 00:23:40.400]   it is you just kind of introduce, let me go back a
[00:23:40.400 --> 00:23:45.040]   couple slides, you kind of add the stop gradients periodically
[00:23:45.040 --> 00:23:47.760]   to this reward function so that you only ever taking gradients
[00:23:47.760 --> 00:23:51.600]   through like 10 steps or so instead of like 1000 steps,
[00:23:51.600 --> 00:23:54.760]   which is the baseline environment. And that that
[00:23:54.760 --> 00:24:00.960]   greatly stabilizes optimization. But it's extremely sensitive to
[00:24:00.960 --> 00:24:05.800]   a lot of things. So this this plot here is showing the like
[00:24:05.800 --> 00:24:09.880]   reward on this this locomotion task as a function of just that
[00:24:09.880 --> 00:24:12.400]   one parameter, truncation length, and then different
[00:24:12.400 --> 00:24:14.240]   colors, different learning rates. And here you can see
[00:24:14.240 --> 00:24:17.960]   like, yeah, we got an ad to that can locomote, but it's, you
[00:24:17.960 --> 00:24:21.320]   know, it's, it's like, okay. And it also took like way longer.
[00:24:21.320 --> 00:24:23.720]   And it's still kind of flips over on its head at the end,
[00:24:23.720 --> 00:24:27.320]   because it's, it's just not as it's just not as good as PPO
[00:24:27.320 --> 00:24:32.800]   PPO is we, in defense of APG, perhaps we spent way longer
[00:24:32.800 --> 00:24:35.640]   optimizing our version of PPO than we have gradient based
[00:24:35.640 --> 00:24:38.760]   algorithms. But really, in my experience, it's been just so
[00:24:38.760 --> 00:24:43.720]   much easier to learn locomotion policies with these more model
[00:24:43.720 --> 00:24:49.520]   free like methods like SAC or PPO or even yes, they all they
[00:24:49.520 --> 00:24:52.000]   all work very well. They're all very good at estimating
[00:24:52.000 --> 00:24:56.400]   gradients. And it seems using the raw gradients is always a
[00:24:56.400 --> 00:25:03.480]   little bit difficult. Okay, then kind of zooming back now.
[00:25:03.480 --> 00:25:08.480]   Finally, just some some simple engine comparisons, I have the
[00:25:08.480 --> 00:25:12.080]   performance of Brax plotted against several other engines on
[00:25:12.080 --> 00:25:14.760]   these astronaut benchmarks. These were introduced by some of
[00:25:14.760 --> 00:25:18.520]   the Majoco authors. The left two plots here are showing like
[00:25:18.520 --> 00:25:22.840]   linear and angular momentum non conservation, as a function of
[00:25:22.840 --> 00:25:26.120]   simulator fidelity of the rightmost plot is showing energy
[00:25:26.120 --> 00:25:30.080]   non conservation. So these are kind of confusing thoughts that
[00:25:30.080 --> 00:25:34.000]   the way to read this is up into the right is better. And the
[00:25:34.000 --> 00:25:36.840]   major takeaway is that Brax isn't really like overwhelmingly
[00:25:36.880 --> 00:25:39.560]   better or worse on any of these things, although we're like,
[00:25:39.560 --> 00:25:43.560]   actually pretty good at angular momentum conservation. But you
[00:25:43.560 --> 00:25:46.880]   know, Majoco, Runge Kutta, which is one of their fancy integrators
[00:25:46.880 --> 00:25:51.320]   is like really good for energy non conservation. But like, you
[00:25:51.320 --> 00:25:53.800]   know, we're kind of middle of the pack for angular momentum
[00:25:53.800 --> 00:25:58.720]   and, and energy. So this is just, you know, you aren't you
[00:25:58.720 --> 00:26:03.040]   aren't sacrificing much by using Brax. It's kind of, I mean, it's
[00:26:03.040 --> 00:26:05.480]   sort of unsurprising, all these engines are using very similar
[00:26:05.480 --> 00:26:08.720]   things under the hood. They're just kind of differences in
[00:26:08.720 --> 00:26:10.960]   detail that that cause these sorts of numerical
[00:26:10.960 --> 00:26:12.880]   inaccuracies to be slightly different.
[00:26:12.880 --> 00:26:20.080]   Alright, so this kind of the story so far, we've enabled this
[00:26:20.080 --> 00:26:24.000]   really fast training of this collection of familiar 3d rigid
[00:26:24.000 --> 00:26:27.720]   body physics based RL problems by making liberal use of Jax's
[00:26:27.720 --> 00:26:32.400]   compilation, parallelization and vectorization primitives, JET,
[00:26:32.400 --> 00:26:36.320]   P map and V map. We have a bunch of really nice collabs to make
[00:26:36.320 --> 00:26:39.400]   jumping in and using Brax super easy. You too can train Ant in
[00:26:39.400 --> 00:26:42.760]   about a minute with PPO. And we're adding new environments
[00:26:42.760 --> 00:26:45.000]   pretty regularly. So since we've submitted to NeurIPS, we've
[00:26:45.000 --> 00:26:48.200]   actually added like Reacher, URPiV, Hopper, Walker2D,
[00:26:48.200 --> 00:26:51.760]   inverted pendulum, swimmer, there's always more things
[00:26:51.760 --> 00:26:54.840]   getting cooked up because there's just infinite RL
[00:26:54.840 --> 00:26:57.240]   environments that people care about. And if you have a
[00:26:57.240 --> 00:27:00.080]   favorite environment, please let us know. We'd like to try it
[00:27:00.080 --> 00:27:03.080]   out. And we do accept pull requests. There's actually one
[00:27:03.080 --> 00:27:05.920]   happening right now, which we're about to add a new environment
[00:27:05.920 --> 00:27:11.000]   to Brax. So for some next steps, we're improving the contact
[00:27:11.000 --> 00:27:14.320]   physics, we want to add more primitives, so more types of
[00:27:14.320 --> 00:27:18.480]   colliders, joints, actuators, integrators, better stepping
[00:27:18.480 --> 00:27:21.000]   schemes. So I actually have a branch where I'm working on
[00:27:21.000 --> 00:27:24.440]   slightly more general constraint physics for like position based
[00:27:24.440 --> 00:27:26.840]   dynamics or velocity level constraints, if you know the
[00:27:26.840 --> 00:27:29.880]   lingo. And we also are working on reduced coordinates. I
[00:27:29.880 --> 00:27:31.960]   mentioned this earlier, where right now everything in Brax
[00:27:31.960 --> 00:27:35.680]   happens with maximal coordinates. And a lot of the
[00:27:35.680 --> 00:27:40.040]   other more popular engines are switching or have already
[00:27:40.040 --> 00:27:43.680]   switched to reduced coordinates, which is a bit more technically
[00:27:43.680 --> 00:27:47.760]   demanding on the on the programming side, but does have
[00:27:47.760 --> 00:27:53.400]   very nice stability properties and sort of uses fewer degrees
[00:27:53.400 --> 00:27:55.840]   of freedom to simulate the system in a very precise
[00:27:55.840 --> 00:27:59.080]   technical sense. And then finally, we'd like to do more
[00:27:59.080 --> 00:28:01.880]   differentiability. So there's actually a bunch of tricks one
[00:28:01.880 --> 00:28:06.440]   can play with contact physics when you have differentiability
[00:28:06.440 --> 00:28:09.840]   that I haven't talked about at all. And then I'd like to think
[00:28:09.840 --> 00:28:15.680]   more even more about this back propagation through time, this
[00:28:15.680 --> 00:28:19.400]   BPTT algorithm that I was talking about for the gradients
[00:28:19.400 --> 00:28:22.000]   with Ant. Differentiating through trajectories is still
[00:28:22.000 --> 00:28:25.320]   really hard. And there's a whole bag of tricks that one can apply
[00:28:25.320 --> 00:28:27.720]   to this problem like shadowing methods. There's there's,
[00:28:27.720 --> 00:28:30.080]   there's tons of stuff left to do to make the gradients in Brax
[00:28:30.080 --> 00:28:37.840]   better. So that's really all I had slides wise. Happy to talk
[00:28:37.840 --> 00:28:43.720]   more answer any questions, we can jump back over to our Ant
[00:28:43.720 --> 00:28:46.600]   Paul or our humanoid policy over here. Let me see if it's done
[00:28:46.600 --> 00:28:47.080]   training.
[00:28:47.080 --> 00:28:52.960]   Yeah, it's fascinating how fast they train now. Like, honestly,
[00:28:52.960 --> 00:28:56.640]   I'm a total RL noob. I just fork repositories and run stuff. But
[00:28:56.640 --> 00:28:59.480]   the first time I tried it, it would take like I remember days
[00:28:59.480 --> 00:29:01.480]   on a CPU just to make things work.
[00:29:01.480 --> 00:29:05.000]   Yeah, yeah, that was that was unacceptable to us. So we
[00:29:05.000 --> 00:29:08.080]   really wanted to, here's our Ant, here's our humanoid now.
[00:29:08.080 --> 00:29:14.080]   And this this took, let's see. This took about five minutes
[00:29:14.080 --> 00:29:17.080]   total. So about two minutes to compile and three minutes to
[00:29:17.080 --> 00:29:19.520]   train. Yeah,
[00:29:19.520 --> 00:29:20.640]   I mean, he looks happy.
[00:29:20.840 --> 00:29:22.880]   Yeah, he looks happy. I mean, it's, you know, it could be more
[00:29:22.880 --> 00:29:27.040]   symmetric, and maybe a bit less wobbly. This is actually a lot
[00:29:27.040 --> 00:29:30.400]   of the things I'm working on right now are making, making it
[00:29:30.400 --> 00:29:34.560]   so he's less wiggly. Well, you can kind of watch him in slow
[00:29:34.560 --> 00:29:37.440]   motion here. My God, look at these, look at these joints.
[00:29:37.440 --> 00:29:40.720]   These joints are like way too wiggly. But that's okay. He's
[00:29:40.720 --> 00:29:43.120]   he's still running. I think I think maybe the biggest surprise
[00:29:43.120 --> 00:29:46.160]   to all of this is that, you know, people spent a really long
[00:29:46.160 --> 00:29:49.920]   time trying to get like, exceptionally high quality
[00:29:49.920 --> 00:29:52.800]   physics in their simulators. And it turns out that like the
[00:29:52.800 --> 00:29:55.160]   underlying reinforcement learning problem actually isn't
[00:29:55.160 --> 00:29:58.560]   really any easier or harder when your physics is like a little
[00:29:58.560 --> 00:30:01.560]   bit lower quality. It's kind of just the same and you can do
[00:30:01.560 --> 00:30:05.560]   lower quality physics way faster, which is evidenced by
[00:30:05.560 --> 00:30:08.640]   Brax. You can also do a really good quality physics this fast,
[00:30:08.640 --> 00:30:11.280]   you just have to be more careful, which is kind of what's
[00:30:11.280 --> 00:30:15.200]   what's coming soon in our future versions of Brax. But this was
[00:30:15.200 --> 00:30:18.360]   definitely kind of a $20 bill laying on the ground in terms of
[00:30:19.240 --> 00:30:22.320]   being able to prototype things that people were familiar with
[00:30:22.320 --> 00:30:23.560]   much, much faster.
[00:30:23.560 --> 00:30:27.160]   Sanyam Bhutani: That makes sense. Christian says in the
[00:30:27.160 --> 00:30:29.920]   chat, he has a few questions. So while while I wait for him to
[00:30:29.920 --> 00:30:34.120]   type that you had shown a slide where you demonstrated how the
[00:30:34.120 --> 00:30:39.400]   scales across TPUs. In what use cases is it really helpful to
[00:30:39.400 --> 00:30:43.840]   scale across such a huge number? And is there like any special
[00:30:43.840 --> 00:30:47.640]   tricks that go into making it so scalable? Or is that just the
[00:30:47.640 --> 00:30:50.000]   Jack's framework underlying?
[00:30:50.000 --> 00:30:58.640]   Um, so to the first question, essentially any you're you want
[00:30:58.640 --> 00:31:04.120]   that many TPUs when you're well, okay, it kind of depends. Like
[00:31:04.120 --> 00:31:07.400]   if you want something to happen quickly, then you need to be
[00:31:07.400 --> 00:31:13.800]   able to get lots of frames of experience. And for the sorts of
[00:31:14.760 --> 00:31:21.200]   reward functions that we have included in like Brax today, we
[00:31:21.200 --> 00:31:23.720]   don't need like, you know, an eight by eight sliced for that
[00:31:23.720 --> 00:31:25.680]   that all these reward functions are pretty straightforward.
[00:31:25.680 --> 00:31:30.280]   They're like, you know, go to a target locomote in some
[00:31:30.280 --> 00:31:33.960]   direction. For for something that would like actually require
[00:31:33.960 --> 00:31:36.720]   many, many TPUs that that'd be more like coordinated game
[00:31:36.720 --> 00:31:39.960]   playing something, something where like you actually the
[00:31:39.960 --> 00:31:42.040]   underlying reinforcement learning policy that you need to
[00:31:42.040 --> 00:31:46.600]   learn takes just gazillions of frames of experience before you
[00:31:46.600 --> 00:31:51.280]   can start estimating really good gradients. So yeah, it's sort of
[00:31:51.280 --> 00:31:55.120]   like a different grain size of problem you need when you and
[00:31:55.120 --> 00:31:57.560]   even then like you don't need an eight by eight slice. That's
[00:31:57.560 --> 00:31:59.920]   just that you want it to go fast, which you know, everyone
[00:31:59.920 --> 00:32:04.200]   wants to go fast. As for how it actually does it under the hood.
[00:32:04.200 --> 00:32:07.520]   It is a company. I mean, it is Jack, it's just it's short
[00:32:07.520 --> 00:32:12.680]   answer jacks. We we write everything to be branchless so
[00:32:12.680 --> 00:32:15.480]   that we can make use of the vectorization primitives and
[00:32:15.480 --> 00:32:18.440]   then kind of once you have things vectorizable and jacks,
[00:32:18.440 --> 00:32:22.960]   it's almost just as easy to make them parallel across machines.
[00:32:22.960 --> 00:32:29.080]   And then TPUs are sort of magical in their ability to just
[00:32:29.080 --> 00:32:33.120]   scale that way. Like you can also do this on like a on GPUs
[00:32:33.120 --> 00:32:37.560]   I've run jacks or I've run racks on like eight GPU machines and
[00:32:37.560 --> 00:32:41.520]   networks like you don't have to do anything special. You just
[00:32:41.520 --> 00:32:45.280]   connect eight GPUs and run it and it's fine. I haven't
[00:32:45.280 --> 00:32:50.080]   actually tried a cross machine parallelism in racks yet for
[00:32:50.080 --> 00:32:53.840]   GPU. For GPU it's straightforward because TPUs
[00:32:53.840 --> 00:32:57.960]   kind of do that for you. But I suspect it would work.
[00:32:57.960 --> 00:33:01.480]   Sanyam Bhutani: Yeah, I guess I guess as you scale it starts to
[00:33:01.480 --> 00:33:04.480]   differentiate TPUs hard to outperform for the initial bits
[00:33:04.480 --> 00:33:08.760]   initial bits where you have just eight GPUs and just one 8 by 8
[00:33:08.760 --> 00:33:11.960]   chip. I think it might not be that different. Yeah, yeah.
[00:33:11.960 --> 00:33:16.000]   Awesome. Thanks. Thanks for answering that. Christian has
[00:33:16.000 --> 00:33:19.800]   typed in his questions. I'll highlight them. Great. Are there
[00:33:19.800 --> 00:33:22.600]   restrictions that come with making a simulator purely
[00:33:22.600 --> 00:33:27.120]   jittable or differentiable? Example, how do you kill or
[00:33:27.120 --> 00:33:31.240]   delete an agent or body given shapes must be static?
[00:33:31.240 --> 00:33:38.880]   Yeah, yeah. So this is this is a whole thing. Yeah, so right now,
[00:33:38.880 --> 00:33:42.520]   the restrictions are kind of what you might expect. So like,
[00:33:42.520 --> 00:33:47.760]   if you want there to be dynamism in the scene, you have to do a
[00:33:47.760 --> 00:33:50.880]   lot of that management yourself, like and sort of already have
[00:33:50.880 --> 00:33:54.280]   those objects sitting around. So like, you know, say, say you
[00:33:54.280 --> 00:33:59.160]   want the ants to interact with like, a variable number of
[00:33:59.160 --> 00:34:07.080]   balls in a scene. For for jacks and for like compiled jacks, the
[00:34:07.080 --> 00:34:09.280]   staticness of this kind of demands that you already have
[00:34:09.280 --> 00:34:12.360]   those three balls or as many balls as you expect the ant to
[00:34:12.360 --> 00:34:16.320]   ever interact with defined in your proto. And then you have to
[00:34:16.320 --> 00:34:19.080]   kind of manage that yourself. So you'd have to like move the
[00:34:19.080 --> 00:34:23.560]   balls in and out of the scene as they need to be used by the
[00:34:23.560 --> 00:34:28.960]   ant. So that is, that is sort of like, you know, gesturing at a
[00:34:28.960 --> 00:34:32.400]   missing interface between practices that exist today and
[00:34:32.400 --> 00:34:35.080]   something like, you know, unity or Unreal Engine, which handles
[00:34:35.080 --> 00:34:38.880]   like the way you interact with kind of fully fledged game
[00:34:38.880 --> 00:34:42.360]   engines, obscures a lot of this memory management. It's just
[00:34:42.360 --> 00:34:44.600]   like, you know, you put you put a thing in the scene, and you
[00:34:44.600 --> 00:34:47.880]   kind of spawn it dynamically as you need it. Whereas doing
[00:34:47.880 --> 00:34:51.400]   things in jacks really does necessitate that everything be
[00:34:51.400 --> 00:34:53.960]   statically compiled. And they're not you can't really have these
[00:34:53.960 --> 00:34:58.120]   like dynamic shapes anywhere. The getting everything to be
[00:34:58.120 --> 00:35:00.840]   vectorized, I mentioned before requires things to be
[00:35:00.840 --> 00:35:05.400]   branchless, which is something of I mean, it's not it's not the
[00:35:05.400 --> 00:35:09.200]   end of the world. It's, it's pretty straightforward to take
[00:35:09.200 --> 00:35:15.720]   modern, like physics pipelines and turn them and make them
[00:35:15.720 --> 00:35:20.240]   branchless. The tricky bits come for actually making modern
[00:35:20.800 --> 00:35:25.280]   collision calling algorithms branchless. And that's actually
[00:35:25.280 --> 00:35:31.120]   a very tricky problem. Not just branchless, but like branchless
[00:35:31.120 --> 00:35:34.400]   and efficient on TPU architectures. So like we have,
[00:35:34.400 --> 00:35:37.640]   we have some somewhat clever calling algorithms that work
[00:35:37.640 --> 00:35:42.760]   great on GPU. But if you try to run, say, like 10,000 objects,
[00:35:42.760 --> 00:35:45.840]   interacting with each other on a TPU, it looks pretty, pretty
[00:35:45.840 --> 00:35:50.280]   poorly, like it, that doesn't work. Like, it kind of has to do
[00:35:50.280 --> 00:35:54.120]   with the memory architecture of TPUs and how they are kind of
[00:35:54.120 --> 00:36:00.560]   bad at doing random access. Access. Yeah, they're just bad
[00:36:00.560 --> 00:36:02.680]   at that period. Whereas GPUs are a lot better at that.
[00:36:02.680 --> 00:36:05.880]   Sanyam Bhutani: Sorry, in what case, would it make sense to
[00:36:05.880 --> 00:36:07.960]   like, spawn so many agents?
[00:36:07.960 --> 00:36:12.240]   Jason Antic: I mean, if you want to do something like, you know,
[00:36:12.240 --> 00:36:15.680]   like a capture the flag game, say you have like, you know, 10
[00:36:15.680 --> 00:36:19.400]   10 ants that are trying to capture the other 10 ants flag.
[00:36:20.160 --> 00:36:21.800]   That's like a lot of objects that can collide with each
[00:36:21.800 --> 00:36:27.560]   other in principle. And you can't do things like dynamically
[00:36:27.560 --> 00:36:29.640]   turn colliders on and off like you could in another game
[00:36:29.640 --> 00:36:32.120]   engine, you kind of have to statically have all of the
[00:36:32.120 --> 00:36:34.680]   things that are going to interact up front. So you have
[00:36:34.680 --> 00:36:38.200]   to you have to be a bit clever about how you do culling and how
[00:36:38.200 --> 00:36:39.560]   you lay things out.
[00:36:39.560 --> 00:36:43.880]   Sanyam Bhutani: Thanks. Thanks for clarifying. Christian has
[00:36:43.880 --> 00:36:46.080]   another question, what challenges come along with
[00:36:46.080 --> 00:36:49.240]   creating a simulator in a functional framework? How do you
[00:36:49.240 --> 00:36:50.080]   handle state?
[00:36:50.080 --> 00:36:56.200]   Yeah, so yeah, like, short answer is, we have to be fairly
[00:36:56.200 --> 00:37:01.320]   careful. Where the things that we expose is like the QP data,
[00:37:01.320 --> 00:37:04.880]   that's the only dynamic state of the problem. And that's what's
[00:37:04.880 --> 00:37:07.880]   passed around functionally, or like you, you start, in fact, I
[00:37:07.880 --> 00:37:16.400]   can I can show this. Let me jump back over to my slide or my
[00:37:16.560 --> 00:37:20.760]   collab here. What's the best place to do this? I can actually
[00:37:20.760 --> 00:37:27.480]   I can do it down here, we do this rollout. Do add a bunch of
[00:37:27.480 --> 00:37:32.600]   cells here. So you see this, this loop here, which is
[00:37:32.600 --> 00:37:34.520]   generate, which just generate this trajectory is really just
[00:37:34.520 --> 00:37:38.800]   driven entirely by these two lines where we're getting some
[00:37:38.800 --> 00:37:41.480]   action on the environment where this this is like the policy,
[00:37:41.480 --> 00:37:43.920]   this is the function, the inference function, this, this
[00:37:43.920 --> 00:37:47.680]   inference function is taking params, which is like, literally
[00:37:47.680 --> 00:37:50.320]   NumPy weights of a neural network, we're giving it the
[00:37:50.320 --> 00:37:54.640]   observation for the system, and some randomness. And that's
[00:37:54.640 --> 00:37:58.160]   producing an action. And then this, this is the brocks system
[00:37:58.160 --> 00:38:01.640]   step. And all we're giving it is the state of the system, and
[00:38:01.640 --> 00:38:04.400]   the action. So we can look at this, the state data, the state
[00:38:04.400 --> 00:38:07.720]   data has a bunch of stuff in it for kind of bookkeeping, but
[00:38:07.720 --> 00:38:11.040]   really state that QP is the state data for the system. So
[00:38:11.040 --> 00:38:14.280]   this is like the positions of all the body parts, the
[00:38:14.280 --> 00:38:19.160]   quaternions for all of the body parts, the velocities of all the
[00:38:19.160 --> 00:38:22.840]   body parts, and it's the zero is the zeroth one. So it's not
[00:38:22.840 --> 00:38:26.720]   moving yet. And Aang is just angular velocity. So like,
[00:38:26.720 --> 00:38:30.800]   we've, we've written it functionally, so that we only
[00:38:30.800 --> 00:38:34.880]   really pass around the data that needs to be passed around. And
[00:38:34.880 --> 00:38:37.400]   that is, this is like the minimal state data for the
[00:38:37.400 --> 00:38:39.800]   problem. The system specification has a bunch of
[00:38:39.800 --> 00:38:43.400]   other stuff that statically compiled. So for example, what
[00:38:43.400 --> 00:38:51.840]   am I going to do? And, and, and that step, so yeah, and big has
[00:38:51.840 --> 00:38:54.880]   all of the stuff that's kind of compiled away, which is things
[00:38:54.880 --> 00:39:00.760]   like, you know, where, where colliders are attached, how big
[00:39:00.760 --> 00:39:04.760]   they are, what the friction is, the inertia is the masses. And
[00:39:04.760 --> 00:39:09.000]   then for joints, it's things like, where are the four, four
[00:39:09.000 --> 00:39:11.840]   A joints between two bodies. So this is like the right knee,
[00:39:11.840 --> 00:39:15.160]   which is connecting the right thigh and the right shin. It's
[00:39:15.160 --> 00:39:17.840]   like, how are they oriented with respect to each other? How are
[00:39:17.840 --> 00:39:20.120]   they rotated? What's their damping? What are their angular
[00:39:20.120 --> 00:39:23.120]   limits, all this stuff is statically compiled. And it's
[00:39:23.120 --> 00:39:26.240]   essentially read in at initialization and set for the
[00:39:26.240 --> 00:39:28.400]   rest of the simulation. So that does mean if you want to change
[00:39:28.400 --> 00:39:31.560]   this stuff, then that's a little annoying. But you know, it's
[00:39:31.560 --> 00:39:34.320]   possible. It's just like, when you know, you're going to be
[00:39:34.320 --> 00:39:36.840]   simulating a humanoid, and you know, none of this stuff is
[00:39:36.840 --> 00:39:40.440]   changing, then by construction, you want to have this stuff
[00:39:40.440 --> 00:39:41.240]   statically compiled.
[00:39:41.240 --> 00:39:48.520]   I'm waiting for a response from Christian, but I'll take a
[00:39:48.520 --> 00:39:50.840]   second. This made sense to me. Cool. Yeah.
[00:39:50.840 --> 00:39:57.160]   Awesome. I'm just checking if there are any other questions.
[00:39:57.160 --> 00:40:01.560]   I don't see any I think Christian will have a follow up.
[00:40:01.560 --> 00:40:06.240]   In the meantime, for anyone who's like me who fairly knows
[00:40:06.240 --> 00:40:09.520]   this way around jargon in RL and is quite new to it, do you still
[00:40:09.520 --> 00:40:14.400]   recommend to play around with Brax or any other learning
[00:40:14.400 --> 00:40:16.080]   resources that you could suggest?
[00:40:16.080 --> 00:40:22.920]   Yeah, so I mean, there's using Brax is definitely like, I
[00:40:22.920 --> 00:40:27.680]   would suggest checking out like the sort of standard jacks
[00:40:27.680 --> 00:40:30.600]   resources first because it's, you know, it's built on top of
[00:40:30.600 --> 00:40:33.520]   jacks, and it has all of the sharp edges that jacks has
[00:40:35.240 --> 00:40:38.440]   probably the best entry point for folks that are maybe not as
[00:40:38.440 --> 00:40:41.440]   well versed in reinforcement learning is our basics co lab.
[00:40:41.440 --> 00:40:44.680]   And I can I can actually let me let me see if I can jump into
[00:40:44.680 --> 00:40:45.400]   that really quick.
[00:40:45.400 --> 00:40:48.880]   Do I can show that off.
[00:40:48.880 --> 00:40:51.840]   I'm just changing the URL here.
[00:40:52.760 --> 00:40:53.120]   To
[00:40:53.120 --> 00:41:12.160]   So this, this this basics collab really just steps very, very
[00:41:12.160 --> 00:41:15.840]   simply through like, a simple configuration with like a
[00:41:15.840 --> 00:41:20.480]   bouncy ball, showing this bouncy ball bounce, you can kind of
[00:41:20.480 --> 00:41:22.520]   play with the system parameters for this bouncy ball, and it
[00:41:22.520 --> 00:41:24.400]   shows you how to like construct the system.
[00:41:24.400 --> 00:41:29.640]   Also, like how to define joints. So here's like a two
[00:41:29.640 --> 00:41:33.120]   pendulum system, where you can watch it like swing, and how to
[00:41:33.120 --> 00:41:36.280]   like actuated to some target angle. So like, this is this is
[00:41:36.280 --> 00:41:41.400]   really the the simplest interface to to Brax physics
[00:41:41.400 --> 00:41:46.880]   internals for reinforcement learning material. Oh, geez,
[00:41:46.880 --> 00:41:49.480]   there's like, there's a gazillion reinforcement
[00:41:49.480 --> 00:41:52.120]   learning tutorials on the internet. I think I learned
[00:41:52.120 --> 00:41:54.400]   RL
[00:41:54.400 --> 00:42:00.000]   probably, I mean, I would suggest anyone that is super
[00:42:00.000 --> 00:42:04.760]   interested in RL, check out open AI is intro materials, they have
[00:42:04.760 --> 00:42:10.960]   like a getting started ramp up set of, of articles and like
[00:42:10.960 --> 00:42:14.440]   blog posts about doing stuff like just just kind of getting
[00:42:14.440 --> 00:42:15.560]   up to speed in RL.
[00:42:16.920 --> 00:42:20.160]   And then I would also suggest anyone that is really serious
[00:42:20.160 --> 00:42:22.640]   about RL, just try re implementing the policy gradient
[00:42:22.640 --> 00:42:26.880]   algorithm. That's kind of the one of the workhorse algorithms
[00:42:26.880 --> 00:42:31.240]   in RL. And it's a good experience for like, really
[00:42:31.240 --> 00:42:35.360]   grokking what is going on in in these sort of gradient estimator
[00:42:35.360 --> 00:42:39.160]   approaches. Because all these are algorithms are really doing
[00:42:39.160 --> 00:42:40.760]   some kind of fancy gradient estimation.
[00:42:40.760 --> 00:42:43.320]   Thanks. Thanks for answering that.
[00:42:45.160 --> 00:42:48.520]   Amit asks, How do you compare Brax to gem?
[00:42:48.520 --> 00:42:54.640]   So we do a couple of comparisons in our paper, probably the most
[00:42:54.640 --> 00:42:59.480]   relevant one for folks is just like learning curves as a
[00:42:59.480 --> 00:43:02.320]   function of number of environment steps seen on the
[00:43:02.320 --> 00:43:06.960]   same using the same algorithm. So like literally take take some
[00:43:06.960 --> 00:43:12.600]   reference implementation of PPO, and then use the the Brax gem
[00:43:12.640 --> 00:43:17.240]   in step or use the Majoko gem in step, and then just see what
[00:43:17.240 --> 00:43:20.120]   happens. And we show that you know, you get basically the same
[00:43:20.120 --> 00:43:23.200]   training curves for like ants, the same thing for humanoid.
[00:43:23.200 --> 00:43:26.920]   Half cheetah is they're not quite the same. There's a some
[00:43:26.920 --> 00:43:31.840]   subtleties in contact physics in 2d that kind of make things not
[00:43:31.840 --> 00:43:37.520]   quite the same short answer. But I mean, the kind of higher level
[00:43:37.520 --> 00:43:40.600]   point is that they're not the same. So like, I will be the
[00:43:40.600 --> 00:43:42.880]   first to tell you that, hopefully not the first to tell
[00:43:42.880 --> 00:43:45.360]   you that that Brax does not do physics the same way Majoko does
[00:43:45.360 --> 00:43:48.720]   like sure in the limit of like, very, very, very tiny step
[00:43:48.720 --> 00:43:51.400]   sizes. I mean, even then there's there's some subtleties around
[00:43:51.400 --> 00:43:54.080]   context about how they treat things differently. But like,
[00:43:54.080 --> 00:43:57.200]   they're different, like the there there are physics
[00:43:57.200 --> 00:43:59.600]   differences, there are important physics differences between
[00:43:59.600 --> 00:44:05.200]   Majoko and Brax. Because Majoko has been around for like, over a
[00:44:05.200 --> 00:44:08.480]   decade at this point, and has all kinds of fun features that
[00:44:08.480 --> 00:44:15.480]   make it very good at doing physics. That said, you can get
[00:44:15.480 --> 00:44:18.400]   pretty close with Brax like the where the places where we're
[00:44:18.400 --> 00:44:24.880]   missing are things like some subtleties during contact some
[00:44:24.880 --> 00:44:28.760]   subtleties around joint, joint physics, so you probably saw the
[00:44:28.760 --> 00:44:32.520]   joints were a little bit slightly in Brax that can
[00:44:32.520 --> 00:44:36.480]   actually be shored up in Brax by turning up joints, stiffnesses a
[00:44:36.480 --> 00:44:39.640]   bunch, like just making them like what you really want to do
[00:44:39.640 --> 00:44:42.080]   is when you're modeling a joint is to say like this joint is
[00:44:42.080 --> 00:44:45.640]   infinitely stiff, because that's sort of how robot joints are. I
[00:44:45.640 --> 00:44:48.200]   mean, it's not, you know, technically, there's some
[00:44:48.200 --> 00:44:51.400]   extremely tight spring constant that's controlled by like,
[00:44:51.400 --> 00:44:55.560]   electrostatics and atoms and metals that are extremely like,
[00:44:55.560 --> 00:44:57.840]   you know, 10s of 1000s of Newton's per meter or something.
[00:44:57.840 --> 00:45:02.680]   But like millions of Newton's per meter. But you know, sure,
[00:45:02.680 --> 00:45:05.400]   zooming out that that joint should be like infinitely stiff.
[00:45:05.400 --> 00:45:08.480]   And there are methods of doing for doing this. So for example,
[00:45:08.480 --> 00:45:13.480]   the Featherstone algorithm is what Majoko uses to model
[00:45:13.480 --> 00:45:17.240]   infinitely stiff joints. I have a branch where I'm working on
[00:45:17.240 --> 00:45:20.360]   using position based dynamics to model infinitely stiff joints.
[00:45:20.360 --> 00:45:23.800]   And even Brax today, you could you could get close to this by
[00:45:23.800 --> 00:45:27.400]   just cranking up the springs and lowering your time steps until
[00:45:27.400 --> 00:45:30.080]   it was good enough for your purposes.
[00:45:31.600 --> 00:45:34.680]   Sanyam Bhutani: That makes sense. Just as a reminder to
[00:45:34.680 --> 00:45:38.040]   people, if you signed up on this link, we'll send out all of
[00:45:38.040 --> 00:45:42.360]   these links, the people that Daniel just referred to and the
[00:45:42.360 --> 00:45:45.200]   link to the repository, the intro collabs, you'll get an
[00:45:45.200 --> 00:45:47.360]   email, you don't have to complain in the comments and
[00:45:47.360 --> 00:45:51.920]   make my colleagues unhappy and ask them to answer that.
[00:45:51.920 --> 00:45:55.320]   Everyone understands it's a pain for me. Please don't do that.
[00:45:55.320 --> 00:46:01.360]   Wait for the email. Here's a question by Christian. Is there
[00:46:01.360 --> 00:46:04.280]   a unity like editor to create scenes or can you import them
[00:46:04.280 --> 00:46:06.120]   from other frameworks into Brax?
[00:46:06.120 --> 00:46:10.040]   Not yet. So we actually did some unity integration got months
[00:46:10.040 --> 00:46:14.200]   ago, just to kind of prove that we could, but then it sort of
[00:46:14.200 --> 00:46:17.200]   became sidelined as we were doing other things. Right now
[00:46:17.200 --> 00:46:24.080]   that the best way to do, like interactive system hacking is
[00:46:24.080 --> 00:46:28.680]   we've actually made the the collab pipeline fairly quick
[00:46:28.680 --> 00:46:32.200]   where like if you if you edit in text a system config, and just
[00:46:32.200 --> 00:46:35.760]   like hit enter, it'll visualize within a second or so so you
[00:46:35.760 --> 00:46:40.280]   can, that is the current supported way of doing system
[00:46:40.280 --> 00:46:45.360]   editing. But it is on our to do list for fairly high priority to
[00:46:45.360 --> 00:46:49.640]   get some interactive tooling in because I, I don't worry, I
[00:46:49.640 --> 00:46:52.920]   understand how irritating it can be to only interact with these
[00:46:52.920 --> 00:46:57.280]   heavily visual scenes through pure code because people people
[00:46:57.280 --> 00:47:00.200]   are used to their fancy editors where you can like drag the
[00:47:00.200 --> 00:47:04.360]   sphere and move the sphere and rotate the stretch and squash
[00:47:04.360 --> 00:47:07.560]   like people people are people are rightfully spoiled by
[00:47:07.560 --> 00:47:11.440]   things like unity. Unity makes your life so so nice. It's such
[00:47:11.440 --> 00:47:13.640]   a such a delightful experience to just kind of put together a
[00:47:13.640 --> 00:47:13.960]   team.
[00:47:13.960 --> 00:47:19.360]   Have you seen this channel called mix and jump on YouTube?
[00:47:19.360 --> 00:47:20.720]   No, what is this?
[00:47:20.720 --> 00:47:24.840]   They they try to side note to totally different tangent. They
[00:47:24.840 --> 00:47:29.200]   try to recreate game dynamics in unity. It's it's like fascinating.
[00:47:29.200 --> 00:47:32.840]   You can do all of this in the game. Sorry, in the engine.
[00:47:32.840 --> 00:47:35.480]   Yeah, yeah, yeah. That's sweet.
[00:47:35.480 --> 00:47:39.360]   Thanks for answering that question. I'll give question a
[00:47:39.360 --> 00:47:42.960]   few more minutes. If he has any more questions. Usually I trust
[00:47:42.960 --> 00:47:44.840]   him to ask all the smart questions. I asked the dumb
[00:47:44.840 --> 00:47:50.120]   questions. In the meantime, we can the audience find you on the
[00:47:50.120 --> 00:47:51.960]   internet apart from the repositories.
[00:47:52.320 --> 00:47:55.800]   Yeah, so I am on the repositories. I'm on Twitter at
[00:47:55.800 --> 00:48:00.200]   bucket of cats. I can. That's I couldn't find you. Yeah, I
[00:48:00.200 --> 00:48:03.480]   actually don't super advertise. It's not like I'm trying to be
[00:48:03.480 --> 00:48:06.360]   anonymous because I post my papers and stuff all the time
[00:48:06.360 --> 00:48:09.840]   there. But it's more just like having one layer of anonymity
[00:48:09.840 --> 00:48:12.800]   makes it slightly less annoying. I don't know because I don't
[00:48:12.800 --> 00:48:15.680]   always post about work stuff. It's sort of my somewhat
[00:48:15.680 --> 00:48:18.080]   pseudonymous. I mean, not anymore. I'm gonna be posting
[00:48:18.080 --> 00:48:21.960]   this on YouTube. It's not it's not anonymous. I've every people
[00:48:22.000 --> 00:48:24.400]   I'm friends with all of the people post me when they're
[00:48:24.400 --> 00:48:27.640]   posting their papers. I'm on bucket of cats. Twitter.
[00:48:27.640 --> 00:48:33.480]   Awesome. Again, you'll find that in the email that goes out. Find
[00:48:33.480 --> 00:48:34.920]   Daniel also in the repository.
[00:48:34.920 --> 00:48:38.560]   I did see used my my LinkedIn headshot for this picture, which
[00:48:38.560 --> 00:48:42.760]   was pretty funny because that picture is from 2012. When I was
[00:48:42.760 --> 00:48:45.640]   in that was like the very first office I was in at Berkeley in
[00:48:45.640 --> 00:48:47.960]   grad school. It was a very beautiful office and we
[00:48:47.960 --> 00:48:50.400]   eventually got kicked out of it. But I don't know that picture
[00:48:50.400 --> 00:48:51.320]   brought back memories.
[00:48:52.280 --> 00:48:53.720]   Haven't haven't seen that face in a while.
[00:48:53.720 --> 00:48:57.320]   We were trying really hard to find you on Twitter and we
[00:48:57.320 --> 00:48:58.720]   couldn't know. Now we know.
[00:48:58.720 --> 00:49:03.200]   Yeah, that means that was successful and being slightly
[00:49:03.200 --> 00:49:04.240]   pseudonymous.
[00:49:04.240 --> 00:49:08.480]   Awesome. I don't see any questions from Christian. So I
[00:49:08.480 --> 00:49:11.240]   wrap up here. Thanks again, Daniel for joining us people
[00:49:11.240 --> 00:49:15.600]   please check out the Braggs repository sign up on this link
[00:49:15.600 --> 00:49:20.120]   to receive these as email updates. And I wanted to point
[00:49:20.120 --> 00:49:23.640]   out another repository developed by a Kaggle Grandmaster. It's
[00:49:23.640 --> 00:49:27.600]   called Jackston. This is more introductory levels stuff for
[00:49:27.600 --> 00:49:30.120]   people like me. Let me share my screen in a second.
[00:49:30.120 --> 00:49:39.440]   It's always tricky to pick the right app. But I quickly wanted
[00:49:39.440 --> 00:49:45.480]   to mention this. It's a set of 100 jacks exercises developed by
[00:49:45.480 --> 00:49:48.680]   Rohan Rao who's a 4x Kaggle Grandmaster. So he's a
[00:49:48.680 --> 00:49:51.880]   Grandmaster in all categories for Kagglers. They know how
[00:49:51.880 --> 00:49:56.040]   hard this is to achieve. It's a set of 100 exercises designed
[00:49:56.040 --> 00:49:59.600]   in a way to actually make you learn jacks. It's not a test.
[00:49:59.600 --> 00:50:02.000]   It's more of a learning experience. I'd highly
[00:50:02.000 --> 00:50:04.640]   encourage everyone to check this out. Just wanted to mention this
[00:50:04.640 --> 00:50:05.880]   repository to everyone.
[00:50:05.880 --> 00:50:06.760]   Yeah, that's sweet.
[00:50:06.760 --> 00:50:11.480]   And thanks again, Daniel for joining us. Christian says
[00:50:11.480 --> 00:50:13.920]   thanks. Sorry, Christian, you couldn't join us. Hopefully
[00:50:13.920 --> 00:50:16.160]   you'll join us in the future session. And thanks everyone for
[00:50:16.160 --> 00:50:16.640]   your time.
[00:50:16.640 --> 00:50:18.440]   Yeah, thanks for having me. Thanks, y'all.
[00:50:18.440 --> 00:50:27.300]   [BLANK_AUDIO]

