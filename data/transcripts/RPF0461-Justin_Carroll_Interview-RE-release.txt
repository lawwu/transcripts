
[00:00:00.000 --> 00:00:03.000]   ♪ Blessing in the mornin' ♪
[00:00:03.000 --> 00:00:05.000]   ♪ Come back Sunday morning ♪
[00:00:05.000 --> 00:00:08.000]   California's top casino and entertainment destination
[00:00:08.000 --> 00:00:11.000]   is now your California to Vegas connection.
[00:00:11.000 --> 00:00:14.000]   Play at Yamava Resort and Casino at San Manuel
[00:00:14.000 --> 00:00:17.000]   to earn points, rewards, and complimentary experiences
[00:00:17.000 --> 00:00:21.000]   for the iconic Palms Casino Resort in Las Vegas.
[00:00:21.000 --> 00:00:23.000]   ♪ We got the store to sell ♪
[00:00:23.000 --> 00:00:26.000]   Two destinations, one loyalty card.
[00:00:26.000 --> 00:00:29.000]   Visit yamava.com/palms to discover more.
[00:00:29.000 --> 00:00:31.000]   - Welcome to Radical Personal Finance,
[00:00:31.000 --> 00:00:33.000]   the show dedicated to providing you with the knowledge,
[00:00:33.000 --> 00:00:36.000]   skills, insight, and encouragement you need
[00:00:36.000 --> 00:00:38.000]   to live a rich and meaningful life now
[00:00:38.000 --> 00:00:40.000]   while building a plan for financial freedom
[00:00:40.000 --> 00:00:41.000]   in 10 years or less.
[00:00:41.000 --> 00:00:43.000]   My name is Joshua, and today I'm thrilled
[00:00:43.000 --> 00:00:46.000]   to have a guest named Justin Carroll.
[00:00:46.000 --> 00:00:49.000]   Justin is the author of various books
[00:00:49.000 --> 00:00:50.000]   on privacy and security,
[00:00:50.000 --> 00:00:52.000]   the co-author of an excellent book
[00:00:52.000 --> 00:00:55.000]   called "The Complete Privacy and Security Desk Reference,"
[00:00:55.000 --> 00:00:58.000]   and also the co-host of "The Complete Privacy
[00:00:58.000 --> 00:01:00.000]   and Security Podcast."
[00:01:00.000 --> 00:01:02.000]   Justin, welcome to Radical Personal Finance.
[00:01:02.000 --> 00:01:04.000]   - Joshua, thank you so much for having me on.
[00:01:04.000 --> 00:01:05.000]   It's great to be here.
[00:01:05.000 --> 00:01:06.000]   - Really glad to have you here.
[00:01:06.000 --> 00:01:09.000]   I was introduced to your work by a listener of mine,
[00:01:09.000 --> 00:01:12.000]   and privacy, especially financial privacy,
[00:01:12.000 --> 00:01:14.000]   has long been an interest of mine,
[00:01:14.000 --> 00:01:18.000]   but I've often found that the information in the space
[00:01:18.000 --> 00:01:23.000]   was either very cursory or not particularly up-to-date.
[00:01:23.000 --> 00:01:25.000]   And when I found the work that you
[00:01:25.000 --> 00:01:27.000]   and your business partner, Mike Urbano,
[00:01:27.000 --> 00:01:30.000]   are making, I was deeply impressed,
[00:01:30.000 --> 00:01:32.000]   and I've become a big fan of yours in the meantime.
[00:01:32.000 --> 00:01:34.000]   So in today's show, I want to outline
[00:01:34.000 --> 00:01:36.000]   and really just give you the floor
[00:01:36.000 --> 00:01:38.000]   to talk about privacy and security.
[00:01:38.000 --> 00:01:40.000]   Before I give you the microphone,
[00:01:40.000 --> 00:01:42.000]   I want to just lay the foundation that I see
[00:01:42.000 --> 00:01:44.000]   and why this is so important
[00:01:44.000 --> 00:01:46.000]   in the context of personal finance.
[00:01:46.000 --> 00:01:48.000]   In finance, there are a few different aspects
[00:01:48.000 --> 00:01:51.000]   wherein the discussion of financial privacy
[00:01:51.000 --> 00:01:53.000]   make a big, big impact,
[00:01:53.000 --> 00:01:57.000]   especially in the areas of asset protection,
[00:01:57.000 --> 00:02:00.000]   especially in the areas of business
[00:02:00.000 --> 00:02:03.000]   and the ability to protect yourself from potential harm.
[00:02:03.000 --> 00:02:05.000]   And one of the major concerns that I have
[00:02:05.000 --> 00:02:08.000]   is that in general, people don't think about
[00:02:08.000 --> 00:02:09.000]   these things in advance.
[00:02:09.000 --> 00:02:11.000]   They usually only start thinking about things
[00:02:11.000 --> 00:02:13.000]   when they get a call from the lawyer,
[00:02:13.000 --> 00:02:14.000]   or they start thinking about them
[00:02:14.000 --> 00:02:16.000]   when all of a sudden the police have shown up
[00:02:16.000 --> 00:02:19.000]   on the front door asking questions, et cetera.
[00:02:19.000 --> 00:02:22.000]   And so I believe that it's part of prudent planning
[00:02:22.000 --> 00:02:24.000]   to put in place some good safeguards
[00:02:24.000 --> 00:02:28.000]   with regard to your own financial privacy and security.
[00:02:28.000 --> 00:02:31.000]   So kick us off, tell us about your background
[00:02:31.000 --> 00:02:33.000]   and how you first started to become interested
[00:02:33.000 --> 00:02:36.000]   in the topic of privacy and security.
[00:02:36.000 --> 00:02:38.000]   - Well, I initially became interested,
[00:02:38.000 --> 00:02:40.000]   I come from a military background,
[00:02:40.000 --> 00:02:42.000]   and after I got out of the military,
[00:02:42.000 --> 00:02:46.000]   I spent several years going overseas
[00:02:46.000 --> 00:02:49.000]   as a contractor with another government agency.
[00:02:49.000 --> 00:02:52.000]   And I realized pretty quickly
[00:02:52.000 --> 00:02:54.000]   that privacy was kind of important.
[00:02:54.000 --> 00:02:57.000]   I had to give out my name and home address
[00:02:57.000 --> 00:03:00.000]   and next of kin information on various visa applications
[00:03:00.000 --> 00:03:03.000]   to countries that maybe aren't necessarily friendly
[00:03:03.000 --> 00:03:06.000]   to the US, and that kind of got the gears turning.
[00:03:06.000 --> 00:03:09.000]   And then a few years later, I spent about five years
[00:03:09.000 --> 00:03:11.000]   teaching a special operations course
[00:03:11.000 --> 00:03:13.000]   at one of the special operations courses
[00:03:13.000 --> 00:03:15.000]   for the US military.
[00:03:15.000 --> 00:03:20.000]   And SOCOM was kind of grappling,
[00:03:20.000 --> 00:03:22.000]   the special operations command was kind of grappling
[00:03:22.000 --> 00:03:26.000]   with this issue, this emerging issue of identity management.
[00:03:26.000 --> 00:03:30.000]   And I was fortunate enough to be one of the instructors
[00:03:30.000 --> 00:03:32.000]   for that and kind of got to develop my own curriculum
[00:03:32.000 --> 00:03:35.000]   and that's what really got the ball rolling.
[00:03:35.000 --> 00:03:37.000]   And then I met my partner, Michael Basil,
[00:03:37.000 --> 00:03:40.000]   who his big specialty is open source intelligence,
[00:03:40.000 --> 00:03:43.000]   which is finding everything there is to find
[00:03:43.000 --> 00:03:46.000]   about a person online just through
[00:03:46.000 --> 00:03:48.000]   really good Google searches and the things you put
[00:03:48.000 --> 00:03:50.000]   on Facebook and things like that.
[00:03:50.000 --> 00:03:53.000]   And between the two of us, we kind of put our heads together.
[00:03:53.000 --> 00:03:55.000]   He had a big interest in the privacy side as well.
[00:03:55.000 --> 00:03:59.000]   And this thing, some would say maybe has gotten
[00:03:59.000 --> 00:04:00.000]   a little bit out of control.
[00:04:00.000 --> 00:04:03.000]   We're maybe a little bit to foil hat and paranoid.
[00:04:03.000 --> 00:04:07.000]   But that's kind of what got me started down this road.
[00:04:07.000 --> 00:04:09.000]   And it's turned into a big personal interest,
[00:04:09.000 --> 00:04:12.000]   big personal hobby, and I'm not saying that everyone
[00:04:12.000 --> 00:04:14.000]   has to take it to the level that Michael and I
[00:04:14.000 --> 00:04:17.000]   have taken it to, but that's where it came from.
[00:04:17.000 --> 00:04:20.000]   - I used to pull back from talking about things
[00:04:20.000 --> 00:04:24.000]   that sounded outlandish and tinfoil hat approach
[00:04:24.000 --> 00:04:26.000]   in various subjects, but I've actually come to terms,
[00:04:26.000 --> 00:04:29.000]   I've come to peace with it and I've realized this.
[00:04:29.000 --> 00:04:34.000]   Almost everybody seems to love watching Jason Bourne movies.
[00:04:34.000 --> 00:04:36.000]   And the reason they love it is just because
[00:04:36.000 --> 00:04:38.000]   he's such a far out character.
[00:04:38.000 --> 00:04:41.000]   And so there's tremendous value in having people
[00:04:41.000 --> 00:04:44.000]   take things to the extreme because I feel it has
[00:04:44.000 --> 00:04:46.000]   more of an influence on moving people a little bit
[00:04:46.000 --> 00:04:50.000]   than oftentimes people who just do a few things here.
[00:04:50.000 --> 00:04:52.000]   It's often fun to have a Jason Bourne character
[00:04:52.000 --> 00:04:56.000]   out on the extreme fringe who can be inspiring
[00:04:56.000 --> 00:05:00.000]   and kind of brings that sexy side of things
[00:05:00.000 --> 00:05:01.000]   to a discussion.
[00:05:01.000 --> 00:05:03.000]   So we're gonna start with mainstream stuff,
[00:05:03.000 --> 00:05:08.000]   but I think it's extremely valuable to talk about
[00:05:08.000 --> 00:05:10.000]   the far out techniques so that people are aware of them.
[00:05:10.000 --> 00:05:13.000]   When you look at financial privacy,
[00:05:13.000 --> 00:05:15.000]   how do you factor into your thinking
[00:05:15.000 --> 00:05:18.000]   a specific focus of general privacy
[00:05:18.000 --> 00:05:21.000]   versus specifically financial privacy?
[00:05:21.000 --> 00:05:25.000]   - There's a lot of overlap between the two.
[00:05:25.000 --> 00:05:27.000]   I'm kind of of the school of thought
[00:05:27.000 --> 00:05:29.000]   that there is no privacy without security
[00:05:29.000 --> 00:05:31.000]   and there is no security without privacy.
[00:05:31.000 --> 00:05:33.000]   If you can get into my email account,
[00:05:33.000 --> 00:05:34.000]   that's a security issue, right?
[00:05:34.000 --> 00:05:37.000]   If I have a poor password and no two-factor authentication
[00:05:37.000 --> 00:05:40.000]   in there and you get into my primary Gmail account
[00:05:40.000 --> 00:05:42.000]   that holds everything,
[00:05:42.000 --> 00:05:45.000]   that's a security breach that's happened,
[00:05:45.000 --> 00:05:47.000]   but it affects my privacy deeply
[00:05:47.000 --> 00:05:49.000]   because now that you're in there,
[00:05:49.000 --> 00:05:52.000]   you have access to all the bank accounts,
[00:05:52.000 --> 00:05:55.000]   any financial account or any other kind of account
[00:05:55.000 --> 00:05:58.000]   that I've authenticated using that Gmail account
[00:05:58.000 --> 00:06:00.000]   as a point of contact for.
[00:06:00.000 --> 00:06:02.000]   So these things all kind of tie together
[00:06:02.000 --> 00:06:06.000]   and we talk about the tinfoil hat stuff,
[00:06:06.000 --> 00:06:11.000]   but it wouldn't exist without brilliance in the basics,
[00:06:11.000 --> 00:06:13.000]   without being very, very good
[00:06:13.000 --> 00:06:16.000]   at these baseline level privacy and security things.
[00:06:16.000 --> 00:06:18.000]   So I think everyone,
[00:06:18.000 --> 00:06:21.000]   whether you intend to take this
[00:06:21.000 --> 00:06:23.000]   to the furthest possible extreme
[00:06:23.000 --> 00:06:26.000]   or if you just wanna be a little bit more
[00:06:26.000 --> 00:06:28.000]   financially secure and financially private,
[00:06:28.000 --> 00:06:32.000]   you should consider those baseline level security measures.
[00:06:32.000 --> 00:06:36.000]   And I know our talk is not primarily around security,
[00:06:36.000 --> 00:06:38.000]   but I'm a firm believer
[00:06:38.000 --> 00:06:40.000]   that you can't have one without the other
[00:06:40.000 --> 00:06:43.000]   and you have to take those initial steps.
[00:06:43.000 --> 00:06:45.000]   And just generally speaking,
[00:06:45.000 --> 00:06:48.000]   the advice I kind of give to everyone,
[00:06:48.000 --> 00:06:51.000]   and these are not financial specific,
[00:06:51.000 --> 00:06:54.000]   but they do deeply impact financial privacy,
[00:06:54.000 --> 00:06:56.000]   is use good passwords.
[00:06:56.000 --> 00:06:58.000]   And to do that, you have to use a password manager.
[00:06:58.000 --> 00:07:00.000]   You need to use a different password
[00:07:00.000 --> 00:07:02.000]   on every account that you have,
[00:07:02.000 --> 00:07:04.000]   and if possible, a different username
[00:07:04.000 --> 00:07:06.000]   because that influences your attack surface.
[00:07:06.000 --> 00:07:08.000]   If I know your username,
[00:07:08.000 --> 00:07:11.000]   I know where to start attacking your account.
[00:07:11.000 --> 00:07:14.000]   However, you have set up a completely random username.
[00:07:14.000 --> 00:07:17.000]   I don't even have a good starting point for that.
[00:07:17.000 --> 00:07:20.000]   Two-factor authentication is another thing.
[00:07:20.000 --> 00:07:23.000]   So the way we implement this,
[00:07:23.000 --> 00:07:25.000]   I go to my bank account, I enter my username,
[00:07:25.000 --> 00:07:27.000]   I enter my password, I hit Log In,
[00:07:27.000 --> 00:07:29.000]   and it presents me with a second screen that says,
[00:07:29.000 --> 00:07:32.000]   "Go ahead and enter your two-factor authentication token."
[00:07:32.000 --> 00:07:35.000]   And maybe that's an app on my smartphone that displays a code,
[00:07:35.000 --> 00:07:37.000]   maybe that's a text message sent to me,
[00:07:37.000 --> 00:07:39.000]   or maybe that's something else.
[00:07:39.000 --> 00:07:42.000]   But those are kind of those baseline-level things
[00:07:42.000 --> 00:07:44.000]   that I would absolutely recommend doing
[00:07:44.000 --> 00:07:47.000]   for every single listener of your podcast
[00:07:47.000 --> 00:07:49.000]   or any other podcast,
[00:07:49.000 --> 00:07:51.000]   is protect your accounts
[00:07:51.000 --> 00:07:54.000]   because that front end really is your biggest attack surface
[00:07:54.000 --> 00:07:56.000]   and possibly your weakest--
[00:07:56.000 --> 00:07:59.000]   your biggest potential point of failure.
[00:07:59.000 --> 00:08:01.000]   One of the things I most appreciate about your work
[00:08:01.000 --> 00:08:05.000]   is you've given me a vocabulary.
[00:08:05.000 --> 00:08:09.000]   With your personal taxonomy of the realm of privacy and security,
[00:08:09.000 --> 00:08:13.000]   I didn't have the vocabulary to apply.
[00:08:13.000 --> 00:08:16.000]   And I really appreciate when you use things like attack surface.
[00:08:16.000 --> 00:08:20.000]   It's really, really helpful to me to do that and to know that.
[00:08:20.000 --> 00:08:23.000]   And just a couple of practical examples,
[00:08:23.000 --> 00:08:25.000]   as I understand what you're saying.
[00:08:25.000 --> 00:08:27.000]   When you have the same email address
[00:08:27.000 --> 00:08:30.000]   that you use constantly for every account,
[00:08:30.000 --> 00:08:31.000]   every social media account,
[00:08:31.000 --> 00:08:33.000]   every personal interaction,
[00:08:33.000 --> 00:08:35.000]   every business interaction, etc.,
[00:08:35.000 --> 00:08:39.000]   that email account is prominent and common
[00:08:39.000 --> 00:08:42.000]   across basically all over the web.
[00:08:42.000 --> 00:08:45.000]   So if there is a data breach from some random company
[00:08:45.000 --> 00:08:47.000]   that you do business with,
[00:08:47.000 --> 00:08:49.000]   which it's my opinion that in the fullness of time,
[00:08:49.000 --> 00:08:52.000]   every company that you do business with will have a data breach,
[00:08:52.000 --> 00:08:55.000]   then now that email address is sold on the black market
[00:08:55.000 --> 00:08:57.000]   and that email address can be used by somebody
[00:08:57.000 --> 00:09:00.000]   and various combinations of it tried.
[00:09:00.000 --> 00:09:02.000]   So if my name is Joshua Sheets
[00:09:02.000 --> 00:09:05.000]   and my email address is joshuasheets@gmail.com
[00:09:05.000 --> 00:09:08.000]   and then all of a sudden I use Joshua Sheets as my login information,
[00:09:08.000 --> 00:09:12.000]   it's not that hard for somebody to start guessing password variations,
[00:09:12.000 --> 00:09:14.000]   put a little bit of computer power behind it,
[00:09:14.000 --> 00:09:18.000]   and now all of a sudden they may have access to my financial accounts.
[00:09:18.000 --> 00:09:21.000]   And I'll beat up on banks a little bit here.
[00:09:21.000 --> 00:09:24.000]   Banks are not great at these authentication measures.
[00:09:24.000 --> 00:09:27.000]   So the bank that I have my corporate account with
[00:09:27.000 --> 00:09:32.000]   is I set it up with them kind of out of convenience,
[00:09:32.000 --> 00:09:34.000]   and I'm really regretting that decision now
[00:09:34.000 --> 00:09:37.000]   because of some of the privacy interventions that I have taken,
[00:09:37.000 --> 00:09:40.000]   it's a little bit difficult for me to just jump to another bank,
[00:09:40.000 --> 00:09:44.000]   but I'm stuck with a bank that doesn't allow two-factor authentication,
[00:09:44.000 --> 00:09:46.000]   that doesn't allow very long passwords.
[00:09:46.000 --> 00:09:49.000]   I think I'm capped at maybe 16 characters,
[00:09:49.000 --> 00:09:51.000]   and the character set is kind of limited,
[00:09:51.000 --> 00:09:53.000]   and this is kind of endemic with banks.
[00:09:53.000 --> 00:09:55.000]   I think some of the banks are doing a good job,
[00:09:55.000 --> 00:09:58.000]   banks like Bank of America, Citi, and Chase
[00:09:58.000 --> 00:10:01.000]   are doing a reasonably good job, these top-tiered banks,
[00:10:01.000 --> 00:10:05.000]   but if any of your listeners are with smaller credit unions
[00:10:05.000 --> 00:10:08.000]   or local banks or things of that nature,
[00:10:08.000 --> 00:10:10.000]   I would take a long, hard look at the security
[00:10:10.000 --> 00:10:13.000]   that is even possible to implement on those accounts
[00:10:13.000 --> 00:10:15.000]   before I go any further with that,
[00:10:15.000 --> 00:10:17.000]   and would maybe consider, you know,
[00:10:17.000 --> 00:10:20.000]   if you don't want to give up that oldest bank account that you have,
[00:10:20.000 --> 00:10:23.000]   maybe consider opening an account with a bank
[00:10:23.000 --> 00:10:25.000]   that offers some better security,
[00:10:25.000 --> 00:10:28.000]   and using that as my primary day-to-day use account
[00:10:28.000 --> 00:10:31.000]   rather than continuing on with that bank that doesn't.
[00:10:31.000 --> 00:10:35.000]   My experience has been that the banks probably aren't paying attention to it
[00:10:35.000 --> 00:10:37.000]   because the customers aren't demanding it.
[00:10:37.000 --> 00:10:39.000]   Just yesterday I released a show talking about--
[00:10:39.000 --> 00:10:41.000]   the title was "Don't Trust Your Financial Advisor."
[00:10:41.000 --> 00:10:43.000]   I released it before recording this,
[00:10:43.000 --> 00:10:45.000]   and the point was, I said you can't--
[00:10:45.000 --> 00:10:47.000]   and the point--it was a clickbait title,
[00:10:47.000 --> 00:10:51.000]   but basically my point was you can't trust your financial advisor
[00:10:51.000 --> 00:10:57.000]   to maintain your privacy, your secrecy, or your security.
[00:10:57.000 --> 00:10:59.000]   And one of my major--
[00:10:59.000 --> 00:11:02.000]   since I come from the world of professional financial advice,
[00:11:02.000 --> 00:11:08.000]   I am disheartened to see how insecure customer data is.
[00:11:08.000 --> 00:11:11.000]   And it's not because the firm doesn't know that they have a need for it.
[00:11:11.000 --> 00:11:13.000]   The firm, on the firm level,
[00:11:13.000 --> 00:11:15.000]   doesn't try to put in place things that are available.
[00:11:15.000 --> 00:11:19.000]   But I used to try to communicate with clients via an encrypted email system.
[00:11:19.000 --> 00:11:22.000]   And we had a very simple encrypted email system set up
[00:11:22.000 --> 00:11:26.000]   that I could use to convey private information to my clients.
[00:11:26.000 --> 00:11:29.000]   And I would use it, and we were required to use it,
[00:11:29.000 --> 00:11:33.000]   whenever we were transmitting personal information
[00:11:33.000 --> 00:11:35.000]   through the encrypted email system.
[00:11:35.000 --> 00:11:38.000]   But most of the clients hated using it
[00:11:38.000 --> 00:11:42.000]   because it required one extra step to decrypt the email.
[00:11:42.000 --> 00:11:43.000]   And so, of course, to get around it,
[00:11:43.000 --> 00:11:46.000]   people are constantly sending unencrypted files,
[00:11:46.000 --> 00:11:49.000]   or they just pop it over and send it through their personal Yahoo account
[00:11:49.000 --> 00:11:51.000]   right there to get it to the client,
[00:11:51.000 --> 00:11:53.000]   and the clients didn't demand it.
[00:11:53.000 --> 00:11:56.000]   So I think one of the first things that I'd love to see my listening audience do
[00:11:56.000 --> 00:12:03.000]   is start demanding better security measures from the people that serve you.
[00:12:03.000 --> 00:12:07.000]   Yeah, the thing I did with my financial advisor is--
[00:12:07.000 --> 00:12:11.000]   or that I do with him--he's still not very good at privacy and security.
[00:12:11.000 --> 00:12:13.000]   He's very good at his job,
[00:12:13.000 --> 00:12:15.000]   but privacy and security are definitely lacking.
[00:12:15.000 --> 00:12:17.000]   And I just put everything into a PDF.
[00:12:17.000 --> 00:12:22.000]   If you have Adobe PDF Pro on Windows or Preview on Mac,
[00:12:22.000 --> 00:12:24.000]   you can encrypt that PDF.
[00:12:24.000 --> 00:12:27.000]   So I'll send him the PDF, and then I'll call him and tell him the password,
[00:12:27.000 --> 00:12:29.000]   which kind of necessitates a simple password,
[00:12:29.000 --> 00:12:32.000]   but it's much better than nothing.
[00:12:32.000 --> 00:12:35.000]   And my question for you is, how do we fix this?
[00:12:35.000 --> 00:12:40.000]   Is there a financial advisor convention that I can get on the speaker list for?
[00:12:40.000 --> 00:12:42.000]   How do we start fixing this issue?
[00:12:42.000 --> 00:12:43.000]   That's a great idea.
[00:12:43.000 --> 00:12:46.000]   We could probably team up because I actually have the outline.
[00:12:46.000 --> 00:12:48.000]   One of the reasons why I consumed all your content
[00:12:48.000 --> 00:12:50.000]   was because I've been concerned about this for a while,
[00:12:50.000 --> 00:12:52.000]   and I had researched the topic.
[00:12:52.000 --> 00:12:56.000]   I have the outline of a book/course in my head.
[00:12:56.000 --> 00:12:57.000]   I have the outline written out.
[00:12:57.000 --> 00:12:59.000]   I'm not committed to actually completing it,
[00:12:59.000 --> 00:13:06.000]   but how to actually maintain as much financial anonymity and privacy as possible.
[00:13:06.000 --> 00:13:09.000]   And it is a big concern.
[00:13:09.000 --> 00:13:13.000]   We could talk about that because there probably is some stuff that could be created
[00:13:13.000 --> 00:13:15.000]   that would bring it to people's attention.
[00:13:15.000 --> 00:13:20.000]   I think people just don't recognize how big the vulnerability is.
[00:13:20.000 --> 00:13:25.000]   I know my experience was that I spent most of my life with my head in the clouds
[00:13:25.000 --> 00:13:28.000]   and I was just simply saying, "Eh, it's not going to happen to me,
[00:13:28.000 --> 00:13:30.000]   and if it does happen to me, it's probably not a big deal.
[00:13:30.000 --> 00:13:31.000]   It can be cleaned up."
[00:13:31.000 --> 00:13:35.000]   But over the last few years, I think we've seen plenty of evidence that, number one,
[00:13:35.000 --> 00:13:36.000]   it's going to happen to you,
[00:13:36.000 --> 00:13:40.000]   whether it's something embarrassing and potentially life-changing,
[00:13:40.000 --> 00:13:43.000]   such as being found in the Ashley Madison database,
[00:13:43.000 --> 00:13:46.000]   or whether it's something just simply inconvenient,
[00:13:46.000 --> 00:13:48.000]   such as being in the Target or Home Depot breach,
[00:13:48.000 --> 00:13:51.000]   or whether it's something potentially serious,
[00:13:51.000 --> 00:13:54.000]   like being involved in a government information breach,
[00:13:54.000 --> 00:13:57.000]   whether it's -- what was the breach on the military system?
[00:13:57.000 --> 00:13:58.000]   SIMON: OPM.
[00:13:58.000 --> 00:14:00.000]   STEVE: Yeah, exactly, recently.
[00:14:00.000 --> 00:14:04.000]   Or, I mean, this goes back years, back when the U.S. Census Bureau lost, what, 50 laptops,
[00:14:04.000 --> 00:14:08.000]   something like that, that were stolen with all this personal information on them.
[00:14:08.000 --> 00:14:13.000]   So I think the understanding that people have has raised,
[00:14:13.000 --> 00:14:18.000]   and so I'm trying to agitate here on the consumer side to get people to care about it,
[00:14:18.000 --> 00:14:24.000]   and my experience has been that just simply by telling people and encouraging people,
[00:14:24.000 --> 00:14:27.000]   "Hey," just requires certain things.
[00:14:27.000 --> 00:14:32.000]   I get a lot of my friends -- I try to get everyone I can to use something as simple as Signal,
[00:14:32.000 --> 00:14:35.000]   which is just a simple encrypted messaging and communication app.
[00:14:35.000 --> 00:14:37.000]   It's so easy to install.
[00:14:37.000 --> 00:14:43.000]   Every time I do it -- or I try to get people to use FaceTime, FaceTime audio, instead of making a phone call.
[00:14:43.000 --> 00:14:46.000]   So all of my friends with iPhones, I just always FaceTime audio them.
[00:14:46.000 --> 00:14:50.000]   "What's this FaceTime audio?" At least it gets a base level of encryption.
[00:14:50.000 --> 00:14:55.000]   And so I personally am a bit of an evangelist for it, and I think that that will have an effect,
[00:14:55.000 --> 00:14:58.000]   and it's only when the customers demand it that the industry will change.
[00:14:58.000 --> 00:15:02.000]   Well, I have to tell you, that's incredibly refreshing to hear,
[00:15:02.000 --> 00:15:07.000]   because it's not very common to hear people outside of the dedicated privacy and security space
[00:15:07.000 --> 00:15:14.000]   agitating for these things or advocating using Signal or encrypted email or things like that.
[00:15:14.000 --> 00:15:20.000]   So that's really kind of uplifting to hear that at least someone is out there doing that.
[00:15:20.000 --> 00:15:25.000]   Well, it used to be hard to do, and my observation is, you know,
[00:15:25.000 --> 00:15:31.000]   setting up manual PGP encryption on your email program is not for the faint of heart, right?
[00:15:31.000 --> 00:15:34.000]   So it's just easier to say, "Well, I'm not going to worry about it."
[00:15:34.000 --> 00:15:38.000]   But now when there are encrypted email options that are free and that are easy,
[00:15:38.000 --> 00:15:41.000]   I think the technology barrier has gone down.
[00:15:41.000 --> 00:15:49.000]   And especially my observation, the political scene really raised with the hacks of the Democratic National Committee
[00:15:49.000 --> 00:15:54.000]   and the releases there, whether that was from an outside attacker or an inside source, I don't know.
[00:15:54.000 --> 00:15:59.000]   But I think that these things have really raised their profile for people.
[00:15:59.000 --> 00:16:04.000]   Absolutely. Yeah. Possibly the best thing to come out of the Snowden leaks
[00:16:04.000 --> 00:16:09.000]   was not massive public awareness and people making behavioral changes,
[00:16:09.000 --> 00:16:14.000]   but companies that are interested in privacy and security are now providing us with options
[00:16:14.000 --> 00:16:16.000]   that are much more easily implemented.
[00:16:16.000 --> 00:16:21.000]   Even, you know, you mentioned PGP, which I still have a PGP key on my blog.
[00:16:21.000 --> 00:16:25.000]   If people want to email me that way, they're welcome to.
[00:16:25.000 --> 00:16:33.000]   But I maybe exchange a manual PGP encrypted email once a month at most.
[00:16:33.000 --> 00:16:40.000]   And it's even still possible for people like me to screw that up because it is such a technically demanding system.
[00:16:40.000 --> 00:16:46.000]   And thankfully, you know, for email, we have things like ProtonMail now that are much more manageable.
[00:16:46.000 --> 00:16:51.000]   Absolutely. So let's go back to the basics. I guess we went into nerd world there.
[00:16:51.000 --> 00:16:56.000]   Because I do want to emphasize the basics and I think these basics matter.
[00:16:56.000 --> 00:17:00.000]   So your best best practices that you mentioned were a few things.
[00:17:00.000 --> 00:17:03.000]   Number one, don't use a common username.
[00:17:03.000 --> 00:17:06.000]   If your name is Joshua Sheets, don't use Joshua Sheets as your login.
[00:17:06.000 --> 00:17:12.000]   Either use variations of that with numbers or even better, use an entirely random string of characters
[00:17:12.000 --> 00:17:20.000]   such as HK57329 and use a password management database system to maintain that information.
[00:17:20.000 --> 00:17:23.000]   Two was use strong passwords.
[00:17:23.000 --> 00:17:33.000]   So at the maximum length possible and of tremendous variation, the only way that's practically possible is to use a password management program,
[00:17:33.000 --> 00:17:36.000]   which I'm going to ask you about in just a moment, Justin, how you recommend.
[00:17:36.000 --> 00:17:40.000]   Because many people just have the habit of using one or two simple passwords.
[00:17:40.000 --> 00:17:43.000]   And they're very proud of themselves when they add a number or two to it.
[00:17:43.000 --> 00:17:49.000]   And they use the same password across all accounts, which is also better than having a simplest password.
[00:17:49.000 --> 00:17:51.000]   But it's also pretty insecure.
[00:17:51.000 --> 00:17:54.000]   And then number three was third-party authentication.
[00:17:54.000 --> 00:18:02.000]   Sorry, two-factor authentication, making sure that whenever possible, you add a second login factor to the login information.
[00:18:02.000 --> 00:18:05.000]   So practically, how do you manage that? How do you do that?
[00:18:05.000 --> 00:18:10.000]   And what are the apps and resources that you use and recommend for that base level of security for financial accounts?
[00:18:10.000 --> 00:18:17.000]   Absolutely. So for a password manager, I use a system called KeePass, which is free and open source.
[00:18:17.000 --> 00:18:22.000]   And there are some benefits and disadvantages to KeePass.
[00:18:22.000 --> 00:18:25.000]   So I'm a security. The security is my platform.
[00:18:25.000 --> 00:18:29.000]   So I'm always going to default to the more secure, less convenient option.
[00:18:29.000 --> 00:18:34.000]   KeePass creates a database that exists locally on your computer.
[00:18:34.000 --> 00:18:41.000]   So I use KeePass for Windows, KeePass X if you have Macs or Linux computers,
[00:18:41.000 --> 00:18:48.000]   and MiniKeePass for iOS, and KeePass for Android operating systems.
[00:18:48.000 --> 00:18:50.000]   And that's a little bit complex.
[00:18:50.000 --> 00:18:59.000]   But once you have the applications installed, you create that KeePass database on whatever your primary system is, probably your desktop computer.
[00:18:59.000 --> 00:19:08.000]   You can then drag that database over to your phone, your tablet, your other computer, your wife's computer, your husband's computer.
[00:19:08.000 --> 00:19:17.000]   They can all be accessed through that KeePass front end program because they all read that same .kbdx file format.
[00:19:17.000 --> 00:19:22.000]   So you can move those databases around. You do run into some version control issues with that.
[00:19:22.000 --> 00:19:27.000]   If you add something on your phone and you don't go in and update that database on your primary machine,
[00:19:27.000 --> 00:19:31.000]   those versions can very quickly start to conflict with each other.
[00:19:31.000 --> 00:19:38.000]   So if you're looking for a simpler, more convenient option, there's a program called LastPass.
[00:19:38.000 --> 00:19:41.000]   This is cloud-based, so it actually manages your database in the cloud.
[00:19:41.000 --> 00:19:47.000]   You can access it from any of your devices, Windows, Mac, Linux, Android, iOS.
[00:19:47.000 --> 00:19:53.000]   You can also log into it from the web, from any of your internet browsers,
[00:19:53.000 --> 00:19:57.000]   or from dedicated browser extensions for most of the major browsers.
[00:19:57.000 --> 00:20:02.000]   And the great thing about this is you can access it from anywhere, and anytime you update that database,
[00:20:02.000 --> 00:20:07.000]   it's updated across every single device because it's maintained in that one central hub.
[00:20:07.000 --> 00:20:12.000]   Now, I'm a little more leery of this because if that database were ever breached,
[00:20:12.000 --> 00:20:18.000]   then all my passwords for absolutely everything I have would be compromised.
[00:20:18.000 --> 00:20:24.000]   But I have some great security measures in place. I have a very, very long, strong password on that.
[00:20:24.000 --> 00:20:29.000]   You can use two-factor authentication, and let's talk about that a little bit.
[00:20:29.000 --> 00:20:33.000]   So I mentioned that you can get a text message, you can have an app on your phone
[00:20:33.000 --> 00:20:37.000]   that maintains those two-factor authentication tokens, or you can have a piece of hardware.
[00:20:37.000 --> 00:20:42.000]   So I don't recommend the SMS generally. That has actually been downgraded by a government agency,
[00:20:42.000 --> 00:20:48.000]   the National Institute of Standards and Technology, because of how easily defeated it is.
[00:20:48.000 --> 00:20:55.000]   It would take a fairly sophisticated, focused adversary that was specifically trying to defeat you,
[00:20:55.000 --> 00:20:59.000]   because in order to do that, I would have to hack into your phone account,
[00:20:59.000 --> 00:21:03.000]   which is not difficult to do at all, and forward your text messages to me.
[00:21:03.000 --> 00:21:07.000]   At that point, I would receive all your two-factor tokens and could log into your accounts,
[00:21:07.000 --> 00:21:10.000]   provided I had cracked the username and password.
[00:21:10.000 --> 00:21:15.000]   So that's not ideal, but it's still far, far better than nothing.
[00:21:15.000 --> 00:21:21.000]   So the next, kind of escalating up, the next thing would be a software token on an app like Google Authenticator,
[00:21:21.000 --> 00:21:29.000]   which you can install on your iOS or Android devices, or Authy, which uses the same protocol.
[00:21:29.000 --> 00:21:35.000]   You install it on your iOS or Android device, you log into your account with your username and password.
[00:21:35.000 --> 00:21:42.000]   The next step will ask for your token. You open up your phone, open that Google Authenticator or Authy app.
[00:21:42.000 --> 00:21:45.000]   You can have multiple different accounts in these apps.
[00:21:45.000 --> 00:21:49.000]   So let's say I have a Gmail account, a Dropbox account, and a Facebook account.
[00:21:49.000 --> 00:21:52.000]   I can have those tokens for all of those in this one single app.
[00:21:52.000 --> 00:21:59.000]   I tap the icon for the account I want, it displays the current six-digit code, I type that in, and I'm allowed to log in.
[00:21:59.000 --> 00:22:04.000]   That code is only good for one login, and it's only valid for a 30-second period.
[00:22:04.000 --> 00:22:11.000]   So you will notice if you watch the app every 30 seconds, the code that's on there will disappear, a new one will pop up.
[00:22:11.000 --> 00:22:15.000]   This is much, much better security than the SMS version.
[00:22:15.000 --> 00:22:19.000]   And then if you really want to go all out, there's a product called the YubiKey,
[00:22:19.000 --> 00:22:22.000]   and I will make sure you have a link for that in your show notes.
[00:22:22.000 --> 00:22:27.000]   But the YubiKey is a hardware token that you plug into a USB port.
[00:22:27.000 --> 00:22:33.000]   And the problem, kind of the issue with this is not a lot of services support this yet,
[00:22:33.000 --> 00:22:39.000]   but it creates a rotating code, you have to have the hardware in your computer,
[00:22:39.000 --> 00:22:44.000]   so you username, password, and on the next screen you just tap a little button on the YubiKey,
[00:22:44.000 --> 00:22:51.000]   it dumps that massive 40-character two-factor authentication token into the website, and you're allowed to log in.
[00:22:51.000 --> 00:22:56.000]   So there's kind of an escalating scale depending on how complex you want to get with it.
[00:22:56.000 --> 00:23:03.000]   Personally, I find the middle of the road, the Authy or Google Authenticator app to be the most usable.
[00:23:03.000 --> 00:23:08.000]   Text messages, I have problems with sometimes if I can't get cell service for whatever reason,
[00:23:08.000 --> 00:23:11.000]   I won't get those two-factor authentication tokens.
[00:23:11.000 --> 00:23:19.000]   So using the app has been the most convenient, and it's the level of security that I'm comfortable with for most of my accounts.
[00:23:19.000 --> 00:23:27.000]   - Authy is really simple to set up, you just do it and scan a code on the site and it's really easily integrated.
[00:23:27.000 --> 00:23:31.000]   My question is this, if you're using an app as in Authy or Google Authenticator,
[00:23:31.000 --> 00:23:38.000]   how do you back that up in case you have a malfunction of your mobile device that you are using the codes from?
[00:23:38.000 --> 00:23:44.000]   - So Authy makes it really, really easy, and I'm a little bit less familiar with Google Authenticator.
[00:23:44.000 --> 00:23:52.000]   If anyone has listened to my podcast, they'll know I kind of have a really negative view of anything with the name Google on it.
[00:23:52.000 --> 00:23:56.000]   - You and me both, I've been trying to extract myself for years, and I'm hoping in a few years I can,
[00:23:56.000 --> 00:23:58.000]   but I don't think I'll ever be able to fully extract.
[00:23:58.000 --> 00:24:03.000]   - So yeah, I'm really hesitant to put a Google-branded app on my phone.
[00:24:03.000 --> 00:24:08.000]   So I'm more familiar with Authy, but it allows you to go in and set a username and password,
[00:24:08.000 --> 00:24:17.000]   and it will store an encrypted version of your account information of those two-factor tokens on Authy's server.
[00:24:17.000 --> 00:24:22.000]   So if I lose my phone, if I drop my phone in the toilet, if my phone just dies one day,
[00:24:22.000 --> 00:24:25.000]   I go get a new one, back it up, and then I re-login to Authy,
[00:24:25.000 --> 00:24:32.000]   and it will refresh those two-factor tokens onto that device, and I don't skip a beat.
[00:24:32.000 --> 00:24:35.000]   - I've been learning how to use YubiKey.
[00:24:35.000 --> 00:24:39.000]   I learned that from you guys. I had never heard of it, and then I listened to your podcast on it
[00:24:39.000 --> 00:24:42.000]   and ordered a couple of them, and I've been using them.
[00:24:42.000 --> 00:24:46.000]   I think it's a tremendous, powerful--I mean, it's really, really cool,
[00:24:46.000 --> 00:24:50.000]   and it does what many of us, I think, would desire to have done.
[00:24:50.000 --> 00:24:56.000]   It uses and integrates the digital technology with the changing code with the physical security,
[00:24:56.000 --> 00:25:04.000]   so I can be confident that my account is not going to be accessed unless my physical token is present.
[00:25:04.000 --> 00:25:07.000]   My question for you is, it doesn't seem to work with Firefox.
[00:25:07.000 --> 00:25:11.000]   How do you do that? Because I like to use Firefox, but it doesn't work with Firefox.
[00:25:11.000 --> 00:25:13.000]   At least it doesn't right now. How do you fix that?
[00:25:13.000 --> 00:25:18.000]   - Yeah, that's-- - That's my personal question,
[00:25:18.000 --> 00:25:21.000]   because I've been trying to learn how to use it, and it's like, I've got to do it on Chrome,
[00:25:21.000 --> 00:25:23.000]   and I try not to use Chrome.
[00:25:23.000 --> 00:25:30.000]   - So if I'm not mistaken, you can use the YubiKey with some services on Firefox.
[00:25:30.000 --> 00:25:35.000]   Gmail will not support it on Chrome. Is that the experience that you're having?
[00:25:35.000 --> 00:25:40.000]   - Right. Gmail won't support it on Firefox. Facebook won't support it on Firefox, etc.
[00:25:40.000 --> 00:25:47.000]   - Okay. And also, I use YubiKey for some local accounts, or some local applications,
[00:25:47.000 --> 00:25:53.000]   like my KeePass database. I use a static YubiKey password to log into that KeePass database,
[00:25:53.000 --> 00:25:59.000]   so that's browser agnostic. It doesn't touch the browser, so it doesn't care.
[00:25:59.000 --> 00:26:05.000]   - I'm a little bit hesitant to recommend the YubiKey to people that aren't specifically privacy and security focused,
[00:26:05.000 --> 00:26:11.000]   because a $40 product is a really tough sell when you can go out and download
[00:26:11.000 --> 00:26:16.000]   Google Authenticator or Authy completely for free, and it works with a lot more things.
[00:26:16.000 --> 00:26:21.000]   However, I do really like the YubiKey. Once you have it set up and running,
[00:26:21.000 --> 00:26:26.000]   if you buy the YubiKey Nano, it just sits in your USB port. You barely even know it's there,
[00:26:26.000 --> 00:26:32.000]   and occasionally you just tap it and it dumps that code. But it's a little bit more technically challenging
[00:26:32.000 --> 00:26:40.000]   to set up and I think to kind of wrap your head around. And that $40 cost of entry is a tough pill for a lot of people to swallow.
[00:26:40.000 --> 00:26:44.000]   - Yeah, we'll get out of nerd world. Appreciate the reigning in there.
[00:26:44.000 --> 00:26:51.000]   LastPass for password management is fantastic, and you make a valid point with regard to security,
[00:26:51.000 --> 00:26:57.000]   but for most of us, our security is so horrifically bad that just to move to LastPass,
[00:26:57.000 --> 00:27:01.000]   where it'll automatically set it up so while you're browsing, everything is right there,
[00:27:01.000 --> 00:27:07.000]   and so that it'll create long, random passwords that are stored is tremendously valuable.
[00:27:07.000 --> 00:27:12.000]   I've had great success with getting people to use LastPass because it's stored in the cloud,
[00:27:12.000 --> 00:27:18.000]   which most people like, and it helps them to feel good, and also because of its just ubiquity across all platforms.
[00:27:18.000 --> 00:27:24.000]   So that would be a tremendous upgrade, and then also I'll affirm, as you said, Authy for two-factor authentication
[00:27:24.000 --> 00:27:32.000]   is easy to use, it's simple to set up, and it would be a tremendous step up for many people.
[00:27:32.000 --> 00:27:36.000]   So these steps would help to secure our accounts. What else?
[00:27:36.000 --> 00:27:42.000]   What are the low-hanging fruits? Are there any other low-hanging fruits that you wanted to add to this?
[00:27:42.000 --> 00:27:47.000]   Yeah, so I guess one more. So those are fairly easy steps to take.
[00:27:47.000 --> 00:27:52.000]   The next one is going to be a little bit painful, but it's kind of necessary, in my opinion,
[00:27:52.000 --> 00:27:56.000]   for both security and privacy, and that is get off Gmail.
[00:27:56.000 --> 00:28:03.000]   This is a tough sell because Google has kind of spread their tentacles into every aspect of life
[00:28:03.000 --> 00:28:09.000]   with Google Maps and Waze and Google Calendar and Google Translate and Google Street View
[00:28:09.000 --> 00:28:17.000]   and all these amazing services. If you have a Google account, you already have access to all these other things
[00:28:17.000 --> 00:28:22.000]   like Google Drive and Google Voice and all these other amazing products that make life so much easier.
[00:28:22.000 --> 00:28:26.000]   But these are all collecting information from you that will never be forgotten.
[00:28:26.000 --> 00:28:32.000]   It's all going onto a server, and a lot of it is very, very personally sensitive, even if you don't send emails.
[00:28:32.000 --> 00:28:39.000]   And most people are migrating to services like iMessage or Snapchat or other messaging services.
[00:28:39.000 --> 00:28:42.000]   Email is kind of going the way of the handwritten letter.
[00:28:42.000 --> 00:28:47.000]   It's becoming less and less common that people exchange these deep, intimate, personal emails.
[00:28:47.000 --> 00:28:52.000]   But if all you're receiving still is service notifications from your bank, from your physician,
[00:28:52.000 --> 00:29:00.000]   from all these services that create a lot of ancillary metadata about who you are and what you are,
[00:29:00.000 --> 00:29:03.000]   that's still a huge, huge privacy invasion.
[00:29:03.000 --> 00:29:06.000]   And there have been instances of rogue Google employees.
[00:29:06.000 --> 00:29:14.000]   There have been instances of, I mean, things like the NSA backdooring Google trunks to obtain all that data.
[00:29:14.000 --> 00:29:21.000]   And, you know, I don't want to emphasize that too much because we're not really trying to hide from the NSA.
[00:29:21.000 --> 00:29:27.000]   But the NSA has also proven very recently with the WannaCry leaks that they have a difficult time
[00:29:27.000 --> 00:29:30.000]   hanging on to the data that they collect.
[00:29:30.000 --> 00:29:32.000]   So if all this is floating around out there, it's at risk.
[00:29:32.000 --> 00:29:35.000]   So my personal solution is ProtonMail.
[00:29:35.000 --> 00:29:42.000]   And to get the functionality that most people need out of email, you're probably going to need a premium account,
[00:29:42.000 --> 00:29:43.000]   which is a couple of bucks a month.
[00:29:43.000 --> 00:29:45.000]   It's not onerous.
[00:29:45.000 --> 00:29:51.000]   You can step up to the ProtonMail Plus plan for under $50 a year if you buy yearly.
[00:29:51.000 --> 00:29:56.000]   And all your emails are end-to-end encrypted between ProtonMail users.
[00:29:56.000 --> 00:30:02.000]   One thing I found really handy with people like my accountant is that I can even encrypt emails to outside users.
[00:30:02.000 --> 00:30:03.000]   I just say encrypt this message.
[00:30:03.000 --> 00:30:05.000]   I assign a password to it.
[00:30:05.000 --> 00:30:08.000]   I call him up and say, hey, here's the password to open this email.
[00:30:08.000 --> 00:30:12.000]   And all the content of that email and any attachments are going to be encrypted.
[00:30:12.000 --> 00:30:17.000]   Everything's stored on an encrypted -- in an encrypted state in Switzerland.
[00:30:17.000 --> 00:30:22.000]   The administration of ProtonMail has no access to my emails.
[00:30:22.000 --> 00:30:27.000]   This is not the ultimate solution if you're going to be the next Edward Snowden.
[00:30:27.000 --> 00:30:38.000]   But for most of us, for our day-to-day communications, this takes you out of that automatic, no opt-in -- automatically opted-in data collection that we're all subject to.
[00:30:38.000 --> 00:30:51.000]   And even if ProtonMail is hacked or has a rogue employee, I don't worry that they're going to have access to my financial accounts or my other email accounts or my Facebook account or my doctor's accounts or whatever emails I'm receiving there.
[00:30:51.000 --> 00:30:54.000]   Because it's encrypted and they have no access to it.
[00:30:54.000 --> 00:31:06.000]   Do you think the rogue employee risk is the highest risk that practically speaking most of us who aren't engaged in foreign espionage and high crimes against the state are involved in?
[00:31:06.000 --> 00:31:08.000]   Do you think the rogue employee is the biggest risk?
[00:31:08.000 --> 00:31:09.000]   No.
[00:31:09.000 --> 00:31:15.000]   I think even as good as Google security is, defense is much harder than offense.
[00:31:15.000 --> 00:31:18.000]   Defense, you have to get it right every single time.
[00:31:18.000 --> 00:31:22.000]   Offense, you have to get it right once to get in and get a bunch of stuff.
[00:31:22.000 --> 00:31:28.000]   And Google is probably the world's biggest target because they're the world's biggest repository of data.
[00:31:28.000 --> 00:31:31.000]   That data is really, really valuable to people.
[00:31:31.000 --> 00:31:41.000]   Google is targeted thousands of times every single day and they have to get everything right 100% of the time to avoid being exploited.
[00:31:41.000 --> 00:31:44.000]   And eventually, they're going to fail.
[00:31:44.000 --> 00:31:56.000]   I really talk up Google security a lot because it's very good, but that's almost an unsustainable model to have to be perfect every single time.
[00:31:56.000 --> 00:32:01.000]   And the sophistication of the attackers is consistently increasing as well.
[00:32:01.000 --> 00:32:13.000]   There's a day when a hacker may have had some basic skills, but more and more, a hacker can turn an army of computing power of remote bots against something.
[00:32:13.000 --> 00:32:22.000]   The coding sophistication, the knowledge just seems to be consistently increasing, which is why we have to consistently step up our game across the board.
[00:32:22.000 --> 00:32:29.000]   Yeah. To misquote Bruce Schneier, today's NSA exploits are tomorrow's PhD theses and the next day's hacker tools.
[00:32:29.000 --> 00:32:40.000]   Yeah. I was thinking as you're talking about communication security, when I try to get people to just take a simple step, use FaceTime audio instead of using a phone call.
[00:32:40.000 --> 00:32:45.000]   Number one, you'll get a better product. You'll get a digital connection instead of an analog connection, which is downgraded signal quality.
[00:32:45.000 --> 00:32:53.000]   Or to use signal or wicker or something like that for your text messaging instead of using the SMS system.
[00:32:53.000 --> 00:33:08.000]   Oftentimes, the number one question is, "Well, I don't have anything to hide. Why should I bother to do that? I don't have anything to hide. I'm not involved in anything illegal. I'm not involved in anything immoral. I don't have anything to hide."
[00:33:08.000 --> 00:33:18.000]   And I often wish to wax eloquent about the philosophical basis of freedom and liberty and how this is important, etc.
[00:33:18.000 --> 00:33:24.000]   But recently, I've been trying this line. In the old days, when you made a phone call, it was automatically a party line.
[00:33:24.000 --> 00:33:33.000]   Anybody all up and down the line, your phone would ring anytime anybody on your phone line was being called.
[00:33:33.000 --> 00:33:38.000]   And you didn't listen for the fact of your phone ringing. You listened for the unique ring.
[00:33:38.000 --> 00:33:42.000]   If you had two short, one long, then you picked up only when it was two short and one long.
[00:33:42.000 --> 00:33:48.000]   But that meant that all up and down the line, anybody who wanted to could pick up the phone line and listen in on your conversation.
[00:33:48.000 --> 00:33:56.000]   And to me, it's as simple as, would you automatically voluntarily choose to use a technology that makes your phone calls a party line?
[00:33:56.000 --> 00:34:01.000]   Or if possible, would you prefer to have a direct person-to-person line and contact?
[00:34:01.000 --> 00:34:07.000]   And I've been trying that nonphilosophical answer to some success. How do you answer that objection?
[00:34:07.000 --> 00:34:17.000]   I think my first answer for that is when I go to the bathroom or when I'm being intimate with my significant other, I'm not doing anything wrong.
[00:34:17.000 --> 00:34:22.000]   But if there are other people in the house, I'm going to close the door. In either of those cases, there's absolutely nothing wrong with what I'm doing.
[00:34:22.000 --> 00:34:30.000]   They're both kind of biological imperatives and things that everyone does to a greater or lesser extent.
[00:34:30.000 --> 00:34:36.000]   But there's still that desire for privacy, right? It's not just because I don't want my guests to be offended.
[00:34:36.000 --> 00:34:42.000]   It's also because I want to have that privacy. And I think ultimately we feel the same about our communications.
[00:34:42.000 --> 00:34:54.000]   We don't think about it. We don't think about carrying a cell phone, which tracks you everywhere you go, because we've opted into that for the benefits that it gives us.
[00:34:54.000 --> 00:35:03.000]   But if there were someone following you around everywhere you went every day and writing in a notebook every place you stopped, how long you stayed there, who you talked to while you were there,
[00:35:03.000 --> 00:35:17.000]   people would get very frustrated with that really quickly. And that is happening. That happens on a daily basis to all of us that use a cell phone, which is probably every single person at this point, at least that listen to podcasts.
[00:35:17.000 --> 00:35:27.000]   That very same data collection is occurring. It's less visibly apparent to us, which I think is why it's less viscerally alarming.
[00:35:27.000 --> 00:35:34.000]   Absolutely. Any other low-hanging fruit that you want to mention before I adjust this a little bit?
[00:35:34.000 --> 00:35:39.000]   No, we can go ahead and push on unless there's something specific you want me to talk about.
[00:35:39.000 --> 00:35:50.000]   Well, it's interesting because one of the things why I think this is so important for people to do and to practice, and here's just my commentary and I'm interested in your take.
[00:35:50.000 --> 00:36:08.000]   Number one, it's my observation that these things are skills that need to be developed. The ability to use a two-factor authentication application or even just the ability to receive an SMS message and to input that code on the website is a skill that has to be learned.
[00:36:08.000 --> 00:36:21.000]   I recently read an author who was citing a report about how two-factor authentication is increasing, and he said, "This is bogus." He was an older guy. He said, "This is bogus. I don't see this anywhere." And I thought to myself, "That's bogus?"
[00:36:21.000 --> 00:36:30.000]   You just obviously don't have the skill. You're not using this because this is certainly not bogus. You need to develop the skills, and you got to develop the skills before you need them.
[00:36:30.000 --> 00:36:47.000]   And one of my concerns is to use your nomenclature, in time most of us hope to do things and to be effective in things that are going to necessarily raise our attack surface, which means bring us to a higher degree of prominence.
[00:36:47.000 --> 00:37:07.000]   Whether that's doing something like creating a podcast and talking about money on the internet or whether it's doing something like doing very well in your job or in your business and earning a significant amount of money or whether it's taking a stand in a political cause that is unpopular or that wherein you start to attract to yourself enemies.
[00:37:07.000 --> 00:37:23.000]   You've got to think years in advance and put the framework in place so that when all of a sudden you're being targeted with a lawsuit by your tenant who's suing you because they fell off the front porch and injured themselves and they know you own ten rental properties.
[00:37:23.000 --> 00:37:31.000]   And now all of a sudden they're going to start – they're going to bring a lawsuit against you. You've got to have thought about that a decade earlier and built the skill set.
[00:37:31.000 --> 00:37:42.000]   So I believe that it's important to plan and to teach people to plan for the fact that your profile in the future is going to be raised and you need to build the skills now to be prepared for that.
[00:37:42.000 --> 00:37:43.000]   What say you?
[00:37:43.000 --> 00:37:51.000]   Absolutely. I'm going to steal a quote from one of our recent podcast guests and say that you should dig your well before you're thirsty.
[00:37:51.000 --> 00:38:04.000]   We've seen plenty of examples of law enforcement officers who have come to national attention because of their actions on the job and I'm not going to weigh in with a judgment either way on that.
[00:38:04.000 --> 00:38:17.000]   But I will say at that point it's too late to do anything. Everything about them becomes public knowledge. It goes in the newspaper on a news crawl at the bottom of the screen for however long that story is at the front of public consciousness.
[00:38:17.000 --> 00:38:28.000]   And at that point it's too late to do anything about it. Once the news media is camped out on your lawn it's too late to hide your address because everyone already knows it.
[00:38:28.000 --> 00:38:43.000]   Or once you're doxxed by anonymous or once your account is breached, yeah you can change that password then and make sure those future emails are safe but that doesn't pull back those old emails and make them safe again.
[00:38:43.000 --> 00:38:54.000]   So don't wait until something happens to try to fix it. Take a proactive approach because that's really the only approach that's going to have any effectiveness.
[00:38:54.000 --> 00:39:02.000]   There are two stories that really sobered me and caused me to start working actively on defense for this.
[00:39:02.000 --> 00:39:20.000]   But in the last couple of years, three actually, and they all involved finances. Number one was the lady, the publicist who was on her way to South Africa and made a flippant comment and a tasteless joke on Twitter about contracting AIDS in Africa.
[00:39:20.000 --> 00:39:36.000]   No, I won't contract AIDS because I'm white and just trended bazillions of times on Twitter. By the time she had landed in South Africa she'd been fired from her job and she had basically the whole world finding out every single detail of her during a single airplane flight.
[00:39:36.000 --> 00:39:44.000]   And her whole world collapsed and it sent her into severe depression, affected all of her relationships, her financial world collapsed, etc.
[00:39:44.000 --> 00:40:01.000]   Second one was the dentist who shot the lion. And he shot the lion and from my observation – I didn't follow the story deeply so I could be wrong in this – but I never saw evidence that he had committed any kind of illegal act or that he had broken the law.
[00:40:01.000 --> 00:40:10.000]   There were a few questions about his interactions with his hunting trip and the purchase of his licenses but my guess was that was just probably standard African bribery systems.
[00:40:10.000 --> 00:40:19.000]   But there was no evidence that he had really done anything illegal and/or even immoral depending on somebody's definition of morality with regard to shooting lions.
[00:40:19.000 --> 00:40:35.000]   But his business was just destroyed overnight and he was sent into hiding. His house – and with the ability of Google reviews and of Yelp reviews, etc., his business was just destroyed and his dental practice sent him to the ground.
[00:40:35.000 --> 00:40:42.000]   I don't know what's happened since then. And then the third one was the pizza restaurant owner in Indiana.
[00:40:42.000 --> 00:40:49.000]   About two years ago when Indiana was passing the religious freedom – I think it was the Religious Freedom Restoration Act.
[00:40:49.000 --> 00:40:58.000]   The news crews were hunting for somebody who was professing an opinion on that piece about being a discriminatory person.
[00:40:58.000 --> 00:41:07.000]   And they found this pizza restaurant and they found the daughter of the owner, interviewed her on camera, making some fairly innocuous statements about homosexuality and religious freedom, etc.
[00:41:07.000 --> 00:41:15.000]   And then this became front and center news. And again, the pizza restaurant was just pounded into the ground. Yelp reviews destroyed, etc.
[00:41:15.000 --> 00:41:28.000]   All of those cases, none of us know what's happened since. But none of those three people set out in advance to cause a stir and to bring problems into their life.
[00:41:28.000 --> 00:41:38.000]   And to the best of my knowledge, none of them committed anything illegal. They just had breaches of judgment or took a position that was unpopular or did something that didn't fit the cultural narrative.
[00:41:38.000 --> 00:41:52.000]   And yet their lives and their livelihoods suffered immensely for it. And in today's day of instant access to the news, etc., I believe this is a serious financial planning concern that needs to be addressed by financial planners everywhere.
[00:41:52.000 --> 00:42:10.000]   Absolutely. And I find this a little bit easier to relate to law enforcement officers in my training. And the thing I tell them is, if you're involved in an officer involved shooting, the news media is going to be at your house before you are, before you get home that day.
[00:42:10.000 --> 00:42:24.000]   And at that point, there's nothing you can do about it. And, you know, I was going to bring up the dentist as well, had nothing to do with his practice, had nothing to do with his family life, had nothing to do with, you know, most aspects of his life.
[00:42:24.000 --> 00:42:47.000]   This one thing occurred, this one unfortunate event that impacted all of these aspects. And at that point, there was there's very little he could do to recover from that. A proactive approach, you know, every dollar spent in prevention is probably worth, you know, probably substitute every hundred dollars you'll spend in repairing the damage later on.
[00:42:47.000 --> 00:42:57.000]   One aspect of – back to financial security and then we'll move to privacy. One other aspect of financial security that you haven't mentioned that I think is important is compartmentalization of information.
[00:42:57.000 --> 00:43:19.000]   And I share this because of my experience in the trenches where, you know, if you're – especially if you have a high profile, high attack surface, again, to use your language, if you are a prominent person, then the people in the office that you're doing business with are going to be talking about your name and are going to be pulling up your accounts in their computer.
[00:43:19.000 --> 00:43:35.000]   I saw this myself. I worked very hard and never participate, but you can't help but overhear, "Oh, so and so is a client of mine." And of course, some people have access at the administrator level, can pull up and look and say, "Oh, here's this person's accounts. Here's that person's accounts," etc.
[00:43:35.000 --> 00:43:53.000]   And the staff, the administrative staff, is often somewhat broad who has access to that information. So the only way that I know to protect against that is to compartmentalize your information to the best degree possible, be very careful, and to just share what needs to be known with the people that need to know it rather than everything.
[00:43:53.000 --> 00:43:56.000]   How do you approach that problem?
[00:43:56.000 --> 00:44:12.000]   I approach that problem with a very proactive front-end approach in that I have essentially deleted my presence from the internet, and there's very little that you will know about me that I don't want you to know about me.
[00:44:12.000 --> 00:44:24.000]   So I run a blog, I have a Twitter page, I have a podcast, and those are things that I choose to put in the public space, but everything else I've worked very, very hard to regain control of.
[00:44:24.000 --> 00:44:39.000]   Also, to a debatable extent, I do have a public presence that supports my occupation, my business, my livelihood, but I tend to maintain a pretty low profile in my personal life.
[00:44:39.000 --> 00:44:49.000]   And that's kind of a tough question in that now we're kind of getting into the things that require a lot of effort for a little bit of payoff.
[00:44:49.000 --> 00:45:06.000]   But I know this is going to be a very unpopular approach, but I would say the first and foremost thing that average people need to do, the average listener, not my audience, but everyone else, which is the majority of society, is pull back your presence on Facebook.
[00:45:06.000 --> 00:45:11.000]   Stop posting every single detail of your life to a public forum.
[00:45:11.000 --> 00:45:23.000]   And even if your Facebook account is fairly locked down, fairly private, it is still on the open Internet, and that information is still available to regular people who really know how to use Facebook.
[00:45:23.000 --> 00:45:28.000]   That's the 90% solution right there.
[00:45:28.000 --> 00:45:30.000]   There's other mitigations we can do.
[00:45:30.000 --> 00:45:38.000]   Sorry, Joshua, but I did conduct a little bit of background research on you.
[00:45:38.000 --> 00:45:40.000]   I would hope you would.
[00:45:40.000 --> 00:45:41.000]   I didn't.
[00:45:41.000 --> 00:45:46.000]   I know you and I exchanged a few emails before this podcast you'd written in with a couple of questions.
[00:45:46.000 --> 00:45:55.000]   And I thought about sending an email back saying you need to you know, you need to change your address from, you know, whatever it is.
[00:45:55.000 --> 00:45:59.000]   I'm not going to say it on air, but I didn't want to scare you off.
[00:45:59.000 --> 00:46:07.000]   So I pulled back from that. But we can get into removing all those public mentions or at least most of them from the Internet.
[00:46:07.000 --> 00:46:11.000]   So your home address is not easily searchable.
[00:46:11.000 --> 00:46:30.000]   And if you get into some of the self background stuff that Michael and I talk about in the book and strongly advocate for just to find out what information exists about you online, you'll probably be surprised to learn that things like your home address is freely available on the open Internet with your name and the names of your family members.
[00:46:30.000 --> 00:46:32.000]   And to some people, that's alarming.
[00:46:32.000 --> 00:46:34.000]   To people like me, that's certainly very alarming.
[00:46:34.000 --> 00:46:36.000]   But some people don't care.
[00:46:36.000 --> 00:46:38.000]   That's kind of public information.
[00:46:38.000 --> 00:46:41.000]   But that also says a lot of other information about you.
[00:46:41.000 --> 00:46:44.000]   I can extrapolate a great deal from that.
[00:46:44.000 --> 00:46:57.000]   Things like your income level, your level of education, your possibly your ethnic demographic, your sexual orientation to some degree based on the neighborhood that you live in.
[00:46:57.000 --> 00:47:08.000]   And that seems like a small piece of information, but it tells me an awful lot about you, especially in certain neighborhoods that are very densely populated by one demographic or another.
[00:47:08.000 --> 00:47:12.000]   That's that's significantly private and intensely personal information to me.
[00:47:12.000 --> 00:47:14.000]   And I want to protect that.
[00:47:14.000 --> 00:47:31.000]   If this gets into a lot more effort for a lot less individual payoff per step, but we can control that information, we can remove a lot of it and and manipulate a lot of it in some cases to make ourselves a little bit less public and a lot less easily researchable.
[00:47:31.000 --> 00:47:33.000]   If that makes sense.
[00:47:33.000 --> 00:47:41.000]   I would say that my own personal and yes, I have conducted my own open source intelligence on myself searches.
[00:47:41.000 --> 00:47:45.000]   And yes, most almost everything is freely and openly available.
[00:47:45.000 --> 00:47:49.000]   So it would not have surprised me when you reached out to me.
[00:47:49.000 --> 00:47:53.000]   I would say that my own story is probably the best example.
[00:47:53.000 --> 00:47:55.000]   I never intended to become a public figure.
[00:47:55.000 --> 00:47:59.000]   It was completely unintentional.
[00:47:59.000 --> 00:48:08.000]   And I think this is the way that many people approach it where they look at it and say, "Well, I don't have anything to hide."
[00:48:08.000 --> 00:48:15.000]   So and so and also in terms of it's hard to put up walls around yourself for your privacy.
[00:48:15.000 --> 00:48:17.000]   Simple example in financial planning in Florida.
[00:48:17.000 --> 00:48:29.000]   In Florida and in most places, if you do something like purchase a home, your name is going to be entered into the property tax records as the owner of that local home.
[00:48:29.000 --> 00:48:40.000]   In Florida, this is a big deal because we have an unlimited homestead exemption amount where you can protect the entire value of your home with no dollar figure.
[00:48:40.000 --> 00:48:42.000]   There are a couple of – no dollar limit.
[00:48:42.000 --> 00:48:47.000]   There are a couple of limits as far as the amount of land that you own, etc.
[00:48:47.000 --> 00:48:49.000]   But there's no dollar limit.
[00:48:49.000 --> 00:48:55.000]   So you can protect the value of your home 100 percent from the claims of any creditors that you might face.
[00:48:55.000 --> 00:49:00.000]   This is very important with regard to asset protection planning.
[00:49:00.000 --> 00:49:06.000]   And as a financial planner, it's very important that I'm knowledgeable and skillful with that with regard to working with somebody.
[00:49:06.000 --> 00:49:17.000]   If you are going to – looking for a very secure place to stash $10 million, well, going ahead and purchasing and living in a $10 million waterfront home in Florida is probably – is a good plan for that.
[00:49:17.000 --> 00:49:20.000]   But if you do that, you give up your privacy.
[00:49:20.000 --> 00:49:30.000]   And if you purchase that home in the context of a trust, a living trust, or if you purchase it in the context of an entity of some other kind, you lose that creditor protection.
[00:49:30.000 --> 00:49:32.000]   So it's a balance.
[00:49:32.000 --> 00:49:44.000]   Well, do I take the value of the – do I take the value of the privacy by owning it within a living trust that's at least at the very limit – at the very lowest hanging fruit masked in another name?
[00:49:44.000 --> 00:49:46.000]   Or do I take the creditor protection?
[00:49:46.000 --> 00:49:51.000]   Because I'll lose that if I put it into a trust that's not held, especially if it's held jointly with my spouse.
[00:49:51.000 --> 00:49:53.000]   That gives very, very strong protection.
[00:49:53.000 --> 00:49:58.000]   And in my own case, along the way, you just make those normal situations.
[00:49:58.000 --> 00:50:03.000]   When I went and bought a house for the first time, I didn't know everything that I know now.
[00:50:03.000 --> 00:50:06.000]   And so I just bought a house and signed up for it and you faced a question.
[00:50:06.000 --> 00:50:14.000]   Well, do I try to move so I can – when I can – when I – do I try to move so that I can get a different place and protect my privacy?
[00:50:14.000 --> 00:50:17.000]   Voting. In the state of Florida, all of the voter records are public data.
[00:50:17.000 --> 00:50:18.000]   So do I register to vote?
[00:50:18.000 --> 00:50:19.000]   Well, I can't.
[00:50:19.000 --> 00:50:27.000]   It would be a crime for me to register using something that's not my actual information to some degree.
[00:50:27.000 --> 00:50:31.000]   So do I deregister, not register to vote, et cetera?
[00:50:31.000 --> 00:50:37.000]   And I have found that the whole path is a very challenging terrain to navigate.
[00:50:37.000 --> 00:50:39.000]   And each person has to look and say, well, what is my threat?
[00:50:39.000 --> 00:50:45.000]   Well, as you – my threat level, my attack surface, as it were, has changed dramatically.
[00:50:45.000 --> 00:50:49.000]   I never expected to be a public figure, never expected to have people know my name all around the world.
[00:50:49.000 --> 00:50:51.000]   And yet here we are.
[00:50:51.000 --> 00:50:56.000]   Absolutely agreed. And it is very much a compromise.
[00:50:56.000 --> 00:50:59.000]   And some things are kind of easy for me to compromise.
[00:50:59.000 --> 00:51:07.000]   You mentioned voting, and that is – man, voting is one of the most invasive things privacy-wise that I can think of.
[00:51:07.000 --> 00:51:13.000]   I can look up voter records for me if I know where to look and find very detailed records.
[00:51:13.000 --> 00:51:16.000]   And I've kind of made a decision not to vote anymore.
[00:51:16.000 --> 00:51:22.000]   And that's much less a – it's not laziness.
[00:51:22.000 --> 00:51:26.000]   And as a veteran, I kind of consider that my right to make that decision or not.
[00:51:26.000 --> 00:51:30.000]   It's a very calculated decision, and part of it is privacy.
[00:51:30.000 --> 00:51:34.000]   And there's also another more ideological aspect to it.
[00:51:34.000 --> 00:51:38.000]   But I've kind of made that decision not to vote.
[00:51:38.000 --> 00:51:45.000]   Also, in regards to owning a home, my first house I bought using a VA loan,
[00:51:45.000 --> 00:51:52.000]   which if you use a VA loan, you can't use any of the privacy mitigations that Michael and I talk about,
[00:51:52.000 --> 00:51:56.000]   some of the more tinfoil hat stuff, because the home has to be in your name.
[00:51:56.000 --> 00:52:00.000]   You are the veteran. There's no business entity that can take that loan out for you.
[00:52:00.000 --> 00:52:04.000]   So I'm not currently a homeowner. I'm currently a renter.
[00:52:04.000 --> 00:52:09.000]   And the next house I purchase, I'm going to have to make a decision about that.
[00:52:09.000 --> 00:52:16.000]   And kind of my plan, my long-term plan is to pay cash for it, but that will be some time down the road for me.
[00:52:16.000 --> 00:52:22.000]   But yeah, all of these things are intensely personal choices,
[00:52:22.000 --> 00:52:29.000]   and I guess I'm not making any specific prescriptions here to do this, don't do that.
[00:52:29.000 --> 00:52:34.000]   I guess what I would advocate much more heavily for is think about it.
[00:52:34.000 --> 00:52:39.000]   Make a conscious decision. Don't just go with the default of, "Yeah, this is how we do it."
[00:52:39.000 --> 00:52:46.000]   Buying cars, for instance, one of the most invasive—buying homes and cars are two of the most invasive things you can do,
[00:52:46.000 --> 00:52:48.000]   privacy-wise, because there's a credit check.
[00:52:48.000 --> 00:52:56.000]   All this information from Chevrolet or Ford or Nissan is sold to dozens of other parties
[00:52:56.000 --> 00:53:02.000]   who want to sell you extended warranties or refinance your loan or all these other kind of things.
[00:53:02.000 --> 00:53:05.000]   So think about that before you buy a car again.
[00:53:05.000 --> 00:53:11.000]   And I'm kind of a subscriber to the school of thought that a car is kind of a wheelchair.
[00:53:11.000 --> 00:53:17.000]   It doesn't need to be fancy. It gets me from A to B. I will never finance another car.
[00:53:17.000 --> 00:53:22.000]   And there's financial reasons for that, but there's also privacy reasons.
[00:53:22.000 --> 00:53:23.000]   I don't want that paper trail.
[00:53:23.000 --> 00:53:34.000]   I don't want to create this huge bloom of personal data in this kind of field, this well-manicured field that I take great pains with everywhere else.
[00:53:34.000 --> 00:53:39.000]   So think about it. Make a conscious decision before you provide this information.
[00:53:39.000 --> 00:53:41.000]   And that kind of goes for everything.
[00:53:41.000 --> 00:53:44.000]   When you go to Lowe's and buy something and they ask for your phone number,
[00:53:44.000 --> 00:53:51.000]   we're habituated and kind of, I guess for lack of a better word, institutionalized to just spit out the phone number.
[00:53:51.000 --> 00:53:56.000]   But when you're asked for personally identifiable information, think about it.
[00:53:56.000 --> 00:54:02.000]   Ask why am I being asked for this? Is it really necessary for what I'm doing?
[00:54:02.000 --> 00:54:09.000]   And that guides my decisions on a day to day basis, probably much more so than it will for most.
[00:54:09.000 --> 00:54:13.000]   But I guess that would be my overall advice on that.
[00:54:13.000 --> 00:54:16.000]   How do you buy a car and own a car privately?
[00:54:16.000 --> 00:54:21.000]   So. A couple of different ways you can do this.
[00:54:21.000 --> 00:54:25.000]   I pay cash. I paid cash for my last two cars.
[00:54:25.000 --> 00:54:32.000]   And, you know, that that involves some longer term financial planning and, you know, being like kind of fiscally responsible.
[00:54:32.000 --> 00:54:36.000]   And also I'm not driving a brand new Audi.
[00:54:36.000 --> 00:54:40.000]   So I pay cash. That's that's kind of the starting point.
[00:54:40.000 --> 00:54:43.000]   Anytime you're taking a loan, it's going to be very, very invasive.
[00:54:43.000 --> 00:54:47.000]   So there's a couple other ways or a couple other techniques that we can use.
[00:54:47.000 --> 00:54:54.000]   So I am kind of set up on a system where I'm considered a nomad by the state where I claim legal residence.
[00:54:54.000 --> 00:54:58.000]   I don't spend 51 percent of my time in any given state because of my travel schedule.
[00:54:58.000 --> 00:55:01.000]   So I'm I'm legally able to do this.
[00:55:01.000 --> 00:55:08.000]   So I just register my car to this mail drop address where I'm legally considered a resident.
[00:55:08.000 --> 00:55:12.000]   I'm legally kind of in the same place as a full time RV or.
[00:55:12.000 --> 00:55:17.000]   So all my mail goes there and I don't really care because I'm never at that place.
[00:55:17.000 --> 00:55:27.000]   If I were a homeowner and lived in the same place, what I would do instead is purchase the car in the name of a New Mexico LLC.
[00:55:27.000 --> 00:55:39.000]   And these limited liability corporations in New Mexico, New Mexico is one of the very few states that doesn't require that you give the names of the members of the LLC to the state.
[00:55:39.000 --> 00:55:47.000]   So it's completely anonymous, provided you set up your LLC through a service that that kind of understands that.
[00:55:47.000 --> 00:55:50.000]   And I can I can give you the name of one such service.
[00:55:50.000 --> 00:55:52.000]   It's JJ Luna's service.
[00:55:52.000 --> 00:55:57.000]   He's he's very he's kind of the godfather of this extreme personal privacy.
[00:55:57.000 --> 00:55:59.000]   But that's how I purchase my car.
[00:55:59.000 --> 00:56:11.000]   When I go to register it, I would I would just tell the DMV that or are in the year, whatever your state's system is, that I am doing business on behalf of this corporation in the state.
[00:56:11.000 --> 00:56:25.000]   And it's the corporation's car because it is and register it to the corporation rather than to my personal name, because the DMV is most states actually sell the information that you give to the DMV, including your photograph to data marketers.
[00:56:25.000 --> 00:56:33.000]   So that's another place that I'm kind of cautious and we're kind of veering a little bit more into, you know, the the more extreme techniques.
[00:56:33.000 --> 00:56:37.000]   But bring it on. Don't worry. I told you. I told you we're not scared of extreme techniques around here.
[00:56:37.000 --> 00:56:39.000]   The show's called Radical Personal Finance for a reason.
[00:56:39.000 --> 00:56:52.000]   OK, good. Good. But yeah, New Mexico LLC or if you're in a situation like I am, like Florida, for instance, allows you to use a mail, a commercial mail receiving agency.
[00:56:52.000 --> 00:56:57.000]   There's a few select ones that you can use as your permanent home address.
[00:56:57.000 --> 00:57:01.000]   If you live in Florida, it's really easy to set that up and just have all your mail go there.
[00:57:01.000 --> 00:57:05.000]   You log in through their website and then they send you your mail to to wherever you want to get it at.
[00:57:05.000 --> 00:57:10.000]   But that becomes your legally official address. That's where my taxes go to.
[00:57:10.000 --> 00:57:14.000]   That's where my voting stuff goes to. That's where my vehicle registrations go to.
[00:57:14.000 --> 00:57:24.000]   So nothing comes to my home address. It's it's very, very doable and very, very simple, simple to do.
[00:57:24.000 --> 00:57:30.000]   What about. Well, let's go on back to instead of going deeper on the car, let's go to housing.
[00:57:30.000 --> 00:57:39.000]   What suggestions do you have for living and maintaining a more private residence, especially for somebody who has concerns about their public status?
[00:57:39.000 --> 00:57:45.000]   OK, sure. So if you're renting like I do, you absolutely have to stay away from the big apartment complexes.
[00:57:45.000 --> 00:57:49.000]   They they have a flowchart of things they have to do for new renters.
[00:57:49.000 --> 00:58:04.000]   And it's I found it impossible to basically to get them to to bend in their practice of running a credit check, running a renter background check and all these other things that place you at that address.
[00:58:04.000 --> 00:58:10.000]   Because these credit reporting agencies save that data. Yes, this was queried from this apartment complex.
[00:58:10.000 --> 00:58:16.000]   Thus, this is probably where this guy lives. So if you're renting, I would find something on Craigslist.
[00:58:16.000 --> 00:58:23.000]   If you work in a big company, there's probably someone looking to sublet a room or, you know, has a basement apartment or whatever.
[00:58:23.000 --> 00:58:29.000]   But you have to find that individual that's renting out a place. And for those I pay cash again.
[00:58:29.000 --> 00:58:33.000]   I'm sure your audience will have no problem with this. I'm I'm fairly fiscally responsible.
[00:58:33.000 --> 00:58:38.000]   I have some cash in the bank. So when I go to that apartment, you know, find that one.
[00:58:38.000 --> 00:58:42.000]   I want just tell the guy, hey, I'm just going to give you three months rent right now.
[00:58:42.000 --> 00:58:47.000]   I will always stay a month ahead on the rent. And that really talks. People really tend to respect that.
[00:58:47.000 --> 00:58:52.000]   And of course, I'm I'm a good tenant. And I know I'm always you know, I've lived up to my word.
[00:58:52.000 --> 00:58:57.000]   I'm always at least a month ahead on the rent. And he has no issues with that.
[00:58:57.000 --> 00:59:01.000]   And I don't check up on him to make sure he's paying taxes on that, though.
[00:59:01.000 --> 00:59:06.000]   I assume he is. I have no reason to believe he's not. But but he likes getting cash.
[00:59:06.000 --> 00:59:10.000]   I like giving him cash because my name is not tied to that apartment in any way.
[00:59:10.000 --> 00:59:17.000]   And for utilities, I give him a little bit of extra money to keep the utility.
[00:59:17.000 --> 00:59:22.000]   His name and then I make sure those bills are paid on time, so he's not getting any blowback from that.
[00:59:22.000 --> 00:59:25.000]   If I'm buying a house, it becomes a little bit more complicated. So I've got a couple options here.
[00:59:25.000 --> 00:59:29.000]   If I can pay in cash, which is hard for most people to do, it's impossible for me to do right now.
[00:59:29.000 --> 00:59:33.000]   It will be a few years down the road before I'm able to do this.
[00:59:33.000 --> 00:59:40.000]   But if I'm paying for cash for a home in cash, again, I can use the New Mexico LLC option.
[00:59:40.000 --> 00:59:46.000]   There's there's a couple other LLC options, but New Mexico is probably the best one.
[00:59:46.000 --> 00:59:52.000]   Alternatively, if I'm taking out a loan and again, if you're if you're a VA, someone who would use a VA loan,
[00:59:52.000 --> 00:59:58.000]   this does not apply to you, unfortunately. But if I'm taking out a loan, I can put that home in the name of a living trust.
[00:59:58.000 --> 01:00:04.000]   And a lot of people put their homes in trust for estate planning, estate management purposes.
[01:00:04.000 --> 01:00:16.000]   And most people put it name. In the trust, their name or, you know, instead of most people name that trust in their real name.
[01:00:16.000 --> 01:00:22.000]   So if if I were doing this, you know, probably my my tendency would be to name it the Justin Carroll Living Trust,
[01:00:22.000 --> 01:00:28.000]   which doesn't afford me any privacy benefit, but it gives me all those estate planning benefits.
[01:00:28.000 --> 01:00:34.000]   However, if I wanted the privacy, I could name it anything I wanted. I could name it the South Florida Living Trust.
[01:00:34.000 --> 01:00:39.000]   I can name it the one to anything you could want to three Maple Street Living Trust.
[01:00:39.000 --> 01:00:43.000]   Yeah, I can name it anything I wanted. And my name is tied to that.
[01:00:43.000 --> 01:00:49.000]   But if you don't know the name of that living, if you can query that trust directly and look at it, you'll see my name on it.
[01:00:49.000 --> 01:00:55.000]   But you have to know the name of it to find it first. So this is a huge, huge privacy mitigation.
[01:00:55.000 --> 01:01:02.000]   And again, we run into setting up utilities. And in either case, whether I'm purchasing the home in an LLC or a living trust,
[01:01:02.000 --> 01:01:08.000]   I would open up an LLC, a New Mexico LLC, to put those utilities into.
[01:01:08.000 --> 01:01:18.000]   Because if I go to all that trouble to purchase a home privately, I also want to make sure that I'm not tying my name to it with the with the utilities,
[01:01:18.000 --> 01:01:21.000]   because that's going to defeat all the hard work that I've done to that point.
[01:01:21.000 --> 01:01:25.000]   And there will undoubtedly be a few roadblocks here.
[01:01:25.000 --> 01:01:30.000]   You know, if you know any attorneys that specialize in privacy, I would love to talk to them.
[01:01:30.000 --> 01:01:35.000]   But sometimes that can be a challenge. Well, not sometimes.
[01:01:35.000 --> 01:01:44.000]   That is always a challenge, finding an attorney who is really comfortable doing these kind of unconventional techniques and really kind of gets privacy.
[01:01:44.000 --> 01:01:48.000]   And that's unfortunate that that's the case. But it is, sadly.
[01:01:48.000 --> 01:01:55.000]   So, yeah, you've got a couple options there. And, you know, none of them are absolutely perfect.
[01:01:55.000 --> 01:02:08.000]   The New Mexico LLC comes closest. But the living trust still provides just immensely more privacy than you're going to have purchasing a home traditionally,
[01:02:08.000 --> 01:02:14.000]   putting in your name, especially if you're borrowing money to pay for it.
[01:02:14.000 --> 01:02:19.000]   To use another one of the terms that I learned from you, you use the term threat model, right?
[01:02:19.000 --> 01:02:20.000]   Yes.
[01:02:20.000 --> 01:02:25.000]   OK, so how do you define threat model when you use it?
[01:02:25.000 --> 01:02:33.000]   OK, so threat modeling is kind of a tough case by case basis thing and depends greatly on what we're talking about.
[01:02:33.000 --> 01:02:40.000]   And basically the way I'll do this is take a look at who my adversary is, who I'm trying to hide from and then what I look like to them.
[01:02:40.000 --> 01:02:53.000]   So let's say we're talking about email. My threat model for email is is really services like Gmail or just the insipid mass mass surveillance that's going on.
[01:02:53.000 --> 01:02:59.000]   I want to kind of opt out of that stuff. If the NSA wants to look at my stuff, I'm sure they can hack into something and take a look at it specifically.
[01:02:59.000 --> 01:03:04.000]   But that's going to require that they dedicate resources to it and time to it and that sort of thing.
[01:03:04.000 --> 01:03:08.000]   I don't want to be in that just default mass, everything being scooped up.
[01:03:08.000 --> 01:03:14.000]   So my threat model is kind of Google. I want to be out of Google. So and mass surveillance.
[01:03:14.000 --> 01:03:22.000]   So I'm comfortable with proton mail. It doesn't protect me from extreme high level actors, but it protects me from 90 percent of things.
[01:03:22.000 --> 01:03:38.000]   If we're talking about, you know, taking Internet privacy, home privacy, for instance, my threat model is that I don't want someone to be able to look at my type, my name into a Google search beside the words home address and actually find my home address.
[01:03:38.000 --> 01:03:45.000]   I'm not you know, I'm not hiding from the U.S. Marshals. If they were my threat model, I'd probably never rent anything, never buy anything.
[01:03:45.000 --> 01:03:52.000]   I'd probably live in a tent in the woods somewhere and never interact with anyone. They're not my threat model.
[01:03:52.000 --> 01:03:58.000]   So it's kind of defining who you're hiding from or who you're trying to protect your information from.
[01:03:58.000 --> 01:04:02.000]   And of course, in all of these, there are other factors. Hackers are also my threat model.
[01:04:02.000 --> 01:04:14.000]   So if I'm using Wi-Fi at Starbucks, I don't want some kid sitting there with a Wi-Fi antenna to be able to read my email or to capture my login credentials to my bank or whatever else I happen to be logging into.
[01:04:14.000 --> 01:04:23.000]   So those kind of general cyber things are always kind of an implied threat model, I guess, rather than an explicit threat model.
[01:04:23.000 --> 01:04:31.000]   Yeah. And so let me give a couple of to add to that. I really like your language. I've stolen all your language and have applied it in the financial.
[01:04:31.000 --> 01:04:32.000]   Please do.
[01:04:32.000 --> 01:04:46.000]   I do try to give credit. Don't worry. But I try to – but I apply it in the financial planning context, especially when you get into something like the question of asset management, asset protection planning.
[01:04:46.000 --> 01:04:50.000]   And that's where you have different tools for different threat models.
[01:04:50.000 --> 01:05:04.000]   One simple thing is do I have the threat model of my relatives thinking that I am – I have a couple of relatives that are just no good, broke all the time, spend all the money, and I'm doing well financially.
[01:05:04.000 --> 01:05:11.000]   And I want to make sure that I have an ability to have a little bit of concealment around how much money that I actually have.
[01:05:11.000 --> 01:05:24.000]   Well, if I go and buy a personal residence in my name and then I go ahead and buy four or five rental properties and they're all personally owned in my name, then with a simple record search on my local county property appraiser's website, all that information is going to come up.
[01:05:24.000 --> 01:05:30.000]   Or do I want my neighbor who finds out that I'm involved in something to be able to know how many properties that I have?
[01:05:30.000 --> 01:05:45.000]   So something as simple as owning my personal residence in a living trust and something as simple as using an entity of some sort for the ownership of my rental properties and having them segmented and segregated, as you said, adds a tiny little bit of cost.
[01:05:45.000 --> 01:05:47.000]   But it lowers my threat significantly.
[01:05:47.000 --> 01:06:03.000]   That doesn't mean that a private investigator who's been hired to investigate me from – based upon a lawsuit from one of my tenants is not going to be able to find those properties if they're commonly owned and have a common threat of ownership.
[01:06:03.000 --> 01:06:07.000]   It all depends on how much money they have.
[01:06:07.000 --> 01:06:12.000]   I think that you mentioned J.J. Luna and his book How to Be Invisible, which is an excellent book.
[01:06:12.000 --> 01:06:16.000]   I recommend to people. It's kind of a very readable, thoughtful, entry-level discussion.
[01:06:16.000 --> 01:06:26.000]   He gives his different levels of private investigators and he says, "OK, you're talking about a level one investigator, a level two, a level three or a level four because at the end of the day, it costs money."
[01:06:26.000 --> 01:06:37.000]   If you're Osama bin Laden and you're up against the US government, which has an unlimited source of money and an unlimited interest in finding you, it's going to happen at some point.
[01:06:37.000 --> 01:06:41.000]   You're not going to be able to escape that scrutiny.
[01:06:41.000 --> 01:06:43.000]   It's just simply not possible.
[01:06:43.000 --> 01:06:49.000]   No matter what you do in time, you're going to be caught up with because of the fact that you have an unlimited budget.
[01:06:49.000 --> 01:06:51.000]   But your neighbor doesn't have an unlimited budget of time.
[01:06:51.000 --> 01:06:56.000]   And so you can put different levels of protection in place.
[01:06:56.000 --> 01:06:59.000]   Now, if all of a sudden you're a public figure, well, now things change.
[01:06:59.000 --> 01:07:01.000]   Now you take different steps.
[01:07:01.000 --> 01:07:06.000]   Or if threat models will vary depending on what type of planning.
[01:07:06.000 --> 01:07:21.000]   If you're involved in something illegal, all of a sudden now things are very, very different where if you're running a chemical lab, we'll call it in quotations, now you've got to take a completely – stop running a chemical lab would be my plea.
[01:07:21.000 --> 01:07:29.000]   But if you're running a chemical lab, you've got to take a completely different approach because you're not worried about a jilted lover.
[01:07:29.000 --> 01:07:32.000]   You're worried about the US government.
[01:07:32.000 --> 01:07:41.000]   And now you're going to be using a very different approach than just somebody – a young woman protecting herself against a jealous ex-lover.
[01:07:41.000 --> 01:07:47.000]   So at every level, you've got to think practically what am I concerned about because none of us have unlimited funds.
[01:07:47.000 --> 01:07:54.000]   And it's all a matter of how much am I willing to pay to get the privacy and security that is appropriate for me.
[01:07:54.000 --> 01:07:56.000]   Aaron Powell: Absolutely.
[01:07:56.000 --> 01:08:01.000]   And I'm glad you brought up that portion of JJ's book because that's my favorite part of that.
[01:08:01.000 --> 01:08:05.000]   Your level one investigator has a $1,000 budget.
[01:08:05.000 --> 01:08:07.000]   He's really easy to defeat.
[01:08:07.000 --> 01:08:12.000]   But that level three or four with a $100,000 budget, he's going to be really, really hard.
[01:08:12.000 --> 01:08:18.000]   And probably most of us aren't worried about defeating that level four investigator.
[01:08:18.000 --> 01:08:27.000]   And it's going to cost a disproportionate amount of money to hide from him that it is from the level one, two, and three.
[01:08:27.000 --> 01:08:34.000]   And we can do those easy things like tightening up our accounts and pulling back on our Facebook profile and taking some information down off the internet.
[01:08:34.000 --> 01:08:38.000]   And those will solve 90% of your problems.
[01:08:38.000 --> 01:08:47.000]   It's that last 5% or 10% that's going to take the disproportionate amount of effort for those very small incremental gains that are going to build up to that.
[01:08:47.000 --> 01:08:57.000]   I say we're never at 100%, but it's going to build up to that 99th percentile of privacy, I guess, for lack of a better word.
[01:08:57.000 --> 01:08:59.000]   And it's as simple as this.
[01:08:59.000 --> 01:09:05.000]   Two books that I've read I really enjoyed relating to threat model.
[01:09:05.000 --> 01:09:15.000]   Many people have heard the advice about don't write on Facebook when you're going on vacation because people are searching Facebook.
[01:09:15.000 --> 01:09:17.000]   That's not a new thing.
[01:09:17.000 --> 01:09:22.000]   There's a great book written by a guy named Jack McLean called Secrets of a Super Thief.
[01:09:22.000 --> 01:09:24.000]   He wrote it back in the mid '80s when he was in jail.
[01:09:24.000 --> 01:09:35.000]   And he was a famous South Florida cat burglar who claims that he stole – and the police agreed with him – claims that he stole about $130 million of jewels, money, etc.
[01:09:35.000 --> 01:09:39.000]   through thousands of burglaries all throughout South Florida here.
[01:09:39.000 --> 01:09:44.000]   He was eventually caught and in prison he wrote this book called Secrets of a Super Thief.
[01:09:44.000 --> 01:09:48.000]   But he talked about some of his techniques of how he would do these robberies.
[01:09:48.000 --> 01:10:02.000]   Well, a basic thing was going and looking at – if he could look at somebody's mailbox, he would case the house and say, "OK, this house looks like it might be an attractive target," and look at the mailbox number and see the name written on the mailbox number.
[01:10:02.000 --> 01:10:06.000]   That gave him access to go to the white pages and look up the phone number for the person.
[01:10:06.000 --> 01:10:11.000]   And he tells a story about one particular mark where he targeted them.
[01:10:11.000 --> 01:10:20.000]   He called them and on their home answering machine, it said, "We're gone to the Bahamas or to the Caribbean for three weeks.
[01:10:20.000 --> 01:10:22.000]   We'll be back in a couple of weeks."
[01:10:22.000 --> 01:10:31.000]   So, of course, he went right over the next night, robbed the house, enjoyed himself, and he left a little note on their kitchen table saying, "I hope you're not too sunburned from your vacation.
[01:10:31.000 --> 01:10:35.000]   Thank you for helping my financial well-being."
[01:10:35.000 --> 01:10:40.000]   He was a very – he did that kind of thing a lot.
[01:10:40.000 --> 01:10:44.000]   So, that's an old technique told from a guy who robbed a person.
[01:10:44.000 --> 01:10:47.000]   And in hindsight, you look at that and say, "Well, that was dumb."
[01:10:47.000 --> 01:10:54.000]   But yet how many of us check in on Instagram and check in on Facebook and say, "Here I am at such and such.
[01:10:54.000 --> 01:10:58.000]   We're having a great time and we've got to do it all right when we're there."
[01:10:58.000 --> 01:11:03.000]   Well, you can look up – any burglar who's casing your house can look you up in the property tax records.
[01:11:03.000 --> 01:11:05.000]   "Oh, such and such a house is owned by Joshua Sheets.
[01:11:05.000 --> 01:11:07.000]   Let's go on Facebook, Joshua Sheets.
[01:11:07.000 --> 01:11:08.000]   Oh, look.
[01:11:08.000 --> 01:11:09.000]   Joshua Sheets is in South Carolina.
[01:11:09.000 --> 01:11:10.000]   It's safe to go in."
[01:11:10.000 --> 01:11:16.000]   That's a very reasonable, reliable, normal threat model that bears consideration.
[01:11:16.000 --> 01:11:25.000]   Another book I read recently – Justin, have you read the Tom Clancy book recent after his death published last year called True Faith and Allegiance?
[01:11:25.000 --> 01:11:26.000]   No, I haven't.
[01:11:26.000 --> 01:11:27.000]   You should read it.
[01:11:27.000 --> 01:11:29.000]   I'm looking up these books as you mentioned them though.
[01:11:29.000 --> 01:11:30.000]   Okay.
[01:11:30.000 --> 01:11:37.000]   So, this book, True Faith and Allegiance, it was written in the Tom Clancy pen name, but of course he's dead now.
[01:11:37.000 --> 01:11:38.000]   It's part of the Jack Ryan series.
[01:11:38.000 --> 01:11:44.000]   But the basic outline of the book is built on open source intelligence.
[01:11:44.000 --> 01:11:50.000]   And the basic plotline – and I'm not – this is not a spoiler alert.
[01:11:50.000 --> 01:12:11.000]   The basic plotline is that a US government database of all security clearances from many years previous was released through the efforts of a foreign state who their government hacking team had been able to get a hold of the file.
[01:12:11.000 --> 01:12:32.000]   And then a rogue Russian agent or Russian or Ukrainian agent had been able to get access to that file and had used open source intelligence techniques to collate the data with the outdated secret security clearance data and use the names, fast forward, and figure out where these different people were.
[01:12:32.000 --> 01:12:49.000]   And then through the use of the publicly available Facebook information, other open source intelligence techniques that you and Michael Bazell teach had been able to use that information and provide that information as targeting information to terrorist organizations who then took out physical attacks.
[01:12:49.000 --> 01:13:08.000]   And it was absolutely astonishing because with the exception of having the data breach – and this is why that recent data breach of government records to me was so horrifying – with the exception of the original data breach, there was nothing in the plot that was out of my capability.
[01:13:08.000 --> 01:13:10.000]   And I'm not even a technical guy.
[01:13:10.000 --> 01:13:12.000]   And I just – it stunned me.
[01:13:12.000 --> 01:13:13.000]   Go ahead.
[01:13:13.000 --> 01:13:20.000]   If you want this capability for yourself, I can't recommend Michael's open source intelligence techniques book strongly enough.
[01:13:20.000 --> 01:13:28.000]   He truly is a world-renowned expert on this, probably one of the best guys in the world at open source intelligence.
[01:13:28.000 --> 01:13:32.000]   And he documents all his techniques in extreme detail in his book.
[01:13:32.000 --> 01:13:35.000]   I don't make anything from the sale of his books.
[01:13:35.000 --> 01:13:44.000]   But if you do want that skill set or even if you just want to play around with it and see what's really possible, it is such an eye-opener.
[01:13:44.000 --> 01:13:46.000]   It's horrifying.
[01:13:46.000 --> 01:13:50.000]   So I kind of take – forgive me for stealing the interview.
[01:13:50.000 --> 01:13:58.000]   But I see that as a very legitimate concern that doesn't involve my hiding from the US government.
[01:13:58.000 --> 01:14:01.000]   People often immediately go in their thinking to the US government.
[01:14:01.000 --> 01:14:04.000]   That's a real problem because I don't have anything to hide from the US government.
[01:14:04.000 --> 01:14:05.000]   I'm not capable of hiding things.
[01:14:05.000 --> 01:14:14.000]   If I were the subject of attention of a specific focused probe, I don't know that I'm capable of hiding anything from the US government.
[01:14:14.000 --> 01:14:17.000]   That's beyond my skill set and it's beyond my real interest.
[01:14:17.000 --> 01:14:29.000]   But that doesn't mean that I shouldn't be very circumspect about posting on Facebook or on my Twitter account that I'm going on vacation when it's very easy for somebody to find that information.
[01:14:29.000 --> 01:14:30.000]   Absolutely.
[01:14:30.000 --> 01:14:36.000]   And yeah, if the government wants my – the contents of my bank account, they're not going to hack the account.
[01:14:36.000 --> 01:14:40.000]   They're just going to go to the bank and say, "Hey, give us everything you have on this guy."
[01:14:40.000 --> 01:14:44.000]   So yeah, that's not the threat model that I'm working against.
[01:14:44.000 --> 01:14:51.000]   But some of the mitigations I take might make it a little harder for them, but that's not the intent.
[01:14:51.000 --> 01:15:01.000]   So since this is a financial show, if we have a couple more minutes, there are a couple financial things that I'd like to hit if that's all right.
[01:15:01.000 --> 01:15:03.000]   You're turning the conversation exactly where I was going to turn.
[01:15:03.000 --> 01:15:06.000]   I didn't want to miss some of the financial tools, so you go.
[01:15:06.000 --> 01:15:07.000]   Okay, great.
[01:15:07.000 --> 01:15:19.000]   I think probably one of the biggest privacy mitigations that you can do for yourself and your spouse and your children is a security freeze with the credit reporting agencies.
[01:15:19.000 --> 01:15:25.000]   I'm sure you're familiar with this, Joshua, but you call up TransUnion, Equifax, and Experian.
[01:15:25.000 --> 01:15:36.000]   And if you really want to get detailed with it, you can also contact Anovus and Chex Systems at C-E-H-E-X, and I'll make sure you have all these links, and ask for a security freeze.
[01:15:36.000 --> 01:15:47.000]   And this will lock down your credit, and no credit can be taken out in your name without the eight-digit code and identity verification with that agency.
[01:15:47.000 --> 01:15:49.000]   This doesn't expire.
[01:15:49.000 --> 01:15:59.000]   It might cost you $10 depending on the state that you live in, and I'm not going to list those, but some states are free, some they cost $10 per agency, unless you have been the victim of identity theft.
[01:15:59.000 --> 01:16:12.000]   If you've ever been the victim of even very low – had to change a credit card number, for instance, because someone had used your credit card number, you're eligible for free credit freezes or security freezes for life.
[01:16:12.000 --> 01:16:21.000]   So if you do need to take out credit, you go to whoever you're applying for credit with, your mortgage lender, and say, "Who are you going to run my credit through?"
[01:16:21.000 --> 01:16:26.000]   They say TransUnion. You call TransUnion and say, "Hey, lift my freeze for 24 hours."
[01:16:26.000 --> 01:16:29.000]   They run your credit, and then that freeze is back in place.
[01:16:29.000 --> 01:16:39.000]   This will also stop you completely from getting pre-approved credit card offers because those credit companies can't do soft pulls on your credit.
[01:16:39.000 --> 01:16:51.000]   It protects your address because no automatically generated mail like that, junk mail, like those pre-approved offers are automatically being sent to your house because they can't see your credit report.
[01:16:51.000 --> 01:16:53.000]   They can't get your address from that.
[01:16:53.000 --> 01:16:55.000]   It has a million benefits.
[01:16:55.000 --> 01:16:57.000]   It's really easy to implement.
[01:16:57.000 --> 01:17:03.000]   It's probably the best security you can do on your line of credit.
[01:17:03.000 --> 01:17:05.000]   This doesn't protect existing accounts.
[01:17:05.000 --> 01:17:12.000]   If you lose your credit card, obviously that card can still be used until you report it and it's locked down by the bank.
[01:17:12.000 --> 01:17:16.000]   But this is the way it should be, in my opinion.
[01:17:16.000 --> 01:17:20.000]   I don't know why this is not the default, but you have to take action.
[01:17:20.000 --> 01:17:32.000]   If you're the average person and not like me whose bank thinks that I'm dead and all these other problems that I have now, this might take you 10 minutes per credit reporting agency.
[01:17:32.000 --> 01:17:38.000]   Just don't lose that eight-digit code, and your credit is extremely well protected for a very long time.
[01:17:38.000 --> 01:17:43.000]   If there's one thing you take out of the show that's beyond the password two-factor stuff, it is this.
[01:17:43.000 --> 01:17:56.000]   The next thing that I'm a strong proponent of is stop giving the bank information about where you shop, where you eat, where you stop for coffee, how you spend your money, all the elective places your money goes.
[01:17:56.000 --> 01:18:02.000]   I do that through kind of a multi-pronged approach.
[01:18:02.000 --> 01:18:04.000]   First and foremost, I use cash.
[01:18:04.000 --> 01:18:08.000]   I take $300, $400 out at the beginning of the week, and that's how I purchase my fuel.
[01:18:08.000 --> 01:18:10.000]   That's how I pay for coffee.
[01:18:10.000 --> 01:18:11.000]   That's how I pay for lunch.
[01:18:11.000 --> 01:18:17.000]   That's how I buy things when I go to the grocery store or to whatever store I'm buying things from.
[01:18:17.000 --> 01:18:22.000]   I've told this story before, and it's on my blog, and I've probably talked about it on the podcast.
[01:18:22.000 --> 01:18:30.000]   But when I applied for my first home loan, I had to give them three months of statements from every credit and bank account that I had.
[01:18:30.000 --> 01:18:34.000]   I was really shocked to find that if you looked at this, it spelled out.
[01:18:34.000 --> 01:18:52.000]   You could pretty much figure out where I live and where I work based on where I stop for gas and where I get coffee every morning and the restaurants that I routinely go to lunch at and the restaurants that I routinely go to dinner at and kind of the special interests I have based on the stores and activities that I spend money on.
[01:18:52.000 --> 01:19:00.000]   This was really shocking to me, and I decided then and there I'm never going to give the bank that level of insight into my life again.
[01:19:00.000 --> 01:19:03.000]   So that was a strong motivator to start using cash.
[01:19:03.000 --> 01:19:07.000]   So the other thing that I recommend is a service called privacy dot com.
[01:19:07.000 --> 01:19:11.000]   And if you've listened to the show, you're familiar with this.
[01:19:11.000 --> 01:19:12.000]   We interviewed the CEO.
[01:19:12.000 --> 01:19:13.000]   But you set up an account.
[01:19:13.000 --> 01:19:16.000]   You give it access to your bank account.
[01:19:16.000 --> 01:19:19.000]   And then if I need to make an online purchase, obviously, I can't use cash.
[01:19:19.000 --> 01:19:29.000]   So what I do is I log into privacy dot com and I tell privacy, hey, I'm getting ready to set up an Amazon dot com account or I'm getting ready to make a purchase through.
[01:19:29.000 --> 01:19:34.000]   I'm getting ready to set up my bill pay for my electric company.
[01:19:34.000 --> 01:19:39.000]   Give me a unique credit card number to use to pay my electricity bill.
[01:19:39.000 --> 01:19:42.000]   Give me a unique credit card number for this Amazon account.
[01:19:42.000 --> 01:19:52.000]   So it creates a credit card complete with a credit card number, an expiration date and a CCV code.
[01:19:52.000 --> 01:19:58.000]   And I can set up all these other factors like they're all set up as single merchant cards.
[01:19:58.000 --> 01:20:04.000]   So my electric company is the only merchant that can bill to that card.
[01:20:04.000 --> 01:20:07.000]   So if they lose that credit card number, it's worthless to everybody else.
[01:20:07.000 --> 01:20:09.000]   I can also set a limit.
[01:20:09.000 --> 01:20:14.000]   So let's say my electric bill is one hundred and fifty dollars a month.
[01:20:14.000 --> 01:20:19.000]   I set that limit, that firm limit at, let's say, one hundred and sixty just in case.
[01:20:19.000 --> 01:20:26.000]   And they can never draw more than one hundred and sixty dollars per month from that account.
[01:20:26.000 --> 01:20:36.000]   If it's, let's say they do have a breach and that number is stolen, I can go in and delete that card, make a new one, give the electric company a new card and now they can run on that.
[01:20:36.000 --> 01:20:44.000]   If this is a one-off website for I'm going to make one purchase one time ever in my life, I can also make that a, they call it a burner card.
[01:20:44.000 --> 01:20:49.000]   So once that one transaction is made, that card is worthless from then on out.
[01:20:49.000 --> 01:20:52.000]   I don't have to worry about canceling it. It's already canceled.
[01:20:52.000 --> 01:20:55.000]   This is a really strong service and it does a couple of things.
[01:20:55.000 --> 01:21:01.000]   It takes the bank out of the loop because all these charges, they just see it being billed to privacy.com.
[01:21:01.000 --> 01:21:06.000]   They don't see that going out to Amazon or Best Buy.com or any of these other services.
[01:21:06.000 --> 01:21:09.000]   They just see a charge to privacy.com.
[01:21:09.000 --> 01:21:18.000]   All these merchants that I'm buying from also don't see my name because I can give it any name, any shipping address and any billing address that I choose.
[01:21:18.000 --> 01:21:27.000]   So if this is, let's say I'm signing up with an online dating site or something that maybe I'm not super proud of, give it any name I want, give it any address I want.
[01:21:27.000 --> 01:21:33.000]   It doesn't tie back to me. So if that's breached, I'm not really that worried about it because it doesn't come back to me.
[01:21:33.000 --> 01:21:37.000]   You'd have to know what name and address I'd given it.
[01:21:37.000 --> 01:21:40.000]   So this protects me in a bunch of different ways.
[01:21:40.000 --> 01:21:48.000]   And like I said, if any of these services spill their data, I don't really care because I just cancel that card, make a new one, and I haven't lost anything.
[01:21:48.000 --> 01:22:00.000]   This takes my risk from account takeover or data breaches down to virtually nothing as far as financial concerns go.
[01:22:00.000 --> 01:22:02.000]   I love privacy.com.
[01:22:02.000 --> 01:22:10.000]   Yeah, I use it for everything. Any purchase I make online, I have all my auto bill pay things set up to privacy.com.
[01:22:10.000 --> 01:22:15.000]   All my online purchases, I don't ever give out my real credit card number anymore.
[01:22:15.000 --> 01:22:19.000]   And one of my favorite things – you did a great job describing the features.
[01:22:19.000 --> 01:22:25.000]   One of my favorite just philosophical aspects is it puts the user back in control.
[01:22:25.000 --> 01:22:28.000]   I don't like auto billing.
[01:22:28.000 --> 01:22:37.000]   I've faced major financial problems in the past because my appetite exceeded my income, and I would sign up for auto billing on this and that and the other thing.
[01:22:37.000 --> 01:22:49.000]   Unfortunately, in today's world, I work with many merchants who just will not send me a paper bill and will not send me a – they just won't do it.
[01:22:49.000 --> 01:22:54.000]   I can't send them a check. I can't send them something. They require an auto bill pay.
[01:22:54.000 --> 01:22:58.000]   Now, 99.999% of the time, that's fine.
[01:22:58.000 --> 01:23:02.000]   We have an amicable working relationship. Everything works fine.
[01:23:02.000 --> 01:23:06.000]   But still, they're in control. They're in the billing.
[01:23:06.000 --> 01:23:14.000]   And if I need to change something or if I get into a dispute with them, that could mess up many accounts if I need to change card numbers and things like that.
[01:23:14.000 --> 01:23:17.000]   Privacy.com is wonderful because it puts me back in control.
[01:23:17.000 --> 01:23:27.000]   And I can set up a different card with every biller and in a voluntary win-win, voluntary transaction where we're working on agreed terms.
[01:23:27.000 --> 01:23:30.000]   I can pay them. They receive their money. We're all happy.
[01:23:30.000 --> 01:23:39.000]   In a combative hostile situation where we've reached a problem, I'm in control just like I used to be with my choice to send a check or not for payment.
[01:23:39.000 --> 01:23:41.000]   And that to me is how it should be.
[01:23:41.000 --> 01:23:48.000]   The consumer is always in charge and the consumer should have control over the billing, not the vendor.
[01:23:48.000 --> 01:23:51.000]   Absolutely. No question about it.
[01:23:51.000 --> 01:23:58.000]   And privacy.com is kind of founded on a little bit of an ideological mindset.
[01:23:58.000 --> 01:24:06.000]   And the one thing I will warn listeners of is if you sign up for this, you have to give your bank username and password to privacy.com.
[01:24:06.000 --> 01:24:10.000]   And that's scary for a lot of people. Absolutely understandable.
[01:24:10.000 --> 01:24:16.000]   Even I was nervous about it. But like I said, I've spent an hour and a half on the phone with the CEO.
[01:24:16.000 --> 01:24:20.000]   Michael and I interviewed him on the podcast.
[01:24:20.000 --> 01:24:23.000]   I have a really good feeling about where they're coming from.
[01:24:23.000 --> 01:24:26.000]   Their privacy policy is clearly spelled out.
[01:24:26.000 --> 01:24:31.000]   And just one thing to note, the way privacy.com is structured, they are essentially a bank.
[01:24:31.000 --> 01:24:39.000]   So you're protected by all the laws that govern banking and how that information is handled.
[01:24:39.000 --> 01:24:44.000]   And I think they're probably actually doing a much better job at security than most banks are.
[01:24:44.000 --> 01:24:52.000]   Justin, did you know I recently was on a phone call with a coaching client of mine and they told me that Citibank offers this service.
[01:24:52.000 --> 01:24:58.000]   That they offer one-time burner numbers for online transactions. Were you aware of that?
[01:24:58.000 --> 01:25:04.000]   I wasn't aware of Citibank specifically. I know that there are a few banks that will do this.
[01:25:04.000 --> 01:25:08.000]   Do you have it? Have you used this? Do you have any experience with it?
[01:25:08.000 --> 01:25:12.000]   I have not. No. Again, back to my book outline. I need to research other banks that did.
[01:25:12.000 --> 01:25:18.000]   I was not aware that this was being marketed nor used outside of the privacy.com, PseudoPay, etc.
[01:25:18.000 --> 01:25:26.000]   Or other services like that. I knew about those services, but I didn't know that the mainstream credit card companies were starting to offer this service.
[01:25:26.000 --> 01:25:36.000]   So for the complete privacy and security desk reference, Michael and I had this idea that we were going to set up accounts with all these different banks to see what features they had.
[01:25:36.000 --> 01:25:45.000]   And we were kind of aware of that one. But with our credit lockdown the way it is and with my address history as sketchy as it is,
[01:25:45.000 --> 01:25:51.000]   I found very quickly it's really hard for me to open up additional bank accounts. So we backed off that.
[01:25:51.000 --> 01:25:58.000]   But if anyone has used this in practice, you would be teaching me something. I'd be really curious to know how that works in practice.
[01:25:58.000 --> 01:26:03.000]   Email Justin through the website. Your website is yourultimatesecurity.guide, right?
[01:26:03.000 --> 01:26:05.000]   Yes, that's correct.
[01:26:05.000 --> 01:26:09.000]   Okay, so email Justin through his contact form and let him know. And send it to me as well.
[01:26:09.000 --> 01:26:26.000]   Justin, I'm going to test you. I'm interested to know. If you wanted, if you had to set up Privacy.com as anonymously as possible, just a mental exercise, knowing that you were going to give banking information to them.
[01:26:26.000 --> 01:26:35.000]   And I consider this to be a back to threat model, an unreasonable threat model. This is where you're in the criminal world or you're accused of something. How would you do it?
[01:26:35.000 --> 01:26:46.000]   This is tough because Privacy.com is accountable to KYC laws, Know Your Customer laws, which requires that they verify identity.
[01:26:46.000 --> 01:27:01.000]   But the way I might do this is set up an LLC, open up a bank account for that LLC, which, you know, again, we run into the problem of I would have to give my social security number to get the bank account.
[01:27:01.000 --> 01:27:18.000]   But that would create one additional layer. And then I would give, I would try to only give Privacy.com the EIN for that business that I had set up. And I don't know if that would work or not, but it might be worth a try.
[01:27:18.000 --> 01:27:37.000]   All right. The only other idea I had was this would be where you would use a nominee. This would be where you would have to find somebody that you could trust, that you could work with. And that way you have the account disconnected from you and your actual identity. And once it's verified, it might be possible to use that.
[01:27:37.000 --> 01:27:46.000]   Sorry, I always enjoy thinking about these scenarios and thinking, OK, in the most hardcore scenario, how do you figure it out? What's the solution? I just I love the mental game of it.
[01:27:46.000 --> 01:28:01.000]   And, you know, that might be a great place to use a nominee. Say, hey, here's 100 bucks. Set up this account and then hand it over to me because you can you can you can change the password and you can put two factor on it, which would essentially lock that person out.
[01:28:01.000 --> 01:28:23.000]   And if they're like most people, they will probably forget about it in six months and never even remember doing that. But I would always have that concern that that person would would get greedy and call Privacy.com and say, hey, someone's using my name. This is actually my account. And I would run into issues that way.
[01:28:23.000 --> 01:28:42.000]   I think the best betch maybe I don't know what was the quote that's attributed to Ben Franklin. Two can keep a secret. Sorry, three. Three can keep a secret of two are dead. Right. That's always how it is. And that's why a crime doesn't pay. That's where all these things it's always going to be somebody usually who who exposes something.
[01:28:42.000 --> 01:28:58.000]   Yeah. And I do want to make clear that nothing in our book like both Michael and I are closely affiliated with the US government. We don't advocate this for any type of criminal activity. And I know that you don't either. But we do enjoy some some thought experiments from time to time.
[01:28:58.000 --> 01:29:26.000]   Exactly. Point well taken. It's just fun to sit down and think about it sometimes. It is. Yeah. I'm so glad you went through that. Last question I would ask you. I mentioned a couple of the other services, the other two competitors, and maybe there are more as well. And I'd love to see more come on the market. But privacy, I think, is privacy is fantastic. There's also PseudoPay, which is an app on the phone and Blur, which is from the company Abine. Is that how you say their name?
[01:29:26.000 --> 01:29:28.000]   Abine. Yeah.
[01:29:28.000 --> 01:29:34.000]   Yeah. Something like that. So how do you mention those services as well in case people would like some options and compare and contrast them, please?
[01:29:34.000 --> 01:29:58.000]   OK, sure. So PseudoPay is an iOS app, and I'll circle back around to this one at the end because their Pseudo app is really fantastic as well. PseudoPay does not require any money to set up an account. You install the app, set up your account, and it draws funds from your Apple Pay account. And much like privacy, it will make one time use credit cards.
[01:29:58.000 --> 01:30:12.000]   And your charges, credit cards and debit cards, are two completely different things in the banking world, I've learned. And you are charged a small fee for each one of these make, and it's based on a percentage of how much money is on the credit card.
[01:30:12.000 --> 01:30:27.000]   But I really do like this because of the convenience of it. As an example, I visited New York City this summer and, you know, kind of at the spur of the moment, we decided to go to the top of the rock, which you have to buy tickets online.
[01:30:27.000 --> 01:30:45.000]   And I, you know, obviously it wasn't at my computer. We were already downtown and I just pulled out my phone, opened up PseudoPay and created a credit card. And I had a card right there to pay for those tickets online. Really, really convenient. It's another option in the toolbox.
[01:30:45.000 --> 01:31:02.000]   Blur is the other one. It requires that you set up an account. And currently, right now, they are offering lifetime accounts for $119. Blur lets you set up one time credit cards. Also, there's also a small fee for each one that you set up. Blur also has a ton of other features.
[01:31:02.000 --> 01:31:22.000]   It gives you a masked phone number, which will forward calls and texts to your real phone number if you so choose. It also has masked email addresses, which I use every single day. And I use these to set up unique usernames on accounts that require an email address, and they all forward into my regular ProtonMail inbox.
[01:31:22.000 --> 01:31:43.000]   So, set up ProtonMail as the account that those go to. And then I give out these. I make unique email addresses for absolutely everything through Blur. Give those out and they're forwarded right into my regular inbox. Super easy. So, that's also another option. And then I mentioned PseudoPay. Their Pseudo app...
[01:31:43.000 --> 01:31:49.000]   By the way, Pseudo is S-U-D-O, not P-S-E-U-D-O. S-U-D-O, PseudoPay.
[01:31:49.000 --> 01:32:09.000]   Yes, good call. But the Pseudo app, man, this thing is a game changer for me. It gives you nine Pseudos, again, S-U-D-O, but nine Pseudo identities, each with its own email address and phone number. So, you have nine phone numbers that will forward to your phone.
[01:32:09.000 --> 01:32:28.000]   And, man, I can't recommend this strongly enough, because here's how I kind of use that. I have one that is for my financial stuff. It's for my bank account, my Coinbase account, any kind of accounts that deal with money that would cost me money financially if those accounts are breached. And there's a reason I do that.
[01:32:28.000 --> 01:32:47.000]   If you breach my Facebook account, which I don't have Facebook, but I realize most people do, if you breach my Facebook account, you're going to have my phone number, which means you're probably going to have the phone number that I verify my bank transactions with. So, I can just take that completely out of the loop, put those bank accounts on their own phone number. That's the only people that get that number.
[01:32:47.000 --> 01:33:00.000]   And then I can have another number just for those two-factor authentication codes with my accounts, my online accounts that send SMS messages. So, yeah, you can hack my cell phone account. It doesn't really matter, because those go to a Pseudo number.
[01:33:00.000 --> 01:33:25.000]   And this just gives you, man, I can't overstate the flexibility of having these different phone numbers, because your phone number these days is literally more valuable than a social security number as far as your identity goes, because we use it to set up all our online accounts, and we use it for verification and all these other things. If I have your phone number, man, I know a lot of information about you.
[01:33:25.000 --> 01:33:41.000]   It's huge. And I can't add any more. I'm thinking about resources to share with the audience as far as people who are new to the subject and some of the news reports that have been done, some of the just different information.
[01:33:41.000 --> 01:34:03.000]   But the phone number is hugely – I have learned and been remiss in the past about how important that little piece of data is. And it's important. And just little things. So, you can use Pseudo. I recommend it to people to start with some simple things like Craigslist transactions.
[01:34:03.000 --> 01:34:21.000]   I recently sold my motorhome on Craigslist. And the transaction – I thought everything went great. Then all of a sudden, everything went bad. And it exposed me afresh. I ended up having to call the police when interacting with the buyer on my transaction.
[01:34:21.000 --> 01:34:35.000]   And so I started asking him about Craigslist fraud. And he started telling me stories about – the police officer started telling me stories about different – just different times of Craigslist fraud and crimes that have been committed and different things.
[01:34:35.000 --> 01:34:49.000]   And just a simple step of using an additional phone number – and there are others. There are burner apps in the app store, et cetera. Pseudo is really beautiful because it integrates phone calls, texting, and email all in one place.
[01:34:49.000 --> 01:35:05.000]   But using something like an additional outside number and then taking just a simple set of – simple step of meeting in a third-party location, et cetera, for safety is more important than I ever thought it was.
[01:35:05.000 --> 01:35:17.000]   And especially when you start layering on – I mean I have the unique advantage of being six and a half feet tall and over 300 pounds. So I'm not the most necessarily attractive rape target.
[01:35:17.000 --> 01:35:28.000]   But for a young lady – for a young woman especially who faces danger there with giving out a phone number, it provides an additional very important layer of privacy and protection.
[01:35:28.000 --> 01:35:38.000]   So my daughter is too young at this point to thankfully need to be concerned about that. But I think that's very important for parents to be educated – kids probably already know.
[01:35:38.000 --> 01:35:44.000]   But parents to be educating and encouraging people to protect themselves. It's very important.
[01:35:44.000 --> 01:35:52.000]   And I'm sure most people won't do it this way, but I don't even know the actual phone number that's on my phone because all I use are pseudo numbers.
[01:35:52.000 --> 01:35:57.000]   I have one that's for friends and family, one that's for – like I said, finances, one that's for online purchases.
[01:35:57.000 --> 01:36:10.000]   And I've seen time and time and time again cell phone companies breached. And these can be small things like a social engineer calling in to get into my account.
[01:36:10.000 --> 01:36:18.000]   Or it can be big things like T-Mobile dumping millions of records. And I just don't want that information out there.
[01:36:18.000 --> 01:36:24.000]   And I guess what I would challenge most people to do is download the app and start moving some of your important stuff over to pseudo.
[01:36:24.000 --> 01:36:30.000]   And again, like Authy, there's also the option to set up a backup username and password.
[01:36:30.000 --> 01:36:39.000]   So if you do lose your phone, you can install pseudo on your new phone, log in with that username and password, and you don't lose all those phone numbers.
[01:36:39.000 --> 01:36:53.000]   That was the thing I was worried about when this initially came out. I didn't want to run the risk of setting up all my numbers on pseudo and then having a catastrophic failure and being – all of a sudden not having access to any of my numbers.
[01:36:53.000 --> 01:36:57.000]   So all of the stuff you should be making good backups of.
[01:36:57.000 --> 01:37:02.000]   And like most things, it's a skill set. Using these things, learning how they work, it's a skill set.
[01:37:02.000 --> 01:37:19.000]   But as we kind of start to wrap up here, Justin, when it comes to privacy/security, which obviously they go together, it seems to me that we in some ways have a double-edged – the sword cuts both ways.
[01:37:19.000 --> 01:37:25.000]   In some ways, it's harder today than it's ever been to maintain privacy and security.
[01:37:25.000 --> 01:37:41.000]   I mean the New York customer laws in the wake of the Patriot Act just destroyed so much ability to bank and to engage in any kind of private financial transactions.
[01:37:41.000 --> 01:37:43.000]   I mean it turned the financial world upside down.
[01:37:43.000 --> 01:37:47.000]   The ability to travel privately was just turned upside down.
[01:37:47.000 --> 01:37:56.000]   I have real concerns about the – things like the Real ID – what's the word for it?
[01:37:56.000 --> 01:37:57.000]   Initiatives.
[01:37:57.000 --> 01:38:01.000]   Yeah, initiatives. The Real ID initiatives all across the country.
[01:38:01.000 --> 01:38:18.000]   So in many ways, the noose has tightened in ways that are – would be inconceivable. Just the existence of a passport, the fact that you have to have a passport to go across and travel across land is, in my mind, utterly indefensible.
[01:38:18.000 --> 01:38:23.000]   Now, that – I don't know – I know of almost nobody who would believe that.
[01:38:23.000 --> 01:38:30.000]   In today's world, you have the majority of people who want to put up a massive wall across every border and say no and control the movement of each and every person.
[01:38:30.000 --> 01:38:33.000]   So philosophically, that's a huge philosophical thing.
[01:38:33.000 --> 01:38:36.000]   But for many years, you didn't need a passport. You didn't need papers.
[01:38:36.000 --> 01:38:52.000]   And so it's very easy to draw the conclusion that the classic line of "your papers please" is something that most of us here are so accustomed and trained to hear as normal that we don't even think about it.
[01:38:52.000 --> 01:38:57.000]   So the sword cuts against it that it's harder than it's ever been.
[01:38:57.000 --> 01:39:03.000]   On the flip side, we haven't talked about cryptocurrency. You mentioned Coinbase. Obviously, that's a cryptocurrency.
[01:39:03.000 --> 01:39:08.000]   We haven't talked about – I mean we're missing a dozen things that we could list off.
[01:39:08.000 --> 01:39:14.000]   But when you have all of these apps and you look at it in a different way, pseudo is a game-changer.
[01:39:14.000 --> 01:39:18.000]   All of these things, encrypted messaging apps, all of these things are complete game-changers.
[01:39:18.000 --> 01:39:32.000]   And so on the flip side, I look at it and say in many ways, it's easier than it's ever been to live privately, communicate privately, maintain a greater sense of security.
[01:39:32.000 --> 01:39:39.000]   So it seems like we live in this very challenging and strange world where the sword cuts both ways.
[01:39:39.000 --> 01:39:48.000]   It is an uphill battle and we have all these tools that make it easier.
[01:39:48.000 --> 01:39:53.000]   Like you said, we're totally habituated to just give out the data when we're asked.
[01:39:53.000 --> 01:40:10.000]   I mean we could go into a huge philosophical thing about this, but that is the default mode and the default mentality and the default way we do business is just to give out what we're asked for.
[01:40:10.000 --> 01:40:16.000]   And living differently, living privately is a deliberate effort.
[01:40:16.000 --> 01:40:23.000]   It's not as simple as get a privacy.com account and a pseudo account and all of a sudden you're private.
[01:40:23.000 --> 01:40:25.000]   It is a very deliberate decision.
[01:40:25.000 --> 01:40:31.000]   It requires behavioral modifications, which quite honestly I think are much more important than the technology.
[01:40:31.000 --> 01:40:34.000]   The technology helps, it supports that.
[01:40:34.000 --> 01:40:39.000]   But you've several times said it's a skill set that you have to practice.
[01:40:39.000 --> 01:40:40.000]   And that's absolutely right.
[01:40:40.000 --> 01:40:42.000]   It is something that you have to do.
[01:40:42.000 --> 01:40:47.000]   And I'm constantly telling military students, implement this into your daily life.
[01:40:47.000 --> 01:40:57.000]   Don't wait until eight months from now when you're about to deploy to all of a sudden set all this up on the laptop and the phone that you're deploying with.
[01:40:57.000 --> 01:41:01.000]   Start living this from day to day and it's second nature when you get there.
[01:41:01.000 --> 01:41:07.000]   And kind of the same thing applies in the, you know, just in the citizen, the private citizen space.
[01:41:07.000 --> 01:41:16.000]   This is a, you know, to greater or lesser extent, a bit of a lifestyle and you can make it, you know, kind of the focal point of your lifestyle like Michael and I have.
[01:41:16.000 --> 01:41:19.000]   Or it can be, you know, one of the many things.
[01:41:19.000 --> 01:41:26.000]   Everyone is a multifaceted individual and it can, you know, it can take greater or lesser prominence in your life, but it does require that you think about it.
[01:41:26.000 --> 01:41:31.000]   It's not as simple as setting up an account, downloading an app and boom, you're private.
[01:41:31.000 --> 01:41:33.000]   Absolutely.
[01:41:33.000 --> 01:41:39.000]   And, you know, we could, Michael and I talk, you know, spend an hour every week talking about this.
[01:41:39.000 --> 01:41:42.000]   So I feel like there's a ton we're leaving out.
[01:41:42.000 --> 01:41:49.000]   I'm just looking at my notes or at an hour and 40 minutes and I'm looking at my notes thinking about we didn't cover just even financial.
[01:41:49.000 --> 01:41:50.000]   We didn't cover cryptocurrencies.
[01:41:50.000 --> 01:41:54.000]   We didn't cover, you know, prepaid debit cards.
[01:41:54.000 --> 01:41:55.000]   We didn't cover money orders.
[01:41:55.000 --> 01:41:58.000]   We didn't cover almost all of these other tools that could be used.
[01:41:58.000 --> 01:42:04.000]   But I think we're at a point where it's a good wrap up, a good wrap up point.
[01:42:04.000 --> 01:42:09.000]   Just looking at my notes here.
[01:42:09.000 --> 01:42:13.000]   We also didn't cover data security.
[01:42:13.000 --> 01:42:16.000]   And, you know what, Michael, I might actually like to have you back on.
[01:42:16.000 --> 01:42:28.000]   I'm very much looking forward to your volume two of the Complete Privacy and Security Desk Reference, which as I understand it is going to be related to physical security.
[01:42:28.000 --> 01:42:36.000]   Because I've come to learn from reading your blog that you're a bit of a security nerd, especially with weird things like locks.
[01:42:36.000 --> 01:42:44.000]   So I'm excited because it seems like you're more excited about locks sometimes than you are about full disk encryption.
[01:42:44.000 --> 01:42:55.000]   Yeah. And that, you know, a little bit that's a product of when, you know, my head is in encrypted apps and encrypting messengers and encryption protocols and all this all the time.
[01:42:55.000 --> 01:43:01.000]   It's nice to have like some grounding in the physical world and do something a little different kind of fun.
[01:43:01.000 --> 01:43:10.000]   And part of that comes from a significant portion of my background that can't go into in too much detail.
[01:43:10.000 --> 01:43:13.000]   But I have a lot of familiarity with locks and how they're defeated.
[01:43:13.000 --> 01:43:22.000]   So it does get me excited to run across some super rare, obscure, high security lock in Seattle or New York or wherever.
[01:43:22.000 --> 01:43:31.000]   Yeah. And so maybe in the future, let's line it up with your Put Me on Your Book promotion tour when you launch volume two.
[01:43:31.000 --> 01:43:36.000]   Let's have you back to talk about physical security because I've learned all kinds of other interesting things.
[01:43:36.000 --> 01:43:45.000]   You've almost convinced me to start flying with a firearm based upon your blog post about that.
[01:43:45.000 --> 01:43:51.000]   That's an interesting context. Obviously, sometimes it adds more hassle, but you go ahead and just describe the outline of that.
[01:43:51.000 --> 01:44:00.000]   I thought that was such an interesting idea from a physical security perspective that you seem to many times choose to travel with a firearm so that you can maintain security over your baggage.
[01:44:00.000 --> 01:44:11.000]   Yeah. Traveling with a firearm. If there's a firearm in your baggage and there's a little bit of nuance, maybe misunderstanding about this,
[01:44:11.000 --> 01:44:17.000]   but you can travel with a firearm in your checked luggage, provided that you meet a few criteria.
[01:44:17.000 --> 01:44:20.000]   It has to be in a hard case. It has to be unloaded.
[01:44:20.000 --> 01:44:26.000]   You may have to demonstrate that it's unloaded to the airline agent or the TSA agent or both sometimes.
[01:44:26.000 --> 01:44:30.000]   But what this does is it lets you lock your luggage up.
[01:44:30.000 --> 01:44:34.000]   So if you have a hard sided suitcase that will take a padlock, you can throw a padlock on there.
[01:44:34.000 --> 01:44:38.000]   And per the letter of the law, it cannot be a TSA approved padlock.
[01:44:38.000 --> 01:44:42.000]   So you can use a very good, very high quality lock.
[01:44:42.000 --> 01:44:47.000]   And I do this because I frequently travel with things like 12 iPhones.
[01:44:47.000 --> 01:44:54.000]   If I'm going to a class where the students have specifically asked and purchased iPhones and want instruction on those phones,
[01:44:54.000 --> 01:45:00.000]   I don't want the opportunity for a TSA agent to open my bag up, say, hey, there's a ton of iPhones in here.
[01:45:00.000 --> 01:45:05.000]   He's probably not going to miss one and, you know, throw one in their lunchbox.
[01:45:05.000 --> 01:45:10.000]   So if you if you don't own firearms or uncomfortable firearms, but you're still interested in this,
[01:45:10.000 --> 01:45:18.000]   you can travel with a couple of other items that will let you lock your suitcase because they're legally considered firearms like flare guns,
[01:45:18.000 --> 01:45:25.000]   which you can purchase very inexpensively or blank firing starter pistols, which will not fire real ammunition.
[01:45:25.000 --> 01:45:30.000]   But they're still treated by fire as firearms by the airlines and by the Transportation Security Administration.
[01:45:30.000 --> 01:45:38.000]   So it's I'm excited that at least one person has actually read those blog posts.
[01:45:38.000 --> 01:45:46.000]   I love I love those little ideas because, again, back to the way, OK, you can travel with a flare gun and you check the local edges,
[01:45:46.000 --> 01:45:53.000]   the local restriction, perhaps the you know, perhaps you might not want to carry a 357 in the local area based upon local firearms laws,
[01:45:53.000 --> 01:46:02.000]   but you can do something. And just the ability to know how to secure your luggage when traveling brings back a little bit more control to somebody.
[01:46:02.000 --> 01:46:09.000]   Now, most of the time I don't travel with 12 iPhones. And my philosophy is there are two kinds of luggage.
[01:46:09.000 --> 01:46:15.000]   There's carry on. Sorry, there's carry on and lost. So but there's a place you need to check a bag.
[01:46:15.000 --> 01:46:21.000]   And so it's really useful. So I'd love to have you back on when you publish volume two of the of the security desk reference.
[01:46:21.000 --> 01:46:28.000]   I'll give to my to just wrap up points and just give you the last word and also make sure you go down the listings of your sites,
[01:46:28.000 --> 01:46:36.000]   your podcasts and all of your materials to promote. And I'll give a wholehearted, unqualified endorsement of the power of your book,
[01:46:36.000 --> 01:46:41.000]   the complete privacy and security desk reference. I think it's about 40 bucks, but a 40 dollar book.
[01:46:41.000 --> 01:46:47.000]   Well spent. I was so impressed with it. But philosophically, we've covered a lot of things.
[01:46:47.000 --> 01:46:54.000]   And my closing commentary would be it's important to start building the skill set and thinking about it.
[01:46:54.000 --> 01:47:06.000]   And there are two very important reasons why. Number one, you don't know in advance what circumstance you might face in the future due to no fault of your own.
[01:47:06.000 --> 01:47:13.000]   Recently on Radical Personal Finance, I've released various episodes on law enforcement, how to interact with law enforcement agents and how to protect yourself.
[01:47:13.000 --> 01:47:24.000]   Every day I see news stories and every single day, the control and the ability of all of the financial information becomes much, much more significant.
[01:47:24.000 --> 01:47:42.000]   And you can't protect it after the fact. Just last week, there was a horrifying story about a student who was arraigned, indicted for murder or for manslaughter at the very least in association with just awful fraternity hazing incident.
[01:47:42.000 --> 01:48:03.000]   And I was interested to read as part of the court proceedings that part of the evidence that the grand jury considered in bringing the charges against him was the fact that he had, number one, had there been communication between him and some of the other people, some of the other fraternity members involved about the situation.
[01:48:03.000 --> 01:48:09.000]   And number two, that he had his Google searches, Google searches on what to do with alcohol poisoning.
[01:48:09.000 --> 01:48:14.000]   Well, those material pieces of evidence were brought against him in terms of the bringing of the charges.
[01:48:14.000 --> 01:48:21.000]   Now, what they did was horrible and all of us want to live in a well-ordered society in which people are held accountable for their crimes.
[01:48:21.000 --> 01:48:27.000]   But, which leads me to the second point, you can't always know in advance what's actually going to be a crime.
[01:48:27.000 --> 01:48:37.000]   And laws change. Number one, there are plenty of laws out there and there are plenty of agents who are trying – I use the term agents to mean just people, not government agents.
[01:48:37.000 --> 01:48:43.000]   But there are people who are seeking to target you and you can't know in advance what the laws are going to be 20 years from now.
[01:48:43.000 --> 01:48:46.000]   But what you do today is going to have an aspect on it.
[01:48:46.000 --> 01:48:59.000]   Whether it's the most simple common advice as what you put on Facebook is going to be seen by a future potential employer or it's the fact that every single one of your Google searches is going to be saved and can be brought against you in a grand jury investigation.
[01:48:59.000 --> 01:49:04.000]   You've got to take steps in advance before you ever need it because if you ever need it, it's too late.
[01:49:04.000 --> 01:49:09.000]   So, Justin, finish us up with closing thoughts and walk through your resources please.
[01:49:09.000 --> 01:49:20.000]   Absolutely. There are 27,000 pages of federal laws and an estimated another 100,000 pages of federal civil statutes.
[01:49:20.000 --> 01:49:27.000]   And a lot of times we're breaking a law and don't even know it. And a lot of these laws are enforced with a great deal of discretion.
[01:49:27.000 --> 01:49:32.000]   So, like you said, a lot of people are like, "Oh, I'm never going to be in that situation."
[01:49:32.000 --> 01:49:41.000]   But the fact is you don't know. And when you find yourself in that situation, if you find yourself in that situation, it's too late to go back and do this legwork.
[01:49:41.000 --> 01:49:43.000]   You have to do it now.
[01:49:43.000 --> 01:49:46.000]   Excuse me. You have to do it now.
[01:49:46.000 --> 01:49:52.000]   So you can find out more about me on your ultimate security dot guide. My blog is contained there.
[01:49:52.000 --> 01:49:57.000]   The book is the Complete Privacy and Security Desk Reference Volume One Digital.
[01:49:57.000 --> 01:50:00.000]   That's by me and Michael Basil.
[01:50:00.000 --> 01:50:05.000]   If you want to check out Michael's site, it is privacy-training.com.
[01:50:05.000 --> 01:50:12.000]   And, of course, you can download our podcast, the Complete Privacy and Security Podcast, wherever you get your podcasts.
[01:50:12.000 --> 01:50:19.000]   Josh, Joshua, thank you so much for being so generous with your time. This was truly a pleasure.
[01:50:19.000 --> 01:50:24.000]   And I will definitely look forward to being back on once Volume Two is out.
[01:50:24.000 --> 01:50:26.000]   Absolutely. Thanks for coming on.
[01:50:26.000 --> 01:50:28.000]   Yes. Thank you.
[01:50:28.000 --> 01:50:33.000]   This show is part of the Radical Life Media network of podcasts and resources.
[01:50:33.000 --> 01:50:37.000]   Find out more at RadicalLifeMedia.com.
[01:50:38.000 --> 01:50:40.000]   Struggling with your electric bill?
[01:50:40.000 --> 01:50:43.000]   Get an energy assist from SDG&E and SAFE.
[01:50:43.000 --> 01:50:46.000]   You may qualify for an 18% discount.
[01:50:46.000 --> 01:50:52.000]   Visit SDGE.com/FERA to find out more.

