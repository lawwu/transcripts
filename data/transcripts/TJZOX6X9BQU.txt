
[00:00:00.000 --> 00:00:04.680]   - What was your mindset around the time
[00:00:04.680 --> 00:00:08.720]   that you wrote "4-Hour Body", "4-Hour Workweek",
[00:00:08.720 --> 00:00:10.180]   but in particular "4-Hour Body",
[00:00:10.180 --> 00:00:14.120]   because the protocols in that book are so very useful.
[00:00:14.120 --> 00:00:17.120]   They were at the time it was published, they still are now.
[00:00:17.120 --> 00:00:20.560]   And so many of the things like ice baths,
[00:00:20.560 --> 00:00:24.080]   the discussion around brown fat thermogenesis,
[00:00:24.080 --> 00:00:27.200]   resistance training in its, you know,
[00:00:27.200 --> 00:00:30.080]   kind of basic form of just providing enough
[00:00:30.080 --> 00:00:32.040]   progressive overload to get an adaptation,
[00:00:32.040 --> 00:00:34.000]   not excessively long workouts,
[00:00:34.000 --> 00:00:38.440]   weight loss, slow carb diet, and on, and on, and on.
[00:00:38.440 --> 00:00:40.400]   What were you thinking at that time?
[00:00:40.400 --> 00:00:42.640]   Like, if you can think back to then,
[00:00:42.640 --> 00:00:45.120]   like what were you foraging for?
[00:00:45.120 --> 00:00:46.440]   What were you thinking about when you woke up
[00:00:46.440 --> 00:00:47.760]   in the morning thinking, oh, I'm gonna go find
[00:00:47.760 --> 00:00:50.520]   all this stuff that at the time was really esoteric,
[00:00:50.520 --> 00:00:53.560]   'cause it is all played out very well.
[00:00:53.560 --> 00:00:56.160]   What I'm basically saying is if you want to know
[00:00:56.160 --> 00:00:59.240]   what's going to be happening hot and useful
[00:00:59.240 --> 00:01:01.480]   in five years, 10 years, and onwards,
[00:01:01.480 --> 00:01:03.960]   just look at what Tim's doing at any moment.
[00:01:03.960 --> 00:01:05.960]   So there it is.
[00:01:05.960 --> 00:01:09.360]   - Well, thank you for the very generous comparison
[00:01:09.360 --> 00:01:10.200]   and intro.
[00:01:10.200 --> 00:01:12.560]   I'm thrilled to be here, so thanks for having me.
[00:01:12.560 --> 00:01:16.720]   And the "4-Hour Body" represented an opportunity
[00:01:16.720 --> 00:01:17.680]   for me to do a few things.
[00:01:17.680 --> 00:01:20.600]   The first was to diversify my identity
[00:01:20.600 --> 00:01:24.180]   from outside of the realm of the, say, business category.
[00:01:24.180 --> 00:01:26.440]   So it was a deliberate move since the success
[00:01:26.440 --> 00:01:29.480]   of the first book bought me permission
[00:01:29.480 --> 00:01:30.920]   to do something else that publishers
[00:01:30.920 --> 00:01:32.840]   would still want to gamble on.
[00:01:32.840 --> 00:01:36.000]   I wanted to see if I could, maybe like a Michael Lewis,
[00:01:36.000 --> 00:01:38.280]   take my audience with me to other topics.
[00:01:38.280 --> 00:01:40.720]   So that was a lateral move that was very deliberate
[00:01:40.720 --> 00:01:43.680]   from a career optionality standpoint.
[00:01:43.680 --> 00:01:46.320]   And then I was doing, I think, what I've done
[00:01:46.320 --> 00:01:48.320]   for a very long time and what I enjoy doing,
[00:01:48.320 --> 00:01:53.320]   which is looking at the most prevalent beliefs
[00:01:54.120 --> 00:01:56.720]   and maybe dogmatic assumptions in a given field.
[00:01:56.720 --> 00:01:58.900]   Could be anything.
[00:01:58.900 --> 00:02:02.080]   If anyone says always, never, should,
[00:02:02.080 --> 00:02:04.400]   I pay attention and take note of that.
[00:02:04.400 --> 00:02:06.000]   They may very well be right.
[00:02:06.000 --> 00:02:08.880]   But if anything is said in absolutes,
[00:02:08.880 --> 00:02:10.680]   I like to stress test.
[00:02:10.680 --> 00:02:13.420]   And in the case of, say, physical performance
[00:02:13.420 --> 00:02:17.040]   or physical manipulation, tracking,
[00:02:17.040 --> 00:02:20.780]   2008, 2009 was a very interesting time
[00:02:20.780 --> 00:02:23.780]   because a number of different technologies
[00:02:23.780 --> 00:02:28.140]   were coming online, meaning being adopted by small groups.
[00:02:28.140 --> 00:02:30.020]   You had the very early stages of, say,
[00:02:30.020 --> 00:02:32.900]   accelerometers as wearables.
[00:02:32.900 --> 00:02:35.880]   You had a number of different innovations
[00:02:35.880 --> 00:02:40.140]   and means of tracking that had never been available before.
[00:02:40.140 --> 00:02:43.540]   You had, for instance, and this took a bit of ferreting
[00:02:43.540 --> 00:02:45.700]   on my side, it wasn't immediately on the roadmap
[00:02:45.700 --> 00:02:48.460]   for the Firebody, but continuous glucose monitors.
[00:02:49.340 --> 00:02:53.380]   At the time, that was, I want to say,
[00:02:53.380 --> 00:02:55.860]   exclusively limited to type one diabetics
[00:02:55.860 --> 00:02:59.140]   or maybe type two diabetics, but largely type one diabetics.
[00:02:59.140 --> 00:03:01.540]   And what captured my interest,
[00:03:01.540 --> 00:03:03.300]   and I can't recall how I came across it,
[00:03:03.300 --> 00:03:07.220]   but it was probably through the very earliest iterations
[00:03:07.220 --> 00:03:09.980]   of what later became the quantified self movement.
[00:03:09.980 --> 00:03:12.040]   And I remember attending the very first gathering
[00:03:12.040 --> 00:03:15.460]   at Kevin Kelly's house in Pacifica, California.
[00:03:15.460 --> 00:03:20.460]   This was around 2009, 12 people, 13 people
[00:03:20.460 --> 00:03:22.700]   to discuss quantifying health.
[00:03:22.700 --> 00:03:27.700]   But the example of a professional race car driver,
[00:03:27.700 --> 00:03:29.340]   I can't remember the form factor,
[00:03:29.340 --> 00:03:31.620]   whether it was F1 or NASCAR or other,
[00:03:31.620 --> 00:03:34.420]   who was using this continual glucose monitor
[00:03:34.420 --> 00:03:39.420]   for paying attention to glucose levels while driving.
[00:03:39.420 --> 00:03:42.300]   And I thought to myself,
[00:03:42.300 --> 00:03:46.020]   would that not be useful for healthy normals?
[00:03:46.020 --> 00:03:48.060]   Would that not have other applications?
[00:03:48.060 --> 00:03:49.700]   If this is being used by a high performer
[00:03:49.700 --> 00:03:51.300]   in this type of context,
[00:03:51.300 --> 00:03:53.560]   might it have other types of applications?
[00:03:53.560 --> 00:03:58.260]   Which then led me to use the very early versions of Dexcom,
[00:03:58.260 --> 00:03:59.820]   which were really painful to implant.
[00:03:59.820 --> 00:04:02.700]   No longer the case, of course that's changed a lot.
[00:04:02.700 --> 00:04:07.260]   And I wanted to see how I might be able to find
[00:04:07.260 --> 00:04:09.800]   a handful of different categories of things.
[00:04:09.800 --> 00:04:11.980]   There's the new, like the genuinely new,
[00:04:11.980 --> 00:04:15.060]   like CGM at that point was genuinely new.
[00:04:15.060 --> 00:04:20.060]   The very old that might have some room
[00:04:20.060 --> 00:04:23.060]   for scientific investigation.
[00:04:23.060 --> 00:04:24.900]   And I would say, when I say scientific,
[00:04:24.900 --> 00:04:28.140]   I don't necessarily mean randomized control trials
[00:04:28.140 --> 00:04:29.020]   at a university.
[00:04:29.020 --> 00:04:32.060]   I do think as an end of one,
[00:04:32.060 --> 00:04:35.580]   if you think about study design and you can even blind,
[00:04:35.580 --> 00:04:36.940]   you could even placebo control.
[00:04:36.940 --> 00:04:39.700]   And I knew people in the small subculture
[00:04:39.700 --> 00:04:41.580]   of quantified self who did this.
[00:04:41.580 --> 00:04:45.780]   You can, I think, approach things in a methodical way
[00:04:45.780 --> 00:04:47.460]   where you can make a lot of progress
[00:04:47.460 --> 00:04:50.960]   in trying to determine causality or lack thereof.
[00:04:50.960 --> 00:04:53.620]   Looking at very old things, looking at orphaned things.
[00:04:53.620 --> 00:04:57.060]   So for instance, there are many examples
[00:04:57.060 --> 00:04:59.660]   in the world of doping,
[00:04:59.660 --> 00:05:03.100]   where you have say, Balco back in the day,
[00:05:03.100 --> 00:05:05.940]   where famously Barry Bonds and others
[00:05:05.940 --> 00:05:09.740]   purportedly use things like the cream and the clear.
[00:05:09.740 --> 00:05:11.340]   And these were based on anabolics
[00:05:11.340 --> 00:05:15.420]   that were sourced from Soviet literature
[00:05:15.420 --> 00:05:18.220]   or older literature from the '50s and '60s
[00:05:18.220 --> 00:05:22.740]   that might not be on the radar of say the anti-doping groups
[00:05:22.740 --> 00:05:24.380]   that would administer the testing.
[00:05:24.380 --> 00:05:28.600]   So all of these different buckets were of interest to me.
[00:05:28.600 --> 00:05:31.540]   And I begin where I usually do, which is interviewing folks.
[00:05:31.540 --> 00:05:34.620]   So I would interview one or two people in a given field,
[00:05:34.620 --> 00:05:38.700]   and I might ask them any number of questions.
[00:05:38.700 --> 00:05:41.420]   So one is, what are the nerds doing
[00:05:41.420 --> 00:05:42.500]   on the weekends or at night?
[00:05:42.500 --> 00:05:43.980]   This is also really good for investing.
[00:05:43.980 --> 00:05:46.580]   It's like, all right, what are the really technical nerds
[00:05:46.580 --> 00:05:49.540]   doing at night or on the weekends
[00:05:49.540 --> 00:05:53.220]   after they've put in a really long work day or work week?
[00:05:53.220 --> 00:05:55.460]   Let's take a really close look at that.
[00:05:55.460 --> 00:05:58.940]   Another one is, and I'll create a flow for this,
[00:05:58.940 --> 00:06:02.380]   but what are rich people doing now
[00:06:02.380 --> 00:06:06.100]   that everyone or tens or hundreds of millions of people
[00:06:06.100 --> 00:06:09.560]   might be doing 10 years from now?
[00:06:09.560 --> 00:06:11.820]   And an example of that would be, let's just say,
[00:06:11.820 --> 00:06:15.260]   full-time assistant, virtual assistant, AI.
[00:06:15.260 --> 00:06:19.940]   So we've seen the needs and wants
[00:06:19.940 --> 00:06:21.540]   being addressed by different technology,
[00:06:21.540 --> 00:06:24.940]   but it's an iteration of the same thing on some level,
[00:06:24.940 --> 00:06:27.000]   in the case of say using ChatGPT
[00:06:27.000 --> 00:06:29.740]   tied into Zapier for various functions.
[00:06:29.740 --> 00:06:32.060]   And then where are people cobbling together
[00:06:32.060 --> 00:06:33.340]   awkward solutions?
[00:06:33.340 --> 00:06:38.340]   So where are people piecing together awkward solutions,
[00:06:38.340 --> 00:06:41.420]   and is there room for some type of innovation there?
[00:06:41.420 --> 00:06:42.620]   These are a few of the questions
[00:06:42.620 --> 00:06:44.620]   that I would not only ask myself,
[00:06:44.620 --> 00:06:46.260]   but ask experts in different areas.
[00:06:46.260 --> 00:06:48.020]   So if I end up spending time, say,
[00:06:48.020 --> 00:06:53.020]   this was a few years prior to writing The 4-Hour Body.
[00:06:53.020 --> 00:06:55.500]   I spent time at NASA Ames
[00:06:55.500 --> 00:06:57.420]   and was interacting with a number of scientists,
[00:06:57.420 --> 00:06:58.980]   some people who were working on all sorts
[00:06:58.980 --> 00:07:03.260]   of biological tests and looking at genomics.
[00:07:03.260 --> 00:07:04.820]   And I had a very frank discussion
[00:07:04.820 --> 00:07:07.900]   about where they thought, if they had to push, right?
[00:07:07.900 --> 00:07:09.260]   So I'll ask questions like,
[00:07:09.260 --> 00:07:12.100]   push a little bit into the realm
[00:07:12.100 --> 00:07:13.620]   of science fiction and speculation,
[00:07:13.620 --> 00:07:16.460]   because I'm sure you can't support
[00:07:16.460 --> 00:07:18.100]   any type of projection like that
[00:07:18.100 --> 00:07:20.060]   with the literature, with scientific literature.
[00:07:20.060 --> 00:07:22.700]   But what do you think some of the risks are
[00:07:22.700 --> 00:07:24.700]   of say publishing your genome?
[00:07:24.700 --> 00:07:26.460]   Because at the time, a number of high-profile folks
[00:07:26.460 --> 00:07:28.700]   had just made their full genomes available.
[00:07:28.700 --> 00:07:30.780]   And they're like, well, I think in the near future,
[00:07:30.780 --> 00:07:34.820]   it might be possible to reconstruct someone's face
[00:07:34.820 --> 00:07:37.020]   based on their genetic data.
[00:07:37.020 --> 00:07:39.260]   And they're like, high degree of confidence,
[00:07:39.260 --> 00:07:40.620]   like zero to 100%, how confident?
[00:07:40.620 --> 00:07:41.940]   They're like, yeah, 80, 90%.
[00:07:41.940 --> 00:07:43.980]   I'm like, okay, I should pay attention to that.
[00:07:43.980 --> 00:07:45.740]   Because if you're making your data available,
[00:07:45.740 --> 00:07:48.220]   let's just say, and it's anonymized per se,
[00:07:48.220 --> 00:07:49.860]   you still might be identifiable.
[00:07:49.860 --> 00:07:51.700]   So it's like, okay, that raises some interesting questions.
[00:07:51.700 --> 00:07:54.900]   Like, okay, well, then how might you get around that?
[00:07:54.900 --> 00:07:56.740]   How might you put in safeguards
[00:07:56.740 --> 00:07:59.500]   so that you are the one and only keeper
[00:07:59.500 --> 00:08:00.940]   of your data, so to speak?
[00:08:00.940 --> 00:08:05.500]   Brought up all sorts of targeted weaponry
[00:08:05.500 --> 00:08:07.820]   by sort of bioweapons possibilities
[00:08:07.820 --> 00:08:08.900]   that I was interested in.
[00:08:08.900 --> 00:08:10.540]   And then I would ask that person
[00:08:10.540 --> 00:08:14.460]   who's clearly willing to step outside of the box
[00:08:14.460 --> 00:08:16.380]   of whatever he's working on day to day,
[00:08:16.380 --> 00:08:19.140]   who are two of your close friends
[00:08:19.140 --> 00:08:21.740]   or two thinkers you really pay a lot of attention to
[00:08:21.740 --> 00:08:24.900]   or kind of at the bleeding edge of something and unorthodox?
[00:08:24.900 --> 00:08:26.420]   And then I would just continue
[00:08:26.420 --> 00:08:28.380]   to have these conversations over and over again.
[00:08:28.380 --> 00:08:32.420]   And the stream of development
[00:08:32.420 --> 00:08:33.580]   that I paid a lot of attention to
[00:08:33.580 --> 00:08:35.660]   is something along the lines of the following.
[00:08:35.660 --> 00:08:39.860]   So the very beginnings are usually
[00:08:39.860 --> 00:08:42.060]   in some type of extreme case.
[00:08:42.060 --> 00:08:44.420]   And I think the extremes,
[00:08:44.420 --> 00:08:45.820]   and this goes for product design as well,
[00:08:45.820 --> 00:08:48.500]   but the extremes inform the mean, but not vice versa.
[00:08:48.500 --> 00:08:51.180]   So you can actually learn a lot by studying the edge cases.
[00:08:51.180 --> 00:08:54.020]   So racehorses, for instance,
[00:08:54.020 --> 00:08:57.380]   you'll often see things start with, say, racehorses,
[00:08:57.380 --> 00:09:00.220]   or people with wasting diseases, for instance,
[00:09:00.220 --> 00:09:04.020]   or any type of chronic or terminal illness
[00:09:04.020 --> 00:09:08.660]   who are willing to try some more experimental interventions.
[00:09:08.660 --> 00:09:12.140]   Then let's just take one step further, bodybuilding.
[00:09:12.140 --> 00:09:14.500]   See a lot of interesting behavior in bodybuilding
[00:09:14.500 --> 00:09:16.220]   and high-level athletes, then billionaires,
[00:09:16.220 --> 00:09:18.500]   then rich people, then the rest of us, right?
[00:09:18.500 --> 00:09:21.860]   So my assumption is and was for the 4-Hour Body
[00:09:21.860 --> 00:09:25.300]   that along the lines of William Gibson's quote,
[00:09:25.300 --> 00:09:26.300]   the future is already here,
[00:09:26.300 --> 00:09:28.140]   it's just not evenly distributed.
[00:09:28.140 --> 00:09:29.860]   So I'm never predicting the future,
[00:09:29.860 --> 00:09:32.740]   I'm just finding the seeds that are germinating
[00:09:32.740 --> 00:09:34.340]   that I think are gonna bloom
[00:09:34.340 --> 00:09:38.060]   and end up spreading really, really widely.
[00:09:38.060 --> 00:09:41.380]   So that's generally where I start.
[00:09:41.380 --> 00:09:42.540]   And I assume the practitioners
[00:09:42.540 --> 00:09:44.500]   are gonna be ahead of the papers.
[00:09:44.500 --> 00:09:48.740]   So studying, say, the coaches whose jobs are on the line,
[00:09:48.740 --> 00:09:51.660]   who are getting paid based on athlete performance,
[00:09:51.660 --> 00:09:54.580]   and assuming that a lot of that will eventually,
[00:09:54.580 --> 00:09:56.980]   if it holds up, make its way into, say,
[00:09:56.980 --> 00:09:59.000]   the peer-reviewed exercise science papers,
[00:09:59.000 --> 00:10:01.420]   but it's gonna have a lag time of three to five years.
[00:10:01.420 --> 00:10:02.980]   - At least. - At least.
[00:10:02.980 --> 00:10:04.060]   At least, it takes a long time.
[00:10:04.060 --> 00:10:07.180]   - Yeah, science is often very slow to catch up.
[00:10:07.180 --> 00:10:11.940]   You mentioned many things I have questions about.
[00:10:11.940 --> 00:10:14.780]   You mentioned paying attention to the new,
[00:10:14.780 --> 00:10:17.120]   the very old, or the orphaned.
[00:10:17.120 --> 00:10:21.160]   So interesting, and I just thought I'd tell you
[00:10:21.160 --> 00:10:23.420]   that when you sit down with a graduate student
[00:10:23.420 --> 00:10:26.900]   or a postdoc, and they're trying to come up with a project,
[00:10:26.900 --> 00:10:29.820]   rarely do you say, "What do you wanna work on?"
[00:10:29.820 --> 00:10:33.360]   And they fire back a really interesting question.
[00:10:33.360 --> 00:10:36.220]   Sometimes they do, but that's the rare person.
[00:10:36.220 --> 00:10:39.580]   More often than not, you'll send them to the literature,
[00:10:39.580 --> 00:10:41.640]   and they'll come back with, "Okay, there's this new technique
[00:10:41.640 --> 00:10:44.720]   "that we can use to answer a set of questions
[00:10:44.720 --> 00:10:47.060]   "better than ever before,"
[00:10:47.060 --> 00:10:49.580]   or, "There's a very old theory I wanna revisit,"
[00:10:49.580 --> 00:10:52.140]   or, "There's this theory that no one pays attention to."
[00:10:52.140 --> 00:10:54.220]   In fact, we had one guest on here, Oded Rashavi,
[00:10:54.220 --> 00:10:57.600]   who is studying, essentially, inheritance of traits,
[00:10:57.600 --> 00:10:59.180]   transgenerational inheritance of traits.
[00:10:59.180 --> 00:11:00.460]   It's a little bit, although,
[00:11:00.460 --> 00:11:04.380]   different from Lamarckian evolution,
[00:11:04.380 --> 00:11:07.140]   but it's a lot like that in some ways.
[00:11:07.140 --> 00:11:09.780]   And these orphaned theories that everyone assumed were wrong
[00:11:09.780 --> 00:11:11.100]   and that there is a basis for them.
[00:11:11.100 --> 00:11:15.280]   So I think there's real genius in that analysis.
[00:11:15.280 --> 00:11:17.860]   (upbeat music)
[00:11:18.700 --> 00:11:21.280]   (upbeat music)
[00:11:21.280 --> 00:11:24.320]   [MUSIC PLAYING]

