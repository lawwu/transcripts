
[00:00:00.000 --> 00:00:02.760]   So, Mark, did you go down to the breakthrough thing this weekend?
[00:00:02.760 --> 00:00:04.840]   The breakthrough prize is amazing.
[00:00:04.840 --> 00:00:08.180]   It's like observing exotic animals in their natural habitat.
[00:00:08.180 --> 00:00:10.680]   Well, a friend of mine, who you hung out with down there, called me
[00:00:10.680 --> 00:00:14.360]   last night to give me the breakdown on all the individuals
[00:00:14.360 --> 00:00:15.940]   he saw and what was going on with them.
[00:00:15.940 --> 00:00:19.740]   I mean, he's like, I don't even know how Nat and I keep getting invited to this.
[00:00:19.740 --> 00:00:22.360]   But like to say we were outclassed is an understatement.
[00:00:22.360 --> 00:00:24.160]   The people at that thing were.
[00:00:24.160 --> 00:00:26.440]   What is it, the breakthrough awards? The breakthrough prize, yeah.
[00:00:26.440 --> 00:00:27.660]   Yeah, I couldn't make it.
[00:00:27.660 --> 00:00:29.820]   I got invited to. It's so incredible.
[00:00:30.140 --> 00:00:31.940]   OK, first of all, shout out to Yuri and Julia.
[00:00:31.940 --> 00:00:33.520]   It is incredible.
[00:00:33.520 --> 00:00:36.440]   There were two moments where I cried.
[00:00:36.440 --> 00:00:41.120]   This woman goes up on stage to give an award to the people
[00:00:41.120 --> 00:00:44.780]   that had made this investment in cystic fibrosis. Yeah.
[00:00:44.780 --> 00:00:49.000]   And she says, my child was born with cystic fibrosis,
[00:00:49.000 --> 00:00:52.120]   and then my second child was born with cystic fibrosis,
[00:00:52.120 --> 00:00:53.840]   and then my second child died.
[00:00:53.840 --> 00:00:56.340]   She said that I just burst into tears.
[00:00:57.300 --> 00:00:59.760]   And then you present an award to the person
[00:00:59.760 --> 00:01:02.600]   that actually is helping them stamp out the disease.
[00:01:02.600 --> 00:01:06.100]   We celebrated the people that found the gene that caused Parkinson's.
[00:01:06.100 --> 00:01:09.480]   And then, yeah, I mean, the people at that is pretty incredible.
[00:01:09.480 --> 00:01:11.940]   It's in L.A., right? They did it in Los Angeles.
[00:01:11.940 --> 00:01:14.660]   Yeah, I mean, like, look, Yuri Milner and Julia Milner.
[00:01:14.660 --> 00:01:21.660]   Zuck. And Priscilla Chan and and Wojcicki and Sergey Brin.
[00:01:21.660 --> 00:01:24.040]   Those six people are the ones that organized this breakthrough prize.
[00:01:24.040 --> 00:01:27.800]   And I think it's just. A modern version of the Nobel,
[00:01:27.800 --> 00:01:31.380]   which tries to really shine a spotlight on people
[00:01:31.380 --> 00:01:35.060]   doing really groundbreaking work in physics and math and life sciences.
[00:01:35.060 --> 00:01:39.720]   And so you get people that have just done things
[00:01:39.720 --> 00:01:42.760]   that are just very practical.
[00:01:42.760 --> 00:01:44.720]   And are very real.
[00:01:44.720 --> 00:01:48.940]   And I think what they do is they make, frankly, these kinds of achievements.
[00:01:50.400 --> 00:01:54.600]   Much more high level in the sense that you're bringing together
[00:01:54.600 --> 00:01:58.320]   people from Hollywood and people from Silicon Valley, and the awareness is up
[00:01:58.320 --> 00:02:01.480]   and it's just incredibly well produced and.
[00:02:01.480 --> 00:02:04.080]   Yeah, it's really a cool thing to be a part of, but I mean,
[00:02:04.080 --> 00:02:06.820]   seeing some of these people are very intimidating.
[00:02:06.820 --> 00:02:08.900]   I sat beside Vin Diesel.
[00:02:08.900 --> 00:02:12.880]   Oh, really? That was super cool.
[00:02:12.880 --> 00:02:15.840]   He is a super nice guy.
[00:02:15.840 --> 00:02:18.540]   And on the other side of me was someone that actually sacks
[00:02:18.540 --> 00:02:21.560]   those Toby Emmerich, who's was the chairman of Warner Brothers.
[00:02:21.560 --> 00:02:24.560]   So just talking to these guys was super cool.
[00:02:24.560 --> 00:02:27.180]   Moving it to Los Angeles was a great move. Great.
[00:02:27.180 --> 00:02:28.980]   Yeah, it's just I was invited.
[00:02:28.980 --> 00:02:31.020]   I couldn't make it. Sorry. Thank you to Julian.
[00:02:31.020 --> 00:02:34.280]   Yuri for inviting us again.
[00:02:34.280 --> 00:02:39.320]   But it's really great that they're giving it the celebration it deserves
[00:02:39.320 --> 00:02:44.160]   and making it, you know, like, dare I say, sexy and cool and hip
[00:02:44.160 --> 00:02:47.400]   to be a scientist and solve the world's biggest problems.
[00:02:47.400 --> 00:02:49.160]   I think it's just so awesome.
[00:02:49.160 --> 00:02:51.240]   And you're right, Sergey Brin and Wojcicki.
[00:02:51.240 --> 00:02:57.740]   Saki, Priscilla and Julia and Yuri are the founders of the Breakthrough Prize.
[00:02:57.740 --> 00:03:01.540]   The craziest thing is they give a they give a youth breakthrough award.
[00:03:01.540 --> 00:03:03.660]   So the Breakthrough Prize is this beautiful globe.
[00:03:03.660 --> 00:03:06.760]   And then the junior winner gets like a smaller version.
[00:03:06.760 --> 00:03:07.960]   Very appropriate.
[00:03:07.960 --> 00:03:10.840]   And it was a video of this kid in India
[00:03:10.840 --> 00:03:15.100]   who had won it a few years ago and then went off to MIT
[00:03:15.460 --> 00:03:17.340]   and then graduated.
[00:03:17.340 --> 00:03:20.380]   And then the video is of him coming back to Bangalore
[00:03:20.380 --> 00:03:25.460]   because his sister had won this year and he presented it to the sister.
[00:03:25.460 --> 00:03:30.140]   And all I could think of was this is an incredible achievement
[00:03:30.140 --> 00:03:31.900]   by like a 16 year old.
[00:03:31.900 --> 00:03:35.180]   And literally at the same time, my 16 year old was like,
[00:03:35.180 --> 00:03:38.520]   Dad, the chicken tenders from DoorDash have arrived.
[00:03:38.520 --> 00:03:42.160]   And I was like, I can't find my chicken fingers.
[00:03:42.180 --> 00:03:45.920]   Oh, I love your winters ride.
[00:03:45.920 --> 00:03:50.500]   Rain Man, David Sachs.
[00:03:50.500 --> 00:03:55.260]   And I said, we open sources to the fans and they've just gone crazy.
[00:03:55.260 --> 00:03:56.500]   Love you guys.
[00:03:56.500 --> 00:03:59.680]   Queen of Kinwam.
[00:03:59.680 --> 00:04:04.640]   Dad, I said, get me the spicy fries, not the regular Cajun fries.
[00:04:04.640 --> 00:04:08.640]   The girl that won it, Freebird did something with Yamanaka factors.
[00:04:08.640 --> 00:04:11.940]   So it's like it's really incredible
[00:04:11.940 --> 00:04:14.200]   and inspiring, but fortunately, don't worry.
[00:04:14.200 --> 00:04:17.740]   My my 16 year old was able to get the chicken tenders and everything was fine.
[00:04:17.740 --> 00:04:19.620]   OK, good. Yeah, sure.
[00:04:19.620 --> 00:04:21.960]   You called rerouted it.
[00:04:21.960 --> 00:04:24.880]   I can't get his chicken tenders.
[00:04:24.880 --> 00:04:26.220]   What do we do?
[00:04:26.220 --> 00:04:30.260]   By the way, the other the other thing I'll say is
[00:04:30.260 --> 00:04:32.800]   the person that performed is really amazing, Charlie Puth.
[00:04:32.800 --> 00:04:36.020]   And and the reason I say it is if you Google
[00:04:36.020 --> 00:04:40.640]   Charlie Puth, this guy,
[00:04:40.640 --> 00:04:44.360]   he's a young guy in his early 20s, I'm guessing he is so talented.
[00:04:44.360 --> 00:04:48.320]   There's all these videos of Charlie Puth where he'll make a random noise,
[00:04:48.320 --> 00:04:52.740]   like he'll clink a Coke bottle with a fork and then he'll record it
[00:04:52.740 --> 00:04:55.540]   and then he'll put it into these digital editing tools.
[00:04:55.540 --> 00:05:00.280]   And then he'll make like an entire five minute song using that as the base,
[00:05:00.280 --> 00:05:03.420]   like as the basic building block.
[00:05:03.420 --> 00:05:07.500]   The guy is so talented.
[00:05:08.720 --> 00:05:10.680]   Anyways, it was a very it was a very cool event.
[00:05:10.680 --> 00:05:13.020]   Fantastic. How are you doing, Sax?
[00:05:13.020 --> 00:05:14.060]   You OK, buddy?
[00:05:14.060 --> 00:05:17.480]   I'm good. Let's get started.
[00:05:17.480 --> 00:05:19.280]   There it is, folks. We're back.
[00:05:19.280 --> 00:05:20.820]   It's going to be a hell of a show.
[00:05:20.820 --> 00:05:22.400]   Let's go. I got to do.
[00:05:22.400 --> 00:05:25.620]   Don't waste time with your with your pointless banter.
[00:05:25.620 --> 00:05:28.160]   It's my people. So it is the banter.
[00:05:28.160 --> 00:05:29.200]   They do enter, bro.
[00:05:29.200 --> 00:05:30.120]   How are you doing, Freebird?
[00:05:30.120 --> 00:05:32.500]   We got a little scene from the movie her.
[00:05:32.500 --> 00:05:36.960]   Wow. We're off to a strong start here.
[00:05:36.960 --> 00:05:39.260]   Look at all these contributions.
[00:05:39.260 --> 00:05:40.840]   I got a shrug from Freebird.
[00:05:40.840 --> 00:05:44.100]   I got a grudge. OK, let's get started from sacks.
[00:05:44.100 --> 00:05:45.380]   I don't talk about my backgrounds.
[00:05:45.380 --> 00:05:47.800]   Let's go. Anything good on the menu tonight, Shemoth?
[00:05:47.800 --> 00:05:49.180]   I just want I'm coming over for poker.
[00:05:49.180 --> 00:05:51.300]   I wanted to know if there's an octopus.
[00:05:51.300 --> 00:05:54.840]   Oh, so the Greek comes back and you get the octopus.
[00:05:54.840 --> 00:05:55.800]   I'll get the octopus.
[00:05:55.800 --> 00:05:58.320]   I think that Sean missed you. Yeah, he did.
[00:05:58.320 --> 00:06:01.780]   By the way, Sean experimented with some Greek cheese that you grill.
[00:06:01.780 --> 00:06:02.980]   That was pretty delicious.
[00:06:02.980 --> 00:06:04.980]   Oh, holy cheese. Halloumi.
[00:06:04.980 --> 00:06:07.700]   What is it? What's the plural of octopus?
[00:06:07.700 --> 00:06:10.280]   Is it octopi? Yeah.
[00:06:10.280 --> 00:06:12.620]   Aren't they like sentient creatures or something?
[00:06:12.620 --> 00:06:13.740]   Halloumi. Yeah.
[00:06:13.740 --> 00:06:16.200]   You know what? It's interesting you bring that up.
[00:06:16.200 --> 00:06:19.460]   I had a grilled octopus stand at one of our events.
[00:06:19.460 --> 00:06:21.380]   And somebody who.
[00:06:21.380 --> 00:06:27.420]   Is, you know, a conscientious consumer of calories.
[00:06:27.420 --> 00:06:32.220]   Lobbying me to take the grilled octopus off of the menu.
[00:06:32.220 --> 00:06:33.520]   I won't say who.
[00:06:33.520 --> 00:06:35.800]   What? Wait, what?
[00:06:35.800 --> 00:06:37.520]   I got lobbied very strongly.
[00:06:37.520 --> 00:06:42.520]   Not only is it deeply wrong to eat all the animals that you people eat
[00:06:42.520 --> 00:06:45.600]   and you will one day realize it or your children or your children's children
[00:06:45.600 --> 00:06:46.240]   will realize it.
[00:06:46.240 --> 00:06:50.820]   But octopus in particular have the IQ of four to eight year olds.
[00:06:50.820 --> 00:06:52.740]   They can actually sign.
[00:06:52.740 --> 00:06:54.280]   They can communicate.
[00:06:54.280 --> 00:06:56.200]   They can solve problems.
[00:06:56.200 --> 00:06:58.580]   You can watch YouTube videos on this. It's pretty incredible.
[00:06:58.580 --> 00:06:59.880]   They're amazing creatures.
[00:06:59.880 --> 00:07:04.420]   It's also why in the movie The Arrival, the future alien race
[00:07:04.420 --> 00:07:07.920]   is made out to be cephalopods, because they're the most advanced
[00:07:07.920 --> 00:07:11.720]   creature that's likely to become a civilized form if humans didn't exist.
[00:07:11.720 --> 00:07:14.680]   I have a one word reaction to that.
[00:07:14.680 --> 00:07:15.600]   Yum.
[00:07:15.600 --> 00:07:17.600]   Delicious.
[00:07:17.600 --> 00:07:19.600]   It's the IQ that makes it taste so good.
[00:07:19.600 --> 00:07:21.600]   Oh my God.
[00:07:21.600 --> 00:07:23.600]   That's dark.
[00:07:23.600 --> 00:07:25.600]   That's dark.
[00:07:25.600 --> 00:07:28.600]   You're saying the IQ is like the spice?
[00:07:28.600 --> 00:07:30.600]   Yeah, it's kind of like the fat content.
[00:07:30.600 --> 00:07:32.600]   It's kind of like the marbling.
[00:07:32.600 --> 00:07:34.600]   It's the marbling of it.
[00:07:34.600 --> 00:07:36.600]   That's dark. I don't know.
[00:07:36.600 --> 00:07:38.600]   By the way, thanks guys. I'm fine.
[00:07:38.600 --> 00:07:40.600]   I'm great. I'm feeling great.
[00:07:40.600 --> 00:07:42.600]   The tooth is healed.
[00:07:42.600 --> 00:07:44.600]   You look like you've been eating well.
[00:07:44.600 --> 00:07:46.600]   Only things with above 120 IQ.
[00:07:46.600 --> 00:07:48.600]   Are you off the Wigovie?
[00:07:48.600 --> 00:07:50.600]   What do you call it?
[00:07:50.600 --> 00:07:52.600]   What I did was I got off the Wigovie so I could eat more animals.
[00:07:52.600 --> 00:07:54.600]   And now I'm getting back on it.
[00:07:54.600 --> 00:07:56.600]   Because I feel so terrible.
[00:07:56.600 --> 00:07:58.600]   I was in Austin.
[00:07:58.600 --> 00:08:00.600]   I ate everything.
[00:08:00.600 --> 00:08:02.600]   I was eating bison.
[00:08:02.600 --> 00:08:04.600]   If you eat high IQ foods,
[00:08:04.600 --> 00:08:06.600]   does it make you smarter?
[00:08:06.600 --> 00:08:08.600]   Absolutely.
[00:08:08.600 --> 00:08:10.600]   This is why the Greeks invented so many things.
[00:08:10.600 --> 00:08:12.600]   We invented math, plumbing, cities,
[00:08:12.600 --> 00:08:14.600]   democracy. All the great things
[00:08:14.600 --> 00:08:16.600]   the Greeks created comes from
[00:08:16.600 --> 00:08:18.600]   the fact that we ate so many high IQ creatures.
[00:08:18.600 --> 00:08:20.600]   Are you able to be vegetarian?
[00:08:20.600 --> 00:08:22.600]   Were you able to find good vegetarian or veggie
[00:08:22.600 --> 00:08:24.600]   options in Austin?
[00:08:24.600 --> 00:08:26.600]   Are you talking to me?
[00:08:26.600 --> 00:08:28.600]   Yeah.
[00:08:28.600 --> 00:08:30.600]   I see a vegetable
[00:08:30.600 --> 00:08:32.600]   and I push it away.
[00:08:32.600 --> 00:08:34.600]   I'm like, wait a second.
[00:08:34.600 --> 00:08:36.600]   Jake, I was on a seafood diet in Austin.
[00:08:36.600 --> 00:08:38.600]   If he saw food, he ate it.
[00:08:38.600 --> 00:08:40.600]   It's not inaccurate.
[00:08:40.600 --> 00:08:42.600]   The barbecue
[00:08:42.600 --> 00:08:44.600]   in Austin is so
[00:08:44.600 --> 00:08:46.600]   spectacular. Terry Black's
[00:08:46.600 --> 00:08:48.600]   beef ribs I had with a friend
[00:08:48.600 --> 00:08:50.600]   of ours, man, they are just dynamite.
[00:08:50.600 --> 00:08:52.600]   Then the Salt Lake
[00:08:52.600 --> 00:08:54.600]   brisket, Franklin's brisket.
[00:08:54.600 --> 00:08:56.600]   It is just extraordinary.
[00:08:56.600 --> 00:08:58.600]   Shout out to all my barbecue folks there and sorry for
[00:08:58.600 --> 00:09:00.600]   triggering. Every mammal that wasn't
[00:09:00.600 --> 00:09:02.600]   buttoned down,
[00:09:02.600 --> 00:09:04.600]   J. Cole battered in
[00:09:04.600 --> 00:09:06.600]   barbecue sauce.
[00:09:06.600 --> 00:09:08.600]   The thing that took out the rib was the bison.
[00:09:08.600 --> 00:09:10.600]   I'm sorry I was away. Apologies to the audience.
[00:09:10.600 --> 00:09:12.600]   It took out a tooth. As far as
[00:09:12.600 --> 00:09:14.600]   I feel, worth it. What does a bison
[00:09:14.600 --> 00:09:16.600]   rib taste like?
[00:09:16.600 --> 00:09:18.600]   The beef
[00:09:18.600 --> 00:09:20.600]   ribs are very tender. The bison's got a little
[00:09:20.600 --> 00:09:22.600]   more chew to it. It's got a little more texture.
[00:09:22.600 --> 00:09:24.600]   They let this thing
[00:09:24.600 --> 00:09:26.600]   go at the Salt Lake
[00:09:26.600 --> 00:09:28.600]   for 12 hours
[00:09:28.600 --> 00:09:30.600]   and they're just barbecue
[00:09:30.600 --> 00:09:32.600]   sauce in it forever. It's a little chewy.
[00:09:32.600 --> 00:09:34.600]   That's what took out the tooth.
[00:09:34.600 --> 00:09:36.600]   Great job, Freebird,
[00:09:36.600 --> 00:09:38.600]   on moderating. The episode was fantastic.
[00:09:38.600 --> 00:09:40.600]   Yes, I was chomping on the bit quite literally
[00:09:40.600 --> 00:09:42.600]   sax to talk about some stuff.
[00:09:42.600 --> 00:09:44.600]   Chomping on the bit to the point that I shattered a tooth.
[00:09:44.600 --> 00:09:46.600]   I am back and I have so much energy.
[00:09:46.600 --> 00:09:48.600]   I missed you guys. I actually
[00:09:48.600 --> 00:09:50.600]   missed you all. Freebird, so much
[00:09:50.600 --> 00:09:52.600]   good stuff happening with the Summit.
[00:09:52.600 --> 00:09:54.600]   I'm delighted
[00:09:54.600 --> 00:09:56.600]   that John is doing all this work. You are doing all
[00:09:56.600 --> 00:09:58.600]   this work and I can just sit
[00:09:58.600 --> 00:10:00.600]   back and enjoy it.
[00:10:00.600 --> 00:10:02.600]   Tell us, is there an update on the Summit?
[00:10:02.600 --> 00:10:04.600]   Yes, you're just collecting your coupon.
[00:10:04.600 --> 00:10:06.600]   We had
[00:10:06.600 --> 00:10:08.600]   within 72
[00:10:08.600 --> 00:10:10.600]   hours, I think we had more
[00:10:10.600 --> 00:10:12.600]   applications than we have seats.
[00:10:12.600 --> 00:10:14.600]   We're still leaving applications
[00:10:14.600 --> 00:10:16.600]   open and in the next week we'll start to
[00:10:16.600 --> 00:10:18.600]   respond to people.
[00:10:18.600 --> 00:10:20.600]   Basically, if you're interested in going
[00:10:20.600 --> 00:10:22.600]   to the Summit, sign
[00:10:22.600 --> 00:10:24.600]   up now, get your applications in this week.
[00:10:24.600 --> 00:10:26.600]   Apply early is the key.
[00:10:26.600 --> 00:10:28.600]   Yes, because it's going to be done in order
[00:10:28.600 --> 00:10:30.600]   of when it's received and
[00:10:30.600 --> 00:10:32.600]   they're going to start processing applications
[00:10:32.600 --> 00:10:34.600]   this week. We'd love to
[00:10:34.600 --> 00:10:36.600]   get everyone that wants to show up, show up.
[00:10:36.600 --> 00:10:38.600]   If you went in the past,
[00:10:38.600 --> 00:10:40.600]   your registration
[00:10:40.600 --> 00:10:42.600]   window is wrapped up this week.
[00:10:42.600 --> 00:10:44.600]   Okay, so alumni
[00:10:44.600 --> 00:10:46.600]   automatically get in? Alumni automatically
[00:10:46.600 --> 00:10:48.600]   are in. Tell us
[00:10:48.600 --> 00:10:50.600]   about the scholarship because I'm getting bombarded
[00:10:50.600 --> 00:10:52.600]   and everybody who's an up-and-coming
[00:10:52.600 --> 00:10:54.600]   all-in fan. We're going to announce it in a couple
[00:10:54.600 --> 00:10:56.600]   of weeks, so no plan yet.
[00:10:56.600 --> 00:10:58.600]   We'll still do scholarships
[00:10:58.600 --> 00:11:00.600]   because I think they were super successful and helpful
[00:11:00.600 --> 00:11:02.600]   to people that otherwise couldn't afford the ticket.
[00:11:02.600 --> 00:11:04.600]   I know it's expensive this year, but
[00:11:04.600 --> 00:11:06.600]   the reason was we actually spent a lot
[00:11:06.600 --> 00:11:08.600]   more per person last year
[00:11:08.600 --> 00:11:10.600]   than people actually paid for their tickets.
[00:11:10.600 --> 00:11:12.600]   It's less than $10.
[00:11:12.600 --> 00:11:14.600]   We're trying to get the price so that we can
[00:11:14.600 --> 00:11:16.600]   make the same break-even
[00:11:16.600 --> 00:11:18.600]   and we're going to have scholarship tickets
[00:11:18.600 --> 00:11:20.600]   with the balance.
[00:11:20.600 --> 00:11:22.600]   I saw a couple speakers come in.
[00:11:22.600 --> 00:11:24.600]   Not talking about it yet.
[00:11:24.600 --> 00:11:26.600]   Oh, come on. Can we just tell the two
[00:11:26.600 --> 00:11:28.600]   speakers who said yes? Come on.
[00:11:28.600 --> 00:11:30.600]   Not yet. We'll do a big
[00:11:30.600 --> 00:11:32.600]   announcement. Saks landed a big speaker
[00:11:32.600 --> 00:11:34.600]   and I think it's going to be awesome.
[00:11:34.600 --> 00:11:36.600]   In a week, we'll announce a bunch together.
[00:11:36.600 --> 00:11:38.600]   One thing I don't want to wait on is today's docket
[00:11:38.600 --> 00:11:40.600]   because it is unbelievable. Welcome everybody
[00:11:40.600 --> 00:11:42.600]   to Episode 175.
[00:11:42.600 --> 00:11:44.600]   That's right. It's Episode 175
[00:11:44.600 --> 00:11:46.600]   of your favorite podcast
[00:11:46.600 --> 00:11:48.600]   and the largest
[00:11:48.600 --> 00:11:50.600]   and most listened to podcast in the world.
[00:11:50.600 --> 00:11:52.600]   Officially, Episode 175 of the All-In Podcast
[00:11:52.600 --> 00:11:54.600]   starts right now.
[00:11:54.600 --> 00:11:56.600]   I've got so many feelings
[00:11:56.600 --> 00:11:58.600]   about this one. Wait, what? It's not the largest, most listened
[00:11:58.600 --> 00:12:00.600]   to podcast in the world? I'm manifesting.
[00:12:00.600 --> 00:12:02.600]   Oh, you're manifesting.
[00:12:02.600 --> 00:12:04.600]   I'm manifesting, Chamath.
[00:12:04.600 --> 00:12:06.600]   Just like the world's
[00:12:06.600 --> 00:12:08.600]   greatest poker player and then we watch
[00:12:08.600 --> 00:12:10.600]   Robo roll over him. Is that
[00:12:10.600 --> 00:12:12.600]   a new word that narcissists use for lying?
[00:12:12.600 --> 00:12:14.600]   Manifesting? No, it's
[00:12:14.600 --> 00:12:16.600]   just like the world's greatest
[00:12:16.600 --> 00:12:18.600]   poker player and then we see Phil Hellmuth
[00:12:18.600 --> 00:12:20.600]   get dominated by
[00:12:20.600 --> 00:12:22.600]   Jason Kuhn. Just so you know, tonight
[00:12:22.600 --> 00:12:24.600]   is a murderer's row and Hellmuth
[00:12:24.600 --> 00:12:26.600]   is flying back. You saw the lineup.
[00:12:26.600 --> 00:12:28.600]   I'm very excited to see what happens tonight.
[00:12:28.600 --> 00:12:30.600]   Is Jason Kuhn coming or no?
[00:12:30.600 --> 00:12:32.600]   Yeah. I mean, Kuhn
[00:12:32.600 --> 00:12:34.600]   and Robo and then the world's greatest
[00:12:34.600 --> 00:12:36.600]   poker player, Phil Hellmuth playing is so great to watch.
[00:12:36.600 --> 00:12:38.600]   It's like a meta-ego
[00:12:38.600 --> 00:12:40.600]   battle. It is.
[00:12:40.600 --> 00:12:42.600]   It's interesting. Two of those three guys are
[00:12:42.600 --> 00:12:44.600]   the most humble guys you would ever
[00:12:44.600 --> 00:12:46.600]   meet in your life.
[00:12:46.600 --> 00:12:48.600]   Am I correct? In your life.
[00:12:48.600 --> 00:12:50.600]   You could not be more low-key
[00:12:50.600 --> 00:12:52.600]   and self-effacing than Robo and Kuhn
[00:12:52.600 --> 00:12:54.600]   for how good they are.
[00:12:54.600 --> 00:12:56.600]   If you were honestly going to rank the three
[00:12:56.600 --> 00:12:58.600]   of them in a high-stakes cash game,
[00:12:58.600 --> 00:13:00.600]   could you just handicap it for the audience?
[00:13:00.600 --> 00:13:02.600]   Because we're in the lucky position,
[00:13:02.600 --> 00:13:04.600]   to play with these three epic
[00:13:04.600 --> 00:13:06.600]   players in the world.
[00:13:06.600 --> 00:13:08.600]   Break down how they play in a home game
[00:13:08.600 --> 00:13:10.600]   like ours.
[00:13:10.600 --> 00:13:16.600]   I would say the most
[00:13:16.600 --> 00:13:18.600]   dynamic
[00:13:18.600 --> 00:13:20.600]   range would probably be
[00:13:20.600 --> 00:13:22.600]   Robo, because Robo has the most experience
[00:13:22.600 --> 00:13:24.600]   playing super, super high-stakes cash.
[00:13:24.600 --> 00:13:26.600]   I think Kuhn
[00:13:26.600 --> 00:13:28.600]   is the most
[00:13:28.600 --> 00:13:30.600]   precise
[00:13:30.600 --> 00:13:32.600]   and
[00:13:32.600 --> 00:13:36.600]   true to GTO.
[00:13:36.600 --> 00:13:38.600]   Hard to exploit.
[00:13:38.600 --> 00:13:40.600]   Kuhn is impossible to exploit.
[00:13:40.600 --> 00:13:42.600]   No mistakes.
[00:13:42.600 --> 00:13:44.600]   Robo knows how to
[00:13:44.600 --> 00:13:46.600]   gamble in certain spots. Kuhn knows
[00:13:46.600 --> 00:13:48.600]   how to be unexploitable.
[00:13:48.600 --> 00:13:50.600]   And the third player is Phil Helmuth.
[00:13:50.600 --> 00:13:52.600]   And the third person is Helmuth.
[00:13:52.600 --> 00:13:54.600]   And Helmuth just loses his mind
[00:13:54.600 --> 00:13:56.600]   in his setup.
[00:13:56.600 --> 00:13:58.600]   No, the thing with Helmuth is
[00:13:58.600 --> 00:14:00.600]   he's capable, unlike anyone
[00:14:00.600 --> 00:14:02.600]   I've ever seen, of folding in spots
[00:14:02.600 --> 00:14:04.600]   that are... and he's correct, by the way.
[00:14:04.600 --> 00:14:06.600]   I've seen Helmuth fold Ace-King
[00:14:06.600 --> 00:14:08.600]   in spots that none of us would ever do it.
[00:14:08.600 --> 00:14:10.600]   I've seen him fold Kings in spots that are basically
[00:14:10.600 --> 00:14:12.600]   impossible. So Helmuth is able
[00:14:12.600 --> 00:14:14.600]   to get these soul reads on people that I think
[00:14:14.600 --> 00:14:16.600]   are amazing.
[00:14:16.600 --> 00:14:18.600]   But look,
[00:14:18.600 --> 00:14:20.600]   the
[00:14:20.600 --> 00:14:22.600]   higher and higher the stakes get,
[00:14:22.600 --> 00:14:24.600]   the more and more I think Robo
[00:14:24.600 --> 00:14:26.600]   will be comfortable and Kuhn
[00:14:26.600 --> 00:14:28.600]   will just go to a playbook that he knows
[00:14:28.600 --> 00:14:30.600]   and trusts.
[00:14:30.600 --> 00:14:32.600]   I am so excited to be
[00:14:32.600 --> 00:14:34.600]   back at the game tonight. Alright,
[00:14:34.600 --> 00:14:36.600]   listen, the docket is so great
[00:14:36.600 --> 00:14:38.600]   this week. We've got a great classic all-in docket.
[00:14:38.600 --> 00:14:40.600]   I want to start with Google
[00:14:40.600 --> 00:14:42.600]   firing 28 employees who were involved
[00:14:42.600 --> 00:14:44.600]   in this protest at their offices.
[00:14:44.600 --> 00:14:46.600]   We didn't think that this would
[00:14:46.600 --> 00:14:48.600]   happen. We were having a discussion on the group chat.
[00:14:48.600 --> 00:14:50.600]   On Tuesday, about a dozen employees
[00:14:50.600 --> 00:14:52.600]   engaged in sit-ins at the company's offices
[00:14:52.600 --> 00:14:54.600]   in Sunnyvale and New York City,
[00:14:54.600 --> 00:14:56.600]   protesting
[00:14:56.600 --> 00:14:58.600]   the conflict in the Middle East
[00:14:58.600 --> 00:15:00.600]   between Israel and Palestine.
[00:15:00.600 --> 00:15:02.600]   And so,
[00:15:02.600 --> 00:15:04.600]   they took over, literally took over
[00:15:04.600 --> 00:15:06.600]   the offices of the CEO of Google
[00:15:06.600 --> 00:15:08.600]   Cloud, and nine employees
[00:15:08.600 --> 00:15:10.600]   were arrested after refusing to leave.
[00:15:10.600 --> 00:15:12.600]   The protest was organized by a group called
[00:15:12.600 --> 00:15:14.600]   No Tech for Apartheid,
[00:15:14.600 --> 00:15:16.600]   and they posted a bunch of clips
[00:15:16.600 --> 00:15:18.600]   of this sit-in on X.
[00:15:18.600 --> 00:15:20.600]   Those 28 employees
[00:15:20.600 --> 00:15:22.600]   were fired on Wednesday
[00:15:22.600 --> 00:15:24.600]   after a quick investigation.
[00:15:24.600 --> 00:15:26.600]   The VP of Global Security
[00:15:26.600 --> 00:15:28.600]   was pretty direct and
[00:15:28.600 --> 00:15:30.600]   candid. I mean, this is
[00:15:30.600 --> 00:15:32.600]   based. They took over
[00:15:32.600 --> 00:15:34.600]   office spaces, defaced our property,
[00:15:34.600 --> 00:15:36.600]   and physically impeded the work
[00:15:36.600 --> 00:15:38.600]   of other Googlers. Behavior like this
[00:15:38.600 --> 00:15:40.600]   has no place in our workplace,
[00:15:40.600 --> 00:15:42.600]   and we will not tolerate it.
[00:15:42.600 --> 00:15:44.600]   If you're one of the few who are tempted
[00:15:44.600 --> 00:15:46.600]   to think we're going to overlook conduct
[00:15:46.600 --> 00:15:48.600]   that violates our policies, think again.
[00:15:48.600 --> 00:15:50.600]   So, what were the protests about?
[00:15:50.600 --> 00:15:52.600]   Google is involved in a project,
[00:15:52.600 --> 00:15:54.600]   Nimbus, a $1.2 billion
[00:15:54.600 --> 00:15:56.600]   cloud contract with Israel's government.
[00:15:56.600 --> 00:15:58.600]   Both Google and Amazon are involved
[00:15:58.600 --> 00:16:00.600]   in the project, which was announced in 2021.
[00:16:00.600 --> 00:16:02.600]   Google has denied it was doing work for the
[00:16:02.600 --> 00:16:04.600]   military, saying it was
[00:16:04.600 --> 00:16:06.600]   working with departments like finance, healthcare,
[00:16:06.600 --> 00:16:08.600]   transportation. There's a lot of details
[00:16:08.600 --> 00:16:10.600]   to this, but let's start with you, Freeberg, since
[00:16:10.600 --> 00:16:12.600]   you were a Googler, and we've been
[00:16:12.600 --> 00:16:14.600]   talking about the culture of Google. Putting aside
[00:16:14.600 --> 00:16:16.600]   what the protests were about,
[00:16:16.600 --> 00:16:18.600]   how do you feel about
[00:16:18.600 --> 00:16:20.600]   protests in the workplace?
[00:16:20.600 --> 00:16:22.600]   We've talked about it before here
[00:16:22.600 --> 00:16:24.600]   with Coinbase and others. And then,
[00:16:24.600 --> 00:16:26.600]   is this
[00:16:26.600 --> 00:16:28.600]   a distinct change in tone
[00:16:28.600 --> 00:16:30.600]   that I'm hearing from Google, that
[00:16:30.600 --> 00:16:32.600]   they've had enough of social
[00:16:32.600 --> 00:16:34.600]   activism at the office?
[00:16:34.600 --> 00:16:38.600]   Yeah, there's obviously
[00:16:38.600 --> 00:16:40.600]   a line crossed in the
[00:16:40.600 --> 00:16:42.600]   view of
[00:16:42.600 --> 00:16:44.600]   security, but
[00:16:44.600 --> 00:16:46.600]   I think you could look at this
[00:16:46.600 --> 00:16:48.600]   two ways.
[00:16:48.600 --> 00:16:50.600]   You could look at this as being a culture
[00:16:50.600 --> 00:16:52.600]   of entitlement that
[00:16:52.600 --> 00:16:54.600]   let folks feel that our employees,
[00:16:54.600 --> 00:16:56.600]   that they have permission
[00:16:56.600 --> 00:16:58.600]   to stage sit-ins
[00:16:58.600 --> 00:17:00.600]   and behaviors like this because Google
[00:17:00.600 --> 00:17:02.600]   is so infinitely tolerant
[00:17:02.600 --> 00:17:04.600]   in giving employees
[00:17:04.600 --> 00:17:06.600]   the space and the
[00:17:06.600 --> 00:17:08.600]   room to do whatever they want
[00:17:08.600 --> 00:17:10.600]   to do, and all of their wishes and demands
[00:17:10.600 --> 00:17:12.600]   can be met and will be met
[00:17:12.600 --> 00:17:14.600]   if they demand it strongly enough.
[00:17:14.600 --> 00:17:16.600]   That's one way to look at this,
[00:17:16.600 --> 00:17:18.600]   and that culture manifested
[00:17:18.600 --> 00:17:20.600]   this behavior. Another
[00:17:20.600 --> 00:17:22.600]   way to look at it is that these people feel so deeply,
[00:17:22.600 --> 00:17:24.600]   strongly, and passionately about the issue
[00:17:24.600 --> 00:17:26.600]   at hand that they were willing to
[00:17:26.600 --> 00:17:28.600]   risk their jobs and arrest,
[00:17:28.600 --> 00:17:30.600]   and they cared so deeply about
[00:17:30.600 --> 00:17:32.600]   an issue that they think no one's paying enough attention
[00:17:32.600 --> 00:17:34.600]   to that they're willing to put themselves and sacrifice
[00:17:34.600 --> 00:17:36.600]   themselves for it. So,
[00:17:36.600 --> 00:17:38.600]   I want to be empathetic to that point of view
[00:17:38.600 --> 00:17:40.600]   as well, but I
[00:17:40.600 --> 00:17:42.600]   do think that there's
[00:17:42.600 --> 00:17:44.600]   a belief that there may have been this
[00:17:44.600 --> 00:17:46.600]   kind of entitlement
[00:17:46.600 --> 00:17:48.600]   culture where anytime Google employees
[00:17:48.600 --> 00:17:50.600]   ask for stuff, they get it.
[00:17:50.600 --> 00:17:52.600]   Someone told me the other day how
[00:17:52.600 --> 00:17:54.600]   TGIFs at Google now, where they
[00:17:54.600 --> 00:17:56.600]   do these all-hands and people get to ask questions,
[00:17:56.600 --> 00:17:58.600]   this person is kind of executive-level.
[00:17:58.600 --> 00:18:00.600]   They're so sick and tired of
[00:18:00.600 --> 00:18:02.600]   how every question is all about
[00:18:02.600 --> 00:18:04.600]   employees asking for more things that they
[00:18:04.600 --> 00:18:06.600]   want. So, it's like,
[00:18:06.600 --> 00:18:08.600]   "When are we going to get this bonus? When are we
[00:18:08.600 --> 00:18:10.600]   going to get this GM? When are we going to get this?"
[00:18:10.600 --> 00:18:12.600]   But so much of the orientation of being
[00:18:12.600 --> 00:18:14.600]   an employee at Google is all about what
[00:18:14.600 --> 00:18:16.600]   Google can do for me and
[00:18:16.600 --> 00:18:18.600]   how I can get more, and
[00:18:18.600 --> 00:18:20.600]   that becomes what you ask for. It's like, you give a
[00:18:20.600 --> 00:18:22.600]   kid something, you give them candy, they'll always ask for candy.
[00:18:22.600 --> 00:18:24.600]   And I think that
[00:18:24.600 --> 00:18:26.600]   there is certainly an element of that culture
[00:18:26.600 --> 00:18:28.600]   kind of being
[00:18:28.600 --> 00:18:30.600]   frothed up over the years at Google.
[00:18:30.600 --> 00:18:32.600]   But I do think that this is an issue
[00:18:32.600 --> 00:18:34.600]   that people care very passionately about right now,
[00:18:34.600 --> 00:18:36.600]   and you're seeing it all over the place.
[00:18:36.600 --> 00:18:38.600]   So, certainly not... In the same
[00:18:38.600 --> 00:18:40.600]   way we had the Golden Gate Bridge
[00:18:40.600 --> 00:18:42.600]   get shut down, the Bay Bridge get shut down
[00:18:42.600 --> 00:18:44.600]   as well. Chamath, your thoughts on these
[00:18:44.600 --> 00:18:46.600]   protests, and then obviously
[00:18:46.600 --> 00:18:48.600]   the entitlement issues
[00:18:48.600 --> 00:18:50.600]   that Freeberg alludes to specifically
[00:18:50.600 --> 00:18:52.600]   at Alphabet/Google.
[00:18:52.600 --> 00:18:54.600]   They're two separate things, and I think
[00:18:54.600 --> 00:18:56.600]   it's important to deal with them
[00:18:56.600 --> 00:18:58.600]   individually.
[00:18:58.600 --> 00:19:00.600]   Groups of people in society
[00:19:00.600 --> 00:19:02.600]   in a democracy should have a right
[00:19:02.600 --> 00:19:04.600]   to protest. That's
[00:19:04.600 --> 00:19:06.600]   absolutely fundamental, and
[00:19:06.600 --> 00:19:08.600]   they can raise a lot of issues
[00:19:08.600 --> 00:19:10.600]   that could otherwise get swept under the carpet.
[00:19:10.600 --> 00:19:12.600]   When that stuff impedes
[00:19:12.600 --> 00:19:14.600]   the public functioning of society
[00:19:14.600 --> 00:19:16.600]   for other people, then I think
[00:19:16.600 --> 00:19:18.600]   there's a responsibility
[00:19:18.600 --> 00:19:20.600]   for law enforcement
[00:19:20.600 --> 00:19:22.600]   and other people to act, and
[00:19:22.600 --> 00:19:24.600]   make sure that that is
[00:19:24.600 --> 00:19:26.600]   better managed. So,
[00:19:26.600 --> 00:19:28.600]   shutting down an entire bridge
[00:19:28.600 --> 00:19:30.600]   is not only disruptive,
[00:19:30.600 --> 00:19:32.600]   it can be really dangerous.
[00:19:32.600 --> 00:19:34.600]   Of course. And it can hurt your cause.
[00:19:34.600 --> 00:19:36.600]   Because then people dislike the cause
[00:19:36.600 --> 00:19:38.600]   because it hurt them. Right. Typically what happens
[00:19:38.600 --> 00:19:40.600]   is you're supposed to file for a permit
[00:19:40.600 --> 00:19:42.600]   to protest, and when you get that,
[00:19:42.600 --> 00:19:44.600]   there are areas that are cordoned off, and then people
[00:19:44.600 --> 00:19:46.600]   are allowed to express their views. That's a really healthy
[00:19:46.600 --> 00:19:48.600]   form of democracy. Going
[00:19:48.600 --> 00:19:50.600]   rogue like this will only blow up in people's
[00:19:50.600 --> 00:19:52.600]   faces because the folks that are
[00:19:52.600 --> 00:19:54.600]   somewhat sympathetic will eventually get
[00:19:54.600 --> 00:19:56.600]   burned by this experience and turn against them.
[00:19:56.600 --> 00:19:58.600]   So that's one set of issues. I think that's
[00:19:58.600 --> 00:20:00.600]   just people going rogue, and I
[00:20:00.600 --> 00:20:02.600]   think that you can't be tolerant of that
[00:20:02.600 --> 00:20:04.600]   kind of chaos. There should be organized
[00:20:04.600 --> 00:20:06.600]   protests, but not disorganized
[00:20:06.600 --> 00:20:08.600]   chaos. And law enforcement needs
[00:20:08.600 --> 00:20:10.600]   to get a control of that.
[00:20:10.600 --> 00:20:12.600]   Inside of a company, I think this is different.
[00:20:12.600 --> 00:20:14.600]   It's this weird thing that I see, which is like
[00:20:14.600 --> 00:20:16.600]   what I would call left-on-left violence.
[00:20:16.600 --> 00:20:18.600]   It's like left-leaning people
[00:20:18.600 --> 00:20:20.600]   creating all of these
[00:20:20.600 --> 00:20:22.600]   distractions and demonstrations inside
[00:20:22.600 --> 00:20:24.600]   of left-leaning organizations for not being
[00:20:24.600 --> 00:20:26.600]   left-leaning enough.
[00:20:26.600 --> 00:20:28.600]   And so it's kind of like a little
[00:20:28.600 --> 00:20:30.600]   bit nutty, because I think
[00:20:30.600 --> 00:20:32.600]   actually shows how totally naive
[00:20:32.600 --> 00:20:34.600]   these employees are and what
[00:20:34.600 --> 00:20:36.600]   basic business understanding they
[00:20:36.600 --> 00:20:38.600]   have. The first and foremost
[00:20:38.600 --> 00:20:40.600]   being that they are at-will employees.
[00:20:40.600 --> 00:20:42.600]   These are not people that are
[00:20:42.600 --> 00:20:44.600]   contracted players in the NBA or
[00:20:44.600 --> 00:20:46.600]   are part of a union,
[00:20:46.600 --> 00:20:48.600]   okay, where you have guaranteed employment
[00:20:48.600 --> 00:20:50.600]   through some mechanism or some arbitration
[00:20:50.600 --> 00:20:52.600]   process to even be let go.
[00:20:52.600 --> 00:20:54.600]   The fact that you don't even understand that you
[00:20:54.600 --> 00:20:56.600]   are at-will means that you are there because
[00:20:56.600 --> 00:20:58.600]   you want to be there, and Google allows
[00:20:58.600 --> 00:21:00.600]   you to be there because they choose for you to be there,
[00:21:00.600 --> 00:21:02.600]   and at any point, if either of you break a covenant,
[00:21:02.600 --> 00:21:04.600]   you can be gone.
[00:21:04.600 --> 00:21:06.600]   That kind of stuff, I think, is
[00:21:06.600 --> 00:21:08.600]   very distracting, and it just belies a
[00:21:08.600 --> 00:21:10.600]   poor understanding of what you're
[00:21:10.600 --> 00:21:12.600]   there to do. Google is a
[00:21:12.600 --> 00:21:14.600]   for-profit business, and they are
[00:21:14.600 --> 00:21:16.600]   in the business of generating maximum
[00:21:16.600 --> 00:21:18.600]   profit on behalf of their shareholders.
[00:21:18.600 --> 00:21:20.600]   They are also incentivized
[00:21:20.600 --> 00:21:22.600]   to do that in a way that achieves a
[00:21:22.600 --> 00:21:24.600]   mission and a set of values that the majority
[00:21:24.600 --> 00:21:26.600]   of their employees
[00:21:26.600 --> 00:21:28.600]   agree with, and the fact that
[00:21:28.600 --> 00:21:30.600]   a small cohort of people
[00:21:30.600 --> 00:21:32.600]   can try to hijack and sabotage
[00:21:32.600 --> 00:21:34.600]   that overall direction, I think,
[00:21:34.600 --> 00:21:36.600]   is very misguided.
[00:21:36.600 --> 00:21:38.600]   Saks,
[00:21:38.600 --> 00:21:40.600]   I don't know if you have
[00:21:40.600 --> 00:21:42.600]   any opinions on this. I didn't see anything in the docket.
[00:21:42.600 --> 00:21:44.600]   I'm not sure if you have any strong feelings here,
[00:21:44.600 --> 00:21:46.600]   but your thoughts on Google
[00:21:46.600 --> 00:21:48.600]   employees and the protest, putting aside
[00:21:48.600 --> 00:21:50.600]   the nature
[00:21:50.600 --> 00:21:52.600]   of the protest. This could be for BLM.
[00:21:52.600 --> 00:21:54.600]   This could be for Trump's indictments.
[00:21:54.600 --> 00:21:56.600]   You could be protesting any number of things,
[00:21:56.600 --> 00:21:58.600]   but the protesting at work issue
[00:21:58.600 --> 00:22:00.600]   and then Google specifically,
[00:22:00.600 --> 00:22:02.600]   which we talked about, with the Gemini
[00:22:02.600 --> 00:22:04.600]   issues and
[00:22:04.600 --> 00:22:06.600]   this stuff bleeding over into product.
[00:22:06.600 --> 00:22:08.600]   I think Freeberg said it really nicely.
[00:22:08.600 --> 00:22:10.600]   Hey, are people
[00:22:10.600 --> 00:22:12.600]   actually focused on products at Google
[00:22:12.600 --> 00:22:14.600]   anymore, or is the whole place
[00:22:14.600 --> 00:22:16.600]   just focused on social
[00:22:16.600 --> 00:22:18.600]   issues that have nothing to do with
[00:22:18.600 --> 00:22:20.600]   their waning, apparently, product set?
[00:22:20.600 --> 00:22:22.600]   Well, Google had no choice
[00:22:22.600 --> 00:22:24.600]   but to fire these employees.
[00:22:24.600 --> 00:22:26.600]   They were being disruptive,
[00:22:26.600 --> 00:22:28.600]   and they were trespassing, and Google has
[00:22:28.600 --> 00:22:30.600]   a business to run, so this is what any
[00:22:30.600 --> 00:22:32.600]   business would do, and I don't think they deserve
[00:22:32.600 --> 00:22:34.600]   either credit or blame for
[00:22:34.600 --> 00:22:36.600]   taking the action they took.
[00:22:36.600 --> 00:22:38.600]   In terms of the protesters themselves,
[00:22:38.600 --> 00:22:40.600]   I think that
[00:22:40.600 --> 00:22:42.600]   in the fullness of
[00:22:42.600 --> 00:22:44.600]   time, we may come to think of them
[00:22:44.600 --> 00:22:46.600]   in a slightly different light,
[00:22:46.600 --> 00:22:48.600]   and some of this reminds me
[00:22:48.600 --> 00:22:50.600]   a little bit of another war.
[00:22:50.600 --> 00:22:52.600]   The protesters in another war,
[00:22:52.600 --> 00:22:54.600]   the Vietnam War, where
[00:22:54.600 --> 00:22:56.600]   they were very disruptive. In some
[00:22:56.600 --> 00:22:58.600]   cases, they trespassed. In some cases, they got
[00:22:58.600 --> 00:23:00.600]   arrested. They were easy to
[00:23:00.600 --> 00:23:02.600]   make fun of in terms of what they look like.
[00:23:02.600 --> 00:23:04.600]   They were sort of unkempt,
[00:23:04.600 --> 00:23:06.600]   unshaven, all the rest of that stuff. They were hippies.
[00:23:06.600 --> 00:23:08.600]   And at the time,
[00:23:08.600 --> 00:23:10.600]   people were, I'd say,
[00:23:10.600 --> 00:23:12.600]   very dismissive of them or
[00:23:12.600 --> 00:23:14.600]   actually antagonistic. They were seen as giving
[00:23:14.600 --> 00:23:16.600]   aid and comfort to the enemy, and they were
[00:23:16.600 --> 00:23:18.600]   sort of demonized.
[00:23:18.600 --> 00:23:20.600]   But now, in the fullness of time, we look back
[00:23:20.600 --> 00:23:22.600]   on that war and realize that they had a
[00:23:22.600 --> 00:23:24.600]   point. In fact, maybe they were right.
[00:23:24.600 --> 00:23:26.600]   In fact, maybe their actions
[00:23:26.600 --> 00:23:28.600]   were justified.
[00:23:28.600 --> 00:23:30.600]   And I think that how we
[00:23:30.600 --> 00:23:32.600]   view these protesters at Google can't
[00:23:32.600 --> 00:23:34.600]   just be judged now. I think it's going to be judged in the fullness
[00:23:34.600 --> 00:23:36.600]   of time based on how we perceive
[00:23:36.600 --> 00:23:38.600]   this war in Gaza. And I want to make
[00:23:38.600 --> 00:23:40.600]   two points about why I think
[00:23:40.600 --> 00:23:42.600]   this war will eventually be
[00:23:42.600 --> 00:23:44.600]   viewed as Israel's Vietnam.
[00:23:44.600 --> 00:23:46.600]   The first is that
[00:23:46.600 --> 00:23:48.600]   in Gaza, Israel faces
[00:23:48.600 --> 00:23:52.600]   a guerrilla-style force,
[00:23:52.600 --> 00:23:54.600]   and they're in a quagmire.
[00:23:54.600 --> 00:23:56.600]   And if you read the latest
[00:23:56.600 --> 00:23:58.600]   news that's coming out of Gaza,
[00:23:58.600 --> 00:24:00.600]   what you'll hear is that
[00:24:00.600 --> 00:24:02.600]   after Israel has supposedly
[00:24:02.600 --> 00:24:04.600]   cleared an area like Gaza City
[00:24:04.600 --> 00:24:06.600]   or Khan Yunis, they then
[00:24:06.600 --> 00:24:08.600]   move south, Hamas has
[00:24:08.600 --> 00:24:10.600]   popped back up again. This whole idea
[00:24:10.600 --> 00:24:12.600]   that they can clear an area has
[00:24:12.600 --> 00:24:14.600]   been proven false. It's like playing whack-a-mole.
[00:24:14.600 --> 00:24:16.600]   They basically hit Hamas in one
[00:24:16.600 --> 00:24:18.600]   area, Hamas disappears
[00:24:18.600 --> 00:24:20.600]   down the tunnels, they come back in a different area.
[00:24:20.600 --> 00:24:22.600]   And this is why you're seeing a lot of articles
[00:24:22.600 --> 00:24:24.600]   now in Haaretz, which is an Israeli newspaper,
[00:24:24.600 --> 00:24:26.600]   saying the war in Gaza is already lost.
[00:24:26.600 --> 00:24:28.600]   You had the Wall Street Journal
[00:24:28.600 --> 00:24:30.600]   last week run an article
[00:24:30.600 --> 00:24:32.600]   saying that Israel is
[00:24:32.600 --> 00:24:34.600]   winning every battle but
[00:24:34.600 --> 00:24:36.600]   losing the war,
[00:24:36.600 --> 00:24:38.600]   which is, again, shades
[00:24:38.600 --> 00:24:40.600]   of Vietnam here. And you
[00:24:40.600 --> 00:24:42.600]   got to understand, the Wall Street Journal is the most
[00:24:42.600 --> 00:24:44.600]   pro-Israel of all the major mainstream
[00:24:44.600 --> 00:24:46.600]   publications. I don't think the Wall Street Journal
[00:24:46.600 --> 00:24:48.600]   has ever written a truly critical
[00:24:48.600 --> 00:24:50.600]   article about Israel. And they
[00:24:50.600 --> 00:24:52.600]   describe this whack-a-mole dynamic.
[00:24:52.600 --> 00:24:54.600]   You also have the general
[00:24:54.600 --> 00:24:56.600]   Gadi Eizenkopp, who's
[00:24:56.600 --> 00:24:58.600]   a member of
[00:24:58.600 --> 00:25:00.600]   the war cabinet. He's a member of the
[00:25:00.600 --> 00:25:02.600]   sort of war government in
[00:25:02.600 --> 00:25:04.600]   Israel, came out and said that we can
[00:25:04.600 --> 00:25:06.600]   degrade Hamas in Gaza, but we
[00:25:06.600 --> 00:25:08.600]   cannot destroy it. And he said, "Anyone
[00:25:08.600 --> 00:25:10.600]   who's telling you that we can destroy
[00:25:10.600 --> 00:25:12.600]   Hamas is telling you a tall tale." And that
[00:25:12.600 --> 00:25:14.600]   was, I think, an appointed reference
[00:25:14.600 --> 00:25:16.600]   to Netanyahu's claim that they would destroy
[00:25:16.600 --> 00:25:18.600]   Hamas in Gaza. So
[00:25:18.600 --> 00:25:20.600]   you've got shades of Vietnam
[00:25:20.600 --> 00:25:22.600]   in terms of it being this unwinnable war.
[00:25:22.600 --> 00:25:24.600]   I think the second aspect of
[00:25:24.600 --> 00:25:26.600]   a similarity to Vietnam
[00:25:26.600 --> 00:25:28.600]   is just the huge number of civilian
[00:25:28.600 --> 00:25:30.600]   casualties. You'll recall that
[00:25:30.600 --> 00:25:32.600]   in Vietnam, the Viet Cong tried to
[00:25:32.600 --> 00:25:34.600]   grab us by the belt buckle. They knew
[00:25:34.600 --> 00:25:36.600]   that America had superior firepower, so they
[00:25:36.600 --> 00:25:38.600]   tried to get in close,
[00:25:38.600 --> 00:25:40.600]   use ambushes, booby traps, snipers.
[00:25:40.600 --> 00:25:42.600]   And in response to that,
[00:25:42.600 --> 00:25:44.600]   the Americans used
[00:25:44.600 --> 00:25:46.600]   immense amounts of firepower and
[00:25:46.600 --> 00:25:48.600]   bombing to try and subdue
[00:25:48.600 --> 00:25:50.600]   the Vietnamese. And 3.4
[00:25:50.600 --> 00:25:52.600]   million Vietnamese
[00:25:52.600 --> 00:25:54.600]   were killed in that war, according to
[00:25:54.600 --> 00:25:56.600]   Robert McNamara.
[00:25:56.600 --> 00:25:58.600]   The second thing that happened is the rules of engagement
[00:25:58.600 --> 00:26:00.600]   in Vietnam got extremely loose.
[00:26:00.600 --> 00:26:02.600]   You took a bunch of scared American
[00:26:02.600 --> 00:26:04.600]   kids, many of whom were conscripts, you drop
[00:26:04.600 --> 00:26:06.600]   them in a jungle. Pretty much,
[00:26:06.600 --> 00:26:08.600]   because they feared ambushes, they shot anything
[00:26:08.600 --> 00:26:10.600]   that moved. And then finally, I think
[00:26:10.600 --> 00:26:12.600]   partly to justify this, you
[00:26:12.600 --> 00:26:14.600]   had a
[00:26:14.600 --> 00:26:16.600]   dehumanization of the Vietnamese
[00:26:16.600 --> 00:26:18.600]   that they were seen as somehow
[00:26:18.600 --> 00:26:20.600]   kind of subhuman. In any event,
[00:26:20.600 --> 00:26:22.600]   if you watch movies about Vietnam,
[00:26:22.600 --> 00:26:24.600]   like "Platoon," which was made by Oliver
[00:26:24.600 --> 00:26:26.600]   Stone, who was a GI in Vietnam, or if
[00:26:26.600 --> 00:26:28.600]   you watch
[00:26:28.600 --> 00:26:30.600]   Stanley Kubrick's masterpiece, "Full Metal Jacket,"
[00:26:30.600 --> 00:26:32.600]   which was based on books about Vietnam,
[00:26:32.600 --> 00:26:34.600]   you can see these dynamics in play
[00:26:34.600 --> 00:26:36.600]   very vividly. Now,
[00:26:36.600 --> 00:26:38.600]   turn to Gaza. All you gotta
[00:26:38.600 --> 00:26:40.600]   do is look at the miles and miles
[00:26:40.600 --> 00:26:42.600]   of video to see.
[00:26:42.600 --> 00:26:44.600]   It looks like a lunar surface. I mean,
[00:26:44.600 --> 00:26:46.600]   even in the words of Joe Biden,
[00:26:46.600 --> 00:26:48.600]   there's been indiscriminate bombing there. In terms
[00:26:48.600 --> 00:26:50.600]   of the rules of engagement, the rules of engagement
[00:26:50.600 --> 00:26:52.600]   have gotten very loose.
[00:26:52.600 --> 00:26:54.600]   A week or two ago, you had the deaths of those seven
[00:26:54.600 --> 00:26:56.600]   aid workers from the International
[00:26:56.600 --> 00:26:58.600]   Kitchen Organization.
[00:26:58.600 --> 00:27:00.600]   And there's an article in "Horetz"
[00:27:00.600 --> 00:27:02.600]   recently about the kill zones have been set up.
[00:27:02.600 --> 00:27:04.600]   Pretty much, if you come
[00:27:04.600 --> 00:27:06.600]   within a certain invisible perimeter of
[00:27:06.600 --> 00:27:08.600]   Israeli troops, you can be shot. I mean, those are the rules of
[00:27:08.600 --> 00:27:10.600]   engagement. And this is why there were three
[00:27:10.600 --> 00:27:12.600]   Israeli hostages who
[00:27:12.600 --> 00:27:14.600]   escaped. And they
[00:27:14.600 --> 00:27:16.600]   were running towards Israeli troops
[00:27:16.600 --> 00:27:18.600]   and yelling in Hebrew, and they still got shot.
[00:27:18.600 --> 00:27:20.600]   And again, this goes back to the rules of engagement
[00:27:20.600 --> 00:27:22.600]   being very loose. And then, the final
[00:27:22.600 --> 00:27:24.600]   piece of it is, you do have this dehumanization
[00:27:24.600 --> 00:27:26.600]   going on of
[00:27:26.600 --> 00:27:28.600]   the Palestinians. You can see this in a lot of the videos
[00:27:28.600 --> 00:27:30.600]   that have been posted by IDF soldiers. So,
[00:27:30.600 --> 00:27:32.600]   look, I think that
[00:27:32.600 --> 00:27:34.600]   these protesters, their actions are gonna
[00:27:34.600 --> 00:27:36.600]   be judged in the fullness of time.
[00:27:36.600 --> 00:27:38.600]   I think there are actually good
[00:27:38.600 --> 00:27:40.600]   reasons to believe
[00:27:40.600 --> 00:27:42.600]   that Israel's war in Gaza,
[00:27:42.600 --> 00:27:44.600]   its shades of Vietnam,
[00:27:44.600 --> 00:27:46.600]   and I think that over the long term,
[00:27:46.600 --> 00:27:48.600]   people may regard these protesters
[00:27:48.600 --> 00:27:50.600]   in a different light. Right now, they're just seeing as
[00:27:50.600 --> 00:27:52.600]   being disruptive and annoying
[00:27:52.600 --> 00:27:54.600]   and interfering.
[00:27:54.600 --> 00:27:56.600]   But if this war ends up
[00:27:56.600 --> 00:27:58.600]   being Israel's Vietnam,
[00:27:58.600 --> 00:28:00.600]   which I think it's on track to be,
[00:28:00.600 --> 00:28:02.600]   again, I think that people may, in time,
[00:28:02.600 --> 00:28:04.600]   give these protesters a little bit more credit.
[00:28:04.600 --> 00:28:06.600]   Jacob, what do you think?
[00:28:06.600 --> 00:28:08.600]   Interesting question.
[00:28:08.600 --> 00:28:10.600]   Putting aside what they're protesting
[00:28:10.600 --> 00:28:12.600]   about, I think they knew,
[00:28:12.600 --> 00:28:14.600]   or some number of them
[00:28:14.600 --> 00:28:16.600]   knew they were gonna get fired. So,
[00:28:16.600 --> 00:28:18.600]   I think they're kind of resigning by sit-in.
[00:28:18.600 --> 00:28:20.600]   And I think, yeah, there could be
[00:28:20.600 --> 00:28:22.600]   nobility to that. If you do not
[00:28:22.600 --> 00:28:24.600]   want to participate
[00:28:24.600 --> 00:28:26.600]   in supporting things in the world, you do not
[00:28:26.600 --> 00:28:28.600]   have to work at Google, and you can
[00:28:28.600 --> 00:28:30.600]   protest, and you can get fired.
[00:28:30.600 --> 00:28:32.600]   And we've seen, like, some pretty intense
[00:28:32.600 --> 00:28:34.600]   protests. I don't know if you guys are aware of, like,
[00:28:34.600 --> 00:28:36.600]   what Greenpeace and other environmentalists
[00:28:36.600 --> 00:28:38.600]   did to stop whaling. I'm sure
[00:28:38.600 --> 00:28:40.600]   you are aware, Friedberg, for your passion
[00:28:40.600 --> 00:28:42.600]   on this subject. Those
[00:28:42.600 --> 00:28:44.600]   people went to jail in Japan
[00:28:44.600 --> 00:28:46.600]   for boarding Japanese whaling ships.
[00:28:46.600 --> 00:28:48.600]   Like, those are really intense protesters.
[00:28:48.600 --> 00:28:50.600]   But then, to your point, Shamaf,
[00:28:50.600 --> 00:28:52.600]   you know, you can really hurt
[00:28:52.600 --> 00:28:54.600]   your cause.
[00:28:54.600 --> 00:28:56.600]   Climate activists have been throwing paint
[00:28:56.600 --> 00:28:58.600]   on works of art. I don't know if you've seen that.
[00:28:58.600 --> 00:29:00.600]   And that's just infuriating. Like,
[00:29:00.600 --> 00:29:02.600]   I have no tolerance for
[00:29:02.600 --> 00:29:04.600]   people destroying works of art or
[00:29:04.600 --> 00:29:06.600]   attempting to get attention. Here,
[00:29:06.600 --> 00:29:08.600]   it is benign to sit in an office
[00:29:08.600 --> 00:29:10.600]   and get fired.
[00:29:10.600 --> 00:29:12.600]   So, I just consider it resigning by sit-in.
[00:29:12.600 --> 00:29:14.600]   If they want to do that, that's fine. I do think
[00:29:14.600 --> 00:29:16.600]   there is something to Google enabling all
[00:29:16.600 --> 00:29:18.600]   this, to your point, Friedberg,
[00:29:18.600 --> 00:29:20.600]   over time. And, listen, they were
[00:29:20.600 --> 00:29:22.600]   parodied on
[00:29:22.600 --> 00:29:24.600]   Silicon Valley, the TV show, because
[00:29:24.600 --> 00:29:26.600]   of how coddled and entitled
[00:29:26.600 --> 00:29:28.600]   people are. So, there's a bunch
[00:29:28.600 --> 00:29:30.600]   of things going on at the same time. And,
[00:29:30.600 --> 00:29:32.600]   you know, if you want to
[00:29:32.600 --> 00:29:34.600]   do these intense protests, you have the right
[00:29:34.600 --> 00:29:36.600]   to do them. And history will
[00:29:36.600 --> 00:29:38.600]   judge you over time. But you
[00:29:38.600 --> 00:29:40.600]   need to be able to pay the price. In this case,
[00:29:40.600 --> 00:29:42.600]   the price is getting fired.
[00:29:42.600 --> 00:29:44.600]   In the case of, like, shutting down the Golden Gate Bridge,
[00:29:44.600 --> 00:29:46.600]   like, you should get a fine for doing that,
[00:29:46.600 --> 00:29:48.600]   I believe. And the fine should be based
[00:29:48.600 --> 00:29:50.600]   on whatever that costs to shut that bridge down.
[00:29:50.600 --> 00:29:52.600]   And that's got to be
[00:29:52.600 --> 00:29:54.600]   a serious fine. And you're right,
[00:29:54.600 --> 00:29:56.600]   Shamaab, people, if there's an emergency
[00:29:56.600 --> 00:29:58.600]   situation, somebody's got to get to a hospital
[00:29:58.600 --> 00:30:00.600]   or something. That's what I always think about
[00:30:00.600 --> 00:30:02.600]   when I see those things, when you block streets
[00:30:02.600 --> 00:30:04.600]   and stuff, or you block airports, or you block
[00:30:04.600 --> 00:30:06.600]   these throughways. There's a lot
[00:30:06.600 --> 00:30:08.600]   of just normal, everyday people trying to live
[00:30:08.600 --> 00:30:10.600]   their life who are probably very sympathetic
[00:30:10.600 --> 00:30:12.600]   to what you stand for.
[00:30:12.600 --> 00:30:14.600]   But when you disrupt their everyday lives
[00:30:14.600 --> 00:30:16.600]   and/or threaten their
[00:30:16.600 --> 00:30:18.600]   physical security,
[00:30:18.600 --> 00:30:20.600]   they're not going to think that that's worth it.
[00:30:20.600 --> 00:30:22.600]   I'm also shocked
[00:30:22.600 --> 00:30:24.600]   that these people actually came to an office.
[00:30:24.600 --> 00:30:26.600]   I mean, these Googlers, I don't think they've actually
[00:30:26.600 --> 00:30:28.600]   been to an office before. They probably had to check that their
[00:30:28.600 --> 00:30:30.600]   badges work. Well, you know, to Sax's
[00:30:30.600 --> 00:30:32.600]   point, I actually would have had
[00:30:32.600 --> 00:30:34.600]   more respect for these people if
[00:30:34.600 --> 00:30:36.600]   they actually protested
[00:30:36.600 --> 00:30:38.600]   the war. But they didn't do that.
[00:30:38.600 --> 00:30:40.600]   They had a very discreet, specific
[00:30:40.600 --> 00:30:42.600]   claim, which was that they wanted to
[00:30:42.600 --> 00:30:44.600]   dissolve a business deal
[00:30:44.600 --> 00:30:46.600]   that Google had to provide cloud
[00:30:46.600 --> 00:30:48.600]   services to the State of Israel
[00:30:48.600 --> 00:30:50.600]   called Project Nimbus. And I think
[00:30:50.600 --> 00:30:52.600]   that's such a discreet thing
[00:30:52.600 --> 00:30:54.600]   that it's hard to understand
[00:30:54.600 --> 00:30:56.600]   that those 28 people would have
[00:30:56.600 --> 00:30:58.600]   even enough knowledge of what that is.
[00:30:58.600 --> 00:31:00.600]   But it sounds like a cloud
[00:31:00.600 --> 00:31:02.600]   hosting deal. Well, what's hosted there?
[00:31:02.600 --> 00:31:04.600]   And it could be any number of things.
[00:31:04.600 --> 00:31:06.600]   And I suspect if it's a billion-dollar-a-year deal,
[00:31:06.600 --> 00:31:08.600]   it's many things. It's probably like the
[00:31:08.600 --> 00:31:10.600]   Israeli DMV. Is that really what you
[00:31:10.600 --> 00:31:12.600]   want? And I think that it would have been
[00:31:12.600 --> 00:31:14.600]   much of a
[00:31:14.600 --> 00:31:16.600]   more powerful thing to do
[00:31:16.600 --> 00:31:18.600]   to protest the actual war if that's what
[00:31:18.600 --> 00:31:20.600]   they cared about. You know, it dovetails nicely
[00:31:20.600 --> 00:31:22.600]   with the discussion you all had last week about
[00:31:22.600 --> 00:31:24.600]   would you back
[00:31:24.600 --> 00:31:26.600]   a, not a defensive, but an
[00:31:26.600 --> 00:31:28.600]   offensive weapons company, a technology
[00:31:28.600 --> 00:31:30.600]   company. And it seemed
[00:31:30.600 --> 00:31:32.600]   like you all had reservations
[00:31:32.600 --> 00:31:34.600]   on if you would not back a defensive
[00:31:34.600 --> 00:31:36.600]   one. Anybody, I think, reasonably
[00:31:36.600 --> 00:31:38.600]   would back a defensive
[00:31:38.600 --> 00:31:40.600]   dome or interception
[00:31:40.600 --> 00:31:42.600]   of bombs coming in. That's an easy one.
[00:31:42.600 --> 00:31:44.600]   But going around the horn
[00:31:44.600 --> 00:31:46.600]   here, how many of us would
[00:31:46.600 --> 00:31:48.600]   back a company making
[00:31:48.600 --> 00:31:50.600]   missiles or bombs
[00:31:50.600 --> 00:31:52.600]   that blow people up
[00:31:52.600 --> 00:31:54.600]   or mines? Would you back
[00:31:54.600 --> 00:31:56.600]   a robot that had
[00:31:56.600 --> 00:31:58.600]   weapon systems on it? I think if you
[00:31:58.600 --> 00:32:00.600]   want to summarize what we said last week, it's like
[00:32:00.600 --> 00:32:02.600]   there are all kinds of businesses
[00:32:02.600 --> 00:32:04.600]   where you'll end up investing in it.
[00:32:04.600 --> 00:32:06.600]   And over time, as it morphs,
[00:32:06.600 --> 00:32:08.600]   some
[00:32:08.600 --> 00:32:10.600]   of us will be faced with some of those decisions.
[00:32:10.600 --> 00:32:12.600]   And it'll frankly depend
[00:32:12.600 --> 00:32:14.600]   on what is the alternative in
[00:32:14.600 --> 00:32:16.600]   that moment. So, I don't think
[00:32:16.600 --> 00:32:18.600]   anybody of us
[00:32:18.600 --> 00:32:20.600]   are going in to
[00:32:20.600 --> 00:32:22.600]   go and build a nuclear bomb. But
[00:32:22.600 --> 00:32:24.600]   you should not be naive that if you're building
[00:32:24.600 --> 00:32:26.600]   nuclear reactors,
[00:32:26.600 --> 00:32:28.600]   you could end up being in a situation
[00:32:28.600 --> 00:32:30.600]   where that thing gets licensed into
[00:32:30.600 --> 00:32:32.600]   a thing that you either agree or disagree with.
[00:32:32.600 --> 00:32:34.600]   So, this is my point, is I think
[00:32:34.600 --> 00:32:36.600]   that those kinds of answers
[00:32:36.600 --> 00:32:38.600]   or those kinds of questions
[00:32:38.600 --> 00:32:40.600]   are missing the nuances.
[00:32:40.600 --> 00:32:42.600]   And the nuances are very important.
[00:32:42.600 --> 00:32:44.600]   So, it's impossible to answer this question
[00:32:44.600 --> 00:32:46.600]   in a thoughtful way, I think, would be my
[00:32:46.600 --> 00:32:48.600]   honest answer. Okay. Sax, any closing
[00:32:48.600 --> 00:32:50.600]   thoughts here?
[00:32:50.600 --> 00:32:52.600]   Well, I think
[00:32:52.600 --> 00:32:54.600]   Chamath brings up an interesting point about
[00:32:54.600 --> 00:32:56.600]   why didn't the protesters
[00:32:56.600 --> 00:32:58.600]   just focus on the war itself rather than Google
[00:32:58.600 --> 00:33:00.600]   doing business with Israel?
[00:33:00.600 --> 00:33:02.600]   My interpretation of that is they're trying to create a nexus
[00:33:02.600 --> 00:33:04.600]   to themselves.
[00:33:04.600 --> 00:33:06.600]   Meaning, they're employees of Google. They're trying to
[00:33:06.600 --> 00:33:08.600]   create a reason for them to stage
[00:33:08.600 --> 00:33:10.600]   the sit-in at Google.
[00:33:10.600 --> 00:33:12.600]   Otherwise, you know, if they just
[00:33:12.600 --> 00:33:14.600]   grabbed picket signs and were on the street, it would just be
[00:33:14.600 --> 00:33:16.600]   much less newsworthy.
[00:33:16.600 --> 00:33:18.600]   So, I think they were just trying to create something newsworthy
[00:33:18.600 --> 00:33:20.600]   here, and it's kind of worked in the sense that
[00:33:20.600 --> 00:33:22.600]   we're talking about it, other people are talking
[00:33:22.600 --> 00:33:24.600]   about it. So, that's my interpretation
[00:33:24.600 --> 00:33:26.600]   of that, is
[00:33:26.600 --> 00:33:28.600]   they were just trying to elevate the
[00:33:28.600 --> 00:33:30.600]   issue in a slightly novel
[00:33:30.600 --> 00:33:32.600]   way. But look, I think that they should
[00:33:32.600 --> 00:33:34.600]   be willing to pay the price of
[00:33:34.600 --> 00:33:36.600]   getting fired or getting arrested. I mean, if
[00:33:36.600 --> 00:33:38.600]   you're going to engage in that kind of
[00:33:38.600 --> 00:33:40.600]   civil disobedience or protest, you should
[00:33:40.600 --> 00:33:42.600]   be willing to accept the price. And I
[00:33:42.600 --> 00:33:44.600]   did see some comments by
[00:33:44.600 --> 00:33:46.600]   the Googlers who got fired saying that they
[00:33:46.600 --> 00:33:48.600]   thought they were being treated unfairly by Google. I think
[00:33:48.600 --> 00:33:50.600]   that's the wrong attitude. I think
[00:33:50.600 --> 00:33:52.600]   the attitude is, "Hey, this
[00:33:52.600 --> 00:33:54.600]   cause is so important to me that I'm willing to
[00:33:54.600 --> 00:33:56.600]   accept the price of being fired."
[00:33:56.600 --> 00:33:58.600]   Saying that you don't deserve to be
[00:33:58.600 --> 00:34:00.600]   fired for disrupting the workplace.
[00:34:00.600 --> 00:34:02.600]   That is kind of an entitled attitude.
[00:34:02.600 --> 00:34:04.600]   So, I think they should have just said, "Yeah,
[00:34:04.600 --> 00:34:06.600]   we did this on purpose because
[00:34:06.600 --> 00:34:08.600]   it's a really important cause." They should say, "I'm proud to get
[00:34:08.600 --> 00:34:10.600]   fired because
[00:34:10.600 --> 00:34:12.600]   that's how much I believe in it. My stock options at
[00:34:12.600 --> 00:34:14.600]   Google are
[00:34:14.600 --> 00:34:16.600]   less important than this issue to me."
[00:34:16.600 --> 00:34:18.600]   And I accept them.
[00:34:18.600 --> 00:34:20.600]   I think they would have gotten just as much press if
[00:34:20.600 --> 00:34:22.600]   they actually protested the war. I
[00:34:22.600 --> 00:34:24.600]   think in a week from now, everybody will forget
[00:34:24.600 --> 00:34:26.600]   what Project Nimbus is. The odds that it
[00:34:26.600 --> 00:34:28.600]   gets cancelled are less than zero
[00:34:28.600 --> 00:34:30.600]   and everybody will move on.
[00:34:30.600 --> 00:34:32.600]   And it will not add to
[00:34:32.600 --> 00:34:34.600]   the drumbeat, as Zak said, of people
[00:34:34.600 --> 00:34:36.600]   that may be eventually on the
[00:34:36.600 --> 00:34:38.600]   right side of this issue, theoretically.
[00:34:38.600 --> 00:34:40.600]   I say "theoretically" because
[00:34:40.600 --> 00:34:42.600]   that stone is still yet
[00:34:42.600 --> 00:34:44.600]   to be overturned on that topic.
[00:34:44.600 --> 00:34:46.600]   So, I think that they missed the mark.
[00:34:46.600 --> 00:34:48.600]   And I think that the part
[00:34:48.600 --> 00:34:50.600]   of the press that people
[00:34:50.600 --> 00:34:52.600]   glommed onto was it was happening inside
[00:34:52.600 --> 00:34:54.600]   of a company in real time and there was video of it.
[00:34:54.600 --> 00:34:56.600]   Mission accomplished
[00:34:56.600 --> 00:34:58.600]   for them. We're talking about it here as the top
[00:34:58.600 --> 00:35:00.600]   story. And, you know,
[00:35:00.600 --> 00:35:02.600]   if they wanted to raise
[00:35:02.600 --> 00:35:04.600]   awareness, they succeeded and they
[00:35:04.600 --> 00:35:06.600]   should just own their firing because
[00:35:06.600 --> 00:35:08.600]   they knew they would get fired, I think.
[00:35:08.600 --> 00:35:10.600]   There has been a ton of chaos
[00:35:10.600 --> 00:35:12.600]   and the culture wars continue over
[00:35:12.600 --> 00:35:14.600]   NPR.
[00:35:14.600 --> 00:35:16.600]   A couple things happened simultaneously this week
[00:35:16.600 --> 00:35:18.600]   that are worth discussing.
[00:35:18.600 --> 00:35:20.600]   Catherine Marr was named NPR's new
[00:35:20.600 --> 00:35:22.600]   CEO back in January. I'm going to have to give a little bit
[00:35:22.600 --> 00:35:24.600]   of a timeline here before I get
[00:35:24.600 --> 00:35:26.600]   comments from the boys
[00:35:26.600 --> 00:35:28.600]   because there's a little setup.
[00:35:28.600 --> 00:35:30.600]   And so she was named the
[00:35:30.600 --> 00:35:32.600]   CEO back in January. She officially started
[00:35:32.600 --> 00:35:34.600]   in March. Okay, she formerly worked at
[00:35:34.600 --> 00:35:36.600]   Wikimedia Foundation. Those are the people
[00:35:36.600 --> 00:35:38.600]   who run the Wikipedia, obviously.
[00:35:38.600 --> 00:35:40.600]   NPR's mission, if you don't
[00:35:40.600 --> 00:35:42.600]   know, is to create a more informed
[00:35:42.600 --> 00:35:44.600]   public. One challenged
[00:35:44.600 --> 00:35:46.600]   and invigorated by a deeper
[00:35:46.600 --> 00:35:48.600]   understanding and appreciation of events, ideas, and
[00:35:48.600 --> 00:35:50.600]   culture. That's their state and mission from their website.
[00:35:50.600 --> 00:35:52.600]   On April 9th, Uri
[00:35:52.600 --> 00:35:54.600]   Berliner, an editor who's been
[00:35:54.600 --> 00:35:56.600]   with NPR for 25 years, wrote
[00:35:56.600 --> 00:35:58.600]   an op-ed for Barry Weiss's
[00:35:58.600 --> 00:36:00.600]   Free Press, friend of the pod,
[00:36:00.600 --> 00:36:02.600]   explaining how NPR lost America's trust
[00:36:02.600 --> 00:36:04.600]   by going hard left and becoming
[00:36:04.600 --> 00:36:06.600]   closed-minded. He said,
[00:36:06.600 --> 00:36:08.600]   "An open-minded spirit no longer exists within
[00:36:08.600 --> 00:36:10.600]   NPR, and now, predictably,
[00:36:10.600 --> 00:36:12.600]   we don't have an audience that reflects
[00:36:12.600 --> 00:36:14.600]   America." Last Friday,
[00:36:14.600 --> 00:36:16.600]   Marr put out a statement
[00:36:16.600 --> 00:36:18.600]   calling his actions "profoundly disrespectful,
[00:36:18.600 --> 00:36:20.600]   hurtful, and demeaning." This Sunday,
[00:36:20.600 --> 00:36:22.600]   conservative activist
[00:36:22.600 --> 00:36:24.600]   Christopher Ruffo—he's
[00:36:24.600 --> 00:36:26.600]   the person who exposed
[00:36:26.600 --> 00:36:28.600]   former Harvard
[00:36:28.600 --> 00:36:30.600]   president Claudine Gay's plagiarism,
[00:36:30.600 --> 00:36:32.600]   he's a vocal critic of LGBTQ
[00:36:32.600 --> 00:36:34.600]   stuff at schools—
[00:36:34.600 --> 00:36:36.600]   started reposting old tweets from Marr, this
[00:36:36.600 --> 00:36:38.600]   new CEO. Her tweets are
[00:36:38.600 --> 00:36:40.600]   super far-left, Trump's a racist,
[00:36:40.600 --> 00:36:42.600]   yadda yadda. There's an interesting
[00:36:42.600 --> 00:36:44.600]   clip of her talking at TED,
[00:36:44.600 --> 00:36:46.600]   talking about how truth
[00:36:46.600 --> 00:36:48.600]   is a bit of a distraction
[00:36:48.600 --> 00:36:50.600]   that prevents people from getting things done. People have
[00:36:50.600 --> 00:36:52.600]   gotten pretty
[00:36:52.600 --> 00:36:54.600]   inflamed about that clip.
[00:36:54.600 --> 00:36:56.600]   And then, on April 16th,
[00:36:56.600 --> 00:36:58.600]   Berliner was suspended
[00:36:58.600 --> 00:37:00.600]   for five days without pay. Wrapping this all
[00:37:00.600 --> 00:37:02.600]   up, Berliner then resigned
[00:37:02.600 --> 00:37:04.600]   after 25 years, saying,
[00:37:04.600 --> 00:37:06.600]   "I cannot work in a newsroom
[00:37:06.600 --> 00:37:08.600]   where I am disparaged by a new CEO
[00:37:08.600 --> 00:37:10.600]   whose divisive views
[00:37:10.600 --> 00:37:12.600]   confirm the very problems
[00:37:12.600 --> 00:37:14.600]   that NPR I cite in my
[00:37:14.600 --> 00:37:16.600]   free-press essay."
[00:37:16.600 --> 00:37:18.600]   Zach, your thoughts? I mean, this just
[00:37:18.600 --> 00:37:20.600]   seems like a dog-bites-man
[00:37:20.600 --> 00:37:22.600]   story. I mean, what is the novel
[00:37:22.600 --> 00:37:24.600]   revelation here? The person running
[00:37:24.600 --> 00:37:26.600]   NPR is a liberal?
[00:37:26.600 --> 00:37:28.600]   I mean— I'm kind of with you, but—
[00:37:28.600 --> 00:37:30.600]   What took 25 years to resign? I mean,
[00:37:30.600 --> 00:37:32.600]   all you have to do is listen to NPR. It's
[00:37:32.600 --> 00:37:34.600]   always been liberal, okay?
[00:37:34.600 --> 00:37:36.600]   This is not some recent capture
[00:37:36.600 --> 00:37:38.600]   of an institution by the left. So why is it going so
[00:37:38.600 --> 00:37:40.600]   crazy viral right now? Why has this become
[00:37:40.600 --> 00:37:42.600]   the topic of the moment?
[00:37:42.600 --> 00:37:44.600]   Well, apparently, there are
[00:37:44.600 --> 00:37:46.600]   some quotes that this
[00:37:46.600 --> 00:37:48.600]   new CEO, Catherine Marr,
[00:37:48.600 --> 00:37:50.600]   tweeted or
[00:37:50.600 --> 00:37:52.600]   said that you can point to
[00:37:52.600 --> 00:37:54.600]   that seem kind of woke
[00:37:54.600 --> 00:37:56.600]   and kind of crazy woke, but they're
[00:37:56.600 --> 00:37:58.600]   just actually pretty standard.
[00:37:58.600 --> 00:38:00.600]   I just don't see the
[00:38:00.600 --> 00:38:02.600]   breaking news here. If they end up firing
[00:38:02.600 --> 00:38:04.600]   Catherine Marr, they're going to hire someone just like
[00:38:04.600 --> 00:38:06.600]   her. I mean, they're going to have the same views.
[00:38:06.600 --> 00:38:08.600]   NPR has always been
[00:38:08.600 --> 00:38:10.600]   left of center, and the only
[00:38:10.600 --> 00:38:12.600]   change that's happened is that the left
[00:38:12.600 --> 00:38:14.600]   has now
[00:38:14.600 --> 00:38:16.600]   become woke. And so
[00:38:16.600 --> 00:38:18.600]   it's become obsessively focused with
[00:38:18.600 --> 00:38:20.600]   the ideas of white supremacy
[00:38:20.600 --> 00:38:22.600]   and white privilege.
[00:38:22.600 --> 00:38:24.600]   And she simply
[00:38:24.600 --> 00:38:26.600]   reflects that. I agree.
[00:38:26.600 --> 00:38:28.600]   It's like a tempest in a teapot.
[00:38:28.600 --> 00:38:30.600]   Newsflash. NPR is woke and
[00:38:30.600 --> 00:38:32.600]   left-leaning? I mean,
[00:38:32.600 --> 00:38:34.600]   I guess maybe that somebody who was there for
[00:38:34.600 --> 00:38:36.600]   25 years wrote the expose
[00:38:36.600 --> 00:38:38.600]   is interesting, or I don't know.
[00:38:38.600 --> 00:38:40.600]   Chamath, any thoughts on this one and why it's
[00:38:40.600 --> 00:38:42.600]   taking up so much headspace for people?
[00:38:42.600 --> 00:38:44.600]   I don't think it is. I think it's
[00:38:44.600 --> 00:38:46.600]   taking up a lot of headspace amongst
[00:38:46.600 --> 00:38:48.600]   breathless journalists. I don't think it
[00:38:48.600 --> 00:38:50.600]   matters to the public at large. I don't think
[00:38:50.600 --> 00:38:52.600]   anybody cares. Can I just add one thing, which is
[00:38:52.600 --> 00:38:54.600]   I do think that the government should not
[00:38:54.600 --> 00:38:56.600]   be funding this anymore. I think NPR
[00:38:56.600 --> 00:38:58.600]   at this point is mostly funded by private
[00:38:58.600 --> 00:39:00.600]   donations, but it got started
[00:39:00.600 --> 00:39:02.600]   with government money, and the government still
[00:39:02.600 --> 00:39:04.600]   funds it. And given that it is
[00:39:04.600 --> 00:39:06.600]   this left
[00:39:06.600 --> 00:39:08.600]   institution at this point,
[00:39:08.600 --> 00:39:10.600]   and really always has been, there's simply
[00:39:10.600 --> 00:39:12.600]   no reason for the government to be
[00:39:12.600 --> 00:39:14.600]   funding one side of the political
[00:39:14.600 --> 00:39:16.600]   debate that way. So I think there is
[00:39:16.600 --> 00:39:18.600]   maybe an issue there in terms
[00:39:18.600 --> 00:39:20.600]   of reminding people
[00:39:20.600 --> 00:39:22.600]   that, "Hey, this is government-funded. Why?"
[00:39:22.600 --> 00:39:24.600]   And there's no reason why NPR can't
[00:39:24.600 --> 00:39:26.600]   be funded with either private
[00:39:26.600 --> 00:39:28.600]   donations or private
[00:39:28.600 --> 00:39:30.600]   subscription dues. Yeah, this is, just to give people some
[00:39:30.600 --> 00:39:32.600]   back-of-the-envelope math,
[00:39:32.600 --> 00:39:34.600]   NPR's budget is like $320 million. It's a
[00:39:34.600 --> 00:39:36.600]   dollar per American, and
[00:39:36.600 --> 00:39:38.600]   they get a bunch of programming
[00:39:38.600 --> 00:39:40.600]   fees and some corporate sponsorship. Corporate
[00:39:40.600 --> 00:39:42.600]   sponsorship is like $100 million.
[00:39:42.600 --> 00:39:44.600]   The programming fees is what the local radio stations
[00:39:44.600 --> 00:39:46.600]   pay them. Net-net, this
[00:39:46.600 --> 00:39:48.600]   is costing like maybe,
[00:39:48.600 --> 00:39:50.600]   I don't know, 30 cents an American.
[00:39:50.600 --> 00:39:52.600]   And if you just swap out,
[00:39:52.600 --> 00:39:54.600]   and this is the way I like to look at these to be objective,
[00:39:54.600 --> 00:39:56.600]   if you were saying this was funding
[00:39:56.600 --> 00:39:58.600]   Fox News or, I don't know,
[00:39:58.600 --> 00:40:00.600]   Ben Shapiro and Daily Wire, how would
[00:40:00.600 --> 00:40:02.600]   you feel about it? You'd be like, "Well, why is the government funding
[00:40:02.600 --> 00:40:04.600]   that?" They should just cut NPR
[00:40:04.600 --> 00:40:06.600]   and all this public broadcasting stuff loose over the next
[00:40:06.600 --> 00:40:08.600]   year or two, wind it down,
[00:40:08.600 --> 00:40:10.600]   and let them fend for themselves in the new
[00:40:10.600 --> 00:40:12.600]   media landscape. Look, Jake, I agree with you. They could
[00:40:12.600 --> 00:40:14.600]   easily sub-stack it. NPR's not going to go away.
[00:40:14.600 --> 00:40:16.600]   Just create subscriptions,
[00:40:16.600 --> 00:40:18.600]   and you're fine. Yeah. I mean, it's only
[00:40:18.600 --> 00:40:20.600]   like, they're down to whatever. It's
[00:40:20.600 --> 00:40:22.600]   very hard to find the numbers. There's a little, like,
[00:40:22.600 --> 00:40:24.600]   hiding of the money here, but there's so
[00:40:24.600 --> 00:40:26.600]   little at stake here, I think that's why it's so
[00:40:26.600 --> 00:40:28.600]   contentious. The government should not be funding
[00:40:28.600 --> 00:40:30.600]   one-sided ideological
[00:40:30.600 --> 00:40:32.600]   institutions on either side of the
[00:40:32.600 --> 00:40:34.600]   political debate, and you're right. If this was
[00:40:34.600 --> 00:40:36.600]   funding going to Daily Wire
[00:40:36.600 --> 00:40:38.600]   or something like that, people would be
[00:40:38.600 --> 00:40:40.600]   up in arms. So, in any event,
[00:40:40.600 --> 00:40:42.600]   what's good for them is good for the gander. The next
[00:40:42.600 --> 00:40:44.600]   tempest in a teapot
[00:40:44.600 --> 00:40:46.600]   is Humane's AI pen getting
[00:40:46.600 --> 00:40:48.600]   barbecued by our modern
[00:40:48.600 --> 00:40:50.600]   day Walt Mossberg. Marques Brownlee,
[00:40:50.600 --> 00:40:52.600]   who is an awesome YouTuber,
[00:40:52.600 --> 00:40:54.600]   I love his reviews, has created
[00:40:54.600 --> 00:40:56.600]   a bit of a social media Rorschach test
[00:40:56.600 --> 00:40:58.600]   here, getting a lot
[00:40:58.600 --> 00:41:00.600]   of feels from people in Silicon Valley.
[00:41:00.600 --> 00:41:02.600]   Let's just tee this up here. Humane is a
[00:41:02.600 --> 00:41:04.600]   hardware startup that you may have heard of.
[00:41:04.600 --> 00:41:06.600]   They make an AI-powered wearable computer.
[00:41:06.600 --> 00:41:08.600]   It's basically a pin you put on your chest.
[00:41:08.600 --> 00:41:10.600]   It's about the size of a pack
[00:41:10.600 --> 00:41:12.600]   of cigarettes, maybe half the size of it.
[00:41:12.600 --> 00:41:14.600]   Founded by two Apple execs back in 2018,
[00:41:14.600 --> 00:41:16.600]   raised a quarter of
[00:41:16.600 --> 00:41:18.600]   a billion dollars or so,
[00:41:18.600 --> 00:41:20.600]   and
[00:41:20.600 --> 00:41:22.600]   the device is now in the hands of reviewers.
[00:41:22.600 --> 00:41:24.600]   It's pretty innovative, and Marques
[00:41:24.600 --> 00:41:26.600]   talks about how innovative it is in his review.
[00:41:26.600 --> 00:41:28.600]   It will let you
[00:41:28.600 --> 00:41:30.600]   talk to it. It's got a camera on it.
[00:41:30.600 --> 00:41:32.600]   We'll show it here on the screen. If you're not subscribed
[00:41:32.600 --> 00:41:34.600]   to the YouTube channel, just go
[00:41:34.600 --> 00:41:36.600]   to YouTube right now, and you'll see us playing
[00:41:36.600 --> 00:41:38.600]   the video of it. Search for "all in."
[00:41:38.600 --> 00:41:40.600]   And really interesting
[00:41:40.600 --> 00:41:42.600]   interface. It does obviously
[00:41:42.600 --> 00:41:44.600]   voice. It connects you to an LLM
[00:41:44.600 --> 00:41:46.600]   on the back end, so if you want to know
[00:41:46.600 --> 00:41:48.600]   some piece of information,
[00:41:48.600 --> 00:41:50.600]   it can answer those questions for you.
[00:41:50.600 --> 00:41:52.600]   But Marques showed it
[00:41:52.600 --> 00:41:54.600]   just absolutely failing
[00:41:54.600 --> 00:41:56.600]   at a bunch of tests, being
[00:41:56.600 --> 00:41:58.600]   overpriced, and he called
[00:41:58.600 --> 00:42:00.600]   it the worst product he's
[00:42:00.600 --> 00:42:02.600]   ever reviewed.
[00:42:02.600 --> 00:42:04.600]   It's very thoughtful and methodical,
[00:42:04.600 --> 00:42:06.600]   but the title
[00:42:06.600 --> 00:42:08.600]   is obviously a bit link-baiting.
[00:42:08.600 --> 00:42:10.600]   As a co-founder of Engadget, I can tell you,
[00:42:10.600 --> 00:42:12.600]   if you want to get a lot of clicks, just say something
[00:42:12.600 --> 00:42:14.600]   is the best or the worst ever, and you can get
[00:42:14.600 --> 00:42:16.600]   ten times
[00:42:16.600 --> 00:42:18.600]   the views.
[00:42:18.600 --> 00:42:20.600]   The pen, according
[00:42:20.600 --> 00:42:22.600]   to him, doesn't do anything
[00:42:22.600 --> 00:42:24.600]   better than a smartphone. It's slow.
[00:42:24.600 --> 00:42:26.600]   It doesn't work. It's often wrong.
[00:42:26.600 --> 00:42:28.600]   It's 700 bucks. The battery sucks.
[00:42:28.600 --> 00:42:30.600]   So many different ways
[00:42:30.600 --> 00:42:32.600]   to go with this. Everybody is
[00:42:32.600 --> 00:42:34.600]   talking about it on X
[00:42:34.600 --> 00:42:36.600]   and in the media.
[00:42:36.600 --> 00:42:38.600]   Where do you stand
[00:42:38.600 --> 00:42:40.600]   on this one, Friedberg?
[00:42:40.600 --> 00:42:42.600]   Both on
[00:42:42.600 --> 00:42:44.600]   how people are responding to it in the tech
[00:42:44.600 --> 00:42:46.600]   industry as being anti-tech,
[00:42:46.600 --> 00:42:48.600]   anti-innovation, versus
[00:42:48.600 --> 00:42:50.600]   "Hey, it's just a reviewer giving his
[00:42:50.600 --> 00:42:52.600]   candid feedback on a product that's clearly not
[00:42:52.600 --> 00:42:54.600]   ready for prime time."
[00:42:54.600 --> 00:42:56.600]   I think there's a lot of issues.
[00:42:56.600 --> 00:42:58.600]   One is just the challenge of
[00:42:58.600 --> 00:43:00.600]   deep tech.
[00:43:00.600 --> 00:43:02.600]   More specifically, in this case,
[00:43:02.600 --> 00:43:04.600]   hardware investing. You
[00:43:04.600 --> 00:43:06.600]   have to invest a lot of capital
[00:43:06.600 --> 00:43:08.600]   before you even have your first
[00:43:08.600 --> 00:43:10.600]   product, and then you don't really know
[00:43:10.600 --> 00:43:12.600]   how well it works until you've already burnt through
[00:43:12.600 --> 00:43:14.600]   a lot of capital. I mean, this is
[00:43:14.600 --> 00:43:16.600]   one of these stunning stories of a startup
[00:43:16.600 --> 00:43:18.600]   that has raised a quarter billion dollars,
[00:43:18.600 --> 00:43:20.600]   and then they come out with their first
[00:43:20.600 --> 00:43:22.600]   product, and it turns out it needs a lot of work
[00:43:22.600 --> 00:43:24.600]   because it doesn't do anything
[00:43:24.600 --> 00:43:26.600]   that consumers really are compelled
[00:43:26.600 --> 00:43:28.600]   by, as evidenced by
[00:43:28.600 --> 00:43:30.600]   the review.
[00:43:30.600 --> 00:43:32.600]   I think it highlights that
[00:43:32.600 --> 00:43:34.600]   challenge and why that market
[00:43:34.600 --> 00:43:36.600]   finds, particularly
[00:43:36.600 --> 00:43:38.600]   in this environment, it to be so hard
[00:43:38.600 --> 00:43:40.600]   to get capitalized.
[00:43:40.600 --> 00:43:42.600]   Now, obviously, there are some entrepreneurs
[00:43:42.600 --> 00:43:44.600]   like Elon who can
[00:43:44.600 --> 00:43:46.600]   take that capital and
[00:43:46.600 --> 00:43:48.600]   drive to the outcome,
[00:43:48.600 --> 00:43:50.600]   spending hundreds of millions
[00:43:50.600 --> 00:43:52.600]   of dollars before you get your first rocket into space,
[00:43:52.600 --> 00:43:54.600]   and you have a lot of failings along the way.
[00:43:54.600 --> 00:43:56.600]   But the
[00:43:56.600 --> 00:43:58.600]   general tone here is
[00:43:58.600 --> 00:44:00.600]   a deep tech investment
[00:44:00.600 --> 00:44:02.600]   is very likely to fail
[00:44:02.600 --> 00:44:04.600]   because you spend so much money before you even know,
[00:44:04.600 --> 00:44:06.600]   and at that point, you have less money, and you can't really
[00:44:06.600 --> 00:44:08.600]   make the necessary iteration to get
[00:44:08.600 --> 00:44:10.600]   there. So it's a tough
[00:44:10.600 --> 00:44:12.600]   data point for other
[00:44:12.600 --> 00:44:14.600]   deep tech companies
[00:44:14.600 --> 00:44:16.600]   that need to raise a lot of capital.
[00:44:16.600 --> 00:44:18.600]   Then I think it brings up the point about
[00:44:18.600 --> 00:44:20.600]   Apple people, that there's a degree
[00:44:20.600 --> 00:44:22.600]   of confidence because people come
[00:44:22.600 --> 00:44:24.600]   from Apple, and a degree of hubris
[00:44:24.600 --> 00:44:26.600]   in the employees that come from Apple
[00:44:26.600 --> 00:44:28.600]   that says, "I have
[00:44:28.600 --> 00:44:30.600]   worked at the best hardware company in the world, therefore
[00:44:30.600 --> 00:44:32.600]   this person is likely to succeed." It turns out
[00:44:32.600 --> 00:44:34.600]   that when you don't have all that built-in infrastructure
[00:44:34.600 --> 00:44:36.600]   for testing and optimization,
[00:44:36.600 --> 00:44:38.600]   all of that built-in distribution,
[00:44:38.600 --> 00:44:40.600]   all of the feedback systems that Apple
[00:44:40.600 --> 00:44:42.600]   has engineered into their business
[00:44:42.600 --> 00:44:44.600]   model for so long, maybe you miss some of the
[00:44:44.600 --> 00:44:46.600]   data around what makes a product great
[00:44:46.600 --> 00:44:48.600]   or not before you launch. I think
[00:44:48.600 --> 00:44:50.600]   that's your key point, Freeberg. That is the best
[00:44:50.600 --> 00:44:52.600]   point, is these folks come from Apple,
[00:44:52.600 --> 00:44:54.600]   they're used to unlimited resources,
[00:44:54.600 --> 00:44:56.600]   and what you don't
[00:44:56.600 --> 00:44:58.600]   see is all the product Apple
[00:44:58.600 --> 00:45:00.600]   doesn't release, right? They never release their car,
[00:45:00.600 --> 00:45:02.600]   correct, Freeberg? And they get to...
[00:45:02.600 --> 00:45:04.600]   Well, I think then there's also this question about
[00:45:04.600 --> 00:45:06.600]   where is the value in
[00:45:06.600 --> 00:45:08.600]   the product? Because they thought,
[00:45:08.600 --> 00:45:10.600]   "Hey, if we have AI on a pen,
[00:45:10.600 --> 00:45:12.600]   it'll work." Without the consumer
[00:45:12.600 --> 00:45:14.600]   feedback about whether or not
[00:45:14.600 --> 00:45:16.600]   people are willing to sit around and wait for 12
[00:45:16.600 --> 00:45:18.600]   seconds to get an answer
[00:45:18.600 --> 00:45:20.600]   to a question. And then it brings up
[00:45:20.600 --> 00:45:22.600]   this other really important point, which is
[00:45:22.600 --> 00:45:24.600]   half the people in Silicon Valley are running
[00:45:24.600 --> 00:45:26.600]   breathlessly into the conversation saying,
[00:45:26.600 --> 00:45:28.600]   "Do not disparage a startup
[00:45:28.600 --> 00:45:30.600]   that's working really hard at getting their first product
[00:45:30.600 --> 00:45:32.600]   right. It'll destroy the motivation
[00:45:32.600 --> 00:45:34.600]   of other startups that need to
[00:45:34.600 --> 00:45:36.600]   iterate to get there.
[00:45:36.600 --> 00:45:38.600]   And we can't just take the first V1
[00:45:38.600 --> 00:45:40.600]   and say that that's it." Chamath, your thoughts?
[00:45:40.600 --> 00:45:42.600]   You're laughing hysterically at this stuff.
[00:45:42.600 --> 00:45:44.600]   The other half of Silicon Valley
[00:45:44.600 --> 00:45:46.600]   are running in and saying, "This thing's a piece of s***. What are you talking
[00:45:46.600 --> 00:45:48.600]   about? It doesn't f***ing work."
[00:45:48.600 --> 00:45:50.600]   So it is a really interesting kind of
[00:45:50.600 --> 00:45:52.600]   debate. Rorschach.
[00:45:52.600 --> 00:45:54.600]   Yeah, a Rorschach test on what's going on.
[00:45:54.600 --> 00:45:56.600]   Chamath, what do you see in this plot
[00:45:56.600 --> 00:45:58.600]   of a product?
[00:45:58.600 --> 00:46:00.600]   Neither of those two cohorts.
[00:46:00.600 --> 00:46:02.600]   I think that incredibly
[00:46:02.600 --> 00:46:04.600]   motivated, dedicated entrepreneurs
[00:46:04.600 --> 00:46:06.600]   don't even know that this is happening
[00:46:06.600 --> 00:46:08.600]   and don't care. Got it.
[00:46:08.600 --> 00:46:10.600]   In other words, the reviewers
[00:46:10.600 --> 00:46:12.600]   are going to review products and
[00:46:12.600 --> 00:46:14.600]   you just got to plow ahead and make a better product.
[00:46:14.600 --> 00:46:16.600]   The idea that in 2009,
[00:46:16.600 --> 00:46:18.600]   10, or 11,
[00:46:18.600 --> 00:46:20.600]   that
[00:46:20.600 --> 00:46:22.600]   when all the rockets
[00:46:22.600 --> 00:46:24.600]   weren't working and Elon was back
[00:46:24.600 --> 00:46:26.600]   against the wall, that he was
[00:46:26.600 --> 00:46:28.600]   reading TechCrunch or
[00:46:28.600 --> 00:46:30.600]   getting upset because a product
[00:46:30.600 --> 00:46:32.600]   failed, some other random product that had
[00:46:32.600 --> 00:46:34.600]   nothing to do with his, I think is
[00:46:34.600 --> 00:46:36.600]   laughable. I think no great entrepreneur
[00:46:36.600 --> 00:46:38.600]   cares. I don't think Freeberg is going to
[00:46:38.600 --> 00:46:40.600]   change what's happening at
[00:46:40.600 --> 00:46:42.600]   O'Halo based on
[00:46:42.600 --> 00:46:44.600]   what is this thing called?
[00:46:44.600 --> 00:46:46.600]   Humane. Right.
[00:46:46.600 --> 00:46:48.600]   Freeberg, have you changed? Have you made decisions?
[00:46:48.600 --> 00:46:50.600]   Are you sadder today in O'Halo when you walked
[00:46:50.600 --> 00:46:52.600]   into the office to manage your team? No.
[00:46:52.600 --> 00:46:54.600]   Okay, so there you go. There's your answer.
[00:46:54.600 --> 00:46:56.600]   You're failing on this. Yeah, I mean, I'm having
[00:46:56.600 --> 00:46:58.600]   a hard time understanding all the controversies
[00:46:58.600 --> 00:47:00.600]   this week. I mean, reviewers are going to
[00:47:00.600 --> 00:47:02.600]   review, protesters are going to protest
[00:47:02.600 --> 00:47:04.600]   and NPR presidents are going to NPR.
[00:47:04.600 --> 00:47:06.600]   Here we go. What's going on?
[00:47:06.600 --> 00:47:08.600]   Everyone's just doing
[00:47:08.600 --> 00:47:10.600]   their job. Yeah.
[00:47:10.600 --> 00:47:12.600]   Here's an idea for the Humane team. Be
[00:47:12.600 --> 00:47:14.600]   thankful somebody took the time
[00:47:14.600 --> 00:47:16.600]   to review your product and give you candid
[00:47:16.600 --> 00:47:18.600]   feedback and incorporate it back into your
[00:47:18.600 --> 00:47:20.600]   product and make it work.
[00:47:20.600 --> 00:47:22.600]   An irreverent elitist will eat octopus.
[00:47:22.600 --> 00:47:24.600]   Here we are. Absolutely.
[00:47:24.600 --> 00:47:26.600]   So delicious. High IQ
[00:47:26.600 --> 00:47:28.600]   foods. We should create a new category.
[00:47:28.600 --> 00:47:30.600]   Yeah, what are the other high IQ
[00:47:30.600 --> 00:47:32.600]   foods? Acorn
[00:47:32.600 --> 00:47:34.600]   fed beef. For
[00:47:34.600 --> 00:47:36.600]   high IQ. Pigs
[00:47:36.600 --> 00:47:38.600]   very high IQ. I saw that cow playing
[00:47:38.600 --> 00:47:40.600]   chess before he was served
[00:47:40.600 --> 00:47:42.600]   for dinner.
[00:47:42.600 --> 00:47:44.600]   I was having a pulled pork sandwich from
[00:47:44.600 --> 00:47:46.600]   Bucky's and it
[00:47:46.600 --> 00:47:48.600]   helped me solve Wordle for the day
[00:47:48.600 --> 00:47:50.600]   before I ate it. So I
[00:47:50.600 --> 00:47:52.600]   got Wordle in two tries.
[00:47:52.600 --> 00:47:54.600]   Oh, I'm so sorry.
[00:47:54.600 --> 00:47:56.600]   Oh, that one landed.
[00:47:56.600 --> 00:47:58.600]   I didn't want that one to land.
[00:47:58.600 --> 00:48:00.600]   Yeah, I
[00:48:00.600 --> 00:48:02.600]   mean, okay, let me ask this question.
[00:48:02.600 --> 00:48:04.600]   Do we think the world let's say this
[00:48:04.600 --> 00:48:06.600]   thing did respond. Here's the theme.
[00:48:06.600 --> 00:48:08.600]   One second Jason. Here's
[00:48:08.600 --> 00:48:10.600]   a theme Jason. The problem is that I think people
[00:48:10.600 --> 00:48:12.600]   right now, the
[00:48:12.600 --> 00:48:14.600]   real Rorschach test is if you are so
[00:48:14.600 --> 00:48:16.600]   easily distracted, you probably
[00:48:16.600 --> 00:48:18.600]   don't have enough to do.
[00:48:18.600 --> 00:48:20.600]   Right. That's the entitlement is
[00:48:20.600 --> 00:48:22.600]   that you don't have enough work. I don't want to call it.
[00:48:22.600 --> 00:48:24.600]   I don't want to call it entitlement. But I think
[00:48:24.600 --> 00:48:26.600]   the reality is that if you get caught up
[00:48:26.600 --> 00:48:28.600]   in all of these silly
[00:48:28.600 --> 00:48:30.600]   little fake battles or
[00:48:30.600 --> 00:48:32.600]   decisions, I think what it really
[00:48:32.600 --> 00:48:34.600]   means is that you're not busy enough and
[00:48:34.600 --> 00:48:36.600]   or you're not working on something that matters enough
[00:48:36.600 --> 00:48:38.600]   to you. Because when either of those
[00:48:38.600 --> 00:48:40.600]   two things are true, people tend
[00:48:40.600 --> 00:48:42.600]   to be tend to have blinders on and
[00:48:42.600 --> 00:48:44.600]   they are super focused and
[00:48:44.600 --> 00:48:46.600]   they just don't have an opinion. They don't care. Like
[00:48:46.600 --> 00:48:48.600]   honestly, many of these topics today, I
[00:48:48.600 --> 00:48:50.600]   really don't care. And it's not because I'm better
[00:48:50.600 --> 00:48:52.600]   or worse or smarter or dumber. It's because I'm
[00:48:52.600 --> 00:48:54.600]   so overworked right now. I don't
[00:48:54.600 --> 00:48:56.600]   have time to have an opinion on this stuff.
[00:48:56.600 --> 00:48:58.600]   Your boss got a CEO job and now he's
[00:48:58.600 --> 00:49:00.600]   overworked. And I think that anybody else
[00:49:00.600 --> 00:49:02.600]   trying to do their job well is probably in
[00:49:02.600 --> 00:49:04.600]   the same category. I
[00:49:04.600 --> 00:49:06.600]   hadn't even heard of this reviewer. What's his name?
[00:49:06.600 --> 00:49:08.600]   Mark, Mark, Mark, Marquez
[00:49:08.600 --> 00:49:10.600]   Brown. I never
[00:49:10.600 --> 00:49:12.600]   heard of him. If you're on YouTube, he's
[00:49:12.600 --> 00:49:14.600]   kind of like the new Walt Mossberg.
[00:49:14.600 --> 00:49:16.600]   He does 20, 30 minute
[00:49:16.600 --> 00:49:18.600]   videos. They get millions of views.
[00:49:18.600 --> 00:49:20.600]   He's huge. I don't
[00:49:20.600 --> 00:49:22.600]   know that he makes or breaks a product though.
[00:49:22.600 --> 00:49:24.600]   By the way, he does not make or break a product.
[00:49:24.600 --> 00:49:26.600]   The product makes or breaks itself. Yeah.
[00:49:26.600 --> 00:49:28.600]   Look, when I was running
[00:49:28.600 --> 00:49:30.600]   companies, I wouldn't care about what one reviewer
[00:49:30.600 --> 00:49:32.600]   said. I would care about the totality
[00:49:32.600 --> 00:49:34.600]   of the reaction to the product, which
[00:49:34.600 --> 00:49:36.600]   would include customers as well
[00:49:36.600 --> 00:49:38.600]   as reviewers and so forth.
[00:49:38.600 --> 00:49:40.600]   So I don't think there's any point getting
[00:49:40.600 --> 00:49:42.600]   too bad out of shape about one review.
[00:49:42.600 --> 00:49:44.600]   I think what's kind of happening in terms of the
[00:49:44.600 --> 00:49:46.600]   reaction here is that
[00:49:46.600 --> 00:49:48.600]   people want to give this company
[00:49:48.600 --> 00:49:50.600]   mercy points for
[00:49:50.600 --> 00:49:52.600]   being innovative. So
[00:49:52.600 --> 00:49:54.600]   my guess is the product just isn't ready for prime time
[00:49:54.600 --> 00:49:56.600]   but everyone wants to kind of
[00:49:56.600 --> 00:49:58.600]   want their reviewers to take it easy on them
[00:49:58.600 --> 00:50:00.600]   or something because they are being
[00:50:00.600 --> 00:50:02.600]   innovative and they're breaking new ground in this
[00:50:02.600 --> 00:50:04.600]   area of wearables. But
[00:50:04.600 --> 00:50:06.600]   the reality is, in the real world
[00:50:06.600 --> 00:50:08.600]   where you want to charge people
[00:50:08.600 --> 00:50:10.600]   for your product, customers
[00:50:10.600 --> 00:50:12.600]   don't have mercy points. Nope.
[00:50:12.600 --> 00:50:14.600]   If the car breaks
[00:50:14.600 --> 00:50:16.600]   down, the car breaks down. By the way,
[00:50:16.600 --> 00:50:18.600]   Marquez got a little bit of heat
[00:50:18.600 --> 00:50:20.600]   just a month ago because he reviewed the Fisker.
[00:50:20.600 --> 00:50:22.600]   The Fisker is just a piece of
[00:50:22.600 --> 00:50:24.600]   garbage car. He said it's the worst car he's ever reviewed.
[00:50:24.600 --> 00:50:26.600]   And you know what? Reviewers
[00:50:26.600 --> 00:50:28.600]   exist in the world
[00:50:28.600 --> 00:50:30.600]   to inform customers
[00:50:30.600 --> 00:50:32.600]   about what products and services they should buy
[00:50:32.600 --> 00:50:34.600]   and then they should inform you to make a better product.
[00:50:34.600 --> 00:50:36.600]   Period. Full stop.
[00:50:36.600 --> 00:50:38.600]   There is an easy solution to this, by the way, which Apple
[00:50:38.600 --> 00:50:40.600]   did. They
[00:50:40.600 --> 00:50:42.600]   released the Vision Pro as a developer
[00:50:42.600 --> 00:50:44.600]   kit. They put a bunch of caveats
[00:50:44.600 --> 00:50:46.600]   on it and said, "Hey, we understand
[00:50:46.600 --> 00:50:48.600]   this is high priced. It's a developer
[00:50:48.600 --> 00:50:50.600]   kit. This is in beta."
[00:50:50.600 --> 00:50:52.600]   What Humane should have done is they should have said,
[00:50:52.600 --> 00:50:54.600]   "This is the Humane beta for
[00:50:54.600 --> 00:50:56.600]   developers." I still don't know what it is.
[00:50:56.600 --> 00:50:58.600]   What is this? Okay, it's a wearable.
[00:50:58.600 --> 00:51:00.600]   It's a square. It has
[00:51:00.600 --> 00:51:02.600]   a projector on it. You put your hand out, it
[00:51:02.600 --> 00:51:04.600]   projects a little screen that shows
[00:51:04.600 --> 00:51:06.600]   you like a computer screen
[00:51:06.600 --> 00:51:08.600]   and you can talk to it and ask it questions.
[00:51:08.600 --> 00:51:10.600]   Yeah, the primary function is like a chat
[00:51:10.600 --> 00:51:12.600]   AI assistant that sits
[00:51:12.600 --> 00:51:14.600]   on you and has a camera.
[00:51:14.600 --> 00:51:16.600]   And so you can say-- Camera is it's taping
[00:51:16.600 --> 00:51:18.600]   everything that it sees?
[00:51:18.600 --> 00:51:20.600]   It doesn't do that by default, but it could.
[00:51:20.600 --> 00:51:22.600]   Sorry, let me just give the quick overview.
[00:51:22.600 --> 00:51:24.600]   Basically, you ask it questions
[00:51:24.600 --> 00:51:26.600]   and it can go get the answers. The problem is
[00:51:26.600 --> 00:51:28.600]   that it has to go make a request
[00:51:28.600 --> 00:51:30.600]   to the internet, run an AI
[00:51:30.600 --> 00:51:32.600]   model, and come back. So it takes like
[00:51:32.600 --> 00:51:34.600]   12 seconds to get results. Most
[00:51:34.600 --> 00:51:36.600]   of the time, according to the reviewer, the results
[00:51:36.600 --> 00:51:38.600]   are actually wrong because it's a
[00:51:38.600 --> 00:51:40.600]   hallucinating model. The voice-to-text
[00:51:40.600 --> 00:51:42.600]   translation is wrong. There's a lot of
[00:51:42.600 --> 00:51:44.600]   things that are wrong about it. So it takes a long time.
[00:51:44.600 --> 00:51:46.600]   It's clunky and then the battery burns out
[00:51:46.600 --> 00:51:48.600]   every two hours and it gets super
[00:51:48.600 --> 00:51:50.600]   hot because of the way they get it to magnetically stick
[00:51:50.600 --> 00:51:52.600]   to your clothes. So it gets very hot.
[00:51:52.600 --> 00:51:54.600]   So there's all sorts of issues and it's $700.
[00:51:54.600 --> 00:51:56.600]   Other than that, how
[00:51:56.600 --> 00:51:58.600]   is the play, Mrs. Lincoln? And by the way,
[00:51:58.600 --> 00:52:00.600]   most importantly to you, Chamath,
[00:52:00.600 --> 00:52:02.600]   it will screw up your fabrics.
[00:52:02.600 --> 00:52:04.600]   If you wear this with a Lora Piana sweater,
[00:52:04.600 --> 00:52:06.600]   it's going to drag your sweater down. Hold on.
[00:52:06.600 --> 00:52:08.600]   You would never attach it to a $6,000
[00:52:08.600 --> 00:52:10.600]   sweater. Yeah, it's
[00:52:10.600 --> 00:52:12.600]   basically what you're telling me is it's
[00:52:12.600 --> 00:52:14.600]   an overpriced device that could give you
[00:52:14.600 --> 00:52:16.600]   50 degree burns.
[00:52:16.600 --> 00:52:18.600]   And it will ruin your sweaters.
[00:52:18.600 --> 00:52:20.600]   It doesn't answer the questions that you ask.
[00:52:20.600 --> 00:52:22.600]   Yeah, basically. But then do
[00:52:22.600 --> 00:52:24.600]   I think the questions or do I have to say it out loud
[00:52:24.600 --> 00:52:26.600]   so it looks like I'm talking to myself?
[00:52:26.600 --> 00:52:28.600]   You look like a lunatic. Yes, you're walking around
[00:52:28.600 --> 00:52:30.600]   like a crazy person talking to yourself. That was the other
[00:52:30.600 --> 00:52:32.600]   thing he said is like when you're in a crowd and
[00:52:32.600 --> 00:52:34.600]   there's a voice around you can use your hand and
[00:52:34.600 --> 00:52:36.600]   hand gestures to control it and do
[00:52:36.600 --> 00:52:38.600]   things with the projectors thing that it does.
[00:52:38.600 --> 00:52:40.600]   And it damages your clothes. It's some really cool
[00:52:40.600 --> 00:52:42.600]   interesting features. It's just like it's not
[00:52:42.600 --> 00:52:44.600]   who invested in it. Let's not make fun of it. Let's
[00:52:44.600 --> 00:52:46.600]   make fun of the investors.
[00:52:46.600 --> 00:52:48.600]   Sam Altman, shout out
[00:52:48.600 --> 00:52:50.600]   to Sam. He's coming on the program I think.
[00:52:50.600 --> 00:52:52.600]   Yeah.
[00:52:52.600 --> 00:52:54.600]   Listen, the concept
[00:52:54.600 --> 00:52:56.600]   I think is good. Wearables are
[00:52:56.600 --> 00:52:58.600]   going to provide some distinct value when they
[00:52:58.600 --> 00:53:00.600]   work because you don't have to
[00:53:00.600 --> 00:53:02.600]   take your phone out. And so the idea behind
[00:53:02.600 --> 00:53:04.600]   wearables like your watch
[00:53:04.600 --> 00:53:06.600]   is, you know, like there are some things I do on
[00:53:06.600 --> 00:53:08.600]   my watch now where I don't take my
[00:53:08.600 --> 00:53:10.600]   phone out. I'll take the other side of this.
[00:53:10.600 --> 00:53:12.600]   I'll take the other side when you're done. Yeah. I use
[00:53:12.600 --> 00:53:14.600]   Fitbit company we invested in
[00:53:14.600 --> 00:53:16.600]   and it puts all my workouts on my watch
[00:53:16.600 --> 00:53:18.600]   when I'm doing weights. I started doing weights now. That's
[00:53:18.600 --> 00:53:20.600]   why I look so buff, folks. Subscribe
[00:53:20.600 --> 00:53:22.600]   to the YouTube channel to see. And
[00:53:22.600 --> 00:53:24.600]   I do my sets and I log them all with
[00:53:24.600 --> 00:53:26.600]   my my watch. I don't have to take my phone
[00:53:26.600 --> 00:53:28.600]   out. That's like the first thing. And then when I'm skiing,
[00:53:28.600 --> 00:53:30.600]   I can see each run. I showed you slopes.
[00:53:30.600 --> 00:53:32.600]   I'm not an investor in
[00:53:32.600 --> 00:53:34.600]   Chamath where I could see my speed and all that stuff.
[00:53:34.600 --> 00:53:36.600]   You're saying something totally different. That's
[00:53:36.600 --> 00:53:38.600]   utility. Of course you'll find
[00:53:38.600 --> 00:53:40.600]   a device will give you utility.
[00:53:40.600 --> 00:53:42.600]   I thought you were saying something else, which is everybody
[00:53:42.600 --> 00:53:44.600]   is going to have wearables and I
[00:53:44.600 --> 00:53:46.600]   want to take the exact opposite side of that.
[00:53:46.600 --> 00:53:48.600]   Yeah, I don't know that everybody will have wearables,
[00:53:48.600 --> 00:53:50.600]   but I do find a couple of little things
[00:53:50.600 --> 00:53:52.600]   that work for me. I totally get that,
[00:53:52.600 --> 00:53:54.600]   you know, the use of an accelerometer or whatever
[00:53:54.600 --> 00:53:56.600]   in a watch or in a band that you
[00:53:56.600 --> 00:53:58.600]   wear on your wrist for a workout. And
[00:53:58.600 --> 00:54:00.600]   I think that that's valuable or heart rate,
[00:54:00.600 --> 00:54:02.600]   a glycemic monitor
[00:54:02.600 --> 00:54:04.600]   so that you could all of that stuff makes super
[00:54:04.600 --> 00:54:06.600]   sense for you as an individual. But that's
[00:54:06.600 --> 00:54:08.600]   not an experience where you're
[00:54:08.600 --> 00:54:10.600]   engaging with it to
[00:54:10.600 --> 00:54:12.600]   something like
[00:54:12.600 --> 00:54:14.600]   to replace some other social interaction.
[00:54:14.600 --> 00:54:16.600]   That's just you getting utility as you live your life.
[00:54:16.600 --> 00:54:18.600]   What I'm saying is the idea that
[00:54:18.600 --> 00:54:20.600]   you start to rely on a device
[00:54:20.600 --> 00:54:22.600]   as your interface into the world.
[00:54:22.600 --> 00:54:24.600]   I would take the exact
[00:54:24.600 --> 00:54:26.600]   other side of that, which is I think that
[00:54:26.600 --> 00:54:28.600]   humans are getting so
[00:54:28.600 --> 00:54:30.600]   sick and tired of being
[00:54:30.600 --> 00:54:32.600]   of only
[00:54:32.600 --> 00:54:34.600]   communicating in these
[00:54:34.600 --> 00:54:36.600]   very rigid ways. Like I'm telling
[00:54:36.600 --> 00:54:38.600]   you, like if you look at our children's generation,
[00:54:38.600 --> 00:54:40.600]   they don't know how to make eye contact.
[00:54:40.600 --> 00:54:42.600]   They don't know how to talk. And I think
[00:54:42.600 --> 00:54:44.600]   it's going to come back and bite them in the ass.
[00:54:44.600 --> 00:54:46.600]   And so I think the pendulum is going to
[00:54:46.600 --> 00:54:48.600]   swing in the other direction where it's like, okay,
[00:54:48.600 --> 00:54:50.600]   enough of this stuff. Let's
[00:54:50.600 --> 00:54:52.600]   actually look each other in the eye and talk to each
[00:54:52.600 --> 00:54:54.600]   other the way that humans were meant to be.
[00:54:54.600 --> 00:54:56.600]   And I think that in that
[00:54:56.600 --> 00:54:58.600]   devices like a glucose monitor
[00:54:58.600 --> 00:55:00.600]   or a band has value, but I
[00:55:00.600 --> 00:55:02.600]   don't think it's going to be this interface where you're
[00:55:02.600 --> 00:55:04.600]   sign languaging it while you're at Coachella.
[00:55:04.600 --> 00:55:06.600]   I think you're going to rip the devices off and
[00:55:06.600 --> 00:55:08.600]   actually be a Coachella without any devices.
[00:55:08.600 --> 00:55:10.600]   Did any of you guys read Jonathan hates book
[00:55:10.600 --> 00:55:12.600]   Anxious Generation. It is
[00:55:12.600 --> 00:55:14.600]   unbelievably awesome. Not right
[00:55:14.600 --> 00:55:16.600]   yet. Stop what you're doing
[00:55:16.600 --> 00:55:18.600]   and just listen to the audio book on your
[00:55:18.600 --> 00:55:20.600]   walks on audible. This book is super
[00:55:20.600 --> 00:55:22.600]   important and awesome. The
[00:55:22.600 --> 00:55:24.600]   Anxious Generation by Jonathan Haidt. I cannot
[00:55:24.600 --> 00:55:26.600]   tell you how important it is. Saxon
[00:55:26.600 --> 00:55:28.600]   and closing feelings here. You have to take any
[00:55:28.600 --> 00:55:30.600]   hot take. Well, I would slightly
[00:55:30.600 --> 00:55:32.600]   disagree with you guys about
[00:55:32.600 --> 00:55:34.600]   this device. So first of all, I
[00:55:34.600 --> 00:55:36.600]   think that humans are becoming more and more cybernetic.
[00:55:36.600 --> 00:55:38.600]   We're getting more and more immersed with
[00:55:38.600 --> 00:55:40.600]   computing power, and I agree
[00:55:40.600 --> 00:55:42.600]   it creates this anxiety and all these problems.
[00:55:42.600 --> 00:55:44.600]   But on the other hand, I think it's an irreversible
[00:55:44.600 --> 00:55:46.600]   trend. So I think that
[00:55:46.600 --> 00:55:48.600]   I would not bet against things that make us
[00:55:48.600 --> 00:55:50.600]   more cybernetic. I think the problem
[00:55:50.600 --> 00:55:52.600]   here is that this company is trying
[00:55:52.600 --> 00:55:54.600]   to do two difficult things. The first
[00:55:54.600 --> 00:55:56.600]   thing is it's trying to capture
[00:55:56.600 --> 00:55:58.600]   everything that's happening in the world around you to
[00:55:58.600 --> 00:56:00.600]   feed it into an AI model so
[00:56:00.600 --> 00:56:02.600]   it can make you smarter. The other
[00:56:02.600 --> 00:56:04.600]   thing is trying to do is reduce your dependence
[00:56:04.600 --> 00:56:06.600]   on your phone by creating
[00:56:06.600 --> 00:56:08.600]   this new projection surface.
[00:56:08.600 --> 00:56:10.600]   And, you know, in my experience
[00:56:10.600 --> 00:56:12.600]   when you try to do two hard things,
[00:56:12.600 --> 00:56:14.600]   you actually square the complexity
[00:56:14.600 --> 00:56:16.600]   and you square the difficulty as opposed
[00:56:16.600 --> 00:56:18.600]   to adding it. So I think
[00:56:18.600 --> 00:56:20.600]   of these two things, the one that sounds interesting
[00:56:20.600 --> 00:56:22.600]   to me is taking in all the information
[00:56:22.600 --> 00:56:24.600]   from the physical world and putting in
[00:56:24.600 --> 00:56:26.600]   an AI model that can be helpful to you.
[00:56:26.600 --> 00:56:28.600]   But I see no reason to replace the phone.
[00:56:28.600 --> 00:56:30.600]   I think it should just work with your phone.
[00:56:30.600 --> 00:56:32.600]   The problem they're going to have is that
[00:56:32.600 --> 00:56:34.600]   that pendant will compete
[00:56:34.600 --> 00:56:36.600]   with the Apple glasses and all the other
[00:56:36.600 --> 00:56:38.600]   wearables that are going to be created
[00:56:38.600 --> 00:56:40.600]   to, you know, suck in all this
[00:56:40.600 --> 00:56:42.600]   information, this computer vision
[00:56:42.600 --> 00:56:44.600]   from the world. Nonetheless,
[00:56:44.600 --> 00:56:46.600]   I do think that is the opportunity. It's
[00:56:46.600 --> 00:56:48.600]   not replacing the phone. It's layering
[00:56:48.600 --> 00:56:50.600]   a new platform on top of
[00:56:50.600 --> 00:56:52.600]   the phone that can kind of,
[00:56:52.600 --> 00:56:54.600]   you know, again, give you that Terminator mode
[00:56:54.600 --> 00:56:56.600]   in the real world. And that was
[00:56:56.600 --> 00:56:58.600]   a complaint about this device specifically was that
[00:56:58.600 --> 00:57:00.600]   it was detached from the phone. I understand
[00:57:00.600 --> 00:57:02.600]   why they want to make it standalone, but
[00:57:02.600 --> 00:57:04.600]   and then this opens up all the privacy.
[00:57:04.600 --> 00:57:06.600]   Let me ask the panel here.
[00:57:06.600 --> 00:57:08.600]   What do you think about this concept
[00:57:08.600 --> 00:57:10.600]   of recording the entire world, all these
[00:57:10.600 --> 00:57:12.600]   conversations and video with these
[00:57:12.600 --> 00:57:14.600]   devices? I think it's a quick way to get yourself
[00:57:14.600 --> 00:57:16.600]   punched in the face. I mean, we saw that with Google
[00:57:16.600 --> 00:57:18.600]   Glass. People showed up at bars
[00:57:18.600 --> 00:57:20.600]   in San Francisco and parties with these Google
[00:57:20.600 --> 00:57:22.600]   Glass things on and literally
[00:57:22.600 --> 00:57:24.600]   got punched in the face. Well, this is
[00:57:24.600 --> 00:57:26.600]   massive privacy things recording your entire
[00:57:26.600 --> 00:57:28.600]   life with a pendant, man. No, thank you.
[00:57:28.600 --> 00:57:30.600]   This is why I said what I said. I do think Saks
[00:57:30.600 --> 00:57:32.600]   is right that ultimately
[00:57:32.600 --> 00:57:34.600]   you'll have some kind of brain
[00:57:34.600 --> 00:57:36.600]   interface because I do think a chip
[00:57:36.600 --> 00:57:38.600]   implant of some kind is very valuable.
[00:57:38.600 --> 00:57:40.600]   But what I'm also saying is that I think
[00:57:40.600 --> 00:57:42.600]   that that will actually lessen
[00:57:42.600 --> 00:57:44.600]   the social
[00:57:44.600 --> 00:57:46.600]   acceptability of these
[00:57:46.600 --> 00:57:48.600]   visible devices that are constantly
[00:57:48.600 --> 00:57:50.600]   getting in between you and another person.
[00:57:50.600 --> 00:57:52.600]   And so the idea that we're
[00:57:52.600 --> 00:57:54.600]   kind of already in a quasi surveillance state
[00:57:54.600 --> 00:57:56.600]   and now we're going to increase
[00:57:56.600 --> 00:57:58.600]   that by n factorial
[00:57:58.600 --> 00:58:00.600]   to the number of people, I think is
[00:58:00.600 --> 00:58:02.600]   very depressing. It is depressing
[00:58:02.600 --> 00:58:04.600]   and you know what? In Jonathan Haidt's book,
[00:58:04.600 --> 00:58:06.600]   he talks about phone lockers
[00:58:06.600 --> 00:58:08.600]   for schools and the transformative
[00:58:08.600 --> 00:58:10.600]   power they have had. When you go to a school,
[00:58:10.600 --> 00:58:12.600]   there are some schools now, high schools,
[00:58:12.600 --> 00:58:14.600]   where the students put their phones in specific
[00:58:14.600 --> 00:58:16.600]   phone lockers. They do it in my kids.
[00:58:16.600 --> 00:58:18.600]   It's actually, Jason, these special
[00:58:18.600 --> 00:58:20.600]   pouches. Pouches.
[00:58:20.600 --> 00:58:22.600]   Those are the pouches comedians use, like
[00:58:22.600 --> 00:58:24.600]   Chappelle at his shows. Chappelle uses it, Kevin
[00:58:24.600 --> 00:58:26.600]   uses them. Yeah, exactly. And they're
[00:58:26.600 --> 00:58:28.600]   great. And then
[00:58:28.600 --> 00:58:30.600]   what the school now also teaches
[00:58:30.600 --> 00:58:32.600]   the kids, at least our school, which I found
[00:58:32.600 --> 00:58:34.600]   really interesting, is the graduated
[00:58:34.600 --> 00:58:36.600]   form of that is they actually now
[00:58:36.600 --> 00:58:38.600]   allow you to put it in a envelope
[00:58:38.600 --> 00:58:40.600]   because they're training the kid.
[00:58:40.600 --> 00:58:42.600]   It's like the pouch you can't get access to.
[00:58:42.600 --> 00:58:44.600]   You have to go back. It locks.
[00:58:44.600 --> 00:58:46.600]   Unlock device. And then I
[00:58:46.600 --> 00:58:48.600]   saw that my son last week had it actually
[00:58:48.600 --> 00:58:50.600]   in a white envelope, and he had to
[00:58:50.600 --> 00:58:52.600]   close the envelope and just keep it with him
[00:58:52.600 --> 00:58:54.600]   as a way of graduating
[00:58:54.600 --> 00:58:56.600]   from the prison form
[00:58:56.600 --> 00:58:58.600]   of keeping the phone away to
[00:58:58.600 --> 00:59:00.600]   having it in your pocket. So the schools
[00:59:00.600 --> 00:59:02.600]   are trying to do a lot to try to teach these kids not
[00:59:02.600 --> 00:59:04.600]   to be so dependent on it. They should ban these devices at
[00:59:04.600 --> 00:59:06.600]   schools 100%. And then at the poker game tonight,
[00:59:06.600 --> 00:59:08.600]   we should make people stack their phones
[00:59:08.600 --> 00:59:10.600]   and charge somebody $1,000 whoever takes the phone
[00:59:10.600 --> 00:59:12.600]   first. Let's do it tonight.
[00:59:12.600 --> 00:59:14.600]   Let me give a shout
[00:59:14.600 --> 00:59:16.600]   out to one of my favorite sci-fi
[00:59:16.600 --> 00:59:18.600]   book series. It's called Nexus by
[00:59:18.600 --> 00:59:20.600]   Ramesh Naum, and it's kind of this cyberpunk
[00:59:20.600 --> 00:59:22.600]   futuristic series.
[00:59:22.600 --> 00:59:24.600]   But what he talks about is
[00:59:24.600 --> 00:59:26.600]   when we have this brain-computer
[00:59:26.600 --> 00:59:28.600]   interface, you'll be able to upload your memories.
[00:59:28.600 --> 00:59:30.600]   And so you talk about
[00:59:30.600 --> 00:59:32.600]   this idea of recording your whole
[00:59:32.600 --> 00:59:34.600]   life through a pendant. Well, eventually
[00:59:34.600 --> 00:59:36.600]   you'll be able to record your whole life based
[00:59:36.600 --> 00:59:38.600]   on just through your eyeballs.
[00:59:38.600 --> 00:59:40.600]   And you'd be able to upload
[00:59:40.600 --> 00:59:42.600]   in theory a first-person view
[00:59:42.600 --> 00:59:44.600]   of whatever
[00:59:44.600 --> 00:59:46.600]   conversation you've been in.
[00:59:46.600 --> 00:59:48.600]   So there's a certain... Look, this
[00:59:48.600 --> 00:59:50.600]   is pretty far off, but there is maybe
[00:59:50.600 --> 00:59:52.600]   a certain inevitability to that.
[00:59:52.600 --> 00:59:54.600]   And we're going to have to figure out how to deal
[00:59:54.600 --> 00:59:56.600]   with the privacy implications there. There was a Black Mirror
[00:59:56.600 --> 00:59:58.600]   episode on this exact idea.
[00:59:58.600 --> 01:00:00.600]   Yeah, you have the DVR of your entire
[01:00:00.600 --> 01:00:02.600]   life, and it is
[01:00:02.600 --> 01:00:04.600]   gnarly to think these things will exist. And I think
[01:00:04.600 --> 01:00:06.600]   humanity's going to have to make a decision
[01:00:06.600 --> 01:00:08.600]   I think to fight this or embrace it. I think
[01:00:08.600 --> 01:00:10.600]   we should fight it. I think it's going to ruin
[01:00:10.600 --> 01:00:12.600]   social existence,
[01:00:12.600 --> 01:00:14.600]   and it's already ruined poker games,
[01:00:14.600 --> 01:00:16.600]   etc., when everybody's on their phone. It's ruined dinner parties
[01:00:16.600 --> 01:00:18.600]   when everybody's on their phones. The constant
[01:00:18.600 --> 01:00:20.600]   distraction is just horrific,
[01:00:20.600 --> 01:00:22.600]   and it's having a horrible impact on this
[01:00:22.600 --> 01:00:24.600]   generation. I'll double down on what you're saying.
[01:00:24.600 --> 01:00:26.600]   It is so lovely to be able to have a dinner
[01:00:26.600 --> 01:00:28.600]   where everybody just talks to each other and looks each
[01:00:28.600 --> 01:00:30.600]   other in the eyes. Yes. And then when you have a
[01:00:30.600 --> 01:00:32.600]   handful of people always on their phone,
[01:00:32.600 --> 01:00:34.600]   it's depressing.
[01:00:34.600 --> 01:00:36.600]   It's actually not even
[01:00:36.600 --> 01:00:38.600]   neutral. It's a net negative and a drag
[01:00:38.600 --> 01:00:40.600]   on the entire night.
[01:00:40.600 --> 01:00:42.600]   Absolutely. I am trying to
[01:00:42.600 --> 01:00:44.600]   come up with ways to remove these devices
[01:00:44.600 --> 01:00:46.600]   from the social settings I'm in.
[01:00:46.600 --> 01:00:48.600]   I've been to a couple of parties with high-profile people where
[01:00:48.600 --> 01:00:50.600]   they have everybody check their phones
[01:00:50.600 --> 01:00:52.600]   at the valet at the door. I gotta
[01:00:52.600 --> 01:00:54.600]   say, those are the best nights of my life. Those are the best nights.
[01:00:54.600 --> 01:00:56.600]   They're incredible. And, you know,
[01:00:56.600 --> 01:00:58.600]   no offense to people who are addicted to their phones.
[01:00:58.600 --> 01:01:00.600]   I am to a certain extent. I put
[01:01:00.600 --> 01:01:02.600]   my social media at one hour on my phone.
[01:01:02.600 --> 01:01:04.600]   My lord, it is hard
[01:01:04.600 --> 01:01:06.600]   to do less than an hour of social media in
[01:01:06.600 --> 01:01:08.600]   our job positions.
[01:01:08.600 --> 01:01:10.600]   I deleted TikTok
[01:01:10.600 --> 01:01:12.600]   about a month ago.
[01:01:12.600 --> 01:01:14.600]   It's been liberating. I was a
[01:01:14.600 --> 01:01:16.600]   slave to that app. I couldn't believe
[01:01:16.600 --> 01:01:18.600]   how much TikTok
[01:01:18.600 --> 01:01:20.600]   I was consuming after
[01:01:20.600 --> 01:01:22.600]   it was gone because I couldn't find anything
[01:01:22.600 --> 01:01:24.600]   to replace it. And then I stumbled
[01:01:24.600 --> 01:01:26.600]   into the fact that YouTube has YouTube
[01:01:26.600 --> 01:01:28.600]   Shorts and there is a lot of that content, but
[01:01:28.600 --> 01:01:30.600]   it's terrible and the algorithm is really
[01:01:30.600 --> 01:01:32.600]   bad. And so
[01:01:32.600 --> 01:01:34.600]   fortunately, I just stopped using YouTube.
[01:01:34.600 --> 01:01:36.600]   It just shows you how the algorithm
[01:01:36.600 --> 01:01:38.600]   is such a key component of that TikTok
[01:01:38.600 --> 01:01:40.600]   experience because I had the same experience.
[01:01:40.600 --> 01:01:42.600]   Shorts
[01:01:42.600 --> 01:01:44.600]   serves up garbage. Instagram
[01:01:44.600 --> 01:01:46.600]   serves up garbage.
[01:01:46.600 --> 01:01:48.600]   And then TikTok is just like right
[01:01:48.600 --> 01:01:50.600]   into your brain. It kicks ass.
[01:01:50.600 --> 01:01:52.600]   It kicks ass. By the way, I want to give
[01:01:52.600 --> 01:01:54.600]   another shout out to a book. I miss TikTok. TikTok,
[01:01:54.600 --> 01:01:56.600]   I miss you. Yeah, whatever. If that's
[01:01:56.600 --> 01:01:58.600]   going away. I miss you. Another incredible book.
[01:01:58.600 --> 01:02:00.600]   I think we should book this speaker
[01:02:00.600 --> 01:02:02.600]   for All In Summit. Bad Therapy.
[01:02:02.600 --> 01:02:04.600]   Why the kids aren't growing
[01:02:04.600 --> 01:02:06.600]   up. Abigail Schreier.
[01:02:06.600 --> 01:02:08.600]   This book is incredible.
[01:02:08.600 --> 01:02:10.600]   And if you read these two, every
[01:02:10.600 --> 01:02:12.600]   parent, read these two books
[01:02:12.600 --> 01:02:14.600]   and we need to have a conversation on it
[01:02:14.600 --> 01:02:16.600]   as parents here. Everybody read these two
[01:02:16.600 --> 01:02:18.600]   books. These are my two top
[01:02:18.600 --> 01:02:20.600]   choices for the All In Summit.
[01:02:20.600 --> 01:02:22.600]   I think it's going to be the topic
[01:02:22.600 --> 01:02:24.600]   of our time. Alright, let's keep
[01:02:24.600 --> 01:02:26.600]   going down this incredible docket. Very important
[01:02:26.600 --> 01:02:28.600]   issue for us to talk about.
[01:02:28.600 --> 01:02:30.600]   Silicon Valley startups having a bit of
[01:02:30.600 --> 01:02:32.600]   the R&D tax
[01:02:32.600 --> 01:02:34.600]   problem. Thanks for putting it on the docket here,
[01:02:34.600 --> 01:02:36.600]   Freeberg. It's a bit inside baseball
[01:02:36.600 --> 01:02:38.600]   but very important topic. Let's
[01:02:38.600 --> 01:02:40.600]   say a company like Acme Corporation
[01:02:40.600 --> 01:02:42.600]   generated a million bucks in revenue and
[01:02:42.600 --> 01:02:44.600]   they spent a million bucks on their software developers
[01:02:44.600 --> 01:02:46.600]   last year. Let's say they had, I don't know,
[01:02:46.600 --> 01:02:48.600]   five developers getting paid 200 grand each.
[01:02:48.600 --> 01:02:50.600]   Well, traditionally, this company would pay nothing
[01:02:50.600 --> 01:02:52.600]   in income tax, right? They spent a million.
[01:02:52.600 --> 01:02:54.600]   They deduct that million from the million dollars
[01:02:54.600 --> 01:02:56.600]   in revenue that came in and
[01:02:56.600 --> 01:02:58.600]   everything's good. But
[01:02:58.600 --> 01:03:00.600]   due to the Tax Cuts and Jobs
[01:03:00.600 --> 01:03:02.600]   Act of 2017,
[01:03:02.600 --> 01:03:04.600]   starting last year, a provision
[01:03:04.600 --> 01:03:06.600]   kicked in, forcing companies to amortize their
[01:03:06.600 --> 01:03:08.600]   R&D expense over five years.
[01:03:08.600 --> 01:03:10.600]   So in this hypothetical situation,
[01:03:10.600 --> 01:03:12.600]   the Acme Corporation
[01:03:12.600 --> 01:03:14.600]   would amortize 200k a year
[01:03:14.600 --> 01:03:16.600]   and pay income tax on the 800k in
[01:03:16.600 --> 01:03:18.600]   profits. This is brutal
[01:03:18.600 --> 01:03:20.600]   obviously for a startup. Profits, air quotes.
[01:03:20.600 --> 01:03:22.600]   Air quotes, profits, correct.
[01:03:22.600 --> 01:03:24.600]   And this is absolutely brutal.
[01:03:24.600 --> 01:03:26.600]   And a lot of companies
[01:03:26.600 --> 01:03:28.600]   took a wait-and-see approach, hoping Congress would
[01:03:28.600 --> 01:03:30.600]   fix the issue in January, a bipartisan
[01:03:30.600 --> 01:03:32.600]   tax bill that would reverse these changes
[01:03:32.600 --> 01:03:34.600]   passed in the House. But the bill
[01:03:34.600 --> 01:03:36.600]   has stalled in the Senate. And we've got to get this
[01:03:36.600 --> 01:03:38.600]   thing fixed because it's going to sink a lot of startups.
[01:03:38.600 --> 01:03:40.600]   Maybe people will start putting
[01:03:40.600 --> 01:03:42.600]   their companies in other countries.
[01:03:42.600 --> 01:03:44.600]   But it's attached
[01:03:44.600 --> 01:03:46.600]   to this child tax credit, which Republicans
[01:03:46.600 --> 01:03:48.600]   don't want to pass. So no reversal
[01:03:48.600 --> 01:03:50.600]   has happened. Freeberg, you highlighted this for us.
[01:03:50.600 --> 01:03:52.600]   Very important topic. Thank you for doing so.
[01:03:52.600 --> 01:03:54.600]   As our
[01:03:54.600 --> 01:03:56.600]   great
[01:03:56.600 --> 01:03:58.600]   contributor here, what are your thoughts on it?
[01:03:58.600 --> 01:04:00.600]   This became law in the
[01:04:00.600 --> 01:04:02.600]   2017 Jobs Act,
[01:04:02.600 --> 01:04:04.600]   as you highlighted.
[01:04:04.600 --> 01:04:06.600]   And basically it means that companies,
[01:04:06.600 --> 01:04:08.600]   not just like tech companies,
[01:04:08.600 --> 01:04:10.600]   but life sciences companies,
[01:04:10.600 --> 01:04:12.600]   defense companies, are pushing
[01:04:12.600 --> 01:04:14.600]   Congress to change this law
[01:04:14.600 --> 01:04:16.600]   because you can't actually
[01:04:16.600 --> 01:04:18.600]   deduct the expenses
[01:04:18.600 --> 01:04:20.600]   that you use to run your business.
[01:04:20.600 --> 01:04:22.600]   You have to only deduct them over five
[01:04:22.600 --> 01:04:24.600]   years, 20% a year. So
[01:04:24.600 --> 01:04:26.600]   like you pointed out, if you're making a million dollars, but
[01:04:26.600 --> 01:04:28.600]   you're spending a million dollars, you made no profit.
[01:04:28.600 --> 01:04:30.600]   But you've got to pay taxes as if you made
[01:04:30.600 --> 01:04:32.600]   800 grand in profit. And a lot of
[01:04:32.600 --> 01:04:34.600]   these small companies don't have that cash.
[01:04:34.600 --> 01:04:36.600]   So venture capital-backed companies
[01:04:36.600 --> 01:04:38.600]   and public companies that are
[01:04:38.600 --> 01:04:40.600]   profitable, they can afford to do this because they have
[01:04:40.600 --> 01:04:42.600]   large balance sheets. So it doesn't affect them as much
[01:04:42.600 --> 01:04:44.600]   as it does the literally
[01:04:44.600 --> 01:04:46.600]   hundreds of thousands
[01:04:46.600 --> 01:04:48.600]   of small businesses that work in
[01:04:48.600 --> 01:04:50.600]   the life sciences sector, the defense sector, the
[01:04:50.600 --> 01:04:52.600]   tech sector, that are struggling
[01:04:52.600 --> 01:04:54.600]   this year to make the tax
[01:04:54.600 --> 01:04:56.600]   payments that are required
[01:04:56.600 --> 01:04:58.600]   under this law that went into effect last
[01:04:58.600 --> 01:05:00.600]   year. And Congress promised that they
[01:05:00.600 --> 01:05:02.600]   were going to repeal this law
[01:05:02.600 --> 01:05:04.600]   leading up to April 15th, which happened
[01:05:04.600 --> 01:05:06.600]   obviously a few days ago,
[01:05:06.600 --> 01:05:08.600]   and make it retroactive to 2023,
[01:05:08.600 --> 01:05:10.600]   but they didn't. But, Freeberg, they know basic
[01:05:10.600 --> 01:05:12.600]   math. Congress knows basic math.
[01:05:12.600 --> 01:05:14.600]   How do they...
[01:05:14.600 --> 01:05:16.600]   What loophole do they think they're closing?
[01:05:16.600 --> 01:05:18.600]   So the original intent
[01:05:18.600 --> 01:05:20.600]   was that this was one of the ways... You guys know
[01:05:20.600 --> 01:05:22.600]   whenever you pass a bill, it gets
[01:05:22.600 --> 01:05:24.600]   run through the OMB and the CBO
[01:05:24.600 --> 01:05:26.600]   that figures out what's the budgetary cost
[01:05:26.600 --> 01:05:28.600]   of the bill. And one of the ways
[01:05:28.600 --> 01:05:30.600]   that they made this work, this bill,
[01:05:30.600 --> 01:05:32.600]   the 2017 Trump Tax and Jobs Act, you guys
[01:05:32.600 --> 01:05:34.600]   may remember in that bill, they also
[01:05:34.600 --> 01:05:36.600]   made it impossible to deduct
[01:05:36.600 --> 01:05:38.600]   entertainment and dining expenses when you take people
[01:05:38.600 --> 01:05:40.600]   out to dinner anymore. That sucks.
[01:05:40.600 --> 01:05:42.600]   And they did all those things to make up some of the money
[01:05:42.600 --> 01:05:44.600]   they were using for basic general
[01:05:44.600 --> 01:05:46.600]   tax breaks for companies.
[01:05:46.600 --> 01:05:48.600]   So they used this as a way to say, "Look,
[01:05:48.600 --> 01:05:50.600]   in a couple of years, we're going to kick in this R&D
[01:05:50.600 --> 01:05:52.600]   expenditure thing, and it'll trigger
[01:05:52.600 --> 01:05:54.600]   a lot more revenue for the federal
[01:05:54.600 --> 01:05:56.600]   government. It'll create a lot more taxes
[01:05:56.600 --> 01:05:58.600]   and a lot more revenue." So that was the idea.
[01:05:58.600 --> 01:06:00.600]   And everyone was like, "Yeah, okay, sure. We'll do
[01:06:00.600 --> 01:06:02.600]   that. Great. It makes the accounting work.
[01:06:02.600 --> 01:06:04.600]   And then in a couple years, nudge, nudge, wink, wink,
[01:06:04.600 --> 01:06:06.600]   we're going to come back and repeal it." Except
[01:06:06.600 --> 01:06:08.600]   Congress has stalled out.
[01:06:08.600 --> 01:06:10.600]   There's this ineptitude where anytime
[01:06:10.600 --> 01:06:12.600]   someone tries to pass a bill in Congress,
[01:06:12.600 --> 01:06:14.600]   someone else says, "I want to get money."
[01:06:14.600 --> 01:06:16.600]   And so the Democrats showed up
[01:06:16.600 --> 01:06:18.600]   and said, "We want this child tax credit thing
[01:06:18.600 --> 01:06:20.600]   to show up," which basically
[01:06:20.600 --> 01:06:22.600]   was passed during
[01:06:22.600 --> 01:06:24.600]   COVID. And they want to extend
[01:06:24.600 --> 01:06:26.600]   it going forward. And the child tax
[01:06:26.600 --> 01:06:28.600]   credit says that you can get
[01:06:28.600 --> 01:06:30.600]   a check for $1,800 a year in
[01:06:30.600 --> 01:06:32.600]   2023, $1,900 in 2024,
[01:06:32.600 --> 01:06:34.600]   and $2,000 in 2025
[01:06:34.600 --> 01:06:36.600]   for each child you have.
[01:06:36.600 --> 01:06:38.600]   And the Republicans in the Senate are saying,
[01:06:38.600 --> 01:06:40.600]   "Wait a second. For people to get this
[01:06:40.600 --> 01:06:42.600]   thing, we want to make sure they're working. We want to
[01:06:42.600 --> 01:06:44.600]   make sure it's not as retroactive." So now
[01:06:44.600 --> 01:06:46.600]   there's this big debate about how big the child tax
[01:06:46.600 --> 01:06:48.600]   credit should be. And that's keeping
[01:06:48.600 --> 01:06:50.600]   this R&D thing from
[01:06:50.600 --> 01:06:52.600]   going through. And meanwhile, I've gotten tons
[01:06:52.600 --> 01:06:54.600]   of emails from CEOs of tech companies
[01:06:54.600 --> 01:06:56.600]   that are breaking even. These are not tech
[01:06:56.600 --> 01:06:58.600]   companies that are making a ton of profit. They're not public.
[01:06:58.600 --> 01:07:00.600]   They're not venture-backed. They're just
[01:07:00.600 --> 01:07:02.600]   people running their
[01:07:02.600 --> 01:07:04.600]   business. And now they're going to have
[01:07:04.600 --> 01:07:06.600]   this huge tax bill, even though they didn't make any money
[01:07:06.600 --> 01:07:08.600]   this year. And it's crippling
[01:07:08.600 --> 01:07:10.600]   businesses around the country, and it needs to be fixed.
[01:07:10.600 --> 01:07:12.600]   They're going to write a check.
[01:07:12.600 --> 01:07:14.600]   They're going to borrow money. They're going to go to the bank, borrow
[01:07:14.600 --> 01:07:16.600]   money, or they're going to incur penalties at the
[01:07:16.600 --> 01:07:18.600]   IRS because they don't have the cash to pay the
[01:07:18.600 --> 01:07:20.600]   tax bill. Because they don't have any profit. They didn't
[01:07:20.600 --> 01:07:22.600]   make any money. If they just ran the business
[01:07:22.600 --> 01:07:24.600]   break-even, which a lot of these companies do, is just
[01:07:24.600 --> 01:07:26.600]   make a little bit of money or break even.
[01:07:26.600 --> 01:07:28.600]   And then they've got this huge tax bill and profits
[01:07:28.600 --> 01:07:30.600]   they didn't actually have. They've got to go figure
[01:07:30.600 --> 01:07:32.600]   out how to write a check. And also, how do you define
[01:07:32.600 --> 01:07:34.600]   R&D? I was talking to an accountant. He's like, "Yeah, I don't know
[01:07:34.600 --> 01:07:36.600]   if that's R&D." I'm like, "You don't know if it's R&D?"
[01:07:36.600 --> 01:07:38.600]   Like, okay, so if I make some piece
[01:07:38.600 --> 01:07:40.600]   of software... Yeah. Yeah.
[01:07:40.600 --> 01:07:42.600]   There's all this writing in the...
[01:07:42.600 --> 01:07:44.600]   If you get audited by the IRS,
[01:07:44.600 --> 01:07:46.600]   they have the ability to basically
[01:07:46.600 --> 01:07:48.600]   capture everything. So, like, let's say you're a
[01:07:48.600 --> 01:07:50.600]   mobile app developer. And you
[01:07:50.600 --> 01:07:52.600]   make a million dollars a year, but you spend
[01:07:52.600 --> 01:07:54.600]   a million dollars a year on your developers.
[01:07:54.600 --> 01:07:56.600]   Okay. They're going to count that.
[01:07:56.600 --> 01:07:58.600]   They have the ability to count that as an R&D.
[01:07:58.600 --> 01:08:00.600]   So, the accountants, the tax accountants, tell
[01:08:00.600 --> 01:08:02.600]   you, "Book it all as R&D." Because
[01:08:02.600 --> 01:08:04.600]   otherwise, you could get audited and actually get in trouble.
[01:08:04.600 --> 01:08:06.600]   Because anything that involves the development
[01:08:06.600 --> 01:08:08.600]   of technology now is considered R&D.
[01:08:08.600 --> 01:08:10.600]   Again, a company working in life sciences
[01:08:10.600 --> 01:08:12.600]   as a research company doing lab
[01:08:12.600 --> 01:08:14.600]   work can kind of... Yeah, but if I do bug fixes,
[01:08:14.600 --> 01:08:16.600]   is a bug fix R&D?
[01:08:16.600 --> 01:08:18.600]   If I make a new feature in an application
[01:08:18.600 --> 01:08:20.600]   this year, does it have to be
[01:08:20.600 --> 01:08:22.600]   amortized over five years? If I put a new
[01:08:22.600 --> 01:08:24.600]   filter on a photo... I'm not a tax attorney. My understanding
[01:08:24.600 --> 01:08:26.600]   is most of this stuff is getting
[01:08:26.600 --> 01:08:28.600]   captured, and that's why it's hurting everything from defense
[01:08:28.600 --> 01:08:30.600]   to life sciences
[01:08:30.600 --> 01:08:32.600]   to lab equipment to
[01:08:32.600 --> 01:08:34.600]   startups that make software to everything.
[01:08:34.600 --> 01:08:36.600]   And Congress can't get out
[01:08:36.600 --> 01:08:38.600]   of its own way, where this bill passed,
[01:08:38.600 --> 01:08:40.600]   by the way, bipartisan in the
[01:08:40.600 --> 01:08:42.600]   House. Then it went to the Senate,
[01:08:42.600 --> 01:08:44.600]   and now it's getting taken apart in the Senate, and now
[01:08:44.600 --> 01:08:46.600]   it's stalled out, and everyone's freaking out that it's stalled out
[01:08:46.600 --> 01:08:48.600]   past April 15th. And
[01:08:48.600 --> 01:08:50.600]   it's actually going to hurt a lot of small businesses
[01:08:50.600 --> 01:08:52.600]   in this country. And here's the other problem,
[01:08:52.600 --> 01:08:54.600]   is it actually limits
[01:08:54.600 --> 01:08:56.600]   our ability to invest in innovation in this
[01:08:56.600 --> 01:08:58.600]   country. Because now you're better off...
[01:08:58.600 --> 01:09:00.600]   There's no other country in the world that does this.
[01:09:00.600 --> 01:09:02.600]   Every other country in the world tries
[01:09:02.600 --> 01:09:04.600]   to incentivize investment in innovation,
[01:09:04.600 --> 01:09:06.600]   and here in the U.S., we're basically saying
[01:09:06.600 --> 01:09:08.600]   no, we're going to tax
[01:09:08.600 --> 01:09:10.600]   you for investing in technology
[01:09:10.600 --> 01:09:12.600]   development and innovation. And the
[01:09:12.600 --> 01:09:14.600]   other thing that's actually not being talked
[01:09:14.600 --> 01:09:16.600]   about, is even in this bill
[01:09:16.600 --> 01:09:18.600]   where they're repealing this, they're
[01:09:18.600 --> 01:09:20.600]   leaving in the fact
[01:09:20.600 --> 01:09:22.600]   that if you invest in R&D outside
[01:09:22.600 --> 01:09:24.600]   the U.S., you have to amortize
[01:09:24.600 --> 01:09:26.600]   it over 15 years.
[01:09:26.600 --> 01:09:28.600]   So let's say that you're a U.S. developer, and you
[01:09:28.600 --> 01:09:30.600]   hire people offshore,
[01:09:30.600 --> 01:09:32.600]   you've got to basically amortize
[01:09:32.600 --> 01:09:34.600]   the offshore stuff over 15 years,
[01:09:34.600 --> 01:09:36.600]   which means you'll never make a profit, you're always
[01:09:36.600 --> 01:09:38.600]   going to have to pay taxes.
[01:09:38.600 --> 01:09:40.600]   We're trying to kill innovation in this country,
[01:09:40.600 --> 01:09:42.600]   and the two things they've got to solve
[01:09:42.600 --> 01:09:44.600]   is this one, and then M&A.
[01:09:44.600 --> 01:09:46.600]   We've got to have a
[01:09:46.600 --> 01:09:48.600]   better solution for allowing
[01:09:48.600 --> 01:09:50.600]   companies to be bought and sold
[01:09:50.600 --> 01:09:52.600]   or merge in this country.
[01:09:52.600 --> 01:09:54.600]   These two things are putting a lot
[01:09:54.600 --> 01:09:56.600]   of headwinds on
[01:09:56.600 --> 01:09:58.600]   the startup ecosystem and on the venture
[01:09:58.600 --> 01:10:00.600]   and the risk-taking capital ecosystems.
[01:10:00.600 --> 01:10:02.600]   If you're in
[01:10:02.600 --> 01:10:04.600]   Washington, D.C.
[01:10:04.600 --> 01:10:06.600]   or you're involved in our government, please
[01:10:06.600 --> 01:10:08.600]   solve these two issues. You've got to figure
[01:10:08.600 --> 01:10:10.600]   out a way to allow companies to be bought and
[01:10:10.600 --> 01:10:12.600]   sold. You've got to figure out a way
[01:10:12.600 --> 01:10:14.600]   to fix this
[01:10:14.600 --> 01:10:16.600]   tax issue, or else we're going to kill a lot
[01:10:16.600 --> 01:10:18.600]   of startups, and these are the companies
[01:10:18.600 --> 01:10:20.600]   that pay a lot of taxes,
[01:10:20.600 --> 01:10:22.600]   and these are the capital gains that fund
[01:10:22.600 --> 01:10:24.600]   a lot of states' treasuries.
[01:10:24.600 --> 01:10:26.600]   It's also an illustration of
[01:10:26.600 --> 01:10:28.600]   just how hungry we are for tax
[01:10:28.600 --> 01:10:30.600]   revenue in this country.
[01:10:30.600 --> 01:10:32.600]   It's only going to grow, and I'm not sitting here
[01:10:32.600 --> 01:10:34.600]   complaining about taxes. The Trump
[01:10:34.600 --> 01:10:36.600]   tax cut that he put in place in 2017
[01:10:36.600 --> 01:10:38.600]   added $1.5 trillion
[01:10:38.600 --> 01:10:40.600]   to the federal deficit.
[01:10:40.600 --> 01:10:42.600]   Tax cuts in general are not
[01:10:42.600 --> 01:10:44.600]   great when you're spending a lot, but it
[01:10:44.600 --> 01:10:46.600]   does highlight just how much we are spending at
[01:10:46.600 --> 01:10:48.600]   the federal level and the demand for tax
[01:10:48.600 --> 01:10:50.600]   revenue, and that demand causes
[01:10:50.600 --> 01:10:52.600]   this counter-cyclical problem,
[01:10:52.600 --> 01:10:54.600]   which is now we're going to eat into innovation,
[01:10:54.600 --> 01:10:56.600]   but it's supposed to get us out of
[01:10:56.600 --> 01:10:58.600]   the problem, the spiral that results
[01:10:58.600 --> 01:11:00.600]   from this debt. So,
[01:11:00.600 --> 01:11:02.600]   it really highlights just the challenges
[01:11:02.600 --> 01:11:04.600]   that are going to emerge, particularly in the decade
[01:11:04.600 --> 01:11:06.600]   ahead, because we have all of the spending
[01:11:06.600 --> 01:11:08.600]   that's coming in front of us over the next decade,
[01:11:08.600 --> 01:11:10.600]   and how we're going to start to demand more and more tax
[01:11:10.600 --> 01:11:12.600]   in all these weird ways that can really
[01:11:12.600 --> 01:11:14.600]   hurt industry. Unintended
[01:11:14.600 --> 01:11:16.600]   consequences are very real.
[01:11:16.600 --> 01:11:18.600]   Shamath, you were going to say something?
[01:11:18.600 --> 01:11:20.600]   Well, doesn't it mean, though,
[01:11:20.600 --> 01:11:22.600]   that if you run it at breakeven
[01:11:22.600 --> 01:11:24.600]   and without a lot
[01:11:24.600 --> 01:11:26.600]   of growth, by year five, you'll be back
[01:11:26.600 --> 01:11:28.600]   to where you were, so you really have to cover
[01:11:28.600 --> 01:11:30.600]   the taxes in years one through four?
[01:11:30.600 --> 01:11:32.600]   That's right. But if the business
[01:11:32.600 --> 01:11:34.600]   is growing, you're always going to be in a hole.
[01:11:34.600 --> 01:11:36.600]   Right.
[01:11:36.600 --> 01:11:38.600]   Right. So, if your revenue is growing and your
[01:11:38.600 --> 01:11:40.600]   OPEX is growing, you're always going to be in a hole.
[01:11:40.600 --> 01:11:42.600]   I think Jason mentioned it earlier, and I think
[01:11:42.600 --> 01:11:44.600]   it's the key thing, which is, what is R&D then?
[01:11:44.600 --> 01:11:46.600]   Yeah. And maybe
[01:11:46.600 --> 01:11:48.600]   you just move things to COGS
[01:11:48.600 --> 01:11:50.600]   and just be done with it. I mean, that's what I would do.
[01:11:50.600 --> 01:11:52.600]   Remember, businesses,
[01:11:52.600 --> 01:11:54.600]   and you guys know this, when you look at a public
[01:11:54.600 --> 01:11:56.600]   company's financials, what you're seeing
[01:11:56.600 --> 01:11:58.600]   is their GAAP financials, Generally Accepted
[01:11:58.600 --> 01:12:00.600]   Accounting Principles.
[01:12:00.600 --> 01:12:02.600]   And that's the way that you present
[01:12:02.600 --> 01:12:04.600]   the financials of a business. That's different
[01:12:04.600 --> 01:12:06.600]   than the way you present financials to the IRS.
[01:12:06.600 --> 01:12:08.600]   You don't have a lot of discretion
[01:12:08.600 --> 01:12:10.600]   in your tax financials.
[01:12:10.600 --> 01:12:12.600]   Your tax financials are actually quite different
[01:12:12.600 --> 01:12:14.600]   than your GAAP financials. Yes.
[01:12:14.600 --> 01:12:16.600]   So, when you file your taxes,
[01:12:16.600 --> 01:12:18.600]   there's a lot of rules on what you are allowed to deduct
[01:12:18.600 --> 01:12:20.600]   and aren't allowed to deduct that's quite different
[01:12:20.600 --> 01:12:22.600]   than how you present your corporate financials to investors.
[01:12:22.600 --> 01:12:24.600]   And that's really where people get screwed.
[01:12:24.600 --> 01:12:26.600]   You don't have that sort of discretion that you do
[01:12:26.600 --> 01:12:28.600]   in kind of
[01:12:28.600 --> 01:12:30.600]   sharing your financials with investors.
[01:12:30.600 --> 01:12:32.600]   This is not financial or accounting advice.
[01:12:32.600 --> 01:12:34.600]   Get great representation. I just hope Congress
[01:12:34.600 --> 01:12:36.600]   resolves this because it's... Yes.
[01:12:36.600 --> 01:12:38.600]   Super important. Alright, sports betting has
[01:12:38.600 --> 01:12:40.600]   gone mainstream, if you don't know.
[01:12:40.600 --> 01:12:42.600]   Two out of three colleges have placed a bet in the
[01:12:42.600 --> 01:12:44.600]   last year since the
[01:12:44.600 --> 01:12:46.600]   Supreme Court struck down the Amateur
[01:12:46.600 --> 01:12:48.600]   Sports Protection Act. 38 states
[01:12:48.600 --> 01:12:50.600]   have legalized sports betting.
[01:12:50.600 --> 01:12:52.600]   I think that's a great thing, but we're starting to see some
[01:12:52.600 --> 01:12:54.600]   weird behavior because of it.
[01:12:54.600 --> 01:12:56.600]   Tons of sites like DraftKings, FanDuel,
[01:12:56.600 --> 01:12:58.600]   ESPNBet,
[01:12:58.600 --> 01:13:00.600]   BetMGM, all of these have broken out.
[01:13:00.600 --> 01:13:02.600]   But this week,
[01:13:02.600 --> 01:13:04.600]   we started to see some weird behavior. The NBA
[01:13:04.600 --> 01:13:06.600]   banned a 24-year-old player,
[01:13:06.600 --> 01:13:08.600]   John Tay Porter,
[01:13:08.600 --> 01:13:10.600]   for life after a scandal.
[01:13:10.600 --> 01:13:12.600]   This one is bizarre
[01:13:12.600 --> 01:13:14.600]   and interesting. Porter was
[01:13:14.600 --> 01:13:16.600]   a bench player for the Toronto Raptors,
[01:13:16.600 --> 01:13:18.600]   averaging about 14 minutes per game.
[01:13:18.600 --> 01:13:20.600]   It's important. On these gambling
[01:13:20.600 --> 01:13:22.600]   apps, you can do all kinds of prop bets. For those
[01:13:22.600 --> 01:13:24.600]   of you who don't know, prop bets
[01:13:24.600 --> 01:13:26.600]   could be things like Steph is
[01:13:26.600 --> 01:13:28.600]   going to hit five threes in
[01:13:28.600 --> 01:13:30.600]   a game, or LeBron's going to score under
[01:13:30.600 --> 01:13:32.600]   30 points. You're just betting on unique
[01:13:32.600 --> 01:13:34.600]   things that could happen, and then you can parlay
[01:13:34.600 --> 01:13:36.600]   them together. You can put multiple bets together,
[01:13:36.600 --> 01:13:38.600]   and it automatically gives you a price,
[01:13:38.600 --> 01:13:40.600]   and you can do really
[01:13:40.600 --> 01:13:42.600]   deep
[01:13:42.600 --> 01:13:44.600]   numbers doing this.
[01:13:44.600 --> 01:13:46.600]   The NBA found out that Porter was telling
[01:13:46.600 --> 01:13:48.600]   people to bet his unders
[01:13:48.600 --> 01:13:50.600]   for points and rebounds during certain games.
[01:13:50.600 --> 01:13:52.600]   During those games, he'd play a few minutes,
[01:13:52.600 --> 01:13:54.600]   then check himself out of
[01:13:54.600 --> 01:13:56.600]   the game with an "illness."
[01:13:56.600 --> 01:13:58.600]   Technically, the bet would still
[01:13:58.600 --> 01:14:00.600]   count since he played the game, but everybody
[01:14:00.600 --> 01:14:02.600]   who bet his unders would win. Normally,
[01:14:02.600 --> 01:14:04.600]   nobody would notice this, of course,
[01:14:04.600 --> 01:14:06.600]   because he doesn't play that much. He's a bench player.
[01:14:06.600 --> 01:14:08.600]   But DraftKings, because they
[01:14:08.600 --> 01:14:10.600]   have all the data,
[01:14:10.600 --> 01:14:12.600]   ripped everyone off because
[01:14:12.600 --> 01:14:14.600]   Porter was
[01:14:14.600 --> 01:14:16.600]   the biggest moneymaker on March 20th.
[01:14:16.600 --> 01:14:18.600]   This led to an NBA investigation.
[01:14:18.600 --> 01:14:20.600]   DraftKings will give you a leaderboard of the
[01:14:20.600 --> 01:14:22.600]   biggest bets, and they saw that somebody
[01:14:22.600 --> 01:14:24.600]   placed an $80,000 bet that Porter would
[01:14:24.600 --> 01:14:26.600]   hit the unders on a bunch of different categories.
[01:14:26.600 --> 01:14:28.600]   Crazy outlier bet.
[01:14:28.600 --> 01:14:30.600]   DraftKings canceled the bet.
[01:14:30.600 --> 01:14:32.600]   The NBA found that Porter separately
[01:14:32.600 --> 01:14:34.600]   placed dozens of bets on NBA
[01:14:34.600 --> 01:14:36.600]   games using his friends' accounts,
[01:14:36.600 --> 01:14:38.600]   winning a whopping $22,000.
[01:14:38.600 --> 01:14:40.600]   And this idiot
[01:14:40.600 --> 01:14:42.600]   now is banned from life from the NBA.
[01:14:42.600 --> 01:14:44.600]   Allegedly, allegedly, allegedly.
[01:14:44.600 --> 01:14:46.600]   But, obviously,
[01:14:46.600 --> 01:14:48.600]   the NBA has
[01:14:48.600 --> 01:14:50.600]   the receipts with DraftKings. Chamath,
[01:14:50.600 --> 01:14:52.600]   you owned a NBA team for
[01:14:52.600 --> 01:14:54.600]   a little while, and you watched as David
[01:14:54.600 --> 01:14:56.600]   Stern—for a decade—you watched as
[01:14:56.600 --> 01:14:58.600]   David Stern, who was
[01:14:58.600 --> 01:15:00.600]   absolutely opposed to
[01:15:00.600 --> 01:15:02.600]   gambling, and then Adam Silver
[01:15:02.600 --> 01:15:04.600]   embraced it. Tell us, from
[01:15:04.600 --> 01:15:06.600]   your front-row seat, your thoughts
[01:15:06.600 --> 01:15:08.600]   on wagering in the NBA.
[01:15:08.600 --> 01:15:10.600]   And wagering writ large.
[01:15:10.600 --> 01:15:12.600]   Okay, look,
[01:15:12.600 --> 01:15:14.600]   I remember when
[01:15:14.600 --> 01:15:18.600]   I joined
[01:15:18.600 --> 01:15:20.600]   the ownership group of the Warriors, I had to file
[01:15:20.600 --> 01:15:22.600]   this enormous document.
[01:15:22.600 --> 01:15:24.600]   And one of the things that they really
[01:15:24.600 --> 01:15:26.600]   dig into is
[01:15:26.600 --> 01:15:28.600]   whether you've bet before.
[01:15:28.600 --> 01:15:30.600]   And they make it
[01:15:30.600 --> 01:15:32.600]   really, really clear that
[01:15:32.600 --> 01:15:34.600]   it is completely
[01:15:34.600 --> 01:15:36.600]   not allowed to bet.
[01:15:36.600 --> 01:15:38.600]   And the only way that you can bet is if you're betting
[01:15:38.600 --> 01:15:40.600]   on non-basketball and if you were in
[01:15:40.600 --> 01:15:42.600]   Vegas and you go to a casino and a troop
[01:15:42.600 --> 01:15:44.600]   sportsbook. That's the only time it's
[01:15:44.600 --> 01:15:46.600]   tolerated. The thing with all
[01:15:46.600 --> 01:15:48.600]   of these sites, FanDuel and
[01:15:48.600 --> 01:15:50.600]   DraftKings, is they did deals
[01:15:50.600 --> 01:15:52.600]   with the leagues, where
[01:15:52.600 --> 01:15:54.600]   part of the feature is that when
[01:15:54.600 --> 01:15:56.600]   there is really crazy, asymmetric
[01:15:56.600 --> 01:15:58.600]   betting on something that's obscure,
[01:15:58.600 --> 01:16:00.600]   they report it back to the leagues
[01:16:00.600 --> 01:16:02.600]   so the leagues know how to look at it. Because
[01:16:02.600 --> 01:16:04.600]   typically what happens is,
[01:16:04.600 --> 01:16:06.600]   if you're talking like
[01:16:06.600 --> 01:16:08.600]   a very well-contested basketball chaser,
[01:16:08.600 --> 01:16:10.600]   you have a relatively
[01:16:10.600 --> 01:16:12.600]   balanced book, right?
[01:16:12.600 --> 01:16:14.600]   And what the goal is, is to figure out where
[01:16:14.600 --> 01:16:16.600]   are the sharps betting, meaning the really smart money
[01:16:16.600 --> 01:16:18.600]   guys, and everybody else is a
[01:16:18.600 --> 01:16:20.600]   square, and most of retail is a square.
[01:16:20.600 --> 01:16:22.600]   Okay, they're going to lose their money. And so
[01:16:22.600 --> 01:16:24.600]   the goal is to always find out where the sharps are
[01:16:24.600 --> 01:16:26.600]   going. But there are some of these bets,
[01:16:26.600 --> 01:16:28.600]   and in this case, this is why they found out,
[01:16:28.600 --> 01:16:30.600]   when you have something being
[01:16:30.600 --> 01:16:32.600]   bet that's very obscure in size,
[01:16:32.600 --> 01:16:34.600]   these apps immediately
[01:16:34.600 --> 01:16:36.600]   go back to the league and say, "This just
[01:16:36.600 --> 01:16:38.600]   happened." So compare
[01:16:38.600 --> 01:16:40.600]   that to, Chamath, what would happen previously
[01:16:40.600 --> 01:16:42.600]   before sports betting was legal
[01:16:42.600 --> 01:16:44.600]   in the US. Before what would
[01:16:44.600 --> 01:16:46.600]   happen is like, all of these
[01:16:46.600 --> 01:16:48.600]   bookies would be able to have relationships
[01:16:48.600 --> 01:16:50.600]   with some of these players. Sometimes
[01:16:50.600 --> 01:16:52.600]   they would also have relationships
[01:16:52.600 --> 01:16:54.600]   with some of the refs, and it has
[01:16:54.600 --> 01:16:56.600]   spilled over. So the NBA has had to deal
[01:16:56.600 --> 01:16:58.600]   with an example where one of
[01:16:58.600 --> 01:17:00.600]   the refs were, I think he was betting on
[01:17:00.600 --> 01:17:02.600]   some games. Tim Donaghy, yeah. Tim Donaghy, and then
[01:17:02.600 --> 01:17:04.600]   he was point shaving. So this has been
[01:17:04.600 --> 01:17:06.600]   going on for a long time.
[01:17:06.600 --> 01:17:08.600]   It moved into the realm of
[01:17:08.600 --> 01:17:10.600]   it being automated with
[01:17:10.600 --> 01:17:12.600]   algorithms looking out.
[01:17:12.600 --> 01:17:14.600]   The fact that this kid
[01:17:14.600 --> 01:17:16.600]   didn't have anybody on his team that
[01:17:16.600 --> 01:17:18.600]   explained that DraftKings
[01:17:18.600 --> 01:17:20.600]   and FanDuel are going to send
[01:17:20.600 --> 01:17:22.600]   this data to the NBA
[01:17:22.600 --> 01:17:24.600]   is inexcusable, because maybe the kid
[01:17:24.600 --> 01:17:26.600]   would not have done it.
[01:17:26.600 --> 01:17:28.600]   Do you agree with the lifetime ban? Or do you think this should be...
[01:17:28.600 --> 01:17:30.600]   Yeah, it has to be lifetime.
[01:17:30.600 --> 01:17:32.600]   Has to be for the NBA to have integrity.
[01:17:32.600 --> 01:17:34.600]   Has to be.
[01:17:34.600 --> 01:17:36.600]   Yeah, it's really...
[01:17:36.600 --> 01:17:38.600]   What do we think about
[01:17:38.600 --> 01:17:40.600]   this becoming legal in the US and
[01:17:40.600 --> 01:17:42.600]   people embracing... The other thing I'll say,
[01:17:42.600 --> 01:17:44.600]   and I mentioned this a few weeks ago,
[01:17:44.600 --> 01:17:46.600]   everything
[01:17:46.600 --> 01:17:48.600]   is being gamified.
[01:17:48.600 --> 01:17:50.600]   You have an entire population
[01:17:50.600 --> 01:17:52.600]   that seemingly, in America,
[01:17:52.600 --> 01:17:54.600]   consumer spending still goes up.
[01:17:54.600 --> 01:17:56.600]   Folks are relatively
[01:17:56.600 --> 01:17:58.600]   still flush with cash.
[01:17:58.600 --> 01:18:00.600]   There's lots of free cash flow.
[01:18:00.600 --> 01:18:02.600]   There are new and more
[01:18:02.600 --> 01:18:04.600]   aggressive forms of
[01:18:04.600 --> 01:18:06.600]   stimulus constantly coming down the pike.
[01:18:06.600 --> 01:18:08.600]   Whether it's student loan
[01:18:08.600 --> 01:18:10.600]   forgiveness or something else, right? Governments are
[01:18:10.600 --> 01:18:12.600]   inventing new and new ways of buying votes.
[01:18:12.600 --> 01:18:14.600]   That's going to put more and more money in people's
[01:18:14.600 --> 01:18:16.600]   hands. That means
[01:18:16.600 --> 01:18:18.600]   a larger and larger percentage of it will bleed
[01:18:18.600 --> 01:18:20.600]   into these kinds of things. And it's not just sports
[01:18:20.600 --> 01:18:22.600]   gambling. There was an article in the Wall Street Journal
[01:18:22.600 --> 01:18:24.600]   about this woman who's a
[01:18:24.600 --> 01:18:26.600]   well-respected lawyer who became
[01:18:26.600 --> 01:18:28.600]   totally addicted playing like
[01:18:28.600 --> 01:18:30.600]   a bingo app, right? And lost
[01:18:30.600 --> 01:18:32.600]   her entire life. So, these
[01:18:32.600 --> 01:18:34.600]   forms of gambling and addiction are just
[01:18:34.600 --> 01:18:36.600]   going to skyrocket, I think, because
[01:18:36.600 --> 01:18:38.600]   you have these apps that are really
[01:18:38.600 --> 01:18:40.600]   incredibly well-engineered
[01:18:40.600 --> 01:18:42.600]   to get you super-hooked.
[01:18:42.600 --> 01:18:44.600]   And then, the adrenaline
[01:18:44.600 --> 01:18:46.600]   rush and the dopamine rush of
[01:18:46.600 --> 01:18:48.600]   actually winning money is a thing that, for some
[01:18:48.600 --> 01:18:50.600]   people, they can't turn off once they
[01:18:50.600 --> 01:18:52.600]   feel it for the first time. Yeah, we know some of those people, and
[01:18:52.600 --> 01:18:54.600]   you know, it's hard for them to control
[01:18:54.600 --> 01:18:56.600]   their sports betting,
[01:18:56.600 --> 01:18:58.600]   blackjack playing, other things.
[01:18:58.600 --> 01:19:00.600]   They just get too into it.
[01:19:00.600 --> 01:19:02.600]   They get too into it.
[01:19:02.600 --> 01:19:04.600]   But other societies, other
[01:19:04.600 --> 01:19:06.600]   geos, Australia, New Zealand,
[01:19:06.600 --> 01:19:08.600]   and the UK, they've had this for a
[01:19:08.600 --> 01:19:10.600]   while, so they've figured out how to deal with this.
[01:19:10.600 --> 01:19:12.600]   This is what I'm going to tell you. The last thing I'll say on this is
[01:19:12.600 --> 01:19:14.600]   when I was in high school, so in the early '90s
[01:19:14.600 --> 01:19:16.600]   in Ontario and Canada, they
[01:19:16.600 --> 01:19:18.600]   introduced sports betting as a way of
[01:19:18.600 --> 01:19:20.600]   generating revenue for the government.
[01:19:20.600 --> 01:19:22.600]   What I will tell you is that
[01:19:22.600 --> 01:19:24.600]   my entire high school,
[01:19:24.600 --> 01:19:26.600]   all the boys, not the girls,
[01:19:26.600 --> 01:19:28.600]   we became instant gambling
[01:19:28.600 --> 01:19:30.600]   addicts. We were
[01:19:30.600 --> 01:19:32.600]   figuring out how to put bets on. Most of it
[01:19:32.600 --> 01:19:34.600]   was betting in hockey because that's the sport
[01:19:34.600 --> 01:19:36.600]   that we all knew the best growing up in
[01:19:36.600 --> 01:19:38.600]   Ottawa.
[01:19:38.600 --> 01:19:40.600]   But it was all day
[01:19:40.600 --> 01:19:42.600]   every day. It consumed us.
[01:19:42.600 --> 01:19:44.600]   And I think when you look inside
[01:19:44.600 --> 01:19:46.600]   of these apps, you're seeing a lot of young men
[01:19:46.600 --> 01:19:48.600]   with a lot of free cash and a lot of time
[01:19:48.600 --> 01:19:50.600]   getting sucked into the gamification
[01:19:50.600 --> 01:19:52.600]   of this thing. I think it's going to be a big problem.
[01:19:52.600 --> 01:19:54.600]   I will tell you, Sax, I'm interested in your
[01:19:54.600 --> 01:19:56.600]   position on this because there is a whole system, an
[01:19:56.600 --> 01:19:58.600]   ecosystem emerging here. The states
[01:19:58.600 --> 01:20:00.600]   are getting massive amounts of revenue.
[01:20:00.600 --> 01:20:02.600]   $11 billion generated last
[01:20:02.600 --> 01:20:04.600]   year, up
[01:20:04.600 --> 01:20:06.600]   44.5% from 2022.
[01:20:06.600 --> 01:20:08.600]   The league is printing
[01:20:08.600 --> 01:20:10.600]   money from this, all the leagues. The NBA will generate
[01:20:10.600 --> 01:20:12.600]   $167 million from
[01:20:12.600 --> 01:20:14.600]   betting this season, up 11% year over year.
[01:20:14.600 --> 01:20:16.600]   The sportsbooks, obviously killing you.
[01:20:16.600 --> 01:20:18.600]   DraftKings got a $20 billion
[01:20:18.600 --> 01:20:20.600]   market cap and bettors obviously love it.
[01:20:20.600 --> 01:20:22.600]   It's more fun. It's making the games more engaging.
[01:20:22.600 --> 01:20:24.600]   And the media
[01:20:24.600 --> 01:20:26.600]   is loving
[01:20:26.600 --> 01:20:28.600]   this. All of the podcasts,
[01:20:28.600 --> 01:20:30.600]   Bill Simmons, ESPN,
[01:20:30.600 --> 01:20:32.600]   you can't watch a game, you can't hear sports commentary
[01:20:32.600 --> 01:20:34.600]   without this being integrated.
[01:20:34.600 --> 01:20:36.600]   And it's being integrated at a very fundamental
[01:20:36.600 --> 01:20:38.600]   editorial level. They're asking
[01:20:38.600 --> 01:20:40.600]   the host of these shows their spend
[01:20:40.600 --> 01:20:42.600]   and what they're betting on.
[01:20:42.600 --> 01:20:44.600]   And they're doing something very smart, which is they're paying
[01:20:44.600 --> 01:20:46.600]   huge endorsement deals to the players
[01:20:46.600 --> 01:20:48.600]   as well. I think DraftKings did
[01:20:48.600 --> 01:20:50.600]   something with LeBron. This is genius because
[01:20:50.600 --> 01:20:52.600]   when you get that ingratiated, you'll never get ripped
[01:20:52.600 --> 01:20:54.600]   out because if they become a huge
[01:20:54.600 --> 01:20:56.600]   part of the off-court revenue
[01:20:56.600 --> 01:20:58.600]   model for these players...
[01:20:58.600 --> 01:21:00.600]   We're locked in. It's like the new
[01:21:00.600 --> 01:21:02.600]   Air Jordans.
[01:21:02.600 --> 01:21:04.600]   Sax, what do you think about this just in
[01:21:04.600 --> 01:21:06.600]   terms of on a societal basis
[01:21:06.600 --> 01:21:08.600]   and the United States?
[01:21:08.600 --> 01:21:10.600]   It's sort of like cannabis.
[01:21:10.600 --> 01:21:12.600]   This is a new thing for Americans to
[01:21:12.600 --> 01:21:14.600]   have access to. There's a lot of
[01:21:14.600 --> 01:21:16.600]   weird behaviors going on, edge cases.
[01:21:16.600 --> 01:21:18.600]   But what do you think, net-net, as a society,
[01:21:18.600 --> 01:21:20.600]   you take away from
[01:21:20.600 --> 01:21:22.600]   the emergence of sports betting
[01:21:22.600 --> 01:21:24.600]   and this next generation being so addicted to it?
[01:21:24.600 --> 01:21:26.600]   Well, I think cannabis is the
[01:21:26.600 --> 01:21:28.600]   right analogy. I think adults
[01:21:28.600 --> 01:21:30.600]   should be allowed to bet on
[01:21:30.600 --> 01:21:32.600]   sporting events, just like they're allowed to
[01:21:32.600 --> 01:21:34.600]   drink or
[01:21:34.600 --> 01:21:36.600]   smoke pot or engage in other mild
[01:21:36.600 --> 01:21:38.600]   vices. Some people
[01:21:38.600 --> 01:21:40.600]   handle it responsibly and some don't.
[01:21:40.600 --> 01:21:42.600]   Probably on a societal basis, it's probably
[01:21:42.600 --> 01:21:44.600]   not a great thing, but it's something you
[01:21:44.600 --> 01:21:46.600]   allow to happen
[01:21:46.600 --> 01:21:48.600]   because of personal freedom and
[01:21:48.600 --> 01:21:50.600]   hopefully people use it responsibly.
[01:21:50.600 --> 01:21:52.600]   Freeberg,
[01:21:52.600 --> 01:21:54.600]   do you have any thoughts? You place any bets,
[01:21:54.600 --> 01:21:56.600]   Freeberg? Do you place any bets on sports? I'm curious.
[01:21:56.600 --> 01:21:58.600]   I do not. You do not.
[01:21:58.600 --> 01:22:00.600]   I don't place bets on sports, but
[01:22:00.600 --> 01:22:02.600]   I love playing cards because it's social.
[01:22:02.600 --> 01:22:04.600]   Chamath, do you do any sports betting
[01:22:04.600 --> 01:22:06.600]   now and again? Maybe on the Super Bowl you get
[01:22:06.600 --> 01:22:08.600]   once in a while, you place a bet?
[01:22:08.600 --> 01:22:10.600]   A wager? When I got admitted to the ownership
[01:22:10.600 --> 01:22:12.600]   group in the NBA, I stopped.
[01:22:12.600 --> 01:22:14.600]   I probably made
[01:22:14.600 --> 01:22:16.600]   three bets since then.
[01:22:16.600 --> 01:22:18.600]   All three were on the Super Bowl
[01:22:18.600 --> 01:22:20.600]   at a casino, so it was
[01:22:20.600 --> 01:22:22.600]   legal when I was still an owner.
[01:22:22.600 --> 01:22:24.600]   I've not done it since.
[01:22:24.600 --> 01:22:26.600]   I've refused to download these apps because
[01:22:26.600 --> 01:22:28.600]   I love sports
[01:22:28.600 --> 01:22:30.600]   and I think that if I
[01:22:30.600 --> 01:22:32.600]   added this to it,
[01:22:32.600 --> 01:22:34.600]   I just don't think it would be good for me,
[01:22:34.600 --> 01:22:36.600]   so I don't want to do it. That was my exact
[01:22:36.600 --> 01:22:38.600]   take, too. Sac, do you ever place any
[01:22:38.600 --> 01:22:40.600]   bets? You're not a wager. I'm not a sports bettor.
[01:22:40.600 --> 01:22:42.600]   Do you ever bet on chess?
[01:22:42.600 --> 01:22:44.600]   No,
[01:22:44.600 --> 01:22:46.600]   no one bets on chess because it's so obvious
[01:22:46.600 --> 01:22:48.600]   who's going to win. There's a very precise
[01:22:48.600 --> 01:22:50.600]   rating system.
[01:22:50.600 --> 01:22:52.600]   Poker is very
[01:22:52.600 --> 01:22:54.600]   different because you can have
[01:22:54.600 --> 01:22:56.600]   players at the same table and you know who are the
[01:22:56.600 --> 01:22:58.600]   great players and who are not the great players, but
[01:22:58.600 --> 01:23:00.600]   still, in any given hand,
[01:23:00.600 --> 01:23:02.600]   the underdog can win because
[01:23:02.600 --> 01:23:04.600]   you can basically suck out or whatever.
[01:23:04.600 --> 01:23:06.600]   There's a significant luck component on
[01:23:06.600 --> 01:23:08.600]   every single hand. Over the long term,
[01:23:08.600 --> 01:23:10.600]   you believe that the luck kind of
[01:23:10.600 --> 01:23:12.600]   evens out and you reach your expected
[01:23:12.600 --> 01:23:14.600]   value, but on any given hand,
[01:23:14.600 --> 01:23:16.600]   you can believe that you're the winner.
[01:23:16.600 --> 01:23:18.600]   So there's a lot of gambling in
[01:23:18.600 --> 01:23:20.600]   poker, even though it is a skill game.
[01:23:20.600 --> 01:23:22.600]   In chess, that just doesn't
[01:23:22.600 --> 01:23:24.600]   work. I mean, if I play
[01:23:24.600 --> 01:23:26.600]   Magnus Carlsen or any
[01:23:26.600 --> 01:23:28.600]   2,000 rated player, I'm just
[01:23:28.600 --> 01:23:30.600]   never going to win, so there's
[01:23:30.600 --> 01:23:32.600]   no point in betting. Sax, what's your rating?
[01:23:32.600 --> 01:23:34.600]   1,400.
[01:23:34.600 --> 01:23:36.600]   I'm a little better than that. I'm like,
[01:23:36.600 --> 01:23:38.600]   I'm probably more like 1,600.
[01:23:38.600 --> 01:23:40.600]   Last time I played, it was 1,400. I stopped playing
[01:23:40.600 --> 01:23:42.600]   him because he would just... I would get to the middle
[01:23:42.600 --> 01:23:44.600]   game with Sax. I'd get like 30 moves in and then
[01:23:44.600 --> 01:23:46.600]   he would just smash me. I'm like 800
[01:23:46.600 --> 01:23:48.600]   or something. How do you get better at chess?
[01:23:48.600 --> 01:23:50.600]   Freebird, do you have a rating?
[01:23:50.600 --> 01:23:52.600]   I don't want to talk about it. He doesn't want to talk.
[01:23:52.600 --> 01:23:54.600]   Freebird, what's your rating?
[01:23:54.600 --> 01:23:56.600]   Are you still upset about the octopus stuff?
[01:23:56.600 --> 01:23:58.600]   No. Oh, okay.
[01:23:58.600 --> 01:24:00.600]   But what's your rating?
[01:24:00.600 --> 01:24:02.600]   It's too personal a question.
[01:24:02.600 --> 01:24:04.600]   It's too personal a question.
[01:24:04.600 --> 01:24:06.600]   Do you never share information where people
[01:24:06.600 --> 01:24:08.600]   can actually like root for you?
[01:24:08.600 --> 01:24:10.600]   Yeah, be vulnerable, dude.
[01:24:10.600 --> 01:24:12.600]   Ask me other questions.
[01:24:12.600 --> 01:24:14.600]   Just don't ask me about my chess rating.
[01:24:14.600 --> 01:24:16.600]   Don't ask me about my chess rating.
[01:24:16.600 --> 01:24:18.600]   Ask me anything else. What is the lowest rating?
[01:24:18.600 --> 01:24:20.600]   What's the best way to get better? Should I get a coach or something, Sax?
[01:24:20.600 --> 01:24:22.600]   The chess.com app has
[01:24:22.600 --> 01:24:24.600]   very good lessons on it, too. It's actually
[01:24:24.600 --> 01:24:26.600]   quite good. Yeah, you could get a coach
[01:24:26.600 --> 01:24:28.600]   and that would definitely help. There's also these
[01:24:28.600 --> 01:24:30.600]   exercises you can do called puzzle rushes
[01:24:30.600 --> 01:24:32.600]   that teach you how to spot tactics.
[01:24:32.600 --> 01:24:34.600]   That's all tactics. That's probably half the game.
[01:24:34.600 --> 01:24:36.600]   Yeah.
[01:24:36.600 --> 01:24:38.600]   Like you learn how to do a knife fork or something
[01:24:38.600 --> 01:24:40.600]   like that, how to do pins. You just need to spot
[01:24:40.600 --> 01:24:42.600]   tactics quickly is really the key. My puzzle
[01:24:42.600 --> 01:24:44.600]   rush scores are pretty good.
[01:24:44.600 --> 01:24:46.600]   Oh, you're over a thousand?
[01:24:46.600 --> 01:24:48.600]   No, it's like how many you can get in a certain period
[01:24:48.600 --> 01:24:50.600]   of time. And it gets
[01:24:50.600 --> 01:24:52.600]   sequentially harder as you complete
[01:24:52.600 --> 01:24:54.600]   the puzzles and you have
[01:24:54.600 --> 01:24:56.600]   a limited period to do it.
[01:24:56.600 --> 01:24:58.600]   Yet you feel shame.
[01:24:58.600 --> 01:25:00.600]   If you want to get better at chess, I've watched
[01:25:00.600 --> 01:25:02.600]   a lot of chess videos on YouTube and
[01:25:02.600 --> 01:25:04.600]   there's a very good series
[01:25:04.600 --> 01:25:06.600]   by John Bartholomew called
[01:25:06.600 --> 01:25:08.600]   Climbing the Ratings Ladder.
[01:25:08.600 --> 01:25:10.600]   And for each level
[01:25:10.600 --> 01:25:12.600]   of Elo ratings, he has
[01:25:12.600 --> 01:25:14.600]   a series of videos. So like, I don't know, if you're
[01:25:14.600 --> 01:25:16.600]   like at 1200, there's a whole series for
[01:25:16.600 --> 01:25:18.600]   1200s and he'll
[01:25:18.600 --> 01:25:20.600]   play a bunch of games against 1200s
[01:25:20.600 --> 01:25:22.600]   showing what they typically do
[01:25:22.600 --> 01:25:24.600]   wrong and you can learn from it.
[01:25:24.600 --> 01:25:26.600]   It's actually, it's a good series.
[01:25:26.600 --> 01:25:28.600]   Have you spent time, Sax, like
[01:25:28.600 --> 01:25:30.600]   studying like openings
[01:25:30.600 --> 01:25:32.600]   and like studying
[01:25:32.600 --> 01:25:34.600]   like specific lines? I don't even know if I'm using
[01:25:34.600 --> 01:25:36.600]   the right language here.
[01:25:36.600 --> 01:25:38.600]   I haven't spent
[01:25:38.600 --> 01:25:40.600]   a ton of time studying them
[01:25:40.600 --> 01:25:42.600]   but I'm certainly familiar with a number
[01:25:42.600 --> 01:25:44.600]   of the most common openings.
[01:25:44.600 --> 01:25:46.600]   So I guess, yes, I guess on
[01:25:46.600 --> 01:25:48.600]   some level I've studied them. I would
[01:25:48.600 --> 01:25:50.600]   say that depending on where
[01:25:50.600 --> 01:25:52.600]   you are in your development
[01:25:52.600 --> 01:25:54.600]   that may not be the most pressing
[01:25:54.600 --> 01:25:56.600]   thing for you to do.
[01:25:56.600 --> 01:25:58.600]   You know, I think
[01:25:58.600 --> 01:26:00.600]   you probably do want to just know a few
[01:26:00.600 --> 01:26:02.600]   basics of a few of the most
[01:26:02.600 --> 01:26:04.600]   common openings but
[01:26:04.600 --> 01:26:06.600]   there's probably other things for you to learn first.
[01:26:06.600 --> 01:26:08.600]   You don't need to like memorize a bunch of
[01:26:08.600 --> 01:26:10.600]   complicated lines. I think it's like really cool
[01:26:10.600 --> 01:26:12.600]   that kids are learning this. I know
[01:26:12.600 --> 01:26:14.600]   this may be a counter
[01:26:14.600 --> 01:26:16.600]   or a contrarian view but I think kids having
[01:26:16.600 --> 01:26:18.600]   access, you know, or young adults
[01:26:18.600 --> 01:26:20.600]   having access to sports betting, poker
[01:26:20.600 --> 01:26:22.600]   is kind of a good thing because
[01:26:22.600 --> 01:26:24.600]   if controlled because they're
[01:26:24.600 --> 01:26:26.600]   learning about odds and
[01:26:26.600 --> 01:26:28.600]   gambling and framing it.
[01:26:28.600 --> 01:26:30.600]   I, with my 14-year-old
[01:26:30.600 --> 01:26:32.600]   am doing an allowance and
[01:26:32.600 --> 01:26:34.600]   then I decided to do an investment club
[01:26:34.600 --> 01:26:36.600]   and so I'm putting $100
[01:26:36.600 --> 01:26:38.600]   every month into like a Robinhood account
[01:26:38.600 --> 01:26:40.600]   and we're going to do like
[01:26:40.600 --> 01:26:42.600]   two meetings every month, one to buy
[01:26:42.600 --> 01:26:44.600]   a new stock and one to examine
[01:26:44.600 --> 01:26:46.600]   our existing stocks and I'm just
[01:26:46.600 --> 01:26:48.600]   starting an investment club so if anybody's kids are
[01:26:48.600 --> 01:26:50.600]   in that age group and they want to join it
[01:26:50.600 --> 01:26:52.600]   let me know because I'm going to do like a
[01:26:52.600 --> 01:26:54.600]   with the cousins like a zoom call every
[01:26:54.600 --> 01:26:56.600]   month where we just talk about stocks
[01:26:56.600 --> 01:26:58.600]   and then I'm going to have them actually buy it
[01:26:58.600 --> 01:27:00.600]   so that they can
[01:27:00.600 --> 01:27:02.600]   be prepared for the real world and how companies
[01:27:02.600 --> 01:27:04.600]   are going but how do you think about
[01:27:04.600 --> 01:27:06.600]   your kids Chamath because you got to do this gambling
[01:27:06.600 --> 01:27:08.600]   when you were young. Didn't that help
[01:27:08.600 --> 01:27:10.600]   you ultimately as an adult?
[01:27:10.600 --> 01:27:12.600]   I mean I ran a casino in my
[01:27:12.600 --> 01:27:14.600]   high school.
[01:27:14.600 --> 01:27:16.600]   Was that the thing?
[01:27:16.600 --> 01:27:18.600]   Yeah, I mean I ran a
[01:27:18.600 --> 01:27:20.600]   little blackjack game where the rich kids
[01:27:20.600 --> 01:27:22.600]   could play and I was the house and
[01:27:22.600 --> 01:27:24.600]   I would make a few extra hundred bucks
[01:27:24.600 --> 01:27:26.600]   a week. Nice.
[01:27:26.600 --> 01:27:28.600]   And that was great because like you know between
[01:27:28.600 --> 01:27:30.600]   that and my job at Burger King it really
[01:27:30.600 --> 01:27:32.600]   helped
[01:27:32.600 --> 01:27:34.600]   and then I would go and take that and I actually
[01:27:34.600 --> 01:27:36.600]   came pretty decent at blackjack and I would go
[01:27:36.600 --> 01:27:38.600]   there would be these what's called charity
[01:27:38.600 --> 01:27:40.600]   casinos so casinos in Ottawa, Ontario were
[01:27:40.600 --> 01:27:42.600]   illegal but if they were to raise
[01:27:42.600 --> 01:27:44.600]   charity for various
[01:27:44.600 --> 01:27:46.600]   charities they were allowed and so
[01:27:46.600 --> 01:27:48.600]   my friend and I would show up at
[01:27:48.600 --> 01:27:50.600]   these things and just run them over.
[01:27:50.600 --> 01:27:52.600]   Did anybody else run an illegal
[01:27:52.600 --> 01:27:54.600]   business as a kid? I'll tell you about mine
[01:27:54.600 --> 01:27:56.600]   after. Zach, did you run any illegal businesses
[01:27:56.600 --> 01:27:58.600]   as a kid? No comment.
[01:27:58.600 --> 01:28:00.600]   Come on, it's Statue of Limitations. What did you do?
[01:28:00.600 --> 01:28:02.600]   You must have been running some scams. Come on, tell us.
[01:28:02.600 --> 01:28:04.600]   I'll tell you my two scams after you tell us yours.
[01:28:04.600 --> 01:28:06.600]   By the way, I'll tell you I had a bad debt situation
[01:28:06.600 --> 01:28:08.600]   in my lunch game.
[01:28:08.600 --> 01:28:10.600]   You know I used to let people bet
[01:28:10.600 --> 01:28:12.600]   up to a buck. Okay, so
[01:28:12.600 --> 01:28:14.600]   four or five guys up
[01:28:14.600 --> 01:28:16.600]   $0.25, $0.50 or a dollar and
[01:28:16.600 --> 01:28:18.600]   one guy he like demanded
[01:28:18.600 --> 01:28:20.600]   an expanded credit line.
[01:28:20.600 --> 01:28:22.600]   So I gave him up to two bucks.
[01:28:22.600 --> 01:28:24.600]   How many boxes of ziti did he go down?
[01:28:24.600 --> 01:28:26.600]   One lunch he lost $80 and it took me
[01:28:26.600 --> 01:28:28.600]   three months to get paid. It was the worst
[01:28:28.600 --> 01:28:30.600]   experience. $80 boxes of ziti?
[01:28:30.600 --> 01:28:32.600]   No, $80. No, I know I'm just doing
[01:28:32.600 --> 01:28:34.600]   a soprano. I had to
[01:28:34.600 --> 01:28:36.600]   sweat this guy for three months to get my $80.
[01:28:36.600 --> 01:28:38.600]   He was rich too.
[01:28:38.600 --> 01:28:40.600]   His parents were rich. What did he do?
[01:28:40.600 --> 01:28:42.600]   Did he have to do your term papers or something?
[01:28:42.600 --> 01:28:44.600]   Did he have to do your essays, clean your bike?
[01:28:44.600 --> 01:28:46.600]   I wouldn't have gotten this kind of money.
[01:28:46.600 --> 01:28:48.600]   Come on, Sax, give it up. What was your scam
[01:28:48.600 --> 01:28:50.600]   you were running as a kid? Let's move on.
[01:28:50.600 --> 01:28:52.600]   I had two scams.
[01:28:52.600 --> 01:28:54.600]   Freeberg, you have a scam when you were running
[01:28:54.600 --> 01:28:56.600]   when you were a kid?
[01:28:56.600 --> 01:28:58.600]   Any scams? I used to go to the
[01:28:58.600 --> 01:29:00.600]   recycler newspaper. Do you guys remember that?
[01:29:00.600 --> 01:29:02.600]   Yeah. The recycler. And I would buy
[01:29:02.600 --> 01:29:04.600]   used electronics equipment,
[01:29:04.600 --> 01:29:06.600]   computer equipment, and then I would
[01:29:06.600 --> 01:29:08.600]   sell it. So I would
[01:29:08.600 --> 01:29:10.600]   then post other ads. I basically did
[01:29:10.600 --> 01:29:12.600]   ad arbitrage as a way to think about it.
[01:29:12.600 --> 01:29:14.600]   So I would go and find people selling
[01:29:14.600 --> 01:29:16.600]   stuff that I thought was underpriced.
[01:29:16.600 --> 01:29:18.600]   And then I would buy it. There was nothing to fix.
[01:29:18.600 --> 01:29:20.600]   It was underpriced. And then I knew
[01:29:20.600 --> 01:29:22.600]   the better market to go sell it and make more money.
[01:29:22.600 --> 01:29:24.600]   So then I'd buy all these old
[01:29:24.600 --> 01:29:26.600]   blocks. Like a broken receiver.
[01:29:26.600 --> 01:29:28.600]   Discman and a receiver.
[01:29:28.600 --> 01:29:30.600]   Speakers that I knew were good, but they were
[01:29:30.600 --> 01:29:32.600]   steeply discounted. I'd drive
[01:29:32.600 --> 01:29:34.600]   around in my white van. I'd pay people
[01:29:34.600 --> 01:29:36.600]   cash. I'd load it up and then I'd go sell it to
[01:29:36.600 --> 01:29:38.600]   other people by putting ads in.
[01:29:38.600 --> 01:29:40.600]   No wonder you wound up at Google.
[01:29:40.600 --> 01:29:42.600]   I had two
[01:29:42.600 --> 01:29:44.600]   really good scams when I was a kid.
[01:29:44.600 --> 01:29:46.600]   The first was this guy owed my dad
[01:29:46.600 --> 01:29:48.600]   some money for backgammon. My dad was
[01:29:48.600 --> 01:29:50.600]   a backgammon shark and he would play in his bar
[01:29:50.600 --> 01:29:52.600]   when I would show up at six in the morning.
[01:29:52.600 --> 01:29:54.600]   My dad would be playing blackjack with guys. They would get
[01:29:54.600 --> 01:29:56.600]   in deep
[01:29:56.600 --> 01:29:58.600]   with him. And so this guy who
[01:29:58.600 --> 01:30:00.600]   was in the mob owed my dad some money.
[01:30:00.600 --> 01:30:02.600]   And for the vig, he gave
[01:30:02.600 --> 01:30:04.600]   them a copy of The Empire Strikes Back
[01:30:04.600 --> 01:30:06.600]   on VHS.
[01:30:06.600 --> 01:30:08.600]   And I was like, "What?"
[01:30:08.600 --> 01:30:10.600]   This was before it was out. They had recorded
[01:30:10.600 --> 01:30:12.600]   it in the movie theaters in 1984 or
[01:30:12.600 --> 01:30:14.600]   something, whenever that came out.
[01:30:14.600 --> 01:30:16.600]   And it was a really bad copy.
[01:30:16.600 --> 01:30:18.600]   So my dad comes home, he gives me the
[01:30:18.600 --> 01:30:20.600]   copy. We watch it. It was incredible. I was like, "Thanks
[01:30:20.600 --> 01:30:22.600]   Dad." And I got my friend to
[01:30:22.600 --> 01:30:24.600]   bring over his VHS. I made 10 copies of it.
[01:30:24.600 --> 01:30:26.600]   I go to school, McKinley Junior High School
[01:30:26.600 --> 01:30:28.600]   in Brooklyn. And I sell them for 30
[01:30:28.600 --> 01:30:30.600]   bucks a pop. Oh my God. Selling
[01:30:30.600 --> 01:30:32.600]   like hotcakes. And then
[01:30:32.600 --> 01:30:34.600]   I get pinched.
[01:30:34.600 --> 01:30:36.600]   Math teacher says, "What's going on with these Empire
[01:30:36.600 --> 01:30:38.600]   Strikes Back?" And I said,
[01:30:38.600 --> 01:30:40.600]   "What do you mean? I don't know what you're talking about."
[01:30:40.600 --> 01:30:42.600]   He's like, "I heard you got Empire Strikes Back."
[01:30:42.600 --> 01:30:44.600]   He kept your mouth shut.
[01:30:44.600 --> 01:30:46.600]   I looked him dead in the eye. And I said,
[01:30:46.600 --> 01:30:48.600]   "Are you interested?"
[01:30:48.600 --> 01:30:50.600]   The teacher goes, "Yeah.
[01:30:50.600 --> 01:30:52.600]   How much are they?" I said, "30 bucks.
[01:30:52.600 --> 01:30:54.600]   But I'll give you one for 10."
[01:30:54.600 --> 01:30:56.600]   And he said, "Okay.
[01:30:56.600 --> 01:30:58.600]   Pull that 10 bucks." I sold my math teacher.
[01:30:58.600 --> 01:31:00.600]   I kid you not, the Empire Strikes Back for 10 bucks.
[01:31:00.600 --> 01:31:02.600]   Can you do this whole thing again but in the
[01:31:02.600 --> 01:31:04.600]   Christopher Walken voice?
[01:31:04.600 --> 01:31:06.600]   I'm not going to do it. But I'll give you the other one I did.
[01:31:06.600 --> 01:31:08.600]   No, it's the Joe Pesci voice. Do this one
[01:31:08.600 --> 01:31:10.600]   in the Christopher Walken voice. And so the name of it
[01:31:10.600 --> 01:31:12.600]   was Jason's Hot Tapes. And so I
[01:31:12.600 --> 01:31:14.600]   made a business card and laminated Jason's Hot Tapes.
[01:31:14.600 --> 01:31:16.600]   And I would hand it to people. And I'd hand
[01:31:16.600 --> 01:31:18.600]   them the Jason's Hot Tape card.
[01:31:18.600 --> 01:31:20.600]   And I'd say, "Give me my card back." But I would just show
[01:31:20.600 --> 01:31:22.600]   them that I had a card. Oh, that reminds me.
[01:31:22.600 --> 01:31:24.600]   I was also in the fake ID business.
[01:31:24.600 --> 01:31:26.600]   Ooh. Say more. I don't know.
[01:31:26.600 --> 01:31:28.600]   I granted out fake IDs with a buddy of mine.
[01:31:28.600 --> 01:31:30.600]   All right. That was mine. That was mine.
[01:31:30.600 --> 01:31:32.600]   Oh! Zach was in the fake ID
[01:31:32.600 --> 01:31:34.600]   business, too? At Stanford? We used Harvard Graphics.
[01:31:34.600 --> 01:31:36.600]   Zach, what were you using? I was using Harvard Graphics.
[01:31:36.600 --> 01:31:38.600]   Well, this was in the days
[01:31:38.600 --> 01:31:40.600]   before holograms. And it just
[01:31:40.600 --> 01:31:42.600]   wasn't that hard to copy.
[01:31:42.600 --> 01:31:44.600]   So we just made boards or whatever
[01:31:44.600 --> 01:31:46.600]   and Polaroids. So we did it for
[01:31:46.600 --> 01:31:48.600]   ourselves and we did it for friends. Yeah, same.
[01:31:48.600 --> 01:31:50.600]   Here's the thing about the fake ID business.
[01:31:50.600 --> 01:31:52.600]   The bouncers
[01:31:52.600 --> 01:31:54.600]   were like, "If you've got money,
[01:31:54.600 --> 01:31:56.600]   show us any piece of paper
[01:31:56.600 --> 01:31:58.600]   so we have plausible deniability."
[01:31:58.600 --> 01:32:00.600]   They knew. That's right. They just wanted plausible
[01:32:00.600 --> 01:32:02.600]   deniability. That's exactly right.
[01:32:02.600 --> 01:32:04.600]   That's the key to the rack.
[01:32:04.600 --> 01:32:06.600]   Did you put "McLovin" in University
[01:32:06.600 --> 01:32:08.600]   of Hawaii? Yeah.
[01:32:08.600 --> 01:32:10.600]   Actually, what was kind of funny
[01:32:10.600 --> 01:32:12.600]   is sometimes the bouncers would go, "What's your
[01:32:12.600 --> 01:32:14.600]   name?" Hmm. And you'd be like,
[01:32:14.600 --> 01:32:16.600]   you'd be stumped because you didn't
[01:32:16.600 --> 01:32:18.600]   remember what was on there. You were so drunk, you don't even
[01:32:18.600 --> 01:32:20.600]   remember.
[01:32:20.600 --> 01:32:22.600]   You're like, "My name is
[01:32:22.600 --> 01:32:24.600]   Christopher Walker." Mine was like,
[01:32:24.600 --> 01:32:26.600]   "Raj Patel."
[01:32:26.600 --> 01:32:28.600]   "My name is
[01:32:28.600 --> 01:32:30.600]   Raj Patel."
[01:32:30.600 --> 01:32:32.600]   Or they'd ask you, "What was your birthday?"
[01:32:32.600 --> 01:32:34.600]   And you don't remember what's on your ID.
[01:32:34.600 --> 01:32:36.600]   You don't know what's on your ID because it's fake. I don't remember.
[01:32:36.600 --> 01:32:38.600]   I don't remember.
[01:32:38.600 --> 01:32:40.600]   I had one drink.
[01:32:40.600 --> 01:32:42.600]   Now, the key in the fake ID game is to use
[01:32:42.600 --> 01:32:44.600]   your month and
[01:32:44.600 --> 01:32:46.600]   day that's yours and then
[01:32:46.600 --> 01:32:48.600]   just change the year.
[01:32:48.600 --> 01:32:50.600]   That's the key.
[01:32:50.600 --> 01:32:52.600]   I'll give you the second one.
[01:32:52.600 --> 01:32:54.600]   So, my friend,
[01:32:54.600 --> 01:32:56.600]   his
[01:32:56.600 --> 01:32:58.600]   brother had a
[01:32:58.600 --> 01:33:00.600]   DeLorean.
[01:33:00.600 --> 01:33:02.600]   I can't do it. I can't sustain it.
[01:33:02.600 --> 01:33:04.600]   Anyway, this kid
[01:33:04.600 --> 01:33:06.600]   who I grew up with.
[01:33:06.600 --> 01:33:08.600]   I should say. Anyway, his name was
[01:33:08.600 --> 01:33:10.600]   beep that out. He lived up on
[01:33:10.600 --> 01:33:12.600]   13th Avenue. I go to his house.
[01:33:12.600 --> 01:33:14.600]   His brother's got a DeLorean. It was
[01:33:14.600 --> 01:33:16.600]   incredible. And we're in junior high
[01:33:16.600 --> 01:33:18.600]   school and I'm talking to his brother.
[01:33:18.600 --> 01:33:20.600]   I go into the garage and there's all
[01:33:20.600 --> 01:33:22.600]   DeLorean parts
[01:33:22.600 --> 01:33:24.600]   on the wall. And I said,
[01:33:24.600 --> 01:33:26.600]   "Why do you have all these parts?"
[01:33:26.600 --> 01:33:28.600]   And he said, "Oh, you know,
[01:33:28.600 --> 01:33:30.600]   there was a DeLorean that
[01:33:30.600 --> 01:33:32.600]   fell apart and
[01:33:32.600 --> 01:33:34.600]   we picked up the pieces." They had
[01:33:34.600 --> 01:33:36.600]   stolen another DeLorean because DeLorean stopped producing
[01:33:36.600 --> 01:33:38.600]   and they just chopped it up. But he had it in his garage.
[01:33:38.600 --> 01:33:40.600]   So, anyway, we're playing
[01:33:40.600 --> 01:33:42.600]   Chess Master at the time and I had hacked
[01:33:42.600 --> 01:33:44.600]   a copy of Chess Master. It was very easy to do.
[01:33:44.600 --> 01:33:46.600]   And the guy said, "You got Chess Master?
[01:33:46.600 --> 01:33:48.600]   Can you get me more copies of that?" I said, "Sure. How many copies
[01:33:48.600 --> 01:33:50.600]   you want?" He's like, "How many can you make?"
[01:33:50.600 --> 01:33:52.600]   I was like, "Well, floppy disks cost $4."
[01:33:52.600 --> 01:33:54.600]   He's like, "I'll give you $10 a copy
[01:33:54.600 --> 01:33:56.600]   of Chess Master." I said, "Fine."
[01:33:56.600 --> 01:33:58.600]   I go, "My friend, we go
[01:33:58.600 --> 01:34:00.600]   steal floppy disks from
[01:34:00.600 --> 01:34:02.600]   the store so we don't want to pay
[01:34:02.600 --> 01:34:04.600]   $4 for them." Not the 3 1/2's?
[01:34:04.600 --> 01:34:06.600]   The 5 1/4's? These are 5 1/4's.
[01:34:06.600 --> 01:34:08.600]   And we go into the store
[01:34:08.600 --> 01:34:10.600]   and we take the flyer
[01:34:10.600 --> 01:34:12.600]   and I hold the flyer open and I
[01:34:12.600 --> 01:34:14.600]   hold it behind my back and my friend takes the disks
[01:34:14.600 --> 01:34:16.600]   out of the sleeve at Staples
[01:34:16.600 --> 01:34:18.600]   or whatever, dumps them in there. We made
[01:34:18.600 --> 01:34:20.600]   copies of it and then we were selling Chess Master
[01:34:20.600 --> 01:34:22.600]   for $10 a pop at scale
[01:34:22.600 --> 01:34:24.600]   and giving them to the guys on 13th
[01:34:24.600 --> 01:34:26.600]   Avenue who were then reselling them for $20.
[01:34:26.600 --> 01:34:28.600]   This is when Chess Master was like a $100 product.
[01:34:28.600 --> 01:34:30.600]   Shout out to Chess Master.
[01:34:30.600 --> 01:34:32.600]   That was my second
[01:34:32.600 --> 01:34:34.600]   scam business. This is some degenerate
[01:34:34.600 --> 01:34:36.600]   sh*t. Yeah.
[01:34:36.600 --> 01:34:38.600]   And that's not even the best one. I'll give you the best
[01:34:38.600 --> 01:34:40.600]   one. This is the best and I'll give you the last scam
[01:34:40.600 --> 01:34:42.600]   we ran.
[01:34:42.600 --> 01:34:44.600]   There were parking permits in the late '80s
[01:34:44.600 --> 01:34:46.600]   in Manhattan. They were
[01:34:46.600 --> 01:34:48.600]   hard to get, but they were legit.
[01:34:48.600 --> 01:34:50.600]   If you had a parking permit in your window
[01:34:50.600 --> 01:34:52.600]   for the fire department, police,
[01:34:52.600 --> 01:34:54.600]   you could park
[01:34:54.600 --> 01:34:56.600]   in Manhattan in a lot of different areas.
[01:34:56.600 --> 01:34:58.600]   And so we went
[01:34:58.600 --> 01:35:00.600]   and we took a picture of these.
[01:35:00.600 --> 01:35:02.600]   Then we got on Pagemaker or whatever
[01:35:02.600 --> 01:35:04.600]   and I went down to Canal Street
[01:35:04.600 --> 01:35:06.600]   and I bought at Pearl Paints
[01:35:06.600 --> 01:35:08.600]   the same color
[01:35:08.600 --> 01:35:10.600]   orange and that lamination
[01:35:10.600 --> 01:35:12.600]   kit and we got on Photoshop.
[01:35:12.600 --> 01:35:14.600]   I kid you not. We held the picture up and we tried
[01:35:14.600 --> 01:35:16.600]   to figure out the fonts they used and
[01:35:16.600 --> 01:35:18.600]   we made a copy of the
[01:35:18.600 --> 01:35:20.600]   placards to park.
[01:35:20.600 --> 01:35:22.600]   And then we sold those for like $50
[01:35:22.600 --> 01:35:24.600]   and people used them and they wouldn't get
[01:35:24.600 --> 01:35:26.600]   tickets. They worked. So we sold
[01:35:26.600 --> 01:35:28.600]   police placards that had to be
[01:35:28.600 --> 01:35:30.600]   super illegal in 1988. All right, everybody.
[01:35:30.600 --> 01:35:32.600]   For your Sultan
[01:35:32.600 --> 01:35:34.600]   of Science, the exceptional
[01:35:34.600 --> 01:35:36.600]   David Friedberg, your Chairman Dictator
[01:35:36.600 --> 01:35:38.600]   Chamath Palihapitiya,
[01:35:38.600 --> 01:35:40.600]   Rain Man, yeah, David Sacks,
[01:35:40.600 --> 01:35:42.600]   I am your
[01:35:42.600 --> 01:35:44.600]   world's greatest moderator, J. Kyle.
[01:35:44.600 --> 01:35:46.600]   We'll see you on Episode 176
[01:35:46.600 --> 01:35:48.600]   and hopefully in September
[01:35:48.600 --> 01:35:50.600]   at the All In Summit.
[01:35:50.600 --> 01:35:52.600]   Bye-bye.
[01:35:52.600 --> 01:35:54.600]   We'll let your winners ride.
[01:35:54.600 --> 01:35:56.600]   Rain Man,
[01:35:56.600 --> 01:35:58.600]   David Sacks.
[01:35:58.600 --> 01:36:00.600]   I'm going all in.
[01:36:00.600 --> 01:36:02.600]   And instead, we open-sourced it to the fans
[01:36:02.600 --> 01:36:04.600]   and they've just gone crazy with it.
[01:36:04.600 --> 01:36:06.600]   I love you, Weston. I'm the queen of quinoa.
[01:36:06.600 --> 01:36:08.600]   I'm going all in.
[01:36:08.600 --> 01:36:10.600]   We'll let your winners ride.
[01:36:10.600 --> 01:36:12.600]   We'll let your winners ride.
[01:36:12.600 --> 01:36:14.600]   Besties are gone.
[01:36:14.600 --> 01:36:16.600]   That's my
[01:36:16.600 --> 01:36:18.600]   dog taking a notice in your driveway, Sacks.
[01:36:18.600 --> 01:36:20.600]   Oh, man.
[01:36:20.600 --> 01:36:22.600]   Oh, man.
[01:36:22.600 --> 01:36:24.600]   He should all just get a room
[01:36:24.600 --> 01:36:26.600]   and just have one big huge orgy
[01:36:26.600 --> 01:36:28.600]   because they're all just useless.
[01:36:28.600 --> 01:36:30.600]   It's like this sexual tension that they just need to release somehow.
[01:36:30.600 --> 01:36:32.600]   Wet your
[01:36:32.600 --> 01:36:34.600]   feet.
[01:36:34.600 --> 01:36:36.600]   Wet your feet.
[01:36:36.600 --> 01:36:38.600]   We need to get merch.
[01:36:38.600 --> 01:36:40.600]   I'm going all in.
[01:36:40.600 --> 01:36:48.600]   I'm going all in.
[01:36:48.600 --> 01:36:50.660]   you

