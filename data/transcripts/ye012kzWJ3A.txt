
[00:00:00.000 --> 00:00:01.880]   - Freeberg's channeling Tim Walz over there.
[00:00:01.880 --> 00:00:04.320]   - I know, wow, he's as exciting as Tim Walz.
[00:00:04.320 --> 00:00:05.760]   - Got your flannel on.
[00:00:05.760 --> 00:00:07.480]   Do you know what a venture capitalist is, Freeberg?
[00:00:07.480 --> 00:00:09.560]   - Oh, he's shilling SuperGut.
[00:00:09.560 --> 00:00:10.920]   - Well, as of last week,
[00:00:10.920 --> 00:00:13.720]   when J-Cal decided to turn All In into a commercial,
[00:00:13.720 --> 00:00:16.560]   I was actually gonna do a SuperGut background.
[00:00:16.560 --> 00:00:19.600]   We're launching SuperGut nationwide in Target this week.
[00:00:19.600 --> 00:00:21.160]   Any Target in the United States,
[00:00:21.160 --> 00:00:23.080]   you can go into and pick up SuperGut.
[00:00:23.080 --> 00:00:26.560]   You can buy the GLP-1 booster.
[00:00:26.560 --> 00:00:29.360]   You can buy the prebiotic shake.
[00:00:29.360 --> 00:00:30.200]   I have that, actually.
[00:00:30.200 --> 00:00:31.160]   Is that the chocolate?
[00:00:31.160 --> 00:00:32.760]   Or do you have the mocha? - Is it the chocolate?
[00:00:32.760 --> 00:00:34.000]   - I mean, I like the mocha. - This one's chocolate.
[00:00:34.000 --> 00:00:35.520]   - Okay, mocha's good, too.
[00:00:35.520 --> 00:00:36.360]   All right, let's get started.
[00:00:36.360 --> 00:00:37.560]   - Well, thanks for the support, J-Cal.
[00:00:37.560 --> 00:00:39.440]   I appreciate it. - Of course, of course, of course.
[00:00:39.440 --> 00:00:41.000]   - We're cutting all this out.
[00:00:41.000 --> 00:00:43.040]   - No way, this is why I do this.
[00:00:43.040 --> 00:00:45.500]   - Next time, plug a company, I have a stake in.
[00:00:45.500 --> 00:00:48.080]   (upbeat music)
[00:00:48.080 --> 00:00:50.960]   ♪ We won't let your winners ride ♪
[00:00:50.960 --> 00:00:53.400]   ♪ Rain Man, David Sachs ♪
[00:00:53.400 --> 00:00:55.360]   ♪ I'm going all in ♪
[00:00:55.360 --> 00:00:57.520]   ♪ And instead, we open-sourced it to the fans ♪
[00:00:57.520 --> 00:00:59.160]   ♪ And they've just gone crazy with it ♪
[00:00:59.160 --> 00:01:01.480]   ♪ Love you, S-I-C-E, Queen of Kinwam ♪
[00:01:01.480 --> 00:01:03.400]   ♪ I'm going all in ♪
[00:01:03.400 --> 00:01:05.720]   - Also, all-in election night livestream
[00:01:05.720 --> 00:01:08.000]   is coming November 5th.
[00:01:08.000 --> 00:01:08.920]   You can watch live.
[00:01:08.920 --> 00:01:10.680]   Sachs will be hosting. - Oh, we're doing that?
[00:01:10.680 --> 00:01:11.520]   - We're doing it.
[00:01:11.520 --> 00:01:12.340]   You're hosting it.
[00:01:12.340 --> 00:01:13.680]   Your team said you're doing it.
[00:01:13.680 --> 00:01:15.800]   And so, you'll either get to see Sachs--
[00:01:15.800 --> 00:01:17.840]   - Are you not going to Mar-a-Lago, Sachs?
[00:01:17.840 --> 00:01:21.200]   - Well, if things continue to look good for Trump,
[00:01:21.200 --> 00:01:24.220]   I might go to Mar-a-Lago, I might.
[00:01:24.220 --> 00:01:25.060]   - Yeah.
[00:01:25.060 --> 00:01:26.840]   - Okay, so you're maybe, let's not commit Sachs.
[00:01:26.840 --> 00:01:28.840]   You're maybe, if you go to Mar-a-Lago, you're excused.
[00:01:28.840 --> 00:01:30.480]   - I could livestream from Mar-a-Lago.
[00:01:30.480 --> 00:01:31.880]   - Oh, that would be amazing.
[00:01:31.880 --> 00:01:32.720]   Absolutely amazing.
[00:01:32.720 --> 00:01:34.080]   - I'll go to Mar-a-Lago, that'd be fun.
[00:01:34.080 --> 00:01:35.960]   Yeah, if it looks good, I'll go.
[00:01:35.960 --> 00:01:36.800]   - So maybe that's--
[00:01:36.800 --> 00:01:38.880]   - Just go, Jason, just go.
[00:01:38.880 --> 00:01:39.820]   - Of course I'm invited.
[00:01:39.820 --> 00:01:40.660]   I talked to Jared.
[00:01:40.660 --> 00:01:42.560]   - If things look as good as they do right now,
[00:01:42.560 --> 00:01:44.400]   then I think I'm gonna have to go to Mar-a-Lago.
[00:01:44.400 --> 00:01:45.960]   - I think we should all be in Mar-a-Lago.
[00:01:45.960 --> 00:01:47.640]   - That's gonna be a unique experience.
[00:01:47.640 --> 00:01:49.840]   - Oh my God, can you imagine being in Mar-a-Lago
[00:01:49.840 --> 00:01:51.320]   and he loses?
[00:01:51.320 --> 00:01:52.320]   Oh my God.
[00:01:52.320 --> 00:01:53.160]   - That's why I don't want to go.
[00:01:53.160 --> 00:01:53.980]   - That would be dark, yeah.
[00:01:53.980 --> 00:01:55.400]   - Unless this thing is in the bag.
[00:01:55.400 --> 00:01:56.800]   It's gotta be too big to rig.
[00:01:56.800 --> 00:01:58.560]   If it's too big to rig, I'm going to Mar-a-Lago.
[00:01:58.560 --> 00:01:59.400]   - Too big to rig.
[00:01:59.400 --> 00:02:03.400]   - Do you guys think Polly Market is like,
[00:02:03.400 --> 00:02:05.600]   why do you think it's different from the polls?
[00:02:05.600 --> 00:02:06.920]   Are we talking about this today?
[00:02:06.920 --> 00:02:11.920]   Polly Market's showing like 60, 40, or 65, 35 now, right?
[00:02:11.920 --> 00:02:13.280]   - Yeah, because they're measuring different things.
[00:02:13.280 --> 00:02:14.360]   I've explained this before.
[00:02:14.360 --> 00:02:16.960]   Polly Market is people betting on the outcome.
[00:02:16.960 --> 00:02:19.320]   So 58% think Trump's gonna win.
[00:02:19.320 --> 00:02:22.240]   Whereas the polls in a particular state
[00:02:22.240 --> 00:02:26.440]   show the percentage of how each person's gonna vote.
[00:02:26.440 --> 00:02:30.620]   So if for sure you knew the election was 51, 49,
[00:02:30.620 --> 00:02:32.280]   the betting markets would swing to 100, zero.
[00:02:32.280 --> 00:02:33.120]   - But let me ask you this.
[00:02:33.120 --> 00:02:34.720]   So Nate Silver's model,
[00:02:34.720 --> 00:02:37.060]   which takes the poll from each state
[00:02:37.060 --> 00:02:41.160]   and builds in a kind of a Monte Carlo of super poll,
[00:02:41.160 --> 00:02:44.320]   like a super model for the whole country.
[00:02:44.320 --> 00:02:47.480]   Why is his estimate 50, 50 right now
[00:02:47.480 --> 00:02:50.400]   while the Polly Market is betting at 60, 40?
[00:02:50.400 --> 00:02:53.640]   - It's possible he's laggy in his estimates.
[00:02:53.640 --> 00:02:55.360]   - Got it.
[00:02:55.360 --> 00:02:56.180]   - On the betting markets.
[00:02:56.180 --> 00:02:59.920]   The betting markets seem to go based on momentum.
[00:02:59.920 --> 00:03:03.240]   So it like, it indicates the swing and momentum.
[00:03:03.240 --> 00:03:04.640]   And then the polls obviously take a week or two.
[00:03:04.640 --> 00:03:05.640]   - How do you think they're gonna change
[00:03:05.640 --> 00:03:07.440]   after the interviews the last couple of days?
[00:03:07.440 --> 00:03:10.120]   Trump on Bloomberg and Kamala on Fox.
[00:03:10.120 --> 00:03:11.680]   Do you think those are gonna change anything?
[00:03:11.680 --> 00:03:13.200]   - I don't think so.
[00:03:13.200 --> 00:03:15.400]   - I think it's all baked in now.
[00:03:15.400 --> 00:03:16.720]   - Well, Trump over the past few weeks
[00:03:16.720 --> 00:03:18.480]   seems to have had a surge
[00:03:18.480 --> 00:03:20.680]   owing to the fact that Kamala's interviews
[00:03:20.680 --> 00:03:22.120]   generally don't go well.
[00:03:22.120 --> 00:03:24.060]   So I think she started off a little behind,
[00:03:24.060 --> 00:03:25.660]   started doing interviews to catch up,
[00:03:25.660 --> 00:03:27.720]   and now she's a lot behind.
[00:03:27.720 --> 00:03:30.400]   I don't think the Barrett interview is gonna help her.
[00:03:30.400 --> 00:03:31.560]   - Well, let me ask you this.
[00:03:31.560 --> 00:03:34.040]   So my observation as, I don't know,
[00:03:34.040 --> 00:03:35.600]   I'm not like a super political person
[00:03:35.600 --> 00:03:38.000]   or whatever, a party oriented person.
[00:03:38.000 --> 00:03:41.460]   I looked at the, a lot of the media on both sides,
[00:03:41.460 --> 00:03:43.120]   and it seems like everyone on the left
[00:03:43.120 --> 00:03:45.520]   says Kamala did an amazing job on Fox.
[00:03:45.520 --> 00:03:46.400]   She defended herself.
[00:03:46.400 --> 00:03:48.400]   She showed her skills and her competency.
[00:03:48.400 --> 00:03:49.420]   And then everyone on the right's like,
[00:03:49.420 --> 00:03:51.200]   she embarrassed herself, she fell apart.
[00:03:51.200 --> 00:03:52.200]   And then the same thing happened
[00:03:52.200 --> 00:03:53.520]   with the Trump interview on Bloomberg.
[00:03:53.520 --> 00:03:55.440]   People are like, on the left, they say,
[00:03:55.440 --> 00:03:57.320]   look at how he couldn't handle the interviewer,
[00:03:57.320 --> 00:03:59.460]   and he fell apart and all his lies were exposed.
[00:03:59.460 --> 00:04:00.300]   And everyone on the right's like,
[00:04:00.300 --> 00:04:02.080]   look at him, he got a standing ovation.
[00:04:02.080 --> 00:04:03.960]   It's almost like everyone's just kind of like
[00:04:03.960 --> 00:04:07.280]   self-asserting their beliefs that they already hold
[00:04:07.280 --> 00:04:09.740]   when they judge these people on these interview shows
[00:04:09.740 --> 00:04:10.580]   at this point.
[00:04:10.580 --> 00:04:12.120]   Is it already baked at this point?
[00:04:12.120 --> 00:04:14.520]   Like, is anyone actually going to change their view
[00:04:14.520 --> 00:04:15.720]   based on these interviews happening?
[00:04:15.720 --> 00:04:17.600]   - Well, the question is what appeals
[00:04:17.600 --> 00:04:20.440]   to that small sliver of independence?
[00:04:20.440 --> 00:04:21.280]   - Yeah.
[00:04:21.280 --> 00:04:23.840]   - The question I would ask back to you is,
[00:04:23.840 --> 00:04:27.000]   if the Brett Baier interview was going so well for Kamala,
[00:04:27.000 --> 00:04:30.560]   why was her staff on the sidelines waving
[00:04:30.560 --> 00:04:31.840]   to try and end the interview?
[00:04:31.840 --> 00:04:34.040]   They apparently had like four people, you know,
[00:04:34.040 --> 00:04:35.880]   waving and trying to cut the interview off.
[00:04:35.880 --> 00:04:37.480]   - Who said that was the case?
[00:04:37.480 --> 00:04:38.300]   - He did.
[00:04:38.300 --> 00:04:39.140]   - Brett Baier said it.
[00:04:39.140 --> 00:04:41.640]   So it was like in "Rocky IV"
[00:04:41.640 --> 00:04:45.000]   when Apollo Creed's corner is like yelling,
[00:04:45.000 --> 00:04:47.400]   "Throw in the damn towel, throw in the damn towel."
[00:04:47.400 --> 00:04:49.280]   They couldn't wait to get her off the stage
[00:04:49.280 --> 00:04:50.600]   after 26 minutes.
[00:04:50.600 --> 00:04:52.520]   I just think that if it was going that great-
[00:04:52.520 --> 00:04:53.360]   - Allegedly, allegedly.
[00:04:53.360 --> 00:04:54.180]   - Yeah.
[00:04:54.180 --> 00:04:55.560]   I don't think Brett Baier's gonna lie about that.
[00:04:55.560 --> 00:04:56.760]   - I don't know why he would lie about that.
[00:04:56.760 --> 00:04:57.600]   That makes sense.
[00:04:57.600 --> 00:04:59.640]   - Why would they get her off the stage after 26 minutes
[00:04:59.640 --> 00:05:00.840]   if it was going so great?
[00:05:00.840 --> 00:05:02.560]   I'm not saying it went as horrible
[00:05:02.560 --> 00:05:05.200]   as some of the partisans on the other side are saying,
[00:05:05.200 --> 00:05:06.840]   but I don't think it went that great.
[00:05:06.840 --> 00:05:08.880]   - Do you give her any credit for going into the lion's den
[00:05:08.880 --> 00:05:09.720]   like she did?
[00:05:09.720 --> 00:05:11.360]   - Well, I think that she went,
[00:05:11.360 --> 00:05:14.560]   she did the interview precisely to get the talking point
[00:05:14.560 --> 00:05:16.360]   that she does adversarial interviews
[00:05:16.360 --> 00:05:18.320]   because that talking point was hurting them.
[00:05:18.320 --> 00:05:20.560]   And so you saw like all of her fans in the media
[00:05:20.560 --> 00:05:23.760]   were saying, "Well, see, she can walk into the lion's den."
[00:05:23.760 --> 00:05:26.680]   But again, she did the shortest interview possible.
[00:05:26.680 --> 00:05:29.880]   I don't think she answered the questions directly.
[00:05:29.880 --> 00:05:31.300]   I think she filibustered a lot.
[00:05:31.300 --> 00:05:32.960]   She deflected a lot.
[00:05:32.960 --> 00:05:34.960]   I don't think she was particularly persuasive.
[00:05:34.960 --> 00:05:37.360]   I don't think she convinced anybody.
[00:05:37.360 --> 00:05:40.560]   So I think that what you saw there was somebody
[00:05:40.560 --> 00:05:43.680]   who just wanted to get it over with as quickly as possible
[00:05:43.680 --> 00:05:47.720]   to check the box on, okay, does adversarial interviews.
[00:05:47.720 --> 00:05:49.240]   Trump, on the other hand,
[00:05:49.240 --> 00:05:51.400]   he actually likes doing these things.
[00:05:51.400 --> 00:05:52.240]   The Bloomberg interview--
[00:05:52.240 --> 00:05:53.920]   - There's no filibustering there, right?
[00:05:53.920 --> 00:05:55.120]   (laughs)
[00:05:55.120 --> 00:05:55.960]   - No, he's crisp in his answers.
[00:05:55.960 --> 00:05:59.120]   - It's all filibustered, come on, it's all anecdotes.
[00:05:59.120 --> 00:06:01.760]   - He can do the weave, he can do the anecdotes,
[00:06:01.760 --> 00:06:06.000]   but he's also very good at coming back on the interviewer
[00:06:06.000 --> 00:06:07.760]   when they get adversarial.
[00:06:07.760 --> 00:06:09.240]   And the audience was with him,
[00:06:09.240 --> 00:06:10.320]   they gave him a standing ovation.
[00:06:10.320 --> 00:06:13.840]   He went for 64 minutes compared to her 26.
[00:06:13.840 --> 00:06:15.160]   I just think there's no comparison.
[00:06:15.160 --> 00:06:18.240]   I think Trump is someone who relishes
[00:06:18.240 --> 00:06:20.800]   walking into the lion's den and doing those interviews.
[00:06:20.800 --> 00:06:22.480]   I think Harris did it because she felt like she had to.
[00:06:22.480 --> 00:06:23.320]   - What do you think, Zach?
[00:06:23.320 --> 00:06:24.140]   What do you think, Jamal?
[00:06:24.140 --> 00:06:24.980]   Do you see it or no?
[00:06:24.980 --> 00:06:25.820]   Do you have any opinion?
[00:06:25.820 --> 00:06:27.840]   - I watched the whole interview.
[00:06:27.840 --> 00:06:30.480]   It was clear in the interview,
[00:06:30.480 --> 00:06:33.400]   he mentioned the fact that he was being waved off
[00:06:33.400 --> 00:06:35.120]   and then he said it after the fact as well.
[00:06:35.120 --> 00:06:37.400]   That's not alleged, I think that that did happen.
[00:06:37.400 --> 00:06:40.400]   I would say two things.
[00:06:40.400 --> 00:06:43.000]   I thought that she was composed
[00:06:43.000 --> 00:06:46.520]   and she maintained her cool.
[00:06:46.520 --> 00:06:49.520]   So I think from a stylistic perspective,
[00:06:49.520 --> 00:06:51.400]   I thought that she did well.
[00:06:51.400 --> 00:06:55.420]   From a substance perspective, it was pretty lacking
[00:06:55.420 --> 00:06:57.640]   because if you actually listened to the answers,
[00:06:57.640 --> 00:07:00.520]   there was just a ton of non-answers.
[00:07:00.520 --> 00:07:04.280]   And they were two very basic questions
[00:07:04.280 --> 00:07:07.040]   that I think a lot of people,
[00:07:07.040 --> 00:07:08.560]   even if you're not a swing voter,
[00:07:08.560 --> 00:07:12.160]   I think would probably want to know the answer to.
[00:07:12.160 --> 00:07:15.120]   Meaning, did she have any regrets
[00:07:15.120 --> 00:07:18.160]   about what's happened in the last three and a half years?
[00:07:18.160 --> 00:07:19.320]   Did she have any regrets
[00:07:19.320 --> 00:07:21.120]   about what she's done on the border?
[00:07:21.120 --> 00:07:26.200]   Has she not noticed that Biden was wavering
[00:07:26.200 --> 00:07:28.400]   before he was hot swapped?
[00:07:28.400 --> 00:07:30.640]   I think that you could have predicted
[00:07:30.640 --> 00:07:33.080]   that these questions were going to come.
[00:07:33.080 --> 00:07:36.440]   So I think I was surprised that there wasn't a crisp answer
[00:07:36.440 --> 00:07:38.080]   that they had practiced for that.
[00:07:38.080 --> 00:07:41.900]   The second thing I'll say is then David is right.
[00:07:41.900 --> 00:07:44.600]   Everybody then gets very tribal in how they interpret it.
[00:07:44.600 --> 00:07:46.480]   I think I saw one tweet from Elon
[00:07:46.480 --> 00:07:49.360]   about how all of the newspapers characterized
[00:07:49.360 --> 00:07:52.360]   her interview with Brett Baier as quote-unquote testy.
[00:07:52.360 --> 00:07:55.160]   And it was sort of like that was the way
[00:07:55.160 --> 00:07:57.120]   that the mainstream media framed it.
[00:07:57.120 --> 00:07:59.840]   I suspect if somebody looked at how Trump's interview
[00:07:59.840 --> 00:08:03.200]   with Bloomberg was analyzed,
[00:08:03.200 --> 00:08:05.240]   it probably had some similar verbiage
[00:08:05.240 --> 00:08:07.040]   that was repeated there as well.
[00:08:07.040 --> 00:08:08.520]   So I think you are right, Jason,
[00:08:08.520 --> 00:08:11.040]   that the mainstream media can't be trusted to tell the truth.
[00:08:11.040 --> 00:08:12.440]   I would just encourage people to watch it.
[00:08:12.440 --> 00:08:14.760]   I think, like I said, stylistically,
[00:08:14.760 --> 00:08:17.280]   I think she did well and remained composed substantively.
[00:08:17.280 --> 00:08:19.400]   I think it was non-existent.
[00:08:19.400 --> 00:08:21.040]   - Yeah, it would have been nice to have another debate
[00:08:21.040 --> 00:08:22.800]   between these two.
[00:08:22.800 --> 00:08:25.440]   - She still can't really explain how she's different
[00:08:25.440 --> 00:08:28.560]   than Joe Biden, other than the fact that he's a white male
[00:08:28.560 --> 00:08:29.640]   and she's a woman of color.
[00:08:29.640 --> 00:08:32.760]   So beyond just sort of the superficial differences,
[00:08:32.760 --> 00:08:34.840]   she can't explain on a policy level
[00:08:34.840 --> 00:08:36.160]   what she would do differently.
[00:08:36.160 --> 00:08:38.040]   She's had so many opportunities to say that.
[00:08:38.040 --> 00:08:38.960]   They asked her on "The View,"
[00:08:38.960 --> 00:08:40.680]   they asked her on Stephen Colbert,
[00:08:40.680 --> 00:08:42.620]   Brett Baier asked her in his way,
[00:08:42.620 --> 00:08:45.240]   and she still can't explain what she would do differently.
[00:08:45.240 --> 00:08:46.880]   And I think that is the fundamental problem
[00:08:46.880 --> 00:08:49.740]   she has in her campaign is voters still don't know
[00:08:49.740 --> 00:08:51.340]   who she is or what she would do.
[00:08:52.600 --> 00:08:54.800]   - Yeah, what did you think of J.D. Vance saying
[00:08:54.800 --> 00:08:56.880]   he wouldn't have certified the election?
[00:08:56.880 --> 00:08:59.740]   They seem to be going after him on that over and over again.
[00:08:59.740 --> 00:09:01.800]   Saxon.
[00:09:01.800 --> 00:09:03.600]   - You're the only person talking about that.
[00:09:03.600 --> 00:09:05.040]   - No, no, literally every interview,
[00:09:05.040 --> 00:09:06.520]   they've been chasing him down the hall asking him.
[00:09:06.520 --> 00:09:07.520]   He's like, "I'm not the only person.
[00:09:07.520 --> 00:09:08.360]   "I may have started it."
[00:09:08.360 --> 00:09:09.480]   But what'd you think of him saying
[00:09:09.480 --> 00:09:10.320]   he wouldn't have certified?
[00:09:10.320 --> 00:09:12.800]   - That is kinda like when he's in a combative
[00:09:12.800 --> 00:09:16.160]   reporting moment, that is the question he gets a lot.
[00:09:16.160 --> 00:09:17.840]   - That's not the interview I saw.
[00:09:17.840 --> 00:09:21.080]   When I saw the interview he just did with Martha Raddatz,
[00:09:21.080 --> 00:09:23.880]   she was saying that Trump was exaggerating.
[00:09:23.880 --> 00:09:25.680]   - No, no, the question I asked you, Sax, was,
[00:09:25.680 --> 00:09:27.160]   I asked you, Sax, about him saying
[00:09:27.160 --> 00:09:28.000]   he wouldn't certify January 6th.
[00:09:28.000 --> 00:09:28.840]   - You're fixated on that whole thing.
[00:09:28.840 --> 00:09:29.660]   You're the only one who's fixated on it.
[00:09:29.660 --> 00:09:30.500]   - No, I'm just curious.
[00:09:30.500 --> 00:09:31.340]   I, well, me and the other journalists.
[00:09:31.340 --> 00:09:32.480]   What do you think, Freeberg?
[00:09:32.480 --> 00:09:35.000]   - No one who is persuadable, who doesn't have TDS,
[00:09:35.000 --> 00:09:37.000]   cares about that topic anymore.
[00:09:37.000 --> 00:09:38.960]   - What do you think, Freeberg, about him saying
[00:09:38.960 --> 00:09:40.600]   he wouldn't certify January 6th?
[00:09:40.600 --> 00:09:42.360]   - It's not what they're asking, J.D.
[00:09:42.360 --> 00:09:43.920]   If you wanna talk about interviews
[00:09:43.920 --> 00:09:46.360]   that J.D. Vance has done, talk about the one
[00:09:46.360 --> 00:09:48.360]   that's actually going viral right now.
[00:09:48.360 --> 00:09:50.640]   And that was the interview he did with Martha Raddatz,
[00:09:50.640 --> 00:09:52.080]   where she starts saying that, you know,
[00:09:52.080 --> 00:09:53.880]   we've only had a few of these apartment buildings
[00:09:53.880 --> 00:09:55.680]   taken over by foreign gangs.
[00:09:55.680 --> 00:09:59.040]   And he's like, do you realize what you're saying?
[00:09:59.040 --> 00:10:00.720]   You know, there's no comeback from that.
[00:10:00.720 --> 00:10:01.560]   He destroyed her.
[00:10:01.560 --> 00:10:04.160]   - It was very compelling, what he did.
[00:10:04.160 --> 00:10:06.680]   - And every interview he does is like that.
[00:10:06.680 --> 00:10:09.640]   - Yeah, I mean, she was basically saying
[00:10:09.640 --> 00:10:12.480]   that she spoke to, what was it, the city manager,
[00:10:12.480 --> 00:10:14.600]   and she's like, he said only a handful of buildings
[00:10:14.600 --> 00:10:16.940]   have been taken over, and J.D. Vance was like,
[00:10:16.940 --> 00:10:17.780]   what do you mean?
[00:10:17.780 --> 00:10:19.640]   Like, only a handful of buildings?
[00:10:19.640 --> 00:10:22.900]   Like, isn't that anything more than zero, like too much?
[00:10:22.900 --> 00:10:24.960]   Or anything more than one is obviously a problem?
[00:10:24.960 --> 00:10:29.960]   Like, it was just such an obvious rebuttal to the narrative
[00:10:29.960 --> 00:10:32.760]   that they're kind of over-exaggerating a particular issue.
[00:10:32.760 --> 00:10:33.920]   I have no data on this,
[00:10:33.920 --> 00:10:36.680]   but he was very compelling in that response.
[00:10:36.680 --> 00:10:37.680]   I thought it was pretty strong.
[00:10:37.680 --> 00:10:38.800]   But I will say, like, generally,
[00:10:38.800 --> 00:10:43.240]   neither candidate seems to be introducing a new message
[00:10:43.240 --> 00:10:45.820]   or seems to be introducing new content.
[00:10:45.820 --> 00:10:48.440]   They're just kind of standing up,
[00:10:48.440 --> 00:10:50.520]   you know, kind of repeating things that they've said,
[00:10:50.520 --> 00:10:52.240]   showing that they can handle and manage
[00:10:52.240 --> 00:10:54.720]   different kind of combative reporting tactics,
[00:10:54.720 --> 00:10:56.240]   and that's kind of what's going on.
[00:10:56.240 --> 00:10:58.000]   And everyone seems to have made up their mind.
[00:10:58.000 --> 00:11:00.720]   I see a lot of people on both sides say,
[00:11:00.720 --> 00:11:03.320]   again, this side, this person did great,
[00:11:03.320 --> 00:11:05.720]   my person did great against this combative reporter,
[00:11:05.720 --> 00:11:06.800]   and the other person did poorly
[00:11:06.800 --> 00:11:07.940]   against their combative reporter,
[00:11:07.940 --> 00:11:10.320]   and everyone's kind of biased in their view.
[00:11:10.320 --> 00:11:11.920]   It just feels like this election's baked
[00:11:11.920 --> 00:11:13.720]   and we should just go to the polls and be done.
[00:11:13.720 --> 00:11:15.400]   - Yeah, what did you think, Freyberg, though?
[00:11:15.400 --> 00:11:18.080]   'Cause there's no October surprise coming out, right, Saxe?
[00:11:18.080 --> 00:11:20.420]   Chamath, Jake, Jake Allen? - Oh, so three weeks.
[00:11:20.420 --> 00:11:21.340]   - Yeah, anything can happen.
[00:11:21.340 --> 00:11:22.540]   - But there hasn't been anything, right?
[00:11:22.540 --> 00:11:26.780]   Like, that's kind of a shocking moment yet this month, right?
[00:11:26.780 --> 00:11:28.620]   - But, Freyberg, the question I was gonna ask you is,
[00:11:28.620 --> 00:11:33.360]   since you're not, like, hosting Trump, you know, fundraisers,
[00:11:33.360 --> 00:11:37.140]   do you think, what did you think when J.D. Vance said
[00:11:37.140 --> 00:11:39.540]   he didn't think that Trump lost the 2020 election?
[00:11:39.540 --> 00:11:40.940]   Does that concern you at all?
[00:11:40.940 --> 00:11:45.940]   - Um, there's no way to answer this
[00:11:45.940 --> 00:11:52.360]   with the kind of clean framing I think you're looking for.
[00:11:52.360 --> 00:11:55.780]   What I saw from J.D. is that he wants the reporter
[00:11:55.780 --> 00:11:57.160]   and the people that he's talking to,
[00:11:57.160 --> 00:12:00.640]   and I hear this from him, to zoom out a little bit
[00:12:00.640 --> 00:12:04.640]   and recognize that there are significant control
[00:12:04.640 --> 00:12:08.200]   and control systems and biases that he believes
[00:12:08.200 --> 00:12:10.840]   and others believe are strongly affecting
[00:12:10.840 --> 00:12:14.400]   the election process and as a result, the election outcome.
[00:12:14.400 --> 00:12:17.640]   And I think that that message is lost
[00:12:17.640 --> 00:12:20.840]   because people want him to say Trump lost the election,
[00:12:20.840 --> 00:12:23.280]   you're not admitting it, you're bad.
[00:12:23.280 --> 00:12:25.480]   But those people also aren't hearing the point
[00:12:25.480 --> 00:12:28.720]   that he's making, which is that there are biases.
[00:12:28.720 --> 00:12:30.880]   And we heard these biases, by the way,
[00:12:30.880 --> 00:12:34.040]   with Democrats in prior elections as well,
[00:12:34.040 --> 00:12:35.920]   where they highlighted that they believed
[00:12:35.920 --> 00:12:38.180]   that there were biases with respect to misinformation
[00:12:38.180 --> 00:12:40.200]   being amplified on social media.
[00:12:40.200 --> 00:12:41.680]   And then the next election cycle,
[00:12:41.680 --> 00:12:43.440]   they were able to step in and influence
[00:12:43.440 --> 00:12:46.360]   what was being changed on those social media platforms.
[00:12:46.360 --> 00:12:49.900]   And so there's this big kind of war, media war going on.
[00:12:49.900 --> 00:12:50.740]   - Yeah, that's what I was questioning.
[00:12:50.740 --> 00:12:51.600]   - Through social media platforms.
[00:12:51.600 --> 00:12:54.620]   And I think that that's what both sides are highlighting,
[00:12:54.620 --> 00:12:56.160]   is their big concern.
[00:12:56.160 --> 00:12:58.300]   And now there's this other big concern
[00:12:58.300 --> 00:13:01.760]   about is there appropriate voter verification
[00:13:01.760 --> 00:13:03.120]   that the people who are voting,
[00:13:03.120 --> 00:13:06.400]   and it's a question to ask that shouldn't be dismissed.
[00:13:06.400 --> 00:13:07.720]   It is a good question to ask.
[00:13:07.720 --> 00:13:08.760]   - Yeah, it's a great question.
[00:13:08.760 --> 00:13:11.680]   - As a person who doesn't have a strong bias
[00:13:11.680 --> 00:13:13.600]   for a political party here,
[00:13:13.600 --> 00:13:16.160]   I feel like I wanna hear answers to those questions.
[00:13:16.160 --> 00:13:20.040]   Like, what is the structure of how the way
[00:13:20.040 --> 00:13:21.440]   that most people are getting their media today,
[00:13:21.440 --> 00:13:23.440]   which is through social media platforms,
[00:13:23.440 --> 00:13:25.320]   what is the mechanism for censorship?
[00:13:25.320 --> 00:13:28.320]   What is the mechanism for filtering, for moderation,
[00:13:28.320 --> 00:13:29.720]   and be public and transparent about it?
[00:13:29.720 --> 00:13:31.840]   And then separately, what are the mechanisms
[00:13:31.840 --> 00:13:35.500]   for deciding who gets to vote and how they get to vote?
[00:13:35.500 --> 00:13:37.120]   And I think those are both really good things to ask.
[00:13:37.120 --> 00:13:39.200]   - I would just like to take a step back
[00:13:39.200 --> 00:13:41.920]   and say that that was one of the most incredible answers
[00:13:41.920 --> 00:13:44.100]   I've ever heard, Freeberg.
[00:13:44.100 --> 00:13:50.160]   Unfortunately, it may not land for the reductive masses,
[00:13:50.160 --> 00:13:53.680]   but it was exceptionally powerful and thoughtful.
[00:13:53.680 --> 00:13:54.960]   Thank you.
[00:13:54.960 --> 00:13:55.960]   - Yeah, I think that- - That's what I'm here for,
[00:13:55.960 --> 00:13:57.360]   Chamath, I'm here for you.
[00:13:57.360 --> 00:14:00.400]   - Well, I mean, independent of who wins,
[00:14:00.400 --> 00:14:04.600]   we need to get this rules of elections really tight
[00:14:04.600 --> 00:14:06.040]   starting next year, I think.
[00:14:06.040 --> 00:14:11.040]   Make it a federal holiday, require people to have ID,
[00:14:11.040 --> 00:14:12.840]   that doesn't seem like such a big deal.
[00:14:12.840 --> 00:14:15.000]   I don't know, Sax, what else should happen?
[00:14:15.000 --> 00:14:16.560]   Federal holiday, make it- - Well, right now,
[00:14:16.560 --> 00:14:19.520]   you've got Biden's DOJ is literally suing
[00:14:19.520 --> 00:14:24.000]   the state of Virginia, which is required by Virginia law
[00:14:24.000 --> 00:14:26.560]   to clean the voter rolls of illegal immigrants,
[00:14:26.560 --> 00:14:28.120]   and they've been doing that,
[00:14:28.120 --> 00:14:30.800]   and Biden's DOJ has sued to stop that.
[00:14:30.800 --> 00:14:32.280]   In California, like you said,
[00:14:32.280 --> 00:14:34.660]   we now have a new law signed by Gavin Newsom
[00:14:34.660 --> 00:14:37.580]   to make it illegal to ask for voter ID.
[00:14:37.580 --> 00:14:39.640]   So Democrats seem to be undermining
[00:14:39.640 --> 00:14:42.640]   the integrity of elections, not fortifying it.
[00:14:42.640 --> 00:14:46.600]   So when you ask, why do Republicans distrust elections,
[00:14:46.600 --> 00:14:47.760]   maybe it has something to do
[00:14:47.760 --> 00:14:50.120]   with the way that Democrats are acting.
[00:14:50.120 --> 00:14:52.600]   But I agree with you, I think that cleaning up
[00:14:52.600 --> 00:14:56.560]   the voter rolls, having a minimum standard
[00:14:56.560 --> 00:15:01.560]   for voter verification is something
[00:15:01.560 --> 00:15:03.320]   that I think should be done.
[00:15:03.320 --> 00:15:04.540]   According to the Constitution,
[00:15:04.540 --> 00:15:06.360]   the states basically run their own elections,
[00:15:06.360 --> 00:15:08.420]   but it doesn't make sense to me
[00:15:08.420 --> 00:15:11.780]   that in a one-party machine politics state,
[00:15:11.780 --> 00:15:14.620]   where basically one party controls the state,
[00:15:14.620 --> 00:15:16.440]   that they could set up a system
[00:15:16.440 --> 00:15:19.300]   that effectively entrenches their power forever
[00:15:19.300 --> 00:15:20.860]   in federal elections.
[00:15:20.860 --> 00:15:23.020]   It just seems to me that the federal government
[00:15:23.020 --> 00:15:27.420]   has a compelling interest that must be constitutional
[00:15:27.420 --> 00:15:30.700]   in ensuring a minimum standard of honesty
[00:15:30.700 --> 00:15:32.380]   in federal elections.
[00:15:32.380 --> 00:15:33.300]   So I think it would be great
[00:15:33.300 --> 00:15:34.920]   to do something about this next year.
[00:15:34.920 --> 00:15:38.400]   I think that if you want people to stop questioning elections
[00:15:38.400 --> 00:15:41.000]   or engaging in election denial,
[00:15:41.000 --> 00:15:43.600]   you need to make the elections above reproach.
[00:15:43.600 --> 00:15:44.440]   So let's do that.
[00:15:44.440 --> 00:15:46.160]   - So anyway, Heritage Foundation,
[00:15:46.160 --> 00:15:49.080]   which is obviously right-leaning,
[00:15:49.080 --> 00:15:52.160]   has a bunch of election fraud cases
[00:15:52.160 --> 00:15:54.840]   they've been documenting and they basically
[00:15:54.840 --> 00:15:58.760]   cannot come up with actual evidence
[00:15:58.760 --> 00:16:03.080]   that this is changing any election results,
[00:16:03.080 --> 00:16:06.220]   but we should make it above reproach, I agree.
[00:16:06.220 --> 00:16:08.220]   All right, our boy Elon had a big week.
[00:16:08.220 --> 00:16:11.500]   Tesla unveiled two new concepts at its WeRobot event,
[00:16:11.500 --> 00:16:16.500]   and Elon caught a 23-story rocket, the Starship.
[00:16:16.500 --> 00:16:19.140]   Here's the RoboTaxi and the RoboBus.
[00:16:19.140 --> 00:16:21.740]   Both of them look really awesome.
[00:16:21.740 --> 00:16:24.460]   And he caught one of the,
[00:16:24.460 --> 00:16:28.220]   I think this is the fifth Starship or the fourth launch?
[00:16:28.220 --> 00:16:29.060]   - Fifth.
[00:16:29.060 --> 00:16:29.900]   - The fifth, right?
[00:16:29.900 --> 00:16:30.860]   - So (beep) incredible.
[00:16:30.860 --> 00:16:32.120]   - Look at this.
[00:16:32.120 --> 00:16:33.180]   - It's so incredible. - Unbelievable.
[00:16:33.180 --> 00:16:34.860]   It's like chopsticks catching
[00:16:34.860 --> 00:16:35.700]   a 23-story building. - Forget about
[00:16:35.700 --> 00:16:37.120]   whatever your (beep) issues are
[00:16:37.120 --> 00:16:38.980]   with Elon and his politics.
[00:16:38.980 --> 00:16:40.940]   Just to appreciate, and we can talk about
[00:16:40.940 --> 00:16:44.020]   why this is so important in this segment,
[00:16:44.020 --> 00:16:47.220]   but technically, the achievement of this skyscraper
[00:16:47.220 --> 00:16:49.660]   falling out of the sky and perfectly aligning itself
[00:16:49.660 --> 00:16:53.260]   to go into that chopstick-catching device,
[00:16:53.260 --> 00:16:56.880]   it is an absolute marvel of human ingenuity.
[00:16:56.880 --> 00:16:58.720]   I mean, and the work and the effort
[00:16:58.720 --> 00:17:01.600]   that people put into this over several decades,
[00:17:01.600 --> 00:17:03.020]   it's just such an incredible feat.
[00:17:03.020 --> 00:17:04.060]   Look at this thing.
[00:17:04.060 --> 00:17:05.500]   I don't know if you guys were as emotionally moved
[00:17:05.500 --> 00:17:06.340]   by this as I was.
[00:17:06.340 --> 00:17:07.580]   I thought it was incredible. - It was incredible.
[00:17:07.580 --> 00:17:09.540]   I think I probably watched this 100 times.
[00:17:09.540 --> 00:17:11.060]   - Totally, from every angle.
[00:17:11.060 --> 00:17:12.180]   - Every angle.
[00:17:12.180 --> 00:17:14.620]   - And so the reason this is so important
[00:17:14.620 --> 00:17:18.260]   is because these things cost a lot of money,
[00:17:18.260 --> 00:17:20.800]   and when they land here, you can clean them up,
[00:17:20.800 --> 00:17:23.460]   and I guess his goal is to have them take off again
[00:17:23.460 --> 00:17:25.420]   after he fills them with propellant
[00:17:25.420 --> 00:17:26.920]   an hour later, Friedberg.
[00:17:26.920 --> 00:17:30.300]   So on a science basis, this is extraordinary.
[00:17:30.300 --> 00:17:32.020]   What, you know, if this works,
[00:17:32.020 --> 00:17:33.580]   and you can start lifting these rockets--
[00:17:33.580 --> 00:17:36.920]   - To be more specific, you don't want it to have feet.
[00:17:36.920 --> 00:17:41.920]   A, it's heavy, and then B, you have to lift them up
[00:17:41.920 --> 00:17:44.500]   in a way that just complicates the entire refueling
[00:17:44.500 --> 00:17:45.860]   and cycle time process.
[00:17:45.860 --> 00:17:48.240]   So by catching it, you put it right back into place
[00:17:48.240 --> 00:17:49.220]   and just go again.
[00:17:49.220 --> 00:17:50.060]   - Unbelievable. - Unbelievable.
[00:17:50.060 --> 00:17:51.660]   - Right, you just catch it and go again.
[00:17:51.660 --> 00:17:53.980]   - I can kind of walk through these numbers.
[00:17:53.980 --> 00:17:57.860]   So obviously the big objective over time
[00:17:57.860 --> 00:18:02.860]   is how cheap can you get it to put material into space?
[00:18:02.860 --> 00:18:05.940]   We need a lot of material to go into space
[00:18:05.940 --> 00:18:08.020]   if we're gonna do things in space,
[00:18:08.020 --> 00:18:11.360]   particularly if we're gonna go build a colony on Mars.
[00:18:11.360 --> 00:18:14.780]   And so this shows you over time the cost per kilogram,
[00:18:14.780 --> 00:18:16.620]   which is the key metric in this industry,
[00:18:16.620 --> 00:18:20.900]   to launch material into low Earth orbit.
[00:18:20.900 --> 00:18:23.340]   And you can see here how SpaceX
[00:18:23.340 --> 00:18:25.000]   has dramatically reduced the cost.
[00:18:25.000 --> 00:18:29.140]   I remember when the small sat era began in the 2010s.
[00:18:29.140 --> 00:18:30.340]   Do you guys remember all these startups
[00:18:30.340 --> 00:18:32.020]   that were starting to build little small sats
[00:18:32.020 --> 00:18:35.340]   and put 'em up to do imaging and comms and stuff?
[00:18:35.340 --> 00:18:39.580]   When this took off, it was about 10,000 bucks a kilogram
[00:18:39.580 --> 00:18:43.340]   to put a small sat into space or to put material into space.
[00:18:43.340 --> 00:18:45.660]   And then SpaceX has dropped the cost to the point
[00:18:45.660 --> 00:18:48.500]   that it's now close to $1,000 a kilogram,
[00:18:48.500 --> 00:18:52.060]   so a 10X reduction in cost in just the last decade or so.
[00:18:52.060 --> 00:18:55.080]   And that's why SpaceX just dominates the launch market.
[00:18:55.080 --> 00:18:59.540]   But Elon's always said that $1,000 a kilogram is too high.
[00:18:59.540 --> 00:19:01.580]   But his objective has been to get the cost down
[00:19:01.580 --> 00:19:03.180]   to 10 bucks a kilogram.
[00:19:03.180 --> 00:19:05.040]   'Cause at 10 bucks a kilogram,
[00:19:05.040 --> 00:19:07.420]   you could launch what some people estimate is needed
[00:19:07.420 --> 00:19:10.560]   to get to Mars, which is about half a million tons
[00:19:10.560 --> 00:19:14.180]   of material and people to set up a colony on Mars.
[00:19:14.180 --> 00:19:16.940]   And it actually becomes feasible
[00:19:16.940 --> 00:19:19.380]   to get half a million tons of material
[00:19:19.380 --> 00:19:20.980]   at 10 bucks a kilogram.
[00:19:20.980 --> 00:19:24.740]   So if you look at this new Starship
[00:19:24.740 --> 00:19:25.940]   and Starship Heavy booster,
[00:19:25.940 --> 00:19:28.860]   it's about 150, 200 ton payload.
[00:19:28.860 --> 00:19:33.740]   The booster holds 3,400 tons of propellant.
[00:19:33.740 --> 00:19:36.920]   And the cost of that propellant is pretty low.
[00:19:36.920 --> 00:19:41.540]   You know, it's only about a million dollars in fuel.
[00:19:41.540 --> 00:19:43.820]   So then if you can get the cost of the booster
[00:19:43.820 --> 00:19:45.780]   and the Starship down enough,
[00:19:45.780 --> 00:19:47.740]   and you can reuse it enough,
[00:19:47.740 --> 00:19:50.200]   and you amortize the cost of making that device
[00:19:50.200 --> 00:19:52.540]   over the lifetime of the device,
[00:19:52.540 --> 00:19:54.040]   the cost per launch comes down.
[00:19:54.040 --> 00:19:55.660]   And that's what brings the cost per kilogram down.
[00:19:55.660 --> 00:19:57.860]   So the booster, there's a group called Payload,
[00:19:57.860 --> 00:19:58.900]   and they do estimates on this.
[00:19:58.900 --> 00:19:59.940]   So I won't speak out of turn
[00:19:59.940 --> 00:20:01.960]   in terms of like having inside knowledge.
[00:20:01.960 --> 00:20:05.620]   But the Payload has estimated that Starship
[00:20:05.620 --> 00:20:08.520]   and the booster cost about 90 million bucks today.
[00:20:08.520 --> 00:20:09.900]   And they think that they have a path
[00:20:09.900 --> 00:20:11.380]   to getting it down to 35 million.
[00:20:11.380 --> 00:20:14.040]   So if you can reuse that thing 10 times,
[00:20:14.040 --> 00:20:17.180]   that's a $3.5 million cost per launch,
[00:20:17.180 --> 00:20:18.280]   plus a million for fuel.
[00:20:18.280 --> 00:20:21.100]   You could easily see, and this thing can launch 200 tons.
[00:20:21.100 --> 00:20:23.740]   That's how you start to get to 10 bucks a kilogram
[00:20:23.740 --> 00:20:25.460]   over the next couple of years.
[00:20:25.460 --> 00:20:28.240]   But it was critical to be able to reuse that heavy booster.
[00:20:28.240 --> 00:20:29.780]   And that's what Elon just demonstrated.
[00:20:29.780 --> 00:20:32.660]   It's we can actually catch that heavy booster,
[00:20:32.660 --> 00:20:34.900]   refuel it, and launch it an hour later.
[00:20:34.900 --> 00:20:36.720]   And if you can do that over and over again,
[00:20:36.720 --> 00:20:38.300]   you're spending 10 bucks a kilogram
[00:20:38.300 --> 00:20:39.980]   to put material into space.
[00:20:39.980 --> 00:20:41.340]   You can get fuel into space
[00:20:41.340 --> 00:20:43.780]   and then get those Starships to fly off to Mars
[00:20:43.780 --> 00:20:45.960]   and deliver all this material,
[00:20:45.960 --> 00:20:47.620]   including setting up a base
[00:20:47.620 --> 00:20:49.920]   that would allow you to actually make more fuel on Mars,
[00:20:49.920 --> 00:20:51.940]   'cause everything we need to make fuel is on Mars.
[00:20:51.940 --> 00:20:55.200]   So it's the beginning of the next series
[00:20:55.200 --> 00:20:56.800]   of really important milestones
[00:20:56.800 --> 00:20:59.180]   that'll hopefully get humanity onto Mars.
[00:20:59.180 --> 00:21:01.340]   It was just so amazing to see it come together.
[00:21:01.340 --> 00:21:02.700]   The economics are legit.
[00:21:02.700 --> 00:21:05.380]   I mean, this is like a thousand X reduction in cost.
[00:21:05.380 --> 00:21:06.480]   It's incredible.
[00:21:06.480 --> 00:21:08.060]   - Yeah, it's gonna be amazing.
[00:21:08.060 --> 00:21:11.300]   And they're gonna do some, I guess, new stuff with Starlink,
[00:21:11.300 --> 00:21:14.860]   some even lower Earth orbit satellites that go even faster
[00:21:14.860 --> 00:21:16.140]   and have less latency.
[00:21:16.140 --> 00:21:18.140]   So that's gonna be super exciting.
[00:21:18.140 --> 00:21:19.380]   - Starlink's apparently, I mean,
[00:21:19.380 --> 00:21:21.580]   I know everyone here is a shareholder in SpaceX,
[00:21:21.580 --> 00:21:24.420]   but Starlink's running at 4 million subs right now.
[00:21:24.420 --> 00:21:27.580]   That's like a hundred bucks a month, 4 million subs.
[00:21:27.580 --> 00:21:29.020]   And if you do the math, I mean,
[00:21:29.020 --> 00:21:33.540]   how many people have ISPs that are slower than Starlink?
[00:21:33.540 --> 00:21:35.460]   Right, how many people have cell phone providers
[00:21:35.460 --> 00:21:37.180]   that they're paying roughly the same amount
[00:21:37.180 --> 00:21:38.340]   that aren't as good as Starlink?
[00:21:38.340 --> 00:21:41.260]   If we can get satellite to phone
[00:21:41.260 --> 00:21:43.980]   and you can get Starlink more broadly available,
[00:21:43.980 --> 00:21:45.900]   this could be a hundred million subscriber business.
[00:21:45.900 --> 00:21:47.220]   I mean, this could be- - Absolutely.
[00:21:47.220 --> 00:21:49.860]   - One of the biggest businesses on the Earth.
[00:21:49.860 --> 00:21:52.020]   - It could be the largest subscription business
[00:21:52.020 --> 00:21:53.660]   in the history of humanity.
[00:21:53.660 --> 00:21:56.300]   I think the largest ones right now are like Netflix,
[00:21:56.300 --> 00:22:01.300]   you know, 250, Disney Plus, 150, Verizon, 100 million.
[00:22:01.300 --> 00:22:04.340]   So yeah, it could be hundreds of millions of subscribers.
[00:22:04.340 --> 00:22:05.180]   It could even be- - It's crazy.
[00:22:05.180 --> 00:22:06.300]   - It could be the first- - And we'll look back
[00:22:06.300 --> 00:22:08.220]   on 500 million subscriber product in the middle.
[00:22:08.220 --> 00:22:09.380]   - We could look back one day and be like,
[00:22:09.380 --> 00:22:11.540]   "Why did we run all this copper wire everywhere?"
[00:22:11.540 --> 00:22:13.380]   - Yeah, like- - We don't need it.
[00:22:13.380 --> 00:22:15.580]   - Yeah, obviously. - It's like crazy.
[00:22:15.580 --> 00:22:16.420]   - Especially if it can get to phones.
[00:22:16.420 --> 00:22:18.100]   - It would be like crazy that we were like ever,
[00:22:18.100 --> 00:22:20.100]   I mean, the whole nutty thing about this past week,
[00:22:20.100 --> 00:22:21.260]   it's like we could look back one day and be like,
[00:22:21.260 --> 00:22:22.380]   "Why did we ever drive cars?
[00:22:22.380 --> 00:22:24.580]   And why do we ever have copper wire laid all over the Earth
[00:22:24.580 --> 00:22:26.620]   to like move internet signals around?"
[00:22:26.620 --> 00:22:29.420]   You know, this efficiency gain that's gonna be realized
[00:22:29.420 --> 00:22:32.940]   over the next decade is just incredible.
[00:22:32.940 --> 00:22:33.780]   Just incredible.
[00:22:33.780 --> 00:22:38.780]   Rob, any thoughts on the Robovan or the CyberCab,
[00:22:38.780 --> 00:22:41.580]   the Model 2, I guess some people are calling it,
[00:22:41.580 --> 00:22:43.820]   but it's, you know, the CyberCab specifically,
[00:22:43.820 --> 00:22:46.220]   not calling it number two
[00:22:46.220 --> 00:22:49.060]   and doesn't have a steering wheel or pedals.
[00:22:49.060 --> 00:22:50.740]   I would have bought two of those immediately
[00:22:50.740 --> 00:22:51.580]   if it had a steering wheel and pedals.
[00:22:51.580 --> 00:22:52.620]   - So beautiful. - I wanna drive it.
[00:22:52.620 --> 00:22:55.820]   Yeah, it looks like the hybrid of like a Model Y
[00:22:55.820 --> 00:22:56.700]   and the Cybertruck.
[00:22:56.700 --> 00:22:58.820]   So I kinda really love the aesthetics of it.
[00:22:58.820 --> 00:23:00.940]   - So beautiful. - Yeah, you like it?
[00:23:00.940 --> 00:23:05.940]   My reaction was actually, I don't know,
[00:23:05.940 --> 00:23:11.260]   just seeing these releases now over 10 or 15 years
[00:23:11.260 --> 00:23:14.820]   plus of knowing him, nothing,
[00:23:14.820 --> 00:23:18.620]   it's, I guess it's like not that surprising.
[00:23:18.620 --> 00:23:20.060]   I mean, it's weird to say,
[00:23:20.060 --> 00:23:23.180]   like I just expect him and his teams to figure it out.
[00:23:23.180 --> 00:23:24.900]   Like, they're just all so good.
[00:23:24.900 --> 00:23:26.060]   It's, and the thing to remember,
[00:23:26.060 --> 00:23:28.380]   it's not just him that's incredible,
[00:23:28.380 --> 00:23:32.580]   but he attracts a kind of technical
[00:23:32.580 --> 00:23:35.700]   and operational wonderkind people.
[00:23:35.700 --> 00:23:37.020]   - For sure. - And that's just,
[00:23:37.020 --> 00:23:38.460]   that's just a really special thing.
[00:23:38.460 --> 00:23:40.260]   So I had that reaction,
[00:23:40.260 --> 00:23:45.260]   which was I was really proud and happy for them.
[00:23:45.260 --> 00:23:46.580]   - For the team, yeah, for sure.
[00:23:46.580 --> 00:23:48.500]   - For the team and for him.
[00:23:48.500 --> 00:23:50.420]   These guys are like incredibly fearless.
[00:23:50.420 --> 00:23:52.100]   Failed bigly, right?
[00:23:52.100 --> 00:23:53.220]   - Yeah, big time. - If you're gonna fail,
[00:23:53.220 --> 00:23:54.540]   fail bigly. - Yeah.
[00:23:54.540 --> 00:23:58.100]   - And then the other thing that I thought was crazy
[00:23:58.100 --> 00:24:01.980]   was how many people were trying to dunk on him this weekend.
[00:24:01.980 --> 00:24:04.900]   - Yeah, it's weird. - And that surprised me,
[00:24:04.900 --> 00:24:06.100]   caught me off guard,
[00:24:06.100 --> 00:24:08.460]   because I think that they were personalizing
[00:24:08.460 --> 00:24:12.980]   a lot of anxiety that they are feeling
[00:24:12.980 --> 00:24:14.740]   through these companies' successes,
[00:24:14.740 --> 00:24:16.260]   which didn't make much sense to me.
[00:24:16.260 --> 00:24:18.420]   - Well, in fairness, he did hurt some people's feelings
[00:24:18.420 --> 00:24:19.780]   with posting of memes.
[00:24:19.780 --> 00:24:23.020]   So, yeah, I mean, it's, it makes no sense.
[00:24:23.020 --> 00:24:26.820]   Like the guy's like gonna save 30,000 road deaths a year
[00:24:26.820 --> 00:24:28.940]   in the United States with self-driving
[00:24:28.940 --> 00:24:31.420]   and people are losing their minds over a couple of memes
[00:24:31.420 --> 00:24:32.900]   or who he's voting for for president.
[00:24:32.900 --> 00:24:35.380]   I don't think you have to worry about that.
[00:24:35.380 --> 00:24:36.620]   You can just look at the products.
[00:24:36.620 --> 00:24:38.460]   They speak for themselves.
[00:24:38.460 --> 00:24:42.580]   Anything, Sax, any response on the Tesla front?
[00:24:42.580 --> 00:24:45.900]   Any thoughts on the bus or Optimus?
[00:24:45.900 --> 00:24:47.940]   - I mean, they're both very exciting products.
[00:24:47.940 --> 00:24:49.740]   I don't think I've got a lot to add.
[00:24:49.740 --> 00:24:51.580]   - Yeah, I love the bus, Friedberg.
[00:24:51.580 --> 00:24:54.580]   I think that thing could become like mobile homes are,
[00:24:54.580 --> 00:24:59.060]   you know, ADUs and you could just send them to-
[00:24:59.060 --> 00:25:00.940]   - Can we buy them or no?
[00:25:00.940 --> 00:25:04.980]   - Well, no, not right now, but I think that might be,
[00:25:04.980 --> 00:25:05.820]   you know, that's gonna be a big question.
[00:25:05.820 --> 00:25:08.220]   - Your mom's gonna put all her kids in one.
[00:25:08.220 --> 00:25:09.900]   - I need it for all my kids.
[00:25:09.900 --> 00:25:10.740]   - Yeah.
[00:25:10.740 --> 00:25:12.020]   - Well, see, if this was a platform
[00:25:12.020 --> 00:25:14.340]   like the Mercedes Sprinter vans have become
[00:25:14.340 --> 00:25:15.620]   that you see a lot in Europe,
[00:25:15.620 --> 00:25:18.180]   then you could buy an empty one of these.
[00:25:18.180 --> 00:25:21.540]   It's got enough battery life to last a month.
[00:25:21.540 --> 00:25:23.700]   And then let's say you had your in-laws over
[00:25:23.700 --> 00:25:26.220]   and there was one that was set up as like a one bedroom,
[00:25:26.220 --> 00:25:30.420]   you could click on Airbnb or, you know, Tesla B&B,
[00:25:30.420 --> 00:25:32.660]   press a button and the thing could drive to your driveway.
[00:25:32.660 --> 00:25:34.820]   You could rent it for a week and then it could leave.
[00:25:34.820 --> 00:25:37.940]   Or let's say 1,000 people or 10,000 people were displaced
[00:25:37.940 --> 00:25:39.780]   because of a hurricane, Friedberg.
[00:25:39.780 --> 00:25:41.620]   You could send 100,000 of these
[00:25:41.620 --> 00:25:43.100]   to the parking lots at Walmart,
[00:25:43.100 --> 00:25:45.220]   which typically does a good job in feeding people
[00:25:45.220 --> 00:25:47.420]   and getting them supplies after hurricanes,
[00:25:47.420 --> 00:25:48.420]   since those are so ubiquitous.
[00:25:48.420 --> 00:25:50.780]   You could put 100 of these in every parking lot
[00:25:50.780 --> 00:25:52.540]   and have a place for people
[00:25:52.540 --> 00:25:54.780]   who are fleeing natural disasters to stay.
[00:25:54.780 --> 00:25:57.180]   So I thought that was like the most compelling product
[00:25:57.180 --> 00:26:00.620]   of the whole thing for me was the possibility of a sled,
[00:26:00.620 --> 00:26:03.220]   like a skiff that you could do anything you want with
[00:26:03.220 --> 00:26:05.980]   would be really exciting for society.
[00:26:05.980 --> 00:26:07.620]   So congratulations to the team.
[00:26:07.620 --> 00:26:09.780]   And it's gonna take a while,
[00:26:09.780 --> 00:26:13.340]   but I could see them having that robo-taxi.
[00:26:13.340 --> 00:26:16.380]   - I think congrats to Amit, he just got promoted.
[00:26:16.380 --> 00:26:18.940]   - I saw that, you know, he's in charge of all AI.
[00:26:18.940 --> 00:26:21.340]   I think he's in charge of all manufacturing
[00:26:21.340 --> 00:26:23.540]   and sales in North America.
[00:26:23.540 --> 00:26:24.380]   - Oh, okay.
[00:26:24.380 --> 00:26:25.220]   Well, there it is.
[00:26:25.220 --> 00:26:27.820]   - So shout out to Amit Afshar, yeah.
[00:26:27.820 --> 00:26:30.260]   - I mean, listen- - Guys, I have big news.
[00:26:30.260 --> 00:26:32.540]   I just bought my first Tesla.
[00:26:32.540 --> 00:26:33.380]   - Oh, you did?
[00:26:33.380 --> 00:26:35.540]   Did you go with a Plaid Model S?
[00:26:35.540 --> 00:26:37.060]   - Model S Plaid, yeah.
[00:26:37.060 --> 00:26:41.580]   I test drove it for two weeks and sold itself.
[00:26:41.580 --> 00:26:43.540]   - And are you using the FSD?
[00:26:43.540 --> 00:26:44.740]   I use FSD every day.
[00:26:44.740 --> 00:26:47.060]   - I use FSD and it was like really impressive, so.
[00:26:47.060 --> 00:26:47.900]   - Super impressive.
[00:26:47.900 --> 00:26:49.860]   I've tried Tesla a couple of times over the years
[00:26:49.860 --> 00:26:51.940]   and I never really, never really worked for me.
[00:26:51.940 --> 00:26:54.300]   The quality just didn't feel like what I,
[00:26:54.300 --> 00:26:56.340]   like given what I had before, the car-wise.
[00:26:56.340 --> 00:26:57.340]   - You were an Audi guy, right?
[00:26:57.340 --> 00:26:59.180]   - But Audi guy, yeah, always loved Audis.
[00:26:59.180 --> 00:27:00.740]   - Audi guys are neat guys.
[00:27:00.740 --> 00:27:04.540]   - That's, you know, it's a big milestone.
[00:27:04.540 --> 00:27:07.140]   I really, I thought the FSD was the selling.
[00:27:07.140 --> 00:27:09.300]   And then the speed on the Plaid, it's just insane.
[00:27:09.300 --> 00:27:11.900]   It's better than my RS7, like, it's incredible.
[00:27:11.900 --> 00:27:14.020]   - With all of my Teslas, I put it in show mode
[00:27:14.020 --> 00:27:16.300]   because when it's in that Plaid mode or whatever,
[00:27:16.300 --> 00:27:17.780]   like coffee goes fine. - It's my favorite.
[00:27:17.780 --> 00:27:18.620]   I love it, I get on the-
[00:27:18.620 --> 00:27:19.740]   - But if you have passengers,
[00:27:19.740 --> 00:27:21.420]   the kids in the back seat would hit,
[00:27:21.420 --> 00:27:23.700]   like literally nauseous because it's too fast.
[00:27:23.700 --> 00:27:26.140]   You gotta be careful with the passengers there.
[00:27:26.140 --> 00:27:28.460]   It's so fast. - It was awesome.
[00:27:28.460 --> 00:27:29.580]   Awesome.
[00:27:29.580 --> 00:27:31.580]   - All right, well, there you have it.
[00:27:31.580 --> 00:27:33.420]   Robo Taxi Star, we didn't get to it last week.
[00:27:33.420 --> 00:27:36.340]   We almost put the show back a day or two just to do it.
[00:27:36.340 --> 00:27:38.660]   In other news, Uber is exploring a bid
[00:27:38.660 --> 00:27:41.180]   to purchase Expedia, breaking news.
[00:27:41.180 --> 00:27:44.540]   This was dispelled as we got here on the show.
[00:27:44.540 --> 00:27:47.260]   They said this was like very preliminary third-party talks
[00:27:47.260 --> 00:27:49.260]   and that there's no serious talks going on about this.
[00:27:49.260 --> 00:27:53.580]   Financial Times reported that advisors
[00:27:53.580 --> 00:27:55.340]   were trying to look at if a deal structure
[00:27:55.340 --> 00:27:57.980]   would be possible between Uber and Expedia.
[00:27:57.980 --> 00:28:00.300]   Expedia's got a $20 billion market cap.
[00:28:00.300 --> 00:28:02.180]   They popped 8% on the news, obviously.
[00:28:02.180 --> 00:28:03.220]   Uber, on the other hand,
[00:28:03.220 --> 00:28:05.420]   trading at $170 billion market cap or so.
[00:28:05.420 --> 00:28:08.100]   That dropped 3%.
[00:28:08.100 --> 00:28:10.540]   If you didn't know, Dara was the CEO of Expedia
[00:28:10.540 --> 00:28:12.500]   from 2005 to 2017.
[00:28:12.500 --> 00:28:14.420]   He's still on the board.
[00:28:14.420 --> 00:28:17.820]   And it looks like this was a trial balloon.
[00:28:17.820 --> 00:28:20.420]   You know, Uber's two biggest businesses,
[00:28:20.420 --> 00:28:21.620]   rides and Uber Eats,
[00:28:21.620 --> 00:28:23.900]   but they also do freight and train bookings.
[00:28:23.900 --> 00:28:25.060]   Dara's been pretty clear.
[00:28:25.060 --> 00:28:29.220]   He wants to create a super app
[00:28:29.220 --> 00:28:32.260]   like you have in China or some other markets.
[00:28:32.260 --> 00:28:34.460]   Expedia's got a lot of cool products.
[00:28:34.460 --> 00:28:37.820]   Hotels.com, Orbitz, Travelocity, Ork.
[00:28:37.820 --> 00:28:39.340]   And I think the most interesting one,
[00:28:39.340 --> 00:28:40.460]   Freeberg, you and I were talking about,
[00:28:40.460 --> 00:28:43.100]   this is VRBO, vacation rental by owner.
[00:28:43.100 --> 00:28:46.980]   It was like Airbnb before Airbnb existed.
[00:28:46.980 --> 00:28:49.180]   And if you look at this chart,
[00:28:49.180 --> 00:28:51.860]   since Dara left, the Dara effect,
[00:28:51.860 --> 00:28:54.700]   Expedia has gone exactly sideways.
[00:28:54.700 --> 00:28:56.100]   The revenue has grown modestly.
[00:28:56.100 --> 00:29:00.380]   What do you think of this deal, Chamath?
[00:29:00.380 --> 00:29:01.980]   I'll just go right to you with this one,
[00:29:01.980 --> 00:29:03.220]   since you like to...
[00:29:03.220 --> 00:29:04.140]   - Stupid.
[00:29:04.140 --> 00:29:05.460]   - Stupid, okay.
[00:29:05.460 --> 00:29:07.260]   There you have it, folks.
[00:29:07.260 --> 00:29:09.300]   Reason number one, it's stupid.
[00:29:09.300 --> 00:29:11.140]   And reason number two, it's stupid.
[00:29:11.140 --> 00:29:13.420]   I mean, this is a $20 billion market cap business.
[00:29:13.420 --> 00:29:17.500]   You probably have to pay a control premium of 50%.
[00:29:17.500 --> 00:29:19.260]   So the question is,
[00:29:19.260 --> 00:29:22.060]   if you were going to spend $30 billion today
[00:29:22.060 --> 00:29:25.500]   in the public markets, what would you spend it on?
[00:29:25.500 --> 00:29:27.420]   And I think the most important lens
[00:29:27.420 --> 00:29:30.620]   that you have to use to answer that question is,
[00:29:30.620 --> 00:29:33.420]   what reinforces a moat that I have
[00:29:33.420 --> 00:29:37.860]   while also being inoculated from the risks of AI?
[00:29:37.860 --> 00:29:42.860]   And I cannot think of a more fragile business model
[00:29:42.860 --> 00:29:48.100]   than the UI layer on top of widely available data.
[00:29:48.100 --> 00:29:51.980]   So the problem that Expedia has is the same
[00:29:51.980 --> 00:29:54.660]   that Booking and a bunch of these other folks have,
[00:29:54.660 --> 00:29:57.340]   which is that the principal heartbeat of the company,
[00:29:57.340 --> 00:29:59.740]   flight information and other things,
[00:29:59.740 --> 00:30:02.060]   are licensed to them by third parties.
[00:30:02.060 --> 00:30:04.900]   And so what they are is a UI and a front door.
[00:30:06.020 --> 00:30:08.300]   I think it's way too early in the evolution of AI
[00:30:08.300 --> 00:30:09.460]   to know that that's safe.
[00:30:09.460 --> 00:30:12.060]   And in fact, I think a more reasonable assumption
[00:30:12.060 --> 00:30:14.700]   is that those things are pretty fragile.
[00:30:14.700 --> 00:30:17.940]   And part of what may explain the doldrums of the stock
[00:30:17.940 --> 00:30:20.300]   is that I think people are anticipating a world where,
[00:30:20.300 --> 00:30:21.460]   for example, I don't know if you saw,
[00:30:21.460 --> 00:30:24.460]   but Perplexity launched something this week.
[00:30:24.460 --> 00:30:26.340]   It's just in test mode.
[00:30:26.340 --> 00:30:27.620]   They whitelisted me into it,
[00:30:27.620 --> 00:30:31.300]   but it's basically a checkout concept.
[00:30:31.300 --> 00:30:35.140]   So you tell Perplexity what you would like it to buy,
[00:30:35.140 --> 00:30:38.180]   and then it will go and complete the transaction for you.
[00:30:38.180 --> 00:30:41.060]   So in the example of flight bookings,
[00:30:41.060 --> 00:30:43.260]   you could go directly to United
[00:30:43.260 --> 00:30:46.980]   because A, Perplexity will just show you all of the flights.
[00:30:46.980 --> 00:30:49.180]   They'll show you the exact prices.
[00:30:49.180 --> 00:30:50.940]   And then it'll go and execute that for you
[00:30:50.940 --> 00:30:52.780]   with your payment method.
[00:30:52.780 --> 00:30:54.940]   In a world that looks like that,
[00:30:54.940 --> 00:30:57.700]   where these companies have the money
[00:30:57.700 --> 00:30:59.640]   to pay for the data feeds,
[00:30:59.640 --> 00:31:05.060]   the existing V1.0 generation UIs, I think, are in trouble.
[00:31:05.060 --> 00:31:08.940]   So it would just be a very bad capital allocation decision.
[00:31:08.940 --> 00:31:11.700]   Now, that's okay to get things wrong,
[00:31:11.700 --> 00:31:13.540]   but not for $30 billion wrong.
[00:31:13.540 --> 00:31:16.380]   You can probably do it for a couple hundred million dollars
[00:31:16.380 --> 00:31:18.260]   wrong, or maybe even a billion dollars wrong,
[00:31:18.260 --> 00:31:19.620]   'cause you can absorb that
[00:31:19.620 --> 00:31:22.380]   as a 150 or $60 billion company,
[00:31:22.380 --> 00:31:24.480]   but 30 billion is too big of a price to pay
[00:31:24.480 --> 00:31:25.760]   for that kind of risk.
[00:31:25.760 --> 00:31:26.600]   - I would agree with you,
[00:31:26.600 --> 00:31:27.940]   and there's other things they could buy,
[00:31:27.940 --> 00:31:32.020]   like WeRide or Pony AI and a bunch of these AI companies
[00:31:32.020 --> 00:31:33.020]   that are doing self-driving,
[00:31:33.020 --> 00:31:35.020]   so why not double down on that?
[00:31:35.020 --> 00:31:36.740]   Freeberg, the one thing you and I talked about
[00:31:36.740 --> 00:31:40.020]   was kind of VRBO, which is a very cool marketplace,
[00:31:40.020 --> 00:31:43.700]   and that feels directly in the Uber kill zone.
[00:31:43.700 --> 00:31:45.460]   What do you think about them just maybe carving out
[00:31:45.460 --> 00:31:48.940]   and buying VRBO and having an Airbnb contemporary?
[00:31:48.940 --> 00:31:50.140]   - Wait, why don't they just buy Waymo?
[00:31:50.140 --> 00:31:51.240]   Why don't they just go to Google
[00:31:51.240 --> 00:31:53.340]   and give them $30 billion of Uber stock
[00:31:53.340 --> 00:31:54.860]   and just carve in Waymo?
[00:31:54.860 --> 00:31:55.700]   Isn't that a better idea?
[00:31:55.700 --> 00:31:57.220]   - I think that's what's gonna happen.
[00:31:57.220 --> 00:31:59.740]   I've been hearing rumblings of that, so.
[00:31:59.740 --> 00:32:03.620]   - So I think that Dara knows Expedia better than anyone.
[00:32:03.620 --> 00:32:07.380]   He ran the business for, what, a decade or so?
[00:32:07.380 --> 00:32:08.220]   - Yep.
[00:32:08.220 --> 00:32:10.760]   - And so he knows how that business operates.
[00:32:10.760 --> 00:32:13.420]   And so if he's looking at this thing,
[00:32:13.420 --> 00:32:15.540]   and the stock price has been flat, roughly,
[00:32:15.540 --> 00:32:18.520]   since he left in 2017,
[00:32:18.520 --> 00:32:20.980]   if you look at the underlying financial performance,
[00:32:20.980 --> 00:32:23.180]   you could kind of start to construct a rationale
[00:32:23.180 --> 00:32:25.420]   for buying Expedia this cheap,
[00:32:25.420 --> 00:32:27.620]   and it would be very accretive to Uber,
[00:32:27.620 --> 00:32:31.860]   even if there are these big strategic risks on the horizon.
[00:32:31.860 --> 00:32:34.300]   So just to give you some numbers on it all,
[00:32:34.300 --> 00:32:38.260]   Uber's got about 150 million monthly active users.
[00:32:38.260 --> 00:32:43.100]   Expedia has about 45, 50 million customers a year
[00:32:43.100 --> 00:32:45.860]   that use the service and pay for stuff.
[00:32:45.860 --> 00:32:49.300]   So there's a real opportunity to think about
[00:32:49.300 --> 00:32:52.940]   the Uber customer base that's installed
[00:32:52.940 --> 00:32:56.060]   as being almost an opportunity to market to them
[00:32:56.060 --> 00:32:58.500]   Expedia services and cross-sell.
[00:32:58.500 --> 00:33:01.300]   So Expedia, on an annualized basis,
[00:33:01.300 --> 00:33:03.420]   is spending about eight billion a year
[00:33:03.420 --> 00:33:04.780]   in sales and marketing,
[00:33:04.780 --> 00:33:08.660]   and about 720 million a year in G&A costs.
[00:33:08.660 --> 00:33:12.580]   And they're running about three billion EBITDA right now,
[00:33:12.580 --> 00:33:13.460]   run rate.
[00:33:13.460 --> 00:33:16.260]   So if you cut about half the G&A in an acquisition,
[00:33:16.260 --> 00:33:17.340]   'cause you don't need all the people
[00:33:17.340 --> 00:33:19.060]   that overlap with Uber's people,
[00:33:19.060 --> 00:33:22.660]   and you cut about 30% of the sales and marketing dollars
[00:33:22.660 --> 00:33:25.980]   because you can cross-sell into the Uber install base,
[00:33:25.980 --> 00:33:27.460]   you could see a scenario
[00:33:27.460 --> 00:33:30.860]   where you could increase Expedia's EBITDA
[00:33:30.860 --> 00:33:35.020]   by 75 to 100%, maybe getting it as high as $6 billion.
[00:33:35.020 --> 00:33:37.700]   And while Expedia's market cap trades at 20 billion,
[00:33:37.700 --> 00:33:40.100]   this is off of obviously the recent news
[00:33:40.100 --> 00:33:41.580]   that they might get acquired.
[00:33:41.580 --> 00:33:44.140]   If you kind of assume a 40, 50% price premium
[00:33:44.140 --> 00:33:46.020]   to the last 90-day average of the stock price,
[00:33:46.020 --> 00:33:48.980]   which is kind of typical or common for a deal like this,
[00:33:48.980 --> 00:33:51.940]   they're probably paying 26 billion for the company.
[00:33:51.940 --> 00:33:53.620]   And they got about four billion in net cash.
[00:33:53.620 --> 00:33:57.420]   So you're kind of paying about 22 billion enterprise value
[00:33:57.420 --> 00:33:58.940]   to buy Expedia.
[00:33:58.940 --> 00:34:01.100]   So 22 billion of enterprise value,
[00:34:01.100 --> 00:34:05.140]   and if you can bump the EBITDA up to six billion a year,
[00:34:05.140 --> 00:34:06.580]   that's a pretty low multiple.
[00:34:06.580 --> 00:34:09.180]   I mean, you could kind of see yourself rationalizing this
[00:34:09.180 --> 00:34:10.420]   just from a financial basis
[00:34:10.420 --> 00:34:13.180]   that you're paying four times EBITDA to buy this thing.
[00:34:13.180 --> 00:34:14.420]   And Dara knows this thing,
[00:34:14.420 --> 00:34:15.860]   and he would have great command
[00:34:15.860 --> 00:34:17.900]   over what needs to be done over there,
[00:34:17.900 --> 00:34:21.500]   and he would have a great sense of what to change
[00:34:21.500 --> 00:34:23.220]   and what's gone wrong.
[00:34:23.220 --> 00:34:25.740]   And there's a lot of interesting assets inside of Expedia.
[00:34:25.740 --> 00:34:28.020]   VRBO is a great one that's been under-monetized
[00:34:28.020 --> 00:34:28.860]   and underutilized.
[00:34:28.860 --> 00:34:31.940]   I don't know if you've used the UX on VRBO versus Airbnb.
[00:34:31.940 --> 00:34:33.780]   There's obviously some influence Dara could have
[00:34:33.780 --> 00:34:35.620]   with people that he knows well
[00:34:35.620 --> 00:34:37.580]   that could go in and fix that interface
[00:34:37.580 --> 00:34:39.380]   and make it a better service.
[00:34:39.380 --> 00:34:41.540]   And even as AI starts to step in
[00:34:41.540 --> 00:34:44.740]   and hotels maybe integrate better with agents and so on,
[00:34:44.740 --> 00:34:46.380]   and they show up in a more ubiquitous way,
[00:34:46.380 --> 00:34:47.940]   there's other things that Expedia does
[00:34:47.940 --> 00:34:50.180]   like build vacation packages and travel packages
[00:34:50.180 --> 00:34:52.740]   that are high margin products that they sell
[00:34:52.740 --> 00:34:54.620]   that are a little bit different than what you're used to
[00:34:54.620 --> 00:34:56.060]   with just booking a flight.
[00:34:56.060 --> 00:34:58.260]   Booking flights makes no money for anyone,
[00:34:58.260 --> 00:35:00.940]   but vacation packages is where all the money's at.
[00:35:00.940 --> 00:35:03.420]   And so theoretically, Expedia could be smarter
[00:35:03.420 --> 00:35:05.260]   about how they build vacation packages
[00:35:05.260 --> 00:35:07.220]   and personalize them for families,
[00:35:07.220 --> 00:35:08.780]   and that's where they can make real margin,
[00:35:08.780 --> 00:35:10.540]   like 20, 30% margin.
[00:35:10.540 --> 00:35:13.220]   So I could see a story where this all starts to click
[00:35:13.220 --> 00:35:15.300]   for the board at Uber saying, "Maybe it makes sense.
[00:35:15.300 --> 00:35:16.500]   "Dara knows what he's talking about.
[00:35:16.500 --> 00:35:19.940]   "We could buy this thing for four times pro forma EBITDA.
[00:35:19.940 --> 00:35:22.580]   "This could be hugely accretive for us."
[00:35:22.580 --> 00:35:23.980]   So I think that's why this is happening,
[00:35:23.980 --> 00:35:25.460]   why this conversation may be happening.
[00:35:25.460 --> 00:35:26.660]   That's just me trying to understand--
[00:35:26.660 --> 00:35:27.500]   - I think it's a good steal, Nate.
[00:35:27.500 --> 00:35:28.860]   - You know, what the rationale might be.
[00:35:28.860 --> 00:35:30.740]   - Can you just go back and explain
[00:35:30.740 --> 00:35:32.780]   how would they drive up EBITDA so much?
[00:35:32.780 --> 00:35:36.500]   - So they're spending about 8 billion a year run rate
[00:35:36.500 --> 00:35:38.900]   on sales and marketing at Expedia right now,
[00:35:38.900 --> 00:35:42.140]   and Uber's got 150 million active installed users
[00:35:42.140 --> 00:35:44.380]   that are using the Uber services every month.
[00:35:44.380 --> 00:35:45.220]   - Customers. - So the idea would be--
[00:35:45.220 --> 00:35:46.060]   - Actually-- - Customers, yeah.
[00:35:46.060 --> 00:35:47.900]   - Yeah, beyond users. - Actually paying customers.
[00:35:47.900 --> 00:35:52.180]   So if Uber could cross-sell some number of Expedia services
[00:35:52.180 --> 00:35:53.860]   to their installed base at Uber,
[00:35:53.860 --> 00:35:56.140]   which they could test and do a little experiment
[00:35:56.140 --> 00:35:57.740]   and see if it works,
[00:35:57.740 --> 00:35:59.740]   they may be able to reduce the marketing dollars
[00:35:59.740 --> 00:36:01.660]   that Expedia is spending to acquire customers
[00:36:01.660 --> 00:36:03.060]   through other third-party sources
[00:36:03.060 --> 00:36:06.020]   like Google and Bing and other places.
[00:36:06.020 --> 00:36:07.700]   So there's a rationale--
[00:36:07.700 --> 00:36:09.420]   - That's where I think the logic breaks down.
[00:36:09.420 --> 00:36:12.820]   I don't think Uber customers wanna be cross-sold
[00:36:12.820 --> 00:36:14.220]   on booking a hotel.
[00:36:14.220 --> 00:36:16.180]   See, this is where I think MBA thinking
[00:36:16.180 --> 00:36:18.140]   is very different than product thinking.
[00:36:18.140 --> 00:36:20.340]   Like an MBA looking at this would say,
[00:36:20.340 --> 00:36:25.340]   "Well, Expedia and Uber are both in the travel business.
[00:36:25.340 --> 00:36:27.500]   Their apps both involve booking trips,
[00:36:27.500 --> 00:36:31.860]   so we can cross-sell Expedia from Uber
[00:36:31.860 --> 00:36:35.020]   and then cut Expedia's marketing budget."
[00:36:35.020 --> 00:36:38.500]   I think that's how an MBA would sort of hand-wave over it.
[00:36:38.500 --> 00:36:40.460]   I think the way like a product manager would look at this
[00:36:40.460 --> 00:36:43.140]   is to say, "What does the user wanna do?"
[00:36:43.140 --> 00:36:45.020]   And I know that when I use the Uber app,
[00:36:45.020 --> 00:36:47.580]   I just wanna basically make a couple of clicks,
[00:36:47.580 --> 00:36:49.580]   set my destination, get my car,
[00:36:49.580 --> 00:36:51.140]   and then move on.
[00:36:51.140 --> 00:36:54.540]   And there was a product initiative a few years back at Uber
[00:36:54.540 --> 00:36:57.500]   where they tried to capture the user's attention
[00:36:57.500 --> 00:36:58.900]   during the ride.
[00:36:58.900 --> 00:37:00.140]   And they, you know, they added--
[00:37:00.140 --> 00:37:00.980]   - That's right.
[00:37:00.980 --> 00:37:01.820]   Yeah, they had that whole ad thing.
[00:37:01.820 --> 00:37:04.420]   That ad's making a ton of money.
[00:37:04.420 --> 00:37:06.020]   It's actually printing money for them.
[00:37:06.020 --> 00:37:07.660]   - It was like an entertainment stream
[00:37:07.660 --> 00:37:09.540]   or something inside the app.
[00:37:09.540 --> 00:37:11.060]   No, but they dialed it way back
[00:37:11.060 --> 00:37:12.580]   because I don't see it anymore.
[00:37:12.580 --> 00:37:13.700]   It was just clutter.
[00:37:13.700 --> 00:37:15.820]   - Would you trust Dara's judgment on this, Sax?
[00:37:15.820 --> 00:37:18.180]   Like if Dara were to think about
[00:37:18.180 --> 00:37:19.620]   what the Uber user would want
[00:37:19.620 --> 00:37:22.100]   and he could rationalize some percentage of them,
[00:37:22.100 --> 00:37:24.380]   they could cross-sell Expedia services into.
[00:37:24.380 --> 00:37:27.140]   I mean, ultimately, I think it's his decision, right?
[00:37:27.140 --> 00:37:27.980]   Like if he believes-- - Well, I mean,
[00:37:27.980 --> 00:37:30.820]   what you're describing is basically a private equity play.
[00:37:30.820 --> 00:37:32.980]   Like Dara's gonna come in
[00:37:32.980 --> 00:37:35.580]   as like a private equity buyer effectively
[00:37:35.580 --> 00:37:37.300]   and he knows the business
[00:37:37.300 --> 00:37:39.900]   and will run it to reduce costs, maybe boost some revenue.
[00:37:39.900 --> 00:37:41.420]   And maybe there is a justification for that.
[00:37:41.420 --> 00:37:44.900]   But if you're trying to justify it based on cross-selling,
[00:37:44.900 --> 00:37:47.660]   I don't think users of the Uber app wanna be cross-sold
[00:37:47.660 --> 00:37:49.940]   when they book a taxi, okay?
[00:37:49.940 --> 00:37:52.540]   They just wanna be able to affect their transaction
[00:37:52.540 --> 00:37:54.300]   as efficiently as possible.
[00:37:54.300 --> 00:37:56.020]   And just to finish the point I was making
[00:37:56.020 --> 00:37:58.340]   on that whole entertainment stream that they had,
[00:37:58.340 --> 00:37:59.900]   they dialed that product way back
[00:37:59.900 --> 00:38:01.180]   'cause it got in the way.
[00:38:01.180 --> 00:38:03.340]   You'd be in the Uber app trying to figure out
[00:38:03.340 --> 00:38:05.220]   how to change your destination or something
[00:38:05.220 --> 00:38:07.140]   and all of a sudden you're being shown
[00:38:07.140 --> 00:38:08.660]   like some entertainment product.
[00:38:08.660 --> 00:38:10.180]   It's not what users wanted.
[00:38:10.180 --> 00:38:15.020]   And it was always kind of a banana's idea
[00:38:15.020 --> 00:38:20.020]   to think that just because the user books an Uber
[00:38:20.020 --> 00:38:22.620]   that you own their attention during that ride
[00:38:22.620 --> 00:38:24.100]   because during that ride,
[00:38:24.100 --> 00:38:27.260]   you're really competing with every app on the iPhone, right?
[00:38:27.260 --> 00:38:28.900]   I mean, and that's the problem
[00:38:28.900 --> 00:38:31.020]   is you wanna get in and out of the Uber app.
[00:38:31.020 --> 00:38:32.380]   It's about transacting efficiently.
[00:38:32.380 --> 00:38:35.820]   - What about not the moment when you're riding in an Uber,
[00:38:35.820 --> 00:38:38.460]   but the moment when you say as an Uber user,
[00:38:38.460 --> 00:38:39.780]   hey, I need to book travel.
[00:38:39.780 --> 00:38:41.300]   I gotta go on a vacation to Austin this weekend.
[00:38:41.300 --> 00:38:43.500]   - I'm never gonna think to go on my Uber app for that.
[00:38:43.500 --> 00:38:44.620]   The only time I open--
[00:38:44.620 --> 00:38:45.940]   - But what if they put that feature in there?
[00:38:45.940 --> 00:38:47.860]   What if they had a tab that said book your travel here?
[00:38:47.860 --> 00:38:49.620]   - You know, when I open the Uber app,
[00:38:49.620 --> 00:38:51.620]   when I wanna hail a taxi, that's what,
[00:38:51.620 --> 00:38:53.140]   it's like I'm ready to go.
[00:38:53.140 --> 00:38:54.340]   - There are a large number of people
[00:38:54.340 --> 00:38:57.100]   who maybe don't have an assistant
[00:38:57.100 --> 00:38:59.100]   to book their hotels in advance.
[00:38:59.100 --> 00:38:59.940]   And like--
[00:38:59.940 --> 00:39:02.060]   - That would be most people, J.Kell.
[00:39:02.060 --> 00:39:04.340]   - I would not think to go into Uber to do that.
[00:39:04.340 --> 00:39:05.300]   It would just be clutter.
[00:39:05.300 --> 00:39:08.420]   - Well, no, but they already have a hotels.com partnership.
[00:39:08.420 --> 00:39:09.900]   And then the Uber One membership's
[00:39:09.900 --> 00:39:10.900]   been growing pretty nicely.
[00:39:10.900 --> 00:39:13.020]   And the advertising is doing a billion dollars a year.
[00:39:13.020 --> 00:39:14.900]   And that is just a money printing machine
[00:39:14.900 --> 00:39:17.780]   because you know that this person's in an Uber black,
[00:39:17.780 --> 00:39:19.580]   you know that they're going to the Four Seasons,
[00:39:19.580 --> 00:39:22.460]   like these users who are, you know.
[00:39:22.460 --> 00:39:23.980]   - They have a real ad business at Uber.
[00:39:23.980 --> 00:39:24.820]   - Yeah, yeah.
[00:39:24.820 --> 00:39:29.060]   - The more Uber tries to promote some unrelated product,
[00:39:29.060 --> 00:39:31.140]   and what I mean by unrelated is it doesn't help you
[00:39:31.140 --> 00:39:33.540]   get to where you're going at that moment,
[00:39:33.540 --> 00:39:34.780]   it's clutter in the app.
[00:39:34.780 --> 00:39:36.220]   - What about Uber Eats, Zacks?
[00:39:36.220 --> 00:39:37.060]   - Yeah.
[00:39:37.060 --> 00:39:37.900]   - Uber Eats is working pretty well.
[00:39:37.900 --> 00:39:38.740]   - It's working great, yeah.
[00:39:38.740 --> 00:39:40.300]   I know the cross promotion's working.
[00:39:40.300 --> 00:39:41.900]   - That is highly related to,
[00:39:41.900 --> 00:39:43.980]   it's basically booking a car to pick up some food.
[00:39:43.980 --> 00:39:44.940]   - Yeah.
[00:39:44.940 --> 00:39:46.780]   - It's still the taxi business, basically.
[00:39:46.780 --> 00:39:49.700]   - I think the hotels integration is good.
[00:39:49.700 --> 00:39:50.820]   - I think there's something here.
[00:39:50.820 --> 00:39:54.660]   We have gone through a cycle where apps and attention
[00:39:54.660 --> 00:39:56.820]   were highly consolidated with a few.
[00:39:56.820 --> 00:39:58.900]   Now the pendulum has swung the other way,
[00:39:58.900 --> 00:40:02.780]   and apps are very narrow features
[00:40:02.780 --> 00:40:04.580]   that are really well described.
[00:40:04.580 --> 00:40:05.860]   Okay, so that's sort of where we are.
[00:40:05.860 --> 00:40:08.620]   That's why we have the billions and billions of apps
[00:40:08.620 --> 00:40:09.500]   in the app store.
[00:40:10.420 --> 00:40:12.340]   The question is, does the pendulum swing back
[00:40:12.340 --> 00:40:13.700]   to these super apps?
[00:40:13.700 --> 00:40:16.140]   And I think the big question is not whether it swings back
[00:40:16.140 --> 00:40:19.180]   to the super apps, but whether there's a new substrate
[00:40:19.180 --> 00:40:23.180]   that puts itself between the user and all of these services
[00:40:23.180 --> 00:40:26.140]   so that they become data oriented services.
[00:40:26.140 --> 00:40:27.580]   And this is where the question is,
[00:40:27.580 --> 00:40:29.980]   if you rely on an agent,
[00:40:29.980 --> 00:40:34.060]   or you rely on a beefed up version of search,
[00:40:34.060 --> 00:40:37.780]   whether that's ChatGPT or Gemini or whatever,
[00:40:37.780 --> 00:40:41.540]   why would you care where all of this stuff was done?
[00:40:41.540 --> 00:40:43.020]   You're not gonna care.
[00:40:43.020 --> 00:40:45.820]   And this is, I think, the big mistake in this thinking
[00:40:45.820 --> 00:40:49.900]   is that that real estate is actually much more fragile
[00:40:49.900 --> 00:40:52.500]   than I think we all think it is.
[00:40:52.500 --> 00:40:54.500]   And I think a much better way to think about this
[00:40:54.500 --> 00:40:57.140]   is in the future, none of this UI real estate
[00:40:57.140 --> 00:40:59.140]   is actually worth anything.
[00:40:59.140 --> 00:41:01.660]   The question is, do you have a data asset that's valuable,
[00:41:01.660 --> 00:41:03.700]   or do you do a service that's valuable?
[00:41:03.700 --> 00:41:06.460]   Because agentically, there'll be all of these
[00:41:06.460 --> 00:41:10.420]   unemotional bots and workflows doing this work for you.
[00:41:10.420 --> 00:41:12.740]   So I think Saks is right in the sense that
[00:41:12.740 --> 00:41:15.220]   whether it's there or not, it won't matter.
[00:41:15.220 --> 00:41:17.660]   Could he run it like a private equity business
[00:41:17.660 --> 00:41:21.340]   where now Uber Corporation owns two services?
[00:41:21.340 --> 00:41:24.900]   Sure, but you're probably just better off
[00:41:24.900 --> 00:41:28.140]   for these agents to go and cannibalize all of search
[00:41:28.140 --> 00:41:30.220]   because you'll be able to just get a data feed
[00:41:30.220 --> 00:41:32.780]   for what Expedia has to create Expedia
[00:41:32.780 --> 00:41:35.420]   for a few million dollars or tens of millions of dollars.
[00:41:35.420 --> 00:41:38.540]   You don't need to pay 20 or $30 billion for this.
[00:41:38.540 --> 00:41:41.540]   - Yeah, the thing that I've talked to Dara about
[00:41:41.540 --> 00:41:43.780]   is when they said, he told me when they do something
[00:41:43.780 --> 00:41:45.740]   that's adjacent to what they're already doing,
[00:41:45.740 --> 00:41:47.860]   it explodes in terms of engagement.
[00:41:47.860 --> 00:41:51.740]   So like they're doing like teens and rental cars
[00:41:51.740 --> 00:41:53.020]   and then package delivery.
[00:41:53.020 --> 00:41:55.660]   And every time they do one of those adjacencies,
[00:41:55.660 --> 00:41:57.460]   it just takes off with the membership.
[00:41:57.460 --> 00:41:59.580]   And to your point, Freeberg,
[00:41:59.580 --> 00:42:01.740]   they have those 150 customers
[00:42:01.740 --> 00:42:03.380]   who have their credit cards in there
[00:42:03.380 --> 00:42:05.260]   and man, it's just, it's explosive.
[00:42:05.260 --> 00:42:06.100]   So that's what I think they're doing.
[00:42:06.100 --> 00:42:07.340]   - I don't think booking a vacation
[00:42:07.340 --> 00:42:09.660]   is an adjacency to ordering food.
[00:42:09.660 --> 00:42:12.500]   - I think hotels would be, I don't think flights would be
[00:42:12.500 --> 00:42:14.500]   'cause I think the flights work really well
[00:42:14.500 --> 00:42:15.340]   with the existing apps,
[00:42:15.340 --> 00:42:17.340]   but things where you have proprietary inventory
[00:42:17.340 --> 00:42:20.860]   like VRBO or hotels, I think those would be very powerful.
[00:42:20.860 --> 00:42:22.740]   And those have 20, 30% commissions,
[00:42:22.740 --> 00:42:25.460]   which are in line with the commissions
[00:42:25.460 --> 00:42:27.700]   that Uber's already getting.
[00:42:27.700 --> 00:42:30.420]   And the commissions on things like flights is very small,
[00:42:30.420 --> 00:42:31.460]   like a couple of dollars.
[00:42:31.460 --> 00:42:33.860]   So I think for hotels and VRBO would be brilliant.
[00:42:33.860 --> 00:42:35.300]   For the other stuff, I'm not so sure.
[00:42:35.300 --> 00:42:37.260]   To your point, Chamath.
[00:42:37.260 --> 00:42:41.020]   - Well, just to finish, my thought was that
[00:42:41.020 --> 00:42:44.380]   you'll notice that Uber Eats is a separate app from Uber.
[00:42:44.380 --> 00:42:46.460]   I mean, I know you can get to the Eats part within Uber,
[00:42:46.460 --> 00:42:49.020]   but they created a separate app for a reason.
[00:42:49.020 --> 00:42:51.540]   It's because whether you're using Uber Eats or Uber,
[00:42:51.540 --> 00:42:53.380]   the goal is immediate gratification.
[00:42:53.380 --> 00:42:54.580]   I wanna get to where I'm going.
[00:42:54.580 --> 00:42:57.020]   I don't book it six hours in advance.
[00:42:57.020 --> 00:42:58.740]   I call it right now.
[00:42:58.740 --> 00:43:00.660]   And the most important thing to me is wait time.
[00:43:00.660 --> 00:43:02.340]   This is why Uber is beating Lyft,
[00:43:02.340 --> 00:43:04.820]   is the wait time is lower.
[00:43:04.820 --> 00:43:05.660]   Same thing with food.
[00:43:05.660 --> 00:43:07.860]   I'm not thinking about booking my dinner right now.
[00:43:07.860 --> 00:43:09.300]   I'm not gonna do it in advance.
[00:43:09.300 --> 00:43:10.660]   If you browse through the restaurants,
[00:43:10.660 --> 00:43:13.180]   the most important piece of data they show you,
[00:43:13.180 --> 00:43:14.260]   in addition to the rating,
[00:43:14.260 --> 00:43:17.420]   is the number of minutes it takes for it to get to you.
[00:43:17.420 --> 00:43:20.660]   So those apps are all about immediate gratification.
[00:43:20.660 --> 00:43:22.540]   And that's why you don't want other things
[00:43:22.540 --> 00:43:24.540]   getting in the way of them.
[00:43:24.540 --> 00:43:26.620]   Now, I guess the claim is somehow
[00:43:26.620 --> 00:43:28.380]   you're gonna be able to cross-sell
[00:43:28.380 --> 00:43:31.180]   the booking of a vacation or a hotel
[00:43:31.180 --> 00:43:33.780]   that you have to think about days or weeks in advance.
[00:43:33.780 --> 00:43:35.460]   This is a completely different state of mind.
[00:43:35.460 --> 00:43:37.580]   I just don't think that there's
[00:43:37.580 --> 00:43:39.780]   much opportunity to cross-sell that.
[00:43:39.780 --> 00:43:41.980]   Or to use the technical jargon,
[00:43:41.980 --> 00:43:45.340]   I don't think the attach rate is gonna be high.
[00:43:45.340 --> 00:43:47.180]   - What about the brand value, Sat?
[00:43:47.180 --> 00:43:49.500]   'Cause you know those people are going to another app
[00:43:49.500 --> 00:43:51.380]   to book their flight and their hotel.
[00:43:51.380 --> 00:43:53.700]   What if that other app was called Uber Travel?
[00:43:53.700 --> 00:43:54.860]   - There might be some value in that.
[00:43:54.860 --> 00:43:55.700]   I can see that.
[00:43:56.700 --> 00:43:58.300]   I think that would be the rationale
[00:43:58.300 --> 00:43:59.860]   where I could see the Expedia brand.
[00:43:59.860 --> 00:44:02.900]   - Yeah, so maybe what you could do is take VRBO,
[00:44:02.900 --> 00:44:07.020]   rebrand it as Uber Hotel or Uber Travel,
[00:44:07.020 --> 00:44:07.860]   whatever you want to call it.
[00:44:07.860 --> 00:44:08.700]   - Exactly, exactly.
[00:44:08.700 --> 00:44:12.420]   - And then maybe you could push people to download that app.
[00:44:12.420 --> 00:44:15.420]   - Well, the thing I would, the counter I would give to this--
[00:44:15.420 --> 00:44:18.380]   - You could quantify the value of the installs, right?
[00:44:18.380 --> 00:44:19.380]   - Yeah, exactly.
[00:44:19.380 --> 00:44:20.460]   I mean, well, you could quantify
[00:44:20.460 --> 00:44:22.300]   'cause Expedia's spending on it every year right now.
[00:44:22.300 --> 00:44:24.460]   - I use the BombVoy app to book hotels.
[00:44:24.460 --> 00:44:26.100]   I use United to book my flights.
[00:44:26.100 --> 00:44:29.300]   And I use Uber to do my rides and obviously for eats.
[00:44:29.300 --> 00:44:32.020]   When you are using it, there's a tab up top.
[00:44:32.020 --> 00:44:33.900]   In the UI, it's quite nice in Uber
[00:44:33.900 --> 00:44:35.700]   where it's rides and eats right next to each other.
[00:44:35.700 --> 00:44:36.700]   I could see a third one,
[00:44:36.700 --> 00:44:39.380]   like hotels or travel being right there.
[00:44:39.380 --> 00:44:41.460]   And all of a sudden, yum, yum,
[00:44:41.460 --> 00:44:43.540]   you just get all that inventory right in there.
[00:44:43.540 --> 00:44:46.880]   And I frequently will book my hotel
[00:44:46.880 --> 00:44:50.580]   and I'll book my ride for the next day in advance on Uber.
[00:44:50.580 --> 00:44:51.420]   And I do those things.
[00:44:51.420 --> 00:44:52.900]   And then when I get to my hotel,
[00:44:52.900 --> 00:44:55.140]   I'm ordering food to my room.
[00:44:55.140 --> 00:44:57.440]   So I think this actually could work really well
[00:44:57.440 --> 00:45:00.020]   as a third tab in the app for travel.
[00:45:00.020 --> 00:45:01.260]   And you could actually,
[00:45:01.260 --> 00:45:03.580]   'cause when you use eats in the Uber app,
[00:45:03.580 --> 00:45:06.300]   it's its own tab and it's the exact same experience.
[00:45:06.300 --> 00:45:08.020]   I believe in super apps.
[00:45:08.020 --> 00:45:09.260]   And they just launched a bus
[00:45:09.260 --> 00:45:11.820]   that's like a bus service in New York for 18 bucks
[00:45:11.820 --> 00:45:12.660]   to go to JFK.
[00:45:12.660 --> 00:45:13.480]   That's really awesome.
[00:45:13.480 --> 00:45:14.660]   I think we're a little bit disconnected
[00:45:14.660 --> 00:45:16.300]   'cause we don't book our own travel.
[00:45:16.300 --> 00:45:18.180]   But okay, let's keep moving here.
[00:45:18.180 --> 00:45:19.780]   Down the docket.
[00:45:19.780 --> 00:45:23.700]   All right, this big tech investing in nuclear power
[00:45:23.700 --> 00:45:25.700]   is off to the races, Chema.
[00:45:25.700 --> 00:45:28.020]   Amazon just announced a $500 million investment
[00:45:28.020 --> 00:45:30.700]   in three nuclear power projects.
[00:45:30.700 --> 00:45:33.880]   All of these are focused on SMRs.
[00:45:33.880 --> 00:45:36.740]   Those are the small modular reactors.
[00:45:36.740 --> 00:45:39.140]   Amazon is working with Dominion Energy
[00:45:39.140 --> 00:45:42.060]   to develop a small modular nuclear reactor
[00:45:42.060 --> 00:45:44.580]   near an existing nuclear power plant in Virginia.
[00:45:44.580 --> 00:45:48.100]   In total, Amazon plans to invest 35 billion
[00:45:48.100 --> 00:45:51.340]   in Virginia based data centers by 2040.
[00:45:51.340 --> 00:45:54.140]   And they wanna power these by SMRs.
[00:45:54.140 --> 00:45:55.140]   And this is a big trend.
[00:45:55.140 --> 00:46:00.140]   Google is purchasing energy directly from Kairos Power,
[00:46:00.140 --> 00:46:02.100]   another company building SMRs.
[00:46:02.100 --> 00:46:03.780]   Microsoft, as you heard,
[00:46:03.780 --> 00:46:06.220]   was reviving one of the Three Mile Island
[00:46:06.220 --> 00:46:07.840]   nuclear power plants.
[00:46:07.840 --> 00:46:09.700]   So this is kind of interesting, Chema.
[00:46:09.700 --> 00:46:12.900]   We went from nuclear not being on the table,
[00:46:12.900 --> 00:46:14.060]   everybody being against it,
[00:46:14.060 --> 00:46:18.740]   the Germans shutting down their reactors post-Fukushima.
[00:46:18.740 --> 00:46:22.340]   And now big tech is the customer for these with AI,
[00:46:22.340 --> 00:46:26.180]   and they're putting down very large deposits and payments
[00:46:26.180 --> 00:46:27.100]   to build them in America.
[00:46:27.100 --> 00:46:29.980]   And I haven't heard any opposition.
[00:46:29.980 --> 00:46:31.660]   Maybe you could just speak to it, Chema.
[00:46:31.660 --> 00:46:34.180]   What we've seen here in terms of opposition to these
[00:46:34.180 --> 00:46:38.220]   versus the opportunity, and everybody's writing checks.
[00:46:38.220 --> 00:46:39.620]   - Well, they're not writing checks.
[00:46:39.620 --> 00:46:41.700]   So this is what, I don't wanna be a Debbie Downer here,
[00:46:41.700 --> 00:46:46.700]   but these press releases need to have an asterisk on them.
[00:46:46.980 --> 00:46:48.940]   So in the hierarchy of deals, right,
[00:46:48.940 --> 00:46:50.860]   just to unpack this for a second,
[00:46:50.860 --> 00:46:53.920]   there are deals where you give me X and I give you money.
[00:46:53.920 --> 00:46:56.780]   That's not what this is.
[00:46:56.780 --> 00:47:00.000]   Then if you degrade that kind of deal structure,
[00:47:00.000 --> 00:47:02.020]   in a lot of heavy industry,
[00:47:02.020 --> 00:47:04.060]   you have deals that are called take or pay,
[00:47:04.060 --> 00:47:06.260]   which is there is something that's working
[00:47:06.260 --> 00:47:08.460]   and you need to basically take this
[00:47:08.460 --> 00:47:10.660]   or you need to give me the monetary equivalent
[00:47:10.660 --> 00:47:12.660]   of what I'm selling you.
[00:47:12.660 --> 00:47:13.860]   That's not what this is.
[00:47:15.060 --> 00:47:18.020]   What this is is sort of this conditional obligation
[00:47:18.020 --> 00:47:19.540]   where the beginning of the deal starts
[00:47:19.540 --> 00:47:21.260]   with a very important statement,
[00:47:21.260 --> 00:47:25.940]   which is if it works and if these approvals happen,
[00:47:25.940 --> 00:47:29.060]   and there's a whole bunch of nested ifs,
[00:47:29.060 --> 00:47:31.100]   then payments can happen.
[00:47:31.100 --> 00:47:33.020]   So while these are important deals
[00:47:33.020 --> 00:47:36.900]   because they show that there are potential buyers
[00:47:36.900 --> 00:47:38.020]   at the finish line,
[00:47:38.020 --> 00:47:41.780]   what it doesn't do is solve the two things
[00:47:41.780 --> 00:47:44.860]   that you need to get to the finish line,
[00:47:44.860 --> 00:47:47.980]   which is the actual risk capital
[00:47:47.980 --> 00:47:51.780]   to finish building these things and technically de-risk them,
[00:47:51.780 --> 00:47:54.180]   and then the regulatory approval that you need
[00:47:54.180 --> 00:47:56.260]   to make sure that they're allowed.
[00:47:56.260 --> 00:47:57.900]   So I think that these deals are good.
[00:47:57.900 --> 00:47:59.900]   I think it's a great signaling,
[00:47:59.900 --> 00:48:01.560]   but I think it's important to understand
[00:48:01.560 --> 00:48:02.980]   the nuances of these things.
[00:48:02.980 --> 00:48:06.700]   These are not things where there's money
[00:48:06.700 --> 00:48:08.100]   really trading hands.
[00:48:08.100 --> 00:48:10.140]   And until that you see that,
[00:48:10.140 --> 00:48:12.580]   where irrespective of what happens,
[00:48:12.580 --> 00:48:16.580]   the balance sheet is investing from an Amazon or a Google,
[00:48:16.580 --> 00:48:20.020]   where there's corp dev folks writing $100 million
[00:48:20.020 --> 00:48:22.400]   or billion dollar checks into these companies.
[00:48:22.400 --> 00:48:24.620]   It's not yet quite there.
[00:48:24.620 --> 00:48:26.380]   This is more the step before,
[00:48:26.380 --> 00:48:29.500]   which is sort of, can you create some marketing
[00:48:29.500 --> 00:48:33.220]   and some buzziness to hopefully induce somebody
[00:48:33.220 --> 00:48:36.640]   to then rip in billions of dollars of risk equity capital.
[00:48:36.640 --> 00:48:39.820]   - Freeberg, your thoughts on SMRs
[00:48:39.820 --> 00:48:41.900]   and these customers showing up,
[00:48:41.900 --> 00:48:43.900]   and then I guess you could comment on the nature
[00:48:43.900 --> 00:48:45.940]   of the deal structure here,
[00:48:45.940 --> 00:48:49.560]   because some of them are contingent
[00:48:49.560 --> 00:48:51.460]   on the nuclear power plant turning on.
[00:48:51.460 --> 00:48:53.420]   Some of them do have deposits, is my understanding.
[00:48:53.420 --> 00:48:55.300]   We'll look that up and fact check it.
[00:48:55.300 --> 00:48:57.600]   There could be a range of deals here.
[00:48:57.600 --> 00:49:00.180]   - Yeah, I don't know the nature of the deals.
[00:49:00.180 --> 00:49:03.740]   I did, I think, talk about this a year ago.
[00:49:03.740 --> 00:49:05.700]   It was also like my prediction for the year
[00:49:05.700 --> 00:49:08.000]   was to buy the uranium stocks,
[00:49:08.000 --> 00:49:12.580]   predicated on what I think is a really important point,
[00:49:12.580 --> 00:49:15.780]   which is as GDP per capita grows,
[00:49:15.780 --> 00:49:18.020]   energy consumption per capita grows,
[00:49:18.020 --> 00:49:20.180]   and if you looked at the projections
[00:49:20.180 --> 00:49:24.340]   of GDP per capita in industrialized nations,
[00:49:24.340 --> 00:49:27.120]   there was no way, there is no way,
[00:49:27.120 --> 00:49:29.180]   to meet the energy demand,
[00:49:29.180 --> 00:49:31.900]   and this was even pre all this crazy AI build out,
[00:49:31.900 --> 00:49:34.220]   which is probably part of the GDP growth,
[00:49:34.220 --> 00:49:37.620]   but there is no way to meet the energy demand
[00:49:37.620 --> 00:49:39.560]   without nuclear.
[00:49:39.560 --> 00:49:44.360]   There is not enough solar, geothermal,
[00:49:44.360 --> 00:49:47.620]   or wind build out potential that's happening
[00:49:47.620 --> 00:49:50.260]   that the stop gap measure is going to have to be,
[00:49:50.260 --> 00:49:52.640]   and probably the right long term solution,
[00:49:52.640 --> 00:49:54.720]   is to have a significant amount of base load
[00:49:54.720 --> 00:49:56.200]   come from nuclear,
[00:49:56.200 --> 00:49:59.440]   and so what's the fastest way to do that nuclear build out?
[00:49:59.440 --> 00:50:01.720]   Well, in China, they have the regulatory authority
[00:50:01.720 --> 00:50:05.200]   and the mandate stated they're gonna build 300 gigawatts
[00:50:05.200 --> 00:50:07.800]   with 300 facilities or whatever the number is,
[00:50:07.800 --> 00:50:08.640]   and that's what they're doing,
[00:50:08.640 --> 00:50:12.120]   very large facilities that make a gigawatt of power each.
[00:50:12.120 --> 00:50:13.920]   In the US, it seems that because
[00:50:13.920 --> 00:50:15.640]   of the regulatory structure here,
[00:50:15.640 --> 00:50:17.440]   and the way that utilities are regulated,
[00:50:17.440 --> 00:50:19.520]   and the way that the states have authority
[00:50:19.520 --> 00:50:22.280]   on the environmental laws and all the other things,
[00:50:22.280 --> 00:50:24.460]   that it might be the fastest path
[00:50:24.460 --> 00:50:28.040]   to solving this energy gap problem is SMRs,
[00:50:28.040 --> 00:50:31.280]   and these things produce tens of megawatts,
[00:50:31.280 --> 00:50:34.220]   so again, a gigawatt is 1,000 megawatts,
[00:50:34.220 --> 00:50:37.840]   and we need to kind of probably grow
[00:50:37.840 --> 00:50:40.320]   our energy production in the United States
[00:50:40.320 --> 00:50:45.200]   by several terawatts over the next decade or two,
[00:50:45.200 --> 00:50:48.020]   so this SMR may be the fastest path.
[00:50:48.020 --> 00:50:49.480]   Now, that could change,
[00:50:49.480 --> 00:50:50.560]   meaning we could end up seeing
[00:50:50.560 --> 00:50:52.600]   much larger facilities get built out
[00:50:52.600 --> 00:50:55.600]   if there's regulatory change in the US,
[00:50:55.600 --> 00:50:56.540]   and there's more availability,
[00:50:56.540 --> 00:51:01.320]   but fundamentally, we are going to need to use uranium
[00:51:01.320 --> 00:51:04.740]   to make electricity to meet the demand
[00:51:04.740 --> 00:51:07.140]   of growing the GDP that it seems
[00:51:07.140 --> 00:51:08.600]   we're going to be growing in.
[00:51:08.600 --> 00:51:10.660]   I think this is just such a necessity.
[00:51:10.660 --> 00:51:13.220]   It's great to see the SMRs getting some attention.
[00:51:13.220 --> 00:51:15.020]   I just don't know if they're actually gonna get turned on,
[00:51:15.020 --> 00:51:15.980]   how long it's gonna take,
[00:51:15.980 --> 00:51:19.060]   and I don't know what this election cycle's gonna bring
[00:51:19.060 --> 00:51:20.220]   in terms of regulatory change.
[00:51:20.220 --> 00:51:21.900]   I think we talked about it with several of the candidates
[00:51:21.900 --> 00:51:23.060]   when we were doing the interviews.
[00:51:23.060 --> 00:51:27.300]   - Sax, if we are able to get a bunch of these SMRs
[00:51:27.300 --> 00:51:29.900]   built here in the United States,
[00:51:29.900 --> 00:51:32.080]   maybe if Europe follows suit,
[00:51:32.080 --> 00:51:34.600]   what would this do on a geopolitical basis
[00:51:34.600 --> 00:51:37.240]   into our relationship with the Middle East,
[00:51:37.240 --> 00:51:39.400]   our energy independence,
[00:51:39.400 --> 00:51:44.400]   and, of course, the AI race to general intelligence?
[00:51:44.400 --> 00:51:47.360]   I'll let you take it, whichever direction you wanna go.
[00:51:47.360 --> 00:51:49.640]   - Well, I don't think we're going to
[00:51:49.640 --> 00:51:51.840]   because I don't think anyone wants a nuclear power plant
[00:51:51.840 --> 00:51:52.680]   in their backyard.
[00:51:52.680 --> 00:51:53.760]   It's really simple.
[00:51:53.760 --> 00:51:56.800]   I mean, no matter what the benefits are for AI
[00:51:56.800 --> 00:51:59.800]   or for America's global competitiveness,
[00:51:59.800 --> 00:52:01.560]   I just don't think your typical community
[00:52:01.560 --> 00:52:03.560]   wants a nuclear power plant in their backyard,
[00:52:03.560 --> 00:52:04.940]   and I don't think it matters that much
[00:52:04.940 --> 00:52:06.760]   if it's a small, modular one either.
[00:52:06.760 --> 00:52:09.240]   - So you think they'll get blocked by local communities?
[00:52:09.240 --> 00:52:11.160]   - Yeah, and probably for good reason.
[00:52:11.160 --> 00:52:13.880]   I mean, I don't want a nuclear power plant in my backyard.
[00:52:13.880 --> 00:52:15.280]   Do you?
[00:52:15.280 --> 00:52:17.000]   I feel like this has suddenly become
[00:52:17.000 --> 00:52:18.840]   a little bit of a luxury belief
[00:52:18.840 --> 00:52:21.360]   where liberal elites are always talking about
[00:52:21.360 --> 00:52:23.600]   how we need to have nuclear power now,
[00:52:23.600 --> 00:52:25.120]   but there you know they're not gonna have
[00:52:25.120 --> 00:52:27.280]   a nuclear power plant in their backyard,
[00:52:27.280 --> 00:52:30.000]   so it's easy for all of us to genuflect
[00:52:30.000 --> 00:52:31.320]   about what a great idea this is,
[00:52:31.320 --> 00:52:34.360]   but let's face it, these things are gonna be built
[00:52:34.360 --> 00:52:39.000]   probably in poor or working class communities,
[00:52:39.000 --> 00:52:41.560]   and inevitably there's gonna be some accident.
[00:52:41.560 --> 00:52:42.720]   I mean, you can tell me how safe they are
[00:52:42.720 --> 00:52:43.780]   to your blue in the face.
[00:52:43.780 --> 00:52:45.120]   I don't believe it.
[00:52:45.120 --> 00:52:47.000]   You know, planes aren't supposed to
[00:52:47.000 --> 00:52:49.600]   fall out of the sky either, and it does happen,
[00:52:49.600 --> 00:52:52.080]   and you know, they're gonna set up
[00:52:52.080 --> 00:52:54.040]   one of these power plants somewhere,
[00:52:54.040 --> 00:52:57.600]   and you know, it's probably gonna have a DEI program,
[00:52:57.600 --> 00:52:58.840]   and something's gonna happen.
[00:52:58.840 --> 00:53:01.260]   I mean, something's gonna happen,
[00:53:01.260 --> 00:53:05.400]   and then the fallout is literally gonna fall out
[00:53:05.400 --> 00:53:07.640]   on the people in that poor community,
[00:53:07.640 --> 00:53:09.480]   so I don't think this is gonna happen.
[00:53:09.480 --> 00:53:11.720]   - This show really has a diversity of views, doesn't it?
[00:53:11.720 --> 00:53:12.840]   - Yeah.
[00:53:12.840 --> 00:53:16.920]   Look, this is a perfect example of liberal business elites
[00:53:16.920 --> 00:53:20.320]   demanding something that isn't gonna affect them.
[00:53:20.320 --> 00:53:21.160]   It's not gonna affect them.
[00:53:21.480 --> 00:53:25.960]   - Your take on a non-binary trans lesbian
[00:53:25.960 --> 00:53:27.040]   with purple hair-- - No comment.
[00:53:27.040 --> 00:53:28.700]   Whatever you're saying, no comment.
[00:53:28.700 --> 00:53:32.880]   - Putting a small nuclear reactor
[00:53:32.880 --> 00:53:35.340]   200 miles outside of Austin, Texas, go.
[00:53:35.340 --> 00:53:37.400]   Put your tinfoil hat on, Freeburg.
[00:53:37.400 --> 00:53:39.960]   - Yeah, how close do you want it to your ranch, Cal?
[00:53:39.960 --> 00:53:44.020]   - I mean, I think there's plenty of land
[00:53:44.020 --> 00:53:47.640]   outside of the triangle here in Texas
[00:53:47.640 --> 00:53:49.920]   where there is no density, and you could put one,
[00:53:49.920 --> 00:53:51.360]   and I'd have no problem with there being one
[00:53:51.360 --> 00:53:53.440]   100 miles, 200 miles-- - Who's gonna work there?
[00:53:53.440 --> 00:53:54.800]   Who's gonna service it?
[00:53:54.800 --> 00:53:57.360]   - I mean, literally, you would have to,
[00:53:57.360 --> 00:54:00.960]   it doesn't take that many people to service these, so yeah.
[00:54:00.960 --> 00:54:01.800]   - Until something goes wrong.
[00:54:01.800 --> 00:54:03.480]   - I think there's plenty of space in the United States
[00:54:03.480 --> 00:54:06.480]   to put these, and maybe, Freeburg, you could talk
[00:54:06.480 --> 00:54:09.680]   and educate us on the safety here.
[00:54:09.680 --> 00:54:11.640]   Do you believe what Sax is saying,
[00:54:11.640 --> 00:54:13.480]   that it's going to have a meltdown,
[00:54:13.480 --> 00:54:16.200]   and he doesn't believe it? - I think Sax's point of view,
[00:54:16.200 --> 00:54:19.520]   to be honest, is the point of view
[00:54:19.520 --> 00:54:22.040]   that will be held by a large number of people
[00:54:22.040 --> 00:54:25.000]   just like they have been with a lot of other--
[00:54:25.000 --> 00:54:26.720]   - Is it the right point of view, though?
[00:54:26.720 --> 00:54:27.800]   Tell us from a science perspective.
[00:54:27.800 --> 00:54:29.600]   - Well, no, no, I don't think it is.
[00:54:29.600 --> 00:54:31.480]   I think that the same argument would have been made
[00:54:31.480 --> 00:54:34.180]   around we shouldn't have airplanes at all
[00:54:34.180 --> 00:54:35.520]   because they can fall from the sky.
[00:54:35.520 --> 00:54:37.640]   We should keep everyone on the ground where they're safe.
[00:54:37.640 --> 00:54:39.120]   Why would you wanna get on an airplane?
[00:54:39.120 --> 00:54:40.960]   Why would you wanna have airplanes flying over your home?
[00:54:40.960 --> 00:54:42.680]   We should all ban airplanes flying over our home.
[00:54:42.680 --> 00:54:43.920]   They could crash in our home.
[00:54:43.920 --> 00:54:45.240]   It's the same sort of argument,
[00:54:45.240 --> 00:54:46.920]   and the reason I'm not gonna argue the point
[00:54:46.920 --> 00:54:49.720]   is 'cause of the point I made earlier,
[00:54:49.720 --> 00:54:52.680]   which is that it ultimately becomes an economic necessity
[00:54:52.680 --> 00:54:55.920]   that for us to meet all of the demands of AI,
[00:54:55.920 --> 00:54:57.240]   all of the demands of industry,
[00:54:57.240 --> 00:54:59.400]   we wanna reindustrialize the United States,
[00:54:59.400 --> 00:55:00.920]   et cetera, et cetera, we need to increase
[00:55:00.920 --> 00:55:04.140]   electricity production capacity on the continent,
[00:55:04.140 --> 00:55:06.800]   and there is no way to generate enough electricity
[00:55:06.800 --> 00:55:10.380]   on this continent fast enough using other means
[00:55:10.380 --> 00:55:12.800]   than there would be if we just got these systems set up.
[00:55:12.800 --> 00:55:16.320]   - So you believe that we'll go through out of necessity?
[00:55:16.320 --> 00:55:17.160]   That's your take.
[00:55:17.160 --> 00:55:18.240]   - I think globally, this is the case,
[00:55:18.240 --> 00:55:19.120]   and we're seeing it in China.
[00:55:19.120 --> 00:55:20.800]   Now, whether the US ends up becoming a Luddite--
[00:55:20.800 --> 00:55:22.800]   - China doesn't have to worry about a NIMBY problem.
[00:55:22.800 --> 00:55:25.140]   The CCP just says, "This is what we're gonna do."
[00:55:25.140 --> 00:55:28.000]   - Yeah, that's right, and we may end up being the--
[00:55:28.000 --> 00:55:29.880]   - China is the M in NIMBY, bye.
[00:55:29.880 --> 00:55:32.740]   - Yeah, and we may end up being the Luddite state,
[00:55:32.740 --> 00:55:33.920]   and we'll end up just saying, "You know what?
[00:55:33.920 --> 00:55:35.500]   "We're not gonna adopt new technology,
[00:55:35.500 --> 00:55:39.480]   "including things like gene editing and cell therapies,"
[00:55:39.480 --> 00:55:41.600]   and I'll go through the list of new technologies,
[00:55:41.600 --> 00:55:43.400]   Seth, you could make the argument
[00:55:43.400 --> 00:55:46.080]   that there's a low probability of a high-risk event,
[00:55:46.080 --> 00:55:49.000]   but the fact is that the progress that it enables
[00:55:49.000 --> 00:55:51.080]   is worth so much more than the risk
[00:55:51.080 --> 00:55:52.480]   that we would be taking on.
[00:55:52.480 --> 00:55:54.120]   - There's a simpler solution to all of this
[00:55:54.120 --> 00:55:57.040]   without having to go and create these reactors,
[00:55:57.040 --> 00:55:59.500]   which is, I don't think that we have a very good grasp
[00:55:59.500 --> 00:56:01.960]   of the material science, broadly speaking.
[00:56:01.960 --> 00:56:03.440]   I don't think we really understand
[00:56:03.440 --> 00:56:05.520]   how to build next-generation materials.
[00:56:05.520 --> 00:56:07.800]   I don't think our specialty chemicals capabilities
[00:56:07.800 --> 00:56:09.440]   are all that strong.
[00:56:09.440 --> 00:56:10.480]   The way that they're going to be
[00:56:10.480 --> 00:56:12.940]   over the next five or 10 years is just with better compute,
[00:56:12.940 --> 00:56:15.760]   so I think that there's gonna be a lot of interim steps
[00:56:15.760 --> 00:56:18.320]   that increase the generally available energy density
[00:56:18.320 --> 00:56:19.960]   without going to nuclear.
[00:56:19.960 --> 00:56:22.040]   I think there's gonna be a lot of businesses to do that.
[00:56:22.040 --> 00:56:24.860]   That'll be much safer, easier to regulate,
[00:56:24.860 --> 00:56:27.800]   easier to test, easier to underwrite,
[00:56:27.800 --> 00:56:29.480]   and I think the government will get behind those,
[00:56:29.480 --> 00:56:31.200]   so I'm not as negative as you are
[00:56:31.200 --> 00:56:32.920]   on the only solution being nuclear.
[00:56:32.920 --> 00:56:35.880]   - The countries and the businesses
[00:56:35.880 --> 00:56:38.360]   that have a lower cost of electricity
[00:56:38.360 --> 00:56:40.360]   and a more abundant source of electricity
[00:56:40.360 --> 00:56:43.400]   will end up winning as the economy continues to progress
[00:56:43.400 --> 00:56:45.280]   towards a much more kind of digital state
[00:56:45.280 --> 00:56:47.840]   and an automated state over the next decades.
[00:56:47.840 --> 00:56:49.640]   So if we're gonna be slower,
[00:56:49.640 --> 00:56:52.060]   we're gonna suffer the consequences of that as a country,
[00:56:52.060 --> 00:56:53.160]   so we'll see how it plays out.
[00:56:53.160 --> 00:56:54.760]   I just think that economic incentives
[00:56:54.760 --> 00:56:56.440]   will ultimately drive, hopefully, a change.
[00:56:56.440 --> 00:57:00.920]   - Would a possible solution be to give an economic incentive
[00:57:00.920 --> 00:57:03.680]   to the people who would be in the surrounding areas?
[00:57:03.680 --> 00:57:05.860]   Obviously, these things could be 50 or 100 miles
[00:57:05.860 --> 00:57:09.440]   from anybody's homes, but even the people who work there
[00:57:09.440 --> 00:57:13.120]   or people who might have, I don't know,
[00:57:13.120 --> 00:57:14.520]   some homes that were near it,
[00:57:14.520 --> 00:57:17.800]   could you give them no taxes, et cetera,
[00:57:17.800 --> 00:57:19.160]   essentially give them incentives
[00:57:19.160 --> 00:57:21.320]   to allow this to go through a free bargain, in your mind?
[00:57:21.320 --> 00:57:23.400]   Do you think that kind of incentive would work?
[00:57:23.400 --> 00:57:28.160]   Taxes or some kind of payoff or subsidy?
[00:57:28.160 --> 00:57:29.000]   - I'm not sure.
[00:57:29.000 --> 00:57:32.040]   I haven't thought much about what the incentives
[00:57:32.040 --> 00:57:32.880]   or subsidies would be.
[00:57:32.880 --> 00:57:33.700]   I think that-- - Yeah, you're gonna have
[00:57:33.700 --> 00:57:35.560]   to give them an incentive, 'cause no one's gonna wanna live
[00:57:35.560 --> 00:57:37.360]   within 200 miles of one of these things.
[00:57:37.360 --> 00:57:38.880]   - What would be the number-- - I think taxes, right.
[00:57:38.880 --> 00:57:43.280]   I think that people have a very deep fear
[00:57:43.280 --> 00:57:46.840]   of what is deemed to be cataclysmic technology.
[00:57:46.840 --> 00:57:48.120]   I do think a lot of this was rooted
[00:57:48.120 --> 00:57:49.360]   in the evolution of the atomic age,
[00:57:49.360 --> 00:57:51.080]   where we basically have these nuclear warheads
[00:57:51.080 --> 00:57:52.640]   mounted to missiles that can travel
[00:57:52.640 --> 00:57:54.840]   at 20 times the speed of sound
[00:57:54.840 --> 00:57:57.440]   and land on your city and wipe out your city.
[00:57:57.440 --> 00:58:00.020]   I mean, that is also nuclear technology,
[00:58:00.020 --> 00:58:02.520]   and people conflate the two as being similar.
[00:58:02.520 --> 00:58:05.120]   And even Three Mile Island, there were no deaths.
[00:58:05.120 --> 00:58:07.520]   It was a shocking, scary thing for people,
[00:58:07.520 --> 00:58:10.640]   but statistically speaking and historically speaking
[00:58:10.640 --> 00:58:13.120]   and technically speaking, it's a lot more complicated
[00:58:13.120 --> 00:58:15.080]   to explain to people what happened and why
[00:58:15.080 --> 00:58:16.460]   and why now it's different.
[00:58:16.460 --> 00:58:17.720]   And no one has the time for that.
[00:58:17.720 --> 00:58:19.160]   No one wants to hear that (beep).
[00:58:19.160 --> 00:58:20.240]   They wanna hear a very simple,
[00:58:20.240 --> 00:58:22.480]   do you really want a nuclear power plant in your backyard?
[00:58:22.480 --> 00:58:23.480]   No way.
[00:58:23.480 --> 00:58:24.320]   What about you?
[00:58:24.320 --> 00:58:25.140]   No way.
[00:58:25.140 --> 00:58:26.720]   All right, let's vote to stop it.
[00:58:26.720 --> 00:58:27.680]   - And they're right.
[00:58:27.680 --> 00:58:32.280]   I mean, you compare it to commercial airlines,
[00:58:32.280 --> 00:58:34.460]   but commercial airlines, that's a technology
[00:58:34.460 --> 00:58:36.160]   that's been around for what, like 100 years?
[00:58:36.160 --> 00:58:38.040]   - Chex, do you have any data on the safety record
[00:58:38.040 --> 00:58:39.120]   of nuclear technology?
[00:58:39.120 --> 00:58:40.040]   'Cause I'm not sure you do.
[00:58:40.040 --> 00:58:41.920]   I think my point is you're just making a statement
[00:58:41.920 --> 00:58:43.080]   out of fear. - Let's see the data.
[00:58:43.080 --> 00:58:44.120]   Where's the data?
[00:58:44.120 --> 00:58:45.080]   - Yeah, let's do it.
[00:58:45.080 --> 00:58:45.920]   Let's do it right now.
[00:58:45.920 --> 00:58:47.560]   I mean, I think this is an important discussion.
[00:58:47.560 --> 00:58:48.400]   I'd like to actually--
[00:58:48.400 --> 00:58:50.120]   - My point about commercial airlines
[00:58:50.120 --> 00:58:52.280]   is we've had that technology for over 100 years.
[00:58:52.280 --> 00:58:55.120]   It was honed and refined over many decades
[00:58:55.120 --> 00:58:58.200]   and commercial airlines now have become--
[00:58:58.200 --> 00:59:00.040]   - Chex, this is going on almost 100,
[00:59:00.040 --> 00:59:02.240]   this is going on 100 years of use, right?
[00:59:02.240 --> 00:59:03.080]   You know that.
[00:59:03.080 --> 00:59:05.320]   - There've been incidents every decade or two
[00:59:05.320 --> 00:59:06.720]   and that is why-- - That's not true.
[00:59:06.720 --> 00:59:07.560]   That's not true.
[00:59:07.560 --> 00:59:09.280]   You're saying something that's not true.
[00:59:09.280 --> 00:59:10.840]   - The reason nuclear has been discredited
[00:59:10.840 --> 00:59:12.600]   is because of Three Mile Island
[00:59:12.600 --> 00:59:14.040]   and Fukushima and-- - First of all,
[00:59:14.040 --> 00:59:15.760]   it's not been discredited. - Chernobyl.
[00:59:15.760 --> 00:59:18.480]   I mean, these names live in infamy.
[00:59:18.480 --> 00:59:21.120]   - It's social fear-mongering like you are doing right now
[00:59:21.120 --> 00:59:22.720]   with no data and no facts
[00:59:22.720 --> 00:59:24.480]   to try and make it a political issue
[00:59:24.480 --> 00:59:26.240]   that drives everyone to one side,
[00:59:26.240 --> 00:59:27.280]   shut their minds down,
[00:59:27.280 --> 00:59:29.640]   and not listen to the actual facts and data.
[00:59:29.640 --> 00:59:31.640]   And this fear-mongering is what keeps us
[00:59:31.640 --> 00:59:32.880]   from being competitive,
[00:59:32.880 --> 00:59:34.720]   what keeps us from having progress.
[00:59:34.720 --> 00:59:37.080]   You talk a lot about people talking shit about Elon.
[00:59:37.080 --> 00:59:40.720]   - Listen, listen, I'm just saying I don't want one near me.
[00:59:40.720 --> 00:59:41.680]   Now, if they're-- - Okay.
[00:59:41.680 --> 00:59:42.520]   - Hold on a second.
[00:59:42.520 --> 00:59:43.360]   I'm not saying you can't-- - Let me get,
[00:59:43.360 --> 00:59:44.600]   there were 46 deaths at Chernobyl.
[00:59:44.600 --> 00:59:46.760]   - I'm not against doing it somewhere
[00:59:46.760 --> 00:59:49.160]   where the community is in favor of doing it.
[00:59:49.160 --> 00:59:52.000]   So if you can find a place that wants to do this,
[00:59:52.000 --> 00:59:54.040]   I would not stop it, just to be clear.
[00:59:54.040 --> 00:59:55.720]   I'm just saying I don't want one near me.
[00:59:55.720 --> 00:59:56.560]   - Let's get to facts.
[00:59:56.560 --> 00:59:58.280]   Yeah, we got you. - Jake, just give me a second.
[00:59:58.280 --> 00:59:59.120]   - Yeah, yeah.
[00:59:59.120 --> 01:00:01.200]   - I don't think you're gonna find many takers,
[01:00:01.200 --> 01:00:02.680]   even among poor communities.
[01:00:02.680 --> 01:00:04.960]   - It's a great adversarial point.
[01:00:04.960 --> 01:00:06.800]   Let's go to the facts. - There's 440
[01:00:06.800 --> 01:00:09.960]   nuclear power reactors operating in 32 countries
[01:00:09.960 --> 01:00:11.080]   around the world.
[01:00:11.080 --> 01:00:13.120]   Since the time that we first had nuclear reactors,
[01:00:13.120 --> 01:00:14.600]   which has now been almost a century,
[01:00:14.600 --> 01:00:16.400]   there have been three incidents,
[01:00:16.400 --> 01:00:18.640]   Chernobyl, Fukushima, and Three Mile Island.
[01:00:18.640 --> 01:00:20.680]   At Three Mile Island, there were zero deaths.
[01:00:20.680 --> 01:00:22.200]   At Fukushima, there was one death,
[01:00:22.200 --> 01:00:24.480]   and at Chernobyl, there were 46 deaths.
[01:00:24.480 --> 01:00:27.480]   The fallout from those events has been
[01:00:27.480 --> 01:00:29.480]   that we shut down energy production,
[01:00:29.480 --> 01:00:31.600]   we shut down nuclear reactor technology,
[01:00:31.600 --> 01:00:33.240]   and we fear-mongered our way
[01:00:33.240 --> 01:00:36.200]   into losing the most abundant, available--
[01:00:36.200 --> 01:00:37.720]   - Can I just ask a question? - Low-cost source of energy.
[01:00:37.720 --> 01:00:38.600]   - Yeah. - Do those deaths
[01:00:38.600 --> 01:00:41.080]   actually include the second and third-order effects
[01:00:41.080 --> 01:00:42.240]   of all this radiation? - At Chernobyl,
[01:00:42.240 --> 01:00:44.280]   there were 15 people who got thyroid cancer,
[01:00:44.280 --> 01:00:48.320]   35 operators and first responders who got radiation sickness,
[01:00:48.320 --> 01:00:50.240]   and then the background radiation effects,
[01:00:50.240 --> 01:00:52.480]   there's a lot of kind of noise around this,
[01:00:52.480 --> 01:00:53.800]   but it's not a significant number
[01:00:53.800 --> 01:00:55.360]   as you may otherwise think.
[01:00:55.360 --> 01:00:56.600]   Same with Fukushima.
[01:00:56.600 --> 01:00:59.120]   - Why is it that whole region is still uninhabited, then?
[01:00:59.120 --> 01:01:00.560]   - They had a radiation event.
[01:01:00.560 --> 01:01:03.360]   There's radioactive material that has covered that area
[01:01:03.360 --> 01:01:05.800]   that will be radioactive for a long period of time.
[01:01:05.800 --> 01:01:08.120]   Now, to understand what happened there
[01:01:08.120 --> 01:01:09.600]   and why that won't happen again
[01:01:09.600 --> 01:01:11.720]   requires talking about the difference in the technology
[01:01:11.720 --> 01:01:15.040]   between Gen 1, Gen 2, Gen 3, and Gen 4 systems.
[01:01:15.040 --> 01:01:16.400]   A lot of what's being rolled out now
[01:01:16.400 --> 01:01:18.360]   are these Gen 3 nuclear reactors,
[01:01:18.360 --> 01:01:19.640]   and the Gen 4 systems,
[01:01:19.640 --> 01:01:21.520]   which we highlighted a little while ago,
[01:01:21.520 --> 01:01:23.640]   do not have a meltdown possibility, right?
[01:01:23.640 --> 01:01:24.800]   We talked about this,
[01:01:24.800 --> 01:01:27.120]   the one that went online in China in December.
[01:01:27.120 --> 01:01:30.560]   Those new systems, the Gen 4 reactors, cannot melt down.
[01:01:30.560 --> 01:01:32.320]   You cannot have an incident like you did
[01:01:32.320 --> 01:01:34.160]   with the Gen 1 and Gen 2 systems.
[01:01:34.160 --> 01:01:36.400]   And the Gen 3 systems are abundantly safe.
[01:01:36.400 --> 01:01:39.040]   China is building hundreds of them.
[01:01:39.040 --> 01:01:42.160]   It is a totally understandable science.
[01:01:42.160 --> 01:01:43.960]   If we want to spend the time looking at the data
[01:01:43.960 --> 01:01:45.280]   and understanding the engineering
[01:01:45.280 --> 01:01:46.680]   and the material science work
[01:01:46.680 --> 01:01:48.320]   and all the effort that's gone in,
[01:01:48.320 --> 01:01:50.160]   billions of dollars over decades,
[01:01:50.160 --> 01:01:52.920]   the biggest stumbling block and the biggest wall
[01:01:52.920 --> 01:01:54.240]   has been the fact that people
[01:01:54.240 --> 01:01:56.320]   have this fear-mongering activity
[01:01:56.320 --> 01:01:58.640]   that they tell people, "Just dismiss it.
[01:01:58.640 --> 01:01:59.880]   "It's too scary.
[01:01:59.880 --> 01:02:01.200]   "We don't want it in our backyard.
[01:02:01.200 --> 01:02:03.360]   "Let's move on to the next opportunity."
[01:02:03.360 --> 01:02:04.480]   That's what's killed it.
[01:02:04.480 --> 01:02:07.440]   - And if you just put these things 50 miles away,
[01:02:07.440 --> 01:02:09.480]   the radiation, even in the meltdowns,
[01:02:09.480 --> 01:02:12.400]   didn't go past those, is my understanding.
[01:02:12.400 --> 01:02:15.000]   So, even if you want to,
[01:02:15.000 --> 01:02:16.400]   just the easiest steel man-
[01:02:16.400 --> 01:02:17.680]   - The new systems don't melt down.
[01:02:17.680 --> 01:02:18.840]   You don't have that possibility.
[01:02:18.840 --> 01:02:20.680]   And the SMRs, I am 100% agreeing with you.
[01:02:20.680 --> 01:02:22.160]   - The new systems don't even work.
[01:02:22.160 --> 01:02:23.840]   These SMRs, they don't work.
[01:02:23.840 --> 01:02:25.960]   - If they're so new, how can you say for sure
[01:02:25.960 --> 01:02:27.480]   what the safety record's gonna be?
[01:02:27.480 --> 01:02:31.000]   - Oh, that's, just to be clear, SMRs don't work yet.
[01:02:31.000 --> 01:02:33.640]   We have theoretical ways in which we can profile
[01:02:33.640 --> 01:02:35.200]   and model that they work,
[01:02:35.200 --> 01:02:36.840]   but we don't have a functional one
[01:02:36.840 --> 01:02:39.240]   that people can look at and inspect.
[01:02:39.240 --> 01:02:42.800]   As part of that, we haven't been able to test how they fail.
[01:02:42.800 --> 01:02:44.440]   Those are also theoretical.
[01:02:44.440 --> 01:02:46.400]   So, I think, let's put SMRs off
[01:02:46.400 --> 01:02:47.680]   and let's just be very accurate.
[01:02:47.680 --> 01:02:50.600]   We don't have a functioning, working version of one
[01:02:50.600 --> 01:02:51.800]   because they don't work yet.
[01:02:51.800 --> 01:02:53.520]   Maybe they'll work in the future.
[01:02:53.520 --> 01:02:54.600]   Let's hope that they do.
[01:02:54.600 --> 01:02:55.440]   - There's about six- - What you're talking
[01:02:55.440 --> 01:02:57.560]   about, Freeberg, is a step before that,
[01:02:57.560 --> 01:02:59.600]   which is the Gen 3 reactor,
[01:02:59.600 --> 01:03:01.400]   which has a different safety- - There are SMRs
[01:03:01.400 --> 01:03:04.200]   operating in China, Russia, and India today,
[01:03:04.200 --> 01:03:07.200]   and there's about 65 being built at this moment, right?
[01:03:07.200 --> 01:03:08.560]   And that's outside the U.S.
[01:03:08.560 --> 01:03:10.920]   So, that's why the U.S. is kind of observing
[01:03:10.920 --> 01:03:12.880]   and trying to catch up and adopt these technologies
[01:03:12.880 --> 01:03:16.040]   that are being used by, call it, economic competitors
[01:03:16.040 --> 01:03:17.880]   and economic partners around the world.
[01:03:17.880 --> 01:03:21.480]   It's important for economic prosperity in the U.S.
[01:03:21.480 --> 01:03:23.120]   for us to have a degree of competitiveness
[01:03:23.120 --> 01:03:24.440]   in electricity prices.
[01:03:24.440 --> 01:03:27.160]   If China races towards 5 cents per kilowatt hour
[01:03:27.160 --> 01:03:29.120]   for electricity, and we're sitting here
[01:03:29.120 --> 01:03:31.200]   at 20 cents a kilowatt hour for electricity,
[01:03:31.200 --> 01:03:33.120]   what's that gonna do to our economic competitiveness?
[01:03:33.120 --> 01:03:35.080]   - We are at 5 cents in the generation.
[01:03:35.080 --> 01:03:37.320]   - And you're saying solar, right?
[01:03:37.320 --> 01:03:38.640]   - We can fix that tomorrow.
[01:03:38.640 --> 01:03:41.280]   We already rely on a nuclear reactor that works,
[01:03:41.280 --> 01:03:43.000]   and to Sax's point, it just happens to be
[01:03:43.000 --> 01:03:45.920]   millions of miles away, so if it goes,
[01:03:45.920 --> 01:03:47.480]   we're all gonna go anyways.
[01:03:47.480 --> 01:03:49.360]   - Yeah, the scalability of solar,
[01:03:49.360 --> 01:03:51.720]   in terms of getting us to a terawatt of production capacity,
[01:03:51.720 --> 01:03:53.480]   is the limiting block to mop that,
[01:03:53.480 --> 01:03:54.560]   in order to get to a terawatt of additional-
[01:03:54.560 --> 01:03:56.440]   - I think that's a material science problem.
[01:03:56.440 --> 01:03:58.080]   I don't think that's, you don't need to run as long-
[01:03:58.080 --> 01:03:59.120]   - Yeah, maybe it's not such a bad thing
[01:03:59.120 --> 01:04:01.400]   that other countries are taking the early adopter risk
[01:04:01.400 --> 01:04:02.240]   with this technology. - Well, I was about to say,
[01:04:02.240 --> 01:04:03.720]   that would be, that's gonna be the forcing-
[01:04:03.720 --> 01:04:05.080]   - This is decades in the making, Sax.
[01:04:05.080 --> 01:04:06.920]   - Yeah, that's gonna be, but if they're,
[01:04:06.920 --> 01:04:08.880]   if China runs away with this,
[01:04:08.880 --> 01:04:10.880]   and they have so many of these running,
[01:04:10.880 --> 01:04:13.000]   and then they're able to power AI
[01:04:13.000 --> 01:04:14.680]   and solve problems we're not,
[01:04:14.680 --> 01:04:15.960]   we're gonna have to get our act together
[01:04:15.960 --> 01:04:17.680]   and start standing these up,
[01:04:17.680 --> 01:04:18.520]   and they just have to be 50- - I don't think power
[01:04:18.520 --> 01:04:20.320]   is the limiting- - Every Navy submarine
[01:04:20.320 --> 01:04:21.560]   has got a nuclear reactor on board.
[01:04:21.560 --> 01:04:23.080]   That's how we get power. - And we have so much space
[01:04:23.120 --> 01:04:26.680]   in this country, these things could be 100, 200 miles away.
[01:04:26.680 --> 01:04:27.520]   - But I don't think energy- - From anybody.
[01:04:27.520 --> 01:04:30.120]   - Is a limiting factor in our ability to innovate.
[01:04:30.120 --> 01:04:32.360]   I don't think it is today.
[01:04:32.360 --> 01:04:33.640]   - In these data centers?
[01:04:33.640 --> 01:04:35.200]   Certainly, it is with these- - It's not the limiting factor
[01:04:35.200 --> 01:04:36.160]   in our ability to innovate.
[01:04:36.160 --> 01:04:39.320]   It's not the limiting factor in, like, for example-
[01:04:39.320 --> 01:04:41.200]   - We're asking us to charge up every car,
[01:04:41.200 --> 01:04:42.880]   every night with electricity, with a battery,
[01:04:42.880 --> 01:04:44.760]   rather than using gasoline. - Let me just make my point.
[01:04:44.760 --> 01:04:47.720]   So we just saw OpenAI launch Strawberry.
[01:04:47.720 --> 01:04:52.080]   Is the reason why Microsoft, or Google,
[01:04:52.080 --> 01:04:56.440]   or Meta not responded with their own version
[01:04:56.440 --> 01:04:57.760]   an energy problem?
[01:04:57.760 --> 01:05:00.760]   No, we're still rate-limited by innovation
[01:05:00.760 --> 01:05:04.160]   and just raw intellectual horsepower and capability.
[01:05:04.160 --> 01:05:07.360]   Meanwhile, we are trying to solve the energy problem,
[01:05:07.360 --> 01:05:10.920]   and people are taking different approaches.
[01:05:10.920 --> 01:05:14.440]   There's storage that's coming online very aggressively.
[01:05:14.440 --> 01:05:18.040]   The solar capability itself is ramping up aggressively.
[01:05:18.040 --> 01:05:19.920]   We're also forcing these utilities
[01:05:19.920 --> 01:05:21.360]   to actually be deconstructed
[01:05:21.360 --> 01:05:23.800]   so that there's more efficiency in the energy markets.
[01:05:23.800 --> 01:05:26.400]   All of this, if you unpack why it costs 20 cents
[01:05:26.400 --> 01:05:29.920]   a kilowatt hour, it's not because of a generation problem.
[01:05:29.920 --> 01:05:31.320]   It is not.
[01:05:31.320 --> 01:05:35.600]   It's graft, it's corruption, it's old legacy infrastructure.
[01:05:35.600 --> 01:05:38.560]   All of it can be replaced in a much simpler and safer way.
[01:05:38.560 --> 01:05:42.640]   So I think by the time that you are rate-limited by energy,
[01:05:42.640 --> 01:05:44.040]   you'll have a plethora of solutions.
[01:05:44.040 --> 01:05:48.160]   My issues with the SMRs is the ones that are promising
[01:05:48.160 --> 01:05:51.840]   these next-gen whiz-bang performance characteristics,
[01:05:51.840 --> 01:05:53.360]   they're all theoretical freebrew.
[01:05:53.360 --> 01:05:55.680]   So even when you say there are SMRs working abroad,
[01:05:55.680 --> 01:05:58.440]   there's no next-generation reactors working abroad.
[01:05:58.440 --> 01:06:00.000]   They don't work.
[01:06:00.000 --> 01:06:02.200]   Where is an example of these modern,
[01:06:02.200 --> 01:06:05.400]   next-generation reactors actually working?
[01:06:05.400 --> 01:06:06.240]   Where?
[01:06:06.240 --> 01:06:07.840]   - Well, we talked about the Gen 4 one
[01:06:07.840 --> 01:06:09.240]   that went live in China.
[01:06:09.240 --> 01:06:11.320]   There's several SMRs in several countries
[01:06:11.320 --> 01:06:13.040]   that are active producing power.
[01:06:13.040 --> 01:06:14.920]   - You can call it a small modular reactor.
[01:06:14.920 --> 01:06:16.640]   What I'm talking about, these next-gen materials,
[01:06:16.640 --> 01:06:18.240]   the things that Kairos and these other guys
[01:06:18.240 --> 01:06:19.080]   are trying to do.
[01:06:19.080 --> 01:06:20.400]   Where is a functioning, working version?
[01:06:20.400 --> 01:06:21.240]   - Here, I'll show you.
[01:06:21.240 --> 01:06:22.080]   They have 'em.
[01:06:22.080 --> 01:06:25.000]   I mean, like, we have one in India, we have one in China.
[01:06:25.000 --> 01:06:27.480]   I'll show you the, I'll send you the links to 'em here.
[01:06:27.480 --> 01:06:28.560]   There's about 50 of 'em
[01:06:28.560 --> 01:06:30.600]   that India's actively building right now.
[01:06:30.600 --> 01:06:33.760]   And they're competitive with Kairos, right?
[01:06:33.760 --> 01:06:35.640]   They all have kind of common design concepts,
[01:06:35.640 --> 01:06:37.680]   but they're different companies.
[01:06:37.680 --> 01:06:38.600]   Anyway, I'm just saying, like,
[01:06:38.600 --> 01:06:40.360]   they're getting rolled out. - What would be the harm,
[01:06:40.360 --> 01:06:42.840]   and just, Freeberg, maybe you can educate us in,
[01:06:42.840 --> 01:06:45.600]   the distance it could be from a city.
[01:06:45.600 --> 01:06:47.880]   Reasonably, in terms of building a grid
[01:06:47.880 --> 01:06:50.200]   to move the energy from,
[01:06:50.200 --> 01:06:52.960]   could it be 200 miles from a major city?
[01:06:52.960 --> 01:06:54.640]   300, 100?
[01:06:54.640 --> 01:06:56.160]   What's the distance? - Hey, put it wherever you want.
[01:06:56.160 --> 01:06:57.800]   You can put power production wherever you want.
[01:06:57.800 --> 01:06:59.080]   - But it has to travel, right? - Just move it through copper.
[01:06:59.080 --> 01:07:00.680]   As long as you got the copper to move it, right?
[01:07:00.680 --> 01:07:02.360]   You move the electrons.
[01:07:02.360 --> 01:07:04.400]   - Yeah, I'm just trying to think reasonably move it
[01:07:04.400 --> 01:07:05.880]   is, I guess, what I was getting at.
[01:07:05.880 --> 01:07:07.880]   But okay, well, there you have it, folks.
[01:07:07.880 --> 01:07:08.720]   A good debate here
[01:07:08.720 --> 01:07:10.280]   on the All In podcast. - A good debate.
[01:07:10.280 --> 01:07:11.120]   A good debate. - I think it's a good debate.
[01:07:11.120 --> 01:07:12.360]   - I still love you all.
[01:07:12.360 --> 01:07:16.800]   - We'll lay copper from some country that has an SMR
[01:07:16.800 --> 01:07:18.240]   all the way to- - That's right.
[01:07:18.240 --> 01:07:19.080]   - All the way to- - You know, it's funny
[01:07:19.080 --> 01:07:20.520]   you said that. - Washington State.
[01:07:20.520 --> 01:07:23.560]   - I was just thinking like if Canada and Mexico have,
[01:07:23.560 --> 01:07:25.360]   you know, economic incentive to do this,
[01:07:25.360 --> 01:07:26.840]   or they're more bold,
[01:07:26.840 --> 01:07:29.160]   maybe they build them in their countries,
[01:07:29.160 --> 01:07:32.040]   and then they'll be selling it to the United States, right?
[01:07:32.040 --> 01:07:34.040]   They'll take the, I mean, if you're Kairos,
[01:07:34.040 --> 01:07:36.360]   and you can't put this in the United States,
[01:07:36.360 --> 01:07:37.920]   but you could put it in Mexico,
[01:07:37.920 --> 01:07:39.360]   and then come up with a, you know,
[01:07:39.360 --> 01:07:41.520]   a way to get it past Trump's border wall.
[01:07:41.520 --> 01:07:43.640]   You may be able to put it into the United States,
[01:07:43.640 --> 01:07:45.760]   but we won't know until we know it works.
[01:07:45.760 --> 01:07:49.440]   Just, I'm sorry, I keep going back to this
[01:07:49.440 --> 01:07:52.040]   tricky little issue of it doesn't work.
[01:07:52.040 --> 01:07:53.360]   - Well, I mean, I think, Freeberg, I'm with you,
[01:07:53.360 --> 01:07:56.480]   in that even with the disasters that have happened,
[01:07:56.480 --> 01:07:58.880]   those are with Gen 1 and Gen 2 reactors.
[01:07:58.880 --> 01:08:00.080]   There hasn't been one in a long time,
[01:08:00.080 --> 01:08:01.240]   and the fallout from them- - Yeah, and that,
[01:08:01.240 --> 01:08:02.080]   I believe- - Haven't been-
[01:08:02.080 --> 01:08:02.920]   - I believe those things- - Significant.
[01:08:02.920 --> 01:08:04.200]   - If we could spin those up right now,
[01:08:04.200 --> 01:08:06.400]   these Gen 2, Gen 3 reactors, do them all day long.
[01:08:06.400 --> 01:08:07.480]   I think that they're very safe.
[01:08:07.480 --> 01:08:08.520]   They're very reliable. - No, the 3 and 4.
[01:08:08.520 --> 01:08:09.360]   The 3's are- - You want one
[01:08:09.360 --> 01:08:10.200]   in your backyard?
[01:08:10.200 --> 01:08:11.520]   - The 3's are going to be fine- - I would be fine
[01:08:11.520 --> 01:08:13.680]   with one being 100 miles from my backyard, no problem.
[01:08:13.680 --> 01:08:14.520]   - 100. - It's four
[01:08:14.520 --> 01:08:15.360]   that's producing- - 100.
[01:08:15.360 --> 01:08:17.280]   - China's producing a gigawatt of power.
[01:08:17.280 --> 01:08:20.240]   - Would you want one 10 miles outside Austin?
[01:08:20.240 --> 01:08:21.440]   - I don't think you should put it 10 miles
[01:08:21.440 --> 01:08:22.280]   outside of any city.
[01:08:22.280 --> 01:08:23.680]   I know that they're doing that in India.
[01:08:23.680 --> 01:08:24.760]   They're doing that in China.
[01:08:24.760 --> 01:08:29.160]   I would think, if you look up the footprint of Fukushima,
[01:08:29.160 --> 01:08:30.520]   I mean, that was a complete disaster.
[01:08:30.520 --> 01:08:32.160]   They put that below sea level.
[01:08:32.160 --> 01:08:33.800]   They told them not to put it there,
[01:08:33.800 --> 01:08:35.320]   and they put it near a bunch of people
[01:08:35.320 --> 01:08:38.280]   who were living within miles of it,
[01:08:38.280 --> 01:08:39.680]   single digit miles of it.
[01:08:39.680 --> 01:08:41.720]   There's no reason for this to be
[01:08:41.720 --> 01:08:43.520]   any closer than 50 or 100 miles,
[01:08:43.520 --> 01:08:46.240]   and I would be totally fine with it being 50 to 100 miles
[01:08:46.240 --> 01:08:48.160]   from where I'm on my ranch right now.
[01:08:48.160 --> 01:08:50.080]   Absolutely no problem with that.
[01:08:50.080 --> 01:08:52.440]   - I think this is a classic luxury belief,
[01:08:52.440 --> 01:08:54.880]   where it's easy for you to espouse this
[01:08:54.880 --> 01:08:57.440]   for everybody else for the nation,
[01:08:57.440 --> 01:09:00.120]   because you know the downsides aren't going to fall on you.
[01:09:00.120 --> 01:09:02.440]   - No, but 50 miles or 100 miles could be any way
[01:09:02.440 --> 01:09:04.840]   from where we use them, and everyone would be safe.
[01:09:04.840 --> 01:09:07.080]   Would you be comfortable with putting them in the desert?
[01:09:07.080 --> 01:09:08.240]   - Yeah, but in that case,
[01:09:08.240 --> 01:09:09.840]   there won't be any- - Okay, then we're done.
[01:09:09.840 --> 01:09:11.720]   - That's how we're running wind and geothermal today.
[01:09:11.720 --> 01:09:15.120]   We're putting these sites in random places, and solar,
[01:09:15.120 --> 01:09:16.240]   and then we're running cable,
[01:09:16.240 --> 01:09:18.080]   and we're producing power and delivering it to-
[01:09:18.080 --> 01:09:18.920]   - And they're doing that with solar
[01:09:18.920 --> 01:09:20.840]   just because they don't want it to be an eyesore, right?
[01:09:20.840 --> 01:09:22.240]   That's why we're doing that with solar,
[01:09:22.240 --> 01:09:25.440]   is we don't want people to look at a giant solar thing.
[01:09:25.440 --> 01:09:27.200]   - Like I said, I'm not against doing it.
[01:09:27.200 --> 01:09:29.400]   If you can find a community that's willing to do it,
[01:09:29.400 --> 01:09:30.920]   and if you put it where there's no humans,
[01:09:30.920 --> 01:09:32.400]   then yeah, that's gonna work.
[01:09:32.400 --> 01:09:33.240]   - So there we go. - That's what you have to do.
[01:09:33.240 --> 01:09:34.360]   - We've resolved our issue.
[01:09:34.360 --> 01:09:35.640]   We got the compromise here.
[01:09:35.680 --> 01:09:37.120]   - I just don't know how feasible that is.
[01:09:37.120 --> 01:09:38.360]   - Solving world problems, yes.
[01:09:38.360 --> 01:09:39.360]   - Are you still gonna need humans
[01:09:39.360 --> 01:09:40.680]   to work at this place? - I'm gonna get my guitar,
[01:09:40.680 --> 01:09:43.240]   and we're gonna sing "Kumbaya" SMR.
[01:09:43.240 --> 01:09:44.760]   - Humans to work at this place.
[01:09:44.760 --> 01:09:46.920]   - You better get some robot employees.
[01:09:46.920 --> 01:09:47.920]   - I can't wait for you guys
[01:09:47.920 --> 01:09:50.400]   to lay millions of miles of copper cabling now
[01:09:50.400 --> 01:09:51.240]   as a solution to truck all this energy.
[01:09:51.240 --> 01:09:52.160]   - I'm fine laying pipe, Chamath.
[01:09:52.160 --> 01:09:53.320]   I'll lay that pipe.
[01:09:53.320 --> 01:09:54.160]   - Genius.
[01:09:54.160 --> 01:09:55.760]   - You need me to lay pipe, I'll do it, Chamath.
[01:09:55.760 --> 01:09:56.600]   - Genius. - No ditty.
[01:09:56.600 --> 01:09:58.760]   - Sax, do you wanna go visit a nuclear power plant?
[01:09:58.760 --> 01:09:59.600]   - Let's do it. - No, zero interest.
[01:09:59.600 --> 01:10:01.320]   - Let's go. - Yeah, we'll go.
[01:10:01.360 --> 01:10:02.200]   - How's that gonna improve your life?
[01:10:02.200 --> 01:10:05.040]   - Any progress, Sax is not interested in any progress, okay?
[01:10:05.040 --> 01:10:07.360]   If we can go back to the '50s, that's what he wants.
[01:10:07.360 --> 01:10:08.200]   Let's get some coal. - You're like
[01:10:08.200 --> 01:10:09.520]   virtue signaling.
[01:10:09.520 --> 01:10:12.000]   - I'm virtue signaling 'cause I'm pro-nuclear?
[01:10:12.000 --> 01:10:13.800]   - Yes, it's a luxury belief.
[01:10:13.800 --> 01:10:14.640]   You're promoting something where--
[01:10:14.640 --> 01:10:16.960]   - Nuclear power is a luxury belief.
[01:10:16.960 --> 01:10:18.360]   You heard it here first.
[01:10:18.360 --> 01:10:20.360]   - 'Cause they're gonna put these things in poor communities.
[01:10:20.360 --> 01:10:21.200]   And so it's never gonna affect your life.
[01:10:21.200 --> 01:10:22.020]   - No, they're not.
[01:10:22.020 --> 01:10:22.860]   They're gonna put it in '50s.
[01:10:22.860 --> 01:10:23.680]   - They're putting it next to data centers, Sax.
[01:10:23.680 --> 01:10:25.600]   - Everything is not identity politics.
[01:10:25.600 --> 01:10:26.880]   - In like Oregon, like.
[01:10:26.880 --> 01:10:29.160]   - It's easy for you to say, oh, I support nuclear.
[01:10:29.160 --> 01:10:30.440]   Look how progressive I am.
[01:10:30.440 --> 01:10:31.800]   Look how smart I am.
[01:10:31.800 --> 01:10:34.200]   You haven't internalized the downsides.
[01:10:34.200 --> 01:10:35.020]   - I just want--
[01:10:35.020 --> 01:10:35.860]   - Shoot the bund in electricity, Sax.
[01:10:35.860 --> 01:10:36.680]   That's what I want. - Is everything
[01:10:36.680 --> 01:10:38.320]   identity politics for you, Sax?
[01:10:38.320 --> 01:10:39.160]   Everything you see
[01:10:39.160 --> 01:10:39.980]   through the lens of poor-- - No, this is not
[01:10:39.980 --> 01:10:42.760]   identity politics. - And rich, everything.
[01:10:42.760 --> 01:10:43.920]   - I'm defending the poor. - The DM.
[01:10:43.920 --> 01:10:46.300]   - You're gonna put these things in poor communities.
[01:10:46.300 --> 01:10:47.840]   - You're genuflecting, Sax.
[01:10:47.840 --> 01:10:48.680]   Looking out for the poor.
[01:10:48.680 --> 01:10:51.640]   Look at you, Mr. Robin Hood over here.
[01:10:51.640 --> 01:10:53.160]   - I'm defending the right of communities
[01:10:53.160 --> 01:10:54.560]   to say no to this.
[01:10:54.560 --> 01:10:56.320]   - You are my favorite. - To your science experiment.
[01:10:56.320 --> 01:10:57.640]   - You're my favorite, Efficen.
[01:10:57.640 --> 01:10:59.360]   - I'm defending the right of local communities
[01:10:59.360 --> 01:11:01.320]   to say no to your science experiment, okay?
[01:11:01.320 --> 01:11:02.320]   That's what it comes down to.
[01:11:02.320 --> 01:11:06.320]   - Freeberg, Freeberg is trying to put this.
[01:11:06.320 --> 01:11:07.480]   - Episode 200.
[01:11:07.480 --> 01:11:08.320]   I love it.
[01:11:08.320 --> 01:11:09.320]   - Wow, off the rails. - The sums up
[01:11:09.320 --> 01:11:10.320]   the 200 shows.
[01:11:10.320 --> 01:11:12.620]   - Sax, let me ask you a serious question.
[01:11:12.620 --> 01:11:14.960]   (laughing)
[01:11:14.960 --> 01:11:17.520]   - It's not serious when you start like that.
[01:11:17.520 --> 01:11:20.940]   - If Trump loses, what's the next four years
[01:11:20.940 --> 01:11:22.960]   of this pod gonna be like?
[01:11:22.960 --> 01:11:24.280]   What are we gonna do here? - He's not coming back.
[01:11:24.280 --> 01:11:25.520]   - We lose.
[01:11:25.520 --> 01:11:26.640]   - He's moving to New Zealand.
[01:11:26.640 --> 01:11:28.720]   There's gonna be lawfare all over the place.
[01:11:28.720 --> 01:11:30.280]   - Absolutely, they're gonna come for you.
[01:11:30.280 --> 01:11:31.480]   - Do you really think so, David?
[01:11:31.480 --> 01:11:32.300]   - Yeah, I do.
[01:11:32.300 --> 01:11:36.040]   I mean, look, I'm definitely not the top of the list.
[01:11:36.040 --> 01:11:37.760]   Elon's at the top of the list, right?
[01:11:37.760 --> 01:11:40.760]   So he has no choice but to go all in.
[01:11:40.760 --> 01:11:43.000]   They're already doing lawfare against him.
[01:11:43.000 --> 01:11:44.320]   - It's ridiculous, man. - But I think the point
[01:11:44.320 --> 01:11:47.340]   is just that if they're not defeated,
[01:11:47.340 --> 01:11:48.360]   they're gonna keep doing it
[01:11:48.360 --> 01:11:50.200]   because there's no downside for it.
[01:11:50.200 --> 01:11:54.440]   - I will comment on the California Coastal Commission
[01:11:54.440 --> 01:11:57.540]   ruling that was based on Elon's political tweets,
[01:11:57.540 --> 01:11:59.480]   which is why they stopped additional launches
[01:11:59.480 --> 01:12:00.720]   out of Vandenberg.
[01:12:00.720 --> 01:12:03.360]   First of all, how the California Coastal Commission
[01:12:03.360 --> 01:12:07.880]   has authority over Vandenberg and the operations
[01:12:07.880 --> 01:12:09.960]   just seems to me like there's something wrong.
[01:12:09.960 --> 01:12:12.000]   The Coastal Commission was set up with the Coastal Act
[01:12:12.000 --> 01:12:15.900]   in 1976 in California as a way to give the beaches
[01:12:15.900 --> 01:12:17.360]   back to the people and the public
[01:12:17.360 --> 01:12:19.420]   and create a commission to regulate building
[01:12:19.420 --> 01:12:20.260]   along the beaches.
[01:12:20.260 --> 01:12:22.680]   It has since grown into, effectively,
[01:12:22.680 --> 01:12:27.080]   a much larger entity with much more authority,
[01:12:27.080 --> 01:12:29.600]   which potentially, after the Chevron ruling
[01:12:29.600 --> 01:12:32.400]   in the Supreme Court, may get peeled back
[01:12:32.400 --> 01:12:33.520]   and may get dialed down.
[01:12:33.520 --> 01:12:34.520]   We'll see what happens.
[01:12:34.520 --> 01:12:35.840]   But as of now, they have the ability
[01:12:35.840 --> 01:12:38.040]   to block launches out of Vandenberg,
[01:12:38.040 --> 01:12:40.160]   which they did, and in their decision,
[01:12:40.160 --> 01:12:42.480]   they said it was because of Elon's political tweets.
[01:12:42.480 --> 01:12:44.440]   Again, starting at the beginning of the show
[01:12:44.440 --> 01:12:46.120]   about the success that they had
[01:12:46.120 --> 01:12:48.240]   with the Starship this week, it's incredible.
[01:12:48.240 --> 01:12:50.200]   It deserves to be recognized on the merits
[01:12:50.200 --> 01:12:51.480]   of what they accomplished.
[01:12:51.480 --> 01:12:53.080]   But to bring in his political tweets
[01:12:53.080 --> 01:12:55.280]   to make a decision about the progress of SpaceX
[01:12:55.280 --> 01:12:58.080]   and allow public space to be used
[01:12:58.080 --> 01:13:00.880]   to further that cause and further that activity
[01:13:00.880 --> 01:13:03.400]   seems to me abhorrent, and it's ridiculous,
[01:13:03.400 --> 01:13:06.520]   and it's exactly what's wrong with the bureaucratic morass
[01:13:06.520 --> 01:13:09.520]   that a lot of these institutions have grown into.
[01:13:09.520 --> 01:13:11.280]   - And this was a split vote, six, four.
[01:13:11.280 --> 01:13:15.440]   - Do you think they're gonna be pro or con SMRs?
[01:13:15.440 --> 01:13:18.000]   - Exactly, yeah.
[01:13:18.000 --> 01:13:18.840]   - No, I'm serious.
[01:13:18.840 --> 01:13:20.500]   Do you think they're gonna be con for sure?
[01:13:20.500 --> 01:13:22.000]   - They're con. - The Coastal Commission?
[01:13:22.000 --> 01:13:24.280]   - What the Coastal Commission does is they--
[01:13:24.280 --> 01:13:25.160]   - They block everything.
[01:13:25.160 --> 01:13:27.520]   - They block everything, and they do pictures
[01:13:27.520 --> 01:13:28.400]   of the entire coastline.
[01:13:28.400 --> 01:13:32.040]   If you build a shed on your beachfront property,
[01:13:32.040 --> 01:13:34.080]   they will know it, and they come to you,
[01:13:34.080 --> 01:13:35.160]   and they're like, "No sheds.
[01:13:35.160 --> 01:13:37.620]   "You cannot build any structures on the beach."
[01:13:37.620 --> 01:13:39.760]   They're just really, really hardcore.
[01:13:39.760 --> 01:13:41.880]   - It's a values decision that the state of California
[01:13:41.880 --> 01:13:43.200]   made in 1976.
[01:13:43.200 --> 01:13:45.720]   The state of California, the citizens voted
[01:13:45.720 --> 01:13:48.240]   and said, "We wanna preserve the coastline,"
[01:13:48.240 --> 01:13:50.280]   and I think that that's a reasonable value
[01:13:50.280 --> 01:13:51.940]   for them to assume and vote for,
[01:13:51.940 --> 01:13:53.460]   and it was a majority vote,
[01:13:53.460 --> 01:13:55.420]   and so they established the Coastal Commission.
[01:13:55.420 --> 01:13:57.660]   But how the Coastal Commission extended
[01:13:57.660 --> 01:13:59.860]   into having authority over Vandenberg and launches
[01:13:59.860 --> 01:14:01.940]   from there for SpaceX, to me,
[01:14:01.940 --> 01:14:04.580]   is part of this kind of administrative growth.
[01:14:04.580 --> 01:14:07.100]   We see all these administrative bureaucracies get started
[01:14:07.100 --> 01:14:08.420]   that have a very simple objective,
[01:14:08.420 --> 01:14:10.180]   preserve the California coastline,
[01:14:10.180 --> 01:14:12.300]   but now they have authority to determine
[01:14:12.300 --> 01:14:13.740]   whether or not launches can happen
[01:14:13.740 --> 01:14:15.900]   and therefore space-- - And this is one person
[01:14:15.900 --> 01:14:19.780]   at the Coastal Commission referenced his tweets,
[01:14:19.780 --> 01:14:22.380]   and the vote was 6-4 to increase these.
[01:14:22.380 --> 01:14:24.420]   So who is this one person? - No, but she did it
[01:14:24.420 --> 01:14:25.620]   in an official context,
[01:14:25.620 --> 01:14:27.060]   which I think she was like retweeting it.
[01:14:27.060 --> 01:14:28.300]   There was like a tweet from her.
[01:14:28.300 --> 01:14:29.620]   - Yeah, this is what I don't understand.
[01:14:29.620 --> 01:14:30.740]   - She was taking credit for it.
[01:14:30.740 --> 01:14:31.880]   I mean, in a way, she does a favor.
[01:14:31.880 --> 01:14:33.660]   - She's proud of it. - She's proud of it.
[01:14:33.660 --> 01:14:35.460]   She said the quiet part out loud.
[01:14:35.460 --> 01:14:37.500]   So in a way, she does a favor,
[01:14:37.500 --> 01:14:40.340]   which is she acknowledged that all of this lawfare
[01:14:40.340 --> 01:14:43.140]   against SpaceX and Elon is political.
[01:14:43.140 --> 01:14:44.840]   She basically pleaded guilty to it.
[01:14:44.840 --> 01:14:46.620]   Look, she's proud of it 'cause she doesn't think
[01:14:46.620 --> 01:14:47.860]   there's anything wrong with it.
[01:14:47.860 --> 01:14:50.180]   She thinks this is her job is as a bureaucrat,
[01:14:50.180 --> 01:14:52.940]   she's supposed to punish people who tweet things
[01:14:52.940 --> 01:14:53.980]   that you're not supposed to say.
[01:14:53.980 --> 01:14:56.180]   That basically is what it comes down to.
[01:14:56.180 --> 01:14:58.700]   And I mean, this is the truth about lawfare.
[01:14:58.700 --> 01:15:01.060]   They're using the agencies of the federal government
[01:15:01.060 --> 01:15:05.840]   to exact reprisals against their political opponents.
[01:15:05.840 --> 01:15:08.100]   And if there's not a punishment for that,
[01:15:08.100 --> 01:15:09.900]   it's gonna keep going.
[01:15:09.900 --> 01:15:13.940]   - And they've filed a, Elon's filed a lawsuit,
[01:15:13.940 --> 01:15:15.340]   and it's a 6-4 decision.
[01:15:15.340 --> 01:15:16.660]   So I think there's-- - By the way,
[01:15:16.660 --> 01:15:18.740]   the Biden-Harris administration could stop that.
[01:15:18.740 --> 01:15:21.300]   They could say no more lawfare, but they don't do that
[01:15:21.300 --> 01:15:23.900]   because the tone was set from the top.
[01:15:23.900 --> 01:15:26.140]   - And Trump is saying he's gonna be a dictator
[01:15:26.140 --> 01:15:27.980]   and he's gonna do a bunch of lawfare when he gets in there.
[01:15:27.980 --> 01:15:30.360]   So both of these sides gotta settle it down.
[01:15:30.360 --> 01:15:31.740]   That's exactly what he said.
[01:15:31.740 --> 01:15:34.060]   This has been another amazing-- - No, that's another risk quote.
[01:15:34.060 --> 01:15:34.900]   - Okay. - Jay Kyle,
[01:15:34.900 --> 01:15:35.860]   you can't wrap a show like that.
[01:15:35.860 --> 01:15:36.680]   That's just not cool.
[01:15:36.680 --> 01:15:38.180]   - I'm just trying to wrap up so we can move on.
[01:15:38.180 --> 01:15:39.940]   - Well, then don't make a sly comment.
[01:15:39.940 --> 01:15:41.000]   Like, just do something else.
[01:15:41.000 --> 01:15:42.660]   Talk about something else besides Trump at the end.
[01:15:42.660 --> 01:15:44.300]   Like, you know. - I'm just giving my opinion.
[01:15:44.300 --> 01:15:45.540]   I'm not allowed to give my opinion on the show.
[01:15:45.540 --> 01:15:48.060]   - What are you grateful for right now in your life?
[01:15:48.060 --> 01:15:51.340]   - I'm grateful for you doing all the work on the events
[01:15:51.340 --> 01:15:52.940]   and making them spectacular.
[01:15:52.940 --> 01:15:56.220]   - I'm really excited for "Sax Live" for Mar-a-Lago.
[01:15:56.220 --> 01:15:57.060]   - Oh, God. - Oh, God.
[01:15:57.060 --> 01:15:59.060]   - I will totally go to Mar-a-Lago for election night.
[01:15:59.060 --> 01:16:00.380]   Can we get a booth there?
[01:16:00.380 --> 01:16:02.220]   That would be hilarious. - You keep saying it.
[01:16:02.220 --> 01:16:04.140]   It's not clear you would be invited.
[01:16:04.140 --> 01:16:05.700]   - Yeah, exactly. - Of course I'm invited.
[01:16:05.700 --> 01:16:06.540]   - Trump loves me.
[01:16:06.540 --> 01:16:07.380]   Jared Kushner loves me. - I don't know if you remember,
[01:16:07.380 --> 01:16:09.260]   but neither you nor I-- - I'm friends with everybody.
[01:16:09.260 --> 01:16:11.140]   - Neither you nor I gave the hundreds of thousands
[01:16:11.140 --> 01:16:12.540]   of dollars per ticket to go to dinner
[01:16:12.540 --> 01:16:14.180]   with Trump, so. - Oh, please.
[01:16:14.180 --> 01:16:15.540]   - Trump loves me. - He invited us.
[01:16:15.540 --> 01:16:16.860]   - He enjoyed his time. - He's very selective.
[01:16:16.860 --> 01:16:18.220]   It's for friends.
[01:16:18.220 --> 01:16:19.060]   (Jared laughing)
[01:16:19.060 --> 01:16:21.620]   It's a mouthy get-in, it's a mouthy get-in, fine.
[01:16:21.620 --> 01:16:23.380]   - I mean, okay, I'll do it remote, it's fine.
[01:16:23.380 --> 01:16:24.740]   I'll do it, we can do it remote, it's fine.
[01:16:24.740 --> 01:16:25.900]   You don't want Jake out there?
[01:16:25.900 --> 01:16:27.500]   It's fine, you can go with me.
[01:16:27.500 --> 01:16:28.340]   - Wait, when is the election?
[01:16:28.340 --> 01:16:30.540]   - I don't wanna be at a party I'm not invited to.
[01:16:30.540 --> 01:16:31.380]   That's for sure, I'll throw my own.
[01:16:31.380 --> 01:16:33.500]   - It's in two weeks and three days, four days?
[01:16:33.500 --> 01:16:34.700]   - Yeah, coming up. - November 5th.
[01:16:34.700 --> 01:16:36.420]   - I can't, please let it be three days.
[01:16:36.420 --> 01:16:38.060]   - It's like just waiting every day for it to drop,
[01:16:38.060 --> 01:16:39.700]   whatever it's gonna be. - I just hope whoever wins
[01:16:39.700 --> 01:16:42.300]   wins significantly, so we don't--
[01:16:42.300 --> 01:16:44.540]   - Significantly, agreed. - Yeah, please, win by--
[01:16:44.540 --> 01:16:46.580]   - Totally. - 30 electoral votes.
[01:16:46.580 --> 01:16:49.900]   - No Supreme Court decision. - Please.
[01:16:49.900 --> 01:16:51.460]   - Right now, the only candidate
[01:16:51.460 --> 01:16:55.340]   who looks like he could get a landslide is Trump.
[01:16:55.340 --> 01:16:56.620]   Otherwise, it's gonna be very close.
[01:16:56.620 --> 01:16:59.020]   So you're rooting for Trump if you want a landslide.
[01:16:59.020 --> 01:17:02.020]   - I mean, I'm going to reveal my vote
[01:17:02.020 --> 01:17:03.260]   on the election special.
[01:17:03.260 --> 01:17:04.300]   I will have my vote. - That's really hard
[01:17:04.300 --> 01:17:05.700]   to figure out, I'm sure the audience
[01:17:05.700 --> 01:17:08.620]   will be held in great suspense by that.
[01:17:08.620 --> 01:17:11.380]   (both laughing)
[01:17:11.380 --> 01:17:13.300]   - Did you guys vote yet, did you guys vote yet?
[01:17:13.300 --> 01:17:15.340]   - I got my ballot on my-- - I got my ballot
[01:17:15.340 --> 01:17:17.060]   on my desk here, yeah, I'm ready to go.
[01:17:17.060 --> 01:17:18.620]   I'm ready to go.
[01:17:18.620 --> 01:17:20.020]   All right, everybody, this has been
[01:17:20.020 --> 01:17:22.140]   another wonderful episode. - Love you, boys.
[01:17:22.140 --> 01:17:25.020]   - Oh, meetups, there are 200 episode meetups happening.
[01:17:25.020 --> 01:17:27.740]   Thank you to all the fans who got together,
[01:17:27.740 --> 01:17:29.300]   take pictures and share 'em on social
[01:17:29.300 --> 01:17:31.620]   and @mentionus, allin.com/meetups.
[01:17:31.620 --> 01:17:34.500]   Every couple episodes, fans get together around the world
[01:17:34.500 --> 01:17:37.940]   and talk about their favorite bestie,
[01:17:37.940 --> 01:17:39.580]   and that's typically Freebird.
[01:17:39.580 --> 01:17:42.580]   And we'll see you next time, bye-bye.
[01:17:42.580 --> 01:17:43.780]   - Love you, boys. - Bye-bye.
[01:17:43.780 --> 01:17:45.740]   ♪ I'm going all in ♪
[01:17:45.740 --> 01:17:48.460]   ♪ We'll let your winners ride ♪
[01:17:48.460 --> 01:17:50.460]   ♪ Rain Man, David Saks ♪
[01:17:50.460 --> 01:17:52.820]   ♪ I'm going all in ♪
[01:17:52.820 --> 01:17:55.060]   ♪ And instead we open source it to the fans ♪
[01:17:55.060 --> 01:17:56.900]   ♪ And they've just gone crazy with it ♪
[01:17:56.900 --> 01:17:59.100]   ♪ Love you, Eskimo Queen of Kinhwa ♪
[01:17:59.100 --> 01:18:01.940]   ♪ I'm going all in ♪
[01:18:01.940 --> 01:18:05.940]   ♪ We'll let your winners ride ♪
[01:18:05.940 --> 01:18:08.700]   ♪ Besties are gone ♪
[01:18:08.700 --> 01:18:10.700]   - That's my dog taking a notice in your driveway.
[01:18:10.700 --> 01:18:12.940]   (laughing)
[01:18:12.940 --> 01:18:17.340]   - We should all just get a room
[01:18:17.340 --> 01:18:18.940]   and just have one big huge orgy
[01:18:18.940 --> 01:18:20.180]   'cause they're all just useless.
[01:18:20.180 --> 01:18:21.660]   It's like this sexual tension
[01:18:21.660 --> 01:18:24.300]   that they just need to release somehow.
[01:18:24.300 --> 01:18:26.180]   ♪ Wet your feet ♪
[01:18:26.180 --> 01:18:28.220]   ♪ Wet your feet ♪
[01:18:28.220 --> 01:18:30.460]   ♪ Wet your feet ♪
[01:18:30.460 --> 01:18:31.300]   ♪ Besties are gone ♪
[01:18:31.300 --> 01:18:36.300]   ♪ I'm going all in ♪
[01:18:36.300 --> 01:18:41.860]   ♪ I'm going all in ♪
[01:18:41.860 --> 01:18:42.360]   you
[01:18:42.360 --> 01:18:52.360]   [BLANK_AUDIO]

