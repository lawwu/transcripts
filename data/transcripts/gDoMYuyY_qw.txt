
[00:00:00.000 --> 00:00:07.440]   Hey everyone, Ivan here, and welcome to the first part of the YOLOv5 series.
[00:00:07.440 --> 00:00:12.280]   In this series, we'll learn how to train a YOLOv5 model in a custom dataset, from start
[00:00:12.280 --> 00:00:13.280]   to finish.
[00:00:13.280 --> 00:00:21.040]   We'll look at how to install YOLOv5 and its dependencies on both Google Colab and on Windows.
[00:00:21.040 --> 00:00:24.400]   Then we'll learn about collecting and labeling our custom data.
[00:00:24.400 --> 00:00:28.840]   We'll also learn how to properly configure your monitor training with the Weights and
[00:00:28.840 --> 00:00:34.320]   Biases machine learning tools.
[00:00:34.320 --> 00:00:39.360]   This video, part 1, focuses on two things in particular - quickly setting up YOLOv5
[00:00:39.360 --> 00:00:44.400]   on Google Colab, and diving deep into what it takes to install it on Windows successfully
[00:00:44.400 --> 00:00:46.440]   with GPU support.
[00:00:46.440 --> 00:00:50.800]   In both cases, the end goal is the ability to run inference - in other words, having
[00:00:50.800 --> 00:00:58.680]   the pre-trained model detect objects in our images or videos.
[00:00:58.680 --> 00:01:02.600]   If you have any comments or questions at any point throughout this video, feel free to
[00:01:02.600 --> 00:01:05.280]   leave them in the comment section down below.
[00:01:05.280 --> 00:01:07.200]   And let's get started!
[00:01:07.200 --> 00:01:12.560]   I've actually already made an overview video about training YOLOv5 with Weights and Biases
[00:01:12.560 --> 00:01:15.280]   integration in an example Colab notebook.
[00:01:15.280 --> 00:01:20.280]   If you want to get a feel for how the training will look like, I really recommend that you
[00:01:20.280 --> 00:01:22.060]   check that video out.
[00:01:22.060 --> 00:01:25.060]   You can call that part 0 of the series.
[00:01:25.060 --> 00:01:30.600]   In the Colab notebook from that video, the first cell sets things up.
[00:01:30.600 --> 00:01:36.560]   The second cell runs inference, aka detecting objects in an example image.
[00:01:36.560 --> 00:01:42.000]   The command detect.py automatically downloads the YOLOv5 model to perform inference on a
[00:01:42.000 --> 00:01:43.000]   selected image.
[00:01:43.000 --> 00:01:49.240]   We can select a new example image and see how the model will do on it.
[00:01:49.240 --> 00:01:56.840]   We'll come back to Colab when we talk about training in part 3, but that's really pretty
[00:01:56.840 --> 00:01:58.840]   much it for now.
[00:01:58.840 --> 00:02:05.320]   Colab is great, but when it comes to inference, there's a very serious drawback - we can't
[00:02:05.320 --> 00:02:09.640]   run detection in real time, save from our webcam feed.
[00:02:09.640 --> 00:02:14.940]   That's where we need to get our hands dirty and set things up on a system like Windows.
[00:02:14.940 --> 00:02:23.360]   The first thing we need to do is to download and unzip the YOLOv5 repository from GitHub.
[00:02:23.360 --> 00:02:26.820]   Now let's go over the requirements outlined in the repo.
[00:02:26.820 --> 00:02:31.260]   We need to be running Python 3.8 or later, which means that even though I have the good
[00:02:31.260 --> 00:02:36.120]   old Python 3.6 installed, I'll need to go ahead and get myself a newer version.
[00:02:36.120 --> 00:02:49.220]   We'll also need to have these modules installed.
[00:02:49.220 --> 00:02:54.620]   Since I have another version of Python already installed, I'll leave the "add Python 3.9
[00:02:54.620 --> 00:03:04.060]   to path" box unchecked and then do it manually afterwards.
[00:03:04.060 --> 00:03:08.380]   You can see that the 3.9 version has now appeared in the Python folder.
[00:03:08.380 --> 00:03:12.900]   However, if I open the console, it still uses Python 3.6 by default.
[00:03:12.900 --> 00:03:17.800]   Since we'll be running YOLOv5 through the console, it is crucial that we call the right
[00:03:17.800 --> 00:03:20.100]   version of Python.
[00:03:20.100 --> 00:03:26.020]   If your console already calls the right Python version, feel free to skip the next step.
[00:03:26.020 --> 00:03:30.300]   Environmental path variables allow us to call certain programs from the console anywhere
[00:03:30.300 --> 00:03:36.740]   in our system, like say running Python 3.9 inside the YOLOv5 repository folder.
[00:03:36.740 --> 00:03:41.820]   In this PC, I will click on "Properties" and then go into the "Advanced System Settings"
[00:03:41.820 --> 00:03:44.140]   to see the environmental variables.
[00:03:44.140 --> 00:03:55.460]   I'll click on the "Path" variable and change Python 3.6 to Python 3.9.
[00:03:55.460 --> 00:04:00.660]   Now we can check and make sure that we are indeed using Python 3.9.
[00:04:00.660 --> 00:04:07.060]   YOLOv5 uses PyTorch, currently one of the most popular machine learning frameworks to
[00:04:07.060 --> 00:04:10.660]   define models, run inference, and perform training.
[00:04:10.660 --> 00:04:15.100]   ML frameworks typically provide an easy and efficient way to run essential inference and
[00:04:15.100 --> 00:04:20.940]   training calculations on a GPU, which tends to be orders of magnitude faster than running
[00:04:20.940 --> 00:04:24.500]   similar calculations on a CPU.
[00:04:24.500 --> 00:04:30.540]   Well, that's provided that you go through the pain of installing everything correctly,
[00:04:30.540 --> 00:04:33.620]   but no worries, that's what I'm here for.
[00:04:33.620 --> 00:04:37.660]   Let's install PyTorch as a Python module.
[00:04:37.660 --> 00:04:42.780]   We'll go to the official "Get Started" page and select the Windows build that we want.
[00:04:42.780 --> 00:04:48.420]   If you're on an Intel-based Mac and have an NVIDIA GPU, you can select Mac as your OS
[00:04:48.420 --> 00:04:51.540]   and proceed with enabling GPU support.
[00:04:51.540 --> 00:04:56.940]   Regardless of the OS, if you don't have an NVIDIA GPU, you can select the CPU build
[00:04:56.940 --> 00:04:59.020]   and proceed with the video.
[00:04:59.020 --> 00:05:04.380]   Alright, if we're using the GPU option, we also need to install the correct version of
[00:05:04.380 --> 00:05:09.340]   NVIDIA's parallel computing platform, CUDA, which is used to enable GPU acceleration for
[00:05:09.340 --> 00:05:11.660]   training and inference.
[00:05:11.660 --> 00:05:16.620]   I'll go with CUDA 11.
[00:05:16.620 --> 00:05:21.740]   We can go to CUDA 11 download page, select our operating system, which is Windows 10
[00:05:21.740 --> 00:05:29.380]   in my case, and download the installer file.
[00:05:29.380 --> 00:05:40.460]   When it's downloaded, we can launch the file and begin installation.
[00:05:40.460 --> 00:05:44.940]   Upon completion, we'll be asked to restart the computer.
[00:05:44.940 --> 00:05:51.260]   Now that we have installed CUDA, we can install GPU-compatible PyTorch as well.
[00:05:51.260 --> 00:05:54.220]   First we will copy this pip install command.
[00:05:54.220 --> 00:05:57.980]   Next we'll run the console inside the Python scripts folder, paste the command from the
[00:05:57.980 --> 00:06:04.060]   PyTorch website there, and press enter.
[00:06:04.060 --> 00:06:08.500]   After successfully installing PyTorch and CUDA, there are a few other Python modules
[00:06:08.500 --> 00:06:11.380]   that YOLOv5 needs.
[00:06:11.380 --> 00:06:18.580]   There's a list of these modules in the requirements.txt file, and we can run pip install our requirements.txt
[00:06:18.580 --> 00:06:23.260]   inside the YOLOv5 folder to install them.
[00:06:23.260 --> 00:06:33.340]   And just as everything was going well, we get a very scary looking error.
[00:06:33.340 --> 00:06:36.740]   There's a problem installing PyCocoaTools.
[00:06:36.740 --> 00:06:41.220]   It's really easy to miss behind all of the redness of this exception, but there's actually
[00:06:41.220 --> 00:06:48.060]   a little sentence asking us to install Microsoft C++ build tools with a link.
[00:06:48.060 --> 00:06:53.620]   So I followed the instructions and installed the build tools, which required another system
[00:06:53.620 --> 00:07:01.420]   restart.
[00:07:01.420 --> 00:07:06.820]   I also used a different pip install command from the PyCocoaTools GitHub page, where they
[00:07:06.820 --> 00:07:20.420]   say they made minor changes to get it to work on Windows.
[00:07:20.420 --> 00:07:25.780]   I ran the pip install requirements.txt command again, just to double check, and this time
[00:07:25.780 --> 00:07:30.460]   it does say that we have all the necessary modules installed.
[00:07:30.460 --> 00:07:39.140]   Now, to run inference, we can open the console inside of the YOLOv5 folder and run python
[00:07:39.140 --> 00:07:42.180]   detect.py source1 command.
[00:07:42.180 --> 00:07:44.940]   The integer is the index of the webcam to use.
[00:07:44.940 --> 00:07:53.740]   Since I have two webcams, I call source1 to start inference using my second webcam.
[00:07:53.740 --> 00:08:21.940]   We can now see it working!
[00:08:21.940 --> 00:08:27.140]   YOLOv5 uses OpenCV in the background to display video, and we can click Q inside the OpenCV
[00:08:27.140 --> 00:08:30.580]   window to stop the program.
[00:08:30.580 --> 00:08:35.180]   We can also run inference in an image or in a video by passing a path to it, instead of
[00:08:35.180 --> 00:08:36.860]   the webcam index.
[00:08:36.860 --> 00:08:54.460]   Let's try it with this image.
[00:08:54.460 --> 00:08:57.060]   We can even pass a link to a YouTube video here.
[00:08:57.060 --> 00:09:01.460]   However, please note that the first time I tried that, it didn't actually work, as it
[00:09:01.460 --> 00:09:05.860]   was saying that some modules still weren't installed.
[00:09:05.860 --> 00:09:11.140]   I then went ahead and also pre-installed Puffy and YouTube DL modules, and then everything
[00:09:11.140 --> 00:09:38.060]   worked fine.
[00:09:38.060 --> 00:09:42.140]   One important thing to note here is that when we start inference, by default it downloads
[00:09:42.140 --> 00:09:44.420]   the smallest YOLOv5 model.
[00:09:44.420 --> 00:09:49.180]   Add the weights parameter to specify which model to use.
[00:09:49.180 --> 00:09:55.020]   Small, medium, large, or extra large models.
[00:09:55.020 --> 00:10:01.260]   For example, this is the large model we pass weights YOLOv5_L.pt, and the weights will
[00:10:01.260 --> 00:10:05.860]   be downloaded automatically.
[00:10:05.860 --> 00:10:10.300]   The smaller models tend to be a little less accurate, but are faster.
[00:10:10.300 --> 00:10:14.360]   While the larger ones tend to require more computing power to run, they usually do better
[00:10:14.360 --> 00:10:16.860]   with accuracy.
[00:10:16.860 --> 00:10:18.680]   It's definitely a trade-off.
[00:10:18.680 --> 00:10:23.060]   It depends on what hardware you have available for training and where the model will be deployed
[00:10:23.060 --> 00:10:28.140]   - on a phone, on a laptop, on a self-driving car, and so on.
[00:10:28.140 --> 00:10:30.180]   Now we know how to run inference.
[00:10:30.180 --> 00:10:36.140]   YOLOv5 is an implementation of a YOLO-type network in Python with PyTorch.
[00:10:36.140 --> 00:10:39.740]   This means that we can open any of the Python files, including the text at Py that we were
[00:10:39.740 --> 00:10:47.060]   just running, and be able to modify them and fairly easily add them to our own Python projects.
[00:10:47.060 --> 00:10:51.580]   In comparison, the original YOLO networks were programmed in C and used the Darknet
[00:10:51.580 --> 00:10:53.620]   deep learning framework.
[00:10:53.620 --> 00:10:57.180]   It definitely had its advantages in speed and, well, the fact that we wouldn't have
[00:10:57.180 --> 00:10:59.180]   YOLO networks without it.
[00:10:59.180 --> 00:11:02.540]   But it did make it rather difficult to integrate with Python code.
[00:11:02.540 --> 00:11:05.020]   That's it for this video.
[00:11:05.020 --> 00:11:13.660]   Stay tuned for the next one where we'll cover data collection and labeling.
[00:11:13.660 --> 00:11:17.260]   If you have any questions or comments, please feel free to leave them in the comments section
[00:11:17.260 --> 00:11:20.500]   down below and I'll be happy to answer them.
[00:11:20.500 --> 00:11:24.420]   And consider subscribing to our channel to see the upcoming parts of the series.
[00:11:24.420 --> 00:11:28.300]   And thank you for watching this video, I really hope you enjoyed it and found it useful.

