
[00:00:00.000 --> 00:00:29.000]   [no sound]
[00:00:29.000 --> 00:00:32.000]   Hey everybody, can you guys hear me okay?
[00:00:32.000 --> 00:00:40.000]   [no sound]
[00:00:40.000 --> 00:00:44.000]   Excellent.
[00:00:44.000 --> 00:00:53.000]   Cool. So then today, welcome everybody. Today we're going to start with session four, and basically we're looking at chapter four.
[00:00:53.000 --> 00:01:12.000]   So last time we looked at chapter two, we finished chapter two and I'm skipping over the chapter three for now, it is the, it's based on ethics, but I'm skipping over chapter three, purely because to keep, purely because to keep the timelines intact and we want to cover the book in next 20-25 weeks.
[00:01:12.000 --> 00:01:27.000]   We will come back to chapter three though, which is on ethics, but today we'll be starting with computer vision, and we'll be looking at basically everything that will be, will be going deep under the hood and we'll be looking at stochastic gradient descent, we'll be looking at
[00:01:27.000 --> 00:01:31.000]   PyTorch tensors, and a lot more.
[00:01:31.000 --> 00:01:40.000]   So something really exciting is Parul is joining us today. Hey Parul.
[00:01:40.000 --> 00:01:42.000]   Hi Aman, how are you?
[00:01:42.000 --> 00:01:49.000]   Good thanks. I'm really excited to have you with us today. And thanks for joining. Thanks for finding the time.
[00:01:49.000 --> 00:01:57.000]   So everybody this is Parul Pandey, she has, I've been following her work for quite some time and I'm really excited that she's here with us today.
[00:01:57.000 --> 00:02:04.000]   I think I started following her work from Kaggle, but she does a lot more writing and she has her own personal blog.
[00:02:04.000 --> 00:02:12.000]   And she's going to be talking to us today about this report that we've already shared with everybody about building a compelling data science portfolio with writing.
[00:02:12.000 --> 00:02:25.000]   So she'll be our guest lecture, guest speaker for today and towards the end, similar as Tanish, she'll be presenting how you can, how everybody should continue with writing and how we can have a compelling data science career.
[00:02:25.000 --> 00:02:27.000]   So thanks for joining us Parul.
[00:02:27.000 --> 00:02:36.000]   Thanks Aman for having me and a big hi to everyone who's joining and good morning and evening and afternoon, depending upon the times on your end.
[00:02:36.000 --> 00:02:45.000]   I'm really excited to be here and I'll just like to catch up with you all at the end of the session and maybe even after that.
[00:02:45.000 --> 00:02:48.000]   And just like to share my two cents with you all.
[00:02:48.000 --> 00:02:57.000]   Even though I know all of you are doing great in your respective careers, but whatever I have gained over my experience, I love to share with you all. Thanks.
[00:02:57.000 --> 00:03:04.000]   Thanks Parul. I'm sure I'm going to benefit a lot from that experience. So thanks for doing this for us.
[00:03:04.000 --> 00:03:06.000]   Yeah, sure.
[00:03:06.000 --> 00:03:15.000]   Same as every Fastbook session this week, we're going to use the 1db.me/fastbook for URL. So if I go to that.
[00:03:15.000 --> 00:03:19.000]   Let me bring it up. This will take us to the report.
[00:03:19.000 --> 00:03:27.000]   As usual, post your questions
[00:03:27.000 --> 00:03:33.000]   at this URL. So I'll share this in chat. Oh, Angelica shared it with everybody. Thanks Angelica.
[00:03:33.000 --> 00:03:41.000]   So yes, if you go to this report, this is where we'll have, there's already a question but please instead of posting on the zoom chat please post them here.
[00:03:41.000 --> 00:03:58.000]   The only reason why I won't be monitoring the zoom chat is because we also live on YouTube and then it gets really hard to monitor zoom chat and YouTube chat and it's just better to have it all in one place.
[00:03:58.000 --> 00:04:04.000]   Cool. We've had a really, really exciting week, and I'm super excited how this week has turned out.
[00:04:04.000 --> 00:04:10.000]   You know, for everybody who participated in everybody who built their projects. Thanks for doing that.
[00:04:10.000 --> 00:04:24.000]   Sai Amrit, he's built his landscape classification, which can classify basically buildings, forest, glacier, mountain, sea and street. He's also, I tried it out, it really did work well.
[00:04:24.000 --> 00:04:29.000]   So thanks for building and hopefully you enjoyed the experience Sai.
[00:04:29.000 --> 00:04:44.000]   And Ravi, Ravi has been part of, he's been blogging I think almost every week now but he's also started his own personal blog which is over here so that he's sharing his reading notes on chapter two in fastbook.
[00:04:44.000 --> 00:04:48.000]   He's also built his own rock paper scissor classifier.
[00:04:48.000 --> 00:04:58.000]   And that, which I did try, which did look really fun I think just I was trying a bit of a rock images I think there was some.
[00:04:58.000 --> 00:05:07.000]   I think I, when I tried it there was some incorrect labels with the rocks but thanks for, thanks for trying this and hope you hope you did enjoy the journey.
[00:05:07.000 --> 00:05:13.000]   We've also had Vinayak, Vinayak's built a cartoon classifier which is really exciting to see.
[00:05:13.000 --> 00:05:24.000]   I'm not sure exactly on how many cartoons this can classify I was trying to find the answer but hopefully Vinayak you can post in the chat as to how many cartoons this can classify.
[00:05:24.000 --> 00:05:37.000]   And he's started his own personal blog, and he's been sharing his blog at bits and biases, or he's got his own blog, and the URLs of which I will post in that single report straight after this talk.
[00:05:37.000 --> 00:05:41.000]   And then finally we've had Brinda and we've had Rashmi, Brinda's builder.
[00:05:41.000 --> 00:05:45.000]   She's built a food classifier so this is again really exciting.
[00:05:45.000 --> 00:06:02.000]   It's a dosa and then you upload an image and then you can tell it look it's 99.6% sure that's a dosa which is really exciting to see Rashmi she's built a, she's built a yoga pose classifier I think there was some initial questions with Charles did help
[00:06:02.000 --> 00:06:12.000]   in the forums and slack. So really excited to see all these projects that are being done as part of the part of last week.
[00:06:12.000 --> 00:06:15.000]   And I'm even more excited for the forums being used.
[00:06:15.000 --> 00:06:31.000]   You know last week we sort of decided that we're going to have one central place to have all the discussions and all the questions. And it's really exciting to see that Korean he's he's gone in and I think I did have a slide on you as well Korean I can't.
[00:06:31.000 --> 00:06:44.000]   I can't find it but I think there was Korean has also shared his blog he's he's been sharing his learnings on Twitter, and he's he's also been asking the question and out so I'm really excited to see the questionnaire doubts being discussed.
[00:06:44.000 --> 00:06:51.000]   And I'm really excited to see people coming together when I coming in and probably coming in and answering those questions for him.
[00:06:51.000 --> 00:07:08.000]   So I think we need to discuss the questions a bit more I'm really, I feel that the questions on the question it was the end of each chapter aren't being discussed as much as I would hope them to be like there's only one or two couple people generally discussing
[00:07:08.000 --> 00:07:22.000]   the question so going forward let's make it a habit that we we discuss the questionnaire a lot more so if I ping everybody on slack that let's discuss the questionnaire I'll create a maybe a forum post and then we can discuss the questionnaires, but going forward let's let's spend
[00:07:22.000 --> 00:07:26.000]   more time discussing more questions.
[00:07:26.000 --> 00:07:27.000]   So that's that.
[00:07:27.000 --> 00:07:32.000]   With that being said, let's get started with.
[00:07:32.000 --> 00:07:52.000]   I do have a different setup today so I think if things go wrong or buggy. Bear with me.
[00:07:52.000 --> 00:08:07.000]   Alright, so today we're going to be looking at MNIST basics. It's called MNIST basics. So, what is MNIST.
[00:08:07.000 --> 00:08:14.000]   As I said, I do have a different setup today so things are going to be a bit harder for me today.
[00:08:14.000 --> 00:08:30.000]   So what is MNIST. MNIST is just a basic 10 digit classifier, it's considered a, it's considered basic because it's considered a very basic problem to solve so we're going to start with a really simple toy problem today, we're going to learn the idea is not to
[00:08:30.000 --> 00:08:44.000]   solve the problem in the best possible way but the idea is to learn the basics the idea is to learn everything that we need to know about, about computer vision and about what it takes, what is training and what does it mean to train a digit classifier and deep
[00:08:44.000 --> 00:08:51.000]   learning so we will slowly be digging down into more and more deep learning as part of this chapter.
[00:08:51.000 --> 00:08:55.000]   So as I said, we're going to be looking into.
[00:08:55.000 --> 00:09:02.000]   We're going to be looking under the hood, and we'll start by using computer vision as an example today.
[00:09:02.000 --> 00:09:20.000]   So, typically, I think to be able to run all these image classifiers or to be able to train a digit classifier, we need to be able to be comfortable with coding and then the two main libraries that most people use, or will you'll see being used on NumPy and
[00:09:20.000 --> 00:09:36.000]   NumPy are arrays and tensors. So if it's a NumPy array, basically arrays are more commonly referred to for the NumPy and tensors are more commonly referred to for PyTorch, but today we'll be looking at what they mean and how, how they help create it.
[00:09:36.000 --> 00:09:44.000]   How can we have all these arrays and tensors and how do they come into this big picture of training a digit classifier.
[00:09:44.000 --> 00:09:56.000]   So we've already looked at stochastic gradient descent briefly we know that it is some method that we can use to be able to, to be able to improve the model weights, so it can help increase the performance.
[00:09:56.000 --> 00:10:05.000]   But today we'll be looking at more deeply into the stochastic gradient descent. We'll also be looking at loss function and finally we'll be looking at many batches.
[00:10:05.000 --> 00:10:14.000]   So that's the basic. That's, that's, that's basically all that we'll be covering today's and that is all that there is in chapter four.
[00:10:14.000 --> 00:10:27.000]   So then, the first thing is the foundations of computer vision, I mean, the first thing we need to understand to be able to build an image classifier. The first thing that we need to be look at is that we need to understand how computers can handle images.
[00:10:27.000 --> 00:10:38.000]   So if this is say a JPEG image, then a computer wouldn't know that there's a man in it or there's a cat in it. All that a computer can see is zeros and ones are basically numbers.
[00:10:38.000 --> 00:10:44.000]   So then we need to be able to know how computers handle, how computers handles images.
[00:10:44.000 --> 00:10:50.000]   So that's where we'll start with today.
[00:10:50.000 --> 00:11:02.000]   And to keep things simple, the very first model that we're going to look into is we're going to classify a digit three or a seven. So we have basically, we have two sets of images.
[00:11:02.000 --> 00:11:10.000]   One set belongs to the digit three and the second set belongs to the digit seven. And we've already looked at untar data in the past.
[00:11:10.000 --> 00:11:20.000]   So all that untar data will do, if we say untar data and we pass in MNIST sample, then this will download these images for us.
[00:11:20.000 --> 00:11:33.000]   But yeah, basically we've looked at untar data. All it does is you pass in a URL, it will download that URL and it will unzip it or untar it and then it returns a path on where that data exists, basically.
[00:11:33.000 --> 00:11:43.000]   So if I go in a list, what's in that path, I can see there's a train folder. I can see there's a labels.csv and I can see there's a valid folder.
[00:11:43.000 --> 00:11:57.000]   And if I go in and if I look into what's in my training folder, I can see that there's a folder basically called three and there's a folder basically called seven, which just means that my training and validation images are separated by folder.
[00:11:57.000 --> 00:12:08.000]   This comes from here. Because all my training images are going to be in the train folder and all my valid images are going to be in the valid folder.
[00:12:08.000 --> 00:12:37.000]   So the next thing I can do is I can just go into this path train three and I can just list them. So if it is helpful, let me just also bring up the code.
[00:12:37.000 --> 00:13:01.000]   So as I said, when we go path untar data, it returns a path object. So that path object basically looks at this.
[00:13:01.000 --> 00:13:16.000]   In my computer, the one that I'm using, it says at this place, this is where you have this data set downloaded. So I could just use a bash command and I could say list whatever there is on this at this specific folder.
[00:13:16.000 --> 00:13:24.000]   So it says there's three things. There's a train folder, there's a valid folder and I could also say, okay, please tell me what's in the train folder.
[00:13:24.000 --> 00:13:34.000]   So in the train folder, you have two more folders. So you have a folder for three, for all the images that belong to three and then you have a folder for all the images that belong to seven.
[00:13:34.000 --> 00:13:49.000]   And then I could just finally say, okay, can you please tell me what's all there in this folder in basically MNIST sample train and then inside the folder for the images three. And you can see there's a long list of images.
[00:13:49.000 --> 00:13:59.000]   An easier way to check the folder structure is to use something called a tree command. So I could just say home.
[00:13:59.000 --> 00:14:07.000]   I could just pass in the path and I can say,
[00:14:07.000 --> 00:14:20.000]   passing in a D at the end, we'll just say only list the directories and don't list the exact file names. So you can see that this is how this folder structure looks like. There's two folders. One of them is a three. The second one is a, sorry, one of them is train.
[00:14:20.000 --> 00:14:35.000]   Second one is valid. In train, there's three and seven and in valid, there's also three and seven. So then basically the main thing to know is that our images, they are separated by folders.
[00:14:35.000 --> 00:14:48.000]   So then, yeah, I can just have a, I can get the parts of all my images that are in the three folder in threes. I can get all the parts of the folders of all the images that are in the seventh, basically in the folder seven, and then I can call it seven.
[00:14:48.000 --> 00:15:03.000]   And if I have a look at the parts and this is what this part looks like. There's all these image names, train/3/1000.png and all that. So you basically have six, one, three, one images that belong to digit three.
[00:15:03.000 --> 00:15:16.000]   And then if I want to sort of, if I want to visualize this, I can just say, okay, give me the first part. So what is this threes.one going to do?
[00:15:16.000 --> 00:15:26.000]   So if you have a look at threes and you go in and you have a look at the first, basically this element, it's the second element. The first one is indexed zero.
[00:15:26.000 --> 00:15:38.000]   But anyway, the idea is that it returns a part. So I can just say, please open that. That's what goes into this image three part. And I can just say, please open that as an image and then display it.
[00:15:38.000 --> 00:15:51.000]   So then we get this image being displayed. And something really, something that's new today that we're looking at today that's a bit new is this, is this basically we're using image.open.
[00:15:51.000 --> 00:16:02.000]   So image comes from PIL or PILO. It's the Python Imaging Library. It's the most standard library that you'll see for opening and basically manipulating images.
[00:16:02.000 --> 00:16:09.000]   You'll also see CV2 being used. You'll also see PyTorch image IO being used in the wild.
[00:16:09.000 --> 00:16:20.000]   But these are the three main ones that I kind of use in my day to day life. But definitely PILO is one of the easiest and the fast, basically just the easiest to get started with.
[00:16:20.000 --> 00:16:27.000]   And it's the one that you'll see being used majority of the time.
[00:16:27.000 --> 00:16:37.000]   So then next thing is right now, Jupyter can display this as an image, but maybe you want to train an image classifier that can classify digits three from seven.
[00:16:37.000 --> 00:16:45.000]   Then a computer doesn't know that this is how a three looks like. A computer doesn't know what seven looks like. In a computer, everything is represented as a number.
[00:16:45.000 --> 00:16:53.000]   So this is something. So then if you want to convert this image into a number, all we can do is we can just call and say array.
[00:16:53.000 --> 00:17:02.000]   What this array will do, it will convert this image three into a NumPy array. So this is just a NumPy array.
[00:17:02.000 --> 00:17:11.000]   And then I can index into it. This is just Python slicing. So one of the requirements as part of Fastbook is that you understand basic Python.
[00:17:11.000 --> 00:17:19.000]   And then in an array, I can just use Python indexing, which means this will display the rows four to 10 and this will display the columns four to 10.
[00:17:19.000 --> 00:17:25.000]   And as you can see, this number three inside, if you convert it to an array, is just numbers.
[00:17:25.000 --> 00:17:33.000]   So this is what a number three would look like. So if number three will just be numbers, that's how.
[00:17:33.000 --> 00:17:42.000]   So these will be zeros, zeros or just some numbers. But inside, it's just a 2D array that looks something like this.
[00:17:42.000 --> 00:17:49.000]   I can also convert it to a tensor instead of converting it to a NumPy array. So this is then using PyTorch.
[00:17:49.000 --> 00:17:56.000]   So if I convert it to PyTorch, then this is basically the same thing.
[00:17:56.000 --> 00:18:01.000]   So PyTorch tensors and NumPy arrays are in most ways very similar.
[00:18:01.000 --> 00:18:07.000]   But again, PyTorch tensors add some extra functionality that we'll look at later.
[00:18:07.000 --> 00:18:18.000]   So then just to see, as I said, just to see that this whole image is basically a list of numbers inside in a computer,
[00:18:18.000 --> 00:18:24.000]   then what we can do is we can just index into it.
[00:18:24.000 --> 00:18:29.000]   So we can just select some rows. We can convert it to a pandas data frame.
[00:18:29.000 --> 00:18:33.000]   So if you don't know what pd.dataframe is, it's a library called pandas.
[00:18:33.000 --> 00:18:38.000]   Please have a look. And we can convert it into a pandas data frame and then we can color code it.
[00:18:38.000 --> 00:18:49.000]   So the one thing that you must realize by looking at this image is that the lighter pixels or the ones that display as white have values close to zero.
[00:18:49.000 --> 00:18:54.000]   And then the ones that display as black would have higher values like 255.
[00:18:54.000 --> 00:19:05.000]   So 255, 245 is also showing as black, but basically then the higher the value of the number, the more basically it's going to be black, closer to black.
[00:19:05.000 --> 00:19:10.000]   And then the lower the value of the number, it's going to be closer to white.
[00:19:10.000 --> 00:19:20.000]   So this is what has been written here as well, that white pixels are stored as the number zero, black is stored as number 255, and then shades of gray are between the two.
[00:19:20.000 --> 00:19:29.000]   So if you have something like this, 111. So 111 is a shade of gray because it's between white and black.
[00:19:29.000 --> 00:19:40.000]   Okay, so that's just the basics. So the basics so far what we've learned is that the only thing that we have learned so far is that image is a number.
[00:19:40.000 --> 00:19:49.000]   That's all that we need to know. And then 255 is black, zero is white.
[00:19:49.000 --> 00:20:00.000]   Cool. And then the next thing we want to do is we're going to, the goal that, let's not forget the goal, our goal is to create a model that can recognize threes from sevens.
[00:20:00.000 --> 00:20:18.000]   So at this stage, there's an exercise of stop and think. I will actually give you guys two minutes to, now that you know that this is how an image looks like, so a three would pretty much look like that, where these would be all the black numbers and a seven would look like that.
[00:20:18.000 --> 00:20:29.000]   And you think of ways, a very basic way where you can sort of differentiate these numbers from one another. So I'll maybe just wait two minutes and I'll go to that.
[00:20:29.000 --> 00:20:36.000]   I'll go over here.
[00:20:36.000 --> 00:20:46.000]   That's a good point. Thanks, Alan. Actually, I was also confused by that fact that in an image, 255 is white and zero is black, but it seemed odd.
[00:20:46.000 --> 00:21:00.000]   So I'll get back to this. It's a good point that's been raised, but let's not worry about this right now. Let's go with what the book has written and let's just say that shades of black are by a high number, just because we color coding,
[00:21:00.000 --> 00:21:04.000]   when we color coding in a pandas data frame, then let's just go with that.
[00:21:04.000 --> 00:21:12.000]   So let's not worry about this comment right now.
[00:21:12.000 --> 00:21:30.000]   So does anybody know of a comment or can anybody come up with a very basic example on how you can classify just numbers from one another?
[00:21:30.000 --> 00:21:36.000]   That's a good point. Three is more likely to have curves, seven is a sharp angle and a straight line component.
[00:21:36.000 --> 00:21:49.000]   But then if you think of it in terms of numbers, it's going to be, I mean, in terms of numbers, then how do you take this property and then how do you build a basic classifier that can take these numbers?
[00:21:49.000 --> 00:22:02.000]   It's just like a computer doesn't know if it's a sharp or it is curvy. A computer just knows that this image has these numbers at this particular spot and the other image has these numbers at the other particular spot.
[00:22:02.000 --> 00:22:08.000]   But that's a good, let's go with that. Let's go with what Christian's written.
[00:22:08.000 --> 00:22:13.000]   So three is basically more curvy and seven is a straight line component.
[00:22:13.000 --> 00:22:18.000]   But if you think of this, three has more pixels, three would have more pixels in an image.
[00:22:18.000 --> 00:22:24.000]   So three would have more black pixels as compared to seven because it covers more area.
[00:22:24.000 --> 00:22:35.000]   So what that means is then in a way, if I take the average of pixels for this image three, the average of pixels for three is going to be sort of higher.
[00:22:35.000 --> 00:22:46.000]   I'm just using standard math. So if there's more numbers that are closer to 255 in the digit three and there's less numbers that are closer to 255 in digit seven,
[00:22:46.000 --> 00:22:57.000]   then that basically means that the average, if I take the average of this whole array, then the average for digit three is going to be a bit higher than the average for digit seven.
[00:22:57.000 --> 00:23:07.000]   So that's something, I'm just going forward with this idea, that's something that's been presented as a baseline in this book, in Fastbook.
[00:23:07.000 --> 00:23:15.000]   So all this says, here is the first idea, how about we find the average pixel value for every pixel of threes and then we do the same for sevens.
[00:23:15.000 --> 00:23:26.000]   This will give us two group averages. And then when there's a new image, then we can check which group is closer to that new image.
[00:23:26.000 --> 00:23:34.000]   That's okay if it doesn't make sense, but as we go down into this book, this will be explained a lot more.
[00:23:34.000 --> 00:23:45.000]   So I can get all my images of basically sevens as seven tensors. All I can say is tensor for O in seven.
[00:23:45.000 --> 00:23:52.000]   So this is something called a list comprehension. Let me show you what a list comprehension is just quickly.
[00:23:52.000 --> 00:24:05.000]   So if I have a list, which looks like this, then I could just say X plus one for X in O.
[00:24:05.000 --> 00:24:19.000]   That will return another list. So this is just another way of creating a, instead of going something like for X in O and then X plus one gets appended to another list,
[00:24:19.000 --> 00:24:27.000]   I could have done this this way. So my L2 looks like this. And then L2 dot append X plus one.
[00:24:27.000 --> 00:24:37.000]   That's just one way of doing this. But in Python, a much faster way of doing it is just saying X plus one for X in O, which gives us the same results.
[00:24:37.000 --> 00:24:43.000]   Then it's either you go this long way or then Python makes it really easy just using list comprehensions.
[00:24:43.000 --> 00:24:51.000]   The second method is actually much faster and easier. So that's what we're using. We're just using list comprehensions here.
[00:24:51.000 --> 00:25:02.000]   So we can iterate over all the parts in sevens. Then we can open that image, convert each part into a tensor, and then we get a list of tensors.
[00:25:02.000 --> 00:25:08.000]   So tensor one, tensor two, tensor four, however many we have. Same thing we do for the threes.
[00:25:08.000 --> 00:25:20.000]   So we get tensor one, two, however many you have. But each tensor is just basically corresponds to a particular part.
[00:25:20.000 --> 00:25:32.000]   Now that this thing has been converted into a tensor, actually, let me also show you in code and how this looks like.
[00:25:32.000 --> 00:25:54.000]   So see how the seven tensors is now a list and it has a length of that's how many parts we had in sevens.
[00:25:54.000 --> 00:26:05.000]   So if I have a look at sevens, sevens has six, two, six, five parts. So this way I just can see that my seven tensors is basically six, two, six, five tensors.
[00:26:05.000 --> 00:26:19.000]   How do I know that inside this each tensor I can just index into one and you can see how the first element is now a tensor instead of it being an image.
[00:26:19.000 --> 00:26:28.000]   The reason why I'm showing these sort of things is when you're trying these things on your own at your own time and you have questions like,
[00:26:28.000 --> 00:26:35.000]   okay, what is this list comprehension, try and break that down into smaller things and then you'll be able to understand the code a lot better.
[00:26:35.000 --> 00:26:39.000]   At least that's something I do to understand code.
[00:26:39.000 --> 00:26:47.000]   So then so I can just show my image because now it's a tensor and I'm going to show the tensor.
[00:26:47.000 --> 00:26:56.000]   I'm going to use the fast.ai show image that looks like this. So you can see that that tensor actually represents the digit three.
[00:26:56.000 --> 00:27:00.000]   The next thing is, as I said, we want to be able to take the mean or we're going to be taking the average.
[00:27:00.000 --> 00:27:05.000]   So we're going to take group average. In Python, if you're in Python, you're going to take group average.
[00:27:05.000 --> 00:27:12.000]   We need to convert integers to float types. So I can stack all my seven tensors and three tensors.
[00:27:12.000 --> 00:27:19.000]   Remember that right now this is a list that looks like T1, T2, so on. It's not a single tensor.
[00:27:19.000 --> 00:27:25.000]   So what we're doing by saying torch.stack is it will convert this list into a tensor.
[00:27:25.000 --> 00:27:32.000]   So then that tensor will have a size of 6131 by 28 by 28.
[00:27:32.000 --> 00:27:39.000]   So that's just basically we're converting because now this is a list of 2D tensors.
[00:27:39.000 --> 00:27:44.000]   So what I mean by 2D tensors. So this seven tensor. So let me show you.
[00:27:44.000 --> 00:27:53.000]   Actually, it's much easier to show it in code. So as I said, my seven tensors.
[00:27:53.000 --> 00:27:58.000]   If I go into the zeroth element and I check the shape of it, it's a 28 by 28.
[00:27:58.000 --> 00:28:11.000]   Basically, it has a width of 28. It has a height of 28. So that means that this is a 2D tensor.
[00:28:11.000 --> 00:28:17.000]   Sorry, I've lost it. Here it is. So that means that this is a 2D tensor.
[00:28:17.000 --> 00:28:32.000]   And then when I say stack, all I'm saying is. So we had.
[00:28:32.000 --> 00:28:39.000]   We had 6265 2D tensors, each of which had a shape and basically a height and width of 28 by 28.
[00:28:39.000 --> 00:28:45.000]   If I say torch dot stack, it will convert this whole list of 2D tensors into a single tensor,
[00:28:45.000 --> 00:28:52.000]   which is now a 3D tensor where my first number is just saying, OK, the 6265 element.
[00:28:52.000 --> 00:28:56.000]   So that's how many we have. So I can just say stack seven.
[00:28:56.000 --> 00:29:09.000]   I can do the same thing for threes. And in that case, I get again a 3D tensor that looks something like this.
[00:29:09.000 --> 00:29:13.000]   So when I'm calling it a 3D tensor, I can also say something like a rank.
[00:29:13.000 --> 00:29:23.000]   I can also say something like a rank three tensor. So if you have a look at the number or if you have a look at the length of however many there are.
[00:29:23.000 --> 00:29:28.000]   So because this shape has three elements in it, that means it has three axis.
[00:29:28.000 --> 00:29:35.000]   That just means that this is a rank three tensor. Rank three tensor.
[00:29:35.000 --> 00:29:40.000]   These are just the PyTorch basics. Like right now, we're not really learning.
[00:29:40.000 --> 00:29:51.000]   We're not really learning more about deep learning, but this is just a sort of a background and just sort of an introduction to PyTorch and NumPy arrays and tensors.
[00:29:51.000 --> 00:29:56.000]   But spend more time with PyTorch and everything over here that's been written will make more sense.
[00:29:56.000 --> 00:30:02.000]   So rank is just a jargon. It's just the number of axes or dimensions that are there in a tensor.
[00:30:02.000 --> 00:30:08.000]   So if it's three dimensions, then that means it's a rank three tensor.
[00:30:08.000 --> 00:30:12.000]   PyTorch also has this function called endim that can give us the rank directly.
[00:30:12.000 --> 00:30:19.000]   So then the rank is three. OK. So then the next thing I do, as I said, now,
[00:30:19.000 --> 00:30:24.000]   each. So I had my let's say these are my threes.
[00:30:24.000 --> 00:30:34.000]   So each three tensor was a 28 by 28. And what I did, I took all of them.
[00:30:34.000 --> 00:30:40.000]   And I converted that into a 3D tensor, which looks something like this. So this is again, 28 by 28.
[00:30:40.000 --> 00:30:50.000]   So the length of this is I think it's like 6125. So then this threes is 6125 by 28 by 28.
[00:30:50.000 --> 00:30:57.000]   That's just how this threes tensors look like. Same for seven. So each seven tensor is again, 28 by 28.
[00:30:57.000 --> 00:31:04.000]   And it's been converted into, I think it's like 6300. So it's 6300 by 28 by 28.
[00:31:04.000 --> 00:31:12.000]   So that's the sevens. Then what I can do is I can all I need to do is I just need to take the average of the pixels.
[00:31:12.000 --> 00:31:18.000]   So all the pixels that are here, all I need is I just need number. I just need the average on what this average is going to look like.
[00:31:18.000 --> 00:31:26.000]   So I can just say. Please give me a mean and then I can if I look at that image,
[00:31:26.000 --> 00:31:34.000]   then this is how the averaged seven would look like. Same thing for three. I can just say.
[00:31:34.000 --> 00:31:40.000]   Sorry, that's just the first three. I can take the average. Here it is.
[00:31:40.000 --> 00:31:45.000]   Here's my stack three. I can just take the mean and that will show me my average three.
[00:31:45.000 --> 00:31:52.000]   So all I've done is I've taken all the images of number three and I've just taken the average.
[00:31:52.000 --> 00:31:57.000]   So when I take the average, I can just say, OK, this is how the averaged image looks like.
[00:31:57.000 --> 00:32:08.000]   So this is my ideal version of three. So any new image, if it if it looks closer to this or it has a closer association with this group average,
[00:32:08.000 --> 00:32:12.000]   then that new number is going to be a three. Same thing for seven.
[00:32:12.000 --> 00:32:17.000]   So if this is how the ideal seven looks like when I have a new number, I can just check.
[00:32:17.000 --> 00:32:28.000]   OK, is it closer to this image or is it closer to this image? Then I can just find out if my new number is a three or a seven.
[00:32:28.000 --> 00:32:38.000]   So that's that's what they're saying, basically, in the book, that's that's just what's being written so far is like now that we know that my ideal seven,
[00:32:38.000 --> 00:32:45.000]   like if I want to this is how a seven would look like. And now that I know this is what a three would look like.
[00:32:45.000 --> 00:32:49.000]   If I have a new image, then how do I know if it's going to be a three or seven?
[00:32:49.000 --> 00:32:55.000]   So to explain that even better. I know that my three looks like this.
[00:32:55.000 --> 00:33:01.000]   I know that my seven looks like that. Sorry, it doesn't have that. It just looks like this.
[00:33:01.000 --> 00:33:05.000]   So that's my three. That's my seven. And let's say I have a new image.
[00:33:05.000 --> 00:33:14.000]   So that looks something like this. Then I need to know if this new image, is it closer to this group average or is it closer to this group average?
[00:33:14.000 --> 00:33:20.000]   If I take this, this is going to be a 28 by 28 length tensor as well.
[00:33:20.000 --> 00:33:27.000]   So I need to know are these pixels, are they closer to this group average or are they closer to this group average?
[00:33:27.000 --> 00:33:35.000]   And then how can we know that? Like, what's the best way to know if this new image is closer to this group or that group?
[00:33:35.000 --> 00:33:41.000]   The easiest way is to take the mean of absolute value differences.
[00:33:41.000 --> 00:33:47.000]   So what does that mean?
[00:33:47.000 --> 00:33:51.000]   This image three looks something like this, right?
[00:33:51.000 --> 00:34:02.000]   It has values 0, 0, 200, 250, 255 and so on.
[00:34:02.000 --> 00:34:15.000]   Then when I have my new number three, this would also have values in it. 0, 0, 220, 225 and so on.
[00:34:15.000 --> 00:34:27.000]   And then a seven would have values 255, 255, 0, 0. Just some random numbers.
[00:34:27.000 --> 00:34:35.000]   This is what the average would look like. So then this represents the group of threes, this represents the group of sevens.
[00:34:35.000 --> 00:34:42.000]   And this is my new image that looks like this, right? Remember each image internally is just a number.
[00:34:42.000 --> 00:34:52.000]   So then what I can do is I can take this pixel, I can check the difference between this pixel and this pixel, this pixel and this pixel and each single pixel.
[00:34:52.000 --> 00:35:07.000]   If I have a difference vector with threes, that would look something like that.
[00:35:07.000 --> 00:35:16.000]   So I can say the difference between 0 and 0 is 0. The difference here is again 0, but the difference here is minus 200.
[00:35:16.000 --> 00:35:23.000]   So similarly, I can calculate the differences and I can do the same thing over here. I can calculate the differences here.
[00:35:23.000 --> 00:35:30.000]   So I can say 0 and difference here is minus 200. The difference between these two is minus 200.
[00:35:30.000 --> 00:35:37.000]   The difference between this and that is just 0. And similarly, I can calculate all the differences.
[00:35:37.000 --> 00:35:42.000]   So that's what this is doing. That's the first thing. And then I can just take the average.
[00:35:42.000 --> 00:35:52.000]   So if I take the average distance, basically the difference, if this difference comes out to be 2.5 and this difference comes out to be,
[00:35:52.000 --> 00:36:00.000]   if I just take the average of all of these numbers and this difference comes out to be 10.0, then that means 2.5 is a lower number,
[00:36:00.000 --> 00:36:08.000]   which means that this new image is much closer to the group of threes, which means that this new image can be classified as a three.
[00:36:08.000 --> 00:36:16.000]   I hope this makes sense. So that's the one way of checking. This is called mean absolute difference.
[00:36:16.000 --> 00:36:23.000]   All I'm doing is I'm just checking the differences. But the one thing I've done wrong here, or the one thing that's incorrect,
[00:36:23.000 --> 00:36:33.000]   is that see how this difference is minus 200. If I take the difference of this number and let's say this was 100,
[00:36:33.000 --> 00:36:38.000]   then that would be 120. So I have a negative difference. I have a positive number.
[00:36:38.000 --> 00:36:46.000]   If I'm taking the average, the negatives and the positives will cancel out each other, which is going to be a problem.
[00:36:46.000 --> 00:36:53.000]   So what I can do is I can just take the modulus. This is just simple math.
[00:36:53.000 --> 00:36:57.000]   So I can instead of just saying minus 200, this becomes 200, this becomes 120.
[00:36:57.000 --> 00:37:05.000]   I basically convert every negative number into a positive number. And then I can calculate the differences between the two.
[00:37:05.000 --> 00:37:09.000]   The same thing you can do is you can check the mean of the square of differences.
[00:37:09.000 --> 00:37:14.000]   So you can take the differences still, but you can, after taking a difference,
[00:37:14.000 --> 00:37:17.000]   you can calculate the square of it and then you can calculate the mean.
[00:37:17.000 --> 00:37:20.000]   And this is something that's called as a root mean square error.
[00:37:20.000 --> 00:37:27.000]   So the first thing is called as an Elvin norm. The second thing is called an RMSE.
[00:37:27.000 --> 00:37:32.000]   The RMSE, sorry, the Elvin norm looks something like this.
[00:37:32.000 --> 00:37:38.000]   So as I said, you take the differences. So I'm just taking the pixel by pixel difference,
[00:37:38.000 --> 00:37:45.000]   which is being happened here, a3 minus mean 3. And then I take the modulus or I just convert every negative number into a positive number.
[00:37:45.000 --> 00:37:50.000]   And then I can calculate the mean. The second thing is you can take the differences,
[00:37:50.000 --> 00:37:55.000]   you can square it and then you can take the mean. So this is the root mean square error.
[00:37:55.000 --> 00:38:04.000]   If any of this doesn't make sense or if any of this is new to you,
[00:38:04.000 --> 00:38:17.000]   in this book, there's this resource mentioned in Khan Academy that says introduction to square roots.
[00:38:17.000 --> 00:38:23.000]   So then what happens is when we take a new image, what they say is in both cases,
[00:38:23.000 --> 00:38:28.000]   the distances between our new number 3 and the ideal 3 is less than the distance to 7,
[00:38:28.000 --> 00:38:44.000]   which means that we can classify this 3 as basically the number 3. I'll take questions now.
[00:38:44.000 --> 00:38:49.000]   Please ignore cosine similarity for now. We're just looking at the closest.
[00:38:49.000 --> 00:38:56.000]   We're just looking at a simple absolute or just a mean of square differences.
[00:38:56.000 --> 00:39:02.000]   Does anybody have any questions so far? Let me just ask this way.
[00:39:02.000 --> 00:39:09.000]   Can you just post on basically the report if so far what we've explained does make sense?
[00:39:09.000 --> 00:39:30.000]   Otherwise, I can spend like five more minutes and try and explain this even in an easier way.
[00:39:30.000 --> 00:39:37.000]   OK, I'm just going to assume that what I've explained so far makes sense.
[00:39:37.000 --> 00:39:45.000]   So that's just the baseline. The next thing we're looking at is NumPy arrays and PyTorch tensors.
[00:39:45.000 --> 00:39:50.000]   So why do we need to care about NumPy and why do we need to care about PyTorch?
[00:39:50.000 --> 00:39:54.000]   Plain Python is really slow. And if you want to be able to do deep learning,
[00:39:54.000 --> 00:39:58.000]   we need to be able to do the operations really fast.
[00:39:58.000 --> 00:40:02.000]   And NumPy and PyTorch are both wrappers around the language C.
[00:40:02.000 --> 00:40:12.000]   So C is a much faster language and it can do it can basically do many thousands of times faster operations than using pure Python.
[00:40:12.000 --> 00:40:20.000]   So that's one reason why we convert everything either to a NumPy array or PyTorch tensor.
[00:40:20.000 --> 00:40:35.000]   But the major difference between PyTorch and NumPy is that in PyTorch, you can do things on the GPU.
[00:40:35.000 --> 00:40:41.000]   So in PyTorch, the tensors or everything that we're creating can also live on the GPU.
[00:40:41.000 --> 00:40:49.000]   But whereas for NumPy, that's not the case. NumPy can only work on CPU.
[00:40:49.000 --> 00:40:55.000]   And the next thing is what PyTorch can do is it can automatically calculate the derivatives of operations.
[00:40:55.000 --> 00:41:07.000]   So let me explain that. This is just examples of how basically how data looks like, how you convert it to an array, how you convert it to an array.
[00:41:07.000 --> 00:41:13.000]   So if I have a data that looks something like this, which is a list of lists, I can convert it into an array.
[00:41:13.000 --> 00:41:16.000]   I can convert it into a tensor. If I look at the array, it looks like this.
[00:41:16.000 --> 00:41:20.000]   If I look at the tensor, it looks like this. So they're both looking very similar.
[00:41:20.000 --> 00:41:29.000]   But again, tensor has some more extra functionality, like taking the derivative of things, or it can it has extra functionality that it can.
[00:41:29.000 --> 00:41:35.000]   It can basically have tensors that live on the GPU. You can select a row.
[00:41:35.000 --> 00:41:38.000]   It's very similar, like it's just Python. You can do indexing.
[00:41:38.000 --> 00:41:43.000]   So you can select the second row that looks like this. This is, again, just basic Python.
[00:41:43.000 --> 00:41:50.000]   You can select the second column. This looks like that.
[00:41:50.000 --> 00:42:01.000]   And that's pretty much it, like tensors have a type. So this is just so far, all we've done is we've just had a look at the basics of NumPy arrays and tensors.
[00:42:01.000 --> 00:42:09.000]   Something I want to briefly touch upon is also broadcasting.
[00:42:09.000 --> 00:42:19.000]   So something that happens, I won't go into the exact detail of what's been mentioned in this book, but I'll explain broadcasting in another way.
[00:42:19.000 --> 00:42:48.000]   So what happens is, if you try -- actually, let me show you in Python. If you have a list that looks something like...
[00:42:48.000 --> 00:43:04.000]   If you have a list that looks something like that, and I'm just using standard Python, then if I'm trying to add number one to it, it's going to give me an error.
[00:43:04.000 --> 00:43:11.000]   So what's happening is you have a list of numbers that looks like one, two, three, four, five.
[00:43:11.000 --> 00:43:21.000]   And I'm then trying to add a number one to this list. It's going to give me an error because it's going to say that you can only add list to list, but you can't add a number to a list.
[00:43:21.000 --> 00:43:31.000]   But what if I had converted this to an array instead? I'm just showing you what broadcasting looks like.
[00:43:31.000 --> 00:43:42.000]   In that case, that lets me add this number one to this whole NumPy array. In fact, if this was a tensor, then that would have let me do it as well.
[00:43:42.000 --> 00:43:52.000]   So what's happening here? What's this? What's different between adding this number one to this list or adding this number one to a NumPy array?
[00:43:52.000 --> 00:44:02.000]   So what NumPy and PyTorch do differently is they use something called broadcasting.
[00:44:02.000 --> 00:44:25.000]   So what broadcasting does is if you have a list that looks like this, and you're trying to add a single number one, it will convert it into a list of duplicate items or an array of duplicate items.
[00:44:25.000 --> 00:44:33.000]   And then you can add the two together. So it's basically broadcasting a single number to whatever the length of my list is.
[00:44:33.000 --> 00:44:41.000]   And then you can add the two together. So then when you add them two together, it adds one and one, two and one, three and one, four and one, five and one.
[00:44:41.000 --> 00:44:49.000]   So you get the output as two, three, four, five, six. But normal Python list can't do something like broadcasting.
[00:44:49.000 --> 00:44:57.000]   And that's just basically what broadcasting means.
[00:44:57.000 --> 00:45:11.000]   So what I've explained so far then...
[00:45:11.000 --> 00:45:25.000]   I'm just going to show in code everything that I've explained so far. So we just had our first pixel similarity.
[00:45:25.000 --> 00:45:54.000]   This is where we were.
[00:45:54.000 --> 00:46:04.000]   Okay.
[00:46:04.000 --> 00:46:06.000]   This is where we are.
[00:46:06.000 --> 00:46:11.000]   So right now, what we want to do in the end is we want to also calculate the accuracy.
[00:46:11.000 --> 00:46:17.000]   So what we've done is our basic approach of being able to classify a number three or a seven.
[00:46:17.000 --> 00:46:25.000]   So if you have a new image, we can basically check how close it is to the average of number threes or how close it is to the average seven.
[00:46:25.000 --> 00:46:33.000]   The ideal seven. Then what we want to do is we want to be able to use this approach and we want to be able to test what the accuracy is.
[00:46:33.000 --> 00:46:38.000]   So what I do is I then go into my list of parts.
[00:46:38.000 --> 00:46:48.000]   And I go and I have a look at what the output of this is. So let me show you.
[00:46:48.000 --> 00:46:55.000]   So I have a thousand valid images. As I said, the train was in the train folder and valid images are in the valid folder.
[00:46:55.000 --> 00:46:59.000]   I have about a thousand and ten valid images for the digit three.
[00:46:59.000 --> 00:47:08.000]   Then what I can do is I can again use my list comprehension that looks like this and I can convert everything into a tensor.
[00:47:08.000 --> 00:47:28.000]   So my first element of this then becomes a tensor. And this is a list.
[00:47:28.000 --> 00:47:36.000]   So this is a list of length, one thousand and ten. And then I can divide everything by two fifty five because it converts everything to a float.
[00:47:36.000 --> 00:47:45.000]   I can do the same thing for my sevens and then I can check. OK, my valid three tens is basically a torch tensor now because I'm using torch dot stack,
[00:47:45.000 --> 00:47:50.000]   which we've already looked at before. It just converts a list of 2D tensors into a 3D tensor.
[00:47:50.000 --> 00:48:03.000]   So I can see that all my images of number three or the digit three have been converted into this tensor of thousand and ten by twenty eight by twenty eight.
[00:48:03.000 --> 00:48:11.000]   And the same thing goes for sevens. All my valid images for the digit seven have been converted into this tensor of thousand twenty eight by twenty eight.
[00:48:11.000 --> 00:48:18.000]   Thousand twenty eight by twenty eight by twenty eight. Then what I want to do is I want to for each of these,
[00:48:18.000 --> 00:48:25.000]   remember that we want to classify each of these validation images, each of these validation threes and each of these validation sevens,
[00:48:25.000 --> 00:48:34.000]   if they are either a three or a seven. Then the next thing that the book tells us to do is I already showed you what this means.
[00:48:34.000 --> 00:48:42.000]   This is just taking the difference between each of the pixels.
[00:48:42.000 --> 00:49:11.000]   To clarify. So this is what this looks like.
[00:49:11.000 --> 00:49:22.000]   That's not a good representation because it doesn't have.
[00:49:22.000 --> 00:49:29.000]   Right, that's better. So this is what my new image was, a three. If I use show image.
[00:49:29.000 --> 00:49:35.000]   And I say a three, and then that's an image of a three. And if I do.
[00:49:35.000 --> 00:49:42.000]   Show image on mean three, and then that's how my ideal three would look like.
[00:49:42.000 --> 00:49:51.000]   So I'm just trying to compare a new image which looks like this. I'm just trying to compare this new image to.
[00:49:51.000 --> 00:49:56.000]   I'm just trying to compare this new image to either that ideal three or that ideal seven.
[00:49:56.000 --> 00:50:03.000]   So what I can do is then, as I said, each number or each image inside is a 2D array.
[00:50:03.000 --> 00:50:08.000]   Then I can take the difference between these two numbers. I can take the difference between these two numbers.
[00:50:08.000 --> 00:50:15.000]   I can take the difference between these two numbers. And I can take and I can call the absolute and then I can take the mean.
[00:50:15.000 --> 00:50:19.000]   So if I do that, I can just say mean distance.
[00:50:19.000 --> 00:50:30.000]   And then that tells me, OK, the mean distance between this new image three and this mean difference between this ideal three is a 0.114.
[00:50:30.000 --> 00:50:36.000]   And I can just say same thing to check for seven. It's 0.1586.
[00:50:36.000 --> 00:50:41.000]   Because the distance of this new image is higher to the sevens and it's lower to the threes.
[00:50:41.000 --> 00:50:47.000]   We can just say that this new image should be a three. Does that make sense?
[00:50:47.000 --> 00:51:02.000]   If it doesn't, just let me know and I can explain that.
[00:51:02.000 --> 00:51:05.000]   Is the difference element wise for the tensor? Yes.
[00:51:05.000 --> 00:51:09.000]   So when we're doing the best way to check would be just try something like this. Don't take the mean.
[00:51:09.000 --> 00:51:14.000]   So just try something like MNIST distance. And then you can just say MNIST distance.
[00:51:14.000 --> 00:51:17.000]   And then you can see how it's showing you the difference for each element.
[00:51:17.000 --> 00:51:21.000]   If I'm going A3, which looks like this, and I'm going mean three, that looks like this.
[00:51:21.000 --> 00:51:26.000]   And then I can actually check the difference for the exact same numbers.
[00:51:26.000 --> 00:51:29.000]   So I can just basically it's just it's just for every element.
[00:51:29.000 --> 00:51:33.000]   And then we take the and then we take the mean.
[00:51:33.000 --> 00:51:39.000]   So we first calculate all the differences as I was showing you.
[00:51:39.000 --> 00:51:55.000]   As I was showing you over here, we first calculate each of the pixel differences and then we take the average.
[00:51:55.000 --> 00:51:57.000]   So that's that. So that's just the basic idea.
[00:51:57.000 --> 00:52:04.000]   I think if you if you go back and you try and look at this part of the notebook, I think this will all make much more sense.
[00:52:04.000 --> 00:52:12.000]   But then what we want to do is we don't want to the next thing is what we want to do is we don't want to actually just check the distance of this one image.
[00:52:12.000 --> 00:52:17.000]   But we want to check the distance of all my validation images. So my validation image.
[00:52:17.000 --> 00:52:26.000]   So so far I know that now there is a way to check the basically this MNIST distance or how close a new image is to the group three or how close new images to the group seven.
[00:52:26.000 --> 00:52:34.000]   But we want to be able to check this distance for a thousand and ten images for threes.
[00:52:34.000 --> 00:52:39.000]   And we want to be able to check this difference for a thousand and twenty eight images for sevens.
[00:52:39.000 --> 00:52:45.000]   Because remember, basically at the end, we want to calculate accuracy. So I can just say do something like this.
[00:52:45.000 --> 00:52:50.000]   MNIST distance valid three tens and then mean three.
[00:52:50.000 --> 00:52:55.000]   So what this PyTorch using broadcasting as I've already explained what broadcasting is.
[00:52:55.000 --> 00:53:04.000]   What it will do is. It will then calculate the distance of each of the validation images threes with that mean three.
[00:53:04.000 --> 00:53:09.000]   So I can have my valid three distance here and I can check the shape. It's a shape thousand and ten.
[00:53:09.000 --> 00:53:20.000]   Because for each image that's in my validation set, it's going to give me how far it is from from this mean three tensor.
[00:53:20.000 --> 00:53:30.000]   So that's that's the basic idea of of using broadcasting. As I've said already, I've explained this in the before that you can convert thing to a tensor and then you can add to it.
[00:53:30.000 --> 00:53:36.000]   If this was Python list, it would give us an error. So see this.
[00:53:36.000 --> 00:53:42.000]   So this is just explained broadcasting so far.
[00:53:42.000 --> 00:53:53.000]   So then the next thing is. I just want to now have a look at this so I can now.
[00:53:53.000 --> 00:53:59.000]   This is where everything will come together. I can now calculate.
[00:53:59.000 --> 00:54:04.000]   My valid seven distances, if I say this is seven.
[00:54:04.000 --> 00:54:09.000]   I should be just able to do. This.
[00:54:09.000 --> 00:54:19.000]   So see that. So now for every validation image.
[00:54:19.000 --> 00:54:23.000]   For every validation image, then I've converted.
[00:54:23.000 --> 00:54:30.000]   I've calculated the difference of. It's much easier. Sorry for me to write it here.
[00:54:30.000 --> 00:54:42.000]   So I have. Three's here and these are my all my images I have, let's say, 1010 of these and I have my sevens here.
[00:54:42.000 --> 00:54:46.000]   These are my 1028 images.
[00:54:46.000 --> 00:54:54.000]   Then I have my.
[00:54:54.000 --> 00:54:59.000]   I have my ideal group of threes and ideal group of seven. So this is three. This is seven.
[00:54:59.000 --> 00:55:03.000]   Then for each of these, I'm calculating the difference, how close it is to three.
[00:55:03.000 --> 00:55:11.000]   And for each of these, I'm calculating how close it is to seven. So if I can do that, then I can check if my.
[00:55:11.000 --> 00:55:15.000]   To see, and if I go, I can check. There's this function I can say is three.
[00:55:15.000 --> 00:55:26.000]   If the distance of my new image. With this ideal three is less than the distance of my new image with this ideal seven.
[00:55:26.000 --> 00:55:34.000]   In that case, what I have is going to be the number three.
[00:55:34.000 --> 00:55:41.000]   So I can just check. OK, that's it. I can convert my new image and just check if it is basically a three or not.
[00:55:41.000 --> 00:55:46.000]   So that becomes my label and I can then convert that into a flow.
[00:55:46.000 --> 00:55:52.000]   So I can then check for all of my validation images that are in folder.
[00:55:52.000 --> 00:55:57.000]   All of my validation images with the image three and I can just convert them and check if they are three or not.
[00:55:57.000 --> 00:56:03.000]   So you can see how it will tell us that many of them are threes or not.
[00:56:03.000 --> 00:56:14.000]   Then I can calculate the accuracy. I can calculate and this basic approach basically is then able to classify the threes and seven.
[00:56:14.000 --> 00:56:28.000]   So if it's able to tell the threes by 91 percent and it's able to tell the sevens by 98 percent and the average accuracy of my classifier or basically my this basic classifier that we've created is 95 percent accurate.
[00:56:28.000 --> 00:56:38.000]   So that's a pretty good start. We're getting above 95 percent, above 90 percent accuracy on both threes and sevens.
[00:56:38.000 --> 00:57:03.000]   So now we'll take questions. So what we've discussed on this basic classifier.
[00:57:03.000 --> 00:57:09.000]   Could you please remind us, could you please tell the audience about the FastAI and Hugging Face studying group as well?
[00:57:09.000 --> 00:57:28.000]   Okay, yeah, sure. So for those, for everybody that's interested, I will go to Sanyam's tweet about it.
[00:57:28.000 --> 00:57:34.000]   So what's happening is Hugging Face just basically released a new course.
[00:57:34.000 --> 00:57:52.000]   So let me. And what's happening at Wits and Biases is that a few people are coming together and we're going to start with another NLP course that's basically using Hugging Face and it will explain what Hugging Face is and how Hugging Face transformers can be used.
[00:57:52.000 --> 00:58:02.000]   But the key idea is then to understand how Hugging Face works and then use that transformers library and see how it can be integrated into FastAI.
[00:58:02.000 --> 00:58:12.000]   So the more details can be found here. I'll just share this with everybody on Zoom.
[00:58:12.000 --> 00:58:18.000]   So if you're interested, please sign up. I think it's going to be another great event.
[00:58:18.000 --> 00:58:26.000]   After using the pixel density, are we going to use the YOLO algorithm? That's too far, going too far ahead.
[00:58:26.000 --> 00:58:32.000]   This is again something separate. But can you introduce Wits and Biases for experiments tracking and integrating with FastAI?
[00:58:32.000 --> 00:58:42.000]   I guess this question was raised on the forums. I think that's a really good point. Can definitely do, but we need to be able to train models first to be able to compare experiments.
[00:58:42.000 --> 00:58:48.000]   So that's something that will definitely be coming in the coming lectures.
[00:58:48.000 --> 00:59:00.000]   Three is more likely to have curves. We've already looked at that.
[00:59:00.000 --> 00:59:14.000]   That's a good point. Thanks, Xavier. Match average pixel. Sorry, what's that? Oh, that's the answer on how we can check. Yes, that's what we did.
[00:59:14.000 --> 00:59:22.000]   We can make a flat array for both and compare. That's exactly kind of the direction that we headed.
[00:59:22.000 --> 00:59:28.000]   Place at which the different values tend to occur.
[00:59:28.000 --> 00:59:35.000]   The number is equal in the surface percentage that's covered by... That's a good point.
[00:59:35.000 --> 00:59:44.000]   Yes, that's exactly what I said. A number three would cover more surface, it would have a higher average.
[00:59:44.000 --> 00:59:51.000]   I'm sorry, I don't understand. I thought of two columns, count of numbers above 10 and count of numbers.
[00:59:51.000 --> 00:59:58.000]   Oh, right. Okay. But that's basically calculating the average. If you calculate the average, you'd kind of be doing the same thing.
[00:59:58.000 --> 01:00:07.000]   You'd kind of be... If the count of numbers above 10 or if the count of numbers above 230 is more, then the average is going to be higher.
[01:00:07.000 --> 01:00:15.000]   So in a way, we're kind of doing the same thing.
[01:00:15.000 --> 01:00:21.000]   Thanks, Vinayak. Yes, that's exactly what we did. And then we can calculate the Euclidean distance.
[01:00:21.000 --> 01:00:30.000]   Instead of calling it Euclidean distance, let's just say we can calculate the difference in the pixels and we can just go from there.
[01:00:30.000 --> 01:00:37.000]   How does Toster stack work for RGB images? Again, just have a look. Try opening an RGB image and see how that would go.
[01:00:37.000 --> 01:00:47.000]   It will still stack all the images. So instead of converting like a 1D tensor, it will convert into a 3D tensor.
[01:00:47.000 --> 01:00:57.000]   If we want to compare a new image with a mean, then we can use cosine similarity. Skipping that one for now because we will get back to that later.
[01:00:57.000 --> 01:01:02.000]   This one has been answered. Can you explain what is L1 and L2 norm?
[01:01:02.000 --> 01:01:07.000]   Why is it used actually in the task of calculating?
[01:01:07.000 --> 01:01:18.000]   Oh, sorry. So then L1 and L2 norm are nothing complicated.
[01:01:18.000 --> 01:01:29.000]   I think you're doing -- the question comes from -- it's not L1 norm, by the way. We're using L1 loss in PyTorch is what this is called.
[01:01:29.000 --> 01:01:36.000]   We've used L1 loss or L1 norm, but in PyTorch it's just called L1 loss.
[01:01:36.000 --> 01:01:46.000]   But this idea of calculating the differences between the pixels -- okay. Let me try and explain that better.
[01:01:46.000 --> 01:01:53.000]   So now you know what a 3 looks like. So far we know what a 3 looks like. A 3 looks like this. A 7 looks like this.
[01:01:53.000 --> 01:02:00.000]   A 3 would have some numbers in here. So I'm just going to say some numbers. I'm not going to put them in.
[01:02:00.000 --> 01:02:10.000]   And a 7 would have some numbers in here as well. This is what we know a 3 looks like. So 3 is on the left. 7 is on the right.
[01:02:10.000 --> 01:02:23.000]   When we have a new image, then we can calculate the differences pixel by pixel. So we can calculate the pixel by pixel differences for each of these pixels for 3,
[01:02:23.000 --> 01:02:32.000]   which will give us this pixel difference. I'm just going to call it pixel difference with 3.
[01:02:32.000 --> 01:02:33.800]   And I can also do the same thing,
[01:02:33.800 --> 01:02:37.360]   calculate the pixel by pixel difference,
[01:02:37.360 --> 01:02:40.200]   which will give me the pixel difference for seven.
[01:02:40.200 --> 01:02:44.600]   So I'm just gonna call it P seven, pixel difference seven.
[01:02:44.600 --> 01:02:45.880]   Now, if you can think of,
[01:02:45.880 --> 01:02:49.960]   some numbers would be positive, negative,
[01:02:49.960 --> 01:02:52.660]   positive, positive, and negative,
[01:02:52.660 --> 01:02:55.200]   positive, positive, negative, negative, positive.
[01:02:55.200 --> 01:02:56.740]   So cause some numbers are positive
[01:02:56.740 --> 01:02:58.360]   and some numbers are negative.
[01:02:58.360 --> 01:02:59.860]   If you take the average of this
[01:02:59.860 --> 01:03:01.640]   and the positive and negative numbers
[01:03:01.640 --> 01:03:04.880]   are going to basically collide with each other,
[01:03:04.880 --> 01:03:06.360]   or when you take the average,
[01:03:06.360 --> 01:03:07.920]   it's not gonna give you a good result
[01:03:07.920 --> 01:03:09.460]   cause that's not a good representation.
[01:03:09.460 --> 01:03:12.880]   That's not how, it will not give you the correct result.
[01:03:12.880 --> 01:03:14.880]   So something you wanna do is,
[01:03:14.880 --> 01:03:17.600]   rather than just taking the difference,
[01:03:17.600 --> 01:03:19.760]   what you could do is you could take the difference,
[01:03:19.760 --> 01:03:23.760]   but also add a modulus or an absolute operation.
[01:03:23.760 --> 01:03:25.880]   What it will do is it will basically,
[01:03:25.880 --> 01:03:28.240]   if the difference, when you're adding the modulus,
[01:03:28.240 --> 01:03:29.640]   if the difference is minus 100,
[01:03:29.640 --> 01:03:32.200]   then adding a modulus will just convert it to a hundred.
[01:03:32.200 --> 01:03:36.520]   So everything then becomes positive over here too.
[01:03:36.520 --> 01:03:38.520]   And then it's easier for you to compare
[01:03:38.520 --> 01:03:41.280]   the two basically differences.
[01:03:41.280 --> 01:03:43.760]   So when we, in Python,
[01:03:43.760 --> 01:03:47.720]   when we checking the MNIST difference,
[01:03:47.720 --> 01:03:53.680]   MNIST distance, sorry.
[01:03:53.680 --> 01:03:54.920]   When we're checking this,
[01:03:54.920 --> 01:03:57.160]   this basically MNIST distance,
[01:03:57.160 --> 01:03:58.780]   we're taking the absolute.
[01:03:58.780 --> 01:04:01.440]   This is basically L1 norm.
[01:04:01.440 --> 01:04:12.560]   And if I would have like done the square of this,
[01:04:12.560 --> 01:04:19.140]   then this would have been L2 norm.
[01:04:19.140 --> 01:04:21.680]   So the next thing then,
[01:04:21.680 --> 01:04:23.520]   so right now I'm just taking the modulus
[01:04:23.520 --> 01:04:25.720]   that converts this into a positive number.
[01:04:25.720 --> 01:04:26.740]   The next thing I could have done is
[01:04:26.740 --> 01:04:28.600]   I could have taken the square of this,
[01:04:28.600 --> 01:04:30.320]   then that would have also converted this
[01:04:30.320 --> 01:04:32.420]   into a positive number.
[01:04:32.420 --> 01:04:35.840]   So if you take the square of the difference,
[01:04:35.840 --> 01:04:37.120]   then that's called L2 norm.
[01:04:37.120 --> 01:04:38.720]   So I hope that explains the difference
[01:04:38.720 --> 01:04:40.200]   between L1 and L2 norm.
[01:04:40.200 --> 01:04:49.200]   Wouldn't we want to eliminate the white rows and columns
[01:04:49.200 --> 01:04:51.560]   and then stretch the images and resize them?
[01:04:51.560 --> 01:04:54.060]   They already, all the images are the same size.
[01:04:54.060 --> 01:04:55.440]   They're all 28 by 28.
[01:04:58.360 --> 01:04:59.600]   If I got that correctly.
[01:04:59.600 --> 01:05:03.880]   I know the book talks about the mean minus one,
[01:05:03.880 --> 01:05:04.720]   minus two part.
[01:05:04.720 --> 01:05:05.540]   Could you explain it again?
[01:05:05.540 --> 01:05:06.540]   Sure can.
[01:05:06.540 --> 01:05:09.820]   Is there a Slack channel for FastAI Hugging Face Study Group?
[01:05:09.820 --> 01:05:12.080]   I don't think there is one yet,
[01:05:12.080 --> 01:05:15.340]   but I think we will get back to you when there is one.
[01:05:15.340 --> 01:05:19.480]   So the thing you're asking is
[01:05:19.480 --> 01:05:22.560]   what does this mean minus one, minus two mean?
[01:05:22.560 --> 01:05:24.440]   Okay, so let's just,
[01:05:24.440 --> 01:05:27.880]   I think the easiest way to understand this
[01:05:28.600 --> 01:05:32.620]   is not calculate the mean, right?
[01:05:32.620 --> 01:05:38.600]   And let me just calculate the MNIST distance.
[01:05:38.600 --> 01:05:41.840]   So I'm just going to say distance equals this.
[01:05:41.840 --> 01:05:46.840]   So now my distance is remember a 28 by 28 array
[01:05:46.840 --> 01:05:49.440]   'cause it's going to calculate the pixel difference
[01:05:49.440 --> 01:05:51.640]   for each of the pixels.
[01:05:51.640 --> 01:05:53.280]   So that's what distance is.
[01:05:54.000 --> 01:05:57.500]   (computer mouse clicking)
[01:05:57.500 --> 01:06:03.680]   Now this distance is of shape 28 by 28.
[01:06:03.680 --> 01:06:09.520]   When I take dot mean and I say minus one, minus two,
[01:06:09.520 --> 01:06:11.920]   it will give me an error
[01:06:11.920 --> 01:06:14.880]   because the number of dimensions of this is higher.
[01:06:14.880 --> 01:06:18.840]   So what minus one basically means is
[01:06:20.520 --> 01:06:23.320]   you're just taking the distance of the last axis.
[01:06:23.320 --> 01:06:24.620]   So when you're taking the,
[01:06:24.620 --> 01:06:29.860]   let me explain this better over here.
[01:06:29.860 --> 01:06:33.840]   When you have three axis,
[01:06:33.840 --> 01:06:36.200]   so remember how we had three axis.
[01:06:36.200 --> 01:06:40.120]   Also I've made a mistake.
[01:06:40.120 --> 01:06:43.960]   Let me go and do it this way.
[01:06:43.960 --> 01:06:45.560]   Let's call this distance,
[01:06:45.560 --> 01:06:49.960]   in which case the distance has a shape of this
[01:06:49.960 --> 01:06:51.160]   and then this will work.
[01:06:51.160 --> 01:07:08.940]   And then this should work too.
[01:07:08.940 --> 01:07:14.680]   Yep, cool.
[01:07:14.680 --> 01:07:18.040]   Okay.
[01:07:18.040 --> 01:07:20.640]   So then what minus one and minus two does is
[01:07:20.640 --> 01:07:21.840]   when you have three axis,
[01:07:21.840 --> 01:07:25.480]   so you have something like 110 by 28 by 28.
[01:07:25.480 --> 01:07:27.320]   So this looks like this, right?
[01:07:27.320 --> 01:07:30.280]   If you're trying to represent it
[01:07:30.280 --> 01:07:31.980]   or if you're trying to think of it visually,
[01:07:31.980 --> 01:07:36.160]   you have 1010 of these images with 28, high 28.
[01:07:36.160 --> 01:07:39.400]   Then what you wanna do is you wanna get to a point where
[01:07:39.400 --> 01:07:42.240]   you take the mean across the height.
[01:07:42.240 --> 01:07:45.400]   So all these numbers get averaged across the height
[01:07:45.400 --> 01:07:47.480]   and you take the mean across the width.
[01:07:47.480 --> 01:07:48.400]   So what you're left with,
[01:07:48.400 --> 01:07:49.960]   you're just left with a single number.
[01:07:49.960 --> 01:07:53.440]   If you take the mean of this whole array,
[01:07:53.440 --> 01:07:55.280]   it will give you one number, right?
[01:07:55.280 --> 01:07:57.120]   But then there's so many of these arrays,
[01:07:57.120 --> 01:07:59.800]   there's like 1010 of these.
[01:07:59.800 --> 01:08:01.780]   So each, every time you take a mean,
[01:08:01.780 --> 01:08:03.420]   it will give you a single number.
[01:08:03.420 --> 01:08:05.960]   So you're left with 110 numbers,
[01:08:05.960 --> 01:08:10.040]   but what this minus one, minus one and minus two means,
[01:08:10.040 --> 01:08:12.080]   minus one means the last axis.
[01:08:12.080 --> 01:08:13.800]   So that just means the width.
[01:08:13.800 --> 01:08:15.920]   Minus two means the second last axis.
[01:08:15.920 --> 01:08:17.180]   That just means the height.
[01:08:17.180 --> 01:08:18.820]   So it's just telling PyTorch in a way
[01:08:18.820 --> 01:08:21.620]   that you're taking the mean across the height and width.
[01:08:21.620 --> 01:08:29.720]   All right, that's it then for today.
[01:08:29.720 --> 01:08:32.800]   We're gonna continue with stochastic gradient descent,
[01:08:32.800 --> 01:08:36.440]   but for now I will hand it over to Parul.
[01:08:36.440 --> 01:08:39.560]   Parul is gonna be sharing how to write publicly
[01:08:39.560 --> 01:08:42.320]   and she's gonna be sharing some expert advice
[01:08:42.320 --> 01:08:44.800]   and how to have a compelling data science career
[01:08:44.800 --> 01:08:46.840]   by sharing publicly.
[01:08:47.580 --> 01:08:48.700]   So over to you, Parul.
[01:08:48.700 --> 01:08:55.140]   - Hi Aman, can you hear?
[01:08:55.140 --> 01:08:59.700]   - Yes, I can hear you.
[01:08:59.700 --> 01:09:00.540]   - All right.
[01:09:00.540 --> 01:09:05.020]   Yeah, so thanks for the session, Aman.
[01:09:05.020 --> 01:09:07.840]   I am also, I regularly join the session.
[01:09:07.840 --> 01:09:12.700]   So I'll just quickly share my screen,
[01:09:12.700 --> 01:09:14.020]   switch on my video.
[01:09:14.020 --> 01:09:14.860]   All right.
[01:09:14.920 --> 01:09:17.680]   (mouse clicking)
[01:09:17.680 --> 01:09:21.460]   It seems I cannot share my screen.
[01:09:21.460 --> 01:09:25.820]   - One second.
[01:09:25.820 --> 01:09:30.040]   Actually, guys, that's something you could help me with.
[01:09:30.040 --> 01:09:32.080]   I know you've helped me with that in the past.
[01:09:32.080 --> 01:09:32.920]   - Okay, okay.
[01:09:32.920 --> 01:09:34.600]   It's possible.
[01:09:34.600 --> 01:09:40.600]   All right, so there's a lot of junk on my system
[01:09:40.600 --> 01:09:43.040]   because I've been working on lots of things.
[01:09:43.040 --> 01:09:44.420]   So let me just quickly.
[01:09:45.240 --> 01:09:50.240]   So most of it, I think I did share in the forum
[01:09:50.240 --> 01:09:55.480]   or the discussion post as to how I approach writing
[01:09:55.480 --> 01:09:57.260]   and why it is important.
[01:09:57.260 --> 01:09:58.920]   So if you're gonna read this,
[01:09:58.920 --> 01:10:02.400]   you are going to get a gist of like how I plan things
[01:10:02.400 --> 01:10:04.560]   and how I write.
[01:10:04.560 --> 01:10:06.360]   And something that I want to share with everybody
[01:10:06.360 --> 01:10:09.120]   is everybody has a very different path of writing
[01:10:09.120 --> 01:10:10.280]   and learning.
[01:10:10.280 --> 01:10:14.820]   And so I think it's okay to be influenced by others,
[01:10:14.820 --> 01:10:17.300]   but then don't get pressurized.
[01:10:17.300 --> 01:10:18.780]   Like if somebody is writing,
[01:10:18.780 --> 01:10:21.220]   like you're absolutely beginner in this
[01:10:21.220 --> 01:10:24.340]   and you see people writing on very complicated,
[01:10:24.340 --> 01:10:26.460]   deep learning stuff, the neural networks
[01:10:26.460 --> 01:10:28.340]   and all those things that are coming
[01:10:28.340 --> 01:10:29.180]   and you feel, you know,
[01:10:29.180 --> 01:10:30.340]   I don't even understand what that means.
[01:10:30.340 --> 01:10:32.540]   It's absolutely all right.
[01:10:32.540 --> 01:10:37.540]   And I'll just show you how I have written on topics
[01:10:38.420 --> 01:10:41.040]   which are like absolutely diverse
[01:10:41.040 --> 01:10:43.160]   and as simple as things like,
[01:10:43.160 --> 01:10:46.240]   so my idea is always to,
[01:10:46.240 --> 01:10:47.960]   I sort of create small projects
[01:10:47.960 --> 01:10:50.680]   and once those projects are done,
[01:10:50.680 --> 01:10:54.440]   and then I'll sort of share them with people.
[01:10:54.440 --> 01:10:57.240]   So something as simple as,
[01:10:57.240 --> 01:11:01.440]   I'll show you here.
[01:11:01.440 --> 01:11:03.300]   So, okay, I'll just quickly show you what,
[01:11:03.300 --> 01:11:06.560]   so I have touched on the functional programming aspect
[01:11:06.560 --> 01:11:10.840]   of Python and apart from the object-oriented that we follow,
[01:11:10.840 --> 01:11:14.080]   I have written on recommender systems, I have.
[01:11:14.080 --> 01:11:17.680]   And so I also, I'm very passionate about, you know,
[01:11:17.680 --> 01:11:20.520]   exploratory data analysis and my,
[01:11:20.520 --> 01:11:22.480]   you could say the entire Kaggle profile is,
[01:11:22.480 --> 01:11:24.800]   it's full of EDA notebooks
[01:11:24.800 --> 01:11:28.800]   because I really like to dive into EDA
[01:11:28.800 --> 01:11:30.280]   and exploring what the data has.
[01:11:30.280 --> 01:11:32.520]   And that's also a great point to actually start
[01:11:32.520 --> 01:11:37.240]   because even before you started doing any modeling process,
[01:11:37.240 --> 01:11:39.760]   especially if you look at the industry today,
[01:11:39.760 --> 01:11:43.960]   still we use the traditional machine learning for that
[01:11:43.960 --> 01:11:47.600]   and data analysis becomes an imperative part of it.
[01:11:47.600 --> 01:11:50.560]   And so for instance, there was this dataset
[01:11:50.560 --> 01:11:54.520]   which I had posted myself that was on clinicaltrials.gov.
[01:11:54.520 --> 01:11:57.040]   So this is a website, US website,
[01:11:57.040 --> 01:12:00.080]   and they have all the researchers which are going on
[01:12:00.080 --> 01:12:02.080]   and all of those papers are put here.
[01:12:02.080 --> 01:12:05.760]   So I specifically filtered out the COVID-related research
[01:12:05.760 --> 01:12:08.040]   and this was during the time
[01:12:08.040 --> 01:12:09.400]   when the vaccines hadn't come out.
[01:12:09.400 --> 01:12:14.400]   So I was really interested to know what are the possibilities
[01:12:14.400 --> 01:12:17.780]   or how were people working on the COVID vaccines.
[01:12:17.780 --> 01:12:20.280]   And so when I actually looked into the data,
[01:12:20.280 --> 01:12:22.400]   I saw that the data was in XML format
[01:12:22.400 --> 01:12:24.560]   and that's an extensible markup language
[01:12:24.560 --> 01:12:26.420]   and that we are not used to
[01:12:26.420 --> 01:12:28.400]   because we mostly work with CSV files
[01:12:28.400 --> 01:12:30.440]   because that's very easily available.
[01:12:30.440 --> 01:12:34.200]   So I then researched and I then tried to understand
[01:12:34.200 --> 01:12:35.400]   what XML is.
[01:12:35.400 --> 01:12:37.720]   And so, because I spent such a lot of time into this,
[01:12:37.720 --> 01:12:40.120]   I thought I'll convert it into an article
[01:12:40.120 --> 01:12:42.400]   and probably people who would want to then
[01:12:42.400 --> 01:12:45.960]   work with XML files will be able to use it.
[01:12:45.960 --> 01:12:47.380]   So that's the concept,
[01:12:47.380 --> 01:12:51.020]   the basic idea that I have before writing any article.
[01:12:51.020 --> 01:12:54.820]   I first research about it, I create a mini project
[01:12:54.820 --> 01:12:56.760]   and then I convert it into an article
[01:12:56.760 --> 01:13:00.400]   and then I try to make this as simple as possible
[01:13:00.400 --> 01:13:01.240]   for people.
[01:13:01.240 --> 01:13:05.520]   And if you talk about simple steps,
[01:13:05.520 --> 01:13:07.640]   so there are sometimes what I do is
[01:13:07.640 --> 01:13:10.200]   I go into the documentation
[01:13:10.200 --> 01:13:13.120]   because what I feel is most of the times
[01:13:13.120 --> 01:13:16.960]   a documentation actually has such a lot of stuff,
[01:13:16.960 --> 01:13:18.600]   but we normally our first instance
[01:13:18.600 --> 01:13:20.840]   always is to go to Stack Overflow.
[01:13:20.840 --> 01:13:23.440]   And if you will just go deeply into documentation,
[01:13:23.440 --> 01:13:26.120]   the authors or the maintainers of a library,
[01:13:26.120 --> 01:13:28.160]   they put in their heart and soul,
[01:13:28.160 --> 01:13:30.800]   like some of the documentations are absolutely great.
[01:13:30.800 --> 01:13:34.080]   Fast.ai is one of them, Scikit-learn is another one.
[01:13:34.080 --> 01:13:37.600]   And so I went into Matplotlib and then I discovered that,
[01:13:37.600 --> 01:13:41.600]   you could also create such beautiful XKCD plots.
[01:13:41.600 --> 01:13:43.320]   And this is really nice if,
[01:13:43.320 --> 01:13:47.480]   of course you cannot use it into a professional setup,
[01:13:47.480 --> 01:13:51.360]   but this is pretty cool if you just want to show things.
[01:13:51.360 --> 01:13:53.840]   And then other way was you could create
[01:13:53.840 --> 01:13:56.040]   the cyberpunk style charts in Matplotlib
[01:13:56.040 --> 01:13:57.720]   and this is like very nice.
[01:13:57.720 --> 01:14:00.280]   And again, I saw Aman was supposed to about
[01:14:00.280 --> 01:14:04.040]   that you could also create a timeline charts in Matplotlib
[01:14:04.040 --> 01:14:06.360]   and then I actually used to them.
[01:14:06.360 --> 01:14:07.880]   So that's how I do.
[01:14:07.880 --> 01:14:10.880]   And if you talk about very small projects,
[01:14:10.880 --> 01:14:13.720]   I like, for instance, this was one of the project,
[01:14:13.720 --> 01:14:16.600]   a very small Python script I wrote.
[01:14:16.600 --> 01:14:19.680]   So for instance, if you have your notebook and you run it
[01:14:19.680 --> 01:14:23.480]   and you just go away from that notebook to some other,
[01:14:23.480 --> 01:14:27.440]   you could say, and so you get this notification
[01:14:27.440 --> 01:14:30.160]   right on the top, when it has finished executing.
[01:14:30.160 --> 01:14:31.760]   So this is very handy.
[01:14:31.760 --> 01:14:33.880]   And then I converted this.
[01:14:33.880 --> 01:14:35.520]   And so that's how I approach.
[01:14:35.520 --> 01:14:39.640]   And if you sort of see what currently I'm doing is
[01:14:39.640 --> 01:14:42.240]   I'm trying to create this sort of app
[01:14:42.240 --> 01:14:46.280]   where it takes a URL of any medium article
[01:14:46.280 --> 01:14:49.560]   and it then converts into an audio and a summary.
[01:14:49.560 --> 01:14:52.840]   And what, and how, such projects
[01:14:52.840 --> 01:14:55.680]   and that's how I would advise everybody is
[01:14:55.680 --> 01:14:57.760]   think of some project that you have in mind.
[01:14:57.760 --> 01:15:00.280]   Don't worry if you have no idea about it.
[01:15:00.280 --> 01:15:02.240]   And then you modularize them,
[01:15:02.240 --> 01:15:04.880]   just like create different objects of them
[01:15:04.880 --> 01:15:07.360]   and then try researching and finding out
[01:15:07.360 --> 01:15:10.920]   how you can actually bring your project to life.
[01:15:10.920 --> 01:15:15.000]   And trust me, when you research about them,
[01:15:15.000 --> 01:15:16.720]   you're gonna find such a lot of stuff
[01:15:16.720 --> 01:15:18.320]   and such a lot of interesting stuff.
[01:15:18.320 --> 01:15:19.880]   And then you might create 10 articles
[01:15:19.880 --> 01:15:22.440]   out of that research that you do.
[01:15:22.440 --> 01:15:26.000]   And so my, because my project was about
[01:15:26.000 --> 01:15:28.360]   converting medium articles into blogs,
[01:15:28.360 --> 01:15:31.840]   into audio files and then summarizing them.
[01:15:31.840 --> 01:15:35.640]   So then I had to know how to scrape them efficiently
[01:15:35.640 --> 01:15:38.000]   so that I don't get the junk from the article.
[01:15:38.000 --> 01:15:40.120]   And then I converted them into audio files
[01:15:40.120 --> 01:15:43.480]   and then summarize them.
[01:15:43.480 --> 01:15:45.760]   And also make sure that they're on my mobile phone
[01:15:45.760 --> 01:15:47.840]   because that's ultimately,
[01:15:47.840 --> 01:15:49.160]   I would want to listen to them
[01:15:49.160 --> 01:15:50.920]   when I'm on a walk or something.
[01:15:50.920 --> 01:15:53.480]   So I also have to make sure the latency part,
[01:15:53.480 --> 01:15:55.560]   it shouldn't take such a lot of time,
[01:15:55.560 --> 01:15:59.120]   because the library that will go behind it,
[01:15:59.120 --> 01:16:00.600]   it doesn't have to be that heavy.
[01:16:00.600 --> 01:16:03.360]   So that's a bunch of thing you have to understand.
[01:16:03.360 --> 01:16:05.680]   You also have to understand how do you deploy them.
[01:16:05.680 --> 01:16:09.280]   So like this is the deployed part of it,
[01:16:09.280 --> 01:16:12.680]   just to make sure I added an option of changing themes.
[01:16:12.680 --> 01:16:16.240]   And still it's just a work in progress.
[01:16:16.240 --> 01:16:20.040]   But now I have such a lot of content to convert them.
[01:16:20.040 --> 01:16:22.200]   And I'm also very happy
[01:16:22.200 --> 01:16:25.200]   that I have created an end-to-end project.
[01:16:25.200 --> 01:16:27.520]   So that is my whole idea behind it.
[01:16:27.520 --> 01:16:31.040]   So whatever you do, you can start blogging
[01:16:31.040 --> 01:16:33.320]   by just telling about the library.
[01:16:33.320 --> 01:16:36.120]   You can start blogging about telling about some features.
[01:16:36.120 --> 01:16:41.120]   But then as you go on, try and start implementing them.
[01:16:41.120 --> 01:16:44.240]   And the real learning actually comes
[01:16:44.240 --> 01:16:47.640]   when you implement stuff, when you hit roadblocks,
[01:16:47.640 --> 01:16:50.760]   when you go search, when you ask people.
[01:16:50.760 --> 01:16:54.280]   And that's how you'll actually understand
[01:16:54.280 --> 01:16:57.560]   how to use something very, very nicely.
[01:16:57.560 --> 01:17:00.040]   This has really helped me.
[01:17:00.040 --> 01:17:05.040]   I started, even initially I wrote an article on Raza
[01:17:05.040 --> 01:17:09.720]   on how to deploy a chatbot.
[01:17:09.720 --> 01:17:12.520]   And the way that gave me an understanding
[01:17:12.520 --> 01:17:13.840]   about how Raza is used,
[01:17:13.840 --> 01:17:16.640]   I wouldn't have known by just reading the documentation.
[01:17:16.640 --> 01:17:18.600]   So now, because you're going through this,
[01:17:18.600 --> 01:17:19.800]   just think of any project
[01:17:19.800 --> 01:17:23.200]   and just don't think of a project
[01:17:23.200 --> 01:17:24.400]   just for the sake of doing.
[01:17:24.400 --> 01:17:27.600]   Why I chose this project was because I write on Medium
[01:17:27.600 --> 01:17:29.560]   and it's always good to listen to other people
[01:17:29.560 --> 01:17:31.440]   and what they're writing.
[01:17:31.440 --> 01:17:34.640]   Then think of similar projects in your own domain.
[01:17:34.640 --> 01:17:37.080]   And the best part is if you're just transitioning
[01:17:37.080 --> 01:17:39.760]   into data science and you are in some other domain,
[01:17:39.760 --> 01:17:44.480]   finance and insurance, healthcare,
[01:17:44.480 --> 01:17:46.760]   think of problems there
[01:17:46.760 --> 01:17:49.280]   and implement them into an end-to-end project,
[01:17:49.280 --> 01:17:53.200]   put them on GitHub and tweet about them,
[01:17:53.200 --> 01:17:55.920]   write about them, share on LinkedIn.
[01:17:55.920 --> 01:17:59.080]   And that's how you will build your credibility
[01:17:59.080 --> 01:18:01.320]   and benefit from everything.
[01:18:01.320 --> 01:18:04.800]   So that's my idea.
[01:18:04.800 --> 01:18:08.200]   And in this, if you'll go back to the forum,
[01:18:08.200 --> 01:18:11.280]   you'll also see, I have given you some examples of,
[01:18:12.200 --> 01:18:14.640]   there's one doubt that people always have
[01:18:14.640 --> 01:18:17.520]   is there are already tens and hundreds of articles
[01:18:17.520 --> 01:18:19.000]   already written for a topic.
[01:18:19.000 --> 01:18:22.600]   How would my single article make a difference?
[01:18:22.600 --> 01:18:25.800]   And that's where I tell people,
[01:18:25.800 --> 01:18:29.760]   try and write on some unexplored part of a library.
[01:18:29.760 --> 01:18:33.840]   So here I've also shared an example of this Lux library
[01:18:33.840 --> 01:18:38.840]   where I wrote about using this to showcase Simpsons Effect.
[01:18:39.920 --> 01:18:42.440]   And Simpsons Effect is a statistical,
[01:18:42.440 --> 01:18:48.040]   you could say an effect or a property where you sort of,
[01:18:48.040 --> 01:18:51.000]   and it's pretty interesting because what you see is
[01:18:51.000 --> 01:18:53.760]   you see different behavior of the dataset
[01:18:53.760 --> 01:18:57.240]   when you combine them and when you separate them out,
[01:18:57.240 --> 01:18:59.080]   it behaves very differently.
[01:18:59.080 --> 01:19:02.560]   And I use this library to actually showcase it.
[01:19:02.560 --> 01:19:05.440]   So my idea was not to tell you about the library,
[01:19:05.440 --> 01:19:06.280]   just like a doc,
[01:19:06.280 --> 01:19:08.720]   I didn't want to create another documentation,
[01:19:08.720 --> 01:19:11.920]   but I wanted to leverage that library to sort of
[01:19:11.920 --> 01:19:14.160]   understand a very different concept.
[01:19:14.160 --> 01:19:17.280]   And you could do the same thing with other libraries.
[01:19:17.280 --> 01:19:21.960]   And again, also another important thing about writing is
[01:19:21.960 --> 01:19:23.520]   it takes a lot of time.
[01:19:23.520 --> 01:19:26.160]   It does take, you have to be very consistent.
[01:19:26.160 --> 01:19:29.040]   I know a lot of people, they start writing very,
[01:19:29.040 --> 01:19:31.200]   the way to the aesthetic initially,
[01:19:31.200 --> 01:19:32.800]   but then they lose that vigor
[01:19:32.800 --> 01:19:35.440]   and then they stop writing about it.
[01:19:35.440 --> 01:19:37.760]   So, but if you were to just go on,
[01:19:38.760 --> 01:19:42.640]   I trust me, it has great benefits
[01:19:42.640 --> 01:19:46.840]   and you'll start enjoying it so much so that,
[01:19:46.840 --> 01:19:48.840]   if you won't try it for a week,
[01:19:48.840 --> 01:19:51.320]   then you're going to miss writing.
[01:19:51.320 --> 01:19:54.560]   Aman is very, I think regularly he posts.
[01:19:54.560 --> 01:19:59.240]   So his blog is just full of such a lot of information.
[01:19:59.240 --> 01:20:03.600]   And I think he has his own inspirational story to share,
[01:20:03.600 --> 01:20:05.360]   because he also writes
[01:20:05.360 --> 01:20:07.320]   and he writes on a lot of complicated stuff.
[01:20:07.320 --> 01:20:08.920]   He writes on research papers.
[01:20:08.920 --> 01:20:13.320]   And so you should also try and read other people's work,
[01:20:13.320 --> 01:20:15.120]   because that will also,
[01:20:15.120 --> 01:20:18.960]   there's a lot of learning from reading other people's work.
[01:20:18.960 --> 01:20:21.760]   Like I read Rachel's work also,
[01:20:21.760 --> 01:20:23.480]   and there's some people,
[01:20:23.480 --> 01:20:26.640]   they write in a very witty fashion, which I really like it.
[01:20:26.640 --> 01:20:30.560]   They try to simplify things by giving analogies.
[01:20:30.560 --> 01:20:31.840]   And so that all of this,
[01:20:31.840 --> 01:20:34.880]   this you will get as long as,
[01:20:34.880 --> 01:20:39.000]   as you'll progress in your writing career.
[01:20:39.000 --> 01:20:40.720]   But even before all this,
[01:20:40.720 --> 01:20:43.480]   the first step is to actually start writing
[01:20:43.480 --> 01:20:45.680]   and that's very important.
[01:20:45.680 --> 01:20:49.440]   So that's, I'll advise you all to just start.
[01:20:49.440 --> 01:20:51.560]   - Thanks, Parul.
[01:20:51.560 --> 01:20:55.640]   I think that's a really, I'm a bit heartfelt to hear this.
[01:20:55.640 --> 01:20:57.600]   And I think it's really good points.
[01:20:57.600 --> 01:20:58.840]   And it's kind of,
[01:20:58.840 --> 01:21:00.840]   writing is also good for everybody who writes.
[01:21:00.840 --> 01:21:03.400]   It's not just for, you don't just write for somebody else,
[01:21:03.400 --> 01:21:04.600]   you also write for yourself,
[01:21:04.600 --> 01:21:08.640]   'cause then that pushes you to learn things in a better way.
[01:21:08.640 --> 01:21:11.560]   And I remember just starting the journey on Medium
[01:21:11.560 --> 01:21:13.800]   and I also started writing about Fast.ai.
[01:21:13.800 --> 01:21:15.880]   So I think that's the advice.
[01:21:15.880 --> 01:21:18.720]   If there's any advice, I mean, this is a perfect platform,
[01:21:18.720 --> 01:21:20.920]   Fast.ai, we're all learning Fastbook.
[01:21:20.920 --> 01:21:22.440]   And this is a really good platform
[01:21:22.440 --> 01:21:24.280]   as you're learning just write about things.
[01:21:24.280 --> 01:21:25.960]   If you're learning what PyTorch,
[01:21:25.960 --> 01:21:29.600]   like we touched upon PyTorch, tensors and NumPy arrays.
[01:21:29.600 --> 01:21:31.400]   I know we didn't go deep into it,
[01:21:31.400 --> 01:21:33.720]   but this is an opportunity for you to then go back,
[01:21:33.720 --> 01:21:36.440]   take that, learn about PyTorch and NumPy arrays
[01:21:36.440 --> 01:21:38.360]   and maybe just write a piece that says,
[01:21:38.360 --> 01:21:40.760]   oh, this is the key difference
[01:21:40.760 --> 01:21:42.120]   between PyTorch and NumPy arrays.
[01:21:42.120 --> 01:21:45.320]   So just as an idea, or like we could take up,
[01:21:45.320 --> 01:21:46.640]   how there's a simple MNIST
[01:21:46.640 --> 01:21:49.560]   between threes and seven digit classifier.
[01:21:49.560 --> 01:21:51.080]   Maybe you could take that and write about it
[01:21:51.080 --> 01:21:52.880]   and have, instead of taking the average,
[01:21:52.880 --> 01:21:54.080]   maybe there's some other idea
[01:21:54.080 --> 01:21:56.520]   or there's some other way of doing it.
[01:21:56.520 --> 01:21:58.240]   So you could maybe think of that
[01:21:58.240 --> 01:22:00.560]   and that could become a blog post.
[01:22:00.560 --> 01:22:03.080]   Is there any questions for Parul?
[01:22:03.080 --> 01:22:06.000]   We'll spend some time just again,
[01:22:06.000 --> 01:22:08.400]   I'll share my screen and go to that report
[01:22:08.400 --> 01:22:15.680]   and just see if there's any questions for Parul
[01:22:15.680 --> 01:22:17.960]   about writing or if you have any questions.
[01:22:17.960 --> 01:22:26.800]   People really love the audio.
[01:22:26.800 --> 01:22:27.640]   - Yeah.
[01:22:27.640 --> 01:22:28.720]   - Audio flyer.
[01:22:28.720 --> 01:22:29.560]   That's just a-
[01:22:29.560 --> 01:22:31.560]   - And so for the people I've seen,
[01:22:31.560 --> 01:22:35.520]   like they've created apps like Yoga Post Detector
[01:22:35.520 --> 01:22:38.880]   and everything, and I would encourage you to try
[01:22:38.880 --> 01:22:43.320]   and sort of research and how you could deploy it on phones.
[01:22:43.320 --> 01:22:46.360]   And for that, you'll have to go and research yourself,
[01:22:46.360 --> 01:22:48.640]   but that's going to be great
[01:22:48.640 --> 01:22:51.440]   because you're going to get to know such a lot of things.
[01:22:51.440 --> 01:22:54.000]   It'll be hard at times, but then start discussing it
[01:22:54.000 --> 01:22:56.680]   because try and take it one step further.
[01:22:56.680 --> 01:22:58.120]   And you could even write blog posts
[01:22:58.120 --> 01:22:59.880]   on what problems you faced
[01:22:59.880 --> 01:23:01.000]   so that there might be others
[01:23:01.000 --> 01:23:02.680]   who are also facing the same problem.
[01:23:02.680 --> 01:23:04.200]   They will benefit from it.
[01:23:04.200 --> 01:23:06.120]   So you don't always have to tell something about,
[01:23:06.120 --> 01:23:08.120]   good, look, I created this project.
[01:23:08.120 --> 01:23:10.680]   I write the roadblocks and write most of common
[01:23:10.680 --> 01:23:13.000]   or the 10 common mistakes that you did
[01:23:13.000 --> 01:23:15.280]   or what are the problems that you faced,
[01:23:15.280 --> 01:23:19.520]   as simple as probably not being able to download a stuff
[01:23:19.520 --> 01:23:20.360]   or where to locate.
[01:23:20.360 --> 01:23:22.720]   So these are also some ideas that you can use.
[01:23:22.720 --> 01:23:26.320]   - Absolutely.
[01:23:26.320 --> 01:23:28.840]   I think Ravi has a good point that he said,
[01:23:28.840 --> 01:23:30.320]   he writes for himself
[01:23:30.320 --> 01:23:33.680]   and if others benefit from it, that's great.
[01:23:33.680 --> 01:23:34.960]   I think that's a good mindset.
[01:23:34.960 --> 01:23:36.720]   So that's good to hear.
[01:23:36.720 --> 01:23:39.320]   Anyway, if there's no questions,
[01:23:39.320 --> 01:23:42.560]   then please post them or just reach out to Parul directly.
[01:23:42.560 --> 01:23:44.560]   She's very active on Twitter.
[01:23:44.560 --> 01:23:46.520]   I know she's very active on Kaggle.
[01:23:46.520 --> 01:23:52.680]   Just having a look at the question from Prabhav,
[01:23:52.680 --> 01:23:56.040]   are there any active research paper reading group for CV?
[01:23:56.920 --> 01:24:00.280]   - Yes, Weights and Biases holds a paper reading group.
[01:24:00.280 --> 01:24:05.280]   So if you go, the best way I think is 1db.me/prg,
[01:24:05.280 --> 01:24:08.840]   which will help you sign up.
[01:24:08.840 --> 01:24:13.440]   So just yesterday, we looked at the EfficientNet WeTube paper
[01:24:13.440 --> 01:24:15.160]   so you can sign up here.
[01:24:15.160 --> 01:24:16.280]   It's also on YouTube,
[01:24:16.280 --> 01:24:19.080]   if you go to YouTube search for Weights and Biases,
[01:24:19.080 --> 01:24:23.640]   but also lots of that information is available on the site.
[01:24:24.360 --> 01:24:26.360]   As I said, I've got a new setup today,
[01:24:26.360 --> 01:24:28.640]   which is making things really difficult for me.
[01:24:28.640 --> 01:24:31.000]   But anyway, so then there's also all this setup
[01:24:31.000 --> 01:24:32.920]   that I'll share with everybody.
[01:24:32.920 --> 01:24:35.560]   But yeah, Weights and Biases has a paper reading group.
[01:24:35.560 --> 01:24:41.320]   Excellent, I'll see you guys then next week.
[01:24:41.320 --> 01:24:42.640]   Next week, we're gonna deep dive
[01:24:42.640 --> 01:24:45.080]   into stochastic gradient descent.
[01:24:45.080 --> 01:24:48.520]   And we spend this week then looking into
[01:24:48.520 --> 01:24:50.040]   coding a lot more in depth.
[01:24:50.040 --> 01:24:51.360]   So I'll see you guys then.
[01:24:51.360 --> 01:24:52.880]   I'll see you guys next week.
[01:24:52.880 --> 01:24:54.200]   And I'll see you guys next week.
[01:24:54.200 --> 01:24:55.280]   And I'll see you guys next week.
[01:24:55.280 --> 01:24:56.320]   And I'll see you guys next week.
[01:24:56.320 --> 01:24:57.320]   And I'll see you guys next week.
[01:24:57.320 --> 01:24:58.320]   And I'll see you guys next week.
[01:24:58.320 --> 01:24:59.320]   And I'll see you guys next week.
[01:24:59.320 --> 01:25:00.320]   And I'll see you guys next week.
[01:25:00.320 --> 01:25:01.320]   And I'll see you guys next week.
[01:25:01.320 --> 01:25:02.320]   And I'll see you guys next week.
[01:25:02.320 --> 01:25:03.320]   And I'll see you guys next week.
[01:25:03.320 --> 01:25:04.320]   And I'll see you guys next week.
[01:25:04.320 --> 01:25:05.320]   And I'll see you guys next week.
[01:25:05.320 --> 01:25:06.320]   And I'll see you guys next week.
[01:25:06.320 --> 01:25:07.320]   And I'll see you guys next week.
[01:25:07.320 --> 01:25:08.320]   And I'll see you guys next week.
[01:25:08.320 --> 01:25:09.320]   And I'll see you guys next week.
[01:25:09.320 --> 01:25:10.320]   And I'll see you guys next week.
[01:25:10.320 --> 01:25:11.320]   And I'll see you guys next week.
[01:25:11.320 --> 01:25:12.320]   And I'll see you guys next week.
[01:25:12.320 --> 01:25:40.080]   And I'll see you guys next week.
[01:25:40.080 --> 01:25:42.200]   Thanks for joining.
[01:25:42.200 --> 01:25:45.540]   [BEEP]

