
[00:00:00.000 --> 00:00:09.080]   As you ramp up and you grow that much, you'll start becoming cognizant of your cost.
[00:00:09.080 --> 00:00:15.600]   Because especially if you're doing it on the cloud, they provide a lot of sharp knives.
[00:00:15.600 --> 00:00:22.360]   And as you play with them, you can cut yourself and bleed yourself to death in terms of money.
[00:00:22.360 --> 00:00:26.200]   You're listening to Gradient Dissent, a show where we learn about making machine learning
[00:00:26.200 --> 00:00:27.860]   models work in the real world.
[00:00:27.860 --> 00:00:30.040]   I'm your host, Lukas Biewald.
[00:00:30.040 --> 00:00:34.880]   Anantha Kancharella is VP of Engineering at Lyft, where he heads up the Level 5 software
[00:00:34.880 --> 00:00:38.200]   team working on building the self-driving car.
[00:00:38.200 --> 00:00:42.980]   Prior to Lyft, he spent time at Dropbox building products that help teams to collaborate.
[00:00:42.980 --> 00:00:47.720]   And before that, he worked at Facebook building mobile software at scale, delivering core
[00:00:47.720 --> 00:00:50.400]   experiences like newsfeed on mobile phones.
[00:00:50.400 --> 00:00:52.560]   I'm super excited to talk to him.
[00:00:52.560 --> 00:00:54.360]   I was thinking it's kind of cool the way you...
[00:00:54.360 --> 00:00:58.240]   I assume that the goal is to make Level 5 automation then?
[00:00:58.240 --> 00:01:00.240]   Level 5 automation.
[00:01:00.240 --> 00:01:01.240]   Yes.
[00:01:01.240 --> 00:01:02.240]   Automated driving?
[00:01:02.240 --> 00:01:05.240]   That is our aspiration.
[00:01:05.240 --> 00:01:07.480]   But I'll take Level 4.
[00:01:07.480 --> 00:01:10.600]   I was actually wondering how you...
[00:01:10.600 --> 00:01:16.440]   I don't think I've ever been part of a team with such a sort of like huge, singular technical
[00:01:16.440 --> 00:01:17.440]   ambition.
[00:01:17.440 --> 00:01:21.720]   I was wondering how you kind of break that problem down to constituent parts.
[00:01:21.720 --> 00:01:27.600]   Like how you think about what the weekly KPI should be when you have this gigantic goal.
[00:01:27.600 --> 00:01:32.400]   No, honestly, this feels for me like how I've always worked.
[00:01:32.400 --> 00:01:33.400]   I don't know why.
[00:01:33.400 --> 00:01:40.840]   I guess I started my career at Windows and by the time I left, it was well into tens
[00:01:40.840 --> 00:01:42.840]   of thousands of people working.
[00:01:42.840 --> 00:01:48.320]   And so all working towards one product, singular focus on one product.
[00:01:48.320 --> 00:01:53.160]   This is obviously way smaller than what Windows was, but it's the same idea.
[00:01:53.160 --> 00:01:55.960]   And so now it's a good question.
[00:01:55.960 --> 00:01:58.520]   What does it mean and how does it break down?
[00:01:58.520 --> 00:02:04.520]   So usually in a project like this, you're going to have so many different skill sets.
[00:02:04.520 --> 00:02:06.560]   So ML is just one of them.
[00:02:06.560 --> 00:02:10.000]   Usually when people think about self-driving cars, they mostly think about the AI part
[00:02:10.000 --> 00:02:11.000]   of it.
[00:02:11.000 --> 00:02:14.920]   But the way we kind of think about it is that you're going to have...
[00:02:14.920 --> 00:02:19.920]   So first of all, you have to kind of think about the work that we do as in two parts,
[00:02:19.920 --> 00:02:24.160]   the work that happens in the cloud, the work that happens in the car, the code that runs
[00:02:24.160 --> 00:02:26.600]   in the car and code that runs in the cloud.
[00:02:26.600 --> 00:02:31.480]   And the code that runs in the car, you can think about it as if you really want to simplify
[00:02:31.480 --> 00:02:36.640]   it, it's kind of two parts or maybe three parts.
[00:02:36.640 --> 00:02:38.720]   So the lowest level, you have the operating system.
[00:02:38.720 --> 00:02:43.520]   So again, if you want to compare it with like say a traditional development environment,
[00:02:43.520 --> 00:02:47.680]   like imagine you have your OS that you're targeting and on top of that OS, there will
[00:02:47.680 --> 00:02:49.680]   be a runtime that you're going to write.
[00:02:49.680 --> 00:02:51.960]   If it's Android, it's like Java or whatever.
[00:02:51.960 --> 00:02:54.320]   So there'll be an equivalent runtime that you want.
[00:02:54.320 --> 00:02:57.120]   And then on top of the runtime, you'll have your applications.
[00:02:57.120 --> 00:02:58.680]   That's how you would write a typical one.
[00:02:58.680 --> 00:02:59.760]   So it's a similar idea here.
[00:02:59.760 --> 00:03:03.600]   So you have your OS that is running on the car hardware.
[00:03:03.600 --> 00:03:07.640]   Now the car hardware is way more complicated than anything that you've seen on the phones
[00:03:07.640 --> 00:03:08.640]   or PCs.
[00:03:08.640 --> 00:03:12.420]   We say it's like a data center on wheels.
[00:03:12.420 --> 00:03:18.360]   So typically a car has a lot of computers in it, but some of them we write software
[00:03:18.360 --> 00:03:24.520]   for, some of them come with the car and they're all on a gigantic network.
[00:03:24.520 --> 00:03:31.240]   So most of the code that we write runs on what we call high performance compute.
[00:03:31.240 --> 00:03:35.880]   But again, different companies do different things.
[00:03:35.880 --> 00:03:38.160]   Maybe they will factor the workload in different ways.
[00:03:38.160 --> 00:03:43.780]   So you can imagine the multiple smaller computers or one large computer and one small computer,
[00:03:43.780 --> 00:03:46.820]   there's different configurations possible.
[00:03:46.820 --> 00:03:50.140]   And you just have to figure out how you're going to break down your workload.
[00:03:50.140 --> 00:03:55.580]   And then on each of those computers, you're going to run a fairly, depending on how big
[00:03:55.580 --> 00:04:00.860]   it is, you're going to run a fairly beefy operating system or possibly even a low operating
[00:04:00.860 --> 00:04:04.920]   system if it is like a microcontroller.
[00:04:04.920 --> 00:04:12.180]   And then sometimes there'll be embedded processors and then you'll run a very, very thin microkernel.
[00:04:12.180 --> 00:04:20.500]   And then on top of that, we have a framework that we build that basically enables the software
[00:04:20.500 --> 00:04:24.740]   components that are running on that one computer to work with each other.
[00:04:24.740 --> 00:04:28.300]   A good equivalent of that is in the open source world, you would have run into something called
[00:04:28.300 --> 00:04:29.300]   ROS.
[00:04:29.300 --> 00:04:31.580]   So it's very similar to that.
[00:04:31.580 --> 00:04:37.220]   And then, but you can imagine they can also communicate across the computers on the network.
[00:04:37.220 --> 00:04:43.360]   And then on top of that, you write the functionality that actually makes it autonomous.
[00:04:43.360 --> 00:04:46.480]   But then you can imagine like that's just one, but you could also have a calibration
[00:04:46.480 --> 00:04:47.480]   functionality.
[00:04:47.480 --> 00:04:50.660]   There's a bunch of other little pieces of functionality that you would write.
[00:04:50.660 --> 00:04:55.680]   But the autonomous itself kind of breaks down into your classical robotics paradigm, right?
[00:04:55.680 --> 00:04:56.680]   Sense, plan, and act.
[00:04:56.680 --> 00:05:01.120]   So sensing is basically what in our world we call it perception.
[00:05:01.120 --> 00:05:07.580]   When you have a block of code that predicts how the world is going to change.
[00:05:07.580 --> 00:05:14.300]   And there's a block of code that basically figures out where I am within the world.
[00:05:14.300 --> 00:05:16.020]   Within the world, it's called localization.
[00:05:16.020 --> 00:05:17.920]   Then there's another block of code.
[00:05:17.920 --> 00:05:19.900]   Once it knows, okay, this is what the world looks like.
[00:05:19.900 --> 00:05:21.280]   This is where I am at.
[00:05:21.280 --> 00:05:25.660]   And this is how the world is going to change in the next few seconds.
[00:05:25.660 --> 00:05:27.940]   How am I going to act?
[00:05:27.940 --> 00:05:29.740]   And what's the plan?
[00:05:29.740 --> 00:05:32.620]   And then it sends it down to the actuators.
[00:05:32.620 --> 00:05:34.300]   And that's the control part of it.
[00:05:34.300 --> 00:05:39.740]   So all of those, so those are all the kinds of components that work on the car.
[00:05:39.740 --> 00:05:45.120]   And now there's a lot of code that actually runs on the cloud for development reasons
[00:05:45.120 --> 00:05:49.200]   as well as like even during deployment like you do.
[00:05:49.200 --> 00:05:54.300]   So there are teams that actually build the infrastructure because even though we are
[00:05:54.300 --> 00:05:59.420]   part of Lyft and Lyft is like a very much a cloud company, the kind of workloads that
[00:05:59.420 --> 00:06:02.980]   the ride sharing part of Lyft does is very different than the kind of workloads that
[00:06:02.980 --> 00:06:04.100]   we run.
[00:06:04.100 --> 00:06:09.620]   So the amount of data that we collect or the amount of compute that we need is very, very
[00:06:09.620 --> 00:06:13.740]   at a different scale and requirements tend to be very different.
[00:06:13.740 --> 00:06:22.180]   So we have teams that actually think about what's the data part of that infrastructure.
[00:06:22.180 --> 00:06:26.340]   And there are teams that think about the compute part of the infrastructure.
[00:06:26.340 --> 00:06:29.860]   And then we also have to think about testing all of these.
[00:06:29.860 --> 00:06:35.580]   So testing, obviously you cannot, a unit test, you'll do whatever with your code, but then
[00:06:35.580 --> 00:06:39.940]   there's also the other side of the testing, which is like on the road.
[00:06:39.940 --> 00:06:43.220]   You build everything and deploy it, but then there's a whole lot of other testing that
[00:06:43.220 --> 00:06:44.260]   needs to happen in between.
[00:06:44.260 --> 00:06:50.580]   So simulation is one example where you try to run the software that you built that you
[00:06:50.580 --> 00:06:54.580]   will eventually deploy on your car somewhere in the cloud.
[00:06:54.580 --> 00:06:58.460]   And then we also have rigs that we build.
[00:06:58.460 --> 00:07:03.100]   These are called, we call them test beds, but another term that you will often hear
[00:07:03.100 --> 00:07:05.060]   is hardware in the loop testing.
[00:07:05.060 --> 00:07:11.460]   So you build, depending on which team it is, like embedded team will build their own smaller
[00:07:11.460 --> 00:07:13.660]   versions of hardware.
[00:07:13.660 --> 00:07:15.580]   Then there'll be full system tests.
[00:07:15.580 --> 00:07:19.460]   So there are different types of these test beds that we build.
[00:07:19.460 --> 00:07:24.780]   And you can think of them as like mini data centers that we have, and you run the code
[00:07:24.780 --> 00:07:26.180]   on those as well.
[00:07:26.180 --> 00:07:30.980]   So we treat them as if it's like another cloud.
[00:07:30.980 --> 00:07:33.500]   And so we have teams that do all of that.
[00:07:33.500 --> 00:07:36.840]   And then there's teams that work on simulation.
[00:07:36.840 --> 00:07:41.120]   So all of these things eventually come together and at the end of the day, it all gets packaged
[00:07:41.120 --> 00:07:44.580]   up into software that is deployed in the car.
[00:07:44.580 --> 00:07:51.700]   And then we test the car on the road and then those metrics are used to drive work on the
[00:07:51.700 --> 00:07:52.700]   software that runs on the car.
[00:07:52.700 --> 00:07:56.020]   But quite often it can also impact stuff that happens in the cloud.
[00:07:56.020 --> 00:08:01.300]   Like for example, if you change your sensor and you capture a lot more data per hour,
[00:08:01.300 --> 00:08:08.220]   that means you may have to potentially replan your storage capacity.
[00:08:08.220 --> 00:08:09.220]   So things like that.
[00:08:09.220 --> 00:08:12.060]   So I don't know, did I answer your question there?
[00:08:12.060 --> 00:08:15.500]   I have so many more questions actually.
[00:08:15.500 --> 00:08:22.500]   I guess you're at the point where you probably have some metric, like how long you can drive
[00:08:22.500 --> 00:08:28.780]   without intervention that you're trying to optimize for or something like that.
[00:08:28.780 --> 00:08:34.020]   But then do you break it down by teams of like, we need to make our perception 10% better
[00:08:34.020 --> 00:08:35.020]   or something like that?
[00:08:35.020 --> 00:08:36.020]   Or how do you think about that?
[00:08:36.020 --> 00:08:37.020]   Yeah, yeah, yeah.
[00:08:37.020 --> 00:08:38.900]   So each team has...
[00:08:38.900 --> 00:08:40.260]   So it kind of breaks down, right?
[00:08:40.260 --> 00:08:44.020]   So there's a top level metric for the overall system performance.
[00:08:44.020 --> 00:08:45.020]   And then...
[00:08:45.020 --> 00:08:46.020]   Do I have that right?
[00:08:46.020 --> 00:08:49.460]   Is it like time between intervention or is that the right metric?
[00:08:49.460 --> 00:08:53.300]   So California DMV reporting, that's what they look at.
[00:08:53.300 --> 00:08:57.420]   So they look at, it's called MPI, miles per intervention.
[00:08:57.420 --> 00:09:00.540]   So how many miles do you drive before you have an intervention?
[00:09:00.540 --> 00:09:05.260]   So that's a very common metric that people track.
[00:09:05.260 --> 00:09:07.540]   But then there are so many other metrics that you have to think about.
[00:09:07.540 --> 00:09:09.980]   End to end latency is one example.
[00:09:09.980 --> 00:09:15.140]   How long does it take from say the time your camera captured a frame till the time that
[00:09:15.140 --> 00:09:16.140]   you reacted to it?
[00:09:16.140 --> 00:09:17.140]   So that's one example.
[00:09:17.140 --> 00:09:18.140]   I see.
[00:09:18.140 --> 00:09:19.140]   Yeah, right.
[00:09:19.140 --> 00:09:20.140]   So you have to think of...
[00:09:20.140 --> 00:09:21.140]   There's a number of other metrics that matter.
[00:09:21.140 --> 00:09:24.820]   But of course, you can argue that all of them come down into an intervention, like some
[00:09:24.820 --> 00:09:27.020]   human had to intervene.
[00:09:27.020 --> 00:09:31.100]   So that's kind of how generally the industry is standardized around today.
[00:09:31.100 --> 00:09:34.500]   But it's very controversial because what is an intervention?
[00:09:34.500 --> 00:09:35.500]   How do you report it?
[00:09:35.500 --> 00:09:39.340]   It's up for debate.
[00:09:39.340 --> 00:09:45.260]   But then internally, we track a number of other broader system level metrics.
[00:09:45.260 --> 00:09:46.380]   And you can do two things.
[00:09:46.380 --> 00:09:51.660]   One is you can apportion, let's say you do MPI, the miles per intervention.
[00:09:51.660 --> 00:09:57.700]   You could apportion MPI to different components and say, "Hey, the reason the intervention
[00:09:57.700 --> 00:10:01.300]   happened because we misperceived was the reason the intervention happened because our map
[00:10:01.300 --> 00:10:02.300]   was wrong."
[00:10:02.300 --> 00:10:04.380]   You can kind of apportion those.
[00:10:04.380 --> 00:10:07.420]   And then they kind of go down as far as they can go down.
[00:10:07.420 --> 00:10:08.420]   That's it.
[00:10:08.420 --> 00:10:11.580]   But then really, that's just only part of the problem.
[00:10:11.580 --> 00:10:15.660]   So each component will also have its own separate metric.
[00:10:15.660 --> 00:10:23.420]   So perception, for example, they may want to track the precision and recall of seeing
[00:10:23.420 --> 00:10:24.420]   different agents.
[00:10:24.420 --> 00:10:31.060]   What's the precision recall for seeing, say, a pedestrian or a car or a bus?
[00:10:31.060 --> 00:10:33.300]   And then you can further subdivide that.
[00:10:33.300 --> 00:10:42.660]   So how good is my precision/recall at 50 meters, at 100 meters, at 500 meters?
[00:10:42.660 --> 00:10:47.780]   So there's lots and lots of metrics that eventually break down at the component level.
[00:10:47.780 --> 00:10:50.060]   It comes down to every component.
[00:10:50.060 --> 00:10:52.100]   And how do you allocate your resources?
[00:10:52.100 --> 00:10:55.260]   Is the perception team a lot bigger than the planning team?
[00:10:55.260 --> 00:10:59.940]   That's a very good question.
[00:10:59.940 --> 00:11:07.460]   I'd say they are roughly similar between the two teams.
[00:11:07.460 --> 00:11:12.780]   But I don't think that there's a perfect science in terms of how you want to allocate.
[00:11:12.780 --> 00:11:17.780]   You kind of have to look at the stage of the project you are in and the maturity.
[00:11:17.780 --> 00:11:24.940]   Because sometimes each project, each part of the stack will move at different paces,
[00:11:24.940 --> 00:11:26.700]   depending upon what they're building.
[00:11:26.700 --> 00:11:31.580]   So let's say you're doing something which is highly machine learning dependent.
[00:11:31.580 --> 00:11:32.580]   So first you have to...
[00:11:32.580 --> 00:11:35.100]   I'm talking about when you're starting from scratch.
[00:11:35.100 --> 00:11:37.500]   In steady state, of course, it's very different.
[00:11:37.500 --> 00:11:43.660]   When you're starting from scratch, when you're beginning, you first may have to spend quite
[00:11:43.660 --> 00:11:47.980]   a bit of time building your machine learning infrastructure, data gathering, all of that.
[00:11:47.980 --> 00:11:52.340]   So those teams you probably want to populate first before you start throwing models at
[00:11:52.340 --> 00:11:53.340]   it.
[00:11:53.340 --> 00:12:00.460]   So you start with a relatively rudimentary team, a smaller team of just a few core experts
[00:12:00.460 --> 00:12:02.100]   in the perception part.
[00:12:02.100 --> 00:12:07.340]   And then once that is ready, then you start putting more people on that area.
[00:12:07.340 --> 00:12:12.420]   And maybe you don't have to work so hard to throw additional people on the infrastructure
[00:12:12.420 --> 00:12:13.740]   side of things.
[00:12:13.740 --> 00:12:18.300]   And it's only once you start unlocking the ability to see the world, then you can start
[00:12:18.300 --> 00:12:21.260]   doing more and more complicated maneuvers and planning.
[00:12:21.260 --> 00:12:24.340]   And then you start pushing more into the planning world.
[00:12:24.340 --> 00:12:26.580]   And then you'll start hitting bottlenecks on that side.
[00:12:26.580 --> 00:12:31.380]   And then you'll say, "Oh yeah, I need to add a few more people to unlock this thing in
[00:12:31.380 --> 00:12:32.380]   another area."
[00:12:32.380 --> 00:12:34.660]   So it is very, very dynamic.
[00:12:34.660 --> 00:12:40.900]   So I wouldn't say there's one standard formula through which we do resource allocation here.
[00:12:40.900 --> 00:12:41.900]   I see.
[00:12:41.900 --> 00:12:48.660]   But is it where you're seeing the most interventions being caused by, or is it where you see the
[00:12:48.660 --> 00:12:50.220]   most opportunity for improvement?
[00:12:50.220 --> 00:12:58.060]   I think interventions in a steady state world, let's say there are a lot of bugs, ignore
[00:12:58.060 --> 00:12:59.060]   interventions.
[00:12:59.060 --> 00:13:03.060]   I mean, if you just replace interventions with bugs, it's the same problem in any software.
[00:13:03.060 --> 00:13:05.660]   Where do you have your biggest bugs?
[00:13:05.660 --> 00:13:09.060]   And sometimes throwing more people at the problem is the right answer.
[00:13:09.060 --> 00:13:10.620]   And sometimes it is not the right answer.
[00:13:10.620 --> 00:13:12.340]   In fact, it's the wrong answer.
[00:13:12.340 --> 00:13:15.980]   So you may want to figure out putting the right people into that.
[00:13:15.980 --> 00:13:17.700]   Maybe you don't have the right expertise.
[00:13:17.700 --> 00:13:23.220]   So it's not always clear that the resource allocation is directly proportional to the
[00:13:23.220 --> 00:13:25.220]   number of bugs that you have.
[00:13:25.220 --> 00:13:26.220]   I see.
[00:13:26.220 --> 00:13:27.220]   That makes sense.
[00:13:27.220 --> 00:13:31.660]   And at this moment, is there a particular part of the chain that feels like the most
[00:13:31.660 --> 00:13:35.420]   challenging for you, that feels like there's the most room to improve?
[00:13:35.420 --> 00:13:44.900]   I think if you look at the state of understanding and state of research in this space, the place
[00:13:44.900 --> 00:13:51.500]   where there is a lot of scope for improvement is in the area of prediction and behavior
[00:13:51.500 --> 00:13:52.500]   planning.
[00:13:52.500 --> 00:13:57.460]   So there's an area where there's still a lot of active development going on.
[00:13:57.460 --> 00:13:59.020]   The industry is changing fast.
[00:13:59.020 --> 00:14:04.300]   Just recently I saw a really cool paper from Waymo's research team.
[00:14:04.300 --> 00:14:08.060]   So there's lots of activity going on in that world.
[00:14:08.060 --> 00:14:10.460]   So I would say that's the area which is developing quite a bit.
[00:14:10.460 --> 00:14:14.180]   So this is predicting where another car is going to go or a pedestrian?
[00:14:14.180 --> 00:14:15.180]   Another agent?
[00:14:15.180 --> 00:14:18.500]   What will happen in the world over the next few seconds?
[00:14:18.500 --> 00:14:20.100]   Who should I pay attention to?
[00:14:20.100 --> 00:14:21.100]   What should I watch out for?
[00:14:21.100 --> 00:14:24.140]   You know, all the things that as a human we take for granted.
[00:14:24.140 --> 00:14:26.980]   So those kinds of problems.
[00:14:26.980 --> 00:14:33.500]   So inside of the car, when it's operating right now, how many different models are running
[00:14:33.500 --> 00:14:34.500]   approximately?
[00:14:34.500 --> 00:14:39.620]   Oh boy, I'm not sure I can tell you the actual number.
[00:14:39.620 --> 00:14:46.740]   But in terms of ML, we have so many different ways of deploying these models.
[00:14:46.740 --> 00:14:51.300]   So on the car, you deploy them.
[00:14:51.300 --> 00:14:54.740]   And then in the cloud, you have a couple of different ways of deploying them.
[00:14:54.740 --> 00:15:00.180]   And if you look at Lyft at large, including Rideshare, there's so many different ways.
[00:15:00.180 --> 00:15:06.500]   There are times when some teams at Lyft will just run that model on their desktop once
[00:15:06.500 --> 00:15:07.500]   in a while.
[00:15:07.500 --> 00:15:08.860]   Pretty ad hoc.
[00:15:08.860 --> 00:15:15.500]   There are online loops that are running, active learning loops.
[00:15:15.500 --> 00:15:20.260]   Then there are online learning that is happening.
[00:15:20.260 --> 00:15:27.540]   Then there are models that run on the phone.
[00:15:27.540 --> 00:15:29.160]   Then there are models that run in the car.
[00:15:29.160 --> 00:15:31.020]   So we have models pretty much everywhere.
[00:15:31.020 --> 00:15:35.220]   But I guess you're responsible for the ones that run in the car and the cloud for that.
[00:15:35.220 --> 00:15:36.220]   Yeah.
[00:15:36.220 --> 00:15:37.740]   And we also help the Rideshare team as well.
[00:15:37.740 --> 00:15:43.420]   So there's a few people on our team who help because we have a lot of pretty amazing machine
[00:15:43.420 --> 00:15:44.420]   learning people.
[00:15:44.420 --> 00:15:46.820]   So we also help the core part of it.
[00:15:46.820 --> 00:15:50.900]   So we do have visibility into how they do it also.
[00:15:50.900 --> 00:15:55.220]   So in fact, sometimes our teams work on the cell phone models.
[00:15:55.220 --> 00:15:56.220]   Oh, that's cool.
[00:15:56.220 --> 00:15:57.220]   Or the offline models.
[00:15:57.220 --> 00:15:58.220]   Yeah.
[00:15:58.220 --> 00:15:59.220]   Wow.
[00:15:59.220 --> 00:16:02.740]   It's cool to talk to someone that's working on so many models at the same time.
[00:16:02.740 --> 00:16:06.220]   I'm really curious about your infrastructure for all this.
[00:16:06.220 --> 00:16:07.940]   How often do these models update?
[00:16:07.940 --> 00:16:08.940]   It all depends.
[00:16:08.940 --> 00:16:17.340]   It completely depends on which one you're talking about.
[00:16:17.340 --> 00:16:24.140]   So if you're doing the mapping ones, that's really dependent upon why you're using the
[00:16:24.140 --> 00:16:25.140]   model.
[00:16:25.140 --> 00:16:34.180]   So sometimes these models are used to help the operators as they work on the new techniques,
[00:16:34.180 --> 00:16:38.140]   new UI techniques or whatever, where there's some additional assist they're providing.
[00:16:38.140 --> 00:16:40.300]   They may update it when that time comes.
[00:16:40.300 --> 00:16:42.460]   Otherwise, generally they work.
[00:16:42.460 --> 00:16:43.800]   It's okay.
[00:16:43.800 --> 00:16:48.620]   Because they're assisting humans as opposed to doing it on their own.
[00:16:48.620 --> 00:16:50.780]   So those models don't update frequently.
[00:16:50.780 --> 00:17:01.020]   But the models that are operating on the car, you do that depending upon what you're addressing
[00:17:01.020 --> 00:17:03.840]   and which area that you're trying to improve.
[00:17:03.840 --> 00:17:12.380]   So let's say you're working in winter and you see a lot of vapor or smoke much more
[00:17:12.380 --> 00:17:13.380]   visible.
[00:17:13.380 --> 00:17:17.020]   So there'll be some parts of the code that are more impacted by all of that.
[00:17:17.020 --> 00:17:19.940]   So you'll see those iterating quite fast.
[00:17:19.940 --> 00:17:26.380]   In general though, these models tend to get trained and iterated upon on almost a continuous
[00:17:26.380 --> 00:17:29.340]   basis like the ones which go on the car.
[00:17:29.340 --> 00:17:34.520]   One thing that I remember being kind of an issue, did these models feed into each other?
[00:17:34.520 --> 00:17:39.200]   I remember when I was building models, there's a big versioning problem of one changes and
[00:17:39.200 --> 00:17:42.720]   the downstream ones need to update.
[00:17:42.720 --> 00:17:47.880]   Do you actually then retrain everything downstream from a model if you change an upstream model?
[00:17:47.880 --> 00:17:50.400]   How do you keep track of that?
[00:17:50.400 --> 00:17:53.400]   So the models do feed into each other.
[00:17:53.400 --> 00:17:54.840]   So that does happen.
[00:17:54.840 --> 00:17:58.840]   So this is where I would say that since I'm not day to day involved in this work, I don't
[00:17:58.840 --> 00:18:01.240]   know the specific details about how the team manages it.
[00:18:01.240 --> 00:18:06.440]   But the way they do that is I don't think that you have to go and retrain the downstream
[00:18:06.440 --> 00:18:07.440]   models.
[00:18:07.440 --> 00:18:11.000]   The way we think about it is that you will have your model metrics.
[00:18:11.000 --> 00:18:14.640]   So you'll train your model, you'll get a bunch of metrics around that model.
[00:18:14.640 --> 00:18:15.740]   But that's not enough.
[00:18:15.740 --> 00:18:18.800]   So you have to kind of look at downstream metrics also.
[00:18:18.800 --> 00:18:22.080]   So because quite often those tend to be the trickiest bugs also.
[00:18:22.080 --> 00:18:26.220]   So you'll kind of train your model and it all looks good in terms of the metrics and
[00:18:26.220 --> 00:18:27.220]   it's all working fine.
[00:18:27.220 --> 00:18:31.160]   You deploy it in the car and then you'll see the behavior change quite a bit.
[00:18:31.160 --> 00:18:35.400]   I don't know, the car may decide to brake more often or it may, I don't know, do something
[00:18:35.400 --> 00:18:36.720]   different.
[00:18:36.720 --> 00:18:41.880]   And then you have to kind of debug that because the model's behavior has impacted something
[00:18:41.880 --> 00:18:42.880]   downstream.
[00:18:42.880 --> 00:18:45.300]   So then you're going to debug that.
[00:18:45.300 --> 00:18:50.040]   So it's not necessary that you have to retrain those downstream models.
[00:18:50.040 --> 00:18:53.600]   You may just want to go and figure out where the interaction is happening.
[00:18:53.600 --> 00:18:59.360]   But there are a few things you do have to be very careful about, like the validation
[00:18:59.360 --> 00:19:06.040]   set that you use to validate this model and the training set that you use for the model
[00:19:06.040 --> 00:19:07.040]   downstream.
[00:19:07.040 --> 00:19:11.560]   You have to be very careful of keeping them all separated and hopefully there's no overlap.
[00:19:11.560 --> 00:19:15.000]   Otherwise you may introduce some weird artifacts.
[00:19:15.000 --> 00:19:18.480]   So those things the team has to be very careful about.
[00:19:18.480 --> 00:19:21.920]   Do you think it's harder with these kinds of modeling stuff?
[00:19:21.920 --> 00:19:26.080]   A lot of people have talked about predicting timelines is much more difficult.
[00:19:26.080 --> 00:19:29.040]   Have you found that to be the case?
[00:19:29.040 --> 00:19:30.280]   Predicting timelines?
[00:19:30.280 --> 00:19:31.280]   Timelines of improvements.
[00:19:31.280 --> 00:19:35.440]   I feel like software is already hard, right?
[00:19:35.440 --> 00:19:41.640]   With the models, it almost seems like it might be unknowable to know how we get X percent
[00:19:41.640 --> 00:19:42.640]   improvement.
[00:19:42.640 --> 00:19:47.600]   Do you give your team goals where you'll say, "Look, I want to see a 10 percent improvement
[00:19:47.600 --> 00:19:51.880]   on this accuracy metric"?
[00:19:51.880 --> 00:19:55.960]   That's how they set themselves goals for improving it.
[00:19:55.960 --> 00:19:58.840]   I think ultimately it's the same with any software.
[00:19:58.840 --> 00:20:04.040]   So you set yourself a goal, but just because it's machine learning doesn't mean that it's
[00:20:04.040 --> 00:20:05.680]   a new problem.
[00:20:05.680 --> 00:20:10.760]   The problem has got to do with the fact that you really don't know the perfect solution
[00:20:10.760 --> 00:20:15.400]   and you can't really estimate what it will take for you to get to the perfect solution.
[00:20:15.400 --> 00:20:21.600]   So the way you do that is by a series of experiments, like by iteration.
[00:20:21.600 --> 00:20:26.160]   Because if you know exactly what to write, then you can pretty accurately estimate the
[00:20:26.160 --> 00:20:27.160]   time.
[00:20:27.160 --> 00:20:28.160]   And sometimes that's the case.
[00:20:28.160 --> 00:20:34.600]   Say you know, "Oh yeah, I need to refactor this code."
[00:20:34.600 --> 00:20:36.680]   So you know roughly how long it will take.
[00:20:36.680 --> 00:20:40.440]   And you have test cases around, you can test it so you know all your unknown unknowns,
[00:20:40.440 --> 00:20:43.080]   all of those things are taken care of.
[00:20:43.080 --> 00:20:45.680]   So you become more and more predictable over time.
[00:20:45.680 --> 00:20:47.440]   That's basically what I'm trying to say.
[00:20:47.440 --> 00:20:53.240]   Basically what happens is that as you keep working on the problem, you start having a
[00:20:53.240 --> 00:20:57.920]   better idea about how long it will take.
[00:20:57.920 --> 00:21:02.440]   Because you start developing intuition about that particular area.
[00:21:02.440 --> 00:21:09.280]   So like, then you probably have unit tests or like integration tests or some other tests
[00:21:09.280 --> 00:21:14.920]   that help you guide and focus on the right areas and carve out the noise.
[00:21:14.920 --> 00:21:21.960]   So then you tend to get a lot more predictable in the work that you do.
[00:21:21.960 --> 00:21:27.480]   Then after that, if you change your model, you come in with a new model, you know how
[00:21:27.480 --> 00:21:29.160]   many experiments you need to run.
[00:21:29.160 --> 00:21:30.160]   You know how to scan.
[00:21:30.160 --> 00:21:33.520]   I mean, then at that point, it's like throwing money at the problem.
[00:21:33.520 --> 00:21:40.400]   You parallelize it and you do a lot more work.
[00:21:40.400 --> 00:21:44.440]   But you are getting more and more predictable over time, just because you've built all this
[00:21:44.440 --> 00:21:46.840]   intuition and all this collateral to test.
[00:21:46.840 --> 00:21:52.840]   So I would say that, going back to your question, are they predictable?
[00:21:52.840 --> 00:21:54.160]   Definitely not at the outset.
[00:21:54.160 --> 00:21:57.680]   But as they start working on it, they get better and better, more accurate about it
[00:21:57.680 --> 00:21:59.760]   in terms of how much they can.
[00:21:59.760 --> 00:22:04.600]   And this is even like predicting improvements, like incremental improvements.
[00:22:04.600 --> 00:22:12.000]   I would say more like, let's say they're trying to fix issues.
[00:22:12.000 --> 00:22:16.640]   So then they tend to get more and more predictable about that.
[00:22:16.640 --> 00:22:19.840]   Now if they're bringing in, if they say, oh, they set themselves a goal, let's say I'm
[00:22:19.840 --> 00:22:24.600]   going to improve it by X percentage improvement.
[00:22:24.600 --> 00:22:29.160]   So the best way they can do that is by running a whole bunch of experiments and see how fast
[00:22:29.160 --> 00:22:30.240]   they can come.
[00:22:30.240 --> 00:22:36.840]   So even that, if your infrastructure is better and you have a good set of tests and all that,
[00:22:36.840 --> 00:22:38.340]   you can get incrementally better.
[00:22:38.340 --> 00:22:41.680]   But I don't think that it's any different than any other software development that you
[00:22:41.680 --> 00:22:42.680]   can get super predictable.
[00:22:42.680 --> 00:22:47.600]   Well, I guess one question or one thing that some people say is different or that I imagine
[00:22:47.600 --> 00:22:53.120]   is different is that when you think about testing these models before you put them into
[00:22:53.120 --> 00:22:58.680]   production, do you test them against a set of unit tests where it's like, I insist that
[00:22:58.680 --> 00:23:02.280]   the model does this or that the car does this in this situation?
[00:23:02.280 --> 00:23:08.240]   Or is it more like an overall accuracy of like, I want it to make the right decision
[00:23:08.240 --> 00:23:10.600]   99% of the time?
[00:23:10.600 --> 00:23:13.600]   How do you think about that?
[00:23:13.600 --> 00:23:19.440]   Because aren't these models somewhat inherently unpredictable or they're not always going
[00:23:19.440 --> 00:23:22.280]   to do exactly the same thing, right?
[00:23:22.280 --> 00:23:23.280]   Right.
[00:23:23.280 --> 00:23:29.960]   So the way it works is that you have a model and you will have a certain...
[00:23:29.960 --> 00:23:35.680]   I'm talking about perception models because if you are doing something else downstream
[00:23:35.680 --> 00:23:39.640]   in some other area and planning, it's very different.
[00:23:39.640 --> 00:23:45.080]   You will have a certain metrics that you reached today.
[00:23:45.080 --> 00:23:52.680]   And then what you do is, obviously, you're working to go beyond that metric.
[00:23:52.680 --> 00:23:58.160]   So you try to, you can identify that as like as part of your model development, like you
[00:23:58.160 --> 00:24:01.020]   develop it, you have the model results.
[00:24:01.020 --> 00:24:02.020]   But that's not enough.
[00:24:02.020 --> 00:24:07.160]   So you then have to do like some level of integration testing.
[00:24:07.160 --> 00:24:08.600]   You put it all together.
[00:24:08.600 --> 00:24:11.920]   And then you see like, hey, how's the downstream metric?
[00:24:11.920 --> 00:24:12.920]   Let's say if it's perception.
[00:24:12.920 --> 00:24:18.120]   So the output of perception that like really planning would consume is like what we call
[00:24:18.120 --> 00:24:19.120]   tracks.
[00:24:19.120 --> 00:24:24.520]   So these are basically objects over time that you track over time.
[00:24:24.520 --> 00:24:30.080]   So you have to get those tracking metrics improved or better or impacted in one way
[00:24:30.080 --> 00:24:33.240]   or another in those areas.
[00:24:33.240 --> 00:24:37.680]   And then when you put that in the car, then you know, like the top level metrics that
[00:24:37.680 --> 00:24:45.720]   you have, you know, like how is the car behaving, like in whether it is driving, is it comfortable?
[00:24:45.720 --> 00:24:46.720]   Is it safe?
[00:24:46.720 --> 00:24:51.280]   So what are the metrics that you track for any of those things?
[00:24:51.280 --> 00:24:53.280]   So you have to kind of get that right.
[00:24:53.280 --> 00:24:55.560]   So you kind of have to like go through this entire journey.
[00:24:55.560 --> 00:25:01.520]   So it's not like one, you just do the model once and then it works.
[00:25:01.520 --> 00:25:05.280]   And are you able to like run these tests like every time there's a new model or do you kind
[00:25:05.280 --> 00:25:09.040]   of like try to pass the first test and then sort of expand out?
[00:25:09.040 --> 00:25:13.600]   Yeah, you have to run through the entire gamut if you do something brand new.
[00:25:13.600 --> 00:25:20.080]   Do you have any interesting examples of something that sort of improved the local test but made
[00:25:20.080 --> 00:25:21.080]   the more...
[00:25:21.080 --> 00:25:24.080]   Yeah, there's a bunch of examples.
[00:25:24.080 --> 00:25:27.280]   Thing is, I don't know what I can tell you.
[00:25:27.280 --> 00:25:28.280]   Fair enough.
[00:25:28.280 --> 00:25:29.280]   Yeah.
[00:25:29.280 --> 00:25:35.800]   Yeah, I mean, there are all these cases like where you'll see the interaction between the
[00:25:35.800 --> 00:25:41.560]   model, say the upstream model, say in the perception and what happens on the planning
[00:25:41.560 --> 00:25:42.560]   side.
[00:25:42.560 --> 00:25:47.480]   I mean, I can tell you as a friend, but maybe I should put it up there on the...
[00:25:47.480 --> 00:25:48.480]   Okay, no worries.
[00:25:48.480 --> 00:25:55.680]   You know, like I was just giving you the example of that one where we had...
[00:25:55.680 --> 00:26:00.120]   I was telling about, you know, like in winter, like you have a lot more smoke that you have
[00:26:00.120 --> 00:26:01.120]   to deal with.
[00:26:01.120 --> 00:26:05.640]   So you could see that like the model performance was pretty good, but like when we integrated
[00:26:05.640 --> 00:26:07.280]   it, it didn't work right.
[00:26:07.280 --> 00:26:13.360]   And so then we had to go back and see if there was some interaction going on between like
[00:26:13.360 --> 00:26:15.840]   the upstream model and the downstream model that caused this problem.
[00:26:15.840 --> 00:26:17.240]   So we already debug these.
[00:26:17.240 --> 00:26:19.840]   These kinds of things happen all the time.
[00:26:19.840 --> 00:26:23.560]   So the team over time has become much more rigorous about all these things.
[00:26:23.560 --> 00:26:26.880]   So anytime they do this, there's a lot of automation built in.
[00:26:26.880 --> 00:26:28.480]   They test all of these things.
[00:26:28.480 --> 00:26:34.480]   And yeah, so they have to go through the whole thing.
[00:26:34.480 --> 00:26:35.480]   I see.
[00:26:35.480 --> 00:26:45.720]   When you see teams improve models, is it typically that they've collected more different data
[00:26:45.720 --> 00:26:50.160]   or kind of changed the data pipeline or improved the model itself?
[00:26:50.160 --> 00:26:52.920]   Do you have a sense of what's...
[00:26:52.920 --> 00:26:53.920]   I guess like what's...
[00:26:53.920 --> 00:26:54.920]   A lot of time.
[00:26:54.920 --> 00:26:57.440]   Most often you'll see the improvements happen with the right data.
[00:26:57.440 --> 00:26:59.000]   Interesting, the right data.
[00:26:59.000 --> 00:27:01.360]   It's less the model architecture.
[00:27:01.360 --> 00:27:05.120]   It's less often that the model architecture itself has to be changed.
[00:27:05.120 --> 00:27:06.120]   Got it.
[00:27:06.120 --> 00:27:07.120]   Yeah.
[00:27:07.120 --> 00:27:10.640]   But is it like an ML team itself that's asking for different types of datasets?
[00:27:10.640 --> 00:27:15.000]   Do they kind of control that process or is there like a data team?
[00:27:15.000 --> 00:27:16.000]   No, no, we don't.
[00:27:16.000 --> 00:27:17.000]   Okay.
[00:27:17.000 --> 00:27:22.640]   So this is another big thing that we've been, I would say, somewhat religious about at level
[00:27:22.640 --> 00:27:23.640]   five.
[00:27:23.640 --> 00:27:28.280]   We don't have a notion of like engineering team and a science team or a data team.
[00:27:28.280 --> 00:27:30.000]   We just have a perception team.
[00:27:30.000 --> 00:27:36.200]   So I think like, I'll tell you my mental model around like an ML.
[00:27:36.200 --> 00:27:39.080]   I think ML is a skill.
[00:27:39.080 --> 00:27:42.680]   So it's like anything, you know, you know how to write Python, great.
[00:27:42.680 --> 00:27:43.680]   Or you know how to write C++.
[00:27:43.680 --> 00:27:44.680]   That's a skill.
[00:27:44.680 --> 00:27:48.520]   So ML is a skill, but a skill alone is not enough.
[00:27:48.520 --> 00:27:50.920]   Like, so you need domain expertise.
[00:27:50.920 --> 00:27:56.600]   So just because you know how to write Python may be good enough for some things, but if
[00:27:56.600 --> 00:28:00.320]   you're trying to build, I don't know, some complex insurance thing, like you probably
[00:28:00.320 --> 00:28:02.360]   need to understand insurance.
[00:28:02.360 --> 00:28:08.360]   So how do you divide the domain knowledge from the skill?
[00:28:08.360 --> 00:28:10.760]   In some cases you can, like, and you see that happening.
[00:28:10.760 --> 00:28:14.440]   Like, so you'll have PMs write a spec and then they'll give you something and say like,
[00:28:14.440 --> 00:28:16.200]   go implement it.
[00:28:16.200 --> 00:28:21.120]   But more often you'll see that like the engineer has to really ramp up and truly understand
[00:28:21.120 --> 00:28:25.080]   like what the actual problem is, because if they have to debug something and they have
[00:28:25.080 --> 00:28:27.680]   to kind of really understand what is going on.
[00:28:27.680 --> 00:28:28.680]   It's the same thing in ML.
[00:28:28.680 --> 00:28:33.280]   So we try to kind of have, we have a team that is called a prediction team.
[00:28:33.280 --> 00:28:34.960]   So their job is to predict.
[00:28:34.960 --> 00:28:40.640]   So we don't have a difference between like some data scientist or a data team and like
[00:28:40.640 --> 00:28:41.640]   an engineer.
[00:28:41.640 --> 00:28:47.200]   So it's the same people who have the domain expertise and have ML skills.
[00:28:47.200 --> 00:28:49.440]   And that's kind of how we've been operating so far.
[00:28:49.440 --> 00:28:50.440]   That's cool.
[00:28:50.440 --> 00:28:54.320]   So all of your teams sort of have a mix of skill sets.
[00:28:54.320 --> 00:28:55.320]   Yeah.
[00:28:55.320 --> 00:29:01.560]   So I've seen this like, there seems to be a pretty big debate in the industry, like,
[00:29:01.560 --> 00:29:06.980]   you know, there'll be this, oh, should we have a science and an engineering team idea?
[00:29:06.980 --> 00:29:12.560]   So the mental model I come up with is like, job of a science is to develop knowledge,
[00:29:12.560 --> 00:29:16.220]   what they produce, their production is knowledge.
[00:29:16.220 --> 00:29:19.620]   And the job of an engineering team is an artifact.
[00:29:19.620 --> 00:29:25.020]   In most cases, we are actually building an artifact, we are building a product.
[00:29:25.020 --> 00:29:29.420]   So in which case I kind of see that science versus engineering divide to be less germane
[00:29:29.420 --> 00:29:30.680]   in these areas.
[00:29:30.680 --> 00:29:33.800]   You can have a research team, their job is to produce knowledge.
[00:29:33.800 --> 00:29:35.040]   And that's okay.
[00:29:35.040 --> 00:29:40.300]   But when it comes to developing a product, I've always found that it is better to have
[00:29:40.300 --> 00:29:42.980]   the domain knowledge and the skilled people together.
[00:29:42.980 --> 00:29:46.100]   And ideally, if you can find the unicorns, which are both, that's awesome.
[00:29:46.100 --> 00:29:50.340]   So but you'll have very few of those, but then you kind of have to bracket them with
[00:29:50.340 --> 00:29:51.900]   people with the right skills.
[00:29:51.900 --> 00:29:53.820]   Does that make sense?
[00:29:53.820 --> 00:29:54.820]   No, totally.
[00:29:54.820 --> 00:29:55.820]   Yeah.
[00:29:55.820 --> 00:29:58.540]   I mean, we see the same thing with a lot of the companies we work with.
[00:29:58.540 --> 00:30:05.640]   And I do, I think if I was in charge, I think I would lean the same way as you.
[00:30:05.640 --> 00:30:11.200]   Make sure that the people doing ML are right inside the teams that are actually trying
[00:30:11.200 --> 00:30:12.200]   to accomplish something.
[00:30:12.200 --> 00:30:13.200]   Right.
[00:30:13.200 --> 00:30:14.760]   And now coming back to the data question that you asked.
[00:30:14.760 --> 00:30:21.600]   So if you are a domain specialist, you already have a very good intuition about what is the
[00:30:21.600 --> 00:30:24.200]   right data that you want.
[00:30:24.200 --> 00:30:30.560]   So and like we just said, most of the problems seem to be about finding the right data than
[00:30:30.560 --> 00:30:32.640]   the right model.
[00:30:32.640 --> 00:30:38.720]   So you have this nice property where the team just knows what is the right data to seek.
[00:30:38.720 --> 00:30:39.720]   Got it.
[00:30:39.720 --> 00:30:40.720]   That makes sense.
[00:30:40.720 --> 00:30:43.920]   Is it challenging for you to deploy models into production?
[00:30:43.920 --> 00:30:47.120]   I've never had to deploy into hardware.
[00:30:47.120 --> 00:30:48.920]   Is that a challenging step for you?
[00:30:48.920 --> 00:30:53.720]   Do you find sometimes the model doesn't perform the same way you expected when it's actually
[00:30:53.720 --> 00:30:54.720]   inside the hardware?
[00:30:54.720 --> 00:31:01.640]   I think the biggest difference between what you say, like when you're building it for
[00:31:01.640 --> 00:31:09.560]   like a cloud service versus what we are doing here is that the model, they may be like a
[00:31:09.560 --> 00:31:11.600]   transform after training.
[00:31:11.600 --> 00:31:12.600]   Right.
[00:31:12.600 --> 00:31:17.440]   Generally, and the transform after training, you could say quantization or something like
[00:31:17.440 --> 00:31:18.440]   that.
[00:31:18.440 --> 00:31:19.440]   Right.
[00:31:19.440 --> 00:31:24.120]   So you need understanding about that, about the impact of that on the model.
[00:31:24.120 --> 00:31:28.160]   The other thing that becomes really important when you're deploying it, and this is no different
[00:31:28.160 --> 00:31:34.360]   for mobile apps also, where you deploy models in your mobile phone, is that you have to
[00:31:34.360 --> 00:31:38.320]   be really careful about power and latency.
[00:31:38.320 --> 00:31:42.560]   So you have to really be rigorous about your op count, how much time does it take?
[00:31:42.560 --> 00:31:45.800]   So all of that you have to think about.
[00:31:45.800 --> 00:31:50.560]   Have you built infrastructure to actually monitor these models as they run in production?
[00:31:50.560 --> 00:31:51.560]   Yeah.
[00:31:51.560 --> 00:31:57.960]   So actually we have an internal framework that, in fact, I was just watching their video
[00:31:57.960 --> 00:31:58.960]   just before this.
[00:31:58.960 --> 00:32:02.240]   They were doing a demo because they had just built a new one.
[00:32:02.240 --> 00:32:03.800]   And that takes care of all of these for you.
[00:32:03.800 --> 00:32:11.240]   So it'll kind of do the stats and everything when you are building and training your model
[00:32:11.240 --> 00:32:13.080]   and running your experiments.
[00:32:13.080 --> 00:32:18.680]   In fact, we dump all of that probably in your tool.
[00:32:18.680 --> 00:32:19.680]   Cool.
[00:32:19.680 --> 00:32:21.180]   Do you look for...
[00:32:21.180 --> 00:32:24.240]   Some people talk to us about worrying about feature drift.
[00:32:24.240 --> 00:32:26.360]   Would you notice if a sensor broke or something?
[00:32:26.360 --> 00:32:29.880]   If the model is getting a different kind of data, is that something you look for?
[00:32:29.880 --> 00:32:33.040]   Or is it mainly just latency of the model?
[00:32:33.040 --> 00:32:34.040]   Oh, I see.
[00:32:34.040 --> 00:32:37.400]   So you're talking about the model, some strange behavior.
[00:32:37.400 --> 00:32:42.120]   Yeah, if it gets a weird situation where it seems to be struggling.
[00:32:42.120 --> 00:32:43.120]   Yeah.
[00:32:43.120 --> 00:32:44.880]   So there could be so many problems, right?
[00:32:44.880 --> 00:32:45.880]   So it could be...
[00:32:45.880 --> 00:32:46.880]   Yeah, for sure.
[00:32:46.880 --> 00:32:47.880]   Yeah, yeah, yeah.
[00:32:47.880 --> 00:32:51.400]   So it could be some sensor has gone bad.
[00:32:51.400 --> 00:32:57.360]   I was just thinking about something specific here.
[00:32:57.360 --> 00:32:59.720]   Yeah, those things happen.
[00:32:59.720 --> 00:33:03.960]   But the way we find out a bunch of these things is that increasingly we depend on something
[00:33:03.960 --> 00:33:05.920]   we call unsupervised metrics.
[00:33:05.920 --> 00:33:11.160]   So imagine, what's the rough size of a bicycle?
[00:33:11.160 --> 00:33:15.480]   Yeah, I don't know what, like a meter or two, two meters?
[00:33:15.480 --> 00:33:16.480]   Oh, no, it's going to be...
[00:33:16.480 --> 00:33:19.680]   I mean, width probably, but like probably a lot more than that.
[00:33:19.680 --> 00:33:21.680]   Oh, yeah, I guess you're right.
[00:33:21.680 --> 00:33:23.520]   Maybe a three or four.
[00:33:23.520 --> 00:33:24.520]   Right.
[00:33:24.520 --> 00:33:29.840]   So, but if you see like a 50 meter bicycle, then there's probably something wrong with
[00:33:29.840 --> 00:33:30.840]   it, right?
[00:33:30.840 --> 00:33:35.840]   I'm just giving that as a very extreme example, but you can imagine that there's a lot of
[00:33:35.840 --> 00:33:41.440]   such heuristics that you could put together and track.
[00:33:41.440 --> 00:33:45.560]   And if you start seeing like weird things happening out of that, that enables you to
[00:33:45.560 --> 00:33:47.420]   catch like lots of crazy bugs.
[00:33:47.420 --> 00:33:51.400]   And sometimes that's a really good way of catching long tail issues as well, because
[00:33:51.400 --> 00:33:52.400]   you may not...
[00:33:52.400 --> 00:33:58.200]   It may not result in a disengagement, but you may see some weird behavior, or it may
[00:33:58.200 --> 00:34:02.080]   trigger a disengagement, but it is probably not often enough that like you know that that's
[00:34:02.080 --> 00:34:05.760]   a problem, important problem to focus on.
[00:34:05.760 --> 00:34:12.360]   So we increasingly depend on all these unsupervised metrics where the data comes in, then you
[00:34:12.360 --> 00:34:19.320]   compute all these various interesting statistics, and then you figure out what is actually going
[00:34:19.320 --> 00:34:21.320]   on and then you go back and debug it.
[00:34:21.320 --> 00:34:22.320]   So that's so interesting.
[00:34:22.320 --> 00:34:23.320]   That's funny.
[00:34:23.320 --> 00:34:26.440]   I was just looking at Jira tickets for my company.
[00:34:26.440 --> 00:34:32.600]   And if you see like one thing wrong, does that like warrant a Jira ticket?
[00:34:32.600 --> 00:34:37.960]   Like if you see one bicycle that's too big, will you actually like file a ticket against
[00:34:37.960 --> 00:34:38.960]   that or how do you...
[00:34:38.960 --> 00:34:39.960]   Yeah, you should.
[00:34:39.960 --> 00:34:43.800]   I mean, all of these things should be like filed in a ticket.
[00:34:43.800 --> 00:34:50.080]   And if it is that glaringly obvious, then yeah, and you have the time to do it, to take
[00:34:50.080 --> 00:34:51.080]   a look at it, you will.
[00:34:51.080 --> 00:34:55.160]   So it's only one example where this thing is wrong, we're going to ticket it.
[00:34:55.160 --> 00:34:56.160]   Yeah.
[00:34:56.160 --> 00:34:57.160]   And again, this has got nothing to do with self-driving cars.
[00:34:57.160 --> 00:34:59.360]   I mean, we used to have similar problems in Windows.
[00:34:59.360 --> 00:35:05.280]   You know, like there'll be some weird one-off thing that you saw and we would record it.
[00:35:05.280 --> 00:35:10.880]   And then next thing you know, like if it's some code changes that suddenly things tend
[00:35:10.880 --> 00:35:13.800]   to pop up and then you're like, "Oh yeah, I've seen it in these environments and these
[00:35:13.800 --> 00:35:14.800]   situations."
[00:35:14.800 --> 00:35:16.800]   And then you kind of go and like track it.
[00:35:16.800 --> 00:35:17.800]   So I think it's important to...
[00:35:17.800 --> 00:35:21.280]   Anytime you see something anomalous, you just file it.
[00:35:21.280 --> 00:35:27.440]   And hopefully you have more context that you capture and then it'll help you debug.
[00:35:27.440 --> 00:35:29.960]   And do you have a team that's tasked with looking for that?
[00:35:29.960 --> 00:35:33.840]   Or is that like kind of everybody's looking for those things?
[00:35:33.840 --> 00:35:40.840]   So we have a team that, like obviously a lot of our reports come from the drivers driving
[00:35:40.840 --> 00:35:41.840]   the road.
[00:35:41.840 --> 00:35:51.920]   But then we also have to have additional people to go back and look at the data and see if
[00:35:51.920 --> 00:35:53.240]   there's something weird going on.
[00:35:53.240 --> 00:35:57.380]   They're not necessarily engineers, we call them operations.
[00:35:57.380 --> 00:36:00.480]   So they kind of scan and take a look at these things.
[00:36:00.480 --> 00:36:08.240]   And of course, engineers also run into these interesting cases and they may actually look
[00:36:08.240 --> 00:36:09.240]   at it as well.
[00:36:09.240 --> 00:36:15.920]   But there's so much data coming in that which one do you look at and how do you prioritize?
[00:36:15.920 --> 00:36:17.640]   That really becomes a more interesting problem.
[00:36:17.640 --> 00:36:19.760]   Yeah, it sounds incredibly challenging.
[00:36:19.760 --> 00:36:20.760]   Yeah.
[00:36:20.760 --> 00:36:26.720]   I mean, by the way, this is a problem of any software that has scale.
[00:36:26.720 --> 00:36:36.160]   So in our case, I had again the luck to work on major products that operated at scale.
[00:36:36.160 --> 00:36:42.080]   And it's the same problem, whether you're running Newspeed at Facebook or you're running
[00:36:42.080 --> 00:36:49.080]   some issues in Windows or you're running a car on the road for thousands of miles.
[00:36:49.080 --> 00:36:51.680]   So then you'll get lots and lots of reports.
[00:36:51.680 --> 00:36:52.680]   And that's the issue of diversity.
[00:36:52.680 --> 00:36:56.920]   Yeah, I guess these are just issues of complexity and scale.
[00:36:56.920 --> 00:36:59.400]   Yeah, it's a complexity and scale problem.
[00:36:59.400 --> 00:37:01.800]   So it's an extremely simple problem.
[00:37:01.800 --> 00:37:05.320]   You have a sanitized test track and you're running your car in that.
[00:37:05.320 --> 00:37:12.160]   It's probably you can be very selective about what you do and be very rigorous.
[00:37:12.160 --> 00:37:14.920]   But when you're running it on the road, anything can happen.
[00:37:14.920 --> 00:37:22.880]   And it's kind of like you run your operating system on any kind of PC, anybody will turn
[00:37:22.880 --> 00:37:23.880]   it.
[00:37:23.880 --> 00:37:26.560]   You still have to figure out what's happening.
[00:37:26.560 --> 00:37:32.280]   And so you've been at Lyft for three years almost now?
[00:37:32.280 --> 00:37:33.280]   Yeah.
[00:37:33.280 --> 00:37:36.320]   And the organization must have grown quite a bit in that time.
[00:37:36.320 --> 00:37:40.800]   I'm kind of curious how processes have just changed as the organization has grown and
[00:37:40.800 --> 00:37:41.800]   things have solidified.
[00:37:41.800 --> 00:37:42.800]   A lot, right?
[00:37:42.800 --> 00:37:44.800]   So it's kind of interesting.
[00:37:44.800 --> 00:37:56.880]   There are teams which were non-existent and then they've kind of been built and then now
[00:37:56.880 --> 00:37:57.880]   they're at scale.
[00:37:57.880 --> 00:38:01.840]   I mean, I would say the current perception team is one of those, which is now operating
[00:38:01.840 --> 00:38:02.840]   at scale.
[00:38:02.840 --> 00:38:06.720]   But then there are still some new teams that are forming.
[00:38:06.720 --> 00:38:11.600]   And it almost feels like they're doing things which were, say, a perception team or some
[00:38:11.600 --> 00:38:15.000]   other team was doing it at their beginning.
[00:38:15.000 --> 00:38:18.480]   But of course, they have a lot more guidance now because there are other teams that have
[00:38:18.480 --> 00:38:22.160]   path broken for them and they get through it.
[00:38:22.160 --> 00:38:23.200]   A few things happen.
[00:38:23.200 --> 00:38:30.040]   One is as you kind of get more bigger scale as the organization has grown.
[00:38:30.040 --> 00:38:36.760]   In the beginning, we would not care about where the training was happening.
[00:38:36.760 --> 00:38:41.520]   The engineer would train it on their desktop, the workstation that they had.
[00:38:41.520 --> 00:38:42.520]   It would be like that.
[00:38:42.520 --> 00:38:48.160]   As the team started growing and more engineers started coming in and reproducibility and
[00:38:48.160 --> 00:38:51.560]   all of that started becoming a real problem because multiple people are working on the
[00:38:51.560 --> 00:38:52.560]   same thing.
[00:38:52.560 --> 00:38:56.640]   So then you start becoming much more rigorous in your process.
[00:38:56.640 --> 00:38:57.640]   And that's fine.
[00:38:57.640 --> 00:39:02.920]   That'll work only if you have maybe four of them working together.
[00:39:02.920 --> 00:39:09.600]   But then once you grow beyond that, process won't fix it or mutual agreements won't fix
[00:39:09.600 --> 00:39:10.600]   it.
[00:39:10.600 --> 00:39:15.360]   So you probably should be building a framework to help you standardize that process and just
[00:39:15.360 --> 00:39:21.040]   make you not worry about all the moving parts.
[00:39:21.040 --> 00:39:24.040]   And then after that, you'll find that framework doesn't last you.
[00:39:24.040 --> 00:39:27.960]   And then you'll write a new framework for the new scale of problems that you run into.
[00:39:27.960 --> 00:39:29.960]   And we've gone through all of that.
[00:39:29.960 --> 00:39:35.160]   And another thing that will happen is as you ramp up and you grow that much, you'll start
[00:39:35.160 --> 00:39:37.760]   becoming cognizant of your cost.
[00:39:37.760 --> 00:39:44.280]   Because especially if you're doing it on the cloud, they provide a lot of sharp knives.
[00:39:44.280 --> 00:39:51.040]   And as you play with them, you can cut yourself and bleed yourself to death in terms of money.
[00:39:51.040 --> 00:39:55.800]   And so again, you start becoming very, very careful about it.
[00:39:55.800 --> 00:40:01.840]   And you kind of try to build your ML frameworks or whatever, maybe it's not just ML, but even
[00:40:01.840 --> 00:40:02.840]   simulation.
[00:40:02.840 --> 00:40:06.920]   You start building your frameworks to help keep that in check.
[00:40:06.920 --> 00:40:10.160]   Then you start becoming very, very rigorous about your data partitioning.
[00:40:10.160 --> 00:40:15.120]   And you have to have versioning and you track all of them in a tool.
[00:40:15.120 --> 00:40:19.360]   And you probably want a custom tool, which is kind of why how we ended up building our
[00:40:19.360 --> 00:40:23.080]   own analytics tool internally to track a number of these things.
[00:40:23.080 --> 00:40:25.800]   And then you start getting even more to track all your experiment data.
[00:40:25.800 --> 00:40:28.880]   And then you've built in weights and biases.
[00:40:28.880 --> 00:40:30.960]   Then you start running into time problems.
[00:40:30.960 --> 00:40:33.680]   You do more and more complicated models.
[00:40:33.680 --> 00:40:36.080]   And then you want to get done with your experiments faster.
[00:40:36.080 --> 00:40:38.320]   And then you start getting into distributed training.
[00:40:38.320 --> 00:40:40.560]   And you've gone through this entire journey.
[00:40:40.560 --> 00:40:41.560]   I'm sure there's more.
[00:40:41.560 --> 00:40:42.560]   Yeah, what's next?
[00:40:42.560 --> 00:40:43.560]   I'm sure there's more.
[00:40:43.560 --> 00:40:51.560]   I'm sure if I talk to somebody at Google, they've probably gone even further than a
[00:40:51.560 --> 00:40:53.560]   lot of the things you've done.
[00:40:53.560 --> 00:40:54.560]   Well, thanks.
[00:40:54.560 --> 00:40:55.560]   That was well said.
[00:40:55.560 --> 00:40:56.560]   We always close with two questions.
[00:40:56.560 --> 00:40:59.120]   I'm kind of curious how you're going to answer these.
[00:40:59.120 --> 00:41:03.280]   So one is like, it's machine learning specific, but maybe you could expand it to autonomous
[00:41:03.280 --> 00:41:04.280]   vehicles.
[00:41:04.280 --> 00:41:09.440]   I guess what's one underrated aspect of machine learning or AVs that you think people should
[00:41:09.440 --> 00:41:11.520]   pay more attention to than they do?
[00:41:11.520 --> 00:41:15.480]   I noticed that there's a tendency to think of it as just as a skill.
[00:41:15.480 --> 00:41:22.280]   And it's like you throw data at it and then you train and it gets better.
[00:41:22.280 --> 00:41:25.080]   And you can do that over and over again.
[00:41:25.080 --> 00:41:27.120]   And then you may be able to get a good result.
[00:41:27.120 --> 00:41:31.440]   But I always go back to the idea that one very underrated aspect of machine learning
[00:41:31.440 --> 00:41:34.200]   is that it has to be coupled with domain knowledge.
[00:41:34.200 --> 00:41:38.840]   You really have to have a good understanding about what problem you're solving and have
[00:41:38.840 --> 00:41:40.360]   a good understanding of the domain.
[00:41:40.360 --> 00:41:44.880]   In fact, I would say spend quite a bit of time really understanding the data that you're
[00:41:44.880 --> 00:41:46.200]   going to get.
[00:41:46.200 --> 00:41:52.040]   And then because I said, the right data is more important than a lot of data.
[00:41:52.040 --> 00:41:58.160]   Actually there was this interesting case for us where we made some change and we cut down
[00:41:58.160 --> 00:41:59.960]   our data usage by half.
[00:41:59.960 --> 00:42:06.200]   It became way cheaper for us to even like end on which model become more accurate.
[00:42:06.200 --> 00:42:11.240]   So that's what you get by actually genuinely understanding.
[00:42:11.240 --> 00:42:18.400]   I think that's, I would say, I don't hear too much about the domain knowledge.
[00:42:18.400 --> 00:42:26.840]   I think that's something that I would say is very important in this area, especially
[00:42:26.840 --> 00:42:28.680]   with machine learning.
[00:42:28.680 --> 00:42:30.920]   But you could argue it's true for anything.
[00:42:30.920 --> 00:42:31.920]   Yeah.
[00:42:31.920 --> 00:42:32.920]   All right.
[00:42:32.920 --> 00:42:33.920]   Well said.
[00:42:33.920 --> 00:42:38.160]   So here's our last question.
[00:42:38.160 --> 00:42:45.080]   You've actually deployed several serious machine learning products at scale.
[00:42:45.080 --> 00:42:52.320]   And what's been the biggest challenge in taking them from the experimental stage to actually
[00:42:52.320 --> 00:42:54.160]   running in production?
[00:42:54.160 --> 00:42:59.320]   So one of the biggest problems with machine learning is getting it to generalize.
[00:42:59.320 --> 00:43:07.040]   So there are lots of long tail events and the data is typically very sparse in your
[00:43:07.040 --> 00:43:08.640]   data set.
[00:43:08.640 --> 00:43:16.240]   And trying to figure out why that happened, what that happened is generally really difficult.
[00:43:16.240 --> 00:43:23.600]   So this is one area where I think you have to figure out how to combine machine learning
[00:43:23.600 --> 00:43:33.520]   with other techniques in a place where you want to have absolute guarantees in a system
[00:43:33.520 --> 00:43:37.960]   like a robot, where there is actually no human intervention.
[00:43:37.960 --> 00:43:43.560]   In other areas, I think there's some very nice properties if you're doing a human assist.
[00:43:43.560 --> 00:43:48.800]   So ML has a very nice property of being able to do good enough.
[00:43:48.800 --> 00:43:54.360]   Let's say you get some 99 point, some number of lines, and then the remaining can be augmented
[00:43:54.360 --> 00:43:56.720]   by human intelligence.
[00:43:56.720 --> 00:44:03.400]   But if you really are trying to build a robot where it has to be completely autonomous,
[00:44:03.400 --> 00:44:10.040]   you have to figure out additional ways in which you can have some guarantees.
[00:44:10.040 --> 00:44:14.120]   And that's actually quite challenging, figuring out everything.
[00:44:14.120 --> 00:44:15.120]   Seems challenging.
[00:44:15.120 --> 00:44:16.120]   Yeah.
[00:44:16.120 --> 00:44:17.120]   Awesome.
[00:44:17.120 --> 00:44:18.120]   Thank you so much.
[00:44:18.120 --> 00:44:19.880]   It was a real pleasure to talk to you.
[00:44:19.880 --> 00:44:20.880]   Thank you.
[00:44:20.880 --> 00:44:20.880]   Thank you.
[00:44:20.880 --> 00:44:21.380]   Thank you.
[00:44:21.380 --> 00:44:24.740]   [MUSIC PLAYING]
[00:44:24.740 --> 00:44:28.380]   [MUSIC PLAYING]
[00:44:28.380 --> 00:44:32.140]   [Music]

