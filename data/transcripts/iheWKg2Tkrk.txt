
[00:00:00.000 --> 00:00:14.920]   .
[00:00:14.920 --> 00:00:16.760]   Hi everybody, my name is Eno.
[00:00:16.760 --> 00:00:19.880]   I really appreciate that introduction.
[00:00:19.880 --> 00:00:23.800]   And maybe I can start with a bit of background.
[00:00:23.800 --> 00:00:27.520]   I started working on LLMs about two and a half years ago
[00:00:27.520 --> 00:00:31.720]   when GPT 3.5 was coming out.
[00:00:31.720 --> 00:00:35.760]   And it became increasingly clear that agentic systems
[00:00:35.760 --> 00:00:39.040]   were going to be possible with the help of LLMs.
[00:00:39.040 --> 00:00:43.900]   At Factory, we believe that the way that we use agents,
[00:00:43.900 --> 00:00:46.200]   in particular to build software, is
[00:00:46.200 --> 00:00:49.660]   going to radically change the field of software development.
[00:00:49.660 --> 00:00:52.600]   We're transitioning from the era of human-driven software
[00:00:52.600 --> 00:00:55.660]   development to agent-driven development.
[00:00:55.660 --> 00:00:57.640]   You can see glimpses of that today.
[00:00:57.640 --> 00:00:59.840]   You guys have already heard a bunch of great talks
[00:00:59.840 --> 00:01:02.140]   about different ways that agents can help
[00:01:02.140 --> 00:01:04.040]   with coding in particular.
[00:01:04.040 --> 00:01:06.640]   However, it seems like right now we're still
[00:01:06.640 --> 00:01:09.420]   trying to find what that interaction pattern, what
[00:01:09.420 --> 00:01:11.260]   that future looks like.
[00:01:11.260 --> 00:01:13.300]   And a lot of what's publicly available
[00:01:13.300 --> 00:01:15.740]   is more or less an incremental improvement.
[00:01:15.740 --> 00:01:18.740]   The current zeitgeist is to take tools that were developed 20
[00:01:18.740 --> 00:01:23.380]   years ago for humans to write every individual line of code,
[00:01:23.380 --> 00:01:25.960]   and ultimately tools that were designed first and foremost
[00:01:25.960 --> 00:01:27.880]   for human beings.
[00:01:27.880 --> 00:01:29.560]   And you sprinkle AI on top.
[00:01:29.560 --> 00:01:31.600]   And then you keep adding layers of AI.
[00:01:31.600 --> 00:01:33.700]   And then at some point, maybe there's some step function
[00:01:33.700 --> 00:01:35.000]   change that happens.
[00:01:35.000 --> 00:01:36.520]   But there's not a lot of clarity there
[00:01:36.520 --> 00:01:38.900]   in exactly what that means.
[00:01:38.900 --> 00:01:42.560]   You know, there's a quote that is attributed to Henry Ford.
[00:01:42.560 --> 00:01:44.720]   If I had asked people what they wanted,
[00:01:44.720 --> 00:01:47.480]   they would have said, faster horses.
[00:01:47.480 --> 00:01:50.640]   Now, we believe that there are some fundamentally hard problems
[00:01:50.640 --> 00:01:55.560]   blocking organizations from accessing the true power of AI.
[00:01:55.560 --> 00:01:58.460]   This power can only be found when your team
[00:01:58.460 --> 00:02:00.660]   is delegating the majority of their tasks
[00:02:00.660 --> 00:02:04.440]   across the software lifecycle to agents.
[00:02:04.440 --> 00:02:06.980]   To do that, you need a platform that
[00:02:06.980 --> 00:02:11.260]   has an intuitive interface for managing and delegating tasks,
[00:02:11.260 --> 00:02:14.660]   centralized context from across all your engineering tools
[00:02:14.660 --> 00:02:18.160]   and data sources, agents that consistently produce
[00:02:18.160 --> 00:02:22.420]   reliable, high-quality outputs, and infrastructure that
[00:02:22.420 --> 00:02:26.340]   supports thousands of agents working in parallel.
[00:02:26.340 --> 00:02:29.040]   These are all hard problems to solve.
[00:02:29.040 --> 00:02:31.460]   But our team has spent the last two years partnering
[00:02:31.460 --> 00:02:35.880]   with large organizations to build towards this future.
[00:02:35.880 --> 00:02:38.400]   This talk is going to serve as sort of a deep dive
[00:02:38.400 --> 00:02:42.840]   into agent-native development and a bit of a share
[00:02:42.840 --> 00:02:44.900]   of some of the lessons that we've learned helping
[00:02:44.900 --> 00:02:47.640]   enterprise organizations make the transition
[00:02:47.640 --> 00:02:51.480]   to agent-native development.
[00:02:51.480 --> 00:02:54.600]   When Andre Karpathy said, English is the new programming
[00:02:54.600 --> 00:02:57.840]   language, he captured this very exciting moment.
[00:02:57.840 --> 00:03:00.480]   And if you're to judge AI progress based on Twitter,
[00:03:00.480 --> 00:03:02.280]   you'd think that you can basically
[00:03:02.280 --> 00:03:04.260]   vibe code your way to anything.
[00:03:04.260 --> 00:03:09.280]   But vibe coding isn't the approach to solve hard problems.
[00:03:09.280 --> 00:03:12.780]   You can't vibe code a legacy Java 7 app that
[00:03:12.780 --> 00:03:16.600]   runs 5% of the world's global bank transactions.
[00:03:16.600 --> 00:03:19.380]   You need a little bit more software engineering.
[00:03:19.380 --> 00:03:21.600]   So agents really should not be thought
[00:03:21.600 --> 00:03:24.180]   of as a replacement for human ingenuity.
[00:03:24.180 --> 00:03:26.320]   Agents are climbing gear.
[00:03:26.320 --> 00:03:28.820]   And building production software is
[00:03:28.820 --> 00:03:31.120]   like scaling Mount Everest.
[00:03:31.120 --> 00:03:35.940]   And so while better tools have made this climb more accessible,
[00:03:35.940 --> 00:03:39.060]   we still need to think about how to leverage them
[00:03:39.060 --> 00:03:41.820]   and use our existing expertise in order
[00:03:41.820 --> 00:03:43.740]   to drive this transformation.
[00:03:43.740 --> 00:03:47.880]   I want to start with a quick video of what's possible today.
[00:03:47.880 --> 00:03:51.140]   And so in this, you'll see a quick glimpse of what
[00:03:51.140 --> 00:03:55.140]   it's like to delegate a task to an agentic system.
[00:03:55.140 --> 00:03:59.520]   You can watch the droid, as we call them, ingest the task,
[00:03:59.520 --> 00:04:02.300]   and start grounding itself in the environment.
[00:04:02.300 --> 00:04:05.060]   It uses tools to search through the code base,
[00:04:05.060 --> 00:04:09.100]   determine the git branch, check out what the machine has available to it.
[00:04:09.100 --> 00:04:11.240]   It looks through recent changes to the code base.
[00:04:11.240 --> 00:04:19.880]   It looks at memories of its recent interactions with users, as well as memories from its interactions across the entire organization.
[00:04:19.880 --> 00:04:26.380]   And then the droid comes back with a plan and says, here's exactly what I'm going to do, but I'd like you to clarify a couple of things.
[00:04:26.380 --> 00:04:35.020]   We need to expect our agents to not just take what we say at face value, but instead question it and make us better software developers.
[00:04:35.020 --> 00:04:40.300]   And so after the user comes back with that info, the droid comes, it executes on that task,
[00:04:40.300 --> 00:04:47.760]   it leverages its tools to write code, runs pre-commit hooks, lints, and ultimately generates a pull request that passes CI.
[00:04:47.760 --> 00:04:54.760]   But how can you achieve outcomes like this on a regular basis, right?
[00:04:54.760 --> 00:04:57.360]   "It's nice when it works, but what about when it fails?"
[00:04:57.360 --> 00:05:02.160]   At the heart of effective AI-assisted development lies a very fundamental truth.
[00:05:02.160 --> 00:05:06.340]   AI tools are only as good as the context that they receive.
[00:05:06.340 --> 00:05:12.740]   So much of what people are calling prompt engineering is really mentally modeling this alien intelligence
[00:05:12.740 --> 00:05:15.680]   that has a slice of context of the real world.
[00:05:15.680 --> 00:05:20.820]   And if you start thinking about your AI tools this way, you're going to start to get a lot better at interacting with them.
[00:05:20.820 --> 00:05:25.420]   We've investigated thousands of droid-assisted development sessions.
[00:05:25.420 --> 00:05:33.800]   And you see this sort of heuristic emerge, where AI is most likely failing to solve the problem, not because the LLMs aren't good enough,
[00:05:33.800 --> 00:05:38.420]   but because it's missing crucial context that's required to truly solve it.
[00:05:38.420 --> 00:05:44.220]   And better models are going to make this happen less often, but the real solution is not just making the AI smarter.
[00:05:44.220 --> 00:05:49.120]   It's going to be getting better at providing these systems with that missing context.
[00:05:49.120 --> 00:05:52.820]   LLMs don't know about your morning stand-up.
[00:05:52.820 --> 00:05:57.760]   They don't know about the meeting that you had ad hoc and the whiteboard that you did, right?
[00:05:57.760 --> 00:06:04.340]   But you can give those things to the LLM if you transcribe your notes, if you take a photo and you upload it, right?
[00:06:04.340 --> 00:06:13.940]   You have to start thinking about these things not as tools, but as something in between a co-worker and a platform, right?
[00:06:13.940 --> 00:06:22.660]   And if you can get that context that lies in the cracks between systems, you use platforms that integrate natively with all of your data sources,
[00:06:22.660 --> 00:06:30.760]   and you have agents that can actually make use of those things, you can start actually driving this transition to agent-native development.
[00:06:30.760 --> 00:06:34.300]   I want to talk a bit as well about planning and design.
[00:06:34.300 --> 00:06:42.100]   When your organization is doing agent-native development, then you are using agents at every stage.
[00:06:42.100 --> 00:06:44.680]   Droids don't just write code.
[00:06:44.680 --> 00:06:49.060]   They can help with that part, but the hardest thing about software development is not the code.
[00:06:49.060 --> 00:06:52.260]   It's about figuring out exactly what to build.
[00:06:52.260 --> 00:06:59.040]   Here you can watch a droid as it's tasked with trying to find the most up-to-date information about a new model release
[00:06:59.040 --> 00:07:02.160]   and integrate that into an existing chat application.
[00:07:02.160 --> 00:07:09.660]   It's going to leverage internet search, its knowledge of your code base, its understanding of your product goals from its organ memory,
[00:07:09.660 --> 00:07:15.080]   and its understanding of your technical architecture from the design doc you wrote last week.
[00:07:15.080 --> 00:07:19.120]   Planning with AI is fundamentally different from planning alone.
[00:07:19.120 --> 00:07:24.900]   It's not necessarily just asking, "Please build this thing for me, or give me the design doc."
[00:07:24.900 --> 00:07:35.900]   But instead, it's about delegating the groundwork and the research to AI agents, then using a collaborative platform to interact and explore possibilities together.
[00:07:35.900 --> 00:07:40.680]   That is how you get better at planning with agents.
[00:07:40.680 --> 00:07:43.680]   Now you can see here we have a nice document, a nice plan.
[00:07:43.680 --> 00:07:52.680]   You could export that to Notion, Confluence, JIRA, any of your integrations with no setup because MCP is great, but having every developer have to install a bunch of servers,
[00:07:52.680 --> 00:07:58.460]   install a bunch of servers, click a bunch of things, pass around the API key is not necessarily ideal.
[00:07:58.460 --> 00:08:04.920]   And so platforms are going to evolve and solve a lot of these problems, but in the meantime, you do have droids.
[00:08:04.920 --> 00:08:08.460]   And now, a little bit more on this.
[00:08:08.460 --> 00:08:19.140]   The real unlock for AI, transforming your organization with respect to planning, is going to be when you start standardizing the way that your organization thinks.
[00:08:19.140 --> 00:08:28.920]   Right? And so there's a bit of an example that we just had a couple of weeks ago while we were planning out a feature related to our cloud development environments.
[00:08:28.920 --> 00:08:34.160]   We got a lot of feedback from users, and so we had about three months of user transcripts.
[00:08:34.160 --> 00:08:40.700]   People from enterprises, individuals that we knew, we transcribe every single interaction and meeting at Factory.
[00:08:40.700 --> 00:08:47.000]   We take those notes and we combine them with a droid that has access to our architecture.
[00:08:47.000 --> 00:08:56.780]   We take an ad hoc meeting that one of our engineers took a granola of, if you guys use granola, I love that tool, and we throw that all to the knowledge droid.
[00:08:56.780 --> 00:09:00.780]   And we say, we don't say, let's plan the feature out.
[00:09:00.780 --> 00:09:06.780]   We say, could you find any patterns in the customer feedback that map up to our assumptions?
[00:09:06.780 --> 00:09:12.660]   Can you highlight any technical constraints with what we have today that might help us make this better?
[00:09:12.660 --> 00:09:26.440]   And then we take all of that output, those documents, there's maybe four or five intermediate results here, and that's what we use to start iterating on a final PRD that helps us outline the full feature.
[00:09:26.440 --> 00:09:39.220]   You can take that PRD, and if you have a droid that has access to linear and JIRA with tools to create tickets, create epics, modify those things, then that PRD can be turned into a roadmap.
[00:09:39.220 --> 00:09:48.220]   Eight tickets, this ticket is dependent on that ticket, but ultimately work that can be parallelized amongst a group of eight code droids.
[00:09:48.220 --> 00:09:59.000]   Right? And so this is how software is going to evolve. We're going to move from executing to orchestrating systems that work on our behalf.
[00:09:59.000 --> 00:10:07.840]   I talked about a couple of these. I think PRDs, ENG design docs, RCA templates, quarterly ENG and product roadmaps, right?
[00:10:07.840 --> 00:10:15.220]   Transcriptions of your meetings. Normally, you might see this stuff as a burden, but when your company is doing agent-native software development,
[00:10:15.220 --> 00:10:24.960]   your process and your documentation is a knowledge base and a map for your droids to learn and imitate the way that your team thinks.
[00:10:24.960 --> 00:10:33.000]   This documentation and process is a conversation with both future developers as well as future AI systems.
[00:10:33.000 --> 00:10:40.940]   And so if you can communicate that why behind the decision, that context for those future developers and agents,
[00:10:40.940 --> 00:10:49.720]   if you can communicate, then you'll start to see that there's a huge lift in their ability to natively work the way that your team actually works.
[00:10:49.720 --> 00:10:56.920]   I want to talk about agent-driven development with respect to site reliability engineering.
[00:10:56.920 --> 00:11:06.660]   There is a lot that goes into a real incident response. It would be crazy for me to go up here and say you could actually just automate all of SRE and RCA work today.
[00:11:06.660 --> 00:11:18.400]   But there is a difference in the AI agent-driven approach, right? Here we're watching a droid take a sentry incident and convert it into a full RCA and mitigation plan.
[00:11:18.400 --> 00:11:30.140]   Traditional incident response is effectively solving a puzzle. The pieces are scattered across dozens of systems. Logs in one place, metrics in another, historical context somewhere else.
[00:11:30.140 --> 00:11:36.060]   There's knowledge in your team's head. Droids in your organization fundamentally change this, right?
[00:11:36.060 --> 00:11:44.840]   When an alert triggers, you can pull in context from relevant system logs, past incident, runbooks in Notion or Confluence, team discussions from Slack.
[00:11:44.840 --> 00:11:54.620]   And you can see that a droid that has the tools and the ability to access this can condense that search effort from hours to minutes.
[00:11:54.620 --> 00:12:02.620]   And so really, the acceptable time to act for a standard enterprise organization, it's really going to be zero, right?
[00:12:02.620 --> 00:12:08.620]   The moment that an incident happens, you should have a droid that's telling you exactly what happened, exactly how to fix it.
[00:12:08.620 --> 00:12:18.520]   And the thing that gets interesting is when you have user and organization level memory, you really start to build a model of what your team's response patterns and common issues are.
[00:12:18.520 --> 00:12:28.360]   And so it's not just generating runbooks or generating a mitigation for one incident, right, but creating new processes that help solve some of these issues.
[00:12:28.360 --> 00:12:38.600]   And once you've written that RCA, right, you can move on to generate runbooks for those new learned patterns, update existing responses,
[00:12:38.600 --> 00:12:56.580]   RCA, right, and RCA, right, you can move on to the next slide, right, you can move on to the next slide, right, and then you can move on to the next slide, right, and then you can move on to the next slide, and then you can move on to the next slide, and then you can move on to the next slide, and then you can move on to the next slide, and then you can move on to the next slide.
[00:12:56.580 --> 00:13:03.880]   So, we're seeing teams that are able to cut incident response time in half because context is immediate.
[00:13:03.880 --> 00:13:20.320]   They're able to reduce repeat incidents because the third time something happens, the droid starts to say, maybe we should fix this, and they're able to improve team collaboration because when a new engineer joins the team and says, how do we do this, it's already in memory.
[00:13:20.320 --> 00:13:41.460]   So, most importantly, what we're seeing in general is a shift from reactive to predictive operations because you can now start to really see the patterns across the entire operational history, and agentic systems turn each of these incidents into an opportunity to make the entire system far more reliable.
[00:13:43.320 --> 00:13:46.560]   AI agents are not replacing software engineers.
[00:13:46.560 --> 00:13:50.800]   They're significantly amplifying their individual capabilities.
[00:13:50.800 --> 00:13:57.060]   The best developers I know are spending far less time in the IDE writing lines of code.
[00:13:57.060 --> 00:13:58.740]   It's just not high leverage.
[00:13:58.740 --> 00:14:12.380]   They're managing agents that can do multiple things at once, that are capable of organizing the systems, and they're building out patterns that supersede the inner loop of software development, and they're moving to the outer loop of software development.
[00:14:12.380 --> 00:14:15.740]   They aren't worried about agents taking their jobs.
[00:14:15.740 --> 00:14:19.640]   They're too busy using the agents to become even better at what they do.
[00:14:19.640 --> 00:14:27.540]   The future belongs to developers who understand how to work with agents, not those who hope that AI will just do the work for them.
[00:14:27.540 --> 00:14:41.880]   And in that future, the skill that matters most is not technical knowledge or your ability to optimize a specific system, but your ability to think clearly and communicate effectively with both humans and AI.
[00:14:41.880 --> 00:14:55.080]   Now, if you find any of this interesting, and you want to try the droids, I'm happy to share that everyone here at this talk can use this QR code to sign up for an account.
[00:14:55.680 --> 00:15:05.980]   Our mobile experience is not optimized yet, but the droids are on that, and so I'd recommend trying this on a laptop, but you will get 20 million free tokens credited to your account.
[00:15:06.680 --> 00:15:11.820]   And I also want to add that, you know, first and foremost, factory is an enterprise platform, right?
[00:15:11.820 --> 00:15:23.340]   And so if you're thinking about security, if you're thinking about where are the audit logs, whose responsibility is it when an agent goes and runs remove RF recursive on your code base, right?
[00:15:23.340 --> 00:15:24.780]   Droids don't do that.
[00:15:24.780 --> 00:15:26.180]   But if it were to, right?
[00:15:26.180 --> 00:15:27.560]   Whose responsibility is that?
[00:15:27.860 --> 00:15:33.200]   Then these are the types of questions that we're interested in and that we're helping large organizations solve today.
[00:15:33.200 --> 00:15:41.440]   And so if you're a security professional, if you're thinking about ownership, auditability, indemnification if you're a lawyer, right?
[00:15:41.440 --> 00:15:50.240]   These are the types of questions that you should start asking today because YOLO mode is probably not the best thing to be running inside your enterprise, right?
[00:15:50.340 --> 00:15:57.320]   And so give it a scan, give it a try, check out some of the controls we have, and if you have any questions, feel free to reach out via email.
[00:15:57.320 --> 00:15:58.280]   Thanks.
[00:15:58.280 --> 00:15:58.400]   Thanks.
[00:15:58.400 --> 00:15:58.420]   Thanks.
[00:15:58.420 --> 00:15:59.420]   Thanks.
[00:15:59.420 --> 00:15:59.420]   Thanks.
[00:15:59.420 --> 00:16:00.420]   Thanks.
[00:16:00.420 --> 00:16:00.420]   Thanks.
[00:16:00.420 --> 00:16:01.420]   Thanks.
[00:16:01.420 --> 00:16:01.420]   Thanks.
[00:16:01.420 --> 00:16:01.420]   Thanks.
[00:16:01.420 --> 00:16:02.420]   Thanks.
[00:16:02.420 --> 00:16:05.660]   We'll see you next time.

