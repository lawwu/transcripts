
[00:00:00.000 --> 00:00:03.200]   Oh no, gosh, I'm having some technical difficulties, Freeberg.
[00:00:03.200 --> 00:00:04.880]   There's something happening.
[00:00:04.880 --> 00:00:05.760]   Oh, you got a bit?
[00:00:05.760 --> 00:00:07.520]   Oh, something's breaking in.
[00:00:07.520 --> 00:00:08.320]   What's happening?
[00:00:08.320 --> 00:00:10.720]   Oh no, my camera, it's not working.
[00:00:10.720 --> 00:00:12.560]   But I sense something is happening, guys.
[00:00:12.560 --> 00:00:15.360]   It's like a transformation I'm going through.
[00:00:15.360 --> 00:00:16.320]   You're not going to believe it.
[00:00:16.320 --> 00:00:19.680]   Yes, it is I, Nostrakalus, I am here.
[00:00:19.680 --> 00:00:22.560]   I am here, Nostrakalus has arrived.
[00:00:22.560 --> 00:00:26.960]   I have predicted the hot swap, Sax.
[00:00:26.960 --> 00:00:29.440]   Can I get my flowers now from you, Sax?
[00:00:30.000 --> 00:00:30.560]   You need to bring--
[00:00:30.560 --> 00:00:32.800]   Yeah, I absolutely give you credit for that.
[00:00:32.800 --> 00:00:36.000]   You also predicted a speedrun primary, which is the opposite of what happened.
[00:00:36.000 --> 00:00:38.960]   So one out of two is not bad, though.
[00:00:38.960 --> 00:00:45.840]   Nostrakalus did not account for the Democratic Party being run by the Deep State.
[00:00:45.840 --> 00:00:48.480]   I'm having a vision.
[00:00:48.480 --> 00:00:55.120]   Producer Nick, there's a vision for you coming in to view.
[00:00:56.640 --> 00:01:02.240]   Yes, your uncle has been bought out of the All In podcast that's going full maga.
[00:01:02.240 --> 00:01:06.480]   And he got the $25 million buyout deal.
[00:01:06.480 --> 00:01:08.240]   And he gave you 20%.
[00:01:08.240 --> 00:01:08.880]   We're leaving.
[00:01:08.880 --> 00:01:10.960]   We're going to start a new podcast.
[00:01:10.960 --> 00:01:13.920]   And Jared Kushner is the new moderator here.
[00:01:13.920 --> 00:01:15.760]   Oh, no, wait, it's JD--
[00:01:15.760 --> 00:01:17.440]   No, it's Alex Jones.
[00:01:17.440 --> 00:01:20.720]   Starting next week, Alex Jones, the new host.
[00:01:20.720 --> 00:01:22.640]   Oh, wait, I'm going away.
[00:01:22.640 --> 00:01:25.680]   Nostrakalus is being pulled away.
[00:01:25.680 --> 00:01:44.800]   All right, let's get started here.
[00:01:44.800 --> 00:01:46.480]   We've got a full docket.
[00:01:46.480 --> 00:01:48.000]   We've got Civil Wars.
[00:01:48.000 --> 00:01:51.840]   Everything is going down in All In Land.
[00:01:51.840 --> 00:01:53.920]   It is episode 189.
[00:01:53.920 --> 00:01:55.520]   You're not done with us yet, folks.
[00:01:55.520 --> 00:01:59.120]   The world's number one podcast is still publishing.
[00:01:59.120 --> 00:02:00.880]   The world is still spinning.
[00:02:00.880 --> 00:02:03.680]   Hey, did you announce that you've moved to Texas?
[00:02:03.680 --> 00:02:04.400]   I did, I did.
[00:02:04.400 --> 00:02:05.360]   I did a little tweet.
[00:02:05.360 --> 00:02:09.040]   We moved to Austin a little earlier this year.
[00:02:09.040 --> 00:02:10.080]   We have a horse ranch.
[00:02:10.080 --> 00:02:12.960]   And we've always wanted to move to Austin.
[00:02:12.960 --> 00:02:14.080]   We looked during the pandemic.
[00:02:14.080 --> 00:02:15.360]   Thanks for asking, Chamath.
[00:02:15.360 --> 00:02:20.400]   And we wanted to have a ranch and horses and live a more homesteading lifestyle.
[00:02:20.400 --> 00:02:23.920]   And obviously, a lot of our friends are in Austin.
[00:02:23.920 --> 00:02:27.600]   So I'll still be spending a lot of time in the Valley in New York, like I always do in Miami.
[00:02:27.600 --> 00:02:33.440]   But the home base and the girls are going to school in Austin.
[00:02:33.440 --> 00:02:35.040]   How is it going so far?
[00:02:35.040 --> 00:02:35.760]   It's super hot.
[00:02:35.760 --> 00:02:36.560]   No, isn't it?
[00:02:36.560 --> 00:02:39.600]   Summers are hot, but most people de-camp.
[00:02:39.600 --> 00:02:44.400]   So we'll de-camp for Tahoe or Park City or something during the summer months and the
[00:02:44.400 --> 00:02:47.520]   winter months to go skiing and get a little lake time or whatever.
[00:02:47.520 --> 00:02:50.720]   And yeah, we're really, really excited.
[00:02:50.720 --> 00:02:55.760]   We found an incredible horse farm, and we're going to raise animals and horses and just
[00:02:55.760 --> 00:02:57.440]   enjoy these last years with the girls.
[00:02:57.440 --> 00:03:04.960]   While some big announcements coming in terms of my accelerator and my investing in startups
[00:03:04.960 --> 00:03:05.760]   in Austin.
[00:03:05.760 --> 00:03:08.720]   So I'll save those announcements for maybe the fourth quarter.
[00:03:08.720 --> 00:03:10.880]   Some big announcements will happen.
[00:03:10.880 --> 00:03:13.200]   And yeah, I'm just super excited.
[00:03:13.200 --> 00:03:18.480]   Obviously, I'm going to miss the weekly poker game, but I will be back on the regular.
[00:03:18.480 --> 00:03:21.200]   And we'll just do a double session, play Friday, Saturdays.
[00:03:21.200 --> 00:03:25.680]   We'll do you got to get for two days in a row and just do a full Friday session.
[00:03:25.680 --> 00:03:27.120]   Everybody take my Fridays.
[00:03:27.120 --> 00:03:28.240]   I'm sad to see you go.
[00:03:28.240 --> 00:03:33.680]   The one thing I'm sad about is like missing the Thursday game, but I'll be back regular.
[00:03:33.680 --> 00:03:35.120]   Don't forget Science Corner today.
[00:03:35.120 --> 00:03:36.800]   We got a great Science Corner lined up.
[00:03:36.800 --> 00:03:37.360]   Absolutely.
[00:03:37.360 --> 00:03:38.880]   I'm looking forward to it.
[00:03:38.880 --> 00:03:40.720]   Sax is in Texas all week about it.
[00:03:40.720 --> 00:03:42.320]   He's like, I can't wait for Science Corner.
[00:03:42.320 --> 00:03:42.880]   I'm thrilled.
[00:03:42.880 --> 00:03:44.080]   He was shaking nervously.
[00:03:44.080 --> 00:03:45.440]   He's ready.
[00:03:47.600 --> 00:03:50.400]   Sax does not look amused.
[00:03:50.400 --> 00:03:51.920]   All right, let's get started.
[00:03:51.920 --> 00:03:56.640]   Wiz has declined Google's $23 billion offer, and it intends to IPO.
[00:03:56.640 --> 00:03:57.840]   Some big news there.
[00:03:57.840 --> 00:04:02.160]   Last week, we talked about Google offering to acquire this cloud security startup for
[00:04:02.160 --> 00:04:02.960]   $23 billion.
[00:04:02.960 --> 00:04:05.360]   CNBC reported Wiz declined Google's offer.
[00:04:05.360 --> 00:04:06.640]   Wow.
[00:04:06.640 --> 00:04:11.440]   That's big time because Wiz was valued at $12 billion in its most recent funding round.
[00:04:11.440 --> 00:04:13.280]   They've got about $500 million in ARR.
[00:04:14.000 --> 00:04:21.520]   So this $23 billion is a massive, massive 50 times current revenue, 23 or so times
[00:04:21.520 --> 00:04:24.240]   forward-looking revenue.
[00:04:24.240 --> 00:04:26.240]   They think they'll hit a billion in ARR.
[00:04:26.240 --> 00:04:28.000]   This is a company that was founded in 2020.
[00:04:28.000 --> 00:04:32.880]   And just so if you don't know what they do, they help people secure their data in clouds
[00:04:32.880 --> 00:04:35.520]   like AWS, Azure, Google Cloud, all that good stuff.
[00:04:35.520 --> 00:04:41.040]   But high growth SaaS businesses are trading at a 10x forward revenue multiple.
[00:04:41.040 --> 00:04:42.240]   There's the chart.
[00:04:42.240 --> 00:04:48.960]   This is obviously an absurd premium and two potential reasons that I can think of, and
[00:04:48.960 --> 00:04:53.680]   I'm curious your positions, gentlemen, of why they would do this.
[00:04:53.680 --> 00:04:56.320]   I guess, Chamath, there's two reasons.
[00:04:56.320 --> 00:04:59.840]   One, they think they can grow this company at a high percentage, maybe fill in that premium
[00:04:59.840 --> 00:05:01.280]   Google was willing to pay.
[00:05:01.280 --> 00:05:07.280]   Or maybe they're scared that they can't get this deal through regulators.
[00:05:07.280 --> 00:05:08.320]   What's your take here?
[00:05:08.320 --> 00:05:13.520]   And then we'll go talk about the wider cloud and Google Cloud and AWS in a moment.
[00:05:13.520 --> 00:05:16.640]   What's your initial take here of why they would do this, Chamath?
[00:05:16.640 --> 00:05:24.560]   I actually wonder whether this deal would have had more probability of happening had
[00:05:24.560 --> 00:05:29.360]   the whole AT&T snowflake leak not happened.
[00:05:29.360 --> 00:05:37.840]   Because I think that when you have moments like this, there's a non-trivial possibility
[00:05:37.840 --> 00:05:41.840]   that it supercharges sales even more.
[00:05:41.840 --> 00:05:46.800]   I think the reality is that if you're a hyperscaler, so if you're Amazon or Google or Microsoft,
[00:05:46.800 --> 00:05:55.360]   your business is pretty fragile and brittle if the services you provide or the services
[00:05:55.360 --> 00:05:59.520]   that third parties like Snowflake provide through you are not reliable.
[00:05:59.520 --> 00:06:04.160]   And so I've never heard of a business that has generated so much ARR so quickly, I mean,
[00:06:04.160 --> 00:06:08.160]   from zero to half a billion dollars in four or five years.
[00:06:08.160 --> 00:06:12.800]   I mean, how do you even build the product surface area quick enough to capture that
[00:06:12.800 --> 00:06:13.920]   much revenue?
[00:06:13.920 --> 00:06:19.440]   I think it just goes to show you how bad security is in the cloud and how needed it is.
[00:06:19.440 --> 00:06:24.880]   So it doesn't surprise me that Google wouldn't buy something like this.
[00:06:24.880 --> 00:06:28.880]   I think Amazon and Microsoft would probably want something like it as well.
[00:06:28.880 --> 00:06:33.680]   I suspect that if you had to guess why they said no is because they thought that they
[00:06:33.680 --> 00:06:40.160]   could grow revenue much faster because of recent events, as well as their own just natural
[00:06:40.160 --> 00:06:40.880]   momentum.
[00:06:40.880 --> 00:06:46.160]   And I think that if this thing had not happened, I wonder whether they wouldn't have just sold.
[00:06:46.160 --> 00:06:46.480]   All right.
[00:06:46.480 --> 00:06:49.680]   Sax, I want to get your take on this after showing you a couple of charts here.
[00:06:49.680 --> 00:06:55.360]   Google's cloud revenue growth has been absolutely stunning.
[00:06:55.360 --> 00:06:57.440]   Here is a chart.
[00:06:57.440 --> 00:07:01.600]   They're going to hit, gosh, in the first half, they did almost 20 billion.
[00:07:01.600 --> 00:07:04.960]   So they're on a run rate of $40 billion this year.
[00:07:04.960 --> 00:07:06.640]   Last year, they did 33.
[00:07:06.640 --> 00:07:08.960]   Back in 2017, they only did four.
[00:07:08.960 --> 00:07:12.480]   And if you compare this to Amazon's AWS, again, these are cloud services.
[00:07:12.480 --> 00:07:14.480]   People can buy, compute in the cloud.
[00:07:14.480 --> 00:07:21.280]   AWS, if you look at those first seven years, the crack all in research team put these side
[00:07:21.280 --> 00:07:21.840]   by side.
[00:07:21.840 --> 00:07:28.240]   Google is tracking almost identical in revenue to AWS's.
[00:07:28.240 --> 00:07:31.360]   Interestingly, Meta and Apple do not have a competitor here.
[00:07:31.360 --> 00:07:36.080]   You said on this podcast, Chamath, I think last year, that would be a pretty bold move
[00:07:36.080 --> 00:07:40.320]   by Apple to have a cloud computing platform since they have all the app developers.
[00:07:40.320 --> 00:07:44.960]   Sax, what do you think of this just tremendous run by Google
[00:07:44.960 --> 00:07:48.480]   cloud, also known as GCP in the industry?
[00:07:48.480 --> 00:07:51.680]   Well, all the cloud service providers are doing extremely well.
[00:07:51.680 --> 00:07:55.840]   I mean, cloud is still the future of software and the cloud service providers are still
[00:07:55.840 --> 00:07:56.800]   growing really strongly.
[00:07:57.520 --> 00:08:02.160]   On Wiz, I think the most likely explanation is that they just want to keep building this
[00:08:02.160 --> 00:08:03.200]   as a standalone company.
[00:08:03.200 --> 00:08:05.840]   I think they're probably also worried that they can't get the deal through.
[00:08:05.840 --> 00:08:08.640]   The multiples that we have right now are not that insane.
[00:08:08.640 --> 00:08:13.200]   I mean, I think the long term median software multiple is around a seven.
[00:08:13.200 --> 00:08:16.720]   So, you know, you see here the mid-growth median 7.7.
[00:08:16.720 --> 00:08:21.760]   We're about tracking at the historical pre-COVID mean.
[00:08:22.400 --> 00:08:29.760]   And we had that really frothy, bubbly period in 2020 and 2021, and that's clearly over.
[00:08:29.760 --> 00:08:36.640]   Now, in terms of how our friends at Altimeter break this down, I think that high growth
[00:08:36.640 --> 00:08:39.600]   means a 30% or greater growth rate.
[00:08:39.600 --> 00:08:45.280]   And then I think the mid-tier is more like, what is it, like 10 or 15% to 30%.
[00:08:45.280 --> 00:08:50.000]   And then the low growth is like, you know, under 10.
[00:08:50.000 --> 00:08:50.500]   Yeah.
[00:08:51.360 --> 00:08:54.640]   So my point is, if Wiz is growing at--
[00:08:54.640 --> 00:08:55.140]   100%.
[00:08:55.140 --> 00:08:56.720]   100%.
[00:08:56.720 --> 00:09:00.640]   I mean, I don't know if it's still growing at 100%, but I mean, I guess they're projecting--
[00:09:00.640 --> 00:09:02.000]   Even 50%, yeah, would be.
[00:09:02.000 --> 00:09:08.160]   Yeah, they're projecting a billion in ARR next year up from, what is it, roughly 500.
[00:09:08.160 --> 00:09:12.880]   Like, that offer may not be that crazy.
[00:09:12.880 --> 00:09:16.800]   Again, you know, you're getting 10 times at a 30% average growth rate.
[00:09:16.800 --> 00:09:21.440]   So, you know, let's say they get to a billion in ARR next year, and then they're forecasting,
[00:09:21.440 --> 00:09:24.320]   you know, whatever it is the year after.
[00:09:24.320 --> 00:09:27.200]   You know, the 23 may be reasonable.
[00:09:27.200 --> 00:09:30.800]   So I can see why these guys would just want to go for it if they think they're building
[00:09:30.800 --> 00:09:32.080]   a big standalone company.
[00:09:32.080 --> 00:09:38.640]   Freeberg, let's talk a little, since you were a Googler at some point, this GCP product,
[00:09:38.640 --> 00:09:42.800]   maybe you could tell us a little bit about, and I know you know some of the people running it,
[00:09:44.000 --> 00:09:48.480]   how meaningful this is becoming to Google, or how much of a priority it is.
[00:09:48.480 --> 00:09:51.200]   YouTube, obviously, Android priority is there at the company.
[00:09:51.200 --> 00:09:56.000]   Then you have, like, the next year down, Nest, Waymo, you know, some of those other projects.
[00:09:56.000 --> 00:09:58.160]   But how important is GCP right now to Google?
[00:09:58.160 --> 00:10:06.240]   Well, GCP in the last quarter did $10.3 billion in revenue, which is up from $8 billion in
[00:10:06.240 --> 00:10:08.880]   revenue the year before, in the same quarter the year before.
[00:10:08.880 --> 00:10:13.760]   And importantly, in this past quarter, they're running at a $1.2 billion operating profit.
[00:10:13.760 --> 00:10:14.800]   It out of GCP.
[00:10:14.800 --> 00:10:20.160]   So, you know, if you kind of think about what cloud margin should be over time, and kind
[00:10:20.160 --> 00:10:26.160]   of call it 20 to 30% margin, this cloud business could be generating $20 to $30 billion a year
[00:10:26.160 --> 00:10:26.960]   of free cash flow.
[00:10:26.960 --> 00:10:33.280]   Now, in the last year, if you kind of look at, or even if you look at the last quarter
[00:10:33.280 --> 00:10:38.240]   annualized, Google is generating currently about $60 billion a year in free cash flow
[00:10:38.240 --> 00:10:40.320]   as an overall organization, Alphabet is.
[00:10:41.440 --> 00:10:43.200]   And they have over $100 billion in cash.
[00:10:43.200 --> 00:10:50.880]   So, you know, what can I do to accelerate this cloud outcome, given the risks, the challenges,
[00:10:50.880 --> 00:10:57.280]   the slowdown with respect to the core consumer business, cloud and AI-based tools really
[00:10:57.280 --> 00:10:58.160]   is where it's at.
[00:10:58.160 --> 00:11:04.240]   And so Google's asking this important strategic question, I would imagine, what can we do
[00:11:04.240 --> 00:11:05.920]   to accelerate outcomes in the cloud?
[00:11:05.920 --> 00:11:10.160]   And what can we do that is going to be big enough to matter?
[00:11:11.120 --> 00:11:14.960]   And what can we do that is going to pass antitrust muster?
[00:11:14.960 --> 00:11:17.600]   So we can actually get it through antitrust authorities.
[00:11:17.600 --> 00:11:19.920]   So cloud security kind of comes top of mind.
[00:11:19.920 --> 00:11:24.080]   It's a fast growing segment as evidenced by the results with with Wiz.
[00:11:24.080 --> 00:11:29.920]   And it's a an opportunity for Google to cross sell and to secure more enterprise customers
[00:11:29.920 --> 00:11:36.240]   and theoretically cross sell more enterprise revenue by getting folks on a platform that
[00:11:36.240 --> 00:11:37.440]   Google could now offer.
[00:11:38.080 --> 00:11:40.720]   I would imagine that what Saks is saying is probably right.
[00:11:40.720 --> 00:11:44.960]   I have absolutely no sense of what these individuals and board members at Wiz are thinking.
[00:11:44.960 --> 00:11:46.480]   But I think what Saks is saying is right.
[00:11:46.480 --> 00:11:48.320]   This is an incredibly fast growing business.
[00:11:48.320 --> 00:11:51.840]   Peter Thiel made the comment once, which I think is totally right.
[00:11:51.840 --> 00:11:57.600]   Either the buyer pays way too much, or the seller sells way too early.
[00:11:57.600 --> 00:12:02.240]   When you have a fast growing business like this, it's really an important question to
[00:12:02.240 --> 00:12:06.560]   kind of acknowledge that if Wiz continues to grow at this rate, it's conceivable they
[00:12:06.560 --> 00:12:10.640]   could be in the range of a Palo Alto Networks $100 billion market cap in a couple of years.
[00:12:10.640 --> 00:12:15.600]   You know, given given this momentum, and if you if you progress it forward.
[00:12:15.600 --> 00:12:17.280]   So if I was them, I would ask that question.
[00:12:17.280 --> 00:12:20.480]   Could we reach 100 billion if we feel reasonable, reasonably confident?
[00:12:20.480 --> 00:12:23.040]   This may be a risk worth taking.
[00:12:23.040 --> 00:12:24.080]   And what's the downside, right?
[00:12:24.080 --> 00:12:26.320]   The downside is they go public next year anyway.
[00:12:26.320 --> 00:12:28.960]   And maybe they're only valued at 15 billion or 20 billion.
[00:12:28.960 --> 00:12:33.200]   There's not a lot of downside from this offer, and certainly seems to be quite a bit of upside.
[00:12:33.200 --> 00:12:36.960]   But I think for cloud, the thing to watch is what they're going to do next.
[00:12:36.960 --> 00:12:39.120]   Google wants to accelerate beyond AWS.
[00:12:39.120 --> 00:12:40.480]   They want to become the leader.
[00:12:40.480 --> 00:12:44.320]   And they're going to look for other sizable transactions that will pass antitrust muster.
[00:12:44.320 --> 00:12:49.920]   And so I think you could see them perhaps looking at some public M&A in the same space.
[00:12:49.920 --> 00:12:53.200]   And I wouldn't be surprised to see them start to get active in that sense.
[00:12:53.200 --> 00:12:57.440]   YouTube and GCP are the are the two money printing machines inside the organization
[00:12:57.440 --> 00:12:58.800]   that have actually paid off.
[00:12:58.800 --> 00:13:05.040]   Android's paid off in terms of dumping more search from the default search buttons or boxes.
[00:13:05.040 --> 00:13:10.000]   But I guess to steel man the other side, if you're on the board and you want your cash,
[00:13:10.000 --> 00:13:13.280]   you get 100% of it.
[00:13:13.280 --> 00:13:14.240]   You take no risk.
[00:13:14.240 --> 00:13:18.560]   And what if Google decides they're going to make this product free and bundle it,
[00:13:18.560 --> 00:13:20.720]   as we saw Microsoft do in a number of cases?
[00:13:20.720 --> 00:13:23.680]   And they just Microsoft Teams this or Internet Explorer it.
[00:13:23.680 --> 00:13:28.720]   I guess that would be the risk is if Google feels some vendetta here and puts this product
[00:13:28.720 --> 00:13:29.360]   out for free.
[00:13:29.360 --> 00:13:36.000]   As you alluded to Chamath, it was a big week for cyber security CrowdStrike had a really
[00:13:36.000 --> 00:13:40.640]   rough week last week, when they knocked out eight and a half million Windows machines.
[00:13:40.640 --> 00:13:43.440]   Just to briefly explain what happened here.
[00:13:43.440 --> 00:13:46.160]   Obviously, Wiz is cyber security.
[00:13:46.160 --> 00:13:47.120]   And so it's CrowdStrike.
[00:13:47.120 --> 00:13:52.320]   CrowdStrike instead of working on data sets in the cloud, they work on securing your laptop,
[00:13:52.320 --> 00:13:55.680]   your desktop, your servers, all that kind of stuff for threats.
[00:13:55.680 --> 00:13:57.040]   And they did an update.
[00:13:57.040 --> 00:14:01.040]   And when they did their update, a sensor configuration update, as they called it,
[00:14:01.040 --> 00:14:03.840]   to Windows machines, they basically brick them.
[00:14:03.840 --> 00:14:06.400]   And this wasn't a cyber attack.
[00:14:06.400 --> 00:14:07.680]   They're a cyber security company.
[00:14:07.680 --> 00:14:08.480]   They weren't attacked.
[00:14:08.480 --> 00:14:11.440]   They updated it, and it crashed all these machines.
[00:14:11.440 --> 00:14:14.880]   And these machines all needed to have a hard reset by IT.
[00:14:14.880 --> 00:14:16.960]   It wasn't something that could just be field swapped.
[00:14:16.960 --> 00:14:19.520]   Apparently, people had to go back to their offices.
[00:14:19.520 --> 00:14:21.360]   In some cases, Delta was hit hardest.
[00:14:21.360 --> 00:14:22.960]   They canceled over 6,000 flights.
[00:14:24.080 --> 00:14:27.520]   And there's a Department of Transportation investigation going on now.
[00:14:27.520 --> 00:14:29.760]   Shares are down 25% since Friday.
[00:14:29.760 --> 00:14:34.480]   So that represents $24 billion in market cap.
[00:14:34.480 --> 00:14:40.000]   CrowdStrike CEO has been clowned for his apology and explanation.
[00:14:40.000 --> 00:14:43.040]   And the good news, though, is they sent everybody an Uber Eats gift card.
[00:14:43.040 --> 00:14:45.280]   So I'm super happy about that.
[00:14:45.280 --> 00:14:49.600]   Chamath Sachs, looking at this and dovetailing with the last story.
[00:14:49.600 --> 00:14:53.360]   This is going to be an ongoing story.
[00:14:53.360 --> 00:14:55.200]   And one of the big trends in our industry.
[00:14:55.200 --> 00:14:55.700]   Yeah.
[00:14:55.700 --> 00:14:58.800]   Major outages like this.
[00:14:58.800 --> 00:15:02.320]   I think the reality is that that code is still really brittle.
[00:15:02.320 --> 00:15:04.640]   And there's gaping holes everywhere.
[00:15:04.640 --> 00:15:10.480]   And I suspect that the reason why foreign adversaries don't hack us is because we could
[00:15:10.480 --> 00:15:11.360]   hack them back.
[00:15:11.360 --> 00:15:15.840]   And so I think it's almost like a mutually assured destruction is the only reason why
[00:15:15.840 --> 00:15:17.200]   these things stay up every day.
[00:15:17.200 --> 00:15:20.560]   So at some point, we're going to write better code.
[00:15:20.560 --> 00:15:25.200]   Maybe these AI agents will do it and there won't be like memory leaks and all this other
[00:15:25.200 --> 00:15:25.760]   random stuff.
[00:15:25.760 --> 00:15:32.640]   But in the meantime, I think you just have to assume that everybody will get access to
[00:15:32.640 --> 00:15:37.200]   all of your information and that eventually everything is hacked and everything is leaked.
[00:15:37.200 --> 00:15:37.520]   Yeah.
[00:15:37.520 --> 00:15:38.480]   And act accordingly.
[00:15:38.480 --> 00:15:39.440]   And act accordingly.
[00:15:39.440 --> 00:15:40.320]   Yeah.
[00:15:40.320 --> 00:15:45.840]   Assume every the worst conversation you ever had on social media or on DMs is going to
[00:15:45.840 --> 00:15:46.320]   come out.
[00:15:46.320 --> 00:15:47.760]   All right.
[00:15:47.760 --> 00:15:49.360]   I think we've kind of finished this.
[00:15:49.360 --> 00:15:51.520]   Anybody have any thoughts on this CrowdStrike thing?
[00:15:51.520 --> 00:15:52.640]   It seems like it's over now.
[00:15:52.640 --> 00:15:56.960]   I don't have a lot to say about them except actually this is that that company has some
[00:15:56.960 --> 00:15:58.880]   murky connections to the deep state.
[00:15:58.880 --> 00:15:59.840]   Oh, right.
[00:15:59.840 --> 00:16:00.960]   And yeah.
[00:16:00.960 --> 00:16:06.000]   Well, apparently they're fingerprints were all over Hillary's bleach server.
[00:16:06.000 --> 00:16:11.120]   Then there's been other reports, which I don't know exactly what to make of.
[00:16:11.120 --> 00:16:15.120]   I can say this, that in the wake of this, Elon announced that he was removing CrowdStrike
[00:16:15.120 --> 00:16:17.600]   from any of his company's servers.
[00:16:18.240 --> 00:16:21.920]   Similarly, I had my IT department check and make sure that we didn't have it running anywhere
[00:16:21.920 --> 00:16:22.400]   and we don't.
[00:16:22.400 --> 00:16:24.080]   I'm just going to be frank.
[00:16:24.080 --> 00:16:25.120]   I don't trust this company.
[00:16:25.120 --> 00:16:26.800]   All right.
[00:16:26.800 --> 00:16:27.760]   There you have it.
[00:16:27.760 --> 00:16:28.480]   Deep state.
[00:16:28.480 --> 00:16:30.640]   Tinfoil hat.
[00:16:30.640 --> 00:16:31.520]   Deep state.
[00:16:31.520 --> 00:16:33.120]   Deep state accusation.
[00:16:33.120 --> 00:16:34.480]   I'm going to wear a tinfoil hat today.
[00:16:34.480 --> 00:16:35.040]   I forgot.
[00:16:35.040 --> 00:16:35.920]   You believe what you want.
[00:16:35.920 --> 00:16:37.360]   I don't.
[00:16:37.360 --> 00:16:38.720]   This is the first I'm hearing about it.
[00:16:38.720 --> 00:16:40.000]   I don't have my tinfoil hat here.
[00:16:40.000 --> 00:16:42.080]   But who knows?
[00:16:42.080 --> 00:16:42.400]   I guess.
[00:16:42.400 --> 00:16:45.040]   Use their products if you want to.
[00:16:45.040 --> 00:16:45.760]   Use their products if you want to.
[00:16:45.760 --> 00:16:46.480]   There you have it, folks.
[00:16:47.840 --> 00:16:51.360]   And Saksas puts his endorsement behind Palantir.
[00:16:51.360 --> 00:16:52.640]   Definitely not deep state, Palantir.
[00:16:52.640 --> 00:16:54.880]   No, Palantir.
[00:16:54.880 --> 00:16:58.320]   Look, there's no question that Palantir sells into the deep state.
[00:16:58.320 --> 00:17:00.800]   But I don't know that that makes it deep state.
[00:17:00.800 --> 00:17:03.120]   Well, I mean, they're on your team, as opposed to the other team.
[00:17:03.120 --> 00:17:04.400]   So that's a lot of numbers.
[00:17:04.400 --> 00:17:04.880]   No, hold on.
[00:17:04.880 --> 00:17:07.440]   I'm not on any team in this spectrum.
[00:17:07.440 --> 00:17:10.000]   I don't really understand what you're saying there.
[00:17:10.000 --> 00:17:10.560]   I'm just goofing.
[00:17:10.560 --> 00:17:12.240]   I have shares in the company.
[00:17:12.240 --> 00:17:13.840]   I think it's a good investment.
[00:17:13.840 --> 00:17:14.640]   Oh, okay.
[00:17:14.640 --> 00:17:15.600]   There you have it, folks.
[00:17:15.600 --> 00:17:15.840]   All right.
[00:17:15.840 --> 00:17:16.880]   Let's go to the stock market.
[00:17:16.880 --> 00:17:18.000]   He just had his first face.
[00:17:18.000 --> 00:17:20.640]   I got to get a tinfoil hat for a bit here.
[00:17:20.640 --> 00:17:21.440]   One thing I want to say.
[00:17:21.440 --> 00:17:25.760]   None of us are at any risk of running Palantir on our servers, okay?
[00:17:25.760 --> 00:17:26.000]   Absolutely.
[00:17:26.000 --> 00:17:30.240]   CrowdStrike is running in the background of many, many companies who may not even be fully
[00:17:30.240 --> 00:17:31.120]   aware of it.
[00:17:31.120 --> 00:17:35.680]   And they were certainly surprised when all those airlines' computers went down, right?
[00:17:35.680 --> 00:17:40.320]   So my only point is maybe you should make sure about whether you're running their products
[00:17:40.320 --> 00:17:40.880]   or not.
[00:17:40.880 --> 00:17:44.000]   And then make a conscious decision whether you think that's a good idea.
[00:17:44.000 --> 00:17:44.560]   That's all.
[00:17:44.560 --> 00:17:45.040]   That's all.
[00:17:45.040 --> 00:17:47.760]   Just a little tip from the more you know from David's side.
[00:17:47.760 --> 00:17:49.600]   Jake, don't move on.
[00:17:49.600 --> 00:17:50.080]   I'm trying.
[00:17:50.080 --> 00:17:50.400]   That's good.
[00:17:50.400 --> 00:17:51.600]   I'm trying my best.
[00:17:51.600 --> 00:17:51.920]   All right.
[00:17:51.920 --> 00:17:55.920]   The stock market just had its worst day since 2020 on Wednesday.
[00:17:55.920 --> 00:18:00.160]   Clearly, this is because of the January 6th insurrection, the NASDAQ, which is the most
[00:18:00.160 --> 00:18:00.400]   tech...
[00:18:00.400 --> 00:18:01.120]   I'm joking.
[00:18:01.120 --> 00:18:03.520]   The NASDAQ, which is the most tech-heavy, fell 3.6%.
[00:18:03.520 --> 00:18:05.280]   S&P down 2.3%.
[00:18:05.280 --> 00:18:08.400]   A bunch of the magnificent seven companies were in the red.
[00:18:08.400 --> 00:18:10.720]   But you got to put this in context.
[00:18:10.720 --> 00:18:15.680]   NASDAQ and S&P still up around 15% for the first half of the year.
[00:18:15.680 --> 00:18:20.000]   Record-setting territory, obviously, if that holds up or increases.
[00:18:20.000 --> 00:18:25.520]   There's a lot of theories about this, that people are rotating into the MAC-7 tech stocks,
[00:18:25.520 --> 00:18:28.960]   which were a place that maybe got a little overheated with the AI bubble.
[00:18:28.960 --> 00:18:36.400]   Here's the top gainers that are not in the MAC-7, as you can see.
[00:18:36.400 --> 00:18:39.520]   Financials, energy, materials.
[00:18:39.520 --> 00:18:43.200]   Over the last six months, S&P financials up 11%.
[00:18:43.200 --> 00:18:44.400]   S&P energy, 9%.
[00:18:44.400 --> 00:18:46.640]   S&P materials, 9% as well.
[00:18:46.640 --> 00:18:48.400]   Broader index up 11%, as we said.
[00:18:48.400 --> 00:18:53.200]   Tesla dropped 12% after missing on earnings, but they had a massive run-up earlier this year.
[00:18:53.200 --> 00:18:53.920]   Google dropped 5%.
[00:18:53.920 --> 00:18:58.880]   I guess YouTube was what most people pointed to.
[00:18:58.880 --> 00:19:01.120]   Their revenue came in lower than expected.
[00:19:01.120 --> 00:19:05.440]   So maybe some softness in the advertising market, which would then correlate with consumers.
[00:19:05.440 --> 00:19:07.040]   NVIDIA down 7%.
[00:19:07.040 --> 00:19:07.680]   Meta down 6%.
[00:19:09.360 --> 00:19:12.560]   Chamath, any thoughts here on what we're saying?
[00:19:12.560 --> 00:19:16.880]   You talked a lot about the consumer weakening on an episode about six weeks ago, I believe.
[00:19:16.880 --> 00:19:20.720]   So is this just the manifestation of that prediction you made?
[00:19:20.720 --> 00:19:22.240]   Not this specific thing.
[00:19:22.240 --> 00:19:28.960]   I think that when you see a broad-based set of revenue misses, that that will kind of mean
[00:19:28.960 --> 00:19:31.040]   that the consumer is really under pressure.
[00:19:31.040 --> 00:19:36.400]   I still think that that's more in the fall, but we're headed in that direction.
[00:19:36.400 --> 00:19:41.360]   I think what happened here is that the market is just priced to perfection.
[00:19:41.360 --> 00:19:44.000]   And all of a sudden, we had all kinds of volatility.
[00:19:44.000 --> 00:19:47.520]   You had the former president almost assassinated.
[00:19:47.520 --> 00:19:50.400]   You have the current sitting president resign.
[00:19:50.400 --> 00:19:57.200]   You have a somewhat convoluted process to pick who replaced him that at a minimum was opaque.
[00:19:57.200 --> 00:20:05.040]   And all of these things create doubt and anxiety in the people that own financial assets.
[00:20:05.040 --> 00:20:09.040]   And so if you saw the volatility index, the VIX, that has spiked.
[00:20:09.040 --> 00:20:13.440]   And so whenever you see that stuff happen, people go risk off, right?
[00:20:13.440 --> 00:20:15.440]   And when you go risk off, what do you sell?
[00:20:15.440 --> 00:20:20.240]   You sell the things that are deepest in the money where you think that they probably don't
[00:20:20.240 --> 00:20:21.600]   have that much more room to run.
[00:20:21.600 --> 00:20:23.600]   And that was the Mag 7.
[00:20:23.600 --> 00:20:28.320]   And so what you actually saw was a huge rotation out of those companies into everything but
[00:20:28.320 --> 00:20:29.200]   those seven names.
[00:20:29.200 --> 00:20:33.840]   And I think that that's a pretty reasonable thing to do.
[00:20:33.840 --> 00:20:36.960]   So I think we're in the part of the cycle where people are getting a little bit more
[00:20:36.960 --> 00:20:38.160]   sober and risk managing.
[00:20:38.160 --> 00:20:43.920]   We're also in the middle of the summer where a lot more vacation is taken, which how it
[00:20:43.920 --> 00:20:50.160]   manifests is that people tend to be, frankly, more risk off and be more liquid because a
[00:20:50.160 --> 00:20:51.760]   lot of people are in and out of the office.
[00:20:51.760 --> 00:20:56.320]   And I think the real setup is for what happens in September.
[00:20:56.320 --> 00:20:58.400]   Maybe there's a cut, which will help.
[00:20:58.400 --> 00:21:00.480]   Maybe there isn't, which won't help.
[00:21:00.480 --> 00:21:06.480]   And then the whole consumer cycle, the consumer credit cycle, that doesn't look good, to be
[00:21:06.480 --> 00:21:06.800]   honest.
[00:21:06.800 --> 00:21:09.360]   And so I think the fall is going to be complicated.
[00:21:09.360 --> 00:21:10.400]   Yeah, absolutely.
[00:21:10.400 --> 00:21:12.240]   What an eventful week on a political front.
[00:21:12.240 --> 00:21:14.640]   We'll get towards that in a moment.
[00:21:14.640 --> 00:21:16.880]   But, Freeberg, your thoughts here.
[00:21:16.880 --> 00:21:22.560]   Is it just people trimming their perfect positions and maybe a dispersion going out, people wanting
[00:21:22.560 --> 00:21:28.400]   to own some other assets that maybe have been undervalued in this market cycle?
[00:21:29.040 --> 00:21:34.800]   No, I think it's definitely this mini AI bubble deflating a bit.
[00:21:34.800 --> 00:21:41.360]   And transactions are, let me get out of some of these high multiple tech stocks that are
[00:21:41.360 --> 00:21:47.760]   expected to grow rapidly because of AI and shift more into stable market recovery.
[00:21:47.760 --> 00:21:51.040]   Interest rates are going to get cut, type trades that will benefit there.
[00:21:51.040 --> 00:21:52.560]   So I think it's just a rebalancing.
[00:21:52.560 --> 00:21:57.360]   And as a result of the high concentration of the Mag 7 and the S&P and in the Qs, the
[00:21:57.360 --> 00:21:58.880]   indices look like they're coming down.
[00:21:58.880 --> 00:22:04.000]   But yeah, there's obviously a lot of complexity in what's going on in the economy right now.
[00:22:04.000 --> 00:22:08.320]   But I do think that that's been a big trade for PMs, for portfolio managers over the last
[00:22:08.320 --> 00:22:08.880]   couple of weeks.
[00:22:08.880 --> 00:22:09.920]   Makes sense.
[00:22:09.920 --> 00:22:10.080]   Yeah.
[00:22:10.080 --> 00:22:15.520]   Sachs, if you owned a bunch of Nvidia and it ran up, Meta, Google, Apple, other companies
[00:22:15.520 --> 00:22:20.320]   that ran way up, you might want to trim your position here and deploy capital and balance
[00:22:20.320 --> 00:22:20.720]   things out.
[00:22:20.720 --> 00:22:20.960]   Yeah.
[00:22:20.960 --> 00:22:22.320]   Sure.
[00:22:22.320 --> 00:22:26.400]   I just don't want to overreact or overread into one day in the market.
[00:22:26.400 --> 00:22:28.000]   I mean, today's up, yesterday was down.
[00:22:28.000 --> 00:22:30.400]   These are blips in the grand scheme of things.
[00:22:30.400 --> 00:22:33.440]   Even a 2% to 3% move is just not that unusual.
[00:22:33.440 --> 00:22:33.840]   Yeah.
[00:22:33.840 --> 00:22:35.440]   Especially given the context.
[00:22:35.440 --> 00:22:42.160]   But definitely something worth keeping an eye on is what the earnings reports will say
[00:22:42.160 --> 00:22:44.560]   for Q3 and Q4.
[00:22:44.560 --> 00:22:47.040]   And those will come out towards the end of the year.
[00:22:47.040 --> 00:22:47.280]   Okay.
[00:22:47.280 --> 00:22:49.520]   Some interesting news.
[00:22:49.520 --> 00:22:52.640]   Sam Altman did a UBI experiment a couple of years ago.
[00:22:53.200 --> 00:23:00.400]   He put 14 of the $60 million into this experiment that was done by a firm called Open Research.
[00:23:00.400 --> 00:23:07.360]   That's a nonprofit group that was founded in 2015 out of an accelerator called Y Combinator.
[00:23:07.360 --> 00:23:08.480]   First, I'm hearing of that one.
[00:23:08.480 --> 00:23:09.920]   Well, here's the experiment they did.
[00:23:09.920 --> 00:23:15.520]   And this took place between November of 2020, October of 2023, 3,000 low-income adults in
[00:23:15.520 --> 00:23:21.520]   Texas and Illinois making just under $30,000 a year on average were selected.
[00:23:21.520 --> 00:23:25.600]   1,000 participants received $1,000 a month for three years.
[00:23:25.600 --> 00:23:30.400]   So on top of the $30,000, they got $12,000 a year tax-free.
[00:23:30.400 --> 00:23:33.520]   So that's nearly a 50% pay increase for doing no more work.
[00:23:33.520 --> 00:23:39.120]   2,000 controlled participants received $50 per month over the same period.
[00:23:39.120 --> 00:23:42.800]   And the research collected and studied a bunch of data.
[00:23:42.800 --> 00:23:45.520]   They did blood draws to do health impact.
[00:23:45.520 --> 00:23:50.720]   They had a custom app that tracked time usage, work, play, etc.
[00:23:50.720 --> 00:23:53.920]   And they checked everybody's credit reports and bank balances.
[00:23:53.920 --> 00:23:59.280]   So broadly speaking, the research found almost no lasting impact on everything
[00:23:59.280 --> 00:24:01.680]   they tested from overall health to work to education.
[00:24:01.680 --> 00:24:05.200]   And here are the quotes directly from the paper.
[00:24:05.200 --> 00:24:06.960]   And I'll get the gentleman's take on this.
[00:24:06.960 --> 00:24:08.640]   UBI, super fascinating, obviously.
[00:24:08.640 --> 00:24:12.640]   "The cash transfer resulted in large but short-lived improvements in stress and food security.
[00:24:13.200 --> 00:24:17.520]   We find no effect of the transfer across several measures of physical health.
[00:24:17.520 --> 00:24:21.760]   We also find that the transfer did not improve mental health after the first year.
[00:24:21.760 --> 00:24:27.200]   And by year two, we can again reject very small improvements."
[00:24:27.200 --> 00:24:27.920]   Final quote.
[00:24:27.920 --> 00:24:33.360]   "We also find precise null effects on self-reported access to health and physical activity and sleep."
[00:24:33.360 --> 00:24:39.840]   I find this so fascinating and reinforces a bunch of intuition that I think we would
[00:24:39.840 --> 00:24:41.120]   probably all have.
[00:24:41.120 --> 00:24:48.080]   Have you guys seen these studies where when somebody has an amputation or they get paralyzed,
[00:24:48.080 --> 00:24:54.160]   they study their free levels of happiness, their interim level of happiness, and then
[00:24:54.160 --> 00:24:57.280]   they just kind of mean revert to their natural state of happiness,
[00:24:57.280 --> 00:25:02.080]   independent of what physical calamity they may have gone through.
[00:25:02.080 --> 00:25:06.080]   And when you were talking about it, Jake, I was reacting in the same way,
[00:25:06.080 --> 00:25:13.920]   which is in the absence of, I think, purpose and community, I think children in many cases,
[00:25:13.920 --> 00:25:19.600]   it just doesn't meaningfully shift any of these curves that really matter.
[00:25:19.600 --> 00:25:21.520]   I think your happiness levels mean revert.
[00:25:21.520 --> 00:25:24.080]   I think your health levels mean revert.
[00:25:24.080 --> 00:25:32.400]   So it's great to kind of confirm at least my intuition, which is that UBI is a
[00:25:34.000 --> 00:25:41.920]   wonderful idea that I think doesn't really understand how humans are both motivated and
[00:25:41.920 --> 00:25:42.420]   wired.
[00:25:42.420 --> 00:25:44.080]   Freberg, your thoughts?
[00:25:44.080 --> 00:25:46.560]   Yeah, so I definitely agree.
[00:25:46.560 --> 00:25:47.600]   I think I've talked about this.
[00:25:47.600 --> 00:25:49.760]   We talked a little bit about it with Jonathan Haidt.
[00:25:49.760 --> 00:25:53.040]   There's some great studies that have shown in the past that the change in income is a
[00:25:53.040 --> 00:25:55.600]   better predictor of happiness than absolute income.
[00:25:55.600 --> 00:25:57.440]   Eventually, everything normalizes.
[00:25:57.440 --> 00:26:00.720]   So I think UBI makes no sense for three reasons.
[00:26:00.720 --> 00:26:03.360]   The first is this normalization of spending levels.
[00:26:03.360 --> 00:26:06.880]   So once you've kind of had this increase, you have a moment of happiness.
[00:26:06.880 --> 00:26:10.000]   And then you actually start spending differently or spending more.
[00:26:10.000 --> 00:26:14.480]   And effectively, every human has one innate trait, desire.
[00:26:14.480 --> 00:26:17.840]   And desire is what drives humanity.
[00:26:17.840 --> 00:26:18.960]   It's what drives progress.
[00:26:18.960 --> 00:26:20.320]   It's what pushes us forward.
[00:26:20.320 --> 00:26:24.240]   Because no matter what our absolute condition, it's our relative condition that matters,
[00:26:24.240 --> 00:26:29.360]   relative to others, or relative to ourselves in the past, or prospectively in the future.
[00:26:29.360 --> 00:26:32.240]   And so we always want to improve our condition.
[00:26:32.240 --> 00:26:35.280]   So a UBI-based system basically gives a flat income.
[00:26:35.280 --> 00:26:39.760]   So the only way for it to really work is if you increase the income automatically by,
[00:26:39.760 --> 00:26:41.120]   say, 10% a year.
[00:26:41.120 --> 00:26:46.320]   So in a UBI world, no amount of money will actually make someone satisfied or meet their
[00:26:46.320 --> 00:26:50.080]   minimum thresholds, because those minimum thresholds will simply shift.
[00:26:50.080 --> 00:26:54.160]   And the second issue is just the net economic effect.
[00:26:54.160 --> 00:27:01.600]   If we gave 350 million Americans $1,000 a month, that's $350 billion a month.
[00:27:01.600 --> 00:27:03.200]   That's $4 trillion a year.
[00:27:03.200 --> 00:27:08.640]   Our prospective budget for next year is $7.3 trillion at the federal level.
[00:27:08.640 --> 00:27:13.920]   So that's already more than 50% of the total projected federal budget next year.
[00:27:13.920 --> 00:27:19.840]   Finding the mechanism for funding this at scale is not what this study actually looked
[00:27:19.840 --> 00:27:20.000]   at.
[00:27:20.000 --> 00:27:23.520]   Because if you look at it, the net effect would be inflationary.
[00:27:23.520 --> 00:27:26.800]   And that's the third major reason, is that ultimately, this would have an inflationary
[00:27:26.800 --> 00:27:27.520]   effect.
[00:27:27.520 --> 00:27:33.520]   Anytime we've stimulated the economy with outside money, with government-driven money,
[00:27:33.520 --> 00:27:36.240]   we see many bubbles emerge, and we see an inflationary effect.
[00:27:36.240 --> 00:27:37.280]   So look at COVID.
[00:27:37.280 --> 00:27:40.000]   There were all these little bubbles that popped up in the financial markets.
[00:27:40.000 --> 00:27:40.720]   We had NFTs.
[00:27:40.720 --> 00:27:41.680]   We had crypto.
[00:27:41.680 --> 00:27:44.880]   We had all these sort of new places that money found its way to.
[00:27:44.880 --> 00:27:46.880]   And then we had an aggregate inflationary effect.
[00:27:46.880 --> 00:27:50.400]   Food prices are still up 30%, 40% since COVID.
[00:27:50.400 --> 00:27:55.760]   And so net-net, I think that the study provides an interesting insight into the micro effects,
[00:27:55.760 --> 00:27:57.840]   the psychological effects, the social effects.
[00:27:57.840 --> 00:28:03.520]   But the macro effects are what is so, like, simply arithmetically obvious, which is inflation
[00:28:03.520 --> 00:28:06.640]   and an inability to actually fund this at scale.
[00:28:06.640 --> 00:28:08.560]   And fundamentally, people want to work.
[00:28:08.560 --> 00:28:12.640]   So they'll take that money, and then they'll go find ways to work and generate more money.
[00:28:12.640 --> 00:28:13.840]   And you have this inflationary effect.
[00:28:13.840 --> 00:28:16.560]   So I think net-net, UBI does not make sense.
[00:28:16.560 --> 00:28:20.960]   SACs participants were 5% more likely to start a business by the third year.
[00:28:20.960 --> 00:28:23.360]   Maybe that was the most encouraging part of this.
[00:28:23.360 --> 00:28:28.320]   People worked slightly less, 2% decrease in labor participation, but that seems negligible.
[00:28:28.320 --> 00:28:33.840]   People in their 20s had a 2% increase in enrolling in post-secondary education.
[00:28:33.840 --> 00:28:35.200]   Again, very tiny impact.
[00:28:35.200 --> 00:28:39.040]   There were major benefits to stress and mental health in year one.
[00:28:39.040 --> 00:28:41.840]   But by year two, as we talked about, it reverted to the baseline.
[00:28:41.840 --> 00:28:47.520]   How do you think about UBI in a world where, let's say, I don't know,
[00:28:47.520 --> 00:28:52.000]   we lost a large amount of jobs in a short period of time because of AI?
[00:28:52.000 --> 00:28:56.160]   So in that hypothetical situation, and we hit 20% or 25% unemployment from the
[00:28:56.160 --> 00:29:00.880]   historic low we're at now, how might you think about UBI?
[00:29:00.880 --> 00:29:03.920]   Well, that's positing a future that I don't think is going to happen.
[00:29:03.920 --> 00:29:07.440]   At least, that's why I'm trying to give you a hypothetical.
[00:29:07.440 --> 00:29:09.440]   Yeah, no, I don't really buy that.
[00:29:09.440 --> 00:29:14.320]   And so I think this whole idea of UBI is premature and very expensive.
[00:29:14.320 --> 00:29:15.120]   And it doesn't work.
[00:29:15.120 --> 00:29:17.920]   I mean, I think what we saw from the study, just to echo what Freeberg said,
[00:29:17.920 --> 00:29:20.960]   is that cash transfers don't work.
[00:29:20.960 --> 00:29:22.160]   We saw this in the Great Society.
[00:29:22.160 --> 00:29:25.040]   Just handing people money doesn't solve poverty.
[00:29:25.040 --> 00:29:28.800]   It actually traps people in conditions of dependence.
[00:29:28.800 --> 00:29:33.600]   We also saw during COVID that all those STEMI checks, it might have had a macro effect in the
[00:29:33.600 --> 00:29:38.480]   economy of kind of boosting the economy during what could have been a COVID depression.
[00:29:38.480 --> 00:29:42.640]   However, at an individual level, what did we see?
[00:29:42.640 --> 00:29:45.680]   We saw people quitting or quite quitting their jobs.
[00:29:45.680 --> 00:29:50.000]   They spent more on leisure, alcohol, and meme stocks.
[00:29:50.000 --> 00:29:52.000]   In other words, it wasn't tremendously productive.
[00:29:52.000 --> 00:29:56.800]   So I think that what we've seen in the past is just handing people money
[00:29:56.800 --> 00:30:01.280]   doesn't create the types of outcomes that people want.
[00:30:01.280 --> 00:30:04.880]   Is all this virtue signaling, Sax?
[00:30:04.880 --> 00:30:06.080]   Is it virtue signaling?
[00:30:06.080 --> 00:30:06.880]   Kind of.
[00:30:06.880 --> 00:30:07.440]   Kind of.
[00:30:07.440 --> 00:30:09.280]   I'm kind of getting that tone from you.
[00:30:09.280 --> 00:30:15.040]   Yeah, I think it's a combination of virtue signaling combined with let's assume that
[00:30:15.040 --> 00:30:21.840]   you want to become the first AI trillionaire and people are concerned about job loss.
[00:30:21.840 --> 00:30:25.200]   You're going to virtue signal in the direction of, well, let's just give everyone money.
[00:30:25.200 --> 00:30:32.000]   And a lot of people in power will love that because it creates a lot of dependence.
[00:30:32.000 --> 00:30:39.440]   So it serves the interests of tech moguls and people in the government.
[00:30:39.440 --> 00:30:41.120]   But I don't think it serves society.
[00:30:41.120 --> 00:30:43.680]   And I think one of the most interesting data points in the study,
[00:30:43.680 --> 00:30:48.240]   please confirm if I get this right, but what it said is that the people who got the thousand
[00:30:48.240 --> 00:30:54.560]   a month UBI saw their incomes rise to $45,000 on average, while the control group who only
[00:30:54.560 --> 00:30:59.840]   got $50 a month increased their average income to 50,000, actually just shy of 51,000.
[00:30:59.840 --> 00:31:07.600]   So the people who didn't get the larger stimmy actually genuinely bettered themselves over
[00:31:07.600 --> 00:31:11.600]   the course of the study, while the ones who got the 12,000 a year stayed in place.
[00:31:12.320 --> 00:31:14.080]   And that's kind of what you'd expect, right?
[00:31:14.080 --> 00:31:16.800]   Which is if you just hand people money without having to work,
[00:31:16.800 --> 00:31:19.360]   it doesn't motivate them to work harder.
[00:31:19.360 --> 00:31:21.920]   It actually motivates them to do less.
[00:31:21.920 --> 00:31:25.360]   And let's say that you're in a point in your career where you need to learn,
[00:31:25.360 --> 00:31:27.920]   you need to get mentorship, you need to advance yourself.
[00:31:27.920 --> 00:31:32.160]   By giving people UBI, you could be kicking out those bottom rungs of the ladder where
[00:31:32.160 --> 00:31:36.320]   the work isn't necessarily that fun, but you're picking up very important skills
[00:31:36.320 --> 00:31:38.160]   that are going to help you rise up in the ladder.
[00:31:38.160 --> 00:31:41.920]   Yeah, being a cashier, like sending your kids to be a cashier at a restaurant,
[00:31:41.920 --> 00:31:45.680]   or a busboy, or a waiter, like that teaches them a work ethic.
[00:31:45.680 --> 00:31:46.800]   I was a dishwasher.
[00:31:46.800 --> 00:31:48.640]   I did hard work as a child.
[00:31:48.640 --> 00:31:49.360]   I was a bartender.
[00:31:49.360 --> 00:31:52.480]   I mean, look, these are all jobs that have dignity.
[00:31:52.480 --> 00:31:57.680]   I mean, I think work has dignity, and you need people to start somewhere.
[00:31:57.680 --> 00:32:01.040]   And if you just give them the stimmy or the UBI,
[00:32:01.040 --> 00:32:04.800]   it demotivates them from starting their careers.
[00:32:04.800 --> 00:32:07.040]   And you trap people at this lower level.
[00:32:07.040 --> 00:32:11.120]   So I just don't think you're doing anyone any favors by doing this.
[00:32:11.120 --> 00:32:15.360]   And I just want to say, my production company's in full swing, and we are actually working on
[00:32:15.360 --> 00:32:17.920]   a remake of Cheers with David Sacks.
[00:32:17.920 --> 00:32:20.320]   Yeah, as the bartender, as the lead character.
[00:32:20.320 --> 00:32:23.040]   It's a really great show.
[00:32:23.040 --> 00:32:29.680]   Looking at the back of the envelope math here, I had the crack research team take a look at this
[00:32:29.680 --> 00:32:35.520]   welfare, $1.1 trillion budget in 2023, eight different federal agencies, Medicare, I'm sorry,
[00:32:35.520 --> 00:32:37.520]   Medicaid was in there as well.
[00:32:37.520 --> 00:32:42.640]   Unemployment, $33 billion paid across, 1.8 million participants last year.
[00:32:42.640 --> 00:32:45.280]   Food stamp safety, $113 billion.
[00:32:45.280 --> 00:32:50.560]   We put all those numbers together, and we've got about 100 million people participating
[00:32:50.560 --> 00:32:54.000]   in these programs in some way for $1.2 trillion per year.
[00:32:54.000 --> 00:32:55.280]   This is all back of the envelope.
[00:32:55.280 --> 00:32:55.920]   It's imperfect.
[00:32:55.920 --> 00:33:01.760]   But that turns out to be about $12K each, which is exactly what the study did.
[00:33:01.760 --> 00:33:02.800]   So not perfect math.
[00:33:02.800 --> 00:33:04.000]   But that's totally reasonable.
[00:33:04.000 --> 00:33:07.840]   I grew up on welfare, and we needed it to make ends meet.
[00:33:07.840 --> 00:33:11.680]   And we would have completely fallen through the cracks without it.
[00:33:11.680 --> 00:33:18.000]   And so I'm glad that I was able to be raised in a country that has welfare.
[00:33:18.000 --> 00:33:24.400]   I guess my question to you, Chamath, is do you think all these agencies put together,
[00:33:24.400 --> 00:33:30.400]   with all this administration and all this complexity, would it be better if we take
[00:33:30.400 --> 00:33:32.960]   something from this UBI and maybe consolidating down?
[00:33:32.960 --> 00:33:34.880]   No, no, no, no.
[00:33:34.880 --> 00:33:38.720]   Because I think you need to be motivated, as Zach said.
[00:33:38.720 --> 00:33:45.680]   And so even though we got support from, I grew up in Canada, so the Canadian government,
[00:33:45.680 --> 00:33:50.800]   there was still an expectation where certain things were not covered, and you still had
[00:33:50.800 --> 00:33:51.120]   to work.
[00:33:51.120 --> 00:33:55.760]   And so you had to find motivation to pick yourself up and go out and get a job.
[00:33:55.760 --> 00:34:02.400]   And it just so happened that in our situation, even welfare and what my mom made as a housekeeper,
[00:34:02.400 --> 00:34:05.440]   and then as a nurse aide wasn't enough, and my dad didn't have a job.
[00:34:05.440 --> 00:34:08.000]   So I went and I started working at Burger King.
[00:34:08.000 --> 00:34:14.480]   And to Sax's point, it's pretty eye-opening when you're 14 years old, and you're working
[00:34:14.480 --> 00:34:18.720]   the night shift, and people come in after going to the bars, they're drunk, they're
[00:34:18.720 --> 00:34:20.000]   puking all over the place.
[00:34:20.000 --> 00:34:25.040]   Sometimes you see people that go to your own high school, and it's a little bit embarrassing
[00:34:25.040 --> 00:34:27.040]   because you're working while they're going out.
[00:34:27.040 --> 00:34:28.880]   But at the end of the day, it was very motivating.
[00:34:28.880 --> 00:34:29.840]   And I think Sax is right.
[00:34:29.840 --> 00:34:34.080]   If you take that away from people, I think that you end up with the worst society.
[00:34:34.080 --> 00:34:38.560]   I don't think that you have a motivated group of people that want to go and better themselves.
[00:34:38.560 --> 00:34:40.880]   I think they just become really lazy.
[00:34:40.880 --> 00:34:42.400]   I think it's well stated.
[00:34:42.400 --> 00:34:48.880]   And I think the pressure cooker that immigrants are under, or people who have tough situations,
[00:34:48.880 --> 00:34:51.040]   it can create the diamonds.
[00:34:51.040 --> 00:34:55.520]   And man, I do think a lot of the folks here on this podcast went through that pressure
[00:34:55.520 --> 00:34:58.400]   cooker, and it does create a chip on your shoulder.
[00:34:58.400 --> 00:35:03.040]   And when people criticize these entry level jobs, and they're, oh, they're not sustainable.
[00:35:03.040 --> 00:35:07.280]   Well, there, we do have a safety net in both countries, can I think that that's not I think
[00:35:07.280 --> 00:35:09.120]   the problem is not the entry level job.
[00:35:09.120 --> 00:35:10.960]   I think it's the expectation of people.
[00:35:10.960 --> 00:35:17.680]   And Friedberg just mentioned this, but what you have is that there is this desire doom
[00:35:17.680 --> 00:35:26.160]   loop that we've fallen ourselves into, where what social media does is amplify, in many
[00:35:26.160 --> 00:35:30.640]   cases, a fake perception of what your neighbor has that you don't have.
[00:35:30.640 --> 00:35:33.200]   And so you're in this constant desire doom loop.
[00:35:33.200 --> 00:35:37.520]   So if you go to a job, and you're expected to work for four years, I'm just going to
[00:35:37.520 --> 00:35:39.200]   make up a number before you get promoted.
[00:35:39.200 --> 00:35:43.520]   And the perception is that your neighbor is getting promoted after eight months, you're
[00:35:43.520 --> 00:35:47.280]   going to be mad, and you're going to be angry, and you're going to feel like life isn't working
[00:35:47.280 --> 00:35:47.760]   out for you.
[00:35:47.760 --> 00:35:52.960]   And we have to figure out a way of resetting that back to normal, so that you know that
[00:35:52.960 --> 00:35:57.280]   that is a lie that is being told to get clicks and likes.
[00:35:57.280 --> 00:36:01.920]   And the real truth is, you're going to have to just put your nose down and grind at something
[00:36:01.920 --> 00:36:02.800]   to get what you want.
[00:36:02.800 --> 00:36:05.520]   And life is not perfect, and it's complicated, and it's messy.
[00:36:05.520 --> 00:36:08.480]   And we need to do a better job of that.
[00:36:08.480 --> 00:36:09.760]   Let me ask you a question, Friedberg.
[00:36:09.760 --> 00:36:14.400]   If you were going to do a 2.0 of this study, I was thinking about it, you know, where do
[00:36:14.400 --> 00:36:15.200]   you go from here?
[00:36:15.200 --> 00:36:21.040]   I just had this idea like, well, what if you put like, half of the money into like a perfect
[00:36:21.040 --> 00:36:26.720]   portfolio, Wealthfront, one of those services, and allow people to take out maybe 5% of it
[00:36:26.720 --> 00:36:31.360]   every year, some sustainable amount, so they see, you know, and get some education around
[00:36:31.360 --> 00:36:31.520]   that.
[00:36:31.520 --> 00:36:37.920]   Or maybe put the money into a business formation fund, people can apply to get grants to, you
[00:36:37.920 --> 00:36:43.920]   know, maybe form a business, and you kind of reframe how this UBI is distributed with
[00:36:43.920 --> 00:36:47.840]   milestones and maybe some education baked into it.
[00:36:47.840 --> 00:36:49.760]   That was my thought on where to go next with it.
[00:36:49.760 --> 00:36:52.720]   Do you have any thoughts of where you would do a 2.0 test of this?
[00:36:52.720 --> 00:36:53.520]   Or would you just...
[00:36:53.520 --> 00:36:55.360]   Well, that's not UBI, right?
[00:36:55.360 --> 00:36:59.920]   And what you're describing, I think, exists, and there are incentives and programs and
[00:36:59.920 --> 00:37:00.880]   opportunities out there.
[00:37:00.880 --> 00:37:05.360]   People can sign up with Roth IRAs, they can contribute some percentage of their paycheck
[00:37:05.360 --> 00:37:09.200]   to a 401(k) if they have a job that has a 401(k) set up for them.
[00:37:09.200 --> 00:37:13.120]   There's a lot of systems and mechanisms out there, and you get tax breaks for doing that.
[00:37:13.120 --> 00:37:16.640]   So there's mechanisms and incentives out there to do that sort of thing.
[00:37:17.520 --> 00:37:23.040]   The concept with UBI is, can you pay people a flat amount of money so that they don't
[00:37:23.040 --> 00:37:27.440]   have to work, and then they end up being able to explore and do other things with their
[00:37:27.440 --> 00:37:29.920]   life as the robots and AI does everything for them?
[00:37:29.920 --> 00:37:34.160]   And I've just always been of the belief that I don't think that there's this natural border
[00:37:34.160 --> 00:37:37.520]   that we hit beyond which humans don't work.
[00:37:37.520 --> 00:37:42.800]   I think that AI-based tools and automation tools are the same as they've always been.
[00:37:42.800 --> 00:37:46.960]   When we developed a tractor, people didn't stop farming, they could get much more leverage
[00:37:46.960 --> 00:37:50.560]   using the tractor and farm more, and new jobs and new industries emerged.
[00:37:50.560 --> 00:37:54.480]   And I expect that the same thing will happen with this next evolution of technology and
[00:37:54.480 --> 00:37:55.680]   human progress.
[00:37:55.680 --> 00:38:00.400]   Humans will find ways to create new things, to push themselves forward, to drive things
[00:38:00.400 --> 00:38:01.200]   forward.
[00:38:01.200 --> 00:38:05.520]   And for the natural market-based incentives that fundamentally are rooted in this internal
[00:38:05.520 --> 00:38:09.600]   system of desire, will create new opportunities that we're not really thinking about.
[00:38:09.600 --> 00:38:14.000]   So I don't believe in this idea of UBI and some utopian world where everyone's happy
[00:38:14.000 --> 00:38:16.800]   not working and letting machines do everything for them.
[00:38:16.800 --> 00:38:21.680]   I think that the fundamental sense of a human is to find purpose and to realize that purpose
[00:38:21.680 --> 00:38:24.000]   to drive themselves forward and progress themselves.
[00:38:24.000 --> 00:38:25.520]   And I think that that's always going to be the case.
[00:38:25.520 --> 00:38:30.880]   The closest thing to leisure and leisurely pursuits that we have today in modern society
[00:38:30.880 --> 00:38:31.840]   is the Nepo baby.
[00:38:31.840 --> 00:38:38.160]   And if you look at the Nepo baby, they're the most miserable group of people I've ever
[00:38:38.160 --> 00:38:38.660]   met.
[00:38:39.600 --> 00:38:41.760]   They're so unhappy with themselves.
[00:38:41.760 --> 00:38:45.120]   And so, and part of it is because they've only ever lived a life of leisure.
[00:38:45.120 --> 00:38:46.400]   Shout out to Alex Oros.
[00:38:46.400 --> 00:38:49.760]   No, I'm not name-checking anyone.
[00:38:49.760 --> 00:38:55.200]   I'm just saying when I, when I, when I observe it, I think that you can see it right in front
[00:38:55.200 --> 00:39:01.040]   of you, which is that there's just so much inherent unhappiness because you're not motivated
[00:39:01.040 --> 00:39:01.920]   to do anything.
[00:39:01.920 --> 00:39:08.080]   And then that's amplified typically by guilty parents because they've been working so hard.
[00:39:08.080 --> 00:39:13.120]   And I, so I don't think you need to run a second study, a different version of an idea
[00:39:13.120 --> 00:39:19.200]   that friend of the pod, Brad Gerstner is working on, which I think deserves a shout out is
[00:39:19.200 --> 00:39:22.560]   this idea of giving every kid when they're born a retirement account.
[00:39:22.560 --> 00:39:28.320]   And I think that that's an interesting idea where you give them some amount of money and
[00:39:28.320 --> 00:39:34.160]   it just matures inside of an index fund that gets unlocked for you when that kid is 65
[00:39:34.160 --> 00:39:35.120]   or 70 years old.
[00:39:35.920 --> 00:39:40.080]   That's great because it helps you have a soft landing in retirement.
[00:39:40.080 --> 00:39:44.880]   I think that that's very humane and a right thing to do, but it doesn't rob you of that
[00:39:44.880 --> 00:39:47.600]   motivation to work in your twenties, thirties, forties, and fifties.
[00:39:47.600 --> 00:39:49.760]   And that's a much better idea than UBI.
[00:39:49.760 --> 00:39:56.160]   And I think, by the way, it's really important to state that UBI can be more of a trap than
[00:39:56.160 --> 00:39:56.640]   a benefit.
[00:39:56.640 --> 00:40:04.240]   It takes away the opportunity for individuals to progress because you no longer have a system
[00:40:04.240 --> 00:40:07.040]   that says you progress, you get richly rewarded.
[00:40:07.040 --> 00:40:11.280]   It ultimately drives to an outcome where you spend all the money and distribute it equally.
[00:40:11.280 --> 00:40:13.600]   So everyone ends up having some sort of stasis.
[00:40:13.600 --> 00:40:16.160]   And I don't think that that's really human nature.
[00:40:16.160 --> 00:40:21.040]   I do think that systems and government programs that support people's ability to succeed,
[00:40:21.040 --> 00:40:25.600]   to work hard, to work smart, to progress while providing these necessary safety nets is a
[00:40:25.600 --> 00:40:26.720]   better solution.
[00:40:26.720 --> 00:40:28.480]   There's no right or wrong way.
[00:40:28.480 --> 00:40:31.360]   It's just, it's a very complicated system that's needed.
[00:40:31.360 --> 00:40:35.120]   And I don't think that there's like this UBI concept, it's fairly naive.
[00:40:35.120 --> 00:40:39.920]   And I think that you'll see it play out at both a micro and a macro scale as being, I
[00:40:39.920 --> 00:40:41.360]   think, net, net negative.
[00:40:41.360 --> 00:40:42.080]   Yeah.
[00:40:42.080 --> 00:40:45.360]   You know, just wrapping up here so we can get onto the rest of the very juicy docket
[00:40:45.360 --> 00:40:46.400]   we have today.
[00:40:46.400 --> 00:40:49.280]   It does seem demotivating to just have money drop in your head.
[00:40:49.280 --> 00:40:50.800]   That's why I like my experiment.
[00:40:50.800 --> 00:40:55.680]   I was referring to Freeberg, just forcing people, not like having these programs that
[00:40:55.680 --> 00:40:59.680]   you have to go find out about and have the social capital and fabric around you that
[00:40:59.680 --> 00:41:03.360]   you know about small business loans, et cetera, but hey, these three things are happening
[00:41:03.360 --> 00:41:04.480]   to you right now.
[00:41:04.480 --> 00:41:08.320]   This money has been put into your account automatically and you can decide what to do
[00:41:08.320 --> 00:41:08.640]   with it.
[00:41:08.640 --> 00:41:14.480]   And just raising the education level and empowering people is a much better idea.
[00:41:14.480 --> 00:41:18.800]   I feel like whatever the education system is, schools or whatever, like actually teaching
[00:41:18.800 --> 00:41:22.240]   the vocational skills or the skills on how to succeed in the workplace.
[00:41:22.240 --> 00:41:24.240]   Like, here's how you go get a job.
[00:41:24.240 --> 00:41:25.840]   Here's how you build a business.
[00:41:25.840 --> 00:41:27.280]   Here's how you start something.
[00:41:27.280 --> 00:41:31.680]   Those are the sorts of skills that are not taught in the educational system that I think
[00:41:31.680 --> 00:41:32.640]   are generally lacking.
[00:41:32.640 --> 00:41:36.800]   And then people kind of learn a bunch of history or some algebra or whatever they learn in
[00:41:36.800 --> 00:41:38.480]   school and they pop out the other end.
[00:41:38.480 --> 00:41:40.800]   And it's like, okay, go figure out how to survive.
[00:41:40.800 --> 00:41:41.840]   Go figure out how to get a job.
[00:41:41.840 --> 00:41:43.040]   Go figure out how to build a business.
[00:41:43.040 --> 00:41:44.080]   To just build on your idea.
[00:41:44.080 --> 00:41:45.520]   We need more healthcare workers.
[00:41:45.520 --> 00:41:50.000]   If you paid somebody $1,000 a month and you paid for their school for one year to become
[00:41:50.000 --> 00:41:54.720]   a nurse, doctor, nurse practitioner, whatever, that would actually have a dramatic impact
[00:41:54.720 --> 00:41:58.000]   and solve a problem for our society while not giving a handout.
[00:41:58.000 --> 00:42:00.000]   I think we all agree on this one.
[00:42:00.000 --> 00:42:02.640]   Let's keep moving through this amazingly juicy docket.
[00:42:02.640 --> 00:42:02.960]   All right.
[00:42:02.960 --> 00:42:06.560]   There is a battle right now for Rupert Murdoch's media empire.
[00:42:06.560 --> 00:42:12.960]   The Times reported on a behind the scenes fight for control of Fox News, Wall Street
[00:42:12.960 --> 00:42:17.440]   Journal, New York Post, and just tons of TV networks in Australia, the UK.
[00:42:17.440 --> 00:42:23.680]   I think we all know the News Corp holding set, a bit like the TV show Secession.
[00:42:24.560 --> 00:42:28.000]   Which makes sense because they based it on the Murdoch family.
[00:42:28.000 --> 00:42:32.320]   It turns out this article in the Times is based on a sealed court document that was
[00:42:32.320 --> 00:42:33.120]   obtained by them.
[00:42:33.120 --> 00:42:38.080]   Murdoch, to remind you, is 93 years old now, and his trust would have given control to
[00:42:38.080 --> 00:42:40.560]   his four eldest children.
[00:42:40.560 --> 00:42:48.400]   However, he changed the trust to ensure that Lachlan Murdoch, who is more conservative,
[00:42:50.240 --> 00:42:56.720]   would take over these assets as opposed to James, Elizabeth, and Prudence, who are more
[00:42:56.720 --> 00:42:58.480]   moderate than Lachlan.
[00:42:58.480 --> 00:43:03.600]   And they are engaged in a massive court case now that's going to start in September.
[00:43:03.600 --> 00:43:08.560]   The trust is irrevocable, but it contains a provision allowing for changes so long as
[00:43:08.560 --> 00:43:13.440]   they're made "in good faith and with the purpose of benefiting all members."
[00:43:13.440 --> 00:43:18.080]   So Rupert argued that the change is in the best interest of James, Elizabeth, and Prudence
[00:43:18.080 --> 00:43:23.680]   as it keeps them formally separate from Fox News without having to worry about its political
[00:43:23.680 --> 00:43:24.480]   point of view.
[00:43:24.480 --> 00:43:30.720]   Fox News obviously has massive influence and has been a bit of a disaster over the last
[00:43:30.720 --> 00:43:31.760]   couple of years.
[00:43:31.760 --> 00:43:40.960]   They did the largest settlement ever in a defamation case with Dominion, paid $787 million.
[00:43:40.960 --> 00:43:47.200]   You remember Tucker Hannity, Laura Ingram, all of them privately trashed the people who
[00:43:47.200 --> 00:43:52.640]   lied about the Dominion case on Fox News, and that all got shown in text messages, and
[00:43:52.640 --> 00:43:54.800]   it was a disaster for them.
[00:43:54.800 --> 00:44:01.440]   Sax, any thoughts on this and how this collection of assets and the GOP have collaborated over
[00:44:01.440 --> 00:44:01.840]   the years?
[00:44:01.840 --> 00:44:03.840]   I wouldn't necessarily call it collaboration.
[00:44:03.840 --> 00:44:05.280]   I call it a market position.
[00:44:05.280 --> 00:44:10.480]   I mean, Fox News has carved out a powerful and profitable market niche by being the one
[00:44:10.480 --> 00:44:12.960]   cable news network that appeals to conservatives.
[00:44:13.760 --> 00:44:20.880]   And now if, let's say, the more liberal members of the family like James take over and change
[00:44:20.880 --> 00:44:25.600]   the content and the programming to serve their own political views, they're going to lose
[00:44:25.600 --> 00:44:26.080]   viewership.
[00:44:26.080 --> 00:44:27.040]   They're going to lose their audience.
[00:44:27.040 --> 00:44:30.800]   It would be a foolish idea just from a business standpoint.
[00:44:30.800 --> 00:44:33.440]   So I think that Loughlin is the right choice.
[00:44:33.440 --> 00:44:34.960]   I've met Loughlin before, by the way.
[00:44:34.960 --> 00:44:36.020]   Nice guy.
[00:44:36.020 --> 00:44:41.040]   Look, I think a pretty mainstream conservative type of guy, he's clearly the right guy in
[00:44:41.040 --> 00:44:42.320]   the family to run this.
[00:44:42.320 --> 00:44:46.480]   And the siblings, I think, could really screw it up.
[00:44:46.480 --> 00:44:51.440]   And I'm talking about not just from a content standpoint, I'm talking about from a revenue
[00:44:51.440 --> 00:44:55.760]   and profit standpoint if they take it in a different direction.
[00:44:55.760 --> 00:45:04.640]   I would already say that Fox News has a market position problem, which is that Rupert is
[00:45:04.640 --> 00:45:06.000]   very much a neocon.
[00:45:06.000 --> 00:45:11.600]   And neoconservatism is on the way out in the Republican Party in favor of a more populist
[00:45:11.600 --> 00:45:15.760]   conservatism that you see with Trump or now his running mate, J.D. Vance.
[00:45:15.760 --> 00:45:22.160]   Rupert and Fox waged a really strong campaign to keep J.D. Vance off the ticket, obviously
[00:45:22.160 --> 00:45:22.960]   lost that battle.
[00:45:22.960 --> 00:45:29.840]   Rupert fired Tucker, by far their highest rated and most profitable host ever.
[00:45:29.840 --> 00:45:35.200]   And it was over, again, this populism versus neoconservatism direction.
[00:45:35.200 --> 00:45:42.720]   So I think that Fox already has a problem where they are becoming misaligned with their
[00:45:42.720 --> 00:45:43.200]   audience.
[00:45:43.200 --> 00:45:47.200]   And regardless of what you think of the politics, this is bad for business.
[00:45:47.200 --> 00:45:53.840]   It'll be really interesting to see if Laughlin will realign things in a more populist direction.
[00:45:53.840 --> 00:45:57.520]   But definitely going in a liberal direction that like James or the other siblings want
[00:45:57.520 --> 00:45:59.200]   to go in, that would be a disaster.
[00:45:59.520 --> 00:46:04.640]   Freeberg, Chamath, any thoughts on this media empire and secession planning?
[00:46:04.640 --> 00:46:11.760]   Man, I think probate and wills and trusts are of the devil's making.
[00:46:11.760 --> 00:46:14.320]   Nothing good comes out of these things.
[00:46:14.320 --> 00:46:20.560]   And I don't know, I just think some of these assets should just be left to shareholders.
[00:46:20.560 --> 00:46:25.920]   Or just sell them and take the money, give it to the kids.
[00:46:25.920 --> 00:46:29.680]   Hopefully you raise good kids, they can all go and pursue their own path.
[00:46:29.680 --> 00:46:36.000]   Because again, I think the point is like, the path and the journey is the fun.
[00:46:36.000 --> 00:46:41.360]   And these kinds of battles are really brutal.
[00:46:41.360 --> 00:46:45.840]   And I'll tell you, to me, the thing that I'm sad when I hear this whole thing, is like,
[00:46:45.840 --> 00:46:49.280]   you have four siblings that I'm guessing grew up together.
[00:46:49.280 --> 00:46:52.480]   And now, are they ever going to talk to each other again?
[00:46:52.480 --> 00:46:57.680]   Or is it like three versus one or two versus two or, and I just think that that's ugly
[00:46:57.680 --> 00:46:59.280]   over what power and money.
[00:46:59.280 --> 00:47:04.160]   I would have just if I was the father, I would have sold the asset given the money to the
[00:47:04.160 --> 00:47:06.080]   kids or to charity or whatever.
[00:47:06.080 --> 00:47:10.240]   And hopefully, they would have found happiness in a different way.
[00:47:10.240 --> 00:47:12.000]   But that is what they did with the Disney deal.
[00:47:12.000 --> 00:47:14.160]   They took the cash and they distributed it to the kids.
[00:47:14.160 --> 00:47:16.080]   So they each got a pretty big windfall.
[00:47:16.080 --> 00:47:20.320]   And then I think the concept was this remaining asset would be managed over the long term.
[00:47:20.960 --> 00:47:23.680]   Maybe I'm speaking out of school a bit, but I thought that's what happened there.
[00:47:23.680 --> 00:47:27.280]   They did sell Fox, the studio and.
[00:47:27.280 --> 00:47:28.400]   Yeah.
[00:47:28.400 --> 00:47:29.360]   And the library.
[00:47:29.360 --> 00:47:30.000]   Yeah, and the library.
[00:47:30.000 --> 00:47:35.520]   And that brings X-Men Fantastic Four, Wolverine back together with the Avengers, which is
[00:47:35.520 --> 00:47:36.160]   most important.
[00:47:36.160 --> 00:47:36.640]   20th Century Fox, yeah.
[00:47:36.640 --> 00:47:38.080]   Clearly, they didn't.
[00:47:38.080 --> 00:47:41.200]   No, it's all coming back together now.
[00:47:41.200 --> 00:47:43.040]   Now, they just got to get Sony to give up.
[00:47:43.040 --> 00:47:44.720]   I mean, we are talking about interesting IP.
[00:47:44.720 --> 00:47:48.000]   Marvel just sold these characters to the highest bidder in perpetuity.
[00:47:49.120 --> 00:47:50.720]   Such a crazy, weird deal.
[00:47:50.720 --> 00:47:56.800]   But it's like it's like me saying, you know, I, I've collected some really nice belts.
[00:47:56.800 --> 00:48:00.560]   And so I'm just going to have like a death match between my five kids to see who gets
[00:48:00.560 --> 00:48:01.680]   the best belt.
[00:48:01.680 --> 00:48:06.240]   Yeah, I just I mean, and it's not it's not even about money, actually, because they have
[00:48:06.240 --> 00:48:06.960]   enough.
[00:48:06.960 --> 00:48:09.280]   It's clearly this is about power.
[00:48:09.280 --> 00:48:10.480]   No, and it's about being picked.
[00:48:10.480 --> 00:48:14.400]   Imagine if your father picks your sibling and not you.
[00:48:14.400 --> 00:48:14.800]   Why?
[00:48:14.800 --> 00:48:15.440]   Why would you?
[00:48:15.440 --> 00:48:16.800]   Why would you do that?
[00:48:16.800 --> 00:48:17.200]   Yeah.
[00:48:17.200 --> 00:48:19.280]   Like, is there is the asset so important?
[00:48:19.280 --> 00:48:24.160]   As I said, there's these are self managing because business people will make rational
[00:48:24.160 --> 00:48:24.960]   business decisions.
[00:48:24.960 --> 00:48:27.600]   So put it in the hands of a rational business person.
[00:48:27.600 --> 00:48:28.800]   Keep the family intact.
[00:48:28.800 --> 00:48:31.840]   Because if you lose the family, what do you have?
[00:48:31.840 --> 00:48:33.280]   Yes, I don't get.
[00:48:33.280 --> 00:48:35.520]   That's what I don't understand.
[00:48:35.520 --> 00:48:37.520]   We might as well just go to our next topic.
[00:48:37.520 --> 00:48:39.920]   Joe Biden has been hot swapped as new shit.
[00:48:39.920 --> 00:48:42.160]   And it's predicted the speedrun primary.
[00:48:42.160 --> 00:48:44.080]   Maybe that's been subverted.
[00:48:44.080 --> 00:48:47.920]   As we all know, Joe Biden, what's your version?
[00:48:47.920 --> 00:48:53.920]   Maybe it has been subverted, possibly could have been subverted, inadvertently knocked
[00:48:53.920 --> 00:48:55.360]   over, forgotten.
[00:48:55.360 --> 00:48:56.720]   It could be an oversight.
[00:48:56.720 --> 00:48:57.680]   Anything's possible.
[00:48:57.680 --> 00:49:05.360]   Joe Biden formerly exited the presidential race on Sunday after donors and party leadership
[00:49:05.360 --> 00:49:07.600]   politely asked him to enjoy his retirement.
[00:49:07.600 --> 00:49:08.480]   Nope, they shipped him.
[00:49:09.520 --> 00:49:14.240]   By most insider accounts, Biden was not happy about the decision and felt betrayed.
[00:49:14.240 --> 00:49:21.520]   Nonetheless, public has backed his VP Kamala Harris, who appears to have already wrapped
[00:49:21.520 --> 00:49:26.400]   up the nomination survey conducted by AP on Monday suggested that Harris already had the
[00:49:26.400 --> 00:49:31.600]   endorsement of enough delegates to secure the nomination in the first round of convention
[00:49:31.600 --> 00:49:32.320]   voting.
[00:49:32.320 --> 00:49:35.840]   So this won't be official until the DNC that starts August 19.
[00:49:35.840 --> 00:49:41.280]   And in Chi Town, so far, no one has stepped forward as a rival for Harris.
[00:49:41.280 --> 00:49:45.200]   And in fact, many of her would be competitors have already endorsed her.
[00:49:45.200 --> 00:49:51.840]   That includes Shapiro, Pennsylvania's governor, Newsom, California's governor, Pritzker, Illinois's
[00:49:51.840 --> 00:49:54.400]   governor, and Whitmer, Michigan's governor.
[00:49:54.400 --> 00:49:57.200]   All of those, I guess, potential VP candidates.
[00:49:57.200 --> 00:50:04.160]   She is now the 90% favorite to get Democratic nomination.
[00:50:04.160 --> 00:50:10.720]   I'll stop there and ask our panelists what they think of this turn of events.
[00:50:10.720 --> 00:50:12.320]   Chamath, you want to start us off?
[00:50:12.320 --> 00:50:18.240]   I mean, I don't think the process was super open and transparent and democratic.
[00:50:18.240 --> 00:50:20.160]   But I don't think they had much of a choice.
[00:50:20.160 --> 00:50:23.360]   And I think we've talked about that because too much of the money would have had to
[00:50:23.360 --> 00:50:25.840]   essentially been returned.
[00:50:25.840 --> 00:50:30.240]   And I don't think you can fight a federal election in 2024 with one hand tied behind
[00:50:30.240 --> 00:50:30.640]   your back.
[00:50:31.360 --> 00:50:37.840]   So she was the de facto nominee when the rumor started.
[00:50:37.840 --> 00:50:44.880]   And now I think the whole point is to figure out where does she stand?
[00:50:44.880 --> 00:50:48.880]   I think the thing that she will have to overcome is that these last three years, three and
[00:50:48.880 --> 00:50:54.640]   a half years, she's been relatively under the radar.
[00:50:54.640 --> 00:50:56.560]   MIA, some might say.
[00:50:56.560 --> 00:50:58.880]   And I think that now there's just like this whole controversy.
[00:50:58.880 --> 00:51:02.320]   I don't know if you guys have seen this where like, she was named the Borders are but then
[00:51:02.320 --> 00:51:03.520]   she was not the Borders are.
[00:51:03.520 --> 00:51:08.160]   And I think there's a mainstream media is it's sort of fighting with itself from six
[00:51:08.160 --> 00:51:09.360]   months ago about the whole thing.
[00:51:09.360 --> 00:51:14.480]   But the point is that we don't know what she believes and we don't yet have a sense of
[00:51:14.480 --> 00:51:18.240]   her agenda, really, you know.
[00:51:18.240 --> 00:51:23.680]   And I think that over these next two months, it'll be up to her to really create a very
[00:51:23.680 --> 00:51:26.320]   clear case of what she believes in.
[00:51:26.320 --> 00:51:30.320]   And then it'll be really interesting to see who she picks as her VP candidate.
[00:51:30.320 --> 00:51:32.560]   And then people, I think, will be in a position to judge.
[00:51:32.560 --> 00:51:36.480]   And I think that that's what, you know, what if I've been kind of like reading the tea
[00:51:36.480 --> 00:51:41.120]   leaves from the folks that I've talked to is sort of what they say, which is TBD, and
[00:51:41.120 --> 00:51:42.400]   we need to figure out where she's at.
[00:51:42.400 --> 00:51:50.960]   Freeberg, your thoughts on this unbelievable 10 days in the history of our country where
[00:51:52.880 --> 00:51:57.040]   president was nearly murdered by an assassin.
[00:51:57.040 --> 00:52:07.920]   And Joe Biden resigns, and a 39 year old political neophyte venture capitalists is picked as
[00:52:07.920 --> 00:52:08.720]   VP.
[00:52:08.720 --> 00:52:10.560]   I mean, this is consequential.
[00:52:10.560 --> 00:52:13.280]   What are your thoughts on this?
[00:52:13.280 --> 00:52:13.920]   10 days?
[00:52:13.920 --> 00:52:15.440]   That's a lot of stuff.
[00:52:15.440 --> 00:52:21.360]   I think we talked about that last week, but the Kamala Harris de facto nomination that
[00:52:21.360 --> 00:52:27.440]   took place over 48 hours, I think was a little bit shocking to a lot of people I've spoken
[00:52:27.440 --> 00:52:34.160]   with that there wasn't a bit more of a process to identify a nominee besides Kamala that
[00:52:34.160 --> 00:52:35.440]   effectively the party lined up.
[00:52:35.440 --> 00:52:42.560]   Now, what I think is relevant here is that for the first time, it's exposing people to
[00:52:42.560 --> 00:52:46.400]   the way the electoral process actually works in the United States, that it's not a direct
[00:52:46.400 --> 00:52:51.520]   democracy, where every individual in this country votes for their federally elected
[00:52:51.520 --> 00:52:51.760]   people.
[00:52:51.760 --> 00:52:56.160]   Remember, the United States was set up as a federated republic, that there was meant
[00:52:56.160 --> 00:53:02.640]   to be the states, the states were in a federation, and then the states would elect electors that
[00:53:02.640 --> 00:53:07.840]   would go and figure out who should be the president who should run the federal office
[00:53:07.840 --> 00:53:12.560]   and the states would elect their representatives, their Congress people to go represent them
[00:53:12.560 --> 00:53:14.000]   in the federal government.
[00:53:14.000 --> 00:53:18.480]   And so I think a lot of people, you know, whether it's just without thinking about it,
[00:53:18.480 --> 00:53:24.240]   or based on precedent, assume I get a vote and who gets to be president, what you get
[00:53:24.240 --> 00:53:29.840]   to have is a vote and who gets to be the delegate to represent your state in picking the president.
[00:53:29.840 --> 00:53:36.080]   And so this process where delegates very quickly fell behind Kamala Harris, because of the
[00:53:36.080 --> 00:53:42.080]   significant coalescing of power and influence within the parties, the two major parties
[00:53:42.080 --> 00:53:46.960]   in the United States, has, I think, exposed a lot of people to the lack of a democratic
[00:53:46.960 --> 00:53:51.120]   process for federal executive role in this country.
[00:53:51.120 --> 00:53:55.200]   And I think that's a little bit shocking to people, but it is the way that the nation
[00:53:55.200 --> 00:53:56.080]   was set up.
[00:53:56.080 --> 00:54:00.080]   And the same thing with the popular vote versus Electoral College, right?
[00:54:00.080 --> 00:54:02.240]   People keep getting confused by that.
[00:54:02.240 --> 00:54:02.720]   That's right.
[00:54:02.720 --> 00:54:07.440]   And in this very unusual condition, where a candidate who's earned all of these delegates
[00:54:07.440 --> 00:54:11.440]   drops out of the race, it's shocking and surprising to people that they don't get
[00:54:11.440 --> 00:54:14.000]   to go and make a vote again, individually.
[00:54:14.000 --> 00:54:15.200]   And I think it feels unfair.
[00:54:15.200 --> 00:54:18.080]   And I think that a lot of people are feeling that way.
[00:54:18.080 --> 00:54:22.080]   I do, however, think that pretty quickly, there's a lot of people who are anyone but
[00:54:22.080 --> 00:54:24.240]   Trump, that are going to rally behind her.
[00:54:24.240 --> 00:54:28.480]   And she seems to be pulling well in the polls that have come out in the last couple days
[00:54:28.480 --> 00:54:28.720]   here.
[00:54:28.720 --> 00:54:29.040]   So...
[00:54:29.040 --> 00:54:31.680]   All right, let me hand it off to Sachs then.
[00:54:32.640 --> 00:54:41.680]   You had a situation where Trump was the runaway favorite, and this unbelievable unity at the
[00:54:41.680 --> 00:54:42.240]   RNC.
[00:54:42.240 --> 00:54:49.760]   And immediately after the RNC, the Democratic Party hot swaps Biden for Kamala.
[00:54:49.760 --> 00:54:53.360]   And they've got a lot of great VP picks that they can choose from.
[00:54:53.360 --> 00:54:59.120]   Mark Kelly looking like the possibility, which would obviously give them a lot of support
[00:54:59.120 --> 00:55:00.240]   in Arizona.
[00:55:00.240 --> 00:55:02.560]   And with moderates and law and order folks.
[00:55:02.560 --> 00:55:06.960]   So Sachs, we're looking at essentially a dead heat.
[00:55:06.960 --> 00:55:13.520]   Some polls have them tied, some polls, Reuters, Ipsos has Harris with a 2% lead, CNN has Trump
[00:55:13.520 --> 00:55:14.640]   with a 3% lead.
[00:55:14.640 --> 00:55:22.160]   What's your take on, forget about how we got here, how does this affect the race itself?
[00:55:22.160 --> 00:55:24.640]   This is a dead heat now.
[00:55:24.640 --> 00:55:26.960]   What are your thoughts on the race going forward?
[00:55:26.960 --> 00:55:30.960]   Who's the VP pick that you're most worried about going up against the Republicans?
[00:55:30.960 --> 00:55:35.360]   Well, look, this clearly reshuffles the race to some degree.
[00:55:35.360 --> 00:55:37.200]   I don't think it's a dead heat.
[00:55:37.200 --> 00:55:40.160]   The polling shows that Trump is still ahead in most of the swing states.
[00:55:40.160 --> 00:55:45.920]   But look, Harris has more upside than Biden does because she can actually campaign.
[00:55:45.920 --> 00:55:49.120]   I mean, Biden clearly was a surefire loser.
[00:55:49.120 --> 00:55:52.240]   And that was exposed in the presidential debate.
[00:55:52.240 --> 00:55:54.880]   And that's why there was a total panic in the Democrat Party.
[00:55:54.880 --> 00:55:57.920]   After that debate, they're like, "We got to get someone new," and they drove him out.
[00:55:57.920 --> 00:56:00.160]   I do want to just say a word about that process.
[00:56:00.160 --> 00:56:04.880]   Throughout that process, remember, it started with Biden doing that Stephanopoulos interview.
[00:56:04.880 --> 00:56:09.040]   He said that even God Almighty won't get me out of this race.
[00:56:09.040 --> 00:56:10.880]   Then he said, "Nobody's pushing me out.
[00:56:10.880 --> 00:56:11.840]   I'm not going anywhere.
[00:56:11.840 --> 00:56:13.360]   I'm campaigning next week."
[00:56:13.360 --> 00:56:16.800]   He expressed that what was happening in the party was a revolt against him.
[00:56:16.800 --> 00:56:20.640]   And then, boom, all of a sudden, he's out.
[00:56:20.640 --> 00:56:27.200]   And all we really know from the public reporting is that Nancy Pelosi said, "Joe, we can do this
[00:56:27.200 --> 00:56:28.400]   the easy way or the hard way."
[00:56:28.400 --> 00:56:36.080]   And he was out, again, less than 24 hours after he said, "I'm in and I'm campaigning next week."
[00:56:36.080 --> 00:56:38.560]   And even his surrogates on the Sunday morning shows
[00:56:38.560 --> 00:56:41.680]   were saying that he's definitely in the race.
[00:56:41.680 --> 00:56:43.040]   The White House staff didn't know.
[00:56:43.040 --> 00:56:44.560]   His campaign staff didn't know.
[00:56:44.560 --> 00:56:45.840]   It kind of came out of the blue.
[00:56:45.840 --> 00:56:48.480]   It's a very strange process.
[00:56:48.480 --> 00:56:54.560]   And it happened via him just posting a photograph of a letter that was on personal stationery,
[00:56:54.560 --> 00:56:57.520]   not even an official White House memorandum.
[00:56:57.520 --> 00:56:59.360]   And we didn't get an update.
[00:56:59.360 --> 00:57:03.280]   We didn't hear directly from the president about one of the most consequential decisions
[00:57:03.280 --> 00:57:06.960]   of his life and of his presidency until Wednesday.
[00:57:06.960 --> 00:57:08.000]   Well, he did have COVID.
[00:57:08.000 --> 00:57:10.720]   So for an 80-year-old, it's pretty hard.
[00:57:10.720 --> 00:57:11.200]   Fair enough.
[00:57:11.200 --> 00:57:12.880]   That was the story.
[00:57:12.880 --> 00:57:17.600]   But still, for us to be left in the dark wondering what was really going on for three days,
[00:57:17.600 --> 00:57:19.040]   it was very strange.
[00:57:19.040 --> 00:57:22.160]   It certainly was not what you would call a democratic process.
[00:57:22.160 --> 00:57:24.640]   There was no speedrun primary, as you wanted, Jason.
[00:57:24.640 --> 00:57:26.240]   There was no open convention.
[00:57:26.240 --> 00:57:30.640]   What happened is the delegates fell in line instantly, as I predicted because I said that
[00:57:30.640 --> 00:57:34.320]   they would not be able to handle the chaos, that they wanted to basically fall in line
[00:57:34.320 --> 00:57:36.480]   immediately and end the chaos.
[00:57:36.480 --> 00:57:41.760]   And they fell in line behind Kamala Harris, who has never gotten even one primary vote.
[00:57:41.760 --> 00:57:43.520]   Who worries you most as a VP candidate?
[00:57:43.520 --> 00:57:45.520]   Give us that because we understand that.
[00:57:45.520 --> 00:57:46.320]   I'll be honest with you.
[00:57:46.320 --> 00:57:50.960]   I think that the scariest, the one I would pick is Josh Shapiro.
[00:57:50.960 --> 00:57:54.560]   He's the governor of Pennsylvania, a rising star.
[00:57:54.560 --> 00:57:58.960]   Look, if he can deliver Pennsylvania for the Democrats, that's powerful.
[00:57:58.960 --> 00:58:08.000]   Because one way for Harris to eke out a victory is if Shapiro can get her Pennsylvania, and
[00:58:08.000 --> 00:58:16.400]   then if she sort of tacks back to appealing to the Arab and Muslim vote in Michigan, to
[00:58:16.400 --> 00:58:19.680]   eke out Michigan and then ekes out Wisconsin with just one point.
[00:58:19.680 --> 00:58:23.680]   In other words, if she can hold on to the blue wall and then she loses the swing states
[00:58:23.680 --> 00:58:29.280]   that Trump is very much ahead in, like Arizona, Nevada, Georgia, North Carolina, she can still
[00:58:29.280 --> 00:58:32.720]   win this election by 270 electoral votes to 268.
[00:58:32.720 --> 00:58:36.800]   It'd be the closest margin in presidential history.
[00:58:36.800 --> 00:58:38.800]   So, that's the scenario.
[00:58:38.800 --> 00:58:44.640]   And it's probably her best path to victory is to win by one electoral vote.
[00:58:44.640 --> 00:58:47.600]   That's the scenario I'd be most worried about as a Republican.
[00:58:47.600 --> 00:58:53.280]   Now, the other candidate you hear a lot about is Mark Kelly, the senator from Arizona, who
[00:58:53.280 --> 00:58:54.800]   on paper looks fantastic.
[00:58:54.800 --> 00:58:56.080]   He's an astronaut.
[00:58:56.080 --> 00:58:59.440]   His wife was a victim of a gunshot.
[00:58:59.440 --> 00:59:00.320]   Moderate, right?
[00:59:00.320 --> 00:59:01.520]   Super moderate.
[00:59:01.520 --> 00:59:04.880]   I personally don't think he is that moderate, but I think he presents as one.
[00:59:04.880 --> 00:59:07.200]   And he's made noises.
[00:59:07.200 --> 00:59:13.360]   He comes across as tough and comes across as someone who's wanted to be tougher on the
[00:59:13.360 --> 00:59:16.000]   border, which is a huge weakness for Harris.
[00:59:16.000 --> 00:59:22.160]   If he can deliver Arizona, then he becomes a strong contender, but I'm not sure that
[00:59:22.160 --> 00:59:22.800]   he can.
[00:59:22.800 --> 00:59:26.160]   So, if it were me, I'd probably go with Shapiro.
[00:59:26.160 --> 00:59:28.080]   I mean, I hope they're not listening to me.
[00:59:28.080 --> 00:59:29.440]   I hope they go with Kelly.
[00:59:29.440 --> 00:59:34.480]   Chamatha, obviously, even in this heated thing, the good news is that both sides are going
[00:59:34.480 --> 00:59:36.080]   to accept the election results.
[00:59:36.080 --> 00:59:41.280]   We have that fairness and that honorability in both parties where we'll accept even a
[00:59:41.280 --> 00:59:42.000]   close election.
[00:59:42.000 --> 00:59:43.280]   There'll be no drama after it.
[00:59:43.280 --> 00:59:47.040]   But what's your thought on the strongest ticket?
[00:59:47.040 --> 00:59:47.840]   Do you think Shapiro?
[00:59:47.840 --> 00:59:48.640]   Do you think Kelly?
[00:59:48.640 --> 00:59:55.680]   CNN said, "Hey," and this went viral, "Do we think a Jewish vice president, the country's
[00:59:55.680 --> 00:59:56.240]   ready for it?"
[00:59:56.240 --> 00:59:57.680]   They got kind of dragged for that.
[00:59:57.760 --> 01:00:02.400]   What do you think is the right VP pick here, Chamath?
[01:00:02.400 --> 01:00:08.080]   What do you think the right VP pick here is, and which one is the scariest to a Trump/J.D.
[01:00:08.080 --> 01:00:10.640]   Vance ticket, which is a very strong ticket in and of itself?
[01:00:10.640 --> 01:00:19.680]   So, if you look at Trump's VP pick, it's about aligning a philosophy.
[01:00:21.520 --> 01:00:27.440]   Donald Trump created the MAGA movement, this populist, conservative, right-wing movement.
[01:00:27.440 --> 01:00:34.480]   And I think J.D. Vance has an opportunity now to carry that torch post-Donald Trump.
[01:00:34.480 --> 01:00:40.240]   And that is an ideology that spans states.
[01:00:40.240 --> 01:00:45.840]   I think this idea that you pick somebody because they can deliver a state is pretty misguided.
[01:00:45.840 --> 01:00:49.040]   I just don't think that that, in reality, is what happens.
[01:00:49.760 --> 01:00:55.920]   So, I think that Kamala has to decide what she stands for, and figure out whether she
[01:00:55.920 --> 01:01:00.080]   needs somebody on her flank that represents a slightly different set of ideas that will
[01:01:00.080 --> 01:01:03.120]   then maximize her appeal, or she wants to double down.
[01:01:03.120 --> 01:01:08.640]   And then she has to pick somebody that sort of, like, aligns with her philosophically.
[01:01:08.640 --> 01:01:13.280]   And again, I would just say that it's not super clear yet what she thinks.
[01:01:13.280 --> 01:01:17.360]   I think that Joe Biden was more of a traditional centrist that
[01:01:17.360 --> 01:01:21.600]   had to appeal to the progressive left in order to get his work done.
[01:01:21.600 --> 01:01:26.640]   So, that kind of makes sense.
[01:01:26.640 --> 01:01:29.840]   You can understand it, you don't have to agree with it, but it's pretty obvious.
[01:01:29.840 --> 01:01:35.200]   I don't know what she, where she's at politically.
[01:01:35.200 --> 01:01:36.560]   So, I think that that's the first thing.
[01:01:36.560 --> 01:01:37.680]   She needs to explain herself.
[01:01:37.680 --> 01:01:38.720]   Is she a centrist?
[01:01:38.720 --> 01:01:42.880]   Is she more of a moderate Democrat?
[01:01:42.880 --> 01:01:45.120]   Is she more of a progressive Democrat?
[01:01:45.120 --> 01:01:50.000]   And then we can then understand who the best person to align her with should be.
[01:01:50.000 --> 01:01:55.680]   But if I was, if I if I was in the democratic kind of like star chamber,
[01:01:55.680 --> 01:01:59.840]   yeah, I would kind of try to figure that out first, because I think the Donald Trump pick
[01:01:59.840 --> 01:02:04.320]   makes a lot of sense, because it basically moves the Republican Party in a very firm
[01:02:04.320 --> 01:02:08.240]   direction that die is cast for the Republicans for many years to come now.
[01:02:08.240 --> 01:02:11.600]   Okay, free bird, your thoughts, who is the VP candidate?
[01:02:11.600 --> 01:02:14.480]   What do you think of this race?
[01:02:14.480 --> 01:02:16.400]   And give us a prediction.
[01:02:16.400 --> 01:02:20.640]   You know, you're famous for your incredible insights and predictions in politics.
[01:02:20.640 --> 01:02:21.440]   Give us your prediction.
[01:02:21.440 --> 01:02:23.200]   Who should you pick?
[01:02:23.200 --> 01:02:23.840]   Who will she pick?
[01:02:23.840 --> 01:02:28.560]   I think there's a lot of talk about Roy Cooper in North Carolina.
[01:02:28.560 --> 01:02:36.640]   Saxon mentioned Cooper, but sounds like could be in the running and could be a leading contender
[01:02:36.640 --> 01:02:37.440]   for the slot.
[01:02:38.800 --> 01:02:48.160]   I think the Harris Trump poll is not out or there's a recent one that shows Harris Yeah,
[01:02:48.160 --> 01:02:51.680]   4448 from in the lead in North Carolina.
[01:02:51.680 --> 01:02:56.720]   So there's some some room there.
[01:02:56.720 --> 01:03:00.880]   If you can get the governor in that spot, that's a lot of electoral votes.
[01:03:00.880 --> 01:03:04.080]   In terms of who I think should be, I'm not sure.
[01:03:04.080 --> 01:03:08.640]   But I do think that might be a top contender from folks I've talked to.
[01:03:08.960 --> 01:03:14.960]   Any thoughts on Shapiro and CNN's positioning that the country's not ready for a Jewish
[01:03:14.960 --> 01:03:16.000]   vice president.
[01:03:16.000 --> 01:03:22.320]   So, you know, I was shocked recently to hear about a board, a pretty, you know, important
[01:03:22.320 --> 01:03:25.040]   board, because it represents a large organization.
[01:03:25.040 --> 01:03:28.480]   And there was a an individual on the board who's supposed to be elected chairman, they
[01:03:28.480 --> 01:03:30.080]   went in for the for the vote.
[01:03:30.080 --> 01:03:34.160]   And in that board meeting, this individual who happens to be Jewish, there was a conversation
[01:03:34.160 --> 01:03:38.400]   that ensued about you can't be the chairman at this time, because having a Jewish chair,
[01:03:38.400 --> 01:03:42.000]   would be really difficult in this current climate.
[01:03:42.000 --> 01:03:48.080]   And I was shocked to hear this, you know, it was, it was not expected by by folks going
[01:03:48.080 --> 01:03:51.280]   into the meeting, things were supposed to be quite different in the vote.
[01:03:51.280 --> 01:03:55.520]   And ultimately, the decision was made that a Jewish person should not be the chair of
[01:03:55.520 --> 01:03:59.760]   the board at this time, Jake out to your question, I think that behind closed doors, these are
[01:03:59.760 --> 01:04:04.560]   the sorts of conversations that are going on, that there's a perception, given the Gaza
[01:04:04.560 --> 01:04:10.720]   conflict, that there is a risk of having Jewish leadership being put into powerful positions
[01:04:10.720 --> 01:04:12.720]   right now Jewish leaders being put in a powerful position.
[01:04:12.720 --> 01:04:15.200]   Wow, that is shocking.
[01:04:15.200 --> 01:04:16.240]   That's insane.
[01:04:16.240 --> 01:04:20.560]   It's just this is this is what is going what?
[01:04:20.560 --> 01:04:23.760]   This is just, yeah, it's shocking and deranged.
[01:04:23.760 --> 01:04:26.960]   And the anti semitism right now on social media.
[01:04:26.960 --> 01:04:34.240]   And what we're seeing online is just absolutely heartbreaking and infuriating in equal parts,
[01:04:34.240 --> 01:04:34.480]   sucks.
[01:04:34.480 --> 01:04:37.680]   Anything you want to add to this as we wrap up our what the
[01:04:37.680 --> 01:04:41.840]   Well, I mean, just talk about Shapiro sacks.
[01:04:41.840 --> 01:04:45.360]   Is the country ready for this that you saw the CNN clip?
[01:04:45.360 --> 01:04:49.200]   And, you know, sort of, can I just ask?
[01:04:49.200 --> 01:04:50.000]   I'm sorry.
[01:04:50.000 --> 01:04:50.800]   Go ahead.
[01:04:50.800 --> 01:04:51.680]   What does it solve?
[01:04:51.680 --> 01:04:54.160]   What does it accomplish?
[01:04:54.160 --> 01:05:00.160]   Less heat coming into that board, less protests, less less protests.
[01:05:00.160 --> 01:05:05.040]   The protesters now have, I guess what I would read into this, correct me if I'm wrong here,
[01:05:05.040 --> 01:05:11.840]   Freeberg, is the protesters have now won in that they've intimidated people to an extent
[01:05:11.840 --> 01:05:14.960]   that they don't want to go near Jewish leadership.
[01:05:14.960 --> 01:05:16.240]   Am I interpreting correctly?
[01:05:16.240 --> 01:05:18.480]   A possibility here?
[01:05:18.480 --> 01:05:22.400]   Sorry, say that again, the protesters and what?
[01:05:22.400 --> 01:05:30.560]   So these protests, the Gaza conflict have reached a point where people do not want to
[01:05:30.560 --> 01:05:35.200]   have Jewish leadership because it would be polarizing and create more protests.
[01:05:35.200 --> 01:05:36.400]   That's right.
[01:05:36.400 --> 01:05:36.880]   That's that.
[01:05:36.880 --> 01:05:40.960]   And that's the conversation that I hear going on behind closed doors or I'm hearing about.
[01:05:40.960 --> 01:05:47.920]   And so, you know, it's almost like a cancel culture against Jews because of the risk of
[01:05:47.920 --> 01:05:51.360]   a Jewish person being in a leadership position that could drive.
[01:05:51.360 --> 01:05:55.520]   Yeah, which is exactly what CNN was bringing up with the VP choice of Shapiro.
[01:05:55.520 --> 01:05:56.080]   And that's right.
[01:05:56.080 --> 01:05:57.360]   I think it's totally crazy.
[01:05:57.360 --> 01:06:00.560]   However, I definitely have seen people online.
[01:06:00.560 --> 01:06:05.920]   I mean, articles online, like saying, like, is this an issue with putting Shapiro on the ticket?
[01:06:05.920 --> 01:06:09.920]   Now, I can't believe this is a problem for the voters of the country.
[01:06:09.920 --> 01:06:15.440]   However, I think if you're one of the democratic masterminds and you're trying to engineer
[01:06:15.440 --> 01:06:20.000]   enough electoral votes for Harris to win, like I said, you're trying to win that blue wall.
[01:06:20.000 --> 01:06:22.080]   You're trying to get not just Pennsylvania, but Michigan.
[01:06:22.080 --> 01:06:31.360]   And the problem that Biden had and now Harris has in Michigan is that the large Arab and
[01:06:31.360 --> 01:06:37.360]   Muslim population of Michigan is really against the administration's support of Israel.
[01:06:37.360 --> 01:06:41.680]   Now, this is why Harris just snubbed Netanyahu when he came to Washington.
[01:06:41.680 --> 01:06:45.200]   So they are immediately trying to reposition that issue.
[01:06:45.200 --> 01:06:48.320]   And remember, the margin of error in Michigan is like 2%.
[01:06:49.200 --> 01:06:56.640]   So if they can win back that vote by seeming to be more progressive on the whole Israel-Gaza
[01:06:56.640 --> 01:06:59.920]   war, then there's a big electoral advantage for them.
[01:06:59.920 --> 01:07:05.920]   So I have to wonder if this is where this talk about, you know, is it an issue for Shapiro
[01:07:05.920 --> 01:07:07.760]   to be Jewish on the ticket or whatever?
[01:07:07.760 --> 01:07:12.400]   Again, it's nuts to me that we could be even having that conversation in this country.
[01:07:12.400 --> 01:07:18.400]   But it's possible that that is what's going on is it's like, can you win Pennsylvania,
[01:07:18.400 --> 01:07:19.440]   but not lose Michigan?
[01:07:19.440 --> 01:07:24.560]   - Well, the inevitable outcome of identity politics by giving everyone a definition on
[01:07:24.560 --> 01:07:30.080]   their race or their gender or their background or their religion is that you ultimately end
[01:07:30.080 --> 01:07:31.440]   up picking winners and losers.
[01:07:31.440 --> 01:07:34.080]   And you don't just get to pick winners.
[01:07:34.080 --> 01:07:41.520]   When you make selections or prioritize things based on identity like this, you also de facto
[01:07:41.520 --> 01:07:42.240]   pick losers.
[01:07:42.240 --> 01:07:46.000]   And that's where this unfortunate snowball.
[01:07:46.000 --> 01:07:49.920]   - When John F. Kennedy ran for president, it was a big issue that he was Catholic.
[01:07:49.920 --> 01:07:51.120]   I mean, you guys don't remember this, but-
[01:07:51.120 --> 01:07:51.600]   - I do.
[01:07:51.600 --> 01:07:53.200]   - In 1960, right?
[01:07:53.200 --> 01:07:54.960]   - It was a major thing in our family.
[01:07:54.960 --> 01:07:58.480]   There was a major point of pride that we had an Irish Catholic in the White House, yeah.
[01:07:58.480 --> 01:08:02.480]   - Yeah, and specifically what people asked is would he be loyal to the United States
[01:08:02.480 --> 01:08:06.640]   or be loyal to the Vatican and the Pope, you know, who was his ultimate authority?
[01:08:06.640 --> 01:08:09.440]   And he made it really clear, look, I'm gonna do what's right for the United States.
[01:08:09.440 --> 01:08:10.640]   And he neutralized that issue.
[01:08:11.760 --> 01:08:17.360]   I think that what matters about Shapiro or any VP is their views and their accomplishments,
[01:08:17.360 --> 01:08:22.560]   their policies, and whether he's Jewish or not really is secondary.
[01:08:22.560 --> 01:08:29.760]   Even if your principal concern is Gaza, there are still plenty of Jews who have a wide spectrum
[01:08:29.760 --> 01:08:31.360]   of views on that issue.
[01:08:31.360 --> 01:08:36.560]   So it is nuts to me that this conversation is seriously happening.
[01:08:36.560 --> 01:08:43.360]   - All right, there has been a kerfuffle, a Donnybrook online between Paul Graham and
[01:08:43.360 --> 01:08:45.760]   our bestie, David Sachs here.
[01:08:45.760 --> 01:08:52.080]   Here, Paul Graham, threatening you, Sachs on X, do you really want the full story of
[01:08:52.080 --> 01:08:54.400]   what you did to Parker being told publicly?
[01:08:54.400 --> 01:08:59.440]   Because it's the worst case of an investor maltreating a founder that I've ever heard,
[01:08:59.440 --> 01:09:01.120]   and I've heard practically all of them.
[01:09:01.120 --> 01:09:03.280]   This is Paul Graham, the founder of Y Combinator.
[01:09:03.280 --> 01:09:07.520]   I was talking recently to another investor about whether you are the most evil person
[01:09:07.520 --> 01:09:09.840]   in Silicon Valley, referring to you, David Sachs.
[01:09:09.840 --> 01:09:11.920]   He thought about it for a few seconds and agreed.
[01:09:11.920 --> 01:09:14.640]   And he couldn't think of anyone worse.
[01:09:14.640 --> 01:09:20.400]   The second tweet about you being the most evil person, David Sachs, in Silicon Valley
[01:09:20.400 --> 01:09:21.440]   has been deleted.
[01:09:21.440 --> 01:09:22.560]   - Well, that's nice to know.
[01:09:22.560 --> 01:09:24.480]   - But your response, it's nice to know, yes.
[01:09:24.480 --> 01:09:25.280]   - That's nice to know.
[01:09:25.280 --> 01:09:29.120]   There was also another unhinged tirade that he had against me a few months ago.
[01:09:29.120 --> 01:09:30.000]   - Okay.
[01:09:30.000 --> 01:09:37.120]   - Where he was commenting in the Ukraine debate and was responding to a Ukrainian partisan
[01:09:37.120 --> 01:09:42.080]   who, this guy is like a propagandist for Ukraine who was embedded in the Azov battalion.
[01:09:42.080 --> 01:09:44.640]   People may know what that is.
[01:09:44.640 --> 01:09:46.480]   In any event, Paul went out of his way.
[01:09:46.480 --> 01:09:49.600]   The thing is, I've never met Paul Graham.
[01:09:49.600 --> 01:09:50.320]   I don't know him.
[01:09:50.320 --> 01:09:53.520]   I've never done business with him.
[01:09:53.520 --> 01:09:58.160]   So it's just weird to me that he has this animus and this vitriol towards me.
[01:09:58.160 --> 01:10:00.560]   It's hard to know exactly what this is based on.
[01:10:00.560 --> 01:10:08.080]   I think that part of it is that he thinks he knows what happened at Zenefits, even though
[01:10:08.080 --> 01:10:09.360]   he wasn't involved at all.
[01:10:09.360 --> 01:10:14.720]   And he's just listening to one guy who's been nursing this vendetta for many years.
[01:10:14.720 --> 01:10:17.440]   And then other people are speculating that there could be other things involved.
[01:10:17.440 --> 01:10:18.800]   I don't quite know.
[01:10:18.800 --> 01:10:22.400]   - Do you want to set the record straight on Zenefits and just say what happened?
[01:10:22.400 --> 01:10:23.840]   - What is it that you guys want to know?
[01:10:23.920 --> 01:10:29.120]   - Parker apparently has done several public interviews where he kind of made claims.
[01:10:29.120 --> 01:10:30.640]   I think, I don't know if I've listened to him.
[01:10:30.640 --> 01:10:31.520]   I've just read the summaries.
[01:10:31.520 --> 01:10:33.200]   But Jake, you probably know that Parker's claimed that he was--
[01:10:33.200 --> 01:10:34.800]   - I just said you ran a coup on him.
[01:10:34.800 --> 01:10:39.360]   Obviously, for folks who don't know, there was an SEC investigation.
[01:10:39.360 --> 01:10:45.120]   And Parker was ousted from Zenefits as the founder CEO.
[01:10:45.120 --> 01:10:46.080]   He's very bitter about that.
[01:10:46.080 --> 01:10:50.080]   Did a revenge startup, Rippling, which is doing quite well, from what I understand.
[01:10:50.640 --> 01:10:55.600]   And he blames Sachs for all of this, even though he was sanctioned for doing essentially
[01:10:55.600 --> 01:11:05.520]   insurance fraud by helping people lie on a test for their insurance certifications.
[01:11:05.520 --> 01:11:08.160]   And he got sanctioned by the SEC for it.
[01:11:08.160 --> 01:11:11.440]   And as you pointed out, Sachs, he was the only person who was sanctioned for that.
[01:11:11.440 --> 01:11:13.760]   So he broke some rules.
[01:11:13.760 --> 01:11:17.600]   And he got a pretty serious penalty, yeah?
[01:11:17.600 --> 01:11:20.000]   Do I have that basically correct?
[01:11:20.000 --> 01:11:26.240]   - Yeah, I mean, look, that whole experience was easily the worst year of my entire professional
[01:11:26.240 --> 01:11:30.400]   career, having to deal with that mess that he created.
[01:11:30.400 --> 01:11:34.720]   And look, anybody can now say anything almost 10 years later in a podcast.
[01:11:34.720 --> 01:11:42.080]   But the situation there was thoroughly investigated by regulators who had subpoena powers, who
[01:11:42.080 --> 01:11:43.280]   did extensive discovery.
[01:11:43.280 --> 01:11:46.640]   They looked at everyone's emails throughout the whole company.
[01:11:46.640 --> 01:11:53.200]   They also interviewed something like a dozen people under oath and took witness testimony
[01:11:53.200 --> 01:11:53.840]   from them.
[01:11:53.840 --> 01:11:58.000]   And then they sanctioned him, they fined him, and they published an account of what happened.
[01:11:58.000 --> 01:12:02.400]   I personally think it's a huge waste of time to be like rehashing events that are almost
[01:12:02.400 --> 01:12:03.040]   a decade old.
[01:12:03.040 --> 01:12:10.720]   But I guess I'm being forced to by this smear campaign that he and Paul Graham have engineered
[01:12:10.720 --> 01:12:11.680]   against me.
[01:12:11.680 --> 01:12:15.760]   If you want to know what happened, just read what the SEC said.
[01:12:15.760 --> 01:12:17.520]   Read what the other regulators said.
[01:12:17.520 --> 01:12:24.320]   There was only one person who was named as being aware of the misconduct.
[01:12:24.320 --> 01:12:29.120]   And there was only one person who was fined and held accountable by regulators.
[01:12:29.120 --> 01:12:31.280]   In fact, he was fined more than the company.
[01:12:31.280 --> 01:12:35.680]   Now, if he just said, yeah, look, I learned from that mistake.
[01:12:35.680 --> 01:12:37.840]   And I made some mistakes, moved on.
[01:12:37.840 --> 01:12:40.000]   And apparently he does have a successful company.
[01:12:40.000 --> 01:12:42.960]   So I don't really understand why he's so bitter.
[01:12:42.960 --> 01:12:47.040]   He seems to have like a, you know, he's like disturbed about it.
[01:12:47.040 --> 01:12:48.800]   Then it would be fine.
[01:12:48.800 --> 01:12:51.520]   I mean, there would be no reason to be talking about this.
[01:12:51.520 --> 01:12:55.920]   But the guy refuses to admit that he did anything wrong.
[01:12:55.920 --> 01:13:00.800]   And instead, he's created this elaborate story that his departure from Zenefits wasn't related
[01:13:00.800 --> 01:13:02.720]   to massive compliance issues.
[01:13:02.720 --> 01:13:06.960]   And that somehow it was related to him seeing a sales target or being the victim of a coup.
[01:13:06.960 --> 01:13:08.640]   That's not what happened.
[01:13:08.640 --> 01:13:14.000]   This was a regulatory crisis that unfolded over many months and kept getting worse and
[01:13:14.000 --> 01:13:14.560]   worse.
[01:13:14.560 --> 01:13:18.480]   And we kept discovering new compliance violations.
[01:13:18.480 --> 01:13:22.960]   And this created a 50 state insurance investigation that could have shut the company down.
[01:13:22.960 --> 01:13:25.360]   And he controlled the board.
[01:13:25.360 --> 01:13:28.640]   He didn't have to leave if he didn't want to.
[01:13:28.640 --> 01:13:32.160]   He ultimately perceived that it was in his interest to leave and let us clean it up.
[01:13:32.160 --> 01:13:36.080]   And then he went on to go do this other startup, which I think he was planning to do all along.
[01:13:36.080 --> 01:13:40.480]   So his plan worked out for him, which is he left a big mess for us to clean up.
[01:13:40.480 --> 01:13:43.840]   And he's very successful now with the new company.
[01:13:43.840 --> 01:13:44.960]   So right, right.
[01:13:44.960 --> 01:13:50.240]   Sax, I remember, I will just say, I remember how hard you worked at that after you were
[01:13:50.240 --> 01:13:52.560]   in the CEO seat, and then you were promoted to CEO.
[01:13:52.560 --> 01:13:57.120]   And I was really impressed watching it and seeing what you did, because you chose to
[01:13:57.120 --> 01:14:02.080]   step up and take care of this company at a time where you expressed to all of us privately
[01:14:02.080 --> 01:14:04.880]   how hard it was and what a challenge this company had found itself in.
[01:14:05.520 --> 01:14:09.520]   And you had investors that were friends of yours that were involved in the company that
[01:14:09.520 --> 01:14:10.240]   were on the board.
[01:14:10.240 --> 01:14:13.200]   And I think you did what felt like at the time.
[01:14:13.200 --> 01:14:17.440]   And from my experience, interacting with you during this time, the right thing, which was
[01:14:17.440 --> 01:14:20.400]   to step up and address this rather than just throw your hands in the air and say, this
[01:14:20.400 --> 01:14:23.280]   guy screwed things up, or this company screwed up and walk away from it.
[01:14:23.280 --> 01:14:27.120]   You had personally put money in, your friends had put money in, and you worked hard to try
[01:14:27.120 --> 01:14:30.480]   and help the business recover after this miserable period of time.
[01:14:30.480 --> 01:14:32.960]   And it was really impressive to watch you do that work.
[01:14:32.960 --> 01:14:37.680]   So I just want to highlight my kind of experience watching you and knowing you during that time.
[01:14:37.680 --> 01:14:38.160]   Yeah, well, thank you.
[01:14:38.160 --> 01:14:40.080]   It was miserable and obviously pretty thankless.
[01:14:40.080 --> 01:14:42.400]   And I did it for no compensation.
[01:14:42.400 --> 01:14:45.040]   I did it because, like you said, I had a lot of friends who invested in the company.
[01:14:45.040 --> 01:14:48.160]   I just thought it was the right thing to do to do this cleanup.
[01:14:48.160 --> 01:14:49.920]   The lawyers said it would take two years.
[01:14:49.920 --> 01:14:51.840]   We managed to get it done in one year.
[01:14:51.840 --> 01:14:53.840]   We got a clean bill of health from regulators.
[01:14:53.840 --> 01:14:56.480]   We had to remediate all the compliance failures.
[01:14:56.480 --> 01:15:01.520]   And when I then handed the torch to the new CEO, we had $200 million in the bank and $60
[01:15:01.520 --> 01:15:03.840]   million of ARR with a clean bill of health.
[01:15:03.840 --> 01:15:09.760]   So, you know, but I didn't know I'd have this like crazy founder like lobbing bombs at me
[01:15:09.760 --> 01:15:10.480]   the whole time.
[01:15:10.480 --> 01:15:15.040]   And frankly, if I had known he was going to do this, I would have just said, listen, man,
[01:15:15.040 --> 01:15:16.560]   you clean up your mess.
[01:15:16.560 --> 01:15:19.840]   And he would have continued playing games and stonewalling the regulators.
[01:15:19.840 --> 01:15:22.480]   And it would have been a much worse situation for sure.
[01:15:22.480 --> 01:15:25.280]   Chamath, you want to add anything here before we wrap up on this?
[01:15:25.280 --> 01:15:27.680]   Because I have two points to make, but I'll let you go first.
[01:15:28.320 --> 01:15:34.240]   Look, I think that part of what happens in Silicon Valley is that there's these cliques,
[01:15:34.240 --> 01:15:41.920]   and there's definitely a YC clique, and they protect their own in absolute terms.
[01:15:41.920 --> 01:15:45.840]   And so I think there's a level of morality that everybody else has to live by.
[01:15:45.840 --> 01:15:49.840]   That's not necessarily the rules that apply if you're a YC CEO.
[01:15:51.040 --> 01:15:55.520]   Now, that was accepted in Silicon Valley, because in the early days,
[01:15:55.520 --> 01:16:04.560]   they were, frankly, one of a very, very small handful of games in town with respect to high
[01:16:04.560 --> 01:16:07.520]   quality deal flow when you started to do series A, B and C.
[01:16:07.520 --> 01:16:12.800]   And as a result of that, I think venture capitalists essentially looked the other way,
[01:16:12.800 --> 01:16:14.880]   because the returns were so good.
[01:16:14.880 --> 01:16:18.000]   The companies that were coming out of the incubator were so good.
[01:16:18.000 --> 01:16:22.720]   But as with all things, when you're successful and you try to scale, returns decay.
[01:16:22.720 --> 01:16:28.960]   And this is not a slight on YC's returns, but it's what happens to everybody.
[01:16:28.960 --> 01:16:33.120]   So if you look at Blackstone's returns, they were incredible when they started,
[01:16:33.120 --> 01:16:34.720]   and they're okay today.
[01:16:34.720 --> 01:16:38.400]   When you look at Sequoia's returns, they were incredible when they started.
[01:16:38.400 --> 01:16:40.320]   They're okay today.
[01:16:40.320 --> 01:16:42.560]   YC's returns were incredible when they started.
[01:16:42.560 --> 01:16:43.600]   They're okay today.
[01:16:43.600 --> 01:16:46.000]   And this is nothing against any of these folks.
[01:16:46.000 --> 01:16:50.560]   It's that in the business of building an organization and scaling, that's what happens.
[01:16:50.560 --> 01:16:55.120]   And when that happens, and a lot more competition emerges on the scene,
[01:16:55.120 --> 01:17:04.560]   the old tactics that you used to run a protection racket, if you will, just doesn't work anymore.
[01:17:04.560 --> 01:17:09.840]   And I think part of what's spilling out in public here is that that kind of immature
[01:17:09.840 --> 01:17:15.040]   form of bullying and intimidation is just kind of dumb, because it just doesn't hang
[01:17:15.040 --> 01:17:15.920]   together anymore.
[01:17:15.920 --> 01:17:24.160]   So I don't know, I thought the whole melee, if you will, ruckus, Jason, fracas, fracas,
[01:17:24.160 --> 01:17:34.800]   Donnie Brock, a clash, yeah, was more about a guy that was engaged in this trying to do
[01:17:34.800 --> 01:17:40.400]   what he perceived to be the right thing for a YC founder in his community.
[01:17:40.400 --> 01:17:44.880]   But probably just he just needs to get back to work and do something productive.
[01:17:44.880 --> 01:17:46.560]   And probably this wouldn't happen the next time.
[01:17:46.560 --> 01:17:48.960]   I'll just make two points here.
[01:17:48.960 --> 01:17:54.800]   Y Combinator has always, like much of our industry, they're not unique in this, been
[01:17:54.800 --> 01:18:01.600]   in favor of rule benders, breakers, and naughty is actually something in their interview process
[01:18:01.600 --> 01:18:03.040]   that they optimize for.
[01:18:03.040 --> 01:18:06.560]   Sam Altman has talked about this very publicly.
[01:18:06.560 --> 01:18:11.600]   I had a YC alum who was trying to get funding for me, hack my voicemail and change my outgoing
[01:18:11.600 --> 01:18:12.240]   voicemail.
[01:18:12.240 --> 01:18:15.760]   And that was like a big brouhaha on Hacker News, et cetera.
[01:18:15.760 --> 01:18:20.160]   And we kind of celebrate a little bit of bending and breaking of rules.
[01:18:20.160 --> 01:18:24.160]   And what everybody needs to understand is sometimes if you bend or break a rule, like
[01:18:24.160 --> 01:18:29.680]   insurance certification, like Parker did here, that can be fatal for a company, which it
[01:18:29.680 --> 01:18:30.080]   was.
[01:18:30.080 --> 01:18:33.680]   And it can be really, really dangerous.
[01:18:33.680 --> 01:18:40.160]   And so then you super impose on top of this, to your point, Chama, Y Combinator, very big,
[01:18:40.160 --> 01:18:41.840]   powerful organization.
[01:18:41.840 --> 01:18:46.000]   Some folks say a mafia, and they described it as a bully stack.
[01:18:46.000 --> 01:18:47.840]   Y Combinator does circle the wagons.
[01:18:47.840 --> 01:18:48.800]   They do bully people.
[01:18:48.800 --> 01:18:55.280]   And they do put out a presentation that we are the only people in Silicon Valley who
[01:18:55.280 --> 01:19:00.400]   are founder friendly, even though they're getting 7% for 125K, like we do in our accelerator,
[01:19:00.400 --> 01:19:04.160]   Techstar does, while also saying everybody else is the enemy.
[01:19:04.160 --> 01:19:06.400]   Everybody else is taking advantage of founders.
[01:19:06.400 --> 01:19:09.040]   The truth is we're all working really hard.
[01:19:09.040 --> 01:19:13.600]   Every founder is going to hack their way to success.
[01:19:13.600 --> 01:19:16.720]   Sometimes you take it too far, like Parker did here.
[01:19:16.720 --> 01:19:18.160]   He learned a lot of lessons.
[01:19:18.160 --> 01:19:19.760]   Like some people say, Uber did.
[01:19:19.760 --> 01:19:21.440]   Like some people say, Airbnb did.
[01:19:21.440 --> 01:19:25.600]   There's always been rule breaking and bending in the entrepreneurial class.
[01:19:25.600 --> 01:19:31.440]   And then you superimpose on it, Paul Graham's feelings in the Middle East, Saks, your strong
[01:19:31.440 --> 01:19:33.360]   feelings about Ukraine and politics.
[01:19:33.360 --> 01:19:38.960]   And now the footprint of Silicon Valley is just so powerful, so influential on the global
[01:19:38.960 --> 01:19:40.880]   stage when it comes to politics.
[01:19:40.880 --> 01:19:44.000]   It just reaches a level of toxicity here that it doesn't need to.
[01:19:44.000 --> 01:19:45.280]   We're all on the same team.
[01:19:45.280 --> 01:19:46.960]   Let's all build great companies.
[01:19:46.960 --> 01:19:49.680]   Let's put this ugliness behind us and get back to work.
[01:19:49.680 --> 01:19:50.720]   That's my final statement.
[01:19:50.720 --> 01:19:51.840]   Nostracanus has spoken.
[01:19:51.840 --> 01:19:53.680]   I like that statement.
[01:19:53.680 --> 01:19:58.560]   And if we were just talking about somebody who had learned their lesson, this wouldn't
[01:19:58.560 --> 01:19:59.280]   even be an issue.
[01:19:59.280 --> 01:20:01.280]   This is like events that happened a decade ago.
[01:20:01.280 --> 01:20:03.760]   Such a waste of our time and energy even be talking about it.
[01:20:03.760 --> 01:20:08.960]   The problem is that you have people, really we're talking about Parker and Paul Graham,
[01:20:08.960 --> 01:20:12.480]   who are trying to smear somebody as a way to-
[01:20:12.480 --> 01:20:12.980]   You.
[01:20:12.980 --> 01:20:15.120]   They're trying to damage your business.
[01:20:15.120 --> 01:20:15.680]   Let's be honest.
[01:20:15.680 --> 01:20:18.480]   They're trying to get founders to not work with you.
[01:20:18.480 --> 01:20:19.600]   For sure they're doing that.
[01:20:19.600 --> 01:20:21.440]   And that's bullshit, by the way.
[01:20:21.440 --> 01:20:26.080]   Look, Parker has this very complicated story and the whole purpose of it is to exonerate
[01:20:26.080 --> 01:20:26.960]   himself.
[01:20:26.960 --> 01:20:31.040]   To basically say that he didn't engage in any wrongdoing and somehow he was set up.
[01:20:31.040 --> 01:20:31.760]   Okay.
[01:20:31.760 --> 01:20:32.640]   It's ridiculous.
[01:20:32.640 --> 01:20:34.800]   I mean, I don't have that kind of power over the SEC.
[01:20:34.800 --> 01:20:38.320]   The SEC, they sent us a list of people they wanted to talk to.
[01:20:38.320 --> 01:20:39.280]   I was not on the list.
[01:20:39.280 --> 01:20:41.600]   And I was like, "Well, wait, don't they want to talk to me?
[01:20:41.600 --> 01:20:43.440]   I'm the new CEO of the company."
[01:20:43.440 --> 01:20:45.840]   And the lawyer said, "No, your discovery was clean as a whistle.
[01:20:45.840 --> 01:20:46.880]   They don't have any questions for you.
[01:20:46.880 --> 01:20:50.960]   They only want to talk to people who they saw in the discovery there was an issue."
[01:20:51.360 --> 01:20:53.920]   So the regulators prosecuted.
[01:20:53.920 --> 01:20:56.560]   They basically conducted this investigation.
[01:20:56.560 --> 01:20:58.640]   I had no impact over that.
[01:20:58.640 --> 01:21:00.640]   It was a very serious issue.
[01:21:00.640 --> 01:21:01.680]   This was not made up.
[01:21:01.680 --> 01:21:07.200]   So I just think it kind of defies belief to now say that all the regulatory compliance
[01:21:07.200 --> 01:21:10.960]   issues which played out over months were not an existential issue for the company.
[01:21:10.960 --> 01:21:12.000]   It certainly was.
[01:21:12.000 --> 01:21:13.520]   But look, we have better things to talk about.
[01:21:13.520 --> 01:21:15.120]   Do you see Ali Resnick's tweet?
[01:21:15.120 --> 01:21:17.040]   This is pretty dark.
[01:21:17.040 --> 01:21:19.440]   Ali Resnick tweeting here.
[01:21:19.440 --> 01:21:27.600]   "Paul Graham reached out to the key SV firm, Silicon Valley firms, to attempt to get Jewish
[01:21:27.600 --> 01:21:31.840]   VCs fired post-October 7th."
[01:21:31.840 --> 01:21:33.200]   No idea if that's true or not.
[01:21:33.200 --> 01:21:41.440]   But there has been this Paul Graham is anti-Semitic sort of meme going around.
[01:21:41.440 --> 01:21:42.800]   I don't think he's anti-Semitic.
[01:21:42.800 --> 01:21:45.040]   But this is a pretty bold charge here.
[01:21:45.040 --> 01:21:46.240]   And I don't know if it's true or not.
[01:21:46.240 --> 01:21:48.560]   Well, I can speak to some of it.
[01:21:48.560 --> 01:21:49.200]   OK, go ahead.
[01:21:49.200 --> 01:21:49.600]   Yeah.
[01:21:49.600 --> 01:21:52.000]   I've talked to a few people who are involved in this.
[01:21:52.000 --> 01:21:55.440]   Look, I think what happened is that in the wake of October 7th, there was obviously a
[01:21:55.440 --> 01:21:57.360]   very heated debate online.
[01:21:57.360 --> 01:22:00.720]   PG is on one side of that.
[01:22:00.720 --> 01:22:03.360]   He got into it with supporters of Israel on the other side.
[01:22:03.360 --> 01:22:07.760]   They accused him of saying anti-Semitic things.
[01:22:07.760 --> 01:22:14.960]   He took offense to that and basically went over their heads to their bosses of a couple
[01:22:14.960 --> 01:22:19.520]   of different VC firms, at least two that I know of, where he basically went to the heads
[01:22:19.520 --> 01:22:23.440]   of these firms to express his displeasure, I guess, with these exchanges.
[01:22:23.440 --> 01:22:28.400]   And I think the feeling on the part of the junior VCs, because the people he was going
[01:22:28.400 --> 01:22:30.960]   over the heads of were not senior partners or whatever.
[01:22:30.960 --> 01:22:34.000]   These were lower-level to mid-level VCs at firms.
[01:22:34.000 --> 01:22:37.200]   You can understand how they would receive that.
[01:22:37.200 --> 01:22:38.800]   The head of YC is going over--
[01:22:38.800 --> 01:22:40.240]   Yeah, Paul Graham is a giant.
[01:22:40.240 --> 01:22:40.800]   Yeah.
[01:22:41.600 --> 01:22:47.600]   He's basically going to the heads of their firm to seek a correction in their behavior,
[01:22:47.600 --> 01:22:50.320]   even though this wasn't like a workplace activity.
[01:22:50.320 --> 01:22:54.960]   And so they certainly felt intimidated and silenced by that.
[01:22:54.960 --> 01:22:57.920]   Or in the worst case, that he was trying to get them fired.
[01:22:57.920 --> 01:23:03.360]   In his case, I guess he's trying to say, "Hey, this isn't cool to call me an anti-Semite"
[01:23:03.360 --> 01:23:04.480]   on Twitter publicly.
[01:23:04.480 --> 01:23:07.040]   And the truth may be somewhere in between.
[01:23:07.040 --> 01:23:12.160]   I mean, the great irony of this, of course, is he's concerned about his reputation being
[01:23:12.160 --> 01:23:12.800]   damaged.
[01:23:12.800 --> 01:23:17.200]   And I know YC took it very seriously, the claims that they're anti-Semitic, and Paul
[01:23:17.200 --> 01:23:18.560]   Graham's anti-Semitic.
[01:23:18.560 --> 01:23:20.560]   They took that very seriously, as they should.
[01:23:20.560 --> 01:23:24.560]   But here he is out there trying to damage your reputation.
[01:23:24.560 --> 01:23:31.120]   So it's a little bit of hypocrisy here, I think, if he's outwardly trying to destroy
[01:23:31.120 --> 01:23:34.240]   your reputation with founders, and then he's concerned about his reputation.
[01:23:34.240 --> 01:23:39.040]   Well, clearly there's a double standard here, because PG doesn't like being called names
[01:23:39.040 --> 01:23:39.600]   on Twitter.
[01:23:39.600 --> 01:23:42.960]   He doesn't like his views being labeled.
[01:23:42.960 --> 01:23:48.080]   And he's willing to take those debates offline, go over the heads, not talk to the people
[01:23:48.080 --> 01:23:52.960]   who said those things, but then go to their bosses, the heads of their firm, maybe not
[01:23:52.960 --> 01:23:57.040]   threaten them, maybe not say, "I don't think he said fire this person," or whatever.
[01:23:57.040 --> 01:24:02.000]   But like you said, there's always an implication of retaliation because people understand the
[01:24:02.000 --> 01:24:03.680]   way that YC operates.
[01:24:03.680 --> 01:24:10.800]   And certainly those junior level VCs experienced it as a form of intimidation.
[01:24:10.800 --> 01:24:13.280]   I mean, this is the classic cancellation playbook, right?
[01:24:13.280 --> 01:24:17.680]   And this is what people will do to the left or the right, or they'll do it to advertisers.
[01:24:17.680 --> 01:24:19.520]   They'll try to get advertisers to cancel.
[01:24:19.520 --> 01:24:24.560]   It feels similar to that cancel culture, even if that's not how PG intended it.
[01:24:24.560 --> 01:24:29.360]   Well, it's also like rather hypocritical when he's super sensitive about this type
[01:24:29.360 --> 01:24:35.520]   of thing, but then he's instigating this pylon when on this whole Zenefits thing, he's basically
[01:24:35.520 --> 01:24:40.160]   single source from a disgruntled founder who has this vendetta, who's been nursing this
[01:24:40.160 --> 01:24:41.040]   thing for years.
[01:24:41.040 --> 01:24:42.240]   He's never talked to me.
[01:24:42.240 --> 01:24:46.960]   Like I said, he's never even met me, but he's willing to call me the most evil person in
[01:24:46.960 --> 01:24:48.160]   all of Silicon Valley.
[01:24:48.160 --> 01:24:53.040]   And then again, instigate this pylon with like all these other people from YC.
[01:24:53.040 --> 01:24:53.280]   Yeah.
[01:24:53.280 --> 01:24:56.640]   I mean, how dare him call you the most evil person?
[01:24:56.640 --> 01:24:58.720]   That's my job here on the podcast.
[01:24:58.720 --> 01:24:59.680]   Yeah, exactly.
[01:24:59.680 --> 01:25:03.440]   And then I saw like other people from YC, like Michael Siebel, who I think is actually
[01:25:03.440 --> 01:25:04.320]   a really cool guy.
[01:25:04.320 --> 01:25:05.040]   Oh, he's awesome.
[01:25:05.040 --> 01:25:05.600]   Yeah.
[01:25:05.600 --> 01:25:07.040]   Super supportive of founders.
[01:25:07.040 --> 01:25:10.800]   And then he's tweeting that like I somehow I put up my founders who were, there were
[01:25:10.800 --> 01:25:15.440]   a lot of founders who basically spoke up and actually said, including many founders who
[01:25:15.440 --> 01:25:18.560]   came out of YC say, you know, actually David's been a great VC to us.
[01:25:18.560 --> 01:25:21.360]   And he's saying, oh, Saks must've put them up to it.
[01:25:21.360 --> 01:25:23.360]   No, I never asked anybody to do that.
[01:25:23.360 --> 01:25:27.440]   And a good reason why is I don't want to trouble my founders.
[01:25:27.440 --> 01:25:28.560]   Or drag them into this.
[01:25:28.560 --> 01:25:28.800]   Yeah.
[01:25:28.800 --> 01:25:29.440]   Drag them into it.
[01:25:29.440 --> 01:25:30.800]   So I'm not going to make them do that.
[01:25:30.800 --> 01:25:32.160]   So I had nothing to do with that.
[01:25:32.160 --> 01:25:36.320]   But, but frankly, you know, old saying that every accusation is a confession.
[01:25:36.320 --> 01:25:40.400]   Maybe the reason why people at YC think that I might've done that is because that's kind
[01:25:40.400 --> 01:25:43.040]   of their playbook is they create these online mobs.
[01:25:43.040 --> 01:25:46.560]   But like what gives him the right to do that?
[01:25:46.560 --> 01:25:47.120]   I can tell you.
[01:25:47.120 --> 01:25:48.400]   Go for it.
[01:25:48.400 --> 01:25:50.160]   He doesn't have enough to do.
[01:25:50.160 --> 01:25:53.600]   He's sitting around, he's got a lot of money.
[01:25:53.600 --> 01:25:55.040]   I mean, he's been very successful.
[01:25:55.680 --> 01:25:59.200]   And as far as I can tell, he's just getting into dustups on Twitter.
[01:25:59.200 --> 01:26:03.200]   And then like, like I, there's a lot of amazing people.
[01:26:03.200 --> 01:26:07.680]   We all know them that are so good when they're under pressure focused and grinding.
[01:26:07.680 --> 01:26:13.600]   And then when you take a little bit of the pressure off, they just go crazy and they
[01:26:13.600 --> 01:26:14.400]   don't have enough to do.
[01:26:14.400 --> 01:26:17.760]   And it's amplified by money and it's amplified their own perceptions of themselves.
[01:26:17.760 --> 01:26:20.880]   So I don't know, maybe, maybe you should just go back to work.
[01:26:20.880 --> 01:26:22.240]   So everybody back to work.
[01:26:23.600 --> 01:26:26.640]   When these things get heated, here's an interesting idea for everybody.
[01:26:26.640 --> 01:26:29.120]   Go get a cup of coffee with the person you disagree with.
[01:26:29.120 --> 01:26:32.800]   Sit down like we do here at the all in podcast and have a vibrant debate.
[01:26:32.800 --> 01:26:33.840]   It makes life richer.
[01:26:33.840 --> 01:26:34.880]   It makes you smarter.
[01:26:34.880 --> 01:26:36.080]   It gives you more perspective.
[01:26:36.080 --> 01:26:41.200]   And so PG, Saks, anybody else involved and just all sit down and have a cup of coffee.
[01:26:41.200 --> 01:26:42.160]   Try to hash this out.
[01:26:42.160 --> 01:26:42.720]   Okay.
[01:26:42.720 --> 01:26:44.080]   Good coffee in San Francisco.
[01:26:44.080 --> 01:26:45.200]   That's my RX.
[01:26:45.200 --> 01:26:46.560]   Freeberg.
[01:26:46.560 --> 01:26:48.320]   I've been talking to Saks privately.
[01:26:48.320 --> 01:26:52.640]   He has been complaining to me for weeks that we've had too much politics on the program
[01:26:52.640 --> 01:26:54.480]   and not enough science corner.
[01:26:54.480 --> 01:27:01.200]   So I acquiesced to Saks' appeals to me and all of his supporters to, to get a science
[01:27:01.200 --> 01:27:02.000]   corner in today.
[01:27:02.000 --> 01:27:04.560]   Let's talk about nuclear power.
[01:27:04.560 --> 01:27:06.640]   Everybody's got nuclear power on their mind.
[01:27:06.640 --> 01:27:10.800]   Obviously, China's doing a really good job of executing on it.
[01:27:10.800 --> 01:27:12.560]   And there's some new science here.
[01:27:12.560 --> 01:27:13.440]   So fill us in.
[01:27:13.440 --> 01:27:16.960]   Saks looks so engaged.
[01:27:16.960 --> 01:27:17.360]   Let's go.
[01:27:17.360 --> 01:27:21.760]   Well, Saks might like it because it's, it's a bit of an economic story and a bit of a
[01:27:21.760 --> 01:27:25.840]   China competitive story, which I think is the main point here.
[01:27:25.840 --> 01:27:31.920]   The story is rooted in a paper that was published out of China on their new high temperature
[01:27:31.920 --> 01:27:37.200]   gas cooled pebble bed reactor, which is a new type of nuclear reactor technology that
[01:27:37.200 --> 01:27:40.640]   shows that this thing cannot melt down, which is an amazing new technology.
[01:27:40.640 --> 01:27:45.280]   But I want to just take a step back and talk about general electricity production in the
[01:27:45.280 --> 01:27:46.880]   US versus China and where it's headed.
[01:27:47.440 --> 01:27:53.120]   So today, the US has roughly one terawatt of total electricity production capacity.
[01:27:53.120 --> 01:27:58.400]   China today has about three terawatts of total electricity production capacity.
[01:27:58.400 --> 01:28:03.360]   And about, you know, two to 3% of that is nuclear today for China.
[01:28:03.360 --> 01:28:08.720]   So by 2050, the US is projected to build out an additional terawatt to getting us to two
[01:28:08.720 --> 01:28:09.760]   terawatts of capacity.
[01:28:09.760 --> 01:28:13.200]   So we're going to double our total electricity output by 2050.
[01:28:13.840 --> 01:28:19.840]   China, meanwhile, has a plan stated to increase electricity production to 8.7 terawatts.
[01:28:19.840 --> 01:28:22.880]   So basically tripling between now and 2050.
[01:28:22.880 --> 01:28:26.480]   88% of their power by 2050 will be renewables.
[01:28:26.480 --> 01:28:32.480]   And by 2060, they've stated this goal that they want about 18% of their overall power
[01:28:32.480 --> 01:28:34.400]   to come from nuclear reactors.
[01:28:34.400 --> 01:28:38.000]   They currently have 26 nuclear reactors in the construction phase.
[01:28:38.000 --> 01:28:40.880]   They've got planning going on around building 300 of these.
[01:28:42.000 --> 01:28:45.920]   And they've already got stated plans around 500 gigawatts of capacity.
[01:28:45.920 --> 01:28:50.800]   Just to give you a sense of that 500 gigawatts, which is what China's got plans for is half
[01:28:50.800 --> 01:28:54.480]   of the total US electricity production today.
[01:28:54.480 --> 01:28:59.040]   That's in their nuclear build out today, just to give you a sense of the relative cost of
[01:28:59.040 --> 01:29:00.000]   electricity.
[01:29:00.000 --> 01:29:02.400]   China is about seven to 9 cents a kilowatt hour.
[01:29:02.400 --> 01:29:05.920]   The US is 17 to 25 cents a kilowatt hour.
[01:29:06.800 --> 01:29:12.480]   And China is projected to drop their price to less than six cents due to the expansion
[01:29:12.480 --> 01:29:15.840]   of renewables and nuclear power in the country.
[01:29:15.840 --> 01:29:20.720]   So the US cost is about triple what it is in China to build out new electricity capacity.
[01:29:20.720 --> 01:29:22.320]   That's a really important point.
[01:29:22.320 --> 01:29:24.240]   So currently, we have about a third of what China has.
[01:29:24.240 --> 01:29:28.320]   China is going to triple, we're going to double by 2050.
[01:29:28.320 --> 01:29:31.200]   Their cost is already lower than ours, and it's going to get lower.
[01:29:31.200 --> 01:29:37.520]   And their cost to build out new electricity is a fraction of what it is in the US.
[01:29:37.520 --> 01:29:39.280]   So this is a massive difference.
[01:29:39.280 --> 01:29:43.440]   The International Energy Agency estimates that the electricity from nuclear power cost
[01:29:43.440 --> 01:29:50.240]   65 bucks per megawatt hour in China compared to 105 in the US and 140 in the EU.
[01:29:50.240 --> 01:29:55.040]   And recent data has US costs looking like they might be anywhere from five to up to
[01:29:55.040 --> 01:29:57.440]   10 times what it costs to build out in China.
[01:29:57.440 --> 01:30:02.960]   So this is a real important, long term competitive point.
[01:30:02.960 --> 01:30:06.800]   China has more electricity production, it's cheaper to make electricity and it's cheaper
[01:30:06.800 --> 01:30:08.080]   to build new capacity.
[01:30:08.080 --> 01:30:09.680]   And they're building at an accelerated rate.
[01:30:09.680 --> 01:30:14.160]   And this really highlights the industrial challenge the United States is going to have
[01:30:14.160 --> 01:30:15.360]   in the decades ahead.
[01:30:15.360 --> 01:30:19.920]   We talk a lot about wanting to onshore manufacturing in the US, build out new manufacturing
[01:30:19.920 --> 01:30:24.400]   technologies, but ultimately, all of these industries, particularly AI, are going to
[01:30:24.400 --> 01:30:25.760]   be driven by the cost of power.
[01:30:26.640 --> 01:30:30.080]   So, Nick, if you pull up this chart, so what's going on in nuclear?
[01:30:30.080 --> 01:30:35.120]   Well, there's effectively considered to be four generations of nuclear reactors.
[01:30:35.120 --> 01:30:37.360]   The first generation was all the early prototypes.
[01:30:37.360 --> 01:30:42.080]   And I've got an image up here to show to show this comes from the Department of Energy.
[01:30:42.080 --> 01:30:45.360]   The second generation, which was the first kind of commercial power reactor started to
[01:30:45.360 --> 01:30:48.080]   get built out in the 1960s, 70s, 80s.
[01:30:48.080 --> 01:30:52.480]   And then these Gen three reactors were these lighter weight reactors that were kind of
[01:30:52.480 --> 01:30:53.200]   more advanced.
[01:30:53.920 --> 01:30:58.400]   Gen four is the next generation of nuclear power reactors.
[01:30:58.400 --> 01:31:02.320]   And they're next generation because they're meant to be much more safe, where they cannot
[01:31:02.320 --> 01:31:03.840]   theoretically have a meltdown.
[01:31:03.840 --> 01:31:09.040]   You can't have a nuclear meltdown like you had with Fukushima or with Three Mile Island.
[01:31:09.040 --> 01:31:11.440]   And to be clear, Fukushima was generation two.
[01:31:11.440 --> 01:31:13.120]   Those are the boiling water reactors.
[01:31:13.120 --> 01:31:13.620]   Yeah.
[01:31:13.620 --> 01:31:14.240]   Yeah.
[01:31:14.240 --> 01:31:21.920]   And so these old reactors have this risk where you pump water in to cool down the reactor
[01:31:21.920 --> 01:31:23.520]   and to drive the turbine.
[01:31:23.520 --> 01:31:29.440]   And if the water pumping system fails, and you can't get the rods out of the reactor,
[01:31:29.440 --> 01:31:35.280]   then the reactor keeps reacting, the uranium keeps having this kind of chain reaction gets
[01:31:35.280 --> 01:31:39.760]   hotter and hotter and eventually gets so hot, it melts all the walls and all the surrounding
[01:31:39.760 --> 01:31:41.280]   materials of the reactor.
[01:31:41.280 --> 01:31:46.400]   And all of the nuclear rods start to evaporate and all this nuclear material is released
[01:31:46.400 --> 01:31:47.440]   into the environment.
[01:31:47.440 --> 01:31:48.800]   That's the risk of a meltdown.
[01:31:48.800 --> 01:31:50.880]   Ultimately, this is not a nuclear bomb.
[01:31:50.880 --> 01:31:54.560]   Just to be clear, it's just about really high temperatures melting the facility, and then
[01:31:54.560 --> 01:31:56.960]   radioactive material escapes the facility.
[01:31:56.960 --> 01:32:00.720]   The Gen Four reactors are designed where that isn't possible.
[01:32:00.720 --> 01:32:04.560]   And so one of the first, if you go to this next slide, you'll see just kind of an image
[01:32:04.560 --> 01:32:04.800]   here.
[01:32:04.800 --> 01:32:07.840]   This is the new reactor called the Pebble Bed Reactor.
[01:32:07.840 --> 01:32:09.440]   China started this facility.
[01:32:09.440 --> 01:32:12.720]   I don't want to butcher the name, but I think I will.
[01:32:12.720 --> 01:32:16.160]   It's at the Shiedawan site in Shandong province.
[01:32:16.160 --> 01:32:20.480]   It's a 210 megawatt electricity production reactor.
[01:32:20.480 --> 01:32:22.640]   They started construction in 2012.
[01:32:22.640 --> 01:32:27.280]   They finished and started doing operational tests in December of '22.
[01:32:27.280 --> 01:32:32.240]   They ran all the safety tests in the summer of '23, where they turned off the cooling
[01:32:32.240 --> 01:32:37.200]   and basically simulated that the system failed to see if it would melt down.
[01:32:37.200 --> 01:32:40.960]   And that's the results that they just published, which was the test they ran last summer.
[01:32:40.960 --> 01:32:43.600]   And even when they turned everything off, the system did not fail.
[01:32:43.600 --> 01:32:45.120]   It did not have a meltdown.
[01:32:45.120 --> 01:32:50.000]   It maintained its ability to control its temperature and not have a meltdown.
[01:32:50.000 --> 01:32:53.920]   And the way it works, as you can see here, is that these little pebbles, they're kind
[01:32:53.920 --> 01:32:56.880]   of like billiard ball-sized pebbles, have uranium in their core.
[01:32:56.880 --> 01:33:00.880]   These pebbles kind of drop into the center reactor chamber.
[01:33:00.880 --> 01:33:05.440]   And when the uranium is close to other uranium, a chain reaction starts to generate heat.
[01:33:05.440 --> 01:33:11.920]   That heat is actually, in this reactor concept, captured by helium gas that's circulated
[01:33:11.920 --> 01:33:13.440]   inside around the reactor.
[01:33:13.440 --> 01:33:17.760]   That hot helium gas heats up water, turns a turbine, generates electricity.
[01:33:17.760 --> 01:33:19.760]   And then these billiard balls fall out the bottom.
[01:33:19.760 --> 01:33:24.320]   So what they did is they simulated that the system stopped circling, that the power went
[01:33:24.320 --> 01:33:25.680]   out, and measured what happened.
[01:33:25.680 --> 01:33:27.840]   Ultimately, it was able to recover.
[01:33:27.840 --> 01:33:29.040]   It didn't melt down.
[01:33:29.040 --> 01:33:33.280]   And this is quite different, Nick, if you show an old model of an old nuclear rod system.
[01:33:33.280 --> 01:33:34.400]   So here's nuclear rods.
[01:33:34.400 --> 01:33:35.840]   They're made of uranium.
[01:33:35.840 --> 01:33:38.640]   They go inside these chambers that have other uranium.
[01:33:38.640 --> 01:33:41.120]   And when they touch each other or get close to each other, they heat up.
[01:33:41.120 --> 01:33:46.080]   And you have water that has to be pumped continuously to keep it cool to maintain a low
[01:33:46.080 --> 01:33:46.960]   temperature.
[01:33:46.960 --> 01:33:51.280]   What happened in Fukushima and other facilities where we've had meltdowns is that the water
[01:33:51.280 --> 01:33:52.160]   stopped pumping.
[01:33:52.160 --> 01:33:54.800]   Everything kind of evaporated away.
[01:33:54.800 --> 01:33:56.000]   And the rods didn't get pulled.
[01:33:56.000 --> 01:33:59.920]   If the rods can't get pulled out and the water can't keep pumping, you have a meltdown.
[01:33:59.920 --> 01:34:03.600]   When things get so hot, it melts everything around it and collapses.
[01:34:03.600 --> 01:34:09.040]   So this Chinese site just demonstrated this pebble bed reactor, which is a Gen 4 reactor.
[01:34:09.040 --> 01:34:12.880]   And it has extraordinary safety profile.
[01:34:12.880 --> 01:34:18.720]   There's basically no condition where the system would have a meltdown.
[01:34:18.720 --> 01:34:20.640]   So these Gen 4 reactors are smaller.
[01:34:20.640 --> 01:34:21.840]   They're more modular.
[01:34:21.840 --> 01:34:22.960]   They're much, much safer.
[01:34:22.960 --> 01:34:23.920]   They're more efficient.
[01:34:23.920 --> 01:34:25.440]   They have much less waste.
[01:34:25.440 --> 01:34:28.240]   You still have to store those used billiards somewhere.
[01:34:28.240 --> 01:34:31.760]   So you still have to kind of take them and put them somewhere and keep them underground
[01:34:31.760 --> 01:34:33.200]   for 10,000 years.
[01:34:33.200 --> 01:34:39.280]   But compared with previous reactors, this plant is designed to be much more efficient,
[01:34:39.280 --> 01:34:40.480]   much safer.
[01:34:40.480 --> 01:34:41.680]   And they completed the safety test.
[01:34:41.680 --> 01:34:43.360]   They published the results on the safety test.
[01:34:43.360 --> 01:34:46.880]   And I think it really shows the performance is there.
[01:34:46.880 --> 01:34:50.560]   And this was always meant to be future technology, these Gen 4 reactors.
[01:34:50.560 --> 01:34:54.480]   China opened up commercial operations of this reactor in December of 2023.
[01:34:54.480 --> 01:34:56.160]   So it's running, producing power.
[01:34:56.160 --> 01:34:56.800]   It's on the grid.
[01:34:56.800 --> 01:35:02.000]   And, you know, this design, funny enough, was first proposed in the 1940s.
[01:35:02.000 --> 01:35:07.200]   And it took us nearly 100 years to get it to market, which makes me also point out why
[01:35:07.200 --> 01:35:10.640]   I'm so optimistic 100 years from now on fusion technology, which seemed crazy.
[01:35:10.640 --> 01:35:14.240]   But today, and this this sort of technology seemed crazy at the time.
[01:35:14.240 --> 01:35:16.240]   But, you know, 80 years later, we've gotten there.
[01:35:16.240 --> 01:35:18.480]   So, you know, this was an exciting outcome.
[01:35:18.480 --> 01:35:23.680]   But I really do want to highlight the competitiveness with China, lower cost to produce,
[01:35:23.680 --> 01:35:27.200]   lower cost to run, and they're expanding like crazy.
[01:35:27.200 --> 01:35:30.880]   And the downstream is they can power more H100s.
[01:35:30.880 --> 01:35:34.480]   And this is why I asked Donald Trump when he came on the show.
[01:35:34.480 --> 01:35:36.160]   And I want to make my passionate plea.
[01:35:36.160 --> 01:35:41.120]   This is why investing in and deregulating nuclear reactor technology in the United States
[01:35:41.120 --> 01:35:44.800]   to enable a competitive playing field with the United States and China in the decades
[01:35:44.800 --> 01:35:45.840]   ahead is so critical.
[01:35:45.840 --> 01:35:49.040]   Because if we don't, China will beat the United States industrially.
[01:35:49.040 --> 01:35:52.960]   And we will eventually find ourselves in a greater point of conflict with respect to
[01:35:52.960 --> 01:35:58.240]   this rising power that is going to be driven by low cost, highly abundant power.
[01:35:58.240 --> 01:35:59.920]   And the United States does not have that.
[01:35:59.920 --> 01:36:01.520]   Power equals AI.
[01:36:01.520 --> 01:36:08.640]   You don't think that distributed energy can basically deliver effectively energy at a
[01:36:08.640 --> 01:36:09.840]   marginal cost of zero?
[01:36:09.840 --> 01:36:16.800]   Yeah, so the solar buildout, Shamak, is in the US forecast where we could get in an optimistic
[01:36:16.800 --> 01:36:20.720]   scenario, a doubling of power output from one terawatt to two.
[01:36:20.720 --> 01:36:23.440]   That's in the system today in the forecast.
[01:36:23.440 --> 01:36:25.040]   But how do we get to nine?
[01:36:25.040 --> 01:36:27.040]   That's where China is going to be at by 2050.
[01:36:27.680 --> 01:36:33.280]   And we have to have this ability to more rapidly kind of accelerate, you know, high power output
[01:36:33.280 --> 01:36:38.000]   systems like nuclear, because while solar is great, it's a low power output, you need,
[01:36:38.000 --> 01:36:39.120]   you know, much more volume.
[01:36:39.120 --> 01:36:41.040]   So this is a highly concentrated system.
[01:36:41.040 --> 01:36:45.520]   And the cost per megawatt hour, you know, can be significantly competitive if you use
[01:36:45.520 --> 01:36:47.760]   these small modular reactors and accelerate.
[01:36:47.760 --> 01:36:51.520]   What about carbon based solutions as a fallback?
[01:36:51.520 --> 01:36:53.520]   Difficult to scale.
[01:36:53.520 --> 01:36:57.440]   I mean, we're not going to open up 500 more coal power plants in the next couple of years.
[01:36:57.440 --> 01:36:58.800]   What about oil and nat gas?
[01:36:58.800 --> 01:37:05.280]   Yeah, so today, nat gas is 44% of US power production capacity.
[01:37:05.280 --> 01:37:09.360]   And we are going to build out and we are building out new nat gas facilities, but that's in
[01:37:09.360 --> 01:37:10.160]   the forecast.
[01:37:10.160 --> 01:37:15.360]   So all of our forecasts today for the US are mostly nat gas going out and a lot of solar
[01:37:15.360 --> 01:37:19.200]   and wind going out to 2050 to double our capacity.
[01:37:19.200 --> 01:37:21.920]   And it's already a stretch for us to be able to double our capacity.
[01:37:21.920 --> 01:37:24.880]   So the only solution is to rewrite the regulation.
[01:37:25.440 --> 01:37:29.120]   We have to get nuclear going in the United States.
[01:37:29.120 --> 01:37:31.200]   And these systems are safe.
[01:37:31.200 --> 01:37:32.480]   They are scalable.
[01:37:32.480 --> 01:37:36.480]   And if the United States embrace this, and we took a public policy perspective that this
[01:37:36.480 --> 01:37:38.240]   is about competitiveness with China.
[01:37:38.240 --> 01:37:39.840]   It's about national security.
[01:37:39.840 --> 01:37:44.560]   I'm hopeful that whoever comes in to lead the executive branch in this next administration
[01:37:44.560 --> 01:37:46.560]   will be really thoughtful and make this a top priority.
[01:37:46.560 --> 01:37:48.640]   So that's my plea and my reason for going through this today.
[01:37:48.640 --> 01:37:50.240]   Yeah, I agree.
[01:37:51.040 --> 01:37:57.520]   Yeah, this has been another amazing episode of the all in podcast for what have we learned,
[01:37:57.520 --> 01:37:59.520]   Jason, it's important to have a job.
[01:37:59.520 --> 01:38:01.520]   Otherwise, everything just goes to pot.
[01:38:01.520 --> 01:38:02.640]   Yeah, do not retire.
[01:38:02.640 --> 01:38:08.080]   Keep your mind sharp and shout out to our friend Phil Helmuth doing really great at
[01:38:08.080 --> 01:38:09.440]   the World Series of Poker.
[01:38:09.440 --> 01:38:10.880]   Happy birthday Xander.
[01:38:10.880 --> 01:38:13.760]   Happy birthday to our guy Xander, yada yada.
[01:38:13.760 --> 01:38:19.920]   And for the German dictator, the Sultan of science and your rain man architect.
[01:38:19.920 --> 01:38:21.760]   Yeah, David Sachs.
[01:38:21.760 --> 01:38:24.320]   I am the world's most moderate moderator.
[01:38:24.320 --> 01:38:25.280]   We'll see you all next time.
[01:38:25.360 --> 01:38:28.560]   I will let your winners ride.
[01:38:28.560 --> 01:38:31.440]   Rain Man, David Sachs.
[01:38:31.440 --> 01:38:38.560]   And instead, we open source it to the fans and they've just gone crazy with it.
[01:38:38.560 --> 01:38:40.480]   Love you, queen of Kinhwa.
[01:38:40.480 --> 01:38:48.480]   Besties are gone.
[01:38:48.480 --> 01:38:52.160]   That is my dog taking a notice in your driveway.
[01:38:53.120 --> 01:38:55.760]   Oh, man.
[01:38:55.760 --> 01:39:01.120]   We should all just get a room and just have one big huge orgy because they're all just
[01:39:01.120 --> 01:39:01.680]   useless.
[01:39:01.680 --> 01:39:04.560]   It's like this, like sexual tension that they just need to release somehow.
[01:39:04.560 --> 01:39:12.560]   What the beep beep, what the beep beep, we need to get merch.
[01:39:12.560 --> 01:39:14.160]   I'm going all in.
[01:39:20.560 --> 01:39:22.560]   I'm going all in
[01:39:22.560 --> 01:39:24.620]   you

