
[00:00:00.000 --> 00:00:02.680]   Welcome back to the all in podcast, everybody. I'm your
[00:00:02.680 --> 00:00:05.000]   host, Jason Calacanis, I'll put in a bunch of plugs for the
[00:00:05.000 --> 00:00:07.640]   projects I'm working on throughout the show to annoy my
[00:00:07.640 --> 00:00:12.360]   co hosts, and continue the grift, but it is 2025. And we
[00:00:12.360 --> 00:00:16.040]   are doing our best the awards. It's going to be amazing today.
[00:00:16.040 --> 00:00:18.720]   We've got so much to do today with us again for the second
[00:00:18.720 --> 00:00:23.360]   time, a truly amazing bestie Gavin Baker from a treatise
[00:00:23.360 --> 00:00:25.840]   capital. Am I correct? Is it a treatise capital?
[00:00:27.280 --> 00:00:31.520]   treatise management. Oh, a treatise management. Okay. And
[00:00:31.520 --> 00:00:34.920]   just call it House of Treaties. Oh, no, that's not gonna be
[00:00:34.920 --> 00:00:35.680]   trouble. IP.
[00:00:35.680 --> 00:00:40.240]   Gavin, welcome back to the program. Let us know. Just
[00:00:40.240 --> 00:00:42.040]   briefly, what is a treatise do?
[00:00:42.040 --> 00:00:47.600]   Thanks for having me here. Jason Chama. And Dave, a treatise
[00:00:47.600 --> 00:00:51.140]   where we're crossover firm, we invest publicly and privately in
[00:00:51.140 --> 00:00:54.600]   consumer intact. And we go from series A to make a cap.
[00:00:55.520 --> 00:00:59.280]   Got it. Okay, so you are capital allocate your place bets on
[00:00:59.280 --> 00:01:02.840]   technology on the most important new companies in the world. We'll
[00:01:02.840 --> 00:01:06.000]   get into that. And this is our prediction show that we did our
[00:01:06.000 --> 00:01:08.320]   bestie awards. How big is your firm, Gavin?
[00:01:08.320 --> 00:01:11.920]   Well, you just met the guy free, but you don't just ask him how
[00:01:11.920 --> 00:01:12.800]   big his firm is.
[00:01:12.800 --> 00:01:15.240]   Audience wants to know is this guy a player? Like, what's the
[00:01:15.240 --> 00:01:17.440]   deal? You know, roughly $4 billion.
[00:01:17.440 --> 00:01:21.920]   Okay. All right. So that's about a half an inch bigger than
[00:01:21.920 --> 00:01:26.320]   Shamoff. He's really worried now. Not that he's a size queen
[00:01:26.320 --> 00:01:26.820]   or anything.
[00:01:26.820 --> 00:01:46.960]   We're going to do a really great prediction show today. And we're
[00:01:46.960 --> 00:01:49.120]   going to do some super predictions this year, each
[00:01:49.120 --> 00:01:51.620]   bestie gets to make a super prediction or two during the
[00:01:51.620 --> 00:01:55.440]   show. And we're going to take those super predictions to mouth
[00:01:55.440 --> 00:01:59.080]   and we're going to put them on Polly market. Yes, that's right.
[00:01:59.080 --> 00:02:02.000]   If you don't know, Polly market is a prediction market where
[00:02:02.000 --> 00:02:07.240]   people can place a wager a bet an investment in one or the
[00:02:07.240 --> 00:02:08.840]   other side. And there's
[00:02:08.840 --> 00:02:10.960]   my image good. It feels like it's blurry.
[00:02:10.960 --> 00:02:15.380]   It's a little blurry. That's the avalanche coming. And so I guess
[00:02:15.380 --> 00:02:18.280]   is that the MAGA avalanche? What is this avalanche? Is that
[00:02:18.280 --> 00:02:20.200]   people streaming across the border? What's the metaphor
[00:02:20.200 --> 00:02:25.100]   here? trim up? Is that the huge orgasm that you're about to lay
[00:02:25.100 --> 00:02:26.920]   down in 2025?
[00:02:26.920 --> 00:02:29.980]   Rocking my friend? No, no, this is a shout out to my friend
[00:02:29.980 --> 00:02:33.980]   Ruben Ostlund, who's the director of a bunch of really
[00:02:33.980 --> 00:02:37.900]   amazing movies, including the one behind me force measure.
[00:02:37.900 --> 00:02:41.540]   There you go. All right. We did an amazing partnership with
[00:02:41.540 --> 00:02:43.900]   Polly market. Freeberg, you want to detail the partnership in
[00:02:43.900 --> 00:02:45.300]   some way you I think you help work on it.
[00:02:45.300 --> 00:02:48.300]   Well, we obviously have talked to Shane at Polly market for
[00:02:48.300 --> 00:02:52.000]   some time, and we set up a deal with them where we could put our
[00:02:52.000 --> 00:02:55.320]   own markets up on the on the site. So we're going to talk
[00:02:55.320 --> 00:02:57.900]   about a couple of our predictions this year. And then
[00:02:57.900 --> 00:03:01.740]   Polly market will post them up on on their site and people can
[00:03:01.740 --> 00:03:06.100]   can trade them obviously x us and we're really excited about
[00:03:06.100 --> 00:03:08.340]   it because it'll allow us to kind of track how we're doing
[00:03:08.340 --> 00:03:11.460]   and give us the opportunity on an ongoing basis to create
[00:03:11.460 --> 00:03:13.900]   markets. So there'll be an all in section on Polly market where
[00:03:13.900 --> 00:03:15.660]   you can kind of go in and see the all in market. It's gonna be
[00:03:15.660 --> 00:03:16.180]   really cool.
[00:03:16.740 --> 00:03:22.060]   Awesome fan tastic. And so we just got we're all wrapping up
[00:03:22.060 --> 00:03:25.020]   our ski trip here. Nick, I understand there was some
[00:03:25.020 --> 00:03:29.380]   footage some found footage from the bestie skiing. Is that true?
[00:03:29.380 --> 00:03:33.180]   Oh, here we go. Look at this. Here I come down the mountain.
[00:03:33.180 --> 00:03:36.180]   Gavin, I want you to rate everybody skiing here. I come
[00:03:36.180 --> 00:03:40.820]   looking great. There comes off looking good. And then here
[00:03:40.820 --> 00:03:45.100]   comes somebody. I think the technical term Joe Lonsdale does
[00:03:45.100 --> 00:03:50.100]   for that third person is a beep beep. Okay, here we go. Look at
[00:03:50.100 --> 00:03:54.400]   this technique coming down. Look at Shamar. Chamath you really
[00:03:54.400 --> 00:03:57.020]   advances last season. Look at him cutting those s turns.
[00:03:57.020 --> 00:03:57.860]   Gavin, what do you think?
[00:03:57.860 --> 00:04:04.140]   Listen to me, I, I made a very strategic decision to stop
[00:04:04.140 --> 00:04:07.700]   snowboarding so I could learn to ski with my kids. It is so hard
[00:04:07.700 --> 00:04:10.460]   to learn how to do something in your 40s. No, I mean, if you've
[00:04:10.460 --> 00:04:12.420]   never done it, but I do appreciate what you and your
[00:04:12.420 --> 00:04:14.820]   brother did for me last season. I learned a couple things. So
[00:04:14.860 --> 00:04:17.780]   it's been Yeah, my throat there with the black bomber. My third
[00:04:17.780 --> 00:04:18.540]   season was great.
[00:04:18.540 --> 00:04:22.460]   I am absolutely amazed at the progress you're making free
[00:04:22.460 --> 00:04:25.300]   bird. I'm amazed you made it onto the mountain you you were
[00:04:25.300 --> 00:04:27.540]   out there a number of days you're getting it done.
[00:04:27.540 --> 00:04:32.500]   I needed new boots and I tore my MCL last season. So I'm in it
[00:04:32.500 --> 00:04:34.540]   got really tweak when I went out there, but I'm good. It was
[00:04:34.540 --> 00:04:36.860]   great. I had a lot of fun. I mean, I think I haven't had four
[00:04:36.860 --> 00:04:37.500]   days. Yeah,
[00:04:37.500 --> 00:04:40.700]   you ski for days. Okay, I finished my 16th day yesterday,
[00:04:40.700 --> 00:04:43.500]   but I took today off just to get prepared here. Yeah, I got 16. I
[00:04:43.500 --> 00:04:45.780]   do the executive program, Gavin, I go out for an hour and a half
[00:04:45.780 --> 00:04:49.100]   to three hours, zip, zip, zip 10 runs, and I'm done. I only ski
[00:04:49.100 --> 00:04:53.380]   in the morning. Yeah, that's the way to do the same. And, and at
[00:04:53.380 --> 00:04:57.340]   1215. Have lunch, relax, get a little work done. You need a
[00:04:57.340 --> 00:04:59.540]   healthy, healthy mix of operate ski and ski.
[00:04:59.540 --> 00:05:03.220]   Gavin, how would you compare yourself to what you just
[00:05:03.220 --> 00:05:06.300]   witnessed in that video? Your skiing ability? Where would you
[00:05:06.300 --> 00:05:08.940]   rank yourself? Clearly, it's me chamath freeberg in that
[00:05:08.940 --> 00:05:10.980]   ranking. Where would you live in the ranking?
[00:05:12.380 --> 00:05:15.420]   Well, I would say I make two observations. First, like I'm in
[00:05:15.420 --> 00:05:18.780]   the bottom percentile in terms of natural athleticism. Okay, I
[00:05:18.780 --> 00:05:23.620]   do have many, many 1000s of hours skiing. Great. Okay, and I
[00:05:23.620 --> 00:05:27.340]   would just leave I would just leave it at that. Yeah. Well,
[00:05:27.340 --> 00:05:31.140]   then we'll be going out with you next year. New bestie. All
[00:05:31.140 --> 00:05:35.060]   right. We got to get to it. We're to start off with politics.
[00:05:35.060 --> 00:05:37.140]   Gentlemen, we got to keep this moving because there's so many
[00:05:37.140 --> 00:05:41.220]   predictions. We're gonna do our 2025 prediction for biggest
[00:05:41.220 --> 00:05:44.540]   political winner. Now last year. Well, yeah, I think we got it
[00:05:44.540 --> 00:05:47.740]   kind of wrong. freeberg. You said independent third party in
[00:05:47.740 --> 00:05:51.460]   the US. And we did see some of that with, you know, the
[00:05:51.460 --> 00:05:55.820]   breakout of Robert Kennedy, maybe. Chamath, you said
[00:05:55.820 --> 00:05:58.500]   independent centrists. We didn't get there with that one. And I
[00:05:58.500 --> 00:06:00.980]   said dark horse presidential candidates. Maybe I get a
[00:06:00.980 --> 00:06:02.260]   quarter point credit there with
[00:06:02.260 --> 00:06:04.620]   wait, hold on. What do you mean? We didn't get their independent
[00:06:04.620 --> 00:06:06.340]   centrists won the election for Megan.
[00:06:06.340 --> 00:06:09.220]   Independent centers won the election. Really? That's what
[00:06:09.220 --> 00:06:12.700]   you believe? Yeah. Okay. I didn't think that it was the
[00:06:12.700 --> 00:06:15.220]   independence. But okay. I think independent centrist swung the
[00:06:15.220 --> 00:06:20.300]   election for Biden in 2020. And then I think they swung the
[00:06:20.300 --> 00:06:24.100]   election for Trump in 2024. Huh? Is that statistically correct?
[00:06:24.100 --> 00:06:27.020]   You think freebird? Do you buy that independent centrist did
[00:06:27.020 --> 00:06:29.140]   the election or Gavin? What do you think?
[00:06:29.140 --> 00:06:32.780]   I think it's right. Like I think a lot of there are a lot of
[00:06:32.780 --> 00:06:35.380]   people not just centrist, but a lot of people who had been
[00:06:35.900 --> 00:06:41.260]   lifelong democratic voters who voted for Trump. So I do think
[00:06:41.260 --> 00:06:44.580]   Trump won the centrist. Trump Trump won everything.
[00:06:44.580 --> 00:06:48.940]   Essentially, yeah. Okay. Chamath, who's your prediction
[00:06:48.940 --> 00:06:50.580]   for the biggest political winner of 2025?
[00:06:50.580 --> 00:06:57.260]   My biggest political winner for 2025 are fiscal conservatives. I
[00:06:57.260 --> 00:07:03.580]   think that we are going to test a very important concept in 2025.
[00:07:04.300 --> 00:07:08.500]   And I hope it works, which is that of austerity. And the
[00:07:08.500 --> 00:07:11.860]   reason why austerity has to work is that the only thing left
[00:07:11.860 --> 00:07:16.300]   after austerity is to cut entitlements. And I think that
[00:07:16.300 --> 00:07:20.580]   in doing this, we're going to figure out how much waste fraud
[00:07:20.580 --> 00:07:25.180]   and abuse exists in the United States federal government. I
[00:07:25.180 --> 00:07:28.540]   think that that's going to spill over to a lot of state
[00:07:28.540 --> 00:07:32.940]   elections. And I think that the fiscal conservatives that have
[00:07:32.940 --> 00:07:38.100]   been clamoring for a more restrained approach to spending
[00:07:38.100 --> 00:07:40.260]   will have their day in 2025.
[00:07:40.260 --> 00:07:43.820]   Okay, fiscal conservatives from Chamath Freeburg, your
[00:07:43.820 --> 00:07:46.700]   prediction for the biggest political winner of 2025.
[00:07:46.700 --> 00:07:50.860]   I also took a class based approach, I chose young
[00:07:50.860 --> 00:07:56.180]   candidates. So Trump's cabinet picks have an average age of 40
[00:07:56.180 --> 00:08:00.020]   to 45 years old, compared to the Biden cabinet where the average
[00:08:00.020 --> 00:08:04.100]   age is a little over 59, almost 60 years old. And I do think
[00:08:04.100 --> 00:08:08.460]   that this marks the beginning of a new trend in the kind of age
[00:08:08.460 --> 00:08:12.620]   range of political candidates shifting younger. So I think
[00:08:12.620 --> 00:08:15.020]   that this is something we should expect as candidates start to
[00:08:15.020 --> 00:08:19.220]   emerge for the midterms by the end of 2025. We'll start to see
[00:08:19.220 --> 00:08:22.860]   younger new names start to pop up that deliver resonant
[00:08:22.860 --> 00:08:26.540]   messages and aren't part of kind of the old guard of, you know,
[00:08:26.540 --> 00:08:29.740]   the aging political class. So I think that's a trend that's kind
[00:08:29.740 --> 00:08:30.580]   of underway now.
[00:08:30.580 --> 00:08:33.300]   Excellent young candidates, we got fiscal conservatives, young
[00:08:33.300 --> 00:08:36.140]   candidates, Gavin, what do you got for the 2025 prediction for
[00:08:36.140 --> 00:08:36.940]   biggest political winner?
[00:08:36.940 --> 00:08:39.180]   I would say Trump and centrism
[00:08:39.180 --> 00:08:43.260]   or my choice for 2025 is biggest political winner. I went with
[00:08:43.260 --> 00:08:46.780]   something similar to you, Friedberg, I said Gen X and the
[00:08:46.780 --> 00:08:50.660]   elder millennials, if you look at the notable Gen X
[00:08:50.660 --> 00:08:54.180]   appointments, you got Elon with Doge, you got sacks, obviously
[00:08:54.180 --> 00:08:57.620]   Marco Rubio, my god, it just goes down. Then if you look at
[00:08:57.620 --> 00:09:02.100]   the elder millennials, JD Vance, Vivek, Tulsi, just a lot of
[00:09:02.100 --> 00:09:05.220]   young people. And this is going to be absolutely fantastic, I
[00:09:05.220 --> 00:09:08.020]   think, because they're going to start thinking not just about
[00:09:08.020 --> 00:09:12.140]   themselves, as the boomers are doing with Social Security taxes,
[00:09:12.140 --> 00:09:15.180]   real estate, all the different issues that they tend to pick
[00:09:15.180 --> 00:09:17.660]   for themselves, they're going to start thinking about maybe their
[00:09:17.660 --> 00:09:20.860]   own kids and themselves. So yeah, it's obviously a sea
[00:09:20.860 --> 00:09:24.340]   changes underway. So there you have it, folks, for our
[00:09:24.340 --> 00:09:26.900]   predictions for political winner. Let's go with political
[00:09:26.900 --> 00:09:29.500]   loser here prediction for political loser. We'll start
[00:09:29.500 --> 00:09:32.180]   off with you, Gavin, we'll do this a little round robin here,
[00:09:32.180 --> 00:09:34.100]   we'll snake it around. Gavin, what do you think will be the
[00:09:34.100 --> 00:09:36.860]   biggest political loser of 2025?
[00:09:36.860 --> 00:09:44.220]   I think Putin, I think Putin is going to lose bigly. So if you
[00:09:44.220 --> 00:09:47.740]   are Xi Jinping, you know, Xi Jinping, Russia is a client
[00:09:47.740 --> 00:09:52.860]   state of China at this point. And if you're Xi Jinping, what
[00:09:52.860 --> 00:09:55.780]   is happening is now a disaster for you, because Europe is
[00:09:55.780 --> 00:09:59.100]   starting to rearm, and which is which will only accelerate this
[00:09:59.100 --> 00:10:04.020]   year. That will allow America to take resources out of Europe,
[00:10:04.020 --> 00:10:08.780]   and put them in Japan and South Korea, and all over the
[00:10:08.780 --> 00:10:12.660]   Pacific. And that makes it a lot harder for you to do what you
[00:10:12.660 --> 00:10:18.020]   most want to do, which is reunify China and Taiwan or
[00:10:18.020 --> 00:10:22.980]   invade Taiwan. Let's call it what it is. And I just think Xi
[00:10:23.060 --> 00:10:27.180]   is going to begin decoupling from Putin. If you're Trump, you
[00:10:27.180 --> 00:10:31.380]   want to show that you're independent, that you're not
[00:10:31.380 --> 00:10:35.260]   enthralled to Putin in any way. So I think Trump is going to be
[00:10:35.260 --> 00:10:41.020]   a lot tougher on Putin than people think. And I think he's
[00:10:41.020 --> 00:10:45.940]   going to get a very, very, a deal that's very, very bad for
[00:10:45.940 --> 00:10:48.740]   Russia and Ukraine. And you know, you've lost half a million
[00:10:48.740 --> 00:10:50.740]   people. And for what?
[00:10:51.460 --> 00:10:56.260]   For what exactly? And it's 1000 over 1000 days into this. No
[00:10:56.260 --> 00:10:59.980]   buddy from the West hat, you know, in the NATO, or America,
[00:10:59.980 --> 00:11:03.340]   no, no soldiers have lost their lives from our side. We've just
[00:11:03.340 --> 00:11:06.020]   given them weapons. And so it's a humiliating defeat so far for
[00:11:06.020 --> 00:11:08.580]   Putin. I agree with you, Freiburg, your prediction for
[00:11:08.580 --> 00:11:12.580]   the biggest political loser of 2025. Freiburg's prediction, I'm
[00:11:12.580 --> 00:11:17.900]   going to predict the pro war neocons who are going to go head
[00:11:17.900 --> 00:11:22.460]   to head with the JD Vance and Elon's and others of the world.
[00:11:22.460 --> 00:11:24.940]   And I think that they're going to lose. And I think that there's
[00:11:24.940 --> 00:11:28.100]   going to be this kind of big crack in the establishment of
[00:11:28.100 --> 00:11:32.620]   this, this neocon movement that's been very pro conflict
[00:11:32.620 --> 00:11:35.460]   around the world. And we've heard it in the speeches and in
[00:11:35.460 --> 00:11:38.260]   the commentary from JD and others. And I think this is
[00:11:38.260 --> 00:11:40.220]   going to be the year it's all going to kind of come to a head.
[00:11:40.220 --> 00:11:42.180]   I think they're gonna end up on the losing side.
[00:11:42.180 --> 00:11:47.100]   Can I can't take the other side just just a little bit. So that's
[00:11:47.100 --> 00:11:51.300]   why I'm here. Yeah, I think it's right in reality. But I think
[00:11:51.300 --> 00:11:53.500]   you know, Trump said something very interesting about john
[00:11:53.500 --> 00:11:57.340]   Bolton. He said, the guy was absolutely crazy. But it was
[00:11:57.340 --> 00:11:59.940]   awesome having him in the room when you're negotiating deals,
[00:11:59.940 --> 00:12:02.820]   right? As people looked at this guy looking angry, red in the
[00:12:02.820 --> 00:12:06.180]   face, so excited to hit the nuclear button so excited to go
[00:12:06.180 --> 00:12:09.860]   to war, ended up with much better deals, right? So I think
[00:12:09.860 --> 00:12:13.540]   you're gonna see probably a lot more bellicosity from the Trump
[00:12:13.540 --> 00:12:16.460]   administration than anyone expects. And that's just to get
[00:12:16.460 --> 00:12:20.500]   a good deal for, you know, between Russia and Ukraine. And
[00:12:20.500 --> 00:12:24.020]   then it's to get China to kind of decouple from Russia. So I
[00:12:24.020 --> 00:12:27.020]   think the in reality, I think you're right, David, but I think
[00:12:27.020 --> 00:12:30.660]   there will be a lot of rhetoric that is at odds with what you're
[00:12:30.660 --> 00:12:32.500]   saying before you end up being wrecked.
[00:12:32.500 --> 00:12:37.260]   We already see it with Canada with NATO with Taiwan, there's a
[00:12:37.260 --> 00:12:40.460]   lot, you know, we're gonna do this or this, the tariffs,
[00:12:40.460 --> 00:12:43.820]   obviously, there's just a lot of very aggressive posturing
[00:12:43.820 --> 00:12:46.180]   leading up to the negotiations that are hopefully going to get
[00:12:46.180 --> 00:12:48.580]   the US good deals. We'll see.
[00:12:48.580 --> 00:12:52.060]   Shamath, you have a prediction for your 2025 biggest political
[00:12:52.060 --> 00:12:53.580]   loser prediction. It's hard to do.
[00:12:53.580 --> 00:12:58.620]   The biggest political loser of 2025 is going to be
[00:12:58.620 --> 00:13:02.940]   progressivism. So November of last year, right after the
[00:13:02.940 --> 00:13:07.020]   election, I flew to London and went up to Oxford and I spoke at
[00:13:07.020 --> 00:13:12.420]   the Oxford Union. And my speech was a full throated defense of
[00:13:12.420 --> 00:13:18.940]   manga. But it was mostly an explanation of manga. And it was
[00:13:18.940 --> 00:13:26.060]   sort of the antidote to progressive instincts that had
[00:13:26.060 --> 00:13:30.020]   been riddling the Western G8 countries and was starting to
[00:13:30.020 --> 00:13:33.300]   basically come on gun. And when you look at what's about to
[00:13:33.300 --> 00:13:37.820]   happen in 2025, in Canada, Justin Trudeau is going to lose
[00:13:37.820 --> 00:13:43.620]   massively to peer poly F. In Germany, a FD looks like they
[00:13:43.620 --> 00:13:47.380]   will win. In France, if there's a deadlock, and it goes into an
[00:13:47.380 --> 00:13:50.300]   election, more than likely Marine Le Pen is going to win.
[00:13:50.300 --> 00:13:54.740]   And then in the UK, where you see this unfolding, child rape
[00:13:54.740 --> 00:13:59.260]   scandal, where allegedly upwards of hundreds of 1000s of young
[00:13:59.260 --> 00:14:02.940]   girls over the course of 20 plus years were being raped by
[00:14:02.940 --> 00:14:07.700]   organizations of Pakistani Muslim men who were then not
[00:14:07.700 --> 00:14:13.940]   prosecuted for fears of stoking Islamophobia, as it turns out,
[00:14:13.940 --> 00:14:18.780]   by the current Prime Minister Keir Starmer. And if all of that
[00:14:18.780 --> 00:14:21.980]   comes to pass in the UK, I think you're going to see the Labour
[00:14:21.980 --> 00:14:24.660]   government fall. And I think you're going to see Nigel Farage
[00:14:24.660 --> 00:14:30.100]   win. So what do all of these countries look like, by the end
[00:14:30.100 --> 00:14:35.220]   of 25? It's very much a repudiation of this class based
[00:14:35.220 --> 00:14:38.660]   identity politics. And I think that has enormous ripple
[00:14:38.660 --> 00:14:41.540]   effects all throughout the world. And so I think the
[00:14:41.540 --> 00:14:44.580]   biggest political loser for 2025, I think stands to be
[00:14:44.580 --> 00:14:47.380]   progressivism, quote, unquote, but they will be labeled
[00:14:47.380 --> 00:14:48.340]   progressivism.
[00:14:48.340 --> 00:14:53.060]   I took something very similar. I said the racist vocal minority
[00:14:53.060 --> 00:14:57.700]   of each one of these parties, and there's a little bit of this
[00:14:57.700 --> 00:15:00.980]   on either side, you have de on one side, and then you just have
[00:15:00.980 --> 00:15:04.340]   outright racism on the other side. And it's probably 5% of
[00:15:04.340 --> 00:15:07.220]   MAGA and 5% of the left. And just to recap last year's
[00:15:07.220 --> 00:15:10.700]   political predictions for 2024. Our predictions for political
[00:15:10.700 --> 00:15:14.420]   loser was I said Netanyahu, Freeberg, you said Ukraine, and
[00:15:14.420 --> 00:15:17.260]   Sharmath, you said the Koch family, the GOP.
[00:15:17.260 --> 00:15:19.260]   Nailed that one. I nailed that one.
[00:15:19.260 --> 00:15:21.180]   Freeberg, any thoughts on last year's?
[00:15:21.180 --> 00:15:25.140]   We're in the Republican side more than the Koch family, do
[00:15:25.140 --> 00:15:25.540]   you think?
[00:15:25.540 --> 00:15:28.900]   I mean, explain for the audience, who maybe aren't as
[00:15:28.900 --> 00:15:29.420]   deep into it?
[00:15:29.420 --> 00:15:33.820]   Well, I think, essentially, 2024 was the end of the
[00:15:33.820 --> 00:15:38.500]   Republican Party as we knew it. And I think what stands in its
[00:15:38.500 --> 00:15:43.060]   place is what I would call the MAGA reflection of a coalition
[00:15:43.060 --> 00:15:47.420]   of people that will be housed under the label of
[00:15:47.420 --> 00:15:50.700]   republicanism, which is to say that these folks aren't
[00:15:50.700 --> 00:15:54.980]   necessarily Republicans, these folks are believers of the MAGA
[00:15:54.980 --> 00:15:58.220]   philosophy, they're just using the Republican vessel in order
[00:15:58.220 --> 00:16:03.060]   to run their candidates and get elected. And in that overturning
[00:16:03.060 --> 00:16:07.660]   of the status quo, what you had was this one family who was at
[00:16:07.660 --> 00:16:12.060]   the center for the last few decades of political machinery
[00:16:12.060 --> 00:16:16.420]   that essentially decided candidates that it decided
[00:16:16.420 --> 00:16:19.500]   agenda that it decided policy. And that was the Koch family,
[00:16:19.500 --> 00:16:22.460]   and they spent an enormous amount of money to get that,
[00:16:22.460 --> 00:16:26.260]   which they stood up, frankly, that literally the day after
[00:16:26.260 --> 00:16:30.220]   Citizens United happened in the Supreme Court. And I think that
[00:16:30.300 --> 00:16:34.580]   in that lens, those billions of dollars of investment have
[00:16:34.580 --> 00:16:37.020]   essentially gone to zero, because I don't think it means
[00:16:37.020 --> 00:16:40.860]   much of anything anymore. And if you look at the new class of
[00:16:40.860 --> 00:16:45.780]   donors who will decide, quote, unquote, Republican policy, it's
[00:16:45.780 --> 00:16:48.580]   going to be the, the Miriam Adelson's of the world, the
[00:16:48.580 --> 00:16:52.220]   Elon Musk's of the world. And that's very different than how I
[00:16:52.220 --> 00:16:54.340]   think the Kochs used to decide things.
[00:16:54.340 --> 00:16:56.660]   Do you think there's too much money in politics now, Gavin?
[00:16:57.500 --> 00:17:06.180]   I think there's too much money in politics now. It's, it's a
[00:17:06.180 --> 00:17:11.660]   good question. You know, I might feel very, very differently if I
[00:17:11.660 --> 00:17:15.420]   didn't agree so profoundly with with the largest donor in this
[00:17:15.420 --> 00:17:22.020]   political cycle. Yeah. I would say the reality is, is like the
[00:17:22.020 --> 00:17:27.060]   the money, as long as the money raised on each side is roughly
[00:17:27.060 --> 00:17:31.380]   equivalent. I don't think it really matters. That would, that
[00:17:31.380 --> 00:17:34.580]   would be my take. You just want some equivalence. That's all.
[00:17:34.580 --> 00:17:38.180]   All right, let's do our 2025 predictions for biggest business
[00:17:38.180 --> 00:17:41.420]   winner. Freeberg, why don't you start us off biggest business
[00:17:41.420 --> 00:17:43.020]   winner for 2025? What's your prediction?
[00:17:43.020 --> 00:17:48.220]   So I feel like we're at a really interesting inflection point.
[00:17:48.220 --> 00:17:54.100]   That is going to make 2025 the year of autonomous hardware or
[00:17:54.100 --> 00:17:59.220]   robotics. If 2024 was the year of kind of compute build out and
[00:17:59.220 --> 00:18:03.460]   the rollout of AI systems in software, I think 2025 will be
[00:18:03.460 --> 00:18:08.060]   the year of the robot. You know, there's a company we just placed
[00:18:08.060 --> 00:18:13.660]   an order today actually, out of China called Unitree. Gavin, have
[00:18:13.660 --> 00:18:14.580]   you looked at this company?
[00:18:14.580 --> 00:18:16.940]   Yeah, it's pretty wild, actually.
[00:18:16.940 --> 00:18:21.380]   It's an incredible business, incredible product. So their GO2
[00:18:21.380 --> 00:18:26.220]   robot is $1,600 has an API, here it is, you can run a payload on
[00:18:26.220 --> 00:18:29.500]   it, it's got LiDAR on it, it's got kind of intelligence
[00:18:29.500 --> 00:18:33.540]   guidance systems on it. This is the robot system that was used on
[00:18:33.540 --> 00:18:35.660]   some of those videos we looked at earlier this year, where there
[00:18:35.660 --> 00:18:38.580]   were machine guns mounted to the back. And it was basically a new
[00:18:38.580 --> 00:18:41.900]   kind of field soldier. It's an autonomous field soldier. But
[00:18:41.900 --> 00:18:44.140]   really, you can use it in scientific applications. We're
[00:18:44.140 --> 00:18:47.420]   looking at using them in our on our on our test farms where it
[00:18:47.420 --> 00:18:50.020]   can wander the farm and take images and report data back to
[00:18:50.020 --> 00:18:53.820]   us. And it's such a low cost at like less than $3,000. You can
[00:18:53.820 --> 00:18:57.180]   do some incredible things with it. So this business just raised
[00:18:57.180 --> 00:19:00.340]   a couple hundred million dollars last month, from mostly Chinese
[00:19:00.340 --> 00:19:03.660]   investors to Chinese company. And I think that there's going to
[00:19:03.660 --> 00:19:07.340]   be, you know, other similar type businesses, you know, kind of
[00:19:07.340 --> 00:19:09.700]   takes a long time for things to work. And then all of a sudden,
[00:19:09.700 --> 00:19:12.100]   they happen faster than you could have ever imagined. I
[00:19:12.100 --> 00:19:13.540]   think this is going to be the year where we're all going to
[00:19:13.540 --> 00:19:16.660]   look at humanoid robots and autonomous systems and be like,
[00:19:16.700 --> 00:19:20.260]   Oh, my God, I can't believe this is here. So this could be the
[00:19:20.260 --> 00:19:20.500]   year.
[00:19:20.500 --> 00:19:25.100]   It's such a great strong choice for the biggest winner. And I
[00:19:25.100 --> 00:19:27.260]   think the quote you're looking for is how did you go bankrupt
[00:19:27.260 --> 00:19:29.860]   slowly, and then all at once. That's how these technology
[00:19:29.860 --> 00:19:31.620]   changes. And man, I would love to have one of these for the
[00:19:31.620 --> 00:19:34.820]   ranch to just run around and do the perimeter security.
[00:19:34.820 --> 00:19:36.820]   Sorry, Nick, pull up the you guys got to watch this. If you
[00:19:36.820 --> 00:19:39.140]   haven't seen it, Nick, find the video of the GO2 with the wheels
[00:19:39.140 --> 00:19:42.580]   on it. Managing Terrain. Oh, yeah. And everyone thought this
[00:19:42.580 --> 00:19:45.900]   was a BS video that it was like, CGI wasn't real. It was AI
[00:19:45.900 --> 00:19:50.140]   generated. But like, this thing is just incredible. Here it is.
[00:19:50.140 --> 00:19:54.580]   This is a real video of this thing. Yeah. And it could learn
[00:19:54.580 --> 00:19:57.620]   from an LLM to write like a large language model. Look at
[00:19:57.620 --> 00:20:00.220]   this. They teach it how to do something. Yeah. Gavin, is this
[00:20:00.220 --> 00:20:04.380]   real? Like, what's your real? Yeah, yeah. I want to get the G
[00:20:04.380 --> 00:20:07.460]   one, which is their humanoid robot. Yeah. So pull up the
[00:20:07.460 --> 00:20:10.860]   humanoid. It's really cool. And it's a little more expensive.
[00:20:10.860 --> 00:20:15.220]   Yeah. Yeah. I mean, $16,000 was the cost of a used Prius. Let's
[00:20:15.220 --> 00:20:18.220]   be honest, that's in spitting distance of being affordable.
[00:20:18.220 --> 00:20:22.740]   Look at this thing, 16 grand. And this thing, you can, you
[00:20:22.740 --> 00:20:25.260]   know, you can basically command it to do things for you in your
[00:20:25.260 --> 00:20:29.340]   house, or in your factory, or in your workplace.
[00:20:29.340 --> 00:20:34.420]   I knew you would do it. I was gonna say maybe we could get a
[00:20:34.420 --> 00:20:37.420]   poker dealer, maybe bow, you know, I wonder if this thing
[00:20:37.420 --> 00:20:42.060]   could deal. Do you guys remember that robot that was on stage for
[00:20:42.060 --> 00:20:46.100]   our all in holiday? Yes. One X. So my, my brother made an
[00:20:46.100 --> 00:20:49.700]   observation. He said, as soon as that robot came out, it's like
[00:20:49.700 --> 00:20:52.620]   everyone just wanted to abuse it. He's like, humans have this
[00:20:52.620 --> 00:20:56.060]   very interesting nature, where like the robot emerges, and all
[00:20:56.060 --> 00:20:58.700]   that humans want to do is like hurt the robot. It's like a
[00:20:58.700 --> 00:21:02.860]   very strange revelation of human behavior. Yeah, like it just,
[00:21:02.860 --> 00:21:04.860]   it's like, Oh, here's something I could dominate. Here's
[00:21:04.860 --> 00:21:09.260]   something I can tell it by it, we want to make sure that we're
[00:21:09.260 --> 00:21:11.660]   the top of the species here. And it doesn't feel like it's going
[00:21:11.660 --> 00:21:13.860]   to be for much longer. I mean, these things will kick our ass
[00:21:13.860 --> 00:21:14.420]   pretty soon.
[00:21:14.420 --> 00:21:17.220]   Anyway, these things are amazing. I think this is gonna
[00:21:17.220 --> 00:21:20.060]   be the year of the robot. That's my year of the robots is your
[00:21:20.060 --> 00:21:22.060]   prediction. I love it. Gavin, what do you got?
[00:21:22.060 --> 00:21:28.820]   profoundly agree. I think you're the robots inclusive of FSD. You
[00:21:28.820 --> 00:21:33.220]   know, I think FSD works today. And it's gonna, it's, it's gonna
[00:21:33.220 --> 00:21:37.740]   cross into mainstream adoption, where I already notice,
[00:21:37.740 --> 00:21:41.020]   particularly if I'm taking an Uber late at night, I really,
[00:21:41.020 --> 00:21:44.380]   really prefer to have a Tesla. Just sometimes you get an Uber
[00:21:44.380 --> 00:21:49.580]   driver who's who's tired. And I just feel a lot safer if they
[00:21:49.580 --> 00:21:53.420]   have the FSD running. And then obviously, using it for yourself
[00:21:53.420 --> 00:21:57.540]   is amazing. But I think it's going to continue compounding at
[00:21:57.540 --> 00:22:02.300]   an accelerating rate. I think the in a lot of ways, what I'd
[00:22:02.300 --> 00:22:06.700]   say broadly is, I think for a while, it's going to be big
[00:22:06.700 --> 00:22:10.060]   businesses are winners, big businesses that use AI
[00:22:10.060 --> 00:22:14.900]   thoughtfully. And the reason is, is that with what is happening,
[00:22:14.900 --> 00:22:19.620]   what what Oh, three showed us open AI's new model, the
[00:22:19.620 --> 00:22:24.060]   combination of reasoning and test time compute. Like I think
[00:22:24.060 --> 00:22:28.420]   you're if you're a big business, and you can pay $1 million to
[00:22:28.420 --> 00:22:31.580]   let an AI think for six weeks about the most important
[00:22:31.580 --> 00:22:35.980]   question for your business. That's going to be a profound
[00:22:35.980 --> 00:22:40.540]   advantage relative to small businesses that can't afford
[00:22:40.540 --> 00:22:43.940]   that. And by the way, we are the other like inference compute is
[00:22:43.940 --> 00:22:47.500]   going to be the the kind of derivative winner of that we're
[00:22:47.500 --> 00:22:53.140]   going to run out of GPUs, accelerators compute in 2025,
[00:22:53.140 --> 00:22:55.020]   the same way we did in 23.
[00:22:55.020 --> 00:23:00.260]   Okay, so you're also long Nvidia and chip makers, grok, etc.
[00:23:00.260 --> 00:23:04.140]   Because we're finding new uses for all that compute.
[00:23:04.580 --> 00:23:08.700]   Absolutely. Okay, very good. Chamath, do you have a
[00:23:08.700 --> 00:23:11.900]   prediction for your biggest business winner of 2025? Sir?
[00:23:11.900 --> 00:23:16.900]   I think the biggest business winner of 2025 are going to be
[00:23:16.900 --> 00:23:22.700]   dollar denominated stable coins. Oh, I'll make two points. In
[00:23:22.700 --> 00:23:28.540]   2024. Two critical things happened. The first is that
[00:23:29.220 --> 00:23:36.660]   stable coins essentially became uncoupled from crypto
[00:23:36.660 --> 00:23:42.300]   volatility. And it started to be used for wholesale useful
[00:23:42.300 --> 00:23:47.100]   functions in running businesses. And there's an image here that
[00:23:47.100 --> 00:23:49.420]   starts to show that so independent of crypto
[00:23:49.420 --> 00:23:53.540]   volatility, what you saw were stable coin usage just rising up
[00:23:53.540 --> 00:23:57.460]   into the right. That's an incredibly important decoupling
[00:23:57.460 --> 00:24:01.700]   that happened in 2024. The second and this data is still
[00:24:01.700 --> 00:24:07.380]   just trickling in, but it's an incredible stat. stable coin
[00:24:07.380 --> 00:24:13.300]   usage, at the end of the second quarter of 2024 was about 1.1
[00:24:13.300 --> 00:24:21.100]   billion transactions, that summed to $8.5 trillion of
[00:24:21.100 --> 00:24:26.540]   transaction volume. If you compare that to visa, over the
[00:24:26.540 --> 00:24:31.580]   same period, it was more than double visas, transaction
[00:24:31.580 --> 00:24:36.780]   volume. So I think what we have now is something that is
[00:24:36.780 --> 00:24:42.700]   fundamentally crossed a point of no return. Similar to how last
[00:24:42.700 --> 00:24:46.300]   year, I thought that the big trend was going to be Bitcoin in
[00:24:46.300 --> 00:24:49.660]   2024. I would say that the big trend in 25 is stable coin
[00:24:49.660 --> 00:24:54.540]   usage, I think we're going to finally attack the duopoly of
[00:24:54.660 --> 00:24:59.340]   visa and MasterCard, I think you're going to see an innumerable
[00:24:59.340 --> 00:25:06.740]   number of use cases that sit and use stable coin rails. I think
[00:25:06.740 --> 00:25:08.900]   when Donald Trump becomes president, I think you're going
[00:25:08.900 --> 00:25:12.940]   to see him go after incredibly high credit card transactions
[00:25:12.940 --> 00:25:19.420]   and costs. You're already seeing cracks in consumer credit
[00:25:19.420 --> 00:25:22.780]   anyways, because of these high APRs, all of this stuff is going
[00:25:22.780 --> 00:25:26.940]   to come to a head in 2025. I think and I think stable coins
[00:25:26.940 --> 00:25:31.060]   could quadruple or quintuple by the end of 25. I think it's just
[00:25:31.060 --> 00:25:32.700]   going to be an enormous market.
[00:25:32.700 --> 00:25:36.700]   Great choice. Should they be regulated? Chamath, we saw at
[00:25:36.700 --> 00:25:39.340]   some of these congressional hearings, Tether was kind of
[00:25:39.340 --> 00:25:45.420]   dragged for being the primary transfer and monetary tool for
[00:25:45.420 --> 00:25:48.780]   terrorism, for getting around sanctions and for human
[00:25:48.780 --> 00:25:52.580]   trafficking, should it be regulated? And how?
[00:25:52.580 --> 00:25:56.580]   I don't think I'm qualified to say how it should. But I think
[00:25:56.580 --> 00:26:01.100]   the point is that there are these immutable logs that sit in
[00:26:01.100 --> 00:26:03.860]   between and on either side of all of these transactions. And
[00:26:03.860 --> 00:26:07.740]   so I think the knowledge is there. And there are a whole
[00:26:07.740 --> 00:26:10.140]   bunch of third party services that add that intelligence
[00:26:10.140 --> 00:26:15.700]   layer. I think the the thing to really question is, if you just
[00:26:15.700 --> 00:26:22.060]   took 300 basis points of drag, yes, out of the global economy,
[00:26:22.060 --> 00:26:25.740]   massive, how valuable would that be? And I think it would be
[00:26:25.740 --> 00:26:29.180]   valuable just in the United States alone, to the tune of a
[00:26:29.180 --> 00:26:32.700]   trillion dollars. So the idea that you wouldn't do it at this
[00:26:32.700 --> 00:26:38.140]   point, is somewhat quizzical to me. So I just think that the
[00:26:38.140 --> 00:26:41.380]   economic justification for this now is just so profound.
[00:26:41.380 --> 00:26:44.180]   Gavin, let me ask you a hard question there as well. Should
[00:26:44.180 --> 00:26:49.300]   the United States government give up the, let's face it, you
[00:26:49.300 --> 00:26:51.540]   know, they have a bit of a stranglehold, they've got a bit
[00:26:51.540 --> 00:26:56.540]   of a monopoly on US dollars, these things are a competitor.
[00:26:56.540 --> 00:26:58.700]   And we were sitting here on this program for the last couple
[00:26:58.700 --> 00:27:01.500]   years talking about the BRICS, and them starting their own
[00:27:01.500 --> 00:27:05.380]   currency. Aren't these in some ways similar to that, and they
[00:27:05.380 --> 00:27:07.980]   would take people off the USD standard? How do you look at
[00:27:07.980 --> 00:27:11.060]   that? Because that is the criticism that some people in
[00:27:11.060 --> 00:27:12.660]   power have put forward.
[00:27:13.260 --> 00:27:17.780]   I do, I do think that they might be very good for the world. But
[00:27:17.780 --> 00:27:20.700]   I do think they would be very bad for America, if they
[00:27:20.700 --> 00:27:25.900]   replaced, if some constellation of stable coins became the new
[00:27:25.900 --> 00:27:31.580]   reserve currency, it is such a, an advantage to be able to
[00:27:31.580 --> 00:27:35.860]   borrow in your own currency. And to give that up lightly, that
[00:27:35.860 --> 00:27:41.700]   just that means you control, you control the real size of your
[00:27:41.700 --> 00:27:46.260]   debt, at all times. Oh, wow, we have a big, big debt. I mean,
[00:27:46.260 --> 00:27:49.020]   this is a little bit like what we just did. Let's just have
[00:27:49.020 --> 00:27:51.380]   let's just let inflation run hot. And oh, wow, that debt's a
[00:27:51.380 --> 00:27:52.620]   lot smaller than it was.
[00:27:52.620 --> 00:27:57.140]   Effectively, so I think it would be a big mistake.
[00:27:57.140 --> 00:28:00.060]   Freeberg, you have any thoughts on it? We've been talking about
[00:28:00.060 --> 00:28:03.340]   currency here and a whole bunch over the last couple years. Any
[00:28:03.340 --> 00:28:07.820]   thoughts on stable coins and just the monopoly we have on it?
[00:28:07.820 --> 00:28:10.900]   I don't know enough about stable coins.
[00:28:11.180 --> 00:28:12.940]   Well, that'll be one of our big topics for the year. And we
[00:28:12.940 --> 00:28:17.420]   should definitely invite Jeremy Allaire from USD on or USDC,
[00:28:17.420 --> 00:28:18.260]   USDC.
[00:28:18.260 --> 00:28:23.980]   Jeremy Allaire. I mentioned, by the way, that I had this small
[00:28:23.980 --> 00:28:30.180]   little product that I exposed to the world, which is just our
[00:28:30.180 --> 00:28:33.380]   research. And we sit it on top of substack. Again, the tools
[00:28:33.380 --> 00:28:37.620]   aren't very good. And we use Stripe. And Jeremy reached out
[00:28:37.620 --> 00:28:40.940]   to me and he's like, I'll just rebuild all your payment rails
[00:28:40.980 --> 00:28:46.380]   on using US dollar stable coins. And it's a no brainer because
[00:28:46.380 --> 00:28:49.220]   I'm spending hundreds of thousands of dollars in
[00:28:49.220 --> 00:28:52.780]   transaction costs that now I can just save and use to hire
[00:28:52.780 --> 00:28:54.540]   somebody else or just pay the team more.
[00:28:54.540 --> 00:28:59.300]   And so I just think paying 10% to substack and the 3%, yeah.
[00:28:59.300 --> 00:29:01.660]   If it's obvious for me, it's obvious for everybody else.
[00:29:01.660 --> 00:29:05.860]   All right, my biggest business winner prediction for 2025 is
[00:29:05.860 --> 00:29:09.740]   Tesla and Google. I think this is going to be the year of AI and
[00:29:09.740 --> 00:29:13.540]   robotics, obviously. But I am just absolutely amazed at the
[00:29:13.540 --> 00:29:17.380]   comeback that Google has made with AI and I'm absolutely in
[00:29:17.380 --> 00:29:19.820]   awe of what Elon did with Colossus. If those of you don't
[00:29:19.820 --> 00:29:24.540]   know, Jensen Wang, Michael Dell, they all obviously participated
[00:29:24.540 --> 00:29:28.540]   in building out x AI. And they were shocked. They couldn't
[00:29:28.540 --> 00:29:33.660]   believe that they stood up 100,000 GPUs in under 45 days.
[00:29:33.660 --> 00:29:37.180]   Was it Gavin? Yeah, I'm thinking that neighborhood. It was a
[00:29:37.180 --> 00:29:42.420]   tremendous effort. And Tesla, right? Is that Tesla? Well, you
[00:29:42.420 --> 00:29:46.340]   want Tesla x AI and Google that cohort who are investing heavily
[00:29:46.340 --> 00:29:49.900]   in AI, those two, specifically those two, three names, I think
[00:29:49.900 --> 00:29:51.980]   are going to be the biggest winners next year, they're going
[00:29:51.980 --> 00:29:55.340]   to come out with some things that people didn't anticipate. I
[00:29:55.340 --> 00:29:58.380]   don't I don't think people are anticipating what Google's going
[00:29:58.380 --> 00:30:01.180]   to come out with because Gemini deep research, I keep telling
[00:30:01.180 --> 00:30:05.580]   people this and I'm using the app is so impressive. Drop what
[00:30:05.580 --> 00:30:09.180]   you're doing right now, pause the podcast, download Gemini, and
[00:30:09.180 --> 00:30:11.620]   just start playing with deep research on your desktop, pay
[00:30:11.620 --> 00:30:15.940]   the 20 bucks for it. It is mind blowing. It blows anything else
[00:30:15.940 --> 00:30:19.900]   in the market out of the water, period, full stop, it is a step
[00:30:19.900 --> 00:30:23.340]   function higher. All right, I'll just leave it at that.
[00:30:23.340 --> 00:30:26.500]   Jason, shouldn't you just go to the vibe of the podcast? Should
[00:30:26.500 --> 00:30:28.500]   you explain what it is? What?
[00:30:28.500 --> 00:30:33.380]   Okay, so what it does is good call. Good call. Yeah. If you
[00:30:33.380 --> 00:30:35.460]   wanted to create a model, let's say, and I did this, where I
[00:30:35.460 --> 00:30:38.780]   said, Hey, make me a model based upon what it would take to
[00:30:38.780 --> 00:30:42.580]   replace all the cars and trips in the United States with full
[00:30:42.580 --> 00:30:46.580]   self driving cars, what would that cost to do? And if you ask
[00:30:46.580 --> 00:30:51.260]   that to chat, GPT, or Brock, or, you know, Claude, it's going to
[00:30:51.260 --> 00:30:54.420]   give you a decent answer. What deep research does is it goes
[00:30:54.420 --> 00:30:56.780]   in, it figures out what the sub components of each of those
[00:30:56.780 --> 00:31:00.020]   questions would be. And then it fires off multiple threads. And
[00:31:00.020 --> 00:31:02.500]   then it searches the web in real time, which Google is
[00:31:02.500 --> 00:31:06.740]   extremely good at. And then it summarizes it gives citations,
[00:31:06.740 --> 00:31:08.820]   and it produces a report that looks like something that
[00:31:08.820 --> 00:31:11.780]   Gartner group McKinsey, Boston consulting group would have
[00:31:11.780 --> 00:31:16.020]   spent, I don't know, 30 days on Gavin, and a million dollars, a
[00:31:16.020 --> 00:31:20.180]   half million dollars. It's bonkers how good this is. But
[00:31:20.180 --> 00:31:23.380]   the amount of compute it takes is extraordinary. That's why
[00:31:23.380 --> 00:31:25.780]   chat GPT released something similar. That's 200 bucks a
[00:31:25.780 --> 00:31:29.540]   month, the one pro I think they call it. And then this one is
[00:31:29.540 --> 00:31:33.620]   like 20 bucks from Gemini. Anyway, given what Google has
[00:31:33.620 --> 00:31:38.180]   access to YouTube, your G drive, your Google Docs, etc, your
[00:31:38.180 --> 00:31:41.060]   Gmail, it's going to do things that you wouldn't anticipate.
[00:31:41.060 --> 00:31:44.220]   Like if you were asking this question, it might look in your
[00:31:44.220 --> 00:31:47.660]   Gmail for possibilities to answer those questions, or
[00:31:47.660 --> 00:31:51.220]   YouTube videos of channels you subscribe to. So this is going
[00:31:51.220 --> 00:31:54.220]   to I think, knock people's socks off and solve problems that
[00:31:54.220 --> 00:31:57.220]   people didn't know they had. Is that a pretty good explanation?
[00:31:57.220 --> 00:32:00.580]   Gavin? Yeah, it's great. For last year, our predictions for
[00:32:00.580 --> 00:32:03.660]   business winner, Chamath said bootstrapped or indoor
[00:32:03.660 --> 00:32:05.700]   profitable startups. I think that's a really great pick. And
[00:32:05.700 --> 00:32:07.860]   that came to pass. We're seeing some of those go public and
[00:32:07.860 --> 00:32:11.540]   raise money at higher valuations or not go out of business.
[00:32:11.540 --> 00:32:13.860]   Freeberg, you said commodities businesses. I'm not sure how
[00:32:13.860 --> 00:32:17.380]   that did. Do you know? Did you check on that pretty flat? Yeah,
[00:32:17.380 --> 00:32:20.700]   we didn't have a lot of the inflationary pressures that I
[00:32:20.700 --> 00:32:24.860]   think were underlying that thesis. So got it. It ended up
[00:32:24.860 --> 00:32:27.900]   being, I'd say a loser relative to other indices you could have
[00:32:27.900 --> 00:32:28.700]   bought this year.
[00:32:28.700 --> 00:32:32.020]   I said training data owners like Reddit, New York Times, Google,
[00:32:32.020 --> 00:32:36.420]   etc. Reddit stock up to 24% in 2024. And they launched their
[00:32:36.420 --> 00:32:36.860]   own Reddit.
[00:32:36.860 --> 00:32:40.620]   Yeah, I think I got that one. New York Times stock is up as
[00:32:40.620 --> 00:32:43.900]   well. And they fired off that lawsuit with open AI. All right,
[00:32:43.900 --> 00:32:47.740]   now we're going to move on to the 2025 biggest business loser
[00:32:47.740 --> 00:32:52.260]   predictions in 2024. Chamath said, pro sports teams because
[00:32:52.260 --> 00:32:54.140]   they hit peak valuations. That's looking like a pretty good
[00:32:54.140 --> 00:32:57.180]   prediction. Freeberg, you said vertical SAS companies because
[00:32:57.180 --> 00:33:00.060]   of AI disruption. That's another one that seems like a great
[00:33:00.060 --> 00:33:03.300]   prediction. I said smartphone manufacturers, Apple stock was
[00:33:03.300 --> 00:33:07.060]   up 30% in 2024. But I think we've all seen that these
[00:33:07.060 --> 00:33:10.420]   smartphones aren't advancing. And people are taking their
[00:33:10.420 --> 00:33:12.420]   times the sales of those are down services are up.
[00:33:12.420 --> 00:33:15.380]   I would take the other side on pro sports teams. It feels like
[00:33:15.380 --> 00:33:20.540]   that market is about to be institutionalized. And funds are
[00:33:20.540 --> 00:33:24.380]   going to start buying pro sports teams. Okay, that ultimately,
[00:33:24.380 --> 00:33:26.900]   and ultimately, capital markets have way more resources than
[00:33:26.900 --> 00:33:31.620]   kind of the wealthy individuals who've done it for today. So I
[00:33:31.620 --> 00:33:35.180]   just think it's the amount of money that can go after pro
[00:33:35.180 --> 00:33:39.540]   sports teams is about to, you know, 10x 100. I think you're
[00:33:39.540 --> 00:33:43.260]   totally right. The reason I said that last year was it was pretty
[00:33:43.260 --> 00:33:47.020]   clear to me at the time. And the NBA was the canary in the coal
[00:33:47.020 --> 00:33:49.660]   mine that there was a viewership problem in professional sports.
[00:33:50.420 --> 00:33:54.940]   And specifically in the NBA, the game has devolved into
[00:33:54.940 --> 00:34:00.260]   essentially rebounds and dunks, or three pointers. And the issue
[00:34:00.260 --> 00:34:02.740]   with that is that it becomes just meaningfully less
[00:34:02.740 --> 00:34:06.820]   interesting to watch. At the same time, because of the fact
[00:34:06.820 --> 00:34:10.020]   that the TV deals are really what determines the discounted
[00:34:10.020 --> 00:34:13.620]   value of these sports franchises. The TV deal was so
[00:34:13.620 --> 00:34:20.420]   enormous, that it creates no reliable rivalries anymore.
[00:34:20.420 --> 00:34:24.380]   Because people will hopscotch teams almost every year, because
[00:34:24.380 --> 00:34:27.340]   the compensation that they can get is just so obscene, quite
[00:34:27.340 --> 00:34:31.340]   honestly. And I think what happens is, sports will have a
[00:34:31.340 --> 00:34:36.220]   decent run until the next TV deals get done. And I think if
[00:34:36.220 --> 00:34:41.180]   you, for example, take pharma ads outside of TV, so like that
[00:34:41.180 --> 00:34:46.220]   pool shrinks, if you have less viewership, and so you can sell
[00:34:46.220 --> 00:34:49.260]   the remaining ads less effectively, because there's
[00:34:49.260 --> 00:34:51.500]   just fewer of them. And then there's fewer buyers, and it
[00:34:51.500 --> 00:34:56.580]   shrinks yet again, then the dollar pool that the television
[00:34:56.580 --> 00:34:59.940]   networks and the streamers are going to be willing to pay for
[00:34:59.940 --> 00:35:03.860]   sports will go down. And the group that will be the most
[00:35:03.860 --> 00:35:07.740]   price sensitive are exactly who you said, Gavin, meaning the
[00:35:07.740 --> 00:35:10.740]   non trophy buyer. So like, you know, when I bought into the
[00:35:10.740 --> 00:35:13.740]   Warriors, I bought it purely as a trophy asset. And I was price
[00:35:13.740 --> 00:35:16.500]   insensitive. But I agree with you that now that you have the
[00:35:16.500 --> 00:35:20.260]   PE firms on the cap tables of these sports franchises, those
[00:35:20.260 --> 00:35:23.820]   folks are all DCFs. Those folks are all Excel models. I don't
[00:35:23.820 --> 00:35:26.740]   think that they're buying things for emotion. I don't think
[00:35:26.740 --> 00:35:29.820]   they've grown up thinking I want to own this thing, not using
[00:35:29.820 --> 00:35:33.300]   institutional LP dollars. So I just think that's why that's why
[00:35:33.300 --> 00:35:34.540]   I said that in 24. So I just
[00:35:34.540 --> 00:35:37.140]   on behalf of Phil Hummuth and I, we appreciate you made that
[00:35:37.140 --> 00:35:40.020]   vanity investment for the number of times we got to sit in your
[00:35:40.020 --> 00:35:41.100]   court side seats.
[00:35:41.100 --> 00:35:44.780]   Yeah, because I never went to the game with NBA players. I
[00:35:44.780 --> 00:35:46.740]   never went to the games. I should have gone to more games.
[00:35:46.740 --> 00:35:49.340]   I went to your games and almost got thrown out of your seats. I
[00:35:49.340 --> 00:35:53.180]   got a red card one time. It's true. Is it true? You did? Oh,
[00:35:53.180 --> 00:35:56.580]   you know, I got up. No, I got a call. I got a call. I think it
[00:35:56.580 --> 00:35:59.100]   was from the Warriors or from the NBA, something to the effect
[00:35:59.100 --> 00:36:01.940]   of Trump. This guy that was sitting in your seats was almost
[00:36:01.940 --> 00:36:04.940]   kicked out. And I said, excuse me, because I knew that it was
[00:36:04.940 --> 00:36:09.220]   the next game in fairness. And he was like, job owning our own
[00:36:09.220 --> 00:36:12.940]   players. I was getting into it with Bogut and with David Lee.
[00:36:12.940 --> 00:36:16.860]   Because I was unbelievable. I told Steve Kerr, listen, you're
[00:36:16.860 --> 00:36:20.460]   up 30 on my next sit these guys down. This is Bush league. What
[00:36:20.460 --> 00:36:23.620]   if Steph Curry gets hurt out there like, and, you know, Bogut
[00:36:23.620 --> 00:36:25.500]   told me to shut up and Andre.
[00:36:25.500 --> 00:36:28.220]   Bogut told them to basically go pound sand and
[00:36:28.220 --> 00:36:32.220]   it was the funniest thing ever. Gavin. This is what happens when
[00:36:32.220 --> 00:36:34.180]   you get it's one of our friends. And he's one of our friends.
[00:36:34.180 --> 00:36:35.620]   So that's why it's so funny.
[00:36:35.620 --> 00:36:38.740]   But they can't they come over free bird and they tap you on
[00:36:38.740 --> 00:36:42.780]   the shoulder. I'm with my wife, she's mortified. And the guy
[00:36:42.780 --> 00:36:48.060]   hand you a card. And the card says you've been warned one time
[00:36:48.060 --> 00:36:53.020]   and one time only about abusive, you know, behavior. If we have
[00:36:53.020 --> 00:36:56.300]   to warn you one more time, you will be squirted out. So I look
[00:36:56.300 --> 00:36:59.380]   at the guy and I say, but he goes, read the card. I read the
[00:36:59.380 --> 00:37:02.420]   card. I say he goes, give me a thumbs up.
[00:37:02.420 --> 00:37:07.980]   You're not supposed to bend. Three years later, I'm sitting
[00:37:07.980 --> 00:37:10.340]   in the same seats, I'm interacting with Draymond
[00:37:10.340 --> 00:37:13.260]   during the finals games, and everybody's hokey dokey with it.
[00:37:13.260 --> 00:37:15.300]   When you say interacting, what do you mean when you say
[00:37:15.300 --> 00:37:15.700]   interact?
[00:37:15.700 --> 00:37:17.700]   Gavin wanted to make a point about what I just
[00:37:17.700 --> 00:37:21.340]   just just come back to Chamath because I for sure these private
[00:37:21.340 --> 00:37:24.820]   equity guys are DCFs. The NBA has been terribly managed. I
[00:37:24.820 --> 00:37:28.620]   give LeBron said they have a big problem. You know, and I'd
[00:37:28.620 --> 00:37:31.580]   separate the NBA is the worst managed NFL is probably the best
[00:37:31.580 --> 00:37:34.420]   managed. But the one kind of counterpoint I would say on the
[00:37:34.420 --> 00:37:39.260]   TV rights is Google bought Sunday ticket and are extremely
[00:37:39.260 --> 00:37:44.940]   happy with it. Amazon and Netflix also bought, you know,
[00:37:44.940 --> 00:37:48.460]   both bought NFL games and are really happy with them. And so I
[00:37:48.460 --> 00:37:50.980]   just think those three companies, it doesn't really
[00:37:50.980 --> 00:37:55.580]   matter to them if pharma ads go away. In 18 months, you're going
[00:37:55.580 --> 00:37:59.540]   to be able to dynamically create an ad for each individual person
[00:37:59.540 --> 00:38:02.700]   and show it to them. And if you're a high value user with a,
[00:38:02.940 --> 00:38:06.020]   you know, the Google knows that you're about to book a vacation,
[00:38:06.020 --> 00:38:08.980]   you know, they'll dynamically generate, you know, whatever,
[00:38:08.980 --> 00:38:12.460]   you know, hotel destinations you want and show click here. So I
[00:38:12.460 --> 00:38:17.260]   just think sports, as long as they command the eyeballs that
[00:38:17.260 --> 00:38:22.260]   they do, and I for sure, if the NBA doesn't fix it, the value of
[00:38:22.260 --> 00:38:26.900]   those franchises will start to decline. But I'm just the fact
[00:38:26.900 --> 00:38:30.580]   that all of the biggest tech companies are so happy with the
[00:38:30.580 --> 00:38:33.580]   sports kind of rights that they bought, they're gonna buy them
[00:38:33.580 --> 00:38:34.980]   all. Every
[00:38:34.980 --> 00:38:40.580]   it may be maybe you're closer to this, but why wouldn't Apple,
[00:38:40.580 --> 00:38:43.820]   Amazon or Google just back up the truck to the NBA and say,
[00:38:43.820 --> 00:38:46.620]   we'll take the whole thing. And then anybody who's got an iPhone
[00:38:46.620 --> 00:38:50.580]   gets the NBA for free. And then everybody else has to pay and
[00:38:50.580 --> 00:38:53.100]   they figure it out in the back and they lose a, you know, 5
[00:38:53.100 --> 00:38:56.140]   billion, they make 2 billion, who cares? It's around here for
[00:38:56.140 --> 00:39:00.340]   Apple. I agree. And they, you know, I mean, they all all
[00:39:00.340 --> 00:39:03.020]   except for Apple, really, and Apple, they have, I think, an
[00:39:03.020 --> 00:39:06.300]   MLS deal. But they all kind of stuck their toe in the water.
[00:39:06.300 --> 00:39:10.060]   And I think they feel like, wow, the water's warm. Let's dive in.
[00:39:10.060 --> 00:39:14.820]   Okay. Yeah. And the new deal is an 11 year deal for the NBA. So
[00:39:14.820 --> 00:39:17.740]   these things don't come up that often. But we'll see over time,
[00:39:17.740 --> 00:39:20.820]   maybe somebody will buy one of these media companies and
[00:39:20.820 --> 00:39:25.140]   inherit them. Okay, biggest business loser for 2025. What's
[00:39:25.140 --> 00:39:26.580]   your prediction? Gavin Baker,
[00:39:26.580 --> 00:39:30.940]   government service providers, you do not you do not want to
[00:39:30.940 --> 00:39:34.140]   have the United States government at any level is over
[00:39:34.140 --> 00:39:35.580]   35% of your revenue.
[00:39:35.580 --> 00:39:40.020]   Good choice. Yes, obviously, in the age of doge, they might not
[00:39:40.020 --> 00:39:42.460]   be spending wildly. And they might actually look at the bill,
[00:39:42.460 --> 00:39:43.660]   they might check the bill.
[00:39:43.660 --> 00:39:45.980]   Crazy thought crazy. Yeah,
[00:39:45.980 --> 00:39:47.900]   crazy thought to actually check the bill. You never know.
[00:39:47.900 --> 00:39:51.340]   Chamath, who do you predict will be the biggest business loser of
[00:39:51.340 --> 00:39:52.060]   2025?
[00:39:53.740 --> 00:39:55.380]   Well, this is a little bit
[00:39:55.380 --> 00:39:58.820]   precarious, but
[00:39:58.820 --> 00:40:06.020]   I don't know what the percentage drawdown from here will be. But
[00:40:06.020 --> 00:40:13.180]   I think when we look back, the absolute dollar drawdown of the
[00:40:13.180 --> 00:40:17.860]   mag seven will be in the trillions of dollars. Okay. And
[00:40:17.860 --> 00:40:21.860]   the reason is not necessarily because of the underlying
[00:40:21.860 --> 00:40:26.460]   fundamentals of these companies. But I am a little bit worried.
[00:40:26.460 --> 00:40:29.700]   And I tweeted this a few days ago about just the general
[00:40:29.700 --> 00:40:37.140]   concentration of the top 789 10 companies in the indices. I
[00:40:37.140 --> 00:40:41.300]   think it's approaching 40%. And I think that when you look at
[00:40:41.300 --> 00:40:46.180]   these historic concentrations, they've generally foreshadowed a
[00:40:46.180 --> 00:40:54.140]   big drawdown. And unfortunately, I don't see how you can sort of,
[00:40:54.140 --> 00:40:57.460]   you know, inoculate yourself from that risk. So independent
[00:40:57.460 --> 00:40:59.540]   of the quality of these companies, because I think these
[00:40:59.540 --> 00:41:02.820]   companies are exceptional businesses. I do think you've
[00:41:02.820 --> 00:41:07.540]   just had too much concentration. And I think it is a setup to
[00:41:07.540 --> 00:41:12.060]   retrade and give back and in that it could even be 10%. But
[00:41:12.060 --> 00:41:16.380]   10% in the mag eight will be a couple trillion bucks. And so on
[00:41:16.380 --> 00:41:18.940]   a one or two percent would be a lot. Yeah, an absolute dollar is
[00:41:18.940 --> 00:41:21.620]   a lot. Okay, freeberg, who do you predict? You predict max
[00:41:21.620 --> 00:41:23.460]   seven government service providers for you, Gavin
[00:41:23.460 --> 00:41:25.580]   freeberg, who do you predict will be the biggest business
[00:41:25.580 --> 00:41:30.420]   loser? I'm sort of on the same vein as Gavin, I went with the
[00:41:30.420 --> 00:41:34.180]   kind of old defense and aerospace providers, Boeing,
[00:41:34.180 --> 00:41:37.660]   Lockheed Martin, Raytheon, defense 1.0, driven by kind of
[00:41:37.660 --> 00:41:40.660]   China dominance driven by us defense budgets that I think
[00:41:40.660 --> 00:41:43.140]   are going to need to shift towards a more kind of tech
[00:41:43.140 --> 00:41:46.620]   oriented and ROI driven rationalization and pricing and
[00:41:46.620 --> 00:41:49.780]   spend. So the Palantir's and Andrews obviously the world will
[00:41:49.780 --> 00:41:52.420]   benefit. And I also just think like there's a lot of failure at
[00:41:52.420 --> 00:41:55.340]   scale with these businesses, they've gotten too clunky and
[00:41:55.340 --> 00:41:58.780]   too bureaucratic, as we've seen with Boeing from their space
[00:41:58.780 --> 00:42:04.260]   program failure in 2024, to the challenges with their, their
[00:42:04.260 --> 00:42:06.580]   airplane business, but I think that this government contracting
[00:42:06.580 --> 00:42:09.060]   business across the board is going to be deeply challenged
[00:42:09.060 --> 00:42:10.980]   this year, with all the new blood.
[00:42:10.980 --> 00:42:14.260]   So the cost plus are going to suffer is what you're saying and
[00:42:14.260 --> 00:42:15.860]   the angels will thrive.
[00:42:15.860 --> 00:42:20.140]   Would you guys add? Just a question? Would you guys add the
[00:42:20.140 --> 00:42:23.780]   traditional consulting companies into the mix as well? Like, if
[00:42:23.780 --> 00:42:26.820]   that's a good point, too, that's a great one. Yeah, we think what
[00:42:26.820 --> 00:42:30.020]   we talked about with deep like the one pros, the Tata's, the
[00:42:30.020 --> 00:42:35.340]   HCL, the Accenture in a sense, the Y's all these folks that are
[00:42:35.340 --> 00:42:37.500]   in real trouble with that, if that also happens.
[00:42:37.820 --> 00:42:42.980]   Yeah, you the efficiency that they'll gain will also be felt
[00:42:42.980 --> 00:42:45.260]   by their customers and their customers might not hire them
[00:42:45.260 --> 00:42:47.540]   when you got a bunch of software entrepreneurs that are now
[00:42:47.540 --> 00:42:49.940]   advising and informing the federal government on how to run
[00:42:49.940 --> 00:42:52.740]   their their operations. I'm pretty sure that some of these
[00:42:52.740 --> 00:42:55.580]   service providers are gonna get washed out. So it's a good idea.
[00:42:55.580 --> 00:42:59.620]   The thing to keep in mind is like cost plus is a fancier way
[00:42:59.620 --> 00:43:03.740]   of saying time and materials. And time and materials is a
[00:43:03.780 --> 00:43:08.420]   fancy way of saying human labor arbitrage. And I think that all
[00:43:08.420 --> 00:43:13.700]   of that stuff will get extremely scrutinized in 2025. Because if
[00:43:13.700 --> 00:43:17.540]   you are buying, you know, $800 wastebaskets and, you know,
[00:43:17.540 --> 00:43:22.300]   $9,000 umbrella hangers, because of time and materials and all of
[00:43:22.300 --> 00:43:26.260]   this other crazy stuff that's in the system, and all of that gets
[00:43:26.260 --> 00:43:28.940]   washed out, then a lot of these folks and their business models
[00:43:28.940 --> 00:43:30.660]   will will get put under severe stress
[00:43:30.660 --> 00:43:33.420]   the alignments, you know, you show me an incentive, I'll show
[00:43:33.420 --> 00:43:36.940]   you the outcome, the alignment of cost plus is to just keep
[00:43:36.940 --> 00:43:40.980]   being inefficient and, and waste. And these defense
[00:43:40.980 --> 00:43:45.660]   contractors are taking 60 7080% off the price of each piece of
[00:43:45.660 --> 00:43:46.940]   munitions or vehicle.
[00:43:46.940 --> 00:43:48.940]   Yeah.
[00:43:48.940 --> 00:43:52.620]   Cost was terrible. No, just cost is terrible.
[00:43:52.620 --> 00:43:55.700]   That's right. For my biggest business loser prediction, I had
[00:43:55.700 --> 00:44:01.060]   to go through a lot of the people I've criticized. I didn't
[00:44:01.060 --> 00:44:03.940]   start fights with over the past year, commercial real estate
[00:44:03.940 --> 00:44:06.340]   came to mind, because these leases are going to keep coming
[00:44:06.340 --> 00:44:09.180]   up. And I think like, they kick the can down the road a little
[00:44:09.180 --> 00:44:12.860]   bit. So I started there. Then I looked at micro strategies. And
[00:44:12.860 --> 00:44:15.460]   that made no sense to me that they were trading at two, three,
[00:44:15.460 --> 00:44:18.340]   four times the book value of their Bitcoin. And I think
[00:44:18.340 --> 00:44:21.940]   that's not sustainable. I looked at truth social, which is like,
[00:44:21.940 --> 00:44:25.980]   doing four or $5 million in revenue, and is valued at 7
[00:44:25.980 --> 00:44:29.260]   billion. That makes absolute no logical sense. But I think the
[00:44:29.260 --> 00:44:32.860]   one that is the most overpriced of all this, and I think is
[00:44:32.860 --> 00:44:38.620]   going to see their peak valuation is open AI. I think
[00:44:38.620 --> 00:44:43.740]   the headwinds for open AI are being absolutely under
[00:44:43.740 --> 00:44:47.860]   appreciated. Like I said before, my previous one, my previous
[00:44:47.860 --> 00:44:51.780]   prediction, Google is kicking ass x AI is just getting started
[00:44:51.780 --> 00:44:57.460]   and building out so much big iron. Microsoft was basically on
[00:44:57.460 --> 00:45:01.980]   another podcast, almost like laughing at open AI for selling
[00:45:01.980 --> 00:45:04.420]   them the source code and that they didn't even need open AI
[00:45:04.420 --> 00:45:06.460]   anymore, because they had it all they don't need them. And they
[00:45:06.460 --> 00:45:10.540]   own all the big iron. I think open AI is valuation made no
[00:45:10.540 --> 00:45:13.100]   sense. I don't think they're gonna be able to keep charging
[00:45:13.100 --> 00:45:19.380]   the prices they're charging. And I think AWS, Apple, Google, x AI
[00:45:19.380 --> 00:45:26.580]   this cohort are going to really take that $157 billion valuation
[00:45:26.740 --> 00:45:30.860]   and make it the peak valuation of the company. And I do I do
[00:45:30.860 --> 00:45:35.100]   think that there is a nonzero chance they could lose their
[00:45:35.100 --> 00:45:40.780]   process and these court cases of transferring $157 billion in
[00:45:40.780 --> 00:45:44.220]   value from a nonprofit into a for profit. I think that whole
[00:45:44.220 --> 00:45:44.980]   thing could blow up.
[00:45:44.980 --> 00:45:48.620]   It's a prediction is open AI will not be able to convert from
[00:45:48.620 --> 00:45:50.380]   nonprofit for profit in 2025.
[00:45:50.380 --> 00:45:53.100]   I think that that's a small piece of it. But that's a really
[00:45:53.100 --> 00:45:56.940]   interesting super prediction. Insert polymarket graphic here.
[00:45:56.940 --> 00:46:01.100]   Super prediction. Will open AI convert?
[00:46:01.100 --> 00:46:04.900]   Is that 2025? Yeah, by the way, you know, they're projecting I
[00:46:04.900 --> 00:46:08.860]   think, in the the leaked financials 12 billion revenue
[00:46:08.860 --> 00:46:11.420]   next year, J. Cal. So unlike a lot of the other things you're
[00:46:11.420 --> 00:46:13.820]   talking about, this is a real business with real revenue, real
[00:46:13.820 --> 00:46:17.300]   scale, real growth, real technology. It's a little bit
[00:46:17.300 --> 00:46:19.820]   distinct from kind of being a meme stock or being a
[00:46:19.820 --> 00:46:22.740]   exactly. That's why I'm picking it because I think it's easy to
[00:46:22.900 --> 00:46:26.740]   pick a meme stock, it's harder to pick a real company. But I do
[00:46:26.740 --> 00:46:29.820]   think that that revenue which you know, a lot of it is
[00:46:29.820 --> 00:46:32.860]   consumer and a lot of it is developers, the developers I
[00:46:32.860 --> 00:46:35.740]   know, all want to do open source, they don't want to have
[00:46:35.740 --> 00:46:39.580]   to be beholden to open AI and Sam Altman, they would much
[00:46:39.580 --> 00:46:42.620]   rather, and they're already setting their queries across
[00:46:42.620 --> 00:46:45.260]   multiple different stacks and trying different ones. I don't
[00:46:45.260 --> 00:46:48.620]   think there's any loyalty to open AI, or Gemini or any of
[00:46:48.620 --> 00:46:51.820]   these services, I think they'll just go with eventually, open
[00:46:51.820 --> 00:46:54.500]   source in many cases. So anyway, that's my thought on open AI.
[00:46:54.500 --> 00:46:59.220]   2025 biggest business deal. What do you got your mouth? What's
[00:46:59.220 --> 00:47:01.980]   your biggest business deal for 2025? Prediction? Jamal? What do
[00:47:01.980 --> 00:47:04.180]   you got? You said Starlink to go public last year?
[00:47:04.180 --> 00:47:10.340]   Yeah, totally worked on that one. I think that this is the
[00:47:10.340 --> 00:47:14.140]   year that we will see the collapse of the traditional auto
[00:47:14.140 --> 00:47:20.060]   OEMs. And I think that the the deal that happened at the end of
[00:47:20.060 --> 00:47:26.500]   2024 with Honda, Nissan, I think is a bit of a signal to what the
[00:47:26.500 --> 00:47:30.020]   industry has to do, which is to go through a massive wave of
[00:47:30.020 --> 00:47:35.540]   consolidation. I think that Tesla is just in an incredible
[00:47:35.540 --> 00:47:38.900]   position with the quality of their vehicles and the quality
[00:47:38.900 --> 00:47:42.620]   of their software, and the quality of their autonomy with
[00:47:42.620 --> 00:47:50.900]   FSD. So I suspect that after a couple of more meaningful
[00:47:50.900 --> 00:47:55.740]   product releases, it's just going to trigger the realization
[00:47:55.740 --> 00:47:59.380]   by the public capital markets, that these auto OEMs are
[00:47:59.380 --> 00:48:04.580]   uninvestable. And I think the result of that will be a wave of
[00:48:04.580 --> 00:48:06.100]   auto mega mergers.
[00:48:06.100 --> 00:48:10.420]   And for people who don't know, Honda and Nissan signed an
[00:48:10.420 --> 00:48:14.020]   agreement to merge and Mitsubishi is involved, because
[00:48:14.020 --> 00:48:16.860]   they're part of I think Nissan's Alliance, this would obviously
[00:48:16.860 --> 00:48:19.540]   get rid of all of the redundancy.
[00:48:19.540 --> 00:48:22.580]   But I think this is going to touch like, like the European
[00:48:22.580 --> 00:48:25.740]   OEMs are in real trouble. You know, what does Volkswagen do?
[00:48:25.740 --> 00:48:29.660]   It's not clear what the Stellantis do. It's not clear.
[00:48:29.660 --> 00:48:32.500]   These are all businesses that are effectively melting
[00:48:32.500 --> 00:48:35.900]   icebergs. And so you know, typically melting iceberg
[00:48:35.900 --> 00:48:39.180]   businesses, when they get put under pressure from smart
[00:48:39.180 --> 00:48:43.700]   investors like Gavin, and and and his ilk, they're forced to
[00:48:43.700 --> 00:48:44.140]   merge.
[00:48:44.140 --> 00:48:48.180]   Gavin, you got to spread trade. Are you short these names?
[00:48:48.180 --> 00:48:52.340]   I, I would rather not talk about specific positions. I would just
[00:48:52.340 --> 00:48:57.220]   say I agree 100% with Chamaf. I think they're gonna lose their
[00:48:57.220 --> 00:49:00.380]   Chinese business because they don't make competitive products
[00:49:00.380 --> 00:49:04.380]   anymore. If there's not massive protectionism, and we're seeing
[00:49:04.380 --> 00:49:07.660]   signs that they'll be caught between Tesla and the Chinese
[00:49:07.660 --> 00:49:12.700]   OEMs. And I think the only way that this doesn't happen to
[00:49:12.700 --> 00:49:16.460]   months, the only risk to Chamaf prediction is just government
[00:49:16.460 --> 00:49:19.700]   intervention, because they're such big employers. And, you
[00:49:19.700 --> 00:49:24.020]   know, often seen as national champions, but absent really
[00:49:24.020 --> 00:49:27.740]   significant government support. They're all in deep trouble.
[00:49:27.740 --> 00:49:33.900]   Okay, well done. Freeberg. Last year. You said there'd be some
[00:49:33.900 --> 00:49:36.660]   blockbuster deals for rights holders licensing data for AI
[00:49:36.660 --> 00:49:39.620]   training. And Reddit did in fact, sign two of them. So a
[00:49:39.620 --> 00:49:42.620]   great prediction from you for last year on biggest business
[00:49:42.620 --> 00:49:45.020]   deal. What do you got this year? See if you can go two for two.
[00:49:45.020 --> 00:49:51.820]   Was it just read it? I should probably look it up. I'll just
[00:49:51.820 --> 00:49:54.820]   follow on my year of the robot theme. I do think that there's
[00:49:54.820 --> 00:49:58.180]   going to be massive funding deals. Similar to what we saw
[00:49:58.180 --> 00:50:00.980]   this past year, for compute build out, I think we're going
[00:50:00.980 --> 00:50:04.820]   to see massive funding deals for hardware based manufacturing
[00:50:04.820 --> 00:50:08.100]   build out in the United States. And I think that those deals may
[00:50:08.100 --> 00:50:12.740]   take the form of kind of traditional equity from private
[00:50:12.740 --> 00:50:16.140]   markets, or they may have some component that includes
[00:50:16.140 --> 00:50:20.100]   government support to kind of motivate and drive and
[00:50:20.100 --> 00:50:22.860]   accelerate onshore manufacturing. We're not going
[00:50:22.860 --> 00:50:26.780]   to go in the US to making stuff that is like last century, I
[00:50:26.780 --> 00:50:29.540]   think we're going to need to move manufacturing to the next
[00:50:29.540 --> 00:50:33.380]   decade, next century of of production. I think that's going
[00:50:33.380 --> 00:50:36.260]   to mean making some of these autonomous and robotic type
[00:50:36.260 --> 00:50:38.900]   systems that are going to become really critical for us,
[00:50:38.900 --> 00:50:42.940]   particularly with China, doing this massive ramp up and build
[00:50:42.940 --> 00:50:47.380]   out for both drones and robots, and autonomous vehicles. So I
[00:50:47.380 --> 00:50:49.140]   think we're going to need to kind of onshore a lot of this.
[00:50:49.140 --> 00:50:51.820]   And so that'll be a big amount of capital that's going to move
[00:50:51.820 --> 00:50:54.060]   in. So you'll see a bunch of these big blockbuster deals for
[00:50:54.060 --> 00:50:55.260]   hardware build out in the US.
[00:50:55.260 --> 00:50:58.540]   Gavin, what do you think should be the biggest business deal in
[00:50:58.540 --> 00:50:59.140]   2025?
[00:50:59.140 --> 00:51:02.100]   I think the biggest business deal is that they're going to be
[00:51:02.100 --> 00:51:04.860]   deals. I think there's going to you're going to see a tidal wave
[00:51:04.860 --> 00:51:08.460]   of M&A after four years of not being able to get anything done.
[00:51:08.460 --> 00:51:13.380]   I think there's an enormous amount of pent up demand. So
[00:51:13.380 --> 00:51:15.340]   kind of point number one point number two, something will
[00:51:15.340 --> 00:51:18.940]   happen with Intel. And that will be big. And hopefully it's good
[00:51:18.940 --> 00:51:23.980]   for America. And then I do think you will see a lot of these
[00:51:23.980 --> 00:51:28.180]   frontier AI labs that are independent be acquired. You
[00:51:28.180 --> 00:51:30.820]   know, I thought your points were well taken, Jason about you
[00:51:30.820 --> 00:51:34.180]   know, everything that, you know, Google is bringing to bear and
[00:51:34.180 --> 00:51:37.940]   X, X AI owns their own compute. When you guys can choose
[00:51:37.940 --> 00:51:41.620]   whichever one of these three you like, but the ultimate AI
[00:51:41.620 --> 00:51:45.860]   winner will be the one with the lowest cost of infrastructure
[00:51:45.860 --> 00:51:48.940]   costs, the lowest cost of compute. And definitionally, you
[00:51:48.940 --> 00:51:52.140]   can't be the low cost provider if you're renting your compute
[00:51:52.140 --> 00:51:53.140]   from someone else.
[00:51:53.140 --> 00:51:54.740]   Because of markups.
[00:51:54.740 --> 00:51:57.380]   Yeah, because there's a markup if you're buying your compute
[00:51:57.380 --> 00:52:02.780]   from Azure, or AWS, or Google, you are at a disadvantage
[00:52:02.780 --> 00:52:05.140]   relative to their internal services over time.
[00:52:05.140 --> 00:52:12.540]   So the full stack wins. Great prediction for me. Last year, my
[00:52:12.540 --> 00:52:15.860]   prediction was that ByteDance would go public or tick tock,
[00:52:15.860 --> 00:52:19.620]   we get divested or some version of this. We are but 18 days away
[00:52:19.620 --> 00:52:22.780]   from figuring out if the Supreme Court will do just that. My
[00:52:22.780 --> 00:52:24.980]   prediction for this year, I was looking at all the media
[00:52:24.980 --> 00:52:28.140]   companies, gentlemen, there were so many possibilities there.
[00:52:28.140 --> 00:52:32.060]   Warner Brothers, we talked about Apple and Disney, you know, a
[00:52:32.060 --> 00:52:36.380]   couple years ago, but I think the age of autonomy is here. And
[00:52:36.380 --> 00:52:40.780]   I think there is going to be some partnerships that will
[00:52:40.780 --> 00:52:45.660]   happen between Amazon, DoorDash, Uber, Tesla, Waymo, and that
[00:52:45.660 --> 00:52:49.380]   cohort. And I would not be surprised to see Tesla could buy
[00:52:49.380 --> 00:52:53.460]   Uber right now for but 10% of its market cap. And Waymo could
[00:52:53.460 --> 00:52:57.940]   spin out and partner with Uber. Amazon could buy DoorDash fairly
[00:52:57.940 --> 00:53:01.900]   easily. And with the wrath of Khan being over the wrath of
[00:53:01.900 --> 00:53:06.540]   Lena Khan being over Gavin, it is possible that mega deals like
[00:53:06.540 --> 00:53:10.180]   these could go through. And if a couple of mega deals go through
[00:53:10.180 --> 00:53:15.100]   like this, whoever, you know, teams up here could win autonomy,
[00:53:15.100 --> 00:53:19.020]   delivery, food delivery, and e commerce. This is a ginormous
[00:53:19.020 --> 00:53:23.300]   space. And I think listen, I don't, I haven't spoken to
[00:53:23.300 --> 00:53:26.900]   obviously my friend about it. But Tesla buying DoorDash and
[00:53:26.900 --> 00:53:31.140]   Uber, or Amazon buying DoorDash and Uber could be the greatest
[00:53:31.140 --> 00:53:34.100]   service ever created if you're wanting to build a super app.
[00:53:34.100 --> 00:53:36.540]   The only thing I would add, and I think dovetails with what you
[00:53:36.540 --> 00:53:41.380]   said, and, and Friedberg's kind of year of the robot is
[00:53:41.380 --> 00:53:44.100]   autonomous drones. There's a company called zip line, which
[00:53:44.100 --> 00:53:48.980]   my firm is an investor in. Fantastic. Yeah, but autonomous
[00:53:48.980 --> 00:53:52.780]   drones, they really are the best way to deliver almost anything
[00:53:52.780 --> 00:53:58.180]   to suburban America. And then I think, over time, it will be
[00:53:58.180 --> 00:54:02.580]   sorted out so that they could deliver in cities as well. So I
[00:54:02.580 --> 00:54:05.660]   just think that that might be a little bit of a wildcard for
[00:54:05.660 --> 00:54:07.580]   some of these delivery services.
[00:54:07.580 --> 00:54:11.460]   Well, and Amazon in I believe it's Texas is actually doing
[00:54:11.460 --> 00:54:15.580]   these now. They've got 60,000 SKUs is my understanding already
[00:54:15.580 --> 00:54:18.780]   being delivered, and they just drop it in your backyard. And
[00:54:18.780 --> 00:54:19.900]   it's there in 45 minutes.
[00:54:19.900 --> 00:54:22.340]   Well, we talked about this like two weeks ago, I, you know,
[00:54:22.340 --> 00:54:25.580]   Meituan in China has got this and they have food delivery
[00:54:25.580 --> 00:54:28.180]   happening with these drones. By the way, I'm just kind of
[00:54:28.180 --> 00:54:30.660]   dovetailing off of this, I think the other big deal potential in
[00:54:30.660 --> 00:54:35.060]   2025. Just to be very specific is a deal with Waymo. You know,
[00:54:35.060 --> 00:54:38.700]   Waymo launched in SF in August 2023. And kind of an open market
[00:54:38.700 --> 00:54:43.260]   way. Uber and Lyft were 66 and 34% market share at the time.
[00:54:43.260 --> 00:54:48.660]   And in 15 months in November of 2024, Waymo is now a 22% market
[00:54:48.660 --> 00:54:52.700]   share of rides in SF, which is the same as Lyft and Uber is now
[00:54:52.700 --> 00:54:57.300]   down to 55. So Waymo aid into both Uber and Lyft market share
[00:54:57.300 --> 00:55:01.340]   by on the order of 12 points in just 15 months. And now they're
[00:55:01.340 --> 00:55:04.380]   launching in LA in Austin, all over the country. They're
[00:55:04.380 --> 00:55:07.820]   already in Phoenix. So I think you could see a massive and by
[00:55:07.820 --> 00:55:10.100]   the way, you know, they also just moved the hardware platform
[00:55:10.100 --> 00:55:13.220]   over to a new drop new device that supposedly going to bring
[00:55:13.220 --> 00:55:16.860]   the CAPEX significantly down for new launches. So you'll see much
[00:55:16.860 --> 00:55:20.460]   improved ROIC metrics, which means that there's a much kind
[00:55:20.460 --> 00:55:23.580]   of more efficient way to use capital to scale. So the system
[00:55:23.580 --> 00:55:26.980]   works, it is scaling, they are opening up in new markets, you
[00:55:26.980 --> 00:55:29.660]   could see something happen with Waymo this year, that could
[00:55:29.660 --> 00:55:32.780]   either be something like a massive financing and IPO, or a
[00:55:32.780 --> 00:55:35.140]   merger or acquisition with one of the big ride sharing
[00:55:35.140 --> 00:55:37.780]   companies. I don't know if that makes as much strategic sense as
[00:55:37.780 --> 00:55:39.820]   I've thought about it a little bit. But I do think you could
[00:55:39.820 --> 00:55:43.100]   see a big deal with Waymo. This company is if you guys have not
[00:55:43.100 --> 00:55:45.820]   been in a Waymo, I think we all talked about this, but it's an
[00:55:45.820 --> 00:55:48.900]   incredible experience. And everyone I know, of every age
[00:55:48.900 --> 00:55:51.900]   group that has been for a ride in Waymo comes out of it saying
[00:55:51.900 --> 00:55:54.340]   that is the future. This is going to absolutely dominate how
[00:55:54.340 --> 00:55:55.380]   I'm going to get around clearly.
[00:55:55.380 --> 00:55:59.780]   Most people say it's slow right now and monotonous, and they
[00:55:59.780 --> 00:56:02.100]   don't like it. But you know, because it does take weird
[00:56:02.100 --> 00:56:05.660]   routes, but that'll be fixed over time, obviously. And just
[00:56:05.660 --> 00:56:08.100]   in case anybody thinks I'm talking my book here, I have
[00:56:08.100 --> 00:56:10.860]   exposure to all these, almost all these companies in a
[00:56:10.860 --> 00:56:13.980]   significant way, because I believe in the entire space, one
[00:56:13.980 --> 00:56:17.420]   and a half percent of rides in the US. And globally, it's less
[00:56:17.420 --> 00:56:20.900]   than 1% are done by ride sharing. The TAM is going to go
[00:56:20.900 --> 00:56:25.180]   to 20% in a very short period of time. And it's going to be across
[00:56:25.180 --> 00:56:28.660]   the board, there's gonna be a lot of winners here. And to my
[00:56:28.660 --> 00:56:31.580]   favorite Uber, obviously, they have deals with eight people,
[00:56:31.580 --> 00:56:35.140]   and it's a global market BYD produces cars for half the price
[00:56:35.420 --> 00:56:38.620]   of any other car manufacturer, and they have full self driving
[00:56:38.620 --> 00:56:40.980]   and it's pretty darn good from what I understand. So this is
[00:56:40.980 --> 00:56:44.260]   going to be a global competition. And that means if
[00:56:44.260 --> 00:56:46.740]   you want to win that global competition, something like
[00:56:46.740 --> 00:56:50.900]   Uber and DoorDash, Waymo, Amazon, BYD, you're going to see
[00:56:50.900 --> 00:56:53.980]   some interesting partnerships happen very quickly, I believe,
[00:56:53.980 --> 00:56:56.420]   because there's so much at stake. All right, any final
[00:56:56.420 --> 00:56:58.980]   thoughts on biggest business deals? I think I maybe have a
[00:56:58.980 --> 00:57:02.580]   good one here. consolidation in the transportation space. Okay,
[00:57:02.940 --> 00:57:09.540]   moving on to 2025. Most contrarian belief. Last year,
[00:57:09.540 --> 00:57:12.780]   enterprise value of open AI goes down from tomorrow. It roughly
[00:57:12.780 --> 00:57:17.460]   doubled. But I just picked it as my prediction. We're sim we're
[00:57:17.460 --> 00:57:20.420]   simpatico on what we think long term freeberg. You said
[00:57:20.420 --> 00:57:23.060]   increased probability of a nuclear weapon being used for
[00:57:23.060 --> 00:57:26.700]   the first time since World War Two. Thank the Lord that that
[00:57:26.700 --> 00:57:28.900]   didn't happen. Again, this is contrarian beliefs. People are
[00:57:28.900 --> 00:57:30.860]   going out there. I didn't predict it was gonna happen. I
[00:57:30.860 --> 00:57:32.900]   just said the probability went up. It was it's a tough
[00:57:32.900 --> 00:57:33.940]   it's a tough thing to call.
[00:57:33.940 --> 00:57:36.660]   Well, this is most contrarian belief. I think it's fine. Dr.
[00:57:36.660 --> 00:57:39.860]   Doom strikes again. It's all good. I picked Apple would
[00:57:39.860 --> 00:57:42.660]   become the player in AI. And they did launch Apple
[00:57:42.660 --> 00:57:49.020]   intelligence. But it sucks. I mean, it sucks. It's terrible. I
[00:57:49.020 --> 00:57:54.660]   just bought the Google pixel fold nine. And the Gemini works
[00:57:54.660 --> 00:57:57.700]   perfectly. It does everything that Siri is supposed to do. If
[00:57:57.700 --> 00:58:01.660]   you say please play this song. If you say please download this
[00:58:01.660 --> 00:58:05.020]   app. If you say add this to my calendar, it does it and it does
[00:58:05.020 --> 00:58:09.900]   it in one fifth or 10th the amount of time that Apple takes.
[00:58:09.900 --> 00:58:15.220]   And Apple gets it wrong. Every time it's a piece of garbage.
[00:58:15.220 --> 00:58:18.100]   It's a disgrace. Disgrace the odd Apple.
[00:58:18.100 --> 00:58:21.500]   Apple intelligence is even worse than copilot which is saying
[00:58:21.500 --> 00:58:22.020]   something.
[00:58:22.020 --> 00:58:26.700]   Jason, would you like to announce? You bought the domain?
[00:58:27.180 --> 00:58:31.580]   Discuss the odd calm. I own it. I'm not selling it. Right now.
[00:58:31.580 --> 00:58:33.020]   If it redirects,
[00:58:33.020 --> 00:58:37.420]   Gavin, Gavin, do you have any direct to Jake what what word
[00:58:37.420 --> 00:58:41.900]   he's even saying when he says that discuss the odd? It's
[00:58:41.900 --> 00:58:46.540]   disgrace the odd is what people used to say in Brooklyn for
[00:58:46.540 --> 00:58:51.540]   somebody who is disgraceful. It is a Italian American slang.
[00:58:51.540 --> 00:58:52.660]   How do you spell it?
[00:58:52.660 --> 00:58:56.820]   No, you own the domain. You don't even know.
[00:58:57.180 --> 00:59:01.380]   D i s g r a z i a d discuss the odd.
[00:59:01.380 --> 00:59:06.100]   Yes. And if you type in discuss the odd, it goes to Jake Paul. I
[00:59:06.100 --> 00:59:08.740]   bought it when I was watching the Tyson fight. It was so
[00:59:08.740 --> 00:59:13.380]   disgraceful. I was saying to my brother Josh, the black bomber,
[00:59:13.380 --> 00:59:16.140]   this is just this and he just said discuss the odd and I just
[00:59:16.140 --> 00:59:18.860]   said I wonder if that's available as a domain. I'm
[00:59:18.860 --> 00:59:22.260]   redirecting discuss the odd right now Tim Cook to Apple
[00:59:22.260 --> 00:59:23.540]   intelligence the website.
[00:59:24.060 --> 00:59:27.500]   Do you guys think Tyson through that fight? That it was part of
[00:59:27.500 --> 00:59:27.980]   the deal?
[00:59:27.980 --> 00:59:32.860]   1000% Yeah, so great person. I would love I think somebody said
[00:59:32.860 --> 00:59:36.700]   Saudi Arabia was offering to host a remake or whatever, a
[00:59:36.700 --> 00:59:40.460]   redo, a rematch, a rematch of the fight, or the winner would
[00:59:40.460 --> 00:59:42.660]   make 50 million and then we'll see what's what.
[00:59:42.660 --> 00:59:46.020]   And the loser gets zero. Yeah, the loser gets zero. This is a
[00:59:46.020 --> 00:59:50.540]   good use of the kingdom's money. But people want to know we will
[00:59:50.540 --> 00:59:53.780]   all fly out there and do an all in episode from this.
[00:59:53.940 --> 00:59:57.580]   Did you see this thing? Where is it? Is it Logan Paul is fighting
[00:59:57.580 --> 01:00:01.860]   Conor McGregor in India, and Conor McGregor is going to get
[01:00:01.860 --> 01:00:07.980]   $250 million? What? Yeah, it's like, Oh, is it boxing? Or is it
[01:00:07.980 --> 01:00:11.620]   an MMR stunt? I think it's boxing and it's meant to sort of
[01:00:11.620 --> 01:00:14.180]   like bring a bunch of tourists into India to show them the
[01:00:14.180 --> 01:00:17.980]   country. But it's a quarter of a billion dollars to Conor. How
[01:00:17.980 --> 01:00:19.180]   did we get in on this grift?
[01:00:19.340 --> 01:00:24.180]   Freeberg versus Baker. Polly hoppity or versus Calacanis? Oh
[01:00:24.180 --> 01:00:27.620]   my gosh, we need to get in our own celebrity box. And who would
[01:00:27.620 --> 01:00:30.580]   we do? Come on, keep going. I gotta drive home. Let's go. Come
[01:00:30.580 --> 01:00:33.340]   on. It's fun this episode. chamath. What's your most
[01:00:33.340 --> 01:00:37.580]   contrarian belief prediction for 2025? We're going out on a limb
[01:00:37.580 --> 01:00:40.740]   here. This is going out on a limb, folks. Don't judge us. The
[01:00:40.740 --> 01:00:42.700]   spicier the take the better here. This is where you can go
[01:00:42.700 --> 01:00:43.380]   freestyle.
[01:00:43.380 --> 01:00:48.380]   I think that you're going to see a banking crisis in one of the
[01:00:48.380 --> 01:00:54.060]   major mainline banks. A banking crisis. Wow, there's a small
[01:00:54.060 --> 01:00:57.220]   chance it happens. But that's a contrarian belief. Okay. Why?
[01:00:57.220 --> 01:01:04.380]   Why? box one? Well, I think if I had to kind of build the the
[01:01:04.380 --> 01:01:08.580]   case for this, it would be along the following lines. If you add
[01:01:08.580 --> 01:01:14.660]   it up, the total indebtedness of Pax America, which is US
[01:01:14.660 --> 01:01:20.100]   government debt, plus corporates, plus mortgage debt.
[01:01:20.100 --> 01:01:29.500]   And you actually sensitize it to rates that are around, call it
[01:01:29.500 --> 01:01:37.340]   5%. What you quickly realize is on a dollar basis, that because
[01:01:37.340 --> 01:01:41.300]   the amount of debt that we have has just massively exploded.
[01:01:42.500 --> 01:01:49.420]   That 5% rates today on 70 odd trillion dollars is actually
[01:01:49.420 --> 01:01:55.220]   equivalent to 10% rates 25 or 30 years ago, because we only had a
[01:01:55.220 --> 01:02:00.060]   fraction of that debt on a dollar basis. And so the pain
[01:02:00.060 --> 01:02:04.020]   that you feel at five or 6% can very quickly ripple through the
[01:02:04.020 --> 01:02:08.580]   economy, the way that it did when rates 25 or 30 years ago
[01:02:08.580 --> 01:02:12.900]   were 10%. And so I think that when people look at rates, they
[01:02:12.900 --> 01:02:18.180]   forget the actual total dollar impact, because when somebody or
[01:02:18.180 --> 01:02:21.780]   collectively, when we have to come up with three or $4
[01:02:21.780 --> 01:02:25.980]   trillion, how do you do that? And so I think that there is a
[01:02:25.980 --> 01:02:28.820]   non trivial risk. I think it's small. This is why it's
[01:02:28.820 --> 01:02:32.660]   contrarian. But I think it's a, it's a risk where if you have a
[01:02:32.660 --> 01:02:39.220]   mark to market problem, if you have a credit default problem
[01:02:39.220 --> 01:02:42.140]   amongst the corporates, or amongst enough individual
[01:02:42.140 --> 01:02:47.980]   consumers, what I think that happens more than anything else
[01:02:47.980 --> 01:02:52.620]   is that it triggers a reserve issue. And I think that the
[01:02:52.620 --> 01:02:58.180]   reserve issue in one of these mainline banks, I have two that
[01:02:58.180 --> 01:03:00.700]   I think are more obvious than others, but I don't want to name
[01:03:00.700 --> 01:03:04.340]   them. Okay. Fair enough. I love this contraintake. This is
[01:03:04.340 --> 01:03:07.980]   great. I think that there's a there's a small but reasonable
[01:03:07.980 --> 01:03:10.300]   chance that that happens. I love it. It's a great, great
[01:03:10.300 --> 01:03:14.180]   contrarian take small chance, but big impact. Gavin, what do
[01:03:14.180 --> 01:03:16.580]   you got? Well, first, you want to respond, Jim and I deep
[01:03:16.580 --> 01:03:20.980]   research to just ask it to look at the total, you know, Pax
[01:03:20.980 --> 01:03:26.020]   Americana debt outstanding, apply the current market
[01:03:26.020 --> 01:03:30.380]   interest rate to it. And then look at that, you know, interest
[01:03:30.380 --> 01:03:33.500]   expense relative to GDP and generate that chart over time.
[01:03:33.500 --> 01:03:38.780]   That would be a cool chart. That would be interesting. I don't I
[01:03:38.780 --> 01:03:44.780]   don't, I don't disagree with Jamal. You know, any, anything is
[01:03:44.780 --> 01:03:49.780]   possible. And, you know, there, there could for sure be be a
[01:03:49.780 --> 01:03:53.100]   problem at a big bank. I don't know that I would say it's
[01:03:53.100 --> 01:03:56.180]   likely, but anything is possible. My most contrarian
[01:03:56.180 --> 01:04:00.060]   belief. So I think that America over the next, at some point
[01:04:00.060 --> 01:04:02.940]   over the next four years, will print at least one year of
[01:04:02.940 --> 01:04:08.540]   greater than 5% GDP growth, real GDP growth. I think
[01:04:08.540 --> 01:04:10.780]   productivity is going to go vertical because of AI and
[01:04:10.780 --> 01:04:15.460]   deregulation. And I think there could be a world where this is
[01:04:15.460 --> 01:04:19.540]   the late 90s. And it doesn't sound like a big difference, you
[01:04:19.540 --> 01:04:23.260]   know, five or 6% versus two or 3%. But it is a massive
[01:04:23.260 --> 01:04:28.300]   difference. You know, at five or 6%, you know, the economy is
[01:04:28.300 --> 01:04:34.100]   doubling. You'll call it every 12 years, roughly, first 24
[01:04:34.100 --> 01:04:38.300]   years at 3%. I mean, it's just it's a massive difference in
[01:04:38.300 --> 01:04:40.540]   terms of kind of the wealth of the country and individual
[01:04:40.540 --> 01:04:44.820]   Americans. As far as a specific prediction for 25, because I
[01:04:44.820 --> 01:04:47.140]   don't know when that will happen. I think you will see the
[01:04:47.140 --> 01:04:50.860]   frontier labs stop releasing their leading edge models to
[01:04:50.860 --> 01:04:54.420]   prevent knowledge distillation, and their IP effectively being
[01:04:54.420 --> 01:04:56.820]   stolen. You know, deep seek from China, it was really
[01:04:56.820 --> 01:05:02.740]   impressive. But I think such GPT four. Yeah. So I just think
[01:05:02.740 --> 01:05:06.020]   you will, you'll see the labs keep their best models in house,
[01:05:06.020 --> 01:05:11.140]   distill them and put small small models out. Over time.
[01:05:11.140 --> 01:05:14.100]   February, do you have a contrarian belief and I did put
[01:05:14.100 --> 01:05:17.060]   into Gemini advanced 1.5 pro with deep research, the
[01:05:17.060 --> 01:05:19.100]   question which banks have the greatest biggest chance of being
[01:05:19.100 --> 01:05:22.860]   insolvent, or having a financial collapse or crisis. So it's
[01:05:22.860 --> 01:05:24.780]   doing its research right now. It'll be done in about 10
[01:05:24.780 --> 01:05:27.900]   minutes, I think, which gives you an idea of how much research
[01:05:27.900 --> 01:05:29.060]   it does. It's nuts.
[01:05:29.060 --> 01:05:31.060]   February, what do you got?
[01:05:31.060 --> 01:05:36.220]   I think that the the party line is that socialism was defeated
[01:05:36.220 --> 01:05:41.420]   in this election cycle, and that there was a resounding kind of
[01:05:41.420 --> 01:05:45.540]   vote from the American populace against socialism. And I
[01:05:45.540 --> 01:05:48.460]   actually think my contrarian belief is that we'll see a rise
[01:05:48.460 --> 01:05:53.180]   a dramatic rise in socialist movements in 2025 in the United
[01:05:53.180 --> 01:05:56.540]   States. Okay, I think that we are going to see as Gavin
[01:05:56.540 --> 01:05:58.820]   pointed out an acceleration of progress, we're going to see an
[01:05:58.820 --> 01:06:04.420]   unleashing of economic growth, because of deregulation and AI.
[01:06:04.420 --> 01:06:08.500]   But I do think that some markets we've also talked about the
[01:06:08.500 --> 01:06:12.260]   downfall of us automate manufacturing, and some other
[01:06:12.260 --> 01:06:15.500]   industries, there's going to be a real significant shift in
[01:06:15.500 --> 01:06:19.100]   2025. Some industries and some companies are going to be huge
[01:06:19.100 --> 01:06:21.940]   winners, and some companies are going to be huge losers, there's
[01:06:21.940 --> 01:06:24.020]   going to be some parts of the economy that are going to be big
[01:06:24.020 --> 01:06:26.020]   winners, and some parts of the economy that are going to be big
[01:06:26.020 --> 01:06:29.660]   losers. When you have this sort of a change this fast, there are
[01:06:29.660 --> 01:06:32.900]   often large contingents of people that are left behind. And
[01:06:32.900 --> 01:06:35.820]   when that happens, I do think that the socialist policies and
[01:06:35.820 --> 01:06:40.420]   the socialist movements gain steam. When Peron came to power
[01:06:40.420 --> 01:06:45.340]   in Argentina, in the mid 1940s, that country was experiencing
[01:06:45.340 --> 01:06:50.060]   8% GDP growth to Gavin's point about accelerating growth. Growth
[01:06:50.100 --> 01:06:52.980]   does not mean that it benefits everyone equally. And I think
[01:06:52.980 --> 01:06:55.580]   that some folks will see people go from being billionaires to
[01:06:55.580 --> 01:06:58.940]   100 billionaires to the world's first trillionaire. And it will
[01:06:58.940 --> 01:07:02.100]   also start to fuel this rise. So I think that we will see an
[01:07:02.100 --> 01:07:04.820]   increase in the breadth and depth of socialist movements in
[01:07:04.820 --> 01:07:08.300]   the United States. By the way, particularly with doge cutting
[01:07:08.300 --> 01:07:11.060]   government funding to programs that benefit individuals,
[01:07:11.060 --> 01:07:14.180]   employment being cut in in the federal government and through
[01:07:14.180 --> 01:07:17.340]   federal contractors, there's just a lot of rapid change
[01:07:17.380 --> 01:07:19.980]   that's about to kind of really upset a lot of people.
[01:07:19.980 --> 01:07:24.940]   I totally agree. I think AI, you know, people are fond of saying
[01:07:24.940 --> 01:07:29.540]   that we're in a world of AGI or ASI, money will be meaningless.
[01:07:29.540 --> 01:07:33.660]   But for a short period of time, money will matter more than it's
[01:07:33.660 --> 01:07:37.460]   ever mattered before. Because the amount of money you can
[01:07:37.460 --> 01:07:43.660]   spend on AI on test time compute is going to give you a massive
[01:07:43.660 --> 01:07:46.100]   advantage, whether you're a company or an individual. So I
[01:07:46.100 --> 01:07:50.340]   just think AI is going to really amplify inequality for some
[01:07:50.340 --> 01:07:54.500]   period of time. Yeah, I hope I'm wrong. Like, I hope you know, AI
[01:07:54.500 --> 01:07:57.060]   leads to you know, all sorts of, you know, opportunities being
[01:07:57.060 --> 01:07:58.260]   created for a lot.
[01:07:58.260 --> 01:08:02.420]   There's just going to be a lot of employment and income
[01:08:02.420 --> 01:08:06.700]   disruption in 2025. And it's going to fuel socialist
[01:08:06.700 --> 01:08:09.060]   movements. And I think that this is going to be a more difficult
[01:08:09.060 --> 01:08:12.340]   year, everyone thinks it's kind of rosy red, because we're all
[01:08:12.340 --> 01:08:15.500]   working in the tech industry in Silicon Valley. But the reality
[01:08:15.500 --> 01:08:18.540]   on the ground for most Americans could be a lot harsher than any
[01:08:18.540 --> 01:08:21.500]   of us anticipate. And that could make for a very difficult
[01:08:21.500 --> 01:08:23.980]   political environment and social environment is a great
[01:08:23.980 --> 01:08:27.180]   contrarian prediction, freeberg, I would build on it that I don't
[01:08:27.180 --> 01:08:30.620]   think this is just going to hit blue collar. I'm seeing in the
[01:08:30.620 --> 01:08:34.020]   venture industry and in entrepreneurs, all over the
[01:08:34.020 --> 01:08:37.260]   place, people who are super qualified, who had six figure
[01:08:37.260 --> 01:08:40.580]   salaries, even to mid six figure salaries, not be able to find
[01:08:40.580 --> 01:08:43.380]   work, or not find work at previous compensation levels.
[01:08:43.620 --> 01:08:47.300]   Why? Because people are doing more with less, it's much better
[01:08:47.300 --> 01:08:52.100]   to invest and do deep research and AI and automate stuff or
[01:08:52.100 --> 01:08:56.900]   deprecate stuff, or delegate stuff to other regions than to
[01:08:56.900 --> 01:09:00.940]   hire Americans in some cases. And that philosophy that's
[01:09:00.940 --> 01:09:03.420]   happening isn't just going to hit truck drivers, it's going to
[01:09:03.420 --> 01:09:07.140]   hit developers, potentially designers, writers, or what is
[01:09:07.140 --> 01:09:09.980]   the contrarian part of what you guys are saying? What's the
[01:09:09.980 --> 01:09:13.460]   contrarian part socialism, socialism, socialism on the
[01:09:13.460 --> 01:09:13.980]   rise?
[01:09:13.980 --> 01:09:16.100]   It's pretty interesting.
[01:09:16.100 --> 01:09:18.940]   Because I think I don't think it's a trend. You think it's
[01:09:18.940 --> 01:09:22.300]   obvious? I think the party line has been that socialism was
[01:09:22.300 --> 01:09:26.020]   getting knocked back this year with this election cycle. And it
[01:09:26.020 --> 01:09:28.940]   was a mandate against socialism, and some of the socialist
[01:09:28.940 --> 01:09:32.100]   policies that were being put forth. And I think that the
[01:09:32.100 --> 01:09:34.820]   contrarian view is that we're actually got this really wrong.
[01:09:34.820 --> 01:09:37.060]   And socialism is going to be on a big rise.
[01:09:37.300 --> 01:09:40.220]   But just to build on what you said earlier, like, what woke
[01:09:40.220 --> 01:09:44.220]   ism and progressivism will decouple from socialism? I
[01:09:44.220 --> 01:09:48.500]   think woke ism and progressivism, you know, will be
[01:09:48.500 --> 01:09:51.020]   on a declining trend, but socialism in terms of the
[01:09:51.020 --> 01:09:55.860]   government, like policy? Yeah, yeah.
[01:09:55.860 --> 01:09:58.900]   Why don't we have universal? Why don't we have universal
[01:09:58.900 --> 01:10:02.060]   healthcare? Why don't we have pre k? Or, you know, in every
[01:10:02.060 --> 01:10:05.540]   state, and you know, these kind of things? I think Americans are
[01:10:05.540 --> 01:10:08.980]   right to ask those questions. Now, other behaviors are
[01:10:08.980 --> 01:10:11.540]   obviously abhorrent, but you do have the right to ask why we
[01:10:11.540 --> 01:10:14.620]   can't figure this out, and why our government has failed us in
[01:10:14.620 --> 01:10:18.860]   something as basic as, you know, providing after school programs
[01:10:18.860 --> 01:10:21.940]   or universal healthcare or universal childcare, these
[01:10:21.940 --> 01:10:25.220]   things are easy to do. And when you see everybody getting rich
[01:10:25.220 --> 01:10:27.780]   and the polarization of wealth, I can understand people saying,
[01:10:27.780 --> 01:10:30.580]   why don't we have these basic things when other countries have
[01:10:30.580 --> 01:10:31.340]   them? It's a reasonable
[01:10:31.340 --> 01:10:33.860]   you're making the assumptive statement that these things are
[01:10:33.860 --> 01:10:36.540]   easy to do, which was what was said about education. It's like,
[01:10:36.540 --> 01:10:39.940]   let's give everyone access to college education with the
[01:10:39.940 --> 01:10:42.980]   federal student loan programs. And what happened was, when we
[01:10:42.980 --> 01:10:46.660]   introduced those programs, those schools started to charge more,
[01:10:46.660 --> 01:10:49.460]   and the tuition went up every year. And eventually, the cost
[01:10:49.460 --> 01:10:52.180]   of education inflated away from the benefit you're getting from
[01:10:52.180 --> 01:10:54.980]   it. And this has happened universally in healthcare. It
[01:10:54.980 --> 01:10:58.180]   has happened in housing, it has happened in education, it has
[01:10:58.180 --> 01:11:03.300]   happened in every market where the government has stepped in to
[01:11:03.300 --> 01:11:06.900]   provide capital to support that market. The market basically no
[01:11:06.900 --> 01:11:08.300]   longer operates in a freeway.
[01:11:08.300 --> 01:11:11.060]   I appreciate the challenge to it. And I'll explain to you why
[01:11:11.060 --> 01:11:14.140]   I believe it's easy. If you just put this down to the states, and
[01:11:14.140 --> 01:11:16.460]   you make it more competitive, I think you solve the problem. If
[01:11:16.460 --> 01:11:19.380]   you introduce school vouchers, and you create competition, if
[01:11:19.380 --> 01:11:21.380]   you take universal healthcare, and maybe you run some
[01:11:21.380 --> 01:11:24.580]   experiments where different states get that money from the
[01:11:24.580 --> 01:11:27.860]   federal government, and let them run 50 different experiments, I
[01:11:27.860 --> 01:11:29.820]   think we could actually solve some of these problems. But
[01:11:29.820 --> 01:11:32.180]   you're correct. Anything that the federal government does, it
[01:11:32.180 --> 01:11:34.820]   eventually becomes corrupt and inefficient. My most contrarian
[01:11:34.820 --> 01:11:40.220]   belief was open AI loses its lead, loses its nonprofit to
[01:11:40.220 --> 01:11:43.780]   for profit transition and becomes the number four player
[01:11:43.780 --> 01:11:48.860]   in AI. The total collapse of open AI is my most contrarian
[01:11:48.860 --> 01:11:49.460]   prediction for
[01:11:49.460 --> 01:11:52.220]   that's a good one. The total collapse,
[01:11:52.220 --> 01:11:56.580]   doubling and tripling down. Hey, man, I'm trying to make this
[01:11:56.580 --> 01:11:59.340]   spicy. It's a spicy category. Let's do it. I got it. Yeah, I
[01:11:59.340 --> 01:12:02.660]   got it. I think he's great. I mean, he'll run for president.
[01:12:02.660 --> 01:12:05.580]   Jekyll. Maybe he's great. I don't know everybody who all his
[01:12:05.580 --> 01:12:08.900]   friends left the company. Maybe he's great. Maybe he's a stand
[01:12:08.900 --> 01:12:13.220]   up guy. I mean, everybody quit. But maybe he's Gavin. Are you
[01:12:13.220 --> 01:12:15.100]   familiar with Jekyll's prediction that Jeff Bezos is
[01:12:15.100 --> 01:12:18.740]   gonna run for president? It was that was my predicting I wanted
[01:12:18.740 --> 01:12:22.220]   him to I wanted to and he bought Washington Post and he quit the
[01:12:22.220 --> 01:12:26.260]   Amazon job. And he bought a house in Washington, DC. And he
[01:12:26.260 --> 01:12:30.340]   went down to Mar-a-Lago. Don't be surprised if Bezos after he
[01:12:30.340 --> 01:12:34.820]   gets through his midlife crisis and going to Coachella and
[01:12:34.820 --> 01:12:37.980]   partying and having a great time which he deserves. If he comes
[01:12:37.980 --> 01:12:39.820]   back and says you know what, I want to serve my country. I
[01:12:39.820 --> 01:12:40.100]   still
[01:12:40.100 --> 01:12:42.980]   post or do you think he's gonna hold on to it?
[01:12:42.980 --> 01:12:45.500]   Well, let's stick with that one because
[01:12:45.500 --> 01:12:49.780]   Jeff Bezos will sell the Washington Post in 2025. That's
[01:12:49.780 --> 01:12:52.260]   a good poly market. Yeah, sell it to Kara Swisher and sell it
[01:12:52.260 --> 01:12:57.780]   to Karen Swisher. Right into the ground. They'll double down.
[01:12:57.780 --> 01:13:02.340]   Okay, best performing asset. Everybody loves this one best
[01:13:02.340 --> 01:13:05.700]   performing asset. Hey, we can we can put a price on this best
[01:13:05.700 --> 01:13:08.340]   performing asset last year. Chamath did a spread trade. He
[01:13:08.340 --> 01:13:12.300]   was long public tech stocks, short private late stage tech
[01:13:12.300 --> 01:13:17.300]   stock index. NASDAQ top 100 tech stock ETF was up 10% 2024
[01:13:17.300 --> 01:13:21.540]   Freiburg. You went with your uranium ETF, not Uranus,
[01:13:21.540 --> 01:13:27.700]   Uranium ETF, and your a URA was down 1% in 2024.
[01:13:27.700 --> 01:13:32.020]   You know what, I looked at the components of that ETF last
[01:13:32.020 --> 01:13:35.340]   week when we were preparing for this. It has absolute junk in
[01:13:35.340 --> 01:13:38.860]   it. Like it was not the right, the right right way to kind of
[01:13:38.860 --> 01:13:44.780]   trade uranium. But anyway, that was my my outcome for the year.
[01:13:44.780 --> 01:13:49.140]   I went with the on demand economy with Uber, Airbnb and
[01:13:49.140 --> 01:13:52.740]   DoorDash. Uber was up 30%. But now it's only up 3% with the
[01:13:52.740 --> 01:13:56.700]   robo taxi headwind. Airbnb is basically flat. And DoorDash up
[01:13:56.700 --> 01:14:00.220]   big 74% shout out to Stanley Tang. Great job to the team over
[01:14:00.220 --> 01:14:02.940]   there. So Chamath get your flowers there. Let's do our best
[01:14:02.940 --> 01:14:06.020]   performing asset. Let's let our guests go first. Gavin, what
[01:14:06.020 --> 01:14:08.820]   would be the best performing asset of 2025?
[01:14:08.820 --> 01:14:13.060]   I think the companies that make high bandwidth memory, going
[01:14:13.060 --> 01:14:17.980]   back to we're gonna we're gonna run out of compute. It's, it's,
[01:14:17.980 --> 01:14:23.860]   it's actually a pretty shocking stat. high bandwidth memory is a
[01:14:23.860 --> 01:14:28.540]   bigger part of NVIDIA's cogs on GPUs than Taiwan sim is. And
[01:14:28.540 --> 01:14:31.860]   today, there's two companies that can make it. Hynix and
[01:14:31.860 --> 01:14:35.860]   Micron. We'll see if Samsung gets their act together. But
[01:14:35.860 --> 01:14:43.220]   HBM memory, it's an NVIDIA GPUs, AMD GPUs, Amazon Triniums. And
[01:14:43.220 --> 01:14:47.060]   particularly in a world of test time compute, and inference,
[01:14:47.060 --> 01:14:51.700]   being so important. high bandwidth memory is arguably
[01:14:51.700 --> 01:14:57.020]   more important than it ever was. And it's been, it's been sold
[01:14:57.020 --> 01:14:59.940]   out for the last two years. So high bandwidth memory would be
[01:14:59.940 --> 01:15:05.380]   my pick. Okay, good pick. Great pick. In fact, what do you got
[01:15:05.380 --> 01:15:09.180]   Shema? So let me preface this by saying that this is a pick
[01:15:09.180 --> 01:15:22.380]   that 92 times out of 100 goes to absolute zero. Okay. And six out
[01:15:22.380 --> 01:15:28.540]   of the remaining eight times, you make 10 extra money. And
[01:15:28.540 --> 01:15:31.780]   then the final two times you make anywhere between 100 to 1000
[01:15:31.780 --> 01:15:36.260]   extra money. Okay, sounds like okay, so it this is a loser
[01:15:36.260 --> 01:15:44.500]   trade. Okay. But I would be long CDS. So what am I buying? I am
[01:15:44.500 --> 01:15:48.900]   buying insurance, I'm buying insurance. Using credit default
[01:15:48.900 --> 01:15:52.980]   swaps, I'm buying what's called protection, that there is no
[01:15:52.980 --> 01:15:59.820]   default event in 2025. Again, I'm not going to tell you which
[01:15:59.860 --> 01:16:05.740]   companies or what maturities but just the general idea for me is
[01:16:05.740 --> 01:16:11.180]   I would like a little bit of an insurance policy in 2025. So
[01:16:11.180 --> 01:16:14.860]   that the men and the women that we have voted in have the chance
[01:16:14.860 --> 01:16:19.380]   to do their work in peace. I think that there is a small
[01:16:19.380 --> 01:16:25.700]   chance of some volatility next year. I hope it doesn't happen.
[01:16:25.700 --> 01:16:28.980]   I hope that this trade, like I said, 92 times out of 100 loses
[01:16:28.980 --> 01:16:34.060]   money. I hope it loses money. But if it hits, it will be the
[01:16:34.060 --> 01:16:37.140]   best performing asset of 2025. It will be the equivalent of
[01:16:37.140 --> 01:16:42.060]   Ackman buying CDS right at the right at the beginning of the
[01:16:42.060 --> 01:16:45.540]   COVID crisis. How does one buy those, you have to have an ISDA,
[01:16:45.540 --> 01:16:48.420]   you talk to the big investment banks, and they'll price it out
[01:16:48.420 --> 01:16:51.260]   for you. But again, I just want to be clear, this is not
[01:16:51.260 --> 01:16:53.660]   something I think will happen. It's not something I want to
[01:16:53.660 --> 01:16:58.780]   happen. But I do think that if you look back, in terms of just
[01:16:58.780 --> 01:17:02.060]   the tonnage of dollars you can make, and the massive risk
[01:17:02.060 --> 01:17:05.220]   asymmetry that it presents to you, when you look at the
[01:17:05.220 --> 01:17:08.380]   concentration of the S&P, when you look at just the total gross
[01:17:08.380 --> 01:17:13.300]   amount of debt that we have, when you look at rate spiking,
[01:17:13.300 --> 01:17:18.180]   all of these things, say having a little insurance may not be a
[01:17:18.180 --> 01:17:20.420]   bad thing. So I hope
[01:17:20.420 --> 01:17:23.140]   Gavin, you're nodding. Gavin, you're nodding. You want to
[01:17:23.140 --> 01:17:25.980]   know, I was just I was just thinking, I mean, if you're, if
[01:17:26.340 --> 01:17:29.420]   Chamath's prediction of a bank failure is true, you absolutely
[01:17:29.420 --> 01:17:34.300]   want to own CDS. Yeah, I mean, you'll forget 100x, you'll get
[01:17:34.300 --> 01:17:35.900]   1000x, 10,000x.
[01:17:35.900 --> 01:17:36.980]   What do you got, Freeberg?
[01:17:36.980 --> 01:17:46.540]   So I went with Chinese tech stocks, Chinese tech ETFs.
[01:17:46.540 --> 01:17:47.820]   Wow.
[01:17:47.820 --> 01:17:50.220]   I think that the market, everyone's kind of dumped
[01:17:50.220 --> 01:17:52.980]   Chinese tech stocks over the last couple of years. Everyone's
[01:17:52.980 --> 01:17:56.700]   taken this isolationary stance on positioning portfolios and
[01:17:56.700 --> 01:17:59.860]   saying, hey, we can't do business with China, it's over.
[01:17:59.860 --> 01:18:03.780]   But I do think that the Trump administration, particularly with
[01:18:03.780 --> 01:18:07.140]   their recent request on TikTok being the ban on TikTok being
[01:18:07.140 --> 01:18:10.500]   kind of halted. They're trying to line up what I would call
[01:18:10.500 --> 01:18:13.380]   kind of like, the great deal with China. So I don't know
[01:18:13.380 --> 01:18:16.020]   anything about what they're actually trying to do. But I
[01:18:16.020 --> 01:18:21.420]   think that Trump and leadership in the US government want to
[01:18:21.420 --> 01:18:24.420]   kind of open up the Chinese market to American companies in
[01:18:24.420 --> 01:18:27.140]   order to give Chinese companies access to the American market.
[01:18:27.140 --> 01:18:29.780]   And I think that they're going to get a deal done given the
[01:18:29.780 --> 01:18:32.020]   position with China. I think that they're very likely to kind
[01:18:32.020 --> 01:18:34.900]   of get a deal done. That's one driver. I think there's three
[01:18:34.900 --> 01:18:37.220]   drivers. The second driver is that obviously, the cost of
[01:18:37.220 --> 01:18:39.580]   build out of electricity production in China is
[01:18:39.580 --> 01:18:43.660]   unfathomable. They recently approved $137 billion hydro
[01:18:43.660 --> 01:18:46.780]   electric dam facility, which is going to add another, I think
[01:18:46.780 --> 01:18:49.940]   couple hundred gigawatts of electricity production in that
[01:18:49.940 --> 01:18:52.620]   country, not to mention all the nuclear build out we've talked
[01:18:52.620 --> 01:18:55.540]   about in the past. So the cost per kilowatt hour is already
[01:18:55.540 --> 01:18:59.060]   lower, the amount of electricity available is going up. And then
[01:18:59.060 --> 01:19:01.900]   I think that the Chinese Communist Party have this
[01:19:01.900 --> 01:19:05.500]   incredible ability to throttle up and down free markets and
[01:19:05.500 --> 01:19:08.540]   entrepreneurship. And this is a moment where you could kind of
[01:19:08.540 --> 01:19:11.700]   see them making the throttle go the way towards enabling more
[01:19:11.700 --> 01:19:14.580]   innovation, more free market activity, and it's going to be
[01:19:14.580 --> 01:19:17.140]   one of the motivators for them to do a deal. So when you put
[01:19:17.140 --> 01:19:19.740]   all of this together, I do think that there's a lot of Chinese
[01:19:19.780 --> 01:19:22.620]   tech companies that have been beat up under the assumption
[01:19:22.620 --> 01:19:25.580]   that this is going to be a very difficult conflict with the US
[01:19:25.580 --> 01:19:28.340]   in the years ahead. And I think that that may not be the case,
[01:19:28.340 --> 01:19:31.180]   going into 25. And I think that there, these stocks are pretty
[01:19:31.180 --> 01:19:33.900]   cheap. I was just looking at Alibaba, and it trades at a
[01:19:33.900 --> 01:19:37.340]   pretty decent multiple. It seems like these stocks could be
[01:19:37.340 --> 01:19:41.140]   poised for a pretty good run in 25. If the macro works out,
[01:19:41.140 --> 01:19:45.260]   it feels like a contrarian take. I mean, Trump, I don't think is
[01:19:45.260 --> 01:19:49.260]   going to find a way to balance the relationship with China very
[01:19:49.260 --> 01:19:52.420]   well. And I don't think you can rattle up entrepreneurship after
[01:19:52.420 --> 01:19:56.100]   you cut everybody's knees out the last time. Plus, I don't
[01:19:56.100 --> 01:19:58.820]   trust any accounting statement coming out of China because they
[01:19:58.820 --> 01:20:03.340]   could fudge whatever they want. But wow, what a great potential,
[01:20:03.340 --> 01:20:05.260]   you know, buy low sell high.
[01:20:05.260 --> 01:20:08.060]   The good thing is, you'll know, you'll know if I'm right or
[01:20:08.060 --> 01:20:08.860]   wrong in a year, you can
[01:20:08.860 --> 01:20:11.900]   exactly, we'll know exactly. That's right. Pull the ETF.
[01:20:11.900 --> 01:20:14.820]   Absolutely. Yeah. Gavin, what do you think of this hot take here?
[01:20:14.820 --> 01:20:16.420]   From from Mr. Freeberg?
[01:20:16.780 --> 01:20:21.180]   Really cheap. I've had a I would call it a no China guideline
[01:20:21.180 --> 01:20:24.500]   ever since the long top financial fraud more than 15
[01:20:24.500 --> 01:20:29.860]   years ago. Or it's just amazing. It was, you know, a lot of great
[01:20:29.860 --> 01:20:35.500]   investors owned it. And, you know, they, they talked a great
[01:20:35.500 --> 01:20:39.500]   game. And they had a Western auditor, but then it turned out
[01:20:39.500 --> 01:20:44.500]   that the fraud was happening at the local post office, where
[01:20:44.500 --> 01:20:47.500]   they're opening up the documents that the local auditors had
[01:20:47.500 --> 01:20:51.140]   signed off on changing them, and then sending different documents,
[01:20:51.140 --> 01:20:55.660]   you know, whatever, FedExing them. Yeah, so I just think it's
[01:20:55.660 --> 01:20:58.620]   it's a hard place if you're I think if you're not Chinese to
[01:20:58.620 --> 01:21:04.300]   make money. But I tend to agree with a lot of what David said, I
[01:21:04.300 --> 01:21:07.340]   think Trump and she both want to deal I think there's a deal to
[01:21:07.340 --> 01:21:13.260]   be done that leaves Putin out in the cold, as I referenced. And
[01:21:13.260 --> 01:21:15.980]   if that happens, Katie bar the door. I mean, they're really,
[01:21:15.980 --> 01:21:19.460]   really high quality companies, you know, that are some of them
[01:21:19.460 --> 01:21:21.220]   are mid single digit multiples.
[01:21:21.220 --> 01:21:24.140]   And they're and it's a big market. So if you did get it,
[01:21:24.140 --> 01:21:27.260]   right, and you do Chinese, Chinese companies serve a global
[01:21:27.260 --> 01:21:31.820]   market. It's not just the US they serve, you know, Africa,
[01:21:31.820 --> 01:21:34.620]   South America, Austria, I mean, the whole Southern Hemisphere.
[01:21:34.620 --> 01:21:38.500]   Well, yeah, you look at BYD. That's all over Europe. It's
[01:21:38.500 --> 01:21:41.940]   yeah, yeah. It's yeah, no, look, I mean, I mean, the Chinese
[01:21:41.940 --> 01:21:46.100]   companies and they have the best unit economics, they have the
[01:21:46.100 --> 01:21:49.540]   best cost of production. I mean, everything is advantaged,
[01:21:49.540 --> 01:21:53.220]   particularly if you believe it's the year of the robot, there's
[01:21:53.220 --> 01:21:56.340]   going to be kind of a massive demand around the world for
[01:21:56.340 --> 01:22:00.740]   automation. And for rebuilding manufacturing capacity all over
[01:22:00.740 --> 01:22:03.100]   the world. And I think that China could service those
[01:22:03.100 --> 01:22:06.220]   markets more efficiently than any other kind of country of
[01:22:06.220 --> 01:22:09.340]   origin. So it's a pretty, pretty powerful set of macro
[01:22:09.340 --> 01:22:10.180]   drivers as well.
[01:22:10.180 --> 01:22:13.140]   I think the max seven is going to be the best performing asset
[01:22:13.140 --> 01:22:15.420]   and take the other side, Chamath, I think in an earlier
[01:22:15.420 --> 01:22:19.060]   prediction said maybe not so much. I think that what they've
[01:22:19.060 --> 01:22:22.340]   learned in the last couple of years is that there is an
[01:22:22.340 --> 01:22:26.580]   incredible earnings expansion you can do by not hiring people
[01:22:26.580 --> 01:22:29.500]   and outsourcing jobs to other parts of the world and
[01:22:29.500 --> 01:22:33.540]   automating and the gains we'll see from AI, which they're
[01:22:33.540 --> 01:22:37.020]   producing for other companies and for consumers, they're
[01:22:37.020 --> 01:22:41.220]   applying first internally. So the internal application of AI
[01:22:41.220 --> 01:22:44.860]   will allow these companies to have earnings growth that people
[01:22:44.860 --> 01:22:48.260]   will not be able to comprehend over the next couple of years.
[01:22:48.260 --> 01:22:52.140]   So I'm going with max seven. We got a lot of different takes
[01:22:52.140 --> 01:22:55.940]   here going different directions. What a great episode so far.
[01:22:55.940 --> 01:23:00.380]   Alright, worst performing asset last year, Chamath said late
[01:23:00.380 --> 01:23:03.220]   stage tech stock index, mostly SAS, Freeberg, you put in a
[01:23:03.220 --> 01:23:07.220]   brilliant spread trade, short vertical SAS, long AI cloud
[01:23:07.220 --> 01:23:11.620]   providers, SAS has had a little bit of a rebound. But Google up
[01:23:11.620 --> 01:23:16.300]   30% for 6% for AI Cloud, Microsoft 14%, Amazon 46% all in
[01:23:16.300 --> 01:23:21.580]   2024. I said LLM startups like OpenAI Anthropic, too many
[01:23:21.580 --> 01:23:25.820]   players open sourcing will kill pricing. Obviously, the one
[01:23:25.820 --> 01:23:29.860]   valuation we can track is OpenAI and it doubled. But I didn't go
[01:23:29.860 --> 01:23:34.460]   long term have that one work worst performing asset of 2025
[01:23:34.460 --> 01:23:34.860]   Gavin
[01:23:34.860 --> 01:23:38.180]   enterprise application software. Okay, this is basically just
[01:23:38.180 --> 01:23:42.660]   about my 2025 is going to be I think the year of agents,
[01:23:42.660 --> 01:23:47.100]   particularly in the second half agents just being AI models that
[01:23:47.100 --> 01:23:50.220]   can take action on your behalf, that can do anything online that
[01:23:50.220 --> 01:23:55.620]   a human can do online. And if the labs and the big cloud
[01:23:55.620 --> 01:24:00.620]   providers dominate agents, which seems likely going back to, you
[01:24:00.620 --> 01:24:05.500]   know, the, the low cost producer is going to win. Enterprise
[01:24:05.500 --> 01:24:07.900]   application software, I think is going to be in a lot of pain.
[01:24:07.900 --> 01:24:11.460]   And, you know, some of these companies are talking a big, big
[01:24:11.460 --> 01:24:14.540]   game about agents. But at the end of the day, they don't have
[01:24:14.540 --> 01:24:20.260]   their own models, they don't own their own compute. And I just
[01:24:20.260 --> 01:24:23.580]   don't see them being ultimate winners in the world of agents.
[01:24:23.580 --> 01:24:27.420]   You know, I could easily, I could be wrong, because they do,
[01:24:27.420 --> 01:24:31.300]   you know, they, they, they have some customer data, maybe a
[01:24:31.300 --> 01:24:34.780]   little bit of a data moat. And they do, you know, have strong
[01:24:34.780 --> 01:24:37.100]   customer relationships. But you know, most companies have
[01:24:37.100 --> 01:24:40.500]   relationships with AWS, Google or Microsoft as well. So I think
[01:24:40.500 --> 01:24:42.620]   enterprise application software will be in pain.
[01:24:42.620 --> 01:24:46.220]   Okay, and trim off, what do you got?
[01:24:46.220 --> 01:24:50.100]   I think Gavin just absolutely nailed it. I'm going to double
[01:24:50.100 --> 01:24:56.420]   down on what he said. I think that there's a term that that we
[01:24:56.420 --> 01:24:59.140]   will start to use more, I started to use it internally at
[01:24:59.140 --> 01:25:03.620]   8090. Over this last year in 2024, which is the software
[01:25:03.620 --> 01:25:09.980]   industrial complex. These are these large bloated, in many
[01:25:09.980 --> 01:25:14.100]   cases, enterprise software companies that effectively have
[01:25:14.100 --> 01:25:19.100]   convinced incredible numbers of organizations to spend a
[01:25:19.100 --> 01:25:23.780]   tremendous amount of money, essentially wrapping a bunch of
[01:25:23.780 --> 01:25:27.340]   heuristics and business rules around a CRUD database. And
[01:25:27.340 --> 01:25:30.980]   along with that, what they have perfected really is a go to
[01:25:30.980 --> 01:25:35.300]   market and sales motion. The golf trips, the steak dinners,
[01:25:35.300 --> 01:25:38.300]   you know, we mentioned this before what Alex Karp railed
[01:25:38.300 --> 01:25:45.020]   against. None of those things equate to product value. And
[01:25:45.020 --> 01:25:50.340]   increasingly, in the world of agentic software and AI, I think
[01:25:50.340 --> 01:25:52.820]   that you can rebuild a lot of these workflows in very
[01:25:52.820 --> 01:25:56.500]   efficient ways. And I think the go to market is going to be
[01:25:56.500 --> 01:26:01.420]   driven by CEOs and CFOs, who start to exert a little bit more
[01:26:01.420 --> 01:26:06.900]   pressure on their CIOs to manage spend. And in that world, I just
[01:26:06.900 --> 01:26:10.820]   think that these next generation AI businesses are built,
[01:26:10.820 --> 01:26:15.300]   frankly, an order of magnitude cheaper than the companies that
[01:26:15.300 --> 01:26:18.100]   they compete against. And so even if it's just feature for
[01:26:18.100 --> 01:26:21.660]   feature the same, I think the software industrial complex,
[01:26:21.660 --> 01:26:27.460]   these old mainline, traditional enterprise software companies, I
[01:26:27.460 --> 01:26:29.460]   think you're going to start to see fissures in those
[01:26:29.460 --> 01:26:32.660]   businesses in 2025. So I, I agree with Gavin, different
[01:26:32.660 --> 01:26:33.940]   words, but same result.
[01:26:33.940 --> 01:26:37.700]   And you put your time and money where your mouth is on this one
[01:26:37.740 --> 01:26:41.500]   11 months ago, you found it 8090, to get 80%.
[01:26:41.500 --> 01:26:47.220]   The traction in, in less than a year, to me is shocking. And I
[01:26:47.220 --> 01:26:49.420]   don't think it speaks necessarily, I think we're
[01:26:49.420 --> 01:26:53.980]   decent, we're very good, we have great engineers. But my 30%
[01:26:53.980 --> 01:26:57.100]   engineering team, I think does the work of 300 people by next
[01:26:57.100 --> 01:27:00.340]   year, it'll be doing the work of 3000 people, maybe we'll only
[01:27:00.340 --> 01:27:04.820]   grow by 10 or 20%. So and the reason is we use these tools,
[01:27:05.380 --> 01:27:08.500]   we're productive to an order of magnitude that I didn't think
[01:27:08.500 --> 01:27:12.140]   was possible. And as a result, we're just able to price it
[01:27:12.140 --> 01:27:16.020]   differently. So even if it's the exact same product, its cost
[01:27:16.020 --> 01:27:19.420]   structure is just meaningfully lower. And so this is what I
[01:27:19.420 --> 01:27:23.020]   mean, where the ROI calculators get blown up, all of the
[01:27:23.020 --> 01:27:26.660]   traditional go to market motions get blown up, because in an RFP
[01:27:26.660 --> 01:27:29.820]   or in any other sales environment, what you do is
[01:27:29.820 --> 01:27:34.420]   somebody says it's $100, and you show up and you say, 10. Okay,
[01:27:34.460 --> 01:27:36.580]   and at 10, it's still hugely profitable for you.
[01:27:36.580 --> 01:27:40.900]   And just to add, just one last thing is just, you know,
[01:27:40.900 --> 01:27:43.420]   fundamentally, these enterprise application software companies,
[01:27:43.420 --> 01:27:45.580]   the software industrial complex, and I agree with everything
[01:27:45.580 --> 01:27:48.860]   Jamal said, you know, they're, they're fundamentally based on
[01:27:48.860 --> 01:27:53.580]   making white collar human employees more efficient. And
[01:27:53.580 --> 01:27:55.900]   what the AI companies are going to do is just say, hey, we're
[01:27:55.900 --> 01:27:58.260]   just going to replace that worker. And it's just a
[01:27:58.260 --> 01:28:03.740]   fundamentally different mentality. And it goes to like,
[01:28:03.780 --> 01:28:06.740]   there may be a lot of pain that accompanies this. And you know,
[01:28:06.740 --> 01:28:09.980]   David's points around the, you know, potential rise of, of
[01:28:09.980 --> 01:28:10.780]   socialism.
[01:28:10.780 --> 01:28:14.940]   What do you got for worst performing asset? Mr. Friedberg?
[01:28:14.940 --> 01:28:17.660]   2020, I'm probably just going to triple underline vertical SAS
[01:28:17.660 --> 01:28:21.660]   again, perceived pricing model being challenged. Pricing being
[01:28:21.660 --> 01:28:25.340]   compressed as companies explore in house tools built with AI
[01:28:25.340 --> 01:28:29.100]   that replaces these kind of traditional business practices.
[01:28:29.420 --> 01:28:30.780]   Most are going to be destroyed.
[01:28:30.780 --> 01:28:36.380]   Yeah, geez, this is obvious. It was an it was an obvious one on
[01:28:36.380 --> 01:28:38.540]   my list. But I want to make a different one. I want to make a
[01:28:38.540 --> 01:28:41.060]   different one. How about open AI? Do you have anything open AI?
[01:28:41.060 --> 01:28:45.900]   No, no, no open eyes. Tell me why people laugh. But you know,
[01:28:45.900 --> 01:28:48.300]   I don't know where they are. Where do all the Where are they
[01:28:48.300 --> 01:28:50.460]   all the other open AI employees? Are they on vacation? They're
[01:28:50.460 --> 01:28:51.220]   skiing too, right?
[01:28:51.220 --> 01:28:53.180]   They've all started competitors.
[01:28:53.180 --> 01:28:56.220]   Oh, right. That's what happened. Correct. Yeah, they all left to
[01:28:56.220 --> 01:28:58.300]   compete and have revenge startups. Wow, that's an
[01:28:58.300 --> 01:29:02.100]   interesting trend. Okay. So consumers make five big
[01:29:02.100 --> 01:29:05.140]   decisions in their life, as we all know, there's 12 billion
[01:29:05.140 --> 01:29:07.860]   revenue. I mean, well, that's that's a projection.
[01:29:07.860 --> 01:29:13.020]   6 billion in losses to David against that 12 billion in
[01:29:13.020 --> 01:29:14.020]   revenue. Yeah,
[01:29:14.020 --> 01:29:15.860]   6 billion this year, 6 billion next year.
[01:29:15.860 --> 01:29:20.020]   I think the six is for next year. But I Yeah, I don't know.
[01:29:20.020 --> 01:29:22.460]   I guess it makes sense why they're trying to charge 200
[01:29:22.460 --> 01:29:26.180]   bucks a month now. Up from 20. They got some headwinds. Okay.
[01:29:26.460 --> 01:29:29.180]   Listen, consumers make five big decisions in their life. We know
[01:29:29.180 --> 01:29:33.460]   college spouse kids are the obvious ones, and then cars and
[01:29:33.460 --> 01:29:38.100]   homes, and the consumer is up against it with record debt. So
[01:29:38.100 --> 01:29:41.820]   since you can't trade college spouse kids, really, I think
[01:29:41.820 --> 01:29:45.100]   legacy car companies and real estate are going to face
[01:29:45.100 --> 01:29:49.420]   continued headwinds and be terrible assets. Because listen,
[01:29:49.420 --> 01:29:52.300]   we've overbuilt in some cases, there's tons of cars on lots.
[01:29:52.300 --> 01:29:55.020]   And people can't afford homes with these mortgages. So I think
[01:29:55.020 --> 01:29:58.220]   these are going to be the two worst performing asset are
[01:29:58.220 --> 01:30:01.180]   people in the legacy OEMs, as Chamath pointed out in a
[01:30:01.180 --> 01:30:03.620]   previous prediction. And then I just think real estate is the
[01:30:03.620 --> 01:30:06.300]   same. If you look at a place like Texas, two years in a row,
[01:30:06.300 --> 01:30:08.940]   housing values have gone down, rent has gone down two years in
[01:30:08.940 --> 01:30:11.380]   a row, same things happening in other states where they allowed
[01:30:11.380 --> 01:30:13.660]   you to build and people are leaving states where they don't
[01:30:13.660 --> 01:30:16.140]   allow you to build. So that's my worst performing asset trade.
[01:30:16.140 --> 01:30:18.980]   Enterprise was my other choice, but I'll go with something
[01:30:18.980 --> 01:30:22.420]   slightly different. Most anticipated trend for 2025. Last
[01:30:22.420 --> 01:30:25.740]   year, Chamath, congratulations. You said last year, that
[01:30:25.740 --> 01:30:29.300]   Bitcoin would hit 100k for the first time, nailed it half court
[01:30:29.300 --> 01:30:32.180]   shot. Well done. I think at the time you made that prediction,
[01:30:32.180 --> 01:30:35.060]   it was probably trading, it felt like a layup, felt like a layup
[01:30:35.060 --> 01:30:38.980]   to you up 112%. Freeberg, you said predictive models and AI
[01:30:38.980 --> 01:30:41.780]   driven discovery and pharma and bioengineering. How did that do
[01:30:41.780 --> 01:30:42.460]   that prediction?
[01:30:42.460 --> 01:30:47.300]   Well, there was a lot of funding and Dennis won the Nobel Prize.
[01:30:47.300 --> 01:30:49.300]   Yeah, so it worked out.
[01:30:49.300 --> 01:30:52.340]   I picked efficiency in the form of AI advancements in labor and
[01:30:52.340 --> 01:30:55.900]   outsourcing. And I've seen that a bunch with our investment in
[01:30:55.900 --> 01:30:59.940]   Athena, go to Athena.com. Okay, got my plug in there. Let's go
[01:30:59.940 --> 01:31:02.820]   for most anticipated 2025 trend. What do you got Chamath?
[01:31:02.820 --> 01:31:08.460]   I think that there are a handful of not to overuse and overuse
[01:31:08.460 --> 01:31:11.660]   term, but canaries in the coal mine for the end of the deep
[01:31:11.660 --> 01:31:20.540]   state. And I would like to point to one, which is this obscure
[01:31:21.140 --> 01:31:26.140]   thing called the supplemental loss ratio. And essentially what
[01:31:26.140 --> 01:31:34.500]   it is, is a mechanism that the banks can use to include or not
[01:31:34.500 --> 01:31:37.140]   include treasuries and how they calculate reserves, etc, etc.
[01:31:37.140 --> 01:31:40.260]   Now, why is this an interesting thing? It's not interesting for
[01:31:40.260 --> 01:31:48.020]   many people. It's very arcane. But if we are unable to manage
[01:31:48.020 --> 01:31:54.900]   the debt situation, in 2025, I think what you're going to see
[01:31:54.900 --> 01:32:00.340]   is maneuvering at the edges of these arcane regulations that
[01:32:00.340 --> 01:32:05.700]   effectively kick the can down the road. And there is a chance
[01:32:05.700 --> 01:32:10.140]   that that could happen to help the banks. Because, you know, we
[01:32:10.140 --> 01:32:14.300]   believe that we meaning collectively America, that maybe
[01:32:14.300 --> 01:32:17.140]   doge won't be as effective as it needs to be that they're still
[01:32:17.140 --> 01:32:20.460]   going to need to be, you know, 10 $20 trillion of debt issuance
[01:32:20.460 --> 01:32:24.140]   to refinance the 10 that's maturing this year and to plug
[01:32:24.140 --> 01:32:28.580]   holes in the coming years. My point in all of this is we don't
[01:32:28.580 --> 01:32:35.180]   need to understand the details, except that if we don't move the
[01:32:35.180 --> 01:32:42.780]   goalposts here, it is a great sign that the folks that are
[01:32:42.780 --> 01:32:46.060]   running the show are the ones that we all elected. Okay, so
[01:32:46.060 --> 01:32:51.020]   that is my most anticipated trend, small, arcane regulatory
[01:32:51.020 --> 01:32:54.020]   changes that allow us to kick the can down the road stop in
[01:32:54.020 --> 01:32:56.180]   its tracks. This is an example.
[01:32:56.180 --> 01:32:58.660]   Okay, freeberg, you got a most anticipated trend for 2025.
[01:32:58.660 --> 01:33:03.860]   My most anticipated trend is around the announcement of
[01:33:03.860 --> 01:33:08.500]   buildout of nuclear power in the United States in 2025. As a
[01:33:08.500 --> 01:33:13.220]   function of deregulation and some new technologies. I do
[01:33:13.220 --> 01:33:16.340]   think that this new government is going to be much more
[01:33:16.340 --> 01:33:19.100]   accommodating. And it's going to, as I've said in the past, I
[01:33:19.100 --> 01:33:23.460]   think it's a necessity, just because of the the rate at which
[01:33:23.460 --> 01:33:26.940]   we have to do power buildouts, to meet kind of competitive
[01:33:26.940 --> 01:33:30.540]   demand against China, the United States is going to need to add
[01:33:30.540 --> 01:33:33.140]   more power, electricity production capacity than we can
[01:33:33.140 --> 01:33:36.780]   scale up with any other renewable source. So I do
[01:33:36.780 --> 01:33:39.500]   believe that nuclear is an inevitability. I think that the
[01:33:39.500 --> 01:33:42.700]   deregulation will happen in 25. And I do know a lot of very
[01:33:42.700 --> 01:33:45.660]   smart people who are actually starting nuclear power
[01:33:45.660 --> 01:33:50.340]   companies, and have left very good jobs to go and do this in
[01:33:50.340 --> 01:33:53.940]   anticipation of this happening in 25. So I'm very bullish.
[01:33:53.940 --> 01:33:57.700]   That's an indicator for sure. When smart people do something
[01:33:57.700 --> 01:33:59.780]   with their time. That's a great indicator. Gavin, what do you
[01:33:59.780 --> 01:34:00.020]   got?
[01:34:00.020 --> 01:34:04.740]   I think AI and Nick, I sent you a chart. I don't know if you
[01:34:04.740 --> 01:34:08.860]   could flash it up. But I think AI is going to make more
[01:34:08.860 --> 01:34:15.900]   progress per quarter in 2025 than it did per year in 23 and
[01:34:15.900 --> 01:34:21.140]   24. And the reason is just with us with oh, one and oh, three,
[01:34:21.140 --> 01:34:24.900]   this is our KGI, it's designed, you know, we keep we keep
[01:34:24.900 --> 01:34:29.940]   changing the goalposts for the Turing test and AGI. And I'm
[01:34:29.940 --> 01:34:32.580]   sure we're going to change it again. Because we're going to
[01:34:32.580 --> 01:34:35.700]   blow through this. And I just think what has happened is, we
[01:34:35.700 --> 01:34:38.940]   were scaling around round one, on one axis, which was
[01:34:38.940 --> 01:34:42.260]   pre-training. And then we started scaling around inference
[01:34:42.260 --> 01:34:46.380]   time compute. And it's very clear that we have now added a
[01:34:46.380 --> 01:34:49.860]   third axis of scaling performance. And that is
[01:34:49.860 --> 01:34:54.860]   reasoning. And what this is, is these models, the internet is
[01:34:54.860 --> 01:34:58.940]   composed of answers, people giving answers. And what the
[01:34:58.940 --> 01:35:04.100]   models really benefit from is kind of the internal monologue
[01:35:04.100 --> 01:35:08.180]   of somebody getting to that answer. And this is, you know,
[01:35:08.180 --> 01:35:11.420]   in AI terms, they call it a reasoning trace. And it's one
[01:35:11.420 --> 01:35:13.300]   reason, you know, 18 months ago, everybody was like, Oh, wow,
[01:35:13.300 --> 01:35:15.900]   the more code you train a model on, the better it does, and all
[01:35:15.900 --> 01:35:19.020]   sorts of things that have seemingly nothing to do with
[01:35:19.020 --> 01:35:24.180]   code. But all code, you see kind of the reasoning, the internal
[01:35:24.180 --> 01:35:27.940]   monologue, the thought process, the step by step. And so what's
[01:35:27.940 --> 01:35:33.340]   happening is you're using models to generate synthetic data that
[01:35:33.340 --> 01:35:36.620]   contains these reasoning traces. So you ask a model, you know,
[01:35:36.620 --> 01:35:39.460]   solve this problem, it has to be a problem that is functionally
[01:35:39.460 --> 01:35:42.660]   verifiable, that has an answer, or we know the answer, we say
[01:35:42.660 --> 01:35:45.700]   show your work. And we have to do that many, many different
[01:35:45.700 --> 01:35:49.260]   ways and times. And then you pick the best ones. And you kind
[01:35:49.260 --> 01:35:51.340]   of feed those back into the model, you apply some
[01:35:51.340 --> 01:35:54.420]   reinforcement learning to it. And so now you're scaling along
[01:35:54.420 --> 01:35:58.260]   three axes that are multiplicative with each other.
[01:35:58.980 --> 01:36:05.580]   And I just, I, you know, a guy on the Google team said, tweeted
[01:36:05.580 --> 01:36:09.420]   maybe five days ago, it's going to be a straight shot to ASI,
[01:36:09.420 --> 01:36:13.100]   artificial superintelligence. And I think that might be right.
[01:36:13.100 --> 01:36:17.300]   Ilya gave a talk at NeurIPS, Ilya Tsutskever, one of kind of
[01:36:17.300 --> 01:36:20.060]   the original pioneers of this field. And he said something
[01:36:20.060 --> 01:36:25.340]   that I thought was scary. And he said, these models that reason
[01:36:25.380 --> 01:36:29.100]   are inherently unpredictable. So the best reasoning models in the
[01:36:29.100 --> 01:36:31.780]   world today are the ones that play games, the kind of alpha go
[01:36:31.780 --> 01:36:35.900]   alpha zero style models, and they are constantly making
[01:36:35.900 --> 01:36:39.580]   unpredictable moves that no human grandmaster ever could
[01:36:39.580 --> 01:36:43.500]   have come up with. And now these models are going to be making
[01:36:43.500 --> 01:36:49.700]   similarly unpredictable leaps in all sorts of domains. Which, you
[01:36:49.700 --> 01:36:52.540]   know, hopefully will be awesome, but you know, might not be.
[01:36:52.540 --> 01:36:55.140]   Yeah, well, they're going to go around corners that people might
[01:36:55.140 --> 01:36:58.020]   not have considered that are non intuitive. And then just to
[01:36:58.020 --> 01:37:00.900]   circle back and do a little callback here. Remember, I asked
[01:37:00.900 --> 01:37:04.100]   which banks would have the biggest chance of being
[01:37:04.100 --> 01:37:07.740]   insolvent, or having financial collapse or crisis, tons of
[01:37:07.740 --> 01:37:10.100]   misspellings in there as I typed it while we're talking. And you
[01:37:10.100 --> 01:37:14.100]   can see what deep, deep research did here. It went and said,
[01:37:14.100 --> 01:37:15.980]   here's what we're going to do, we're going to research a bunch
[01:37:15.980 --> 01:37:18.740]   of websites and find a list of banks in the US find top banks
[01:37:18.740 --> 01:37:21.420]   by us by asset. For each one of these banks find their latest
[01:37:21.420 --> 01:37:24.060]   financial savings for each of these banks find their capital
[01:37:24.820 --> 01:37:27.140]   adequacy ratios for each of these banks find their loan
[01:37:27.140 --> 01:37:31.180]   loss, you get the idea. And then it went in and analyzed. And
[01:37:31.180 --> 01:37:34.140]   then it created a report. This took about 10 minutes. And when
[01:37:34.140 --> 01:37:37.500]   you look, it created this final report here, where it gave a
[01:37:37.500 --> 01:37:41.220]   list Chamath of JP Morgan, Bank of America, Citigroup, yada,
[01:37:41.220 --> 01:37:46.580]   yada, it did an analysis of each one. And at the end, you can see
[01:37:46.580 --> 01:37:50.540]   all the different websites it pulled. It was well over 100
[01:37:50.540 --> 01:37:54.940]   websites that it pulled. That's incredible live data from 162
[01:37:54.940 --> 01:37:58.300]   websites. And you have to pay for this, but it's only $20 a
[01:37:58.300 --> 01:38:01.820]   month. And its conclusion. This analysis is provided a snapshot
[01:38:01.820 --> 01:38:04.620]   of financial health of some of the largest US banks while all
[01:38:04.620 --> 01:38:07.660]   banks face inherent risk Citigroup and Wells Fargo
[01:38:07.660 --> 01:38:09.620]   appeared to be the highest risk of insolvency or financial
[01:38:09.620 --> 01:38:12.620]   collapse. Compared to JP Morgan Chase Bank of America Goldman
[01:38:12.620 --> 01:38:16.700]   Sachs Citigroup's recent net loss lower CET one ratio and
[01:38:16.700 --> 01:38:18.780]   high exposure. I mean, you start looking at is that I don't know
[01:38:18.780 --> 01:38:21.740]   how much of this is correct. I'm no expert on this. But it does
[01:38:21.740 --> 01:38:24.460]   seem like it's a pretty good start of where it's getting to
[01:38:24.460 --> 01:38:27.980]   and if you haven't used 1.5 pro with deep research, just go to
[01:38:27.980 --> 01:38:30.940]   gemini.google.com. I'm not being paid to say this. I just think
[01:38:30.940 --> 01:38:35.260]   it's the best product in the market. And it's pretty darn
[01:38:35.260 --> 01:38:41.420]   impressive. Okay. My most anticipated trend for 2025 was
[01:38:41.420 --> 01:38:44.500]   alluded to in an earlier prediction, I think by Gavin
[01:38:44.500 --> 01:38:49.460]   himself. Mine is that exits and DPI shower town will have this
[01:38:49.460 --> 01:38:53.300]   incredible distribution as the wrath of Lena Khan ends and M&A
[01:38:53.300 --> 01:38:58.660]   and IPOs will surge. That is my prediction, my most anticipated
[01:38:58.660 --> 01:39:03.340]   trend. Okay, let's go to most anticipated media. I had to that
[01:39:03.340 --> 01:39:06.980]   I was working back and forth from James, James guns, DC
[01:39:06.980 --> 01:39:09.860]   universe with Superman coming out this year, I think is going
[01:39:09.860 --> 01:39:13.740]   to be amazing and or season two could be amazing. I predict
[01:39:13.740 --> 01:39:15.980]   they're going to do a Clone Wars live action series. If you
[01:39:15.980 --> 01:39:18.220]   don't have the Clone Wars, watch it with your kids. It's amazing
[01:39:18.220 --> 01:39:21.820]   animated series that takes place during the prequels. But I went
[01:39:21.820 --> 01:39:25.860]   with a little of a weird choice here. I think my most
[01:39:25.860 --> 01:39:29.380]   anticipated media is seeing what happens with legacy media
[01:39:29.380 --> 01:39:33.660]   outlets owned by billionaires and or people who no longer want
[01:39:33.660 --> 01:39:37.020]   to pick aside Washington Post, CNN and LA Times specifically,
[01:39:37.020 --> 01:39:40.260]   are steering towards the middle and trying to get back to
[01:39:40.260 --> 01:39:44.500]   classic journalism. The editors are revolting. Karen Swisher is
[01:39:44.500 --> 01:39:48.940]   upset. And they're adding some right wing voices. It is going
[01:39:48.940 --> 01:39:53.780]   to be popcorn time for everybody. So enjoy whatever you
[01:39:53.780 --> 01:39:56.500]   want to enjoy Star Wars. I got a little Star Wars for you with
[01:39:56.500 --> 01:39:59.580]   Andrew season two, I got a little Superman or you can watch
[01:39:59.580 --> 01:40:02.820]   the chaos in the editorial newsrooms at Washington Post and
[01:40:02.820 --> 01:40:06.020]   LA Times. What do you got for most anticipated media tomorrow?
[01:40:06.100 --> 01:40:12.260]   It is the enormity of the files that are going to get
[01:40:12.260 --> 01:40:15.780]   declassified and released by the Trump administration. I think
[01:40:15.780 --> 01:40:22.500]   it's going to be unbelievably interesting, salacious, useful,
[01:40:22.500 --> 01:40:31.220]   good, earnest. All of the above. So the JFK files, the Epstein
[01:40:31.220 --> 01:40:35.940]   files, Diddy files, the moon landing, who knows what they
[01:40:35.940 --> 01:40:38.620]   find across all of these other fringe, quote unquote,
[01:40:38.620 --> 01:40:40.940]   conspiracy theories that may turn out to actually have some
[01:40:40.940 --> 01:40:44.780]   shred of truth. But all of that, let's call it content, for lack
[01:40:44.780 --> 01:40:47.540]   of a better word that gets released in 2025 by the Trump
[01:40:47.540 --> 01:40:51.100]   administration, I think will be incredibly interesting. What do
[01:40:51.100 --> 01:40:53.700]   you got to media? Any anticipated media for you? What
[01:40:53.700 --> 01:40:57.660]   do you got? I'm into AI video games. The cost of production
[01:40:57.660 --> 01:41:00.780]   comes way down when you use AI and you can have dynamic
[01:41:00.780 --> 01:41:03.700]   storylines, you can have new gameplay concepts, things that
[01:41:03.700 --> 01:41:07.340]   don't exist today. I think that the creative talent plus the
[01:41:07.340 --> 01:41:09.540]   technical talent that you typically find a development
[01:41:09.540 --> 01:41:11.980]   houses can be kind of unleashed with tools that have come to
[01:41:11.980 --> 01:41:14.020]   come to market recently, we've seen a lot of the generative
[01:41:14.020 --> 01:41:17.540]   video stuff. But there's also ways structurally that video
[01:41:17.540 --> 01:41:19.980]   games can kind of be rebuilt where the video game engine can
[01:41:19.980 --> 01:41:23.340]   run kind of locally can be generating parameters that can
[01:41:23.340 --> 01:41:26.380]   then use an existing rendering engine. So you can have entirely
[01:41:26.380 --> 01:41:30.340]   new storylines and entirely new kind of plot sequences. So I do
[01:41:30.340 --> 01:41:33.020]   think that there's going to be a rewrite of video games in the
[01:41:33.020 --> 01:41:36.900]   video game industry, with the variety of AI kind of
[01:41:36.900 --> 01:41:39.700]   capabilities that are hitting market now. And it's going to be
[01:41:39.700 --> 01:41:42.140]   incredible. It's going to be incredible entertainment, people
[01:41:42.140 --> 01:41:44.380]   are gonna, people that don't play video games are going to
[01:41:44.380 --> 01:41:45.580]   find stuff that they're going to love.
[01:41:45.580 --> 01:41:49.100]   Gavin, most anticipated media 2025.
[01:41:49.100 --> 01:41:53.820]   Unquestioned 1923. Season two, I'm normally a science fiction
[01:41:54.980 --> 01:42:00.420]   kind of fantasy, or you know, spy kind of guy when it comes to
[01:42:00.420 --> 01:42:04.780]   TV. But 1883 and 1923 were the first TV shows that kind of hit
[01:42:04.780 --> 01:42:07.860]   me the way Game of Thrones did. And I'm crazy excited for that
[01:42:07.860 --> 01:42:08.420]   to come out.
[01:42:08.420 --> 01:42:12.260]   Fantastic. Are you watching Landman? I'm enjoying Landman.
[01:42:12.260 --> 01:42:15.860]   I haven't watched it yet. I'm excited. It's quite fun, quite
[01:42:15.860 --> 01:42:19.500]   fun. Turns out this guy Taylor Sheridan. He's I mean, yeah,
[01:42:19.500 --> 01:42:21.460]   it's incredible. He's in the zone.
[01:42:22.420 --> 01:42:25.580]   I highly recommend Day of the Jackal. I know Chamath also
[01:42:25.580 --> 01:42:26.700]   loved Day of the Jackal.
[01:42:26.700 --> 01:42:29.140]   Oh, that was really good. That was really good. That was a
[01:42:29.140 --> 01:42:31.060]   good suggestion for streaming.
[01:42:31.060 --> 01:42:35.620]   Yeah, I'm excited. It was incredible. Yeah. Absolutely.
[01:42:35.620 --> 01:42:38.220]   What was your predictions for, for this last year?
[01:42:38.220 --> 01:42:42.940]   Last year, Chamath predicted Mr. Beast, Freeberg, AI generated
[01:42:42.940 --> 01:42:47.100]   news. I predicted Gladiator 2 and the three body problem.
[01:42:47.100 --> 01:42:51.260]   Gladiator 2 was mid, but okay, three body problem. I didn't
[01:42:51.260 --> 01:42:52.660]   finish. So I guess mid
[01:42:52.660 --> 01:42:57.860]   Jimmy's show on Amazon Prime, the Mr. Beast thing was the top
[01:42:57.860 --> 01:43:01.420]   unscripted drama in 140 of 180 countries.
[01:43:01.420 --> 01:43:04.860]   Wow, incredible. All right, we're gonna do our prediction
[01:43:04.860 --> 01:43:09.100]   markets here. I'm going to put up a prediction market, which is
[01:43:09.100 --> 01:43:13.460]   based upon immigration and the promise that Trump made to have
[01:43:13.460 --> 01:43:17.340]   15 million people be deported from the country. I think in the
[01:43:17.340 --> 01:43:21.020]   first year, I'm going to set the over under at 5% of that stated
[01:43:21.020 --> 01:43:27.340]   number, which is 750,000. So after one year in office, will
[01:43:27.340 --> 01:43:33.620]   Trump have deported 750,000 less or more? That's my first
[01:43:33.620 --> 01:43:35.620]   prediction. How are you going to measure that you have to there
[01:43:35.620 --> 01:43:38.660]   has to be a like a source of truth on these things, right?
[01:43:38.660 --> 01:43:40.900]   We'll do it based on the White House's reporting of
[01:43:40.900 --> 01:43:41.740]   deportations.
[01:43:41.740 --> 01:43:42.820]   Yeah, it's reasonable.
[01:43:42.820 --> 01:43:45.740]   And we'll check with the poly market team if there's a way to
[01:43:45.740 --> 01:43:47.900]   do that prediction market, obviously, but I think that was
[01:43:47.900 --> 01:43:49.740]   the biggest issue of the election. So I'm putting it up
[01:43:49.740 --> 01:43:51.940]   there with just 5% in the first year.
[01:43:51.940 --> 01:43:55.060]   Yeah, it is interesting. Obama deported, I think more than 2
[01:43:55.060 --> 01:43:58.460]   million people. It's like people have forgotten, but he was
[01:43:58.460 --> 01:44:00.820]   actually really, really tough on the border. Yeah.
[01:44:00.820 --> 01:44:02.660]   tomorrow. Do you have a prediction market you want to
[01:44:02.660 --> 01:44:12.140]   put up the Maggie representation on the s&p 500 shrinks below 30%
[01:44:12.140 --> 01:44:15.980]   Oh, that's a good one. That's a good one. So dispersion would
[01:44:15.980 --> 01:44:18.980]   happen to the other stocks. That's a good concentration.
[01:44:18.980 --> 01:44:21.580]   That's a good one. So we'll finalize these, you'll be able
[01:44:21.580 --> 01:44:21.740]   to
[01:44:21.740 --> 01:44:26.820]   I wanted to kind of play with was Microsoft AWS and Google
[01:44:26.820 --> 01:44:31.220]   cloud revenue growth, who's gonna win in growth in 2025. I
[01:44:31.220 --> 01:44:35.140]   don't know how closely you guys track, but I get a sense that
[01:44:35.140 --> 01:44:38.020]   Google is kind of accelerating ahead. Gavin, I don't know how
[01:44:38.020 --> 01:44:38.460]   much you've
[01:44:38.460 --> 01:44:43.700]   Yeah, I mean, Google is, I would say they're a lot smaller, which
[01:44:43.700 --> 01:44:48.340]   makes it easier for them to grow faster. Yeah.
[01:44:48.340 --> 01:44:55.540]   Should we talk about? Yeah, I mean, I guess. Who has the
[01:44:55.540 --> 01:45:00.460]   largest gain dollar dollar gain in revenue in cloud revenue in
[01:45:00.460 --> 01:45:03.980]   2025? Is it Google, Amazon, or Microsoft?
[01:45:03.980 --> 01:45:06.940]   Well, it probably won't be Google because if they had the
[01:45:06.940 --> 01:45:09.580]   largest dollar gain, it would mean they were growing at an at
[01:45:09.580 --> 01:45:14.180]   insane rates. But I think Azure versus AWS will be interesting.
[01:45:14.180 --> 01:45:17.620]   Oh, I know the other one I want you to do, which was the
[01:45:17.620 --> 01:45:22.420]   national debt. The national debt has grown about 2 trillion per
[01:45:22.420 --> 01:45:29.100]   year in each of the previous two presidential administrations,
[01:45:29.100 --> 01:45:31.340]   right. So over the last eight years, we've gone up over 16
[01:45:31.340 --> 01:45:34.300]   trillion 2 trillion per year average. So I'm going to set it
[01:45:34.300 --> 01:45:40.100]   at and Trump said he would not increase the national debt. I'll
[01:45:40.100 --> 01:45:44.020]   just set it at the national debt increases 1 trillion in the next
[01:45:44.020 --> 01:45:47.780]   year over under. Is that a good prediction of market? Or is it
[01:45:47.780 --> 01:45:48.660]   should be 2 trillion?
[01:45:48.660 --> 01:45:53.940]   Yeah, so what I would do is I would set the federal debt for
[01:45:53.940 --> 01:45:57.700]   December, the US Treasury market report on federal debt in 2025.
[01:45:57.700 --> 01:46:02.340]   And I would set it at 30 37 trillion. And so basically, the
[01:46:02.340 --> 01:46:08.380]   US Treasury market report 20 December 2025, above or below
[01:46:08.380 --> 01:46:10.780]   37 trillion, it's going to be above, I mean, let's just call
[01:46:10.780 --> 01:46:11.700]   it 38 billion, then.
[01:46:11.700 --> 01:46:16.340]   Yeah, you want to basically in order to make this when you set
[01:46:16.340 --> 01:46:20.180]   a line, Dave, it's got to be one where people take either side of
[01:46:20.180 --> 01:46:23.380]   it. It can't be everybody will do the US Treasury market report
[01:46:23.380 --> 01:46:27.700]   December 2025, federal debt above 38 trillion or below 38
[01:46:27.700 --> 01:46:31.180]   trillion. Perfect. Which would be how much added in the year?
[01:46:31.300 --> 01:46:32.700]   About one and a half. Yeah.
[01:46:32.700 --> 01:46:36.140]   I love that. I love that. That's a perfect one. We'll see if he
[01:46:36.140 --> 01:46:39.220]   can make any, he can control the spending or it will just be the
[01:46:39.220 --> 01:46:39.580]   same.
[01:46:39.580 --> 01:46:41.780]   Gavin, what's your sense on federal debt next year?
[01:46:41.780 --> 01:46:43.980]   I think like most things that will take like immigration will
[01:46:43.980 --> 01:46:48.020]   take time to get going. Yeah. It just it's gonna take a little
[01:46:48.020 --> 01:46:50.580]   bit of time, but I think they will make progress. By the way,
[01:46:50.580 --> 01:46:54.940]   at some point, if I'm here on the all in again, I want to talk
[01:46:54.940 --> 01:46:56.620]   about UFOs and the drones.
[01:46:58.300 --> 01:47:00.940]   Let's talk about it. Do it right now. Are you going full
[01:47:00.940 --> 01:47:04.020]   conspiracy theorist? Are you are you trying to get your seat here
[01:47:04.020 --> 01:47:06.700]   by being a little more Alex Jones? Do you believe those
[01:47:06.700 --> 01:47:08.580]   drones were aliens? What's going on?
[01:47:08.580 --> 01:47:11.940]   So I don't know. And I think it's very clear if you look at
[01:47:11.940 --> 01:47:15.380]   all the, you know, statements from the New Jersey mayors and
[01:47:15.380 --> 01:47:19.940]   governors, you know, who've met with the police, the FBI, the
[01:47:19.940 --> 01:47:23.900]   Defense Department that they don't know. Now, you know, Trump
[01:47:23.900 --> 01:47:27.260]   said someone in the government knows what they are. He also
[01:47:27.260 --> 01:47:30.860]   said he was not going to go to Bedminster anytime soon. His
[01:47:30.860 --> 01:47:35.500]   resort there. I just think over the last, I'd say eight years,
[01:47:35.500 --> 01:47:39.300]   every 18 months, there's a big story in the New York Times, the
[01:47:39.300 --> 01:47:43.940]   Washington Post, the New Yorker, the Atlantic very credible media
[01:47:43.940 --> 01:47:47.860]   sources. With dozens of interviews with fighter pilots
[01:47:47.860 --> 01:47:51.180]   and commercial pilots, talking about seeing things with advanced
[01:47:51.180 --> 01:47:54.620]   sensors that made no sense to them. Then there's kind of a
[01:47:54.620 --> 01:48:00.940]   taboo that went away. I was an article in the New Yorker, where
[01:48:00.940 --> 01:48:05.980]   they quoted from a bunch of people who were at, you know,
[01:48:05.980 --> 01:48:09.420]   kind of the the skunk works laboratories in the 1950s. And
[01:48:09.420 --> 01:48:14.500]   said they absolutely saw extraterrestrial materials that
[01:48:14.500 --> 01:48:16.900]   have been recovered from a crash. That's one reason the US
[01:48:16.900 --> 01:48:22.380]   made such big leaps in material science. And, you know, there
[01:48:22.380 --> 01:48:25.580]   was a lot of thing where essentially a lot of, you know,
[01:48:25.580 --> 01:48:29.860]   astronomers said, Hey, this is, this is clearly a UFO of some
[01:48:29.860 --> 01:48:34.820]   sort, including the head of astronomy at Harvard. And then
[01:48:34.820 --> 01:48:40.700]   just the conspiracy theory I would have is if, if, if, if,
[01:48:40.700 --> 01:48:47.180]   if these are actually UFOs, and not, you know, government
[01:48:47.180 --> 01:48:51.380]   drones, either from the United States or China, it seems like
[01:48:51.380 --> 01:48:54.020]   the most likely explanation in New Jersey is that some sort of
[01:48:54.020 --> 01:48:59.020]   a drill. And obviously, once this hysteria gets going, people,
[01:48:59.020 --> 01:49:05.460]   you know, misidentify commercial airplanes as drones. And like,
[01:49:05.460 --> 01:49:09.180]   why would UFOs have blinking green and red lights. But it is
[01:49:09.180 --> 01:49:13.260]   just interesting that there was, you know, a big concentration of
[01:49:13.260 --> 01:49:18.780]   these reports, as we're scaling into nuclear technology, 1945 to
[01:49:18.780 --> 01:49:23.420]   1960. And then now that AI is getting going, which is the next
[01:49:23.420 --> 01:49:26.340]   kind of technological phase shift for humanity. There's
[01:49:26.340 --> 01:49:27.820]   another big
[01:49:27.820 --> 01:49:35.060]   I love this. Come back next week. You Congratulations. We
[01:49:35.060 --> 01:49:38.020]   have our winner for all and I don't think Gavin is now the
[01:49:38.020 --> 01:49:42.340]   fourth best. I love this kind of conspiracy. But I mean, come on.
[01:49:42.340 --> 01:49:44.580]   I we How do we make a poly market at this free?
[01:49:48.180 --> 01:49:51.460]   Are there documents that you think Trump will release about
[01:49:51.460 --> 01:49:54.940]   the past and in terms of UFOs, there must be just an entire
[01:49:54.940 --> 01:49:59.180]   spectrum of stuff that could be subject to FOIA if we went
[01:49:59.180 --> 01:49:59.980]   after it? No.
[01:49:59.980 --> 01:50:04.660]   I mean, I think it depends how deeply it's classified. And, you
[01:50:04.660 --> 01:50:07.460]   know, I'm sure if the government doesn't want to give it up, they
[01:50:07.460 --> 01:50:11.420]   won't give it up. But you know, there's all the you know,
[01:50:11.420 --> 01:50:13.900]   there's all you think, but look, let's be honest, you think that
[01:50:13.900 --> 01:50:17.300]   there are docs, like there, there's documentation that the
[01:50:17.300 --> 01:50:21.220]   US government has that there are UFOs that there have been we
[01:50:21.220 --> 01:50:22.260]   just can't explain it.
[01:50:22.260 --> 01:50:26.620]   Yeah, and you know, they they call it uaps now to make it you
[01:50:26.620 --> 01:50:31.020]   know, not flying saucers. But it just feels like something but
[01:50:31.020 --> 01:50:35.620]   percentage chance you put on, we have actual knowledge on a
[01:50:35.620 --> 01:50:37.820]   percentage basis, what percentage chance you put on the
[01:50:37.820 --> 01:50:40.380]   government, US government is sitting on knowledge of
[01:50:40.380 --> 01:50:43.580]   extraterrestrial percent, at least 20%. What do you say
[01:50:43.580 --> 01:50:47.060]   Gavin? I would say 25. I would take the over on the 20.
[01:50:47.060 --> 01:50:51.140]   Okay, great. So you think there's a non a significant
[01:50:51.140 --> 01:50:53.660]   small chance that this is the case Freeberg, Sultan of
[01:50:53.660 --> 01:50:58.100]   science? What chance do you think there is this government
[01:50:58.100 --> 01:51:01.060]   sitting on some extraterrestrial life or proof of it?
[01:51:01.060 --> 01:51:04.620]   So longer conversation, I don't have time for this. But I got to
[01:51:04.620 --> 01:51:07.660]   be honest, I don't. I don't generally align with the idea
[01:51:07.660 --> 01:51:13.380]   that like our very narrow range of, like, understanding of
[01:51:13.380 --> 01:51:19.860]   technology and biology kind of is what visits us or would visit
[01:51:19.860 --> 01:51:23.780]   us. I think that there's an extension of information
[01:51:23.780 --> 01:51:28.740]   gathering that doesn't require moving physical biological life
[01:51:28.740 --> 01:51:31.460]   forms from one part of the galaxy to another. So I think
[01:51:31.460 --> 01:51:35.100]   that the whole premise of like, UFOs moving bodies around is
[01:51:35.100 --> 01:51:39.660]   rooted in the current state of technology of humanity, which is
[01:51:39.660 --> 01:51:44.300]   the basis of Arthur Clarke's treatment of 2001, a space
[01:51:44.300 --> 01:51:47.380]   odyssey, not which was done before the screenplay, which was
[01:51:47.380 --> 01:51:51.100]   done before the book. And the treatment which you can buy, I
[01:51:51.100 --> 01:51:53.820]   think highlights this the best, which is eventually every
[01:51:53.820 --> 01:51:56.260]   civilization reaches a sufficiently advanced level of
[01:51:56.260 --> 01:51:59.340]   technology that you no longer need to physically move the
[01:51:59.340 --> 01:52:03.900]   bodies of the biological organisms around that you simply
[01:52:03.900 --> 01:52:06.580]   are gathering information and affecting information because
[01:52:06.580 --> 01:52:09.020]   once you have the ability to convert any molecule into any
[01:52:09.020 --> 01:52:11.740]   other molecule, and you have access to sufficient energy,
[01:52:11.740 --> 01:52:14.300]   which you will eventually evolve to be able to do, you can
[01:52:14.300 --> 01:52:16.740]   basically turn your local part of the universe into anything
[01:52:16.740 --> 01:52:19.180]   you want it to turn into. And then you're simply gathering
[01:52:19.180 --> 01:52:22.140]   information from all over the rest of the universe. So I would
[01:52:22.140 --> 01:52:25.880]   argue that there doesn't really make a lot of basic sense and
[01:52:25.880 --> 01:52:28.700]   why alien bodies would want to move around the galaxy.
[01:52:28.700 --> 01:52:34.380]   I'm just saying it right now. If Trump releases information on
[01:52:34.380 --> 01:52:37.980]   extraterrestrial life, I'm voting for him to have a third
[01:52:37.980 --> 01:52:40.620]   term. I'm putting it out there. I'm going full MAGA. He gets a
[01:52:40.620 --> 01:52:43.060]   third term for me. We're changing the Constitution. This
[01:52:43.060 --> 01:52:45.620]   has been another amazing episode of the all last question for
[01:52:45.620 --> 01:52:48.780]   Gavin. Oh, well, let's forget. Okay. Do you think
[01:52:48.780 --> 01:52:54.060]   extraterrestrial life built the pyramids? Is that the most
[01:52:54.060 --> 01:52:57.420]   plausible explanation to the accuracy?
[01:52:57.420 --> 01:53:02.820]   I don't know. It is. It is so strange the way there are, you
[01:53:02.820 --> 01:53:06.980]   know, in so many, I would say, cultures all over the world pre
[01:53:07.980 --> 01:53:13.420]   you know, we are closer in time to Cleopatra than she was to the
[01:53:13.420 --> 01:53:17.140]   time of the Great Pyramids, like there was a long time ago. But
[01:53:17.140 --> 01:53:19.980]   it's just weird that in so many cultures all over the world,
[01:53:19.980 --> 01:53:24.420]   there are these depictions of what looked like astronauts. And
[01:53:24.420 --> 01:53:27.740]   then there's all these Renaissance era paintings that
[01:53:27.740 --> 01:53:32.940]   clearly show what we would call UFOs in the skies over cities.
[01:53:35.540 --> 01:53:38.060]   So I don't know, I just think it's I'm with you. I love
[01:53:38.060 --> 01:53:39.060]   conspiracy, Gavin.
[01:53:39.060 --> 01:53:46.660]   If you're Jason, if you're a questioning person, these things
[01:53:46.660 --> 01:53:50.540]   I get these weird on and, you know, open loops that it's like,
[01:53:50.540 --> 01:53:54.180]   I think we're in a simulation. So I'm fully I'm fully vested in
[01:53:54.180 --> 01:53:57.140]   anyways, I've never got to drive back. Freiberg's driving home. I
[01:53:57.140 --> 01:53:59.420]   think the pyramids are the best most credible thing I saw on the
[01:53:59.420 --> 01:54:03.060]   pyramids was that they used water and they raised water in
[01:54:03.060 --> 01:54:06.180]   channels. So they put them on wood slats or something. And
[01:54:06.180 --> 01:54:10.660]   then they would raise like in like the Panama Canal, they
[01:54:10.660 --> 01:54:13.620]   would do canals and float them up and then place them and then
[01:54:13.620 --> 01:54:17.180]   release the water, which you know, sounds great to me. This
[01:54:17.180 --> 01:54:22.140]   has been another amazing episode of the all in podcast. And thank
[01:54:22.140 --> 01:54:22.980]   you to everybody. It's
[01:54:22.980 --> 01:54:24.980]   an amazing 2025 to everybody.
[01:54:24.980 --> 01:54:30.980]   Let's kick off 2025. Let's take care. All right, we'll see you
[01:54:30.980 --> 01:54:33.060]   all next time. Bye bye.
[01:54:33.060 --> 01:54:43.060]   All right, let your winners ride. Rain Man David says we
[01:54:43.060 --> 01:54:46.020]   open source it to the fans and they've just gone crazy with it.
[01:54:46.020 --> 01:54:48.020]   Love you. I'm the Queen of King.
[01:54:48.020 --> 01:54:56.420]   Besties are gone.
[01:54:56.420 --> 01:54:59.940]   That's my dog taking a notice in your driveway.
[01:54:59.940 --> 01:55:08.340]   We should all just get a room and just have one big huge orgy
[01:55:08.340 --> 01:55:10.180]   because they're all just useless. It's like this like
[01:55:10.180 --> 01:55:12.460]   sexual tension that they just need to release somehow.
[01:55:12.460 --> 01:55:19.940]   What? You're a bee. What? You're a bee. We need to get merch.
[01:55:19.940 --> 01:55:30.140]   I'm going all in. I'm going all in.
[01:55:30.140 --> 01:55:32.720]   (upbeat music)

