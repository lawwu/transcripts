
[00:00:00.000 --> 00:00:02.580]   (upbeat music)
[00:00:02.580 --> 00:00:07.720]   - All right, who do we got next, Jesse?
[00:00:07.720 --> 00:00:09.040]   - Next up we have Anthony.
[00:00:09.040 --> 00:00:10.360]   He has a question.
[00:00:10.360 --> 00:00:11.880]   You've been getting a lot of these questions lately
[00:00:11.880 --> 00:00:13.880]   about seeking counter arguments.
[00:00:13.880 --> 00:00:19.280]   - Hi Cal, Anthony here.
[00:00:19.280 --> 00:00:23.480]   Thank you for your books, your articles, and this podcast.
[00:00:23.480 --> 00:00:27.120]   They truly inspire me to keep living the deep life.
[00:00:27.120 --> 00:00:28.360]   Keep up the great work.
[00:00:29.540 --> 00:00:32.080]   My question is about your advice
[00:00:32.080 --> 00:00:34.800]   to seek out the best counter arguments
[00:00:34.800 --> 00:00:39.040]   when developing a philosophy or stance on an issue.
[00:00:39.040 --> 00:00:41.920]   I think the advice makes sense.
[00:00:41.920 --> 00:00:45.160]   I was just wondering if you could provide some tips
[00:00:45.160 --> 00:00:47.920]   on how to actually go about finding
[00:00:47.920 --> 00:00:51.360]   the best counter arguments and engaging with them.
[00:00:51.360 --> 00:00:53.700]   What does this process look like?
[00:00:53.700 --> 00:00:56.380]   How do you go about doing it?
[00:00:56.380 --> 00:00:59.240]   Any details you could share would be helpful.
[00:00:59.240 --> 00:01:00.080]   Thank you.
[00:01:00.080 --> 00:01:03.560]   - Well, Anthony, this question has come up
[00:01:03.560 --> 00:01:04.800]   a couple of times recently.
[00:01:04.800 --> 00:01:08.480]   And the answer I gave last week
[00:01:08.480 --> 00:01:11.040]   in responding to a similar question
[00:01:11.040 --> 00:01:16.040]   was find someone that you know or trust or respect
[00:01:16.040 --> 00:01:19.180]   that is on the other side of a topic
[00:01:19.180 --> 00:01:23.020]   and then ask them what are the great sources here?
[00:01:23.020 --> 00:01:25.340]   Like what's the writing that inspires you?
[00:01:25.340 --> 00:01:26.840]   What's the writing that's the foundation
[00:01:26.840 --> 00:01:29.040]   of whatever it is you care about, right?
[00:01:29.040 --> 00:01:33.120]   So like let's say your natural instinct
[00:01:33.120 --> 00:01:37.160]   is towards a sort of big government political theory.
[00:01:37.160 --> 00:01:38.440]   You're like, I should probably understand
[00:01:38.440 --> 00:01:40.200]   what these libertarians are about.
[00:01:40.200 --> 00:01:41.960]   So I kind of understand the opposite side of it.
[00:01:41.960 --> 00:01:44.160]   Find, you know, everyone has the libertarian friend.
[00:01:44.160 --> 00:01:45.440]   They kind of advertise.
[00:01:45.440 --> 00:01:46.880]   And be like, what's the thing you're reading, man?
[00:01:46.880 --> 00:01:47.760]   What got you into this?
[00:01:47.760 --> 00:01:50.780]   Like, who do you think the big books are here,
[00:01:50.780 --> 00:01:51.960]   the ones that made you into this?
[00:01:51.960 --> 00:01:53.360]   And then they tell you, like, great, okay.
[00:01:53.360 --> 00:01:54.560]   So these were the books they read
[00:01:54.560 --> 00:01:55.560]   that were quite inspiring to them.
[00:01:55.560 --> 00:01:57.200]   And then you know what to go read.
[00:01:57.200 --> 00:01:58.040]   So that's what I'd recommend.
[00:01:58.040 --> 00:02:00.160]   Find someone that seems reasonable
[00:02:00.160 --> 00:02:01.400]   on that side of the argument
[00:02:01.400 --> 00:02:03.820]   and ask them not for their arguments,
[00:02:03.820 --> 00:02:06.760]   not for their particular reasons,
[00:02:06.760 --> 00:02:08.600]   but what they read that was most inspiring.
[00:02:08.600 --> 00:02:10.160]   It's usually not that hard to find.
[00:02:10.160 --> 00:02:12.920]   Almost every stance and almost every position
[00:02:12.920 --> 00:02:15.240]   on almost every topic has some foundational text.
[00:02:15.240 --> 00:02:18.040]   So it's all about going and finding foundational text.
[00:02:18.040 --> 00:02:19.840]   Here's the added benefit of doing that
[00:02:19.840 --> 00:02:21.940]   that I wasn't able to mention last time.
[00:02:21.940 --> 00:02:26.140]   Put aside the particular content that you are exploring
[00:02:26.140 --> 00:02:28.320]   when you do this exercise.
[00:02:28.320 --> 00:02:31.000]   You are being exposed when you do this on a regular basis
[00:02:31.000 --> 00:02:32.560]   to foundational text.
[00:02:32.560 --> 00:02:37.320]   Foundational texts in abstract are incredibly interesting
[00:02:37.320 --> 00:02:39.360]   and useful to encounter.
[00:02:39.360 --> 00:02:41.440]   'Cause what makes a text foundational?
[00:02:41.440 --> 00:02:44.080]   It means someone was able to come in on some topic
[00:02:44.080 --> 00:02:47.200]   and deliver such a well-organized
[00:02:47.200 --> 00:02:50.280]   and persuasive structuring of the world
[00:02:50.280 --> 00:02:53.640]   that many people changed the way they lived their lives
[00:02:53.640 --> 00:02:54.680]   because of it.
[00:02:54.680 --> 00:02:56.360]   Those are cool books.
[00:02:56.360 --> 00:02:58.820]   I think Tyler Cowen calls these quake books.
[00:02:58.820 --> 00:03:00.000]   They cause an earthquake
[00:03:00.000 --> 00:03:02.580]   in your personal intellectual life.
[00:03:02.580 --> 00:03:04.920]   Just being exposed to that type of writing,
[00:03:04.920 --> 00:03:06.180]   I think is exciting.
[00:03:06.180 --> 00:03:09.440]   And it also really sharpens your own rhetorical skills
[00:03:09.440 --> 00:03:12.520]   because you're being exposed to the very highest level
[00:03:12.520 --> 00:03:13.840]   of people trying to be persuasive
[00:03:13.840 --> 00:03:14.760]   about understanding the world.
[00:03:14.760 --> 00:03:18.140]   So even if you don't care about what they're saying,
[00:03:18.140 --> 00:03:19.660]   even if after you read what they're saying,
[00:03:19.660 --> 00:03:20.760]   it doesn't change your mind
[00:03:20.760 --> 00:03:22.360]   because you read a quake book on the other side.
[00:03:22.360 --> 00:03:23.200]   And when they combined,
[00:03:23.200 --> 00:03:25.160]   you realize like that side's probably right.
[00:03:25.160 --> 00:03:28.020]   You're still picking up the raw craft tools.
[00:03:28.020 --> 00:03:30.600]   And it's a really interesting, fun reading experience.
[00:03:30.600 --> 00:03:34.240]   And it infuses in you the power of nonfiction done right.
[00:03:34.240 --> 00:03:37.080]   So that is the hidden benefit I wanted to point out here
[00:03:37.080 --> 00:03:39.800]   is that not only do you enrich
[00:03:39.800 --> 00:03:42.880]   in your own understanding of a topic
[00:03:42.880 --> 00:03:44.920]   by reading the best stuff on the other side,
[00:03:44.920 --> 00:03:46.440]   not only does that give you more authenticity,
[00:03:46.440 --> 00:03:48.060]   not only does that give you more deeper roots
[00:03:48.060 --> 00:03:48.900]   of understanding,
[00:03:48.900 --> 00:03:49.880]   not only does that give you the confidence
[00:03:49.880 --> 00:03:52.080]   to take actual action,
[00:03:52.080 --> 00:03:55.360]   it also exposes you to a really cool genre of writing,
[00:03:55.360 --> 00:03:57.600]   those type of books that can change the way
[00:03:57.600 --> 00:03:58.800]   that people live.
[00:03:58.800 --> 00:04:00.960]   And I gotta say, I just have to,
[00:04:00.960 --> 00:04:02.840]   I continue to double down on this idea
[00:04:02.840 --> 00:04:06.080]   that it is not wrong to expose yourself
[00:04:06.080 --> 00:04:08.180]   to people that you worry or disagree with.
[00:04:08.180 --> 00:04:12.240]   Be very, very wary of anyone who says,
[00:04:12.240 --> 00:04:14.520]   "I don't want you being exposed to that
[00:04:14.520 --> 00:04:16.320]   "because you might be tricked."
[00:04:16.320 --> 00:04:17.480]   I won't be.
[00:04:17.480 --> 00:04:18.840]   I'm smart, I'm sophisticated,
[00:04:18.840 --> 00:04:21.320]   but you might be tricked into believing the wrong thing.
[00:04:21.320 --> 00:04:22.880]   So I don't want you to listen to that.
[00:04:22.880 --> 00:04:25.320]   And in fact, we should probably make that thing go away
[00:04:25.320 --> 00:04:27.160]   because people might hear that and be tricked.
[00:04:27.160 --> 00:04:29.600]   We need to be very careful about what you hear.
[00:04:29.600 --> 00:04:32.420]   That is always the character you don't wanna be
[00:04:32.420 --> 00:04:33.480]   in the Orwell novel.
[00:04:33.480 --> 00:04:35.720]   That's always the character in the Huxley book
[00:04:35.720 --> 00:04:37.680]   that you're saying like, "Ooh, that's not the guy I like."
[00:04:37.680 --> 00:04:39.800]   All right, so just be very wary of that.
[00:04:39.800 --> 00:04:42.460]   I can think of no better way to build convictions
[00:04:42.460 --> 00:04:44.080]   than to expose those convictions
[00:04:44.080 --> 00:04:46.840]   to good arguments that disagree.
[00:04:46.840 --> 00:04:49.840]   It's going to nuance and sophisticate your understanding.
[00:04:49.840 --> 00:04:51.120]   And as I talked about last week,
[00:04:51.120 --> 00:04:54.240]   it means you're gonna take more action,
[00:04:54.240 --> 00:04:56.480]   more action in the service of things you care about
[00:04:56.480 --> 00:04:58.880]   if you're exposed to the countervailing arguments
[00:04:58.880 --> 00:05:01.880]   because you get more confidence in your stance.
[00:05:01.880 --> 00:05:03.240]   You get more nuance.
[00:05:03.240 --> 00:05:06.700]   You're not just online firing emojis at people.
[00:05:06.700 --> 00:05:09.120]   You actually say, "I get this and feel strong about this.
[00:05:09.120 --> 00:05:10.360]   "And I have a sophisticated,
[00:05:10.360 --> 00:05:12.640]   "dielectrically formed vision on this.
[00:05:12.640 --> 00:05:13.740]   "So why don't we actually get out there
[00:05:13.740 --> 00:05:14.580]   "and make some change?"
[00:05:14.580 --> 00:05:17.420]   So a lot of great things come out of that strategy, Anthony.
[00:05:17.420 --> 00:05:20.200]   So seek out those books, read those books,
[00:05:20.200 --> 00:05:23.120]   and you will be well off.
[00:05:23.120 --> 00:05:25.700]   (upbeat music)
[00:05:25.700 --> 00:05:29.440]   [MUSIC]

