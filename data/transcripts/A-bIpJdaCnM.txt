
[00:00:00.000 --> 00:00:02.520]   My stance really took over the comment board.
[00:00:02.520 --> 00:00:08.080]   Yeah, Saks, how was your week off when you gave up on the pod for a week and then did
[00:00:08.080 --> 00:00:11.040]   four media appearances for 90 minutes each on other pods?
[00:00:11.040 --> 00:00:12.280]   You did six hours apart.
[00:00:12.280 --> 00:00:17.120]   You took off from this pod to give your ratings to Megyn Kelly and Dave Rubin.
[00:00:17.120 --> 00:00:21.600]   Yeah, I did a 45 minute hit with Dave Rubin on Ukraine.
[00:00:21.600 --> 00:00:23.200]   So be sure to check that out.
[00:00:23.200 --> 00:00:28.720]   And then, yeah, did I do no Megyn, Megyn Kelly, Freeberg and I did that the week before.
[00:00:28.720 --> 00:00:29.720]   Was that this week?
[00:00:29.720 --> 00:00:31.280]   Surprisingly, she didn't invite you back.
[00:00:31.280 --> 00:00:33.160]   Yeah, I don't know what could have happened.
[00:00:33.160 --> 00:00:34.160]   So great.
[00:00:34.160 --> 00:00:35.860]   It was so great.
[00:00:35.860 --> 00:00:36.860]   That was awesome.
[00:00:36.860 --> 00:00:37.860]   I love Megyn Kelly.
[00:00:37.860 --> 00:00:38.860]   Didn't she call you a prick?
[00:00:38.860 --> 00:00:39.860]   Yeah, she did.
[00:00:39.860 --> 00:00:40.860]   She did.
[00:00:40.860 --> 00:00:41.860]   And she only knew me for 45 minutes.
[00:00:41.860 --> 00:00:43.480]   Usually that takes like three or four days.
[00:00:43.480 --> 00:00:49.280]   She just got right to it.
[00:00:49.280 --> 00:00:50.040]   Rain man David Saks.
[00:00:50.040 --> 00:00:57.040]   And it said we open source it to the fans and they've just gone crazy with it.
[00:00:57.040 --> 00:00:58.040]   Love you guys.
[00:00:58.040 --> 00:00:59.040]   Nice.
[00:00:59.040 --> 00:01:00.040]   Queen of quinoa.
[00:01:00.040 --> 00:01:06.600]   Saks, we have not had such negative panning comments on YouTube since J.
[00:01:06.600 --> 00:01:10.720]   Cal got brigadooned for his pro Ukraine rhetoric a few weeks ago.
[00:01:10.720 --> 00:01:13.280]   Now I'm getting brigadooned for Saks not showing up.
[00:01:13.280 --> 00:01:15.680]   I get brigadooned for asking him a question.
[00:01:15.680 --> 00:01:17.040]   Then I get brigadooned from him not showing up.
[00:01:17.040 --> 00:01:18.040]   So maybe you're not getting brigadooned.
[00:01:18.040 --> 00:01:19.040]   I don't know.
[00:01:19.040 --> 00:01:20.040]   I'm just honest.
[00:01:20.040 --> 00:01:24.600]   When will you guys realize that there are three to 5 million people a week that listen
[00:01:24.600 --> 00:01:25.600]   to this podcast?
[00:01:25.600 --> 00:01:29.240]   100 nitwits who comment on YouTube.
[00:01:29.240 --> 00:01:30.760]   They're neither right nor wrong.
[00:01:30.760 --> 00:01:33.240]   They should just be completely ignored.
[00:01:33.240 --> 00:01:34.240]   Turn the comments off.
[00:01:34.240 --> 00:01:36.040]   The only thing that matters are the ratings.
[00:01:36.040 --> 00:01:37.600]   If you care about that at all.
[00:01:37.600 --> 00:01:40.720]   And last week was one of the best rated shows we've ever done.
[00:01:40.720 --> 00:01:43.180]   I think it was highest rated after Elon's episode.
[00:01:43.180 --> 00:01:45.360]   It would have been even better with David.
[00:01:45.360 --> 00:01:48.560]   So we should brigadoon the brigadooners.
[00:01:48.560 --> 00:01:50.120]   Those nitwits should be ignored.
[00:01:50.120 --> 00:01:54.880]   I think this is a little bit like a band where like you can't mess with the chemistry of
[00:01:54.880 --> 00:01:55.880]   the band.
[00:01:55.880 --> 00:01:57.360]   And that's the lesson.
[00:01:57.360 --> 00:02:01.560]   Even though there's a lot of infighting in the band, like it just works.
[00:02:01.560 --> 00:02:02.560]   It works.
[00:02:02.560 --> 00:02:04.360]   And so you don't want to second guess it too much.
[00:02:04.360 --> 00:02:08.160]   Well and then if somebody from the band gets sick and somebody sits in, even if it's like
[00:02:08.160 --> 00:02:11.240]   you get some incredible guitar players sit in, people are like, that's not the guitar
[00:02:11.240 --> 00:02:13.800]   player who I have the T shirt of.
[00:02:13.800 --> 00:02:15.600]   I need my guitar player back.
[00:02:15.600 --> 00:02:16.600]   All right.
[00:02:16.600 --> 00:02:17.600]   Anyway.
[00:02:17.600 --> 00:02:19.480]   I'm glad Ringo showed up 22 minutes late.
[00:02:19.480 --> 00:02:20.480]   Welcome back, Freeburg.
[00:02:20.480 --> 00:02:21.480]   Let's get started.
[00:02:21.480 --> 00:02:22.480]   Sorry.
[00:02:22.480 --> 00:02:23.480]   I don't mean to fuck with the band.
[00:02:23.480 --> 00:02:28.760]   I'm not going to fuck with the band.
[00:02:28.760 --> 00:02:31.400]   Ringo was an underrated drummer.
[00:02:31.400 --> 00:02:34.480]   Freeburg, you have a role here.
[00:02:34.480 --> 00:02:35.480]   That's amazing.
[00:02:35.480 --> 00:02:37.720]   I think you're more like the drummer of J. Cal.
[00:02:37.720 --> 00:02:40.600]   Freeburg maybe bass, maybe bass player.
[00:02:40.600 --> 00:02:41.600]   You know I'm John Lennon.
[00:02:41.600 --> 00:02:42.600]   George Harrison.
[00:02:42.600 --> 00:02:43.600]   George Harrison.
[00:02:43.600 --> 00:02:44.600]   Yeah.
[00:02:44.600 --> 00:02:46.840]   Actually George Harrison, very underrated, but I, you know, I'm, I'm pretty clear.
[00:02:46.840 --> 00:02:52.920]   Have you guys ever heard the version of Blackbird that Paul Picard did just with the ukulele?
[00:02:52.920 --> 00:02:54.720]   No, I'd like to hear that.
[00:02:54.720 --> 00:02:57.160]   Maybe one of the best songs ever recorded.
[00:02:57.160 --> 00:02:58.800]   One of the best records I've ever heard.
[00:02:58.800 --> 00:02:59.800]   Fantastic.
[00:02:59.800 --> 00:03:00.800]   Incredible.
[00:03:00.800 --> 00:03:01.800]   All right.
[00:03:01.800 --> 00:03:06.000]   Listen, there's so much to start with, but I think birds swimming in the dead of night.
[00:03:06.000 --> 00:03:10.400]   Take these broken wings and learn to fly.
[00:03:10.400 --> 00:03:13.320]   All sax life.
[00:03:13.320 --> 00:03:17.800]   Guys, were you at a building on market street yesterday by any chance?
[00:03:17.800 --> 00:03:18.800]   No fly zone.
[00:03:18.800 --> 00:03:19.800]   The homeless shelter.
[00:03:19.800 --> 00:03:26.160]   Well, I think you can talk about abandoned homeless shelter.
[00:03:26.160 --> 00:03:31.800]   I think it's fair to say that there will be a lot of people that we know that will go
[00:03:31.800 --> 00:03:35.180]   and help make market street better.
[00:03:35.180 --> 00:03:37.320]   Make market street great again.
[00:03:37.320 --> 00:03:39.000]   Make market street great again.
[00:03:39.000 --> 00:03:40.000]   Absolutely.
[00:03:40.000 --> 00:03:43.480]   I'm looking forward to some tofu salads and meditation.
[00:03:43.480 --> 00:03:44.480]   Namaste.
[00:03:44.480 --> 00:03:50.760]   Literally, I think 8000 square feet is meditation rooms that haven't been used in five years.
[00:03:50.760 --> 00:03:53.760]   Quite honestly, though, like on the other side of this, I would say Prague Agrawal does
[00:03:53.760 --> 00:03:56.760]   deserve a statue for shareholder value creation.
[00:03:56.760 --> 00:04:01.720]   What he what 5420 a share, which by the way, we said was going to happen and it did happen
[00:04:01.720 --> 00:04:04.760]   was ginormous in this market.
[00:04:04.760 --> 00:04:12.000]   And I just want to see the look on that barista's face when they're warming up the oat milk.
[00:04:12.000 --> 00:04:19.400]   When a band of very, very tough knuckled company builders walks through that door.
[00:04:19.400 --> 00:04:21.880]   Yeah, the only has left the building.
[00:04:21.880 --> 00:04:23.160]   Let's just leave it at that.
[00:04:23.160 --> 00:04:24.160]   Wow.
[00:04:24.160 --> 00:04:25.600]   So I guess we can talk about it now.
[00:04:25.600 --> 00:04:27.440]   Elon has closed closed.
[00:04:27.440 --> 00:04:29.320]   Yes, we can talk about it.
[00:04:29.320 --> 00:04:34.120]   Well, no, I'm just saying sax and I could not talk about this because we had, you know,
[00:04:34.120 --> 00:04:36.360]   we couldn't talk about it for legal reasons.
[00:04:36.360 --> 00:04:42.040]   They deserve a statue in front of the bronze statue for shareholder value creation on Market
[00:04:42.040 --> 00:04:43.960]   Street in front of that Twitter building.
[00:04:43.960 --> 00:04:46.280]   Best tech CEO of the year.
[00:04:46.280 --> 00:04:48.640]   All right, girl, hold on a second.
[00:04:48.640 --> 00:04:56.580]   So your theory is that he did such a bad job in terms of suppressing viewpoints and censorship
[00:04:56.580 --> 00:05:02.600]   that he actually induced Elon to want to buy the company so he could fix their censorship
[00:05:02.600 --> 00:05:03.600]   problem.
[00:05:03.600 --> 00:05:10.520]   My theory, my theory is simpler than this, which is they got great representation to
[00:05:10.520 --> 00:05:13.600]   do a very bulletproof deal.
[00:05:13.600 --> 00:05:18.000]   And it turns out that contract law still matters in the United States.
[00:05:18.000 --> 00:05:21.080]   And Elon did the right thing and just said, you know what, I'm going to own this thing
[00:05:21.080 --> 00:05:23.240]   and probably double or triple my money.
[00:05:23.240 --> 00:05:25.080]   So I'm just going to go and do it.
[00:05:25.080 --> 00:05:27.440]   And I'll do it for the benefit of everybody else.
[00:05:27.440 --> 00:05:35.080]   But my point is more that they and the board had the wherewithal to fight because you know,
[00:05:35.080 --> 00:05:39.080]   that they could have easily gotten intimidated and capitulated.
[00:05:39.080 --> 00:05:43.720]   And in doing that, whether they were right or wrong or good or bad is irrelevant to me.
[00:05:43.720 --> 00:05:47.780]   They represented shareholder values well, and they got shareholders paid in a moment
[00:05:47.780 --> 00:05:53.320]   where the stock market is still down 2030 40% where big tech is down 50% some of these
[00:05:53.320 --> 00:05:55.800]   big tech companies are on 80%.
[00:05:55.800 --> 00:05:57.720]   These guys sold the company at a premium.
[00:05:57.720 --> 00:06:00.720]   And so that just, you know, we just have to acknowledge that that happened.
[00:06:00.720 --> 00:06:01.720]   That's all.
[00:06:01.720 --> 00:06:04.960]   I wanted to just give you a little bit of background on Twitter historically, you know,
[00:06:04.960 --> 00:06:10.440]   in 2013, the stock was trading at $69.
[00:06:10.440 --> 00:06:12.120]   And it got sold for 54.
[00:06:12.120 --> 00:06:17.200]   Like this company has been sideways for a decade, essentially, in terms of its market
[00:06:17.200 --> 00:06:18.200]   cap.
[00:06:18.200 --> 00:06:26.000]   So, but there's no doubt that I think Elon can turn this around pretty quickly.
[00:06:26.000 --> 00:06:30.520]   And make it massively profitable, I think and clean up the bot problem.
[00:06:30.520 --> 00:06:31.520]   Very quickly.
[00:06:31.520 --> 00:06:34.760]   If you can land two rockets at a time create self driving cars.
[00:06:34.760 --> 00:06:36.560]   I think you can figure this out.
[00:06:36.560 --> 00:06:40.080]   This isn't rocket science and Elon's done rocket science.
[00:06:40.080 --> 00:06:41.400]   So I think he's gonna figure it out.
[00:06:41.400 --> 00:06:42.400]   Right.
[00:06:42.400 --> 00:06:45.120]   Yeah, for what it's worth, I think Elon's really excited about it.
[00:06:45.120 --> 00:06:48.160]   And there is tremendous potential at Twitter.
[00:06:48.160 --> 00:06:52.200]   I mean, the company's been sideways because it hasn't done that much in 10 years.
[00:06:52.200 --> 00:06:54.440]   But there's so much you can do with that product.
[00:06:54.440 --> 00:06:57.240]   It's just, you know, there's a ton of potential.
[00:06:57.240 --> 00:07:02.320]   I think the best way to think about it is he bought a quarter of a billion mouths for
[00:07:02.320 --> 00:07:04.680]   $44 billion.
[00:07:04.680 --> 00:07:09.760]   And in the grand scheme of things, that is, I think going to turn out to be pretty reasonably
[00:07:09.760 --> 00:07:12.320]   cheap.
[00:07:12.320 --> 00:07:16.920]   Especially if he can layer in a few of his bigger ideas.
[00:07:16.920 --> 00:07:20.920]   And I think that those mouths, the value of those monthly active users could probably
[00:07:20.920 --> 00:07:22.440]   double or triple pretty quickly.
[00:07:22.440 --> 00:07:23.440]   Right.
[00:07:23.440 --> 00:07:27.920]   I think that was the so I just sent you guys this link from this analyst.
[00:07:27.920 --> 00:07:35.320]   And he said that Twitter was bought at $172 per monthly active user compared to $81 per
[00:07:35.320 --> 00:07:39.640]   monthly active user at meta, where they sit today.
[00:07:39.640 --> 00:07:43.040]   So but that's but that's for a very different point, which we can double click into because
[00:07:43.040 --> 00:07:49.800]   meta is its own bag of, you know, it's a little bit of an unfortunately, you know, a bit of
[00:07:49.800 --> 00:07:52.120]   a dumpster fire, attached to it.
[00:07:52.120 --> 00:07:58.320]   And I'll explain why because the meta the meta problem is, it's, it's a deep and a very
[00:07:58.320 --> 00:08:03.720]   dangerous situation that they've put themselves in, which is why their mal values are this
[00:08:03.720 --> 00:08:04.720]   low.
[00:08:04.720 --> 00:08:10.920]   But you know, if you had done this analysis a few years ago, the trade was looking at
[00:08:10.920 --> 00:08:16.080]   metas mal values being so high, where you would have said, Why isn't Twitter doing more?
[00:08:16.080 --> 00:08:20.320]   So I know that this, this is a little bit, in my opinion, cherry picking.
[00:08:20.320 --> 00:08:26.440]   Yeah, I think making everything verified in a path to verification, which Ilana has talked
[00:08:26.440 --> 00:08:31.240]   about publicly many times and payments, you know, he's talked about publicly many times,
[00:08:31.240 --> 00:08:36.720]   just those two things alone, could make the experience of being on Twitter, absolutely
[00:08:36.720 --> 00:08:37.720]   delightful.
[00:08:37.720 --> 00:08:40.600]   If everybody could verify themselves, this thing could turn around so quickly.
[00:08:40.600 --> 00:08:44.240]   I'll say I'll say what you're saying in a slightly more, I think the most powerful change
[00:08:44.240 --> 00:08:50.840]   that Twitter could make today is there are two classes of users, people who are verified
[00:08:50.840 --> 00:08:52.440]   real world identity.
[00:08:52.440 --> 00:08:53.440]   Yeah.
[00:08:53.440 --> 00:08:55.520]   And people who want to stay anonymous.
[00:08:55.520 --> 00:08:56.520]   Correct.
[00:08:56.520 --> 00:09:01.440]   There is 100% distribution firehose for people who are real.
[00:09:01.440 --> 00:09:07.920]   And there is a firehose for fake people or fake names that you need to pay to amplify.
[00:09:07.920 --> 00:09:10.520]   Just that one simple change will cut through all the nonsense.
[00:09:10.520 --> 00:09:11.520]   Yeah.
[00:09:11.520 --> 00:09:15.800]   Because if you want to see where the money is being spent, you will be able to see very
[00:09:15.800 --> 00:09:21.160]   quickly because otherwise, there'll be virtually no distribution for anonymous fake people.
[00:09:21.160 --> 00:09:25.120]   And it'll force those people if they really want to be heard, then and that there's something
[00:09:25.120 --> 00:09:28.400]   valuable to say to spend against it.
[00:09:28.400 --> 00:09:30.800]   Well, it really is about the Brigadoons.
[00:09:30.800 --> 00:09:35.080]   And Elon's been very clear about this, you know, it's pretty easy to get rid of the bots.
[00:09:35.080 --> 00:09:39.920]   And if people are opting in to putting themselves into the top class of verified users, well,
[00:09:39.920 --> 00:09:41.440]   that's a revenue stream, right?
[00:09:41.440 --> 00:09:45.480]   And so all of a sudden, you know, I don't know how many millions of people would instantly
[00:09:45.480 --> 00:09:48.200]   say, I'll pay for this for five or 10 bucks a month.
[00:09:48.200 --> 00:09:49.200]   I think you're right.
[00:09:49.200 --> 00:09:52.800]   And I think like what we want to do is like, you know, no offense to all the people out
[00:09:52.800 --> 00:09:58.080]   there, although I don't really care, but no offense, but you cannot use Twitter as a coping
[00:09:58.080 --> 00:09:59.080]   mechanism.
[00:09:59.080 --> 00:10:00.080]   Okay?
[00:10:00.080 --> 00:10:04.720]   Like, I get that life is hard, or that, you know, life hasn't lived out to your expectations,
[00:10:04.720 --> 00:10:09.080]   or, you know, there's envy and whatever of other people, but to go out there and spew
[00:10:09.080 --> 00:10:11.520]   hate doesn't solve anything.
[00:10:11.520 --> 00:10:13.480]   We talk about Brigadoons.
[00:10:13.480 --> 00:10:18.080]   Well, there's also just a lot of people that are just in general.
[00:10:18.080 --> 00:10:20.000]   They're just they're just mean.
[00:10:20.000 --> 00:10:21.480]   And I'll give you a perfect example.
[00:10:21.480 --> 00:10:24.760]   There was a woman that I saw on tik tok.
[00:10:24.760 --> 00:10:29.800]   And she's like, you know, been married for 13 years, mother of two kids.
[00:10:29.800 --> 00:10:34.840]   And she was, she had a thing that went viral, where she was talking about who's in charge
[00:10:34.840 --> 00:10:37.200]   her or her husband, and it was a very funny little thing.
[00:10:37.200 --> 00:10:41.360]   And so I followed a couple of her videos just to see what else she had posted.
[00:10:41.360 --> 00:10:45.360]   And one of the videos was how she has some complicated health issues, which she was very
[00:10:45.360 --> 00:10:51.000]   public about PCOS and how it causes, you know, issues in losing weight.
[00:10:51.000 --> 00:10:56.340]   And she posted a pre and post picture of her, which takes a lot of courage.
[00:10:56.340 --> 00:10:58.980]   And she was like Brigadoon.
[00:10:58.980 --> 00:11:04.160]   And it's like, what is wrong with these broken people that have to give this woman a hard
[00:11:04.160 --> 00:11:05.160]   time.
[00:11:05.160 --> 00:11:10.280]   And it just it took so to me, these social media channels are not coping mechanisms,
[00:11:10.280 --> 00:11:11.800]   they were never meant to be.
[00:11:11.800 --> 00:11:18.040]   And so, you know, if they have to go to 4chan or 8chan or Reddit or whatever, better to
[00:11:18.040 --> 00:11:23.040]   sort of create these honeypots of hatred, then to have it spew everywhere, because it
[00:11:23.040 --> 00:11:26.080]   makes for the rest of us these platforms to be unusable.
[00:11:26.080 --> 00:11:32.920]   Saks, you were the CEO of PayPal with Elon and Roloff and TL and everybody in that crew
[00:11:32.920 --> 00:11:38.480]   over 20 years ago, and verified you understand pretty well, because you yourself have been
[00:11:38.480 --> 00:11:44.560]   Brigadoon of late, and you've experienced this firsthand the psychological torture that
[00:11:44.560 --> 00:11:48.200]   made you take a week off from the show, in fact, because you were so under duress.
[00:11:48.200 --> 00:11:51.880]   I'm kidding, you had a planned week off, you're allowed to have vacation.
[00:11:51.880 --> 00:11:54.200]   Which of the two ideas is the bigger idea?
[00:11:54.200 --> 00:11:59.720]   Payments, making Twitter into PayPal, including that x.com, which was the original name of
[00:11:59.720 --> 00:12:03.840]   that was Elon's payment company, and he owns a domain x.com.
[00:12:03.840 --> 00:12:08.660]   Which is a bigger idea, the payments, or the verification?
[00:12:08.660 --> 00:12:11.920]   Which is the bigger idea for increasing shareholder value?
[00:12:11.920 --> 00:12:12.920]   Which would you do first?
[00:12:12.920 --> 00:12:16.240]   I mean, payments is an entire roadmap, right?
[00:12:16.240 --> 00:12:18.360]   So there's a lot that could be done there.
[00:12:18.360 --> 00:12:19.360]   Explain.
[00:12:19.360 --> 00:12:23.480]   Well, I mean, it's, it's about I mean, you could layer on a lot of services on top of
[00:12:23.480 --> 00:12:24.480]   that.
[00:12:24.480 --> 00:12:26.280]   So it's not just like one feature.
[00:12:26.280 --> 00:12:29.400]   Look, I think they're both compelling in terms of where they could lead.
[00:12:29.400 --> 00:12:35.680]   I think what's amazing about Elon as an entrepreneur is he always starts with a mission.
[00:12:35.680 --> 00:12:39.120]   And then he figures out how to turn it into a great product and a great business.
[00:12:39.120 --> 00:12:44.800]   So for example, with SpaceX, the mission was to get to Mars to make life multi planetary,
[00:12:44.800 --> 00:12:48.200]   you would think that'd be a spectacularly unprofitable business.
[00:12:48.200 --> 00:12:52.360]   But in the course of pursuing that mission, he figured out the launch business.
[00:12:52.360 --> 00:12:53.680]   And then the satellite business was Starlink.
[00:12:53.680 --> 00:12:57.720]   And I think Starlink is going to be a phenomenal business.
[00:12:57.720 --> 00:13:01.560]   And likewise, with Tesla, he started with the mission of moving the world to sustainable
[00:13:01.560 --> 00:13:02.560]   energy.
[00:13:02.560 --> 00:13:03.560]   Yeah.
[00:13:03.560 --> 00:13:06.960]   And in the process of doing that, he created the world's best car, not just the world's
[00:13:06.960 --> 00:13:10.120]   best electric car, but I just think it's the best car in the world.
[00:13:10.120 --> 00:13:11.800]   And Tesla is this amazing business today.
[00:13:11.800 --> 00:13:14.000]   It's so far ahead of every other car company.
[00:13:14.000 --> 00:13:19.160]   So look, I think what's cool about what Elon is doing is he's starting with this mission
[00:13:19.160 --> 00:13:24.600]   of restoring Twitter to being a free speech platform of being the town square, it was
[00:13:24.600 --> 00:13:25.960]   always meant to be.
[00:13:25.960 --> 00:13:29.360]   And in the process of doing that, he's going to figure out how to make Twitter into an
[00:13:29.360 --> 00:13:33.120]   even better product and into a great business, which is not today.
[00:13:33.120 --> 00:13:36.240]   I think Twitter's losing, you know, a few hundred million dollars a quarter.
[00:13:36.240 --> 00:13:38.720]   So there's work to do on all those fronts.
[00:13:38.720 --> 00:13:42.720]   But I think, you know, it's really impressive to see.
[00:13:42.720 --> 00:13:44.720]   And you know, he's still operating at the top of his game.
[00:13:44.720 --> 00:13:49.720]   I mean, 20 years after PayPal, some of us are just doing a podcast, but he is, he's
[00:13:49.720 --> 00:13:52.720]   still like, some of us are exhausted.
[00:13:52.720 --> 00:13:54.920]   We're tired, but we're tired.
[00:13:54.920 --> 00:13:56.600]   He's like working 16 hour days.
[00:13:56.600 --> 00:13:58.800]   He's been leveling up for 20 years.
[00:13:58.800 --> 00:14:02.520]   And at this point, he's like a level 99 major something.
[00:14:02.520 --> 00:14:05.160]   No, he's like a crazy.
[00:14:05.160 --> 00:14:07.040]   It's amazing to see.
[00:14:07.040 --> 00:14:12.560]   Freeberg, the biggest issue I perceive in the short term for Twitter is going to be
[00:14:12.560 --> 00:14:17.760]   what to do with people like Trump and Kanye West or yay.
[00:14:17.760 --> 00:14:23.160]   And of course, that's all going to seem like Elon is making those decisions as an individual
[00:14:23.160 --> 00:14:25.480]   as opposed to for the platform, etc.
[00:14:25.480 --> 00:14:30.160]   Should he let somebody like Kanye West, I'm sorry, yay is he likes to call himself who
[00:14:30.160 --> 00:14:34.200]   was in the middle of an obvious manic episode back on the platform?
[00:14:34.200 --> 00:14:35.720]   Should he let Trump back on the platform?
[00:14:35.720 --> 00:14:40.280]   How do you think he should handle those two polarizing individuals specifically?
[00:14:40.280 --> 00:14:44.240]   Look, I mean, I think this is what's going to be really interesting to watch because
[00:14:44.240 --> 00:14:51.120]   there have been very successful, very inspirational, very intelligent, very creative entrepreneurs
[00:14:51.120 --> 00:14:57.120]   that have started and built generally kind of open platforms at the beginning, only to
[00:14:57.120 --> 00:15:03.800]   over time, be challenged with the content that doesn't feel appropriate.
[00:15:03.800 --> 00:15:07.120]   And then they come back and they make the necessary kind of moderation guidelines and
[00:15:07.120 --> 00:15:10.000]   they make the necessary edits to the way the platform operates.
[00:15:10.000 --> 00:15:14.000]   This is how Google operated originally, you know, and then they ended up saying, you know
[00:15:14.000 --> 00:15:17.200]   what, if we're going to be in China, we do have to create a censored version of the internet.
[00:15:17.200 --> 00:15:18.200]   And they did that.
[00:15:18.200 --> 00:15:19.880]   And that was controversial.
[00:15:19.880 --> 00:15:22.720]   With YouTube, they've got a lot of censoring, and it was supposed to be just a generally
[00:15:22.720 --> 00:15:25.000]   open platform for anyone to use.
[00:15:25.000 --> 00:15:29.500]   And they were even Larry and Sergey were kind of flouting DMCA at the beginning.
[00:15:29.500 --> 00:15:33.160]   And they were like, it's not our job to monitor copyright, you have to file a takedown notice.
[00:15:33.160 --> 00:15:35.160]   And they kind of waved their hands in the air.
[00:15:35.160 --> 00:15:38.800]   Over time, they realized that that could actually damage and completely ruin the platform.
[00:15:38.800 --> 00:15:42.360]   And they had to go in and create guidelines and moderation systems.
[00:15:42.360 --> 00:15:46.160]   And the same was true of Ev and Jack at Twitter.
[00:15:46.160 --> 00:15:48.400]   The same was true of the founders at Reddit.
[00:15:48.400 --> 00:15:51.720]   And I don't know if you guys, you know, remember that period of time when Ellen Powell was
[00:15:51.720 --> 00:15:56.400]   CEO of Reddit, and she went in and cleaned up a lot of the bullying and harassment and
[00:15:56.400 --> 00:15:58.120]   nastiness that was going on on Reddit.
[00:15:58.120 --> 00:16:00.800]   And she got a lot of controversy for why are you closing it down?
[00:16:00.800 --> 00:16:02.120]   Why are you censoring it?
[00:16:02.120 --> 00:16:04.620]   Elon is a reasonable person.
[00:16:04.620 --> 00:16:07.980]   And he's going to be faced with unreasonable people on this platform.
[00:16:07.980 --> 00:16:11.600]   And when that happens, he's going to have very tough decisions to make about what kind
[00:16:11.600 --> 00:16:15.400]   of platform he wants to have, what's the quality of that platform going to need to look like.
[00:16:15.400 --> 00:16:18.480]   And then all of a sudden, he's gonna have to look in the mirror and say, did I step
[00:16:18.480 --> 00:16:19.480]   on the wrong side?
[00:16:19.480 --> 00:16:22.400]   And you know, he's, he's idealistic, and it's great.
[00:16:22.400 --> 00:16:23.400]   And it's wonderful.
[00:16:23.400 --> 00:16:24.920]   And I hope that he's successful.
[00:16:24.920 --> 00:16:28.520]   But to some degree, some amount of moderation is going to be necessary to create a high
[00:16:28.520 --> 00:16:29.520]   quality product.
[00:16:29.520 --> 00:16:30.880]   Would you allow?
[00:16:30.880 --> 00:16:34.000]   Would you if you were in charge yourself, freeberg?
[00:16:34.000 --> 00:16:36.480]   Would you put Trump back on the platform?
[00:16:36.480 --> 00:16:37.680]   And under what circumstances?
[00:16:37.680 --> 00:16:41.240]   And would you allow something like Kanye West back on the platform?
[00:16:41.240 --> 00:16:42.240]   At some point?
[00:16:42.240 --> 00:16:43.240]   Me, obviously?
[00:16:43.240 --> 00:16:44.240]   Yeah, you personally?
[00:16:44.240 --> 00:16:46.440]   Yeah, I think I'm gonna answer you personally on those two.
[00:16:46.440 --> 00:16:49.280]   Yeah, look, my content moderation guidelines.
[00:16:49.280 --> 00:16:51.800]   You know, it's, it gets very nuanced very quick.
[00:16:51.800 --> 00:16:52.800]   What do you allow people to say?
[00:16:52.800 --> 00:16:54.160]   What do you not allow them to say?
[00:16:54.160 --> 00:16:57.720]   And then if they violate them, is there the opportunity for a lifetime ban?
[00:16:57.720 --> 00:16:58.720]   I don't think so.
[00:16:58.720 --> 00:17:00.360]   I don't think anyone should have a lifetime ban on these platforms.
[00:17:00.360 --> 00:17:05.160]   So I'm totally would you do that for Kanye West, who has been saying crazy anti semitic
[00:17:05.160 --> 00:17:07.160]   stuff, which has real world danger.
[00:17:07.160 --> 00:17:09.960]   That's already started to spill over where people are putting up banners like Kanye's
[00:17:09.960 --> 00:17:11.760]   what right about the Jews.
[00:17:11.760 --> 00:17:16.120]   And they're putting up banners like over the, you know, 10 freeway, as you may have seen
[00:17:16.120 --> 00:17:20.360]   in Los Angeles, how would you deal with Kanye specifically in a manic anti semitic episode
[00:17:20.360 --> 00:17:21.360]   that he's been?
[00:17:21.360 --> 00:17:25.360]   Look, I think the question is anyone that's saying anything racist or whatever might be
[00:17:25.360 --> 00:17:29.600]   deemed kind of to fall in that category.
[00:17:29.600 --> 00:17:34.160]   There's a tagging mechanism, you have to figure out how to create the tagging mechanism.
[00:17:34.160 --> 00:17:37.800]   Based on that tagging mechanism, the default is it's like when you go to Google and you
[00:17:37.800 --> 00:17:39.720]   search for stuff, they exclude porn.
[00:17:39.720 --> 00:17:47.160]   So all porn content that's indexed on Google's index servers is indexes porn, and it's default
[00:17:47.160 --> 00:17:48.160]   off.
[00:17:48.160 --> 00:17:53.480]   There's a safe search thing you got to turn, I think off or something to access stuff that
[00:17:53.480 --> 00:17:54.720]   Google deems inappropriate.
[00:17:54.720 --> 00:17:57.840]   So how do you how do you how do you do that?
[00:17:57.840 --> 00:18:03.440]   No, but I think I by the way, I'll tell you when I worked at Google, we used to have pizza
[00:18:03.440 --> 00:18:07.240]   weekends where you would go into the office on the weekends, they give you free pizza,
[00:18:07.240 --> 00:18:11.080]   and everyone would tag, you'd watch porn, and you would tag porn.
[00:18:11.080 --> 00:18:15.000]   And so you basically go through the indexing servers, they show you images and Google images,
[00:18:15.000 --> 00:18:16.600]   and you click porn or not porn.
[00:18:16.600 --> 00:18:18.920]   And it was just like, Hey, come and volunteer, come and help us do it.
[00:18:18.920 --> 00:18:23.040]   And there was all these engineers sitting in the friggin cafeteria tagging porn.
[00:18:23.040 --> 00:18:24.760]   But actually, that happened to sacks.
[00:18:24.760 --> 00:18:25.760]   And he saw Tucker Carlson.
[00:18:25.760 --> 00:18:27.360]   And he said, Yeah, that's porn.
[00:18:27.360 --> 00:18:31.440]   That's, that's my, my personal for Yes, I think I think they're on Moncler had Yes,
[00:18:31.440 --> 00:18:35.040]   I think the same mechanism is needed on these social networks, which is that you have to
[00:18:35.040 --> 00:18:39.560]   figure out what you have to figure out a way to use AI to tag content.
[00:18:39.560 --> 00:18:41.000]   And think about them as cable.
[00:18:41.000 --> 00:18:44.720]   Just let me finish for one second, you think about them as cable, cable stations on a cable
[00:18:44.720 --> 00:18:45.720]   company.
[00:18:45.720 --> 00:18:46.720]   So they're the cable company.
[00:18:46.720 --> 00:18:47.720]   And there's different stations.
[00:18:47.720 --> 00:18:50.640]   And you as a user decide, what do you not want to opt into?
[00:18:50.640 --> 00:18:51.760]   And what do you want to opt into?
[00:18:51.760 --> 00:18:55.960]   What content you want to exclude from your version and your experience of Twitter.
[00:18:55.960 --> 00:18:59.680]   And if you're okay with the stuff Kanye says, you're okay with the stuff Trump says, you
[00:18:59.680 --> 00:19:00.720]   can keep that stuff in.
[00:19:00.720 --> 00:19:04.360]   If you want to exclude that type of content, it's excluded for you.
[00:19:04.360 --> 00:19:06.440]   And I think that's what Twitter ultimately has to become.
[00:19:06.440 --> 00:19:07.840]   What do you think, Chamath?
[00:19:07.840 --> 00:19:10.160]   Would you put Trump back on the platform?
[00:19:10.160 --> 00:19:15.200]   And seeing, you know, Kanye West having this manic episode and saying, you know, basically
[00:19:15.200 --> 00:19:17.960]   participating in hate speech explicitly?
[00:19:17.960 --> 00:19:21.320]   How would you handle those two specific instances in 2022?
[00:19:21.320 --> 00:19:23.000]   Going into 2023?
[00:19:23.000 --> 00:19:28.720]   I think that there has to be a way where nobody is banned forever.
[00:19:28.720 --> 00:19:34.120]   Okay, I think that when somebody is banned temporarily, they can be banned for any reason
[00:19:34.120 --> 00:19:40.240]   that violates a term of service that's well understood and uniformly enforced.
[00:19:40.240 --> 00:19:43.160]   And I think that's the right of a private company.
[00:19:43.160 --> 00:19:48.720]   But there has to be a way to get back on in the case of both of these folks.
[00:19:48.720 --> 00:19:56.200]   There should be a way to basically, you know, have because of the the step, the quantity
[00:19:56.200 --> 00:20:04.400]   of their reach, some sort of almost like tribunal or, you know, mediator that can understand
[00:20:04.400 --> 00:20:07.080]   what's going on.
[00:20:07.080 --> 00:20:10.640]   Because if somebody is going through a manic episode, it's absolutely right to turn that
[00:20:10.640 --> 00:20:11.640]   off.
[00:20:11.640 --> 00:20:16.240]   I mean, these guys should have turned him off much, much sooner.
[00:20:16.240 --> 00:20:19.960]   Because when you're in the middle of a mania, and I said this last week, like, you know,
[00:20:19.960 --> 00:20:24.240]   like, for example, like this, this relative of mine, when they're in a manic episode,
[00:20:24.240 --> 00:20:31.400]   it's 60 7080 emails a day and text messages 100 texts that I get.
[00:20:31.400 --> 00:20:34.040]   And they're honestly, they're vile.
[00:20:34.040 --> 00:20:35.040]   Yeah.
[00:20:35.040 --> 00:20:36.040]   Okay.
[00:20:36.040 --> 00:20:37.040]   And they don't even remember them half the time.
[00:20:37.040 --> 00:20:38.040]   And they don't even know.
[00:20:38.040 --> 00:20:42.220]   So and, and, you know, they go through paranoia, they go through mania, they go through these
[00:20:42.220 --> 00:20:44.720]   periods where they think they're completely right.
[00:20:44.720 --> 00:20:48.400]   They go through these periods where they look completely sane and normal.
[00:20:48.400 --> 00:20:53.520]   So, so it's a tough, the most important thing, when you have a family member in mental health
[00:20:53.520 --> 00:20:56.600]   crisis is to get the phone away from them.
[00:20:56.600 --> 00:21:02.140]   That is a weapon that only continues the loop and to re regulate this person.
[00:21:02.140 --> 00:21:07.260]   And then there should be a way to prove that you're back in a re regulated state to get
[00:21:07.260 --> 00:21:08.260]   these tools back.
[00:21:08.260 --> 00:21:12.800]   But I think that that needs to, we just need to acknowledge that there's just a lot of
[00:21:12.800 --> 00:21:14.100]   people with mental health issues.
[00:21:14.100 --> 00:21:18.200]   There's a lot of social media, there's a lot of damage that can be done.
[00:21:18.200 --> 00:21:19.760]   It's not to forgive these people.
[00:21:19.760 --> 00:21:23.320]   But it's to explain that in moments, you got to shut these channels down, and then give
[00:21:23.320 --> 00:21:25.840]   them a way to come back when they've re regulated.
[00:21:25.840 --> 00:21:28.080]   Sacks, how do you think about it?
[00:21:28.080 --> 00:21:33.760]   Well, with regard to Trump, I don't know what the continuing reason is for him not being
[00:21:33.760 --> 00:21:35.520]   allowed on the platform.
[00:21:35.520 --> 00:21:42.240]   Remember that when he was banned, it was considered to be a temporary measure because he was supposedly
[00:21:42.240 --> 00:21:44.600]   inciting a riot, right.
[00:21:44.600 --> 00:21:50.920]   So I think incitement to violence is legitimate grounds for taking down speech.
[00:21:50.920 --> 00:21:55.440]   But once that breach of the peace is over, I don't know why it would become a permanent
[00:21:55.440 --> 00:21:57.140]   ban as opposed to a timeout.
[00:21:57.140 --> 00:22:03.000]   So I don't even know how the companies continue to justify the ban on Trump, except for the
[00:22:03.000 --> 00:22:05.480]   fact that they just think that he's a threat to democracy.
[00:22:05.480 --> 00:22:11.400]   Well, I don't think that's for social networks to determine is that who gets to participate
[00:22:11.400 --> 00:22:13.400]   in our political process.
[00:22:13.400 --> 00:22:16.360]   So it's not necessarily the first thing I would do.
[00:22:16.360 --> 00:22:18.400]   But do I think that Trump should be allowed back?
[00:22:18.400 --> 00:22:19.840]   Yeah, I do.
[00:22:19.840 --> 00:22:25.600]   With regard to Kanye, it's a little more complicated because like you're saying, it's
[00:22:25.600 --> 00:22:30.500]   hard to know whether he's having a manic episode or he's just being Kanye.
[00:22:30.500 --> 00:22:33.240]   What he's saying right now is probably not in his own interest and probably it would
[00:22:33.240 --> 00:22:35.680]   be in his best interest to have a timeout.
[00:22:35.680 --> 00:22:40.840]   But what I would look for guidance here is there is a Supreme Court decision.
[00:22:40.840 --> 00:22:46.300]   And my general view on the content moderation is that these social networking companies
[00:22:46.300 --> 00:22:51.280]   should be looking for inspiration to Supreme Court decisions because Supreme Court's been
[00:22:51.280 --> 00:22:55.280]   wrestling with these issues for hundreds of years, whereas social networks are just making
[00:22:55.280 --> 00:22:57.200]   it up as they go along.
[00:22:57.200 --> 00:23:01.960]   And there are nine major categories of speech that the Supreme Court has said are not protected
[00:23:01.960 --> 00:23:04.120]   because they actually are dangerous speech.
[00:23:04.120 --> 00:23:10.560]   So for example, in this decision called Chplinsky v. New Hampshire, which came out in 1942,
[00:23:10.560 --> 00:23:15.020]   the Supreme Court held that so-called fighting words were not protected.
[00:23:15.020 --> 00:23:19.440]   And they define fighting words as speech that tends to incite an immediate breach of the
[00:23:19.440 --> 00:23:25.000]   peace through the use of "personally abusive language" that when addressed, the ordinary
[00:23:25.000 --> 00:23:30.140]   citizen is as a matter of common knowledge, inherently likely to provoke a violent reaction.
[00:23:30.140 --> 00:23:38.720]   So I would use that type of decision by the Supreme Court as inspiration to say that racist,
[00:23:38.720 --> 00:23:45.780]   misogynistic, homophobic and other racial and ethnic slurs shouldn't be allowed on these
[00:23:45.780 --> 00:23:50.480]   networks because it doesn't do anything to enhance the public debate.
[00:23:50.480 --> 00:23:55.600]   Now, there is a question like could Kanye frame his arguments in a way that is still
[00:23:55.600 --> 00:23:59.440]   incredibly offensive to us, but doesn't use slurs?
[00:23:59.440 --> 00:24:03.520]   Yeah, for example, he could say, hey, here are the top 10 media companies, here are the
[00:24:03.520 --> 00:24:06.040]   executives, here's the percentage that are Jewish.
[00:24:06.040 --> 00:24:09.280]   And this is, you know, my concern is that this is a, and here's the percentage of people
[00:24:09.280 --> 00:24:12.040]   who are Jewish in the population, you could some bullshit like that.
[00:24:12.040 --> 00:24:16.160]   And then you're like, okay, did he say something anti Semitic, you know, and you're kind of
[00:24:16.160 --> 00:24:18.080]   in this area.
[00:24:18.080 --> 00:24:20.400]   And there's always going to be edge cases, and people are always going to be pushing
[00:24:20.400 --> 00:24:21.400]   the envelope.
[00:24:21.400 --> 00:24:26.560]   And so listen, just because we find it offensive, and you know, it's specifically offensive
[00:24:26.560 --> 00:24:30.120]   to me, that doesn't mean that it should automatically be banned.
[00:24:30.120 --> 00:24:35.160]   I think slurs slurs banned or out but, but arguments, I don't know that we should be
[00:24:35.160 --> 00:24:37.200]   banning entire categories of arguments.
[00:24:37.200 --> 00:24:41.400]   And, and look, part of the problem here is that lots of people are hearing the arguments
[00:24:41.400 --> 00:24:44.880]   that Ye is making, whether he's making them on Twitter or not.
[00:24:44.880 --> 00:24:50.740]   And because he's there's a total ban, people can't really engage with him on Twitter.
[00:24:50.740 --> 00:24:55.480]   And so he's not getting off ramped from this rabbit hole he's falling into.
[00:24:55.480 --> 00:24:59.800]   And nobody else who might be a fan of his is hearing the other side of the argument.
[00:24:59.800 --> 00:25:05.240]   So I don't know that it's ultimately in the long term interest of the town square to be
[00:25:05.240 --> 00:25:10.520]   banning, you know, the argument, the you know, ACLU and other people have is like, hey, you
[00:25:10.520 --> 00:25:15.240]   put a little sunlight on these bad opinions, at least everybody knows who has the bad opinions,
[00:25:15.240 --> 00:25:16.240]   and you can fight them.
[00:25:16.240 --> 00:25:19.440]   Paradoxically, while we're talking, I mean, do you really want these folks going to the
[00:25:19.440 --> 00:25:24.100]   dark web and you know, being untraceable, there is some value in kind of knowing who's
[00:25:24.100 --> 00:25:28.760]   getting radicalized, and hopefully, exposing them to other opinions in the same conversation
[00:25:28.760 --> 00:25:29.760]   that can all frame them.
[00:25:29.760 --> 00:25:35.200]   Yeah, I mean, paradoxically, while we're talking, Ilan just tweeted at 1118 am, Twitter will
[00:25:35.200 --> 00:25:39.760]   be forming a content moderation council with widely diverse viewpoints, no matter no major
[00:25:39.760 --> 00:25:44.680]   content decisions or account reinstatements will happen before that council convenes.
[00:25:44.680 --> 00:25:48.520]   So he's going to take the same approach that Facebook has, they have a council as well
[00:25:48.520 --> 00:25:50.320]   that Zuckerberg tried to set up.
[00:25:50.320 --> 00:25:53.120]   So I think he realizes there should be a thoughtful discussion.
[00:25:53.120 --> 00:25:55.200]   So you're gonna be on that council?
[00:25:55.200 --> 00:25:56.200]   I have no idea.
[00:25:56.200 --> 00:26:01.000]   That sounds like a the worst purgatory you could ever be in is to be the person who has
[00:26:01.000 --> 00:26:02.240]   to make these decisions.
[00:26:02.240 --> 00:26:04.640]   Like, talk about a no win situation.
[00:26:04.640 --> 00:26:07.280]   I'm curious Chamath.
[00:26:07.280 --> 00:26:12.280]   We talked last week about Kanye and then Lex Friedman dropped his episode Lex came at it
[00:26:12.280 --> 00:26:14.880]   with he pushed back on Kanye.
[00:26:14.880 --> 00:26:16.120]   I don't know if you watch some of the highlights.
[00:26:16.120 --> 00:26:17.560]   I saw some of the highs he pushed back pretty hard.
[00:26:17.560 --> 00:26:18.560]   I watched the whole thing.
[00:26:18.560 --> 00:26:22.360]   Okay, so he pushed back really hard on the anti semitic stuff.
[00:26:22.360 --> 00:26:23.360]   And we had a discussion last week.
[00:26:23.360 --> 00:26:25.120]   I said, Hey, you can't platform this guy.
[00:26:25.120 --> 00:26:31.280]   But it looks like Lex had a specific point of view, which is he has a friendship with
[00:26:31.280 --> 00:26:32.860]   Kanye of some level.
[00:26:32.860 --> 00:26:37.280]   And he wanted to try to convince him in this manicness that he's wrong about things did
[00:26:37.280 --> 00:26:38.960]   do you think Lex succeeded?
[00:26:38.960 --> 00:26:39.960]   And he should have done it?
[00:26:39.960 --> 00:26:41.480]   I obviously we won't question Lex's intent.
[00:26:41.480 --> 00:26:49.840]   We know I have had replaced Lex with me and Kanye with my relative.
[00:26:49.840 --> 00:26:55.720]   Wasn't on television or whatever, but I've had these same kinds of I'll call them interventions.
[00:26:55.720 --> 00:27:01.500]   And like I said, this person goes through periods of lucidity, periods of mania, periods
[00:27:01.500 --> 00:27:06.080]   of paranoia, periods of anger.
[00:27:06.080 --> 00:27:11.280]   And so that's all I saw when I was watching this thing is just what a lot of people in
[00:27:11.280 --> 00:27:16.760]   the United States deal in the world deal with when they have relatives who are suffering
[00:27:16.760 --> 00:27:18.480]   from one of these things.
[00:27:18.480 --> 00:27:21.280]   And my relative has said the same thing.
[00:27:21.280 --> 00:27:22.960]   There's nothing wrong with me.
[00:27:22.960 --> 00:27:24.240]   I don't need medication.
[00:27:24.240 --> 00:27:26.200]   I'm not on these meds, blah, blah, blah.
[00:27:26.200 --> 00:27:28.320]   I don't want to judge because I don't know him.
[00:27:28.320 --> 00:27:34.400]   But I'll tell you in my situation, trying to like, for example, like this person thinks
[00:27:34.400 --> 00:27:42.720]   that myself and one other person like we hacked into a computer system of the place that they
[00:27:42.720 --> 00:27:48.880]   worked to manipulate the financial records to point to this person as having committed
[00:27:48.880 --> 00:27:53.920]   a fraud and has and then thinks that people are now listening and bugging the phone.
[00:27:53.920 --> 00:27:56.680]   I mean, there's all kinds of stuff over and over again.
[00:27:56.680 --> 00:27:58.920]   And then sometimes they don't think that and sometimes they do.
[00:27:58.920 --> 00:28:00.560]   And it's like, it's mad.
[00:28:00.560 --> 00:28:06.400]   What I'm trying to tell you is like, when you're not when you're in a normal state,
[00:28:06.400 --> 00:28:11.440]   regulated state, and you're talking to somebody who's dysregulated, it's not too normal people
[00:28:11.440 --> 00:28:16.240]   having a conversation where you're trying to get them to see the logic of your ways.
[00:28:16.240 --> 00:28:19.880]   So again, I just think that it's not it's not a thing that should be litigated in the
[00:28:19.880 --> 00:28:20.880]   media.
[00:28:20.880 --> 00:28:25.280]   I think it is a thing that is where people that care for this person need to surround
[00:28:25.280 --> 00:28:32.880]   them and get them with a doctor to help them rebalance in in the in the case of our family.
[00:28:32.880 --> 00:28:38.360]   What it turns out is that this person needs to constantly be retitrated the drugs for
[00:28:38.360 --> 00:28:40.760]   them to be regulated.
[00:28:40.760 --> 00:28:42.000]   That may be different for other people.
[00:28:42.000 --> 00:28:43.520]   And I don't know Kanye situation.
[00:28:43.520 --> 00:28:50.000]   So anyways, I see all that and I and I and I go to my own family situation, which I'm
[00:28:50.000 --> 00:28:51.760]   which we actively deal with today.
[00:28:51.760 --> 00:28:55.680]   And I don't have much of an idea of what to do about Kanye because it brings up too much
[00:28:55.680 --> 00:28:59.400]   stuff about what I'm dealing with in real time with my own family.
[00:28:59.400 --> 00:29:00.880]   I'm sorry, going through that.
[00:29:00.880 --> 00:29:04.440]   And I Yeah, like I said, I mean, I think Lex had good intent.
[00:29:04.440 --> 00:29:06.720]   I don't think it's worth doing.
[00:29:06.720 --> 00:29:08.760]   No, he's somebody he's incredible.
[00:29:08.760 --> 00:29:12.040]   You know, he's a really beautiful, empathetic person Lex is in general.
[00:29:12.040 --> 00:29:14.400]   So I think he tried to do the best job he could.
[00:29:14.400 --> 00:29:18.360]   So I saw I saw part of the the Lex interview, it was two and a half hours and I wasn't gonna
[00:29:18.360 --> 00:29:19.760]   sit through two and a half hours of it.
[00:29:19.760 --> 00:29:24.400]   You know, that's I went to I went to the chapter titles and I was in the middle is like Holocaust
[00:29:24.400 --> 00:29:25.400]   like, right.
[00:29:25.400 --> 00:29:28.000]   I was like, Okay, let's just go right to the train wreck.
[00:29:28.000 --> 00:29:29.240]   Yeah.
[00:29:29.240 --> 00:29:30.560]   So I skipped it to there.
[00:29:30.560 --> 00:29:34.640]   But anyway, I think the argument that that Lex should have made or pointed out to Kanye
[00:29:34.640 --> 00:29:41.400]   is like, go see the new Elvis movie, which is all about how an artist basically got taken
[00:29:41.400 --> 00:29:45.480]   advantage of by his business manager.
[00:29:45.480 --> 00:29:51.520]   And you'll see that this idea is a very familiar trope in the music business.
[00:29:51.520 --> 00:29:55.120]   But that manager, Colonel Tom Parker, he wasn't Jewish.
[00:29:55.120 --> 00:29:58.600]   He was a Dutch con man pretending to be a southern hick.
[00:29:58.600 --> 00:30:00.000]   So this can happen.
[00:30:00.000 --> 00:30:05.160]   And it's a very common story and it's got nothing to do with the religion or race or
[00:30:05.160 --> 00:30:08.400]   whatever of the business people.
[00:30:08.400 --> 00:30:14.720]   So and in fact, the person in that movie who has the best advice for Elvis is BB King,
[00:30:14.720 --> 00:30:19.240]   who says to Elvis at a very early point in the movie, he says, if you don't do the business,
[00:30:19.240 --> 00:30:22.080]   the business will do you.
[00:30:22.080 --> 00:30:28.200]   And so look, I think Kanye, again, if I was to sort of steel man and respond to it is,
[00:30:28.200 --> 00:30:33.120]   you know, what you're describing is a pretty common of artists being taken advantage of
[00:30:33.120 --> 00:30:34.520]   is is a common issue.
[00:30:34.520 --> 00:30:37.800]   It goes back a long time and it's got nothing to do with religion.
[00:30:37.800 --> 00:30:42.400]   And quite frankly, you know, there's probably a lot of other Jews in your life who've helped
[00:30:42.400 --> 00:30:43.400]   you.
[00:30:43.400 --> 00:30:46.480]   I mean, I wonder the last time you went to a doctor, did you notice whether they were
[00:30:46.480 --> 00:30:47.480]   Jewish or not?
[00:30:47.480 --> 00:30:53.840]   You know, and so he's developed a little bit of a fixation here of noticing that some people
[00:30:53.840 --> 00:30:57.400]   are Jewish, but probably he's not noticing when other people are Jewish who probably
[00:30:57.400 --> 00:30:58.400]   helped him.
[00:30:58.400 --> 00:30:59.400]   Yeah.
[00:30:59.400 --> 00:31:02.600]   So that's probably like the argument I would have made with him.
[00:31:02.600 --> 00:31:04.760]   You know, if I were conducting that interview,
[00:31:04.760 --> 00:31:08.640]   and you make the argument to a person who's in a manic episode, and there's no way to
[00:31:08.640 --> 00:31:09.640]   reach them.
[00:31:09.640 --> 00:31:11.120]   They don't even realize what they're saying.
[00:31:11.120 --> 00:31:13.400]   They forget what they say when they get through the manic episode.
[00:31:13.400 --> 00:31:17.480]   These paranoid, these paranoias don't tend to come up when you're in a regulated normal
[00:31:17.480 --> 00:31:18.480]   state.
[00:31:18.480 --> 00:31:19.480]   Exactly.
[00:31:19.480 --> 00:31:21.400]   All right, let's talk about meta.
[00:31:21.400 --> 00:31:25.400]   Brad Gerson was on last week, we've had an ongoing discussion about big tech entitlement
[00:31:25.400 --> 00:31:28.760]   spending, the number of employees at these companies.
[00:31:28.760 --> 00:31:33.520]   On Monday, Brad, I think, you know, got a little worked up on the last pod, maybe, and
[00:31:33.520 --> 00:31:40.040]   dropped an open letter, some might say activist, he would say constructivist to Zuckerberg
[00:31:40.040 --> 00:31:45.600]   and the team over there, hey, maybe pump the brakes on the capex, maybe do a riff, maybe
[00:31:45.600 --> 00:31:46.600]   become profitable.
[00:31:46.600 --> 00:31:55.360]   Anyway, the revenue and the third quarter was a complete, utter disaster for meta.
[00:31:55.360 --> 00:31:59.960]   And the stock has plummeted, and been under $100 a share.
[00:31:59.960 --> 00:32:02.160]   I don't know who wants to start on this one.
[00:32:02.160 --> 00:32:04.120]   Okay, look, there's a lot to unpack here.
[00:32:04.120 --> 00:32:10.000]   So I think I think we should take our time because I think one part of it is meta.
[00:32:10.000 --> 00:32:14.240]   But one part of it is actually about what we talked about a few episodes ago, which
[00:32:14.240 --> 00:32:21.080]   is like this big tech put, right, where they define the rules of the game on the field
[00:32:21.080 --> 00:32:23.160]   for every other startup.
[00:32:23.160 --> 00:32:27.560]   And I think the third part is just about like the era of big tech being over and what it
[00:32:27.560 --> 00:32:28.560]   means for the stock market.
[00:32:28.560 --> 00:32:33.360]   If I think if you section it out in those three ways, Jason, we can have a pretty rich
[00:32:33.360 --> 00:32:34.360]   convo.
[00:32:34.360 --> 00:32:35.360]   I'd love to tease some of the stuff.
[00:32:35.360 --> 00:32:36.360]   Where do you want to start?
[00:32:36.360 --> 00:32:38.060]   Okay, so let's let's start with meta.
[00:32:38.060 --> 00:32:42.560]   So Nick, can you please throw up Apple versus meta for a second.
[00:32:42.560 --> 00:32:45.240]   And let me just give you guys the talk track.
[00:32:45.240 --> 00:32:47.020]   And then maybe we can go from there.
[00:32:47.020 --> 00:32:53.080]   So when you look at Apple versus meta, there's this really interesting thing that comes up
[00:32:53.080 --> 00:32:59.640]   which is in 2016, you know, and we've said this before, you could not give Apple stock
[00:32:59.640 --> 00:33:00.800]   away.
[00:33:00.800 --> 00:33:04.660]   They were generating a ton of cash, it was sitting on the balance sheet.
[00:33:04.660 --> 00:33:07.440]   In many ways, Facebook was doing the same thing.
[00:33:07.440 --> 00:33:10.240]   And there was this famous dinner, I don't know if it was a dinner that ever happened,
[00:33:10.240 --> 00:33:17.160]   but that's how the the lore is told between Tim Cook, Carl Icahn, and I think Luca Maestri,
[00:33:17.160 --> 00:33:18.800]   the CFO.
[00:33:18.800 --> 00:33:27.040]   And in it, what Carl Icahn said is, listen, I have a below the line suggestion for Apple.
[00:33:27.040 --> 00:33:28.040]   And what does that mean?
[00:33:28.040 --> 00:33:33.140]   If you look at a P&L, you have your revenues, that's above the line, you have costs, that's
[00:33:33.140 --> 00:33:34.720]   also above the line.
[00:33:34.720 --> 00:33:38.120]   And then you have your profits, and then it's what you do with the profits.
[00:33:38.120 --> 00:33:41.000]   So what he was suggesting is below the line.
[00:33:41.000 --> 00:33:45.020]   After the fact, he had no suggestions for how the business should be run.
[00:33:45.020 --> 00:33:49.800]   He just said, give us back the money, and we will reward you, the stock price will go
[00:33:49.800 --> 00:33:50.980]   up.
[00:33:50.980 --> 00:33:55.560]   And what's interesting to note here is the black line is the performance of Apple stock
[00:33:55.560 --> 00:33:58.320]   as as they've given back.
[00:33:58.320 --> 00:34:02.920]   And they've used a ton of their own balance sheet cash to buy back the stock.
[00:34:02.920 --> 00:34:11.660]   Okay, so they've spent $396 billion since 2016 to buy back stock in the same time Facebook
[00:34:11.660 --> 00:34:14.320]   has spent almost 100 billion.
[00:34:14.320 --> 00:34:18.040]   Now, here is here's where you start to see the divergence.
[00:34:18.040 --> 00:34:23.340]   So you would have said, well, shouldn't Facebook's stock have reacted in the same way.
[00:34:23.340 --> 00:34:29.200]   And for a very long time, it actually looked like it was right until about September 21.
[00:34:29.200 --> 00:34:32.980]   And then obviously, this thing fell off a cliff.
[00:34:32.980 --> 00:34:37.200]   And the reason why it started to fall off a cliff was somebody started to notice that
[00:34:37.200 --> 00:34:39.480]   hold on a second.
[00:34:39.480 --> 00:34:44.000]   Even though you're buying back all these shares, the bottom of the funnel, right, you're
[00:34:44.000 --> 00:34:47.520]   leaking all of these shares to all of these new employees.
[00:34:47.520 --> 00:34:50.260]   Why are you hiring so many people.
[00:34:50.260 --> 00:34:55.220]   And this is when people started to uncover what was happening above the line at Facebook
[00:34:55.220 --> 00:34:57.680]   and is what caused this massive dispersion.
[00:34:57.680 --> 00:35:04.920]   So Nick, if you go to the first chart, so what is actually been going on above the line?
[00:35:04.920 --> 00:35:06.880]   Here's what's going on.
[00:35:06.880 --> 00:35:13.000]   If you look at the light purple bar, Facebook in the last two years have spent $25 billion
[00:35:13.000 --> 00:35:14.920]   on reality labs.
[00:35:14.920 --> 00:35:19.260]   And they said that they're going to spend, you know, meaningfully more in 2023 and then
[00:35:19.260 --> 00:35:21.920]   sustain that investment for a while.
[00:35:21.920 --> 00:35:25.600]   So if you do a little bit of math, if they spent, you know, they spend around 4 billion
[00:35:25.600 --> 00:35:26.600]   a quarter right now.
[00:35:26.600 --> 00:35:31.220]   So 16 billion a year, that'll go to 25 billion in 2023.
[00:35:31.220 --> 00:35:32.920]   And then they'll sustain that.
[00:35:32.920 --> 00:35:37.960]   What that means is that over this, you know, 12 or 13 year life of reality labs, as we've
[00:35:37.960 --> 00:35:43.400]   seen it, these guys will have spent a quarter of a trillion dollars.
[00:35:43.400 --> 00:35:47.880]   And what I did here was I just wanted to understand there is I wanted to understand a quarter
[00:35:47.880 --> 00:35:52.740]   of a trillion dollars in the context of other major leaps in humanity.
[00:35:52.740 --> 00:35:56.000]   So at the left is what Apple spent in its entirety.
[00:35:56.000 --> 00:35:58.680]   By the way, these are all inflation adjusted dollars.
[00:35:58.680 --> 00:36:04.520]   For today, Apple spent $3.6 billion to create the first iPhone.
[00:36:04.520 --> 00:36:10.680]   And what they did was they said every subsequent version of the iPhone would only be funded
[00:36:10.680 --> 00:36:13.840]   from the cash flow and profits of the generation before it.
[00:36:13.840 --> 00:36:18.440]   Right, so they used consumer demand as their guiding principle.
[00:36:18.440 --> 00:36:22.800]   So it was a very incremental approach, iPhone one, iPhone two, and now we're at iPhone,
[00:36:22.800 --> 00:36:25.040]   you know, 14, or whatever 13.
[00:36:25.040 --> 00:36:31.040]   But the point is, it took 3.6 billion to get that juggernaut off the ground.
[00:36:31.040 --> 00:36:37.320]   The Manhattan Project will cost 23 billion in today's dollars to create the atomic bomb.
[00:36:37.320 --> 00:36:43.040]   Tesla in its entire life spent 25 billion to get free cash flow profitability, and they
[00:36:43.040 --> 00:36:45.280]   took this incremental approach as well.
[00:36:45.280 --> 00:36:50.680]   Will create the you know, the the coupe, the Roadster, then the Model S, then the Model
[00:36:50.680 --> 00:36:53.640]   X, they iterated their way.
[00:36:53.640 --> 00:36:58.000]   They used customer demand, and all of that revenue to fund future growth.
[00:36:58.000 --> 00:37:01.120]   Cume spend on Tesla was 25 billion.
[00:37:01.120 --> 00:37:05.160]   Boeing spent 32, Google and other bets has spent 40.
[00:37:05.160 --> 00:37:10.420]   The only thing that I could find in history that is comparable to what meta has basically
[00:37:10.420 --> 00:37:15.360]   said they're going to spend is the entire Apollo program, which cost in today's dollars
[00:37:15.360 --> 00:37:17.240]   a quarter of a trillion as well.
[00:37:17.240 --> 00:37:22.920]   So the problem is that below the line meta was doing the right things.
[00:37:22.920 --> 00:37:28.280]   Above the line, they've created, I think, an enormous set of pressures for themselves,
[00:37:28.280 --> 00:37:33.360]   which is, you know, if you think about the Apollo program, this was 13 years of building
[00:37:33.360 --> 00:37:37.560]   rockets, getting to low Earth orbit, then getting to be able to, you know, orbit the
[00:37:37.560 --> 00:37:41.440]   Earth, then eventually building an entire infrastructure and capability to land on the
[00:37:41.440 --> 00:37:43.120]   moon and get back.
[00:37:43.120 --> 00:37:45.000]   So there was a lot of incremental progress there.
[00:37:45.000 --> 00:37:49.200]   I think what people don't understand is where is this quarter of a trillion dollars going?
[00:37:49.200 --> 00:37:55.040]   And is it going to be a leap in humanity at the scale of the Apollo program?
[00:37:55.040 --> 00:38:04.360]   Because it now is becoming the single largest capital allocation program in capitalism history.
[00:38:04.360 --> 00:38:06.000]   Nothing comes close.
[00:38:06.000 --> 00:38:11.060]   So I think that that is a really interesting, maybe jumping off point to talk about what's
[00:38:11.060 --> 00:38:12.680]   going on inside of this business.
[00:38:12.680 --> 00:38:15.880]   It's I think they're doing all the right things below the line.
[00:38:15.880 --> 00:38:20.960]   But there's this one major big red flag above the line that has to be probably better explained
[00:38:20.960 --> 00:38:22.140]   by them.
[00:38:22.140 --> 00:38:23.880]   If they want to have long term shareholders.
[00:38:23.880 --> 00:38:26.800]   And basically what happened was when people heard this, they said, this is a dumpster
[00:38:26.800 --> 00:38:27.800]   fire.
[00:38:27.800 --> 00:38:28.800]   We're out of here.
[00:38:28.800 --> 00:38:29.880]   Saks, what do you guys the question?
[00:38:29.880 --> 00:38:32.840]   What happened with the whole Brad Gershner proposal?
[00:38:32.840 --> 00:38:35.080]   Was that actually discussed on the call?
[00:38:35.080 --> 00:38:36.360]   No earnings call?
[00:38:36.360 --> 00:38:38.560]   They, you know, they ignored?
[00:38:38.560 --> 00:38:42.280]   Well, I don't want to say it was totally ignored.
[00:38:42.280 --> 00:38:46.400]   Because I do think that they should be given credit for a couple of things.
[00:38:46.400 --> 00:38:50.560]   I think that the core business continues to march forward.
[00:38:50.560 --> 00:38:54.300]   And they basically said, look, we're going to slow headcount growth.
[00:38:54.300 --> 00:38:56.000]   Some teams will shrink.
[00:38:56.000 --> 00:39:01.040]   I think the problem is really in this reality labs, the amount of investment that they're
[00:39:01.040 --> 00:39:07.840]   making is so outsized, and so abnormal, and doesn't compare to anything anybody's ever
[00:39:07.840 --> 00:39:08.840]   seen.
[00:39:08.840 --> 00:39:13.600]   I think everything else in the business seems to be actually quite functional.
[00:39:13.600 --> 00:39:18.880]   So the problem is that this above the line thing, though, has become so big.
[00:39:18.880 --> 00:39:24.240]   It could sink the business, you know, it's very, very hard to see an investment case
[00:39:24.240 --> 00:39:28.300]   for a quarter of a trillion dollars of money in the door before you really start to see
[00:39:28.300 --> 00:39:29.300]   something magical.
[00:39:29.300 --> 00:39:33.660]   Now, they may have something super magical that nobody knows about that they're going
[00:39:33.660 --> 00:39:36.600]   to unveil and say, ha, see told you.
[00:39:36.600 --> 00:39:40.340]   And maybe there should be a set of outcomes where we plan for that.
[00:39:40.340 --> 00:39:46.100]   But the reality is, it's, you know, $25 billion a year for the next umpteen years.
[00:39:46.100 --> 00:39:50.040]   And it's, it's, and I think people 10 billion, where did the 25 billion come from?
[00:39:50.040 --> 00:39:52.860]   No, this number, it's 4 billion, a quarter right now.
[00:39:52.860 --> 00:39:57.840]   So 16 billion a year, and they said that they're going to significantly increase it to 2023.
[00:39:57.840 --> 00:40:02.280]   So I just assumed it was a 50% increase, maybe significant means 100.
[00:40:02.280 --> 00:40:03.860]   But 16 goes to 25.
[00:40:03.860 --> 00:40:06.520]   And they said they're gonna keep going at that pace.
[00:40:06.520 --> 00:40:11.400]   And so if you run that out till 2030, that's how you get to $250 billion.
[00:40:11.400 --> 00:40:14.840]   You think there's a business here in VR, AR, sax?
[00:40:14.840 --> 00:40:16.040]   You think this will be the next platform?
[00:40:16.040 --> 00:40:18.320]   I guess that's a key question to ask here.
[00:40:18.320 --> 00:40:21.520]   Yeah, I mean, I like I actually like these Oculus products.
[00:40:21.520 --> 00:40:25.480]   I think it's a very cool product.
[00:40:25.480 --> 00:40:28.640]   The question is really just about the magnitude of the investment level.
[00:40:28.640 --> 00:40:31.560]   But I think there is a future in VR and AR.
[00:40:31.560 --> 00:40:42.080]   And it is a you've tried the Oculus headset before it is like a very magical, you know,
[00:40:42.080 --> 00:40:46.840]   experience with software, one of the most magical that I've had, the question is just,
[00:40:46.840 --> 00:40:49.400]   we're talking about magnitude and timeframe.
[00:40:49.400 --> 00:40:55.720]   And use case, I think also comes to mind for me, sax, I everybody seems to, you know, try
[00:40:55.720 --> 00:40:58.400]   and then say, Oh, my, and then say goodbye to these headsets.
[00:40:58.400 --> 00:41:00.160]   Like people buy them, they try them.
[00:41:00.160 --> 00:41:03.040]   And they're like, this is incredible, but there's no use case for them.
[00:41:03.040 --> 00:41:05.900]   I see very few people just use them on a regular basis.
[00:41:05.900 --> 00:41:13.000]   We just invested in a company that is creating professional flight simulators using VR as
[00:41:13.000 --> 00:41:14.000]   a component.
[00:41:14.000 --> 00:41:18.080]   And these are like, yeah, I think training is actually a huge use case.
[00:41:18.080 --> 00:41:19.080]   Huge, huge.
[00:41:19.080 --> 00:41:24.600]   And, by the way, these are not like video game flight simulator programs.
[00:41:24.600 --> 00:41:29.920]   These are actual, they create physical cockpits with knobs and dials and stuff.
[00:41:29.920 --> 00:41:35.240]   It's just that the pilot is using a professional grade VR headset.
[00:41:35.240 --> 00:41:39.800]   And so they're able to load, you know, a lot more training programs and scenarios, and
[00:41:39.800 --> 00:41:44.160]   they're able to train on more planes, they can like change up the cockpit.
[00:41:44.160 --> 00:41:47.440]   By the way, the cockpits on gyros, so it actually moves around.
[00:41:47.440 --> 00:41:49.080]   Let me put a date in a different way.
[00:41:49.080 --> 00:41:52.680]   I think that we should assume that VR and AR is going to be a really important part
[00:41:52.680 --> 00:41:54.760]   of our existence.
[00:41:54.760 --> 00:41:58.640]   And I do think that, as David said, many of these experiences are magical.
[00:41:58.640 --> 00:42:05.440]   I think what investors reacted to was spending $25 billion a year needs to be measurable
[00:42:05.440 --> 00:42:06.860]   somehow.
[00:42:06.860 --> 00:42:11.040]   And I think what they said is the things that we're seeing don't necessarily tell us that
[00:42:11.040 --> 00:42:13.880]   this bet is going to make any sense at that level of spend.
[00:42:13.880 --> 00:42:18.560]   So if you were spending 2 billion a year, or 3 billion a year, I don't think people
[00:42:18.560 --> 00:42:20.480]   would have said anything.
[00:42:20.480 --> 00:42:25.200]   It's just the magnitude relative to the progress that's being demonstrated publicly.
[00:42:25.200 --> 00:42:29.720]   And that's the thing that I think the Tesla program got right, the Apple phone program
[00:42:29.720 --> 00:42:34.760]   got right, the Boeing program, even the Apollo 13 program for that quantum of spend.
[00:42:34.760 --> 00:42:38.960]   So it's not to say that you can't spend a quarter trillion dollars over the next decade,
[00:42:38.960 --> 00:42:42.760]   but you got to eat what you kill, you have to be able to show progress in a way that
[00:42:42.760 --> 00:42:45.160]   says, this, this investment is tracking.
[00:42:45.160 --> 00:42:52.280]   freeberg, I think the biggest issue he's having is he's trying to build a moonshot that you'll
[00:42:52.280 --> 00:42:54.360]   only get to see when I'm done.
[00:42:54.360 --> 00:42:56.320]   It's like, Hey, I'm behind the curtain over here.
[00:42:56.320 --> 00:42:59.720]   I'm Willy Wonka, I'm going to come out with the most amazing chocolate bar in 10 years.
[00:42:59.720 --> 00:43:03.600]   And after I spend $100 billion, but don't worry, it's gonna be awesome.
[00:43:03.600 --> 00:43:05.960]   Trust me, shareholders, it's gonna be amazing.
[00:43:05.960 --> 00:43:10.440]   And with consumer products in particular, not guys, you keep saying 100, it's 250.
[00:43:10.440 --> 00:43:12.240]   Yeah, whatever it ends up being.
[00:43:12.240 --> 00:43:17.480]   In general, I think consumer products, you want to see them in the market.
[00:43:17.480 --> 00:43:19.480]   And you want to iterate to success.
[00:43:19.480 --> 00:43:23.680]   Tell me one consumer product that launched and didn't iterate after launch and didn't
[00:43:23.680 --> 00:43:28.160]   kind of evolve over time in a way that responded to what the market was telling the builder
[00:43:28.160 --> 00:43:29.160]   of that product.
[00:43:29.160 --> 00:43:31.680]   But freeberg, in fairness to them, they're doing that too.
[00:43:31.680 --> 00:43:38.160]   It's just I think what people can't square is, we see the next gen oculuses.
[00:43:38.160 --> 00:43:41.960]   And then we see the spend, and we think that they're upside down relative to what we're
[00:43:41.960 --> 00:43:43.160]   seeing in terms of progress.
[00:43:43.160 --> 00:43:44.480]   I think that's what people are reacting.
[00:43:44.480 --> 00:43:47.640]   If he was spending 5 billion a year, this wouldn't be an issue, Chamath, right?
[00:43:47.640 --> 00:43:49.920]   A nothing burger, a nothing.
[00:43:49.920 --> 00:43:52.640]   People would say good idea, throw a long ball.
[00:43:52.640 --> 00:43:56.960]   I think that there's two kind of ways to think about the distinct things that they're building.
[00:43:56.960 --> 00:44:01.640]   One is this hardware platform with oculus and a better kind of experience for immersive
[00:44:01.640 --> 00:44:05.480]   experiences, whether that's VR or AR.
[00:44:05.480 --> 00:44:09.680]   The second is what's all the software layer look like and what goes on in that platform.
[00:44:09.680 --> 00:44:13.520]   That's where this thing seems to be pretty short and where people seem to have a lack
[00:44:13.520 --> 00:44:15.320]   of confidence and conviction.
[00:44:15.320 --> 00:44:17.400]   The hardware seems super interesting.
[00:44:17.400 --> 00:44:23.000]   But I got to tell you, Epic Games just raised money earlier this year at a $31 billion valuation.
[00:44:23.000 --> 00:44:26.200]   If Zuck was a smart guy, he would go to Tencent and cut him a check and buy the whole thing
[00:44:26.200 --> 00:44:31.080]   for 50 billion and you know, buy those guys because that's a platform that has a couple
[00:44:31.080 --> 00:44:38.080]   hundred million active users is making money has a really deep immersive, but two dimensional
[00:44:38.080 --> 00:44:39.080]   experience.
[00:44:39.080 --> 00:44:46.160]   I mean, it's not on VR and on top of Fortnite and on top of their engine that they've built,
[00:44:46.160 --> 00:44:53.920]   there are just countless experiences and worlds and interactions and models that exist today
[00:44:53.920 --> 00:44:57.360]   that are already active, that are being iterated, that have been evolving for years.
[00:44:57.360 --> 00:45:01.080]   And if you look at where Fortnite and some of the tools and experiences that have been
[00:45:01.080 --> 00:45:05.760]   built into Fortnite over the past couple of years, sit relative to when Fortnite was first
[00:45:05.760 --> 00:45:09.680]   launched, I don't think that Tim Sweeney and that team would have ever said, Hey, this
[00:45:09.680 --> 00:45:12.240]   is where we're going to be in a couple of years, this is what we're going to be doing.
[00:45:12.240 --> 00:45:16.040]   It was part of an evolutionary experience of building a great platform and having an
[00:45:16.040 --> 00:45:17.520]   engaged user base.
[00:45:17.520 --> 00:45:21.200]   And unfortunately, there doesn't seem to be a great engaged user base in the software
[00:45:21.200 --> 00:45:26.080]   layer of what he's built here today, making it very difficult to track a path to get consumer
[00:45:26.080 --> 00:45:29.080]   feedback and to identify where that goes over time.
[00:45:29.080 --> 00:45:33.160]   The hardware experience totally understand that that takes time to build something incredible
[00:45:33.160 --> 00:45:37.320]   also should be in the market and getting iterative feedback, but really that that software pieces
[00:45:37.320 --> 00:45:38.800]   would would feel short.
[00:45:38.800 --> 00:45:43.060]   To your point, I think that that's another great example of a below the line decision
[00:45:43.060 --> 00:45:46.320]   that they could have made with all of this money.
[00:45:46.320 --> 00:45:50.620]   You know, if you compare what Brad asked Facebook to do on Monday versus what Icon asked Apple
[00:45:50.620 --> 00:45:56.940]   to do in 2016, you know, Icon basically said, just make this below the line change and everybody
[00:45:56.940 --> 00:45:57.940]   will be happy.
[00:45:57.940 --> 00:45:59.680]   It's a do no harm solution.
[00:45:59.680 --> 00:46:01.240]   None of us are getting in the way.
[00:46:01.240 --> 00:46:03.600]   We're not telling you how to run the business.
[00:46:03.600 --> 00:46:07.160]   The thing that I think that, you know, what Facebook had to react to was Brad's suggestions
[00:46:07.160 --> 00:46:08.580]   were fundamentally above the line.
[00:46:08.580 --> 00:46:13.140]   It's like, you know, firing 20% of the people or 30% or changing the capital allocation
[00:46:13.140 --> 00:46:15.880]   would require some changes to strategy.
[00:46:15.880 --> 00:46:21.480]   And I think this is a good moment to recognize it as as much clarity as Brad's letter had
[00:46:21.480 --> 00:46:25.360]   and as much sense as it probably makes to outsiders looking in.
[00:46:25.360 --> 00:46:28.540]   The minute you have to tell companies how to change above the line, it's just a good
[00:46:28.540 --> 00:46:31.820]   reminder to me that no, it's not going to happen.
[00:46:31.820 --> 00:46:34.320]   Because these folks will not want to make those changes.
[00:46:34.320 --> 00:46:36.520]   They don't want saying Zuck won't make the changes.
[00:46:36.520 --> 00:46:38.360]   I think it's natural human psychology.
[00:46:38.360 --> 00:46:40.400]   I think you want to make those changes yourself.
[00:46:40.400 --> 00:46:42.760]   You don't want to be told what to do.
[00:46:42.760 --> 00:46:43.760]   Got it.
[00:46:43.760 --> 00:46:47.920]   Saks, what do you think this is going to do to governance in Silicon Valley writ large?
[00:46:47.920 --> 00:46:48.920]   Probably nothing.
[00:46:48.920 --> 00:46:49.920]   Really?
[00:46:49.920 --> 00:46:51.920]   So it's not going to change anything.
[00:46:51.920 --> 00:46:52.920]   It is interesting.
[00:46:52.920 --> 00:46:57.740]   If you look at Elon's Twitter deal, there is no dual class.
[00:46:57.740 --> 00:47:01.800]   Everybody has, there's this one class of security.
[00:47:01.800 --> 00:47:03.680]   This is one type of stock.
[00:47:03.680 --> 00:47:06.080]   So it's simple majority voting.
[00:47:06.080 --> 00:47:11.280]   Elon actually had the choice of doing dual class and he decided not to.
[00:47:11.280 --> 00:47:13.120]   So that's pretty interesting.
[00:47:13.120 --> 00:47:19.120]   So if people want to follow Elon's example, then they would, you know, not not necessarily
[00:47:19.120 --> 00:47:20.920]   go for Tesla doesn't have super shares either.
[00:47:20.920 --> 00:47:23.640]   And he said it many times, if you want to vote me out, you can vote me out.
[00:47:23.640 --> 00:47:24.640]   Right?
[00:47:24.640 --> 00:47:27.760]   I mean, he's so he's putting his face X either.
[00:47:27.760 --> 00:47:30.960]   Yeah, he's putting his neck on the line.
[00:47:30.960 --> 00:47:31.960]   I don't know.
[00:47:31.960 --> 00:47:32.960]   I has a space actually.
[00:47:32.960 --> 00:47:33.960]   I have no idea.
[00:47:33.960 --> 00:47:34.960]   I don't know.
[00:47:34.960 --> 00:47:35.960]   It's a structure.
[00:47:35.960 --> 00:47:36.960]   Yeah, I can't remember.
[00:47:36.960 --> 00:47:37.960]   SpaceX isn't public yet.
[00:47:37.960 --> 00:47:38.960]   So maybe it doesn't matter.
[00:47:38.960 --> 00:47:40.520]   Like they haven't reached that decision point.
[00:47:40.520 --> 00:47:45.440]   Yeah, I will tell you, I just I think Starlink has such a huge opportunity.
[00:47:45.440 --> 00:47:51.840]   I just got Starlink for two locations as a backup because you lose your internet a couple
[00:47:51.840 --> 00:47:54.640]   times a year and you can get these routers now that'll fail over.
[00:47:54.640 --> 00:47:57.600]   So since I'm doing business, like, I can't really lose the internet.
[00:47:57.600 --> 00:48:02.420]   So for 1000 bucks a year, I can have Starlink as a backup and I started using it.
[00:48:02.420 --> 00:48:05.280]   And the speed is getting pretty compelling already.
[00:48:05.280 --> 00:48:09.600]   Like zoom calls, you can't tell the difference right now, most of the time, and certainly
[00:48:09.600 --> 00:48:13.400]   for web browsing or watching a movie.
[00:48:13.400 --> 00:48:14.520]   You know, it just works.
[00:48:14.520 --> 00:48:18.880]   So I could see many companies putting in Starlink, even if they have a fiber line or whatever,
[00:48:18.880 --> 00:48:20.500]   just as a backup.
[00:48:20.500 --> 00:48:22.000]   That business alone could be ginormous.
[00:48:22.000 --> 00:48:24.600]   Just to provide both sides of the story here.
[00:48:24.600 --> 00:48:30.560]   I mean, the reason why dual class emerged and was seen as viable is that if you look
[00:48:30.560 --> 00:48:35.860]   at the historic performance of internet companies, the ones that have done the best perform the
[00:48:35.860 --> 00:48:39.360]   best are the ones where the founder stays involved for a long time.
[00:48:39.360 --> 00:48:43.680]   And the ones where the founder checked out, like after a few years and hired a professional
[00:48:43.680 --> 00:48:47.520]   CEO, those are the ones that went off the rails, it happened again and again.
[00:48:47.520 --> 00:48:52.240]   So there is an argument for dual class in the sense that you keep the founder involved
[00:48:52.240 --> 00:48:56.240]   and you avoid a power struggle.
[00:48:56.240 --> 00:48:57.240]   That's not what happened.
[00:48:57.240 --> 00:48:59.880]   Well, but that was why it was considered acceptable.
[00:48:59.880 --> 00:49:03.680]   Well, I think it was considered acceptable because in the Google bake off, all these
[00:49:03.680 --> 00:49:06.220]   banks were clamoring so hard.
[00:49:06.220 --> 00:49:08.600]   And you know, there were two vectors of iteration.
[00:49:08.600 --> 00:49:13.200]   One vector was on the way that, you know, Google wanted to do this IPO process, they
[00:49:13.200 --> 00:49:15.100]   pick Credit Suisse, they did this Dutch auction.
[00:49:15.100 --> 00:49:19.520]   The other one was the bankers basically pitched them on a dual class voting control structure.
[00:49:19.520 --> 00:49:23.840]   And Morgan Stanley, Morgan Stanley, and once Google got it, everybody else was able to
[00:49:23.840 --> 00:49:28.200]   copy because all the bankers realized that if you want to win a bake off, you're not
[00:49:28.200 --> 00:49:32.520]   trying to win over the CFO, you're actually trying to win over the CEO.
[00:49:32.520 --> 00:49:36.480]   And giving that person control turned out to be an incredible commitment, and a way
[00:49:36.480 --> 00:49:37.780]   to win the deal.
[00:49:37.780 --> 00:49:43.820]   And so I actually think it was never a governance issue or a reflection of how value was created.
[00:49:43.820 --> 00:49:49.280]   It was just basically a feature that you that one banker used in an IPO bake off to try
[00:49:49.280 --> 00:49:50.720]   to differentiate versus another.
[00:49:50.720 --> 00:49:54.360]   This is why, you know, like I said, like Elon has never cared about that stuff, because
[00:49:54.360 --> 00:49:58.540]   it's like, if I'm not doing well, vote me out, which is so clarifying, because he realizes
[00:49:58.540 --> 00:50:02.860]   that that's actually the best check on him making bad decisions.
[00:50:02.860 --> 00:50:06.920]   You know, and I think part of it is why he's done so well, you know, one class of stock,
[00:50:06.920 --> 00:50:10.200]   he was able to negotiate an incredible compensation package.
[00:50:10.200 --> 00:50:15.020]   And it's he's he has clarity, a lot of the few things of the business that matter.
[00:50:15.020 --> 00:50:18.260]   But I think he's also more compelling than some of these other guys.
[00:50:18.260 --> 00:50:23.080]   And there may be some degree of feeling like this is a mechanism that other people need
[00:50:23.080 --> 00:50:28.180]   that Elon has a degree of confidence and a degree of charisma and salesmanship that gets
[00:50:28.180 --> 00:50:29.460]   him what he wants.
[00:50:29.460 --> 00:50:33.300]   I just want to read you guys the excerpt from Larry and Sergei's founders letter from the
[00:50:33.300 --> 00:50:35.140]   IPO in 2004.
[00:50:35.140 --> 00:50:38.860]   As a private company, we've concentrated on the long term and this has served us well.
[00:50:38.860 --> 00:50:40.820]   As a public company, we will do the same.
[00:50:40.820 --> 00:50:46.380]   In our opinion, outside pressures, too often tempt companies to sacrifice long term opportunities
[00:50:46.380 --> 00:50:49.580]   to meet quarterly market expectations.
[00:50:49.580 --> 00:50:53.580]   Sometimes this has caused opportunities to manipulate financial results in order to make
[00:50:53.580 --> 00:50:55.860]   their quarter, and they go on and on and on.
[00:50:55.860 --> 00:50:59.900]   And they say, Look, you might ask us how long is long term, usually we expect them in a
[00:50:59.900 --> 00:51:02.140]   couple of years, and they go on.
[00:51:02.140 --> 00:51:05.980]   Many companies are under pressure to keep their earnings in line with analysts forecasts.
[00:51:05.980 --> 00:51:11.300]   Therefore, they often accept smaller, predictable earnings, rather than larger and less predictable
[00:51:11.300 --> 00:51:12.300]   returns.
[00:51:12.300 --> 00:51:16.580]   Sergei and I feel this is harmful, and we intend to steer in the opposite direction.
[00:51:16.580 --> 00:51:20.140]   I think that the statement that they made really resonated in Silicon Valley at the
[00:51:20.140 --> 00:51:24.060]   time, particularly during this era of what people were calling web two and the internet
[00:51:24.060 --> 00:51:25.060]   was being rebuilt.
[00:51:25.060 --> 00:51:27.980]   And all these businesses were starting to thrive.
[00:51:27.980 --> 00:51:31.060]   And it was like we have this massive road ahead of us this long road ahead of us and
[00:51:31.060 --> 00:51:32.980]   we can really change the world.
[00:51:32.980 --> 00:51:37.380]   But in order to do it well, in order to do it effectively, we have to as entrepreneurs
[00:51:37.380 --> 00:51:42.340]   as engineers, be able to have the freedom to operate for the long term, I don't think
[00:51:42.340 --> 00:51:44.900]   it had anything to get stuck in the short term.
[00:51:44.900 --> 00:51:49.460]   But I think that that had nothing to do with anything that there was no pressure on them.
[00:51:49.460 --> 00:51:51.180]   It's not like they shied away.
[00:51:51.180 --> 00:51:54.940]   It's not like that super voting control allowed them to make one seminal decision.
[00:51:54.940 --> 00:51:58.380]   There were quarters to moth where Google was getting a lot of heat for the amount of money
[00:51:58.380 --> 00:52:00.940]   they were spending on capex because they were building their own data centers, they were
[00:52:00.940 --> 00:52:05.740]   building their own servers, they were building their own, eventually DRAM, they started to
[00:52:05.740 --> 00:52:07.340]   build their own switches.
[00:52:07.340 --> 00:52:11.900]   Every element of how Google build a competitive advantage over time was difficult for analysts
[00:52:11.900 --> 00:52:12.900]   to understand.
[00:52:12.900 --> 00:52:15.660]   You're not saying that you're not saying the obvious thing.
[00:52:15.660 --> 00:52:20.260]   The reason why they were allowed to do it in the end was because more and more users
[00:52:20.260 --> 00:52:22.900]   use their product because it was better and better.
[00:52:22.900 --> 00:52:26.500]   And they consistently meet and beat every expectation.
[00:52:26.500 --> 00:52:28.860]   This is not I didn't need to use this option.
[00:52:28.860 --> 00:52:30.900]   This was not I didn't need to call this option.
[00:52:30.900 --> 00:52:35.700]   This is not a company that went back and forth between meeting and missing expectations.
[00:52:35.700 --> 00:52:36.700]   Okay?
[00:52:36.700 --> 00:52:38.380]   They were up into the right.
[00:52:38.380 --> 00:52:40.220]   They were they were up into the right is correct.
[00:52:40.220 --> 00:52:41.620]   That is the general principle.
[00:52:41.620 --> 00:52:47.180]   But the time to return the ROC, the timeframe to hit their ROC targets was long.
[00:52:47.180 --> 00:52:49.980]   And it was hard for people to get that when they not true.
[00:52:49.980 --> 00:52:55.460]   That is not to David YouTube, and they spent 10s of billions of dollars investing in YouTube
[00:52:55.460 --> 00:52:56.700]   before generated cash.
[00:52:56.700 --> 00:52:57.700]   I get it.
[00:52:57.700 --> 00:52:58.700]   That would Yeah.
[00:52:58.700 --> 00:52:59.700]   That's not math.
[00:52:59.700 --> 00:53:01.140]   You're not what you're saying is not true.
[00:53:01.140 --> 00:53:05.780]   It is not mathematically true what you're saying there was no 13 year Roick play that
[00:53:05.780 --> 00:53:08.860]   they executed on not true.
[00:53:08.860 --> 00:53:09.860]   And you can just look at it.
[00:53:09.860 --> 00:53:14.420]   They may have put their own they put their own fiber optic lines across the oceans.
[00:53:14.420 --> 00:53:18.140]   The CAPEX I understand scrutinized and not well understood.
[00:53:18.140 --> 00:53:19.140]   I get it.
[00:53:19.140 --> 00:53:22.340]   You can read but you might you can read the analyst reports and see how difficult this
[00:53:22.340 --> 00:53:23.340]   was.
[00:53:23.340 --> 00:53:26.380]   I'm asking for you to do is look at they had voting shares is what gave them the ability
[00:53:26.380 --> 00:53:27.580]   to do this bullshit.
[00:53:27.580 --> 00:53:32.660]   I think that if you look at their performance, their EBITDA margins and their Roick was exceptional
[00:53:32.660 --> 00:53:34.020]   when they were making those investments.
[00:53:34.020 --> 00:53:35.820]   In fact, I would say the opposite.
[00:53:35.820 --> 00:53:41.300]   I would say that they were surprised by high how by how high quality their business model
[00:53:41.300 --> 00:53:42.300]   was.
[00:53:42.300 --> 00:53:44.020]   They were generating so much cash.
[00:53:44.020 --> 00:53:48.340]   What they were probably thinking back in the day was, oh, my gosh, we need to make sure
[00:53:48.340 --> 00:53:50.380]   that we are actually making long term investments.
[00:53:50.380 --> 00:53:52.540]   And now we have the ability to do it.
[00:53:52.540 --> 00:53:54.780]   Because we have all this cash we didn't expect.
[00:53:54.780 --> 00:53:59.860]   And we should probably bleed off cash so that we don't show 50% gross margins to raise all
[00:53:59.860 --> 00:54:03.060]   of the attention of regulators and everybody else.
[00:54:03.060 --> 00:54:04.620]   And so what do you think Zuck is doing?
[00:54:04.620 --> 00:54:06.500]   What's different today?
[00:54:06.500 --> 00:54:10.620]   I think that they have an incredible core business because he's got good business, good
[00:54:10.620 --> 00:54:12.860]   EBITDA margins, good revenue growth.
[00:54:12.860 --> 00:54:13.860]   What's different?
[00:54:13.860 --> 00:54:16.220]   They have an incredible core business.
[00:54:16.220 --> 00:54:21.620]   And they have decided for whatever reason, to make an enormous bet.
[00:54:21.620 --> 00:54:25.260]   And that bet could be a very good bet.
[00:54:25.260 --> 00:54:29.460]   But the way that you make a bet, and you said this well, is you have to look at incremental
[00:54:29.460 --> 00:54:30.900]   progress.
[00:54:30.900 --> 00:54:34.660]   And you have to demonstrate that all of these bets make sense.
[00:54:34.660 --> 00:54:41.500]   Because the problem is when you could compared to the Tesla program, look, Tesla is reinventing
[00:54:41.500 --> 00:54:47.460]   an entire category, trillions of dollars of energy generation and transportation.
[00:54:47.460 --> 00:54:53.580]   But they did it on in one year of meta reality lab spend.
[00:54:53.580 --> 00:55:00.260]   Apple reinvented an entire compute platform on one quarter of meta's reality lab spend.
[00:55:00.260 --> 00:55:01.260]   That's not a judgment.
[00:55:01.260 --> 00:55:03.520]   That's just a numerical observation.
[00:55:03.520 --> 00:55:08.580]   So if you want to get people on your side, you just have to be able to double click into
[00:55:08.580 --> 00:55:15.180]   that in an elegant, articulate way and say, here are all of these things that justify
[00:55:15.180 --> 00:55:17.220]   $25 billion a year.
[00:55:17.220 --> 00:55:19.140]   Hey, guys, let me show you a chart.
[00:55:19.140 --> 00:55:26.380]   Here's a chart of alphabets, capital expenditures by quarter, and here is their revenue.
[00:55:26.380 --> 00:55:29.300]   The blue line at $7 billion right now.
[00:55:29.300 --> 00:55:30.300]   This is my point.
[00:55:30.300 --> 00:55:32.820]   Yeah, they struggled.
[00:55:32.820 --> 00:55:35.420]   They struggled to find ways to spend money.
[00:55:35.420 --> 00:55:36.420]   Exactly.
[00:55:36.420 --> 00:55:40.660]   I mean, literally, they they created project loon, they were gonna do balloons, guys, they
[00:55:40.660 --> 00:55:44.420]   wanted to do a fiber, they wanted to build a VTOL, they wanted to build they wanted to
[00:55:44.420 --> 00:55:49.020]   build at one point a ladder to the moon, a ladder, they thought they could build from
[00:55:49.020 --> 00:55:50.020]   Ted.
[00:55:50.020 --> 00:55:51.020]   It was an elevator.
[00:55:51.020 --> 00:55:54.260]   But yeah, yeah, whatever an elevator is in that seven point to climb there.
[00:55:54.260 --> 00:55:55.260]   Right.
[00:55:55.260 --> 00:55:56.740]   The elevator was in the purple line.
[00:55:56.740 --> 00:55:57.740]   Yeah.
[00:55:57.740 --> 00:56:01.220]   And somewhere in there, they spent a billion or whatever on maps and it ended up being
[00:56:01.220 --> 00:56:03.500]   a phenomenal asset when the whole world moved to mobile.
[00:56:03.500 --> 00:56:05.660]   I think we're not saying the obvious thing.
[00:56:05.660 --> 00:56:07.900]   We spent a lot less than we're not.
[00:56:07.900 --> 00:56:12.220]   We're not saying the obvious thing, which is great leaps of progress in humanity are
[00:56:12.220 --> 00:56:14.580]   not correlated to dollars all the time.
[00:56:14.580 --> 00:56:20.780]   In fact, most examples are the exact opposite, which is it's more about small and extremely
[00:56:20.780 --> 00:56:25.020]   nimble and talented management teams that generate human progress.
[00:56:25.020 --> 00:56:29.660]   And again, if you go back to that first chart of Apple versus meta, you know, the fact that
[00:56:29.660 --> 00:56:35.320]   you've hired so many people to work on a category with so much money, it just violates a lot
[00:56:35.320 --> 00:56:39.580]   of pattern recognition that people have historically seen.
[00:56:39.580 --> 00:56:42.780]   So all I'm saying is maybe this is a great bet.
[00:56:42.780 --> 00:56:46.260]   They just need to do a better job of explaining this would have been so much easier if he
[00:56:46.260 --> 00:56:49.020]   had just put your burden.
[00:56:49.020 --> 00:56:52.320]   I'm saying this could be this could have been such a better transition, he should have put
[00:56:52.320 --> 00:56:57.540]   Sheryl Sandberg, a CEO of the Facebook Corporation, he should have became CEO of meta.
[00:56:57.540 --> 00:57:01.460]   And then he should have ran that other business to print even more profits.
[00:57:01.460 --> 00:57:06.300]   And then if you look at some of their forays into building a super app, they added Facebook
[00:57:06.300 --> 00:57:09.280]   marketplace to Facebook, and it was a huge hit.
[00:57:09.280 --> 00:57:13.380]   They started to pull the ecommerce string over at Instagram, it started to work.
[00:57:13.380 --> 00:57:15.380]   There's just no focus on those products.
[00:57:15.380 --> 00:57:19.620]   If you look at the Facebook collection of billions of users, what apps could you add
[00:57:19.620 --> 00:57:20.620]   to that?
[00:57:20.620 --> 00:57:23.660]   You know, whether it's payments, they did the whole crypto thing, they gave up on that
[00:57:23.660 --> 00:57:28.780]   it seems like there's no leadership on the Facebook side that actually wants to take
[00:57:28.780 --> 00:57:30.360]   swings over there.
[00:57:30.360 --> 00:57:31.900]   They just are obsessed with this one thing.
[00:57:31.900 --> 00:57:32.900]   It makes no sense to me.
[00:57:32.900 --> 00:57:37.320]   I think that there's probably part of it, which is that, you know, when you're working
[00:57:37.320 --> 00:57:42.580]   on a thing for a long time, there's a certain personality type that loves the mastery that
[00:57:42.580 --> 00:57:45.860]   comes from working on the thing for a long, long time.
[00:57:45.860 --> 00:57:49.940]   And then there's a different personality type that likes more shiny new things.
[00:57:49.940 --> 00:57:54.860]   And you kind of have to have a balance of all of those different people.
[00:57:54.860 --> 00:57:58.500]   And so maybe what we're seeing as well is that, you know, you're right, maybe the boring
[00:57:58.500 --> 00:58:01.460]   business was just labeled too boring internally.
[00:58:01.460 --> 00:58:04.180]   And there wasn't enough heat around wanting to work on it forever.
[00:58:04.180 --> 00:58:05.180]   Nobody wanted to keep grinding.
[00:58:05.180 --> 00:58:07.640]   And so you wanted to throw these big hill Marys.
[00:58:07.640 --> 00:58:09.740]   All I'm saying is you just need to explain the hill Mary.
[00:58:09.740 --> 00:58:12.700]   All right, let's, let's look, by the way, let me just ping you on this.
[00:58:12.700 --> 00:58:19.060]   So the meta spend in the quarter relative to the revenue, it's about 15 are the virtual
[00:58:19.060 --> 00:58:20.060]   reality stuff.
[00:58:20.060 --> 00:58:21.060]   It's about 15 billion 15%.
[00:58:21.060 --> 00:58:22.060]   Does that sound right?
[00:58:22.060 --> 00:58:23.060]   I don't know.
[00:58:23.060 --> 00:58:24.620]   But they said it was 4 billion this quarter.
[00:58:24.620 --> 00:58:25.620]   Yeah.
[00:58:25.620 --> 00:58:27.700]   So 4 billion out of 27 of revenue.
[00:58:27.700 --> 00:58:29.620]   So it's about 15%.
[00:58:29.620 --> 00:58:33.620]   And Alphabet's last quarter revenue was 70 billion.
[00:58:33.620 --> 00:58:35.780]   And they spent about a billion billion.
[00:58:35.780 --> 00:58:36.780]   Let me show you this.
[00:58:36.780 --> 00:58:41.860]   I actually actually had this chart handy because I was talking about it on this, which is 1.4%.
[00:58:41.860 --> 00:58:48.380]   So on a relative basis, Alphabet is spending one 10th of what meta is per dollar earned
[00:58:48.380 --> 00:58:52.420]   or top line revenue earned on their other bets category.
[00:58:52.420 --> 00:58:56.820]   So tomorrow, do you think it's a relative spend problem that because they're spending
[00:58:56.820 --> 00:59:01.620]   10 times as much as a percent of revenue that it's causing so much heartache, even if it
[00:59:01.620 --> 00:59:02.620]   is directionally correct?
[00:59:02.620 --> 00:59:06.740]   If you want to see the capex versus revenue, here's that on the screen right now.
[00:59:06.740 --> 00:59:11.700]   I know we know we know what we haven't shown this is Google and meta on the same chart,
[00:59:11.700 --> 00:59:17.660]   the blue line on the red on the bottom 9 billion in capex for Facebook 7 for Google.
[00:59:17.660 --> 00:59:19.940]   Is this your new like charting tool that you guys built?
[00:59:19.940 --> 00:59:22.100]   Yeah, no, no, we just do it on this.
[00:59:22.100 --> 00:59:23.100]   We can startups all the time.
[00:59:23.100 --> 00:59:24.100]   What do you use?
[00:59:24.100 --> 00:59:25.100]   What is it?
[00:59:25.100 --> 00:59:26.100]   What is it?
[00:59:26.100 --> 00:59:29.440]   Yeah, actually beep it out because I don't want to give them a free.
[00:59:29.440 --> 00:59:32.680]   I'm not giving a free promo.
[00:59:32.680 --> 00:59:33.680]   They didn't let you invest.
[00:59:33.680 --> 00:59:34.680]   Whatever.
[00:59:34.680 --> 00:59:35.680]   I mean, the truth comes out.
[00:59:35.680 --> 00:59:36.680]   The truth comes out.
[00:59:36.680 --> 00:59:37.680]   They didn't let him invest.
[00:59:37.680 --> 00:59:38.680]   Yeah, no, they've been around forever.
[00:59:38.680 --> 00:59:39.680]   They've been around for a good product.
[00:59:39.680 --> 00:59:40.680]   I've used it just to be a good product.
[00:59:40.680 --> 00:59:41.680]   Listen, we're gonna promo something.
[00:59:41.680 --> 00:59:42.680]   It's gonna be call in or Nick, can you throw up the histogram?
[00:59:42.680 --> 00:59:43.680]   Super got super got this is super got charts.
[00:59:43.680 --> 00:59:44.680]   So look, I think the new charting feature on Colin, I think the problem is that I don't
[00:59:44.680 --> 00:59:45.680]   know if I'm gonna be able to get a call in.
[00:59:45.680 --> 00:59:46.680]   I don't know if I'm gonna be able to get a call in.
[00:59:46.680 --> 01:00:14.680]   I don't know if I'm gonna be able to get a call in.
[01:00:14.680 --> 01:00:33.680]   I don't know if I'm gonna be able to get a call in.
[01:00:33.680 --> 01:01:01.520]   I don't know if I'm gonna be able to get a call in.
[01:01:01.520 --> 01:01:28.400]   I don't know if I'm gonna be able to get a call in.
[01:01:28.400 --> 01:01:57.920]   I don't know if I'm gonna be able to get a call in.
[01:01:57.920 --> 01:02:02.960]   we were basically calling the top of the market and told people to sell. One of the trades that
[01:02:02.960 --> 01:02:08.800]   he put on Nick if you want to just throw it up was this long Google short meta spread trade,
[01:02:08.800 --> 01:02:13.760]   he called to tell me that you know, he closed it out yesterday. This is how that trade did.
[01:02:13.760 --> 01:02:18.800]   So yeah, there was just a lot of folks that just kind of like went to the exits and said,
[01:02:18.800 --> 01:02:24.400]   you know what, we're kind of done for the short term. I just think that it's it's a moment in
[01:02:24.400 --> 01:02:31.680]   time where those folks have to realize that they just have to explain a little bit better how they
[01:02:31.680 --> 01:02:36.240]   want to spend the money and show a little bit more incremental progress that justifies that level of
[01:02:36.240 --> 01:02:40.640]   spend. Otherwise, people will be a little skeptical, they'll build their own histogram.
[01:02:40.640 --> 01:02:45.360]   And it'll violate too many rules. And so it goes into the too hard bucket.
[01:02:45.360 --> 01:02:51.680]   Okay, we got macro, we got Ukraine. And I think I think that you should talk about big tech, because
[01:02:52.560 --> 01:02:57.360]   Amazon puked as well, Jason, the Can you just throw up the big tech chart? Because I think like
[01:02:57.360 --> 01:03:00.560]   you guys should see this, because I think this is very important for Silicon Valley.
[01:03:00.560 --> 01:03:06.080]   Amazon reported their q3 earnings yesterday, Thursday, total revenue 127 billion of 15%
[01:03:06.080 --> 01:03:11.840]   year over year 5% quarter of a quarter net income was 2.9 billion. And they're predicting they're
[01:03:11.840 --> 01:03:16.240]   giving slower guidance going forward. I mean, what's incredible on this chart is that you know,
[01:03:16.240 --> 01:03:21.600]   when when everybody talks about being long the S&P 500, it was always really a proxy for being long.
[01:03:22.480 --> 01:03:27.360]   Amazon, Facebook, Google, Microsoft and Apple. And at the peak, you know, in May of this year,
[01:03:27.360 --> 01:03:33.440]   it was still, you know, 25 cents of every single dollar of the S&P 500 were these five companies.
[01:03:33.440 --> 01:03:38.720]   And, you know, we always said the market bottom will be when the generals quote unquote get shot,
[01:03:38.720 --> 01:03:43.520]   you know, to borrow a phrase from Gavin Baker. And it looks like the generals have been shot.
[01:03:43.520 --> 01:03:47.200]   Yeah. And what's incredible is this week, every single one of those companies,
[01:03:47.200 --> 01:03:52.640]   other than Apple really reported pretty crappy earnings. They got totally taken to the woodshed.
[01:03:52.640 --> 01:03:57.520]   The percentage of the of these companies as a percentage of the S&P is now, you know,
[01:03:57.520 --> 01:04:05.280]   off by 500 basis points, it's down to 20%. Yet the markets are ripping higher today. So I think
[01:04:05.280 --> 01:04:09.360]   it's kind of what we talked about three weeks ago, like the bottom is kind of in for the short term,
[01:04:09.360 --> 01:04:13.360]   you know, so it's really exciting, actually, to see, I think this is the point where you have to
[01:04:13.360 --> 01:04:19.040]   now start to get pretty constructive about where things are going. Because if this stuff could not
[01:04:19.040 --> 01:04:23.840]   bring the market down, it's hard to see something other than an exogenous event, probably some
[01:04:23.840 --> 01:04:30.400]   Russia, Ukraine event really having a negative impact. So to me, I'm kind of like, I don't know,
[01:04:30.400 --> 01:04:36.720]   it seems like pretty bullish for also GDP was 2.6%. So I mean, the this this very weird conflicting
[01:04:36.720 --> 01:04:41.040]   data, we had two negative quarters of growth, we're in a recession, then we have a third quarter
[01:04:41.040 --> 01:04:46.480]   is up 2.6%. So remember, Jason, I said that we were gonna have a double dip that was sure,
[01:04:46.480 --> 01:04:54.000]   that was most likely thing. So we had this sort of mild technical recession based on nominal GDP
[01:04:54.000 --> 01:04:59.680]   growth, not being bad, but simply not quite keeping up with the inflation rate. Yeah, now
[01:04:59.680 --> 01:05:04.320]   things are a little bit better. But I still think the huge recession is to come next year, because
[01:05:04.320 --> 01:05:10.000]   all the interest rate increases we've seen. So the Fed is, you know, pedal to the metal on interest
[01:05:10.000 --> 01:05:15.040]   rate increases, just like they were pedal to the metal on printing money. And so first, they,
[01:05:15.040 --> 01:05:19.280]   you know, they were too loose. And now they're probably being too tight too fast. So I think
[01:05:19.280 --> 01:05:23.120]   we're headed for a huge recession next year. And I think you're seeing that in the softness of all
[01:05:23.120 --> 01:05:30.400]   these forecasts. Yeah, look at the look at the mortgage rates right now, something like 7.1%.
[01:05:30.400 --> 01:05:38.160]   They broke the backs of the housing market that the inventory and prices inventory shot up,
[01:05:38.800 --> 01:05:44.640]   prices have shot up, new mortgages have gone down. And you know, we talked about job openings.
[01:05:44.640 --> 01:05:49.600]   Here's the the Fred chart for job openings real quick. You can see the the peak we were talking
[01:05:49.600 --> 01:05:52.800]   about, we're wondering if that would come plummeting down. Well, here it is, folks.
[01:05:52.800 --> 01:05:58.480]   Yeah, plummeting down from 11 million, losing a million in a month. Yeah, job openings coming
[01:05:58.480 --> 01:06:03.280]   smashing down. There's the Fed fund rate. You know, that's a pretty high ramp. So you think
[01:06:03.280 --> 01:06:09.280]   double dip recession? What do you think? freeberg Chamath in terms of what 2023 looks like you're
[01:06:09.280 --> 01:06:14.080]   sort of saying Chamath a bottom is forming. I kind of agree with that. I think the stock market is
[01:06:14.080 --> 01:06:21.120]   going up. Then it'll go back down because I think what David said is right. But for the short term,
[01:06:21.120 --> 01:06:26.640]   this thing is going up. short term up. And we've generally been positioned for it to go up. And,
[01:06:26.640 --> 01:06:32.720]   and at some point, we will reverse and position for it to go back down. But it's going up sacks,
[01:06:32.720 --> 01:06:37.760]   it seems like you took a week off from the all in podcast and people stopped talking about Ukraine.
[01:06:37.760 --> 01:06:42.080]   You want to give us an update? I mean, obviously, the war is not over. But it does seem like
[01:06:42.080 --> 01:06:48.480]   it somehow has fallen out of the public's consciousness a bit. I don't know if I go
[01:06:48.480 --> 01:06:55.120]   that far. There was the big event in the Ukraine war debate this week was that the House Progressive
[01:06:55.120 --> 01:07:04.160]   Caucus put out a letter signed by 30 progressive members to merely suggest that while we continue
[01:07:04.160 --> 01:07:10.080]   to fund Ukraine on a virtually unlimited basis, we also in parallel open up a diplomatic track
[01:07:10.080 --> 01:07:16.880]   with Russia to mitigate against the threat of us being drawn into the war and specifically a nuclear
[01:07:16.880 --> 01:07:25.360]   war. And just that very, I'd say anodyne letter that very tepid sentiment, really, they weren't
[01:07:25.360 --> 01:07:31.520]   questioning in any way, the providing again, a virtually unlimited support to Ukraine, that
[01:07:31.520 --> 01:07:38.000]   met with such a fierce reaction on social media and in the traditional media that I think all
[01:07:38.000 --> 01:07:45.200]   but one of the signatories recanted or walk back the letter and kudos to Representative Ro Khanna
[01:07:45.200 --> 01:07:52.960]   for not being one of the people who recanted he sat tall and gave an interview on CNN and MSNBC
[01:07:52.960 --> 01:07:59.440]   saying why has diplomacy become a dirty word? I voted for every single appropriation to give aid
[01:07:59.440 --> 01:08:04.560]   and weapons to Ukraine. I'll continue to do that. But I don't see a problem with us maintaining
[01:08:04.560 --> 01:08:09.440]   diplomatic relations, we might need those to avoid an unwanted escalation.
[01:08:09.440 --> 01:08:10.720]   Well, and here we are.
[01:08:10.720 --> 01:08:14.720]   Kudos to him for standing tall. But it's amazing to me that the Progressive Caucus,
[01:08:14.720 --> 01:08:22.400]   which used to be one of the groups in Congress that questioned American involvement in foreign
[01:08:22.400 --> 01:08:29.600]   wars, like the Iraq War, they basically, they have moved off that. And they threw in the towel so
[01:08:29.600 --> 01:08:32.800]   quickly on this, it was really kind of pathetic to see.
[01:08:32.800 --> 01:08:37.440]   I mean, it really like this is back to Shakespeare, like politics makes for strange bedfellows,
[01:08:37.440 --> 01:08:43.440]   you find yourself aligned with the most left part of the Democratic Party in trying to just say,
[01:08:43.440 --> 01:08:48.640]   hey, maybe we should negotiate peace a little more for us to pursue the right foreign policy.
[01:08:48.640 --> 01:08:54.400]   And I don't really care which party has you would you would actually donate to anybody who is
[01:08:54.400 --> 01:09:00.720]   pushing for that. So did you actually make any? I mean, I just happened, but I plan to donate to
[01:09:00.720 --> 01:09:06.480]   members of both party who push for a correct foreign policy, which I believe needs to be
[01:09:06.480 --> 01:09:12.160]   a little bit more restrained a little bit more questioning of what is in it for the United
[01:09:12.160 --> 01:09:17.520]   States. And we need to be careful about overextending ourselves. And we need to
[01:09:17.520 --> 01:09:20.720]   ask what is in America's vital interests? And we can support
[01:09:20.720 --> 01:09:27.920]   AOC be coming to the with a she's pro recanted. So she's one of the ones that were can't
[01:09:27.920 --> 01:09:31.520]   What do you think happens in a situation like that? Well, how do they get them to recant? Yeah,
[01:09:31.520 --> 01:09:36.400]   like, why? What is the point of recanting something that was so benign? It's not
[01:09:36.400 --> 01:09:40.800]   totally no, but what do you think? Like what what's happening behind the scenes? Like, why
[01:09:41.360 --> 01:09:45.360]   are people so afraid to say that, you know, you can be in support of Ukraine,
[01:09:45.360 --> 01:09:48.880]   but also still try to find a reason why was that turned into such a scarlet letter?
[01:09:48.880 --> 01:09:55.440]   It's a great point. And I think it just shows the heat right now on the issue. Here's what I think
[01:09:55.440 --> 01:09:58.880]   does it do that? Or does it just show how the progressives as just kind of clown tones?
[01:09:58.880 --> 01:10:05.840]   I mean, it's it's kind of sad. I mean, Jayapal, who was sort of the leader who put out the letter
[01:10:05.840 --> 01:10:10.800]   through her own staff under the bus. And I guess there was this snafu where the members all signed
[01:10:10.800 --> 01:10:14.720]   this letter in July and then held it for a few months. And then they put it out two weeks before
[01:10:14.720 --> 01:10:20.480]   the election. I can see why that timing didn't make sense. I don't know why, like they released
[01:10:20.480 --> 01:10:25.920]   it now, not two months ago, not three weeks from now, after the election. I can understand all
[01:10:25.920 --> 01:10:30.960]   those political considerations. But once you put the letter out to stand by it, don't throw your
[01:10:30.960 --> 01:10:36.240]   own staff under the bus. Because like you're saying, the letter was really a pretty anodyne
[01:10:36.240 --> 01:10:40.480]   statement of, hey, listen, do you think we can just have diplomacy on a parallel track at the
[01:10:40.480 --> 01:10:46.080]   same time that we're arming Ukraine? I just don't see the downside. But look, here's why I think
[01:10:46.080 --> 01:10:51.760]   they took so much heat is there's a lot of people on this issue who start with the end result of
[01:10:51.760 --> 01:10:58.800]   what they want. And the end result that they want is Putin and Russia leave Ukraine with their tail
[01:10:58.800 --> 01:11:04.320]   tucked between their legs. And they basically don't get one square inch of Ukraine. They believe that
[01:11:04.320 --> 01:11:10.560]   is the only acceptable moral outcome here. And they may be right about that. But then what they're
[01:11:10.560 --> 01:11:15.680]   doing is they're kind of reverse engineering all the beliefs that they have based on that outcome,
[01:11:15.680 --> 01:11:20.240]   that moral outcome they want to get to. So, for example, for the longest time, you heard things
[01:11:20.240 --> 01:11:25.200]   like Putin is definitely bluffing about using nuclear weapons. Well, how do they know that?
[01:11:25.200 --> 01:11:29.680]   They don't know that. They can't say that for sure. But it's what they want to believe. Because
[01:11:29.680 --> 01:11:36.560]   if you believe that nuclear war is a possibility, you might not go all the way for that maximalist
[01:11:36.560 --> 01:11:40.960]   position of the only acceptable outcome here is Russia leaving with his tail tucked between his
[01:11:40.960 --> 01:11:47.920]   legs. And I think the same thing is happening here with diplomacy is people who want a certain
[01:11:47.920 --> 01:11:54.480]   result in the war are afraid that diplomacy might result in something less than that. That's not a
[01:11:54.480 --> 01:12:01.840]   reason not to engage in diplomacy. And it's not a reason to deny the potential of this war to spin
[01:12:01.840 --> 01:12:07.360]   out of control, potentially into a nuclear war. Saks Saks is like a walking thesaurus. So J Cal,
[01:12:07.360 --> 01:12:12.960]   for you, I looked up anodyne and it means not likely to provoke dissent or offense inoffensive,
[01:12:12.960 --> 01:12:17.680]   often deliberately. So yeah, like, it's like, Oh, I know you were looking, you were looking at the
[01:12:17.680 --> 01:12:23.840]   screen, like a confused little puppy when he said anodyne. I got a thesaurus over here. Also,
[01:12:23.840 --> 01:12:25.520]   I didn't know what it meant. So thank you.
[01:12:25.520 --> 01:12:31.600]   But seriously, what is the I want to know the fallout from two things. And then we're going
[01:12:31.600 --> 01:12:38.960]   to do science corner. So number one, what is the I've been getting a lot of oat milk stands emailing
[01:12:38.960 --> 01:12:43.680]   me different brands of oat milk have been emailing me this week. Just give us an update, generally
[01:12:43.680 --> 01:12:48.960]   speaking on the ultimate milk crowd and your inbox tomorrow. They're trying to they're definitely
[01:12:48.960 --> 01:12:53.760]   trying to bring a do me but but these people like, you know what's so funny about these folks?
[01:12:53.760 --> 01:13:02.000]   They have no judgment clearly. Because they can't even say you know what, it actually tastes much
[01:13:02.000 --> 01:13:07.280]   crappier than these alternatives, but I choose to for x, y, z reasons that I could respect. It's
[01:13:07.280 --> 01:13:12.000]   the Oh my god, it's incredible. And he's so much better. You know, look at my little mustache.
[01:13:12.000 --> 01:13:17.680]   Disgusting. It doesn't foam properly. It tastes like dishwater. It's ridiculous. And then sacks
[01:13:17.680 --> 01:13:24.960]   discussed this horrific illustration of you in the new republic I saw look like Dolly broke and
[01:13:24.960 --> 01:13:28.640]   they use Dolly to make that illustration. No offense to the illustrator got paid 1000 bucks.
[01:13:28.640 --> 01:13:34.160]   Well, it was like, it was pre Olympic sacks. I thought it was Yeah, that's the problem. If
[01:13:34.160 --> 01:13:39.840]   you're chubby sacks or chubby J cow. It sucks when people base an illustration on a previous one.
[01:13:39.840 --> 01:13:44.400]   But sacks like a deranged sociopath. I mean, you look like Alex Jones.
[01:13:45.280 --> 01:13:48.480]   Well, look, they got Elon and Peter up there too. It's such a stupid hit piece.
[01:13:48.480 --> 01:13:52.560]   Elon looks like Hugh Grant. Peter Thiel looks like he's rolling on.
[01:13:52.560 --> 01:14:01.520]   He's got Molly jaw. And also he's, he you show a lot of stubble, which you also don't have.
[01:14:01.520 --> 01:14:04.320]   But look how fat they make you look. Look at you.
[01:14:04.320 --> 01:14:11.520]   Yeah, the chin. Jesus, my lord. But what I mean, what's going on in terms of the general reaction
[01:14:11.520 --> 01:14:16.320]   to the amount of attention you're getting for political commentary now?
[01:14:16.320 --> 01:14:20.640]   sacks David sacks will be our next Secretary of State. Well, no, I'm here for it. I can't wait.
[01:14:20.640 --> 01:14:25.200]   I'll go long. David sacks will be our Secretary of State within two or three presidents.
[01:14:25.200 --> 01:14:28.160]   I'll take he's got to make a little more cash.
[01:14:28.160 --> 01:14:31.840]   My views, my views are so out of step with the foreign policy establishment.
[01:14:31.840 --> 01:14:36.720]   I wouldn't why you went, that's why you that's why I wouldn't feel the need to be so out there
[01:14:36.720 --> 01:14:43.120]   on this issue. If the foreign policy establishment was doing its job. If you actually had, you know,
[01:14:43.120 --> 01:14:48.720]   people from the policy elite going out there saying sensible things about Ukraine, it wouldn't
[01:14:48.720 --> 01:14:56.400]   fall on me or other people like and China, like Elon basically posted that straw poll on Twitter,
[01:14:56.400 --> 01:15:00.720]   which was totally reasonable, got condemned for it. And then Bill Ackman, actually, who's been
[01:15:00.720 --> 01:15:05.680]   in Twitter spats with me before we've been on opposite sides of issues, actually came out
[01:15:05.680 --> 01:15:12.000]   and retweeted something I wrote as basically being supportive. Because the weird thing is want this
[01:15:12.000 --> 01:15:17.680]   war to escalate out of control. I think the weird thing is people are, there's a group in the in the
[01:15:17.680 --> 01:15:23.120]   media class, other podcasters, other journalists, who are saying you have no right to talk about
[01:15:23.120 --> 01:15:27.440]   this topic. And what I said is, you know, hey, listen, Saxon, I could disagree about things on
[01:15:27.440 --> 01:15:31.280]   the margin here or there. But I'm glad we're having the discussion shouldn't all Americans
[01:15:31.280 --> 01:15:35.280]   be having a discussion about our foreign policy and what our goals are. That's our civic duty
[01:15:35.280 --> 01:15:40.000]   is to have this discussion. So whenever you hear the political class, the podcasting class,
[01:15:40.000 --> 01:15:44.560]   the coastal elites, which we are part of, when they tell you you can't participate, or this
[01:15:44.560 --> 01:15:48.480]   person can participate in the discussion, because they're successful in this other aspect of life,
[01:15:48.480 --> 01:15:53.760]   that's complete bullshit. Everybody should talk about this and disagree or agree and try to work
[01:15:53.760 --> 01:15:58.640]   towards some common understanding. You're right. So first of all, whenever they say listen to the
[01:15:58.640 --> 01:16:03.360]   experts, and you're not an expert, first of all, they're expressing an opinion themselves. And
[01:16:03.360 --> 01:16:07.920]   they are expressing equally passionate opinions on the other side about the sole Ukraine war.
[01:16:07.920 --> 01:16:11.920]   So first of all, why are they allowed to have an opinion? So whenever somebody uses this,
[01:16:11.920 --> 01:16:16.480]   you're not allowed to have an opinion argument, it's always very selective. And it's only applied
[01:16:16.480 --> 01:16:21.760]   to people they disagree with, not to people who are equally inexpert on their side of the debate.
[01:16:21.760 --> 01:16:27.120]   So that's point number one. Hold on point number two is I've listened to plenty of experts. Okay.
[01:16:27.120 --> 01:16:30.400]   I've listened to the IR scholar, John Mearsheimer, I've listened to the international development
[01:16:30.400 --> 01:16:35.520]   economist, Jeffrey Sachs, I've gone back and listened to our former ambassador to the Soviet
[01:16:35.520 --> 01:16:40.880]   Union, Jack Matlock. I've read George Kennan's interviews. I've read Bill Burns, our current CIA
[01:16:40.880 --> 01:16:46.800]   director on this matter. There are plenty of experts who warned that our policy of trying to
[01:16:46.800 --> 01:16:52.880]   bring NATO right up to Russia's border would eventually blow up in our faces, it would poison
[01:16:52.880 --> 01:16:58.800]   our relations with them, and lead to conflict and this war. So there are plenty of authoritative
[01:16:58.800 --> 01:17:04.560]   sources going back many years on this topic. And the problem is that the people on the other side
[01:17:04.560 --> 01:17:10.720]   of this debate simply want to memory hole all of these warnings and deny that they that this war
[01:17:10.720 --> 01:17:15.200]   was ever predicted. Because if this war was predicted, it means it could have been avoided.
[01:17:15.200 --> 01:17:17.760]   They don't want to admit that this war could have been avoided.
[01:17:17.760 --> 01:17:23.520]   Or how about this? How about war is messy, resolving things internationally with dictators
[01:17:24.160 --> 01:17:28.880]   can be very hard. And nobody wins in some of these cases. No, there's no perfect outcome here.
[01:17:28.880 --> 01:17:33.440]   And you could hold in your head two things. Number one, Putin's a dictator, we need to hold the line
[01:17:33.440 --> 01:17:37.680]   and make sure it doesn't invade other countries. And number two, yeah, you probably want to keep
[01:17:37.680 --> 01:17:43.520]   normal relations with these people and negotiate with them to resolve conflict. I'm getting a
[01:17:43.520 --> 01:17:47.840]   little concerned about the saber rattling on both sides in China. You know, we're escalating all this
[01:17:47.840 --> 01:17:52.960]   chip stuff. We're escalating and Xi Jinping is taking complete control. I'm wondering who's
[01:17:52.960 --> 01:17:57.040]   going to meet with him who's going to talk to Xi Jinping about how we could collaborate together?
[01:17:57.040 --> 01:18:01.280]   Who's left to talk to him Tim cook? There's a there's a bunch of unforced errors happening
[01:18:01.280 --> 01:18:04.880]   in China. How do we de escalate? Well, there's a bunch of unforced errors that you have to let
[01:18:04.880 --> 01:18:11.040]   play out because they have huge economic implications. So I don't think this I don't
[01:18:11.040 --> 01:18:15.520]   think this is a time for again, I think David's generally right. We do not have time for
[01:18:15.520 --> 01:18:20.400]   adventurism right now. Because even before we engage in some of these other places,
[01:18:20.960 --> 01:18:26.160]   there are a lot of, you know, headwinds that are working against for so for example, in China,
[01:18:26.160 --> 01:18:31.840]   you have these massive demographic headwinds that are just building, we have to see what
[01:18:31.840 --> 01:18:36.400]   the chips act does in terms of follow through to China's ability to expand militarily or
[01:18:36.400 --> 01:18:42.960]   technologically. There are all of these things that that you owe as a citizen of the United
[01:18:42.960 --> 01:18:47.440]   States to see some more data on the ground in terms of its empirical impact before you re
[01:18:47.440 --> 01:18:53.040]   underwrite a different strategy. Right now the strategy is working. You know, we we are observing
[01:18:53.040 --> 01:18:57.440]   this, you know, one China policy, I think that's the right thing to do. And now let all of this
[01:18:57.440 --> 01:19:03.120]   other stuff play out. Can I say one thing about this? So what the administration did in banning
[01:19:03.120 --> 01:19:08.880]   China from buying from us or any of our allied countries, these advanced semiconductor chips,
[01:19:08.880 --> 01:19:13.120]   that's what they did. They only banned the sale of chips to China, they banned the sale of
[01:19:13.120 --> 01:19:17.600]   equipment that can make the chips. And they even prohibited American citizens and companies
[01:19:17.600 --> 01:19:24.080]   from working in China to basically help them set up their own foundries and chip fabrication. So
[01:19:24.080 --> 01:19:30.080]   they are essentially cutting off China from advanced chips. That's the goal here. And you
[01:19:30.080 --> 01:19:34.880]   know, we've talked about on this pod before how chips are the new oil, right? These advanced
[01:19:34.880 --> 01:19:41.520]   semiconductors are the new oil. So this is almost like an oil embargo of China. If you go back and
[01:19:41.520 --> 01:19:46.720]   look at it, if you go back and look at history, reason why the reason why is they don't want
[01:19:46.720 --> 01:19:54.480]   these in weapons, correct? That is the stated reason. That's the tip of the spear. But I think
[01:19:54.480 --> 01:20:02.320]   the more impactful mechanism is to prevent an entire layer of infrastructure to be built in
[01:20:02.320 --> 01:20:08.000]   China that allows them to advance all of these next generation cyber capabilities, including a
[01:20:08.000 --> 01:20:15.680]   whole bunch of things in AI, that we want to make sure that as often and as often as possible is,
[01:20:15.680 --> 01:20:21.760]   is for the United States and our allies as we choose. So all this next generation silicon will
[01:20:21.760 --> 01:20:27.360]   do a lot more to push that forward. And so if you put that in the hands of Chinese technology
[01:20:27.360 --> 01:20:31.680]   companies, or Chinese government, or the Chinese government in the parts that are actually
[01:20:31.680 --> 01:20:38.880]   technological, you actually increase the surface area in which you compete. By preventing that
[01:20:38.880 --> 01:20:43.360]   technology to go to them, you decrease the service area in which you're competitive, and they are
[01:20:43.360 --> 01:20:46.800]   one or two steps behind and have an hour forced to build it themselves.
[01:20:46.800 --> 01:20:52.320]   So freeberg, if that happens, do you think that China escalates and says, Well,
[01:20:52.320 --> 01:20:59.120]   why are we building iPhones here? No, I think China makes decisions a little differently
[01:20:59.120 --> 01:21:06.800]   than perhaps US policymakers and foreign policy makers make decisions, they think forward,
[01:21:06.800 --> 01:21:12.240]   and calculate the series of events that will follow from that decision. Whereas we are typically
[01:21:12.240 --> 01:21:17.840]   reacting to some event that's happened in the past, not necessarily always thinking through
[01:21:17.840 --> 01:21:22.640]   the second and third or third order effects and consequences of our decisions. So the China
[01:21:22.640 --> 01:21:27.200]   calculus would likely look something more like, if we were to say stop making iPhones here,
[01:21:27.840 --> 01:21:31.920]   we would estimate that the US would do the following to retaliate back against us.
[01:21:31.920 --> 01:21:36.640]   And as they do through that calculation, you end up realizing pretty quickly that there isn't as
[01:21:36.640 --> 01:21:42.320]   much to gain as there is more to lose by doing that. That would be my guess. I'm no China expert,
[01:21:42.320 --> 01:21:47.280]   I'm no foreign policy expert. But from my understanding of how Chinese policymakers
[01:21:47.280 --> 01:21:51.760]   do think and do make decisions, it's much more about what's the rational calculated
[01:21:51.760 --> 01:21:56.640]   set of outcomes that will emerge and evolve from this decision. And in my experience,
[01:21:56.640 --> 01:22:01.600]   talking with people in the United States, that are in various communities of influence,
[01:22:01.600 --> 01:22:06.000]   it's much more about let's do what we consider to be the right or moral thing right now.
[01:22:06.000 --> 01:22:10.560]   And in response and retaliation, and let's do an eye for an eye. So that's why I don't think that
[01:22:10.560 --> 01:22:16.800]   they're likely to be the first step in an escalation escalatory ladder. There probably
[01:22:16.800 --> 01:22:22.080]   be a few more series of provocations before that may happen, at which point, it may need to be kind
[01:22:22.080 --> 01:22:24.800]   of an inevitable step that they'd have to take. But again, I think,
[01:22:25.840 --> 01:22:29.760]   I don't know, I mean, so in terms of the motivation for this, I think it's pretty clear,
[01:22:29.760 --> 01:22:35.760]   this is an attempt to hobble the Chinese economy, not just that all their weapons programs,
[01:22:35.760 --> 01:22:41.520]   but their economy itself, and hold them back and slow down their rise and their rapid growth.
[01:22:41.520 --> 01:22:45.040]   Now, is that a good idea? I mean, I think what this shows is we've moved from
[01:22:45.040 --> 01:22:51.840]   sort of economic logic, which is about finding trade surplus and win-win scenarios to geopolitical
[01:22:51.840 --> 01:22:57.920]   logic, which is about balance of power. And this sort of ban on sales of semiconductors to them,
[01:22:57.920 --> 01:23:02.800]   it's very much geopolitical, because it's hurting our companies, but it hurts China more. And so
[01:23:02.800 --> 01:23:09.840]   it's about increasing our balance of power against them. And now listen, I think you could make the
[01:23:09.840 --> 01:23:16.880]   argument that we were overdue to be thinking in terms of great power competition and geopolitical
[01:23:16.880 --> 01:23:23.920]   rivalry. And this is an attempt now to correct the bad decisions that were made 20 years ago in
[01:23:23.920 --> 01:23:28.880]   terms of how we fed the Chinese economy until it became a pure competitor to the United States.
[01:23:28.880 --> 01:23:34.640]   So I think you can make those arguments. The thing that concerns me most about it is,
[01:23:34.640 --> 01:23:42.800]   do our leaders really have the bandwidth to manage a second front in the sort of great
[01:23:42.800 --> 01:23:47.760]   power competition right now, while we've got Russia and Ukraine going on, on the one hand,
[01:23:47.760 --> 01:23:53.600]   are they really ready to manage an escalation of the competition with China? And to Freeburg's
[01:23:53.600 --> 01:23:58.320]   point, have they really thought through all the second, third, fourth order consequences of this?
[01:23:58.320 --> 01:24:03.600]   Have they thought through the incentives this may create on China, for example, to take Taiwan? I
[01:24:03.600 --> 01:24:11.200]   mean, if Taiwan is the place that makes all these chips through TSMC, for example, and we have now
[01:24:11.200 --> 01:24:16.400]   cut them off, we've now embargoed them from these chips, does it strengthen China's incentive to go
[01:24:16.400 --> 01:24:22.960]   after Taiwan? Does it strengthen China's incentives right now to help Russia in its war in Ukraine
[01:24:22.960 --> 01:24:30.800]   in retaliation, because they don't want to see Russia decisively defeated, and then they will
[01:24:30.800 --> 01:24:36.480]   solely be in the gun sights of US hawks. So I think there's a lot of things that could go wrong here
[01:24:37.040 --> 01:24:44.800]   when the US is now escalating geopolitical tensions and competition, not just on one front,
[01:24:44.800 --> 01:24:52.160]   but on two fronts. And especially given how weak the US economy is, and that we're headed into
[01:24:52.160 --> 01:24:58.880]   a major recession next year, it just feels to me like they are, you know, they are kind of putting
[01:24:58.880 --> 01:25:02.880]   their foot on the accelerator in terms of geopolitical risk at a time when we're not
[01:25:02.880 --> 01:25:08.640]   really in a great spot to be taking those risks. Also, on a foreign policy basis. Is there no
[01:25:08.640 --> 01:25:12.880]   common ground? Are there no things we could collaborate on and work on together? Right?
[01:25:12.880 --> 01:25:16.880]   And that's the thing that seems to be missing in the foreign policy for the last couple of
[01:25:16.880 --> 01:25:21.040]   administrations is, are there things that we could be building together? Are there things that we
[01:25:21.040 --> 01:25:26.560]   could be working on the environment, energy, sustainability, education, I don't know what it
[01:25:26.560 --> 01:25:31.040]   is. But it felt like, you know, with China for a couple of decades, we felt like we were working
[01:25:31.040 --> 01:25:35.040]   in a very collaborative way. And now it feels like every single instance is adversarial.
[01:25:35.040 --> 01:25:40.480]   Right? Because the problem is that those policies of constructive engagement that you're talking
[01:25:40.480 --> 01:25:47.440]   about, fed the Chinese tiger until it became a dragon. Yeah. Now the size of vagar or something
[01:25:47.440 --> 01:25:59.120]   and the US policy establishment in the Pentagon look at the rise of China. And they're like,
[01:25:59.120 --> 01:26:03.200]   what have we done, we have created a peer competitor, the United States, we need to stop
[01:26:03.200 --> 01:26:10.240]   their economic rise. And I think that, again, I think there is a geopolitical logic and strategy
[01:26:10.240 --> 01:26:14.480]   to what the administration has done. But I question the timing of doing it at the same time
[01:26:14.480 --> 01:26:19.280]   that we have this unresolved war in Eastern Europe. Well, it is nice that we're seem to be
[01:26:19.280 --> 01:26:22.400]   getting some of this on showing of chips, and that money is actually starting to flow. It does
[01:26:22.400 --> 01:26:26.640]   seem like we're thinking a little bit like in decades and strategy. The other part, I think
[01:26:26.640 --> 01:26:31.280]   Biden and Blinken have done a good job. They've done a good job on this right now. They've played
[01:26:31.280 --> 01:26:39.040]   it well. I don't know about that. I just come on. First of all, horrible job. Hold on a second.
[01:26:39.040 --> 01:26:45.120]   Biden did a horrible job. The tiger. Hold on. Hold on. You poke the tiger. No, hold on. They
[01:26:45.120 --> 01:26:49.600]   take where they did a bad job is last year, they had a whole year to negotiate to avoid
[01:26:49.600 --> 01:26:56.080]   this Ukraine war from happening. Biden even had a summit with Putin on June 16. Last year,
[01:26:56.080 --> 01:27:01.280]   they never engaged in diplomacy. And now they have stacked this geopolitical risk with China
[01:27:01.280 --> 01:27:06.640]   on top of the risk they've already created in Ukraine. I, this policy may or may not ultimately
[01:27:06.640 --> 01:27:11.360]   turn out to be correct. I like I said, I can see the strategy behind it. But I do not believe
[01:27:11.360 --> 01:27:16.000]   that Biden and Blinken have thought through the second, third and fourth order consequences,
[01:27:16.000 --> 01:27:20.160]   just like freeberg said. So I think it's a little early to be giving them credit on this.
[01:27:20.160 --> 01:27:24.240]   All right, freeberg, you got anything in the science corner, we gave we gave saxes red meat.
[01:27:25.440 --> 01:27:29.280]   And he ripped it to shreds. Now it's time to give you your soy tofu.
[01:27:29.280 --> 01:27:33.840]   You guys a quick, a quick science corner, please, please. So we've talked in the past about the
[01:27:33.840 --> 01:27:38.880]   human gut biome, 10 trillion bacterial cells living in our gut biome. And it turns out and
[01:27:38.880 --> 01:27:43.360]   there has been this theory for many years, that a lot of human disease actually originates in the
[01:27:43.360 --> 01:27:48.560]   gut. And there's increasingly evidence of how and why this happens. So it turns out that your immune
[01:27:48.560 --> 01:27:54.800]   cells can sometimes see a protein on the outside of a bacteria that sits in your gut, and it attacks
[01:27:54.800 --> 01:27:59.520]   that bacteria, and it tries to get rid of it. That protein can look a little bit like a human
[01:27:59.520 --> 01:28:04.960]   protein at some cell in your body. And so that then triggers an autoimmune reaction, meaning you
[01:28:04.960 --> 01:28:11.120]   are now making these antibodies to proteins that look a lot like your proteins and other parts of
[01:28:11.120 --> 01:28:16.080]   your body. And then your cells start to destroy yourself. And you end up having inflammation and
[01:28:16.080 --> 01:28:20.640]   disease. And they found evidence of this across a lot of disease states. So just the other day
[01:28:20.640 --> 01:28:26.800]   published in the journal science, translational medicine was a really interesting paper by a team
[01:28:26.800 --> 01:28:32.400]   that identified a very specific bacteria that we find in the gut, that can actually trigger
[01:28:32.400 --> 01:28:37.600]   rheumatoid arthritis. And so you know, I think 2 million Americans have rheumatoid arthritis,
[01:28:37.600 --> 01:28:42.000]   it's a really debilitating inflammatory disease. And we never understood where the inflammation
[01:28:42.000 --> 01:28:49.040]   comes from. Why is the human immune cell creating antibodies to attack its own protein in the joints
[01:28:49.040 --> 01:28:52.880]   of the body. And now it looks like that the protein that we find in the joints of the body
[01:28:52.880 --> 01:28:58.000]   has some overlap or three dimensional structure that looks similar to the protein we'll find
[01:28:58.000 --> 01:29:03.200]   on this very specific gut bacteria that they found, which creates obviously a path now,
[01:29:03.200 --> 01:29:08.480]   for if we can stop that gut bacteria from proliferating, or, you know, existing in the gut
[01:29:08.480 --> 01:29:13.920]   over time, that can have a reduction, but sorry, it's a rate of rheumatoid arthritis.
[01:29:13.920 --> 01:29:16.080]   Did they guess what the mechanism of action was?
[01:29:16.640 --> 01:29:20.080]   So so this tech, not this, so the mechanism of action is typically what's called,
[01:29:20.080 --> 01:29:24.960]   generally speaking, protein mimicry. And so protein mimicry means that there's some so
[01:29:24.960 --> 01:29:30.800]   think about a protein as being like, you know, a clumpy rock. And there's some part of the clumpy
[01:29:30.800 --> 01:29:34.880]   rock that looks a little bit like the part of another clumpy rock. And that's the protein,
[01:29:34.880 --> 01:29:39.520]   think about that as being the protein on the bacterial cell, and the protein in your joint
[01:29:39.520 --> 01:29:44.720]   cells. And so your body makes an antibody to that little part of the rock on the bacterial cell
[01:29:44.720 --> 01:29:48.720]   to get rid of it. And then it that there's some overlap that looks a little bit like your own
[01:29:48.720 --> 01:29:54.560]   cell. And so that's called protein mimicry. And because of the ability now to do DNA sequencing,
[01:29:54.560 --> 01:30:00.640]   and now with, you know, some of the alpha fold technology, we can actually take the genome from
[01:30:00.640 --> 01:30:06.880]   that bacteria, predict the 3d structure of the proteins created that by that bacteria,
[01:30:06.880 --> 01:30:11.600]   and then potentially identify that there's a mimicry or an overlap between our own protein
[01:30:11.600 --> 01:30:16.320]   in ourselves and the protein of the bacteria, which is why we're having auto immunity, which
[01:30:16.320 --> 01:30:19.840]   now our immune cells are not just attacking the bacteria, we could solve arthritis, we
[01:30:19.840 --> 01:30:23.520]   saw for arthritis. And so there's a lot of disease states that are starting to look like this. So the
[01:30:23.520 --> 01:30:28.080]   combination of DNA sequencing and our ability to identify organisms in the gut biome. And by the
[01:30:28.080 --> 01:30:32.080]   way, so much of this goes back to the gut biome, we're finding all these disease states from lupus
[01:30:32.080 --> 01:30:37.280]   to show grins to rheumatoid arthritis, that have some linkage back to some bacteria that shows up
[01:30:37.280 --> 01:30:42.000]   in your gut. And so now we can be very targeted potentially about eradicating that bacteria from
[01:30:42.000 --> 01:30:47.200]   the gut, or, you know, kind of changing our gut biome in a way that ultimately resolved to
[01:30:47.200 --> 01:30:50.800]   eliminating that disease risk. And so it's really fascinating. Yeah.
[01:30:50.800 --> 01:30:52.640]   Jamal, any thoughts on this gut biome?
[01:30:52.640 --> 01:30:56.960]   I mean, I always knew the solution was either in freeberg's gut, you know,
[01:31:02.320 --> 01:31:03.680]   in his gut or on Uranus.
[01:31:03.680 --> 01:31:07.200]   Oh, freeberg science quarter.
[01:31:07.200 --> 01:31:10.880]   Do it again. The joke didn't land.
[01:31:10.880 --> 01:31:15.520]   All right, here we go one more time. So Chamath, any feedback on this? It's pretty great science
[01:31:15.520 --> 01:31:21.280]   going on here. I mean, it was always 50/50 that the solution was either your gut or Uranus.
[01:31:21.280 --> 01:31:26.000]   Okay, you can't laugh till after you land the joke. Come on, do it again.
[01:31:26.000 --> 01:31:30.400]   I saw it coming. It was coming around the corner and I just started peeking his head out.
[01:31:30.400 --> 01:31:32.560]   Just leave this all in.
[01:31:32.560 --> 01:31:34.160]   Let's get this right for the fans.
[01:31:34.160 --> 01:31:38.320]   Okay, here we go. Three, two. All right, Chamath, it seems like very interesting science
[01:31:38.320 --> 01:31:39.600]   there coming out of science corner.
[01:31:39.600 --> 01:31:40.640]   50/50.
[01:31:40.640 --> 01:31:41.120]   50/50.
[01:31:41.120 --> 01:31:45.120]   You got Uranus.
[01:31:45.120 --> 01:31:53.120]   You can't even get it out. I mean, you tried to get it out of his anus. It was poking. It was
[01:31:53.120 --> 01:31:55.840]   like a little turtle coming out of his anus, but you couldn't get it out.
[01:31:55.840 --> 01:31:58.000]   Oh my gosh. 50/50.
[01:31:58.720 --> 01:32:00.880]   You got Uranus.
[01:32:00.880 --> 01:32:06.240]   It's like the entire science quarter is just here for us to beat up the nerd and throw him in a
[01:32:06.240 --> 01:32:06.640]   locker.
[01:32:06.640 --> 01:32:11.760]   Oh my God. My stomach is hurting. Oh my God.
[01:32:11.760 --> 01:32:12.160]   Poor guy.
[01:32:12.160 --> 01:32:13.520]   Oh, I needed that laugh.
[01:32:13.520 --> 01:32:16.800]   You ever see Smokey and the Bandit where they have the reels at the end sacks?
[01:32:16.800 --> 01:32:17.120]   The outtakes.
[01:32:17.120 --> 01:32:22.400]   When Don DeLuise and Burr Reynolds. I just keep losing it. That's what this is.
[01:32:22.400 --> 01:32:23.840]   Oh my God.
[01:32:23.840 --> 01:32:26.800]   It's like, I'm going to say science quarter and people are going to just start laughing
[01:32:26.800 --> 01:32:29.040]   and thinking about Freeberg's anus.
[01:32:29.040 --> 01:32:33.440]   All right. Listen.
[01:32:33.440 --> 01:32:37.600]   Welcome home, Saks. We miss you for your week off.
[01:32:37.600 --> 01:32:41.680]   We miss you, David.
[01:32:41.680 --> 01:32:42.640]   Thanks, guys.
[01:32:42.640 --> 01:32:46.480]   Thanks. And we'll see you over on Market Street. No announcements right now.
[01:32:46.480 --> 01:32:50.160]   No testimonials, no announcements. I'll see you at yoga. We're going to do a--
[01:32:50.160 --> 01:32:53.600]   I'll see you at the homeless shelter. We're volunteering today, right?
[01:32:53.600 --> 01:32:55.840]   Yeah, volunteering. I'll see you over at the homeless shelter.
[01:32:55.840 --> 01:32:57.440]   You're pouring soup?
[01:32:57.440 --> 01:33:01.440]   Yeah. If you could get me a tofu salad with extra tempeh before Freeberg eats it all.
[01:33:01.440 --> 01:33:04.880]   Don't don't go. Don't get me started on tempeh.
[01:33:04.880 --> 01:33:07.840]   I'm going to go. I'm going to pour all the oatmeal out. I'm going right to the cafe.
[01:33:07.840 --> 01:33:11.360]   I'm going right to the cafe. I'm getting all the oatmeal right down the drain.
[01:33:11.360 --> 01:33:16.960]   Honestly, honestly, there should be there should be one milk, non-lactose alternative.
[01:33:16.960 --> 01:33:18.880]   And then one milk.
[01:33:18.880 --> 01:33:20.000]   It's called black coffee. And that's it.
[01:33:20.000 --> 01:33:23.040]   Black coffee. That's it. If you're lactose intolerant. Yeah. Lactose intolerant milk.
[01:33:23.040 --> 01:33:25.680]   No, have one. Have one thing without lactose.
[01:33:25.680 --> 01:33:26.800]   So whatever that is.
[01:33:26.800 --> 01:33:28.320]   Can we wrap the show now?
[01:33:28.320 --> 01:33:29.360]   No, we're having too much fun.
[01:33:29.360 --> 01:33:35.440]   Can you imagine? Can you imagine the distribution of gluten-free snacks?
[01:33:35.440 --> 01:33:39.120]   I mean, there should have a few, but you know, all kinds of different snacks.
[01:33:39.120 --> 01:33:42.880]   And by the way, the keto snacks have horrendous amounts of chemicals in it.
[01:33:42.880 --> 01:33:44.880]   The xylitol. What is xylitol?
[01:33:44.880 --> 01:33:48.320]   Here's xylitol. Well, screw up your stomach, man. Do not have that.
[01:33:48.320 --> 01:33:49.200]   It's horrible.
[01:33:49.200 --> 01:33:52.480]   Freeberg, you want to tell everybody about xylitol and the impact it has on your anus?
[01:33:52.800 --> 01:33:57.280]   [Laughter]
[01:33:57.280 --> 01:33:58.720]   No, it seriously does.
[01:33:58.720 --> 01:34:02.480]   I think xylitol is the thing that gives you a lot of gas and you just keep ripping.
[01:34:02.480 --> 01:34:05.440]   I think it's really bad for you.
[01:34:05.440 --> 01:34:06.080]   Here's an idea.
[01:34:06.080 --> 01:34:10.880]   [Laughter]
[01:34:10.880 --> 01:34:12.320]   Way to go, J-Cal.
[01:34:12.320 --> 01:34:14.240]   Yeah, now he's going to turn into a school shooter.
[01:34:14.240 --> 01:34:16.400]   Well, that's your fault. You were mean to him.
[01:34:16.400 --> 01:34:18.320]   You came up with the anus jokes.
[01:34:18.320 --> 01:34:18.880]   That was all your anus.
[01:34:18.880 --> 01:34:22.400]   I've been doing that joke for five years with him.
[01:34:22.400 --> 01:34:23.280]   You're a bully.
[01:34:23.280 --> 01:34:24.080]   I'm not.
[01:34:24.080 --> 01:34:24.480]   No, no, no.
[01:34:24.480 --> 01:34:26.160]   You bullied Freeberg off the show.
[01:34:26.160 --> 01:34:26.960]   You brigaded him.
[01:34:26.960 --> 01:34:28.400]   I did not on the show.
[01:34:28.400 --> 01:34:30.000]   We brigadooned him.
[01:34:30.000 --> 01:34:31.680]   We brigadooned our bestie.
[01:34:31.680 --> 01:34:32.240]   Sorry, bestie.
[01:34:32.240 --> 01:34:32.720]   All right.
[01:34:32.720 --> 01:34:37.440]   For the dictator himself, Chamath Palihapitiya, going into sweater season, I might note,
[01:34:37.440 --> 01:34:39.680]   it's going to be a big, big Q4 for us.
[01:34:39.680 --> 01:34:40.400]   Big Q4.
[01:34:40.400 --> 01:34:45.280]   And the beep of the beep corporation, David Sachs.
[01:34:45.280 --> 01:34:47.840]   Oh, if you mean the general partner of Kraft Ventures.
[01:34:47.840 --> 01:34:49.760]   Yes, the general partner of Kraft Ventures.
[01:34:49.760 --> 01:34:50.400]   That's it.
[01:34:50.400 --> 01:34:57.200]   And the queen of quinoa, the prince of panic attacks, the ambassador of Uranus, David Freeberg.
[01:34:57.200 --> 01:34:58.320]   We will see you next time.
[01:34:58.320 --> 01:34:58.800]   I'm J-Cal.
[01:34:58.800 --> 01:34:59.120]   Love you, boys.
[01:34:59.120 --> 01:34:59.840]   Greatest moderator.
[01:34:59.840 --> 01:35:00.400]   I love you, guys.
[01:35:00.400 --> 01:35:00.640]   Bye.
[01:35:00.640 --> 01:35:00.880]   Bye.
[01:35:00.880 --> 01:35:02.880]   [MUSIC PLAYING]
[01:35:02.880 --> 01:35:04.880]   [MUSIC PLAYING]
[01:35:05.360 --> 01:35:07.360]   [MUSIC PLAYING]
[01:35:07.360 --> 01:35:10.040]    I'm going, I'm going all in 
[01:35:10.040 --> 01:35:14.040]    And it said, we open-sourced it to the fans, and they've just gone crazy with it 
[01:35:14.040 --> 01:35:14.940]    Loving You L.A. 
[01:35:14.940 --> 01:35:16.200]    I'm the Queen of Kin-wah 
[01:35:16.200 --> 01:35:17.940]    I'm going all in 
[01:35:17.940 --> 01:35:20.960]    What, what your winners like? 
[01:35:20.960 --> 01:35:22.960]    What, what your winners like? 
[01:35:22.960 --> 01:35:25.140]    Besties are gone 
[01:35:25.140 --> 01:35:28.100]    'Cause my, uh, dog taken notice in your driveway steps 
[01:35:28.100 --> 01:35:29.340]    Oh, yeah 
[01:35:29.340 --> 01:35:31.300]    Oh, man 
[01:35:31.300 --> 01:35:33.460]    The dasher will meet me at Woodson Land
[01:35:33.460 --> 01:35:37.260]    We should all get a room and just have one big huge orgy, 'cause they're all just useless 
[01:35:37.260 --> 01:35:40.360]    It's like this, like, sexual tension that they just need to release somehow 
[01:35:40.360 --> 01:35:43.160]    What, what your, uh, B? 
[01:35:43.160 --> 01:35:45.160]    What, what your, uh, B? 
[01:35:45.160 --> 01:35:47.160]    B, what your, uh, B? 
[01:35:47.160 --> 01:35:49.160]    Besties are gone 
[01:35:49.160 --> 01:35:51.160]    I'm going all in 
[01:35:51.160 --> 01:35:56.160]   
[01:35:56.160 --> 01:35:58.160]    I'm going all in 
[01:35:58.160 --> 01:35:59.160]   [inaudible].
[01:35:59.160 --> 01:35:59.660]   you
[01:35:59.660 --> 01:36:09.660]   [BLANK_AUDIO]

