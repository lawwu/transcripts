
[00:00:00.000 --> 00:00:07.920]   Do you do any kind of machine learning now on the rover? Is that even possible with the hardware
[00:00:07.920 --> 00:00:14.080]   you have? And if you have a Snapdragon on the helicopter, it seems like you could do some
[00:00:14.080 --> 00:00:20.000]   in that or try to do some. Is there any happening or is it mostly older techniques for now?
[00:00:20.000 --> 00:00:26.400]   Yeah, a lot of it is human in the loop, but there are some elements of autonomy, both in
[00:00:26.400 --> 00:00:31.680]   terrain classification. So we have been doing a number of work to take newer modern algorithms.
[00:00:31.680 --> 00:00:36.320]   So the interesting part is DevOps at the edge where the edge is Mars, right?
[00:00:36.320 --> 00:00:42.960]   You know, we talk about the edge today in the cloud or in IoT and, you know, so it's DevOps. So
[00:00:42.960 --> 00:00:47.840]   what you test terrestrially, you've got to make sure that, you know, we can uplink it and port it,
[00:00:47.840 --> 00:00:52.720]   you know, to, again, these older devices and in some cases, devices that were deployed almost
[00:00:52.720 --> 00:00:56.960]   eight years ago, like Curiosity and things like that. And so we have been working on that. There
[00:00:56.960 --> 00:01:02.080]   is an algorithm called Spock, again, Star Trek names, you know, but this is a soil property
[00:01:02.080 --> 00:01:07.040]   object classifier. It's like a terrain classifier. And we can run that on the older devices. You
[00:01:07.040 --> 00:01:11.840]   know, obviously the tricks with that are, you know, you don't have a GPU, you know, you may
[00:01:11.840 --> 00:01:16.480]   have to quantize the models trade for, you know, accuracy and performance and things like that
[00:01:16.480 --> 00:01:20.720]   within acceptable bounds. And so a lot of these things are for human subject matter expert review
[00:01:20.720 --> 00:01:26.480]   or for mission tactical ops review with human in the loop. The more in the future we can get that
[00:01:26.480 --> 00:01:30.320]   out of the loop and more autonomous decisions, we're going to need it. And I'll say one quick
[00:01:30.320 --> 00:01:36.480]   example. The next mission is called Mars sample return in the program. And the basic idea is this,
[00:01:36.480 --> 00:01:40.400]   this big car size rover driving around perseverance. One of the things that does is it's
[00:01:40.400 --> 00:01:46.960]   coring rocks and it's going to drop tubules of those cord rocks as it drives over the next N
[00:01:46.960 --> 00:01:52.720]   years. In the next N years, we'll be building in partnership with ESA, the fetch rover,
[00:01:52.720 --> 00:01:57.920]   which is more of a couple of tricycle size rover that has to drive farther and faster because it's
[00:01:57.920 --> 00:02:02.800]   going to have to go pick up all those tubules, make it to a rendezvous point, take those tubules,
[00:02:02.800 --> 00:02:07.440]   fly them up out of the Martian atmosphere into space to a spacecraft, and then take that
[00:02:07.440 --> 00:02:11.680]   spacecraft back to earth. Yes, that's ambitious, but we're, you know, NASA JPL.
[00:02:11.680 --> 00:02:16.080]   Thanks for watching this clip. You can see the full episode on our YouTube channel.
[00:02:16.640 --> 00:02:22.640]   And you can join our friendly Slack community with over 4,000 ML engineers to participate in
[00:02:22.640 --> 00:02:27.440]   paper reading groups, AMAs, and other fun events.

