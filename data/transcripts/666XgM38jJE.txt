
[00:00:00.000 --> 00:00:04.160]   Going back to Gemini, I'm curious what the bottlenecks were in the development.
[00:00:04.160 --> 00:00:07.120]   Like, why not make it immediately one order of magnitude bigger?
[00:00:07.120 --> 00:00:09.280]   Well, look, first of all, there are practical limits.
[00:00:09.280 --> 00:00:12.640]   How much compute can you actually fit in one data center?
[00:00:12.640 --> 00:00:16.160]   And actually, you know, you're bumping up against very interesting
[00:00:16.160 --> 00:00:18.560]   distributed computing kind of challenges, right?
[00:00:18.560 --> 00:00:21.440]   Fortunately, we have some of the best people in the world on those challenges.
[00:00:21.440 --> 00:00:25.040]   And, you know, cross data center training, all these kinds of things.
[00:00:25.040 --> 00:00:26.880]   Very interesting challenges, hardware challenges.
[00:00:26.880 --> 00:00:30.720]   And we have our TPUs and so on that we're building and designing all the time,
[00:00:30.720 --> 00:00:32.320]   as well as using GPUs.
[00:00:32.320 --> 00:00:34.640]   And so there's all of that.
[00:00:34.640 --> 00:00:37.520]   And then you also have to, the scaling laws, you know,
[00:00:37.520 --> 00:00:39.040]   they don't just work by magic.
[00:00:39.040 --> 00:00:42.320]   You sort of, you still need to scale up the hyperparameters and
[00:00:42.320 --> 00:00:45.120]   various innovations are going in all the time with each new scale.
[00:00:45.120 --> 00:00:47.760]   It's not just about repeating the same recipe.
[00:00:47.760 --> 00:00:50.320]   At each new scale, you have to adjust the recipe.
[00:00:50.320 --> 00:00:52.720]   And that's a bit of an art form in a way.
[00:00:52.720 --> 00:00:55.120]   And you have to sort of almost get new data points.
[00:00:55.120 --> 00:00:58.400]   If you try and extend your predictions, extrapolate them,
[00:00:58.400 --> 00:01:02.240]   say several orders of magnitude out, sometimes they don't hold anymore, right?
[00:01:02.240 --> 00:01:07.280]   Because new capabilities, they can be step functions in terms of new capabilities.
[00:01:07.280 --> 00:01:11.040]   And some things hold and other things don't.
[00:01:11.040 --> 00:01:15.600]   So often you do need those intermediate data points actually to correct
[00:01:15.600 --> 00:01:18.720]   some of your hyperparameter optimization and other things.
[00:01:18.720 --> 00:01:21.200]   So the scaling law continues to be true.
[00:01:22.960 --> 00:01:26.480]   So there's sort of various practical limitations onto that.
[00:01:26.480 --> 00:01:30.560]   So, you know, kind of one order of magnitude is about probably the
[00:01:30.560 --> 00:01:33.120]   maximum that you want to carry on.
[00:01:33.120 --> 00:01:35.600]   You want to sort of do between each era.
[00:01:35.600 --> 00:01:37.200]   - Oh, that's so fascinating.
[00:01:37.200 --> 00:01:38.720]   You know, in the GPT-4 technical report,
[00:01:38.720 --> 00:01:41.120]   they say that they were able to predict the training loss,
[00:01:41.120 --> 00:01:45.680]   you know, tens of thousands of times less compute than GPT-4.
[00:01:45.680 --> 00:01:46.480]   They could see the curve.
[00:01:46.480 --> 00:01:49.440]   But at the point you're making is that the actual capabilities that loss implies
[00:01:49.440 --> 00:01:50.800]   may not be so clear.
[00:01:50.800 --> 00:01:53.440]   - Yeah, the downstream capabilities sometimes don't follow from the...
[00:01:53.440 --> 00:01:57.440]   You can often predict the core metrics like training loss or something like that.
[00:01:57.440 --> 00:02:01.360]   But then it doesn't actually translate into MMLU or math
[00:02:01.360 --> 00:02:04.880]   or some other actual capability that you care about.
[00:02:04.880 --> 00:02:07.840]   They're not necessarily linear all the time.
[00:02:07.840 --> 00:02:11.280]   I think we've got to push scaling as hard as we can.
[00:02:11.280 --> 00:02:12.640]   And that's what we're doing here.
[00:02:12.640 --> 00:02:14.240]   And, you know, it's an empirical question
[00:02:14.240 --> 00:02:16.960]   whether that will hit an asymptote or a brick wall.
[00:02:16.960 --> 00:02:19.280]   And there are, you know, different people argue about that.
[00:02:19.280 --> 00:02:20.880]   But actually, I think we should just test it.
[00:02:20.880 --> 00:02:21.840]   I think no one knows.
[00:02:21.840 --> 00:02:28.000]   But in the meantime, we should also double down on innovation and invention.
[00:02:28.000 --> 00:02:31.360]   And this is something that Google Research and DeepMind
[00:02:31.360 --> 00:02:33.840]   and Google Brain have, you know,
[00:02:33.840 --> 00:02:36.000]   we've pioneered many, many things over the last decade.
[00:02:36.000 --> 00:02:37.840]   That's something that's our bread and butter.
[00:02:37.840 --> 00:02:40.480]   And, you know, you can think of half our effort
[00:02:40.480 --> 00:02:42.160]   is to do with scaling and half our effort
[00:02:42.160 --> 00:02:44.960]   is to do with inventing the next architectures,
[00:02:44.960 --> 00:02:46.480]   the next algorithms that will be needed.
[00:02:47.280 --> 00:02:50.160]   Knowing that you've got this scaled, larger and larger model
[00:02:50.160 --> 00:02:51.120]   coming along the lines.
[00:02:51.120 --> 00:02:53.120]   - What's been the biggest surprise to you
[00:02:53.120 --> 00:02:55.520]   if you go back to yourself in 2010,
[00:02:55.520 --> 00:02:56.640]   when you were starting DeepMind
[00:02:56.640 --> 00:02:58.640]   in terms of what AI progress has looked like?
[00:02:58.640 --> 00:03:00.000]   Did you anticipate back then
[00:03:00.000 --> 00:03:02.720]   that it would in some large sense amount to spend,
[00:03:02.720 --> 00:03:04.480]   you know, dumping billions of dollars into these models?
[00:03:04.480 --> 00:03:05.920]   Or did you have a different sense of what it would look like?
[00:03:05.920 --> 00:03:07.760]   - We thought that, and actually, you know, if you,
[00:03:07.760 --> 00:03:09.760]   I know you've interviewed my colleague, Shane,
[00:03:09.760 --> 00:03:14.640]   and he always thought that in terms of like compute curves
[00:03:14.640 --> 00:03:17.360]   and then maybe comparing roughly to like the brain
[00:03:17.360 --> 00:03:19.840]   and how many neurons and synapses there are very loosely.
[00:03:19.840 --> 00:03:21.360]   But we're actually, interestingly,
[00:03:21.360 --> 00:03:22.560]   in that kind of regime now,
[00:03:22.560 --> 00:03:24.560]   roughly in the right order of magnitude of,
[00:03:24.560 --> 00:03:26.160]   you know, number of synapses in the brain
[00:03:26.160 --> 00:03:28.720]   and the sort of compute that we have.
[00:03:28.720 --> 00:03:30.960]   But I think more fundamentally, you know,
[00:03:30.960 --> 00:03:33.360]   we always thought that we bet
[00:03:33.360 --> 00:03:36.320]   on generality and learning, right?
[00:03:36.320 --> 00:03:38.320]   So those were always at the core
[00:03:38.320 --> 00:03:39.760]   of any technique we would use.
[00:03:39.760 --> 00:03:42.000]   That's why we triangulated on reinforcement learning
[00:03:42.000 --> 00:03:44.800]   and search and deep learning, right?
[00:03:44.800 --> 00:03:48.800]   As three types of algorithms that would scale
[00:03:48.800 --> 00:03:51.600]   and would be very general
[00:03:51.600 --> 00:03:55.040]   and not require a lot of handcrafted human priors,
[00:03:55.040 --> 00:03:57.280]   which we thought was the sort of failure mode
[00:03:57.280 --> 00:04:00.960]   really of the efforts to build AI in the '90s, right?
[00:04:00.960 --> 00:04:03.520]   Places like MIT where there were very, you know,
[00:04:03.520 --> 00:04:06.240]   logic-based systems, expert systems, you know,
[00:04:06.240 --> 00:04:09.520]   masses of hand-coded, handcrafted human information
[00:04:09.520 --> 00:04:11.040]   going into that turned out to be wrong
[00:04:11.040 --> 00:04:12.400]   or too rigid.
[00:04:12.400 --> 00:04:13.920]   So we wanted to move away from that.
[00:04:13.920 --> 00:04:15.840]   I think we spotted that trend early
[00:04:15.840 --> 00:04:18.800]   and, you know, and obviously we use games
[00:04:18.800 --> 00:04:21.120]   as our proving ground and we did very well with that.
[00:04:21.120 --> 00:04:22.320]   You know, things like AlphaGo, I think,
[00:04:22.320 --> 00:04:24.960]   was a big moment for inspiring many others to think,
[00:04:24.960 --> 00:04:27.680]   "Oh, actually these systems are ready to scale."
[00:04:27.680 --> 00:04:29.840]   And then of course, with the advent of transformers
[00:04:29.840 --> 00:04:31.280]   invented by our colleagues at Google,
[00:04:31.280 --> 00:04:32.800]   you know, research and brain,
[00:04:32.800 --> 00:04:36.000]   that was then, you know, the type of deep learning
[00:04:36.000 --> 00:04:37.280]   that allowed us to ingest
[00:04:37.280 --> 00:04:39.760]   masses of amounts of information.
[00:04:39.760 --> 00:04:41.520]   And that, of course, has really
[00:04:41.520 --> 00:04:42.960]   turbocharged where we are today.
[00:04:42.960 --> 00:04:44.880]   So I think that's all part of the same lineage.
[00:04:44.880 --> 00:04:46.880]   You know, we couldn't have predicted
[00:04:46.880 --> 00:04:47.920]   every twist and turn there,
[00:04:47.920 --> 00:04:50.000]   but I think the general direction we were going in

