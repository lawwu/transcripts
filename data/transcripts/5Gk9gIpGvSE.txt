
[00:00:00.000 --> 00:00:01.440]   people all around the world,
[00:00:01.440 --> 00:00:03.940]   their lives are basically dependent on fossil fuels.
[00:00:03.940 --> 00:00:06.740]   And so the idea that we're gonna get people off
[00:00:06.740 --> 00:00:08.400]   by making it so expensive
[00:00:08.400 --> 00:00:11.840]   that it becomes impossible for them to live good lives
[00:00:11.840 --> 00:00:13.900]   is almost morally reprehensible.
[00:00:13.900 --> 00:00:16.540]   - People who have the most basic science literacy,
[00:00:16.540 --> 00:00:18.940]   like who know the most about greenhouse effect,
[00:00:18.940 --> 00:00:22.220]   they're at both ends of the spectrum of views on climate,
[00:00:22.220 --> 00:00:23.720]   dismissives and alarmed.
[00:00:23.720 --> 00:00:27.600]   - What is likely the worst effect of climate change?
[00:00:29.800 --> 00:00:32.520]   - The following is a conversation with Bjorn Lomborg
[00:00:32.520 --> 00:00:36.400]   and Andrew Refkin on the topic of climate change.
[00:00:36.400 --> 00:00:38.280]   It is framed as a debate,
[00:00:38.280 --> 00:00:41.380]   but with the goal of having a nuanced conversation,
[00:00:41.380 --> 00:00:44.680]   talking with each other, not at each other.
[00:00:44.680 --> 00:00:47.040]   I hope to continue having debates like these,
[00:00:47.040 --> 00:00:49.640]   including on controversial topics.
[00:00:49.640 --> 00:00:51.840]   I believe in the power of conversation
[00:00:51.840 --> 00:00:53.640]   to bring people together,
[00:00:53.640 --> 00:00:56.400]   not to convince one side or the other,
[00:00:56.400 --> 00:00:58.640]   but to enlighten both with the insights
[00:00:58.640 --> 00:01:00.180]   and wisdom that each hold.
[00:01:00.180 --> 00:01:02.940]   Bjorn Lomborg is the president
[00:01:02.940 --> 00:01:05.300]   of Copenhagen Consensus Think Tank
[00:01:05.300 --> 00:01:09.040]   and author of "False Alarm," "Cool It,"
[00:01:09.040 --> 00:01:12.120]   and "Skeptical Environmentalist."
[00:01:12.120 --> 00:01:14.600]   Please check out his work at lomborg.com
[00:01:14.600 --> 00:01:18.640]   that includes his books, articles, and other writing.
[00:01:18.640 --> 00:01:21.960]   Andrew Refkin is one of the most respected journalists
[00:01:21.960 --> 00:01:24.360]   in the world on the topic of climate.
[00:01:24.360 --> 00:01:26.820]   He's been writing about global environmental change
[00:01:26.820 --> 00:01:29.560]   and risk for more than 30 years,
[00:01:29.560 --> 00:01:32.280]   20 of it at the New York Times.
[00:01:32.280 --> 00:01:35.520]   Please check out his work in the Linktree
[00:01:35.520 --> 00:01:39.480]   that includes his books, articles, and other writing.
[00:01:39.480 --> 00:01:41.480]   This is the Lex Friedman Podcast.
[00:01:41.480 --> 00:01:43.680]   To support it, please check out our sponsors
[00:01:43.680 --> 00:01:45.000]   in the description.
[00:01:45.000 --> 00:01:46.520]   And now, dear friends,
[00:01:46.520 --> 00:01:50.260]   here's Bjorn Lomborg and Andrew Refkin.
[00:01:50.260 --> 00:01:54.680]   There's a spectrum of belief on the topic of climate change,
[00:01:54.680 --> 00:01:56.700]   and the landscape of that spectrum
[00:01:56.700 --> 00:01:59.580]   has probably changed over several decades.
[00:01:59.580 --> 00:02:00.940]   On one extreme, there's a belief
[00:02:00.940 --> 00:02:02.960]   that climate change is a hoax,
[00:02:02.960 --> 00:02:05.540]   it's not human-caused.
[00:02:05.540 --> 00:02:06.500]   To pile on top of that,
[00:02:06.500 --> 00:02:07.940]   there's a belief that institutions,
[00:02:07.940 --> 00:02:10.340]   scientific, political, the media,
[00:02:10.340 --> 00:02:14.980]   are corrupt and are kind of constructing this fabrication.
[00:02:14.980 --> 00:02:15.820]   That's one extreme.
[00:02:15.820 --> 00:02:17.860]   And then the other extreme,
[00:02:17.860 --> 00:02:22.140]   there's a level of alarmism
[00:02:22.140 --> 00:02:25.220]   about the catastrophic impacts of climate change
[00:02:25.220 --> 00:02:29.820]   that lead to the extinction of human civilization.
[00:02:29.820 --> 00:02:33.700]   So not just economic costs, hardship, suffering,
[00:02:33.700 --> 00:02:37.380]   but literally the destruction of the human species
[00:02:37.380 --> 00:02:38.300]   in the short term.
[00:02:38.300 --> 00:02:39.820]   Okay, so that's the spectrum.
[00:02:39.820 --> 00:02:43.220]   And I would love to find the center,
[00:02:43.220 --> 00:02:44.420]   and my sense is,
[00:02:44.420 --> 00:02:46.780]   and the reason I wanted to talk to the two of you,
[00:02:46.780 --> 00:02:51.780]   aside from the humility with which you approach this topic,
[00:02:52.220 --> 00:02:54.480]   is I feel like you're close to the center
[00:02:54.480 --> 00:02:57.860]   and are on different sides of that center,
[00:02:57.860 --> 00:02:59.620]   if it's possible to define the center.
[00:02:59.620 --> 00:03:01.500]   Like there is a political center
[00:03:01.500 --> 00:03:03.700]   for center left and center right.
[00:03:03.700 --> 00:03:05.380]   Of course, it's very difficult to define,
[00:03:05.380 --> 00:03:08.140]   but can you help me define what the extremes are again,
[00:03:08.140 --> 00:03:09.540]   as they have changed over the years,
[00:03:09.540 --> 00:03:10.620]   what they are today,
[00:03:10.620 --> 00:03:12.120]   and where's the center?
[00:03:12.120 --> 00:03:13.060]   - Oh boy.
[00:03:13.060 --> 00:03:14.780]   Well, in a way, on this issue,
[00:03:14.780 --> 00:03:15.940]   I think there is no center,
[00:03:15.940 --> 00:03:18.980]   except in this, if you're looking on social media
[00:03:18.980 --> 00:03:21.340]   or if you're looking on TV,
[00:03:21.340 --> 00:03:23.060]   there are people who are trying to fabricate the idea
[00:03:23.060 --> 00:03:24.500]   there's a single question.
[00:03:24.500 --> 00:03:27.460]   And that's the first mistake.
[00:03:27.460 --> 00:03:31.460]   We are developing a new relationship with the climate system
[00:03:31.460 --> 00:03:35.380]   and we're rethinking our energy systems.
[00:03:35.380 --> 00:03:39.380]   And those are very disconnected in so many ways,
[00:03:39.380 --> 00:03:40.940]   they connect around climate change.
[00:03:40.940 --> 00:03:44.060]   But the first way to me to overcome this idea
[00:03:44.060 --> 00:03:48.340]   of there is this polarized universe around this issue
[00:03:48.340 --> 00:03:50.420]   is to step back and say,
[00:03:50.420 --> 00:03:51.740]   well, what is this actually?
[00:03:51.740 --> 00:03:53.860]   And when you do, you realize it's kind of
[00:03:53.860 --> 00:03:56.940]   an uncomfortable collision between old energy norms
[00:03:56.940 --> 00:04:01.100]   and a growing awareness of how the planet works.
[00:04:01.100 --> 00:04:03.460]   That if you keep adding gases that are invisible,
[00:04:03.460 --> 00:04:05.140]   it's the bubbles in beer.
[00:04:05.140 --> 00:04:06.680]   If you keep adding that to the atmosphere,
[00:04:06.680 --> 00:04:09.020]   because it accumulates, that will change everything,
[00:04:09.020 --> 00:04:10.780]   is changing everything for thousands of years,
[00:04:10.780 --> 00:04:11.820]   it's already happening.
[00:04:11.820 --> 00:04:13.340]   - What do you mean by bubbles in beer?
[00:04:13.340 --> 00:04:16.620]   - CO2, carbon dioxide, the main greenhouse gas.
[00:04:16.620 --> 00:04:17.880]   - Why beer?
[00:04:17.880 --> 00:04:19.140]   - Well, 'cause I like beer.
[00:04:19.140 --> 00:04:20.460]   - It's also in Coca-Cola,
[00:04:20.460 --> 00:04:22.220]   we were talking about Cola before.
[00:04:22.220 --> 00:04:24.500]   And so it's innocuous.
[00:04:24.500 --> 00:04:27.060]   We grew up with this idea is CO2,
[00:04:27.060 --> 00:04:29.600]   unless you're trapped in a room suffocating,
[00:04:29.600 --> 00:04:31.860]   is an innocuous gas.
[00:04:31.860 --> 00:04:34.940]   It's plant food, it's beer bubbles.
[00:04:34.940 --> 00:04:39.580]   And the idea we can swiftly transition to a world
[00:04:39.580 --> 00:04:43.600]   where that gas is a pollutant, regulated,
[00:04:43.600 --> 00:04:48.260]   tamped down from the top is fantastical.
[00:04:48.260 --> 00:04:50.740]   Having looked at this for 35 years,
[00:04:50.740 --> 00:04:52.860]   I brought along one of my tokens.
[00:04:52.860 --> 00:04:56.620]   This is my 1988 cover story on global warming.
[00:04:56.620 --> 00:05:00.380]   - The Greenhouse Effect, this cover, 1988.
[00:05:00.380 --> 00:05:03.060]   - Jim Hansen, the famous American climate scientist,
[00:05:03.060 --> 00:05:05.500]   really he stimulated this article
[00:05:05.500 --> 00:05:08.280]   by doing this dramatic testimony
[00:05:08.280 --> 00:05:10.100]   in a Senate committee that summer,
[00:05:10.100 --> 00:05:12.060]   in May, actually, spring, late spring.
[00:05:12.060 --> 00:05:14.960]   It was a hot day and it got headlines
[00:05:14.960 --> 00:05:16.420]   and this was the result.
[00:05:16.420 --> 00:05:17.700]   But it's complicated.
[00:05:17.700 --> 00:05:19.980]   Look what we were selling on the back cover.
[00:05:19.980 --> 00:05:21.900]   - What you see is when you get tobacco--
[00:05:21.900 --> 00:05:22.740]   - Cigarettes.
[00:05:22.740 --> 00:05:24.420]   - Tobacco, yeah.
[00:05:24.420 --> 00:05:26.300]   - You know, looking back at my own career
[00:05:26.300 --> 00:05:27.660]   on the climate question,
[00:05:27.660 --> 00:05:29.720]   it's no longer a belief fight over
[00:05:29.720 --> 00:05:30.940]   is global warming real or not.
[00:05:30.940 --> 00:05:32.860]   You say, well, what kind of energy future do you want?
[00:05:32.860 --> 00:05:36.460]   That's a very different question than stop global warming.
[00:05:36.460 --> 00:05:40.900]   And when you look at climate, actually,
[00:05:40.900 --> 00:05:43.060]   I had this learning journey on my reporting
[00:05:43.060 --> 00:05:45.980]   where I started out with this
[00:05:45.980 --> 00:05:47.680]   as the definition of the problem.
[00:05:47.680 --> 00:05:52.220]   The '70s and '80s, pollution was changing things
[00:05:52.220 --> 00:05:53.600]   that were making things bad.
[00:05:53.600 --> 00:05:55.740]   - So really focusing in on the greenhouse effect
[00:05:55.740 --> 00:05:56.580]   and the pollution.
[00:05:56.580 --> 00:05:58.620]   - But what I missed, the big thing that I missed
[00:05:58.620 --> 00:06:00.740]   of the first 15 years of my reporting
[00:06:00.740 --> 00:06:04.140]   from 1988 through about 2007,
[00:06:04.140 --> 00:06:09.100]   when I was, that period I was at the New York Times
[00:06:09.100 --> 00:06:10.580]   in the middle there,
[00:06:10.580 --> 00:06:11.980]   was that we're building vulnerability
[00:06:11.980 --> 00:06:13.860]   to climate hazards at the same time.
[00:06:13.860 --> 00:06:15.780]   So climate is changing,
[00:06:15.780 --> 00:06:17.460]   but we're changing too.
[00:06:17.460 --> 00:06:21.580]   And where we are here in Austin, Texas is a great example.
[00:06:21.580 --> 00:06:26.500]   Flash Flood Alley, named in the 1920s, west of here.
[00:06:26.500 --> 00:06:28.140]   Everyone forgot about flash floods.
[00:06:28.140 --> 00:06:32.220]   Built these huge developments along these river basins
[00:06:32.220 --> 00:06:33.580]   that in one side starts saying,
[00:06:33.580 --> 00:06:35.180]   global warming, global warming,
[00:06:35.180 --> 00:06:38.100]   and the other side is not recognizing
[00:06:38.100 --> 00:06:41.920]   that we built willfully, greedily,
[00:06:43.540 --> 00:06:45.860]   vulnerability in places of utter hazard.
[00:06:45.860 --> 00:06:47.860]   Same things played out in Pakistan
[00:06:47.860 --> 00:06:49.280]   and in Fort Myers, Florida.
[00:06:49.280 --> 00:06:51.500]   And you start to understand
[00:06:51.500 --> 00:06:53.500]   that we're creating a landscape of risk
[00:06:53.500 --> 00:06:56.240]   as climate is changing,
[00:06:56.240 --> 00:06:59.380]   then it feels, oh my God, that's more complex, right?
[00:06:59.380 --> 00:07:01.100]   But it also gives you more action points.
[00:07:01.100 --> 00:07:03.780]   It's like, okay, well, we know how to design better.
[00:07:03.780 --> 00:07:07.900]   We know that today's coasts won't be tomorrow's coasts.
[00:07:07.900 --> 00:07:08.740]   Work with that.
[00:07:08.740 --> 00:07:11.700]   And then let's chart an energy future at the same time.
[00:07:11.700 --> 00:07:12.940]   So the story became so different.
[00:07:12.940 --> 00:07:16.900]   It didn't become like a story you could package
[00:07:16.900 --> 00:07:20.240]   into a magazine article or the like.
[00:07:20.240 --> 00:07:21.780]   And it just led me to a whole different way
[00:07:21.780 --> 00:07:24.460]   of even my journalism changed over time.
[00:07:24.460 --> 00:07:27.800]   So I don't fight the belief disbelief fight anymore.
[00:07:27.800 --> 00:07:30.780]   I think it's actually kind of a waste.
[00:07:30.780 --> 00:07:32.860]   It's a good way to start the discussion
[00:07:32.860 --> 00:07:34.320]   'cause that's where we're at.
[00:07:34.320 --> 00:07:38.180]   But this isn't about, to me, going forward from where we're at
[00:07:38.180 --> 00:07:41.740]   isn't about tipping that balance
[00:07:41.740 --> 00:07:44.820]   back toward the center so much as finding opportunities
[00:07:44.820 --> 00:07:46.900]   to just do something about this stuff.
[00:07:46.900 --> 00:07:47.820]   - What do you think, Bjorn?
[00:07:47.820 --> 00:07:51.460]   Do you agree that it's multiple questions in one big question?
[00:07:51.460 --> 00:07:53.020]   Do you think it's possible to define the center?
[00:07:53.020 --> 00:07:54.700]   Where is the center?
[00:07:54.700 --> 00:07:56.580]   - I think it's wonderful to hear Andy
[00:07:56.580 --> 00:07:59.420]   sort of unconstruct the whole conversation
[00:07:59.420 --> 00:08:01.740]   and say we should be worried about different things.
[00:08:01.740 --> 00:08:03.020]   And I think that's exactly,
[00:08:03.020 --> 00:08:05.300]   or we should be worried about things in a different way
[00:08:05.300 --> 00:08:08.360]   that makes it much more useful.
[00:08:08.360 --> 00:08:11.220]   And I think that's exactly the right way to think about it.
[00:08:11.220 --> 00:08:12.060]   On the other hand,
[00:08:12.060 --> 00:08:13.840]   that was also where you kind of ended,
[00:08:13.840 --> 00:08:16.560]   we are stuck in a place where this very much
[00:08:16.560 --> 00:08:18.260]   is the conversation right now.
[00:08:18.260 --> 00:08:21.500]   And so I think in one sense,
[00:08:21.500 --> 00:08:23.580]   certainly the people who used to say,
[00:08:23.580 --> 00:08:24.820]   "Oh, this is not happening."
[00:08:24.820 --> 00:08:27.540]   They're very, very small and diminishing crowd
[00:08:27.540 --> 00:08:28.800]   and certainly not right.
[00:08:28.800 --> 00:08:34.700]   But on the other hand, I think to an increasing extent,
[00:08:34.700 --> 00:08:37.340]   we've gotten into a world where a lot of people
[00:08:37.340 --> 00:08:40.740]   really think this is the end of times.
[00:08:40.740 --> 00:08:45.380]   If you, so the OECD did a new survey of all OECD countries
[00:08:45.380 --> 00:08:46.460]   and it's shocking.
[00:08:46.460 --> 00:08:50.260]   So it shows that 60% of all people in the OECD,
[00:08:50.260 --> 00:08:51.780]   so the rich world,
[00:08:51.780 --> 00:08:53.780]   believes that global warming will likely
[00:08:53.780 --> 00:08:57.780]   or very likely lead to the extinction of mankind.
[00:08:57.780 --> 00:09:02.300]   And that's scary in a very, very clear way
[00:09:02.300 --> 00:09:04.500]   because look, if this really is true,
[00:09:04.500 --> 00:09:08.380]   if global warming is this meteor hurtling towards earth
[00:09:08.380 --> 00:09:10.980]   and we're gonna be destroyed in 12 years
[00:09:10.980 --> 00:09:14.380]   or whatever the number is today,
[00:09:14.380 --> 00:09:16.560]   then clearly we should care about nothing else.
[00:09:16.560 --> 00:09:19.020]   We should just be focusing on making sure
[00:09:19.020 --> 00:09:20.820]   that that asteroid gets,
[00:09:20.820 --> 00:09:24.180]   we should send up Bruce Willis and get this done with.
[00:09:24.180 --> 00:09:26.300]   But that's not the way it is.
[00:09:26.300 --> 00:09:29.200]   This is not actually what the UN climate panel tells us
[00:09:29.200 --> 00:09:30.180]   or anything else.
[00:09:30.180 --> 00:09:34.100]   So I think it's not so much about arcing against the people
[00:09:34.100 --> 00:09:35.540]   who are saying it's a hoax.
[00:09:35.540 --> 00:09:36.880]   That's not really where I am.
[00:09:36.880 --> 00:09:38.460]   I don't think that's where Andy or really
[00:09:38.460 --> 00:09:40.020]   where the conversation is.
[00:09:40.020 --> 00:09:42.780]   But it is a question of sort of pulling people back
[00:09:42.780 --> 00:09:45.180]   from this end of the world conversation
[00:09:45.180 --> 00:09:47.380]   because it really skews our way
[00:09:47.380 --> 00:09:48.820]   that we think about problems.
[00:09:48.820 --> 00:09:51.380]   Also, if you really think this is the end of time
[00:09:51.380 --> 00:09:53.140]   and you only have 12 years,
[00:09:53.140 --> 00:09:57.860]   nothing that can only work in 13 years can be considered.
[00:09:57.860 --> 00:10:00.660]   And the reality of most of what we're talking about
[00:10:00.660 --> 00:10:02.540]   in climate and certainly our vulnerability,
[00:10:02.540 --> 00:10:04.300]   certainly our energy system
[00:10:04.300 --> 00:10:06.540]   is gonna be half to a full century.
[00:10:06.540 --> 00:10:08.740]   And so when you talk to people and say,
[00:10:08.740 --> 00:10:10.060]   well, but we're gonna, you know,
[00:10:10.060 --> 00:10:11.980]   we're really gonna go a lot more renewable
[00:10:11.980 --> 00:10:13.020]   in the next half century.
[00:10:13.020 --> 00:10:15.220]   They look at you and like, but that's what,
[00:10:15.220 --> 00:10:17.220]   38 years too late.
[00:10:17.220 --> 00:10:18.180]   And I get that.
[00:10:18.180 --> 00:10:21.300]   But so I think in your question,
[00:10:21.300 --> 00:10:23.020]   what I'm trying to do and I would imagine
[00:10:23.020 --> 00:10:24.460]   that's true for you as well,
[00:10:24.460 --> 00:10:27.500]   is to try to pull people away from this precipice
[00:10:27.500 --> 00:10:30.540]   and this end of the world and then open it up.
[00:10:30.540 --> 00:10:33.100]   And I think Andy did that really well by saying,
[00:10:33.100 --> 00:10:36.180]   look, there are so many different sub conversations
[00:10:36.180 --> 00:10:38.020]   and we need to have all of them
[00:10:38.020 --> 00:10:40.380]   and we need to be respectful of,
[00:10:40.380 --> 00:10:43.700]   some of these are right in the sort of standard media
[00:10:43.700 --> 00:10:46.320]   kind of way, but some of them are very, very wrong.
[00:10:46.320 --> 00:10:49.880]   And it actually means that we end up doing much less good,
[00:10:49.880 --> 00:10:52.620]   both on climate, but also on all the other problems
[00:10:52.620 --> 00:10:53.460]   the world faces.
[00:10:53.460 --> 00:10:55.580]   - Oh yeah, and it just empowers people too.
[00:10:55.580 --> 00:10:58.740]   Those who believe this then just sit back,
[00:10:58.740 --> 00:11:01.820]   even in Adam McKay's movie, the "Don't Look Up" movie,
[00:11:01.820 --> 00:11:03.460]   there was that sort of nihilist crowd
[00:11:03.460 --> 00:11:05.180]   for those who've seen it, who just say,
[00:11:05.180 --> 00:11:09.020]   you know, fuck this, and a lot of people have that,
[00:11:09.020 --> 00:11:10.220]   when something's too big,
[00:11:10.220 --> 00:11:14.580]   and it just paralyzes you,
[00:11:14.580 --> 00:11:16.900]   as opposed to giving you these action points.
[00:11:16.900 --> 00:11:20.540]   And the other thing is, I hate it when economists
[00:11:20.540 --> 00:11:22.140]   are right about stuff like the--
[00:11:22.140 --> 00:11:24.380]   (laughing)
[00:11:24.380 --> 00:11:25.420]   - It happens all that often, though.
[00:11:25.420 --> 00:11:27.260]   - No, no, there are these phrases,
[00:11:27.260 --> 00:11:30.220]   like I never knew the words path dependency
[00:11:30.220 --> 00:11:32.740]   until probably 10 years ago in my reporting.
[00:11:32.740 --> 00:11:35.420]   And it basically says you're in a system,
[00:11:35.420 --> 00:11:37.980]   the things around you, how we pass laws,
[00:11:37.980 --> 00:11:39.940]   the brokenness of the Senate, you know.
[00:11:39.940 --> 00:11:43.980]   We don't have a climate crisis in America,
[00:11:43.980 --> 00:11:45.900]   we have a decision crisis,
[00:11:45.900 --> 00:11:48.660]   as it comes to how the government works or doesn't work.
[00:11:48.660 --> 00:11:51.460]   But those big features of our landscape,
[00:11:51.460 --> 00:11:54.500]   it's path dependency.
[00:11:54.500 --> 00:11:56.820]   When you screw in a light bulb,
[00:11:56.820 --> 00:11:58.140]   even if it's an LED light bulb,
[00:11:58.140 --> 00:12:02.360]   it's going into a 113, 120-year-old fixture,
[00:12:02.360 --> 00:12:05.220]   because, and actually that fixture is almost designed,
[00:12:05.220 --> 00:12:07.660]   if you look at 19th century gas fixtures,
[00:12:07.660 --> 00:12:09.140]   they had this screw in thing.
[00:12:09.140 --> 00:12:11.380]   So we're on these long path dependencies
[00:12:11.380 --> 00:12:12.680]   when it comes to energy and stuff like that,
[00:12:12.680 --> 00:12:16.540]   that you don't just magically transition a car fleet.
[00:12:16.540 --> 00:12:18.540]   A car built today will last 40 years,
[00:12:18.540 --> 00:12:20.660]   it'll end up in Mexico, sold as a used car,
[00:12:20.660 --> 00:12:21.820]   et cetera, et cetera.
[00:12:21.820 --> 00:12:26.260]   And so there is no quick fix,
[00:12:26.260 --> 00:12:30.780]   even if we're true that things are coming to an end
[00:12:30.780 --> 00:12:32.360]   in 13 years or 12 years or eight years.
[00:12:32.360 --> 00:12:34.280]   - So most people don't believe
[00:12:34.280 --> 00:12:35.720]   that climate change is a hoax,
[00:12:35.720 --> 00:12:39.240]   so they believe that there is an increase,
[00:12:39.240 --> 00:12:41.360]   there's a global warming of a few degrees
[00:12:41.360 --> 00:12:43.000]   in the next century,
[00:12:43.000 --> 00:12:44.200]   and then maybe debate about
[00:12:44.200 --> 00:12:46.740]   what the number of the degrees is.
[00:12:46.740 --> 00:12:50.680]   And do most people believe that it's human caused
[00:12:50.680 --> 00:12:54.140]   at this time in this history
[00:12:54.140 --> 00:12:55.320]   of discussion of climate change?
[00:12:55.320 --> 00:12:57.240]   So is that the center still?
[00:12:57.240 --> 00:12:59.640]   Is there still debate on this?
[00:12:59.640 --> 00:13:02.380]   - Yale University, the climate communication group
[00:13:02.380 --> 00:13:06.920]   there for like 13 years has done this Six Americas study
[00:13:06.920 --> 00:13:09.700]   where they've charted pretty carefully
[00:13:09.700 --> 00:13:13.920]   in ways that I really find useful what people believe.
[00:13:13.920 --> 00:13:15.300]   And we could talk about the word belief
[00:13:15.300 --> 00:13:16.380]   in the context of science too,
[00:13:16.380 --> 00:13:19.440]   but and they've identified kind of six kinds of us.
[00:13:19.440 --> 00:13:22.480]   There's from dismissive to alarmed
[00:13:22.480 --> 00:13:24.200]   and with lots of bubbles in between.
[00:13:24.200 --> 00:13:25.700]   I think some of those bubbles in between
[00:13:25.700 --> 00:13:27.780]   are mostly disengaged people
[00:13:27.780 --> 00:13:29.480]   don't really deal with the issue.
[00:13:29.480 --> 00:13:32.660]   And they've shown a drift for sure.
[00:13:32.660 --> 00:13:36.420]   There's much more majority now at the alarmed
[00:13:36.420 --> 00:13:40.760]   or engaged bubbles than just the dismissive bubble.
[00:13:40.760 --> 00:13:42.540]   There's a durable like with vaccination
[00:13:42.540 --> 00:13:43.720]   and lots of other issues.
[00:13:43.720 --> 00:13:47.980]   There's a durable never anything belief group,
[00:13:47.980 --> 00:13:51.260]   but on the reality that humans are contributing
[00:13:51.260 --> 00:13:55.020]   to climate change, most Americans when you ask them,
[00:13:55.020 --> 00:13:57.820]   and it also depends on how you write your survey.
[00:13:57.820 --> 00:13:59.500]   Think there's a component.
[00:13:59.500 --> 00:14:01.780]   - I mean, when you ask around, I mean,
[00:14:01.780 --> 00:14:03.880]   and this is, if you hear the story
[00:14:03.880 --> 00:14:05.060]   from the media of 20 years,
[00:14:05.060 --> 00:14:06.760]   of course that's what you will believe.
[00:14:06.760 --> 00:14:09.220]   And it also happens to be true.
[00:14:09.220 --> 00:14:11.060]   That is what the science, I think,
[00:14:11.060 --> 00:14:12.420]   it's perhaps worth saying,
[00:14:12.420 --> 00:14:15.020]   and it's a little depressing that you always have to say,
[00:14:15.020 --> 00:14:16.560]   but I think it's worth saying that
[00:14:16.560 --> 00:14:19.420]   I think we both really do accept
[00:14:19.420 --> 00:14:21.420]   the climate panel science
[00:14:21.420 --> 00:14:23.740]   and there's absolutely global warming.
[00:14:23.740 --> 00:14:26.780]   It is an issue and it's probably just worthwhile
[00:14:26.780 --> 00:14:27.620]   to get it out of the way.
[00:14:27.620 --> 00:14:30.500]   - It's an issue and it's caused by humans.
[00:14:30.500 --> 00:14:32.020]   - It's caused by humans, yeah.
[00:14:32.020 --> 00:14:36.160]   But vulnerability, the losses that are driven
[00:14:36.160 --> 00:14:39.340]   by climate-related events still predominantly
[00:14:39.340 --> 00:14:42.260]   are caused by humans, but on the ground.
[00:14:42.260 --> 00:14:45.500]   It's where we build stuff, where we settle.
[00:14:45.500 --> 00:14:50.500]   Pakistan, in 1960, I just looked these data up,
[00:14:50.500 --> 00:14:52.740]   there were 40 million people in Pakistan.
[00:14:52.740 --> 00:14:54.940]   Today there are 225 million
[00:14:54.940 --> 00:14:56.820]   and a big chunk of them are still rural.
[00:14:56.820 --> 00:14:59.680]   They live in the floodplain of the amazing Indus River,
[00:14:59.680 --> 00:15:01.820]   which comes down from the Himalayas.
[00:15:01.820 --> 00:15:05.900]   Extraordinary 5,000 year history of agriculture there.
[00:15:05.900 --> 00:15:09.860]   But when you put 200 million people in harm's way,
[00:15:09.860 --> 00:15:11.220]   and this doesn't say anything about
[00:15:11.220 --> 00:15:13.020]   the bigger questions about,
[00:15:13.020 --> 00:15:15.620]   oh, shame on Pakistan for having more people.
[00:15:15.620 --> 00:15:19.220]   It just says the reality is the losses that we see
[00:15:19.220 --> 00:15:22.980]   in the news are, and the science finds this,
[00:15:22.980 --> 00:15:25.940]   even though there's a new weather attribution group,
[00:15:25.940 --> 00:15:28.900]   it's WXRisk on Twitter.
[00:15:28.900 --> 00:15:33.280]   This does pretty good work on how much of what just happened
[00:15:33.280 --> 00:15:36.060]   was some tweak in the storm from global warming,
[00:15:36.060 --> 00:15:38.240]   from CO2 changing weather.
[00:15:38.240 --> 00:15:42.420]   But, and the media glom onto that,
[00:15:42.420 --> 00:15:46.020]   as I did in the '80s, '90s, 2000s.
[00:15:47.000 --> 00:15:50.440]   But the reports also have a section on, by the way,
[00:15:50.440 --> 00:15:52.200]   the vulnerability that was built in this region
[00:15:52.200 --> 00:15:55.560]   was a big driver of loss.
[00:15:55.560 --> 00:15:58.000]   So discriminating between loss,
[00:15:58.000 --> 00:16:02.820]   change in what's happening on the ground,
[00:16:02.820 --> 00:16:05.160]   and change in the climate system,
[00:16:05.160 --> 00:16:07.440]   is never solely about CO2.
[00:16:07.440 --> 00:16:12.440]   In fact, Lawrence Bauer, B-O-U-W-E-R,
[00:16:14.840 --> 00:16:17.280]   I first wrote on his work in 2010 in the New York Times,
[00:16:17.280 --> 00:16:20.760]   and basically, in 2010, there was no sign in the data
[00:16:20.760 --> 00:16:23.380]   of climate change driving disasters.
[00:16:23.380 --> 00:16:27.080]   Climate change is up here, disasters are on the ground,
[00:16:27.080 --> 00:16:29.160]   they depend on how many people are in the way,
[00:16:29.160 --> 00:16:31.080]   how much stuff you built in the way.
[00:16:31.080 --> 00:16:32.880]   And so far, we've done so much of that,
[00:16:32.880 --> 00:16:35.920]   so fast in the 20th century, particularly,
[00:16:35.920 --> 00:16:38.120]   that it completely dominates, it makes it hard,
[00:16:38.120 --> 00:16:41.400]   impossible to discriminate how much of that disaster
[00:16:42.600 --> 00:16:47.600]   was from the change in weather from global warming.
[00:16:47.600 --> 00:16:53.120]   - So a function of greenhouse gases to human suffering
[00:16:53.120 --> 00:16:57.880]   is unclear.
[00:16:57.880 --> 00:17:00.520]   - And that's very much in our control, theoretically.
[00:17:00.520 --> 00:17:03.560]   - Right, the point, I think, is exactly right,
[00:17:03.560 --> 00:17:06.440]   that if you look at the Hurricane Ian
[00:17:06.440 --> 00:17:08.960]   that went through Florida, you have a situation
[00:17:08.960 --> 00:17:12.200]   where Florida went from, what, 600,000 houses
[00:17:12.200 --> 00:17:17.200]   in 1940 to 17 million houses,
[00:17:17.200 --> 00:17:21.580]   sorry, 10 million houses, so 17 times more,
[00:17:21.580 --> 00:17:24.240]   over, what, a period of 80 years?
[00:17:24.240 --> 00:17:25.920]   Of course you're gonna have, what?
[00:17:25.920 --> 00:17:26.760]   - Yeah, yeah, yeah.
[00:17:26.760 --> 00:17:28.640]   - You're gonna have lots more damage,
[00:17:28.640 --> 00:17:30.520]   and many of these houses now have been built
[00:17:30.520 --> 00:17:33.480]   on places where you probably shouldn't be building.
[00:17:33.480 --> 00:17:37.200]   And so I think a lot of scientists are very focused
[00:17:37.200 --> 00:17:40.280]   on saying, can we measure whether global warming
[00:17:40.280 --> 00:17:43.320]   had an impact, which is an interesting science question.
[00:17:43.320 --> 00:17:46.960]   I think it's very implausible that eventually
[00:17:46.960 --> 00:17:48.960]   we won't be able to say it has an impact.
[00:17:48.960 --> 00:17:51.040]   But the real question, it seems to me,
[00:17:51.040 --> 00:17:53.360]   is if we actually wanna make sure that people
[00:17:53.360 --> 00:17:54.900]   are less harmed in the future,
[00:17:54.900 --> 00:17:58.280]   what are the levers that we can control?
[00:17:58.280 --> 00:18:01.040]   And it turns out that the CO2 lever,
[00:18:01.040 --> 00:18:03.720]   doing something about climate, is an incredibly
[00:18:03.720 --> 00:18:06.240]   difficult and slightly inefficient way
[00:18:06.240 --> 00:18:08.280]   of trying to help these people in the future,
[00:18:08.280 --> 00:18:11.180]   whereas, of course, zoning, making sure that you have
[00:18:11.180 --> 00:18:16.180]   better housing rules, what is it, regulations,
[00:18:16.180 --> 00:18:19.100]   that you maybe don't have people building
[00:18:19.100 --> 00:18:21.000]   in the flash flood, what was it called?
[00:18:21.000 --> 00:18:21.840]   - Flash flood alley.
[00:18:21.840 --> 00:18:23.280]   - Flash flood alley.
[00:18:23.280 --> 00:18:27.000]   It's just simple stuff, and because we're so focused
[00:18:27.000 --> 00:18:32.000]   on this one issue, it almost feels sacrilegious
[00:18:32.000 --> 00:18:35.180]   to talk about these other things that are much more
[00:18:35.180 --> 00:18:37.360]   in our power and that we can do something about
[00:18:37.360 --> 00:18:39.680]   much quicker and that would help a lot more people.
[00:18:39.680 --> 00:18:42.480]   So I think this is gonna be a large part
[00:18:42.480 --> 00:18:44.400]   of the whole conversation.
[00:18:44.400 --> 00:18:47.080]   Yes, climate is a problem, but it's not the only problem.
[00:18:47.080 --> 00:18:49.240]   And there are many other things where we can actually
[00:18:49.240 --> 00:18:52.100]   have a much, much bigger impact at much lower cost.
[00:18:52.100 --> 00:18:53.760]   Maybe we should also remember those.
[00:18:53.760 --> 00:18:58.680]   - Can you still man the case of Greta,
[00:18:58.680 --> 00:19:03.140]   who's a representative of alarmism,
[00:19:04.160 --> 00:19:08.200]   that we need that kind of level of alarmism
[00:19:08.200 --> 00:19:10.360]   for people to pay attention and to think
[00:19:10.360 --> 00:19:11.840]   about climate change?
[00:19:11.840 --> 00:19:16.840]   So you said the singular view is not the correct way
[00:19:16.840 --> 00:19:21.440]   to look at climate change, just the emissions.
[00:19:21.440 --> 00:19:25.920]   But for us to have a discussion, shouldn't there be
[00:19:25.920 --> 00:19:30.760]   somebody who's really raising the concern?
[00:19:30.760 --> 00:19:33.720]   Can you still man the case for alarmism, essentially,
[00:19:33.720 --> 00:19:36.620]   or is there a better term than alarmism?
[00:19:36.620 --> 00:19:42.500]   Communication of like, holy shit,
[00:19:42.500 --> 00:19:44.760]   we should be thinking about this.
[00:19:44.760 --> 00:19:48.440]   - So I totally understand why Greta Thunberg
[00:19:48.440 --> 00:19:49.640]   is doing what she's doing.
[00:19:49.640 --> 00:19:53.560]   I have great respect for her because I look at a lot
[00:19:53.560 --> 00:19:56.680]   of kids growing up and they're basically being told,
[00:19:56.680 --> 00:19:58.880]   you're not gonna reach adulthood, or at least not,
[00:19:58.880 --> 00:20:01.720]   you're not gonna get very far into adulthood.
[00:20:01.720 --> 00:20:05.120]   And that, of course, this is the meteor hurtling
[00:20:05.120 --> 00:20:07.320]   towards Earth, and then this is the only thing
[00:20:07.320 --> 00:20:08.720]   we should be focusing on.
[00:20:08.720 --> 00:20:10.920]   I understand why she's making that argument.
[00:20:10.920 --> 00:20:14.340]   I think it's, at the end of the day, it's incorrect,
[00:20:14.340 --> 00:20:16.680]   and I'm sure we'll get around to talking about that.
[00:20:16.680 --> 00:20:18.600]   And one of the things is, of course,
[00:20:18.600 --> 00:20:22.200]   that her whole generation, I can understand
[00:20:22.200 --> 00:20:25.040]   why they're saying, if we're gonna be dead in 12 years,
[00:20:25.040 --> 00:20:26.560]   why would I wanna study?
[00:20:26.560 --> 00:20:28.640]   Why would I really care about anything?
[00:20:28.640 --> 00:20:32.280]   So I totally want to sort of pull Greta and many others
[00:20:32.280 --> 00:20:35.080]   out of this end of the world fear,
[00:20:35.080 --> 00:20:37.160]   but I totally get why she's doing it.
[00:20:37.160 --> 00:20:39.080]   I think she's done a service in the sense
[00:20:39.080 --> 00:20:41.760]   that she's gotten more people to talk about climate,
[00:20:41.760 --> 00:20:44.960]   and that's good because we need to have this discussion.
[00:20:44.960 --> 00:20:48.460]   I think it's unfortunate, and this is just what happens
[00:20:48.460 --> 00:20:51.800]   in almost all policy discussions, that they end up being
[00:20:51.800 --> 00:20:54.780]   sort of discussions from the extreme groups,
[00:20:54.780 --> 00:20:57.120]   because it's just more fun on media
[00:20:57.120 --> 00:20:59.680]   to have sort of the total deniers
[00:20:59.680 --> 00:21:02.540]   and the people who say, we're gonna die tomorrow,
[00:21:02.540 --> 00:21:04.320]   and it sort of becomes that discussion.
[00:21:04.320 --> 00:21:06.920]   It's more sort of a mud wrestling fight.
[00:21:06.920 --> 00:21:09.600]   - So would you think the mud wrestling fight is not useful
[00:21:09.600 --> 00:21:11.680]   or is useful for communication,
[00:21:11.680 --> 00:21:14.200]   for effective science communication,
[00:21:14.200 --> 00:21:16.360]   on one of the platforms that you're a fan of,
[00:21:16.360 --> 00:21:17.720]   which is Twitter?
[00:21:17.720 --> 00:21:21.740]   - Yeah, I wrote a piece recently in my Sustain What column
[00:21:21.740 --> 00:21:25.680]   saying, if you go on there for the entertainment value
[00:21:25.680 --> 00:21:30.120]   of seeing those knockdown fights, I guess that's useful,
[00:21:30.120 --> 00:21:31.880]   if that's what you're looking for.
[00:21:31.880 --> 00:21:34.200]   The thing I found Twitter invaluable for,
[00:21:34.200 --> 00:21:37.260]   but it's a practice.
[00:21:37.260 --> 00:21:39.300]   It's just like the workouts you do,
[00:21:39.300 --> 00:21:44.140]   or it's how do I put this tool to use today,
[00:21:44.140 --> 00:21:49.140]   thinking about energy action in poor communities?
[00:21:49.140 --> 00:21:51.880]   How do I put this tool today, learning about
[00:21:51.880 --> 00:21:54.640]   what really happened with Ian the hurricane,
[00:21:54.640 --> 00:21:59.520]   who was most at risk, and how would you build forward better?
[00:21:59.520 --> 00:22:00.560]   I hate build back.
[00:22:00.560 --> 00:22:03.440]   Or you can go there and just watch it
[00:22:03.440 --> 00:22:04.600]   as an entertainment value.
[00:22:04.600 --> 00:22:07.040]   That's not gonna get the world anywhere.
[00:22:07.040 --> 00:22:10.120]   - You don't think entertainment,
[00:22:10.120 --> 00:22:11.800]   I wouldn't call it entertainment,
[00:22:11.800 --> 00:22:14.480]   but giving voice to the extremes
[00:22:14.480 --> 00:22:16.680]   isn't a productive way forward.
[00:22:16.680 --> 00:22:20.600]   It seems to, to push back against the main narrative,
[00:22:20.600 --> 00:22:22.880]   it seems to work pretty well in the American system.
[00:22:22.880 --> 00:22:25.880]   We think politics is totally broken,
[00:22:25.880 --> 00:22:29.200]   but maybe that works, that oscillation back and forth.
[00:22:29.200 --> 00:22:31.640]   You need a Greta, and you need somebody
[00:22:31.640 --> 00:22:34.720]   that pushes back against the Greta to get everybody's,
[00:22:34.720 --> 00:22:38.080]   just to get everybody's attention.
[00:22:38.080 --> 00:22:43.080]   The fun of battle over time creates progress.
[00:22:43.080 --> 00:22:46.100]   - Well, and this gets to the, you know,
[00:22:46.100 --> 00:22:48.160]   people who focus on communication science,
[00:22:48.160 --> 00:22:50.460]   I'm not a scientist, I write about this stuff.
[00:22:51.360 --> 00:22:55.120]   If you're gonna try to prod someone with a warning,
[00:22:55.120 --> 00:22:57.760]   like, this is three years apart.
[00:22:57.760 --> 00:22:59.000]   Nuclear winter.
[00:22:59.000 --> 00:23:00.600]   - Nuclear winter, we'll talk about that.
[00:23:00.600 --> 00:23:02.320]   - Global warming, well, yeah, we'll talk about it.
[00:23:02.320 --> 00:23:04.160]   But look at that, you know, this is three years apart
[00:23:04.160 --> 00:23:05.560]   in the covers of a magazine.
[00:23:05.560 --> 00:23:08.920]   But then you have to say to what end,
[00:23:08.920 --> 00:23:13.200]   if you're not directing people to a basket of things to do.
[00:23:13.200 --> 00:23:15.400]   And if you want political change,
[00:23:15.400 --> 00:23:18.000]   then it would be to support a politician.
[00:23:18.000 --> 00:23:20.920]   If you want energy access, it would be to look
[00:23:20.920 --> 00:23:25.920]   at this $370 billion the American government
[00:23:25.920 --> 00:23:27.760]   just put into play on climate and say,
[00:23:27.760 --> 00:23:30.140]   well, how can my community benefit from that?
[00:23:30.140 --> 00:23:31.720]   And I've been told over and over again
[00:23:31.720 --> 00:23:34.360]   by people in government, Jigar Shah,
[00:23:34.360 --> 00:23:37.640]   who heads this giant loan program, the energy department,
[00:23:37.640 --> 00:23:40.620]   he says, what I need now is like 19,500 people
[00:23:40.620 --> 00:23:42.520]   who are worried about climate change.
[00:23:42.520 --> 00:23:45.060]   Maybe because Greta got them worried.
[00:23:45.060 --> 00:23:46.960]   But here's the thing you could do,
[00:23:46.960 --> 00:23:48.800]   you can connect your local government right now
[00:23:48.800 --> 00:23:50.600]   with these multimillion dollar loans
[00:23:50.600 --> 00:23:53.800]   so you can have electric buses instead of diesel buses.
[00:23:53.800 --> 00:23:55.280]   And that's an action pathway.
[00:23:55.280 --> 00:23:59.060]   So without, so you know, alarm for the sake
[00:23:59.060 --> 00:24:02.720]   of getting attention or clicks,
[00:24:02.720 --> 00:24:07.720]   to me is not any more valuable than watching an action movie.
[00:24:07.720 --> 00:24:10.680]   - And again, I think also it very easily ends up
[00:24:10.680 --> 00:24:12.400]   sort of skewing our conversation
[00:24:12.400 --> 00:24:15.280]   about what are the actual solutions.
[00:24:15.280 --> 00:24:17.880]   You know, because yes, it's great to get rid
[00:24:17.880 --> 00:24:20.520]   of the diesel bus, but probably not for the reason
[00:24:20.520 --> 00:24:22.360]   people think, it's because diesel buses
[00:24:22.360 --> 00:24:26.400]   are really polluting in the air pollution sense.
[00:24:26.400 --> 00:24:27.240]   - Right, right, right.
[00:24:27.240 --> 00:24:29.960]   - And that is why you should get rid of them.
[00:24:29.960 --> 00:24:32.520]   And again, if you really wanted to help people,
[00:24:32.520 --> 00:24:34.400]   for instance, with hurricanes,
[00:24:34.400 --> 00:24:38.520]   you should have better rules and zoning in Florida,
[00:24:38.520 --> 00:24:40.280]   which is a very different outcome.
[00:24:40.280 --> 00:24:44.680]   So the mud wrestling fight also gets our attention
[00:24:44.680 --> 00:24:49.680]   diverted towards solutions that seem easy, fun,
[00:24:50.240 --> 00:24:52.680]   you know, sort of the electric car is a great example
[00:24:52.680 --> 00:24:54.560]   of this, the electric car has somehow become
[00:24:54.560 --> 00:24:58.320]   almost the sign that I care and I'm really gonna do
[00:24:58.320 --> 00:24:59.960]   something about climate.
[00:24:59.960 --> 00:25:01.960]   Of course, electric cars are great
[00:25:01.960 --> 00:25:04.000]   and they're probably part of the solution
[00:25:04.000 --> 00:25:06.840]   and they will actually cut carbon emissions somewhat,
[00:25:06.840 --> 00:25:09.560]   but they're an incredibly ineffective way
[00:25:09.560 --> 00:25:11.700]   of cutting carbon emissions right now.
[00:25:11.700 --> 00:25:14.760]   They're fairly expensive, you have to subsidize them a lot
[00:25:14.760 --> 00:25:17.000]   and they still emit quite a bit of CO2,
[00:25:17.000 --> 00:25:18.960]   both because the batteries get produced
[00:25:18.960 --> 00:25:21.320]   and because they usually run off power
[00:25:21.320 --> 00:25:22.600]   that's not-- - Strong words
[00:25:22.600 --> 00:25:24.560]   from your in-law, okay, let's go there,
[00:25:24.560 --> 00:25:27.560]   let's go electric cars, okay, educate us
[00:25:27.560 --> 00:25:30.360]   on the pros and cons of electric cars
[00:25:30.360 --> 00:25:33.520]   in this complex picture of climate change.
[00:25:33.520 --> 00:25:36.560]   What do you think of the efforts of Tesla and Elon Musk
[00:25:36.560 --> 00:25:40.760]   on pushing forward the electric car revolution?
[00:25:40.760 --> 00:25:43.040]   - So look, electric cars are great.
[00:25:43.040 --> 00:25:47.160]   I don't own a car, but you know, I've been driving--
[00:25:47.160 --> 00:25:48.960]   - There you go, socially signaling.
[00:25:48.960 --> 00:25:49.800]   (laughing)
[00:25:49.800 --> 00:25:51.560]   - Yeah, but yeah, I've--
[00:25:51.560 --> 00:25:52.960]   - We're in Texas, it's okay. - Well, I flew in here,
[00:25:52.960 --> 00:25:57.600]   so it's not like I'm in any way a virtuous guy on that path,
[00:25:57.600 --> 00:26:01.880]   but look, they're great cars and eventually,
[00:26:01.880 --> 00:26:04.680]   electric cars will take over a significant part
[00:26:04.680 --> 00:26:07.560]   of our driving and that's good
[00:26:07.560 --> 00:26:10.080]   because they're more effective,
[00:26:10.080 --> 00:26:12.320]   they're probably also gonna be cheaper.
[00:26:12.320 --> 00:26:15.000]   There's a lot of good opportunities with them,
[00:26:15.000 --> 00:26:16.960]   but it's because they've become reified
[00:26:16.960 --> 00:26:19.880]   as this thing that you do to fix climate
[00:26:19.880 --> 00:26:24.320]   and right now, they're not really all that great for climate.
[00:26:24.320 --> 00:26:28.720]   You need a lot of extra material into the batteries,
[00:26:28.720 --> 00:26:31.320]   which is very polluting and it's also,
[00:26:31.320 --> 00:26:32.880]   it emits a lot of CO2.
[00:26:32.880 --> 00:26:37.120]   A lot of electric cars are bought as second cars in the US.
[00:26:37.120 --> 00:26:38.840]   So we used to think that they were driven
[00:26:38.840 --> 00:26:41.440]   almost as much as a regular car.
[00:26:41.440 --> 00:26:43.800]   It turns out that they're more likely driven
[00:26:43.800 --> 00:26:47.080]   less than half as much as regular cars.
[00:26:47.080 --> 00:26:50.440]   So, 89% of all Americans who have an electric car
[00:26:50.440 --> 00:26:53.920]   also have a real car that they use for the long trips
[00:26:53.920 --> 00:26:56.200]   and then they use the electric car for short trips.
[00:26:56.200 --> 00:26:58.000]   - 89%? - 89, yeah.
[00:26:58.000 --> 00:27:02.480]   So the point here is that it's one of these things
[00:27:02.480 --> 00:27:05.200]   that become more sort of a virtue signaling thing.
[00:27:05.200 --> 00:27:09.000]   And again, look, once electric cars are sufficiently cheap
[00:27:09.000 --> 00:27:11.160]   that people will want to buy them, that's great
[00:27:11.160 --> 00:27:14.520]   and they will do some good for the environment.
[00:27:14.520 --> 00:27:16.720]   But in reality, what we should be focusing on
[00:27:16.720 --> 00:27:20.000]   is instead of getting people electric cars
[00:27:20.000 --> 00:27:22.800]   in rich countries, where because we're subsidizing
[00:27:22.800 --> 00:27:25.280]   typically in many countries,
[00:27:25.280 --> 00:27:28.200]   you actually get a sort of sliding scale.
[00:27:28.200 --> 00:27:30.880]   You get more subsidy, the more expensive it is.
[00:27:30.880 --> 00:27:33.120]   We sort of subsidize this to very rich people
[00:27:33.120 --> 00:27:37.600]   to buy very large Teslas to drive around in.
[00:27:37.600 --> 00:27:39.400]   Whereas what we should be focusing on
[00:27:39.400 --> 00:27:42.440]   is perhaps getting electric motorcycles
[00:27:42.440 --> 00:27:44.840]   in third world developing cities,
[00:27:44.840 --> 00:27:46.960]   where they would do a lot more good.
[00:27:46.960 --> 00:27:49.040]   They can actually go as far as you need.
[00:27:49.040 --> 00:27:51.760]   There's no worry about running out of them.
[00:27:51.760 --> 00:27:55.040]   And they would obviously, they're much, much more polluting
[00:27:55.040 --> 00:27:58.080]   just air pollution wise, and they're much cheaper
[00:27:58.080 --> 00:27:59.480]   and they use very little battery.
[00:27:59.480 --> 00:28:01.480]   So it's about getting our senses right.
[00:28:01.480 --> 00:28:06.080]   But the electric car is not a conversation about
[00:28:06.080 --> 00:28:08.080]   is it technically really good
[00:28:08.080 --> 00:28:10.720]   or is it a somewhat good insight?
[00:28:10.720 --> 00:28:12.440]   It's more like it's a virtual signal.
[00:28:12.440 --> 00:28:15.120]   So just, I work with economists.
[00:28:15.120 --> 00:28:16.480]   I'm actually not an economist,
[00:28:16.480 --> 00:28:19.040]   but I like to say I claim I kind of am.
[00:28:19.040 --> 00:28:21.840]   But the fundamental point is we would say,
[00:28:21.840 --> 00:28:25.960]   well, how much does it cost to cut a ton of CO2?
[00:28:25.960 --> 00:28:28.400]   And the answer is for most electric cars,
[00:28:28.400 --> 00:28:31.960]   we're paying in the order of 1000, 2000,
[00:28:31.960 --> 00:28:36.960]   Norway, they pay up to what $5,000 or thereabouts,
[00:28:37.400 --> 00:28:40.080]   huge amount for one ton of CO2.
[00:28:40.080 --> 00:28:42.720]   You can right now cut a ton of CO2 for about,
[00:28:42.720 --> 00:28:45.880]   what is it, $14 on the Reggie or something.
[00:28:45.880 --> 00:28:46.720]   You can do this.
[00:28:46.720 --> 00:28:48.960]   - That's a regional greenhouse gas.
[00:28:48.960 --> 00:28:51.400]   - So you can basically cut it really, really cheaply.
[00:28:51.400 --> 00:28:54.920]   Why would we not want to cut dozens and dozens of tons
[00:28:54.920 --> 00:28:58.560]   of CO2 for the same price instead of just cutting one ton?
[00:28:58.560 --> 00:29:00.480]   And the simple answer is we only do that
[00:29:00.480 --> 00:29:02.000]   because we're so focused on electric.
[00:29:02.000 --> 00:29:04.680]   - If I may interrupt, typically European come here
[00:29:04.680 --> 00:29:08.040]   in Texas, tell me I can't have my Ford F-150.
[00:29:08.040 --> 00:29:10.920]   - Well, now you can have your F-150 Lightning.
[00:29:10.920 --> 00:29:12.320]   - Yes, that's true.
[00:29:12.320 --> 00:29:14.560]   I'm just joking.
[00:29:14.560 --> 00:29:16.480]   But what do you think about electric cars?
[00:29:16.480 --> 00:29:17.920]   If you could just link on that moment
[00:29:17.920 --> 00:29:22.920]   and this particular element of helping reduce emissions.
[00:29:22.920 --> 00:29:26.720]   - Well, you talked about the middle in the beginning.
[00:29:26.720 --> 00:29:29.440]   And I loved moving to the hybrid.
[00:29:29.440 --> 00:29:30.800]   The Prius was fantastic.
[00:29:30.800 --> 00:29:33.120]   It did everything our other sedan did.
[00:29:33.120 --> 00:29:36.640]   But it was 60 miles per gallon performance.
[00:29:36.640 --> 00:29:39.280]   And you don't have range anxiety
[00:29:39.280 --> 00:29:42.240]   because it has a regular engine too.
[00:29:42.240 --> 00:29:43.600]   We still have a Prius.
[00:29:43.600 --> 00:29:45.480]   We also inherited my dad,
[00:29:45.480 --> 00:29:48.800]   dear dad's year 2000 Toyota Sienna,
[00:29:48.800 --> 00:29:53.240]   which is an old 100,000 mile minivan.
[00:29:53.240 --> 00:29:55.080]   And we use it all the time to do the stuff
[00:29:55.080 --> 00:29:57.640]   we can't do in the Prius.
[00:29:57.640 --> 00:29:58.640]   - Like what?
[00:29:58.640 --> 00:30:00.000]   - Taking stuff to the dump.
[00:30:00.000 --> 00:30:01.840]   - Oh, you mean in terms of the size of the vehicle?
[00:30:02.560 --> 00:30:06.520]   - Yeah, size and just convenience factor for a bigger vehicle.
[00:30:06.520 --> 00:30:12.400]   I would love a fully electrified transportation world.
[00:30:12.400 --> 00:30:13.640]   It's kind of exciting.
[00:30:13.640 --> 00:30:16.160]   I think what Elon did with Tesla,
[00:30:16.160 --> 00:30:18.000]   I remember way, way back in the day
[00:30:18.000 --> 00:30:19.400]   when the first models were coming out.
[00:30:19.400 --> 00:30:22.800]   They were very slick Ferrari style cars.
[00:30:22.800 --> 00:30:24.280]   And I thought, this is cool.
[00:30:24.280 --> 00:30:27.160]   And there's a history of privileged markets
[00:30:27.160 --> 00:30:29.120]   testing new technologies.
[00:30:29.120 --> 00:30:31.240]   And I'm all for that.
[00:30:31.240 --> 00:30:33.040]   And I think it's done a huge service
[00:30:33.040 --> 00:30:36.440]   prodding so much more R and D.
[00:30:36.440 --> 00:30:39.200]   And once GM and Ford started to realize,
[00:30:39.200 --> 00:30:42.280]   oh my God, this is a real phenomenon,
[00:30:42.280 --> 00:30:43.840]   getting them in the game.
[00:30:43.840 --> 00:30:47.920]   There was that documentary, "Who Killed the Electric Car?"
[00:30:47.920 --> 00:30:52.360]   which seemed to imply that there were fights
[00:30:52.360 --> 00:30:54.120]   to keep this tamp down.
[00:30:54.120 --> 00:30:57.080]   And it's fundamentally cleaner, fundamentally better.
[00:30:57.080 --> 00:31:01.000]   But then you have to manage these bigger questions.
[00:31:01.000 --> 00:31:03.000]   If we're gonna do a build out here,
[00:31:03.000 --> 00:31:05.240]   how do you make it fair?
[00:31:05.240 --> 00:31:08.640]   As you were saying, who actually uses transformed cars?
[00:31:08.640 --> 00:31:10.880]   And Jagir Shah, that guy at the energy department
[00:31:10.880 --> 00:31:13.440]   I mentioned who has all this money to give out,
[00:31:13.440 --> 00:31:18.440]   he wants to give loans to, if you had an Uber fleet,
[00:31:18.440 --> 00:31:23.460]   those Uber drivers, they're the ones who need electric cars.
[00:31:23.460 --> 00:31:28.600]   As his work, and there was a recent story in Grist also,
[00:31:28.600 --> 00:31:30.640]   said that most of the sales of Teslas
[00:31:30.640 --> 00:31:31.840]   are the high end of the market.
[00:31:31.840 --> 00:31:33.820]   They're 60, $80,000 vehicles.
[00:31:33.820 --> 00:31:37.600]   Like the Hummer, the electric Hummer,
[00:31:37.600 --> 00:31:41.800]   there was a data point on that, astonishing data point,
[00:31:41.800 --> 00:31:44.780]   the battery in that Hummer weighs more than,
[00:31:44.780 --> 00:31:49.040]   I'd have to look it up, it weighs more than a car.
[00:31:49.040 --> 00:31:51.120]   Yeah, I think it might have been a Prius.
[00:31:51.120 --> 00:31:53.040]   And think of the material costs there.
[00:31:53.040 --> 00:31:55.720]   Think of where that battery, the cobalt and the lithium,
[00:31:55.720 --> 00:31:59.480]   where does this stuff come from to build this stuff out?
[00:31:59.480 --> 00:32:03.000]   I'm all for it, but we have to be honest and clear about
[00:32:03.000 --> 00:32:05.960]   that's a new resource rush, like the oil rush
[00:32:05.960 --> 00:32:08.040]   back in the early 20th century.
[00:32:08.040 --> 00:32:10.480]   And those impacts have to be figured out too.
[00:32:10.480 --> 00:32:14.660]   And if they're all big Hummers for rich people,
[00:32:14.660 --> 00:32:16.560]   there's so many contrary arguments to that
[00:32:16.560 --> 00:32:19.680]   that I think we have to figure out a way, we,
[00:32:19.680 --> 00:32:23.080]   I don't like the word we, I use it too much, we all do.
[00:32:23.080 --> 00:32:23.920]   - We all do.
[00:32:23.920 --> 00:32:26.480]   - You usually refer when you say we, we humans.
[00:32:26.480 --> 00:32:28.800]   - We society, we government, yeah.
[00:32:28.800 --> 00:32:31.560]   There has to be some thought and attention put
[00:32:31.560 --> 00:32:33.800]   to where you put these incentives so that you get
[00:32:33.800 --> 00:32:38.000]   the best use of this technology for the carbon benefit,
[00:32:38.000 --> 00:32:41.040]   for the conventional sooty pollution benefit,
[00:32:41.040 --> 00:32:42.800]   for the transportation benefit.
[00:32:42.800 --> 00:32:45.600]   - Can I step back and ask a sort of big question?
[00:32:45.600 --> 00:32:48.360]   We mentioned economics, journalism.
[00:32:48.360 --> 00:32:53.280]   How does an economist and a climate scientist
[00:32:53.280 --> 00:32:57.040]   and a journalist that writes about climate
[00:32:57.040 --> 00:32:58.400]   see the world differently?
[00:32:58.400 --> 00:33:00.560]   What are the strengths and potential blind spots
[00:33:00.560 --> 00:33:02.080]   of each discipline?
[00:33:02.080 --> 00:33:06.320]   I mean, that's just sort of, just so people may be aware.
[00:33:06.320 --> 00:33:10.200]   I think you'll be able to fall into the economics camp a bit.
[00:33:10.200 --> 00:33:12.280]   There's climate scientists,
[00:33:12.280 --> 00:33:15.080]   and there's climate scientists adjacent people,
[00:33:15.080 --> 00:33:17.640]   like who hang, some of my best friends are climate scientists
[00:33:17.640 --> 00:33:19.920]   kind of, which is I think where you fall in
[00:33:19.920 --> 00:33:22.120]   because you're a journalist, you've been writing it,
[00:33:22.120 --> 00:33:27.120]   so you're not completely in the trenches of doing the work
[00:33:28.120 --> 00:33:31.720]   you're just step into the trenches every once in a while.
[00:33:31.720 --> 00:33:33.920]   So can you speak to that maybe beyond like,
[00:33:33.920 --> 00:33:37.880]   what does the world look like to an economist?
[00:33:37.880 --> 00:33:41.520]   Let's try to empathize with these beings that--
[00:33:41.520 --> 00:33:46.520]   - Unfortunately has fallen into the disreputable economics.
[00:33:46.520 --> 00:33:50.880]   So I think the main point that I've been trying
[00:33:50.880 --> 00:33:52.800]   for a long time, and I think that's also a little bit
[00:33:52.800 --> 00:33:56.180]   what Andy has been talking about, for a very long time,
[00:33:56.180 --> 00:33:57.440]   the whole conversation was about
[00:33:57.440 --> 00:33:59.320]   what does the science tell us?
[00:33:59.320 --> 00:34:01.080]   Is global warming real?
[00:34:01.080 --> 00:34:05.720]   And to me, it's much more, what can we actually do?
[00:34:05.720 --> 00:34:08.520]   What are the policies that we can take
[00:34:08.520 --> 00:34:10.400]   and how effective are they gonna be?
[00:34:10.400 --> 00:34:12.680]   So the conversation we just had about electric cars
[00:34:12.680 --> 00:34:15.920]   is a good example of how an economist think about,
[00:34:15.920 --> 00:34:18.880]   look, this is not a question about
[00:34:18.880 --> 00:34:20.720]   whether you feel morally virtuous
[00:34:20.720 --> 00:34:22.640]   or whether you can sort of display
[00:34:22.640 --> 00:34:24.600]   how much you care about the environment.
[00:34:24.600 --> 00:34:27.460]   This is about how much you actually ended up
[00:34:27.460 --> 00:34:28.820]   affecting the world.
[00:34:28.820 --> 00:34:32.540]   And the honest answer is that electric cars right now
[00:34:32.540 --> 00:34:36.300]   in the next decade or so will have a fairly small impact.
[00:34:36.300 --> 00:34:38.340]   And unfortunately right now at a very high cost
[00:34:38.340 --> 00:34:40.700]   because we're basically subsidizing these things
[00:34:40.700 --> 00:34:44.940]   at five or $10,000 around the world per car.
[00:34:44.940 --> 00:34:47.300]   That's just not, it's not really sustainable,
[00:34:47.300 --> 00:34:48.980]   but it's certainly not a very great way
[00:34:48.980 --> 00:34:50.460]   to cut carbon emissions.
[00:34:50.460 --> 00:34:53.220]   So I would be the kind of guy and economists
[00:34:53.220 --> 00:34:55.620]   would be the types of people who would say,
[00:34:55.620 --> 00:34:59.160]   is there a smarter way where you for less money
[00:34:59.160 --> 00:35:01.200]   can for instance, cut more CO2?
[00:35:01.200 --> 00:35:03.980]   And the obvious answer is yes.
[00:35:03.980 --> 00:35:07.140]   That's what we've seen for instance, with fracking.
[00:35:07.140 --> 00:35:10.380]   The fact that the US went from a lot of coal
[00:35:10.380 --> 00:35:13.360]   to a lot of gas because gas became incredibly cheap
[00:35:13.360 --> 00:35:16.780]   because gas emits about half as much as coal does
[00:35:16.780 --> 00:35:20.060]   when you use it for power,
[00:35:20.060 --> 00:35:22.340]   that basically cut more carbon emissions
[00:35:22.340 --> 00:35:24.780]   than pretty much any other single thing.
[00:35:24.780 --> 00:35:27.940]   And we should get the rest of the world in some sense
[00:35:27.940 --> 00:35:30.540]   to frack because it's really cheap.
[00:35:30.540 --> 00:35:32.300]   There are some problems and absolutely
[00:35:32.300 --> 00:35:34.180]   we can also have that conversation.
[00:35:34.180 --> 00:35:36.860]   No technology is problem-free,
[00:35:36.860 --> 00:35:39.780]   but fundamentally it's an incredibly cheap way
[00:35:39.780 --> 00:35:42.460]   to get people to cut a lot of CO2.
[00:35:42.460 --> 00:35:43.860]   It's not the final solution
[00:35:43.860 --> 00:35:45.180]   because it's still a fossil fuel,
[00:35:45.180 --> 00:35:47.980]   but it's a much better fossil fuel, if you will.
[00:35:47.980 --> 00:35:50.340]   And it's much more realistic to do that.
[00:35:50.340 --> 00:35:52.160]   So that's one part of the thing.
[00:35:52.160 --> 00:35:54.900]   The other one is when we talked about, for instance,
[00:35:54.900 --> 00:35:58.520]   how do we help people in Florida who gets hit by a hurricane
[00:35:58.520 --> 00:36:02.900]   or how do we help people that get damaged in flash floods,
[00:36:02.900 --> 00:36:05.740]   the people who are in heat waves.
[00:36:05.740 --> 00:36:10.300]   And the simple answer is there's a lot of very, very cheap
[00:36:10.300 --> 00:36:12.420]   and effective things that we could do first.
[00:36:12.420 --> 00:36:15.380]   So most climate people will tend to sort of say,
[00:36:15.380 --> 00:36:18.780]   we gotta get rid of all carbon emissions,
[00:36:18.780 --> 00:36:23.660]   we gotta change the engine that sort of powers the world
[00:36:23.660 --> 00:36:26.080]   and has powered us for the last 200 years.
[00:36:26.080 --> 00:36:27.200]   And that's all good and well,
[00:36:27.200 --> 00:36:28.480]   but it's really, really hard to do
[00:36:28.480 --> 00:36:30.440]   and it's probably not gonna do very much.
[00:36:30.440 --> 00:36:33.280]   And even if you succeed it, it would only help
[00:36:33.280 --> 00:36:36.280]   future victims of future hurricane Ians in Florida
[00:36:36.280 --> 00:36:38.320]   a tiny, tiny bit at best.
[00:36:38.320 --> 00:36:41.420]   So instead, let's try to focus on not getting people
[00:36:41.420 --> 00:36:43.640]   to build right on the waterfront
[00:36:43.640 --> 00:36:45.240]   where you're incredibly vulnerable
[00:36:45.240 --> 00:36:47.160]   and where you're very likely to get hit,
[00:36:47.160 --> 00:36:51.560]   where we subsidize people with federal insurance again,
[00:36:51.560 --> 00:36:53.540]   which is just actually losing money.
[00:36:53.540 --> 00:36:55.840]   So we're much more about saying,
[00:36:55.840 --> 00:36:57.240]   it's not a science question,
[00:36:57.240 --> 00:36:58.840]   I just take the science for granted.
[00:36:58.840 --> 00:37:00.700]   Yes, there is a problem with climate change,
[00:37:00.700 --> 00:37:02.040]   but it's much more about saying,
[00:37:02.040 --> 00:37:03.520]   how can we make smart decisions?
[00:37:03.520 --> 00:37:06.080]   - Can I ask you about blind spots?
[00:37:06.080 --> 00:37:09.800]   When you reduce stuff to numbers, the cost and benefits,
[00:37:09.800 --> 00:37:11.880]   is there stuff you might miss
[00:37:11.880 --> 00:37:16.900]   that are important to the flourishing of the human species?
[00:37:16.900 --> 00:37:18.920]   - So everyone will have to say,
[00:37:18.920 --> 00:37:21.240]   of course there must be blind spots.
[00:37:21.240 --> 00:37:23.120]   - But I don't know what they are.
[00:37:23.120 --> 00:37:26.400]   - Yeah, I'm sure Andy would probably be better
[00:37:26.400 --> 00:37:28.560]   at telling me what they are.
[00:37:28.560 --> 00:37:30.480]   So we try to incorporate all of it,
[00:37:30.480 --> 00:37:32.600]   but obviously we're not successful.
[00:37:32.600 --> 00:37:34.240]   You can't incorporate everything,
[00:37:34.240 --> 00:37:36.320]   for instance, in a cost benefit analysis.
[00:37:36.320 --> 00:37:38.180]   But the point is in some way,
[00:37:38.180 --> 00:37:41.440]   I would worry a lot about this
[00:37:41.440 --> 00:37:44.400]   if we were sort of close to perfection,
[00:37:44.400 --> 00:37:47.080]   human race, we're doing almost everything right,
[00:37:47.080 --> 00:37:48.260]   but we're not quite right,
[00:37:48.260 --> 00:37:50.340]   then we need to get the last digits right.
[00:37:50.340 --> 00:37:51.980]   But I think it's much more of the,
[00:37:51.980 --> 00:37:54.800]   and the point that I tried to make before,
[00:37:54.800 --> 00:37:58.820]   that we're all focused on going to an electric car
[00:37:58.820 --> 00:38:01.700]   or something else rather than fracking,
[00:38:01.700 --> 00:38:04.300]   we're all focused on cutting carbon emissions
[00:38:04.300 --> 00:38:06.620]   instead of reducing vulnerability.
[00:38:06.620 --> 00:38:10.380]   So we're similarly getting in orders of magnitude wrong.
[00:38:10.380 --> 00:38:13.380]   And while I'm sure I have blind spots,
[00:38:13.380 --> 00:38:15.040]   I think they're probably not big enough
[00:38:15.040 --> 00:38:16.600]   to overturn that point.
[00:38:16.600 --> 00:38:18.760]   - Andy, wise, Bjorn, economists
[00:38:18.760 --> 00:38:21.260]   are all wrong about everything.
[00:38:21.260 --> 00:38:25.780]   - Well, models, we could spend a whole day on models.
[00:38:25.780 --> 00:38:26.840]   There are economic models,
[00:38:26.840 --> 00:38:29.340]   there's this thing called optimization models.
[00:38:29.340 --> 00:38:33.660]   There were two big ones used to assess the US plan,
[00:38:33.660 --> 00:38:38.420]   this new big IRA, inflation reduction package.
[00:38:38.420 --> 00:38:41.260]   And they're fine, they're a starting point
[00:38:41.260 --> 00:38:43.980]   for understanding what's possible.
[00:38:43.980 --> 00:38:47.860]   But as this gets to the journalism part or the public part,
[00:38:47.860 --> 00:38:49.260]   you have to look at the caveats.
[00:38:49.260 --> 00:38:51.420]   You have to look at what model,
[00:38:51.420 --> 00:38:56.220]   economists expressly exclude things that are not modelable.
[00:38:56.220 --> 00:38:59.540]   And if you look in the fine print on the repeat project,
[00:38:59.540 --> 00:39:01.940]   the Princeton version of the assessment
[00:39:01.940 --> 00:39:04.040]   of the recent giant legislation,
[00:39:04.040 --> 00:39:09.280]   the fine print is the front page for me
[00:39:09.280 --> 00:39:11.140]   as a deep diving journalist,
[00:39:11.140 --> 00:39:16.140]   because it says we didn't include any sources of friction,
[00:39:16.140 --> 00:39:20.220]   meaning resistance to putting new transmission lines
[00:39:20.220 --> 00:39:21.540]   through your community,
[00:39:21.540 --> 00:39:26.540]   or people who don't want mining in America
[00:39:26.540 --> 00:39:29.420]   because we've exported all of our mining.
[00:39:29.420 --> 00:39:32.820]   We mine our cobalt in Congo,
[00:39:32.820 --> 00:39:35.300]   and trying to get a new mine in Nevada
[00:39:35.300 --> 00:39:40.240]   was a fraught fight that took more than 10 years for lithium.
[00:39:41.240 --> 00:39:46.240]   So if you're excluding those elements from your model,
[00:39:46.240 --> 00:39:51.440]   which on the surface makes this $370 billion package
[00:39:51.440 --> 00:39:53.500]   have an emissions reduction trajectory
[00:39:53.500 --> 00:39:54.800]   that's really pretty good,
[00:39:54.800 --> 00:39:58.080]   and you're not saying in your first line,
[00:39:58.080 --> 00:40:00.920]   by the way, these are the things we're not considering.
[00:40:00.920 --> 00:40:02.320]   That's the job of a journalist.
[00:40:02.320 --> 00:40:04.360]   - You could probably summarize all of human history
[00:40:04.360 --> 00:40:06.680]   with that one word, friction.
[00:40:06.680 --> 00:40:08.760]   - Yeah, yeah, well, inertia,
[00:40:08.760 --> 00:40:10.320]   friction implies there's a force
[00:40:10.320 --> 00:40:11.920]   that's already being resisted,
[00:40:11.920 --> 00:40:15.420]   but there's also inertia, which is a huge part of our,
[00:40:15.420 --> 00:40:18.740]   we have a status quo bias.
[00:40:18.740 --> 00:40:21.800]   The scientists that I,
[00:40:21.800 --> 00:40:25.360]   in grappling with the climate problem as a journalist,
[00:40:25.360 --> 00:40:28.440]   I paid too much attention to climate scientists.
[00:40:28.440 --> 00:40:31.740]   That's why all my articles focused on climate change,
[00:40:31.740 --> 00:40:33.360]   and it was 2006.
[00:40:33.360 --> 00:40:35.380]   I remember now pretty clearly,
[00:40:35.380 --> 00:40:38.040]   I was asked by the Week in Review section
[00:40:38.040 --> 00:40:40.400]   of the New York Times to write a sort of a weekend
[00:40:40.400 --> 00:40:42.840]   thumb sucker, we call them, on--
[00:40:42.840 --> 00:40:43.680]   - Thumb sucker?
[00:40:43.680 --> 00:40:45.360]   - You know, you sit and suck your thumb
[00:40:45.360 --> 00:40:46.600]   and think about something.
[00:40:46.600 --> 00:40:48.520]   Why is everybody so pissed off about climate change?
[00:40:48.520 --> 00:40:49.760]   It was after Al Gore's movie,
[00:40:49.760 --> 00:40:51.720]   the Al Gore movie came out, "Inconvenient Truth,"
[00:40:51.720 --> 00:40:53.600]   Hurricane Katrina, it was big.
[00:40:53.600 --> 00:40:56.200]   Senator Inhofe in the Senate from Oklahoma
[00:40:56.200 --> 00:40:59.040]   wasn't yet throwing snowballs, but it was close to that.
[00:40:59.040 --> 00:41:02.000]   And so I looked into what was going on.
[00:41:02.000 --> 00:41:03.400]   Why is this so heated?
[00:41:03.400 --> 00:41:07.440]   In 2006, the story's called "Yelling Fire on a Hot Planet."
[00:41:08.120 --> 00:41:10.000]   And that was the first time,
[00:41:10.000 --> 00:41:13.320]   this is after 18 years of writing about global warming,
[00:41:13.320 --> 00:41:15.660]   that was the first time I interviewed a social scientist,
[00:41:15.660 --> 00:41:16.840]   not a climate scientist.
[00:41:16.840 --> 00:41:20.560]   Her name was Helen Ingram, she was at UC Irvine.
[00:41:20.560 --> 00:41:23.500]   And she laid out for me the factors
[00:41:23.500 --> 00:41:26.240]   that determine why people vote,
[00:41:26.240 --> 00:41:29.100]   what they vote for, what they think about politically.
[00:41:29.100 --> 00:41:32.000]   And they were the antithesis of the climate problem.
[00:41:32.000 --> 00:41:33.240]   She used the words, she said,
[00:41:33.240 --> 00:41:36.960]   "People go in the voting booth thinking about things
[00:41:36.960 --> 00:41:41.040]   "that are soon, salient, and certain."
[00:41:41.040 --> 00:41:44.560]   And climate change is complex, has long timescales.
[00:41:44.560 --> 00:41:46.680]   And that really jogged me.
[00:41:46.680 --> 00:41:49.320]   And then between 2006, 2010,
[00:41:49.320 --> 00:41:52.620]   I started interviewing other social scientists.
[00:41:52.620 --> 00:41:56.780]   And this was by far the scariest science of all.
[00:41:56.780 --> 00:42:01.280]   It's the climate in our heads, or inconvenient minds,
[00:42:01.280 --> 00:42:04.560]   and in how that translates into political norms and stuff,
[00:42:04.560 --> 00:42:07.760]   really became the monster, not the climate system.
[00:42:07.760 --> 00:42:10.800]   - Is there social dynamics to the scientists themselves?
[00:42:10.800 --> 00:42:14.240]   Because I've gotten to witness
[00:42:14.240 --> 00:42:18.120]   a kind of flocking behavior with scientists.
[00:42:18.120 --> 00:42:19.820]   So it's almost like a flock of birds.
[00:42:19.820 --> 00:42:23.200]   Within the flock, there's a lot of disagreement,
[00:42:23.200 --> 00:42:25.520]   and fun debates, and everybody trying
[00:42:25.520 --> 00:42:26.760]   to prove each other wrong.
[00:42:26.760 --> 00:42:29.240]   But they're all kind of headed in the same direction.
[00:42:29.240 --> 00:42:30.740]   And you don't want to be the bird
[00:42:30.740 --> 00:42:32.940]   that kind of leaves that flock.
[00:42:32.940 --> 00:42:36.760]   So there's an idea that science is a mechanism
[00:42:36.760 --> 00:42:38.480]   will get us towards the truth.
[00:42:38.480 --> 00:42:41.360]   But it'll definitely get us somewhere.
[00:42:41.360 --> 00:42:45.040]   But it could be not the truth in the short term.
[00:42:45.040 --> 00:42:48.080]   In the long term, a bigger flock will come along,
[00:42:48.080 --> 00:42:49.240]   and it'll get us to the truth.
[00:42:49.240 --> 00:42:51.320]   But there's a sense that, I don't know
[00:42:51.320 --> 00:42:52.880]   if there's a mechanism within science
[00:42:52.880 --> 00:42:57.200]   to snap out of it if you're down the wrong track.
[00:42:57.200 --> 00:43:01.080]   Usually you get it right, but sometimes you don't.
[00:43:01.080 --> 00:43:03.100]   And when you don't, it's very costly.
[00:43:03.100 --> 00:43:05.300]   - And there's so many factors that line up
[00:43:05.300 --> 00:43:09.340]   to perpetuate that flocking behavior.
[00:43:09.340 --> 00:43:12.860]   One is media attention comes in.
[00:43:12.860 --> 00:43:14.940]   The other is funding comes in.
[00:43:14.940 --> 00:43:17.720]   National Science Foundation or whatever,
[00:43:17.720 --> 00:43:19.820]   European foundations pour a huge amount of money
[00:43:19.820 --> 00:43:22.340]   into things related to climate.
[00:43:22.340 --> 00:43:25.140]   And then your narrative in your head
[00:43:25.140 --> 00:43:29.060]   is shaped by that aspect of the climate problem
[00:43:29.060 --> 00:43:30.580]   that's in the spotlight.
[00:43:30.580 --> 00:43:34.440]   I started using this hashtag a few years back,
[00:43:34.440 --> 00:43:38.500]   narrative capture, be wary of narrative capture,
[00:43:38.500 --> 00:43:42.980]   where you're on a train and everyone's getting on the train.
[00:43:42.980 --> 00:43:44.820]   And this is in the media too, not just science.
[00:43:44.820 --> 00:43:47.940]   And it becomes self-sustaining.
[00:43:47.940 --> 00:43:52.700]   And contrary indications are ignored or downplayed.
[00:43:52.700 --> 00:43:54.540]   No one does replication science
[00:43:54.540 --> 00:43:56.700]   because your career doesn't advance
[00:43:56.700 --> 00:43:58.900]   through replicating someone else's work.
[00:43:58.900 --> 00:44:03.580]   So those contrary indications are not necessarily
[00:44:03.580 --> 00:44:05.020]   really dug in on.
[00:44:05.020 --> 00:44:07.420]   And this is way beyond climate.
[00:44:07.420 --> 00:44:08.700]   This is many fields.
[00:44:08.700 --> 00:44:10.500]   As you said, you might've seen this in AI.
[00:44:10.500 --> 00:44:14.140]   And it's really hard to find.
[00:44:14.140 --> 00:44:16.300]   It's another form of path dependency,
[00:44:16.300 --> 00:44:18.860]   the term I used before.
[00:44:18.860 --> 00:44:21.340]   But breaking narrative capture to me,
[00:44:21.340 --> 00:44:26.420]   for me, has come mostly from stepping back
[00:44:27.660 --> 00:44:30.900]   and reminding myself of the basic principles of journalism.
[00:44:30.900 --> 00:44:35.020]   Journalism's basic principles are useful for anybody.
[00:44:35.020 --> 00:44:38.340]   Confronting a big, enormous, dynamic, complex thing
[00:44:38.340 --> 00:44:40.780]   is who, what, where, when, why.
[00:44:40.780 --> 00:44:44.420]   Just be really rigorous about not assuming
[00:44:44.420 --> 00:44:47.560]   because there's a fire in Boulder County
[00:44:47.560 --> 00:44:50.660]   or a flood in Fort Myers that climate,
[00:44:50.660 --> 00:44:52.500]   which is in your head because you're part
[00:44:52.500 --> 00:44:54.980]   of the climate team at the New York Times or whatever,
[00:44:54.980 --> 00:44:59.100]   is the foreground part of this problem.
[00:44:59.100 --> 00:45:02.940]   - What's the psychological challenge of that
[00:45:02.940 --> 00:45:07.460]   if you incorporate the fact that if you try to step back
[00:45:07.460 --> 00:45:09.520]   and have nuance, you might get attacked
[00:45:09.520 --> 00:45:12.260]   by the others in the flock?
[00:45:12.260 --> 00:45:13.460]   - Oh, I was.
[00:45:13.460 --> 00:45:14.660]   Well, you've certainly been--
[00:45:14.660 --> 00:45:18.820]   - So both of you get attacked continuously
[00:45:18.820 --> 00:45:20.220]   from different sides.
[00:45:20.220 --> 00:45:21.820]   So let me just ask about that.
[00:45:21.820 --> 00:45:26.260]   How does that feel and how do you continue thinking clearly
[00:45:26.260 --> 00:45:31.580]   and continuously try to have humility and step back
[00:45:31.580 --> 00:45:36.380]   and not get defensive in that as a communicator?
[00:45:36.380 --> 00:45:38.700]   - I mean, there are other things happening
[00:45:38.700 --> 00:45:39.540]   at the same time, right?
[00:45:39.540 --> 00:45:42.900]   I'm now 35 years into, almost 40 years
[00:45:42.900 --> 00:45:44.060]   into my journalism career.
[00:45:44.060 --> 00:45:45.240]   So I have some independence.
[00:45:45.240 --> 00:45:47.800]   I'm free from the obligations of,
[00:45:47.800 --> 00:45:50.680]   you know, I don't really need my next paycheck.
[00:45:50.680 --> 00:45:52.860]   I live in Maine now in a house I love.
[00:45:52.860 --> 00:45:53.780]   I own it outright.
[00:45:53.780 --> 00:45:55.500]   It's a great privilege and honor
[00:45:55.500 --> 00:45:59.260]   and as a result of a lot of hard work.
[00:45:59.260 --> 00:46:03.060]   And so I'm freer to think freely.
[00:46:03.060 --> 00:46:04.940]   And I know my colleagues in newsrooms,
[00:46:04.940 --> 00:46:08.140]   when I was at the New York Times, in the newsroom,
[00:46:08.140 --> 00:46:10.980]   you become captive to a narrative,
[00:46:10.980 --> 00:46:13.380]   just as you do out in the world.
[00:46:13.380 --> 00:46:18.100]   The New York Times had a narrative about Saddam Hussein.
[00:46:18.900 --> 00:46:21.800]   Drove us into that war.
[00:46:21.800 --> 00:46:26.480]   The Times sucked right into that and helped perpetuate it.
[00:46:26.480 --> 00:46:30.680]   I think we're in a bit of a narrative, we, the media,
[00:46:30.680 --> 00:46:33.800]   my friends at the Times and others are on a train ride
[00:46:33.800 --> 00:46:37.000]   on climate change, depicting it in a certain way
[00:46:37.000 --> 00:46:39.600]   that really, I saw problems
[00:46:39.600 --> 00:46:42.760]   with how they handled the Joe Manchin issue in America.
[00:46:42.760 --> 00:46:46.720]   The West Virginia Senator, they really kind of piled on
[00:46:46.720 --> 00:46:49.700]   and zoomed in on his investments,
[00:46:49.700 --> 00:46:50.960]   which is really important to do,
[00:46:50.960 --> 00:46:52.760]   but they never pulled back and said,
[00:46:52.760 --> 00:46:55.360]   by the way, he's a rare species.
[00:46:55.360 --> 00:46:57.640]   He's a Democrat in West Virginia,
[00:46:57.640 --> 00:47:00.880]   and which is otherwise occupied by a Republican.
[00:47:00.880 --> 00:47:02.480]   There'd be no talk of a climate deal
[00:47:02.480 --> 00:47:04.540]   or any of that stuff without him.
[00:47:04.540 --> 00:47:06.280]   And, but when you, once you're starting
[00:47:06.280 --> 00:47:07.800]   to kind of frame a story in a certain way,
[00:47:07.800 --> 00:47:10.260]   you carry it along and as you said,
[00:47:10.260 --> 00:47:12.760]   sometimes it breaks and a new norm arrives,
[00:47:12.760 --> 00:47:17.260]   but the climate train is still kind of rushing forward
[00:47:17.260 --> 00:47:22.260]   and missing the opportunity to cut it into its pieces
[00:47:22.260 --> 00:47:25.560]   and say, well, what's really wrong with Florida?
[00:47:25.560 --> 00:47:28.120]   And it's for me, when you ask you about how I handle
[00:47:28.120 --> 00:47:30.680]   the slings and arrows and stuff,
[00:47:30.680 --> 00:47:34.620]   it's partially 'cause I'm past worrying about it too much.
[00:47:34.620 --> 00:47:37.720]   I mean, it was pretty intense.
[00:47:37.720 --> 00:47:41.440]   2009 Rush Limbaugh suggested I kill myself
[00:47:41.440 --> 00:47:42.280]   on his radio show.
[00:47:42.280 --> 00:47:43.120]   It's a really great time.
[00:47:43.120 --> 00:47:44.240]   - What was that about?
[00:47:44.240 --> 00:47:49.240]   - I had, actually, this was a meeting in Washington in 2009
[00:47:49.240 --> 00:47:52.520]   on population at the Wilson Center.
[00:47:52.520 --> 00:47:54.400]   I couldn't be there, so actually this is pre-COVID,
[00:47:54.400 --> 00:47:57.740]   but I was Zooming in or something like Skyping in,
[00:47:57.740 --> 00:48:00.960]   and I was talking about in a playful way.
[00:48:00.960 --> 00:48:04.240]   I said, well, if you really wanna worry about carbon,
[00:48:04.240 --> 00:48:08.360]   this was during the debate over a carbon tax model
[00:48:08.360 --> 00:48:09.940]   for a bill in America.
[00:48:10.840 --> 00:48:13.920]   We should probably have a carbon tax for kids
[00:48:13.920 --> 00:48:15.520]   because a bigger family in America
[00:48:15.520 --> 00:48:18.120]   is a big source of more emissions.
[00:48:18.120 --> 00:48:20.160]   It was kind of a playful thought bubble.
[00:48:20.160 --> 00:48:22.240]   Some right-wing blogger blogged about it.
[00:48:22.240 --> 00:48:26.400]   It got into Rush's pile of things to talk about,
[00:48:26.400 --> 00:48:28.880]   and the clip is really fun.
[00:48:28.880 --> 00:48:33.880]   - Oh, so meaning, so if humans are bad for the environment,
[00:48:33.880 --> 00:48:38.880]   I can imagine Rush.
[00:48:38.880 --> 00:48:40.640]   - He was very explicit. - That's how you know
[00:48:40.640 --> 00:48:41.560]   you've made it.
[00:48:41.560 --> 00:48:43.480]   - He said, Mr. Revkin of the New York,
[00:48:43.480 --> 00:48:44.720]   Andrew Revkin of the New York Times,
[00:48:44.720 --> 00:48:46.360]   if you really think that people are the worst thing
[00:48:46.360 --> 00:48:48.160]   that ever happened to this planet,
[00:48:48.160 --> 00:48:49.440]   why don't you just kill yourself
[00:48:49.440 --> 00:48:51.560]   and save the planet by dying?
[00:48:51.560 --> 00:48:53.360]   - So that was tough for you.
[00:48:53.360 --> 00:48:55.080]   - It was tough for my family.
[00:48:55.080 --> 00:48:57.240]   To me, it did generate some interesting calls
[00:48:57.240 --> 00:48:58.920]   and stuff in my voicemail.
[00:48:58.920 --> 00:49:03.840]   But on the left, I was also undercut.
[00:49:03.840 --> 00:49:06.800]   Roger Pilkey, Jr., a prominent researcher
[00:49:06.800 --> 00:49:09.600]   of climate risk and climate policy,
[00:49:09.600 --> 00:49:14.160]   UC Boulder, was actively, his career track
[00:49:14.160 --> 00:49:17.600]   was derailed purposefully by people
[00:49:17.600 --> 00:49:21.880]   who just thought his message was too off the path.
[00:49:21.880 --> 00:49:26.920]   You've been dealing with this for a very long time.
[00:49:26.920 --> 00:49:27.760]   - Oh, God, yeah, yeah.
[00:49:27.760 --> 00:49:28.600]   - What do you--
[00:49:28.600 --> 00:49:31.400]   - So I just wanna get back to, so the science,
[00:49:31.400 --> 00:49:34.620]   I don't think the science get it so much wrong
[00:49:34.620 --> 00:49:38.480]   as it just becomes accepted to make certain assumptions,
[00:49:38.480 --> 00:49:40.740]   as you just said, we assume no friction.
[00:49:40.740 --> 00:49:43.900]   So there's a way that you kind of model the world
[00:49:43.900 --> 00:49:47.920]   that ends up being also a convenient message in many ways.
[00:49:47.920 --> 00:49:51.340]   And I think the main convenient message in climate,
[00:49:51.340 --> 00:49:54.280]   and it's not surprising if you think about it,
[00:49:54.280 --> 00:49:57.520]   the main convenient message is that the best way
[00:49:57.520 --> 00:50:00.280]   to do something about all the things that we call climate
[00:50:00.280 --> 00:50:02.220]   is to cut CO2.
[00:50:02.220 --> 00:50:05.000]   And that turns out to only sometimes be true
[00:50:05.000 --> 00:50:07.280]   and with a lot of caveats.
[00:50:07.280 --> 00:50:08.120]   But that's sort of the message--
[00:50:08.120 --> 00:50:09.440]   - And it takes a long time.
[00:50:09.440 --> 00:50:12.140]   - Yes, yes, it's really, really difficult to do
[00:50:12.140 --> 00:50:15.040]   in any meaningful sort of timeframe.
[00:50:15.040 --> 00:50:19.760]   And if you challenge that, yes, you're outside the flock
[00:50:19.760 --> 00:50:20.720]   and you get attacked.
[00:50:20.720 --> 00:50:24.960]   I've always, so somebody told me once, I think it's true,
[00:50:24.960 --> 00:50:27.760]   they say at the Harvard Law School,
[00:50:27.760 --> 00:50:30.120]   if you have a good case, pound the case.
[00:50:30.120 --> 00:50:32.780]   If you have a bad case, pound the table.
[00:50:32.780 --> 00:50:35.940]   And so I've always felt that when people go after me,
[00:50:35.940 --> 00:50:37.220]   they're kind of pounding the table.
[00:50:37.220 --> 00:50:40.320]   They're literally screaming, I don't have a good case.
[00:50:40.320 --> 00:50:42.260]   I'm really annoyed with what you're saying.
[00:50:42.260 --> 00:50:46.060]   And so to me, that actually means it's much more important
[00:50:46.060 --> 00:50:47.640]   to make this argument.
[00:50:47.640 --> 00:50:50.860]   Sure, I mean, I would love everyone just saying,
[00:50:50.860 --> 00:50:53.160]   oh, that's a really good point, I'm gonna use that.
[00:50:53.160 --> 00:50:56.020]   But we're stuck in a situation,
[00:50:56.020 --> 00:50:59.260]   certainly in a conversation where a lot of people
[00:50:59.260 --> 00:51:02.620]   invest a lot of time and energy on saying,
[00:51:02.620 --> 00:51:04.040]   we should cut carbon emissions.
[00:51:04.040 --> 00:51:06.420]   This is the way to help humankind.
[00:51:06.420 --> 00:51:09.260]   And just be clear, I think we should cut carbon emissions
[00:51:09.260 --> 00:51:11.660]   as well, but we should also just be realistic
[00:51:11.660 --> 00:51:13.020]   about what we can achieve with that
[00:51:13.020 --> 00:51:16.940]   and what are all the other things that we could also do.
[00:51:16.940 --> 00:51:18.740]   And it turns out that a lot of these other things
[00:51:18.740 --> 00:51:20.340]   are much cheaper, much more effective,
[00:51:20.340 --> 00:51:22.660]   will help much more, much quicker.
[00:51:22.660 --> 00:51:26.860]   And so getting that point out is just incredibly important
[00:51:26.860 --> 00:51:28.280]   for us to get it right.
[00:51:28.280 --> 00:51:32.580]   So in some sense, to make sure that we don't do another
[00:51:32.580 --> 00:51:37.580]   Iraq and we don't do another, lots of stupid decisions.
[00:51:37.580 --> 00:51:40.580]   This is one of the things mankind is very good at.
[00:51:40.580 --> 00:51:45.540]   And I guess I see my role, and I think that's probably also
[00:51:45.540 --> 00:51:48.440]   how you see yourself is trying to get everyone
[00:51:48.440 --> 00:51:50.420]   to do it slightly less wrong.
[00:51:50.420 --> 00:51:54.940]   - So let me ask you about a deep psychological effect
[00:51:54.940 --> 00:51:55.980]   for you.
[00:51:55.980 --> 00:51:58.640]   There's also a drug of martyrdom.
[00:51:58.640 --> 00:52:01.000]   So whenever you stand against the flock,
[00:52:01.000 --> 00:52:07.420]   there's, you wrote a couple of really good books
[00:52:07.420 --> 00:52:11.760]   on the topic, the most recent, "False Alarm."
[00:52:11.760 --> 00:52:14.920]   "I stand as the holder of truth,
[00:52:14.920 --> 00:52:18.060]   "that everybody who is alarmist is wrong.
[00:52:18.060 --> 00:52:20.800]   "And here's just simple, calm way to express
[00:52:20.800 --> 00:52:22.960]   "the facts of the matter."
[00:52:22.960 --> 00:52:26.500]   And that's very compelling to a very large number of people.
[00:52:26.500 --> 00:52:28.300]   They wanna make a martyr out of you.
[00:52:28.300 --> 00:52:31.920]   Is that, are you worried about your own mind
[00:52:31.920 --> 00:52:37.620]   being corrupted by that, by enjoying standing
[00:52:37.620 --> 00:52:39.080]   against the crowd?
[00:52:39.080 --> 00:52:40.700]   - No, no, no.
[00:52:40.700 --> 00:52:45.020]   There's very little, I guess I can see what you're saying
[00:52:45.020 --> 00:52:47.140]   sort of in a literary way or something.
[00:52:47.140 --> 00:52:48.840]   - Yeah, it's a bit poetic here.
[00:52:48.840 --> 00:52:53.180]   - Yeah, there's very little comfort or sort of usefulness
[00:52:53.180 --> 00:52:55.700]   in annoying a lot of people.
[00:52:55.700 --> 00:53:00.100]   Whenever I go to a party, for instance,
[00:53:00.100 --> 00:53:01.980]   I know that there's a good chance people
[00:53:01.980 --> 00:53:03.360]   are gonna be annoyed with me.
[00:53:03.360 --> 00:53:06.120]   And I would love that not to be the case.
[00:53:06.120 --> 00:53:10.380]   But what I try to do is, so I try to be very polite
[00:53:10.380 --> 00:53:13.220]   and sort of not push people's buttons
[00:53:13.220 --> 00:53:15.100]   unless they sort of actively say,
[00:53:15.100 --> 00:53:18.060]   "So you're saying all kind of stupid stuff
[00:53:18.060 --> 00:53:19.660]   "on the climate, right?"
[00:53:19.660 --> 00:53:21.300]   And then try to engage with them and say,
[00:53:21.300 --> 00:53:23.100]   "Well, what is it you're thinking about?"
[00:53:23.100 --> 00:53:24.820]   And hopefully, during that party,
[00:53:24.820 --> 00:53:26.560]   and then it ends up being a really bad party for me.
[00:53:26.560 --> 00:53:31.220]   But anyway, so I'll end up possibly convincing one person
[00:53:31.220 --> 00:53:32.960]   that I'm not totally stupid.
[00:53:32.960 --> 00:53:35.200]   But no, I'm not playing the martyr
[00:53:35.200 --> 00:53:36.560]   and I'm not enjoying that.
[00:53:36.560 --> 00:53:39.160]   - It's so interesting.
[00:53:39.160 --> 00:53:42.820]   I mean, the martyr complex
[00:53:42.820 --> 00:53:44.480]   is all around the climate question.
[00:53:44.480 --> 00:53:48.120]   Michael Mann, at the far end of the spectrum of activism
[00:53:48.120 --> 00:53:50.760]   from where Bjorn is, was a climate scientist,
[00:53:50.760 --> 00:53:53.680]   is a climate scientist who was actively attacked
[00:53:53.680 --> 00:53:58.120]   by Inhofe and West Virginia politicians
[00:53:58.120 --> 00:54:00.600]   and really abused in many ways.
[00:54:00.600 --> 00:54:03.000]   He had come up with a very prominent model
[00:54:03.000 --> 00:54:06.440]   of looking at long-term records of climate change
[00:54:06.440 --> 00:54:08.940]   and got this hockey stick for temperature.
[00:54:08.940 --> 00:54:14.040]   And he definitely sits there in a certain kind of spotlight
[00:54:14.040 --> 00:54:15.920]   because of that.
[00:54:15.920 --> 00:54:19.560]   So it's not unique at any particular vantage point
[00:54:19.560 --> 00:54:24.000]   in the spectrum of sort of prominent people on the debate.
[00:54:24.000 --> 00:54:25.360]   - Andrew, you co-wrote the book,
[00:54:25.360 --> 00:54:30.360]   "The Human Planet, Earth at the Dawn of the Anthropocene,"
[00:54:30.360 --> 00:54:33.760]   which is the new age when humans are actually
[00:54:33.760 --> 00:54:35.580]   having an impact on the environment.
[00:54:35.580 --> 00:54:37.000]   Let me ask the question of,
[00:54:37.000 --> 00:54:39.120]   what do you find most beautiful and fascinating
[00:54:39.120 --> 00:54:41.560]   about our planet Earth?
[00:54:41.560 --> 00:54:43.280]   - It'd be cheap to say everything,
[00:54:43.280 --> 00:54:46.360]   but just walking here this morning under the bridge
[00:54:46.360 --> 00:54:48.680]   over the Colorado River, seeing the birds,
[00:54:48.680 --> 00:54:50.040]   knowing there's bat colonies,
[00:54:50.040 --> 00:54:51.480]   massive bat colonies around here
[00:54:51.480 --> 00:54:53.520]   that I got to visit a few years ago.
[00:54:53.520 --> 00:54:57.780]   I experienced one of those bat explosions.
[00:54:57.780 --> 00:54:59.220]   It's mind-blowing.
[00:54:59.220 --> 00:55:03.360]   I've been really lucky as a journalist
[00:55:03.360 --> 00:55:05.040]   to have gone to the North Pole,
[00:55:05.040 --> 00:55:08.840]   the camp on the sea ice with Russian help.
[00:55:08.840 --> 00:55:10.520]   This is a camp that was set up for tourists
[00:55:10.520 --> 00:55:12.360]   coming from Europe every year.
[00:55:12.360 --> 00:55:14.280]   There were scientists on the sea ice
[00:55:14.280 --> 00:55:18.000]   floating on the 14,000-foot-deep Arctic Ocean,
[00:55:18.000 --> 00:55:19.320]   and I was with them for several days.
[00:55:19.320 --> 00:55:22.440]   I wrote a book about that, too, along with my reporting.
[00:55:22.440 --> 00:55:25.360]   Been in the depths of the Amazon rainforest.
[00:55:25.360 --> 00:55:28.720]   When I was very young, I was a crew on a sailboat
[00:55:28.720 --> 00:55:31.200]   that sailed 2/3 of the way around the world.
[00:55:31.200 --> 00:55:33.160]   I was halfway across the Indian Ocean,
[00:55:33.160 --> 00:55:36.440]   again, in 14,000-foot-deep water.
[00:55:36.440 --> 00:55:39.160]   There was no wind, and we were,
[00:55:39.160 --> 00:55:40.760]   this was way before I was a journalist,
[00:55:40.760 --> 00:55:43.640]   22, 23 years old, and we went swimming,
[00:55:43.640 --> 00:55:46.020]   and swimming in 14,000-foot-deep water,
[00:55:46.020 --> 00:55:49.800]   500 miles from land, the Western Indian Ocean,
[00:55:49.800 --> 00:55:53.920]   halfway between Somalia and the Maldives.
[00:55:53.920 --> 00:55:59.720]   It's like so mind-boggling, chillingly fantastical thing,
[00:55:59.720 --> 00:56:02.120]   with a mask on, looking at your shadow
[00:56:02.120 --> 00:56:04.320]   going to the vanishing point below you,
[00:56:04.320 --> 00:56:06.760]   looking over at the boat, which is a 60-foot boat,
[00:56:06.760 --> 00:56:09.800]   but it just looks like a toy, and then getting back on
[00:56:09.800 --> 00:56:11.440]   and being beholden to the elements,
[00:56:11.440 --> 00:56:13.760]   the sailboat heading toward Djibouti.
[00:56:13.760 --> 00:56:15.080]   - The immensity and the power of the elements.
[00:56:15.080 --> 00:56:20.080]   - Oh my God, and then the human qualities are unbelievable.
[00:56:20.080 --> 00:56:25.480]   The Anthropocene, I played a bit of a role as a journalist
[00:56:25.480 --> 00:56:29.040]   in waking people up to the idea that this era
[00:56:29.040 --> 00:56:31.560]   called the Holocene, the last 11,000 years,
[00:56:31.560 --> 00:56:35.380]   since the last Ice Age, had ended.
[00:56:35.380 --> 00:56:38.320]   I wrote my 1992 book on global warming,
[00:56:39.480 --> 00:56:41.120]   thinking about all that we're just talking about,
[00:56:41.120 --> 00:56:43.160]   thinking about the wonders of the planet,
[00:56:43.160 --> 00:56:45.640]   thinking about the impact of humans so far
[00:56:45.640 --> 00:56:49.880]   in our explosive growth in the 20th century.
[00:56:49.880 --> 00:56:53.120]   I wrote that perhaps earth scientists of the future
[00:56:53.120 --> 00:56:57.200]   will name this post-Holocene era
[00:56:57.200 --> 00:57:00.160]   for its formative element for us,
[00:57:00.160 --> 00:57:05.480]   because we're kind of in charge in certain ways,
[00:57:05.480 --> 00:57:08.040]   you know, which is hubristic at the same time.
[00:57:08.040 --> 00:57:11.640]   It's like, you know, the variability of the climate system
[00:57:11.640 --> 00:57:13.920]   is still profound with or without global warming.
[00:57:13.920 --> 00:57:16.840]   - So this immense, powerful, beautiful organism
[00:57:16.840 --> 00:57:19.840]   that is earth, all the different sub-organisms
[00:57:19.840 --> 00:57:21.680]   that are on it, do you see humans
[00:57:21.680 --> 00:57:23.640]   as a kind of parasite on this earth?
[00:57:23.640 --> 00:57:24.880]   - No, no. - Or do you see it
[00:57:24.880 --> 00:57:29.440]   as something that helps the flourishing
[00:57:29.440 --> 00:57:31.200]   of the entire organism?
[00:57:31.200 --> 00:57:32.900]   - That can. - Can.
[00:57:32.900 --> 00:57:35.120]   Intelligence. - That hasn't yet.
[00:57:35.120 --> 00:57:35.960]   - Hasn't yet?
[00:57:36.800 --> 00:57:39.240]   I mean, aren't we on a,
[00:57:39.240 --> 00:57:41.520]   so the ability of the collective intelligence
[00:57:41.520 --> 00:57:43.520]   of the human species to develop
[00:57:43.520 --> 00:57:45.640]   all these kinds of technologies,
[00:57:45.640 --> 00:57:50.200]   and to be able to have Twitter to introspect onto itself.
[00:57:50.200 --> 00:57:51.040]   (Luke laughs)
[00:57:51.040 --> 00:57:51.880]   - We should get Twitter to the animals.
[00:57:51.880 --> 00:57:54.960]   - Oh, I think we're doing a, it's always--
[00:57:54.960 --> 00:57:56.320]   - In a way, we are. - It's catch-up.
[00:57:56.320 --> 00:57:58.880]   We're always in catch-up mode, you know.
[00:57:58.880 --> 00:58:01.080]   - Right. - I was at the Vatican
[00:58:01.080 --> 00:58:04.520]   for a big meeting in 2014 on sustainable humanity,
[00:58:04.520 --> 00:58:07.000]   sustainable nature, our responsibility.
[00:58:07.000 --> 00:58:11.400]   And it was a week of presentations by Martin Rees,
[00:58:11.400 --> 00:58:14.880]   who's this famed British scientist, physicist who--
[00:58:14.880 --> 00:58:16.360]   - Been on his podcast.
[00:58:16.360 --> 00:58:17.600]   - Yeah, great. - Yeah.
[00:58:17.600 --> 00:58:21.440]   - Well, he's fixated on existential risk, right?
[00:58:21.440 --> 00:58:22.660]   - Yes, he is. - So it was a week
[00:58:22.660 --> 00:58:27.400]   of this stuff, and the meeting was kicked off by,
[00:58:27.400 --> 00:58:31.120]   I wrote about it, Cardinal Maradiaga,
[00:58:31.120 --> 00:58:32.440]   who is, I think, from El Salvador.
[00:58:32.440 --> 00:58:34.040]   He's one of the Pope's kind of posse.
[00:58:34.040 --> 00:58:36.360]   He gave one of the initial speeches, and he said,
[00:58:36.360 --> 00:58:41.360]   "Nowadays, mankind looks like a technical giant
[00:58:41.360 --> 00:58:46.480]   "and an ethical child," meaning our technological wizardry
[00:58:46.480 --> 00:58:49.440]   is unbelievable, but it's way out in front of our ability
[00:58:49.440 --> 00:58:52.680]   to step back and kind of like consider
[00:58:52.680 --> 00:58:55.320]   in the full dimensions we need to, is it helping everybody?
[00:58:55.320 --> 00:58:59.440]   Is it, what are the consequences of CRISPR,
[00:58:59.440 --> 00:59:01.160]   you know, genetics, technology?
[00:59:01.160 --> 00:59:03.480]   And there's no single answer to that,
[00:59:03.480 --> 00:59:06.360]   if I'm in the African Union.
[00:59:06.360 --> 00:59:08.480]   I'm just using this as an example.
[00:59:08.480 --> 00:59:09.960]   CRISPR has emerged so fast.
[00:59:09.960 --> 00:59:13.320]   It can do so much by changing the nature of nature,
[00:59:13.320 --> 00:59:18.280]   in a kind of a programming way, you know, building genes,
[00:59:18.280 --> 00:59:21.520]   not just transferring them from one organism to another.
[00:59:21.520 --> 00:59:24.160]   We've only just begun to taste the fruits of that,
[00:59:24.160 --> 00:59:29.160]   literally, and it can wipe out a mosquito species.
[00:59:29.160 --> 00:59:30.300]   We know how to do that now.
[00:59:30.300 --> 00:59:35.300]   You can like literally take out the dengue-causing mosquito.
[00:59:35.300 --> 00:59:37.840]   The scientists have done the work, and you think,
[00:59:37.840 --> 00:59:39.980]   "Okay, cool, well, that's great."
[00:59:39.980 --> 00:59:43.820]   Now, there's this big fight over whether that should happen.
[00:59:43.820 --> 00:59:47.940]   African Union, and I'm with their view, says,
[00:59:47.940 --> 00:59:50.520]   "Hey, if we can take out a mosquito species
[00:59:50.520 --> 00:59:55.520]   "that's causing horrific, chronic loss through dengue,"
[00:59:55.520 --> 00:59:58.260]   which I had once in Indonesia, it's not fun,
[00:59:58.260 --> 01:00:01.340]   and we should do it, you know?
[01:00:01.340 --> 01:00:02.980]   And Europe-- - What's the other side
[01:00:02.980 --> 01:00:04.860]   of the argument? - The European Union,
[01:00:04.860 --> 01:00:08.100]   they're saying, using their,
[01:00:08.100 --> 01:00:11.620]   capital P, precautionary principle,
[01:00:11.620 --> 01:00:14.020]   says, "No, we can't meddle with nature."
[01:00:14.020 --> 01:00:15.940]   And this is just like we were talking with climate.
[01:00:15.940 --> 01:00:17.600]   You know, there's the real-time question
[01:00:17.600 --> 01:00:21.260]   and the long-term question, and there's the people
[01:00:21.260 --> 01:00:23.460]   who are just facing the need to get through the day
[01:00:23.460 --> 01:00:26.440]   and be healthy and survive and have enough food,
[01:00:26.440 --> 01:00:29.060]   which is not integrated sufficiently at all
[01:00:29.060 --> 01:00:32.440]   into the climate, stop climate change debate,
[01:00:32.440 --> 01:00:35.400]   and those who are trying to cut CO2,
[01:00:35.400 --> 01:00:38.300]   which will have a benefit in the future
[01:00:38.300 --> 01:00:43.300]   by limiting the fat-tail outcomes of this journey we're on.
[01:00:43.300 --> 01:00:45.600]   So when I think about the Anthropocene,
[01:00:45.600 --> 01:00:47.480]   I think about this planet.
[01:00:47.480 --> 01:00:50.640]   I love that we're here right now.
[01:00:50.640 --> 01:00:53.980]   I love that our species has these capacities.
[01:00:53.980 --> 01:00:55.480]   I would love for there to be
[01:00:55.480 --> 01:00:59.000]   a little bit more reflection in where things come from
[01:00:59.000 --> 01:01:02.420]   and where they might go, whether you're a student, a kid.
[01:01:02.420 --> 01:01:05.340]   What's your role?
[01:01:05.340 --> 01:01:07.620]   The wonderful thing about the complexity of it
[01:01:07.620 --> 01:01:09.760]   is everyone can play a role.
[01:01:09.760 --> 01:01:14.620]   If you're an artist or a designer or an architect
[01:01:14.620 --> 01:01:17.860]   or an economist or a podcaster,
[01:01:17.860 --> 01:01:20.120]   whatever you do, just tweak a little bit
[01:01:20.120 --> 01:01:23.140]   toward examining these questions,
[01:01:23.140 --> 01:01:26.940]   stepping back from the simplistic label-throwing
[01:01:26.940 --> 01:01:30.940]   toward what actually is the problem in front of me,
[01:01:30.940 --> 01:01:35.940]   whether it's in Pakistan or in Boston or wherever,
[01:01:35.940 --> 01:01:37.900]   you know, Florida.
[01:01:37.900 --> 01:01:39.400]   - Bjorn, what do you find beautiful
[01:01:39.400 --> 01:01:41.760]   about this collective intelligence machine we have?
[01:01:41.760 --> 01:01:43.180]   From an economics perspective,
[01:01:43.180 --> 01:01:46.900]   it's kind of fascinating that we're able to,
[01:01:46.900 --> 01:01:50.380]   there is a machine to it that we've built up
[01:01:50.380 --> 01:01:54.980]   that's able to represent interests and desires and value
[01:01:54.980 --> 01:01:59.640]   and hopes and dreams in sort of monetary ways
[01:01:59.640 --> 01:02:02.500]   that we can trade with each other,
[01:02:02.500 --> 01:02:04.220]   we can make agreements with each other,
[01:02:04.220 --> 01:02:05.580]   we can represent our goals
[01:02:05.580 --> 01:02:09.500]   and build companies that actually help and so on.
[01:02:09.500 --> 01:02:11.140]   Do you just step back every once in a while
[01:02:11.140 --> 01:02:13.660]   and marvel at the fact that a few billion of us
[01:02:13.660 --> 01:02:17.820]   are able to somehow not create complete chaos
[01:02:17.820 --> 01:02:22.020]   and actually collaborate and have collaborative disagreements
[01:02:22.020 --> 01:02:26.540]   that ultimately, or so far, have led to progress?
[01:02:26.540 --> 01:02:29.580]   - Yeah, I think fundamentally the point,
[01:02:29.580 --> 01:02:32.940]   apart from the fact that we should just be joyful
[01:02:32.940 --> 01:02:35.700]   of the fact that humans live here,
[01:02:35.700 --> 01:02:38.340]   I think it's incredibly important to remember
[01:02:38.340 --> 01:02:41.420]   how much progress we've had.
[01:02:41.420 --> 01:02:44.180]   Most people just don't stop to think about those stats.
[01:02:44.180 --> 01:02:47.620]   You know, I get that in the normal bustle of day,
[01:02:47.620 --> 01:02:50.020]   but just, you know, in 1900,
[01:02:50.020 --> 01:02:54.420]   the average person on the planet lived to be 32 years.
[01:02:54.420 --> 01:02:57.740]   32 years, that was our average life expectancy.
[01:02:57.740 --> 01:03:00.140]   Today, it's about 74.
[01:03:00.140 --> 01:03:04.140]   So we've literally got two lifetimes on this planet,
[01:03:04.140 --> 01:03:05.340]   each one of us.
[01:03:05.340 --> 01:03:09.020]   And, you know, every year you live in the rich world,
[01:03:09.020 --> 01:03:12.140]   you get to live three months longer,
[01:03:12.140 --> 01:03:14.420]   and the poor world is about four months longer
[01:03:14.420 --> 01:03:16.380]   because of medical advances,
[01:03:16.380 --> 01:03:18.460]   because we get better at dealing both with cancer
[01:03:18.460 --> 01:03:22.420]   and especially right now with heart disease.
[01:03:22.420 --> 01:03:24.060]   These are amazing achievements.
[01:03:24.060 --> 01:03:26.140]   Of course, it's a very, very small part of it.
[01:03:26.140 --> 01:03:28.660]   We're much better fed, we're much better educated.
[01:03:28.660 --> 01:03:31.260]   We've gone from a world where virtually everyone,
[01:03:31.260 --> 01:03:34.700]   or, you know, 90% were illiterate,
[01:03:34.700 --> 01:03:36.940]   to a world where more than 90% illiterate.
[01:03:36.940 --> 01:03:39.140]   This is an astounding opportunity.
[01:03:39.140 --> 01:03:44.140]   And 200 years ago, 95%, 94% of the world
[01:03:45.700 --> 01:03:49.100]   were extremely poor, that is less than a dollar a day.
[01:03:49.100 --> 01:03:54.100]   Today, for the first time in 2015, it was down below 10%.
[01:03:54.100 --> 01:03:57.180]   And again, these are kind of boring statistics,
[01:03:57.180 --> 01:04:00.300]   but they're also astounding testaments
[01:04:00.300 --> 01:04:02.440]   of how well humanity has done.
[01:04:02.440 --> 01:04:04.700]   So just on the point of,
[01:04:04.700 --> 01:04:06.820]   we've kind of just been focused
[01:04:06.820 --> 01:04:09.060]   on making our own world better.
[01:04:09.060 --> 01:04:10.100]   And in many ways, you know,
[01:04:10.100 --> 01:04:12.740]   so we've hunted a lot of big animals,
[01:04:12.740 --> 01:04:15.380]   either to extinction or down to much,
[01:04:15.380 --> 01:04:16.780]   much smaller populations,
[01:04:16.780 --> 01:04:19.380]   as much smaller populations of fish in the ocean.
[01:04:19.380 --> 01:04:21.300]   So there's a lot of things
[01:04:21.300 --> 01:04:24.460]   that sort of bear the brunt of our success.
[01:04:24.460 --> 01:04:26.300]   It's not because we're evil in that sense,
[01:04:26.300 --> 01:04:29.620]   it's just because we didn't care all that much about them.
[01:04:29.620 --> 01:04:33.100]   I think it is important as one funnel of that,
[01:04:33.100 --> 01:04:35.340]   I'm not gonna make a big deal out of it,
[01:04:35.340 --> 01:04:37.180]   but the fact that we're putting out more CO2
[01:04:37.180 --> 01:04:39.140]   in the atmosphere, because CO2,
[01:04:39.140 --> 01:04:42.580]   as you also mentioned before, it's actually plant food.
[01:04:42.580 --> 01:04:46.220]   You know, if you're a greenhouse grower,
[01:04:46.220 --> 01:04:48.580]   you know if you put in CO2 in your greenhouse,
[01:04:48.580 --> 01:04:51.460]   you actually get bigger and plumper tomatoes.
[01:04:51.460 --> 01:04:53.580]   And that's essentially what we're doing in the world.
[01:04:53.580 --> 01:04:55.380]   This has overall bad consequences,
[01:04:55.380 --> 01:04:58.380]   and that's why we should be doing something about it.
[01:04:58.380 --> 01:05:00.580]   But one of the good side effects
[01:05:00.580 --> 01:05:03.460]   is actually that the world is getting greener.
[01:05:03.460 --> 01:05:05.340]   So we get much more green stuff.
[01:05:05.340 --> 01:05:06.300]   Now, I don't know,
[01:05:06.300 --> 01:05:10.380]   and this is where I sort of show my economist roots,
[01:05:10.380 --> 01:05:15.380]   because if you just measure all living stuff in tons,
[01:05:15.380 --> 01:05:20.780]   so in weight, there's actually more living stuff
[01:05:20.780 --> 01:05:22.740]   than there were 100 years ago.
[01:05:22.740 --> 01:05:27.460]   Because elephants and all these other big fish and stuff
[01:05:27.460 --> 01:05:30.140]   are actually really, really small fraction of the world.
[01:05:30.140 --> 01:05:33.100]   So just the fact that we have,
[01:05:33.100 --> 01:05:35.220]   yes, so we have an enormous amount of live stuff,
[01:05:35.220 --> 01:05:37.220]   but that doesn't even measure it.
[01:05:37.220 --> 01:05:40.660]   It's mostly just wood, you know, wooden green stuff
[01:05:40.660 --> 01:05:43.500]   that has dramatically increased in the world.
[01:05:43.500 --> 01:05:46.620]   Now, we're still not there from what it was in 1500.
[01:05:46.620 --> 01:05:49.420]   So we've still cut down the world a lot,
[01:05:49.420 --> 01:05:51.660]   but we're actually making a much greener world.
[01:05:51.660 --> 01:05:54.740]   Again, not because we really cared or thought about it,
[01:05:54.740 --> 01:05:57.060]   but just sort of a side effect of what we're doing.
[01:05:57.060 --> 01:06:00.180]   I think the crucial bit to remember is,
[01:06:00.180 --> 01:06:02.820]   when you're poor and you worry about
[01:06:02.820 --> 01:06:05.140]   what's gonna happen the next day,
[01:06:05.140 --> 01:06:08.140]   this is just not your main issue.
[01:06:08.140 --> 01:06:12.740]   Am I killing too many large animals in the world?
[01:06:12.740 --> 01:06:16.300]   But when you're rich and you can actually sit in a podcast
[01:06:16.300 --> 01:06:18.660]   in a convenient place in Austin,
[01:06:18.660 --> 01:06:20.300]   you can also start thinking about this.
[01:06:20.300 --> 01:06:22.780]   So one of the crucial bits, I think,
[01:06:22.780 --> 01:06:24.980]   if we want to get the rest of the world
[01:06:24.980 --> 01:06:27.820]   to care about the environment, care about climate,
[01:06:27.820 --> 01:06:29.860]   care about all these other issues,
[01:06:29.860 --> 01:06:32.700]   we really need to get them out of poverty first.
[01:06:32.700 --> 01:06:35.020]   And it's a simple point that we often forget.
[01:06:35.020 --> 01:06:37.500]   - And get them connected to all these gifts.
[01:06:37.500 --> 01:06:38.540]   - Yes.
[01:06:38.540 --> 01:06:40.740]   - I have these memories of,
[01:06:40.740 --> 01:06:43.500]   I was reporting on the next big earthquake
[01:06:43.500 --> 01:06:47.420]   that's gonna devastate Istanbul in 2009.
[01:06:47.420 --> 01:06:53.540]   I was in a slum, immigrant, poor neighborhood,
[01:06:53.540 --> 01:06:56.900]   and walking around with an engineer
[01:06:56.900 --> 01:06:58.980]   pointing out to the buildings that were gonna fall down.
[01:06:58.980 --> 01:06:59.860]   This is all known.
[01:06:59.860 --> 01:07:03.060]   There was an earthquake in 1999, and the next one's coming.
[01:07:03.060 --> 01:07:04.820]   One of my advantages in covering climate
[01:07:04.820 --> 01:07:06.380]   is I've covered other kinds of disasters too,
[01:07:06.380 --> 01:07:07.860]   so it keeps my context,
[01:07:07.860 --> 01:07:11.100]   me in touch with other things we can do.
[01:07:11.100 --> 01:07:12.900]   So I'm walking around and interviewing everybody.
[01:07:12.900 --> 01:07:14.820]   Went to this school that's being retrofit.
[01:07:14.820 --> 01:07:16.460]   They actually were getting ahead of it there.
[01:07:16.460 --> 01:07:17.860]   The World Bank provided some funding
[01:07:17.860 --> 01:07:20.660]   to put in iron bars in the brick building.
[01:07:20.660 --> 01:07:25.260]   And I met these kids, and they came,
[01:07:25.260 --> 01:07:28.140]   when you're a journalist with a camera and stuff and a pad,
[01:07:28.140 --> 01:07:31.940]   you get swarmed by kids, mostly in developing countries.
[01:07:31.940 --> 01:07:33.780]   And so these kids are running up to me,
[01:07:33.780 --> 01:07:36.260]   and they weren't going like, "Are you American?"
[01:07:36.260 --> 01:07:38.860]   Or just, they were saying, "Facebook, Facebook."
[01:07:38.860 --> 01:07:41.820]   And I went, "That's interesting."
[01:07:41.820 --> 01:07:44.740]   And they led me to their little town,
[01:07:44.740 --> 01:07:47.460]   a little community center that had a bank of eight or 10
[01:07:47.460 --> 01:07:49.780]   pretty flimsy computers.
[01:07:49.780 --> 01:07:52.620]   And they were all there playing Farm,
[01:07:52.620 --> 01:07:54.500]   it was a game that was hot at that time on Facebook.
[01:07:54.500 --> 01:07:55.420]   - Farm? - Farm.
[01:07:55.420 --> 01:07:57.060]   - Farmville? - Farmville, yeah.
[01:07:57.060 --> 01:08:00.300]   And my son back in the Hudson Valley,
[01:08:00.300 --> 01:08:02.460]   I remember him playing it, and I thought,
[01:08:02.460 --> 01:08:06.580]   "Wow, that is so fricking cool that these kids."
[01:08:06.580 --> 01:08:08.220]   And actually, I became Facebook friends
[01:08:08.220 --> 01:08:11.140]   with a couple of them afterwards, we traded our,
[01:08:11.140 --> 01:08:15.140]   and I thought back to my youth when we had pen pals.
[01:08:15.140 --> 01:08:18.460]   I would write a letter to a kid in West Cameroon,
[01:08:18.460 --> 01:08:20.140]   and he would write back.
[01:08:20.140 --> 01:08:23.580]   And it took weeks, and it was a crinkly letter,
[01:08:23.580 --> 01:08:25.540]   and I never met him.
[01:08:25.540 --> 01:08:27.140]   And now you can kind of connect with people,
[01:08:27.140 --> 01:08:30.860]   and that all, through my blogging,
[01:08:30.860 --> 01:08:32.980]   at the New York Times, I was doing my regular reporting,
[01:08:32.980 --> 01:08:36.100]   but I launched a blog in 2007 called Dot Earth,
[01:08:36.100 --> 01:08:39.280]   which was all about what you were just describing,
[01:08:39.280 --> 01:08:41.700]   the newosphere, the connected world.
[01:08:41.700 --> 01:08:44.940]   That's a term from these two earliest,
[01:08:44.940 --> 01:08:46.140]   a Russian guy in early,
[01:08:46.140 --> 01:08:51.280]   Vernadsky and a French theologian and scientist,
[01:08:51.280 --> 01:08:55.580]   which is so interesting, Teilhard de Chardin.
[01:08:55.580 --> 01:08:58.140]   They had this idea in the early 20th century
[01:08:58.140 --> 01:09:00.840]   that we're creating a planet of the mind,
[01:09:00.840 --> 01:09:06.740]   that human intelligence can foster a better Earth.
[01:09:06.740 --> 01:09:09.980]   And I just became smitten with that,
[01:09:09.980 --> 01:09:12.500]   especially meeting kids in Istanbul slums
[01:09:12.500 --> 01:09:14.540]   who were on Facebook, looking at connectedness,
[01:09:14.540 --> 01:09:16.240]   what can you do with these tools,
[01:09:16.240 --> 01:09:18.500]   which is what drives me with my work now.
[01:09:18.500 --> 01:09:24.100]   But then there are these counter-currents
[01:09:24.100 --> 01:09:27.700]   that if the connectedness can cut back,
[01:09:27.700 --> 01:09:30.580]   it allowed Al-Qaeda to recruit,
[01:09:30.580 --> 01:09:32.740]   use decapitation videos to recruit
[01:09:32.740 --> 01:09:38.620]   distributed, disaffected young people into extremism.
[01:09:38.620 --> 01:09:42.160]   And there's lots of, these systems are not,
[01:09:42.160 --> 01:09:43.780]   they're just like every other tool, right?
[01:09:43.780 --> 01:09:46.180]   They're just for good or ill.
[01:09:46.180 --> 01:09:50.820]   And the efficiency thing, the economics of the world,
[01:09:50.820 --> 01:09:53.340]   which I also wrote about a little bit,
[01:09:53.340 --> 01:09:55.200]   late 20th century, it was so cool
[01:09:55.200 --> 01:09:58.320]   that everything became so efficient,
[01:09:58.320 --> 01:10:02.780]   that our supply chains are just in time manufacturing,
[01:10:02.780 --> 01:10:07.740]   getting the stuff from where the sources of the material are
[01:10:07.740 --> 01:10:10.220]   to the car factory and to get the car to the floor
[01:10:10.220 --> 01:10:11.900]   just in time for someone to buy it.
[01:10:11.900 --> 01:10:14.820]   And everyone got totally sucked in by that, including me.
[01:10:14.820 --> 01:10:17.600]   It's great, super efficient, cheaper.
[01:10:17.600 --> 01:10:18.980]   And then COVID hit
[01:10:18.980 --> 01:10:22.460]   and the whole supply chain concept crumbled.
[01:10:22.460 --> 01:10:24.900]   And one of the big lessons there, hopefully,
[01:10:24.900 --> 01:10:28.100]   and this is relevant to sustainability generally,
[01:10:28.100 --> 01:10:32.460]   is efficiency matters, but resilience matters too.
[01:10:32.460 --> 01:10:34.420]   And resilience is inefficient.
[01:10:34.420 --> 01:10:39.420]   You need redundancy or a variety of options, right?
[01:10:39.420 --> 01:10:42.900]   Which is not what corporate companies think about,
[01:10:42.900 --> 01:10:45.060]   which is not what, if you're only focused
[01:10:45.060 --> 01:10:48.380]   on a bottom line, short-term timeline,
[01:10:48.380 --> 01:10:51.540]   those disruptions are not what you're thinking about.
[01:10:51.540 --> 01:10:52.380]   You're still thinking about,
[01:10:52.380 --> 01:10:53.540]   can we get that widget here just in time
[01:10:53.540 --> 01:10:56.100]   for this thing to happen and then on we go.
[01:10:56.100 --> 01:10:58.960]   So it's kind of, I love the noosphere,
[01:10:58.960 --> 01:11:02.900]   this noosphere idea, the connectedness is fantastic.
[01:11:02.900 --> 01:11:06.020]   Oh, another thing, like in the early '90s,
[01:11:06.020 --> 01:11:08.660]   when I wrote my first book on global warming,
[01:11:08.660 --> 01:11:12.140]   it was for an exhibition at the Museum of Natural History.
[01:11:12.140 --> 01:11:13.980]   The Environmental Defense Fund was involved.
[01:11:13.980 --> 01:11:15.580]   They were like a partner,
[01:11:15.580 --> 01:11:18.100]   one of these longstanding environmental groups.
[01:11:18.100 --> 01:11:19.140]   And they're very old-fashioned.
[01:11:19.140 --> 01:11:20.300]   It's mostly lawyers, really,
[01:11:20.300 --> 01:11:22.340]   just using the Clean Air Act, Clean Water Act
[01:11:22.340 --> 01:11:24.200]   to litigate against pollution.
[01:11:24.200 --> 01:11:28.580]   And now, EDF is vastly bigger.
[01:11:28.580 --> 01:11:29.940]   And they're actually, this coming year,
[01:11:29.940 --> 01:11:31.540]   they're launching a satellite.
[01:11:31.540 --> 01:11:35.500]   An environmental group is launching methane sat.
[01:11:35.500 --> 01:11:37.740]   And it's providing a view, an independent view
[01:11:37.740 --> 01:11:40.220]   of where there's this gas.
[01:11:40.220 --> 01:11:41.140]   You know, it's the same thing,
[01:11:41.140 --> 01:11:42.700]   natural gas is basically methane.
[01:11:42.700 --> 01:11:47.580]   So if you have a leak, whether it's in Siberia or in Oklahoma
[01:11:47.580 --> 01:11:49.860]   you can cross-reference, you can ground,
[01:11:49.860 --> 01:11:52.220]   you can identify the hotspot,
[01:11:52.220 --> 01:11:56.580]   you can know where the problem is to fix in so many ways.
[01:11:56.580 --> 01:11:57.500]   And that's just one example.
[01:11:57.500 --> 01:11:59.820]   I'm like, if someone had told me in 1993
[01:11:59.820 --> 01:12:01.860]   that EDF was gonna launch a methane satellite,
[01:12:01.860 --> 01:12:02.980]   I would have laughed out loud.
[01:12:02.980 --> 01:12:05.380]   So technology plays a huge role
[01:12:05.380 --> 01:12:08.460]   if it's kind of employed
[01:12:08.460 --> 01:12:11.220]   with the bigger vision and leadership.
[01:12:11.220 --> 01:12:13.980]   - So Bjorn, you wrote, one of the books you wrote,
[01:12:13.980 --> 01:12:16.260]   the most recent one called "False Alarm,
[01:12:16.260 --> 01:12:19.860]   "How Climate Change Panic Costs Us Trillions,
[01:12:19.860 --> 01:12:23.940]   "Hurts the Poor and Fails to Fix the Planet."
[01:12:23.940 --> 01:12:25.540]   Good title by the way, very intense,
[01:12:25.540 --> 01:12:26.980]   makes me wanna read it.
[01:12:26.980 --> 01:12:31.100]   "What is likely the worst effect of climate change?"
[01:12:31.100 --> 01:12:34.700]   - First let me just, my editor actually hated the subtitle
[01:12:34.700 --> 01:12:36.820]   because it gives away the whole book.
[01:12:36.820 --> 01:12:39.500]   Basically, it tells you what the book tries to make.
[01:12:39.500 --> 01:12:41.980]   I think that's exactly what it should be.
[01:12:41.980 --> 01:12:44.220]   It's about getting this conversation out
[01:12:44.220 --> 01:12:46.220]   in the public sphere.
[01:12:46.220 --> 01:12:50.220]   So the worst thing that climate change can do
[01:12:50.220 --> 01:12:52.940]   is like the worst thing that anything can do
[01:12:52.940 --> 01:12:55.700]   is that it wipes out everything and we all die.
[01:12:55.700 --> 01:12:57.980]   So it's not like,
[01:12:57.980 --> 01:13:00.540]   if you're just looking for worst case outcomes,
[01:13:00.540 --> 01:13:04.940]   anything can get to the worst case outcome.
[01:13:04.940 --> 01:13:07.820]   Imagine if we, what's the worst thing
[01:13:07.820 --> 01:13:10.180]   that could happen from HIV?
[01:13:10.180 --> 01:13:14.700]   It breaks down one or more African states
[01:13:14.700 --> 01:13:16.340]   because we don't fix it.
[01:13:16.340 --> 01:13:20.260]   And then you get sort of biological warfare and terrorism,
[01:13:20.260 --> 01:13:21.500]   throw that in the mix,
[01:13:21.500 --> 01:13:23.220]   and then you get someone who makes a virus
[01:13:23.220 --> 01:13:24.700]   and kills the whole world.
[01:13:24.700 --> 01:13:27.580]   You can make worst case scenarios for everything.
[01:13:27.580 --> 01:13:29.380]   - Well, let's just call it, I get the point.
[01:13:29.380 --> 01:13:31.100]   And I'm sorry for the interruption.
[01:13:31.100 --> 01:13:33.260]   And I appreciate worst case analysis
[01:13:33.260 --> 01:13:35.620]   'cause I am fundamentally a computer scientist
[01:13:35.620 --> 01:13:38.420]   and that was the thing that defined the discipline
[01:13:38.420 --> 01:13:40.980]   of the measure, the quality of the algorithm,
[01:13:40.980 --> 01:13:44.340]   you measure what is its worst case performance.
[01:13:44.340 --> 01:13:45.540]   That's the big O notation.
[01:13:45.540 --> 01:13:46.940]   That's how you discuss algorithms.
[01:13:46.940 --> 01:13:49.820]   What is the worst possible thing
[01:13:49.820 --> 01:13:52.600]   in terms of performance this thing can do?
[01:13:52.600 --> 01:13:57.340]   But for climate change, let's even go crazy.
[01:13:57.340 --> 01:14:01.200]   What is exactly the worst case scenario for climate change?
[01:14:01.200 --> 01:14:04.420]   Because I have to be honest and say,
[01:14:04.420 --> 01:14:08.020]   I haven't really paid deep attention.
[01:14:08.020 --> 01:14:10.060]   I just have a lot of colleagues
[01:14:10.060 --> 01:14:13.120]   who think about climate and so on.
[01:14:13.120 --> 01:14:15.420]   And there's a kind of in the alarmism,
[01:14:15.420 --> 01:14:19.680]   there was a sense why this is a very serious problem.
[01:14:19.680 --> 01:14:22.740]   And then the sentence would never finish.
[01:14:22.740 --> 01:14:24.140]   What exactly is the problem?
[01:14:24.140 --> 01:14:27.260]   Well, the extinction of the human species, okay.
[01:14:27.260 --> 01:14:30.700]   With a virus, I understand how that can possibly happen.
[01:14:30.700 --> 01:14:33.580]   What is the mechanism by which the human species
[01:14:33.580 --> 01:14:36.380]   becomes extinct because of climate change?
[01:14:36.380 --> 01:14:38.580]   - I'm not sure I would want to be able to argue that
[01:14:38.580 --> 01:14:40.100]   because it really requires you to have
[01:14:40.100 --> 01:14:43.120]   sort of very, very extreme parameter choices
[01:14:43.120 --> 01:14:44.680]   all down the line.
[01:14:44.680 --> 01:14:46.820]   And so it's more, it's this kind of idea
[01:14:46.820 --> 01:14:50.600]   that we hit some of these unexpected outcomes.
[01:14:50.600 --> 01:14:53.600]   So for instance, the Western Arctic ice sheet
[01:14:53.600 --> 01:14:55.620]   melts really, really quickly.
[01:14:55.620 --> 01:14:58.080]   It doesn't look like that can happen really, really quickly.
[01:14:58.080 --> 01:15:00.240]   But let's just say that this could happen
[01:15:00.240 --> 01:15:02.120]   within a hundred years or something.
[01:15:02.120 --> 01:15:05.120]   So we basically get what, seven meters,
[01:15:05.120 --> 01:15:07.880]   what is that, 20 feet of sea level rise.
[01:15:08.940 --> 01:15:11.320]   That will be a real challenge to a lot of places
[01:15:11.320 --> 01:15:12.200]   around the world.
[01:15:12.200 --> 01:15:14.720]   This would have significant costs.
[01:15:14.720 --> 01:15:17.480]   It's likely, and there's actually been a study
[01:15:17.480 --> 01:15:19.880]   that's tried to estimate, could we deal with that?
[01:15:19.880 --> 01:15:24.880]   And the short answer is yes, if you're fairly well off.
[01:15:24.880 --> 01:15:27.280]   If you're Holland, you can definitely deal with it.
[01:15:27.280 --> 01:15:30.120]   It's also likely that most developing countries
[01:15:30.120 --> 01:15:32.160]   are gonna be much closer to Holland
[01:15:32.160 --> 01:15:33.400]   towards the end of the century
[01:15:33.400 --> 01:15:34.880]   because they'll be much richer.
[01:15:34.880 --> 01:15:36.360]   So they can probably handle it,
[01:15:36.360 --> 01:15:37.680]   but it will be a real challenge.
[01:15:37.680 --> 01:15:39.140]   - May I ask a dumb question?
[01:15:39.140 --> 01:15:43.140]   What happens when the sea level rises exactly?
[01:15:43.140 --> 01:15:45.820]   What is the painful aspect of that?
[01:15:45.820 --> 01:15:48.780]   - It is that all of your current infrastructure
[01:15:48.780 --> 01:15:51.380]   in a lot of coastal cities around the world
[01:15:51.380 --> 01:15:53.240]   that are literally built on,
[01:15:53.240 --> 01:15:54.700]   Jakarta is a good example,
[01:15:54.700 --> 01:15:56.540]   that are literally built on the,
[01:15:56.540 --> 01:16:00.420]   inches above the sea level.
[01:16:00.420 --> 01:16:02.420]   If you then get a sea level rise,
[01:16:02.420 --> 01:16:05.300]   they'll rise say, what would 20 feet,
[01:16:05.300 --> 01:16:08.780]   that would be like a third or a fourth of a foot every year.
[01:16:08.780 --> 01:16:11.960]   - Yeah, I see no evidence that that's even.
[01:16:11.960 --> 01:16:14.220]   - But hold on a second, we're not talking about evidence.
[01:16:14.220 --> 01:16:16.780]   We're talking about worst case analysis and algorithm.
[01:16:16.780 --> 01:16:20.200]   - And so basically you would see your infrastructure,
[01:16:20.200 --> 01:16:24.460]   all your stuff very quickly being very, very challenged.
[01:16:24.460 --> 01:16:27.660]   And you basically have to put up huge sea walls
[01:16:27.660 --> 01:16:29.620]   or migrate out of that area.
[01:16:29.620 --> 01:16:30.820]   - Very quickly.
[01:16:30.820 --> 01:16:33.380]   - Well, very quickly as in 50 years or something.
[01:16:33.380 --> 01:16:38.380]   - Right, so like, is that as a human species,
[01:16:38.380 --> 01:16:42.220]   we're not able to respond to that kind of threat?
[01:16:42.220 --> 01:16:43.060]   - Of course we are.
[01:16:43.060 --> 01:16:45.420]   And look, again, the point here is,
[01:16:45.420 --> 01:16:47.540]   then there's a lot of other arguments.
[01:16:47.540 --> 01:16:50.380]   And I should just put the disclaimer,
[01:16:50.380 --> 01:16:52.120]   this is not what I think is correct,
[01:16:52.120 --> 01:16:55.460]   but you're asking me what's the worst case outcome
[01:16:55.460 --> 01:16:56.600]   that you have.
[01:16:56.600 --> 01:17:00.140]   So most of global warming is really about
[01:17:00.140 --> 01:17:03.280]   that we're used to one way of doing things.
[01:17:03.280 --> 01:17:07.700]   So, we live in Jakarta because it's right next to the sea.
[01:17:07.700 --> 01:17:10.160]   We're used to the sea being at this level.
[01:17:10.160 --> 01:17:13.900]   We grow our crops because we're used to,
[01:17:13.900 --> 01:17:16.300]   you grow corn here, you grow wheat here
[01:17:16.300 --> 01:17:18.900]   because we're used to that's where the precipitation
[01:17:18.900 --> 01:17:22.420]   and the temperature is the right for this kind of crop.
[01:17:22.420 --> 01:17:26.800]   If this changes, and this is the same thing with houses,
[01:17:26.800 --> 01:17:28.900]   if it gets colder, if it gets warmer,
[01:17:28.900 --> 01:17:30.000]   it's suddenly uncomfortable
[01:17:30.000 --> 01:17:32.140]   because you've built your house wrong.
[01:17:32.140 --> 01:17:35.780]   So our infrastructure will be wrong if the world changes.
[01:17:35.780 --> 01:17:36.940]   And that's what climate change does.
[01:17:36.940 --> 01:17:38.180]   - At a large scale.
[01:17:38.180 --> 01:17:42.100]   - Yes, and so this is a problem in most of these senses.
[01:17:42.100 --> 01:17:45.140]   But if you then sort of take it to the extreme and say,
[01:17:45.140 --> 01:17:48.100]   well, imagine that you're gonna get a huge sea level rise.
[01:17:48.100 --> 01:17:50.380]   Imagine that you're gonna get a very different
[01:17:50.380 --> 01:17:52.180]   sort of precipitation, for instance,
[01:17:52.180 --> 01:17:55.100]   what is it, the rain season,
[01:17:55.100 --> 01:18:00.100]   monsoon in the Indian subcontinent changes dramatically.
[01:18:01.700 --> 01:18:03.900]   That could affect a lot of agriculture
[01:18:03.900 --> 01:18:05.800]   and make it really hard to imagine
[01:18:05.800 --> 01:18:07.860]   that you could feed India well.
[01:18:07.860 --> 01:18:11.100]   There are these kinds of things where you can imagine
[01:18:11.100 --> 01:18:14.820]   and then that this would be very difficult to deal with.
[01:18:14.820 --> 01:18:16.780]   And then if you add all of it up,
[01:18:16.780 --> 01:18:19.240]   you could possibly get sort of a system collapse
[01:18:19.240 --> 01:18:21.580]   because you just have too many problems in one.
[01:18:21.580 --> 01:18:23.420]   - Is it possible to model those kinds of things?
[01:18:23.420 --> 01:18:28.420]   So what I understand is the sea level rise itself
[01:18:29.720 --> 01:18:32.200]   isn't the destructive thing.
[01:18:32.200 --> 01:18:35.360]   It's the fact that it creates migration patterns
[01:18:35.360 --> 01:18:38.440]   and human tension, battle over resources.
[01:18:38.440 --> 01:18:43.440]   And so you start to get these human things, human conflict.
[01:18:43.440 --> 01:18:46.960]   So the big negative impact won't be necessarily
[01:18:46.960 --> 01:18:48.920]   from the fact that you have to move your house.
[01:18:48.920 --> 01:18:51.220]   It's the fact that once you move your house,
[01:18:51.220 --> 01:18:53.160]   that means something else down the line.
[01:18:53.160 --> 01:18:55.400]   And this is secondary tertiary effects
[01:18:55.400 --> 01:18:59.240]   that can have potentially to wars, military conflict,
[01:18:59.240 --> 01:19:02.360]   can have destabilized entire economies,
[01:19:02.360 --> 01:19:04.680]   all that kind of stuff because of the migration pattern.
[01:19:04.680 --> 01:19:07.040]   Is it possible to model those kinds of things?
[01:19:07.040 --> 01:19:08.800]   - So there are people who looked at this
[01:19:08.800 --> 01:19:12.320]   and surprisingly again, most people will move
[01:19:12.320 --> 01:19:14.640]   within their country for a lot of different reasons,
[01:19:14.640 --> 01:19:17.960]   but mainly language and political structure.
[01:19:17.960 --> 01:19:20.640]   You have your money, you have your relationships there.
[01:19:20.640 --> 01:19:23.600]   So it's not like we're gonna see these big moves
[01:19:23.600 --> 01:19:28.600]   from the Southern Mexico and Central America
[01:19:28.720 --> 01:19:32.000]   up to the US or from Africa up to the EU.
[01:19:32.000 --> 01:19:33.800]   That's not predominantly because of climate.
[01:19:33.800 --> 01:19:38.520]   That's because there's a lot of welfare opportunity.
[01:19:38.520 --> 01:19:40.640]   You can make your life much, much better
[01:19:40.640 --> 01:19:42.040]   and you can become much more productive
[01:19:42.040 --> 01:19:45.280]   if you move into a richer country.
[01:19:45.280 --> 01:19:47.500]   So yes, there are these issues.
[01:19:47.500 --> 01:19:50.320]   Again, you're asking me for sort of what is it
[01:19:50.320 --> 01:19:52.560]   that could really sort of break down the world?
[01:19:52.560 --> 01:19:55.720]   I think the fundamental point is to recognize
[01:19:55.720 --> 01:19:57.720]   that it's not like we haven't dealt
[01:19:57.720 --> 01:20:00.480]   with huge challenges in the past
[01:20:00.480 --> 01:20:02.240]   and we've dealt with them really well.
[01:20:02.240 --> 01:20:05.320]   So just one fun thing, I encourage everyone
[01:20:05.320 --> 01:20:09.680]   to just look that up on Wikipedia, the rising of Chicago.
[01:20:09.680 --> 01:20:14.680]   So in the 1850s, Chicago was a terribly dirty place
[01:20:14.680 --> 01:20:18.320]   and they didn't have good sewers.
[01:20:18.320 --> 01:20:21.900]   And so they decided, and we can't really make up all,
[01:20:21.900 --> 01:20:26.400]   they decided to raise Chicago one to two feet.
[01:20:26.400 --> 01:20:28.760]   And so they simply took one block at a time.
[01:20:28.760 --> 01:20:31.440]   They put like 50,000 jacks underneath a building
[01:20:31.440 --> 01:20:32.640]   and they would just raise the building
[01:20:32.640 --> 01:20:34.240]   and then they'd go on to the next building.
[01:20:34.240 --> 01:20:37.360]   They raised all of Chicago one to two feet.
[01:20:37.360 --> 01:20:39.640]   This is almost 200 years ago.
[01:20:39.640 --> 01:20:42.200]   Of course, we will be able to deal with these things.
[01:20:42.200 --> 01:20:45.520]   I'm not saying it'll be fun or that it'll be cheap.
[01:20:45.520 --> 01:20:48.160]   Of course, we would rather not have to deal with this,
[01:20:48.160 --> 01:20:50.200]   but we're a very inventive species.
[01:20:50.200 --> 01:20:53.020]   And so it's very unlikely that we'll not be able to--
[01:20:53.020 --> 01:20:57.200]   - What about COVID pandemic just said, hold my beer.
[01:20:57.200 --> 01:21:03.740]   The response of human civilization to the COVID pandemic
[01:21:03.740 --> 01:21:07.200]   seems to have not, they didn't find the car jacks.
[01:21:07.200 --> 01:21:08.020]   (laughing)
[01:21:08.020 --> 01:21:08.860]   - Oh, yeah.
[01:21:08.860 --> 01:21:10.900]   - It seems to have not been as effective
[01:21:10.900 --> 01:21:15.900]   as I would have hoped for as a human that believes
[01:21:15.900 --> 01:21:19.740]   in the basic competence of leadership
[01:21:19.740 --> 01:21:20.920]   and all that kind of stuff.
[01:21:20.920 --> 01:21:24.000]   It seems that given the COVID pandemic,
[01:21:24.000 --> 01:21:27.020]   luckily did not turn out to be a pandemic
[01:21:27.020 --> 01:21:30.460]   that would eradicate most of the human species,
[01:21:30.460 --> 01:21:32.620]   which is something you always have to consider
[01:21:32.620 --> 01:21:35.460]   and worry about, that I would have hoped
[01:21:35.460 --> 01:21:37.280]   we would have less economic impact
[01:21:37.280 --> 01:21:39.620]   and we would respond more effectively
[01:21:39.620 --> 01:21:44.620]   and in terms of policy, in terms of socially, medically,
[01:21:44.620 --> 01:21:45.600]   all that kind of stuff.
[01:21:45.600 --> 01:21:49.900]   So if the COVID pandemic brought the world to its knees,
[01:21:49.900 --> 01:21:53.440]   then what does a sea level rise?
[01:21:53.440 --> 01:21:55.240]   - I think there's a different kind of thing
[01:21:55.240 --> 01:21:57.300]   that happened in the COVID.
[01:21:57.300 --> 01:21:59.760]   So politicians, a lot of politicians,
[01:21:59.760 --> 01:22:04.000]   I think made certainly suboptimal decisions,
[01:22:04.000 --> 01:22:06.480]   but I also find the fact that we actually managed
[01:22:06.480 --> 01:22:09.160]   to get a vaccine in a year.
[01:22:09.160 --> 01:22:12.480]   We should not be sort of unaware of the fact that,
[01:22:12.480 --> 01:22:14.000]   yes, we did a lot of stupid stuff
[01:22:14.000 --> 01:22:15.920]   and a lot of people were really, really annoyed,
[01:22:15.920 --> 01:22:18.440]   but fundamentally we fixed this.
[01:22:18.440 --> 01:22:20.520]   We could have done it better and prettier.
[01:22:20.520 --> 01:22:24.120]   I mean, I rode through the COVID pandemic
[01:22:24.120 --> 01:22:25.320]   in Southern Sweden.
[01:22:25.320 --> 01:22:30.020]   Yes, we can have that whole conversation.
[01:22:30.020 --> 01:22:32.840]   It was certainly much easier to live there
[01:22:32.840 --> 01:22:36.440]   than many other places, but the fundamental point was,
[01:22:36.440 --> 01:22:37.480]   we actually fixed it.
[01:22:37.480 --> 01:22:40.080]   So yes, we'll do, and we'll do that with climate.
[01:22:40.080 --> 01:22:41.960]   We'll make a lot of bad decisions
[01:22:41.960 --> 01:22:43.580]   and we'll waste a lot of money,
[01:22:43.580 --> 01:22:45.400]   like we do with all other problems,
[01:22:45.400 --> 01:22:47.400]   but are we gonna fix this?
[01:22:47.400 --> 01:22:48.520]   - Yeah.
[01:22:48.520 --> 01:22:51.560]   - Can you add onto that uncomfortable discussion
[01:22:51.560 --> 01:22:54.040]   of what's the worst thing that could possibly happen?
[01:22:54.040 --> 01:22:56.840]   - I'm not worried about the sea level rise component,
[01:22:56.840 --> 01:22:59.200]   certainly not nearly as much as the heat
[01:22:59.200 --> 01:23:03.000]   and disruption of agriculture patterns and water supplies.
[01:23:03.000 --> 01:23:05.420]   And a lot of it relates to, again,
[01:23:05.420 --> 01:23:07.980]   path dependency and history.
[01:23:07.980 --> 01:23:11.440]   Farmers are the heroes of humanity all through history
[01:23:11.440 --> 01:23:13.120]   'cause they're incredibly adaptable
[01:23:13.120 --> 01:23:18.220]   if you give them access to resources.
[01:23:18.220 --> 01:23:20.780]   In some cases, it's just crop insurance,
[01:23:20.780 --> 01:23:23.240]   which is really, basically still impossible
[01:23:23.240 --> 01:23:24.960]   to get in big chunks of Africa
[01:23:24.960 --> 01:23:26.560]   to get you through those hard spots.
[01:23:26.560 --> 01:23:29.400]   But the heat issue is the one that's most,
[01:23:29.400 --> 01:23:32.960]   the most basic element related to global warming
[01:23:32.960 --> 01:23:37.960]   from CO2 buildup is hotter heat waves.
[01:23:37.960 --> 01:23:40.280]   There's still some lack of evidence
[01:23:40.280 --> 01:23:44.360]   of the intensification, but the duration,
[01:23:44.360 --> 01:23:47.480]   and that's what really matters for heat,
[01:23:47.480 --> 01:23:51.000]   is how many days seems to be very powerfully linked
[01:23:51.000 --> 01:23:52.560]   to global warming.
[01:23:52.560 --> 01:23:55.800]   And so how many people die as a result of that is important.
[01:23:55.800 --> 01:24:00.080]   - So we're talking about, maybe you can also educate me,
[01:24:00.080 --> 01:24:03.840]   what's the average projection for the next 100 years
[01:24:03.840 --> 01:24:07.000]   as the temperature rises at two degrees Celsius?
[01:24:07.000 --> 01:24:09.760]   - Well, yeah, although this gets us
[01:24:09.760 --> 01:24:11.280]   into the modeling realm.
[01:24:11.280 --> 01:24:13.920]   You're assuming, you have to assume
[01:24:13.920 --> 01:24:16.800]   different emissions possibilities.
[01:24:16.800 --> 01:24:20.640]   You have to assume we still don't know the basic physics,
[01:24:20.640 --> 01:24:24.080]   like how many clouds form in a warming climate
[01:24:24.080 --> 01:24:26.840]   and how that relates to limiting warming.
[01:24:26.840 --> 01:24:29.240]   There are aspects of the fundamental warming question
[01:24:29.240 --> 01:24:30.840]   that are still deeply uncertain.
[01:24:30.840 --> 01:24:33.840]   - But the debate is like two, three, or four Celsius.
[01:24:33.840 --> 01:24:34.680]   - It's in that range.
[01:24:34.680 --> 01:24:38.800]   - But the thing is, all of those are bad for,
[01:24:38.800 --> 01:24:40.920]   this is an educational question.
[01:24:40.920 --> 01:24:41.760]   - Sure.
[01:24:41.760 --> 01:24:46.440]   - It doesn't seem like that much from a weather perspective,
[01:24:46.440 --> 01:24:48.440]   if you just turn up the AC and so on
[01:24:48.440 --> 01:24:50.640]   in your own personal home.
[01:24:50.640 --> 01:24:52.760]   But it is, from a global perspective,
[01:24:52.760 --> 01:24:55.040]   a huge impact on agriculture.
[01:24:55.040 --> 01:24:58.480]   - Well, yeah, and getting back to sea level and glaciers,
[01:24:58.480 --> 01:25:02.040]   the melting point of ice is a number.
[01:25:02.040 --> 01:25:02.880]   - Yeah.
[01:25:02.880 --> 01:25:04.120]   - And so if you pass that number,
[01:25:04.120 --> 01:25:06.040]   things start to change.
[01:25:06.040 --> 01:25:08.760]   What became known about Antarctica and Greenland more
[01:25:08.760 --> 01:25:10.880]   is that its ocean temperature,
[01:25:10.880 --> 01:25:15.200]   the seawater in and around and under these ice sheets,
[01:25:15.200 --> 01:25:18.120]   'cause it kind of gets under parts of Antarctica,
[01:25:18.120 --> 01:25:20.920]   is what's driving the dynamics
[01:25:20.920 --> 01:25:23.280]   that could lead to more abrupt change,
[01:25:23.280 --> 01:25:25.440]   more than air temperature.
[01:25:25.440 --> 01:25:27.400]   Glaciers, these big ice sheets live or die
[01:25:27.400 --> 01:25:29.680]   based on how much snow falls
[01:25:29.680 --> 01:25:32.200]   and how much ice leaves every year.
[01:25:32.200 --> 01:25:36.160]   And I was up on the Greenland ice sheet in 2004
[01:25:36.160 --> 01:25:40.440]   and written about it forever since then.
[01:25:40.440 --> 01:25:43.000]   It's the same amount of water that's in the Gulf of Mexico
[01:25:43.000 --> 01:25:45.280]   as if God or some great force came down
[01:25:45.280 --> 01:25:48.000]   and flash flows the Gulf of Mexico
[01:25:48.000 --> 01:25:49.320]   and plunked it up on land.
[01:25:49.320 --> 01:25:50.280]   That's the ice sheet.
[01:25:50.280 --> 01:25:51.600]   It's a lot of water.
[01:25:51.600 --> 01:25:54.760]   That's 23 feet of sea level rise.
[01:25:54.760 --> 01:25:56.720]   But you were not gonna melt it all.
[01:25:56.720 --> 01:26:01.720]   And the pace at which that erosion begins
[01:26:02.560 --> 01:26:05.800]   and becomes sort of a runaway train
[01:26:05.800 --> 01:26:09.160]   is still not well understood.
[01:26:09.160 --> 01:26:14.160]   That change from like a manageable level of sea level rise
[01:26:14.160 --> 01:26:16.040]   from these ice sheets
[01:26:16.040 --> 01:26:18.240]   to something that becomes truly unstoppable
[01:26:18.240 --> 01:26:19.640]   or that has these discontinuities
[01:26:19.640 --> 01:26:22.560]   where you get a lot more all of a sudden,
[01:26:22.560 --> 01:26:26.200]   to me, it's in the realm of what I've taken to calling
[01:26:26.200 --> 01:26:27.320]   known unknowables.
[01:26:27.320 --> 01:26:30.760]   Like don't count on another IPCC report
[01:26:30.760 --> 01:26:33.040]   magically including science that says,
[01:26:33.040 --> 01:26:37.560]   aha, now we know it's gonna be five feet by 2100.
[01:26:37.560 --> 01:26:38.840]   Because learning,
[01:26:38.840 --> 01:26:40.920]   there's a lot of negative learning in science.
[01:26:40.920 --> 01:26:43.320]   This may be true in your body of science too.
[01:26:43.320 --> 01:26:47.480]   There's a guy named Jeremy Bassis, B-A-S-S-I-S,
[01:26:47.480 --> 01:26:51.280]   who wrote a paper about this West Antarctic,
[01:26:51.280 --> 01:26:55.560]   the idea that you could get this sudden cliff breakdown
[01:26:55.560 --> 01:26:58.920]   of these ice shelves around Antarctica
[01:26:58.920 --> 01:27:01.200]   leading to rapid sea level rise.
[01:27:01.200 --> 01:27:02.880]   He did more modeling in physics
[01:27:02.880 --> 01:27:05.120]   and it turns out that you end up with,
[01:27:05.120 --> 01:27:08.080]   it's a much more progressive and self-limiting phenomenon.
[01:27:08.080 --> 01:27:11.000]   But those papers don't get any attention in the media
[01:27:11.000 --> 01:27:12.440]   because-- - They're not scary.
[01:27:12.440 --> 01:27:15.440]   - They're not scary and they're sort of after the fact.
[01:27:15.440 --> 01:27:16.280]   Just this past year,
[01:27:16.280 --> 01:27:18.680]   there's been this cycle around collapse,
[01:27:18.680 --> 01:27:22.720]   the word collapse and Antarctic ice.
[01:27:22.720 --> 01:27:27.000]   It started actually several years ago
[01:27:27.000 --> 01:27:29.480]   with the idea that the West Antarctic ice sheet
[01:27:29.480 --> 01:27:31.080]   is particularly vulnerable.
[01:27:31.080 --> 01:27:33.400]   And some paper, everyone, the science community,
[01:27:33.400 --> 01:27:34.600]   like the birds we were talking about,
[01:27:34.600 --> 01:27:39.080]   flocks to it and some high profile papers are written.
[01:27:39.080 --> 01:27:41.480]   And then a deeper inquiry reveals,
[01:27:41.480 --> 01:27:43.120]   you know, it's more complicated than that.
[01:27:43.120 --> 01:27:45.800]   And we, the journalists, the media,
[01:27:45.800 --> 01:27:49.400]   pundits don't pay attention to that stuff.
[01:27:49.400 --> 01:27:54.040]   And actually, which is why I started to develop
[01:27:54.040 --> 01:27:56.480]   kind of a dictionary, I call it watchwords,
[01:27:56.480 --> 01:27:58.520]   like words to, if you're out there,
[01:27:58.520 --> 01:28:02.400]   you're just a public person,
[01:28:02.400 --> 01:28:04.280]   you wanna know what's really going on.
[01:28:04.280 --> 01:28:08.520]   You hear these words like collapse in the context of ice,
[01:28:08.520 --> 01:28:09.840]   what do you do with that?
[01:28:09.840 --> 01:28:12.560]   And so I've created conversations around these words.
[01:28:12.560 --> 01:28:15.680]   Geologists and ice scientists use the word collapse.
[01:28:15.680 --> 01:28:18.040]   They're talking about a centuries long process.
[01:28:18.040 --> 01:28:20.880]   They're not talking about the World Trade Center.
[01:28:20.880 --> 01:28:24.880]   And scientists would do well to be more careful
[01:28:24.880 --> 01:28:26.040]   with words like that.
[01:28:26.040 --> 01:28:29.440]   Unless your focus is what we were saying earlier,
[01:28:29.440 --> 01:28:33.240]   your idea that alarming people will spur them to act,
[01:28:33.240 --> 01:28:35.640]   then you use that word carelessly.
[01:28:35.640 --> 01:28:38.240]   - Can I just follow up on the other point
[01:28:38.240 --> 01:28:40.440]   that you said, you know, two, three, four degrees,
[01:28:40.440 --> 01:28:42.040]   you know, that doesn't sound like much,
[01:28:42.040 --> 01:28:44.400]   I can just crank up the air conditioning.
[01:28:44.400 --> 01:28:46.440]   I think that sort of touches on a really,
[01:28:46.440 --> 01:28:49.960]   really important point that for most rich people,
[01:28:49.960 --> 01:28:53.000]   much of climate change is not really gonna be
[01:28:53.000 --> 01:28:55.720]   all that impactful, it still will have an impact.
[01:28:55.720 --> 01:28:58.200]   But fundamentally, if you're well off,
[01:28:58.200 --> 01:29:00.600]   you can mitigate a lot of these impacts.
[01:29:00.600 --> 01:29:02.760]   - And there's a young scientist at Carnegie Mellon,
[01:29:02.760 --> 01:29:06.680]   Destiny Nock, she just was the lead author on a study,
[01:29:06.680 --> 01:29:12.080]   what poor and prosperous households do in a heat wave
[01:29:12.080 --> 01:29:14.280]   when they have access to air conditioning.
[01:29:14.280 --> 01:29:18.720]   In a poor household, you wait, they found through science,
[01:29:18.720 --> 01:29:21.800]   they delay turning on the air conditioner
[01:29:21.800 --> 01:29:23.640]   four to seven degrees more of heating
[01:29:23.640 --> 01:29:25.440]   before they start to use the air conditioner.
[01:29:25.440 --> 01:29:27.360]   And that can create adverse outcomes.
[01:29:27.360 --> 01:29:29.920]   If you have an asthmatic in the house, an old person,
[01:29:29.920 --> 01:29:32.000]   you're endangering their lives.
[01:29:32.000 --> 01:29:34.960]   And that's just a little tiny, microscopic,
[01:29:34.960 --> 01:29:39.800]   fractal example of this powerful, real phenomenon
[01:29:39.800 --> 01:29:42.080]   that there's a divide in vulnerability,
[01:29:42.080 --> 01:29:44.760]   and it's not just based on where you live.
[01:29:44.760 --> 01:29:47.360]   This is families in like Pittsburgh.
[01:29:47.360 --> 01:29:48.840]   We're not talking about Botswana.
[01:29:48.840 --> 01:29:52.320]   And so that divide in capacity to deal
[01:29:52.320 --> 01:29:55.840]   with environmental stress is something
[01:29:55.840 --> 01:29:57.080]   you can really work on.
[01:29:57.080 --> 01:30:00.520]   And it gets hidden in all this talk of climate crisis.
[01:30:00.520 --> 01:30:04.600]   - And that's one of the important parts is both to say,
[01:30:04.600 --> 01:30:07.960]   look, if seven billion people, sorry,
[01:30:07.960 --> 01:30:11.680]   eight billion people will now have all experienced this,
[01:30:11.680 --> 01:30:14.120]   even though for each one of them, it's manageable,
[01:30:14.120 --> 01:30:17.320]   it's still a big problem because it's eight billion people
[01:30:17.320 --> 01:30:18.160]   living through this.
[01:30:18.160 --> 01:30:19.440]   - And how's the air conditioning eight billion people?
[01:30:19.440 --> 01:30:24.400]   - Yes, and then it's the point of getting to realize
[01:30:24.400 --> 01:30:27.920]   it's very, very much about how do you help the world's poor?
[01:30:27.920 --> 01:30:30.920]   And that's very much about making it more affordable,
[01:30:30.920 --> 01:30:33.480]   basically getting them out of poverty.
[01:30:33.480 --> 01:30:35.760]   And remember, getting out of poverty doesn't just mean
[01:30:35.760 --> 01:30:37.920]   that they can now afford to air condition themselves,
[01:30:37.920 --> 01:30:40.360]   but they get better education,
[01:30:40.360 --> 01:30:42.040]   they get better opportunities,
[01:30:42.040 --> 01:30:44.920]   they get better lives in so many other ways.
[01:30:44.920 --> 01:30:47.080]   And then at the end of it,
[01:30:47.440 --> 01:30:50.040]   it's not just about making sure that we focus
[01:30:50.040 --> 01:30:52.520]   on this one problem, but it's recognizing
[01:30:52.520 --> 01:30:56.220]   that these families have lots of different issues
[01:30:56.220 --> 01:30:58.320]   that they would like us to focus on,
[01:30:58.320 --> 01:31:01.720]   climate and heat waves just being one of them.
[01:31:01.720 --> 01:31:04.280]   So it's sort of taking progressive steps back
[01:31:04.280 --> 01:31:07.400]   and realizing, all right, okay, this is a problem,
[01:31:07.400 --> 01:31:08.240]   not the end of the world.
[01:31:08.240 --> 01:31:09.920]   - And one tiny little last example,
[01:31:09.920 --> 01:31:12.240]   you mentioned Jakarta at the beginning.
[01:31:12.240 --> 01:31:13.840]   It's really valuable to look around the world
[01:31:13.840 --> 01:31:16.600]   at places that are sort of leading indicator places,
[01:31:16.600 --> 01:31:20.200]   whether it's sea level rise or heat, and you could do that.
[01:31:20.200 --> 01:31:23.720]   Jakarta is sinking like a foot a year,
[01:31:23.720 --> 01:31:26.920]   literally a foot a year, it's some insane number,
[01:31:26.920 --> 01:31:30.480]   from withdrawing groundwater, from gas withdrawal,
[01:31:30.480 --> 01:31:33.540]   from, it's a delta, it's sediment, it's built on sediment.
[01:31:33.540 --> 01:31:35.840]   I wrote a piece ages ago, the New York Times
[01:31:35.840 --> 01:31:38.520]   is calling it Delta Blues, you know, musicians.
[01:31:38.520 --> 01:31:40.740]   And in Jakarta, so what are they doing?
[01:31:40.740 --> 01:31:44.740]   They're moving, they're moving the capital to another area.
[01:31:45.820 --> 01:31:49.240]   So that says to me, there's a lot of plasticity too.
[01:31:49.240 --> 01:31:51.640]   It's a city that's going through this,
[01:31:51.640 --> 01:31:54.400]   that rate of sea level, of their relationship
[01:31:54.400 --> 01:31:57.520]   with the sea level through sinking is way faster
[01:31:57.520 --> 01:31:59.160]   than what's happening with global warming.
[01:31:59.160 --> 01:32:00.960]   So look there, look to those kinds of places
[01:32:00.960 --> 01:32:02.560]   and you can start to build.
[01:32:02.560 --> 01:32:05.520]   - Tokyo had the same thing in the 1930s.
[01:32:05.520 --> 01:32:09.160]   They were also withdrawing lots of water way too fast.
[01:32:09.160 --> 01:32:11.080]   And so, you know, one of the obvious things is
[01:32:11.080 --> 01:32:13.880]   maybe you should stop withdrawing water so fast.
[01:32:13.880 --> 01:32:16.740]   - Yeah, and again, we seem to almost be intent
[01:32:16.740 --> 01:32:19.500]   on finding the most politically correct way
[01:32:19.500 --> 01:32:22.220]   to fix a problem or, you know, the most,
[01:32:22.220 --> 01:32:24.520]   the thing that sort of gets the most clicks
[01:32:24.520 --> 01:32:27.500]   instead of the thing that actually works the best.
[01:32:27.500 --> 01:32:29.660]   So a lot of these things are really, you know,
[01:32:29.660 --> 01:32:31.140]   not rocket science solutions.
[01:32:31.140 --> 01:32:32.260]   - Well, we'll get there.
[01:32:32.260 --> 01:32:34.780]   Let me add one more on top of the pile
[01:32:34.780 --> 01:32:36.220]   of the worst case analysis.
[01:32:36.220 --> 01:32:38.300]   So what people talk about, which is hurricanes
[01:32:38.300 --> 01:32:42.020]   and earthquakes, is there a connection
[01:32:42.020 --> 01:32:44.860]   that's well understood between climate change
[01:32:44.860 --> 01:32:51.020]   and the increased frequency and intensity
[01:32:51.020 --> 01:32:52.740]   of hurricanes and earthquakes?
[01:32:52.740 --> 01:32:54.780]   - I've dug in on both a lot.
[01:32:54.780 --> 01:32:56.460]   The earthquake connection to climate change,
[01:32:56.460 --> 01:32:58.860]   I'm not worried about compared to just the earthquake risk
[01:32:58.860 --> 01:33:01.340]   that we live with in many parts of the world already.
[01:33:01.340 --> 01:33:04.980]   The Himalayas, even with that earthquake in 2015
[01:33:04.980 --> 01:33:09.980]   in Kathmandu, that whole range is overdue
[01:33:09.980 --> 01:33:11.480]   for major earthquakes.
[01:33:11.480 --> 01:33:14.100]   And what has happened in the last 50 years
[01:33:14.100 --> 01:33:15.940]   since they last had big earthquakes?
[01:33:15.940 --> 01:33:17.920]   Huge development, big cities,
[01:33:17.920 --> 01:33:19.820]   a lot of informal construction,
[01:33:19.820 --> 01:33:22.060]   like the stuff I wrote about in Istanbul,
[01:33:22.060 --> 01:33:24.700]   where the family builds another layer and another,
[01:33:24.700 --> 01:33:26.540]   they put a floor on, every time someone gets married
[01:33:26.540 --> 01:33:28.420]   and has kids, you put another floor in the house.
[01:33:28.420 --> 01:33:30.420]   And unfortunately, that's, you know,
[01:33:30.420 --> 01:33:36.340]   what was the term, this Turkish engineer,
[01:33:36.340 --> 01:33:38.460]   rubble in waiting.
[01:33:38.460 --> 01:33:39.300]   - Rubble in waiting.
[01:33:39.300 --> 01:33:40.140]   - It's rubble in waiting.
[01:33:40.140 --> 01:33:42.280]   And we're looking at it, you know, videotaping it,
[01:33:42.280 --> 01:33:44.240]   and there are people playing there.
[01:33:44.240 --> 01:33:45.640]   So I don't worry about the earthquake connection
[01:33:45.640 --> 01:33:46.940]   to climate change.
[01:33:46.940 --> 01:33:49.500]   The hurricanes I've written about for decades.
[01:33:49.500 --> 01:33:53.740]   And the most illuminating body of science
[01:33:53.740 --> 01:33:58.560]   that I've dug in on, literally, related to hurricanes
[01:33:58.560 --> 01:34:00.080]   is this field that's emerged,
[01:34:00.080 --> 01:34:02.760]   it gets a tiny bit of money compared to climate modeling.
[01:34:02.760 --> 01:34:05.520]   It's called paleotempestology.
[01:34:05.520 --> 01:34:07.440]   It's like paleontology, you know?
[01:34:07.440 --> 01:34:10.120]   They look for evidence of past hurricanes
[01:34:10.120 --> 01:34:12.200]   along coasts that we care about.
[01:34:12.200 --> 01:34:16.840]   And they dig down into the lagoons behind,
[01:34:16.840 --> 01:34:19.360]   like the barrier beaches along Florida,
[01:34:19.360 --> 01:34:21.280]   or the Carolinas, or in Puerto Rico.
[01:34:21.280 --> 01:34:24.720]   And what you have is a history book of past hurricanes.
[01:34:24.720 --> 01:34:27.040]   So there's mud, mud, mud, mud, mud, mud, mud,
[01:34:27.040 --> 01:34:28.940]   you know, accumulating over centuries.
[01:34:28.940 --> 01:34:32.620]   And then there's a layer of sand and seashells.
[01:34:32.620 --> 01:34:34.980]   And what that indicates is that there was a great storm
[01:34:34.980 --> 01:34:38.240]   that came across the beach, pushed a lot of sediment
[01:34:38.240 --> 01:34:39.280]   into the mud.
[01:34:39.280 --> 01:34:41.360]   And then there's mud, mud, mud, mud, mud, mud, mud.
[01:34:41.360 --> 01:34:43.200]   And when you look at that work,
[01:34:43.200 --> 01:34:45.520]   I first wrote about this in 2001 in the Times,
[01:34:45.520 --> 01:34:48.300]   a long story, and then I kept track
[01:34:48.300 --> 01:34:53.300]   of these intrepid scientists putting these core tubes down.
[01:34:53.300 --> 01:34:55.880]   It shows you that we're in a landscape
[01:34:55.880 --> 01:35:00.880]   where big, bad hurricanes are not, they're the norm.
[01:35:00.880 --> 01:35:03.960]   But something that's rare and big
[01:35:03.960 --> 01:35:05.960]   is something that's extreme.
[01:35:05.960 --> 01:35:07.280]   When you think about the word extreme, right,
[01:35:07.280 --> 01:35:10.560]   it means it's at the end of the spectrum of what's possible.
[01:35:10.560 --> 01:35:13.840]   They're rare, rare in human timescales.
[01:35:13.840 --> 01:35:17.720]   Hurricane Michael, four years ago, devastated.
[01:35:17.720 --> 01:35:21.760]   Category 5 came ashore in the panhandle of Florida,
[01:35:21.760 --> 01:35:24.580]   leveled that much-photographed town, Mexico Beach.
[01:35:24.580 --> 01:35:29.560]   And people, actually, the Tallahassee National Weather
[01:35:29.560 --> 01:35:33.140]   Service said, "Unprecedented hurricane."
[01:35:33.140 --> 01:35:35.560]   And the damage was unprecedented
[01:35:35.560 --> 01:35:38.240]   because there hadn't been a community there before.
[01:35:38.240 --> 01:35:40.320]   But the hurricane was not unprecedented at all.
[01:35:40.320 --> 01:35:42.680]   If you look at the history, and this is published research,
[01:35:42.680 --> 01:35:44.800]   it's just that no one bothers to,
[01:35:44.800 --> 01:35:49.240]   we have this blind spot for the longer timescale
[01:35:49.240 --> 01:35:50.440]   you need to examine if you're thinking
[01:35:50.440 --> 01:35:52.440]   about big, bad things that are rare.
[01:35:52.440 --> 01:35:54.760]   And hurricanes are still rare.
[01:35:54.760 --> 01:35:59.760]   I was recently covering Fort Myers, the awful devastation.
[01:35:59.760 --> 01:36:01.660]   There's a young climate scientist
[01:36:01.660 --> 01:36:06.340]   at Florida Gulf Coast University, Jo Muller,
[01:36:06.340 --> 01:36:08.500]   who's done that paleotempestology work there,
[01:36:08.500 --> 01:36:09.420]   right in Fort Myers.
[01:36:09.420 --> 01:36:11.620]   She lives there, and she was away in London
[01:36:11.620 --> 01:36:13.420]   at a meeting of reinsurance companies
[01:36:13.420 --> 01:36:15.740]   that reinsure all the world's big, bad risks
[01:36:15.740 --> 01:36:17.460]   when this was happening.
[01:36:17.460 --> 01:36:19.460]   But she has done the work that shows,
[01:36:19.460 --> 01:36:21.420]   it's a thousand-year record of past hurricanes,
[01:36:21.420 --> 01:36:24.740]   and it's super sobering when you consider
[01:36:24.740 --> 01:36:28.460]   how fast people have moved into Florida
[01:36:28.460 --> 01:36:33.460]   and built vulnerably in an area that hurricanes will hammer.
[01:36:33.460 --> 01:36:35.700]   That's part of the fundamental dynamics
[01:36:35.700 --> 01:36:39.100]   of the Gulf of Mexico, and the storms come off of Africa.
[01:36:39.100 --> 01:36:40.900]   It's a place where they will come.
[01:36:40.900 --> 01:36:44.420]   Now, the question of global warming impact is subtle.
[01:36:44.420 --> 01:36:47.500]   There are aspects of hurricanes that haven't changed.
[01:36:47.500 --> 01:36:51.580]   There's aspects like rainfall that seem pretty powerfully
[01:36:51.580 --> 01:36:53.420]   linked to global warming.
[01:36:53.420 --> 01:36:55.460]   A warmer atmosphere holds more moisture,
[01:36:55.460 --> 01:36:56.700]   so when you have a big disturbance,
[01:36:57.620 --> 01:36:59.620]   the heat engine of a hurricane comes through it,
[01:36:59.620 --> 01:37:00.520]   you get more rain.
[01:37:00.520 --> 01:37:03.580]   There's rapid intensification,
[01:37:03.580 --> 01:37:08.580]   how quickly these storms jump from category one
[01:37:08.580 --> 01:37:13.780]   to five or four before they hit is a new area of science.
[01:37:13.780 --> 01:37:16.780]   So I think it's still early days in knowing,
[01:37:16.780 --> 01:37:19.060]   because no one was looking for that.
[01:37:19.060 --> 01:37:21.820]   There were no data back 300 years ago
[01:37:21.820 --> 01:37:24.500]   when these big, bad previous hurricanes came
[01:37:24.500 --> 01:37:27.020]   to know whether they were rapidly intensified or not.
[01:37:27.020 --> 01:37:30.780]   So as a journalist, I try to keep track
[01:37:30.780 --> 01:37:33.600]   of what we don't know, not to be too constrained,
[01:37:33.600 --> 01:37:37.340]   and think about new science as being robust,
[01:37:37.340 --> 01:37:42.740]   unless it's considering and actually actively stating
[01:37:42.740 --> 01:37:46.820]   we don't really know what's going on with earlier hurricanes.
[01:37:46.820 --> 01:37:49.960]   And all of that is swamped, ultimately, literally,
[01:37:49.960 --> 01:37:54.180]   by the vulnerability, building vulnerability in these areas.
[01:37:54.180 --> 01:37:56.860]   You know, if there's a marginal change in a storm,
[01:37:56.860 --> 01:38:01.780]   and you've quadrupled or sextupled how much stuff
[01:38:01.780 --> 01:38:03.800]   and how many people are in the way,
[01:38:03.800 --> 01:38:06.380]   and if some of those people are poor and vulnerable,
[01:38:06.380 --> 01:38:08.980]   or elderly and can't swim,
[01:38:08.980 --> 01:38:11.300]   you're creating a landscape of destruction.
[01:38:11.300 --> 01:38:15.920]   - So a lot of the human suffering that has to do with storms
[01:38:15.920 --> 01:38:19.860]   is about where and how you build,
[01:38:19.860 --> 01:38:22.420]   versus the frequency and the intensity of storms.
[01:38:22.420 --> 01:38:26.540]   - Still, you didn't quite answer the question.
[01:38:26.540 --> 01:38:29.980]   You know, when I'm having a beer with people at a bar,
[01:38:29.980 --> 01:38:32.140]   and they say, "Hey, why are you having a beer?
[01:38:32.140 --> 01:38:34.620]   "We're all going to die," because of climate change,
[01:38:34.620 --> 01:38:36.020]   usually what they bring up,
[01:38:36.020 --> 01:38:38.460]   and I'm just trying to add some levity here.
[01:38:38.460 --> 01:38:39.940]   - No, this is good.
[01:38:39.940 --> 01:38:43.380]   - Usually what they bring up is the hurricanes,
[01:38:43.380 --> 01:38:46.700]   and the most recent hurricane, saying like,
[01:38:46.700 --> 01:38:49.700]   they're getting crazy, hurricanes all the time,
[01:38:49.700 --> 01:38:53.460]   they're getting more intense, more frequent, and so on.
[01:38:53.460 --> 01:38:57.860]   I'm sure there's incredible science going on
[01:38:57.860 --> 01:38:59.020]   trying to look at this.
[01:38:59.020 --> 01:39:04.300]   Is there evidence, and is it possible to have evidence
[01:39:04.300 --> 01:39:07.660]   that there's a connection between
[01:39:07.660 --> 01:39:10.060]   what we can call global warming
[01:39:10.060 --> 01:39:12.940]   and the increased frequency and intensity of storms?
[01:39:12.940 --> 01:39:15.080]   - No. - Okay, no, thank you.
[01:39:15.080 --> 01:39:18.420]   - Well, you added intensity.
[01:39:18.420 --> 01:39:22.180]   You know, let me just get into this a tiny bit more.
[01:39:22.180 --> 01:39:25.220]   I mean, hurricanes, I grew up with them in Rhode Island
[01:39:25.220 --> 01:39:28.060]   in my youth, and there was a very active period
[01:39:28.060 --> 01:39:32.900]   of hurricanes in New England in the '50s and '60s, '70s,
[01:39:32.900 --> 01:39:35.420]   and then in the North Atlantic, generally,
[01:39:35.420 --> 01:39:39.340]   it was very, very active in '50 when I was a kid,
[01:39:39.340 --> 01:39:42.980]   and the dynamics of them forming off of Africa
[01:39:42.980 --> 01:39:46.240]   and coming here, circling up the coast, was just prime time.
[01:39:47.180 --> 01:39:49.220]   Then there was like what Kerry Emanuel,
[01:39:49.220 --> 01:39:53.100]   who's the most experienced hurricane climate scientist
[01:39:53.100 --> 01:39:58.100]   around at MIT, he's in this story, he's in my 1988 article.
[01:39:58.100 --> 01:40:04.220]   He and colleagues have found, and others,
[01:40:04.220 --> 01:40:07.660]   that there's what they call a hurricane drought
[01:40:07.660 --> 01:40:11.480]   from like the '70s through about 1994 in the Atlantic,
[01:40:11.480 --> 01:40:13.540]   specifically the Atlantic Basin,
[01:40:13.540 --> 01:40:15.640]   and there's been a lot of questions about that.
[01:40:15.640 --> 01:40:17.460]   People thought it was ocean circulation,
[01:40:17.460 --> 01:40:18.900]   something about the currents.
[01:40:18.900 --> 01:40:22.820]   There's these multi-decadal variabilities in the oceans.
[01:40:22.820 --> 01:40:27.220]   And then now it looks robustly,
[01:40:27.220 --> 01:40:30.340]   I can't find a climate scientist who disagrees,
[01:40:30.340 --> 01:40:34.960]   that the thing that caused the drought was pollution, smog,
[01:40:34.960 --> 01:40:38.340]   and significantly in Europe.
[01:40:38.340 --> 01:40:40.380]   And you say, well, how does smog in Europe relate
[01:40:40.380 --> 01:40:42.820]   to hurricanes crossing the Atlantic
[01:40:42.820 --> 01:40:45.380]   and getting to the United States?
[01:40:45.380 --> 01:40:49.700]   It's because of the smog was changing the behavior
[01:40:49.700 --> 01:40:52.300]   of the Sahara Desert, which is just south of Europe.
[01:40:52.300 --> 01:40:56.840]   And the Sahara Desert kills hurricanes.
[01:40:56.840 --> 01:40:58.500]   Sand and dust coming off the Sahara,
[01:40:58.500 --> 01:40:59.820]   you can see this every year.
[01:40:59.820 --> 01:41:03.380]   When that's active, it stifles these big storms.
[01:41:03.380 --> 01:41:06.020]   At the point, right in their nursery, they all form,
[01:41:06.020 --> 01:41:09.020]   there's this area for hurricanes off of West Africa
[01:41:09.020 --> 01:41:10.620]   that's like the nursery zone.
[01:41:10.620 --> 01:41:12.160]   And so if you're stifling those hurricanes
[01:41:12.160 --> 01:41:15.280]   because of pollution in Europe
[01:41:15.280 --> 01:41:18.880]   before the Clean Air Act's cleanups,
[01:41:18.880 --> 01:41:21.740]   and then that goes away,
[01:41:21.740 --> 01:41:23.900]   none of that has anything to do with global warming.
[01:41:23.900 --> 01:41:25.860]   It's another kind of forcing in the climate system,
[01:41:25.860 --> 01:41:28.700]   a local one that created a regional dynamic
[01:41:28.700 --> 01:41:30.720]   that created a quiet period
[01:41:30.720 --> 01:41:32.420]   when all these friends in the bar,
[01:41:32.420 --> 01:41:37.380]   maybe they were born in the '90s or whatever,
[01:41:37.380 --> 01:41:38.940]   they grew up in an area of like,
[01:41:40.860 --> 01:41:42.320]   hurricanes weren't a big deal.
[01:41:42.320 --> 01:41:45.200]   And now we have an end to that drought
[01:41:45.200 --> 01:41:47.020]   because we cleaned up the air pollution,
[01:41:47.020 --> 01:41:49.960]   the sooty kind of air pollution, sulfury.
[01:41:49.960 --> 01:41:53.300]   And anyone who says global warming, global warming,
[01:41:53.300 --> 01:41:55.320]   without saying, well, that's in there too,
[01:41:55.320 --> 01:41:57.440]   is kind of missing that.
[01:41:57.440 --> 01:41:58.920]   And when you look globally,
[01:41:58.920 --> 01:42:03.400]   still, I think it was 90 or so hurricanes a year,
[01:42:03.400 --> 01:42:05.720]   cyclones, hurricanes, typhoons globally.
[01:42:05.720 --> 01:42:06.560]   That hasn't changed.
[01:42:06.560 --> 01:42:09.000]   The number of these tropical storms
[01:42:09.000 --> 01:42:12.360]   that reach that ferocity has not changed.
[01:42:12.360 --> 01:42:14.600]   It's just a fundamental dynamic of,
[01:42:14.600 --> 01:42:16.480]   and by the way, on the long time scale,
[01:42:16.480 --> 01:42:21.480]   the models still indicate as you warm the planet,
[01:42:21.480 --> 01:42:23.800]   and remember the Arctic warms quicker,
[01:42:23.800 --> 01:42:26.280]   this is something people probably understand,
[01:42:26.280 --> 01:42:29.320]   you're actually evening out the imbalance
[01:42:29.320 --> 01:42:31.640]   between the heat at the equator
[01:42:31.640 --> 01:42:35.260]   and the cold in the northern part of the hemisphere,
[01:42:35.260 --> 01:42:36.860]   and that calms the whole system down.
[01:42:36.860 --> 01:42:40.040]   So there could be fewer hurricanes later in the century
[01:42:40.040 --> 01:42:41.500]   because of global warming.
[01:42:41.500 --> 01:42:44.760]   And for me, that's a lot of information,
[01:42:44.760 --> 01:42:49.240]   but if I'm in a bar, I start with what do you care about?
[01:42:49.240 --> 01:42:51.500]   You care about safety, you care about security,
[01:42:51.500 --> 01:42:55.000]   you care about having everybody safe, not just you.
[01:42:55.000 --> 01:42:56.800]   You get in your car and you can evacuate.
[01:42:56.800 --> 01:43:00.720]   What about the old person or the poor family
[01:43:00.720 --> 01:43:02.980]   who can't do that, they're not gonna leave their house?
[01:43:02.980 --> 01:43:05.780]   What are we doing to limit vulnerability now?
[01:43:05.780 --> 01:43:08.560]   That, I circle back to that over and over again.
[01:43:08.560 --> 01:43:12.000]   I have a pocket card, I have this graphic card
[01:43:12.000 --> 01:43:13.880]   I created about risk,
[01:43:13.880 --> 01:43:17.080]   and what we really care about is climate risk.
[01:43:17.080 --> 01:43:19.640]   Who's at risk, what's driving the risk,
[01:43:19.640 --> 01:43:20.480]   how do you reduce that?
[01:43:20.480 --> 01:43:21.960]   It's a card, you can almost pull it out in a bar,
[01:43:21.960 --> 01:43:22.800]   I should print them.
[01:43:22.800 --> 01:43:23.640]   - You should do that.
[01:43:23.640 --> 01:43:25.440]   - It's like risk is the hazard.
[01:43:25.440 --> 01:43:26.440]   - Climate bar, Pat.
[01:43:26.440 --> 01:43:32.480]   - Risk is the hazard, the hazard is a storm,
[01:43:34.160 --> 01:43:37.980]   times exposure, how many people, how much stuff,
[01:43:37.980 --> 01:43:43.740]   factoring in vulnerability or resilience.
[01:43:43.740 --> 01:43:48.580]   And climate change is changing the hazard for some things,
[01:43:48.580 --> 01:43:50.820]   not for tornadoes, not for everything.
[01:43:50.820 --> 01:43:54.620]   Exposure is this expanding bullseye,
[01:43:54.620 --> 01:43:57.540]   this is another hashtag, expanding bullseye.
[01:43:57.540 --> 01:43:59.620]   Get out there and look for that and you'll see,
[01:43:59.620 --> 01:44:03.140]   I'm pushing these two geographers who do this
[01:44:03.140 --> 01:44:07.940]   for every hazard, wildfire, earthquake, flood,
[01:44:07.940 --> 01:44:11.620]   coastal storm, and we're building an expanding bullseye
[01:44:11.620 --> 01:44:14.020]   in an area and nature's throwing darts.
[01:44:14.020 --> 01:44:15.100]   Some of the darts are getting bigger
[01:44:15.100 --> 01:44:17.780]   because of global warming, some of the darts we don't know.
[01:44:17.780 --> 01:44:18.620]   What do you do?
[01:44:18.620 --> 01:44:19.560]   Like, what do you do?
[01:44:19.560 --> 01:44:21.300]   Well, you get out of the way, right?
[01:44:21.300 --> 01:44:23.020]   You don't wanna be on the dartboard.
[01:44:23.020 --> 01:44:25.780]   And that, it just simplifies the whole formula.
[01:44:25.780 --> 01:44:31.220]   To me, it's kind of a transformational potential
[01:44:32.740 --> 01:44:33.660]   to go into a bar.
[01:44:33.660 --> 01:44:35.180]   Maybe I should print these things.
[01:44:35.180 --> 01:44:36.020]   - 100%.
[01:44:36.020 --> 01:44:37.740]   And I should go drinking with you more often.
[01:44:37.740 --> 01:44:39.340]   - There should be coasters in bars.
[01:44:39.340 --> 01:44:41.460]   - 'Cause that was fascinating about smog.
[01:44:41.460 --> 01:44:44.620]   I mean, it's nice to be reminded about how complicated
[01:44:44.620 --> 01:44:46.420]   and fascinating the weather system is.
[01:44:46.420 --> 01:44:50.500]   - Let me try to answer the questions slightly quicker
[01:44:50.500 --> 01:44:53.860]   before your friends have drunk too much.
[01:44:53.860 --> 01:44:54.700]   - Never enough.
[01:44:54.700 --> 01:44:56.620]   - Or not enough.
[01:44:56.620 --> 01:45:01.580]   So if you look at the amount of,
[01:45:01.580 --> 01:45:05.300]   the number of hurricanes, as Andy rightly pointed out,
[01:45:05.300 --> 01:45:08.500]   it doesn't look like it's changing.
[01:45:08.500 --> 01:45:11.980]   So we see more because we have now much better
[01:45:11.980 --> 01:45:14.080]   detection systems with satellites.
[01:45:14.080 --> 01:45:17.780]   But if you look since 1980,
[01:45:17.780 --> 01:45:19.700]   when we have good satellite coverage,
[01:45:19.700 --> 01:45:22.420]   for instance, last year was the year
[01:45:22.420 --> 01:45:25.960]   that had the lowest number of hurricanes in the world.
[01:45:25.960 --> 01:45:28.820]   And you're sort of like, that's odd
[01:45:28.820 --> 01:45:31.020]   because it's probably the year where I heard
[01:45:31.020 --> 01:45:32.460]   the most about hurricanes.
[01:45:32.460 --> 01:45:34.500]   And what that tells you is that just because you hear
[01:45:34.500 --> 01:45:36.620]   a lot about hurricanes doesn't actually mean
[01:45:36.620 --> 01:45:37.820]   that there is a lot of hurricanes.
[01:45:37.820 --> 01:45:39.380]   You can't just go that way.
[01:45:39.380 --> 01:45:44.100]   If you remember in the 1990s and 2000s,
[01:45:44.100 --> 01:45:47.260]   there was an enormous amount of talk about how violence,
[01:45:47.260 --> 01:45:49.600]   how crime was getting worse in the US,
[01:45:49.600 --> 01:45:51.300]   while all the objective indicators
[01:45:51.300 --> 01:45:52.900]   showed that it was going down.
[01:45:52.900 --> 01:45:55.820]   But there's sufficient amount of violence
[01:45:55.820 --> 01:46:00.580]   that you can fill every radio and TV show with a new crime.
[01:46:00.580 --> 01:46:03.180]   And so if you get more and more TV shows
[01:46:03.180 --> 01:46:05.900]   that talk about crime, actually most people end up
[01:46:05.900 --> 01:46:07.340]   thinking that there's more crime
[01:46:07.340 --> 01:46:09.860]   while the real number is going down.
[01:46:09.860 --> 01:46:14.320]   So the reality here is yes, climate change
[01:46:14.320 --> 01:46:17.260]   will probably affect hurricanes in the sense
[01:46:17.260 --> 01:46:20.300]   that they'll be the same number or slightly fewer
[01:46:20.300 --> 01:46:21.740]   as Andy was mentioning,
[01:46:21.740 --> 01:46:25.140]   but they will likely be somewhat stronger.
[01:46:25.140 --> 01:46:27.900]   This seems to be the best outcome.
[01:46:27.900 --> 01:46:30.180]   We're not sure, but this seems to be the outcome.
[01:46:30.180 --> 01:46:32.060]   And it's important to remember,
[01:46:32.060 --> 01:46:35.680]   stronger is worse than fewer is better.
[01:46:35.680 --> 01:46:40.680]   So overall, climate will make the world a little bit worse.
[01:46:40.680 --> 01:46:43.420]   So that's the sort of bottom line,
[01:46:43.420 --> 01:46:45.940]   but, and that's the real issue here,
[01:46:45.940 --> 01:46:46.900]   all the other things,
[01:46:46.900 --> 01:46:49.140]   the fact that people are much more vulnerable,
[01:46:49.140 --> 01:46:51.660]   is just vastly outweigh this,
[01:46:51.660 --> 01:46:55.820]   which is why if you look at the impact of hurricanes
[01:46:55.820 --> 01:46:57.780]   and impact of pretty much everything,
[01:46:57.780 --> 01:47:00.060]   it is typically going down.
[01:47:00.060 --> 01:47:02.340]   If you look, for instance, in percent of GDP,
[01:47:02.340 --> 01:47:03.860]   you have to look at percent of GDP,
[01:47:03.860 --> 01:47:05.680]   because if you have twice as many houses,
[01:47:05.680 --> 01:47:08.540]   obviously, the same kind of impact will have twice
[01:47:08.540 --> 01:47:12.020]   the impact or if they're worth twice as much.
[01:47:12.020 --> 01:47:13.580]   If you do that in percent of GDP,
[01:47:13.580 --> 01:47:16.180]   and even the UN says that's how you should measure it,
[01:47:16.180 --> 01:47:17.260]   it's going down.
[01:47:17.260 --> 01:47:18.140]   Why is that?
[01:47:18.140 --> 01:47:20.580]   It's because we're becoming more resilient.
[01:47:20.580 --> 01:47:23.420]   Just simply, if you look at what happens
[01:47:23.420 --> 01:47:24.620]   when hurricanes come in,
[01:47:24.620 --> 01:47:27.060]   we have much better prediction in the long run.
[01:47:27.060 --> 01:47:30.340]   That means you now know, two or three days out,
[01:47:30.340 --> 01:47:32.860]   that there's a big hurricane that's likely to come here.
[01:47:32.860 --> 01:47:33.740]   What does that mean?
[01:47:33.740 --> 01:47:36.020]   All the things that can be moved.
[01:47:36.020 --> 01:47:38.900]   So, typically all buses, all trucks,
[01:47:38.900 --> 01:47:42.140]   everything that's not bolted down will leave this area.
[01:47:42.140 --> 01:47:44.620]   And so you will get less damage from that.
[01:47:44.620 --> 01:47:46.220]   You will have more people knowing,
[01:47:46.220 --> 01:47:47.660]   oh, this is gonna be a big one.
[01:47:47.660 --> 01:47:49.760]   They moved to their relative somewhere else.
[01:47:49.760 --> 01:47:52.060]   So you'll have fewer people being vulnerable.
[01:47:52.060 --> 01:47:52.900]   There's a lot-
[01:47:52.900 --> 01:47:53.940]   - If people are responsive and aware.
[01:47:53.940 --> 01:47:56.260]   - Yeah, there's a lot of way you can do this.
[01:47:56.260 --> 01:47:57.540]   So the outcome,
[01:47:57.540 --> 01:47:59.660]   and this is important for the whole conversation,
[01:47:59.660 --> 01:48:03.580]   the outcome is that we're actually becoming less vulnerable
[01:48:03.580 --> 01:48:07.820]   and that damages are becoming smaller, not bigger.
[01:48:07.820 --> 01:48:10.800]   But had there not been global warming,
[01:48:10.800 --> 01:48:13.480]   it would probably have gone down even faster.
[01:48:13.480 --> 01:48:16.860]   So we would have become even better off quicker
[01:48:16.860 --> 01:48:18.380]   had there been no global warming.
[01:48:18.380 --> 01:48:20.540]   But this is a crucial difference
[01:48:20.540 --> 01:48:23.040]   and this is what I find really hard to communicate.
[01:48:23.040 --> 01:48:24.740]   Climate change is not this,
[01:48:24.740 --> 01:48:27.900]   oh my God, everything is going off the charts
[01:48:27.900 --> 01:48:29.900]   and we're all gonna be doomed kind of thing.
[01:48:29.900 --> 01:48:32.820]   Climate change is a thing that means
[01:48:32.820 --> 01:48:36.460]   we're gonna get better slightly slower.
[01:48:36.460 --> 01:48:39.660]   And that's a very, very different kind of attitude.
[01:48:39.660 --> 01:48:41.180]   It's one of the many problems
[01:48:41.180 --> 01:48:43.780]   rather than this is the end of all of us.
[01:48:43.780 --> 01:48:44.620]   - And by the way,
[01:48:44.620 --> 01:48:47.580]   if you look at what's happening in the world,
[01:48:47.580 --> 01:48:50.980]   the data also show that in rich places and poor places,
[01:48:50.980 --> 01:48:53.540]   we still are moving into zones of hazard
[01:48:53.540 --> 01:48:55.620]   faster than climate is changing.
[01:48:55.620 --> 01:48:59.700]   Beth Tellman, who's at Columbia and she moved to Arizona,
[01:48:59.700 --> 01:49:03.340]   she and colleagues at this outfit called Cloud to Street
[01:49:03.340 --> 01:49:05.300]   did an amazing study showing,
[01:49:05.300 --> 01:49:06.740]   this is a year or so ago I wrote about,
[01:49:06.740 --> 01:49:09.700]   showing again, we're moving into zones of hazard,
[01:49:09.700 --> 01:49:11.120]   which it applies to me,
[01:49:11.120 --> 01:49:14.020]   just what Bjorn was saying that
[01:49:14.020 --> 01:49:16.340]   people wouldn't be doing that
[01:49:16.340 --> 01:49:19.980]   if they thought that was gonna lead to devastation.
[01:49:19.980 --> 01:49:22.200]   And this is today, we're doing this now.
[01:49:22.200 --> 01:49:25.100]   And it's flood zones, wildfire zones.
[01:49:25.100 --> 01:49:28.600]   So that means there's these things to do.
[01:49:28.600 --> 01:49:32.140]   There's so much plasticity in the human behavior
[01:49:32.140 --> 01:49:34.340]   and how we build and where we build.
[01:49:34.340 --> 01:49:37.620]   You can make a big, big change in the outcomes.
[01:49:37.620 --> 01:49:39.540]   - I mean, one of the things to remember is,
[01:49:39.540 --> 01:49:41.620]   people move to where hurricanes hit
[01:49:41.620 --> 01:49:42.940]   because when they're not there,
[01:49:42.940 --> 01:49:44.820]   it's a really beautiful place to be.
[01:49:44.820 --> 01:49:45.780]   - Yeah, yeah.
[01:49:45.780 --> 01:49:49.620]   - So in many ways, we make the trade-offs and say,
[01:49:49.620 --> 01:49:53.200]   look, I'm happy to have an ocean view
[01:49:53.200 --> 01:49:55.240]   and then maybe a hurricane's gonna hit.
[01:49:55.240 --> 01:49:56.800]   And of course it becomes a lot easier
[01:49:56.800 --> 01:49:58.000]   than when the federal government
[01:49:58.000 --> 01:50:00.440]   is actually subsidizing your risk by saying,
[01:50:00.440 --> 01:50:02.600]   we'll ensure you're really cheaply.
[01:50:02.600 --> 01:50:05.720]   And that's one of the things that we should stop doing.
[01:50:05.720 --> 01:50:06.880]   We should actually tell people,
[01:50:06.880 --> 01:50:09.300]   look, if you wanna live where hurricanes hit,
[01:50:09.300 --> 01:50:11.160]   maybe you should be more careful.
[01:50:11.160 --> 01:50:14.200]   - Yeah, by the way, what I was saying about past storms,
[01:50:14.200 --> 01:50:17.800]   the paleo tempestology, past fires, it's the same thing.
[01:50:17.800 --> 01:50:21.640]   We've suppressed fire in the United States for 100 years
[01:50:21.640 --> 01:50:23.080]   through much of the West,
[01:50:23.080 --> 01:50:26.440]   through wanting to save the forests,
[01:50:26.440 --> 01:50:28.160]   the whole Smokey the Bear thing.
[01:50:28.160 --> 01:50:29.000]   Don't start.
[01:50:29.000 --> 01:50:32.500]   When these are landscapes that evolved to burn,
[01:50:32.500 --> 01:50:34.280]   and what happened in the last 100 years?
[01:50:34.280 --> 01:50:35.680]   A lot of people love the West.
[01:50:35.680 --> 01:50:37.400]   We love these environments.
[01:50:37.400 --> 01:50:39.080]   We love to live with the trees.
[01:50:39.080 --> 01:50:41.740]   The Boulder County area, the explosive development
[01:50:41.740 --> 01:50:45.680]   in zones of implicit hazard leads to big, bad outcomes
[01:50:45.680 --> 01:50:46.920]   when conditions align
[01:50:46.920 --> 01:50:49.760]   and climate change is worsening some of those conditions.
[01:50:49.760 --> 01:50:52.080]   And sometimes it's really counterintuitive.
[01:50:52.080 --> 01:50:54.980]   A wet season builds more grass.
[01:50:54.980 --> 01:50:57.760]   A dry season comes along, parches the grass.
[01:50:57.760 --> 01:50:59.440]   Then comes a human ignition.
[01:50:59.440 --> 01:51:01.720]   It's almost always human ignitions.
[01:51:01.720 --> 01:51:02.960]   And then you have this disaster
[01:51:02.960 --> 01:51:05.280]   where a thousand homes burn in Boulder County.
[01:51:05.280 --> 01:51:07.800]   And it's like, there's so many elements there
[01:51:07.800 --> 01:51:12.400]   that can be worked on that give me confidence
[01:51:12.400 --> 01:51:16.080]   that we can change these outcomes.
[01:51:16.080 --> 01:51:17.720]   Natural disasters are not natural.
[01:51:17.720 --> 01:51:21.040]   Disasters are designed, really, as some people say.
[01:51:21.040 --> 01:51:25.000]   - Can I take a quick aside and ask about terminology
[01:51:25.000 --> 01:51:26.840]   of climate change and global warming?
[01:51:26.840 --> 01:51:29.760]   'Cause we use it interchangeably.
[01:51:29.760 --> 01:51:33.320]   It is an aside, but it's one that's worthy of taking.
[01:51:33.320 --> 01:51:36.040]   Do those carry different meanings?
[01:51:36.040 --> 01:51:38.760]   And has that meaning changed over the years?
[01:51:38.760 --> 01:51:43.120]   Between those two terms, are they really equivalent?
[01:51:43.120 --> 01:51:45.480]   - Well, some people say there was this industry
[01:51:45.480 --> 01:51:48.400]   or propagandistic shift from,
[01:51:48.400 --> 01:51:51.720]   let's see, which came first?
[01:51:51.720 --> 01:51:53.800]   Oh, no, they're going to climate change now.
[01:51:53.800 --> 01:51:56.880]   It's a new thing, which is, it's ridiculous.
[01:51:56.880 --> 01:52:01.040]   The Intergovernmental Panel on Climate Change in 1988
[01:52:01.040 --> 01:52:03.960]   wasn't the Intergovernmental Panel on Global Warming.
[01:52:03.960 --> 01:52:06.000]   It was on climate change.
[01:52:06.000 --> 01:52:07.980]   So these terms have been there.
[01:52:07.980 --> 01:52:09.120]   They've been sort of evolving.
[01:52:09.120 --> 01:52:11.800]   When I wrote this cover story, it was the greenhouse effect.
[01:52:11.800 --> 01:52:13.520]   - So, and that's fallen out of favor.
[01:52:13.520 --> 01:52:15.360]   Greenhouse effect is not often talked about.
[01:52:15.360 --> 01:52:18.200]   - Well, it's really, that's the physical effect
[01:52:18.200 --> 01:52:19.440]   that's holding in the heat.
[01:52:19.440 --> 01:52:21.240]   - But see-- - It's not a good--
[01:52:21.240 --> 01:52:22.920]   - There's terms that mean stuff,
[01:52:22.920 --> 01:52:26.580]   and there's terms that are actually used in public discourse
[01:52:26.580 --> 01:52:28.480]   to designate what your,
[01:52:28.480 --> 01:52:32.440]   a whole umbrella of opinions you have.
[01:52:32.440 --> 01:52:34.400]   And I guess as somebody, me,
[01:52:34.400 --> 01:52:38.440]   who doesn't pay attention to this carefully,
[01:52:38.440 --> 01:52:40.600]   you have to use terms carefully.
[01:52:40.600 --> 01:52:42.720]   - Sure. - Because people will,
[01:52:44.040 --> 01:52:47.720]   a noob that rolls into the topic will often use terms
[01:52:47.720 --> 01:52:50.280]   to mean exactly what they mean, like literally.
[01:52:50.280 --> 01:52:52.400]   But they actually have political implications,
[01:52:52.400 --> 01:52:53.240]   all that kind of stuff.
[01:52:53.240 --> 01:52:55.480]   So I guess I'm asking, is there like,
[01:52:55.480 --> 01:53:00.880]   are you signaling something by using global warming
[01:53:00.880 --> 01:53:02.160]   versus climate change?
[01:53:02.160 --> 01:53:04.840]   Or people have calmed down in terms of the use of these?
[01:53:04.840 --> 01:53:08.560]   - No, no, but the Guardian newspapers made it worse.
[01:53:08.560 --> 01:53:09.880]   Now they have their style book.
[01:53:09.880 --> 01:53:11.920]   You know, every newspaper has a,
[01:53:11.920 --> 01:53:14.480]   they prescribe, they don't want their reporters
[01:53:14.480 --> 01:53:16.320]   to use any of those terms anymore.
[01:53:16.320 --> 01:53:18.760]   They call it climate crisis, climate emergency.
[01:53:18.760 --> 01:53:20.000]   - Oh no. - Oh yeah.
[01:53:20.000 --> 01:53:21.200]   - Global heating. - It's literally
[01:53:21.200 --> 01:53:22.240]   in their rule book.
[01:53:22.240 --> 01:53:24.120]   - Global heating, that sounds more intense.
[01:53:24.120 --> 01:53:25.680]   - Global heating. - And that was the point.
[01:53:25.680 --> 01:53:28.560]   - Well, I wrote about the global heating thing
[01:53:28.560 --> 01:53:29.720]   more than a decade ago.
[01:53:29.720 --> 01:53:30.560]   That's been around.
[01:53:30.560 --> 01:53:33.200]   But you know, so they're doing the,
[01:53:33.200 --> 01:53:35.320]   what was the movie where the,
[01:53:35.320 --> 01:53:36.880]   the comedy, the rock and roll comedy,
[01:53:36.880 --> 01:53:39.280]   where he sets his-- - To 11, yeah, yeah.
[01:53:39.280 --> 01:53:40.640]   - His amplifier goes to 11.
[01:53:40.640 --> 01:53:42.400]   You know, the idea that you turned up
[01:53:42.400 --> 01:53:44.720]   the rhetorical volume and that's gonna change people
[01:53:44.720 --> 01:53:47.080]   is ridiculous. - I mean, so for me,
[01:53:47.080 --> 01:53:51.040]   I mean, I use global warming and climate change
[01:53:51.040 --> 01:53:53.480]   interchangeably, and I think it's fair.
[01:53:53.480 --> 01:53:57.080]   There's some technical ways that you can differentiate them.
[01:53:57.080 --> 01:53:59.520]   But the reality is that global warming
[01:53:59.520 --> 01:54:02.080]   is probably a better way to describe a lot of it
[01:54:02.080 --> 01:54:04.760]   because this is really what is the main driver
[01:54:04.760 --> 01:54:06.280]   of what we worry about.
[01:54:06.280 --> 01:54:08.280]   Climate change seems a little diffuse,
[01:54:08.280 --> 01:54:10.080]   but you know, it's convenient to,
[01:54:10.080 --> 01:54:11.800]   when you talk about climate all the time,
[01:54:11.800 --> 01:54:13.160]   that you can call both of them.
[01:54:13.160 --> 01:54:16.520]   But I think the climate crisis and the climate catastrophe
[01:54:16.520 --> 01:54:21.120]   is really sort of, this is the amping up of a catastrophe.
[01:54:21.120 --> 01:54:23.320]   And again, as we've talked about before,
[01:54:23.320 --> 01:54:26.400]   if it really were true, we should tell people.
[01:54:26.400 --> 01:54:28.600]   But if it's not true, and I think there's a lot of reasons
[01:54:28.600 --> 01:54:32.600]   why this is not a climate catastrophe, this is a problem,
[01:54:32.600 --> 01:54:34.720]   we're actually doing everyone a disservice
[01:54:34.720 --> 01:54:37.280]   because we end up making people so worried
[01:54:37.280 --> 01:54:39.160]   that they say, "We gotta fix this in 12 years,"
[01:54:39.160 --> 01:54:40.640]   or whatever the number is.
[01:54:40.640 --> 01:54:43.160]   And also that it makes it almost impossible
[01:54:43.160 --> 01:54:45.440]   to have a conversation of,
[01:54:45.440 --> 01:54:48.640]   well, maybe we should be focusing on vulnerability first.
[01:54:48.640 --> 01:54:52.280]   And a lot of people, and I think a lot of well-meaning
[01:54:52.280 --> 01:54:55.600]   and well-intentioned people feel that it's almost
[01:54:55.600 --> 01:55:00.320]   sacrilegious to say it's about vulnerability
[01:55:00.320 --> 01:55:03.960]   because you're taking away the guilt of climate change.
[01:55:03.960 --> 01:55:05.200]   You're taking away our focus
[01:55:05.200 --> 01:55:07.400]   on dealing with climate change,
[01:55:07.400 --> 01:55:09.080]   whereas I think we would say,
[01:55:09.080 --> 01:55:11.880]   "No, it's about stuff that actually works
[01:55:11.880 --> 01:55:13.640]   "and doing that first."
[01:55:13.640 --> 01:55:17.240]   - Well, and by making it about carbon dioxide,
[01:55:17.240 --> 01:55:20.680]   you're implicitly making it about fossil fuels,
[01:55:20.680 --> 01:55:23.560]   which implicitly gives you another great narrative,
[01:55:23.560 --> 01:55:24.600]   good guy, bad guy.
[01:55:24.600 --> 01:55:27.240]   It's these big companies.
[01:55:27.240 --> 01:55:30.040]   - Where's the source of alarmism?
[01:55:30.040 --> 01:55:32.920]   So is it the IPCC,
[01:55:32.920 --> 01:55:35.960]   the Intergovernmental Panel on Climate Change?
[01:55:35.960 --> 01:55:37.720]   There's a chain here.
[01:55:37.720 --> 01:55:39.880]   Is there somebody to blame along the chain,
[01:55:39.880 --> 01:55:42.080]   or is this some kind of weird complex system
[01:55:42.080 --> 01:55:44.560]   where everybody encourages each other?
[01:55:44.560 --> 01:55:45.880]   Can you point to one place?
[01:55:45.880 --> 01:55:46.920]   Is it the media?
[01:55:46.920 --> 01:55:48.040]   Is it the scientists?
[01:55:48.040 --> 01:55:49.360]   - I think the UN Climate Panel
[01:55:49.360 --> 01:55:54.040]   is fundamentally a really good climate research group.
[01:55:54.040 --> 01:55:56.240]   You can have some quibbles with the way
[01:55:56.240 --> 01:55:57.880]   that they sort of summarize it
[01:55:57.880 --> 01:56:00.720]   in politically coordinated documents and stuff.
[01:56:00.720 --> 01:56:03.120]   But fundamentally, I think they do a good job
[01:56:03.120 --> 01:56:05.880]   of putting together all the research.
[01:56:05.880 --> 01:56:08.200]   This also means it's incredibly boring to read,
[01:56:08.200 --> 01:56:10.760]   which is why virtually nobody does.
[01:56:10.760 --> 01:56:11.640]   I'm sure you have,
[01:56:11.640 --> 01:56:14.480]   but I'm pretty sure a lot of climate journalists
[01:56:14.480 --> 01:56:16.760]   have never sort of looked past
[01:56:16.760 --> 01:56:19.320]   at least the summary for policy makers.
[01:56:19.320 --> 01:56:23.000]   - So the UN Climate Panel, they do predictions as well?
[01:56:23.000 --> 01:56:26.400]   - No, well, they pull together all the stuff
[01:56:26.400 --> 01:56:30.040]   that people have published in the period literature
[01:56:30.040 --> 01:56:32.600]   and then try to summarize it and basically tell you,
[01:56:32.600 --> 01:56:35.160]   so what's up and down with climate change.
[01:56:35.160 --> 01:56:37.880]   They do that in four large volumes
[01:56:37.880 --> 01:56:40.960]   every four to five to six, seven years or something.
[01:56:40.960 --> 01:56:45.840]   And yes, I think it's the gold-plated version
[01:56:45.840 --> 01:56:47.360]   of what we know.
[01:56:47.360 --> 01:56:49.120]   There tends to be a lot of,
[01:56:49.120 --> 01:56:52.680]   well, this is what they say.
[01:56:52.680 --> 01:56:55.040]   Actually, they say so many different places
[01:56:55.040 --> 01:56:56.600]   with so many different people
[01:56:56.600 --> 01:56:59.360]   that it's not quite clear exactly what they're saying often.
[01:56:59.360 --> 01:57:03.120]   You can sort of find contradictions between one volume
[01:57:03.120 --> 01:57:05.280]   with one set of authors and another.
[01:57:05.280 --> 01:57:09.800]   But yeah, I think this is fundamentally the right way
[01:57:09.800 --> 01:57:12.680]   that we know about climate,
[01:57:12.680 --> 01:57:15.480]   but then it gets translated into,
[01:57:15.480 --> 01:57:17.000]   how do you know about this?
[01:57:17.000 --> 01:57:19.720]   When most people don't read these 4,000 pages,
[01:57:19.720 --> 01:57:23.080]   you read a news story in a newspaper
[01:57:23.080 --> 01:57:27.800]   and that news story will be very heavily slanted towards,
[01:57:27.800 --> 01:57:30.600]   if you say, so sea levels could rise
[01:57:30.600 --> 01:57:34.120]   somewhere between one and three foot, what do you hear?
[01:57:34.120 --> 01:57:35.840]   Yeah, you obviously hear the three foot.
[01:57:35.840 --> 01:57:38.360]   Three foot is just more fun, more scary,
[01:57:38.360 --> 01:57:40.880]   more interesting than one foot.
[01:57:40.880 --> 01:57:43.080]   And it's that way with all of these.
[01:57:43.080 --> 01:57:47.000]   So what's the prediction for temperature rises?
[01:57:47.000 --> 01:57:50.840]   It's somewhere from not very scary to pretty damn scary.
[01:57:50.840 --> 01:57:53.880]   And again, you hear the pretty damn scary all the time.
[01:57:53.880 --> 01:57:57.400]   And then there's obviously always researchers
[01:57:57.400 --> 01:57:58.880]   who are saying, well, but actually,
[01:57:58.880 --> 01:58:00.960]   it could be a little more scary than that.
[01:58:00.960 --> 01:58:02.920]   And then there are likewise researchers who say,
[01:58:02.920 --> 01:58:05.840]   well, it's probably not gonna be as scary as that.
[01:58:05.840 --> 01:58:09.520]   And most of the journalists will interview-
[01:58:09.520 --> 01:58:11.680]   Do you really put the blame fundamentally
[01:58:11.680 --> 01:58:13.200]   on the journalists?
[01:58:13.200 --> 01:58:15.760]   I put it on the media setup.
[01:58:15.760 --> 01:58:18.360]   Look, media is simply trying to get clicks
[01:58:18.360 --> 01:58:19.640]   or sell newspapers.
[01:58:19.640 --> 01:58:23.820]   And if you were just gonna say, this is not a big issue,
[01:58:23.820 --> 01:58:25.360]   it just doesn't sell anything.
[01:58:25.360 --> 01:58:28.160]   But I think you're probably much better able to address this.
[01:58:28.160 --> 01:58:32.280]   Well, no, folks can Google for my name, Revkin,
[01:58:32.280 --> 01:58:37.280]   and the words front page thought in the newsroom
[01:58:37.280 --> 01:58:38.840]   every afternoon.
[01:58:38.840 --> 01:58:41.680]   Now we have a 24/7 news cycle, so it's different.
[01:58:41.680 --> 01:58:44.440]   But back in the day, the New York Times,
[01:58:44.440 --> 01:58:46.880]   when it was a flourishing print institution,
[01:58:46.880 --> 01:58:49.280]   every afternoon there was a front page meeting.
[01:58:49.280 --> 01:58:51.320]   And the big pooh-bah editors would go in there.
[01:58:51.320 --> 01:58:54.640]   And the desk editors come in with their pitches for the day.
[01:58:54.640 --> 01:58:57.240]   And my friend, Corrie Dean, who was the science editor
[01:58:57.240 --> 01:58:58.400]   for a chunk of my time,
[01:58:58.400 --> 01:59:01.240]   I remember having a conversation with her
[01:59:01.240 --> 01:59:04.320]   about some new study of, I think it was Greenland,
[01:59:04.320 --> 01:59:07.000]   the ice sheet, and I laid it out for her.
[01:59:07.000 --> 01:59:09.700]   And she said, "Where's the front page thought in that?"
[01:59:09.700 --> 01:59:15.040]   So we're all set up to look for the, that.
[01:59:15.040 --> 01:59:15.880]   - The scary bit.
[01:59:15.880 --> 01:59:19.280]   - And the news environment has gotten so much worse
[01:59:19.280 --> 01:59:21.960]   than 10 or 20 years ago.
[01:59:21.960 --> 01:59:26.400]   At least you had filters and limited number of outlets,
[01:59:26.400 --> 01:59:29.560]   and there was some sense you could track what's good or bad.
[01:59:29.560 --> 01:59:31.520]   There's lots of problems with that system too.
[01:59:31.520 --> 01:59:34.000]   But now you have an information buffet.
[01:59:34.000 --> 01:59:36.560]   So if you wanna be alarmed, or you wanna be,
[01:59:36.560 --> 01:59:39.840]   can stay in the tribe of those who think
[01:59:39.840 --> 01:59:43.400]   this is utter bull, you can find your flow.
[01:59:43.400 --> 01:59:46.640]   And that has led, but getting back
[01:59:46.640 --> 01:59:50.600]   to this specific question, the 2018 IPCC report,
[01:59:50.600 --> 01:59:52.600]   which was a special report commissioned
[01:59:52.600 --> 01:59:55.760]   to learn about the difference between 1.5 degrees
[01:59:55.760 --> 01:59:58.480]   of warming and two, which sounds so weird
[01:59:58.480 --> 02:00:00.760]   and technocratic and complicated.
[02:00:00.760 --> 02:00:03.080]   That's the one that generated the whole meme
[02:00:03.080 --> 02:00:04.680]   about eight years left.
[02:00:04.680 --> 02:00:06.360]   - 12 years. - Till doomsday.
[02:00:06.360 --> 02:00:07.200]   - 2030. - And that's the one.
[02:00:07.200 --> 02:00:08.120]   - Can you explain the meme?
[02:00:08.120 --> 02:00:11.480]   - This was the idea that there's a point we're gonna,
[02:00:11.480 --> 02:00:15.080]   if we don't cut emissions in half by whatever it was,
[02:00:15.080 --> 02:00:17.040]   2050, we're doomed. - 2030, yeah.
[02:00:17.040 --> 02:00:19.280]   - That emerged from that specific report.
[02:00:19.280 --> 02:00:21.080]   And it wasn't something that was in the report.
[02:00:21.080 --> 02:00:22.920]   It was in the spin around the report.
[02:00:22.920 --> 02:00:25.400]   And that's what captivated Greta appropriately
[02:00:25.400 --> 02:00:27.600]   as a young person going, you know,
[02:00:27.600 --> 02:00:30.360]   and with her unique vantage point and stuff.
[02:00:30.360 --> 02:00:33.040]   And that report, I still need to dig in
[02:00:33.040 --> 02:00:35.920]   and write something deeper about what happened
[02:00:35.920 --> 02:00:37.400]   with that particular dynamics,
[02:00:37.400 --> 02:00:41.400]   created this recent burst of we're doomed rhetoric
[02:00:41.400 --> 02:00:44.320]   that I think you're focusing on.
[02:00:44.320 --> 02:00:48.000]   And it's all in the external interpretations,
[02:00:48.000 --> 02:00:50.760]   which journalism laps up
[02:00:50.760 --> 02:00:53.160]   because we're looking for the front page thought.
[02:00:53.160 --> 02:00:56.120]   But it's not just the journalists, it's the whole system,
[02:00:56.120 --> 02:00:58.040]   NGOs, environmental groups.
[02:00:58.040 --> 02:01:00.840]   If you're, and developing country,
[02:01:00.840 --> 02:01:03.560]   well-meaning leaders in developing countries,
[02:01:03.560 --> 02:01:05.640]   because of the structure of this treaty
[02:01:05.640 --> 02:01:07.280]   that goes back to 1992,
[02:01:07.280 --> 02:01:09.480]   that's the Paris Agreement is part of,
[02:01:09.480 --> 02:01:14.880]   they're now really looking for a way
[02:01:14.880 --> 02:01:17.920]   to portray this as a CO2 problem.
[02:01:17.920 --> 02:01:19.720]   Not a vulnerability.
[02:01:19.720 --> 02:01:21.160]   Well, there's a vulnerability aspect,
[02:01:21.160 --> 02:01:25.520]   but like in Pakistan, their climate minister,
[02:01:25.520 --> 02:01:26.960]   which they didn't even have a climate minister
[02:01:26.960 --> 02:01:27.800]   five years ago,
[02:01:27.800 --> 02:01:30.720]   is blaming everything that happened in Pakistan
[02:01:30.720 --> 02:01:32.600]   on carbon dioxide warming the climate,
[02:01:32.600 --> 02:01:34.840]   creating this, when a lot of what was going on
[02:01:34.840 --> 02:01:36.400]   was also on the ground.
[02:01:36.400 --> 02:01:38.920]   And you can blame colonialism, Pakistan's history,
[02:01:38.920 --> 02:01:40.360]   all kinds of things.
[02:01:40.360 --> 02:01:43.560]   But under the treaty, you want it to be about CO2
[02:01:43.560 --> 02:01:46.200]   because that puts the onus on rich countries.
[02:01:46.200 --> 02:01:47.680]   You're not paying us.
[02:01:47.680 --> 02:01:48.840]   Where's our money?
[02:01:48.840 --> 02:01:50.320]   And they're right.
[02:01:50.320 --> 02:01:52.680]   In the context of what everyone agreed to,
[02:01:52.680 --> 02:01:55.320]   there was supposed to be $100 billion a year
[02:01:55.320 --> 02:01:57.600]   from rich countries to poor countries starting in 2020.
[02:01:57.600 --> 02:01:58.440]   It didn't happen.
[02:01:58.440 --> 02:02:01.840]   It's like basically some money is flowing,
[02:02:01.840 --> 02:02:03.400]   but it's not really made up money.
[02:02:03.400 --> 02:02:06.080]   Yeah, and so that whole dynamic,
[02:02:06.080 --> 02:02:07.840]   they latch onto the climate science,
[02:02:07.840 --> 02:02:10.520]   and they, so they're there,
[02:02:10.520 --> 02:02:12.920]   and they're very handy, quotable people.
[02:02:12.920 --> 02:02:14.040]   And you have a justice angle.
[02:02:14.040 --> 02:02:16.240]   You have bad guys and good guys,
[02:02:16.240 --> 02:02:18.000]   which fits all of these narrative threads
[02:02:18.000 --> 02:02:21.080]   that come together into this information storm
[02:02:21.080 --> 02:02:22.040]   we're still living with.
[02:02:22.040 --> 02:02:25.080]   And then of course, it's not Pakistan's fault either.
[02:02:25.080 --> 02:02:28.520]   I mean, it also actually, almost all leaders now say,
[02:02:28.520 --> 02:02:30.760]   it's because of climate, because then it's not,
[02:02:30.760 --> 02:02:32.760]   you know, we didn't do anything wrong.
[02:02:32.760 --> 02:02:36.360]   In Germany, for instance, when we had that flood last year,
[02:02:36.360 --> 02:02:40.560]   it's not impossible that climate had a part in that,
[02:02:40.560 --> 02:02:42.680]   but it's very, very clear that the main reason
[02:02:42.680 --> 02:02:45.280]   why so many people died in Germany and Belgium
[02:02:45.280 --> 02:02:48.240]   was because the alarm systems didn't work.
[02:02:48.240 --> 02:02:52.120]   And this was plainly the local leaders in Germany.
[02:02:52.120 --> 02:02:54.640]   Now, if I'm stuck here and basically have caused
[02:02:54.640 --> 02:02:57.920]   the death of 200 people, would I rather say,
[02:02:57.920 --> 02:03:00.560]   yeah, that's on me, or would I say climate?
[02:03:00.560 --> 02:03:03.520]   Or, you know, so it's just such an easy scapegoat.
[02:03:03.520 --> 02:03:05.760]   I don't wanna place it all on the journalists,
[02:03:05.760 --> 02:03:08.200]   I think, because there's a lot of,
[02:03:08.200 --> 02:03:10.040]   if I were to think about, what did you call it,
[02:03:10.040 --> 02:03:14.200]   front page thought, there's a lot of really
[02:03:15.040 --> 02:03:20.040]   narratives that result in destruction of the human species,
[02:03:20.040 --> 02:03:24.880]   so nuclear war, pandemics, all that kind of stuff.
[02:03:24.880 --> 02:03:27.040]   It seems that climate is a sticky one.
[02:03:27.040 --> 02:03:30.000]   So the fact that it's sticky means there's other interests
[02:03:30.000 --> 02:03:31.960]   at play, like you guys are talking about,
[02:03:31.960 --> 02:03:33.720]   in terms of politics, all that kind of stuff.
[02:03:33.720 --> 02:03:35.480]   So it's not just the journalists.
[02:03:35.480 --> 02:03:37.360]   I feel like journalists will try anything
[02:03:37.360 --> 02:03:40.480]   for the front page, but it won't stick
[02:03:40.480 --> 02:03:43.360]   unless there's bigger interests at play
[02:03:43.360 --> 02:03:45.720]   for which these narratives are useful.
[02:03:45.720 --> 02:03:47.480]   So journalists will just throw stuff out there
[02:03:47.480 --> 02:03:52.480]   and see if it gets clicks, and it's like a first spark,
[02:03:52.480 --> 02:03:57.800]   maybe, it's maybe a tiny catalyst of the initial steps,
[02:03:57.800 --> 02:04:00.400]   but it has to be picked up by the politicians,
[02:04:00.400 --> 02:04:03.200]   by interest groups, and all that kind of stuff.
[02:04:03.200 --> 02:04:08.160]   Let me ask you, Bjorn, about the first part of the subtitle.
[02:04:08.160 --> 02:04:12.320]   How Climate Change Panic Costs Us Trillions.
[02:04:12.320 --> 02:04:14.840]   How does Climate Change Panic Cost Us Trillions?
[02:04:14.840 --> 02:04:17.320]   - So we're basically deciding to make policies
[02:04:17.320 --> 02:04:21.400]   that'll have fairly little impact, even in 50 or 100 years,
[02:04:21.400 --> 02:04:24.040]   that literally cost trillions of dollars.
[02:04:24.040 --> 02:04:26.520]   So, you know, I'll give you two examples.
[02:04:26.520 --> 02:04:31.320]   So the European Union is trying to go to net zero.
[02:04:31.320 --> 02:04:35.080]   So our attempt to go halfway there by 2030
[02:04:35.080 --> 02:04:38.520]   will cost about a trillion dollars a year,
[02:04:38.520 --> 02:04:41.280]   and yet the net impact will be almost unmeasurable
[02:04:41.280 --> 02:04:42.720]   by the end of the century.
[02:04:42.720 --> 02:04:43.800]   Why is that?
[02:04:43.800 --> 02:04:46.160]   That's because the EU and the rich countries
[02:04:46.160 --> 02:04:48.280]   is a fairly small part of the emissions
[02:04:48.280 --> 02:04:50.120]   that are gonna come out in the 21st century.
[02:04:50.120 --> 02:04:51.920]   Now, we used to be a big part of it,
[02:04:51.920 --> 02:04:53.720]   as that's mainly because nobody else, you know,
[02:04:53.720 --> 02:04:56.400]   it was just the US and Europe and a few others
[02:04:56.400 --> 02:04:59.200]   that put out CO2 in the 20th century.
[02:04:59.200 --> 02:05:02.560]   So we used to be big, but in the 21st century,
[02:05:02.560 --> 02:05:04.480]   we'll be a small bit player.
[02:05:04.480 --> 02:05:07.040]   And so we're basically spending a lot of money,
[02:05:07.040 --> 02:05:09.720]   and remember, a trillion dollars is a lot of money
[02:05:09.720 --> 02:05:11.680]   that could have been spent on a lot of things
[02:05:11.680 --> 02:05:14.520]   that could have made humanity better
[02:05:14.520 --> 02:05:18.120]   on something that will only make us tiny bit better.
[02:05:18.120 --> 02:05:21.000]   Now, it will do some good, but, you know,
[02:05:21.000 --> 02:05:22.760]   the reasonable estimates is if you do
[02:05:22.760 --> 02:05:24.960]   a cost-benefit analysis, and again, you know,
[02:05:24.960 --> 02:05:27.720]   technically it's really, really complicated,
[02:05:27.720 --> 02:05:29.880]   but the basic idea is very, very simple.
[02:05:29.880 --> 02:05:33.680]   You just simply say, what are all the costs on one side
[02:05:33.680 --> 02:05:35.200]   and what are all the benefits?
[02:05:35.200 --> 02:05:37.560]   So the costs are mainly that we have to live
[02:05:37.560 --> 02:05:40.520]   with more expensive energy, you have to forego
[02:05:40.520 --> 02:05:42.720]   some opportunities, you have to have, you know,
[02:05:42.720 --> 02:05:45.400]   more complicated services, that kind of thing.
[02:05:45.400 --> 02:05:47.440]   The benefit is that you cut carbon emissions
[02:05:47.440 --> 02:05:48.960]   and that eventually means that you'll have
[02:05:48.960 --> 02:05:51.960]   less climate damage, you'll have lower temperature rises
[02:05:51.960 --> 02:05:53.120]   and so on.
[02:05:53.120 --> 02:05:55.640]   If you try to weigh up all of those,
[02:05:55.640 --> 02:05:59.840]   it's reasonable to assume that the EU policies
[02:05:59.840 --> 02:06:02.640]   will deliver for every dollar you spend,
[02:06:02.640 --> 02:06:04.200]   it'll deliver less than a dollar,
[02:06:04.200 --> 02:06:06.800]   probably about 30 cents back on the dollar,
[02:06:06.800 --> 02:06:08.840]   which is a really bad way to spend dollars
[02:06:08.840 --> 02:06:11.440]   because there's lots of other things out in the world
[02:06:11.440 --> 02:06:13.360]   where you could do, you know, multiple, you know,
[02:06:13.360 --> 02:06:15.400]   so for instance, if you think about tuberculosis
[02:06:15.400 --> 02:06:19.400]   or education of small kids or nutrition for small kids
[02:06:19.400 --> 02:06:21.560]   and those kinds of things, every dollar you spend
[02:06:21.560 --> 02:06:24.160]   will do like 30 to $100 worth of good.
[02:06:24.160 --> 02:06:26.040]   So there are much, much better places
[02:06:26.040 --> 02:06:27.440]   where you could spend this money.
[02:06:27.440 --> 02:06:32.160]   Likewise, the US is thinking of going net zero by 2050.
[02:06:32.160 --> 02:06:35.120]   It's not actually gonna happen, but it's sort of a thing
[02:06:35.120 --> 02:06:36.200]   that everybody talks about.
[02:06:36.200 --> 02:06:38.160]   Biden is talking a lot about it.
[02:06:38.160 --> 02:06:40.320]   If you look at the models that indicate
[02:06:40.320 --> 02:06:44.240]   how much will that cost, it's not implausible
[02:06:44.240 --> 02:06:47.880]   that this will cost somewhere between two and $4 trillion
[02:06:47.880 --> 02:06:49.920]   per year by mid century.
[02:06:49.920 --> 02:06:54.480]   And remember, if the US went carbon neutral today,
[02:06:54.480 --> 02:06:57.840]   by the end of the century, that would reduce temperatures
[02:06:57.840 --> 02:07:00.440]   by about 0.3 degree Fahrenheit.
[02:07:00.440 --> 02:07:03.000]   So you would just be able to measure it.
[02:07:03.000 --> 02:07:05.160]   It probably wouldn't in real life, but you know,
[02:07:05.160 --> 02:07:07.000]   you'd just be able to measure it.
[02:07:07.000 --> 02:07:09.600]   Again, this is not saying that there's not some good
[02:07:09.600 --> 02:07:11.520]   coming out of it, but you're basically spending
[02:07:11.520 --> 02:07:14.720]   an enormous amount of money on fairly small benefits.
[02:07:14.720 --> 02:07:16.520]   So that's my main point.
[02:07:16.520 --> 02:07:18.840]   - Yeah, this reminds me of what we were saying earlier
[02:07:18.840 --> 02:07:22.240]   about the things that models don't integrate
[02:07:22.240 --> 02:07:24.160]   and the things that cost benefit leave out
[02:07:24.160 --> 02:07:26.600]   because you really can't go there.
[02:07:26.600 --> 02:07:28.120]   One of the issues facing the world right now
[02:07:28.120 --> 02:07:30.720]   is the reality that we're reminded of,
[02:07:30.720 --> 02:07:34.800]   that energy availability is a geopolitical destabilizer.
[02:07:34.800 --> 02:07:39.200]   If you have uneven access to energy
[02:07:39.200 --> 02:07:41.280]   and you have Vladimir Putin coming into office
[02:07:41.280 --> 02:07:44.640]   or something else happening that disrupts that system,
[02:07:44.640 --> 02:07:47.720]   you're vastly increasing poverty.
[02:07:47.720 --> 02:07:49.720]   This is playing out across the world.
[02:07:49.720 --> 02:07:54.080]   Fertilizer prices, fertilizer comes from gas, natural gas.
[02:07:54.080 --> 02:07:59.940]   If you can envision a world later in the century
[02:07:59.940 --> 02:08:01.680]   where we're no longer beholden on this material
[02:08:01.680 --> 02:08:04.400]   in the ground, at least fossil fuels,
[02:08:04.400 --> 02:08:06.560]   you know, cobalt and lithium for batteries,
[02:08:06.560 --> 02:08:08.700]   that's pretty cool, you know,
[02:08:08.700 --> 02:08:11.640]   'cause you're taking away geopolitical instability.
[02:08:11.640 --> 02:08:15.040]   And you don't, but that's not factored in, right?
[02:08:15.040 --> 02:08:17.020]   That's like way outside of what you'd factor in.
[02:08:17.020 --> 02:08:18.880]   But it does feel like to me, you know,
[02:08:18.880 --> 02:08:20.660]   if I was gonna make the case for,
[02:08:20.660 --> 02:08:23.320]   you can choose your trillions,
[02:08:23.320 --> 02:08:28.320]   whatever that investing big isn't for these marginal things.
[02:08:28.320 --> 02:08:30.840]   It's for looking at the big picture,
[02:08:30.840 --> 02:08:33.560]   a world of abundant energy that doesn't come
[02:08:33.560 --> 02:08:36.800]   from a black rock or a gooey liquid
[02:08:36.800 --> 02:08:38.280]   that when you burn it creates--
[02:08:38.280 --> 02:08:40.440]   - But isn't that what the proposals are?
[02:08:40.440 --> 02:08:43.640]   Is investing in different kinds of energy,
[02:08:43.640 --> 02:08:45.200]   renewable energy, so what--
[02:08:45.200 --> 02:08:47.320]   - But I don't think most people are making that case.
[02:08:47.320 --> 02:08:51.080]   - What's in the trillion in the T costs?
[02:08:51.080 --> 02:08:53.320]   What's incorporated, what are the big costs there?
[02:08:53.320 --> 02:08:55.720]   - So the big cost is that you have
[02:08:55.720 --> 02:08:58.240]   slightly lower productivity gains.
[02:08:58.240 --> 02:08:59.600]   So basically again, you know,
[02:08:59.600 --> 02:09:00.960]   and this is sort of the opposite
[02:09:00.960 --> 02:09:03.020]   of what we just talked about by climate change.
[02:09:03.020 --> 02:09:05.360]   We're gonna get richer and richer in the world.
[02:09:05.360 --> 02:09:07.360]   This is all models, also the UN,
[02:09:07.360 --> 02:09:09.160]   this is really the only way that you can get
[02:09:09.160 --> 02:09:11.940]   big climate changes because everybody gets a lot richer.
[02:09:11.940 --> 02:09:14.180]   So also the developing world gets a lot richer.
[02:09:14.180 --> 02:09:16.320]   So we're likely to get richer.
[02:09:16.320 --> 02:09:19.520]   But one of the things that drive wealth production
[02:09:19.520 --> 02:09:21.420]   is the fact that we have ample
[02:09:21.420 --> 02:09:23.840]   and cheap and available energy.
[02:09:23.840 --> 02:09:25.820]   If you make that slightly harder,
[02:09:25.820 --> 02:09:28.260]   which is what you do with climate legislation,
[02:09:28.260 --> 02:09:29.920]   because you're basically telling people
[02:09:29.920 --> 02:09:31.820]   you have to use a source of energy
[02:09:31.820 --> 02:09:34.080]   that you'd rather not have used,
[02:09:34.080 --> 02:09:35.920]   because if people wanted to do it,
[02:09:35.920 --> 02:09:37.360]   we'd already have solved the problem.
[02:09:37.360 --> 02:09:38.360]   So you're basically telling them
[02:09:38.360 --> 02:09:40.160]   you've got to use this wind turbine
[02:09:40.160 --> 02:09:42.740]   instead of this natural gas plant,
[02:09:42.740 --> 02:09:44.680]   or you know, that kind of thing.
[02:09:44.680 --> 02:09:47.780]   It's not that you suddenly become poor or anything,
[02:09:47.780 --> 02:09:50.360]   it simply makes production slightly harder.
[02:09:50.360 --> 02:09:53.000]   What do you do when the wind is not blowing kind of thing?
[02:09:53.000 --> 02:09:54.440]   And of course we have lots of ways
[02:09:54.440 --> 02:09:56.120]   to somewhat mitigate that,
[02:09:56.120 --> 02:09:57.580]   but it's a little more costly,
[02:09:57.580 --> 02:10:00.080]   a little more complicated, a little less convenient.
[02:10:00.080 --> 02:10:02.480]   And that means you grow a little less.
[02:10:02.480 --> 02:10:05.720]   That's the main problem with these policies,
[02:10:05.720 --> 02:10:08.360]   that it simply makes you somewhat less well-off.
[02:10:08.360 --> 02:10:10.640]   - So energy becomes more inefficient.
[02:10:10.640 --> 02:10:11.480]   - Yes.
[02:10:11.480 --> 02:10:14.140]   - So let me challenge you here.
[02:10:14.140 --> 02:10:17.640]   Try to steel man some critics.
[02:10:17.640 --> 02:10:19.600]   So you have critics.
[02:10:19.600 --> 02:10:25.160]   I would love you to take it seriously
[02:10:25.160 --> 02:10:27.200]   and sort of consider this criticism
[02:10:27.200 --> 02:10:29.820]   and try to steel man their case.
[02:10:29.820 --> 02:10:34.820]   There's a bunch, I could mention this list of criticisms
[02:10:34.820 --> 02:10:39.080]   from Bob Ward in London School of Economics.
[02:10:39.080 --> 02:10:40.600]   I don't know if you're familiar with him.
[02:10:40.600 --> 02:10:42.200]   But just on this point,
[02:10:42.200 --> 02:10:45.080]   in terms of one of the big costs being an energy,
[02:10:45.080 --> 02:10:50.240]   he criticizes your recent book in saying,
[02:10:50.240 --> 02:10:53.760]   "You consider the 143 billion in annual support
[02:10:53.760 --> 02:10:54.860]   "for renewable energy,
[02:10:54.860 --> 02:10:59.640]   "but ignore the 300 billion in fossil fuel subsidies."
[02:10:59.640 --> 02:11:03.820]   So a lot of the criticism has to do with,
[02:11:03.820 --> 02:11:06.220]   well, you're cherry-picking the models,
[02:11:06.220 --> 02:11:09.580]   which the models are always cherry-picking anyway.
[02:11:09.580 --> 02:11:12.740]   But you wanna take those seriously.
[02:11:12.740 --> 02:11:16.620]   So he claims that you ignore,
[02:11:16.620 --> 02:11:21.620]   you're not fully modeling the costs, the trade-off here.
[02:11:21.620 --> 02:11:26.100]   How expensive is the renewable energy
[02:11:26.100 --> 02:11:28.180]   and how expensive is the fossil fuel?
[02:11:28.180 --> 02:11:29.600]   Can you steel man his case?
[02:11:29.600 --> 02:11:30.440]   - Sure.
[02:11:30.440 --> 02:11:31.780]   So two things.
[02:11:31.780 --> 02:11:34.180]   The first, the quote,
[02:11:34.180 --> 02:11:36.580]   it's absolutely true that the world spends
[02:11:36.580 --> 02:11:40.260]   a large chunk of money on fossil fuels,
[02:11:40.260 --> 02:11:42.980]   and that's just stupid, and we should stop doing it.
[02:11:42.980 --> 02:11:45.780]   We should also recognize that this is not rich countries.
[02:11:45.780 --> 02:11:46.980]   This is not the countries
[02:11:46.980 --> 02:11:48.620]   where we're talking about climate change.
[02:11:48.620 --> 02:11:49.580]   This is poor countries.
[02:11:49.580 --> 02:11:51.420]   This is Saudi Arabia.
[02:11:51.420 --> 02:11:54.180]   No, that's actually not a terribly poor country.
[02:11:54.180 --> 02:11:57.940]   It's China, it's Indonesia, it's Russia.
[02:11:58.300 --> 02:12:01.100]   It's places where you're basically paying off
[02:12:01.100 --> 02:12:03.820]   your population, just like that you subsidize bread,
[02:12:03.820 --> 02:12:05.340]   you make sure that they don't rebel
[02:12:05.340 --> 02:12:08.220]   by making cheap fuels available.
[02:12:08.220 --> 02:12:11.260]   That's dumb, but it's not like they don't know
[02:12:11.260 --> 02:12:12.080]   what they're doing.
[02:12:12.080 --> 02:12:13.300]   They're mostly doing this for things
[02:12:13.300 --> 02:12:15.020]   that have nothing to do with climate.
[02:12:15.020 --> 02:12:17.300]   So I totally agree we should get rid of it.
[02:12:17.300 --> 02:12:18.260]   It's hard to do.
[02:12:18.260 --> 02:12:22.020]   Indonesia's actually somewhat managed to get rid of it,
[02:12:22.020 --> 02:12:23.780]   because remember, if you spend a lot of money
[02:12:23.780 --> 02:12:25.140]   on fossil fuel subsidies,
[02:12:25.140 --> 02:12:26.980]   you're basically subsidizing the rich,
[02:12:26.980 --> 02:12:29.220]   because poor people don't have a car.
[02:12:29.220 --> 02:12:33.300]   It's the rich people who can now buy very cheap gasoline.
[02:12:33.300 --> 02:12:35.860]   That's unjust as well.
[02:12:35.860 --> 02:12:38.100]   So it's dumb in so many different ways.
[02:12:38.100 --> 02:12:40.180]   I would never argue that you shouldn't do it.
[02:12:40.180 --> 02:12:43.380]   I've plenty of times said we should stop that,
[02:12:43.380 --> 02:12:46.300]   but we should also recognize these are mostly regimes
[02:12:46.300 --> 02:12:48.260]   that are not going to be taken over
[02:12:48.260 --> 02:12:51.180]   either by my argument or Bob Ward's or anyone else's.
[02:12:51.180 --> 02:12:53.580]   They're doing this for totally different reasons.
[02:12:53.580 --> 02:12:58.580]   Now, on the model side, there is virtually no model
[02:12:58.580 --> 02:13:00.540]   that don't show, economic model,
[02:13:00.540 --> 02:13:02.260]   that don't show this has a cost.
[02:13:02.260 --> 02:13:05.940]   And that's the fundamental point is that the,
[02:13:05.940 --> 02:13:08.680]   this is sort of a basic point from economics.
[02:13:08.680 --> 02:13:11.260]   The system is already working most effectively,
[02:13:11.260 --> 02:13:12.660]   because if it wasn't,
[02:13:12.660 --> 02:13:15.100]   you could actually make money changing over.
[02:13:15.100 --> 02:13:17.860]   So if you want to have a change outside
[02:13:17.860 --> 02:13:19.580]   of what the system is already doing,
[02:13:19.580 --> 02:13:21.620]   it's because you're saying you have to do something
[02:13:21.620 --> 02:13:23.340]   that you'd rather not want to do,
[02:13:23.340 --> 02:13:25.780]   namely use an energy source that is less convenient
[02:13:25.780 --> 02:13:28.460]   or less cost-effective and so on.
[02:13:28.460 --> 02:13:30.560]   And that will incur a cost.
[02:13:30.560 --> 02:13:33.260]   Now there's huge discussion about just exactly
[02:13:33.260 --> 02:13:34.540]   how much cost is that.
[02:13:34.540 --> 02:13:36.240]   So there's definitely a cost.
[02:13:36.240 --> 02:13:38.780]   Is the cost going to be one or 5 trillion?
[02:13:38.780 --> 02:13:40.740]   That's absolutely a discussion about
[02:13:40.740 --> 02:13:42.060]   where do you take your models from?
[02:13:42.060 --> 02:13:45.540]   I try to do, and again, this is not possible everywhere.
[02:13:45.540 --> 02:13:47.900]   I try to actually take the average
[02:13:47.900 --> 02:13:49.820]   of all of the economic models.
[02:13:49.820 --> 02:13:51.460]   So there's a group called
[02:13:51.460 --> 02:13:53.000]   the Stanford Energy Modeling Forum,
[02:13:53.000 --> 02:13:56.220]   which tries to pull together all these different groups
[02:13:56.220 --> 02:13:57.140]   that do the modeling.
[02:13:57.140 --> 02:14:00.620]   So some models, a lot of this cost actually comes down to
[02:14:00.620 --> 02:14:04.500]   the fact that we don't quite know how much more
[02:14:04.500 --> 02:14:06.740]   fossil fuels you're going to need in the future.
[02:14:06.740 --> 02:14:09.000]   And so if you're projections are
[02:14:09.000 --> 02:14:10.520]   you're not going to use that much,
[02:14:10.520 --> 02:14:12.820]   the cost of reducing it is going to be very small.
[02:14:12.820 --> 02:14:16.500]   If you think you're going to use a ton of extra fossil fuels
[02:14:16.500 --> 02:14:17.700]   and you have to reduce that,
[02:14:17.700 --> 02:14:19.220]   the cost is going to be bigger.
[02:14:19.220 --> 02:14:20.060]   So I think-
[02:14:20.060 --> 02:14:21.740]   - That's just one of the variables.
[02:14:21.740 --> 02:14:22.580]   - Oh yeah, yeah.
[02:14:22.580 --> 02:14:24.700]   - And there's many, many, many more.
[02:14:24.700 --> 02:14:26.780]   - I think the point here is to say
[02:14:26.780 --> 02:14:30.540]   that if you take the average of all the best modelists
[02:14:30.540 --> 02:14:31.620]   that sort of aggregate it,
[02:14:31.620 --> 02:14:34.160]   for instance, at the Stanford Energy Modeling Forum,
[02:14:34.160 --> 02:14:36.460]   you're pretty secure ground.
[02:14:36.460 --> 02:14:41.500]   So again, I would argue that Bob Ward,
[02:14:41.500 --> 02:14:44.920]   yes, I've had a lot of run-ins with Bob Ward,
[02:14:44.920 --> 02:14:49.840]   and he has a very different set of views on things,
[02:14:49.840 --> 02:14:52.260]   but I just don't think he's right in saying
[02:14:52.260 --> 02:14:53.340]   that I'm cherry picking.
[02:14:53.340 --> 02:14:54.180]   - Well, yes.
[02:14:54.180 --> 02:14:56.420]   And I mean, he also has similar criticism
[02:14:56.420 --> 02:14:59.860]   about the estimate of the EU cost of climate action
[02:14:59.860 --> 02:15:04.300]   based on the NOP 2013 model.
[02:15:04.300 --> 02:15:06.740]   But ultimately these criticisms have to do is like,
[02:15:06.740 --> 02:15:09.620]   what are the sources for the different models?
[02:15:09.620 --> 02:15:10.780]   - And just very briefly,
[02:15:10.780 --> 02:15:12.980]   I mean, I'm laying it out very transparently
[02:15:12.980 --> 02:15:14.340]   where I get these models,
[02:15:14.340 --> 02:15:16.380]   where I get these estimates from in the book.
[02:15:16.380 --> 02:15:18.180]   I've really tried to document this.
[02:15:18.180 --> 02:15:19.740]   And yes, I mean, look,
[02:15:19.740 --> 02:15:22.980]   there's nobody who sort of has all the information
[02:15:22.980 --> 02:15:26.220]   and gets everything right in all of these areas.
[02:15:26.220 --> 02:15:29.780]   I think most of Bob Ward's argument
[02:15:29.780 --> 02:15:34.260]   is not a good faith effort
[02:15:34.260 --> 02:15:38.580]   to sort of improve on these estimates.
[02:15:38.580 --> 02:15:40.900]   He's right in saying some of these estimates,
[02:15:40.900 --> 02:15:42.880]   we only have a few estimates.
[02:15:42.880 --> 02:15:45.700]   And yeah, I'd like to have more of them.
[02:15:45.700 --> 02:15:47.660]   One thing I should mention is
[02:15:47.660 --> 02:15:50.060]   that there is very little interest in general
[02:15:50.060 --> 02:15:51.620]   and there's very little funding
[02:15:51.620 --> 02:15:55.380]   in finding out how much do our climate policies cost?
[02:15:55.380 --> 02:15:58.180]   Because that's just inconvenient to everyone
[02:15:58.180 --> 02:15:59.540]   in the whole game.
[02:15:59.540 --> 02:16:02.440]   Who wants to know that, for instance,
[02:16:02.440 --> 02:16:06.340]   would you want to fund something that says
[02:16:06.340 --> 02:16:08.020]   that the Inflation Reduction Act
[02:16:08.020 --> 02:16:09.640]   is not gonna be very effective?
[02:16:09.640 --> 02:16:11.740]   Of course you don't want to do that, right?
[02:16:11.740 --> 02:16:15.500]   So again, it's a little bit the flock of birds
[02:16:15.500 --> 02:16:17.540]   will look at something else.
[02:16:17.540 --> 02:16:20.940]   And what I think is that given that we're paying for it,
[02:16:20.940 --> 02:16:22.980]   and this is public money,
[02:16:22.980 --> 02:16:24.740]   we're deciding we're gonna spend money here
[02:16:24.740 --> 02:16:25.720]   rather than there,
[02:16:25.720 --> 02:16:28.800]   let's at least look at what are the best estimates out there.
[02:16:28.800 --> 02:16:31.180]   I would love to have more estimates.
[02:16:31.180 --> 02:16:32.420]   More estimates is always better.
[02:16:32.420 --> 02:16:35.780]   - And just a quick comment on the good faith part.
[02:16:35.780 --> 02:16:38.060]   Me as a consumer looking for truth,
[02:16:38.060 --> 02:16:40.460]   it's hard to find who's good faith and not.
[02:16:40.460 --> 02:16:42.460]   So it's not only are you looking for
[02:16:42.460 --> 02:16:45.500]   sort of accurate information,
[02:16:46.380 --> 02:16:48.300]   you're also trying to infer
[02:16:48.300 --> 02:16:50.940]   about the communicator of that information.
[02:16:50.940 --> 02:16:52.280]   And it's very difficult.
[02:16:52.280 --> 02:16:55.820]   - You put me on the podcast.
[02:16:55.820 --> 02:16:58.700]   Of course I'm gonna say I'm a trustworthy guy.
[02:16:58.700 --> 02:17:02.980]   - Well, I mean, and we believe we're trustworthy too,
[02:17:02.980 --> 02:17:07.980]   but I've been reading for various reasons,
[02:17:07.980 --> 02:17:10.260]   but mostly because I've been traveling to Ukraine
[02:17:10.260 --> 02:17:15.260]   and thinking just about the people suffering through war.
[02:17:15.580 --> 02:17:17.260]   I've been reading a lot about World War II
[02:17:17.260 --> 02:17:19.220]   and Stalin and Hitler.
[02:17:19.220 --> 02:17:21.800]   And from the perspective of Hitler,
[02:17:21.800 --> 02:17:28.460]   he really believed he's doing good for the world.
[02:17:28.460 --> 02:17:33.320]   And he was communicating from his perspective in good faith.
[02:17:33.320 --> 02:17:36.260]   He started to believe, I think, early on,
[02:17:36.260 --> 02:17:37.340]   his own propaganda.
[02:17:37.340 --> 02:17:40.620]   So even your understanding and perception
[02:17:40.620 --> 02:17:41.780]   of the world completely shifted.
[02:17:41.780 --> 02:17:44.780]   So it's very, very, very difficult
[02:17:44.780 --> 02:17:46.520]   to understand who to trust.
[02:17:46.520 --> 02:17:52.540]   And just because it's a consensus in a particular community
[02:17:52.540 --> 02:17:54.820]   doesn't necessarily mean it's a source of trust.
[02:17:54.820 --> 02:17:57.960]   So it's, I mean, basically,
[02:17:57.960 --> 02:18:01.220]   I don't know how to operate in this world
[02:18:01.220 --> 02:18:02.620]   except to have a humility
[02:18:02.620 --> 02:18:05.780]   and constantly questioning your assumptions.
[02:18:05.780 --> 02:18:08.900]   But not so much that you're completely out in the ocean,
[02:18:08.900 --> 02:18:10.840]   not knowing what is true and not.
[02:18:10.840 --> 02:18:13.140]   So it's this weird, weird world.
[02:18:13.140 --> 02:18:16.540]   Because I ultimately, bigger than climate,
[02:18:16.540 --> 02:18:22.420]   my hope is to have institutions that can be trusted.
[02:18:22.420 --> 02:18:25.140]   And that's been very much under attack
[02:18:25.140 --> 02:18:28.620]   as part of the climate debate,
[02:18:28.620 --> 02:18:31.200]   as part of the COVID debate,
[02:18:31.200 --> 02:18:33.180]   as part of all these discussions.
[02:18:33.180 --> 02:18:37.740]   And science, to me, is one of the sources of truth.
[02:18:37.740 --> 02:18:39.760]   And the fact that that's under question now
[02:18:39.760 --> 02:18:43.020]   is something that hurts me on many levels.
[02:18:43.020 --> 02:18:44.100]   Deeply.
[02:18:44.100 --> 02:18:45.260]   - You said something earlier,
[02:18:45.260 --> 02:18:47.580]   I took a note down here and I can't find it,
[02:18:47.580 --> 02:18:48.620]   about cooperation.
[02:18:48.620 --> 02:18:51.340]   It was like collaborative cooperation or something like that?
[02:18:51.340 --> 02:18:52.460]   - Sure.
[02:18:52.460 --> 02:18:56.200]   - To me, there was a point, like in 2013,
[02:18:56.200 --> 02:18:58.460]   after just dealing with everything
[02:18:58.460 --> 02:18:59.820]   you've been grappling with,
[02:18:59.820 --> 02:19:05.380]   if you know you don't know how this is gonna work out,
[02:19:05.380 --> 02:19:06.380]   what do you work on?
[02:19:06.380 --> 02:19:10.180]   And one morning I made a list of words
[02:19:10.180 --> 02:19:13.860]   that kind of summarized basically system properties
[02:19:13.860 --> 02:19:17.020]   that give you confidence in a system, trust.
[02:19:17.020 --> 02:19:21.740]   And transparency is one, just as you were saying earlier.
[02:19:21.740 --> 02:19:28.380]   Connectivity is another, so everyone's connected.
[02:19:28.380 --> 02:19:31.400]   So on the subsidy issue, for example,
[02:19:31.400 --> 02:19:35.500]   there are young entrepreneurs in Nairobi
[02:19:35.500 --> 02:19:38.260]   who are selling ingeniously using
[02:19:38.260 --> 02:19:41.460]   Nairobi's digital currency, propane,
[02:19:41.460 --> 02:19:44.720]   the fuel that's in our backyard barbecue grills,
[02:19:44.720 --> 02:19:47.520]   which comes out of gas wells, but it's a separate fuel,
[02:19:47.520 --> 02:19:50.040]   in little increments that poor people
[02:19:50.040 --> 02:19:51.560]   can use instead of charcoal.
[02:19:51.560 --> 02:19:56.700]   And LPG subsidies are helping them
[02:19:56.700 --> 02:20:01.120]   get people off of charcoal, which is a horrific trade
[02:20:01.120 --> 02:20:05.020]   from the source through the warlords in Somalia
[02:20:05.020 --> 02:20:07.420]   and elsewhere who are getting the money
[02:20:07.420 --> 02:20:09.580]   to the pollution in houses.
[02:20:09.580 --> 02:20:14.140]   So being sure when we're having these big debates
[02:20:14.140 --> 02:20:17.500]   about who the World Bank is gonna give loans to,
[02:20:17.500 --> 02:20:20.860]   and drawing a simple line, no more fossil fuel subsidies,
[02:20:20.860 --> 02:20:24.440]   hurts a really good, valuable,
[02:20:24.440 --> 02:20:29.880]   small-scale but scalable way to have people
[02:20:29.880 --> 02:20:31.760]   not die from cooking smoke in their houses
[02:20:31.760 --> 02:20:33.060]   and take down forests.
[02:20:34.220 --> 02:20:37.020]   But that only is considered if they're in the conversation.
[02:20:37.020 --> 02:20:40.080]   So connectivity, full connectivity, digital access,
[02:20:40.080 --> 02:20:42.900]   so those entrepreneurs are in the mix of people,
[02:20:42.900 --> 02:20:44.180]   when they're thinking about subsidies,
[02:20:44.180 --> 02:20:45.660]   you're not just thinking about Big Bad Exxon,
[02:20:45.660 --> 02:20:47.820]   you're thinking about this little company
[02:20:47.820 --> 02:20:51.260]   in Nairobi, Pago LPG, I think is the name,
[02:20:51.260 --> 02:20:52.500]   and India, the same thing.
[02:20:52.500 --> 02:20:55.340]   So you can list those properties of systems.
[02:20:55.340 --> 02:20:59.100]   And the IPCC wasn't originally transparent
[02:20:59.100 --> 02:21:03.820]   when I started writing about it in 1988 and 1990,
[02:21:03.820 --> 02:21:05.340]   and now it's way more transparent.
[02:21:05.340 --> 02:21:06.780]   They have more public review.
[02:21:06.780 --> 02:21:09.540]   So it's even better than it was.
[02:21:09.540 --> 02:21:12.300]   It's like a really good example of a science process
[02:21:12.300 --> 02:21:14.020]   of assessing the science,
[02:21:14.020 --> 02:21:16.800]   providing periodic output to the world,
[02:21:16.800 --> 02:21:20.140]   and iteratively improving the model going forward
[02:21:20.140 --> 02:21:23.680]   because of critique, because of scrutiny,
[02:21:23.680 --> 02:21:26.620]   and finding better ways for that to interface with people
[02:21:26.620 --> 02:21:28.860]   so they have information they can use from that big thing.
[02:21:28.860 --> 02:21:31.220]   And the media are not doing a good job
[02:21:32.700 --> 02:21:35.360]   because of this front-page thotism.
[02:21:35.360 --> 02:21:40.460]   But we can all, I work partially in academia, Columbia,
[02:21:40.460 --> 02:21:43.460]   on an initiative partially in communication innovation.
[02:21:43.460 --> 02:21:45.980]   Like how can we have an open landscape
[02:21:45.980 --> 02:21:47.460]   of access to information that matters?
[02:21:47.460 --> 02:21:48.940]   How can you, what can you do
[02:21:48.940 --> 02:21:51.180]   to foster better conversations
[02:21:51.180 --> 02:21:52.380]   so that words like collapse
[02:21:52.380 --> 02:21:54.660]   aren't just thrown around like emblems?
[02:21:54.660 --> 02:21:58.380]   And so system properties give you confidence, I think.
[02:21:58.380 --> 02:22:01.120]   And then you don't have to be flailing around
[02:22:01.120 --> 02:22:06.120]   for Bjorn or Tom Friedman or Catherine Hayhoe.
[02:22:06.120 --> 02:22:11.620]   You can always, right now, find your character to follow.
[02:22:11.620 --> 02:22:13.620]   But I think what would be better
[02:22:13.620 --> 02:22:15.420]   is if you actually develop some skills
[02:22:15.420 --> 02:22:19.420]   to just have a basic ability to know how to cut to the chase.
[02:22:19.420 --> 02:22:21.660]   - Can I just follow up on that?
[02:22:21.660 --> 02:22:23.700]   Because one of the things that I try to do,
[02:22:23.700 --> 02:22:26.900]   and so my day job is actually something else I work with,
[02:22:26.900 --> 02:22:29.700]   I think called the Copenhagen Consensus,
[02:22:29.700 --> 02:22:31.440]   where we work with more than 300
[02:22:31.440 --> 02:22:32.520]   of the world's top economists,
[02:22:32.520 --> 02:22:35.280]   and we've worked with seven Nobel laureates in economics.
[02:22:35.280 --> 02:22:38.240]   And the point there is really to talk about
[02:22:38.240 --> 02:22:40.160]   where can you spend a dollar
[02:22:40.160 --> 02:22:42.720]   and do the most good for the world?
[02:22:42.720 --> 02:22:46.240]   That's basically the thing that we try to do.
[02:22:46.240 --> 02:22:48.480]   And as you rightly point out,
[02:22:48.480 --> 02:22:50.440]   look, there are lots of different estimates
[02:22:50.440 --> 02:22:52.400]   of what can you do, for instance, on climate?
[02:22:52.400 --> 02:22:54.560]   What can you do on tuberculosis?
[02:22:54.560 --> 02:22:56.900]   What can you do for vulnerability
[02:22:56.900 --> 02:22:58.960]   in all kinds of different ways?
[02:22:58.960 --> 02:23:00.920]   And if these were all sort of,
[02:23:00.920 --> 02:23:04.640]   well, you can spend a dollar here and do 2.36,
[02:23:04.640 --> 02:23:08.560]   but you can spend a dollar here and do 2.34 over here,
[02:23:08.560 --> 02:23:09.520]   I would worry a lot.
[02:23:09.520 --> 02:23:11.280]   But that's not how the world works,
[02:23:11.280 --> 02:23:13.840]   because we're terribly inefficient.
[02:23:13.840 --> 02:23:16.520]   So there are literally lots and lots
[02:23:16.520 --> 02:23:18.640]   of amazing things you can do out there.
[02:23:18.640 --> 02:23:20.080]   - There's a lot of low-hanging fruit.
[02:23:20.080 --> 02:23:23.000]   - And there's a lot of not terribly great things
[02:23:23.000 --> 02:23:24.020]   that you can do.
[02:23:24.020 --> 02:23:25.800]   And unfortunately, one of the things
[02:23:25.800 --> 02:23:28.360]   I try to sort of battle is that,
[02:23:28.360 --> 02:23:29.480]   we get a lot of things right.
[02:23:29.480 --> 02:23:31.160]   That's why the world is a lot better
[02:23:31.160 --> 02:23:32.720]   than what it used to be.
[02:23:32.720 --> 02:23:35.320]   But the things that are sort of left over
[02:23:35.320 --> 02:23:37.760]   are often the boring things
[02:23:37.760 --> 02:23:39.480]   that happen to be incredibly effective
[02:23:39.480 --> 02:23:41.320]   and the exciting things that are often
[02:23:41.320 --> 02:23:43.640]   not that terribly effective.
[02:23:43.640 --> 02:23:46.560]   And so I think one way to look at this
[02:23:46.560 --> 02:23:49.160]   is basically to have people do cost-benefit
[02:23:49.160 --> 02:23:50.680]   across a wide range of areas.
[02:23:50.680 --> 02:23:53.160]   And we try to get a lot of different economists to do this,
[02:23:53.160 --> 02:23:54.760]   and they come up with different numbers
[02:23:54.760 --> 02:23:56.800]   and different models and different results.
[02:23:56.800 --> 02:23:59.680]   But if you sort of consistently get that some things
[02:23:59.680 --> 02:24:02.720]   give you in tens or maybe even hundreds of dollars
[02:24:02.720 --> 02:24:04.120]   back per dollar,
[02:24:04.120 --> 02:24:06.000]   remember this is not actually you getting rich,
[02:24:06.000 --> 02:24:07.200]   it's the world getting rich.
[02:24:07.200 --> 02:24:10.960]   It's that the world gets better worth $100
[02:24:10.960 --> 02:24:12.560]   for every dollar you spend.
[02:24:12.560 --> 02:24:14.240]   And over here, you can spend a dollar
[02:24:14.240 --> 02:24:15.920]   and do somewhere between 30 cents
[02:24:15.920 --> 02:24:17.800]   and maybe a couple of dollars.
[02:24:17.800 --> 02:24:19.040]   You should probably be focused
[02:24:19.040 --> 02:24:20.800]   on the other opportunity first.
[02:24:20.800 --> 02:24:23.520]   And that's really the point that I try to make with climate.
[02:24:23.520 --> 02:24:25.040]   There are some smart things we can do,
[02:24:25.040 --> 02:24:28.560]   and I hope we get to talk about them in climate.
[02:24:28.560 --> 02:24:31.280]   But there's also a lot of sort of the standard approaches
[02:24:31.280 --> 02:24:35.080]   to fixing climate turns out to be very likely
[02:24:35.080 --> 02:24:36.880]   below $1 back in dollar,
[02:24:36.880 --> 02:24:38.880]   and certainly not terribly high.
[02:24:38.880 --> 02:24:41.640]   Even if you're very optimistic, it'll be like two or three.
[02:24:41.640 --> 02:24:43.600]   Whereas many other things
[02:24:43.600 --> 02:24:46.400]   are just fantastically better investment.
[02:24:46.400 --> 02:24:48.320]   - Like the thing I've been advocating,
[02:24:48.320 --> 02:24:53.320]   a modest proposal to eat the children of the poor in England.
[02:24:53.400 --> 02:24:56.960]   Was that in Jonathan Swift's modest proposal
[02:24:56.960 --> 02:24:58.680]   from a few centuries ago?
[02:24:58.680 --> 02:25:02.560]   So it's not just cost benefit,
[02:25:02.560 --> 02:25:05.440]   it's also in the context of what is moral
[02:25:05.440 --> 02:25:08.480]   and the full complexity of it.
[02:25:08.480 --> 02:25:10.160]   - You just hit on something really important.
[02:25:10.160 --> 02:25:11.520]   Having been on this beat for so long,
[02:25:11.520 --> 02:25:14.440]   and again, on the disaster beat as well, earthquakes.
[02:25:14.440 --> 02:25:18.100]   I can't tell you how many disaster science experts
[02:25:18.100 --> 02:25:20.160]   keep telling me, like everyone says,
[02:25:20.160 --> 02:25:22.520]   preparedness, invest for preparedness.
[02:25:22.520 --> 02:25:24.800]   A strict cost benefit analysis will always tell you
[02:25:24.800 --> 02:25:27.860]   a dollar invested in resilience
[02:25:27.860 --> 02:25:32.000]   before a community gets hit by whatever is worth 10.
[02:25:32.000 --> 02:25:33.720]   You'll always have to spend 10 after.
[02:25:33.720 --> 02:25:36.100]   And so it's fine to do the cost benefit stuff,
[02:25:36.100 --> 02:25:38.120]   but it's just the baseline.
[02:25:38.120 --> 02:25:40.200]   Then you have to look at the social science,
[02:25:40.200 --> 02:25:42.100]   which shows, or history,
[02:25:42.100 --> 02:25:44.860]   which shows you how few times we do it.
[02:25:44.860 --> 02:25:46.320]   It's like, we just don't do it.
[02:25:46.320 --> 02:25:49.240]   Therefore, you can bang that drum.
[02:25:49.240 --> 02:25:52.260]   Your work is valuable, but it's really constrained.
[02:25:52.260 --> 02:25:56.820]   Because show me in the world where that does happen,
[02:25:56.820 --> 02:25:59.560]   and then how you turn that success,
[02:25:59.560 --> 02:26:02.200]   which is basically something not happening,
[02:26:02.200 --> 02:26:03.040]   into a story.
[02:26:03.040 --> 02:26:06.000]   - So, just very briefly, we try to,
[02:26:06.000 --> 02:26:07.840]   so we do this for a lot of countries.
[02:26:07.840 --> 02:26:10.320]   So we did it for Haiti, for instance,
[02:26:10.320 --> 02:26:13.920]   funded by the Canadian Development Ministry,
[02:26:13.920 --> 02:26:15.320]   because they're basically saying,
[02:26:15.320 --> 02:26:17.860]   we've spent a billion dollars in Haiti since the earthquake,
[02:26:17.860 --> 02:26:19.840]   and we really can't tell the difference.
[02:26:19.840 --> 02:26:21.280]   So they want it to find,
[02:26:21.280 --> 02:26:22.740]   I mean, they actually say that, right?
[02:26:22.740 --> 02:26:24.660]   And so they said, we want to find out
[02:26:24.660 --> 02:26:27.440]   what are the really smart things you can do in Haiti.
[02:26:27.440 --> 02:26:31.420]   And so we, together with lots of people in Haiti,
[02:26:31.420 --> 02:26:34.320]   and all the business community, and the political community,
[02:26:34.320 --> 02:26:36.820]   and the religious community, and labor community,
[02:26:36.820 --> 02:26:39.500]   and everybody else, what are the smart things to do?
[02:26:39.500 --> 02:26:41.540]   And then we had economists evaluate it.
[02:26:41.540 --> 02:26:43.740]   And there are a lot of these things that everybody wanted
[02:26:43.740 --> 02:26:45.420]   that were not all that smart.
[02:26:45.420 --> 02:26:47.460]   There's actually a lot of smart things.
[02:26:47.460 --> 02:26:50.300]   And yes, the politicians didn't pick most of them.
[02:26:50.300 --> 02:26:53.740]   So our sense is, we try to give people,
[02:26:53.740 --> 02:26:56.180]   you're thinking about these 70 things,
[02:26:56.180 --> 02:26:59.040]   you should actually just think about these 20 things.
[02:26:59.040 --> 02:27:01.420]   And then we consider ourselves incredibly lucky
[02:27:01.420 --> 02:27:02.980]   if they actually do one of them.
[02:27:02.980 --> 02:27:04.060]   - So you wrote the book,
[02:27:04.060 --> 02:27:08.140]   "How to Spend $75 Billion to Make the World a Better Place."
[02:27:08.140 --> 02:27:11.460]   So can we just list some of the things?
[02:27:11.460 --> 02:27:16.180]   If you got $75 billion, how do you spend them?
[02:27:16.180 --> 02:27:18.600]   - All right, so there's some incredibly good
[02:27:18.600 --> 02:27:20.500]   and very, very well-documented things
[02:27:20.500 --> 02:27:21.820]   that you could spend money on.
[02:27:21.820 --> 02:27:24.980]   So we have two big infectious diseases
[02:27:24.980 --> 02:27:27.100]   that almost nobody think about,
[02:27:27.100 --> 02:27:30.020]   because we only think about COVID.
[02:27:30.020 --> 02:27:32.180]   But tuberculosis used to be
[02:27:32.180 --> 02:27:34.820]   the world's biggest infectious disease killer.
[02:27:34.820 --> 02:27:38.460]   It still kills about 1.5 million people every year.
[02:27:38.460 --> 02:27:41.580]   The reason why we don't really worry about it
[02:27:41.580 --> 02:27:44.600]   is because we fixed it 100 years ago.
[02:27:44.600 --> 02:27:46.220]   We know how to fix it.
[02:27:46.220 --> 02:27:49.280]   It's just basically getting medication to people.
[02:27:49.280 --> 02:27:50.920]   It's also about getting them to take it
[02:27:50.920 --> 02:27:53.080]   while when they're sort of been cured,
[02:27:53.080 --> 02:27:55.280]   because you need to take it for four to six months,
[02:27:55.280 --> 02:27:56.780]   and that's actually hard to do.
[02:27:56.780 --> 02:27:59.560]   So you also need to incentivize that in some kind of way.
[02:27:59.560 --> 02:28:01.820]   It turns out it's incredibly cheap
[02:28:01.820 --> 02:28:05.460]   to basically save almost all of the 1.5 million people.
[02:28:05.460 --> 02:28:08.680]   These are people that die in the prime of their lives.
[02:28:08.680 --> 02:28:09.680]   They're typically parents,
[02:28:09.680 --> 02:28:12.080]   so it also have a lot of knock-on effects.
[02:28:12.080 --> 02:28:14.920]   And basically we find for a couple billion dollars,
[02:28:14.920 --> 02:28:16.820]   you could save the vast number of these.
[02:28:16.820 --> 02:28:17.660]   Not all of them,
[02:28:17.660 --> 02:28:19.000]   but you could save the vast number of them.
[02:28:19.000 --> 02:28:22.220]   It would also improve outcomes in all kinds of other ways.
[02:28:22.220 --> 02:28:24.460]   Likewise with malaria, another,
[02:28:24.460 --> 02:28:27.540]   it has somewhat better PR.
[02:28:27.540 --> 02:28:30.380]   - It's funny to think of malaria as PR,
[02:28:30.380 --> 02:28:31.500]   and tuberculosis not.
[02:28:31.500 --> 02:28:33.300]   They need to improve their PR department.
[02:28:33.300 --> 02:28:34.340]   (laughing)
[02:28:34.340 --> 02:28:36.700]   Those mosquitoes are the good PR.
[02:28:36.700 --> 02:28:39.740]   - By far the biggest infectious disease
[02:28:39.740 --> 02:28:42.880]   that got good PR, if you will, was HIV.
[02:28:44.700 --> 02:28:46.460]   And I'm not trying to compare it and say,
[02:28:46.460 --> 02:28:49.080]   oh, it's worse or better to have HIV
[02:28:49.080 --> 02:28:51.280]   than tuberculosis or anything.
[02:28:51.280 --> 02:28:53.240]   But I'm simply saying we are underfunding
[02:28:53.240 --> 02:28:57.680]   because it doesn't really get the public attention.
[02:28:57.680 --> 02:28:58.520]   We just, you know, we don't really care.
[02:28:58.520 --> 02:29:00.800]   - But spending money on that has,
[02:29:00.800 --> 02:29:02.880]   in terms of benefit, a much bigger impact than other.
[02:29:02.880 --> 02:29:05.900]   - So every dollar you spend on TB
[02:29:05.900 --> 02:29:08.980]   will probably do about $43 worth of good.
[02:29:08.980 --> 02:29:10.680]   So it'll do an amazing amount of good,
[02:29:10.680 --> 02:29:12.280]   basically because it'll save lives,
[02:29:12.280 --> 02:29:14.680]   it'll make sure parents stay with their kids
[02:29:14.680 --> 02:29:17.200]   and be more productive in their communities,
[02:29:17.200 --> 02:29:19.520]   and it'll have a lot of knock-on effects.
[02:29:19.520 --> 02:29:21.960]   And it's incredibly cheap to do.
[02:29:21.960 --> 02:29:23.600]   Same thing with malaria.
[02:29:23.600 --> 02:29:26.240]   It's mostly mosquito nets that we need to get out.
[02:29:26.240 --> 02:29:29.040]   - And you're saying, just to contrast with climate change,
[02:29:29.040 --> 02:29:32.120]   the dollar you spend on, no, not climate change,
[02:29:32.120 --> 02:29:35.400]   but decreasing emissions does not have,
[02:29:35.400 --> 02:29:38.040]   does not come close to the $43 benefit?
[02:29:38.040 --> 02:29:40.440]   - No, nobody would ever argue that.
[02:29:40.440 --> 02:29:44.480]   So very, very enthusiastic climate advocates
[02:29:44.480 --> 02:29:47.040]   would probably say it'll do $2 or $3
[02:29:47.040 --> 02:29:48.280]   worth of good for every dollar.
[02:29:48.280 --> 02:29:50.200]   So, you know, it's still worthwhile to do.
[02:29:50.200 --> 02:29:51.460]   That's what they would say.
[02:29:51.460 --> 02:29:53.800]   I would argue, and I think a lot of the evidence
[02:29:53.800 --> 02:29:55.240]   seems to side that way,
[02:29:55.240 --> 02:29:56.920]   that a lot of the things that we're doing
[02:29:56.920 --> 02:29:59.760]   deliver actually less than a dollar back.
[02:29:59.760 --> 02:30:03.160]   But it's certainly not nearly the same kind of place.
[02:30:03.160 --> 02:30:05.040]   But there's many, many other things.
[02:30:05.040 --> 02:30:07.440]   And, you know, just if you'll allow me to.
[02:30:07.440 --> 02:30:08.880]   - Yes, please, I love this.
[02:30:08.880 --> 02:30:11.160]   - But yeah, there are lots of other things,
[02:30:11.160 --> 02:30:13.720]   for instance, e-procurement.
[02:30:13.720 --> 02:30:16.480]   So, you know, it's incredibly boring.
[02:30:16.480 --> 02:30:18.560]   So most developing countries,
[02:30:18.560 --> 02:30:20.000]   well, actually most governments,
[02:30:20.000 --> 02:30:21.880]   spend most of their money on procurement,
[02:30:21.880 --> 02:30:24.320]   is typically incredibly corrupt.
[02:30:24.320 --> 02:30:27.280]   So we did this project for Bangladesh where-
[02:30:27.280 --> 02:30:28.360]   - Can you explain procurement?
[02:30:28.360 --> 02:30:31.880]   - Yes, so that's governments buying stuff.
[02:30:31.880 --> 02:30:34.920]   So a large part of the government revenue
[02:30:34.920 --> 02:30:37.280]   is spent on buying anything from, you know,
[02:30:37.280 --> 02:30:39.320]   post-it notes to roads.
[02:30:39.320 --> 02:30:41.240]   And obviously, you know, roads are much,
[02:30:41.240 --> 02:30:42.440]   much more expensive.
[02:30:42.440 --> 02:30:44.600]   It's mostly infrastructure stuff.
[02:30:44.600 --> 02:30:46.080]   Hugely corrupt.
[02:30:46.080 --> 02:30:47.540]   For instance, in Bangladesh,
[02:30:47.540 --> 02:30:51.240]   it would already have been decided among the ruling elite
[02:30:51.240 --> 02:30:54.020]   in that local area, who's gonna get this.
[02:30:54.020 --> 02:30:56.200]   So they'll have this bidding competition
[02:30:56.200 --> 02:30:58.080]   where you have to hand in an envelope,
[02:30:58.080 --> 02:31:00.520]   a sealed envelope with your bid on it.
[02:31:00.520 --> 02:31:03.760]   But you put a goon outside the office.
[02:31:03.760 --> 02:31:06.120]   So you literally physically can't get in
[02:31:06.120 --> 02:31:08.440]   with your bid.
[02:31:08.440 --> 02:31:11.080]   Now, what we found, and this is, you know,
[02:31:11.080 --> 02:31:14.260]   I'm not claiming any sort of ownership to this.
[02:31:14.260 --> 02:31:16.440]   A lot of smart people have done this way before.
[02:31:16.440 --> 02:31:18.840]   We're just simply proving that it's a good idea.
[02:31:18.840 --> 02:31:22.500]   It turns out that if you put this on eBay, essentially,
[02:31:22.500 --> 02:31:24.800]   so if you do an e-procurement system
[02:31:24.800 --> 02:31:26.840]   where bidders can come in,
[02:31:26.840 --> 02:31:29.480]   suddenly it becomes harder to put up the goon.
[02:31:29.480 --> 02:31:32.080]   You can still do it, but it's harder to do it.
[02:31:32.080 --> 02:31:35.480]   It also means you get bids from all over Bangladesh.
[02:31:35.480 --> 02:31:38.760]   And in general, you'll get bids from all over.
[02:31:38.760 --> 02:31:41.000]   Actually, it turns out you get better quality,
[02:31:41.000 --> 02:31:44.240]   but most important is you get it much cheaper.
[02:31:44.240 --> 02:31:46.580]   So basically, you can simply save money.
[02:31:46.580 --> 02:31:49.360]   So we did a scaled experiment in Bangladesh
[02:31:49.360 --> 02:31:53.240]   where we had about 4% go to be e-procurement,
[02:31:53.240 --> 02:31:55.440]   and you could compare what it would have cost
[02:31:55.440 --> 02:31:57.120]   and then what it did cost.
[02:31:57.120 --> 02:32:01.160]   And the average reduction was, as I remember, it's 7%.
[02:32:01.160 --> 02:32:03.560]   And the finance minister loved it, you know,
[02:32:03.560 --> 02:32:06.160]   because that basically gives him a lot more money,
[02:32:06.160 --> 02:32:08.720]   or you can buy more stuff at the same cost.
[02:32:08.720 --> 02:32:10.600]   - No, it is just corruption.
[02:32:10.600 --> 02:32:13.560]   - So it's basically you get rid of some corruption.
[02:32:13.560 --> 02:32:16.000]   There'll still be corruption, but less corruption.
[02:32:16.000 --> 02:32:18.160]   Ukraine has actually been big on this.
[02:32:18.160 --> 02:32:19.160]   - Yeah, I've talked to them.
[02:32:19.160 --> 02:32:21.660]   I talked to the digital transformation minister.
[02:32:21.660 --> 02:32:22.760]   It's kind of incredible.
[02:32:22.760 --> 02:32:26.220]   I mean, this is before the war, but still working.
[02:32:26.220 --> 02:32:30.800]   It's like the entirety of the government is in an app.
[02:32:30.800 --> 02:32:33.800]   And that, one of the big effects
[02:32:33.800 --> 02:32:36.160]   is the reduction of corruption.
[02:32:36.160 --> 02:32:39.480]   And not like from, as politicians say,
[02:32:39.480 --> 02:32:40.640]   to say we've reduced,
[02:32:40.640 --> 02:32:42.400]   we've taken these actions to reduce corruption.
[02:32:42.400 --> 02:32:45.840]   No, literally, it's just much more difficult to be corrupt.
[02:32:45.840 --> 02:32:46.840]   - Yeah.
[02:32:46.840 --> 02:32:48.280]   - The incentives aren't quite there,
[02:32:48.280 --> 02:32:51.240]   and there's friction for corruption.
[02:32:51.240 --> 02:32:52.080]   - Yeah. - Oh, yeah, yeah.
[02:32:52.080 --> 02:32:55.560]   So basically, you can spend a little bit of money,
[02:32:55.560 --> 02:32:57.140]   and you can make a huge benefit.
[02:32:57.140 --> 02:32:58.520]   There's still about 70 countries
[02:32:58.520 --> 02:32:59.960]   that haven't gone e-procurement.
[02:32:59.960 --> 02:33:02.040]   So obviously, they should do that.
[02:33:02.040 --> 02:33:04.160]   Food for small kids, another thing.
[02:33:04.160 --> 02:33:09.120]   So basically, it's morally wrong that people are starving,
[02:33:09.120 --> 02:33:13.240]   but it also turns out that it's a really, really dumb thing
[02:33:13.240 --> 02:33:15.080]   not to get kids good food.
[02:33:15.080 --> 02:33:17.000]   Because if you get them good food,
[02:33:17.000 --> 02:33:18.560]   their brains develop more,
[02:33:18.560 --> 02:33:21.400]   so that when they get into school, they learn more.
[02:33:21.400 --> 02:33:23.760]   And so when they come out in adult lives,
[02:33:23.760 --> 02:33:25.200]   they're much more productive.
[02:33:25.200 --> 02:33:28.720]   So we can actually make every kid,
[02:33:28.720 --> 02:33:30.280]   especially in developing countries,
[02:33:30.280 --> 02:33:33.200]   much more productive by making sure they get good food.
[02:33:33.200 --> 02:33:35.400]   So getting good food is not cost-free.
[02:33:35.400 --> 02:33:37.960]   So it probably costs about $100,
[02:33:37.960 --> 02:33:41.800]   both in you need some directed advertisement,
[02:33:41.800 --> 02:33:42.640]   you need to make sure
[02:33:42.640 --> 02:33:44.900]   that you actually get some of the food out there,
[02:33:44.900 --> 02:33:46.020]   that you help the families,
[02:33:46.020 --> 02:33:48.180]   and you also make sure you don't just give it to everyone,
[02:33:48.180 --> 02:33:50.400]   because then it becomes a lot more expensive.
[02:33:50.400 --> 02:33:54.040]   If you do that right, it costs about $100 per kid, but-
[02:33:54.040 --> 02:33:56.040]   - Per kid, or what do you do?
[02:33:56.040 --> 02:33:59.040]   - For two years, so it's for their first two years of life.
[02:33:59.040 --> 02:34:03.720]   And if you do that, you then get a benefit
[02:34:03.720 --> 02:34:06.480]   in that they become smarter and go longer to school,
[02:34:06.480 --> 02:34:07.640]   and they actually learn more
[02:34:07.640 --> 02:34:11.260]   and become more productive of $4,500.
[02:34:11.260 --> 02:34:13.680]   Remember, this is far into the future.
[02:34:13.680 --> 02:34:16.960]   So this is discounted, the benefit is actually much higher.
[02:34:16.960 --> 02:34:18.040]   And this is one of the things
[02:34:18.040 --> 02:34:20.760]   that we also have a conversation about in climate change,
[02:34:20.760 --> 02:34:23.520]   because all, and when you talk about climate change,
[02:34:23.520 --> 02:34:25.520]   cost and benefits, all the costs are now,
[02:34:25.520 --> 02:34:27.160]   and all the benefits are in the future,
[02:34:27.160 --> 02:34:29.080]   but it's just like that in education.
[02:34:29.080 --> 02:34:30.760]   You know, all the costs are now,
[02:34:30.760 --> 02:34:33.200]   all the benefits are far into the future.
[02:34:33.200 --> 02:34:34.720]   And if you try to do that right,
[02:34:34.720 --> 02:34:38.120]   and that's a whole other conversation we could have,
[02:34:38.120 --> 02:34:40.640]   then it turns out that for every dollar spent,
[02:34:40.640 --> 02:34:42.720]   you do $45 worth of good.
[02:34:42.720 --> 02:34:46.420]   Again, remember, about a third of all kids
[02:34:46.420 --> 02:34:47.920]   that go to school right now
[02:34:47.920 --> 02:34:50.380]   just don't learn pretty much anything.
[02:34:50.380 --> 02:34:53.700]   And if we could make them more productive
[02:34:53.700 --> 02:34:55.740]   in the school system, we have another proposal
[02:34:55.740 --> 02:34:57.860]   on how to do that in the school system.
[02:34:57.860 --> 02:34:59.720]   But, you know, by just simply making sure
[02:34:59.720 --> 02:35:02.800]   that they're smarter when they get into school.
[02:35:02.800 --> 02:35:04.040]   We've been focusing so much
[02:35:04.040 --> 02:35:06.320]   on making the education system better,
[02:35:06.320 --> 02:35:07.580]   which is really hard,
[02:35:07.580 --> 02:35:10.840]   but it's actually really easy to make the kids smarter.
[02:35:10.840 --> 02:35:12.560]   - Then when you say the education system
[02:35:12.560 --> 02:35:13.800]   is not working well,
[02:35:13.800 --> 02:35:16.680]   we're talking about not the American education system,
[02:35:16.680 --> 02:35:17.680]   we're talking about globally.
[02:35:17.680 --> 02:35:19.080]   - Yes, we're talking about globally.
[02:35:19.080 --> 02:35:21.160]   You know, so about a third of the teachers
[02:35:21.160 --> 02:35:24.620]   in developing countries have a hard time passing the tests
[02:35:24.620 --> 02:35:27.220]   of the things they have to teach their students, right?
[02:35:27.220 --> 02:35:30.300]   And, you know, all these students have lots of other issues.
[02:35:30.300 --> 02:35:33.300]   You know, they need to do farm work,
[02:35:33.300 --> 02:35:37.180]   they're constantly considering,
[02:35:37.180 --> 02:35:39.480]   should I just go out and start working instead?
[02:35:39.480 --> 02:35:42.300]   You know, there's constant disruption.
[02:35:42.300 --> 02:35:43.900]   There's a lot of teachers that don't show up.
[02:35:43.900 --> 02:35:47.380]   In India, you know, you have this absurd situation
[02:35:47.380 --> 02:35:50.440]   where all the teachers are basically paid
[02:35:50.440 --> 02:35:53.420]   and hired for eternity, for the rest of their lives.
[02:35:53.420 --> 02:35:56.380]   And so not surprisingly, a lot of them decide not to show up.
[02:35:56.380 --> 02:36:00.220]   So now they've hired assistant teachers
[02:36:00.220 --> 02:36:01.580]   that basically have taken over.
[02:36:01.580 --> 02:36:02.660]   So they're paying, you know,
[02:36:02.660 --> 02:36:05.820]   for I think it's 7 million teachers that,
[02:36:05.820 --> 02:36:08.300]   I'm not saying they're all not working,
[02:36:08.300 --> 02:36:10.900]   but a lot of them are not working as much as they should.
[02:36:10.900 --> 02:36:13.700]   And we've now hired another 7 million teachers
[02:36:13.700 --> 02:36:16.660]   that will eventually, you know, stop working as well.
[02:36:16.660 --> 02:36:18.260]   They're working much better right now
[02:36:18.260 --> 02:36:21.600]   because they're not on permanent contracts,
[02:36:21.600 --> 02:36:23.520]   but eventually they'll get on permanent contracts
[02:36:23.520 --> 02:36:24.800]   and then you have the same problem again.
[02:36:24.800 --> 02:36:26.480]   There's lots of these issues.
[02:36:26.480 --> 02:36:28.320]   And, you know, it's just simply about saying,
[02:36:28.320 --> 02:36:29.920]   we can't fix all problems,
[02:36:29.920 --> 02:36:32.800]   but there are some problems that are incredibly easy to solve
[02:36:32.800 --> 02:36:35.200]   and there are some that are incredibly hard to solve.
[02:36:35.200 --> 02:36:38.640]   Why don't we start with solving the easy and effective ones?
[02:36:38.640 --> 02:36:40.960]   And this of course bears on that whole conversation
[02:36:40.960 --> 02:36:43.400]   on climate change, because in some ways, you know,
[02:36:43.400 --> 02:36:45.240]   that's also Andy's point of saying,
[02:36:45.240 --> 02:36:46.600]   look, if you want to save people
[02:36:47.180 --> 02:36:48.780]   from the impacts of hurricanes,
[02:36:48.780 --> 02:36:52.660]   let's fix this simple, easy things about vulnerability first
[02:36:52.660 --> 02:36:55.120]   whereas we have somehow latched onto this,
[02:36:55.120 --> 02:36:57.580]   let's fix the hardest thing to do,
[02:36:57.580 --> 02:37:00.500]   which is to get everyone to stop using fossil fuels,
[02:37:00.500 --> 02:37:02.500]   which is basically what's driven
[02:37:02.500 --> 02:37:05.060]   the last 200 years of development.
[02:37:05.060 --> 02:37:07.100]   That's gonna be, that's a tall order,
[02:37:07.100 --> 02:37:08.940]   no matter how you look at it.
[02:37:08.940 --> 02:37:10.580]   - There's some really cool elements
[02:37:10.580 --> 02:37:12.740]   that you guys just brought up.
[02:37:12.740 --> 02:37:14.300]   When you mentioned that word moral before,
[02:37:14.300 --> 02:37:17.320]   I wasn't, I latched onto it because it relates
[02:37:17.320 --> 02:37:21.640]   to these timescales that really are immeasurable.
[02:37:21.640 --> 02:37:23.320]   If you know it's gonna take decades
[02:37:23.320 --> 02:37:27.960]   to confirm the benefit of some investment now,
[02:37:27.960 --> 02:37:30.020]   that implies you're doing the investment
[02:37:30.020 --> 02:37:33.000]   with some moral imperative,
[02:37:33.000 --> 02:37:36.800]   not because you can do a spreadsheet
[02:37:36.800 --> 02:37:38.580]   and come up with a number.
[02:37:38.580 --> 02:37:42.560]   And that process, letting go of the need
[02:37:43.540 --> 02:37:46.760]   for kind of a mechanistic cost-benefit approach
[02:37:46.760 --> 02:37:49.280]   and thinking about kids' education in poor countries
[02:37:49.280 --> 02:37:51.880]   or several things we talk about,
[02:37:51.880 --> 02:37:52.920]   seems to be really important
[02:37:52.920 --> 02:37:55.040]   and it's very hard for all of us to do.
[02:37:55.040 --> 02:37:57.080]   Philanthropists suck at it.
[02:37:57.080 --> 02:37:59.120]   I worked at National Geographic Society for a year
[02:37:59.120 --> 02:38:00.320]   building some new programs
[02:38:00.320 --> 02:38:02.420]   when they got a big infusion of money.
[02:38:02.420 --> 02:38:04.800]   They have a whole department that's called M&E,
[02:38:04.800 --> 02:38:06.440]   it's measurement and evaluation,
[02:38:06.440 --> 02:38:10.220]   which is if you don't prove it, it goes away.
[02:38:10.220 --> 02:38:11.720]   I mentioned Spotify earlier,
[02:38:11.720 --> 02:38:13.740]   Spotify killing a climate podcast
[02:38:13.740 --> 02:38:18.740]   because that podcast didn't measure out for their impact,
[02:38:18.740 --> 02:38:20.260]   what they wanna do.
[02:38:20.260 --> 02:38:22.920]   And if we're always making the judgments
[02:38:22.920 --> 02:38:24.380]   based on strict cost-benefit,
[02:38:24.380 --> 02:38:28.020]   we're gonna miss larger realities.
[02:38:28.020 --> 02:38:30.820]   Another thing is, a really exciting example
[02:38:30.820 --> 02:38:32.300]   of what you're talking about
[02:38:32.300 --> 02:38:34.700]   in terms of in Ukraine with the trust
[02:38:34.700 --> 02:38:38.080]   and lack of less corruption and stuff was in India.
[02:38:39.420 --> 02:38:44.340]   For all of his issues, Modi recognized
[02:38:44.340 --> 02:38:48.060]   that middle-class people in India cook on LPG, propane,
[02:38:48.060 --> 02:38:51.260]   or on piped gas, natural gas if they're in cities.
[02:38:51.260 --> 02:38:55.460]   Much cleaner, much healthier in so many ways.
[02:38:55.460 --> 02:38:58.100]   And actually, compared to chopping down trees
[02:38:58.100 --> 02:39:00.820]   and cooking on wood, it's actually better for the climate,
[02:39:00.820 --> 02:39:02.740]   even though it's a fossil fuel.
[02:39:02.740 --> 02:39:06.060]   So he and others, there was an American scientist,
[02:39:06.060 --> 02:39:07.860]   Kirk Smith, who worked this all out.
[02:39:07.860 --> 02:39:12.220]   If you find a way, they were getting a subsidy.
[02:39:12.220 --> 02:39:13.740]   They had that energy subsidy.
[02:39:13.740 --> 02:39:15.900]   You were talking about many poor countries
[02:39:15.900 --> 02:39:18.700]   subsidize energy just to stay in office,
[02:39:18.700 --> 02:39:21.520]   to make something cheap that everyone wants.
[02:39:21.520 --> 02:39:22.900]   But they wanted to shift the subsidy
[02:39:22.900 --> 02:39:25.740]   away from the middle class to the poor people
[02:39:25.740 --> 02:39:29.460]   who are cooking on firewood and dying young from pneumonia.
[02:39:29.460 --> 02:39:35.020]   And the critical factor was India's digital currency.
[02:39:35.020 --> 02:39:37.660]   India went to a digital economy.
[02:39:37.660 --> 02:39:38.980]   Very poor families there now.
[02:39:38.980 --> 02:39:42.180]   If you have a phone, basically that's your bank.
[02:39:42.180 --> 02:39:44.700]   And you could make the case to the public
[02:39:44.700 --> 02:39:48.900]   that we're gonna be starting to shift your LPG,
[02:39:48.900 --> 02:39:51.660]   your propane subsidy to poor people.
[02:39:51.660 --> 02:39:53.020]   But we know they're poor.
[02:39:53.020 --> 02:39:55.700]   We know they're not just gonna be using it
[02:39:55.700 --> 02:39:58.100]   behind their restaurant, which was,
[02:39:58.100 --> 02:40:02.700]   when it was a general subsidy, people were hoarding the LPG.
[02:40:02.700 --> 02:40:04.480]   And the system has worked.
[02:40:04.480 --> 02:40:07.420]   They've shifted a lot of capacity
[02:40:07.420 --> 02:40:11.100]   to cook on a clean blue flame that turns off and on
[02:40:11.100 --> 02:40:12.460]   in homes that previously,
[02:40:12.460 --> 02:40:15.380]   where the woman would spend hours collecting firewood,
[02:40:15.380 --> 02:40:17.660]   smoky fire, cooking, clean the pots,
[02:40:17.660 --> 02:40:19.580]   and start all over again.
[02:40:19.580 --> 02:40:22.460]   But it's all built on trust, built on the digital economy,
[02:40:22.460 --> 02:40:24.180]   and the same thing in Nairobi.
[02:40:24.180 --> 02:40:28.140]   So that excites me every day, with all the doomism.
[02:40:28.140 --> 02:40:33.140]   I just hope people can literally take a breath,
[02:40:33.260 --> 02:40:37.040]   look for these examples that show the potential
[02:40:37.040 --> 02:40:39.520]   when you have a trustworthy system,
[02:40:39.520 --> 02:40:42.600]   when you have a clear path to making lives better.
[02:40:42.600 --> 02:40:47.240]   And then knowing that kid having electric light
[02:40:47.240 --> 02:40:49.280]   as opposed to a kerosene lamp.
[02:40:49.280 --> 02:40:52.760]   We don't know how much that's gonna improve his homework
[02:40:52.760 --> 02:40:54.320]   and lead to a better outcome.
[02:40:54.320 --> 02:40:56.920]   But we know from history that sometimes it does.
[02:40:56.920 --> 02:40:58.600]   Ban Ki-moon, former Secretary General,
[02:40:58.600 --> 02:41:01.840]   told the most powerful story I ever heard from a UN.
[02:41:01.840 --> 02:41:04.060]   Secretary General, it was like 2012
[02:41:04.060 --> 02:41:05.900]   when they were rolling out
[02:41:05.900 --> 02:41:08.080]   this Sustainable Energy for All initiative,
[02:41:08.080 --> 02:41:09.380]   which is not just climate,
[02:41:09.380 --> 02:41:10.940]   it was just getting people energy
[02:41:10.940 --> 02:41:14.180]   they need to survive and thrive.
[02:41:14.180 --> 02:41:16.600]   He was growing up in post-war Korea.
[02:41:16.600 --> 02:41:20.580]   Everyone was poor, everything was broken, destroyed.
[02:41:20.580 --> 02:41:24.540]   Sadly, like so many parts of Ukraine.
[02:41:24.540 --> 02:41:27.960]   And he would do his homework by kerosene lamp.
[02:41:27.960 --> 02:41:30.740]   He said when he was studying for his finals,
[02:41:30.740 --> 02:41:32.340]   his mom would give him a candle
[02:41:32.340 --> 02:41:35.340]   'cause it was a brighter flame,
[02:41:35.340 --> 02:41:37.740]   better grades maybe.
[02:41:37.740 --> 02:41:39.340]   And he became Secretary General.
[02:41:39.340 --> 02:41:42.180]   - That's a hell of a story.
[02:41:42.180 --> 02:41:45.860]   So which,
[02:41:45.860 --> 02:41:52.040]   for climate change, which policies work, which don't?
[02:41:52.040 --> 02:41:57.540]   Which are, when we look at this formula of $1 in,
[02:41:57.540 --> 02:42:01.100]   $45 out, for climate change,
[02:42:01.100 --> 02:42:05.220]   what dollar in, what policies for dollar in
[02:42:05.220 --> 02:42:08.260]   and dollar out are good and which are not?
[02:42:08.260 --> 02:42:13.060]   - So we actually did a whole project back in 2009
[02:42:13.060 --> 02:42:17.180]   when the whole world circus was coming to Copenhagen
[02:42:17.180 --> 02:42:19.620]   and we were gonna save the world there.
[02:42:19.620 --> 02:42:22.500]   We brought together about 50 climate economists
[02:42:22.500 --> 02:42:24.180]   and three Nobel laureates to look at
[02:42:24.180 --> 02:42:25.180]   where can you spend a dollar
[02:42:25.180 --> 02:42:26.980]   and do the most good for climate?
[02:42:26.980 --> 02:42:29.140]   And what they found was a lot of these things
[02:42:29.140 --> 02:42:30.820]   as we've been talking about before,
[02:42:30.820 --> 02:42:34.740]   that basically investing in the current sort of technology
[02:42:34.740 --> 02:42:38.140]   that we're trying very hard is at best
[02:42:38.140 --> 02:42:41.100]   a pretty dicey outcome.
[02:42:41.100 --> 02:42:44.220]   Much of it is probably less than a dollar back in the dollar.
[02:42:44.220 --> 02:42:48.900]   There's some investments on adaptation, for instance,
[02:42:48.900 --> 02:42:51.420]   that's pretty good, but it's sort of two, $3
[02:42:51.420 --> 02:42:52.380]   back in the dollar.
[02:42:52.380 --> 02:42:53.680]   - Oh, what is adaptation?
[02:42:53.680 --> 02:42:55.660]   - The obvious thing is that you build a dike
[02:42:55.660 --> 02:42:59.100]   for a sea level rise or that you make people,
[02:42:59.100 --> 02:43:01.140]   you get some apps that people know
[02:43:01.140 --> 02:43:04.100]   that there's a hurricane coming or that,
[02:43:04.100 --> 02:43:04.940]   so you can adapt--
[02:43:04.940 --> 02:43:05.940]   - Adapting infrastructure, right?
[02:43:05.940 --> 02:43:06.780]   - Yes.
[02:43:06.780 --> 02:43:08.980]   - The physical and the digital infrastructure.
[02:43:08.980 --> 02:43:10.580]   - The point is that people are really good
[02:43:10.580 --> 02:43:12.180]   at doing this already
[02:43:12.180 --> 02:43:13.940]   because they have a strong incentive to do it.
[02:43:13.940 --> 02:43:16.820]   So the extra thing that governments can do outside
[02:43:16.820 --> 02:43:19.620]   is somewhat good, but it's not amazing or anything.
[02:43:19.620 --> 02:43:24.620]   What we found by far the best investment in the long run
[02:43:24.820 --> 02:43:27.980]   was on investment in energy innovation.
[02:43:27.980 --> 02:43:30.980]   So, and I think this also sort of corresponds
[02:43:30.980 --> 02:43:33.780]   with what we would think in general.
[02:43:33.780 --> 02:43:36.300]   If we could innovate, so for instance, Bill Gates
[02:43:36.300 --> 02:43:38.700]   is arguing we should have fourth generation nuclear,
[02:43:38.700 --> 02:43:42.700]   so the next, more advanced than what we currently have
[02:43:42.700 --> 02:43:44.340]   in third generation nuclear,
[02:43:44.340 --> 02:43:47.380]   which would be industrial scale process.
[02:43:47.380 --> 02:43:51.900]   You'd just be building these modular nuclear power plants.
[02:43:51.900 --> 02:43:54.500]   They would be, instead of being this artwork
[02:43:54.500 --> 02:43:57.300]   that we design once for every different plant,
[02:43:57.300 --> 02:43:59.420]   which is one of the reasons why they're so expensive,
[02:43:59.420 --> 02:44:02.220]   they would just be mass produced and you'd have one,
[02:44:02.220 --> 02:44:06.820]   they all be recognized in one go, so it'd be much cheaper.
[02:44:06.820 --> 02:44:08.580]   They would also be passively safe.
[02:44:08.580 --> 02:44:12.620]   So if all the power goes, they'll shut down
[02:44:12.620 --> 02:44:14.540]   rather than go boom.
[02:44:14.540 --> 02:44:16.620]   So that's another very good thing.
[02:44:16.620 --> 02:44:19.700]   And then they'll also be very hard to transform
[02:44:19.700 --> 02:44:21.980]   into nuclear weapons.
[02:44:21.980 --> 02:44:23.860]   So you can actually imagine them being out
[02:44:23.860 --> 02:44:25.580]   in a lot of different places where we'd perhaps
[02:44:25.580 --> 02:44:28.660]   be a little worried about having plutonium lying around.
[02:44:28.660 --> 02:44:30.940]   Now, this is all still being worked out,
[02:44:30.940 --> 02:44:33.060]   but imagine if that actually comes out.
[02:44:33.060 --> 02:44:36.020]   And again, remember the other three generations,
[02:44:36.020 --> 02:44:38.260]   we were also told that it'll be incredibly safe
[02:44:38.260 --> 02:44:39.780]   and it'll be incredibly cheap,
[02:44:39.780 --> 02:44:40.980]   and it didn't turn out that way.
[02:44:40.980 --> 02:44:43.980]   So let's wait, but it could be.
[02:44:43.980 --> 02:44:47.860]   And so the argument is invest in these ideas,
[02:44:47.860 --> 02:44:49.740]   for instance, fourth generation nuclear,
[02:44:49.740 --> 02:44:52.100]   and if fourth generation nuclear becomes cheaper
[02:44:52.100 --> 02:44:54.620]   than fossil fuels, we're done.
[02:44:54.620 --> 02:44:56.980]   Everyone will just switch, not just rich,
[02:44:56.980 --> 02:44:59.500]   well-meaning Americans or Europeans,
[02:44:59.500 --> 02:45:02.380]   but also the Chinese, the Indians, everybody in Africa,
[02:45:02.380 --> 02:45:05.100]   the rest of the Indian subcontinent.
[02:45:05.100 --> 02:45:07.500]   That's how you fix these issues, right?
[02:45:07.500 --> 02:45:09.540]   So the idea here is to say,
[02:45:09.540 --> 02:45:13.380]   instead of thinking that we can sort of push people
[02:45:13.380 --> 02:45:16.540]   to do stuff they really don't want to do,
[02:45:16.540 --> 02:45:20.700]   which is basically saying, let's use more of the,
[02:45:20.700 --> 02:45:22.340]   the solar and wind that you would otherwise
[02:45:22.340 --> 02:45:25.420]   have invested in, force people to buy an electric car
[02:45:25.420 --> 02:45:27.460]   by giving huge subsidies, because otherwise
[02:45:27.460 --> 02:45:30.540]   they're clearly not all that interested in buying it
[02:45:30.540 --> 02:45:34.060]   and so on, then get the innovation such that
[02:45:34.060 --> 02:45:36.260]   they become cheaper than fossil fuels
[02:45:36.260 --> 02:45:38.020]   and everyone will switch.
[02:45:38.020 --> 02:45:39.780]   This is how we've solved problems in the past,
[02:45:39.780 --> 02:45:42.980]   if you think, and Los Angeles in the 1950s
[02:45:42.980 --> 02:45:46.420]   was hugely polluted place, mostly because of cars.
[02:45:46.420 --> 02:45:49.220]   The sort of standard climate approach today
[02:45:49.220 --> 02:45:51.140]   would be to tell everyone in Los Angeles,
[02:45:51.140 --> 02:45:53.700]   I'm sorry, could you just walk instead?
[02:45:53.700 --> 02:45:55.420]   And of course, that just doesn't work,
[02:45:55.420 --> 02:45:57.180]   that doesn't pay off, you never get,
[02:45:57.180 --> 02:45:59.660]   you know, politicians voted in office,
[02:45:59.660 --> 02:46:01.540]   or at least staying in office,
[02:46:01.540 --> 02:46:03.060]   if you make that kind of policy.
[02:46:03.060 --> 02:46:05.860]   What did solve the problem was the innovation
[02:46:05.860 --> 02:46:07.380]   of the catalytic converter.
[02:46:07.380 --> 02:46:09.300]   You basically get those little gizmo
[02:46:09.300 --> 02:46:10.780]   and it cost a couple hundred dollars,
[02:46:10.780 --> 02:46:13.700]   you put it on your tailpipe, and then you can drive around
[02:46:13.700 --> 02:46:15.900]   and basically almost not pollute.
[02:46:15.900 --> 02:46:19.220]   And that's how you fix the air pollution in Los Angeles.
[02:46:19.220 --> 02:46:22.580]   Basically, we've solved all problems in humanity,
[02:46:22.580 --> 02:46:25.820]   all big, difficult problems with innovation.
[02:46:25.820 --> 02:46:27.740]   We haven't solved it by telling everyone,
[02:46:27.740 --> 02:46:30.220]   I'm sorry, could you be a little less comfortable
[02:46:30.220 --> 02:46:33.140]   and a little more cold and a little poorer,
[02:46:33.140 --> 02:46:36.580]   and believing that that can go on for decades.
[02:46:36.580 --> 02:46:41.380]   And while it possibly works in some pockets of the US,
[02:46:41.380 --> 02:46:44.620]   and I think actually in large parts of Europe, at least,
[02:46:44.620 --> 02:46:48.660]   it used to, the war in Ukraine is definitely
[02:46:48.660 --> 02:46:50.380]   sort of changing that whole perspective.
[02:46:50.380 --> 02:46:52.140]   But yeah, there's a willingness to say,
[02:46:52.140 --> 02:46:53.820]   we're gonna suffer a little bit,
[02:46:53.820 --> 02:46:55.220]   then we'll fix this problem.
[02:46:55.220 --> 02:46:58.020]   But the point is, we're gonna be willing to suffer a little
[02:46:58.020 --> 02:47:02.140]   and so fix a tiny bit of the climate problem,
[02:47:02.140 --> 02:47:04.700]   instead of actually focusing on innovation.
[02:47:04.700 --> 02:47:07.940]   So what we found was, if you spend a dollar on innovation,
[02:47:07.940 --> 02:47:11.380]   you will probably avoid about $11 of climate damage
[02:47:11.380 --> 02:47:14.300]   in the long run, which is a great investment.
[02:47:14.300 --> 02:47:17.940]   And the terrible thing is, we have not been doing this.
[02:47:17.940 --> 02:47:20.520]   So because everybody's focused on saying,
[02:47:20.520 --> 02:47:23.420]   we need this solution within the next 12 years,
[02:47:23.420 --> 02:47:25.980]   it means you're not thinking about the innovation.
[02:47:25.980 --> 02:47:27.300]   We're actually spending less money,
[02:47:27.300 --> 02:47:30.700]   not more money on innovation globally.
[02:47:30.700 --> 02:47:33.660]   - So everyone is focusing on reducing carbon emission
[02:47:33.660 --> 02:47:36.460]   versus innovating on alternate energy.
[02:47:36.460 --> 02:47:38.180]   - You're basically focusing on putting
[02:47:38.180 --> 02:47:40.500]   the existing solar panels or wind turbines,
[02:47:40.500 --> 02:47:44.180]   which are either just about inefficient or inefficient,
[02:47:44.180 --> 02:47:46.340]   instead of making the next generation,
[02:47:46.340 --> 02:47:50.880]   or it's more likely the 10th generation after that,
[02:47:50.880 --> 02:47:54.060]   that comes with lots of battery backup power,
[02:47:54.060 --> 02:47:57.040]   or fourth generation nuclear,
[02:47:57.040 --> 02:47:59.300]   or Craig Venter has this great idea.
[02:47:59.300 --> 02:48:01.180]   Craig Venter, the guy who cracked the human genome
[02:48:01.180 --> 02:48:04.420]   back in 2000, he has this idea of growing algae
[02:48:04.420 --> 02:48:05.700]   out on the ocean surface.
[02:48:05.700 --> 02:48:07.900]   These algae, they'd be genetically modified
[02:48:07.900 --> 02:48:11.420]   and they would basically soak up sunlight and CO2
[02:48:11.420 --> 02:48:12.740]   and produce oil.
[02:48:12.740 --> 02:48:15.300]   Then we could basically just grow our own Saudi Arabia
[02:48:15.300 --> 02:48:17.620]   out on the ocean surface and we'd harvest it,
[02:48:17.620 --> 02:48:19.940]   we'd keep our entire fossil fuel economy,
[02:48:19.940 --> 02:48:21.540]   but it'd now be net zero,
[02:48:21.540 --> 02:48:24.100]   because we just soaked up the CO2 out there.
[02:48:24.100 --> 02:48:28.380]   - $1 invested in the portfolio of different ideas.
[02:48:28.380 --> 02:48:29.900]   - Gives $11 back.
[02:48:29.900 --> 02:48:31.980]   - I first wrote about that in the New York Times.
[02:48:31.980 --> 02:48:33.980]   It was one of my actual page one stories.
[02:48:33.980 --> 02:48:40.180]   In 2006, it was declining R&D in energy
[02:48:40.180 --> 02:48:41.980]   at a time of global warming.
[02:48:41.980 --> 02:48:46.100]   And the baseline is so low for this
[02:48:46.100 --> 02:48:47.940]   that it's a super bargain.
[02:48:47.940 --> 02:48:52.820]   We were, during the energy crisis,
[02:48:52.820 --> 02:48:55.420]   the first energy crisis in the '70s,
[02:48:55.420 --> 02:48:56.620]   before the current one,
[02:48:56.620 --> 02:49:00.780]   our annual spending in the United States
[02:49:00.780 --> 02:49:03.380]   and constant dollars on R&D,
[02:49:03.380 --> 02:49:05.740]   research and development for energy,
[02:49:05.740 --> 02:49:07.020]   was about $5 billion.
[02:49:07.020 --> 02:49:11.100]   And then it's just dribbled away since then.
[02:49:11.100 --> 02:49:13.580]   And recently now, there's a big burst of new money
[02:49:13.580 --> 02:49:16.260]   coming through these new bills that got passed.
[02:49:16.260 --> 02:49:17.580]   But what I was told over and over again
[02:49:17.580 --> 02:49:21.660]   by people in that arena is you can't just have
[02:49:21.660 --> 02:49:24.300]   these little bubbles of investment.
[02:49:24.300 --> 02:49:27.340]   You don't get young people away from thinking
[02:49:27.340 --> 02:49:28.500]   about Wall Street for jobs
[02:49:28.500 --> 02:49:30.820]   towards thinking about energy innovation
[02:49:30.820 --> 02:49:33.220]   if there isn't a future there.
[02:49:33.220 --> 02:49:35.660]   And a lot of the, in the United States and Europe,
[02:49:35.660 --> 02:49:37.420]   the presumption was the wage of that future
[02:49:37.420 --> 02:49:40.040]   was taxing carbon.
[02:49:41.040 --> 02:49:45.040]   You make that so punitive that you're basically
[02:49:45.040 --> 02:49:48.080]   evening the landscape for cleaner stuff
[02:49:48.080 --> 02:49:49.400]   that's more expensive.
[02:49:49.400 --> 02:49:51.760]   That has failed completely.
[02:49:51.760 --> 02:49:54.480]   There are little examples in Europe where it's working.
[02:49:54.480 --> 02:49:57.080]   And what's happened now is, well, in the United States,
[02:49:57.080 --> 02:50:01.280]   this big chunk of money is designed to take us
[02:50:01.280 --> 02:50:04.680]   over a finish line that was started with
[02:50:04.680 --> 02:50:07.760]   not just innovation, but with the production efficiency too.
[02:50:07.760 --> 02:50:09.440]   This is one thing I got wrong, I think,
[02:50:09.440 --> 02:50:10.440]   a little bit in my reporting.
[02:50:10.440 --> 02:50:12.920]   I was so fixated on the innovation part,
[02:50:12.920 --> 02:50:15.280]   just because I love science too,
[02:50:15.280 --> 02:50:18.440]   I saw this untapped possibility,
[02:50:18.440 --> 02:50:21.040]   that others were saying, no, no, production efficiency,
[02:50:21.040 --> 02:50:23.100]   the more people are producing batteries,
[02:50:23.100 --> 02:50:24.140]   the cheaper they'll get.
[02:50:24.140 --> 02:50:28.960]   This is Elon Musk's path and many others.
[02:50:28.960 --> 02:50:29.880]   And it really is both.
[02:50:29.880 --> 02:50:31.620]   So when you were talking about purchasing power
[02:50:31.620 --> 02:50:36.400]   for governments, for example, that can stimulate production,
[02:50:36.400 --> 02:50:39.400]   capacity for batteries, or whatever the good thing is,
[02:50:39.400 --> 02:50:41.400]   and take you down faster.
[02:50:41.400 --> 02:50:43.680]   And it's all about getting that margin
[02:50:43.680 --> 02:50:46.000]   of the new thing out competing the old.
[02:50:46.000 --> 02:50:48.520]   And it's not just innovation.
[02:50:48.520 --> 02:50:50.260]   It has so many parts of the pipeline
[02:50:50.260 --> 02:50:51.880]   that need to be nurtured.
[02:50:51.880 --> 02:50:55.880]   So, and the other thing is relative cost.
[02:50:55.880 --> 02:50:58.780]   The United States, when I was writing about this in 2006,
[02:50:58.780 --> 02:51:02.120]   our budget for DARPA,
[02:51:02.120 --> 02:51:04.080]   the Advanced Research Project Agency
[02:51:04.080 --> 02:51:05.920]   for the Defense Department,
[02:51:06.800 --> 02:51:10.080]   just for science was 80 billion a year.
[02:51:10.080 --> 02:51:13.440]   For health, for medical frontier research on cancer
[02:51:13.440 --> 02:51:14.800]   and stuff, 40 billion.
[02:51:14.800 --> 02:51:16.080]   Energy was two or three.
[02:51:16.080 --> 02:51:19.600]   So we weren't taking this remotely seriously.
[02:51:19.600 --> 02:51:21.940]   So now that if we get that up,
[02:51:21.940 --> 02:51:23.780]   to me there's like this level,
[02:51:23.780 --> 02:51:25.900]   you know we're taking something seriously
[02:51:25.900 --> 02:51:28.560]   when it's like in the tens of billions for R&D.
[02:51:28.560 --> 02:51:30.640]   It's not that R&D will solve the problem,
[02:51:30.640 --> 02:51:33.480]   but it's a proxy for what we really care about.
[02:51:33.480 --> 02:51:35.680]   We care a shitload about defense.
[02:51:35.680 --> 02:51:37.360]   What's the defense budget in the United States now?
[02:51:37.360 --> 02:51:38.800]   Like 800 billion?
[02:51:38.800 --> 02:51:40.080]   It's some insane number.
[02:51:40.080 --> 02:51:41.640]   - Who's counting when you're having fun?
[02:51:41.640 --> 02:51:42.480]   - Yeah, yeah, yeah.
[02:51:42.480 --> 02:51:45.880]   And so innovation is not just like for the better,
[02:51:45.880 --> 02:51:49.540]   you know, camera, the better solar panel,
[02:51:49.540 --> 02:51:50.920]   the better battery.
[02:51:50.920 --> 02:51:53.040]   Social innovation actually matters hugely.
[02:51:53.040 --> 02:51:55.560]   Like the guy in Nairobi I mentioned
[02:51:55.560 --> 02:51:58.560]   with a company doing micropayment gas
[02:51:58.560 --> 02:52:00.440]   to get people off charcoal.
[02:52:00.440 --> 02:52:03.560]   We need that as much as this.
[02:52:03.560 --> 02:52:06.240]   And I actually, I interviewed Bill Gates.
[02:52:06.240 --> 02:52:09.640]   We had spent an hour with him in Seattle in 2016
[02:52:09.640 --> 02:52:14.080]   when he was rolling out his breakthrough energy thing.
[02:52:14.080 --> 02:52:15.960]   I got to spend, it was 45 minutes,
[02:52:15.960 --> 02:52:17.760]   me and Bill Gates, which was pretty fun.
[02:52:17.760 --> 02:52:19.000]   But I brought this up.
[02:52:19.000 --> 02:52:20.760]   I said, you know, 'cause he's all about
[02:52:20.760 --> 02:52:23.520]   the new nuclear thing that will solve the world's problems.
[02:52:23.520 --> 02:52:25.120]   And I, yes, yes, yes, but we also--
[02:52:25.120 --> 02:52:26.320]   - He brought up nuclear, sorry to interrupt.
[02:52:26.320 --> 02:52:27.560]   - Oh, he did, oh sure, yeah.
[02:52:27.560 --> 02:52:29.400]   - So he's interested in one of the--
[02:52:29.400 --> 02:52:31.240]   - Oh, he's investing heavily in nuclear,
[02:52:31.240 --> 02:52:32.560]   but he invests in everything.
[02:52:32.560 --> 02:52:34.320]   You know, he's got a big portfolio.
[02:52:34.320 --> 02:52:37.840]   But I brought up a guy I met in India
[02:52:37.840 --> 02:52:41.400]   who runs a little outfit called Selco
[02:52:41.400 --> 02:52:44.640]   that they do really interesting, cool village to village.
[02:52:44.640 --> 02:52:47.560]   They're like an energy analyst
[02:52:47.560 --> 02:52:48.840]   who'll come to your house here in the States
[02:52:48.840 --> 02:52:50.840]   and tell you how to weatherize your house,
[02:52:50.840 --> 02:52:52.880]   but they do it at the village scale.
[02:52:52.880 --> 02:52:57.000]   And in a village that has, where they're milling wheat,
[02:52:57.000 --> 02:53:00.080]   he'll put in a solar-powered wheat mill.
[02:53:00.080 --> 02:53:02.840]   And, you know, that's not gonna solve the world's problems,
[02:53:02.840 --> 02:53:05.720]   but it gives them a way to control their energy.
[02:53:05.720 --> 02:53:08.040]   They don't have to buy something to grind their wheat.
[02:53:08.040 --> 02:53:10.640]   And that needs just as much attention
[02:53:10.640 --> 02:53:14.320]   as the things I really like too, the cool technologies.
[02:53:14.320 --> 02:53:16.560]   And I thought I cornered Bill Gates.
[02:53:16.560 --> 02:53:20.760]   I was like, 'cause he really does focus on these big wins,
[02:53:20.760 --> 02:53:22.800]   the big, you know, like nuclear
[02:53:22.800 --> 02:53:25.680]   that will make net zero completely doable.
[02:53:25.680 --> 02:53:28.320]   And I said, well, you know, what about nuclear,
[02:53:28.320 --> 02:53:30.760]   like New York City, where I was still living at the time,
[02:53:30.760 --> 02:53:34.200]   or near, and I said, it's got a million buildings.
[02:53:34.200 --> 02:53:37.000]   New York City has one million buildings.
[02:53:37.000 --> 02:53:40.240]   And in 2013, the Bloomberg government analyzed,
[02:53:40.240 --> 02:53:43.280]   they said, looking ahead to 2050,
[02:53:43.280 --> 02:53:45.640]   75% of the buildings in New York City
[02:53:45.640 --> 02:53:48.720]   that will exist in 2050 already exist.
[02:53:48.720 --> 02:53:51.460]   Think about these brave new futures, right?
[02:53:51.460 --> 02:53:53.480]   Like we're just gonna like come in,
[02:53:53.480 --> 02:53:56.380]   have these shiny, cool passive house cities.
[02:53:56.380 --> 02:53:58.200]   And so I put this to Bill and I said,
[02:53:58.200 --> 02:54:00.520]   so how do you do that?
[02:54:00.520 --> 02:54:03.600]   How do you retrofit all those boilers,
[02:54:03.600 --> 02:54:07.040]   many of which were coal-fired like 20 years ago,
[02:54:07.040 --> 02:54:08.600]   to get a zero-energy New York City?
[02:54:08.600 --> 02:54:11.240]   And I kind of thought I had him.
[02:54:11.240 --> 02:54:13.880]   And then he immediately, he kind of sat back and went,
[02:54:13.880 --> 02:54:17.100]   well, but if you have unlimited clean power
[02:54:17.100 --> 02:54:20.080]   coming into that city, it doesn't really matter.
[02:54:20.080 --> 02:54:21.400]   - It's a pretty good Bill Gates impression.
[02:54:21.400 --> 02:54:22.920]   - It was a good answer.
[02:54:22.920 --> 02:54:24.320]   I mean, it was a good answer.
[02:54:24.320 --> 02:54:25.920]   He said, oh yeah, it's a leaky bucket,
[02:54:25.920 --> 02:54:29.920]   but pour in zero-carbon energy, then it doesn't matter.
[02:54:29.920 --> 02:54:32.240]   But I still think we have to figure out the other part too.
[02:54:32.240 --> 02:54:35.320]   The that end, how do you innovate at the household level,
[02:54:35.320 --> 02:54:36.580]   at the village level?
[02:54:36.580 --> 02:54:40.260]   It's much more of a distributed problem, we used to think.
[02:54:40.260 --> 02:54:42.680]   The one big change I've had in my own thinking too
[02:54:42.680 --> 02:54:47.680]   is from top down to distributed.
[02:54:47.680 --> 02:54:50.500]   Everything about the climate problem
[02:54:50.500 --> 02:54:53.540]   through the first three decades of my reporting
[02:54:53.540 --> 02:54:57.380]   was that the IPCC will come out a new report,
[02:54:57.380 --> 02:55:02.240]   the framework convention, the treaty will get us on board,
[02:55:02.240 --> 02:55:03.520]   we'll all behave better.
[02:55:03.520 --> 02:55:07.960]   It has this top down parent to child architecture.
[02:55:07.960 --> 02:55:13.000]   And everything I've learned has gone the other way.
[02:55:13.000 --> 02:55:17.880]   It's distributed capacity for improved lives.
[02:55:17.880 --> 02:55:19.720]   Kids getting through school,
[02:55:19.720 --> 02:55:23.080]   women not having to spend three hours collecting firewood.
[02:55:23.080 --> 02:55:24.940]   And if it means propane for that household
[02:55:24.940 --> 02:55:26.460]   in that context, that's a good thing.
[02:55:26.460 --> 02:55:27.880]   So stop with all your yammering
[02:55:27.880 --> 02:55:30.140]   about any oil, fossil fuel subsidies.
[02:55:30.140 --> 02:55:33.380]   And what's an America look like
[02:55:33.380 --> 02:55:37.980]   that has some climate safe energy future?
[02:55:37.980 --> 02:55:39.780]   Find your part in that.
[02:55:39.780 --> 02:55:41.860]   Don't get disempowered by the scale of it.
[02:55:41.860 --> 02:55:43.340]   There's like a thousand things to do
[02:55:43.340 --> 02:55:45.420]   when you start to cut it into pieces.
[02:55:45.420 --> 02:55:48.440]   So it's very different, it's not a top down thing.
[02:55:48.440 --> 02:55:49.940]   No one's gonna magically come in and--
[02:55:49.940 --> 02:55:52.080]   - And that's where I think,
[02:55:52.080 --> 02:55:55.880]   so I agree that everyone should try to play their part
[02:55:55.880 --> 02:55:59.480]   and do whatever they can.
[02:55:59.480 --> 02:56:03.040]   But I also think just the sheer incentives,
[02:56:03.040 --> 02:56:08.040]   what we saw happening with shale gas is a great example.
[02:56:08.040 --> 02:56:10.040]   When shale gas becomes so cheap
[02:56:10.040 --> 02:56:12.480]   that you just stop using coal,
[02:56:12.480 --> 02:56:14.760]   then you don't really have to convince
[02:56:14.760 --> 02:56:17.600]   lots and lots of people, coal is really bad.
[02:56:17.600 --> 02:56:18.640]   - And it wasn't labeled a climate.
[02:56:18.640 --> 02:56:20.640]   - No, it wasn't a climate thing, it was an energy thing.
[02:56:20.640 --> 02:56:21.480]   - It was totally.
[02:56:21.480 --> 02:56:25.760]   And the point is just the power of an innovation
[02:56:25.760 --> 02:56:30.400]   is that you almost don't see it anymore, it just happens.
[02:56:30.400 --> 02:56:32.720]   And I think that's really the only way
[02:56:32.720 --> 02:56:35.000]   we're gonna fix these big problems.
[02:56:35.000 --> 02:56:38.160]   If you think about the nutrition problem
[02:56:38.160 --> 02:56:40.160]   back in the 60s, 70s,
[02:56:40.160 --> 02:56:42.440]   we worried a lot about India and other places.
[02:56:42.440 --> 02:56:44.640]   A solution is not worrying,
[02:56:44.640 --> 02:56:47.200]   or the solution was not us eating a little bit less
[02:56:47.200 --> 02:56:49.360]   and sending it down to India, wherever.
[02:56:49.360 --> 02:56:51.240]   The solution was the green revolution, right?
[02:56:51.240 --> 02:56:53.880]   It was the fact that some scientists made ways
[02:56:53.880 --> 02:56:56.440]   to make every seed produce three times as much,
[02:56:56.440 --> 02:56:59.040]   so you could grow three times as much food on an acre.
[02:56:59.040 --> 02:57:02.120]   And that's what basically made it possible for India
[02:57:02.120 --> 02:57:03.880]   to go from a basket case
[02:57:03.880 --> 02:57:07.040]   to the world's leading rice exporter.
[02:57:07.040 --> 02:57:10.320]   And that's how you do these things,
[02:57:10.320 --> 02:57:13.320]   you solve these big problems through innovation.
[02:57:13.320 --> 02:57:15.160]   And again, I'm not saying that,
[02:57:15.160 --> 02:57:17.320]   we're actually arguing our carbon tax
[02:57:17.320 --> 02:57:18.960]   is a smart thing to do.
[02:57:18.960 --> 02:57:21.520]   That's what any economist would tell you to do.
[02:57:21.520 --> 02:57:24.280]   But it also turns out that it's partly,
[02:57:24.280 --> 02:57:26.240]   it's not gonna solve most of the problem,
[02:57:26.240 --> 02:57:29.600]   and it's incredibly politically hard to do.
[02:57:29.600 --> 02:57:33.080]   So it may also just be the wrong sort of tree to bark up.
[02:57:33.080 --> 02:57:36.200]   If you can do it, please do.
[02:57:36.200 --> 02:57:38.920]   But this is not the main thing that's gonna solve climate.
[02:57:38.920 --> 02:57:41.520]   The main thing is that we get these innovations
[02:57:41.520 --> 02:57:44.080]   that basically make green energy so cheap,
[02:57:44.080 --> 02:57:46.200]   everyone will just want.
[02:57:46.200 --> 02:57:48.640]   - We mentioned nuclear quite a few times.
[02:57:48.640 --> 02:57:50.940]   You know, there was for a long time,
[02:57:50.940 --> 02:57:52.400]   it seems to have shifted recently,
[02:57:52.400 --> 02:57:54.760]   maybe you can clarify and educate me on this,
[02:57:54.760 --> 02:57:58.080]   but for the longest time people thought that nuclear
[02:57:58.080 --> 02:58:02.680]   is almost unclean energy,
[02:58:02.680 --> 02:58:05.560]   or dangerous energy, or all that kind of stuff.
[02:58:05.560 --> 02:58:07.280]   When did that shift?
[02:58:07.280 --> 02:58:09.520]   What was the source of that alarmism?
[02:58:11.240 --> 02:58:15.080]   Maybe is that a case study of how alarmism
[02:58:15.080 --> 02:58:20.080]   can turn into a productive, constructive policy?
[02:58:20.080 --> 02:58:22.960]   - (laughs) Productive from whose standpoint?
[02:58:22.960 --> 02:58:25.440]   - Is it not?
[02:58:25.440 --> 02:58:27.000]   Is it not like nuclear--
[02:58:27.000 --> 02:58:28.560]   - No, I was trying to, do you mean productive
[02:58:28.560 --> 02:58:30.680]   in terms of yay, we banned it, or productive for those--
[02:58:30.680 --> 02:58:32.200]   - Oh, I see, I see what you mean, yes.
[02:58:32.200 --> 02:58:34.680]   I meant productive for human civilization.
[02:58:34.680 --> 02:58:36.840]   - No, the alarmism over nuclear power
[02:58:36.960 --> 02:58:41.960]   dominated any alarmism over global warming, absolutely.
[02:58:41.960 --> 02:58:43.320]   - Really?
[02:58:43.320 --> 02:58:46.160]   - Oh yeah, just in the United States,
[02:58:46.160 --> 02:58:48.560]   Three Mile Island, then you had Chernobyl there,
[02:58:48.560 --> 02:58:52.360]   and the traditional environmental movement
[02:58:52.360 --> 02:58:54.560]   still won't go there.
[02:58:54.560 --> 02:58:59.080]   They still, the big groups, NRDC, EDF,
[02:58:59.080 --> 02:59:02.080]   that whole alphabet soup of the big greens,
[02:59:02.080 --> 02:59:06.080]   are reluctant to put forward the nuclear option
[02:59:06.080 --> 02:59:08.400]   because they know a lot of their aging donors
[02:59:08.400 --> 02:59:11.840]   basically grew up in the thinking about nuclear
[02:59:11.840 --> 02:59:14.200]   as the problem, not the solution.
[02:59:14.200 --> 02:59:17.220]   I lived for the last 30 years, I moved to Maine recently,
[02:59:17.220 --> 02:59:19.520]   but I lived in the Hudson Valley,
[02:59:19.520 --> 02:59:21.880]   10 miles from the Indian Point Nuclear Power Plant,
[02:59:21.880 --> 02:59:26.760]   which was built in the '60s, '70s, and had some problems.
[02:59:26.760 --> 02:59:30.560]   None of them were to the point of a meltdown
[02:59:30.560 --> 02:59:31.840]   or the threat of it,
[02:59:31.840 --> 02:59:33.960]   even the theoretical possibility of one.
[02:59:35.400 --> 02:59:38.320]   I've been in, I was in it twice as a reporter,
[02:59:38.320 --> 02:59:39.720]   looking down in the cooling pool.
[02:59:39.720 --> 02:59:41.880]   I can send you a fun video of bubbles
[02:59:41.880 --> 02:59:43.400]   in the cooling pool with the rods.
[02:59:43.400 --> 02:59:47.560]   And progressively they demonstrated how to handle waste.
[02:59:47.560 --> 02:59:49.520]   In the United States now, the waste is,
[02:59:49.520 --> 02:59:50.440]   because we haven't figured out
[02:59:50.440 --> 02:59:52.140]   how to move it across state lines,
[02:59:52.140 --> 02:59:57.280]   it's glassified, it's put into kind of containers
[02:59:57.280 --> 02:59:59.480]   that sit there at the plant.
[02:59:59.480 --> 03:00:02.540]   We just simply don't have a long-term solution.
[03:00:04.640 --> 03:00:09.640]   The Nevada politicians were successful in saying,
[03:00:09.640 --> 03:00:12.040]   not here, not Yucca Mountain.
[03:00:12.040 --> 03:00:16.800]   But my wife, who I've been married to,
[03:00:16.800 --> 03:00:19.400]   well, I met 30 years ago, and she lives with me,
[03:00:19.400 --> 03:00:21.520]   she's an environmental educator.
[03:00:21.520 --> 03:00:25.080]   She was very happy when Cuomo shut it down,
[03:00:25.080 --> 03:00:27.680]   said we're gonna shut it down three or four years ago,
[03:00:27.680 --> 03:00:30.520]   which just happened a year, it actually is shut down now.
[03:00:30.520 --> 03:00:33.080]   It's being mothballed, and I was like, that sucks.
[03:00:33.080 --> 03:00:34.600]   We need-- - But she's happy.
[03:00:34.600 --> 03:00:36.360]   - Yeah, and we still love each other.
[03:00:36.360 --> 03:00:40.240]   - And she's an environmentalist, so that just speaks to,
[03:00:40.240 --> 03:00:43.800]   a lot of environmentalists still see nuclear as bad.
[03:00:43.800 --> 03:00:45.200]   - Oh, totally, oh yeah.
[03:00:45.200 --> 03:00:46.400]   You know, and you bring in
[03:00:46.400 --> 03:00:50.420]   the weapons proliferation issues.
[03:00:50.420 --> 03:00:53.240]   But it's a safety thing, it's a generational thing.
[03:00:53.240 --> 03:00:56.260]   I think young people are different, I hope.
[03:00:56.260 --> 03:00:59.680]   These small modular reactor designs,
[03:00:59.680 --> 03:01:03.120]   several of which, there's a couple of PhDs
[03:01:03.120 --> 03:01:07.360]   from MIT who did transatomic power.
[03:01:07.360 --> 03:01:09.640]   They're both in their early 30s.
[03:01:09.640 --> 03:01:11.540]   We need so much more of them.
[03:01:11.540 --> 03:01:14.480]   And just briefly, the one thing I say about nuclear is,
[03:01:14.480 --> 03:01:17.240]   with so many of these things, like subsidies,
[03:01:17.240 --> 03:01:20.400]   don't talk to me about yes/no nuclear.
[03:01:20.400 --> 03:01:21.880]   Talk to me about what do you wanna do
[03:01:21.880 --> 03:01:24.320]   with existing nuclear power plants,
[03:01:24.320 --> 03:01:28.000]   and what do you wanna do about the possibility of new ones?
[03:01:28.000 --> 03:01:29.680]   Let's parse this out in chunks
[03:01:29.680 --> 03:01:32.400]   that we can have constructive conversations about.
[03:01:32.400 --> 03:01:35.160]   The idea of no nuclear drives me crazy,
[03:01:35.160 --> 03:01:38.400]   just like no fossil fuel subsidies is silly
[03:01:38.400 --> 03:01:40.440]   in the world we inhabit that has these pockets
[03:01:40.440 --> 03:01:41.760]   of no energy.
[03:01:41.760 --> 03:01:46.760]   So that's just my sustain what mantras.
[03:01:46.760 --> 03:01:50.600]   Start with some, divide and conquer.
[03:01:50.600 --> 03:01:53.200]   To conquer the dispute over by saying,
[03:01:53.200 --> 03:01:54.860]   let's at least get real.
[03:01:54.860 --> 03:01:57.760]   This power plant has been in the Hudson Valley for 30 years.
[03:01:57.760 --> 03:02:00.160]   It was the baseload, it was baseload.
[03:02:00.160 --> 03:02:01.520]   Baseload is a real thing.
[03:02:02.360 --> 03:02:05.040]   And guess what has filled the gap
[03:02:05.040 --> 03:02:07.240]   since that power plant has turned off?
[03:02:07.240 --> 03:02:09.200]   Natural gas, natural gas.
[03:02:09.200 --> 03:02:13.460]   But, and you don't hear that from the environmental community
[03:02:13.460 --> 03:02:17.120]   that was so eager to turn off the Indian Point.
[03:02:17.120 --> 03:02:19.200]   - I think both the point of saying,
[03:02:19.200 --> 03:02:21.080]   the people are saying, it's the end of the world,
[03:02:21.080 --> 03:02:23.560]   but no, I don't want a nuclear power plant.
[03:02:23.560 --> 03:02:24.920]   It just doesn't make sense.
[03:02:24.920 --> 03:02:28.640]   And Andy's absolutely right to talk about,
[03:02:28.640 --> 03:02:30.760]   so existing nuclear power plants,
[03:02:30.760 --> 03:02:32.640]   we already paid for them.
[03:02:32.640 --> 03:02:34.120]   We already have them.
[03:02:34.120 --> 03:02:37.760]   We already committed to decommissioning them eventually
[03:02:37.760 --> 03:02:39.080]   while they're running.
[03:02:39.080 --> 03:02:41.120]   They're pretty much the cheapest power
[03:02:41.120 --> 03:02:42.980]   you can possibly have on the planet
[03:02:42.980 --> 03:02:46.480]   because it costs almost nothing to run them day to day.
[03:02:46.480 --> 03:02:51.480]   So, it's basically cheap or almost free CO2 baseload power.
[03:02:51.480 --> 03:02:54.960]   There's just nothing there that doesn't,
[03:02:54.960 --> 03:02:56.960]   you should embrace.
[03:02:56.960 --> 03:03:00.360]   Now, new nuclear power plants turn out
[03:03:00.360 --> 03:03:02.620]   to be very expensive currently.
[03:03:02.620 --> 03:03:04.800]   So, the one they built in Finland,
[03:03:04.800 --> 03:03:08.880]   some in the UK and France and several other places
[03:03:08.880 --> 03:03:10.940]   turn out to be incredibly expensive.
[03:03:10.940 --> 03:03:12.440]   So, they're much more expensive
[03:03:12.440 --> 03:03:16.600]   than the costliest renewables you can imagine.
[03:03:16.600 --> 03:03:19.680]   So, they're actually not a solution right now.
[03:03:19.680 --> 03:03:21.800]   And that's why we need the innovation.
[03:03:21.800 --> 03:03:23.560]   That's why we need the potentially
[03:03:23.560 --> 03:03:25.140]   fourth generation nuclear power.
[03:03:25.140 --> 03:03:27.440]   It's just simply, it's a bad deal.
[03:03:27.440 --> 03:03:30.320]   And that's why nuclear's never gonna win
[03:03:30.320 --> 03:03:31.600]   on its third generation.
[03:03:31.600 --> 03:03:35.520]   Now, it may never get there, who knows?
[03:03:35.520 --> 03:03:38.800]   But it's certainly a possibility
[03:03:38.800 --> 03:03:40.160]   and we should be looking into it.
[03:03:40.160 --> 03:03:45.160]   - And there are wonky realities that need to be dealt with.
[03:03:45.160 --> 03:03:48.100]   The Nuclear Regulatory Commission in the United States,
[03:03:48.100 --> 03:03:51.760]   their approval process is still locked and designed
[03:03:51.760 --> 03:03:55.260]   on this 50 year old model of big, giant power plants.
[03:03:55.260 --> 03:03:57.140]   There's an intense discussion right now
[03:03:57.140 --> 03:04:01.620]   about evolving a new regulatory scheme
[03:04:01.620 --> 03:04:03.980]   for small modular ones because of all these
[03:04:03.980 --> 03:04:06.260]   implicit advantages they offer.
[03:04:06.260 --> 03:04:09.100]   And that, so, along with the innovation,
[03:04:09.100 --> 03:04:12.300]   you need to have this get out of the way
[03:04:12.300 --> 03:04:14.100]   or you're never gonna have the investment.
[03:04:14.100 --> 03:04:17.060]   So, it really is an all of the above thing.
[03:04:17.060 --> 03:04:19.220]   Looking at these as systems problems,
[03:04:19.220 --> 03:04:21.460]   systems solutions is really important.
[03:04:21.460 --> 03:04:25.020]   - Let me ask you about Alex Epstein.
[03:04:25.020 --> 03:04:29.680]   So, he wrote, I'm not sure if you're familiar who he is,
[03:04:29.680 --> 03:04:31.580]   but he wrote a couple of books.
[03:04:31.580 --> 03:04:34.040]   It's just interesting to ask a question about fossil fuels
[03:04:34.040 --> 03:04:36.000]   because we're talking about reality.
[03:04:36.000 --> 03:04:37.960]   And he's somebody that doesn't just talk about
[03:04:37.960 --> 03:04:41.360]   the reality of fossil fuels, but he wrote a book,
[03:04:41.360 --> 03:04:45.100]   "A Moral Case for Fossil Fuels and Fossil Future"
[03:04:45.100 --> 03:04:49.360]   where he makes the case that, as his subtitle says,
[03:04:49.360 --> 03:04:52.980]   "Global human flourishing requires oil, coal,
[03:04:52.980 --> 03:04:57.980]   "and natural gas," or more oil, coal, and natural gas,
[03:04:57.980 --> 03:04:58.960]   not less.
[03:04:58.960 --> 03:05:02.140]   What do you think about the argument he makes?
[03:05:02.140 --> 03:05:05.460]   So, he pushes, we've had this kind of,
[03:05:05.460 --> 03:05:08.620]   speaking of the center, of this balanced discussion
[03:05:08.620 --> 03:05:11.860]   of the reality of fossil fuels, but also investing a lot
[03:05:11.860 --> 03:05:16.860]   into renewable energy and then having the $1 to $11 return.
[03:05:16.860 --> 03:05:22.100]   He says, I'm not sure exactly how to frame it,
[03:05:22.100 --> 03:05:27.100]   but investing and maintaining investment of fossil fuels
[03:05:27.100 --> 03:05:30.940]   also has a positive return because of how efficient
[03:05:30.940 --> 03:05:32.120]   the energy is.
[03:05:32.120 --> 03:05:33.620]   - I read the first book.
[03:05:33.620 --> 03:05:35.380]   Yeah, I haven't read, I've got his second one.
[03:05:35.380 --> 03:05:37.620]   I've been planning to have him on my webcast,
[03:05:37.620 --> 03:05:38.500]   my tiny webcast.
[03:05:38.500 --> 03:05:41.220]   - What's the name of the webcast?
[03:05:41.220 --> 03:05:42.100]   - Sustain What?
[03:05:42.100 --> 03:05:43.900]   Everything I do is sustain what?
[03:05:43.900 --> 03:05:46.620]   'Cause it's like, don't talk to me about sustainability.
[03:05:46.620 --> 03:05:47.580]   Sustain what?
[03:05:47.580 --> 03:05:48.420]   For whom?
[03:05:48.420 --> 03:05:49.240]   How?
[03:05:49.240 --> 03:05:50.540]   Then we're talking, you know?
[03:05:50.540 --> 03:05:53.140]   Interrogatory approach to things.
[03:05:53.140 --> 03:05:57.660]   So, I think the valuable part of what he has done
[03:05:57.660 --> 03:06:02.140]   is to remind people, particularly in the West or North
[03:06:02.140 --> 03:06:04.460]   or whatever, the developed world,
[03:06:04.460 --> 03:06:06.820]   that everything we take for granted,
[03:06:07.820 --> 03:06:10.940]   low fertilizer, from low fertilizer prices
[03:06:10.940 --> 03:06:13.300]   to air conditioning to everything else,
[03:06:13.300 --> 03:06:15.500]   exists because we had this bounty
[03:06:15.500 --> 03:06:18.900]   that we dug out of the ground or pumped out of the ground.
[03:06:18.900 --> 03:06:22.100]   It's a boon, it's been an amazing boon to society, period.
[03:06:22.100 --> 03:06:23.460]   So, start there.
[03:06:23.460 --> 03:06:26.300]   Which means, going forward, what we're talking about
[03:06:26.300 --> 03:06:28.060]   is a substitution.
[03:06:28.060 --> 03:06:31.540]   Or, having your fossil fuels and eating it too,
[03:06:31.540 --> 03:06:33.220]   meaning getting rid of the carbon dioxide.
[03:06:33.220 --> 03:06:34.980]   If you focus on the carbon dioxide,
[03:06:34.980 --> 03:06:37.600]   which is the thing warming the planet,
[03:06:37.600 --> 03:06:40.340]   not the burning of the fuels,
[03:06:40.340 --> 03:06:41.860]   then that's another way forward
[03:06:41.860 --> 03:06:44.020]   that could sustain fossil fuels.
[03:06:44.020 --> 03:06:46.220]   As far as I can tell from at least the first book,
[03:06:46.220 --> 03:06:48.620]   he makes the moral case that fossil fuels
[03:06:48.620 --> 03:06:52.740]   are essentially a good overall.
[03:06:52.740 --> 03:06:55.660]   I don't think he adequately accounts for the need
[03:06:55.660 --> 03:06:58.060]   to stop global warming.
[03:06:58.060 --> 03:07:01.100]   You know, I think that we have to slow,
[03:07:01.100 --> 03:07:03.660]   slowing global warming is a fundamental need
[03:07:03.660 --> 03:07:06.340]   in this century we're in.
[03:07:06.340 --> 03:07:08.400]   And that's just not factored into his math.
[03:07:08.400 --> 03:07:10.160]   - Well, I think that's where,
[03:07:10.160 --> 03:07:13.200]   I've had a few sort of offline conversations with him.
[03:07:13.200 --> 03:07:16.040]   I think he said, 'cause I mentioned I'm talking to the two,
[03:07:16.040 --> 03:07:19.600]   he said that he, that's probably where he disagrees
[03:07:19.600 --> 03:07:24.600]   about sort of the level of threat that global warming causes.
[03:07:24.600 --> 03:07:27.340]   - Well, Steve Koonin is another one.
[03:07:27.340 --> 03:07:29.200]   He's a brilliant guy.
[03:07:29.200 --> 03:07:31.800]   He lived right close to me in the Hudson Valley.
[03:07:31.800 --> 03:07:34.320]   He was in the Obama administration energy department.
[03:07:34.320 --> 03:07:35.840]   It's K-O-O-N-I-N.
[03:07:35.840 --> 03:07:37.400]   He wrote a bestseller that came out recently
[03:07:37.400 --> 03:07:40.260]   on skepticism about climate.
[03:07:40.260 --> 03:07:46.720]   And there are other smart people who somehow feel
[03:07:46.720 --> 03:07:49.800]   we can literally adapt our way forward
[03:07:49.800 --> 03:07:53.960]   without any constraint on the gases changing the climate.
[03:07:53.960 --> 03:07:57.200]   And I, you know, I've spent enough time on this.
[03:07:57.200 --> 03:07:59.140]   I think I'm a pretty level-headed reporter
[03:07:59.140 --> 03:08:00.440]   when it comes to this issue.
[03:08:00.440 --> 03:08:04.820]   And I think having some sense that we can adapt our way
[03:08:04.820 --> 03:08:06.640]   into the world we're building
[03:08:06.640 --> 03:08:09.840]   through relentless climate change with no new normal,
[03:08:09.840 --> 03:08:14.080]   remember, more gas accumulating in the air every year.
[03:08:14.080 --> 03:08:17.360]   These are not static moments.
[03:08:17.360 --> 03:08:20.520]   That that's a good thing to do is,
[03:08:20.520 --> 03:08:25.360]   doesn't strike me as smart.
[03:08:25.360 --> 03:08:29.240]   - I'll probably say that I think it's more sort of a,
[03:08:29.240 --> 03:08:31.680]   at least the thing that I take away from Alex
[03:08:31.680 --> 03:08:35.380]   is the fact, as you point out,
[03:08:35.380 --> 03:08:37.900]   that we need to recognize that fossil fuels
[03:08:37.900 --> 03:08:40.960]   is basically the backbone of our society today.
[03:08:40.960 --> 03:08:44.340]   We get 80% of our energy from fossil fuels today.
[03:08:44.340 --> 03:08:46.540]   - Still, as we did 50 years ago, 40 years ago.
[03:08:46.540 --> 03:08:49.060]   - Yeah, yeah, and people have no sense of this, right?
[03:08:49.060 --> 03:08:50.620]   So they have the idea,
[03:08:50.620 --> 03:08:53.580]   because you see so many wind turbines and solar panels
[03:08:53.580 --> 03:08:55.020]   and everybody's talking about it,
[03:08:55.020 --> 03:08:57.020]   that this is huge, big things.
[03:08:57.020 --> 03:08:58.380]   But the reality is, remember,
[03:08:58.380 --> 03:09:01.800]   only about a fifth of all energy use is electricity.
[03:09:01.800 --> 03:09:04.040]   The rest is in processes and heating,
[03:09:04.040 --> 03:09:06.320]   industrial processes and so on.
[03:09:06.320 --> 03:09:09.680]   So actually, solar and wind right now
[03:09:09.680 --> 03:09:14.680]   produces 1% of energy from wind and 0.8% from solar.
[03:09:14.680 --> 03:09:16.800]   This is not a huge thing.
[03:09:16.800 --> 03:09:18.400]   It's a fairly tiny bit.
[03:09:18.400 --> 03:09:20.520]   - And growing explosively, but from this--
[03:09:20.520 --> 03:09:21.920]   - Yes, it's absolutely growing.
[03:09:21.920 --> 03:09:23.960]   But actually, it's growing slower
[03:09:23.960 --> 03:09:26.640]   than what nuclear was growing in the '70s and '80s,
[03:09:26.640 --> 03:09:28.320]   which I thought was a fun point,
[03:09:28.320 --> 03:09:31.200]   not by a little amount, by like two or three times.
[03:09:31.200 --> 03:09:34.040]   So we're still talking about something
[03:09:34.040 --> 03:09:37.240]   which is somewhat boutique, at least.
[03:09:37.240 --> 03:09:40.200]   And when you then look out into the future,
[03:09:40.200 --> 03:09:42.980]   and I think this is the interesting part of it,
[03:09:42.980 --> 03:09:44.520]   when you look out into the future,
[03:09:44.520 --> 03:09:47.320]   if you look at the Biden administration's own estimate
[03:09:47.320 --> 03:09:49.160]   of what will happen by 2050,
[03:09:49.160 --> 03:09:54.480]   we will be at, if all countries do all the stuff
[03:09:54.480 --> 03:09:56.080]   that they promised and everything,
[03:09:56.080 --> 03:10:01.080]   we will be at 70% fossil fuels by 2050, globally.
[03:10:01.080 --> 03:10:04.640]   This is just, yes, it's a better world.
[03:10:04.640 --> 03:10:07.160]   I think it's good that we're now down to 70
[03:10:07.160 --> 03:10:11.000]   instead of 80, but it is still a world
[03:10:11.000 --> 03:10:14.040]   that's fundamentally dependent on fossil fuels
[03:10:14.040 --> 03:10:17.440]   for almost everything that we really like about the world.
[03:10:17.440 --> 03:10:20.900]   And forgetting that, and I think we are doing that
[03:10:20.900 --> 03:10:22.480]   in the sense, as you also mentioned,
[03:10:22.480 --> 03:10:24.120]   that people say, "No fossil fuels,"
[03:10:24.120 --> 03:10:26.680]   and we're, in all development organizations,
[03:10:26.680 --> 03:10:28.800]   we're now telling the poor countries,
[03:10:28.800 --> 03:10:31.200]   you can't get any funding for anything
[03:10:31.200 --> 03:10:33.360]   that has to do with fossil fuels.
[03:10:33.360 --> 03:10:37.280]   We have literally reduced our investment
[03:10:37.280 --> 03:10:42.280]   in oil and gas by more than half since 2014.
[03:10:42.280 --> 03:10:46.680]   And much of this is because of climate concerns.
[03:10:46.680 --> 03:10:48.460]   This has real world consequences.
[03:10:48.460 --> 03:10:51.600]   This is why energy prices have gone up.
[03:10:51.600 --> 03:10:52.920]   It's not the only reason.
[03:10:52.920 --> 03:10:55.360]   COVID also, certainly the war in Ukraine,
[03:10:55.360 --> 03:10:58.480]   but this is an underlying systemic reason
[03:10:58.480 --> 03:11:01.400]   why fossil fuel costs will go up dramatically.
[03:11:01.400 --> 03:11:03.920]   Now, a lot of greens will sort of tend to say,
[03:11:03.920 --> 03:11:06.800]   "Well, that's great because we want fossil fuels
[03:11:06.800 --> 03:11:07.700]   "to be expensive.
[03:11:07.700 --> 03:11:10.720]   "We want people to be forced over to renewables."
[03:11:10.720 --> 03:11:14.080]   But that's very easy to say if you're rich.
[03:11:14.080 --> 03:11:16.320]   You know, it's the kind of thing that New Yorkers will say,
[03:11:16.320 --> 03:11:18.400]   you know, when you go to rich,
[03:11:18.400 --> 03:11:20.820]   well-meaning green New Yorkers and say,
[03:11:20.820 --> 03:11:24.080]   "Yes, gasoline should cost $20 a gallon."
[03:11:24.080 --> 03:11:26.160]   Well, you don't have a car.
[03:11:26.160 --> 03:11:27.720]   You just ride the Metro.
[03:11:27.720 --> 03:11:29.140]   It's very easy for you to say that,
[03:11:29.140 --> 03:11:31.480]   but lots of people, both in the rich world,
[03:11:31.480 --> 03:11:33.840]   but in poor parts of the US,
[03:11:33.840 --> 03:11:35.260]   but all around the world,
[03:11:35.260 --> 03:11:37.760]   their lives are basically dependent on fossil fuels.
[03:11:37.760 --> 03:11:40.560]   And so the idea that we're gonna get people off
[03:11:40.560 --> 03:11:42.220]   by making it so expensive
[03:11:42.220 --> 03:11:45.640]   that it becomes impossible for them to live good lives
[03:11:45.640 --> 03:11:47.680]   is almost morally reprehensible.
[03:11:47.680 --> 03:11:50.720]   And I think Alex has the right point there.
[03:11:50.720 --> 03:11:53.340]   We need to get people to realize
[03:11:53.340 --> 03:11:55.980]   we're not gonna get off fossil fuels anytime soon.
[03:11:55.980 --> 03:11:59.300]   So we need reasonably affordable fossil fuels
[03:11:59.300 --> 03:12:00.620]   for most of the world.
[03:12:00.620 --> 03:12:03.300]   And that's, of course, why we need to focus so much more
[03:12:03.300 --> 03:12:05.900]   on the innovation so that we can get to the point
[03:12:05.900 --> 03:12:09.220]   where we no longer need fossil fuels as soon as possible.
[03:12:09.220 --> 03:12:10.520]   But to say to everyone,
[03:12:10.520 --> 03:12:12.760]   "Look, we're gonna make fossil fuels expensive
[03:12:12.760 --> 03:12:15.420]   "way before we have the solution," is just terrible.
[03:12:15.420 --> 03:12:19.240]   - And so much is on the rich countries of the world.
[03:12:19.480 --> 03:12:20.320]   - Yeah.
[03:12:20.320 --> 03:12:24.180]   - I did a conversation recently with Johan Rockström,
[03:12:24.180 --> 03:12:29.180]   who's a famed sustainability scientist in Stockholm.
[03:12:29.180 --> 03:12:31.680]   Actually, Potsdam now.
[03:12:31.680 --> 03:12:32.520]   - Right.
[03:12:32.520 --> 03:12:35.220]   - And he's come up with the idea of planetary boundaries.
[03:12:35.220 --> 03:12:37.860]   There's lots of things he has said that I,
[03:12:37.860 --> 03:12:39.980]   as a journalist, I'm still looking into about that.
[03:12:39.980 --> 03:12:40.940]   - Planetary boundaries?
[03:12:40.940 --> 03:12:43.260]   - Yeah, that there are limits to what Earth can absorb
[03:12:43.260 --> 03:12:46.340]   in human, our use of water, phosphorus,
[03:12:46.340 --> 03:12:48.740]   or carbon dioxide loading in the atmosphere.
[03:12:48.740 --> 03:12:51.180]   There are these tipping, there are these boundaries.
[03:12:51.180 --> 03:12:54.380]   If we cross them, we're in a hot zone, a danger zone.
[03:12:54.380 --> 03:12:55.820]   He's an interesting thinker.
[03:12:55.820 --> 03:13:00.820]   But on this point, last year at the Glasgow Climate Talks,
[03:13:00.820 --> 03:13:05.740]   he gave a very important talk about the equity thing here.
[03:13:05.740 --> 03:13:11.000]   He basically laid out a landscape saying
[03:13:11.000 --> 03:13:14.160]   the rich nations of the world need to greatly ramp up
[03:13:14.160 --> 03:13:15.620]   their reduction of emissions
[03:13:15.620 --> 03:13:17.960]   or what they're gonna pay poor countries to do.
[03:13:18.880 --> 03:13:20.720]   To allow poor countries,
[03:13:20.720 --> 03:13:25.040]   some of which have fossil resources, like in Africa,
[03:13:25.040 --> 03:13:26.920]   to have the carbon space,
[03:13:26.920 --> 03:13:30.360]   to own whatever space or time is left
[03:13:30.360 --> 03:13:34.060]   to be able to develop their fossil fuels
[03:13:34.060 --> 03:13:36.480]   as a fundamental right.
[03:13:36.480 --> 03:13:39.320]   Because also, they're starting from this little baseline.
[03:13:39.320 --> 03:13:41.880]   Ghana hasn't contributed squat
[03:13:41.880 --> 03:13:44.320]   to the global warming problem in terms of emissions.
[03:13:44.320 --> 03:13:46.000]   Ghana has natural gas.
[03:13:46.000 --> 03:13:48.560]   And right now, this month,
[03:13:48.560 --> 03:13:52.640]   environmental groups are outside the World Bank,
[03:13:52.640 --> 03:13:54.860]   today, actually tonight,
[03:13:54.860 --> 03:13:57.640]   saying this was on their list of dirty projects.
[03:13:57.640 --> 03:13:59.000]   World Bank should stop financing
[03:13:59.000 --> 03:14:01.440]   Ghana's right to get gas out of the ground.
[03:14:01.440 --> 03:14:04.440]   To develop its economy, get its people less poor,
[03:14:04.440 --> 03:14:07.560]   make them more productive, innovative parts of humanity.
[03:14:07.560 --> 03:14:10.260]   To me, that's really reprehensible.
[03:14:10.260 --> 03:14:12.320]   One of the other projects on their list,
[03:14:12.320 --> 03:14:14.280]   as a World Bank kind of gotcha,
[03:14:14.280 --> 03:14:16.480]   like how dare they give money,
[03:14:16.480 --> 03:14:19.840]   was for a fertilizer factory in Bangladesh
[03:14:19.840 --> 03:14:23.480]   that is designed to get three times as much fertilizer
[03:14:23.480 --> 03:14:25.060]   from the same amount of natural gas
[03:14:25.060 --> 03:14:27.000]   as the old plants that are now dormant.
[03:14:27.000 --> 03:14:32.600]   This is in a time when we're facing high energy prices,
[03:14:32.600 --> 03:14:34.960]   high gas prices, high food prices,
[03:14:34.960 --> 03:14:37.600]   when food insecurity is spreading rapidly.
[03:14:37.600 --> 03:14:40.000]   When a country like Bangladesh has millions of rice farmers
[03:14:40.000 --> 03:14:44.320]   who need urea tablets to put in their rice fields.
[03:14:44.320 --> 03:14:46.320]   And to say that shouldn't,
[03:14:46.320 --> 03:14:47.680]   how dare they finance that
[03:14:47.680 --> 03:14:50.720]   because there's a fossil fuel involved is immoral.
[03:14:50.720 --> 03:14:52.720]   So yes on that point from Alex.
[03:14:52.720 --> 03:14:56.960]   - So this is 2022 poll.
[03:14:56.960 --> 03:14:59.020]   Polls.
[03:14:59.020 --> 03:15:01.720]   Just this is a bunch of different ways
[03:15:01.720 --> 03:15:04.440]   to look at the same basic effect.
[03:15:04.440 --> 03:15:05.880]   In the United States,
[03:15:05.880 --> 03:15:09.460]   Democrats, younger Americans identify
[03:15:09.460 --> 03:15:12.000]   dealing with climate change as a top priority.
[03:15:12.000 --> 03:15:14.240]   US adults,
[03:15:14.240 --> 03:15:15.920]   42% say,
[03:15:15.920 --> 03:15:19.160]   42% say that dealing with climate change
[03:15:19.160 --> 03:15:21.160]   should be a top priority.
[03:15:21.160 --> 03:15:23.440]   11% of Republicans,
[03:15:23.440 --> 03:15:25.840]   65% of Democrats.
[03:15:25.840 --> 03:15:28.940]   And we could see this effect throughout.
[03:15:28.940 --> 03:15:34.660]   46% of Americans say human activity
[03:15:34.660 --> 03:15:37.180]   contributes a great deal to climate change.
[03:15:37.180 --> 03:15:39.560]   By the way, this is a little bit different
[03:15:39.560 --> 03:15:41.040]   than what we're discussing.
[03:15:41.040 --> 03:15:44.040]   I was just looking through different polls.
[03:15:44.040 --> 03:15:48.480]   In the public there seems to still be uncertainty
[03:15:48.480 --> 03:15:52.840]   about how much humans contribute to climate change.
[03:15:52.840 --> 03:15:55.320]   More than the scientific--
[03:15:55.320 --> 03:15:57.480]   - It would only be 24% that disagree
[03:15:57.480 --> 03:15:59.400]   with the UN Climate Panel.
[03:15:59.400 --> 03:16:00.920]   Three quarters would agree.
[03:16:00.920 --> 03:16:02.840]   - Are you uncomfortable about the 29?
[03:16:02.840 --> 03:16:06.160]   - 29 is actually, it's exactly right.
[03:16:06.160 --> 03:16:08.560]   I mean, the UN doesn't say it's all.
[03:16:08.560 --> 03:16:11.260]   Well, they say that could be the border case.
[03:16:11.260 --> 03:16:12.740]   - But anyway, this is interesting,
[03:16:12.740 --> 03:16:14.740]   but to me, across all these polls,
[03:16:14.740 --> 03:16:18.440]   if you look Republican versus Democrat,
[03:16:18.440 --> 03:16:19.520]   Republican,
[03:16:19.520 --> 03:16:24.560]   say that 17% say it's a great deal.
[03:16:24.560 --> 03:16:28.040]   Democrats say 71% say it's a great deal.
[03:16:28.040 --> 03:16:30.500]   And you just see this complete division.
[03:16:30.500 --> 03:16:33.200]   I think you probably,
[03:16:34.120 --> 03:16:35.540]   with COVID pandemic,
[03:16:35.540 --> 03:16:39.680]   you can ask a lot of questions like this.
[03:16:39.680 --> 03:16:41.160]   Do masks work?
[03:16:41.160 --> 03:16:43.040]   Are they an effective method
[03:16:43.040 --> 03:16:45.320]   to slow transmission of a pandemic?
[03:16:45.320 --> 03:16:47.880]   You'll probably have the same kind of polls
[03:16:47.880 --> 03:16:50.120]   about Republicans and Democrats.
[03:16:50.120 --> 03:16:54.700]   And while the effectiveness of masks,
[03:16:54.700 --> 03:16:56.400]   to me, is a scientific question.
[03:16:56.400 --> 03:17:00.520]   So there's different truths here, apparently.
[03:17:00.520 --> 03:17:02.060]   One is a scientific truth.
[03:17:03.700 --> 03:17:07.360]   One is a truth held by the scientific community,
[03:17:07.360 --> 03:17:08.640]   which seems to be also different
[03:17:08.640 --> 03:17:11.000]   than the scientific truth sometimes.
[03:17:11.000 --> 03:17:13.000]   And the other is the public perception
[03:17:13.000 --> 03:17:18.000]   that's polluted or affected by political affiliation.
[03:17:18.000 --> 03:17:23.040]   And then there's whatever is the narrative
[03:17:23.040 --> 03:17:25.960]   that's communicated by the media.
[03:17:25.960 --> 03:17:27.480]   They will also have a question,
[03:17:27.480 --> 03:17:30.120]   answer to the question of whether masks work or not.
[03:17:30.120 --> 03:17:32.080]   And they will also have an answer to the question
[03:17:32.080 --> 03:17:34.180]   about all these climate-related things.
[03:17:34.180 --> 03:17:38.120]   So that's a long way of asking the question
[03:17:38.120 --> 03:17:43.120]   of how is politics mixed into all of this?
[03:17:43.120 --> 03:17:45.000]   On the communication front,
[03:17:45.000 --> 03:17:48.380]   on the figuring out what the right policy is front,
[03:17:48.380 --> 03:17:50.660]   on the friction of humanity
[03:17:50.660 --> 03:17:53.580]   in the face of the right policies.
[03:17:53.580 --> 03:17:55.580]   - Well, I've written a ton on this.
[03:17:55.580 --> 03:17:59.740]   After I had that conversion about the social science in 2006,
[03:17:59.740 --> 03:18:03.180]   I began digging in a lot more on how people hold beliefs
[03:18:03.180 --> 03:18:06.980]   and what they do as opposed to what they think
[03:18:06.980 --> 03:18:10.260]   and questions about polling.
[03:18:10.260 --> 03:18:12.040]   And there's two things that come to me
[03:18:12.040 --> 03:18:15.020]   that make me not worry about the basic literacy,
[03:18:15.020 --> 03:18:19.260]   like is climate change X percent of whatever?
[03:18:19.260 --> 03:18:21.300]   I don't really care about that.
[03:18:21.300 --> 03:18:22.560]   And I'll explain why.
[03:18:22.560 --> 03:18:27.260]   For one thing, more science literacy,
[03:18:27.260 --> 03:18:30.940]   more basic literacy, like what is a greenhouse gas,
[03:18:30.940 --> 03:18:32.380]   all that stuff.
[03:18:32.380 --> 03:18:35.540]   Dan Kahane, K-A-H-A-N at Yale.
[03:18:35.540 --> 03:18:37.900]   He's actually at Yale Law School.
[03:18:37.900 --> 03:18:40.060]   The last decade, he did all this work
[03:18:40.060 --> 03:18:41.960]   on what he calls cultural cognition,
[03:18:41.960 --> 03:18:47.080]   which is, and he did studies that showed
[03:18:47.080 --> 03:18:53.140]   how what you believe emerges based on culture,
[03:18:53.140 --> 03:18:56.220]   based on your background, your red, blue,
[03:18:56.220 --> 03:18:58.340]   your where you are in the country.
[03:18:58.340 --> 03:19:01.180]   And one of the really disturbing findings was
[03:19:01.180 --> 03:19:04.940]   that the people who have the most basic science literacy,
[03:19:04.940 --> 03:19:09.080]   like who know the most about greenhouse effect or whatever,
[03:19:09.080 --> 03:19:13.260]   they're at both ends of the spectrum of views on climate,
[03:19:13.260 --> 03:19:15.260]   dismissives and alarmed.
[03:19:15.260 --> 03:19:17.140]   Steve Koonin, as I mentioned, is a good example.
[03:19:17.140 --> 03:19:19.300]   He's a brilliant physicist.
[03:19:19.300 --> 03:19:20.980]   And he knows all the science
[03:19:20.980 --> 03:19:23.420]   and he's completely at the end of skepticism.
[03:19:24.860 --> 03:19:29.460]   Will Happer, who was close to being Trump's science advisor,
[03:19:29.460 --> 03:19:31.100]   was even more out there.
[03:19:31.100 --> 03:19:34.460]   And they're both on the Jason Committee
[03:19:34.460 --> 03:19:37.060]   that advises the government on big strategic things.
[03:19:37.060 --> 03:19:40.780]   And people who are really alarmed about it
[03:19:40.780 --> 03:19:41.980]   also have the same belief.
[03:19:41.980 --> 03:19:43.380]   So as a journalist, I was thinking,
[03:19:43.380 --> 03:19:47.020]   do I just spend my time writing more explanatory stories
[03:19:47.020 --> 03:19:48.680]   that explain the science better?
[03:19:48.680 --> 03:19:51.020]   No.
[03:19:51.020 --> 03:19:53.120]   Do I dig in on this work to understand
[03:19:53.120 --> 03:19:54.520]   what brings people together?
[03:19:54.520 --> 03:19:58.200]   And then these same surveys, the same science shows you,
[03:19:58.200 --> 03:20:01.120]   if you don't make it about climate, among other things,
[03:20:01.120 --> 03:20:04.060]   this becomes, you don't have to worry about this anymore.
[03:20:04.060 --> 03:20:09.060]   If you Google for no red-blue divide climate revkin,
[03:20:09.060 --> 03:20:11.860]   you'll find a piece I did with some really good graphs.
[03:20:11.860 --> 03:20:15.140]   Essentially, it shows that in America,
[03:20:15.140 --> 03:20:16.380]   this is the Yale group again,
[03:20:16.380 --> 03:20:19.200]   their climate communication group.
[03:20:19.200 --> 03:20:23.180]   There's no red-blue divide on energy innovation, none.
[03:20:23.180 --> 03:20:26.060]   We need more climate energy, clean energy innovation.
[03:20:26.060 --> 03:20:29.820]   There wasn't even a divide country by state by state
[03:20:29.820 --> 03:20:33.620]   on whether CO2 should be regulated as a pollutant.
[03:20:33.620 --> 03:20:37.220]   But it's all like, what are the questions you ask?
[03:20:37.220 --> 03:20:40.220]   If you ask about innovation,
[03:20:40.220 --> 03:20:44.400]   if you ask about more incentives for renewable power.
[03:20:44.400 --> 03:20:50.180]   Oklahoma, Iowa, I did a piece when I was at ProPublica
[03:20:50.180 --> 03:20:54.420]   showing that the 17 states that were fighting Obama
[03:20:54.420 --> 03:20:59.020]   in court over his clean power plan,
[03:20:59.020 --> 03:21:00.940]   were actually, the majority of them
[03:21:00.940 --> 03:21:02.340]   were actually meeting the targets
[03:21:02.340 --> 03:21:04.720]   that the clean power plan had
[03:21:04.720 --> 03:21:07.900]   because they're expanding wind power already.
[03:21:07.900 --> 03:21:09.100]   Not because of the climate,
[03:21:09.100 --> 03:21:12.140]   because it makes money sense and energy sense.
[03:21:12.140 --> 03:21:14.100]   - So you don't think there's a political divide in this?
[03:21:14.100 --> 03:21:16.580]   - There is on climate, if you call it climate.
[03:21:16.580 --> 03:21:18.060]   If you say it's a climate,
[03:21:18.060 --> 03:21:19.580]   do you believe in the climate crisis?
[03:21:19.580 --> 03:21:21.420]   You're not asking,
[03:21:21.420 --> 03:21:24.820]   what kind of energy future do you want in your town?
[03:21:24.820 --> 03:21:27.420]   And so if you ask that question,
[03:21:27.420 --> 03:21:28.860]   the polarization goes away.
[03:21:28.860 --> 03:21:30.900]   - I guess what I'm asking,
[03:21:30.900 --> 03:21:33.260]   is there polarization on policy?
[03:21:33.260 --> 03:21:35.960]   - No, well there, again,
[03:21:35.960 --> 03:21:39.920]   the bipartisan infrastructure law
[03:21:39.920 --> 03:21:43.060]   that was passed last November, that was bipartisan.
[03:21:43.060 --> 03:21:44.340]   All of Congress said yes.
[03:21:44.340 --> 03:21:45.840]   And that's a trillion dollars,
[03:21:45.840 --> 03:21:48.060]   several hundred billion of which
[03:21:48.060 --> 03:21:50.100]   are for cleaner energy and resilience.
[03:21:50.100 --> 03:21:51.940]   - Yeah, but that's--
[03:21:51.940 --> 03:21:55.180]   - And that, but it's not a climate bill.
[03:21:55.180 --> 03:21:56.940]   And it wasn't a tax.
[03:21:56.940 --> 03:22:00.180]   It's incentives.
[03:22:00.180 --> 03:22:02.780]   - So the word climate and similar words
[03:22:02.780 --> 03:22:06.660]   are just used as part of the signaling, like masks.
[03:22:06.660 --> 03:22:09.140]   It's not-- - Absolutely.
[03:22:09.140 --> 03:22:11.460]   Dan Cahan's work, the guy at Yale,
[03:22:11.460 --> 03:22:13.460]   he really demonstrated powerfully
[03:22:13.460 --> 03:22:16.700]   abortion, gun rights, climate.
[03:22:16.700 --> 03:22:19.740]   And a more part level nuclear power
[03:22:19.740 --> 03:22:22.620]   has enduring camps that for and against--
[03:22:22.620 --> 03:22:24.460]   - What are the camps for?
[03:22:24.460 --> 03:22:28.260]   - Some of it's cultural cognition.
[03:22:28.260 --> 03:22:30.860]   It's how you grew up, it's what you fear.
[03:22:30.860 --> 03:22:32.540]   There's no common human frame for--
[03:22:32.540 --> 03:22:34.020]   - Is it 'cause of like folks,
[03:22:34.020 --> 03:22:36.340]   like certain individuals like Al Gore?
[03:22:36.340 --> 03:22:38.260]   - Ah.
[03:22:38.260 --> 03:22:39.940]   - Like he would make a film,
[03:22:39.940 --> 03:22:42.780]   he cares about this thing, he's a Democrat.
[03:22:42.780 --> 03:22:44.100]   - Therefore I hate this thing.
[03:22:44.100 --> 03:22:45.380]   - Therefore I don't like this thing, yeah.
[03:22:45.380 --> 03:22:46.860]   - Oh sure, yeah.
[03:22:46.860 --> 03:22:48.220]   When people get attached to an issue,
[03:22:48.220 --> 03:22:50.820]   if that's what pops into your head
[03:22:50.820 --> 03:22:52.300]   when you hear climate then.
[03:22:52.300 --> 03:22:56.240]   And it got politicized, it became emblematic.
[03:22:56.240 --> 03:23:00.380]   And the whole vaccine thing.
[03:23:00.380 --> 03:23:01.740]   - I mean, I'm not American,
[03:23:01.740 --> 03:23:03.540]   so I should stay a little bit out of this,
[03:23:03.540 --> 03:23:07.620]   but I think it seems to me that a lot of the thing
[03:23:07.620 --> 03:23:10.020]   that people believe and talk about
[03:23:10.020 --> 03:23:13.460]   is really about what they worry that that will lead to
[03:23:13.460 --> 03:23:15.700]   in terms of policy down the line.
[03:23:15.700 --> 03:23:18.280]   So a little bit like, do masks work?
[03:23:18.280 --> 03:23:21.940]   I'm sort of imagining, I don't know whether this is true,
[03:23:21.940 --> 03:23:25.060]   but I think part of it is, if I say masks work,
[03:23:25.060 --> 03:23:27.840]   they're gonna force me to wear it for the next year.
[03:23:27.840 --> 03:23:30.400]   So it doesn't work because then I don't have to wear it,
[03:23:30.400 --> 03:23:31.240]   kind of thing.
[03:23:31.240 --> 03:23:34.740]   That it's really, you're looking much further down the line.
[03:23:34.740 --> 03:23:37.160]   And certainly on climate, it seems to me
[03:23:37.160 --> 03:23:40.340]   that a lot of the people who say it's not real,
[03:23:40.340 --> 03:23:42.500]   it's not because they don't know it's,
[03:23:42.500 --> 03:23:43.580]   of course it's real,
[03:23:43.580 --> 03:23:45.780]   but it's that they don't want you to then come
[03:23:45.780 --> 03:23:48.060]   and regulate it really heavily.
[03:23:48.060 --> 03:23:48.900]   So it's-
[03:23:48.900 --> 03:23:50.220]   - Because they don't like top-down government.
[03:23:50.220 --> 03:23:53.220]   - Yeah, and also because they don't want another tax.
[03:23:53.220 --> 03:23:55.420]   And there's lots of other,
[03:23:55.420 --> 03:23:57.700]   so it's really, it's not a science,
[03:23:57.700 --> 03:23:59.900]   it's not a straight science question.
[03:23:59.900 --> 03:24:03.100]   It really is a question of what do you want to do?
[03:24:03.100 --> 03:24:04.620]   And that's where I think, Andy,
[03:24:04.620 --> 03:24:06.600]   you're much, much more right in saying
[03:24:06.600 --> 03:24:08.800]   we should have that discussion.
[03:24:08.800 --> 03:24:10.440]   So what do you wanna do?
[03:24:10.440 --> 03:24:13.840]   Because that will be a much easier conversation to say,
[03:24:13.840 --> 03:24:15.820]   do you wanna do really smart, cheap stuff?
[03:24:15.820 --> 03:24:18.740]   Or do you wanna do pretty dumb, expensive stuff?
[03:24:18.740 --> 03:24:21.300]   When you put it that way, you can get most people on board.
[03:24:21.300 --> 03:24:23.460]   Of course, it's not as simple as that, I know.
[03:24:23.460 --> 03:24:25.060]   - And it gets back to what you said earlier,
[03:24:25.060 --> 03:24:27.700]   that again, you talked about collaborative cooperation
[03:24:27.700 --> 03:24:28.540]   or whatever.
[03:24:28.540 --> 03:24:31.460]   There's a guy at Columbia, Peter Coleman,
[03:24:31.460 --> 03:24:32.300]   who runs this thing called
[03:24:32.300 --> 03:24:34.300]   the Difficult Conversations Laboratory.
[03:24:34.300 --> 03:24:35.620]   (laughing)
[03:24:35.620 --> 03:24:36.460]   Yeah.
[03:24:36.460 --> 03:24:37.280]   - Yeah, that's awesome.
[03:24:37.280 --> 03:24:38.120]   - And when I first heard about it, I was like,
[03:24:38.120 --> 03:24:39.380]   oh man, we need that.
[03:24:40.340 --> 03:24:45.340]   And his background's in psychology and conflict resolution,
[03:24:45.340 --> 03:24:48.900]   mostly at the global scale related to atrocities
[03:24:48.900 --> 03:24:50.260]   that countries are trying to get over.
[03:24:50.260 --> 03:24:54.500]   And there's a science to how to hold a better conversation.
[03:24:54.500 --> 03:24:58.340]   As you, either through experience or whatever, know,
[03:24:58.340 --> 03:25:00.540]   if you hold a debate,
[03:25:00.540 --> 03:25:02.900]   like I wouldn't wanna be in a debate with Bjorn.
[03:25:02.900 --> 03:25:05.180]   We could find lots of things we disagree on.
[03:25:05.180 --> 03:25:08.000]   But that takes it back to the win-lose model, right?
[03:25:08.860 --> 03:25:11.420]   That's not how you make progress.
[03:25:11.420 --> 03:25:15.420]   And what Peter, what I learned, absorbed from him,
[03:25:15.420 --> 03:25:18.740]   Peter Coleman, 'cause I was thinking,
[03:25:18.740 --> 03:25:19.820]   we need room for agreement.
[03:25:19.820 --> 03:25:21.060]   I need to build a room for agreement.
[03:25:21.060 --> 03:25:24.820]   My blog and at the Times and then the stuff I do now,
[03:25:24.820 --> 03:25:27.420]   it's like, how can we talk and come to agreement?
[03:25:27.420 --> 03:25:29.140]   He says, no, no, you don't want agreement.
[03:25:29.140 --> 03:25:30.180]   You want cooperation.
[03:25:30.180 --> 03:25:34.060]   That allows you to hold onto your beliefs.
[03:25:34.060 --> 03:25:37.800]   But to, we can disbelieve,
[03:25:37.800 --> 03:25:39.060]   we can disagree on all these things,
[03:25:39.060 --> 03:25:41.140]   but let's cooperate on that one thing.
[03:25:41.140 --> 03:25:44.560]   And that's a really valuable distinction
[03:25:44.560 --> 03:25:46.620]   that's needed so much in this arena,
[03:25:46.620 --> 03:25:49.200]   because as I said earlier,
[03:25:49.200 --> 03:25:52.140]   you can parse it right down to the whole menu
[03:25:52.140 --> 03:25:56.000]   of things Joe Manchin wanted, transmission lines.
[03:25:56.000 --> 03:25:57.940]   Now we're gonna have big fights over transmission lines.
[03:25:57.940 --> 03:25:59.460]   We've got billions of dollars to spend
[03:25:59.460 --> 03:26:01.560]   expanding America's grid.
[03:26:01.560 --> 03:26:04.220]   And every community in America is gonna say, not here.
[03:26:04.220 --> 03:26:08.920]   So how do you foster a federal local dialogue
[03:26:08.920 --> 03:26:10.360]   that allows that to happen
[03:26:10.360 --> 03:26:12.940]   if you wanna have any hope of a better grid?
[03:26:12.940 --> 03:26:18.220]   So that's like, those insights come from behavioral sciences
[03:26:18.220 --> 03:26:23.220]   that I think are completely undervalued in this area.
[03:26:23.220 --> 03:26:26.840]   - Pilka loves to quote, I think it's Lippert, but--
[03:26:26.840 --> 03:26:28.000]   - Oh, Walter Lippman.
[03:26:28.000 --> 03:26:31.160]   - Lippman, yes, that democracy is not about
[03:26:31.160 --> 03:26:33.800]   everybody agreeing, but it's about different people
[03:26:33.800 --> 03:26:36.520]   disagreeing, but doing the same thing.
[03:26:36.520 --> 03:26:37.800]   - Doing one thing together.
[03:26:37.800 --> 03:26:40.260]   - Yes, I mean, agreeing that we're gonna do this thing.
[03:26:40.260 --> 03:26:42.840]   So you can disagree, but still do a thing,
[03:26:42.840 --> 03:26:45.640]   possibly for very different reasons.
[03:26:45.640 --> 03:26:48.340]   - Yeah, and there's an amazing video clip
[03:26:48.340 --> 03:26:51.560]   that shows this so powerfully.
[03:26:51.560 --> 03:26:54.360]   2015 was the buildup to the Paris talks
[03:26:54.360 --> 03:26:57.840]   that led to the Paris agreement, you know this.
[03:26:57.840 --> 03:27:00.920]   And a really talented journalist at CNN at the time,
[03:27:00.920 --> 03:27:03.720]   John Sutter, who's from Oklahoma originally,
[03:27:03.720 --> 03:27:08.720]   he saw another Yale study that was a county by county study
[03:27:08.720 --> 03:27:12.040]   of American attitudes on global warming,
[03:27:12.040 --> 03:27:13.440]   like right down to the county level.
[03:27:13.440 --> 03:27:17.760]   And there's this little glowing data point
[03:27:17.760 --> 03:27:20.500]   in Woodward County, Oklahoma.
[03:27:20.500 --> 03:27:22.440]   Woodward County, Oklahoma was ground zero
[03:27:22.440 --> 03:27:24.400]   for climate skepticism, climate denial,
[03:27:24.400 --> 03:27:25.920]   whatever you wanna call it.
[03:27:25.920 --> 03:27:27.080]   And he thought, oh, I'm gonna go there.
[03:27:27.080 --> 03:27:30.520]   And he went there just to meet people on the street,
[03:27:30.520 --> 03:27:33.240]   talk to them about energy and weather.
[03:27:33.240 --> 03:27:35.080]   And he did these little interviews.
[03:27:35.080 --> 03:27:36.480]   And there's this one with this guy
[03:27:36.480 --> 03:27:39.540]   who's like a middle-aged oil company employee,
[03:27:39.540 --> 03:27:43.380]   like a administrator, Thai kind of guy.
[03:27:43.380 --> 03:27:46.080]   And he starts out the interview,
[03:27:46.080 --> 03:27:47.880]   and the guy is saying, well, you know,
[03:27:47.880 --> 03:27:49.780]   God controls the environment.
[03:27:49.780 --> 03:27:51.880]   And if you're watching this, you're just going,
[03:27:51.880 --> 03:27:54.000]   okay, this is gonna be interesting.
[03:27:54.000 --> 03:27:55.640]   And the backstory, by the way, is the guy,
[03:27:55.640 --> 03:27:59.480]   he paid for the local playground
[03:27:59.480 --> 03:28:01.400]   to have dinosaurs and people,
[03:28:01.400 --> 03:28:04.440]   like toy dinosaurs and people on the playground,
[03:28:04.440 --> 03:28:06.280]   'cause he believes in creation,
[03:28:06.280 --> 03:28:07.960]   6,000-year creation. - 6,000, yeah.
[03:28:07.960 --> 03:28:09.980]   - So that's the guy, right?
[03:28:09.980 --> 03:28:11.880]   And then he gets to energy, and the guy says,
[03:28:11.880 --> 03:28:14.240]   you know, the same guy who believes
[03:28:14.240 --> 03:28:16.820]   God controls the environment says,
[03:28:16.820 --> 03:28:18.100]   you know, we have half of our roof covered
[03:28:18.100 --> 03:28:21.640]   with solar panels, and we wanna get off the grid entirely.
[03:28:21.640 --> 03:28:24.240]   And when I show this, I show this to audiences,
[03:28:24.240 --> 03:28:27.640]   and I say, just pause and think about that for a second.
[03:28:27.640 --> 03:28:30.320]   If you went, why do you think that's happening?
[03:28:30.320 --> 03:28:31.600]   And it's 'cause he's independent.
[03:28:31.600 --> 03:28:33.040]   He wants to have his own source of power.
[03:28:33.040 --> 03:28:33.880]   He's libertarian.
[03:28:33.880 --> 03:28:35.520]   He doesn't want the government telling him what to do.
[03:28:35.520 --> 03:28:37.480]   He would never vote for Hillary, I guarantee you.
[03:28:37.480 --> 03:28:39.480]   This is 2015.
[03:28:39.480 --> 03:28:40.880]   But he wanted to get off the grid entirely
[03:28:40.880 --> 03:28:44.300]   to be his own, to be himself.
[03:28:44.300 --> 03:28:47.000]   And so then I say, okay, so if you were going
[03:28:47.000 --> 03:28:49.840]   around the country with your climate crisis placard,
[03:28:49.840 --> 03:28:51.880]   and you go to Woodward County,
[03:28:51.880 --> 03:28:54.360]   do you think that would be a productive way
[03:28:54.360 --> 03:28:57.120]   to go to that place and make your case?
[03:28:57.120 --> 03:29:00.240]   And the answer is pretty obvious, no.
[03:29:00.240 --> 03:29:02.080]   If you go in there and you listen,
[03:29:02.080 --> 03:29:04.360]   like listening is such an important property
[03:29:04.360 --> 03:29:06.440]   that we all forget, including journalists,
[03:29:06.440 --> 03:29:11.560]   you're much more apt to find a path to cooperation.
[03:29:11.560 --> 03:29:13.840]   You could talk to him about, I guarantee,
[03:29:13.840 --> 03:29:15.840]   if I went there today, maybe I should go
[03:29:15.840 --> 03:29:18.320]   to talk about this new bill, $370 billion.
[03:29:18.320 --> 03:29:21.880]   How do we make that work at the local level?
[03:29:21.880 --> 03:29:23.960]   How do we answer that guy at the energy department,
[03:29:23.960 --> 03:29:26.680]   Jigar Shah, so how do we put this to work
[03:29:26.680 --> 03:29:29.760]   to get our buses off, to get electrified,
[03:29:29.760 --> 03:29:33.040]   or transition our street lamps and stuff?
[03:29:33.040 --> 03:29:34.560]   You could have a good chat with him.
[03:29:34.560 --> 03:29:36.960]   If you go in there and say, I'm here to debate you
[03:29:36.960 --> 03:29:39.580]   to death on global warming, forget about it.
[03:29:39.580 --> 03:29:42.560]   - Actually, let me ask you a question,
[03:29:42.560 --> 03:29:45.140]   given your roots as a journalist.
[03:29:45.140 --> 03:29:49.480]   So yeah, talking to a guy you disagree with,
[03:29:49.480 --> 03:29:51.080]   that's one thing.
[03:29:51.080 --> 03:29:56.080]   What about talking to people that might be,
[03:29:56.200 --> 03:30:01.200]   society might consider bad, unethical, even evil?
[03:30:01.200 --> 03:30:05.040]   What's the role of a journalist in that context?
[03:30:05.040 --> 03:30:09.080]   So climate change is a large number of people
[03:30:09.080 --> 03:30:11.200]   that believe one thing, a large number of people
[03:30:11.200 --> 03:30:13.200]   that believe another thing.
[03:30:13.200 --> 03:30:16.320]   It turns out, even with people that society deems as evil,
[03:30:16.320 --> 03:30:19.360]   there's a large number of people that support them.
[03:30:19.360 --> 03:30:24.360]   What's your role as a journalist to talk to them?
[03:30:24.600 --> 03:30:27.600]   - Well, I have talked to really bad people.
[03:30:27.600 --> 03:30:29.960]   When I wrote about the murder of Chico Mendes,
[03:30:29.960 --> 03:30:34.360]   a Brazilian Amazon rainforest activist in 1989,
[03:30:34.360 --> 03:30:36.260]   I interviewed the killers.
[03:30:36.260 --> 03:30:41.280]   One was in jail, several of them were just ranchers
[03:30:41.280 --> 03:30:45.080]   who, you know, they had their point of view.
[03:30:45.080 --> 03:30:47.980]   They were there in the Amazon rainforest to,
[03:30:47.980 --> 03:30:51.880]   the word in Brazil and Portuguese is limpar,
[03:30:51.880 --> 03:30:53.240]   to clean the land.
[03:30:53.240 --> 03:30:56.360]   You know, they're the bandarantes, the pioneers of Brazil.
[03:30:56.360 --> 03:30:58.680]   They go into these frontiers and tame them
[03:30:58.680 --> 03:31:01.120]   like we had in our West, you know?
[03:31:01.120 --> 03:31:03.160]   And they would bring that up too.
[03:31:03.160 --> 03:31:06.240]   They would say to me, well, you did this, you know?
[03:31:06.240 --> 03:31:08.540]   They didn't say you murdered your Native Americans
[03:31:08.540 --> 03:31:10.160]   and stuff, but they could easily have said that too,
[03:31:10.160 --> 03:31:12.720]   and you deforested all your landscapes.
[03:31:12.720 --> 03:31:14.480]   So who are you to come down here to?
[03:31:14.480 --> 03:31:16.920]   But if I didn't talk to them,
[03:31:16.920 --> 03:31:20.840]   that would be not a way to do journalism.
[03:31:20.840 --> 03:31:23.920]   But when you talk to them, did you empathize with them
[03:31:23.920 --> 03:31:26.200]   or did you push back?
[03:31:26.200 --> 03:31:28.120]   That's the ultimate question.
[03:31:28.120 --> 03:31:29.880]   Like if you want to understand,
[03:31:29.880 --> 03:31:35.240]   like if you talk to Hitler in 1941,
[03:31:35.240 --> 03:31:39.080]   you empathize with him or do you push back?
[03:31:39.080 --> 03:31:41.720]   Because most journalists would push
[03:31:41.720 --> 03:31:45.640]   because they're trying to signal to fellow journalists
[03:31:45.640 --> 03:31:48.600]   and to people back home that this,
[03:31:48.600 --> 03:31:50.800]   me, the journalist is on the right side.
[03:31:50.800 --> 03:31:54.800]   But if you actually want to understand the person,
[03:31:54.800 --> 03:31:56.080]   you should empathize.
[03:31:56.080 --> 03:31:59.400]   If you want to be the kind of person
[03:31:59.400 --> 03:32:04.400]   that actually understands in the full arc of history,
[03:32:04.400 --> 03:32:07.120]   you need to empathize.
[03:32:07.120 --> 03:32:10.280]   I find that journalists, a lot of times,
[03:32:10.280 --> 03:32:12.380]   perhaps they're protecting their job,
[03:32:12.380 --> 03:32:14.680]   their reputation, their sanity,
[03:32:14.680 --> 03:32:16.600]   are not willing to empathize.
[03:32:16.600 --> 03:32:18.440]   - Yeah, I think this happened with Joe Manchin.
[03:32:18.440 --> 03:32:20.360]   I'm not doing any kind of equation here
[03:32:20.360 --> 03:32:22.080]   related to Hitler and Joe Manchin.
[03:32:22.080 --> 03:32:23.440]   Or Trump, I mean Trump.
[03:32:23.440 --> 03:32:25.480]   I interviewed the guy, Will Hepper, I mentioned,
[03:32:25.480 --> 03:32:27.400]   who was a physicist at Princeton
[03:32:27.400 --> 03:32:29.840]   who thinks carbon dioxide is the greatest thing
[03:32:29.840 --> 03:32:32.680]   in the world and we should have more of it in the atmosphere.
[03:32:32.680 --> 03:32:35.680]   I profoundly disagree on that point.
[03:32:35.680 --> 03:32:37.680]   But I interviewed him for an hour
[03:32:37.680 --> 03:32:40.700]   and it was so interesting
[03:32:40.700 --> 03:32:43.360]   because he was trying to kind of rope-a-dope me
[03:32:43.360 --> 03:32:47.880]   into making it about CO2 and climate
[03:32:47.880 --> 03:32:51.520]   'cause he's a super smart physicist.
[03:32:51.520 --> 03:32:55.700]   And I kind of said, "Let's talk about some other things."
[03:32:55.700 --> 03:32:57.040]   And we started talking about education
[03:32:57.040 --> 03:32:57.960]   and science education.
[03:32:57.960 --> 03:32:59.720]   He went on for like 20 minutes
[03:32:59.720 --> 03:33:03.660]   about the vital importance of better science education
[03:33:03.660 --> 03:33:04.720]   for Americans.
[03:33:04.720 --> 03:33:08.520]   He drew on people he knew from Europe, Hungary.
[03:33:08.520 --> 03:33:11.640]   Bunch of Nobel Prize winners came from some town in Hungary,
[03:33:11.640 --> 03:33:12.980]   at least a couple.
[03:33:12.980 --> 03:33:15.140]   And he said that he learned their teachers.
[03:33:15.140 --> 03:33:18.320]   At any rate, he went at a long exposition on that.
[03:33:18.320 --> 03:33:20.820]   He then defended climate science.
[03:33:20.820 --> 03:33:22.220]   He said, "We need more climate science."
[03:33:22.220 --> 03:33:23.180]   He says, "I love this stuff.
[03:33:23.180 --> 03:33:24.960]   "I love the ocean buoys."
[03:33:24.960 --> 03:33:26.560]   There are now thousands of them in the oceans
[03:33:26.560 --> 03:33:30.940]   charting clear pictures of ocean circulation and satellites.
[03:33:30.940 --> 03:33:32.320]   And he said something really important
[03:33:32.320 --> 03:33:33.680]   that many people discount,
[03:33:33.680 --> 03:33:36.000]   which is we need sustained investment
[03:33:36.000 --> 03:33:37.440]   in monitoring this planet.
[03:33:37.440 --> 03:33:41.240]   We neglect our systems
[03:33:41.240 --> 03:33:44.440]   that just tell us what's happening in the world.
[03:33:44.440 --> 03:33:47.120]   And that's happened over and over again.
[03:33:47.120 --> 03:33:48.520]   So if I had left it,
[03:33:48.520 --> 03:33:53.520]   if I had gone into the terrain of the fight over CO2,
[03:33:53.520 --> 03:33:55.760]   some journalist friends might say,
[03:33:55.760 --> 03:33:59.840]   "Oh, that was a good mashup, you know, matchup."
[03:33:59.840 --> 03:34:02.680]   But I found these really profound and important things
[03:34:02.680 --> 03:34:05.200]   that I wanted the world to know about
[03:34:05.200 --> 03:34:06.440]   in the context of whether Trump
[03:34:06.440 --> 03:34:08.960]   was gonna have him as a science advisor.
[03:34:08.960 --> 03:34:11.640]   And so if I hadn't gone there,
[03:34:11.640 --> 03:34:13.480]   and a lot of people, if you look back,
[03:34:13.480 --> 03:34:18.000]   I got hammered for doing that, even from friends.
[03:34:18.000 --> 03:34:21.560]   And then later, John Holdren,
[03:34:21.560 --> 03:34:24.340]   who had been Obama's science advisor for eight years,
[03:34:24.340 --> 03:34:29.080]   he said, "I would rather have Will Happer
[03:34:29.080 --> 03:34:32.840]   "as Trump's science advisor than no science advisor."
[03:34:32.840 --> 03:34:34.280]   In other words, there's a landscape
[03:34:34.280 --> 03:34:35.200]   of things that are important.
[03:34:35.200 --> 03:34:37.740]   He recognized that Happer's really smart about defense
[03:34:37.740 --> 03:34:39.040]   and all kinds of things too.
[03:34:39.040 --> 03:34:42.400]   So it's like you do have to sort of screw up your,
[03:34:42.400 --> 03:34:44.680]   ideally, you screw up your courage,
[03:34:44.680 --> 03:34:47.760]   but then not necessarily get into the,
[03:34:47.760 --> 03:34:49.520]   it's like with the guy in Oklahoma.
[03:34:49.520 --> 03:34:53.640]   If you go in looking for the differences, you'll find them.
[03:34:53.640 --> 03:34:54.840]   You can amplify them.
[03:34:54.840 --> 03:34:59.240]   You can leave with this paralyzed sense
[03:34:59.240 --> 03:35:02.720]   of nothing having happened that was useful.
[03:35:02.720 --> 03:35:04.720]   Or you can find these nuggets.
[03:35:04.720 --> 03:35:06.940]   Everyone is a human being.
[03:35:06.940 --> 03:35:08.760]   I can't play the mind game
[03:35:08.760 --> 03:35:11.360]   of what I would have asked to Hitler.
[03:35:11.360 --> 03:35:14.480]   But-- - I play that mind game
[03:35:14.480 --> 03:35:16.720]   all the time, but that's for another conversation.
[03:35:16.720 --> 03:35:19.680]   - Yeah, yeah. - I had many in my family
[03:35:19.680 --> 03:35:22.880]   that have suffered under him.
[03:35:22.880 --> 03:35:25.260]   Nevertheless, he is a human being.
[03:35:25.260 --> 03:35:28.320]   - Yeah. - And people sometimes
[03:35:28.320 --> 03:35:31.040]   caricature Hitler saying like,
[03:35:31.040 --> 03:35:32.280]   that's when you mentioned Hitler,
[03:35:32.280 --> 03:35:34.080]   the conversation devolves. - Oh, right,
[03:35:34.080 --> 03:35:35.240]   you've got a certain point.
[03:35:35.240 --> 03:35:37.000]   - But I don't agree.
[03:35:37.000 --> 03:35:38.560]   I think sort of these extremes
[03:35:38.560 --> 03:35:40.760]   are useful thought experiments to understand.
[03:35:40.760 --> 03:35:43.160]   Because if you're not willing to take your ideals
[03:35:43.160 --> 03:35:47.480]   to that extreme, then maybe your ideals
[03:35:47.480 --> 03:35:51.000]   need some rethinking from a journalist's perspective,
[03:35:51.000 --> 03:35:52.400]   all that kind of stuff.
[03:35:52.400 --> 03:35:53.720]   - A number of years ago, my wife and I
[03:35:53.720 --> 03:35:56.920]   were with our veterinarian who was German born,
[03:35:56.920 --> 03:35:59.360]   Dr. Bach, B-A-C-H.
[03:35:59.360 --> 03:36:00.560]   We were talking about the dog and stuff,
[03:36:00.560 --> 03:36:02.800]   and then we were talking about Trump.
[03:36:02.800 --> 03:36:03.960]   And he just mentioned in passing,
[03:36:03.960 --> 03:36:05.860]   he said, "My mother voted for Hitler."
[03:36:05.860 --> 03:36:09.040]   Wow, that hit me like a brick.
[03:36:09.040 --> 03:36:09.880]   - Yeah.
[03:36:09.880 --> 03:36:13.400]   - Because it was so, at the very least,
[03:36:13.400 --> 03:36:17.000]   understanding how pathways that lead to
[03:36:17.000 --> 03:36:21.480]   people doing things like he did in "Ordered"
[03:36:21.480 --> 03:36:23.980]   is essential, and the only way to understand that
[03:36:23.980 --> 03:36:28.980]   is to dig in and ask questions and get uncomfortable.
[03:36:28.980 --> 03:36:30.120]   It still makes my hair prickle
[03:36:30.120 --> 03:36:32.040]   when I think back to him saying,
[03:36:32.040 --> 03:36:33.800]   yeah, my mom voted for Hitler.
[03:36:33.800 --> 03:36:35.240]   - That somehow makes it super real.
[03:36:35.240 --> 03:36:37.080]   Like, oh, yeah. - Yeah, wow.
[03:36:37.080 --> 03:36:39.600]   - Yeah, there's elections, there's real people
[03:36:39.600 --> 03:36:40.880]   living their lives.
[03:36:40.880 --> 03:36:43.240]   - Exactly, struggling with a broken economy
[03:36:43.240 --> 03:36:44.800]   and all kinds of things.
[03:36:44.800 --> 03:36:48.120]   - Having their own little personal resentments
[03:36:48.120 --> 03:36:49.840]   and all that kind of stuff.
[03:36:49.840 --> 03:36:52.480]   Let me ask you about presidents, American presidents.
[03:36:52.480 --> 03:36:58.640]   Who had a positive or negative impact
[03:36:58.640 --> 03:37:01.280]   on climate change efforts in your view?
[03:37:01.280 --> 03:37:03.800]   Clinton, Bush, Obama, Trump, Biden,
[03:37:03.800 --> 03:37:06.120]   or maybe you could say that they don't have much of an impact.
[03:37:06.120 --> 03:37:09.200]   So, like, they, in public discourse,
[03:37:09.200 --> 03:37:14.200]   presidents have a kind of, maybe, disproportional,
[03:37:14.200 --> 03:37:18.080]   like, we imagine they have a huge amount of impact.
[03:37:18.080 --> 03:37:23.020]   How much impact do they actually have on climate policy?
[03:37:23.020 --> 03:37:25.760]   I don't know if you have comments on this.
[03:37:25.760 --> 03:37:29.040]   - Well, there is a background decarbonization rate
[03:37:29.040 --> 03:37:30.920]   that's happened for 150 years.
[03:37:30.920 --> 03:37:34.640]   You know, we move from wood to charcoal
[03:37:34.640 --> 03:37:38.480]   to coal to oil and gas is cleaner,
[03:37:38.480 --> 03:37:40.360]   it's more hydrogen, less carbon.
[03:37:40.360 --> 03:37:44.680]   And I asked recently, I asked some really smart scientists
[03:37:44.680 --> 03:37:47.760]   who study these long trajectories of energy.
[03:37:47.760 --> 03:37:48.840]   When you look at those curves,
[03:37:48.840 --> 03:37:50.520]   is there anything in that curve that says,
[03:37:50.520 --> 03:37:53.000]   oh, climate treaty, 1992?
[03:37:53.000 --> 03:37:55.800]   Oh, Paris?
[03:37:55.800 --> 03:37:58.040]   And it's really hard.
[03:37:58.040 --> 03:38:00.160]   Or China, I mean, when China came in
[03:38:00.160 --> 03:38:03.400]   with its huge growth in emissions,
[03:38:03.400 --> 03:38:07.160]   that created a bit of a recarbonization blip,
[03:38:07.160 --> 03:38:08.920]   but that was this huge growth in their economy.
[03:38:08.920 --> 03:38:11.520]   They pulled a bunch of people out of poverty.
[03:38:11.520 --> 03:38:15.040]   So, yeah, no, presidents don't really change anything.
[03:38:15.040 --> 03:38:17.440]   On timescales that we would measure,
[03:38:17.440 --> 03:38:19.640]   as meaning where you could parse it out,
[03:38:19.640 --> 03:38:23.560]   I think that's not to say that Obama's
[03:38:23.560 --> 03:38:27.960]   and the current focus on the stimulus that's happening,
[03:38:27.960 --> 03:38:29.840]   which includes a lot more money for research,
[03:38:29.840 --> 03:38:31.420]   et cetera, and innovation.
[03:38:32.400 --> 03:38:35.760]   I do think that will be beneficial in a very, very long run.
[03:38:35.760 --> 03:38:38.680]   But I have to say, when Obama stood up
[03:38:38.680 --> 03:38:42.920]   and took credit for reductions
[03:38:42.920 --> 03:38:46.020]   from moving from coal to gas because of fracking,
[03:38:46.020 --> 03:38:49.760]   that was actually Cheney who set that in motion.
[03:38:49.760 --> 03:38:51.840]   - I was thinking, I would say Bush,
[03:38:51.840 --> 03:38:53.200]   not because I like him or anything,
[03:38:53.200 --> 03:38:57.400]   but he's the guy who inadvertently started fracking.
[03:38:57.400 --> 03:38:58.520]   - It goes further back than that.
[03:38:58.520 --> 03:39:00.000]   It was a federal investment in fracking
[03:39:00.000 --> 03:39:01.040]   in the '60s and '70s,
[03:39:01.040 --> 03:39:03.920]   and then this one guy in Texas, right here in Texas,
[03:39:03.920 --> 03:39:08.360]   George Mischel, who cobbled together technology,
[03:39:08.360 --> 03:39:13.360]   and that led to this real dramatic change from gas to coal
[03:39:13.360 --> 03:39:16.160]   that mostly played out in the Obama years,
[03:39:16.160 --> 03:39:17.440]   but that really was stimulated
[03:39:17.440 --> 03:39:20.720]   by Cheney's early energy task force,
[03:39:20.720 --> 03:39:23.560]   2001, when they were getting into office.
[03:39:23.560 --> 03:39:25.640]   And also, Bush did something interesting
[03:39:25.640 --> 03:39:30.840]   in the whole wonky climate treaty process.
[03:39:30.840 --> 03:39:34.020]   It was under Bush that they started to focus on sectors.
[03:39:34.020 --> 03:39:37.960]   Oh, and also on big emitters.
[03:39:37.960 --> 03:39:40.400]   This isn't about 200 countries.
[03:39:40.400 --> 03:39:43.320]   It's about basically eight or 10 countries.
[03:39:43.320 --> 03:39:44.660]   Let's get them into a room,
[03:39:44.660 --> 03:39:47.040]   and let's have these little subrooms
[03:39:47.040 --> 03:39:52.040]   on electrification, on mining, on whatever,
[03:39:52.040 --> 03:39:54.120]   and by parsing it out,
[03:39:54.120 --> 03:39:55.760]   and Obama picked up the same model.
[03:39:55.760 --> 03:39:56.960]   They had different names for it
[03:39:56.960 --> 03:39:58.920]   because presidents always name something different
[03:39:58.920 --> 03:40:00.480]   than the last president.
[03:40:00.480 --> 03:40:02.160]   One was the major economies forum,
[03:40:02.160 --> 03:40:05.820]   and then it was the major emitters, something or other,
[03:40:05.820 --> 03:40:09.480]   and that getting away from the treaty dots and dashes
[03:40:09.480 --> 03:40:13.960]   toward just sectoral, big sectors that matter,
[03:40:13.960 --> 03:40:17.760]   gas, electrification, makes a difference.
[03:40:17.760 --> 03:40:20.100]   But again, you couldn't ever measure.
[03:40:20.100 --> 03:40:22.960]   It's always the lag time would be a problem.
[03:40:22.960 --> 03:40:27.840]   - And also, I think one very under-reported fact,
[03:40:27.840 --> 03:40:30.400]   so the UNEP, the Environment Program,
[03:40:30.400 --> 03:40:34.920]   they come out with what they call a gap report every year
[03:40:34.920 --> 03:40:37.360]   where they estimate how much is the world doing
[03:40:37.360 --> 03:40:40.320]   compared to what should it or has it promised to do.
[03:40:40.320 --> 03:40:41.440]   - Emissions.
[03:40:41.440 --> 03:40:45.960]   - Yeah, and in 2019, so just before COVID hit,
[03:40:45.960 --> 03:40:49.240]   they actually did a survey of the 2010s,
[03:40:49.240 --> 03:40:52.800]   so the last big sort of report on how well are we doing,
[03:40:52.800 --> 03:40:54.320]   and their takeaway quote,
[03:40:54.320 --> 03:40:55.720]   and I'm not gonna get this right,
[03:40:55.720 --> 03:40:57.800]   but it's pretty much what they said was,
[03:40:57.800 --> 03:41:01.560]   "If you take the world as if we hadn't cared
[03:41:01.560 --> 03:41:04.900]   "about climate change since 2005,
[03:41:04.900 --> 03:41:09.000]   "we can't tell the difference between that world
[03:41:09.000 --> 03:41:11.680]   "and the world that we're actually living in."
[03:41:11.680 --> 03:41:14.120]   So despite the fact that we've had 10 years
[03:41:14.120 --> 03:41:18.760]   of immense focus on climate, and everybody talks about it,
[03:41:18.760 --> 03:41:19.920]   and the Paris Agreement,
[03:41:19.920 --> 03:41:22.920]   which is perhaps the biggest global sort of agreement
[03:41:22.920 --> 03:41:25.960]   on what we're gonna be doing, you can't actually tell,
[03:41:25.960 --> 03:41:29.480]   and that I think is incredibly important
[03:41:29.480 --> 03:41:31.960]   because what it tells you is all that we're doing
[03:41:31.960 --> 03:41:35.240]   is not even on the margin, it's sort of smaller than that,
[03:41:35.240 --> 03:41:36.720]   and I'm not sure what that is,
[03:41:36.720 --> 03:41:39.160]   but we're basically dealing in,
[03:41:39.160 --> 03:41:41.120]   for instance, the UK loves to point out
[03:41:41.120 --> 03:41:43.600]   that they have dramatically reduced their carbon emissions,
[03:41:43.600 --> 03:41:46.040]   and they have, they've really dramatically
[03:41:46.040 --> 03:41:47.400]   lowered their emissions,
[03:41:47.400 --> 03:41:50.100]   but mostly because they've de-industrialized.
[03:41:50.100 --> 03:41:52.600]   They basically said, "Look, we're just gonna be bankers
[03:41:52.600 --> 03:41:53.440]   "for all of you guys,
[03:41:53.440 --> 03:41:56.360]   "and then everybody else is gonna produce our stuff,"
[03:41:56.360 --> 03:41:58.200]   which of course is great for Britain,
[03:41:58.200 --> 03:41:59.800]   or I don't know if it's great for Britain,
[03:41:59.800 --> 03:42:02.320]   but we can't all do that,
[03:42:02.320 --> 03:42:05.600]   and so most of what we're trying to do right now
[03:42:05.600 --> 03:42:10.040]   is sort of this virtue signaling, it makes us feel good,
[03:42:10.040 --> 03:42:11.840]   it's sort of, yeah, on the margin,
[03:42:11.840 --> 03:42:14.680]   or in the very tiny margin, but what we basically,
[03:42:14.680 --> 03:42:17.520]   and that was, Andy, your point with China,
[03:42:17.520 --> 03:42:19.260]   and the reason why we can't tell the difference,
[03:42:19.260 --> 03:42:21.080]   of course, is because China basically
[03:42:21.080 --> 03:42:22.920]   became the workshop for everyone,
[03:42:22.920 --> 03:42:25.440]   and so not only did they lift
[03:42:25.440 --> 03:42:27.480]   more than half a million people out of poverty,
[03:42:27.480 --> 03:42:29.360]   sorry, half a billion, yes,
[03:42:29.360 --> 03:42:31.200]   half a billion people out of poverty,
[03:42:31.200 --> 03:42:34.200]   but they also basically took over
[03:42:34.200 --> 03:42:36.120]   most production in the world,
[03:42:36.120 --> 03:42:40.720]   and so of course, many rich countries could decarbonize,
[03:42:40.720 --> 03:42:42.600]   or at least reduce their carbon emissions
[03:42:42.600 --> 03:42:44.200]   and feel very virtuous about it,
[03:42:44.200 --> 03:42:45.920]   but fundamentally, we haven't solved
[03:42:45.920 --> 03:42:48.000]   how does the world do this,
[03:42:48.000 --> 03:42:50.600]   and that's why I think we're also left with this sense
[03:42:50.600 --> 03:42:52.200]   of not only are we being told
[03:42:52.200 --> 03:42:54.920]   this is an unmitigated catastrophe,
[03:42:54.920 --> 03:42:56.360]   and that's why this is the only thing
[03:42:56.360 --> 03:42:58.480]   we should be focusing on, but also somehow,
[03:42:58.480 --> 03:43:02.040]   and we can all fix it, and I don't think we have any sense
[03:43:02.040 --> 03:43:04.200]   of how hard this is actually gonna be,
[03:43:04.200 --> 03:43:06.240]   and that's, of course, why I would go back and say,
[03:43:06.240 --> 03:43:07.920]   look, the only way you're gonna fix this
[03:43:07.920 --> 03:43:09.920]   is through innovation, because if you have something
[03:43:09.920 --> 03:43:12.280]   that's cheaper than fossil fuels, you've fixed it.
[03:43:12.280 --> 03:43:16.040]   If you have something that's harder and costlier
[03:43:16.040 --> 03:43:19.720]   and more inconvenient, no, you're just not gonna make it.
[03:43:19.720 --> 03:43:23.400]   - And getting more time by cutting vulnerability.
[03:43:23.400 --> 03:43:24.220]   - Yes.
[03:43:24.220 --> 03:43:26.240]   - The pockets of vulnerability on the planet are huge,
[03:43:26.240 --> 03:43:28.280]   and they're identifiable, and you know what to do.
[03:43:28.280 --> 03:43:30.600]   - What are the biggest pockets of vulnerability?
[03:43:30.600 --> 03:43:32.600]   - Well, they're like-- - Infrastructure of cities?
[03:43:32.600 --> 03:43:33.960]   - No, it's where people are living
[03:43:33.960 --> 03:43:36.120]   and what their capacities are.
[03:43:36.120 --> 03:43:38.800]   - So moving people, how do you decrease
[03:43:38.800 --> 03:43:40.240]   the vulnerability in the world?
[03:43:40.240 --> 03:43:42.080]   What are the big-- - Affordable housing.
[03:43:42.080 --> 03:43:45.120]   One reason so many people moved out of San Francisco
[03:43:45.120 --> 03:43:47.560]   and adjacent cities into the countryside
[03:43:47.560 --> 03:43:50.000]   and then had their houses burned down
[03:43:50.000 --> 03:43:52.960]   is because they can't afford to live in the city anymore.
[03:43:52.960 --> 03:43:57.200]   So affordable housing in cities can limit exposure to,
[03:43:57.200 --> 03:43:58.720]   in that case, wildfire.
[03:43:58.720 --> 03:44:01.700]   Durban, South Africa, that terrible, devastating flood
[03:44:01.700 --> 03:44:05.480]   they had this year, past year, who was washed away?
[03:44:05.480 --> 03:44:07.480]   Poor people who don't have any place to live,
[03:44:07.480 --> 03:44:11.840]   so they settle in a floodplain along a stream bed
[03:44:11.840 --> 03:44:15.360]   that's livable when it's not raining buckets.
[03:44:15.360 --> 03:44:17.840]   And those are vulnerabilities that are there
[03:44:17.840 --> 03:44:21.080]   because of dislocation, housing.
[03:44:21.080 --> 03:44:24.800]   Tacloban, this typhoon that hit the Philippines terribly,
[03:44:24.800 --> 03:44:27.000]   ahead of the Paris talks, or was it the previous one?
[03:44:27.000 --> 03:44:29.520]   - No, it was in 2013, I believe.
[03:44:29.520 --> 03:44:31.880]   - Yeah, yeah, yeah, thousands died.
[03:44:31.880 --> 03:44:34.320]   Most of the stories that were written
[03:44:34.320 --> 03:44:35.760]   were framed around climate change
[03:44:35.760 --> 03:44:37.480]   because the Pope made a deal about it.
[03:44:37.480 --> 03:44:39.980]   It was just before the climate talks of that year.
[03:44:41.320 --> 03:44:45.400]   And what happened, partially why there were so many losses,
[03:44:45.400 --> 03:44:49.760]   was Tacloban City had quadrupled in population
[03:44:49.760 --> 03:44:50.680]   in the last 30 years,
[03:44:50.680 --> 03:44:52.320]   and most of the people coming into the city
[03:44:52.320 --> 03:44:53.600]   were poor, looking for work,
[03:44:53.600 --> 03:44:55.720]   and settling in marginal places
[03:44:55.720 --> 03:44:58.160]   where a storm surge killed them.
[03:44:58.160 --> 03:44:59.840]   So those are things we,
[03:44:59.840 --> 03:45:03.940]   whatever the we is in the different places,
[03:45:03.940 --> 03:45:07.040]   really can work on, and that gives more flex for sure,
[03:45:07.040 --> 03:45:09.800]   and thinking about having this long trajectory
[03:45:09.800 --> 03:45:11.520]   that seems so immovable and so hard,
[03:45:11.520 --> 03:45:15.000]   the decarbonization part, there's no excuse.
[03:45:15.000 --> 03:45:18.200]   I wrote a piece, I guess a year ago.
[03:45:18.200 --> 03:45:20.060]   I said there's a vulnerability emergency
[03:45:20.060 --> 03:45:24.760]   hiding behind this climate emergency label.
[03:45:24.760 --> 03:45:27.480]   That's really what needs work.
[03:45:27.480 --> 03:45:28.920]   - And also on the Tacloban,
[03:45:28.920 --> 03:45:32.240]   I mean, the hurricane that hit in 2013,
[03:45:32.240 --> 03:45:34.160]   there was almost a similar hurricane
[03:45:34.160 --> 03:45:37.640]   in the early part of the 1900s
[03:45:37.640 --> 03:45:40.800]   that hit pretty much the same strength,
[03:45:40.800 --> 03:45:42.480]   and it eradicated half the city.
[03:45:42.480 --> 03:45:44.440]   It killed half the city.
[03:45:44.440 --> 03:45:45.800]   And so what's happened since then
[03:45:45.800 --> 03:45:48.720]   is people just got much, much richer
[03:45:48.720 --> 03:45:52.000]   from early 1900 to 2013.
[03:45:52.000 --> 03:45:54.360]   We've just moved a lot of people out of poverty.
[03:45:54.360 --> 03:45:55.200]   Now it's a lot bigger.
[03:45:55.200 --> 03:45:56.920]   - And Bangladesh.
[03:45:56.920 --> 03:45:58.560]   Bangladesh is even a bigger example of that.
[03:45:58.560 --> 03:46:01.280]   In the 1970s, they had horrible cyclones,
[03:46:01.280 --> 03:46:02.720]   one of which was the Beatles,
[03:46:02.720 --> 03:46:04.920]   George Harrison's Concert for Bangladesh,
[03:46:04.920 --> 03:46:08.120]   great album that I still have somewhere.
[03:46:08.120 --> 03:46:10.200]   - What's the album? - Hundreds of thousands.
[03:46:10.200 --> 03:46:12.200]   He did a concert, a fundraising concert,
[03:46:12.200 --> 03:46:13.400]   the Concert for Bangladesh
[03:46:13.400 --> 03:46:16.680]   after this terrible cyclone tragedy hit Bangladesh,
[03:46:16.680 --> 03:46:18.560]   and I think there were several hundred thousand
[03:46:18.560 --> 03:46:22.320]   who were killed, and a couple like that around that time.
[03:46:22.320 --> 03:46:25.520]   Bangladesh has been hit by comparable storms recently,
[03:46:25.520 --> 03:46:27.440]   and it's terrible, every death is terrible,
[03:46:27.440 --> 03:46:29.200]   but it's like 123 deaths.
[03:46:29.200 --> 03:46:31.600]   And it's not just 'cause of wealth,
[03:46:31.600 --> 03:46:33.520]   it's 'cause people know what to do.
[03:46:33.520 --> 03:46:35.080]   It's because there's cell phones.
[03:46:35.080 --> 03:46:37.400]   It's because they have elevated platforms
[03:46:37.400 --> 03:46:40.600]   in many communities in the floodplains there
[03:46:40.600 --> 03:46:41.920]   that you know to get to.
[03:46:41.920 --> 03:46:44.720]   So they went from hundreds of thousands of deaths
[03:46:44.720 --> 03:46:47.400]   in a cyclone to 123.
[03:46:47.400 --> 03:46:49.320]   - When we were working with Bangladesh,
[03:46:49.320 --> 03:46:52.200]   it's no longer the problem of people dying,
[03:46:52.200 --> 03:46:53.920]   it's the fact that their cattle dies.
[03:46:53.920 --> 03:46:57.560]   So they want cattle places where you could herd your cattle.
[03:46:57.560 --> 03:47:00.240]   This is their capital, and it's not to make fun of it,
[03:47:00.240 --> 03:47:01.800]   but it's an amazing progress
[03:47:01.800 --> 03:47:04.720]   that you've stopped worrying about your parents dying
[03:47:04.720 --> 03:47:06.240]   and you worry about your cows dying.
[03:47:06.240 --> 03:47:08.000]   - And when I was talking about social innovation,
[03:47:08.000 --> 03:47:10.760]   the other hour, there's a model emerging in Bangladesh
[03:47:10.760 --> 03:47:14.640]   for farmers to move from raising chickens, poultry, to ducks.
[03:47:14.640 --> 03:47:17.280]   And it's working.
[03:47:17.280 --> 03:47:19.920]   And ducks actually fetch a higher price at the market.
[03:47:19.920 --> 03:47:20.760]   And guess what?
[03:47:20.760 --> 03:47:22.960]   When you get flooded-- - They survive.
[03:47:22.960 --> 03:47:25.440]   - You can still have your income and your future.
[03:47:25.440 --> 03:47:30.600]   - Let me ask you to give advice.
[03:47:30.600 --> 03:47:35.520]   Put on your sage, wise hat, and give advice to young people
[03:47:35.520 --> 03:47:38.880]   that are looking into this world
[03:47:38.880 --> 03:47:40.560]   and see how they can do the most good.
[03:47:40.560 --> 03:47:44.040]   We talked about what is the $1
[03:47:44.040 --> 03:47:47.280]   that can do the most positive improvement
[03:47:47.280 --> 03:47:51.640]   to lead to $40, $45, and so on.
[03:47:51.640 --> 03:47:53.600]   What advice would you give to young people
[03:47:53.600 --> 03:47:56.120]   in high school and college
[03:47:56.120 --> 03:47:58.880]   how to have a positive impact on the world?
[03:47:58.880 --> 03:48:01.240]   How to have a career they can be proud of?
[03:48:01.240 --> 03:48:02.440]   Maybe ask Bjorn first.
[03:48:02.440 --> 03:48:06.120]   And how to have a life they can be proud of?
[03:48:06.120 --> 03:48:09.040]   - So I think, and this really pretty well reflects
[03:48:09.040 --> 03:48:10.720]   the whole conversation we've had,
[03:48:10.720 --> 03:48:14.400]   we've gotta sort of take the catastrophism
[03:48:14.400 --> 03:48:17.840]   out of the climate conversation.
[03:48:17.840 --> 03:48:21.080]   And this really matters because a lot of kids
[03:48:21.080 --> 03:48:24.280]   literally think that the world is gonna end pretty soon.
[03:48:24.280 --> 03:48:27.120]   And that obviously makes any other kind of plan
[03:48:27.960 --> 03:48:29.920]   meaningless.
[03:48:29.920 --> 03:48:32.720]   So first of all, look, you're not gonna die.
[03:48:32.720 --> 03:48:36.960]   That poster that people, a lot of kids have,
[03:48:36.960 --> 03:48:38.280]   you're gonna die from old age,
[03:48:38.280 --> 03:48:39.480]   but I'm gonna die from climate.
[03:48:39.480 --> 03:48:40.760]   No, you're not.
[03:48:40.760 --> 03:48:42.120]   You're gonna die from old age
[03:48:42.120 --> 03:48:45.120]   and you're gonna die much older, very likely.
[03:48:45.120 --> 03:48:49.800]   So the reality is the world has improved dramatically
[03:48:49.800 --> 03:48:52.040]   and it's very likely to improve even more.
[03:48:52.040 --> 03:48:54.560]   So the baseline is good.
[03:48:54.560 --> 03:48:56.480]   This is just the facts.
[03:48:56.480 --> 03:49:00.440]   Then there's still lots and lots of problems.
[03:49:00.440 --> 03:49:02.760]   And what you should do as a young person is
[03:49:02.760 --> 03:49:06.120]   stop being paralyzed by fear
[03:49:06.120 --> 03:49:08.240]   and then realize what you can do
[03:49:08.240 --> 03:49:12.280]   is basically help humanity become even smarter.
[03:49:12.280 --> 03:49:14.400]   There's a lot of different places you can do.
[03:49:14.400 --> 03:49:15.520]   I mean, the obvious thing
[03:49:15.520 --> 03:49:17.280]   when you're talking about climate is
[03:49:17.280 --> 03:49:19.080]   what if you could become the guy
[03:49:19.080 --> 03:49:21.920]   that develops fourth generation nuclear?
[03:49:21.920 --> 03:49:23.800]   It's very likely it's something that
[03:49:23.800 --> 03:49:26.080]   neither of us know anything about right now,
[03:49:26.080 --> 03:49:28.320]   but develop the energy source
[03:49:28.320 --> 03:49:30.360]   that'll basically power the rest of humanity.
[03:49:30.360 --> 03:49:32.080]   How cool would that be?
[03:49:32.080 --> 03:49:34.200]   That's one of the many things you could do.
[03:49:34.200 --> 03:49:36.920]   But again, also remember there are lots and lots
[03:49:36.920 --> 03:49:39.360]   of other things that need solutions.
[03:49:39.360 --> 03:49:42.680]   So what about you become the guy that makes the,
[03:49:42.680 --> 03:49:46.120]   or the girl that makes the social innovation
[03:49:46.120 --> 03:49:50.160]   in Tanzania or in Kenya, sorry, in Kenya?
[03:49:50.160 --> 03:49:53.920]   Or what about if you become the person who finds a way
[03:49:53.920 --> 03:49:56.640]   that is a much cheaper, more effective way
[03:49:56.640 --> 03:49:58.520]   to tackle tuberculosis right now,
[03:49:58.520 --> 03:50:00.840]   it needs four to six months of medication.
[03:50:00.840 --> 03:50:02.400]   That one of the big problems is
[03:50:02.400 --> 03:50:04.800]   once you pop the pills and you're fresh,
[03:50:04.800 --> 03:50:06.320]   it's really hard to get people to do it
[03:50:06.320 --> 03:50:08.280]   for the other five and a half months, right?
[03:50:08.280 --> 03:50:09.760]   And you need that,
[03:50:09.760 --> 03:50:11.800]   otherwise you actually have a big risk
[03:50:11.800 --> 03:50:15.920]   of getting a multi-drug resistant tuberculosis,
[03:50:15.920 --> 03:50:18.200]   which is a real scourge on the earth.
[03:50:18.200 --> 03:50:20.760]   So, what if you develop that?
[03:50:20.760 --> 03:50:24.720]   So the truth is, not only can your life be much better
[03:50:24.720 --> 03:50:28.240]   when you sort of ditch that doomerism,
[03:50:28.240 --> 03:50:30.160]   but it also becomes much more possible
[03:50:30.160 --> 03:50:33.040]   for you to be a positive part of making sure
[03:50:33.040 --> 03:50:34.280]   that you do that progress.
[03:50:34.280 --> 03:50:36.440]   Why has the world improved so much?
[03:50:36.440 --> 03:50:39.560]   Because our parents and great grandparents,
[03:50:39.560 --> 03:50:41.240]   they made all this work.
[03:50:41.240 --> 03:50:44.560]   This was all their innovations and a lot of hard work.
[03:50:44.560 --> 03:50:47.240]   And I'm incredibly grateful that they've done it.
[03:50:47.240 --> 03:50:49.280]   But now it's kind of time to pay back.
[03:50:49.280 --> 03:50:53.360]   So, you got to do this for our grandkids.
[03:50:53.360 --> 03:50:55.200]   You got to make those innovations,
[03:50:55.200 --> 03:50:57.800]   make those policy opportunities
[03:50:57.800 --> 03:51:00.960]   that'll make the world an even better place.
[03:51:00.960 --> 03:51:01.800]   - Totally.
[03:51:01.800 --> 03:51:06.040]   And to me, there's never been a better time
[03:51:06.040 --> 03:51:08.440]   to be effective as a young person
[03:51:08.440 --> 03:51:11.640]   'cause the internet, connectedness.
[03:51:11.640 --> 03:51:15.160]   You can brainstorm with someone in another country
[03:51:15.160 --> 03:51:16.480]   just as easily as you can brainstorm
[03:51:16.480 --> 03:51:19.240]   with someone down the block when we were kids.
[03:51:19.240 --> 03:51:24.000]   As I said earlier, my pen pal was letters taking weeks.
[03:51:24.000 --> 03:51:29.640]   And so the key properties, ideally,
[03:51:29.640 --> 03:51:34.640]   that young people would do well to cultivate are,
[03:51:34.640 --> 03:51:39.800]   well, certainly adaptability because change is changing.
[03:51:39.800 --> 03:51:42.520]   Not just, you know, the rate of change is changing.
[03:51:42.520 --> 03:51:45.280]   These layers of change are all piling up on each other.
[03:51:46.280 --> 03:51:49.520]   Having an ability to understand
[03:51:49.520 --> 03:51:53.240]   the information environment is a fundamental need now
[03:51:53.240 --> 03:51:55.400]   that wasn't a need when we were growing up.
[03:51:55.400 --> 03:51:56.760]   We read a few newspapers.
[03:51:56.760 --> 03:51:58.920]   My dad would turn on the nightly news
[03:51:58.920 --> 03:52:01.880]   and Walter Cronkite would say, "That's the way it is."
[03:52:01.880 --> 03:52:03.840]   I'd say, "That's the way it is."
[03:52:03.840 --> 03:52:07.600]   And that's so not the way the media environment is now.
[03:52:07.600 --> 03:52:10.120]   So courses in media literacy should be kind of
[03:52:10.120 --> 03:52:14.240]   fundamental parts of curriculum from like kindergarten on
[03:52:14.240 --> 03:52:16.320]   or parents can do the same thing.
[03:52:16.320 --> 03:52:18.480]   There's a woman at URI, University of Rhode Island,
[03:52:18.480 --> 03:52:21.380]   Renee Hobbs, who teaches a course in propaganda literacy.
[03:52:21.380 --> 03:52:26.140]   And she said, you know, the history of the word is not bad.
[03:52:26.140 --> 03:52:27.280]   Propaganda could be good.
[03:52:27.280 --> 03:52:30.440]   It's pro, it's for the church.
[03:52:30.440 --> 03:52:32.560]   She did a wonderful chat with me.
[03:52:32.560 --> 03:52:34.120]   She laid this out.
[03:52:34.120 --> 03:52:37.040]   But understanding when it is propaganda,
[03:52:37.040 --> 03:52:38.760]   like the tobacco, you know,
[03:52:38.760 --> 03:52:42.760]   there is hopefully a difference between that and that,
[03:52:42.760 --> 03:52:47.760]   but cigarette ads and journalistically acquired information.
[03:52:47.760 --> 03:52:51.320]   So key to everything Bjorn was talking about too
[03:52:51.320 --> 03:52:54.040]   is just understanding how to not be sucked
[03:52:54.040 --> 03:52:55.520]   into this information environment
[03:52:55.520 --> 03:53:00.280]   and spit out as a paralyzed, doomist entity.
[03:53:00.280 --> 03:53:03.540]   Because once you have an ability to step back,
[03:53:03.540 --> 03:53:07.360]   then you can use Twitter or whatever you're on
[03:53:07.360 --> 03:53:10.120]   to find people who might have a skillset you don't have
[03:53:10.120 --> 03:53:14.200]   that is something you need to do to incorporate,
[03:53:14.200 --> 03:53:17.680]   to harness, to do the thing you want to do in the world.
[03:53:17.680 --> 03:53:19.680]   Finding your way to make the world better.
[03:53:19.680 --> 03:53:21.760]   And it can have nothing to do with climate,
[03:53:21.760 --> 03:53:24.120]   but if it makes a few more people's lives better,
[03:53:24.120 --> 03:53:26.480]   then overall you're leading toward better capacity
[03:53:26.480 --> 03:53:27.480]   for all this stuff.
[03:53:27.480 --> 03:53:29.120]   So that, and then the climate problem,
[03:53:29.120 --> 03:53:31.160]   the prismatic giant nature of it
[03:53:31.160 --> 03:53:35.240]   is what makes it so daunting,
[03:53:35.240 --> 03:53:37.880]   but it's also what gives everybody an opportunity.
[03:53:37.880 --> 03:53:41.000]   Like there's something for artists, scientists, poets,
[03:53:41.000 --> 03:53:43.800]   everybody needs to get in the game.
[03:53:43.800 --> 03:53:46.320]   I just spent some time with Kim Stanley Robinson
[03:53:46.320 --> 03:53:47.800]   who wrote that book, "Ministry of the Future,"
[03:53:47.800 --> 03:53:52.200]   which is this sprawling novel about a worst case outcome
[03:53:52.200 --> 03:53:53.840]   where everyone in India is dying.
[03:53:53.840 --> 03:54:00.680]   So fiction can help experiment,
[03:54:00.680 --> 03:54:02.680]   different kinds of fiction, different kinds of arts
[03:54:02.680 --> 03:54:04.480]   can help us sort of experiment
[03:54:04.480 --> 03:54:06.240]   with what the future might look like in different ways.
[03:54:06.240 --> 03:54:08.040]   And just get started.
[03:54:08.040 --> 03:54:10.480]   And the other thing, unfortunately, that's needed,
[03:54:10.480 --> 03:54:13.960]   I think I first said this in 2008
[03:54:13.960 --> 03:54:15.720]   when someone asked me something about climate.
[03:54:15.720 --> 03:54:19.360]   I said, "Weirdly, you have to sort of have a sense
[03:54:19.360 --> 03:54:22.560]   "of urgency, but a sense of patience at the same time."
[03:54:22.560 --> 03:54:24.480]   Like, just roll those words around in your mind.
[03:54:24.480 --> 03:54:25.600]   Like, what does that mean?
[03:54:25.600 --> 03:54:27.960]   Urgent and patient, how could that possibly be?
[03:54:27.960 --> 03:54:32.440]   But actually it really is the reality.
[03:54:32.440 --> 03:54:34.600]   There is an urgency with this building gas
[03:54:34.600 --> 03:54:37.000]   that's cumulative, that doesn't go away like smoke
[03:54:37.000 --> 03:54:39.160]   when it rains.
[03:54:39.160 --> 03:54:42.960]   And every year that happens, it's adding to risk.
[03:54:42.960 --> 03:54:46.340]   And you can kind of wake up completely freaked out urgent,
[03:54:46.340 --> 03:54:49.200]   but when you realize energy transitions take time,
[03:54:49.200 --> 03:54:50.800]   then you have to sort of find patience
[03:54:50.800 --> 03:54:53.360]   or whatever your word is for that.
[03:54:53.360 --> 03:54:55.320]   - Yeah, I think you have to oscillate back and forth
[03:54:55.320 --> 03:54:57.880]   throughout the day, having a sense of urgency
[03:54:57.880 --> 03:55:02.040]   when you're trying to actually be productive and patient
[03:55:02.040 --> 03:55:03.760]   so you can have a calm head about you
[03:55:03.760 --> 03:55:06.520]   in terms of putting everything into perspective.
[03:55:06.520 --> 03:55:10.380]   And like you said, with information, that is interesting,
[03:55:10.380 --> 03:55:11.800]   especially in the scientific community.
[03:55:11.800 --> 03:55:13.800]   I think you've spoken about this before.
[03:55:13.800 --> 03:55:16.600]   That there is some responsibility,
[03:55:16.600 --> 03:55:19.280]   or at least an opportunity for scientists
[03:55:19.280 --> 03:55:22.180]   to not just do science, but to understand the dynamics
[03:55:22.180 --> 03:55:25.720]   of the different mediums in which information is exchanged.
[03:55:25.720 --> 03:55:28.020]   So it could be Twitter for a few years,
[03:55:28.020 --> 03:55:31.280]   then it could be TikTok, then it could be,
[03:55:31.280 --> 03:55:33.520]   I'm a huge believer in the power of YouTube
[03:55:33.520 --> 03:55:39.000]   over the next several years, perhaps decades.
[03:55:39.000 --> 03:55:42.360]   I mean, it's a very interesting medium for education
[03:55:42.360 --> 03:55:46.640]   and communication and for debate and that's grassroots.
[03:55:46.640 --> 03:55:48.720]   That's from like the bottom up,
[03:55:48.720 --> 03:55:52.440]   that every scientist is able to communicate their work.
[03:55:52.440 --> 03:55:55.040]   And I personally believe have the responsibility
[03:55:55.040 --> 03:55:56.360]   to communicate their work.
[03:55:56.360 --> 03:56:00.400]   If anything, the internet made me realize
[03:56:00.400 --> 03:56:04.720]   that science is not just about doing the science,
[03:56:04.720 --> 03:56:06.160]   it's about communicating it.
[03:56:06.160 --> 03:56:11.440]   Like this is not some kind of virtue signaling on my part.
[03:56:11.440 --> 03:56:12.280]   - No, no, no.
[03:56:12.280 --> 03:56:15.760]   - No, like I feel like if the tree falls in the forest
[03:56:15.760 --> 03:56:19.440]   and nobody's around to hear it, it really didn't fall.
[03:56:19.440 --> 03:56:22.600]   Like that's not, there should be a culture of,
[03:56:22.600 --> 03:56:27.920]   well, at MIT, there's a place called the Media Lab.
[03:56:27.920 --> 03:56:28.760]   - Yes, sir.
[03:56:28.760 --> 03:56:31.160]   - Where they really emphasize,
[03:56:31.160 --> 03:56:35.040]   like you always be able to demo something,
[03:56:35.040 --> 03:56:35.960]   to show off your work.
[03:56:35.960 --> 03:56:37.760]   They really emphasize showing off their work.
[03:56:37.760 --> 03:56:41.040]   And I think that was in some part criticized
[03:56:41.040 --> 03:56:42.800]   in the bigger MIT culture that,
[03:56:42.800 --> 03:56:47.360]   that's like being focusing too much on the PR
[03:56:47.360 --> 03:56:49.000]   versus doing the science.
[03:56:49.000 --> 03:56:50.560]   But I really disagree with that.
[03:56:50.560 --> 03:56:52.560]   Of course, there's a balance to strike.
[03:56:52.560 --> 03:56:54.280]   You don't want to be all smoke and mirrors,
[03:56:54.280 --> 03:56:57.800]   but there really is a lot of value to communication
[03:56:57.800 --> 03:57:01.800]   and not just sort of some broad,
[03:57:01.800 --> 03:57:04.400]   you almost don't want to teach a course on communication
[03:57:04.400 --> 03:57:06.720]   because by the time you teach the course, it's already too late.
[03:57:06.720 --> 03:57:11.720]   It's always being on top of how, what is the language?
[03:57:11.720 --> 03:57:13.880]   What is the culture and the etiquette?
[03:57:13.880 --> 03:57:17.640]   What is the technology of communication that is effective?
[03:57:17.640 --> 03:57:18.480]   - Yeah.
[03:57:18.480 --> 03:57:20.680]   - I actually had a big conversation about that
[03:57:20.680 --> 03:57:22.920]   in my university because I think,
[03:57:22.920 --> 03:57:26.160]   and this is perhaps especially true for social sciences,
[03:57:26.160 --> 03:57:28.440]   but I think it's probably true for everyone,
[03:57:28.440 --> 03:57:30.880]   just simply communicating what it is that you've done
[03:57:30.880 --> 03:57:32.880]   in research makes it possible for you
[03:57:32.880 --> 03:57:35.240]   to sort of get an outsider's perspective and see,
[03:57:35.240 --> 03:57:39.040]   did I just go into an incredibly deep hole
[03:57:39.040 --> 03:57:42.120]   that just three other people really care about in the world?
[03:57:42.120 --> 03:57:44.720]   Or is this actually something that matters to the world?
[03:57:44.720 --> 03:57:47.640]   And being able to explain what it is that you've done
[03:57:47.640 --> 03:57:49.760]   to everyone else makes,
[03:57:49.760 --> 03:57:52.440]   my sort of sense is if you can't say it
[03:57:52.440 --> 03:57:54.640]   in a couple of minutes, it's probably,
[03:57:54.640 --> 03:57:56.360]   it's not necessarily true,
[03:57:56.360 --> 03:57:59.000]   but it's probably because it wasn't all that important.
[03:57:59.000 --> 03:58:03.280]   - There was a hashtag generated maybe seven years ago
[03:58:03.280 --> 03:58:06.800]   by a Caltech PhD candidate woman,
[03:58:06.800 --> 03:58:09.400]   and it was fantastic.
[03:58:09.400 --> 03:58:13.000]   The hashtag was #iamascientistbecause,
[03:58:13.000 --> 03:58:14.800]   and she posted it with a picture of herself
[03:58:14.800 --> 03:58:16.900]   with her answer, you know?
[03:58:16.900 --> 03:58:19.040]   And that, when I talk to scientists,
[03:58:19.040 --> 03:58:21.580]   or basically anybody about communicating,
[03:58:21.580 --> 03:58:26.580]   I say don't start with I am a phytologist,
[03:58:26.580 --> 03:58:30.740]   and I use a spectrophotometer to do X.
[03:58:30.740 --> 03:58:34.020]   Start with I am a scientist because
[03:58:34.020 --> 03:58:36.020]   the world is endlessly interesting,
[03:58:36.020 --> 03:58:39.340]   and I just found these salamanders,
[03:58:39.340 --> 03:58:42.660]   which are gonna vanish if we don't stop this fungus
[03:58:42.660 --> 03:58:45.300]   from coming to the United States, utterly interesting.
[03:58:45.300 --> 03:58:47.620]   And then you've got people hooked.
[03:58:47.620 --> 03:58:49.020]   But it's the motivation part,
[03:58:49.020 --> 03:58:50.700]   'cause everyone grew up as a kid,
[03:58:50.700 --> 03:58:52.260]   and a kid is basically like a scientist.
[03:58:52.260 --> 03:58:53.300]   Wow, what the hell is this?
[03:58:53.300 --> 03:58:54.540]   How does this work?
[03:58:54.540 --> 03:58:56.820]   So you can connect with people that way.
[03:58:56.820 --> 03:58:59.460]   But this other issue you broached is really important,
[03:58:59.460 --> 03:59:01.980]   and what I love about MIT particularly,
[03:59:01.980 --> 03:59:04.020]   I spent a lot of time there over the decades,
[03:59:04.020 --> 03:59:06.540]   not just talking to the hurricane guy,
[03:59:06.540 --> 03:59:08.340]   Amy Smith, who has the development lab
[03:59:08.340 --> 03:59:09.540]   in the basement there somewhere.
[03:59:09.540 --> 03:59:11.620]   - Most of MIT looks like it's the basement,
[03:59:11.620 --> 03:59:14.620]   but yes, it's part of the charm.
[03:59:14.620 --> 03:59:16.500]   - But it's a usability function
[03:59:16.500 --> 03:59:18.780]   is part of a lot of that goes on there.
[03:59:18.780 --> 03:59:20.320]   It's engineering and science.
[03:59:20.320 --> 03:59:23.740]   And it reminds me, in 1997,
[03:59:23.740 --> 03:59:25.780]   these two very different scientists,
[03:59:25.780 --> 03:59:28.660]   Dan Kamin at Berkeley and Michael Dove at Yale,
[03:59:28.660 --> 03:59:32.460]   wrote a manifesto, and it was
[03:59:32.460 --> 03:59:35.120]   the virtues of mundane science.
[03:59:35.120 --> 03:59:36.180]   That's what they called it.
[03:59:36.180 --> 03:59:38.460]   It was a prod to the scientific community to,
[03:59:38.460 --> 03:59:41.020]   actually, it's about useful, utility.
[03:59:41.020 --> 03:59:44.540]   'Cause the whole arena is set up to advance your career
[03:59:44.540 --> 03:59:47.540]   through revealing new knowledge
[03:59:47.540 --> 03:59:49.180]   that will get you tenure someday.
[03:59:49.180 --> 03:59:53.980]   And actually doing useful science is disincentivized.
[03:59:53.980 --> 03:59:54.820]   Having a conversation,
[03:59:54.820 --> 03:59:58.740]   and especially if it involves more than one discipline.
[03:59:58.740 --> 04:00:00.200]   'Cause as a young scientist,
[04:00:00.200 --> 04:00:04.020]   there were some postdocs at Columbia
[04:00:04.020 --> 04:00:06.340]   wrote this other manifesto paper saying,
[04:00:06.340 --> 04:00:09.260]   "Here are the things universities need to do
[04:00:09.260 --> 04:00:11.660]   "to foster the collaborative capacity we need
[04:00:11.660 --> 04:00:14.220]   "to have sustainable development."
[04:00:14.220 --> 04:00:15.560]   And it was like four or five things
[04:00:15.560 --> 04:00:17.020]   that universities don't do.
[04:00:17.840 --> 04:00:19.960]   Give you time to become fluent.
[04:00:19.960 --> 04:00:24.960]   And for a physicist to talk to an anthropologist
[04:00:24.960 --> 04:00:28.120]   and understand how anthropology works with sociology
[04:00:28.120 --> 04:00:28.960]   takes time.
[04:00:28.960 --> 04:00:30.620]   And then building a relationship with a community
[04:00:30.620 --> 04:00:34.000]   that has a problem that you wanna fix takes time.
[04:00:34.000 --> 04:00:37.400]   And so you do these quick turnaround papers
[04:00:37.400 --> 04:00:40.400]   that get you toward your little micro career goal,
[04:00:40.400 --> 04:00:41.920]   but they're not actually getting you
[04:00:41.920 --> 04:00:43.680]   what you want in the world.
[04:00:43.680 --> 04:00:45.480]   Those are really hard problems going forward.
[04:00:45.480 --> 04:00:47.560]   But starting with that idea of usability,
[04:00:47.560 --> 04:00:49.640]   what can I do with my skill sets?
[04:00:49.640 --> 04:00:51.120]   You know, a lot of great physicists I know
[04:00:51.120 --> 04:00:53.600]   are dug in on string theory and stuff.
[04:00:53.600 --> 04:00:55.720]   And someone has to dig in on that too.
[04:00:55.720 --> 04:00:57.280]   But I'd like to have them pull a little bit
[04:00:57.280 --> 04:00:59.640]   of their brain power away to think about
[04:00:59.640 --> 04:01:02.440]   some of the practical things Bjorn thinks about too.
[04:01:02.440 --> 04:01:06.240]   - So the two of you have been thinking
[04:01:06.240 --> 04:01:08.640]   about some of the biggest questions,
[04:01:08.640 --> 04:01:11.360]   which is life here on Earth.
[04:01:11.360 --> 04:01:12.520]   The history of life here,
[04:01:12.520 --> 04:01:14.960]   the future of life here on Earth.
[04:01:14.960 --> 04:01:17.200]   Of Earth itself.
[04:01:17.200 --> 04:01:21.040]   And how to allocate our resources
[04:01:21.040 --> 04:01:23.240]   to alleviate suffering in the world.
[04:01:23.240 --> 04:01:24.920]   So let me ask the big question.
[04:01:24.920 --> 04:01:27.920]   What do you think is the why of it all?
[04:01:27.920 --> 04:01:29.280]   What's the meaning of it?
[04:01:29.280 --> 04:01:31.520]   What's the meaning of our life here on Earth?
[04:01:31.520 --> 04:01:33.840]   (laughing)
[04:01:33.840 --> 04:01:37.840]   - You waited 'til the last moment to ask us that question.
[04:01:37.840 --> 04:01:39.520]   - Yes, in case there's,
[04:01:41.320 --> 04:01:44.880]   yeah, in case I can trick you into finding an answer.
[04:01:44.880 --> 04:01:49.400]   - Well, so I mean, again, I'm just gonna take a stab
[04:01:49.400 --> 04:01:52.040]   in this because I think in some ways
[04:01:52.040 --> 04:01:55.600]   it's the same thing that you were talking about before.
[04:01:55.600 --> 04:01:58.520]   It's not about getting everybody sort of in the same track
[04:01:58.520 --> 04:02:00.440]   and all agree on something.
[04:02:00.440 --> 04:02:02.240]   But it's about getting a lot of people
[04:02:02.240 --> 04:02:05.320]   with very different goals and targets
[04:02:05.320 --> 04:02:07.520]   and ways of thinking about the world
[04:02:07.520 --> 04:02:09.480]   to go in the same direction.
[04:02:09.480 --> 04:02:14.480]   So for me, the goal of life, certainly my goal,
[04:02:14.480 --> 04:02:16.640]   but I think for most people,
[04:02:16.640 --> 04:02:18.600]   is to make the world a better place.
[04:02:18.600 --> 04:02:21.080]   It sounds incredibly pedestrian
[04:02:21.080 --> 04:02:22.760]   because it's become so overused,
[04:02:22.760 --> 04:02:25.020]   but that really and literally is the point.
[04:02:25.020 --> 04:02:28.680]   Your point of your life is to,
[04:02:28.680 --> 04:02:31.120]   when one of your friends is sad,
[04:02:31.120 --> 04:02:33.040]   to make sure that they sort of get out of that
[04:02:33.040 --> 04:02:35.080]   and find out why they're sad
[04:02:35.080 --> 04:02:37.240]   and maybe move them a little bit in the right direction.
[04:02:38.040 --> 04:02:40.680]   And all the things that we've talked about,
[04:02:40.680 --> 04:02:43.120]   stop people from dying from tuberculosis
[04:02:43.120 --> 04:02:46.120]   and live longer lives and fix climate change,
[04:02:46.120 --> 04:02:48.480]   but fix it in such a way
[04:02:48.480 --> 04:02:50.840]   that we actually use resources smartest
[04:02:50.840 --> 04:02:52.080]   because there are lots of problems.
[04:02:52.080 --> 04:02:55.960]   So let's make sure we deal with them adequately.
[04:02:55.960 --> 04:02:59.640]   This is very unsexy in some sense,
[04:02:59.640 --> 04:03:03.400]   but I think it's also very basic and really what matters.
[04:03:03.400 --> 04:03:08.400]   - Well, biologically evolution has demanded
[04:03:08.400 --> 04:03:12.800]   that life is about finding sources of energy
[04:03:12.800 --> 04:03:14.800]   and perpetuating yourself, right?
[04:03:14.800 --> 04:03:15.960]   So that's the baseline.
[04:03:15.960 --> 04:03:19.560]   And that's led us into a bit of a bollocks
[04:03:19.560 --> 04:03:22.480]   because we have this easy energy
[04:03:22.480 --> 04:03:24.280]   that's come from the ground so far,
[04:03:24.280 --> 04:03:30.640]   but our brilliance has given this larger awareness
[04:03:30.840 --> 04:03:35.320]   of everything about the planet is transitory.
[04:03:35.320 --> 04:03:39.160]   And so how do you work with that productively
[04:03:39.160 --> 04:03:41.080]   is really an important question.
[04:03:41.080 --> 04:03:44.400]   I could just sort of try to be as rich as possible
[04:03:44.400 --> 04:03:49.240]   and use as much energy as possible and have other people.
[04:03:49.240 --> 04:03:50.680]   I mean, Alex Epstein, I think, again,
[04:03:50.680 --> 04:03:52.480]   this is one of the constraints on my support
[04:03:52.480 --> 04:03:56.160]   for what he says is he's just talking about growth
[04:03:56.160 --> 04:03:58.480]   and progress in that sense,
[04:03:58.480 --> 04:04:00.320]   but there are consequences
[04:04:00.320 --> 04:04:02.080]   and there are long-term trajectories here
[04:04:02.080 --> 04:04:04.440]   that have to be taken into account too.
[04:04:04.440 --> 04:04:07.040]   So what do you wake up to do?
[04:04:07.040 --> 04:04:10.300]   To me, it's finding your part of this.
[04:04:10.300 --> 04:04:12.360]   And as Bjorn said,
[04:04:12.360 --> 04:04:16.560]   finding a way to pursue and expand betterment.
[04:04:16.560 --> 04:04:19.540]   When I taught, I was at Pace University for six years,
[04:04:19.540 --> 04:04:22.040]   and one of the courses I launched there
[04:04:22.040 --> 04:04:23.920]   was called "Blogging a Better Planet."
[04:04:23.920 --> 04:04:27.440]   And it was for grad students mostly in communication.
[04:04:27.440 --> 04:04:29.880]   It wasn't an environment, it wasn't like better planet,
[04:04:29.880 --> 04:04:31.880]   like save the climate.
[04:04:31.880 --> 04:04:33.880]   But my task for the students was to blog
[04:04:33.880 --> 04:04:36.000]   about something they're passionate about, first of all,
[04:04:36.000 --> 04:04:36.880]   'cause you can't do this,
[04:04:36.880 --> 04:04:38.640]   just like you can't do your conversations
[04:04:38.640 --> 04:04:39.680]   if you don't wake up in the morning
[04:04:39.680 --> 04:04:41.600]   wanting to do what you're doing, right?
[04:04:41.600 --> 04:04:42.720]   You're doing this.
[04:04:42.720 --> 04:04:44.480]   I used to call myself a selfish blogger
[04:04:44.480 --> 04:04:45.720]   because I was learning every day.
[04:04:45.720 --> 04:04:46.880]   I still am.
[04:04:46.880 --> 04:04:47.720]   I love this.
[04:04:47.720 --> 04:04:51.480]   My wife laughs, she thinks I work too much,
[04:04:51.480 --> 04:04:54.960]   but I'm always asking those questions, like sustain what?
[04:04:54.960 --> 04:04:59.200]   So my charge to the students was harness a passion,
[04:04:59.200 --> 04:05:02.800]   build a blog, either alone or with others,
[04:05:02.800 --> 04:05:05.400]   that notches the world a little bit
[04:05:05.400 --> 04:05:07.200]   towards some better outcome.
[04:05:07.200 --> 04:05:10.200]   And so there was a musician who did a thing on music,
[04:05:10.200 --> 04:05:12.760]   musicians who use their art for their work
[04:05:12.760 --> 04:05:14.400]   for making the world better.
[04:05:14.400 --> 04:05:16.680]   Some of it was like music therapy,
[04:05:16.680 --> 04:05:18.560]   bands contributing money, whatever.
[04:05:18.560 --> 04:05:22.020]   Another one did, her blog was on comfort food
[04:05:22.020 --> 04:05:22.920]   all around the world.
[04:05:22.920 --> 04:05:24.040]   And I thought it was my favorite.
[04:05:24.040 --> 04:05:25.200]   It was a video.
[04:05:25.200 --> 04:05:27.880]   See, I think it should be viral, actually.
[04:05:27.880 --> 04:05:30.040]   It was like looking at the world,
[04:05:30.040 --> 04:05:32.000]   every different cultures.
[04:05:32.000 --> 04:05:34.120]   She was in Queens, so every culture,
[04:05:34.120 --> 04:05:38.160]   every cuisine is there in Queens, 200 countries, right?
[04:05:38.160 --> 04:05:39.520]   But she would go and talk to people's moms
[04:05:39.520 --> 04:05:41.360]   and have them cook the food of that country
[04:05:41.360 --> 04:05:42.480]   that's their comfort food.
[04:05:42.480 --> 04:05:45.200]   I mean, I just love this 'cause we all need to eat
[04:05:45.200 --> 04:05:49.120]   and you're getting this expanded sense of what comfort is
[04:05:49.120 --> 04:05:52.120]   by thinking about what other cultures choose.
[04:05:52.120 --> 04:05:54.320]   And that felt like a great course
[04:05:54.320 --> 04:05:55.840]   'cause it was not directive.
[04:05:55.840 --> 04:05:59.320]   It was just, it gave them this potential to go forward.
[04:05:59.320 --> 04:06:02.200]   I'd love to think they've all gone on to become a superstar,
[04:06:02.200 --> 04:06:03.600]   whatever it is, I don't know.
[04:06:03.600 --> 04:06:06.360]   That's the giving, that's the letting go part.
[04:06:06.360 --> 04:06:08.680]   Even if one did something special,
[04:06:08.680 --> 04:06:10.440]   then that makes me feel job done.
[04:06:10.440 --> 04:06:15.560]   And after I'd been writing about climate for 30 years,
[04:06:15.560 --> 04:06:20.560]   2016-ish, I did a lot of writing about what did I learn,
[04:06:20.560 --> 04:06:22.240]   unlearn and stuff.
[04:06:22.240 --> 04:06:26.200]   And I had had a stroke in 2011, which was interesting.
[04:06:26.200 --> 04:06:29.140]   It was the first time I really thought about my brain.
[04:06:29.140 --> 04:06:32.880]   You don't think about your brain on a day-to-day basis,
[04:06:32.880 --> 04:06:34.760]   but this is my brain telling me,
[04:06:34.760 --> 04:06:38.000]   ding, ding, ding, ding, some weird shit's happening.
[04:06:38.000 --> 04:06:40.000]   And when I was thinking about climate
[04:06:40.000 --> 04:06:40.920]   or confronting climate change,
[04:06:40.920 --> 04:06:42.480]   it felt like some of the things I learned
[04:06:42.480 --> 04:06:45.760]   about my own existence, I'm gonna die,
[04:06:45.760 --> 04:06:48.000]   but you don't really absorb that.
[04:06:48.000 --> 04:06:49.680]   - Is that the first time you kind of faced your mortality?
[04:06:49.680 --> 04:06:51.160]   - That was like my first, like,
[04:06:51.160 --> 04:06:53.400]   yeah, this is really the shit,
[04:06:53.400 --> 04:06:55.520]   or at least deep disability, if not death,
[04:06:55.520 --> 04:06:59.800]   and that ability is transitory.
[04:06:59.800 --> 04:07:01.840]   And I thought about the climate problem.
[04:07:01.840 --> 04:07:03.760]   We're not gonna solve the global warming problem,
[04:07:03.760 --> 04:07:05.480]   at least not in our lifetimes.
[04:07:05.480 --> 04:07:10.480]   But you work on making those trajectories sustainable,
[04:07:10.480 --> 04:07:13.080]   the end of life particularly.
[04:07:13.080 --> 04:07:16.440]   You work on making sure other people don't get strokes
[04:07:16.440 --> 04:07:17.280]   if they can avoid it.
[04:07:17.280 --> 04:07:18.840]   In my case, I wrote about it.
[04:07:18.840 --> 04:07:21.800]   I was blogging about my stroke while I was having it.
[04:07:21.800 --> 04:07:22.640]   I was tweeting about it.
[04:07:22.640 --> 04:07:25.440]   There's a funny tweet that's kind of mistyped
[04:07:25.440 --> 04:07:27.480]   because things weren't working.
[04:07:27.480 --> 04:07:28.960]   - Wow, Co-PP?
[04:07:28.960 --> 04:07:31.480]   - Yeah, yeah, yeah, right, right, right.
[04:07:31.480 --> 04:07:34.400]   So that's like share your knowledge, share your learning.
[04:07:34.400 --> 04:07:37.640]   And everyone can do this now, like on whatever platform.
[04:07:37.640 --> 04:07:41.640]   And then there's also this like giving up part,
[04:07:41.640 --> 04:07:43.320]   but not in a depressing,
[04:07:43.320 --> 04:07:45.760]   well, maybe you could call it depressing.
[04:07:45.760 --> 04:07:47.920]   I started to Zoom in years ago
[04:07:47.920 --> 04:07:50.920]   on the idea of the serenity prayer, the sobriety thing.
[04:07:50.920 --> 04:07:54.120]   It's like know what you can change, know what you can't.
[04:07:54.120 --> 04:07:56.480]   - Grant me the serenity to accept the things
[04:07:56.480 --> 04:07:59.160]   that cannot change, the courage to change the things
[04:07:59.160 --> 04:08:02.520]   that can, and the wisdom to know the difference.
[04:08:02.520 --> 04:08:04.560]   - Yeah, see, those three properties
[04:08:04.560 --> 04:08:06.560]   are really important right now.
[04:08:06.560 --> 04:08:08.840]   Some aspects of this, we know absolutely
[04:08:08.840 --> 04:08:11.560]   what we can work on, cutting vulnerability.
[04:08:11.560 --> 04:08:13.560]   Energy transitions take time.
[04:08:13.560 --> 04:08:16.800]   Science can help us discriminate the difference.
[04:08:17.680 --> 04:08:21.320]   And that's an iterative changing landscape going forward.
[04:08:21.320 --> 04:08:26.440]   But at the same time, science,
[04:08:26.440 --> 04:08:28.760]   like I personally on climate modeling,
[04:08:28.760 --> 04:08:31.720]   or like narrowing how hot it's gonna get,
[04:08:31.720 --> 04:08:36.040]   or more clarity on when an ice sheet is gonna collapse.
[04:08:36.040 --> 04:08:38.080]   I think those are what I call known unknowables.
[04:08:38.080 --> 04:08:41.400]   So being able to, I've seen enough evidence
[04:08:41.400 --> 04:08:44.240]   that those are deeply complex problems
[04:08:44.240 --> 04:08:45.640]   that we're not gonna get there quickly.
[04:08:45.640 --> 04:08:47.960]   So then that gives you a landscape to act on.
[04:08:47.960 --> 04:08:51.920]   And that, whether you bring God into the mix is irrelevant.
[04:08:51.920 --> 04:08:55.160]   It's really know what you can change, know what you can't,
[04:08:55.160 --> 04:08:58.480]   and that gives you the quality to work on them.
[04:08:58.480 --> 04:09:03.200]   And serenity is comfort with that this is transitory,
[04:09:03.200 --> 04:09:08.200]   that the human journey, like anyone's individual journey,
[04:09:08.200 --> 04:09:11.520]   will have some end.
[04:09:11.520 --> 04:09:13.680]   That doesn't mean it has to be near.
[04:09:13.680 --> 04:09:15.440]   This Anthropocene that I've been writing about
[04:09:15.440 --> 04:09:20.440]   for decades can still be a good Anthropocene,
[04:09:20.440 --> 04:09:23.760]   or at least a less bad one in terms of how we get through it.
[04:09:23.760 --> 04:09:27.160]   - And you're also a musician, so in context,
[04:09:27.160 --> 04:09:30.960]   one of my favorite songs of yours, an album,
[04:09:30.960 --> 04:09:34.160]   "A Very Fine Line," I should mention that
[04:09:34.160 --> 04:09:37.280]   with the stroke coming close to death,
[04:09:37.280 --> 04:09:39.680]   the lyrics here are quite brilliant, I have to say.
[04:09:39.680 --> 04:09:40.520]   - Oh yeah.
[04:09:40.520 --> 04:09:43.920]   - It's a very fine line between winning and losing,
[04:09:43.920 --> 04:09:46.320]   a very fine line between living and dying,
[04:09:46.320 --> 04:09:48.880]   a very fine line, by the way, people should listen to this.
[04:09:48.880 --> 04:09:52.400]   I can't play this because YouTube will give me trouble.
[04:09:52.400 --> 04:09:55.540]   A very fine line between loving and leaving.
[04:09:55.540 --> 04:09:58.880]   Most of your life you spend walking a very fine line,
[04:09:58.880 --> 04:10:01.920]   and the rest of the lyrics are just quite brilliant.
[04:10:01.920 --> 04:10:03.520]   It is a fine line.
[04:10:03.520 --> 04:10:04.360]   - Yeah.
[04:10:04.360 --> 04:10:06.840]   - I'm glad you walked it with me today, gentlemen.
[04:10:06.840 --> 04:10:10.800]   You're brilliant, kind, beautiful human beings.
[04:10:10.800 --> 04:10:13.560]   Thank you so much for having this quote-unquote debate
[04:10:13.560 --> 04:10:16.840]   that was much more about just exploring ideas together.
[04:10:16.840 --> 04:10:18.720]   Bjorn, thank you so much.
[04:10:18.720 --> 04:10:21.400]   And Andy, thank you so much for talking today.
[04:10:21.400 --> 04:10:25.360]   - You know, these kinds of extended conversations
[04:10:25.360 --> 04:10:27.040]   are the more of it the better,
[04:10:27.040 --> 04:10:31.480]   and finding ways to spread that capacity
[04:10:31.480 --> 04:10:33.640]   just to get people out of this win-lose thing
[04:10:33.640 --> 04:10:35.360]   is really important, so thanks for what you're doing.
[04:10:35.360 --> 04:10:36.600]   - Yeah.
[04:10:36.600 --> 04:10:38.160]   - Thanks for listening to this conversation
[04:10:38.160 --> 04:10:40.840]   with Bjorn Lomborg and Andrew Refkin.
[04:10:40.840 --> 04:10:43.360]   To support this podcast, please check out our sponsors
[04:10:43.360 --> 04:10:44.840]   in the description.
[04:10:44.840 --> 04:10:46.960]   And now, let me leave you with some words
[04:10:46.960 --> 04:10:49.280]   from Henry David Thoreau.
[04:10:49.280 --> 04:10:54.280]   "Heaven is under our feet as well as over our heads."
[04:10:54.280 --> 04:10:57.200]   Thank you for listening, and hope to see you next time.
[04:10:57.200 --> 04:10:59.800]   (upbeat music)
[04:10:59.800 --> 04:11:02.400]   (upbeat music)
[04:11:02.400 --> 04:11:12.400]   [BLANK_AUDIO]

