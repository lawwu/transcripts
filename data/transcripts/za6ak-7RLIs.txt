
[00:00:00.000 --> 00:00:04.040]   All right, everybody, let's get started.
[00:00:04.040 --> 00:00:08.520]   So I want to just give everybody a warm welcome to the What's New with Weights and Biases.
[00:00:08.520 --> 00:00:09.520]   I'm Phil Gerbacchi.
[00:00:09.520 --> 00:00:13.160]   I lead the product team here at Weights and Biases, and I'm going to be your host for
[00:00:13.160 --> 00:00:14.580]   today's session.
[00:00:14.580 --> 00:00:19.080]   I'm just really excited about all the product innovations we have ready for you today.
[00:00:19.080 --> 00:00:22.280]   And if you're as pumped as I am, maybe show me some love in the chat.
[00:00:22.280 --> 00:00:23.280]   Let's see some comments.
[00:00:23.280 --> 00:00:27.160]   Let's see how many people are out there.
[00:00:27.160 --> 00:00:29.860]   All right.
[00:00:29.860 --> 00:00:33.280]   So we're going to have a really interactive session today.
[00:00:33.280 --> 00:00:36.200]   Please send in your questions, comments in the chat.
[00:00:36.200 --> 00:00:41.080]   We're actually going to be spending some time at the end of the session today to do a Q&A
[00:00:41.080 --> 00:00:43.120]   with all of the presenters.
[00:00:43.120 --> 00:00:44.400]   And so let's jump in.
[00:00:44.400 --> 00:00:48.640]   So anybody who's out there, send us your location.
[00:00:48.640 --> 00:00:50.200]   Where are you calling in from?
[00:00:50.200 --> 00:00:52.920]   Location, city, state, country.
[00:00:52.920 --> 00:00:57.160]   And then just so you know, we have an amazing events team that's running this webinar.
[00:00:57.160 --> 00:01:00.720]   So we're going to be sending out swag bags to people with the best comments, the best
[00:01:00.720 --> 00:01:03.960]   interactivity throughout the session.
[00:01:03.960 --> 00:01:06.240]   So send us your location.
[00:01:06.240 --> 00:01:07.720]   Let's see where everybody's from.
[00:01:07.720 --> 00:01:13.560]   I'm currently broadcasting from Rochester, New York, upstate New York in the United States.
[00:01:13.560 --> 00:01:15.400]   And just really excited to get started.
[00:01:15.400 --> 00:01:17.360]   So why don't we jump in here?
[00:01:17.360 --> 00:01:19.640]   So what's new with Weights and Biases?
[00:01:19.640 --> 00:01:22.740]   We have an amazing lineup of speakers today.
[00:01:22.740 --> 00:01:27.440]   So Stacey, deep learning engineer in our R&D team, is going to be showing you what's possible
[00:01:27.440 --> 00:01:29.160]   with Weights and Biases.
[00:01:29.160 --> 00:01:33.280]   She's going to be pushing the limits of the product and showcasing all of the latest and
[00:01:33.280 --> 00:01:36.440]   greatest innovation that we've released in the past months.
[00:01:36.440 --> 00:01:40.320]   You'll learn best practices, tips and tricks, and be able to maximize your effectiveness
[00:01:40.320 --> 00:01:42.080]   when using the product.
[00:01:42.080 --> 00:01:44.060]   Carrie is our product lead here at Weights and Biases.
[00:01:44.060 --> 00:01:49.720]   She's going to be going to showcase some brand new, never-before-seen model lifecycle management
[00:01:49.720 --> 00:01:50.860]   capabilities.
[00:01:50.860 --> 00:01:54.720]   She's also going to drop some new functionality that I'm sure is going to impress.
[00:01:54.720 --> 00:02:00.480]   Chris Van Pelt, aka CVP, is a co-founder and our chief information security officer.
[00:02:00.480 --> 00:02:04.880]   And he's going to walk us through Weights and Biases' security posture, our enterprise
[00:02:04.880 --> 00:02:07.540]   readiness, our brand new security portal.
[00:02:07.540 --> 00:02:10.240]   He's also going to be announcing some brand new enterprise offerings.
[00:02:10.240 --> 00:02:14.800]   So tune in to CVP to learn how the most highly regulated and secure organizations in the
[00:02:14.800 --> 00:02:17.960]   world are taking advantage of Weights and Biases.
[00:02:17.960 --> 00:02:20.360]   So I really can't wait to see all this great stuff.
[00:02:20.360 --> 00:02:22.920]   Hopefully you can't wait as well.
[00:02:22.920 --> 00:02:25.760]   But really what I want to do is I want to say thank you.
[00:02:25.760 --> 00:02:31.340]   The world's leading ML teams across the world, across a broad spectrum of industries, trust
[00:02:31.340 --> 00:02:35.880]   Weights and Biases to help address their ML tooling and ML ops needs.
[00:02:35.880 --> 00:02:39.840]   And so you all are pushing the limits of what's possible with machine learning.
[00:02:39.840 --> 00:02:43.400]   You're solving the most pressing problems and challenges of our time and pushing the
[00:02:43.400 --> 00:02:45.020]   human race forward.
[00:02:45.020 --> 00:02:49.680]   So I have to think, if we're like 10 years from now, we're looking back when the history
[00:02:49.680 --> 00:02:52.120]   books have been written, the stories will be about you.
[00:02:52.120 --> 00:02:56.960]   The stories about the leaders of the ML revolution that are really on the forefront of these
[00:02:56.960 --> 00:02:59.000]   technological breakthroughs.
[00:02:59.000 --> 00:03:00.000]   And so I'm really inspired.
[00:03:00.000 --> 00:03:01.800]   I'm really excited.
[00:03:01.800 --> 00:03:05.280]   And with that, I'm going to introduce you to Stacey, who's going to walk through the
[00:03:05.280 --> 00:03:07.920]   art of the possible with Weights and Biases.
[00:03:07.920 --> 00:03:08.920]   Stacey.
[00:03:08.920 --> 00:03:11.200]   Hi, thanks so much, Phil.
[00:03:11.200 --> 00:03:12.200]   Great.
[00:03:12.200 --> 00:03:13.200]   Hi, folks.
[00:03:13.200 --> 00:03:14.200]   I'm Stacey.
[00:03:14.200 --> 00:03:15.200]   I'm a deep learning engineer here.
[00:03:15.200 --> 00:03:19.600]   I'm really excited to be giving you a live demo of some of the features of Weights and
[00:03:19.600 --> 00:03:20.600]   Biases.
[00:03:20.600 --> 00:03:24.600]   And we'll hop right in with a live notebook.
[00:03:24.600 --> 00:03:29.520]   So here I have already installed WANDB and logged into my account.
[00:03:29.520 --> 00:03:34.400]   This is going to be a pretty simple convolutional neural network and PyTorch training on MNIST,
[00:03:34.400 --> 00:03:40.120]   which is a classic, let's say, data set of handwritten digits from 0 through 9.
[00:03:40.120 --> 00:03:46.360]   And I'm going to very quickly run through the code here and then explain what's happening.
[00:03:46.360 --> 00:03:51.480]   So right here, let's give our project a new name for this demo.
[00:03:51.480 --> 00:03:54.680]   Let's say choose demo 2.
[00:03:54.680 --> 00:04:01.360]   I'm going to train a baseline or an experiment.
[00:04:01.360 --> 00:04:04.640]   I'm saving some hyperparameters to WANDB here.
[00:04:04.640 --> 00:04:09.400]   It's a small network, two layer sizes, batch size, learning rate, et cetera.
[00:04:09.400 --> 00:04:13.440]   As the network is training, I'm logging the loss to Weights and Biases.
[00:04:13.440 --> 00:04:18.200]   I'm also logging a table, which you'll get to see live in a second.
[00:04:18.200 --> 00:04:23.000]   A cool trick here is that you can actually just pass in a pandas data frame directly
[00:04:23.000 --> 00:04:27.600]   to a table, and then you don't need to set up the columns or any of the fields.
[00:04:27.600 --> 00:04:29.760]   And we're also logging accuracy.
[00:04:29.760 --> 00:04:34.560]   And here we'll get a live link to the run as it's going.
[00:04:34.560 --> 00:04:36.640]   And we'll see that the loss is going down.
[00:04:36.640 --> 00:04:41.680]   The accuracy at the end of the first epoch is already pretty good because it's MNIST.
[00:04:41.680 --> 00:04:48.040]   And then if we hop into the project view, we'll get this live table from our experiment.
[00:04:48.040 --> 00:04:53.800]   In each row, you'll see the image and then the guess from the model and then the true
[00:04:53.800 --> 00:04:59.520]   label as well as the confidence scores that that image belongs to any of the other classes.
[00:04:59.520 --> 00:05:04.280]   So some things we can do here are sort and filter and group by any of these columns.
[00:05:04.280 --> 00:05:06.920]   We can see the highest scoring zeros.
[00:05:06.920 --> 00:05:08.960]   This is doing pretty well.
[00:05:08.960 --> 00:05:15.080]   But what if we want to look at specifically cases where the model is highly confident
[00:05:15.080 --> 00:05:19.040]   that it's a zero, but actually that's not the true answer?
[00:05:19.040 --> 00:05:22.880]   Here we'll see that the model thinks this is a zero, but it's actually a six.
[00:05:22.880 --> 00:05:27.040]   You can sort of see why that's happening, perhaps.
[00:05:27.040 --> 00:05:32.440]   So now that we've trained the baseline, let's go back and log a comparison run.
[00:05:32.440 --> 00:05:39.840]   And here I'm going to just do a super toy example where we're going to double some of
[00:05:39.840 --> 00:05:40.840]   the hyperparameters.
[00:05:40.840 --> 00:05:41.840]   128.
[00:05:41.840 --> 00:05:42.840]   Double the learning rate.
[00:05:42.840 --> 00:05:43.840]   Set up that config.
[00:05:43.840 --> 00:05:52.280]   I'm going to call this run our double model.
[00:05:52.280 --> 00:05:57.240]   And it's going to start turning to bits and biases and logging to the same project that
[00:05:57.240 --> 00:05:59.520]   I already have open here.
[00:05:59.520 --> 00:06:00.520]   Start to see it come in.
[00:06:00.520 --> 00:06:03.320]   Here we see the loss hopefully going down as well.
[00:06:03.320 --> 00:06:06.680]   We'll see if we get a higher accuracy or not.
[00:06:06.680 --> 00:06:15.840]   So one really cool thing we can do is change the query here to get a different view of
[00:06:15.840 --> 00:06:17.500]   our table.
[00:06:17.500 --> 00:06:23.240]   So I actually want to see the tables side by side for these two runs so I can look at
[00:06:23.240 --> 00:06:27.760]   the different predictions that my two model variants are making.
[00:06:27.760 --> 00:06:31.800]   So here I'm going to have to go in and change to a list of tables.
[00:06:31.800 --> 00:06:34.160]   I want to see two of them side by side.
[00:06:34.160 --> 00:06:36.240]   I could also make this view vertical.
[00:06:36.240 --> 00:06:38.200]   But for now I'll do one.
[00:06:38.200 --> 00:06:42.600]   And then let's hit refresh because it's actually logging a set of every epoch.
[00:06:42.600 --> 00:06:45.600]   And I want to make sure I'm looking at the same epoch.
[00:06:45.600 --> 00:06:50.360]   And here, well, it looks like my model variant is actually doing a little worse than the
[00:06:50.360 --> 00:06:51.360]   baseline.
[00:06:51.360 --> 00:06:56.400]   But we should get a side by side view of the predictions.
[00:06:56.400 --> 00:06:58.640]   Let's hit refresh one more time.
[00:06:58.640 --> 00:06:59.880]   Make sure that it's loaded in.
[00:06:59.880 --> 00:07:00.880]   Great.
[00:07:00.880 --> 00:07:01.880]   Okay.
[00:07:01.880 --> 00:07:06.440]   So here on the left we have the double model in red.
[00:07:06.440 --> 00:07:09.120]   And then on the right, that baseline in blue.
[00:07:09.120 --> 00:07:16.140]   And what I want to see is how are these models doing on true labels.
[00:07:16.140 --> 00:07:19.800]   So here we have a filter.
[00:07:19.800 --> 00:07:20.800]   I left this filter.
[00:07:20.800 --> 00:07:23.200]   I don't want to filter just for zeros anymore.
[00:07:23.200 --> 00:07:28.880]   I want to find where the true label does not equal the model's guess.
[00:07:28.880 --> 00:07:33.240]   And we'll get this view.
[00:07:33.240 --> 00:07:36.680]   So where the truth is zero, but the model was wrong.
[00:07:36.680 --> 00:07:37.840]   Here are predictions.
[00:07:37.840 --> 00:07:41.840]   It looks like the double model gets a few more wrong for some of these classes.
[00:07:41.840 --> 00:07:44.080]   And again, this is just a sample variant.
[00:07:44.080 --> 00:07:46.560]   But you can click through the actual images.
[00:07:46.560 --> 00:07:53.040]   And you can sort of see, for example, why this one was mistaken for a two.
[00:07:53.040 --> 00:07:58.640]   You can really scroll through the predictions, look at the distribution of guessed scores,
[00:07:58.640 --> 00:08:03.280]   et cetera, and compare these variants side by side.
[00:08:03.280 --> 00:08:08.240]   And this is a really quick view of what is possible with a simple test case like MNIST,
[00:08:08.240 --> 00:08:10.960]   just so you can understand the configuration here.
[00:08:10.960 --> 00:08:13.920]   But what happens if we have a more realistic project?
[00:08:13.920 --> 00:08:16.480]   So this is a semantic segmentation task.
[00:08:16.480 --> 00:08:19.680]   Here we're looking at photos of car dashboard scenes.
[00:08:19.680 --> 00:08:25.920]   And for each pixel, we want to identify if it belongs to one of 20 classes, like human,
[00:08:25.920 --> 00:08:28.800]   vehicle, building, et cetera.
[00:08:28.800 --> 00:08:33.000]   And in the left column, I have the photos.
[00:08:33.000 --> 00:08:35.000]   In the middle, the model's predictions.
[00:08:35.000 --> 00:08:36.000]   And on the right, the ground truth.
[00:08:36.000 --> 00:08:41.440]   You can see that my model thinks there's some sidewalk here and actually parses this bus
[00:08:41.440 --> 00:08:42.840]   as a truck.
[00:08:42.840 --> 00:08:45.560]   And I have a bunch of metrics for the different experiments.
[00:08:45.560 --> 00:08:51.160]   I have almost 400 different experiments here with different hyperparameter settings, encoder
[00:08:51.160 --> 00:08:54.120]   models, learning rates, et cetera.
[00:08:54.120 --> 00:08:59.360]   And I have other teammates who have their own view of this workspace.
[00:08:59.360 --> 00:09:04.600]   But what makes our collaboration really powerful is integration with artifacts and tables.
[00:09:04.600 --> 00:09:11.240]   So if we imagine a case where we have a single test data set with hidden answers for null,
[00:09:11.240 --> 00:09:16.240]   and we have a bunch of folks submitting their best semantic segmentation models and evaluating
[00:09:16.240 --> 00:09:18.560]   them on this test data set.
[00:09:18.560 --> 00:09:22.800]   So we have Ada, Bob, Charlie, et cetera, all submitting their best models.
[00:09:22.800 --> 00:09:24.640]   We can look at different metrics.
[00:09:24.640 --> 00:09:27.600]   We might want to look at false positive pixels or false negative pixels.
[00:09:27.600 --> 00:09:32.480]   We might care about false negative pixels of humans a lot more than we care about false
[00:09:32.480 --> 00:09:34.500]   positive pixels of trees.
[00:09:34.500 --> 00:09:40.080]   We can lay all of this out in this Biases workspace, comparing these models.
[00:09:40.080 --> 00:09:46.040]   And let's see which of these submissions has the highest average IOU.
[00:09:46.040 --> 00:09:47.400]   That's intersection over union.
[00:09:47.400 --> 00:09:51.280]   So that'll be highest when the segmentation masks match perfectly.
[00:09:51.280 --> 00:09:54.160]   One is perfect overlap.
[00:09:54.160 --> 00:09:56.360]   So it looks like that's Janet's model.
[00:09:56.360 --> 00:10:01.120]   And we can go here and see which table she logged.
[00:10:01.120 --> 00:10:05.120]   So we have the output artifacts results here.
[00:10:05.120 --> 00:10:08.060]   And let's click in.
[00:10:08.060 --> 00:10:13.920]   And we'll see for each image on the test set, the ground truth.
[00:10:13.920 --> 00:10:19.960]   Let's zoom into these a little bit, just so we have a larger view.
[00:10:19.960 --> 00:10:26.440]   And we can really go through and look at image by image, what the ground truth is, what Janet's
[00:10:26.440 --> 00:10:27.440]   model is predicting here.
[00:10:27.440 --> 00:10:31.800]   It looks like we do pretty well on the cars, but maybe we're missing the sidewalk here.
[00:10:31.800 --> 00:10:37.280]   We can sort, as we saw, by any of these columns, see where the false positives are highest.
[00:10:37.280 --> 00:10:39.640]   We can really dig into the details.
[00:10:39.640 --> 00:10:43.920]   We can even toggle individual classes here.
[00:10:43.920 --> 00:10:47.080]   And this is really powerful.
[00:10:47.080 --> 00:10:52.880]   What we can also do, because all of these folks also used artifacts and tables, we can
[00:10:52.880 --> 00:10:57.560]   actually compare Janet's model very precisely to, say, Bob's model.
[00:10:57.560 --> 00:11:01.240]   Again, here we'll need to switch to a list.
[00:11:01.240 --> 00:11:02.680]   And you can make it vertical.
[00:11:02.680 --> 00:11:06.200]   I think it's nice to see it side by side.
[00:11:06.200 --> 00:11:12.400]   And we can individually see on specific images how the two models do.
[00:11:12.400 --> 00:11:19.080]   We can, again, compare on any particular metric and see which images the models perform on
[00:11:19.080 --> 00:11:20.080]   the best.
[00:11:20.080 --> 00:11:21.880]   It looks like Janet's on the left here.
[00:11:21.880 --> 00:11:23.800]   It does pretty well with these trees.
[00:11:23.800 --> 00:11:26.920]   And for Bob, it's these maybe simpler images.
[00:11:26.920 --> 00:11:37.720]   We can also do things like add in a new column if we decide that we have a metric that we
[00:11:37.720 --> 00:11:38.720]   care about.
[00:11:38.720 --> 00:11:43.680]   I'm going to paste in a metric that I think might be useful.
[00:11:43.680 --> 00:11:48.440]   But the point I want to illustrate is that this can literally be any expression of things
[00:11:48.440 --> 00:11:49.440]   you've already logged.
[00:11:49.440 --> 00:11:55.000]   So here I'm looking at the ratio of false negative pixels of humans to false positive
[00:11:55.000 --> 00:11:56.960]   pixels of vegetation.
[00:11:56.960 --> 00:11:59.280]   Let's call it human to tree.
[00:11:59.280 --> 00:12:02.440]   Again, this can be anything that you've already logged to a table.
[00:12:02.440 --> 00:12:03.440]   And we've re-ranked.
[00:12:03.440 --> 00:12:09.640]   Now let's re-rank by this.
[00:12:09.640 --> 00:12:14.600]   And we'll see that for Janet's model, this ratio is much, much higher than it is for
[00:12:14.600 --> 00:12:15.600]   Bob's.
[00:12:15.600 --> 00:12:20.000]   We can start to see where the model makes mistakes.
[00:12:20.000 --> 00:12:24.920]   And here we might be interested in why one of these models is performing so much better.
[00:12:24.920 --> 00:12:32.880]   So if we go ahead and trace using artifacts the lineage and development of this model,
[00:12:32.880 --> 00:12:37.820]   we'll see that Janet's results were produced by this Weights and Biases run.
[00:12:37.820 --> 00:12:41.980]   This read in predictions and the labeled test set to generate those results.
[00:12:41.980 --> 00:12:44.240]   So let's look at the actual predictions.
[00:12:44.240 --> 00:12:46.000]   Those are generated by this run.
[00:12:46.000 --> 00:12:49.600]   And it looks like it pulled in a model that was the ResNet18v3 version.
[00:12:49.600 --> 00:12:52.680]   Oh, and it looks like that's the best version.
[00:12:52.680 --> 00:12:56.800]   And we have an IOU of 0.7 trained for 20 epochs.
[00:12:56.800 --> 00:12:57.800]   That's fantastic.
[00:12:57.800 --> 00:13:04.440]   If we do the same thing for Bob and we trace back through the artifact lineage, we'll see
[00:13:04.440 --> 00:13:09.800]   that his model pulls in ResNet18v1.
[00:13:09.800 --> 00:13:15.600]   And that version happens to only have an IOU of 0.48.
[00:13:15.600 --> 00:13:17.480]   That's the Beyond Roads model.
[00:13:17.480 --> 00:13:22.320]   And this can very easily help us trace back.
[00:13:22.320 --> 00:13:24.720]   And of course, I trained all of these models.
[00:13:24.720 --> 00:13:28.040]   So I know that they all fit together in one tree.
[00:13:28.040 --> 00:13:32.960]   But once this is set up, I don't need to think about which specific version was logged where,
[00:13:32.960 --> 00:13:34.000]   what the name of it was.
[00:13:34.000 --> 00:13:39.800]   I can do this comparison and trace this history precisely and very easily.
[00:13:39.800 --> 00:13:44.280]   One last thing I want to show you, I know both of these examples were images in tables.
[00:13:44.280 --> 00:13:49.280]   We can also do text and 3D structures and videos in tables.
[00:13:49.280 --> 00:13:51.800]   So this is popping into a different project.
[00:13:51.800 --> 00:13:57.840]   We have a reinforcement learning agent training to navigate a little grid world.
[00:13:57.840 --> 00:14:03.160]   And we want to balance the agent solving the maze with not causing too many side effects
[00:14:03.160 --> 00:14:04.640]   in this world.
[00:14:04.640 --> 00:14:10.640]   And I've used artifacts and tables to log episodes from training.
[00:14:10.640 --> 00:14:18.560]   And we have 40,000 videos in this table here.
[00:14:18.560 --> 00:14:21.360]   And as before, I can sort them by side effects.
[00:14:21.360 --> 00:14:23.000]   I can sort by reward.
[00:14:23.000 --> 00:14:26.840]   But what if I want to see a grid of these?
[00:14:26.840 --> 00:14:30.000]   So this will take a little bit, perhaps, to pull up the data.
[00:14:30.000 --> 00:14:34.240]   But we'll see increasing side effects from the video on the x-axis.
[00:14:34.240 --> 00:14:37.920]   And then I actually want to look at reward on the y-axis.
[00:14:37.920 --> 00:14:42.200]   And you'll note that I can flexibly change what is happening in these fields.
[00:14:42.200 --> 00:14:45.240]   I can also change the label.
[00:14:45.240 --> 00:14:49.960]   I want this to be whether the agent succeeds or not.
[00:14:49.960 --> 00:14:52.640]   And on my tool tip, you'll see the actual videos.
[00:14:52.640 --> 00:14:57.880]   So now I should get a scatter plot of all 40,000 episodes.
[00:14:57.880 --> 00:15:02.740]   And the dark blue ones here are cases where the agent succeeded.
[00:15:02.740 --> 00:15:06.720]   You can hover over them to see the details of the video.
[00:15:06.720 --> 00:15:13.080]   And I can start to use this flexible querying to figure out how I actually want to score
[00:15:13.080 --> 00:15:14.080]   these videos.
[00:15:14.080 --> 00:15:20.640]   How I want to combine the different features to keep improving my model.
[00:15:20.640 --> 00:15:24.920]   So that's all I have time for in this section.
[00:15:24.920 --> 00:15:29.800]   There's a link to a report where you can go through in much more detail and with more
[00:15:29.800 --> 00:15:36.280]   interactive notebooks and see how you can use tables for molecules, for text, for named
[00:15:36.280 --> 00:15:42.600]   entity recognition, and also see a little bit more about some of the examples that I
[00:15:42.600 --> 00:15:44.760]   presented very briefly.
[00:15:44.760 --> 00:15:50.600]   And to wrap up, hopefully this gives you a sense of how artifacts can be used for versioned
[00:15:50.600 --> 00:15:56.440]   and reproducible workflows and how tables can be really awesome for dynamic querying
[00:15:56.440 --> 00:15:58.120]   and visualization.
[00:15:58.120 --> 00:16:03.120]   And with that, I will hand it over to Carrie for product or roadmap highlights.
[00:16:03.120 --> 00:16:05.120]   >> Thanks, Stacey.
[00:16:05.120 --> 00:16:08.440]   That was awesome.
[00:16:08.440 --> 00:16:09.440]   So hi, I'm Carrie.
[00:16:09.440 --> 00:16:11.880]   I'm the product lead at WMB.
[00:16:11.880 --> 00:16:16.800]   And today I'm going to be talking about one key piece of the larger offering that we're
[00:16:16.800 --> 00:16:18.040]   building here.
[00:16:18.040 --> 00:16:24.160]   So we're constantly hearing new requests from across different teams, different types of
[00:16:24.160 --> 00:16:25.400]   machine learning.
[00:16:25.400 --> 00:16:31.280]   And as we're building out our product, Stacey touched on artifacts, tables, experiment tracking.
[00:16:31.280 --> 00:16:35.680]   And you can see the echoes of some of the core components that she shared, like the
[00:16:35.680 --> 00:16:40.720]   charts for live visualization and the model lineage graph in what I'm about to show you,
[00:16:40.720 --> 00:16:44.200]   which is really focused around that model management experience.
[00:16:44.200 --> 00:16:49.000]   And in here, I'll give you a sneak preview of a really early demo of what we're building,
[00:16:49.000 --> 00:16:50.680]   which is the model registry.
[00:16:50.680 --> 00:16:54.200]   So what are the key user pain points that are driving us here?
[00:16:54.200 --> 00:16:57.360]   Well, first off, there's just a mess of models.
[00:16:57.360 --> 00:17:01.640]   A lot of folks we work with are dealing with this massive, ever-growing stack of different
[00:17:01.640 --> 00:17:03.280]   model versions.
[00:17:03.280 --> 00:17:07.920]   And it's tough to compare models apples to apples when there aren't consistent evaluation
[00:17:07.920 --> 00:17:08.920]   metrics.
[00:17:08.920 --> 00:17:15.720]   So that model evaluation workflow, it really boils down to keeping track of everything
[00:17:15.720 --> 00:17:20.240]   in an organized way and being able to have standardized metrics, and then being able
[00:17:20.240 --> 00:17:23.040]   to trace that model's lineage to see where it came from.
[00:17:23.040 --> 00:17:27.400]   Right now, it can be really tough to see what was upstream from a given trained model, what
[00:17:27.400 --> 00:17:30.800]   was the exact data set or the code that trained it.
[00:17:30.800 --> 00:17:35.120]   And it's also not always clear with some of the folks we work with when a model moves
[00:17:35.120 --> 00:17:36.440]   into production.
[00:17:36.440 --> 00:17:42.200]   So tracking that movement through the system is sometimes really frustrating.
[00:17:42.200 --> 00:17:47.520]   And so we break down the model evaluation cycle into these five steps.
[00:17:47.520 --> 00:17:51.600]   What does this look like in a well-oiled machine, a team that's working really efficiently?
[00:17:51.600 --> 00:17:56.120]   Well, they start with training a new model and then evaluating it on a golden set.
[00:17:56.120 --> 00:18:02.520]   So having a clear comparison between the newest candidate and previous models.
[00:18:02.520 --> 00:18:06.800]   And then comparing that model with the model that's in production, potentially over a larger
[00:18:06.800 --> 00:18:08.440]   data set.
[00:18:08.440 --> 00:18:12.300]   And then once they have a better candidate, deploying that into production and reporting
[00:18:12.300 --> 00:18:14.900]   back to the rest of the team on their progress.
[00:18:14.900 --> 00:18:19.560]   And so in those steps, I see kind of three main themes.
[00:18:19.560 --> 00:18:22.360]   Versioning, keeping track of all that mess.
[00:18:22.360 --> 00:18:25.760]   Lineage, getting back to what trained model.
[00:18:25.760 --> 00:18:28.880]   And lifecycle, how's the model move through the system?
[00:18:28.880 --> 00:18:31.440]   So what does that look like in WMB?
[00:18:31.440 --> 00:18:37.480]   Well, in a lot of our customers' use cases, there's just a ton of ways you can train the
[00:18:37.480 --> 00:18:38.480]   model.
[00:18:38.480 --> 00:18:40.120]   That could be a notebook that someone's hacking on.
[00:18:40.120 --> 00:18:43.640]   That could be like a CI/CD job that's triggered automatically.
[00:18:43.640 --> 00:18:47.960]   But ultimately, all of these jobs are producing model artifacts.
[00:18:47.960 --> 00:18:51.880]   And those are the drafts that you see up here in WMB.
[00:18:51.880 --> 00:18:55.200]   And Stacey actually touched on this with the model artifacts she was logging.
[00:18:55.200 --> 00:18:59.120]   But now the key new piece we're bringing in here with the registry is what do you do once
[00:18:59.120 --> 00:19:00.880]   you have those draft models?
[00:19:00.880 --> 00:19:06.400]   How do you curate them in a central page where you can see all of the best models that are
[00:19:06.400 --> 00:19:09.360]   candidates for production or are currently in production?
[00:19:09.360 --> 00:19:13.320]   And so that's where we get to this lineage piece here in this third column, is registering
[00:19:13.320 --> 00:19:17.100]   models and being able to see where they came from.
[00:19:17.100 --> 00:19:22.160]   And then for the lifecycle component, that's applying an alias, a label that says, hey,
[00:19:22.160 --> 00:19:26.160]   this is the model that's in production, or this is the model that's currently being staged.
[00:19:26.160 --> 00:19:31.720]   And then using that to, for example, run more evaluation jobs on a candidate model or serve
[00:19:31.720 --> 00:19:34.120]   a model in inference.
[00:19:34.120 --> 00:19:38.680]   So in terms of versioning, what does this actually look like in the code, iterating
[00:19:38.680 --> 00:19:40.920]   to get the best model for a given task?
[00:19:40.920 --> 00:19:45.520]   Well, here's a simplified version of -- I just mocked up what the code looks like.
[00:19:45.520 --> 00:19:49.240]   So you're training a model, and then you have a line to log live metrics.
[00:19:49.240 --> 00:19:52.240]   And you saw what that looks like for Stacey.
[00:19:52.240 --> 00:19:57.960]   And this new piece of logging the model as an artifact, that's what's going to enable
[00:19:57.960 --> 00:20:01.900]   this model-centric loop that we're about to walk through.
[00:20:01.900 --> 00:20:04.120]   So let's get into the UI.
[00:20:04.120 --> 00:20:06.020]   I'm starting on the team page.
[00:20:06.020 --> 00:20:10.040]   So this is a central space where I can browse all of the projects, all the different runs
[00:20:10.040 --> 00:20:12.360]   and reports that my whole team has created.
[00:20:12.360 --> 00:20:17.040]   And I can dive into one of these given projects to see more detail.
[00:20:17.040 --> 00:20:21.240]   And so you saw this with Stacey, how you can have this central dashboard with all these
[00:20:21.240 --> 00:20:22.760]   live metrics coming in.
[00:20:22.760 --> 00:20:27.560]   But how do you get to, say, a given job in this system?
[00:20:27.560 --> 00:20:31.960]   Well, you can filter down to a single job type, like model training.
[00:20:31.960 --> 00:20:36.520]   So say you're tracking dataset creation, model evaluation, model training.
[00:20:36.520 --> 00:20:40.840]   It's easy to focus the workspace on a specific job that you care about, like the model training
[00:20:40.840 --> 00:20:41.840]   job.
[00:20:41.840 --> 00:20:46.240]   And then I can sort a given column based on the metric that I care about, an evaluation
[00:20:46.240 --> 00:20:48.840]   metric that I want to optimize.
[00:20:48.840 --> 00:20:51.760]   Now what does this look like when we get into the model registry itself?
[00:20:51.760 --> 00:20:56.240]   Well, I can click through to the model page for a given run.
[00:20:56.240 --> 00:21:01.780]   So in this example, I'm looking at a specific run that's logged some promising-looking models.
[00:21:01.780 --> 00:21:06.400]   And I can sift through to see the history of that given model and previous versions
[00:21:06.400 --> 00:21:08.880]   in this central standardized UI.
[00:21:08.880 --> 00:21:13.720]   So this is talking about versioning both of runs and of models.
[00:21:13.720 --> 00:21:15.700]   And next, we'll talk about lineage.
[00:21:15.700 --> 00:21:21.500]   So how do I document and reproduce that entire pipeline of everything that happened upstream
[00:21:21.500 --> 00:21:23.800]   of the model that I trained?
[00:21:23.800 --> 00:21:27.920]   So in the model registry, I can go to the lineage tab here at the bottom.
[00:21:27.920 --> 00:21:32.920]   And I can get to see all of the jobs that happened upstream and all of the artifacts
[00:21:32.920 --> 00:21:34.960]   that fed into this model training.
[00:21:34.960 --> 00:21:39.180]   As you can see, this is a centralized UI for the model itself.
[00:21:39.180 --> 00:21:43.760]   So I can flip between model versions and see if there were changes.
[00:21:43.760 --> 00:21:48.280]   In terms of lineage, I can also click back into the run that produced the model, which
[00:21:48.280 --> 00:21:50.880]   is what I'm doing here, and look at things like metrics.
[00:21:50.880 --> 00:21:56.120]   We're also capturing everything from the git commit to the diff patch, any uncommitted
[00:21:56.120 --> 00:21:57.120]   changes.
[00:21:57.120 --> 00:22:02.220]   So all of that context that you need to understand where this model came from is easily accessible
[00:22:02.220 --> 00:22:04.400]   from inside the model registry.
[00:22:04.400 --> 00:22:08.960]   And that's why I think this system is really cool, because we already have that critical
[00:22:08.960 --> 00:22:12.920]   information about the model training process from your experiment tracking.
[00:22:12.920 --> 00:22:17.520]   And so adding on this model tracking with artifacts and having this model management
[00:22:17.520 --> 00:22:21.960]   experience really means that you have that more complete picture of the model-centric
[00:22:21.960 --> 00:22:22.960]   workflow.
[00:22:22.960 --> 00:22:25.400]   So next, I'll talk about lifecycle.
[00:22:25.400 --> 00:22:30.160]   So how do we manage the stages as a model moves from training to production?
[00:22:30.160 --> 00:22:37.200]   Well, if we look here in the single model, I can link this model version to a registered
[00:22:37.200 --> 00:22:38.200]   model.
[00:22:38.200 --> 00:22:39.200]   What does that mean?
[00:22:39.200 --> 00:22:45.920]   I'm taking a new good candidate, and I'm saying I want to promote this into the central registry.
[00:22:45.920 --> 00:22:49.120]   And so let's look at what the registry looks like itself.
[00:22:49.120 --> 00:22:54.440]   So here I've got a set of different registered models on the left-hand side.
[00:22:54.440 --> 00:22:59.640]   And this is a sneak preview, a very early look at what we're building for the model
[00:22:59.640 --> 00:23:00.640]   registry.
[00:23:00.640 --> 00:23:04.320]   And so you can see, you can browse across all of the different kind of model tasks or
[00:23:04.320 --> 00:23:06.640]   use cases that your team has.
[00:23:06.640 --> 00:23:12.080]   And then if I'm looking at a particular model use case, here where my mouse is going over
[00:23:12.080 --> 00:23:16.520]   the different model versions, I can see, for example, for this segmentation task, I have
[00:23:16.520 --> 00:23:18.920]   three different model versions here.
[00:23:18.920 --> 00:23:22.320]   And I can see which one's in staging and which one's in production.
[00:23:22.320 --> 00:23:26.600]   So tracking the progress in that lifecycle as it moves across the different stages of
[00:23:26.600 --> 00:23:28.880]   getting it out.
[00:23:28.880 --> 00:23:36.880]   I can also take the updates that I've captured in the system by tracking models and visualize
[00:23:36.880 --> 00:23:39.120]   them in a centralized report.
[00:23:39.120 --> 00:23:41.520]   So this customized view that we're seeing here.
[00:23:41.520 --> 00:23:46.560]   And what's happening in this page, I think, is really interesting because it brings together
[00:23:46.560 --> 00:23:51.500]   some of what Stacey was showing along with this new model evaluation workflow.
[00:23:51.500 --> 00:23:55.280]   So for the registry, you can easily say, hey, I have a new model in staging.
[00:23:55.280 --> 00:24:03.160]   And I'm going to test it on a set of evaluation sets, like from different locations, for example,
[00:24:03.160 --> 00:24:05.400]   if you're training a self-driving car.
[00:24:05.400 --> 00:24:08.380]   So here I've got Arizona, Oregon, California.
[00:24:08.380 --> 00:24:12.120]   And each of the models are tested on the same version of that data set.
[00:24:12.120 --> 00:24:16.120]   So the model registry makes it really easy to compare apples to apples.
[00:24:16.120 --> 00:24:20.740]   So all of the models are being evaluated on the same metrics on the same data.
[00:24:20.740 --> 00:24:25.060]   And I can easily visualize, based on different metrics that I care about, which model is
[00:24:25.060 --> 00:24:29.060]   performing the best, and then check to see which model is in staging and which is in
[00:24:29.060 --> 00:24:30.980]   production here.
[00:24:30.980 --> 00:24:34.900]   And finally, what do I do when I want to communicate this to the rest of my team?
[00:24:34.900 --> 00:24:40.860]   Well, all of this process is easily pulled into the standard WMB charts that you've seen
[00:24:40.860 --> 00:24:41.860]   before.
[00:24:41.860 --> 00:24:46.300]   So here I've just rolled down that same report to communicate progress over time of how this
[00:24:46.300 --> 00:24:51.020]   model is improving on a key metric that I'm trying to increase the value of.
[00:24:51.020 --> 00:24:56.300]   So you can see, OK, the latest model in blue there at the end didn't quite perform as well
[00:24:56.300 --> 00:24:57.780]   as the previous red one.
[00:24:57.780 --> 00:25:01.580]   And so being able to have that central page that you can describe and share to the rest
[00:25:01.580 --> 00:25:06.460]   of your team makes it easier to communicate about the progress of model development.
[00:25:06.460 --> 00:25:11.860]   And so to summarize the updates with the model management tools here and the new model registry
[00:25:11.860 --> 00:25:17.940]   that we're working on, the key for us is having the entire process be reproducible.
[00:25:17.940 --> 00:25:23.420]   So I'm alluding here to that graph down at the bottom on this slide of all of the different
[00:25:23.420 --> 00:25:27.900]   steps that it takes to get the new model trained and then evaluated.
[00:25:27.900 --> 00:25:29.700]   We also care about governance.
[00:25:29.700 --> 00:25:34.120]   So being able to have each of those steps tracked in a single central system makes it
[00:25:34.120 --> 00:25:41.820]   much easier to evaluate and audit what happened when, say, a given model was underperforming.
[00:25:41.820 --> 00:25:46.700]   Teamwork record is also just a key feature of model management for us.
[00:25:46.700 --> 00:25:50.900]   Having that single central place where everybody is logging their different model versions
[00:25:50.900 --> 00:25:57.100]   makes it a lot easier to transfer a project to someone else or to pick up a previous model
[00:25:57.100 --> 00:26:02.400]   that you haven't been working on for a while and build on top of that project.
[00:26:02.400 --> 00:26:07.860]   So having that core standard toolbox, that's really what we're building on top of with
[00:26:07.860 --> 00:26:09.620]   this model evaluation.
[00:26:09.620 --> 00:26:13.140]   And then standardization.
[00:26:13.140 --> 00:26:19.060]   I think this is one of the nicest pieces of the model management workflow is if everyone
[00:26:19.060 --> 00:26:25.160]   is using the same standardized model registry, it's really clear and obvious what status
[00:26:25.160 --> 00:26:26.740]   a given model is in.
[00:26:26.740 --> 00:26:30.740]   And so there's no slacking back and forth or sending screenshots of how did this model
[00:26:30.740 --> 00:26:32.580]   do on a given case.
[00:26:32.580 --> 00:26:35.100]   It's all in this one organized layer.
[00:26:35.100 --> 00:26:40.580]   And so if you're interested in trying the model registry as we're coming out with it,
[00:26:40.580 --> 00:26:42.780]   I would love to hear from you.
[00:26:42.780 --> 00:26:47.300]   We have this short link, wmv.me/modelregistry.
[00:26:47.300 --> 00:26:49.900]   You can hop on here to get on our wait list.
[00:26:49.900 --> 00:26:55.660]   So this will let us get a sense of what you're looking for in particular and get you into
[00:26:55.660 --> 00:26:57.820]   the early pilot program.
[00:26:57.820 --> 00:27:01.060]   So model registry is coming soon.
[00:27:01.060 --> 00:27:05.020]   And it was really fun to get to walk you through an early preview of what we're doing here
[00:27:05.020 --> 00:27:06.020]   for model management.
[00:27:06.020 --> 00:27:08.100]   So thanks so much.
[00:27:08.100 --> 00:27:14.340]   And I'll turn it over to Chris to talk about WMB for the Enterprise.
[00:27:14.340 --> 00:27:17.060]   Thanks, Keri.
[00:27:17.060 --> 00:27:23.380]   So today I'm going to talk about weights and biases and what we're doing to ensure that
[00:27:23.380 --> 00:27:30.620]   our most security conscious enterprise users are able to use our product.
[00:27:30.620 --> 00:27:36.540]   So we knew early on that security for the enterprise is table stakes.
[00:27:36.540 --> 00:27:43.260]   And I lead the security program here at Weights and Biases and wanted to share a little bit
[00:27:43.260 --> 00:27:46.340]   about what security means for us here.
[00:27:46.340 --> 00:27:52.620]   So security isn't just creating a team that says, OK, deal with security and we wash our
[00:27:52.620 --> 00:27:53.620]   hands.
[00:27:53.620 --> 00:27:56.900]   Security impacts every person in our company.
[00:27:56.900 --> 00:28:03.500]   So from the way that we onboard new employees to the way that we provision their workstations
[00:28:03.500 --> 00:28:10.740]   and our ability to kind of limit access to any core systems is at the center of our security
[00:28:10.740 --> 00:28:11.740]   program.
[00:28:11.740 --> 00:28:15.900]   And today we're announcing our new security portal.
[00:28:15.900 --> 00:28:26.100]   So now at WMB.me/security, you can find out all of the various controls and procedures
[00:28:26.100 --> 00:28:32.500]   that we put in place here at Weights and Biases to ensure that our software is as secure as
[00:28:32.500 --> 00:28:34.220]   we can make it.
[00:28:34.220 --> 00:28:38.820]   We also pursue various compliance frameworks.
[00:28:38.820 --> 00:28:43.100]   You can see here in the slide here, SOC 2 Type 2.
[00:28:43.100 --> 00:28:49.860]   We just got our second formal attestation for achieving compliance in the SOC 2 standard
[00:28:49.860 --> 00:28:57.700]   and are always looking at industry and considering further attestations as well.
[00:28:57.700 --> 00:29:01.860]   So if you care about security and want to learn more about what we're doing here at
[00:29:01.860 --> 00:29:05.620]   Weights and Biases, definitely go to the portal and you can actually request access to any
[00:29:05.620 --> 00:29:10.540]   of our documentation or attestations as well.
[00:29:10.540 --> 00:29:17.380]   We also know that often our customers are deploying into a wide variety of environments
[00:29:17.380 --> 00:29:22.860]   that have different levels of security controls in place, which is why we offer our software
[00:29:22.860 --> 00:29:27.740]   as something that can be run by the customers themselves.
[00:29:27.740 --> 00:29:33.420]   This is great in that it gets our software into the hands of more people, but it has
[00:29:33.420 --> 00:29:39.740]   a big disadvantage in that now the burden of running the software securely is on the
[00:29:39.740 --> 00:29:41.180]   customer.
[00:29:41.180 --> 00:29:42.380]   And we wanted to do better.
[00:29:42.380 --> 00:29:46.900]   We wanted to find a way where we could take all of our best in class security practices
[00:29:46.900 --> 00:29:51.060]   and actually offer them to our customers as a service.
[00:29:51.060 --> 00:29:56.940]   So with that, I'm excited to announce the Weights and Biases dedicated cloud.
[00:29:56.940 --> 00:30:02.460]   This is our attempt at having the best of both worlds, giving customers full isolation
[00:30:02.460 --> 00:30:07.940]   and strong security guarantees, while also being able to ensure that the best practices
[00:30:07.940 --> 00:30:11.980]   around how our infrastructure is deployed, how the networking is set up, and how it is
[00:30:11.980 --> 00:30:20.140]   maintained and updated is handled by the Weights and Biases engineering and SRE team.
[00:30:20.140 --> 00:30:25.940]   So Weights and Biases dedicated cloud allows you to deploy an instance of Weights and Biases
[00:30:25.940 --> 00:30:30.280]   into any cloud in any region in that cloud.
[00:30:30.280 --> 00:30:36.540]   So say you're in the EU and want to have an instance of Weights and Biases next to all
[00:30:36.540 --> 00:30:41.700]   of your compute, which happens to be in Ireland, we can spin it up in AWS Ireland.
[00:30:41.700 --> 00:30:48.460]   Or perhaps you're using GCP and you're based in South America.
[00:30:48.460 --> 00:30:49.460]   Great.
[00:30:49.460 --> 00:30:55.900]   We'll put it up in GCP South America region.
[00:30:55.900 --> 00:31:00.060]   Some highlights of the Weights and Biases dedicated cloud are as follows.
[00:31:00.060 --> 00:31:04.680]   So number one, and this is a feature I'm really excited about, is the secure storage connector.
[00:31:04.680 --> 00:31:09.500]   So what the secure storage connector allows you to do is actually keep all of your most
[00:31:09.500 --> 00:31:14.620]   sensitive data within the control of your own IT ops and security teams.
[00:31:14.620 --> 00:31:19.340]   So you can run the object storage layer, the S3 bucket, the GCS storage bucket, the Azure
[00:31:19.340 --> 00:31:24.860]   Blob store, and actually connect that to an application that our SRE team is running.
[00:31:24.860 --> 00:31:31.180]   And this allows you to assert full control and auditability over those resources.
[00:31:31.180 --> 00:31:35.180]   Of course, one of the biggest benefits of the dedicated cloud is you get our operational
[00:31:35.180 --> 00:31:36.180]   expertise.
[00:31:36.180 --> 00:31:42.100]   We have the world's experts on running this software in a way that is secure and can scale.
[00:31:42.100 --> 00:31:48.140]   And we ensure that only the minimum amount of Weights and Biases resources would ever
[00:31:48.140 --> 00:31:54.700]   have access to any of the infrastructure to perform updates or ongoing maintenance.
[00:31:54.700 --> 00:32:01.300]   We operate industry standards, security, and compliance programs to ensure that our controls
[00:32:01.300 --> 00:32:07.140]   and procedures and disaster recovery processes are in line with those standards.
[00:32:07.140 --> 00:32:09.340]   And as mentioned, you can deploy this anywhere.
[00:32:09.340 --> 00:32:12.000]   So we can go wherever you need us to go.
[00:32:12.000 --> 00:32:16.300]   Even if you have an on-premise cluster, we can deploy in a cloud region very close to
[00:32:16.300 --> 00:32:19.480]   that on-premise cluster and connect to the object storage in it.
[00:32:19.480 --> 00:32:24.760]   So you get the scalability and the benefits of the cloud while also ensuring you have
[00:32:24.760 --> 00:32:27.160]   that isolation.
[00:32:27.160 --> 00:32:32.600]   So I just wanted to touch just briefly on the high-level architecture.
[00:32:32.600 --> 00:32:34.520]   You choose the cloud and the region.
[00:32:34.520 --> 00:32:40.520]   We deploy a MySQL database, our Weights and Biases server on top of Kubernetes, a Redis
[00:32:40.520 --> 00:32:42.280]   instance for caching.
[00:32:42.280 --> 00:32:49.520]   All of this is in a completely isolated VPC with audit logging and industry standard best
[00:32:49.520 --> 00:32:52.960]   practices in terms of the security of the infrastructure.
[00:32:52.960 --> 00:32:55.880]   And then you can have us run the object storage for you.
[00:32:55.880 --> 00:33:01.880]   Or if you want to bring your own S3 bucket or on-premise object storage layer, you're
[00:33:01.880 --> 00:33:09.680]   able to connect that securely to this isolated instance and maintain auditability on your
[00:33:09.680 --> 00:33:10.680]   side.
[00:33:10.680 --> 00:33:16.440]   And we can capture all audit logs of all traffic from this storage layer.
[00:33:16.440 --> 00:33:22.800]   On the network connectivity side, we can connect to a VPC, a private link, or simply do IP
[00:33:22.800 --> 00:33:25.560]   address allow listing.
[00:33:25.560 --> 00:33:33.380]   And of course, we support single sign-on with any central identity provider, which as someone
[00:33:33.380 --> 00:33:37.840]   that is operating a security program, I also understand it's table stakes for onboarding
[00:33:37.840 --> 00:33:44.200]   and offboarding and ensuring access is restricted to only the individuals that need to have
[00:33:44.200 --> 00:33:46.760]   access.
[00:33:46.760 --> 00:33:50.280]   So this is something that we've been working on for a while and have actually piloted it
[00:33:50.280 --> 00:33:57.640]   with a handful of customers, including NVIDIA, who is a user of this dedicated cloud instance
[00:33:57.640 --> 00:33:59.080]   today.
[00:33:59.080 --> 00:34:00.520]   We're really excited about this.
[00:34:00.520 --> 00:34:06.880]   Can't wait to see what other customers can benefit from a highly secure, up-to-date,
[00:34:06.880 --> 00:34:12.640]   scalable, completely dedicated enterprise instance of Weights & Biases.
[00:34:12.640 --> 00:34:17.240]   I also wanted to call out that this is available on all of the cloud marketplaces.
[00:34:17.240 --> 00:34:24.640]   So GCP, AWS, Azure, you can actually procure a license to a dedicated Weights & Biases
[00:34:24.640 --> 00:34:31.480]   cloud instance through these marketplaces, which we found makes the process of actually
[00:34:31.480 --> 00:34:33.800]   buying the software a lot easier.
[00:34:33.800 --> 00:34:38.440]   And it can piggyback on a lot of the advantages of any of these ecosystems.
[00:34:38.440 --> 00:34:44.640]   So you could use your cloud credits that you've accrued for various commit levels to actually
[00:34:44.640 --> 00:34:47.700]   procure software like WMB.
[00:34:47.700 --> 00:34:51.000]   So we're super excited about that as well.
[00:34:51.000 --> 00:34:56.320]   If you are interested in having a dedicated instance of Weights & Biases that is fully
[00:34:56.320 --> 00:35:03.360]   managed and will scale to your use cases, go ahead and go to WMB.me/enterprise.
[00:35:03.360 --> 00:35:04.360]   Reach out to us.
[00:35:04.360 --> 00:35:10.840]   We'd love to set up a trial and have you kick the tires and work with your IT and SecOps
[00:35:10.840 --> 00:35:16.800]   teams to ensure that we deliver the most secure, best experience software that we can.
[00:35:16.800 --> 00:35:22.240]   And with that, I'm going to hand it back to Phil to close this out.
[00:35:22.240 --> 00:35:23.240]   Thanks CVP.
[00:35:23.240 --> 00:35:25.240]   I mean, that was just awesome.
[00:35:25.240 --> 00:35:30.120]   Yeah, hopefully everybody is really excited about everything that's coming out.
[00:35:30.120 --> 00:35:35.760]   Stacey just showed you the art of the possible with the product, tips and tricks, and really
[00:35:35.760 --> 00:35:40.880]   deep dive into how to really maximize performance with Weights & Biases.
[00:35:40.880 --> 00:35:44.880]   Carrie just introduced the brand new model registry and model lifecycle management that's
[00:35:44.880 --> 00:35:50.480]   really been inspired by hundreds and hundreds of our users that are doing this every day.
[00:35:50.480 --> 00:35:54.680]   And so we've learned quite a bit from you all as you've been using the product and really
[00:35:54.680 --> 00:35:58.960]   building this for the workflows and the feedback that you're providing.
[00:35:58.960 --> 00:36:03.880]   CVP just went through our hardened security practice and brand new dedicated cloud.
[00:36:03.880 --> 00:36:08.900]   We're going to have a what's new blog post, updated documentation and some technical content
[00:36:08.900 --> 00:36:10.420]   that we're making available as well.
[00:36:10.420 --> 00:36:15.420]   So if you didn't get the information during this, you can review that afterwards.
[00:36:15.420 --> 00:36:18.920]   We're going to transition over to the Q&A portion.
[00:36:18.920 --> 00:36:23.720]   And so just as a reminder, best questions and interactivity are going to get some of
[00:36:23.720 --> 00:36:24.720]   the swag back.
[00:36:24.720 --> 00:36:28.160]   So feel free to send in your questions and comments.
[00:36:28.160 --> 00:36:32.680]   I'm going to invite all the speakers back on stage and we're going to actually answer
[00:36:32.680 --> 00:36:37.040]   your questions live when you go ahead and send those in.
[00:36:37.040 --> 00:36:41.460]   The other thing that I'll note, please sign up for the model registry early access.
[00:36:41.460 --> 00:36:47.800]   So if you want to be one of the first to try out the new capability, you can sign up and
[00:36:47.800 --> 00:36:50.760]   get access first and foremost.
[00:36:50.760 --> 00:36:51.760]   All right.
[00:36:51.760 --> 00:36:56.420]   So switching over to Q&A, a bunch of awesome questions that came in.
[00:36:56.420 --> 00:36:59.440]   The first question is actually for Kerry.
[00:36:59.440 --> 00:37:04.240]   So Kerry, amazing that we introduced a brand new model registry.
[00:37:04.240 --> 00:37:07.440]   When do we expect general availability of this model registry to come out?
[00:37:07.440 --> 00:37:08.440]   >> Hey, Phil.
[00:37:08.440 --> 00:37:09.440]   Sure.
[00:37:09.440 --> 00:37:11.800]   Yeah, awesome to hear people are excited.
[00:37:11.800 --> 00:37:14.240]   So we're actively working on this right now.
[00:37:14.240 --> 00:37:19.920]   And yeah, if you want to get on the wait list, I can pop that link back up here.
[00:37:19.920 --> 00:37:27.680]   But yes, targeting next quarter or so, trying to get this new model registry piece out as
[00:37:27.680 --> 00:37:29.920]   soon as possible.
[00:37:29.920 --> 00:37:30.920]   >> That's awesome.
[00:37:30.920 --> 00:37:31.920]   Yeah.
[00:37:31.920 --> 00:37:34.360]   I can't wait to see that come out at BGA.
[00:37:34.360 --> 00:37:37.240]   Stacey, the next one was for you, actually.
[00:37:37.240 --> 00:37:43.880]   So I think a lot of folks were really impressed by the breadth of the different types of data
[00:37:43.880 --> 00:37:44.880]   that we can use.
[00:37:44.880 --> 00:37:48.800]   So images, videos, reinforcement tasks.
[00:37:48.800 --> 00:37:53.800]   Maybe can you give some perspective and some best practice on how you use multimodal data
[00:37:53.800 --> 00:37:58.920]   or mixed data sets in the projects to make the best use of weights and biases?
[00:37:58.920 --> 00:38:05.120]   >> Yeah, so when you log columns to a table, for example, you could have text and images
[00:38:05.120 --> 00:38:06.120]   in a single row.
[00:38:06.120 --> 00:38:11.960]   So I would associate, you know, whatever your sentence is corresponding to an image, you
[00:38:11.960 --> 00:38:14.480]   could log that in multiple columns.
[00:38:14.480 --> 00:38:18.600]   And then you can, you know, join on ID or any particular item.
[00:38:18.600 --> 00:38:24.640]   And then you can, you know, plot any set of those columns.
[00:38:24.640 --> 00:38:28.600]   It really depends on what exactly you're trying to do with the data further.
[00:38:28.600 --> 00:38:33.400]   But we have tons of examples in the fully connected gallery to show how people use this
[00:38:33.400 --> 00:38:40.680]   for generating images from text, let's say, or generating text that describes images and
[00:38:40.680 --> 00:38:43.040]   so forth.
[00:38:43.040 --> 00:38:44.040]   >> That's fantastic.
[00:38:44.040 --> 00:38:45.040]   That's awesome.
[00:38:45.040 --> 00:38:50.160]   The next one, so Carrie, it looks like there's just a ton of interest in the model registry.
[00:38:50.160 --> 00:38:55.000]   The next one comes in, model registry looks awesome as a feedback.
[00:38:55.000 --> 00:39:00.600]   And then the question is, will there be any role-based access controls, like moving from
[00:39:00.600 --> 00:39:05.120]   a staging environment to a production environment or, you know, maybe even having some approval
[00:39:05.120 --> 00:39:09.440]   workflows as part of bringing a model from development to production?
[00:39:09.440 --> 00:39:11.120]   >> Thanks, Phil.
[00:39:11.120 --> 00:39:13.080]   Yeah, really good question.
[00:39:13.080 --> 00:39:17.960]   And you know, it's clear to us this type of, you know, core management of models is like
[00:39:17.960 --> 00:39:21.600]   a critical piece of what we're building, what we have so far.
[00:39:21.600 --> 00:39:25.160]   We haven't gotten to that next step yet.
[00:39:25.160 --> 00:39:29.120]   But we are really excited in working with people who can guide us with questions like
[00:39:29.120 --> 00:39:30.120]   this.
[00:39:30.120 --> 00:39:35.360]   So yeah, if you'd like to join that early access program, I would really love to hear
[00:39:35.360 --> 00:39:36.360]   from you.
[00:39:36.360 --> 00:39:37.360]   >> All right.
[00:39:37.360 --> 00:39:39.400]   And the next one, Carrie, is for you again.
[00:39:39.400 --> 00:39:42.000]   Again, a ton of interest in model registry.
[00:39:42.000 --> 00:39:47.240]   Question is, can our enterprise users also apply for model registry early access?
[00:39:47.240 --> 00:39:48.240]   >> Yeah.
[00:39:48.240 --> 00:39:50.320]   And, you know, we'd love to hear from you.
[00:39:50.320 --> 00:39:55.280]   I think, yeah, especially folks who have the core of experiment tracking set up are in
[00:39:55.280 --> 00:40:00.320]   a really good position to start talking about this next step of tracking models in this
[00:40:00.320 --> 00:40:01.320]   standardized way.
[00:40:01.320 --> 00:40:05.600]   So absolutely, if you're a customer already, we would love to start talking to you about
[00:40:05.600 --> 00:40:09.280]   the model registry as well.
[00:40:09.280 --> 00:40:10.280]   >> That's fantastic.
[00:40:10.280 --> 00:40:17.360]   And the next one, you know, really comes in, I think this one's actually for Carrie.
[00:40:17.360 --> 00:40:22.560]   I think you showed some of the views for artifacts and tracking the different linears across
[00:40:22.560 --> 00:40:26.160]   the various different tasks for the artifacts.
[00:40:26.160 --> 00:40:34.560]   And so the question's really around how does Weights & Biases actually track the overall
[00:40:34.560 --> 00:40:40.520]   data versioning and like the data flows, like from one version to the next, as well as the
[00:40:40.520 --> 00:40:46.640]   dependency to the next task, as well as, you know, to finally the evaluation task.
[00:40:46.640 --> 00:40:49.920]   So can you help us understand, you know, under the hood what's being tracked and what are
[00:40:49.920 --> 00:40:54.720]   the different metadata that's associated with that information?
[00:40:54.720 --> 00:40:55.720]   Carrie?
[00:40:55.720 --> 00:40:56.720]   >> Sure.
[00:40:56.720 --> 00:40:57.720]   Yeah, great question.
[00:40:57.720 --> 00:41:03.440]   So we're building this model management workflow and capturing that whole pipeline on top of
[00:41:03.440 --> 00:41:04.600]   artifacts.
[00:41:04.600 --> 00:41:09.960]   So the core concept that you're thinking here is add WMB init to each of the scripts, like
[00:41:09.960 --> 00:41:14.080]   dataset preprocessing or model training or model evaluation.
[00:41:14.080 --> 00:41:17.160]   And then for each of the inputs or outputs, that's tracked as an artifact.
[00:41:17.160 --> 00:41:20.600]   So that's just a quick line WMB log artifact.
[00:41:20.600 --> 00:41:25.600]   And so you can take each of those stages, and I've just popped the link to the docs
[00:41:25.600 --> 00:41:29.560]   here as well, so you can see that context of the core infrastructure we're building
[00:41:29.560 --> 00:41:30.720]   on top of.
[00:41:30.720 --> 00:41:36.120]   And then we have this new model management documentation that we've put together to get
[00:41:36.120 --> 00:41:41.280]   a bit more into those nitty gritty details of how everything works under the hood here.
[00:41:41.280 --> 00:41:45.640]   So if you'd like to see beyond artifacts, how we're thinking about that model management
[00:41:45.640 --> 00:41:53.680]   lifecycle, I also have this second docs link that I'm asking my colleagues to pop on the
[00:41:53.680 --> 00:41:54.680]   screen.
[00:41:54.680 --> 00:42:00.400]   So core concepts, artifacts are tracking each of those stages along the lifecycle, and that's
[00:42:00.400 --> 00:42:01.880]   what's giving you that dynamic deck.
[00:42:01.880 --> 00:42:05.040]   So you don't have to specify it up front, and it's additive.
[00:42:05.040 --> 00:42:10.160]   So if you have just the model training section instrumented, and then on top of that you
[00:42:10.160 --> 00:42:13.960]   add, say, an upstream piece for tracking datasets, that works.
[00:42:13.960 --> 00:42:18.840]   And you don't have to do everything up front to start getting that value.
[00:42:18.840 --> 00:42:19.840]   That's awesome.
[00:42:19.840 --> 00:42:22.360]   CVP, the next one's for you.
[00:42:22.360 --> 00:42:24.960]   I think it's your favorite capability.
[00:42:24.960 --> 00:42:33.800]   And so the question is, if there's an enterprise customer that has concerns around data security,
[00:42:33.800 --> 00:42:39.920]   how does the secure storage connector work with the actual dedicated cloud environment?
[00:42:39.920 --> 00:42:45.400]   Can you give us more details on how the system actually works and how it protects the customer's
[00:42:45.400 --> 00:42:49.720]   data and accesses the data where it lives?
[00:42:49.720 --> 00:42:50.720]   Sure.
[00:42:50.720 --> 00:42:56.360]   So not to get too deep in the weeds here, but I'm probably going to.
[00:42:56.360 --> 00:43:01.480]   The way that we communicate with the object storage layer is always through short-lived
[00:43:01.480 --> 00:43:03.080]   signed URLs.
[00:43:03.080 --> 00:43:08.360]   So when the Python library says, hey, I need to upload a dataset, or I need to upload a
[00:43:08.360 --> 00:43:13.600]   model, the Python library talks to a Wasted Biases server and says, hey, where should
[00:43:13.600 --> 00:43:14.600]   I upload this to?
[00:43:14.600 --> 00:43:19.800]   Give me a short-lived secure URL that lets me upload it directly to the object store
[00:43:19.800 --> 00:43:21.960]   when needed.
[00:43:21.960 --> 00:43:29.200]   So the way the secure storage connector works is that you give our AWS account or our GCP
[00:43:29.200 --> 00:43:36.160]   account permission to perform read object and write object calls in that data store,
[00:43:36.160 --> 00:43:43.120]   and we generate signed URLs that then ultimately make those read object or write object calls
[00:43:43.120 --> 00:43:44.960]   to the data store.
[00:43:44.960 --> 00:43:49.560]   So it means that our application needs access to this data store, but it also means that
[00:43:49.560 --> 00:43:52.160]   now you have full control over the data store.
[00:43:52.160 --> 00:43:57.120]   You could revoke that access at any point, but probably most importantly is you get full
[00:43:57.120 --> 00:44:01.900]   auditability into all of the calls that are made to the object store.
[00:44:01.900 --> 00:44:09.520]   So you know exactly what data has gone into the object store and what data comes out within
[00:44:09.520 --> 00:44:18.240]   your own AWS or GCS account using their native kind of cloud audit logging functionality.
[00:44:18.240 --> 00:44:19.240]   That's fantastic.
[00:44:19.240 --> 00:44:21.380]   Thanks, CBP.
[00:44:21.380 --> 00:44:23.540]   The next one is for Stacey.
[00:44:23.540 --> 00:44:29.000]   So Stacey, I think we're getting a lot of feedback that the folks on the call were just
[00:44:29.000 --> 00:44:36.320]   very impressed by your use of tables, being able to have tables side by side, the interactivity,
[00:44:36.320 --> 00:44:41.320]   the actual filtering and the various different ways that you're slicing and dicing the information.
[00:44:41.320 --> 00:44:45.380]   Maybe can you share any best practices, tips or tricks or anything you'd recommend for
[00:44:45.380 --> 00:44:50.040]   folks that are getting started, that are trying to take their tables use to the next level
[00:44:50.040 --> 00:44:55.200]   and really build on maybe the core competency that they already have?
[00:44:55.200 --> 00:44:56.200]   Stacey?
[00:44:56.200 --> 00:44:57.980]   Yeah, sure.
[00:44:57.980 --> 00:45:03.040]   So one thing that's really helpful is if you get it in a nice configuration, you can
[00:45:03.040 --> 00:45:04.040]   always save it to a report.
[00:45:04.040 --> 00:45:08.400]   And I think I forgot to demo that part because I was trying to move quickly.
[00:45:08.400 --> 00:45:14.320]   But once you've set up a table, it stays in that state from the run workspace.
[00:45:14.320 --> 00:45:17.480]   And if there's a particular view that you really like, I would recommend saving it to
[00:45:17.480 --> 00:45:18.480]   a report.
[00:45:18.480 --> 00:45:25.160]   You can always click on the three dots in the header of the column name and then edit
[00:45:25.160 --> 00:45:26.440]   an expression there.
[00:45:26.440 --> 00:45:30.980]   And that's something that I use very often.
[00:45:30.980 --> 00:45:34.840]   You can also edit those expressions in the modal and panel plot.
[00:45:34.840 --> 00:45:41.120]   That's the part that I showed when we go from a regular table to a chart.
[00:45:41.120 --> 00:45:47.340]   And you can also iteratively edit those expressions until the right thing shows up if you're really
[00:45:47.340 --> 00:45:51.240]   getting into the details of how you want that data to look.
[00:45:51.240 --> 00:45:52.800]   I really like the side by side view.
[00:45:52.800 --> 00:45:55.480]   That's .table.rows in the query.
[00:45:55.480 --> 00:46:01.120]   And also, it's a super open ended and flexible way to interact with those tables.
[00:46:01.120 --> 00:46:05.800]   So there's definitely more coming soon.
[00:46:05.800 --> 00:46:06.800]   That's fantastic.
[00:46:06.800 --> 00:46:07.800]   Thanks, Stacey.
[00:46:07.800 --> 00:46:15.320]   Another kind of follow on for, it's either maybe you or Kerry, actually, but any plans
[00:46:15.320 --> 00:46:19.000]   for like adding artifacts to the WANDB clients?
[00:46:19.000 --> 00:46:27.000]   We can easily look at output from, say, Spark jobs or other downstream processes.
[00:46:27.000 --> 00:46:31.000]   What are some of the plans for adding that to the client package?
[00:46:31.000 --> 00:46:33.000]   Interesting.
[00:46:33.000 --> 00:46:41.200]   So if I'm hearing this right, it sounds like specifically on the command line rather than
[00:46:41.200 --> 00:46:44.000]   in the script.
[00:46:44.000 --> 00:46:47.320]   So that one's fresh for me.
[00:46:47.320 --> 00:46:57.600]   For using artifacts in the SDK, we do have an existing public API and inside runs SDK
[00:46:57.600 --> 00:47:01.840]   to pull down an artifact that you've previously logged and use it in a new script.
[00:47:01.840 --> 00:47:06.240]   So say you logged a dataset version, you can pull it down in your next script to train
[00:47:06.240 --> 00:47:07.240]   a model.
[00:47:07.240 --> 00:47:14.000]   And then we also have the public API for looking across, say, if you want to do aggregate statistics
[00:47:14.000 --> 00:47:19.440]   and calculate that in a Jupyter notebook, you can use the public API to pull down high
[00:47:19.440 --> 00:47:23.600]   level information about artifacts that you've logged in a project.
[00:47:23.600 --> 00:47:28.400]   So in terms of command line interactions, we haven't actually really explored that yet.
[00:47:28.400 --> 00:47:35.080]   But artifacts are already available in Python itself.
[00:47:35.080 --> 00:47:36.080]   That's fantastic.
[00:47:36.080 --> 00:47:37.080]   Thanks, Kerry.
[00:47:37.080 --> 00:47:38.400]   Kerry, another one for you that came in.
[00:47:38.720 --> 00:47:47.200]   So folks that are maybe bandwidth constrained or they're used to having disk space constraints,
[00:47:47.200 --> 00:47:51.760]   what are the recommended best practices for logging artifacts?
[00:47:51.760 --> 00:47:53.480]   Do you log every intermediate step?
[00:47:53.480 --> 00:47:57.720]   Do you just log kind of the final model once it's been selected?
[00:47:57.720 --> 00:48:02.840]   Or what are some of the best practices around logging artifacts just from some folks that
[00:48:02.840 --> 00:48:07.040]   maybe are bandwidth conscious or disk space conscious?
[00:48:07.040 --> 00:48:10.600]   I can pop in here.
[00:48:10.600 --> 00:48:17.320]   So one thing, one big escape hatch with artifacts that we see customers using quite a bit is
[00:48:17.320 --> 00:48:19.720]   something we call artifact references.
[00:48:19.720 --> 00:48:25.240]   So if you don't want to upload the data over the internet to some object store, or if you're
[00:48:25.240 --> 00:48:28.960]   using our dedicated cloud option, maybe you don't even want to go from your on-prem data
[00:48:28.960 --> 00:48:34.200]   center to S3 in the cloud, you can create an artifact reference and actually upload
[00:48:34.200 --> 00:48:37.480]   it to a local object store.
[00:48:37.480 --> 00:48:43.960]   So as long as that object store is on your hopefully very fast network locally, then
[00:48:43.960 --> 00:48:45.520]   you won't have any of these constraints.
[00:48:45.520 --> 00:48:52.480]   I'd also say in terms of deciding how much data to upload is really going to be a case-by-case
[00:48:52.480 --> 00:48:54.280]   basis.
[00:48:54.280 --> 00:48:58.840]   In my view, the world is moving towards just log as much data as possible.
[00:48:58.840 --> 00:49:07.880]   Data is super important for everything, and it's fairly cheap to store as our hard drives
[00:49:07.880 --> 00:49:09.560]   get bigger.
[00:49:09.560 --> 00:49:15.840]   But in practice, we do start to run into consuming massive amounts of data, and a lot of that
[00:49:15.840 --> 00:49:17.720]   is inefficient and unneeded.
[00:49:17.720 --> 00:49:22.480]   So in our tool, we try to provide as much visibility as we can into what objects or
[00:49:22.480 --> 00:49:25.960]   what storage is being used.
[00:49:25.960 --> 00:49:31.920]   So we give you a nice high-level storage explorer that if you've ever had to clean up your local
[00:49:31.920 --> 00:49:37.920]   workstation because the disk was full, you can think of it as this, but at cloud scale,
[00:49:37.920 --> 00:49:41.840]   where you can see, okay, yep, this project, we were making big models and we stored all
[00:49:41.840 --> 00:49:47.240]   the checkpoints and it's taking up too much space, so let's go clean house a bit.
[00:49:47.240 --> 00:49:48.240]   That's awesome.
[00:49:48.240 --> 00:49:51.120]   In CVP, it's a natural flow.
[00:49:51.120 --> 00:49:54.500]   So maybe we'll do one more question for CVP.
[00:49:54.500 --> 00:49:59.280]   So kind of building on that, a comment you just made, somebody wrote in, like, if they're
[00:49:59.280 --> 00:50:04.280]   already sending artifacts to their S3 bucket and they're using reference artifacts to track
[00:50:04.280 --> 00:50:09.240]   that artifact, would the dedicated cloud add even more security?
[00:50:09.240 --> 00:50:11.060]   Or how does that technique work?
[00:50:11.060 --> 00:50:12.200]   Is it effectively the same way?
[00:50:12.200 --> 00:50:16.000]   Or how should our users think about kind of using dedicated cloud in that scenario if
[00:50:16.000 --> 00:50:23.040]   they're already using a reference artifact with a S3 bucket?
[00:50:23.040 --> 00:50:30.160]   Yeah, so using dedicated cloud is going to give you an additional layer of isolation.
[00:50:30.160 --> 00:50:37.920]   So in our multi-tenant cloud, all customer's data is stored on the same logical database.
[00:50:37.920 --> 00:50:42.480]   With dedicated cloud, the customer gets their own database that's completely isolated on
[00:50:42.480 --> 00:50:46.420]   its own network that only their data is living there.
[00:50:46.420 --> 00:50:51.960]   In terms of the artifact references themselves and how they differ between dedicated cloud
[00:50:51.960 --> 00:50:57.480]   and our fully hosted multi-tenant cloud, there's no difference in functionality.
[00:50:57.480 --> 00:51:02.320]   I will say, one big drawback of artifact references is we can't read the data.
[00:51:02.320 --> 00:51:04.440]   That's kind of the point of artifact references.
[00:51:04.440 --> 00:51:12.560]   So we can't display it in a table or do some of these fancy visual features with that data.
[00:51:12.560 --> 00:51:19.040]   But there are discussions internally and potential future work to be done that would unlock the
[00:51:19.040 --> 00:51:27.040]   ability to actually federate authentication to the user to actually view that data.
[00:51:27.040 --> 00:51:32.760]   And I would imagine if we do implement this, which I'm not saying we are, it would probably
[00:51:32.760 --> 00:51:38.360]   be piloted on the dedicated cloud first and then introduced into the shared multi-tenant
[00:51:38.360 --> 00:51:39.360]   environment.
[00:51:39.360 --> 00:51:40.360]   That's awesome.
[00:51:40.360 --> 00:51:41.800]   All right.
[00:51:41.800 --> 00:51:46.680]   So for those folks that have questions that maybe you didn't ask or that we didn't get
[00:51:46.680 --> 00:51:50.720]   to, contact@wandb.com, send in your questions.
[00:51:50.720 --> 00:51:54.280]   We'll be happy to answer them.
[00:51:54.280 --> 00:51:56.000]   And we'll be sure to get right back to you.
[00:51:56.000 --> 00:51:59.200]   I'll just say thank you, thank you, thank you so much for joining.
[00:51:59.200 --> 00:52:00.200]   This has been amazing.
[00:52:00.200 --> 00:52:05.880]   Again, Stacey went through art of the possible, as a power user, tips and tricks, pushing
[00:52:05.880 --> 00:52:10.520]   the envelope, Cary launched the brand new model registry, model lifecycle management.
[00:52:10.520 --> 00:52:14.920]   Again, be sure to check out the blog post and take a look at the model registry early
[00:52:14.920 --> 00:52:20.460]   access and then CVP, thanks for everything that you do around security best practices
[00:52:20.460 --> 00:52:22.040]   and the brand new dedicated cloud.
[00:52:22.040 --> 00:52:26.960]   I really think that's going to be super meaningful, especially for our customers that are pushing
[00:52:26.960 --> 00:52:31.760]   like just the leading edge in terms of security compliance and regulation.
[00:52:31.760 --> 00:52:33.640]   So thanks again, everybody.
[00:52:33.640 --> 00:52:35.840]   Have a good rest of your day and we appreciate your time.

