
[00:00:00.000 --> 00:00:03.760]   The following is a conversation with Anne Julian,
[00:00:03.760 --> 00:00:07.020]   writer, producer, director, and one of the most important
[00:00:07.020 --> 00:00:10.340]   and impactful communicators of science in our time.
[00:00:10.340 --> 00:00:14.360]   She co-wrote the 1980 science documentary series, "Cosmos,"
[00:00:14.360 --> 00:00:19.180]   hosted by Carl Sagan, whom she married in 1981,
[00:00:19.180 --> 00:00:22.500]   and her love for whom, with the help of NASA,
[00:00:22.500 --> 00:00:25.780]   was recorded as brainwaves on a golden record,
[00:00:25.780 --> 00:00:28.780]   along with other things our civilization has to offer,
[00:00:28.780 --> 00:00:31.460]   and launched into space on the Voyager 1
[00:00:31.460 --> 00:00:36.020]   and Voyager 2 spacecraft that are now, 42 years later,
[00:00:36.020 --> 00:00:39.660]   still active, reaching out farther into deep space
[00:00:39.660 --> 00:00:41.940]   than any human-made object ever has.
[00:00:41.940 --> 00:00:46.060]   This was a profound and beautiful decision
[00:00:46.060 --> 00:00:48.340]   Anne made as a creative director
[00:00:48.340 --> 00:00:51.960]   of NASA's Voyager Interstellar Message Project.
[00:00:51.960 --> 00:00:55.700]   In 2014, she went on to create the second season of "Cosmos,"
[00:00:55.700 --> 00:00:58.380]   called "Cosmos, A Spacetime Odyssey."
[00:00:58.380 --> 00:01:01.780]   And in 2020, the new third season
[00:01:01.780 --> 00:01:04.140]   called "Cosmos, Possible Worlds,"
[00:01:04.140 --> 00:01:08.020]   which is being released this upcoming Monday, March 9th.
[00:01:08.020 --> 00:01:11.220]   It is hosted, once again, by the fun
[00:01:11.220 --> 00:01:13.680]   and the brilliant Neil deGrasse Tyson.
[00:01:13.680 --> 00:01:18.480]   Carl Sagan, Anne Julian, and "Cosmos"
[00:01:18.480 --> 00:01:21.100]   have inspired millions of scientists and curious minds
[00:01:21.100 --> 00:01:24.740]   across several generations by revealing the magic,
[00:01:24.740 --> 00:01:27.820]   the power, the beauty of science.
[00:01:27.820 --> 00:01:30.300]   I am one such curious mind.
[00:01:30.300 --> 00:01:31.900]   And if you listen to this podcast,
[00:01:31.900 --> 00:01:35.380]   you may know that Elon Musk is as well.
[00:01:35.380 --> 00:01:38.220]   He graciously agreed to read Carl Sagan's words
[00:01:38.220 --> 00:01:42.180]   about the pale blue dot in my second conversation with him.
[00:01:42.180 --> 00:01:44.700]   If you listened, there was an interesting
[00:01:44.700 --> 00:01:46.920]   and inspiring twist at the end.
[00:01:46.920 --> 00:01:50.980]   This is the Artificial Intelligence Podcast.
[00:01:50.980 --> 00:01:53.260]   If you enjoy it, subscribe on YouTube,
[00:01:53.260 --> 00:01:55.180]   give it five stars on Apple Podcasts,
[00:01:55.180 --> 00:01:58.100]   support it on Patreon, or connect with me on Twitter
[00:01:58.100 --> 00:02:02.260]   at Lex Friedman, spelled F-R-I-D-M-A-N.
[00:02:02.260 --> 00:02:05.260]   As usual, I'll do one or two minutes of ads now,
[00:02:05.260 --> 00:02:06.740]   and never any ads in the middle
[00:02:06.740 --> 00:02:09.020]   that can break the flow of the conversation.
[00:02:09.020 --> 00:02:10.460]   I hope that works for you
[00:02:10.460 --> 00:02:13.660]   and doesn't hurt the listening experience.
[00:02:13.660 --> 00:02:15.660]   This show is presented by Cash App,
[00:02:15.660 --> 00:02:18.180]   the number one finance app in the App Store.
[00:02:18.180 --> 00:02:21.380]   When you get it, use code LEXPODCAST.
[00:02:21.380 --> 00:02:23.540]   Cash App lets you send money to friends,
[00:02:23.540 --> 00:02:25.900]   buy Bitcoin, and invest in the stock market
[00:02:25.900 --> 00:02:27.100]   with as little as $1.
[00:02:27.100 --> 00:02:31.180]   Since Cash App allows you to send and receive money
[00:02:31.180 --> 00:02:34.260]   digitally, peer-to-peer, and security
[00:02:34.260 --> 00:02:36.580]   in all digital transactions is very important,
[00:02:36.580 --> 00:02:39.660]   let me mention the PCI data security standard
[00:02:39.660 --> 00:02:41.980]   that Cash App is compliant with.
[00:02:41.980 --> 00:02:45.220]   I'm a big fan of standards for safety and security.
[00:02:45.220 --> 00:02:48.100]   PCI DSS is a good example of that,
[00:02:48.100 --> 00:02:50.060]   where a bunch of competitors got together
[00:02:50.060 --> 00:02:52.700]   and agreed that there needs to be a global standard
[00:02:52.700 --> 00:02:55.340]   around the security of transactions.
[00:02:55.340 --> 00:02:58.260]   Now we just need to do the same for autonomous vehicles
[00:02:58.260 --> 00:03:00.620]   and artificial intelligence systems in general.
[00:03:00.620 --> 00:03:04.260]   So again, if you get Cash App from the App Store,
[00:03:04.260 --> 00:03:07.540]   Google Play, and use the code LEXPODCAST,
[00:03:07.540 --> 00:03:11.540]   you get $10, and Cash App will also donate $10 to FIRST,
[00:03:11.540 --> 00:03:13.460]   one of my favorite organizations
[00:03:13.460 --> 00:03:16.780]   that's helping to advance robotics and STEM education
[00:03:16.780 --> 00:03:19.140]   for young people around the world.
[00:03:19.140 --> 00:03:23.300]   And now, here's my conversation with Ann Julianne.
[00:03:23.300 --> 00:03:27.460]   What is the role of science in our society?
[00:03:27.460 --> 00:03:30.220]   - Well, I think of what Einstein said
[00:03:30.220 --> 00:03:34.660]   when he opened the 1939 New York World's Fair.
[00:03:34.660 --> 00:03:40.740]   He said, "If science is ever to fulfill its mission
[00:03:40.740 --> 00:03:45.600]   "the way art has done, it must penetrate.
[00:03:46.700 --> 00:03:49.760]   "Its inner meaning must penetrate
[00:03:49.760 --> 00:03:52.420]   "the consciousness of everyone."
[00:03:52.420 --> 00:03:56.820]   And so for me, especially in a civilization
[00:03:56.820 --> 00:03:59.520]   dependent on high technology and science,
[00:03:59.520 --> 00:04:03.580]   one that aspires to be democratic,
[00:04:03.580 --> 00:04:08.920]   it's critical that the public,
[00:04:08.920 --> 00:04:11.600]   as informed decision-makers,
[00:04:11.600 --> 00:04:15.200]   understand the values and the methods
[00:04:15.200 --> 00:04:18.100]   and the rules of science.
[00:04:18.100 --> 00:04:21.140]   - So you think about what you just mentioned,
[00:04:21.140 --> 00:04:23.340]   the values and the methods and the rules
[00:04:23.340 --> 00:04:27.140]   and maybe the technology that science produces,
[00:04:27.140 --> 00:04:31.700]   but what about sort of the beauty, the mystery of science?
[00:04:31.700 --> 00:04:34.580]   - Well, you've touched on what I think is, for me,
[00:04:34.580 --> 00:04:38.540]   that's my way into science, is that for me,
[00:04:38.540 --> 00:04:42.100]   it's much more spiritually uplifting.
[00:04:42.100 --> 00:04:43.740]   The revelations of science,
[00:04:43.740 --> 00:04:47.920]   the collective revelations of, you know,
[00:04:47.920 --> 00:04:51.780]   really countless generations of searchers.
[00:04:51.780 --> 00:04:54.900]   And the little tiny bit we know about reality
[00:04:54.900 --> 00:04:56.580]   is the greatest joy for me,
[00:04:56.580 --> 00:05:01.580]   because I think that it relates to the idea of love.
[00:05:01.580 --> 00:05:06.820]   Like what is love that is based on illusion about the other?
[00:05:06.820 --> 00:05:08.880]   That's not love.
[00:05:08.880 --> 00:05:12.900]   Love is seeing unflinching the other.
[00:05:13.780 --> 00:05:16.060]   And accepting with all your heart.
[00:05:16.060 --> 00:05:18.540]   And to me, knowing the universe as it is,
[00:05:18.540 --> 00:05:21.500]   or the little bit that we're able to understand
[00:05:21.500 --> 00:05:25.220]   at this point, is the purest kind of love.
[00:05:25.220 --> 00:05:28.780]   And therefore, you know, how can our philosophy,
[00:05:28.780 --> 00:05:32.540]   our religion, if it's rootless in nature,
[00:05:32.540 --> 00:05:35.540]   how can it really be true?
[00:05:35.540 --> 00:05:36.700]   I just don't understand.
[00:05:36.700 --> 00:05:41.500]   So I think you need science to get a sense
[00:05:41.500 --> 00:05:45.380]   of the real romance of life,
[00:05:45.380 --> 00:05:50.380]   and the great experience of being awake in the cosmos.
[00:05:50.380 --> 00:05:53.940]   - So the fact that we know so little,
[00:05:53.940 --> 00:05:55.860]   the humbling nature of that,
[00:05:55.860 --> 00:06:00.100]   and you kind of connect love to that,
[00:06:00.100 --> 00:06:02.820]   but isn't it also, isn't it scary?
[00:06:02.820 --> 00:06:06.780]   Isn't it, why is it so inspiring, do you think?
[00:06:06.780 --> 00:06:10.460]   Why is it so beautiful that we know so little?
[00:06:11.420 --> 00:06:13.900]   - Well, first of all, as Socrates thought,
[00:06:13.900 --> 00:06:16.420]   knowing that you know little is knowing,
[00:06:16.420 --> 00:06:19.420]   really knowing something, knowing more than others.
[00:06:19.420 --> 00:06:24.420]   And it's that voice whispering in our heads,
[00:06:24.420 --> 00:06:26.380]   you might be wrong.
[00:06:26.380 --> 00:06:29.740]   Which I think is not only it's really healthy,
[00:06:29.740 --> 00:06:32.780]   because we're so imperfect, we're human, of course.
[00:06:32.780 --> 00:06:36.180]   But also, love to me is the feeling
[00:06:36.180 --> 00:06:38.900]   that you always want to go deeper, get closer.
[00:06:38.900 --> 00:06:41.460]   You can't get enough of it.
[00:06:41.460 --> 00:06:44.780]   You can't get close enough, deep enough.
[00:06:44.780 --> 00:06:47.220]   So, and that's what science is always saying.
[00:06:47.220 --> 00:06:49.660]   Science is never simply content
[00:06:49.660 --> 00:06:53.540]   with its understanding of any aspect of nature.
[00:06:53.540 --> 00:06:56.100]   It's always saying, it's always finding
[00:06:56.100 --> 00:06:59.620]   that even smaller cosmos beneath.
[00:06:59.620 --> 00:07:03.900]   So I think the two are very much parallel.
[00:07:03.900 --> 00:07:08.540]   - So you said that love is not an illusion.
[00:07:08.540 --> 00:07:10.140]   - No, it's not.
[00:07:10.140 --> 00:07:11.980]   Well, if it is-- - So what is love?
[00:07:11.980 --> 00:07:15.580]   - What is love is knowing, for me,
[00:07:15.580 --> 00:07:18.180]   love is knowing something deeply
[00:07:18.180 --> 00:07:25.020]   and still being completely gratified by it, you know,
[00:07:25.020 --> 00:07:28.260]   and wanting to know more.
[00:07:28.260 --> 00:07:33.260]   So what is loving someone, a person, let's say, deeply?
[00:07:36.140 --> 00:07:38.700]   Is not idealizing them,
[00:07:38.700 --> 00:07:44.820]   not putting some kind of subjective projection on them,
[00:07:44.820 --> 00:07:48.740]   but knowing them as they are.
[00:07:48.740 --> 00:07:52.220]   And so for me, the only aperture to that,
[00:07:52.220 --> 00:07:55.580]   knowing about nature, the universe, is science,
[00:07:55.580 --> 00:07:58.740]   because it has that error-correcting mechanism
[00:07:58.740 --> 00:08:01.540]   that most of the stuff that we do doesn't have.
[00:08:01.540 --> 00:08:03.180]   You know, you could say the Bill of Rights
[00:08:03.180 --> 00:08:05.780]   is kind of an error-correcting mechanism,
[00:08:05.780 --> 00:08:08.820]   which is one of the things I really appreciate
[00:08:08.820 --> 00:08:10.620]   about the society in which I live,
[00:08:10.620 --> 00:08:16.020]   to the extent that it's upheld and we keep faith with it.
[00:08:16.020 --> 00:08:17.180]   And the same with science.
[00:08:17.180 --> 00:08:21.740]   It's like, we will give you the highest rewards we have
[00:08:21.740 --> 00:08:24.740]   for proving us wrong about something.
[00:08:24.740 --> 00:08:26.860]   That's genius.
[00:08:26.860 --> 00:08:31.860]   That's why, in only 400 years
[00:08:32.900 --> 00:08:35.660]   since Galileo's first look through a telescope,
[00:08:35.660 --> 00:08:40.580]   we could get from this really dim, vague,
[00:08:40.580 --> 00:08:46.540]   this vague apprehension of another world
[00:08:46.540 --> 00:08:50.620]   to sending our eyes and our senses there,
[00:08:50.620 --> 00:08:52.260]   or even to going beyond.
[00:08:52.260 --> 00:08:57.260]   So it delivers the goods, like nothing else, you know?
[00:08:57.260 --> 00:09:00.420]   It really, it delivers the goods
[00:09:00.420 --> 00:09:05.420]   because it's always self-aware of its fallibility.
[00:09:05.420 --> 00:09:10.620]   - So on that topic, I'd like to ask just your opinion,
[00:09:10.620 --> 00:09:13.260]   and a feeling I have that I'm not sure what to do with,
[00:09:13.260 --> 00:09:18.060]   which is the skeptical aspect of science.
[00:09:18.060 --> 00:09:22.180]   So the modern skeptics community, and just in general,
[00:09:22.180 --> 00:09:24.060]   certain scientists, many scientists,
[00:09:24.060 --> 00:09:27.500]   maybe most scientists that apply this scientific method,
[00:09:27.500 --> 00:09:30.620]   are kind of rigorous in that application.
[00:09:30.620 --> 00:09:34.340]   And it feels like sometimes miss out some of the ideas
[00:09:34.340 --> 00:09:35.420]   outside the reach of,
[00:09:35.420 --> 00:09:37.420]   just slightly outside the reach of science.
[00:09:37.420 --> 00:09:40.000]   And they don't dare to sort of dream
[00:09:40.000 --> 00:09:41.560]   or think of revolutionary ideas
[00:09:41.560 --> 00:09:45.460]   that others will call crazy in this particular moment.
[00:09:45.460 --> 00:09:48.700]   So how do you think about the skeptical aspect of science
[00:09:48.700 --> 00:09:51.740]   that is really good at sort of keeping us in check,
[00:09:51.740 --> 00:09:54.920]   keeping us humble, but at the same time,
[00:09:54.920 --> 00:09:57.540]   sort of the kind of dreams that you and Carl Sagan
[00:09:57.540 --> 00:09:59.740]   have inspired in the world,
[00:09:59.740 --> 00:10:02.940]   it kind of shuts it down sometimes a little bit.
[00:10:02.940 --> 00:10:05.140]   - Yeah, I mean, I think it's up to the individual.
[00:10:05.140 --> 00:10:09.140]   But for me, I was so ridiculously fortunate
[00:10:09.140 --> 00:10:12.060]   in that my tutorial in science,
[00:10:12.060 --> 00:10:15.020]   because I'm not a scientist and I wasn't trained in science,
[00:10:15.020 --> 00:10:20.020]   was 20 years of days and nights with Carl Sagan.
[00:10:20.020 --> 00:10:24.260]   And the wonder, I think the reason Carl remains so beloved,
[00:10:24.260 --> 00:10:26.280]   well, I think there are many reasons,
[00:10:26.280 --> 00:10:31.040]   but at the root of it is the fact that his skepticism
[00:10:31.040 --> 00:10:33.420]   was never at the cost of his wonder
[00:10:33.420 --> 00:10:38.100]   and his wonder was never at the cost of his skepticism.
[00:10:38.100 --> 00:10:40.100]   So he couldn't fool himself
[00:10:40.100 --> 00:10:42.240]   into believing something he wanted to believe
[00:10:42.240 --> 00:10:43.780]   because it made him feel good.
[00:10:43.780 --> 00:10:46.500]   But on the other hand,
[00:10:46.500 --> 00:10:51.460]   he recognized that what science, what nature is,
[00:10:51.460 --> 00:10:54.260]   is really, it's good enough, you know?
[00:10:54.260 --> 00:10:57.460]   It's way better than our fantasies.
[00:10:57.460 --> 00:11:00.500]   And so if you're that kind of person
[00:11:00.500 --> 00:11:03.980]   who loves happiness, loves life,
[00:11:03.980 --> 00:11:05.460]   and your eyes are wide open
[00:11:05.460 --> 00:11:08.220]   and you read everything you can get your hands on,
[00:11:08.220 --> 00:11:12.300]   and you spend years studying what is known so far
[00:11:12.300 --> 00:11:17.080]   about the universe, then you have that capacity,
[00:11:17.080 --> 00:11:22.080]   that really infinite capacity to be alive,
[00:11:22.080 --> 00:11:24.400]   and also at the same time,
[00:11:24.400 --> 00:11:29.400]   to be very rigorous about what you're willing to believe.
[00:11:29.400 --> 00:11:31.760]   For Carl, I don't think he ever felt
[00:11:31.760 --> 00:11:35.760]   that his skepticism cost him anything
[00:11:35.760 --> 00:11:37.440]   because again, it comes back to love.
[00:11:37.440 --> 00:11:40.960]   He wanted to know what nature really was like,
[00:11:40.960 --> 00:11:44.960]   not to inflict his preconceived notions
[00:11:44.960 --> 00:11:46.480]   on what he wanted it to be.
[00:11:46.480 --> 00:11:50.080]   So you can't go wrong because it does, you know,
[00:11:50.080 --> 00:11:52.280]   I mean, you know, I think the pale blue dot
[00:11:52.280 --> 00:11:57.280]   is a perfect example of this massive achievement
[00:11:57.280 --> 00:12:04.160]   is to say, okay, or the Voyager record is another example,
[00:12:04.160 --> 00:12:05.600]   is here we have this mission,
[00:12:05.600 --> 00:12:09.440]   our first reconnaissance of the outer solar system.
[00:12:09.440 --> 00:12:13.000]   Well, how can we make it a mission
[00:12:13.000 --> 00:12:18.000]   in which we absolutely squeeze every drop of consciousness
[00:12:18.000 --> 00:12:21.800]   and understanding from it?
[00:12:21.800 --> 00:12:26.000]   We don't have to be scientists and then be human beings.
[00:12:26.000 --> 00:12:28.880]   I think that's the tragedy of Western civilization
[00:12:28.880 --> 00:12:33.880]   is that it's, you know, one of its greatest gifts
[00:12:33.880 --> 00:12:39.360]   has been science, and yet at the same time,
[00:12:39.360 --> 00:12:43.320]   it believing that we are the children
[00:12:43.320 --> 00:12:46.760]   of a disappointed father, a tyrant
[00:12:46.760 --> 00:12:50.400]   who puts us in a maximum security prison
[00:12:50.400 --> 00:12:53.040]   and calls it paradise, who looks at us,
[00:12:53.040 --> 00:12:55.160]   who watches us every moment
[00:12:55.160 --> 00:12:59.960]   and hates us for being our human selves, you know,
[00:12:59.960 --> 00:13:02.920]   and then most of all, what is our great sin?
[00:13:02.920 --> 00:13:06.080]   It's partaking of the tree of knowledge,
[00:13:06.080 --> 00:13:09.440]   which is our greatest gift as humans,
[00:13:09.440 --> 00:13:14.440]   this pattern recognition, this ability to see things
[00:13:14.440 --> 00:13:19.000]   and then synthesize them and jump to conclusions about them
[00:13:19.000 --> 00:13:21.200]   and test those conclusions.
[00:13:21.200 --> 00:13:26.200]   So I think the reason that in literature, in movies,
[00:13:26.200 --> 00:13:31.400]   the scientist is a figure of alienation,
[00:13:31.560 --> 00:13:34.920]   a figure, you know, oh, you see these biopics
[00:13:34.920 --> 00:13:39.240]   about scientists and yeah, he might've been great,
[00:13:39.240 --> 00:13:42.040]   but you know, he was a misthinking ship, you know,
[00:13:42.040 --> 00:13:44.320]   he was a lousy husband.
[00:13:44.320 --> 00:13:49.320]   He lacked, you know, the kind of spiritual understanding
[00:13:49.320 --> 00:13:53.120]   that maybe, you know, his wife had,
[00:13:53.120 --> 00:13:55.800]   and it's always in the end and they come around,
[00:13:55.800 --> 00:13:59.080]   but to me, that's a false dichotomy
[00:13:59.080 --> 00:14:03.240]   that we are, you know, to the extent that we are aware
[00:14:03.240 --> 00:14:05.440]   of our surroundings and understand them,
[00:14:05.440 --> 00:14:08.800]   which is what science makes it possible for us to do,
[00:14:08.800 --> 00:14:10.040]   we're even more alive.
[00:14:10.040 --> 00:14:13.960]   - So you mentioned a million awesome things there.
[00:14:13.960 --> 00:14:16.960]   Let's even just, can you tell me about the Voyager 1
[00:14:16.960 --> 00:14:21.960]   and 2 spacecraft and the interstellar message project
[00:14:21.960 --> 00:14:24.760]   and that whole just fascinating world leading up to that?
[00:14:24.760 --> 00:14:26.160]   - One of my favorite subjects.
[00:14:26.160 --> 00:14:27.480]   I love talking about it.
[00:14:27.480 --> 00:14:29.160]   I'll never get over it.
[00:14:29.160 --> 00:14:32.280]   I'll never be able to really wrap my head around
[00:14:32.280 --> 00:14:35.160]   the reality of it, the truth of it.
[00:14:35.160 --> 00:14:36.000]   - What is it, first of all?
[00:14:36.000 --> 00:14:37.560]   What's the Voyager spacecraft?
[00:14:37.560 --> 00:14:41.720]   - Okay, so Voyagers 1 and 2 were our first
[00:14:41.720 --> 00:14:44.700]   reconnaissance mission of what was then considered
[00:14:44.700 --> 00:14:46.920]   the outer solar system.
[00:14:46.920 --> 00:14:49.400]   And it was a gift of gravity,
[00:14:49.400 --> 00:14:54.400]   the idea that swinging around these worlds
[00:14:54.400 --> 00:14:57.320]   gives you a gravitational assist,
[00:14:57.320 --> 00:15:01.480]   which ultimately will send you out of the solar system
[00:15:01.480 --> 00:15:06.480]   to wander the Milky Way galaxy for one to 5 billion years.
[00:15:06.480 --> 00:15:11.640]   So Voyager gave us our first closeup look
[00:15:11.640 --> 00:15:17.080]   of Jupiter, Saturn, Uranus, Neptune.
[00:15:17.080 --> 00:15:21.680]   It discovered new moons.
[00:15:21.680 --> 00:15:26.280]   It discovered volcanoes on Io.
[00:15:26.280 --> 00:15:31.240]   Its achievements are astonishing.
[00:15:31.240 --> 00:15:33.720]   And remember, this is technology
[00:15:33.720 --> 00:15:37.160]   from the early to mid 1970s.
[00:15:37.160 --> 00:15:38.480]   - And it's still active.
[00:15:38.480 --> 00:15:39.320]   - And it's still active.
[00:15:39.320 --> 00:15:41.440]   We talked to Voyager a few days ago.
[00:15:41.440 --> 00:15:46.280]   We talked to it, in fact, a year ago I think it was.
[00:15:46.280 --> 00:15:50.680]   We needed to slightly change the attitude of the spacecraft.
[00:15:50.680 --> 00:15:53.520]   And so we fired up its thrusters
[00:15:53.520 --> 00:15:56.440]   for the first time since 1987.
[00:15:56.440 --> 00:15:57.280]   - Did they work?
[00:15:57.280 --> 00:15:58.800]   - Instantly.
[00:15:58.800 --> 00:16:02.800]   It was as if you had left your car in the garage in 1987.
[00:16:02.800 --> 00:16:05.680]   And you put the key in the ignition
[00:16:05.680 --> 00:16:08.280]   because you used keys then in the ignition.
[00:16:08.280 --> 00:16:12.080]   And it turned over the first time you stepped on the gas.
[00:16:12.080 --> 00:16:17.000]   And so that's the genius of the engineering of Voyager.
[00:16:17.000 --> 00:16:21.200]   And Carl was one of the key participants
[00:16:21.200 --> 00:16:25.920]   in imagining what its mission would be
[00:16:25.920 --> 00:16:28.960]   because it was a gift actually
[00:16:28.960 --> 00:16:33.960]   of the fact that every 175 years, plus or minus,
[00:16:33.960 --> 00:16:36.920]   there is an alignment of the worlds.
[00:16:36.920 --> 00:16:41.920]   And so you could send two spacecraft to these other worlds
[00:16:41.920 --> 00:16:46.160]   and photograph them and use your mass spectrometer
[00:16:46.160 --> 00:16:49.760]   and all the other devices on Voyager
[00:16:49.760 --> 00:16:54.000]   to really explore these worlds.
[00:16:54.000 --> 00:16:56.320]   - And it's the farthest spacecraft,
[00:16:56.320 --> 00:17:00.520]   it's the farthest human creation away from us today.
[00:17:00.520 --> 00:17:01.560]   - Yes, Voyager 1.
[00:17:01.560 --> 00:17:02.760]   - Voyager 1.
[00:17:02.760 --> 00:17:04.880]   - These two spacecraft not only gave us
[00:17:04.880 --> 00:17:09.840]   our first close-up look at hundreds of moons and planets,
[00:17:09.840 --> 00:17:12.760]   these four giant, these planets,
[00:17:12.760 --> 00:17:17.640]   but also it told us the shape of the solar system
[00:17:17.640 --> 00:17:19.760]   as it moves through the galaxy
[00:17:19.760 --> 00:17:23.600]   because there were two of them going in different directions
[00:17:23.600 --> 00:17:26.120]   and they finally, and they arrived at a place
[00:17:26.120 --> 00:17:29.960]   called the heliopause, which is where the wind from the sun,
[00:17:29.960 --> 00:17:31.960]   the solar wind dies down
[00:17:31.960 --> 00:17:34.960]   and the interstellar medium begins.
[00:17:34.960 --> 00:17:38.640]   And both Voyagers were the first spacecraft that we had
[00:17:38.640 --> 00:17:41.800]   that could tell us when that happened.
[00:17:41.800 --> 00:17:43.880]   So it's a consummate,
[00:17:44.040 --> 00:17:48.520]   I think it's the greatest scientific achievement
[00:17:48.520 --> 00:17:50.000]   of the 20th century.
[00:17:50.000 --> 00:17:51.840]   - And engineering in some sense.
[00:17:51.840 --> 00:17:53.920]   - Engineering, I mean really,
[00:17:53.920 --> 00:17:58.920]   Voyager is doing this on less energy
[00:17:58.920 --> 00:18:04.000]   than you have in your toaster, something like 11 watts.
[00:18:04.000 --> 00:18:07.640]   So, okay, but because of this gravitational assist,
[00:18:07.640 --> 00:18:11.720]   both Voyagers were destined, as I say, to,
[00:18:11.720 --> 00:18:13.760]   they were, first of all, they were supposed to function
[00:18:13.760 --> 00:18:18.320]   for a dozen years and now it's 42 years since launch
[00:18:18.320 --> 00:18:20.840]   and we're still talking to them.
[00:18:20.840 --> 00:18:22.720]   So that's amazing.
[00:18:22.720 --> 00:18:27.480]   But prior to launch, almost a year,
[00:18:27.480 --> 00:18:29.280]   eight, nine months prior to launch,
[00:18:29.280 --> 00:18:34.040]   it was decided that since Frank Drake and Carl Sagan
[00:18:34.040 --> 00:18:36.960]   and Linda Salzman Sagan had created something called
[00:18:36.960 --> 00:18:41.360]   the Pioneer 10 plaque for the Pioneer spacecraft
[00:18:41.360 --> 00:18:46.200]   that preceded Voyager, which was kind of like a license plate
[00:18:46.200 --> 00:18:50.520]   for the planet Earth, you know, man and a woman, hands up,
[00:18:50.520 --> 00:18:55.520]   you know, very basic, but very effective.
[00:18:55.520 --> 00:18:59.440]   And it captured the imagination of people all over the world.
[00:18:59.440 --> 00:19:04.440]   And so NASA turned to Frank and to Carl and said,
[00:19:04.440 --> 00:19:08.840]   "We'd like you to do a message for Voyager
[00:19:08.840 --> 00:19:13.240]   because if it's going to be circumnavigating
[00:19:13.240 --> 00:19:16.840]   the Milky Way galaxy for one to five billion years,
[00:19:16.840 --> 00:19:20.320]   you know, it's like 20 trips around the galaxy.
[00:19:20.320 --> 00:19:23.560]   And there's a very small chance
[00:19:23.560 --> 00:19:27.840]   that a spacefaring civilization would be able to flag
[00:19:27.840 --> 00:19:29.520]   one of them down.
[00:19:29.520 --> 00:19:33.440]   And so on board, you see this exquisite golden disc
[00:19:33.440 --> 00:19:38.440]   with scientific hieroglyphics explaining our address.
[00:19:39.040 --> 00:19:44.040]   And various basic scientific concepts that we believe
[00:19:44.040 --> 00:19:50.720]   that would be common to any spacefaring civilization.
[00:19:50.720 --> 00:19:54.360]   And then beneath this exquisite golden disc
[00:19:54.360 --> 00:19:58.960]   is the Voyager record, the golden record.
[00:19:58.960 --> 00:20:05.400]   And it contains something like 118 photographs, images
[00:20:08.360 --> 00:20:13.360]   of life on earth, as well as 27 pieces of music
[00:20:13.360 --> 00:20:17.800]   from all around the world.
[00:20:17.800 --> 00:20:22.320]   Many people describe it as the invention of world music.
[00:20:22.320 --> 00:20:25.200]   World music was not a concept that existed
[00:20:25.200 --> 00:20:27.120]   before the Voyager record.
[00:20:27.120 --> 00:20:29.880]   And we were determined to take our music,
[00:20:29.880 --> 00:20:32.920]   not just from the dominant technical cultures,
[00:20:32.920 --> 00:20:37.920]   but from all of the rich cultural heritage of the earth.
[00:20:38.920 --> 00:20:43.920]   And there's a sound essay, which is a kind of using,
[00:20:43.920 --> 00:20:49.040]   using a microphone as a camera to tell the story
[00:20:49.040 --> 00:20:53.680]   of the earth, beginning with its geological sounds
[00:20:53.680 --> 00:20:58.680]   and moving into biology and then into technology.
[00:20:58.680 --> 00:21:03.080]   And Lex, I think what you were getting at is that
[00:21:03.080 --> 00:21:06.160]   at the end of this sound essay,
[00:21:07.160 --> 00:21:12.160]   I had asked Carl if it were in the making of the record,
[00:21:12.160 --> 00:21:16.480]   it was my honor to be the creative director of the project,
[00:21:16.480 --> 00:21:21.480]   if it was possible to, if I had meditated for an hour
[00:21:21.480 --> 00:21:25.360]   while I was hooked up so that, you know,
[00:21:25.360 --> 00:21:29.320]   every single signal that was coming from my brain,
[00:21:29.320 --> 00:21:34.320]   my body was recorded and then converted into a sound.
[00:21:34.320 --> 00:21:38.960]   And then converted into sound for the record.
[00:21:38.960 --> 00:21:42.480]   Was it possible that these putative extraterrestrials
[00:21:42.480 --> 00:21:46.520]   of the distant future of perhaps a billion years from now
[00:21:46.520 --> 00:21:49.560]   would be able to reconstitute this message
[00:21:49.560 --> 00:21:51.520]   and to understand it?
[00:21:51.520 --> 00:21:54.360]   And he just, big smile, you know, and just said,
[00:21:54.360 --> 00:21:56.640]   "Well, hey, a billion years is a long time."
[00:21:56.640 --> 00:21:58.840]   - It was a long time. - "Here we go, do it."
[00:21:58.840 --> 00:22:01.120]   And so I did this.
[00:22:01.120 --> 00:22:03.440]   - And what were you thinking about in the meditation?
[00:22:03.440 --> 00:22:06.040]   Like what, I mean, it's such an interesting idea
[00:22:06.040 --> 00:22:09.040]   of recording as you think about things.
[00:22:09.040 --> 00:22:10.680]   What were you thinking about?
[00:22:10.680 --> 00:22:15.680]   - So I was blindfolded and couldn't hear anything.
[00:22:15.680 --> 00:22:21.200]   And I had made a mental itinerary
[00:22:21.200 --> 00:22:23.480]   of exactly where I wanted to go.
[00:22:23.480 --> 00:22:28.480]   I was truly humbled by the idea
[00:22:28.600 --> 00:22:33.320]   that these thoughts could conceivably touch
[00:22:33.320 --> 00:22:35.360]   the distant future. - Yeah, that's incredible.
[00:22:35.360 --> 00:22:40.360]   - So it's 1977, there are some 60,000 nuclear weapons
[00:22:40.360 --> 00:22:41.520]   on the planet.
[00:22:41.520 --> 00:22:44.240]   The Soviet Union and the United States
[00:22:44.240 --> 00:22:49.240]   are engaged in a, you know, to the death competition.
[00:22:49.240 --> 00:22:55.720]   And so I began by trying to tell the history of the planet
[00:22:56.600 --> 00:23:00.080]   in, you know, to my limited ability,
[00:23:00.080 --> 00:23:02.960]   what I understood about the story
[00:23:02.960 --> 00:23:06.440]   of the early existence of the planet,
[00:23:06.440 --> 00:23:10.760]   about the origin of life, about the evolution of life,
[00:23:10.760 --> 00:23:15.240]   about the history of humans,
[00:23:15.240 --> 00:23:19.760]   about our current at that time predicament,
[00:23:19.760 --> 00:23:23.520]   about the fact that one in five of us was starving
[00:23:24.820 --> 00:23:28.140]   or unable to get potable water.
[00:23:28.140 --> 00:23:33.220]   And so I sort of gave a kind of, you know,
[00:23:33.220 --> 00:23:38.220]   as general a picture as I possibly could of our predicament.
[00:23:38.220 --> 00:23:44.140]   And I also was very newly within days
[00:23:44.140 --> 00:23:51.300]   of the moment when Carl and I fell in love with each other.
[00:23:51.300 --> 00:23:53.420]   Maybe we fell in love with each other long before
[00:23:53.420 --> 00:23:55.500]   'cause we'd known each other for years,
[00:23:55.500 --> 00:23:58.380]   but it was the first time that we had expressed
[00:23:58.380 --> 00:23:59.700]   our feelings for each other.
[00:23:59.700 --> 00:24:01.580]   - Acknowledged it, the existence of this love.
[00:24:01.580 --> 00:24:04.180]   - Yes, because we were both involved with other people
[00:24:04.180 --> 00:24:09.180]   and it was a completely outside his morality and mine
[00:24:09.180 --> 00:24:12.780]   to even broach the subject.
[00:24:12.780 --> 00:24:17.380]   But it was only days after that it happened.
[00:24:17.380 --> 00:24:20.700]   And for me, it was a eureka moment.
[00:24:20.700 --> 00:24:25.700]   It was in the context of finding that piece of Chinese music
[00:24:25.700 --> 00:24:28.860]   that was worthy to represent
[00:24:28.860 --> 00:24:32.300]   one of the oldest musical traditions on earth.
[00:24:32.300 --> 00:24:35.500]   When those of us who worked on the Voyager record
[00:24:35.500 --> 00:24:38.060]   were completely ignorant about Chinese music.
[00:24:38.060 --> 00:24:42.180]   And so that had been a constant challenge for me,
[00:24:42.180 --> 00:24:46.380]   talking to professors of Chinese music,
[00:24:46.380 --> 00:24:48.740]   as known musicologists everywhere
[00:24:48.740 --> 00:24:50.980]   and all through the project,
[00:24:50.980 --> 00:24:53.900]   desperately trying to find this one piece.
[00:24:53.900 --> 00:24:58.140]   Found the piece, lived on the Upper West Side,
[00:24:58.140 --> 00:25:02.420]   found the piece, a professor at Columbia University
[00:25:02.420 --> 00:25:03.380]   gave it to me.
[00:25:03.380 --> 00:25:07.380]   And he's, of all the people I talked to,
[00:25:07.380 --> 00:25:08.900]   everyone had said, "That's hopeless.
[00:25:08.900 --> 00:25:09.740]   "You can't do that.
[00:25:09.740 --> 00:25:12.620]   "There can't be one piece of Chinese music."
[00:25:12.620 --> 00:25:17.500]   But he was completely, "No problem, I've got it."
[00:25:17.500 --> 00:25:21.740]   And so he told me the story of the piece,
[00:25:21.740 --> 00:25:26.740]   which only made it an even greater candidate for the record.
[00:25:26.740 --> 00:25:30.380]   And I listened to it, called Carl Sagan,
[00:25:30.380 --> 00:25:33.300]   who was in Tucson, Arizona,
[00:25:33.300 --> 00:25:38.300]   addressing the American Society of Newspaper Editors.
[00:25:38.300 --> 00:25:43.300]   And I left him a message, Hotel Message Center.
[00:25:45.500 --> 00:25:49.500]   And he called me back an hour later
[00:25:49.500 --> 00:25:55.300]   and heard this beautiful voice say,
[00:25:55.300 --> 00:25:57.100]   "I get back to my hotel room
[00:25:57.100 --> 00:26:00.020]   "and I find this message that Annie called."
[00:26:00.020 --> 00:26:00.860]   And I asked myself,
[00:26:00.860 --> 00:26:03.780]   "Why didn't you leave me this message 10 years ago?"
[00:26:03.780 --> 00:26:09.000]   My heart was beating out of my chest.
[00:26:09.000 --> 00:26:14.940]   It was, for me, a kind of eureka moment.
[00:26:14.940 --> 00:26:18.020]   A kind of scientific breakthrough.
[00:26:18.020 --> 00:26:22.980]   A truth, a great truth had suddenly been revealed.
[00:26:22.980 --> 00:26:25.540]   And of course, I was awkward
[00:26:25.540 --> 00:26:27.660]   and didn't really know what to say.
[00:26:27.660 --> 00:26:29.940]   And so I blurted something out like,
[00:26:29.940 --> 00:26:32.020]   "Oh, I've been meaning to talk to you about that, Carl,"
[00:26:32.020 --> 00:26:32.940]   which wasn't really true.
[00:26:32.940 --> 00:26:34.420]   I never would have talked to him about it.
[00:26:34.420 --> 00:26:36.340]   We had been alone countless times.
[00:26:36.340 --> 00:26:39.740]   - We humans are so awkward in these beautiful moments.
[00:26:39.740 --> 00:26:41.660]   - In these amazing moments.
[00:26:41.660 --> 00:26:45.180]   And I just said, "For keeps?"
[00:26:45.180 --> 00:26:48.860]   And he thought for a very brief, like a second,
[00:26:48.860 --> 00:26:50.740]   and said, "You mean get married?"
[00:26:50.740 --> 00:26:53.100]   And I said, "Yeah."
[00:26:53.100 --> 00:26:55.020]   And he said, "Yeah."
[00:26:55.020 --> 00:26:58.980]   And we put down the phone
[00:26:58.980 --> 00:27:05.140]   and I literally was jumping around my apartment
[00:27:05.140 --> 00:27:10.140]   like a lunatic because it was so obvious.
[00:27:10.300 --> 00:27:12.500]   It was something like, "Of course."
[00:27:12.500 --> 00:27:14.180]   And then the phone rang again.
[00:27:14.180 --> 00:27:17.940]   And I thought, "Damn, no, he's gonna say,
[00:27:17.940 --> 00:27:19.300]   "I don't know what I was saying.
[00:27:19.300 --> 00:27:23.420]   "I am married, I have a kid, I'm not gonna do this."
[00:27:23.420 --> 00:27:26.060]   But he was like, "I just wanna make sure
[00:27:26.060 --> 00:27:27.740]   "that that really happened."
[00:27:27.740 --> 00:27:29.260]   And I said, "Yeah."
[00:27:29.260 --> 00:27:30.620]   He said, "We're getting married."
[00:27:30.620 --> 00:27:32.820]   And I said, "Yeah, we're getting married."
[00:27:32.820 --> 00:27:36.620]   Now this was June 1st, 1977.
[00:27:36.620 --> 00:27:41.620]   The records had not been affixed to the spacecraft yet.
[00:27:41.620 --> 00:27:44.380]   And there'd been a lot of controversy
[00:27:44.380 --> 00:27:45.660]   about what we were doing.
[00:27:45.660 --> 00:27:50.820]   I should say that among the 118 pictures
[00:27:50.820 --> 00:27:56.180]   was an image of a man and a woman,
[00:27:56.180 --> 00:27:58.700]   frontally, completely naked.
[00:27:58.700 --> 00:27:59.700]   Naked.
[00:27:59.700 --> 00:28:04.620]   And there was, I believe, a congressman on the floor
[00:28:04.620 --> 00:28:09.540]   that said, "NASA to send smut to the stars."
[00:28:09.540 --> 00:28:12.900]   And so NASA really, they got very upset.
[00:28:12.900 --> 00:28:14.460]   And they said, "You can't send a picture."
[00:28:14.460 --> 00:28:16.300]   And we had done it so that it was so brilliant.
[00:28:16.300 --> 00:28:20.380]   It was like this lovely couple, completely naked.
[00:28:20.380 --> 00:28:25.340]   And then the next image was a kind of overlay schematic
[00:28:25.340 --> 00:28:30.180]   to show the fetus inside this woman that was developing.
[00:28:30.180 --> 00:28:33.860]   And then that went off into additional imagery
[00:28:33.860 --> 00:28:35.340]   of human reproduction.
[00:28:35.340 --> 00:28:40.660]   And it really hit me that how much we hate ourselves,
[00:28:40.660 --> 00:28:45.500]   that we couldn't bear to be seen as we are.
[00:28:45.500 --> 00:28:47.820]   So-
[00:28:47.820 --> 00:28:52.820]   - In some sense that congressman also represents our society.
[00:28:52.820 --> 00:28:56.300]   Perhaps his opposition should have been included as well.
[00:28:56.300 --> 00:28:59.700]   - Yes, well, that was one of the most vigorous debates
[00:28:59.700 --> 00:29:03.780]   during the making of the record with the five, six people
[00:29:03.780 --> 00:29:06.020]   that we collaborated with was,
[00:29:06.020 --> 00:29:09.500]   do we only put our best foot forward?
[00:29:09.500 --> 00:29:14.500]   Or do we show Hiroshima, Auschwitz, the Congo,
[00:29:14.500 --> 00:29:18.020]   what we have done?
[00:29:18.020 --> 00:29:20.740]   - What do you think represents humanity?
[00:29:20.740 --> 00:29:25.380]   If you think about it, are darker moments,
[00:29:25.380 --> 00:29:26.940]   are they essential for humanity?
[00:29:26.940 --> 00:29:28.220]   All the wars we've been through,
[00:29:28.220 --> 00:29:32.220]   all the tortures and the suffering and the cruelty,
[00:29:32.220 --> 00:29:36.780]   is that essential for happiness, for beauty, for creation?
[00:29:36.780 --> 00:29:37.620]   Generally speaking.
[00:29:37.620 --> 00:29:38.460]   - Well, it's certainly not essential
[00:29:38.460 --> 00:29:40.580]   for happiness or beauty, that's for sure.
[00:29:40.580 --> 00:29:42.380]   I mean, it's part of who we are.
[00:29:42.380 --> 00:29:44.540]   If we're gonna be real about it, which is,
[00:29:44.540 --> 00:29:47.620]   I think we tell on ourselves,
[00:29:47.620 --> 00:29:49.540]   even if we don't wanna be real.
[00:29:49.540 --> 00:29:54.500]   I think that if you're a spacefaring civilization
[00:29:54.500 --> 00:29:58.100]   and you've gotten it together sufficiently,
[00:29:58.100 --> 00:30:00.780]   you can move from world to world,
[00:30:00.780 --> 00:30:04.220]   then I think they probably took one look
[00:30:04.220 --> 00:30:06.540]   at this derelict spacecraft,
[00:30:06.540 --> 00:30:08.540]   and they knew that these were people
[00:30:08.540 --> 00:30:10.580]   in their technological adolescence,
[00:30:10.580 --> 00:30:13.940]   and they were just setting forth,
[00:30:13.940 --> 00:30:16.340]   and they must have had these issues.
[00:30:16.340 --> 00:30:22.580]   And so, that's the great thing about lying,
[00:30:22.580 --> 00:30:25.100]   is that a lie only has a shelf life.
[00:30:25.100 --> 00:30:29.660]   If a great work of art that's a forgery,
[00:30:30.660 --> 00:30:32.260]   people can be fooled immediately,
[00:30:32.260 --> 00:30:34.620]   but 10 or 15 years, 20 years later,
[00:30:34.620 --> 00:30:35.860]   they start to look at it,
[00:30:35.860 --> 00:30:39.660]   they begin to realize the lens,
[00:30:39.660 --> 00:30:44.660]   our lens of our present is coloring everything that we see.
[00:30:44.660 --> 00:30:48.740]   So, I think it didn't matter
[00:30:48.740 --> 00:30:52.460]   that we didn't show our atrocities.
[00:30:52.460 --> 00:30:54.140]   - They would fill in the blanks.
[00:30:54.140 --> 00:30:55.500]   - They would fill in the blanks.
[00:30:55.500 --> 00:30:56.860]   - So let me sort of ask,
[00:30:56.860 --> 00:30:58.420]   you've mentioned how unlikely it is
[00:30:58.460 --> 00:31:03.020]   that you and Carl, that two souls like yours
[00:31:03.020 --> 00:31:04.980]   would meet in this vast world.
[00:31:04.980 --> 00:31:08.340]   What are your views on how and why
[00:31:08.340 --> 00:31:10.860]   incredibly unlikely things like these
[00:31:10.860 --> 00:31:12.740]   nevertheless do happen?
[00:31:12.740 --> 00:31:15.100]   - It's purely to me, chance.
[00:31:15.100 --> 00:31:17.620]   It's totally random.
[00:31:17.620 --> 00:31:20.900]   It's just, I mean, and the fact is,
[00:31:20.900 --> 00:31:23.220]   is that some people are,
[00:31:23.220 --> 00:31:25.860]   and it's happening every day right now,
[00:31:25.860 --> 00:31:30.340]   some people are the random casualties of chance.
[00:31:30.340 --> 00:31:33.180]   And I don't just mean the people
[00:31:33.180 --> 00:31:38.180]   who are being destroyed in childhood, in wartime,
[00:31:38.180 --> 00:31:41.820]   I'm also, or the people who starved to death
[00:31:41.820 --> 00:31:43.460]   because of famine,
[00:31:43.460 --> 00:31:46.060]   but also the people who,
[00:31:46.060 --> 00:31:52.020]   who are not living to the fullest.
[00:31:52.020 --> 00:31:53.780]   All of these things, I think there's a,
[00:31:53.780 --> 00:31:57.460]   my parents met on the subway in rush hour.
[00:31:57.460 --> 00:31:59.100]   And so I'm only here with you
[00:31:59.100 --> 00:32:03.420]   because of the most random possible situation.
[00:32:03.420 --> 00:32:05.260]   And so I've had this, a sense of this,
[00:32:05.260 --> 00:32:06.820]   even before I knew Carl,
[00:32:06.820 --> 00:32:08.500]   I always felt this way,
[00:32:08.500 --> 00:32:12.140]   that I only existed because of the generosity.
[00:32:12.140 --> 00:32:13.180]   - Of the rush hour.
[00:32:13.180 --> 00:32:17.260]   - Of the, no, of just all of the things,
[00:32:17.260 --> 00:32:20.500]   all of the skeins of causality.
[00:32:20.500 --> 00:32:21.340]   - Yeah.
[00:32:21.340 --> 00:32:22.780]   It's interesting 'cause, you know,
[00:32:22.780 --> 00:32:26.460]   the rush hour is a source of stress for a lot of people,
[00:32:26.460 --> 00:32:29.300]   but clearly in its moments,
[00:32:29.300 --> 00:32:32.420]   it can also be a source of something beautiful.
[00:32:32.420 --> 00:32:33.260]   - That's right.
[00:32:33.260 --> 00:32:35.220]   - Of strangers meeting and so on.
[00:32:35.220 --> 00:32:38.100]   So everything, everything is,
[00:32:38.100 --> 00:32:40.100]   has a possibility of doing something beautiful.
[00:32:40.100 --> 00:32:41.340]   - That's right.
[00:32:41.340 --> 00:32:47.420]   - So let me ask sort of a quick tangent on the Voyager.
[00:32:47.420 --> 00:32:52.220]   This beautiful romantic notion that Voyager 1
[00:32:52.220 --> 00:32:55.780]   is sort of our farthest human reach into space.
[00:32:55.780 --> 00:32:58.460]   If you think of what, I don't know if you've seen,
[00:32:58.460 --> 00:33:02.900]   but what Elon Musk did with putting the roadster,
[00:33:02.900 --> 00:33:05.020]   letting it fly out into space,
[00:33:05.020 --> 00:33:07.260]   there's a sort of humor to it.
[00:33:07.260 --> 00:33:10.020]   I think that's also kind of interesting,
[00:33:10.020 --> 00:33:11.900]   but maybe you can comment on that.
[00:33:11.900 --> 00:33:16.900]   But in general, if now that we are developing,
[00:33:16.900 --> 00:33:21.740]   we're venturing out into space again in a more serious way,
[00:33:21.740 --> 00:33:26.500]   what kind of stuff that represent since Voyager was launched
[00:33:26.500 --> 00:33:28.900]   should we send out as a follow-up?
[00:33:28.900 --> 00:33:31.940]   Is there things that you think that's developed
[00:33:31.940 --> 00:33:34.580]   in the next, in the 40 years after
[00:33:34.580 --> 00:33:38.860]   that we should update the spacefaring aliens?
[00:33:38.860 --> 00:33:41.780]   - Well, of course now we could send the worldwide,
[00:33:41.780 --> 00:33:45.340]   we could send everything that's on the world wide web.
[00:33:45.340 --> 00:33:47.700]   We could send, I mean, you know,
[00:33:47.700 --> 00:33:50.860]   that was a time when we're talking about photograph records
[00:33:50.860 --> 00:33:52.580]   and transistor radios.
[00:33:52.580 --> 00:33:57.580]   And, you know, so we tried to be,
[00:33:57.580 --> 00:34:00.100]   to take advantage of the existing technology
[00:34:00.100 --> 00:34:02.140]   to the fullest extent.
[00:34:02.140 --> 00:34:04.500]   You know, the computer that was hooked up to me
[00:34:04.500 --> 00:34:06.420]   from my brainwaves and my heart sounds
[00:34:06.420 --> 00:34:08.660]   while I was meditating was, you know,
[00:34:08.660 --> 00:34:10.940]   the size of a gigantic room.
[00:34:10.940 --> 00:34:15.500]   And I'm sure it's not, it didn't have the power of a phone,
[00:34:15.500 --> 00:34:17.260]   has, the phone has now.
[00:34:17.260 --> 00:34:19.540]   So, you know, now we could just,
[00:34:19.540 --> 00:34:21.060]   I think we could let it all hang out.
[00:34:21.060 --> 00:34:23.420]   We could just like send, you know, every,
[00:34:23.420 --> 00:34:25.940]   I mean, that's the wonder, like,
[00:34:25.940 --> 00:34:29.220]   I would send, you know, Wikipedia or something
[00:34:29.220 --> 00:34:34.220]   and not be a gatekeeper, but show who we are.
[00:34:34.220 --> 00:34:38.700]   - You were also, it's interesting 'cause one of the problems
[00:34:38.700 --> 00:34:41.660]   of the internet of having so much information
[00:34:41.660 --> 00:34:44.660]   is it's actually the curation,
[00:34:44.660 --> 00:34:48.820]   the human curation is still the powerful, beautiful thing.
[00:34:48.820 --> 00:34:52.020]   So what you did with the record is actually,
[00:34:52.020 --> 00:34:54.020]   is exactly the right process.
[00:34:54.020 --> 00:34:57.500]   It's kind of boiling down a massive amount of possibilities
[00:34:57.500 --> 00:35:01.020]   of what you could send into something that represents,
[00:35:01.020 --> 00:35:02.940]   you know, the better angels of our nature
[00:35:02.940 --> 00:35:05.060]   or represents our humanity.
[00:35:05.060 --> 00:35:08.860]   So if you think about, you know,
[00:35:08.860 --> 00:35:10.860]   what would you send from the internet,
[00:35:10.860 --> 00:35:12.940]   as opposed to sending all of Wikipedia, for example,
[00:35:12.940 --> 00:35:14.820]   all of human knowledge,
[00:35:14.820 --> 00:35:18.580]   is there something just new that we've developed, you think?
[00:35:18.580 --> 00:35:23.580]   Or fundamentally, we're still the same kind of human species?
[00:35:23.580 --> 00:35:25.900]   - I think fundamentally we're the same,
[00:35:25.900 --> 00:35:29.940]   but we have a kind of, we have advanced
[00:35:29.940 --> 00:35:35.620]   to an astonishing degree in our capacity for data retrieval
[00:35:35.620 --> 00:35:37.420]   and for transmission.
[00:35:37.420 --> 00:35:40.100]   And so, you know, I would send YouTube,
[00:35:40.100 --> 00:35:43.060]   I would send, you know, really, like think of all the,
[00:35:43.060 --> 00:35:48.060]   you know, I still feel so lucky
[00:35:48.180 --> 00:35:52.340]   that there's any great musical artist
[00:35:52.340 --> 00:35:55.900]   of the last hundred years who I revere.
[00:35:55.900 --> 00:35:59.740]   I can just find them and watch them and listen to them.
[00:35:59.740 --> 00:36:02.060]   And, you know, that's fantastic.
[00:36:02.060 --> 00:36:04.820]   I also love how democratic it is
[00:36:04.820 --> 00:36:07.980]   that we each become curators
[00:36:07.980 --> 00:36:10.340]   and that we each decide those things.
[00:36:10.340 --> 00:36:14.220]   Now, I may not agree with, you know,
[00:36:14.220 --> 00:36:17.740]   those, the choices that everyone makes, but of course not,
[00:36:17.740 --> 00:36:19.060]   because that's not the point.
[00:36:19.060 --> 00:36:22.380]   The point is, is that we are, you know,
[00:36:22.380 --> 00:36:26.580]   we have discovered largely through the internet
[00:36:26.580 --> 00:36:29.480]   that we are an intercommunicating organism,
[00:36:29.480 --> 00:36:32.260]   and that can only be good.
[00:36:32.260 --> 00:36:37.260]   - So you could also send now Cosmos.
[00:36:37.260 --> 00:36:38.980]   - Yes, I'd love to.
[00:36:38.980 --> 00:36:39.980]   I would be proud to.
[00:36:39.980 --> 00:36:45.900]   - I mean, you've spoken about a very specific voice
[00:36:45.900 --> 00:36:50.580]   that Cosmos had in, that it reveals the magic of science.
[00:36:50.580 --> 00:36:53.300]   I think you said shamanic journey of it,
[00:36:53.300 --> 00:36:57.380]   and not the details of the latest breakthroughs or so on.
[00:36:57.380 --> 00:36:59.060]   It's just revealing the magic.
[00:36:59.060 --> 00:37:03.700]   Can you try to describe what this voice of Cosmos is
[00:37:03.700 --> 00:37:07.380]   with the follow-up and the new Cosmos
[00:37:07.380 --> 00:37:09.300]   that you're working on now?
[00:37:09.300 --> 00:37:13.620]   - Yes, well, the dream of Cosmos is really,
[00:37:14.460 --> 00:37:17.100]   like Einstein's quote, you know,
[00:37:17.100 --> 00:37:20.740]   it's the idea of the awesome power of science
[00:37:20.740 --> 00:37:25.340]   to be in absolutely everyone's hands.
[00:37:25.340 --> 00:37:27.700]   You know, it belongs to all of us.
[00:37:27.700 --> 00:37:31.620]   It's not the preserve of a priesthood.
[00:37:31.620 --> 00:37:35.620]   It's just the community of science is becoming more diverse
[00:37:35.620 --> 00:37:39.000]   and being less exclusive than it was guilty of
[00:37:39.000 --> 00:37:41.540]   in the not so recent past.
[00:37:41.540 --> 00:37:43.580]   The discoveries of science,
[00:37:43.580 --> 00:37:48.380]   our understanding of the cosmos that we live in
[00:37:48.380 --> 00:37:52.100]   has really grown by leaps and bounds,
[00:37:52.100 --> 00:37:54.860]   and probably we've learned more
[00:37:54.860 --> 00:37:58.820]   in the last hundred years about it.
[00:37:58.820 --> 00:38:03.820]   You know, the tempo of discovery has picked up so rapidly.
[00:38:03.820 --> 00:38:09.140]   And so the idea of Cosmos from the 1970s,
[00:38:09.140 --> 00:38:12.820]   when Carl and I and Steven Soder, another astronomer,
[00:38:12.820 --> 00:38:17.820]   first imagined it was that interweaving,
[00:38:17.820 --> 00:38:23.140]   not only of these scientific concepts and revelations
[00:38:23.140 --> 00:38:27.500]   and using, you know, cinematic VFX
[00:38:27.500 --> 00:38:32.500]   to take the viewer on this transporting, uplifting journey,
[00:38:32.500 --> 00:38:36.220]   but also the stories of the searchers.
[00:38:36.220 --> 00:38:41.220]   Because the more I have learned about, you know,
[00:38:41.220 --> 00:38:46.620]   the process of science through my life with Carl and since,
[00:38:46.620 --> 00:38:51.780]   the more I am really persuaded
[00:38:51.780 --> 00:38:55.100]   that it's that adherence to the facts
[00:38:55.100 --> 00:39:00.980]   and to that adherence to that little approximation,
[00:39:00.980 --> 00:39:02.380]   that little bit of reality
[00:39:02.380 --> 00:39:05.080]   that we've been able to get our hands around.
[00:39:05.920 --> 00:39:08.880]   It's something that we desperately need.
[00:39:08.880 --> 00:39:11.360]   And it doesn't matter if you are a scientist.
[00:39:11.360 --> 00:39:15.760]   In fact, the people, it matters even more if you're not.
[00:39:15.760 --> 00:39:19.240]   And since, you know, the level of science teaching
[00:39:19.240 --> 00:39:22.280]   has been fairly or unfairly maligned.
[00:39:22.280 --> 00:39:28.200]   And the idea that once there was such a thing
[00:39:28.200 --> 00:39:29.840]   as a television network,
[00:39:29.840 --> 00:39:33.600]   which of course has now evolved into many other things,
[00:39:33.600 --> 00:39:37.360]   the idea that you could, in the most democratic way,
[00:39:37.360 --> 00:39:39.880]   make accessible to absolutely everyone,
[00:39:39.880 --> 00:39:44.040]   and most especially people who don't even realize
[00:39:44.040 --> 00:39:46.180]   that they have an interest in the subject
[00:39:46.180 --> 00:39:50.920]   or who feel so intimidated by the jargon of science
[00:39:50.920 --> 00:39:54.760]   and its kind of exclusive history.
[00:39:54.760 --> 00:39:56.880]   The idea that we could do this,
[00:39:56.880 --> 00:39:59.680]   and, you know, in season two of "Cosmos,"
[00:39:59.680 --> 00:40:01.760]   the "Space Time Odyssey,"
[00:40:01.760 --> 00:40:06.440]   we were in 181 countries in the space of two weeks.
[00:40:06.440 --> 00:40:09.920]   It was the largest rollout in television history,
[00:40:09.920 --> 00:40:13.580]   which is really amazing for a,
[00:40:13.580 --> 00:40:15.600]   there is no science-based programming.
[00:40:15.600 --> 00:40:18.040]   - By the way, just to clarify, the series was rolled out,
[00:40:18.040 --> 00:40:21.280]   so it was shown in that many countries.
[00:40:21.280 --> 00:40:23.280]   You said we were in--
[00:40:23.280 --> 00:40:25.680]   - Well, our show was in 180 countries.
[00:40:25.680 --> 00:40:27.280]   - Yeah, the show, which is incredible.
[00:40:27.280 --> 00:40:29.640]   I mean, the hundreds of millions,
[00:40:29.640 --> 00:40:31.640]   whatever that number is, the people that watched it,
[00:40:31.640 --> 00:40:33.360]   it's just, it's crazy.
[00:40:33.360 --> 00:40:35.760]   - It's so crazy that, for instance,
[00:40:35.760 --> 00:40:41.000]   my son had a cerebral hemorrhage a year ago,
[00:40:41.000 --> 00:40:45.120]   and the doctor who saved his life
[00:40:45.120 --> 00:40:49.280]   in a very dangerous situation,
[00:40:49.280 --> 00:40:53.880]   when he realized that, you know,
[00:40:53.880 --> 00:40:57.880]   that Sam and I were who we were,
[00:40:57.880 --> 00:41:00.360]   he said, "That's why I'm here."
[00:41:00.360 --> 00:41:03.680]   You know, he said, "If you come of age in a poor country,
[00:41:03.680 --> 00:41:07.360]   "like Colombia, and Carl Sagan calls you to science
[00:41:07.360 --> 00:41:12.360]   "when you're a child, then, you know, you go to medicine,
[00:41:12.360 --> 00:41:15.500]   "because that's the only avenue open to you,
[00:41:15.500 --> 00:41:17.720]   "but that's why I'm here."
[00:41:17.720 --> 00:41:21.440]   And I have heard that story, and I hear that story.
[00:41:22.680 --> 00:41:25.040]   I think every week.
[00:41:25.040 --> 00:41:26.120]   - How does that make you feel?
[00:41:26.120 --> 00:41:29.460]   I mean, the number of scientists,
[00:41:29.460 --> 00:41:31.400]   I mean, a lot of it is quiet, right?
[00:41:31.400 --> 00:41:34.920]   But the number of scientists Cosmos has created
[00:41:34.920 --> 00:41:36.300]   is just countless.
[00:41:36.300 --> 00:41:38.380]   I mean, it probably touched a lot of, I don't know,
[00:41:38.380 --> 00:41:40.720]   probably, it could be a crazy number,
[00:41:40.720 --> 00:41:43.840]   like 90% of scientists or something have been--
[00:41:43.840 --> 00:41:45.480]   - I would love to do that census,
[00:41:45.480 --> 00:41:50.040]   because that's the greatest gratification,
[00:41:50.040 --> 00:41:52.080]   because that's the dream of science.
[00:41:52.080 --> 00:41:56.040]   That's the whole idea, is that if it belongs to all of us,
[00:41:56.040 --> 00:42:00.200]   and not just a tiny few, then we have some chance
[00:42:00.200 --> 00:42:02.800]   of determining how it's used.
[00:42:02.800 --> 00:42:06.040]   And if it's only in the hands of people
[00:42:06.040 --> 00:42:11.040]   whose only interests are the balance sheet,
[00:42:11.040 --> 00:42:17.720]   or hegemony over other nations, or things like that,
[00:42:17.720 --> 00:42:22.560]   then it'll probably end up being a gun aimed at our heads.
[00:42:22.560 --> 00:42:27.560]   But if it's distributed in the widest possible way,
[00:42:27.560 --> 00:42:32.360]   a capability that we now have because of our technology,
[00:42:32.360 --> 00:42:37.360]   then the chance is that it'll be used with wisdom.
[00:42:37.360 --> 00:42:39.040]   That's the dream of it.
[00:42:39.040 --> 00:42:42.920]   So that's why we did the first Cosmos.
[00:42:42.920 --> 00:42:46.040]   We wanted to take not just, as I say,
[00:42:46.040 --> 00:42:47.960]   the scientific information,
[00:42:47.960 --> 00:42:52.520]   but also tell the stories of these searchers.
[00:42:52.520 --> 00:42:55.600]   Because for us, and for me,
[00:42:55.600 --> 00:42:59.600]   in carrying on this series in the second and third seasons,
[00:42:59.600 --> 00:43:06.640]   the primary interest was that we wouldn't tell a story
[00:43:06.640 --> 00:43:09.040]   unless it was kind of a threefer.
[00:43:09.040 --> 00:43:10.720]   You know, it was not just a way
[00:43:10.720 --> 00:43:13.920]   to understand a new scientific idea,
[00:43:13.920 --> 00:43:18.920]   but it was also a way to understand what,
[00:43:18.920 --> 00:43:21.000]   if it matters what's true,
[00:43:21.000 --> 00:43:24.440]   how the world can change for us,
[00:43:24.440 --> 00:43:26.200]   and how we can be protected.
[00:43:26.200 --> 00:43:29.280]   And if it doesn't matter what's true,
[00:43:29.280 --> 00:43:32.100]   then we're in grave danger,
[00:43:32.100 --> 00:43:34.680]   because we have the capability
[00:43:34.680 --> 00:43:38.800]   to not only destroy ourselves and our civilization,
[00:43:38.800 --> 00:43:42.240]   but to take so many species with us.
[00:43:42.240 --> 00:43:45.280]   - And I'd like to talk to you about that particular,
[00:43:45.280 --> 00:43:48.840]   the sort of the dangers of ourselves in a little bit,
[00:43:48.840 --> 00:43:51.280]   but sort of to linger on Cosmos.
[00:43:51.280 --> 00:43:56.280]   Maybe for the first, the 1980 and the 2014 follow-up,
[00:43:56.280 --> 00:44:01.480]   what's a, or one of the, or several memorable moments
[00:44:01.480 --> 00:44:07.140]   from the creation of either of those seasons?
[00:44:07.140 --> 00:44:10.780]   - Well, you know, the critical thing really
[00:44:10.780 --> 00:44:15.780]   was the fact that Seth MacFarlane became our champion,
[00:44:15.780 --> 00:44:19.080]   because I had been, with three colleagues,
[00:44:19.080 --> 00:44:22.440]   I had been schlepping around from network to network
[00:44:22.440 --> 00:44:25.280]   with a treatment for Cosmos,
[00:44:25.280 --> 00:44:27.920]   and every network said they wanted to do it,
[00:44:27.920 --> 00:44:30.920]   but they wouldn't give me creative control,
[00:44:30.920 --> 00:44:34.360]   and they wouldn't give me enough money
[00:44:34.360 --> 00:44:36.520]   to make it cinematic,
[00:44:36.520 --> 00:44:40.480]   and to make it feel like you're really going on an adventure.
[00:44:40.480 --> 00:44:41.320]   And so--
[00:44:41.320 --> 00:44:42.720]   - And I think both of those things,
[00:44:42.720 --> 00:44:44.980]   sorry to interrupt, both of those things there,
[00:44:44.980 --> 00:44:48.640]   given what Cosmos represents, the legacy of it,
[00:44:48.640 --> 00:44:50.460]   the legacy of Carl Sagan is essential,
[00:44:50.460 --> 00:44:53.980]   control, especially in the modern world.
[00:44:53.980 --> 00:44:56.460]   It's wonderful that you sought control,
[00:44:56.460 --> 00:44:57.300]   that you did not really push it.
[00:44:57.300 --> 00:44:58.940]   - And I keep saying no.
[00:44:58.940 --> 00:45:00.980]   And my partners, I'm sure, you know,
[00:45:00.980 --> 00:45:03.820]   I know they would look at me like I was nuts, you know?
[00:45:03.820 --> 00:45:06.480]   And they probably must have entertained the idea
[00:45:06.480 --> 00:45:09.060]   that maybe I didn't really want to do it, you know,
[00:45:09.060 --> 00:45:11.260]   because I was afraid or something,
[00:45:11.260 --> 00:45:12.280]   but I kept saying no,
[00:45:12.280 --> 00:45:15.420]   and it wasn't until I met Seth MacFarlane,
[00:45:15.420 --> 00:45:20.420]   and he took me to Fox, and to Peter Rice,
[00:45:20.420 --> 00:45:24.220]   and said, you know, "I'll pay for half the pilot
[00:45:24.220 --> 00:45:26.020]   "if I have to," you know, and Peter Rice was like,
[00:45:26.020 --> 00:45:27.340]   "Put your money away."
[00:45:27.340 --> 00:45:28.180]   And--
[00:45:28.180 --> 00:45:29.000]   - Seth said that.
[00:45:29.000 --> 00:45:29.840]   - Yeah.
[00:45:29.840 --> 00:45:34.840]   And in every time since, in the 10 years since,
[00:45:35.260 --> 00:45:39.220]   at every turn, when we needed Seth to intervene
[00:45:39.220 --> 00:45:43.340]   on our behalf, he stood up and he did it.
[00:45:43.340 --> 00:45:47.900]   And so that was like, in a way, that is the,
[00:45:47.900 --> 00:45:50.340]   you know, the watershed for me
[00:45:50.340 --> 00:45:52.300]   of everything that followed since.
[00:45:52.300 --> 00:45:54.980]   And then I was so lucky because, you know,
[00:45:54.980 --> 00:45:57.100]   Steve and I, Steve Soder and I,
[00:45:57.100 --> 00:45:59.820]   written the original "Cosmos" with Carl,
[00:45:59.820 --> 00:46:03.780]   and collaborated on the treatment for season two.
[00:46:03.780 --> 00:46:08.780]   And then Brandon Braga came into our project
[00:46:08.780 --> 00:46:14.300]   at the perfect moment, and has proven to be just the,
[00:46:14.300 --> 00:46:17.140]   really, I've been so lucky my whole life.
[00:46:17.140 --> 00:46:19.860]   I've collaborated, I've been lucky with the people,
[00:46:19.860 --> 00:46:22.640]   my collaborators have been extraordinary.
[00:46:22.640 --> 00:46:26.060]   And so that was a critical thing.
[00:46:26.060 --> 00:46:28.820]   But also to have, you know, for instance,
[00:46:28.820 --> 00:46:32.500]   our astonishing VFX supervisor,
[00:46:32.500 --> 00:46:34.100]   who comes from the movies,
[00:46:34.100 --> 00:46:39.100]   who heads the global association of VFX people, Jeff Oken.
[00:46:39.100 --> 00:46:44.340]   And then, and you know, I could rattle off 10 more names,
[00:46:44.340 --> 00:46:46.300]   I'd be happy to do that.
[00:46:46.300 --> 00:46:49.620]   And it was that collaboration.
[00:46:49.620 --> 00:46:52.180]   - So the people were essential to the creation of-
[00:46:52.180 --> 00:46:53.380]   - Absolutely.
[00:46:53.380 --> 00:46:56.060]   I mean, when it came down, I have to say that
[00:46:56.060 --> 00:46:59.220]   when it came down to the vision of what the series would be,
[00:46:59.220 --> 00:47:01.780]   that was me sitting in my home,
[00:47:01.780 --> 00:47:03.900]   looking out the window, and, you know,
[00:47:03.900 --> 00:47:06.580]   really imagining like what I wanted to do.
[00:47:06.580 --> 00:47:07.900]   - Can you pause on that for a second?
[00:47:07.900 --> 00:47:09.020]   Like, what's the process?
[00:47:09.020 --> 00:47:11.220]   'Cause it, you know, "Cosmos" is also,
[00:47:11.220 --> 00:47:12.680]   it's grounded in science, of course,
[00:47:12.680 --> 00:47:15.380]   but it's also incredibly imaginative,
[00:47:15.380 --> 00:47:19.260]   and the words used are carefully crafted.
[00:47:19.260 --> 00:47:20.100]   - Thank you.
[00:47:20.100 --> 00:47:24.860]   - So what's, if you can talk about the process of that,
[00:47:24.860 --> 00:47:28.100]   the big picture, imaginative thinking,
[00:47:28.100 --> 00:47:31.340]   and sort of the rigorous crafting of words
[00:47:31.340 --> 00:47:35.180]   that like basically turns into something like poetry.
[00:47:35.180 --> 00:47:36.180]   - Thank you so much.
[00:47:36.180 --> 00:47:42.420]   For me, these are rare occasions for human self-esteem.
[00:47:42.420 --> 00:47:49.020]   The scientists that we bring to life in "Cosmos"
[00:47:49.020 --> 00:47:55.900]   are people, in my view, who have everything we need
[00:47:55.900 --> 00:47:59.340]   to see us through this current crisis.
[00:48:00.220 --> 00:48:03.860]   It's their, very often they come,
[00:48:03.860 --> 00:48:08.700]   they're poor, they're female, they're outsiders
[00:48:08.700 --> 00:48:13.700]   who are not expected to have gifts that are so prodigious,
[00:48:13.700 --> 00:48:18.660]   but they persevere.
[00:48:18.660 --> 00:48:21.900]   And so you have someone like Michael Faraday,
[00:48:21.900 --> 00:48:25.060]   who is, comes from a family,
[00:48:25.060 --> 00:48:27.660]   dysfunctional family of like 14 people,
[00:48:27.660 --> 00:48:32.660]   and it never goes to, university never learns the math,
[00:48:32.660 --> 00:48:39.020]   but there's Einstein years later
[00:48:39.020 --> 00:48:44.020]   looking up at the picture of Faraday to inspire him.
[00:48:44.020 --> 00:48:49.220]   So it's, if we had people with that kind of humility
[00:48:49.220 --> 00:48:56.180]   and unselfishness who didn't wanna patent everything
[00:48:56.180 --> 00:49:01.180]   as, Michael Faraday created the wealth of the 20th century
[00:49:01.180 --> 00:49:04.980]   with his various inventions.
[00:49:04.980 --> 00:49:07.260]   And yet he never took out a single patent
[00:49:07.260 --> 00:49:10.580]   at a time when people were patenting everything
[00:49:10.580 --> 00:49:13.020]   because that was not what he was about.
[00:49:13.020 --> 00:49:17.020]   And to me, that's a kind of almost a saintliness
[00:49:17.020 --> 00:49:22.020]   that says that, here's a man who finds in his life
[00:49:23.260 --> 00:49:27.700]   this tremendous gratification from searching.
[00:49:27.700 --> 00:49:30.660]   And it's just so impressive to me.
[00:49:30.660 --> 00:49:32.820]   And there are so many other people in cosmos,
[00:49:32.820 --> 00:49:34.820]   especially the new season of cosmos,
[00:49:34.820 --> 00:49:36.580]   which is called "Possible Worlds."
[00:49:36.580 --> 00:49:37.860]   - Possible, beautiful title.
[00:49:37.860 --> 00:49:42.460]   - "Possible Worlds," well, I stole it from an author
[00:49:42.460 --> 00:49:44.260]   and a scientist from the 1940s,
[00:49:44.260 --> 00:49:49.260]   but it, for me, encapsulates not just, you know,
[00:49:49.260 --> 00:49:53.140]   the exoplanets that we've begun to discover,
[00:49:53.140 --> 00:49:57.780]   not just, you know, the worlds that we might visit,
[00:49:57.780 --> 00:50:01.460]   but also the world that this could be,
[00:50:01.460 --> 00:50:03.300]   a hopeful vision of the future.
[00:50:03.300 --> 00:50:06.620]   You ask me, what is common to all three seasons of cosmos?
[00:50:06.620 --> 00:50:08.340]   Or what is that voice?
[00:50:08.340 --> 00:50:10.580]   It's a voice of hope.
[00:50:10.580 --> 00:50:13.380]   It's a voice that says there is a future
[00:50:13.380 --> 00:50:16.900]   which we bring to life in, I think,
[00:50:16.900 --> 00:50:21.620]   a fairly dazzling fashion that we can still have, you know?
[00:50:21.620 --> 00:50:24.820]   And in sitting down to imagine what this season would be,
[00:50:24.820 --> 00:50:26.460]   the new season would be,
[00:50:26.460 --> 00:50:29.140]   I'm sitting where I live in Ithaca, beautiful,
[00:50:29.140 --> 00:50:35.100]   just gorgeous place, trees everywhere, waterfalls.
[00:50:35.100 --> 00:50:38.420]   I'm sitting there thinking, well, you know, you can't,
[00:50:38.420 --> 00:50:41.620]   how do you, how do you awaken people?
[00:50:41.620 --> 00:50:43.540]   I mean, you can't yell at them and say,
[00:50:43.540 --> 00:50:45.140]   we're all gonna die, you know?
[00:50:45.140 --> 00:50:47.300]   It's not, it doesn't help.
[00:50:47.300 --> 00:50:48.900]   It doesn't help.
[00:50:48.900 --> 00:50:53.900]   But I think if you give them a vision of the future
[00:50:53.900 --> 00:50:59.260]   that's not pie in the sky, but something,
[00:50:59.260 --> 00:51:02.940]   ways in which science can be redemptive,
[00:51:02.940 --> 00:51:06.780]   can actually remediate our future.
[00:51:06.780 --> 00:51:09.860]   We have those capabilities right now,
[00:51:09.860 --> 00:51:14.860]   as well as the capabilities to do things in the cosmos
[00:51:14.860 --> 00:51:18.860]   that we could be doing right now, but we're not doing them.
[00:51:18.860 --> 00:51:22.140]   Not because we don't know how to,
[00:51:22.140 --> 00:51:25.580]   how, you know, with the engineering or the material sciences
[00:51:25.580 --> 00:51:28.700]   or the physics, we know all we need to know,
[00:51:28.700 --> 00:51:32.700]   but we're a little bit paralyzed in some sense.
[00:51:32.700 --> 00:51:34.900]   And, you know, we're like,
[00:51:34.900 --> 00:51:37.140]   I always think we're like the toddler, you know?
[00:51:37.140 --> 00:51:40.900]   Like we left our mother's legs, you know,
[00:51:40.900 --> 00:51:43.260]   and scurried out to the moon.
[00:51:43.260 --> 00:51:46.300]   And we had a moment of, wow, we can do this.
[00:51:46.300 --> 00:51:48.260]   And then we realized,
[00:51:48.260 --> 00:51:50.700]   and somehow we had a failure of nerve
[00:51:50.700 --> 00:51:53.540]   and we went scurrying back to our mother
[00:51:53.540 --> 00:51:55.540]   and, you know, did things that really weren't
[00:51:55.540 --> 00:51:58.020]   going to get us out there, like the space shuttle,
[00:51:58.020 --> 00:52:02.260]   things like that, because it was a kind of failure of nerve.
[00:52:02.260 --> 00:52:06.780]   So cosmos is about overcoming those fears.
[00:52:06.780 --> 00:52:10.300]   - We're now as a civilization ready to be a teenager
[00:52:10.300 --> 00:52:12.220]   venturing out into college.
[00:52:12.220 --> 00:52:13.300]   We're returning back.
[00:52:13.300 --> 00:52:14.860]   - Exactly.
[00:52:14.860 --> 00:52:15.700]   Exactly.
[00:52:16.100 --> 00:52:21.100]   And that's one of my theories about our current situation
[00:52:21.100 --> 00:52:25.460]   is that this is our adolescence.
[00:52:25.460 --> 00:52:28.460]   And I was a total mess as an adolescent.
[00:52:28.460 --> 00:52:31.540]   I was reckless, irresponsible, totally.
[00:52:31.540 --> 00:52:33.660]   I didn't, I was inconsiderate.
[00:52:33.660 --> 00:52:37.660]   The reality of other people's feelings
[00:52:37.660 --> 00:52:41.420]   and the future didn't exist for me.
[00:52:41.420 --> 00:52:44.900]   So why should a technologically adolescent civilization
[00:52:44.900 --> 00:52:46.540]   be any different?
[00:52:46.540 --> 00:52:51.540]   But, you know, the vast majority of people I know
[00:52:51.540 --> 00:52:58.620]   made it through that period and went on to be more wise.
[00:52:58.620 --> 00:53:02.700]   And that's what my hope is for our civilization.
[00:53:02.700 --> 00:53:07.580]   - On a sort of a darker and more difficult subject
[00:53:07.580 --> 00:53:10.780]   in terms of, so you just talked about the cosmos
[00:53:10.780 --> 00:53:13.540]   being an inspiration for science
[00:53:13.540 --> 00:53:18.540]   and for us growing out of our messy adolescence,
[00:53:18.540 --> 00:53:22.060]   but nevertheless, there is threats in this world.
[00:53:22.060 --> 00:53:25.180]   So do you worry about existential threats
[00:53:25.180 --> 00:53:27.500]   like you mentioned nuclear weapons?
[00:53:27.500 --> 00:53:29.900]   Do you worry about nuclear war?
[00:53:29.900 --> 00:53:30.740]   - Yes.
[00:53:30.740 --> 00:53:32.820]   - And if you could also maybe comment,
[00:53:32.820 --> 00:53:34.460]   I don't know how much you've thought about it,
[00:53:34.460 --> 00:53:37.580]   but there's folks like Elon Musk
[00:53:37.580 --> 00:53:39.620]   who are worried about the existential threats
[00:53:39.620 --> 00:53:41.380]   of artificial intelligence,
[00:53:41.380 --> 00:53:45.300]   sort of our robotic computer creations
[00:53:45.300 --> 00:53:49.300]   sort of resulting in us humans losing control.
[00:53:49.300 --> 00:53:52.140]   So can you speak to the things that worry you
[00:53:52.140 --> 00:53:53.900]   in terms of existential concerns?
[00:53:53.900 --> 00:53:55.620]   - Oh, all of the above.
[00:53:55.620 --> 00:53:57.220]   You don't have to be silly, you know,
[00:53:57.220 --> 00:54:00.540]   like not to think and not to look at, for instance,
[00:54:00.540 --> 00:54:05.540]   our rapidly burgeoning capability
[00:54:05.540 --> 00:54:08.660]   in artificial intelligence,
[00:54:08.660 --> 00:54:13.660]   not, and to see how sick so much of the planet is,
[00:54:13.660 --> 00:54:15.820]   not to be concerned.
[00:54:15.820 --> 00:54:19.140]   - Sick isn't evil, potentially.
[00:54:19.140 --> 00:54:22.140]   - Well, how much cruelty and brutality
[00:54:22.140 --> 00:54:25.380]   is happening at this very moment?
[00:54:25.380 --> 00:54:30.380]   And I would put climate change higher up on that list
[00:54:30.380 --> 00:54:34.820]   because I believe that there are unforeseen discoveries
[00:54:34.820 --> 00:54:38.080]   that we are making right now.
[00:54:38.080 --> 00:54:39.740]   For instance, all that methane
[00:54:39.740 --> 00:54:42.700]   that's coming out of the ocean floor
[00:54:42.700 --> 00:54:47.420]   that was sequestered because of the permafrost,
[00:54:47.420 --> 00:54:48.720]   which is now melting.
[00:54:48.720 --> 00:54:51.420]   I think there are other effects
[00:54:51.420 --> 00:54:54.820]   besides our greed and short-term thinking
[00:54:54.820 --> 00:54:58.780]   that we are triggering now
[00:54:58.780 --> 00:55:01.020]   with all the greenhouse gases
[00:55:01.020 --> 00:55:02.460]   we're putting into the atmosphere.
[00:55:02.460 --> 00:55:04.180]   And that worries me day and night.
[00:55:04.200 --> 00:55:08.840]   I think about it every single, every moment, really,
[00:55:08.840 --> 00:55:11.240]   because I really think that's how we have to be.
[00:55:11.240 --> 00:55:16.240]   We have to begin to really focus
[00:55:16.240 --> 00:55:21.920]   on how grave the challenge is to our civilization
[00:55:21.920 --> 00:55:25.540]   and to the other species that are,
[00:55:25.540 --> 00:55:29.480]   it's a mass, this is a mass extinction event
[00:55:29.480 --> 00:55:30.960]   that we're living through.
[00:55:30.960 --> 00:55:35.060]   And we're seeing it, we're seeing news of it every day.
[00:55:35.060 --> 00:55:38.580]   - So what do you think about, another touchy subject,
[00:55:38.580 --> 00:55:41.820]   but what do you think about the politicization of science
[00:55:41.820 --> 00:55:44.020]   on topics like global warming,
[00:55:44.020 --> 00:55:47.420]   embryonic stem cell research, and other topics like it?
[00:55:47.420 --> 00:55:48.380]   What's your sense?
[00:55:48.380 --> 00:55:49.220]   Why?
[00:55:49.220 --> 00:55:52.700]   - What do you mean by the politicization of global warming?
[00:55:52.700 --> 00:55:57.700]   - Meaning that if you say, I think what you just said,
[00:55:58.460 --> 00:56:01.160]   which is global warming is a serious concern,
[00:56:01.160 --> 00:56:04.600]   it's human caused, there might be some detrimental effects.
[00:56:04.600 --> 00:56:08.240]   Currently, there's a large percent of the population
[00:56:08.240 --> 00:56:10.400]   in the United States that would,
[00:56:10.400 --> 00:56:14.380]   as opposed to listening to that statement,
[00:56:14.380 --> 00:56:16.120]   would immediately think,
[00:56:16.120 --> 00:56:20.000]   or that's just a liberal talking point.
[00:56:20.000 --> 00:56:20.840]   That's what I mean by politicization.
[00:56:20.840 --> 00:56:22.280]   - I think that's not so true anymore.
[00:56:22.280 --> 00:56:26.280]   I don't think our problem is a population
[00:56:26.280 --> 00:56:29.920]   that's skeptical about climate change,
[00:56:29.920 --> 00:56:34.140]   because I think that the extreme weather fire events
[00:56:34.140 --> 00:56:38.880]   that we are experiencing with such frequency
[00:56:38.880 --> 00:56:40.760]   is really gotten to people.
[00:56:40.760 --> 00:56:45.760]   I think that there are people in leadership positions
[00:56:45.760 --> 00:56:52.000]   who choose to ignore it and to pretend it's not there,
[00:56:52.000 --> 00:56:55.640]   but ultimately I think they will be rejected.
[00:56:55.640 --> 00:56:57.680]   The question is, will it be fast enough?
[00:56:57.680 --> 00:57:03.680]   But I think actually that most people
[00:57:03.680 --> 00:57:07.800]   have really finally taken the reality
[00:57:07.800 --> 00:57:11.280]   of global climate change to heart.
[00:57:11.280 --> 00:57:14.560]   And they look at their children and grandchildren,
[00:57:14.560 --> 00:57:19.560]   and they don't feel good because they come from a world
[00:57:19.560 --> 00:57:23.160]   which was in many ways, in terms of climate,
[00:57:23.160 --> 00:57:26.360]   fairly familiar and benign.
[00:57:26.360 --> 00:57:28.640]   And they know that we're headed in another direction.
[00:57:28.640 --> 00:57:32.180]   And it's not just that, it's what we do to the oceans,
[00:57:32.180 --> 00:57:34.120]   the rivers, the air.
[00:57:34.120 --> 00:57:39.640]   You asked me, what is the message of "Cosmos"?
[00:57:39.640 --> 00:57:44.640]   It's that we have to think in longer terms.
[00:57:44.640 --> 00:57:49.040]   I think of the Soviet Union and the United States
[00:57:49.040 --> 00:57:51.720]   in the Cold War, and they're ready to kill each other
[00:57:51.720 --> 00:57:53.880]   over these two different views
[00:57:53.880 --> 00:57:56.660]   of the distribution of resources.
[00:57:56.660 --> 00:58:02.480]   But neither of them has a form of human social organization
[00:58:02.480 --> 00:58:05.680]   that thinks in terms of a hundred years,
[00:58:05.680 --> 00:58:07.480]   let alone a thousand years,
[00:58:07.480 --> 00:58:11.880]   which are the timescales that science speaks in.
[00:58:11.880 --> 00:58:13.740]   And that's part of the problem,
[00:58:13.740 --> 00:58:18.480]   is that we have to get a grip on reality
[00:58:18.480 --> 00:58:20.360]   and where we're headed.
[00:58:20.360 --> 00:58:24.760]   And I'm not fatalistic at all,
[00:58:24.760 --> 00:58:30.680]   but I do feel like, and in setting out to do this series,
[00:58:30.680 --> 00:58:35.360]   each season, we were talking about climate change
[00:58:35.360 --> 00:58:38.600]   in the original "Cosmos" in episode four.
[00:58:38.600 --> 00:58:44.640]   And warning about inadvertent climate modification in 1980.
[00:58:44.640 --> 00:58:48.840]   And of course, Carl did his PhD thesis
[00:58:48.840 --> 00:58:50.760]   on the greenhouse effect on Venus,
[00:58:50.760 --> 00:58:53.560]   and he was painfully cognizant
[00:58:53.560 --> 00:58:57.880]   of what a runaway greenhouse effect would do to our planet.
[00:58:57.880 --> 00:59:00.780]   And not only that, but the climatic history of the planet,
[00:59:00.780 --> 00:59:04.520]   which we go into in great detail in the series.
[00:59:04.520 --> 00:59:08.320]   So yeah, I mean, how are we gonna get a grip on this
[00:59:08.320 --> 00:59:13.020]   if not through some kind of understanding of science?
[00:59:13.020 --> 00:59:16.760]   Can I just say one more thing about science?
[00:59:16.760 --> 00:59:21.760]   Is that its powers of prophecy are astonishing.
[00:59:21.760 --> 00:59:27.160]   You launch a spacecraft in 1977,
[00:59:27.160 --> 00:59:31.440]   and you know where each and every planet
[00:59:31.440 --> 00:59:34.780]   in the solar system is gonna be in every moon.
[00:59:34.780 --> 00:59:38.400]   And you rendezvous with that flawlessly,
[00:59:38.400 --> 00:59:41.240]   and you exceed the design specifications
[00:59:41.240 --> 00:59:44.720]   of the greatest dreams of the engineers.
[00:59:44.720 --> 00:59:49.120]   And then you go on to explore the Milky Way galaxy,
[00:59:49.120 --> 00:59:50.040]   and you do it.
[00:59:50.040 --> 00:59:53.360]   I mean, the climate scientists,
[00:59:53.360 --> 00:59:57.240]   some of the people whose stories we tell in "Cosmos,"
[00:59:57.240 --> 01:00:01.600]   their predictions were,
[01:00:01.600 --> 01:00:04.840]   and they were working with very early
[01:00:04.840 --> 01:00:07.400]   computer modeling capabilities.
[01:00:07.400 --> 01:00:11.640]   They have proven to be so robust, nuclear winter,
[01:00:11.640 --> 01:00:12.720]   all of these things.
[01:00:12.720 --> 01:00:14.540]   This is a prophetic power.
[01:00:14.540 --> 01:00:17.280]   And yet how crazy that, you know,
[01:00:17.280 --> 01:00:21.960]   it's like the Romans with their lead cooking pots
[01:00:21.960 --> 01:00:23.140]   and their lead pipes,
[01:00:23.140 --> 01:00:27.560]   or the Aztecs ripping out their own people's hearts.
[01:00:27.560 --> 01:00:28.620]   This is us.
[01:00:28.620 --> 01:00:32.240]   We know better, and yet we are acting
[01:00:32.240 --> 01:00:34.460]   as if it's business as usual.
[01:00:34.460 --> 01:00:39.280]   - Yeah, the beautiful complexity of human nature.
[01:00:39.280 --> 01:00:42.040]   Speaking of which, let me ask.
[01:00:42.040 --> 01:00:44.480]   (laughs)
[01:00:44.480 --> 01:00:45.900]   A tough question, I guess,
[01:00:45.900 --> 01:00:47.800]   because there's so many possible answers,
[01:00:47.800 --> 01:00:49.840]   but what aspect of life here on Earth
[01:00:49.840 --> 01:00:51.640]   do you find most fascinating?
[01:00:51.640 --> 01:00:55.480]   From the origin of life, the evolutionary process itself,
[01:00:55.480 --> 01:00:58.140]   the origin of the human mind, so intelligence,
[01:00:58.140 --> 01:01:02.880]   some of the technological developments going on now,
[01:01:02.880 --> 01:01:05.860]   or us venturing out into space or space exploration.
[01:01:05.860 --> 01:01:07.720]   What just inspires you?
[01:01:07.720 --> 01:01:09.120]   - Oh, they all inspire me.
[01:01:09.120 --> 01:01:10.420]   Every one of those inspire me,
[01:01:10.420 --> 01:01:13.260]   but I'll have to say that to me,
[01:01:13.260 --> 01:01:15.100]   at the origin, as I've gotten older,
[01:01:15.100 --> 01:01:20.100]   to me the origin of life has become less interesting.
[01:01:20.100 --> 01:01:21.560]   - Interesting, wow.
[01:01:21.560 --> 01:01:24.880]   - Because I feel, well, not because it's more,
[01:01:24.880 --> 01:01:29.720]   I think I understand, I have a better grasp
[01:01:29.720 --> 01:01:31.600]   of how it might have happened.
[01:01:31.600 --> 01:01:33.160]   - Do you think it was a huge leap?
[01:01:33.160 --> 01:01:34.000]   So a moment--
[01:01:34.000 --> 01:01:37.880]   - I think it was a, we are a byproduct of geophysics,
[01:01:37.880 --> 01:01:42.480]   and I think it's not, my suspicion, of course,
[01:01:42.480 --> 01:01:45.800]   which is, take it with a grain of salt,
[01:01:45.800 --> 01:01:50.560]   but my suspicion is that it happens more often
[01:01:50.560 --> 01:01:53.800]   in more places than we like to think,
[01:01:53.800 --> 01:01:56.600]   because after all, the history of our thinking
[01:01:56.600 --> 01:02:00.920]   about ourselves has been a constant series of demotions
[01:02:00.920 --> 01:02:03.960]   in which we've had to realize, no, no.
[01:02:03.960 --> 01:02:04.800]   So to me that's--
[01:02:04.800 --> 01:02:06.240]   - We're not at the center of the solar system.
[01:02:06.240 --> 01:02:09.000]   - And the origin of consciousness is to me also
[01:02:09.000 --> 01:02:10.840]   not so amazing.
[01:02:10.840 --> 01:02:14.200]   If you think of it as going back to these
[01:02:14.200 --> 01:02:18.080]   once-held organisms of a billion years ago,
[01:02:18.080 --> 01:02:23.080]   who had to know, well, if I go higher up,
[01:02:23.080 --> 01:02:26.800]   I'll get too much sun, and if I go lower down,
[01:02:26.800 --> 01:02:31.400]   I'll be protected from UV rays, things like that.
[01:02:31.400 --> 01:02:34.400]   They had to know that, or you I eat, me I don't.
[01:02:34.400 --> 01:02:38.360]   I mean, even that, I can see, if you know that,
[01:02:38.360 --> 01:02:40.720]   then knowing what we know now,
[01:02:40.720 --> 01:02:43.640]   it's just, it's not so hard to fathom.
[01:02:43.640 --> 01:02:45.800]   It seems like, you know, there's,
[01:02:45.800 --> 01:02:48.580]   I never believed there was a duality
[01:02:48.580 --> 01:02:51.160]   between our minds and our bodies,
[01:02:51.160 --> 01:02:52.520]   and I think that--
[01:02:52.520 --> 01:02:54.200]   - Even consciousness, all those--
[01:02:54.200 --> 01:02:57.080]   - All those things seem to me, except--
[01:02:57.080 --> 01:03:00.760]   - Byproduct of geophysics.
[01:03:00.760 --> 01:03:03.240]   - Yeah, all of chemistry, yes.
[01:03:03.240 --> 01:03:05.680]   Geochemistry, geophysics, absolutely.
[01:03:06.640 --> 01:03:09.000]   You know, it makes perfect sense to me,
[01:03:09.000 --> 01:03:12.360]   and it doesn't make it any less wondrous.
[01:03:12.360 --> 01:03:17.360]   It doesn't rob it at all of the wonder of it,
[01:03:17.360 --> 01:03:21.600]   and so, yeah, I think that's amazing.
[01:03:21.600 --> 01:03:23.960]   I think, you know, we tell the story
[01:03:23.960 --> 01:03:26.600]   of someone you have never heard of, I guarantee,
[01:03:26.600 --> 01:03:29.360]   and I think you're very knowledgeable on the subject,
[01:03:29.360 --> 01:03:33.960]   who was more responsible for our ability
[01:03:33.960 --> 01:03:37.400]   to venture out to other worlds than anyone else,
[01:03:37.400 --> 01:03:40.400]   and who was completely forgotten,
[01:03:40.400 --> 01:03:42.840]   and so, those are the kinds of stories
[01:03:42.840 --> 01:03:45.360]   I like best for "Cosmos," because--
[01:03:45.360 --> 01:03:46.200]   - Can you tell me who?
[01:03:46.200 --> 01:03:49.120]   - No, I'm gonna make you watch this series.
[01:03:49.120 --> 01:03:52.800]   I'm gonna make you buy my book, and, you know,
[01:03:52.800 --> 01:03:57.360]   but just saying, like, this person would be forgotten,
[01:03:57.360 --> 01:04:01.520]   but, you know, you just, the way that we do "Cosmos"
[01:04:01.520 --> 01:04:05.200]   is that, like, I ask a question to myself.
[01:04:05.200 --> 01:04:07.840]   We really wanna get to the bottom, to the answer,
[01:04:07.840 --> 01:04:09.480]   and keep going deeper, deeper,
[01:04:09.480 --> 01:04:12.120]   until we find what the story is,
[01:04:12.120 --> 01:04:15.000]   a story that I know, because I'm not a scientist.
[01:04:15.000 --> 01:04:20.000]   If it moves me, if it moves me, then I wanna tell it,
[01:04:20.000 --> 01:04:22.360]   and other people will be moved.
[01:04:22.360 --> 01:04:25.440]   - Do you ponder mortality?
[01:04:25.440 --> 01:04:26.600]   - Yes. - Human mortality,
[01:04:26.600 --> 01:04:29.080]   and maybe even your own mortality?
[01:04:29.080 --> 01:04:30.320]   - Oh, all the time.
[01:04:30.320 --> 01:04:34.080]   I just turned 70, so, yeah, I think about it a lot.
[01:04:34.080 --> 01:04:37.720]   I mean, it's, you know, how can you not think about it?
[01:04:37.720 --> 01:04:38.640]   But--
[01:04:38.640 --> 01:04:41.760]   - What do you make of this short life of ours?
[01:04:41.760 --> 01:04:46.680]   I mean, let me ask it sort of another way.
[01:04:46.680 --> 01:04:52.880]   You've lost Carl, and speaking of mortality,
[01:04:52.880 --> 01:04:58.400]   if you could be, if you could choose immortality,
[01:04:58.400 --> 01:05:00.320]   you know, it's possible that science allows us
[01:05:00.320 --> 01:05:02.400]   to live much, much longer.
[01:05:02.400 --> 01:05:05.360]   Is that something you would choose for yourself, for Carl?
[01:05:05.360 --> 01:05:07.160]   For you to-- - Well, for Carl, definitely.
[01:05:07.160 --> 01:05:09.960]   I would've, you know, in a nanosecond,
[01:05:09.960 --> 01:05:13.480]   I would take that deal, but not for me.
[01:05:13.480 --> 01:05:14.720]   I mean, if Carl were alive, yes,
[01:05:14.720 --> 01:05:15.920]   I would wanna live forever,
[01:05:15.920 --> 01:05:19.640]   because I know it would be fun, but no.
[01:05:19.640 --> 01:05:21.560]   - Would it be fun forever?
[01:05:21.560 --> 01:05:22.400]   That's the essential nature of the--
[01:05:22.400 --> 01:05:24.080]   - I don't know, it's just that the universe
[01:05:24.080 --> 01:05:28.240]   is so full of so many wonderful things to discover
[01:05:28.240 --> 01:05:31.360]   that it feels like it would be fun,
[01:05:31.360 --> 01:05:33.120]   but no, I don't wanna live forever.
[01:05:33.120 --> 01:05:37.160]   I have had a magical life.
[01:05:37.160 --> 01:05:41.800]   I just, my, you know, my craziest dreams have come true.
[01:05:41.800 --> 01:05:44.280]   And I feel, you know, forgive me,
[01:05:44.280 --> 01:05:49.280]   but this crazy quirk of fate
[01:05:49.280 --> 01:05:54.360]   that put my most joyful, deepest feelings,
[01:05:54.800 --> 01:05:58.680]   feelings that decades later, 42 years later,
[01:05:58.680 --> 01:06:02.440]   I know how real, how true those feelings were.
[01:06:02.440 --> 01:06:04.920]   Everything that happened after that
[01:06:04.920 --> 01:06:09.720]   was an affirmation of how true those feelings were.
[01:06:09.720 --> 01:06:12.080]   And so I don't feel that way.
[01:06:12.080 --> 01:06:15.100]   I feel like I have gotten so much more than my share,
[01:06:15.100 --> 01:06:21.400]   not just my extraordinary life with Carl,
[01:06:21.400 --> 01:06:26.400]   my family, my parents, my children, my friends,
[01:06:26.400 --> 01:06:31.520]   the places that I've been able to explore,
[01:06:31.520 --> 01:06:36.760]   the books I've read, the music I've heard.
[01:06:36.760 --> 01:06:41.660]   So I feel like, you know, if it'd be much better,
[01:06:41.660 --> 01:06:45.960]   if instead of working on the immortality of the lucky few,
[01:06:45.960 --> 01:06:49.460]   of the most privileged people in this society,
[01:06:49.460 --> 01:06:52.960]   I would really like to see a concerted effort
[01:06:52.960 --> 01:06:55.240]   for us to get our act together.
[01:06:55.240 --> 01:07:00.080]   You know, that to me is topic A, more pressing.
[01:07:00.080 --> 01:07:04.320]   You know, this possible world, that is the challenge.
[01:07:04.320 --> 01:07:09.120]   And we're at a kind of moment where if we can,
[01:07:09.120 --> 01:07:10.840]   we can make that choice.
[01:07:10.840 --> 01:07:14.080]   So immortality doesn't really interest me.
[01:07:14.080 --> 01:07:16.480]   I really, I love nature.
[01:07:16.480 --> 01:07:21.360]   And I have to say that I, because I'm a product of nature,
[01:07:21.360 --> 01:07:26.360]   I recognize that it's great gifts and it's great cruelty.
[01:07:26.360 --> 01:07:33.040]   - Well, I don't think there's a better way to end it.
[01:07:33.040 --> 01:07:33.880]   Thank you so much for talking to me.
[01:07:33.880 --> 01:07:35.480]   It was an honor. - Oh, it's wonderful.
[01:07:35.480 --> 01:07:36.800]   - I really appreciate it. - I really enjoyed it.
[01:07:36.800 --> 01:07:38.440]   I thought your questions were great.
[01:07:38.440 --> 01:07:39.940]   - Thank you.
[01:07:39.940 --> 01:07:42.680]   Thanks for listening to this conversation with Ann Druyan.
[01:07:42.680 --> 01:07:45.880]   And thank you to our presenting sponsor, Cash App.
[01:07:45.880 --> 01:07:50.280]   Download it, use code LEXPODCAST, you'll get $10,
[01:07:50.280 --> 01:07:53.640]   and $10 will go to FIRST, an organization that inspires
[01:07:53.640 --> 01:07:56.040]   and educates young minds to become science
[01:07:56.040 --> 01:07:58.680]   and technology innovators of tomorrow.
[01:07:58.680 --> 01:08:01.600]   If you enjoy this podcast, subscribe on YouTube,
[01:08:01.600 --> 01:08:05.000]   give it five stars on Apple Podcast, support on Patreon,
[01:08:05.000 --> 01:08:08.480]   or simply connect with me on Twitter @LexFriedman.
[01:08:08.480 --> 01:08:11.920]   And now, let me leave you with some words of wisdom
[01:08:11.920 --> 01:08:13.060]   from Carl Sagan.
[01:08:13.920 --> 01:08:16.960]   "What an astonishing thing a book is.
[01:08:16.960 --> 01:08:21.240]   "It's a flat object made from a tree with flexible parts
[01:08:21.240 --> 01:08:24.900]   "on which are imprinted lots of funny dark squiggles.
[01:08:24.900 --> 01:08:27.480]   "But one glance at it, and you're inside the mind
[01:08:27.480 --> 01:08:29.820]   "of another person, maybe somebody dead
[01:08:29.820 --> 01:08:31.660]   "for thousands of years.
[01:08:31.660 --> 01:08:34.800]   "Across the millennia, an author is speaking clearly
[01:08:34.800 --> 01:08:39.280]   "and silently inside your head, directly to you.
[01:08:39.280 --> 01:08:43.180]   "Writing is perhaps the greatest of human inventions.
[01:08:43.180 --> 01:08:46.540]   "Binding together people who never knew each other,
[01:08:46.540 --> 01:08:50.120]   "citizens of distant epics.
[01:08:50.120 --> 01:08:53.060]   "Books break the shackles of time.
[01:08:53.060 --> 01:08:58.060]   "A book is proof that humans are capable of working magic."
[01:08:58.060 --> 01:09:02.920]   Thank you for listening, and hope to see you next time.
[01:09:02.920 --> 01:09:05.500]   (upbeat music)
[01:09:05.500 --> 01:09:08.080]   (upbeat music)
[01:09:08.080 --> 01:09:18.080]   [BLANK_AUDIO]

