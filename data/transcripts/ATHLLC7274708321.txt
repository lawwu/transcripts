
[00:00:00.000 --> 00:00:01.680]   A quick word from our sponsor today.
[00:00:01.680 --> 00:00:08.040]   I love helping you answer all the toughest questions about life, money, and so much
[00:00:08.040 --> 00:00:12.860]   more, but sometimes it's helpful to talk to other people in your situation, which
[00:00:12.860 --> 00:00:14.920]   actually gets harder as you build your wealth.
[00:00:14.920 --> 00:00:18.200]   So I want to introduce you to today's sponsor, Longangle.
[00:00:18.200 --> 00:00:22.220]   Longangle is a community of high net worth individuals with backgrounds in
[00:00:22.220 --> 00:00:26.040]   everything from technology, finance, medicine, to real estate, law,
[00:00:26.040 --> 00:00:27.600]   manufacturing, and more.
[00:00:27.600 --> 00:00:29.440]   I'm a member of Longangle.
[00:00:29.480 --> 00:00:33.040]   I've loved being a part of the community, and I've even had one of the founders,
[00:00:33.040 --> 00:00:37.200]   Tad Fallows, join me on All The Hacks in episode 87 to talk about alternative
[00:00:37.200 --> 00:00:37.920]   investments.
[00:00:37.920 --> 00:00:42.660]   Now, the majority of Longangle members are first generation wealth, young, highly
[00:00:42.660 --> 00:00:46.400]   successful individuals who join the community to share knowledge and learn
[00:00:46.400 --> 00:00:49.600]   from each other in a confidential, unbiased setting.
[00:00:49.600 --> 00:00:54.400]   On top of that, members also get access to some unique private market investment
[00:00:54.400 --> 00:00:55.200]   opportunities.
[00:00:55.200 --> 00:00:59.120]   Like I said, I'm a member and I've gotten so much value from the community
[00:00:59.120 --> 00:01:02.320]   because you're getting advice and feedback from people in a similar
[00:01:02.320 --> 00:01:06.280]   situation to you on everything from your investment portfolio, to your
[00:01:06.280 --> 00:01:09.240]   children's education, to finding a concierge doctor.
[00:01:09.240 --> 00:01:13.160]   So many of these conversations aren't happening anywhere else online.
[00:01:13.160 --> 00:01:17.440]   So if you have more than 2.2 million in investable assets, which is their
[00:01:17.440 --> 00:01:22.000]   minimum for membership, I encourage you to check out Longangle and it's totally
[00:01:22.000 --> 00:01:22.800]   free to join.
[00:01:22.800 --> 00:01:26.160]   Just go to longangle.com to learn more.
[00:01:26.400 --> 00:01:29.960]   And if you choose to apply, be sure to let them know you heard about it here.
[00:01:29.960 --> 00:01:34.640]   Again, that's longangle.com.
[00:01:34.640 --> 00:01:41.720]   Hello, and welcome to another episode of All The Hacks, a show about upgrading
[00:01:41.720 --> 00:01:43.480]   your life, money, and travel.
[00:01:43.480 --> 00:01:45.800]   If you're new here, I'm your host, Chris Hutchins.
[00:01:45.800 --> 00:01:49.440]   And usually on the show, I'm sitting down with the world's best experts to
[00:01:49.440 --> 00:01:53.080]   learn the strategies, tactics, and frameworks they use to improve and
[00:01:53.080 --> 00:01:54.280]   optimize their lives.
[00:01:54.640 --> 00:01:59.280]   That means optimizing travel, think flights, hotels, points, and miles, your
[00:01:59.280 --> 00:02:04.160]   money, think savings, investing, getting deals, as well as life and work, think
[00:02:04.160 --> 00:02:08.320]   happiness, leadership, relationships, negotiation, and so much more.
[00:02:08.320 --> 00:02:13.560]   And in my last episode, I talked with Adam Levin about cybersecurity, identity
[00:02:13.560 --> 00:02:15.640]   theft, fraud, and a lot more.
[00:02:15.640 --> 00:02:20.560]   Well, that episode sent me down a serious rabbit hole of research about everything
[00:02:20.560 --> 00:02:24.880]   I can be doing to protect myself and my family online, so I thought it'd be
[00:02:24.880 --> 00:02:28.400]   helpful to share everything I learned so you know what you might want to do
[00:02:28.400 --> 00:02:29.000]   yourself.
[00:02:29.000 --> 00:02:32.160]   We're going to cover protecting everything from your devices, your
[00:02:32.160 --> 00:02:36.960]   identity, to your online accounts, your credit, and trying to remove all your
[00:02:36.960 --> 00:02:38.240]   personal data online.
[00:02:38.240 --> 00:02:42.320]   An incredible amount of time went into this episode, so I'd really love to know
[00:02:42.320 --> 00:02:46.000]   if it's valuable to you, and if so, it would mean the world to me if you shared
[00:02:46.000 --> 00:02:49.920]   it with your friends, your family, maybe your parents, and anyone else you think
[00:02:49.960 --> 00:02:51.200]   would benefit from listening.
[00:02:51.200 --> 00:02:55.320]   Thank you so much in advance for doing that, and let's get started with
[00:02:55.320 --> 00:02:56.600]   protecting your devices.
[00:02:56.600 --> 00:03:04.240]   So simple, quick thing is making sure that you have encryption turned on on
[00:03:04.240 --> 00:03:04.880]   your computer.
[00:03:04.880 --> 00:03:07.400]   If it's a Mac, you turn on FileVault.
[00:03:07.400 --> 00:03:08.160]   It's simple.
[00:03:08.160 --> 00:03:12.280]   If it's Windows, you can go into device encryption and enable that.
[00:03:12.280 --> 00:03:15.720]   The reason I think this is so important is if someone has access to your
[00:03:15.720 --> 00:03:20.200]   computer, you're able to get access to what's on your hard drive if it's not
[00:03:20.200 --> 00:03:20.840]   encrypted.
[00:03:20.840 --> 00:03:23.640]   You might think, "Oh, they can't log into Windows, they can't log into your
[00:03:23.640 --> 00:03:26.400]   computer," but if they have your physical hard drive, get your information.
[00:03:26.400 --> 00:03:28.200]   So definitely turn on encryption.
[00:03:28.200 --> 00:03:31.840]   Also, I just got an email from a listener named Randy who suggested if you want to
[00:03:31.840 --> 00:03:35.280]   create a secure FileVault on your computer for sensitive documents, check out
[00:03:35.280 --> 00:03:39.680]   VeriCrypt, but you can also use disk images on Mac to create a secure disk as
[00:03:39.680 --> 00:03:40.080]   well.
[00:03:40.080 --> 00:03:43.640]   He also suggested that if you're looking to store stuff in the cloud, despite that
[00:03:43.640 --> 00:03:46.720]   they're supposed to be secure, you might want to go a little bit further.
[00:03:46.720 --> 00:03:51.600]   He suggested checking out Cryptomator or BoxCryptor as two ways that you can store
[00:03:51.600 --> 00:03:52.760]   stuff securely in the cloud.
[00:03:52.760 --> 00:03:54.400]   So thanks, Randy, for those suggestions.
[00:03:54.400 --> 00:03:58.320]   Now, on your phone, I would recommend setting up a PIN or a password to unlock
[00:03:58.320 --> 00:04:03.000]   the device, and I would set your phone to automatically erase after a certain number
[00:04:03.000 --> 00:04:04.000]   of failed attempts.
[00:04:04.000 --> 00:04:08.800]   You can also set an option in iOS to not connect to USB devices while the phone's
[00:04:08.800 --> 00:04:12.360]   locked, and you can also turn off what notifications show up when your phone's
[00:04:12.360 --> 00:04:12.760]   locked.
[00:04:13.160 --> 00:04:17.560]   Another thing that I want to talk about is your data when you're on your device.
[00:04:17.560 --> 00:04:22.400]   So I've got a question actually about VPNs and browsing online and when it's safe
[00:04:22.400 --> 00:04:23.600]   and using public Wi-Fi.
[00:04:23.600 --> 00:04:26.520]   So there's really two things that I recommend here.
[00:04:26.520 --> 00:04:32.520]   So one is the DNS servers that you use, which is when you type into Google.com, a
[00:04:32.520 --> 00:04:36.240]   DNS server will translate that to where you're actually trying to go.
[00:04:36.240 --> 00:04:41.040]   And by default, your computer's probably using the DNS server from your ISP, your
[00:04:41.040 --> 00:04:44.480]   Comcast, your Verizon, whoever's providing your internet service.
[00:04:44.480 --> 00:04:49.680]   I don't love the idea of letting those services see where all my traffic's going
[00:04:49.680 --> 00:04:52.520]   because they're notorious for selling that anonymized data.
[00:04:52.520 --> 00:04:54.840]   But I mostly don't like that it's slow.
[00:04:54.840 --> 00:04:58.560]   And so I recommend CloudFlare is my preferred DNS.
[00:04:58.560 --> 00:05:03.480]   If you search CloudFlare 1.1.1.1, you can go figure it out and set it up.
[00:05:03.480 --> 00:05:06.080]   They have an iOS app that lets you set that up also.
[00:05:06.080 --> 00:05:07.560]   So I think it's a great option.
[00:05:07.560 --> 00:05:09.760]   But the question of VPNs also comes up.
[00:05:10.320 --> 00:05:16.200]   So most traffic nowadays is all happening over HTTPS, which means it's secure and
[00:05:16.200 --> 00:05:19.320]   encrypted. So if you're in a coffee shop and you log into your bank, I don't think
[00:05:19.320 --> 00:05:25.800]   you need to worry about someone else there or the cafe owner or their ISP getting
[00:05:25.800 --> 00:05:27.680]   your banking credentials and logging into your account.
[00:05:27.680 --> 00:05:28.880]   That I wouldn't worry about.
[00:05:28.880 --> 00:05:31.720]   However, they will know what sites you browse.
[00:05:31.720 --> 00:05:36.400]   So if you're concerned with privacy and you don't want whoever's operating the
[00:05:36.400 --> 00:05:40.560]   cafe or your ISP knowing where you're going on the Internet, what sites you're
[00:05:40.560 --> 00:05:43.120]   visiting, they won't be able to see your logins, they won't be able to see what
[00:05:43.120 --> 00:05:45.880]   you're doing on the sites, but they will see what you're accessing.
[00:05:45.880 --> 00:05:50.840]   If that's important to you, you can absolutely use a VPN when you're not at home.
[00:05:50.840 --> 00:05:55.120]   But I will say I don't think you need to worry about the VPN for the purpose of
[00:05:55.120 --> 00:05:57.000]   someone getting access to your logins.
[00:05:57.000 --> 00:06:01.320]   I would say when traveling internationally, there's two other reasons to use a VPN.
[00:06:01.480 --> 00:06:06.200]   One, there are a lot of countries whose data collection and privacy rules are not
[00:06:06.200 --> 00:06:07.720]   nearly what they are in the US.
[00:06:07.720 --> 00:06:10.120]   And by the way, the US is not at the top either.
[00:06:10.120 --> 00:06:14.360]   So if you were in China, if you were in other states where you're worried about
[00:06:14.360 --> 00:06:16.840]   that, you can use a VPN to encrypt everything you're doing.
[00:06:16.840 --> 00:06:22.600]   You can also use a VPN to connect back to whatever country you're from and maybe be
[00:06:22.600 --> 00:06:26.320]   able to access things like Netflix when you're online in another country.
[00:06:26.320 --> 00:06:31.000]   I've heard a lot of good recommendations from others using Cloudflare has a service
[00:06:31.000 --> 00:06:33.920]   called Warp, which helps protect all of your traffic.
[00:06:33.920 --> 00:06:37.000]   It doesn't let you do the specify a new location.
[00:06:37.000 --> 00:06:40.800]   I've had a lot of people recommend ExpressVPN for that service as well.
[00:06:40.800 --> 00:06:45.000]   And then finally, in your browser, if you want to prevent ads from being able to
[00:06:45.000 --> 00:06:49.640]   see who you are, you can use extensions like uBlock Origin and other ad blockers
[00:06:49.640 --> 00:06:50.160]   in Chrome.
[00:06:50.160 --> 00:06:56.440]   If you're on an iPhone and you pay for iCloud Plus, Safari has, I think it's
[00:06:56.440 --> 00:07:00.480]   called Private Relay, which will also provide some protection browsing online.
[00:07:00.640 --> 00:07:02.800]   And I think they add the same thing to the mail app.
[00:07:02.800 --> 00:07:05.240]   So that's another option for iOS users.
[00:07:05.240 --> 00:07:07.320]   So that's kind of device.
[00:07:07.320 --> 00:07:08.960]   But let's talk about logins.
[00:07:08.960 --> 00:07:13.000]   Hopefully from the earlier episode and plenty of other episodes, you're all using
[00:07:13.000 --> 00:07:14.120]   password managers.
[00:07:14.120 --> 00:07:18.240]   My personal favorite is 1Password, allthehacks.com/1password.
[00:07:18.240 --> 00:07:22.680]   If you haven't checked it out, I will call out that 1Password is a cloud hosted
[00:07:22.680 --> 00:07:23.520]   password manager.
[00:07:23.520 --> 00:07:27.760]   That means your credentials, while stored and encrypted with 1Password on their
[00:07:27.760 --> 00:07:31.080]   servers, they don't actually have access to your logins because they don't have
[00:07:31.080 --> 00:07:34.360]   your master password, but they are stored in the cloud.
[00:07:34.360 --> 00:07:38.320]   So there are other options if you want to self-host your own password manager files
[00:07:38.320 --> 00:07:39.160]   on your devices.
[00:07:39.160 --> 00:07:44.600]   For me, I think the convenience is worth using something in the cloud, but totally
[00:07:44.600 --> 00:07:46.720]   understand why you might want to hold them locally.
[00:07:46.720 --> 00:07:53.560]   So I use 1Password to go into all of my logins out there, and I want to really
[00:07:53.560 --> 00:07:56.840]   make sure that I have a different password for every single site.
[00:07:57.360 --> 00:08:00.240]   But there are a few other things I think you can do beyond just that.
[00:08:00.240 --> 00:08:03.240]   So one is using secondary emails.
[00:08:03.240 --> 00:08:10.200]   So when someone's trying to, let's say, hack into your Gmail or hack into your
[00:08:10.200 --> 00:08:14.920]   bank account, most likely the email address they're going to try to use is the
[00:08:14.920 --> 00:08:18.640]   email address that is found all over the internet for you, your most common email
[00:08:18.640 --> 00:08:19.040]   address.
[00:08:19.040 --> 00:08:23.840]   But you can go create a secondary email, either on a per login basis or just one
[00:08:23.840 --> 00:08:25.840]   you use for all your important logins.
[00:08:26.040 --> 00:08:28.360]   You can use the plus feature on Gmail.
[00:08:28.360 --> 00:08:35.200]   So if your email address is John Doe at Gmail, you can say John Doe plus Twitter
[00:08:35.200 --> 00:08:40.600]   at Gmail, and it'll always get rerouted to your Gmail, but the email address will
[00:08:40.600 --> 00:08:41.200]   be different.
[00:08:41.200 --> 00:08:45.440]   And someone who knows John Doe at Gmail might not know what you put in after the
[00:08:45.440 --> 00:08:49.840]   plus sign, and Twitter will know that you have to have the plus sign because that's
[00:08:49.840 --> 00:08:50.560]   your email login.
[00:08:50.560 --> 00:08:54.880]   Your email at Twitter wouldn't be John Doe at, it would be John Doe plus Twitter.
[00:08:54.880 --> 00:08:56.160]   And so you have to know that.
[00:08:56.160 --> 00:09:00.400]   So there's a couple options there for how you can set that up for usernames.
[00:09:00.400 --> 00:09:04.120]   I would also recommend not just using your name, maybe use something that's a
[00:09:04.120 --> 00:09:08.040]   little different, and maybe even do something slightly different for each
[00:09:08.040 --> 00:09:10.280]   site so that your username isn't obvious.
[00:09:10.280 --> 00:09:15.000]   This is all to help prevent people from taking your username or your email
[00:09:15.000 --> 00:09:17.280]   address and trying to reset your password.
[00:09:17.280 --> 00:09:19.400]   You can also do a couple other things.
[00:09:19.400 --> 00:09:22.880]   So I definitely recommend changing your mother's maiden name.
[00:09:23.040 --> 00:09:25.480]   It's too easy to find that kind of information online.
[00:09:25.480 --> 00:09:30.000]   So you can just put any other phrase, word, combination of letters in there.
[00:09:30.000 --> 00:09:34.200]   For a lot of services like banks or your cell phone provider, you can call up and
[00:09:34.200 --> 00:09:38.240]   usually request that they add some increased security to your account.
[00:09:38.240 --> 00:09:39.080]   I would do that.
[00:09:39.080 --> 00:09:42.120]   And then last, if you have those security questions, that's like, "What street did
[00:09:42.120 --> 00:09:42.720]   you grow up?"
[00:09:42.720 --> 00:09:44.160]   Or, "Who is your high school teacher?"
[00:09:44.160 --> 00:09:46.960]   Or, "What's your paternal grandmother's first name?"
[00:09:46.960 --> 00:09:49.280]   You can always just make up an answer.
[00:09:49.280 --> 00:09:52.240]   The answer does not have to be the true answer.
[00:09:52.400 --> 00:09:55.080]   And if you use a password manager, you could store those security
[00:09:55.080 --> 00:09:56.200]   questions there if you want.
[00:09:56.200 --> 00:09:57.640]   You can store them somewhere else.
[00:09:57.640 --> 00:09:59.520]   There are a lot of options for where you can put them.
[00:09:59.520 --> 00:10:05.080]   When it comes to two-factor authentication, given how easy it is for someone to
[00:10:05.080 --> 00:10:10.360]   hijack your phone number, whether that's through SIM swapping or a good friend of
[00:10:10.360 --> 00:10:15.560]   mine had this happen to him recently, someone was able to call AT&T and convince
[00:10:15.560 --> 00:10:17.120]   them to turn on call forwarding.
[00:10:17.120 --> 00:10:19.280]   So they didn't actually take his SIM card.
[00:10:19.280 --> 00:10:21.160]   They didn't actually redirect anything.
[00:10:21.160 --> 00:10:22.400]   His phone still worked.
[00:10:22.400 --> 00:10:26.640]   But for a few days, he didn't realize that every time someone called his phone, it
[00:10:26.640 --> 00:10:31.520]   got redirected to someone else, which meant they were able to go to sites online
[00:10:31.520 --> 00:10:34.360]   and say, "Don't text me the code, but call me with the code."
[00:10:34.360 --> 00:10:38.520]   And this other random person was able to get those calls rerouted to them.
[00:10:38.520 --> 00:10:45.680]   So, if it's possible, I would recommend turning off SMS authentication everywhere
[00:10:46.000 --> 00:10:51.400]   and using an authentication app, like a time-based one-time password, those six
[00:10:51.400 --> 00:10:55.040]   digit codes that refresh, you can put them in the Google Authenticator app.
[00:10:55.040 --> 00:10:59.800]   I'm going to get to other places to put them, but if you have to use SMS, I would
[00:10:59.800 --> 00:11:03.560]   say it would be ideal if you used a number that's not your primary phone number.
[00:11:03.560 --> 00:11:06.000]   So you could set up a free Google voice number.
[00:11:06.000 --> 00:11:09.680]   If you have a Google voice number and you've been giving it out freely over the
[00:11:09.680 --> 00:11:13.760]   past few years, you can always just change that Google voice number for free and move
[00:11:13.760 --> 00:11:18.080]   your two-factor authentication codes where you have to have SMS to Google voice.
[00:11:18.080 --> 00:11:20.480]   Obviously, if you can turn off SMS, even better.
[00:11:20.480 --> 00:11:22.640]   Security keys.
[00:11:22.640 --> 00:11:28.960]   I recently bought a YubiKey 5C NFC, which lets you use USB-C and NFC, so you can tap
[00:11:28.960 --> 00:11:31.760]   the back of your phone and you don't have to actually plug it in.
[00:11:31.760 --> 00:11:33.640]   YubiKey has a bunch of other options.
[00:11:33.640 --> 00:11:38.480]   I'm recently a very big fan of security keys because you have to physically have
[00:11:38.480 --> 00:11:42.880]   the key with you, so you can have set up backups and have multiple keys in case you
[00:11:42.880 --> 00:11:46.120]   lose them. Obviously, the downside is if you didn't bring your key and you need to
[00:11:46.120 --> 00:11:48.160]   log in, it's very difficult to do that.
[00:11:48.160 --> 00:11:51.400]   There are some backup codes that you can set up, but for the most part, you need
[00:11:51.400 --> 00:11:56.000]   your key. So it might be too much for some people, but I really like that added
[00:11:56.000 --> 00:12:00.760]   security. As for authenticator codes, you can put them in the authenticator app.
[00:12:00.760 --> 00:12:05.840]   You can also put them in 1Password, which was something that I was doing, but
[00:12:05.840 --> 00:12:11.640]   realized that by having my authenticator codes in 1Password, I was not necessarily
[00:12:11.640 --> 00:12:13.440]   having two-factor authentication.
[00:12:13.440 --> 00:12:17.520]   I wouldn't say it might not be perfect two-factor authentication to store your
[00:12:17.520 --> 00:12:22.200]   authenticator codes in your 1Password because your Gmail password might also be
[00:12:22.200 --> 00:12:26.000]   in there. However, if someone were to compromise your Gmail password or your
[00:12:26.000 --> 00:12:31.680]   Facebook password, but not your 1Password login, then you would actually have some
[00:12:31.680 --> 00:12:35.480]   protection because they would need both your Gmail password and your 1Password
[00:12:35.480 --> 00:12:36.840]   login to be able to get in.
[00:12:36.840 --> 00:12:41.360]   And if you have 1Password secured with a security key, you're making 1Password
[00:12:41.520 --> 00:12:42.840]   two-factor authenticated.
[00:12:42.840 --> 00:12:47.160]   So you can have a little bit of protection putting your OTP codes into 1Password.
[00:12:47.160 --> 00:12:52.440]   And I think the convenience of on mobile and web being able to copy and paste your
[00:12:52.440 --> 00:12:56.800]   two-factor codes from 1Password directly in and autofill them is certainly a
[00:12:56.800 --> 00:13:02.080]   convenience. But for people who really want true two-factor auth, you can use a
[00:13:02.080 --> 00:13:06.400]   service like Google Authenticator or OTP Auth is another app and store those
[00:13:06.400 --> 00:13:10.560]   locally. You can use the Authy app as well, which actually stores those codes in
[00:13:10.560 --> 00:13:13.680]   the cloud so you can transfer them between devices, but they're in at least a
[00:13:13.680 --> 00:13:15.680]   different service than 1Password.
[00:13:15.680 --> 00:13:21.440]   So I haven't experimented yet with Yubikey's ability to store one-time passwords
[00:13:21.440 --> 00:13:25.480]   on your security key, which would be a different place to store them than OTP
[00:13:25.480 --> 00:13:30.040]   Auth or the app. But it's something that I might play around with in the future.
[00:13:30.040 --> 00:13:34.080]   And finally, once you have a security key set up, you're now eligible for Google's
[00:13:34.080 --> 00:13:36.280]   advanced protection program, which is awesome.
[00:13:36.760 --> 00:13:41.200]   So that just adds an increased layer of security to your Gmail account, which is
[00:13:41.200 --> 00:13:44.480]   something that if this is important to you, I would definitely take a look at.
[00:13:44.480 --> 00:13:50.040]   It does add a couple restrictions for authenticating third-party services to your
[00:13:50.040 --> 00:13:53.200]   Gmail, to your Google Drive and that kind of stuff.
[00:13:53.200 --> 00:13:56.640]   It disables app passwords, but it does add a lot more security.
[00:13:56.640 --> 00:14:00.480]   So if that's important to you, then I would definitely check out Google Advanced
[00:14:00.480 --> 00:14:04.760]   Protection. But you do need two security keys, a primary and a backup to be able to
[00:14:04.760 --> 00:14:07.960]   turn that on. Finally, if you're going through all these Gmail settings, I do
[00:14:07.960 --> 00:14:11.720]   recommend that you look at all the services that you've authed, and this is true on
[00:14:11.720 --> 00:14:15.920]   Google, on Facebook, on Twitter, to go in and see, is there an app that I
[00:14:15.920 --> 00:14:20.880]   authenticated to my Gmail five years ago that I gave all of these permissions to?
[00:14:20.880 --> 00:14:24.560]   And so I would definitely go check out what you've authenticated to all of your
[00:14:24.560 --> 00:14:29.400]   services and potentially delete a lot of them or even refresh them, because
[00:14:29.400 --> 00:14:32.800]   sometimes you've set them up so long ago that there weren't as many options.
[00:14:33.040 --> 00:14:36.120]   There might have just been auth Twitter or auth Google.
[00:14:36.120 --> 00:14:40.880]   Now there might be more options like allow this thing to only read my Drive files,
[00:14:40.880 --> 00:14:43.000]   but not make changes to or delete things.
[00:14:43.000 --> 00:14:44.240]   So I definitely would go do that.
[00:14:44.240 --> 00:14:49.880]   I want to tell you all about the most amazing way to buy a second home, and I know
[00:14:49.880 --> 00:14:53.040]   because we actually bought one for one eighth the cost.
[00:14:53.040 --> 00:14:55.320]   And don't worry, I'm not talking timeshares.
[00:14:55.320 --> 00:14:59.240]   I'm talking about Picasso, and I'm excited to partner with them for this episode.
[00:14:59.240 --> 00:15:00.280]   So how does it work?
[00:15:00.400 --> 00:15:05.760]   Picasso buys amazing luxury homes in over 40 world-class destinations, creates an
[00:15:05.760 --> 00:15:10.000]   LLC for each home, and you can buy as little as one eighth of the property.
[00:15:10.000 --> 00:15:11.440]   But it doesn't stop there.
[00:15:11.440 --> 00:15:16.480]   Picasso also professionally manages the home, handling design, cleaning,
[00:15:16.480 --> 00:15:19.400]   bills, repairs, taxes, and more.
[00:15:19.400 --> 00:15:22.720]   And the scheduling system makes it fair and equitable for
[00:15:22.720 --> 00:15:24.280]   everyone to enjoy their home.
[00:15:24.280 --> 00:15:28.200]   When we found Picasso, it felt like it was made just for us.
[00:15:28.400 --> 00:15:32.600]   That same week we found the perfect place in Napa, we toured it, and
[00:15:32.600 --> 00:15:34.080]   the next week we were closing.
[00:15:34.080 --> 00:15:38.440]   Since then, it's truly become our second home, and it's been so amazing.
[00:15:38.440 --> 00:15:40.640]   And it's true real estate ownership.
[00:15:40.640 --> 00:15:45.680]   Owners can sell at any time, set their own price, and tap into Picasso's
[00:15:45.680 --> 00:15:47.280]   active marketplace of buyers.
[00:15:47.280 --> 00:15:53.840]   In fact, on average, Picasso listings resell in 12 days with a 12% annualized gain.
[00:15:54.040 --> 00:16:00.200]   For a modern way to buy and own a second home, go to allthehacks.com/picaso,
[00:16:00.200 --> 00:16:04.520]   where our listeners will get a free Picasso access account, which means you
[00:16:04.520 --> 00:16:09.480]   can see new listings before they go on the website and get up to $10,000
[00:16:09.480 --> 00:16:11.200]   in credit towards closing costs.
[00:16:11.200 --> 00:16:14.920]   Again, that's allthehacks.com/picaso.
[00:16:14.920 --> 00:16:17.840]   P-A-C-A-S-O.
[00:16:17.840 --> 00:16:23.200]   I wish I could say that I'm eating a fully balanced diet every day, but the
[00:16:23.200 --> 00:16:25.320]   reality is that I am definitely not.
[00:16:25.320 --> 00:16:29.960]   So I love having an easy way to get my daily nutritional insurance, which is
[00:16:29.960 --> 00:16:33.640]   why I kickstart my day with Athletic Greens, and I am excited to be
[00:16:33.640 --> 00:16:35.280]   partnering with them for this episode.
[00:16:35.280 --> 00:16:39.280]   I started taking it because I wanted to see what all the hype was about, and I've
[00:16:39.280 --> 00:16:41.760]   kept it in my daily routine for months.
[00:16:41.760 --> 00:16:45.920]   Every morning, I mix it up with some cold water, add a few ice cubes, it
[00:16:45.920 --> 00:16:49.960]   tastes so good when it's cold, and I head to my office feeling focused and
[00:16:49.960 --> 00:16:53.520]   energized for the day, which is a feeling I absolutely love.
[00:16:53.520 --> 00:16:57.920]   I also love that it's made from 75 high-quality vitamins, minerals, and
[00:16:57.920 --> 00:17:01.200]   superfoods, and contains less than one gram of sugar.
[00:17:01.200 --> 00:17:05.360]   It also has no GMOs, nasty chemicals, or artificial anything.
[00:17:05.360 --> 00:17:09.720]   To make giving it a try easy, Athletic Greens is going to give you a free
[00:17:09.720 --> 00:17:14.280]   one-year supply of immune-supporting vitamin D and five free travel
[00:17:14.280 --> 00:17:15.960]   packs with your first purchase.
[00:17:16.360 --> 00:17:21.280]   All you have to do is visit allthehacks.com/athleticgreens.
[00:17:21.280 --> 00:17:26.800]   Again, that's allthehacks.com/athleticgreens to take ownership over
[00:17:26.800 --> 00:17:30.320]   your health and pick up the ultimate daily nutritional insurance.
[00:17:30.320 --> 00:17:32.560]   So that's passwords and logins.
[00:17:32.560 --> 00:17:35.800]   I want to talk a little bit about financial stuff, your credit.
[00:17:35.800 --> 00:17:38.280]   So I definitely recommend monitoring your credit.
[00:17:38.280 --> 00:17:41.200]   I have Experian Alerts set up for free.
[00:17:41.200 --> 00:17:44.240]   I use Credit Karma, which is also free to get alerts.
[00:17:44.560 --> 00:17:48.600]   Chase also has a free identity monitoring product called Chase Credit
[00:17:48.600 --> 00:17:50.440]   Journey, which is worth looking into.
[00:17:50.440 --> 00:17:54.160]   Also, if you've ever been part of a security breach, the company that was
[00:17:54.160 --> 00:17:57.920]   breached usually offers a free premium credit monitoring service for at least
[00:17:57.920 --> 00:17:59.960]   one year, so that could be an option as well.
[00:17:59.960 --> 00:18:02.280]   For me so far, I think those alerts work.
[00:18:02.280 --> 00:18:04.440]   I don't pay for an extra service.
[00:18:04.440 --> 00:18:08.000]   However, I do think it makes a lot of sense for people to freeze their credit.
[00:18:08.000 --> 00:18:12.520]   So you can go into Experian, Equifax, and TransUnion and go freeze your credit.
[00:18:12.680 --> 00:18:17.120]   And that means that anytime someone is trying to open up a new credit card, open
[00:18:17.120 --> 00:18:22.400]   up a new loan for an automobile or a mortgage or anything, you have to unfreeze
[00:18:22.400 --> 00:18:23.400]   your credit to do that.
[00:18:23.400 --> 00:18:25.880]   So I definitely think freezing your credit makes sense.
[00:18:25.880 --> 00:18:30.600]   Even I, who like opening up new cards and getting signup bonuses, it's not hard to
[00:18:30.600 --> 00:18:35.200]   go in, temporarily lift that freeze, apply, and then refreeze those accounts.
[00:18:35.200 --> 00:18:38.960]   Or if it's temporary, you set it to automatically reinstate the freeze.
[00:18:39.120 --> 00:18:44.080]   I did look into credit fraud alerts, which you can set up for one year easily or a
[00:18:44.080 --> 00:18:48.160]   longer period of time, I think if you're in the military or if you have been a
[00:18:48.160 --> 00:18:51.520]   victim of identity theft, but if you're going to go ahead and freeze your credit,
[00:18:51.520 --> 00:18:55.480]   everything I've read is that it's a little bit redundant because fraud alerts
[00:18:55.480 --> 00:18:59.440]   will kind of tell the financial institutions to take a little bit of extra
[00:18:59.440 --> 00:19:01.240]   precaution when opening up an account.
[00:19:01.240 --> 00:19:04.320]   But if your credit's frozen, then they won't open it up at all.
[00:19:04.320 --> 00:19:06.840]   So I don't know if fraud alerts make sense if you're willing to freeze your
[00:19:06.840 --> 00:19:09.480]   credit, but if for some reason you don't want to freeze your credit, I would
[00:19:09.480 --> 00:19:11.200]   definitely look at setting up fraud alerts.
[00:19:11.200 --> 00:19:15.600]   I actually, in the process of doing research here, was recommended to freeze
[00:19:15.600 --> 00:19:20.000]   my credit on two new credit bureaus that I never even really knew existed.
[00:19:20.000 --> 00:19:22.840]   One is ChexSystems and one is Inovus.
[00:19:22.840 --> 00:19:25.600]   The three that everyone should be having their stuff frozen on are
[00:19:25.600 --> 00:19:29.200]   Experian, Equifax, and TransUnion, but I didn't know about those other two.
[00:19:29.200 --> 00:19:32.600]   I'll put some links in the show notes for everything I'm talking about here.
[00:19:32.600 --> 00:19:35.280]   So it's going to be a really detailed show notes, or if you go to
[00:19:35.280 --> 00:19:41.360]   allthehacks.com/78, which is this episode, you'll get a link to everything
[00:19:41.360 --> 00:19:43.600]   I'm talking about, lots of details there.
[00:19:43.600 --> 00:19:47.720]   So I froze my credit on those two new credit bureaus because I didn't
[00:19:47.720 --> 00:19:49.400]   know I should, and I'm glad I did.
[00:19:49.400 --> 00:19:52.240]   One thing you can do when it comes to your credit is there's a website,
[00:19:52.240 --> 00:19:58.120]   optoutprescreen.com, which lets you opt out of all of the mail you get with
[00:19:58.120 --> 00:19:59.960]   different offers for new credit cards.
[00:19:59.960 --> 00:20:04.520]   And I was so tempted to do it because we get so many credit card offers at home,
[00:20:04.920 --> 00:20:10.760]   but I would say one in a thousand of them is for an offer that is sometimes
[00:20:10.760 --> 00:20:12.040]   better than all the other offers.
[00:20:12.040 --> 00:20:16.600]   So I remember one time, I think I got an Amex Platinum 150,000 point signup
[00:20:16.600 --> 00:20:20.160]   bonus in the mail that you could only get if you got the letter in the mail.
[00:20:20.160 --> 00:20:24.400]   So for me, I'm willing to deal with a bunch of junk mail about credit card
[00:20:24.400 --> 00:20:25.920]   offers on the off chance I get one.
[00:20:25.920 --> 00:20:29.840]   But if you'd rather just get rid of them, optoutprescreen.com is a good option.
[00:20:29.840 --> 00:20:33.320]   And finally, I talked about reviewing all the services you've offed to
[00:20:33.320 --> 00:20:37.880]   Google and Facebook and Twitter, but lately in the last few years, financial
[00:20:37.880 --> 00:20:40.760]   institutions have been adopting something called open banking.
[00:20:40.760 --> 00:20:46.360]   So if you've ever used Mint or a bunch of other products online to aggregate
[00:20:46.360 --> 00:20:50.440]   your financial data, it used to be that you would go in and type in your Chase
[00:20:50.440 --> 00:20:54.560]   login and password, and they would just go crawl the data from your Chase
[00:20:54.560 --> 00:20:56.880]   account and aggregate it in one place.
[00:20:56.880 --> 00:21:02.320]   Recently, a lot of the banks have adopted a similar authentication service
[00:21:02.360 --> 00:21:06.480]   called open banking, where they redirect you to Chase's site, you log into your
[00:21:06.480 --> 00:21:11.200]   Chase account and you approve sharing your information with Mint or like
[00:21:11.200 --> 00:21:13.240]   Expensify does it for expense reporting.
[00:21:13.240 --> 00:21:18.720]   So given that, I would encourage everyone to go look on Chase or Capital One or
[00:21:18.720 --> 00:21:23.800]   any other banks that you have an account at, Wells Fargo, et cetera, and go look
[00:21:23.800 --> 00:21:27.640]   in your settings to see who you're sharing your data with, because you might
[00:21:27.640 --> 00:21:31.640]   be sharing your bank data with an app you downloaded to, you know, explore your
[00:21:31.640 --> 00:21:35.840]   money, deleted the app, but forgot that you're still sharing your data with them.
[00:21:35.840 --> 00:21:39.120]   So that's another one when it comes to your money and things to do there.
[00:21:39.120 --> 00:21:42.640]   When it comes to just your general identity, I already mentioned making
[00:21:42.640 --> 00:21:46.720]   sure you ask for increased security from a lot of your services like banks and
[00:21:46.720 --> 00:21:52.760]   cell phones, but I would also go to have I been pawned pwnd.com and I'll link to
[00:21:52.760 --> 00:21:54.880]   that in the show notes and just set up alerts.
[00:21:54.880 --> 00:22:00.760]   This is a site that tracks all of the breaches from different companies who
[00:22:01.040 --> 00:22:06.880]   have their databases breached online and expose, unfortunately, your email
[00:22:06.880 --> 00:22:10.720]   address, your information, your logins, your passwords, your phone numbers.
[00:22:10.720 --> 00:22:14.840]   This will show you on a one-time basis, all of the breaches you've been a part
[00:22:14.840 --> 00:22:17.480]   of and what email addresses were leaked there.
[00:22:17.480 --> 00:22:19.520]   So great thing to go look at.
[00:22:19.520 --> 00:22:23.000]   Or if you use one password, they have a feature called Watchtower, which does
[00:22:23.000 --> 00:22:26.080]   this for you already, and will highlight all the logins you have that have been
[00:22:26.080 --> 00:22:29.520]   found in breaches, but you can also set up alerts on your email and your phone
[00:22:29.520 --> 00:22:31.280]   number for new breaches.
[00:22:31.280 --> 00:22:33.800]   So if they find your information in a new breach, they'll let you know.
[00:22:33.800 --> 00:22:35.360]   So that's identity theft.
[00:22:35.360 --> 00:22:39.360]   I want to talk about personal data because this is where I spent an
[00:22:39.360 --> 00:22:42.840]   incredibly large amount of time over the last few weeks.
[00:22:42.840 --> 00:22:46.920]   So in the episode I did with Adam Levin, he talked about how there's all these
[00:22:46.920 --> 00:22:48.520]   data brokers that collect your data.
[00:22:48.520 --> 00:22:51.560]   I was blown away at how many there were.
[00:22:51.560 --> 00:22:57.320]   And if you go online and search for your name and, you know, maybe your street
[00:22:57.320 --> 00:23:01.960]   number and street name in quotes, or search for your phone number in quotes,
[00:23:01.960 --> 00:23:06.480]   or even search your name and the city you live in on Google or Bing or anywhere,
[00:23:06.480 --> 00:23:11.440]   there are so many websites, hundreds I found that have my personal data of my
[00:23:11.440 --> 00:23:14.320]   address and my phone number and all this stuff, family members.
[00:23:14.320 --> 00:23:17.200]   And so I wanted to figure out what to do here.
[00:23:17.200 --> 00:23:19.840]   So I went first and said, you know what?
[00:23:19.840 --> 00:23:20.840]   I want to learn about this.
[00:23:20.840 --> 00:23:22.240]   I'm going to go do it all myself.
[00:23:22.240 --> 00:23:27.040]   And there's actually a really great list of all of the data brokers out there on
[00:23:27.040 --> 00:23:29.120]   GitHub, and I'll link to that in the show notes.
[00:23:29.120 --> 00:23:33.920]   And if you want, you can manually go through all of them and you can request
[00:23:33.920 --> 00:23:34.840]   them, remove your data.
[00:23:34.840 --> 00:23:37.040]   Some of them, it's really simple.
[00:23:37.040 --> 00:23:39.040]   You just give them your email address and remove it.
[00:23:39.040 --> 00:23:42.440]   Some of them you fill out a Google form and who knows how long it will take.
[00:23:42.440 --> 00:23:45.400]   Some of them you have to upload your driver's license.
[00:23:45.400 --> 00:23:49.800]   Some of them you have to send an email and, and some of them make it even harder
[00:23:49.800 --> 00:23:51.200]   than all of those things.
[00:23:51.200 --> 00:23:52.720]   And you, maybe you have to send them a letter.
[00:23:53.200 --> 00:23:56.960]   And so fortunately there are states that are adopting new laws.
[00:23:56.960 --> 00:24:02.720]   And so in California, we have the CCPA, which makes companies and data brokers
[00:24:02.720 --> 00:24:06.600]   need to comply with your requests to delete their data.
[00:24:06.600 --> 00:24:11.320]   And so if you're in California, there are some sites that's like, is this a CCPA
[00:24:11.320 --> 00:24:16.000]   request, which may take longer, but is possible online or is it not?
[00:24:16.000 --> 00:24:17.560]   And then maybe you have to mail something in.
[00:24:17.560 --> 00:24:21.640]   Also, when it comes to removing data, Google has this blog post I'll link to
[00:24:21.720 --> 00:24:25.080]   about some new options for removing your data online and from search.
[00:24:25.080 --> 00:24:29.520]   And then there's also these marketing sites, Axiom and LexisNexis, where
[00:24:29.520 --> 00:24:33.120]   there's personal data there in like marketing databases, and you can
[00:24:33.120 --> 00:24:34.480]   request those be removed.
[00:24:34.480 --> 00:24:37.360]   But I went through this process and I was like, God, I spent.
[00:24:37.360 --> 00:24:41.040]   Dozens of hours trying to delete my information.
[00:24:41.040 --> 00:24:45.520]   And I felt like I was just, it was cat and mouse and I would delete a bunch
[00:24:45.520 --> 00:24:47.560]   and then I would look and there was still a few more.
[00:24:47.560 --> 00:24:51.520]   And so I asked a handful of people I know, one of whom is actually the
[00:24:51.520 --> 00:24:56.200]   person who shared a lot of the info in here, because he's very meticulous
[00:24:56.200 --> 00:24:59.720]   with privacy and security and protecting himself.
[00:24:59.720 --> 00:25:01.480]   I'm not going to name him, but thank you so much.
[00:25:01.480 --> 00:25:03.600]   If you listen for helping me with this episode.
[00:25:03.600 --> 00:25:08.440]   And, you know, he suggested I check out a service called delete me and I did.
[00:25:08.440 --> 00:25:12.000]   And I was like, Oh, wow, here's a company that's just going to do all of this for
[00:25:12.000 --> 00:25:12.280]   you.
[00:25:12.280 --> 00:25:18.040]   And so I actually first checked it out, signed up for it and looked and ran a
[00:25:18.040 --> 00:25:19.280]   process to delete myself.
[00:25:19.280 --> 00:25:23.600]   And even though I thought I had gotten through all the information online for
[00:25:23.600 --> 00:25:28.040]   myself, they still found a handful of sites with my personal info.
[00:25:28.040 --> 00:25:33.600]   So after that, I was like, wow, I spent easily 15, 20 hours deleting my own data.
[00:25:33.600 --> 00:25:37.720]   And then I went through this process with them and they found yet more for around
[00:25:37.720 --> 00:25:38.800]   a hundred dollars.
[00:25:38.800 --> 00:25:41.960]   I could have had someone do all this, save me dozens of hours.
[00:25:41.960 --> 00:25:46.520]   And then they'll continually check on an ongoing basis to find more data because
[00:25:46.520 --> 00:25:48.520]   it turns out that data just keeps popping up.
[00:25:48.520 --> 00:25:52.280]   And actually I reached out to them and said, Hey, I really like your product.
[00:25:52.280 --> 00:25:53.560]   Can we talk about it?
[00:25:53.560 --> 00:25:56.760]   So I got connected with their CEO and then I actually asked them if there was
[00:25:56.760 --> 00:25:57.880]   something we could do together.
[00:25:57.880 --> 00:26:01.400]   And they offered a 20% discount and became a partner of the show.
[00:26:01.400 --> 00:26:03.680]   So I first heard about their product.
[00:26:03.680 --> 00:26:06.400]   I then use their product and then reached out to them.
[00:26:06.400 --> 00:26:13.160]   So if you go to all the hacks.com/delete me, you get 20% off and so far I'm very
[00:26:13.160 --> 00:26:14.240]   happy with the product.
[00:26:14.280 --> 00:26:18.760]   And if you have requests for things that they don't search for, they focus on
[00:26:18.760 --> 00:26:21.880]   personal information on data brokers, but there are a couple other requests I'll
[00:26:21.880 --> 00:26:25.560]   talk about that they have a service where you can ask one of their advisors to help
[00:26:25.560 --> 00:26:26.600]   remove other things.
[00:26:26.600 --> 00:26:30.160]   So if there's other stuff you find online, maybe it's related to real estate or
[00:26:30.160 --> 00:26:33.880]   financial transactions or something, you can actually ask them to help and remove
[00:26:33.880 --> 00:26:34.720]   that as well.
[00:26:34.720 --> 00:26:40.680]   So I'm actually going to bring on Rob from delete me for a minute right now,
[00:26:40.680 --> 00:26:43.840]   because I had some questions that I just couldn't get the answer to.
[00:26:44.000 --> 00:26:47.560]   And I thought it'd be great to have him on for a little bit to just talk a little
[00:26:47.560 --> 00:26:49.600]   bit more about where this data comes from.
[00:26:49.600 --> 00:26:52.520]   Rob, thanks for joining me.
[00:26:52.520 --> 00:26:53.880]   Thanks for having me.
[00:26:53.880 --> 00:26:54.840]   Yeah.
[00:26:54.840 --> 00:26:58.920]   So as people listening know, I've gone through a lot of the process of trying to
[00:26:58.920 --> 00:27:02.520]   really take what I learned in the last episode and put it into action.
[00:27:02.520 --> 00:27:07.640]   And the one that really took way more time than I expected was trying to delete
[00:27:07.640 --> 00:27:08.680]   myself off the internet.
[00:27:08.680 --> 00:27:12.520]   And I had found your service and I thought, Hmm, do I want to try this myself?
[00:27:12.520 --> 00:27:13.160]   Do I not?
[00:27:13.520 --> 00:27:17.200]   I went through the process of trying it myself and then ultimately ended up using
[00:27:17.200 --> 00:27:19.720]   you guys as well and found stuff that I didn't even find.
[00:27:19.720 --> 00:27:22.160]   But I just want to start and understand this problem.
[00:27:22.160 --> 00:27:26.320]   How is everybody getting all this data about people on the internet that we need
[00:27:26.320 --> 00:27:27.240]   to go find and delete?
[00:27:27.240 --> 00:27:27.760]   Yeah.
[00:27:27.760 --> 00:27:33.520]   I mean, what's happened over the last decade or 15 years or so is that the data
[00:27:33.520 --> 00:27:37.560]   that we've all been sharing in our daily activities when we're going online.
[00:27:37.560 --> 00:27:41.840]   And last time I checked, we spent a lot more time online today than we did 10
[00:27:41.840 --> 00:27:42.400]   years ago.
[00:27:42.480 --> 00:27:47.320]   That ultimately is feeding databases, which get traded in sort of a gray
[00:27:47.320 --> 00:27:51.480]   aftermarket behind the scenes where data is bought and sold.
[00:27:51.480 --> 00:27:58.040]   And ultimately a combination of that data and data that's scraped from the public
[00:27:58.040 --> 00:28:03.520]   internet has created vast treasure troves of profiles about every American which
[00:28:03.520 --> 00:28:10.040]   reside in hundreds of data brokers databases today and which they sell to
[00:28:10.040 --> 00:28:12.000]   anyone and everyone that wants to buy it.
[00:28:12.920 --> 00:28:15.200]   And is it as easy as just deleting it all?
[00:28:15.200 --> 00:28:17.600]   Or is it going to pop up next week, next month?
[00:28:17.600 --> 00:28:19.520]   Because there's so many people with this data.
[00:28:19.520 --> 00:28:20.960]   Yeah.
[00:28:20.960 --> 00:28:25.200]   Under today's laws, which hopefully we'll get a chance to talk about, which are
[00:28:25.200 --> 00:28:29.320]   changing and evolving rapidly because of this problem.
[00:28:29.320 --> 00:28:35.280]   Under today's laws, there's no simple way to say, "Hey, remove me once and for all
[00:28:35.280 --> 00:28:36.560]   from your database."
[00:28:36.560 --> 00:28:41.800]   There's simply a way to say, "Hey, you're publishing a link to my profile.
[00:28:41.800 --> 00:28:44.280]   It contains information that I don't want exposed.
[00:28:44.280 --> 00:28:49.800]   My family, my children, my home address, the net worth of my house, my cell phone
[00:28:49.800 --> 00:28:51.880]   number for robocallers," all this kind of stuff.
[00:28:51.880 --> 00:28:54.320]   And you can say, "Hey, opt me out of that.
[00:28:54.320 --> 00:28:58.520]   I don't want that link shown to anybody, period, or resold."
[00:28:58.520 --> 00:29:05.840]   And so the design of our service, and that's Delete Me and similar services
[00:29:05.840 --> 00:29:10.440]   that you can find, have built into it an annual subscription where we relentlessly
[00:29:10.440 --> 00:29:15.920]   go back and monitor and look to see if these data brokers get your information
[00:29:15.920 --> 00:29:17.640]   again, and then republish it.
[00:29:17.640 --> 00:29:20.680]   And a couple of stats I'd love to know.
[00:29:20.680 --> 00:29:24.800]   On average, how many hours does each session save?
[00:29:24.800 --> 00:29:26.680]   Yeah, it's a great question.
[00:29:26.680 --> 00:29:33.000]   Over a year, our average customer will save 60 to 80 hours of their
[00:29:33.000 --> 00:29:34.600]   life through signing up for us.
[00:29:34.600 --> 00:29:37.120]   So we think at $129, that's a pretty good deal.
[00:29:37.480 --> 00:29:42.240]   What percentage of people after that first report have stuff pop up again in
[00:29:42.240 --> 00:29:44.080]   the same places you've already scanned?
[00:29:44.080 --> 00:29:47.840]   Is that 90% of people that comes back or how frequent is that?
[00:29:47.840 --> 00:29:57.560]   Yeah, so about 35% of our customers will see their personal information
[00:29:57.560 --> 00:30:03.040]   repopulated in some shape or form at a data broker that we remove
[00:30:03.040 --> 00:30:05.400]   them from after six months.
[00:30:05.400 --> 00:30:06.280]   Wow.
[00:30:06.680 --> 00:30:08.920]   And how have laws affected this?
[00:30:08.920 --> 00:30:13.320]   Right now, we have a patchwork of state laws, more and more going
[00:30:13.320 --> 00:30:14.640]   through different legislatures.
[00:30:14.640 --> 00:30:19.200]   There's laws that have been passed recently in Colorado and Utah and
[00:30:19.200 --> 00:30:23.560]   Vermont, and they continue to evolve mainly based on California, which was
[00:30:23.560 --> 00:30:27.320]   mainly based on the European GDPR and all these laws.
[00:30:27.320 --> 00:30:30.760]   I mean, I'm not a lawyer, I'm an entrepreneur, but they're all this sort
[00:30:30.760 --> 00:30:32.400]   of the same shape and size to me.
[00:30:32.400 --> 00:30:36.320]   When I look at them, they have all these nuances, but they grant citizens
[00:30:36.680 --> 00:30:41.120]   rights to access their data, correct their data if they're mistake being
[00:30:41.120 --> 00:30:45.440]   made that they find and to redact or remove or delete their data
[00:30:45.440 --> 00:30:46.920]   in certain instances as well.
[00:30:46.920 --> 00:30:54.600]   So the really good news here is that no matter where you live, it is almost
[00:30:54.600 --> 00:30:58.880]   guaranteed that you're going to get more rights to wherever your data is located
[00:30:58.880 --> 00:31:01.600]   in any database that's custodying it.
[00:31:02.200 --> 00:31:07.360]   And that's good for everybody, except for the companies that are doing
[00:31:07.360 --> 00:31:09.560]   stuff with your data that you don't want them to do.
[00:31:09.560 --> 00:31:14.080]   They might be less profitable and I'm okay with that, but is it as simple
[00:31:14.080 --> 00:31:17.480]   as if I have a friend that lives in California, can I use their address
[00:31:17.480 --> 00:31:20.520]   when I submit this form so that I can take advantage of some of those
[00:31:20.520 --> 00:31:24.840]   protections or if I open up a PO box in California, is that enough?
[00:31:24.840 --> 00:31:25.680]   It's not simple.
[00:31:25.680 --> 00:31:28.640]   You can't simply claim you're a resident, but we do like playing
[00:31:28.640 --> 00:31:30.880]   tricks on the data brokers ourselves.
[00:31:30.920 --> 00:31:32.120]   So we do what we can.
[00:31:32.120 --> 00:31:36.160]   We use threats under the CCPA for residents of other
[00:31:36.160 --> 00:31:38.520]   States to get things removed.
[00:31:38.520 --> 00:31:42.360]   And a lot of times companies are not mal-intentioned and
[00:31:42.360 --> 00:31:43.560]   sometimes they will just do it.
[00:31:43.560 --> 00:31:46.760]   They want an easy process as well to make things efficient.
[00:31:46.760 --> 00:31:51.080]   So if California sets a certain bar, their processes will often
[00:31:51.080 --> 00:31:53.160]   be extended to other States.
[00:31:53.160 --> 00:31:58.240]   That said, there are some frustrating data brokers out there that I would
[00:31:58.240 --> 00:32:01.560]   call the true bad guys that really just don't give a damn.
[00:32:01.560 --> 00:32:05.000]   How hard can it be for some sites to remove your data?
[00:32:05.000 --> 00:32:08.160]   Yeah, it's a whole litany of things.
[00:32:08.160 --> 00:32:11.480]   I mean, every one of these data brokers has different processes and some of
[00:32:11.480 --> 00:32:13.680]   them are super technical and efficient.
[00:32:13.680 --> 00:32:19.440]   And I'd go so far as to say almost user-friendly, almost, but many of them
[00:32:19.440 --> 00:32:24.440]   are not, and they are increasingly changing them, requiring more identity
[00:32:24.440 --> 00:32:27.040]   verification, "Hey, give us your phone number.
[00:32:27.040 --> 00:32:31.000]   Give us your email," to which we say, "Hey, screw you data broker.
[00:32:31.000 --> 00:32:34.560]   We're going to use aliases so that you never get more of our customer's
[00:32:34.560 --> 00:32:36.560]   information than you already have."
[00:32:36.560 --> 00:32:41.360]   Getting the crew together isn't as easy as it used to be.
[00:32:41.360 --> 00:32:42.080]   I get it.
[00:32:42.080 --> 00:32:46.360]   Life comes at you fast, but trust me, your friends are probably
[00:32:46.360 --> 00:32:47.680]   desperate for a good hang.
[00:32:47.680 --> 00:32:51.720]   So kick 2024 off right by finally hosting that event.
[00:32:51.720 --> 00:32:56.640]   Just make sure you do it the easy way and let our sponsor Drizzly, the go-to
[00:32:56.640 --> 00:32:59.160]   app for drink delivery, take care of the supplies.
[00:32:59.160 --> 00:33:02.200]   All you need to come up with is the excuse to get together.
[00:33:02.200 --> 00:33:04.040]   It doesn't even have to be a good one.
[00:33:04.040 --> 00:33:08.120]   It could be your dog's birthday, that the sun finally came out, or maybe
[00:33:08.120 --> 00:33:10.960]   you just want to celebrate that you got through another week.
[00:33:10.960 --> 00:33:14.840]   With Drizzly, you can make hosting easy by taking the drink run off
[00:33:14.840 --> 00:33:18.200]   your to-do list, which means you can entice your friends to leave their
[00:33:18.200 --> 00:33:20.560]   houses without ever leaving yours.
[00:33:20.560 --> 00:33:24.000]   And since I know you like a good deal, Drizzly compares prices on their
[00:33:24.000 --> 00:33:27.720]   massive selection of beer, wine, and spirits across multiple stores.
[00:33:27.720 --> 00:33:30.680]   So when I really wanted to make a few cocktails while we were hosting
[00:33:30.680 --> 00:33:34.640]   family last week, not only could I get an Italian Amaro delivered in less
[00:33:34.640 --> 00:33:38.720]   than an hour, but I found it for $15 less than my local liquor store.
[00:33:38.720 --> 00:33:43.720]   So whatever the occasion, download the Drizzly app or go to drizzly.com.
[00:33:43.720 --> 00:33:47.640]   That's D-R-I-Z-L-Y.com today.
[00:33:47.640 --> 00:33:51.000]   Must be 21 plus, not available in all locations.
[00:33:52.920 --> 00:33:56.280]   I just want to thank you quick for listening to and supporting the show.
[00:33:56.280 --> 00:33:59.120]   Your support is what keeps this show going.
[00:33:59.120 --> 00:34:04.000]   To get all of the URLs, codes, deals, and discounts from our partners, you
[00:34:04.000 --> 00:34:07.080]   can go to allthehacks.com/deals.
[00:34:07.080 --> 00:34:10.480]   So please consider supporting those who support us.
[00:34:10.480 --> 00:34:14.360]   I think about this in the context of my children and I'm like, wait, there's
[00:34:14.360 --> 00:34:16.840]   no information about them on the internet yet, right?
[00:34:16.840 --> 00:34:19.840]   How soon should I be worried about this for them?
[00:34:19.840 --> 00:34:21.280]   It's a great question.
[00:34:21.280 --> 00:34:26.160]   And I was just on another podcast with somebody talking about a new law in
[00:34:26.160 --> 00:34:30.360]   California that they just passed in addition to the CCPA, which is designed
[00:34:30.360 --> 00:34:35.560]   to protect children's data on social media in ways that it is currently not
[00:34:35.560 --> 00:34:40.840]   protected. And the problem is it, this data starts leaking out about
[00:34:40.840 --> 00:34:42.480]   our kids earlier and earlier.
[00:34:42.480 --> 00:34:46.040]   We give them iPads, we give them access to watch streaming media.
[00:34:46.040 --> 00:34:49.440]   When kids used to watch TV, TV had no idea there was a kid in the room.
[00:34:49.760 --> 00:34:54.640]   Now they know and they know exactly what's being watched, when, for how long.
[00:34:54.640 --> 00:34:58.960]   And they'll eventually connect the dots to exactly who that identity is.
[00:34:58.960 --> 00:35:00.320]   And that's somebody's children.
[00:35:00.320 --> 00:35:04.000]   And I was just talking about this concept, which I think is pretty scary.
[00:35:04.000 --> 00:35:09.960]   And I'm a parent as well, of a digital profile being built up over many, many
[00:35:09.960 --> 00:35:14.360]   years from when somebody is, say, 10 years old to when somebody's post
[00:35:14.360 --> 00:35:19.640]   graduated from college and starting out in their work life and then getting
[00:35:19.640 --> 00:35:24.400]   married and everything, if that digital trail can be correlated from that
[00:35:24.400 --> 00:35:28.880]   child all the way through, and there's the amount of data that we think there
[00:35:28.880 --> 00:35:34.240]   is in these profiles, whether it's Apple, Google, Amazon, who knows?
[00:35:34.240 --> 00:35:38.560]   I think big tech might be able to predict things about your child that
[00:35:38.560 --> 00:35:40.120]   you would never be able to predict.
[00:35:40.120 --> 00:35:44.120]   And for them to have that level of information, I don't know what
[00:35:44.120 --> 00:35:45.000]   they're going to do with it.
[00:35:45.000 --> 00:35:48.520]   Maybe it's innocent and they just want to sell you stuff and maybe they cross
[00:35:48.520 --> 00:35:54.240]   lines, but it's pretty scary to me because I don't know as a parent, you
[00:35:54.240 --> 00:35:58.920]   know, what the possibilities are if big tech ends up with more insight
[00:35:58.920 --> 00:36:00.200]   about my children than I have.
[00:36:00.200 --> 00:36:02.680]   And so what's the solution?
[00:36:02.680 --> 00:36:06.360]   Is it don't let your kids use an iPhone or a Gmail?
[00:36:06.360 --> 00:36:09.360]   Cause that seems like it would not go over well for most families.
[00:36:09.360 --> 00:36:10.480]   It wouldn't.
[00:36:10.480 --> 00:36:12.120]   And I don't think that's the solution.
[00:36:12.120 --> 00:36:15.640]   I think that, you know, modern life requires us to participate
[00:36:15.640 --> 00:36:17.240]   in using modern technology.
[00:36:17.240 --> 00:36:22.760]   So I think the best thing to do as a parent for children is some of the
[00:36:22.760 --> 00:36:26.800]   basics I think you've talked about in some of your other podcasts, you know,
[00:36:26.800 --> 00:36:33.600]   one is do not let them use the same email for all their different accounts.
[00:36:33.600 --> 00:36:38.280]   Whether they have a streaming media account and then a Snapchat account or
[00:36:38.280 --> 00:36:43.680]   an Instagram account, create a different profile with no linkage between a common
[00:36:43.680 --> 00:36:48.560]   email or a common phone number so that the data about them can't be
[00:36:48.560 --> 00:36:49.960]   aggregated and correlated.
[00:36:49.960 --> 00:36:51.560]   That's, I think, very important.
[00:36:51.560 --> 00:36:55.880]   And then I think, you know, the basic things that most parents are already
[00:36:55.880 --> 00:37:02.760]   doing, limiting some, some screen time and teaching them about the do's and
[00:37:02.760 --> 00:37:07.000]   don'ts of social media and actually teaching them about digital advertising
[00:37:07.000 --> 00:37:10.800]   as well, Hey, when you're watching a streaming media, here's who's making
[00:37:10.800 --> 00:37:13.960]   money and why the ads are being sold to you and this kind of thing.
[00:37:13.960 --> 00:37:16.400]   So last thing you've been in this space a lot longer than me.
[00:37:16.400 --> 00:37:19.280]   Is there other data out there that I should be trying to make sure it's
[00:37:19.280 --> 00:37:19.840]   removed?
[00:37:19.840 --> 00:37:24.400]   That's not my contact information or pictures of my house and floor plans
[00:37:24.400 --> 00:37:25.240]   and all that kind of stuff.
[00:37:25.240 --> 00:37:30.080]   Everyone should be Googling themselves on a semi-regular basis and seeing what
[00:37:30.080 --> 00:37:35.040]   those results look like, because you never know what data is out there and
[00:37:35.040 --> 00:37:36.440]   presented in what context.
[00:37:36.480 --> 00:37:42.800]   Beyond that, there are a ton of hidden data sets about us that we should be
[00:37:42.800 --> 00:37:48.400]   more aware of and we should constrain the use of that includes your credit card
[00:37:48.400 --> 00:37:51.400]   company, selling all the data about your transactions.
[00:37:51.400 --> 00:37:57.600]   That includes your telephone carrier and your ISP selling data about your
[00:37:57.600 --> 00:38:02.000]   behaviors that they collect sort of secretly without telling you.
[00:38:02.000 --> 00:38:05.840]   I think Verizon sent out a huge notice to all their customers.
[00:38:06.040 --> 00:38:10.200]   I mean, it was amazing to read this because it was like, here's why we value
[00:38:10.200 --> 00:38:12.840]   your choice and your privacy.
[00:38:12.840 --> 00:38:17.480]   And then you read it and you're like, hold on, this whole five pages written
[00:38:17.480 --> 00:38:21.640]   by the best lawyers in the world are all about how they're selling all of your
[00:38:21.640 --> 00:38:26.440]   data from your cell phone and your ISP service to anyone they want.
[00:38:26.440 --> 00:38:29.200]   So could I email Verizon and say, hey, please stop doing this?
[00:38:29.200 --> 00:38:32.480]   Is that like an option for a lot of these companies that they don't tell you
[00:38:32.480 --> 00:38:33.640]   about and make easy to know?
[00:38:34.560 --> 00:38:39.840]   It is. And again, if you're a resident of a state, not just California, but
[00:38:39.840 --> 00:38:44.880]   there's five or 10 other states now that have specific privacy laws that you can
[00:38:44.880 --> 00:38:51.200]   cite, it makes it easier for them to have to comply with some of your requests.
[00:38:51.200 --> 00:38:56.040]   But all of this stuff requires some knowledge, some expertise, and that's the
[00:38:56.040 --> 00:38:58.520]   kind of thing that we want to bring to our customers.
[00:38:58.520 --> 00:39:02.600]   And even if you're not a customer, you can come visit us and ask us a question
[00:39:02.600 --> 00:39:06.840]   and our privacy advisors will try to help out and rest assured, you know, it's
[00:39:06.840 --> 00:39:12.880]   not just us, but we are trying to map out where these data sets are, how to go
[00:39:12.880 --> 00:39:16.720]   constrain the resale of your data, even if you like the product, right?
[00:39:16.720 --> 00:39:19.760]   Like I'm happy with my cell phone service from T-Mobile.
[00:39:19.760 --> 00:39:24.480]   I don't want to stop being a customer of T-Mobile, but I want to understand what
[00:39:24.480 --> 00:39:29.160]   my rights are to make sure they're not doing things with my data that I wouldn't
[00:39:29.160 --> 00:39:33.040]   want. And I got to say, the first thing I found when I was doing my search on
[00:39:33.040 --> 00:39:35.840]   myself is you guys have a site where it's like, if you don't want to pay us,
[00:39:35.840 --> 00:39:38.640]   that's fine. Here's a list of how to remove yourself from all the data
[00:39:38.640 --> 00:39:40.520]   brokers. So I appreciate that, though.
[00:39:40.520 --> 00:39:43.400]   After going through that process, I'm not sure it was worth my time.
[00:39:43.400 --> 00:39:47.320]   And, you know, this episode was a follow up to the last one because there was so
[00:39:47.320 --> 00:39:49.120]   much I needed to go do that I hadn't done.
[00:39:49.120 --> 00:39:52.720]   Now I feel like I have a few more calls to make with Verizon and my ISP.
[00:39:52.720 --> 00:39:55.920]   So now maybe I'm going to have to do a second follow up with everyone to share
[00:39:55.920 --> 00:39:58.000]   what else I found and worked on removing.
[00:39:58.000 --> 00:40:00.600]   But this has been great. Thank you so much for joining me.
[00:40:00.600 --> 00:40:01.480]   Thanks for having me, Chris.
[00:40:01.480 --> 00:40:07.520]   OK, so hopefully that was really helpful to hear a little bit from Rob about
[00:40:07.520 --> 00:40:09.520]   Delete Me. I'm a big fan of the product.
[00:40:09.520 --> 00:40:12.760]   I want to talk about some other personal data that I found online that I was
[00:40:12.760 --> 00:40:16.720]   surprised about and really spent some time thinking about what to do.
[00:40:16.720 --> 00:40:19.080]   So a lot of it was related to real estate.
[00:40:19.080 --> 00:40:23.360]   And whether you rent or buy, there was probably some website when you found your
[00:40:23.360 --> 00:40:27.360]   home or your apartment that you looked at in order to decide you wanted it.
[00:40:27.480 --> 00:40:30.160]   Maybe it was Zillow, maybe it was Hotpads.
[00:40:30.160 --> 00:40:34.360]   There are a bunch of sites online, apartments.com, where real estate
[00:40:34.360 --> 00:40:37.400]   brokerage sites, MLS sites, apartment rental sites.
[00:40:37.400 --> 00:40:42.480]   And they almost never take down the information about your property.
[00:40:42.480 --> 00:40:45.840]   On top of that, it seems like every house has its own website.
[00:40:45.840 --> 00:40:48.280]   And that website often doesn't get taken down.
[00:40:48.280 --> 00:40:50.840]   And that website might not just have photos of the house.
[00:40:50.840 --> 00:40:52.280]   They might have the floor plans.
[00:40:52.280 --> 00:40:54.480]   They might have all of the disclosure packet.
[00:40:54.480 --> 00:40:57.360]   They might have one of those Matterport 3D walkthroughs.
[00:40:57.560 --> 00:41:01.320]   So aside from just personal data, if someone is able to get your address,
[00:41:01.320 --> 00:41:05.160]   I figure it's probably not beneficial for someone to be able to click through
[00:41:05.160 --> 00:41:08.800]   57 pictures of your house in every room or download your floor plans.
[00:41:08.800 --> 00:41:12.320]   So I would recommend reaching out to two sources.
[00:41:12.320 --> 00:41:16.160]   One, any of the sites that have this information, sites like Zillow and Redfin
[00:41:16.160 --> 00:41:20.240]   or apartments.com, they all have an ability to opt out and request pictures
[00:41:20.240 --> 00:41:24.520]   or be removed from the website, but also to the real estate agent
[00:41:24.520 --> 00:41:26.560]   who listed the house if you purchased it.
[00:41:26.720 --> 00:41:29.840]   They can actually go into the MLS and remove all those photos,
[00:41:29.840 --> 00:41:33.480]   which will push out to all of these sites and they'll update them.
[00:41:33.480 --> 00:41:36.440]   They can also take down the pages on their own website.
[00:41:36.440 --> 00:41:40.720]   And something else you can do is once any of these sites have been removed,
[00:41:40.720 --> 00:41:44.920]   whether it's pictures or content, Google and Bing have a remove
[00:41:44.920 --> 00:41:48.240]   outdated content tool that I mentioned when I was talking with Rob,
[00:41:48.240 --> 00:41:53.000]   which will actually go in and remove the search results.
[00:41:53.000 --> 00:41:55.080]   So Google's out there indexing the Internet, right?
[00:41:55.080 --> 00:41:57.280]   They're not trying to store your information.
[00:41:57.280 --> 00:42:00.240]   But if you delete a picture from Zillow,
[00:42:00.240 --> 00:42:03.640]   Google might not immediately know that that picture is gone.
[00:42:03.640 --> 00:42:07.240]   So Google has this tool and Bing has one as well where you can say, hey,
[00:42:07.240 --> 00:42:08.560]   in your search results, there's a picture.
[00:42:08.560 --> 00:42:11.400]   But the actual website that has that picture is no longer there.
[00:42:11.400 --> 00:42:14.840]   And in somewhere between minutes and hours, you can give them the URL
[00:42:14.840 --> 00:42:15.440]   of that picture.
[00:42:15.440 --> 00:42:17.720]   If Google says, oh, yeah, you're right, that picture is not there.
[00:42:17.720 --> 00:42:20.000]   They'll remove it immediately from their search results.
[00:42:20.000 --> 00:42:24.200]   So that happens over time, naturally over about a month or weeks.
[00:42:24.320 --> 00:42:25.920]   But if you want to get it gone right away,
[00:42:25.920 --> 00:42:28.040]   you can use their remove outdated content tool,
[00:42:28.040 --> 00:42:29.920]   which I'll link to in the show notes also.
[00:42:29.920 --> 00:42:33.520]   And finally, when it comes to maps, you can actually reach out to Google,
[00:42:33.520 --> 00:42:37.600]   Bing and Apple and ask them to blur your house on Street View.
[00:42:37.600 --> 00:42:40.800]   I will point out that it is a irreversible decision.
[00:42:40.800 --> 00:42:44.080]   So make sure that you really want to do this now and forever
[00:42:44.080 --> 00:42:46.600]   if you make that request, but it is something you can do.
[00:42:46.600 --> 00:42:48.640]   And then finally, when it comes to personal data,
[00:42:48.640 --> 00:42:52.560]   if you've set up a trust for yourself or your family, know two things.
[00:42:52.560 --> 00:42:55.800]   One, it is possible for someone to find out
[00:42:55.800 --> 00:42:57.800]   who the trustees are on that trust.
[00:42:57.800 --> 00:43:02.600]   So it doesn't really protect anyone from finding out who you are, what you do.
[00:43:02.600 --> 00:43:04.640]   It does make it a little more obfuscated.
[00:43:04.640 --> 00:43:07.800]   So if you do want to buy your home and you want to buy it in a way
[00:43:07.800 --> 00:43:11.080]   that no one will be able to trace it to you, you probably should be doing that
[00:43:11.080 --> 00:43:15.320]   in an LLC and likely a two tiered LLC for true privacy.
[00:43:15.320 --> 00:43:16.840]   And that's for things like,
[00:43:16.840 --> 00:43:19.120]   you know, your car registration, your house deed, you know,
[00:43:19.120 --> 00:43:21.200]   even if you buy I bonds or something.
[00:43:21.200 --> 00:43:24.160]   So that's something to do if you want the most privacy.
[00:43:24.160 --> 00:43:26.360]   Most of those things don't show up on the Internet,
[00:43:26.360 --> 00:43:29.840]   but they are records that someone could usually request or find
[00:43:29.840 --> 00:43:31.960]   from different places, especially with your home.
[00:43:31.960 --> 00:43:35.520]   But if you do just have a trust, you know, maybe consider not naming it
[00:43:35.520 --> 00:43:39.120]   the John Doe Trust, maybe come up with a name that is a little bit different
[00:43:39.120 --> 00:43:41.440]   so that it's not so obvious who it is.
[00:43:41.440 --> 00:43:44.080]   OK, so that's personal data.
[00:43:44.080 --> 00:43:46.960]   There's just a couple other things I'll hit on before I wrap.
[00:43:46.960 --> 00:43:49.400]   I was thinking about how all these data brokers get your information
[00:43:49.400 --> 00:43:51.600]   and you're filling out your address online all the time.
[00:43:51.600 --> 00:43:54.360]   And obviously, if you're trying to ship something to your house,
[00:43:54.360 --> 00:43:56.720]   you might need to put your address there so you get it.
[00:43:56.720 --> 00:43:59.600]   But you can also get a P.O.
[00:43:59.600 --> 00:44:01.080]   box at the post office.
[00:44:01.080 --> 00:44:03.960]   You can go to UPS and actually get a P.O.
[00:44:03.960 --> 00:44:07.440]   box, but one that has a real street address and can receive packages,
[00:44:07.440 --> 00:44:10.320]   even packages, whether they're FedEx or DHL or something else.
[00:44:10.320 --> 00:44:13.800]   There are a lot of virtual mailbox services online where you can get an address
[00:44:13.800 --> 00:44:16.400]   in a city and send mail there and they'll scan it.
[00:44:16.400 --> 00:44:19.200]   You can even send packages there and they'll reship them to you.
[00:44:19.520 --> 00:44:23.800]   So depending on how much you want to complicate the process of receiving mail,
[00:44:23.800 --> 00:44:27.520]   you could get one of these services and send your mail there
[00:44:27.520 --> 00:44:31.360]   and not have to worry about it, or even just use it for websites
[00:44:31.360 --> 00:44:34.920]   where you don't think you need to be giving out your home address,
[00:44:34.920 --> 00:44:36.400]   but you need to give out an address.
[00:44:36.400 --> 00:44:37.440]   But you want it to be yours
[00:44:37.440 --> 00:44:39.800]   in case for some reason there's something that's going to come.
[00:44:39.800 --> 00:44:43.880]   When I did some quick research at the lowest price point online,
[00:44:43.880 --> 00:44:46.400]   these virtual mailboxes where they scan your mail,
[00:44:46.400 --> 00:44:48.720]   you can get them at like ten dollars a month.
[00:44:48.880 --> 00:44:52.320]   You might have to pay for the scans, but you know, you can at least get the address
[00:44:52.320 --> 00:44:56.040]   PO box at the post office in the Bay Area is about 20 bucks.
[00:44:56.040 --> 00:44:59.920]   And then a lot of other postal services where you can receive packages and mail
[00:44:59.920 --> 00:45:04.320]   were anywhere from 20 to 40 dollars a month because you can't receive packages
[00:45:04.320 --> 00:45:07.600]   if you get a PO box at the post office, unless they're USPS packages.
[00:45:07.600 --> 00:45:11.200]   When it comes to unsolicited mail, there's a website, DMA Choice,
[00:45:11.200 --> 00:45:13.720]   which you can go in and submit yourself and say,
[00:45:13.720 --> 00:45:16.640]   I don't want to receive unsolicited mail, please stop sending it to me.
[00:45:16.800 --> 00:45:19.960]   They also let you put your email address on a stop spamming me list.
[00:45:19.960 --> 00:45:20.960]   That's an option.
[00:45:20.960 --> 00:45:22.560]   If you're getting catalogs you don't want,
[00:45:22.560 --> 00:45:25.320]   you can always call the catalog company and ask to remove you.
[00:45:25.320 --> 00:45:28.520]   And then if you're not already on the do not call registry
[00:45:28.520 --> 00:45:31.320]   and don't want more spam calls, that's an option.
[00:45:31.320 --> 00:45:34.680]   Also, a lot of carriers have recently launched their own apps
[00:45:34.680 --> 00:45:38.040]   that you can download to block and screen spam calls.
[00:45:38.040 --> 00:45:39.560]   And most of those are free as well.
[00:45:39.560 --> 00:45:44.160]   So I know this is a lot of information.
[00:45:44.160 --> 00:45:47.240]   Hopefully the show notes will be helpful in organizing it
[00:45:47.240 --> 00:45:50.120]   and figuring out what you want to do and taking action.
[00:45:50.120 --> 00:45:55.480]   This was a scary but kind of fun process for me because now I feel a lot better.
[00:45:55.480 --> 00:45:57.960]   You certainly don't need to take all of these actions, right?
[00:45:57.960 --> 00:46:01.680]   You can decide which ones are the most important to you and focus on those.
[00:46:01.680 --> 00:46:05.720]   But I wanted to make sure I kind of tried to gather everything I could
[00:46:05.720 --> 00:46:09.640]   and put it in one place for all of you so that if this is important to you,
[00:46:09.640 --> 00:46:11.800]   you know what to do and you know how to do it.
[00:46:11.800 --> 00:46:13.600]   So hopefully that's really helpful.
[00:46:13.600 --> 00:46:15.720]   And I really appreciate you guys listening.
[00:46:15.720 --> 00:46:16.320]   Definitely.
[00:46:16.320 --> 00:46:19.160]   If you think other people need to know this, share this episode with them.
[00:46:19.160 --> 00:46:21.200]   You can share it straight from the player app.
[00:46:21.200 --> 00:46:23.840]   You can share a link to the website, whatever is easiest.
[00:46:23.840 --> 00:46:25.040]   I really appreciate it.
[00:46:25.040 --> 00:46:28.840]   I would love as many people as possible to be able to protect themselves online
[00:46:28.840 --> 00:46:32.360]   and fight back against these brokers, scammers, fishers and everyone out there.
[00:46:32.360 --> 00:46:34.560]   Really just that suck, to be honest.
[00:46:34.560 --> 00:46:36.280]   So thank you so much for listening.
[00:46:36.280 --> 00:46:37.360]   I will see you next week.
[00:46:37.360 --> 00:46:47.360]   [MUSIC]
[00:46:47.360 --> 00:46:57.360]   [BLANK_AUDIO]

