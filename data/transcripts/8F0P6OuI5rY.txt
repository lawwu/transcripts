
[00:00:00.000 --> 00:00:05.600]   [Music]
[00:00:05.600 --> 00:00:07.360]   I'm Kamata from Waze Advisors.
[00:00:07.360 --> 00:00:18.320]   In this video, I will explain how Waze Advisors was able to be used in the development of LLM and the development of applications using LLM.
[00:00:18.320 --> 00:00:27.800]   Waze Advisors, or FUNDB, has been used by many companies that have been working on AI since the beginning of the industry, including OpenAI.
[00:00:27.800 --> 00:00:35.080]   In Japan, we have been using it since 2023 by companies that have been developing AI.
[00:00:35.080 --> 00:00:44.080]   We continue to develop products while reflecting the needs that have actually been used.
[00:00:44.080 --> 00:00:50.360]   This is a rough flow that shows the development of LLM applications.
[00:00:50.360 --> 00:00:57.880]   There are various topics and pain points in this flow, but I will introduce three representative ones.
[00:00:57.880 --> 00:01:10.360]   One is that it is very important to ensure that complex processes are executed on an AI-scale at the stage of building a base model, so it is a complex task to manage experiments.
[00:01:10.360 --> 00:01:20.200]   Another is that it is difficult to build a fire system that supports downstream tasks at the stage of fine-tuning.
[00:01:20.200 --> 00:01:32.520]   And finally, at the stage of building an application, it is difficult to debug because various methods need to be combined.
[00:01:32.520 --> 00:01:38.680]   FUNDB provides solutions to solve these problems.
[00:01:38.680 --> 00:01:43.760]   This is a diagram of the solutions provided by FUNDB.
[00:01:43.760 --> 00:01:51.840]   In addition to the function of starting to manage experiments, we have recently provided a special feature for LLM.
[00:01:51.840 --> 00:02:09.840]   I think that some people have a strong image of SARS, but we also provide a variety of environments such as home play, dedicated cloud, and so on so that you can safely develop on the enterprise.
[00:02:09.840 --> 00:02:18.240]   From here, I will explain how these functions can be used based on three scenarios.
[00:02:18.240 --> 00:02:21.120]   First of all, from the example of building a base model.
[00:02:21.120 --> 00:02:37.040]   FUNDB provides a solution that allows you to manage the settings and results on the sophisticated FUNDB dashboard just by entering a number of lines of FUNDB code into the code you have.
[00:02:37.040 --> 00:02:41.520]   Let's take a look at the dashboard of FUNDB.
[00:02:41.520 --> 00:02:45.360]   This is an example of the dashboard of FUNDB.
[00:02:45.360 --> 00:02:54.960]   This is an example of the dashboard that gpt-neoX, which is used by many LLM models, is showing.
[00:02:54.960 --> 00:02:59.760]   For example, here the loss and GB metrics are tracked.
[00:02:59.760 --> 00:03:15.600]   These can be tracked in real time, so you can check for example if the loss has dropped properly or if the explosion has not occurred, and you can stop learning and restart learning from the checkpoint you saved at that time.
[00:03:15.600 --> 00:03:28.480]   In this way, you will try to develop while looking at the results, but with trial and error, the tracking of the experiment settings will also be important.
[00:03:28.480 --> 00:03:52.160]   FUNDB automatically captures all the information that the team can reproduce later, but for example, here, the command used to execute the sub from the final commit such as git repository, and other settings used to record these things automatically with the results of the experiment.
[00:03:52.160 --> 00:04:07.200]   Since this information is recorded along with the results, FUNDB not only serves as a tool for improving individual productivity, but also serves as a central place for gathering data as a whole.
[00:04:07.200 --> 00:04:11.600]   Next, let's look at the example of fine tuning.
[00:04:11.600 --> 00:04:20.640]   We are thinking of a way to tune a model of about a billion for the development of an application in the company.
[00:04:20.640 --> 00:04:39.600]   As before, you can track the loss during the experiment in this way, but here are some colors, and the colors show the names of each experiment, so you can compare several experiments at the same time with one dashboard.
[00:04:39.600 --> 00:04:56.880]   In fine tuning, it is required to search for appropriate hyperparameters, but FUNDB also provides a function called sweep that automatically executes multiple settings by automatically taking several hyperparameters.
[00:04:56.880 --> 00:05:13.440]   The rightmost one is validation loss, and the leftmost one shows the combination of hyperparameters, but FUNDB is able to find the best combination of hyperparameters in this.
[00:05:13.440 --> 00:05:19.600]   This example is the most accurate model.
[00:05:19.600 --> 00:05:24.560]   Actually, this model is also stored in FUNDB.
[00:05:24.560 --> 00:05:35.760]   In addition to fine tuning, it is also important to evaluate downstream tasks.
[00:05:35.760 --> 00:05:45.840]   Various benchmarks are proposed as part of the evaluation of downstream tasks, but in Japanese, for example, JGroo is famous.
[00:05:45.840 --> 00:05:50.000]   Let's actually evaluate using JGroo.
[00:05:50.000 --> 00:06:01.840]   You can run the script from the command, but in FUNDB, you can also run the previously registered job from the CUI.
[00:06:01.840 --> 00:06:15.280]   Actually, this is the evaluation job for JGroo, but just specify the model you want to evaluate, you can automatically execute the evaluation for JGroo.
[00:06:15.280 --> 00:06:33.680]   This job can be thrown as a sphere in the calculation environment such as the previously set GPU, so even if it is a calculation using GPU, it can be easily efficient.
[00:06:33.680 --> 00:06:40.720]   The result of the calculation is this table.
[00:06:40.720 --> 00:06:47.760]   Here you can see the scores for some specifications in JGroo.
[00:06:47.760 --> 00:07:05.680]   In FUNDB, it is not only a metric visualization, but also a record of what kind of output was actually made, so you can debug what kind of case it is easy to remove.
[00:07:05.680 --> 00:07:25.520]   Also, all the data used and models built are stored in the archive, so the data such as which data was evaluated and which model was extracted are all highly transparent.
[00:07:25.520 --> 00:07:44.400]   In summary, in October 2023, when we evaluated the famous Japanese language published in JGroo to deepen our understanding of the Japanese model using such functions, we also published the most popular leaderboards in Japan.
[00:07:44.400 --> 00:08:04.240]   I hope you will take a look. As with the previous results, you can see the combination of input and output, so you can see what kind of model is suitable for what kind of task.
[00:08:04.240 --> 00:08:10.800]   We also saw that you can evaluate LLM using FUNDB.
[00:08:10.800 --> 00:08:17.040]   Finally, I think you saw an example of application development using LLM.
[00:08:17.040 --> 00:08:34.320]   As an example of a famous example of a chatbot using LAG, FUNDB also publishes a chatbot that answers questions about FUNDB products.
[00:08:34.320 --> 00:08:41.280]   Japanese FUNDB can be used from the Slack channel of the community, so please try it.
[00:08:41.280 --> 00:08:52.560]   Chatbots are built by combining several elements, but there are such issues that make debugging difficult.
[00:08:52.560 --> 00:09:06.400]   Here, we can use the LLM-specific function called Traces, which I showed a little in the fine tuning part.
[00:09:06.400 --> 00:09:24.320]   Traces not only records the input and output pairs, but also all the processes that are performed on the way, so you can see where it didn't work.
[00:09:24.320 --> 00:09:40.800]   For example, in LAG, we start by extracting some related high sentences, but we can also check whether appropriate sentences can be extracted.
[00:09:40.800 --> 00:09:54.240]   You can easily see where the problem occurred, so you can easily identify the cause of the problem and think about the next step.
[00:09:54.240 --> 00:10:08.160]   In this video, I briefly introduced the functions that FUNDB provides in the development of LLM and the development of applications using LLM.
[00:10:08.160 --> 00:10:28.160]   In addition to the functions introduced in this video, we also provide a model registry that can manage the models used in production, and an automatic tool that can build an automatic execution process for CI/CD.
[00:10:28.160 --> 00:10:41.760]   In addition, we are also developing a dashboard that can manage and monitor the operation time, and we hope that you will be able to use such a dashboard in the future.
[00:10:41.760 --> 00:10:51.760]   I will explain these functions in another video, but please check the latest information on the website and the document.
[00:10:51.760 --> 00:10:53.760]   Thank you for watching.
[00:10:54.320 --> 00:10:56.320]   [Music]
[00:10:56.320 --> 00:10:59.320]   [MUSIC]

