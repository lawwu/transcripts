
[00:00:00.000 --> 00:00:06.280]   What are your thoughts, sticking on artificial intelligence a little bit, about the displacement
[00:00:06.280 --> 00:00:07.280]   of jobs?
[00:00:07.280 --> 00:00:10.840]   That's another perspective that candidates like Andrew Yang talk about.
[00:00:10.840 --> 00:00:12.640]   Yang Gang forever.
[00:00:12.640 --> 00:00:15.000]   Yang Gang.
[00:00:15.000 --> 00:00:18.320]   So he unfortunately, speaking of Yang Gang, has recently dropped out.
[00:00:18.320 --> 00:00:20.960]   I know, it was very disappointing and depressing.
[00:00:20.960 --> 00:00:25.160]   Yeah, but on the positive side, he's I think launching a podcast.
[00:00:25.160 --> 00:00:26.160]   So uh...
[00:00:26.160 --> 00:00:27.160]   Really?
[00:00:27.160 --> 00:00:28.160]   Cool.
[00:00:28.160 --> 00:00:31.800]   I'm sure he'll try to talk you into trying to come on to the podcast.
[00:00:31.800 --> 00:00:32.800]   I would love to.
[00:00:32.800 --> 00:00:33.800]   Talk about Ratatouille.
[00:00:33.800 --> 00:00:39.160]   Yeah, maybe he'll be more welcoming of the Ratatouille argument.
[00:00:39.160 --> 00:00:43.920]   What are your thoughts on his concerns of the displacement of jobs, of automation, of
[00:00:43.920 --> 00:00:47.800]   course there's positive impacts that could come from automation and AI, but there could
[00:00:47.800 --> 00:00:50.400]   also be negative impacts.
[00:00:50.400 --> 00:00:54.340]   And within that framework, what are your thoughts about universal basic income?
[00:00:54.340 --> 00:01:01.760]   So these interesting new ideas of how we can empower people in the economy.
[00:01:01.760 --> 00:01:07.600]   I think he was 100% right on almost every dimension.
[00:01:07.600 --> 00:01:10.480]   We see this in Square's business.
[00:01:10.480 --> 00:01:21.600]   He identified truck drivers, some from Missouri, and he certainly pointed to the concern and
[00:01:21.600 --> 00:01:28.440]   the issue that people from where I'm from feel every single day that is often invisible
[00:01:28.440 --> 00:01:30.520]   and not talked about enough.
[00:01:30.520 --> 00:01:32.960]   The next big one is cashiers.
[00:01:32.960 --> 00:01:36.640]   This is where it pertains to Square's business.
[00:01:36.640 --> 00:01:43.720]   We are seeing more and more of the point of sale move to the individual customer's hand
[00:01:43.720 --> 00:01:48.200]   in the form of their phone and apps and pre-order and order ahead.
[00:01:48.200 --> 00:01:50.560]   We're seeing more kiosks.
[00:01:50.560 --> 00:01:53.480]   We're seeing more things like Amazon Go.
[00:01:53.480 --> 00:02:01.520]   And the number of workers as a cashier in retail is immense.
[00:02:01.520 --> 00:02:12.040]   And there's no real answers on how they transform their skills and work into something else.
[00:02:12.040 --> 00:02:17.200]   And I think that does lead to a lot of really negative ramifications.
[00:02:17.200 --> 00:02:22.880]   And the important point that he brought up around universal basic income is given that
[00:02:22.880 --> 00:02:32.880]   this shift is going to come, and given it is going to take time to set people up with
[00:02:32.880 --> 00:02:38.880]   new skills and new careers, they need to have a floor to be able to survive.
[00:02:38.880 --> 00:02:43.560]   And this $1,000 a month is such a floor.
[00:02:43.560 --> 00:02:47.720]   It's not going to incentivize you to quit your job because it's not enough.
[00:02:47.720 --> 00:02:56.920]   But it will enable you to not have to worry as much about just getting on day to day so
[00:02:56.920 --> 00:03:06.160]   that you can focus on what am I going to do now and what skills do I need to acquire.
[00:03:06.160 --> 00:03:14.840]   And I think a lot of people point to the fact that during the industrial age, we had the
[00:03:14.840 --> 00:03:20.160]   same concerns around automation, factory lines, and everything worked out okay.
[00:03:20.160 --> 00:03:28.760]   But the biggest change is just the velocity and the centralization of a lot of the things
[00:03:28.760 --> 00:03:35.640]   that make this work, which is the data and the algorithms that work on this data.
[00:03:35.640 --> 00:03:45.720]   I think the second biggest scary thing around AI is just who actually owns the data and
[00:03:45.720 --> 00:03:47.440]   who can operate on it.
[00:03:47.440 --> 00:03:56.080]   And are we able to share the insights from the data so that we can also build algorithms
[00:03:56.080 --> 00:04:00.040]   that help our needs or help our business or whatnot.
[00:04:00.040 --> 00:04:07.640]   So that's where I think regulation could play a strong and positive part.
[00:04:07.640 --> 00:04:13.520]   First looking at the primitives of AI and the tools we use to build these services that
[00:04:13.520 --> 00:04:17.440]   will ultimately touch every single aspect of the human experience.
[00:04:17.440 --> 00:04:26.900]   And then where data is owned and how it's shared.
[00:04:26.900 --> 00:04:32.760]   So those are the answers that as a society, as a world, we need to have better answers
[00:04:32.760 --> 00:04:34.680]   around, which we're currently not.
[00:04:34.680 --> 00:04:40.440]   They're just way too centralized into a few very, very large companies.
[00:04:40.440 --> 00:04:45.480]   But I think it was spot on with identifying the problem and proposing solutions that would
[00:04:45.480 --> 00:04:47.600]   actually work.
[00:04:47.600 --> 00:04:52.320]   At least that we'd learned from that you could expand or evolve.
[00:04:52.320 --> 00:04:59.720]   But I mean, I think UBI is well past its due.
[00:04:59.720 --> 00:05:05.720]   It was certainly trumpeted by Martin Luther King and even before him as well.
[00:05:05.720 --> 00:05:11.440]   And like you said, the exact thousand dollar mark might not be the correct one, but you
[00:05:11.440 --> 00:05:17.360]   should take the steps to try to implement these solutions and see what works.
[00:05:17.360 --> 00:05:17.440]   100%.
[00:05:17.440 --> 00:05:26.980]   [BLANK_AUDIO]
[00:05:26.980 --> 00:05:36.980]   [BLANK_AUDIO]
[00:05:36.980 --> 00:05:39.040]   you

