
[00:00:00.000 --> 00:00:03.960]   Obviously there's the things we can all agree on, you know, cure all the diseases.
[00:00:03.960 --> 00:00:07.100]   But now it's 2030, you've solved all the real problems.
[00:00:07.100 --> 00:00:08.040]   What happens next?
[00:00:08.040 --> 00:00:10.100]   What are we doing with a superhuman God?
[00:00:10.100 --> 00:00:12.280]   I actually get nervous when someone says, what are you going
[00:00:12.280 --> 00:00:13.680]   to do with the superhuman AI?
[00:00:13.680 --> 00:00:17.620]   We've learned a lot of things over the last 150 years about markets and
[00:00:17.620 --> 00:00:22.880]   democracy and that societies work out norms and what they value in this
[00:00:22.880 --> 00:00:24.480]   complex and decentralized way.
[00:00:24.480 --> 00:00:25.900]   How do we make things good?
[00:00:25.900 --> 00:00:29.560]   Most people, most groups, most ideologies that started with like,
[00:00:29.980 --> 00:00:33.040]   let's sit down and think over what the definition of the good life is.
[00:00:33.040 --> 00:00:34.960]   I think most of those have led to disaster.
[00:00:34.960 --> 00:00:38.300]   So this vision you have of a market-oriented system with AGI, like what
[00:00:38.300 --> 00:00:40.680]   is each person has their own AGI?
[00:00:40.680 --> 00:00:41.440]   Like, what does that mean?
[00:00:41.440 --> 00:00:42.280]   I don't know.
[00:00:42.280 --> 00:00:43.740]   I don't know what it looks like, right?
[00:00:43.740 --> 00:00:47.640]   We need to solve the important safety problems and the important externalities.
[00:00:47.640 --> 00:00:50.780]   Which again, those could be just narrowly about alignment.
[00:00:50.780 --> 00:00:53.680]   Subject to that, we should think about what's worked in the past.
[00:00:53.680 --> 00:00:57.560]   And I think in general, unitary visions for what it means to live a good
[00:00:57.560 --> 00:00:59.360]   life have not worked out well at all.

