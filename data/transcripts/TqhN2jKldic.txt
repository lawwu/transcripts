
[00:00:00.000 --> 00:00:01.880]   All right.
[00:00:01.880 --> 00:00:03.060]   Wow.
[00:00:03.060 --> 00:00:04.060]   Thank you guys for coming.
[00:00:04.060 --> 00:00:06.120]   This is just absolutely incredible.
[00:00:06.120 --> 00:00:07.120]   All right.
[00:00:07.120 --> 00:00:11.900]   I'm going to talk about something we call Weave.
[00:00:11.900 --> 00:00:15.040]   But what is Weave?
[00:00:15.040 --> 00:00:18.880]   Weave is a powerful compositional toolkit for ML practitioners.
[00:00:18.880 --> 00:00:20.920]   So I hope that answered the question.
[00:00:20.920 --> 00:00:21.920]   Okay.
[00:00:21.920 --> 00:00:23.660]   It probably didn't.
[00:00:23.660 --> 00:00:27.300]   But before we talk about what Weave is today, we're going to go back and talk about what
[00:00:27.300 --> 00:00:29.400]   Weave was.
[00:00:29.400 --> 00:00:33.740]   It all started with Weave.js or JavaScript.
[00:00:33.740 --> 00:00:37.960]   So back in 2020, we had just built this thing called Artifacts, our tool for versioning
[00:00:37.960 --> 00:00:42.940]   unstructured data on top of object stores and tracking all its lineage.
[00:00:42.940 --> 00:00:46.680]   But people started saying, okay, cool, I put all my data in there, but you guys make analysis
[00:00:46.680 --> 00:00:47.680]   tools.
[00:00:47.680 --> 00:00:48.940]   So how can I see my data?
[00:00:48.940 --> 00:00:50.320]   So we built Weave.
[00:00:50.320 --> 00:00:55.680]   We originally built it with the goal of helping people organize and understand model evaluations.
[00:00:55.680 --> 00:01:00.520]   It lets you easily see the results of large-scale analysis while tracking the individual computations
[00:01:00.520 --> 00:01:03.700]   and examples that make it up.
[00:01:03.700 --> 00:01:07.180]   Our customers use Weave to understand their models in context.
[00:01:07.180 --> 00:01:11.600]   This is a screenshot from a case study by Woven Toyota about how they use Weave in their
[00:01:11.600 --> 00:01:15.160]   core model evaluation processes.
[00:01:15.160 --> 00:01:19.240]   The Weave UI is built from some really cool technology with the unique goal of making
[00:01:19.240 --> 00:01:22.000]   a truly programmable UI.
[00:01:22.000 --> 00:01:26.400]   Any Weave UI component can expose Weave expressions, which themselves are compositions of Weave
[00:01:26.400 --> 00:01:29.880]   ops directly to the user.
[00:01:29.880 --> 00:01:31.260]   Why do we call it Weave?
[00:01:31.260 --> 00:01:35.280]   Because the Weave rendering engine Weaves a compute graph through the UI.
[00:01:35.280 --> 00:01:40.400]   This means any value displayed by the UI, we can ask, how is this value computed, enabling
[00:01:40.400 --> 00:01:45.200]   powerful faceting, drill down, and comparison capabilities.
[00:01:45.200 --> 00:01:49.280]   This gives Weave more expressiveness than other UIs while remaining highly visual.
[00:01:49.280 --> 00:01:54.280]   And we've only just scratched the surface of what we can do with this.
[00:01:54.280 --> 00:01:59.260]   Weave is built on a powerful type system comparable to the ones found in Python and TypeScript.
[00:01:59.260 --> 00:02:03.520]   This lets us suggest the right operations in the right place, and at any place a visualization
[00:02:03.520 --> 00:02:07.440]   can be used, users can choose the one that makes the most sense for their data.
[00:02:07.440 --> 00:02:11.080]   In other words, we design Weave so that at any given point, we can present you the right
[00:02:11.080 --> 00:02:14.320]   options in an intuitive way.
[00:02:14.320 --> 00:02:19.560]   And it powers a lot of WMB today, from tables, our tool for data understanding, to the UI
[00:02:19.560 --> 00:02:26.680]   for our model registry that Kerry just showed, and the browser for WMB artifacts.
[00:02:26.680 --> 00:02:29.520]   And because of Weave, we can ship new stuff really quickly.
[00:02:29.520 --> 00:02:33.200]   One of the Weave engineers, Tim, took a quick weekend break from building Weave to ship
[00:02:33.200 --> 00:02:37.400]   our new trace visualizer a couple months ago.
[00:02:37.400 --> 00:02:40.000]   It's pretty magical.
[00:02:40.000 --> 00:02:43.520]   But there are a few limitations.
[00:02:43.520 --> 00:02:45.880]   Weave executes entirely in the browser.
[00:02:45.880 --> 00:02:49.960]   This means it has to download all of your data to your machine before it can be processed.
[00:02:49.960 --> 00:02:54.840]   So if you uploaded a 500 megabyte table, yeah, we download that whole thing into your browser
[00:02:54.840 --> 00:02:59.000]   on every single page load.
[00:02:59.000 --> 00:03:02.760]   Weave has a really powerful extension model, but only we at Weights and Biases can use
[00:03:02.760 --> 00:03:05.360]   it to make cool stuff.
[00:03:05.360 --> 00:03:09.240]   And it's not implemented in the language that our users use the most.
[00:03:09.240 --> 00:03:10.920]   So what did we do?
[00:03:10.920 --> 00:03:20.280]   Well, we're excited to announce Weave Python, which we now just call Weave.
[00:03:20.280 --> 00:03:30.280]   [ Applause ] Weave from the ground up on top of Apache
[00:03:30.280 --> 00:03:31.680]   Arrow.
[00:03:31.680 --> 00:03:35.260]   It has a vectorizing DAG execution engine for performance and scale and a first-class
[00:03:35.260 --> 00:03:36.800]   Python API.
[00:03:36.800 --> 00:03:41.680]   Now when we first built Weights and Biases back in 2017, we had an open-source Python
[00:03:41.680 --> 00:03:44.040]   client and a closed backend.
[00:03:44.040 --> 00:03:48.200]   Lucas, Chris, and I made multiple attempts at open-sourcing larger parts of it, but none
[00:03:48.200 --> 00:03:49.820]   of them saw the light of day.
[00:03:49.820 --> 00:03:54.040]   And I'm here to tell you it is hard to open something that starts off closed.
[00:03:54.040 --> 00:04:03.680]   So I'm very proud to announce that as of today, Weave is free and open-source.
[00:04:03.680 --> 00:04:08.060]   And I really mean open-source with a permissive Apache 2 license.
[00:04:08.060 --> 00:04:10.000]   And now I get to show it to you.
[00:04:10.000 --> 00:04:12.080]   First, one question for the audience.
[00:04:12.080 --> 00:04:16.600]   How many people here use notebooks like Jupyter notebooks every week?
[00:04:16.600 --> 00:04:17.600]   Pretty good.
[00:04:17.600 --> 00:04:18.600]   Pretty good.
[00:04:18.600 --> 00:04:20.520]   For the rest of you, you might want to -- okay.
[00:04:20.520 --> 00:04:23.760]   You can stay, but this is going to get pretty nerdy.
[00:04:23.760 --> 00:04:25.440]   Cool.
[00:04:25.440 --> 00:04:26.520]   Okay.
[00:04:26.520 --> 00:04:27.760]   So Weave is notebook first.
[00:04:27.760 --> 00:04:31.140]   And I'm going to show the demo, but just let me give a little setup.
[00:04:31.140 --> 00:04:34.900]   We built a question/answer bot that runs in our Discord channel that can answer questions
[00:04:34.900 --> 00:04:37.700]   about weights and biases based on our docs.
[00:04:37.700 --> 00:04:42.280]   It's built with LangChain and the face vector store and chat GPT.
[00:04:42.280 --> 00:04:44.120]   Hopefully all of you have made one of these by now.
[00:04:44.120 --> 00:04:46.620]   It's really easy to do.
[00:04:46.620 --> 00:04:50.340]   And in this first demo, we're going to take a look at how a dataset that came from evaluating
[00:04:50.340 --> 00:04:54.180]   our doc bot with three different prompt templates.
[00:04:54.180 --> 00:04:55.740]   Cool.
[00:04:55.740 --> 00:04:57.120]   Okay.
[00:04:57.120 --> 00:04:59.820]   So here we are in a Jupyter notebook.
[00:04:59.820 --> 00:05:05.000]   And this is the default -- familiar default pandas data frame visualization.
[00:05:05.000 --> 00:05:08.940]   So you can see the first few rows and the last few rows and the first few columns and
[00:05:08.940 --> 00:05:10.220]   the last few columns.
[00:05:10.220 --> 00:05:17.960]   But you can't do much more than that.
[00:05:17.960 --> 00:05:20.020]   So let's see how this looks in Weave.
[00:05:20.020 --> 00:05:21.580]   First we convert the data to Weave.
[00:05:21.580 --> 00:05:24.660]   You can go back and forth between pandas and Weave really easily.
[00:05:24.660 --> 00:05:28.180]   Then we save it to give it a name and start versioning it.
[00:05:28.180 --> 00:05:36.060]   And now we see the Weave UI.
[00:05:36.060 --> 00:05:40.500]   You can click to the end to see the tail of the data, go back to the beginning, change
[00:05:40.500 --> 00:05:45.780]   the row height to get a better view.
[00:05:45.780 --> 00:05:56.040]   And you can expand large values with this cool hover state.
[00:05:56.040 --> 00:05:58.660]   Now let's do some checks on this data.
[00:05:58.660 --> 00:06:01.300]   I see there are three token columns here.
[00:06:01.300 --> 00:06:02.900]   Token counts -- sorry.
[00:06:02.900 --> 00:06:06.140]   Prompt tokens, completion tokens, and total tokens.
[00:06:06.140 --> 00:06:09.300]   And I think that the prompt and completion tokens should add up to total.
[00:06:09.300 --> 00:06:10.300]   But let's check.
[00:06:10.300 --> 00:06:19.540]   So we can add a Weave expression here to add those two columns together.
[00:06:19.540 --> 00:06:20.620]   And yeah.
[00:06:20.620 --> 00:06:22.900]   The first few rows at least seem to match.
[00:06:22.900 --> 00:06:25.780]   Let's make sure everything matches.
[00:06:25.780 --> 00:06:30.600]   We can add a Boolean operation to make the comparison.
[00:06:30.600 --> 00:06:33.140]   So now we see these rows are true.
[00:06:33.140 --> 00:06:39.420]   We can sort up and down to make sure that both ends are true.
[00:06:39.420 --> 00:06:45.580]   Or we can group by this column and make sure there's just one row in the result.
[00:06:45.580 --> 00:06:48.780]   Let's see.
[00:06:48.780 --> 00:06:49.780]   There we go.
[00:06:49.780 --> 00:06:50.780]   Just one row.
[00:06:50.780 --> 00:06:51.780]   So it looks like everything matches.
[00:06:51.780 --> 00:06:53.180]   Great.
[00:06:53.180 --> 00:06:54.920]   Okay.
[00:06:54.920 --> 00:06:59.040]   So now let's actually compare the three prompt templates that we evaluated here.
[00:06:59.040 --> 00:07:10.220]   We'll go over to the right and group by the prompt template to get one row for each.
[00:07:10.220 --> 00:07:14.260]   Under grouping in Weave, scalar columns become lists of scalars.
[00:07:14.260 --> 00:07:17.900]   And by default, Weave chooses the histogram panel for lists of numbers.
[00:07:17.900 --> 00:07:21.860]   But we can choose another one, like the list of number panel, which gives us a little pager
[00:07:21.860 --> 00:07:25.400]   so we can see the individual values.
[00:07:25.400 --> 00:07:30.140]   We can also change the Weave expression to do a new operation here.
[00:07:30.140 --> 00:07:33.080]   So we'll ask for the average.
[00:07:33.080 --> 00:07:37.540]   And we can see that the few-shot model actually was more expensive by token cost, which makes
[00:07:37.540 --> 00:07:39.200]   sense.
[00:07:39.200 --> 00:07:40.200]   What else can we find?
[00:07:40.200 --> 00:07:45.100]   Well, if we scroll over to the synth grader column, we can see that the default lang chain
[00:07:45.100 --> 00:07:48.260]   model actually had a better ratio of negative feedback.
[00:07:48.260 --> 00:07:53.480]   So it looks like the default lang chain model is better on both the cost axis and the performance
[00:07:53.480 --> 00:07:54.520]   axis.
[00:07:54.520 --> 00:07:57.440]   So we should probably just use that.
[00:07:57.440 --> 00:08:01.320]   So Weave is designed to make it incredibly easy to iteratively ask questions of your
[00:08:01.320 --> 00:08:08.300]   data and give you the right operations and visualizations just as you need them.
[00:08:08.300 --> 00:08:11.080]   And it takes the meaning of composition to a new level.
[00:08:11.080 --> 00:08:12.320]   So let me show you.
[00:08:12.320 --> 00:08:13.320]   Okay.
[00:08:13.320 --> 00:08:17.800]   So for an analysis like this, it's really useful to compare models across the same input.
[00:08:17.800 --> 00:08:22.040]   For example, we can look for questions that all the models struggled with or questions
[00:08:22.040 --> 00:08:25.440]   where some models were right and some were wrong.
[00:08:25.440 --> 00:08:34.320]   To do that in Weave, we'll group by the question column.
[00:08:34.320 --> 00:08:36.360]   Now it seems like we have a problem.
[00:08:36.360 --> 00:08:40.400]   The number of grouped rows is about the same as the number of ungrouped rows.
[00:08:40.400 --> 00:08:44.240]   So I'm not sure that we actually asked the models the same question.
[00:08:44.240 --> 00:08:51.160]   We can continue to edit the table to count these groups.
[00:08:51.160 --> 00:08:54.600]   And we can see the counts, but we actually want a count of those counts to finish this
[00:08:54.600 --> 00:08:55.600]   analysis.
[00:08:55.600 --> 00:08:56.600]   How can we do it?
[00:08:56.600 --> 00:09:00.880]   Well, we can go to the right in this cool little drawer and click the plus icon to add
[00:09:00.880 --> 00:09:02.080]   a new panel.
[00:09:02.080 --> 00:09:09.200]   And we can refer to the first panel from the second one to ask for its values.
[00:09:09.200 --> 00:09:13.760]   So now we see the data from the first table mirrored in the second, and we can do further
[00:09:13.760 --> 00:09:15.520]   operations from here.
[00:09:15.520 --> 00:09:31.800]   We can group by that second count column, count that, and finally we have our answer.
[00:09:31.800 --> 00:09:36.920]   There are only 32 questions that two or more models actually answered, so we can't actually
[00:09:36.920 --> 00:09:39.420]   do the analysis that we want here.
[00:09:39.420 --> 00:09:43.520]   So one of the major goals of Weave is that you never hit a dead end and never feel boxed
[00:09:43.520 --> 00:09:44.520]   in.
[00:09:44.520 --> 00:09:47.960]   Composing panels together in the way we just showed is just one of the many ways that we
[00:09:47.960 --> 00:09:51.440]   achieve that.
[00:09:51.440 --> 00:09:53.240]   What other types of visualizations can we do?
[00:09:53.240 --> 00:09:55.400]   Well, of course, plots are pretty useful.
[00:09:55.400 --> 00:09:57.560]   And Weave has an incredibly powerful one built in.
[00:09:57.560 --> 00:10:00.360]   You can add all kinds of layers and dimensions.
[00:10:00.360 --> 00:10:02.720]   But for now, we'll keep it simple.
[00:10:02.720 --> 00:10:10.820]   So we'll change the panel type here to plot, and then edit its configuration.
[00:10:10.820 --> 00:10:20.140]   We'll look at latency versus cost, and we'll color by prompt version.
[00:10:20.140 --> 00:10:23.580]   Cool.
[00:10:23.580 --> 00:10:27.020]   We can see some outliers here on the latency axis.
[00:10:27.020 --> 00:10:30.820]   That's pretty common when you're working with LLM APIs.
[00:10:30.820 --> 00:10:34.300]   And we can see some other outliers on the cost axis that might be interesting.
[00:10:34.300 --> 00:10:39.980]   But first we'll zoom into this big group here to get a better view.
[00:10:39.980 --> 00:10:46.420]   Yeah, and again, we can see the distribution of latencies pretty well.
[00:10:46.420 --> 00:10:50.500]   We'll make the point size a little smaller to get more space.
[00:10:50.500 --> 00:10:51.720]   That looks good.
[00:10:51.720 --> 00:10:57.300]   We can see the few-shot model truly is more expensive than the others.
[00:10:57.300 --> 00:11:00.120]   Let's zoom back out.
[00:11:00.120 --> 00:11:05.100]   And now let's look at those cost outliers.
[00:11:05.100 --> 00:11:09.540]   So the default Weave tooltip doesn't actually show you the underlying data.
[00:11:09.540 --> 00:11:11.580]   It shows you the plot values, but we can edit it.
[00:11:11.580 --> 00:11:15.900]   Here we put a dictionary in the prompt in the tooltip.
[00:11:15.900 --> 00:11:19.940]   And now we can render the actual question and answer from the underlying data.
[00:11:19.940 --> 00:11:23.340]   So we can see here, this was asking how to plot stuff with weights and biases, and we
[00:11:23.340 --> 00:11:24.820]   answered to use scikit-learn.
[00:11:24.820 --> 00:11:27.820]   That doesn't seem right.
[00:11:27.820 --> 00:11:29.940]   Cool.
[00:11:29.940 --> 00:11:37.260]   So, this was another example of how powerful composition is in Weave.
[00:11:37.260 --> 00:11:40.680]   Any panel can expose expressions and panel choices.
[00:11:40.680 --> 00:11:46.420]   Here the Weave plot tooltip gave us complete control over how we viewed our data.
[00:11:46.420 --> 00:11:50.080]   And now we'll start to break out of the Jupyter notebook to show you something brand new,
[00:11:50.080 --> 00:11:51.520]   the Weave board.
[00:11:51.520 --> 00:11:55.040]   This is a new kind of truly programmable UI, and we're only just starting to figure out
[00:11:55.040 --> 00:11:57.320]   ourselves what this powerful tool can do.
[00:11:57.320 --> 00:12:01.280]   I hope you like it.
[00:12:01.280 --> 00:12:05.920]   So in the last demo, we showed a way to drill down on a single point in a plot.
[00:12:05.920 --> 00:12:09.520]   Let's look at another type of drill down you can do in Weave.
[00:12:09.520 --> 00:12:15.280]   Starting from the table, we'll add a new panel, and we'll refer to the first panel again,
[00:12:15.280 --> 00:12:17.220]   this time asking for active data.
[00:12:17.220 --> 00:12:20.040]   Now we have a view of a single row on the right.
[00:12:20.040 --> 00:12:22.920]   So we can click on the row index on the left to select a new row.
[00:12:22.920 --> 00:12:26.040]   This is a nice drill down, a way to see more details about our data.
[00:12:26.040 --> 00:12:28.680]   But we're starting to run out of space in the notebook.
[00:12:28.680 --> 00:12:30.760]   Let's click the full screen button.
[00:12:30.760 --> 00:12:34.960]   Now we're in the Weave UI, and we can see our data in all its glory.
[00:12:34.960 --> 00:12:38.880]   And from here, we can convert to a Weave board.
[00:12:38.880 --> 00:12:43.120]   The Weave board has a special area on the left for storing variables, expressions, and
[00:12:43.120 --> 00:12:46.320]   controls that we affectionately call the var bar.
[00:12:46.320 --> 00:12:49.360]   Someone internally was saying if we have a bar at the conference, we should call it the
[00:12:49.360 --> 00:12:50.360]   var bar.
[00:12:50.360 --> 00:12:54.200]   Not sure if we did that, but that would be awesome.
[00:12:54.200 --> 00:12:56.160]   So you can also lay things out as you want.
[00:12:56.160 --> 00:12:57.720]   We're reorganizing the board here.
[00:12:57.720 --> 00:13:00.960]   And now we're going to add a different type of visualization.
[00:13:00.960 --> 00:13:05.160]   So our data set contains synthetic evaluation results for each of the QA pairs.
[00:13:05.160 --> 00:13:08.480]   Let's get a view of how each model did across those evaluations.
[00:13:08.480 --> 00:13:10.200]   We do it using the facet panel.
[00:13:10.200 --> 00:13:14.360]   So we're setting the x dimension to the prompt version and the y dimension to the synthetic
[00:13:14.360 --> 00:13:18.820]   grader response.
[00:13:18.820 --> 00:13:23.480]   And then we'll set the cell to show the count of the intersection.
[00:13:23.480 --> 00:13:24.480]   Awesome.
[00:13:24.480 --> 00:13:29.800]   Now, down here we can see the counts of how each model did.
[00:13:29.800 --> 00:13:33.600]   But it's kind of hard to read numbers like this, so let's add some color.
[00:13:33.600 --> 00:13:38.560]   We split the panel into two, convert one of them into a color panel, change that to a
[00:13:38.560 --> 00:13:43.840]   layer, and normalize the data a little bit by manipulating the Weave expression.
[00:13:43.840 --> 00:13:47.840]   Now we have a nice-looking, almost confusion matrix of our data.
[00:13:47.840 --> 00:13:51.760]   Still, we want to see the individual examples every time we do something like this.
[00:13:51.760 --> 00:13:53.200]   So we want to drill down.
[00:13:53.200 --> 00:13:57.320]   We can click a cell here and then refer to the selected state on the left so that now
[00:13:57.320 --> 00:14:00.920]   when we pick a cell in the confusion matrix, we can see the actual examples that make it
[00:14:00.920 --> 00:14:03.200]   up.
[00:14:03.200 --> 00:14:07.520]   Here the grader ding the response for not including enough detail, which seems fair
[00:14:07.520 --> 00:14:08.520]   in this case.
[00:14:08.520 --> 00:14:09.520]   OK.
[00:14:09.520 --> 00:14:15.380]   We're going to add one more visualization, a distribution.
[00:14:15.380 --> 00:14:18.120]   And for this, we'll use a distribution plot.
[00:14:18.120 --> 00:14:28.320]   So we can compare latencies across models.
[00:14:28.320 --> 00:14:29.320]   There we go.
[00:14:29.320 --> 00:14:30.320]   But there's a problem here.
[00:14:30.320 --> 00:14:33.200]   Our data is not actually showing up, and it's cut off at the bottom of the screen.
[00:14:33.200 --> 00:14:38.000]   But if we could see the x-axis, we would see that it looks like the data axis is extended
[00:14:38.000 --> 00:14:41.000]   way far out, so there must be outliers pulling it out.
[00:14:41.000 --> 00:14:44.280]   So we can come up here and add a new Weave expression to filter that data out of the
[00:14:44.280 --> 00:14:46.160]   data set.
[00:14:46.160 --> 00:14:51.200]   We'll give that expression a nice variable name.
[00:14:51.200 --> 00:14:54.120]   And then we can refer to it in this plot.
[00:14:54.120 --> 00:14:55.760]   Cool.
[00:14:55.760 --> 00:14:57.560]   There's the data.
[00:14:57.560 --> 00:15:01.080]   Now let's just change the bin size to make it a little finer grained.
[00:15:01.080 --> 00:15:03.760]   And it looks like we've cut the data off with our filter.
[00:15:03.760 --> 00:15:09.000]   So we'll go back up and extend the filter.
[00:15:09.000 --> 00:15:11.440]   And now we have what we want to see.
[00:15:11.440 --> 00:15:15.160]   So a great next step from here would be to normalize the latency distributions using
[00:15:15.160 --> 00:15:17.960]   the var bar to get a fair comparison.
[00:15:17.960 --> 00:15:18.960]   Okay.
[00:15:18.960 --> 00:15:20.840]   The Weave board is super cool.
[00:15:20.840 --> 00:15:24.660]   It's a powerful new tool, a WYSIWYG UI for programmers, and we're only just scratching
[00:15:24.660 --> 00:15:26.880]   the surface of what it can do.
[00:15:26.880 --> 00:15:32.960]   Now before we leave, did you notice the publish button earlier in the upper right-hand corner?
[00:15:32.960 --> 00:15:38.640]   You can publish anything you do in Weave to weights and biases.
[00:15:38.640 --> 00:15:40.940]   Published Weave objects are stored in WMB artifacts.
[00:15:40.940 --> 00:15:46.480]   You can see all your published objects, dashboards and objects at weave.wanby.ai and use them
[00:15:46.480 --> 00:15:49.000]   in WMB workspaces and reports.
[00:15:49.000 --> 00:15:52.400]   And you can share anything with your team or the world.
[00:15:52.400 --> 00:15:54.220]   Okay.
[00:15:54.220 --> 00:15:56.400]   Now let's talk about the Weave ecosystem.
[00:15:56.400 --> 00:15:59.680]   We're just getting started with the ecosystem, and you can find all of our experiments in
[00:15:59.680 --> 00:16:06.200]   the Weave ecosystem folder in the repo.
[00:16:06.200 --> 00:16:09.360]   I'm going to explain this a little bit because this goes by super fast.
[00:16:09.360 --> 00:16:13.600]   So we're first going to show how easy it is to render other data types in Weave.
[00:16:13.600 --> 00:16:16.760]   We'll create a list of dictionaries that have some pill images in them, and when we run
[00:16:16.760 --> 00:16:21.280]   that top cell, we'll get a familiar Weave table with the images in line.
[00:16:21.280 --> 00:16:24.080]   If we want to add a new operation, we'll run the third cell.
[00:16:24.080 --> 00:16:25.760]   It's very blurry.
[00:16:25.760 --> 00:16:34.220]   There's code in there that creates a Weave op, and then we call it from the UI.
[00:16:34.220 --> 00:16:36.880]   So here's our table with images in it.
[00:16:36.880 --> 00:16:41.540]   We run the cell below, and now we can add a new column that uses that operation to flip
[00:16:41.540 --> 00:16:44.400]   the image from left to right.
[00:16:44.400 --> 00:16:47.960]   Super easy.
[00:16:47.960 --> 00:16:51.300]   Next we're going to show how Weave seamlessly integrates different libraries from the community.
[00:16:51.300 --> 00:16:55.840]   So here we'll use our hugging face integration to load in a motion classifier model.
[00:16:55.840 --> 00:17:01.320]   The panel shows the model card by default, but we can also call the model.
[00:17:01.320 --> 00:17:04.920]   So we're going to call it with the string "I'm in love."
[00:17:04.920 --> 00:17:10.060]   And we can see that the model actually classifies love as mostly anger and joy, which is surprising
[00:17:10.060 --> 00:17:11.060]   to us.
[00:17:11.060 --> 00:17:12.880]   Why is it doing that?
[00:17:12.880 --> 00:17:17.820]   So we can ask for the attention that was paid off of this model, and we get a new view that's
[00:17:17.820 --> 00:17:22.340]   registered called the BERT_VIZ_HEAD_VIEW from a different library in the ecosystem.
[00:17:22.340 --> 00:17:26.680]   This is a little interactive visualization for understanding attention.
[00:17:26.680 --> 00:17:30.020]   But I still can't really tell what's going on here, so let's try another one.
[00:17:30.020 --> 00:17:37.180]   We use the SHAP_EXPLAIN_OP to get SHAP values that maybe will give us another view.
[00:17:37.180 --> 00:17:43.480]   So this will render a SHAP visualization where we can hover over the words in our input to
[00:17:43.480 --> 00:17:44.860]   see where the attention was paid.
[00:17:44.860 --> 00:17:48.740]   And we can see when we hover over anger, it's actually paying attention to the exclamation
[00:17:48.740 --> 00:17:49.740]   point.
[00:17:49.740 --> 00:17:53.980]   So maybe if we remove that, we'll get something better.
[00:17:53.980 --> 00:17:56.800]   Yeah.
[00:17:56.800 --> 00:18:01.560]   Now the model mostly classifies love as love, and just the right amount of anger to keep
[00:18:01.560 --> 00:18:04.900]   things interesting.
[00:18:04.900 --> 00:18:08.500]   Yeah.
[00:18:08.500 --> 00:18:16.360]   Model understanding and explainability are becoming more and more important as models
[00:18:16.360 --> 00:18:18.340]   get larger and more powerful.
[00:18:18.340 --> 00:18:23.180]   Weave's type dispatch system means that anyone can publish a new explainability technique
[00:18:23.180 --> 00:18:26.340]   and make it available to everyone else who has the right type of data.
[00:18:26.340 --> 00:18:29.560]   This is one of the primary reasons Weave is designed the way it is, and I hope it helps
[00:18:29.560 --> 00:18:34.540]   the community in the work needed to understand these models at a fundamental level.
[00:18:34.540 --> 00:18:35.540]   Okay.
[00:18:35.540 --> 00:18:39.460]   Now, we're standing on the shoulders of giants with everything we do, but this is all the
[00:18:39.460 --> 00:18:42.580]   Weave code we needed for that BERT visualization.
[00:18:42.580 --> 00:18:46.860]   We register a new Weave op that takes the hugging face attention and returns some HTML
[00:18:46.860 --> 00:18:50.660]   using the BERT vis library, and then we register a panel that will render that in the right
[00:18:50.660 --> 00:18:51.820]   context.
[00:18:51.820 --> 00:18:54.100]   That's all you have to do.
[00:18:54.100 --> 00:18:56.900]   Okay.
[00:18:56.900 --> 00:19:03.300]   Thank you.
[00:19:03.300 --> 00:19:08.260]   And now we're going to show three small applications Weave made that put all this stuff together.
[00:19:08.260 --> 00:19:12.020]   You can find each one of these in the examples directory in the Weave repo.
[00:19:12.020 --> 00:19:15.540]   And the first one I'll show is actually kind of a toy, but I really want to say something
[00:19:15.540 --> 00:19:16.640]   about this.
[00:19:16.640 --> 00:19:20.940]   Making stuff fun to play with is a really important part of product development for
[00:19:20.940 --> 00:19:21.940]   us.
[00:19:21.940 --> 00:19:26.620]   We spend so much time on making it feel nice to resize panels in WMB workspaces, or why
[00:19:26.620 --> 00:19:29.860]   the WMB logo animates when you hover over it.
[00:19:29.860 --> 00:19:31.940]   Play and experimentation are closely related.
[00:19:31.940 --> 00:19:35.440]   You need to play with these models to understand how they work and make use of them.
[00:19:35.440 --> 00:19:41.560]   So crossing the threshold of fun in Weave boards was a huge moment for us.
[00:19:41.560 --> 00:19:45.620]   So this is a Weave board that uses a language model to generate a storyboard for a film,
[00:19:45.620 --> 00:19:50.020]   and then uses stable diffusion to render each panel in the storyboard.
[00:19:50.020 --> 00:19:54.180]   Here we generated a storyboard about a rollerblading documentary by Wes Anderson, who's feeling
[00:19:54.180 --> 00:19:55.180]   worldly.
[00:19:55.180 --> 00:20:01.180]   And you can change any of the parameters, prompts, or structures by editing the var bar.
[00:20:01.180 --> 00:20:05.200]   I want to call your attention to one thing as we click through here.
[00:20:05.200 --> 00:20:11.580]   We asked the chat model to output the storyline as a JSON list structure, and then we just
[00:20:11.580 --> 00:20:13.980]   parsed the JSON list using a Weave op.
[00:20:13.980 --> 00:20:18.980]   So the format of that JSON list that actually comes out in this UI changes from run to run.
[00:20:18.980 --> 00:20:22.380]   So you'll see that table on the top shift around if you come play with this thing.
[00:20:22.380 --> 00:20:23.540]   You'll have all different columns.
[00:20:23.540 --> 00:20:26.700]   It just depends on what GPT decided to do.
[00:20:26.700 --> 00:20:29.900]   So essentially we're letting the model generate the Weave UI here, and I just think that's
[00:20:29.900 --> 00:20:31.840]   like super cool.
[00:20:31.840 --> 00:20:36.040]   This next one is an evaluation playground we use for the doc bot we talked about earlier.
[00:20:36.040 --> 00:20:39.380]   So this makes use of our integration with the awesome Lang chain library you'll hear
[00:20:39.380 --> 00:20:41.420]   about later.
[00:20:41.420 --> 00:20:45.380]   And in the var bar we've configured the entire pipeline for two models.
[00:20:45.380 --> 00:20:49.620]   We load our documents and questions from Weave objects, create a vector store, create two
[00:20:49.620 --> 00:20:53.420]   different models or chains for comparison, and you can add new questions or documents
[00:20:53.420 --> 00:20:57.220]   by saving new versions of Weave objects, and soon you'll be able to edit the data right
[00:20:57.220 --> 00:20:59.100]   here in the UI.
[00:20:59.100 --> 00:21:03.220]   Weave's powerful memoization model means that we'll only recompute what's necessary whenever
[00:21:03.220 --> 00:21:04.220]   parameters change.
[00:21:04.220 --> 00:21:13.820]   So if you add new questions to the list, it'll just make two new LLM API calls.
[00:21:13.820 --> 00:21:22.500]   So here we are clicking through the var bar to see how it's configured.
[00:21:22.500 --> 00:21:25.940]   At the top we can test our model with new questions, so we can ask whatever we want
[00:21:25.940 --> 00:21:28.260]   here and see new results.
[00:21:28.260 --> 00:21:32.900]   We can compare the model outputs and see other stats like latency, and we can click down
[00:21:32.900 --> 00:21:37.180]   to view traces of the Lang chain executions using the WBB trace viewer.
[00:21:37.180 --> 00:21:41.540]   The next table lets us explore inference results across all the questions we loaded in.
[00:21:41.540 --> 00:21:47.500]   Here we're comparing 10 negative and positively reviewed responses.
[00:21:47.500 --> 00:21:52.300]   We can drill down on a projection of the docs in our vector store here, and we can see that
[00:21:52.300 --> 00:21:57.740]   that pink cluster is mostly the Weave documentation, and we can do similarity searches on the vector
[00:21:57.740 --> 00:22:00.980]   store to help us understand it better.
[00:22:00.980 --> 00:22:06.180]   So Weave boards are a fantastic way to do prompt engineering and build LLM applications.
[00:22:06.180 --> 00:22:10.340]   You can build up a set of helpful visualizations and tools that are unique to the specific
[00:22:10.340 --> 00:22:12.140]   problem you're trying to solve.
[00:22:12.140 --> 00:22:16.500]   Okay, now this last application is incredibly important.
[00:22:16.500 --> 00:22:20.820]   People have been asking me to do this for a very long time, so I'm proud to say that
[00:22:20.820 --> 00:22:28.300]   today we're launching production monitoring.
[00:22:28.300 --> 00:22:31.860]   You can log production data to weights and biases with a few lines of code and get beautiful
[00:22:31.860 --> 00:22:36.500]   Weave dashboards that you can customize to your use case.
[00:22:36.500 --> 00:22:39.900]   We'll take a quick look at a production monitoring dashboard for a completion model we've been
[00:22:39.900 --> 00:22:42.700]   running since January.
[00:22:42.700 --> 00:22:47.820]   So on the top, we can see the count of predictions we've made for each model version, and on
[00:22:47.820 --> 00:22:52.340]   the right, we can see the count of predictions we've made for each user.
[00:22:52.340 --> 00:22:57.980]   Below we have different views on API cost, token count, and latency, and at the bottom,
[00:22:57.980 --> 00:23:07.540]   we have a table of all the records that are displayed in the dashboard.
[00:23:07.540 --> 00:23:09.820]   We can edit the time range to zoom out.
[00:23:09.820 --> 00:23:12.780]   Soon we'll add a date picker control, so you can use that if you'd rather have something
[00:23:12.780 --> 00:23:14.420]   visual.
[00:23:14.420 --> 00:23:17.820]   And we can see that our service has been steadily growing as we've continued to add new model
[00:23:17.820 --> 00:23:18.820]   versions.
[00:23:18.820 --> 00:23:19.820]   Awesome.
[00:23:19.820 --> 00:23:23.500]   You can click on items in the table to drill down or use the controls in the sidebar.
[00:23:23.500 --> 00:23:29.340]   So let's filter down to model version 1.4.
[00:23:29.340 --> 00:23:32.900]   The whole dashboard updates to this slice, and we can see that we ran this particular
[00:23:32.900 --> 00:23:35.620]   version between January and February.
[00:23:35.620 --> 00:23:38.740]   We had a lot less usage back then.
[00:23:38.740 --> 00:23:43.820]   So all of this is totally configurable in Weave, from the way the charts do their aggregations
[00:23:43.820 --> 00:23:49.040]   to the exact setup details of the VARBAR.
[00:23:49.040 --> 00:23:52.320]   So that was a really, really quick look at production monitoring with Weights and Biases
[00:23:52.320 --> 00:23:53.320]   in Weave.
[00:23:53.320 --> 00:23:58.420]   We'll be providing out-of-the-box starting dashboards for different problem domains,
[00:23:58.420 --> 00:24:01.980]   but as you learn about the problems you're trying to solve, you can add new views, capabilities,
[00:24:01.980 --> 00:24:05.780]   and techniques by taking advantage of the growing Weave ecosystem or extending Weave
[00:24:05.780 --> 00:24:09.380]   with those three simple primitives.
[00:24:09.380 --> 00:24:11.380]   So that's Weave.
[00:24:11.380 --> 00:24:14.920]   Now I've been working on this for a very long time.
[00:24:14.920 --> 00:24:18.740]   And actually, it's these folks who have been working on Weave for a very long time.
[00:24:18.740 --> 00:24:23.180]   So we're really lucky that we get to work in this space with customers and users like
[00:24:23.180 --> 00:24:25.340]   all of you on problems that we love.
[00:24:25.340 --> 00:24:30.260]   But there's been a massive amount of blood, sweat, and tears poured into making this happen.
[00:24:30.260 --> 00:24:35.060]   And I'm so proud of this team and everyone else at WMB for the work that they do.
[00:24:35.060 --> 00:24:44.380]   So thank you.
[00:24:44.380 --> 00:24:48.300]   We focused on the details from the inside out to enable the next generation of ML apps
[00:24:48.300 --> 00:24:49.420]   and tooling.
[00:24:49.420 --> 00:24:53.700]   It's early, there are sharp edges and gotchas, but the system is also incredibly powerful
[00:24:53.700 --> 00:24:54.700]   and fun.
[00:24:54.700 --> 00:24:56.820]   And I couldn't be more excited to put it in your hands.
[00:24:56.820 --> 00:25:00.580]   So go out and try Weave or go to the link above to get in touch with us about production
[00:25:00.580 --> 00:25:01.580]   monitoring.
[00:25:01.580 --> 00:25:02.580]   And thank you all very much.
[00:25:02.580 --> 00:25:02.580]   [APPLAUSE]
[00:25:03.340 --> 00:25:09.340]   [MUSIC PLAYING]
[00:25:09.340 --> 00:25:12.700]   [MUSIC]

