
[00:00:00.000 --> 00:00:02.040]   Hardship will show you who your real friends are,
[00:00:02.040 --> 00:00:03.440]   that's for sure.
[00:00:03.440 --> 00:00:05.640]   Okay, read the quote once more.
[00:00:05.640 --> 00:00:08.740]   "Don't eat with people you wouldn't starve with."
[00:00:08.740 --> 00:00:16.400]   The following is a conversation with Andrew Huberman,
[00:00:16.400 --> 00:00:18.480]   his fifth time on the podcast.
[00:00:18.480 --> 00:00:22.440]   He is the host of the Huberman Lab podcast
[00:00:22.440 --> 00:00:26.480]   and is an amazing scientist, teacher, human being,
[00:00:26.480 --> 00:00:28.520]   and someone I'm grateful
[00:00:28.520 --> 00:00:31.000]   to be able to call a close friend.
[00:00:31.000 --> 00:00:34.160]   Also, he has a book coming out next year
[00:00:34.160 --> 00:00:37.980]   that you should pre-order now called "Protocols,"
[00:00:37.980 --> 00:00:40.840]   an operating manual for the human body.
[00:00:40.840 --> 00:00:42.720]   This is the Lex Huberman Podcast.
[00:00:42.720 --> 00:00:43.560]   To support it,
[00:00:43.560 --> 00:00:45.960]   please check out our sponsors in the description.
[00:00:45.960 --> 00:00:49.600]   And now, dear friends, here's Andrew Huberman.
[00:00:49.600 --> 00:00:51.760]   You think there's ever gonna be a day
[00:00:51.760 --> 00:00:53.760]   when you walk away from podcasting?
[00:00:53.760 --> 00:00:55.200]   Definitely.
[00:00:55.200 --> 00:00:58.600]   I mean, I came up within
[00:00:58.600 --> 00:01:03.320]   and then on the periphery of skateboard culture.
[00:01:03.320 --> 00:01:05.400]   And for the record, I was not a great skateboarder.
[00:01:05.400 --> 00:01:06.240]   I always have to say that
[00:01:06.240 --> 00:01:08.400]   'cause skateboarders are relentless.
[00:01:08.400 --> 00:01:11.200]   If you call something you didn't do or whatever.
[00:01:11.200 --> 00:01:14.480]   I mean, I could do a few things and I loved the community,
[00:01:14.480 --> 00:01:17.000]   and I still have a lot of friends in that community.
[00:01:17.000 --> 00:01:19.440]   Jim Thiebaud at Deluxe, you can look him up.
[00:01:19.440 --> 00:01:21.680]   He's kind of the man behind the whole scene.
[00:01:21.680 --> 00:01:24.960]   I know Tony Hawk, Danny Whale, these guys.
[00:01:24.960 --> 00:01:27.360]   I got to see them come up and get big
[00:01:27.360 --> 00:01:29.640]   and stay big in many cases, start huge companies
[00:01:29.640 --> 00:01:31.960]   like Danny and Colin McKay's are DC.
[00:01:31.960 --> 00:01:35.920]   Some people have a long life in something, some don't.
[00:01:35.920 --> 00:01:37.900]   But one thing I observed and learned a lot from
[00:01:37.900 --> 00:01:42.840]   in skateboarding at the level of observing the skateboarders
[00:01:42.840 --> 00:01:45.080]   and then the ones that started companies.
[00:01:45.080 --> 00:01:49.160]   And then what I also observed in science
[00:01:49.160 --> 00:01:52.440]   and still observe is you do it for a while,
[00:01:53.320 --> 00:01:56.800]   you do it at the highest possible level for you,
[00:01:56.800 --> 00:01:59.080]   and then at some point you pivot
[00:01:59.080 --> 00:02:03.160]   and you start supporting the young talent coming in.
[00:02:03.160 --> 00:02:04.680]   In fact, the greatest scientists,
[00:02:04.680 --> 00:02:07.840]   people like Richard Axel, Catherine Duloc,
[00:02:07.840 --> 00:02:11.600]   there are many other labs in neuroscience, Karl Deisseroth.
[00:02:11.600 --> 00:02:13.640]   They're not just known for doing great science,
[00:02:13.640 --> 00:02:16.840]   they're known for mentoring some of the best scientists
[00:02:16.840 --> 00:02:18.920]   that then go on to start their own labs.
[00:02:18.920 --> 00:02:20.880]   And I think in podcasting,
[00:02:20.880 --> 00:02:23.840]   I am very fortunate I got in in a fairly early wave,
[00:02:23.840 --> 00:02:25.160]   not the earliest wave,
[00:02:25.160 --> 00:02:27.560]   but thanks to your suggestion of doing a podcast,
[00:02:27.560 --> 00:02:28.800]   fairly early wave.
[00:02:28.800 --> 00:02:31.680]   And I'll continue to go as long as it feels right.
[00:02:31.680 --> 00:02:33.040]   And I feel like I'm doing good in the world
[00:02:33.040 --> 00:02:34.200]   and providing good.
[00:02:34.200 --> 00:02:36.880]   But I'm already starting to scout talent.
[00:02:36.880 --> 00:02:40.340]   My company that I started with Rob Moore,
[00:02:40.340 --> 00:02:43.000]   Sycom Media, there's a couple other guys in there too,
[00:02:43.000 --> 00:02:45.320]   Mike Blayback, our photographer, Ian Mackey,
[00:02:45.320 --> 00:02:47.660]   Chris Ray, Martin Fobes.
[00:02:48.700 --> 00:02:51.280]   We are a company that produces podcasts.
[00:02:51.280 --> 00:02:52.680]   Right now that's Huberman Lab Podcast,
[00:02:52.680 --> 00:02:54.180]   but we're launching a new podcast,
[00:02:54.180 --> 00:02:55.980]   Perform with Dr. Andy Galpin.
[00:02:55.980 --> 00:02:56.940]   - Nice.
[00:02:56.940 --> 00:02:58.560]   - And we wanna do more of that kind of thing,
[00:02:58.560 --> 00:02:59.960]   finding a really great talent,
[00:02:59.960 --> 00:03:02.560]   highly qualified people, credentialed people.
[00:03:02.560 --> 00:03:05.680]   And I've got a new kind of obsession
[00:03:05.680 --> 00:03:07.340]   with scouring the internet,
[00:03:07.340 --> 00:03:10.260]   looking for the young talent in science,
[00:03:10.260 --> 00:03:12.900]   in health and related fields.
[00:03:12.900 --> 00:03:16.920]   And so will there be a final episode of the HLP?
[00:03:16.920 --> 00:03:21.240]   - Yeah, I mean, bullet buster cancer aside,
[00:03:21.240 --> 00:03:23.320]   someday they'll be the very last,
[00:03:23.320 --> 00:03:25.260]   and thank you for your interest in science.
[00:03:25.260 --> 00:03:26.500]   And I'll clip out.
[00:03:26.500 --> 00:03:29.580]   - Yeah, I love the idea of walking away
[00:03:29.580 --> 00:03:31.240]   and not be dramatic about it.
[00:03:31.240 --> 00:03:32.080]   - Right.
[00:03:32.080 --> 00:03:33.260]   - When it feels right, you can leave
[00:03:33.260 --> 00:03:35.600]   and you can come back whenever the fuck you want.
[00:03:35.600 --> 00:03:36.440]   - Right.
[00:03:36.440 --> 00:03:38.780]   - Jon Stewart did this well with "The Daily Show."
[00:03:38.780 --> 00:03:41.020]   I think that was during the 2016 election
[00:03:41.020 --> 00:03:42.940]   when everybody wanted him to stay on
[00:03:42.940 --> 00:03:44.420]   and he just walked away.
[00:03:44.440 --> 00:03:48.240]   Dave Chappelle, for different reasons, walked away.
[00:03:48.240 --> 00:03:49.640]   - Disappeared, came back.
[00:03:49.640 --> 00:03:51.320]   - Gave away so much money.
[00:03:51.320 --> 00:03:52.160]   Didn't care.
[00:03:52.160 --> 00:03:55.440]   And then came back and was doing standup in the park
[00:03:55.440 --> 00:03:57.500]   in the middle of nowhere.
[00:03:57.500 --> 00:03:58.460]   Genius.
[00:03:58.460 --> 00:04:01.160]   You have Habib, who undefeated,
[00:04:01.160 --> 00:04:03.720]   walks away at the very top of a sport.
[00:04:03.720 --> 00:04:04.720]   - Is he coming back?
[00:04:04.720 --> 00:04:05.840]   - No.
[00:04:05.840 --> 00:04:07.040]   - At least we don't know.
[00:04:07.040 --> 00:04:07.880]   - Yeah.
[00:04:07.880 --> 00:04:08.720]   Right, you don't know.
[00:04:08.720 --> 00:04:09.540]   I don't know if you know.
[00:04:09.540 --> 00:04:10.380]   - Bears everywhere are worried.
[00:04:10.380 --> 00:04:12.120]   (laughing)
[00:04:12.120 --> 00:04:15.620]   - Yeah, I think it's always a call.
[00:04:15.620 --> 00:04:19.060]   The last few years have been tremendous growth.
[00:04:19.060 --> 00:04:20.660]   We launched in January, 2021.
[00:04:20.660 --> 00:04:24.820]   And even this last year, 2024, has been huge growth
[00:04:24.820 --> 00:04:26.840]   in all sorts of ways.
[00:04:26.840 --> 00:04:28.060]   It's been wild.
[00:04:28.060 --> 00:04:31.480]   And we have some short-form content planned,
[00:04:31.480 --> 00:04:35.160]   30-minute shorter episodes that really distill down
[00:04:35.160 --> 00:04:36.540]   the critical elements.
[00:04:36.540 --> 00:04:39.940]   We're also thinking about moving to other venues
[00:04:39.940 --> 00:04:41.380]   besides podcasting.
[00:04:41.380 --> 00:04:43.420]   So there's always the thought and the discussion.
[00:04:43.420 --> 00:04:45.820]   But when it comes to when to hang up your cleats,
[00:04:45.820 --> 00:04:49.180]   there just comes a natural time where you can do more
[00:04:49.180 --> 00:04:51.700]   to mentor the next generation coming in
[00:04:51.700 --> 00:04:53.620]   than focusing on self.
[00:04:53.620 --> 00:04:55.660]   And so there will come a time for that.
[00:04:55.660 --> 00:04:56.900]   And I think it's critical.
[00:04:56.900 --> 00:04:58.500]   I mean, again, I saw this in skateboarding.
[00:04:58.500 --> 00:05:01.900]   Danny and Collin and Danny's brother, Damon,
[00:05:01.900 --> 00:05:05.220]   started DC with Ken Block, the driver who unfortunately
[00:05:05.220 --> 00:05:08.460]   passed away a little while ago, rally car driver.
[00:05:08.460 --> 00:05:11.180]   And they eventually sold it, I think, to Quicksilver
[00:05:11.180 --> 00:05:12.020]   or something like that.
[00:05:12.020 --> 00:05:14.800]   But they're all phenomenal talents
[00:05:14.800 --> 00:05:16.540]   in their respective areas.
[00:05:16.540 --> 00:05:21.420]   But they brought in the next line of amazing riders,
[00:05:21.420 --> 00:05:23.560]   the Plan B thing, you know, Paul Rodriguez.
[00:05:23.560 --> 00:05:24.740]   For skateboarders, they know who this is.
[00:05:24.740 --> 00:05:28.060]   Now, in science, there are scientists
[00:05:28.060 --> 00:05:30.020]   like Feynman, for instance.
[00:05:30.020 --> 00:05:34.100]   I don't know if anyone can name one of his mentor offspring.
[00:05:34.100 --> 00:05:36.660]   So there are scientists who are phenomenal,
[00:05:36.660 --> 00:05:38.660]   like beyond world class, right?
[00:05:38.660 --> 00:05:40.940]   Multi-generational world class,
[00:05:40.940 --> 00:05:42.820]   who don't make good mentors.
[00:05:42.820 --> 00:05:43.980]   I'm not saying he wasn't a good mentor,
[00:05:43.980 --> 00:05:45.040]   but that's not what he's known for.
[00:05:45.040 --> 00:05:47.740]   And then there are scientists who are known
[00:05:47.740 --> 00:05:50.300]   for being excellent scientists and great mentors.
[00:05:50.300 --> 00:05:54.340]   And I think there's no higher celebration
[00:05:54.340 --> 00:05:55.840]   to be had at the end of one's career.
[00:05:55.840 --> 00:05:56.940]   If you can look back and like, hey,
[00:05:56.940 --> 00:05:59.680]   I put some really important knowledge into the world.
[00:05:59.680 --> 00:06:01.520]   People made use of that knowledge.
[00:06:01.520 --> 00:06:02.500]   And guess what?
[00:06:02.500 --> 00:06:07.220]   You spawned all these other scientific offspring
[00:06:07.220 --> 00:06:11.740]   or sport offspring or podcast offspring.
[00:06:11.740 --> 00:06:13.740]   I mean, in some ways we look to Rogan
[00:06:13.740 --> 00:06:16.420]   and to some of the other earlier podcasters,
[00:06:16.420 --> 00:06:18.700]   like they paved the way.
[00:06:18.700 --> 00:06:22.380]   Rhonda Patrick, first science podcast out there.
[00:06:22.380 --> 00:06:26.740]   So, you know, eventually the baton passes,
[00:06:26.740 --> 00:06:28.940]   but fortunately right now everybody's active
[00:06:28.940 --> 00:06:31.500]   and it feels really good.
[00:06:31.500 --> 00:06:33.220]   - Yeah, well, you're talking about the healthy way to do it,
[00:06:33.220 --> 00:06:37.860]   but there's also a different kind of way
[00:06:37.860 --> 00:06:41.940]   where you have somebody like Grisha Grigori Pearlman,
[00:06:41.940 --> 00:06:44.820]   the mathematician who refused to accept the Fields Medal.
[00:06:44.820 --> 00:06:46.780]   So, he's one of the greatest living mathematicians
[00:06:46.780 --> 00:06:48.700]   and he just walked away from mathematics
[00:06:48.700 --> 00:06:50.220]   and rejected the Fields Medal.
[00:06:50.220 --> 00:06:52.620]   - What did he do after he left mathematics?
[00:06:52.620 --> 00:06:55.580]   - Life, private, 100%.
[00:06:55.580 --> 00:06:56.820]   - Yeah, I respect that.
[00:06:56.820 --> 00:06:58.780]   - He's become essentially a recluse.
[00:06:58.780 --> 00:07:02.020]   These photos of him looking very broke,
[00:07:02.020 --> 00:07:03.660]   like he could use the money.
[00:07:03.660 --> 00:07:06.260]   He turned away the money, he turned away everything.
[00:07:06.260 --> 00:07:10.740]   You just have to listen to the inner voice,
[00:07:10.740 --> 00:07:11.740]   you have to listen to yourself
[00:07:11.740 --> 00:07:13.860]   and make the decisions that don't make any sense
[00:07:13.860 --> 00:07:16.380]   for the rest of the world and make sense to you.
[00:07:16.380 --> 00:07:17.500]   - I mean, Bob Dylan didn't show up
[00:07:17.500 --> 00:07:19.140]   to pick up his Nobel Peace Prize.
[00:07:19.140 --> 00:07:19.980]   That's punk.
[00:07:19.980 --> 00:07:21.180]   - Yeah. - Yeah.
[00:07:21.180 --> 00:07:25.580]   He probably grew in notoriety for that.
[00:07:25.580 --> 00:07:27.740]   Maybe he just doesn't like going to Sweden,
[00:07:27.740 --> 00:07:29.460]   but it seemed like it would be a fun trip.
[00:07:29.460 --> 00:07:31.180]   I think they do it in a nice time of year.
[00:07:31.180 --> 00:07:33.620]   But hey, that's his right, he earned that right.
[00:07:33.620 --> 00:07:36.220]   - I think the best artists aren't doing it for the prize.
[00:07:36.220 --> 00:07:37.940]   They aren't doing it for the fame or the money.
[00:07:37.940 --> 00:07:39.740]   They're doing it because they love the art.
[00:07:39.740 --> 00:07:41.780]   - Yeah, it's the Rick Rubin thing.
[00:07:41.780 --> 00:07:46.560]   You gotta verb it through, download your inner thing.
[00:07:46.560 --> 00:07:47.620]   I don't think we've talked about this,
[00:07:47.620 --> 00:07:50.220]   that this obsession that I have
[00:07:50.220 --> 00:07:54.580]   about how Rick has this way
[00:07:54.580 --> 00:07:57.180]   of being very, very still in his body,
[00:07:57.180 --> 00:07:59.960]   but keeping his mind very active.
[00:08:00.920 --> 00:08:03.620]   As a practice, I went and spent some time with him
[00:08:03.620 --> 00:08:06.660]   in Italy last June, and we would tread water
[00:08:06.660 --> 00:08:08.460]   in his pool in the morning and listen
[00:08:08.460 --> 00:08:11.700]   to a history of rock and roll and 100 songs.
[00:08:11.700 --> 00:08:14.180]   Amazing podcast, by the way.
[00:08:14.180 --> 00:08:15.380]   - It is. - Yeah.
[00:08:15.380 --> 00:08:17.580]   And then he would spend a fair amount of time
[00:08:17.580 --> 00:08:20.080]   during the day in this kind of meditative state
[00:08:20.080 --> 00:08:22.760]   where his mind is very active, body very still.
[00:08:22.760 --> 00:08:25.540]   And then Karl Deisseroth, when he came on my podcast,
[00:08:25.540 --> 00:08:27.620]   talked about how he forces himself to sit still
[00:08:27.620 --> 00:08:29.660]   and think in complete sentences late at night
[00:08:29.660 --> 00:08:31.620]   after his kids go to sleep.
[00:08:31.620 --> 00:08:36.320]   And there's a state of mind, rapid eye movement sleep,
[00:08:36.320 --> 00:08:38.340]   where your body is completely paralyzed
[00:08:38.340 --> 00:08:39.700]   and the mind is extremely active.
[00:08:39.700 --> 00:08:41.340]   And people credit rapid eye movement sleep
[00:08:41.340 --> 00:08:44.360]   with some of the more elaborate emotion-filled dreams
[00:08:44.360 --> 00:08:47.140]   and the source of many ideas.
[00:08:47.140 --> 00:08:49.180]   And there are other examples.
[00:08:49.180 --> 00:08:53.860]   Einstein, people described him as taking walks
[00:08:53.860 --> 00:08:56.600]   around the Princeton campus, then pausing,
[00:08:56.600 --> 00:08:58.980]   and would ask him what was going on.
[00:08:58.980 --> 00:09:00.780]   And the idea that his mind was continuing
[00:09:00.780 --> 00:09:03.120]   to churn forward at a high rate.
[00:09:03.120 --> 00:09:08.500]   So this is far from controlled studies,
[00:09:08.500 --> 00:09:10.860]   but we're talking about some incredible minds
[00:09:10.860 --> 00:09:14.960]   and creatives who have a practice of stilling the body
[00:09:14.960 --> 00:09:17.980]   while keeping the mind deliberately very active,
[00:09:17.980 --> 00:09:19.480]   very similar to rapid eye movement sleep.
[00:09:19.480 --> 00:09:22.380]   And then there are a lot of people who also report
[00:09:22.380 --> 00:09:25.860]   great ideas coming to them in the shower, while running.
[00:09:25.860 --> 00:09:27.140]   So it can be the opposite as well,
[00:09:27.140 --> 00:09:29.440]   where the body is very active and the mind
[00:09:29.440 --> 00:09:34.060]   is perhaps more on kind of like a default mode network,
[00:09:34.060 --> 00:09:36.300]   not really focusing on any one specific thing.
[00:09:36.300 --> 00:09:38.820]   - You know, interesting, there's a bunch of physicists
[00:09:38.820 --> 00:09:40.700]   and mathematicians I've talked to.
[00:09:40.700 --> 00:09:44.060]   They talk about sleep deprivation
[00:09:44.060 --> 00:09:46.180]   and going crazy hours through the night,
[00:09:46.180 --> 00:09:48.460]   obsessively pursuing a thing.
[00:09:48.460 --> 00:09:50.740]   And then the solution to the problem comes
[00:09:50.740 --> 00:09:52.660]   when they finally get rest.
[00:09:52.660 --> 00:09:56.180]   - Right, and we know, we just did this six episode
[00:09:56.180 --> 00:09:59.740]   special series on sleep with Matt Walker.
[00:09:59.740 --> 00:10:04.300]   We know that when you deprive yourself of sleep
[00:10:04.300 --> 00:10:06.540]   and then you get sleep, you get a rebound
[00:10:06.540 --> 00:10:08.540]   in rapid eye movement sleep, you get a higher percentage
[00:10:08.540 --> 00:10:10.340]   of rapid eye movement sleep.
[00:10:10.340 --> 00:10:12.420]   And Matt talks about this in the podcast
[00:10:12.420 --> 00:10:16.380]   and he did an episode on sleep and creativity,
[00:10:16.380 --> 00:10:18.420]   sleep and memory, and rapid eye movement sleep
[00:10:18.420 --> 00:10:21.020]   comes up multiple times in that series.
[00:10:21.020 --> 00:10:23.500]   There's also some very interesting stuff
[00:10:23.500 --> 00:10:26.300]   about cannabis withdrawal and rapid eye movement sleep.
[00:10:26.300 --> 00:10:27.500]   People are coming off cannabis,
[00:10:27.500 --> 00:10:30.580]   often will suffer from insomnia,
[00:10:30.580 --> 00:10:32.160]   but when they finally do start sleeping,
[00:10:32.160 --> 00:10:34.300]   they like dream like crazy.
[00:10:34.300 --> 00:10:36.460]   Cannabis is a very controversial topic right now.
[00:10:36.460 --> 00:10:38.020]   - Oh yeah, I saw that, what happened?
[00:10:38.020 --> 00:10:40.860]   There's a bunch of drama around episode
[00:10:40.860 --> 00:10:42.260]   you did on cannabis.
[00:10:42.260 --> 00:10:44.820]   - Yeah, we did an episode about cannabis,
[00:10:44.820 --> 00:10:46.860]   talked about the health benefits
[00:10:46.860 --> 00:10:48.500]   and the potential risks, right?
[00:10:48.500 --> 00:10:51.140]   It's neither here nor there.
[00:10:51.140 --> 00:10:52.860]   Depends on the person, depends on the age,
[00:10:52.860 --> 00:10:55.920]   depends on genetic background, a number of other things.
[00:10:55.920 --> 00:11:01.340]   We published that episode well over a year ago
[00:11:01.340 --> 00:11:04.980]   and it had no issues online, so to speak.
[00:11:04.980 --> 00:11:07.640]   And then a clip of it was put to X
[00:11:07.640 --> 00:11:11.600]   where the real action occurs, as you know,
[00:11:11.600 --> 00:11:12.860]   your favorite spot.
[00:11:12.860 --> 00:11:16.180]   Yeah, the four ounce gloves
[00:11:16.180 --> 00:11:18.620]   as opposed to the 16 ounce gloves,
[00:11:18.620 --> 00:11:22.260]   that is X versus Instagram or YouTube.
[00:11:22.900 --> 00:11:26.780]   There was kind of an immediate dog pile
[00:11:26.780 --> 00:11:30.580]   from a few people in the cannabis research field.
[00:11:30.580 --> 00:11:32.380]   - The PhDs and MDs, yeah.
[00:11:32.380 --> 00:11:33.800]   - There were people on our side,
[00:11:33.800 --> 00:11:35.000]   there were people not on our side.
[00:11:35.000 --> 00:11:40.000]   I mean, the statement that got things riled up the most
[00:11:40.000 --> 00:11:45.140]   was this notion that for certain individuals,
[00:11:45.140 --> 00:11:49.980]   there's a high potential for inducing psychosis
[00:11:49.980 --> 00:11:52.980]   with high THC-containing cannabis.
[00:11:52.980 --> 00:11:54.700]   For certain individuals, not all.
[00:11:54.700 --> 00:11:57.820]   That sparked some issues.
[00:11:57.820 --> 00:12:00.820]   There was really a split.
[00:12:00.820 --> 00:12:03.380]   You know, you see this in different fields.
[00:12:03.380 --> 00:12:05.940]   There was one person in particular
[00:12:05.940 --> 00:12:08.600]   who came out swinging with language
[00:12:08.600 --> 00:12:11.020]   that in my opinion is not like of the sort
[00:12:11.020 --> 00:12:14.460]   that you would use at a university venue,
[00:12:14.460 --> 00:12:17.100]   especially among colleagues, but that's fine.
[00:12:17.100 --> 00:12:18.100]   You know, we're all grownups.
[00:12:18.100 --> 00:12:19.700]   - Well, for me, from my perspective,
[00:12:19.700 --> 00:12:24.700]   it was strangely rude, and it had an air of like elitism
[00:12:24.700 --> 00:12:32.100]   that to me was at the source of the problem during COVID
[00:12:32.100 --> 00:12:36.860]   that led to the distrust of science
[00:12:36.860 --> 00:12:40.220]   and the popularization of disrespecting science
[00:12:40.220 --> 00:12:42.500]   because so many scientists spoke with an arrogance
[00:12:42.500 --> 00:12:45.500]   and a douchebaggery that I wish we would have
[00:12:45.500 --> 00:12:47.060]   a little bit less of.
[00:12:47.060 --> 00:12:49.860]   - Yeah, it's tough because most academics
[00:12:49.860 --> 00:12:52.760]   don't understand that people outside the university system
[00:12:52.760 --> 00:12:59.220]   they're not familiar with the inner workings of science
[00:12:59.220 --> 00:13:03.700]   and the culture, and so you have to be very careful
[00:13:03.700 --> 00:13:07.260]   how you present when you're a university professor.
[00:13:07.260 --> 00:13:09.480]   And when, yeah, so he came out swinging
[00:13:09.480 --> 00:13:12.300]   in some four-letter word-type language,
[00:13:12.300 --> 00:13:13.500]   and he was obviously upset about it,
[00:13:13.500 --> 00:13:15.700]   so I simply said what I would say anywhere,
[00:13:15.700 --> 00:13:18.700]   which was, hey, come on the podcast, let's chat.
[00:13:18.700 --> 00:13:21.700]   And why don't you give your, tell me where I'm wrong,
[00:13:21.700 --> 00:13:26.700]   and let's discuss, and fortunately, he agreed.
[00:13:26.700 --> 00:13:29.260]   And initially, he said, well, no, how can I be sure
[00:13:29.260 --> 00:13:30.740]   you're not gonna misrepresent me?
[00:13:30.740 --> 00:13:35.240]   And so I said, we got on a DM, then an email,
[00:13:35.240 --> 00:13:36.780]   then eventually a phone call, and just said, hey, listen,
[00:13:36.780 --> 00:13:39.060]   like, you're welcome to record the whole conversation.
[00:13:39.060 --> 00:13:41.100]   We've never done a gotcha on my podcast,
[00:13:41.100 --> 00:13:42.500]   and let's just get to the heart of the matter.
[00:13:42.500 --> 00:13:47.380]   I think this little controversy is perfect kindling
[00:13:47.380 --> 00:13:49.540]   for a really great discussion.
[00:13:49.540 --> 00:13:52.940]   And he had some other conditions that we worked out,
[00:13:52.940 --> 00:13:56.460]   and I felt like, cool, like he's really interested.
[00:13:56.460 --> 00:13:58.140]   You get a very different person on the phone
[00:13:58.140 --> 00:13:59.540]   than you do on Twitter.
[00:13:59.540 --> 00:14:00.860]   I will say he's been very collegial,
[00:14:00.860 --> 00:14:03.240]   and that conversation is on the schedule.
[00:14:03.240 --> 00:14:04.980]   I said, we'll fly you out, we'll put you up.
[00:14:04.980 --> 00:14:06.240]   He said, no, he wants to fly himself.
[00:14:06.240 --> 00:14:08.940]   He really wants to make sure that there's kind of a space
[00:14:08.940 --> 00:14:12.100]   between, I think some of the perception
[00:14:12.100 --> 00:14:15.020]   of science and health podcasts in the academic community
[00:14:15.020 --> 00:14:17.380]   is that it's all designed to sell something.
[00:14:17.380 --> 00:14:20.100]   No, we run ads so it can be free to everyone else.
[00:14:20.100 --> 00:14:23.420]   But I think, look, in the end, he agreed,
[00:14:23.420 --> 00:14:25.340]   and I'm excited for the conversation.
[00:14:25.340 --> 00:14:28.980]   It was interesting because in the wake of that
[00:14:28.980 --> 00:14:33.260]   little exchange, there's been a bunch of press
[00:14:33.260 --> 00:14:36.100]   from traditional press about cannabis
[00:14:36.100 --> 00:14:39.580]   has now surpassed alcohol in many cultures
[00:14:39.580 --> 00:14:43.100]   as within the United States as, when I say cultures,
[00:14:43.100 --> 00:14:46.020]   I mean demographics, the United States
[00:14:46.020 --> 00:14:47.640]   as the drug of choice.
[00:14:47.640 --> 00:14:50.100]   There have been people highlighting the issues
[00:14:50.100 --> 00:14:53.700]   of potential psychosis and high THC containing.
[00:14:53.700 --> 00:14:55.740]   And so it's kind of interesting to see
[00:14:55.740 --> 00:14:58.420]   how traditional media is sort of on board certain elements
[00:14:58.420 --> 00:15:01.600]   that I put forward, and I think there's some controversy
[00:15:01.600 --> 00:15:03.420]   as to whether or not the different strains,
[00:15:03.420 --> 00:15:07.020]   the indicas and sativas are biologically different, et cetera.
[00:15:07.020 --> 00:15:09.980]   So we'll get down into the weeds, pun intended,
[00:15:09.980 --> 00:15:11.340]   during that one, and I'm excited.
[00:15:11.340 --> 00:15:14.160]   It's the first time that we've responded
[00:15:14.160 --> 00:15:19.160]   to a direct criticism online about scientific content
[00:15:19.160 --> 00:15:20.820]   in a way that really promoted like,
[00:15:20.820 --> 00:15:23.580]   oh, here, the idea of inviting a particular guest.
[00:15:23.580 --> 00:15:24.840]   And so it's great, let's get a guest
[00:15:24.840 --> 00:15:26.660]   who is an expert in cannabis.
[00:15:26.660 --> 00:15:28.420]   I believe, I could be wrong about this,
[00:15:28.420 --> 00:15:30.580]   that he's a behavioral neuroscientist.
[00:15:30.580 --> 00:15:31.820]   It's slightly different training.
[00:15:31.820 --> 00:15:34.320]   But look, he seems highly credentialed, it'll be fun.
[00:15:34.320 --> 00:15:39.020]   And we, you know, we welcome that kind of exchange.
[00:15:39.020 --> 00:15:41.060]   - I deeply- - And I'm not being diplomatic.
[00:15:41.060 --> 00:15:42.020]   I'm just saying like, it's cool.
[00:15:42.020 --> 00:15:43.380]   Like he's coming on, you know,
[00:15:43.380 --> 00:15:45.020]   and he was friendly on the phone, right?
[00:15:45.020 --> 00:15:46.420]   Like he literally came out online
[00:15:46.420 --> 00:15:49.340]   and was like basically like, kind of like F you,
[00:15:49.340 --> 00:15:50.500]   like F this and F you.
[00:15:50.500 --> 00:15:51.900]   But you get someone on the phone and it's like,
[00:15:51.900 --> 00:15:52.740]   hey, how's it going?
[00:15:52.740 --> 00:15:54.820]   And they're like, oh yeah, well, you know,
[00:15:54.820 --> 00:15:57.140]   there was an immediate apology of like, hey, listen,
[00:15:57.140 --> 00:16:00.260]   I came out, normally I'm like, not like that, but online,
[00:16:00.260 --> 00:16:01.100]   you know, you get a different-
[00:16:01.100 --> 00:16:02.260]   - Oh yeah, okay, listen.
[00:16:02.260 --> 00:16:04.460]   - So it's a little bit like jujitsu, right?
[00:16:04.460 --> 00:16:05.860]   People say all sorts of things, I guess,
[00:16:05.860 --> 00:16:08.900]   but if you're like, all right, well, let's go,
[00:16:08.900 --> 00:16:10.700]   then it's probably a different story, you know?
[00:16:10.700 --> 00:16:12.420]   - It's not like jujitsu 'cause in jujitsu,
[00:16:12.420 --> 00:16:14.020]   people don't talk shit 'cause they know
[00:16:14.020 --> 00:16:15.420]   what the consequences are.
[00:16:15.420 --> 00:16:17.460]   Let me just say, on mic and off mic,
[00:16:17.460 --> 00:16:20.140]   you have been very respectful towards this person.
[00:16:20.140 --> 00:16:23.580]   And I look up to you and respect you
[00:16:23.580 --> 00:16:25.660]   and admire the fact that you have been.
[00:16:25.660 --> 00:16:28.580]   That said, to me, that guy was being a dick.
[00:16:28.580 --> 00:16:31.020]   And when you graciously, politely,
[00:16:31.020 --> 00:16:32.260]   invited him on the podcast,
[00:16:32.260 --> 00:16:34.820]   he was still talking down to you the whole time.
[00:16:34.820 --> 00:16:36.500]   So I really admire and look forward
[00:16:36.500 --> 00:16:38.380]   to listening to you talk to him,
[00:16:38.380 --> 00:16:41.740]   but I hope others don't do that.
[00:16:41.740 --> 00:16:46.540]   Like, you are a positive, humble voice,
[00:16:46.540 --> 00:16:49.340]   exploring all the interesting aspects of science.
[00:16:49.340 --> 00:16:51.660]   Like, you want to learn.
[00:16:51.660 --> 00:16:55.740]   If you've got anything wrong, you wanna learn about it.
[00:16:55.740 --> 00:17:00.180]   The way he was being a dick, I was just hurt a little bit,
[00:17:00.180 --> 00:17:02.660]   not because of him, but 'cause there's some people
[00:17:02.660 --> 00:17:05.420]   I really, really admire, brilliant scientists,
[00:17:05.420 --> 00:17:10.340]   that are not their best selves on Twitter, on X.
[00:17:10.340 --> 00:17:11.180]   - Definitely.
[00:17:11.180 --> 00:17:13.340]   - I don't understand what happens to their brain.
[00:17:13.340 --> 00:17:14.700]   - Well, they regress.
[00:17:14.700 --> 00:17:18.420]   They regress, and they also are protected, you know?
[00:17:18.420 --> 00:17:22.220]   When you remove the, I mean, no scientific argument
[00:17:22.220 --> 00:17:24.700]   should ever come to physical blows, right?
[00:17:24.700 --> 00:17:26.900]   But when you remove the real-world thing
[00:17:26.900 --> 00:17:29.380]   of being right in front of somebody,
[00:17:29.380 --> 00:17:32.700]   people will throw all sorts of stones at a distance,
[00:17:32.700 --> 00:17:34.180]   you know, and over a wall,
[00:17:34.180 --> 00:17:36.580]   and they've got their wife or their husband
[00:17:36.580 --> 00:17:38.140]   or their boyfriend or their dog or their cat
[00:17:38.140 --> 00:17:39.840]   to go cuddle with them afterwards.
[00:17:39.840 --> 00:17:44.220]   But you get in a room, and it's like, you know,
[00:17:44.220 --> 00:17:49.060]   confrontational people in real life are pretty rare,
[00:17:49.060 --> 00:17:50.660]   but hopefully, if they do it,
[00:17:50.660 --> 00:17:52.540]   they're, like, willing to back it up
[00:17:52.540 --> 00:17:53.940]   with knowledge in this case, right?
[00:17:53.940 --> 00:17:55.380]   We're not talking about physical altercation.
[00:17:55.380 --> 00:17:58.360]   Yeah, he kept coming, and he kept putting on conditions.
[00:17:58.360 --> 00:17:59.340]   How do I know you want this?
[00:17:59.340 --> 00:18:00.720]   And I was like, well, you can record the conversation.
[00:18:00.720 --> 00:18:01.560]   How do I know you want that?
[00:18:01.560 --> 00:18:02.660]   Listen, we'll pay for you to come out.
[00:18:02.660 --> 00:18:03.500]   How do you know?
[00:18:03.500 --> 00:18:06.080]   And eventually, he just kind of relented,
[00:18:06.080 --> 00:18:09.980]   and to his credit, you know, he's agreed to come on.
[00:18:09.980 --> 00:18:11.340]   I mean, he still has to show up,
[00:18:11.340 --> 00:18:13.860]   but once he does, you know, we'll treat him right
[00:18:13.860 --> 00:18:15.100]   like we would any other guest.
[00:18:15.100 --> 00:18:16.500]   - Yeah, you treat people really well,
[00:18:16.500 --> 00:18:19.420]   and I just hope that people are a little bit nicer
[00:18:19.420 --> 00:18:20.260]   on the internet.
[00:18:20.260 --> 00:18:22.100]   - Yeah, well, you know, X is an interesting one
[00:18:22.100 --> 00:18:25.740]   because it thickens your skin, you know,
[00:18:25.740 --> 00:18:26.800]   just to go on there.
[00:18:26.800 --> 00:18:29.140]   I mean, you have to be ready to deal with--
[00:18:29.140 --> 00:18:30.900]   - Sure, but I can still criticize people
[00:18:30.900 --> 00:18:33.980]   for being douchebags because, like,
[00:18:33.980 --> 00:18:36.460]   that's still not good, inspiring behavior,
[00:18:36.460 --> 00:18:38.780]   like, especially for scientists,
[00:18:38.780 --> 00:18:43.360]   that should be sort of symbols of scientific thinking,
[00:18:43.360 --> 00:18:45.920]   which requires intellectual humility.
[00:18:45.920 --> 00:18:48.480]   Humility is a big part of that,
[00:18:48.480 --> 00:18:51.400]   and Twitter is a good place to illustrate that.
[00:18:51.400 --> 00:18:53.620]   - Yeah, years ago, I used to,
[00:18:53.620 --> 00:18:56.860]   I was a student in TA, then instructor,
[00:18:56.860 --> 00:18:59.700]   and then directed a Cold Spring Harbor course
[00:18:59.700 --> 00:19:00.740]   on visual neuroscience.
[00:19:00.740 --> 00:19:04.020]   These are summer courses that explore different topics,
[00:19:04.020 --> 00:19:08.180]   and at night, we would host what we hoped were battles
[00:19:08.180 --> 00:19:11.100]   in front of the students where you'd get two people on a,
[00:19:11.100 --> 00:19:13.140]   you know, would it be neural prosthetics
[00:19:13.140 --> 00:19:16.580]   or molecular tools that would first, you know,
[00:19:16.580 --> 00:19:18.460]   restore vision to the blind kind of arguments.
[00:19:18.460 --> 00:19:20.020]   You know, kind of like, it's kind of a silly argument
[00:19:20.020 --> 00:19:22.100]   'cause it's gonna be a combination of both, right?
[00:19:22.100 --> 00:19:25.020]   But you'd get these great arguments,
[00:19:25.020 --> 00:19:28.800]   but the arguments were always couched in data,
[00:19:28.800 --> 00:19:31.300]   and occasionally, you'd get somebody would go like,
[00:19:31.300 --> 00:19:32.300]   or would curse or something,
[00:19:32.300 --> 00:19:37.300]   but it was the rare, very well-placed, you know, insult.
[00:19:37.300 --> 00:19:40.180]   It wasn't, you know, coming out swinging.
[00:19:40.180 --> 00:19:41.420]   I think, ultimately, you know,
[00:19:41.420 --> 00:19:43.320]   Twitter's a record of people's behavior,
[00:19:43.320 --> 00:19:45.500]   the internet is a record of people's behavior,
[00:19:45.500 --> 00:19:47.800]   and here, I'm not talking about news reports
[00:19:47.800 --> 00:19:48.640]   about people's behavior.
[00:19:48.640 --> 00:19:51.860]   I'm talking about how people show up online
[00:19:51.860 --> 00:19:53.700]   is really important.
[00:19:53.700 --> 00:19:55.300]   You've always carried yourself
[00:19:55.300 --> 00:19:56.900]   with a ton of composure and respect,
[00:19:56.900 --> 00:19:58.700]   and, you know, you just,
[00:19:58.700 --> 00:20:00.820]   you would hope that people would grow from that example.
[00:20:00.820 --> 00:20:03.500]   Well, I'll tell you that the podcasters that I'm scouting,
[00:20:03.500 --> 00:20:07.020]   it's their energy, but it's also how they treat other people,
[00:20:07.020 --> 00:20:08.320]   how they respond to comments,
[00:20:08.320 --> 00:20:10.380]   and, you know, we're blessed
[00:20:10.380 --> 00:20:12.380]   to have pretty significant reach.
[00:20:12.380 --> 00:20:15.100]   When we put out a podcast like someone else's podcast,
[00:20:15.100 --> 00:20:16.180]   it goes far and wide.
[00:20:16.180 --> 00:20:19.560]   So, like a skateboard team, like a laboratory
[00:20:19.560 --> 00:20:22.240]   where you're selecting people to be in your lab,
[00:20:22.240 --> 00:20:24.920]   you want to pick people that you would enjoy working with
[00:20:24.920 --> 00:20:26.020]   and that are collegial.
[00:20:26.020 --> 00:20:31.320]   Etiquette is lacking nowadays,
[00:20:31.320 --> 00:20:33.760]   but you're in the suit and tie, you're bringing it back.
[00:20:33.760 --> 00:20:35.560]   - Bringing it back.
[00:20:35.560 --> 00:20:38.440]   You said that your conversation with James Hollis,
[00:20:38.440 --> 00:20:41.120]   a Jungian psychoanalyst, had a big impact on you.
[00:20:41.120 --> 00:20:42.560]   What do you mean?
[00:20:42.560 --> 00:20:46.920]   - James Hollis is a 84-year-old Jungian psychoanalyst
[00:20:46.920 --> 00:20:50.540]   who's written 17 books, including "Under Saturn's Shadow,"
[00:20:50.540 --> 00:20:52.040]   which is on the healing and trauma of men,
[00:20:52.040 --> 00:20:53.880]   the Eden Project, excuse me,
[00:20:53.880 --> 00:20:57.360]   which is about relationships and creating a life.
[00:20:57.360 --> 00:20:59.940]   I discovered James Hollis in an online lecture
[00:20:59.940 --> 00:21:01.560]   that was recorded, I think, in San Diego.
[00:21:01.560 --> 00:21:02.400]   It's on YouTube.
[00:21:02.400 --> 00:21:05.340]   The audio is terrible, called "Creating a Life."
[00:21:05.340 --> 00:21:09.140]   And this was somewhere in the 2011 to 2015 span,
[00:21:09.140 --> 00:21:11.180]   I can't remember, and I was on my way to Europe,
[00:21:11.180 --> 00:21:13.020]   and I called my girlfriend at the time.
[00:21:13.020 --> 00:21:14.800]   I was like, I just found the most incredible lecture
[00:21:14.800 --> 00:21:16.300]   I've ever heard.
[00:21:16.300 --> 00:21:20.500]   And he talks about the shadow.
[00:21:20.500 --> 00:21:24.780]   He talks about your developmental upbringing
[00:21:24.780 --> 00:21:29.060]   and how you either align with or go 180 degrees
[00:21:29.060 --> 00:21:33.320]   off your parents' tendencies and values in certain areas.
[00:21:33.320 --> 00:21:37.060]   He talked about the specific questions to ask of oneself
[00:21:37.060 --> 00:21:38.860]   at different stages of life, to live a full life.
[00:21:38.860 --> 00:21:41.060]   So it's always been a dream of mine to meet him
[00:21:41.060 --> 00:21:42.980]   and to record a podcast.
[00:21:42.980 --> 00:21:45.200]   And he wasn't able to travel,
[00:21:45.200 --> 00:21:47.900]   so our team went out to D.C. and sat down with him.
[00:21:47.900 --> 00:21:49.260]   We rarely do that nowadays.
[00:21:49.260 --> 00:21:51.000]   People come to our studio.
[00:21:51.000 --> 00:21:54.460]   And he came in, he had some surgeries recently,
[00:21:54.460 --> 00:21:58.660]   and he kinda came in with some assistance from a cane
[00:21:58.660 --> 00:22:03.460]   and then sat down and just blew my mind.
[00:22:03.460 --> 00:22:07.180]   From start to finish, he didn't miss a syllable.
[00:22:07.180 --> 00:22:12.180]   And every sentence that he spoke was a quotable sentence
[00:22:12.180 --> 00:22:16.460]   with real potency and actionable items.
[00:22:16.460 --> 00:22:20.300]   I think one of the things that was most striking to me
[00:22:20.300 --> 00:22:23.660]   was how he said when we take ourselves out of stimulus
[00:22:23.660 --> 00:22:27.220]   and response and we just force ourselves
[00:22:27.220 --> 00:22:31.060]   to spend some time in the quiet of our thoughts
[00:22:31.060 --> 00:22:34.340]   while walking or while seated or while lying down.
[00:22:34.340 --> 00:22:37.100]   Doesn't have to be meditation, but it could be.
[00:22:37.100 --> 00:22:40.340]   That we access our unconscious mind
[00:22:40.340 --> 00:22:42.940]   in ways that reveals to us who we really are
[00:22:42.940 --> 00:22:43.940]   and what we really want.
[00:22:43.940 --> 00:22:46.220]   And that if we do that practice repeatedly,
[00:22:46.220 --> 00:22:49.180]   10 minutes a day here, 15 minutes a day there,
[00:22:49.180 --> 00:22:53.460]   that we start to really touch into our unique gifts
[00:22:53.460 --> 00:22:56.040]   and the things that make us each us
[00:22:56.040 --> 00:22:58.340]   and the directions we need to take.
[00:22:58.340 --> 00:23:01.400]   But that so often we just stay in stimulus response.
[00:23:01.400 --> 00:23:03.920]   We just do, do, do, do, do, which is great.
[00:23:03.920 --> 00:23:05.220]   We have to be productive.
[00:23:06.060 --> 00:23:09.740]   But we miss those important messages.
[00:23:09.740 --> 00:23:14.180]   And interestingly, he also put forward this idea
[00:23:14.180 --> 00:23:16.580]   of what is this, like get up, shut up, suit up?
[00:23:16.580 --> 00:23:17.660]   Yeah, something like that.
[00:23:17.660 --> 00:23:21.460]   Like get out of bed, suit up and shut up and get to work.
[00:23:21.460 --> 00:23:25.340]   He also has that in him, kind of a Goggins type mindset.
[00:23:25.340 --> 00:23:28.140]   - So be able to turn off all this self-reflection
[00:23:28.140 --> 00:23:29.980]   and self-analysis and just get shit done.
[00:23:29.980 --> 00:23:32.900]   - Get shit done, but then also take dedicated time
[00:23:32.900 --> 00:23:35.600]   and stop and just let stuff geyser to the surface
[00:23:35.600 --> 00:23:37.020]   from the unconscious mind.
[00:23:37.020 --> 00:23:39.100]   And he quotes Shakespeare and he quotes Jung
[00:23:39.100 --> 00:23:41.980]   and he quotes everybody through history
[00:23:41.980 --> 00:23:43.820]   with incredible accuracy
[00:23:43.820 --> 00:23:48.820]   and in exactly the way needed to drive home a point.
[00:23:48.820 --> 00:23:51.660]   But that conversation to me was one
[00:23:51.660 --> 00:23:54.060]   that I really felt like, okay,
[00:23:54.060 --> 00:23:57.180]   if I don't wake up tomorrow for whatever reason,
[00:23:57.180 --> 00:24:00.260]   that one's in the can and I feel really great about it.
[00:24:00.260 --> 00:24:03.740]   To me, it's the most important guest recording
[00:24:03.740 --> 00:24:04.600]   we've ever done.
[00:24:04.820 --> 00:24:09.820]   In particular, because he has wisdom.
[00:24:09.820 --> 00:24:13.540]   And while I hope he lives to be 204,
[00:24:13.540 --> 00:24:19.260]   chances are he's got another, what, 20, 30 years with us,
[00:24:19.260 --> 00:24:21.100]   hopefully more.
[00:24:21.100 --> 00:24:24.900]   But I really, really wanted to capture that information
[00:24:24.900 --> 00:24:25.720]   and get it out there.
[00:24:25.720 --> 00:24:27.520]   So I'm very, very proud of that one.
[00:24:27.520 --> 00:24:31.260]   And he's the kind of guy that anyone listens to him,
[00:24:31.260 --> 00:24:33.240]   young, old, male, female, whatever,
[00:24:33.240 --> 00:24:35.060]   and you're gonna get something of value.
[00:24:35.060 --> 00:24:39.180]   - What do you think about this idea of the shadow?
[00:24:39.180 --> 00:24:44.060]   That the good and the bad that we repress,
[00:24:44.060 --> 00:24:45.620]   that hides from plain sight
[00:24:45.620 --> 00:24:47.980]   when we analyze ourselves that's there.
[00:24:47.980 --> 00:24:49.660]   You think there's like a ocean
[00:24:49.660 --> 00:24:52.340]   that we don't have direct access to?
[00:24:52.340 --> 00:24:53.620]   - Yes.
[00:24:53.620 --> 00:24:54.900]   Yeah, Jung said it.
[00:24:54.900 --> 00:24:56.820]   We have all things inside of us and we do.
[00:24:56.820 --> 00:24:59.460]   And some people are more in touch with those than others
[00:24:59.460 --> 00:25:01.500]   and some people it's repressed.
[00:25:01.500 --> 00:25:04.080]   I mean, does that mean that we could all be,
[00:25:04.080 --> 00:25:07.880]   you know, horrible people or marvelous people,
[00:25:07.880 --> 00:25:09.080]   benevolent people?
[00:25:09.080 --> 00:25:09.920]   Perhaps.
[00:25:09.920 --> 00:25:14.440]   I think that thankfully more often than not,
[00:25:14.440 --> 00:25:16.920]   people lean away from the like violent
[00:25:16.920 --> 00:25:19.520]   and harmful parts of their shadow.
[00:25:19.520 --> 00:25:24.240]   But I think spending time thinking about,
[00:25:24.240 --> 00:25:28.040]   you know, one's shadow,
[00:25:28.040 --> 00:25:30.120]   shadows is super important.
[00:25:30.120 --> 00:25:32.500]   How else are we going to grow?
[00:25:32.500 --> 00:25:33.780]   Otherwise, you know,
[00:25:33.780 --> 00:25:36.500]   we have these unconscious blind spots of denial
[00:25:36.500 --> 00:25:39.900]   or repression or whatever, you know,
[00:25:39.900 --> 00:25:41.780]   the psychiatrists tell us.
[00:25:41.780 --> 00:25:43.580]   But it clearly exists within all of us.
[00:25:43.580 --> 00:25:45.540]   I mean, we have neural circuits for rage.
[00:25:45.540 --> 00:25:46.360]   We all do.
[00:25:46.360 --> 00:25:49.780]   We have neural circuits for altruism.
[00:25:49.780 --> 00:25:52.420]   And no one's born without these things.
[00:25:52.420 --> 00:25:53.620]   And some people they're atrophied
[00:25:53.620 --> 00:25:55.140]   and some people they're hypertrophied.
[00:25:55.140 --> 00:25:59.340]   But looking inward and recognizing what's there
[00:25:59.340 --> 00:26:01.320]   is key.
[00:26:01.320 --> 00:26:03.160]   - Or positive things like creativity.
[00:26:03.160 --> 00:26:04.980]   Maybe that's what Rick Rubin is accessing
[00:26:04.980 --> 00:26:06.520]   when he goes silent.
[00:26:06.520 --> 00:26:08.340]   Silent body, active mind.
[00:26:08.340 --> 00:26:10.080]   That's interesting.
[00:26:10.080 --> 00:26:11.940]   What is it for you?
[00:26:11.940 --> 00:26:15.680]   What place do you go to that generates ideas,
[00:26:15.680 --> 00:26:17.060]   that helps you generate ideas?
[00:26:17.060 --> 00:26:19.480]   - I have a lot of new practices around this.
[00:26:19.480 --> 00:26:21.960]   I mean, I'm always exploring for protocols.
[00:26:21.960 --> 00:26:23.080]   I have to.
[00:26:23.080 --> 00:26:24.360]   That's like in my nature.
[00:26:24.360 --> 00:26:27.520]   When I went and spent time with Rick,
[00:26:27.520 --> 00:26:30.560]   I tried to adopt his practice of staying very still
[00:26:30.560 --> 00:26:32.700]   and just letting stuff come to the surface
[00:26:32.700 --> 00:26:37.700]   or the Dicerothian way of formulating complete sentences
[00:26:37.700 --> 00:26:39.980]   while being still in the body.
[00:26:39.980 --> 00:26:42.420]   What I have found works better
[00:26:42.420 --> 00:26:46.820]   is what my good friend Tim Armstrong does to write music.
[00:26:46.820 --> 00:26:48.160]   He writes music every day.
[00:26:48.160 --> 00:26:49.140]   He's a music producer.
[00:26:49.140 --> 00:26:51.580]   He's obviously a singer, guitar player for Rancid.
[00:26:51.580 --> 00:26:55.420]   And he's helped dozens and dozens and dozens
[00:26:55.420 --> 00:26:58.920]   of female pop artists and punk rock artists
[00:26:58.920 --> 00:27:01.000]   write great songs.
[00:27:01.000 --> 00:27:04.520]   And many of the famous songs that you've heard
[00:27:04.520 --> 00:27:07.040]   from other artists, Tim helped them write.
[00:27:07.040 --> 00:27:11.140]   Tim wakes up sometimes in the middle of the night,
[00:27:11.140 --> 00:27:14.240]   and what he does is he'll start drawing or painting.
[00:27:14.240 --> 00:27:17.640]   So what he's done, and Joni Mitchell talks about this too,
[00:27:17.640 --> 00:27:19.200]   you find some creative outlet
[00:27:19.200 --> 00:27:23.180]   that's like 15 degrees off center
[00:27:23.180 --> 00:27:27.280]   from your main creative outlet, and you do that thing.
[00:27:27.280 --> 00:27:28.380]   So for me, that's drawing.
[00:27:28.380 --> 00:27:30.600]   I like doing anatomical drawings,
[00:27:30.600 --> 00:27:32.360]   neuroscience-based drawing, drawing neurons,
[00:27:32.360 --> 00:27:33.480]   that kind of thing.
[00:27:33.480 --> 00:27:35.740]   And if I do that for a little while,
[00:27:35.740 --> 00:27:40.080]   my mind starts churning on the nervous system and biology,
[00:27:40.080 --> 00:27:43.080]   and then I come up with areas
[00:27:43.080 --> 00:27:45.080]   I'd like to explore for the podcast,
[00:27:45.080 --> 00:27:47.680]   ways I'd like to address certain topics.
[00:27:47.680 --> 00:27:49.600]   Right now, I'm very interested in autonomic control.
[00:27:49.600 --> 00:27:50.800]   A beautiful paper came out
[00:27:50.820 --> 00:27:51.980]   that shows that anyone can learn
[00:27:51.980 --> 00:27:55.940]   to control their pupil sizes without changing luminance
[00:27:55.940 --> 00:27:57.540]   through a biofeedback mechanism,
[00:27:57.540 --> 00:28:00.660]   and that gives them control
[00:28:00.660 --> 00:28:03.820]   over their so-called automatic autonomic nervous system.
[00:28:03.820 --> 00:28:05.620]   And I've been looking at what the circuitry is,
[00:28:05.620 --> 00:28:09.320]   and it's beautiful, so I'll draw the circuitry
[00:28:09.320 --> 00:28:11.340]   that we know underlies autonomic function.
[00:28:11.340 --> 00:28:12.420]   And as I'm doing that, I'm thinking,
[00:28:12.420 --> 00:28:14.020]   oh, what about autonomic control
[00:28:14.020 --> 00:28:15.220]   and those people that supposedly
[00:28:15.220 --> 00:28:16.340]   can control their pupil size?
[00:28:16.340 --> 00:28:17.340]   Then you go in, and there's a paper
[00:28:17.340 --> 00:28:19.860]   published in Nature Press, one of the nature journals,
[00:28:19.860 --> 00:28:21.060]   and there's a recent paper on this.
[00:28:21.060 --> 00:28:22.600]   Like, oh, cool, and then we talk about this,
[00:28:22.600 --> 00:28:25.740]   and then how could this be put into a kind of a post,
[00:28:25.740 --> 00:28:27.040]   or how could this, you know,
[00:28:27.040 --> 00:28:29.460]   so doing things that are about 15 degrees off-center
[00:28:29.460 --> 00:28:31.680]   from your main thing is a great way to access,
[00:28:31.680 --> 00:28:34.200]   I believe, the circuits for, in Tim's case,
[00:28:34.200 --> 00:28:35.840]   painting goes to songwriting.
[00:28:35.840 --> 00:28:40.620]   I think for Joni Mitchell, that was also the case, right?
[00:28:40.620 --> 00:28:42.040]   I think it was drawing and painting
[00:28:42.040 --> 00:28:44.000]   to singing and songwriting.
[00:28:44.000 --> 00:28:45.080]   For Rick, I don't know what it is.
[00:28:45.080 --> 00:28:47.320]   Maybe it's listening to podcasts.
[00:28:47.320 --> 00:28:49.120]   I don't know, that's his business.
[00:28:49.120 --> 00:28:52.020]   Do you have anything that you like to focus on
[00:28:52.020 --> 00:28:54.420]   that allows you then an easier transition
[00:28:54.420 --> 00:28:56.020]   into your main creative work?
[00:28:56.020 --> 00:28:59.440]   - No, I really like to focus on emptiness and silence,
[00:28:59.440 --> 00:29:02.500]   so I pick the dragon I have to slay,
[00:29:02.500 --> 00:29:05.160]   so whatever the problem I have to work on,
[00:29:05.160 --> 00:29:08.760]   and I just sit there and stare at it.
[00:29:08.760 --> 00:29:10.680]   I love how fucking linear you are.
[00:29:10.680 --> 00:29:15.500]   And if there's no, if you're tired, I'll just sit.
[00:29:15.500 --> 00:29:18.540]   I believe in the power of just waiting,
[00:29:18.540 --> 00:29:22.000]   and usually I'll stop being tired,
[00:29:22.000 --> 00:29:24.520]   or energy rises from somewhere,
[00:29:24.520 --> 00:29:25.880]   or an idea pops from somewhere,
[00:29:25.880 --> 00:29:28.420]   but there needs to be a silence and an emptiness.
[00:29:28.420 --> 00:29:30.320]   It's an empty room, just me and the dragon,
[00:29:30.320 --> 00:29:32.920]   and we wait, that's it.
[00:29:32.920 --> 00:29:34.520]   Like if it's, usually with programming,
[00:29:34.520 --> 00:29:36.040]   you're thinking about a particular design,
[00:29:36.040 --> 00:29:41.040]   like how do I design this thing to solve this problem?
[00:29:41.040 --> 00:29:42.600]   - Any cognitive enhancers?
[00:29:42.600 --> 00:29:44.440]   I've got quite the gallery in front of me.
[00:29:44.440 --> 00:29:45.560]   - Oh, that's right, yeah.
[00:29:45.560 --> 00:29:46.600]   - Should we walk through this?
[00:29:47.120 --> 00:29:49.200]   This is not a sales thing, it's just,
[00:29:49.200 --> 00:29:52.400]   I tend to do this, bounce back and forth.
[00:29:52.400 --> 00:29:53.740]   Your refrigerator just happened
[00:29:53.740 --> 00:29:55.880]   to have a lot of different choices, so water.
[00:29:55.880 --> 00:29:57.360]   - This is all of my refrigerator.
[00:29:57.360 --> 00:29:58.200]   - I know, right?
[00:29:58.200 --> 00:29:59.120]   There's no food in there.
[00:29:59.120 --> 00:30:03.640]   There's water, there's Element, which they now have canned.
[00:30:03.640 --> 00:30:05.480]   And yes, they're a podcast sponsor for both of us,
[00:30:05.480 --> 00:30:06.840]   but that's not why I cracked one of these open.
[00:30:06.840 --> 00:30:08.560]   I like them, provided they're cold.
[00:30:08.560 --> 00:30:09.400]   - And that's, by the way,
[00:30:09.400 --> 00:30:11.520]   my least favorite flavor, as I was saying.
[00:30:11.520 --> 00:30:13.700]   That's the reason it's still left in the fridge.
[00:30:13.700 --> 00:30:15.360]   - The cherry one is really good.
[00:30:15.360 --> 00:30:18.420]   - The black cherry, there's an orange one.
[00:30:18.420 --> 00:30:20.560]   - I pushed the sled this morning
[00:30:20.560 --> 00:30:22.600]   and pulled the sled from my workout at the gym,
[00:30:22.600 --> 00:30:26.840]   and it was hot today here in Austin, so some salt is good.
[00:30:26.840 --> 00:30:29.680]   And then, Matina Yerba Mate, zero sugar.
[00:30:29.680 --> 00:30:31.480]   Full confession, I helped develop this.
[00:30:31.480 --> 00:30:33.680]   I'm a partial owner, but I love Yerba Mate.
[00:30:33.680 --> 00:30:36.660]   Half-Argentine, been drinking mate since I was a little kid.
[00:30:36.660 --> 00:30:38.200]   There's actually a photo somewhere on the internet
[00:30:38.200 --> 00:30:40.680]   when I'm like three, sitting on my grandfather's lap,
[00:30:40.680 --> 00:30:42.480]   sipping mate out the gourd.
[00:30:42.480 --> 00:30:44.120]   And then this, you might find interesting.
[00:30:44.120 --> 00:30:46.160]   This is just a little bit of coffee
[00:30:46.160 --> 00:30:50.960]   with a scoop of, Brian Johnson gave me cocoa,
[00:30:50.960 --> 00:30:52.800]   just like pure unsweetened cocoa.
[00:30:52.800 --> 00:30:54.560]   So I put that in chocolate, and I like it.
[00:30:54.560 --> 00:30:55.440]   - Just for the taste.
[00:30:55.440 --> 00:30:56.960]   - Well, it actually nukes my appetite,
[00:30:56.960 --> 00:30:59.340]   and since we're not going out to dinner tonight until later,
[00:30:59.340 --> 00:31:01.360]   I figure that's good.
[00:31:01.360 --> 00:31:02.640]   Yeah, Brian's an interesting one, right?
[00:31:02.640 --> 00:31:04.360]   He's really pushing this thing.
[00:31:04.360 --> 00:31:06.000]   - The optimization of everything.
[00:31:06.000 --> 00:31:07.400]   - Although he just hurt his ankle.
[00:31:07.400 --> 00:31:08.740]   He posted a photo that he hurt his ankle,
[00:31:08.740 --> 00:31:12.240]   so now he's injecting BPC, Body Protection Compound 157,
[00:31:12.240 --> 00:31:14.200]   which many, many people are taking, by the way.
[00:31:14.200 --> 00:31:16.480]   I did an episode on peptides.
[00:31:16.480 --> 00:31:18.720]   I should just say, you know, BPC 157,
[00:31:18.720 --> 00:31:21.240]   one of the known effects in animal models
[00:31:21.240 --> 00:31:24.960]   is angiogenesis, like development of new vasculature,
[00:31:24.960 --> 00:31:27.720]   which can be great in some context,
[00:31:27.720 --> 00:31:28.960]   but also if you have a tumor,
[00:31:28.960 --> 00:31:31.560]   you don't really wanna vascularize that tumor anymore.
[00:31:31.560 --> 00:31:34.520]   So I worry about people taking BPC 157 continually,
[00:31:34.520 --> 00:31:39.200]   and there's very little human data.
[00:31:39.200 --> 00:31:41.440]   I think there's like one study, and it's a lousy one.
[00:31:41.440 --> 00:31:43.200]   It's a lot of animal data.
[00:31:43.200 --> 00:31:46.280]   Some of the peptides are interesting, however.
[00:31:46.280 --> 00:31:48.160]   There's one that I've experimented with a little bit
[00:31:48.160 --> 00:31:51.640]   called pinelan, which I find,
[00:31:51.640 --> 00:31:54.640]   even if I've just taken it twice a week before sleep,
[00:31:54.640 --> 00:31:56.960]   then it seems to do something
[00:31:56.960 --> 00:31:59.800]   to the circadian timekeeping mechanism,
[00:31:59.800 --> 00:32:02.640]   because then on other days, when I don't take it,
[00:32:02.640 --> 00:32:05.320]   I get unbelievably tired at that time
[00:32:05.320 --> 00:32:07.160]   that normally I would do the injection.
[00:32:07.160 --> 00:32:08.320]   These are things that I'll experiment with
[00:32:08.320 --> 00:32:10.160]   for a couple weeks and then typically stop,
[00:32:10.160 --> 00:32:11.240]   maybe try something else,
[00:32:11.240 --> 00:32:14.960]   but I stay out of things that really stimulate
[00:32:14.960 --> 00:32:18.720]   any of the major hormone pathways when it comes to peptides.
[00:32:18.720 --> 00:32:19.920]   - That's actually a really good question
[00:32:19.920 --> 00:32:22.000]   of how do you experiment?
[00:32:22.000 --> 00:32:23.240]   Like, how long do you try a thing
[00:32:23.240 --> 00:32:24.840]   to figure out if it works for you?
[00:32:24.840 --> 00:32:27.040]   - Well, I'm very sensitive to these things,
[00:32:27.040 --> 00:32:29.360]   and I have been doing a lot of things for a long time,
[00:32:29.360 --> 00:32:31.760]   so if I add something in, it's always one thing at a time,
[00:32:31.760 --> 00:32:34.720]   and I notice right away if it does not make me feel good.
[00:32:34.720 --> 00:32:35.840]   Like, there's a lot of excitement
[00:32:35.840 --> 00:32:39.680]   about some of the so-called growth hormone secretagogues,
[00:32:39.680 --> 00:32:42.800]   iopramerolin, testomerolin, seromerolin.
[00:32:42.800 --> 00:32:44.960]   I've experimented a little bit with those in the past,
[00:32:44.960 --> 00:32:48.240]   and they've nuked my rapid eye movement sleep,
[00:32:48.240 --> 00:32:49.400]   but given me a lot of deep sleep,
[00:32:49.400 --> 00:32:52.920]   which doesn't feel good to me, but other people like them.
[00:32:52.920 --> 00:32:57.920]   I also just generally try and avoid taking peptides
[00:32:57.920 --> 00:32:59.520]   that tap into these hormone pathways,
[00:32:59.520 --> 00:33:01.160]   because you can run into all sorts of issues,
[00:33:01.160 --> 00:33:02.860]   but some people take them safely.
[00:33:02.860 --> 00:33:04.600]   But usually after about four or five days,
[00:33:04.600 --> 00:33:07.420]   I know if I like something or I don't, and then I move on.
[00:33:07.420 --> 00:33:10.300]   But I am not super adventurous with these things.
[00:33:10.300 --> 00:33:12.380]   I know people that will take cocktails of peptides
[00:33:12.380 --> 00:33:15.040]   with multiple things, they'll try anything.
[00:33:15.040 --> 00:33:17.340]   That's not me, and I do blood work.
[00:33:17.340 --> 00:33:23.240]   But also, I'm mainly reading papers and podcasting,
[00:33:23.240 --> 00:33:27.500]   and I'm teaching a course next spring at Stanford.
[00:33:27.500 --> 00:33:29.860]   I'm gonna do a big undergraduate course,
[00:33:29.860 --> 00:33:33.020]   so I'm trying to develop that course and things like that.
[00:33:33.020 --> 00:33:36.620]   So I don't need to lift more weight
[00:33:36.620 --> 00:33:38.460]   or run further than I already do,
[00:33:38.460 --> 00:33:40.780]   which is not that much weight or far as it is.
[00:33:40.780 --> 00:33:42.100]   - All right, you're not going to the Olympics.
[00:33:42.100 --> 00:33:44.220]   You're not trying to truly maximize
[00:33:44.220 --> 00:33:45.420]   some aspect of your performance.
[00:33:45.420 --> 00:33:48.900]   - No, and I'm not trying to get down below whatever,
[00:33:48.900 --> 00:33:50.260]   7% body fat or something.
[00:33:50.260 --> 00:33:52.420]   I don't have those kinds of goals.
[00:33:52.420 --> 00:33:55.940]   So hydration, electrolytes, caffeine in the form of mate,
[00:33:55.940 --> 00:33:57.260]   and then this coffee thing.
[00:33:57.260 --> 00:33:59.660]   And then here's one that I think I brought out
[00:33:59.660 --> 00:34:01.920]   for discussion, this is a piece of Nicorette.
[00:34:01.920 --> 00:34:03.020]   They're not a sponsor.
[00:34:04.380 --> 00:34:06.860]   Nicotine is an interesting compound.
[00:34:06.860 --> 00:34:08.820]   It will raise blood pressure,
[00:34:08.820 --> 00:34:12.620]   and it is probably not safe for everybody.
[00:34:12.620 --> 00:34:16.020]   But nicotine is gaining in popularity like crazy,
[00:34:16.020 --> 00:34:19.060]   mainly these pouches that people put in the lip.
[00:34:19.060 --> 00:34:21.300]   We're not talking about smoking,
[00:34:21.300 --> 00:34:23.420]   vaping, dipping, or snuffing.
[00:34:23.420 --> 00:34:26.320]   You know, my interest in nicotine started,
[00:34:26.320 --> 00:34:29.920]   this was in 2010, I was visiting Columbia Medical School,
[00:34:29.920 --> 00:34:33.220]   and I was in the office of the great neurobiologist,
[00:34:33.220 --> 00:34:35.660]   Richard Axel, won the Nobel Prize,
[00:34:35.660 --> 00:34:36.940]   co-recipient with Linda Buck
[00:34:36.940 --> 00:34:40.980]   for the discovery of the molecular basis of olfaction.
[00:34:40.980 --> 00:34:41.820]   Brilliant guy.
[00:34:41.820 --> 00:34:45.200]   He's probably in his late 70s now, probably, yeah.
[00:34:45.200 --> 00:34:48.100]   And he kept popping Nicorette in his mouth.
[00:34:48.100 --> 00:34:49.060]   And I was like, "What's this about?"
[00:34:49.060 --> 00:34:51.380]   And he said, "Oh, well, this was just anecdote, right?"
[00:34:51.380 --> 00:34:52.900]   But he said this.
[00:34:52.900 --> 00:34:53.740]   He said, "Oh, well, you know,
[00:34:53.740 --> 00:34:55.860]   "it protects against Parkinson's and Alzheimer's."
[00:34:55.860 --> 00:34:56.680]   I said, "It does?"
[00:34:56.680 --> 00:34:57.520]   And he goes, "Yeah, yeah, yeah."
[00:34:57.520 --> 00:34:58.560]   I don't know if he was kidding or not.
[00:34:58.560 --> 00:34:59.700]   He's known for making jokes.
[00:34:59.700 --> 00:35:02.340]   And then he said that when he used to smoke,
[00:35:02.340 --> 00:35:04.040]   it really helped his focus and creativity,
[00:35:04.040 --> 00:35:06.260]   but then he quit smoking 'cause he didn't want lung cancer.
[00:35:06.260 --> 00:35:07.760]   And he found that he couldn't focus as well,
[00:35:07.760 --> 00:35:09.340]   so he would choose Nicorette.
[00:35:09.340 --> 00:35:12.020]   So occasionally, like right now,
[00:35:12.020 --> 00:35:15.220]   I do a half a piece, but I'm not Russian.
[00:35:15.220 --> 00:35:16.780]   So I'm a little, you know.
[00:35:16.780 --> 00:35:18.880]   You have to just pop the whole thing in your mouth.
[00:35:18.880 --> 00:35:22.300]   So I'll do a couple milligrams every now and again.
[00:35:22.300 --> 00:35:24.000]   And it definitely sharpens the mind,
[00:35:24.000 --> 00:35:26.380]   on an empty stomach in particular, but you fast all day.
[00:35:26.380 --> 00:35:27.540]   You're still doing one meal a day.
[00:35:27.540 --> 00:35:28.380]   - One meal a day.
[00:35:28.380 --> 00:35:29.220]   - Yeah.
[00:35:29.220 --> 00:35:32.220]   - Yeah, I did a nicotine pouch with Rogan at dinner.
[00:35:32.220 --> 00:35:33.580]   And that got high.
[00:35:33.580 --> 00:35:35.320]   - Yeah, that's a lot.
[00:35:35.320 --> 00:35:37.800]   That's like usually six or eight milligrams.
[00:35:37.800 --> 00:35:42.220]   I know people that get a canister of Zyn, take one a day.
[00:35:42.220 --> 00:35:44.340]   Pretty soon, they're taking a canister a day.
[00:35:44.340 --> 00:35:45.460]   So you have to be very careful.
[00:35:45.460 --> 00:35:48.220]   I will only allow myself two pieces
[00:35:48.220 --> 00:35:51.380]   of Nicorette total per week.
[00:35:51.380 --> 00:35:53.620]   And you will notice that, you know,
[00:35:53.620 --> 00:35:55.620]   in the day after you use it, you know,
[00:35:55.620 --> 00:35:57.860]   sometimes your throat will feel a little bit like,
[00:35:57.860 --> 00:35:58.760]   like a little spasmy,
[00:35:58.760 --> 00:36:00.900]   like you might want to cough once or twice.
[00:36:00.900 --> 00:36:04.060]   And so, you know, if you're a singer or you're a podcaster
[00:36:04.060 --> 00:36:05.860]   or something, you have to do long podcasts,
[00:36:05.860 --> 00:36:06.820]   you want to just be mindful of it.
[00:36:06.820 --> 00:36:08.060]   But yeah, you're supposed to kind of like
[00:36:08.060 --> 00:36:10.340]   keep it in your cheek and, you know, here we go.
[00:36:10.340 --> 00:36:14.140]   - But it did make me intensely focused.
[00:36:14.140 --> 00:36:16.740]   In a way, that was a little bit scary 'cause--
[00:36:16.740 --> 00:36:19.900]   - The nucleus basalis is in the, you know,
[00:36:19.900 --> 00:36:23.500]   in basal forebrain, nucleus has cholinergic neurons
[00:36:23.500 --> 00:36:27.180]   that radiate out axons, little wires
[00:36:27.180 --> 00:36:30.820]   that release acetylcholine into the neocortex and elsewhere.
[00:36:30.820 --> 00:36:34.220]   And when you focus on one particular topic matter
[00:36:34.220 --> 00:36:36.780]   or one particular area of your visual field
[00:36:36.780 --> 00:36:39.500]   or listening to something and focusing visually,
[00:36:39.500 --> 00:36:41.580]   we know that there's an elaboration
[00:36:41.580 --> 00:36:43.620]   of the amount of acetylcholine released there
[00:36:43.620 --> 00:36:46.940]   and it binds to nicotinic acetylcholine receptor sites there.
[00:36:46.940 --> 00:36:50.100]   So it's a kind of an attentional modulation
[00:36:50.100 --> 00:36:51.660]   by acetylcholine.
[00:36:51.660 --> 00:36:53.260]   So you're getting with nicotine,
[00:36:53.260 --> 00:36:55.260]   you're getting a exogenous
[00:36:55.260 --> 00:36:58.500]   or artificial heightening of that circuitry.
[00:36:58.500 --> 00:37:00.980]   - And the time I had Tucker Carlson on the podcast,
[00:37:00.980 --> 00:37:03.620]   he told me that apparently it helps him,
[00:37:03.620 --> 00:37:08.620]   as he said publicly, keep his love life vibrant.
[00:37:08.620 --> 00:37:11.060]   - Really?
[00:37:11.060 --> 00:37:12.220]   It causes visual constrictions?
[00:37:12.220 --> 00:37:14.580]   - Well, he literally said it makes his dick very hard.
[00:37:14.580 --> 00:37:16.060]   He said that publicly also.
[00:37:16.060 --> 00:37:17.820]   - Okay, well, as little as I wanna think
[00:37:17.820 --> 00:37:22.460]   about Tucker Carlson's sex life, no disrespect.
[00:37:23.840 --> 00:37:28.480]   The major effect of nicotine on the vasculature,
[00:37:28.480 --> 00:37:31.120]   my understanding is that it causes vasoconstriction,
[00:37:31.120 --> 00:37:32.880]   not vasodilation.
[00:37:32.880 --> 00:37:36.720]   Drugs like Cialis, Tadalafil, Viagra, et cetera,
[00:37:36.720 --> 00:37:39.160]   vasodilators, they allow more blood flow.
[00:37:39.160 --> 00:37:44.040]   Nicotine does the opposite, less blood flow to the periphery,
[00:37:44.040 --> 00:37:46.400]   but provided dosages are kept low.
[00:37:46.400 --> 00:37:50.140]   And I don't recommend people use it frequently or at all.
[00:37:50.140 --> 00:37:52.240]   And I don't recommend young people use it,
[00:37:52.240 --> 00:37:56.240]   you know, 25 and younger.
[00:37:56.240 --> 00:37:58.080]   Brain's very plastic at that time.
[00:37:58.080 --> 00:38:02.760]   And certainly smoking, dipping, vaping, and snuffing
[00:38:02.760 --> 00:38:06.540]   aren't good because you're gonna run into trouble
[00:38:06.540 --> 00:38:07.840]   for other reasons.
[00:38:07.840 --> 00:38:10.280]   But in any case, oh, and even there,
[00:38:10.280 --> 00:38:12.000]   vaping's a controversial topic.
[00:38:12.000 --> 00:38:15.660]   Probably safer than smoking, but has its own issues.
[00:38:15.660 --> 00:38:17.520]   And I said something like that,
[00:38:17.520 --> 00:38:19.320]   and boy, did I catch a lot of heat for that.
[00:38:19.320 --> 00:38:21.440]   You can't say anything as a health science educator
[00:38:21.440 --> 00:38:23.360]   and not piss somebody off.
[00:38:23.360 --> 00:38:25.640]   It just depends on where the center of mass is
[00:38:25.640 --> 00:38:27.720]   and how far outside that you are.
[00:38:27.720 --> 00:38:30.280]   - For me, the caffeine is the main thing.
[00:38:30.280 --> 00:38:34.300]   And actually, it's a really big part of my life.
[00:38:34.300 --> 00:38:35.400]   And one of the things you recommend
[00:38:35.400 --> 00:38:38.880]   that people wait a bit in the morning to consume caffeine.
[00:38:38.880 --> 00:38:43.480]   - If they experience a crash in the afternoon,
[00:38:43.480 --> 00:38:48.480]   this is one of the misconceptions I regret,
[00:38:49.080 --> 00:38:50.880]   maybe even discussing it for people
[00:38:50.880 --> 00:38:52.280]   that crash in the afternoon.
[00:38:52.280 --> 00:38:55.960]   Oftentimes, if they delay their caffeine
[00:38:55.960 --> 00:38:57.840]   by 60 and 90 minutes in the morning,
[00:38:57.840 --> 00:38:59.520]   they will offset some of that.
[00:38:59.520 --> 00:39:01.000]   But if you eat a lunch that's too big
[00:39:01.000 --> 00:39:02.220]   or you didn't sleep well the night before,
[00:39:02.220 --> 00:39:04.840]   you're not gonna avoid that afternoon crash.
[00:39:04.840 --> 00:39:06.440]   But I'll wake up sometimes
[00:39:06.440 --> 00:39:08.040]   and go straight to hydration and caffeine,
[00:39:08.040 --> 00:39:09.120]   especially if I'm gonna work out.
[00:39:09.120 --> 00:39:10.080]   Here's a weird one.
[00:39:10.080 --> 00:39:16.040]   If I exercise before 8.30 a.m.,
[00:39:16.280 --> 00:39:17.760]   especially if I start exercising
[00:39:17.760 --> 00:39:19.200]   when I'm a little bit tired,
[00:39:19.200 --> 00:39:21.880]   I get energy that lasts all day.
[00:39:21.880 --> 00:39:24.160]   If I wait until my peak of energy,
[00:39:24.160 --> 00:39:26.480]   which is mid-morning, 10 a.m., 11 a.m.,
[00:39:26.480 --> 00:39:28.240]   and I start exercising then,
[00:39:28.240 --> 00:39:30.160]   I'm basically exhausted all afternoon.
[00:39:30.160 --> 00:39:31.360]   And I don't understand why.
[00:39:31.360 --> 00:39:33.880]   I mean, it depends on the intensity of the workout.
[00:39:33.880 --> 00:39:36.280]   So I like to be done, showered,
[00:39:36.280 --> 00:39:39.420]   and heading into work by 9 a.m.,
[00:39:39.420 --> 00:39:41.280]   but I don't always meet that mark.
[00:39:41.280 --> 00:39:43.080]   - So you're saying it doesn't affect your energy
[00:39:43.080 --> 00:39:45.320]   if you start with exercising.
[00:39:45.320 --> 00:39:46.720]   - I think you can get energy
[00:39:46.720 --> 00:39:49.600]   and wake yourself up with exercise if you start early,
[00:39:49.600 --> 00:39:52.240]   and then that fuels you all day long.
[00:39:52.240 --> 00:39:53.160]   I think that if you wait
[00:39:53.160 --> 00:39:56.480]   until you're feeling at your best to train,
[00:39:56.480 --> 00:39:57.740]   sometimes that's detrimental
[00:39:57.740 --> 00:39:59.960]   because then in the afternoon when you're doing
[00:39:59.960 --> 00:40:01.640]   the work we get paid for,
[00:40:01.640 --> 00:40:04.260]   like research, podcasting, et cetera,
[00:40:04.260 --> 00:40:08.160]   then oftentimes your brain isn't firing as well.
[00:40:08.160 --> 00:40:09.000]   - That's interesting.
[00:40:09.000 --> 00:40:10.720]   I haven't really rigorously tried that,
[00:40:10.720 --> 00:40:12.920]   wake up and just start running or lifting.
[00:40:12.920 --> 00:40:14.160]   - This is the Jocko thing.
[00:40:14.160 --> 00:40:17.080]   And then there's this phenomenon called entrainment
[00:40:17.080 --> 00:40:21.200]   where if you force yourself to exercise or eat
[00:40:21.200 --> 00:40:23.960]   or socialize or view bright light
[00:40:23.960 --> 00:40:26.680]   at a certain time of day for three to seven days in a row,
[00:40:26.680 --> 00:40:29.480]   pretty soon there's an anticipatory circuit
[00:40:29.480 --> 00:40:30.320]   that gets generated.
[00:40:30.320 --> 00:40:34.240]   This is why anyone in theory can become a morning person
[00:40:34.240 --> 00:40:35.680]   to some degree or another.
[00:40:35.680 --> 00:40:39.760]   And this is also a beautiful example
[00:40:39.760 --> 00:40:42.320]   of why you wake up before your alarm clock goes off.
[00:40:42.320 --> 00:40:43.920]   People wake up and all of a sudden it goes off.
[00:40:43.920 --> 00:40:45.040]   It wasn't 'cause it clicked,
[00:40:45.040 --> 00:40:47.960]   it's because you have this incredible timekeeping mechanism
[00:40:47.960 --> 00:40:49.720]   that exists in sleep.
[00:40:49.720 --> 00:40:51.000]   And there's some papers that have been published
[00:40:51.000 --> 00:40:52.480]   in the last couple of years,
[00:40:52.480 --> 00:40:54.160]   Nature Neuroscience and elsewhere showing
[00:40:54.160 --> 00:40:56.560]   that people can answer math problems in their sleep,
[00:40:56.560 --> 00:40:59.960]   simple math problems, but math problems nonetheless.
[00:40:59.960 --> 00:41:01.480]   (laughing)
[00:41:01.480 --> 00:41:03.560]   This does not mean that if you ask your partner a question
[00:41:03.560 --> 00:41:06.720]   in sleep that they're gonna answer accurately.
[00:41:06.720 --> 00:41:11.320]   - Like they might screw up the whole cumulative probability
[00:41:11.320 --> 00:41:13.420]   of 20% across multiple months.
[00:41:13.420 --> 00:41:14.700]   - All right, listen.
[00:41:14.700 --> 00:41:15.540]   - What happened?
[00:41:15.540 --> 00:41:16.380]   - What happened?
[00:41:16.380 --> 00:41:17.360]   Here's the deal.
[00:41:17.360 --> 00:41:19.640]   A few years back, I did a four and a half hour,
[00:41:19.640 --> 00:41:21.660]   after editing, four and a half hour episode
[00:41:21.660 --> 00:41:23.220]   on male and female fertility.
[00:41:23.220 --> 00:41:27.880]   The entire recording took 11 hours.
[00:41:27.880 --> 00:41:30.640]   And at one point during the,
[00:41:30.640 --> 00:41:33.040]   and by the way, I'm very proud of that episode.
[00:41:33.040 --> 00:41:36.680]   Many couples have written to me and said
[00:41:36.680 --> 00:41:39.040]   they now have children as a consequence of that episode.
[00:41:39.040 --> 00:41:40.000]   And my first question is,
[00:41:40.000 --> 00:41:41.960]   what were you doing during the episode?
[00:41:41.960 --> 00:41:43.860]   But in all seriousness--
[00:41:43.860 --> 00:41:47.320]   - We should say that it's four and a half hours.
[00:41:47.320 --> 00:41:51.460]   And for people, and they should listen to the episode,
[00:41:51.460 --> 00:41:53.340]   it's an extremely technical episode.
[00:41:53.340 --> 00:41:55.140]   Like you're nonstop dropping facts
[00:41:55.140 --> 00:41:58.360]   and referencing a huge number of papers.
[00:41:58.360 --> 00:41:59.500]   It must be exhausting.
[00:41:59.500 --> 00:42:00.340]   I don't understand how you can possibly--
[00:42:00.340 --> 00:42:02.740]   - It talks about sperm health, spermatogenesis.
[00:42:02.740 --> 00:42:04.980]   It talks about the ovulatory cycle.
[00:42:04.980 --> 00:42:06.380]   It talks about things people can do
[00:42:06.380 --> 00:42:09.860]   that are considered absolutely supported by science.
[00:42:09.860 --> 00:42:10.740]   It talks about some of the things
[00:42:10.740 --> 00:42:12.420]   kind of out on the edge a little bit
[00:42:12.420 --> 00:42:13.580]   that are a little bit more experimental.
[00:42:13.580 --> 00:42:14.420]   It talks about IVF.
[00:42:14.420 --> 00:42:15.240]   It talks about ICSI.
[00:42:15.240 --> 00:42:17.580]   It talks about all of that.
[00:42:17.580 --> 00:42:19.660]   It talks about frequency of pregnancy
[00:42:19.660 --> 00:42:22.360]   as a function of age, et cetera.
[00:42:22.360 --> 00:42:26.760]   But there's this one portion there in the podcast
[00:42:26.760 --> 00:42:29.500]   where I'm talking about the probability
[00:42:29.500 --> 00:42:32.740]   of a successful pregnancy as a function of age.
[00:42:32.740 --> 00:42:37.140]   And so there was a clip that was cut
[00:42:37.140 --> 00:42:40.860]   in which I was describing cumulative probability.
[00:42:40.860 --> 00:42:41.700]   And by the way,
[00:42:41.700 --> 00:42:43.620]   we've published cumulative probability histograms
[00:42:43.620 --> 00:42:45.380]   in many of my laboratory's papers,
[00:42:45.380 --> 00:42:47.620]   including one that was a Nature article in 2018.
[00:42:47.620 --> 00:42:48.920]   So we run these all the time.
[00:42:48.920 --> 00:42:49.900]   And yes, I know the difference
[00:42:49.900 --> 00:42:52.340]   between independent and cumulative probability.
[00:42:52.340 --> 00:42:53.640]   That's just like, I do.
[00:42:53.640 --> 00:42:58.980]   The way the clip was cut and what I stated,
[00:42:58.980 --> 00:43:03.220]   unfortunately combined to like a pretty great gaffe
[00:43:03.220 --> 00:43:05.860]   where I say, you're just adding,
[00:43:05.860 --> 00:43:09.540]   I said, you're just adding percentages, 20 to 120%.
[00:43:09.540 --> 00:43:11.300]   And then I made a kind of,
[00:43:11.300 --> 00:43:13.480]   unfortunately my humor isn't always so good.
[00:43:13.480 --> 00:43:14.320]   And I made a joke.
[00:43:14.320 --> 00:43:18.300]   I said, 120%, but that's a different thing altogether.
[00:43:18.300 --> 00:43:22.900]   What I should have said was that's impossible.
[00:43:22.900 --> 00:43:25.580]   And here's how it actually works.
[00:43:25.580 --> 00:43:28.380]   But then it continues where I then describe
[00:43:28.380 --> 00:43:30.140]   the cumulative probability histogram
[00:43:30.140 --> 00:43:33.500]   for successful pregnancy.
[00:43:33.500 --> 00:43:35.620]   But somewhere in the early portion,
[00:43:35.620 --> 00:43:37.480]   I misstated something, right?
[00:43:37.480 --> 00:43:39.300]   I made a math error,
[00:43:39.300 --> 00:43:40.940]   which implied I didn't understand the difference
[00:43:40.940 --> 00:43:43.580]   between independent and cumulative probability,
[00:43:43.580 --> 00:43:44.740]   which I do.
[00:43:44.740 --> 00:43:46.860]   And it got picked up and run,
[00:43:46.860 --> 00:43:48.780]   and people had a really good laugh
[00:43:48.780 --> 00:43:51.140]   with that one at my expense.
[00:43:51.140 --> 00:43:53.600]   And so what I did in response to it was,
[00:43:53.600 --> 00:43:56.780]   rather than just say everything I just said now,
[00:43:56.780 --> 00:43:59.180]   I said, I just came out online and said,
[00:43:59.180 --> 00:44:03.660]   hey folks, in an episode dated this on fertility,
[00:44:03.660 --> 00:44:04.900]   I made a math error.
[00:44:04.900 --> 00:44:08.500]   Here is the formula for cumulative probability,
[00:44:08.500 --> 00:44:10.300]   successful pregnancy at that age.
[00:44:10.300 --> 00:44:11.940]   Here's the graph, here's the, you know,
[00:44:11.940 --> 00:44:14.900]   and I offered it as a teaching moment in two ways.
[00:44:14.900 --> 00:44:17.580]   One, for people to understand cumulative probability.
[00:44:17.580 --> 00:44:19.100]   It was sort of interesting to a number of people
[00:44:19.100 --> 00:44:21.380]   that had come out critiquing the GAF.
[00:44:21.380 --> 00:44:24.420]   Also like biology and folks came out
[00:44:24.420 --> 00:44:26.040]   pointing out that they didn't understand
[00:44:26.040 --> 00:44:26.940]   cumulative probability.
[00:44:26.940 --> 00:44:28.660]   So there was a lot of posturing.
[00:44:28.660 --> 00:44:29.580]   You know, the dog pile,
[00:44:29.580 --> 00:44:31.300]   oftentimes people are quick to dog pile.
[00:44:31.300 --> 00:44:32.140]   They didn't understand,
[00:44:32.140 --> 00:44:33.500]   but a lot of people did understand.
[00:44:33.500 --> 00:44:35.820]   Some smart people out there, obviously.
[00:44:35.820 --> 00:44:37.540]   I called my dad and he was just laughing.
[00:44:37.540 --> 00:44:38.780]   He goes, oh, this is good.
[00:44:38.780 --> 00:44:41.600]   This is like the old school way of hammering academics.
[00:44:41.600 --> 00:44:46.060]   But the point being, it was a teaching moment.
[00:44:46.060 --> 00:44:49.540]   Gave me an opportunity to say, hey, I made a mistake.
[00:44:49.540 --> 00:44:51.300]   I also made a mistake in another podcast
[00:44:51.300 --> 00:44:54.780]   where I did a micron to millimeter conversion
[00:44:54.780 --> 00:44:56.500]   and or centimeter conversion.
[00:44:56.500 --> 00:44:58.440]   And we always correct these in the show note captions.
[00:44:58.440 --> 00:45:00.100]   We correct them in the audio now.
[00:45:00.100 --> 00:45:03.020]   Unfortunately on YouTube, it's harder to correct.
[00:45:03.020 --> 00:45:04.300]   You can't go and edit in segments.
[00:45:04.300 --> 00:45:05.660]   We put it in the captions.
[00:45:05.660 --> 00:45:07.900]   But that was the one teaching moment.
[00:45:07.900 --> 00:45:10.420]   If you make a mistake, it's substantive and relate to data.
[00:45:10.420 --> 00:45:12.780]   You apologize and correct the mistake.
[00:45:12.780 --> 00:45:13.660]   Use it as a teaching moment.
[00:45:13.660 --> 00:45:16.340]   The other one was to say, hey, you know,
[00:45:16.340 --> 00:45:19.060]   in all the thousands of hours of content we've put out,
[00:45:19.060 --> 00:45:20.540]   I'm sure I've made some small errors.
[00:45:20.540 --> 00:45:23.060]   I think I once said serotonin when I meant dopamine
[00:45:23.060 --> 00:45:25.700]   and you know, you're going, you're riffing.
[00:45:25.700 --> 00:45:30.240]   And it's a reminder to be careful, to edit, double-check.
[00:45:30.240 --> 00:45:33.080]   But the internet usually edits for us.
[00:45:33.080 --> 00:45:34.560]   And then we go make corrections.
[00:45:34.560 --> 00:45:37.120]   But it didn't feel good at first, but ultimately,
[00:45:37.120 --> 00:45:39.220]   you know, I can laugh at myself about it.
[00:45:39.220 --> 00:45:44.280]   Long ago at Berkeley, when I was TAing my first class,
[00:45:44.280 --> 00:45:49.120]   it was a biopsychology class, to be 1998 or 1999.
[00:45:49.120 --> 00:45:51.880]   I was drawing the pituitary gland,
[00:45:51.880 --> 00:45:53.600]   which is, you know, it has an anterior
[00:45:53.600 --> 00:45:56.140]   and a posterior lobe, actually it's a medial lobe too.
[00:45:56.140 --> 00:45:58.980]   I had probably 500, 600 students in that lecture hall.
[00:45:58.980 --> 00:46:01.820]   And I drew a chalkboard and I drew the two lobes
[00:46:01.820 --> 00:46:04.580]   of the pituitary and I said, my back was to the audience.
[00:46:04.580 --> 00:46:07.980]   I said, you know, and so they just sort of hang there
[00:46:07.980 --> 00:46:10.100]   and everyone just erupted in laughter
[00:46:10.100 --> 00:46:12.560]   'cause it looked like a scrotum with two testicles.
[00:46:12.560 --> 00:46:14.940]   And I remember thinking like, oh my God,
[00:46:14.940 --> 00:46:19.100]   I don't think I can turn around, I can face this, you know.
[00:46:19.100 --> 00:46:21.640]   And I'm like, oh, I got to turn around sooner or later.
[00:46:21.640 --> 00:46:24.820]   So I turned around and we just all had a big laugh together.
[00:46:24.820 --> 00:46:26.060]   It was embarrassing.
[00:46:26.060 --> 00:46:27.040]   I'll tell you one thing though,
[00:46:27.040 --> 00:46:29.820]   they never forgot about the two lobes of the pituitary.
[00:46:29.820 --> 00:46:32.740]   - Yeah, and you haven't forgotten about that either.
[00:46:32.740 --> 00:46:36.260]   - Right, there's a high salience for these kinds of things.
[00:46:36.260 --> 00:46:41.260]   And it also was kind of fun to see how excited people get
[00:46:41.260 --> 00:46:44.260]   to see people trip.
[00:46:44.260 --> 00:46:47.180]   It's like an elite sprinter trips and does something stupid,
[00:46:47.180 --> 00:46:48.820]   like, you know, runs the opposite direction
[00:46:48.820 --> 00:46:50.240]   of the blocks or something like that.
[00:46:50.240 --> 00:46:55.240]   And, or, you know, I recall at one World Cup match years ago,
[00:46:55.240 --> 00:46:57.280]   a guy scored against his own team.
[00:46:57.280 --> 00:46:58.840]   I think they killed the guy.
[00:46:58.840 --> 00:47:00.220]   Do you remember that?
[00:47:00.220 --> 00:47:02.200]   Some South American or Central American team.
[00:47:02.200 --> 00:47:04.040]   - Yeah. - And they killed the guy.
[00:47:04.040 --> 00:47:06.340]   But yeah, let's look it up.
[00:47:06.340 --> 00:47:08.440]   I just said World Cup.
[00:47:08.440 --> 00:47:09.860]   Yeah, he was gunned down.
[00:47:09.860 --> 00:47:13.000]   - Andres Escobar. - Yeah.
[00:47:13.000 --> 00:47:15.960]   - Scored against his own team in 1994 World Cup
[00:47:15.960 --> 00:47:17.740]   in the United States.
[00:47:17.740 --> 00:47:22.740]   Just 27 years old, playing for the Columbia national team.
[00:47:22.740 --> 00:47:25.760]   - Yeah, last name Escobar, it's a good name.
[00:47:25.760 --> 00:47:27.800]   - Think it would protect you.
[00:47:27.800 --> 00:47:30.880]   - Listen, you know, so there are some gaffes
[00:47:30.880 --> 00:47:35.380]   that get people killed, right?
[00:47:35.380 --> 00:47:40.380]   So, you know, how forgiving are we for online mistakes?
[00:47:40.380 --> 00:47:43.080]   You know, it's the nature of the mistakes.
[00:47:43.080 --> 00:47:45.960]   People were quite gracious about the gaffe,
[00:47:45.960 --> 00:47:46.920]   and some weren't.
[00:47:46.920 --> 00:47:51.540]   And, you know, it's interesting that we,
[00:47:51.540 --> 00:47:55.240]   as public health science educators,
[00:47:55.240 --> 00:47:58.980]   you know, we'll do long podcasts sometimes,
[00:47:58.980 --> 00:48:00.580]   and you need to be really careful.
[00:48:00.580 --> 00:48:04.260]   What's great is AI allows you to check
[00:48:04.260 --> 00:48:07.060]   these things now more readily.
[00:48:07.060 --> 00:48:09.340]   So that's cool.
[00:48:09.340 --> 00:48:12.900]   And there are ways that it's now gonna
[00:48:12.900 --> 00:48:14.060]   be more self-correcting.
[00:48:14.060 --> 00:48:17.340]   I mean, you know, I think there's a lot of errors
[00:48:17.340 --> 00:48:19.660]   out there on the internet, and people are finding them,
[00:48:19.660 --> 00:48:21.740]   and it's cool, like things are getting cleaned up.
[00:48:21.740 --> 00:48:23.860]   - Yeah, but mistakes nevertheless will happen.
[00:48:23.860 --> 00:48:28.860]   Are you, do you feel the pressure of not making mistakes?
[00:48:28.860 --> 00:48:32.380]   - Sure, I mean, you know, I try and get things right
[00:48:32.380 --> 00:48:35.440]   to the best of, you know, to the best of my ability.
[00:48:35.440 --> 00:48:36.660]   I check with experts.
[00:48:36.660 --> 00:48:39.140]   It's kind of interesting when people really don't like
[00:48:39.140 --> 00:48:41.340]   something that was said in a podcast,
[00:48:41.340 --> 00:48:43.380]   a lot of times I chuckle 'cause I'm, you know,
[00:48:43.380 --> 00:48:45.740]   at Stanford we have some amazing scientists,
[00:48:45.740 --> 00:48:48.100]   but I talk to them else, people elsewhere.
[00:48:48.100 --> 00:48:54.460]   And it's always interesting to me how,
[00:48:54.460 --> 00:48:59.740]   you know, I'll get divergent information,
[00:48:59.740 --> 00:49:02.980]   and then I'll find the overlap in the Venn diagram,
[00:49:02.980 --> 00:49:04.720]   and I have this, like, question.
[00:49:04.720 --> 00:49:07.500]   Do I just stay with the overlap in the Venn diagram?
[00:49:07.500 --> 00:49:09.940]   Like, I did an episode on oral health.
[00:49:09.940 --> 00:49:12.940]   I didn't know this until I researched that episode,
[00:49:12.940 --> 00:49:15.900]   but oral health is critically related
[00:49:15.900 --> 00:49:17.420]   to heart health and brain health.
[00:49:17.420 --> 00:49:20.380]   There's a bacteria that causes cavity streptococcus,
[00:49:20.380 --> 00:49:23.540]   you know, that can make its way
[00:49:23.540 --> 00:49:25.820]   into other parts of the body through the mouth
[00:49:25.820 --> 00:49:28.140]   that can cause serious issues.
[00:49:28.140 --> 00:49:30.460]   There's the idea that some forms of dementia,
[00:49:30.460 --> 00:49:34.380]   some forms of heart disease start in the mouth, basically.
[00:49:34.380 --> 00:49:38.540]   I talked to no fewer than four dentists, dental experts,
[00:49:38.540 --> 00:49:40.520]   and there was a lot of convergence.
[00:49:40.520 --> 00:49:44.480]   I also learned that teeth can demineralize,
[00:49:44.480 --> 00:49:45.880]   that's the formation of cavities.
[00:49:45.880 --> 00:49:47.120]   They can also remineralize.
[00:49:47.120 --> 00:49:48.400]   As long as the cavity isn't too deep,
[00:49:48.400 --> 00:49:50.320]   it can actually fill itself back in,
[00:49:50.320 --> 00:49:53.360]   especially if you provide the right substrates for it.
[00:49:53.360 --> 00:49:55.640]   That saliva is this incredible fluid
[00:49:55.640 --> 00:49:58.120]   that has all this capacity to remineralize teeth,
[00:49:58.120 --> 00:50:00.000]   provided the milieu is right.
[00:50:00.000 --> 00:50:02.340]   Things like alcohol-based mouthwashes,
[00:50:02.340 --> 00:50:04.560]   killing off some of the critical things you need.
[00:50:04.560 --> 00:50:06.400]   It's fascinating, and I put out that episode thinking,
[00:50:06.400 --> 00:50:08.360]   oh, I'm not a dentist, I'm not an oral health episode,
[00:50:08.360 --> 00:50:09.900]   but I talked to a pediatric dentist.
[00:50:09.900 --> 00:50:13.740]   There's a terrific one, Dr. Downscore Stacey,
[00:50:13.740 --> 00:50:17.200]   S-T-A-C-I on Instagram, does great content.
[00:50:17.200 --> 00:50:22.200]   Talked to some others, and then I just waited for the attack.
[00:50:22.200 --> 00:50:25.200]   I was like, here we go, and it didn't come,
[00:50:25.200 --> 00:50:26.640]   and dentists were thanking me.
[00:50:26.640 --> 00:50:28.640]   I was like, whew, you know?
[00:50:28.640 --> 00:50:29.880]   That's a rare thing.
[00:50:29.880 --> 00:50:32.080]   More often than not, if I do an episode about,
[00:50:32.080 --> 00:50:35.880]   say, psilocybin or MDMA, you get some people liking it,
[00:50:35.880 --> 00:50:37.800]   or ADHD and the drugs for ADHD.
[00:50:37.800 --> 00:50:40.140]   We did a whole episode on the Ritalin, Vyvanse,
[00:50:40.140 --> 00:50:41.220]   Adderall stuff.
[00:50:41.220 --> 00:50:42.460]   You get people saying, thank you.
[00:50:42.460 --> 00:50:45.360]   You know, I prescribed this to my kid, and it really helps.
[00:50:45.360 --> 00:50:48.900]   But they're private about the fact that they do it
[00:50:48.900 --> 00:50:52.100]   because they get so much attack from other people.
[00:50:52.100 --> 00:50:57.100]   So I like to find the center of mass, report that,
[00:50:57.100 --> 00:50:59.320]   try and make it as clear as possible,
[00:50:59.320 --> 00:51:01.060]   and then I know that there's some stuff
[00:51:01.060 --> 00:51:03.200]   where I'm gonna catch shit.
[00:51:03.200 --> 00:51:08.140]   What's frustrating for me is when I see claims
[00:51:08.140 --> 00:51:11.580]   that I'm against fluoridization of water, which I'm not.
[00:51:11.580 --> 00:51:13.100]   We talked about the benefits of fluoride.
[00:51:13.100 --> 00:51:16.100]   It builds hyper-strong bonds within the teeth.
[00:51:16.100 --> 00:51:18.340]   I went and looked at some of the,
[00:51:18.340 --> 00:51:19.960]   literally, the crystal, excuse me,
[00:51:19.960 --> 00:51:21.220]   not the crystal structure,
[00:51:21.220 --> 00:51:26.220]   but essentially the micron and submicron structure of teeth.
[00:51:26.220 --> 00:51:29.140]   It's incredible, and where fluoride can get in there
[00:51:29.140 --> 00:51:31.460]   and form these super-strong bonds,
[00:51:31.460 --> 00:51:33.160]   and you can also form them with things
[00:51:33.160 --> 00:51:35.520]   like hydroxyapatite, and why is there fluoride in water?
[00:51:35.520 --> 00:51:36.360]   Well, it's the best.
[00:51:36.360 --> 00:51:39.700]   Okay, you say some things that are interesting,
[00:51:39.700 --> 00:51:41.200]   but then somehow it gets turned into
[00:51:41.200 --> 00:51:43.720]   like you're against fluoridization, which I'm not,
[00:51:43.720 --> 00:51:46.200]   or I've been accused of being against sunscreen.
[00:51:46.200 --> 00:51:49.120]   I wear mineral-based sunscreen on my face.
[00:51:49.120 --> 00:51:52.480]   I don't wanna get skin cancer, or I use a physical barrier.
[00:51:52.480 --> 00:51:53.680]   There is a cohort of people out there
[00:51:53.680 --> 00:51:55.120]   that think that all sunscreens are bad.
[00:51:55.120 --> 00:51:55.960]   I'm not one of them.
[00:51:55.960 --> 00:51:57.960]   I'm not what's called a sunscreen truther,
[00:51:57.960 --> 00:52:00.000]   but then you get attacked for it.
[00:52:00.000 --> 00:52:01.640]   So we're talking about there are certain sunscreens
[00:52:01.640 --> 00:52:05.680]   that are problematic, and Rhonda Patrick's now
[00:52:05.680 --> 00:52:07.040]   starting to get vocal about this,
[00:52:07.040 --> 00:52:09.840]   and so there's certain topics it's interesting for which
[00:52:09.840 --> 00:52:15.760]   you have to listen carefully to what somebody is saying,
[00:52:15.760 --> 00:52:19.060]   but there's a lumping as opposed to splitting
[00:52:19.060 --> 00:52:21.880]   of what health educators say,
[00:52:21.880 --> 00:52:24.480]   and so it just seems like, like with politics,
[00:52:24.480 --> 00:52:27.520]   there's this urgency to just put people into a camp
[00:52:27.520 --> 00:52:31.480]   of expert versus like renegade or something,
[00:52:31.480 --> 00:52:32.360]   and it's not like that.
[00:52:32.360 --> 00:52:33.200]   It's just not like that.
[00:52:33.200 --> 00:52:36.000]   So the short answer is I really strive,
[00:52:36.000 --> 00:52:37.760]   really strive to get things right,
[00:52:37.760 --> 00:52:40.040]   but I know that I'm gonna piss certain people off,
[00:52:40.040 --> 00:52:44.600]   and you've taught me, and Joe's taught me,
[00:52:44.600 --> 00:52:47.520]   and other podcasters have taught me
[00:52:47.520 --> 00:52:50.160]   that if you worry too much about it,
[00:52:50.160 --> 00:52:54.280]   then you aren't gonna get the newest information out there.
[00:52:54.280 --> 00:52:56.160]   Like peptides, there's very little human data
[00:52:56.160 --> 00:52:59.240]   unless you're talking about Vilese or the melanin,
[00:52:59.240 --> 00:53:00.640]   you know, the stuff in the alpha melanocyte
[00:53:00.640 --> 00:53:02.620]   stimulating hormone stuff which are prescribed
[00:53:02.620 --> 00:53:04.960]   for female libido to enhance female libido,
[00:53:04.960 --> 00:53:07.480]   or sermorelin, which is for certain
[00:53:07.480 --> 00:53:08.520]   growth hormone deficiencies.
[00:53:08.520 --> 00:53:11.360]   With rare exception, there's very little human data,
[00:53:11.360 --> 00:53:13.520]   but people are still super interested,
[00:53:13.520 --> 00:53:15.160]   and a lot of people are taking and doing these things,
[00:53:15.160 --> 00:53:16.960]   so you wanna get the information out.
[00:53:16.960 --> 00:53:20.000]   - Do you try to not just look at the science
[00:53:20.000 --> 00:53:22.120]   but research what the communities are talking,
[00:53:22.120 --> 00:53:23.780]   what the various communities are talking about?
[00:53:23.780 --> 00:53:26.620]   Like maybe research what the conspiracy theorists
[00:53:26.620 --> 00:53:29.580]   are talking about, just so you know
[00:53:29.580 --> 00:53:34.000]   all the armies that are going to be attacking your castle.
[00:53:34.000 --> 00:53:35.320]   - Yes, so like for instance,
[00:53:35.320 --> 00:53:36.720]   there is a community of people online
[00:53:36.720 --> 00:53:39.460]   that believe that like if you consume seed oils
[00:53:39.460 --> 00:53:42.940]   or something that like you're setting up your skin
[00:53:42.940 --> 00:53:44.620]   for sunburn, and if you don't, you know,
[00:53:44.620 --> 00:53:46.620]   like there's all these like theories,
[00:53:46.620 --> 00:53:48.540]   but I like to, so I like to know what the theories are.
[00:53:48.540 --> 00:53:50.580]   I like to know what the extremes are,
[00:53:50.580 --> 00:53:53.440]   but I also like to know what the standard conversation is,
[00:53:53.440 --> 00:53:56.720]   but there's generally more agreement than disagreement.
[00:53:56.720 --> 00:54:01.360]   I think where, you know, I've been kind of bullish actually
[00:54:01.360 --> 00:54:02.900]   is, you know, like supplements.
[00:54:02.900 --> 00:54:04.100]   Like people go, "Oh, supplements."
[00:54:04.100 --> 00:54:06.580]   Well, there's food supplements, like a protein powder,
[00:54:06.580 --> 00:54:09.660]   just different than a vitamin, and then there are compounds.
[00:54:09.660 --> 00:54:11.940]   There are compounds that have real benefit,
[00:54:11.940 --> 00:54:13.820]   but people get very nervous about the fact
[00:54:13.820 --> 00:54:15.300]   that they're not regulated,
[00:54:15.300 --> 00:54:18.660]   but some of them are vetted for potency
[00:54:18.660 --> 00:54:23.060]   and for safety with more rigor than others, you know,
[00:54:23.060 --> 00:54:27.940]   and it's interesting to see how people
[00:54:27.940 --> 00:54:32.300]   who take care of themselves and put a lot of work into that
[00:54:32.300 --> 00:54:33.380]   are often attacked.
[00:54:33.380 --> 00:54:34.300]   That's been interesting.
[00:54:34.300 --> 00:54:36.460]   Also, one of the most controversial topics nowadays
[00:54:36.460 --> 00:54:38.540]   is Ozempic, Munjaro.
[00:54:38.540 --> 00:54:40.200]   I'm very middle of the road on this.
[00:54:40.200 --> 00:54:43.300]   I don't understand why the, quote, unquote,
[00:54:43.300 --> 00:54:46.200]   health wellness community is so against these things.
[00:54:46.200 --> 00:54:48.620]   I also don't understand why they have to be looked at
[00:54:48.620 --> 00:54:49.820]   as the only route.
[00:54:49.820 --> 00:54:52.300]   For some people, they've really helped them lose weight,
[00:54:52.300 --> 00:54:54.020]   and yes, there can be some muscle loss
[00:54:54.020 --> 00:54:56.180]   and other lean body loss,
[00:54:56.180 --> 00:54:58.220]   but that can be offset with resistance training.
[00:54:58.220 --> 00:54:59.740]   They've helped a lot of people,
[00:54:59.740 --> 00:55:02.380]   and other people are like, "No, this stuff is terrible."
[00:55:02.380 --> 00:55:04.540]   I think the most interesting thing about Ozempic, Munjaro
[00:55:04.540 --> 00:55:06.500]   is that they are GLP-1.
[00:55:06.500 --> 00:55:09.560]   They're in the GLP-1 pathway, glucagon-like peptide one,
[00:55:09.560 --> 00:55:12.700]   and it was discovered in Gila monsters,
[00:55:12.700 --> 00:55:17.100]   which is a lizard, basically,
[00:55:17.100 --> 00:55:20.740]   and someone, now the entomologist will dive on me.
[00:55:20.740 --> 00:55:22.460]   It's a big lizard-looking thing
[00:55:22.460 --> 00:55:24.020]   that doesn't eat very often,
[00:55:24.020 --> 00:55:25.660]   and they figured out that there's this peptide
[00:55:25.660 --> 00:55:28.980]   that allows it to curb its own appetite
[00:55:28.980 --> 00:55:32.180]   at the level of the brain and the gut,
[00:55:32.180 --> 00:55:34.860]   and it has a lot of homology, sequence homology,
[00:55:34.860 --> 00:55:36.580]   to what we now call GLP-1.
[00:55:36.580 --> 00:55:38.620]   So I love any time there's animal biology
[00:55:38.620 --> 00:55:40.660]   linked to cool human biology,
[00:55:40.660 --> 00:55:42.700]   linked to a drug that's powerful
[00:55:42.700 --> 00:55:45.100]   that can help people with obesity and type 2 diabetes,
[00:55:45.100 --> 00:55:47.900]   and there's evidence that can even curb some addictions.
[00:55:49.380 --> 00:55:52.740]   Those are newer data, but I don't see it as either/or.
[00:55:52.740 --> 00:55:54.260]   In fact, I've been a little bit disappointed
[00:55:54.260 --> 00:55:57.220]   at the way that the, whatever you want to call it,
[00:55:57.220 --> 00:55:58.780]   health, wellness, biohacking community
[00:55:58.780 --> 00:56:00.700]   has slammed on Ozempic, Munjaro.
[00:56:00.700 --> 00:56:02.660]   It's like, they're like, "Just get out and run."
[00:56:02.660 --> 00:56:04.020]   Listen, there are people who are carrying
[00:56:04.020 --> 00:56:05.620]   substantial amounts of weight
[00:56:05.620 --> 00:56:07.540]   that running could injure them.
[00:56:07.540 --> 00:56:09.700]   They get on these drugs and they can improve,
[00:56:09.700 --> 00:56:11.660]   and then hopefully they're also doing resistance training
[00:56:11.660 --> 00:56:12.500]   and eating better,
[00:56:12.500 --> 00:56:14.540]   and then you're bringing all the elements together.
[00:56:14.540 --> 00:56:16.420]   - Well, why do you think the criticism is happening?
[00:56:16.420 --> 00:56:18.540]   Is it that Ozempic became super popular
[00:56:18.540 --> 00:56:20.500]   so people are misusing it or that kind of thing?
[00:56:20.500 --> 00:56:24.020]   - No, I think what it is is that people think
[00:56:24.020 --> 00:56:27.300]   if it's a pharmaceutical, it's bad,
[00:56:27.300 --> 00:56:30.180]   and then, or if it's a supplement, it's bad,
[00:56:30.180 --> 00:56:31.300]   depending on which camp they're in,
[00:56:31.300 --> 00:56:33.860]   and it wouldn't it be wonderful to kind of like
[00:56:33.860 --> 00:56:35.620]   fill in the gap between this divide?
[00:56:35.620 --> 00:56:38.980]   You know, what I would like to see in politics
[00:56:38.980 --> 00:56:41.900]   and in health is neither right nor left,
[00:56:41.900 --> 00:56:44.540]   but what we can just call a league of reasonable people
[00:56:44.540 --> 00:56:47.340]   that looks at things on an issue-by-issue basis
[00:56:47.340 --> 00:56:48.620]   and fills in the center,
[00:56:48.620 --> 00:56:50.740]   'cause I think most people are in the,
[00:56:50.740 --> 00:56:52.780]   are, I don't wanna say center in a political way,
[00:56:52.780 --> 00:56:54.580]   but I think most people are reasonable.
[00:56:54.580 --> 00:56:58.260]   They want to be reasonable, but that's not what sells clicks.
[00:56:58.260 --> 00:57:01.260]   That's not what drives interest.
[00:57:01.260 --> 00:57:04.660]   But I'm a very, like, I look at issue-by-issue,
[00:57:04.660 --> 00:57:06.020]   person-by-person.
[00:57:06.020 --> 00:57:07.460]   I don't like in-group, out-group stuff.
[00:57:07.460 --> 00:57:08.300]   I never have.
[00:57:08.300 --> 00:57:10.060]   I've got friends from all walks of life.
[00:57:10.060 --> 00:57:11.180]   I said this on another podcast,
[00:57:11.180 --> 00:57:12.860]   and it always sounds like a political statement,
[00:57:12.860 --> 00:57:17.700]   but like the push towards, like, you know,
[00:57:17.700 --> 00:57:19.980]   polarization is, it's so frustrating.
[00:57:19.980 --> 00:57:22.180]   If there's one thing that's discouraging to me
[00:57:22.180 --> 00:57:24.740]   as I get older each year, I'm like,
[00:57:24.740 --> 00:57:28.420]   wow, are we ever gonna get out of this, like, polarization?
[00:57:28.420 --> 00:57:30.340]   Speaking of which, how are you gonna vote
[00:57:30.340 --> 00:57:31.700]   for the presidential election?
[00:57:31.700 --> 00:57:33.140]   (laughing)
[00:57:33.140 --> 00:57:34.380]   - I'm still trying to figure out
[00:57:34.380 --> 00:57:37.660]   how to interview the people involved and do it well.
[00:57:37.660 --> 00:57:39.380]   - What do you think the role of podcasts
[00:57:39.380 --> 00:57:41.980]   is gonna be in this year's election?
[00:57:41.980 --> 00:57:44.820]   - I would love long-form conversations
[00:57:44.820 --> 00:57:48.260]   to happen with the candidates.
[00:57:48.260 --> 00:57:49.820]   I think it's gonna be huge.
[00:57:49.820 --> 00:57:51.180]   I would love Trump to go on,
[00:57:51.180 --> 00:57:54.660]   Rogan, I'm embarrassed to say this,
[00:57:54.660 --> 00:57:56.820]   but I would love to, honestly,
[00:57:56.820 --> 00:58:00.020]   would love to see Joe Biden go on Joe Rogan also.
[00:58:00.020 --> 00:58:02.940]   - I would imagine that both would go on, but separately.
[00:58:02.940 --> 00:58:06.500]   - Separately, I think it's, I think a debate,
[00:58:06.500 --> 00:58:09.180]   Joe does debates, but I think Joe at his best
[00:58:09.180 --> 00:58:11.380]   is one-on-one conversation, really intimate.
[00:58:12.380 --> 00:58:14.500]   I just wish that Joe Biden
[00:58:14.500 --> 00:58:17.300]   would actually do long-form conversations.
[00:58:17.300 --> 00:58:18.860]   - I thought he had done a, it wasn't,
[00:58:18.860 --> 00:58:21.300]   I think it was on Jay Shetty's podcast.
[00:58:21.300 --> 00:58:23.180]   - He did Jay Shetty, he did a few,
[00:58:23.180 --> 00:58:27.620]   but when I mean long-form, I mean really long-form,
[00:58:27.620 --> 00:58:29.540]   like two, three hours, and more relaxed.
[00:58:29.540 --> 00:58:31.580]   It was much more orchestrated,
[00:58:31.580 --> 00:58:32.780]   because what happens when it's,
[00:58:32.780 --> 00:58:34.900]   the interview's a little bit too short,
[00:58:34.900 --> 00:58:39.220]   it becomes into this generic political type
[00:58:39.220 --> 00:58:42.740]   of NBC/CNN type of interview.
[00:58:42.740 --> 00:58:44.180]   You get a set of questions,
[00:58:44.180 --> 00:58:47.700]   and you don't get to really feel the human,
[00:58:47.700 --> 00:58:50.860]   expose the human to the light in the full,
[00:58:50.860 --> 00:58:53.460]   we talked about the shadow, the good, the bad, and the ugly.
[00:58:53.460 --> 00:58:55.340]   So I think there's something magical
[00:58:55.340 --> 00:58:57.020]   about two, three, four hours,
[00:58:57.020 --> 00:58:59.860]   but it doesn't have to be that long,
[00:58:59.860 --> 00:59:02.460]   but it has to have that feeling to it,
[00:59:02.460 --> 00:59:05.140]   where there's not people standing around,
[00:59:05.140 --> 00:59:06.460]   and everybody's nervous,
[00:59:06.500 --> 00:59:09.860]   and you're going to be strictly sticking
[00:59:09.860 --> 00:59:12.060]   to the question/answer type of feel,
[00:59:12.060 --> 00:59:13.100]   but just shooting shit,
[00:59:13.100 --> 00:59:17.620]   which Rogan is the best by far in the world at that.
[00:59:17.620 --> 00:59:19.940]   - I don't think people really appreciate
[00:59:19.940 --> 00:59:25.980]   how skilled he is at what he does,
[00:59:25.980 --> 00:59:30.420]   and the number, I mean the three or four podcasts per week,
[00:59:30.420 --> 00:59:34.340]   plus the UFC announcing, plus comedy tours in stadiums,
[00:59:34.340 --> 00:59:39.180]   plus doing comedy shows in the middle of the week,
[00:59:39.180 --> 00:59:43.260]   plus a husband, and a father, and a friend in jiu-jitsu,
[00:59:43.260 --> 00:59:46.340]   the guy's got superhuman levels of output.
[00:59:46.340 --> 00:59:49.100]   I agree that long form conversation
[00:59:49.100 --> 00:59:50.620]   is a whole other business,
[00:59:50.620 --> 00:59:52.940]   and I think that people want and deserve
[00:59:52.940 --> 00:59:56.700]   to know the people that are running for office
[00:59:56.700 --> 00:59:59.800]   in a different way, and to really get to know them.
[01:00:01.260 --> 01:00:03.620]   - Well, listen, I guess you,
[01:00:03.620 --> 01:00:06.260]   is it clear that he's gonna do jail time,
[01:00:06.260 --> 01:00:07.660]   or maybe he gets away with a fine?
[01:00:07.660 --> 01:00:08.740]   - No, I don't think, I'm--
[01:00:08.740 --> 01:00:10.140]   - Because I was gonna say,
[01:00:10.140 --> 01:00:11.820]   does that mean you're gonna be podcasting from jail?
[01:00:11.820 --> 01:00:13.580]   - In prison, yeah, we're going to,
[01:00:13.580 --> 01:00:16.600]   in fact, I'm going to figure out how to commit a crime
[01:00:16.600 --> 01:00:17.860]   so I can get in prison with him.
[01:00:17.860 --> 01:00:18.940]   - Please don't, please don't.
[01:00:18.940 --> 01:00:22.280]   - Well, that's, I'm sure they have visitors, right?
[01:00:22.280 --> 01:00:23.980]   - That just doesn't feel an authentic way
[01:00:23.980 --> 01:00:26.580]   to get the interview, but yeah, I understand.
[01:00:26.580 --> 01:00:28.260]   - You wouldn't be able to wear that suit,
[01:00:28.260 --> 01:00:29.720]   you'd be wearing a different suit.
[01:00:29.720 --> 01:00:30.560]   - That's true.
[01:00:30.560 --> 01:00:32.900]   - Yeah, it's gonna be interesting,
[01:00:32.900 --> 01:00:34.860]   and you'd do, I'm not just saying this
[01:00:34.860 --> 01:00:37.220]   'cause you're my friend, but you would do a marvelous job.
[01:00:37.220 --> 01:00:40.420]   I think you should sit down with all of them separately
[01:00:40.420 --> 01:00:43.940]   to keep it civil, and see what happens.
[01:00:43.940 --> 01:00:47.500]   Here's one thing that I found really interesting
[01:00:47.500 --> 01:00:49.740]   in this whole political landscape.
[01:00:49.740 --> 01:00:52.700]   When I'm in Los Angeles, I often get invited to these,
[01:00:52.700 --> 01:00:55.660]   like, they're not dinners, but gatherings where,
[01:00:55.660 --> 01:00:59.900]   you know, a local bunch of podcasters will come together,
[01:00:59.900 --> 01:01:02.620]   but a lot of people from the entertainment industry,
[01:01:02.620 --> 01:01:05.420]   big agencies, big tech, like big, big tech,
[01:01:05.420 --> 01:01:08.300]   many of the people have been on this podcast,
[01:01:08.300 --> 01:01:11.300]   and they'll host a discussion or a debate,
[01:01:11.300 --> 01:01:13.500]   and what you find, if you look around the room
[01:01:13.500 --> 01:01:16.460]   and you talk to people, is that about half the people
[01:01:16.460 --> 01:01:19.420]   in the room are very left-leaning,
[01:01:19.420 --> 01:01:21.080]   and very outspoken about that,
[01:01:21.080 --> 01:01:22.660]   and they'll tell you exactly who they wanna see
[01:01:22.660 --> 01:01:24.980]   in the, win the presidential race,
[01:01:24.980 --> 01:01:26.780]   and the other half will tell you
[01:01:26.780 --> 01:01:28.380]   that they're for the other side.
[01:01:28.380 --> 01:01:33.140]   A lot of people that people assume
[01:01:33.140 --> 01:01:35.740]   are on one side of the aisle or the other
[01:01:35.740 --> 01:01:37.660]   are in the exact opposite side.
[01:01:37.660 --> 01:01:40.180]   Now, some people are very open about who they're for,
[01:01:40.180 --> 01:01:43.720]   but it's been very interesting to see how,
[01:01:43.720 --> 01:01:46.300]   when you get people one-on-one, they're, like, telling you
[01:01:46.300 --> 01:01:49.180]   they want X candidate to win, or Y candidate to win,
[01:01:49.180 --> 01:01:50.440]   and sometimes, like, really?
[01:01:50.440 --> 01:01:51.280]   I can't believe it.
[01:01:51.280 --> 01:01:52.380]   Like, you?
[01:01:52.380 --> 01:01:53.220]   Like, yep.
[01:01:53.220 --> 01:01:57.100]   And so, it's what people think about
[01:01:57.540 --> 01:02:02.540]   people's political leanings is often exactly wrong,
[01:02:02.540 --> 01:02:06.300]   and that's been eye-opening for me.
[01:02:06.300 --> 01:02:09.660]   And I've seen that on university campuses, too.
[01:02:09.660 --> 01:02:12.100]   And so, it's gonna be really, really interesting
[01:02:12.100 --> 01:02:13.860]   to see what happens in November.
[01:02:13.860 --> 01:02:15.560]   - In addition to that, as you said,
[01:02:15.560 --> 01:02:17.540]   most people are close to the center,
[01:02:17.540 --> 01:02:19.940]   despite what Twitter makes it seem like.
[01:02:19.940 --> 01:02:22.420]   Most people, whether they're center-left or center-right,
[01:02:22.420 --> 01:02:23.700]   they're kinda close to the center.
[01:02:23.700 --> 01:02:25.500]   - Yeah, I mean, here's, to me,
[01:02:25.500 --> 01:02:26.420]   the most interesting question.
[01:02:26.420 --> 01:02:31.140]   Who is gonna be the next big candidate in years to come?
[01:02:31.140 --> 01:02:32.320]   Like, who's that going to be?
[01:02:32.320 --> 01:02:36.020]   Right now, I don't see or know of that person.
[01:02:36.020 --> 01:02:37.140]   Who's it gonna be?
[01:02:37.140 --> 01:02:39.140]   - Yeah, the young, promising candidates,
[01:02:39.140 --> 01:02:40.820]   we're not seeing them.
[01:02:40.820 --> 01:02:42.140]   We're not seeing them.
[01:02:42.140 --> 01:02:45.740]   Another way to ask that question, who would want to be?
[01:02:45.740 --> 01:02:47.900]   - Well, that's the issue, right?
[01:02:47.900 --> 01:02:50.320]   Who wants to live in this 12-hour news cycle
[01:02:50.320 --> 01:02:52.920]   where you're just trying to dunk on the other team
[01:02:52.920 --> 01:02:57.000]   so that nobody notices the shit that you fucked up?
[01:02:57.000 --> 01:03:01.680]   That's not only not fun or interesting,
[01:03:01.680 --> 01:03:04.680]   it also is just, it's gotta be
[01:03:04.680 --> 01:03:07.000]   psychosis-inducing at some point.
[01:03:07.000 --> 01:03:09.100]   And I think that,
[01:03:09.100 --> 01:03:12.780]   God willing, we're gonna,
[01:03:12.780 --> 01:03:17.400]   some young guy or woman is on this
[01:03:17.400 --> 01:03:21.160]   and refuses to back down
[01:03:21.160 --> 01:03:23.480]   and was just determined to be president
[01:03:23.480 --> 01:03:24.320]   and will make it happen.
[01:03:24.320 --> 01:03:29.320]   But I don't even know who the viable candidates are.
[01:03:29.320 --> 01:03:32.000]   Maybe you, Lex, you know?
[01:03:32.000 --> 01:03:33.400]   We should ask Sagar.
[01:03:33.400 --> 01:03:34.760]   Sagar would know.
[01:03:34.760 --> 01:03:36.440]   - Yeah. - Yeah.
[01:03:36.440 --> 01:03:38.440]   - Maybe Sagar himself.
[01:03:38.440 --> 01:03:40.520]   - Sagar's show is awesome.
[01:03:40.520 --> 01:03:41.360]   - Yeah, it is. - He and Crystal
[01:03:41.360 --> 01:03:42.520]   do a great thing. - He's incredible.
[01:03:42.520 --> 01:03:43.360]   - Especially since they have
[01:03:43.360 --> 01:03:45.080]   somewhat divergent opinions on things.
[01:03:45.080 --> 01:03:46.080]   That's what makes it so cool.
[01:03:46.080 --> 01:03:46.920]   - He's great.
[01:03:46.920 --> 01:03:48.280]   He looks great in the suit, looks real sexy.
[01:03:48.280 --> 01:03:49.520]   - He's taking real good care of himself.
[01:03:49.520 --> 01:03:51.360]   - I think he's getting married soon.
[01:03:51.360 --> 01:03:52.600]   Congratulations, Sagar.
[01:03:52.600 --> 01:03:56.160]   Forgive me for not remembering your future wife's name.
[01:03:56.160 --> 01:03:57.920]   - He won my heart by giving me
[01:03:57.920 --> 01:04:01.400]   a biography of Hitler as a present.
[01:04:01.400 --> 01:04:02.240]   - That's what he gave you?
[01:04:02.240 --> 01:04:04.080]   - Yeah. - I gave you a hatchet
[01:04:04.080 --> 01:04:07.280]   with a poem inscribed in it. - That just shows
[01:04:07.280 --> 01:04:08.360]   the fundamental difference
[01:04:08.360 --> 01:04:11.080]   between the two. - With a poem inscribed in it.
[01:04:11.080 --> 01:04:13.360]   - Which was pretty damn good.
[01:04:13.360 --> 01:04:15.320]   - I realize everything we bring up on the screen
[01:04:15.320 --> 01:04:18.440]   is really depressing,
[01:04:18.440 --> 01:04:21.320]   like the soccer player getting killed.
[01:04:21.320 --> 01:04:23.480]   Can we bring up something happy?
[01:04:23.480 --> 01:04:26.880]   - Sure, let's go to Nature's Metal Instagram.
[01:04:26.880 --> 01:04:28.480]   - Those are pretty intense.
[01:04:28.480 --> 01:04:31.480]   We actually did a collaborative post on a shark thing.
[01:04:31.480 --> 01:04:32.320]   - Really? - Yeah.
[01:04:32.320 --> 01:04:33.160]   - What kind of shark thing?
[01:04:33.160 --> 01:04:37.560]   - So to generate the fear VR stimulus for my lab,
[01:04:37.560 --> 01:04:41.920]   in 20, was it, yeah, 2016,
[01:04:41.920 --> 01:04:44.720]   we went down to Guadalupe Island off the coast of Mexico.
[01:04:44.720 --> 01:04:45.920]   Me and a guy named Michael Muller,
[01:04:45.920 --> 01:04:48.800]   who's a very famous portrait photographer,
[01:04:48.800 --> 01:04:51.600]   but also takes photos of sharks,
[01:04:51.600 --> 01:04:56.600]   and we used 360 video to build VR of great white sharks,
[01:04:56.600 --> 01:05:00.480]   brought it back to the lab.
[01:05:00.480 --> 01:05:02.920]   We published that study in Current Biology.
[01:05:02.920 --> 01:05:05.200]   In 2017, went back down there,
[01:05:05.200 --> 01:05:12.240]   and that was the year that I exited the cage.
[01:05:12.240 --> 01:05:13.680]   You lower the cage with a crane,
[01:05:13.680 --> 01:05:14.840]   and that year I exited the cage.
[01:05:14.840 --> 01:05:17.320]   I had a whole mess with an air failure the day before.
[01:05:17.320 --> 01:05:19.280]   I was breathing from a hookah line while in the cage.
[01:05:19.280 --> 01:05:20.520]   I had no scuba on.
[01:05:20.520 --> 01:05:21.800]   Divers were out.
[01:05:21.800 --> 01:05:23.240]   The thing got boa constricted up,
[01:05:23.240 --> 01:05:24.240]   and I had an air failure,
[01:05:24.240 --> 01:05:25.760]   and I had to actually share air,
[01:05:25.760 --> 01:05:26.760]   and it was a whole mess.
[01:05:26.760 --> 01:05:27.960]   Story for another time.
[01:05:27.960 --> 01:05:30.640]   But the next day, because I didn't want to get PTSD,
[01:05:30.640 --> 01:05:31.480]   and it was pretty scary,
[01:05:31.480 --> 01:05:34.840]   the next day I cage exited with some other divers.
[01:05:34.840 --> 01:05:37.080]   And it turns out with these great white sharks,
[01:05:37.080 --> 01:05:38.960]   in Guadalupe, the water's very clear,
[01:05:38.960 --> 01:05:40.160]   and you can swim toward them,
[01:05:40.160 --> 01:05:42.580]   and then they'll veer off you if you swim toward them.
[01:05:42.580 --> 01:05:44.320]   Otherwise, they see you as prey.
[01:05:44.320 --> 01:05:47.360]   Well, in the evening, you've brought all the cages up,
[01:05:47.360 --> 01:05:49.980]   and you're hopefully all alive,
[01:05:49.980 --> 01:05:54.520]   and we were hanging out fishing for tuna.
[01:05:54.520 --> 01:05:59.520]   We had one of the crew on board had a line in the water
[01:05:59.520 --> 01:06:01.640]   and was fishing for tuna for dinner,
[01:06:01.640 --> 01:06:04.160]   and a shark took the tuna off the line.
[01:06:04.160 --> 01:06:07.760]   And it's a very dramatic take,
[01:06:07.760 --> 01:06:10.920]   and you can see the just absolute size
[01:06:10.920 --> 01:06:12.320]   of these great white sharks.
[01:06:12.320 --> 01:06:13.920]   The waters there are filled with them.
[01:06:13.920 --> 01:06:15.160]   That's the one.
[01:06:15.160 --> 01:06:18.120]   So this video, just the Neuralink link,
[01:06:18.120 --> 01:06:20.880]   was shot by Matt McDougall,
[01:06:20.880 --> 01:06:23.600]   who is the head neurosurgeon at Neuralink.
[01:06:23.600 --> 01:06:24.440]   There it is, it takes it.
[01:06:24.440 --> 01:06:25.760]   Now, believe it or not, it looks like it missed,
[01:06:25.760 --> 01:06:26.660]   like it didn't get the fish.
[01:06:26.660 --> 01:06:29.960]   It actually just cut that thing like a band saw.
[01:06:29.960 --> 01:06:32.320]   So I'm up on the deck with Matt.
[01:06:32.320 --> 01:06:35.320]   Yeah, and so when you look at it from the side,
[01:06:35.320 --> 01:06:40.320]   you really get a sense of the girth of this freaking thing.
[01:06:40.800 --> 01:06:44.680]   So as it comes up, if you look at the size of that thing,
[01:06:44.680 --> 01:06:47.400]   and they move through the water with such speed,
[01:06:47.400 --> 01:06:49.480]   just a couple, so when you're in the cage
[01:06:49.480 --> 01:06:52.000]   and the cage is lowered down below the surface,
[01:06:52.000 --> 01:06:53.320]   they're going around.
[01:06:53.320 --> 01:06:54.760]   You're not allowed to chum the water there.
[01:06:54.760 --> 01:06:58.540]   Some people do it, but, and then when you cage exit,
[01:06:58.540 --> 01:06:59.900]   they're like, well, what are you doing out here?
[01:06:59.900 --> 01:07:03.480]   And then, you know, you swim toward them, they veer off.
[01:07:03.480 --> 01:07:05.240]   But what's interesting is that
[01:07:05.240 --> 01:07:07.500]   if you look at how they move through the water,
[01:07:07.500 --> 01:07:09.440]   all it takes for one of these great white sharks,
[01:07:09.440 --> 01:07:11.880]   when it sees a tuna or something it wants to eat,
[01:07:11.880 --> 01:07:16.800]   is like two flicks of the tail and becomes like a missile.
[01:07:16.800 --> 01:07:19.760]   It's just unbelievable economy of effort.
[01:07:19.760 --> 01:07:22.600]   And Ocean Ramsey, who is, in my opinion,
[01:07:22.600 --> 01:07:24.720]   the greatest of all cage exit shark divers,
[01:07:24.720 --> 01:07:27.480]   this woman who dove with enormous great white sharks,
[01:07:27.480 --> 01:07:29.960]   she really understands their behavior
[01:07:29.960 --> 01:07:30.860]   when they're aggressive,
[01:07:30.860 --> 01:07:32.080]   when they're not gonna be aggressive.
[01:07:32.080 --> 01:07:35.200]   She and her husband, Juan, I believe his name is,
[01:07:35.200 --> 01:07:36.800]   they understand how the tiger sharks
[01:07:36.800 --> 01:07:38.040]   differ from the great white sharks.
[01:07:38.040 --> 01:07:39.720]   We were down there basically,
[01:07:39.720 --> 01:07:41.280]   like not understanding any of this.
[01:07:41.280 --> 01:07:42.320]   We never should have been there.
[01:07:42.320 --> 01:07:45.000]   And actually, the air failure the day before,
[01:07:45.000 --> 01:07:47.200]   plus cage exiting the next day,
[01:07:47.200 --> 01:07:49.760]   I told myself after coming up from the cage exit, that's it.
[01:07:49.760 --> 01:07:51.520]   I'm no longer taking risks with my life.
[01:07:51.520 --> 01:07:52.400]   I wanna live.
[01:07:52.400 --> 01:07:55.400]   Got back across the border a couple days later.
[01:07:55.400 --> 01:07:56.240]   I was like, that's it.
[01:07:56.240 --> 01:07:58.300]   I don't take risks with my life any longer.
[01:07:58.300 --> 01:08:01.160]   But yeah, MacDougall, Matt MacDougall shot that video,
[01:08:01.160 --> 01:08:05.900]   and then it went "viral" through "Nature is Metal."
[01:08:05.900 --> 01:08:07.360]   We passed them that video.
[01:08:07.360 --> 01:08:11.960]   - Actually, I saw a video where an instructor
[01:08:11.960 --> 01:08:14.960]   was explaining how to behave with a shark in the water,
[01:08:14.960 --> 01:08:16.680]   and that you don't wanna be swimming away
[01:08:16.680 --> 01:08:18.200]   because then you're acting like a prey.
[01:08:18.200 --> 01:08:19.040]   - That's right.
[01:08:19.040 --> 01:08:20.620]   - And then you wanna be acting like a predator
[01:08:20.620 --> 01:08:22.440]   by looking at it and swimming towards it.
[01:08:22.440 --> 01:08:23.800]   - Right towards them, and they'll bank off.
[01:08:23.800 --> 01:08:26.080]   Now, if you don't see them, they're ambush predators.
[01:08:26.080 --> 01:08:27.120]   You know, you're swimming in the surface.
[01:08:27.120 --> 01:08:28.440]   - And apparently, if they get close,
[01:08:28.440 --> 01:08:29.960]   you should just guide them away
[01:08:29.960 --> 01:08:32.520]   by grabbing them and moving them away.
[01:08:32.520 --> 01:08:34.760]   - Some people will actually roll them,
[01:08:34.760 --> 01:08:36.080]   but if they're coming in full speedy,
[01:08:36.080 --> 01:08:37.520]   you're not gonna roll the shark.
[01:08:37.520 --> 01:08:40.180]   But here we are, back to dark stuff again.
[01:08:40.180 --> 01:08:41.800]   I like the shark attack map,
[01:08:41.800 --> 01:08:44.880]   and the shark attack map shows that, you know,
[01:08:44.880 --> 01:08:46.240]   Northern California, there were a couple.
[01:08:46.240 --> 01:08:48.800]   Actually, a guy's head got taken off.
[01:08:48.800 --> 01:08:50.960]   He was swimming north of San Francisco.
[01:08:50.960 --> 01:08:52.800]   There's been a couple in Northern California.
[01:08:52.800 --> 01:08:54.000]   That was really tragic,
[01:08:54.000 --> 01:08:56.680]   but most of them are in Florida and Australia.
[01:08:56.680 --> 01:08:57.520]   - Florida, same with the alligators, right?
[01:08:57.520 --> 01:09:00.080]   - So the Surfrider Foundation shark attack map,
[01:09:00.080 --> 01:09:02.420]   there it is, they have a great map.
[01:09:02.420 --> 01:09:03.260]   - There you go.
[01:09:03.260 --> 01:09:05.480]   - So they look like, they have all these scars on them.
[01:09:05.480 --> 01:09:09.120]   So if you zoom in on, I mean, look at this.
[01:09:09.120 --> 01:09:10.640]   If you go to North America.
[01:09:10.640 --> 01:09:13.680]   - Look at the skulls, there's a--
[01:09:13.680 --> 01:09:16.180]   - Yeah, where they're deadly attacks.
[01:09:16.180 --> 01:09:17.840]   But in, yeah, Northern California,
[01:09:17.840 --> 01:09:19.400]   sadly, this is really tragic.
[01:09:19.400 --> 01:09:23.680]   If you zoom in on this one, I read about this.
[01:09:23.680 --> 01:09:26.320]   This guy, if you can click the link,
[01:09:26.320 --> 01:09:28.920]   50-year-old male, he was in chest-high water.
[01:09:28.920 --> 01:09:30.040]   This is just tragic.
[01:09:30.040 --> 01:09:32.760]   I feel so sad for him and his family.
[01:09:32.760 --> 01:09:35.760]   You know, he's just, three members of the party
[01:09:35.760 --> 01:09:36.600]   chose to go in.
[01:09:36.600 --> 01:09:38.800]   He was, you know, nigh, nigh,
[01:09:38.800 --> 01:09:43.080]   was in his chest-high water, 25 to 50 yards from shore.
[01:09:43.080 --> 01:09:44.780]   Great, breached the water, seized his head,
[01:09:44.780 --> 01:09:45.760]   and that was it.
[01:09:45.760 --> 01:09:47.000]   You know, so it does happen.
[01:09:47.000 --> 01:09:48.200]   It's very infrequent.
[01:09:48.200 --> 01:09:51.280]   If you don't go in the ocean,
[01:09:51.280 --> 01:09:54.160]   there's a very, very, very low probability.
[01:09:54.160 --> 01:09:55.040]   But--
[01:09:55.040 --> 01:09:59.240]   - But if it doesn't happen six times in a row,
[01:09:59.240 --> 01:10:01.160]   that's 120% chance.
[01:10:01.160 --> 01:10:02.000]   - Yeah.
[01:10:02.000 --> 01:10:05.280]   - Are penguins a saltwater crocodile or a shark?
[01:10:05.280 --> 01:10:07.920]   - Okay, I do not like saltwater crocodiles.
[01:10:07.920 --> 01:10:09.480]   They scare me to no end.
[01:10:09.480 --> 01:10:11.320]   Muller, Michael Muller, who dove all over the world,
[01:10:11.320 --> 01:10:16.240]   he sent me a picture of him diving with salties,
[01:10:16.240 --> 01:10:18.120]   saltwater crocs in Cuba.
[01:10:18.120 --> 01:10:19.840]   It was a smaller one, but goodness gracious.
[01:10:19.840 --> 01:10:21.960]   Have you seen the size of some of those saltwater crocs?
[01:10:21.960 --> 01:10:22.880]   Yeah.
[01:10:22.880 --> 01:10:25.900]   I'm thinking the sharks are so agile.
[01:10:25.900 --> 01:10:27.080]   They're amazing.
[01:10:27.080 --> 01:10:30.160]   They've head-cammed one or body-cammed one
[01:10:30.160 --> 01:10:31.520]   moving through the kelp bed.
[01:10:32.360 --> 01:10:33.640]   And you look and it's just,
[01:10:33.640 --> 01:10:35.680]   they're so agile moving through the water.
[01:10:35.680 --> 01:10:37.640]   And it's looking up at the surface,
[01:10:37.640 --> 01:10:38.880]   like the camera's looking at the surface,
[01:10:38.880 --> 01:10:41.760]   and you just realize, if you're out there,
[01:10:41.760 --> 01:10:44.560]   you're not, and you're swimming,
[01:10:44.560 --> 01:10:46.280]   and you get hit by a shark, you're not--
[01:10:46.280 --> 01:10:48.560]   - I was gonna talk shit and say that a saltie
[01:10:48.560 --> 01:10:53.120]   has way more bite force, but according to the internet,
[01:10:53.120 --> 01:10:56.920]   recently data indicates that the shark has a stronger bite.
[01:10:56.920 --> 01:10:59.320]   So I was assuming that a crocodile
[01:10:59.320 --> 01:11:01.320]   would have a stronger bite force,
[01:11:01.320 --> 01:11:02.800]   and therefore agility doesn't matter,
[01:11:02.800 --> 01:11:04.680]   but apparently a shark.
[01:11:04.680 --> 01:11:06.880]   - Yeah, and turning one of those big salties
[01:11:06.880 --> 01:11:09.480]   is probably not that, you know, turning around,
[01:11:09.480 --> 01:11:10.400]   it's like a battleship.
[01:11:10.400 --> 01:11:11.520]   I mean, those sharks are unbelievable.
[01:11:11.520 --> 01:11:12.760]   They can hit from all sorts.
[01:11:12.760 --> 01:11:15.880]   Oh, and they do this thing, we saw this,
[01:11:15.880 --> 01:11:18.200]   you're out of the cage or in the cage,
[01:11:18.200 --> 01:11:20.040]   and you'll look at one, and you'll see its eye
[01:11:20.040 --> 01:11:21.760]   kind of like looking at you.
[01:11:21.760 --> 01:11:23.560]   They can't really fovee it, but they'll look at you.
[01:11:23.560 --> 01:11:26.480]   And you're tracking it, and then you'll look down,
[01:11:26.480 --> 01:11:28.000]   and you'll realize that one's coming at you.
[01:11:28.000 --> 01:11:30.920]   They're ambush preys, they're working together.
[01:11:30.920 --> 01:11:32.440]   It's fascinating.
[01:11:32.440 --> 01:11:36.160]   - I like how you know that they can't fovee it.
[01:11:36.160 --> 01:11:38.060]   You're already considering the vision system there.
[01:11:38.060 --> 01:11:39.520]   It's a very primitive vision system.
[01:11:39.520 --> 01:11:41.360]   - Very primitive, eyes on the side of the head.
[01:11:41.360 --> 01:11:42.640]   Vision is decent enough.
[01:11:42.640 --> 01:11:44.640]   They're mostly, obviously, sensing things
[01:11:44.640 --> 01:11:47.600]   with their electro-sensing in the water,
[01:11:47.600 --> 01:11:50.040]   but also olfaction.
[01:11:50.040 --> 01:11:53.680]   Yeah, I spend far too much time thinking about
[01:11:53.680 --> 01:11:56.040]   and learning about the visual systems of different animals.
[01:11:56.040 --> 01:11:58.280]   If you get me going on this, we'll be here all night.
[01:11:58.280 --> 01:12:00.160]   - See, this is why I have the smuggled out tooth.
[01:12:00.160 --> 01:12:02.040]   I saw this in a store, and I got it.
[01:12:02.040 --> 01:12:05.200]   'Cause this is from a shark.
[01:12:05.200 --> 01:12:06.040]   - Goodness.
[01:12:06.040 --> 01:12:08.200]   Yeah, I can't say I ever saw one with teeth this big,
[01:12:08.200 --> 01:12:09.640]   but it's beautiful. - Imagine that.
[01:12:09.640 --> 01:12:11.080]   - It's beautiful.
[01:12:11.080 --> 01:12:13.320]   Yeah, it's probably, you know,
[01:12:13.320 --> 01:12:14.680]   probably your blood pressure just goes,
[01:12:14.680 --> 01:12:16.280]   and you don't feel a thing.
[01:12:16.280 --> 01:12:17.840]   - Yeah, it's not good.
[01:12:17.840 --> 01:12:20.400]   - Before we went down for the cage exit,
[01:12:20.400 --> 01:12:22.920]   a guy in our crew, Pat Dossett,
[01:12:22.920 --> 01:12:26.540]   who's a very experienced diver,
[01:12:26.540 --> 01:12:29.400]   asked one of the South African divers,
[01:12:29.400 --> 01:12:33.080]   so what's the contingency plan if somebody catches a bite?
[01:12:33.080 --> 01:12:35.840]   And they were like, he was like every man for himself,
[01:12:35.840 --> 01:12:37.240]   and they're like, basically saying,
[01:12:37.240 --> 01:12:39.800]   if somebody catches a bite, that's it, you know?
[01:12:39.800 --> 01:12:43.440]   Anyway, I thought we were gonna bring up something happy.
[01:12:43.440 --> 01:12:45.020]   - Oh, that is happy.
[01:12:45.020 --> 01:12:46.480]   - Well, we lived. - Nature is beautiful.
[01:12:46.480 --> 01:12:48.040]   - Yeah, nature is beautiful.
[01:12:48.040 --> 01:12:52.280]   We lived, but you know, there are happy things.
[01:12:52.280 --> 01:12:53.720]   You brought up nature as metal.
[01:12:53.720 --> 01:12:54.640]   See, this is the difference
[01:12:54.640 --> 01:12:58.400]   between Russian Americans and Americans.
[01:12:58.400 --> 01:13:00.200]   It's like, maybe this is actually a good time
[01:13:00.200 --> 01:13:02.520]   to bring up your ayahuasca journey.
[01:13:02.520 --> 01:13:06.480]   I've never done ayahuasca, but I'm curious about it.
[01:13:06.480 --> 01:13:09.360]   I'm also curious about ibogaine, iboga,
[01:13:09.360 --> 01:13:14.280]   but you told me that you did ayahuasca,
[01:13:14.280 --> 01:13:17.600]   and that for you, it wasn't the dark, scary ride
[01:13:17.600 --> 01:13:19.080]   that it is for everybody else.
[01:13:19.080 --> 01:13:20.760]   - Yeah, it was an incredible experience for me.
[01:13:20.760 --> 01:13:22.080]   I did it twice, actually.
[01:13:22.080 --> 01:13:24.600]   - And have you done high-dose psilocybin?
[01:13:24.600 --> 01:13:25.440]   - Never, no.
[01:13:25.440 --> 01:13:28.880]   I just did small-dose psilocybin a couple times.
[01:13:28.880 --> 01:13:30.640]   So, I was nervous about it.
[01:13:30.640 --> 01:13:32.360]   I was very scared. - Yeah, understandably so.
[01:13:32.360 --> 01:13:33.600]   I've done high-dose psilocybin.
[01:13:33.600 --> 01:13:35.680]   It's terrifying, but I've always gotten
[01:13:35.680 --> 01:13:37.360]   something very useful out of it.
[01:13:37.360 --> 01:13:40.560]   - So, I mean, I was nervous about whatever demons
[01:13:40.560 --> 01:13:43.600]   might hide in the shadow, in the Jungian shadow.
[01:13:43.600 --> 01:13:47.160]   Like, I was nervous, but I think it turns out,
[01:13:47.160 --> 01:13:49.280]   I don't know what the lesson is to draw from that,
[01:13:49.280 --> 01:13:52.200]   but my experience-- - Be born Russian.
[01:13:52.200 --> 01:13:54.040]   - It must be the Russian thing.
[01:13:54.040 --> 01:13:57.020]   I mean, there's also something to the jungle.
[01:13:57.020 --> 01:13:59.760]   It strips away all the bullshit of life,
[01:13:59.760 --> 01:14:01.200]   and you're just there.
[01:14:01.200 --> 01:14:04.540]   I forgot the outside civilization exists.
[01:14:04.540 --> 01:14:08.800]   I forgot time, because when you don't have your phone,
[01:14:08.800 --> 01:14:10.960]   you don't have meetings or calls or whatever,
[01:14:10.960 --> 01:14:12.400]   you lose a sense of time.
[01:14:12.400 --> 01:14:14.480]   The sun comes up, the sun comes down.
[01:14:14.480 --> 01:14:17.560]   - That's the fundamental biological timer.
[01:14:17.560 --> 01:14:21.640]   You know, every mammalian species has a short wavelength.
[01:14:21.640 --> 01:14:25.520]   So you think like blue UV type, but like absorbing cone,
[01:14:25.520 --> 01:14:27.440]   and a longer wavelength absorbing cone,
[01:14:27.440 --> 01:14:30.120]   and it does this interesting subtraction
[01:14:30.120 --> 01:14:31.920]   to designate when it's morning and evening,
[01:14:31.920 --> 01:14:33.320]   because when the sun is low in the sky,
[01:14:33.320 --> 01:14:36.000]   you've got short wavelength and long wavelength light.
[01:14:36.000 --> 01:14:37.200]   Like when you look at a sunrise,
[01:14:37.200 --> 01:14:38.760]   it's got blues and yellows, orange and yellows.
[01:14:38.760 --> 01:14:41.560]   You look in the evening, reds, orange, and blues,
[01:14:41.560 --> 01:14:44.160]   and in the middle of the day, it's like full-spectrum light.
[01:14:44.160 --> 01:14:45.320]   Now, it's always full-spectrum light,
[01:14:45.320 --> 01:14:49.340]   but because of some atmospheric elements,
[01:14:49.340 --> 01:14:51.700]   and because of the low solar angle,
[01:14:51.700 --> 01:14:54.960]   that difference between the different wavelengths of light
[01:14:54.960 --> 01:14:57.680]   is the fundamental signal that the neurons in your eye
[01:14:57.680 --> 01:14:59.160]   pay attention to and signal
[01:14:59.160 --> 01:15:01.320]   to your circadian timekeeping mechanism.
[01:15:01.320 --> 01:15:03.720]   At the core of our brain, in the suprachiasmatic nucleus,
[01:15:03.720 --> 01:15:08.720]   we are wired to be entrained
[01:15:08.720 --> 01:15:11.080]   to the rising and setting of the sun.
[01:15:11.080 --> 01:15:13.360]   That's the biological timer, which makes perfect sense,
[01:15:13.360 --> 01:15:18.360]   because obviously, as the planets spin and revolve.
[01:15:18.400 --> 01:15:20.580]   - I also wonder how that is affected by,
[01:15:20.580 --> 01:15:24.060]   you know, in the rainforest, the sun is not visible often,
[01:15:24.060 --> 01:15:27.100]   so you're under the cover of the trees.
[01:15:27.100 --> 01:15:28.700]   So maybe that affects--
[01:15:28.700 --> 01:15:30.300]   - Well, there are social rhythms.
[01:15:30.300 --> 01:15:31.620]   There are feeding rhythms.
[01:15:31.620 --> 01:15:34.100]   Sometimes, in terms of some species,
[01:15:34.100 --> 01:15:37.020]   will signal the timing of activity of other species.
[01:15:37.020 --> 01:15:41.900]   But yeah, getting out from the canopy is critical.
[01:15:41.900 --> 01:15:44.060]   Of course, even under the canopy during the daytime,
[01:15:44.060 --> 01:15:46.980]   there's far more photons than at night.
[01:15:46.980 --> 01:15:48.480]   You know, this is always when I'm telling people
[01:15:48.480 --> 01:15:50.260]   to get sunlight in their eyes in the morning
[01:15:50.260 --> 01:15:51.200]   and in the evening.
[01:15:51.200 --> 01:15:53.760]   People say, "There's no light, no sunlight this time of year."
[01:15:53.760 --> 01:15:55.480]   Go outside on a really overcast day.
[01:15:55.480 --> 01:15:57.760]   It's far brighter than it is at night, right?
[01:15:57.760 --> 01:15:59.860]   So there's still lots of sunlight,
[01:15:59.860 --> 01:16:01.260]   even if you can't see the sun as an object.
[01:16:01.260 --> 01:16:06.260]   But I love time perception shifts.
[01:16:06.260 --> 01:16:08.260]   And you mentioned that in the jungle,
[01:16:08.260 --> 01:16:10.280]   it's linked to the rising and setting of the sun.
[01:16:10.280 --> 01:16:12.160]   You also mentioned that on Ayahuasca,
[01:16:12.160 --> 01:16:13.960]   you zoomed out from the earth.
[01:16:13.960 --> 01:16:16.280]   These are like, to me, the most interesting aspects
[01:16:16.280 --> 01:16:18.920]   of having a human brain, as opposed to another brain.
[01:16:18.920 --> 01:16:20.720]   Of course, I've only ever had a human brain.
[01:16:20.720 --> 01:16:24.100]   But, which is that you can consciously
[01:16:24.100 --> 01:16:27.920]   set your time domain window.
[01:16:27.920 --> 01:16:29.560]   Like, we can be focused here,
[01:16:29.560 --> 01:16:30.960]   we can be focused on all of Austin,
[01:16:30.960 --> 01:16:32.960]   or we can be focused on the entire planet.
[01:16:32.960 --> 01:16:35.520]   You can make those choices consciously.
[01:16:35.520 --> 01:16:37.280]   But in the time domain, it's hard.
[01:16:37.280 --> 01:16:39.600]   Like, different activities bring us into fine slicing
[01:16:39.600 --> 01:16:41.860]   or more broad bending of time,
[01:16:41.860 --> 01:16:43.600]   depending on what we're doing.
[01:16:43.600 --> 01:16:47.280]   Programming, or exercising, or researching, or podcasting.
[01:16:47.280 --> 01:16:52.160]   But just how unbelievably fluid the human brain is
[01:16:52.160 --> 01:16:56.560]   in terms of the aperture of the time-space window
[01:16:56.560 --> 01:16:59.320]   of our cognition and of our experience.
[01:16:59.320 --> 01:17:01.160]   And I feel like this is perhaps
[01:17:01.160 --> 01:17:04.060]   one of the more valuable tools that we have access to
[01:17:04.060 --> 01:17:06.480]   that we don't really leverage as much as we should,
[01:17:06.480 --> 01:17:09.280]   which is when things are really hard,
[01:17:09.280 --> 01:17:12.880]   you need to zoom out and see it as one element
[01:17:12.880 --> 01:17:15.780]   within your whole lifespan, and that there's more to come.
[01:17:15.780 --> 01:17:19.400]   You know, I mean, people commit suicide
[01:17:19.400 --> 01:17:21.760]   because they can't see beyond the time domain they're in,
[01:17:21.760 --> 01:17:24.520]   or they think it's gonna go on forever.
[01:17:24.520 --> 01:17:26.400]   When we're happy, we rarely think
[01:17:26.400 --> 01:17:27.920]   this is gonna last forever.
[01:17:27.920 --> 01:17:31.160]   But, which is an interesting contrast in its own right.
[01:17:31.160 --> 01:17:35.020]   But, I think that psychedelics,
[01:17:35.020 --> 01:17:36.840]   while I have very little experience with them,
[01:17:36.840 --> 01:17:38.480]   I have some, and it sounds like
[01:17:38.480 --> 01:17:40.880]   they're just a very interesting window
[01:17:40.880 --> 01:17:43.600]   into the different apertures.
[01:17:43.600 --> 01:17:46.420]   - Well, how to surf that wave is probably a skill.
[01:17:46.420 --> 01:17:49.600]   One of the things I was prepared for,
[01:17:49.600 --> 01:17:52.220]   and I think it's important, is not to resist.
[01:17:52.220 --> 01:17:56.080]   I think, I understand what it means to resist a thing,
[01:17:56.080 --> 01:17:58.080]   a powerful wave, and it's not going to be good,
[01:17:58.080 --> 01:17:59.240]   so you have to be able to surf it.
[01:17:59.240 --> 01:18:00.960]   So, I was ready for that, to relax through it.
[01:18:00.960 --> 01:18:04.560]   And maybe because I'm quite good at that,
[01:18:04.560 --> 01:18:09.560]   from knowing how to relax in all kinds of disciplines,
[01:18:10.360 --> 01:18:13.600]   playing piano and guitar when I was super young,
[01:18:13.600 --> 01:18:16.280]   and then through jiu-jitsu, knowing the value of relaxation,
[01:18:16.280 --> 01:18:17.960]   and through all kinds of sports,
[01:18:17.960 --> 01:18:19.760]   to be able to relax the body fully,
[01:18:19.760 --> 01:18:21.600]   just accept whatever happens to you.
[01:18:21.600 --> 01:18:23.120]   That process is probably why
[01:18:23.120 --> 01:18:25.520]   it was a very positive experience for me.
[01:18:25.520 --> 01:18:27.160]   - Do you have any interest in Iboga?
[01:18:27.160 --> 01:18:29.640]   I'm very interested in Ibogaine, Iboga.
[01:18:29.640 --> 01:18:31.360]   There's a colleague of mine and researcher
[01:18:31.360 --> 01:18:32.520]   at Stanford, Nolan Williams,
[01:18:32.520 --> 01:18:34.920]   who's been doing some transcranial magnetic stimulation
[01:18:34.920 --> 01:18:38.520]   and brain imaging on people who have taken Ibogaine.
[01:18:38.520 --> 01:18:41.800]   - Ibogaine, as I understand it,
[01:18:41.800 --> 01:18:44.640]   gives a 22-hour psychedelic journey
[01:18:44.640 --> 01:18:46.680]   where no hallucinations with eyes open,
[01:18:46.680 --> 01:18:50.360]   but you close your eyes and you get a very high-resolution
[01:18:50.360 --> 01:18:52.680]   image of actual events that happened in your life,
[01:18:52.680 --> 01:18:55.160]   but then you have agency within those movies.
[01:18:55.160 --> 01:18:58.220]   I think you have to be of healthy heart to be able to do it.
[01:18:58.220 --> 01:18:59.560]   I think you have to be on a heart rate monitor.
[01:18:59.560 --> 01:19:03.040]   It's not trivial, it's not like these other psychedelics.
[01:19:03.040 --> 01:19:07.360]   But there's a wonderful group called Veteran Solutions,
[01:19:08.360 --> 01:19:13.360]   that has used Iboga combined with some other psychedelics
[01:19:13.360 --> 01:19:17.620]   in the veterans community to great success
[01:19:17.620 --> 01:19:19.640]   for things like PTSD.
[01:19:19.640 --> 01:19:22.480]   And it's a group I've really tried to support
[01:19:22.480 --> 01:19:23.980]   in any way that I can,
[01:19:23.980 --> 01:19:26.540]   mainly by being vocal about the great work they're doing.
[01:19:26.540 --> 01:19:29.880]   But you hear incredible stories of people
[01:19:29.880 --> 01:19:33.080]   who are just like near cratered in their life
[01:19:33.080 --> 01:19:37.380]   or zombied by PTSD and other things post-war,
[01:19:37.380 --> 01:19:41.640]   get back a lightness or achieve a lightness and a clarity
[01:19:41.640 --> 01:19:43.640]   that they didn't feel they had.
[01:19:43.640 --> 01:19:46.440]   So I'm very curious about these compounds.
[01:19:46.440 --> 01:19:48.060]   The state of Kentucky, we should check this,
[01:19:48.060 --> 01:19:50.320]   but I believe it's taken money
[01:19:50.320 --> 01:19:55.240]   from the opioid crisis settlement for Ibogaine research.
[01:19:55.240 --> 01:19:58.080]   So this is like no longer, yeah, so if you look here,
[01:19:58.080 --> 01:20:00.480]   let's see, did they do it?
[01:20:00.480 --> 01:20:01.320]   Oh, no. - No.
[01:20:01.320 --> 01:20:03.240]   - Oh, no, they backed away.
[01:20:03.240 --> 01:20:04.640]   - Kentucky backs away from the plan
[01:20:04.640 --> 01:20:06.440]   to fund opioid treatment research.
[01:20:06.440 --> 01:20:09.140]   - They were going to use the money to treat opioid.
[01:20:09.140 --> 01:20:10.440]   Now officials are backing off.
[01:20:10.440 --> 01:20:14.080]   50 billion, what, is on its way over the coming years.
[01:20:14.080 --> 01:20:15.600]   $50 billion.
[01:20:15.600 --> 01:20:18.320]   - $50 billion is on its way to state and local government
[01:20:18.320 --> 01:20:19.320]   over the coming years.
[01:20:19.320 --> 01:20:21.600]   The pool of funding comes from multiple legal statements
[01:20:21.600 --> 01:20:23.680]   with pharmaceutical companies that profited
[01:20:23.680 --> 01:20:27.200]   from manufacturing or selling opioid painkillers.
[01:20:27.200 --> 01:20:29.400]   - Kentucky has some of the highest number of deaths
[01:20:29.400 --> 01:20:30.240]   from the opioid.
[01:20:30.240 --> 01:20:34.000]   We're going to do psychedelic research with Ibogaine,
[01:20:34.000 --> 01:20:38.560]   supporting research on illegal, illegal folks,
[01:20:38.560 --> 01:20:39.780]   psychedelic drug called Ibogaine.
[01:20:39.780 --> 01:20:41.020]   Well, I guess they backed away from it.
[01:20:41.020 --> 01:20:44.720]   Well, sooner or later we'll get some happy news
[01:20:44.720 --> 01:20:47.920]   up on the internet during this episode.
[01:20:47.920 --> 01:20:49.720]   - I don't know what you're talking about,
[01:20:49.720 --> 01:20:51.280]   the shark and the crocodile fighting.
[01:20:51.280 --> 01:20:52.840]   - Yeah, yeah, that's true, that's true.
[01:20:52.840 --> 01:20:54.440]   And you survived the jungle.
[01:20:54.440 --> 01:20:56.160]   - Well, that's the thing.
[01:20:56.160 --> 01:20:59.000]   - I was writing to you on WhatsApp multiple times
[01:20:59.000 --> 01:21:00.120]   'cause I was gonna put it on the internet.
[01:21:00.120 --> 01:21:00.960]   Are you okay?
[01:21:00.960 --> 01:21:01.800]   And if you're like alive,
[01:21:01.800 --> 01:21:03.720]   and then I was going to just like put it to Twitter,
[01:21:03.720 --> 01:21:05.120]   just like, he's alive.
[01:21:05.120 --> 01:21:07.040]   But then of course you're far too classy for that.
[01:21:07.040 --> 01:21:08.880]   So you just came back alive.
[01:21:08.880 --> 01:21:15.120]   - Well, jungle or not, one of the lessons is also,
[01:21:15.120 --> 01:21:17.360]   when you hear the call for adventure,
[01:21:17.360 --> 01:21:21.040]   just fucking do it.
[01:21:21.040 --> 01:21:22.760]   - I was going to ask you, it's kind of a silly question,
[01:21:22.760 --> 01:21:26.120]   but like, give me a small fraction of things
[01:21:26.120 --> 01:21:27.080]   on your bucket list.
[01:21:27.080 --> 01:21:29.040]   - Bucket list?
[01:21:29.280 --> 01:21:30.120]   - Yeah.
[01:21:30.120 --> 01:21:32.240]   - Go to Mars.
[01:21:32.240 --> 01:21:35.120]   - Yeah, what's the status of that?
[01:21:35.120 --> 01:21:37.920]   - I don't know, I'm being patient about the whole thing.
[01:21:37.920 --> 01:21:41.720]   - Red Planet ran that cartoon of you guys going to Mars.
[01:21:41.720 --> 01:21:42.560]   That was pretty funny.
[01:21:42.560 --> 01:21:43.440]   - That's true.
[01:21:43.440 --> 01:21:44.600]   - That was pretty funny.
[01:21:44.600 --> 01:21:46.120]   One where Goggins is already up there.
[01:21:46.120 --> 01:21:46.960]   - Yeah.
[01:21:46.960 --> 01:21:48.840]   - That's a great, that's a funny one.
[01:21:48.840 --> 01:21:50.240]   - Probably also true.
[01:21:50.240 --> 01:21:53.080]   I would love to die on Mars.
[01:21:53.080 --> 01:21:58.680]   But I just love humanity reaching onto the stars
[01:21:58.680 --> 01:22:01.320]   and doing this bold adventure
[01:22:01.320 --> 01:22:03.200]   and taking big risks and exploring.
[01:22:03.200 --> 01:22:04.920]   I love exploration.
[01:22:04.920 --> 01:22:06.560]   - What about seeing different animal species?
[01:22:06.560 --> 01:22:09.480]   I'm a huge fan of this guy, Joel Sartori,
[01:22:09.480 --> 01:22:12.480]   where he has this photo arc project
[01:22:12.480 --> 01:22:15.520]   where he takes portraits of all these different animals.
[01:22:15.520 --> 01:22:17.320]   If people aren't already following him on Instagram,
[01:22:17.320 --> 01:22:19.240]   he's doing some really important work.
[01:22:19.240 --> 01:22:25.760]   This guy's Instagram is amazing.
[01:22:25.760 --> 01:22:26.600]   - Like portraits of animals.
[01:22:26.600 --> 01:22:28.280]   - Well, look at it, look at these portraits.
[01:22:28.280 --> 01:22:31.160]   The amount of, I won't say personality,
[01:22:31.160 --> 01:22:32.800]   'cause we don't want to project anything onto them,
[01:22:32.800 --> 01:22:36.120]   but the amount, like the eyes.
[01:22:36.120 --> 01:22:37.760]   And he'll occasionally put a movie.
[01:22:37.760 --> 01:22:39.560]   Look at that, there's a little owl.
[01:22:39.560 --> 01:22:41.320]   I delight in things like this.
[01:22:41.320 --> 01:22:43.800]   I've got some content coming on animals
[01:22:43.800 --> 01:22:46.920]   and animal neuroscience and eyes.
[01:22:46.920 --> 01:22:48.320]   - Dogs or all kinds?
[01:22:48.320 --> 01:22:49.200]   - All animals.
[01:22:49.200 --> 01:22:55.040]   And I'm very interested in kids content
[01:22:55.040 --> 01:22:57.080]   that incorporates animals.
[01:22:57.080 --> 01:22:58.240]   So we have some things brewing there.
[01:22:58.240 --> 01:23:00.400]   Like I could look at this kind of stuff all day long.
[01:23:00.400 --> 01:23:01.440]   Look at that bat.
[01:23:01.440 --> 01:23:02.720]   Like bats, people think about bats
[01:23:02.720 --> 01:23:03.840]   as kind of like a little flickering,
[01:23:03.840 --> 01:23:05.440]   a little annoying, disease-carrying things,
[01:23:05.440 --> 01:23:07.400]   but look how beautiful that little sucker is.
[01:23:07.400 --> 01:23:10.760]   - How's your podcast with the Cookie Monster coming?
[01:23:10.760 --> 01:23:13.260]   - Oh yeah, we've been in discussions with Cookie.
[01:23:13.260 --> 01:23:17.120]   Can't say too much about that,
[01:23:17.120 --> 01:23:20.880]   but Cookie Monster embodies dopamine, right?
[01:23:20.880 --> 01:23:22.720]   Cookie Monster wants cookie, right?
[01:23:22.720 --> 01:23:23.640]   Wants cookie right now.
[01:23:23.640 --> 01:23:25.520]   You know, like it was that one tweet,
[01:23:25.520 --> 01:23:27.280]   Cookie Monster, I bounce because cookies
[01:23:27.280 --> 01:23:28.680]   come from all directions.
[01:23:28.680 --> 01:23:31.560]   You know, it's like, it's just embodying the desire
[01:23:31.560 --> 01:23:35.240]   for something, which is an incredible aspect of ourselves.
[01:23:35.240 --> 01:23:38.280]   The other one is, you remember a little while ago,
[01:23:38.280 --> 01:23:40.440]   Elmo put out a tweet.
[01:23:40.440 --> 01:23:42.480]   Hey, how's everyone doing out there?
[01:23:42.480 --> 01:23:43.960]   And it went viral.
[01:23:43.960 --> 01:23:46.160]   And you know, the Surgeon General of the United States
[01:23:46.160 --> 01:23:47.880]   had been talking about the loneliness crisis.
[01:23:47.880 --> 01:23:49.000]   He came on the podcast.
[01:23:49.000 --> 01:23:50.920]   And a lot of people have been talking about
[01:23:50.920 --> 01:23:51.840]   problems with loneliness,
[01:23:51.840 --> 01:23:53.640]   mental health issues with loneliness.
[01:23:53.640 --> 01:23:55.200]   Elmo puts out a tweet.
[01:23:55.200 --> 01:23:57.040]   Hey, how's everyone doing out there?
[01:23:57.040 --> 01:23:59.680]   And everyone gravitates toward it.
[01:23:59.680 --> 01:24:02.120]   You know, so the different Sesame Street characters
[01:24:02.120 --> 01:24:05.120]   really embody the different kind of aspects of self
[01:24:05.120 --> 01:24:08.100]   through very like narrow neural circuit perspective.
[01:24:08.100 --> 01:24:10.680]   You know, Snuffleupagus is shy,
[01:24:10.680 --> 01:24:13.240]   and Oscar the Grouch is grouchy, right?
[01:24:13.240 --> 01:24:15.680]   And the Count, one, two.
[01:24:15.680 --> 01:24:17.080]   - The archetypes of, yeah.
[01:24:17.080 --> 01:24:17.920]   - The archetypes.
[01:24:17.920 --> 01:24:19.040]   - This is very Jungian, once again.
[01:24:19.040 --> 01:24:21.440]   - Yeah, and I think that, you know,
[01:24:21.440 --> 01:24:23.320]   the creators of Sesame Street clearly
[01:24:23.320 --> 01:24:24.160]   either understand that
[01:24:24.160 --> 01:24:25.840]   or it's an unconscious genius to that.
[01:24:25.840 --> 01:24:28.560]   So yeah, there are some things brewing
[01:24:28.560 --> 01:24:31.640]   on conversations with Sesame Street characters.
[01:24:31.640 --> 01:24:33.880]   It's not, I know you'd like to talk to Vladimir Putin.
[01:24:33.880 --> 01:24:36.120]   I'd like to talk to Cookie Monster.
[01:24:36.120 --> 01:24:38.480]   It illustrates the differences in our like,
[01:24:38.480 --> 01:24:40.600]   the sophistication or something.
[01:24:40.600 --> 01:24:41.440]   - Well, that's, yeah.
[01:24:41.440 --> 01:24:42.400]   - It illustrates a lot.
[01:24:42.400 --> 01:24:44.800]   Yeah, illustrates a lot.
[01:24:44.800 --> 01:24:46.800]   But yeah, I also, I love animation.
[01:24:46.800 --> 01:24:48.560]   So I'm not anime.
[01:24:48.560 --> 01:24:49.960]   That's not my thing, but animation.
[01:24:49.960 --> 01:24:52.120]   So I'm very interested in the use of animation
[01:24:52.120 --> 01:24:54.600]   to get science content across.
[01:24:54.600 --> 01:24:56.320]   So there are a bunch of things brewing.
[01:24:56.320 --> 01:24:59.800]   But anyway, I delight in Sartori's work
[01:24:59.800 --> 01:25:03.320]   and there's a conservation aspect to it as well.
[01:25:03.320 --> 01:25:05.760]   But I think that, mostly I want to thank you
[01:25:05.760 --> 01:25:07.160]   for finally putting up something that like,
[01:25:07.160 --> 01:25:08.480]   where something's not being killed
[01:25:08.480 --> 01:25:11.560]   or like some sad, sad outcome.
[01:25:11.560 --> 01:25:12.800]   - These are all really positive.
[01:25:12.800 --> 01:25:13.880]   - They're really cool.
[01:25:13.880 --> 01:25:14.720]   They're really cool.
[01:25:14.720 --> 01:25:17.220]   And every once in a while, look at that mountain lion.
[01:25:17.220 --> 01:25:20.320]   But I also like to look at these
[01:25:20.320 --> 01:25:23.760]   and some of them remind me of certain people, right?
[01:25:23.760 --> 01:25:25.000]   So let's just scroll through.
[01:25:25.000 --> 01:25:26.560]   Like for instance, I think when we don't try
[01:25:26.560 --> 01:25:27.520]   and process it too much.
[01:25:27.520 --> 01:25:31.600]   So like, okay, look at this cat, this civic cat.
[01:25:31.600 --> 01:25:32.440]   Amazing.
[01:25:32.440 --> 01:25:33.320]   Like, I feel like that's somebody,
[01:25:33.320 --> 01:25:36.760]   I feel like this is like someone I met once.
[01:25:36.760 --> 01:25:37.600]   As a young kid.
[01:25:37.600 --> 01:25:38.420]   - Curiosity.
[01:25:38.420 --> 01:25:40.560]   - Curiosity and a playfulness.
[01:25:40.560 --> 01:25:41.800]   - Carnivore.
[01:25:41.800 --> 01:25:43.640]   - Carnivore, frontalized eyes.
[01:25:43.640 --> 01:25:45.640]   - Found in forested areas.
[01:25:45.640 --> 01:25:46.480]   - Right.
[01:25:46.480 --> 01:25:49.360]   So then you go down, it's like,
[01:25:49.360 --> 01:25:50.880]   this beautiful fish.
[01:25:50.880 --> 01:25:52.060]   - Neon pink.
[01:25:52.060 --> 01:25:52.900]   - Right.
[01:25:52.900 --> 01:25:53.880]   So it reminds you of some of the,
[01:25:53.880 --> 01:25:56.320]   like the influencers you see on Instagram, right?
[01:25:56.320 --> 01:25:57.660]   Except this one's natural.
[01:25:57.660 --> 01:25:58.500]   Just kidding.
[01:25:58.500 --> 01:26:01.960]   Let's see, no filter.
[01:26:01.960 --> 01:26:02.800]   - No filter.
[01:26:02.800 --> 01:26:03.640]   - Yeah.
[01:26:03.640 --> 01:26:06.880]   Let's see, like, I feel like.
[01:26:06.880 --> 01:26:08.360]   - Bears, I'm a big fan of bears.
[01:26:08.360 --> 01:26:09.200]   - Yeah, bears are beautiful.
[01:26:09.200 --> 01:26:10.700]   This one kind of reminds me of you a little bit.
[01:26:10.700 --> 01:26:13.720]   There's like a stoic nature to it, a curiosity.
[01:26:13.720 --> 01:26:16.020]   So you can kind of feel like the essence of animals.
[01:26:16.020 --> 01:26:18.680]   You don't even have to do psychedelics to get there.
[01:26:18.680 --> 01:26:19.520]   - Oh, look at that.
[01:26:19.520 --> 01:26:21.360]   He's like the behind the scenes of how it's actually.
[01:26:21.360 --> 01:26:22.560]   - Yeah.
[01:26:22.560 --> 01:26:23.400]   And then there's.
[01:26:23.400 --> 01:26:26.200]   - Wow.
[01:26:26.200 --> 01:26:27.320]   - Yeah.
[01:26:27.320 --> 01:26:31.480]   Yeah, in the jungle, the diversity of life was also stark.
[01:26:31.480 --> 01:26:32.720]   From a scientific perspective,
[01:26:32.720 --> 01:26:36.000]   just the fact that most of those species are not identified
[01:26:36.000 --> 01:26:36.840]   was fascinating.
[01:26:36.840 --> 01:26:37.680]   - Right.
[01:26:37.680 --> 01:26:38.600]   - It was like a little,
[01:26:38.600 --> 01:26:42.240]   every little insect is a kind of discovery.
[01:26:42.240 --> 01:26:43.080]   - Right.
[01:26:43.080 --> 01:26:45.000]   I mean, one of the reasons I love New York City so much,
[01:26:45.000 --> 01:26:47.080]   despite its problems at times,
[01:26:47.080 --> 01:26:50.120]   is that everywhere you look, there's life.
[01:26:50.120 --> 01:26:51.200]   It's like a tropical reef.
[01:26:51.200 --> 01:26:53.480]   If you've ever done scuba diving or snorkeling,
[01:26:53.480 --> 01:26:55.320]   you look on a tropical reef and it's like,
[01:26:55.320 --> 01:26:56.880]   there's some little crab working on something.
[01:26:56.880 --> 01:26:58.720]   And like everywhere you look, there's life.
[01:26:58.720 --> 01:26:59.560]   You know, in the Bay Area,
[01:26:59.560 --> 01:27:01.160]   if you go scuba diving or snorkeling,
[01:27:01.160 --> 01:27:02.000]   it's like a kelp bed.
[01:27:02.000 --> 01:27:03.280]   You know, the Bay Area is like a kelp bed.
[01:27:03.280 --> 01:27:05.040]   Every once in a while, some big fish goes by.
[01:27:05.040 --> 01:27:06.920]   It's like a big IPO.
[01:27:06.920 --> 01:27:09.500]   But like most of the time, not a whole lot happens.
[01:27:09.500 --> 01:27:10.920]   Actually, the Bay Area, it's interesting,
[01:27:10.920 --> 01:27:13.560]   as I've been going back there more and more recently,
[01:27:14.480 --> 01:27:17.880]   there are really cool little subcultures
[01:27:17.880 --> 01:27:19.440]   starting to pop up again.
[01:27:19.440 --> 01:27:20.280]   - Nice.
[01:27:20.280 --> 01:27:22.440]   - There's incredible skateboarding.
[01:27:22.440 --> 01:27:26.000]   The GX1000 guys are these guys that bomb down hills.
[01:27:26.000 --> 01:27:27.320]   They're nuts.
[01:27:27.320 --> 01:27:29.400]   Like they're just going like--
[01:27:29.400 --> 01:27:31.000]   - So it's just speed, not tricks.
[01:27:31.000 --> 01:27:32.240]   - You gotta see GX1000.
[01:27:32.240 --> 01:27:34.600]   These guys going down hills in San Francisco.
[01:27:34.600 --> 01:27:36.260]   They are wild.
[01:27:36.260 --> 01:27:38.360]   And unfortunately, occasionally someone will get hit
[01:27:38.360 --> 01:27:42.260]   by a car, but GX1000, look, into intersections.
[01:27:42.260 --> 01:27:43.100]   They have spotters.
[01:27:43.100 --> 01:27:44.400]   You can see someone there.
[01:27:44.400 --> 01:27:46.920]   - Oh, I see.
[01:27:46.920 --> 01:27:48.640]   There's somebody looking out. - Into traffic.
[01:27:48.640 --> 01:27:50.080]   Yeah, into traffic.
[01:27:50.080 --> 01:27:50.900]   - In San Francisco.
[01:27:50.900 --> 01:27:51.740]   - Yeah, this is crazy.
[01:27:51.740 --> 01:27:53.000]   Like this is unbelievable.
[01:27:53.000 --> 01:27:57.680]   And they're just wild.
[01:27:57.680 --> 01:27:59.500]   But in any case.
[01:27:59.500 --> 01:28:01.640]   - What's on your bucket list that you haven't done?
[01:28:01.640 --> 01:28:02.720]   - Well, I'm working on a book.
[01:28:02.720 --> 01:28:06.160]   So I'm actually going to head to a cabin
[01:28:06.160 --> 01:28:09.200]   for a couple of weeks and write, which I've never done.
[01:28:09.200 --> 01:28:12.100]   People talk about doing this, but I'm gonna do that.
[01:28:12.100 --> 01:28:13.040]   I'm excited for that.
[01:28:13.040 --> 01:28:15.400]   Just the mental space of really dropping into writing.
[01:28:15.400 --> 01:28:17.480]   - Like Jack Nicholson in "The Shining" cabin?
[01:28:17.480 --> 01:28:18.600]   - Let's hope not.
[01:28:18.600 --> 01:28:19.440]   Let's hope not.
[01:28:19.440 --> 01:28:21.600]   You know, before, I mean, I only started doing
[01:28:21.600 --> 01:28:24.320]   public-facing anything, posting on Instagram in 2019,
[01:28:24.320 --> 01:28:27.000]   but I used to head up to Walla Walla
[01:28:27.000 --> 01:28:29.400]   on the northern coast of California,
[01:28:29.400 --> 01:28:33.280]   sometimes by myself, to a little cabin there
[01:28:33.280 --> 01:28:36.600]   and spend a weekend by myself and just read
[01:28:36.600 --> 01:28:38.280]   and write papers and things like that.
[01:28:38.280 --> 01:28:40.480]   I used to do that all the time.
[01:28:40.480 --> 01:28:41.500]   I miss that.
[01:28:41.500 --> 01:28:44.680]   So some of that, I'm trying to spend a bit more time
[01:28:44.680 --> 01:28:46.240]   with my relatives in Argentina,
[01:28:46.240 --> 01:28:50.080]   relatives on the East Coast, see my parents more.
[01:28:50.080 --> 01:28:51.760]   They're in good health, thankfully.
[01:28:51.760 --> 01:28:53.200]   I want to get married and have a family.
[01:28:53.200 --> 01:28:54.840]   That's an important priority.
[01:28:54.840 --> 01:28:56.760]   I'm putting a lot of work in there.
[01:28:56.760 --> 01:28:57.600]   - Yeah, that's a big one.
[01:28:57.600 --> 01:28:59.720]   - Yeah, yeah, yeah, putting a lot of work
[01:28:59.720 --> 01:29:02.200]   into the runway on that.
[01:29:02.200 --> 01:29:07.480]   - What's your advice for people about that?
[01:29:07.480 --> 01:29:09.820]   Or give advice to yourself about how to find love
[01:29:09.820 --> 01:29:14.400]   in this world, how to build a family and get there.
[01:29:14.400 --> 01:29:15.640]   And then I'll listen to it someday
[01:29:15.640 --> 01:29:16.980]   and see if I hit the marks.
[01:29:16.980 --> 01:29:20.400]   Yeah, well, obviously pick the right partner,
[01:29:20.400 --> 01:29:22.520]   but also do the work on yourself.
[01:29:22.520 --> 01:29:26.400]   Know yourself, the oracle, know thyself.
[01:29:26.400 --> 01:29:31.120]   And I think, listen, I have a friend.
[01:29:31.120 --> 01:29:36.120]   He's a new friend, but he's a friend who I met for a meal.
[01:29:36.120 --> 01:29:39.760]   He's a very, very well-known actor overseas.
[01:29:39.760 --> 01:29:42.920]   And his stuff has made it over here and we become friends.
[01:29:42.920 --> 01:29:45.580]   And we went to lunch and we were talking about work
[01:29:45.580 --> 01:29:48.520]   and being public facing and all this kind of thing.
[01:29:48.520 --> 01:29:51.160]   And then I said, "You have kids, right?"
[01:29:51.160 --> 01:29:52.240]   And he says, "Yes, four kids."
[01:29:52.240 --> 01:29:54.320]   I was like, "Oh yeah, I see your post with the kids.
[01:29:54.320 --> 01:29:55.160]   "You seem really happy."
[01:29:55.160 --> 01:29:56.960]   And he said, he just looked at me, leaned in,
[01:29:56.960 --> 01:30:01.960]   and he said, "It's the best gift you'll ever give yourself."
[01:30:01.960 --> 01:30:05.820]   And he also said, "And pick your partner,
[01:30:05.820 --> 01:30:09.240]   "the mother of your kids, very carefully."
[01:30:09.240 --> 01:30:11.760]   So, you know, that's good advice coming from,
[01:30:11.760 --> 01:30:14.200]   excellent advice coming from somebody who's, you know,
[01:30:14.200 --> 01:30:16.560]   very successful in work and family.
[01:30:16.560 --> 01:30:18.640]   So that's the only thing I can pass along.
[01:30:18.640 --> 01:30:20.480]   We hear this from friends of ours as well,
[01:30:20.480 --> 01:30:24.360]   but kids are amazing and family's amazing.
[01:30:24.360 --> 01:30:28.280]   And, you know, that's the different people,
[01:30:28.280 --> 01:30:30.160]   all these people who wanna like be immortal
[01:30:30.160 --> 01:30:33.520]   and like live to be 200 or something, you know,
[01:30:33.520 --> 01:30:36.240]   there's also the old fashioned way of, you know,
[01:30:36.240 --> 01:30:40.440]   having children that live on and evolve a new legacy,
[01:30:40.440 --> 01:30:42.560]   but they have, you know, half your DNA.
[01:30:42.560 --> 01:30:43.680]   So that's exciting.
[01:30:43.680 --> 01:30:45.800]   - Yeah, I think you would make an amazing dad.
[01:30:45.800 --> 01:30:46.640]   - Thank you.
[01:30:46.640 --> 01:30:48.000]   - It seems like a fun thing.
[01:30:48.000 --> 01:30:50.200]   And, you know, I've also gotten advice from friends
[01:30:50.200 --> 01:30:55.200]   who are super high performing and have a lot of kids.
[01:30:55.200 --> 01:30:57.880]   They'll say, "Just don't overthink it.
[01:30:57.880 --> 01:30:59.360]   "Start having kids.
[01:30:59.360 --> 01:31:00.200]   "Let's go."
[01:31:00.200 --> 01:31:02.240]   - Right, well, the chaos of kids is kind of the,
[01:31:02.240 --> 01:31:06.880]   like it can either bury you or it can give you energy.
[01:31:06.880 --> 01:31:08.800]   But I grew up in a big pack of boys
[01:31:08.800 --> 01:31:10.600]   always doing like wild and crazy things.
[01:31:10.600 --> 01:31:12.480]   And so that kind of energy is great.
[01:31:12.480 --> 01:31:14.440]   And if it's not a big pack of wild boys,
[01:31:14.440 --> 01:31:16.760]   it's, you know, you have daughters
[01:31:16.760 --> 01:31:19.040]   and they can be, you know, different form of chaos,
[01:31:19.040 --> 01:31:20.480]   sometimes same form of chaos.
[01:31:20.480 --> 01:31:22.760]   - How many kids do you think you want?
[01:31:22.760 --> 01:31:27.120]   - Hmm, you know, it's either two or five.
[01:31:27.120 --> 01:31:29.640]   - Yeah.
[01:31:29.640 --> 01:31:30.460]   - Very different dynamics.
[01:31:30.460 --> 01:31:31.300]   You're one of two, right?
[01:31:31.300 --> 01:31:32.140]   - Yep.
[01:31:32.140 --> 01:31:32.960]   - Yeah.
[01:31:32.960 --> 01:31:34.980]   I mean, I'm very close with my sister.
[01:31:34.980 --> 01:31:36.560]   I couldn't imagine having another sibling
[01:31:36.560 --> 01:31:38.400]   'cause there's so much richness there.
[01:31:38.400 --> 01:31:39.800]   We talk almost every day.
[01:31:39.800 --> 01:31:43.480]   Or, you know, three, four times a week, you know.
[01:31:43.480 --> 01:31:45.720]   Sometimes just briefly, but we're tight.
[01:31:45.720 --> 01:31:48.820]   You know, we're really look out for one another.
[01:31:48.820 --> 01:31:53.360]   She's an amazing person, like truly an amazing person.
[01:31:53.360 --> 01:31:56.600]   And has like raised her daughter in amazing ways.
[01:31:56.600 --> 01:31:59.800]   She's like, you know, my niece is like
[01:31:59.800 --> 01:32:01.240]   gonna head to college in a year or two.
[01:32:01.240 --> 01:32:03.280]   And like, my sister's done an amazing job.
[01:32:03.280 --> 01:32:05.120]   And her dad's done a great job too.
[01:32:05.120 --> 01:32:10.120]   They both really put a lot into the family aspect.
[01:32:10.120 --> 01:32:13.120]   - Had a chance to spend time with a really amazing person
[01:32:13.120 --> 01:32:15.800]   in Peru, in the Amazon jungle.
[01:32:15.800 --> 01:32:18.400]   And he is one of 20 kids.
[01:32:18.400 --> 01:32:19.240]   - Wow.
[01:32:19.240 --> 01:32:22.000]   - So he's got, it's mostly guys.
[01:32:22.000 --> 01:32:23.480]   So it's just a lot of brothers.
[01:32:23.480 --> 01:32:25.200]   And I think two sisters.
[01:32:25.200 --> 01:32:26.040]   - Wow.
[01:32:26.040 --> 01:32:27.720]   I just had Jonathan Haidt on the podcast,
[01:32:27.720 --> 01:32:29.240]   the guy who's talking about "Anxious Generation,"
[01:32:29.240 --> 01:32:30.160]   "Causaling the American Mind."
[01:32:30.160 --> 01:32:31.040]   He's great.
[01:32:31.040 --> 01:32:31.880]   But he was saying that, you know,
[01:32:31.880 --> 01:32:33.160]   in order to keep kids healthy,
[01:32:33.160 --> 01:32:35.200]   they need to not be on social media
[01:32:35.200 --> 01:32:37.880]   or have smartphones until they're 16.
[01:32:37.880 --> 01:32:39.280]   I've actually been thinking a lot
[01:32:39.280 --> 01:32:41.600]   about getting a bunch of friends
[01:32:41.600 --> 01:32:43.080]   onto neighboring properties.
[01:32:43.080 --> 01:32:44.520]   You know, everyone talks about this.
[01:32:44.520 --> 01:32:46.380]   Not creating a commune or anything like that.
[01:32:46.380 --> 01:32:49.000]   But I think he, I think Jonathan's right.
[01:32:49.000 --> 01:32:52.500]   We were more or less, our brain wiring does best
[01:32:52.500 --> 01:32:56.040]   when we are raised in small village type environments
[01:32:56.040 --> 01:32:58.680]   where kids can forage, the whole free range kids idea.
[01:32:58.680 --> 01:33:00.940]   And I grew up skateboarding and building forts
[01:33:00.940 --> 01:33:03.320]   and dirt clod wars and all that stuff.
[01:33:03.320 --> 01:33:07.400]   It would be so strange to have a childhood without that.
[01:33:07.400 --> 01:33:10.840]   - Yeah, and I think more and more,
[01:33:10.840 --> 01:33:13.000]   as we wake up to the negative aspects
[01:33:13.000 --> 01:33:14.360]   of the digital interaction,
[01:33:14.360 --> 01:33:17.560]   it will put more and more value to in-person interaction.
[01:33:17.560 --> 01:33:18.400]   So.
[01:33:18.400 --> 01:33:19.600]   - I mean, it's cool to see, for instance,
[01:33:19.600 --> 01:33:21.320]   kids in New York City.
[01:33:21.320 --> 01:33:22.500]   They're just kind of moving around the city
[01:33:22.500 --> 01:33:23.800]   with so much sense of agency.
[01:33:23.800 --> 01:33:25.000]   It's really, really cool.
[01:33:25.000 --> 01:33:27.560]   The suburbs, like where I grew up,
[01:33:27.560 --> 01:33:29.400]   like as soon as we could get out,
[01:33:29.400 --> 01:33:31.280]   take the 7F bus up to San Francisco
[01:33:31.280 --> 01:33:34.460]   and hang out with wild ones like that.
[01:33:34.460 --> 01:33:35.900]   While there were dangers, I mean,
[01:33:35.900 --> 01:33:37.700]   we couldn't wait to get out of the suburbs.
[01:33:37.700 --> 01:33:40.160]   The moment that forts and dirt clod wars
[01:33:40.160 --> 01:33:41.700]   and stuff didn't cut it,
[01:33:41.700 --> 01:33:43.100]   we just like wanted into the city.
[01:33:43.100 --> 01:33:45.060]   So, bucket list.
[01:33:45.060 --> 01:33:48.020]   I will probably move to a major city,
[01:33:48.020 --> 01:33:49.940]   not Los Angeles or San Francisco,
[01:33:49.940 --> 01:33:53.780]   in the next few years.
[01:33:53.780 --> 01:33:55.900]   New York City, potentially.
[01:33:55.900 --> 01:33:58.420]   - Those are all such different flavors of experiences.
[01:33:58.420 --> 01:33:59.260]   - Yeah.
[01:33:59.260 --> 01:34:01.260]   So, I'd love to live in New York City for a while.
[01:34:01.260 --> 01:34:03.660]   I've always wanted to do that, and I will do that.
[01:34:03.660 --> 01:34:05.940]   I've always wanted to also have a place
[01:34:05.940 --> 01:34:08.100]   in a very rural area.
[01:34:08.100 --> 01:34:11.580]   So, Colorado and Montana are high on my list right now.
[01:34:11.580 --> 01:34:13.780]   And to be able to pivot back and forth
[01:34:13.780 --> 01:34:15.420]   between the two would be great,
[01:34:15.420 --> 01:34:17.300]   just for such different experiences.
[01:34:17.300 --> 01:34:19.140]   And also, I like a very physical life.
[01:34:19.140 --> 01:34:22.060]   So, the idea of getting up with the sun
[01:34:22.060 --> 01:34:24.440]   in a Montana or Colorado type environment.
[01:34:24.440 --> 01:34:28.460]   And I've been putting some effort
[01:34:28.460 --> 01:34:31.980]   towards finding a spot for that.
[01:34:31.980 --> 01:34:34.380]   And New York City, to me, I know it's got its issues,
[01:34:34.380 --> 01:34:35.820]   and people say, "It wasn't what it was."
[01:34:35.820 --> 01:34:37.820]   Okay, I get it, but listen, I've never lived there,
[01:34:37.820 --> 01:34:39.540]   so for me, it'd be entirely new.
[01:34:39.540 --> 01:34:43.980]   And, you know, Schulz seems full of life.
[01:34:43.980 --> 01:34:46.780]   - There is an energy to that city, and he represents that.
[01:34:46.780 --> 01:34:48.140]   I mean, there's-- - Yeah.
[01:34:48.140 --> 01:34:50.860]   - And the full diversity of weird
[01:34:50.860 --> 01:34:53.780]   that is represented in New York City is great.
[01:34:53.780 --> 01:34:54.620]   - Yeah, you walk down the street,
[01:34:54.620 --> 01:34:56.140]   there's a person with a cat on their head,
[01:34:56.140 --> 01:34:56.960]   and no one gives a shit.
[01:34:56.960 --> 01:34:58.540]   - Yeah, that's great.
[01:34:58.540 --> 01:35:00.380]   - San Francisco used to be like that.
[01:35:00.380 --> 01:35:03.460]   The joke was like, you have to be naked and on fire
[01:35:03.460 --> 01:35:04.800]   in San Francisco before someone takes it,
[01:35:04.800 --> 01:35:05.920]   but now it's changed.
[01:35:05.920 --> 01:35:08.880]   But again, recently, I've noticed that San Francisco,
[01:35:08.880 --> 01:35:10.480]   it's not just about the skateboarders,
[01:35:10.480 --> 01:35:13.740]   there's some community houses of people in tech
[01:35:13.740 --> 01:35:14.760]   that are super interesting.
[01:35:14.760 --> 01:35:17.880]   There's some community housing of people not in tech
[01:35:17.880 --> 01:35:22.440]   that I've learned about and known people have lived there,
[01:35:22.440 --> 01:35:23.960]   and it's cool.
[01:35:23.960 --> 01:35:25.600]   Like, there's stuff happening.
[01:35:26.440 --> 01:35:28.300]   In these cities, that's new and different.
[01:35:28.300 --> 01:35:29.720]   I mean, that's what youth is for.
[01:35:29.720 --> 01:35:31.880]   They're supposed to evolve things out.
[01:35:31.880 --> 01:35:36.720]   - So amidst all that, you still have to get shit done.
[01:35:36.720 --> 01:35:40.520]   I've been really obsessed with tracking time recently,
[01:35:40.520 --> 01:35:43.040]   like making sure I have daily activities,
[01:35:43.040 --> 01:35:45.840]   I have habits that I'm maintaining,
[01:35:45.840 --> 01:35:50.840]   and I'm very religious about making sure I get shit done.
[01:35:50.840 --> 01:35:52.480]   - Do you use an app or something like that?
[01:35:52.480 --> 01:35:54.280]   - No, just Google Sheets.
[01:35:54.280 --> 01:35:57.120]   So basically a spreadsheet, and I'm tracking daily,
[01:35:57.120 --> 01:36:00.840]   and I write scripts that whenever I achieve a goal,
[01:36:00.840 --> 01:36:03.180]   it glows green.
[01:36:03.180 --> 01:36:05.320]   - Yeah, do you track your workouts
[01:36:05.320 --> 01:36:06.880]   and all that kind of stuff too?
[01:36:06.880 --> 01:36:10.360]   - No, just the fact that I got the workout done.
[01:36:10.360 --> 01:36:12.000]   So it's a checkmark thing.
[01:36:12.000 --> 01:36:16.880]   So I'm really, really big on making sure I do a thing.
[01:36:16.880 --> 01:36:18.320]   It doesn't matter how long it is.
[01:36:18.320 --> 01:36:22.040]   So I have a rule for myself that I do a set of tasks
[01:36:22.900 --> 01:36:24.760]   for at least five minutes every day.
[01:36:24.760 --> 01:36:29.100]   And it turns out that many of them I do way longer,
[01:36:29.100 --> 01:36:33.340]   but just even just doing it, I have to do it every day.
[01:36:33.340 --> 01:36:36.540]   And there's currently 11 of them.
[01:36:36.540 --> 01:36:37.380]   It's just a thing.
[01:36:37.380 --> 01:36:39.740]   Like one of them is playing guitar, for example.
[01:36:39.740 --> 01:36:40.740]   - So do you do that kind of stuff?
[01:36:40.740 --> 01:36:43.340]   Do you do like daily habits?
[01:36:43.340 --> 01:36:44.540]   - Yeah, I do.
[01:36:44.540 --> 01:36:49.400]   I wake up, if I don't feel I slept enough,
[01:36:49.400 --> 01:36:52.380]   I do this non-sleep deep rest yoga nidra thing
[01:36:52.380 --> 01:36:53.220]   that I've talked about a bunch.
[01:36:53.220 --> 01:36:54.740]   We actually released a few of those tracks
[01:36:54.740 --> 01:36:59.300]   as audio tracks on Spotify, 10 minute, 20 minute ones.
[01:36:59.300 --> 01:37:02.060]   Puts me back into a state that feels like sleep
[01:37:02.060 --> 01:37:03.060]   and I feel very rested.
[01:37:03.060 --> 01:37:04.860]   Actually, Matt Walker and I are gonna run a study.
[01:37:04.860 --> 01:37:07.940]   He's just submitted the IRB to run a study on NSDR
[01:37:07.940 --> 01:37:09.780]   and what it's actually doing to the brain.
[01:37:09.780 --> 01:37:12.340]   There's some evidence of increases in dopamine, et cetera,
[01:37:12.340 --> 01:37:14.060]   but those are older studies, still cool studies.
[01:37:14.060 --> 01:37:17.260]   But so I'll do that, get up, hydrate.
[01:37:17.260 --> 01:37:21.520]   And if I've got my act together, I punch some caffeine down.
[01:37:22.400 --> 01:37:24.640]   Like some Matina, some coffee, maybe another Matina
[01:37:24.640 --> 01:37:28.160]   and resistance train three days a week,
[01:37:28.160 --> 01:37:30.840]   run three days a week and then take one day off.
[01:37:30.840 --> 01:37:34.080]   And like to be done by 8.39.
[01:37:34.080 --> 01:37:35.880]   And then I wanna get into some real work.
[01:37:35.880 --> 01:37:38.960]   I actually have a sticky note on my computer.
[01:37:38.960 --> 01:37:41.040]   It's like, just like reminding me how good it feels
[01:37:41.040 --> 01:37:42.120]   to accomplish some real work.
[01:37:42.120 --> 01:37:43.760]   And then I go into it right now.
[01:37:43.760 --> 01:37:46.480]   It's the book writing, researching a podcast
[01:37:46.480 --> 01:37:50.960]   and just fight tooth and nail to stay off social media,
[01:37:50.960 --> 01:37:54.840]   text message, WhatsApp, YouTube, all that.
[01:37:54.840 --> 01:37:55.760]   Get something done.
[01:37:55.760 --> 01:37:56.600]   - How long can you go?
[01:37:56.600 --> 01:38:01.120]   Can you go like three hours, just deep focus?
[01:38:01.120 --> 01:38:04.380]   - If I hit a groove, yeah, 90 minutes to three hours
[01:38:04.380 --> 01:38:05.680]   if I'm really in a groove.
[01:38:05.680 --> 01:38:09.720]   - For me, I start the day actually.
[01:38:09.720 --> 01:38:12.920]   That's why I'm afraid I'd really prize that,
[01:38:12.920 --> 01:38:15.720]   those morning hours I start with the work.
[01:38:15.720 --> 01:38:20.720]   And it's, I'm trying to hit the four hour mark
[01:38:21.200 --> 01:38:22.180]   of deep focus.
[01:38:22.180 --> 01:38:23.440]   - Great, I love it.
[01:38:23.440 --> 01:38:28.260]   - Then often can't, I'm really, really big believer.
[01:38:28.260 --> 01:38:30.040]   It's often torture actually.
[01:38:30.040 --> 01:38:31.080]   It's really, really difficult.
[01:38:31.080 --> 01:38:32.840]   - Oh yeah, the agitation.
[01:38:32.840 --> 01:38:36.460]   But I've sat across the table from you a couple of years ago
[01:38:36.460 --> 01:38:38.040]   when I was out here in Austin doing some work
[01:38:38.040 --> 01:38:39.160]   and I was working on stuff.
[01:38:39.160 --> 01:38:41.600]   And I noticed you just like stare at your notebook sometimes
[01:38:41.600 --> 01:38:45.200]   just like pen at the same position
[01:38:45.200 --> 01:38:46.240]   and then you'll get back into it.
[01:38:46.240 --> 01:38:48.000]   Like there are those (indistinct)
[01:38:48.000 --> 01:38:50.620]   building that hydraulic pressure and then go.
[01:38:50.620 --> 01:38:52.580]   - Yeah, I try and get something done of value.
[01:38:52.580 --> 01:38:55.060]   Then the communications start
[01:38:55.060 --> 01:38:59.040]   and talking to my podcast producer, my team is everything.
[01:38:59.040 --> 01:39:04.040]   I mean, like the magic potion in the podcast is Rob Moore,
[01:39:04.040 --> 01:39:05.460]   right?
[01:39:05.460 --> 01:39:08.900]   Who's in the, has been in the room with me every single solo.
[01:39:08.900 --> 01:39:10.860]   Costello used to be in there with us, but that's it.
[01:39:10.860 --> 01:39:12.100]   People have asked, journalists have asked,
[01:39:12.100 --> 01:39:13.980]   can they sit in, friends have asked.
[01:39:13.980 --> 01:39:16.300]   Nope, just Rob.
[01:39:16.300 --> 01:39:20.240]   And for guests interviews, he's there as well.
[01:39:20.240 --> 01:39:23.260]   And I talk to Rob all the time, all the time.
[01:39:23.260 --> 01:39:25.300]   We talk multiple times per day.
[01:39:25.300 --> 01:39:29.180]   And in life, I've made some errors
[01:39:29.180 --> 01:39:31.120]   in certain relationship domains in my life
[01:39:31.120 --> 01:39:32.860]   in terms of partner choice and things like that.
[01:39:32.860 --> 01:39:35.540]   And certainly don't blame all of it on them,
[01:39:35.540 --> 01:39:36.700]   but I've played my role.
[01:39:36.700 --> 01:39:41.620]   But in terms of picking business partners and friends,
[01:39:41.620 --> 01:39:44.940]   like to work with, I mean, Rob's just, it's been bullseyes.
[01:39:44.940 --> 01:39:46.820]   And it's just Rob has been amazing.
[01:39:46.820 --> 01:39:48.060]   Mike Blayback, our photographer
[01:39:48.060 --> 01:39:49.100]   and the guys I mentioned earlier.
[01:39:49.100 --> 01:39:53.180]   Like we just communicate as much as we need to.
[01:39:53.180 --> 01:39:56.820]   And we pour over every decision like near neuroticism
[01:39:56.820 --> 01:39:58.820]   before we make, we put anything out there.
[01:39:58.820 --> 01:39:59.920]   And-
[01:39:59.920 --> 01:40:01.780]   - So including like even creative decisions
[01:40:01.780 --> 01:40:03.380]   of like topics to cover, all of that.
[01:40:03.380 --> 01:40:06.020]   - Yeah, like a photo for the book jacket the other day,
[01:40:06.020 --> 01:40:06.980]   Mike shoots photos.
[01:40:06.980 --> 01:40:10.940]   Then, and then we look at them, we pour over them together.
[01:40:10.940 --> 01:40:13.060]   Logo for the perform podcast with Andy Gallop.
[01:40:13.060 --> 01:40:14.740]   And then we're launching like, is that the right contour?
[01:40:14.740 --> 01:40:17.060]   Mike's the real, he's got the aesthetic thing.
[01:40:17.060 --> 01:40:20.020]   'Cause he was at DC so long as a portrait photographer.
[01:40:20.020 --> 01:40:23.300]   And he's cute, he's close friends with Ken Block,
[01:40:23.300 --> 01:40:25.660]   to Jim Cona, like all the car jumping in the city stuff.
[01:40:25.660 --> 01:40:27.180]   Like, I mean, Mike is a master.
[01:40:27.180 --> 01:40:29.660]   He's a true master of that stuff.
[01:40:29.660 --> 01:40:33.580]   And we just pour over every little decision,
[01:40:33.580 --> 01:40:35.700]   but even which sponsors, you know,
[01:40:35.700 --> 01:40:37.280]   there are dozens of ads now.
[01:40:37.280 --> 01:40:40.140]   By the way, that whole Jawserciser thing of me saying,
[01:40:40.140 --> 01:40:42.100]   oh, a guy went from a two to a seven.
[01:40:42.100 --> 01:40:43.900]   I never said that, that's AI.
[01:40:43.900 --> 01:40:45.780]   Like I would never call it number off somebody,
[01:40:45.780 --> 01:40:46.700]   a two to a seven.
[01:40:46.700 --> 01:40:47.660]   Are you kidding me?
[01:40:47.660 --> 01:40:48.500]   It's crazy.
[01:40:48.500 --> 01:40:49.320]   So it was AI.
[01:40:49.320 --> 01:40:50.940]   If you bought the thing, I'm sorry.
[01:40:50.940 --> 01:40:53.580]   But like our sponsors, we list the sponsors that we have
[01:40:53.580 --> 01:40:55.020]   and why on our website.
[01:40:55.020 --> 01:40:57.380]   And like the decision, do we work with this person or not?
[01:40:57.380 --> 01:40:58.660]   Do we still like the product?
[01:40:58.660 --> 01:41:00.620]   I mean, we've got ways with sponsors
[01:41:00.620 --> 01:41:04.180]   'cause of like changes in the product or, you know,
[01:41:04.180 --> 01:41:06.600]   most of the time it's amicable, all good.
[01:41:06.600 --> 01:41:08.640]   But you know, like just every detail.
[01:41:08.640 --> 01:41:11.080]   And that just takes a ton of time and energy.
[01:41:11.080 --> 01:41:14.020]   But I try and work mostly on content.
[01:41:14.020 --> 01:41:15.420]   And my team's constantly trying to keep me
[01:41:15.420 --> 01:41:20.020]   out of the other discussions 'cause I obsess.
[01:41:20.020 --> 01:41:22.220]   But yeah, you have to.
[01:41:22.220 --> 01:41:23.740]   You have to have a team of some sort,
[01:41:23.740 --> 01:41:25.260]   someone that you can run things by.
[01:41:25.260 --> 01:41:26.100]   - For sure.
[01:41:26.100 --> 01:41:28.780]   But one of the challenges, the larger the team is,
[01:41:28.780 --> 01:41:31.400]   and I'd like to be involved in a lot of different kinds
[01:41:31.400 --> 01:41:33.540]   of stuff, including engineering stuff, robotics work,
[01:41:33.540 --> 01:41:38.540]   research, all of those interactions, at least for me,
[01:41:38.540 --> 01:41:41.980]   take away from the deep work, the deep focus.
[01:41:41.980 --> 01:41:45.540]   Unfortunately, I get drained by social interaction,
[01:41:45.540 --> 01:41:47.540]   even with the people I love and really respect
[01:41:47.540 --> 01:41:48.660]   and all that kind of stuff.
[01:41:48.660 --> 01:41:49.540]   - You're an introvert.
[01:41:49.540 --> 01:41:51.420]   - Yeah, like fundamentally an introvert.
[01:41:51.420 --> 01:41:54.760]   So to me, it's a trade-off getting shit done
[01:41:54.760 --> 01:41:57.100]   versus collaborating.
[01:41:57.100 --> 01:41:59.480]   And I have to choose wisely because without collaboration,
[01:41:59.480 --> 01:42:01.980]   without a great team, which I'm fortunate enough
[01:42:01.980 --> 01:42:04.980]   to be a part of, like you wouldn't get anything really done.
[01:42:04.980 --> 01:42:07.800]   But as an individual contributor to get stuff done,
[01:42:07.800 --> 01:42:10.860]   like to do the hard work of researching or programming,
[01:42:10.860 --> 01:42:14.020]   all that kind of stuff, you need the hours of deep work.
[01:42:14.020 --> 01:42:16.100]   I used to spend a lot more time alone.
[01:42:16.100 --> 01:42:18.580]   That's on my bucket list, spend a bit more time
[01:42:18.580 --> 01:42:20.000]   dropped into work alone.
[01:42:20.000 --> 01:42:24.380]   I think social media causes our brain
[01:42:24.380 --> 01:42:25.780]   to go the other direction.
[01:42:25.780 --> 01:42:29.420]   I try and answer some comments and then get back to work.
[01:42:29.420 --> 01:42:32.340]   I'm really, after going to the jungle,
[01:42:32.340 --> 01:42:35.580]   I appreciate not using the device.
[01:42:35.580 --> 01:42:39.980]   I play with the idea of spending certainly,
[01:42:39.980 --> 01:42:44.180]   maybe like one week a month not using social media at all.
[01:42:44.180 --> 01:42:46.060]   - I used it, so after that morning block,
[01:42:46.060 --> 01:42:47.980]   I'll eat some lunch and I'll usually do something
[01:42:47.980 --> 01:42:50.860]   while I'm doing lunch or something and then a bit more work
[01:42:50.860 --> 01:42:52.480]   and that real work, deep work.
[01:42:52.480 --> 01:42:56.320]   And then around 2.30, I do a non-sleep deep rest,
[01:42:56.320 --> 01:42:58.860]   take a short nap, wake up, boom,
[01:42:58.860 --> 01:43:03.300]   maybe a little more caffeine and then lean into it again.
[01:43:03.300 --> 01:43:07.420]   And then I find if you really put in the deep work,
[01:43:07.420 --> 01:43:10.340]   two or three bouts per day by about five or 6 p.m.,
[01:43:10.340 --> 01:43:11.180]   it's over.
[01:43:11.180 --> 01:43:13.380]   I was down at Jocko's place not that long ago
[01:43:13.380 --> 01:43:15.800]   and in the evening did a sauna session with him
[01:43:15.800 --> 01:43:19.300]   and some family members of his and some of their friends.
[01:43:19.300 --> 01:43:21.300]   And it's really cool, like they'll work all day
[01:43:21.300 --> 01:43:23.340]   and train all day and then in the evening they get together
[01:43:23.340 --> 01:43:25.680]   and they sauna and cold plunge.
[01:43:25.680 --> 01:43:29.840]   I'm really into this whole thing of gathering
[01:43:29.840 --> 01:43:32.900]   with other people at a specific time of day.
[01:43:32.900 --> 01:43:36.020]   I have a gym at my house and Tim will come over and train
[01:43:36.020 --> 01:43:40.140]   or that we've kind of slowed that down in recent months.
[01:43:40.140 --> 01:43:44.280]   But I think gathering in groups once a day,
[01:43:44.280 --> 01:43:45.780]   being alone for part of the day,
[01:43:45.780 --> 01:43:47.300]   I mean, it's like very fundamental stuff.
[01:43:47.300 --> 01:43:48.980]   We're not saying anything that hasn't been said
[01:43:48.980 --> 01:43:50.020]   millions of times before,
[01:43:50.020 --> 01:43:52.380]   but how often do people actually do that?
[01:43:52.380 --> 01:43:55.060]   And call the party, be the person
[01:43:55.060 --> 01:43:56.980]   to bring people together if it's not happening.
[01:43:56.980 --> 01:43:58.700]   That's something I've really had to learn,
[01:43:58.700 --> 01:44:00.260]   even though I'm an introvert.
[01:44:00.260 --> 01:44:02.100]   Like, hey, I'm like, gather people together.
[01:44:02.100 --> 01:44:03.740]   You came through town the other day
[01:44:03.740 --> 01:44:06.500]   and there's a lot of people at the house, it was rad.
[01:44:06.500 --> 01:44:08.300]   Actually, it was funny 'cause I was getting a massage
[01:44:08.300 --> 01:44:09.220]   when you walked in.
[01:44:09.220 --> 01:44:11.900]   I don't sit around getting massages very often,
[01:44:11.900 --> 01:44:14.220]   but I was getting one that day and then everyone came in
[01:44:14.220 --> 01:44:16.300]   and the dog came in and like everyone was piled in.
[01:44:16.300 --> 01:44:18.060]   It was very sweet.
[01:44:18.060 --> 01:44:19.580]   - Again, no devices.
[01:44:19.580 --> 01:44:23.220]   But choose wisely the people you gather with.
[01:44:23.220 --> 01:44:24.920]   - Right, right, and I was clothed.
[01:44:24.920 --> 01:44:27.260]   - Thank you for clarifying.
[01:44:27.260 --> 01:44:29.300]   I wasn't, which is very weird.
[01:44:32.060 --> 01:44:35.700]   - Yeah, yeah, the friends you surround yourself with.
[01:44:35.700 --> 01:44:36.700]   That's another thing.
[01:44:36.700 --> 01:44:40.220]   It's like I understood that from ayahuasca
[01:44:40.220 --> 01:44:41.780]   and from just the experience in the jungle
[01:44:41.780 --> 01:44:45.620]   is like just select the people.
[01:44:45.620 --> 01:44:47.480]   Just be careful how you allocate your time.
[01:44:47.480 --> 01:44:52.300]   I just saw somewhere, Conor McGregor has this good line.
[01:44:52.300 --> 01:44:54.780]   I wrote it down about loyalty.
[01:44:54.780 --> 01:44:57.780]   He said, "Don't eat with people you wouldn't starve with."
[01:44:57.780 --> 01:45:01.380]   That guy's, I mean, he's big on loyalty.
[01:45:01.380 --> 01:45:04.660]   All the shit talk, all of that, set that aside.
[01:45:04.660 --> 01:45:06.780]   To me, like loyalty's really big.
[01:45:06.780 --> 01:45:08.780]   'Cause then if you invest in certain people in your life
[01:45:08.780 --> 01:45:11.020]   and they stick by you and you stick by them,
[01:45:11.020 --> 01:45:13.980]   and what else is life about?
[01:45:13.980 --> 01:45:15.260]   - Yeah, well, hardship will show you
[01:45:15.260 --> 01:45:17.920]   who your real friends are, that's for sure.
[01:45:17.920 --> 01:45:21.580]   And we're fortunate to have a lot of them.
[01:45:21.580 --> 01:45:26.160]   It'll also show you who really has put in the time
[01:45:26.160 --> 01:45:29.700]   to try and understand you and understand people.
[01:45:29.700 --> 01:45:31.420]   Like people are complicated.
[01:45:31.420 --> 01:45:35.180]   I love that, so you can read the quote once more.
[01:45:35.180 --> 01:45:38.280]   "Don't eat with people you wouldn't starve with."
[01:45:38.280 --> 01:45:43.900]   Yeah, so in that way, a hardship is a gift.
[01:45:43.900 --> 01:45:48.060]   It shows you.
[01:45:48.060 --> 01:45:50.420]   - Definitely, and it makes you stronger.
[01:45:50.420 --> 01:45:52.060]   It definitely makes you stronger.
[01:45:52.060 --> 01:45:55.160]   - Let's go get some food.
[01:45:55.160 --> 01:45:57.020]   - Yeah, you're a one-meal-a-day guy.
[01:45:57.020 --> 01:45:57.860]   - Yeah.
[01:45:57.860 --> 01:45:58.780]   - I actually ate something earlier,
[01:45:58.780 --> 01:46:00.180]   but it was like a protein shake
[01:46:00.180 --> 01:46:02.260]   and a couple pieces of biltong.
[01:46:02.260 --> 01:46:03.780]   I hope we're eating a steak.
[01:46:03.780 --> 01:46:04.620]   - I hope so, too.
[01:46:04.620 --> 01:46:06.880]   I'm full of nicotine and caffeine.
[01:46:06.880 --> 01:46:07.960]   - Yeah, what do you think?
[01:46:07.960 --> 01:46:08.800]   How do you feel?
[01:46:08.800 --> 01:46:09.620]   - I feel good.
[01:46:09.620 --> 01:46:11.540]   - Yeah, I was thinking you'd probably,
[01:46:11.540 --> 01:46:13.420]   like I only did a half a piece,
[01:46:13.420 --> 01:46:15.100]   and I won't have more for a little while,
[01:46:15.100 --> 01:46:15.940]   but--
[01:46:15.940 --> 01:46:16.840]   - A little too good.
[01:46:16.840 --> 01:46:17.680]   - Yeah.
[01:46:17.680 --> 01:46:20.800]   - Thank you for talking once again, brother.
[01:46:20.800 --> 01:46:22.820]   - Yeah, thanks so much, Lex.
[01:46:22.820 --> 01:46:24.780]   It's been a great ride, this podcast thing,
[01:46:24.780 --> 01:46:26.460]   and you're the reason I started the podcast.
[01:46:26.460 --> 01:46:28.660]   You inspired me to do it, you told me to do it.
[01:46:28.660 --> 01:46:32.060]   You did it, and you've also been an amazing friend.
[01:46:32.060 --> 01:46:35.860]   You showed up in some very challenging times,
[01:46:35.860 --> 01:46:37.780]   and you've shown up for me publicly,
[01:46:37.780 --> 01:46:41.140]   you've shown up for me in my home, in my life,
[01:46:41.140 --> 01:46:46.000]   and it's an honor to have you as a friend.
[01:46:46.000 --> 01:46:47.040]   Thank you.
[01:46:47.040 --> 01:46:47.880]   I love you, brother.
[01:46:47.880 --> 01:46:48.700]   - Love you, too.
[01:46:48.700 --> 01:46:51.400]   - Thanks for listening to this conversation
[01:46:51.400 --> 01:46:52.620]   with Andrew Huberman.
[01:46:52.620 --> 01:46:53.740]   To support this podcast,
[01:46:53.740 --> 01:46:56.300]   please check out our sponsors in the description.
[01:46:56.300 --> 01:46:58.260]   And now, let me leave you with some words
[01:46:58.260 --> 01:46:59.200]   from Carl Jung.
[01:46:59.200 --> 01:47:02.340]   Until you make the unconscious conscious,
[01:47:02.340 --> 01:47:05.680]   it will direct your life, and you will call it fate.
[01:47:05.680 --> 01:47:09.860]   Thank you for listening, and hope to see you next time.
[01:47:09.860 --> 01:47:12.440]   (upbeat music)
[01:47:12.440 --> 01:47:15.020]   (upbeat music)
[01:47:15.020 --> 01:47:17.080]   you
[01:47:17.080 --> 01:47:27.080]   [BLANK_AUDIO]

