
[00:00:00.000 --> 00:00:05.840]   The following is a conversation with Sheldon Solomon, a social psychologist, a philosopher,
[00:00:05.840 --> 00:00:11.960]   co-developer of terror management theory, and co-author of "The Warm at the Core"
[00:00:11.960 --> 00:00:14.380]   on the role of death in life.
[00:00:14.380 --> 00:00:19.240]   He further carried the ideas of Ernest Becker that can crudely summarize as the idea that
[00:00:19.240 --> 00:00:25.560]   our fear of death is at the core of the human condition and the driver of most of the creations
[00:00:25.560 --> 00:00:27.840]   of human civilization.
[00:00:27.840 --> 00:00:32.800]   Quick summary of the sponsors, Blinkist, ExpressVPN, and Cash App.
[00:00:32.800 --> 00:00:35.240]   Click the links in the description to get a discount.
[00:00:35.240 --> 00:00:37.800]   It really is the best way to support this podcast.
[00:00:37.800 --> 00:00:43.880]   Let me say as a side note that Ernest Becker's book, "Denial of Death" had a big impact
[00:00:43.880 --> 00:00:50.320]   on my thinking about human cognition, consciousness, and the deep ocean currents of our mind that
[00:00:50.320 --> 00:00:53.400]   are behind the surface behaviors we observe.
[00:00:53.400 --> 00:00:58.520]   Many people have told me that they think about death or don't think about death, fear death
[00:00:58.520 --> 00:01:04.980]   or don't fear death, but I think not many people think about this topic deeply, rigorously,
[00:01:04.980 --> 00:01:07.560]   in the way that Nietzsche suggested.
[00:01:07.560 --> 00:01:14.960]   This topic, like many that lead to deep personal self-reflection, frankly is dangerous for
[00:01:14.960 --> 00:01:16.240]   the mind.
[00:01:16.240 --> 00:01:20.640]   As all first principles thinking about the human condition is, if you gaze long into
[00:01:20.640 --> 00:01:25.360]   the abyss, like Nietzsche said, the abyss will gaze back into you.
[00:01:25.360 --> 00:01:30.760]   I've been recently reading a lot about World War II, Stalin, and Hitler.
[00:01:30.760 --> 00:01:35.080]   It feels to me that there's some fundamental truth there to be discovered in the moments
[00:01:35.080 --> 00:01:39.440]   of history that changed everything, the suffering, the triumphs.
[00:01:39.440 --> 00:01:44.480]   If I bring up Donald Trump or Vladimir Putin in these conversations, it is never through
[00:01:44.480 --> 00:01:45.800]   a political lens.
[00:01:45.800 --> 00:01:48.360]   I'm not left nor right.
[00:01:48.360 --> 00:01:54.440]   I think for myself, deeply, and often question everything, changing my mind as often as is
[00:01:54.440 --> 00:01:55.440]   needed.
[00:01:55.440 --> 00:01:59.040]   I ask for your patience, empathy, and rigorous thinking.
[00:01:59.040 --> 00:02:03.840]   If you arrived to this podcast from a place of partisanship, if you hate Trump or love
[00:02:03.840 --> 00:02:10.220]   Trump or any other political leader no matter what he or they do, and see everyone who disagrees
[00:02:10.220 --> 00:02:16.520]   with you as delusional, I ask that you unsubscribe and don't listen to these conversations, because
[00:02:16.520 --> 00:02:21.080]   my hope is to go beyond that kind of divisive thinking.
[00:02:21.080 --> 00:02:26.520]   I think we can only make progress toward truth through deep, empathetic thinking and conversation,
[00:02:26.520 --> 00:02:28.520]   and as always, love.
[00:02:28.520 --> 00:02:34.360]   If you enjoy this thing, subscribe on YouTube, review it with Five Stars and Apple Podcasts,
[00:02:34.360 --> 00:02:39.680]   follow on Spotify, support on Patreon, or connect with me on Twitter @LexFriedman.
[00:02:39.680 --> 00:02:43.160]   As usual, I'll do a few minutes of ads now and no ads in the middle.
[00:02:43.160 --> 00:02:48.160]   I try to make these interesting, but I give you timestamps so you can skip.
[00:02:48.160 --> 00:02:51.480]   But please do check out the sponsors by clicking the links in the description.
[00:02:51.480 --> 00:02:54.800]   It's the best way to support this podcast.
[00:02:54.800 --> 00:03:00.040]   This episode is supported by Blinkist, my favorite app for learning new things.
[00:03:00.040 --> 00:03:06.760]   Get it at Blinkist.com/Lex for a 7-day free trial and 25% off after.
[00:03:06.760 --> 00:03:11.320]   Blinkist takes the key ideas from thousands of nonfiction books and condenses them down
[00:03:11.320 --> 00:03:14.760]   into just 15 minutes that you can read or listen to.
[00:03:14.760 --> 00:03:18.320]   I'm a big believer in reading at least an hour a day.
[00:03:18.320 --> 00:03:23.080]   As part of that, I use Blinkist every day, and in general, it's a great way to broaden
[00:03:23.080 --> 00:03:27.680]   your view of the ideal landscape out there and find books that you may want to read more
[00:03:27.680 --> 00:03:28.680]   deeply.
[00:03:28.680 --> 00:03:33.560]   With Blinkist, you get unlimited access to read or listen to a massive library of condensed
[00:03:33.560 --> 00:03:35.040]   nonfiction books.
[00:03:35.040 --> 00:03:39.920]   Right now, for a limited time, Blinkist has a special offer just for our audience.
[00:03:39.920 --> 00:03:47.120]   Go to Blinkist.com/Lex to try it free for 7 days and save 25% off your new subscription.
[00:03:47.120 --> 00:03:54.560]   That's Blinkist.com/Lex, Blinkist spelled B-L-I-N-K-I-S-T.
[00:03:54.560 --> 00:03:57.320]   This show is sponsored by ExpressVPN.
[00:03:57.320 --> 00:04:02.840]   Get it at ExpressVPN.com/LexPod to get a discount and to support this podcast.
[00:04:02.840 --> 00:04:04.080]   Have you ever watched The Office?
[00:04:04.080 --> 00:04:10.280]   If you have, you probably know it's based on a UK series also called The Office.
[00:04:10.280 --> 00:04:14.080]   Not to stir up trouble, but I think the British version is actually more brilliant than the
[00:04:14.080 --> 00:04:16.720]   American one, but both are pretty amazing.
[00:04:16.720 --> 00:04:21.400]   Anyway, there are actually 9 other countries with their own version of The Office.
[00:04:21.400 --> 00:04:25.840]   You can get access to them with no geo-restrictions when you use ExpressVPN.
[00:04:25.840 --> 00:04:30.240]   It lets you control where you want sites to think you're located.
[00:04:30.240 --> 00:04:34.580]   You can choose from nearly 100 countries, giving you access to content that isn't available
[00:04:34.580 --> 00:04:36.000]   in your region.
[00:04:36.000 --> 00:04:42.560]   So again, get it on any device at ExpressVPN.com/LexPod to get extra 3 months free and to support
[00:04:42.560 --> 00:04:44.320]   this podcast.
[00:04:44.320 --> 00:04:50.240]   This show is presented by the great, the powerful Cash App, the number one finance app in the
[00:04:50.240 --> 00:04:51.240]   App Store.
[00:04:51.240 --> 00:04:54.180]   When you get it, use code LEXPODCAST.
[00:04:54.180 --> 00:04:58.040]   Cash App lets you send money to friends, buy Bitcoin, and invest in the stock market with
[00:04:58.040 --> 00:05:00.000]   as little as $1.
[00:05:00.000 --> 00:05:04.120]   Since Cash App allows you to send and receive money digitally, let me mention a surprising
[00:05:04.120 --> 00:05:06.040]   fact about physical money.
[00:05:06.040 --> 00:05:09.320]   It costs 2.4 cents to produce a single penny.
[00:05:09.320 --> 00:05:14.000]   In fact, I think it costs $85 million annually to produce them.
[00:05:14.000 --> 00:05:19.360]   So again, if you get Cash App from the App Store or Google Play and use the code LEXPODCAST,
[00:05:19.360 --> 00:05:20.360]   you get $10.
[00:05:20.360 --> 00:05:25.380]   And Cash App will also donate $10 to FIRST, an organization that is helping to advance
[00:05:25.380 --> 00:05:29.880]   robotics and STEM education for young people around the world.
[00:05:29.880 --> 00:05:35.040]   And now, here's my conversation with Sheldon Solomon.
[00:05:35.040 --> 00:05:38.440]   What is the role of death and fear of death in life?
[00:05:38.440 --> 00:05:48.160]   - Well, from our perspective, the uniquely human awareness of death and our unwillingness
[00:05:48.160 --> 00:05:56.240]   to accept that fact, we would argue is the primary motivational impetus for almost everything
[00:05:56.240 --> 00:06:00.160]   that people do, whether they're aware of it or not.
[00:06:00.160 --> 00:06:06.400]   - So that's kind of been your life work, your view of the human condition is that death,
[00:06:06.400 --> 00:06:10.480]   you've written the book, "Warm at the Core," that death is at the core of our consciousness
[00:06:10.480 --> 00:06:14.280]   of everything, of how we see the world, of what drives us.
[00:06:14.280 --> 00:06:21.320]   Maybe can you elaborate how you see death fitting in?
[00:06:21.320 --> 00:06:24.560]   What does it mean to be at the core of our being?
[00:06:24.560 --> 00:06:27.320]   - I think that's a great question.
[00:06:27.320 --> 00:06:36.400]   And to be pedantic, I usually start my psychology classes and I say to the students, "Okay,
[00:06:36.400 --> 00:06:37.840]   let's define our terms."
[00:06:37.840 --> 00:06:41.000]   And the ology part, they get right away.
[00:06:41.000 --> 00:06:46.040]   It's the study of, and then we get to the psyche part.
[00:06:46.040 --> 00:06:50.800]   And understandably, the students are like, "Oh, that means mind."
[00:06:50.800 --> 00:06:55.120]   I'm like, "Well, no, that's a modern interpretation."
[00:06:55.120 --> 00:07:03.840]   But in ancient Greek, it means soul, but not in the Cartesian dualistic sense that most
[00:07:03.840 --> 00:07:07.600]   of us in the West think when that word comes to mind.
[00:07:07.600 --> 00:07:14.720]   And so you hear the word soul and you're like, "Well, all right, that's the non-physical
[00:07:14.720 --> 00:07:20.560]   part of me that's potentially detachable from my corporal container when I'm no longer
[00:07:20.560 --> 00:07:21.680]   here."
[00:07:21.680 --> 00:07:31.760]   But Aristotle, who coined the word psyche, I think, he was not a dualist, he was a monist.
[00:07:31.760 --> 00:07:38.720]   He thought that the soul was inextricably connected to the body, and he defined soul
[00:07:38.720 --> 00:07:43.880]   as the essence of a natural body that is alive.
[00:07:43.880 --> 00:07:50.080]   And then he goes on and he says, "All right, let me give you an example.
[00:07:50.080 --> 00:07:57.680]   If an ax was alive, the soul of an ax would be to chop.
[00:07:57.680 --> 00:08:04.600]   And if you can pluck your eyeball out of your head and it was still functioning, then the
[00:08:04.600 --> 00:08:08.160]   soul of the eyeball would be to see."
[00:08:08.160 --> 00:08:12.840]   You know, and then he's like, "All right, the soul of a grasshopper is to hop, the soul
[00:08:12.840 --> 00:08:19.000]   of a woodpecker is to peck," which raises the question, of course, what is the essence
[00:08:19.000 --> 00:08:22.680]   of what it means to be human?
[00:08:22.680 --> 00:08:30.720]   And here, of course, there is no one universally accepted conception of the essence of our
[00:08:30.720 --> 00:08:31.720]   humanity.
[00:08:31.720 --> 00:08:39.960]   All right, Aristotle gives us the idea of humans as rational animals, we're homo sapiens.
[00:08:39.960 --> 00:08:44.880]   But not the only game in town, got Joseph Heusinger, an anthropologist in the 20th
[00:08:44.880 --> 00:08:51.720]   century, he called us homo ludens, that were basically fundamentally playful creatures.
[00:08:51.720 --> 00:08:58.640]   And I think it was Hannah Arendt, homo faber, we're tool-making creatures.
[00:08:58.640 --> 00:09:04.680]   Another woman, Ellen Dizanayake, wrote a book called Homo Aestheticus, and following Aristotle
[00:09:04.680 --> 00:09:09.800]   and his poetics, she's like, "Well, we're not only rational animals, we're also aesthetic
[00:09:09.800 --> 00:09:13.280]   creatures that appreciate beauty."
[00:09:13.280 --> 00:09:20.080]   There's another take on humans, I think they call us homo narratans, we're storytelling
[00:09:20.080 --> 00:09:21.440]   creatures.
[00:09:21.440 --> 00:09:29.280]   And I think all of those designations of what it means to be human are quite useful heuristically,
[00:09:29.280 --> 00:09:32.200]   and certainly worthy of our collective cogitation.
[00:09:32.200 --> 00:09:39.200]   But what garnered my attention when I was a young punk was just a single line in an
[00:09:39.200 --> 00:09:47.520]   essay by a Scottish guy, it was Alexander Smith, in a book called Dreamthorpe, I think
[00:09:47.520 --> 00:09:50.360]   it's written in the 1860s.
[00:09:50.360 --> 00:09:55.360]   He just says right in the middle of an essay, "It is our knowledge that we have to die that
[00:09:55.360 --> 00:09:57.280]   makes us human."
[00:09:57.280 --> 00:10:04.260]   And I remember reading that, and in my gut, I was like, "Oh, man, I don't like that,
[00:10:04.260 --> 00:10:06.640]   but I think you're onto something."
[00:10:06.640 --> 00:10:12.640]   And then William James, the great Harvard philosopher, and arguably the first academic
[00:10:12.640 --> 00:10:20.080]   psychologist, he referred to death as the worm at the core of the human condition.
[00:10:20.080 --> 00:10:23.640]   So that's where the worm at the core idea comes in.
[00:10:23.640 --> 00:10:28.040]   And that's just an allusion to the story of Genesis.
[00:10:28.040 --> 00:10:35.920]   Back in the proverbial old days in the Garden of Eden, everything was going tremendously
[00:10:35.920 --> 00:10:42.400]   well, until the serpent tempts Eve to take a chomp out of the apple of the tree of knowledge,
[00:10:42.400 --> 00:10:45.640]   and Adam partakes also.
[00:10:45.640 --> 00:10:51.800]   And this is, according to the Bible, what brings death into the world.
[00:10:51.800 --> 00:11:01.040]   And from our vantage point, the story of Genesis is a remarkable allegorical recount of the
[00:11:01.040 --> 00:11:08.640]   origin of consciousness, where we get to the point where, by virtue of our vast intelligence,
[00:11:08.640 --> 00:11:12.560]   we come to realize the inevitability of death.
[00:11:12.560 --> 00:11:18.920]   And so the apple is beautiful and it's tasty, but when you get right into the middle of
[00:11:18.920 --> 00:11:23.320]   it, there's that ugly reality, which is our finitude.
[00:11:23.320 --> 00:11:31.040]   And then fast forward a bit, and I was a young professor at Skidmore College in 1980.
[00:11:31.040 --> 00:11:38.120]   My PhD is in experimental social psychology, and I mainly did studies with clinical psychologists
[00:11:38.120 --> 00:11:44.200]   evaluating the efficacy of non-pharmacological interventions to reduce stress.
[00:11:44.200 --> 00:11:51.040]   And that was good work, and I found it interesting, but in my first week as a professor at Skidmore,
[00:11:51.040 --> 00:11:57.800]   I, just walking up and down the shelves of the library, saw some books by a guy I had
[00:11:57.800 --> 00:12:02.920]   never heard of, Ernest Becker, a cultural anthropologist, recently deceased.
[00:12:02.920 --> 00:12:06.360]   He died in 1974.
[00:12:06.360 --> 00:12:15.200]   After weeks before, actually, he was posthumously awarded the Pulitzer Prize in nonfiction for
[00:12:15.200 --> 00:12:18.240]   his book, The Denial of Death.
[00:12:18.240 --> 00:12:20.000]   And that was his last book?
[00:12:20.000 --> 00:12:22.200]   It's actually his next to last book.
[00:12:22.200 --> 00:12:27.000]   I don't know how you pull this off, but he had one more after he died called Escape from
[00:12:27.000 --> 00:12:28.380]   Evil.
[00:12:28.380 --> 00:12:32.860]   And evidently it was supposed to, originally The Denial of Death was supposed to be this
[00:12:32.860 --> 00:12:40.480]   giant thousand-page book that was both, and they split it up, and what became Escape from
[00:12:40.480 --> 00:12:44.560]   Evil, his wife, Marie Becker, finished.
[00:12:44.560 --> 00:12:52.560]   Well, be that as it may, it is in The Denial of Death where Becker just says in the first
[00:12:52.560 --> 00:13:01.640]   paragraph, "I believe that the terror of death and the way that human beings respond to it
[00:13:01.640 --> 00:13:09.440]   or decline to respond to it is primarily responsible for almost everything we do, whether we're
[00:13:09.440 --> 00:13:15.200]   aware of it or not, and mostly we're not."
[00:13:15.200 --> 00:13:19.640]   And so I read that first paragraph, Lex, and I was like, "Wow.
[00:13:19.640 --> 00:13:21.760]   Okay, this dude's- You're onto something.
[00:13:21.760 --> 00:13:22.760]   You're onto something.
[00:13:22.760 --> 00:13:23.760]   It's the same thing here.
[00:13:23.760 --> 00:13:25.720]   It's the same thing."
[00:13:25.720 --> 00:13:33.800]   And then it reminded me, I think, not to play psychologist, but let's face it, I believe
[00:13:33.800 --> 00:13:40.120]   there's a reason why we end up drifting where we ultimately come to.
[00:13:40.120 --> 00:13:42.360]   So I'm in my mid-20s.
[00:13:42.360 --> 00:13:48.240]   I got Ernest Becker's book in my hand, and the next thing I know I'm remembering when
[00:13:48.240 --> 00:13:52.200]   I'm eight years old, the day that my grandmother died.
[00:13:52.200 --> 00:13:58.560]   And the day before my mom said, "Oh, say goodbye to grandma.
[00:13:58.560 --> 00:13:59.800]   She's not well."
[00:13:59.800 --> 00:14:03.480]   And so I was like, "Okay, grandma."
[00:14:03.480 --> 00:14:08.280]   And I knew she wasn't well, but I didn't really appreciate the magnitude of her illness.
[00:14:08.280 --> 00:14:14.920]   Well, she dies the next day, and it's in the evening, and I'm just sitting there looking
[00:14:14.920 --> 00:14:17.240]   at my stamp collection.
[00:14:17.240 --> 00:14:20.240]   And I'm like, "Wow, I'm going to miss my grandmother."
[00:14:20.240 --> 00:14:22.040]   And I'm like, "No, wait a minute.
[00:14:22.040 --> 00:14:26.960]   That means my mother's going to die after she gets old.
[00:14:26.960 --> 00:14:28.180]   And that's even worse.
[00:14:28.180 --> 00:14:30.840]   After all, who's going to make me dinner?"
[00:14:30.840 --> 00:14:35.360]   And that bothered me for a while, but then I'm looking at the stamps, all the dead American
[00:14:35.360 --> 00:14:36.360]   presidents.
[00:14:36.360 --> 00:14:38.360]   And I'm like, "There's George Washington.
[00:14:38.360 --> 00:14:39.360]   He's dead.
[00:14:39.360 --> 00:14:40.360]   There's Thomas Jefferson.
[00:14:40.360 --> 00:14:41.360]   He's dead.
[00:14:41.360 --> 00:14:43.360]   My mom's going to be dead.
[00:14:43.360 --> 00:14:48.040]   Oh, I'm going to get old and be dead someday."
[00:14:48.040 --> 00:14:52.960]   And at eight years old, that was my first explicit existential crisis.
[00:14:52.960 --> 00:15:02.240]   I remember it being one of these blood-curdling realizations that I tried my best to ignore
[00:15:02.240 --> 00:15:05.880]   for most of the time I was subsequently growing up.
[00:15:05.880 --> 00:15:14.680]   But fast forward back to Skidmore College, mid-20s, reading Becker's book in the 1980s,
[00:15:14.680 --> 00:15:20.680]   thinking to myself, "Wow, one of the reasons why I'm finding this so compelling is that
[00:15:20.680 --> 00:15:23.760]   it squares with my own personal experience."
[00:15:23.760 --> 00:15:31.560]   And then to make a short story long, and I'll shut up, Lex, but what grabbed me about Becker,
[00:15:31.560 --> 00:15:37.160]   and this is in part because I read a lot of his other books, there's another book, The
[00:15:37.160 --> 00:15:44.560]   Birth and Death of Meaning, which is framed from an evolutionary perspective.
[00:15:44.560 --> 00:15:51.360]   And then The Denial of Death is really more framed from an existential psychodynamic vantage
[00:15:51.360 --> 00:15:52.960]   point.
[00:15:52.960 --> 00:16:05.200]   And as a young academic, I was really taken by what I found to be a very potent juxtaposition
[00:16:05.200 --> 00:16:07.720]   that you really don't see that often.
[00:16:07.720 --> 00:16:15.280]   That usually evolutionary types are eager to dismiss the psychodynamic types and vice
[00:16:15.280 --> 00:16:16.520]   versa.
[00:16:16.520 --> 00:16:24.240]   And maybe only John Bowlby, there's other folks, but the attachment theorist John Bowlby
[00:16:24.240 --> 00:16:32.440]   was really one of the first serious academics to say these ways of thinking about things
[00:16:32.440 --> 00:16:35.160]   are quite compatible.
[00:16:35.160 --> 00:16:39.800]   - Can you comment on what a psychodynamic view of the world is versus an evolutionary
[00:16:39.800 --> 00:16:41.800]   view of the world, just in case people are not aware?
[00:16:41.800 --> 00:16:43.920]   - Oh yeah, absolutely, that's a fine question.
[00:16:43.920 --> 00:16:57.240]   Well, the evolutionary types in general are interested in how it is and why it is that
[00:16:57.240 --> 00:17:04.240]   we have adapted to our surroundings in the service of persisting over time and being
[00:17:04.240 --> 00:17:08.800]   represented in the gene pool thereafter.
[00:17:08.800 --> 00:17:09.800]   - Used to be a fish.
[00:17:09.800 --> 00:17:10.800]   - Yes.
[00:17:10.800 --> 00:17:16.080]   - We used to be a fish, and now we end up talking on a podcast, how we came to be that
[00:17:16.080 --> 00:17:17.080]   way.
[00:17:17.080 --> 00:17:18.480]   - How we came to be that way.
[00:17:18.480 --> 00:17:23.640]   And so, whereas the existential psychodynamic types, I would say, are more interested in
[00:17:23.640 --> 00:17:29.160]   development across a single lifespan.
[00:17:29.160 --> 00:17:37.120]   But the evolutionary types dismiss the psychodynamic types as overly speculative and devoid of
[00:17:37.120 --> 00:17:42.120]   empirical support for their views.
[00:17:42.120 --> 00:17:46.240]   They'll just say, "These guys are talking shit," if you'll pardon the expression.
[00:17:46.240 --> 00:17:52.560]   And of course, you can turn right around and say the same about the evolutionary types.
[00:17:52.560 --> 00:17:58.200]   They are often and rightfully criticized, evolutionary psychologists, for what are called
[00:17:58.200 --> 00:18:06.520]   the just-so stories, where it's like, "Oh, this is probably why fill-in-the-blank is
[00:18:06.520 --> 00:18:09.360]   potentially adaptive."
[00:18:09.360 --> 00:18:20.520]   And my thought, again, early on was I didn't see any intrinsic antithesis between these
[00:18:20.520 --> 00:18:21.520]   viewpoints.
[00:18:21.520 --> 00:18:27.440]   I just found them dialectically compatible and very powerful when combined.
[00:18:27.440 --> 00:18:33.960]   - So one question I would ask here is about science being speculative.
[00:18:33.960 --> 00:18:36.360]   We understand so little about the human mind.
[00:18:36.360 --> 00:18:40.600]   You said you picked up Becker's book, and it felt like it was onto something.
[00:18:40.600 --> 00:18:46.880]   That's the same thing I felt when I picked up Becker's book, probably also in my early
[00:18:46.880 --> 00:18:47.880]   20s.
[00:18:47.880 --> 00:18:54.480]   I read a lot of philosophy, but it felt like the question of the meaning of life kind of...
[00:18:54.480 --> 00:18:59.640]   It seemed to be the closest to the truth somehow.
[00:18:59.640 --> 00:19:00.640]   It was onto something.
[00:19:00.640 --> 00:19:08.160]   So I guess the question I want to ask also is how speculative is psychology?
[00:19:08.160 --> 00:19:13.000]   All of your life's work.
[00:19:13.000 --> 00:19:18.160]   How confident do you feel about the whole thing, about understanding our mind?
[00:19:18.160 --> 00:19:26.160]   - I feel confidently unconfident to have it both ways.
[00:19:26.160 --> 00:19:27.160]   - What do we make of psychology?
[00:19:27.160 --> 00:19:33.280]   What do we make, starting with Freud's, starting just our...
[00:19:33.280 --> 00:19:41.720]   Even just philosophy, even the aspects of the sciences, like my field of artificial
[00:19:41.720 --> 00:19:45.320]   intelligence, but also physics.
[00:19:45.320 --> 00:19:50.800]   It often feels like, "Man, we don't really understand most of what's going on here."
[00:19:50.800 --> 00:19:54.080]   And certainly that's true with the human mind.
[00:19:54.080 --> 00:19:58.000]   - Yeah, well to me that's the proper epistemological stance.
[00:19:58.000 --> 00:20:00.320]   - I don't know anything.
[00:20:00.320 --> 00:20:07.240]   - It's the Socratic, "I know that I don't know," which is the first step on the path
[00:20:07.240 --> 00:20:08.240]   to wisdom.
[00:20:08.240 --> 00:20:18.080]   I would argue forcefully that we know a lot more than we used to.
[00:20:18.080 --> 00:20:24.360]   I would argue equally forcefully, not that I have a PhD in the philosophy of science,
[00:20:24.360 --> 00:20:31.360]   but I believe that the Thomas Kuhns of the world are right when they point out that change
[00:20:31.360 --> 00:20:35.520]   is not necessarily progress.
[00:20:35.520 --> 00:20:42.080]   And so on the one hand, I do think we know a lot more than we did back in the day when
[00:20:42.080 --> 00:20:47.360]   if you wanted to fly, you put on some wax wings and jumped off a mountain.
[00:20:47.360 --> 00:20:56.800]   On the other hand, I think it's quite arrogant when scientists, I'll just speak about psychological
[00:20:56.800 --> 00:21:07.280]   scientists, when they have the audacity to mistake statistical precision for knowledge
[00:21:07.280 --> 00:21:09.760]   and insight.
[00:21:09.760 --> 00:21:17.720]   And when they make the mistake, in my estimation, that Einstein bemoaned, and that's this idea
[00:21:17.720 --> 00:21:26.640]   that the mere accumulation of data will necessarily result in conceptual breakthroughs.
[00:21:26.640 --> 00:21:32.840]   And so I like the, well, we're all, I hope, appreciative of the people who trained us,
[00:21:32.840 --> 00:21:37.440]   but I remember my first day in graduate school at the University of Kansas, they brought
[00:21:37.440 --> 00:21:43.560]   us into a room and on one side of the board was a quote by Kurt Lewin or Levine, famous
[00:21:43.560 --> 00:21:47.520]   German social psychologist.
[00:21:47.520 --> 00:21:51.280]   And the quote is, "There's nothing more useful than a good theory."
[00:21:51.280 --> 00:21:56.120]   And then on the other side was another quote by a German physicist, his name eludes me,
[00:21:56.120 --> 00:21:58.840]   and it was, "All theories are wrong."
[00:21:58.840 --> 00:22:02.480]   And I'm like, which is it?
[00:22:02.480 --> 00:22:06.680]   And of course, the point is that it's both.
[00:22:06.680 --> 00:22:16.040]   Our theories are, I believe, powerful ways to direct our attention to aspects of human
[00:22:16.040 --> 00:22:23.480]   affairs that might render us better able to understand ourselves and the world around
[00:22:23.480 --> 00:22:24.480]   us.
[00:22:24.480 --> 00:22:34.960]   Now, I also, as an experimental psychologist, I adhere to the view that theories are essentially
[00:22:34.960 --> 00:22:42.040]   hypothesis generating devices, and that at its best, science is a dialectical interplay
[00:22:42.040 --> 00:22:49.360]   where you have theoretical assertions that yield testable hypotheses, and that either
[00:22:49.360 --> 00:22:57.960]   results in the corroboration of the theory, the rejection of it, or the modification thereafter.
[00:22:57.960 --> 00:23:05.920]   If we look at the existentialists or even like modern philosopher-psychology types like
[00:23:05.920 --> 00:23:08.080]   Jordan Peterson, I'm not sure if you're familiar with him.
[00:23:08.080 --> 00:23:11.020]   I know Jordan pretty well.
[00:23:11.020 --> 00:23:12.560]   We go way back, actually.
[00:23:12.560 --> 00:23:20.240]   If he were here with us today, he would be jumping in in, I believe, very interesting
[00:23:20.240 --> 00:23:21.920]   and important ways.
[00:23:21.920 --> 00:23:24.440]   But yeah, we go back 30 years ago.
[00:23:24.440 --> 00:23:29.400]   He was basically saying our work is nonsense.
[00:23:29.400 --> 00:23:33.080]   Let's get into this, because I'm sure I'll talk to Jordan eventually on this thing.
[00:23:33.080 --> 00:23:34.080]   Yeah.
[00:23:34.080 --> 00:23:35.080]   Going through some rough times right now.
[00:23:35.080 --> 00:23:38.560]   Oh, absolutely, and I wish him well.
[00:23:38.560 --> 00:23:45.520]   Jordan was working on his maps of meaning, and we were publishing our work.
[00:23:45.520 --> 00:23:55.680]   And I think Jordan at the time was concerned about our vague claims to the effect that
[00:23:55.680 --> 00:23:59.600]   all meaning is arbitrary.
[00:23:59.600 --> 00:24:06.880]   He takes a more Jungian as well as evolutionary view that I don't think is wrong, by the way,
[00:24:06.880 --> 00:24:17.520]   which is that there are certain kinds of meanings that are more important, let's say religious
[00:24:17.520 --> 00:24:26.040]   types, and that we didn't pay sufficient attention to that in our early days.
[00:24:26.040 --> 00:24:30.320]   So can you try to elucidate what his worldview is?
[00:24:30.320 --> 00:24:32.560]   Because he's also a religious man.
[00:24:32.560 --> 00:24:38.240]   So what was some of the interesting aspects of the disagreements then?
[00:24:38.240 --> 00:24:42.240]   Yeah, well, back in the day, I just said, Jordan was a young punk.
[00:24:42.240 --> 00:24:43.240]   We were young punks.
[00:24:43.240 --> 00:24:49.400]   He was just kind of flailing in an animated way at some conferences saying that we-
[00:24:49.400 --> 00:24:51.320]   You're still both kind of punks.
[00:24:51.320 --> 00:24:52.720]   Yeah, we are both kind of punks.
[00:24:52.720 --> 00:24:54.360]   So I saw him three or four years ago.
[00:24:54.360 --> 00:24:56.720]   We spoke on a, it was an awesome day.
[00:24:56.720 --> 00:25:02.840]   We were in Canada at the Ontario Shakespeare Festival where we were asked to be on a Canadian
[00:25:02.840 --> 00:25:05.480]   broadcast system program.
[00:25:05.480 --> 00:25:12.560]   I think we were talking about Macbeth from a psychodynamic perspective.
[00:25:12.560 --> 00:25:18.360]   I hadn't seen him in a ton of years, and we spent two days together, had a great time.
[00:25:18.360 --> 00:25:24.000]   We had just written our book, The Worm at the Core, and he's like, "You're missing a
[00:25:24.000 --> 00:25:27.000]   big opportunity every time you say something.
[00:25:27.000 --> 00:25:31.720]   You have to have your phone and you have to film yourself, and then you have to put it
[00:25:31.720 --> 00:25:32.720]   on YouTube."
[00:25:32.720 --> 00:25:33.720]   Yeah.
[00:25:33.720 --> 00:25:41.160]   He was onto something that just as a small tangent, it's almost sad to look at Jordan
[00:25:41.160 --> 00:25:43.880]   Peterson and somebody like yourself.
[00:25:43.880 --> 00:25:48.160]   After having done this podcast, I've realized that there is really brilliant people in this
[00:25:48.160 --> 00:25:56.280]   world, and oftentimes, especially when they're, I mean it with love, are a little bit like
[00:25:56.280 --> 00:25:57.280]   punks.
[00:25:57.280 --> 00:25:58.280]   That's right.
[00:25:58.280 --> 00:26:03.600]   They kind of do their own thing, and the world doesn't know they exist as much as they should.
[00:26:03.600 --> 00:26:10.040]   It's so interesting because most people are kind of boring.
[00:26:10.040 --> 00:26:14.240]   And then the interesting ones kind of go on their own, and there's not a smartphone recording.
[00:26:14.240 --> 00:26:15.240]   No, no, that's what I'm talking about.
[00:26:15.240 --> 00:26:16.240]   It's so interesting.
[00:26:16.240 --> 00:26:21.240]   He was onto something that, I mean, it's interesting that he, I don't think he was thinking from
[00:26:21.240 --> 00:26:27.920]   a money perspective, but he was probably thinking of connecting with people or sharing his knowledge,
[00:26:27.920 --> 00:26:29.800]   but people don't often think that way.
[00:26:29.800 --> 00:26:30.800]   That's right.
[00:26:30.800 --> 00:26:36.240]   So maybe we can try to get back to, you're both brilliant people, and I'd love to get
[00:26:36.240 --> 00:26:42.880]   some interesting disagreements earlier and later about in your psychological work, in
[00:26:42.880 --> 00:26:43.880]   your worldviews.
[00:26:43.880 --> 00:26:44.880]   Sure.
[00:26:44.880 --> 00:26:52.440]   So my disagreements today would be along two dimensions.
[00:26:52.440 --> 00:27:04.560]   One is, and again, I wish he was here to correct me when I say that he is more committed to
[00:27:04.560 --> 00:27:12.220]   the virtues of the Judeo-Christian tradition, particularly Christianity, and in a sense
[00:27:12.220 --> 00:27:20.600]   is a contemporary Kierkegaard of sorts when he's saying there's only one way to leap into
[00:27:20.600 --> 00:27:22.320]   faith.
[00:27:22.320 --> 00:27:27.960]   And I would take ardent issue with that claim on the grounds that that is one, but by no
[00:27:27.960 --> 00:27:35.840]   means not the only way to find meaning and value in life.
[00:27:35.840 --> 00:27:39.440]   And so, and I see his-
[00:27:39.440 --> 00:27:41.000]   What's his worm at the core?
[00:27:41.000 --> 00:27:46.480]   What is, like, so we're talking about a little bit of a higher level of discovering meaning.
[00:27:46.480 --> 00:27:48.960]   What's his, what does he make of death?
[00:27:48.960 --> 00:27:50.120]   Oh, I don't know.
[00:27:50.120 --> 00:27:54.840]   And this is where it would be nice to have him here.
[00:27:54.840 --> 00:28:02.200]   He has, you know, from a distance criticized our work as misguided.
[00:28:02.200 --> 00:28:07.260]   Having said that though, when we were together, he said something along the lines that there
[00:28:07.260 --> 00:28:16.040]   is no theoretical body of work in academic psychology right now for which there is more
[00:28:16.040 --> 00:28:18.160]   empirical evidence.
[00:28:18.160 --> 00:28:20.040]   And so I appreciated that.
[00:28:20.040 --> 00:28:22.120]   He's a great researcher.
[00:28:22.120 --> 00:28:23.560]   He's a good clinician.
[00:28:23.560 --> 00:28:36.920]   The other thing that we will agree to disagree about rather vociferously is ultimately political/economic.
[00:28:36.920 --> 00:28:41.080]   So I remember being at dinner with him and telling him that the next book that I wanted
[00:28:41.080 --> 00:28:47.120]   to write was going to be called Why Left and Right Are Both Beside the Point.
[00:28:47.120 --> 00:28:52.400]   And my argument was going to be, and it is going to be, that both liberal and political,
[00:28:52.400 --> 00:29:00.280]   no, liberal and conservative political philosophy are each intellectually and morally bankrupt
[00:29:00.280 --> 00:29:06.800]   because they're both framed in terms of assumptions about human nature that are demonstrably false.
[00:29:06.800 --> 00:29:14.680]   And Jordan didn't mind me knocking liberal political philosophy on those grounds.
[00:29:14.680 --> 00:29:19.160]   That would basically be like Steven Pinker's blank slate.
[00:29:19.160 --> 00:29:27.700]   But he took issue when I pointed out that actually it's conservative political philosophy
[00:29:27.700 --> 00:29:33.520]   which starts with John Locke's assumption that in a state of nature there are no societies,
[00:29:33.520 --> 00:29:40.440]   just autonomous individuals who are striving for survival.
[00:29:40.440 --> 00:29:48.000]   That's one of the most obviously patently wrong assertions in the history of intellectual
[00:29:48.000 --> 00:29:49.120]   thought.
[00:29:49.120 --> 00:29:57.440]   And Locke uses that to justify his claims about the individual right to acquire unlimited
[00:29:57.440 --> 00:30:06.160]   amounts of property, which is ultimately the justification for neoliberal economics.
[00:30:06.160 --> 00:30:07.160]   And well--
[00:30:07.160 --> 00:30:09.080]   Can you linger on that a little bit?
[00:30:09.080 --> 00:30:10.080]   Sure.
[00:30:10.080 --> 00:30:16.600]   What's the, can you describe his philosophy again as view of the world and what neoliberal
[00:30:16.600 --> 00:30:17.600]   economics is?
[00:30:17.600 --> 00:30:19.760]   Yeah, let me translate it in English.
[00:30:19.760 --> 00:30:30.680]   So basically on all these days, anybody who says I'm a conservative free market type,
[00:30:30.680 --> 00:30:35.260]   you're following John Locke and Adam Smith, whether you're aware of it or not.
[00:30:35.260 --> 00:30:39.800]   So here's John Locke, who by the way, all of these guys are great.
[00:30:39.800 --> 00:30:45.180]   So for me to appear to criticize any of these folks, it is with the highest regard.
[00:30:45.180 --> 00:30:51.760]   And also we need to understand in my estimation how important their ideas are.
[00:30:51.760 --> 00:30:58.500]   Locke is working in a time where all rule was top down by divine right.
[00:30:58.500 --> 00:31:06.400]   And he's trying desperately to come up with a philosophical justification to shift power
[00:31:06.400 --> 00:31:10.800]   and autonomy to individuals.
[00:31:10.800 --> 00:31:18.920]   And he starts in his second treatise on government, 1690 or so, he says, okay, let's start with
[00:31:18.920 --> 00:31:20.380]   a state of nature.
[00:31:20.380 --> 00:31:27.640]   And he's like, in a state of nature, there's no societies, there's just individuals.
[00:31:27.640 --> 00:31:32.240]   And in a perfect universe, there wouldn't be any societies.
[00:31:32.240 --> 00:31:40.520]   There would just be individuals who by the law of nature have a right to survive.
[00:31:40.520 --> 00:31:49.300]   And in the service of survival, they have the right to acquire and preserve the fruits
[00:31:49.300 --> 00:31:52.580]   of their own labor.
[00:31:52.580 --> 00:31:56.900]   But his point is, and it's actually a good one, he's following Hobbes here.
[00:31:56.900 --> 00:32:00.920]   He's like, well, the problem with that is that people are assholes.
[00:32:00.920 --> 00:32:06.580]   I mean, if they would let each other alone, then we would still be living in a state of
[00:32:06.580 --> 00:32:11.720]   nature, everybody just doing what they did to get by each day.
[00:32:11.720 --> 00:32:18.700]   But it's a whole lot easier if I see like an apple tree a mile away, well, I can go
[00:32:18.700 --> 00:32:21.100]   over and pick an apple.
[00:32:21.100 --> 00:32:25.540]   But if you're 10 meters away with an apple in your hand, it's a lot easier if I pick
[00:32:25.540 --> 00:32:29.660]   up a rock and crack your head and take the apple.
[00:32:29.660 --> 00:32:37.740]   And his point was that the problem is that people can't be counted on to behave.
[00:32:37.740 --> 00:32:41.820]   They will take each other's property.
[00:32:41.820 --> 00:32:52.020]   Moreover, he argued, if someone takes your property, you have the right to retribution
[00:32:52.020 --> 00:32:56.220]   in proportion to the degree of the magnitude of the transgression.
[00:32:56.220 --> 00:33:03.180]   English translation, if I take your apple, you have the right to take an apple back.
[00:33:03.180 --> 00:33:06.340]   You don't have the right to kill my firstborn.
[00:33:06.340 --> 00:33:14.180]   But people being people, they're apt to escalate retaliatory behavior, thus creating what Locke
[00:33:14.180 --> 00:33:16.180]   called a state of war.
[00:33:16.180 --> 00:33:22.420]   So he said, in order to avoid a state of war, people reluctantly give up their freedom in
[00:33:22.420 --> 00:33:24.860]   exchange for security.
[00:33:24.860 --> 00:33:31.220]   They agree to obey the law, and that the sole function of government is to keep domestic
[00:33:31.220 --> 00:33:38.420]   tranquility and to ward off foreign evasion in order to protect our right to property.
[00:33:38.420 --> 00:33:41.620]   So now here's the property thing.
[00:33:41.620 --> 00:33:51.740]   So Locke says, if you look in the Bible and in nature, there is no private property.
[00:33:51.740 --> 00:34:00.020]   But Locke says, well, surely if there's anything that you own, it's your body.
[00:34:00.020 --> 00:34:05.220]   And surely you have a right by nature to stay alive.
[00:34:05.220 --> 00:34:13.360]   And then by extension, anything that you do where you exert effort or labor, that becomes
[00:34:13.360 --> 00:34:14.980]   your private property.
[00:34:14.980 --> 00:34:16.860]   So back to the apple tree.
[00:34:16.860 --> 00:34:23.980]   If I walk over to an apple tree, that's everybody's apples until I pick one.
[00:34:23.980 --> 00:34:26.380]   And the minute I do, that is my apple.
[00:34:26.380 --> 00:34:34.500]   And then he says, you can have as many apples as you want as long as you don't waste them
[00:34:34.500 --> 00:34:42.180]   and as long as you don't impinge on somebody else's right to get apples.
[00:34:42.180 --> 00:34:44.740]   So far, so good.
[00:34:44.740 --> 00:34:58.980]   And then he says, well, okay, in the early days, you could only eat so many apples or
[00:34:58.980 --> 00:35:03.580]   you could only trade so many apples with somebody else.
[00:35:03.580 --> 00:35:09.180]   So he was like, well, if you put a fence around a bunch of apple trees, those become your
[00:35:09.180 --> 00:35:10.180]   apples.
[00:35:10.180 --> 00:35:11.680]   That's your property.
[00:35:11.680 --> 00:35:19.320]   If somebody else wants to put a fence around Nebraska, that's their property.
[00:35:19.320 --> 00:35:27.140]   And everybody can have as much property as they want because the world is so big that
[00:35:27.140 --> 00:35:35.360]   there is no limit to what you can have if you pursue it by virtue of your own effort.
[00:35:35.360 --> 00:35:38.500]   But then he says money came into the picture.
[00:35:38.500 --> 00:35:45.080]   And this is important because he noticed long before anybody, before the Freud's of the
[00:35:45.080 --> 00:35:50.000]   world that money is funky because it has no intrinsic value.
[00:35:50.000 --> 00:35:56.320]   He's like, ooh, look at that shiny piece of metal that actually has, if you're hungry
[00:35:56.320 --> 00:36:00.980]   and you have a choice between a carrot and a lump of gold in the desert, most people
[00:36:00.980 --> 00:36:03.200]   are going to go for the carrot.
[00:36:03.200 --> 00:36:12.540]   But his point is, is that the allure of money is that it's basically a concentrated symbol
[00:36:12.540 --> 00:36:20.340]   of wealth, but because it doesn't spoil, Locke said, you're entitled to have as much money
[00:36:20.340 --> 00:36:23.860]   as you're able to garner.
[00:36:23.860 --> 00:36:32.060]   Then he says, well, the reality is, is that some people are more, the word that he used
[00:36:32.060 --> 00:36:33.700]   was industrious.
[00:36:33.700 --> 00:36:36.700]   He said some people more industrious than others.
[00:36:36.700 --> 00:36:37.700]   All right.
[00:36:37.700 --> 00:36:42.500]   Today, we would say smarter, less lazy, more ambitious.
[00:36:42.500 --> 00:36:44.140]   He just said that's natural.
[00:36:44.140 --> 00:36:46.220]   It's also true.
[00:36:46.220 --> 00:36:54.260]   Therefore he argued, uh, over time, some people are going to have a whole lot of property
[00:36:54.260 --> 00:36:57.180]   and other people, not much at all.
[00:36:57.180 --> 00:37:04.660]   Inequality for Locke is natural and beneficial for everyone.
[00:37:04.660 --> 00:37:11.860]   His argument was that, you know, the rising tide lifts all boats and that the truly creative
[00:37:11.860 --> 00:37:18.460]   and innovative are entitled to relatively unlimited worth because we're all better off
[00:37:18.460 --> 00:37:20.120]   as a result.
[00:37:20.120 --> 00:37:25.160]   So the point very simply is that, well, that's base.
[00:37:25.160 --> 00:37:31.000]   And then you have Adam Smith, you know, in the next century with the invisible hand where
[00:37:31.000 --> 00:37:37.660]   Adam Smith says, everyone pursuing their own selfish, that's not necessarily pejorative.
[00:37:37.660 --> 00:37:44.920]   If everyone pursues their own selfish interests, we will all be better off as a result.
[00:37:44.920 --> 00:37:47.320]   And what do you think is the flaw in that way?
[00:37:47.320 --> 00:37:48.480]   Well, there's two flaws.
[00:37:48.480 --> 00:37:57.480]   One is, is that, um, well, one flaw is first of all, that, that it is based on an erroneous
[00:37:57.480 --> 00:38:01.880]   assumption to begin with, which is that there never was a time in human history when we
[00:38:01.880 --> 00:38:05.260]   were an asocial species.
[00:38:05.260 --> 00:38:10.960]   In a sense, you don't feel like that where there's a, this emphasis of a individual autonomy
[00:38:10.960 --> 00:38:12.840]   is a flawed premise.
[00:38:12.840 --> 00:38:18.560]   Like where there's a, there's something fundamentally deeply, uh, interconnected between us.
[00:38:18.560 --> 00:38:19.560]   I do.
[00:38:19.560 --> 00:38:26.800]   I think that Plato and Socrates, uh, you know, in the Crito were closer to the truth, uh,
[00:38:26.800 --> 00:38:31.940]   when they started with the assumption that we were interdependent, then they derived
[00:38:31.940 --> 00:38:37.480]   individual autonomy as a manifestation of a functional social system.
[00:38:37.480 --> 00:38:38.480]   That's fascinating.
[00:38:38.480 --> 00:38:44.520]   When Margaret Thatcher, you're too young, uh, you know, in the 1980s, she said, societies,
[00:38:44.520 --> 00:38:46.600]   there's no such thing as societies.
[00:38:46.600 --> 00:38:52.160]   There's just individuals pursuing their self-interest.
[00:38:52.160 --> 00:38:57.680]   So, uh, so that's one point where I would take issue respectfully with John Locke.
[00:38:57.680 --> 00:39:04.160]   Point number two is when Locke says in 1690, well, England's filled up.
[00:39:04.160 --> 00:39:09.680]   Um, so if you want some land, just go to America, it's empty.
[00:39:09.680 --> 00:39:13.360]   Or maybe there's a few savages there, just kill them.
[00:39:13.360 --> 00:39:19.760]   So, and Melville does the same thing in Moby Dick where he, he thinks about, will there
[00:39:19.760 --> 00:39:23.840]   ever come a time where we run out of whales?
[00:39:23.840 --> 00:39:27.520]   And he says, no, but we have run out of whales.
[00:39:27.520 --> 00:39:37.360]   And so Locke was right, maybe in 1690 that the world was large and had infinite resources.
[00:39:37.360 --> 00:39:47.860]   He certainly wrong today in, in my opinion, also wrong is the claim that the unlimited
[00:39:47.860 --> 00:39:52.360]   pursuit of personal wealth does not harm those around us.
[00:39:52.360 --> 00:40:00.440]   There is no doubt that radical inequality is tragic psychologically and physically is
[00:40:00.440 --> 00:40:03.240]   poverty is not that terrible.
[00:40:03.240 --> 00:40:07.480]   It's easy for me to say it because I have a place to stay and something to eat.
[00:40:07.480 --> 00:40:14.360]   But as long as you're not starving and have a place to be, poverty is not as challenging
[00:40:14.360 --> 00:40:21.560]   as being, having the impoverished in close proximity to those who are obscenely wealthy.
[00:40:21.560 --> 00:40:27.400]   - So it's not the absolute measure of your wellbeing, it's the inequality of that wellbeing
[00:40:27.400 --> 00:40:29.760]   that's quite painful.
[00:40:29.760 --> 00:40:37.240]   So maybe just to linger on the Jordan Peterson thing, in terms of your disagreement in his
[00:40:37.240 --> 00:40:42.200]   worldview, so he went through quite a bit, you know, there's been quite a bit of fire,
[00:40:42.200 --> 00:40:50.480]   right, in his defense or maybe his opposition of the idea of equality of outcomes.
[00:40:50.480 --> 00:40:57.840]   So looking at the inequality that's in our world, looking at, you know, certain groups
[00:40:57.840 --> 00:41:03.320]   measurably having an outcome that's different than other groups, and then drawing conclusions
[00:41:03.320 --> 00:41:09.520]   about fundamental unfairness, injustice, inequality in the system.
[00:41:09.520 --> 00:41:16.960]   So like systematic racism, systematic sexism, systematic anything else that creates inequality.
[00:41:16.960 --> 00:41:24.560]   And he's been kind of saying pretty simple things to say that, you know, the system for
[00:41:24.560 --> 00:41:29.120]   the most part is not broken or flawed.
[00:41:29.120 --> 00:41:37.720]   That the inequality of outcomes is part of our world, what we should strive for is the,
[00:41:37.720 --> 00:41:39.280]   you know, equality of opportunity.
[00:41:39.280 --> 00:41:44.720]   - Yeah, and I do not dispute that as an abstraction.
[00:41:44.720 --> 00:41:51.240]   But again, to back up for a second, I do take issue with Jordan's fervent devotion to the
[00:41:51.240 --> 00:42:02.200]   free market and his cavalier dismissal of Marxist ideas, which he has, in my estimation,
[00:42:02.200 --> 00:42:06.640]   mischaracterized in his public depictions.
[00:42:06.640 --> 00:42:07.640]   - Let's get into it.
[00:42:07.640 --> 00:42:14.440]   He just seems to really not like socialism, Marxism, communism.
[00:42:14.440 --> 00:42:18.440]   Historically speaking, sort of, I mean, how would I characterize it?
[00:42:18.440 --> 00:42:23.400]   I'm not exactly sure, I don't want to, again, he'll eventually be here to defend himself.
[00:42:23.400 --> 00:42:26.640]   John Locke, unfortunately not here to defend himself.
[00:42:26.640 --> 00:42:36.000]   But what's your sense about Marxism and the way Jordan talks about it, the way you think
[00:42:36.000 --> 00:42:39.640]   about it from the economics, from the philosophical perspective?
[00:42:39.640 --> 00:42:45.600]   - Yeah, well, if we were all here together, I'd say we need to start with Marx's economic
[00:42:45.600 --> 00:42:53.200]   and philosophical manuscripts of 1844, before Marx became more of a polemicist.
[00:42:53.200 --> 00:43:01.640]   And I would argue that Marx's political philosophy, he's a crappy economist, I don't dispute that.
[00:43:01.640 --> 00:43:09.040]   But his arguments about human nature, his arguments about the inevitably catastrophic
[00:43:09.040 --> 00:43:16.240]   psychological and environmental and economic effects of capitalism, I would argue every
[00:43:16.240 --> 00:43:19.880]   one of those has proven quite right.
[00:43:19.880 --> 00:43:31.600]   Marx maybe did not have the answer, but he saw in the 18, whenever he was writing, that
[00:43:31.600 --> 00:43:43.040]   inevitably capitalism would lead to massive inequity, that it was ultimately based on
[00:43:43.040 --> 00:43:50.280]   the need to denigrate and dehumanize labor, to render them in his language, a fleshy cog
[00:43:50.280 --> 00:43:52.520]   in a giant machine.
[00:43:52.520 --> 00:44:00.800]   And that it would create a tension and conflict between those who own things and those who
[00:44:00.800 --> 00:44:07.200]   made things, that over time would always, you know, the Thomas Pickardy guy who writes
[00:44:07.200 --> 00:44:15.200]   about capital and just makes the point that return on investment will always be greater
[00:44:15.200 --> 00:44:17.440]   than wages.
[00:44:17.440 --> 00:44:21.440]   That means the people with money are gonna have a lot more.
[00:44:21.440 --> 00:44:27.080]   That means there's gonna come a point where the economic house of cards falls apart.
[00:44:27.080 --> 00:44:32.000]   Now the Joseph Schumpters of the world, they're like, that's creative destruction, bring it.
[00:44:32.000 --> 00:44:33.000]   That's great.
[00:44:33.000 --> 00:44:36.040]   So I think it's Niles Ferguson, he's a historian.
[00:44:36.040 --> 00:44:38.920]   He may be at Stanford now, he was at Harvard.
[00:44:38.920 --> 00:44:44.820]   He writes about the history of money and he's like, yeah, there's been 20 or whatever depressions
[00:44:44.820 --> 00:44:50.180]   and big recessions in the last several hundred years.
[00:44:50.180 --> 00:44:58.520]   And when that happens, half of the population or whatever is catastrophically inconvenienced,
[00:44:58.520 --> 00:45:03.320]   but that's the price that we pay for progress.
[00:45:03.320 --> 00:45:13.100]   Other people would argue and I would agree with them that I will happily sacrifice the
[00:45:13.100 --> 00:45:20.420]   rate of progress in order to flatten the curve of economic destruction.
[00:45:20.420 --> 00:45:31.900]   To put that in plainer English, I would direct our attention to the social democracies that
[00:45:31.900 --> 00:45:37.140]   forgetting for the moment of whether it's possible to do this on a scale in a country
[00:45:37.140 --> 00:45:45.700]   as big as ours on all of the things that really matter, gross domestic GDP or whatever, that's
[00:45:45.700 --> 00:45:47.460]   just an abstraction.
[00:45:47.460 --> 00:45:54.260]   But when you look at whatever the United Nations says, how we measure quality of life, life
[00:45:54.260 --> 00:46:01.760]   expectancy, education, rates of alcoholism, suicide, and so on, the countries that do
[00:46:01.760 --> 00:46:10.740]   better are the mixed economies, they're market economies that have high tax rates in exchange
[00:46:10.740 --> 00:46:17.500]   for the provision of services that come as a right for citizens.
[00:46:17.500 --> 00:46:24.540]   Yeah, so I mean, I guess the question is, you've kind of mentioned that, you know, as
[00:46:24.540 --> 00:46:30.520]   Marx described capitalism with a slippery slope, eventually things go awry in some kind
[00:46:30.520 --> 00:46:31.520]   of way.
[00:46:31.520 --> 00:46:37.160]   The question is, when you implement a system, how does it go wrong eventually?
[00:46:37.160 --> 00:46:39.760]   You know, eventually we'll all be dead.
[00:46:39.760 --> 00:46:41.760]   That's exactly right.
[00:46:41.760 --> 00:46:44.120]   No, that's right.
[00:46:44.120 --> 00:46:50.400]   And then the criticism, I mean, I think these days, unfortunately, Marxism is a dirty word.
[00:46:50.400 --> 00:46:58.280]   I say unfortunately because even if you disagree with a philosophy, you should, like calling
[00:46:58.280 --> 00:47:04.640]   somebody a Marxist should not be a thing that shuts down all conversation.
[00:47:04.640 --> 00:47:05.840]   No, that's right.
[00:47:05.840 --> 00:47:13.520]   And the fact is, is I'm sympathetic with Jordan's dismissal of the folks, the talking heads
[00:47:13.520 --> 00:47:19.200]   these days who spew Marxist words.
[00:47:19.200 --> 00:47:21.600]   To me, it's like fashionable nonsense.
[00:47:21.600 --> 00:47:25.080]   Do you know that book that the physicist wrote, Mocking?
[00:47:25.080 --> 00:47:26.080]   You're too young.
[00:47:26.080 --> 00:47:28.040]   I think it was 20 or so years ago.
[00:47:28.040 --> 00:47:29.040]   We're all pretty young, relatively.
[00:47:29.040 --> 00:47:30.040]   Yeah, that's right.
[00:47:30.040 --> 00:47:36.120]   But I think there were these NYU physicists, they wrote a paper just mocking the kind of
[00:47:36.120 --> 00:47:39.200]   literary postmodern types.
[00:47:39.200 --> 00:47:40.840]   Oh, those kinds of, yeah.
[00:47:40.840 --> 00:47:42.080]   Yeah, and it was just nonsense.
[00:47:42.080 --> 00:47:46.080]   And of course, it was made the lead article.
[00:47:46.080 --> 00:47:49.720]   And you know, my point is Marx wouldn't be a Marxist.
[00:47:49.720 --> 00:47:50.720]   True.
[00:47:51.440 --> 00:47:56.000]   I've read and listened to some of the work of Richard Wolff.
[00:47:56.000 --> 00:47:58.120]   He speaks pretty eloquently about Marxism.
[00:47:58.120 --> 00:47:59.120]   I like him.
[00:47:59.120 --> 00:48:08.240]   He's one of the only people speaking a lot about Marxism in the way we are now in a serious
[00:48:08.240 --> 00:48:09.240]   way.
[00:48:09.240 --> 00:48:13.900]   And it's sort of saying, you know, what are the flaws of capitalism?
[00:48:13.900 --> 00:48:17.480]   Not saying like, yeah, basically sounding very different.
[00:48:17.480 --> 00:48:18.880]   People should check out his work.
[00:48:18.880 --> 00:48:29.920]   Because all this kind of outrage, mob culture of sort of demanding equality of outcome,
[00:48:29.920 --> 00:48:30.920]   that's not Marxism.
[00:48:30.920 --> 00:48:33.200]   It is not Marxism.
[00:48:33.200 --> 00:48:34.200]   He didn't say that.
[00:48:34.200 --> 00:48:39.320]   You know, he literally said each, what was it, like each according to their needs and
[00:48:39.320 --> 00:48:42.480]   each according to their abilities or something like that.
[00:48:42.480 --> 00:48:44.880]   So the question is the implementation, like.
[00:48:44.880 --> 00:48:45.880]   Absolutely.
[00:48:45.880 --> 00:48:48.520]   Humans are messy, so how does it go wrong?
[00:48:48.520 --> 00:48:50.080]   There you go, Lex.
[00:48:50.080 --> 00:48:51.080]   It's messy.
[00:48:51.080 --> 00:48:52.080]   Brilliant.
[00:48:52.080 --> 00:48:53.080]   It's messy.
[00:48:53.080 --> 00:48:57.640]   And this gets back to my rant about the book that I want to try if I don't stroke out,
[00:48:57.640 --> 00:49:01.360]   why left and right are both beside the point.
[00:49:01.360 --> 00:49:10.600]   You know, the people, conservatives are right when they condemn liberals for being simple
[00:49:10.600 --> 00:49:19.120]   minded by assuming that a modification of external conditions will yield changes in
[00:49:19.120 --> 00:49:20.800]   human nature.
[00:49:20.800 --> 00:49:26.500]   You know, again, that's where Marx and Skinner are odd bedfellows.
[00:49:26.500 --> 00:49:32.860]   You know, here they are just saying, oh, let's change the surroundings and things will inevitably
[00:49:32.860 --> 00:49:34.240]   get better.
[00:49:34.240 --> 00:49:44.120]   On the other hand, when conservatives say that people are innately selfish and they
[00:49:44.120 --> 00:49:51.280]   use that as the justification for glorifying the unbridled pursuit of wealth, well, they're
[00:49:51.280 --> 00:49:58.920]   only half right because it turns out that we can be innately selfish, but we are also
[00:49:58.920 --> 00:50:03.680]   innately generous and reciprocating creatures.
[00:50:03.680 --> 00:50:09.720]   There's remarkable studies, I think they've been done at Yale, of, you know, babies, 14
[00:50:09.720 --> 00:50:12.680]   month old babies.
[00:50:12.680 --> 00:50:20.120]   If someone hands them a toy and then wants something in return, babies before they can
[00:50:20.120 --> 00:50:23.000]   walk and talk will reciprocate.
[00:50:23.000 --> 00:50:26.120]   All right, fine.
[00:50:26.120 --> 00:50:31.480]   If someone, if they want a toy, let's say, or a bottle of water, baby wants a bottle
[00:50:31.480 --> 00:50:40.560]   of water and I look like I'm trying to give it to the baby, but I dropped the bottle so
[00:50:40.560 --> 00:50:47.320]   the baby doesn't get what she or he wanted, when given a chance to reciprocate, little
[00:50:47.320 --> 00:50:54.640]   babies will reciprocate because they're aware of and are responding to intention.
[00:50:54.640 --> 00:51:04.320]   Similarly, if they see somebody behaving unfairly to someone, they will not help that person
[00:51:04.320 --> 00:51:05.960]   in return.
[00:51:05.960 --> 00:51:15.620]   So my point is, yeah, we are selfish creatures at times, but we are also simultaneously uber
[00:51:15.620 --> 00:51:20.280]   social creatures who are eager to reciprocate.
[00:51:20.280 --> 00:51:26.400]   And in fact, we're congenitally prepared to be reciprocators to the point where we will
[00:51:26.400 --> 00:51:32.080]   reciprocate on the basis of intentions above and beyond what actually happens.
[00:51:32.080 --> 00:51:39.960]   - How close, so, I mean, your work is on the fundamental role of the fear of mortality
[00:51:39.960 --> 00:51:42.080]   in ourselves.
[00:51:42.080 --> 00:51:46.840]   How fundamental is this reciprocation, this human connection to other humans?
[00:51:46.840 --> 00:51:48.680]   - Oh, I think it's really innate.
[00:51:48.680 --> 00:51:55.960]   Yeah, I think it's because, yeah, bats reciprocate not by intention, but this, I'm going here
[00:51:55.960 --> 00:52:00.960]   from Richard Dawkins, "The Selfish Gene."
[00:52:00.960 --> 00:52:04.560]   I love the early Dawkins, I'm less enamored with-
[00:52:04.560 --> 00:52:05.880]   - The early Beatles.
[00:52:05.880 --> 00:52:07.200]   - Yeah, no, no, no.
[00:52:07.200 --> 00:52:15.920]   And again, I say this with great respect, but Dawkins just points out that reciprocation
[00:52:15.920 --> 00:52:21.240]   is just fundamental, cooperation is fundamental.
[00:52:21.240 --> 00:52:29.800]   You know, it's a one-sided view of evolutionary takes on things when we see it solely in terms
[00:52:29.800 --> 00:52:32.840]   of individual competition.
[00:52:32.840 --> 00:52:36.920]   - It's almost, from a game theoretic perspective too, it's just easier to see the world that
[00:52:36.920 --> 00:52:37.920]   way.
[00:52:37.920 --> 00:52:43.480]   It's easier to, I don't know, I mean, you see this in physics, there's a whole field
[00:52:43.480 --> 00:52:49.840]   of folks like complexity that kind of embrace the fact that it's all an intricately connected
[00:52:49.840 --> 00:52:55.080]   mess and it's just very difficult to do anything with that kind of science.
[00:52:55.080 --> 00:52:59.040]   But it seems to be much closer to actually representing what the world is like.
[00:52:59.040 --> 00:53:02.680]   - So like you put it earlier, Lex, it's messy.
[00:53:02.680 --> 00:53:06.760]   - So left and right, you mentioned, you're thinking of maybe actually putting it down
[00:53:06.760 --> 00:53:07.760]   on paper or something?
[00:53:07.760 --> 00:53:13.440]   - Yeah, I would like to, because what I would like to point out, again, in admiration of
[00:53:13.440 --> 00:53:18.760]   all of the people that I will then try and have the gall to criticize is, look, these
[00:53:18.760 --> 00:53:20.760]   are all geniuses.
[00:53:20.760 --> 00:53:23.280]   Locke, genius.
[00:53:23.280 --> 00:53:29.760]   Adam Smith, genius, when he uses the notion that we're bartering creatures.
[00:53:29.760 --> 00:53:35.480]   So he uses that reciprocation idea as the basis of his way of thinking about things.
[00:53:35.480 --> 00:53:37.000]   - But that's not at the core.
[00:53:37.000 --> 00:53:39.080]   The bartering's not at the core of human nature.
[00:53:39.080 --> 00:53:41.200]   - It's not at, well, he says it is.
[00:53:41.200 --> 00:53:43.520]   He says we're fundamentally bartering creatures.
[00:53:43.520 --> 00:53:49.360]   - Well, that doesn't even make sense then, because then how can we then be autonomous
[00:53:49.360 --> 00:53:50.360]   individuals?
[00:53:50.360 --> 00:53:53.520]   - Well, because we're gonna barter with an eye on--
[00:53:53.520 --> 00:53:54.520]   - For self.
[00:53:54.520 --> 00:53:55.520]   - For ourselves.
[00:53:55.520 --> 00:53:56.520]   - Self-interest.
[00:53:56.520 --> 00:53:59.880]   - Yeah, but all right, so, but back to Adam Smith for a second, Lex.
[00:53:59.880 --> 00:54:05.520]   It's like Adam Smith, he's got the invisible hand, and my conservative friends, I'm like,
[00:54:05.520 --> 00:54:12.400]   you need to read his books, because he is a big fan of the free market, and this is
[00:54:12.400 --> 00:54:20.720]   my other gripe with folks who support just unbridled markets.
[00:54:20.720 --> 00:54:26.400]   Adam Smith understood that there was a role for government for two reasons.
[00:54:26.400 --> 00:54:33.040]   One is that, just like Locke, people are not gonna behave with integrity, and he understood
[00:54:33.040 --> 00:54:41.600]   that one role of government is to maintain a proverbial even playing field.
[00:54:41.600 --> 00:54:45.760]   And then the other thing Smith said was that there's some things that can't be done well
[00:54:45.760 --> 00:54:53.440]   for a profit, and I believe he talked about education and public health and infrastructure
[00:54:53.440 --> 00:55:02.760]   as things that are best done by governments, because you can make a profit, but that doesn't
[00:55:02.760 --> 00:55:06.920]   mean that the institutions themselves will be maximally beneficial.
[00:55:06.920 --> 00:55:16.800]   Yeah, so I would, I'm just eager to engage people by saying, let's start with our most
[00:55:16.800 --> 00:55:27.280]   contemporary understanding of human nature, which is that we are both selfish and tend
[00:55:27.280 --> 00:55:40.680]   to cooperate, and we also can be heroically helpful to folks in our own tribe.
[00:55:40.680 --> 00:55:47.880]   And of course, how you define one's tribe becomes critically important.
[00:55:47.880 --> 00:55:55.760]   But what some people say is, look, what would then be, what kind of political institutions
[00:55:55.760 --> 00:56:04.040]   and what kind of economic organization can we think about to kind of hit that sweet spot?
[00:56:04.040 --> 00:56:12.120]   And that would be, in my opinion, how do we maximize individual autonomy in a way that
[00:56:12.120 --> 00:56:21.200]   fosters creativity and innovation and the self-regard that comes from creative expression,
[00:56:21.200 --> 00:56:31.720]   while engaging our more cooperative and reciprocal tendencies in order to come up with a system
[00:56:31.720 --> 00:56:35.320]   that is potentially stable over time?
[00:56:35.320 --> 00:56:38.480]   Because the other thing about all capital-based systems-
[00:56:38.480 --> 00:56:41.160]   The stability, it's fundamentally unstable.
[00:56:41.160 --> 00:56:46.520]   Yeah, because it's based on infinite growth, and it's a positive feedback loop.
[00:56:46.520 --> 00:56:53.080]   To be silly, infinite growth is only good for malignant cancer cells and compound interest.
[00:56:53.080 --> 00:56:59.920]   Otherwise, we want to seek a steady state.
[00:56:59.920 --> 00:57:06.040]   So when Steven Pinker writes, for example, again, great scholar, but I'm going to disagree
[00:57:06.040 --> 00:57:13.600]   when he says the world has never been better, and all we need to do is keep making stuff
[00:57:13.600 --> 00:57:14.600]   and buying stuff.
[00:57:14.600 --> 00:57:24.800]   So your sense is the world, sort of in disagreement with Steven Pinker, that the world is facing
[00:57:24.800 --> 00:57:28.880]   a potential catastrophic collapse in multiple directions?
[00:57:28.880 --> 00:57:29.880]   Yes.
[00:57:29.880 --> 00:57:34.680]   And the fact that there are certain, like the rate of violence in aggregate is decreasing,
[00:57:34.680 --> 00:57:41.000]   the death, the quality of life, all those kinds of measures that you can plot across
[00:57:41.000 --> 00:57:45.920]   centuries that it's improving, that doesn't capture the fact that our world might be-
[00:57:45.920 --> 00:57:52.200]   We might destroy ourselves in very painful ways in the next century.
[00:57:52.200 --> 00:57:59.620]   So I'm with Jared Diamond in the book "Collapse," where he points out, studying the collapse
[00:57:59.620 --> 00:58:05.880]   of major civilizations, that it often happens right after things appear to never have been
[00:58:05.880 --> 00:58:07.840]   better.
[00:58:07.840 --> 00:58:15.720]   And in that regard, I mean, there are more known voices that have taken issue with Dr.
[00:58:15.720 --> 00:58:16.720]   Pinker.
[00:58:16.720 --> 00:58:23.400]   I'm thinking of John Gray, who's a British philosopher, and here in the States, I don't
[00:58:23.400 --> 00:58:27.040]   know where he is these days, but Robert J. Lifton, the psycho historian.
[00:58:27.040 --> 00:58:33.840]   Yeah, they're both of my view, which I hope is, by the way, wrong.
[00:58:33.840 --> 00:58:35.400]   Me too.
[00:58:35.400 --> 00:58:47.520]   No, but between ongoing ethnic tensions, environmental degradation, economic instability, and the
[00:58:47.520 --> 00:58:53.120]   fact that the world has become a Petri dish of psychopathology.
[00:58:53.120 --> 00:58:59.460]   What really worries me is the quiet economic pain that people are going through, the businesses
[00:58:59.460 --> 00:59:03.840]   that are closed, dreams that are broken because you can no longer do the thing that you've
[00:59:03.840 --> 00:59:10.600]   wanted to do, and how, I mentioned to you off camera that I've been reading "The Rise
[00:59:10.600 --> 00:59:20.440]   and Fall of the Third Reich," and I mean, the amount of anger and hatred, and on the
[00:59:20.440 --> 00:59:26.880]   flip side of that, sort of a nationalist pride that can arise from deep economic pain.
[00:59:26.880 --> 00:59:30.380]   What happens with that economic pain is you become bitter.
[00:59:30.380 --> 00:59:36.400]   You start to find the other, whether it's other European nations that mistreated you,
[00:59:36.400 --> 00:59:41.800]   whether it's other groups that mistreated you, it always ends up being the Jews that
[00:59:41.800 --> 00:59:45.200]   somehow are at fault here.
[00:59:45.200 --> 00:59:53.920]   That's what worries me, is where this quiet anger and pain goes in 2021, 2022, 2030.
[00:59:53.920 --> 00:59:57.960]   If you look, sorry to see the parallels.
[00:59:57.960 --> 01:00:04.660]   "The Rise and Fall of the Third Reich," but what happens 10, 15 years from now from what's,
[01:00:04.660 --> 01:00:08.260]   because of the COVID pandemic that's happening now?
[01:00:08.260 --> 01:00:12.860]   And Lex, you make, I think, a really profoundly important point.
[01:00:12.860 --> 01:00:19.420]   Back to our work for a bit, or Ernest Becker, rather, his point is that the way that we
[01:00:19.420 --> 01:00:28.740]   manage existential terror is to embrace culturally constructed belief systems that give us a
[01:00:28.740 --> 01:00:32.640]   sense that life has meaning and we have value.
[01:00:32.640 --> 01:00:38.720]   And in the form of self-esteem, which we get from perceiving that we meet or exceed the
[01:00:38.720 --> 01:00:45.360]   expectations associated with the role that we play in society, well, here we are right
[01:00:45.360 --> 01:00:50.800]   now in a world where, first of all, if you have nothing, you are nothing.
[01:00:50.800 --> 01:00:58.740]   And secondly, as you were saying before we got started today, a lot of jobs are gone
[01:00:58.740 --> 01:01:00.840]   and they're not coming back.
[01:01:00.840 --> 01:01:02.320]   And that's where the self-esteem-
[01:01:02.320 --> 01:01:04.640]   That's where the self-esteem and identity come in.
[01:01:04.640 --> 01:01:09.160]   With people, it's not only that you don't have anything to eat, you don't even have
[01:01:09.160 --> 01:01:12.200]   a self anymore to speak of.
[01:01:12.200 --> 01:01:17.920]   Because we typically define ourselves, as Marx put it, you are what you do.
[01:01:17.920 --> 01:01:25.140]   And now who are you when your way of life as well as your way of earning a living is
[01:01:25.140 --> 01:01:26.480]   no longer available?
[01:01:26.480 --> 01:01:31.040]   Yeah, and it feels like that yearning for self-esteem, though we could talk a little
[01:01:31.040 --> 01:01:37.280]   bit more because you, about defining self-esteem is quite interesting.
[01:01:37.280 --> 01:01:43.240]   The more I've read, so to warm up the core and just in general, your thinking, it made
[01:01:43.240 --> 01:01:46.000]   me realize I haven't thought enough about the idea of self-esteem.
[01:01:46.000 --> 01:01:54.160]   But the thing I want to say is it feels like when you lose your job, then it's easy to
[01:01:54.160 --> 01:02:04.520]   find, it's tempting to find that self-esteem in a tribe that's not somehow often positive.
[01:02:04.520 --> 01:02:05.520]   That's exactly-
[01:02:05.760 --> 01:02:09.040]   A tribe that defines itself on the hatred of somebody else.
[01:02:09.040 --> 01:02:10.040]   So that's brilliant.
[01:02:10.040 --> 01:02:16.480]   And this is what John Gray, the philosopher in the 1990s, he predicted what's happening
[01:02:16.480 --> 01:02:17.480]   today.
[01:02:17.480 --> 01:02:20.520]   He wrote a book about globalism.
[01:02:20.520 --> 01:02:27.880]   And actually, Hannah Arendt in the 1950s said the same thing in her book about totalitarianism.
[01:02:27.880 --> 01:02:37.640]   And she said that economics has reached the point where most money is made not by actually
[01:02:37.640 --> 01:02:39.840]   making stuff.
[01:02:39.840 --> 01:02:42.880]   You use money to make money.
[01:02:42.880 --> 01:02:51.760]   And therefore, what happens is money chases money across national boundaries.
[01:02:51.760 --> 01:03:00.240]   Ultimately, governments become subordinate to the corporate entities whose sole function
[01:03:00.240 --> 01:03:03.480]   is to generate money.
[01:03:03.480 --> 01:03:11.320]   And what John Gray said is that that will inevitably produce economic upheaval in local
[01:03:11.320 --> 01:03:19.460]   areas, which will not be attributed to the economic order.
[01:03:19.460 --> 01:03:30.160]   It will be misattributed to whoever the scapegoat du jour is, and the anger and the distress
[01:03:30.160 --> 01:03:39.240]   associated with that uncertainty will be picked up on by ideological demagogues who will transform
[01:03:39.240 --> 01:03:41.220]   that into rage.
[01:03:41.220 --> 01:03:48.360]   So both Hannah Arendt as well as John Gray, they just said, "Watch out.
[01:03:48.360 --> 01:03:57.160]   We're going to have right-wingish populist movements where demagogues who are the alchemists
[01:03:57.160 --> 01:04:05.000]   of hate, what makes them brilliant is they don't  the hate's already there, but
[01:04:05.000 --> 01:04:13.280]   they take the fears and they expertly redirect them to who it is that I need to hate and
[01:04:13.280 --> 01:04:16.680]   kill in order to feel good about myself."
[01:04:16.680 --> 01:04:19.400]   So back to your point, Lex, that's right.
[01:04:19.400 --> 01:04:27.680]   So the self-regard that used to come from having a job and doing it well, and as a result
[01:04:27.680 --> 01:04:34.440]   of that, having adequate resources to provide a decent life for your family, well, those
[01:04:34.440 --> 01:04:40.000]   opportunities are gone, and yeah, what's left?
[01:04:40.000 --> 01:04:47.800]   So Max Weber, German sociologist at the beginning of the 20th century, he said in times of historical
[01:04:47.800 --> 01:04:50.880]   upheaval, "We are apt to embrace."
[01:04:50.880 --> 01:04:58.080]   He was the one who coined the term charismatic leader, seemingly larger-than-life individuals
[01:04:58.080 --> 01:05:03.920]   who often believe or their followers believe are divinely ordained to rid the world of
[01:05:03.920 --> 01:05:04.920]   evil.
[01:05:04.920 --> 01:05:05.920]   All right.
[01:05:05.920 --> 01:05:14.480]   Now, Ernest Becker, he used Weber's ideas in order to account for the rise of Hitler.
[01:05:14.480 --> 01:05:20.800]   Hitler was elected, and he was elected when Germans were in an extraordinary state of
[01:05:20.800 --> 01:05:27.160]   existential distress, and he said, "I'm going to make Germany great again."
[01:05:27.160 --> 01:05:28.160]   All right.
[01:05:28.160 --> 01:05:36.440]   Now, what Becker adds to the equation is his claim that what underlies our affection for
[01:05:36.440 --> 01:05:42.440]   charismatic populist leaders, good and bad, is death anxiety.
[01:05:42.440 --> 01:05:44.000]   All right.
[01:05:44.000 --> 01:05:45.520]   Now here's where we come in.
[01:05:45.520 --> 01:05:49.240]   We're egghead experimental researchers.
[01:05:49.240 --> 01:05:54.440]   You know, Becker wrote this book, The Denial of Death, and he couldn't get a job.
[01:05:54.440 --> 01:06:02.480]   People just dismiss these ideas as fanciful speculation for which there's no evidence.
[01:06:02.480 --> 01:06:04.480]   You've done some good experimental work.
[01:06:04.480 --> 01:06:10.520]   Yeah, and here's where I can be more cavalier and where what I would urge people, like what
[01:06:10.520 --> 01:06:19.380]   you said, Lex, is ignore my histrionic and polemic language if possible, and step back,
[01:06:19.380 --> 01:06:28.520]   if you can, myself included, and let's just consider the research findings, because in
[01:06:28.520 --> 01:06:36.480]   September 11th, 2001, people that are old enough to remember that horrible day, two
[01:06:36.480 --> 01:06:43.440]   days before George W. Bush had the lowest approval rating in the history of presidential
[01:06:43.440 --> 01:06:50.400]   polling, three weeks later, after he said, "We will rid the world of the evildoers,"
[01:06:50.400 --> 01:06:55.480]   and then a week or two after that, he said in a cover story on Time magazine that he
[01:06:55.480 --> 01:07:01.280]   believed that God had chosen him to lead the world during this, to lead the country, rather,
[01:07:01.280 --> 01:07:05.600]   during this perilous time, he had the highest approval rating.
[01:07:05.600 --> 01:07:08.420]   And so we're like, "Well, what happened?"
[01:07:08.420 --> 01:07:15.280]   You know, what happened to Americans that their approval of President Bush got so high
[01:07:15.280 --> 01:07:16.280]   so fast?
[01:07:16.280 --> 01:07:24.520]   Well, our view, following Becker, is that 2001 was like a giant death reminder.
[01:07:24.520 --> 01:07:32.420]   The people dying plus the symbols of American greatness, World Trade Center and the Pentagon.
[01:07:32.420 --> 01:07:36.760]   So we did a bunch of experiments, and most of our experiments are disarmingly simple.
[01:07:36.760 --> 01:07:41.280]   We have one group of people, and we just remind them that they're going to die.
[01:07:41.280 --> 01:07:44.680]   We say, "Hey, write your thoughts and feelings about dying."
[01:07:44.680 --> 01:07:50.720]   Or in other cases, we stop them outside, either in front of a funeral home or 100 meters to
[01:07:50.720 --> 01:07:55.680]   either side, our thought being that if we stop you in front of a funeral home, then
[01:07:55.680 --> 01:07:58.760]   death is on your mind, even if you don't know it.
[01:07:58.760 --> 01:08:02.240]   And then there's other studies that are even more subtle, where we bring people into the
[01:08:02.240 --> 01:08:08.920]   lab and they read stuff on a computer, and while they're doing that, we flash the word
[01:08:08.920 --> 01:08:11.920]   "death" for 28 milliseconds.
[01:08:11.920 --> 01:08:14.640]   It's so fast, you don't see anything.
[01:08:14.640 --> 01:08:20.180]   And then we just measure people's reactions or behavior thereafter.
[01:08:20.180 --> 01:08:28.720]   So what we found in 2003, leading up to the election of 2004, was that Americans did not
[01:08:28.720 --> 01:08:36.200]   care for President Bush or his policies in Iraq in control conditions.
[01:08:36.200 --> 01:08:42.080]   But if we reminded them of their mortality first, they liked Bush a lot more.
[01:08:42.080 --> 01:08:48.360]   So in every study that we did, Americans like John Kerry, who was running against Bush,
[01:08:48.360 --> 01:08:51.640]   they like Kerry more than Bush.
[01:08:51.640 --> 01:08:52.920]   Policy-wise, in a control...
[01:08:52.920 --> 01:08:55.520]   In a control condition.
[01:08:55.520 --> 01:09:02.000]   But if they were reminded of death first, then they like Bush a lot more.
[01:09:02.000 --> 01:09:06.200]   So by the way, just a small pause, you said there are disarmingly simple experiments.
[01:09:06.200 --> 01:09:11.000]   I think that's... and people should read Warm at the Core for some other description.
[01:09:11.000 --> 01:09:13.920]   You have a lot of different experiments of this nature.
[01:09:13.920 --> 01:09:22.840]   I think it's a brilliant experiment, connected to the Stoics, perhaps, of how your worldview
[01:09:22.840 --> 01:09:28.840]   on anything, on how delicious that water tastes, after you're reminded of your own mortality.
[01:09:28.840 --> 01:09:33.920]   It's such a fascinating experiment that you could probably keep doing millions of them
[01:09:33.920 --> 01:09:39.000]   to draw insight about the way we see the world.
[01:09:39.000 --> 01:09:40.000]   No, that's right, Lex.
[01:09:40.000 --> 01:09:47.920]   And I appreciate the compliment, not because we did anything, but because what these studies,
[01:09:47.920 --> 01:09:54.360]   many of which are now done by other people around the world in labs that we're not connected
[01:09:54.360 --> 01:09:59.480]   with, what I'm most proud about our work, I am proud of the experiments that we've done,
[01:09:59.480 --> 01:10:05.400]   but it's not science until somebody else can replicate your findings, and independent researchers
[01:10:05.400 --> 01:10:08.000]   are interested in pursuing them.
[01:10:08.000 --> 01:10:09.880]   It's such a fascinating idea.
[01:10:09.880 --> 01:10:10.880]   I don't...
[01:10:10.880 --> 01:10:16.840]   I have to think about, a lot about the experiments you've done, and that you've inspired, about
[01:10:16.840 --> 01:10:21.840]   the fact that death changes the way you see a bunch of different things.
[01:10:21.840 --> 01:10:27.940]   I think the Stoics talked about, I mean, in general, just memento mori, like just thinking
[01:10:27.940 --> 01:10:36.800]   about death and meditating on death is a really positive, not a positive, it's an enlightening
[01:10:36.800 --> 01:10:40.560]   way to live life.
[01:10:40.560 --> 01:10:45.280]   So what do you think about that at the individual level?
[01:10:45.280 --> 01:10:51.800]   What is the role about bringing that terror of death, fear of death to the surface, and
[01:10:51.800 --> 01:10:53.000]   being cognizant of it?
[01:10:53.000 --> 01:10:57.200]   For us, that's the ballgame.
[01:10:57.200 --> 01:11:06.540]   So what we write in our book, and here we're just paying homage to the philosophers and
[01:11:06.540 --> 01:11:16.840]   theologians that come before us, is to point out that literally since antiquity, there
[01:11:16.840 --> 01:11:25.240]   has been a consensus that to lead a full life requires...
[01:11:25.240 --> 01:11:32.080]   Albert Camus said, "Come to terms with death, thereafter anything is possible."
[01:11:32.080 --> 01:11:39.320]   So you've got the Stoics, and you've got the Epicureans, and then you've got the Tibetan
[01:11:39.320 --> 01:11:46.600]   Book of the Dead, and then you've got the medieval monks that worked with a skull on
[01:11:46.600 --> 01:11:49.560]   their desk.
[01:11:49.560 --> 01:11:56.840]   The whole idea, I should back up a bit, because and just remind folks that our studies, when
[01:11:56.840 --> 01:12:03.080]   we remind people that they're going to die, and we find that, yeah, they drink more water
[01:12:03.080 --> 01:12:09.600]   if a famous person is advertising it.
[01:12:09.600 --> 01:12:11.400]   They eat more cookies.
[01:12:11.400 --> 01:12:14.380]   They want more fancy clothes.
[01:12:14.380 --> 01:12:17.600]   They sit closer to people that look like them.
[01:12:17.600 --> 01:12:19.320]   It changes who they vote for.
[01:12:19.320 --> 01:12:23.300]   But all of those things, those are very subtle death reminders.
[01:12:23.300 --> 01:12:26.200]   You don't even know that death is on your mind.
[01:12:26.200 --> 01:12:33.720]   And so our point is that, and this is kind of counterintuitive, and that is that the
[01:12:33.720 --> 01:12:41.720]   most problematic and unsavory human reactions to death anxiety are malignant manifestations
[01:12:41.720 --> 01:12:44.560]   of repressed death anxiety.
[01:12:44.560 --> 01:12:49.200]   We try and bury it under the psychological bushes, and then it comes back to bear bitter
[01:12:49.200 --> 01:12:50.320]   fruit.
[01:12:50.320 --> 01:12:58.560]   But what the theologians and the philosophers of the world are saying is it behooves each
[01:12:58.560 --> 01:13:02.620]   of us to spend considerable time.
[01:13:02.620 --> 01:13:11.100]   You don't have to be a goth death rocker, you know, wallowing in death imagery to spend
[01:13:11.100 --> 01:13:18.280]   enough time entertaining the reality of the human condition, which is that you too will
[01:13:18.280 --> 01:13:31.120]   pass, to get to the point where there is, to lapse into a cliche, the capacity for personal
[01:13:31.120 --> 01:13:36.240]   transformation and growth.
[01:13:36.240 --> 01:13:39.160]   Let's go personal for a second.
[01:13:39.160 --> 01:13:42.280]   Are you yourself afraid of death?
[01:13:42.280 --> 01:13:43.280]   Yeah.
[01:13:43.280 --> 01:13:48.960]   I mean, and how much do you meditate on that thought?
[01:13:48.960 --> 01:13:53.720]   Maybe your own study of it is a kind of escape from your own mortality.
[01:13:53.720 --> 01:13:55.000]   It is absolutely, Lex.
[01:13:55.000 --> 01:13:57.480]   So you've got it.
[01:13:57.480 --> 01:13:59.800]   Like if you figure out death, somehow you won't die.
[01:13:59.800 --> 01:14:01.180]   So no, no.
[01:14:01.180 --> 01:14:07.040]   So my colleagues and good friends, Jeff Greenberg and Tom Pazinski, we met in graduate school
[01:14:07.040 --> 01:14:08.520]   in the 1970s.
[01:14:08.520 --> 01:14:15.960]   We've been doing this work for 40 years and we cheerfully admit, even though it doesn't
[01:14:15.960 --> 01:14:23.000]   reflect well on us as humans, that I should just speak for myself, but I feel like there's
[01:14:23.000 --> 01:14:31.480]   a real sense in which doing these studies and writing books and lecturing has been my
[01:14:31.480 --> 01:14:41.320]   way of avoiding directly confronting my anxieties by turning it into an intellectual exercise.
[01:14:41.320 --> 01:14:47.240]   And every once in a while, therefore, when I think that I'm making some progress as a
[01:14:47.240 --> 01:14:57.880]   human, I have to remind myself that that is probably not the case and that I have at times,
[01:14:57.880 --> 01:15:03.400]   like all humans, been more preoccupied with the implications of these ideas for my self-esteem.
[01:15:03.400 --> 01:15:11.000]   It's like, "Oh, we're going to write a book and maybe we'll get to go on TV or something."
[01:15:11.000 --> 01:15:21.240]   Well, no, that's not the same as to actually think about it in a way that you feel it rather
[01:15:21.240 --> 01:15:22.920]   than just think it.
[01:15:22.920 --> 01:15:24.960]   Yeah, like you did when you were eight.
[01:15:24.960 --> 01:15:27.560]   That's exactly right.
[01:15:27.560 --> 01:15:34.760]   So when I first read The Denial of Death, I was so literally flabbergasted by it that
[01:15:34.760 --> 01:15:41.840]   I took a leave of absence for a year and just did what would be considered menial jobs.
[01:15:41.840 --> 01:15:51.400]   I did construction work, I worked in a restaurant, and I was just like, "Wait a minute.
[01:15:51.400 --> 01:16:00.760]   If I understand what this guy is saying, then I'm just a culturally constructed meat puppet
[01:16:00.760 --> 01:16:07.080]   doing things for reasons that I know not in order to assuage death anxiety."
[01:16:07.080 --> 01:16:10.880]   And I was like, "That's not acceptable."
[01:16:10.880 --> 01:16:16.680]   Maybe another interesting person to talk about is Ernest Becker himself.
[01:16:16.680 --> 01:16:21.280]   So how did he face his death?
[01:16:21.280 --> 01:16:25.040]   Is there something interesting, personal?
[01:16:25.040 --> 01:16:26.040]   I think so.
[01:16:26.040 --> 01:16:40.240]   So interesting to me is Becker, also from a Jewish family, claimed to be atheistic,
[01:16:40.240 --> 01:16:44.000]   did not identify ultimately as Jewish.
[01:16:44.000 --> 01:16:51.400]   I believe he converted to Christianity, but was himself a religious person, and he said
[01:16:51.400 --> 01:16:55.880]   he became religious when his first child was born.
[01:16:55.880 --> 01:16:58.680]   Now religious, what does that mean?
[01:16:58.680 --> 01:17:01.800]   Does he have a faith?
[01:17:01.800 --> 01:17:05.080]   Let's talk more, most importantly, is the afterlife.
[01:17:05.080 --> 01:17:09.720]   He was agnostic on that.
[01:17:09.720 --> 01:17:21.400]   But he did, now the denial of death is, there's a chapter devoted to Kierkegaard, and he talks
[01:17:21.400 --> 01:17:30.240]   about for Kierkegaard, if you wanna become a mature individual, if you wanna learn something,
[01:17:30.240 --> 01:17:32.540]   you go to the university.
[01:17:32.540 --> 01:17:38.240]   If you wanna become a more mature individual, according to Kierkegaard, you gotta go to
[01:17:38.240 --> 01:17:41.520]   the school of anxiety.
[01:17:41.520 --> 01:17:47.360]   What Kierkegaard said is that we have to let this vague dis-ease, put a hyphen between
[01:17:47.360 --> 01:17:51.360]   dis and ease, about death.
[01:17:51.360 --> 01:17:57.320]   Kierkegaard's point is you have to really think about that.
[01:17:57.320 --> 01:17:59.360]   You have to think about it and feel it.
[01:17:59.360 --> 01:18:11.640]   You gotta let it seep into your mind, at which point, according to Kierkegaard, basically
[01:18:11.640 --> 01:18:18.640]   you realize that your present identity is fundamentally a cultural construction.
[01:18:18.640 --> 01:18:20.920]   You didn't choose the time and place of your birth.
[01:18:20.920 --> 01:18:23.600]   You didn't choose your name.
[01:18:23.600 --> 01:18:28.720]   You didn't choose necessarily even the social role that you occupy.
[01:18:28.720 --> 01:18:34.040]   You might've chosen from what's available in your culture, but not from the full palette
[01:18:34.040 --> 01:18:36.880]   of human opportunities.
[01:18:36.880 --> 01:18:46.480]   What Kierkegaard said is that we need to realize that we've been living a lie of sorts.
[01:18:46.480 --> 01:18:50.600]   Becker calls it a necessary lie.
[01:18:50.600 --> 01:18:55.200]   We have to momentarily dispose of that.
[01:18:55.200 --> 01:18:57.800]   Now Kierkegaard says, "Well, here I am.
[01:18:57.800 --> 01:19:08.400]   I have shrugged off all of the cultural accoutrements that I have used to define myself.
[01:19:08.400 --> 01:19:11.320]   Now what am I or who am I?"
[01:19:11.320 --> 01:19:19.440]   This is like the ancient Greek tragedy where the worst thing was to be no one or no thing.
[01:19:19.440 --> 01:19:26.040]   At this point, Kierkegaard said, you're really dangling on the precipice of oblivion.
[01:19:26.040 --> 01:19:31.620]   Some people tumble into that abyss and never come out.
[01:19:31.620 --> 01:19:37.060]   On the other hand, Kierkegaard said that what you can now do metaphorically and literally
[01:19:37.060 --> 01:19:41.320]   is to rebuild yourself from the ground up.
[01:19:41.320 --> 01:19:46.840]   In the New Testament, there's something you have to die in order to be reborn.
[01:19:46.840 --> 01:19:50.040]   Kierkegaard's view though is that there's only one way to do that.
[01:19:50.040 --> 01:19:54.200]   This is his proverbial leap into faith.
[01:19:54.200 --> 01:20:02.960]   In Kierkegaard's case, it was faith in Christianity, that you can't have unbridled faith in cultural
[01:20:02.960 --> 01:20:04.580]   constructions.
[01:20:04.580 --> 01:20:13.480]   The only thing that you can have unequivocal faith in is some kind of transcendent power.
[01:20:13.480 --> 01:20:20.960]   But of course, this raises the question of, well, is that just another death-denying belief
[01:20:20.960 --> 01:20:22.440]   system?
[01:20:22.440 --> 01:20:30.480]   At the end of the denial of death, Becker admits that there's no way to tell while still
[01:20:30.480 --> 01:20:36.680]   advocating for what is ultimately a religious stance.
[01:20:36.680 --> 01:20:42.440]   One of the things that I don't understand, and Becker has been the most singularly potent
[01:20:42.440 --> 01:20:50.920]   influence in my academic and personal life, but a year or two ago, I started reading Martin
[01:20:50.920 --> 01:20:51.920]   Heidegger.
[01:20:51.920 --> 01:21:02.960]   I'm reading Being and Time, and what I now wonder is why Becker, who refers to Heidegger
[01:21:02.960 --> 01:21:09.840]   from time to time in his work, why he didn't take Heidegger more seriously, because Heidegger
[01:21:09.840 --> 01:21:12.320]   is like a secular Kierkegaard.
[01:21:12.320 --> 01:21:15.600]   He has the same thing, which is death anxiety.
[01:21:15.600 --> 01:21:20.680]   Oh, and I should have pointed out that what Kierkegaard says is that death anxiety, most
[01:21:20.680 --> 01:21:25.000]   people don't go to the school of anxiety.
[01:21:25.000 --> 01:21:32.000]   They flee from death anxiety by embracing their cultural beliefs.
[01:21:32.000 --> 01:21:37.040]   Kierkegaard says they then tranquilize themselves with the trivial.
[01:21:37.040 --> 01:21:38.040]   And I love that phrase.
[01:21:38.040 --> 01:21:42.280]   It's a beautiful phrase, because at the end of the denial of death, Becker's like, "Oh,
[01:21:42.280 --> 01:21:47.320]   wait, look, the average American is either drinking or shopping or watching television,
[01:21:47.320 --> 01:21:50.320]   and they're all the same thing."
[01:21:50.320 --> 01:21:51.640]   Heidegger says the same thing.
[01:21:51.640 --> 01:21:54.680]   He says, "Look," and he acknowledges Kierkegaard.
[01:21:54.680 --> 01:22:01.680]   He says, "What makes us feel unsettled," and evidently that's an English translation of
[01:22:01.680 --> 01:22:08.200]   angst, that it's, "We don't feel at home in the world."
[01:22:08.200 --> 01:22:11.280]   Heidegger says that's death anxiety.
[01:22:11.280 --> 01:22:15.280]   And one direction is the Kierkegaard one.
[01:22:15.280 --> 01:22:17.880]   Heidegger calls it a flight from death.
[01:22:17.880 --> 01:22:23.960]   You just unselfreflexively cling to your cultural constructions.
[01:22:23.960 --> 01:22:31.160]   And Heidegger borrows the term tranquilized, but he points out that he doesn't care for
[01:22:31.160 --> 01:22:38.760]   that term because tranquilized sounds like you're subdued, when in fact what most culturally
[01:22:38.760 --> 01:22:44.640]   constructed meat puppets do is to be frenetically engaged with their surroundings to ensure
[01:22:44.640 --> 01:22:51.360]   that they never sit still long enough to actually think about anything consequential.
[01:22:51.360 --> 01:22:53.480]   Heidegger says there's another way, though.
[01:22:53.480 --> 01:23:01.480]   He's like, "Yo, what you can do is to come to terms with that death anxiety in the following
[01:23:01.480 --> 01:23:02.480]   way.
[01:23:02.480 --> 01:23:13.000]   Way number one is to realize that not only are you going to die, but your death can happen
[01:23:13.000 --> 01:23:14.760]   at any given moment."
[01:23:14.760 --> 01:23:20.280]   So for Heidegger, if you say, "I know I'm going to die in some vaguely unspecified future
[01:23:20.280 --> 01:23:27.360]   moment," that's still death denial because you're saying, "Yeah, not me, not now."
[01:23:27.360 --> 01:23:34.360]   Heidegger's point is you need to get to the point where you need to realize that, you
[01:23:34.360 --> 01:23:42.880]   know, I need to realize that I can walk outside and get smoked by a comet, or I can stop for
[01:23:42.880 --> 01:23:49.560]   gas on the way home and catch the virus and be dead in two days, or any number of potentially
[01:23:49.560 --> 01:23:52.800]   unanticipated and uncontrollable fatal outcomes.
[01:23:52.800 --> 01:23:58.280]   - That's brilliant, by the way, sorry, to bring it into the now.
[01:23:58.280 --> 01:23:59.840]   - Yeah, it is brilliant.
[01:23:59.840 --> 01:24:05.120]   I agree, Lex, and this is why I'm wondering why didn't Becker notice this, because that's
[01:24:05.120 --> 01:24:09.600]   the being and time thing, is it's gotta be now.
[01:24:09.600 --> 01:24:18.120]   And then he says, "So okay, so now I've dealt somewhat with the death part," and now he
[01:24:18.120 --> 01:24:24.040]   says, "Now you've gotta deal with what he calls existential guilt."
[01:24:24.040 --> 01:24:33.000]   And he says, "Well, all right, you have to realize that like it or not, you have to make
[01:24:33.000 --> 01:24:34.000]   choices."
[01:24:34.000 --> 01:24:40.760]   You know, this is Jean-Paul Sartre, "We are condemned by virtue of consciousness to choosing,"
[01:24:40.760 --> 01:24:42.800]   but Heidegger's a little bit more precise.
[01:24:42.800 --> 01:24:51.560]   He's like, "Look, as I was saying earlier, you're in reality, you're an insignificant
[01:24:51.560 --> 01:24:58.240]   speck of respiring carbon-based dust born into a time and place not of your choosing
[01:24:58.240 --> 01:25:06.160]   when you're here for a microscopic amount of time after which you are not."
[01:25:06.160 --> 01:25:15.720]   And for Heidegger, you have to realize that, like I said, I didn't choose to be born a
[01:25:15.720 --> 01:25:24.160]   male or Jewish or in America the offspring of working-class people.
[01:25:24.160 --> 01:25:31.360]   And Heidegger, what he says is, "Yeah, but you still have to make choices and accept
[01:25:31.360 --> 01:25:36.000]   responsibility for those choices."
[01:25:36.000 --> 01:25:41.120]   Even though you didn't choose any of the parameters that ultimately limit what's available to
[01:25:41.120 --> 01:25:42.600]   you.
[01:25:42.600 --> 01:25:48.720]   And moreover, you're gonna not always make good choices.
[01:25:48.720 --> 01:25:54.840]   So now you're guilty for your choices.
[01:25:54.840 --> 01:26:03.080]   And then he uses the poet Rilke, he has a phrase, Becker uses it in "The Denial of
[01:26:03.080 --> 01:26:06.720]   Death," "The guilt of unlived life."
[01:26:06.720 --> 01:26:08.680]   I just love that.
[01:26:08.680 --> 01:26:20.920]   You have to accept that you have already diminished and in many ways amputated your own possibilities
[01:26:20.920 --> 01:26:28.400]   by virtue of choices that you've made or just as often have declined to make because you
[01:26:28.400 --> 01:26:38.000]   are reluctant to accept responsibility for the opportunities that you are now able to
[01:26:38.000 --> 01:26:44.600]   create by virtue of seeing the possibilities that lay before you.
[01:26:44.600 --> 01:26:53.560]   So anyway, Heidegger then says, "Look, okay, so I'm a professor and I live in America in
[01:26:53.560 --> 01:26:55.080]   the 21st century.
[01:26:55.080 --> 01:27:01.880]   Well, if I was in the third century living in a yurt in Mongolia, I'm not gonna have
[01:27:01.880 --> 01:27:05.880]   an opportunity to be a professor."
[01:27:05.880 --> 01:27:15.520]   But what he submits is that there is some aspects of whatever I am that are independent
[01:27:15.520 --> 01:27:19.040]   of my cultural and historical circumstances.
[01:27:19.040 --> 01:27:21.520]   In other words, there is a me of sorts.
[01:27:21.520 --> 01:27:25.080]   Heidegger would take vigorous issue and so would Heidegger scholars, because I'm not
[01:27:25.080 --> 01:27:26.680]   claiming to understand him.
[01:27:26.680 --> 01:27:29.460]   This is my classic comic book rendering.
[01:27:29.460 --> 01:27:37.740]   But Heidegger's point is that you get to the point where you're able to say, "Okay, I am
[01:27:37.740 --> 01:27:45.520]   a contingent historical and cultural artifact, but so what?
[01:27:45.520 --> 01:27:54.120]   If I was transported a thousand years in the past in Asia, I'd be in the same situation.
[01:27:54.120 --> 01:27:57.680]   I would still be conditioned by time and place.
[01:27:57.680 --> 01:28:04.440]   I would still have choices that I could make within the confines of what opportunities
[01:28:04.440 --> 01:28:07.320]   are afforded to me."
[01:28:07.320 --> 01:28:14.520]   And then Heidegger says, "If I can get that far," and this is his language, he says that
[01:28:14.520 --> 01:28:17.040]   there is a transformation.
[01:28:17.040 --> 01:28:19.320]   And he literally, he calls it a turning.
[01:28:19.320 --> 01:28:28.160]   You're turning away from a flight from death, and you are allowed, therefore you see a horizon,
[01:28:28.160 --> 01:28:38.800]   is his word, of opportunity that makes you in a state of anticipatory resoluteness with
[01:28:38.800 --> 01:28:48.540]   solicitous regard for others that makes your life seem like an adventure perfused with
[01:28:48.540 --> 01:28:50.720]   unshakable joy.
[01:28:50.720 --> 01:28:51.720]   Let me unpack those things.
[01:28:51.720 --> 01:28:52.720]   That's beautiful.
[01:28:52.720 --> 01:28:53.720]   It is beautiful.
[01:28:53.720 --> 01:28:56.120]   I love, Lex, that you're resonating to the time thing.
[01:28:56.120 --> 01:29:02.920]   So he's like, "Okay, we already talked about now anticipatory is already hopeful because
[01:29:02.920 --> 01:29:05.400]   it's looking forward."
[01:29:05.400 --> 01:29:15.200]   To be resolute, it means to be steadfast and to just have confidence in what you're
[01:29:15.200 --> 01:29:17.400]   doing moving forward.
[01:29:17.400 --> 01:29:18.400]   All right.
[01:29:18.400 --> 01:29:21.800]   Solicitous, I had to look up all these words, by the way.
[01:29:21.800 --> 01:29:28.240]   It just means that you are concerned about your fellow human beings.
[01:29:28.240 --> 01:29:35.340]   But I love the idea, even if it seems allegorical, I don't mind that at all.
[01:29:35.340 --> 01:29:41.200]   This idea, you said love earlier, and I think that when Heidegger is talking about being
[01:29:41.200 --> 01:29:45.680]   solicitous, that's as close as he can get.
[01:29:45.680 --> 01:29:46.680]   There's an Italian-
[01:29:46.680 --> 01:29:47.680]   Yes, Sargentrave.
[01:29:47.680 --> 01:29:50.840]   So what was that line again with the solicitous of the-
[01:29:50.840 --> 01:29:51.840]   Okay, so-
[01:29:51.840 --> 01:29:53.840]   I mean, the whole thing of turning away from death and the-
[01:29:53.840 --> 01:29:54.840]   Yeah, he-
[01:29:54.840 --> 01:29:56.200]   I mean, all the words you said are just beautiful.
[01:29:56.200 --> 01:29:58.200]   I love those words, yeah.
[01:29:58.200 --> 01:30:05.080]   "A solitary resoluteness that is accompanied with solicitous regard to our fellow humans,
[01:30:05.080 --> 01:30:15.040]   which makes life appear to us to be an ongoing adventure that is permeated by unshakable
[01:30:15.040 --> 01:30:16.040]   joy."
[01:30:16.040 --> 01:30:19.120]   Now, again, Heidegger's not Mary Poppins.
[01:30:19.120 --> 01:30:20.120]   This-
[01:30:20.120 --> 01:30:21.120]   I just got a tattoo.
[01:30:21.120 --> 01:30:22.120]   This is great.
[01:30:22.120 --> 01:30:23.760]   I just love the-
[01:30:23.760 --> 01:30:25.160]   Wait, is that an exact quote?
[01:30:25.160 --> 01:30:27.240]   No, I'm piecing together.
[01:30:27.240 --> 01:30:33.440]   These are his exact words that, and I spent the last two years reading almost everything
[01:30:33.440 --> 01:30:38.320]   that I can find because I want to, I'm sick of death.
[01:30:38.320 --> 01:30:41.600]   You said it, so I want to second what you say, Lex.
[01:30:41.600 --> 01:30:43.520]   It's not about death.
[01:30:43.520 --> 01:30:46.480]   It's the Sherwood Anderson guy.
[01:30:46.480 --> 01:30:53.520]   He's a novelist that I like about, he wrote a book called "Winesburg, Ohio," and now I'm
[01:30:53.520 --> 01:30:56.960]   going to forget what he said on his tombstone.
[01:30:56.960 --> 01:31:04.160]   But it was something to the effect, oh, he said, "Life, not death, is the great adventure."
[01:31:04.160 --> 01:31:12.640]   The point being is that to consider that we must die and the existential implications
[01:31:12.640 --> 01:31:22.240]   of that, really the goal, the way I see it, is getting from hate to love.
[01:31:22.240 --> 01:31:32.840]   I feel like Heidegger has a way of thinking about things that moves us more in that direction.
[01:31:32.840 --> 01:31:42.000]   So that's kind of my current preoccupation is to take what I just said to you and to
[01:31:42.000 --> 01:31:47.720]   talk about it with my colleagues and other academic psychologists because the way we
[01:31:47.720 --> 01:31:53.880]   started with Ernest Becker, remember I said earlier, I wasn't trained in any of these
[01:31:53.880 --> 01:31:54.880]   things.
[01:31:54.880 --> 01:32:02.080]   I'm an egghead researcher that was doing experiments about biofeedback.
[01:32:02.080 --> 01:32:07.800]   Then we read these Becker books, and I thought they were so interesting that for the first
[01:32:07.800 --> 01:32:10.680]   few years, we didn't have any studies.
[01:32:10.680 --> 01:32:14.200]   I just would travel around and I'd be like, "Here's what this Becker guy says.
[01:32:14.200 --> 01:32:16.320]   I think this is cool."
[01:32:16.320 --> 01:32:22.120]   Well, my present view is I'm like, "Here's what this Heidegger guy says.
[01:32:22.120 --> 01:32:29.960]   I think these ideas are consistent with what Becker is saying because they are anchored
[01:32:29.960 --> 01:32:32.680]   in death anxiety."
[01:32:32.680 --> 01:32:42.080]   But I like that direction as an alternative to the Kierkegaardian insistence that the
[01:32:42.080 --> 01:32:51.520]   only psychologically tenable way to extricate ourselves from maladaptive reactions to death
[01:32:51.520 --> 01:32:55.960]   anxiety is through faith in the traditional sense.
[01:32:55.960 --> 01:32:56.960]   Yeah.
[01:32:56.960 --> 01:33:03.920]   I always kind of saw Kierkegaard unfairly, like you said, in a comic book sense of the
[01:33:03.920 --> 01:33:06.120]   word faith as a non-traditional sense.
[01:33:06.120 --> 01:33:07.760]   I kind of like the idea of leap of faith.
[01:33:07.760 --> 01:33:09.440]   Oh, I love that idea.
[01:33:09.440 --> 01:33:15.720]   And so what I've been babbling about with Kierkegaard or Heidegger, I'm like, "Yeah,
[01:33:15.720 --> 01:33:19.600]   Kierkegaard is a leap of faith in God.
[01:33:19.600 --> 01:33:22.960]   Heidegger's a leap of faith in life."
[01:33:22.960 --> 01:33:25.400]   And I just, I like it.
[01:33:25.400 --> 01:33:30.400]   I found the leap of faith really interesting in the technological space.
[01:33:30.400 --> 01:33:37.160]   So I've talked to on this thing with Elon Musk, but I think he's also just in general
[01:33:37.160 --> 01:33:39.200]   for our culture a really important figure.
[01:33:39.200 --> 01:33:40.320]   Oh, absolutely.
[01:33:40.320 --> 01:33:48.360]   That takes, I mean, he's sometimes a little bit insane on social media and just in life.
[01:33:48.360 --> 01:33:54.360]   When I met him, it was kind of interesting that of course there's, I mean, he's a
[01:33:54.360 --> 01:33:58.240]   legit engineer, so he's fun to talk to about the technical things.
[01:33:58.240 --> 01:34:06.160]   But he also just the way the humor and the way he sees life, it just like refuses to
[01:34:06.160 --> 01:34:07.160]   be conventional.
[01:34:07.160 --> 01:34:08.160]   Yeah.
[01:34:08.160 --> 01:34:13.240]   So it's a constant leap into the unknown.
[01:34:13.240 --> 01:34:19.840]   And one of the things that he does, and this isn't even like fake, a lot of people say,
[01:34:19.840 --> 01:34:23.680]   because he's a CEO, there's a business owner, so he's trying to make money.
[01:34:23.680 --> 01:34:30.520]   No, I think this is, I looked him in his eyes, I mean, this is real, is a lot of the things
[01:34:30.520 --> 01:34:36.480]   he believes that are going to be accomplished that a lot of others are saying are impossible,
[01:34:36.480 --> 01:34:39.440]   like autonomous vehicles, he truly believes it.
[01:34:39.440 --> 01:34:44.800]   To me, that is the leap of faith of what was going like, we're like, the entirety of our
[01:34:44.800 --> 01:34:47.200]   experience is shrouded in mystery.
[01:34:47.200 --> 01:34:49.600]   We don't know what the hell's going to happen.
[01:34:49.600 --> 01:34:52.400]   You don't know what we're actually capable of as human beings.
[01:34:52.400 --> 01:34:54.200]   He just takes the leap.
[01:34:54.200 --> 01:34:59.120]   He fully believes that we can, you know, we can go to Mars, we can colonize Mars.
[01:34:59.120 --> 01:35:07.640]   I mean, how crazy is it to just believe and dream and actually be taking steps towards
[01:35:07.640 --> 01:35:12.840]   it to colonizing Mars when most people are like, that's the stupidest idea ever?
[01:35:12.840 --> 01:35:16.000]   Yeah, well, I'm in agreement with you on that.
[01:35:16.000 --> 01:35:21.680]   You know, two things, you know, one is it reminds me of Ben Franklin, who in his autobiography,
[01:35:21.680 --> 01:35:30.680]   you know, has a similarly childish in the best sense of the word, unbridled imagination
[01:35:30.680 --> 01:35:37.440]   for what might become, you know, Ben Franklin's like, yeah, I got electricity, that's cool,
[01:35:37.440 --> 01:35:39.480]   but we'll be levitating soon.
[01:35:39.480 --> 01:35:44.960]   And I, we can't even begin to imagine what we are capable of.
[01:35:44.960 --> 01:35:48.800]   And of course, people are like, dude, that's crazy.
[01:35:48.800 --> 01:35:56.000]   And there's a guy with FCS Schiller, some humanistic guy at the beginning of the 20th
[01:35:56.000 --> 01:35:57.240]   century.
[01:35:57.240 --> 01:36:08.640]   He's like, you know, lots of things that people think about may appear to be absurd to the
[01:36:08.640 --> 01:36:19.080]   point of obscene, but the reality is historically, every fantastic innovation has generally been
[01:36:19.080 --> 01:36:25.480]   initiated by someone who was condemned for being a lunatic.
[01:36:25.480 --> 01:36:31.960]   And it's not that anything is possible, but surely things that we don't try will never
[01:36:31.960 --> 01:36:34.240]   manifest as possibilities.
[01:36:34.240 --> 01:36:39.440]   - Yeah, and that's, there's something beautiful to that.
[01:36:39.440 --> 01:36:42.520]   That's the embracing the abyss.
[01:36:42.520 --> 01:36:49.960]   And again, it's like the, it's the embracing the fear of death, the reality of death, and
[01:36:49.960 --> 01:36:54.000]   then turning and to look at all the opportunities before us.
[01:36:54.000 --> 01:36:55.080]   - Oh, yeah, that's right.
[01:36:55.080 --> 01:37:00.840]   - Let me ask you, whenever I bring up Ernest Becker's work, which I do, and yours quite
[01:37:00.840 --> 01:37:12.560]   a bit, I find it surprising how, that it's not a lot more popular in a sense that, no,
[01:37:12.560 --> 01:37:15.400]   I don't mean just your book.
[01:37:15.400 --> 01:37:19.040]   That's well-written, people should read it, should buy it, whatever.
[01:37:19.040 --> 01:37:23.960]   I think it has the same kind of qualities that are useful to think about as like Jordan
[01:37:23.960 --> 01:37:26.320]   Peterson's work and stuff like that.
[01:37:26.520 --> 01:37:37.240]   I just mean like why people are not, don't think of that as a compelling description
[01:37:37.240 --> 01:37:41.920]   of the core of the human condition.
[01:37:41.920 --> 01:37:45.880]   I think what you mentioned about Heidegger's quite connects with me quite well.
[01:37:45.880 --> 01:37:51.480]   So I ask, on this podcast, I often ask people if they're afraid of death.
[01:37:51.480 --> 01:37:57.720]   It's like almost every single, I almost always get criticized for asking world-class people,
[01:37:57.720 --> 01:38:04.560]   scientists and technologists about the fear of death and the meaning of life.
[01:38:04.560 --> 01:38:12.920]   And on the fear of death, they often don't say anything interesting.
[01:38:12.920 --> 01:38:17.600]   What I mean by that is they haven't thought deeply about it.
[01:38:17.600 --> 01:38:21.360]   You kind of brought this up a few times of really letting it sink in.
[01:38:21.360 --> 01:38:26.280]   They kind of say this thing about exactly what you said, which is like, it's something
[01:38:26.280 --> 01:38:29.000]   that happens not today.
[01:38:29.000 --> 01:38:32.480]   I'm aware that it's something that happens.
[01:38:32.480 --> 01:38:35.560]   The thing they usually say is, I'm not afraid of death.
[01:38:35.560 --> 01:38:40.920]   I just want to live a good life kind of thing.
[01:38:40.920 --> 01:38:45.000]   What I'm trying to express is like when I look in their eyes and the kind of the core
[01:38:45.000 --> 01:38:51.120]   of the conversation, it looks like they haven't really become, like they haven't really meditated
[01:38:51.120 --> 01:38:52.120]   on death.
[01:38:52.120 --> 01:38:59.320]   I guess the question is, what do I say to people that there's something to really think
[01:38:59.320 --> 01:39:02.000]   about here?
[01:39:02.000 --> 01:39:07.080]   There's some demons, some realities that need to be faced by more people.
[01:39:07.080 --> 01:39:09.040]   - Well, that's a tough one.
[01:39:09.040 --> 01:39:12.160]   I could tell you what not to do.
[01:39:12.160 --> 01:39:19.200]   So when we are young and annoying, a lot of famous people, mostly psychologists, because
[01:39:19.200 --> 01:39:29.120]   that's who we intersected with, we would lay out these ideas and they would be, well, I
[01:39:29.120 --> 01:39:32.320]   don't think about death like that.
[01:39:32.320 --> 01:39:35.200]   So these ideas must be wrong.
[01:39:35.200 --> 01:39:41.720]   And we would say, well, you don't think about death because you're lucky enough to be comfortably
[01:39:41.720 --> 01:39:46.880]   ensconced in a cultural worldview from which you derive self-esteem.
[01:39:46.880 --> 01:39:53.460]   And that has spared you the existential excruciations that would otherwise arise.
[01:39:53.460 --> 01:39:55.600]   But that's like Freud.
[01:39:55.600 --> 01:40:00.920]   You're repressing, so you either agree with me, in which case I'm right, or you disagree
[01:40:00.920 --> 01:40:04.840]   with me, in which case you're repressing and I'm right.
[01:40:04.840 --> 01:40:08.400]   - So that's the Nietzsche thing.
[01:40:08.400 --> 01:40:13.480]   What I've felt when I've, there've been moments in my life when I really thought about death.
[01:40:13.480 --> 01:40:18.120]   I mean, there's not too many, like really, really thought about it and feel the thing
[01:40:18.120 --> 01:40:26.960]   when you felt at eight, maybe I'm dramatizing or romanticizing it, but I feel like it's,
[01:40:26.960 --> 01:40:34.400]   the conservatives call it popularly, or the movie Matrix call it the red pill moment.
[01:40:34.400 --> 01:40:41.000]   I feel like it's a dangerous thought because I feel like I'm taking a step out of society.
[01:40:41.000 --> 01:40:43.920]   Like there's a nice narrative that we've all constructed.
[01:40:43.920 --> 01:40:44.920]   - You are.
[01:40:44.920 --> 01:40:51.960]   - And I'm taking a step out and it feels, there's this feeling like you're basically
[01:40:51.960 --> 01:40:52.960]   drowning.
[01:40:52.960 --> 01:40:56.120]   I mean, it's not a good feeling.
[01:40:56.120 --> 01:40:57.120]   - It is not.
[01:40:57.120 --> 01:41:00.200]   But this gets back to the Heidegger-Kierkegaard school of anxiety.
[01:41:00.200 --> 01:41:08.340]   You are stepping out and you are momentarily shrugging off, again, the culturally constructed
[01:41:08.340 --> 01:41:13.880]   psychological accoutrements that allow you to stand up in the morning.
[01:41:13.880 --> 01:41:14.880]   And--
[01:41:14.880 --> 01:41:26.200]   - So, I mean, in that sense, it feels like, I mean, how do you have that conversation?
[01:41:26.200 --> 01:41:32.400]   Because I guess I'm dancing around a set of questions, which is like, I guess I'm disappointed
[01:41:32.400 --> 01:41:42.120]   that people are not as willing to step outside.
[01:41:42.120 --> 01:41:44.760]   Even any kind of thought experiment.
[01:41:44.760 --> 01:41:49.420]   Forget denial of death.
[01:41:49.420 --> 01:41:53.760]   There's now a community of people, let's take an easy one that I think is scientifically
[01:41:53.760 --> 01:41:59.860]   ridiculous, which is there's a community of people that believe that the earth is flat.
[01:41:59.860 --> 01:42:06.100]   Or actually, even better, that space is fake.
[01:42:06.100 --> 01:42:15.940]   What I find surprising is that a lot of people I talk to are not willing to, imagine if it
[01:42:15.940 --> 01:42:18.460]   is, imagine the earth is flat.
[01:42:18.460 --> 01:42:19.460]   Think about it.
[01:42:19.460 --> 01:42:23.260]   A lot of people are just like, no, the earth is round.
[01:42:23.260 --> 01:42:25.540]   They're like scientists, too.
[01:42:25.540 --> 01:42:30.940]   They're like, yeah, well, actually, wait, have you actually thought about it?
[01:42:30.940 --> 01:42:34.460]   Imagine, it's a thought experiment.
[01:42:34.460 --> 01:42:38.700]   Basically step outside the little narrative that we are comfortable with.
[01:42:38.700 --> 01:42:48.260]   Now, that one in particular has really strong evidence and scientific validation, so it's
[01:42:48.260 --> 01:42:53.420]   a pretty simple thing to show that it at least is not flat.
[01:42:53.420 --> 01:43:00.820]   But just the willingness to take a step outside of the stories that bring us comfort has been
[01:43:00.820 --> 01:43:04.620]   disappointing that people are not willing to do that.
[01:43:04.620 --> 01:43:09.220]   I think the philosophy that you've constructed and that Ernest Becker's constructed and you've
[01:43:09.220 --> 01:43:14.860]   tested, I think is really compelling in the fact that people aren't often willing to take
[01:43:14.860 --> 01:43:15.860]   that step.
[01:43:15.860 --> 01:43:16.860]   It's disappointing.
[01:43:16.860 --> 01:43:17.860]   Yeah.
[01:43:17.860 --> 01:43:21.060]   Well, yes, but perhaps understandable.
[01:43:21.060 --> 01:43:28.620]   This is an anecdote, of course, but when we were trying to get a publisher for our book,
[01:43:28.620 --> 01:43:40.120]   we had a meeting with a publisher who published some Malcolm Gladwell books.
[01:43:40.120 --> 01:43:45.860]   She said, "I'm very interested in your book, but can you write it without mentioning death
[01:43:45.860 --> 01:43:48.260]   because people don't like death?"
[01:43:48.260 --> 01:43:53.860]   We're like, "No, it's really kind of central."
[01:43:53.860 --> 01:43:55.820]   I think that's part of it.
[01:43:55.820 --> 01:44:03.860]   I think, again, if these ideas have merit, and I actually like the way that you put it,
[01:44:03.860 --> 01:44:18.060]   Lex, it's that to step away is to momentarily expose yourself to all of the anxiety that
[01:44:18.060 --> 01:44:22.900]   our identity and our beliefs typically enable us to manage.
[01:44:22.900 --> 01:44:24.700]   I think it's as simple as that.
[01:44:24.700 --> 01:44:25.700]   Yeah.
[01:44:25.700 --> 01:44:37.060]   I had this experience in college with my best friend who got really high, and he forgot
[01:44:37.060 --> 01:44:38.340]   it was in the winter.
[01:44:38.340 --> 01:44:39.340]   It was really freezing.
[01:44:39.340 --> 01:44:40.620]   It was memorable to me.
[01:44:40.620 --> 01:44:43.740]   I think as an analogist, very useful.
[01:44:43.740 --> 01:44:45.140]   He went to get some pizza.
[01:44:45.140 --> 01:44:46.140]   Of course.
[01:44:46.140 --> 01:44:55.940]   He left me outside and said, "I'll be back in five minutes."
[01:44:55.940 --> 01:44:58.220]   He forgot that he left me outside.
[01:44:58.220 --> 01:45:01.300]   I remember I was in shorts.
[01:45:01.300 --> 01:45:03.140]   It was freezing winter.
[01:45:03.140 --> 01:45:07.900]   I remember standing outside his dorm, and I'm looking from the outside in.
[01:45:07.900 --> 01:45:10.460]   It's light and it's warm.
[01:45:10.460 --> 01:45:16.120]   I'm just standing there frozen, I think for an hour or more.
[01:45:16.120 --> 01:45:18.260]   That's how I think about it.
[01:45:18.260 --> 01:45:23.740]   I don't give a damn about the stupid winter.
[01:45:23.740 --> 01:45:27.020]   I'm drawn to be back to the warm.
[01:45:27.020 --> 01:45:29.300]   That's how I feel about thinking about death.
[01:45:29.300 --> 01:45:33.620]   At a certain point, it's too much.
[01:45:33.620 --> 01:45:34.820]   It's that cold.
[01:45:34.820 --> 01:45:36.620]   I want to be back into the warm.
[01:45:36.620 --> 01:45:38.140]   I want to be back.
[01:45:38.140 --> 01:45:42.740]   Getting back to Heidegger for a moment.
[01:45:42.740 --> 01:45:48.500]   He uses a lot the idea of feeling at home.
[01:45:48.500 --> 01:45:53.180]   Not as in your house, but just feeling like you're comfortably situated.
[01:45:53.180 --> 01:45:59.780]   Maybe we could talk about ... I had a conversation about this with my dad a little bit.
[01:45:59.780 --> 01:46:03.800]   How does religion relate to this?
[01:46:03.800 --> 01:46:09.600]   I see it as the disease and the cure.
[01:46:09.600 --> 01:46:16.460]   In a sense, a few things.
[01:46:16.460 --> 01:46:26.760]   One is that I think a case could be made that humans are innately religious.
[01:46:26.760 --> 01:46:31.480]   Now we're going to get into territory where there's going to be a lot of disputes.
[01:46:31.480 --> 01:46:35.940]   What do you mean by religious?
[01:46:35.940 --> 01:46:39.420]   Religion is an evolutionary adaptation.
[01:46:39.420 --> 01:46:44.380]   Religion is like a belief in something outside of yourself kind of thing.
[01:46:44.380 --> 01:46:45.380]   Not necessarily.
[01:46:45.380 --> 01:46:48.320]   Here we got to be a little bit more careful.
[01:46:48.320 --> 01:46:53.180]   Again, I'm not a scholar.
[01:46:53.180 --> 01:47:00.240]   How about I'm a well-intentioned dilettante in this regard?
[01:47:00.240 --> 01:47:11.260]   What I have read is that religion evolved very early on, long before our ancestors were
[01:47:11.260 --> 01:47:18.540]   conscious and the issue of death arose.
[01:47:18.540 --> 01:47:24.060]   The word religion evidently is from a Latin word, regatear.
[01:47:24.060 --> 01:47:25.780]   We can look it up.
[01:47:25.780 --> 01:47:28.300]   It means to bind.
[01:47:28.300 --> 01:47:36.580]   Emile Durkheim, the dead French sociologist, he said, "Originally, religion is a," Darsa
[01:47:36.580 --> 01:47:43.020]   Lessing, who's a dead novelist, she calls it the substance of we feeling.
[01:47:43.020 --> 01:47:51.500]   That it's literally that it arose because we're uber social creatures who from time
[01:47:51.500 --> 01:48:00.740]   to time took comfort in just being in physical proximity with our fellow humans and that
[01:48:00.740 --> 01:48:12.260]   there is this kind of sense of transcendent exuberance, just back to the unshakable joy
[01:48:12.260 --> 01:48:16.580]   that Heidegger alludes to.
[01:48:16.580 --> 01:48:25.620]   The original function of religion was to foster social cohesion and coordination and that
[01:48:25.620 --> 01:48:33.300]   it was only subsequently, some claim, that a burgeoning level of consciousness made it
[01:48:33.300 --> 01:48:43.700]   such that religious belief systems that included the hope of some kind of immortality were
[01:48:43.700 --> 01:48:47.540]   just naturally selected thereafter.
[01:48:47.540 --> 01:48:57.180]   So there are some people, so it's David Sloan Wilson wrote a book called Darwin's Cathedral
[01:48:57.180 --> 01:48:59.900]   and he said religion has nothing to do with death.
[01:48:59.900 --> 01:49:03.860]   It evolved to make groups viable.
[01:49:03.860 --> 01:49:06.820]   He's actually a group selection guy.
[01:49:06.820 --> 01:49:08.260]   What's group selection?
[01:49:08.260 --> 01:49:13.060]   The idea that it's the group that is selected for rather than the individual.
[01:49:13.060 --> 01:49:16.300]   Yeah, so people have vigorous disagreements about that.
[01:49:16.300 --> 01:49:24.540]   But I guess our point would be we see religion as being inextricably connected ultimately
[01:49:24.540 --> 01:49:29.460]   to assuaging concerns about death.
[01:49:29.460 --> 01:49:35.740]   Well I guess another question to ask around this, what does the world look like without
[01:49:35.740 --> 01:49:36.740]   religion?
[01:49:36.740 --> 01:49:46.020]   Will we, if it's inextricably connected to our fears of death, do you think it always
[01:49:46.020 --> 01:49:49.380]   returns in some kind of shape?
[01:49:49.380 --> 01:49:52.220]   Maybe it's not called religion, but whatever, it just keeps returning?
[01:49:52.220 --> 01:49:53.220]   Yeah, who knows?
[01:49:53.220 --> 01:49:54.980]   So that's a great question, Lex.
[01:49:54.980 --> 01:49:58.420]   There's a woman named Karen Armstrong.
[01:49:58.420 --> 01:50:07.300]   She was a nun turned historian and she's, I can't remember the name of the book, but
[01:50:07.300 --> 01:50:09.220]   no matter.
[01:50:09.220 --> 01:50:10.500]   We could look that up, but-
[01:50:10.500 --> 01:50:14.220]   If you want I can look it up, but I can also, I'll just add it and post it.
[01:50:14.220 --> 01:50:23.100]   Yeah, her point, it has God in the title of course, but she's like, "Look, all religions
[01:50:23.100 --> 01:50:32.140]   are generally fairly right-minded in that they advocate the golden rule, and all religions
[01:50:32.140 --> 01:50:42.380]   at their best do seem to foster pro-social behavior towards the in-group, and that confers
[01:50:42.380 --> 01:50:46.660]   both psychological as well as physical benefits.
[01:50:46.660 --> 01:50:53.900]   That's the good news, and the bad news is historically all religions are subject to
[01:50:53.900 --> 01:51:05.980]   being hijacked by a lunatic French who declares that they're the ones in sole possession of
[01:51:05.980 --> 01:51:14.460]   the liturgical practices or whatever they call them, and they're the ones that turn
[01:51:14.460 --> 01:51:21.060]   at its best into your crusades and holocausts."
[01:51:21.060 --> 01:51:33.340]   My view, not that it should matter for much, but I grew up just skeptical of religion because
[01:51:33.340 --> 01:51:39.660]   I'm like, as a kid, I'm like, "Well, if we didn't have these beliefs, we wouldn't be
[01:51:39.660 --> 01:51:43.620]   killing each other because of them."
[01:51:43.620 --> 01:51:49.220]   And I'd be like to my parents, "Well, you're telling me that all people should be judged
[01:51:49.220 --> 01:51:56.180]   on the merits of their character, but don't come home if you don't marry a Jewish woman,"
[01:51:56.180 --> 01:52:01.180]   which is implying that if you're not Jewish, you're an inferior form of life.
[01:52:01.180 --> 01:52:02.500]   That's what tribes always do.
[01:52:02.500 --> 01:52:04.060]   And there's the tribal thing.
[01:52:04.060 --> 01:52:10.380]   And so there's a guy named Amin Malouf, a Lebanese guy who writes in French in the 1990s,
[01:52:10.380 --> 01:52:20.180]   I think, wrote a book called, in the name of identity, "Violence and the Need to Belong."
[01:52:20.180 --> 01:52:32.540]   And that was his point is, unless we can overcome this tribal mentality, this will not end well.
[01:52:32.540 --> 01:52:38.500]   But you said earlier something, Lex, that I think is profound and profoundly important,
[01:52:38.500 --> 01:52:46.180]   and that is you did not recoil in horror when I mentioned Kierkegaard's use of the term
[01:52:46.180 --> 01:52:47.900]   faith.
[01:52:47.900 --> 01:52:55.020]   And so I'm a big fan of faith, and I'm not sure what that implies.
[01:52:55.020 --> 01:52:56.740]   I have...
[01:52:56.740 --> 01:53:03.580]   And by the way, this is just a peripheral comment, but I find less resistance to Becker's
[01:53:03.580 --> 01:53:09.580]   ideas in our work when I'm in Jesuit schools.
[01:53:09.580 --> 01:53:18.580]   It's the Americans, the secular humanists who are most disinclined to accept these ideas.
[01:53:18.580 --> 01:53:23.260]   - It's an important side comment because I think it's mostly because they don't think
[01:53:23.260 --> 01:53:24.260]   philosophically.
[01:53:24.260 --> 01:53:31.820]   I mean, I speak with a lot of scientists, and I think that's my main criticism is you
[01:53:31.820 --> 01:53:32.820]   don't...
[01:53:32.820 --> 01:53:35.180]   I mean, that's the problem with science.
[01:53:35.180 --> 01:53:42.060]   It's so comforting to focus in on the details that you can escape thinking about the mystery
[01:53:42.060 --> 01:53:46.660]   of it all, the big picture things, the philosophical, the fact that you don't actually know shit
[01:53:46.660 --> 01:53:48.660]   at all.
[01:53:48.660 --> 01:54:00.100]   Yeah, so in terms of Jesuit, that's the beauty of the experience of faith and so on is wherever
[01:54:00.100 --> 01:54:04.500]   that journey takes you is you actually explore the biggest questions of our world.
[01:54:04.500 --> 01:54:05.500]   - Yeah.
[01:54:05.500 --> 01:54:06.500]   - Yeah.
[01:54:06.500 --> 01:54:15.500]   - So I don't see religion going away because I don't see humans as capable of surviving
[01:54:15.500 --> 01:54:25.900]   without faith and hope, and everyone from the Pope to Elon Musk will acknowledge that
[01:54:25.900 --> 01:54:35.820]   it is a world that is unfathomably mysterious, and like it or not, in the absence of beliefs...
[01:54:35.820 --> 01:54:40.500]   Here I'm Charles Peirce, the pragmatic philosopher.
[01:54:40.500 --> 01:54:42.900]   He just said, "Beliefs are the basis of action."
[01:54:42.900 --> 01:54:46.620]   If you don't have any beliefs, you're paralyzed with indecision.
[01:54:46.620 --> 01:54:51.500]   Whether we're aware of it or not, whether we like it or not, in order to stand up in
[01:54:51.500 --> 01:54:59.780]   the morning, you have to subscribe to beliefs that can never be unequivocally proven right
[01:54:59.780 --> 01:55:00.780]   or wrong.
[01:55:00.780 --> 01:55:04.340]   Well, then why do you maintain them?
[01:55:04.340 --> 01:55:09.420]   Well, ultimately, it's because of some form of faith.
[01:55:09.420 --> 01:55:16.700]   - But also, faith shouldn't be a dogmatic thing that you should always be leaping.
[01:55:16.700 --> 01:55:17.700]   - Yes.
[01:55:17.900 --> 01:55:25.300]   - I guess the problem with science or with religion is you could sort of all of a sudden
[01:55:25.300 --> 01:55:30.580]   take a step into a place where you're super confident that you know the absolute truth
[01:55:30.580 --> 01:55:31.580]   of things.
[01:55:31.580 --> 01:55:32.580]   - There you go.
[01:55:32.580 --> 01:55:36.900]   And again, back to Socrates, Plato, back in the cave.
[01:55:36.900 --> 01:55:42.980]   At Skidmore, where I work, that's what I have the students read in their first week, and
[01:55:42.980 --> 01:55:45.820]   Plato's like, "Oh, look at all those poor bastards.
[01:55:45.820 --> 01:55:49.020]   They're in the cave, but they don't know it."
[01:55:49.020 --> 01:55:54.700]   And then they are freed from their chains, and they have to be dragged out of the cave,
[01:55:54.700 --> 01:55:56.720]   by the way, which is another interesting point.
[01:55:56.720 --> 01:56:02.820]   They don't run out, but that gets back to why people don't like to be divested of their
[01:56:02.820 --> 01:56:04.080]   comfortable illusions.
[01:56:04.080 --> 01:56:09.140]   But anyway, they get dragged out of the cave into the sunlight, which he claims is a representation
[01:56:09.140 --> 01:56:11.620]   of truth and beauty.
[01:56:11.620 --> 01:56:15.740]   And I say to the students, "Well, what's wrong with that?"
[01:56:15.740 --> 01:56:18.060]   And they're like, "Nothing.
[01:56:18.060 --> 01:56:19.620]   That's like awesome."
[01:56:19.620 --> 01:56:25.740]   And then I'm like, "Yo, dudes, you're out of the cave, but how do you know that you're
[01:56:25.740 --> 01:56:28.220]   not in another cave?
[01:56:28.220 --> 01:56:38.820]   The illumination may be better, but the minute you think you're at the end of the proverbial
[01:56:38.820 --> 01:56:49.740]   intellectual/epistemological trail, then you have already succumbed to either laziness
[01:56:49.740 --> 01:56:51.380]   or dogmatism or both."
[01:56:51.380 --> 01:56:52.380]   That's really well put.
[01:56:52.380 --> 01:56:59.460]   - That's both terrifying and exciting, that there's always a bigger cave.
[01:56:59.460 --> 01:57:03.820]   A little bit of an out there question, but I think some of the interesting qualities
[01:57:03.820 --> 01:57:10.800]   of the human mind is the ideas of intelligence and consciousness.
[01:57:10.800 --> 01:57:13.220]   So what do you make of consciousness?
[01:57:13.220 --> 01:57:18.420]   So do you think death creates consciousness?
[01:57:18.420 --> 01:57:22.380]   Like the fear of death, the terror of death creates consciousness?
[01:57:22.380 --> 01:57:29.700]   - And consciousness in turn magnifies the terror of death.
[01:57:29.700 --> 01:57:30.700]   I do.
[01:57:30.700 --> 01:57:33.700]   - Like what is consciousness to you?
[01:57:33.700 --> 01:57:34.700]   - Oh, don't ask me that.
[01:57:34.700 --> 01:57:40.380]   So now, because if I could answer that, I'd be chugging rum out of a coconut with my Nobel
[01:57:40.380 --> 01:57:41.380]   Prize.
[01:57:41.380 --> 01:57:45.100]   That, it's literally...
[01:57:45.100 --> 01:57:50.180]   Steven Pinker, I do agree with his claim, and I think how the mind works, that it is
[01:57:50.180 --> 01:58:01.660]   the key question for the psychological sciences broadly defined in the 21st century.
[01:58:01.660 --> 01:58:02.660]   - What is consciousness?
[01:58:02.660 --> 01:58:04.260]   - What is consciousness?
[01:58:04.260 --> 01:58:09.660]   And I don't think it's an epiphenomenological afterthought.
[01:58:09.660 --> 01:58:17.860]   So a lot of people, I think Dan Wegner at Harvard, a lot of folks consider it just the
[01:58:17.860 --> 01:58:28.960]   ass end of a process that by the time we are aware of what it is, it's just basically an
[01:58:28.960 --> 01:58:34.460]   integrated rendering of something that's already happened.
[01:58:34.460 --> 01:58:39.780]   Evidently there's a half second delay between when something happens, you know those studies,
[01:58:39.780 --> 01:58:43.660]   and our awareness of it.
[01:58:43.660 --> 01:58:47.580]   - And then that's where ideas of free will will step in, so you can explain away a lot
[01:58:47.580 --> 01:58:48.580]   of stuff.
[01:58:48.580 --> 01:58:52.820]   - And I think those are all important and interesting questions.
[01:58:52.820 --> 01:59:05.900]   I'm of the persuasion, I mean even, not even, but Dawkins in The Selfish Gene is very thoughtful,
[01:59:05.900 --> 01:59:11.280]   actually in a lot of, it's actually more in notes than in the text of the book, but he's
[01:59:11.280 --> 01:59:22.420]   just like, it's hard for me to imagine that consciousness doesn't have some sort of important
[01:59:22.420 --> 01:59:25.040]   and highly adaptive function.
[01:59:25.040 --> 01:59:31.320]   And what Dawkins says is, he thought about it in terms of just that we can do mental
[01:59:31.320 --> 01:59:33.320]   simulations.
[01:59:33.320 --> 01:59:43.460]   That one possibly extraordinary product of consciousness is to, rather than find out
[01:59:43.460 --> 01:59:51.520]   often by adverse consequences through trying something, would be to run mental simulations.
[01:59:51.520 --> 01:59:57.280]   And so one possibility is that consciousness is highly adaptive.
[01:59:57.280 --> 02:00:02.800]   Another possibility is Nicholas Humphrey, a British dude who wrote a book about, I think
[02:00:02.800 --> 02:00:09.400]   it's called Regaining Consciousness, and he hypothesized, I think this is 1980s, maybe
[02:00:09.400 --> 02:00:18.560]   even earlier, that consciousness arose as a way to better predict the behavior of others
[02:00:18.560 --> 02:00:26.680]   in social settings, that by knowing how I feel makes me better able to know how you
[02:00:26.680 --> 02:00:27.680]   may be feeling.
[02:00:27.680 --> 02:00:31.320]   This is like the rudiments of a theory of mind.
[02:00:31.320 --> 02:00:38.080]   And that it really may not have had anything to do with intelligence so much as social
[02:00:38.080 --> 02:00:39.080]   intelligence.
[02:00:39.080 --> 02:00:44.640]   - So in that sense, consciousness is a social construct?
[02:00:44.640 --> 02:00:45.640]   - Yes.
[02:00:45.640 --> 02:00:48.720]   - It's just a useful thing for interacting with other humans.
[02:00:48.720 --> 02:00:49.720]   - Yeah.
[02:00:49.720 --> 02:00:57.640]   - I don't know, but there seems to be something about realizing your own mortality that's
[02:00:57.640 --> 02:01:00.680]   somehow intricately connected to the idea of consciousness.
[02:01:00.680 --> 02:01:01.920]   - Well I think so also.
[02:01:01.920 --> 02:01:10.040]   So this is where, and Nietzsche, he said a solitary creature would not need consciousness.
[02:01:10.040 --> 02:01:13.480]   - Well what do you think?
[02:01:13.480 --> 02:01:15.720]   - Well I don't know what I think about that.
[02:01:15.720 --> 02:01:19.360]   But what I do, and then he goes on to say that consciousness is the most calamitous
[02:01:19.360 --> 02:01:22.920]   stupidity by which we shall someday perish.
[02:01:22.920 --> 02:01:26.320]   And wow, I was like dude.
[02:01:26.320 --> 02:01:29.440]   - Relax.
[02:01:29.440 --> 02:01:36.040]   But so what, if you, say you were on an island alone and you saw a reflection of yourself
[02:01:36.040 --> 02:01:41.400]   in the water, like if you were alone your whole life.
[02:01:41.400 --> 02:01:43.220]   - Great question.
[02:01:43.220 --> 02:01:50.360]   - Nietzsche's view would be that your thoughts of yourself would never come to mind.
[02:01:50.360 --> 02:01:52.720]   I don't know how I feel about that though.
[02:01:52.720 --> 02:02:00.360]   - In a sense, this sounds weird, but in a sense I feel like my mental conversation has
[02:02:00.360 --> 02:02:02.060]   always been with death.
[02:02:02.060 --> 02:02:12.960]   It's almost like another notion, like there's these visualizations of a death in the cloak.
[02:02:12.960 --> 02:02:20.560]   I always felt like I am a living thing, and then there's an other thing that is the end
[02:02:20.560 --> 02:02:21.560]   of me.
[02:02:21.560 --> 02:02:24.520]   And I'm having a conversation with that.
[02:02:24.520 --> 02:02:33.800]   So in a sense that's the way I construct my, the fact that I am a thing is because there's
[02:02:33.800 --> 02:02:38.240]   somebody else that tells me, well you won't be a thing eventually.
[02:02:38.240 --> 02:02:39.240]   - Wow.
[02:02:39.520 --> 02:02:46.280]   - So this feels like a conversation perhaps, but that might be kind of this mental simulation
[02:02:46.280 --> 02:02:51.200]   kind of idea that you're kind of, it's not really a, it's a conversation with yourself
[02:02:51.200 --> 02:02:52.200]   essentially.
[02:02:52.200 --> 02:02:53.200]   - Sure.
[02:02:53.200 --> 02:03:00.160]   - Yeah, but yeah, I don't know how I feel about that, but I tend to be in agreement
[02:03:00.160 --> 02:03:08.840]   with you when we're talking about economics more so that we're deeply social beings.
[02:03:08.840 --> 02:03:13.280]   Like everything, the way, it just feels like we're humans.
[02:03:13.280 --> 02:03:20.240]   I'm with Harari, with the Sapiens, that we're kind of, we seem to construct ideas on top
[02:03:20.240 --> 02:03:23.520]   of each other, and that's a fundamentally a social process.
[02:03:23.520 --> 02:03:24.520]   - Absolutely.
[02:03:24.520 --> 02:03:26.840]   I think that's a fine book.
[02:03:26.840 --> 02:03:31.440]   It overlaps considerably with our take on these matters.
[02:03:31.440 --> 02:03:37.560]   And the fact that we get to these points, drawing on different sources I think makes
[02:03:37.560 --> 02:03:39.240]   me more confident.
[02:03:39.240 --> 02:03:45.560]   - It's so fascinating, just like reading your book, I'm sorry, on a small tangent, that
[02:03:45.560 --> 02:03:51.880]   Sapiens is like one of the most popular books in the world.
[02:03:51.880 --> 02:03:52.880]   - Yep.
[02:03:52.880 --> 02:04:01.160]   - And just reading your book is like, oh this sounds, I mean like, I don't know, I don't
[02:04:01.160 --> 02:04:02.640]   know what makes a popular book.
[02:04:02.720 --> 02:04:08.680]   - Well if you want me to be petty and stupid, I will tell you that from time to time, we
[02:04:08.680 --> 02:04:19.640]   also wonder why our book, you know, like all books, people can take issue with it, but
[02:04:19.640 --> 02:04:21.240]   we thought it would be--
[02:04:21.240 --> 02:04:22.240]   - A bigger hit.
[02:04:22.240 --> 02:04:24.960]   - That it would be more widely read.
[02:04:24.960 --> 02:04:31.280]   - It's funny because I've, I don't know if I have good examples, 'cause I forgot already,
[02:04:31.280 --> 02:04:37.560]   but I'm often saddened by like Franz Kafka, I think he wasn't known in his life.
[02:04:37.560 --> 02:04:44.920]   But I always wonder like, these great, like some of the greatest books ever written are
[02:04:44.920 --> 02:04:52.720]   completely unknown during the author's lifetime, and it's like, man, for some reason it's again
[02:04:52.720 --> 02:04:56.520]   this identity thing, I think, oh man, that sucks.
[02:04:56.520 --> 02:05:03.160]   - Well I'm comforted by that, so Van Gogh sold one painting in his life, and evidently
[02:05:03.160 --> 02:05:13.280]   Thoreau sold like 75 copies of Walden, Nietzsche's books did not sell well.
[02:05:13.280 --> 02:05:17.120]   - How did Ernest Becker sell?
[02:05:17.120 --> 02:05:24.800]   - His books are published by the free press, and have sold more than any other books that
[02:05:24.800 --> 02:05:26.680]   they have published, so.
[02:05:26.680 --> 02:05:28.240]   - So what does that mean, it's a lot?
[02:05:28.240 --> 02:05:32.720]   - I don't know if it's like Jordan Peterson millions, but it's hundreds of thousands.
[02:05:32.720 --> 02:05:35.120]   - Was he respected?
[02:05:35.120 --> 02:05:37.960]   I just don't see him, okay.
[02:05:37.960 --> 02:05:43.880]   I don't see him brought up as like in the top 10 philosophers of--
[02:05:43.880 --> 02:05:45.760]   - No, not at all.
[02:05:45.760 --> 02:05:50.400]   - So how far away is he, is he in the top 100 for people?
[02:05:50.400 --> 02:05:51.400]   - I don't think so.
[02:05:51.400 --> 02:05:53.460]   - Like he's not brought up that often.
[02:05:53.460 --> 02:05:57.920]   - Like your work is brought up more often.
[02:05:57.920 --> 02:06:03.040]   'Cause I think he got, yeah, I mean I think he's one of the great philosophers of the
[02:06:03.040 --> 02:06:04.040]   20th century.
[02:06:04.040 --> 02:06:11.400]   - So what we say, Lex, is that our goal, certainly when we first started, and now just as much
[02:06:11.400 --> 02:06:18.320]   actually, but what I say at all my talks is, look, if these ideas have interest you enough
[02:06:18.320 --> 02:06:21.160]   to go read Ernest Becker, then this has been good.
[02:06:21.160 --> 02:06:28.720]   I consider him to be one of the most important voices of the 20th century who does not get
[02:06:28.720 --> 02:06:33.120]   the attention that he deserves.
[02:06:33.120 --> 02:06:41.060]   Similarly, our work I believe to be important because point by point we provide empirical
[02:06:41.060 --> 02:06:48.900]   corroboration for all of the claims.
[02:06:48.900 --> 02:06:54.940]   So that's literally, the students that read The Denial of Death and then Escape from Evil,
[02:06:54.940 --> 02:07:00.480]   they're like, yeah, wow, every chapter of the book you have studies.
[02:07:00.480 --> 02:07:05.200]   And I'm like, yeah, because for 40 years if a Skidmore student said, oh, that's gotta
[02:07:05.200 --> 02:07:08.900]   be bullshit, I'm like, well, let's do a study.
[02:07:08.900 --> 02:07:10.660]   - Let's do a study.
[02:07:10.660 --> 02:07:18.780]   My own dreams are in creating robots and artificial intelligence systems that a human can love.
[02:07:18.780 --> 02:07:26.500]   And I think there's something about mortality and fear mortality that is essential for implementing
[02:07:26.500 --> 02:07:29.640]   in our AI systems.
[02:07:29.640 --> 02:07:36.380]   And so maybe can you comment on that?
[02:07:36.380 --> 02:07:42.140]   So this is a different perspective on your work, which is like, how do we engineer a
[02:07:42.140 --> 02:07:43.140]   human?
[02:07:43.140 --> 02:07:44.540]   - Yeah, so, no, this is awesome, Lex.
[02:07:44.540 --> 02:07:46.180]   I'm delighted that you said that.
[02:07:46.180 --> 02:07:51.660]   First of all, and I may have mentioned this to you, I can't remember 'cause I am senile.
[02:07:51.660 --> 02:07:58.740]   When you first contacted me, I had just been told I have to learn more about your work
[02:07:58.740 --> 02:08:09.700]   because I'm working with some very talented people in New York and they're writing a screenplay
[02:08:09.700 --> 02:08:20.180]   for a movie about an artificial intelligence, it's a female AI, it's set in like 30 years
[02:08:20.180 --> 02:08:23.060]   in the future.
[02:08:23.060 --> 02:08:29.220]   And basically the little twist, this is how I had to read Heidegger.
[02:08:29.220 --> 02:08:35.200]   So these people call me and they're like, we're making a movie, it's based on Becker
[02:08:35.200 --> 02:08:44.060]   and your work and Heidegger and this other philosopher, Levinas, and then another philosopher,
[02:08:44.060 --> 02:08:47.580]   Silvia Benso, who's an Italian philosopher.
[02:08:47.580 --> 02:08:57.140]   And the long short story is the movie is about supposedly the most advanced artificial intelligence
[02:08:57.140 --> 02:09:03.960]   entity, an embodied one, and who-
[02:09:03.960 --> 02:09:05.140]   - Human form?
[02:09:05.140 --> 02:09:16.240]   - Human form, who finds out who is having essentially existential anxieties.
[02:09:16.240 --> 02:09:21.120]   And I think the project is called "A Dinner with Her" or something, and it doesn't really
[02:09:21.120 --> 02:09:33.200]   matter, but the punchline is that she finds out that her creator has made her mortal.
[02:09:33.200 --> 02:09:46.480]   And so the question is what happens phenomenologically and behaviorally to an artificial intelligence
[02:09:46.480 --> 02:09:50.360]   who now knows that it's mortal?
[02:09:50.360 --> 02:09:55.320]   And it's actually the same question that you're posing.
[02:09:55.320 --> 02:10:05.200]   And that is, is that necessary in order for an AI to approximate humanity?
[02:10:05.200 --> 02:10:16.080]   - Yeah, so the intuition, again, it's unknown, but I think it's absolutely necessary.
[02:10:16.080 --> 02:10:22.160]   A lot of people, the same kind of shallow thinking that people have about our own end
[02:10:22.160 --> 02:10:27.680]   of life, our own death, is the same way people think about artificial intelligence.
[02:10:27.680 --> 02:10:34.080]   It's like, well, okay, so yeah, so within the system there's a terminal position where
[02:10:34.080 --> 02:10:40.240]   like there's a point at which it ends, the program ends.
[02:10:40.240 --> 02:10:41.880]   There's a goal state.
[02:10:41.880 --> 02:10:43.840]   You reach the end point.
[02:10:43.840 --> 02:10:56.320]   But the thing is making that end a thing that's also within the program, like making the thing,
[02:10:56.320 --> 02:10:58.920]   and it's also the mystery of it.
[02:10:58.920 --> 02:11:03.600]   The thing is we don't know what the hell this death thing is.
[02:11:03.600 --> 02:11:12.280]   It's not like we, the program doesn't give us information about the meaning of it all.
[02:11:12.280 --> 02:11:15.360]   And that's where the terror is.
[02:11:15.360 --> 02:11:23.000]   And it feels like, I mean, in the language that you would think about is the terror of
[02:11:23.000 --> 02:11:27.480]   this death or like anticipation of it or thinking about it is the creative force that builds
[02:11:27.480 --> 02:11:28.680]   everything.
[02:11:28.680 --> 02:11:34.920]   And that feels like, that feels really important to implement.
[02:11:34.920 --> 02:11:41.040]   Again, very difficult to know how to do technically currently, but it's important to think about.
[02:11:41.040 --> 02:11:47.600]   What I find is, you mentioned screenplays and so on, is sci-fi folks and philosophers
[02:11:47.600 --> 02:11:51.200]   are the only ones thinking about it currently.
[02:11:51.200 --> 02:11:53.920]   And that's what these folks have convinced me.
[02:11:53.920 --> 02:11:54.920]   Yeah.
[02:11:54.920 --> 02:12:03.120]   And engineers aren't, which is, I get, yeah, most of the things I talk about I get kind
[02:12:03.120 --> 02:12:07.160]   of, people roll their eyes from the engineer perspective.
[02:12:07.160 --> 02:12:08.160]   Not these folks.
[02:12:08.160 --> 02:12:12.320]   They're like, because again, I saw your name and they're like, wait a minute, I've just
[02:12:12.320 --> 02:12:13.320]   seen that.
[02:12:13.320 --> 02:12:17.360]   They're like, here's someone you should check out.
[02:12:17.360 --> 02:12:18.360]   Yeah.
[02:12:18.360 --> 02:12:20.240]   So this was a delightful confluence.
[02:12:20.240 --> 02:12:21.240]   Yeah.
[02:12:21.240 --> 02:12:27.640]   I was a huge fan of your work and Ernest Becker.
[02:12:27.640 --> 02:12:31.960]   It's funny that not enough people are talking about it.
[02:12:31.960 --> 02:12:32.960]   Yeah.
[02:12:32.960 --> 02:12:33.960]   I don't know what to do with that.
[02:12:33.960 --> 02:12:38.680]   But I think that there's a possibility to create real deep, meaningful connections between
[02:12:38.680 --> 02:12:41.240]   AI systems and humans.
[02:12:41.240 --> 02:12:42.240]   Absolutely.
[02:12:42.240 --> 02:12:49.880]   And I think some of these things of fear mortality are essential for the element of human experience.
[02:12:49.880 --> 02:12:55.520]   I don't think it might be essential to create general intelligence, like very intelligent
[02:12:55.520 --> 02:13:02.320]   machines, but to create a machine that connects to a human in some deep way.
[02:13:02.320 --> 02:13:10.360]   What's your view, not to make me the interviewer, but what's your view about machine ethics?
[02:13:10.360 --> 02:13:20.200]   Can you imagine an ethical AI without some semblance of finitude, let's say?
[02:13:20.200 --> 02:13:29.560]   Well, I think ethics, there's a trolley problem that's often used in the work that I've done
[02:13:29.560 --> 02:13:30.560]   at MIT.
[02:13:30.560 --> 02:13:31.560]   Joshua Green.
[02:13:31.560 --> 02:13:32.560]   Yeah.
[02:13:32.560 --> 02:13:33.560]   Well, the Thomas vehicles in particular.
[02:13:33.560 --> 02:13:35.440]   Oh, yeah, yeah.
[02:13:35.440 --> 02:13:42.320]   That people, I think they offload, they ask like, how would a machine deal with an ethical
[02:13:42.320 --> 02:13:47.920]   situation that they themselves, humans don't know how to deal with?
[02:13:47.920 --> 02:13:48.920]   Exactly.
[02:13:48.920 --> 02:13:57.680]   And so I don't know if a machine is able to do a better job on difficult ethical questions,
[02:13:57.680 --> 02:14:03.720]   but I certainly think to behave properly and effectively in this world, it needs to have
[02:14:03.720 --> 02:14:10.120]   a fear of mortality and be able to even dance, because I don't think you can solve ethical
[02:14:10.120 --> 02:14:17.800]   problems, but you have to, I think ethics is like a dance floor, you have to dance properly
[02:14:17.800 --> 02:14:19.160]   with the rest of the humans.
[02:14:19.160 --> 02:14:22.400]   If people are dancing tango, you have to dance in the same kind of way.
[02:14:22.400 --> 02:14:25.760]   And for that, you have to have a fear of mortality.
[02:14:25.760 --> 02:14:31.760]   I think of more practically speaking, I said, autonomous vehicles, like the way you interact
[02:14:31.760 --> 02:14:37.960]   with pedestrians fundamentally has to have a sense of mortality.
[02:14:37.960 --> 02:14:47.560]   So when pedestrians cross the road, now I've watched most certainly a hundred plus hours
[02:14:47.560 --> 02:14:57.160]   of pedestrian videos, there's a kind of social contract where you walk in front of a car
[02:14:57.160 --> 02:15:01.920]   and you're putting your life in the hands of another human being.
[02:15:01.920 --> 02:15:09.040]   And like death is in the car, in the game that's being played, death is right there.
[02:15:09.040 --> 02:15:17.000]   It's part of the calculus, but it's not like a simple calculus, it's not a simple equation.
[02:15:17.000 --> 02:15:23.160]   I mean, I don't know what it is, but it's in there and it has to be part of the optimization
[02:15:23.160 --> 02:15:24.160]   problem.
[02:15:24.160 --> 02:15:29.440]   Like it's not as simple as, so from the computer vision, from the artificial intelligence perspective,
[02:15:29.440 --> 02:15:36.680]   it's detecting there's a human estimating the trajectory, like treating everything like
[02:15:36.680 --> 02:15:45.280]   it's a billiard balls, as opposed to like being able to construct an effective model,
[02:15:45.280 --> 02:15:50.160]   a world model of what the person's thinking, what they're going to do, what are the different
[02:15:50.160 --> 02:15:58.040]   possibilities of how the scene might evolve, I think requires having some sense of, yeah,
[02:15:58.040 --> 02:15:59.040]   fear of mortality.
[02:15:59.040 --> 02:16:06.640]   See, the thing is, I think it's really important to think about, I can be honest enough to
[02:16:06.640 --> 02:16:14.400]   say that I haven't been able to figure out how to engineer any of these things.
[02:16:14.400 --> 02:16:16.080]   But I do think it's really, really important.
[02:16:16.080 --> 02:16:26.240]   Like I have a bunch of Roombas here, I can show it to you after, Roombas is a robot that
[02:16:26.240 --> 02:16:27.480]   vacuums the floor.
[02:16:27.480 --> 02:16:33.720]   And I've had them make different sounds, like I had them scream in pain.
[02:16:33.720 --> 02:16:41.960]   And it, you immediately anthropomorphize.
[02:16:41.960 --> 02:16:49.600]   And it creates a, I don't know, knowing that they can feel pain, see I'm speaking, like
[02:16:49.600 --> 02:16:55.880]   knowing, I immediately imagine that they can feel pain and it immediately draws me closer
[02:16:55.880 --> 02:16:58.480]   to them, the human experience.
[02:16:58.480 --> 02:17:05.720]   And there's something in that that should be engineered in our systems, it feels like.
[02:17:05.720 --> 02:17:11.360]   I believe personally, I don't know what you think, but I believe it's possible for a robot
[02:17:11.360 --> 02:17:14.560]   and a human to fall in love, for example, in the future.
[02:17:14.560 --> 02:17:17.720]   - Oh, I think, yeah, it's already there.
[02:17:17.720 --> 02:17:23.880]   - Well, there's a certain kind of deep connection with technology, but I mean a real, like you
[02:17:23.880 --> 02:17:26.360]   would choose to marry.
[02:17:26.360 --> 02:17:31.760]   - I mean, again, it sounds, I'll find a book title and I'll send it to you.
[02:17:31.760 --> 02:17:42.640]   And it's a serious consideration of people who started out with these sex dolls, but
[02:17:42.640 --> 02:17:48.360]   it turned into a relationship of enduring significance that the woman who wrote the
[02:17:48.360 --> 02:17:52.280]   book is not willing to dismiss as a perversion.
[02:17:52.280 --> 02:17:58.520]   - Yeah, that's what, you know, people kind of joke about sex robots, which is funny.
[02:17:58.520 --> 02:18:04.120]   I mean, there's a lot of stuff about robots that's just kind of fun to talk about that
[02:18:04.120 --> 02:18:07.240]   is not necessarily connected to reality.
[02:18:07.240 --> 02:18:11.900]   People joke about sex robots, but if you actually look how sex robots, which are pretty rare
[02:18:11.900 --> 02:18:18.200]   these days, are used, they're not used by people who want sex.
[02:18:18.200 --> 02:18:19.200]   - Precisely.
[02:18:19.200 --> 02:18:20.200]   - They're actually--
[02:18:20.200 --> 02:18:21.200]   - They're companions.
[02:18:21.200 --> 02:18:24.200]   - They become companions.
[02:18:24.200 --> 02:18:30.320]   It's fascinating, and they're just, we're not even talking about any kind of intelligence,
[02:18:30.320 --> 02:18:33.720]   we're talking about just, I mean, human beings seek companionships.
[02:18:33.720 --> 02:18:34.720]   We're deeply lonely.
[02:18:34.720 --> 02:18:39.160]   I mean, that was the other sense I have that I don't know if I can articulate clearly.
[02:18:39.160 --> 02:18:43.880]   You can probably do a better job, but I have a sense that there's a deep loneliness within
[02:18:43.880 --> 02:18:44.880]   all of us.
[02:18:44.880 --> 02:18:45.880]   - Absolutely.
[02:18:45.880 --> 02:18:48.800]   - In the face of death, it feels like we're alone.
[02:18:48.800 --> 02:19:01.800]   So what drew me to the existential take on things, Lex, was the, who is it, Rollo May
[02:19:01.800 --> 02:19:11.240]   and Erwin Yalom write about existentialism, and they're like, look, there's different
[02:19:11.240 --> 02:19:18.520]   flavors of existentialism, but they all have in common, what is it, four universal concerns.
[02:19:18.520 --> 02:19:28.760]   The overriding one is about death, and that next is choice and responsibility.
[02:19:28.760 --> 02:19:36.120]   The next one is existential isolation, and they're like, that's one of the things about
[02:19:36.120 --> 02:19:39.880]   consciousness, and the last one is meaninglessness.
[02:19:39.880 --> 02:19:53.200]   But the existential isolation point is we are, by virtue of consciousness, able to apprehend
[02:19:53.200 --> 02:20:00.320]   that unless you're a Siamese twin, you are fundamentally alone.
[02:20:00.320 --> 02:20:08.080]   And because it is claimed, it's Eric Fromm in a book called "Escape from Freedom," he's
[02:20:08.080 --> 02:20:14.800]   like, look, you're smart enough to know that the most direct way that we typically communicate
[02:20:14.800 --> 02:20:21.680]   with our fellow human beings is through language, but you also know that language is a pale
[02:20:21.680 --> 02:20:29.880]   shadow of the totality of our interior phenomenological existence.
[02:20:29.880 --> 02:20:37.000]   Therefore, there's always gonna be times in our lives where even under the best of circumstances,
[02:20:37.000 --> 02:20:43.880]   you could be trying desperately to convey your thoughts and feelings, and somebody listening
[02:20:43.880 --> 02:20:48.360]   could be like, yeah, I get it, I get it, I get it, and you're like, you have no fucking
[02:20:48.360 --> 02:20:51.080]   idea what I'm talking about.
[02:20:51.080 --> 02:20:58.240]   So you can be desperately lonely in a house where you live with 10 people in the middle
[02:20:58.240 --> 02:21:00.480]   of Tokyo where there's millions.
[02:21:00.480 --> 02:21:04.560]   - Ah, yeah, it's the Great Gatsby.
[02:21:04.560 --> 02:21:06.720]   You could be alone in a big party, yeah.
[02:21:06.720 --> 02:21:07.720]   - Exactly.
[02:21:07.720 --> 02:21:14.680]   - Maybe this is a small tangent, but let me ask you on the topic of academia, you're kind
[02:21:14.680 --> 02:21:22.680]   of, we talked about Jordan Peterson, there's a lot of sort of renegade type of thinkers,
[02:21:22.680 --> 02:21:27.840]   certainly in psychology, but it applies in all disciplines.
[02:21:27.840 --> 02:21:38.560]   What are your thoughts about academia being a place to harbor people like yourself, that
[02:21:38.560 --> 02:21:46.240]   people who think deeply about things, who are not constrained by sort of the, I don't
[02:21:46.240 --> 02:21:47.920]   think you're quite controversial.
[02:21:47.920 --> 02:21:49.600]   - No, not really.
[02:21:49.600 --> 02:21:57.440]   - But you are a person who thinks deeply about things, and it feels like academia can sometimes
[02:21:57.440 --> 02:21:58.440]   stifle that.
[02:21:58.440 --> 02:21:59.520]   - I think so.
[02:21:59.520 --> 02:22:13.400]   So my concern right now, Lex, for young scholars is that the restrictions and expectations
[02:22:13.400 --> 02:22:24.600]   are such that it's highly unlikely that anybody will do anything of great value or innovation
[02:22:24.600 --> 02:22:32.320]   except for, and this is not a bad thing, but stepwise improvement of existing paradigms.
[02:22:32.320 --> 02:22:39.160]   So in simple English, I went to Princeton for a job interview 40 years ago, and they're
[02:22:39.160 --> 02:22:42.160]   like, "What are you gonna do if we give you a job?"
[02:22:42.160 --> 02:22:48.720]   And I'm like, "I don't know, I wanna think about it and read."
[02:22:48.720 --> 02:22:55.200]   And I saw that that interview was over, the window of opportunity shut in my face, and
[02:22:55.200 --> 02:23:00.480]   they actually called my mentors, and they're like, "What are you doing?
[02:23:00.480 --> 02:23:02.000]   Tell this guy to buy some pants."
[02:23:02.000 --> 02:23:03.440]   I had hair down to my waist also.
[02:23:03.440 --> 02:23:06.000]   He's like, "This guy looks like Charles Manson in Jesus."
[02:23:06.000 --> 02:23:18.040]   But the expectation is that you come to a post, you start publishing so that you can
[02:23:18.040 --> 02:23:19.040]   get grants.
[02:23:19.040 --> 02:23:22.640]   That's certainly true, but there's also kind of a behavioral thing.
[02:23:22.640 --> 02:23:26.200]   You said long hair.
[02:23:26.200 --> 02:23:28.520]   There's a certain style of the way you're supposed to behave.
[02:23:28.520 --> 02:23:33.200]   For example, I'm wearing a suit.
[02:23:33.200 --> 02:23:36.160]   It sounds weird, but I feel comfortable in this.
[02:23:36.160 --> 02:23:38.440]   I wore it when I was teaching at MIT.
[02:23:38.440 --> 02:23:44.760]   I wore it to meetings and so on, the different, sometimes a blue and red tie.
[02:23:44.760 --> 02:23:49.360]   But that was an outsider thing to do at MIT.
[02:23:49.360 --> 02:23:52.440]   So there was a strong pressure to not wear a suit.
[02:23:52.440 --> 02:23:53.440]   - No, that's right.
[02:23:53.440 --> 02:23:56.320]   - And there's a pressure to behave, to have a hair thing.
[02:23:56.320 --> 02:23:57.320]   - No, that's right.
[02:23:57.320 --> 02:23:59.800]   - The way you wear your hair, the way you...
[02:23:59.800 --> 02:24:02.680]   This isn't a liberal or a left-wing or anything.
[02:24:02.680 --> 02:24:12.160]   It's just in tribes and academia, to me, or any place that dreams of having renegade,
[02:24:12.160 --> 02:24:20.240]   free thinkers, really deep thinkers should, in fact, glorify the outsider.
[02:24:20.240 --> 02:24:25.520]   Should welcome people that don't fit in.
[02:24:25.520 --> 02:24:26.520]   - Yeah.
[02:24:26.520 --> 02:24:32.760]   - That sounds weird, but I can just imagine an interview at Princeton.
[02:24:32.760 --> 02:24:40.160]   I can imagine, why aren't you at Harvard, for example, or MIT?
[02:24:40.160 --> 02:24:46.520]   - Yeah, well, so that, look, I would love to...
[02:24:46.520 --> 02:24:49.400]   I haven't lectured at MIT, but I've lectured at Harvard.
[02:24:49.400 --> 02:24:55.960]   I've gotten to lecture at almost every place that wouldn't consider me for a job.
[02:24:55.960 --> 02:24:58.960]   And I...
[02:24:58.960 --> 02:25:01.560]   Well, a few things.
[02:25:01.560 --> 02:25:05.440]   I'm lucky because I go to Princeton, I'm like, "I don't know what I wanna do."
[02:25:05.440 --> 02:25:10.000]   And then two days later, I go to Skidmore, and I'm like, "I don't know what I wanna do."
[02:25:10.000 --> 02:25:16.080]   And they offer me a job later that day, which I declined for months because of the extraordinary
[02:25:16.080 --> 02:25:24.400]   pressure of my mentors, who right-mindedly felt that I wouldn't get much done there.
[02:25:24.400 --> 02:25:28.860]   But what they told me at Skidmore was, "Take your time.
[02:25:28.860 --> 02:25:34.160]   Show up for your classes and don't molest barnyard animals, and you'll probably get tenure."
[02:25:34.160 --> 02:25:35.840]   And I'm like, "I'll show up for my classes.
[02:25:35.840 --> 02:25:36.840]   We'll talk about it."
[02:25:36.840 --> 02:25:37.840]   - That was the negotiation.
[02:25:37.840 --> 02:25:38.840]   - Yeah, I negotiated.
[02:25:38.840 --> 02:25:43.160]   I drove a hard bargain.
[02:25:43.160 --> 02:25:46.040]   But honestly, Lex, that's...
[02:25:46.040 --> 02:25:54.640]   I feel I'm very committed to Skidmore because I was given tenure when our first terror management
[02:25:54.640 --> 02:25:57.280]   paper wasn't published.
[02:25:57.280 --> 02:25:59.000]   It took eight years to publish.
[02:25:59.000 --> 02:26:01.840]   It was rejected at every journal.
[02:26:01.840 --> 02:26:05.560]   And I submitted it as like a purple ditto sheet thing.
[02:26:05.560 --> 02:26:07.560]   I'm like, "Here's what I've been doing.
[02:26:07.560 --> 02:26:09.720]   Here's the reviews.
[02:26:09.720 --> 02:26:13.120]   Here's why I think this is still a pretty good idea."
[02:26:13.120 --> 02:26:17.560]   And I don't know that this would happen even at Skidmore anymore, but I was very lucky
[02:26:17.560 --> 02:26:21.800]   to be given the latitude and to be encouraged.
[02:26:21.800 --> 02:26:24.160]   I took classes at Skidmore.
[02:26:24.160 --> 02:26:26.680]   That's how I learned all this stuff.
[02:26:26.680 --> 02:26:29.960]   I got a PhD unscathed by knowledge.
[02:26:29.960 --> 02:26:39.280]   We were great statisticians and methodologists, but we didn't have any substance.
[02:26:39.280 --> 02:26:45.240]   And I don't mean this cynically, but we were trained in a method in search of a question.
[02:26:45.240 --> 02:26:51.980]   So I appreciate having five years at Skidmore basically to read books.
[02:26:51.980 --> 02:26:57.880]   And I also appreciate that I look like this 40 years ago.
[02:26:57.880 --> 02:27:08.440]   And my view is that this is how I comported myself.
[02:27:08.440 --> 02:27:14.440]   Other people, the guy I learned the most from at Skidmore is now dead, a history professor,
[02:27:14.440 --> 02:27:16.040]   Ted Kuroda.
[02:27:16.040 --> 02:27:18.200]   He wore a bow tie.
[02:27:18.200 --> 02:27:22.560]   And there's another guy, Darnell Rucker, who taught me about philosophy.
[02:27:22.560 --> 02:27:31.000]   And he was very proper and he had his jacket with the leather patches.
[02:27:31.000 --> 02:27:34.240]   But these guys weren't pompous at all.
[02:27:34.240 --> 02:27:38.640]   They were, "This is the way I am."
[02:27:38.640 --> 02:27:46.080]   And I always felt that that's important, that somebody who looks at you and says, "Oh, what
[02:27:46.080 --> 02:27:47.080]   a stiff.
[02:27:47.080 --> 02:27:48.080]   He's probably an MBA."
[02:27:48.080 --> 02:27:50.400]   Well, they're wrong.
[02:27:50.400 --> 02:27:56.640]   And someone who looks at me, when I first got to Skidmore, other professors would ask
[02:27:56.640 --> 02:27:59.720]   when I'd be coming to their office to empty the garbage.
[02:27:59.720 --> 02:28:04.680]   They just assumed, as in my 20s, they assumed I was housekeeping.
[02:28:04.680 --> 02:28:10.080]   I always felt that was important that the students learn not to judge an idea by the
[02:28:10.080 --> 02:28:13.720]   appearance of the person who purveys it.
[02:28:13.720 --> 02:28:22.520]   - Yeah, I mean, I guess this is such a high concern now because I personally still have
[02:28:22.520 --> 02:28:25.840]   faith that academia is where the great geniuses will come from.
[02:28:25.840 --> 02:28:26.840]   - I do too.
[02:28:26.840 --> 02:28:27.840]   - And great ideas.
[02:28:27.840 --> 02:28:29.480]   - I love hearing you say that.
[02:28:29.480 --> 02:28:37.800]   I still, and it's one of the reasons why I'm really apprehensive about the future of education
[02:28:37.800 --> 02:28:41.120]   right now in the context of the pandemic.
[02:28:41.120 --> 02:28:42.120]   - Oh, yeah.
[02:28:42.120 --> 02:28:49.520]   - Is that a lot of folks, and a lot of these are Google-type people who I don't, you know,
[02:28:49.520 --> 02:28:56.720]   they're geniuses also, but I don't like this idea that all learning can be virtual and
[02:28:56.720 --> 02:28:58.680]   that much could happen.
[02:28:58.680 --> 02:29:02.840]   I'm big on embodied environments with actual humans interacting.
[02:29:02.840 --> 02:29:12.720]   - I mean, there's so much to the university education, but I think the key part is the
[02:29:12.720 --> 02:29:16.400]   mentorship that occurs somehow at the human level.
[02:29:16.400 --> 02:29:24.560]   Like I've gotten a lot of flack, like this conversation, we're in person now, and I've,
[02:29:24.560 --> 02:29:32.280]   even with Edward Snowden, who done all interviews remote, I'm a stickler to in-person.
[02:29:32.280 --> 02:29:34.520]   It has to be in person.
[02:29:34.520 --> 02:29:36.320]   And a lot of people just don't get it.
[02:29:36.320 --> 02:29:39.640]   They're like, "Well, why can't, this is so much easier.
[02:29:39.640 --> 02:29:40.960]   Why go through the pain?"
[02:29:40.960 --> 02:29:48.240]   Like I've traveled, I'm traveling in the next month to Paris for a single stupid conversation
[02:29:48.240 --> 02:29:51.440]   nobody cares about just to be in person.
[02:29:51.440 --> 02:29:54.040]   - Well, it's important to me.
[02:29:54.040 --> 02:29:59.200]   Honestly, I was like, this...
[02:29:59.200 --> 02:30:00.440]   - And thank you for coming down today.
[02:30:00.440 --> 02:30:01.440]   - Oh, it's my pleasure.
[02:30:01.440 --> 02:30:03.320]   But again, it's very self-serving.
[02:30:03.320 --> 02:30:04.320]   I've enjoyed this.
[02:30:04.320 --> 02:30:09.600]   I knew I was going to, but it's not about our enjoyment per se.
[02:30:09.600 --> 02:30:21.360]   Again, at the risk of sounding cavalier, there are a host of factors beyond verbal that I
[02:30:21.360 --> 02:30:25.400]   don't believe can be adequately captured.
[02:30:25.400 --> 02:30:30.800]   I don't care how much the acuity is decent on a Zoom conversation.
[02:30:30.800 --> 02:30:43.880]   I feel, again, I felt within five minutes that this was going to be, for me, easy in
[02:30:43.880 --> 02:30:45.840]   the sense that I could speak freely.
[02:30:45.840 --> 02:30:50.560]   I just don't see that happening so easily from a distance.
[02:30:50.560 --> 02:30:52.040]   - Yeah, I tend to.
[02:30:52.040 --> 02:30:56.960]   Well, I'm hopeful, I agree with you on the current technology, but I am hopeful, unlike
[02:30:56.960 --> 02:31:01.680]   some others, on the technology eventually being able to create that kind of experience.
[02:31:01.680 --> 02:31:03.040]   - Oh, I think it's...
[02:31:03.040 --> 02:31:05.800]   - We're quite far away from that, but it might be able...
[02:31:05.800 --> 02:31:09.520]   My hope is, I'm hopeful.
[02:31:09.520 --> 02:31:14.920]   - I was at Microsoft in Seattle, and I can't remember why.
[02:31:14.920 --> 02:31:18.200]   No, I can't.
[02:31:18.200 --> 02:31:19.420]   That's how...
[02:31:19.420 --> 02:31:29.360]   I'm in my early Mr. Magoo phase, and somebody there was showing us a virtual wall where
[02:31:29.360 --> 02:31:34.120]   the entire wall, when you're talking to somebody...
[02:31:34.120 --> 02:31:41.960]   So it's life-size, and they were beginning to get the appearance of motion and stuff.
[02:31:41.960 --> 02:31:42.960]   It looked pretty...
[02:31:42.960 --> 02:31:44.840]   - Yeah, with virtual reality, too.
[02:31:44.840 --> 02:31:47.720]   I don't know if you've ever been inside a virtual world.
[02:31:47.720 --> 02:31:53.120]   To me, I can see the future.
[02:31:53.120 --> 02:31:54.880]   It's quite real.
[02:31:54.880 --> 02:31:58.920]   In terms of a terror of death, I'm afraid of heights.
[02:31:58.920 --> 02:31:59.920]   - Me too.
[02:31:59.920 --> 02:32:00.920]   - And there's...
[02:32:00.920 --> 02:32:03.360]   I don't know if you've ever tried.
[02:32:03.360 --> 02:32:04.360]   You should if you haven't.
[02:32:04.360 --> 02:32:08.600]   There's a virtual reality experience where you can walk a plank, and you can look down,
[02:32:08.600 --> 02:32:12.360]   and man, I was on the ground, like, terrified.
[02:32:12.360 --> 02:32:13.360]   I was like...
[02:32:13.360 --> 02:32:14.360]   I was afraid.
[02:32:14.360 --> 02:32:15.360]   I was deeply afraid.
[02:32:15.360 --> 02:32:21.560]   It was as real as anything else could be.
[02:32:21.560 --> 02:32:25.840]   I mean, these are very early days of that technology, relatively speaking.
[02:32:25.840 --> 02:32:30.560]   So yeah, I mean, I don't know what to do with that.
[02:32:30.560 --> 02:32:31.920]   Same with crossing the street.
[02:32:31.920 --> 02:32:39.200]   We did these experiments crossing the street in front of a car, and just being run over
[02:32:39.200 --> 02:32:41.600]   by a car.
[02:32:41.600 --> 02:32:43.280]   It's terrifying.
[02:32:43.280 --> 02:32:44.760]   It's just that...
[02:32:44.760 --> 02:32:49.200]   Yeah, so there is a rich experience to be created there.
[02:32:49.200 --> 02:32:52.600]   We're not there yet, but yeah.
[02:32:52.600 --> 02:32:57.320]   And I've seen a lot of people try, like you said, the Google folks, Silicon Valley folks
[02:32:57.320 --> 02:33:00.440]   try to create a virtual online education.
[02:33:00.440 --> 02:33:01.440]   I don't know.
[02:33:01.440 --> 02:33:10.280]   I think they've raised really important questions about what makes the education experience
[02:33:10.280 --> 02:33:12.440]   fulfilling, what makes it effective.
[02:33:12.440 --> 02:33:14.560]   Yeah, these are important questions.
[02:33:14.560 --> 02:33:20.120]   And I think what they highlight is we have no clue.
[02:33:20.120 --> 02:33:27.640]   There's Thomas Sowell wrote a book about...
[02:33:27.640 --> 02:33:30.680]   Recent book on charter schools.
[02:33:30.680 --> 02:33:32.560]   Yeah, I would like to talk to him.
[02:33:32.560 --> 02:33:34.520]   Yeah, he's an interesting guy.
[02:33:34.520 --> 02:33:37.120]   We will disagree about a lot, but respectfully.
[02:33:37.120 --> 02:33:40.200]   Yeah, such a powerful mind.
[02:33:40.200 --> 02:33:42.560]   I need to read...
[02:33:42.560 --> 02:33:52.200]   I've only heard him talk about the book, but he argues quite seemingly effectively that
[02:33:52.200 --> 02:33:55.440]   the public education system is broken.
[02:33:55.440 --> 02:33:56.440]   That we blame...
[02:33:56.440 --> 02:34:06.200]   He basically says that we kind of blame the conditions or the environment, but the upbringing
[02:34:06.200 --> 02:34:11.960]   of people like parenting, blah, blah, blah, like the set of opportunities.
[02:34:11.960 --> 02:34:18.760]   But okay, putting that aside, it seems like charter schools, no matter who it is that
[02:34:18.760 --> 02:34:22.840]   attends them, does much better than in public schools.
[02:34:22.840 --> 02:34:25.360]   And he puts a bunch of data behind it.
[02:34:25.360 --> 02:34:31.840]   And in his usual way, as you know, just is very eloquent in arguing his points.
[02:34:31.840 --> 02:34:39.840]   So that to me just highlights, man, education is probably the most important thing in our
[02:34:39.840 --> 02:34:45.680]   civilization and we're doing a shitty job of it.
[02:34:45.680 --> 02:34:53.200]   In academia, in university education, and younger education, the whole thing.
[02:34:53.200 --> 02:34:54.600]   The whole thing.
[02:34:54.600 --> 02:35:06.160]   And yet we value just about anyone or anything more than educators.
[02:35:06.160 --> 02:35:15.680]   Part of it is just the relatively low regard that Americans have for teachers.
[02:35:15.680 --> 02:35:25.860]   Also similarly, just people of service, I think great teachers are the greatest thing
[02:35:25.860 --> 02:35:26.860]   in our society.
[02:35:26.860 --> 02:35:33.920]   And I would say now on a controversial note, like Black Lives Matter, great police officers
[02:35:33.920 --> 02:35:36.620]   is the greatest thing in our society also.
[02:35:36.620 --> 02:35:42.160]   All people that do service, we undervalue cops.
[02:35:42.160 --> 02:35:45.160]   This whole defund the police is missing the point.
[02:35:45.160 --> 02:35:47.480]   And it's a stupid word.
[02:35:47.480 --> 02:35:50.480]   I'm with you on that, Lex.
[02:35:50.480 --> 02:35:56.240]   Neighbors to one side of our house are three generations of police, our neighbors across
[02:35:56.240 --> 02:36:00.000]   the street are police.
[02:36:00.000 --> 02:36:07.960]   They know my political predilections.
[02:36:07.960 --> 02:36:11.720]   And we've gotten along fine for 30 years.
[02:36:11.720 --> 02:36:18.280]   And I go out and tell them every day, when you go in today, you tell the people on the
[02:36:18.280 --> 02:36:24.800]   force that I appreciate what they're doing.
[02:36:24.800 --> 02:36:32.480]   I think it's really important to not tribalize those concerns.
[02:36:32.480 --> 02:36:42.040]   - I mean, we mentioned so many brilliant books and philosophers, but it'd be nice to sort
[02:36:42.040 --> 02:36:47.440]   of in a focused way, try to see if we can get some recommendations from you.
[02:36:47.440 --> 02:36:53.000]   So what three books, technical or fiction or philosophical had a-
[02:36:53.000 --> 02:36:54.000]   - Oh man.
[02:36:54.000 --> 02:36:55.000]   - This is the worst question.
[02:36:55.000 --> 02:36:56.000]   - Well, you know what?
[02:36:56.000 --> 02:36:59.000]   - Had a big impact in your life and you would recommend?
[02:36:59.000 --> 02:37:03.920]   - I spent four hours driving here, perseverating about that.
[02:37:03.920 --> 02:37:04.920]   Everything else you sent me.
[02:37:04.920 --> 02:37:05.920]   - That's fine.
[02:37:05.920 --> 02:37:11.320]   - And I actually, I skimmed it and I'm like, I don't want to look at it because I want
[02:37:11.320 --> 02:37:12.760]   us to talk.
[02:37:12.760 --> 02:37:15.840]   The ones in blue, I'm like, all right.
[02:37:15.840 --> 02:37:26.320]   And I've already said that I've found Becker's work and I put "The Denial of Death" out there.
[02:37:26.320 --> 02:37:27.320]   - Is that his best?
[02:37:27.320 --> 02:37:28.960]   Sorry, to go on a small tangent.
[02:37:28.960 --> 02:37:31.200]   Is there other books of his?
[02:37:31.200 --> 02:37:36.800]   - Yes, if I could have this count as one, that "The Birth and Death of Meaning", "The
[02:37:36.800 --> 02:37:43.920]   Denial of Death" and "Escape from Evil" are three books of Ernest Becker's that I believe
[02:37:43.920 --> 02:37:47.480]   to all be profound.
[02:37:47.480 --> 02:37:54.200]   - In a little sort of brief dance around topics, I've only read "Denial of Death".
[02:37:54.200 --> 02:37:55.600]   How do those books connect in your-
[02:37:55.600 --> 02:37:56.600]   - Yeah, nice.
[02:37:56.600 --> 02:38:04.320]   So "The Birth and Death of Meaning" is where Becker situates his thinking in more of an
[02:38:04.320 --> 02:38:06.660]   evolutionary foundation.
[02:38:06.660 --> 02:38:09.160]   So I like that for that reason.
[02:38:09.160 --> 02:38:19.080]   "Escape from Evil" is where he applies the ideas in "The Denial of Death" more directly
[02:38:19.080 --> 02:38:28.520]   to economic matters and to inequality, and also to our inability to peacefully coexist
[02:38:28.520 --> 02:38:30.940]   with other folks who don't share our beliefs.
[02:38:30.940 --> 02:38:36.560]   So I would put Ernest Becker out there as one.
[02:38:36.560 --> 02:38:39.520]   I also like novels a lot.
[02:38:39.520 --> 02:38:46.200]   And here I was like, "God damn it, no matter what I say, I'm gonna be like, 'Yes, but.'"
[02:38:46.200 --> 02:38:49.000]   - "The Existentialist", do you like all those folks?
[02:38:49.000 --> 02:38:52.320]   "Camus", do you like that literary existentialist?
[02:38:52.320 --> 02:38:58.240]   - I do, but I mean, I've read all those books.
[02:38:58.240 --> 02:39:02.800]   I will tell you the last line of "The Plague", "We learn in times of pestilence that there's
[02:39:02.800 --> 02:39:06.800]   more to admire in men than to despise."
[02:39:06.800 --> 02:39:07.800]   And I love that.
[02:39:07.800 --> 02:39:08.800]   - Yeah.
[02:39:08.800 --> 02:39:12.680]   "The Plague" is such a, I don't know, I find "The Plague" is a brilliant book.
[02:39:12.680 --> 02:39:13.680]   - Me too.
[02:39:13.680 --> 02:39:18.960]   - And before "The Plague" has come to us in 2020, it was just such a good book.
[02:39:18.960 --> 02:39:19.960]   - Yes, so.
[02:39:19.960 --> 02:39:21.800]   - A book about love, about...
[02:39:21.800 --> 02:39:25.240]   - But I'll toss one that may be less known to folks.
[02:39:25.240 --> 02:39:31.400]   I'm enamored with a novel by a woman named Carson McCullers, written in 1953, called
[02:39:31.400 --> 02:39:34.120]   "Clock Without Hands".
[02:39:34.120 --> 02:39:41.440]   And I find it a brilliant literary depiction of many of the ideas that we have spoken about.
[02:39:41.440 --> 02:39:42.440]   - Fiction?
[02:39:42.440 --> 02:39:43.440]   - Fiction, yeah.
[02:39:43.440 --> 02:39:46.880]   - What kind of ideas are we talking about?
[02:39:46.880 --> 02:39:52.840]   - All of the existential ideas that we have encountered today, but in the context of a
[02:39:52.840 --> 02:39:59.280]   story of someone who finds out that he is terminally ill.
[02:39:59.280 --> 02:40:04.980]   It's set in the South, in the heyday of like segregation.
[02:40:04.980 --> 02:40:11.120]   So there's a lot of social issues, a lot of existential issues, but it's basically a fictional
[02:40:11.120 --> 02:40:19.660]   account of someone who finds out that they're terminally ill and who reacts originally
[02:40:19.660 --> 02:40:30.160]   as you might expect anyone, becomes more hostile to people who are different, like petty and
[02:40:30.160 --> 02:40:33.620]   stupid, denies that anything's happening.
[02:40:33.620 --> 02:40:45.700]   But as the book goes on and he comes more to terms with his own mortality, it ends lovingly.
[02:40:45.700 --> 02:40:53.980]   And back to your idea about love being incredibly potent.
[02:40:53.980 --> 02:40:59.500]   - That's the nice thing, as you mentioned before with Heidegger.
[02:40:59.500 --> 02:41:06.420]   I really like that idea, and I've seen that in people who are terminally ill, is they
[02:41:06.420 --> 02:41:12.540]   bring, the idea of death becomes current.
[02:41:12.540 --> 02:41:15.300]   It becomes like a thing, I could die.
[02:41:15.300 --> 02:41:23.820]   I really like that idea, I can die not just tomorrow, but like now.
[02:41:23.820 --> 02:41:28.980]   That's a really useful, I don't even know, I think I've been too afraid to even think
[02:41:28.980 --> 02:41:29.980]   about that.
[02:41:29.980 --> 02:41:30.980]   - I have.
[02:41:30.980 --> 02:41:38.100]   - Like sit here and think like in five minutes, it's over.
[02:41:38.100 --> 02:41:39.100]   - Yeah.
[02:41:39.100 --> 02:41:43.060]   - This is it, in five minutes it's over.
[02:41:43.060 --> 02:41:50.580]   - So that would be my most recent addition, is I really am struck by Heidegger.
[02:41:50.580 --> 02:41:51.580]   - Would you recommend that?
[02:41:51.580 --> 02:41:53.580]   - Well, okay, if you have a few years.
[02:41:53.580 --> 02:41:57.260]   - I remember I tuned out, being in time, I was like, I tried to read it, I was like,
[02:41:57.260 --> 02:41:58.260]   that's it.
[02:41:58.260 --> 02:42:05.700]   It took me 40 years to read Ulysses, I could not get past the first five pages, and it
[02:42:05.700 --> 02:42:11.620]   took me 40 years to read Being in Time, it's a slog.
[02:42:11.620 --> 02:42:19.300]   - I took a James Joyce course in college, so I even, I guess read parts of Finnegans
[02:42:19.300 --> 02:42:20.300]   Wake.
[02:42:20.300 --> 02:42:21.300]   - No way.
[02:42:21.300 --> 02:42:27.340]   - But like, there's a difference between reading and like, I don't think I understood anything.
[02:42:27.340 --> 02:42:29.020]   - I like his short stories.
[02:42:29.020 --> 02:42:30.020]   - Me too.
[02:42:30.020 --> 02:42:31.020]   - The Dead.
[02:42:31.020 --> 02:42:32.020]   - Yeah, I love that.
[02:42:32.020 --> 02:42:37.860]   - And I like Faulkner, Absalom, Absalom is a fine book.
[02:42:37.860 --> 02:42:43.500]   - But would you, is there something Heidegger connected in a book you would recommend or
[02:42:43.500 --> 02:42:44.500]   no?
[02:42:44.500 --> 02:42:46.060]   - No, so maybe I got to abandon him.
[02:42:46.060 --> 02:42:54.220]   I mean, Being in Time is awesome, but here's an interesting thing, and not to get all academic-y,
[02:42:54.220 --> 02:43:01.180]   but you know, there's two parts to it, and most philosophers are preoccupied with the
[02:43:01.180 --> 02:43:02.860]   first part.
[02:43:02.860 --> 02:43:09.300]   It's in the second part where he gets into all the flight from death stuff and this idea
[02:43:09.300 --> 02:43:14.460]   of a turning, and philosophers don't like that.
[02:43:14.460 --> 02:43:17.300]   And I'm like, this is where he's starting to--
[02:43:17.300 --> 02:43:18.300]   - Really shine.
[02:43:18.300 --> 02:43:20.020]   - To really shine for me, so.
[02:43:20.020 --> 02:43:21.020]   - Yeah.
[02:43:21.020 --> 02:43:22.020]   - Yeah.
[02:43:22.020 --> 02:43:23.020]   - All right, that's a beautiful set of books.
[02:43:23.020 --> 02:43:34.580]   So what advice would you give to a young person today about their career, about life, about
[02:43:34.580 --> 02:43:37.900]   how to survive in this world full of suffering?
[02:43:37.900 --> 02:43:40.780]   - Yeah, great.
[02:43:40.780 --> 02:43:42.980]   My advice is to get competent advice.
[02:43:42.980 --> 02:43:46.780]   That's what I tell my students at Stitt-Mart.
[02:43:46.780 --> 02:43:47.780]   - Don't listen to me.
[02:43:47.780 --> 02:43:48.780]   - Yeah, don't listen to me.
[02:43:48.780 --> 02:43:59.580]   - Well, you know, I think my big piece of advice these days is, you know, again, it's
[02:43:59.580 --> 02:44:08.420]   at the risk of sounding like a simpleton, but it's to emphasize a few things.
[02:44:08.420 --> 02:44:16.500]   One is, you know, one of your questions, I think, was, you know, what's the meaning of
[02:44:16.500 --> 02:44:17.500]   life?
[02:44:17.500 --> 02:44:22.740]   And I think the existentialists say, life has no meaning, but it doesn't follow from
[02:44:22.740 --> 02:44:26.340]   that that it's intrinsic, that it's meaningless.
[02:44:26.340 --> 02:44:32.740]   You know what, the existential point is not that life is meaningless so much as it doesn't
[02:44:32.740 --> 02:44:42.180]   have one inevitable and intrinsic meaning, you know, which then it opens up, you know,
[02:44:42.180 --> 02:44:48.740]   I think it was Kierkegaard who said, "Consciousness gives us the possibility of possibilities."
[02:44:48.740 --> 02:44:55.620]   But there's another lunatic, Oswald Spengler, who wrote a book called "Decline of the West."
[02:44:55.620 --> 02:45:01.140]   And he says that the philosopher, the German philosopher, Goethe, he says, "The purpose
[02:45:01.140 --> 02:45:04.300]   of life is to live."
[02:45:04.300 --> 02:45:07.300]   And so that's one of my pieces of advice.
[02:45:07.300 --> 02:45:11.200]   - So the possibility of possibilities, it's interesting.
[02:45:11.200 --> 02:45:14.460]   So what do you do with this kind of sea of possibilities?
[02:45:14.460 --> 02:45:23.220]   Like while, this is one of the, when young folks talk to me, especially these days, is
[02:45:23.220 --> 02:45:25.220]   there swimming in a sea of possibilities?
[02:45:25.220 --> 02:45:27.500]   - Yeah, well, so this, it's great.
[02:45:27.500 --> 02:45:35.540]   And so that's another existential point, which is that we yearn for freedom, we react vigorously
[02:45:35.540 --> 02:45:43.100]   when we perceive that our choices have been curtailed, and then we're paralyzed by indecision
[02:45:43.100 --> 02:45:49.700]   in the wake of seemingly unlimited possibilities because we're not choking on choice.
[02:45:49.700 --> 02:45:58.020]   And I'm not sure if this is helpful advice or not, but what I say to folks is that the
[02:45:58.020 --> 02:46:06.540]   fact of the matter is, is that for most people, choice is a first world problem.
[02:46:06.540 --> 02:46:18.020]   And sometimes the best option is to do something, as silly as it sounds, and then if that doesn't
[02:46:18.020 --> 02:46:24.300]   work, do something else, which just sounds like my mom torturing me when I was young.
[02:46:24.300 --> 02:46:33.860]   But part of the thing that I find myself singularly ill-equipped is that we're at the, I may be
[02:46:33.860 --> 02:46:40.860]   at the tail end of the last generation of Americans where you like picked something
[02:46:40.860 --> 02:46:42.400]   and that's what you did.
[02:46:42.400 --> 02:46:48.100]   Like I've been at a job for 40 years, where you can expect to do better than your parents
[02:46:48.100 --> 02:46:56.100]   because those days are gone, and where you can make a comfortable inference that the
[02:46:56.100 --> 02:47:05.260]   world in a decade or two will have any remote similarity to the one that we now inhabit.
[02:47:05.260 --> 02:47:06.260]   And so-
[02:47:06.260 --> 02:47:09.020]   But still, you recommend just do.
[02:47:09.020 --> 02:47:10.100]   Yeah.
[02:47:10.100 --> 02:47:20.740]   And to do so, again, this is, so back to the Heidegger guy, because, all right, I consider
[02:47:20.740 --> 02:47:26.400]   myself a professor, but what happens if most of the schools go out of business?
[02:47:26.400 --> 02:47:34.460]   Somebody else may consider themselves a restaurateur, but what happens if there's no more restaurants?
[02:47:34.460 --> 02:47:42.860]   So what I, this is negative advice, but I tell folks, don't define yourself as a social
[02:47:42.860 --> 02:47:43.860]   caricature.
[02:47:43.860 --> 02:47:44.860]   Yeah.
[02:47:44.860 --> 02:48:01.260]   Don't limit how you feel about yourself by, through identification with a host of variables
[02:48:01.260 --> 02:48:03.420]   that may be uncertain.
[02:48:03.420 --> 02:48:04.420]   Maybe temporary.
[02:48:04.420 --> 02:48:05.420]   What?
[02:48:05.420 --> 02:48:06.420]   Oh, sorry.
[02:48:06.420 --> 02:48:11.060]   No, but of course, that gets back to your point earlier, Lex, where you're like, yeah,
[02:48:11.060 --> 02:48:17.940]   but when you step out of that, it's extraordinarily discombobulating.
[02:48:17.940 --> 02:48:27.620]   So what, I think you talked about an axe of chopping wood and soul from Socrates.
[02:48:27.620 --> 02:48:35.460]   What is your soul, what is the essence of Sheldon?
[02:48:35.460 --> 02:48:36.460]   Wow.
[02:48:36.460 --> 02:48:39.620]   That was like, awesome.
[02:48:39.620 --> 02:48:45.420]   Like when God, when you show up at the end of this thing, He kind of looks at you, He's
[02:48:45.420 --> 02:48:48.820]   like, "Oh, yeah, I remember you."
[02:48:48.820 --> 02:49:05.580]   Well, you know, to be honest, what I muse about is to me, when people are, I told you,
[02:49:05.580 --> 02:49:17.420]   we have two kids, late 20s, early 30s, and over the years, when we meet people that know
[02:49:17.420 --> 02:49:23.700]   our kids and they're like, "Oh, your kids are kind and decent."
[02:49:23.700 --> 02:49:29.140]   And I'd be like, that's what I would like to be.
[02:49:29.140 --> 02:49:32.300]   Because I think intelligence is vastly overrated.
[02:49:32.300 --> 02:49:34.940]   You know, the Unabomber was a smart guy.
[02:49:34.940 --> 02:49:44.100]   And I do admire intelligence and I do venerate education and I find that to be tremendously
[02:49:44.100 --> 02:49:46.060]   important.
[02:49:46.060 --> 02:49:53.860]   But if I had to pay the ultimate homage to myself, it would be to be known as somebody
[02:49:53.860 --> 02:49:58.380]   who takes himself too seriously to take myself too seriously.
[02:49:58.380 --> 02:50:07.460]   Again, as corny as it sounds, I like to leave the world a tad better than I found it, or
[02:50:07.460 --> 02:50:10.940]   at least do no harm.
[02:50:10.940 --> 02:50:17.100]   And I think you did all right in that regard.
[02:50:17.100 --> 02:50:18.580]   I love that question, Alex.
[02:50:18.580 --> 02:50:19.580]   That's a good one.
[02:50:19.580 --> 02:50:21.700]   I think everyone should be asked that.
[02:50:21.700 --> 02:50:24.060]   What is your soul?
[02:50:24.060 --> 02:50:31.860]   Do you have maybe just a few lingering questions around it?
[02:50:31.860 --> 02:50:38.300]   So I mean, on the point of the soul, you've talked about the meaning of life.
[02:50:38.300 --> 02:50:50.580]   Do you have, on a personal level, do you have an answer to the meaning of your life, of
[02:50:50.580 --> 02:51:05.300]   something that brought you meaning, happiness, some sense of sense?
[02:51:05.300 --> 02:51:08.300]   Yeah.
[02:51:08.300 --> 02:51:11.780]   No, I mean, yes and no.
[02:51:11.780 --> 02:51:23.580]   I mean, I'm 66, so I'm in the kind of not ready to wrap it up, literally or metaphorically,
[02:51:23.580 --> 02:51:35.260]   but I look back and just really with a sense of awe and wonder, gratitude.
[02:51:35.260 --> 02:51:42.300]   Is there memories that stand out to you from childhood, from earlier, that stand out as
[02:51:42.300 --> 02:51:49.700]   something you're really proud of or just happy to have been on this earth?
[02:51:49.700 --> 02:51:51.540]   Does that stuff happen?
[02:51:51.540 --> 02:51:53.380]   Mainly, yeah, that.
[02:51:53.380 --> 02:52:04.980]   My family, also a chunk, my folks, my grandparents are from Eastern Europe, Russia, Austria.
[02:52:04.980 --> 02:52:08.180]   As far as we know, some of them never made it out.
[02:52:08.180 --> 02:52:22.300]   I consider myself very fortunate to have been a so-called product of the American dream.
[02:52:22.300 --> 02:52:26.340]   My grandparents were basically peasants.
[02:52:26.340 --> 02:52:33.980]   My parents, my dad worked two full-time jobs when I was growing up, and I would see him
[02:52:33.980 --> 02:52:36.900]   on the weekends, I'd be like, "Why are you working all the time?"
[02:52:36.900 --> 02:52:41.380]   He'd be like, "So you won't have to."
[02:52:41.380 --> 02:52:47.460]   He said, "Look, the world does not owe you a living, and so your first responsibility
[02:52:47.460 --> 02:52:55.620]   is to take care of yourself, and then your next responsibility is to take care of other
[02:52:55.620 --> 02:52:56.620]   people."
[02:52:56.620 --> 02:53:00.060]   I think you did a pretty good job of that.
[02:53:00.060 --> 02:53:08.940]   I don't know, but those are the things that I'm proud of.
[02:53:08.940 --> 02:53:17.420]   It's funny, you've talked about just yourself as a human being, but you've also contributed
[02:53:17.420 --> 02:53:29.060]   some really important ideas for your ideas and also integrating and maybe even popularizing
[02:53:29.060 --> 02:53:37.620]   the work of Ernest Becker, of connecting it, of making it legitimate scientifically.
[02:53:37.620 --> 02:53:44.340]   As a human, of course, you want your ripple to be one that makes the world a better place,
[02:53:44.340 --> 02:53:51.980]   but also I think in the span of time, I think it's of great value what you've contributed
[02:53:51.980 --> 02:53:58.980]   in terms of how we think about the human condition, how we think about ourselves, assuming as
[02:53:58.980 --> 02:54:01.580]   finite beings in this world.
[02:54:01.580 --> 02:54:08.740]   I hope also in our technology of engineering intelligence, I think, at least for me, and
[02:54:08.740 --> 02:54:14.460]   I'm sure there's a lot of other people like me that your work has been a gift for.
[02:54:14.460 --> 02:54:16.380]   - Oh, well, thank you.
[02:54:16.380 --> 02:54:18.060]   I like that.
[02:54:18.060 --> 02:54:21.540]   We have described ourselves as giant interneurons.
[02:54:21.540 --> 02:54:28.780]   I'm like, we have had no original ideas, and maybe that's the only thing that's original
[02:54:28.780 --> 02:54:31.380]   about our work is we don't claim to be original.
[02:54:31.380 --> 02:54:42.020]   What we claim to have done is to integrate, to connect these disparate and superficially
[02:54:42.020 --> 02:54:44.260]   unconnected discourses.
[02:54:44.260 --> 02:54:47.100]   So existentialists, they'd be like, "Evidence?
[02:54:47.100 --> 02:54:49.180]   What's that?"
[02:54:49.180 --> 02:54:54.460]   And yeah, there's now a branch of psychology, experimental existential psychology that I
[02:54:54.460 --> 02:55:05.740]   think we could take credit for having encouraged the formation of, and that in turn has gotten
[02:55:05.740 --> 02:55:13.860]   these ideas in circulation in academic communities where they may not have otherwise gotten.
[02:55:13.860 --> 02:55:14.860]   So I think that's good.
[02:55:14.860 --> 02:55:17.220]   - Well, Sheldon, it's a huge honor.
[02:55:17.220 --> 02:55:19.860]   I can't believe you came down here.
[02:55:19.860 --> 02:55:22.820]   I've been a fan of your work.
[02:55:22.820 --> 02:55:24.860]   I hope we get to talk again.
[02:55:24.860 --> 02:55:25.860]   Huge honor to talk to you.
[02:55:25.860 --> 02:55:26.860]   Thank you so much for talking today.
[02:55:26.860 --> 02:55:27.860]   - Thanks, Lex.
[02:55:27.860 --> 02:55:28.860]   We'll do it again soon, I hope.
[02:55:28.860 --> 02:55:33.140]   - Thanks for listening to this conversation with Sheldon Solomon, and thank you to our
[02:55:33.140 --> 02:55:37.700]   sponsors, Blinkist, ExpressVPN, and Cash App.
[02:55:37.700 --> 02:55:40.100]   Click the links in the description to get a discount.
[02:55:40.100 --> 02:55:42.060]   It's the best way to support this podcast.
[02:55:42.060 --> 02:55:46.900]   If you enjoy this thing, subscribe on YouTube, review it with Five Star Snapper Podcast,
[02:55:46.900 --> 02:55:52.780]   follow on Spotify, support on Patreon, or connect with me on Twitter @LexFriedman.
[02:55:52.780 --> 02:55:57.340]   And now let me leave you with some words from Vladimir Nabokov that Sheldon uses in his
[02:55:57.340 --> 02:56:00.540]   book "Warm at the Core."
[02:56:00.540 --> 02:56:05.900]   The cradle rocks above an abyss, and common sense tells us that our existence is but a
[02:56:05.900 --> 02:56:11.500]   brief crack of light between two eternities of darkness.
[02:56:11.500 --> 02:56:14.300]   Thanks for listening, and hope to see you next time.
[02:56:14.300 --> 02:56:22.920]   [BLANK_AUDIO]

