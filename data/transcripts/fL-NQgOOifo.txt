
[00:00:00.000 --> 00:00:05.660]   Like many creative types, I can't resist a good story about the writing habits of famous authors.
[00:00:05.660 --> 00:00:10.380]   I was reading over one such article recently when I noticed something interesting,
[00:00:10.380 --> 00:00:14.180]   something relevant to any of us looking to do important work,
[00:00:14.180 --> 00:00:20.300]   but perhaps not able or willing to hustle until our eyes bleed.
[00:00:20.300 --> 00:00:23.900]   All right, so here's the article. I'll load it on the screen for people who are watching.
[00:00:23.900 --> 00:00:26.620]   It comes from the story. It's an Australian website,
[00:00:27.140 --> 00:00:30.640]   and it's a daily writing routine type of article.
[00:00:30.640 --> 00:00:35.460]   There's two stories in here that I want to contrast.
[00:00:35.460 --> 00:00:40.220]   The first is about this gentleman here. This is Haruki Murakami.
[00:00:40.220 --> 00:00:41.680]   I'm going to read from the article here.
[00:00:41.680 --> 00:00:48.220]   When I'm in writing mode for a novel, I get up at 4 a.m. and work for five to six hours.
[00:00:48.220 --> 00:00:52.860]   In the afternoon, I run for 10 kilometers or swim for 1,500 meters or do both.
[00:00:53.380 --> 00:00:57.340]   Then I read a bit and listen to good music. I go to bed at 9 p.m.
[00:00:57.340 --> 00:01:02.820]   All right, so this is how we often think about what it takes to create important work.
[00:01:02.820 --> 00:01:06.780]   Up at four in the morning, every single morning, regardless,
[00:01:06.780 --> 00:01:12.360]   working for six hours and then following it up just to show that you're not intimidated by the workload
[00:01:12.360 --> 00:01:18.540]   with a 10-kilometer run, maybe followed by a long swim, this is life dedicated to art.
[00:01:18.540 --> 00:01:22.140]   It's an approach that makes sense to us.
[00:01:22.140 --> 00:01:25.340]   We like to hear stories like this, but is this the only other, is this the only way?
[00:01:25.340 --> 00:01:28.080]   Well, I want to consider a second story from this article.
[00:01:28.340 --> 00:01:33.520]   This is of Joan Didion. I have her up on the screen now, the essayist Joan Didion.
[00:01:33.520 --> 00:01:36.100]   Let me read from the article here.
[00:01:36.100 --> 00:01:41.360]   Most of the day, working on a piece is not actually putting anything on paper,
[00:01:41.360 --> 00:01:46.480]   just sitting there trying to form a coherent idea that maybe something will come to me about five in the afternoon.
[00:01:46.480 --> 00:01:50.720]   Then I'll work for a couple of hours and get three or four sentences, maybe a paragraph.
[00:01:51.420 --> 00:01:55.080]   I need an hour alone before dinner with a drink to go over what I've done that day.
[00:01:55.080 --> 00:01:57.520]   I can't do it late in the afternoon because I'm too close to it.
[00:01:57.520 --> 00:01:59.720]   Also, the drink helps. It removes me from the pages.
[00:01:59.720 --> 00:02:04.080]   So I spent this hour taking things out and putting other things in.
[00:02:04.080 --> 00:02:06.080]   All right, so look at that contrast.
[00:02:06.080 --> 00:02:10.760]   Murakami, six hours, straight work writing.
[00:02:10.760 --> 00:02:12.520]   He has a very specific word count.
[00:02:12.520 --> 00:02:14.340]   I found another interview with him where he talks about,
[00:02:14.340 --> 00:02:16.240]   I have to produce this many words per day.
[00:02:16.240 --> 00:02:18.520]   He talks about it like clock it into a factory.
[00:02:18.520 --> 00:02:21.320]   He says, look, writing's not art, it's work, and here's how I do it.
[00:02:22.120 --> 00:02:26.440]   Long marathon of running followed by like really hard physical activity
[00:02:26.440 --> 00:02:28.200]   just to sort of show that he's into it.
[00:02:28.200 --> 00:02:32.620]   Didion, she thinks about the piece off and on throughout the day,
[00:02:32.620 --> 00:02:34.720]   but just when it comes time in the afternoon,
[00:02:34.720 --> 00:02:38.520]   she'll finally sit down for an hour or two, write a paragraph maybe,
[00:02:38.520 --> 00:02:42.280]   have a drink to kind of just think about what she wrote and edit a little bit.
[00:02:42.280 --> 00:02:45.460]   That's a much nicer routine.
[00:02:45.460 --> 00:02:48.340]   These are both equally famous authors, but one is masochistic,
[00:02:48.340 --> 00:02:49.760]   and the other one sounds pretty nice.
[00:02:50.240 --> 00:02:51.860]   a paragraph and a drink per night.
[00:02:51.860 --> 00:02:53.520]   But here's the thing.
[00:02:53.520 --> 00:02:57.020]   They both produced really good work.
[00:02:57.020 --> 00:03:00.060]   And if you're just thinking about their names,
[00:03:00.060 --> 00:03:04.440]   you don't know anything about how hard they worked per day.
[00:03:04.440 --> 00:03:07.280]   If anything, Didion's a much more famous writer than Murakami,
[00:03:07.280 --> 00:03:11.740]   even though her work pace and style was much less masochistic.
[00:03:11.740 --> 00:03:15.160]   This is an idea that I explored in more depth in my book,
[00:03:15.360 --> 00:03:20.600]   slow productivity, this idea that the pace at which you produce good work doesn't really matter.
[00:03:20.600 --> 00:03:23.740]   What matters is the eventual quality of what you do produce.
[00:03:23.740 --> 00:03:28.580]   Slow and steady can work just as well as fast and heavy in the long run.
[00:03:29.240 --> 00:03:37.040]   So it's not necessarily the worst thing that take your time as you go and maybe enjoy a drink as you do it.
[00:03:37.040 --> 00:03:42.200]   Now, there's two key caveats, and I've developed these some since that book came out.
[00:03:42.200 --> 00:03:44.680]   There's two key caveats to the slow and steady approach.
[00:03:44.680 --> 00:03:45.560]   The benefits are clear.
[00:03:45.640 --> 00:03:51.140]   You're not going to potentially burn yourself out in the way that a Murakami schedule might do.
[00:03:51.140 --> 00:03:54.600]   Also, most people just don't have the capability of running a schedule like that.
[00:03:54.600 --> 00:03:56.280]   So there's clear advantages to slow and steady.
[00:03:56.280 --> 00:04:00.140]   It's more accessible and sustainable, but there's two caveats to make sure that it works.
[00:04:00.140 --> 00:04:05.280]   One, you have to be careful about not allowing slow progress
[00:04:05.280 --> 00:04:11.080]   to devolve into no progress or random progress.
[00:04:11.480 --> 00:04:13.260]   The steady piece is key.
[00:04:13.260 --> 00:04:16.700]   Didion didn't crush a word count for six hours every day,
[00:04:16.700 --> 00:04:20.180]   but she did sit down and write her three or four sentences every day.
[00:04:20.180 --> 00:04:24.160]   She talks about later in that article that when she's really getting close to finishing a book,
[00:04:24.160 --> 00:04:28.580]   she would move to a house she had in Sacramento because she didn't know anybody there.
[00:04:28.580 --> 00:04:33.040]   And it was very important to her that she not get distracted with invitations or other things going on
[00:04:33.040 --> 00:04:34.720]   so that every single day she could do that.
[00:04:34.720 --> 00:04:37.880]   Slow is fine as long as you're steady.
[00:04:38.500 --> 00:04:42.680]   If you get into like, oh, I write sometimes and sometimes I don't, I'm working on my novel.
[00:04:42.680 --> 00:04:48.280]   I didn't really, I was busy this week, but you know, I was inspired the week before and stayed up late one night.
[00:04:48.280 --> 00:04:52.240]   That's not going to lead to a completed result.
[00:04:52.240 --> 00:04:55.240]   That's just, you have like a hobby sometimes writing.
[00:04:55.240 --> 00:05:02.520]   So you have to keep steady accompanying the slowness when you use the Didion approach.
[00:05:04.160 --> 00:05:06.420]   Another caveat, I said two, but I'm going to give three.
[00:05:06.420 --> 00:05:08.700]   Second of three caveats, concentration.
[00:05:08.700 --> 00:05:12.200]   So slow doesn't mean distracted.
[00:05:12.200 --> 00:05:16.200]   Slow doesn't mean easy.
[00:05:16.200 --> 00:05:21.500]   When Didion was writing those two or three sentences, it was getting her full attention.
[00:05:21.500 --> 00:05:27.500]   So don't, don't let you, you're taking your foot off the accelerator in terms of like how many hours you're working
[00:05:27.500 --> 00:05:28.860]   or how early you're getting up.
[00:05:28.860 --> 00:05:34.240]   Don't mean that you're going to take your foot off the accelerator in terms of what you're doing when you're actually working.
[00:05:34.240 --> 00:05:40.460]   If you're sitting around kind of looking on your phone, kind of writing, but also doing some text messaging with people,
[00:05:40.460 --> 00:05:42.400]   that's not going slow and steady.
[00:05:42.400 --> 00:05:44.200]   Right?
[00:05:44.200 --> 00:05:45.700]   You're not producing good work.
[00:05:45.700 --> 00:05:48.880]   So yeah, again, you don't have to work all the time, but when you work, you got to lock in.
[00:05:48.880 --> 00:05:49.420]   I'm focused.
[00:05:49.420 --> 00:05:50.160]   Here's my ritual.
[00:05:50.260 --> 00:05:56.120]   I go out to my work, my work shed for writing the attic E for I have the writing desk at the same cup of tea every time.
[00:05:56.120 --> 00:05:58.520]   My phone is in another room and I'm locked in.
[00:05:58.520 --> 00:06:03.520]   And maybe it's just for an hour every day or 30 minutes every day, but it's, it's going to be locked in.
[00:06:03.520 --> 00:06:07.120]   So it's slow, steady, and focused if we're really going to expand this.
[00:06:07.120 --> 00:06:09.720]   And the third caveat is going the other direction.
[00:06:09.720 --> 00:06:11.980]   You have to be wary of perfectionism.
[00:06:11.980 --> 00:06:18.100]   You're not really like pushing it every day for huge amounts of hours and word count.
[00:06:18.600 --> 00:06:23.840]   It's easy to say, let me just slow and steadily with concentration, just keep going and tweaking and changing.
[00:06:23.840 --> 00:06:25.100]   And maybe this could be better.
[00:06:25.100 --> 00:06:27.160]   And while it's not quite ready yet, let me go back again.
[00:06:27.160 --> 00:06:28.580]   Let me look at this one more time.
[00:06:28.580 --> 00:06:30.480]   And you never actually finish.
[00:06:30.480 --> 00:06:37.820]   It's easier to avoid perfectionism when you have a more Akami type schedule, because you're, you're hammering this book every day with a word count.
[00:06:37.820 --> 00:06:40.920]   The words pile up and then you've edited it once, you've edited it twice.
[00:06:40.920 --> 00:06:41.900]   You're like, that's enough.
[00:06:41.900 --> 00:06:47.940]   But when you're going slow and steady, you can drag things out and kind of, I'm still, I've been working on this chapter for six months.
[00:06:47.940 --> 00:06:49.060]   And you never makes progress.
[00:06:49.060 --> 00:06:50.960]   So you do have to fight perfectionism.
[00:06:50.960 --> 00:06:58.880]   I have a whole long section about this in my book, Slow Productivity, where I get into like a lot of details about why this arises and how to get around it.
[00:06:58.880 --> 00:07:05.380]   But I can give you a sort of cliff notes version of this right now, which is you need accountability and benchmarks.
[00:07:05.580 --> 00:07:09.620]   Okay, I'm going to give this chapter to my friend at the end of this month.
[00:07:09.620 --> 00:07:11.160]   We're going to get together to talk about it.
[00:07:11.160 --> 00:07:12.140]   That's just it.
[00:07:12.140 --> 00:07:14.640]   I'm going to make it as good as I can in this time.
[00:07:14.640 --> 00:07:18.980]   Okay, then I'm going to have this like six month period where I'm going to present the whole thing to my writers group.
[00:07:19.320 --> 00:07:27.200]   So it's, you put stakes in the ground and then you say, I'm going to do the best I can up until I get to that stake in the ground.
[00:07:27.200 --> 00:07:31.940]   So you're trying to do good work, but you're not allowed to work past when you put that stake in the ground.
[00:07:32.500 --> 00:07:39.900]   So when you are working, you're trying to create art, but when you hit that limit, that timeline checkpoint, you say, okay, but now I have to move on.
[00:07:39.900 --> 00:07:42.660]   It helps to tell yourself, I do this all the time.
[00:07:42.660 --> 00:07:46.020]   It helps to tell yourself the next project can be great.
[00:07:46.020 --> 00:07:48.020]   This is just a stepping stone.
[00:07:48.020 --> 00:07:49.060]   It has to be good enough.
[00:07:49.060 --> 00:07:50.080]   This just has to be good enough.
[00:07:50.080 --> 00:07:51.040]   The next one can be great.
[00:07:51.040 --> 00:07:52.760]   That's a great way to diffuse perfectionism.
[00:07:52.760 --> 00:07:54.160]   Hey, it's Cal.
[00:07:54.160 --> 00:08:05.760]   I wanted to interrupt briefly to say that if you're enjoying this video, then you need to check out my new book, Slow Productivity, The Lost Art of Accomplishment Without Burnout.
[00:08:05.760 --> 00:08:11.280]   This is like the Bible for most of the ideas we talk about here in these videos.
[00:08:11.280 --> 00:08:16.600]   You can get a free excerpt at calnewport.com slash slow.
[00:08:16.600 --> 00:08:18.420]   I know you're going to like it.
[00:08:18.420 --> 00:08:19.440]   Check it out.
[00:08:19.440 --> 00:08:20.780]   Now let's get back to the video.
[00:08:20.780 --> 00:08:22.160]   All right.
[00:08:22.160 --> 00:08:23.280]   So what's my conclusion here?
[00:08:23.960 --> 00:08:29.560]   Well, when we're thinking about the deep life, which is the overall theme of this show, there's two notable threats.
[00:08:29.560 --> 00:08:36.300]   One is the threat that we talk about more commonly, which is not doing enough of the stuff that's interesting or important to you.
[00:08:36.300 --> 00:08:43.260]   In our current technological landscape, it's really the digital that helps divert us from doing the stuff that matters to us.
[00:08:43.260 --> 00:08:44.420]   We're on our phone too much.
[00:08:44.420 --> 00:08:46.360]   Our work devolves into email and Zoom.
[00:08:46.360 --> 00:08:47.480]   We're distracted.
[00:08:47.480 --> 00:08:49.300]   We're anxious.
[00:08:49.300 --> 00:08:52.380]   We're over-activated in our nervous system.
[00:08:52.800 --> 00:08:55.080]   And that's the big threat we often talk about.
[00:08:55.080 --> 00:09:06.080]   But the other threat that's less talked about is doing so much that you become burnt out or stressed or so locked in on one thing, you miss all the other stuff that can make the world great.
[00:09:07.180 --> 00:09:18.600]   So when you get away from the distractions, like I want to work on something important, I want to produce that computer program, that book, that novel, that nonfiction, the great new idea.
[00:09:18.600 --> 00:09:24.840]   When you have the thing to work on that's very important, sometimes slow and steady is the right way to do it.
[00:09:24.840 --> 00:09:28.060]   Slow down, do good work, enjoy life along the way.
[00:09:28.140 --> 00:09:32.980]   We don't talk about that piece about it enough, but I like seeing that in this example of real authors.
[00:09:32.980 --> 00:09:39.160]   I liked writing about it in my book, Slow Productivity, so I wanted to get into it today as well.
[00:09:39.160 --> 00:09:40.660]   There you go, Jesse.
[00:09:40.660 --> 00:09:50.020]   Summer is starting for me, which means it's time for my summer hours, which means I have to really get my – it's when I play act at being a full-time author is in the summer.
[00:09:50.420 --> 00:09:57.520]   So I'm just – next week is my last – the week this comes out is my last week of semester stuff.
[00:09:57.520 --> 00:10:03.140]   So I'm getting ready for my two and a half months I get every summer of play acting as a full-time writer.
[00:10:03.140 --> 00:10:04.600]   So this is why I always look at these articles.
[00:10:04.600 --> 00:10:06.000]   I'm in that mood right now.
[00:10:06.000 --> 00:10:12.160]   So when you were writing Slow Productivity, did you have to use the line, the next project will be great a lot?
[00:10:12.160 --> 00:10:14.200]   Oh, I always use that, yeah, yeah.
[00:10:14.200 --> 00:10:16.360]   I'm like, all right, this has just got to be good enough.
[00:10:16.360 --> 00:10:17.140]   It'll be the stepping stone.
[00:10:17.140 --> 00:10:19.760]   The next thing will be where I'm going to do something like innovative and great.
[00:10:19.840 --> 00:10:25.100]   Because otherwise you keep waiting to have this muse come down and tell you that you've created something that's brilliant.
[00:10:25.100 --> 00:10:27.340]   You rarely feel that, right?
[00:10:27.340 --> 00:10:29.880]   When you're producing a work, it's more just like slog.
[00:10:29.880 --> 00:10:31.500]   This doesn't work.
[00:10:31.500 --> 00:10:32.400]   You're listening to your instincts.
[00:10:32.400 --> 00:10:33.340]   Okay, this is good enough.
[00:10:33.340 --> 00:10:34.040]   Let's keep moving.
[00:10:34.040 --> 00:10:34.560]   And then you see.
[00:10:34.560 --> 00:10:36.300]   And sometimes it works and sometimes it doesn't.
[00:10:36.300 --> 00:10:38.320]   Do you say it too when you write the New Yorker articles?
[00:10:38.320 --> 00:10:39.080]   Yeah.
[00:10:39.080 --> 00:10:40.200]   Yeah.
[00:10:40.200 --> 00:10:41.380]   So you pretty much say it all the time.
[00:10:41.380 --> 00:10:41.900]   I say it all the time.
[00:10:41.900 --> 00:10:47.060]   Well, the New Yorker articles is like just to get an idea that they're willing to have you explore is very hard.
[00:10:47.200 --> 00:10:50.180]   And then to get a piece that's good enough to get published is very hard.
[00:10:50.180 --> 00:10:56.760]   I often just tell myself, if I can actually get this piece published, then like it's good enough.
[00:10:56.760 --> 00:10:57.700]   Like that's hard to do.
[00:10:57.700 --> 00:10:58.480]   Yeah.
[00:10:58.480 --> 00:10:59.700]   Not trying to.
[00:11:00.260 --> 00:11:03.800]   They announced the Pulitzers yesterday, the day before we recorded this.
[00:11:03.800 --> 00:11:06.220]   New Yorker got three, but I'm not trying to win one of the Pulitzers.
[00:11:06.220 --> 00:11:06.700]   Who are the three?
[00:11:06.700 --> 00:11:07.000]   Do you know?
[00:11:07.000 --> 00:11:08.580]   Yes.
[00:11:08.580 --> 00:11:13.560]   There was the one for writing was for commentary.
[00:11:13.560 --> 00:11:20.120]   And it was, I forgot the writer's name, but his dispatch is from Gaza.
[00:11:21.360 --> 00:11:23.100]   But my editor edited those pieces.
[00:11:23.100 --> 00:11:27.340]   So I was like, whoa, that makes my stuff seem much worse by comparison.
[00:11:27.340 --> 00:11:32.040]   He's just got done editing a Pulitzer Prize winning series.
[00:11:32.040 --> 00:11:36.380]   There was one for audio, I believe.
[00:11:36.380 --> 00:11:38.220]   And then one for.
[00:11:38.220 --> 00:11:40.460]   In the dark podcast.
[00:11:40.460 --> 00:11:41.280]   In the dark podcast.
[00:11:41.280 --> 00:11:41.920]   Do you listen to that?
[00:11:41.920 --> 00:11:43.540]   No, but I've.
[00:11:43.540 --> 00:11:44.440]   I haven't even heard of it.
[00:11:44.660 --> 00:11:46.880]   I've been hearing about it on like my New Yorker email address.
[00:11:46.880 --> 00:11:48.280]   Like Rimnick's been writing about it.
[00:11:48.280 --> 00:11:49.520]   I think it's fantastic, supposedly.
[00:11:49.520 --> 00:11:50.460]   I need to check it out.
[00:11:50.460 --> 00:11:52.620]   And then there was one other that I think was not.
[00:11:52.620 --> 00:11:54.480]   I don't know what it was.
[00:11:54.480 --> 00:11:55.260]   I don't know if it was writing.
[00:11:55.260 --> 00:11:55.820]   Photography.
[00:11:55.820 --> 00:11:56.240]   Photography.
[00:11:56.240 --> 00:11:56.540]   Yeah.
[00:11:56.540 --> 00:11:58.320]   Yeah.
[00:11:58.320 --> 00:11:58.820]   So there you go.
[00:11:58.820 --> 00:11:59.200]   So three.
[00:11:59.200 --> 00:11:59.940]   I think that's their record.
[00:11:59.940 --> 00:12:00.660]   They tied their record.
[00:12:00.660 --> 00:12:01.320]   Three Pulitzers.
[00:12:01.320 --> 00:12:07.700]   I'm surprised they didn't get a Pulitzer for commentary for my piece on Michael Crichton.
[00:12:07.700 --> 00:12:10.660]   My column on Michael Crichton.
[00:12:10.660 --> 00:12:13.160]   My column about me using TikTok.
[00:12:13.160 --> 00:12:14.500]   Why did that?
[00:12:14.820 --> 00:12:17.620]   Why did that not win over war coverage?
[00:12:17.620 --> 00:12:17.960]   Come on.
[00:12:17.960 --> 00:12:19.360]   All right.
[00:12:19.360 --> 00:12:21.020]   We've got some good questions coming up.
[00:12:21.020 --> 00:12:25.220]   But first, let's have a quick word from our sponsor.
[00:12:25.220 --> 00:12:29.160]   This show is sponsored by BetterHelp.
[00:12:29.160 --> 00:12:31.420]   We talk a lot on this show about the deep life.
[00:12:31.420 --> 00:12:35.300]   How you want to focus on the stuff that matters and try to reduce the stuff that doesn't.
[00:12:35.300 --> 00:12:39.220]   One of the things you need to succeed with this is a good relationship with your brain.
[00:12:39.220 --> 00:12:43.060]   There's any number of reasons in our modern distracted world that you might end up with a
[00:12:43.060 --> 00:12:45.260]   bad relationship with your brain.
[00:12:46.620 --> 00:12:46.900]   It could be anxiety.
[00:12:46.900 --> 00:12:48.100]   It could be depression.
[00:12:48.100 --> 00:12:51.920]   It could be, you know, over rumination on things that are going on in your life.
[00:12:51.920 --> 00:12:53.780]   This is where therapy helps.
[00:12:53.780 --> 00:12:56.380]   You can get a professional to help you fix that relationship.
[00:12:56.380 --> 00:13:00.800]   Just like you might turn to me to help you fix your relationship with your to-do list.
[00:13:01.580 --> 00:13:05.580]   When it comes to therapy, BetterHelp makes it easy.
[00:13:05.580 --> 00:13:10.580]   BetterHelp has over 10 years of experience matching people with the right therapist from
[00:13:10.580 --> 00:13:14.480]   the diverse network of more than 30,000 licensed therapists with a wide range of specialties.
[00:13:14.480 --> 00:13:20.040]   BetterHelp is fully online, making therapy affordable and convenient, serving over 5 million people
[00:13:20.040 --> 00:13:20.580]   worldwide.
[00:13:20.820 --> 00:13:25.580]   And you can easily switch therapists anytime at no extra cost.
[00:13:25.580 --> 00:13:29.120]   If you're worried about your relationship with your brain, therapy could be just what you
[00:13:29.120 --> 00:13:29.360]   need.
[00:13:29.360 --> 00:13:32.100]   And BetterHelp makes that so easy.
[00:13:32.100 --> 00:13:35.540]   We're all better with help.
[00:13:35.540 --> 00:13:42.780]   Visit betterhelp.com slash deep questions to get 10% off your first month.
[00:13:42.780 --> 00:13:49.560]   That's betterhelp.com slash deep questions to get 10% off your first month.
[00:13:49.560 --> 00:13:57.820]   I also want to talk about VPNs going online without express VPN is like driving without car
[00:13:57.820 --> 00:13:58.260]   insurance.
[00:13:58.260 --> 00:14:04.260]   You might be a great driver, but with all those crazy people on the road, and I'm really thinking
[00:14:04.260 --> 00:14:09.900]   mainly here about Jesse's truck, which could in front of you, the wheels could just fall off
[00:14:09.900 --> 00:14:14.080]   as you were going down the interstate and the truck would just slam into you.
[00:14:14.080 --> 00:14:15.160]   Why take the risk?
[00:14:15.160 --> 00:14:18.020]   Well, the same thing with going on the internet without a VPN.
[00:14:18.020 --> 00:14:19.760]   Here's how this works.
[00:14:19.760 --> 00:14:22.620]   Let me give you my 10 second computer scientist summary.
[00:14:22.620 --> 00:14:27.520]   Typically, when you use the internet, you send these little messages called packets to the website
[00:14:27.520 --> 00:14:28.740]   or service you're talking to.
[00:14:28.740 --> 00:14:33.320]   Now, you might be encrypting what's in the packet, but the address is visible.
[00:14:33.320 --> 00:14:39.000]   So anyone who's nearby when you're using a wireless network or your internet service provider,
[00:14:39.000 --> 00:14:43.240]   if you're using your internet at home, they can look at those addresses like, oh, I know
[00:14:43.240 --> 00:14:45.360]   what sites and services you're using.
[00:14:45.360 --> 00:14:46.720]   Hackers can use that information.
[00:14:46.720 --> 00:14:48.500]   ISPs can gather it and sell it.
[00:14:48.500 --> 00:14:50.140]   A VPN hides that.
[00:14:50.140 --> 00:14:57.000]   So instead of directly sending a message to a site or service, you send that message encrypted
[00:14:57.000 --> 00:14:58.840]   to a VPN server.
[00:14:58.840 --> 00:15:02.920]   The VPN server unencrypts it, talks to the site and service on your behalf, encrypts the response
[00:15:02.920 --> 00:15:03.600]   and sends it back.
[00:15:03.600 --> 00:15:08.140]   So if someone is listening to what you're up to, all they know is you're talking to a
[00:15:08.140 --> 00:15:08.920]   VPN server.
[00:15:08.920 --> 00:15:11.680]   So you gain yourself some privacy.
[00:15:11.680 --> 00:15:16.740]   Now, if you're going to use a VPN, use the one I recommend, which is Express VPN.
[00:15:16.740 --> 00:15:18.700]   It's very easy to use.
[00:15:18.700 --> 00:15:22.140]   Once you've installed the app, you just click a button and it's on and you use your sites
[00:15:22.140 --> 00:15:24.080]   and web browsers and apps just like normal.
[00:15:24.280 --> 00:15:27.240]   But in the back end, you're automatically going through the VPN.
[00:15:27.240 --> 00:15:31.200]   It works on all of your devices, phones, laptops, tablets, and more.
[00:15:31.200 --> 00:15:33.940]   So you can stay secure on the go.
[00:15:33.940 --> 00:15:37.280]   It was rated number one by tech reviewers like CNET and The Verge.
[00:15:37.280 --> 00:15:38.740]   They have servers all around the world.
[00:15:38.740 --> 00:15:40.500]   So there's always going to be one probably nearby.
[00:15:40.500 --> 00:15:41.460]   They've got great bandwidth.
[00:15:41.460 --> 00:15:43.140]   It's just a really good VPN product.
[00:15:43.140 --> 00:15:44.260]   You need a VPN.
[00:15:44.260 --> 00:15:46.180]   So why not use that one?
[00:15:46.180 --> 00:15:47.520]   It's the one I recommend.
[00:15:47.520 --> 00:15:52.220]   So secure your online data today by visiting expressvpn.com slash deep.
[00:15:52.220 --> 00:15:58.640]   That's E-X-P-R-E-S-S vpn.com slash deep to find out how you can get up to four extra months
[00:15:58.640 --> 00:16:02.200]   free expressvpn.com slash deep.
[00:16:02.200 --> 00:16:04.640]   All right, Jesse, let's do some questions.
[00:16:04.640 --> 00:16:07.860]   First questions from Aaron.
[00:16:07.860 --> 00:16:10.520]   I'm a solo attorney without an assistant.
[00:16:10.520 --> 00:16:12.260]   I'm going to trial in three weeks.
[00:16:12.260 --> 00:16:13.880]   So most of my time is devoted to that.
[00:16:13.960 --> 00:16:17.740]   Yet I still need to take calls and answer emails from current and prospective clients
[00:16:17.740 --> 00:16:19.900]   so that there is work lined up for after the trial.
[00:16:19.900 --> 00:16:22.860]   How would you recommend communicating with people during this time?
[00:16:22.860 --> 00:16:26.820]   I do not like putting an out-of-office response in my email, but I also don't want to take
[00:16:26.820 --> 00:16:29.980]   the time to write individual emails saying that my response will be delayed.
[00:16:29.980 --> 00:16:37.980]   Well, I don't like out-of-office responders either, especially if it's just, I'm going to
[00:16:37.980 --> 00:16:39.580]   be delayed answering your email.
[00:16:39.580 --> 00:16:42.740]   They're more appropriate in their original incarnation.
[00:16:42.740 --> 00:16:45.540]   Their original incarnation of these was, I'm on vacation.
[00:16:45.540 --> 00:16:49.680]   Hey, I want to let you know I'm on vacation for, you know, a couple of weeks or something
[00:16:49.680 --> 00:16:50.100]   like that.
[00:16:50.100 --> 00:16:53.980]   What I recommend people do is don't explain your delays until someone asks.
[00:16:53.980 --> 00:16:58.560]   What percentage of the people corresponding with you are going to get upset or ask, why
[00:16:58.560 --> 00:16:59.300]   didn't you respond to me?
[00:16:59.300 --> 00:17:00.580]   It's going to be like 5%.
[00:17:00.580 --> 00:17:04.000]   So you can explain to them what's going on.
[00:17:04.000 --> 00:17:07.080]   The other people don't care, right?
[00:17:07.080 --> 00:17:12.640]   When they send you an email nine times out of 10, the win for them is that that thing
[00:17:12.640 --> 00:17:13.640]   is off their brain.
[00:17:13.640 --> 00:17:14.500]   It's off their plate.
[00:17:14.500 --> 00:17:15.560]   They don't have to think about it.
[00:17:15.560 --> 00:17:17.340]   The open loop has been temporarily closed.
[00:17:17.340 --> 00:17:20.740]   They don't really even want you to respond right away because now the hot potato is back
[00:17:20.740 --> 00:17:22.920]   on them and now they have to deal with it.
[00:17:23.660 --> 00:17:28.520]   So when they hit send, they're kind of done with that and they're probably not going to
[00:17:28.520 --> 00:17:32.040]   notice that you get back to them in two batch times during the day where you go through and
[00:17:32.040 --> 00:17:32.620]   handle your email.
[00:17:32.620 --> 00:17:35.360]   So I would say create a system for how you want to deal with your emails.
[00:17:35.860 --> 00:17:39.340]   Probably during trial prep, you want to have like two set times during the day in which
[00:17:39.340 --> 00:17:40.100]   you get into it.
[00:17:40.100 --> 00:17:43.440]   Respond to people after like, why can't you get back to me quicker?
[00:17:43.440 --> 00:17:45.000]   You say I'm in trial prep.
[00:17:45.000 --> 00:17:48.840]   So I'm only checking in on other correspondence during these times.
[00:17:48.840 --> 00:17:51.700]   Give them a steam valve, emergency release valve.
[00:17:51.700 --> 00:17:54.000]   That is like a phone number they can use if there's an emergency.
[00:17:54.000 --> 00:17:58.260]   They won't, but it gets rid of any complaint they can have about you not being in your inbox
[00:17:58.260 --> 00:17:58.840]   all the time.
[00:17:58.840 --> 00:18:03.180]   But if they know like, oh, you won't see this till four, but if there was a real emergency,
[00:18:03.280 --> 00:18:07.000]   I could call you beforehand, that's now you're talking like 99% of people are covered.
[00:18:07.000 --> 00:18:09.620]   So that's my general thing for out of office responders.
[00:18:09.620 --> 00:18:12.480]   I don't care that you're going to be slow to respond to your email.
[00:18:12.480 --> 00:18:14.280]   I don't need to hear it.
[00:18:14.280 --> 00:18:16.860]   I don't need an explanation unless like it's urgent.
[00:18:16.860 --> 00:18:20.120]   And then you can explain it to me after the fact, right?
[00:18:20.120 --> 00:18:23.480]   You can apologize to the small number of people who actually care.
[00:18:23.480 --> 00:18:25.860]   So no out of office responder.
[00:18:25.860 --> 00:18:28.120]   Just explain to the small number of people who are mad.
[00:18:28.120 --> 00:18:30.280]   All right, who do we get next?
[00:18:30.280 --> 00:18:31.460]   Next up is Stefan.
[00:18:32.100 --> 00:18:34.920]   If I read 60 books a year, I'd hardly remember anything.
[00:18:34.920 --> 00:18:38.140]   Would it be better to read six to 12 books a year and really study them?
[00:18:38.140 --> 00:18:40.420]   Well, it matters what your goal is.
[00:18:40.420 --> 00:18:43.380]   Like what type of books are we reading and for what reason, right?
[00:18:43.380 --> 00:18:44.980]   It all depends on the type of book.
[00:18:44.980 --> 00:18:49.140]   If you're reading like a novel or a journalistic nonfiction book,
[00:18:49.140 --> 00:18:51.880]   like do you care about remembering it?
[00:18:51.880 --> 00:18:55.180]   It's just more about the experience of reading itself, right?
[00:18:55.200 --> 00:18:59.180]   Is that you are engaging in a linguistically constructed world.
[00:18:59.180 --> 00:19:01.720]   You're getting like satisfactions out of that.
[00:19:01.720 --> 00:19:05.020]   You're also gaining new information and like empathy.
[00:19:05.020 --> 00:19:06.860]   And it's like an enjoyable experience.
[00:19:07.480 --> 00:19:11.720]   But it's like not critical to me that if I finish a David Grand book that like I can go back
[00:19:11.720 --> 00:19:18.780]   and say, I've really locked in all the details about when the wager crashed in the 18th century,
[00:19:18.780 --> 00:19:24.780]   and I can really talk about what are the names of the different crew members who are marooned on that island,
[00:19:24.780 --> 00:19:27.380]   I would say like, oh, I enjoyed it while I was reading it.
[00:19:27.880 --> 00:19:29.840]   Now, if you're reading something that you want to understand,
[00:19:29.840 --> 00:19:33.700]   it's like a nonfiction book on a topic that's important to you or to your development,
[00:19:33.700 --> 00:19:34.540]   yeah, then slow down.
[00:19:34.540 --> 00:19:41.300]   What really works there is you have two things with increasing levels of involvement.
[00:19:41.300 --> 00:19:44.180]   If you really want to remember something happening in a nonfiction book,
[00:19:44.180 --> 00:19:47.340]   the first level is the page mark, right?
[00:19:47.340 --> 00:19:50.180]   So what I do is if there's a passage or line that's important,
[00:19:50.180 --> 00:19:53.260]   I'll bracket it or put a check mark next to it or underlying key words,
[00:19:53.260 --> 00:19:57.080]   and then I'll put a slash across the upper corner of that page.
[00:19:57.880 --> 00:20:02.220]   So now what happens is if I later want to go back and remember the insights of that book,
[00:20:02.220 --> 00:20:04.440]   I just flip to every page that has a marked corner,
[00:20:04.440 --> 00:20:08.080]   and then I see what I underlined, checked, or bracketed on that page.
[00:20:08.080 --> 00:20:13.220]   What I find is it allows you in about five minutes to very quickly get all the main ideas from a book back again
[00:20:13.220 --> 00:20:15.600]   and loaded back up in your mind again.
[00:20:15.600 --> 00:20:20.100]   So this is like the first thing you can do if there's a nonfiction book where you want to remember things, page mark.
[00:20:20.100 --> 00:20:24.920]   If you really want to, maybe go back when you're done and read over all your page marks
[00:20:24.920 --> 00:20:26.540]   just to sort of like remember what was there.
[00:20:26.620 --> 00:20:29.720]   But more importantly, like if you want to access those ideas again later,
[00:20:29.720 --> 00:20:31.540]   you don't have to have them all memorized.
[00:20:31.540 --> 00:20:34.480]   You can get them very quickly out of that book by using your page marks.
[00:20:34.480 --> 00:20:36.820]   If you want to understand something even deeper,
[00:20:36.820 --> 00:20:40.260]   so maybe you want to integrate the wisdom from a book into your like own life
[00:20:40.260 --> 00:20:44.320]   or understanding of something that you're doing professionally or personally, take notes.
[00:20:44.960 --> 00:20:49.380]   I would typically say after every chapter, have a document like a Word document or Google Doc,
[00:20:49.380 --> 00:20:54.860]   which you go in and write in your own words, like a summary of that chapter and your take on it,
[00:20:54.860 --> 00:20:59.680]   your sort of narrative reaction to what was personal narrative reaction to what was going on.
[00:20:59.740 --> 00:21:01.840]   And you build out a document of notes.
[00:21:01.840 --> 00:21:03.880]   That'll really cement the ideas.
[00:21:03.880 --> 00:21:07.620]   To have to summarize things in your own word and then articulate your reaction.
[00:21:07.620 --> 00:21:13.820]   That's really the gold standard of trying to cement an idea into your mind that you're reading about.
[00:21:13.820 --> 00:21:16.580]   But I would only do that if it was a book where that was really important.
[00:21:17.460 --> 00:21:19.100]   So it just depends on what your goals are.
[00:21:19.100 --> 00:21:24.260]   And it might just be a mix of like novels and fun nonfiction that you just read because reading is good for you.
[00:21:24.260 --> 00:21:26.400]   And then occasionally maybe you're really studying something,
[00:21:26.400 --> 00:21:30.100]   then slow down and page mark or take personal notes as needed.
[00:21:30.100 --> 00:21:31.660]   How often do you take notes?
[00:21:31.660 --> 00:21:35.760]   Typically if it's a book that I think I might need for an article or a book in the future.
[00:21:35.760 --> 00:21:36.600]   Right.
[00:21:36.600 --> 00:21:43.480]   So like if we look at recent books, like from last episode, we did books from April, right?
[00:21:44.320 --> 00:21:48.180]   So I didn't take notes in the baseball book of why.
[00:21:48.180 --> 00:21:50.000]   That was just like a fun book to read.
[00:21:50.000 --> 00:21:54.200]   But in Alex Karp's book, The Technological Republic, I did page marking.
[00:21:54.200 --> 00:21:55.080]   Yeah.
[00:21:55.080 --> 00:21:58.380]   Notes, I don't do that too often.
[00:21:58.380 --> 00:22:01.700]   Typically it'll be like if it's philosophical, I might.
[00:22:01.700 --> 00:22:03.120]   It's been a little bit since I've done that.
[00:22:03.120 --> 00:22:06.840]   Because I'm so good at using my page marking and going back through.
[00:22:06.840 --> 00:22:09.960]   So I'll page mark anything I think I might need for a future project.
[00:22:09.960 --> 00:22:14.220]   Notes, probably the last thing is I took notes like that on.
[00:22:15.180 --> 00:22:16.380]   No, I can think of some things recently.
[00:22:16.380 --> 00:22:17.280]   So I'll do that sometimes.
[00:22:17.280 --> 00:22:27.100]   If I think I'm not just going to cite some ideas, but I'm going to integrate the ideas of a book into my own personal theories, then I'll take notes.
[00:22:27.100 --> 00:22:31.000]   So you just have like a computer right next to you and you're just typing away?
[00:22:31.760 --> 00:22:33.620]   I'll do it after the fact, after I read a chapter.
[00:22:33.620 --> 00:22:37.040]   While it's still fresh, I go back, yeah.
[00:22:37.040 --> 00:22:40.220]   I'll do it with books on tape, with the Great Courses lectures.
[00:22:40.220 --> 00:22:41.060]   I'll do this as well.
[00:22:41.060 --> 00:22:45.120]   I'll listen to a lecture in the commute and then take notes when I get to Georgetown.
[00:22:45.120 --> 00:22:48.240]   It's like immediately after the fact, but not during.
[00:22:48.240 --> 00:22:50.360]   All right, who do we got?
[00:22:50.360 --> 00:22:51.920]   Next question is from Lisa.
[00:22:51.920 --> 00:22:57.480]   In your conversation with David DeWayne, you talked about the concept of one email address per project.
[00:22:57.480 --> 00:23:00.140]   My work is largely project-based.
[00:23:00.140 --> 00:23:03.280]   We work in Bible translation and have multiple team members per project.
[00:23:03.280 --> 00:23:05.960]   How would I go about implementing this type of structure?
[00:23:06.960 --> 00:23:09.920]   Well, there's like the IT question here and then there's the workflow question here.
[00:23:09.920 --> 00:23:11.860]   The IT question is not that interesting.
[00:23:11.860 --> 00:23:14.500]   It just depends on like what you're using as your email provider.
[00:23:14.500 --> 00:23:22.320]   If you have your own domain, it's typically easy for you to set up many different email addresses for that domain, right?
[00:23:22.320 --> 00:23:23.880]   So you can just set up different addresses.
[00:23:23.880 --> 00:23:28.720]   It could be for specific projects or it could be for specific project types or groups.
[00:23:28.720 --> 00:23:30.620]   I've seen that as well, right?
[00:23:30.620 --> 00:23:38.540]   So, you know, new client inquiries, marketing process.
[00:23:38.540 --> 00:23:44.380]   Like, so it could be not for this specific project, for this specific book that we're working on,
[00:23:44.380 --> 00:23:49.180]   but for like this specific part of the process that we do for every book could have its own email address.
[00:23:49.180 --> 00:23:54.140]   Once you have it set up, then, you know, you give access to that email address to whoever needs it.
[00:23:54.140 --> 00:23:57.980]   From a workflow perspective, that's not so important.
[00:23:57.980 --> 00:24:00.100]   It's okay if like lots of people see these addresses.
[00:24:00.100 --> 00:24:06.900]   Interestingly, it's okay even if everyone gets all the messages from these addresses.
[00:24:06.900 --> 00:24:17.020]   I've seen this before for small organizations where sometimes it's easy to set up aliases where you say any address at thisdomain.com can just like come to me or to all the people.
[00:24:17.020 --> 00:24:20.740]   And then you set up all these individual addresses, but everyone is just getting all the messages.
[00:24:20.740 --> 00:24:22.120]   Why does that help?
[00:24:22.120 --> 00:24:26.340]   Because what you're changing here is the psychology of the sender, right?
[00:24:26.340 --> 00:24:29.300]   Because now the psychology of the sender is different.
[00:24:29.300 --> 00:24:39.760]   If they are sending a message to client inquiries or marketing, they do not imagine in their mind that they're having a one-on-one interaction.
[00:24:40.460 --> 00:24:45.520]   They imagine themselves as being part of a communication process and their patience for responses is greatly increased.
[00:24:45.520 --> 00:25:01.460]   When I'm sending an email when it's individuals on the other side, and I know this because it's like their name at domain.com, my mind is often going to have the same reactions if we were talking in the same room because our sociality circuits don't really know about digital asynchronous communication.
[00:25:02.200 --> 00:25:04.160]   So I might be like, hey, just answer this.
[00:25:04.160 --> 00:25:10.640]   Like, I imagine I simulate you on the other side, seeing that message, right?
[00:25:10.640 --> 00:25:12.900]   And just being like, ha, screw you.
[00:25:12.900 --> 00:25:14.720]   Like, I'm not going to answer this now, right?
[00:25:14.720 --> 00:25:17.700]   And you just, you're like, I'm just like offended at this, right?
[00:25:17.700 --> 00:25:20.440]   Like they're seeing this message and they're purposely not responding.
[00:25:20.780 --> 00:25:25.060]   There's probably like several people in the recipient's office and like, hey, look at this loser.
[00:25:25.060 --> 00:25:26.140]   He thinks I'm going to respond.
[00:25:26.140 --> 00:25:27.400]   And there's like a lot of high-fiving.
[00:25:27.400 --> 00:25:29.740]   And then someone's like kind of simulating you.
[00:25:29.740 --> 00:25:30.460]   Like, oh, look at me.
[00:25:30.460 --> 00:25:31.360]   I'm sending a message.
[00:25:31.360 --> 00:25:33.000]   And everyone's like cheery.
[00:25:33.000 --> 00:25:34.420]   Like, yeah, loser, loser.
[00:25:34.420 --> 00:25:35.440]   Let's get them, right?
[00:25:35.440 --> 00:25:36.940]   And everyone's just like making fun of you.
[00:25:36.940 --> 00:25:39.020]   And someone puts up a picture of you on the wall.
[00:25:39.020 --> 00:25:42.180]   And they're drawing mustaches on it.
[00:25:42.180 --> 00:25:43.500]   And then it kind of gets out of control.
[00:25:43.500 --> 00:25:46.660]   They put the picture on a hastily constructed effigy.
[00:25:46.660 --> 00:25:51.180]   And then pretty soon that thing is that it's on fire and they're just slamming pitchforks in this effigy.
[00:25:51.180 --> 00:25:52.140]   And it really gets kind of dark.
[00:25:52.140 --> 00:25:55.960]   That's what people imagine when they send an email to someone's name.
[00:25:55.960 --> 00:25:59.820]   Because it's this interpersonal sociality that comes up.
[00:25:59.820 --> 00:26:04.500]   But when I'm sending an email to a generic process-related address, I'm like, yeah, it'll get processed.
[00:26:04.500 --> 00:26:06.660]   But I don't know when someone's going to look at that.
[00:26:06.660 --> 00:26:12.200]   So really the benefit is to the psychology of the sender more than it's like on the receiver side.
[00:26:12.200 --> 00:26:13.160]   Everyone can get the messages.
[00:26:13.160 --> 00:26:14.880]   I don't care how you check those inboxes.
[00:26:14.880 --> 00:26:16.520]   But I do think it makes a big difference.
[00:26:16.520 --> 00:26:26.080]   I wrote about this in my book, A World Without Email, where I talked about the fact that email addresses are associated with individuals is just the happenstance of the technology's development.
[00:26:26.080 --> 00:26:35.280]   The very first email programs were from time-shared mainframe computers where you had an account you logged into because you were time-sharing the computer.
[00:26:35.280 --> 00:26:37.180]   And other people could log in from their terminals.
[00:26:37.180 --> 00:26:39.060]   But there's one big computer you were sharing.
[00:26:39.060 --> 00:26:41.840]   So you had to have an account to log into so they could bill you.
[00:26:42.320 --> 00:26:52.040]   And the very first email programs, the way they actually worked is if I was going to send the message to you, it would actually just have the computer write into a text file in your file directory.
[00:26:53.100 --> 00:26:58.220]   And then when you went to read your email, it was just reading that text file and you say, hey, what text has been placed in there?
[00:26:58.220 --> 00:27:03.180]   So you're just placing text in the directories of different users on the same shared mainframe.
[00:27:03.440 --> 00:27:10.280]   Because accounts were associated with individuals, everyone had their own account, email addresses were associated with individuals.
[00:27:10.280 --> 00:27:13.180]   So that's where that convention came.
[00:27:13.180 --> 00:27:19.260]   But it could just as easily have been if email had come later, like let's say after we had networked computers.
[00:27:19.260 --> 00:27:23.120]   It just as easily could be like, oh, you send messages to a computer.
[00:27:23.120 --> 00:27:25.080]   That computer has a name.
[00:27:25.780 --> 00:27:33.900]   And maybe you have like anyone on that computer could see like a sorted collection of messages or you could, you know, it could be, it could have been something very different.
[00:27:33.900 --> 00:27:38.860]   So it's a bit of happenstance that email is associated with people, but it creates a lot of those expectations.
[00:27:38.860 --> 00:27:44.340]   So again, yeah, it's the psychology of the center is going to matter more than how you implement it from an IT perspective.
[00:27:44.340 --> 00:27:47.140]   I was dying laughing when you were taking that analogy.
[00:27:47.140 --> 00:27:49.660]   People get weird psychology around email, man.
[00:27:49.660 --> 00:27:52.120]   When you can't, I talk about this in World Without Email.
[00:27:52.120 --> 00:27:53.460]   There's a lot of studies about this.
[00:27:53.940 --> 00:27:55.680]   Linguistic communication is impoverished.
[00:27:55.680 --> 00:28:02.120]   If it's just text going back and forth, our brains freak out because we need to like see someone's face.
[00:28:02.120 --> 00:28:03.460]   We need to see their body language.
[00:28:03.460 --> 00:28:04.640]   We need to see, are they upset?
[00:28:04.640 --> 00:28:05.400]   Are they happy?
[00:28:05.400 --> 00:28:07.800]   Are they enraged?
[00:28:07.800 --> 00:28:08.880]   Or are they bored?
[00:28:08.880 --> 00:28:10.860]   We need to know that information.
[00:28:10.860 --> 00:28:16.260]   And when you just send me text or like I send an email and I don't get a response, our brain fills in the blanks.
[00:28:16.260 --> 00:28:20.900]   And it often fills in the blanks in like really elaborate, exotic ways.
[00:28:21.240 --> 00:28:25.800]   Because it needs to imagine another person on the other end.
[00:28:25.800 --> 00:28:28.600]   And if I can't see that person, I'm going to invent what they're doing.
[00:28:28.600 --> 00:28:32.080]   And almost always, it's like they're thinking about you and they're really upset.
[00:28:32.080 --> 00:28:35.240]   Like that is where our brain will default if we can't actually see someone.
[00:28:35.240 --> 00:28:38.580]   Linguistic communication is really not a great way to coordinate.
[00:28:38.580 --> 00:28:40.560]   I've long said this.
[00:28:40.560 --> 00:28:41.440]   All right.
[00:28:41.440 --> 00:28:42.040]   What do we got next?
[00:28:42.540 --> 00:28:47.260]   We have a reaction from Justin with Conan and Brian in his burner phone.
[00:28:47.260 --> 00:28:49.120]   So I'm going to play you a video.
[00:28:49.120 --> 00:28:49.560]   Okay.
[00:28:49.560 --> 00:28:52.500]   And then you can react.
[00:28:52.500 --> 00:28:52.900]   All right.
[00:28:52.900 --> 00:28:53.380]   Let's hear this.
[00:28:53.380 --> 00:28:55.780]   I haven't heard this before.
[00:28:55.780 --> 00:28:56.820]   So I'm curious.
[00:28:56.820 --> 00:28:57.840]   I see.
[00:28:57.840 --> 00:29:01.300]   I want to come clean about something, which is that recently I got a burner phone.
[00:29:01.300 --> 00:29:01.880]   You did.
[00:29:02.140 --> 00:29:03.600]   And I love it.
[00:29:03.600 --> 00:29:05.080]   I love having a burner phone.
[00:29:05.080 --> 00:29:05.900]   Okay.
[00:29:05.900 --> 00:29:10.800]   Now you've been intimately a part of the process, David.
[00:29:10.800 --> 00:29:11.040]   Yeah.
[00:29:11.700 --> 00:29:15.000]   Basically, Oscars were getting close.
[00:29:15.000 --> 00:29:22.840]   And I was noticing that there was so much going on between the podcast and the HBO Max series and the Oscars.
[00:29:22.840 --> 00:29:23.820]   Humble brag.
[00:29:23.820 --> 00:29:24.800]   Busy much, Conan?
[00:29:24.800 --> 00:29:26.640]   Oh, my God.
[00:29:26.640 --> 00:29:27.580]   No, anyway.
[00:29:27.580 --> 00:29:30.160]   I was getting crazy.
[00:29:30.160 --> 00:29:30.620]   Yeah.
[00:29:30.620 --> 00:29:35.300]   And I said to you, I just want to have a phone so that I can call Liza.
[00:29:35.300 --> 00:29:37.440]   I can call you, David.
[00:29:37.440 --> 00:29:38.900]   I can call Jeff.
[00:29:38.900 --> 00:29:40.060]   I can call Sweeney, the head writer.
[00:29:40.060 --> 00:29:42.620]   Like, I really want to just be able to Sona's number's in there, too.
[00:29:42.620 --> 00:29:43.160]   And Sona's.
[00:29:43.160 --> 00:29:44.700]   Yes, Sona, you're in there as well.
[00:29:44.700 --> 00:29:45.180]   Okay, thanks.
[00:29:45.180 --> 00:29:45.540]   Okay.
[00:29:45.540 --> 00:29:46.620]   I just chose not to call you.
[00:29:46.620 --> 00:29:49.100]   No, I did call you from the burner phone.
[00:29:49.100 --> 00:29:50.020]   But here's the thing.
[00:29:50.020 --> 00:29:55.100]   So we went and we got a plastic flip phone.
[00:29:55.100 --> 00:29:56.980]   Yeah, I just called and ordered it.
[00:29:56.980 --> 00:29:58.980]   You went and picked it up all on your own.
[00:29:58.980 --> 00:30:07.680]   And the young man selling it to me recognized me and was weirded out that I wanted this phone.
[00:30:07.680 --> 00:30:10.160]   Well, because, okay, well, I was thinking after a picture.
[00:30:10.160 --> 00:30:11.640]   All right.
[00:30:11.640 --> 00:30:18.760]   Well, first of all, Conan's probably at the top of my list of shows I'll never be invited to do, but wish I could.
[00:30:18.760 --> 00:30:20.260]   I'm a huge Conan fan.
[00:30:20.260 --> 00:30:22.240]   You don't think you have a chance?
[00:30:22.240 --> 00:30:24.720]   You have a better chance than I have him than you do with Rogan.
[00:30:24.720 --> 00:30:26.780]   Well, yes and no.
[00:30:26.780 --> 00:30:27.980]   So Rogan doesn't like me.
[00:30:27.980 --> 00:30:30.400]   I think he doesn't like you because you hate social media.
[00:30:30.400 --> 00:30:31.900]   But he has non-celebrities on.
[00:30:31.900 --> 00:30:32.400]   Yeah.
[00:30:32.960 --> 00:30:35.700]   Conan doesn't know who I am and only has celebrities on.
[00:30:35.700 --> 00:30:36.560]   That's the problem.
[00:30:36.560 --> 00:30:37.760]   I got to get into that circle.
[00:30:37.760 --> 00:30:40.940]   We were both Ivy League editors of Ivy League humor magazines.
[00:30:40.940 --> 00:30:41.380]   I know.
[00:30:41.380 --> 00:30:42.120]   So that's something.
[00:30:42.120 --> 00:30:46.540]   When we were in Boston recently, I showed my son the Harvard Lampoon cast.
[00:30:46.540 --> 00:30:47.040]   He didn't care.
[00:30:47.040 --> 00:30:48.040]   Though he does like Conan.
[00:30:48.040 --> 00:30:49.480]   We watch Conan stuff.
[00:30:49.480 --> 00:30:51.800]   I like their studio, though.
[00:30:51.800 --> 00:30:52.660]   Maybe that's what we need to do.
[00:30:52.660 --> 00:30:53.380]   They have a cool studio.
[00:30:53.380 --> 00:30:54.900]   It's in Larchmont in L.A.
[00:30:55.720 --> 00:30:56.640]   They bought a building.
[00:30:56.640 --> 00:30:57.120]   Yeah.
[00:30:57.120 --> 00:30:57.420]   Yeah.
[00:30:57.420 --> 00:30:58.500]   We don't have a building.
[00:30:58.500 --> 00:31:00.320]   Not that our studio is not great.
[00:31:00.320 --> 00:31:00.960]   All right.
[00:31:00.960 --> 00:31:02.860]   So we own one of these burner phones.
[00:31:02.860 --> 00:31:09.080]   We bought one for the family so that we have a couple uses for it.
[00:31:09.080 --> 00:31:16.820]   If we leave my 12-year-old at home while we go do something, it's there.
[00:31:16.820 --> 00:31:17.620]   It's a family phone.
[00:31:17.620 --> 00:31:18.520]   He can use it.
[00:31:18.520 --> 00:31:20.920]   It's a flip phone to call us if there's a problem.
[00:31:21.480 --> 00:31:26.640]   And on days like today, when he takes the bus to baseball practice from school, he can put it in his bag.
[00:31:26.640 --> 00:31:33.780]   And that way, if there's a problem with the bus or he gets there and like, oh, there is no baseball practice there, he can call us or text us on it.
[00:31:33.780 --> 00:31:36.520]   And it's incredibly inconvenient to use by design.
[00:31:36.520 --> 00:31:37.980]   All you can do is call and text.
[00:31:37.980 --> 00:31:40.180]   He sends us – he doesn't like to call.
[00:31:40.180 --> 00:31:43.180]   So he'll send us like I practice this over or something.
[00:31:43.180 --> 00:31:45.860]   It must take 25 minutes to write that message.
[00:31:47.360 --> 00:32:02.000]   I mean it's roughly – these old phones, like the pace at which you construct messages is like roughly the pace at which like a printer's apprentice in Benjamin Franklin's print shop could typeset the lead slugs to print a broadsheet newspaper.
[00:32:02.000 --> 00:32:03.640]   That's what it's like.
[00:32:03.640 --> 00:32:06.260]   It's like, okay, now we were going to – we need an N.
[00:32:06.260 --> 00:32:07.380]   All right.
[00:32:07.380 --> 00:32:11.480]   Let me press these buttons and I'll turn this crank and that letter is locked in.
[00:32:11.480 --> 00:32:11.740]   All right.
[00:32:11.740 --> 00:32:15.980]   Now we need an O and, you know, it's just like really long process, which is great.
[00:32:15.980 --> 00:32:19.340]   The way we did it, by the way, people ask, well, what burner phone do you need?
[00:32:19.340 --> 00:32:20.120]   It's some fancy thing.
[00:32:20.120 --> 00:32:22.280]   I just bought something off Amazon that was cheap.
[00:32:22.280 --> 00:32:33.240]   And then one of our sponsors, Mint Mobile, we just got like an El Cheapo plan, not El Cheapo, but just like basic plan, like text and voice.
[00:32:33.240 --> 00:32:36.200]   And they mail you a SIM card.
[00:32:36.200 --> 00:32:39.220]   And then like we just stuck – we literally stuck that thing in the phone.
[00:32:39.220 --> 00:32:39.700]   And there we go.
[00:32:39.700 --> 00:32:41.180]   I think it's like $15 a month.
[00:32:41.520 --> 00:32:45.260]   And we keep it as – so burner – I'm a big believer in burner phones.
[00:32:45.260 --> 00:32:48.060]   The Conan scenario should be more common.
[00:32:48.060 --> 00:32:55.280]   I don't mean it should be more common that you get asked to host the Oscars and that your house – you know, he got evacuated from his house too.
[00:32:55.280 --> 00:32:59.300]   Right before the Oscars, the Palisade fires destroyed the neighborhood where he lived.
[00:32:59.300 --> 00:33:04.840]   So he's living in a hotel and doing the Oscars and filming his travel show for HBO.
[00:33:04.840 --> 00:33:06.000]   I know too much about Conan.
[00:33:06.000 --> 00:33:08.020]   Do you think it was a Motel 6?
[00:33:08.020 --> 00:33:09.420]   Probably a Motel 6.
[00:33:09.420 --> 00:33:09.980]   Yeah.
[00:33:10.360 --> 00:33:12.080]   You got to – you got to economize.
[00:33:12.080 --> 00:33:14.440]   You know what they do, by the way?
[00:33:14.440 --> 00:33:15.320]   I like this idea.
[00:33:15.320 --> 00:33:17.660]   In the summer, I just discovered this on his podcast.
[00:33:17.660 --> 00:33:30.020]   Him and his producer and co-host – I guess his co-host, they do this thing where they just sit outside and they drink by a fire and like make s'mores and just talk about stuff.
[00:33:30.020 --> 00:33:31.480]   I was like, I like this idea.
[00:33:31.480 --> 00:33:32.960]   Summer s'mores it's called.
[00:33:32.960 --> 00:33:34.300]   Maybe we should do that.
[00:33:35.120 --> 00:33:35.560]   All right.
[00:33:35.560 --> 00:33:36.400]   Anyways, back to it.
[00:33:36.400 --> 00:33:43.780]   This idea of like I have like a dedicated phone just for like emergencies and now I can be largely disconnected but not in a way that's going to be a problem.
[00:33:43.780 --> 00:33:46.060]   Like my wife can still reach me or I can reach the key people.
[00:33:46.060 --> 00:33:48.060]   Like I think more people should do this, right?
[00:33:48.060 --> 00:33:51.380]   And having a burner phone, this should become more common.
[00:33:52.380 --> 00:33:56.220]   It's like, okay, I need to get something important done.
[00:33:56.220 --> 00:34:03.200]   I'll bring the family burner with me so like your husband or wife or whatever can still reach you if needed and you leave your other phone at home.
[00:34:04.040 --> 00:34:15.580]   Like this is the problem with how powerful we've made smartphones is that when we do need to be away from that distraction, the basic communication we need is on the same thing as the amusement park, right?
[00:34:16.120 --> 00:34:24.780]   Like it's sort of like, you know, you're trying to, you live, you're, you're trying to get things done, but your car keys is at the center of a Las Vegas casino.
[00:34:24.780 --> 00:34:35.220]   So like every day when you're like, I want to go like drive over to the gym, you have to walk past cocktail waitresses, giving you free bourbon past the poker tables to get to your car keys.
[00:34:35.320 --> 00:34:36.980]   That's what it's like having a smartphone.
[00:34:36.980 --> 00:34:41.320]   Like, well, I need this in case my kid needs to get picked up early from practice.
[00:34:41.320 --> 00:34:48.540]   But now once I have this, I also have like a hundred billion dollars of distraction infrastructure that's aimed at my eyeballs.
[00:34:48.540 --> 00:34:50.900]   You know, it's not a fair fight.
[00:34:50.900 --> 00:34:53.660]   So I think more people should have this, like what Conan did.
[00:34:53.660 --> 00:34:58.440]   You know, some, some people, their issue is actually too many people have their number.
[00:34:58.440 --> 00:35:01.280]   It's not like the internet distraction is too many people have their number.
[00:35:01.460 --> 00:35:06.800]   So like Joe Rogan, for example, he just replaces his phone and his phone number, like every six months.
[00:35:06.800 --> 00:35:07.600]   Does he really?
[00:35:07.600 --> 00:35:08.400]   That's how he does it.
[00:35:08.400 --> 00:35:08.680]   Yeah.
[00:35:08.680 --> 00:35:11.760]   He's just constantly replacing his phone and his phone number.
[00:35:11.760 --> 00:35:21.000]   It's like declaring phone bankruptcy because I, from what I understand, he uses it, his phone, when he's booking people, like he'll text them and stuff like that.
[00:35:21.000 --> 00:35:27.940]   I think just too many people get the number and then he'll just reset and like his friends have it and like slowly people build back up.
[00:35:29.540 --> 00:35:31.660]   So that's the way I suppose, but I like that.
[00:35:31.660 --> 00:35:34.000]   Conan, you got to have us on, Conan.
[00:35:34.000 --> 00:35:35.280]   Let's invite him on the show.
[00:35:35.280 --> 00:35:35.860]   You think he would come?
[00:35:35.860 --> 00:35:38.980]   Maybe if you read some of your books.
[00:35:38.980 --> 00:35:40.120]   You hesitated too long there.
[00:35:40.120 --> 00:35:42.920]   Jesse's like, yeah, I mean.
[00:35:42.920 --> 00:35:43.540]   He would not.
[00:35:43.540 --> 00:35:44.740]   That's the answer to that question.
[00:35:44.740 --> 00:35:46.540]   He doesn't need an Inbox Zero?
[00:35:46.540 --> 00:35:48.440]   He doesn't need Inbox Zero.
[00:35:48.440 --> 00:35:49.340]   He's had a staff.
[00:35:49.340 --> 00:35:55.340]   You know, he got that show in his, he was like 29 when he got his late night show in the early night, in the 90s.
[00:35:55.340 --> 00:35:57.280]   So he's never, he's never had to deal with computers.
[00:35:57.280 --> 00:35:58.320]   All right.
[00:35:58.320 --> 00:35:59.100]   What do we got?
[00:35:59.100 --> 00:36:00.760]   Next up is Sophie.
[00:36:00.760 --> 00:36:07.820]   I really value the support from my department and community and I've managed to maintain a balanced life with teaching, research and personal interests.
[00:36:07.960 --> 00:36:10.800]   However, I'm facing repeated rejections on the tenure track.
[00:36:10.800 --> 00:36:13.200]   Made me question if I'm working hard enough.
[00:36:13.200 --> 00:36:22.660]   As a first generation international academic, I often wonder how to know if I'm truly giving it my best sustainable effort, especially when I feel like an outsider among the elite.
[00:36:23.160 --> 00:36:29.400]   So Sophie, the key, when it comes to paper publications for tenure, it's not, here's the tricky thing.
[00:36:29.400 --> 00:36:31.520]   It's not a pure effort game.
[00:36:31.520 --> 00:36:40.900]   Like this is the secret of academia is it's not something you're just like, I'm going to throw more hard work at and then I'll get more results.
[00:36:41.620 --> 00:36:55.520]   It's a game of doing the right sort of efforts, like understanding what goes into, what does it feel like, what's important and what's not important for producing research that gets published in the right places.
[00:36:55.700 --> 00:37:01.680]   There is a lot of implicit knowledge required to succeed in that game.
[00:37:01.680 --> 00:37:02.840]   You can't just get there through effort.
[00:37:02.840 --> 00:37:08.640]   This is why you see a lot of academically speaking, the rich staying rich.
[00:37:08.640 --> 00:37:15.660]   In other words, like the people who study at top institutions are much more likely to be successful in top institutions themselves.
[00:37:15.660 --> 00:37:20.160]   Is this just because like the smartest people go to the top institutions?
[00:37:20.160 --> 00:37:21.840]   It's no.
[00:37:21.840 --> 00:37:25.640]   Anyone who's gets a professorship is very, very smart.
[00:37:25.640 --> 00:37:33.400]   By any like classical definition and the correspondence between some sort of like vague notion of smarts and academic success, it gets really messy.
[00:37:33.400 --> 00:37:37.560]   Everyone's like really smart and like Einstein's a smart guy.
[00:37:37.560 --> 00:37:42.340]   But like if you were measuring his mathematical chops, he was average, right?
[00:37:42.340 --> 00:37:45.620]   I mean, it's like what makes smart or not smart is like a complicated thing, right?
[00:37:45.620 --> 00:37:47.200]   So what makes the difference?
[00:37:47.200 --> 00:37:55.620]   Like you go to MIT, you're much more likely to be successful in institutions is because you learn how to specifically do the thing that you need to be successful.
[00:37:55.620 --> 00:37:58.340]   Which is producing papers to get published.
[00:37:58.340 --> 00:38:02.440]   If you work with a top biologist, you learn what it takes to get a paper in the nature.
[00:38:02.440 --> 00:38:05.060]   And yeah, it's hard, but it's not just hard.
[00:38:05.060 --> 00:38:07.620]   It's not just, oh, it takes this many hours.
[00:38:07.620 --> 00:38:10.180]   It's like the type of problem you look at.
[00:38:10.180 --> 00:38:13.220]   The rigor of the research, the type of collaborators you need.
[00:38:13.220 --> 00:38:14.680]   You learn the pitfalls.
[00:38:14.680 --> 00:38:20.960]   Here are the things that if it's not in your papers, in your paper is going to deep six the whole thing.
[00:38:21.340 --> 00:38:23.420]   You get rid of the reasons for rejections.
[00:38:23.420 --> 00:38:24.820]   You put in the things that help it.
[00:38:24.820 --> 00:38:26.820]   And this is just knowledge.
[00:38:26.820 --> 00:38:28.340]   It's institutional knowledge.
[00:38:28.340 --> 00:38:37.140]   I was talking to someone about this last weekend about some of the stuff I learned about publishing more theory style computer science papers when I was at MIT.
[00:38:37.140 --> 00:38:38.900]   And we got really good at this.
[00:38:38.900 --> 00:38:40.220]   I was trying to go back and remember this.
[00:38:40.220 --> 00:38:41.080]   We got really good.
[00:38:41.080 --> 00:38:42.900]   We got good at publishing papers.
[00:38:42.900 --> 00:38:44.160]   We're all smart, but everyone's smart.
[00:38:44.160 --> 00:38:45.700]   But I published a lot of papers, right?
[00:38:45.700 --> 00:38:47.540]   We got really good at this.
[00:38:47.740 --> 00:38:53.540]   And, like, one of the things we learned is, like, okay, here's the venues that we want to publish in, the good venues in our field.
[00:38:53.540 --> 00:38:55.900]   What does it take to publish in these venues?
[00:38:55.900 --> 00:39:01.140]   And I could get this information, like, the top venue in my field was created by my advisor, right?
[00:39:01.140 --> 00:39:02.540]   So, like, I'm in that world.
[00:39:02.540 --> 00:39:08.480]   And, like, one of the things we realized, for example, is what type of things flag your paper not to get in.
[00:39:08.480 --> 00:39:09.400]   So you make sure you didn't do that.
[00:39:09.480 --> 00:39:20.380]   And then we learned at some point, hey, it's really helpful if you have some sort of, like, really advanced mathematical idea that you integrate into your argument.
[00:39:20.380 --> 00:39:34.480]   Good arguments in my field didn't require super sophisticated math necessarily, but you would put in super sophisticated math because we learned this is part of just signaling to the reviewer, this is a serious paper in a serious minds.
[00:39:34.480 --> 00:39:39.660]   And I remember we had, you know, I had a copy of the Handbook of Combinatorics, both volumes.
[00:39:39.660 --> 00:39:47.380]   And you would look through there and, like, learn, like, interesting complicated combinatorial theorems and sort of think, like, hey, how could I integrate this?
[00:39:47.380 --> 00:39:57.700]   Like, I was remembering a paper I wrote once about avoiding, it was an abstract model of multi-communication broadcast channels that there was, like, disruption, adversarial disruption on some.
[00:39:57.780 --> 00:40:02.980]   And we were looking for deterministic solutions to evade, to evade jamming.
[00:40:02.980 --> 00:40:09.600]   And actually, like, the core insights were not that complicated, but we found a way to prove a lower bound by referencing Tehran's theorem.
[00:40:09.600 --> 00:40:24.500]   And Tehran's theorem, which I believe is from, like, the 1930s, if I remember properly, is an extremal combinatorics theorem about the size of cliques that must be left after removing a certain number of hypergraph edges.
[00:40:25.360 --> 00:40:29.440]   You put that in your paper, now you're, like, playing with juice.
[00:40:29.440 --> 00:40:31.760]   They're like, okay, yeah, yeah, yeah, these are serious thinkers, right?
[00:40:31.760 --> 00:40:40.800]   Even if, like, the, someone else could have the same general ideas that we had in our algorithm, but have a couple things that looked a little, like, looked a little fuzzy, like, you're not properly.
[00:40:40.800 --> 00:40:43.240]   The other thing was you need to cite the hell.
[00:40:43.240 --> 00:40:46.120]   You have to show in your citations that you understand the hell out of the field.
[00:40:46.860 --> 00:40:51.980]   So you're signaling, like, I understand this stuff inside and out, and here's Tehran's theorem as part of my results.
[00:40:51.980 --> 00:40:53.320]   Like, that's what you had to do.
[00:40:54.800 --> 00:41:05.600]   That's all, like, implicit knowledge that got our accept rates much higher than someone who is equally smart, who didn't happen to study under the person who founded the conference in which you're trying to publish.
[00:41:05.740 --> 00:41:16.100]   And you didn't realize, like, your idea was probably just as good, but you didn't realize you needed to put in a complicated combinatorics theorem and that you had to have this, like, you know, my advisor drilled into us, like, you've got to understand this field.
[00:41:16.240 --> 00:41:24.760]   And we had special seminars, and we had postdocs coming in to teach classes on advanced topics so that, like, when we were citing a field, we were citing the field.
[00:41:24.760 --> 00:41:31.040]   In fact, probably some of the key authors in that field have come through our office, and we met them and went out to lunch with them and studied papers with them.
[00:41:31.040 --> 00:41:42.920]   That stuff all mattered, which is all to say, Sophie, you need to talk to or be around people who are successfully publishing in the places you want to publish and learn from them.
[00:41:43.440 --> 00:41:47.100]   Self-authorship is the best way to do it. Let's write something together and get a sense of what matters.
[00:41:47.100 --> 00:41:55.480]   And then you learn, oh, this is what matters. Great. Now I know what to do. Do not just put effort into it. It's the right effort that matters.
[00:41:55.480 --> 00:41:59.500]   It's not hours. It's what you do with those hours that really matter.
[00:41:59.500 --> 00:42:06.580]   It's a long academia question, but I was just going down this rabbit hole last week, and I was talking to someone, and it really makes a difference.
[00:42:06.580 --> 00:42:11.740]   You learn how to write a paper that gets accepted, and the hours game is a sucker's game.
[00:42:12.620 --> 00:42:16.920]   If I just work 20 hours a day, then I'll definitely be successful. You can put as many hours as you want.
[00:42:16.920 --> 00:42:20.080]   If you're not doing the exact right things to get a paper published, it's not going to get published.
[00:42:20.080 --> 00:42:20.400]   Right.
[00:42:20.400 --> 00:42:22.840]   And even then, it's hard to get these things published.
[00:42:22.840 --> 00:42:25.120]   All right. What do we got next?
[00:42:25.120 --> 00:42:27.080]   We have a case study next.
[00:42:27.080 --> 00:42:31.240]   Oh, interesting. Okay. Let's see here. Is this the full case study right here?
[00:42:31.240 --> 00:42:31.820]   Yep.
[00:42:31.820 --> 00:42:35.380]   Oh, we got visuals for this. Oh, my Lord. Look at this.
[00:42:35.880 --> 00:42:42.340]   Email processing protocol. All right. For those who are watching, instead of just listening, we're going to put this up on the screen while I read this case study.
[00:42:42.340 --> 00:42:43.800]   All right. It's from Charles.
[00:42:43.800 --> 00:42:57.060]   Charles says, I enjoyed the recent episode where Cal did a deep dive into Inbox Zero and wanted to share that his advice on email processing has been among the most lasting and transformative ideas that I have taken from his books and his podcast.
[00:42:57.620 --> 00:43:03.180]   I use Cal's approach with a slight variation that my sorting context are projects rather than roles.
[00:43:03.180 --> 00:43:04.680]   I am a project manager.
[00:43:04.680 --> 00:43:12.600]   The two or three minutes it takes to move my email into a project-specific processing folder has dramatically reduced the overall time and cognitive load of handling my email.
[00:43:12.600 --> 00:43:14.520]   Here is a flowchart on my process.
[00:43:14.520 --> 00:43:15.680]   Let's look at this flowchart, Jesse.
[00:43:15.680 --> 00:43:18.280]   All right. Step one. I'm going to read this.
[00:43:18.280 --> 00:43:22.860]   Step one. Drag all emails from Inbox to Processing folder.
[00:43:22.860 --> 00:43:24.740]   Do not return to the Inbox.
[00:43:24.740 --> 00:43:27.420]   All right. So emails are moving to a separate folder called Processing.
[00:43:27.420 --> 00:43:28.180]   Step two.
[00:43:28.180 --> 00:43:30.620]   Here, I'll make these bigger.
[00:43:30.620 --> 00:43:31.540]   Step two.
[00:43:31.540 --> 00:43:36.160]   Drag and drop each email into the appropriate processing subfolder.
[00:43:36.160 --> 00:43:44.300]   For those who didn't hear my last episode, I said group like emails with like so that you can deal with a bunch of emails on the same topic at a time.
[00:43:44.300 --> 00:43:50.160]   Charles was saying here that he has processing subfolders for each of the projects he's managing as a project manager.
[00:43:50.160 --> 00:43:53.540]   So now he's moving emails into project-specific folders.
[00:43:53.540 --> 00:43:55.060]   Step three.
[00:43:55.060 --> 00:43:56.220]   So, so far, these have been linear.
[00:43:56.220 --> 00:43:57.460]   There's been no choices yet.
[00:43:57.460 --> 00:43:58.800]   Step three.
[00:43:58.800 --> 00:44:01.780]   Moving through one processing subfolder at a time.
[00:44:01.780 --> 00:44:03.820]   Review each email from oldest to newest.
[00:44:03.820 --> 00:44:04.160]   Okay.
[00:44:04.160 --> 00:44:06.400]   So now you're in a single cognitive context.
[00:44:06.640 --> 00:44:15.000]   If you're only answering emails about the same thing, it will go faster and it will have less cognitive drain because you're not trying to cognitive context switch.
[00:44:15.000 --> 00:44:16.000]   It really is like magic.
[00:44:16.000 --> 00:44:16.980]   You have to try it.
[00:44:16.980 --> 00:44:24.300]   It is so much easier to do 10 emails on one topic and 10 emails on another than to go interleave those emails together.
[00:44:24.300 --> 00:44:25.220]   All right.
[00:44:25.220 --> 00:44:25.240]   All right.
[00:44:25.240 --> 00:44:27.360]   Now we get to a big orange box.
[00:44:27.360 --> 00:44:30.960]   This is a decision box in the flow chart.
[00:44:30.960 --> 00:44:36.380]   Looking at each email in a particular processing subfolder from oldest to newest, you ask for each email.
[00:44:38.140 --> 00:44:40.600]   Will the email take less than a few minutes to address?
[00:44:40.600 --> 00:44:42.100]   So now we have a choice.
[00:44:42.100 --> 00:44:48.600]   If the answer is yes, you go to step 4a and you deal with it.
[00:44:48.600 --> 00:44:52.820]   Read, respond, archive, create a waiting for task to track item if needed.
[00:44:52.920 --> 00:45:03.520]   Another big point of mine, if you send off a response, but you need to get a response back and act on it, put a placeholder on a waiting for list somewhere so you know that you're waiting to hear back.
[00:45:03.520 --> 00:45:19.640]   If the answer is no, if the email will not take less than a few minutes to address, step 4b says create a new task in the NQ column on the project board, save attachments, move email to the corresponding active subfolder to respond to later.
[00:45:19.640 --> 00:45:20.660]   All right.
[00:45:20.660 --> 00:45:21.540]   That's a pretty cool system.
[00:45:22.660 --> 00:45:28.080]   When he says he moves stuff into a folder, does he just like copy the text and put it in like a text file in the folder?
[00:45:28.080 --> 00:45:31.660]   No, I think he means within the inbox, within the email client itself.
[00:45:31.660 --> 00:45:32.360]   Oh, I see.
[00:45:32.360 --> 00:45:32.940]   That's what I'm saying.
[00:45:32.940 --> 00:45:35.260]   So probably he's using some like Outlook with actual folders.
[00:45:35.260 --> 00:45:38.980]   In a Google-based email, it would be labels.
[00:45:38.980 --> 00:45:39.720]   Right.
[00:45:39.720 --> 00:45:40.520]   But same idea.
[00:45:40.520 --> 00:45:40.880]   Yeah.
[00:45:40.880 --> 00:45:41.700]   All right.
[00:45:41.700 --> 00:45:45.820]   So the only thing new about this is create a new task in the Q column of the project board.
[00:45:45.820 --> 00:45:47.200]   Save attachments.
[00:45:47.200 --> 00:45:47.520]   Okay.
[00:45:47.520 --> 00:45:49.780]   So he makes a task out of it.
[00:45:50.940 --> 00:45:53.600]   In the project board related to the project.
[00:45:53.600 --> 00:45:56.840]   And then he archives the email.
[00:45:57.580 --> 00:45:58.680]   So he's using folders.
[00:45:58.680 --> 00:45:59.860]   So this is not Google.
[00:45:59.860 --> 00:46:05.500]   He moves it into a folder so that he can find it again when that task comes up.
[00:46:05.500 --> 00:46:07.360]   He can go back and find it if he needs to respond to it.
[00:46:07.360 --> 00:46:08.460]   I use Google.
[00:46:08.460 --> 00:46:15.480]   So when I create a task related to an email, I copy the subject line into the task so that I can search for it because everything's archived in Google.
[00:46:15.560 --> 00:46:17.300]   I can search for it to pull it back up again.
[00:46:17.300 --> 00:46:19.020]   That's pretty cool.
[00:46:19.020 --> 00:46:20.020]   He had a question at the end.
[00:46:20.020 --> 00:46:21.420]   Let's answer this question.
[00:46:21.420 --> 00:46:26.360]   Charles says, my question has to do with tracking emails to ensure recipients respond and follow up.
[00:46:26.360 --> 00:46:28.180]   How do you decide which emails require tracking?
[00:46:28.180 --> 00:46:30.980]   And how do you track those to ensure the outcome is achieved?
[00:46:30.980 --> 00:46:32.620]   That's the waiting for list.
[00:46:32.620 --> 00:46:38.900]   So if it's you need an answer to make progress on something important to you, put a note about it in the waiting for list.
[00:46:38.900 --> 00:46:41.980]   And then when you're reviewing your task board or task list, you'll see it.
[00:46:41.980 --> 00:46:44.060]   And if it's been a little bit, you can follow up.
[00:46:44.520 --> 00:46:49.700]   If you don't really care, if you're like, I don't know, you know, if they don't get back to me, it's not the worst thing.
[00:46:49.700 --> 00:46:50.880]   Like I did my best.
[00:46:50.880 --> 00:46:51.640]   I did my part.
[00:46:51.640 --> 00:46:55.560]   Like I responded to this and it's up to them if they want to get back to me, then you don't need it.
[00:46:55.560 --> 00:46:58.080]   You only put a stake in the ground on the waiting for list.
[00:46:58.080 --> 00:47:04.360]   If there's something you need to do and they are on the critical path, but the, the, you need their answer to do something.
[00:47:04.360 --> 00:47:09.440]   And it's an important thing for you and you don't want to drop this ball and you will follow up.
[00:47:09.440 --> 00:47:14.100]   If you don't hear from them for a while, then you put something in a waiting for an appropriate waiting for list.
[00:47:14.100 --> 00:47:16.780]   And you'll see that you'll see it every time you review your list.
[00:47:16.780 --> 00:47:18.740]   And eventually you'll say, I should probably follow up on this.
[00:47:18.740 --> 00:47:20.300]   All right.
[00:47:20.300 --> 00:47:23.280]   We got ourselves a, what a call?
[00:47:23.280 --> 00:47:24.140]   Two calls.
[00:47:24.140 --> 00:47:24.860]   Two calls.
[00:47:24.860 --> 00:47:25.320]   All right.
[00:47:25.320 --> 00:47:26.160]   Let's hear the first one.
[00:47:26.160 --> 00:47:26.540]   Okay.
[00:47:26.540 --> 00:47:37.120]   Hey Cal, I'm Gabriel, a 28 year old senior concept artist with six years of experience in different studios in Europe.
[00:47:37.120 --> 00:47:42.280]   And now I want to pursue my teenage dream of working for a studio in California.
[00:47:42.280 --> 00:47:44.720]   And that requires more strategic action.
[00:47:44.720 --> 00:47:51.760]   For that, I'll be taking six months of part-time work to dedicate two days a week to portfolio development.
[00:47:51.760 --> 00:47:53.420]   And I know myself.
[00:47:53.420 --> 00:47:58.140]   And during that time, the biggest challenge will be managing my creative intensity.
[00:47:58.140 --> 00:48:01.920]   When I'm drawing and it's going well, I'll work marathon sessions.
[00:48:01.920 --> 00:48:04.180]   And when it's not, I spiral into frustration.
[00:48:04.580 --> 00:48:06.300]   I guess it's the artist's curse.
[00:48:06.300 --> 00:48:11.980]   But how would you, you know, manage these emotional extremes?
[00:48:11.980 --> 00:48:26.240]   Specifically, how can an artist develop a workflow that is sustainable, prevents burnout, maintains consistent progress, and, yeah, creates emotional resilience during the inevitable ups and downs of creative work?
[00:48:26.240 --> 00:48:32.120]   I think I would be really interested in what you have to say into more artistic endeavors.
[00:48:32.120 --> 00:48:34.040]   All right.
[00:48:34.040 --> 00:48:34.740]   That's a good question.
[00:48:34.740 --> 00:48:36.620]   I have two things to say here.
[00:48:36.620 --> 00:48:41.260]   So, one, you're working on a sort of open-ended, quality-dependent creative project.
[00:48:41.400 --> 00:48:47.820]   I'm going to go back to the Morikami advice from earlier in the show during the deep dive.
[00:48:47.820 --> 00:48:53.040]   So, I read a lot more about Morikami when I was preparing for that segment.
[00:48:53.040 --> 00:49:01.900]   And one of the things he said in one of the articles I was reading is that he treats his writing like he's clocking in and out of a factory.
[00:49:01.900 --> 00:49:04.460]   And he has certain times he writes.
[00:49:05.700 --> 00:49:10.260]   And he's going to do the full-time, even if he's not feeling it, he'll do the full-time.
[00:49:10.260 --> 00:49:17.180]   Equally important, he clocks out when it's clock-out time, even if he feels like he still has energy and more to do.
[00:49:17.180 --> 00:49:19.680]   He's like, I'm just going to be regular.
[00:49:19.680 --> 00:49:26.640]   And some days it'll be hard to fill the time, and some days I'll be frustrated that I'm stopping when I have a lot more to do.
[00:49:26.640 --> 00:49:30.600]   But he's like, it's the only way I could produce sustainably over time.
[00:49:30.600 --> 00:49:32.280]   This might be what you want to try.
[00:49:33.060 --> 00:49:38.640]   It's on the part-time days, it's two hours, it's an hour, a break, and then another hour, whatever it is.
[00:49:38.640 --> 00:49:40.540]   And you clock in and you clock out.
[00:49:40.540 --> 00:49:42.320]   And the days you're not feeling it, you do your best.
[00:49:42.320 --> 00:49:44.720]   And on the days you are feeling it, you end with gas in the tank.
[00:49:44.720 --> 00:49:47.140]   And let that aggregate over time.
[00:49:47.140 --> 00:49:52.120]   That method will probably work for you now because otherwise if you fall into this, like I'm following my inspiration.
[00:49:52.120 --> 00:49:54.020]   Yeah, you have days where you're going to work 12 hours.
[00:49:54.020 --> 00:49:56.720]   You're going to have other days where you're not feeling it and you do none.
[00:49:56.720 --> 00:49:59.640]   And then the whole thing will eventually sort of get creaky or spiral out of control.
[00:49:59.640 --> 00:50:01.440]   So you probably need to factory mindset it.
[00:50:01.900 --> 00:50:08.420]   My other advice is more lifestyle, career capital advice, I would say, is I like the idea.
[00:50:08.420 --> 00:50:10.520]   You know, you have some clarity.
[00:50:10.520 --> 00:50:12.780]   You want to live in California, work for a California studio.
[00:50:12.780 --> 00:50:20.420]   The big trap here is writing your own story about what you think is going to matter to get those jobs as opposed to getting evidence about what really does matter.
[00:50:20.980 --> 00:50:30.380]   Find someone in one of these studios to talk to, a confidant, to say, what would really be required for someone like me in Europe to get hired there?
[00:50:30.380 --> 00:50:31.680]   Get the real answer.
[00:50:31.680 --> 00:50:35.680]   It might not be, we just need to see your portfolio and hope it's nice.
[00:50:35.680 --> 00:50:37.920]   There might be a whole other pipeline.
[00:50:38.060 --> 00:50:46.480]   I don't know anything about that field, but I'm saying you need to hear it from the ears of someone at a place, from the mouth of someone at a place you want to work saying, this is what we would look for.
[00:50:46.580 --> 00:50:47.880]   Here's what you would have to do.
[00:50:47.880 --> 00:50:53.820]   You need to be putting your effort as directed as possible on what matters and not just what you think might matters.
[00:50:53.820 --> 00:50:58.080]   You also maybe want to have someone to look at your work as it's ongoing.
[00:50:58.080 --> 00:51:00.760]   So otherwise you're going to fall into a perfectionism trap.
[00:51:00.760 --> 00:51:05.260]   So look, I'm going to spend two months doing my factory clock in and out.
[00:51:05.780 --> 00:51:06.680]   And then we have an appointment.
[00:51:06.680 --> 00:51:08.080]   I'm going to meet with you at the end of that two months.
[00:51:08.080 --> 00:51:08.700]   It's on the calendar.
[00:51:08.700 --> 00:51:09.800]   I'm going to show you what I have.
[00:51:09.800 --> 00:51:11.540]   Is this ready or not?
[00:51:11.540 --> 00:51:14.340]   Is this good enough yet for me to bring it to the California studio?
[00:51:14.340 --> 00:51:16.140]   If not, another month, I'll show it to you again.
[00:51:16.140 --> 00:51:17.620]   So you have stakes in the ground.
[00:51:17.620 --> 00:51:21.460]   You do the best you can in that time, but you have to finish when you have to finish.
[00:51:21.460 --> 00:51:23.500]   Otherwise, this could go on for a long time.
[00:51:23.500 --> 00:51:27.820]   But otherwise, look, I like what you're working on and good luck with that.
[00:51:27.820 --> 00:51:29.740]   Concept Artist Studio in California.
[00:51:29.740 --> 00:51:31.920]   I don't even know what that means, but it sounds cool.
[00:51:31.920 --> 00:51:32.480]   Yeah.
[00:51:32.640 --> 00:51:36.340]   I don't know if that's like movie related or who knows.
[00:51:36.340 --> 00:51:37.080]   All right.
[00:51:37.080 --> 00:51:37.820]   We have a second call.
[00:51:37.820 --> 00:51:38.040]   Yeah.
[00:51:38.040 --> 00:51:42.760]   The next one is just an update from the Inbox Zero episode.
[00:51:42.760 --> 00:51:43.200]   All right.
[00:51:43.200 --> 00:51:43.360]   Cool.
[00:51:43.360 --> 00:51:44.040]   Hey, Cal.
[00:51:44.040 --> 00:51:46.100]   This is Michael from Portland, Oregon.
[00:51:46.100 --> 00:51:47.840]   Long time, first time.
[00:51:47.840 --> 00:51:51.580]   My brother Mark and I are avid listeners of the show.
[00:51:51.580 --> 00:51:55.560]   I'm a Salesforce implementation consultant.
[00:51:55.560 --> 00:51:57.320]   It's actually owned my own business.
[00:51:57.920 --> 00:52:04.300]   So I'm a big follower of your work because it directly impacts my free time.
[00:52:04.300 --> 00:52:10.660]   It's helping get down to about 30 hours of replacing my salary for my full-time job.
[00:52:10.660 --> 00:52:16.080]   So I just wanted to give a commentary on the Inbox Zero from this week's episode.
[00:52:16.120 --> 00:52:25.100]   I had gotten pretty close to it by unsubscribing to everything possible, moving communications out of email.
[00:52:25.100 --> 00:52:27.040]   And, yeah, that took a long time.
[00:52:27.040 --> 00:52:31.700]   But I just got home from a two-week vacation and only had 70 emails.
[00:52:31.700 --> 00:52:34.520]   And a few of those can be deleted right off the bat.
[00:52:35.040 --> 00:52:38.220]   So I just want to say there is hope for all of you in.
[00:52:38.220 --> 00:52:39.760]   All right.
[00:52:39.760 --> 00:52:47.420]   Well, first of all, I appreciate him going through the effort of calling in, especially given, based on the sound quality,
[00:52:47.420 --> 00:52:51.920]   I believe he was calling from a submarine at the bottom of the Marianas Trench.
[00:52:51.920 --> 00:52:54.580]   So good luck with your undersea exploration.
[00:52:54.580 --> 00:53:00.820]   I'm glad your radio phone, your sonar-based radio phone, was able to get a signal to the surface.
[00:53:01.260 --> 00:53:06.360]   No, but it is good to hear, like, look, this is someone who says it's a pain to take the time.
[00:53:06.360 --> 00:53:12.520]   I think the thing he was talking about is he said one of the other things you do for Inbox Zero is once a week or twice a month,
[00:53:12.520 --> 00:53:17.620]   you go through and unsubscribe or filter the stuff you don't need to kind of keep on top of it.
[00:53:17.620 --> 00:53:19.320]   And he was arguing, like, hey, that kind of works.
[00:53:19.320 --> 00:53:23.060]   He went away for a long time, and what was left in his inbox when he came back was very manageable.
[00:53:23.060 --> 00:53:25.000]   I have to do that.
[00:53:25.000 --> 00:53:29.100]   I've lost control of Arthur at CalNewport.com.
[00:53:29.100 --> 00:53:30.020]   I got to get in there.
[00:53:30.360 --> 00:53:38.220]   I lost control because, I'm telling you, people started selling that address to these lists for, like, PR companies.
[00:53:38.220 --> 00:53:40.180]   And now it's just out of control.
[00:53:40.180 --> 00:53:42.220]   I have 6,000 emails in there.
[00:53:42.220 --> 00:53:44.040]   Well, you should just do a Rogan and get a new one.
[00:53:44.040 --> 00:53:45.340]   Just get a new address?
[00:53:45.340 --> 00:53:45.640]   Yeah.
[00:53:45.640 --> 00:53:47.280]   That address is a lot of places.
[00:53:47.280 --> 00:53:52.160]   I want to go through and unsubscribe, but it might be quixotic.
[00:53:52.160 --> 00:53:53.360]   Yeah, maybe you're right.
[00:53:53.360 --> 00:53:54.400]   Maybe we should just change the address.
[00:53:54.400 --> 00:53:56.080]   Something else at CalNewport.com.
[00:53:56.080 --> 00:53:56.440]   Yeah.
[00:53:56.440 --> 00:53:56.840]   All right.
[00:53:56.840 --> 00:53:57.600]   I'll think about that.
[00:53:58.440 --> 00:53:59.240]   All right.
[00:53:59.240 --> 00:54:03.220]   We've got a final segment coming up, but first, here for another sponsor.
[00:54:03.220 --> 00:54:08.520]   We'll talk about our friends at My Body Tutor.
[00:54:09.200 --> 00:54:12.200]   I've known Adam Gilbert, My Body Tutor's founder, for many years.
[00:54:12.200 --> 00:54:14.760]   He's a good source of fitness advice for me.
[00:54:14.760 --> 00:54:17.240]   He used to be a fitness columnist for my blog in his early days.
[00:54:17.240 --> 00:54:20.900]   His company, My Body Tutor, is something that I'm excited about.
[00:54:20.900 --> 00:54:23.420]   It's doing really well because the idea is very smart.
[00:54:23.520 --> 00:54:27.840]   It's a 100% online coaching program that solves the biggest problem in health and fitness, which
[00:54:27.840 --> 00:54:29.240]   is the lack of consistency.
[00:54:29.240 --> 00:54:32.360]   The way it works is you get assigned a coach.
[00:54:32.360 --> 00:54:38.220]   That coach helps you come up with a customized plan for both your fitness and your nutrition.
[00:54:38.220 --> 00:54:41.520]   And then, and here's the key thing, you check in with them every day.
[00:54:41.520 --> 00:54:42.360]   It's easy.
[00:54:42.360 --> 00:54:44.160]   You use the app, but you check it every day.
[00:54:44.200 --> 00:54:49.040]   And that accountability is what keeps you consistently on track.
[00:54:49.040 --> 00:54:53.360]   You also get the advantage if you have your own coach, if there's a change, like you're traveling
[00:54:53.360 --> 00:54:55.660]   or something's not working, they can just adjust for you.
[00:54:55.660 --> 00:54:56.560]   Hey, let's try this.
[00:54:56.560 --> 00:54:57.260]   Let's do that.
[00:54:57.260 --> 00:55:00.400]   Working with someone else makes all the difference in health and fitness.
[00:55:00.400 --> 00:55:05.400]   And by harnessing the power of the internet, My Body Tutor makes that possible without the
[00:55:05.400 --> 00:55:09.060]   expense of having a trainer in your house and a nutritionist in your house.
[00:55:09.060 --> 00:55:11.280]   So it's a fantastic way.
[00:55:11.280 --> 00:55:11.920]   You want to get healthier?
[00:55:11.920 --> 00:55:13.380]   This is the way to do it.
[00:55:13.800 --> 00:55:15.640]   Go to mybodytutor.com.
[00:55:15.640 --> 00:55:16.780]   That's T-U-T-O-R.
[00:55:16.780 --> 00:55:21.340]   Mention that you came from the Deep Questions podcast and Adam will give you $50 off your
[00:55:21.340 --> 00:55:21.860]   first month.
[00:55:21.860 --> 00:55:27.660]   That's mybodytutor, T-U-T-O-R.com and mention Deep Questions to get $50 off.
[00:55:27.660 --> 00:55:31.140]   I also want to talk about our friends at Oracle.
[00:55:31.140 --> 00:55:34.040]   There is a growing expense eating into your company's profits.
[00:55:34.040 --> 00:55:36.260]   It's your cloud computing bill.
[00:55:36.260 --> 00:55:41.300]   You may have gotten a deal to start, but now the spend is sky high and increasing every year.
[00:55:41.300 --> 00:55:43.380]   What if you could cut your cloud bill in half?
[00:55:43.400 --> 00:55:45.300]   And improve performance at the same time?
[00:55:45.300 --> 00:55:52.060]   Well, if you act by May 31st, Oracle's cloud infrastructure can help you do just that.
[00:55:52.060 --> 00:55:56.940]   OCI is the next generation cloud designed for every workload where you can run any application,
[00:55:56.940 --> 00:56:00.280]   including any AI projects, faster and more securely for less.
[00:56:00.840 --> 00:56:06.280]   In fact, Oracle has a special promotion where you can cut your cloud bill in half when you switch to OCI.
[00:56:06.280 --> 00:56:08.140]   The savings are real.
[00:56:08.140 --> 00:56:13.760]   On average, OCI costs 50% less for compute, 70% less for storage and 80% less for networking.
[00:56:14.560 --> 00:56:19.960]   Join modal, Skydance Animation and today's innovative AI tech companies who upgraded to OCI and saved.
[00:56:19.960 --> 00:56:23.400]   This offer is only for new U.S. customers with a minimum financial commitment.
[00:56:23.400 --> 00:56:27.600]   See if you qualify for half off at oracle.com slash deep questions.
[00:56:28.300 --> 00:56:31.200]   That's oracle.com slash deep questions.
[00:56:31.200 --> 00:56:34.620]   All right, Jesse, let's go to our final segment.
[00:56:34.620 --> 00:56:36.620]   All right.
[00:56:36.620 --> 00:56:38.120]   So for our final segment, I'm going to do a tech corner.
[00:56:38.120 --> 00:56:39.120]   I'm going to get back to AI.
[00:56:39.120 --> 00:56:44.600]   I'm going to react to an article that appeared in the New York Times not long ago.
[00:56:44.600 --> 00:56:47.380]   I'm going to bring this on the screen for people who are watching instead of just reading.
[00:56:47.880 --> 00:56:49.560]   I'm going to read a couple of things from this here.
[00:56:49.560 --> 00:56:56.840]   The title of this article is, if AI systems become conscious, should they have rights?
[00:56:56.840 --> 00:56:58.500]   It's a Kevin Roos article.
[00:56:58.500 --> 00:57:00.360]   All right.
[00:57:00.360 --> 00:57:01.740]   So I'm going to read a couple of things from this.
[00:57:01.740 --> 00:57:07.860]   He starts by saying, one of my deeply held values as a tech columnist is humanism.
[00:57:07.860 --> 00:57:09.340]   I believe in humans.
[00:57:09.340 --> 00:57:12.900]   And I think that technology should help people rather than disempower or replace them.
[00:57:12.900 --> 00:57:17.400]   I care about aligning artificial intelligence because I think our values are fundamentally good
[00:57:17.400 --> 00:57:19.460]   or at least better than the values a robot could come up with.
[00:57:19.460 --> 00:57:24.820]   So when I heard that researchers at Anthropic, the AI company that made the Claude chatbot,
[00:57:24.820 --> 00:57:29.440]   were starting to study model welfare, the idea that AI models might soon become conscious
[00:57:29.440 --> 00:57:33.880]   and deserve some kind of moral status, the humanist in me thought, who cares about the chatbots?
[00:57:33.880 --> 00:57:37.780]   Are we supposed to be worried about AI mistreating us, not us mistreating it?
[00:57:37.780 --> 00:57:45.620]   And then he goes on to say, it's hard to argue that today's AI systems are conscious, dot, dot, dot.
[00:57:45.620 --> 00:57:46.520]   But I was intrigued.
[00:57:46.920 --> 00:57:50.580]   After all, more people are beginning to treat AI systems as if they are conscious,
[00:57:50.580 --> 00:57:56.120]   falling in love with them and using them as therapists or soliciting their advice, dot, dot, dot.
[00:57:56.120 --> 00:58:01.360]   There's a small body of academic research on AI model welfare and a modest but growing number
[00:58:01.360 --> 00:58:05.680]   of experts in fields like philosophy and neuroscience are taking the prospect of AI consciousness more
[00:58:05.680 --> 00:58:06.400]   seriously.
[00:58:07.460 --> 00:58:11.560]   Recently, the tech podcaster, Dworkish Patel, compared AI welfare to animal welfare, saying
[00:58:11.560 --> 00:58:14.920]   he believed it was important to make sure the digital equivalent of factory farming doesn't
[00:58:14.920 --> 00:58:16.940]   happen to future AI beings.
[00:58:16.940 --> 00:58:20.200]   Tech companies are starting to talk about it more, too.
[00:58:21.200 --> 00:58:25.540]   So, last year, Anthropic hired its first AI welfare researcher, Kyle Fish.
[00:58:25.540 --> 00:58:30.540]   Kevin says, I interviewed Mr. Fish at Anthropic's San Francisco office last week.
[00:58:30.540 --> 00:58:35.900]   He's a friendly vegan who, like a number of Anthropic employees, has ties to effective altruism,
[00:58:35.900 --> 00:58:38.280]   an intellectual movement with roots in the Bay Area tech scene.
[00:58:38.960 --> 00:58:42.060]   Mr. Fish told me that his work in Anthropic focused on two basic questions.
[00:58:42.060 --> 00:58:46.000]   First, is it possible that Claude or other AI systems will become conscious in the near future?
[00:58:46.000 --> 00:58:49.100]   And second, if that happens, what should Anthropic do about it?
[00:58:49.100 --> 00:58:49.560]   All right.
[00:58:49.560 --> 00:58:51.520]   Here's the thing.
[00:58:51.520 --> 00:58:53.280]   I can answer your question, Mr. Fish.
[00:58:53.280 --> 00:58:53.800]   No.
[00:58:53.800 --> 00:58:58.340]   No, Claude will not become conscious in the near future.
[00:58:58.340 --> 00:58:59.900]   And two, your job is made up.
[00:58:59.900 --> 00:59:03.540]   I think this is a PR stunt from Anthropic.
[00:59:05.840 --> 00:59:12.040]   I think the more they're talking about these issues of these magical ideas, like the AI is
[00:59:12.040 --> 00:59:17.680]   alive, it's a mysterious technology, we don't understand what's going on, the more it distracts
[00:59:17.680 --> 00:59:23.480]   from like actual pragmatic questions about actual pragmatic uses and harms and also inconvenient
[00:59:23.480 --> 00:59:27.900]   things like how much money are you making or what's your plan for profitability, the more
[00:59:27.900 --> 00:59:33.380]   the technology seems magical, the more runway they get, they keep sort of attracting money
[00:59:33.380 --> 00:59:34.320]   and trying to move forward.
[00:59:34.940 --> 00:59:40.540]   But Anthropic knows, engineers there know good and well that Claude, which is a large
[00:59:40.540 --> 00:59:43.740]   language model, cannot become conscious.
[00:59:43.740 --> 00:59:45.380]   Right?
[00:59:45.380 --> 00:59:46.160]   Why is this?
[00:59:46.160 --> 00:59:47.180]   We've talked about this all the time.
[00:59:47.180 --> 00:59:48.960]   Large language models are static.
[00:59:48.960 --> 00:59:52.720]   They have no state that can change.
[00:59:52.720 --> 00:59:56.920]   They have no autonomous action.
[00:59:57.640 --> 01:00:02.720]   What it is, is a collection of layers captured as matrices of numbers.
[01:00:02.720 --> 01:00:08.160]   You put text in the one end, actually an embedding of text into a new multidimensional space in
[01:00:08.160 --> 01:00:08.660]   the one end.
[01:00:08.660 --> 01:00:11.800]   It moves feed forward systematically through these layers.
[01:00:11.800 --> 01:00:12.780]   Patterns are recognized.
[01:00:12.780 --> 01:00:13.680]   Rules are applied.
[01:00:13.680 --> 01:00:17.160]   And out the other end comes a probability distribution over tokens, which are parts of words.
[01:00:17.160 --> 01:00:18.360]   That's what it does.
[01:00:18.560 --> 01:00:21.620]   Then you can take that token and add it to the original prompt.
[01:00:21.620 --> 01:00:24.420]   And now you have a slightly longer prompt.
[01:00:24.420 --> 01:00:27.980]   You put that whole thing through the model again, and you get a probability distribution
[01:00:27.980 --> 01:00:28.840]   for the next token.
[01:00:28.840 --> 01:00:32.920]   And you just keep repeating this until you've expanded the text long enough to send it back
[01:00:32.920 --> 01:00:33.600]   to the user.
[01:00:33.720 --> 01:00:35.740]   It's the exact same model every time.
[01:00:35.740 --> 01:00:36.800]   Nothing changes.
[01:00:36.800 --> 01:00:37.480]   It's static.
[01:00:37.480 --> 01:00:39.180]   It's spread over a bunch of GPUs.
[01:00:39.180 --> 01:00:40.840]   It's just a bunch of multiplications going on.
[01:00:40.840 --> 01:00:45.860]   If you wanted something like autonomy, consciousness is too complicated, but if you wanted something
[01:00:45.860 --> 01:00:51.160]   like this as an autonomous being, you have to have, in addition to understanding, which
[01:00:51.160 --> 01:00:54.840]   a language model has, you have to have a model of a world that can be updated.
[01:00:54.840 --> 01:00:59.340]   This is the model's understanding of the world, and it's updated based on new experience.
[01:00:59.340 --> 01:01:01.120]   You need some notion of values or incentives.
[01:01:01.120 --> 01:01:01.700]   What's good?
[01:01:01.700 --> 01:01:02.400]   What's bad?
[01:01:02.760 --> 01:01:04.540]   You need some notion of actuation.
[01:01:04.540 --> 01:01:05.800]   You can actually take action.
[01:01:05.800 --> 01:01:12.500]   So you put world models, you put incentives, you put actuation, you put understanding together,
[01:01:12.500 --> 01:01:13.840]   and you tightly loop those together.
[01:01:13.840 --> 01:01:15.240]   That becomes more interesting.
[01:01:15.240 --> 01:01:20.220]   Now you have something which can look into the world, simulate possible possibilities in
[01:01:20.220 --> 01:01:23.860]   its world model, using its values to figure out what makes sense, take action on it, see
[01:01:23.860 --> 01:01:27.820]   what happens, update its world model, and repeat using some sort of understanding to help
[01:01:27.820 --> 01:01:28.660]   it make those decisions.
[01:01:29.100 --> 01:01:33.840]   That's the architecture you need for something that you might have some notion of autonomy.
[01:01:33.840 --> 01:01:35.040]   A language model is not that.
[01:01:35.040 --> 01:01:36.080]   It's just the understanding piece.
[01:01:36.080 --> 01:01:38.600]   It can't become conscious any more than my toaster can.
[01:01:40.180 --> 01:01:43.640]   Anthropic knows this, but this, you know, they got a nice Kevin Roosh profile.
[01:01:43.640 --> 01:01:47.280]   Has anyone built a machine like I described?
[01:01:47.280 --> 01:01:48.640]   Well, here's the problem.
[01:01:48.640 --> 01:01:49.080]   Yes.
[01:01:49.080 --> 01:01:50.900]   We are building those machines.
[01:01:50.900 --> 01:01:51.900]   Let me tell you about one.
[01:01:51.900 --> 01:01:55.800]   DeepMind, subsidiary of Google, has a system called Dreamer.
[01:01:55.800 --> 01:01:57.140]   It's now version three.
[01:01:57.920 --> 01:01:59.540]   That's exactly what Dreamer does.
[01:01:59.540 --> 01:02:06.340]   It has a model of the world developed through reinforcement learning.
[01:02:06.340 --> 01:02:09.300]   It has a goal programmed into it.
[01:02:09.300 --> 01:02:10.620]   It can actuate.
[01:02:10.620 --> 01:02:14.080]   So like Dreamer is often used, the worlds it's run in is like video game worlds.
[01:02:14.080 --> 01:02:16.020]   I think the most interesting example is in Minecraft.
[01:02:16.720 --> 01:02:22.340]   And so it can take actions in the Minecraft world based on what it sees.
[01:02:22.340 --> 01:02:25.880]   It updates its policy with reinforcement learning techniques.
[01:02:25.880 --> 01:02:29.240]   So it can kind of learn what's from happening and it can simulate the future.
[01:02:29.240 --> 01:02:34.560]   So using its world model, its understanding of the world and its goals and its current state,
[01:02:34.560 --> 01:02:38.780]   its current situation, it can look at various things that might do next to see which of these
[01:02:38.780 --> 01:02:40.400]   looks best by its values.
[01:02:40.400 --> 01:02:42.180]   And then it does that action.
[01:02:42.180 --> 01:02:44.080]   And then it learns from that action a little bit, updates it.
[01:02:44.320 --> 01:02:48.040]   That's the type of system where you might worry less about consciousness, but you might
[01:02:48.040 --> 01:02:50.960]   worry about systems getting out of control or doing things you don't expect.
[01:02:50.960 --> 01:02:53.460]   Language models is a completely different game.
[01:02:53.460 --> 01:02:56.140]   They're massive collections of numbers.
[01:02:56.140 --> 01:02:56.840]   It's static.
[01:02:56.840 --> 01:02:57.760]   There's no world model.
[01:02:57.760 --> 01:02:58.380]   There's no state.
[01:02:58.380 --> 01:02:59.000]   There's no memory.
[01:02:59.000 --> 01:02:59.700]   There's no actuation.
[01:02:59.700 --> 01:03:00.820]   It puts out tokens.
[01:03:00.820 --> 01:03:03.740]   Cloud cannot become alive.
[01:03:03.740 --> 01:03:10.020]   It feels like it's alive because these tokens, when you string them all together, like its goal,
[01:03:10.020 --> 01:03:15.840]   what this was trained to optimize was to produce the text that best matches what you would expect
[01:03:15.840 --> 01:03:17.300]   from the text that trained on.
[01:03:17.300 --> 01:03:19.020]   And those texts are written by people.
[01:03:19.020 --> 01:03:21.360]   And so it seems very much like it's alive.
[01:03:21.360 --> 01:03:24.720]   Like there's someone that's sitting around and thinking and modeling the world and using
[01:03:24.720 --> 01:03:26.160]   this to figure out what to tell you.
[01:03:26.160 --> 01:03:28.620]   But it's just, it's not doing that.
[01:03:28.620 --> 01:03:30.460]   Language models is a red herring.
[01:03:30.460 --> 01:03:34.400]   And when it comes to autonomy, you would need to be looking at these much more reinforcement
[01:03:34.400 --> 01:03:35.440]   learning-based models.
[01:03:37.300 --> 01:03:39.240]   That's where the interesting action's happening.
[01:03:39.240 --> 01:03:46.120]   So I think this is a bit of a stunt from OpenAI, I mean, from Anthropics' point of view.
[01:03:46.120 --> 01:03:46.900]   I don't know.
[01:03:46.900 --> 01:03:53.040]   I think the right journalistic response here is like, hey, Mr. Fish, explain to me how a
[01:03:53.040 --> 01:03:57.480]   transformer-based feed-forward neural network can be conscious.
[01:03:57.480 --> 01:03:59.020]   Walk me through this.
[01:03:59.020 --> 01:04:04.620]   Like walk me through like what's, all it can do is data moves through and a token comes out.
[01:04:04.980 --> 01:04:07.440]   It could be a really big thing that the token comes out.
[01:04:07.440 --> 01:04:11.420]   The token could be based on really complicated understandings of the world, but there's no
[01:04:11.420 --> 01:04:13.120]   autonomy.
[01:04:13.120 --> 01:04:13.780]   There's no world model.
[01:04:13.780 --> 01:04:14.440]   There's no actuation.
[01:04:14.440 --> 01:04:15.380]   Like, come on, what's going on here?
[01:04:15.380 --> 01:04:23.680]   Anyways, have skepticism about AI coverage, especially announcements made by the AI companies
[01:04:23.680 --> 01:04:24.180]   themselves.
[01:04:24.180 --> 01:04:26.880]   I think there's, yeah, there's cool stuff coming.
[01:04:26.880 --> 01:04:27.740]   Where are we right now?
[01:04:27.800 --> 01:04:31.840]   I think like right now, language models have proven that they are like becoming, it's like
[01:04:31.840 --> 01:04:34.560]   a, the best AI models are much better than Google.
[01:04:34.560 --> 01:04:35.520]   This is really interesting.
[01:04:35.520 --> 01:04:36.880]   That's a big market.
[01:04:36.880 --> 01:04:39.740]   And they're really useful for computer programmers.
[01:04:39.740 --> 01:04:43.180]   Like these are the, those are two big breakthroughs.
[01:04:43.180 --> 01:04:44.240]   Like Google is a big business.
[01:04:44.240 --> 01:04:47.540]   If you can take away that business, maybe you can start to make back some of this huge burn
[01:04:47.540 --> 01:04:48.400]   rate these companies have.
[01:04:49.020 --> 01:04:50.380]   There's a lot of computer programming.
[01:04:50.380 --> 01:04:55.500]   It allows non-expert programmers to produce prototype systems pretty quickly.
[01:04:55.500 --> 01:04:59.080]   And it allows expert programmers to program faster because they don't have to look things
[01:04:59.080 --> 01:04:59.260]   up.
[01:04:59.260 --> 01:05:03.620]   They can get auto, essentially like a fancy autocomplete and documentation integrated into
[01:05:03.620 --> 01:05:04.060]   their IDE.
[01:05:04.060 --> 01:05:08.780]   Those are like two cool things, but it is different than like, I don't know, next week we might
[01:05:08.780 --> 01:05:10.120]   wake up and Claude's going to be alive.
[01:05:10.120 --> 01:05:10.940]   We are not there.
[01:05:10.940 --> 01:05:12.640]   It's impossible for that system to do it.
[01:05:12.640 --> 01:05:16.660]   The types of systems that have that architecture are very simple right now, but let's keep an eye
[01:05:16.660 --> 01:05:16.980]   on them.
[01:05:18.360 --> 01:05:24.420]   AI is, it's cool and more cool stuff's being discovered, but the pace of this I think is
[01:05:24.420 --> 01:05:29.360]   proving to be like a little bit more regular than some of the Topians might've predicted.
[01:05:29.360 --> 01:05:30.140]   So there we go.
[01:05:30.140 --> 01:05:31.400]   I don't think that's a real job.
[01:05:31.400 --> 01:05:34.260]   I don't think Kyle Fish has a real job, but you know, what do I know?
[01:05:34.260 --> 01:05:37.680]   I'll be the first to go when Claude comes alive.
[01:05:37.680 --> 01:05:42.440]   We're going to get zapped by the old electrical system in this building and zapped by one of
[01:05:42.440 --> 01:05:43.560]   these lights and then we'll know.
[01:05:43.560 --> 01:05:44.720]   That's how we'll know.
[01:05:44.720 --> 01:05:46.620]   If I disappear mysteriously, it was Claude.
[01:05:46.620 --> 01:05:47.980]   Then you can go to the new barn.
[01:05:48.200 --> 01:05:51.320]   The new barn with the rower in my truck.
[01:05:51.320 --> 01:05:51.820]   Oh yeah.
[01:05:51.820 --> 01:05:52.520]   In our studio.
[01:05:52.520 --> 01:05:52.840]   Yeah.
[01:05:52.840 --> 01:05:55.300]   There's going to be no, no electricity in the studio.
[01:05:55.300 --> 01:05:56.960]   You move AI.
[01:05:56.960 --> 01:05:58.780]   All right.
[01:05:58.780 --> 01:05:59.720]   That's all the time we have for today.
[01:05:59.720 --> 01:06:01.300]   We'll be back next week with another episode.
[01:06:01.300 --> 01:06:03.420]   And until then, as always, stay deep.
[01:06:03.420 --> 01:06:09.120]   Hey, if you liked today's episode about slowing down, you might also like episode 315, which
[01:06:09.120 --> 01:06:12.180]   was titled The Surprising Math of Doing Less.
[01:06:12.180 --> 01:06:14.100]   We pick up on some similar themes.
[01:06:14.100 --> 01:06:15.100]   Check it out.
[01:06:15.100 --> 01:06:16.100]   I think you'll like it.

