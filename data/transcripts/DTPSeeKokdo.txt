
[00:00:00.000 --> 00:00:04.400]   Democrats still think the currency of politics is money and the currency of politics is attention.
[00:00:04.400 --> 00:00:07.000]   And that's a huge difference between the two sides right now.
[00:00:07.000 --> 00:00:09.500]   I think the steel man is very easy to make here.
[00:00:09.500 --> 00:00:11.240]   Department of Government Efficiency.
[00:00:11.240 --> 00:00:15.560]   That sounds like an organization that's needed if government is inefficient.
[00:00:15.560 --> 00:00:20.260]   And one of the themes of our book is just how inefficient government can be.
[00:00:20.260 --> 00:00:25.300]   Not only at building houses, building energy, often at achieving its own ends.
[00:00:25.300 --> 00:00:28.140]   Building high-speed rail when it wants to build high-speed rail.
[00:00:28.320 --> 00:00:32.460]   Adding affordable housing units when it wants to add affordable housing units.
[00:00:32.460 --> 00:00:37.020]   You know, I love Ezra's line that we don't just need to think about, you know, deregulating the market.
[00:00:37.020 --> 00:00:39.800]   We need to think about deregulating government itself.
[00:00:39.800 --> 00:00:46.140]   Getting the rules out of the way that keep government from achieving the democratic outcomes that it's trying to achieve.
[00:00:46.140 --> 00:00:51.820]   This is a world in which a Department of Government Efficiency is a godsend.
[00:00:52.340 --> 00:01:01.580]   We should be absolutely obsessed with making government work well, especially if we're going to be the kind of liberals who believe that government is important in the first place.
[00:01:02.200 --> 00:01:13.140]   In my lifetime, the Democratic Party has never been as internally fragmented and weak, leaderless, rudderless, as it is right now.
[00:01:13.140 --> 00:01:14.680]   Now, it won't stay that way.
[00:01:14.680 --> 00:01:17.060]   You cannot change American politics.
[00:01:17.060 --> 00:01:21.800]   You can't change the Democratic Party if you're not willing to upset people.
[00:01:21.940 --> 00:01:25.500]   Donald Trump reformed the Republican Party by willing and able to fight Republicans.
[00:01:25.500 --> 00:01:35.140]   He ran against George W. Bush, against Jeb Bush, against Mitt Romney, against the trade deals, against a bunch of things that were understood to be sacred cows.
[00:01:35.220 --> 00:01:41.420]   Somehow this guy ran, like, right after Mitt Romney and John McCain while attacking Mitt Romney and John McCain, right?
[00:01:41.420 --> 00:01:44.260]   If you are not, like, the Democratic Party does need to change.
[00:01:44.260 --> 00:01:47.540]   It needs to attain a different form because the Obama coalition is exhausted.
[00:01:47.540 --> 00:01:48.180]   It's done.
[00:01:48.180 --> 00:01:53.480]   It's not going to be able to do that if it doesn't have standard bears who are willing to say, we were wrong about some things.
[00:01:53.480 --> 00:01:55.720]   We have to change our views on some things.
[00:01:55.720 --> 00:01:57.580]   We have to act differently and speak differently.
[00:01:57.820 --> 00:02:10.260]   When Elon takes over Tesla, when Elon is at SpaceX, when Elon's at X, I would imagine, and you know this better than me because you know him, and maybe most importantly, for the purposes of this part of the conversation, you know the people who work for him.
[00:02:10.260 --> 00:02:17.400]   I'll bet if you ask the people who work under Elon at X, Tesla, SpaceX, they say, I know exactly what Elon wants.
[00:02:17.400 --> 00:02:20.000]   This is his goal for the super heavy rocket.
[00:02:20.000 --> 00:02:22.540]   This is his goal in terms of humanoid robots.
[00:02:22.540 --> 00:02:29.640]   This is his goal in terms of profitability of Twitter and the growth of our subscription business and how we're going to integrate new features.
[00:02:29.640 --> 00:02:31.980]   There's probably a really clear mind meld.
[00:02:31.980 --> 00:02:35.100]   Right now, I have no sense that there's a mind meld.
[00:02:35.100 --> 00:02:44.260]   And in fact, I have the exact opposite sense, that rather than an example of creative destruction, which would be a mitzvah of entrepreneurship, we have an act of destruction, destruction.
[00:02:44.260 --> 00:02:46.740]   We have destruction for the sake of destruction.
[00:02:47.360 --> 00:03:05.780]   It's much cleaner to me, from an interpretive standpoint, to describe Doge as an ideological purge of progressivism, performing an act of, or performing the job of efficiency, rather than a department of actual efficiency itself.
[00:03:07.540 --> 00:03:12.500]   The following is a conversation with Ezra Klein and Derek Thompson.
[00:03:12.500 --> 00:03:18.300]   Ezra is one of the most influential voices representing the left wing of American politics.
[00:03:18.300 --> 00:03:26.540]   He is a columnist for the New York Times, author of Why We're Polarized, and host of the Ezra Klein Show.
[00:03:26.540 --> 00:03:35.960]   Derek is a writer at The Atlantic, author of Hitmakers and On Work, and host of the Plain English Podcast.
[00:03:36.620 --> 00:03:43.820]   Together, they've written a new book, simply titled Abundance, that lays out a kind of manifesto for the left.
[00:03:43.820 --> 00:03:54.420]   It is already a controversial, widely debated book, but I think it puts forward a powerful vision for what the Democratic Party could stand for in the coming election.
[00:03:54.420 --> 00:04:02.560]   If I may, let me comment on the fact that sometimes in this podcast, I delve into the dark realm of politics.
[00:04:03.300 --> 00:04:09.440]   Indeed, politics often divides us, and frankly, brings out the worst in some very smart people.
[00:04:09.440 --> 00:04:19.640]   Plus, to me, it is frustrating how much of the political discourse is drama, and how little of it is rigorous, empathetic discussion of policy.
[00:04:20.500 --> 00:04:23.340]   I hate this, but I guess I understand why.
[00:04:23.340 --> 00:04:37.200]   If the other side is called either Hitler or Stalin, unlined by swarms of chanting mobs, it's hard to carry out a nuanced discussion about immigration, healthcare, housing, education, foreign policy, and so on.
[00:04:37.960 --> 00:04:43.120]   On top of that, anytime I talk about politics, half the audience is pissed off at me.
[00:04:43.120 --> 00:04:46.100]   And no, there is no audience capture.
[00:04:46.680 --> 00:04:51.580]   I get shit on equally by different groups across the political spectrum, depending on the guest.
[00:04:51.580 --> 00:04:56.900]   Why, I don't know, but I'm slowly coming to accept that this is the way of the world.
[00:04:56.900 --> 00:05:06.200]   I try to maintain my cool, return hate with compassion, and learn from the criticism and the general madness of it all.
[00:05:06.900 --> 00:05:10.440]   Still, I think it's valuable to sometimes talk about politics.
[00:05:10.440 --> 00:05:17.400]   It's an important part to the big picture of human civilization, but indeed, it is only still a small part.
[00:05:17.400 --> 00:05:27.220]   My happy place is talking to scientists, engineers, programmers, video game designers, historians, philosophers, musicians, athletes, filmmakers, and so on.
[00:05:27.220 --> 00:05:32.920]   So, I apologize for the occasional detour into politics, especially over the past few months.
[00:05:33.280 --> 00:05:38.920]   I did a few conversations with world leaders, and I have a few more coming up.
[00:05:38.920 --> 00:05:49.440]   So, there will be a few more political podcasts coming out, in part so I can be better prepared to deeply understand the mind, the life, and the perspective of each world leader.
[00:05:49.440 --> 00:05:54.460]   I hope you come along with me on this journey into the darkness of politics.
[00:05:54.460 --> 00:06:00.000]   As I try to shine a light on the complex human mess of it all, hoping to understand us humans better,
[00:06:00.200 --> 00:06:04.800]   always backed, of course, by deep, rigorous research and by empathy.
[00:06:04.800 --> 00:06:10.300]   Long-term, I hope for political discussions to be only a small percentage of this podcast.
[00:06:10.300 --> 00:06:16.040]   If it's not your thing, please just skip these episodes, or maybe come along anyway,
[00:06:16.040 --> 00:06:20.340]   since both you and I are reluctant travelers on this road trip.
[00:06:20.720 --> 00:06:25.320]   But who knows what we'll learn together about the world and about ourselves.
[00:06:25.320 --> 00:06:27.940]   This is the Lex Reuben Podcast.
[00:06:27.940 --> 00:06:31.240]   To support it, please check out our sponsors in the description.
[00:06:31.240 --> 00:06:36.780]   And now, dear friends, here's Ezra Klein and Derek Thompson.
[00:06:37.880 --> 00:06:42.520]   You are both firmly on the left of the U.S. political spectrum.
[00:06:42.520 --> 00:06:44.900]   Ezra, I've been a fan of yours for a long time.
[00:06:44.900 --> 00:06:50.840]   You're often referred to, at least I think of you as, one of the most intellectually rigorous voices on the left.
[00:06:50.840 --> 00:06:56.460]   Can you try to define, can you define the ideals and the vision of the American left?
[00:06:56.460 --> 00:06:56.980]   Oh, good.
[00:06:56.980 --> 00:06:58.380]   We're starting small here.
[00:06:58.380 --> 00:07:00.460]   And maybe contrast them with the American right.
[00:07:00.700 --> 00:07:01.080]   Sure.
[00:07:01.080 --> 00:07:05.580]   So, the thing I should say here is that you can define the left in different ways.
[00:07:05.580 --> 00:07:07.920]   I think the left has a couple fundamental views.
[00:07:07.920 --> 00:07:10.400]   One is that life is unfair.
[00:07:10.400 --> 00:07:13.480]   We are born with different talents.
[00:07:13.480 --> 00:07:16.140]   We are born into different nations, right?
[00:07:16.140 --> 00:07:21.260]   The luck of being born into America is very different than the luck of being born into Venezuela.
[00:07:21.260 --> 00:07:24.300]   We are born into different families.
[00:07:24.300 --> 00:07:30.280]   We have luck operating as an omnipresence across our entire lives.
[00:07:31.180 --> 00:07:36.820]   And as such, the people for whom it works out well, we don't deserve all of that.
[00:07:36.820 --> 00:07:38.200]   We got lucky.
[00:07:38.200 --> 00:07:41.980]   I mean, we also worked hard and we also had talent and we also applied that talent.
[00:07:41.980 --> 00:07:46.300]   But at a very fundamental level, that we are sitting here is unfair.
[00:07:46.300 --> 00:07:55.680]   And that so many other people are in conditions that are much worse, much more precarious, much more exploited is unfair.
[00:07:56.100 --> 00:08:08.040]   And one of the fundamental roles of government should not necessarily be to turn that unfairness into perfect equality, but to rectify that unfairness into a kind of universal dignity, right?
[00:08:08.040 --> 00:08:09.540]   So people can have lives of flourishing.
[00:08:09.540 --> 00:08:10.480]   So I'd say that's one thing.
[00:08:10.760 --> 00:08:16.400]   The left is fundamentally more skeptical of capitalism and particularly unchecked forms of capitalism than the right.
[00:08:16.400 --> 00:08:22.560]   I always think this is hard to talk about because what we call unchecked capitalism is nevertheless very much supported by government.
[00:08:22.560 --> 00:08:32.260]   So I think in a way, markets are things that are enforced by government, whether they are how you set the rules of them is what ends up differing between the left and the right.
[00:08:32.580 --> 00:08:44.980]   But the left tends to be more worried about the fact that you could get rich building coal-fired power plants, belching pollution into the air, and you could get rich laying down solar panels.
[00:08:44.980 --> 00:08:47.720]   And the market doesn't know the difference between the two.
[00:08:48.080 --> 00:08:57.740]   And so there's a set of goals about regulating the unchecked potential of capitalism that also relates to sort of exploitation of workers.
[00:08:57.740 --> 00:09:03.880]   There's very fundamental questions about how much people get paid, how much power they have.
[00:09:03.880 --> 00:09:08.720]   Again, the rectification of economic and other forms of power is very fundamental to the left.
[00:09:08.760 --> 00:09:13.820]   When you think about what the minimum wage is, I am a successful podcast host.
[00:09:13.820 --> 00:09:20.360]   When I go into a negotiation with the New York Times, I have a certain amount of market power in that negotiation because other firms want to hire me.
[00:09:20.360 --> 00:09:27.740]   When you are a minimum wage worker, the reason we have a minimum wage is in part to rectify a power problem.
[00:09:27.740 --> 00:09:29.940]   A lot of workers do not have market power.
[00:09:29.940 --> 00:09:32.000]   They do not have a bunch of job opportunities.
[00:09:32.000 --> 00:09:33.440]   They are not working with firms.
[00:09:34.360 --> 00:09:39.620]   And by the way, without certain kinds of regulation, those firms will cartelize and make it so they can hold down wages anyway.
[00:09:39.620 --> 00:09:44.440]   So trying to rectify power imbalances is, I think, another thing folks on the left take more seriously.
[00:09:44.440 --> 00:09:50.000]   That would be a start of things that I think broadly unite the, maybe let's call it the intuitions.
[00:09:50.000 --> 00:09:53.100]   I want to say that's a podcast answer, not a book.
[00:09:53.100 --> 00:09:56.880]   I'm sure I left a million things out here, but I'll start there.
[00:09:56.880 --> 00:10:04.380]   I mean, there's a lot of fascinating things there on the unfairness of life that could be the inter-person unfairness.
[00:10:04.380 --> 00:10:09.540]   So one person getting more money than another person, more skills or more natural abilities than another person.
[00:10:09.540 --> 00:10:15.000]   And then there's just the general unfairness of the environment, the luck of the draw, the things that happen.
[00:10:15.000 --> 00:10:20.620]   All of a sudden you cross a street and the car runs a red light and runs you over and you're in the hospital.
[00:10:20.620 --> 00:10:29.800]   So that unfairness of life and in general, I guess the left sees there's some role or a lot of role for government to help you when that unfairness strikes.
[00:10:29.800 --> 00:10:36.420]   And then maybe there's also a general notion of the size of government.
[00:10:36.420 --> 00:10:42.620]   I think the left is more comfortable with a larger government as long as it's effective and efficient, at least in this.
[00:10:42.620 --> 00:10:44.620]   That's certainly true in the last 100 years.
[00:10:44.620 --> 00:10:49.480]   It was New Deal liberals who enlarged the government in the 1930s.
[00:10:49.600 --> 00:10:53.720]   It was Republicans who acquiesced to that larger government in the 1950s.
[00:10:53.720 --> 00:10:59.880]   And then starting in the 1970s, 1980s, it's typically been conservatives who've tried to constrict governments.
[00:10:59.880 --> 00:11:04.620]   Sometimes they failed, while liberals have typically tried to expand, certainly, taxing and spending.
[00:11:04.620 --> 00:11:10.300]   Well, one thing that I was thinking as Ezra was talking, and I was just writing this down because I thought Ezra's answer was really lovely.
[00:11:10.300 --> 00:11:13.460]   But at a really high level, I thought, maybe you disagree with this.
[00:11:14.420 --> 00:11:24.000]   I thought about distinguishing between liberals and conservatives based on three factors, what each side fears, what each side values, and what each side tolerates.
[00:11:24.540 --> 00:11:34.780]   I think liberals fear injustice and conservatives often fear cultural radicalism or the destruction of society.
[00:11:34.780 --> 00:11:37.320]   And as a result, they value different things.
[00:11:37.320 --> 00:11:40.000]   Liberals, I think, tend to value change.
[00:11:40.000 --> 00:11:45.600]   And at the level of government, that can mean change in terms of creating new programs that don't previously exist.
[00:11:45.780 --> 00:11:51.300]   It's typically been liberals, for example, who've been trying to expand health coverage, while conservatives have tried to cut it back.
[00:11:51.300 --> 00:12:01.540]   Just in the last few years, it was Biden who tried to add a bunch of programs, whether it was infrastructure, the Chips and Science Act, the IRA, and then Trump comes into office and is unwinding it.
[00:12:01.540 --> 00:12:04.420]   And then I also think they tolerate different things.
[00:12:04.420 --> 00:12:13.100]   I think liberals are more likely to tolerate a little bit of overreach, a little bit of radicalism in terms of trying to push society into a world where it hasn't been.
[00:12:13.460 --> 00:12:16.600]   Well, I think conservatives are more likely to tolerate injustice.
[00:12:16.600 --> 00:12:25.920]   They're more likely to say there's a kind of natural inequality in the nature of the world, and we're not going to try to overcorrect for it with our policies.
[00:12:25.920 --> 00:12:41.560]   And so I think that even at a layer above what Ezra was articulating with the policy differences between liberals and conservatives, there's almost like an archetypal difference between what they fear and value and tolerate.
[00:12:42.220 --> 00:12:54.080]   Liberals fearing injustice, seeking change, tolerating sometimes a bit of what people might think of as overreach, while conservatives fear that overreach, value tradition, and often tolerate injustice.
[00:12:54.080 --> 00:13:01.880]   The only thing I would say is that I do think this sort of the left likes big government, the right likes small government oversimplifies.
[00:13:01.880 --> 00:13:12.240]   The left is pretty comfortable with an expansive government that is trying to correct for some of the imbalances of power and injustices and imbalances of luck I talked about earlier.
[00:13:12.660 --> 00:13:17.860]   The right is very comfortable with a very powerful police and surveillance and national security state.
[00:13:17.860 --> 00:13:26.580]   I always think about the sort of George W. Bush there, although right now with ICE agents hassling all kinds of green card holders, you can think about this moment too.
[00:13:26.580 --> 00:13:47.220]   But the right's view that on the one hand the government is incompetent, and on the other hand we could send our army across oceans, invade Afghanistan and Iraq, and then rebuild these societies we don't understand into fully functioning liberal democracies that will be our allies, was an extraordinary level of trust in a very big government.
[00:13:47.220 --> 00:14:00.680]   I mean, that was expensive, that took manpower, that was compared to, we're going to set up, you know, the Affordable Care Act in America, that took a lot more faith in the U.S. government being able to do something that was extraordinarily difficult.
[00:14:00.680 --> 00:14:06.200]   But the left has more confidence in the government of the check, and the right has more confidence in the government of the gun.
[00:14:06.200 --> 00:14:17.180]   You're right, there's some degree to which what the right, when the right speaks about the size of government, it's a little bit rhetoric and not actual policy.
[00:14:17.180 --> 00:14:20.320]   Because they seem to always grow the size of government, anyway.
[00:14:20.320 --> 00:14:36.640]   They just kind of say small government, but they don't, it's, you know, in the surveillance state, in the foreign policy in terms of military involvement abroad, and really in every program, they're not very good at cutting either.
[00:14:36.640 --> 00:14:38.420]   They just kind of like to say it.
[00:14:38.420 --> 00:14:39.660]   Cutting is really hard.
[00:14:39.660 --> 00:14:46.540]   If you, government spends trillions of dollars, and if you cut billions of dollars, someone is going to feel that pain,
[00:14:46.540 --> 00:14:47.320]   and they're going to scream.
[00:14:47.320 --> 00:14:51.660]   And so you look at defense spending under Reagan, you look at overall spending under Reagan,
[00:14:51.660 --> 00:14:57.620]   Reagan might be one of the most archetypally conservative presidents of the last 40, 50 years.
[00:14:57.620 --> 00:15:01.940]   He utterly failed in his attempt to shrink government.
[00:15:01.940 --> 00:15:03.580]   Government grew under Reagan.
[00:15:03.580 --> 00:15:05.560]   Defense grew, all sorts of programs grew.
[00:15:05.560 --> 00:15:11.900]   So I think that one thing we're sort of scrambling around in our answers is that at a really high level,
[00:15:11.900 --> 00:15:19.780]   there are differences between liberalism and conservatism in American history, but often at the level of implementation, it can be a little bit messy.
[00:15:19.780 --> 00:15:27.340]   Even Bush's foreign policy that Ezra was describing, sort of from a big sense of American history, is very like Wilsonian, right?
[00:15:27.340 --> 00:15:30.880]   This sense of like, it's America's duty to go out and change the world.
[00:15:31.080 --> 00:15:32.860]   Or to use a current example, McKinleyan.
[00:15:32.860 --> 00:15:34.200]   Or McKinleyan, right.
[00:15:34.200 --> 00:15:43.080]   And a lot of people compare Donald Trump's foreign policy to Andrew Jackson, this sense of we need to pull back from the world.
[00:15:43.080 --> 00:15:43.980]   America first.
[00:15:43.980 --> 00:15:47.880]   We need to care about what's inside of our borders and care much less about what's outside of our borders.
[00:15:47.880 --> 00:15:58.320]   Sometimes the differences between Republican and Democrat administrations don't fall cleanly into the lines of liberal versus conservative because those definitions can be mushy.
[00:15:58.400 --> 00:16:07.460]   All right, so to descend down from the platonic ideals of the left and the right, who is actually running the show on the right and the left?
[00:16:07.460 --> 00:16:09.180]   Who are the dominant forces?
[00:16:09.180 --> 00:16:19.840]   Maybe you could describe, and you mentioned Democratic Socialists, the progressives, maybe liberals, maybe more sort of mainstream left.
[00:16:20.780 --> 00:16:23.600]   And the same on the right with Trump and Trumpism.
[00:16:23.600 --> 00:16:27.220]   So on the right, it's pretty straightforward at the moment.
[00:16:27.220 --> 00:16:30.240]   And the right is composed differently than it was 10 years ago.
[00:16:30.240 --> 00:16:36.400]   But the right is run by Donald Trump and the people who have been given the nod of power by Donald Trump.
[00:16:36.400 --> 00:16:38.520]   So that is right now Elon Musk.
[00:16:38.520 --> 00:16:40.760]   But Elon Musk's power is coming from Donald Trump.
[00:16:41.160 --> 00:16:49.780]   That is, you know, maybe in some degrees, J.D. Vance, maybe in some degrees, Russ Vought, maybe sometimes, you know, Homans over at DHS.
[00:16:50.720 --> 00:16:57.240]   The right beneath that, the Republicans in Congress are extraordinarily disempowered compared to in other administrations.
[00:16:57.240 --> 00:17:01.360]   They are sort of being told what to do, and they are doing what they are told.
[00:17:01.360 --> 00:17:05.080]   Republicans in Congress, Senate Republicans, they didn't want Pete Hegseth.
[00:17:05.440 --> 00:17:07.000]   They didn't want Kash Patel.
[00:17:07.000 --> 00:17:08.960]   They didn't want Tulsi Gabbard.
[00:17:08.960 --> 00:17:10.440]   They didn't want RFK Jr.
[00:17:10.440 --> 00:17:21.260]   Nobody got elected to be a Republican in the Senate, hoping that they would confirm Robert F. Kennedy Jr., a member of the Kennedys, a Democrat who was pro-choice and running as a Democrat two years ago, for HHS.
[00:17:21.260 --> 00:17:23.260]   But Donald Trump told them to do it, and they did.
[00:17:23.260 --> 00:17:26.260]   So the right has developed a very, very top-down structure.
[00:17:26.980 --> 00:17:38.420]   And one of Trump's talents, one of the things that makes him a disruptive force in politics is his ability to upend the sort of coalitional structure, the interest group structure that used to prevail.
[00:17:38.420 --> 00:17:44.000]   You know, the Koch brothers were the big enemy of the left, you know, 10, 15 years ago.
[00:17:44.000 --> 00:17:46.180]   The view was that in many ways they set the agenda of the right.
[00:17:46.180 --> 00:17:52.040]   The Koch brother network is much less powerful under Donald Trump because he just disagrees with them and has disempowered them.
[00:17:52.040 --> 00:17:55.220]   Not to say none of their people or none of their groups are meaningful at all.
[00:17:55.280 --> 00:17:59.520]   They are, but you wouldn't put them at the forefront in the way that you might have at another time.
[00:17:59.520 --> 00:18:06.500]   Right this second, we're using the left, but Democrats are in fundamental disarray.
[00:18:06.500 --> 00:18:07.720]   There is no leader.
[00:18:07.720 --> 00:18:13.880]   Democrats, Senate Democrats decided to vote for the continuing resolution, avoiding a shutdown or a critical mass of them did.
[00:18:13.880 --> 00:18:22.820]   Hakeem Jeffries, the leader of the House Democrats, and Chuck Schumer, the leader of Senate Democrats, are in bitter disagreement over whether or not they should have done that.
[00:18:23.280 --> 00:18:28.600]   Democratic leadership isn't even united on the single biggest point of leverage they might have had.
[00:18:28.740 --> 00:18:31.100]   They disagree over whether or not it was even a point of leverage.
[00:18:31.100 --> 00:18:36.660]   Outside of them, the party is no leader, which is fairly normal after a pretty crushing defeat.
[00:18:36.660 --> 00:18:40.160]   But there isn't the next in line.
[00:18:40.160 --> 00:18:42.400]   So, you know, you go back, right?
[00:18:42.400 --> 00:18:46.700]   And it was pretty clear that, you know, after Barack Obama, it was going to be Hillary Clinton.
[00:18:46.700 --> 00:18:50.620]   After Hillary Clinton was either going to be Joe Biden or Bernie Sanders.
[00:18:50.620 --> 00:18:52.640]   Bernie Sanders had come in second in the primary.
[00:18:52.900 --> 00:18:54.260]   Joe Biden had been the vice president.
[00:18:54.260 --> 00:18:59.740]   You often have a presumptive next nominee who the party can look to for a kind of leadership.
[00:18:59.740 --> 00:19:03.560]   Even after 2000, Al Gore was still giving big speeches.
[00:19:03.560 --> 00:19:05.420]   There was a question about Al Gore running again.
[00:19:05.420 --> 00:19:09.380]   There is no presumptive in the Democratic Party right now.
[00:19:09.380 --> 00:19:12.740]   You can't turn around and say, oh, it's going to be Pete Buttigieg.
[00:19:12.740 --> 00:19:13.960]   It's going to be Josh Shapiro.
[00:19:14.100 --> 00:19:15.180]   It's going to be Gretchen Whitmer.
[00:19:15.180 --> 00:19:21.680]   Absent parties are given force, modern parties, which are quite weak by historical standards.
[00:19:21.680 --> 00:19:25.060]   Modern parties tend to be given force by a centralizing personality.
[00:19:25.060 --> 00:19:27.840]   Donald Trump being a very strong example of that on the right.
[00:19:27.840 --> 00:19:31.960]   But Barack Obama was the person who held together the Democratic Party for a long time.
[00:19:33.000 --> 00:19:44.400]   In my lifetime, the Democratic Party has never been as internally fragmented and weak, leaderless, rudderless as it is right now.
[00:19:44.400 --> 00:19:45.940]   Now, it won't stay that way.
[00:19:45.940 --> 00:19:47.940]   There's a rhythm to these things.
[00:19:47.940 --> 00:19:48.800]   There'll be a midterm.
[00:19:48.800 --> 00:19:50.820]   They're probably going to pick up a bunch of seats in the midterm.
[00:19:50.820 --> 00:19:57.420]   If that means Hakeem Jeffries becomes speaker after the midterm, he's going to have a much louder voice because he's going to have power.
[00:19:58.240 --> 00:20:02.120]   It's going to be a harder road for Schumer to get back to the majority because of the Senate map.
[00:20:02.120 --> 00:20:05.280]   And then we'll start having a primary on the left.
[00:20:05.280 --> 00:20:09.160]   And you'll begin to see voices emerge out of that.
[00:20:09.160 --> 00:20:13.780]   But right now, the Democratic Party, it doesn't have points of power.
[00:20:13.780 --> 00:20:23.460]   They're simply outside of, you know, at the national level, there is no Democrat who wields control over a branch of government, right?
[00:20:23.460 --> 00:20:24.320]   They don't have the Supreme Court.
[00:20:24.320 --> 00:20:25.340]   They don't have the House.
[00:20:25.340 --> 00:20:26.180]   They don't have the Senate.
[00:20:26.180 --> 00:20:27.120]   They don't have the presidency.
[00:20:27.580 --> 00:20:29.180]   And they don't have a next in line.
[00:20:29.180 --> 00:20:34.840]   So you're looking at an organization without any of the people in a position to structure it.
[00:20:34.840 --> 00:20:38.080]   And the head of the DNC, the new head, Ken Martin, doesn't have power in that way.
[00:20:38.080 --> 00:20:41.080]   So they're pretty fractured.
[00:20:41.080 --> 00:20:49.260]   You got a lot of criticism for this, but you were one of the people that early on said that Biden should step down.
[00:20:49.260 --> 00:20:57.180]   So why is the Democratic Party at this stage in its history so bad at generating the truly inspiring person?
[00:20:57.180 --> 00:21:03.500]   To me personally, you know, AOC is an example of a person that might be that person.
[00:21:03.760 --> 00:21:04.580]   You should have her on the show.
[00:21:04.580 --> 00:21:07.180]   I would watch that.
[00:21:07.180 --> 00:21:07.860]   Definitely.
[00:21:07.860 --> 00:21:10.800]   I mean, you know, I really try to, and we'll talk about this.
[00:21:10.800 --> 00:21:18.160]   I try to do like two, three hours, and there's a hesitancy on the left, especially to do these kinds of long programs.
[00:21:18.160 --> 00:21:19.340]   I think it's a trust issue.
[00:21:19.340 --> 00:21:20.820]   I'm not exactly sure what it is.
[00:21:20.820 --> 00:21:24.920]   Eighty percent of the people on this show are left wing.
[00:21:24.920 --> 00:21:29.080]   I'm pretty good faith, and I try to bring out the best in people.
[00:21:29.080 --> 00:21:29.780]   Have you invited her?
[00:21:29.780 --> 00:21:30.380]   Is that what you're saying?
[00:21:30.380 --> 00:21:31.280]   Yeah, yeah.
[00:21:31.280 --> 00:21:34.060]   We'll see what happens when people get closer to 2028.
[00:21:34.060 --> 00:21:35.280]   Sure.
[00:21:35.280 --> 00:21:37.240]   Maybe people begin taking that kind of risk.
[00:21:37.240 --> 00:21:40.440]   Also, you know, Bernie's up there in age, so he can't, you know, he can't do it anymore.
[00:21:40.440 --> 00:21:43.880]   Why is the Democratic Party so bad at generating this kind of talent?
[00:21:43.880 --> 00:21:46.300]   I don't think it's so bad at generating them.
[00:21:46.300 --> 00:21:49.620]   I think that it turned out to be bad at generating them this year.
[00:21:49.620 --> 00:21:56.260]   Look, like I, yeah, as you mentioned, you know, back in February 2023, somebody came out and said, like, Biden can't run again.
[00:21:56.260 --> 00:21:57.020]   This isn't going to work.
[00:21:57.020 --> 00:22:05.120]   And my view, and that was really what that set of pieces was about, was about the argument that even though Biden was clearly going to win the primary,
[00:22:05.900 --> 00:22:09.680]   there was still time for Democrats to do something the parties had done in the past and have an open convention.
[00:22:09.680 --> 00:22:14.800]   And you could structure the lead up to an open convention in a number of different ways, right?
[00:22:14.800 --> 00:22:19.360]   You could have something like a mini primary, but basically you'd have Democrats out in the media, out giving speeches,
[00:22:19.360 --> 00:22:25.160]   and their ultimate audience would be the delegates at the Democratic National Convention.
[00:22:25.160 --> 00:22:28.920]   And my hope was through that you would find the person for this moment.
[00:22:28.920 --> 00:22:33.680]   The thing for Kamala Harris that was really difficult was she was for another moment.
[00:22:34.460 --> 00:22:46.640]   She was picked by Joe Biden in 2020 amidst just a very different political equilibrium, a sense that you had a transitionary moment between two versions of the Democratic Party.
[00:22:46.640 --> 00:22:52.140]   Maybe Joe Biden reaching a little bit back to the past, to these sort of lunch pail, you know, blue collar Democrats.
[00:22:52.140 --> 00:22:55.060]   Joe from Scranton was a big, a big part of the Joe Biden appeal.
[00:22:55.440 --> 00:22:59.820]   But also Biden never has a chance if he's not Barack Obama's vice president.
[00:22:59.820 --> 00:23:05.360]   And so you have this sort of weird set of historical factors like operating at the same time.
[00:23:05.360 --> 00:23:10.120]   There's a desire for stability and experience amidst the chaos of Donald Trump and the pandemic.
[00:23:10.120 --> 00:23:16.580]   There is Biden as Obama's vice president, who nevertheless did not run in the election after Obama.
[00:23:17.400 --> 00:23:24.560]   I think a lot of people look back at 2016 and think, you know what, if Biden had been the candidate, he would have beaten Trump and we would live in a different reality.
[00:23:24.560 --> 00:23:31.440]   And then Biden chose Harris as an effort to shore up his own at least assumed weaknesses.
[00:23:31.440 --> 00:23:36.140]   Right. He's a white man in the Democratic Party at a time when the Democratic Party is diversifying.
[00:23:36.400 --> 00:23:44.140]   And when the view of how you win elections is you put is you put back together the Obama coalition and the Obama coalition is young people.
[00:23:44.140 --> 00:23:51.720]   It's, you know, voters of color and it's enough working class white voters and then college educated white voters.
[00:23:51.720 --> 00:23:52.860]   Right. That's the Obama coalition.
[00:23:52.860 --> 00:23:56.700]   And so Biden picks Harris, you know, for different reasons.
[00:23:56.700 --> 00:24:00.860]   My view at that time was I was sort of a Tammy Duckworth person and thought I should have picked Tammy Duckworth.
[00:24:00.860 --> 00:24:04.320]   But but there are different people out there.
[00:24:04.880 --> 00:24:08.840]   And then the kind of moment that Harris was running in just sort of dissipates.
[00:24:08.840 --> 00:24:14.940]   First, she has a particular background from California where she's a tough on crime.
[00:24:14.940 --> 00:24:16.960]   Her book is called Smart on Crime Prosecutor.
[00:24:16.960 --> 00:24:21.000]   But she runs in the Democratic Party at a time when it's turned on that kind of politics.
[00:24:21.000 --> 00:24:28.700]   People want a lot from her personally, but they don't want a sort of prosecutorial character.
[00:24:29.000 --> 00:24:36.760]   So she sort of abandons that and never, I think, really finds another political identity, certainly before she begins running, you know, in 2024 that works.
[00:24:36.760 --> 00:24:38.240]   But she's a talented debater.
[00:24:38.240 --> 00:24:40.900]   She's a very talented performer on the stump.
[00:24:40.900 --> 00:24:46.060]   But she doesn't really have a theory of politics and policy that she's identified with.
[00:24:46.060 --> 00:24:55.560]   But she's a way for Biden to signal that he understands that him being, you know, in 2020, a 78-year-old white guy, he understands the future is not him or at least not just him.
[00:24:55.560 --> 00:25:01.560]   And he's sort of trying to make a coalitional pick that speaks to his own, you know, potential weaknesses.
[00:25:02.300 --> 00:25:04.800]   I think by 2024, you have two problems, right?
[00:25:04.800 --> 00:25:08.040]   Once he only steps down, what is it, June?
[00:25:08.040 --> 00:25:11.500]   Like, they are weeks from the DNC.
[00:25:11.500 --> 00:25:13.940]   They don't have time anymore for an open convention.
[00:25:13.940 --> 00:25:19.720]   You now have the Biden administration is very unpopular for a number of reasons, but particularly inflation and cost of living.
[00:25:20.380 --> 00:25:25.000]   So now you have Kamala Harris running with a sort of anvil of being associated.
[00:25:25.000 --> 00:25:26.700]   I mean, it's a Biden-Harris administration.
[00:25:26.700 --> 00:25:30.100]   She doesn't really have a lane on cost of living.
[00:25:30.100 --> 00:25:32.380]   It's not something she's known for working on in the Senate.
[00:25:32.380 --> 00:25:34.540]   It's not something she has a bunch of great ideas about.
[00:25:34.540 --> 00:25:36.320]   Not something she's great at talking about.
[00:25:36.320 --> 00:25:39.760]   It's probably not the candidate you would pick for a cost of living election.
[00:25:39.760 --> 00:25:42.620]   And she's had no time to build that out, right?
[00:25:42.620 --> 00:25:52.320]   Maybe if she had been running in a primary for, you know, a year and a half, having to fend off Elizabeth Warren and Bernie Sanders and Pete Buttigieg and whomever else, she either would have figured out how to do it, right?
[00:25:52.320 --> 00:25:55.620]   Primaries are periods of education and learning for the candidates, too.
[00:25:55.620 --> 00:25:58.160]   Or they would have found somebody else who could do it.
[00:25:58.160 --> 00:26:00.120]   But she doesn't get any of that, right?
[00:26:00.120 --> 00:26:02.120]   She's thrown into the game with three months to go.
[00:26:02.120 --> 00:26:05.960]   So, you know, they picked the candidate in 2020 who won.
[00:26:05.960 --> 00:26:09.900]   Whether you think Biden's inspiring or not, he was probably—he was a reasonable pick for that moment.
[00:26:09.900 --> 00:26:14.100]   He should have never run for a second term, and he sort of implied to a lot of people that he wouldn't.
[00:26:14.100 --> 00:26:23.520]   And then the handover to Harris was a very difficult handover to a candidate who didn't go through any kind of selection process for the moment in which he was running.
[00:26:23.520 --> 00:26:29.220]   We'll see what they do in 2028, but the consequences of what they did in 2024 have been severe.
[00:26:29.220 --> 00:26:34.160]   There's two really big questions on the table that I think click together in an interesting way.
[00:26:34.160 --> 00:26:36.660]   You asked, one, why did Trump win?
[00:26:36.660 --> 00:26:45.600]   And two, why do Democrats have this certain communication style that might make them less interested in coming on to an unstructured three-hour conversation with you?
[00:26:45.600 --> 00:26:47.900]   Let me try to tell a story that connects them.
[00:26:47.900 --> 00:26:51.160]   I think Trump's victory in 2024 was overdetermined.
[00:26:51.160 --> 00:26:52.900]   There are a lot of factors here.
[00:26:52.900 --> 00:26:57.360]   Number one, if you look internationally, incumbents lost all over the world.
[00:26:57.360 --> 00:27:04.640]   They lost in the U.S., they lost in Europe, they lost in pretty much every developed country at rates that we really haven't seen in 50 years.
[00:27:04.640 --> 00:27:11.920]   And that's largely because the inflation crisis that came after COVID created an absolute disaster for incumbent establishment power.
[00:27:11.920 --> 00:27:13.640]   People couldn't bring prices down.
[00:27:13.640 --> 00:27:14.440]   Voters were furious.
[00:27:14.440 --> 00:27:17.440]   And they were destroying establishment orders all over the world.
[00:27:17.440 --> 00:27:18.900]   Democrats happened to be in power.
[00:27:18.900 --> 00:27:20.560]   And as a result, they got the brunt of it.
[00:27:20.560 --> 00:27:21.200]   That's number one.
[00:27:21.360 --> 00:27:25.500]   Number two, if you look at elections over the 21st century, two things are true.
[00:27:25.500 --> 00:27:28.440]   One, almost every election is unbelievably close.
[00:27:28.440 --> 00:27:43.580]   For reasons that I'm not sure I entirely understand, the parties have gotten really good, historically, bizarrely good, at getting each group to come to the polls with about 48%, such that every election is a battle over the next 1.5%.
[00:27:43.580 --> 00:27:48.520]   And in a world like that, little thermostatic swings are very important.
[00:27:48.980 --> 00:27:59.680]   And what we've seen over the last few years, and there's this theory about thermostatic public opinion in American politics, that says that what often happens in politics is one party has a very compelling message of change.
[00:27:59.680 --> 00:28:06.520]   They become the establishment, and then they become the victims of exactly the weapon that they marshaled.
[00:28:06.520 --> 00:28:10.400]   That then the next outgroup party says, we have a theory of change, and we're going to throw out the bums.
[00:28:10.400 --> 00:28:13.380]   And the next party comes in, and they overreach, and then they lose.
[00:28:13.380 --> 00:28:18.600]   In a world where you have thermostatic change, and every election is very close, you tend to have elections swinging back and forth.
[00:28:18.720 --> 00:28:31.580]   So I think that also explains why Democrats and Republicans have struggled to hold on to power for six-year, eight-year, 12-year terms the same way they did, say, in the 1930s or 1960s.
[00:28:31.580 --> 00:28:37.680]   But finally, you have to look at what kind of character Donald Trump is, and what kind of a media figure he is.
[00:28:37.680 --> 00:28:50.340]   We were just talking off camera about how every age of communications technology revolution clicks into focus a new skill that is suddenly in critical demand for the electorate.
[00:28:50.680 --> 00:28:58.140]   The world of radio technology is a world in which Franklin Delano Roosevelt can be powerful in a way that he can't be in the 1890s.
[00:28:58.140 --> 00:29:00.140]   And then you have the 1950s.
[00:29:00.140 --> 00:29:04.920]   Dwight Eisenhower, 1956, I believe, was the first televised national convention.
[00:29:05.380 --> 00:29:20.560]   Famously, the 1960 presidential debates between JFK and Richard Nixon take an election that is leaning toward Nixon and make an election that's leaning toward JFK because he's so damn handsome and also just electrically compelling on a screen.
[00:29:21.060 --> 00:29:25.520]   We have a new screened technology right now, which is not just television and steroids.
[00:29:25.520 --> 00:29:26.880]   It's a different species entirely.
[00:29:26.880 --> 00:29:30.060]   And it seems to favor.
[00:29:30.060 --> 00:29:41.500]   It seems to provide value for individuals, influencers, and even celebrities and politicians who are good at something like live wire authenticity.
[00:29:41.500 --> 00:29:45.640]   They're good at performing authenticity, as paradoxical as that sounds.
[00:29:46.340 --> 00:29:54.920]   Trump is an absolute marvel at performing authenticity, even when the audience somehow acknowledges that he might be bullshitting.
[00:29:54.920 --> 00:29:58.120]   He's just an amazing performer for this age.
[00:29:58.120 --> 00:30:05.620]   And it speaks to the fact that he seems to be, to borrow Ezra's term, remarkably disinhibited in front of every single audience.
[00:30:05.620 --> 00:30:12.620]   There doesn't seem to be this sort of background algorithm in his head calculating exactly how to craft his message to different audiences.
[00:30:12.620 --> 00:30:16.220]   He just seems to be like a live wire animal in front of every audience.
[00:30:16.220 --> 00:30:25.540]   And I think that compares very distinctly to the democratic character of bureaucratic caution in our age.
[00:30:25.540 --> 00:30:37.160]   And there is a really important distinction between this vibe of the Trumpian ruler and the vibe of the rule follower.
[00:30:37.160 --> 00:30:50.520]   And the vibe of the bureaucratic rule follower is a little bit afraid of unstructured conversation, is always performing the background algorithm of how do I communicate in a way that balances all of the coalitions on my side?
[00:30:50.680 --> 00:30:57.920]   Because if you look at the Democratic Party right now to compare to the Republican Party, I mean, in 2015, I think there were four political parties in America.
[00:30:57.920 --> 00:31:03.720]   There was MAGA, there was a center right, there was the Bernie wing, and there was the Biden-Clinton-Obama wing.
[00:31:04.360 --> 00:31:09.820]   And what happened is that Trump killed and skinned the center right and is now wearing it as a hat.
[00:31:09.820 --> 00:31:15.940]   The entire Republican Party is Donald Trump wearing the skins of the old center right, the Romney wing.
[00:31:15.940 --> 00:31:18.280]   And the Democratic Party is still a fight.
[00:31:18.280 --> 00:31:19.980]   It's exactly what Ezra described.
[00:31:19.980 --> 00:31:20.580]   It's a jungle.
[00:31:21.240 --> 00:31:42.640]   And maybe there's something about that jungle nature of the Democratic Party that is making some of its leaders perform this sort of coalitional calculation when they're communicating, such that it makes them less interested in appearing in settings that might cost them, that might not benefit them in exactly the sort of pre-calculated way they have to get their message across.
[00:31:42.640 --> 00:31:46.580]   And so there's not necessarily a whole lot of empirics to that theory.
[00:31:46.580 --> 00:31:50.120]   I'm a little bit going on vibes here, and maybe Ezra sees some flaws to the theory.
[00:31:50.120 --> 00:31:50.920]   It's an age of the vibe.
[00:31:50.920 --> 00:31:52.360]   It's an age of the vibe.
[00:31:52.360 --> 00:31:52.640]   Yeah, exactly.
[00:31:52.640 --> 00:31:55.280]   I'm trying to perform the live wire authenticity that I'm describing.
[00:31:55.280 --> 00:32:16.080]   But I do think that might begin to explain why you, Lex, might be picking up on a difference between the political vibes, an eagerness and a willingness on the one hand to have kind of unstructured and even chaotic conversations, and a care on the other side about not letting conversations become too unstructured or too careless.
[00:32:16.080 --> 00:32:17.400]   Can I build on that?
[00:32:17.400 --> 00:32:20.260]   I know we're supposed to talk about abundance, but I want to talk about this.
[00:32:20.260 --> 00:32:23.220]   There's an abundance of time.
[00:32:23.220 --> 00:32:24.220]   An abundance of time.
[00:32:24.220 --> 00:32:25.180]   We're on the Lex Friedman show.
[00:32:25.180 --> 00:32:28.320]   So two or three things.
[00:32:28.320 --> 00:32:33.840]   One is Democrats still think the currency of politics is money and the currency of politics is attention.
[00:32:33.840 --> 00:32:36.960]   And that's a huge difference between the two sides right now.
[00:32:37.560 --> 00:32:39.160]   So what did Kamala Harris come in and do?
[00:32:39.160 --> 00:32:43.520]   She came in and raised a shit ton of money, right?
[00:32:43.520 --> 00:32:46.620]   Like a billion dollars in, you know, record time, basically.
[00:32:46.620 --> 00:32:51.340]   She had more money than Donald Trump did and used it to try to buy attention.
[00:32:52.200 --> 00:32:56.280]   What it meant for Democrats to be good at social media is to have a good social media team.
[00:32:56.280 --> 00:33:04.260]   People in your office somewhere, in your campaign headquarters, who put out cool things on social media, good memes and, you know, good advertisements and so on.
[00:33:04.260 --> 00:33:08.460]   What it means on the right to be good at social media is to be you personally good at social media.
[00:33:08.840 --> 00:33:17.420]   You're Vivek Ramaswamy, you're J.D. Vance, you're Donald Trump, you're Elon Musk, and what you understand is you are the product.
[00:33:17.420 --> 00:33:21.200]   What it means to be good at attention is you are good at attention.
[00:33:21.200 --> 00:33:24.840]   Now, Harris, I think, was actually better at some dimensions of this.
[00:33:24.840 --> 00:33:27.200]   They were just slightly older dimensions and people always gave her credit for.
[00:33:27.200 --> 00:33:28.900]   Hell of a performer on the stump.
[00:33:28.900 --> 00:33:31.540]   She was way better on the stump than people realized she would be.
[00:33:31.540 --> 00:33:32.500]   And a good debater.
[00:33:32.500 --> 00:33:33.720]   She'd always been a good debater.
[00:33:33.720 --> 00:33:35.300]   She trashed Donald Trump in that debate.
[00:33:36.000 --> 00:33:39.620]   But she does not do social media herself at any level, right?
[00:33:39.620 --> 00:33:40.900]   Because she's not going to take risk.
[00:33:40.900 --> 00:33:48.860]   Democrats, most Democrats, still live in a world where the thing that they are optimizing for in attention is to not get negative attention.
[00:33:48.860 --> 00:33:59.260]   And what the Trumpist wing of the Republican Party understands, and this is truer for them than it probably would be for Democrats, because for them, the media is the enemy or at least mainstream media is, etc.
[00:33:59.580 --> 00:34:05.420]   But is that attention, a volume of attention is itself good.
[00:34:05.420 --> 00:34:09.100]   And you can only get a critical mass of it if you're willing to accept negative attention.
[00:34:09.100 --> 00:34:12.400]   Agenda control doesn't come from positive attention.
[00:34:12.400 --> 00:34:13.800]   It comes from conflict.
[00:34:13.800 --> 00:34:17.800]   You get agenda control by doing things the other side disagrees with.
[00:34:17.800 --> 00:34:22.420]   So they enter into functioning agreement with you to keep the thing you're doing at the front.
[00:34:22.420 --> 00:34:24.440]   Now, that doesn't make you highly popular.
[00:34:24.440 --> 00:34:30.120]   Donald Trump is the most unpopular modern president at this stage of his presidency, except for Donald Trump's first term.
[00:34:30.120 --> 00:34:36.740]   It took I think Nate Silver said it was two hundred and twenty one days for Joe Biden's net favorability to go negative.
[00:34:36.740 --> 00:34:40.260]   It's taken something like fifty five days for Donald Trump to do the same.
[00:34:40.260 --> 00:34:44.380]   So what Donald Trump is doing does not optimize for favorability.
[00:34:44.380 --> 00:34:47.320]   It does not it does not optimize, by the way, for big wins.
[00:34:47.320 --> 00:34:50.800]   Democrats feel like they got trashed in 2024 and in a way they did.
[00:34:50.800 --> 00:35:01.840]   But Trump's popular vote victory was the smallest popular vote victory since 2000 when Al Gore beat George W. Bush by 17 dogs and three old men or whatever it was.
[00:35:02.540 --> 00:35:05.180]   And so attention works really differently.
[00:35:05.180 --> 00:35:17.340]   And while I don't I think some of the like, you know, the Rogan of the left discourse has been, frankly, overstated because honestly, the most parsimonious model of 2024 and 2020 is in 2020.
[00:35:17.340 --> 00:35:19.700]   You have a 48, 48 nation, something like that.
[00:35:19.700 --> 00:35:23.100]   Or maybe you have something that's more like a 49 Democrat, 47 Republican nation.
[00:35:24.100 --> 00:35:31.620]   And in 2020, because of the pandemic, Donald Trump suffered a let's call it a 2.5 point incumbent penalty.
[00:35:31.620 --> 00:35:33.180]   People are mad about the pandemic.
[00:35:33.180 --> 00:35:34.780]   They're mad about things being chaotic.
[00:35:34.780 --> 00:35:36.560]   So he loses 2.5 points.
[00:35:36.560 --> 00:35:43.820]   That gives given the natural split of the electorate, Joe Biden, a 4.5 point popular vote victory in 2024.
[00:35:43.820 --> 00:35:45.780]   People are mad about inflation.
[00:35:45.780 --> 00:35:47.520]   They're somewhat mad about the border.
[00:35:47.520 --> 00:35:51.720]   You have a 2.5 point penalty applied to the incumbent administration.
[00:35:51.720 --> 00:35:52.460]   Now it's Harris.
[00:35:52.460 --> 00:35:54.060]   And you get a 1.5.
[00:35:54.060 --> 00:35:55.800]   1.5 point popular vote victory for Donald Trump.
[00:35:55.800 --> 00:35:59.560]   I genuinely don't think, and this held internationally too, right?
[00:35:59.560 --> 00:36:02.680]   I genuinely don't think you need a lot more to explain the election right now than that.
[00:36:02.680 --> 00:36:08.840]   But you do need something more than that to explain Donald Trump's now, since 2016, almost
[00:36:08.840 --> 00:36:14.920]   decade-long dominance of all attention in American politics, starting when he came down the golden
[00:36:14.920 --> 00:36:22.040]   escalator in 2015, Donald Trump, American politics from 2015 to 2020, when Joe Biden won, was about
[00:36:22.040 --> 00:36:22.520]   Donald Trump.
[00:36:22.520 --> 00:36:27.260]   Then from 2020 to 2024, when Joe Biden was president, it was about Donald Trump.
[00:36:27.260 --> 00:36:30.520]   And then from 2024 on, it's about Donald Trump.
[00:36:30.520 --> 00:36:32.660]   Joe Biden was an intentional void.
[00:36:32.660 --> 00:36:40.460]   Be it his age, be it their strategy, they agreed that the topic of the nation should be Donald Trump, right?
[00:36:40.460 --> 00:36:45.540]   When he went back to begin his campaign in 2024, he goes to Valley Forge and gives a speech about
[00:36:45.540 --> 00:36:47.260]   January 6th and Donald Trump, right?
[00:36:47.260 --> 00:36:48.520]   It wasn't about his own achievements.
[00:36:48.520 --> 00:36:49.900]   It was about Donald Trump.
[00:36:49.900 --> 00:36:52.600]   Joe Biden didn't do the Super Bowl interview, right?
[00:36:52.600 --> 00:36:53.360]   In 2023.
[00:36:53.360 --> 00:36:55.800]   That's when I did my thing about, this is not going to work.
[00:36:55.800 --> 00:37:01.740]   Like, probably because at that point he was not capable of good extemporaneous, you know,
[00:37:01.820 --> 00:37:02.180]   interviews.
[00:37:02.180 --> 00:37:04.580]   I mean, I think that was my view of them, right?
[00:37:04.580 --> 00:37:07.940]   That the revealed thing here was that they didn't trust him to do interviews.
[00:37:07.940 --> 00:37:10.000]   I didn't have some inside information about anything.
[00:37:10.000 --> 00:37:12.420]   I just looked at what they were doing, what they weren't doing.
[00:37:12.420 --> 00:37:13.360]   They're behind in the polls.
[00:37:13.360 --> 00:37:15.120]   They weren't doing things like the Super Bowl interview.
[00:37:15.120 --> 00:37:19.980]   If you can't turn your candidate into the product, if you don't trust your candidate to
[00:37:19.980 --> 00:37:22.720]   be the product, in an election, you're fucked, right?
[00:37:22.720 --> 00:37:24.840]   And so that was, that was to me, the tell.
[00:37:24.840 --> 00:37:27.600]   But attention is the coin of the realm.
[00:37:27.600 --> 00:37:30.140]   Now, there are better and worse ways of doing it.
[00:37:30.140 --> 00:37:32.840]   I don't think Donald Trump is doing himself huge favors right now.
[00:37:32.840 --> 00:37:36.680]   I think they had, there was a path they could have walked to be a majority party.
[00:37:36.680 --> 00:37:41.720]   I think that if he was more restrained, more inhibited, if he was able to not do a bunch
[00:37:41.720 --> 00:37:46.180]   of things that are mobilizing opposition to him, you know, you could talk about what they
[00:37:46.180 --> 00:37:47.560]   would or wouldn't achieve that way.
[00:37:47.560 --> 00:37:50.800]   But I think they could be in a much stronger political position that would make them stronger
[00:37:50.800 --> 00:37:51.620]   for the midterms.
[00:37:51.620 --> 00:37:52.880]   They would eventually make, you know, J.D.
[00:37:52.880 --> 00:37:54.200]   Vance stronger as a successor.
[00:37:54.200 --> 00:38:00.340]   I think they're running a very high risk strategy that has a very reasonable chance of, you know,
[00:38:00.340 --> 00:38:04.040]   if they don't make a, you know, what I would call like an autocratic breakthrough, they might,
[00:38:04.040 --> 00:38:06.180]   yeah, they might completely blow up their own movement, right?
[00:38:06.180 --> 00:38:07.600]   It's all very high risk.
[00:38:07.600 --> 00:38:12.860]   So for them, like for everybody, for everything, what makes them good at politics is also what
[00:38:12.860 --> 00:38:13.940]   makes them bad at politics.
[00:38:13.940 --> 00:38:20.020]   But for Democrats, the caution, the sort of bureaucratic culture, the fear of saying anything
[00:38:20.020 --> 00:38:24.640]   that will make anybody mad, it is optimized for a different attentional era.
[00:38:24.640 --> 00:38:27.680]   And one of the things I am watching when you were saying about leaders, one of the things
[00:38:27.680 --> 00:38:33.560]   I'm watching in the people coming up, the ones who want to run in 2028, is who seems like
[00:38:33.560 --> 00:38:37.420]   they have adapted to this era, not in the way Trump did or Vance did or Musk did.
[00:38:37.420 --> 00:38:39.500]   I think they're going to need something different.
[00:38:39.500 --> 00:38:42.720]   They fully represent the Twitter era of politics.
[00:38:42.800 --> 00:38:43.860]   I mean, Musk bought Twitter.
[00:38:43.860 --> 00:38:48.760]   They're sort of all in on what politics right now, what online politics feels like.
[00:38:48.760 --> 00:38:56.140]   I think the thing that will come next is someone who's able to synthesize both the lessons of
[00:38:56.140 --> 00:39:01.580]   it and the feeling that we all have that it's kind of sick and poisoned, right?
[00:39:01.580 --> 00:39:03.060]   That Twitter is not a good place.
[00:39:03.060 --> 00:39:04.160]   X is not a good place.
[00:39:04.160 --> 00:39:05.940]   TikTok politics is not a good place.
[00:39:05.940 --> 00:39:07.840]   That we're all being turned on each other.
[00:39:07.920 --> 00:39:12.280]   Somehow you need to be authentic and authentically angry at what we've all become in the way
[00:39:12.280 --> 00:39:16.500]   that Obama ran as a political reformer who hated the red and blue cut of America, who
[00:39:16.500 --> 00:39:19.040]   hated what political consultants and pollsters were doing to us.
[00:39:19.040 --> 00:39:21.140]   You're not going to have somebody who just echoes.
[00:39:21.140 --> 00:39:23.800]   There's not going to be, there'll be no Joe Rogan of the left.
[00:39:23.800 --> 00:39:26.840]   There'll be no Donald Trump of the left because the left is different than the right.
[00:39:26.840 --> 00:39:32.320]   But it will have to be something authentically of this era, but also authentic to the backlash
[00:39:32.320 --> 00:39:36.320]   to it, which I think as we enter into this period where the president and everybody
[00:39:36.320 --> 00:39:42.200]   around him fully embraces this attentional economy, I think people are going to want something
[00:39:42.200 --> 00:39:44.940]   different from this attentional economy in four years.
[00:39:44.940 --> 00:39:48.740]   And be okay with a negative attention that comes with being authentic.
[00:39:48.740 --> 00:39:50.780]   You're going to have to have some of it, right?
[00:39:50.780 --> 00:39:53.140]   You cannot change American politics.
[00:39:53.140 --> 00:39:57.860]   You can't change the Democratic Party if you're not willing to upset people.
[00:39:57.860 --> 00:40:01.560]   Donald Trump reformed the Republican Party by willing and able to fight Republicans.
[00:40:02.020 --> 00:40:06.940]   He ran against George W. Bush, against Jeb Bush, against Mitt Romney, against the trade
[00:40:06.940 --> 00:40:11.200]   deals, against a bunch of things that were understood to be sacred cows.
[00:40:11.200 --> 00:40:16.140]   Somehow this guy ran like right after Mitt Romney and John McCain while attacking Mitt Romney
[00:40:16.140 --> 00:40:17.500]   and John McCain, right?
[00:40:17.500 --> 00:40:21.540]   If you are not like the Democratic Party does need to change, it needs to attain a different
[00:40:21.540 --> 00:40:23.640]   form because the Obama coalition is exhausted.
[00:40:23.640 --> 00:40:24.240]   It's done.
[00:40:24.640 --> 00:40:27.300]   It's not going to be able to do that if it doesn't have standard bears who are willing
[00:40:27.300 --> 00:40:29.580]   to say, we were wrong about some things.
[00:40:29.580 --> 00:40:31.800]   We have to change our views on some things.
[00:40:31.800 --> 00:40:33.680]   We have to act differently and speak differently.
[00:40:33.680 --> 00:40:44.800]   Is there a degree to which the left uniquely attacks its own more intensely than maybe other
[00:40:44.800 --> 00:40:45.960]   parts of the political spectrum?
[00:40:46.620 --> 00:40:47.440]   It's possible.
[00:40:47.440 --> 00:40:51.760]   You know, you go back to the model that I gave you of 2015, where there used to be these
[00:40:51.760 --> 00:40:56.340]   four large parties, MAGA, center-right, center-left, and left.
[00:40:56.340 --> 00:40:58.540]   Right now, the Republican Party is all MAGA.
[00:40:58.540 --> 00:41:01.060]   So there is no coalitional fight to be had.
[00:41:01.060 --> 00:41:02.220]   It's all Donald Trump.
[00:41:02.220 --> 00:41:08.600]   And if Donald Trump wants to name a former left-wing environmentalist to be the HHS secretary,
[00:41:08.600 --> 00:41:10.980]   everyone says, OK, that sounds like a fantastic idea.
[00:41:10.980 --> 00:41:12.480]   That's exactly who we were going to nominate to.
[00:41:12.480 --> 00:41:13.040]   Thank you, Donald.
[00:41:13.040 --> 00:41:13.520]   That's wonderful.
[00:41:13.860 --> 00:41:22.020]   Tip of my tongue, on the Democratic side, there is a fight and it's happening right now.
[00:41:22.020 --> 00:41:30.760]   And our book is trying to win a certain intra-left coalitional fight about defining the future
[00:41:30.760 --> 00:41:32.020]   of liberalism, the Democratic Party.
[00:41:32.020 --> 00:41:34.460]   So I'm not of the left.
[00:41:34.460 --> 00:41:35.940]   I'm certainly not of the far left.
[00:41:35.940 --> 00:41:42.900]   I have center-left politics and maybe even like a center-left personality style, if we can
[00:41:42.900 --> 00:41:43.620]   even call it that.
[00:41:43.620 --> 00:41:49.580]   But I do not begrudge the left for fighting because there's a fight to be had.
[00:41:49.580 --> 00:41:54.040]   In many ways, I think sometimes they see—I'm not endorsing this.
[00:41:54.040 --> 00:41:55.100]   I'm describing it.
[00:41:55.100 --> 00:42:03.900]   I think they see their near-term opposition as not always the Republican Party, but as the
[00:42:03.900 --> 00:42:09.400]   forces of the Democratic Party that are in the way for them controlling one of the two major
[00:42:09.400 --> 00:42:10.780]   parties in this country.
[00:42:10.780 --> 00:42:15.040]   And so they do have an oppositional style, and maybe that's personality-based.
[00:42:15.040 --> 00:42:16.720]   They are fighting the center-left.
[00:42:16.720 --> 00:42:18.760]   They are criticizing the center-left consistently.
[00:42:18.760 --> 00:42:23.860]   But I want to be good faith about this, even though I don't share their politics, and say
[00:42:23.860 --> 00:42:28.760]   that they're doing it because they're trying to win power on the left of center.
[00:42:29.140 --> 00:42:31.620]   And so that's why they're criticizing the way they are.
[00:42:31.620 --> 00:42:39.780]   Now, our book and much of my writing is an attempt to do a little bit of a very specific
[00:42:39.780 --> 00:42:40.220]   dance.
[00:42:40.220 --> 00:42:42.300]   Ezra touched on this, I think, really beautifully.
[00:42:42.300 --> 00:42:47.880]   We're in an era right now of anti-institution politics, anti-establishment politics.
[00:42:48.280 --> 00:42:54.420]   And Democrats are at risk right now as being seen as the party that always defends institutions,
[00:42:54.420 --> 00:42:57.640]   the party that always defends the establishment status quo.
[00:42:57.640 --> 00:43:04.720]   And that is an absolute death knell, I think, for this century's angry anti-establishment
[00:43:04.720 --> 00:43:05.200]   politics.
[00:43:05.200 --> 00:43:10.280]   So what we're trying to do is essentially say, here's a way to channel the anger that people
[00:43:10.280 --> 00:43:12.920]   have at the establishment, but toward our own ends, right?
[00:43:12.960 --> 00:43:18.700]   We believe that we have answers on housing and energy and high-quality governance and science
[00:43:18.700 --> 00:43:25.460]   and technology, really good answers that are fiercely critical of the status quo in Democrat-led
[00:43:25.460 --> 00:43:26.920]   cities and Democrat-led states.
[00:43:26.920 --> 00:43:33.500]   We're trying to be oppositional in a way that's constructive rather than just destructive.
[00:43:33.500 --> 00:43:38.700]   Just to put a nice pretty bow tie on the whole thing, let me ask for advice.
[00:43:41.500 --> 00:43:47.340]   What do I need to do for AOC to do a three-hour interview with you, Ezra, from your throne
[00:43:47.340 --> 00:43:47.860]   of wisdom?
[00:43:47.860 --> 00:43:52.060]   I don't think I know how you get AOC herself to do it.
[00:43:52.060 --> 00:43:59.380]   I would not pretend to know her offices or her particular views on this.
[00:43:59.380 --> 00:44:06.340]   I do think, though, that you can see different Democrats taking on different kinds of risks.
[00:44:06.340 --> 00:44:09.900]   Right now, we're sort of in the age of Gavin Newsom starting a party.
[00:44:09.900 --> 00:44:13.380]   I mean, Gavin Newsom is the governor of California, and he's spending some percentage of his time
[00:44:13.380 --> 00:44:17.960]   doing a podcast with Charlie Cook and Michael Savage and Steve Bannon.
[00:44:17.960 --> 00:44:24.660]   Gavin Newsom realizes that one lane for a Democrat is to be high-risk and talking to virtually everybody.
[00:44:24.660 --> 00:44:29.580]   I think Pete Buttigieg, in a different way, is somebody who wants to take media risks.
[00:44:29.800 --> 00:44:34.220]   Now, I think he's going to—my gut on him is he's going to hold his powder a little bit.
[00:44:34.220 --> 00:44:39.260]   So he'll probably want to do the Lex Frubin podcast, assuming he runs in 2028, in 2027.
[00:44:39.260 --> 00:44:39.800]   Buttigieg.
[00:44:39.800 --> 00:44:40.420]   Buttigieg, right.
[00:44:40.420 --> 00:44:45.420]   I think a lot of them are trying to figure out what is the lane for right now.
[00:44:45.420 --> 00:44:48.820]   And there's a lane for the next two years, and there's a lane for the two years after that.
[00:44:49.520 --> 00:44:53.400]   And you're going to see a lot of people begin to blanket media in the two years after that.
[00:44:53.400 --> 00:44:54.420]   Now, it'd be interesting.
[00:44:54.420 --> 00:44:57.280]   I would be curious to know, would Hakeem Jeffries come on to your show right now?
[00:44:57.280 --> 00:44:58.220]   That'd be interesting.
[00:44:58.220 --> 00:44:59.600]   I mean, would he do it for four hours?
[00:44:59.600 --> 00:45:00.200]   I don't know.
[00:45:00.200 --> 00:45:05.600]   The four-hour ask, the three- to four-hour ask, as somebody who also books politicians, is hard.
[00:45:05.600 --> 00:45:15.000]   I have trouble—I like to book people for 90 minutes to two hours, and I tend to get negotiated down to—I try not to go under 75 or 65.
[00:45:16.200 --> 00:45:23.100]   But even as somebody, I think, well-regarded in that world, you know, it's very, very, very hard for me to get politicians to sit for two hours.
[00:45:23.100 --> 00:45:27.520]   I don't have the sense that the three-hour ask is a big ask because of scheduling.
[00:45:27.520 --> 00:45:32.220]   I think it still is grounded in the fear of saying the wrong thing.
[00:45:32.220 --> 00:45:34.140]   I just think they're used to something else, right?
[00:45:34.140 --> 00:45:38.240]   I think that when you talk—I mean, they are scheduled by schedulers, right?
[00:45:38.240 --> 00:45:44.680]   If you talk to them yourself, if you end up having a personal relationship with Wes Moore of Maryland, and he wants to do your show,
[00:45:45.120 --> 00:45:48.500]   he will tell his scheduler, I want three to four hours to do the show.
[00:45:48.500 --> 00:45:50.740]   But the scheduler is used to a world.
[00:45:50.740 --> 00:45:54.020]   The staff is used to a world where nobody gets three to four hours for the boss.
[00:45:54.020 --> 00:45:55.540]   Reporters don't.
[00:45:55.540 --> 00:45:56.820]   Donors don't.
[00:45:56.820 --> 00:45:58.480]   Policy staffers don't.
[00:45:58.480 --> 00:46:06.100]   So then when some interview comes in and they say, hey, I want three to four hours, the answer is no, because culturally it's not done.
[00:46:06.100 --> 00:46:14.820]   You need Donald Trump himself, Pete Buttigieg himself, AOC herself, to say to their staff, no, no, no, we're making time for this.
[00:46:14.820 --> 00:46:15.180]   Right.
[00:46:15.180 --> 00:46:17.220]   Because it's not how they make time for things normally.
[00:46:17.220 --> 00:46:18.900]   I don't know how much it is fear.
[00:46:18.900 --> 00:46:22.780]   I do think they're unused to it, but I suspect a lot of it is simply booking culture.
[00:46:23.340 --> 00:46:24.800]   Like, I run into it, too.
[00:46:24.800 --> 00:46:27.140]   They're not used to saying yes to three to four hours for anything.
[00:46:27.140 --> 00:46:29.080]   It's not that they don't have it.
[00:46:29.080 --> 00:46:31.420]   They have three to four hours if their kid is having a graduation.
[00:46:31.420 --> 00:46:31.960]   Right.
[00:46:31.960 --> 00:46:33.220]   I mean, they're human beings.
[00:46:33.220 --> 00:46:34.060]   They can make time.
[00:46:34.740 --> 00:46:38.120]   But it would have to come in a way from them.
[00:46:38.120 --> 00:46:40.160]   My sense is this is part of the Rogan.
[00:46:40.160 --> 00:46:44.360]   It's very unclear because there are very differing stories on what happened in the Rogan-Harris negotiations.
[00:46:44.360 --> 00:46:47.900]   But it does seem that time was one of the sticking points.
[00:46:47.900 --> 00:46:56.900]   It's also possible that you're going to find, as you try to interview Democratic politicians, that the exact same thing that happened with tech CEOs is going to happen among Democratic politicians.
[00:46:56.900 --> 00:47:01.780]   You interviewed some tech CEOs, and then they did a great job.
[00:47:01.780 --> 00:47:04.720]   And their friends were like, you were fantastic on the Lex Friedman podcast.
[00:47:04.720 --> 00:47:08.500]   That was such a great thing that you said in, you know, minute 97.
[00:47:08.500 --> 00:47:14.780]   And then there becomes a bit of a meme that you can create really high-value moments for yourself if you appear on Lex's podcast.
[00:47:14.780 --> 00:47:19.000]   And then it becomes less risky for the next marginal CEO to say yes.
[00:47:19.000 --> 00:47:22.880]   And I think right now, what we're talking about fundamentally is not physics.
[00:47:22.880 --> 00:47:23.560]   It's culture.
[00:47:23.560 --> 00:47:24.520]   It's just norms.
[00:47:24.520 --> 00:47:31.700]   I think there's a fear of low expected value if you're a high-ranking Democratic politician and maybe you do a podcast like this.
[00:47:31.700 --> 00:47:42.180]   What if I say the wrong thing and it goes viral and my bookers and my agenda people and myself just feel terrible for the next few weeks because all we see on Blue Sky and X is just people hating.
[00:47:42.920 --> 00:47:55.040]   But if you get one interview that goes well, if you talk to Wes Moore, let's say, and there is a five-minute segment where he articulates some vision of liberalism in the 2020s that everyone says,
[00:47:55.040 --> 00:48:00.780]   my gosh, that is the best possible articulation of what the Democratic Party can stand for the next four years that I've ever heard.
[00:48:01.280 --> 00:48:05.680]   Suddenly what's happened is that appearing on the show becomes massively de-risked.
[00:48:05.680 --> 00:48:08.240]   And in fact, the risk valence entirely switches.
[00:48:08.240 --> 00:48:13.700]   We are leaving dollars on the floor by not appearing on this guy's podcast because I'm AOC.
[00:48:14.300 --> 00:48:16.000]   I'm a sensational communicator.
[00:48:16.000 --> 00:48:19.040]   If Wes Moore can do it, I can do it even better.
[00:48:19.040 --> 00:48:24.160]   And so I think to a certain extent, there's a little bit like of a riot theory phenomenon here.
[00:48:24.160 --> 00:48:27.300]   The person who throws the first stone in a riot has to be very courageous.
[00:48:27.300 --> 00:48:31.420]   The person who throws the hundredth and first stone in a riot doesn't need to be courageous at all.
[00:48:32.080 --> 00:48:43.680]   And there might be a little bit of that going on that people need to see proof of high expected value before it breaks what we're acknowledging to be a bit of a communications norm on the left.
[00:48:43.680 --> 00:48:46.520]   That's a really convincing and powerful theory.
[00:48:46.520 --> 00:48:52.820]   I think I want to push back on it because so what's what's going to happen?
[00:48:52.820 --> 00:48:56.340]   For example, this very conversation, you're both going to come off brilliant.
[00:48:56.340 --> 00:48:59.160]   Well, we're barely like 50 minutes into.
[00:48:59.160 --> 00:49:00.060]   Yeah, it's good.
[00:49:00.060 --> 00:49:01.900]   I have no more material, Lex.
[00:49:01.900 --> 00:49:03.380]   It's all straight downhill.
[00:49:03.380 --> 00:49:08.280]   But what people will get tired, they'll listen to this and they're like, well, that's Ezra.
[00:49:08.280 --> 00:49:09.680]   Like he's brilliant.
[00:49:09.680 --> 00:49:13.500]   They're going to be worried about their own candidate if AOC comes off brilliant.
[00:49:13.500 --> 00:49:17.560]   They're not going to be thinking, oh, this is a place to be brilliant.
[00:49:17.560 --> 00:49:19.920]   They're going to be like, well, that's because AOC is brilliant.
[00:49:19.920 --> 00:49:22.080]   But my candidate is not.
[00:49:22.080 --> 00:49:24.300]   It still boils down to the caution.
[00:49:24.300 --> 00:49:28.280]   I've had a lot of Republican, high profile Republican people reach out to me.
[00:49:28.280 --> 00:49:29.980]   They don't give a shit.
[00:49:29.980 --> 00:49:31.940]   They're just like, whatever, I'll come.
[00:49:31.940 --> 00:49:44.900]   People on the left, I've had two people who I respect deeply and admire express caution about the previous people I've interviewed and not wanting to come on.
[00:49:45.400 --> 00:49:46.900]   Well, that's the thing the left has to get over.
[00:49:46.900 --> 00:49:47.380]   Yeah.
[00:49:47.380 --> 00:49:49.480]   Like that's a very important cultural.
[00:49:49.480 --> 00:49:56.100]   They began to do a thing where spaces were verboten because it had platformed so-and-so.
[00:49:56.100 --> 00:49:58.480]   And I think that culture is changing.
[00:49:58.480 --> 00:50:08.020]   I think they realized that they abandoned huge, vast swaths of significant culture because they wouldn't go places.
[00:50:08.280 --> 00:50:08.940]   It's crazy.
[00:50:08.940 --> 00:50:13.660]   Like you have to – the idea that you only go where people agree with you is genuine lunacy.
[00:50:13.660 --> 00:50:15.860]   I don't want to act as your booker here.
[00:50:15.860 --> 00:50:20.640]   And, you know, 2020 candidates are what they are and they each have their own press strategy.
[00:50:20.640 --> 00:50:23.660]   But I would say, like I'm doing this myself on my show.
[00:50:24.440 --> 00:50:33.640]   Like I don't think the best people to get right now in the Democratic Party are the seven people who lead the polls.
[00:50:33.640 --> 00:50:35.580]   Like I'm looking for people who will think out loud.
[00:50:35.580 --> 00:50:37.740]   Like I just had Jake Auchincloss on.
[00:50:37.740 --> 00:50:41.380]   He's like a not that well-known House member from Massachusetts.
[00:50:41.380 --> 00:50:43.220]   I just think he's a guy who thinks out loud.
[00:50:44.800 --> 00:50:48.520]   I am booking someone else right now like that.
[00:50:48.520 --> 00:50:50.880]   I have two more people like that, frankly, who are neither of them.
[00:50:50.880 --> 00:50:54.300]   They're like – like I could get like a bigger name.
[00:50:54.300 --> 00:50:56.860]   I'm more interested in people who are thinking.
[00:50:56.860 --> 00:51:03.960]   Like one reason I think Bernie Sanders always did everything is to him, the thing he was really doing was he had something to say.
[00:51:03.960 --> 00:51:10.100]   The point of almost everything for Bernie Sanders is to be in a place where people can hear the thing he has to say.
[00:51:10.100 --> 00:51:13.000]   And a lot of politicians don't have that, right?
[00:51:13.000 --> 00:51:17.640]   The point of anything is what it does for them in the polls, what it does for them with the donors, how it repositions them.
[00:51:17.640 --> 00:51:21.580]   I'm interested right now at this moment because it's not 2028.
[00:51:21.580 --> 00:51:22.960]   It's not 2027.
[00:51:22.960 --> 00:51:25.400]   There's no Democratic primary happening right now.
[00:51:25.400 --> 00:51:29.140]   The idea that you can like pre-run the Democratic Party is stupid – or primary – is stupid.
[00:51:29.140 --> 00:51:31.840]   We don't even know what the – like we might be in World War III, right?
[00:51:31.840 --> 00:51:34.300]   We have no idea what – you know, we might have AGI.
[00:51:34.300 --> 00:51:41.680]   Like the things that the 2027 primary might be about, the kinds of scandals that might have erupted by them are totally different.
[00:51:42.200 --> 00:51:46.060]   Whereas, you know, the reason to have people on is because they are saying something.
[00:51:46.060 --> 00:51:53.200]   They're a live mind in the moment that has a perspective on this that you want to hear.
[00:51:53.200 --> 00:51:55.900]   And so I would look for that.
[00:51:55.900 --> 00:52:05.480]   And I think a lot of people who are not – you know, there are people who are trying to protect something, protect a standing in the polls, protect a sort of coalitional set of allies they currently have.
[00:52:05.600 --> 00:52:09.460]   And then there are people who are, you know, trying to just be heard.
[00:52:10.600 --> 00:52:17.140]   And again, a lot of Bernie Sanders' culture, the way he does media, is now Bernie Sanders is Bernie Sanders.
[00:52:17.140 --> 00:52:18.840]   He didn't used to be.
[00:52:18.840 --> 00:52:20.940]   He wasn't in 2015 even.
[00:52:20.940 --> 00:52:25.840]   Like when Bernie Sanders ran for president in 2015, it wasn't initially a big deal.
[00:52:25.840 --> 00:52:28.560]   It was like, oh, bummer, Elizabeth Warren didn't run for president.
[00:52:28.560 --> 00:52:30.340]   It was a feeling of most people on the left.
[00:52:30.460 --> 00:52:36.860]   And so Bernie Sanders was a guy who's been saying the same thing for decades, but in the wilderness and nobody was listening.
[00:52:36.860 --> 00:52:48.080]   And now he still has the instincts of somebody who understood that, like, the most important thing was to find a place where people were listening, where they would let you talk and even better let you talk for a while.
[00:52:48.080 --> 00:52:52.580]   I think the candidate who's going to do well in 2028 is going to have an instinct like that.
[00:52:52.580 --> 00:52:59.660]   But even right now, I think the question is – one of my big questions as I'm booking for my show is just –
[00:52:59.660 --> 00:53:11.380]   I want someone who has a perspective on this moment, who feels like they have had a thought that is about right now and who we are right now and what the story of America is right now.
[00:53:11.380 --> 00:53:13.180]   I think what's really important is what Ezra said.
[00:53:13.180 --> 00:53:14.120]   It's about having something to say.
[00:53:14.120 --> 00:53:20.840]   We wanted to talk to you and talk together about how much we wanted to talk to you because we got something to say.
[00:53:20.840 --> 00:53:24.220]   You know, we wrote a 300-page book about how much we have to say.
[00:53:24.220 --> 00:53:32.060]   We love going on podcasts and television shows and radio and then doing live events to tell people what we have to say.
[00:53:32.060 --> 00:53:39.340]   We think this idea of abundance isn't just important for redefining what the American left means.
[00:53:39.340 --> 00:53:46.400]   We think that the outcome of thinking abundantly about housing and energy and science and technology is what politics is all about.
[00:53:46.400 --> 00:53:49.520]   It's about giving people the good life, and we think this is the path toward it.
[00:53:50.360 --> 00:53:58.560]   Certainly, one thing that's profoundly motivated us is having something very concrete that we just want to get out there in the world.
[00:53:58.560 --> 00:54:07.180]   Like, my sense as a writer, as a thinker, is I want my software running on as many pieces of hardware as possible.
[00:54:07.180 --> 00:54:10.360]   I want to get my ideas out there as much as possible.
[00:54:10.500 --> 00:54:15.200]   And who gets credit for them and where the idea goes, and that's all secondary.
[00:54:15.200 --> 00:54:17.360]   I believe in ideas because they're important.
[00:54:17.360 --> 00:54:23.880]   And so I want to talk to people who have large platforms about those ideas because how else is the idea getting to the mainstream except through those large platforms?
[00:54:23.880 --> 00:54:26.940]   That's how broadcast technology works in the first place.
[00:54:26.940 --> 00:54:32.400]   So maybe one thing that you're touching on is a little bit of ideological ambiguity.
[00:54:33.400 --> 00:54:38.940]   Maybe a part of this is this sense that people don't know exactly what it is they have to say for three hours.
[00:54:38.940 --> 00:54:42.240]   All I can say for sure is that we know.
[00:54:42.240 --> 00:54:46.380]   There's also a reality, and I mean, the book is trying to enter into this reality.
[00:54:46.380 --> 00:54:49.200]   I think one thing you're saying is that people have coded you.
[00:54:49.200 --> 00:54:54.120]   And so Donald Trump is really excited to do it and maybe loving politicians or not.
[00:54:55.880 --> 00:54:59.760]   One thing that we think is that we're in a period of realignment.
[00:54:59.760 --> 00:55:07.260]   The last chapter of the book, we talk about an idea that is picked up from a historian named Gary Garstle, which is an idea of political orders.
[00:55:07.260 --> 00:55:16.860]   And political orders are periods that have a sort of structure of consensus and a structure of a zone of conflict.
[00:55:16.860 --> 00:55:20.900]   But it's more or less agreed on by the two sides, even if only tacitly.
[00:55:20.900 --> 00:55:22.800]   So you have a New Deal order.
[00:55:22.800 --> 00:55:24.740]   New Deal order is founded by FDR.
[00:55:25.480 --> 00:55:35.420]   It is entrenched when Dwight Eisenhower accepts the New Deal as part of the U.S. proving that it can treat workers better than the Soviet Union.
[00:55:35.420 --> 00:55:39.920]   So those are sort of right there, the three ingredients typically of an order.
[00:55:39.920 --> 00:55:45.740]   You have a party that starts it, an opposition party that accepts key premises, right?
[00:55:45.740 --> 00:55:48.420]   Dwight Eisenhower doesn't come in and say, we're going to roll back the whole New Deal.
[00:55:48.420 --> 00:55:52.820]   And it's often held in place by an external antagonist, in that case, the Soviet Union.
[00:55:52.820 --> 00:56:00.020]   You have then, you have in the 70s, stagflation, the Vietnam War, a series of problems that the New Deal order no longer seems able to handle.
[00:56:00.020 --> 00:56:02.780]   So you have the rise of what he calls the neoliberal order.
[00:56:02.780 --> 00:56:07.720]   And the neoliberal order is, if you're going to choose a founder, it's going to be Reagan on that one, right?
[00:56:07.720 --> 00:56:09.000]   It's much more about markets.
[00:56:09.000 --> 00:56:11.200]   It is very concerned with things like inflation.
[00:56:11.860 --> 00:56:13.880]   And it really is entrenched by Bill Clinton.
[00:56:13.880 --> 00:56:16.200]   You know, the era of big government is over.
[00:56:16.200 --> 00:56:20.200]   And partially, it's entrenched also by the fall of the Soviet Union, right?
[00:56:20.200 --> 00:56:28.840]   The fall of the Soviet Union is like this proof point that the sort of capitalists were right, that markets are the way of the future.
[00:56:28.840 --> 00:56:30.660]   Government does not know what it's doing.
[00:56:31.940 --> 00:56:34.540]   And that becomes like the governing set of assumptions.
[00:56:34.540 --> 00:56:36.740]   And so there are arguments about what the markets should be doing, right?
[00:56:36.740 --> 00:56:39.660]   You know, Obamacare is about creating sort of markets and health insurance, right?
[00:56:39.660 --> 00:56:41.520]   You can use markets for very progressive ends.
[00:56:41.520 --> 00:56:44.460]   We want to use markets for lots of progressive ends.
[00:56:44.980 --> 00:56:51.400]   But the neoliberal order basically collapses amidst a financial crisis and climate change and China.
[00:56:51.400 --> 00:57:00.220]   And those are the three things that sort of girth a little bit, but also separately we think kill it, which is the neoliberal order does not have an answer to the financial crisis.
[00:57:00.220 --> 00:57:09.580]   And it botches, in many ways, the answer to the financial crisis, puts too little demand in the economy, lets a sort of recession linger and a very slow recovery linger for too long.
[00:57:09.580 --> 00:57:12.100]   It doesn't know what to say really about climate change.
[00:57:12.200 --> 00:57:19.780]   Markets have made a lot of people rich by, you know, doing a lot of things that are very, very damaging for the environment, very damaging for the future of the human race, potentially.
[00:57:19.780 --> 00:57:21.520]   And you have the rise of China.
[00:57:21.520 --> 00:57:26.060]   And the neoliberal order said, you integrate China into the global economy.
[00:57:26.060 --> 00:57:27.620]   You bring them into the WTO.
[00:57:27.620 --> 00:57:28.760]   You trade with them.
[00:57:28.760 --> 00:57:30.720]   You help them build their industrial base.
[00:57:30.720 --> 00:57:33.280]   You help them pull their people out of poverty, which that part is good.
[00:57:33.280 --> 00:57:35.780]   And they will become more like the West.
[00:57:35.780 --> 00:57:37.620]   They will liberalize.
[00:57:37.620 --> 00:57:38.920]   They will have a free press.
[00:57:39.560 --> 00:57:44.220]   The richer we make China, the more China is going to become like us.
[00:57:44.220 --> 00:57:46.840]   And that proves totally wrong, right?
[00:57:46.840 --> 00:57:48.520]   China becomes more authoritarian over time.
[00:57:48.520 --> 00:57:51.320]   But it also sort of develops an industrial base.
[00:57:51.320 --> 00:57:56.300]   It becomes, as it does not become more like us, it becomes dangerous, you know, at least in our view, right?
[00:57:56.300 --> 00:58:03.100]   You don't want to ever have a conflict with another country who you've outsourced your key industrial base to.
[00:58:03.780 --> 00:58:05.520]   And so you have the sort of fall of that order.
[00:58:05.520 --> 00:58:12.600]   And then, again, here, things that would have been ridiculous at one point in American politics had become possible.
[00:58:12.600 --> 00:58:14.580]   Bernie Sanders is one of them, right?
[00:58:14.580 --> 00:58:22.080]   The idea that you would have somebody, a self-described socialist, running for president and coming anywhere near the Democratic nomination, that was unthinkable in 2004.
[00:58:22.080 --> 00:58:24.320]   And by 2016, it almost happened.
[00:58:24.320 --> 00:58:25.460]   And Donald Trump is another thing.
[00:58:25.460 --> 00:58:31.740]   Donald Trump runs, like, headlong into the failures of neoliberalism in the Republican Party.
[00:58:31.740 --> 00:58:33.360]   He runs against trade.
[00:58:33.360 --> 00:58:36.500]   He runs against a sort of Paul Ryan, more open to immigration.
[00:58:36.500 --> 00:58:41.100]   George W. Bush and John McCain were both very big on liberalizing immigration policy.
[00:58:42.060 --> 00:58:46.300]   He runs against the Iraq War and, you know, sort of foreign adventurism.
[00:58:46.300 --> 00:58:52.440]   And there's a sort of isolationist instinct that coexists very awkwardly now within a territorial expansionist instinct.
[00:58:52.440 --> 00:58:55.240]   But at least in 2016, it was more isolationist.
[00:58:55.240 --> 00:59:10.560]   And so Donald Trump and his sort of reimagining of the Republican Party as a right wing populist, more like sort of some Christian Democratic parties in other countries, you know, up in that quadrant of socially conservative, economically populist.
[00:59:11.060 --> 00:59:12.860]   That becomes something that's possible.
[00:59:12.860 --> 00:59:17.040]   But nothing has found an equilibrium, right?
[00:59:17.040 --> 00:59:19.620]   Nobody's agreed to the other side's premises.
[00:59:19.620 --> 00:59:21.520]   There are certain ones that people are agreeing on.
[00:59:21.520 --> 00:59:25.760]   Both the Republican and Democratic parties have a very different view on China now, right?
[00:59:25.760 --> 00:59:30.060]   Like Biden kept a lot of Trump's policies on China and actually strengthened them.
[00:59:30.060 --> 00:59:32.620]   And now Trump is building on that aggressively again.
[00:59:32.620 --> 00:59:38.240]   But in terms of the other things, there isn't agreement about what the next period in American politics should look like.
[00:59:38.240 --> 00:59:40.560]   And that's one reason I think it's very dangerous.
[00:59:40.560 --> 00:59:48.340]   Both as a question of media strategy, but also as a question of politics to code people, places, platforms too tightly.
[00:59:48.340 --> 00:59:51.300]   Republicans and Democrats aren't going to get along in Congress.
[00:59:51.300 --> 00:59:53.680]   That has to do with, I think, the incentives of Congress.
[00:59:53.680 --> 00:59:55.580]   My first book is called Why We're Polarized.
[00:59:55.740 --> 00:59:58.880]   It's about those almost hydraulic incentives for partisanship.
[00:59:58.880 --> 01:00:13.280]   But in terms of what is the meaning of my podcast, of Derek's, of yours, of Joe Rogan, of Theo Vaughn, of Call Her Daddy, of a million different places that are not well-coded.
[01:00:14.840 --> 01:00:16.420]   That's, I think, very up for grabs.
[01:00:16.420 --> 01:00:19.100]   I mean, Elon Musk was an Obama-era liberal in 2012.
[01:00:19.100 --> 01:00:23.720]   I mean, I think his personal process of radicalization is not going to unwind itself.
[01:00:23.720 --> 01:00:27.340]   But a lot of the people who Democrats are like, all these billionaires are right-wing now.
[01:00:27.340 --> 01:00:29.420]   No, people are just uncertain.
[01:00:29.420 --> 01:00:32.160]   I mean, some of them are a little bit afraid, but people are uncertain.
[01:00:32.160 --> 01:00:33.500]   They're moving back and forth.
[01:00:33.500 --> 01:00:36.280]   The sort of texture of it is unsettled.
[01:00:37.160 --> 01:00:38.940]   And it's going to take time.
[01:00:38.940 --> 01:00:42.540]   These transitionary periods, I mean, they can go very badly, too.
[01:00:42.540 --> 01:00:44.500]   But they take time.
[01:00:44.500 --> 01:00:59.860]   And I think people who are clinging to old certainties about what tells you which side folks are on, my sense is a lot of people who are very open to MAGA in 2025 are going to feel very differently about it in 2028, depending on how they do, right?
[01:00:59.860 --> 01:01:01.840]   If they do great, then they're going to entrench.
[01:01:01.840 --> 01:01:06.840]   But if they don't, then a lot of people who became MAGA-curious are not going to be MAGA-curious anymore.
[01:01:06.840 --> 01:01:10.280]   But they're not going to want the last Democratic Party either.
[01:01:10.280 --> 01:01:19.660]   I was making this point to someone the other day about why the Democratic Party's embrace of the Liz Cheney-style independent didn't work.
[01:01:19.660 --> 01:01:23.120]   Liz Cheney, of course, being Dick Cheney's daughter, a Republican.
[01:01:23.120 --> 01:01:30.380]   But what Liz Cheney, the never-Trumpers, were, were a way of reaching out to who the Democratic Party thought the independents were.
[01:01:30.380 --> 01:01:37.420]   But the key thing about an independent to a political party is not that they don't like the other party.
[01:01:37.420 --> 01:01:40.420]   It's that they're an independent because they also don't like your party.
[01:01:40.420 --> 01:01:46.660]   And so finding a bunch of people who are meant to be messengers to them about why they shouldn't like the other party, it's fine.
[01:01:47.200 --> 01:01:50.800]   But what you need to do is explain why they should like your party.
[01:01:50.800 --> 01:01:52.760]   You need to have some message.
[01:01:52.760 --> 01:01:54.380]   You need to accept some fault.
[01:01:54.380 --> 01:01:57.680]   You need to think about what it was about you that drove them away.
[01:01:57.680 --> 01:02:09.860]   One of our deep views about politics right now, and not politics, policy, the texture of the economy of the country, is that the last period in American politics, in the economy, was about demand.
[01:02:10.640 --> 01:02:13.760]   The fundamental problem coming out of the financial crisis was demand.
[01:02:13.760 --> 01:02:15.540]   We had too little demand in the economy.
[01:02:15.540 --> 01:02:22.520]   Behind that too little demand in the economy was this other thing that was building up, which was a cost-of-living crisis.
[01:02:22.520 --> 01:02:24.520]   Housing was getting super expensive.
[01:02:24.520 --> 01:02:25.620]   Health care.
[01:02:25.620 --> 01:02:30.280]   In certain ways, energy, but energy is more complicated in ways we can talk about.
[01:02:30.280 --> 01:02:31.260]   Elder care.
[01:02:31.260 --> 01:02:32.500]   Child care.
[01:02:32.500 --> 01:02:33.960]   Higher education, right?
[01:02:33.960 --> 01:02:34.480]   This is a point.
[01:02:34.560 --> 01:02:43.840]   My wife is a journalist at The Atlantic, Annie Lowry, with Derek, and she wrote this piece in 2020, early 2020, right before the pandemic, that went very viral, called the affordability crisis.
[01:02:43.840 --> 01:02:48.820]   And it sticks in my head because she's writing at a time when people were saying, the economy's great.
[01:02:48.820 --> 01:02:49.820]   Everything's great.
[01:02:49.820 --> 01:02:53.360]   Like, you looked at measures of consumer confidence in 2020, February of 2020.
[01:02:53.360 --> 01:02:54.200]   Terrific.
[01:02:54.200 --> 01:02:58.300]   She's like, so how come if the economy's so great, everybody I talk to is so upset?
[01:02:58.300 --> 01:03:05.760]   And she's like, look, like, people are making more money than ever, but it's getting eaten up and eaten up and eaten up by these things they really need.
[01:03:05.760 --> 01:03:08.880]   They keep getting more expensive, even as consumer goods get cheaper.
[01:03:08.880 --> 01:03:10.520]   Then the pandemic hits.
[01:03:10.520 --> 01:03:12.220]   The problem becomes COVID.
[01:03:12.220 --> 01:03:14.400]   But then you have inflation.
[01:03:14.400 --> 01:03:20.140]   And inflation moves the problem of the economy, the fundamental problem everybody's paying attention to.
[01:03:20.140 --> 01:03:22.960]   From the demand side, how do we get more people at work?
[01:03:22.960 --> 01:03:24.220]   How do we get them to spend more money?
[01:03:24.220 --> 01:03:25.700]   To the supply side.
[01:03:25.700 --> 01:03:27.820]   We don't have enough, right?
[01:03:27.820 --> 01:03:32.760]   We have a constriction of semiconductors, of used cars, and then eventually everything, right?
[01:03:32.760 --> 01:03:34.100]   Everything is getting more expensive.
[01:03:34.100 --> 01:03:36.920]   And we do get, I mean, we'll see what happens with tariffs.
[01:03:36.920 --> 01:03:42.080]   We do get, you know, by 2024, the rate of inflation under control.
[01:03:42.080 --> 01:03:43.420]   But prices are still much higher.
[01:03:43.420 --> 01:03:46.380]   And now people are paying real attention to prices.
[01:03:46.380 --> 01:03:53.660]   And the affordability crisis, which, again, is a cost-of-living crisis, which had been growing for a very long time, is now at crisis levels.
[01:03:53.660 --> 01:03:55.720]   And it becomes the substance of politics.
[01:03:55.720 --> 01:03:58.700]   People, you know, you had all these Democrats saying, I don't know what the problem is.
[01:03:58.700 --> 01:04:02.000]   Like, inflation has come down to whatever it was, 3% to 4% in 2024.
[01:04:02.000 --> 01:04:03.440]   And they're right about that.
[01:04:03.440 --> 01:04:05.320]   But one, the price level of everything remained high.
[01:04:05.320 --> 01:04:09.100]   But two, people were now like, the fuck is housing so expensive for?
[01:04:09.100 --> 01:04:11.160]   Like, I'm never going to be able to afford a home.
[01:04:11.160 --> 01:04:14.420]   Like, my parents went to public university debt-free.
[01:04:14.500 --> 01:04:15.760]   I could never do that.
[01:04:15.760 --> 01:04:19.120]   And what we've done is fail.
[01:04:19.120 --> 01:04:21.960]   I mean, Democrats in this case, Republicans haven't done that great on it either.
[01:04:21.960 --> 01:04:24.360]   But in blue states, Democrats have failed on cost-of-living.
[01:04:24.360 --> 01:04:33.280]   The reason California, Illinois, New York are losing hundreds of thousands of people to Florida, Texas, Arizona, Colorado, is that they've failed on cost-of-living.
[01:04:33.440 --> 01:04:35.480]   It is too expensive to live there.
[01:04:35.480 --> 01:04:37.600]   And the reason they failed at cost-of-living is supply.
[01:04:37.600 --> 01:04:39.600]   They did not make enough.
[01:04:39.600 --> 01:04:42.860]   They actually made it too hard, in many cases, to make enough of the things people needed.
[01:04:42.860 --> 01:04:45.980]   Some of those are straightforward, like we didn't let people build enough homes.
[01:04:45.980 --> 01:04:51.600]   Some of them are more like we've made it too expensive to build public infrastructure, like high-speed rail or the 2nd Avenue subway.
[01:04:51.600 --> 01:04:57.520]   Some of it has to do, I think, in the long run with innovation and the relationship between Democrats and technology.
[01:04:57.980 --> 01:05:08.320]   But one of our views is that there are other things in politics that will matter too, but we are in a period where the cost-of-living, supply, affordability, is the fundamental economic question.
[01:05:08.320 --> 01:05:11.580]   Donald Trump himself has said he won because of the price of groceries.
[01:05:11.580 --> 01:05:18.780]   He's got this very funny quote where he's like, nobody said, I don't have a Donald Trump impression, but he's like, nobody ever used the word groceries in politics before I did.
[01:05:18.780 --> 01:05:23.080]   Well, it'd be good if he then wasn't making it more expensive, but Democrats believe his weakness is cost-of-living.
[01:05:23.080 --> 01:05:26.160]   They're probably right, but they don't have a strength on it.
[01:05:27.100 --> 01:05:33.560]   And the key question our book is trying to refocus politics on is how do we make more of what we need?
[01:05:33.560 --> 01:05:39.600]   How does the government either organize itself or organize markets to create more of what we need?
[01:05:39.600 --> 01:05:46.880]   And how do we admit, as liberals, times when we've made it so the government makes it too hard to make more of what we need?
[01:05:46.880 --> 01:05:49.260]   I'll say one last thing in this pretty long answer.
[01:05:50.140 --> 01:05:58.560]   I thought one of the most important things that has come out recently is a piece in Foreign Affairs by Brian Deese, who's a former head of Joe Biden's National Economics Council.
[01:05:58.560 --> 01:06:02.240]   And Deese helped negotiate every major bill Biden passed.
[01:06:02.980 --> 01:06:10.840]   It's a very straightforward piece about what it is Democrats have not done to make it possible to build at the level of their goals.
[01:06:10.840 --> 01:06:17.460]   And he says things like, we should just remove federal funding from cities that have highly restrictive home zoning codes.
[01:06:17.460 --> 01:06:21.780]   He says we should have a goal for how much nuclear we build in the next 10 years.
[01:06:21.860 --> 01:06:24.520]   We should be trying to reach a goal of new nuclear capacity.
[01:06:24.520 --> 01:06:29.280]   It's a very, very important piece because Deese is right at the center of democratic policy.
[01:06:29.280 --> 01:06:31.960]   Instead of retrenching, he's like, OK, we didn't get there.
[01:06:31.960 --> 01:06:36.060]   What do we do now to make it possible to get to the place we promised you we can go?
[01:06:37.500 --> 01:06:43.600]   And we should say that the book you've mentioned, which I've gotten a chance to read, and I think it's incredible, highly recommend.
[01:06:43.600 --> 01:06:44.940]   It's called Abundance.
[01:06:44.940 --> 01:06:54.760]   I think of it as a kind of manifesto for what the left would represent in the coming years.
[01:06:54.760 --> 01:06:59.460]   So I think people should read it from that angle.
[01:06:59.460 --> 01:07:05.400]   And both of you have been writing about this topic sort of from different angles for a while.
[01:07:05.400 --> 01:07:15.760]   I think in 22, Derek, you wrote an article on this topic of abundance titled The Simple Plan to Solve All of America's Problems.
[01:07:15.760 --> 01:07:22.620]   And Ezra, you wrote an article in 21, Supply Side Progressivism, titled The Economic Mistake.
[01:07:23.160 --> 01:07:25.200]   The Left is Finally Confronting.
[01:07:25.200 --> 01:07:33.260]   And you've just described, laid out this more progressive perspective on supply side economics that you're presenting in abundance.
[01:07:33.260 --> 01:07:44.340]   I was wondering if you could kind of give the broad, high level explanation of this idea of supply side progressivism.
[01:07:44.340 --> 01:07:53.140]   Well, my piece about the abundance agenda, which I wrote in 2022, started with me standing outside waiting for a COVID test.
[01:07:53.140 --> 01:07:57.820]   And this was a period where two years after the pandemic started, COVID tests were still being rationed.
[01:07:57.820 --> 01:07:59.600]   And it was like 21 degrees outside.
[01:07:59.600 --> 01:08:04.620]   And I was getting very, very frustrated about the fact that still we seem to have a scarcity of COVID tests.
[01:08:04.960 --> 01:08:10.220]   And as I'm sitting outside, just, you know, freezing my ass off and just getting really mad, I'm thinking, you know, it's not just COVID tests.
[01:08:10.220 --> 01:08:10.960]   We've had scarcity.
[01:08:10.960 --> 01:08:19.900]   We also had a scarcity of COVID vaccines early on in the rollout, which created this really discombobulated scheme for distributing the early COVID vaccines.
[01:08:20.300 --> 01:08:30.060]   And then also you go earlier into March and May of 2020, and we had a shortage of PPE equipment for our doctors to remain safe as they were taking care of a pandemic.
[01:08:30.060 --> 01:08:37.320]   And I thought, you know, it's interesting that this entire experience of the pandemic has essentially been defined by this concept of scarcity.
[01:08:37.760 --> 01:08:40.640]   And as I zoomed out a little bit, I thought, you know, it's not just the pandemic.
[01:08:40.640 --> 01:08:45.700]   It's really so much the 21st century economy that's been defined by scarcity.
[01:08:45.700 --> 01:08:54.040]   Ezra beautifully described the degree to which housing unaffordability has become the economic problem of our time.
[01:08:54.280 --> 01:09:01.560]   You know, in the history of political orders, each political order is in part defined by the internal crisis.
[01:09:01.560 --> 01:09:04.980]   The Great Depression springs new neoliberalism.
[01:09:04.980 --> 01:09:08.100]   Stagflation springs neoliberalism.
[01:09:08.100 --> 01:09:12.560]   Now we're in this molten moment where we're waiting for the new political order to emerge.
[01:09:12.560 --> 01:09:19.120]   And it's going to emerge because of the lever, because of the power of housing affordability.
[01:09:19.120 --> 01:09:24.140]   You have to solve that problem if you want to solve the problem of American anger about prices.
[01:09:24.540 --> 01:09:26.100]   And part of this is just pure arithmetic.
[01:09:26.100 --> 01:09:33.520]   If you look at any family's budget, the biggest part of their budget in any given year is the part that goes to rent or mortgage.
[01:09:33.520 --> 01:09:34.920]   It's housing, housing, housing.
[01:09:34.920 --> 01:09:37.800]   And housing connects to everything else.
[01:09:37.800 --> 01:09:39.060]   It connects to innovation.
[01:09:39.060 --> 01:09:42.600]   You want cities to agglomerate, to bring smart people together.
[01:09:42.600 --> 01:09:45.060]   Housing relates to all sorts of other affordability.
[01:09:45.060 --> 01:09:53.260]   Like if you care about the cost of child care or elder care, you want to make it cheaper to house institutions, buildings that can care for children,
[01:09:53.360 --> 01:09:55.240]   which means you want to bring those rents down.
[01:09:55.240 --> 01:10:03.080]   And so I thought as I'm zooming out on this concept of scarcity in the 21st century, we have chosen to make housing scarce.
[01:10:03.080 --> 01:10:13.920]   In some of the most productive cities and states often run by Democrats, we have rules, zoning rules, historic preservation rules, permitting processes, environmental reviews,
[01:10:14.340 --> 01:10:22.820]   laws that we created that have gotten in the way of making abundant the most important material good there is, which is housing.
[01:10:23.180 --> 01:10:29.200]   And as I kept sort of working myself into a lather and getting mad about the world, I thought, you know, it's actually not just housing.
[01:10:29.200 --> 01:10:30.800]   It's clean energy, too.
[01:10:30.800 --> 01:10:46.680]   There's lots of environmentalists who are on my side and believing very fervently in climate change who've made it very difficult to site solar panels or site solar farms or to raise wind turbines or to advance geothermal or to accept nuclear power.
[01:10:46.820 --> 01:11:16.800]   We have chosen to make clean energy scarce as well.
[01:11:16.800 --> 01:11:19.860]   America's problems that puts abundance first.
[01:11:19.860 --> 01:11:23.500]   And Ezra and I have a very focused definition of abundance.
[01:11:23.500 --> 01:11:31.240]   We believe we say in the first page of the book, America needs to build and invent more of the things it needs.
[01:11:31.840 --> 01:11:34.980]   We believe we believe that we believe energy is critical.
[01:11:34.980 --> 01:11:55.240]   We talk a lot about science and technology, but we really put government effectiveness at the heart of this because one really deep vein of our book is a criticism of where liberalism has gone wrong in the last 50 years, where liberalism has gone from in the New Deal era, a politics of building things.
[01:11:55.240 --> 01:12:04.560]   I mean, FDR and the progressives transformed the physical world, not just with infrastructure projects, but with building roads, the highway system under Dwight Eisenhower.
[01:12:04.560 --> 01:12:09.420]   We change the physical world during the decades, the 1930s to the 1950s.
[01:12:09.480 --> 01:12:16.660]   But in the last half century, liberalism has become very good at the politics of blocking rather than the politics of building.
[01:12:17.040 --> 01:12:30.760]   And if you look at the way that liberals define success in the last few decades, it's often about success defined by how much money you can spend rather than how much money, rather than how many things you can actually build.
[01:12:31.000 --> 01:12:41.220]   I mean, you look at the fact that, for example, in the book, we have so many examples that California authorizes more than $30 billion to build a high-speed rail system, which basically doesn't exist.
[01:12:41.220 --> 01:12:48.940]   I mean, just last week, the mayor of Chicago bragged that they spent $11 billion building 10,000 affordable housing units.
[01:12:48.940 --> 01:12:52.640]   That's $1.1 million per affordable housing unit.
[01:12:52.640 --> 01:12:53.900]   That's absolutely pathetic.
[01:12:54.380 --> 01:13:00.360]   We have a story in the book about a $1.7 million public toilet built in San Francisco.
[01:13:00.360 --> 01:13:10.160]   $1.7 million for a toilet because of all of the rules that get in the way and raise the price of building public infrastructure like public bathrooms in San Francisco and California.
[01:13:10.160 --> 01:13:22.460]   So liberalism, I'm worried, over the last 50 years has become so good at the politics of blocking and the politics of associating the money authorized as success rather than what you build in the physical world,
[01:13:22.660 --> 01:13:28.700]   that we've lost sense of material abundance, of how important outcomes are and not just processes.
[01:13:28.700 --> 01:13:36.820]   And so this is a book that's trying to nudge the Democratic Party back to what we think are, in a way, historically its roots,
[01:13:36.820 --> 01:13:43.400]   thinking about what Americans need and making it easier for government to act efficiently to provide them.
[01:13:43.400 --> 01:13:46.440]   And that really does, I think, begin with housing and energy.
[01:13:47.780 --> 01:14:08.360]   Is there a tension between kind of the left, the progressive wealth redistribution kind of ideas with the idea of building that's primarily sort of getting out of the way and letting the market get the job done?
[01:14:08.600 --> 01:14:09.920]   Let's say two things on that.
[01:14:09.920 --> 01:14:18.160]   So one, we think there is a real tension between equality, redistribution, and constricting the supply of specifically housing.
[01:14:18.160 --> 01:14:21.740]   So housing, by the way, I would love to understand this.
[01:14:21.740 --> 01:14:23.980]   That's the big problem of our era.
[01:14:23.980 --> 01:14:28.360]   Housing and energy, I think, are the two most significant that we focus on in the book, right?
[01:14:28.360 --> 01:14:29.260]   Housing and clean energy.
[01:14:29.360 --> 01:14:30.000]   We don't have enough housing.
[01:14:30.000 --> 01:14:30.860]   We don't have enough clean energy.
[01:14:30.860 --> 01:14:32.900]   I would add things to that.
[01:14:32.900 --> 01:14:34.620]   Public infrastructure.
[01:14:34.620 --> 01:14:39.840]   We don't really focus that much on education, but we could, and we could talk about that.
[01:14:39.840 --> 01:14:43.740]   Immigration is probably there for me, too, and we talk about that a little bit in the book.
[01:14:43.740 --> 01:14:46.960]   And we do talk a lot about how to pull innovation forward from the future.
[01:14:46.960 --> 01:14:53.040]   But when you ask about sort of redistribution, I really think this is an important point because there's a great new paper by David Schleicher,
[01:14:53.040 --> 01:14:56.100]   and I'm so sorry because I'm forgetting his co-author, their law professor.
[01:14:56.100 --> 01:15:03.400]   So when they talk about the victory of gentry law, we used to have a law that was very dynamic when it came to property and land.
[01:15:03.400 --> 01:15:05.120]   It was very different than how things were in Britain.
[01:15:05.120 --> 01:15:11.580]   And over time, you know, sort of back half of the 20th century, we moved American law to be much more for what they call the gentry.
[01:15:11.580 --> 01:15:15.880]   We moved it much more towards protecting those who currently have things, right?
[01:15:15.880 --> 01:15:22.700]   And we do that through a million things, covenants and HOAs and all these sort of contracts who make people enter into so they can't even build on their own land.
[01:15:22.700 --> 01:15:33.580]   But one of the things that just happens when you constrict the supply of housing is that people who got in when the getting was good, you know, I mean, it's a classic story in New York and L.A. and in SF.
[01:15:33.580 --> 01:15:43.540]   You know, you bought a place in 1977 for $220,000, and now it's worth $2.7 million, and maybe you'll pass it on to your kids or you'll sell it.
[01:15:43.660 --> 01:15:46.940]   But the working-class families can't afford to live there anymore, right?
[01:15:46.940 --> 01:15:49.120]   So that's not even a question of redistribution.
[01:15:49.120 --> 01:15:55.780]   Sometimes what you need in order to create the possibilities for opportunity and mobility is enough supply of the thing.
[01:15:55.780 --> 01:16:00.360]   At the same time, we don't think, like, that redistribution is the problem here.
[01:16:00.360 --> 01:16:01.200]   I'm pro-redistribution.
[01:16:01.200 --> 01:16:03.200]   I'm pro-more redistribution than we currently do.
[01:16:03.560 --> 01:16:10.940]   But to give one example of the way these can be great days that go together, Derek tells in the book at some great length the story of Operation Warp Speed.
[01:16:10.940 --> 01:16:21.260]   And here you have, in the mRNA vaccines, technology that was critically funded by public money, specifically DARPA, at different points.
[01:16:22.560 --> 01:16:32.120]   They've hastened, you know, after COVID, government through Operation Warp Speed under Donald Trump, you know, really tried to clear out regulatory cruft, move these things really fast.
[01:16:32.120 --> 01:16:40.400]   But the demand on the side of the public for having funded so much of this or having made so much possible was that when these vaccines hit, they were going to be free.
[01:16:40.400 --> 01:16:43.640]   Maybe the most important medical advance of that entire era.
[01:16:43.880 --> 01:16:50.000]   And it wasn't going to be like Ozempic, say, where it's, you know, $15,000 for a year of doses, right?
[01:16:50.000 --> 01:16:52.580]   It wasn't going to be only available to the richest people at the beginning.
[01:16:52.580 --> 01:16:58.080]   We were going to try to give it to everybody, sorted by need, to the best that we could, and it would be free.
[01:16:58.080 --> 01:17:00.400]   Now, you're not going to do that with everything, right?
[01:17:00.400 --> 01:17:05.220]   There are places for the price signal to actually function and where it can function to then bring on more supply later.
[01:17:05.220 --> 01:17:07.700]   And, you know, there's all the econ 101 stuff that we all know.
[01:17:08.700 --> 01:17:14.380]   But there are a lot of places where redistribution and supply increases go hand in hand.
[01:17:14.380 --> 01:17:20.340]   Another good example, I've done over the course of my career a huge amount of work on health insurance reform and universal health care.
[01:17:20.340 --> 01:17:34.080]   And let's say you got, you know, Bernie Sanders had become president in 2016 and had swept in a huge Democratic majority, and they passed Bernie's single-payer-for-all plan, which was, by the way, much more expansive than any existing single-payer plan in the world, right?
[01:17:34.080 --> 01:17:37.020]   It covered much more than Canada's or the UK's or anybody else.
[01:17:37.540 --> 01:17:44.000]   If you had done that, what you would have needed immediately was a huge supply increase in health care because you would have had a huge demand increase.
[01:17:44.000 --> 01:17:45.440]   What happens if you make health care-free?
[01:17:45.440 --> 01:17:46.740]   People are going to use more of it.
[01:17:46.740 --> 01:17:50.100]   If you make insurance much more widespread, people are going to go to the doctor more often.
[01:17:50.100 --> 01:17:55.280]   Well, if you don't have enough doctors, you don't have enough nurses, you don't have enough surgeons, you need more.
[01:17:55.280 --> 01:18:06.560]   We constrict the supply of all those things using residency rules, using, you know, nursing rules, immigration rules, who can practice as a nurse practitioner, what can a nurse practitioner actually do?
[01:18:06.600 --> 01:18:11.000]   So you have to be attentive to the supply side, even if what you're doing is aggressive redistribution.
[01:18:11.000 --> 01:18:13.320]   Now, there are places where these things don't conflict.
[01:18:13.320 --> 01:18:19.620]   Like, I'd like to see a much expanded child tax credit, and I don't think that has a big supply side implication one way or the other.
[01:18:20.060 --> 01:18:32.660]   But on a lot of things we're talking about, even if what you want to do, and it is often what we want to do, to do more redistribution, if you're redistributing some kind of thing that gives you access to a good or a service, you need to expand the good or the service.
[01:18:32.660 --> 01:18:34.240]   We do rental vouchers.
[01:18:34.240 --> 01:18:47.320]   Giving people rental vouchers in the San Francisco housing market, unless you build more housing, just creates something that our friends at the Niskanen Center call cost-disease socialism, where you are increasing demand for good at which you've constricted supply.
[01:18:47.320 --> 01:18:49.320]   If you do that, you're just going to drive the price up.
[01:18:49.540 --> 01:18:52.420]   To some degree, that's at least part of the story of higher education.
[01:18:52.420 --> 01:18:54.060]   We give people Pell grants.
[01:18:54.060 --> 01:18:56.240]   We give people all kinds of subsidies for higher ed.
[01:18:56.240 --> 01:19:03.080]   But we have not done nearly enough to increase supply or regulate the way in which college is just in pocket part of that money.
[01:19:03.080 --> 01:19:09.320]   And so they're building these fancy gyms, and they're competing with each other, but they're not actually increasing the supply of slots.
[01:19:09.320 --> 01:19:11.660]   It's certainly not the level we want them to.
[01:19:11.660 --> 01:19:15.780]   So there's a lot here where I think it scrambles traditional categories.
[01:19:16.600 --> 01:19:26.260]   You cannot do effective redistribution in ways that we would like to see them done, and many people on the left would like to see them done, if you're not taking supply of the thing that you're subsidizing seriously.
[01:19:26.260 --> 01:19:38.040]   If you think about it from a first principle standpoint, what if what you wanted to do was to bring American poverty as close to 0.0% as you possibly could?
[01:19:38.040 --> 01:19:40.400]   You got a bunch of smart people into a room.
[01:19:40.400 --> 01:19:41.920]   You said, what can we possibly do?
[01:19:43.280 --> 01:19:53.000]   In my opinion, the answer would include a lot of what are sometimes called demand-side policies, a lot of redistribution of income.
[01:19:53.000 --> 01:19:56.160]   The child tax credit, I think, would be essential.
[01:19:56.160 --> 01:19:59.240]   Expanding the earned income tax credit would be essential.
[01:19:59.240 --> 01:20:02.700]   Expanding cash welfare might be essential.
[01:20:03.400 --> 01:20:07.920]   Certainly redistributing income from the rich to the poor would be essential.
[01:20:07.920 --> 01:20:10.320]   These are demand-side policies.
[01:20:10.320 --> 01:20:12.000]   They're tax and spending policies.
[01:20:12.000 --> 01:20:18.480]   But if you only approach this subject through the demand-side, you will utterly and categorically fail.
[01:20:18.480 --> 01:20:22.880]   Because like we said, housing is the biggest part of a typical family's budget.
[01:20:23.300 --> 01:20:32.500]   And if your only policy on housing is to increase housing vouchers without increasing the supply of housing, macroeconomically speaking, there's only one direction for housing prices to go.
[01:20:32.500 --> 01:20:33.660]   And it's straight up to the moon.
[01:20:33.660 --> 01:20:35.940]   You're not actually bringing housing prices down.
[01:20:35.940 --> 01:20:40.360]   You're just subsidizing a constricted market and therefore creating enormous inflation.
[01:20:40.760 --> 01:20:44.120]   You have to solve some of these problems on the supply side.
[01:20:44.120 --> 01:20:58.220]   And one of the conceptual scoops that Ezra and I are trying to work out for the left, for liberals in America, is to get people to ask the question, how do we solve this problem with supply?
[01:20:58.220 --> 01:20:59.920]   Housing is a crisis.
[01:20:59.920 --> 01:21:01.040]   How do we solve it with supply?
[01:21:01.040 --> 01:21:02.720]   Energy is a crisis.
[01:21:02.720 --> 01:21:04.200]   How do we solve it with supply?
[01:21:04.200 --> 01:21:09.260]   Medical innovation, scientific discovery is a massively interesting phenomenon.
[01:21:09.260 --> 01:21:12.000]   We don't even understand how it exists, really.
[01:21:12.000 --> 01:21:14.100]   Like, how do great discoveries actually happen?
[01:21:14.100 --> 01:21:17.000]   Is there a supply-side policy for that as well?
[01:21:17.000 --> 01:21:19.540]   That's the question we're asking over and over in the book.
[01:21:19.540 --> 01:21:26.640]   So at the end of the day, demand-side progressivism and what Ezra calls supply-side progressivism really are peanut butter and chocolate.
[01:21:26.640 --> 01:21:29.200]   They are two flavors that go beautifully well together.
[01:21:29.200 --> 01:21:32.880]   But here's the problem that I think your question was putting your finger on.
[01:21:32.880 --> 01:21:36.740]   I think a lot of Americans don't believe that these things work together.
[01:21:37.080 --> 01:21:45.880]   Because what they see is a liberalism that just taxes and spends and Americans don't see the benefits of that spending.
[01:21:45.880 --> 01:21:50.700]   The Biden administration authorized $42 billion to build rural broadband in America.
[01:21:50.700 --> 01:21:52.100]   Practically none of it was built.
[01:21:52.100 --> 01:21:56.420]   Authorized $7.5 billion to build EV charger stations in America.
[01:21:56.420 --> 01:21:57.860]   Practically none of it was built.
[01:21:58.000 --> 01:22:01.780]   How many tens of billions of dollars have been authorized to build high-speed rail in California?
[01:22:01.780 --> 01:22:03.300]   Practically none of it exists.
[01:22:03.300 --> 01:22:04.340]   You can't write it.
[01:22:04.340 --> 01:22:13.080]   So the problem is when the reputation of a tax and spend liberal makes contact with the fact that people don't see the results in the physical world.
[01:22:13.080 --> 01:22:14.980]   Like, where's my money going?
[01:22:15.680 --> 01:22:21.340]   I have in my head something like this idea of what I call equinox liberalism.
[01:22:21.340 --> 01:22:25.980]   Which is to say there's some forms of liberalism where it's very expensive, but you see what you're getting.
[01:22:25.980 --> 01:22:29.920]   Like, when you spend $270 to go to equinox for the month, right?
[01:22:30.160 --> 01:22:33.240]   It's a really expensive gym bill, but people who go there seem to love it.
[01:22:33.240 --> 01:22:35.260]   They're like, the equipment is always free.
[01:22:35.260 --> 01:22:36.140]   Everything is clean.
[01:22:36.140 --> 01:22:37.300]   I go into the locker room.
[01:22:37.300 --> 01:22:40.480]   There's a bunch of Kiehl's lotions to, like, put on my face after I shower.
[01:22:40.480 --> 01:22:42.540]   I am getting exactly what I'm paying for.
[01:22:42.540 --> 01:22:48.340]   Yes, I'll pay out the nose for a gym because I love seeing that money going to work.
[01:22:48.340 --> 01:22:52.020]   And in places like Sweden, Denmark, citizens seem very happy.
[01:22:52.020 --> 01:22:56.980]   They're paying much higher taxes than people are in America, but they're seeing where the money is going to work.
[01:22:57.320 --> 01:23:03.260]   The problem with a liberalism that blocks rather than builds is that people don't see the money going to work.
[01:23:03.260 --> 01:23:08.100]   All they see are the dollar signs being spent by government, and then they walk out of their house,
[01:23:08.100 --> 01:23:13.080]   and they see collapsing infrastructure, and they see crime, and they see housing prices going to the moon.
[01:23:13.080 --> 01:23:16.740]   And so they think, wait, this social contract is broken down.
[01:23:16.740 --> 01:23:25.040]   You're asking for equinox prices, but you're giving me a shit-ass gym, and that's unfair.
[01:23:25.700 --> 01:23:30.380]   And so what we're trying to say is, I mean, in a very serious way, because I'm not trying to be flippant about gyms.
[01:23:30.380 --> 01:23:37.520]   In a very serious way, what we're trying to say is a part of this problem is that you Democrats have looked so hard at the demand side of the ledger
[01:23:37.520 --> 01:23:41.120]   that you've forgotten how powerful the levers are on the supply side.
[01:23:41.120 --> 01:23:46.940]   And if we can just pull those levers on housing in particular, we can bring down the cost of living,
[01:23:47.080 --> 01:23:54.700]   and people might even support the tax and spend model more because they'll feel like they're participating in equinox liberalism and not its opposite.
[01:23:54.700 --> 01:23:56.780]   Can we zoom in on the housing problem?
[01:23:56.780 --> 01:24:05.880]   Can you explain the housing problem and what's the importance of housing in the quality of life,
[01:24:05.880 --> 01:24:11.500]   in the flourishing of the nation, the United States in general, and what is broken about it?
[01:24:12.080 --> 01:24:13.460]   Let's take the second part of the question first.
[01:24:13.460 --> 01:24:14.620]   What's so important about housing?
[01:24:14.620 --> 01:24:16.820]   We're talking about life.
[01:24:16.820 --> 01:24:19.960]   And even at a higher level, we're kind of talking about freedom.
[01:24:19.960 --> 01:24:22.940]   Like the freedom to live where you want to live,
[01:24:22.940 --> 01:24:27.840]   the freedom to feel like the good and achievable life is actually good and achievable.
[01:24:28.520 --> 01:24:30.760]   This is profoundly a question of housing.
[01:24:30.760 --> 01:24:37.160]   There's this great paper that was written several years ago called The Housing Theory of Everything by Bauman, Southwood,
[01:24:37.160 --> 01:24:39.040]   and I forget the other guy's name.
[01:24:39.040 --> 01:24:44.180]   But they made this really beautiful point that no matter what you care about in terms of public policy or politics,
[01:24:44.180 --> 01:24:46.180]   housing probably makes contact with it.
[01:24:46.180 --> 01:24:51.780]   If you care about innovation, innovation, as I said, it's about getting people together in a city where they can work together.
[01:24:51.780 --> 01:24:53.060]   That's about housing density.
[01:24:53.060 --> 01:24:56.840]   If you care about child care costs, that's about bringing down the cost of buildings.
[01:24:56.840 --> 01:24:58.420]   That's also about housing.
[01:24:58.420 --> 01:25:04.720]   If you care about being able to live near your friends and family, this is also profoundly a question of housing.
[01:25:04.720 --> 01:25:12.760]   So when we talk about housing over and over, we're not just talking about the four walls and roof and floor.
[01:25:12.760 --> 01:25:15.800]   We're talking about what housing means to people because housing is life.
[01:25:16.360 --> 01:25:24.100]   And right now, what we very clearly see in the data is that Americans are leaving expensive cities and states that tend to be run by Democrats,
[01:25:24.100 --> 01:25:30.080]   and they're moving to areas that are sunnier, that are cheaper, and are often more likely to be run by Republicans.
[01:25:30.120 --> 01:25:39.700]   And this is, I think, because starting in the 1960s, 1970s, you had this era of blockage points in housing.
[01:25:39.700 --> 01:25:42.100]   We started seeing zoning regulations.
[01:25:42.100 --> 01:25:44.640]   We started seeing historic preservation rules.
[01:25:44.640 --> 01:25:51.400]   We started seeing laws that made it easier for citizens to sue to stop a new development from going up.
[01:25:51.580 --> 01:25:56.440]   Essentially, new tools were invented to empower people's natural conservatism.
[01:25:56.440 --> 01:26:00.480]   You know, for hundreds of years, people might have always felt like, I kind of want my neighborhood to stay the same.
[01:26:00.480 --> 01:26:03.500]   Like, that might have been something that, like, the Neanderthals were feeling.
[01:26:03.500 --> 01:26:11.380]   But only in the last 50 years have we really outfitted human beings with a weapon to go along with their biological preference for the familiar,
[01:26:11.380 --> 01:26:16.560]   such that they can utilize it to stop the change of the physical world around them.
[01:26:16.560 --> 01:26:20.900]   And so we've seen the rise of what is commonly called nimbyism, not in my backyard,
[01:26:20.900 --> 01:26:25.900]   the rise of a movement to stop the development of new housing around where they live.
[01:26:25.900 --> 01:26:32.040]   And so what you see in the data is, according to one study that was reported on by Yoni Applebaum, my colleague at The Atlantic,
[01:26:32.440 --> 01:26:37.680]   if there's a city with a 10 percent increase in the progressive vote share,
[01:26:37.680 --> 01:26:42.180]   there's a 30 percent decline in the number of houses that are permitted.
[01:26:42.180 --> 01:26:50.000]   For some reason, it does tend to be these areas that are more populated by progressives that have more of these choke points.
[01:26:50.000 --> 01:26:57.840]   Some of this is just historical quirk, but some of it is, I think, maybe the character of a certain kind of liberal,
[01:26:58.140 --> 01:27:04.760]   maybe often an older liberal who believes that preserving the physical environment is the good,
[01:27:04.760 --> 01:27:09.400]   that the best thing you can do for the planet is to stop things from changing around you,
[01:27:09.400 --> 01:27:10.960]   stop things from being built.
[01:27:10.960 --> 01:27:17.640]   And that's an old fashioned version of environmentalism that we're trying to turn the liberals against.
[01:27:17.640 --> 01:27:24.280]   Because really, we see the challenge with climate change is not how do we get everybody to stop using electricity?
[01:27:24.280 --> 01:27:31.400]   How do we get people to stop using any power or joules or electrons that come from natural gas and oil?
[01:27:31.400 --> 01:27:35.560]   We want people to recognize that if the people want to lead modern lives,
[01:27:35.980 --> 01:27:38.160]   and they're going to continue to demand modern lives.
[01:27:38.160 --> 01:27:42.940]   And so we have to use clean energy technology to allow them to live those lives.
[01:27:42.940 --> 01:27:47.400]   That means you have to build an absolute shit ton of new clean energy,
[01:27:47.400 --> 01:27:49.940]   solar and wind and geothermal and nuclear,
[01:27:49.940 --> 01:27:52.200]   and maybe in the near future, even fusion.
[01:27:52.200 --> 01:27:57.580]   It requires an attitude of being excited about building new things
[01:27:57.580 --> 01:28:03.600]   rather than a liberalism that seeks always to block changes to the physical environment around them.
[01:28:03.960 --> 01:28:11.820]   So I think that what we're trying to do is to allow people in a way to meet processes and outcomes.
[01:28:11.820 --> 01:28:17.940]   I think liberals want housing abundance in some part of their brains,
[01:28:17.940 --> 01:28:18.720]   in some part of their hearts.
[01:28:18.720 --> 01:28:21.260]   I think they want the price of housing to go down.
[01:28:21.260 --> 01:28:28.340]   But there hasn't quite been a really clean articulation of a mindset or paradigm shifting argument
[01:28:28.340 --> 01:28:31.780]   that gets them to see how the processes that we've created
[01:28:31.780 --> 01:28:34.840]   go so dramatically against the outcomes that liberals want.
[01:28:34.840 --> 01:28:36.720]   And we're trying to say, here's a new process.
[01:28:36.720 --> 01:28:38.480]   Here's a new question you can ask yourself.
[01:28:38.480 --> 01:28:41.120]   How can we solve the housing problem on the supply side?
[01:28:41.120 --> 01:28:47.200]   And also, solving the housing problem is one of the mechanisms to lift people out of poverty.
[01:28:47.200 --> 01:28:51.180]   So there's a lot of goals that align well with liberals.
[01:28:51.180 --> 01:28:52.440]   You write about cities.
[01:28:52.440 --> 01:28:56.200]   Cities are where wealth is created, not just where it is displayed.
[01:28:56.200 --> 01:29:00.720]   They are meant to be escalators into the middle class, not penthouses for the upper class.
[01:29:00.720 --> 01:29:06.380]   So the housing problem we're talking about specifically, or most importantly, is in urban areas.
[01:29:06.380 --> 01:29:09.700]   Yeah, this is something that we spend a lot of time thinking about for the book.
[01:29:10.800 --> 01:29:13.840]   There's a lot of land in the United States.
[01:29:13.840 --> 01:29:18.480]   And sometimes you'll hear people say something like, I've heard this a lot.
[01:29:18.480 --> 01:29:25.460]   Well, not everybody can live in San Francisco or Venice in Los Angeles or, you know, Manhattan
[01:29:25.460 --> 01:29:26.760]   or Brooklyn or whatever.
[01:29:26.760 --> 01:29:29.520]   And fine, right?
[01:29:29.520 --> 01:29:30.500]   Not everybody can.
[01:29:30.500 --> 01:29:31.020]   That's true.
[01:29:31.860 --> 01:29:40.240]   But the problem is that cities are engines of opportunity and economic dynamism.
[01:29:40.240 --> 01:29:49.140]   I mean, as you know better than we do, the frontier AI labs in the U.S., basically all of them outside
[01:29:49.140 --> 01:29:52.940]   of China, exist in 50 square miles in the Bay Area.
[01:29:52.940 --> 01:29:54.480]   There's not one in New York.
[01:29:54.480 --> 01:29:56.100]   There's not one in Dallas.
[01:29:56.100 --> 01:29:57.500]   There's not one in Chicago.
[01:29:57.500 --> 01:29:58.860]   There's not one in Austin.
[01:29:58.860 --> 01:30:01.380]   There's not one anywhere but in the Bay Area.
[01:30:01.800 --> 01:30:07.420]   But the key thing is that there is huge spillover from these hyperdynamic industries, be it finance
[01:30:07.420 --> 01:30:13.120]   in New York, be it tech in San Francisco, be it culture in Los Angeles.
[01:30:13.120 --> 01:30:21.360]   You make a lot more money being a barber near Google than you do being a barber in, you know,
[01:30:21.360 --> 01:30:22.600]   rural Arkansas.
[01:30:22.600 --> 01:30:27.280]   And this is the ancient pathway to mobility.
[01:30:28.020 --> 01:30:38.880]   People who are poor and work in the service sector, they move to richer areas where the productivity is higher and thus the sort of money spreads around.
[01:30:38.880 --> 01:30:50.940]   And if you look at American mobility and opportunity over the 20th century, about a third roughly on some calculation just comes from this people moving to richer areas.
[01:30:51.500 --> 01:31:04.080]   And if you look in like the last 20-ish years, 30-ish years, you see this extremely steady process of income convergence as people move towards richer areas begin to throw itself into reverse.
[01:31:04.780 --> 01:31:08.520]   Because it used to make sense for the janitor and the lawyer to move to New York City.
[01:31:08.520 --> 01:31:20.760]   But now it only makes sense for the lawyer to and the janitor leaves because you can't support yourself and your family and live in a home and have a reasonable commute being a, you know, a janitor working in Manhattan.
[01:31:20.900 --> 01:31:24.060]   Obviously, some people do it and it's often very tough and they live very far.
[01:31:24.060 --> 01:31:26.060]   It's very hard in San Francisco.
[01:31:26.060 --> 01:31:33.240]   You can't look at cities as, well, that's just where the rich people are.
[01:31:33.240 --> 01:31:35.600]   And that's a problem that many Democrats now have.
[01:31:35.600 --> 01:31:41.380]   I mean, Michael Bloomberg famously described New York City as a luxury good and luxury goods cost luxury prices.
[01:31:42.440 --> 01:31:47.260]   I mean, that's true in the sense that New York became a luxury good, but that's a problem.
[01:31:47.260 --> 01:31:50.720]   Like, that is a terrible, prominent inversion of what the city is.
[01:31:50.720 --> 01:32:00.020]   You know, there's this famous advice, possibly apocryphally, from Horace Greeley, who's a kind of, you know, early American newspaper publisher and political candidate.
[01:32:00.020 --> 01:32:02.840]   But he says, like, go west, young man, go west, right?
[01:32:02.840 --> 01:32:05.700]   The opportunity is out in the west where the lands are open.
[01:32:05.700 --> 01:32:07.760]   It's never been true, including for him.
[01:32:07.980 --> 01:32:15.420]   That guy moved from a rural area to New York City, and that's how he became famous, and he ran a newspaper, and he ran against Ulysses S. Grant in a presidential election.
[01:32:15.420 --> 01:32:17.520]   The cities are the frontier.
[01:32:17.520 --> 01:32:21.060]   The cities have always been the frontier, not of the land, but of the economy.
[01:32:21.060 --> 01:32:23.660]   Because the frontier of the economy is where ideas are produced.
[01:32:23.660 --> 01:32:28.340]   And ideas even now, even the age of remote work, are produced in the big cities where people live together.
[01:32:28.340 --> 01:32:32.060]   And they compete with each other, and they cooperate with each other.
[01:32:32.060 --> 01:32:42.740]   And so if you gate the cities, if you make it impossible for someone making $50,000 with two kids to live in the city, then what you've done is you've actually closed the American frontier.
[01:32:42.740 --> 01:32:45.300]   You've forced them into lower productivity places.
[01:32:45.300 --> 01:32:50.020]   Their children are less likely to grow up around, you know, the sort of inventors in the cities.
[01:32:50.020 --> 01:33:03.420]   There's really amazing research from Raj Chetty and others, basically showing that kids, no matter what they are, no matter what income class they're in, they are likelier to grow up innovating and patenting in the innovations of the place around them, right?
[01:33:03.420 --> 01:33:05.960]   Smart kids don't just grow up and innovate in anything.
[01:33:05.960 --> 01:33:11.240]   You know, if they grew up in the Bay Area, they innovate in technology, as Steve Jobs did and Wozniak did, right?
[01:33:11.240 --> 01:33:12.920]   Because they just, like, lived around those people.
[01:33:13.080 --> 01:33:15.620]   And that is true in many, many, many different things.
[01:33:15.620 --> 01:33:21.260]   And so when you gate the cities, it's not—housing is almost too small of a thing for what we're talking about.
[01:33:21.260 --> 01:33:24.720]   We're talking about if you can live next to economic opportunity.
[01:33:24.720 --> 01:33:31.580]   We are talking also about if you can put the people together who will create the next era of economic opportunity.
[01:33:31.580 --> 01:33:35.940]   You know, right now, the Bay Area is still in some ways drafting off the back when it was cheap.
[01:33:35.940 --> 01:33:42.800]   A lot of the people we're talking about who have made amazing things there, they started in the Bay Area when you could afford to live there.
[01:33:42.800 --> 01:33:46.260]   It wasn't always like this, and it wasn't that long ago that it wasn't like this.
[01:33:46.260 --> 01:33:50.840]   And now, fine, you can go there if you have money or you have a great job offer from Google or Apple or whomever.
[01:33:50.840 --> 01:33:53.760]   But over time, you need the ferment.
[01:33:53.760 --> 01:33:59.520]   I have, like, a personal interest in reading memoirs and noticing if the memoir is really a housing story.
[01:33:59.520 --> 01:34:08.160]   One of the ones I like about this, Moby, the electronic musician, his first memoir, which is great, it's a memoir of a certain era in New York.
[01:34:08.160 --> 01:34:09.720]   It's a housing story.
[01:34:10.040 --> 01:34:13.380]   He was just living next to a bunch of other musicians in cheap-ass housing.
[01:34:13.380 --> 01:34:19.840]   I just read Meet Me in the Bathroom by Lizzie Goodman, a sort of oral history of the aughts rock revival in New York City.
[01:34:19.840 --> 01:34:21.220]   A housing story.
[01:34:21.220 --> 01:34:22.320]   They could afford to live here.
[01:34:22.320 --> 01:34:22.960]   Right?
[01:34:23.120 --> 01:34:27.500]   I've read a bunch of these in San Francisco, too, where people are just like, they're functionally squatting.
[01:34:27.500 --> 01:34:28.160]   Right?
[01:34:28.160 --> 01:34:35.980]   Like, the San Francisco ferment, its queerness, its openness and tolerance of new ideas.
[01:34:35.980 --> 01:34:42.180]   It's sort of like, it's home of the psychedelic counterculture that intermixed with the defense culture that created Silicon Valley.
[01:34:42.180 --> 01:34:42.380]   Right?
[01:34:42.460 --> 01:34:47.120]   You've read probably, is it Frederick Turner's, from counterculture to cyberculture.
[01:34:47.120 --> 01:34:49.060]   That was a story of cheap housing.
[01:34:49.060 --> 01:34:53.880]   You need to allow people to be around each other, to mix each other.
[01:34:53.880 --> 01:34:59.100]   If only one type of person can afford to be there, it becomes a monocultural over time.
[01:34:59.840 --> 01:35:01.720]   And so, it's not just housing.
[01:35:01.720 --> 01:35:05.700]   This is about the geography of economic innovation and opportunity.
[01:35:05.700 --> 01:35:07.120]   That's why it's so fucking important.
[01:35:07.120 --> 01:35:08.140]   Yeah.
[01:35:08.140 --> 01:35:22.240]   I mean, that's so brilliantly put, that, you know, the economic dynamism and the intellectual dynamism that makes America, I think, the greatest nation on earth, is at the core housing story.
[01:35:22.680 --> 01:35:29.560]   It's like, you have to live near the place where there is turmoil and turbulence, intellectually and economically speaking.
[01:35:29.560 --> 01:35:42.720]   And so, like, you want to be able to move there and, like, be part of that culture, part of that economy, and part of that, like, how you raise your kids and culturally, what you want them to study, what you want them to do.
[01:35:42.720 --> 01:35:42.980]   Yeah.
[01:35:42.980 --> 01:35:44.320]   That's fascinating.
[01:35:44.320 --> 01:35:47.280]   So, what, how do we solve the housing problem?
[01:35:47.280 --> 01:35:49.520]   Is it just remove as much regulation as possible?
[01:35:49.520 --> 01:35:50.620]   Like, get out of the way?
[01:35:51.020 --> 01:35:52.840]   There's certainly a lot of regulation that you want to get out of the way.
[01:35:52.840 --> 01:35:54.640]   I mean, you look at California, for example.
[01:35:54.640 --> 01:35:59.800]   You were just giving a beautiful summary of just how important it is for people to be able to move next to economic opportunity.
[01:35:59.800 --> 01:36:07.960]   If you look at the number of houses that have been permitted in the state of California, over the last 40 years, it's basically just a squiggle line down.
[01:36:07.960 --> 01:36:16.480]   The tragedy here, just to put a really fine point on it, is that the city wasn't gated by geography or by destiny.
[01:36:16.480 --> 01:36:17.700]   Or by technology.
[01:36:17.700 --> 01:36:19.220]   We know how to build apartment buildings.
[01:36:19.220 --> 01:36:19.600]   Yeah, yeah.
[01:36:19.600 --> 01:36:21.880]   Elijah Otis invented the elevator in, like, the 1850s.
[01:36:21.880 --> 01:36:23.420]   This is not exactly a breaking technology.
[01:36:23.420 --> 01:36:25.520]   We chose to do this.
[01:36:25.520 --> 01:36:27.440]   We wrote these laws.
[01:36:27.440 --> 01:36:30.300]   We, people, are filing these lawsuits.
[01:36:30.300 --> 01:36:34.780]   We, judges, are accepting these lawsuits and determining that this building can't be built.
[01:36:34.780 --> 01:36:36.860]   This is entirely self-inflicted.
[01:36:36.860 --> 01:36:42.440]   And it's why, over and over again in this book, we call it a manufactured scarcity, which is like a little bit of a funny term.
[01:36:42.440 --> 01:36:44.420]   How do you manufacture the absence of something?
[01:36:44.420 --> 01:36:48.580]   No, a manufactured scarcity means you didn't have to do this.
[01:36:48.580 --> 01:36:56.520]   This is a human-made rule whose purposeful goal was to make it harder to add to the supply of something.
[01:36:56.880 --> 01:37:04.080]   And in this case, especially since the 1960s, we have made it purposefully difficult to add housing supply.
[01:37:04.080 --> 01:37:06.340]   And the outcome just followed the process.
[01:37:06.340 --> 01:37:13.940]   You see housing supply decline, often in the richest cities and these states that are governed too often by progressives.
[01:37:14.460 --> 01:37:15.540]   How do we undo it?
[01:37:15.540 --> 01:37:19.860]   Yes, a huge part of it exists at the layer of law, right?
[01:37:19.860 --> 01:37:22.640]   California is already trying to change its laws, right?
[01:37:22.640 --> 01:37:28.680]   End single-family zoning, make it easier to add accessory dwelling units called ADUs.
[01:37:28.680 --> 01:37:30.940]   We're changing this at the level of law.
[01:37:30.940 --> 01:37:39.100]   But one thing I'm very fixated on is making sure that we also communicate to people that it has to be changed at the level of mindset
[01:37:39.100 --> 01:37:45.480]   and even at the level of political courage because here's like a model of what often happens.
[01:37:45.480 --> 01:37:51.920]   You're the mayor of some city and you want to add a housing development of, let's say, 500 units, right?
[01:37:51.920 --> 01:37:56.140]   500 apartment unit building is going to be set up by some developer.
[01:37:56.140 --> 01:38:01.260]   And there's a city council meeting to determine whether or not this apartment building is going to be built.
[01:38:02.060 --> 01:38:11.440]   Because of law subversion and because the people who tend to go to city council meetings are older and richer and homeowners,
[01:38:11.440 --> 01:38:16.840]   guess what the overwhelming volume of reaction is in those city council meetings?
[01:38:16.840 --> 01:38:21.860]   It's a lot of people who feel like they have something to lose saying you cannot put up this building.
[01:38:21.860 --> 01:38:23.240]   You cannot add these apartments.
[01:38:23.240 --> 01:38:24.860]   It's going to ruin the character of the neighborhood.
[01:38:24.860 --> 01:38:26.360]   It's going to create traffic.
[01:38:26.360 --> 01:38:30.880]   It's going to be like an eyesore because I don't like buildings that are that tall.
[01:38:30.880 --> 01:38:34.800]   Any number of excuses can come out of like the Pez dispenser of excuses.
[01:38:34.800 --> 01:38:37.240]   You take care of one, there's going to be another that comes to the surface.
[01:38:37.240 --> 01:38:40.900]   And so what often happens is that these mayors or these people sitting in the city council
[01:38:40.900 --> 01:38:44.100]   will look out into this room of 50 people saying no, no, no.
[01:38:44.100 --> 01:38:48.060]   And they'll say, I'm going to represent the feedback that I see.
[01:38:48.060 --> 01:38:52.540]   And I'm going to vote no on the addition of this housing bill, on the addition of these housing units,
[01:38:52.540 --> 01:38:54.100]   the addition of this apartment building.
[01:38:54.100 --> 01:38:59.180]   Where political courage comes into play is the ability to say, you know what?
[01:38:59.700 --> 01:39:02.340]   I want everyone here to know that I hear you.
[01:39:02.340 --> 01:39:04.840]   I'm listening to you and I represent you.
[01:39:04.840 --> 01:39:06.960]   And so I'm grateful that you showed up to the city council meeting.
[01:39:06.960 --> 01:39:13.520]   But for every one person here who says they see a benefit to adding a new apartment building,
[01:39:13.520 --> 01:39:19.520]   I know that there are 10,000 people in the city that didn't have the wealth or the knowledge
[01:39:19.520 --> 01:39:21.000]   to be here at this meeting.
[01:39:21.260 --> 01:39:25.060]   And they're going to benefit from more housing because that's going to bring down their housing
[01:39:25.060 --> 01:39:25.440]   costs.
[01:39:25.440 --> 01:39:27.540]   And I represent them as well.
[01:39:27.540 --> 01:39:33.020]   I don't just represent, you could say, the circle of care that I can see right now.
[01:39:33.020 --> 01:39:37.720]   I also represent the circle of voters that we can't see right now.
[01:39:37.720 --> 01:39:44.320]   Who are in the city or who are in the state or might even want to move to the state, but currently
[01:39:44.320 --> 01:39:47.960]   can't because housing prices are too high on account of housing supply being restricted.
[01:39:47.960 --> 01:39:54.940]   And so one thing we're trying to get liberals to have is a sense of political courage to stand
[01:39:54.940 --> 01:40:00.160]   up against this very visible nimbyism and say, we represent interests that aren't necessarily
[01:40:00.160 --> 01:40:01.820]   visible at this city council meeting.
[01:40:01.820 --> 01:40:04.840]   We represent the larger interest of housing abundance.
[01:40:05.100 --> 01:40:11.560]   So we're going to always default to saying yes, rather than default to saying no, just
[01:40:11.560 --> 01:40:13.700]   because the people who happen to come to these meetings are NIMBYs.
[01:40:13.700 --> 01:40:16.780]   I want to add a wrinkle on regulation and deregulation.
[01:40:16.780 --> 01:40:19.080]   So we were talking about coding earlier.
[01:40:19.080 --> 01:40:20.480]   Who gets coded as right wing?
[01:40:20.480 --> 01:40:21.560]   Who gets coded as left wing?
[01:40:21.560 --> 01:40:25.080]   Deregulation is a word that is highly coded as right wing.
[01:40:25.080 --> 01:40:27.120]   The right wing wants it to deregulate, right?
[01:40:27.120 --> 01:40:29.280]   They want the government to stop regulating the market.
[01:40:29.280 --> 01:40:29.900]   It's fine.
[01:40:29.900 --> 01:40:32.740]   In many cases, the government should deregulate parts of the market.
[01:40:32.740 --> 01:40:34.960]   In many cases, it should regulate parts of the market more.
[01:40:35.840 --> 01:40:41.920]   What we don't talk about enough is how much the government regulates the government and
[01:40:41.920 --> 01:40:44.160]   how badly it needs to deregulate the government.
[01:40:44.160 --> 01:40:48.480]   So I have many more left friends and they'll come to me or they'll critique me and they'll
[01:40:48.480 --> 01:40:52.840]   say, this all is fine, but what we really need in this country is public housing or it's
[01:40:52.840 --> 01:40:54.180]   been rebranded social housing.
[01:40:54.180 --> 01:40:54.860]   It's fine.
[01:40:54.860 --> 01:40:57.480]   Singapore, huge amount of social housing, right?
[01:40:57.480 --> 01:40:58.500]   They do a great job with it.
[01:40:58.500 --> 01:41:04.920]   One of the things we go into, and this book is a manifesto on some level, but something
[01:41:04.920 --> 01:41:12.140]   we really try to do is take you into the gritty, grimy, frustrating details of how policy plays
[01:41:12.140 --> 01:41:12.720]   out on the ground.
[01:41:12.720 --> 01:41:16.320]   What actually happens after a bill passes and why we get the outcomes we do.
[01:41:16.320 --> 01:41:21.160]   Because often it's like a bunch of decisions made after everybody stopped paying attention.
[01:41:21.160 --> 01:41:26.980]   So one of the things we pay some real attention to is the part of the kind of housing that people
[01:41:26.980 --> 01:41:31.260]   on the left all agree on is affordable housing through government grants, right?
[01:41:31.260 --> 01:41:34.820]   The government says, oh, we're not just going to have market rate developers coming in,
[01:41:34.820 --> 01:41:37.860]   building more luxury condos for the children of the upper class.
[01:41:37.860 --> 01:41:44.540]   We're going to build affordable housing for people who should be in this city, but otherwise
[01:41:44.540 --> 01:41:46.200]   couldn't pay enough to be here.
[01:41:46.200 --> 01:41:47.920]   California.
[01:41:47.920 --> 01:41:50.980]   I can give you two different examples, but let's look at Los Angeles.
[01:41:51.100 --> 01:41:54.700]   I'm from outside LA, and they have something, I always forget if it's measure H or measure
[01:41:54.700 --> 01:42:01.420]   HHH, but California, LA voters pass a bond measure, about a billion dollars, a little bit
[01:42:01.420 --> 01:42:03.380]   more, I think it was, to build affordable housing.
[01:42:03.380 --> 01:42:09.140]   Six years later, when I'm writing about this, they have built a couple thousand units at an
[01:42:09.140 --> 01:42:12.460]   average cost of $600,000 to $700,000 a unit.
[01:42:13.000 --> 01:42:18.160]   So it's costing more to build housing under this affordable housing bond measure, which
[01:42:18.160 --> 01:42:23.460]   they have agreed to pay for, than it is to buy a home market rate in Denver.
[01:42:23.460 --> 01:42:25.460]   Denver is a nice place to live.
[01:42:25.460 --> 01:42:26.620]   So why?
[01:42:26.620 --> 01:42:27.200]   What had happened?
[01:42:27.200 --> 01:42:33.340]   Well, it turns out that when you trigger the public money in various cities, these are city
[01:42:33.340 --> 01:42:37.340]   ordinances often, but not always, and you use these public grants and you cobble together
[01:42:37.340 --> 01:42:41.280]   the different grants you need to build an affordable housing complex, what you've done is layer
[01:42:41.280 --> 01:42:45.960]   onto yourself a huge number of rules that the market rate developers don't have to follow.
[01:42:45.960 --> 01:42:48.840]   You're either using union labor or paying prevailing wage.
[01:42:48.840 --> 01:42:51.420]   You're building to higher green building codes.
[01:42:51.420 --> 01:42:54.840]   Oftentimes, by the way, to get through the kind of planning board meetings that Derek is
[01:42:54.840 --> 01:42:57.360]   talking about, you've made a bunch of concessions on the design.
[01:42:57.360 --> 01:42:59.520]   You know, is there going to be parking in it?
[01:42:59.520 --> 01:43:01.840]   You know, security, things like that.
[01:43:01.840 --> 01:43:05.540]   You have to often agree to who's going to be in the home.
[01:43:06.060 --> 01:43:10.100]   So you're getting, you know, there's a thing in the Measure H stuff where, well, they wanted
[01:43:10.100 --> 01:43:11.680]   it to not just be the taxpayer money.
[01:43:11.680 --> 01:43:14.040]   They also wanted non-profit grants so the money would go further.
[01:43:14.040 --> 01:43:17.520]   So you're trying to get these other grants, but these grants are to house homeless veterans.
[01:43:17.520 --> 01:43:19.640]   So now to open the thing, you need to find these homeless veterans.
[01:43:19.640 --> 01:43:22.920]   You need to go through extra disability accessibility reviews.
[01:43:22.920 --> 01:43:27.020]   And of course, we all want these things to be accessible, but they already had to comply with
[01:43:27.020 --> 01:43:28.140]   the American Disability Act.
[01:43:28.140 --> 01:43:30.680]   But now you're doing another Disability Act review in the city.
[01:43:30.680 --> 01:43:34.640]   And they come in, they say, well, you know, your doors are a little bit not as wide as we
[01:43:34.640 --> 01:43:37.380]   think so you got to make all your doors three inches wider before you can open up.
[01:43:37.380 --> 01:43:39.040]   And that adds time and that adds cost.
[01:43:39.040 --> 01:43:41.260]   You have these subcontractor rules, right?
[01:43:41.260 --> 01:43:45.440]   This is now I'm using an example from San Francisco, but you had a preference initially for minority
[01:43:45.440 --> 01:43:49.520]   based subcontractors that became illegal, became small businesses.
[01:43:49.520 --> 01:43:52.740]   But that meant it had a preference against the bigger contractors who are more efficient
[01:43:52.740 --> 01:43:53.440]   at building housing.
[01:43:54.480 --> 01:44:00.440]   In order to use public money, and then very much in order to build public housing directly,
[01:44:00.440 --> 01:44:05.680]   it ends up being more expensive and slower than market rate.
[01:44:05.680 --> 01:44:07.660]   And that is a choice.
[01:44:07.660 --> 01:44:13.520]   We do not have to try to solve every problem in society through an individual housing project.
[01:44:13.520 --> 01:44:15.520]   Building affordable housing is hard enough.
[01:44:15.520 --> 01:44:17.820]   It's not impossible, but it's difficult to do.
[01:44:17.820 --> 01:44:19.200]   You do have to talk with the neighbors, right?
[01:44:19.240 --> 01:44:23.180]   It's never going to be trivial to build 500, you know, a 500 unit apartment building.
[01:44:23.180 --> 01:44:28.620]   But instead, we layer on all these external and additional agenda items.
[01:44:28.620 --> 01:44:32.060]   I call this everything bagel liberalism because, like, you know, you sprinkle just enough on
[01:44:32.060 --> 01:44:32.940]   the bagel and it's great.
[01:44:32.940 --> 01:44:36.960]   But if you saw everything everywhere all at once, you put everything on the everything bagel
[01:44:36.960 --> 01:44:39.280]   and it becomes a black hole from which nothing can escape.
[01:44:40.000 --> 01:44:42.440]   And so the need to deregulate government, right?
[01:44:42.440 --> 01:44:49.440]   Why I saw some of Elon Musk's marathon appearance on your show, and he talks about high-speed
[01:44:49.440 --> 01:44:50.060]   rail in California.
[01:44:50.060 --> 01:44:55.280]   And the thing he says there that it's functionally illegal to build high-speed rail in California.
[01:44:55.280 --> 01:44:58.060]   I got a hundred disagreements with Elon Musk right now.
[01:44:58.060 --> 01:44:58.920]   That's not one of them.
[01:44:58.920 --> 01:45:01.160]   It's functionally illegal to build high-speed rail in California.
[01:45:01.160 --> 01:45:02.040]   Like, I went out.
[01:45:02.040 --> 01:45:03.860]   I toured the high-speed rail.
[01:45:03.860 --> 01:45:05.260]   I've done a lot of reporting on that.
[01:45:05.260 --> 01:45:07.320]   You can't build it affordably.
[01:45:07.320 --> 01:45:08.620]   You just can't on time.
[01:45:08.620 --> 01:45:11.160]   Like, they have no way to get the money to build the rest of it.
[01:45:11.160 --> 01:45:12.060]   It's not going to happen.
[01:45:12.060 --> 01:45:15.020]   And it's not going to happen not because you can't build high-speed rail.
[01:45:15.020 --> 01:45:16.440]   Europe builds high-speed rail.
[01:45:16.440 --> 01:45:17.620]   Japan builds high-speed rail.
[01:45:17.620 --> 01:45:18.800]   China builds high-speed rail.
[01:45:18.800 --> 01:45:22.880]   And it's not because of the private market, like, we'll only build luxury high-speed rail.
[01:45:22.880 --> 01:45:29.080]   It's because we have so heavily regulated a public project that you can't finish it.
[01:45:29.080 --> 01:45:31.600]   And you definitely can't bring it in on time and affordably.
[01:45:31.600 --> 01:45:36.740]   And so I really would like to, like, uncode deregulation.
[01:45:37.180 --> 01:45:39.260]   Because, yeah, there's places where I would like to regulate more.
[01:45:39.260 --> 01:45:41.840]   I don't want you to be able to build a coal-fired power plant in America.
[01:45:41.840 --> 01:45:43.200]   I just don't want it to be possible.
[01:45:43.200 --> 01:45:44.040]   I think it's bad.
[01:45:44.040 --> 01:45:49.740]   But I do want it to be possible to build high-speed rail and affordable housing, including through the public market.
[01:45:49.740 --> 01:45:54.880]   And one thing my friends on the left, I think, really underrate is how hard they've made it for the government to act.
[01:45:55.340 --> 01:45:56.360]   They believe in government.
[01:45:56.360 --> 01:46:00.780]   But if you believe in government, then you have to make it possible for government to complete projects.
[01:46:00.780 --> 01:46:07.260]   You have to make it possible for the people who work for government to apply their own genius and initiative.
[01:46:07.260 --> 01:46:08.640]   They have to have agency.
[01:46:09.380 --> 01:46:16.780]   I always say that, like, we're sort of trapped right now between a party that wants government to fail and a party that won't make government work.
[01:46:16.780 --> 01:46:26.980]   And, like, we are trying to push this idea that the thing we want is a capable government, a strong government, a government that when it promises it will do something, it actually doesn't and gets it done.
[01:46:27.320 --> 01:46:33.860]   And that requires not just deregulation of the private sector, though sometimes it does require that, it requires deregulation of the government itself.
[01:46:33.860 --> 01:46:36.620]   I love this question of deregulation.
[01:46:36.620 --> 01:46:44.120]   But I also sometimes find it very frustrating because sometimes I find that people's sense of regulation is so specifically coded.
[01:46:44.120 --> 01:46:46.120]   Regulation is just rules.
[01:46:46.120 --> 01:46:53.760]   If you change the word from regulation to rules, I think it would be easier for people to see some rules are good and some rules are stupid.
[01:46:53.760 --> 01:46:55.680]   We all understand that in life.
[01:46:56.140 --> 01:46:57.320]   That's what regulations are.
[01:46:57.320 --> 01:46:57.960]   They're just rules.
[01:46:57.960 --> 01:47:03.640]   And sometimes they give us exactly the outcomes we want, and sometimes they give us the outcomes we would never hope for.
[01:47:03.640 --> 01:47:04.700]   And here's a good example.
[01:47:04.700 --> 01:47:07.860]   You go back to the 1940s, 1950s.
[01:47:07.860 --> 01:47:09.980]   America was fucking disgusting.
[01:47:09.980 --> 01:47:11.700]   Disgusting.
[01:47:11.700 --> 01:47:14.860]   The air and the water was horrifying.
[01:47:14.860 --> 01:47:23.820]   In 1943, residents of Los Angeles woke up to a smog that was so black they thought the Japanese had launched a chemical attack against America.
[01:47:24.340 --> 01:47:33.560]   In New Hampshire, in the rivers next to textile mills, sometimes the rivers themselves would run green and purple and red, depending on what textile colors were being dumped into the river.
[01:47:33.560 --> 01:47:37.600]   You had the Ohio River on fire in the 1960s, 1970s.
[01:47:37.600 --> 01:47:44.360]   The world of mid-1900s America was truly sickening, and it made people sick.
[01:47:44.360 --> 01:47:46.880]   And so we passed a raft of environmental rules.
[01:47:46.880 --> 01:47:49.360]   And some of them achieved exactly what we wanted.
[01:47:49.360 --> 01:47:54.940]   The air we breathe and the water we drink is cleaner because of the Clean Air and Water Acts.
[01:47:55.340 --> 01:47:59.080]   We did extraordinary things with this era of regulation.
[01:47:59.080 --> 01:48:08.180]   Some of these regulations were about outcomes, like the Clean Air and Water Act regulates specific pollution levels in the air and the water or the emissions coming out of tailpipes.
[01:48:08.180 --> 01:48:11.380]   Some of the regulations, though, were about process.
[01:48:11.380 --> 01:48:16.100]   NEPA is the National Environmental Protection Act, and it, among many other things,
[01:48:16.560 --> 01:48:32.660]   empowered individuals and citizens to sue the government and organizations, businesses to stop construction or fill out environmental reviews to prove that their construction wouldn't, would meat buster, wouldn't degrade the, the, the environment too severely.
[01:48:33.120 --> 01:48:41.620]   This opened the door to an infinitude of lawsuits to wrap up any effort to build anything in red tape forever.
[01:48:41.620 --> 01:48:54.940]   So fast forward to 2021, the year or sorry, the month after Newsom signs, Gavin Newsom, governor of California, signs the law to end single family zoning in California.
[01:48:54.940 --> 01:48:58.480]   Seems like a massive win for the pro-housing YIMBYs of California.
[01:48:58.480 --> 01:49:12.020]   The month after that law was passed, the Board of Supervisors in San Francisco decided to rule against an apartment building that would have added 500 total units and 100 below market rent units,
[01:49:12.020 --> 01:49:17.320]   so something like public or social housing, that was going to be built on a Nordstrom parking lot,
[01:49:17.320 --> 01:49:21.600]   just about the best possible place you could add housing in the world, a Nordstrom parking lot,
[01:49:21.600 --> 01:49:28.360]   because the builders, the developers, didn't file the appropriate paperwork under environmental review.
[01:49:28.360 --> 01:49:42.060]   So this is a world in which the most housing starved city in America is being starved even more of housing because of the expression of or the power of the instrumentalization of a rule past the 1970s
[01:49:42.060 --> 01:49:46.280]   that has allowed people to sue to stop the physical world from being changed.
[01:49:46.280 --> 01:49:54.500]   And I think it goes back to this idea that like sometimes the solutions of one era can become the problems of the next generation, right?
[01:49:54.500 --> 01:50:07.620]   It was really good to pass the set of environmental bills that we did in the 1960s and 1970s because it addressed the extremely real problem of air and water and land being degraded by industry.
[01:50:07.980 --> 01:50:13.000]   But we're in a new world, and the problem of environmentalism today is in part a problem of global warming,
[01:50:13.000 --> 01:50:16.640]   and we have to build not only dense housing but also clean energy.
[01:50:16.640 --> 01:50:27.020]   And the same rules that were designed to help the environment in the 1960s and 1970s are sometimes ironically used in a way that hurt the environment in the 2020s.
[01:50:27.100 --> 01:50:32.220]   And that's one reason why we, as liberals, need a paradigm shift.
[01:50:32.220 --> 01:50:34.980]   Okay, you said a lot of really interesting insights there.
[01:50:34.980 --> 01:50:44.300]   So one, if I understood correctly, that regulation of outcomes is more a good idea than regulation of process
[01:50:44.300 --> 01:50:50.060]   because regulation of process is where you can breed a lot of basically the lawyers show up.
[01:50:50.180 --> 01:50:54.200]   The other insight is if we get rid of 99% of lawyers, the world would be a better place.
[01:50:54.200 --> 01:50:55.460]   There's a lot of jokes around that.
[01:50:55.460 --> 01:50:55.940]   I don't know.
[01:50:55.940 --> 01:50:57.780]   I don't know if you agree, but that-
[01:50:57.780 --> 01:50:59.340]   I definitely wouldn't say 99%.
[01:50:59.340 --> 01:50:59.820]   98.
[01:50:59.820 --> 01:51:00.440]   Yeah, yeah.
[01:51:00.440 --> 01:51:02.240]   82.3 to be absolutely right.
[01:51:02.240 --> 01:51:02.940]   In the 80s.
[01:51:02.940 --> 01:51:03.140]   No.
[01:51:03.140 --> 01:51:03.280]   Okay.
[01:51:03.280 --> 01:51:04.540]   Majority of them.
[01:51:04.540 --> 01:51:04.880]   No.
[01:51:04.880 --> 01:51:09.920]   They're simply there to take advantage of the rules.
[01:51:09.920 --> 01:51:11.500]   We talk a lot about a book.
[01:51:11.500 --> 01:51:17.180]   I don't know if you've run into this one, but it's by Mansur Olson, who's sort of a founder of public interest economics.
[01:51:17.180 --> 01:51:20.020]   And it's called The Rise and Decline of Nations.
[01:51:20.020 --> 01:51:21.640]   This is like a very famous book.
[01:51:21.640 --> 01:51:22.820]   Libertarians love this book.
[01:51:22.820 --> 01:51:24.680]   And I love this book.
[01:51:24.680 --> 01:51:35.040]   It's not right about everything, but its fundamental question is how come after World War II did the completely destroyed, bombed out countries of Germany and Japan?
[01:51:35.040 --> 01:51:37.560]   You would have thought they would be just screwed.
[01:51:37.560 --> 01:51:40.000]   Instead, they both become growth miracles.
[01:51:40.000 --> 01:51:43.360]   They both do much better than the UK, which, you know, was on the winning side of the war.
[01:51:43.360 --> 01:51:43.720]   Why?
[01:51:44.140 --> 01:51:56.140]   And Olson's argument is that affluent, stable societies over long periods of time develop something that is very difficult to develop and very important to develop, which is bargaining organizations, right?
[01:51:56.140 --> 01:51:57.400]   Collective action is hard.
[01:51:57.400 --> 01:51:59.020]   It is hard to form an organization.
[01:51:59.020 --> 01:52:00.900]   It is hard to make that organization persist.
[01:52:01.260 --> 01:52:07.840]   But if you can do that in an atmosphere of stability, then over time, that organization will tend to entrench its power, right?
[01:52:07.840 --> 01:52:17.860]   Think about AARP or the Chamber of Commerce or certain unions or, you know, the National Manufacturing Council, et cetera, the Business Roundtable.
[01:52:18.600 --> 01:52:25.700]   You know, they're not that powerful when they start, but over a long period of time, they become really powerful and they start to pass laws and make themselves more powerful and so on.
[01:52:25.700 --> 01:52:36.620]   There's a lot you can say about this insight, but my favorite part of Olson's book and one that I don't think people emphasize enough is this insight he has, which is that over time, countries will begin.
[01:52:36.620 --> 01:52:39.700]   And every country has a kind of form of natural selection within it.
[01:52:39.700 --> 01:52:47.360]   And that form of natural selection will select for people with the skills to navigate, best navigate the kind of economy that country has.
[01:52:47.360 --> 01:52:54.160]   So if you're in China right now and China is in its developmentalism phase, you really want to be in civil infrastructure, right?
[01:52:54.160 --> 01:53:01.200]   It is great to be a civil engineer in China, great to be working on semiconductors in China, great to be doing all this stuff in the physical world.
[01:53:01.460 --> 01:53:12.100]   But America, you know, as a kind of price of our affluence and our success, we've become a country, and this happens for a lot of countries, where negotiation is really important.
[01:53:12.100 --> 01:53:26.740]   And a country in which negotiation is really important is going to, over time, start developing a preference for lots of lawyers, people in finance, management consultants, because it is a society that requires continuous, what he calls complex bargaining.
[01:53:27.680 --> 01:53:33.600]   And I think this actually explains all Patrick Collison, we quote him in the, who's a founder, CEO of Stripe, you know, brilliant tech guy.
[01:53:33.600 --> 01:53:41.560]   Here's his point that he made in an interview with Noah Smith, who's a blogger and economist, where they were talking about high-speed rail.
[01:53:41.560 --> 01:53:47.580]   And sort of Patrick makes this point, he's like, it's just tough to be a high-speed rail engineer in America.
[01:53:47.580 --> 01:53:51.140]   You're going to have a much easier time working in the digital space.
[01:53:51.200 --> 01:53:54.340]   And so the digital space becomes a kind of frontier of last resort.
[01:53:54.340 --> 01:54:01.100]   And so people want to build things, go into bits and bytes, not into atoms, right, to use the old kind of Peter Thiel cut.
[01:54:01.100 --> 01:54:03.260]   And I think there's something to that.
[01:54:03.260 --> 01:54:04.500]   It's not that lawyers are bad.
[01:54:04.500 --> 01:54:09.300]   Some of the people I love most in this world are lawyers, and many lawyers do amazing, amazing work.
[01:54:09.720 --> 01:54:20.140]   But one reason we've selected for so many lawyers, and America has a lot of lawyers, is we became a society that needs a lot of lawyers, because we are a society that is stable, affluent, and have become, like, very into bargaining.
[01:54:20.140 --> 01:54:22.920]   You know, Donald Trump is a real estate developer.
[01:54:22.920 --> 01:54:24.420]   That's a relational business.
[01:54:24.800 --> 01:54:34.960]   The way real estate development works in this country, the reason you don't have all that many huge firms building housing in many, many states simultaneously, is it requires a lot of relationships in the individual city you're in.
[01:54:34.960 --> 01:54:47.560]   And so, you know, if you read, say, Maggie Haberman's great biography of Donald Trump, Confidence Man, which focuses a lot on his time as a real estate magnate in New York, you see, like, Donald Trump doesn't build a ton of stuff in other states.
[01:54:47.560 --> 01:54:52.000]   He actually builds in other countries sometimes, or more to the point, he puts his name on things built in other countries.
[01:54:52.040 --> 01:54:57.640]   But really, what he did was build here, and he built here through his relationships with the New York political system.
[01:54:57.640 --> 01:55:17.660]   And so, over time, societies that make building and construction and creation something that is the output of negotiations, rather than, like, very clear standards and rules where if you've done it, you can just do it, you get a lot of lawyers, you get a lot of management consultants, you get a lot of finance people, because that's what society is selecting for.
[01:55:17.760 --> 01:55:20.800]   That's what you've made it possible to have agency and freedom in.
[01:55:20.800 --> 01:55:22.960]   That's what you need to do to do big things.
[01:55:22.960 --> 01:55:27.020]   This is coming from Nick Bagley, who's a University of Michigan law professor.
[01:55:27.020 --> 01:55:35.540]   But between Walter Mondale and Tim Walls, there's not a single person on a Democratic presidential ticket who didn't go to law school, not one.
[01:55:36.480 --> 01:55:38.520]   Like, the Democratic Party in particular is a party of lawyers.
[01:55:38.520 --> 01:55:41.120]   And lawyers look at things from the legal perspective.
[01:55:41.120 --> 01:55:45.260]   And the legal perspective is that government is legitimate by following process.
[01:55:45.260 --> 01:55:51.540]   And Bagley's point is that government attains legitimacy, at least in part, through outcomes.
[01:55:52.080 --> 01:56:01.460]   And when you prize process so high over outcomes, you think you're acting legitimately, but actually it would have made you legitimate in the view of the people, is that you built the thing you told them you were going to build.
[01:56:01.460 --> 01:56:03.580]   You made it possible to live affordably in the city.
[01:56:03.580 --> 01:56:11.340]   And so you have this sort of movement then over time to populist strongmen who say, I alone can fix it, because they've kind of given up on this procedural liberalism.
[01:56:11.340 --> 01:56:12.620]   Like, they didn't deliver for them.
[01:56:12.760 --> 01:56:16.460]   So you keep telling them, you know, we're the ones who know how to run government, and they don't see it.
[01:56:16.460 --> 01:56:21.880]   And eventually somebody else comes and says, I'm going to bust through the walls of this thing like the Kool-Aid man, and they win.
[01:56:21.880 --> 01:56:23.900]   So speaking of the Kool-Aid man.
[01:56:23.900 --> 01:56:26.660]   I see what you're about to do.
[01:56:26.660 --> 01:56:32.400]   Yeah, I'm so transparent.
[01:56:32.400 --> 01:56:36.780]   It makes me think I'm a robot built in a lab somewhere.
[01:56:36.780 --> 01:56:43.880]   Sam Altman once said to me, he said, well, aren't you just a reinforcement learning system with energy running through it?
[01:56:43.880 --> 01:56:44.140]   Yeah.
[01:56:44.140 --> 01:56:46.460]   It's like, I'd like to think not, but maybe.
[01:56:46.460 --> 01:56:59.240]   So on the Kool-Aid man, I was wondering if you could maybe steel man the case for and against Elon Musk and Doge.
[01:56:59.440 --> 01:57:06.060]   Because you mentioned all of these regulations, all of the complexities that get in the way of building.
[01:57:06.060 --> 01:57:13.520]   It seems like a bold human like Elon is required to break through the regulation.
[01:57:13.520 --> 01:57:15.580]   Put that on one side.
[01:57:15.580 --> 01:57:21.340]   And the other side, I read somewhere that abundance is kind of the anti-Doge.
[01:57:23.260 --> 01:57:29.660]   So, which to me, it seems like there is conflicting ideas, but there's also alignment.
[01:57:29.660 --> 01:57:31.560]   So maybe can we break all that?
[01:57:31.560 --> 01:57:34.100]   I think the steel man is very easy to make here.
[01:57:34.100 --> 01:57:35.860]   Department of Government Efficiency.
[01:57:35.860 --> 01:57:40.160]   That sounds like an organization that's needed if government is inefficient.
[01:57:40.160 --> 01:57:44.860]   And one of the themes of our book is just how inefficient government can be.
[01:57:44.860 --> 01:57:49.920]   Not only at building houses, building energy, often at achieving its own ends.
[01:57:50.160 --> 01:57:52.740]   Building high-speed rail when it wants to build high-speed rail.
[01:57:52.740 --> 01:57:57.060]   Adding affordable housing units when it wants to add affordable housing units.
[01:57:57.060 --> 01:58:01.620]   You know, I love Ezra's line that we don't just need to think about, you know, deregulating the market.
[01:58:01.620 --> 01:58:04.400]   We need to think about deregulating government itself.
[01:58:04.400 --> 01:58:10.740]   Getting the rules out of the way that keep government from achieving the democratic outcomes that it's trying to achieve.
[01:58:10.740 --> 01:58:16.440]   This is a world in which a Department of Government Efficiency is a godsend.
[01:58:17.160 --> 01:58:26.160]   We should be absolutely obsessed with making government work well, especially if we're going to be the kind of liberals who believe that government is important in the first place.
[01:58:26.160 --> 01:58:31.960]   So that, to me, is the sort of pillbox version of a steel case for a Department of Government Efficiency.
[01:58:31.960 --> 01:58:34.700]   Wait, before you do the anti-case, can I offer a different steel man?
[01:58:34.700 --> 01:58:35.160]   Please.
[01:58:35.160 --> 01:58:46.060]   I think the steel man case for what Doge is, right, rather than what it pretended to be, is that the government is an interest.
[01:58:46.060 --> 01:58:50.160]   The bureaucracy, the deep state, the rules, the regulations.
[01:58:50.160 --> 01:58:51.640]   And it's not about efficiency.
[01:58:51.640 --> 01:58:52.760]   Never was.
[01:58:52.760 --> 01:58:54.360]   You wouldn't do this if it was about efficiency.
[01:58:55.360 --> 01:58:56.980]   That it's zero-based budgeting.
[01:58:56.980 --> 01:58:59.560]   That you're breaking the thing.
[01:58:59.560 --> 01:59:01.840]   You're turning it on and off.
[01:59:01.840 --> 01:59:03.880]   You're firing massive parts of it.
[01:59:03.880 --> 01:59:10.040]   Because the only way to make change within it possible is to delete what currently exists.
[01:59:10.040 --> 01:59:11.360]   Whether it was efficient or not.
[01:59:11.360 --> 01:59:12.820]   You would never actually know.
[01:59:12.820 --> 01:59:16.620]   That if you had it all come and present its case for efficiency or something, you'd never know.
[01:59:17.080 --> 01:59:18.740]   You'd get turned around, whatever.
[01:59:18.740 --> 01:59:24.500]   That the only way, like, the problem with the government is there is no actual competition.
[01:59:24.500 --> 01:59:32.640]   The Department of Education doesn't get out-competed by the, you know, the Agency of Education, which has started up, you know, three years ago or something.
[01:59:32.640 --> 01:59:41.920]   And because of that, the only way to make possible radical change is to bulldoze the thing that currently exists.
[01:59:41.920 --> 01:59:45.660]   And then once that is done, you can begin to rebuild.
[01:59:46.520 --> 01:59:50.900]   You can, you know, if you've fired half of the Department of Education, then you can start rehiring your people.
[01:59:50.900 --> 01:59:52.600]   And they will actually do what you want.
[01:59:52.600 --> 01:59:58.680]   If you have shown that you can delete every regulation or just not follow it, then you can begin deciding which ones to actually follow.
[01:59:58.680 --> 02:00:05.460]   If there is no Department of USAID and you've moved it back under state, then you can tell state what really to fund in terms of foreign aid, right?
[02:00:05.460 --> 02:00:09.160]   There's a theory here, I think, that was never about efficiency.
[02:00:09.160 --> 02:00:10.760]   It was about deletion.
[02:00:10.760 --> 02:00:14.200]   He's not trying to make things run a little bit better.
[02:00:14.200 --> 02:00:16.540]   He's not trying to lower the overhead cost of government.
[02:00:16.540 --> 02:00:22.620]   That the theory is that in the first term, the bureaucracy impeded Donald Trump.
[02:00:22.620 --> 02:00:23.780]   It didn't listen to him.
[02:00:23.780 --> 02:00:26.220]   Bureaucracy is supposed to be limbs of the president.
[02:00:26.220 --> 02:00:34.500]   The only way to make the federal government a neural link of Donald Trump himself is to destroy the federal government and then rebuild it as that thing.
[02:00:34.680 --> 02:00:43.960]   I think if you talk to people at Doge or talk to people who are authors of the project of Project 2025, who are at Heritage, who are chiefs of staff of the people working for Heritage.
[02:00:44.500 --> 02:00:50.340]   If you have a truth serum conversation with these folks and you say, oh, they'll defend what's happening.
[02:00:50.340 --> 02:00:53.240]   That's not just what they're saying.
[02:00:53.240 --> 02:01:04.940]   They're saying something metastatic has grown inside of government, not just over the last few years under Joe Biden, but over the last few decades, maybe going all the way back to FDR and even Woodrow Wilson.
[02:01:05.020 --> 02:01:21.020]   We have allowed an administrative state to accumulate like barnacles on a ship around the executive branch and it's keeping the executive branch from being able to translate the democratic will into policy because there's never any president who is purely elected by the people.
[02:01:21.020 --> 02:01:25.940]   They're elected into an office that is already pre-contaminated by the bureaucracy itself.
[02:01:25.940 --> 02:01:28.560]   And we're trying to take all of that away.
[02:01:28.560 --> 02:01:43.840]   We're trying to I mean, this is this is very just explicitly the case they're going to make trying to make government more democratic, not less by allowing the democratic, the elected president guide in a lead in a pure way.
[02:01:43.840 --> 02:01:46.380]   OK, so as you said, two things.
[02:01:46.380 --> 02:01:47.320]   One is the steel man.
[02:01:47.320 --> 02:01:50.000]   And then at the end there, there was a non steel man.
[02:01:50.000 --> 02:01:57.040]   So the first part is cutting, removing as much as possible to see what's actually needed.
[02:01:57.040 --> 02:02:02.540]   This seems like one of the ways to figure out what's actually needed is by removing it.
[02:02:02.540 --> 02:02:11.820]   And then there's the second thing is that you mentioned so that you can install the people that follow your policy.
[02:02:11.820 --> 02:02:13.960]   Well, I disagree with you that that wasn't the steel man.
[02:02:13.960 --> 02:02:17.080]   I mean, I think you have to listen to them to do the steel man.
[02:02:17.080 --> 02:02:17.340]   Right.
[02:02:17.340 --> 02:02:18.640]   I don't think the steel man is imaginary.
[02:02:18.640 --> 02:02:32.860]   If you read the the OMB regulation that froze funding, it said explicitly that the government has to reflect the will of the people as expressed through their choice of president.
[02:02:33.540 --> 02:02:37.700]   If you read anything Russ Vought has ever said, they have the unitary executive theory.
[02:02:37.700 --> 02:02:38.720]   I'm not saying it's right or wrong.
[02:02:38.720 --> 02:02:42.420]   I if you ask me to do the non steel man, which I would love to do, too.
[02:02:42.420 --> 02:02:48.880]   It is not my view that the steel man case of this is to make the federal government fully responsive to Donald Trump.
[02:02:49.380 --> 02:02:52.920]   But the steel man case for what they are doing as expressed by them.
[02:02:52.920 --> 02:02:56.560]   And I think like a steel man reflects like I mean, I have talked to these people.
[02:02:56.560 --> 02:02:56.840]   Right.
[02:02:56.840 --> 02:02:59.220]   Like I'm telling you what they tell me on some level.
[02:02:59.220 --> 02:03:05.180]   The steel man cases, they believe, like as Derek said a minute ago, this has become non democratically responsive.
[02:03:05.180 --> 02:03:10.560]   Like and the way it becomes democratically responsive is deeply responsive to the president.
[02:03:10.560 --> 02:03:14.580]   The president represents a different politics than Joe Biden's politics.
[02:03:14.580 --> 02:03:24.760]   And so if you have a state filled with liberal civil servants who don't want to do what he says, that is a violation of small d democratic principles of how the government should be run.
[02:03:25.320 --> 02:03:27.320]   I think if you don't like it, that's fine.
[02:03:27.320 --> 02:03:30.460]   But I do want to say, like, I actually think that is that is the steel man.
[02:03:30.460 --> 02:03:32.540]   He's not they're not doing this for no reason.
[02:03:32.540 --> 02:03:33.860]   They have an intention here.
[02:03:33.860 --> 02:03:39.760]   And I think, you know, the whether you like it or not sort of depends on whether or not you like their view.
[02:03:39.760 --> 02:03:52.000]   OK, well, I don't like it because it cuts my ear in a certain way that one of the criticisms I have for Donald Trump and and the Trump administration is there's a natural circles of sycophancy that forms.
[02:03:52.000 --> 02:03:56.080]   And, you know, every president has their personality and psychological quirks.
[02:03:56.080 --> 02:04:01.960]   And I think he is one of the people where favoritism is more likely to develop.
[02:04:01.960 --> 02:04:05.560]   So when you choose who to install as the head of whatever organization.
[02:04:05.560 --> 02:04:20.700]   So if you fire everybody and rehire, the rehiring process is more likely to have people that just said nice things about Donald Trump in the past versus a meritocracy based system that these people are really good.
[02:04:20.700 --> 02:04:22.660]   Lex, AOC should definitely come on the show.
[02:04:22.660 --> 02:04:24.360]   Well, she has her own.
[02:04:24.360 --> 02:04:40.900]   But the ideal, the steel man to me about not maybe what Elon is doing is in order to have the best people in the world doing a great job at every part of government.
[02:04:41.100 --> 02:04:46.120]   You have to figure out, I mean, his first email of like, what have you done this week?
[02:04:46.120 --> 02:04:58.120]   There's the if we just steel man, everything he's been doing, which is like, let's find the productive people that show up to work that love what they're doing, that are actually sort of amazing at what they're doing.
[02:04:58.280 --> 02:05:01.400]   I mean, how would you solve that problem from his experience in business?
[02:05:01.400 --> 02:05:09.840]   It's painful, but effective to just fire almost everybody and then rebuild from there and continuously do that.
[02:05:09.840 --> 02:05:17.860]   And as a result, as long as everybody's aligned in a mission is you're simplifying over and over the system.
[02:05:17.860 --> 02:05:34.540]   So it's more and more and more effective now, like how would you, how else would you approach, um, we could start now criticizing how, how would you make government more efficient if not by the way that they're doing it?
[02:05:34.540 --> 02:05:34.660]   Yeah.
[02:05:34.660 --> 02:05:36.080]   Can I steal men to the other side now?
[02:05:36.080 --> 02:05:36.280]   Sure.
[02:05:36.280 --> 02:05:37.880]   Um, okay.
[02:05:37.880 --> 02:05:38.000]   Okay.
[02:05:38.000 --> 02:05:41.240]   You wouldn't do this.
[02:05:41.240 --> 02:05:43.200]   You wouldn't do this.
[02:05:43.200 --> 02:05:44.380]   So let me say a couple of things.
[02:05:44.380 --> 02:05:50.800]   One is that efficiency only makes sense when yoked to a goal.
[02:05:50.800 --> 02:05:56.400]   So when, if Elon Musk came in and did this at Tesla, Musk had a goal for Tesla.
[02:05:56.400 --> 02:05:59.780]   It was to build the electric vehicle of the future.
[02:05:59.780 --> 02:06:02.100]   SpaceX, he had a goal for SpaceX.
[02:06:02.100 --> 02:06:07.180]   We know what the goal for SpaceX is in some long-term way, go to Mars, but in some short-term way, you know,
[02:06:07.320 --> 02:06:13.700]   cheaper orbital travel, you know, cheaper orbital shipping, reusable rockets, et cetera.
[02:06:13.700 --> 02:06:17.100]   We know what the goal for SolarCity was in a way.
[02:06:17.100 --> 02:06:22.120]   And I do think sort of the purchase of Twitter is late Elon, which becomes a much more political set of goals.
[02:06:22.120 --> 02:06:26.360]   But, but nevertheless, um, in a way, at least there's an expressed idea at Twitter, right?
[02:06:26.360 --> 02:06:28.000]   Which is the, the return of free expression.
[02:06:28.000 --> 02:06:38.020]   I think it's really important if you are steel manning or any kind of manning is, is being, is really asking and like listening to what people are saying their goal is.
[02:06:38.020 --> 02:06:40.980]   Because efficiency does not exist in a vacuum, right?
[02:06:41.040 --> 02:06:46.860]   The, uh, a state that is efficient at building dirty energy in a state that are, is efficient at burning clean energy.
[02:06:46.860 --> 02:06:49.720]   They're, they're sort of, they can be opposite versions of each other, right?
[02:06:49.720 --> 02:06:52.300]   You have to be, you have to be optimizing towards something.
[02:06:52.300 --> 02:06:53.060]   You're an AI guy.
[02:06:53.060 --> 02:06:54.640]   You have to optimize towards something.
[02:06:55.420 --> 02:07:05.260]   And the goal, I, I, I find myself really consistently frustrated by conversations about Doge that treat efficiency as some free floating thing.
[02:07:05.260 --> 02:07:13.720]   Or I sometimes will hear people say to me, very smart people have said to me, oh, what Doge is really doing is stripping the government down to studs so it can put AI into it.
[02:07:13.720 --> 02:07:17.960]   Because Elon believes in AGI is coming soon and you need to make a government capable of using AGI.
[02:07:18.220 --> 02:07:25.320]   And I always say to them, okay, AI towards what, towards what value function, towards what prompt are you inserting at the, at the base level?
[02:07:25.320 --> 02:07:26.280]   Sorry about that.
[02:07:26.280 --> 02:07:30.380]   Um, and I think a few things become very clear.
[02:07:30.380 --> 02:07:33.060]   One is it, it is towards Donald Trump.
[02:07:33.060 --> 02:07:34.040]   It is his movement.
[02:07:34.040 --> 02:07:35.800]   Elon Musk serves at his pleasure.
[02:07:35.800 --> 02:07:41.380]   Elon Musk has said that he would like to himself chisel Donald Trump's face into Mount Rushmore.
[02:07:41.380 --> 02:07:45.640]   He said he loves Donald Trump as much as a man can love any other man.
[02:07:46.320 --> 02:07:48.260]   He believes in Trump, right?
[02:07:48.260 --> 02:07:49.620]   I think you have to take him at his word.
[02:07:49.620 --> 02:07:53.840]   Or maybe you think he's very cynical and he's saying all that to curry favor in a sycophantic way with Trump.
[02:07:53.840 --> 02:07:57.400]   But at some point, Elon Musk does not serve with any kind of independence.
[02:07:57.400 --> 02:07:59.440]   If Trump says your power is gone, his power is gone.
[02:07:59.440 --> 02:08:01.700]   He's an outside, he's functionally an outside advisor to the government.
[02:08:01.700 --> 02:08:06.780]   So then you, you really do, I think, have to listen to what Donald Trump has said, what Russ Vought has said.
[02:08:06.780 --> 02:08:09.460]   And they believe that Trump represents something fundamental.
[02:08:09.460 --> 02:08:12.680]   His movement represents something fundamental that has been suppressed in American life.
[02:08:12.680 --> 02:08:18.380]   I think if you were doing something, the best cases I've seen for Elon are a zero-based budgeting case.
[02:08:18.380 --> 02:08:23.080]   You're trying to break everything down to studs and then it needs to re-justify.
[02:08:23.080 --> 02:08:29.660]   So if he did this at Twitter, the engineers had to come in and justify to his people what they were actually doing.
[02:08:29.660 --> 02:08:31.500]   But that wasn't how those emails worked.
[02:08:31.500 --> 02:08:32.720]   We all know this, right?
[02:08:32.720 --> 02:08:43.480]   He doesn't have a staff capable of seriously working through and then following up on emails from two-some million government employees about what they did that week.
[02:08:43.480 --> 02:08:45.960]   And then really checking, well, did they do it well?
[02:08:45.960 --> 02:08:47.760]   Like, was the thing accomplished, right?
[02:08:47.760 --> 02:08:49.040]   Like, that's not how you do that.
[02:08:49.040 --> 02:08:50.960]   Like, what, he's got 50 people at Doge?
[02:08:50.960 --> 02:08:51.300]   Nothing.
[02:08:53.060 --> 02:08:56.620]   If you wanted to do zero-based budgeting, it has to be against the criteria.
[02:08:56.620 --> 02:08:58.400]   So coming in and gutting USAID.
[02:08:58.400 --> 02:09:02.600]   Some of the things USAID does are just extraordinary, right?
[02:09:02.600 --> 02:09:03.160]   PEPFAR.
[02:09:03.160 --> 02:09:06.500]   Nobody anywhere thought PEPFAR was not an efficient program.
[02:09:06.500 --> 02:09:13.420]   PEPFAR is maybe the highest value thing that we have ever done in the U.S. government to save human life through foreign aid.
[02:09:14.000 --> 02:09:16.800]   I mean, just bluntly, it's a George W. Bush program.
[02:09:16.800 --> 02:09:19.260]   It saved a generation of people from dying of HIV-AIDS.
[02:09:19.260 --> 02:09:23.700]   They just turned it off, and they didn't have somebody come in and justify the PEPFAR funding.
[02:09:23.700 --> 02:09:30.600]   They just turned it off as they turned all these different things off and have never given people a serious effort to come back in and say, this is what we do.
[02:09:30.600 --> 02:09:32.960]   They just fired half of the people at DOE.
[02:09:32.960 --> 02:09:41.060]   DOE is, if you look at it, DOE has the lowest staffing level of any agency, but the fourth highest appropriation.
[02:09:41.520 --> 02:09:45.620]   And it administers the more than $1 trillion higher ed.
[02:09:45.620 --> 02:09:50.940]   It is, in overhead terms, one of the leanest of all the agencies, alongside Social Security Agency.
[02:09:50.940 --> 02:09:55.800]   They didn't tell those people, like, what they wanted out of a DOE of half the size.
[02:09:55.800 --> 02:09:58.940]   They didn't let those people come in and argue for their jobs.
[02:09:58.940 --> 02:10:04.700]   They're just cutting things, and they're not explaining at any point, at any level, what they want to do with them.
[02:10:04.700 --> 02:10:09.040]   And then I will also say what they're doing is probably illegal, right?
[02:10:09.100 --> 02:10:16.300]   Just this week or last week, a judge said that about 26,000 people need to be rehired by the federal government because their firings were illegal.
[02:10:16.300 --> 02:10:21.260]   And now that's going to go up to the Supreme Court, and we'll see what John Roberts and Amy Coney Barrett say, right?
[02:10:21.260 --> 02:10:23.160]   That game is not done yet.
[02:10:23.160 --> 02:10:26.360]   But they have Congress.
[02:10:27.200 --> 02:10:30.440]   I am a person who believes we needed civil service reform.
[02:10:30.440 --> 02:10:31.800]   Too hard to hire.
[02:10:31.800 --> 02:10:33.500]   Too hard to fire.
[02:10:33.500 --> 02:10:34.900]   Too hard to manage.
[02:10:34.900 --> 02:10:37.620]   And they could have gone to Congress.
[02:10:37.620 --> 02:10:41.740]   And frankly, at the beginning, Ro Khanna and a bunch of Democrats that they wanted to work with DOGE.
[02:10:41.740 --> 02:10:43.060]   Democrats were defeated.
[02:10:43.460 --> 02:10:48.720]   If you had wanted to build some amount of, like, political, you know, bipartisanship, it was there to do, right?
[02:10:48.720 --> 02:10:52.040]   Like, the Democrats voted for the Lake and Riley bill, the hardcore immigration bill.
[02:10:52.040 --> 02:10:53.480]   They were ready to deal.
[02:10:53.480 --> 02:10:58.140]   But they didn't want to do that because it is fundamentally for them about political control.
[02:10:58.140 --> 02:11:00.000]   And this is my steelman case for the action.
[02:11:00.000 --> 02:11:01.040]   This is a case, I believe.
[02:11:01.900 --> 02:11:04.360]   What Elon did at Twitter was not make Twitter more efficient.
[02:11:04.360 --> 02:11:05.920]   It's not, like, a better product now.
[02:11:05.920 --> 02:11:06.840]   It's a different product.
[02:11:06.840 --> 02:11:08.480]   But what he did was he made it controllable.
[02:11:08.480 --> 02:11:12.580]   What he did at Twitter was he went into something where he thought the people disagreed with him.
[02:11:12.580 --> 02:11:16.220]   And he broke it until he had actual operational control of the thing.
[02:11:16.220 --> 02:11:17.720]   And they would do what he wanted them to do.
[02:11:17.720 --> 02:11:19.420]   And then he could move it in his direction.
[02:11:19.420 --> 02:11:26.740]   What they're doing in the federal government, and this is what Chris Rufo wanted to do, it's what Russ Vought wanted to do, is make the thing controllable.
[02:11:26.740 --> 02:11:30.280]   And what they want to do with that control, I don't even think they fully know.
[02:11:30.480 --> 02:11:36.360]   But their view was that the federal government is like a – it is the capital city that they have conquered.
[02:11:36.360 --> 02:11:40.500]   And now they need to turn it into something that they can actually use.
[02:11:40.500 --> 02:11:45.740]   And in order to do that, I mean, Russ Vought has said you need to traumatize the civil servants, right?
[02:11:45.740 --> 02:11:48.300]   That was his word, traumatize the civil servants.
[02:11:48.300 --> 02:11:52.140]   When, you know, Elon Musk talked about USAID, he said, it's all worms, no apple.
[02:11:52.140 --> 02:11:53.560]   We're going to feed it to the wood chipper.
[02:11:53.560 --> 02:11:58.300]   This isn't the language of let's see who's really doing a good job here and who's not.
[02:11:58.300 --> 02:11:59.780]   This is the language of conquering.
[02:11:59.900 --> 02:12:01.400]   This is the language of destruction.
[02:12:01.400 --> 02:12:06.400]   And they have not articulated new, better goals for it.
[02:12:06.400 --> 02:12:09.160]   And nor are they starting with the parts of the government where I think you would start with.
[02:12:09.160 --> 02:12:11.900]   Like, what do they want the education department to do?
[02:12:11.900 --> 02:12:13.720]   Like, I'm a professional political journalist.
[02:12:13.720 --> 02:12:15.560]   I talk to people in the Trump administration.
[02:12:15.560 --> 02:12:19.220]   I can't tell you what they want out of it aside from the fact that they don't like it.
[02:12:19.340 --> 02:12:21.880]   And they think it's like a hotbed of other people's power.
[02:12:21.880 --> 02:12:27.460]   I can tell you what some conservatives have written about it, but the administration itself has not articulated goals.
[02:12:27.460 --> 02:12:35.800]   So what I think their view is right now is they're breaking the thing and trying to make the people who would be oppositional either like leave or go into hiding.
[02:12:36.180 --> 02:12:38.000]   And then they're going to figure out what they want to do with it.
[02:12:38.000 --> 02:12:40.920]   But like right now, they're in the period where you have to sack.
[02:12:41.560 --> 02:12:47.200]   And then like later on, you can build yourself your monuments and turn the civil service to your own ends.
[02:12:47.200 --> 02:12:51.860]   That is my, like, I don't think it's still, I just, that is what I think is going on.
[02:12:52.720 --> 02:12:59.160]   I think that's an, from a certain perspective, accurate and insightful description.
[02:12:59.160 --> 02:13:06.200]   If we just look at Twitter, you said that he didn't make it more efficient.
[02:13:06.200 --> 02:13:07.580]   He made it more controllable.
[02:13:07.580 --> 02:13:17.400]   Let me just describe, just because I know the engineers inside Twitter well, which we could argue that the government is very different than a company.
[02:13:17.400 --> 02:13:18.720]   That's an important argument there.
[02:13:19.000 --> 02:13:28.380]   With Twitter, the culture that's there now, people are really excited to work there and to be productive there.
[02:13:28.380 --> 02:13:29.060]   Engineers.
[02:13:29.060 --> 02:13:36.560]   Elon is really good at finding people that are there, extremely good at what they do and are there to give everything.
[02:13:36.560 --> 02:13:43.740]   And the resulting thing, this machine that is created, all barriers removed, you create beautiful stuff.
[02:13:43.740 --> 02:13:47.060]   It's not like move fast and break things.
[02:13:47.060 --> 02:13:49.520]   It's a very cynical perspective on it.
[02:13:49.520 --> 02:13:57.940]   No, you, everybody loves what they do, are good at it, and are really rapidly figuring out all the multitude of problems that arise in that.
[02:13:57.940 --> 02:14:02.420]   And so it just creates a, it's a different culture, a culture of productivity.
[02:14:02.680 --> 02:14:11.440]   And it's not like some negative boys club or this, there's all kinds of negative perspectives you can take on those things.
[02:14:11.440 --> 02:14:14.380]   No, it's, it's a positive culture of productivity.
[02:14:14.380 --> 02:14:18.840]   Controllable side, also really important to understand.
[02:14:19.420 --> 02:14:23.720]   And that could be taken advantage of in a really negative way, especially in government.
[02:14:23.720 --> 02:14:33.380]   But you should say on some of the most successful software projects, there is a level of control required to, like, open source projects.
[02:14:33.380 --> 02:14:38.300]   Linus Torvald, the head of the, that heads up the Linux kernel.
[02:14:38.640 --> 02:14:42.500]   There has to be what's often called the benevolent dictator for life.
[02:14:42.500 --> 02:14:50.460]   There, there has to be a controllability to the machine of this extremely productive, efficient team to work together.
[02:14:50.580 --> 02:14:52.440]   Now, those are engineering projects.
[02:14:52.440 --> 02:14:59.840]   And the problem with government is you get elected new, benevolent dictators for life that come.
[02:14:59.840 --> 02:15:01.000]   They're often not benevolent.
[02:15:01.000 --> 02:15:02.480]   And they're often not benevolent.
[02:15:02.480 --> 02:15:04.780]   And they all convince themselves they're benevolent.
[02:15:04.780 --> 02:15:10.920]   You know, I'm sure Hitler thought he's doing the right thing, the good thing, the benevolent thing in his worldview.
[02:15:10.920 --> 02:15:12.740]   Every single dictator does that.
[02:15:12.740 --> 02:15:13.400]   Yes.
[02:15:13.400 --> 02:15:14.440]   So that's a problem.
[02:15:14.440 --> 02:15:18.960]   But in order to be efficient, there has to be some level of controllability.
[02:15:19.360 --> 02:15:29.540]   And there has to be, I think, just to go back to the steel man, you have to have a culture of productivity that I'm not sure.
[02:15:29.540 --> 02:15:36.020]   I've had quite a bit of experience with DOD and DARPA from the academic side.
[02:15:36.020 --> 02:15:38.400]   Just everything is so bureaucratic and slow.
[02:15:38.400 --> 02:15:40.060]   That's a different culture.
[02:15:40.060 --> 02:15:49.320]   So, you know, part of the destruction is in reestablishing a culture and, yes, make it more controllable so you can be efficient.
[02:15:50.140 --> 02:15:52.140]   We still need to define what the outcome is.
[02:15:52.140 --> 02:15:52.400]   Yes.
[02:15:52.400 --> 02:15:54.140]   Productivity in service of what?
[02:15:54.140 --> 02:15:54.860]   In service of what?
[02:15:54.860 --> 02:15:55.620]   Efficiency in service of what?
[02:15:55.620 --> 02:15:59.920]   And I think the juxtaposition of the private and public sectors is really useful here.
[02:16:01.120 --> 02:16:08.920]   Private companies, publicly traded companies, have the benefit of tight and quantifiable feedback loops.
[02:16:08.920 --> 02:16:12.800]   Are you making more money this quarter than you were last quarter or less?
[02:16:12.800 --> 02:16:14.320]   How's consumer feedback?
[02:16:14.320 --> 02:16:16.000]   Do people say they like the product more?
[02:16:16.000 --> 02:16:18.640]   Are you getting 4.8 on your reviews or 4.6?
[02:16:19.040 --> 02:16:22.440]   The feedback loops are very quantifiable and they're also very, very quick.
[02:16:22.440 --> 02:16:24.380]   You know exactly when you're doing a good and bad job.
[02:16:24.380 --> 02:16:31.540]   And so the KPIs are so cleanly drawn that people are aligned in their sense of we are moving forward and moving back, right?
[02:16:32.220 --> 02:16:34.640]   I don't think government has done this at all under Doge.
[02:16:34.640 --> 02:16:41.620]   In fact, I think in some ways, goals that you could clearly identify as being good are being torn down.
[02:16:41.620 --> 02:16:53.480]   And this is why, again, it's so useful to be able to articulate goals in politics because without an articulation of goals, you don't know whether the job to be done is to take something away or to add something.
[02:16:53.760 --> 02:16:59.040]   And right now, the answer from Doge is to take away, take away, subtract everything, break down to studs, as Ezra said.
[02:16:59.040 --> 02:17:01.640]   But let's take a really, really concrete example here.
[02:17:01.640 --> 02:17:03.520]   The FDA, right?
[02:17:03.520 --> 02:17:16.000]   Doge just laid off dozens of probationary employees, so upwardly mobile, recently hired, often very young, nicely credentialed employees at the FDA as a part of its slashing of the federal workforce.
[02:17:16.000 --> 02:17:22.220]   One of the big problems of the FDA is slow approval of phase three clinical trial drugs, right?
[02:17:22.280 --> 02:17:31.860]   Everyone in this country who believes in science and technology wants the most life-saving drugs to be brought into the public marketplace as soon as possible and competed against with other drugs.
[02:17:31.860 --> 02:17:35.420]   The price comes down and helps to extend people's lives and health spans.
[02:17:35.420 --> 02:17:38.440]   I think everyone agrees that that is an outcome worth fighting for.
[02:17:38.440 --> 02:17:42.000]   And if they don't, certainly, Ezra and I are willing to say, that's an outcome that we want.
[02:17:42.000 --> 02:17:44.180]   That's what we want from our science policy.
[02:17:44.180 --> 02:17:48.480]   What happens if you cut probationary employees at the FDA?
[02:17:48.480 --> 02:17:51.240]   The FDA doesn't become more efficient.
[02:17:51.760 --> 02:18:05.280]   It becomes less efficient because the same amount of work spread over fewer people means longer delays in terms of approving phase three clinical trial drugs and deciding whether or not to approve them for public consumption.
[02:18:05.680 --> 02:18:11.700]   So in this really, really clear and very specific example, I think we can see the problem with not having articulated goals.
[02:18:11.700 --> 02:18:17.220]   You don't know whether the job to be done is to take away employees or to add them.
[02:18:17.360 --> 02:18:27.560]   I think if instead what Doge had done is come in and say, you know what, Elon Musk and a bunch of other people from Silicon Valley, one thing we take very seriously is the importance of scientific and technological progress.
[02:18:27.560 --> 02:18:37.300]   Because if you look back over decades and centuries, what distinguishes our generation from every other generation in terms of its health and its power is science and technology.
[02:18:37.300 --> 02:18:41.320]   And we want to infuse government with a sense of science and technological progress.
[02:18:41.320 --> 02:18:48.800]   And to that end, one thing we want to do is to have a smarter and more efficient FDA so that people can experience life-saving medicines.
[02:18:49.220 --> 02:19:05.680]   I think what you would do is research the bottlenecks that exist to American science and pharmaceutical policy and say we should hire more people at the FDA to accelerate drug approval, decide which drugs are to be rejected and which drugs are to get the FDA label.
[02:19:05.680 --> 02:19:09.200]   That is the opposite of the Doge approach.
[02:19:09.200 --> 02:19:15.520]   And this really, I think, puts a fine point to the problem of a Doge without goals.
[02:19:16.060 --> 02:19:28.140]   When Elon takes over Tesla, when Elon is at SpaceX, when Elon's at X, I would imagine, and you know this better than me because you know him, and maybe most importantly, for the purposes of this part of the conversation, you know the people who work for him.
[02:19:28.140 --> 02:19:35.260]   I'll bet if you ask the people who work under Elon at X, Tesla, SpaceX, they say, I know exactly what Elon wants.
[02:19:35.260 --> 02:19:37.860]   This is his goal for the super heavy rocket.
[02:19:37.860 --> 02:19:40.400]   This is his goal in terms of humanoid robots.
[02:19:40.400 --> 02:19:47.520]   This is his goal in terms of profitability of Twitter and the growth of our subscription business and how we're going to integrate new features.
[02:19:47.520 --> 02:19:49.860]   There's probably a really clear mind meld.
[02:19:49.860 --> 02:19:52.980]   Right now, I have no sense that there's a mind meld.
[02:19:52.980 --> 02:19:54.660]   And in fact, I have the exact opposite sense.
[02:19:54.660 --> 02:20:02.120]   That rather than an example of creative destruction, which would be a mitzvah of entrepreneurship, we have an act of destruction, destruction.
[02:20:02.120 --> 02:20:04.600]   We have destruction for the sake of destruction.
[02:20:05.280 --> 02:20:23.640]   It's much cleaner to me, from an interpretive standpoint, to describe Doge as an ideological purge of progressivism, performing an act of, or performing the job of efficiency, rather than a department of actual efficiency itself.
[02:20:23.640 --> 02:20:26.320]   I want to say, because I really want to emphasize that it has goals.
[02:20:26.320 --> 02:20:31.160]   The goals are clear on some level, and they have to do with centralizing power.
[02:20:31.260 --> 02:20:36.660]   So let me take out something that's not Doge, because this is, I think, an important place where you see what the effort is.
[02:20:36.660 --> 02:20:39.720]   What is Congress for?
[02:20:39.720 --> 02:20:44.260]   Not just Democrats in Congress who are, in theory, right now, the opposition party, but Republicans in Congress.
[02:20:44.260 --> 02:20:53.480]   Congress is this aggregation of information from different places in the country who've chosen representatives to represent them in Washington.
[02:20:53.480 --> 02:20:54.800]   That's how the system works.
[02:20:55.840 --> 02:21:19.360]   One of the things that has really cowed congressional Republicans, it is a huge sun-like gravitational force now on Capitol Hill, is that Elon has made it known that any House or Senate Republican who defies Trump on a key vote, cabinet nominees, the CR, that kind of thing, he will dump $50 to $100 million into a primary.
[02:21:19.860 --> 02:21:21.020]   It's no money at all for him.
[02:21:21.020 --> 02:21:23.620]   It's lethal for them, right?
[02:21:23.620 --> 02:21:24.600]   This is well-known.
[02:21:24.600 --> 02:21:27.360]   He has said this, like, personally to some of them, right?
[02:21:27.360 --> 02:21:28.380]   It's been well-reported.
[02:21:28.380 --> 02:21:31.800]   This is probably why Jody Ernst voted for Pete Hegseth.
[02:21:31.800 --> 02:21:33.600]   Well, what's achieved by this?
[02:21:33.600 --> 02:21:34.780]   I think it's, like, an interesting question.
[02:21:34.780 --> 02:21:37.720]   Because Republicans, in theory, are allied to Donald Trump, right?
[02:21:37.720 --> 02:21:39.040]   He's the nominee of their party.
[02:21:39.040 --> 02:21:41.040]   And they don't have, like, literally the same view of him.
[02:21:41.720 --> 02:21:47.460]   But I think you might say from one perspective, there is a value in the system in there being checks and balances.
[02:21:47.460 --> 02:21:52.100]   There's a value in the system in the system having to absorb other kinds of information.
[02:21:52.100 --> 02:22:03.460]   Now, we already don't have the checks and balances we once had or thought we would have in this country because we have nationalized political parties instead of, you know, branches of government that sort of compete, you know, with ambition checking ambition.
[02:22:03.460 --> 02:22:06.460]   And I've done whole shows on this, and we can talk about that if we want.
[02:22:06.460 --> 02:22:08.500]   But we do have political parties.
[02:22:08.500 --> 02:22:19.120]   And political parties are themselves institutions that aggregate different kinds of information in order to try to come to some outcome that is a better outcome because more information has surfaced.
[02:22:19.320 --> 02:22:34.860]   I think Donald Trump would be in a stronger position for him if Senate Republicans could have done what they actually wanted to do and not confirm RFK Jr., not confirm Tulsi Gabbard, not confirm Pete Hegseth, not confirm Kash Patel and Don Vigino, right?
[02:22:34.860 --> 02:22:38.240]   That's actually a huge amount of risk the Trump administration has taken on.
[02:22:38.240 --> 02:22:43.460]   If they had named a sort of normal figure to HHS and then there's a measles outbreak.
[02:22:43.460 --> 02:22:45.140]   Well, measles outbreaks are tough.
[02:22:45.140 --> 02:22:46.060]   Like, that's a hard thing.
[02:22:46.280 --> 02:22:52.480]   If you name RFK Jr. and there's a huge measles outbreak, you're really going to get blamed for that because people are ready to blame you.
[02:22:52.480 --> 02:23:09.080]   If there is a domestic terror attack after you've put Kash Patel, who's quite unqualified, in charge of the FBI, and they sort of launched a war internally against the FBI, which they see as a hotbed of anti-Trump sentiment, and the FBI in the sort of internal chaos misses some things and you have deaths on Americans.
[02:23:09.080 --> 02:23:11.240]   So that's a huge amount of risk you've taken on.
[02:23:11.240 --> 02:23:14.440]   I mean, the guy they fired, Chris Wray, he was Trump's appointee.
[02:23:14.440 --> 02:23:15.560]   It wasn't some Democrat.
[02:23:15.560 --> 02:23:16.980]   Trump named him in his first term.
[02:23:16.980 --> 02:23:18.920]   But Elon, right?
[02:23:18.920 --> 02:23:22.940]   What he did here was he created a kind of death star of primary money.
[02:23:22.940 --> 02:23:28.120]   And he has said that, like, if you cross Trump in Congress, even as a Republican, you're done.
[02:23:28.120 --> 02:23:33.800]   Like, between Trump's control of attention and loyalty and my ability to outspend you, like, you're toast.
[02:23:35.080 --> 02:23:39.940]   I think what that reveals is that what he wants is for power to be centralized under Trump.
[02:23:39.940 --> 02:23:42.820]   We've been talking about the bureaucracy, but he also wants it to be true in Congress.
[02:23:43.760 --> 02:23:48.300]   I am not a Donald Trump fan, but obviously other people are Donald Trump fans, right?
[02:23:48.300 --> 02:23:52.960]   Obviously, I think at this point Elon Musk is a Donald Trump fan, but much of the country thinks this guy is great.
[02:23:52.960 --> 02:23:57.400]   And I think we should take what they are doing at word and deed.
[02:23:57.400 --> 02:24:01.520]   The point of Donald Trump is that Donald Trump is right about things.
[02:24:01.520 --> 02:24:03.900]   We should give him power and he should use that power.
[02:24:04.300 --> 02:24:07.080]   My sense is you have some mixed feelings about him, but not everybody does.
[02:24:07.080 --> 02:24:27.560]   And this sort of very consistent application of authority across the people he's named, J.D. Vance, the difference between Mike Pence and J.D. Vance is J.D. Vance said explicitly in the whole run-up to the vice presidential sweepstakes that his view of what went wrong in the first administration is between the bureaucracy and the staff, too many people are trying to inhibit Donald Trump.
[02:24:27.900 --> 02:24:34.800]   And that what he would do is tell Trump that, like, he's got to get rid of these generals and he's got to get people who will do what Trump actually said.
[02:24:34.800 --> 02:24:51.260]   The view of Trump's fans, the view of his allies, is that the first term didn't go well enough because they had too much opposition from Republicans in Congress who talked Trump into things they shouldn't have talked him into and too much opposition from the civil service and even from Trump's own staff.
[02:24:51.540 --> 02:25:00.980]   I think a very simple heuristic of why these terms are so different is that the most important member of the Trump family, Trump aside, in the first term was Jared Kushner and maybe Ivanka.
[02:25:00.980 --> 02:25:04.840]   And the most important member of the family in the second is Don Trump Jr., right?
[02:25:04.840 --> 02:25:06.960]   Kushner brought in a bunch of inhibitors.
[02:25:06.960 --> 02:25:09.540]   He brought in mainstream figures like Gary Cohn.
[02:25:09.540 --> 02:25:14.680]   And, you know, Kushner represented other parts of society that, you know, were sort of mixed on Trump.
[02:25:14.680 --> 02:25:16.880]   And they wanted him to do certain things and not others.
[02:25:16.880 --> 02:25:18.500]   And there was maybe a productive tension.
[02:25:18.500 --> 02:25:21.220]   McConnell, you know, was majority leader.
[02:25:21.220 --> 02:25:22.820]   He was more powerful than Thune is.
[02:25:22.820 --> 02:25:23.960]   Paul Ryan was speaker.
[02:25:23.960 --> 02:25:25.600]   He's more powerful than Mike Johnson is.
[02:25:25.600 --> 02:25:29.460]   In the second term, you have Don Trump Jr., who brings in much more right-wing figures.
[02:25:29.460 --> 02:25:31.740]   They're accelerators, not inhibitors.
[02:25:31.740 --> 02:25:34.100]   Accelerationists, in many cases, explicitly.
[02:25:34.100 --> 02:25:39.140]   You have Elon Musk, who believes, like, the likeliest problem is Trump doesn't go far enough fast enough.
[02:25:39.140 --> 02:25:43.200]   And you have a weak Republican Congress that is further cowed by Musk's money.
[02:25:43.200 --> 02:25:50.900]   It could be good or it could be bad, but the Curtis Yarvin take that we need a more monarch-like figure is clearly being tested
[02:25:50.900 --> 02:25:51.340]   out.
[02:25:51.340 --> 02:25:56.580]   Like, the view, just as you said, about software engineering things is that you often need a benevolent dictator.
[02:25:56.580 --> 02:25:58.560]   Now, I don't think Trump is benevolent.
[02:25:58.560 --> 02:25:59.600]   Other people do.
[02:25:59.600 --> 02:26:07.960]   But the view that what is being attempted here is something much more centralized in its power, I think is actually a shared view of what's going on.
[02:26:08.020 --> 02:26:12.100]   It's like a consensus reality we have, not like an argument over reality we're having.
[02:26:12.100 --> 02:26:23.840]   Do you think there's some degree to where, if you trust in the system of democracy, which I do, and there's some people, and we'll talk about them, one of the main criticisms and concerns of Donald Trump is he's going to break democracy.
[02:26:23.840 --> 02:26:48.040]   But if you trust that democracy holds, isn't this an interesting experiment of how, when everybody's aligned, aggressive cutting of regulation and the number of people is an experiment of like, okay, let's see what this does to a really over-bloated bureaucracy that's become extremely inefficient.
[02:26:48.280 --> 02:27:07.060]   And, by the way, so I have an optimism about it that matches the vision of abundance in the book, that once you do the creative destruction, then you start to really be able to step in and have a clear vision of like, okay, housing.
[02:27:07.060 --> 02:27:10.480]   How do we, what are the policies to solve housing?
[02:27:10.480 --> 02:27:14.300]   But I do think the first step that's needed is the destruction.
[02:27:14.860 --> 02:27:24.880]   As Ezra said, we're sort of speed running a particular experiment here of what does executive power look like if we do away as much as possible with checks and balances.
[02:27:24.880 --> 02:27:31.540]   And I would submit that we're already starting to get some feedback loops from the market.
[02:27:32.300 --> 02:27:38.120]   The stock market is not the economy, but it is a very clear voting mechanism.
[02:27:38.120 --> 02:27:48.480]   And what's clear is that many institutional and retail investors think that the current economic regime is pushing us toward a recession that we don't have to have.
[02:27:48.480 --> 02:27:49.280]   Right.
[02:27:49.280 --> 02:28:01.340]   Donald Trump has insulated himself from any feedback loop or any sense of criticism that his tariff policy might not be the best course of strategy for American industry or global relations.
[02:28:01.420 --> 02:28:07.580]   And as a result, what we have is, I think, fairly described as a kind of purposeful chaos.
[02:28:07.580 --> 02:28:12.160]   I mean, what other term can you use if a tariff is being announced at 9 a.m.
[02:28:12.160 --> 02:28:14.220]   and then taken away at 3.30 p.m.
[02:28:14.220 --> 02:28:18.980]   and then 10 days later announced at 9.37 and then renegotiated at 2.45?
[02:28:19.320 --> 02:28:26.520]   This is not a principled theory of the perfect tariff level on international trade.
[02:28:26.640 --> 02:28:32.920]   This is, I think, much more parsimoniously explained by just an expression of Donald Trump's personality.
[02:28:32.920 --> 02:28:36.000]   This is a New York real estate guy.
[02:28:36.000 --> 02:28:50.340]   He loves making big, awesome pronouncements and then using those big, awesome pronouncements in order to negotiate little one-on-one dealings where he can rest for himself a personal sense of power or money or pride.
[02:28:50.340 --> 02:28:56.600]   Announcing these tariffs in a sort of chaotic way forces world leaders to get on the phone with him and say,
[02:28:56.600 --> 02:28:59.680]   Donald, what can I give you to bring down the tariff, right?
[02:28:59.680 --> 02:29:06.540]   This is personality standing in for politics in a way that's totally unmolested by anybody else's sense of,
[02:29:06.540 --> 02:29:08.480]   hey, Donald, maybe chill it on the tariff policy.
[02:29:08.480 --> 02:29:10.280]   Hey, let's maybe slow down on the deportations.
[02:29:10.380 --> 02:29:12.980]   I'm not so sure about this particular move over here.
[02:29:12.980 --> 02:29:17.460]   Instead, you have an executive branch that's just a full manifestation of Donald Trump's mind.
[02:29:17.460 --> 02:29:26.600]   And I do think that the early returns, if you look at consumer sentiment, if you look at the stock market, if you look at the 10-year yield,
[02:29:26.600 --> 02:29:37.760]   you have a range of, let's call them, aggregated economic information telling us that the economy, consumers, employers, investors do not like what's happening now,
[02:29:37.800 --> 02:29:39.800]   which is going to be a really interesting test case.
[02:29:39.800 --> 02:29:48.340]   Donald Trump's first four years in office, right, love him or hate him, were four rather successful years of economic growth.
[02:29:48.340 --> 02:29:53.460]   Low unemployment, steady growth, low inflation, pretty much every economic indicator in the green.
[02:29:53.460 --> 02:29:59.860]   We're already in the red in many of the economic indicators that never even blinked yellow under his first administration.
[02:30:00.100 --> 02:30:08.700]   And I personally don't think it's a coincidence that you're getting these red indicators at a time when Donald Trump is having an entirely different experience of being president,
[02:30:08.700 --> 02:30:12.880]   where there is no Mnuchin to tell him, hey, maybe let's cool it off in the tariffs.
[02:30:13.100 --> 02:30:22.880]   The one more thing I would add here is you said, you know, maybe, maybe Trump's presidency is a kind of right-wing abundance, right?
[02:30:22.880 --> 02:30:25.500]   And I think that's a worthy question, right?
[02:30:25.500 --> 02:30:29.120]   Is Donald Trump just doing his own version of abundance?
[02:30:29.120 --> 02:30:35.460]   And we should, even if we disagree with his process ideologically, sort of root for the outcomes that are likely under it.
[02:30:35.980 --> 02:30:36.920]   Here's why I don't think so.
[02:30:36.920 --> 02:30:44.680]   Let's say that you, or just someone as a conservative, shares our view that they want housing to be abundant.
[02:30:44.680 --> 02:30:52.340]   I think what they should really root for is to reduce the tax for building and make it easier to add housing units cheaply.
[02:30:52.340 --> 02:30:55.160]   Well, houses are made out of materials.
[02:30:55.160 --> 02:31:00.980]   Two of the most important materials in home building are soft lumber and drywall.
[02:31:00.980 --> 02:31:03.640]   Soft lumber we import from Canada.
[02:31:04.400 --> 02:31:07.280]   Drywall, one of the key ingredients, we import from Mexico.
[02:31:07.280 --> 02:31:15.080]   One of the first things that's going to happen if you raise 25% tariff on lumber from Canada and drywall from Mexico is that the cost of housing is going to go straight up.
[02:31:15.080 --> 02:31:16.500]   And this isn't my personal opinion.
[02:31:16.500 --> 02:31:23.100]   This was a March 7th memo sent by the National Association of Homebuilders, essentially in a kind of controlled panic, saying,
[02:31:23.100 --> 02:31:26.020]   please don't do a tariff policy like this.
[02:31:26.020 --> 02:31:34.380]   You're going to screw over home builders, even though, ironically, you, Donald Trump, were elected by Biden to Trump voters who were mad about the price of housing.
[02:31:34.380 --> 02:31:45.140]   So I am not in the moment optimistic that his centralizing style is going to be economically useful for Americans, whatever their interests.
[02:31:45.260 --> 02:31:53.280]   My sense of the early feedback and of the early returns is that he, in fact, does not have a very clear and beneficial economic agenda.
[02:31:53.280 --> 02:31:55.160]   He has a personal agenda.
[02:31:55.160 --> 02:32:01.480]   He likes taking phone calls from international leaders and working out little deals with them.
[02:32:01.700 --> 02:32:04.740]   I don't think that's in the larger interest of economic growth.
[02:32:04.740 --> 02:32:08.900]   And certainly, I don't think it's in the specific interest of reducing housing prices.
[02:32:08.900 --> 02:32:11.060]   Okay, there's a lot to say there.
[02:32:11.060 --> 02:32:16.760]   So, first of all, can we separate the sort of abundance and those efforts from tariffs?
[02:32:16.760 --> 02:32:21.660]   Because I don't know who agrees with tariffs.
[02:32:21.660 --> 02:32:23.760]   Tariffs don't make sense to me economically.
[02:32:24.280 --> 02:32:30.480]   Maybe you can explain who agrees or likes to tariffs on the right or the left or anybody.
[02:32:30.480 --> 02:32:31.640]   But you see my point that...
[02:32:31.640 --> 02:32:33.660]   Well, that point also, to comment on it.
[02:32:33.660 --> 02:32:42.620]   I mean, one of the mechanisms by which bureaucracy forms is a kind of polite civility and a structure and a process.
[02:32:43.180 --> 02:32:50.540]   There is an argument to be made, and I'm not saying Donald Trump is that person, but there's some qualities there of picking up the phone and calling Putin.
[02:32:50.540 --> 02:32:53.580]   That goes against all the process.
[02:32:53.580 --> 02:33:00.420]   Some of the most successful peace negotiations throughout history broke process.
[02:33:00.420 --> 02:33:02.920]   I just spoke with Dorendra Modi.
[02:33:02.920 --> 02:33:04.360]   You know, there's a process.
[02:33:04.360 --> 02:33:07.040]   You're not supposed to meet with Pakistan or whatever for India.
[02:33:07.040 --> 02:33:08.820]   You just screw it.
[02:33:08.820 --> 02:33:12.320]   I'm going to go to a wedding, a Pakistan wedding of a high-up official.
[02:33:12.320 --> 02:33:14.820]   I'm going to do these things that are very Trumpian.
[02:33:14.820 --> 02:33:16.200]   Break the rules.
[02:33:16.200 --> 02:33:16.560]   Okay.
[02:33:16.560 --> 02:33:29.080]   Now, that, you know, in a perfect world, some of that is good matched with principled policy that's surrounded by a large number of experts that actually understand that policy.
[02:33:29.080 --> 02:33:29.320]   Okay.
[02:33:29.320 --> 02:33:30.960]   I can criticize Trump all day.
[02:33:30.960 --> 02:33:40.360]   But I'm just saying that there is some degree to picking up the phone and talking to leaders and playing in the morning, say one thing, in the evening, another.
[02:33:40.360 --> 02:33:43.420]   That could be part of a principled chaos.
[02:33:43.420 --> 02:33:46.660]   I think the important part of madman theory is that you're not actually a madman.
[02:33:46.660 --> 02:33:48.660]   You just got to convince people you are.
[02:33:48.660 --> 02:33:49.120]   Yes, yes.
[02:33:49.120 --> 02:33:52.180]   Look, I don't think I am in agreement that we should talk to everybody.
[02:33:52.180 --> 02:33:57.940]   People, I don't know how many, I don't know how many people followed the 2008 election closely who are watching this.
[02:33:58.040 --> 02:34:03.580]   There was a big fight in that election between Clinton and Obama about should you negotiate with your enemies.
[02:34:03.580 --> 02:34:05.580]   And Obama's view is we should.
[02:34:05.580 --> 02:34:06.700]   We should talk to anybody.
[02:34:06.700 --> 02:34:10.540]   And Clinton's view was more nuanced than that, right?
[02:34:10.540 --> 02:34:12.000]   Certainly we shouldn't at this juncture.
[02:34:12.000 --> 02:34:17.800]   And during his presidency, Obama did a deal with Iran on the nuclear question.
[02:34:18.000 --> 02:34:20.300]   He negotiated with Cuba, right?
[02:34:20.300 --> 02:34:22.280]   He had very direct negotiations with Russia.
[02:34:22.280 --> 02:34:28.700]   He did it, importantly, unlike Donald Trump, without alienating all of our traditional allies.
[02:34:29.540 --> 02:34:40.240]   One of the things that I think is important to say about Trump is that the difference between Trump and, say, Biden or Trump and Obama is not that Trump will negotiate with Putin and Obama wouldn't.
[02:34:40.240 --> 02:34:44.280]   It's that Trump is realigning our alliances.
[02:34:44.280 --> 02:34:50.100]   He doesn't really seem to want to negotiate with the Europeans, or at least he wants to do it from a more hostile position.
[02:34:50.100 --> 02:34:54.780]   He wants to make Canada the 51st state, not treat it as a longtime ally.
[02:34:54.780 --> 02:34:59.080]   The thing here is not that Trump is negotiating with our perceived enemies.
[02:34:59.880 --> 02:35:05.320]   These are his perceived allies, and he's turning our traditional allies into perceived enemies.
[02:35:05.320 --> 02:35:07.000]   So with him, I think it's important.
[02:35:07.000 --> 02:35:09.740]   Like, I am very much on the view of you talk to everybody.
[02:35:09.740 --> 02:35:18.120]   And it was my view going back, you know, for some years that, like, it was clear that the Biden administration needed to be pushing for negotiations over Ukraine.
[02:35:18.120 --> 02:35:22.320]   There was not going to be some endgame here where Ukraine got all of its territory back.
[02:35:23.500 --> 02:35:33.520]   But, but, but, but, I don't think it is reasonable to look at what he is doing and say that is the norm that he has broken.
[02:35:33.520 --> 02:35:35.500]   The idea that we should have negotiations.
[02:35:35.500 --> 02:35:38.160]   I mean, many different presidents have done many surprising things.
[02:35:38.160 --> 02:35:40.260]   And he's rolled back a bunch of those things.
[02:35:40.260 --> 02:35:45.080]   You know, Republicans have been very unfriendly to the opening that began with Cuba.
[02:35:45.420 --> 02:35:56.000]   Right. And that was like a big deal in American foreign policy, something Obama did against very heavy criticism, something that cost him and cost Democrats in Florida and among Cuban voters in the following election.
[02:35:56.380 --> 02:35:59.740]   So when I, I just don't think that that's that unusual thing with Trump.
[02:35:59.740 --> 02:36:05.520]   I also just want to say with the tariffs, you sort of wanted to cut the tariffs off from Doge and cut the tariffs off from this broader agenda.
[02:36:05.520 --> 02:36:12.680]   And one reason I don't is that I think the way to understand tariffs, look, you can be accomplishing many different things with tariffs.
[02:36:13.220 --> 02:36:29.660]   One thing, which was a theory that, that you heard from some people around Trump and, and, and sort of fit what he said on the campaign trail, which was Trump's position on the campaign trail was that he was going to lay down 10 to 20% tariffs on all imported goods and 65% tariffs on imported goods from China.
[02:36:29.660 --> 02:36:32.880]   So I think that's a bad idea for a bunch of different reasons.
[02:36:32.880 --> 02:36:38.060]   But what that is, is a stable change in the cost structure for all corporations and all trade.
[02:36:38.060 --> 02:36:43.380]   And then different players can make different investment decisions in the longterm based on this new cost structure.
[02:36:43.380 --> 02:36:54.280]   What he's doing is, as Derek said, and I've had these funny experiences where I'm literally doing a podcast with a tariffs expert and I'll be talking about like the auto parts problem.
[02:36:54.280 --> 02:36:59.120]   And then my producer would be like, uh, he just, you know, delayed the tariff on the auto parts.
[02:37:00.160 --> 02:37:05.000]   What he's doing with these tariffs that you move on and you move off and you negotiate over endlessly.
[02:37:05.000 --> 02:37:11.120]   And I've been told this again, by people around him is their view is that America had leverage.
[02:37:11.120 --> 02:37:15.400]   It wasn't using and tariffs in particular are a form of executive control.
[02:37:15.400 --> 02:37:19.300]   Trade deals need to be negotiated and ratified with Congress.
[02:37:19.300 --> 02:37:25.020]   Trade deals are, are, are something you have to do with the rest of the system, but tariffs are something Trump can do unilaterally.
[02:37:25.020 --> 02:37:26.660]   And one thing Trump wants is control.
[02:37:26.660 --> 02:37:30.080]   That is the through line of virtually everything in his politics.
[02:37:30.080 --> 02:37:33.060]   Tariffs are a leverage based form of foreign policy.
[02:37:33.060 --> 02:37:33.880]   They are.
[02:37:33.880 --> 02:37:41.480]   America has the biggest economy in the world that anybody who's going to get into a trade war with us is going to suffer worse than we will.
[02:37:41.820 --> 02:37:47.640]   And there's something where the president can use the tariffs because of authority granted by Congress some time ago for other purposes.
[02:37:47.640 --> 02:37:50.500]   He can use them with a huge amount of discretion.
[02:37:50.500 --> 02:37:56.800]   So you can use them on the one hand to say, well, I think that we've lost too much manufacturing and the dollar is undervalued in other places.
[02:37:56.800 --> 02:38:06.580]   And so we want to use tariffs to make the cost structure differently so that people to locate more of the supply chains and the intermediate manufacturing in the United States.
[02:38:06.580 --> 02:38:11.640]   But you can also use a tariff to say Columbia has to take the people we're deporting and they have to take them in chains.
[02:38:11.640 --> 02:38:12.580]   Right.
[02:38:12.660 --> 02:38:14.160]   And Donald Trump is doing both things.
[02:38:14.160 --> 02:38:21.360]   And the reason I think it's important to keep those in mind is that what Donald Trump wants, what connects a lot of different things, is that he wants leverage over things.
[02:38:21.360 --> 02:38:23.400]   He wants I think it connects to Eric Adams.
[02:38:23.400 --> 02:38:25.040]   And you were sitting here talking in New York City.
[02:38:25.040 --> 02:38:28.540]   Eric Adams is a Democratic mayor.
[02:38:28.540 --> 02:38:29.280]   Right.
[02:38:29.280 --> 02:38:31.760]   Donald Trump is no truck with Eric Adams.
[02:38:31.760 --> 02:38:32.040]   Right.
[02:38:32.040 --> 02:38:33.260]   He did not support Eric Adams.
[02:38:33.260 --> 02:38:34.980]   Eric Adams is not his natural ally.
[02:38:35.260 --> 02:38:42.580]   But what he had over Eric Adams, he realized, was a leverage that he could get the cases off of Eric Adams and then get Eric Adams in his pocket.
[02:38:42.580 --> 02:38:58.180]   So Donald Trump stepped in to save like the like the Democrat, the corrupt Democratic mayor of New York City, because not because they have a deep ideological alliance, but because then Donald Trump would have power over New York City and its policy that he wouldn't otherwise have.
[02:38:58.180 --> 02:39:01.380]   The thing that connects Trump, Trump is a very old school politician.
[02:39:01.380 --> 02:39:02.680]   He's very relational.
[02:39:02.680 --> 02:39:04.140]   He's very 19th century.
[02:39:04.500 --> 02:39:05.680]   He's looking for the angle.
[02:39:05.680 --> 02:39:07.020]   He's very zero sum.
[02:39:07.020 --> 02:39:08.600]   He's looking for things to give him power.
[02:39:08.600 --> 02:39:10.840]   Doge is a way of getting power over the bureaucracy.
[02:39:10.840 --> 02:39:16.680]   Tariffs are a way of getting power over the international financial system and foreign policy and breaking sort of traditional alliances.
[02:39:16.680 --> 02:39:28.220]   Maybe in his mind, even getting Canada to become the 51st state, maybe getting Mexico to change its immigration policy, use trying to weaponize the Justice Department against Eric Adams as a way of getting power over Democratic mayor.
[02:39:28.220 --> 02:39:34.000]   Some of what they're doing with grants and money is a way of getting power over sort of other institutions in American life.
[02:39:34.600 --> 02:39:38.620]   Again, you could think it's bad or you could think it's good, but it is coherent, right?
[02:39:38.620 --> 02:39:40.680]   I think it's bad, but it is coherent.
[02:39:40.680 --> 02:39:43.480]   And the people who think it's good think it's good for Trump to have power.
[02:39:43.480 --> 02:39:46.560]   Again, with the Eric Adams thing, they were very explicit about this, right?
[02:39:46.560 --> 02:39:56.840]   They said that it is worthwhile for the president to negotiate over his policy objectives and to trade things to get his policy objectives more fully carried out.
[02:39:56.840 --> 02:40:02.080]   And so Eric Adams went from saying New York City would be a sanctuary city to they'd aggressively carry out deportations.
[02:40:02.080 --> 02:40:04.820]   You can think that kind of transactionalism is fine.
[02:40:04.900 --> 02:40:08.720]   I think in this case, given that it's about corruption, it wasn't.
[02:40:08.720 --> 02:40:19.220]   But the idea, Trump's idea, that the problem is that the president doesn't wield enough power here the way he does in Russia, the way he might in India, the way he might in China.
[02:40:19.380 --> 02:40:23.300]   And Trump has spoken very openly of envying some of the powers these other people have.
[02:40:23.300 --> 02:40:28.240]   I think it's a consistent governing philosophy that needs to be taken as that, right?
[02:40:28.240 --> 02:40:35.700]   I think sometimes you describe one of the difficulties Trump poses is sometimes if you just describe what he's doing, I think, quite neutrally.
[02:40:35.980 --> 02:40:39.080]   People say, oh, you're criticizing him, you're anti-Trump.
[02:40:39.080 --> 02:40:42.740]   But I'm just describing what he's doing.
[02:40:42.740 --> 02:40:52.140]   You can think it's good or it's bad, but the fact that he wants to arrogate power and find points of leverage and tariffs are one, what he's doing through Doge is another, what he did with the DOJ is another.
[02:40:52.140 --> 02:40:54.200]   It's all very consistent.
[02:40:54.200 --> 02:41:00.420]   The question is really then just whether or not you have what your normative view is on Trump having that much power.
[02:41:00.840 --> 02:41:19.500]   Yeah, I have a question about DOJ, but before that, I'll just say that I don't think Donald Trump should have that much power because I think to this day, my biggest criticism and concern is that he is a person that denied the results of the election.
[02:41:19.500 --> 02:41:26.560]   And so I'm unwilling, you know, I like George Washington.
[02:41:27.000 --> 02:41:42.060]   I like people that have the skill, the ability, the track record to walk away from power and a person who is unwilling to accept reality and is willing to bend reality to maintain a grip on power.
[02:41:42.060 --> 02:41:49.180]   Even if what they're trying to do is really good, maybe making a government more efficient makes me very concerned.
[02:41:49.380 --> 02:42:09.280]   But on the topic of DOJ is more on the Elon side, if we can sort of combine DOJ and abundance as a topic, if DOJ succeeds, the effort, let's just forget DOJ, but the effort of making government more efficient, what does that look like before the next election and after the next election?
[02:42:09.280 --> 02:42:12.120]   If we can just look at success.
[02:42:12.280 --> 02:42:14.980]   I know I'm jumping again, but I'll do something quick and then pass to you.
[02:42:14.980 --> 02:42:30.280]   I, from my, I'm not a huge fan of the experiment framing because amidst this experiment, people are through USAID, as my colleague Nick Kristof has documented and potentially further in other ways will die, lose homes, be scammed by things.
[02:42:30.360 --> 02:42:47.000]   So I'm, I feel like experimenting with the government at that level is very dangerous, but if, assuming democracy survives, um, Democrats, if they're going to make the government work again, are going to have to become less rule bound than they were.
[02:42:47.720 --> 02:42:51.440]   I have this line that the problem with the personality type of the right is it's autocratic now.
[02:42:51.440 --> 02:42:54.080]   And the problem with the personality type of the left is it's bureaucratic.
[02:42:54.080 --> 02:43:02.820]   And I don't want to see things going either to where DOJ is in terms of, I think there's a fundamental lawlessness to it, but I also don't like the aims of it.
[02:43:03.160 --> 02:43:14.360]   But I don't want to see things where Democrats were, which is such unfathomably, which is such respect for process that they will put the process ahead of getting their own things done.
[02:43:14.360 --> 02:43:20.500]   They will listen to any lawyer with any super intense interpretation of any law, and that'll turn them all the way back.
[02:43:20.640 --> 02:43:31.940]   What DOJ has demonstrated is that the room for movement inside the American government, inside the state, is much wider than anybody gave it credit for, both Republican and Democratic administrations.
[02:43:31.940 --> 02:43:33.480]   It may not be as wide.
[02:43:33.480 --> 02:43:37.980]   It probably isn't legally as wide as what DOJ is trying to do, and that's why they're losing all these court cases.
[02:43:37.980 --> 02:43:40.980]   But it is wide, and you could also use Congress, right?
[02:43:40.980 --> 02:43:44.220]   You could pass statute to make it wider, and you should.
[02:43:44.840 --> 02:43:54.400]   There is no abundance agenda that works if the Democratic Party is as rule-bound and as process-obsessed as it was in the last 10 years.
[02:43:54.400 --> 02:43:56.820]   It doesn't work flatly, right?
[02:43:56.820 --> 02:44:09.480]   That is why so many of the stories we tell in the book are about process gone, not just—it's not process gone wrong because it's doing exactly what it was intended to do, but it is process that has become antagonistic to the promised outcomes.
[02:44:10.240 --> 02:44:15.000]   And so I do hope there's a kind of, you know, thesis, right?
[02:44:15.000 --> 02:44:16.600]   All the institutions are great.
[02:44:16.600 --> 02:44:18.280]   Democrats are the defenders of government.
[02:44:18.280 --> 02:44:21.820]   Antithesis, the government is a corrupt cesspool.
[02:44:21.820 --> 02:44:30.200]   It's a, you know, it's a ball of worms, and it has to be destroyed and taken over by a benevolent or non-benevolent dictator.
[02:44:30.200 --> 02:44:37.120]   And synthesis, which is that the government's process has made it not a functional state.
[02:44:37.280 --> 02:44:55.800]   It's non-responsive in many important ways, and it needs to be, like, reformed at a quite fundamental level, but in a way that is lawful, in a way that is thoughtful, in a way that is running experiments, it gathers information and then can make adjustments, in a way that is respectful of the human lives that it touches and affects.
[02:44:56.060 --> 02:45:07.040]   In a way that is not hostile to the goals of good government, but is more committed to them than it is committed to the process the government has erected and evolved over time.
[02:45:07.900 --> 02:45:17.700]   I just articulated the principle beautifully, and just to put some meat on the bones, abundance is about being incredibly concrete about what you want to accomplish in the world.
[02:45:17.700 --> 02:45:25.340]   Then it's about understanding how to accomplish that, a stage of the process that I think Doge has entirely skipped.
[02:45:25.340 --> 02:45:27.660]   I don't think we've reached the stage of understanding.
[02:45:27.660 --> 02:45:33.000]   We've destroyed, and then maybe it's sometimes promised to understand the thing that we've destroyed after the fact.
[02:45:33.800 --> 02:45:37.520]   You want to set goals, you want to understand how to meet those goals, and then you want to meet them.
[02:45:37.520 --> 02:45:44.780]   And the problem with liberalism of the last few years and the last few decades is that we've become disconnected from outcomes.
[02:45:44.780 --> 02:45:46.780]   Really, really crystal clear example.
[02:45:46.780 --> 02:45:58.220]   So Joe Biden in 2021 signs the bipartisan infrastructure law, and he and Pete Buttigieg call it, truthfully, one of the most important infrastructure bills passed in the last few decades.
[02:45:58.360 --> 02:46:03.960]   $1.2 trillion to do exactly what Ezra and I want to do, to build in the world.
[02:46:03.960 --> 02:46:12.280]   There's a piece of that law that's a $42 billion program called BEAD, which stands for Broadband Equity Access and Deployment, I think.
[02:46:12.280 --> 02:46:15.000]   $42 billion to build rural broadband.
[02:46:15.000 --> 02:46:18.620]   Fast forward to 2024, practically none of it is built.
[02:46:18.620 --> 02:46:23.440]   We're now four calendar years after it was passed, and the program is, at this point, it seems like it's going to die,
[02:46:23.440 --> 02:46:25.620]   and they're just going to transfer the whole thing to Starlink.
[02:46:26.140 --> 02:46:27.340]   So why, right?
[02:46:27.340 --> 02:46:35.560]   We want to understand why does government fail to achieve its outcomes, and how can we learn from those failures to allow government to succeed at its outcomes?
[02:46:35.560 --> 02:46:41.560]   Well, you look into it, and it turns out that in order to take these $42 billion and send it to the states,
[02:46:41.560 --> 02:46:47.260]   the states had to go through a 14-stage process in order to get the money.
[02:46:47.720 --> 02:46:54.920]   First, the FCC had to draw a map of the places where America needed more rural broadband, and then there was a challenge period where people could question the map.
[02:46:54.920 --> 02:46:59.600]   And the FCC would remake the map, and then the challengers would re-sue them to change the map again.
[02:47:00.040 --> 02:47:08.860]   Then the states had to file a letter of intent and a five-year action plan and a funding program, all of which could be subject to their own challenge periods.
[02:47:08.860 --> 02:47:12.540]   And in each of these challenge periods, the Commerce Department is going back to the states and saying,
[02:47:12.620 --> 02:47:20.800]   you really like your five-year plan, but your workforce development program didn't pass this matrix of equity, and you didn't reach out to the right bidders over here.
[02:47:20.800 --> 02:47:29.540]   And if you try harder to reach out to more people who just aren't white men to be your employees, that would be fantastic if you could put that into the new edit that you submit to us.
[02:47:29.780 --> 02:47:35.340]   And of course, there are delays because every state has to do its own programs, the Commerce Department is backed up, yada, yada, yada.
[02:47:35.340 --> 02:47:52.580]   You get to a point where out of 56 states and jurisdictions that have applied to begin the 14-stage process, by the time the Democrats lose the election in November 2024, three out of the 56 have passed all 14 stages,
[02:47:52.580 --> 02:47:58.920]   and very little of the money has actually been spent because of all the problems that Ezra and I discussed about how hard it is to build in the physical world.
[02:47:59.560 --> 02:48:04.760]   $42 billion, therefore, dies upon contact with planet Earth.
[02:48:04.760 --> 02:48:07.760]   That's not government achieving its goals.
[02:48:07.760 --> 02:48:16.700]   And a doge that we were sort of, you know, du-umvrits of in this parallel universe is one that would try very clearly to, A, articulate a goal.
[02:48:16.700 --> 02:48:17.860]   What are we trying to do here?
[02:48:17.860 --> 02:48:20.260]   We're trying to build rural broadband.
[02:48:20.260 --> 02:48:20.740]   Why?
[02:48:20.740 --> 02:48:23.900]   Because we think connectivity is incredibly important to the economy of the future.
[02:48:23.900 --> 02:48:25.220]   It helps people's health.
[02:48:25.220 --> 02:48:27.020]   It helps the economy of rural areas.
[02:48:27.020 --> 02:48:28.500]   Let's build rural broadband.
[02:48:28.680 --> 02:48:30.220]   Two, what are the roadblocks?
[02:48:30.220 --> 02:48:31.700]   What are the bottlenecks?
[02:48:31.700 --> 02:48:40.460]   What's hard about taking a pot of money that exists in Washington and actually creating broadband networks in rural Kentucky?
[02:48:40.460 --> 02:48:43.380]   Let's understand what those roadblocks are so that we can do two things.
[02:48:43.380 --> 02:48:51.160]   We can take away the things that need to be taken away to accelerate the program, and maybe we can add new policies that will accelerate the spending.
[02:48:51.240 --> 02:48:53.580]   Because bottom line, we want to make a difference in the world.
[02:48:53.580 --> 02:48:59.400]   That's a world where government is, to borrow Ezra's language, deregulated itself.
[02:48:59.400 --> 02:49:02.240]   It's easier for the government to achieve its goals.
[02:49:02.980 --> 02:49:17.040]   I think that it's really important at the level of principle here that liberals fall out of love with this procedural fetish that has dominated the left over the last half century and fall back in love with outcomes.
[02:49:17.040 --> 02:49:25.900]   To be ruthlessly obsessed with how liberalism has failed and how these kind of failures aren't just technocratic stories to tell in a podcast.
[02:49:26.420 --> 02:49:35.320]   I think this is fundamental to why Democrats are losing the communications war in an era of anti-establishment and anti-institution.
[02:49:35.320 --> 02:49:43.420]   We find ourselves in a reflexive position of having all the cranks, so to speak, having left the Democratic Party, and we're the ones who defend all institutions.
[02:49:43.420 --> 02:49:44.980]   We're the ones who defend the establishments.
[02:49:44.980 --> 02:49:47.140]   We're the ones saying government can only do good.
[02:49:47.560 --> 02:50:01.920]   But as a result, we lose the ability to talk to people about how government fails and how they can see that failure and how sometimes they're literally leaving cities and states run by Democrats because that failure is so effing obvious to them.
[02:50:01.920 --> 02:50:04.920]   So this isn't just about the BEAD program.
[02:50:04.920 --> 02:50:06.720]   It's not just about 14-step programs.
[02:50:06.720 --> 02:50:07.800]   It's not just about rural broadband.
[02:50:07.800 --> 02:50:11.960]   It really is about a higher-level principle of political communication.
[02:50:12.640 --> 02:50:25.260]   How do you develop a liberalism that, in an age of anti-establishment anger, both reflects that anger and channels it for proactive purposes, by not just doing destruction-destruction, but creative destruction?
[02:50:25.260 --> 02:50:26.860]   So first of all, beautifully put.
[02:50:26.860 --> 02:50:32.580]   And second, the big thing that Doge did is make this a sexy topic to discuss.
[02:50:32.580 --> 02:50:36.700]   And then you can tear down Doge with the way they're doing it, say it's wrong, criticize.
[02:50:36.700 --> 02:50:41.440]   But then people are all of a sudden more and more caring about the efficiency of government.
[02:50:41.940 --> 02:50:47.100]   And educating themselves, learning about it, and it's creating a culture of transparency to the whole thing.
[02:50:47.100 --> 02:50:56.020]   So now you can swoop in with a book like Abundance and describe, here's how to do actually, how to have a clear mission and metrics, how to solve these problems.
[02:50:56.020 --> 02:51:07.480]   But that allows, as opposed to have this culture of process, me personally, one of the things that really frustrates me about this world is that.
[02:51:08.880 --> 02:51:19.280]   The bureaucracy of that kind of process, especially because everybody, at least in the United States, is just all so fucking polite everywhere about the whole thing.
[02:51:19.280 --> 02:51:21.660]   They're all so nice to you as they're doing the process.
[02:51:21.660 --> 02:51:27.960]   About every single thing, they're just like, this is, and then you have to call from nine to five.
[02:51:28.100 --> 02:51:34.320]   There's hours and let's schedule a meeting and three weeks from now to discuss this document so we can have another document.
[02:51:34.320 --> 02:51:43.380]   And all of a sudden, the big dreams and the visions, the hopes that people have invested in building a project that's an incredible project, dies.
[02:51:43.380 --> 02:51:45.020]   It's not just a waste of money.
[02:51:45.020 --> 02:51:49.300]   It's the possibility of a beautiful thing that could have been built, never gets built.
[02:51:49.860 --> 02:51:57.140]   You're retracing Ezra's lovely line about how the character of the right these days is autocratic and the character of the left can be overly bureaucratic.
[02:51:57.140 --> 02:52:04.840]   I hope there's a middle synthesis lane here where there's a political identity that believes in efficient bureaucracies.
[02:52:04.840 --> 02:52:08.220]   Sometimes it actually does take a lot of people to get certain things done.
[02:52:08.220 --> 02:52:12.460]   But you really, I think, need to have an eye toward institutional reform.
[02:52:12.580 --> 02:52:26.900]   This is a theme of our book that we haven't talked about as much yet, but I think it's so important for abundance to believe that each generation adopts, is passed down, institutions that were created for different eras, different decades to solve different problems.
[02:52:26.900 --> 02:52:39.780]   That's how you get an environmental revolution in the 1960s that solves the problem of dirty air and dirty water, but leaves us with a set of norms like NEPA that make it impossible to add clean energy in our generation.
[02:52:39.780 --> 02:52:43.160]   Just a tragedy of unintended outcomes.
[02:52:43.160 --> 02:52:52.100]   And to narrow this down to a world that I know you care a lot about, there's a chapter in our book about science policy and the history of the NIH.
[02:52:52.100 --> 02:53:01.940]   The NIH really comes into its own after World War II, and it is immediately this beautifully funded crown jewel of biomedical research.
[02:53:01.940 --> 02:53:09.320]   Just the federal government irrigating university researchers studying cancer and heart disease and brain science and everything else.
[02:53:09.400 --> 02:53:17.180]   I mean, practically every single scientific breakthrough in the U.S. in the last 70 years at least bears the fingerprints of NIH.
[02:53:17.180 --> 02:53:19.300]   But the NIH is also a bureaucracy.
[02:53:19.300 --> 02:53:30.560]   And like every bureaucracy, it has accumulated a set of processes and habits that the people most affected by it, scientists in America, told us and will tell anybody else who's listening, has flaws.
[02:53:30.980 --> 02:53:41.620]   According to some surveys, 40% of the time that scientists are working today in America, they are filling out grants and doing paperwork, not doing science.
[02:53:41.760 --> 02:53:43.000]   That is astonishing.
[02:53:43.000 --> 02:53:58.580]   I mean, as we say in the book, imagine if we discovered that one year there was a virus that broke out in the American academic scene such that our scientists suffered from chronic fatigue disorder between January and June every single year.
[02:53:58.580 --> 02:53:59.620]   They just couldn't work.
[02:53:59.620 --> 02:54:01.400]   We'd be like, this is an absolute Shonda.
[02:54:01.400 --> 02:54:02.600]   We have to fix this problem.
[02:54:03.100 --> 02:54:04.120]   This problem exists.
[02:54:04.120 --> 02:54:05.600]   It's our own bureaucratic rules.
[02:54:05.600 --> 02:54:08.640]   It's the rules that we wrote that's slowing down science.
[02:54:08.640 --> 02:54:09.740]   So what should we do?
[02:54:09.740 --> 02:54:11.900]   I don't think we should tear down the NIH.
[02:54:11.900 --> 02:54:16.640]   I don't think we should slash and burn grants as we're currently doing in the administration.
[02:54:17.120 --> 02:54:21.560]   I think we should understand what's broken and be clear about our desired outcomes.
[02:54:21.560 --> 02:54:33.660]   My desired outcome for science is that we produce and pursue high-risk, high-reward science under the theory that almost no important breakthrough is going to be obvious before you discovered it.
[02:54:33.660 --> 02:54:35.420]   If it's obvious, you probably already knew it.
[02:54:35.420 --> 02:54:36.600]   So why is it some new science?
[02:54:36.600 --> 02:54:43.760]   You should want to incentivize scientists to ask their biggest, most curious questions in a high-risk, high-reward environment.
[02:54:43.760 --> 02:54:45.640]   And right now, the NIH doesn't do that.
[02:54:46.300 --> 02:54:54.280]   The NIH, for a variety of reasons, whether it's aspects of the peer-review process or just assumptions that scientists have of the system, is too incrementalist.
[02:54:54.280 --> 02:55:00.060]   It funds older researchers, and it wastes a lot of scientists' time with bureaucratic paperwork and kludge.
[02:55:00.060 --> 02:55:01.620]   We'd love to reform it.
[02:55:01.620 --> 02:55:03.000]   We have ideas for reforming it.
[02:55:03.000 --> 02:55:15.860]   But if liberals don't use the language of and act on institutional reform, we will allow institutions to grow old and sclerotic and piss off Americans.
[02:55:15.860 --> 02:55:20.820]   And they'll vote for people who come in with a wrecking ball to tear it down, right?
[02:55:20.820 --> 02:55:30.320]   So that's why I think it's so important for abundance liberals like us to be very clear about our goals, our outcomes, and exactly what we want to accomplish.
[02:55:30.320 --> 02:55:36.480]   Because I think that's the only way to really see how and why institutions that are all around us truly do need reform.
[02:55:36.480 --> 02:55:40.760]   Listen, I hope your book becomes the manifesto of the Democratic Party.
[02:55:40.760 --> 02:55:42.060]   It's a beautiful vision.
[02:55:42.420 --> 02:55:49.140]   I'm a little bit skeptical because of the momentum of bureaucratic thought, but I nevertheless remain hopeful.
[02:55:50.340 --> 02:55:55.480]   I have to ask, because I'm a fan of both of you in the interest of time, Ezra.
[02:55:57.560 --> 02:56:02.660]   You had an intense debate many years ago with Sam Harris.
[02:56:02.660 --> 02:56:03.800]   Okay.
[02:56:03.800 --> 02:56:08.300]   So you're, I would say, like I said, I'm a fan of both of you.
[02:56:08.300 --> 02:56:10.200]   You're both intellectually rigorous people.
[02:56:10.520 --> 02:56:19.060]   So it was, the debate, the contentiousness of it was both sad to me, but also just a fan of you.
[02:56:19.060 --> 02:56:23.340]   And since I admire your intellects, it's just fun to watch.
[02:56:23.920 --> 02:56:24.740]   What is it?
[02:56:24.740 --> 02:56:27.120]   Godzilla and King Kong fight.
[02:56:27.120 --> 02:56:29.460]   I wish there was more of it.
[02:56:29.460 --> 02:56:33.800]   I wish you would do this podcast again and debate it more on some other topic and argue.
[02:56:33.800 --> 02:56:34.420]   It's just great.
[02:56:34.420 --> 02:56:38.980]   Anyway, you know, some time has passed.
[02:56:38.980 --> 02:56:41.220]   What was this, eight years ago now?
[02:56:41.220 --> 02:56:42.560]   Yeah.
[02:56:42.560 --> 02:56:43.980]   2018-ish, something there.
[02:56:43.980 --> 02:56:44.560]   Yeah.
[02:56:44.560 --> 02:56:46.800]   The battles you have fought over the years.
[02:56:46.800 --> 02:56:48.560]   A lot of chapters.
[02:56:48.560 --> 02:56:49.480]   A lot of chapters.
[02:56:49.480 --> 02:56:49.800]   Yeah.
[02:56:49.800 --> 02:56:52.360]   This is like several chapters ago.
[02:56:53.140 --> 02:57:00.040]   But, you know, in the interest of camaraderie, what do you admire most about Sam Harris?
[02:57:00.040 --> 02:57:01.480]   Oh, that's not a hard question.
[02:57:01.480 --> 02:57:06.300]   If you go back, if you listen to that debate on my show at Vox, I introved that debate by saying,
[02:57:06.300 --> 02:57:12.020]   look, I disagree with Harris on like this specific conversation he had with Charles Murray about race and IQ.
[02:57:12.020 --> 02:57:13.780]   But he's good on meditation.
[02:57:13.780 --> 02:57:15.700]   He's good on psychedelics.
[02:57:15.700 --> 02:57:17.020]   He's good on consciousness.
[02:57:17.020 --> 02:57:17.680]   He's good.
[02:57:17.680 --> 02:57:19.840]   I don't know if I said AI back then, but I think he's good on AI.
[02:57:20.480 --> 02:57:30.180]   I always felt in that without going like back into the Wayback Machine that Sam really thought like he really somehow got where I was wrong.
[02:57:30.180 --> 02:57:33.600]   And I thought I offered like a lot of like tries for de-escalation.
[02:57:33.760 --> 02:57:37.760]   And you can he did me weirdly the favor of publishing our whole email correspondence.
[02:57:37.760 --> 02:57:41.300]   I think if you read that, you can see that like I was not angling for a fight here.
[02:57:41.300 --> 02:57:47.280]   What I admired about him since I think the thing that he's been good on is he's been very independent.
[02:57:47.980 --> 02:57:53.380]   So Sam at that time, there was sort of the emergence around then of this thing that people then called the intellectual dark web.
[02:57:53.380 --> 02:57:58.040]   And it was like Sam and the Weinstein brothers and Ben Shapiro.
[02:57:58.040 --> 02:58:00.260]   And I forget who was part of it.
[02:58:01.260 --> 02:58:05.540]   And as a bunch of those people, I think, I mean, it kind of split up over time.
[02:58:05.540 --> 02:58:18.560]   But Harris has done a good job not falling into conspiracy as the Weinstein brothers did, not letting his anger at the left blind him to the failures of the right.
[02:58:19.100 --> 02:58:25.340]   He's a guy, you know, I guess both for better and for worse, as we all are, but he is perfectly willing to stand alone in a crowd.
[02:58:25.340 --> 02:58:31.480]   Like I haven't listened to that much of his stuff lately, but my sense is he's been like quite clear eyed from my perspective on Donald Trump.
[02:58:31.480 --> 02:58:35.620]   So I don't think Sam, my view is not that Sam Harris is in general a bad actor.
[02:58:35.620 --> 02:58:36.780]   It just isn't.
[02:58:36.780 --> 02:58:48.380]   Yeah, he's been like difficult to categorize and fearless about it, meaning like he doesn't, he deliberately resists audience capture.
[02:58:48.380 --> 02:58:50.060]   So yeah, which is a hard thing to do.
[02:58:50.060 --> 02:58:55.040]   I think I saw a clip of him on this show sort of like going after Trump and it became like a big whole thing.
[02:58:55.040 --> 02:58:55.440]   Yeah.
[02:58:55.440 --> 02:58:57.820]   I mean, he's been very consistent on that.
[02:58:57.820 --> 02:59:00.780]   Let's, let's try to find the interesting thing here.
[02:59:00.780 --> 02:59:04.860]   I actually had a while back a podcast with Richard Heyer.
[02:59:04.860 --> 02:59:15.100]   He studies intelligence and it was a very detailed non-policy discussion about IQ tests and all that kind of stuff.
[02:59:15.240 --> 02:59:16.700]   And there I did.
[02:59:16.700 --> 02:59:23.660]   I tried extremely hard to be very nuanced because that felt like an uncomfortable topic back then.
[02:59:23.660 --> 02:59:25.560]   It doesn't feel so uncomfortable now.
[02:59:25.560 --> 02:59:28.500]   Do you think the Overton window has expanded?
[02:59:28.500 --> 02:59:31.820]   Do you think the kind of things we're willing to talk about now?
[02:59:32.020 --> 02:59:34.460]   I mean, this has to do with the Trump moment also.
[02:59:34.460 --> 02:59:42.720]   I think the place where the topic seems to me to have changed in my ambient awareness of it is two things.
[02:59:42.720 --> 02:59:49.480]   One is a sense of the Flynn effect, which is, yeah, it's hard to individually change your IQ, but there is a very well-documented effect.
[02:59:49.540 --> 02:59:51.760]   And I talked to James Flynn before I talked to Sam.
[02:59:51.760 --> 02:59:56.600]   There is a very well-documented effect where IQs have been rising over time.
[02:59:56.600 --> 02:59:59.000]   There's good evidence now that that has stopped.
[03:00:00.820 --> 03:00:04.080]   Again, this is ambiently my sense, right?
[03:00:04.080 --> 03:00:05.840]   I've read some things like in passing.
[03:00:05.840 --> 03:00:06.680]   I have not.
[03:00:06.680 --> 03:00:10.360]   I did not come to this podcast preparing to talk about IQ or I would have prepared very carefully.
[03:00:10.360 --> 03:00:13.240]   And then there was an interesting FT article just the other day.
[03:00:13.240 --> 03:00:15.340]   It was like, have we passed peak human intelligence?
[03:00:16.280 --> 03:00:21.300]   And my sense is not is that that wasn't about IQ, although, again, like I don't remember exactly what was in it.
[03:00:21.300 --> 03:00:23.780]   I kind of glanced at it and put it aside to read more later.
[03:00:23.780 --> 03:00:27.720]   But that literacy scores are going down and a number of test scores are going down.
[03:00:27.720 --> 03:00:37.000]   And the sort of sense of the piece was that we are making ourselves stupider by endlessly staring at screens and social media, which I think is probably right.
[03:00:37.000 --> 03:00:44.880]   I've had this sort of line since becoming aware of that piece in my head that we spend a lot of time talking about how to get smarter
[03:00:44.880 --> 03:00:48.020]   and not enough time talking about how to avoid getting dumber.
[03:00:48.020 --> 03:00:51.740]   But we do a lot of things that a lot of things that we think make us smarter.
[03:00:51.740 --> 03:00:57.420]   Like I would say having social media on our phones because like, oh, you're getting all this information all the time that in fact make us dumber.
[03:00:57.420 --> 03:01:05.140]   Because it's not just that the information is bad, but the lack of concentration, the constant distraction, the sort of lack of focus.
[03:01:05.140 --> 03:01:09.620]   And so my sense is that there is a different kind of conversation here.
[03:01:09.620 --> 03:01:14.420]   I'm not sure it's really an IQ conversation, but that there is a sense that we are.
[03:01:14.420 --> 03:01:22.620]   inflicting a possibly global, certainly societal, cognitive wound on ourselves, right?
[03:01:22.620 --> 03:01:24.580]   That's what John Height's book is a little bit about, right?
[03:01:24.580 --> 03:01:26.680]   That's sort of more coming at it from a behavioral standpoint.
[03:01:26.680 --> 03:01:30.760]   But we have, you know, the Flynn effect reflects, right?
[03:01:30.820 --> 03:01:33.120]   This is how James Flynn would describe it.
[03:01:33.120 --> 03:01:39.580]   The Flynn effect reflects societies putting on, as he, I think, put it, the scientific spectacles.
[03:01:39.580 --> 03:01:45.800]   You create societies where we prize things like reading, abstract intelligence, symbolic logic.
[03:01:45.800 --> 03:01:49.660]   You teach people and them a lot, and we get better and better and better at doing it.
[03:01:49.660 --> 03:01:51.720]   And I mean, reading changes the brain.
[03:01:51.720 --> 03:01:53.520]   It changes the physical structure of the brain.
[03:01:53.600 --> 03:01:58.440]   You're hijacking parts of the mind meant for other purposes to do this kind of interpretive work.
[03:01:58.440 --> 03:02:10.520]   But it's, of course, possible just as we became societally connected and then made more and more widespread technologies like literacy that changed our brains and led to the increase in this thing we call G, right?
[03:02:10.520 --> 03:02:11.100]   G intelligence.
[03:02:11.100 --> 03:02:13.080]   And decreases in other things, right?
[03:02:13.080 --> 03:02:24.520]   Like, I'm really shitty at knowing which direction I'm going into this sort of part of my brain that does navigation is terribly atrophied compared to somebody in a more, in a society that did not have Google Maps.
[03:02:24.520 --> 03:02:28.680]   It's entirely possible to go too far in that, right?
[03:02:28.680 --> 03:02:32.200]   It's entirely possible to move on to technologies to begin to weaken that.
[03:02:32.200 --> 03:02:37.960]   I have this concern very profoundly about AI, by the way, which obviously you have a lot of your roots in.
[03:02:38.680 --> 03:02:45.460]   And there are parts of AI I'm very optimistic about, but my biggest concern about AI is we're going to make ourselves much stupider without realizing it.
[03:02:45.460 --> 03:02:58.100]   Because the things that are easy to automate in AI, which is like getting the AI to summarize the reading of something or getting AI to write the first draft of something, that's where all the intelligence happens, in my view.
[03:02:59.040 --> 03:03:07.920]   I think, you know, one advantage I have over a lot of other podcast hosts who superficially do what I do, probably this is true for you, I'm sure this is true for you, I know, is that I really do do the reading.
[03:03:07.920 --> 03:03:17.620]   No summary is equivalent to me doing the reading and sitting there and making the associations myself and spending the time in the book and then like sort of thinking about what it brought up in me.
[03:03:17.960 --> 03:03:19.380]   I write the first draft.
[03:03:19.380 --> 03:03:22.220]   ChatGPT cannot write the first draft of my book.
[03:03:22.220 --> 03:03:24.460]   The first draft is fucking hard to write.
[03:03:24.460 --> 03:03:29.080]   And it's often hard because it's completely wrong, but not because it's narrowly wrong, right?
[03:03:29.080 --> 03:03:34.140]   ChatGPT will never tell you the problem with what you're trying to do is you're just trying to do the wrong thing.
[03:03:34.140 --> 03:03:36.420]   It'll never tell you if you tell it to write a first draft.
[03:03:36.420 --> 03:03:38.660]   That's the wrong direction for this draft.
[03:03:38.660 --> 03:03:40.760]   Some part of you has to know it.
[03:03:40.760 --> 03:03:44.840]   And often the problem is you just haven't done enough reporting, haven't done enough research.
[03:03:44.840 --> 03:03:46.380]   And ChatGPT can't tell you that either.
[03:03:46.940 --> 03:04:06.720]   And my worry for my kids, my worry for society is creating technologies that make it incredibly alluring to automate the part of creation that is most difficult, most laborious, and most likely to lead to genuine insight and the sort of sharpening of your own mental acuity.
[03:04:06.720 --> 03:04:11.880]   I mean, we better fucking hope the AIs can autonomously make innovations because we're going to stop.
[03:04:11.880 --> 03:04:14.020]   I really worry we're going to stop being able to.
[03:04:14.260 --> 03:04:20.760]   Yeah, I definitely think, and all of that is brilliantly put, I definitely think that social media is making me dumber.
[03:04:20.760 --> 03:04:31.000]   If I spend a week checking social media versus reading books, I'm just distinctly the quality of my thoughts.
[03:04:31.540 --> 03:04:36.740]   Even the same content, I don't read things anymore as much as I can on a screen.
[03:04:36.740 --> 03:04:39.680]   I print everything out and I sit at a table and I read it.
[03:04:39.680 --> 03:04:44.200]   I can read it on my iPad, I can read it on my laptop, I print it all out because my attention is different.
[03:04:44.200 --> 03:04:55.760]   And the same goes for AI, whether we're talking about this kind of research, it's more distinct and rigorous in the other space that I do every single day is programming.
[03:04:56.480 --> 03:05:03.720]   I'm definitely becoming a worse programmer by using AI, offloading, because it actually works really well there.
[03:05:03.720 --> 03:05:18.880]   I'm becoming worse at creative thinking at what you're saying, writing the first draft, which require that skill, that first little leap, that little mini leap into the creative genius that we all do every single day.
[03:05:19.820 --> 03:05:23.600]   AI is not able to do that, and it's definitely dulling that.
[03:05:23.600 --> 03:05:26.540]   All right, we covered a lot of ground today.
[03:05:26.540 --> 03:05:46.580]   On the note of optimism, what gives you hope about the future of this great nation of ours, the future of America, looking out in the next few years, in the next few decades, centuries, when we colonize the solar system and beyond?
[03:05:46.580 --> 03:05:49.160]   Or we could just stick to the next couple of decades.
[03:05:49.160 --> 03:05:49.540]   Sure.
[03:05:49.540 --> 03:06:03.340]   Despite the fact that our book is a deep diagnosis of modern liberalism, with a ton of criticism of the last half decade in politics, I am, at root, a profound optimist about everything.
[03:06:03.340 --> 03:06:07.340]   Just at a general personality sense, right?
[03:06:07.340 --> 03:06:18.500]   To a certain extent, a question like this is attempting to elicit a little bit of what can be considered analysis of the world, but you're also eliciting what is fundamentally like personality, right?
[03:06:18.500 --> 03:06:19.160]   Yeah.
[03:06:19.160 --> 03:06:20.620]   Like what makes you optimistic?
[03:06:20.620 --> 03:06:23.980]   I've just always been a real optimist.
[03:06:25.600 --> 03:06:33.780]   I'm optimistic about science and technology, especially in the realm of biomedical science in a big way.
[03:06:33.780 --> 03:06:57.660]   I think if you look at what's happening right now in mRNA cancer vaccines, in CAR T cell therapy for redesigning T cells to attack cancers, if you look at the GLP-1 drug revolution and some of these studies that have been done on the fact that GLP-1 drugs, while they were initially synthesized from lizard venom to help people with type 2 diabetes, turn out to have these effects that seem to reduce body-wide inflammation.
[03:06:58.440 --> 03:07:09.860]   That not only rewires our minds and makes it easier for people's desired sense of moderation to be actualized, so people who want to eat more fruits and vegetables seem to find it easier to eat more fruits and vegetables when they're on GLP-1 drugs.
[03:07:10.100 --> 03:07:26.260]   But also because there's probably a lot of neurological issues that are fundamentally issues of inflammation, including maybe dementia and Alzheimer's, we might have accidentally, from the tongue of a lizard, a partial medicine for Alzheimer's disease.
[03:07:26.760 --> 03:07:38.840]   The ability of science to connect these dots in the cosmos just absolutely thrills and fascinates me, and I hope that we get better at making those connections.
[03:07:38.840 --> 03:07:53.760]   And while I have a lot of fears about AI, many of them shared by Ezra, I am really interested in the possibility of AI being useful for synthesizing large bodies of knowledge to allow people to make cross-domain comparisons.
[03:07:53.760 --> 03:08:01.380]   I think a lot of inventions in tech history are essentially ingenious recombinations of ideas.
[03:08:01.380 --> 03:08:07.520]   To a certain extent, you look at something as fundamental or archetypal as Thomas Edison inventing the incandescent light bulb.
[03:08:07.520 --> 03:08:08.140]   What did he do?
[03:08:08.140 --> 03:08:16.160]   He just tested 10,000 different materials and figured out that actually it was like a very special kind of bamboo that burned for the right amount of time and said, boom, I did it.
[03:08:16.220 --> 03:08:18.340]   I made the incandescent light bulb.
[03:08:18.340 --> 03:08:45.600]   The ability to have a machine or accelerate the degree to which we understand what those 10,000 materials can do or synthesize knowledge so people can combine it and say, we're going to take a little bit of CRISPR over here and a little bit of cancer science over here to develop a gene therapy that targets a particular inhibitor that allows the immune system to attack a protein that is explicitly related to pancreatic cancer.
[03:08:45.600 --> 03:08:49.960]   I do absolutely believe that we might be on the doorstep of those kind of breakthroughs.
[03:08:49.960 --> 03:08:55.620]   And that makes me incredibly optimistic because I think at base, it's like, you know, what's life about?
[03:08:55.620 --> 03:08:56.500]   Right.
[03:08:56.500 --> 03:08:57.580]   What's abundance about?
[03:08:57.580 --> 03:08:59.180]   Why housing and energy?
[03:08:59.180 --> 03:09:01.360]   Well, because we think they're fundamental to living a good life.
[03:09:01.360 --> 03:09:05.440]   You need a place to live and people deserve the freedom to live where they want to live.
[03:09:06.440 --> 03:09:23.380]   Energy is what powers the entire economy and more energy would power technologies that we can't even imagine or just be getting to, whether it's supersonic flight powered by clean fuel or fusion technology that basically gives us infinite solar energy, the sun's actual energy in a particular location.
[03:09:23.920 --> 03:09:27.640]   I mean, these are beautiful things that can happen.
[03:09:27.640 --> 03:09:31.060]   But also, I think the good life is about is about health.
[03:09:31.060 --> 03:09:39.480]   It's about health and it's about the wealth that comes and the freedom that comes from from finding health in your own life.
[03:09:39.600 --> 03:09:52.600]   And I do I am incredibly optimistic that we might be at the cusp of a real golden age in taking all these little ingredients that we've spent decades on, whether it's genomics and proteomics and a little bit of AI.
[03:09:52.760 --> 03:10:05.620]   We're at the at a moment right now, I hope we can have this explosion of combinatorial intelligence and that hopefully in an optimistic way, AI could be useful in accelerating us toward that future.
[03:10:05.620 --> 03:10:10.220]   But I also think to the point of this book, we have to get institutions right, too.
[03:10:10.220 --> 03:10:17.440]   These are discoveries that are going to happen inside of institutions and how those institutions work and how they're funded.
[03:10:17.640 --> 03:10:23.640]   And the incentives that are created by law or by technology really matter in terms of the world that we build.
[03:10:23.640 --> 03:10:36.500]   And so that's why I think it's really important to not only be obsessed with what the technology can do, but how it's instantiated in the institutions that we have, because it ultimately is institutions and individuals that build the world, not technology acting on its own.
[03:10:36.500 --> 03:10:43.340]   Yeah, and I should say that you make a really great case for investing in weird science, meaning stuff that doesn't on the surface make sense.
[03:10:43.340 --> 03:11:06.360]   We said lizard venom, you know, there's all this popular criticism of scientific projects that sound like a waste of money, when in reality, at least in the scientific realm, projects that seem like they don't have any positive effect might actually end up being the ones that transform human civilization as we know it, because of the unintended discoveries that happen.
[03:11:06.360 --> 03:11:18.280]   And all the eureka moments, all the special discoveries happen, truly, when you're just passionately pursuing a cool thing in science, that's how scientific minds work.
[03:11:18.280 --> 03:11:26.920]   And so it makes sense to invest in things that, in exploring weird shit, the weird mysteries of the universe.
[03:11:27.300 --> 03:11:29.920]   So anyway, Ezra, what gives you hope?
[03:11:29.920 --> 03:11:34.540]   I'm a less temperamentally honest person than Derek, by a lot, actually.
[03:11:34.540 --> 03:11:41.160]   And I would usually give a pretty similar answer to this question that Derek gave, which is, you know, technological advancement, right?
[03:11:41.160 --> 03:11:43.120]   We live in an age of marvels.
[03:11:43.120 --> 03:11:48.580]   I guess I'll say from the realist perspective that we live in a more liquid moment than many.
[03:11:49.300 --> 03:12:01.520]   That, you know, if one of the advantages of the 90s of, you know, much of the life that I have grown up in is that much of the structure of technology of global governance was fairly stable.
[03:12:01.520 --> 03:12:10.120]   We could sort of like look at it and there were certain, not certainties, but fairly reliable guardrails of what was and what wasn't going to happen.
[03:12:10.120 --> 03:12:13.580]   And there were disruptions like 9-11 and the financial crisis.
[03:12:13.580 --> 03:12:16.400]   They weren't small and slowly they broke that entire system.
[03:12:17.360 --> 03:12:25.840]   But there, you know, I think one of the things people sort of miss, sort of feel about the way history is accelerated is that things have just all gotten faster and less predictable.
[03:12:25.840 --> 03:12:27.980]   And they really have, I think, gotten faster and less predictable.
[03:12:27.980 --> 03:12:35.660]   We're in an age, it seems to be more like the early 20th century, late 19th century than like the 1990s.
[03:12:35.660 --> 03:12:41.560]   And that means the possibilities range very widely, right?
[03:12:41.560 --> 03:12:58.980]   When you think about AI, when you think about biotech advances, when you think about energetic advances, when you think about the sort of shifting nature of global alliances, of the technological and political systems, we are in the most high variance period that I think has happened in a very, very, very long time.
[03:12:59.540 --> 03:13:02.080]   And that carries tremendous peril.
[03:13:02.080 --> 03:13:06.920]   Things could go terribly, and it carries tremendous possibility, right?
[03:13:06.920 --> 03:13:10.020]   What if AI is an incredible boon for humanity?
[03:13:10.020 --> 03:13:23.200]   What if we do invent and deploy the clean energy technologies that deliver energy abundance, not just a kind of answer to the worst of climate change, but genuine energy abundance, unlocking new things like mass desalination.
[03:13:23.200 --> 03:13:29.460]   And, you know, like what if we do, like I'm an animal suffering person, I'm a vegetarian, I care a lot about animal suffering.
[03:13:29.500 --> 03:13:41.080]   What if we did figure out cultivated meat, right, that we grow in, you know, breweries and on scaffolds, and we don't have to kill tens of billions of animals that we have raised in unimaginable suffering every single year, right?
[03:13:41.080 --> 03:13:45.480]   Like, you know, what if we do figure out how to make government better and more responsive, right?
[03:13:45.480 --> 03:13:48.760]   What if that thesis, antithesis, synthesis thing does work out?
[03:13:49.340 --> 03:13:57.560]   But it's not hope, it's like, that's a future you have to create, a future you have to call into being, a future you'll have to fight for.
[03:13:57.560 --> 03:14:13.660]   So it isn't so much that I found myself hopeful about what America or the world would be like in 2030 or 2040, but I find that I believe in the possibility of enough remarkable outcomes that it makes like the present really worth being engaged in.
[03:14:13.660 --> 03:14:24.400]   And, you know, really worth trying to, you know, do your small part to bend the arc of the time in the direction that you find more just.
[03:14:24.400 --> 03:14:42.960]   Well, thank you to both of you for fighting for abundance and writing this manifesto for abundance and for all the writing and the work you do in the podcasts and just being incredible minds in this world that I'm a fan of.
[03:14:42.960 --> 03:14:45.080]   So, uh, thank you for talking today.
[03:14:45.080 --> 03:14:46.000]   Thanks very much, Lex.
[03:14:46.000 --> 03:14:46.620]   Thanks so much.
[03:14:46.620 --> 03:14:51.260]   Thanks for listening to this conversation with Ezra Klein and Derek Thompson.
[03:14:51.260 --> 03:14:55.080]   To support this podcast, please check out our sponsors in the description.
[03:14:55.080 --> 03:14:59.320]   And now, let me leave you with some words from Napoleon Bonaparte.
[03:14:59.320 --> 03:15:04.160]   In politics, stupidity is not a handicap.
[03:15:04.160 --> 03:15:08.480]   Thank you for listening and hope to see you next time.
[03:15:08.480 --> 03:15:09.180]   Thank you.
[03:15:09.180 --> 03:15:09.180]   Thank you.
[03:15:09.180 --> 03:15:09.480]   Thank you.
[03:15:09.480 --> 03:15:10.180]   Thank you.
[03:15:10.180 --> 03:15:10.180]   Thank you.
[03:15:10.180 --> 03:15:10.180]   Thank you.
[03:15:10.180 --> 03:15:10.180]   Thank you.
[03:15:10.180 --> 03:15:10.180]   Thank you.
[03:15:10.180 --> 03:15:10.240]   Thank you.
[03:15:10.240 --> 03:15:10.940]   Thank you.
[03:15:10.940 --> 03:15:11.600]   Thank you.
[03:15:11.600 --> 03:15:11.600]   Thank you.
[03:15:11.600 --> 03:15:11.700]   Thank you.
[03:15:11.700 --> 03:15:11.980]   Thank you.
[03:15:11.980 --> 03:15:12.040]   Thank you.
[03:15:12.040 --> 03:15:13.040]   Thank you.
[03:15:13.040 --> 03:15:13.340]   Thank you.
[03:15:13.340 --> 03:15:13.340]   Thank you.
[03:15:13.340 --> 03:15:13.400]   Thank you.
[03:15:13.400 --> 03:15:13.400]   Thank you.
[03:15:13.400 --> 03:15:13.940]   Thank you.
[03:15:13.940 --> 03:15:43.920]   Thank you.

