
[00:00:00.000 --> 00:00:10.560]   I'm Cal Newport, and this is Deep Questions, episode 177.
[00:00:10.560 --> 00:00:15.680]   I'm here in my Deep Work HQ, joined by my professor.
[00:00:15.680 --> 00:00:16.680]   Professor?
[00:00:16.680 --> 00:00:19.440]   Yeah, you don't know this about Jesse, everyone.
[00:00:19.440 --> 00:00:26.320]   My producer Jesse is also the professor who taught me everything I know about optimization
[00:00:26.320 --> 00:00:27.880]   and distributed algorithm theories.
[00:00:27.880 --> 00:00:29.800]   Is that not true, Jesse?
[00:00:29.800 --> 00:00:32.000]   It's not true.
[00:00:32.000 --> 00:00:35.040]   We are having, so we're off to a difficult technical start today.
[00:00:35.040 --> 00:00:36.720]   I think this is a fair assessment.
[00:00:36.720 --> 00:00:42.320]   We've had multiple issues as we're preparing to record today's episode.
[00:00:42.320 --> 00:00:47.560]   And Jesse, correct me if I'm wrong, but both issues had an incredibly technically nuanced
[00:00:47.560 --> 00:00:48.560]   solution.
[00:00:48.560 --> 00:00:50.200]   You're correct.
[00:00:50.200 --> 00:00:52.200]   Turn it off and turn it back on.
[00:00:52.200 --> 00:00:53.200]   This is right.
[00:00:53.200 --> 00:00:57.600]   Multiple unrelated issues were solved today by turning off different things, mind you.
[00:00:57.600 --> 00:01:03.920]   Not the same component, completely unrelated problems that we have fixed so far by turning
[00:01:03.920 --> 00:01:05.400]   it off and turning it on.
[00:01:05.400 --> 00:01:08.480]   That is why I hired the professor in the first place.
[00:01:08.480 --> 00:01:11.480]   This is his specialty, his complex.
[00:01:11.480 --> 00:01:13.120]   So we've turned it off and turned it on.
[00:01:13.120 --> 00:01:17.520]   That's why I keep, I keep, look, I'm glancing at our, at our equipment here with a trepidation.
[00:01:17.520 --> 00:01:21.760]   I keep checking that it looks like things are actually recording.
[00:01:21.760 --> 00:01:22.760]   We also had the mouse.
[00:01:22.760 --> 00:01:24.680]   Oh, our mouse died.
[00:01:24.680 --> 00:01:26.560]   Yes, our mouse died.
[00:01:26.560 --> 00:01:30.320]   I think there's a 50% chance there's going to be a power outage in the next 15 minutes.
[00:01:30.320 --> 00:01:35.920]   Yeah, there was, this was before your time, Jesse, but there was a period when I was recording,
[00:01:35.920 --> 00:01:41.800]   I was recording an episode and there was a lightning storm and so I'm recording and there's
[00:01:41.800 --> 00:01:46.080]   lightning and, and there's this huge lightning strike that was nearby.
[00:01:46.080 --> 00:01:52.000]   Like you could just hear the thunder or whatever and like immediately began hearing a hum,
[00:01:52.000 --> 00:01:53.000]   right?
[00:01:53.000 --> 00:01:54.000]   In my, my equipment.
[00:01:54.000 --> 00:01:56.520]   And that hum has been with us ever since.
[00:01:56.520 --> 00:02:00.480]   It's like the bat in the natural, something about that lightning strike has like added
[00:02:00.480 --> 00:02:02.960]   a hum to the equipment that we've been battling ever since.
[00:02:02.960 --> 00:02:04.640]   So I don't know.
[00:02:04.640 --> 00:02:06.880]   I don't know what to turn off and turn on to fix that one.
[00:02:06.880 --> 00:02:10.680]   But, but yeah, we can only go uphill or downhill.
[00:02:10.680 --> 00:02:11.680]   I don't know what's better.
[00:02:11.680 --> 00:02:14.880]   We can, it can only get better from here, technically speaking.
[00:02:14.880 --> 00:02:16.480]   Now that we're actually recording.
[00:02:16.480 --> 00:02:18.160]   Oh, well.
[00:02:18.160 --> 00:02:19.480]   All right.
[00:02:19.480 --> 00:02:21.560]   So here's what I'm thinking.
[00:02:21.560 --> 00:02:24.800]   I think we'll do a deep dive.
[00:02:24.800 --> 00:02:31.720]   I always enjoy doing those and then we'll get into our normal collection of questions.
[00:02:31.720 --> 00:02:39.200]   So for today's deep dive, the topic I want to tackle is the following provocative question,
[00:02:39.200 --> 00:02:42.200]   is ambition worth it?
[00:02:42.200 --> 00:02:46.280]   Now, let me give a disclaimer before I set up this discussion.
[00:02:46.280 --> 00:02:52.040]   The disclaimer is this is not a topic for which I have polished, evolved thoughts that
[00:02:52.040 --> 00:02:53.800]   I am now going to convey to you.
[00:02:53.800 --> 00:02:57.440]   It's instead a topic that I have found interesting off and on.
[00:02:57.440 --> 00:02:59.480]   And particularly recently I've been thinking about.
[00:02:59.480 --> 00:03:01.720]   So this morning I just jotted down some thoughts.
[00:03:01.720 --> 00:03:07.120]   So what this is, what you're going to hear today is me thinking out loud, not delivering
[00:03:07.120 --> 00:03:08.680]   well thought through conclusions.
[00:03:08.680 --> 00:03:12.260]   So this, this should be fun, you know, buckle up for that.
[00:03:12.260 --> 00:03:15.000]   So what made me start thinking about ambition recently?
[00:03:15.000 --> 00:03:20.000]   There has been recently as there happens off and on, it feels like over the last couple
[00:03:20.000 --> 00:03:26.240]   of years, a big collection of various essays and articles that have come out that are all
[00:03:26.240 --> 00:03:32.000]   taking a negative stance against the idea of ambition.
[00:03:32.000 --> 00:03:35.400]   People often send these to me and so I encounter them quite often.
[00:03:35.400 --> 00:03:37.800]   I'm cited in some of these.
[00:03:37.800 --> 00:03:42.120]   What's interesting is sometimes I'm cited as the villain and sometimes I'm cited as
[00:03:42.120 --> 00:03:46.800]   the non-villain, depending on how you think about me or what part of my writing you're
[00:03:46.800 --> 00:03:47.800]   actually citing.
[00:03:47.800 --> 00:03:52.720]   These come to me because they often, they often cite me, but it got me thinking recently
[00:03:52.720 --> 00:03:57.040]   about this topic of ambition.
[00:03:57.040 --> 00:04:04.980]   So if you look at these, what I call anti-ambition essays, there's really two pieces to them.
[00:04:04.980 --> 00:04:11.180]   There's the piece which is personal and interesting and compelling, which is often people talking
[00:04:11.180 --> 00:04:19.200]   about their own struggles with ambition and the difficulty they have with it and the attempts
[00:04:19.200 --> 00:04:22.760]   they're making to perhaps disentangle their life from this ambition.
[00:04:22.760 --> 00:04:29.160]   And then there's a, maybe the explanatory part that's saying why, why is ambition something
[00:04:29.160 --> 00:04:30.920]   that is so popular?
[00:04:30.920 --> 00:04:34.080]   Why was I as the person writing this essay so entangled in ambition?
[00:04:34.080 --> 00:04:38.500]   And in some sense, that's less interesting to me because you just see whatever frame
[00:04:38.500 --> 00:04:42.280]   that person's cultural context lies within, we'll just give them that answer.
[00:04:42.280 --> 00:04:46.680]   So if you read anti-ambition essays coming from, let's say a sub stack writer who lives
[00:04:46.680 --> 00:04:50.520]   in Brooklyn, they're going to look around their cultural world and say, well, ambition
[00:04:50.520 --> 00:04:53.300]   is, it's from capitalism.
[00:04:53.300 --> 00:04:57.600]   Let's have like an economic materialist approach to this, where we say, if we can just get
[00:04:57.600 --> 00:05:05.100]   rid of capitalism, we can get rid of these sort of disordered affectations, these disordered
[00:05:05.100 --> 00:05:07.240]   compulsions towards accomplishment.
[00:05:07.240 --> 00:05:13.680]   Whereas if you read an anti-ambition essay, let's say from someone who lives in Montana
[00:05:13.680 --> 00:05:18.320]   and is really into bow hunting or Brazilian Jiu Jitsu, the frame there might be a much
[00:05:18.320 --> 00:05:24.860]   more Thoreauian type frame about simplicity and focusing on things that really matter
[00:05:24.860 --> 00:05:26.400]   and getting clutter out of your life.
[00:05:26.400 --> 00:05:27.400]   So it really just depends.
[00:05:27.400 --> 00:05:31.000]   So I don't care about the explanation, but I care about the phenomenon.
[00:05:31.000 --> 00:05:36.680]   I care about the phenomenon of these essays once again, becoming something that we read
[00:05:36.680 --> 00:05:39.720]   quite a bit about.
[00:05:39.720 --> 00:05:42.480]   So I want to jump, I want to jump into this and try to actually tackle this.
[00:05:42.480 --> 00:05:43.720]   So let's define ambition.
[00:05:43.720 --> 00:05:48.220]   Number one, the drive to do things of increasing impact.
[00:05:48.220 --> 00:05:55.680]   So it's that drive to do things that are notable, that have impact, that are rewarded or remunerative,
[00:05:55.680 --> 00:06:00.540]   depending on what your metrics are, but generally that drive, and it's often insatiable.
[00:06:00.540 --> 00:06:06.560]   So if you hit one level, then that next level begins to be appealing.
[00:06:06.560 --> 00:06:13.680]   And what I want to try to do here is go over the pros and cons of ambition.
[00:06:13.680 --> 00:06:14.680]   So let's get into that.
[00:06:14.680 --> 00:06:15.880]   Let's start with the cons.
[00:06:15.880 --> 00:06:19.180]   What's the issue with ambition?
[00:06:19.180 --> 00:06:23.240]   Number one, it leads or it can lead to burnout.
[00:06:23.240 --> 00:06:26.360]   We talk about burnout often on this show.
[00:06:26.360 --> 00:06:30.320]   And if we're talking in particular about professional burnout for people who do computer screen
[00:06:30.320 --> 00:06:36.040]   and email type jobs, there's really two big sources of burnout that people suffer from.
[00:06:36.040 --> 00:06:37.800]   One is chronic overload.
[00:06:37.800 --> 00:06:42.480]   I talked about this, for example, in my writing and my core ideas video on slow productivity.
[00:06:42.480 --> 00:06:46.320]   But if you have more on your plate consistently than you can even imagine accomplishing just
[00:06:46.320 --> 00:06:50.880]   too much on your plate, that can be quite distressing.
[00:06:50.880 --> 00:06:54.760]   It can short circuit the planning parts of your circuits, it can lead to an overhead
[00:06:54.760 --> 00:06:59.560]   spiral where you spend more time tending to all of these pending tasks than actually executing
[00:06:59.560 --> 00:07:00.560]   them.
[00:07:00.560 --> 00:07:02.640]   Recipe for burnout.
[00:07:02.640 --> 00:07:09.040]   The other main source of burnout among this particular context is when you spend too much
[00:07:09.040 --> 00:07:15.560]   time in a high arousal emotional state, so high stress state, high anxiety state.
[00:07:15.560 --> 00:07:21.800]   So, you know, your work is such that there's crises happening that keeps you at a high
[00:07:21.800 --> 00:07:22.800]   level of alertness.
[00:07:22.800 --> 00:07:25.000]   You can basically just burn out those systems.
[00:07:25.000 --> 00:07:27.120]   That's too much cortisol in your system.
[00:07:27.120 --> 00:07:29.340]   Your mind gives up on it.
[00:07:29.340 --> 00:07:31.480]   Burnout can happen as well.
[00:07:31.480 --> 00:07:33.640]   One can amplify both those issues.
[00:07:33.640 --> 00:07:39.520]   Because if you're ambitious, you are putting more and more stuff on your plate probably.
[00:07:39.520 --> 00:07:42.720]   Because you see these opportunities, you want to keep moving, you want to get after it.
[00:07:42.720 --> 00:07:46.880]   So chronic overload is a real hazard.
[00:07:46.880 --> 00:07:49.960]   Also if you're ambitious, that means you're taking on responsibility and making moves
[00:07:49.960 --> 00:07:53.720]   that are more likely to expose yourself to those high arousal states.
[00:07:53.720 --> 00:07:56.040]   So I'm going to start my own business.
[00:07:56.040 --> 00:07:58.800]   We're going to build this thing big.
[00:07:58.800 --> 00:08:02.160]   That's going to set you up for a lot of situations where there's a crisis with your business.
[00:08:02.160 --> 00:08:03.440]   You can't get the funding together.
[00:08:03.440 --> 00:08:04.480]   You're not going to make payroll.
[00:08:04.480 --> 00:08:08.960]   It's going to set you up for a lot of situations where you might have that consistent stress.
[00:08:08.960 --> 00:08:12.540]   Ambition can make it more likely that you burn out.
[00:08:12.540 --> 00:08:17.440]   It amplifies our human instinct to compare.
[00:08:17.440 --> 00:08:18.440]   Compare to other people.
[00:08:18.440 --> 00:08:19.920]   Now, we all do this.
[00:08:19.920 --> 00:08:23.960]   I mean, regardless of your ambition or not, you look on Instagram, you see this, you get
[00:08:23.960 --> 00:08:24.960]   a little bit jealous.
[00:08:24.960 --> 00:08:32.320]   But when you are ambitious, it can become close to intolerable when you see the success
[00:08:32.320 --> 00:08:34.120]   you want that you're not getting.
[00:08:34.120 --> 00:08:38.600]   And I want to say I'm speaking from some experience here.
[00:08:38.600 --> 00:08:42.360]   I have ambition.
[00:08:42.360 --> 00:08:46.920]   It is an odd mistress of mine that has both given and taken away.
[00:08:46.920 --> 00:08:49.320]   But I have felt this amplification of comparison issue.
[00:08:49.320 --> 00:08:51.000]   It's almost weird how it works.
[00:08:51.000 --> 00:08:54.000]   It's like your brain is being taken over by someone else.
[00:08:54.000 --> 00:08:57.800]   Here's something that I have periodic, just to make this personal, I have periodic bouts
[00:08:57.800 --> 00:09:05.000]   of this where I'll go through a period where I will feel bad about my status as a writer.
[00:09:05.000 --> 00:09:11.120]   Like, man, I just, I didn't hit where I want to get.
[00:09:11.120 --> 00:09:12.800]   Now by some standards, that's preposterous.
[00:09:12.800 --> 00:09:14.160]   Like I'm a successful writer.
[00:09:14.160 --> 00:09:18.000]   I have multiple books, I think four books at this point that are healthily into the
[00:09:18.000 --> 00:09:19.160]   six figures with sales.
[00:09:19.160 --> 00:09:21.360]   So I can consistently sell six figure books.
[00:09:21.360 --> 00:09:24.800]   I have a seven figure or a seven figure sale number book.
[00:09:24.800 --> 00:09:28.640]   I'm relatively well known, done well financially with the books.
[00:09:28.640 --> 00:09:30.040]   I've made impact on culture.
[00:09:30.040 --> 00:09:32.600]   I've introduced new ideas into the vernacular.
[00:09:32.600 --> 00:09:37.120]   Like I am a successful writer by most standards, but then I'll say, but here's what I'm not.
[00:09:37.120 --> 00:09:41.360]   I've never had a book where right out of the gate, it is on the New York Times bestseller
[00:09:41.360 --> 00:09:43.680]   list for a while.
[00:09:43.680 --> 00:09:46.480]   Notice how I'm subtly shifting the goalposts.
[00:09:46.480 --> 00:09:48.380]   My last two books have been New York Times bestsellers.
[00:09:48.380 --> 00:09:49.640]   So my mind shifts it.
[00:09:49.640 --> 00:09:52.320]   I've never had a book that stays on the list.
[00:09:52.320 --> 00:09:56.960]   I've never had one of those books where it's just on that Amazon chart, top 10 for six
[00:09:56.960 --> 00:09:58.380]   months when it comes out.
[00:09:58.380 --> 00:10:03.320]   Now we're talking about in my space, there's like five people who do that, but my mind
[00:10:03.320 --> 00:10:07.160]   will say, why aren't you one of those five?
[00:10:07.160 --> 00:10:08.960]   And then I'll come back to earth and be like, oh, that's crazy.
[00:10:08.960 --> 00:10:11.800]   I feel great about what I'm doing, but I'll have those bouts.
[00:10:11.800 --> 00:10:16.320]   And I point out that personal example, just to talk about the way that ambition can rewire
[00:10:16.320 --> 00:10:20.320]   your mind in these ways that are malformed as far as the outside world is concerned,
[00:10:20.320 --> 00:10:25.720]   that is crazy talk, but it'll hit you hard.
[00:10:25.720 --> 00:10:29.080]   Another issue with ambition is that it can keep you from other things that are important
[00:10:29.080 --> 00:10:30.080]   in your life.
[00:10:30.080 --> 00:10:33.320]   If you're not careful, this is often one of the big points that's hit when you read the
[00:10:33.320 --> 00:10:38.260]   modern anti-ambition essays is that, you know, if you're all in on, I am going to start the
[00:10:38.260 --> 00:10:41.480]   next Uber, you're not spending time with your kids.
[00:10:41.480 --> 00:10:43.660]   You're not spending time out in nature.
[00:10:43.660 --> 00:10:45.320]   Your mind is probably always moving.
[00:10:45.320 --> 00:10:48.960]   You're probably not very involved in your community and becoming a leader and sacrificing
[00:10:48.960 --> 00:10:51.200]   time and energy on behalf of people you care about.
[00:10:51.200 --> 00:10:53.080]   You're doing this one thing.
[00:10:53.080 --> 00:10:55.960]   So this is a real danger of ambition.
[00:10:55.960 --> 00:10:58.880]   It's easy to fall there, to get very out of balance in your life.
[00:10:58.880 --> 00:11:04.160]   This is why, when I talk about the deep life and my bucket system for the deep life, we
[00:11:04.160 --> 00:11:07.960]   have these various aspects you should focus on to try to keep that balance.
[00:11:07.960 --> 00:11:13.020]   And the final thing about ambition, the piece we don't talk about, even when we encourage
[00:11:13.020 --> 00:11:18.280]   people to follow their dreams or do whatever they want to do, is that you probably won't
[00:11:18.280 --> 00:11:20.280]   succeed.
[00:11:20.280 --> 00:11:22.720]   So the things that we are ambitious about are very hard.
[00:11:22.720 --> 00:11:24.600]   That's what makes them a target of ambition.
[00:11:24.600 --> 00:11:26.800]   Most people won't succeed.
[00:11:26.800 --> 00:11:32.680]   So you go to a really good school, you worked really hard to get there.
[00:11:32.680 --> 00:11:37.040]   You take an elite job, like I'm going to be a writer, going to move to New York, I'm going
[00:11:37.040 --> 00:11:38.420]   to be a writer.
[00:11:38.420 --> 00:11:43.860]   Maybe I'll be the next Joan Didion, and most people won't be.
[00:11:43.860 --> 00:11:50.840]   And so 10 years later, you're writing essays about, well, ambition is stupid anyways.
[00:11:50.840 --> 00:11:52.440]   So it's hard, man.
[00:11:52.440 --> 00:11:53.440]   It's hard.
[00:11:53.440 --> 00:11:56.480]   Most people don't get anywhere close to where they're going.
[00:11:56.480 --> 00:11:58.880]   There are also pros of ambition.
[00:11:58.880 --> 00:12:01.520]   Let's lay out the other side of this.
[00:12:01.520 --> 00:12:05.800]   So first of all, the pursuit of big goals is life affirming.
[00:12:05.800 --> 00:12:10.680]   I mean, this is the one thing I don't think the anti-ambition people acknowledge enough,
[00:12:10.680 --> 00:12:15.160]   is that there are few results that are better understood in human psychology than if you
[00:12:15.160 --> 00:12:19.720]   take away people's sense of efficacy, take away their sense of here's something you're
[00:12:19.720 --> 00:12:23.060]   in charge of that's important that you're working on.
[00:12:23.060 --> 00:12:24.700]   They will just wither.
[00:12:24.700 --> 00:12:27.860]   There's almost nothing worth you can do to a human than put them in a situation where
[00:12:27.860 --> 00:12:30.040]   they can't do anything.
[00:12:30.040 --> 00:12:31.400]   There's nothing I'm working towards.
[00:12:31.400 --> 00:12:32.640]   There's nothing I'm taking care of.
[00:12:32.640 --> 00:12:36.000]   There's no challenges I'm facing.
[00:12:36.000 --> 00:12:38.080]   That makes humans miserable.
[00:12:38.080 --> 00:12:39.840]   They need that and they need sociality.
[00:12:39.840 --> 00:12:41.800]   You take away either of those two things and it's a problem.
[00:12:41.800 --> 00:12:47.600]   So there is something life affirming going after something that's important or ambitious.
[00:12:47.600 --> 00:12:49.680]   It gives a focus, your energy.
[00:12:49.680 --> 00:12:53.360]   The human brain does not want to do nothing.
[00:12:53.360 --> 00:12:57.360]   For very brief periods, it gets uncomfortable with doing nothing.
[00:12:57.360 --> 00:13:00.360]   Also, accomplishment does make people feel good.
[00:13:00.360 --> 00:13:06.120]   Again, the anti-ambition essays tend to downplay this, but actually it feels good to accomplish
[00:13:06.120 --> 00:13:07.120]   something.
[00:13:07.120 --> 00:13:08.320]   There's like the burst of chemicals in the moment.
[00:13:08.320 --> 00:13:09.320]   Yes, that goes away.
[00:13:09.320 --> 00:13:13.920]   You're not going to have that opioid style high permanently, but there is a background
[00:13:13.920 --> 00:13:17.520]   hum of confidence and satisfaction that does come from accomplishment.
[00:13:17.520 --> 00:13:19.600]   And I think that is worth acknowledging.
[00:13:19.600 --> 00:13:23.880]   If you're doing something at a high level and you're recognized for it, you get a steady
[00:13:23.880 --> 00:13:28.680]   state sense of pride, of self-worth.
[00:13:28.680 --> 00:13:30.760]   You have more confidence.
[00:13:30.760 --> 00:13:32.920]   It feels good.
[00:13:32.920 --> 00:13:34.600]   So it's not all invented.
[00:13:34.600 --> 00:13:38.800]   So it's not all just constructed as part of a conspiracy to help certain groups exploit
[00:13:38.800 --> 00:13:39.800]   others.
[00:13:39.800 --> 00:13:41.320]   There are real benefits that you get there.
[00:13:41.320 --> 00:13:46.160]   And of course, society needs at least some people to be ambitious.
[00:13:46.160 --> 00:13:50.320]   That's what moves forward whole technologies and industries.
[00:13:50.320 --> 00:13:55.640]   You take someone like Elon Musk and when he is discussed in sort of elite cultural circles,
[00:13:55.640 --> 00:13:58.760]   everyone's just focusing on, does he believe the right things?
[00:13:58.760 --> 00:14:00.360]   Does he talk about things properly?
[00:14:00.360 --> 00:14:01.360]   Is he on our team?
[00:14:01.360 --> 00:14:02.900]   Is he on the other people's team?
[00:14:02.900 --> 00:14:03.900]   And I say, I don't know.
[00:14:03.900 --> 00:14:04.900]   I don't really care about that.
[00:14:04.900 --> 00:14:05.900]   He's kind of a weird guy.
[00:14:05.900 --> 00:14:10.040]   Yeah, I think we all kind of acknowledge that, but he single-handedly made basically every
[00:14:10.040 --> 00:14:14.740]   automaker in the country have a serious electric car strategy.
[00:14:14.740 --> 00:14:20.800]   He single-handedly reduced the cost of space flight by a factor of 10.
[00:14:20.800 --> 00:14:22.440]   That's crazy ambition.
[00:14:22.440 --> 00:14:25.000]   I don't want to live Elon Musk life.
[00:14:25.000 --> 00:14:31.720]   It's brutal, but I'm glad there's people living Elon Musk's life because we have cool electric
[00:14:31.720 --> 00:14:32.720]   cars now.
[00:14:32.720 --> 00:14:38.320]   And you can do this again and again with medicine and science, with the practitioners there.
[00:14:38.320 --> 00:14:42.440]   We wouldn't have relativity if it's not for the fierce ambition of Einstein.
[00:14:42.440 --> 00:14:44.240]   His whole family broke apart about this.
[00:14:44.240 --> 00:14:45.960]   His hair went white.
[00:14:45.960 --> 00:14:51.080]   Einstein's hair went white at a younger age than mine from the stress of trying to make
[00:14:51.080 --> 00:14:53.480]   these theories come together.
[00:14:53.480 --> 00:14:56.480]   His family life got terrible because of this.
[00:14:56.480 --> 00:14:59.000]   His health faltered because of this.
[00:14:59.000 --> 00:15:03.840]   I wouldn't want to do it, but relativity was absolutely foundational for understanding
[00:15:03.840 --> 00:15:04.840]   the modern world.
[00:15:04.840 --> 00:15:09.240]   So we also need ambition in the world, even if not everyone is doing it.
[00:15:09.240 --> 00:15:10.240]   All right, so we have pros and cons.
[00:15:10.240 --> 00:15:11.480]   So we get to the conclusion then.
[00:15:11.480 --> 00:15:13.520]   All right, so who wins?
[00:15:13.520 --> 00:15:15.360]   If the question is, is ambition worth it?
[00:15:15.360 --> 00:15:17.400]   We have two possible answers here.
[00:15:17.400 --> 00:15:20.680]   A, no, it's just an invention.
[00:15:20.680 --> 00:15:26.560]   It's a cultural construct that is exploitative of you.
[00:15:26.560 --> 00:15:28.560]   Stop it.
[00:15:28.560 --> 00:15:30.080]   Focus on just being present.
[00:15:30.080 --> 00:15:32.120]   Do less.
[00:15:32.120 --> 00:15:37.320]   And we'll just get rid of capitalism or whatever, or move to Montana, and we'll be OK.
[00:15:37.320 --> 00:15:40.120]   The other answer is, no, no, it's critical to feeling good.
[00:15:40.120 --> 00:15:42.320]   It's critical to self-affirmation.
[00:15:42.320 --> 00:15:43.840]   It's critical to the society growing.
[00:15:43.840 --> 00:15:45.640]   So what answer is right?
[00:15:45.640 --> 00:15:47.640]   I'm going to say neither.
[00:15:48.520 --> 00:15:51.320]   And I'm going to say both.
[00:15:51.320 --> 00:15:55.000]   Because this is where I'm beginning to fall on this issue.
[00:15:55.000 --> 00:15:56.440]   And beginning is the key word here.
[00:15:56.440 --> 00:15:58.920]   I do not have a comprehensive take on this yet.
[00:15:58.920 --> 00:16:05.760]   But where I'm beginning to fall on this issue is that ambition is novelistic.
[00:16:05.760 --> 00:16:08.160]   It's novelistic in its scope and impact.
[00:16:08.160 --> 00:16:16.600]   When I say novelistic, I mean messy and human and tragic and inspiring all at the same time.
[00:16:16.600 --> 00:16:21.600]   I think ambition gets to core contradictions in the human experience.
[00:16:21.600 --> 00:16:25.520]   We're miserable when it's removed from our life, but as we pursue it, it takes out of
[00:16:25.520 --> 00:16:28.920]   our life other things that we need to not be miserable.
[00:16:28.920 --> 00:16:31.200]   And there's tragedy in that.
[00:16:31.200 --> 00:16:33.240]   But there's also great inspiration in that.
[00:16:33.240 --> 00:16:34.880]   That's why I say it's novelistic.
[00:16:34.880 --> 00:16:37.840]   It's not something that we look at through an economic lens.
[00:16:37.840 --> 00:16:41.720]   It's not something that we necessarily look through a philosophic lens.
[00:16:41.720 --> 00:16:42.720]   It is messy.
[00:16:42.720 --> 00:16:46.040]   And it's very human.
[00:16:46.040 --> 00:16:51.360]   And just like when you read a deep novel, a deep, good piece of literature, you're able
[00:16:51.360 --> 00:16:55.520]   to actually revel in the complexity because that's part of what you try to get out of
[00:16:55.520 --> 00:16:56.520]   a good novel.
[00:16:56.520 --> 00:17:01.240]   We need that mindset, I believe, when we're thinking about ambition.
[00:17:01.240 --> 00:17:07.200]   Now I think there's probably an evolutionary explanation we could put behind this messiness.
[00:17:07.200 --> 00:17:12.600]   I never hesitate to throw in some ill-conceived, ill-thought-through pop evolutionary psychology.
[00:17:12.600 --> 00:17:14.540]   So let's do that real quick.
[00:17:14.540 --> 00:17:17.020]   And if you really were going to pull back the covers here, here's what you're going
[00:17:17.020 --> 00:17:18.200]   to find.
[00:17:18.200 --> 00:17:21.060]   In the Paleolithic, you have humans living tribally.
[00:17:21.060 --> 00:17:27.780]   We evolve a strong drive to be a respected member of our tribe that is critical to survival
[00:17:27.780 --> 00:17:28.900]   and passing on your genes.
[00:17:28.900 --> 00:17:37.300]   We know this is true in part because nothing makes us feel more immediate, uncontrolled,
[00:17:37.300 --> 00:17:43.300]   positive feelings than when we encounter a story of someone sacrificing on behalf of
[00:17:43.300 --> 00:17:44.820]   their tribe.
[00:17:44.820 --> 00:17:48.060]   It just hits us at a core, like, yes, that is right.
[00:17:48.060 --> 00:17:54.420]   Look at this person who stood up and took the arrows on behalf of his or her people.
[00:17:54.420 --> 00:17:58.540]   That instinctively feels well, and nothing makes us feel more uncomfortable and squirrely
[00:17:58.540 --> 00:18:06.900]   and weasely than hearing a story of someone who betrays their tribe or is weak or cowardly.
[00:18:06.900 --> 00:18:07.900]   Those are deep instincts.
[00:18:07.900 --> 00:18:10.940]   Deep instincts mean deep evolutionary paths.
[00:18:10.940 --> 00:18:12.420]   This thing has evolved.
[00:18:12.420 --> 00:18:16.980]   The issue, of course, is the Paleolithic gave way to the Neolithic, and suddenly we had
[00:18:16.980 --> 00:18:21.180]   cities and city-states and eventually nations.
[00:18:21.180 --> 00:18:24.860]   And so now we have this drive to be respected and be a leader, except for the people in
[00:18:24.860 --> 00:18:29.740]   our immediate surroundings are no longer 15 people that we have lived with intergenerationally
[00:18:29.740 --> 00:18:31.060]   for 15 generations.
[00:18:31.060 --> 00:18:33.580]   It's 15,000 people in a city-state.
[00:18:33.580 --> 00:18:39.100]   And that gave rise to this new type of Neolithic ambition, which we weren't evolved for.
[00:18:39.100 --> 00:18:44.860]   It is the evolved instinct to be a leader in the tribe applied to a much bigger context,
[00:18:44.860 --> 00:18:48.740]   and that's what gives you suddenly political ambitions.
[00:18:48.740 --> 00:18:50.600]   You have the pharaohs.
[00:18:50.600 --> 00:18:52.300]   It's what gives us intellectual ambition.
[00:18:52.300 --> 00:18:54.500]   You get Aristotle, you get Socrates.
[00:18:54.500 --> 00:19:00.360]   What gives us these theological ambitions, you get Siddhartha, you get Jesus Christ,
[00:19:00.360 --> 00:19:06.060]   you get people who are trying to think through religious thoughts that are going to impact
[00:19:06.060 --> 00:19:07.260]   the entire world.
[00:19:07.260 --> 00:19:13.460]   This is a parochial instinct applied on a scale that was never evolved for.
[00:19:13.460 --> 00:19:17.780]   And so I don't know if this is true, but I would wager it is that tension between an
[00:19:17.780 --> 00:19:23.780]   instinct that was evolved to make sense among 20 people, applied to a world of 6 billion
[00:19:23.780 --> 00:19:29.580]   that we now can communicate with and see and have an audience amongst, that creates this
[00:19:29.580 --> 00:19:34.620]   weird tension that we feel in our life, where this ambition to keep going farther, and yet
[00:19:34.620 --> 00:19:37.700]   that ambition is taking us away from the things that are important to us, like being with
[00:19:37.700 --> 00:19:40.780]   our family and with our community, and that's because there was a time when that was all
[00:19:40.780 --> 00:19:42.660]   the same thing.
[00:19:42.660 --> 00:19:44.380]   That time was 100,000 years ago.
[00:19:44.380 --> 00:19:49.060]   I don't know if that's true, but I think that's one way of trying to get at this fundamental,
[00:19:49.060 --> 00:19:55.820]   novelistic, tragic, inspirational tug-of-war that is at the core of so many people's life,
[00:19:55.820 --> 00:19:58.180]   which is the fight over ambition.
[00:19:58.180 --> 00:20:01.260]   So I don't have a nice, clean story to give you.
[00:20:01.260 --> 00:20:02.740]   I don't have a nice, clean answer.
[00:20:02.740 --> 00:20:03.740]   This is what you should do.
[00:20:03.740 --> 00:20:08.620]   You do these three steps, put this card on your Trello board, and use a time-block planner.
[00:20:08.620 --> 00:20:09.820]   Boom, you're good with ambition.
[00:20:09.820 --> 00:20:13.780]   I don't know the answer here yet, but I'm increasingly feeling that the answer is going
[00:20:13.780 --> 00:20:20.420]   to evolve, cutting each other some slack, and seeing ambition as this complicated, wonderful,
[00:20:20.420 --> 00:20:27.940]   terrible, interesting piece of the human condition, and not just a simple football we can kick
[00:20:27.940 --> 00:20:28.940]   back and forth.
[00:20:28.940 --> 00:20:32.100]   It's good, it's bad, that team likes it, this team doesn't.
[00:20:32.100 --> 00:20:38.700]   Something interesting going on here, and we should be okay with that nuance.
[00:20:38.700 --> 00:20:42.700]   So those are my thoughts on ambition.
[00:20:42.700 --> 00:20:45.900]   So there we go.
[00:20:45.900 --> 00:20:47.900]   All right, Chelsea.
[00:20:47.900 --> 00:20:54.140]   Well, I'm ambitious to get onto some questions, but we should probably take a brief moment
[00:20:54.140 --> 00:20:57.380]   to talk about a couple of our sponsors.
[00:20:57.380 --> 00:21:03.700]   Let's start with Blinkist, longtime sponsor of the show.
[00:21:03.700 --> 00:21:09.060]   Blinkist is a subscription service that allows you to get short summaries, 10 to 15 minute
[00:21:09.060 --> 00:21:14.700]   summaries of best-selling nonfiction books, important nonfiction books.
[00:21:14.700 --> 00:21:22.300]   You can get these short summaries called Blinks of thousands of important nonfiction titles.
[00:21:22.300 --> 00:21:25.060]   Now there's a lot of ways you can use Blinkist.
[00:21:25.060 --> 00:21:28.780]   What I've been talking about for a long time is that it is a great way to try to figure
[00:21:28.780 --> 00:21:34.020]   out which books are worth reading and where just a summary is enough.
[00:21:34.020 --> 00:21:38.300]   I read a lot of books, but there are way more books out there than I can possibly ever handle.
[00:21:38.300 --> 00:21:40.540]   Blinkist gives me a way of wading through these opportunities.
[00:21:40.540 --> 00:21:47.960]   If I'm interested in an idea, I can look at the Blinks for multiple books in that idea,
[00:21:47.960 --> 00:21:50.340]   get the lay of the land almost immediately.
[00:21:50.340 --> 00:21:54.860]   Here's the main topics, here's the main theories, and decide if there's any particular books
[00:21:54.860 --> 00:21:59.220]   in that genre that now I should actually go out and buy and dive in more deeper.
[00:21:59.220 --> 00:22:00.740]   I'm no longer flying blind.
[00:22:00.740 --> 00:22:06.420]   I can move through the world of books with some guidance.
[00:22:06.420 --> 00:22:11.020]   So I was looking at Blinkist just the other day, in particular, looking at the technology
[00:22:11.020 --> 00:22:15.820]   and future category, because this is a space I care about, and there's a lot of big ideas
[00:22:15.820 --> 00:22:20.040]   and it's impossible to figure out which books you should and shouldn't read.
[00:22:20.040 --> 00:22:27.140]   But just to give you an example here, if you're interested in Yuval Harari, who wrote Sapiens,
[00:22:27.140 --> 00:22:31.100]   and you see he has this follow-up book, Homo Deus, and you're trying to figure out, should
[00:22:31.100 --> 00:22:32.140]   I read this or not?
[00:22:32.140 --> 00:22:33.820]   What's it about?
[00:22:33.820 --> 00:22:37.380]   Here it is right here on the list, technology and the future.
[00:22:37.380 --> 00:22:43.100]   Ten, 15 minutes later, you have the main ideas.
[00:22:43.100 --> 00:22:49.260]   So Blinkist is a must-have tool for those who want to play in the world of books and
[00:22:49.260 --> 00:22:50.260]   ideas.
[00:22:50.260 --> 00:22:54.420]   So right now Blinkist has a special offer just for our audience.
[00:22:54.420 --> 00:23:02.020]   If you go to Blinkist.com/deep to start a free seven-day trial, you will get 25% off
[00:23:02.020 --> 00:23:06.060]   a Blinkist premium membership.
[00:23:06.060 --> 00:23:15.020]   That's Blinkist spelled B-L-I-N-K-I-S-T, Blinkist.com/deep to get 25% off and a seven-day free trial.
[00:23:15.020 --> 00:23:19.780]   That's Blinkist.com/deep.
[00:23:19.780 --> 00:23:22.820]   Let's also talk about Athletic Greens.
[00:23:22.820 --> 00:23:27.500]   Now Jesse, you can confirm you have heard me talk frequently about my Athletic Greens
[00:23:27.500 --> 00:23:28.500]   habits.
[00:23:28.500 --> 00:23:30.240]   I do indeed take Athletic Greens every morning.
[00:23:30.240 --> 00:23:31.240]   Can you confirm this, sir?
[00:23:31.240 --> 00:23:32.240]   I can confirm it.
[00:23:32.240 --> 00:23:33.240]   All right.
[00:23:33.240 --> 00:23:35.580]   So Jesse is the official voice of confirmation.
[00:23:35.580 --> 00:23:36.820]   What is Athletic Greens?
[00:23:36.820 --> 00:23:43.660]   It is, let me use their, I'll use their exact wording here so that I don't get it wrong.
[00:23:43.660 --> 00:23:46.820]   So it is a powder that you put into a drink.
[00:23:46.820 --> 00:23:53.220]   I add it to 12 ounces of waters that includes 75 high quality vitamins, minerals, whole
[00:23:53.220 --> 00:23:57.980]   food source, super foods, probiotics, and adaptogens.
[00:23:57.980 --> 00:24:03.420]   You drink it once a day, you drink it in the morning, and it makes sure that you have all
[00:24:03.420 --> 00:24:07.460]   of the different vitamins, minerals, super food, probiotics, adaptogens, all the stuff
[00:24:07.460 --> 00:24:11.460]   you want to get out of your diet, you make sure you have it all.
[00:24:11.460 --> 00:24:15.700]   You can try to eat clean, which I do, but you're not going to get all the things you
[00:24:15.700 --> 00:24:16.700]   need.
[00:24:16.700 --> 00:24:20.300]   So you do one scoop of Athletic Greens every morning, you are covered.
[00:24:20.300 --> 00:24:24.780]   Jesse, a couple of weeks ago we were trying to figure out what adaptogens are.
[00:24:24.780 --> 00:24:26.500]   I looked it up.
[00:24:26.500 --> 00:24:27.500]   Do you have a guess?
[00:24:27.500 --> 00:24:29.020]   Or do you, you might already know.
[00:24:29.020 --> 00:24:30.020]   You don't know, do you?
[00:24:30.020 --> 00:24:31.020]   I don't know.
[00:24:31.020 --> 00:24:32.020]   All right.
[00:24:32.020 --> 00:24:34.140]   So what's your guess as to what adaptogens do?
[00:24:34.140 --> 00:24:38.540]   Recovery, assist with recovery.
[00:24:38.540 --> 00:24:39.540]   That is incorrect.
[00:24:39.540 --> 00:24:42.660]   No, they give you the power of flight.
[00:24:42.660 --> 00:24:43.660]   So I don't know if you know that.
[00:24:43.660 --> 00:24:44.660]   So then I can dunk?
[00:24:44.660 --> 00:24:45.660]   Yes, you can dunk.
[00:24:45.660 --> 00:24:50.860]   No, actually, I heard it helps with anxiety.
[00:24:50.860 --> 00:24:56.840]   So I think this is a good selling point for these current times.
[00:24:56.840 --> 00:24:57.840]   So that is Athletic Greens.
[00:24:57.840 --> 00:24:59.820]   So I take it every morning.
[00:24:59.820 --> 00:25:02.760]   What I like about them, and I've said this before because I talked to them before I agreed
[00:25:02.760 --> 00:25:06.000]   to be their sponsor, this is all they do is this one product.
[00:25:06.000 --> 00:25:08.020]   And every year they call it a new version.
[00:25:08.020 --> 00:25:11.720]   They upgrade it again and again to make sure that the quality of the ingredients is better.
[00:25:11.720 --> 00:25:13.540]   They obsess about this, right?
[00:25:13.540 --> 00:25:18.140]   Getting just the right, best sourced versions of these things.
[00:25:18.140 --> 00:25:19.580]   Jess and I talk about this all the time.
[00:25:19.580 --> 00:25:22.540]   I cannot go into GNC to try to figure this out on my own.
[00:25:22.540 --> 00:25:27.900]   If I go into GNC, I will be immediately punched in the face by a bodybuilder.
[00:25:27.900 --> 00:25:31.800]   Athletic Greens allows me to avoid that.
[00:25:31.800 --> 00:25:35.340]   So to make it easy for you, let's see what we got here.
[00:25:35.340 --> 00:25:41.600]   Athletic Greens is going to give you a free one year supply of their immune supporting
[00:25:41.600 --> 00:25:46.820]   vitamin D and five free travel packs with your first purchase.
[00:25:46.820 --> 00:25:52.580]   I will just say briefly the vitamin D they figured out needs to be in solution to be
[00:25:52.580 --> 00:25:53.580]   stable.
[00:25:53.580 --> 00:25:55.420]   So you add the vitamin D with a dropper at the last minute.
[00:25:55.420 --> 00:25:58.260]   So it's the only thing not in the powder that just shows how much they care about getting
[00:25:58.260 --> 00:25:59.260]   this right.
[00:25:59.260 --> 00:26:04.500]   They will give you a free vitamin D addition for your athletic greens and five free travel
[00:26:04.500 --> 00:26:05.840]   packs with your first purchase.
[00:26:05.840 --> 00:26:11.220]   All you have to do is visit athleticgreens.com/deep.
[00:26:11.220 --> 00:26:15.880]   Again that is athleticgreens.com/deep to take ownership over your health, to pick up the
[00:26:15.880 --> 00:26:21.300]   ultimate daily nutritional insurance and to gain the power of flight.
[00:26:21.300 --> 00:26:24.940]   So I think that's pretty good offer.
[00:26:24.940 --> 00:26:30.260]   I think there's probably a note on here somewhere that says, do not claim that this product
[00:26:30.260 --> 00:26:32.260]   gives people the power of flight.
[00:26:32.260 --> 00:26:35.500]   We've just created a lawsuit there.
[00:26:35.500 --> 00:26:37.420]   But you know, sometimes you gotta do what you gotta do.
[00:26:37.420 --> 00:26:40.780]   All right, Jesse, I think we should do some questions.
[00:26:40.780 --> 00:26:43.340]   I have so many papers these days.
[00:26:43.340 --> 00:26:44.820]   Our show is becoming too complicated.
[00:26:44.820 --> 00:26:48.740]   I have so many stacks, so many stacks of paper in front of me these days that...
[00:26:48.740 --> 00:26:50.900]   It's a good thing the printer worked today.
[00:26:50.900 --> 00:26:58.240]   Yeah, this was one of the big additions to the HQ is when Jesse brought us a printer.
[00:26:58.240 --> 00:26:59.240]   We use that thing.
[00:26:59.240 --> 00:27:00.240]   Yeah, good printer.
[00:27:00.240 --> 00:27:01.240]   Good printer.
[00:27:01.240 --> 00:27:02.240]   Black and white.
[00:27:02.240 --> 00:27:04.640]   All right, let's do some questions.
[00:27:04.640 --> 00:27:09.960]   Let's start as always with questions about deep work.
[00:27:09.960 --> 00:27:14.000]   Our first question comes from Brandon.
[00:27:14.000 --> 00:27:21.620]   Brandon asks, does adopting a slow productivity mindset mean you should ditch your to-do list
[00:27:21.620 --> 00:27:23.180]   and capture systems?
[00:27:23.180 --> 00:27:27.380]   Am I doing too much if I need a full-fledged capture system?
[00:27:27.380 --> 00:27:33.900]   Well, Brandon, in an ideal world where you had complete control over what your working
[00:27:33.900 --> 00:27:37.940]   life looked like and you had no concerns about money, you were independently wealthy, so
[00:27:37.940 --> 00:27:42.680]   you could completely control your working life, I would say, yeah, it would be great
[00:27:42.680 --> 00:27:47.440]   if you didn't need all the things I talk about when I talk about time management.
[00:27:47.440 --> 00:27:50.120]   You don't need complicated capture systems.
[00:27:50.120 --> 00:27:54.560]   You don't need weekly and daily time block plans.
[00:27:54.560 --> 00:27:57.560]   That would probably actually be ideal.
[00:27:57.560 --> 00:28:01.320]   There are some people who do actually more or less accomplish this.
[00:28:01.320 --> 00:28:06.000]   The example that I like to give comes from probably the first article I wrote that began
[00:28:06.000 --> 00:28:09.240]   to scratch the surface on some of these ideas.
[00:28:09.240 --> 00:28:12.880]   It's also one of the favorite articles I've written in the past two years.
[00:28:12.880 --> 00:28:19.960]   It was for the New Yorker, and it was called The Rise and Fall of Getting Things Done.
[00:28:19.960 --> 00:28:25.160]   The narrative spine of this article was Merlin Mann.
[00:28:25.160 --> 00:28:30.000]   This name is familiar to a lot of Deep Questions listeners, but Merlin Mann in the 2000s started
[00:28:30.000 --> 00:28:39.040]   this blog called 43 Folders that was all about using modern technology to build these hyper-optimized,
[00:28:39.040 --> 00:28:42.400]   digitally enhanced productivity systems.
[00:28:42.400 --> 00:28:48.720]   He had a job as a project manager that he took in the '90s that as we fell into more
[00:28:48.720 --> 00:28:53.640]   and more of a culture of constant communication and constant email and constant work overload,
[00:28:53.640 --> 00:28:58.280]   the culture I talk about in my book, A World Without Email, he got more and more overloaded,
[00:28:58.280 --> 00:29:02.360]   and he stumbled across David Allen and Getting Things Done, and he was a real tech guy.
[00:29:02.360 --> 00:29:07.840]   He was like, "Man, I think if we could just build the right tools, I could stop feeling
[00:29:07.840 --> 00:29:13.240]   this way where I'm completely overwhelmed and completely stressed out."
[00:29:13.240 --> 00:29:16.160]   He started writing about trying to build those tools, and a lot of other people felt the
[00:29:16.160 --> 00:29:21.520]   same way, so that website got very popular, and he became a real leader of the productivity
[00:29:21.520 --> 00:29:22.520]   movement.
[00:29:22.520 --> 00:29:25.760]   Eventually, he was doing that website full-time and giving talks about it, and then he got
[00:29:25.760 --> 00:29:31.040]   a book deal to write a book about it, and that's when the wheels came off.
[00:29:31.040 --> 00:29:37.000]   This is the narrative that was the spine for that article, is that Merlin Mann eventually
[00:29:37.000 --> 00:29:45.720]   figured out, "I can't fix this problem by organizing better the deluge of things that
[00:29:45.720 --> 00:29:52.200]   are coming towards me, by having better tools, having better systems, better processes for
[00:29:52.200 --> 00:29:54.160]   dealing with the deluges coming with me."
[00:29:54.160 --> 00:29:59.960]   He said, "Ultimately, I can fix this problem by reducing the deluge, that instead of having
[00:29:59.960 --> 00:30:04.080]   a better system for having too much to do, what if I changed my notion of work so I didn't
[00:30:04.080 --> 00:30:09.200]   have that much to do, so that having these productivity systems that are so complex would
[00:30:09.200 --> 00:30:10.200]   be unnecessary?"
[00:30:10.200 --> 00:30:12.880]   That's roughly what he did.
[00:30:12.880 --> 00:30:16.400]   He shifted into podcasting pretty early on.
[00:30:16.400 --> 00:30:18.000]   This is just what I'm going to do.
[00:30:18.000 --> 00:30:23.200]   The way he explained it to me when I talked to him about it for the article was he doesn't
[00:30:23.200 --> 00:30:25.720]   really need those systems because his life is really simple.
[00:30:25.720 --> 00:30:27.960]   He has a recording schedule.
[00:30:27.960 --> 00:30:33.640]   This is when I need to be in the studio to record my podcast, and that's kind of it.
[00:30:33.640 --> 00:30:37.440]   He keeps to-do lists for household stuff.
[00:30:37.440 --> 00:30:40.580]   What do I need to buy at the grocery store, whatever, but he basically simplified his
[00:30:40.580 --> 00:30:44.920]   working life down to the point where he didn't really need to manage it.
[00:30:44.920 --> 00:30:49.000]   I think, yes, kind of ideally, a slow productivity ideal would be such that you're working on
[00:30:49.000 --> 00:30:50.720]   a small number of things one at a time.
[00:30:50.720 --> 00:30:51.760]   It's clear what you're working on.
[00:30:51.760 --> 00:30:53.520]   There's not that much to track.
[00:30:53.520 --> 00:30:57.800]   You don't have to squeeze as much as possible out of an eight-hour day because you're juggling
[00:30:57.800 --> 00:31:01.400]   16 different tasks and projects, and you have to make progress on each without losing your
[00:31:01.400 --> 00:31:02.400]   mind.
[00:31:02.400 --> 00:31:05.240]   You don't need six Trello boards each for different roles because you only have one
[00:31:05.240 --> 00:31:06.240]   role.
[00:31:06.240 --> 00:31:08.320]   There's only one thing you need to do right now.
[00:31:08.320 --> 00:31:09.840]   You're writing or you're recording.
[00:31:09.840 --> 00:31:12.440]   So, yes, I think, Brandon, you're onto something.
[00:31:12.440 --> 00:31:14.200]   Ideally you would not need all of these systems.
[00:31:14.200 --> 00:31:19.000]   Now, in the real world, it's hard to get all the way to that point.
[00:31:19.000 --> 00:31:22.280]   If you can't get all the way to that point, then having all these systems is what you
[00:31:22.280 --> 00:31:24.880]   absolutely need.
[00:31:24.880 --> 00:31:27.600]   This weird step function here.
[00:31:27.600 --> 00:31:30.960]   So if you've simplified things, but there's still a non-trivial amount of work on your
[00:31:30.960 --> 00:31:38.440]   plate, by taming that with systems, you can actually get closer to the slow ideal.
[00:31:38.440 --> 00:31:43.440]   So having more systems is actually important when you're close to the slow productivity
[00:31:43.440 --> 00:31:45.920]   ideal, but not quite there.
[00:31:45.920 --> 00:31:48.600]   I've been working through some of these thoughts recently about slow productivity.
[00:31:48.600 --> 00:31:54.040]   I mean, I think, for example, part of what you can do with systems, if you're trying
[00:31:54.040 --> 00:31:59.640]   to be, embrace more slow productivity, is you can be much more automated about your
[00:31:59.640 --> 00:32:01.780]   small tasks.
[00:32:01.780 --> 00:32:05.600]   With the right systems, you can push these small tasks into certain times on certain
[00:32:05.600 --> 00:32:08.360]   days so that they're not weighing on your mind elsewise.
[00:32:08.360 --> 00:32:12.160]   So you can't get rid of them, but you can tame them, you can automate them and control
[00:32:12.160 --> 00:32:16.160]   them and move them into certain places where they only take your time three hours a week
[00:32:16.160 --> 00:32:17.360]   at these set times.
[00:32:17.360 --> 00:32:21.440]   That requires a lot of systems, but that's compressing the impact on your schedule.
[00:32:21.440 --> 00:32:26.280]   It's compressing the impact so your mind can be free in other times.
[00:32:26.280 --> 00:32:29.280]   I think being very careful about tracking what you're working on is critical if you're
[00:32:29.280 --> 00:32:33.440]   going to reduce that, because you can figure out what is my limits?
[00:32:33.440 --> 00:32:36.880]   What is the limit of work that I can handle easily?
[00:32:36.880 --> 00:32:41.120]   You can't figure that out if you're not carefully tracking this and tracking your time.
[00:32:41.120 --> 00:32:45.320]   So systems are critical for slow productivity.
[00:32:45.320 --> 00:32:49.640]   If and when, until you reach the slow productivity ideal, then maybe you don't need them anymore.
[00:32:49.640 --> 00:32:50.640]   Most of us aren't going to get there.
[00:32:50.640 --> 00:32:51.960]   So Brandon, most of us need systems.
[00:32:51.960 --> 00:32:56.360]   We want to be careful about our time so that we can protect that time.
[00:32:56.360 --> 00:33:02.000]   And then if we're lucky, we'll end up in a Merlin man type situation where we don't need
[00:33:02.000 --> 00:33:03.000]   the systems anymore.
[00:33:03.000 --> 00:33:08.400]   So until we get there, I think systems help make you do the best with what you can.
[00:33:08.400 --> 00:33:13.800]   All right, we got a question here from Steven.
[00:33:13.800 --> 00:33:19.560]   Steven says, "Hi Cal, I'm a software engineer and I struggle to stay focused anytime I have
[00:33:19.560 --> 00:33:22.280]   to wait for something to happen.
[00:33:22.280 --> 00:33:26.200]   For example, I may be waiting on a test suite to run or PR checks to pass or a service to
[00:33:26.200 --> 00:33:27.200]   start up.
[00:33:27.200 --> 00:33:30.480]   And these can take anywhere from two to 10 minutes.
[00:33:30.480 --> 00:33:32.480]   Is it okay to context switch these scenarios?
[00:33:32.480 --> 00:33:36.040]   And if not, what should I do with my attention given my next action will be dependent on
[00:33:36.040 --> 00:33:38.240]   the outcome of whatever I'm waiting for?"
[00:33:38.240 --> 00:33:41.160]   Steven, I hear this a lot from developers.
[00:33:41.160 --> 00:33:42.160]   They have all these pauses.
[00:33:42.160 --> 00:33:47.200]   Yeah, well, you're waiting for a compiler for your for your checks to complete.
[00:33:47.200 --> 00:33:52.760]   From a context switching perspective, there's two extremes that you should stick towards
[00:33:52.760 --> 00:33:53.760]   here.
[00:33:53.760 --> 00:33:58.240]   Very, very related activities are very, very unrelated activities.
[00:33:58.240 --> 00:34:00.660]   Don't go in the middle.
[00:34:00.660 --> 00:34:05.920]   So by very related activities, I'm working on this code, I'm running these checks on
[00:34:05.920 --> 00:34:07.680]   that, it's going to take four minutes.
[00:34:07.680 --> 00:34:13.400]   All right, during that four minutes, I'm looking at similar code, the next thing I'm going
[00:34:13.400 --> 00:34:17.520]   to test or I'm going back and trying to clean up some code I just wrote.
[00:34:17.520 --> 00:34:21.720]   So you stay, you're staying entirely within the context of the thing you're working on.
[00:34:21.720 --> 00:34:25.560]   That will minimize the context switching overhead because you're keeping most of the context
[00:34:25.560 --> 00:34:26.560]   the same.
[00:34:26.560 --> 00:34:29.780]   The other option is to go way far away from work altogether.
[00:34:29.780 --> 00:34:37.540]   So you say, "I need to go check Jesse Rogers' Twitter account to see how the player union
[00:34:37.540 --> 00:34:42.140]   management MLB union discussions are going today.
[00:34:42.140 --> 00:34:45.660]   And are we getting closer to an agreement on the collective bargaining?"
[00:34:45.660 --> 00:34:48.260]   Actually, their issue is with the competitive balance tax.
[00:34:48.260 --> 00:34:49.500]   Let's see what's going on there.
[00:34:49.500 --> 00:34:50.940]   That's so different from your work.
[00:34:50.940 --> 00:34:55.580]   But yes, it's a context shift, but it's not going to have nearly the same capture effect
[00:34:55.580 --> 00:34:59.020]   as something that's work related, but different than what you're doing.
[00:34:59.020 --> 00:35:01.060]   So what is this work related, but different what you're doing?
[00:35:01.060 --> 00:35:03.740]   What's the middle of the spectrum that's going to kill you?
[00:35:03.740 --> 00:35:06.180]   That's going to be things like email.
[00:35:06.180 --> 00:35:11.740]   Let me go look at other work related stuff, expose myself to questions I need to answer,
[00:35:11.740 --> 00:35:15.460]   responsibilities being put on my plate, stuff that people need from me, but I can't respond
[00:35:15.460 --> 00:35:16.860]   to all of them right now.
[00:35:16.860 --> 00:35:19.880]   And then turn my attention back to what I'm doing.
[00:35:19.880 --> 00:35:22.280]   That gray zone is what's killer.
[00:35:22.280 --> 00:35:25.800]   That gray zone, if you look at an email inbox, I'm seeing work stuff, but not super related
[00:35:25.800 --> 00:35:29.420]   to exactly what I'm doing is what's going to give you 20 minutes of sluggishness until
[00:35:29.420 --> 00:35:32.020]   you get your mind locked back in.
[00:35:32.020 --> 00:35:34.700]   That's the gray zone that if you keep going to it again and again throughout the morning
[00:35:34.700 --> 00:35:39.460]   by 2pm, you're done because that's a painful context shift.
[00:35:39.460 --> 00:35:42.860]   So either stick with what very close to what you're doing or go very far away from what
[00:35:42.860 --> 00:35:44.460]   you're doing.
[00:35:44.460 --> 00:35:46.120]   But don't go in somewhere in between.
[00:35:46.120 --> 00:35:50.340]   So unrelated work stuff, email is killer.
[00:35:50.340 --> 00:35:51.820]   Social media is killer.
[00:35:51.820 --> 00:35:54.060]   If it's emotionally arousing, that's also a problem.
[00:35:54.060 --> 00:35:56.180]   So I'll put that as a caveat.
[00:35:56.180 --> 00:36:02.700]   Don't look at information about the war, the Ukraine during your five minute check.
[00:36:02.700 --> 00:36:03.980]   That's also going to be quite diverting.
[00:36:03.980 --> 00:36:07.660]   So nothing emotionally arousing, nothing that's related, but not exactly related to what you're
[00:36:07.660 --> 00:36:09.820]   doing and it's the best you can do.
[00:36:09.820 --> 00:36:10.820]   All right.
[00:36:10.820 --> 00:36:15.780]   So we've got a question here from Tom.
[00:36:15.780 --> 00:36:21.980]   Tom says, "What do you do when you get tired?"
[00:36:21.980 --> 00:36:26.700]   He elaborates he's extremely good at sticking to time blocking, not going on social media,
[00:36:26.700 --> 00:36:29.820]   doing Pomodoro at the beginning of the week, but as the week goes on, I get a bit tired
[00:36:29.820 --> 00:36:32.380]   and burnt out and it's easier and easier to lose focus.
[00:36:32.380 --> 00:36:33.980]   I wonder if you can relate at all.
[00:36:33.980 --> 00:36:36.300]   Of course not, Tom.
[00:36:36.300 --> 00:36:38.060]   Tiredness is equivalent to cowardice.
[00:36:38.060 --> 00:36:39.060]   You should be ashamed.
[00:36:39.060 --> 00:36:40.060]   Don't do tiredness.
[00:36:40.060 --> 00:36:44.100]   No, Tom, of course people get tired.
[00:36:44.100 --> 00:36:46.500]   And there's two answers to this, right?
[00:36:46.500 --> 00:36:53.620]   I mean, one, if you're tired at a given day for whatever reason, sleep, sickness, et cetera,
[00:36:53.620 --> 00:36:56.260]   do less, do less that day.
[00:36:56.260 --> 00:36:58.260]   I mean, what are you doing during the day?
[00:36:58.260 --> 00:37:03.900]   You're taking energy and you're converting it into output of value.
[00:37:03.900 --> 00:37:08.100]   And you're doing that mainly by putting this energy through the circuits in your brain
[00:37:08.100 --> 00:37:11.500]   to add value to information if you're a knowledge worker, but you're converting energy to value
[00:37:11.500 --> 00:37:15.540]   if you have less energy, there's less value you can produce.
[00:37:15.540 --> 00:37:17.500]   So I think that's fine.
[00:37:17.500 --> 00:37:21.980]   The key, however, is to remain intentional about it.
[00:37:21.980 --> 00:37:26.380]   So the thing that you don't want to do is as you get tired, if you're tired in a given
[00:37:26.380 --> 00:37:32.140]   day or you get tired as the week goes on, you don't want to just become ad hoc and lax.
[00:37:32.140 --> 00:37:38.220]   Like, eh, I'm sort of falling off my time block schedule and going down rabbit holes
[00:37:38.220 --> 00:37:41.820]   online, and I sort of limp in for a finish on that day or limp in for a finish that week.
[00:37:41.820 --> 00:37:42.820]   No, don't do that.
[00:37:42.820 --> 00:37:45.060]   If you see you're less energy, say I'm going to work less today, but I'm going to make
[00:37:45.060 --> 00:37:48.100]   a plan for this less work day.
[00:37:48.100 --> 00:37:49.900]   I'm going to end it early.
[00:37:49.900 --> 00:37:52.580]   I'm going to put a two hour break in the middle.
[00:37:52.580 --> 00:37:56.260]   I'm going to move things from this week to next week, but I'm still going to stick to
[00:37:56.260 --> 00:37:57.260]   the plan.
[00:37:57.260 --> 00:37:59.420]   I'm just going to make a plan that better fits my energy.
[00:37:59.420 --> 00:38:00.580]   That is the key.
[00:38:00.580 --> 00:38:05.620]   That is the key to energy and time management is intentionality, intentionality, intentionality.
[00:38:05.620 --> 00:38:10.260]   If you are giving your time a job that is based off a realistic assessment of what's
[00:38:10.260 --> 00:38:12.800]   going on in your current context, you're winning.
[00:38:12.800 --> 00:38:18.600]   If you are letting other factors in your mind and context just push you around like a leaf
[00:38:18.600 --> 00:38:22.860]   on a turbulent stream, you're in trouble.
[00:38:22.860 --> 00:38:24.700]   The exhaustion is going to amplify.
[00:38:24.700 --> 00:38:25.700]   You're going to feel bad.
[00:38:25.700 --> 00:38:28.540]   You're not going to end up in a place that's good.
[00:38:28.540 --> 00:38:30.780]   So it's always the best thing to do is to be intentional.
[00:38:30.780 --> 00:38:33.760]   And the main point I want to make here, Tom, and I think it's a good one, and I'm glad
[00:38:33.760 --> 00:38:34.760]   you asked it.
[00:38:34.760 --> 00:38:39.460]   The main point I want to make is that some days you have more energy than others.
[00:38:39.460 --> 00:38:41.540]   That means there's less work you can produce and that's fine.
[00:38:41.540 --> 00:38:46.660]   But what I want to see again is a plan that reflects a lower energy day.
[00:38:46.660 --> 00:38:48.420]   Here's my lower energy day plan.
[00:38:48.420 --> 00:38:50.540]   I finish at two.
[00:38:50.540 --> 00:38:52.980]   I take an hour lunch or I don't work.
[00:38:52.980 --> 00:38:56.860]   I replace this hard thing with an easier thing, whatever you need to do.
[00:38:56.860 --> 00:38:58.860]   So be intentional about it, Tom.
[00:38:58.860 --> 00:39:01.940]   All right, let's see what else what we have here.
[00:39:01.940 --> 00:39:05.420]   I've got a question from DK.
[00:39:05.420 --> 00:39:13.700]   DK is asking if I have any suggestions on what habits to add and improve when going
[00:39:13.700 --> 00:39:16.860]   from a PhD to a postdoc.
[00:39:16.860 --> 00:39:22.460]   Yeah, postdocs are highly autonomous as compared to PhD programs.
[00:39:22.460 --> 00:39:23.980]   It's all about research.
[00:39:23.980 --> 00:39:26.620]   Build your whole day around research.
[00:39:26.620 --> 00:39:30.940]   That's what it's about is doing research, doing research well.
[00:39:30.940 --> 00:39:37.180]   You will find that you probably have more free time than you're used to because if all
[00:39:37.180 --> 00:39:39.620]   you're doing is research, there's only so much of you doing the research during the
[00:39:39.620 --> 00:39:40.620]   day.
[00:39:40.620 --> 00:39:41.860]   That's fine.
[00:39:41.860 --> 00:39:43.980]   Just build a schedule that doesn't require as many hours.
[00:39:43.980 --> 00:39:49.540]   I'll tell you what I did, DK, when I switched from my doctoral work to my postdoctoral work
[00:39:49.540 --> 00:39:54.060]   is I was looking ahead to when I was going to become a professor after being a postdoc.
[00:39:54.060 --> 00:39:58.780]   And I said, when I'm a professor, my time is going to be way more limited than it is
[00:39:58.780 --> 00:40:00.060]   right now as a postdoc.
[00:40:00.060 --> 00:40:05.460]   I'm going to have classes, I'm going to have committees, and I have students to supervise.
[00:40:05.460 --> 00:40:12.220]   And so I don't know, in addition to practicing research as a postdoc, I want to practice
[00:40:12.220 --> 00:40:15.500]   being effective at doing research even if I have reduced time.
[00:40:15.500 --> 00:40:18.980]   So I added artificial constraints to my schedule.
[00:40:18.980 --> 00:40:22.660]   I had a dog at this point, lived about a mile from campus.
[00:40:22.660 --> 00:40:26.420]   I've talked about this before, across the bridge in Beacon Hill.
[00:40:26.420 --> 00:40:30.740]   And so I built a schedule where I'd start at 9, but I'd take a two-hour block out of
[00:40:30.740 --> 00:40:31.740]   the middle of every day.
[00:40:31.740 --> 00:40:36.060]   Where I'd take my dog, Bailey, we'd go for a run.
[00:40:36.060 --> 00:40:42.060]   We'd run from the east campus there of MIT down the Charles, we would go down to the
[00:40:42.060 --> 00:40:43.780]   Mass Avenue Bridge.
[00:40:43.780 --> 00:40:47.140]   We'd cross at the Mass Avenue Bridge, come running back on the Charles on the Boston
[00:40:47.140 --> 00:40:48.140]   side.
[00:40:48.140 --> 00:40:52.460]   We'd exercise calisthenics on one of the docks that's out in the Charles River off of that
[00:40:52.460 --> 00:40:53.460]   exercise.
[00:40:53.460 --> 00:40:58.260]   And if it was winter, we would dig out a spot on that dock out of the snow to do our push-ups.
[00:40:58.260 --> 00:40:59.500]   We were hardcore about it.
[00:40:59.500 --> 00:41:01.220]   Then do our pull-ups.
[00:41:01.220 --> 00:41:05.220]   And so we would do this long run, weather didn't matter, I had gear.
[00:41:05.220 --> 00:41:09.780]   Go back to my apartment on Beacon Hill, I would have lunch, I would take a shower, and
[00:41:09.780 --> 00:41:14.740]   then I would walk back to campus, now crossing the Longfellow Bridge.
[00:41:14.740 --> 00:41:17.460]   This is like a two-hour plus thing.
[00:41:17.460 --> 00:41:21.300]   But I wanted to put an artificial constraint in my day to say, "Okay, I not only need to
[00:41:21.300 --> 00:41:25.140]   get used to doing research, but getting a lot of research done when I only have a limited
[00:41:25.140 --> 00:41:26.140]   amount of time."
[00:41:26.140 --> 00:41:28.100]   So I felt like I was training.
[00:41:28.100 --> 00:41:29.900]   I also wrote a book.
[00:41:29.900 --> 00:41:34.660]   So I wrote most of Sogo, They Can't Ignore You during my postdoc as well.
[00:41:34.660 --> 00:41:35.660]   So that's what I would suggest.
[00:41:35.660 --> 00:41:39.100]   It's all about research, get used to research, making progress on research.
[00:41:39.100 --> 00:41:40.460]   Don't worry about having too much time.
[00:41:40.460 --> 00:41:44.180]   In fact, this is a good time to do something else so you can practice doing that research
[00:41:44.180 --> 00:41:45.340]   with some constraints.
[00:41:45.340 --> 00:41:47.380]   It's an awesome job, basically, DK.
[00:41:47.380 --> 00:41:51.020]   It doesn't pay well, but it's otherwise an awesome job, so enjoy it.
[00:41:51.020 --> 00:41:54.900]   All right, we got a question from Jeff.
[00:41:54.900 --> 00:41:57.380]   Jeff wants to know about diet.
[00:41:57.380 --> 00:42:00.660]   Can you please discuss how you approach your diet?
[00:42:00.660 --> 00:42:04.460]   Have you experimented with what specific foods best facilitate deep work, and how do you
[00:42:04.460 --> 00:42:06.300]   balance this with realities of life?
[00:42:06.300 --> 00:42:12.340]   Jeff, I'm not super strict about this, but I would say that the person I default back
[00:42:12.340 --> 00:42:16.460]   to following on food is probably Mark Sisson.
[00:42:16.460 --> 00:42:19.260]   I like the way Mark Sisson talks about things.
[00:42:19.260 --> 00:42:21.860]   There's different ways to describe what he's talking about.
[00:42:21.860 --> 00:42:25.220]   It's keto adjacent.
[00:42:25.220 --> 00:42:28.040]   So he talks about metabolic flexibility.
[00:42:28.040 --> 00:42:32.900]   So it's not that you want to be in ketosis all the time, but you have the ability to
[00:42:32.900 --> 00:42:35.060]   tip over into ketosis a little bit and come back.
[00:42:35.060 --> 00:42:39.580]   But what that means for people who don't follow that type of stuff is not a lot of simple
[00:42:39.580 --> 00:42:41.180]   sugars, not a lot of carbohydrates.
[00:42:41.180 --> 00:42:44.020]   It's not carb-free, but you're not eating a ton of bread.
[00:42:44.020 --> 00:42:47.300]   You're not eating a ton of pasta.
[00:42:47.300 --> 00:42:52.740]   Healthy fats, vegetables, proteins, what you would think.
[00:42:52.740 --> 00:42:55.420]   And I've fallen back on him as a default.
[00:42:55.420 --> 00:42:58.260]   I try to eat that way to the best of my ability.
[00:42:58.260 --> 00:43:01.580]   Jesse, I know you think about this more.
[00:43:01.580 --> 00:43:05.620]   Again, my understanding of your diet is you eat once every two weeks.
[00:43:05.620 --> 00:43:06.620]   Is that right?
[00:43:06.620 --> 00:43:07.620]   But what do you do?
[00:43:07.620 --> 00:43:08.620]   What do you do for your food?
[00:43:08.620 --> 00:43:11.100]   Because you care about this more than I do.
[00:43:11.100 --> 00:43:12.540]   I'm actually just looking up Mark Sisson.
[00:43:12.540 --> 00:43:13.620]   I've never heard of him.
[00:43:13.620 --> 00:43:14.620]   He's jack.
[00:43:14.620 --> 00:43:15.620]   Yeah.
[00:43:15.620 --> 00:43:16.620]   And he's 65 now, I think.
[00:43:16.620 --> 00:43:17.620]   Yeah.
[00:43:17.620 --> 00:43:18.620]   Yeah.
[00:43:18.620 --> 00:43:19.620]   I'm going to start following him.
[00:43:19.620 --> 00:43:23.100]   So do you know the Mark Sisson story?
[00:43:23.100 --> 00:43:24.100]   No.
[00:43:24.100 --> 00:43:25.100]   Okay.
[00:43:25.100 --> 00:43:26.260]   He's an endurance athlete.
[00:43:26.260 --> 00:43:27.260]   He was an endurance athlete.
[00:43:27.260 --> 00:43:31.420]   He was a professional triathlete when he was younger.
[00:43:31.420 --> 00:43:32.580]   And destroyed his body.
[00:43:32.580 --> 00:43:34.580]   He was sick all the time.
[00:43:34.580 --> 00:43:36.540]   I think he got prediabetes at some point.
[00:43:36.540 --> 00:43:40.380]   Because back then, it was like carb, carb, carb.
[00:43:40.380 --> 00:43:43.860]   And it's not like you're going to look fat if you're a professional athlete.
[00:43:43.860 --> 00:43:44.860]   You're burning it all up.
[00:43:44.860 --> 00:43:46.420]   But it was just ripping up his body.
[00:43:46.420 --> 00:43:49.140]   He was having immune responses or whatever.
[00:43:49.140 --> 00:43:50.140]   And so he shifted.
[00:43:50.140 --> 00:43:52.740]   He was one of the early sort of paleoprimal type people.
[00:43:52.740 --> 00:43:53.740]   He's like, you know what?
[00:43:53.740 --> 00:43:57.380]   I'm just going to eat the junk that was around for hundreds of thousands of years.
[00:43:57.380 --> 00:44:03.900]   And he sort of switched over to no more grains, no more processed food.
[00:44:03.900 --> 00:44:04.900]   And he did that early on.
[00:44:04.900 --> 00:44:06.860]   And all of his issues went away.
[00:44:06.860 --> 00:44:11.100]   His knee problems and his joint problems and his prediabetes.
[00:44:11.100 --> 00:44:13.100]   And he got really jacked.
[00:44:13.100 --> 00:44:14.940]   He's a big guy.
[00:44:14.940 --> 00:44:16.180]   And then he started a company eventually.
[00:44:16.180 --> 00:44:20.140]   So he had an early blog called Mark's Daily Apple, where he would talk about this stuff.
[00:44:20.140 --> 00:44:21.740]   And he had a cool book called The Primal Blueprint.
[00:44:21.740 --> 00:44:23.180]   Because it wasn't just about food.
[00:44:23.180 --> 00:44:25.940]   It was like, you need to live like a caveman type stuff.
[00:44:25.940 --> 00:44:27.740]   He was early to that.
[00:44:27.740 --> 00:44:30.540]   But more accessible than like a Rob Wolf type.
[00:44:30.540 --> 00:44:36.620]   And then he started a company called Primal Kitchen that was doing mainly salad dressings.
[00:44:36.620 --> 00:44:40.020]   That were made with avocado oil.
[00:44:40.020 --> 00:44:42.020]   So it didn't have the junk seed oils.
[00:44:42.020 --> 00:44:43.380]   And didn't have sugars in them.
[00:44:43.380 --> 00:44:47.980]   And so if you liked what he was doing, he had mayonnaises and salad dressings or whatever.
[00:44:47.980 --> 00:44:52.140]   And about four or five years ago, Kraft bought that for $200 million.
[00:44:52.140 --> 00:44:54.740]   So then he peaced out of California.
[00:44:54.740 --> 00:44:57.220]   And he lives down on Miami Beach now.
[00:44:57.220 --> 00:44:59.180]   And is tanned and ripped.
[00:44:59.180 --> 00:45:00.940]   And is doing well for himself.
[00:45:00.940 --> 00:45:02.940]   But anyways, I like him.
[00:45:02.940 --> 00:45:03.940]   He's accessible too.
[00:45:03.940 --> 00:45:07.580]   He doesn't get weirdly doctrinaire.
[00:45:07.580 --> 00:45:09.860]   Some people, like paleo people can get weirdly doctrinaire.
[00:45:09.860 --> 00:45:17.500]   Where they're arguing about what nuts a Neanderthal in this region of France would have had access
[00:45:17.500 --> 00:45:19.420]   to during the early place.
[00:45:19.420 --> 00:45:20.740]   No, he's not super doctrinaire.
[00:45:20.740 --> 00:45:24.500]   He's like, guys, just don't eat a bunch of flour and sugar and crap that didn't exist.
[00:45:24.500 --> 00:45:26.380]   And healthy fats are good.
[00:45:26.380 --> 00:45:28.140]   And be outside a lot.
[00:45:28.140 --> 00:45:29.700]   And don't just be in a gym.
[00:45:29.700 --> 00:45:31.780]   He's all about play.
[00:45:31.780 --> 00:45:33.540]   Do sports and stuff with people.
[00:45:33.540 --> 00:45:34.540]   Or when you're outside.
[00:45:34.540 --> 00:45:35.540]   So that's Marxism.
[00:45:35.540 --> 00:45:37.700]   But anyway, so back to your diet.
[00:45:37.700 --> 00:45:44.260]   So once every two weeks, you eat one gallon of athletic greens.
[00:45:44.260 --> 00:45:45.260]   Is that how it works?
[00:45:45.260 --> 00:45:51.020]   You just have a giant bucket of athletic greens that you sit there and you spend an hour and
[00:45:51.020 --> 00:45:52.220]   you eat it once every two weeks.
[00:45:52.220 --> 00:45:53.220]   Do I have that about right?
[00:45:53.220 --> 00:45:54.900]   Yeah, more or less.
[00:45:54.900 --> 00:45:58.420]   Actually a good resource is Tom Brady's TV 12 book.
[00:45:58.420 --> 00:46:00.980]   They got a good chapter in there on food and diet.
[00:46:00.980 --> 00:46:01.980]   I looked at that book.
[00:46:01.980 --> 00:46:08.500]   A lot of it's like, not that it's weird, but a lot of it's about flexibility.
[00:46:08.500 --> 00:46:12.820]   It felt very specific to being a 40 year old quarterback.
[00:46:12.820 --> 00:46:16.820]   Like aggressive work to make tendons more flexible.
[00:46:16.820 --> 00:46:19.660]   There's a chapter though in there about nutrition and what he buys at the store.
[00:46:19.660 --> 00:46:20.740]   And there's some good stuff in there.
[00:46:20.740 --> 00:46:24.140]   Is that what you do?
[00:46:24.140 --> 00:46:28.220]   It seems like Mark and Brady, they eat pretty much the same stuff.
[00:46:28.220 --> 00:46:29.220]   It's pretty simple.
[00:46:29.220 --> 00:46:32.020]   They just eat the sugar and other...
[00:46:32.020 --> 00:46:36.340]   Why is there this, I don't get this pushback on the paleo world.
[00:46:36.340 --> 00:46:38.420]   There's a huge pushback on it.
[00:46:38.420 --> 00:46:42.100]   And I think it's just personal.
[00:46:42.100 --> 00:46:45.140]   People don't like the paleo people are kind of annoying.
[00:46:45.140 --> 00:46:49.500]   And so they're like, well, we're going to dunk on you and say there was grains of certain
[00:46:49.500 --> 00:46:50.980]   types that people ate or this or that.
[00:46:50.980 --> 00:46:55.420]   And the whole thing to me seems pretty crazy because what could be more self-evident than
[00:46:55.420 --> 00:47:03.300]   at the very least, you can't possibly be doing harm by focusing mainly on foods that humans
[00:47:03.300 --> 00:47:04.540]   ate for a long time.
[00:47:04.540 --> 00:47:09.100]   Now you could debate like, okay, maybe bread's not as bad as you think it is or something
[00:47:09.100 --> 00:47:15.540]   like this, but you can't possibly be doing harm by not eating bread because that's whatever
[00:47:15.540 --> 00:47:17.860]   it is, 10,000 years old or something like that.
[00:47:17.860 --> 00:47:26.900]   You can't possibly be doing harm by not eating cane sugar because we barely ate that until
[00:47:26.900 --> 00:47:27.900]   recently.
[00:47:27.900 --> 00:47:34.500]   So that's what I don't get about is the pushback is if you avoid stuff that is new, you're
[00:47:34.500 --> 00:47:40.660]   avoiding processed food, you're avoiding sugar, you're avoiding a lot of processed carbohydrates,
[00:47:40.660 --> 00:47:43.100]   can't possibly be bad.
[00:47:43.100 --> 00:47:49.380]   So then the debate is about like, well, maybe not doing that isn't as bad as you think,
[00:47:49.380 --> 00:47:51.580]   or maybe these things you're avoiding maybe aren't as bad as you're thinking.
[00:47:51.580 --> 00:47:52.580]   Yeah, maybe it is.
[00:47:52.580 --> 00:47:55.860]   But I think a lot of it's just they don't like how annoying, which they do get annoying.
[00:47:55.860 --> 00:47:59.700]   The paleo people get so doctrinaire and weird about it because people like to be doctrinaire
[00:47:59.700 --> 00:48:00.700]   and weird about things.
[00:48:00.700 --> 00:48:07.380]   But this is general idea of like, you're not going to go wrong eating meats and vegetables
[00:48:07.380 --> 00:48:12.500]   and fruits in moderation, like roughly what you might've eaten 20,000 years ago.
[00:48:12.500 --> 00:48:15.420]   It's not going to be unhealthy.
[00:48:15.420 --> 00:48:16.420]   Yeah.
[00:48:16.420 --> 00:48:19.340]   I mean, the food industry does such a good job of marketing.
[00:48:19.340 --> 00:48:24.580]   You walk into any grocery store, like the whole middle of it is all well-marketed, really
[00:48:24.580 --> 00:48:28.300]   good tasting stuff that's not good for you.
[00:48:28.300 --> 00:48:34.020]   I mean, what Sisson does, I think is he calls it a big ass salad, but his first meal of
[00:48:34.020 --> 00:48:38.020]   the day, he makes a huge salad with all sorts of crap in it.
[00:48:38.020 --> 00:48:41.500]   And he has these salad dressings, which because he's all about healthy fats, so they're avocado
[00:48:41.500 --> 00:48:43.580]   oil dressings, like get fat, right?
[00:48:43.580 --> 00:48:44.580]   But healthy fats.
[00:48:44.580 --> 00:48:50.580]   He has this huge salad and it makes him full and then he does a good dinner.
[00:48:50.580 --> 00:48:56.180]   We have lean steak and we eat broccoli and whatever, like stuff he likes and doesn't
[00:48:56.180 --> 00:48:57.180]   think about that much.
[00:48:57.180 --> 00:49:02.020]   And spends a lot of time outside and exercises in various ways and hangs out with people
[00:49:02.020 --> 00:49:03.020]   on the beach.
[00:49:03.020 --> 00:49:06.140]   The other thing too is like going to restaurants and stuff.
[00:49:06.140 --> 00:49:09.460]   I mean, it's hard to eat well in restaurants, any restaurant really.
[00:49:09.460 --> 00:49:12.140]   I mean, the food tastes really good and it's super salty.
[00:49:12.140 --> 00:49:13.140]   Yeah.
[00:49:13.140 --> 00:49:14.140]   Got a lot of butter.
[00:49:14.140 --> 00:49:15.140]   Yeah.
[00:49:15.140 --> 00:49:16.140]   I hear you with that.
[00:49:16.140 --> 00:49:17.140]   All right, Jeff.
[00:49:17.140 --> 00:49:18.140]   So I don't know.
[00:49:18.140 --> 00:49:21.180]   I don't know if that was helpful, but at the very least, look at pictures of how ripped
[00:49:21.180 --> 00:49:26.260]   the 65 year old man is because it's almost disturbing.
[00:49:26.260 --> 00:49:32.620]   It's like a little bit disturbing because he's old, but he's my hero from a food perspective
[00:49:32.620 --> 00:49:33.620]   and read the primal blueprint.
[00:49:33.620 --> 00:49:34.620]   It's a cool book.
[00:49:34.620 --> 00:49:36.900]   All right, let's do one more question here.
[00:49:36.900 --> 00:49:37.900]   What are we at?
[00:49:37.900 --> 00:49:39.140]   We're rolling along here.
[00:49:39.140 --> 00:49:40.860]   Let's do one more deep work question.
[00:49:40.860 --> 00:49:43.220]   This one is from Sparky.
[00:49:43.220 --> 00:49:50.700]   Sparky says in a 2014 blog post, you talked about temporary plans.
[00:49:50.700 --> 00:49:55.460]   As I am a professor as well, these longer two to three week plans seem more useful than
[00:49:55.460 --> 00:49:59.180]   a purely weekly plan for occasions like into the semester or a period before spring break
[00:49:59.180 --> 00:50:00.380]   or big conference travel.
[00:50:00.380 --> 00:50:03.660]   Do you have any updated tips or advice for these?
[00:50:03.660 --> 00:50:04.780]   I do Sparky.
[00:50:04.780 --> 00:50:11.780]   So when I used to talk about temporary plans, these were either habits you were temporarily
[00:50:11.780 --> 00:50:18.380]   trying out or work heuristics or plans that apply to a time delimited period, like the
[00:50:18.380 --> 00:50:20.020]   next month or the next two or three weeks.
[00:50:20.020 --> 00:50:21.700]   And I used to email these to myself.
[00:50:21.700 --> 00:50:25.300]   They'd be in my inbox, temporary plans.
[00:50:25.300 --> 00:50:27.220]   So I could see them in there.
[00:50:27.220 --> 00:50:29.580]   The main change I've made Sparky is I don't do that anymore.
[00:50:29.580 --> 00:50:34.260]   I just have the temporary plans live on my weekly plan.
[00:50:34.260 --> 00:50:37.500]   And when I redo my weekly plan, I'll be like, yeah, this temporary plan is still in effect.
[00:50:37.500 --> 00:50:40.240]   So I'll just keep it there.
[00:50:40.240 --> 00:50:43.820]   And I used to email my temporary plans to myself, my weekly plans to myself rather.
[00:50:43.820 --> 00:50:44.820]   Now I print them out.
[00:50:44.820 --> 00:50:49.540]   Now I just keep, I don't want to have to look in my inbox at any occasion when I don't have
[00:50:49.540 --> 00:50:50.540]   to.
[00:50:50.540 --> 00:50:54.180]   So that's my one change is just have that live on your weekly plan at the top of your
[00:50:54.180 --> 00:50:55.960]   weekly plan.
[00:50:55.960 --> 00:50:58.940]   You can even label them as like ongoing or temporary plans.
[00:50:58.940 --> 00:51:02.760]   And I just have a Word document where my last weekly plan exists.
[00:51:02.760 --> 00:51:04.340]   And I just update it.
[00:51:04.340 --> 00:51:08.500]   When I update it, there's a lot of these bigger picture, temporary plan or heuristic type
[00:51:08.500 --> 00:51:10.500]   things that I just keep there.
[00:51:10.500 --> 00:51:12.140]   So that'd be my only change.
[00:51:12.140 --> 00:51:13.620]   All right.
[00:51:13.620 --> 00:51:16.600]   So that's what we have about deep work.
[00:51:16.600 --> 00:51:22.100]   Before we go on to questions about the deep life, however, I want to talk briefly about
[00:51:22.100 --> 00:51:26.700]   another sponsor that helps make this show possible.
[00:51:26.700 --> 00:51:27.980]   That sponsor is Mark Sisson.
[00:51:27.980 --> 00:51:30.500]   So thank you, Mark Sisson.
[00:51:30.500 --> 00:51:32.500]   Mark Sisson, weirdly ripped.
[00:51:32.500 --> 00:51:33.500]   All right.
[00:51:33.500 --> 00:51:35.140]   So that's one of our sponsors.
[00:51:35.140 --> 00:51:37.260]   No, but actually this is a nutritional sponsor.
[00:51:37.260 --> 00:51:39.660]   So it's relevant.
[00:51:39.660 --> 00:51:43.580]   And that is Just Egg.
[00:51:43.580 --> 00:51:45.820]   So Jess and I were just talking about diet, right?
[00:51:45.820 --> 00:51:51.740]   As part of talking about diet, we talked about how we eat clean, avoid a bunch of processed
[00:51:51.740 --> 00:51:55.340]   food, avoid a lot of carbohydrates and sugars.
[00:51:55.340 --> 00:51:59.660]   And this is why often for breakfast, I'm an eggs guy.
[00:51:59.660 --> 00:52:06.420]   Good healthy fat eggs bought from the farmer's market is I love it, but that's a lot of eggs.
[00:52:06.420 --> 00:52:10.020]   If you're going to have that every single day, and this is where Just Eggs enters the
[00:52:10.020 --> 00:52:12.280]   picture.
[00:52:12.280 --> 00:52:17.460]   Just Eggs is a company that's going to help you cook the best omelets you'll have all
[00:52:17.460 --> 00:52:20.580]   year round, all while changing the world one egg at a time.
[00:52:20.580 --> 00:52:27.580]   And the way they do it is with their product, which is a cholesterol free plant based egg
[00:52:27.580 --> 00:52:32.660]   that will give you the most decadent quiches of your life, the fluffiest scrambles and
[00:52:32.660 --> 00:52:36.420]   the easiest egg sandwiches of all time.
[00:52:36.420 --> 00:52:39.580]   It has about the same protein as a chicken egg, but less saturated fat.
[00:52:39.580 --> 00:52:44.580]   Plus Just Egg is packed with cholesterol, lowing polyunsaturated fat.
[00:52:44.580 --> 00:52:48.340]   Chicken eggs wish they were this healthy.
[00:52:48.340 --> 00:52:54.580]   And because Just Eggs comes from plants, you're also helping to save the planet.
[00:52:54.580 --> 00:52:58.740]   This is why I like Just Eggs is sure I like chicken eggs, but I get a little bit uncomfortable
[00:52:58.740 --> 00:53:01.260]   eating them every single day.
[00:53:01.260 --> 00:53:04.580]   Throw Just Eggs into the rotation.
[00:53:04.580 --> 00:53:05.580]   They taste great.
[00:53:05.580 --> 00:53:07.540]   They're based on plants.
[00:53:07.540 --> 00:53:09.340]   It feels lighter.
[00:53:09.340 --> 00:53:10.580]   I am a fan.
[00:53:10.580 --> 00:53:14.500]   So Just Eggs, really good eggs.
[00:53:14.500 --> 00:53:16.140]   That's a good tagline.
[00:53:16.140 --> 00:53:17.740]   Just Eggs, really good eggs.
[00:53:17.740 --> 00:53:20.980]   So keep your eyes peeled for Just Eggs.
[00:53:20.980 --> 00:53:26.700]   I also want to talk about New Relic.
[00:53:26.700 --> 00:53:32.840]   So New Relic is a company that is very relevant if you are a software engineer.
[00:53:32.840 --> 00:53:38.420]   If you're a software engineer, you've probably been there before where it is 9pm, you're
[00:53:38.420 --> 00:53:45.940]   finally unwinding from work, your phone buzzes with an alert, and something's broken.
[00:53:45.940 --> 00:53:49.580]   So your mind begins racing trying to figure out what could be wrong.
[00:53:49.580 --> 00:53:50.580]   Is it my server?
[00:53:50.580 --> 00:53:54.540]   Is there a network connection down that I misconfigure something in my cloud setup,
[00:53:54.540 --> 00:53:58.960]   you have a whole team now scrambling from tool to tool and loading up this web interface
[00:53:58.960 --> 00:54:03.900]   and running this kludge together script that someone wrote messaging person after person
[00:54:03.900 --> 00:54:05.060]   trying to fix the issue.
[00:54:05.060 --> 00:54:13.260]   So this is a very large problem that you will not face if you use New Relic.
[00:54:13.260 --> 00:54:17.440]   So New Relic combines 16 different monitoring products that you'd normally buy separately.
[00:54:17.440 --> 00:54:22.300]   So engineering teams can see across their entire software stack in one place.
[00:54:22.300 --> 00:54:27.520]   There's a problem, load up New Relic, look at the dashboard, boom, there it is.
[00:54:27.520 --> 00:54:28.620]   There's the issue.
[00:54:28.620 --> 00:54:33.260]   So you can pinpoint issues down to the line of code.
[00:54:33.260 --> 00:54:38.300]   So you know exactly why the problem happened, and how you can resolve it quickly.
[00:54:38.300 --> 00:54:43.780]   That's why the dev teams and ops teams at places like DoorDash, GitHub and Epic Games
[00:54:43.780 --> 00:54:47.060]   rely on New Bug to debug and improve their software.
[00:54:47.060 --> 00:54:48.060]   I was blown away.
[00:54:48.060 --> 00:54:51.620]   I talked to someone from New Relic.
[00:54:51.620 --> 00:54:54.620]   I'm blown away by how widely used this is.
[00:54:54.620 --> 00:54:58.420]   Jesse, if you had to guess, and I know if there's one thing you know about, it's debugging
[00:54:58.420 --> 00:55:00.060]   real time issues with software stacks.
[00:55:00.060 --> 00:55:05.380]   But if you had to guess, how many companies do you think are using New Relic right now?
[00:55:05.380 --> 00:55:08.020]   1500.
[00:55:08.020 --> 00:55:10.660]   More than 14,000.
[00:55:10.660 --> 00:55:15.980]   So if you're in the world, if you're a dev teams or an ops team, this is like hearing,
[00:55:15.980 --> 00:55:17.780]   I don't know, Microsoft or something.
[00:55:17.780 --> 00:55:21.460]   It is the player that you have to keep in mind.
[00:55:21.460 --> 00:55:25.780]   So whether you're running a cloud native startup or a fortune 500 company, it takes just five
[00:55:25.780 --> 00:55:29.780]   minutes to set up New Relic in your environment.
[00:55:29.780 --> 00:55:34.860]   So that next 9pm call is just waiting to happen, get New Relic before it does.
[00:55:34.860 --> 00:55:39.460]   You can get access to the whole New Relic platform and 100 gigabytes of data forever
[00:55:39.460 --> 00:55:44.540]   no credit card required if you sign up at New Relic.com slash deep.
[00:55:44.540 --> 00:55:55.580]   That's any w r e l i c.com slash deep New Relic.com slash deep.
[00:55:55.580 --> 00:55:58.700]   You're only if you don't get New Relic, your alternative is to have Jesse debug your software
[00:55:58.700 --> 00:55:59.700]   stack.
[00:55:59.700 --> 00:56:01.420]   That's your options.
[00:56:01.420 --> 00:56:09.820]   New Relic, 16 tools all in one place, or Jesse, who will turn it off and turn it back on.
[00:56:09.820 --> 00:56:10.820]   That fix your problem.
[00:56:10.820 --> 00:56:13.740]   Did you try unplugging it?
[00:56:13.740 --> 00:56:16.060]   Yeah, that's all I would be able to offer to you.
[00:56:16.060 --> 00:56:17.940]   I am a terrible at software.
[00:56:17.940 --> 00:56:19.620]   Computer scientists use terrible at software.
[00:56:19.620 --> 00:56:22.660]   But what I can do is answer questions about the deep life.
[00:56:22.660 --> 00:56:24.900]   And that's what we're gonna do right now.
[00:56:24.900 --> 00:56:31.540]   We got one here from Andrew, writing all the way from Australia.
[00:56:31.540 --> 00:56:36.940]   He says Morning Cal, I started my PhD late last year, and stumbling on your books and
[00:56:36.940 --> 00:56:40.100]   podcasts has helped me focus and work deeper.
[00:56:40.100 --> 00:56:44.100]   I love trail running and doing Ironmans, but I'm struggling to permit myself to continue
[00:56:44.100 --> 00:56:48.940]   training and competing in these while undertaking the biggest deep work of my life so far my
[00:56:48.940 --> 00:56:51.940]   PhD.
[00:56:51.940 --> 00:56:54.500]   Can I do both or should I just focus on the PhD?
[00:56:54.500 --> 00:56:57.380]   Andrew, I think you should do both.
[00:56:57.380 --> 00:57:07.180]   Do not inflate the PhD in your mind to be this incredibly difficult hell week at Navy
[00:57:07.180 --> 00:57:14.900]   SEAL training, taking the beach at Normandy type of massive trial that some people do
[00:57:14.900 --> 00:57:18.660]   and say this is a relatively easy job.
[00:57:18.660 --> 00:57:22.540]   I have some classes and the classes are done and then I mainly focus on research and research
[00:57:22.540 --> 00:57:25.380]   is hard, but it only takes up so much of your time each day.
[00:57:25.380 --> 00:57:29.260]   So I say do the hardcore athletic training if anything is going to help balance you out
[00:57:29.260 --> 00:57:34.580]   so that when you get worn out intellectually, your confidence gets shaken.
[00:57:34.580 --> 00:57:39.360]   Oh, man, I'm not getting this my paper got rejected, you have something else to do.
[00:57:39.360 --> 00:57:41.380]   And so do those two things.
[00:57:41.380 --> 00:57:47.340]   For most programs, again, a PhD program is not this huge, life consuming type of position.
[00:57:47.340 --> 00:57:53.980]   I know this in part because when I was writing about student stuff, PhD student myself, I
[00:57:53.980 --> 00:57:59.780]   was writing about a lot of student stuff, I had noticed there was this disturbing subculture
[00:57:59.780 --> 00:58:06.620]   of people at this point largely blogging, sort of pre-social media, blogging about life
[00:58:06.620 --> 00:58:07.900]   as a grad student.
[00:58:07.900 --> 00:58:13.380]   And they would inflate it into this like terrible thing that was the hardest burden that anyone
[00:58:13.380 --> 00:58:18.280]   would ever do and these things had titles like dissertation hell and you would read
[00:58:18.280 --> 00:58:25.900]   these things and you would think, you would think that these students had been deployed
[00:58:25.900 --> 00:58:31.980]   to war torn countries in which they had to run life threatening commando raids through
[00:58:31.980 --> 00:58:33.700]   terrible conditions or something like this.
[00:58:33.700 --> 00:58:38.100]   And what I finally figured out was happening is that being a doctoral student, A, is a
[00:58:38.100 --> 00:58:39.180]   really weird job.
[00:58:39.180 --> 00:58:40.500]   It's not like a normal job.
[00:58:40.500 --> 00:58:45.900]   There's big periods where you don't have much to do or the things you do is non-standard.
[00:58:45.900 --> 00:58:48.700]   It's not people giving you tasks to accomplish.
[00:58:48.700 --> 00:58:50.860]   You don't have a nine to five schedule.
[00:58:50.860 --> 00:58:52.740]   That makes a lot of people uncomfortable.
[00:58:52.740 --> 00:58:54.420]   Like is this really a job I have?
[00:58:54.420 --> 00:59:00.460]   So by inflating it to be this big, hard thing, I think it somehow helps people counter that
[00:59:00.460 --> 00:59:03.260]   feeling of like, I don't really have a real job.
[00:59:03.260 --> 00:59:04.940]   So I thought that was part of it.
[00:59:04.940 --> 00:59:09.460]   Another part of it is there is an anxiety or intellectual insecurity that a lot of people
[00:59:09.460 --> 00:59:11.020]   rightly would suffer from.
[00:59:11.020 --> 00:59:13.580]   When I say rightly, I mean it's justified because it's a weird world.
[00:59:13.580 --> 00:59:19.520]   It's a job that's all about your brain and people posturing who's smarter and it helps
[00:59:19.520 --> 00:59:20.520]   you feel better.
[00:59:20.520 --> 00:59:26.180]   I can justify this anxiety I'm feeling about intellectual issues, like can I keep up or
[00:59:26.180 --> 00:59:32.460]   whatever by just describing what I'm going through as this big, terrible thing in general.
[00:59:32.460 --> 00:59:34.540]   And then your anxiety makes sense.
[00:59:34.540 --> 00:59:36.800]   But I'm going to say resist that.
[00:59:36.800 --> 00:59:38.940]   It's a pretty easy job.
[00:59:38.940 --> 00:59:49.820]   And again, I wrote two books during my PhD that had nothing to do with my PhD, just as
[00:59:49.820 --> 00:59:51.580]   something to do on the side.
[00:59:51.580 --> 00:59:54.920]   And I ran study hacks where we were doing three posts a week back then.
[00:59:54.920 --> 00:59:57.340]   And I was still bored because it's kind of a fake job.
[00:59:57.340 --> 01:00:00.340]   So Andrew, keep training for Iron Man at the same time.
[01:00:00.340 --> 01:00:01.660]   All right.
[01:00:01.660 --> 01:00:06.620]   Jennifer asks, at what age will you allow your kids to have phones and access to social
[01:00:06.620 --> 01:00:07.620]   media?
[01:00:07.620 --> 01:00:09.500]   Well, we'll see, Jennifer.
[01:00:09.500 --> 01:00:12.380]   I mean, I think the culture around this, as I talk about, is changing.
[01:00:12.380 --> 01:00:16.900]   So by the time it's relevant, the culture on this may have already changed.
[01:00:16.900 --> 01:00:23.140]   But in general, right now, the way I think about it is I'm fine with flip phones, like
[01:00:23.140 --> 01:00:27.820]   whatever age it is that it becomes convenient for you to be able to text your kid.
[01:00:27.820 --> 01:00:31.780]   You know, they're at sports practice and can you come pick me up or they want to text their
[01:00:31.780 --> 01:00:33.540]   friends like, are you coming over today?
[01:00:33.540 --> 01:00:36.980]   I don't know what age that becomes relevant.
[01:00:36.980 --> 01:00:37.980]   But a flip phone is fine.
[01:00:37.980 --> 01:00:42.980]   I have no problem with text communication and I recognize that it's useful.
[01:00:42.980 --> 01:00:47.380]   Giving a kid, however, access to a full smartphone where they have unrestricted access to the
[01:00:47.380 --> 01:00:52.140]   internet and social media, sanctioning your kid having social media accounts, I would
[01:00:52.140 --> 01:00:56.980]   say 16 at the youngest, 18 from the psychology perspective is probably better.
[01:00:56.980 --> 01:01:01.380]   Hey, when you leave this house, you do you, but nothing good is going to come from an
[01:01:01.380 --> 01:01:03.660]   adolescent brain having access to it.
[01:01:03.660 --> 01:01:06.500]   This doesn't make me popular among a lot of teenagers.
[01:01:06.500 --> 01:01:10.660]   However, as I've written before and talked about before, the culture is changing on this.
[01:01:10.660 --> 01:01:14.660]   I think the idea that teenagers should be using social media is something that we'll
[01:01:14.660 --> 01:01:19.860]   look back on six or seven years from now and say that was not a good idea.
[01:01:19.860 --> 01:01:22.380]   Teenagers themselves are also increasingly turning on this.
[01:01:22.380 --> 01:01:27.340]   They have moved most of their socializing out of tools such as Snapchat and into instant
[01:01:27.340 --> 01:01:29.060]   messenger and text messaging.
[01:01:29.060 --> 01:01:33.460]   So social media does no longer really plays as critical of a role in their social life.
[01:01:33.460 --> 01:01:37.940]   So it's much easier for them to not be on, say, Instagram or to not be on Snapchat because
[01:01:37.940 --> 01:01:41.700]   they're using text and WhatsApp type tools.
[01:01:41.700 --> 01:01:47.780]   Now the role these tools play in young people's lives is increasingly more cultural and entertainment
[01:01:47.780 --> 01:01:49.060]   related.
[01:01:49.060 --> 01:01:54.860]   So like TikTok is very popular with young kids, but not being on TikTok is not nearly
[01:01:54.860 --> 01:01:59.780]   as big of an issue as seven or eight years ago, not being on Snapchat because people
[01:01:59.780 --> 01:02:02.460]   aren't using TikTok to talk to each other.
[01:02:02.460 --> 01:02:07.820]   People aren't using TikTok to discuss with other people in their schools, the party that
[01:02:07.820 --> 01:02:11.420]   went on or to see where people are going or to be plugged into a social scene.
[01:02:11.420 --> 01:02:14.820]   They're largely consuming content on TikTok.
[01:02:14.820 --> 01:02:17.420]   So if you're not using it, who cares?
[01:02:17.420 --> 01:02:19.520]   You're communicating with your friends on text.
[01:02:19.520 --> 01:02:20.520]   They might be using TikTok.
[01:02:20.520 --> 01:02:21.520]   If you're not, what do you miss?
[01:02:21.520 --> 01:02:24.040]   There's some cultural theme that you don't know about.
[01:02:24.040 --> 01:02:25.660]   So I think things are getting better with that.
[01:02:25.660 --> 01:02:30.140]   But honestly, that is my read of the psychological literature right now is be very, very wary
[01:02:30.140 --> 01:02:35.380]   of giving the adolescent brain unrestricted access to social internet tools.
[01:02:35.380 --> 01:02:36.940]   All right.
[01:02:36.940 --> 01:02:40.900]   So we have a big question here from EA.
[01:02:40.900 --> 01:02:48.340]   EA asks, "Is Cal Newport's outlook on the future too positive?
[01:02:48.340 --> 01:02:52.420]   Cal often compares social media and digital technology addiction to cigarettes, claiming
[01:02:52.420 --> 01:02:56.980]   that it will probably end up with bans and less tolerance as happened with cigarettes.
[01:02:56.980 --> 01:03:01.780]   It seems to me that everything is pointing towards the opposite."
[01:03:01.780 --> 01:03:04.500]   Here are six examples that EA gives.
[01:03:04.500 --> 01:03:09.260]   One, it is almost impossible to go to a restaurant and not see kids on a phone.
[01:03:09.260 --> 01:03:12.100]   Two, schools are becoming lax in their rules.
[01:03:12.100 --> 01:03:15.860]   Three, proving that cigarettes are harmful is way easier than proving that social media
[01:03:15.860 --> 01:03:16.860]   is harmful.
[01:03:16.860 --> 01:03:21.420]   Four, this troubling rush for remote work indicates that people want more digital interactions,
[01:03:21.420 --> 01:03:22.420]   not less.
[01:03:22.420 --> 01:03:27.220]   Five, I contend that cigarettes actually prove that people want more addiction as long as
[01:03:27.220 --> 01:03:29.320]   it's less visible.
[01:03:29.320 --> 01:03:32.820]   And six, something could also be said about energy drinks.
[01:03:32.820 --> 01:03:36.220]   I'm not sure if I get point six.
[01:03:36.220 --> 01:03:38.260]   So here's what I'd say, EA.
[01:03:38.260 --> 01:03:43.680]   You might not be correctly portraying my views on this.
[01:03:43.680 --> 01:03:49.700]   So here are the two claims I actually make, which are similar, but I think they've become
[01:03:49.700 --> 01:03:53.220]   twisted a little bit in the way that you're talking about them.
[01:03:53.220 --> 01:03:58.520]   So one, when it comes to cigarettes and social media use, the claim I've made is that teenage
[01:03:58.520 --> 01:04:06.020]   social media use will be seen in the future like we now see teenage smoking.
[01:04:06.020 --> 01:04:13.060]   So we realized teenagers are particularly vulnerable to the addictive properties of
[01:04:13.060 --> 01:04:21.380]   nicotine, so we should find it to be inappropriate for a 16-year-old or a 14-year-old to be smoking
[01:04:21.380 --> 01:04:22.380]   cigarettes.
[01:04:22.380 --> 01:04:23.380]   Cigarette companies should not advertise towards them.
[01:04:23.380 --> 01:04:25.340]   The culture shifted on that.
[01:04:25.340 --> 01:04:27.460]   And obviously, some teenagers still smoke.
[01:04:27.460 --> 01:04:28.580]   It's not like it once was.
[01:04:28.580 --> 01:04:32.420]   We're like, look, this is if you're cool is what you're doing, and it was much more prevalent.
[01:04:32.420 --> 01:04:39.800]   So I've made that argument, not that digital use in general culture-wide, population-wide
[01:04:39.800 --> 01:04:44.060]   is going to go the way of cigarettes, where cigarette usage, after staying stable at about
[01:04:44.060 --> 01:04:47.620]   30% for a long time, has in more recent years been falling.
[01:04:47.620 --> 01:04:55.700]   Two, I've been arguing that the age of having a small number of social media platform monopolies
[01:04:55.700 --> 01:05:01.980]   that everyone feels cultural pressure to use, universal social media tools, like we were
[01:05:01.980 --> 01:05:07.860]   five years ago with Facebook, Instagram, and Twitter, that that age is going to go away.
[01:05:07.860 --> 01:05:13.380]   And that the tools we use to communicate and to be entertained is going to fragment and
[01:05:13.380 --> 01:05:15.500]   become more bespoke.
[01:05:15.500 --> 01:05:18.820]   And so you might be using TikTok, and I might be listening to this podcast, and you might
[01:05:18.820 --> 01:05:23.060]   be into this streaming service, and I use that streaming service, and you might be on
[01:05:23.060 --> 01:05:27.260]   this social network platform that's specifically aimed at athletes.
[01:05:27.260 --> 01:05:29.700]   And it's going to become much more fragmented and bespoke.
[01:05:29.700 --> 01:05:34.580]   This age of, if you're not on this one or two platforms, it's weird that we look at
[01:05:34.580 --> 01:05:39.700]   you with concern in our eyes, that you get the same type of blowback I used to get in
[01:05:39.700 --> 01:05:43.980]   2014 or 2015 or 2016 when I said, "I don't use social media."
[01:05:43.980 --> 01:05:49.580]   That type of pearl-clutching gasping, "What do you mean?"
[01:05:49.580 --> 01:05:53.140]   That's all going to go away for a lot of reasons I've talked about before.
[01:05:53.140 --> 01:05:58.240]   However, none of this claims that people aren't going to be very distracted looking at screens
[01:05:58.240 --> 01:06:00.260]   all the time.
[01:06:00.260 --> 01:06:04.900]   I don't know if that's going to change broadly anytime soon.
[01:06:04.900 --> 01:06:10.340]   I just think we're not going to have 14-year-olds with unrestricted social media access.
[01:06:10.340 --> 01:06:14.580]   I just think that we're not going to have two companies that everyone has to use their
[01:06:14.580 --> 01:06:15.580]   service.
[01:06:15.580 --> 01:06:21.020]   And I think that's good, and I think that is optimistic, but I do not have a view that
[01:06:21.020 --> 01:06:26.100]   is so optimistic that it says, "Oh, we're not going to be distracted by the digital
[01:06:26.100 --> 01:06:27.100]   in the future."
[01:06:27.100 --> 01:06:28.660]   I don't think that's going to be the case.
[01:06:28.660 --> 01:06:31.260]   I think if anything, it might become more distracting, and we have to talk about the
[01:06:31.260 --> 01:06:36.360]   metaverse and augmented reality and virtual reality, and it's a whole complicated picture
[01:06:36.360 --> 01:06:38.820]   that I can't see clearly through.
[01:06:38.820 --> 01:06:41.620]   So I think I'm a lot more narrow in what I claim EA.
[01:06:41.620 --> 01:06:48.220]   So for better or for worse, my optimism is more focused than the brand of optimism that
[01:06:48.220 --> 01:06:49.500]   you're pushing back against here.
[01:06:49.500 --> 01:06:51.060]   I will say one thing, though.
[01:06:51.060 --> 01:06:55.140]   Your point number three, proving that cigarettes are harmful is way easier than proving that
[01:06:55.140 --> 01:06:56.460]   social media is harmful.
[01:06:56.460 --> 01:07:00.500]   I'm not sure that that's true, and I'll just point you towards a New Yorker piece
[01:07:00.500 --> 01:07:02.900]   I wrote in the fall, last fall.
[01:07:02.900 --> 01:07:06.580]   I wrote a New Yorker piece that asked the question, "Should teenagers be using social
[01:07:06.580 --> 01:07:07.580]   media?"
[01:07:07.580 --> 01:07:16.380]   And one of the points I made in there is we often forget how long it took to convince
[01:07:16.380 --> 01:07:18.680]   ourselves that smoking was harmful.
[01:07:18.680 --> 01:07:22.340]   And I went back and I found the original articles.
[01:07:22.340 --> 01:07:30.020]   I mean, I have scientific articles from early 20th century where people are saying there
[01:07:30.020 --> 01:07:35.100]   might be a lung cancer thing going on here, and there was a lot of pushback about it.
[01:07:35.100 --> 01:07:38.740]   When did we get to the point where we had a sort of consistent message from, let's
[01:07:38.740 --> 01:07:41.100]   say, the surgeon general that smoking caused lung cancer?
[01:07:41.100 --> 01:07:42.100]   You had to get to the '50s or '60s.
[01:07:42.100 --> 01:07:44.300]   I mean, it took decades.
[01:07:44.300 --> 01:07:46.300]   And I talked about it in that article.
[01:07:46.300 --> 01:07:50.140]   I was looking at the research and I was talking to experts about the social psych research
[01:07:50.140 --> 01:07:53.980]   on social media use among adolescents and harmful outcomes.
[01:07:53.980 --> 01:07:56.500]   And I was saying, "Yeah, it's a messy literature.
[01:07:56.500 --> 01:07:57.740]   These literatures are messy."
[01:07:57.740 --> 01:08:02.100]   And even when it says clear-cut as smoking and lung cancer, it wasn't clear-cut, and
[01:08:02.100 --> 01:08:04.580]   it took decades to really be confident about it.
[01:08:04.580 --> 01:08:11.140]   So my point there was don't expect the "science" to come in and have a clear answer.
[01:08:11.140 --> 01:08:12.820]   We couldn't do it for smoking.
[01:08:12.820 --> 01:08:15.100]   It's going to take a long time to get an answer like that for social media.
[01:08:15.100 --> 01:08:21.620]   So we have to move beyond the science and depend more on our own experience, the testimony
[01:08:21.620 --> 01:08:26.140]   of the people using these tools, our own instincts as parents and educators, that this is a cultural
[01:08:26.140 --> 01:08:28.700]   problem, not one that we can look to the science to solve.
[01:08:28.700 --> 01:08:32.900]   So anyway, it's interesting aside, it took a long time to figure out that smoking really
[01:08:32.900 --> 01:08:33.900]   was harmful.
[01:08:33.900 --> 01:08:37.980]   All right, let's do one more question here.
[01:08:37.980 --> 01:08:40.820]   I have one from Matt.
[01:08:40.820 --> 01:08:48.340]   Matt says, "In college, I had a couple influential role models tell me to follow my passion.
[01:08:48.340 --> 01:08:51.140]   This led me to get my bachelor's in cultural anthropology.
[01:08:51.140 --> 01:08:53.580]   Now I'm in a PhD program.
[01:08:53.580 --> 01:08:58.660]   Only after I started my PhD did I read your book, So Good They Can't Ignore You, and I
[01:08:58.660 --> 01:09:04.020]   became convinced of your philosophy of acquiring career capital rather than following a pre-existing
[01:09:04.020 --> 01:09:07.400]   passion to attain career fulfillment.
[01:09:07.400 --> 01:09:10.780]   Now I've committed to a path based on a philosophy that I no longer believe in.
[01:09:10.780 --> 01:09:14.180]   How would you adjust the advice that you give in So Good They Can't Ignore You for people
[01:09:14.180 --> 01:09:19.300]   who have already committed to a passion-based path and now see it as a sunk cost?"
[01:09:19.300 --> 01:09:24.780]   Well, Matt, there's no adjustment you need to do because here is the reality of my advice.
[01:09:24.780 --> 01:09:32.940]   I say, when it comes to figuring out what path you set down, you can lower the bar.
[01:09:32.940 --> 01:09:37.620]   There's lots of paths that you can transform into a life, a professional life that's a
[01:09:37.620 --> 01:09:41.460]   real source of passion and fulfillment.
[01:09:41.460 --> 01:09:44.700]   So what really is going to matter is once you fix one path, for whatever reason you
[01:09:44.700 --> 01:09:48.300]   chose that path, is what you do once you chose it, which is focus on building rare and valuable
[01:09:48.300 --> 01:09:52.660]   skills, use the career capital that generates to take control of your career, move it towards
[01:09:52.660 --> 01:09:57.620]   things that resonate and away from things that don't, have a clear lifestyle in mind
[01:09:57.620 --> 01:10:02.040]   that you use to help guide these decisions.
[01:10:02.040 --> 01:10:06.880]   So the key to that philosophy is I don't care that much how you chose your current path.
[01:10:06.880 --> 01:10:11.440]   So the fact that you chose your current path because you were using passion philosophy,
[01:10:11.440 --> 01:10:12.880]   that's fine.
[01:10:12.880 --> 01:10:16.640]   If you thought, described this as a passion, that means it's something that was interesting
[01:10:16.640 --> 01:10:20.600]   to you, that probably had interesting opportunities associated with it and that you had some sort
[01:10:20.600 --> 01:10:21.600]   of inclination for.
[01:10:21.600 --> 01:10:25.480]   So great, that's a perfectly good reason to choose a path.
[01:10:25.480 --> 01:10:29.000]   So the idea is not, let's be really clear about this, that if you follow your passion
[01:10:29.000 --> 01:10:33.560]   that that will lead you to a bad career.
[01:10:33.560 --> 01:10:35.000]   That's not true.
[01:10:35.000 --> 01:10:41.480]   The issue I have is if your only strategy for getting to a good career is matching a
[01:10:41.480 --> 01:10:46.360]   job to a passion and then sitting back and saying, my work here is done, I should love
[01:10:46.360 --> 01:10:47.360]   this now.
[01:10:47.360 --> 01:10:50.160]   I'm saying, no, no, no, your work is just beginning.
[01:10:50.160 --> 01:10:53.540]   So I don't care much about how you chose your career.
[01:10:53.540 --> 01:10:55.880]   You chose it because you thought it was your passion.
[01:10:55.880 --> 01:10:56.880]   Great.
[01:10:56.880 --> 01:10:58.360]   Good way to do it.
[01:10:58.360 --> 01:11:00.800]   What matters is what you do next.
[01:11:00.800 --> 01:11:04.280]   What you do next is you focus with deliberate practice on becoming so good you can't be
[01:11:04.280 --> 01:11:05.280]   ignored.
[01:11:05.280 --> 01:11:08.080]   Take the career capital that earns you to have leverage over your career.
[01:11:08.080 --> 01:11:11.000]   This is where you're going to need courage, not in choosing what to do, but choosing to
[01:11:11.000 --> 01:11:14.020]   change what you do to be different than what other people are doing.
[01:11:14.020 --> 01:11:18.800]   This is where you step back and say, I'm going to not take a professorship or I'm going to
[01:11:18.800 --> 01:11:22.760]   be a professorship at this school and still write books, or I'm going to do my own thing
[01:11:22.760 --> 01:11:23.760]   or whatever it is.
[01:11:23.760 --> 01:11:27.880]   But you're, you're, you're investing your career capital to create a career that pushes
[01:11:27.880 --> 01:11:30.120]   towards things that resonate and away from things that don't.
[01:11:30.120 --> 01:11:34.640]   And again, the way you, you hone those instincts of residence and anti-residence is lifestyle
[01:11:34.640 --> 01:11:36.440]   centered career planning.
[01:11:36.440 --> 01:11:40.440]   Fix in your head, a really clear image of what your life is like, where you live, what
[01:11:40.440 --> 01:11:45.540]   you do, who you're with, what your time is like, how you feel, fix it, fix an image.
[01:11:45.540 --> 01:11:46.540]   You can taste that.
[01:11:46.540 --> 01:11:51.400]   You can smell that just touches something right in you and let that be your guide to
[01:11:51.400 --> 01:11:56.580]   figuring out, I want to go more towards this in my career or more towards that.
[01:11:56.580 --> 01:11:59.700]   And the thing that allows you to make those choices is career capital.
[01:11:59.700 --> 01:12:02.020]   It is being good at things that are rare and valuable.
[01:12:02.020 --> 01:12:04.740]   So Matt, you're in a great position.
[01:12:04.740 --> 01:12:06.820]   You've already chosen a good path.
[01:12:06.820 --> 01:12:09.160]   It's a good match for you.
[01:12:09.160 --> 01:12:14.540]   Now let's focus on actually navigating that path as effectively as possible.
[01:12:14.540 --> 01:12:17.220]   All right.
[01:12:17.220 --> 01:12:21.100]   Well that we went a little over today, but we had some good questions.
[01:12:21.100 --> 01:12:22.100]   So I appreciated that.
[01:12:22.100 --> 01:12:24.220]   Thank you everyone who wrote in.
[01:12:24.220 --> 01:12:28.580]   As I always say, if you liked what you heard, you'll like what you read.
[01:12:28.580 --> 01:12:32.220]   If you sign up for my email newsletter at calnewport.com and let me add for that.
[01:12:32.220 --> 01:12:35.180]   If you'd like what you heard, you will like what you see.
[01:12:35.180 --> 01:12:42.900]   If you go to the YouTube page for the show at calnewport.com/calnewportmedia, you can
[01:12:42.900 --> 01:12:47.420]   get videos of full episodes, as well as videos of each individual question and deep dive
[01:12:47.420 --> 01:12:48.820]   that I do on this show.
[01:12:48.820 --> 01:12:52.100]   We'll be back on Thursday with a calls episode.
[01:12:52.100 --> 01:12:54.180]   And until then, as always, stay deep.
[01:12:54.460 --> 01:13:01.460]   [MUSIC]

