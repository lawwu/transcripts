
[00:00:00.000 --> 00:00:07.860]   Okay, so we've looked at the IMDB sentiment dataset, we've looked at LSTMs
[00:00:07.860 --> 00:00:11.980]   for generating text and explain how they worked, and we've looked at GRUs in
[00:00:11.980 --> 00:00:15.960]   previous videos, and we've also looked at using convolutions to do text
[00:00:15.960 --> 00:00:20.420]   classification. In this video I want to take it all and put it together. So I
[00:00:20.420 --> 00:00:25.440]   want to show how to use LSTMs and some hybrid models to actually do text
[00:00:25.440 --> 00:00:29.740]   classification on the IMDB dataset. And I'm going to warn you, you know, I wish
[00:00:29.740 --> 00:00:33.040]   there was a punchline where when you put everything together you get like amazing
[00:00:33.040 --> 00:00:37.360]   accuracy and everything's great, but that actually doesn't happen in this dataset.
[00:00:37.360 --> 00:00:40.920]   And honestly it doesn't happen a lot when you're working with neural networks.
[00:00:40.920 --> 00:00:45.580]   So we're gonna put this together, but the dataset is probably too small to really
[00:00:45.580 --> 00:00:50.280]   take advantage of the power of LSTMs. And some people even say that in general
[00:00:50.280 --> 00:00:54.120]   these convolutions work better on text classification. I think the jury's still
[00:00:54.120 --> 00:00:59.080]   out. So I'll show you how to do it, and on bigger datasets you may see a bigger
[00:00:59.080 --> 00:01:03.400]   impact than you see on this. But at least we'll get working code together, and then
[00:01:03.400 --> 00:01:06.840]   maybe you can take it on your bigger dataset and let me know how it goes. So
[00:01:06.840 --> 00:01:12.640]   let's jump right in. The way this is gonna work is we're gonna take our text
[00:01:12.640 --> 00:01:16.440]   and we're gonna do a word embedding. And in this case we're gonna learn the word
[00:01:16.440 --> 00:01:19.360]   embedding. So if you don't know what that is you should go back to the previous
[00:01:19.360 --> 00:01:22.120]   video where I talk about it, but basically we're gonna take each word and
[00:01:22.120 --> 00:01:26.080]   we're gonna transform it into a fixed length vector. And we're also gonna pad
[00:01:26.080 --> 00:01:30.040]   it out so that every single document that we have in our dataset has the
[00:01:30.040 --> 00:01:34.120]   exact same length and the exact same height. Then we're gonna feed that data
[00:01:34.120 --> 00:01:40.880]   as inputs into an LSTM, and we're gonna take the last output of the LSTM and
[00:01:40.880 --> 00:01:44.560]   we're gonna feed that into a perceptron. And the perceptron is gonna take that
[00:01:44.560 --> 00:01:49.560]   output and classify the sentiment as positive or negative. Let's go to the
[00:01:49.560 --> 00:01:55.200]   code. So in this case for this video you want to go to ml-class/video/lstm-classifier
[00:01:55.200 --> 00:02:01.440]   and then open up imdb-lstm. You'll notice that a lot of this
[00:02:01.440 --> 00:02:05.440]   code looks just like the code from the previous video, and actually you're
[00:02:05.440 --> 00:02:09.960]   gonna have to run download-imdb or copy over the imdb file into this
[00:02:09.960 --> 00:02:15.560]   directory to make it work. In this case the directory is videos/lstm-classifier.
[00:02:15.560 --> 00:02:20.840]   And so imdb.lstm is going to do this classification and the first 11
[00:02:20.840 --> 00:02:26.840]   lines are just like we had before in the previous video when we did a
[00:02:26.840 --> 00:02:32.200]   CNN classifier. And we have a lot of the same configuration parameters and we do
[00:02:32.200 --> 00:02:37.840]   a lot of the same pre-processing. So up to line 34 it's basically the exact same
[00:02:37.840 --> 00:02:43.160]   setup as the convolutional imdb classifier. So we're basically
[00:02:43.160 --> 00:02:47.920]   transforming the data and padding the data so that we have X train and X test,
[00:02:47.920 --> 00:02:53.400]   the training words and the testing words, as one-hot encoded vectors that are
[00:02:53.400 --> 00:02:57.920]   padded out to all be the same length. But our model is going to be different. So here
[00:02:57.920 --> 00:03:02.280]   we set up the model as a sequential model in Keras. We add an embedding layer,
[00:03:02.280 --> 00:03:05.200]   and in this case we're going to learn the embedding layer, but you could try
[00:03:05.200 --> 00:03:09.520]   porting over the material from the last class into this class to actually freeze
[00:03:09.520 --> 00:03:14.320]   the embedding layer with the glove classifier. And then line 40 is different.
[00:03:14.320 --> 00:03:17.480]   So in this line we're actually going to build, instead of a convolutional
[00:03:17.480 --> 00:03:22.760]   network, an LSTM classifier. And the important parameter here is the number
[00:03:22.760 --> 00:03:26.320]   of hidden dimensions. So the bigger this is, the more complicated we're making our
[00:03:26.320 --> 00:03:32.280]   LSTM. And our LSTM actually outputs something that's the size of the number
[00:03:32.280 --> 00:03:37.880]   of hidden dimensions. And then our dense classifier, our dense layer, is going to
[00:03:37.880 --> 00:03:41.160]   do the perception operation and actually output one number. Then we're going to
[00:03:41.160 --> 00:03:47.320]   interpret a 1 as a positive sentiment and a 0 as a negative sentiment. So
[00:03:47.320 --> 00:03:57.680]   let's actually run this classifier with Python imdb-lstm. So one thing you'll
[00:03:57.680 --> 00:04:02.200]   notice is that these LSTMs run much more slowly than convolutional networks, which
[00:04:02.200 --> 00:04:04.880]   is why a lot of people tend to prefer these convolutional networks for many
[00:04:04.880 --> 00:04:11.480]   applications. But potentially the LSTM could learn more complicated interactions.
[00:04:11.480 --> 00:04:17.520]   What if you want to make this LSTM go deeper? So one way to make the LSTM model
[00:04:17.520 --> 00:04:21.280]   more complicated is to actually just add more information that's passed between
[00:04:21.280 --> 00:04:25.200]   the nodes or passed into the output. So making that hidden dimension number
[00:04:25.200 --> 00:04:30.120]   bigger will make the LSTM more complicated and learn more. But everyone
[00:04:30.120 --> 00:04:33.400]   talks about kind of deep learning and deeper neural networks. And actually
[00:04:33.400 --> 00:04:37.920]   there is a trend to be stacking these LSTMs on top of each other. So taking the
[00:04:37.920 --> 00:04:45.120]   output of one LSTM and feeding it as input into the next LSTM. So how could we
[00:04:45.120 --> 00:04:50.080]   do that with this model? So if we look at the code, we see this line 40 says model
[00:04:50.080 --> 00:04:55.640]   that added LSTM. And so one thing we could try is just copying this line and
[00:04:55.640 --> 00:05:01.720]   making a second LSTM. So let's see if that works.
[00:05:01.720 --> 00:05:09.720]   [no audio]
[00:05:09.720 --> 00:05:15.240]   So you can see actually that the input of the LSTM, the second LSTM layer, is
[00:05:15.240 --> 00:05:19.480]   incompatible with the output of the previous layer. So you might think, well
[00:05:19.480 --> 00:05:24.840]   why is that? So why is that? It's because that so far we've actually been just
[00:05:24.840 --> 00:05:29.480]   using one output of the LSTM, the last output of the LSTM. But when we stack
[00:05:29.480 --> 00:05:34.920]   these LSTMs, the second LSTM wants an input that's the output at each
[00:05:34.920 --> 00:05:40.400]   iteration of the previous LSTM. So you actually have to set a flag in Keras in
[00:05:40.400 --> 00:05:46.120]   the previous LSTM to enable these two to hook up with each other. So in this case
[00:05:46.120 --> 00:05:55.600]   on the second, on the first LSTM, we say return sequences equals true. So let's
[00:05:55.600 --> 00:06:02.760]   try running that just to make sure I don't have any bugs. I never have bugs.
[00:06:02.760 --> 00:06:06.760]   [no audio]
[00:06:06.760 --> 00:06:11.040]   And actually you can see that this is going to take a good long time to run. So
[00:06:11.040 --> 00:06:15.160]   this is a powerful technique but requires a ton of computational power to
[00:06:15.160 --> 00:06:19.360]   make it work. In fact I think I did try this on this data set once and it really
[00:06:19.360 --> 00:06:22.640]   didn't fit it well. It's a way too powerful model, at least with this size
[00:06:22.640 --> 00:06:26.720]   of dimension. So I'll just leave that there and there might be ways to improve
[00:06:26.720 --> 00:06:30.240]   this. Maybe you could add dropout and make it work better but that would be a
[00:06:30.240 --> 00:06:34.240]   fun project maybe for an excited viewer. There's one more thing I really want to
[00:06:34.240 --> 00:06:38.040]   cover. Actually two more things I really want to cover. The first is making a
[00:06:38.040 --> 00:06:44.400]   bi-directional LSTM. So the idea here is that you take two LSTMs and you run
[00:06:44.400 --> 00:06:49.720]   them in opposite directions. So in language there's information kind of
[00:06:49.720 --> 00:06:52.520]   flowing from left to right but there's also probably information flowing
[00:06:52.520 --> 00:06:57.480]   from right to left. So for predicting the future it really doesn't make sense to
[00:06:57.480 --> 00:07:01.040]   run the LSTM in both directions. But if we're really just trying to process the
[00:07:01.040 --> 00:07:05.120]   information contained in this text it might really make sense to run on the
[00:07:05.120 --> 00:07:10.000]   LSTMs in both directions and then we'll take the output of the very last LSTM on
[00:07:10.000 --> 00:07:13.120]   the one running left to right and the very first LSTM on the one running right
[00:07:13.120 --> 00:07:18.160]   to left and we'll actually concatenate those two vectors that it's outputting.
[00:07:18.160 --> 00:07:24.960]   So this is a super simple thing to do in Keras and you can do it by just adding a
[00:07:24.960 --> 00:07:29.560]   bi-directional wrapper around the LSTM. So why don't we actually only use one
[00:07:29.560 --> 00:07:34.120]   layer for this because the model is certainly already complicated enough. But
[00:07:34.120 --> 00:07:41.160]   if we add the bi-directional layer here we wrap it around the LSTM and then
[00:07:41.160 --> 00:07:48.160]   we'll probably have to add it up at the top from in the layers. This can often
[00:07:48.160 --> 00:07:51.520]   make our model work better.
[00:07:51.520 --> 00:08:02.720]   So one more architecture that's been getting popular recently is a hybrid CNN
[00:08:02.720 --> 00:08:07.280]   LSTM and I think actually you have enough information to build this on your
[00:08:07.280 --> 00:08:11.880]   own if you like but I'll show you how to do it. So we basically can start with the
[00:08:11.880 --> 00:08:16.600]   convolution and a pooling and then feed that into an LSTM. So some people think
[00:08:16.600 --> 00:08:20.680]   that this gets kind of all the power or most of the power of LSTMs but we can
[00:08:20.680 --> 00:08:25.400]   actually use the convolution to reduce the complexity of the problem so that
[00:08:25.400 --> 00:08:34.860]   the LSTM runs faster. So here we add a conv layer and then a single 1D pooling
[00:08:34.860 --> 00:08:39.920]   layer. Let's make sure we have filters and kernels size set so yep that's right.
[00:08:39.920 --> 00:08:43.800]   So if we save this.
[00:08:43.800 --> 00:08:48.360]   Awesome so we introduced a whole bunch of different types of architectures
[00:08:48.360 --> 00:08:53.080]   involving LSTMs for classifying text today. So we had just a simple vanilla
[00:08:53.080 --> 00:08:57.680]   LSTM which is actually already pretty complicated. We did multiple layers of
[00:08:57.680 --> 00:09:03.960]   LSTMs, bi-directional LSTMs and convolution LSTM hybrids all in this IMDB
[00:09:03.960 --> 00:09:09.120]   data set. This is all super applicable to other types of text even other
[00:09:09.120 --> 00:09:13.440]   languages and in future videos we'll show how to take these models and apply
[00:09:13.440 --> 00:09:16.520]   them to bigger data sets.

