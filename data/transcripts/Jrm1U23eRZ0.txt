
[00:00:00.000 --> 00:00:07.920]   YouTube. I always watch these recordings later just to
[00:00:07.920 --> 00:00:10.840]   critique myself and then I realized I'm looking around like
[00:00:10.840 --> 00:00:13.820]   a squirrel. That's because I have this big monitor I'm trying
[00:00:13.820 --> 00:00:19.400]   to figure out if I'm live or not on YouTube. I can hear it.
[00:00:19.400 --> 00:00:21.760]   Sorry.
[00:00:21.760 --> 00:00:26.360]   Oh, no. I was gonna say I can hear an echo which means I'm
[00:00:26.360 --> 00:00:28.080]   live on YouTube and I can hear myself.
[00:00:28.080 --> 00:00:29.400]   Okay.
[00:00:29.400 --> 00:00:34.640]   All right. Awesome. Let me share my screen and get started.
[00:00:34.640 --> 00:00:40.240]   Hey, everybody. Welcome. Thanks for joining us on a Saturday
[00:00:40.240 --> 00:00:42.760]   evening, morning or Friday evening depending on where in
[00:00:42.760 --> 00:00:44.760]   the world you're joining us from. Or if you're watching the
[00:00:44.760 --> 00:00:49.000]   recording, thanks for checking the recording out. I am excited
[00:00:49.000 --> 00:00:54.840]   to be hosting Sahil and Nikhil for CTDS 2.0. That's what we're
[00:00:54.840 --> 00:00:57.760]   calling "Chai Time Kaggle Talks". I'll give an introduction
[00:00:57.760 --> 00:01:00.960]   about the session, then about our guests and we'll quickly
[00:01:00.960 --> 00:01:06.320]   jump into learning about their journey and the solution. So a
[00:01:06.320 --> 00:01:09.520]   quick heads up if it's not quite obvious from the banner, we'll
[00:01:09.520 --> 00:01:12.600]   be learning about the fifth position solution from the
[00:01:12.600 --> 00:01:16.560]   ventilator pressure prediction competition. Sahil and Nikhil's
[00:01:16.560 --> 00:01:20.840]   team called CR7 is the GOAT. Some of you may agree, some of
[00:01:20.840 --> 00:01:23.040]   you may not agree. I'm not a football fan. I just know what
[00:01:23.040 --> 00:01:26.640]   that means. Won the fifth position medal and we'll be
[00:01:26.640 --> 00:01:29.200]   learning about how did they come up with the solution? How did
[00:01:29.200 --> 00:01:32.320]   they get started on Kaggle? Both of them are Kaggle masters and
[00:01:32.320 --> 00:01:38.160]   how did they become Kaggle masters? So as a reminder,
[00:01:38.160 --> 00:01:43.440]   please ask all of your questions here. It's quite tough to keep
[00:01:43.440 --> 00:01:46.800]   an eye out in the YouTube chat. And if you head over to this
[00:01:46.800 --> 00:01:50.560]   link, it should take you to our forums. You can simply reply
[00:01:50.560 --> 00:02:00.840]   with your question here. And towards the later end, we'll
[00:02:00.840 --> 00:02:03.400]   keep an eye out for all the questions. Let me post this link
[00:02:03.400 --> 00:02:17.560]   on the YouTube chat as well. Awesome. So for the agenda, this
[00:02:17.560 --> 00:02:22.240]   is CTDS 2.0. I've gotten a lot of feedback where basically
[00:02:22.240 --> 00:02:26.800]   everyone wants to learn more about code solutions, learn more
[00:02:26.800 --> 00:02:31.120]   about how did the solution come about and also cover how did the
[00:02:31.120 --> 00:02:35.520]   guest reach to their point in the career where they are. So
[00:02:35.520 --> 00:02:39.460]   that's what we'll be doing. As I mentioned earlier, most of these
[00:02:39.460 --> 00:02:43.240]   are live and are deep walkthroughs of the solutions.
[00:02:43.240 --> 00:02:47.000]   So first of all, I'd love to introduce Sahil Verma. He's a
[00:02:47.240 --> 00:02:50.080]   Kaggle competitions master. As you can see, he's ranked
[00:02:50.080 --> 00:02:56.760]   currently on 385 out of the 171,000 people globally in the
[00:02:56.760 --> 00:03:00.840]   competitions ranking. He's also analytics with the as current
[00:03:00.840 --> 00:03:05.320]   number two rank holder and works as a data scientist at OkCredit.
[00:03:05.320 --> 00:03:07.040]   Sahil, thanks. Thanks for joining us.
[00:03:07.040 --> 00:03:10.560]   Thanks, Karthik. Thank you so much.
[00:03:10.560 --> 00:03:14.840]   I'm excited to dive into your journey. And I know we'll be
[00:03:14.840 --> 00:03:18.160]   learning a lot more about that. I'll hold my questions for
[00:03:18.160 --> 00:03:22.440]   another minute. Nikhil is a Kaggle competition master as
[00:03:22.440 --> 00:03:25.280]   well. I believe both of them got their recent gold medal which
[00:03:25.280 --> 00:03:29.040]   moved them up to competition master, you need one gold medal
[00:03:29.040 --> 00:03:32.560]   and two silver medals. Nikhil has three silver medals already.
[00:03:32.560 --> 00:03:38.040]   He currently works at Karma Life AI. And if you go through his
[00:03:38.040 --> 00:03:42.040]   LinkedIn profile, you will find at least I ran out of counting,
[00:03:42.040 --> 00:03:45.480]   but you can find a lot of competitions where his team has
[00:03:45.480 --> 00:03:48.640]   performed really well on platforms like Zindi, analytics
[00:03:48.640 --> 00:03:52.520]   with the ISO competition related to AWS as well. Nikhil, thanks
[00:03:52.520 --> 00:03:53.320]   for joining us.
[00:03:53.320 --> 00:03:56.320]   Thank you, Sanyam for having us.
[00:03:56.320 --> 00:04:00.480]   Super excited to dive into your journey. And I'll stop sharing
[00:04:00.480 --> 00:04:03.480]   my screen and start asking my stupid questions like I always
[00:04:03.480 --> 00:04:08.000]   do. So first, I always start with this question. How did you
[00:04:08.000 --> 00:04:10.920]   discover data science? And how did you get started on Kaggle?
[00:04:11.080 --> 00:04:14.320]   Maybe I'll start with Sahil, you graduated from IIT in around
[00:04:14.320 --> 00:04:19.120]   2016. My college friends in when I was I started my college
[00:04:19.120 --> 00:04:22.520]   journey in 2015. In India, no one knew about Kaggle at that
[00:04:22.520 --> 00:04:25.680]   point. Was it the same for you? How did you discover Kaggle?
[00:04:25.680 --> 00:04:31.000]   So Kaggle for me, I discovered it at my stint at ZS Associates.
[00:04:31.000 --> 00:04:36.560]   So there, there I was working as a data analyst there. But there
[00:04:36.560 --> 00:04:40.520]   was a group which used to like a group of data analysts who used
[00:04:40.520 --> 00:04:43.200]   to come together, which was being supervised by a couple of
[00:04:43.200 --> 00:04:47.400]   managers who were also inclined in data sciences. And they used
[00:04:47.400 --> 00:04:51.080]   to work over the weekends on different Kaggle problems. I
[00:04:51.080 --> 00:04:54.080]   still remember the first Kaggle problem that was discussed there
[00:04:54.080 --> 00:04:59.840]   was Instacart from 2017. So that was the first time like I saw
[00:04:59.840 --> 00:05:02.200]   a group of people working towards Kaggle. I'd heard about
[00:05:02.200 --> 00:05:08.000]   Kaggle, but never had this like, inside of me like to find out
[00:05:08.000 --> 00:05:12.000]   what Kaggle is all about. But that group helped me discover
[00:05:12.000 --> 00:05:15.160]   Kaggle and basically got me interested in data sciences.
[00:05:15.160 --> 00:05:21.840]   How was the scene earlier? Like it's a few years earlier. Now
[00:05:21.840 --> 00:05:24.120]   you can find all of these resources to get started. How
[00:05:24.120 --> 00:05:26.440]   did you go about learning all of those things?
[00:05:26.440 --> 00:05:31.920]   So for me, the first couple of competitions I couldn't even
[00:05:31.920 --> 00:05:35.040]   enter, like there is this inertia with the beginners, like,
[00:05:35.920 --> 00:05:38.520]   even right now people might be starting out with a certain
[00:05:38.520 --> 00:05:41.440]   inertia, like it's very difficult to like to see your
[00:05:41.440 --> 00:05:43.800]   public ranking not being there on the top, even though you
[00:05:43.800 --> 00:05:46.400]   don't you yourself know that you don't know anything much about
[00:05:46.400 --> 00:05:50.000]   the data science world, but still that, that feedback that
[00:05:50.000 --> 00:05:53.480]   you get from the LV that is quite scary in the first go. So
[00:05:53.480 --> 00:05:57.320]   it even now also, if you see the number, I barely have
[00:05:57.320 --> 00:06:00.960]   participated in 10 to 12 Kaggle competitions till till date. And
[00:06:00.960 --> 00:06:03.720]   that inertia is still there with me like a some amount of inertia
[00:06:03.720 --> 00:06:08.680]   is still there. But for me, the critical part was trying to
[00:06:08.680 --> 00:06:10.440]   learn from the public selection, even though you are not
[00:06:10.440 --> 00:06:14.000]   participating. So what beginners try to do is try to submit a
[00:06:14.000 --> 00:06:17.000]   public kernel and get get some rank, maybe they might even get
[00:06:17.000 --> 00:06:20.200]   a bronze or a silver medal also. But the learning part is not
[00:06:20.200 --> 00:06:23.200]   there. So what I tried to do was even though I was not
[00:06:23.200 --> 00:06:27.080]   participating, I, like I said, I have I have only participated
[00:06:27.080 --> 00:06:29.680]   in 10 or 11 competitions, but I would be knowing about all the
[00:06:29.680 --> 00:06:32.040]   competitions that are happening on Kaggle. And I would be
[00:06:32.040 --> 00:06:34.960]   actively going through the discussions, because that
[00:06:34.960 --> 00:06:38.600]   discussion, that rich source of information that is there in the
[00:06:38.600 --> 00:06:42.200]   discussions, like that is the goldmine of Kaggle. So for me,
[00:06:42.200 --> 00:06:46.040]   when I was starting out, I didn't participate in Kaggle,
[00:06:46.040 --> 00:06:50.280]   but it acted as a learning guide for me. And because of which I
[00:06:50.280 --> 00:06:53.480]   started competing on other platforms, where I felt that to
[00:06:53.480 --> 00:06:56.600]   get early success was relatively simple as compared to Kaggle,
[00:06:56.600 --> 00:06:59.680]   like to get that initial feedback, which got me more
[00:06:59.680 --> 00:07:02.800]   interested into competitions. So for me, like it was a mixture
[00:07:02.800 --> 00:07:05.760]   of both like Kaggle was a learning guide for me in the
[00:07:05.760 --> 00:07:06.400]   initial phases.
[00:07:06.400 --> 00:07:10.120]   That's awesome. I'll probably come back to this question
[00:07:10.120 --> 00:07:13.440]   again. But Nikhil, I'd love to know about your journey as well.
[00:07:13.440 --> 00:07:17.040]   You've just graduated recently. Did your college friends know
[00:07:17.040 --> 00:07:20.400]   more about Kaggle? I really hope they did. And how did you
[00:07:20.400 --> 00:07:22.960]   discover Kaggle? How did you get started on Kaggle?
[00:07:22.960 --> 00:07:28.560]   Yes. So thanks for the question. So basically, my I started my
[00:07:28.560 --> 00:07:32.640]   college in 2016. And my ML journey started from the
[00:07:32.640 --> 00:07:34.800]   beginning of my second year, right. So there was one of
[00:07:34.800 --> 00:07:39.000]   professors of us, who was working with us, extraterrestrial
[00:07:39.000 --> 00:07:43.120]   life discovery, right. So basically life on other planets.
[00:07:43.120 --> 00:07:47.960]   So he was using ML for that. And he was giving us a webinar. So
[00:07:47.960 --> 00:07:50.960]   that got me really interested, like, what is this thing like,
[00:07:50.960 --> 00:07:54.880]   we can use it to do so many cool, cool stuff, right. And
[00:07:54.880 --> 00:07:58.640]   then I gradually searched on internet, like, how do you get
[00:07:58.640 --> 00:08:01.520]   started with ML and stuff. And then I came across the famous
[00:08:01.520 --> 00:08:05.040]   Andrew and GML course, right. So I just got started with it. And
[00:08:05.040 --> 00:08:08.600]   then, you know, the journey began. And for me, it's always
[00:08:08.600 --> 00:08:11.760]   been like, whenever I try to learn something, I participate
[00:08:11.760 --> 00:08:16.200]   in competitions. So firstly, when I was thinking of like, how
[00:08:16.200 --> 00:08:19.800]   do I practice what I've learned in ML, I came across a different
[00:08:19.800 --> 00:08:24.680]   platforms, notably Kaggle, right. So in platforms like
[00:08:24.680 --> 00:08:28.120]   Kaggle, the biggest thing I feel is in a short amount of time,
[00:08:28.120 --> 00:08:31.360]   you get to try a lot of different things, right. So for
[00:08:31.360 --> 00:08:35.120]   me, I think, just two months or three months after I completed
[00:08:35.120 --> 00:08:37.760]   my first course on machine learning, I started
[00:08:37.760 --> 00:08:42.240]   participating in competitions. So I think the first major
[00:08:42.240 --> 00:08:45.520]   competition I participated on Kaggle was I think Porto Seguro
[00:08:45.520 --> 00:08:48.720]   competition, right. So I did really bad there. But then
[00:08:48.720 --> 00:08:53.200]   again, I got to learn a lot of things. And yeah, so many
[00:08:53.200 --> 00:08:56.360]   Indian platforms like HackerEarth and Analytics Vidya
[00:08:56.360 --> 00:09:00.040]   have also been there. So I just like to mention like, when I
[00:09:00.040 --> 00:09:03.320]   was just starting out competitions, I used to see
[00:09:03.320 --> 00:09:06.840]   Sahil getting really high ranks like in Analytics Vidya. So
[00:09:06.840 --> 00:09:10.960]   again, he was also a source of inspiration for me that like,
[00:09:10.960 --> 00:09:13.480]   you can do well in machine learning competitions. Yeah.
[00:09:13.480 --> 00:09:17.840]   The journey for me in Kaggle and different competitions have
[00:09:17.840 --> 00:09:18.880]   been like this.
[00:09:18.880 --> 00:09:23.400]   That's, that's awesome to hear. I also saw that you have teamed
[00:09:23.400 --> 00:09:26.760]   up with Sahil earlier as well. But question for both of you,
[00:09:26.760 --> 00:09:29.240]   how did once you discovered these platform and there's
[00:09:29.240 --> 00:09:33.280]   always this hesitation to me. I basically retired since I know I
[00:09:33.280 --> 00:09:35.920]   can't get another gold medal. And that also happened because
[00:09:35.920 --> 00:09:39.800]   of great team. I don't think I'll compete again out of that.
[00:09:39.800 --> 00:09:44.080]   That terror. But once you start competing, how did you make a
[00:09:44.080 --> 00:09:46.840]   conscious decision to improve? Sahil, you said you were going
[00:09:46.840 --> 00:09:50.400]   through solutions? Did you try to re implement them? How did
[00:09:50.400 --> 00:09:51.200]   you try to improve?
[00:09:51.200 --> 00:09:56.600]   Yeah, so this is like the most critical part, like, even if you
[00:09:56.600 --> 00:09:59.480]   don't perform well in a competition, or let's say, you
[00:09:59.480 --> 00:10:01.880]   were just a bystander in that competition, you are observing a
[00:10:01.880 --> 00:10:05.280]   competition, it's really important to understand the top
[00:10:05.280 --> 00:10:09.720]   solution, like it's, it's the most common. If you ask any of
[00:10:09.720 --> 00:10:12.680]   the top Kagglers, this is what they would also recommend that
[00:10:12.680 --> 00:10:15.680]   try to implement the solution that people discuss in the
[00:10:15.680 --> 00:10:19.320]   forums on your own. Like, it's good that you are able to
[00:10:19.320 --> 00:10:23.720]   understand a kernel or maybe some form of discussion. But
[00:10:23.720 --> 00:10:29.160]   that once you implement a thing that sticks in your mind, and
[00:10:29.160 --> 00:10:31.800]   you would be able to use those solutions later on in the
[00:10:31.800 --> 00:10:35.040]   competition, for example, many of the tricks in this, the
[00:10:35.040 --> 00:10:38.960]   competition that we used, were taken like, some of the
[00:10:38.960 --> 00:10:44.280]   inspirations were from past competitions. So yes, this this
[00:10:44.600 --> 00:10:48.320]   idea that you need to implement the solutions on your own is
[00:10:48.320 --> 00:10:53.080]   like the the way to go about improving your Kaggle skills.
[00:10:53.080 --> 00:10:57.280]   Nikit, do you want to add anything?
[00:10:57.280 --> 00:11:03.480]   Yes, yes, yes. So I think from the beginning of my data science
[00:11:03.480 --> 00:11:07.360]   and machine learning competition journey, so what I see is that
[00:11:07.360 --> 00:11:11.040]   if, like, if there were no solutions from the people who
[00:11:11.040 --> 00:11:15.040]   did really well, I think many of us would not even be able to
[00:11:15.040 --> 00:11:18.600]   progress that further, right. So I think I read solutions from
[00:11:18.600 --> 00:11:22.560]   say, a science competitions in which you did well in say
[00:11:22.560 --> 00:11:25.120]   analytics with Dan, there were many other competitors, right.
[00:11:25.120 --> 00:11:28.840]   So I think it's very important that you go through these
[00:11:28.840 --> 00:11:32.360]   solutions. So they help you think from an other person's
[00:11:32.360 --> 00:11:36.000]   perspective, how they go about problems. And yes, it's it's
[00:11:36.000 --> 00:11:40.400]   always good to, you know, keep keep learning from other
[00:11:40.400 --> 00:11:43.640]   solutions and trying to implement it yourself. So yes,
[00:11:43.640 --> 00:11:46.520]   the answer is quite similar from my side.
[00:11:46.520 --> 00:11:52.800]   If that's, that's very practical advice. And what I'm hearing is
[00:11:52.800 --> 00:11:55.200]   you should jump on to competitions also as soon as you
[00:11:55.200 --> 00:11:59.960]   can. I have a book on introduction, the standard ISL
[00:11:59.960 --> 00:12:03.000]   ESL books, but I've, I'm never going to read starts in the
[00:12:03.000 --> 00:12:05.680]   foreseeable future. When should one start competing in your
[00:12:05.680 --> 00:12:06.240]   opinion?
[00:12:07.520 --> 00:12:16.360]   So I think, so I think, as soon as he did my first course, I
[00:12:16.360 --> 00:12:18.520]   participated in machine learning, even though I did not
[00:12:18.520 --> 00:12:22.160]   get a good rank, I learned a lot about it. So I think you should
[00:12:22.160 --> 00:12:25.400]   not fear going there and start participating in competitions,
[00:12:25.400 --> 00:12:29.200]   even though I don't get a good time, right. So even now I just
[00:12:29.200 --> 00:12:33.120]   participate in some competitions, just so that I get
[00:12:33.120 --> 00:12:36.920]   a flavor of a new field, right? So new era, so maybe some kind
[00:12:36.920 --> 00:12:39.360]   of say image segmentation competitions or something maybe
[00:12:39.360 --> 00:12:41.880]   which I have not explored, I want to go there and try
[00:12:41.880 --> 00:12:45.120]   something. Even though I don't participate actively, I'll try
[00:12:45.120 --> 00:12:49.280]   to participate passively and try to learn from what people are
[00:12:49.280 --> 00:12:52.360]   doing there, right. So I think it's very important that you
[00:12:52.360 --> 00:12:55.480]   start participating in competitions. It's, it's not
[00:12:55.480 --> 00:12:59.120]   like, I've also been asked this question many times on LinkedIn,
[00:12:59.120 --> 00:13:02.240]   that when should, when participate in competitions,
[00:13:02.240 --> 00:13:05.200]   like, should we wait for a year or two or become too much
[00:13:05.200 --> 00:13:08.520]   confident and then start? So it's not like that. You start
[00:13:08.520 --> 00:13:11.240]   and then the learning will always be there. It's like, it's
[00:13:11.240 --> 00:13:15.280]   continuous, just can't jump steps. That's what I feel about
[00:13:15.280 --> 00:13:15.440]   it.
[00:13:15.440 --> 00:13:21.800]   So just just a point to add here. So there are generally
[00:13:21.800 --> 00:13:23.960]   when you come to Kaggle, there are two schools of thought that
[00:13:23.960 --> 00:13:26.920]   we have already seen being discussed on different social
[00:13:26.920 --> 00:13:31.440]   media platforms, that Kaggle is beneficial or not. So to any,
[00:13:31.440 --> 00:13:34.080]   any beginner, what I would suggest is, so there are two
[00:13:34.080 --> 00:13:39.200]   things that you can learn from Kaggle. One, like, one is the
[00:13:39.200 --> 00:13:41.960]   obviously the modeling related things that you get to learn.
[00:13:41.960 --> 00:13:45.480]   And second is the competitive spirit that it builds inside of
[00:13:45.480 --> 00:13:49.600]   you. So that is something, this is something which I believe
[00:13:49.600 --> 00:13:53.360]   that if you experience it the first time, you would continue
[00:13:53.360 --> 00:13:55.720]   doing Kaggle for the rest of your life, we can even see,
[00:13:55.720 --> 00:14:00.800]   like, people like CPMP, like they they have, like given given
[00:14:00.800 --> 00:14:03.760]   so much experience they have, they don't even require to do
[00:14:03.760 --> 00:14:06.960]   Kaggle, but still they are like getting great ranks doing
[00:14:06.960 --> 00:14:10.080]   really well coming, coming up with innovative solutions. So
[00:14:10.080 --> 00:14:12.920]   what I would suggest is, as Nikhil said, get into a
[00:14:12.920 --> 00:14:17.280]   competition, give it a good go, and post that you would have
[00:14:17.280 --> 00:14:20.560]   that you would get that feeling that whether you would want to
[00:14:20.560 --> 00:14:26.200]   continue with Kaggle or not like this. So even even for me now,
[00:14:26.200 --> 00:14:29.880]   if I enter a competition, even though the rank is bad, but that
[00:14:29.880 --> 00:14:35.320]   not like the drive inside of me to get that rank upwards is
[00:14:35.320 --> 00:14:38.920]   something that I really like, that is the best feeling that I
[00:14:38.920 --> 00:14:42.320]   get from Kaggle apart from the learning. So as I said that
[00:14:42.320 --> 00:14:45.120]   there are two things which I think decide whether you would
[00:14:45.120 --> 00:14:48.240]   continue on Kaggle or not, that competitive drive is really an
[00:14:48.240 --> 00:14:51.560]   essential thing. I believe Nikhil is also the same. And most
[00:14:51.560 --> 00:14:54.240]   of the top Kagglers are, if they try to participate in a
[00:14:54.240 --> 00:14:57.400]   competition, they will try to drive that rank up and
[00:14:57.840 --> 00:15:00.160]   eventually that is how you also learn. Yeah.
[00:15:00.160 --> 00:15:05.640]   I found roots to competitiveness in both your profiles. Sahil,
[00:15:05.640 --> 00:15:09.080]   you ranked up I think somewhere around the 700 in India is one
[00:15:09.080 --> 00:15:12.600]   of the most difficult papers, which requires you to get into
[00:15:12.600 --> 00:15:16.360]   IIT from there also in CAT you ranked, I think it was like a
[00:15:16.360 --> 00:15:19.560]   really high percentile and same for Nikhil, he's ranked really
[00:15:19.560 --> 00:15:21.880]   well across different data science competitions. So I think
[00:15:21.880 --> 00:15:24.480]   that's that's where both of your roots on Kaggle come from.
[00:15:25.840 --> 00:15:30.200]   Yeah, so that competitive thing is something I feel that if you
[00:15:30.200 --> 00:15:34.280]   have you, you will get like hooked into Kaggle. That is for
[00:15:34.280 --> 00:15:34.640]   sure.
[00:15:34.640 --> 00:15:37.880]   Awesome. So exactly.
[00:15:37.880 --> 00:15:42.720]   One more Kaggle related question before we start diving into the
[00:15:42.720 --> 00:15:47.160]   solution. Both of you are from India. And we've seen, I'll
[00:15:47.160 --> 00:15:49.560]   point the platform out on LinkedIn, this constant debate
[00:15:49.560 --> 00:15:52.480]   of if Kaggle is useful, have you found your Kaggle achievements
[00:15:52.480 --> 00:15:57.360]   relevant to employers? Or how do you present them? When you're
[00:15:57.360 --> 00:15:58.800]   talking to an employer, for example?
[00:15:58.800 --> 00:16:04.000]   So, yeah, I'll go first on this one. So basically, in my
[00:16:04.000 --> 00:16:07.640]   college, it's not like companies don't even come for say, a data
[00:16:07.640 --> 00:16:10.640]   science placement or something, right. So people always come
[00:16:10.640 --> 00:16:14.320]   from, say, if you want to become a software developer or not. So
[00:16:14.320 --> 00:16:17.920]   for me, that was a really challenging journey, because I
[00:16:17.920 --> 00:16:20.360]   really wanted to become a data scientist from the point I
[00:16:20.360 --> 00:16:25.240]   started this data science. And I believe Kaggle has been the most
[00:16:25.240 --> 00:16:30.480]   important factor for me in this journey, right. So Kaggle or any
[00:16:30.480 --> 00:16:33.520]   machine learning competitions that I participated in, that
[00:16:33.520 --> 00:16:37.760]   really helped build my profile. And then I, you know, I had, I
[00:16:37.760 --> 00:16:41.040]   started building connections. And then I found great people,
[00:16:41.040 --> 00:16:44.400]   including Sail and I have competed with many people,
[00:16:44.400 --> 00:16:49.600]   right. So in Zindi, I competed with people from Africa. I also
[00:16:49.600 --> 00:16:52.600]   competed with people from France, Australia, and different
[00:16:52.600 --> 00:16:56.120]   countries. So what I felt that when you participate in machine
[00:16:56.120 --> 00:16:59.720]   learning competitions, you build a lot of connections. And many
[00:16:59.720 --> 00:17:03.320]   of these connections have been helpful in me getting a data
[00:17:03.320 --> 00:17:06.520]   science job and, you know, growing in my career. So I
[00:17:06.520 --> 00:17:09.880]   think, if Kaggle or machine learning competitions was not
[00:17:09.880 --> 00:17:12.680]   there, I would not have been here, first of all. So I would
[00:17:12.680 --> 00:17:15.920]   be doing some software engineering job. Software
[00:17:15.920 --> 00:17:19.320]   engineering is great too. But yeah, for me, like if I wanted
[00:17:19.320 --> 00:17:22.040]   to become a data scientist, and I did not have a machine
[00:17:22.040 --> 00:17:25.000]   learning competition platform such as Kaggle, I would not be
[00:17:25.000 --> 00:17:28.720]   here. So yeah, I'm really thankful to Kaggle and all of
[00:17:28.720 --> 00:17:30.240]   the data science community out here.
[00:17:30.240 --> 00:17:37.320]   Yeah. So I believe that there are two sides of the story
[00:17:37.320 --> 00:17:42.520]   here. So as you said, Sayyam, that people generally, like it
[00:17:42.520 --> 00:17:46.040]   depends on which company you are applying for. Specifically, if
[00:17:46.040 --> 00:17:49.360]   we talk about India, you generally find two sets, two
[00:17:49.360 --> 00:17:52.360]   kinds of hiring managers, like the people who come into touch
[00:17:52.360 --> 00:17:56.840]   with you and try to hire for a data science role. Right. And
[00:17:56.840 --> 00:17:59.920]   they would be the ones who are super secretive, who ask you to
[00:17:59.920 --> 00:18:03.160]   send your resume and don't tell you about the job unless you
[00:18:03.160 --> 00:18:06.440]   hop on a call with them, as if they're, they're dealing
[00:18:06.440 --> 00:18:07.360]   something illegal.
[00:18:07.360 --> 00:18:09.920]   Yeah, I face.
[00:18:09.920 --> 00:18:15.040]   Yeah. So, again, the two sets of people, again, they are from
[00:18:15.040 --> 00:18:17.600]   two schools of thought that Kaggle is useful or not. It
[00:18:17.600 --> 00:18:20.600]   really depends on them whether they feel that Kaggle
[00:18:20.600 --> 00:18:23.560]   achievements, which are listed on your resume are going to be
[00:18:23.560 --> 00:18:27.640]   useful or not. What Nikhil said is absolutely makes sense that
[00:18:27.640 --> 00:18:31.080]   the community that you get from Kaggle eventually might help you
[00:18:31.080 --> 00:18:33.920]   land a much better job might be in India or might be outside
[00:18:33.920 --> 00:18:37.720]   like that is one of the like the true potentials of having a good
[00:18:37.720 --> 00:18:41.720]   data science community. But what I feel that if someone who is
[00:18:41.720 --> 00:18:44.400]   not from that community, or if he's not from that background,
[00:18:44.880 --> 00:18:48.040]   there are many people in India who are still not part of the
[00:18:48.040 --> 00:18:50.360]   Kaggle community. And even if they have heard of Kaggle, they
[00:18:50.360 --> 00:18:55.720]   don't find the value there. So in that case, to justify that
[00:18:55.720 --> 00:18:59.640]   getting a good rank in Kaggle is a really difficult thing. I
[00:18:59.640 --> 00:19:03.000]   think like it, it's difficult for them to understand how much
[00:19:03.000 --> 00:19:08.120]   effort it takes to get even even the top a bronze medal solution
[00:19:08.120 --> 00:19:12.600]   also for say, like it's it. That is really difficult for them to
[00:19:12.600 --> 00:19:17.560]   understand. Yeah. And also one more thing that I would like to
[00:19:17.560 --> 00:19:24.920]   add. Sorry, man. I forgot what I was going to add. Yeah. Sorry.
[00:19:24.920 --> 00:19:32.200]   No worries. I guess my interruption must have. But no,
[00:19:32.200 --> 00:19:36.400]   from, in my experience, I totally agree with you. And you
[00:19:36.400 --> 00:19:39.880]   probably wouldn't be want you probably wouldn't want to be at
[00:19:39.880 --> 00:19:43.160]   a place where they don't respect Kaggle as much if you really a
[00:19:43.160 --> 00:19:46.880]   Kaggle because if you work at a place where people understand
[00:19:46.880 --> 00:19:49.720]   Kaggle, you can simply tell them that, hey, I'm going to spend
[00:19:49.720 --> 00:19:52.280]   some time on a competition and they'll absolutely respect the
[00:19:52.280 --> 00:19:56.040]   time that goes into it. Other places might not appreciate even
[00:19:56.040 --> 00:19:58.880]   how difficult it is to get a silver medal, for example.
[00:19:58.880 --> 00:20:03.000]   Yeah. So the point that I was going to add Sam was that even
[00:20:03.000 --> 00:20:05.040]   though these two people are from two different school of
[00:20:05.040 --> 00:20:08.680]   thoughts, what next what what is necessary for people to
[00:20:08.680 --> 00:20:12.120]   understand is that a simple example, like importance of
[00:20:12.120 --> 00:20:14.600]   cross validation schemes, this is not something that you are
[00:20:14.600 --> 00:20:17.840]   going to learn in your real life projects like that is just a
[00:20:17.840 --> 00:20:21.000]   small part of the pipeline. So it's important for them to
[00:20:21.000 --> 00:20:23.680]   understand it's not just not just about the ranks. It's about
[00:20:23.680 --> 00:20:26.120]   the entire process that we understand when we are
[00:20:26.120 --> 00:20:27.360]   competing in a competition.
[00:20:27.360 --> 00:20:34.760]   Absolutely. Awesome. I'd love to dive into the competition a bit.
[00:20:35.040 --> 00:20:39.680]   Before that, does any one of you have anything to add from your
[00:20:39.680 --> 00:20:41.240]   journey or any point that I missed?
[00:20:41.240 --> 00:20:45.720]   No, I think we can go to the competitions part I think.
[00:20:45.720 --> 00:20:51.040]   No, no, no, we can continue.
[00:20:51.040 --> 00:20:56.360]   Awesome. Let me share my screen. And I'm insanely lazy. So
[00:20:56.360 --> 00:20:59.240]   instead of preparing an EDA kernel myself like I should
[00:20:59.240 --> 00:21:02.160]   have, I just find ones that I can understand and walk through
[00:21:02.160 --> 00:21:06.160]   real quickly. That's what I like to do. And I usually start with
[00:21:06.160 --> 00:21:08.760]   the description. So the competition just to again, point
[00:21:08.760 --> 00:21:11.720]   out to the audience's Google Brain Ventilator pressure
[00:21:11.720 --> 00:21:15.160]   prediction. And if you go to the leaderboard, you don't have to
[00:21:15.160 --> 00:21:18.560]   scroll too much, you can find both of our guests right outside
[00:21:18.560 --> 00:21:23.440]   of the prize zone. It's I'm not sure if being two places under
[00:21:23.440 --> 00:21:30.440]   it is more hurtful or fun. I can imagine. But coming back to the
[00:21:30.440 --> 00:21:33.120]   description from what I understand, you're required to
[00:21:33.120 --> 00:21:37.200]   simulate ventilators and just talk about what ventilators are
[00:21:37.200 --> 00:21:41.960]   and this was to help reduce the cost barrier for developing new
[00:21:41.960 --> 00:21:45.440]   methods. So this was literally something that's real close to
[00:21:45.440 --> 00:21:51.680]   providing human value. And I found this kernel called
[00:21:51.680 --> 00:21:54.920]   ventilator pressure slash LSTM starter that gives this nice
[00:21:54.920 --> 00:21:59.200]   outline. ventilators to those of you who don't know are used to
[00:21:59.200 --> 00:22:01.880]   provide life support to someone who's having trouble breathing,
[00:22:01.880 --> 00:22:05.120]   they usually sedated and can't breathe themselves. And
[00:22:05.120 --> 00:22:10.520]   ventilators helps pump air into their lungs. Essentially, this
[00:22:10.520 --> 00:22:13.760]   is how they function. And from what I understand, we were
[00:22:13.760 --> 00:22:21.720]   trying to optimize this process. Correct? Yeah. Yes, yes. Now
[00:22:21.720 --> 00:22:24.680]   continuing my laziness instead of going to the data tab, I'll
[00:22:24.920 --> 00:22:28.840]   use this kernel called ventilator EDA by Ishan Dutta
[00:22:28.840 --> 00:22:41.080]   who's also created a WNB dashboard around it. I just
[00:22:41.080 --> 00:22:43.960]   wanted to quickly point out the different columns that exist in
[00:22:43.960 --> 00:22:49.120]   the data. So you can see there's a global identifier for the
[00:22:49.120 --> 00:22:53.920]   entire file set, you can find breathe ID and this was to
[00:22:53.920 --> 00:22:57.160]   measure different breaths as I understood. So every single
[00:22:57.160 --> 00:23:01.800]   breath that the patient was taking had a different timestamp
[00:23:01.800 --> 00:23:05.680]   attached to it. So this is for identifying that. And Nikhil
[00:23:05.680 --> 00:23:08.200]   and Sahil, please, since I haven't completed, please feel
[00:23:08.200 --> 00:23:09.760]   free to interrupt me anytime I'm wrong.
[00:23:09.760 --> 00:23:11.000]   Sure.
[00:23:11.000 --> 00:23:16.760]   R stands for the lung attribute and, and this basically
[00:23:16.760 --> 00:23:21.240]   indicates how clogged your breathing pathways or how
[00:23:21.240 --> 00:23:24.760]   clogged your lung is. I tried to Google a bit and this is one of
[00:23:24.760 --> 00:23:28.200]   the standard units in which it's measured. I won't bother
[00:23:28.200 --> 00:23:33.600]   explaining it since I'm not an expert. C column tells you the
[00:23:33.600 --> 00:23:38.560]   lung attribute indicating how compliant the lung was. And you
[00:23:38.560 --> 00:23:44.360]   can find the timestamp, the input, control input for the
[00:23:44.360 --> 00:23:48.120]   solenoid valve. And now if you try to Google this, again, you'll
[00:23:48.120 --> 00:23:51.920]   find more details around ventilators and all those
[00:23:51.920 --> 00:23:55.120]   things. I'll try to skip those details. But it long story
[00:23:55.120 --> 00:23:58.480]   short is it gives you the control input and output and
[00:23:58.480 --> 00:24:03.200]   pressure points out the airway pressure. Anything that you
[00:24:03.200 --> 00:24:04.000]   might want to add it?
[00:24:04.000 --> 00:24:08.440]   No, this looks good. Yeah.
[00:24:08.440 --> 00:24:15.920]   And I'll continue continuing on my laziness. I'll shamelessly
[00:24:15.920 --> 00:24:20.520]   use the plots by Ishan to point out details in the data. I'll
[00:24:20.520 --> 00:24:23.840]   post this link again on the forum thread I'd shown. So any
[00:24:23.840 --> 00:24:26.080]   of the links being discussed today will be posted on our
[00:24:26.080 --> 00:24:29.000]   forums. So please check there if you're curious about anything.
[00:24:29.000 --> 00:24:35.320]   This plot shows the comparison against density versus R and
[00:24:35.320 --> 00:24:40.040]   just to remind everyone what R was it was how restricted the
[00:24:40.040 --> 00:24:46.280]   airway inside your lung is. And a similar distribution of sort
[00:24:46.280 --> 00:24:50.600]   is visible for lung compliance. Control input, I guess this sort
[00:24:50.600 --> 00:24:53.840]   of makes sense because you probably wouldn't want to blast
[00:24:53.840 --> 00:24:58.120]   a lot of air or very tense air into anyone's lungs. So it
[00:24:58.120 --> 00:25:06.080]   usually how was around a smaller set of values. And I couldn't
[00:25:06.080 --> 00:25:09.560]   understand this maybe silo nickel you could add here but I
[00:25:09.560 --> 00:25:12.840]   couldn't understand why there's different values for the out
[00:25:12.840 --> 00:25:13.640]   density.
[00:25:13.640 --> 00:25:18.160]   You win was more of a continuous spectrum which was provided to
[00:25:18.160 --> 00:25:24.040]   us. If you look at the values of ui in the input control variable,
[00:25:24.040 --> 00:25:28.880]   it was more of a con in the continuous form. Whereas for you
[00:25:28.880 --> 00:25:31.480]   out, we were given a binary flag, it was an indicator
[00:25:31.480 --> 00:25:35.680]   variable, which indicated whether the air that is being
[00:25:35.680 --> 00:25:41.560]   flown into like flown into the lung. Is it like going out or
[00:25:41.560 --> 00:25:45.680]   not? It was just a zero or a one flag. Like when you inhale, that
[00:25:45.680 --> 00:25:48.880]   is how it is defined as like the inspiratory phase and the
[00:25:48.880 --> 00:25:53.560]   expiratory phase. When you inhale you are not like the air
[00:25:53.560 --> 00:25:57.160]   is not moving out of the lung in that case, your you out would be
[00:25:57.160 --> 00:26:01.160]   equal to zero. And when you are exhaling, that means that the
[00:26:01.160 --> 00:26:04.400]   valve is open now it's indicator variable it becomes one that
[00:26:04.400 --> 00:26:07.920]   means now you're exhaling it's in the expiratory. Yes, yes.
[00:26:07.920 --> 00:26:10.240]   Yes. Sorry.
[00:26:10.240 --> 00:26:15.880]   Yeah, so and you are and you could also see that in many of
[00:26:15.880 --> 00:26:19.040]   the cases in the expiratory phase also we had positive
[00:26:19.040 --> 00:26:22.320]   values for you. So that was basically used to reset the
[00:26:22.320 --> 00:26:27.200]   lung right so the you out the UN values for the expiratory phase
[00:26:27.200 --> 00:26:30.560]   were kind of hard coded so you can reset the lung and then you
[00:26:30.560 --> 00:26:32.120]   can start a new experiment with it.
[00:26:33.560 --> 00:26:37.480]   I guess if I were to like, plot these on top of each other with
[00:26:37.480 --> 00:26:40.840]   the same timestamp, this would be more visible to you. Yes.
[00:26:40.840 --> 00:26:45.720]   That makes sense. Thanks. Thanks for that clarification. And to
[00:26:45.720 --> 00:26:48.280]   the audience, I'm sorry, I'm talking more than I guess, but
[00:26:48.280 --> 00:26:51.400]   my problem is to them offline was I'll do more of the prep I'll
[00:26:51.400 --> 00:26:53.720]   do more of the walkthrough so that they don't have to do much
[00:26:53.720 --> 00:26:56.880]   preparation. That's why unfortunately, you have to hear
[00:26:56.880 --> 00:26:59.480]   me walk through the EDA. Sorry about that.
[00:27:03.080 --> 00:27:06.160]   So I think the airway pressure is quite clear and continue
[00:27:06.160 --> 00:27:07.360]   scrolling and
[00:27:07.360 --> 00:27:12.560]   just just to understand the the RC the RC combination you are
[00:27:12.560 --> 00:27:18.120]   on the right one thing we can go down a bit. The the actual if
[00:27:18.120 --> 00:27:20.880]   you want to understand the significance of RNC you can look
[00:27:20.880 --> 00:27:25.440]   at it this way that my my set of lungs will be very different
[00:27:25.440 --> 00:27:29.240]   from say hems and nickels. So these combinations of RC
[00:27:29.240 --> 00:27:32.840]   actually influence how you're basically your lung is going to
[00:27:32.840 --> 00:27:39.080]   expand or basically compress to the different flow of air. So
[00:27:39.080 --> 00:27:42.480]   different combinations of RC can be seen as different set of
[00:27:42.480 --> 00:27:47.720]   patient lungs per se. So yeah, these these actually play a
[00:27:47.720 --> 00:27:51.840]   like sort of an important role. While while modeling.
[00:27:51.840 --> 00:27:56.280]   That makes sense. Thanks. Thanks for the clarification.
[00:28:00.480 --> 00:28:04.280]   I guess, but there's still some peers right? And I'm guessing
[00:28:04.280 --> 00:28:07.320]   people fall into similar buckets. That's what's visible
[00:28:07.320 --> 00:28:10.960]   here. Yeah, yeah, the train and test distribution were very
[00:28:10.960 --> 00:28:15.200]   similar. Like if you see, that makes sense. As you said, like,
[00:28:15.200 --> 00:28:15.480]   yeah.
[00:28:15.480 --> 00:28:17.520]   So
[00:28:17.520 --> 00:28:22.640]   Ishan has done an amazing job, which is why I can continue just
[00:28:22.640 --> 00:28:26.440]   working through his notebook and instead of checking out another
[00:28:26.440 --> 00:28:26.960]   notebook.
[00:28:28.240 --> 00:28:29.160]   So the next thing is,
[00:28:29.160 --> 00:28:32.800]   just a quick, quick pointer. So if you look at the data, the
[00:28:32.800 --> 00:28:35.760]   data is not very complex. Even if you look at the number of
[00:28:35.760 --> 00:28:39.000]   columns, the size of the data, it's not huge, the number of
[00:28:39.000 --> 00:28:43.040]   columns are not very large. And you can easily understand like
[00:28:43.040 --> 00:28:46.040]   what is happening and do a simple idea. And this was
[00:28:46.040 --> 00:28:50.440]   probably one of the reasons that we started out with, like, why
[00:28:50.440 --> 00:28:53.360]   not just try this competition, given that the data set size is
[00:28:53.360 --> 00:28:58.080]   also not very large. So this was one of the like decision, like
[00:28:58.080 --> 00:29:01.880]   the decision making points based on which we decided to enter
[00:29:01.880 --> 00:29:02.640]   this competition.
[00:29:02.640 --> 00:29:04.840]   Thanks, thanks for that.
[00:29:04.840 --> 00:29:11.280]   This is just a feature correlation plot of all of the
[00:29:11.280 --> 00:29:14.960]   different data points or data features that exist in the
[00:29:14.960 --> 00:29:15.880]   training data set.
[00:29:15.880 --> 00:29:22.560]   I'm just trying to see how is this highly correlated, but this
[00:29:22.560 --> 00:29:25.800]   sort of makes sense you output happen at regular intervals, I'm
[00:29:25.800 --> 00:29:27.600]   guessing which is why we see higher
[00:29:27.600 --> 00:29:34.440]   zero and one. Yeah. So for certain starting n time steps,
[00:29:34.440 --> 00:29:36.960]   you have the inspiratory phase and I suppose that you have the
[00:29:36.960 --> 00:29:39.440]   exploratory phase. So there would be a very high
[00:29:39.440 --> 00:29:40.560]   correlation in that.
[00:29:40.560 --> 00:29:42.120]   Yes, yes, yes.
[00:29:42.120 --> 00:29:47.840]   Okay. If I can understand the test, the graph, I assume the
[00:29:47.840 --> 00:29:52.440]   audience can as well. So I'll continue further. And we do the
[00:29:52.440 --> 00:29:57.480]   same for the test data, the same as visible here as well. Almost
[00:29:57.480 --> 00:30:00.480]   which means like like, so I'll say there's a nice balance
[00:30:00.480 --> 00:30:02.480]   amongst both the training and test data set.
[00:30:02.480 --> 00:30:12.240]   And here's a plot of variation of pressure and input valve
[00:30:12.240 --> 00:30:17.480]   position during the first was the second breath. And it just,
[00:30:17.480 --> 00:30:21.280]   I maybe I'm wrong, but to me, it was quite clear that this just
[00:30:21.280 --> 00:30:26.800]   shows the slight shift amongst the time steps. And same for
[00:30:26.800 --> 00:30:30.320]   brevity as to me, it was quite visible that the graph is just
[00:30:30.320 --> 00:30:36.800]   shifting along the x axis a little. Is there anything else
[00:30:36.800 --> 00:30:37.880]   that we can learn from?
[00:30:37.880 --> 00:30:42.040]   Yes, just one point that Nikhil, yeah, Nikhil, please go ahead.
[00:30:42.040 --> 00:30:48.680]   No, no, no. I just wanted to point out that he has this
[00:30:48.880 --> 00:30:52.960]   ishanas taken the x axis of the ID. So he's plotting multiple
[00:30:52.960 --> 00:30:55.200]   breath IDs together. So yeah.
[00:30:55.200 --> 00:30:58.800]   I will look that
[00:30:58.800 --> 00:31:04.800]   is a for each time we had 80 time steps. And if you could
[00:31:04.800 --> 00:31:09.160]   look at the go out part for so basically what what happened
[00:31:09.160 --> 00:31:12.640]   was we were given around 30 to 35 time steps of the inspiratory
[00:31:12.640 --> 00:31:16.280]   phase and remaining time steps are of the expiratory phase. And
[00:31:16.280 --> 00:31:20.800]   what you could see was there's a sharp decline, like a drop in
[00:31:20.800 --> 00:31:26.400]   the value of the I is the UN plotted here? Or is it just the
[00:31:26.400 --> 00:31:26.920]   pressure?
[00:31:26.920 --> 00:31:30.720]   I think it's just the pressure.
[00:31:30.720 --> 00:31:34.840]   No, it's just the UN is not plotted. Only ID versus pressure
[00:31:34.840 --> 00:31:39.000]   is plotted. Yeah. So ideas is the different breaths that we
[00:31:39.000 --> 00:31:39.200]   have.
[00:31:39.200 --> 00:31:44.200]   But thanks. Thanks for that clarification.
[00:31:44.200 --> 00:31:44.840]   Yeah.
[00:31:45.840 --> 00:31:52.680]   I'm from the side. Sorry. I'm sorry. Ishan talks about the
[00:31:52.680 --> 00:31:55.840]   architectural needs and I'll probably just skip that. Now
[00:31:55.840 --> 00:31:58.160]   coming coming to the competition, I was gonna ask and
[00:31:58.160 --> 00:32:01.560]   you've already shared the answer. But at what point did
[00:32:01.560 --> 00:32:05.200]   both of you decide to team up? And how did you start
[00:32:05.200 --> 00:32:08.560]   approaching the competition? So what I'm trying to understand is
[00:32:08.560 --> 00:32:12.040]   when either Sahil or Nikhil when you see this, when you saw this
[00:32:12.040 --> 00:32:14.440]   competition, how did you create a baseline? What was your
[00:32:14.440 --> 00:32:15.040]   baseline?
[00:32:15.040 --> 00:32:21.280]   Yes, yes. So I think we both had participated together many times
[00:32:21.280 --> 00:32:23.680]   right in different competitions. I think this was the fourth or
[00:32:23.680 --> 00:32:27.000]   fifth competition we were participating together. So yeah,
[00:32:27.000 --> 00:32:30.680]   when we just saw this competition, we both wanted to
[00:32:30.680 --> 00:32:33.040]   become Kaggle masters, right. So it was a kind of internal
[00:32:33.040 --> 00:32:35.800]   challenge between us like, let's see who does better or
[00:32:35.800 --> 00:32:40.440]   something, right. So we both started so Sahil I think had a
[00:32:40.440 --> 00:32:44.080]   lot of office work. So he's, he started out a bit later. And
[00:32:44.080 --> 00:32:47.320]   then I had started, I think from the first year, the second year
[00:32:47.320 --> 00:32:50.440]   of the competition itself, right. So regarding the
[00:32:50.440 --> 00:32:54.200]   baseline, I think it was mostly the public. And so I think
[00:32:54.200 --> 00:32:57.920]   firstly, I started with I like GVM and XGBoost. I don't know
[00:32:57.920 --> 00:33:01.640]   why. And I thought that maybe I can try this and get a really
[00:33:01.640 --> 00:33:05.520]   high score. Then I, for the first one or two days, I started
[00:33:05.520 --> 00:33:10.200]   with this only. So I saw that, yeah, this, the data is not as
[00:33:10.200 --> 00:33:14.560]   huge. So I think I can start with some of the common
[00:33:14.560 --> 00:33:17.720]   structured data frameworks like, like GVM, right. So I started
[00:33:17.720 --> 00:33:22.320]   with that. And then I slowly shifted towards LSTMs and GIUs
[00:33:22.320 --> 00:33:26.240]   when I saw public kernels performing that, right. So this
[00:33:26.240 --> 00:33:29.000]   is one more benefit of the Kaggle community that you get public
[00:33:29.000 --> 00:33:31.920]   kernels, right. So even if you are a beginner, and you don't
[00:33:31.920 --> 00:33:35.080]   know how to approach problems, these public kernels are really
[00:33:35.080 --> 00:33:38.680]   helpful to you. So I just I started with that. And yeah,
[00:33:38.800 --> 00:33:43.200]   just one more point I would like to add. So I had used
[00:33:43.200 --> 00:33:47.920]   transformers, but I had not used them in this for time series
[00:33:47.920 --> 00:33:53.600]   competitions, right. So again, again, this was one of one major
[00:33:53.600 --> 00:33:56.440]   reasons for me entering this competition, right. So I wanted
[00:33:56.440 --> 00:33:59.520]   to just try out how transformers work for time series data. And
[00:33:59.520 --> 00:34:03.840]   then I saw that the data size is not that huge. And it looks
[00:34:03.840 --> 00:34:08.160]   kind of neat. You know, kind of easy to work with. So yeah,
[00:34:08.440 --> 00:34:10.880]   let's give it a go. Yes, I
[00:34:10.880 --> 00:34:15.520]   so I also started like when I saw this competition, the first
[00:34:15.520 --> 00:34:19.400]   thing that came to my mind with a different front end that I
[00:34:19.400 --> 00:34:22.160]   would eventually use in this competition, like if you see a
[00:34:22.160 --> 00:34:27.480]   1D series data sort of the first thing that came to my mind was
[00:34:27.480 --> 00:34:31.800]   I just listed out my things I'm going to use sequential, like
[00:34:31.800 --> 00:34:34.840]   RNNs, I'm going to use 1D CNNs, transformers, conformers,
[00:34:34.840 --> 00:34:39.680]   whatever possible. And the first attempt was again, I guess the
[00:34:39.680 --> 00:34:43.960]   LSTM one if I remember correctly, and one of the early
[00:34:43.960 --> 00:34:46.800]   patterns which you could see that most of the kernels were in
[00:34:46.800 --> 00:34:50.280]   TensorFlow. I mean, I'm a PyTorch guy. So you could
[00:34:50.280 --> 00:34:53.920]   clearly see. Yeah. So but you
[00:34:53.920 --> 00:34:56.800]   I was waving my hand in happiness for the audience. I
[00:34:56.800 --> 00:34:59.200]   love PyTorch as well. Sorry, sorry.
[00:34:59.200 --> 00:35:02.840]   So but you could really see the difference in performance from
[00:35:02.840 --> 00:35:05.920]   the get go. There was like, and it eventually turned out to be
[00:35:05.920 --> 00:35:09.400]   an initialization issue. But the because of that issue, and we
[00:35:09.400 --> 00:35:12.560]   are talking about Kaggle margins, that was an issue. So I
[00:35:12.560 --> 00:35:16.520]   struggled a bit in the beginning to get a good enough baseline
[00:35:16.520 --> 00:35:20.080]   that would get a decent enough rank. But again, the model was
[00:35:20.080 --> 00:35:24.080]   driven by what was there in the discussion that is like LSTM.
[00:35:24.080 --> 00:35:24.840]   Yeah.
[00:35:24.840 --> 00:35:30.160]   That makes sense. So just for my own understanding, I'm always
[00:35:30.160 --> 00:35:33.440]   curious, how did how do you find ideas from there? Is it just
[00:35:33.440 --> 00:35:37.200]   based on discussions? Or are you also trying to find papers that
[00:35:37.200 --> 00:35:40.400]   somewhat relate to this maybe from older competitions? How do
[00:35:40.400 --> 00:35:41.320]   you go about that?
[00:35:41.320 --> 00:35:46.720]   So I think, yeah, you want to go first, please.
[00:35:46.720 --> 00:35:56.640]   So, for me, I think I got a lot of ideas from participating in
[00:35:56.640 --> 00:35:59.320]   different time series competitions. And you know how
[00:35:59.360 --> 00:36:02.840]   people approach things, right. So these were the ideas for me.
[00:36:02.840 --> 00:36:05.600]   And then again, if you start a new thing, basically, the first
[00:36:05.600 --> 00:36:09.640]   thing I do is I try to read a lot of blogs about it and a few
[00:36:09.640 --> 00:36:13.240]   papers, right. So I basically hit Google something like state
[00:36:13.240 --> 00:36:16.120]   of the art method for time series, right. So I hit Google
[00:36:16.120 --> 00:36:19.880]   like that. And then I see a few papers and say when I was
[00:36:19.880 --> 00:36:22.360]   starting with transformers and my transformers were not
[00:36:22.360 --> 00:36:26.440]   converging, I just hit Google for how to converge transformers
[00:36:26.440 --> 00:36:29.920]   faster or something, right. So I came across one paper that we
[00:36:29.920 --> 00:36:33.320]   eventually utilize at the end of the competition, right. So I
[00:36:33.320 --> 00:36:37.200]   think for me, it's a mixed bag. So obviously, there's a lot to
[00:36:37.200 --> 00:36:39.960]   take from different past competitions. And when you're
[00:36:39.960 --> 00:36:43.280]   trying out new techniques, you can obviously Google and see
[00:36:43.280 --> 00:36:46.200]   what are the state of the art methods for the things that you
[00:36:46.200 --> 00:36:46.680]   want to do.
[00:36:46.680 --> 00:36:53.160]   Yeah, same for me almost like, it's not a single shot solution,
[00:36:53.200 --> 00:36:57.880]   you need to try to experiment with multiple sources. So one
[00:36:57.880 --> 00:37:00.880]   one tip is like if Hank Seeg is participating in a competition,
[00:37:00.880 --> 00:37:02.000]   it will make your life easier.
[00:37:02.000 --> 00:37:06.120]   Wait for his presentation that's highly annotated. And he also
[00:37:06.120 --> 00:37:08.680]   creates arrows pointing toward different code snippets.
[00:37:08.680 --> 00:37:13.320]   Exactly. Yeah. Like so for him, like, that is my dream scenario
[00:37:13.320 --> 00:37:17.080]   that even like someday in the future, I would be taking my
[00:37:17.080 --> 00:37:20.080]   Kaggle competitions in such a setup like, there should be
[00:37:20.080 --> 00:37:23.120]   mini research projects wherein you have a working you have your
[00:37:23.120 --> 00:37:27.000]   working notes, and people could refer to them. Like, even like
[00:37:27.000 --> 00:37:30.680]   for me, the process is really messy right now. But that is
[00:37:30.680 --> 00:37:34.240]   like the ideal scenario that I would like to see myself in
[00:37:34.240 --> 00:37:38.600]   someday. Yeah. So first is like discussions from such reputed
[00:37:38.600 --> 00:37:41.760]   Kagglers who have a demonstrated history like they come up with
[00:37:41.760 --> 00:37:45.160]   various solutions, innovative ideas, and they even link the
[00:37:45.160 --> 00:37:48.840]   papers that they read through to get to those solutions. So
[00:37:48.840 --> 00:37:52.040]   reading upon those past solutions. So again, in this
[00:37:52.040 --> 00:37:55.560]   particular competition, given the nature of the data, and the
[00:37:55.560 --> 00:37:59.240]   recent increase in the number of audio competitions, it was
[00:37:59.240 --> 00:38:02.280]   really straightforward that you could just look at the solutions
[00:38:02.280 --> 00:38:04.640]   from the audio competitions also, like what kind of
[00:38:04.640 --> 00:38:08.680]   frontend they were using. And it actually helped us like in one
[00:38:08.680 --> 00:38:12.200]   of the one of the things that we tried in our solution also. So
[00:38:12.200 --> 00:38:17.800]   it's a mixed bag, you need to go through multiple papers or
[00:38:17.800 --> 00:38:21.160]   multiple discussion. One thing we've missed in this competition
[00:38:21.160 --> 00:38:24.760]   was going through the paper that was quoted by the by the
[00:38:24.760 --> 00:38:28.640]   organizer. So we did through that, maybe if we had gone
[00:38:28.640 --> 00:38:31.840]   through that, that we might have ended up in the money zone. Who
[00:38:31.840 --> 00:38:33.160]   knows? But yeah,
[00:38:33.160 --> 00:38:38.040]   you still landed good those who fun intended. That's, that's
[00:38:38.040 --> 00:38:44.280]   incredible. Now, continuing to solution, I believe you have a
[00:38:44.280 --> 00:38:47.680]   presentation. Would you like to share? Yes, I can. Okay.
[00:38:47.720 --> 00:39:13.840]   Yeah, sure. So I'll skip over the part that we have already
[00:39:13.840 --> 00:39:16.080]   covered, right, we have gone through the problem statement.
[00:39:16.920 --> 00:39:21.320]   The input data we have already looked at. So just a brief of
[00:39:21.320 --> 00:39:25.640]   the solution summary that we are going to go through. So we are
[00:39:25.640 --> 00:39:29.320]   going to go through some of the key features of our model, the
[00:39:29.320 --> 00:39:34.800]   ideas behind the problem setup, we had, and validation strategy
[00:39:34.800 --> 00:39:39.160]   and finally the transformer that we had built. And, and obviously
[00:39:39.160 --> 00:39:42.360]   the things that didn't work in this competition.
[00:39:44.840 --> 00:39:48.800]   Yeah. So yeah, just.
[00:39:48.800 --> 00:39:56.680]   So as seen in the data for every breath, we were given 80 time
[00:39:56.680 --> 00:39:59.480]   steps, like each breath was being defined by 80 time steps.
[00:39:59.480 --> 00:40:04.840]   But the question that we can ask ourselves is do we need those 80
[00:40:04.840 --> 00:40:07.680]   time steps? Do we need the entire full data? As we could
[00:40:07.680 --> 00:40:11.640]   see that, since the metric of the competition was also ma on
[00:40:11.640 --> 00:40:16.320]   the inspiratory phase, we tried this experiment that where we
[00:40:16.320 --> 00:40:21.320]   removed all the breath, all the timestamps, which were from the
[00:40:21.320 --> 00:40:25.160]   expiratory phase. So doing EDM, what we could find was the
[00:40:25.160 --> 00:40:28.240]   maximum length of the inspiratory phase for any given
[00:40:28.240 --> 00:40:32.280]   breath was around 35, like 35 time steps were from the
[00:40:32.280 --> 00:40:34.560]   inspiratory phase. And this varied from different breath
[00:40:34.560 --> 00:40:37.880]   IDs to breath IVs. But this was the maximum length. So to avoid
[00:40:37.880 --> 00:40:40.840]   padding, what we thought was let's truncate our entire
[00:40:40.840 --> 00:40:44.760]   sequences at the first 35 time steps. The idea again behind
[00:40:44.760 --> 00:40:49.000]   that was driven by the kind of metric that our models are going
[00:40:49.000 --> 00:40:51.640]   to be evaluated on. So what we decided,
[00:40:51.640 --> 00:40:55.320]   I'm guessing that would also help help to training time and
[00:40:55.320 --> 00:40:56.840]   cut it down by quite a bit.
[00:40:56.840 --> 00:41:01.440]   Exactly. That was like the major advantage. And we will come to
[00:41:01.440 --> 00:41:05.320]   that. So we decided to work with the sequence in the 40. And what
[00:41:05.320 --> 00:41:09.160]   we saw that we got slightly better and mostly comparable
[00:41:09.160 --> 00:41:15.880]   performances, given the some some noise, like noise in
[00:41:15.880 --> 00:41:18.720]   performance, but mostly comparable performances. But the
[00:41:18.720 --> 00:41:22.240]   major boost that we got was from the training times, like we were
[00:41:22.240 --> 00:41:24.880]   almost able to have the training times, which eventually if you
[00:41:24.880 --> 00:41:27.720]   look at a solution that was one of the necessities of a solution
[00:41:27.720 --> 00:41:32.400]   that the models had to, like we wanted to train more number of
[00:41:32.400 --> 00:41:34.840]   models and eventually model had to run for a longer period of
[00:41:34.840 --> 00:41:39.440]   time. So yeah, this was like the one of the core ideas of a
[00:41:39.440 --> 00:41:43.000]   solution that using only the first 40 time steps, and just
[00:41:43.000 --> 00:41:50.880]   truncating our solutions, sequences to that. Now, this
[00:41:50.880 --> 00:41:53.560]   started out as a regression problem, like if you see the
[00:41:53.560 --> 00:41:56.600]   output variable, it looks on the face value that it's a continuous
[00:41:56.600 --> 00:42:00.360]   variable. Why not just try a regression based solution here.
[00:42:00.360 --> 00:42:03.760]   And all our initial baselines, even in the public forum, this
[00:42:03.760 --> 00:42:06.840]   was driven by that fact. And people started out building
[00:42:06.840 --> 00:42:11.240]   regression models. But if you look closely into the
[00:42:11.240 --> 00:42:15.080]   distribution of the output variable, what you could see
[00:42:15.080 --> 00:42:17.640]   that even though it looked continuous, it was a discrete
[00:42:17.640 --> 00:42:22.080]   variable, it had only 950 unique values. And these values are
[00:42:22.080 --> 00:42:26.760]   also like the delta between the unique values was also a
[00:42:26.760 --> 00:42:31.640]   constant step difference, like it was d one plus delta d plus
[00:42:32.040 --> 00:42:35.920]   the second value would be d one plus two delta d. So only 950
[00:42:35.920 --> 00:42:38.960]   unique values. So we thought, let's try a classification
[00:42:38.960 --> 00:42:46.200]   approach. And what we found out was that we were able to achieve
[00:42:46.200 --> 00:42:50.640]   slightly better performance. But the major advantage we got from
[00:42:50.640 --> 00:42:53.280]   this was that the convergence was much faster, the
[00:42:53.280 --> 00:42:56.480]   performance that we were getting, let's say, at 100 epochs
[00:42:56.480 --> 00:42:58.680]   from a regression model, we were able to get the same
[00:42:58.680 --> 00:43:02.400]   performance in less than 50 epochs. So combining this with
[00:43:02.400 --> 00:43:05.440]   the fact that we were training our models only on the first 40
[00:43:05.440 --> 00:43:09.080]   timestamps of the sequence length, and the improved
[00:43:09.080 --> 00:43:12.880]   convergence we got from the classification model. This
[00:43:12.880 --> 00:43:16.000]   really helped us do much more experiments, much faster
[00:43:16.000 --> 00:43:18.960]   iterations. And eventually in the final model that we will,
[00:43:18.960 --> 00:43:24.840]   you must have read about the 1000 epochs. Because of these
[00:43:24.840 --> 00:43:29.800]   two core ideas. So yeah, these are the two core things that we
[00:43:29.800 --> 00:43:34.000]   build our model on. Nikhil, would you would you like to
[00:43:34.000 --> 00:43:34.640]   continue from it?
[00:43:34.640 --> 00:43:41.000]   Yeah, sure, sure. So yeah, this part, I think you might already
[00:43:41.000 --> 00:43:44.240]   be familiar with Sunlocked, we spend time on that. But just for
[00:43:44.240 --> 00:43:47.280]   the beginners, it's just how do we validate things, right? So
[00:43:47.280 --> 00:43:52.400]   basically, what we did was we split our breadth ideas into
[00:43:52.400 --> 00:43:57.480]   different parts. And then for each, each part, we treated it
[00:43:57.480 --> 00:44:00.200]   as a test set and trained on the rest of the data. And then we
[00:44:00.200 --> 00:44:04.640]   got, say, predictions for that part. And then we combine all
[00:44:04.640 --> 00:44:07.000]   of the training data. And that's how we get our out of hold
[00:44:07.000 --> 00:44:10.160]   predictions. And if we combine all of our test predictions, we
[00:44:10.160 --> 00:44:14.120]   get our mean test predictions. But yeah, for this competition,
[00:44:14.120 --> 00:44:18.160]   I think median test predictions work better, because again, the
[00:44:18.160 --> 00:44:21.600]   metric was mean absolute error. So in mean absolute error, if
[00:44:21.600 --> 00:44:25.840]   you try to optimize it, the best will come when you take the
[00:44:25.840 --> 00:44:30.000]   median instead of the mean. Yeah. So can you go to the next
[00:44:30.000 --> 00:44:34.120]   slide? Okay, yeah. So before I go to the next slide, and if I
[00:44:34.120 --> 00:44:37.360]   before I forget, I just like to highlight two points, I think I
[00:44:37.360 --> 00:44:41.480]   missed them in the beginning. So whenever I do any competition,
[00:44:41.480 --> 00:44:45.600]   it's very important for me to do two things, right. So the first
[00:44:45.600 --> 00:44:50.640]   thing is to have a very flexible pipeline, right. So one thing
[00:44:50.640 --> 00:44:53.640]   that stood out for both of us in this competition was having
[00:44:53.640 --> 00:44:57.640]   flexible pipeline. So I really believe at the beginning of your
[00:44:57.640 --> 00:45:00.560]   competition, you should spend time in writing your code in
[00:45:00.560 --> 00:45:03.960]   such a way that you can modify it easily, right. So it does not
[00:45:03.960 --> 00:45:07.880]   require you much effort to change little parts of your code
[00:45:07.880 --> 00:45:11.720]   at the end, right. So I think in such competition such as this,
[00:45:11.720 --> 00:45:16.960]   where we had only I think, around a month, right. So if you
[00:45:16.960 --> 00:45:21.120]   can change your code and iterate quickly, that will be a really
[00:45:21.120 --> 00:45:24.920]   big advantage for you, because you can do more experiments. And
[00:45:24.920 --> 00:45:27.960]   I think in competition such as Kaggle, where you have to try a
[00:45:27.960 --> 00:45:32.200]   lot of unexplored ideas, the biggest advantage can come from
[00:45:32.200 --> 00:45:36.760]   iterating quickly, right. So yeah, coming to iterating
[00:45:36.760 --> 00:45:40.760]   quickly, what I usually do is I train on one 10th of the data,
[00:45:40.760 --> 00:45:44.400]   and then I can do 10 experiments compared to training on the full
[00:45:44.400 --> 00:45:48.400]   data and do only one experiment, right. So I think, at the
[00:45:48.400 --> 00:45:51.920]   beginning, if you can do a lot of experiments, and then come
[00:45:51.920 --> 00:45:55.000]   with a good solution, you can always train on the whole data
[00:45:55.000 --> 00:45:58.520]   and then get a really good boost on the leaderboard. So what I do
[00:45:58.520 --> 00:46:03.560]   is basically I take two, I split my experiment into two parts.
[00:46:03.560 --> 00:46:07.120]   One, one which I train on the full data and one in which I
[00:46:07.120 --> 00:46:10.400]   train on only say, one 10th or one fifth of the data are
[00:46:10.400 --> 00:46:15.400]   depending on the competition's data size, right. So I track my
[00:46:15.400 --> 00:46:19.280]   experiments on that small portion of the data and try to
[00:46:19.280 --> 00:46:22.720]   improve on that portion of the data. So once I'm really
[00:46:22.720 --> 00:46:25.840]   confident that my experiments are working on that small
[00:46:25.840 --> 00:46:29.360]   portion of the data, I go and apply it on the large portion of
[00:46:29.360 --> 00:46:32.160]   the data. And then you know, we can obviously submit it to the
[00:46:32.160 --> 00:46:33.440]   leaderboard to get feedback.
[00:46:33.440 --> 00:46:37.120]   I'm sorry to interrupt. How do you tag the experiments? This is
[00:46:37.120 --> 00:46:39.760]   being live streamed to Waits and Bises, but not as a Waits and
[00:46:39.760 --> 00:46:41.520]   Bises question, how do you tag them?
[00:46:41.520 --> 00:46:46.600]   So I'm not gonna lie, but yeah, I use Waits and Bises for this
[00:46:46.600 --> 00:46:51.080]   competition. So before that, I was doing it in a semi manual
[00:46:51.080 --> 00:46:54.600]   way. But yeah, in this competition, I really wanted to
[00:46:54.600 --> 00:46:58.080]   try out Waits and Bises. I had heard a lot about it. And it
[00:46:58.080 --> 00:47:01.560]   lives up to its name, right? So Waits and Bises, it's, it's
[00:47:01.560 --> 00:47:04.680]   definitely a great tool for tracking. So we use Waits and
[00:47:04.680 --> 00:47:07.520]   Bises. I think even Sahil uses Waits and Bises in this
[00:47:07.520 --> 00:47:08.760]   competition for tracking.
[00:47:09.240 --> 00:47:14.080]   Yeah, so for me, like before, WANBI was really difficult. We
[00:47:14.080 --> 00:47:20.160]   use like I used to track it on Slack, like using a webhook. So
[00:47:20.160 --> 00:47:24.280]   okay, that was the way to go. But as you can imagine that,
[00:47:24.280 --> 00:47:27.320]   that is really a painful experience. And before that, it
[00:47:27.320 --> 00:47:30.120]   was like, like printing out the log, storing it in some log
[00:47:30.120 --> 00:47:34.240]   file and then visualizing the log file. But now like, it's
[00:47:34.240 --> 00:47:37.480]   really simple. And it's a really, really useful tool. Like
[00:47:37.480 --> 00:47:40.800]   for me, the entire setup is PyTorch tracking and Waits and
[00:47:40.800 --> 00:47:41.160]   Bises.
[00:47:41.160 --> 00:47:45.280]   That's, that's great to hear. I didn't inform the guests of
[00:47:45.280 --> 00:47:47.920]   this question earlier. I just thought of asking this and it's
[00:47:47.920 --> 00:47:50.600]   surprising that you were already using Waits and Bises. Thanks
[00:47:50.600 --> 00:47:51.360]   for the great feedback.
[00:47:51.360 --> 00:47:53.760]   Yeah, definitely.
[00:47:53.760 --> 00:47:55.120]   Nikhil, please continue.
[00:47:55.120 --> 00:47:59.600]   Yeah. Okay, so coming to the feature engineering and
[00:47:59.600 --> 00:48:03.560]   learnable front end part, right. So yeah, firstly to the feature
[00:48:03.560 --> 00:48:07.040]   engineering. So I think feature engineering is one of the most
[00:48:07.040 --> 00:48:10.000]   important steps in any competition. So yeah, this
[00:48:10.000 --> 00:48:13.520]   competition was mostly about architecture and then different
[00:48:13.520 --> 00:48:16.640]   other components. But generally, if you participate in data
[00:48:16.640 --> 00:48:19.120]   science competitions, I think feature engineering is one of
[00:48:19.120 --> 00:48:22.560]   the most crucial steps. But yeah, for this competition, we
[00:48:22.560 --> 00:48:25.800]   did not have a very complex features. So most of our
[00:48:25.800 --> 00:48:28.080]   features were similar to what you would see in public
[00:48:28.080 --> 00:48:32.560]   kernels, right? So say, for time series, what, what general
[00:48:32.560 --> 00:48:36.400]   features do we keep? One is shifted features, you basically
[00:48:36.520 --> 00:48:40.240]   shift your sequences one time step or two time steps or say n
[00:48:40.240 --> 00:48:43.560]   time steps back and get another feature, right? And then we had
[00:48:43.560 --> 00:48:46.560]   window features, where you have fixed size windows, and then you
[00:48:46.560 --> 00:48:51.360]   aggregate your data information on those windows, right? So
[00:48:51.360 --> 00:48:55.800]   basically, we can take what is the average you in, in the last
[00:48:55.800 --> 00:48:58.400]   three time steps or the last four time steps, or what is the
[00:48:58.400 --> 00:49:01.520]   deviation between it, something like that. And then we also had
[00:49:01.520 --> 00:49:05.240]   cumulative features. So one of the cumulative features that was
[00:49:05.240 --> 00:49:09.480]   helping a lot was the cumulative sum of the you in, right? So
[00:49:09.480 --> 00:49:12.840]   basically, your pressure is even if you think of it intuitively,
[00:49:12.840 --> 00:49:16.480]   it's basically controlled by the amount of air that is entering
[00:49:16.480 --> 00:49:20.400]   in your lungs, right? So you in is kind of cumulative sum of
[00:49:20.400 --> 00:49:25.040]   units also giving you a giving your model a similar information
[00:49:25.040 --> 00:49:28.240]   to that, right? So yeah, one more thing I would like to point
[00:49:28.240 --> 00:49:30.840]   about feature engineering is very important to have domain
[00:49:30.840 --> 00:49:34.560]   knowledge, right? So once you understand the problem, and why
[00:49:34.560 --> 00:49:39.240]   your problem was created, and why things should work, you'll,
[00:49:39.240 --> 00:49:43.360]   you'll be able to create much better features than just trying
[00:49:43.360 --> 00:49:46.560]   out random features, right? So I think it's very important that
[00:49:46.560 --> 00:49:49.600]   you understand the data first, and then try to create features
[00:49:49.600 --> 00:49:50.480]   based on that.
[00:49:50.480 --> 00:49:56.240]   One point Nikhil I would like to add is, so one very
[00:49:56.240 --> 00:50:00.520]   counterintuitive thought could be that we were using LSTMs,
[00:50:00.520 --> 00:50:03.560]   they are known to capture the sequential nature of data, then
[00:50:03.560 --> 00:50:09.120]   why use these features. So our hypothesis was that even using a
[00:50:09.120 --> 00:50:12.960]   single, like even without these features, you could attain a
[00:50:12.960 --> 00:50:17.120]   similar performance, but that would take a lot of epoch and
[00:50:17.120 --> 00:50:20.120]   longer experiments for the model to reach similar results. So
[00:50:20.120 --> 00:50:22.840]   this basically was another thought experiment, which helps
[00:50:22.840 --> 00:50:26.680]   us help us accelerate the performance, we were able to get
[00:50:26.680 --> 00:50:31.200]   in limited amount of time, like feed in the like, we knew that
[00:50:31.200 --> 00:50:34.640]   there was an inductive bias in the data set, given the temporal
[00:50:34.640 --> 00:50:37.400]   nature of the data. So we embedded that from the get go.
[00:50:37.400 --> 00:50:40.360]   And this again, that is why you could see most of the public
[00:50:40.360 --> 00:50:43.760]   forums also, and the kernels had these set of features.
[00:50:43.760 --> 00:50:51.560]   Yes, yes. So coming to that, right. So basically, our idea
[00:50:51.560 --> 00:50:54.480]   was that features help your model convergence converge
[00:50:54.480 --> 00:50:58.600]   faster, right? So this was a learnable front end idea, right?
[00:50:58.600 --> 00:51:03.200]   So I think this was inspired from a sales idea that you'd
[00:51:03.200 --> 00:51:06.840]   seen in a lot of different audio competitions was that if you
[00:51:06.840 --> 00:51:10.720]   have a learnable front end, which actually tries to create
[00:51:10.720 --> 00:51:14.200]   features on its own, and then you feed it to the model along
[00:51:14.200 --> 00:51:17.800]   with your raw input features, it will help your model much
[00:51:17.800 --> 00:51:22.800]   better, right? So basically, what is the how do we think of
[00:51:22.800 --> 00:51:26.120]   CNNs, right? So CNNs help capture neighboring information,
[00:51:26.120 --> 00:51:31.080]   right? So basically, if you have 10 time steps that 10 time
[00:51:31.080 --> 00:51:35.080]   steps near to a particular time step, and then you apply a
[00:51:35.080 --> 00:51:39.080]   CNN on it, it can aggregate or secrete combination of these
[00:51:39.080 --> 00:51:42.520]   10 time steps that you might not be able to do manually, right?
[00:51:42.520 --> 00:51:46.160]   So manually, we do something like, say, what is the
[00:51:46.160 --> 00:51:49.080]   difference between the last two time steps or say, what is the
[00:51:49.080 --> 00:51:54.200]   total sum of human we have seen, right? But we do not go for
[00:51:54.200 --> 00:51:58.280]   complex combinations. But I think, yeah, what CNNs help you
[00:51:58.280 --> 00:52:02.360]   do is they create feature combinations on their own, which
[00:52:02.360 --> 00:52:06.480]   they think are useful to the model. And yeah, learnable
[00:52:06.480 --> 00:52:11.320]   front end really helped us. So we'll go into detail of how we
[00:52:11.320 --> 00:52:15.320]   designed a learnable front end, right? So yeah, if you can see
[00:52:15.320 --> 00:52:19.200]   this numerical features, we have a lot of different
[00:52:19.200 --> 00:52:22.400]   convolutions, and they are all of different sizes, right? So
[00:52:22.400 --> 00:52:25.520]   again, the intuition behind is that we wanted to capture
[00:52:25.520 --> 00:52:29.720]   information that is very near to my current data point and also
[00:52:29.720 --> 00:52:34.640]   information that is far in terms of time from my current data
[00:52:34.640 --> 00:52:37.840]   point, right? So if you take kernel sizes of two, it captures
[00:52:37.840 --> 00:52:43.000]   the really nearby information. And if you take the last
[00:52:43.000 --> 00:52:48.440]   convolution kernel, which is of kernel size 15, it captures
[00:52:49.200 --> 00:52:54.160]   nearby as well as the information which is quite far
[00:52:54.160 --> 00:52:58.320]   away from my current data point, right? So then we concatenated
[00:52:58.320 --> 00:53:02.240]   all this, the outputs from all these convolutional kernels, and
[00:53:02.240 --> 00:53:05.280]   then we concatenated it along with the raw features, right? So
[00:53:05.280 --> 00:53:09.120]   this helped our model do some of its feature engineering on its
[00:53:09.120 --> 00:53:11.840]   own. So yeah, that was our idea about that.
[00:53:11.840 --> 00:53:13.160]   A couple of...
[00:53:13.160 --> 00:53:16.520]   And this was being... Sorry, this was being fed to the
[00:53:16.520 --> 00:53:20.160]   transformer, right? After this front end was being learned?
[00:53:20.160 --> 00:53:23.200]   Yes, yes. Thanks.
[00:53:23.200 --> 00:53:28.760]   So on the face of it, this looks like a really simple like
[00:53:28.760 --> 00:53:32.480]   front end to have. And the reason behind that was we tried
[00:53:32.480 --> 00:53:36.320]   a couple of like complicated architectures like which were
[00:53:36.320 --> 00:53:40.000]   done in few of the prior competitions, like ResNet, 1D,
[00:53:40.000 --> 00:53:43.920]   CNN sort of architecture, but we couldn't really find a
[00:53:43.920 --> 00:53:46.760]   performance boost, like the simple was working the best. And
[00:53:46.760 --> 00:53:50.240]   second thing is like the number of channels and then kernel
[00:53:50.240 --> 00:53:53.560]   sizes that you would want to use. This this could be tuned
[00:53:53.560 --> 00:53:56.120]   like this is not the perfect architecture we found for this.
[00:53:56.120 --> 00:53:58.080]   This is something that's working for us. Yeah.
[00:53:58.080 --> 00:54:04.240]   Makes sense. To me, it's still quite complex based on other
[00:54:04.240 --> 00:54:07.160]   solutions that I would I would have come up with. So.
[00:54:09.440 --> 00:54:14.760]   Yes, yes, yes. So finally, we came to transformers, the magic.
[00:54:14.760 --> 00:54:18.280]   So it's not like we just try transformers, we tried a lot of
[00:54:18.280 --> 00:54:21.560]   different things. And yeah, Sahil can cover it. But yeah,
[00:54:21.560 --> 00:54:24.400]   transformers were definitely the magic for us, right? So
[00:54:24.400 --> 00:54:28.680]   basically, transformer has two components and encoder and
[00:54:28.680 --> 00:54:32.200]   decoder structure. And ideally, you can use both of these
[00:54:32.200 --> 00:54:35.200]   structures combined together for time series problems. But
[00:54:35.200 --> 00:54:39.840]   yeah, for this, we use only the encoder part, right? So I think
[00:54:39.840 --> 00:54:42.480]   most I did not get time to experiment with the decoder. So
[00:54:42.480 --> 00:54:48.160]   we are stuck with the encoder part. So we did us, we did
[00:54:48.160 --> 00:54:51.000]   slight modifications to the original transformer
[00:54:51.000 --> 00:54:55.520]   architecture. So I'll just quickly go over that, right. So
[00:54:55.520 --> 00:54:59.200]   one, one of the things that we did was RE0, the speed of
[00:54:59.200 --> 00:55:01.920]   convergence, right. So basically, when we were doing
[00:55:01.920 --> 00:55:05.920]   transformers, we were trying out different things that could
[00:55:05.920 --> 00:55:10.720]   help us speed the convergence of transformers, right. So yeah,
[00:55:10.720 --> 00:55:15.120]   so again, time was a very big issue in this competition. And
[00:55:15.120 --> 00:55:17.720]   what we were seeing in our discussion forums, and even I
[00:55:17.720 --> 00:55:21.960]   had posted this as a joke, was that maybe at the end of the
[00:55:21.960 --> 00:55:24.880]   competitions, people will train their models for 1000 deep
[00:55:24.880 --> 00:55:30.120]   oxide. So definitely, the problem was, yeah. Definitely
[00:55:30.120 --> 00:55:33.560]   the problem was, the models were not converging as fast as we
[00:55:33.560 --> 00:55:37.000]   wanted them to, right. So one of the papers that we really found
[00:55:37.000 --> 00:55:41.160]   helpful was RE0, right. So it basically tells that instead of
[00:55:41.160 --> 00:55:44.960]   adding the output of a previous layer and the current output,
[00:55:44.960 --> 00:55:48.760]   you add a parameter to the, which you multiply to the
[00:55:48.760 --> 00:55:52.080]   current output, and then you add the output of the previous
[00:55:52.080 --> 00:55:55.800]   layer. So thinking of it intuitively, it's basically
[00:55:55.800 --> 00:56:00.040]   telling the model to keep only as much information of the
[00:56:00.040 --> 00:56:03.960]   current output that it wants to retain, right. So it can even
[00:56:03.960 --> 00:56:07.280]   retain more of the current information if it scales the
[00:56:07.280 --> 00:56:10.480]   current output by say, a higher number, right. So that is
[00:56:10.480 --> 00:56:12.920]   basically the idea of RE0. And yeah,
[00:56:12.920 --> 00:56:17.880]   like a learnable, residual connection that you are setting
[00:56:17.880 --> 00:56:18.080]   up.
[00:56:18.080 --> 00:56:19.320]   Makes sense.
[00:56:19.320 --> 00:56:28.400]   Exactly. And then, as we train deep transformer networks, this
[00:56:28.400 --> 00:56:32.440]   RE0 really helped us speed up our convergence, right. So yeah,
[00:56:32.440 --> 00:56:35.880]   I'll quickly talk about the key features of a transformers.
[00:56:35.880 --> 00:56:39.120]   Okay, the firstly, the most important thing was highly
[00:56:39.120 --> 00:56:42.400]   parameterized and regularized deep transformers, right. So
[00:56:42.400 --> 00:56:45.400]   what do we mean by highly parameterized? It's basically
[00:56:45.400 --> 00:56:48.920]   having a large number of parameters, right. So even at
[00:56:48.920 --> 00:56:51.360]   the end of the competition, I think we did not have enough
[00:56:51.360 --> 00:56:54.520]   parameters to train our model. And I think we could go more,
[00:56:54.520 --> 00:56:58.360]   but then again, we had run out of the GPU limit that we had.
[00:56:58.360 --> 00:57:04.920]   Right. So one big problem with high parameterization is that
[00:57:04.920 --> 00:57:08.440]   you need a good regularization, right. So otherwise, the model
[00:57:08.440 --> 00:57:12.800]   starts overfitting very quickly, right. So I think, Sahil can
[00:57:12.800 --> 00:57:14.200]   tell the joke about the dropout.
[00:57:14.200 --> 00:57:19.160]   Yeah, so basically, the final solution had a dropout of 0.8.
[00:57:19.160 --> 00:57:23.240]   But there was this inside joke that was going on that if we
[00:57:23.240 --> 00:57:26.560]   keep increasing the number of layers, the number of heads, we
[00:57:26.560 --> 00:57:30.560]   might even reach a dropout of like, maybe one like no pass no
[00:57:30.560 --> 00:57:34.120]   information. Yeah. But yeah,
[00:57:34.120 --> 00:57:38.880]   I was really curious, but maybe I'm wrong. But like, I've never
[00:57:38.880 --> 00:57:43.000]   seen such a high dropout value. Like, what was the reason for
[00:57:43.000 --> 00:57:46.480]   like the model still training after having a 80% dropout?
[00:57:46.480 --> 00:57:52.680]   Yeah, so yes. Yeah, please. Yes, I'll say please. Please.
[00:57:53.600 --> 00:58:00.040]   Good. So we feel that the number so there's this thing that if
[00:58:00.040 --> 00:58:02.840]   you increase the number of parameters in our model, ideally
[00:58:02.840 --> 00:58:05.560]   you want would want to regularize it so that as Nicole
[00:58:05.560 --> 00:58:08.120]   mentioned, you want to avoid overfitting. And it was driven
[00:58:08.120 --> 00:58:10.800]   by that fact. So if you look at the configuration of a final
[00:58:10.800 --> 00:58:15.680]   transformers, it had 20 layers, it had 128 heads. And if even if
[00:58:15.680 --> 00:58:19.560]   you compare it with let's say a base bird, or even let's say,
[00:58:19.880 --> 00:58:24.680]   large bird, the number of heads and the number of players, like
[00:58:24.680 --> 00:58:29.400]   bird, I believe has 12 layers and 12 heads or six or six or
[00:58:29.400 --> 00:58:32.080]   something, something of this combination, we had 20 layers
[00:58:32.080 --> 00:58:38.120]   and 128 heads. So the number of parameters was such that the
[00:58:38.120 --> 00:58:41.000]   dropout had to be high. And again, it is it was driven by
[00:58:41.000 --> 00:58:46.160]   our experiments also, like, in the end, it has to, if it's
[00:58:46.160 --> 00:58:50.040]   working, don't fix it, right. So we kept on increasing the
[00:58:50.040 --> 00:58:54.120]   dropout and the performance was increasing for us. Just one
[00:58:54.120 --> 00:58:57.480]   point that I would like to add here. So there's this idea that
[00:58:57.480 --> 00:59:00.120]   if the data set is small, you won't be able to fit a good
[00:59:00.120 --> 00:59:03.160]   neural net model. So given the size of the model that we were
[00:59:03.160 --> 00:59:06.640]   using, the data set was relatively very small, if you
[00:59:06.640 --> 00:59:08.800]   look at the number of parameters, but we were still
[00:59:08.800 --> 00:59:11.800]   able to get very good performance, because we
[00:59:12.720 --> 00:59:16.520]   basically were able to regularize our model by that
[00:59:16.520 --> 00:59:19.800]   much. So this belief that you won't be able to fit a good
[00:59:19.800 --> 00:59:24.920]   neural net model with a small data set can it can be done, but
[00:59:24.920 --> 00:59:27.120]   you need the appropriate amount of regularization.
[00:59:27.120 --> 00:59:30.920]   Makes sense. And that's why I was earlier also asking this
[00:59:30.920 --> 00:59:34.240]   question. Nikhil and Shail are both experienced data scientists
[00:59:34.240 --> 00:59:37.480]   and you just shared this experimental framework, we start
[00:59:37.480 --> 00:59:41.280]   with the smallest subset and continuously increase it. So you
[00:59:41.280 --> 00:59:44.280]   didn't randomly arrive on a point eight dropout. I'm sure
[00:59:44.280 --> 00:59:46.840]   there was a lot of experiment that yes, behind it. And it
[00:59:46.840 --> 00:59:49.040]   wasn't just, oh, let's try a point eight. Let's see.
[00:59:49.040 --> 00:59:51.800]   No, no, definitely. It was not that.
[00:59:51.800 --> 00:59:57.800]   So one point. So whenever you are designing your experiments,
[00:59:57.800 --> 01:00:00.960]   it's so whenever you read some good papers, there's a section
[01:00:00.960 --> 01:00:04.720]   of ablation study. Try to think it in that manner. Whenever you
[01:00:04.720 --> 01:00:08.400]   are competing in a competition, we we we had a document like a
[01:00:08.400 --> 01:00:11.640]   Google Doc, where when we listed out all the parameters that we
[01:00:11.640 --> 01:00:14.760]   had to iterate on all the ideas that we had to iterate on, and
[01:00:14.760 --> 01:00:17.920]   the corresponding performance that we got, so that in the end,
[01:00:17.920 --> 01:00:20.120]   when you are finalizing your solutions, you also have
[01:00:20.120 --> 01:00:24.040]   something to backtrack on. So this also helps like doing
[01:00:24.040 --> 01:00:27.240]   random experiments will not help. Again, weights and bias
[01:00:27.240 --> 01:00:30.120]   again help there also, like you could eventually track your
[01:00:30.120 --> 01:00:33.240]   performance, you could add metadata there. So that you
[01:00:33.240 --> 01:00:35.720]   could also even though if you were not logging your
[01:00:35.720 --> 01:00:38.840]   information in a Google Doc, you could track it from there as
[01:00:38.840 --> 01:00:42.680]   well. So it is very important to do lots of experiments, but in
[01:00:42.680 --> 01:00:43.640]   an organized manner.
[01:00:43.640 --> 01:00:47.560]   That makes sense. Thanks. Thanks for that clarification.
[01:00:47.560 --> 01:00:49.760]   Can you please?
[01:00:49.760 --> 01:00:55.600]   Yeah. So yeah, the second thing was increasing number of heads
[01:00:55.600 --> 01:00:58.800]   number of layers and embedding size, right. So again, this is
[01:00:58.800 --> 01:01:03.400]   just a part of highly parameterizing this
[01:01:03.400 --> 01:01:07.200]   transformers. So I think the most important among these was
[01:01:07.200 --> 01:01:11.200]   the number of layers. So I think we trained at 20 layer deep
[01:01:11.200 --> 01:01:16.560]   does a transformers network at the end. And even a number of
[01:01:16.560 --> 01:01:20.000]   heads, I think it's it's was way beyond what people usually use.
[01:01:20.000 --> 01:01:22.440]   So we had 128 heads that Sahil mentioned.
[01:01:22.440 --> 01:01:28.480]   So I don't know one point, one point, then again, so yes, you
[01:01:28.480 --> 01:01:31.200]   look at the past transformer solution, which did very good on
[01:01:31.360 --> 01:01:35.040]   tabular data. For example, there was this data science bowl,
[01:01:35.040 --> 01:01:40.000]   which was held by both both and company, right? So they're the
[01:01:40.000 --> 01:01:42.960]   one of the catalyst Patrick and who performed very well in this
[01:01:42.960 --> 01:01:46.240]   competition. Also, he built a transformer only solution. And
[01:01:46.240 --> 01:01:49.360]   the key ingredient of that solution was he was around 32 or
[01:01:49.360 --> 01:01:54.400]   64 heads, if I recall correctly. And again, like that was sort of
[01:01:54.400 --> 01:01:57.720]   you could say, one of the inspiring ideas that we got using
[01:01:57.720 --> 01:02:01.240]   high number of heads from like, it was demonstrated in the past.
[01:02:01.440 --> 01:02:02.560]   So a high number of heads.
[01:02:02.560 --> 01:02:09.680]   Yes, yes. Okay. So we have talked about re0, we have talked
[01:02:09.680 --> 01:02:13.680]   about dropout. Okay, so the last bit under I think one of the
[01:02:13.680 --> 01:02:17.000]   really interesting bits was adding 1D convolutions, right?
[01:02:17.000 --> 01:02:20.000]   So, Sahil was insisting we had done that we should try
[01:02:20.000 --> 01:02:23.040]   conformance, we should try conformance. So conformance is
[01:02:23.040 --> 01:02:27.880]   basically convolutions and transformers combined. Maybe as
[01:02:27.920 --> 01:02:32.360]   Sahil can elaborate on it a bit more. But yeah, we were quite
[01:02:32.360 --> 01:02:35.600]   we are quite lazy to not actually try the original
[01:02:35.600 --> 01:02:40.800]   conformance architecture. But what we did was we concatenated
[01:02:40.800 --> 01:02:44.440]   the output of each of our transformers in encoded layers
[01:02:44.440 --> 01:02:50.280]   by using a convolution like we did similar to our front end,
[01:02:50.280 --> 01:02:54.240]   right? So basically, instead of just feeding the output of the
[01:02:54.520 --> 01:02:58.000]   current transformer layer to the next transformer layer, what we
[01:02:58.000 --> 01:03:00.560]   did was we also applied convolutions to the output,
[01:03:00.560 --> 01:03:04.480]   right? So it's basically for the next transformer layer, you are
[01:03:04.480 --> 01:03:08.560]   getting transformer outputs that perform the transformer plus
[01:03:08.560 --> 01:03:14.160]   the inner layer outputs, right? So again, I think it was bit
[01:03:14.160 --> 01:03:18.040]   intuition driven and bit because we wanted to experiment but
[01:03:18.040 --> 01:03:23.320]   yeah, I think this worked out really well, right? So using
[01:03:23.320 --> 01:03:27.080]   just this, I think we were able to skip 10 or 20 positions on
[01:03:27.080 --> 01:03:31.720]   the leaderboard, right? So I think but in many of the modern
[01:03:31.720 --> 01:03:35.880]   architectures too, I think like, if I recall correctly, spin
[01:03:35.880 --> 01:03:39.200]   transformers too, they use convolutions, right? So
[01:03:39.200 --> 01:03:44.800]   convolutions, you know, married with transformers, it works
[01:03:44.800 --> 01:03:48.520]   really well, right? So this transformer plus inner layer
[01:03:48.760 --> 01:03:54.640]   give us a really good boost. Yeah, and finally, we had two
[01:03:54.640 --> 01:03:57.840]   outputs rather than a single output. So that was also in the
[01:03:57.840 --> 01:04:00.960]   last two days of the competition, I think. So this
[01:04:00.960 --> 01:04:04.920]   was again inspired from Heng CK's, this PPT or whatever you
[01:04:04.920 --> 01:04:10.320]   call it, that's really good diagram that we had separate
[01:04:10.320 --> 01:04:14.840]   outputs for inspiratory phase and expiratory phase, right? So
[01:04:15.560 --> 01:04:19.920]   basically, all of your model is same, but they will add your
[01:04:19.920 --> 01:04:22.760]   last layer bifurcates into two, right? So when you predict for
[01:04:22.760 --> 01:04:25.320]   the inspiratory phase separately and the expiratory phase
[01:04:25.320 --> 01:04:29.080]   separately, right? So at the beginning, also, I told that the
[01:04:29.080 --> 01:04:33.520]   expiratory phase values were kind of hard coded, right? So I
[01:04:33.520 --> 01:04:38.200]   we thought that it will make much sense if we try to learn
[01:04:38.200 --> 01:04:41.560]   these two things separately, right? And yeah, this was also
[01:04:41.560 --> 01:04:45.440]   helping on model by reducing our CVs.
[01:04:45.440 --> 01:04:51.680]   That's really helpful. Sorry, I just wanted to interrupt if
[01:04:51.680 --> 01:04:55.320]   that's okay. I just wanted to point out that people are always
[01:04:55.320 --> 01:04:58.920]   asking how do researchers come up with architectures and you
[01:04:58.920 --> 01:05:00.960]   could have called this architecture, you could have
[01:05:00.960 --> 01:05:04.240]   named this architecture after your names as well. But it's
[01:05:04.240 --> 01:05:07.400]   literally experimentation driven and we're getting to learn this
[01:05:07.400 --> 01:05:10.760]   behind the scenes of how the architectures come about. For
[01:05:10.760 --> 01:05:13.840]   this, it's a data set driven problem. But I'm guessing that's
[01:05:13.840 --> 01:05:16.960]   also how it's for research for a lot of research.
[01:05:16.960 --> 01:05:21.560]   Most of the architectures are experiment driven. That is what
[01:05:21.560 --> 01:05:24.680]   they if you read again, reiterating the point I
[01:05:24.680 --> 01:05:27.360]   mentioned earlier, any good research paper would always have
[01:05:27.360 --> 01:05:30.280]   ablation studies. And those ablation studies would only
[01:05:30.280 --> 01:05:33.000]   highlight like help you highlight the point that what
[01:05:33.000 --> 01:05:37.120]   all component added worthwhile value. So in the end, they also
[01:05:37.120 --> 01:05:40.040]   so we also had as I had mentioned out in the beginning
[01:05:40.040 --> 01:05:44.840]   that we had a set of ideas like to use LSTMs to use GRUs, 1D
[01:05:44.840 --> 01:05:48.560]   CNNs, transformers, conformers. So we had all these components
[01:05:48.560 --> 01:05:51.640]   in our mind. And in the end, we had experiment pipelines that
[01:05:51.640 --> 01:05:56.320]   how we would want to experiment. And eventually, like you keep on
[01:05:56.320 --> 01:05:59.720]   iterating and find some architecture that works and
[01:05:59.720 --> 01:06:02.520]   kudos to Nikhil on this transformer. Like, if you read
[01:06:02.520 --> 01:06:05.720]   most of the people were not able to make the transformer work.
[01:06:06.080 --> 01:06:10.720]   But it required some like a persistent effort to finally get
[01:06:10.720 --> 01:06:12.640]   it to work. Even in the beginning, we were not getting
[01:06:12.640 --> 01:06:17.480]   anywhere close to let's say, a transformer plus LSTM model,
[01:06:17.480 --> 01:06:21.720]   like our best model was transformer plus LSTM. But in
[01:06:21.720 --> 01:06:24.400]   the end, we were able to somehow manage this model.
[01:06:24.400 --> 01:06:27.720]   That's that's helpful.
[01:06:27.720 --> 01:06:33.880]   So this was what the final model look like we trained on 15
[01:06:33.880 --> 01:06:39.600]   different seats, the CV score as shown here is point 105 to 107.
[01:06:39.600 --> 01:06:45.440]   The number of epochs again, this was the important bit. And this
[01:06:45.440 --> 01:06:49.840]   might not have even saturated in terms of learning, it could have
[01:06:49.840 --> 01:06:55.360]   gone on maybe till 1500 or 2000 owners. So yeah, so this was the
[01:06:55.360 --> 01:06:59.840]   final model how it looked like. And one more thing that people
[01:06:59.840 --> 01:07:02.640]   which again was driven by something which Heng CK
[01:07:02.640 --> 01:07:08.960]   highlighted that we could see that the delta between the C,
[01:07:08.960 --> 01:07:12.360]   the CV and the train was saturating. And what people
[01:07:12.360 --> 01:07:16.200]   started to do was train the data, just remove the cross
[01:07:16.200 --> 01:07:19.040]   validation part. Since now you know that the performance delta
[01:07:19.040 --> 01:07:21.560]   is not going to increase or decrease, both the curves are
[01:07:21.560 --> 01:07:25.400]   saturating. Train your model on different seeds of data, shuffle
[01:07:25.400 --> 01:07:29.800]   the data on the entire data set. And we could gain another let's
[01:07:29.800 --> 01:07:34.400]   say, like point 005 order of improvement using that. That is
[01:07:34.400 --> 01:07:39.680]   why you see that we were able to like, if we do it on a 15 fold
[01:07:39.680 --> 01:07:43.520]   cross validation, the score that you would get would be of point
[01:07:43.520 --> 01:07:48.000]   105 107, very similar to our CV, but the final public will be was
[01:07:48.000 --> 01:07:51.000]   less than point one. So this was the data that we got by training
[01:07:51.000 --> 01:07:58.560]   on the whole data set with different sheets. Yeah. So,
[01:07:59.560 --> 01:08:04.000]   finally, the things like that did not work this this is the
[01:08:04.000 --> 01:08:07.840]   main juice of it, I feel that by this not happening, we might not
[01:08:07.840 --> 01:08:10.440]   have ended up with the architecture that we have. So we
[01:08:10.440 --> 01:08:16.360]   tried a bunch of augmentations like how we could augment the
[01:08:16.360 --> 01:08:19.760]   data, we tried to add some noise to the input data set, we tried
[01:08:19.760 --> 01:08:24.000]   to shift the sequences of it by like shifting the augmentation
[01:08:24.000 --> 01:08:28.320]   and we also tried flipping it. Strangely, flip augmentation was
[01:08:28.320 --> 01:08:33.360]   used by one of the top solutions also, but in our case, it did
[01:08:33.360 --> 01:08:37.200]   not work. The important thing that we missed was the multitask
[01:08:37.200 --> 01:08:40.760]   training, we did it, but we did it in a wrong manner. What we
[01:08:40.760 --> 01:08:44.160]   tried to do was we thought that since RNC are something that
[01:08:44.160 --> 01:08:49.680]   dictate how a lung would look like, and what how different
[01:08:49.680 --> 01:08:53.000]   lungs behave, we thought that why not let the model learn
[01:08:53.000 --> 01:08:55.640]   this? Why not let the transformer understand the
[01:08:55.640 --> 01:08:58.080]   difference between the different lungs also not only the
[01:08:58.080 --> 01:09:02.320]   breadth, but different lungs. Again, this did not work out as
[01:09:02.320 --> 01:09:07.920]   well. What people did here was instead of using just the output
[01:09:07.920 --> 01:09:10.920]   pressure as your output, like the target variable, they
[01:09:10.920 --> 01:09:15.080]   started adding multiple different variables like the
[01:09:15.080 --> 01:09:20.720]   consecutive delta basically the delta in pressure and the two
[01:09:20.720 --> 01:09:25.840]   delta in pressure basically two lag shifted differences in the
[01:09:25.840 --> 01:09:30.400]   pressure values. Now this if you if you look at the winning
[01:09:30.400 --> 01:09:34.400]   solutions post, like what the winners have posted, the first
[01:09:34.400 --> 01:09:37.320]   and the second team who had reverse engineer the data, they
[01:09:37.320 --> 01:09:40.400]   had come up with this concept of PID that the data was generated
[01:09:40.400 --> 01:09:45.240]   using using a PID controller, and it has three parts. One was
[01:09:45.240 --> 01:09:47.640]   the proportion part integral part and the derivative part.
[01:09:47.640 --> 01:09:50.840]   Now why this might now this is again our hypothesis. And I
[01:09:50.840 --> 01:09:55.560]   think this is true that why this delta like using these auxiliary
[01:09:55.560 --> 01:09:58.800]   met targets like delta in pressure was working because it
[01:09:58.800 --> 01:10:03.360]   indicative of the derivative part of the PID. And similarly,
[01:10:03.360 --> 01:10:07.000]   what people have not mentioned in the forum, or maybe I've
[01:10:07.000 --> 01:10:11.880]   missed it is using cumulative pressure as an auxiliary target
[01:10:11.880 --> 01:10:15.560]   that could have hinted towards the indie in integral part of
[01:10:15.560 --> 01:10:19.120]   the PID. So most of the winning solutions have highlighted the
[01:10:19.120 --> 01:10:22.880]   delta in pressure using delta in pressure as the target metric,
[01:10:23.160 --> 01:10:26.680]   but maybe the cumulative using cumulative pressure as another
[01:10:26.680 --> 01:10:29.960]   set of auxiliary variable would also help. Because that is how
[01:10:29.960 --> 01:10:33.320]   like the delta part in general, in most of the time series
[01:10:33.320 --> 01:10:36.680]   competition, delta in consecutive time, target values
[01:10:36.680 --> 01:10:39.560]   generally doesn't help. But in this case, it was helping. So
[01:10:39.560 --> 01:10:42.280]   maybe the cumulative pressure might also help. So that is
[01:10:42.280 --> 01:10:44.840]   something we didn't try. And this was a major miss on our
[01:10:44.840 --> 01:10:47.560]   part, because most of the top solutions are using multitask
[01:10:47.560 --> 01:10:52.880]   learning. And finally, none of the non transform. So our final
[01:10:52.880 --> 01:10:57.080]   solution was a single, single transformer. And the reason for
[01:10:57.080 --> 01:11:01.200]   that was we were not able to get other architectures, which
[01:11:01.200 --> 01:11:05.840]   included LSTMs, GRUs. We tried very few experiments with
[01:11:05.840 --> 01:11:09.800]   original conformance, but the results were not at all close,
[01:11:09.800 --> 01:11:13.960]   and combinations of LSTMs and transformers, like none of them
[01:11:13.960 --> 01:11:17.600]   had a CV, which was as good as the transformer. So in the end,
[01:11:17.600 --> 01:11:20.040]   we had to check all this. Yeah.
[01:11:21.920 --> 01:11:25.160]   That's, that's really helpful. And for the audience will also
[01:11:25.160 --> 01:11:28.720]   be learning from the winning team later today in like four or
[01:11:28.720 --> 01:11:31.600]   five hours. So you might want to join there, they had figured out
[01:11:31.600 --> 01:11:35.960]   how to reverse engineer, how to create the data. And this was
[01:11:35.960 --> 01:11:38.600]   artificially generated. So that figured out a way around it,
[01:11:38.600 --> 01:11:41.200]   which wasn't the goal of the competition, but that was
[01:11:41.200 --> 01:11:44.000]   required to win the competition. And there was a little debate
[01:11:44.000 --> 01:11:46.840]   around that as well. But if you're curious to learn,
[01:11:46.840 --> 01:11:50.480]   yeah, the solutions were really good and kudos to the winning
[01:11:50.480 --> 01:11:51.680]   team. They did really good.
[01:11:51.680 --> 01:12:00.280]   Yes, awesome to me. I'll just try to recap quickly. So I, a
[01:12:00.280 --> 01:12:03.600]   lot of your idea was driven by yourselves. Because one thing I
[01:12:03.600 --> 01:12:07.760]   learned was, I think yours was one of the only if not the only
[01:12:07.760 --> 01:12:09.920]   solution using a smaller sequence length.
[01:12:09.920 --> 01:12:14.640]   Yeah, most of the top solutions didn't use 40 sequence length.
[01:12:14.640 --> 01:12:18.600]   So I'm guessing a lot of your own idea went on behind the
[01:12:18.600 --> 01:12:21.320]   scenes. But apart from that, you're used to transformer based
[01:12:21.320 --> 01:12:24.800]   architecture and a lot of experiments that led to this
[01:12:24.800 --> 01:12:29.720]   really strange architecture, which had a lot of parameters,
[01:12:29.720 --> 01:12:33.360]   really counterintuitive for a small tabular data set as well
[01:12:33.360 --> 01:12:37.800]   in a way. And you could, it still wasn't overfitting, as you
[01:12:37.800 --> 01:12:39.960]   mentioned, because you could have trained it for longer, it
[01:12:39.960 --> 01:12:44.960]   took a lot of epochs, you had to really set a high value of
[01:12:45.040 --> 01:12:49.320]   dropout, which is also key here. And adding an inspiration from
[01:12:49.320 --> 01:12:52.400]   the recent swing transformer or similar architectures where you
[01:12:52.400 --> 01:12:56.240]   fed in a convolution based feature back into the
[01:12:56.240 --> 01:12:59.560]   transformer along with a learnable front end. These would
[01:12:59.560 --> 01:13:01.800]   be the key summaries of your solution, if I may.
[01:13:01.800 --> 01:13:09.320]   Yeah, one more point like having good hardware. So what we did
[01:13:09.320 --> 01:13:14.040]   was we used to be basically for us each experiment was running
[01:13:14.040 --> 01:13:18.400]   on multiple TPUs. So Nikhil, if you would like to give this
[01:13:18.400 --> 01:13:21.680]   advice to maybe someone who's beginning out in like, how did
[01:13:21.680 --> 01:13:23.760]   we use hardware for this particular model?
[01:13:23.760 --> 01:13:32.000]   Yes, yes, yes. So I think one of the key components was
[01:13:32.000 --> 01:13:35.680]   definitely hardware, right? So you require good hardware to
[01:13:35.680 --> 01:13:38.480]   participate in Kaggle competitions really
[01:13:38.480 --> 01:13:42.080]   competitively. So what we did was, we used a Google collab,
[01:13:42.120 --> 01:13:46.600]   right? So Google collab, I think it's pretty cheap. And
[01:13:46.600 --> 01:13:49.840]   basically, what you do is if you get a collab pro plus
[01:13:49.840 --> 01:13:53.840]   subscription, you can train on three TPUs parallelly if you're
[01:13:53.840 --> 01:13:57.800]   using the low RAM one, right? So basically, RAM was not a big
[01:13:57.800 --> 01:14:00.920]   requirement for this competition, because all of our
[01:14:00.920 --> 01:14:05.000]   training was being done on GPU, right? So what we did was, we
[01:14:05.000 --> 01:14:08.760]   initially, initially, we were training on a single collab pro
[01:14:08.760 --> 01:14:11.600]   machine, and we were running three experiments parallelly,
[01:14:11.600 --> 01:14:14.880]   right? So basically, yeah, one more thing that I'd like to
[01:14:14.880 --> 01:14:18.640]   highlight is, if you if you can find ways to do things
[01:14:18.640 --> 01:14:23.640]   parallelly, it will be much, you know, it will be, sorry, it
[01:14:23.640 --> 01:14:26.560]   will be much faster, and it will really give you an edge in the
[01:14:26.560 --> 01:14:30.200]   competition, right? So what we did was, we were running three
[01:14:30.200 --> 01:14:34.440]   safe folds of the model parallelly on a single collab
[01:14:34.440 --> 01:14:37.400]   pro account, right? And then what we did at the end of the
[01:14:37.400 --> 01:14:42.440]   competition, say, due to this, this kind of adrenaline rush
[01:14:42.440 --> 01:14:46.320]   that we had, we purchased five different collab pro accounts,
[01:14:46.320 --> 01:14:51.080]   right? So that we could train 15 different folds of 15 different
[01:14:51.080 --> 01:14:55.600]   seeds together at the time, right? So yeah, that was a bit
[01:14:55.600 --> 01:14:59.800]   crazy from our end. But yeah, it really helped us give us get a
[01:14:59.800 --> 01:15:02.000]   competitive edge at the end of the competition.
[01:15:02.000 --> 01:15:05.800]   I'm guessing that's still much cheaper than what a few folks
[01:15:05.800 --> 01:15:09.720]   would have paid in other cloud vendor expenses on GPUs.
[01:15:09.720 --> 01:15:15.080]   So I think it's only $50 for a month, even Google collab pro
[01:15:15.080 --> 01:15:19.560]   plus, even if you purchase five accounts, it's only $250. So I
[01:15:19.560 --> 01:15:25.360]   think for India $250 might be a bit high, but yeah. For other
[01:15:25.360 --> 01:15:28.440]   countries, you might you might think that okay, $250 is really
[01:15:28.440 --> 01:15:30.120]   affordable for the resources part.
[01:15:30.120 --> 01:15:32.600]   For a first place finish, I think in India.
[01:15:32.600 --> 01:15:34.120]   Yes, yeah, it's it's
[01:15:34.240 --> 01:15:39.440]   it's very much justified. Yeah, yeah. So I'll stop the
[01:15:39.440 --> 01:15:40.000]   screenshot.
[01:15:40.000 --> 01:15:45.960]   Thanks. I'll just read the audience if there are any
[01:15:45.960 --> 01:15:55.920]   question from any one of you. I'll just give you a minute. No,
[01:15:55.920 --> 01:15:59.680]   I don't see any questions. I think the explanation was super
[01:15:59.680 --> 01:16:04.160]   crystal clear. Thanks, everyone. That joined I'll quickly share
[01:16:04.160 --> 01:16:09.600]   my screen and point out Nikhil's LinkedIn profile. You can find
[01:16:09.600 --> 01:16:13.960]   Nikhil on LinkedIn, you need to change your cover profile.
[01:16:13.960 --> 01:16:14.920]   Nikhil, it seems.
[01:16:14.920 --> 01:16:20.400]   One thing about that one thing about that. So this was the
[01:16:20.400 --> 01:16:23.760]   first competition on Kaggle that I did really well, right. So I
[01:16:23.760 --> 01:16:26.960]   think I'm a bit proud of that. So that's why I want to keep
[01:16:26.960 --> 01:16:30.480]   continuing. Okay, using it, even if I become a grandmaster in the
[01:16:30.480 --> 01:16:30.920]   future.
[01:16:31.520 --> 01:16:34.560]   Sorry, I assumed you just forgot about this. Sorry.
[01:16:34.560 --> 01:16:36.560]   No issue.
[01:16:36.560 --> 01:16:40.720]   You can also find Sahil on LinkedIn any other places where
[01:16:40.720 --> 01:16:42.600]   the audience can find you apart from Kaggle.
[01:16:42.600 --> 01:16:47.960]   So I guess I'm active on Twitter, like passively active
[01:16:47.960 --> 01:16:53.320]   on Twitter. I so just advice like another advice which I do
[01:16:53.320 --> 01:16:57.160]   regularly. Twitter is a goldmine of resources like, even though
[01:16:57.160 --> 01:17:01.840]   I'm not very actively tweeting on Twitter, but what I do is
[01:17:01.840 --> 01:17:06.560]   I follow relevant people. And they really post useful stuff
[01:17:06.560 --> 01:17:09.240]   like apart from Kaggle, Twitter is one of the major sources of
[01:17:09.240 --> 01:17:11.120]   learning for me. So yeah.
[01:17:11.120 --> 01:17:15.720]   Exactly, exactly. So even I joined Twitter, I think only a
[01:17:15.720 --> 01:17:20.120]   year back, but I think Twitter is a really good if you see the
[01:17:20.120 --> 01:17:23.240]   threads of see if even if you follow many Kagglers including
[01:17:23.240 --> 01:17:27.200]   Sunim and then you can find a really helpful and useful links
[01:17:27.200 --> 01:17:32.720]   which you can study in your free time. So yeah, even I'm also a
[01:17:32.720 --> 01:17:35.720]   bit active on Twitter, not very much active. So yeah, you can
[01:17:35.720 --> 01:17:38.920]   definitely connect to me on Twitter or on LinkedIn, right?
[01:17:38.920 --> 01:17:41.000]   And feel free to shoot me a message if you have any
[01:17:41.000 --> 01:17:41.520]   doubts.
[01:17:41.520 --> 01:17:45.400]   I would put the caveat I'm not a good Kaggler. I'm a new Kaggler
[01:17:45.400 --> 01:17:48.360]   who somehow manages to learn from great Kagglers like
[01:17:48.360 --> 01:17:50.800]   yourself. So maybe the audience would want to follow you. I'll
[01:17:51.200 --> 01:17:55.040]   put all of these links on the forum link I'd shared initially.
[01:17:55.040 --> 01:17:59.120]   And to wrap up Nikhil, Sahil, thanks so much for joining us
[01:17:59.120 --> 01:18:01.640]   today. Thank you so much for giving such a detailed walk
[01:18:01.640 --> 01:18:03.840]   through of a solution. It was incredible to learn from
[01:18:03.840 --> 01:18:04.360]   everybody.
[01:18:04.360 --> 01:18:08.520]   Thank you. Thank you. Thank you, Sunim. Thank you for inviting
[01:18:08.520 --> 01:18:10.080]   us. Thank you, Sahil. It was a great

