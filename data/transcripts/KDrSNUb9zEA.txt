
[00:00:00.000 --> 00:00:04.400]   Users are always going to tell you incremental things.
[00:00:04.400 --> 00:00:06.080]   They're always going to tell you they want this better.
[00:00:06.080 --> 00:00:07.960]   They're never going to tell you they want the iPhone.
[00:00:07.960 --> 00:00:10.920]   They're always going to tell you, "Can you make my BlackBerry keyboard slide out instead?"
[00:00:10.920 --> 00:00:11.920]   or whatever.
[00:00:11.920 --> 00:00:14.640]   Those inputs are going to usually improve the product, but they're not going to help
[00:00:14.640 --> 00:00:17.440]   you create a leapfrog product.
[00:00:17.440 --> 00:00:21.800]   You're listening to Gradient Dissent, a show about machine learning in the real world,
[00:00:21.800 --> 00:00:24.680]   and I'm your host, Lukas Biewald.
[00:00:24.680 --> 00:00:29.760]   William Falken started his career training to be a Navy SEAL before becoming an iOS developer
[00:00:29.760 --> 00:00:35.880]   and eventually the CEO of Lightning.ai, which makes PyTorch Lightning a very successful
[00:00:35.880 --> 00:00:41.480]   ML framework and Lightning.ai, which is an awesome website that calls itself the OS for
[00:00:41.480 --> 00:00:43.920]   machine learning that we're going to talk a lot about today.
[00:00:43.920 --> 00:00:49.480]   This is a super fun conversation and I hope you enjoy it.
[00:00:49.480 --> 00:00:52.060]   I thought it might be fun to start with your background.
[00:00:52.060 --> 00:00:55.200]   We don't have a lot of people that went through Navy SEAL training on this podcast, so could
[00:00:55.200 --> 00:00:58.800]   you tell us a little bit of your story on how you came to found Lightning?
[00:00:58.800 --> 00:00:59.800]   Yeah, sure.
[00:00:59.800 --> 00:01:03.960]   I'm originally from Venezuela, so I don't know if people know that.
[00:01:03.960 --> 00:01:10.000]   I'm actually born and raised there, so English is my second language, which is why you'll
[00:01:10.000 --> 00:01:13.000]   hear me slip up today in a few things.
[00:01:13.000 --> 00:01:16.480]   Code does not care what language you speak, which is great.
[00:01:16.480 --> 00:01:22.760]   I moved here when I was in my teens and then eventually ended up going to the US military
[00:01:22.760 --> 00:01:24.520]   and I went through SEAL training, BUD/S.
[00:01:24.520 --> 00:01:27.280]   I was there for a few years.
[00:01:27.280 --> 00:01:33.320]   If anyone knows BUD/S, it's in classes 272 and 277, which is great.
[00:01:33.320 --> 00:01:39.160]   I came out injured, actually, and so I basically got stashed in one of the SEAL teams that
[00:01:39.160 --> 00:01:41.680]   does a lot of intelligence work.
[00:01:41.680 --> 00:01:48.080]   It's a very interesting team, so I also happen to speak Arabic from just fun, I guess.
[00:01:48.080 --> 00:01:50.680]   There's a lot of cool stuff that we're doing there.
[00:01:50.680 --> 00:01:55.840]   When it was time for me to go back into training, this is when we pulled out of Iraq in 2012
[00:01:55.840 --> 00:02:02.040]   or 2013, so the Navy gave me an option to leave or become a pilot or something, and
[00:02:02.040 --> 00:02:04.360]   I chose to leave.
[00:02:04.360 --> 00:02:07.760]   Maybe if I'd seen Top Gun, I would have stayed as a pilot, potentially.
[00:02:07.760 --> 00:02:15.160]   It was a great time, and yeah, we did a lot of good work there and very happy about the
[00:02:15.160 --> 00:02:16.160]   time.
[00:02:16.160 --> 00:02:19.080]   I think it really set me up for success for everything I did afterwards.
[00:02:19.080 --> 00:02:23.240]   I didn't care about school until I left the military, it turns out.
[00:02:23.240 --> 00:02:25.760]   And then how did you get into machine learning?
[00:02:25.760 --> 00:02:36.200]   So I was at Columbia doing my undergrad, and it's around 2013, I want to say, and basically
[00:02:36.200 --> 00:02:43.480]   people started telling me about this machine learning thing, and I wasn't super into math
[00:02:43.480 --> 00:02:45.320]   or any of this stuff back then.
[00:02:45.320 --> 00:02:52.680]   I started my degree as computer science, and for some reason, the CS part was fun, but
[00:02:52.680 --> 00:02:53.880]   it wasn't the most interesting part.
[00:02:53.880 --> 00:02:58.600]   I really gravitated towards math at some point, and I think if you were doing anything with
[00:02:58.600 --> 00:03:04.360]   statistics or math in 2013, and you were touching code, it's impossible not to run into SVMs
[00:03:04.360 --> 00:03:06.600]   and random forest and all this stuff.
[00:03:06.600 --> 00:03:09.800]   I remember taking my first neural networks class, and they were like, "Yeah, you got
[00:03:09.800 --> 00:03:15.760]   this image," and we've all seen this MNIST thing that Jan put together back in the day
[00:03:15.760 --> 00:03:20.360]   with carousel music, and I was like, "I don't know why this is useful.
[00:03:20.360 --> 00:03:22.800]   I don't see the value of this."
[00:03:22.800 --> 00:03:29.800]   And then many, many years later, I ended up working with Jan as one of my PhD advisors.
[00:03:29.800 --> 00:03:36.920]   So at some point in my undergrad, I went into finance because it was interesting, I guess,
[00:03:36.920 --> 00:03:39.800]   and I went there to try to use deep learning on the trading floor.
[00:03:39.800 --> 00:03:45.400]   And finance today is probably maybe not so allergic to deep learning anymore, but back
[00:03:45.400 --> 00:03:50.440]   then it was, because of all the observability problems.
[00:03:50.440 --> 00:03:53.440]   So I didn't love that, and so I went back to school.
[00:03:53.440 --> 00:03:56.480]   I got into computational neuroscience, and that's really where I learned about deep learning
[00:03:56.480 --> 00:03:59.960]   and got really into machine learning.
[00:03:59.960 --> 00:04:03.080]   So really the science is trying to decode neural activity and trying to understand how
[00:04:03.080 --> 00:04:04.080]   the brain works.
[00:04:04.080 --> 00:04:08.960]   So I still care a lot about that, and that's a lot of my drive is really the pursuit of
[00:04:08.960 --> 00:04:10.120]   science.
[00:04:10.120 --> 00:04:15.040]   But I find that a lot of the tools are really limiting to enable science to advance and
[00:04:15.040 --> 00:04:17.120]   do what it needs to do.
[00:04:17.120 --> 00:04:19.760]   But then what were you seeing when you started Lightning?
[00:04:19.760 --> 00:04:24.040]   What was the problem you were setting out to solve in the very beginning of it?
[00:04:24.040 --> 00:04:28.040]   So I don't think I was explicitly...
[00:04:28.040 --> 00:04:31.560]   So when I started Lightning, I was still an undergrad, right?
[00:04:31.560 --> 00:04:33.160]   So this is around 2015.
[00:04:33.160 --> 00:04:38.640]   I was doing my research, and I wasn't building Lightning for Lightning or anything like that.
[00:04:38.640 --> 00:04:41.560]   It was just my research code that I had internally.
[00:04:41.560 --> 00:04:47.000]   And what I was trying to optimize for was how do I try ideas as quickly as possible
[00:04:47.000 --> 00:04:51.960]   without having to rewrite the code over and over again, but in a way that doesn't limit
[00:04:51.960 --> 00:04:52.960]   me, right?
[00:04:52.960 --> 00:04:57.120]   Because as a researcher, the worst thing that you can do is you can adopt something and
[00:04:57.120 --> 00:05:01.640]   you spend six months going to research, and then suddenly the last few months you're like
[00:05:01.640 --> 00:05:05.160]   blocked and you're like, "Oh my God, I have to rewrite everything," and then it discredits
[00:05:05.160 --> 00:05:06.160]   all your results.
[00:05:06.160 --> 00:05:10.000]   So flexibility was like the number one thing that I cared about, right?
[00:05:10.000 --> 00:05:12.360]   And so that's a lot of what I was solving.
[00:05:12.360 --> 00:05:16.200]   And over the years, really, I mean, I did open source until 2019.
[00:05:16.200 --> 00:05:20.720]   So it took about four or five years to get there.
[00:05:20.720 --> 00:05:24.120]   What I did during that time was just try so many different ideas, right?
[00:05:24.120 --> 00:05:27.240]   So my first research was, like I said, neuroscience.
[00:05:27.240 --> 00:05:29.760]   A lot of that was using GANs and VAEs.
[00:05:29.760 --> 00:05:33.560]   Then after that, I moved into NLP when I started my PhD.
[00:05:33.560 --> 00:05:37.600]   So Cho is one of the main authors on the Seek2Seek and Attention paper.
[00:05:37.600 --> 00:05:41.520]   So my first thing was to implement Attention from scratch and a Seek2Seek network and all
[00:05:41.520 --> 00:05:47.880]   this stuff and learned, which is very rough if you guys have ever tried this.
[00:05:47.880 --> 00:05:48.880]   It's not trivial.
[00:05:48.880 --> 00:05:51.160]   I know Lucas has implemented this a bunch of times now.
[00:05:51.160 --> 00:05:54.160]   I've tried to do it once and I agree.
[00:05:54.160 --> 00:05:55.160]   It's non-trivial.
[00:05:55.160 --> 00:05:58.040]   Maybe it's not quite as daunting as it seems at first.
[00:05:58.040 --> 00:05:59.040]   I don't know.
[00:05:59.040 --> 00:06:00.760]   I guess there's probably less resources when you did it.
[00:06:00.760 --> 00:06:01.760]   Yeah.
[00:06:01.760 --> 00:06:03.800]   I mean, back then you're writing everything yourself.
[00:06:03.800 --> 00:06:07.680]   Nowadays, there's like Attention heads and all this stuff you can plug in, but there
[00:06:07.680 --> 00:06:12.480]   you're calculating your own stuff and then PyTorch didn't support certain things.
[00:06:12.480 --> 00:06:16.240]   You're like blocked and it was really confusing.
[00:06:16.240 --> 00:06:17.760]   So it was rough.
[00:06:17.760 --> 00:06:21.160]   And then we took that and then we started working on complex.
[00:06:21.160 --> 00:06:24.120]   So Cho also introduced GRU units, right?
[00:06:24.120 --> 00:06:29.960]   So we started working on complex GRUs and the idea there was to help eliminate the need
[00:06:29.960 --> 00:06:34.760]   for like the eliminate gradients from exploding or zeroing out.
[00:06:34.760 --> 00:06:38.160]   And so complex numbers can help you do that, especially for audio, right?
[00:06:38.160 --> 00:06:40.520]   With some normalization techniques and all that.
[00:06:40.520 --> 00:06:44.600]   But complex numbers is not something that PyTorch supported, literally until like a
[00:06:44.600 --> 00:06:45.600]   year ago.
[00:06:45.600 --> 00:06:50.760]   So a little old PhD me, I'm like sitting there and I'm like, "I have to implement this whole
[00:06:50.760 --> 00:06:54.160]   complex number library," which I did and it's open source.
[00:06:54.160 --> 00:06:55.160]   Super slow.
[00:06:55.160 --> 00:06:56.160]   Don't use it.
[00:06:56.160 --> 00:06:57.160]   Use the PyTorch one.
[00:06:57.160 --> 00:06:58.160]   It's better now.
[00:06:58.160 --> 00:07:00.600]   But it's like willing to do what it takes, I guess, to get the thing done.
[00:07:00.600 --> 00:07:05.920]   But yeah, I mean, through all those learnings, eventually I ended up in computer vision and
[00:07:05.920 --> 00:07:07.000]   self-supervised research.
[00:07:07.000 --> 00:07:10.760]   I think if you work with Jan, there's no way you don't do self-supervised learning at some
[00:07:10.760 --> 00:07:11.960]   point.
[00:07:11.960 --> 00:07:17.120]   And so I kind of fell into it and this is like 2019, I think, before it like blew up.
[00:07:17.120 --> 00:07:21.640]   Well, before the world found out about it, people have been doing this for many years.
[00:07:21.640 --> 00:07:23.640]   And so all of that stressed us a lightning, right?
[00:07:23.640 --> 00:07:27.600]   And so that was pretty flexible by the time that it got open source.
[00:07:27.600 --> 00:07:29.600]   Like I knew I could do a lot of this stuff.
[00:07:29.600 --> 00:07:33.480]   And then when I joined FAIR, it was a lot of like, "Oh, can we use it for this or that?"
[00:07:33.480 --> 00:07:34.480]   I'm like, "Yes, of course you can.
[00:07:34.480 --> 00:07:35.480]   Let me show you how."
[00:07:35.480 --> 00:07:39.120]   And it just took forever to explain all the possible ways you could use it.
[00:07:39.120 --> 00:07:43.480]   And today I think it's obvious that it can work for pretty much anything, but it wasn't
[00:07:43.480 --> 00:07:44.480]   back then.
[00:07:44.480 --> 00:07:49.040]   And we still learn as we go sometimes and someone finds that it's not flexible for something
[00:07:49.040 --> 00:07:50.600]   and we fix it and we move on, right?
[00:07:50.600 --> 00:07:52.240]   But it's a long process.
[00:07:52.240 --> 00:07:54.640]   It's taken a lot of years to get here.
[00:07:54.640 --> 00:08:01.000]   So when you go back to 2015, was PyTorch actually in use at the time?
[00:08:01.000 --> 00:08:02.000]   It was just Torch, right?
[00:08:02.000 --> 00:08:05.680]   I'm trying to remember what years these things came out, but certainly an unusual choice
[00:08:05.680 --> 00:08:10.240]   to build on top of PyTorch in 2015, if that's even possible.
[00:08:10.240 --> 00:08:11.440]   How did that happen?
[00:08:11.440 --> 00:08:14.900]   Well, so my original version wasn't on top of PyTorch.
[00:08:14.900 --> 00:08:17.480]   So I had actually started in Theano, right?
[00:08:17.480 --> 00:08:22.120]   So basically what happened, I was using Theano and SKLearn mostly.
[00:08:22.120 --> 00:08:26.040]   So I think I did what everyone does where they take the model and they add the .fit
[00:08:26.040 --> 00:08:27.040]   to it, right?
[00:08:27.040 --> 00:08:30.200]   And then you start building off of that.
[00:08:30.200 --> 00:08:33.200]   And so that was my original version and that was Theano, right?
[00:08:33.200 --> 00:08:36.640]   And Theano, have you worked on Theano?
[00:08:36.640 --> 00:08:39.080]   I don't know when you started, Lukas.
[00:08:39.080 --> 00:08:43.240]   I think I might've touched Theano, but very little.
[00:08:43.240 --> 00:08:47.160]   I think I was using Keras on top of Theano if that dates me.
[00:08:47.160 --> 00:08:48.160]   Yeah, yeah.
[00:08:48.160 --> 00:08:49.520]   No, for sure.
[00:08:49.520 --> 00:08:51.680]   So I got really annoyed at it.
[00:08:51.680 --> 00:08:54.680]   I mean, I think it was great to show proof of concepts for sure.
[00:08:54.680 --> 00:08:57.520]   So I started using Keras immediately, right?
[00:08:57.520 --> 00:09:01.360]   And I think that helped me unblock a lot of stuff, but I got very, at some point you end
[00:09:01.360 --> 00:09:06.440]   up running into limitations and I'm sure that's changed, but back then that was true.
[00:09:06.440 --> 00:09:10.720]   And so that happened and that's when I was like, fine, I guess I have to go and get into
[00:09:10.720 --> 00:09:11.800]   TensorFlow.
[00:09:11.800 --> 00:09:13.760]   I was like trying to avoid it, right?
[00:09:13.760 --> 00:09:17.880]   And so my first version actually was built on top of TensorFlow.
[00:09:17.880 --> 00:09:22.080]   But the second that PyTorch came out, which was a few years later, I rewrote it all in
[00:09:22.080 --> 00:09:26.440]   PyTorch and mostly because it just felt more mathematical.
[00:09:26.440 --> 00:09:28.360]   I could see the math.
[00:09:28.360 --> 00:09:29.360]   It was easier, right?
[00:09:29.360 --> 00:09:34.320]   Whereas in TensorFlow, you had this duplicate layer where it was like a meta language on
[00:09:34.320 --> 00:09:38.560]   top of the thing, which again, that's changed since then, but back then that's kind of the
[00:09:38.560 --> 00:09:39.920]   world we lived in, right?
[00:09:39.920 --> 00:09:43.840]   So yeah, it was very experiment.
[00:09:43.840 --> 00:09:46.320]   PyTorch back then was very hard to work with.
[00:09:46.320 --> 00:09:51.840]   Oh, sorry, it was easy, but installing things like that was really difficult.
[00:09:51.840 --> 00:09:52.840]   That's really interesting.
[00:09:52.840 --> 00:09:59.440]   So were you at all inspired by the way Keras did things or do you feel like your Lightning
[00:09:59.440 --> 00:10:01.960]   was sort of in contrast to parts of Keras?
[00:10:01.960 --> 00:10:03.000]   How did you think about that?
[00:10:03.000 --> 00:10:08.640]   Because I sort of feel like Lightning plays a similar role to PyTorch as Keras plays to
[00:10:08.640 --> 00:10:09.640]   TensorFlow.
[00:10:09.640 --> 00:10:13.800]   Do you feel like that's too simple or wrong?
[00:10:13.800 --> 00:10:21.280]   Yeah, I mean, I think when I first released Lightning and we put it on the Torch thing,
[00:10:21.280 --> 00:10:25.680]   I called it the Keras for PyTorch because at a high level it kind of looked like it,
[00:10:25.680 --> 00:10:27.280]   but it really wasn't, right?
[00:10:27.280 --> 00:10:33.320]   So I may be the cause of this confusion, unfortunately.
[00:10:33.320 --> 00:10:39.440]   But yeah, like I just said, I used the Adno, I used Keras, I used TensorFlow, I used SKLearn,
[00:10:39.440 --> 00:10:42.920]   so a lot of my inspiration obviously comes from a lot of these things.
[00:10:42.920 --> 00:10:46.680]   Before I got into machine learning though, I was an iPhone developer, so I worked on
[00:10:46.680 --> 00:10:48.880]   iOS for a long time.
[00:10:48.880 --> 00:10:53.440]   And so a lot of these ideas that people bring in as callbacks and all these things are actually
[00:10:53.440 --> 00:10:57.320]   ideas that have been introduced in Objective-C since the '70s, '80s.
[00:10:57.320 --> 00:11:01.800]   So if you work on mobile, if you work at web, you've been exposed to these ideas.
[00:11:01.800 --> 00:11:08.520]   So I would say a lot of my inspiration really was, I think the API simplicity, like .fit
[00:11:08.520 --> 00:11:13.720]   kind of thing, came from most likely SKLearn, like I would say.
[00:11:13.720 --> 00:11:18.720]   And then I think that a lot of the callback and things like that, I was actually very
[00:11:18.720 --> 00:11:19.720]   opposed to callbacks.
[00:11:19.720 --> 00:11:24.240]   It turns out a lot of the hook names, and even if you see the way I've named things,
[00:11:24.240 --> 00:11:28.760]   a lot of them are inspired by Objective-C and these super long names that Objective...
[00:11:28.760 --> 00:11:34.400]   Actually, you told me you started with Objective-C, so I'm sure you know what I'm talking about.
[00:11:34.400 --> 00:11:37.200]   But yeah, it's a lot like super long syntax names, right?
[00:11:37.200 --> 00:11:42.960]   I'm a little surprised you like Objective-C. I feel like most people, they hate it.
[00:11:42.960 --> 00:11:47.000]   And I think one of the reasons people tend to hate Objective-C is the verbosity, but
[00:11:47.000 --> 00:11:49.440]   it sounds like you see the sense in it.
[00:11:49.440 --> 00:11:50.440]   Yeah.
[00:11:50.440 --> 00:11:52.560]   I mean, the verbosity makes us not have to think about it, right?
[00:11:52.560 --> 00:11:56.840]   I hate when names are so short and you're like, "What do you mean by this?"
[00:11:56.840 --> 00:12:01.400]   Objective-C is like, "View did load on this and that and that."
[00:12:01.400 --> 00:12:02.560]   And you're like, "That makes sense.
[00:12:02.560 --> 00:12:03.880]   I read this whole thing."
[00:12:03.880 --> 00:12:11.320]   I think all of them did inspire me.
[00:12:11.320 --> 00:12:15.880]   And I would say, I think something I really liked about Keras was the feedback that you
[00:12:15.880 --> 00:12:16.880]   get, right?
[00:12:16.880 --> 00:12:21.360]   So the summary tables and all of that, that's inspired by Keras as well.
[00:12:21.360 --> 00:12:23.880]   So I would say it's a combination of a lot of things, right?
[00:12:23.880 --> 00:12:28.840]   But I would say most of the things that I've really thought about really are driven in
[00:12:28.840 --> 00:12:33.160]   that fundamental Objective-C world and that iOS world, right?
[00:12:33.160 --> 00:12:36.600]   And in fact, if you look at Lightning apps now, the new abstractions that we put into
[00:12:36.600 --> 00:12:39.560]   Lightning, a lot of them are kind of similar to that, right?
[00:12:39.560 --> 00:12:41.920]   So there have a lot more elements of that.
[00:12:41.920 --> 00:12:46.920]   So yeah, I think over the years, things have evolved, but no, I think Lightning's taken
[00:12:46.920 --> 00:12:53.160]   kind of its own soul and its own thing, and it's started to become kind of its own paradigm
[00:12:53.160 --> 00:12:59.360]   that I hope that does become a standard in the industry, and I hope that it does inspire
[00:12:59.360 --> 00:13:02.600]   a lot of other people, especially in their APIs and how they write things, right?
[00:13:02.600 --> 00:13:04.280]   Because I do think it works and scales.
[00:13:04.280 --> 00:13:09.320]   So I'm not offended if people grab the APIs and do something with them, because it means
[00:13:09.320 --> 00:13:14.000]   that at the very least, we standardize them out, which is a win for everyone, right?
[00:13:14.000 --> 00:13:19.640]   So what's the part of the Lightning API that you feel super proud of that you feel like
[00:13:19.640 --> 00:13:22.960]   was different than what was around when you built it?
[00:13:22.960 --> 00:13:23.960]   Yeah.
[00:13:23.960 --> 00:13:29.440]   So I mean, I would say the main two things in Lightning are the Lightning module on the
[00:13:29.440 --> 00:13:34.320]   trainer, right, and I think those are the two that everyone uses, and those two together
[00:13:34.320 --> 00:13:36.960]   allow you to abstract most of it away, right?
[00:13:36.960 --> 00:13:38.920]   And so I think that's really what I'm proud of.
[00:13:38.920 --> 00:13:45.120]   I think I'm proud of the trainer really, I think, has changed a lot, right?
[00:13:45.120 --> 00:13:50.160]   And it's starting to become a standard across many other things outside of Lightning, because
[00:13:50.160 --> 00:13:52.760]   it is a good API.
[00:13:52.760 --> 00:13:55.880]   And I think it's just the simplicity of it, right?
[00:13:55.880 --> 00:14:00.040]   It's ability to see what's happening, change things and just see magic happen.
[00:14:00.040 --> 00:14:06.040]   So yeah, and I would say like, probably, honestly, the new stuff that we just released with the
[00:14:06.040 --> 00:14:10.600]   Lightning work, Lightning flow and Lightning app, you know, it's taken us a few years to
[00:14:10.600 --> 00:14:16.180]   really think about this and figure out how do we take those ideas from building models
[00:14:16.180 --> 00:14:21.200]   and how do you generalize that to building full end-to-end ML workflows, right?
[00:14:21.200 --> 00:14:24.240]   Research workflows, production pipelines, all that stuff.
[00:14:24.240 --> 00:14:25.640]   And that's just not an easy thing to do.
[00:14:25.640 --> 00:14:30.160]   So we wanted to do it in a way where it was not, it felt Lightning.
[00:14:30.160 --> 00:14:34.200]   It like has a spirit and the DNA of Lightning and you feel like you're using Lightning where
[00:14:34.200 --> 00:14:35.560]   you're using it, right?
[00:14:35.560 --> 00:14:37.600]   So I'm very proud of that.
[00:14:37.600 --> 00:14:39.960]   And that's something that was a team effort.
[00:14:39.960 --> 00:14:43.120]   I mean, all of this, by the way, has been a team effort collectively.
[00:14:43.120 --> 00:14:47.440]   I think I've seeded some ideas, but there's no way that we would have been here at all
[00:14:47.440 --> 00:14:50.200]   without the community and the team here at Lightning specifically.
[00:14:50.200 --> 00:14:57.920]   Yeah, I totally want to talk about the Lightning launch that you just came out with recently.
[00:14:57.920 --> 00:15:03.160]   I'm super impressed by what you did there, but I guess I'm curious before we go into
[00:15:03.160 --> 00:15:08.480]   that, like I remember a moment where I think PyTorch had something called Ignite, I think
[00:15:08.480 --> 00:15:12.520]   that was really similar to Lightning or at least the PyTorch team thought it was similar
[00:15:12.520 --> 00:15:13.520]   to Lightning.
[00:15:13.520 --> 00:15:17.240]   I'm kind of curious, you were actually working at Facebook, I think.
[00:15:17.240 --> 00:15:21.000]   Were you working at Facebook at the same time that Facebook is also sort of making a somewhat
[00:15:21.000 --> 00:15:24.320]   competitive piece of software to you?
[00:15:24.320 --> 00:15:25.320]   And was that awkward?
[00:15:25.320 --> 00:15:26.800]   Like, do you have any sense?
[00:15:26.800 --> 00:15:29.440]   Like, did it feel competitive at the time?
[00:15:29.440 --> 00:15:30.440]   So two things.
[00:15:30.440 --> 00:15:34.960]   One, Ignite is not done by PyTorch and it's not a Facebook product.
[00:15:34.960 --> 00:15:40.920]   It is a third party product where all they're doing is hosting the docs for it, right?
[00:15:40.920 --> 00:15:43.580]   So it's not actually built by Facebook or PyTorch.
[00:15:43.580 --> 00:15:46.760]   It just seems that way because of the way the docs have been structured.
[00:15:46.760 --> 00:15:48.440]   So that's the first thing.
[00:15:48.440 --> 00:15:55.680]   The second thing is, I was a researcher and a student and I was literally trying to build
[00:15:55.680 --> 00:15:58.880]   papers, not build software for machine learning.
[00:15:58.880 --> 00:16:02.280]   So I wasn't like sitting around using tools and looking around at stuff, right?
[00:16:02.280 --> 00:16:04.160]   So I had no idea that they were in a round.
[00:16:04.160 --> 00:16:05.640]   I had no idea that most of these tools were out.
[00:16:05.640 --> 00:16:09.040]   The ones I've used are the only ones I like literally knew about, right?
[00:16:09.040 --> 00:16:12.560]   You've been in research, like I'm sure there's like a ton of stuff that you're like, oh,
[00:16:12.560 --> 00:16:15.760]   that's cool, but like never used it because I don't care because I'm doing my research,
[00:16:15.760 --> 00:16:16.760]   right?
[00:16:16.760 --> 00:16:21.520]   So I think it's a pretty normal thing for researchers to be pretty narrow focus.
[00:16:21.520 --> 00:16:25.800]   And I think it wasn't until it got launched that people like Alfredo and everyone else
[00:16:25.800 --> 00:16:27.040]   was like, oh my God, it's kind of like this.
[00:16:27.040 --> 00:16:28.040]   I was like, oh, interesting.
[00:16:28.040 --> 00:16:29.040]   What is that thing?
[00:16:29.040 --> 00:16:31.920]   And then I look at it, I'm like, I guess kind of this like this, but like it's got its own
[00:16:31.920 --> 00:16:33.080]   DNA, right?
[00:16:33.080 --> 00:16:35.200]   So it's not surprising though.
[00:16:35.200 --> 00:16:36.960]   I mean, it's happens in research, right?
[00:16:36.960 --> 00:16:40.960]   Like you have people who are parallel working on something because something has happened
[00:16:40.960 --> 00:16:41.960]   that unblocks that.
[00:16:41.960 --> 00:16:44.880]   So it's going to trigger similar ideas in a lot of people.
[00:16:44.880 --> 00:16:47.840]   But when they come up at the end, they're going to be very different things, right?
[00:16:47.840 --> 00:16:52.400]   My analogy is always like, you know, if you and I are like, hey, let's paint the face
[00:16:52.400 --> 00:16:57.120]   of a person and just say like, I described the face, I bet you and I are going to paint
[00:16:57.120 --> 00:16:58.120]   it differently, right?
[00:16:58.120 --> 00:17:00.680]   Even though we're trying to do the same thing.
[00:17:00.680 --> 00:17:03.720]   I guess what caused you to actually start a company around Lightning?
[00:17:03.720 --> 00:17:05.600]   What was that journey like?
[00:17:05.600 --> 00:17:10.400]   Very interesting because the first adopter of Lightning was Facebook, right?
[00:17:10.400 --> 00:17:13.840]   And that kind of got us enterprise features very quickly.
[00:17:13.840 --> 00:17:16.680]   I mean, I was really annoyed because I was literally trying to do my PhD.
[00:17:16.680 --> 00:17:20.840]   I was like, you know, we have this thing internally called a workplace where people message each
[00:17:20.840 --> 00:17:25.400]   other and I kept getting pinged by like the Facebook team, not at fair, like the actual
[00:17:25.400 --> 00:17:28.400]   people building, you know, all the fun stuff.
[00:17:28.400 --> 00:17:30.000]   And then I didn't check this thing.
[00:17:30.000 --> 00:17:34.600]   Again, I was like, literally, I mean, you know, we've tried to exchange emails.
[00:17:34.600 --> 00:17:37.800]   You know, I'm not the best at emails, right?
[00:17:37.800 --> 00:17:41.760]   So I hadn't checked this thing literally for like four months.
[00:17:41.760 --> 00:17:44.560]   And then my manager came in and was like, dude, you have to check workplace.
[00:17:44.560 --> 00:17:46.320]   I was like, why?
[00:17:46.320 --> 00:17:49.520]   And then it's these Facebook teams being like, hey, we want to use your thing.
[00:17:49.520 --> 00:17:51.680]   I'm like, dude, it's a PhD project.
[00:17:51.680 --> 00:17:52.680]   Why would you want to do that?
[00:17:52.680 --> 00:17:53.680]   Right?
[00:17:53.680 --> 00:17:54.680]   And they're like, no, it's okay.
[00:17:54.680 --> 00:17:55.680]   We'll help you make it better.
[00:17:55.680 --> 00:17:56.680]   I was like, fine.
[00:17:56.680 --> 00:17:59.320]   And so they took it and started working on it.
[00:17:59.320 --> 00:18:03.040]   And you know, we've been super tight with the team since then.
[00:18:03.040 --> 00:18:06.300]   But then it was like crazy because then big companies started using it immediately.
[00:18:06.300 --> 00:18:09.440]   It was like someone would submit a PR and they're like, hey, can you fix this?
[00:18:09.440 --> 00:18:13.560]   I'm like, no, I'm not doing, I don't know, FFT research or whatever you're doing.
[00:18:13.560 --> 00:18:14.560]   I don't want to fix that.
[00:18:14.560 --> 00:18:15.720]   And they're like, but I'm a Bloomberg.
[00:18:15.720 --> 00:18:16.720]   I'm like, that's cool.
[00:18:16.720 --> 00:18:19.680]   All right, I guess I should help you out.
[00:18:19.680 --> 00:18:21.000]   Right.
[00:18:21.000 --> 00:18:23.560]   And so then, you know, as a developer, that's the best thing.
[00:18:23.560 --> 00:18:25.280]   You're like, cool, my stuff's being used for real.
[00:18:25.280 --> 00:18:26.280]   Like that's great.
[00:18:26.280 --> 00:18:30.920]   So I think when I had like hundreds of these, I was like, okay, well, these people are really
[00:18:30.920 --> 00:18:34.200]   struggling with this bigger problem, which is what we just launched.
[00:18:34.200 --> 00:18:35.200]   Right.
[00:18:35.200 --> 00:18:38.080]   So let's go ahead and really solve that problem in a meaningful way.
[00:18:38.080 --> 00:18:42.200]   But, you know, it turned out that you couldn't do it alone and you needed a ton of money
[00:18:42.200 --> 00:18:43.840]   and people and so on.
[00:18:43.840 --> 00:18:46.040]   And so that's how we ended up here.
[00:18:46.040 --> 00:18:47.920]   And I guess what year was that?
[00:18:47.920 --> 00:18:48.920]   Was that 2019?
[00:18:48.920 --> 00:18:52.760]   Yeah, that was summer of 2019.
[00:18:52.760 --> 00:18:54.940]   And then I left Facebook in December of 2019.
[00:18:54.940 --> 00:18:59.580]   So started the company January 2020, two months before COVID, right?
[00:18:59.580 --> 00:19:04.160]   So Lucas, yeah, you built a few companies, you've been successful.
[00:19:04.160 --> 00:19:08.120]   And I'm sure you know how hard it is to build during COVID.
[00:19:08.120 --> 00:19:12.520]   Well, I mean, actually, here we are summer 2022.
[00:19:12.520 --> 00:19:13.880]   How big is your company?
[00:19:13.880 --> 00:19:15.220]   Yeah, good question.
[00:19:15.220 --> 00:19:19.560]   So we're about 60 people now, all over the world.
[00:19:19.560 --> 00:19:25.720]   And yeah, I think we've mostly clustered around New York, San Francisco and London.
[00:19:25.720 --> 00:19:28.160]   And then we have people kind of everywhere else.
[00:19:28.160 --> 00:19:30.440]   I will say one thing that I'm really proud of in the company.
[00:19:30.440 --> 00:19:32.320]   It's again, I'm not from the US.
[00:19:32.320 --> 00:19:33.680]   I'm not from Silicon Valley.
[00:19:33.680 --> 00:19:37.320]   So I think that that's kind of been the DNA of the company now.
[00:19:37.320 --> 00:19:40.320]   Like we have a ton of people from like 20 different countries.
[00:19:40.320 --> 00:19:44.440]   And it's amazing because everyone speaks all these languages and it's pretty cool.
[00:19:44.440 --> 00:19:46.080]   It feels pretty international.
[00:19:46.080 --> 00:19:49.020]   So I think for like a New York startup, this is great.
[00:19:49.020 --> 00:19:50.520]   It's like exactly what you want, right?
[00:19:50.520 --> 00:19:51.520]   That melting pot.
[00:19:51.520 --> 00:19:52.520]   That's awesome.
[00:19:52.520 --> 00:19:58.640]   What has the experience been like to go from kind of like a researcher, seller developer
[00:19:58.640 --> 00:20:03.320]   to like suddenly running like a really significantly large company?
[00:20:03.320 --> 00:20:08.080]   Do you find time to think, to write code on your own still?
[00:20:08.080 --> 00:20:09.080]   Yeah, good question.
[00:20:09.080 --> 00:20:10.080]   Maybe I'll ask you this.
[00:20:10.080 --> 00:20:12.080]   Don't you feel like building a company is kind of like doing research?
[00:20:12.080 --> 00:20:14.320]   There are a lot of parallels, no?
[00:20:14.320 --> 00:20:16.040]   I do think there's some parallels, but you go first.
[00:20:16.040 --> 00:20:18.160]   Tell me what you think the parallels are.
[00:20:18.160 --> 00:20:19.160]   Yeah.
[00:20:19.160 --> 00:20:21.480]   So what are you doing in research?
[00:20:21.480 --> 00:20:26.800]   So you have a hypothesis and you're proven wrong most of the time and you got to just
[00:20:26.800 --> 00:20:31.060]   try something quickly and then move on to the next thing and try ideas, ideas and so
[00:20:31.060 --> 00:20:33.120]   on until you find something that works, right?
[00:20:33.120 --> 00:20:34.920]   And then you dig into it.
[00:20:34.920 --> 00:20:38.640]   That's no different than a company, right?
[00:20:38.640 --> 00:20:42.080]   The difference is you have to do it through people, which is really hard, right?
[00:20:42.080 --> 00:20:45.040]   So it's not just a solo person building.
[00:20:45.040 --> 00:20:46.520]   And I think people forget this, right?
[00:20:46.520 --> 00:20:50.280]   It's like if you want to build anything meaningful, you have to have a team.
[00:20:50.280 --> 00:20:51.280]   You cannot do it alone.
[00:20:51.280 --> 00:20:55.600]   At this point, I have to tell you, like I just said that Lightning took about five years
[00:20:55.600 --> 00:20:57.060]   to go live.
[00:20:57.060 --> 00:21:00.800]   If I had been working with this team, I probably would have been, I could have gotten there
[00:21:00.800 --> 00:21:05.160]   in a year, right, because it's a lot faster when you have really smart people around you
[00:21:05.160 --> 00:21:06.600]   and you're working together.
[00:21:06.600 --> 00:21:10.880]   So I don't love this notion of like the solo, whatever, who did whatever.
[00:21:10.880 --> 00:21:12.280]   That doesn't work, guys.
[00:21:12.280 --> 00:21:13.480]   Like I don't do that, right?
[00:21:13.480 --> 00:21:15.640]   So it's been amazing.
[00:21:15.640 --> 00:21:18.840]   So you have to build a company through people and that's really hard to do, right?
[00:21:18.840 --> 00:21:25.040]   So people management, taking a vision and getting everyone to go towards that same vision
[00:21:25.040 --> 00:21:27.120]   where they don't even know what the output is going to look like.
[00:21:27.120 --> 00:21:30.960]   That's really hard, right, because you're asking 60 people to just dismiss disbelief
[00:21:30.960 --> 00:21:33.320]   and say, you know what, fine, we're going for it.
[00:21:33.320 --> 00:21:35.000]   And when we get there, we'll see what it is, right?
[00:21:35.000 --> 00:21:37.360]   And so you have to trade that off a lot as a leader.
[00:21:37.360 --> 00:21:41.880]   And I think honestly, you know, spending the first six years in the military, you know,
[00:21:41.880 --> 00:21:46.160]   even though I didn't do all the SEAL training that everyone does and then I become a full
[00:21:46.160 --> 00:21:51.280]   SEAL, but the stuff that I did go through, especially leading small teams and training
[00:21:51.280 --> 00:21:54.760]   and at the SEAL team actually did translate really well, right?
[00:21:54.760 --> 00:22:00.280]   It's like, how do you get an aggressive bunch of people to go towards a goal really fast
[00:22:00.280 --> 00:22:04.400]   when you have no information and you have limited resources, right?
[00:22:04.400 --> 00:22:05.400]   It's like perfect.
[00:22:05.400 --> 00:22:06.400]   - That's really cool.
[00:22:06.400 --> 00:22:07.400]   Like tell me more about that.
[00:22:07.400 --> 00:22:08.400]   I'm really curious.
[00:22:08.400 --> 00:22:13.600]   What are some of the sort of things that you learned about leadership in the military that
[00:22:13.600 --> 00:22:16.040]   you applied to running your company?
[00:22:16.040 --> 00:22:20.920]   - Yeah, I mean, like, you know, if you show up to BUD/S as a junior officer, right?
[00:22:20.920 --> 00:22:25.760]   So I was 20 when I started SEAL training, you know, I got put in charge of a 300 person
[00:22:25.760 --> 00:22:27.880]   class, like that's crazy, right?
[00:22:27.880 --> 00:22:31.520]   And so you have to be accountable for everything, all their gear, where they are.
[00:22:31.520 --> 00:22:35.000]   And it's like all 18, 19 year olds, they're all getting in trouble out in town.
[00:22:35.000 --> 00:22:37.240]   They're all doing really silly things, right?
[00:22:37.240 --> 00:22:39.280]   So you're having to deal with a ton of people issues.
[00:22:39.280 --> 00:22:43.040]   And it's, you're like 20, you're like learning on the job, right?
[00:22:43.040 --> 00:22:46.360]   And then you show up to your first SEAL team and then you're like put in charge of a team
[00:22:46.360 --> 00:22:48.320]   and those guys have been there for 30, 40 years.
[00:22:48.320 --> 00:22:50.600]   There's so much better than you in every possible way, right?
[00:22:50.600 --> 00:22:54.720]   So if you show up trying to teach, you feel like, hey, I'm here, I'm like big, bad boss,
[00:22:54.720 --> 00:22:56.800]   I'm gonna do whatever, you're done, right?
[00:22:56.800 --> 00:22:57.800]   That's not how it works.
[00:22:57.800 --> 00:23:01.400]   So I think specifically, I can't speak for the whole military, but I can say in the SEAL
[00:23:01.400 --> 00:23:04.760]   teams and special operations, you're taught to lead from the front, right?
[00:23:04.760 --> 00:23:09.040]   So as an officer, you're supposed to be the fastest runner, the best swimmer, all of that
[00:23:09.040 --> 00:23:11.500]   because you're always leading from the front, right?
[00:23:11.500 --> 00:23:13.640]   And so that, I still carry that here, right?
[00:23:13.640 --> 00:23:18.240]   So that's why I'm not like coding all the time right now, but I do like, do want the
[00:23:18.240 --> 00:23:20.160]   team to be at a specific level, right?
[00:23:20.160 --> 00:23:22.160]   And I can get there because I can push the team.
[00:23:22.160 --> 00:23:23.920]   So I think it's a lot about that.
[00:23:23.920 --> 00:23:27.800]   And it's a mentality that if I'm going through that door, I'm going first, right?
[00:23:27.800 --> 00:23:30.120]   And I'm going to be there first always, right?
[00:23:30.120 --> 00:23:32.320]   And so a lot of those lessons carry over.
[00:23:32.320 --> 00:23:36.640]   So it's, there are a bunch of civilian terms for this, whatever leadership is called, but
[00:23:36.640 --> 00:23:40.120]   that's kind of ingrained in me since I was 20, basically.
[00:23:40.120 --> 00:23:41.840]   That's really interesting.
[00:23:41.840 --> 00:23:49.040]   Do you think there's any really striking differences about managing a company of mostly highly
[00:23:49.040 --> 00:23:52.920]   technical people distributed around the world that you were surprised by that's different
[00:23:52.920 --> 00:23:57.480]   than leading a team of 18 and 19 year olds?
[00:23:57.480 --> 00:23:59.760]   Yeah, I mean, for sure.
[00:23:59.760 --> 00:24:03.720]   So in the military, it's very dictatorial, I guess.
[00:24:03.720 --> 00:24:06.040]   You make a decision and that's it.
[00:24:06.040 --> 00:24:07.440]   There's no question, right?
[00:24:07.440 --> 00:24:09.760]   No one questions or anything like that.
[00:24:09.760 --> 00:24:12.840]   You of course take people's input and everyone has that, but at the end of the day, you say
[00:24:12.840 --> 00:24:14.560]   something and it just happens, right?
[00:24:14.560 --> 00:24:17.180]   And there's no second guessing, whatever.
[00:24:17.180 --> 00:24:21.480]   In the civilian world, oh my God, there's questions and this and that and blah, right?
[00:24:21.480 --> 00:24:24.600]   And so you have to really learn how to live in that world.
[00:24:24.600 --> 00:24:25.920]   So it's fascinating.
[00:24:25.920 --> 00:24:29.520]   I think that the few years that I spent in finance were the best kind of middle ground,
[00:24:29.520 --> 00:24:30.520]   right?
[00:24:30.520 --> 00:24:33.040]   And I actually think a lot of veterans have a hard time adjusting to the civilian world,
[00:24:33.040 --> 00:24:34.380]   probably for this reason, right?
[00:24:34.380 --> 00:24:37.560]   Because the way you do things in the military is just so different.
[00:24:37.560 --> 00:24:39.320]   So you can't approach people that way.
[00:24:39.320 --> 00:24:41.160]   You have to learn day Q, right?
[00:24:41.160 --> 00:24:45.800]   So in finance, it's kind of this hybrid, like super aggressive ground, but you still have
[00:24:45.800 --> 00:24:47.680]   to learn how to talk to people.
[00:24:47.680 --> 00:24:52.640]   And so if any veterans are watching this, I would urge you to go to finance first so
[00:24:52.640 --> 00:24:57.360]   you can learn a soft landing and then go into tech because in tech you're dealing with designers
[00:24:57.360 --> 00:25:00.360]   and creatives and people are very different there.
[00:25:00.360 --> 00:25:02.520]   That's awesome.
[00:25:02.520 --> 00:25:06.120]   Do you think you have any role to play?
[00:25:06.120 --> 00:25:07.120]   This is a total aside.
[00:25:07.120 --> 00:25:10.960]   I'm just curious if you have any thoughts on this, but sometimes I feel like at least
[00:25:10.960 --> 00:25:17.600]   in Silicon Valley, there's often a lot of friction between military and tech working
[00:25:17.600 --> 00:25:18.600]   together.
[00:25:18.600 --> 00:25:19.600]   Do you think about that at all?
[00:25:19.600 --> 00:25:25.440]   Do you hope that there's military applications of lightning and do you think you can play
[00:25:25.440 --> 00:25:28.440]   a translation role or how do you think about that?
[00:25:28.440 --> 00:25:29.440]   Yeah.
[00:25:29.440 --> 00:25:36.680]   I mean, look, I think that specifically I'm in the military, everyone's like autonomous
[00:25:36.680 --> 00:25:38.480]   weapons, blah, right?
[00:25:38.480 --> 00:25:39.480]   That's what everyone jumps to.
[00:25:39.480 --> 00:25:42.080]   And I'm like, yes, that is an extreme use of it for sure.
[00:25:42.080 --> 00:25:43.840]   And that's not a use that I want to support.
[00:25:43.840 --> 00:25:47.800]   I don't think any of us want to support that, especially having been in some situations
[00:25:47.800 --> 00:25:50.880]   where it's pretty clear that you don't want to enable more of that.
[00:25:50.880 --> 00:25:55.960]   But I think what people don't understand is that some of these tools can be used in also
[00:25:55.960 --> 00:25:58.520]   positive ways.
[00:25:58.520 --> 00:26:01.520]   There are ways where you could, for example, I don't know.
[00:26:01.520 --> 00:26:05.640]   I mean, I don't even want to get into it because people are going to judge all the parts.
[00:26:05.640 --> 00:26:10.600]   But there's ways that you can use it still in a good way, translation, right?
[00:26:10.600 --> 00:26:13.960]   You're in the field and you're meeting someone in a new village and you can't speak to them,
[00:26:13.960 --> 00:26:14.960]   right?
[00:26:14.960 --> 00:26:15.960]   How do you do that?
[00:26:15.960 --> 00:26:22.680]   And a lot of what the military has done during the war has been around winning hearts and
[00:26:22.680 --> 00:26:25.720]   minds in Afghanistan and Iraq.
[00:26:25.720 --> 00:26:28.800]   And that's really making those connections with villagers and trying to understand what
[00:26:28.800 --> 00:26:32.480]   happens and trying to rebuild countries and so on.
[00:26:32.480 --> 00:26:35.560]   And I think that a lot of AI could actually facilitate a lot of these things, right?
[00:26:35.560 --> 00:26:36.560]   Casualties.
[00:26:36.560 --> 00:26:38.400]   When you have casualties, you need to call something out.
[00:26:38.400 --> 00:26:39.720]   Maybe the person can't speak, right?
[00:26:39.720 --> 00:26:41.480]   So translating or something.
[00:26:41.480 --> 00:26:44.440]   So there's some great applications of it, but it's like anything.
[00:26:44.440 --> 00:26:48.120]   Like, yes, can the internet be used to find your long lost family?
[00:26:48.120 --> 00:26:49.120]   Of course it can.
[00:26:49.120 --> 00:26:50.560]   But can it be used to traffic people?
[00:26:50.560 --> 00:26:51.560]   Yes, it can.
[00:26:51.560 --> 00:26:52.560]   So what are you going to do?
[00:26:52.560 --> 00:26:53.560]   Shut it down?
[00:26:53.560 --> 00:26:54.560]   You know, like it's hard.
[00:26:54.560 --> 00:26:55.560]   There's not a simple answer, right?
[00:26:55.560 --> 00:26:56.560]   All right.
[00:26:56.560 --> 00:26:59.320]   So tell me about the new Lightning website.
[00:26:59.320 --> 00:27:01.080]   What's the best way to talk about it?
[00:27:01.080 --> 00:27:03.440]   Lightning, the operating system.
[00:27:03.440 --> 00:27:07.640]   I'm curious to know how you conceived of it and how you built it.
[00:27:07.640 --> 00:27:11.920]   It's such an impressive launch with some very impressive demos.
[00:27:11.920 --> 00:27:14.200]   I'd love to know about the process and your vision here.
[00:27:14.200 --> 00:27:15.200]   Yeah, for sure.
[00:27:15.200 --> 00:27:20.160]   So if you go to lightning.ai today, you're going to see the new homepage for the Lightning
[00:27:20.160 --> 00:27:21.320]   community, right?
[00:27:21.320 --> 00:27:25.120]   So I think the first thing to note is, you know, PyTorch Lightning has grown.
[00:27:25.120 --> 00:27:27.400]   The project is no longer called PyTorch Lightning.
[00:27:27.400 --> 00:27:28.720]   It's called Lightning now, right?
[00:27:28.720 --> 00:27:33.160]   Because when it was just PyTorch Lightning, it let you do one thing, which is build models.
[00:27:33.160 --> 00:27:36.800]   So that's cool, except that when you build that model, there's a ton of other stuff you
[00:27:36.800 --> 00:27:38.000]   have to do around it.
[00:27:38.000 --> 00:27:41.280]   You need to, you know, wrangle data and you have feature stores.
[00:27:41.280 --> 00:27:43.100]   You need to manage experiments, right?
[00:27:43.100 --> 00:27:46.320]   You need to do a lot of the stuff that you guys are doing, analyze it, understand what's
[00:27:46.320 --> 00:27:47.320]   going on.
[00:27:47.320 --> 00:27:52.960]   So what we are now enabling the framework to do, so the framework is now Lightning, it
[00:27:52.960 --> 00:27:54.480]   enables you to build models.
[00:27:54.480 --> 00:27:56.000]   Still, you can do that.
[00:27:56.000 --> 00:28:00.360]   But now when you want to build research workflows or production pipelines, you can now do that
[00:28:00.360 --> 00:28:03.680]   within the framework as well in the Lightning way, right?
[00:28:03.680 --> 00:28:08.160]   And what we really want to do is allow people to connect, to stitch together the best tools
[00:28:08.160 --> 00:28:09.160]   in class.
[00:28:09.160 --> 00:28:13.280]   So we're really thinking about it as like kind of the glue for machine learning, right?
[00:28:13.280 --> 00:28:17.360]   So if I want to use Weights and Biases, Feature X with this other thing, I should be able
[00:28:17.360 --> 00:28:18.360]   to, right?
[00:28:18.360 --> 00:28:21.480]   And what we, so really, I think you should think about us like Apple.
[00:28:21.480 --> 00:28:24.720]   Like we're really introducing kind of the iPhone equivalents, right?
[00:28:24.720 --> 00:28:26.760]   So that people can build apps on there.
[00:28:26.760 --> 00:28:29.240]   So they can build their own apps and publish them.
[00:28:29.240 --> 00:28:31.280]   But these apps are extremely complex workflows, right?
[00:28:31.280 --> 00:28:32.920]   They're not just demos or something like that.
[00:28:32.920 --> 00:28:38.360]   These are actual end-to-end production workflows or research workflows that can run in distributed
[00:28:38.360 --> 00:28:39.720]   cloud environments, right?
[00:28:39.720 --> 00:28:41.940]   But they stitch together the best in class tools.
[00:28:41.940 --> 00:28:45.760]   So Lightning AI today is really the page for where these apps get published.
[00:28:45.760 --> 00:28:49.080]   So if you're trying to start a new machine learning project, you can go there, find something
[00:28:49.080 --> 00:28:52.600]   similar to what you're working on, run it on your infrastructure very quickly within
[00:28:52.600 --> 00:28:55.800]   minutes and then change the code and off you go, right?
[00:28:55.800 --> 00:28:58.480]   And so I think some of the things that I'm super excited about, and you and I have chatted
[00:28:58.480 --> 00:29:02.160]   about a lot about this is what are some of those integrations we can do with partners,
[00:29:02.160 --> 00:29:03.160]   right?
[00:29:03.160 --> 00:29:05.440]   And so what are some of the great tools that we can enable, for example, from Weights and
[00:29:05.440 --> 00:29:09.240]   Biases there so that people can embed into their apps in really cool ways that probably
[00:29:09.240 --> 00:29:11.000]   are not possible today, right?
[00:29:11.000 --> 00:29:12.240]   And so it's really around that.
[00:29:12.240 --> 00:29:16.600]   I think I'd like to partner with every single framework and every single tool out there
[00:29:16.600 --> 00:29:20.720]   to help them shine and really provide the best capabilities of what they have for the
[00:29:20.720 --> 00:29:21.720]   community, right?
[00:29:21.720 --> 00:29:24.160]   So I think that's what we're shooting for.
[00:29:24.160 --> 00:29:26.960]   And I guess, how long has this been in the works?
[00:29:26.960 --> 00:29:33.720]   I mean, it seems like a pretty different vision, as I understand it, than PyTorch Lightning
[00:29:33.720 --> 00:29:35.400]   when it first came out.
[00:29:35.400 --> 00:29:37.840]   How did you come to it?
[00:29:37.840 --> 00:29:40.400]   Was this always on your mind ever since you started the company?
[00:29:40.400 --> 00:29:41.600]   Yeah, for sure.
[00:29:41.600 --> 00:29:45.160]   So that was definitely a vision from day one.
[00:29:45.160 --> 00:29:48.520]   It's really hard to build up front, so you really have to do the work for it.
[00:29:48.520 --> 00:29:55.880]   But that's how PyTorch Lightning had already started to do a lot of this.
[00:29:55.880 --> 00:29:57.680]   We were some of the first early partners there, right?
[00:29:57.680 --> 00:30:04.200]   So when PyTorch Lightning first launched, we have to go back to 2019, I don't know,
[00:30:04.200 --> 00:30:05.920]   May, June, whatever it was.
[00:30:05.920 --> 00:30:10.720]   You had frameworks that were running, and if you wanted to watch your experiments or
[00:30:10.720 --> 00:30:12.720]   something, it was really hard to do, right?
[00:30:12.720 --> 00:30:14.520]   You had to integrate something.
[00:30:14.520 --> 00:30:15.920]   And so you had TensorBoard.
[00:30:15.920 --> 00:30:19.160]   I think you guys were probably live by then, I assume.
[00:30:19.160 --> 00:30:22.120]   And it was like no one knew about these things because they weren't there, right?
[00:30:22.120 --> 00:30:23.640]   They weren't easy to use.
[00:30:23.640 --> 00:30:27.440]   And so one of the first things we did was I personally use TensorBoard, right?
[00:30:27.440 --> 00:30:29.000]   So I used it back then.
[00:30:29.000 --> 00:30:30.000]   And I was like, "Hey, you know what?
[00:30:30.000 --> 00:30:31.280]   I don't want to start it up myself.
[00:30:31.280 --> 00:30:33.000]   Let me just let this thing do it."
[00:30:33.000 --> 00:30:35.680]   And so we started integrating that in there.
[00:30:35.680 --> 00:30:39.320]   And then very quickly, your users started coming by and saying, "Hey, can we add weights
[00:30:39.320 --> 00:30:40.800]   and biases and so on?"
[00:30:40.800 --> 00:30:45.080]   And then we kind of came up with these abstractions, and then suddenly people could use it implicitly.
[00:30:45.080 --> 00:30:46.200]   And that was amazing, right?
[00:30:46.200 --> 00:30:48.060]   Because it started to stitch together tools.
[00:30:48.060 --> 00:30:50.280]   So that vision started back then already, right?
[00:30:50.280 --> 00:30:52.060]   And then if you look at the accelerators, right?
[00:30:52.060 --> 00:30:56.280]   So we wrote this API called Accelerate, which lets you train on different hardware.
[00:30:56.280 --> 00:30:58.680]   This is back summer 2020.
[00:30:58.680 --> 00:31:00.960]   And it powers all of Lightning, but that's what it is, right?
[00:31:00.960 --> 00:31:03.960]   It allows you to go between CPUs and GPUs and TPUs.
[00:31:03.960 --> 00:31:06.840]   And I think we were the first framework to actually let you do that seamlessly, right?
[00:31:06.840 --> 00:31:11.680]   So PyTorch supported XLA for TPUs and supported GPUs, but you have to rewrite your code over
[00:31:11.680 --> 00:31:12.840]   and over again, right?
[00:31:12.840 --> 00:31:16.920]   So we introduced for the first time the ability to go between GPU and TPU just like that,
[00:31:16.920 --> 00:31:17.920]   right?
[00:31:17.920 --> 00:31:18.920]   And that really changed the game.
[00:31:18.920 --> 00:31:20.960]   And that's been amazing because that was an integration.
[00:31:20.960 --> 00:31:23.800]   So it started to become a platform back then, right?
[00:31:23.800 --> 00:31:27.520]   And so kind of for me was, okay, how can we do more of this?
[00:31:27.520 --> 00:31:31.680]   Except that in the model, you're very limited to just these kinds of things, right?
[00:31:31.680 --> 00:31:34.920]   But when you start talking about feature stores and deployments and all that stuff, you need
[00:31:34.920 --> 00:31:36.800]   something a little bit higher level.
[00:31:36.800 --> 00:31:40.840]   And again, I'm lazy and I hate learning new things.
[00:31:40.840 --> 00:31:44.680]   So I was like, okay, how do we make it just as easy as Lightning so that if you know PyTorch
[00:31:44.680 --> 00:31:46.720]   Lightning, you already know how to build production systems.
[00:31:46.720 --> 00:31:48.960]   And so that's kind of what we released.
[00:31:48.960 --> 00:31:51.800]   And the hard part was getting it to exactly be like Lightning.
[00:31:51.800 --> 00:31:52.800]   What is that DNA?
[00:31:52.800 --> 00:31:54.480]   How does the user experience feel like?
[00:31:54.480 --> 00:31:59.200]   I'm curious how you think about product development and customer feedback.
[00:31:59.200 --> 00:32:04.560]   It felt like you kind of created a lot from your own vision.
[00:32:04.560 --> 00:32:10.160]   How much of what you do is sort of informed by your gut and how much of it is coming from
[00:32:10.160 --> 00:32:15.280]   a user saying like, "Hey, XYZ, could you make something that does this or this or this?"
[00:32:15.280 --> 00:32:17.800]   How do you think, what's your product development process look like?
[00:32:17.800 --> 00:32:23.360]   Yeah, so I think I'm probably the worst person to ask this because I don't care what anyone's
[00:32:23.360 --> 00:32:24.360]   doing.
[00:32:24.360 --> 00:32:25.360]   I legitimately don't.
[00:32:25.360 --> 00:32:26.360]   I don't look at what people are doing.
[00:32:26.360 --> 00:32:27.360]   I don't care, right?
[00:32:27.360 --> 00:32:30.080]   We're going to do what we're going to do and we're going to do things that I think are
[00:32:30.080 --> 00:32:31.080]   interesting.
[00:32:31.080 --> 00:32:35.400]   And so we're going to basically form a thesis around something that we want to do and we'll
[00:32:35.400 --> 00:32:38.620]   see the behavior of the users, of course, right?
[00:32:38.620 --> 00:32:41.920]   But if you only talk to users, we speak to users all the time, by the way, right?
[00:32:41.920 --> 00:32:42.920]   So it's not about that.
[00:32:42.920 --> 00:32:43.920]   We take their feedback in.
[00:32:44.040 --> 00:32:47.040]   But users are always going to tell you kind of incremental things.
[00:32:47.040 --> 00:32:48.840]   They're always going to tell you they want this better.
[00:32:48.840 --> 00:32:50.680]   They're never going to tell you they want the iPhone.
[00:32:50.680 --> 00:32:53.680]   They're always going to tell you, "Can you make my BlackBerry keyboard slide out instead?"
[00:32:53.680 --> 00:32:54.840]   or whatever, right?
[00:32:54.840 --> 00:32:59.040]   So you have to have just a different mentality there where you take things with a grain of
[00:32:59.040 --> 00:33:03.240]   salt and you do take their inputs, but it's really, those inputs are going to usually
[00:33:03.240 --> 00:33:09.160]   improve the product, but they're not going to help you create like a leapfrog product,
[00:33:09.160 --> 00:33:10.160]   right?
[00:33:10.160 --> 00:33:13.080]   And so that's really where, again, I just don't care what people are working on.
[00:33:13.080 --> 00:33:16.440]   I'm just going to do what I think should be done for machine learning and that's what
[00:33:16.440 --> 00:33:17.920]   we build next, right?
[00:33:17.920 --> 00:33:21.240]   And sometimes we're wrong and sometimes we're right, right?
[00:33:21.240 --> 00:33:26.160]   Do you think it's important to hire people with a machine learning background to do the
[00:33:26.160 --> 00:33:30.840]   kind of work that you do or do you look for people with kind of more like an operational
[00:33:30.840 --> 00:33:34.280]   or like engineering or database background?
[00:33:34.280 --> 00:33:40.980]   So I guess first and foremost, I care that people are creative, driven and interesting
[00:33:40.980 --> 00:33:41.980]   in some way.
[00:33:41.980 --> 00:33:45.400]   I think they just have interests and they're like not just the same kind of cookie cutter
[00:33:45.400 --> 00:33:46.400]   persona.
[00:33:46.400 --> 00:33:48.120]   So that's the first thing, right?
[00:33:48.120 --> 00:33:52.480]   Then after that, yes, I want you to be good at your thing, whatever your thing is, right?
[00:33:52.480 --> 00:33:55.720]   Now specifically in machine learning, like, yeah, it's nice to have, please, by all means,
[00:33:55.720 --> 00:33:57.200]   I hope you know what you're doing with it.
[00:33:57.200 --> 00:34:00.920]   If you're on the lightning team, you will 1000% need to know and every single person
[00:34:00.920 --> 00:34:04.880]   on the lighting team has a PhD or came out of a PhD program, so they're all experts in
[00:34:04.880 --> 00:34:08.800]   this stuff, but everyone else who's around that, I just want you to be really good at
[00:34:08.800 --> 00:34:09.800]   your thing.
[00:34:09.800 --> 00:34:10.800]   And I don't care how you got that knowledge, right?
[00:34:10.800 --> 00:34:11.800]   I don't care.
[00:34:11.800 --> 00:34:15.720]   I remember I didn't go, well, I eventually went to fancy schools, but for like most of
[00:34:15.720 --> 00:34:17.320]   my life I hadn't, right?
[00:34:17.320 --> 00:34:20.600]   And so I didn't really care about that.
[00:34:20.600 --> 00:34:23.960]   So yeah, I think machine learning is not necessarily a deal breaker.
[00:34:23.960 --> 00:34:26.360]   It just depends on your particular role, right?
[00:34:26.360 --> 00:34:27.360]   Now I could be wrong.
[00:34:27.360 --> 00:34:30.560]   How does the lightning team fit into the broader company team?
[00:34:30.560 --> 00:34:32.360]   What's the distinction there?
[00:34:32.360 --> 00:34:34.920]   Yeah, so the lighting team works on all the open source stuff.
[00:34:34.920 --> 00:34:37.320]   And then we have people who work on all the closed source stuff, right?
[00:34:37.320 --> 00:34:42.400]   So when you run lightning apps on your own, you're using all the free stuff.
[00:34:42.400 --> 00:34:46.080]   When you run it on the cloud, that's when you use some private proprietary stuff, right?
[00:34:46.080 --> 00:34:49.800]   So you can take a lightning app, you fork the code, even models and all that stuff,
[00:34:49.800 --> 00:34:50.880]   you run them locally.
[00:34:50.880 --> 00:34:54.080]   But if you want to run them in the cloud, you say dash dash cloud, and then that stuff
[00:34:54.080 --> 00:34:58.760]   is now being done, being built by the other people who are not lighting teams people,
[00:34:58.760 --> 00:34:59.760]   right?
[00:34:59.760 --> 00:35:03.280]   And these people are infrastructure people, they're database people, they're from all
[00:35:03.280 --> 00:35:05.520]   sorts of walks of life, I guess.
[00:35:05.520 --> 00:35:09.800]   And I think that diversity is always better in this world, because there's just a lot
[00:35:09.800 --> 00:35:10.800]   of unknowns.
[00:35:10.800 --> 00:35:16.080]   And I know, you know, both know this, that ML is evolving, we just don't know what's
[00:35:16.080 --> 00:35:17.480]   going to need to be built next, right?
[00:35:17.480 --> 00:35:20.640]   So we kind of have to have a research hats on a little bit.
[00:35:20.640 --> 00:35:27.480]   Are there like top of mind applications that you hope get built on your lightning platform
[00:35:27.480 --> 00:35:28.480]   right away?
[00:35:28.480 --> 00:35:30.800]   What are the next things that you're excited about?
[00:35:31.200 --> 00:35:35.920]   Yeah, so I think, I mean, top of mind right now is a few of these key partners that we've
[00:35:35.920 --> 00:35:41.040]   been working with for a long time, like you guys, where we want to make the tools just
[00:35:41.040 --> 00:35:45.880]   more widely adopted and bring more visibility to them and have the ability for people to
[00:35:45.880 --> 00:35:47.080]   mix and match and more, right?
[00:35:47.080 --> 00:35:48.960]   So it's really about these immediate partners.
[00:35:48.960 --> 00:35:53.360]   Some of these include cloud providers, some of these include, like the hardware makers
[00:35:53.360 --> 00:35:56.360]   and so on, it's people that we've had really good relationships for a long time.
[00:35:56.360 --> 00:35:59.560]   So it's about enabling those tools to work first, right?
[00:35:59.560 --> 00:36:04.000]   In terms of capabilities, I do think that we do want to make sure that people have a
[00:36:04.000 --> 00:36:08.360]   really good way to, I don't know, to do inferencing, for example, right?
[00:36:08.360 --> 00:36:12.400]   So we're partnering with the cloud providers to do that, like SageMaker team and so on.
[00:36:12.400 --> 00:36:16.240]   And then I think for people who want to do anything with data, right?
[00:36:16.240 --> 00:36:21.200]   So love to partner with like the snowflakes and the data bricks of the world to enable
[00:36:21.200 --> 00:36:22.880]   these things as well.
[00:36:22.880 --> 00:36:26.480]   And then there's all the labeling things that people are starting to do as well, right?
[00:36:26.480 --> 00:36:30.120]   So I don't know if you guys are doing anything there, but obviously, you know, happy to partner
[00:36:30.120 --> 00:36:31.520]   in any of these.
[00:36:31.520 --> 00:36:36.240]   But yeah, I think it's those things that are immediately around the model development part,
[00:36:36.240 --> 00:36:37.240]   right?
[00:36:37.240 --> 00:36:41.160]   There's a lot more that we can do, but we're really want to focus on this part first.
[00:36:41.160 --> 00:36:46.240]   Would you ever work with frameworks that aren't PyTorch, like do like a scikit integration
[00:36:46.240 --> 00:36:48.640]   or XGBoost or anything like that?
[00:36:48.640 --> 00:36:49.640]   Is that within scope?
[00:36:49.640 --> 00:36:50.720]   Yeah, for sure.
[00:36:50.720 --> 00:36:53.320]   I mean, people, it's crazy.
[00:36:53.320 --> 00:36:57.080]   People use Lightning for all sorts of stuff, but people have actually ran SQL in Lightning.
[00:36:57.080 --> 00:36:59.240]   I don't even know how they did that.
[00:36:59.240 --> 00:37:03.320]   But I was like, how are you doing this?
[00:37:03.320 --> 00:37:05.640]   So yeah, honestly, I love to integrate all the frameworks.
[00:37:05.640 --> 00:37:10.680]   Like, you know, I'm long PyTorch in general, but I don't have anything against TensorFlow
[00:37:10.680 --> 00:37:12.840]   and JAX and Keras or any of these things.
[00:37:12.840 --> 00:37:13.840]   Right.
[00:37:13.840 --> 00:37:17.360]   So I think any partnerships there, we're happy to obviously work with and enable the tools
[00:37:17.360 --> 00:37:18.360]   as well.
[00:37:18.360 --> 00:37:23.800]   And I think that we really evolved from where we were before to a point where we're saying,
[00:37:23.800 --> 00:37:28.560]   okay, now that we're able to support a lot more than we could, and before it's just a
[00:37:28.560 --> 00:37:30.280]   function of having bandwidth, right?
[00:37:30.280 --> 00:37:32.560]   Now we can support a lot more than we could.
[00:37:32.560 --> 00:37:33.560]   We want to do that, right?
[00:37:33.560 --> 00:37:35.120]   And make sure we welcome these partners as well.
[00:37:35.120 --> 00:37:38.160]   So yeah, we're happy to work with any framework.
[00:37:38.160 --> 00:37:43.880]   I'm just curious, why are you long PyTorch over the long term?
[00:37:43.880 --> 00:37:50.000]   I think that a lot of these frameworks have converged in functionality, I guess.
[00:37:50.000 --> 00:37:54.360]   I haven't gone back and used TensorFlow, and I think it's probably changed quite a bit.
[00:37:54.360 --> 00:37:57.440]   You know, we just done so much work already in PyTorch that I think we're just excited
[00:37:57.440 --> 00:37:59.600]   to continue improving that user experience.
[00:37:59.600 --> 00:38:03.880]   I think if Google wanted to partner with these other ones, we'd be happy to do that as well.
[00:38:03.880 --> 00:38:06.640]   But I kind of believe that you can't really do everything well.
[00:38:06.640 --> 00:38:11.040]   And so it's a function of having focus as well as a company.
[00:38:11.040 --> 00:38:15.680]   And anything in particular in PyTorch, I think it's really become the standard for research
[00:38:15.680 --> 00:38:19.260]   and also production nowadays.
[00:38:19.260 --> 00:38:23.160]   And yeah, I firmly believe that that team has done a really good job at continuing to
[00:38:23.160 --> 00:38:24.160]   push the boundaries.
[00:38:24.160 --> 00:38:30.320]   So I think that the energy, the way that the team thinks about things and how it's approached,
[00:38:30.320 --> 00:38:34.600]   even doing production workloads and inference, it's just very unique and different.
[00:38:34.600 --> 00:38:37.720]   And I don't know, I like unique and different thinking, I guess.
[00:38:37.720 --> 00:38:39.560]   So I gravitate towards that.
[00:38:39.560 --> 00:38:46.320]   I guess one of the things that I struggle with as we scale our company and our team,
[00:38:46.320 --> 00:38:52.040]   you know, we hire all these like really creative, smart people that have, you know, slightly
[00:38:52.040 --> 00:38:56.960]   different points of view and vision and stuff and like kind of keeping things aligned and
[00:38:56.960 --> 00:39:01.720]   keeping consistency always feels like, you know, like a lot of work to me.
[00:39:01.720 --> 00:39:06.160]   I'm curious how you've dealt with that, if that's been an issue for you as you scaled
[00:39:06.160 --> 00:39:07.960]   up to 60 people.
[00:39:07.960 --> 00:39:14.000]   Yeah, I think, you know, I think you always want to take everyone's inputs into account,
[00:39:14.000 --> 00:39:16.800]   but you also want to be opinionated and that's the difference, right?
[00:39:16.800 --> 00:39:22.240]   And I think that when everyone just says whatever and then they'll do whatever they want, then
[00:39:22.240 --> 00:39:25.080]   you end up with something that isn't really cohesive, right?
[00:39:25.080 --> 00:39:30.040]   And so to some extent, you got to be a little of the bad guy and just say, hey, you know
[00:39:30.040 --> 00:39:31.040]   what?
[00:39:31.040 --> 00:39:32.040]   Cool, I get it.
[00:39:32.040 --> 00:39:33.040]   But like, we're going to go this way, right?
[00:39:33.040 --> 00:39:35.120]   And that's just the way it is.
[00:39:35.120 --> 00:39:37.080]   And it's a lot of these micro decisions that get made.
[00:39:37.080 --> 00:39:38.080]   It's not just me, right?
[00:39:38.080 --> 00:39:40.680]   It's people on the team where I encourage them to be opinionated.
[00:39:40.680 --> 00:39:43.680]   And so, you know, it's kind of the same philosophy that we have for lightning.
[00:39:43.680 --> 00:39:45.560]   It's like, cool, you don't like subclassing things.
[00:39:45.560 --> 00:39:46.560]   Cool.
[00:39:46.560 --> 00:39:47.560]   Sounds good.
[00:39:47.560 --> 00:39:48.560]   Go use something else.
[00:39:48.560 --> 00:39:49.560]   We don't care, right?
[00:39:49.560 --> 00:39:51.040]   This is the way that we think it should be built and that's fine.
[00:39:51.040 --> 00:39:54.440]   Well, look, we always end with two questions.
[00:39:54.440 --> 00:39:56.320]   I want to make sure we get to them.
[00:39:56.320 --> 00:40:03.320]   So the second to last question is if you had a little more time on your hands or I guess,
[00:40:03.320 --> 00:40:09.000]   you know, if you had time to work on something else in ML research broadly, what would it
[00:40:09.000 --> 00:40:10.000]   be?
[00:40:10.000 --> 00:40:11.000]   Yeah.
[00:40:11.000 --> 00:40:16.320]   So if I were back to doing just research right now, I'm pretty sure I would have continued
[00:40:16.320 --> 00:40:17.880]   on the self-supervised learning routes.
[00:40:17.880 --> 00:40:20.200]   I still track that work.
[00:40:20.200 --> 00:40:24.880]   I believe that, you know, we published a paper about this like a year ago.
[00:40:24.880 --> 00:40:26.400]   So I'm going to talk about that.
[00:40:26.400 --> 00:40:31.680]   But I believe that a lot of the things that have been pushed into self-supervised learning,
[00:40:31.680 --> 00:40:36.360]   a lot of those advancements are actually not necessarily being driven by the methods, you
[00:40:36.360 --> 00:40:38.960]   know, like negative sample this versus that.
[00:40:38.960 --> 00:40:41.840]   I think it's actually being driven by the transforms.
[00:40:41.840 --> 00:40:45.480]   And so the paper that we published a while back, I would have continued on this line
[00:40:45.480 --> 00:40:47.480]   is my answer, I guess.
[00:40:47.480 --> 00:40:51.360]   The paper that we published a while back showed that we could achieve very similar performance
[00:40:51.360 --> 00:40:55.320]   to like SimClear using a plain VAE without any of the fancy tricks.
[00:40:55.320 --> 00:41:00.120]   And actually we removed one of the terms of the elbow loss.
[00:41:00.120 --> 00:41:04.600]   And why we could do that is because we took the SimClear transforms and used them, right?
[00:41:04.600 --> 00:41:08.640]   But then the way that we generated the negative samples was using the transforms and then
[00:41:08.640 --> 00:41:10.600]   you reconstruct the original, right?
[00:41:10.600 --> 00:41:13.240]   And so that actually created a really good learning signal.
[00:41:13.240 --> 00:41:18.920]   And what that showed me and showed our group as well was that, you know, it's not about
[00:41:18.920 --> 00:41:24.080]   the fancy negative sampling algorithm and whatever thing you're doing with, I don't
[00:41:24.080 --> 00:41:27.160]   know, information theory, whatever thing you're coming up with.
[00:41:27.160 --> 00:41:31.000]   It's that I think that we're just embedding most of these things into the transforms and
[00:41:31.000 --> 00:41:34.400]   the transforms are actually pulling the weight, which actually is kind of in line with what
[00:41:34.400 --> 00:41:35.940]   the data scientists have been saying forever.
[00:41:35.940 --> 00:41:37.120]   It's about the data, right?
[00:41:37.120 --> 00:41:38.120]   It is about the data.
[00:41:38.120 --> 00:41:42.400]   So it turns out that we've just pushed all that knowledge into transforms now for images
[00:41:42.400 --> 00:41:43.720]   specifically.
[00:41:43.720 --> 00:41:48.660]   And so I'm a little bit sad about that, but at a minimum, I think like I would probably
[00:41:48.660 --> 00:41:53.680]   continue down that route exploring how can I reduce the complexity of these algorithms?
[00:41:53.680 --> 00:41:58.400]   I don't want these tricks, I don't want these like weird learning rate schedulers and all
[00:41:58.400 --> 00:41:59.400]   this stuff.
[00:41:59.400 --> 00:42:04.800]   I want the super simple like PAE loss or something super basic that I know why it works and I
[00:42:04.800 --> 00:42:06.920]   can pinpoint exactly why it's doing what it's doing.
[00:42:06.920 --> 00:42:10.880]   And I think self-supervised learning has kind of lost its way in that most of these papers
[00:42:10.880 --> 00:42:14.400]   are like brand new paper that does this and it's like, oh, they changed this one tiny
[00:42:14.400 --> 00:42:16.960]   term and it's like, come on guys.
[00:42:16.960 --> 00:42:17.960]   Interesting.
[00:42:17.960 --> 00:42:24.160]   Well, my last question is when you look at people that are trying to make machine learning
[00:42:24.160 --> 00:42:30.200]   work for real stuff, like companies like Facebook or Bloomberg or anyone, and they're kind of
[00:42:30.200 --> 00:42:33.880]   going from like, here's an idea of something we want to apply machine learning to, to like
[00:42:33.880 --> 00:42:36.200]   deployed and working in production.
[00:42:36.200 --> 00:42:41.280]   Where do you see the biggest bottleneck right now in summer 2022?
[00:42:41.280 --> 00:42:45.320]   You know, it's like that meme where it's like expectation and reality.
[00:42:45.320 --> 00:42:47.320]   I think that's what we see all the time.
[00:42:47.320 --> 00:42:48.320]   Yeah.
[00:42:48.320 --> 00:42:49.320]   Why though?
[00:42:49.320 --> 00:42:50.320]   Yeah.
[00:42:50.320 --> 00:42:51.320]   Yeah.
[00:42:51.320 --> 00:42:56.520]   You know, I think there's a lot of like, it's just unknown.
[00:42:56.520 --> 00:43:01.480]   Like the thing is so new that you stress tested in a production system and things break and
[00:43:01.480 --> 00:43:04.120]   you're like, ah, my chatbot's racist or something.
[00:43:04.120 --> 00:43:06.640]   You're like, yeah, well no one's deployed a chatbot before.
[00:43:06.640 --> 00:43:08.120]   So of course you're going to learn that lesson.
[00:43:08.120 --> 00:43:09.120]   Right.
[00:43:09.120 --> 00:43:12.040]   So there's a lot of new unknowns that we're discovering.
[00:43:12.040 --> 00:43:16.440]   But I think a lot of it is the explosion of tooling that's out there and the lack of a
[00:43:16.440 --> 00:43:18.760]   standard on how to use that tooling together.
[00:43:18.760 --> 00:43:19.760]   Right.
[00:43:19.760 --> 00:43:22.320]   So I think that's a lot of what's holding us back today.
[00:43:22.320 --> 00:43:24.760]   You know, I think there are many ways to solve that problem.
[00:43:24.760 --> 00:43:29.880]   I think that we're obviously taking a stab at that with the things that we've just introduced.
[00:43:29.880 --> 00:43:33.280]   And so I honestly think that's a big part of it.
[00:43:33.280 --> 00:43:36.240]   Now I believe that that's only a part of it.
[00:43:36.240 --> 00:43:42.600]   I think that the other ones are yeah, this fragmentation, like, you know, you, everyone
[00:43:42.600 --> 00:43:45.960]   wants you to go from this to that, to that, to that, and then use this on next thing.
[00:43:45.960 --> 00:43:48.680]   And then with this thing and that, and it's just like, ah, right.
[00:43:48.680 --> 00:43:52.800]   Like if we just have a standard and everyone works together, we can actually do well.
[00:43:52.800 --> 00:43:58.120]   I honestly think there's like a super unhealthy, like weird competitive thing in ML.
[00:43:58.120 --> 00:43:59.760]   Like guys, this is a massive market.
[00:43:59.760 --> 00:44:01.760]   There's a ton of people who are going to pay for this thing.
[00:44:01.760 --> 00:44:03.800]   Like it's not about one or the other tool.
[00:44:03.800 --> 00:44:05.120]   Everyone's using all the tools together.
[00:44:05.120 --> 00:44:06.120]   Right.
[00:44:06.120 --> 00:44:10.080]   And so, so this unhealthy competition thing, it's actually causing a lot of these problems.
[00:44:10.080 --> 00:44:11.080]   Right.
[00:44:11.080 --> 00:44:15.040]   I think actually the community worked together more and we had better communication and collaboration
[00:44:15.040 --> 00:44:20.680]   between frameworks and between open source projects and, and, and, you know, tools like
[00:44:20.680 --> 00:44:24.800]   you guys, then, then things would be a lot easier because we'd be speaking to each other
[00:44:24.800 --> 00:44:29.480]   and then some, some random engineer sitting in like Facebook doesn't have to waste six
[00:44:29.480 --> 00:44:32.880]   months being like, man, if they just did this one thing, it could have been so much easier.
[00:44:32.880 --> 00:44:33.880]   Right.
[00:44:33.880 --> 00:44:34.880]   Awesome.
[00:44:34.880 --> 00:44:41.080]   Well, I hope we can find some ways to work together.
[00:44:41.080 --> 00:44:42.080]   Just think of that one.
[00:44:42.080 --> 00:44:45.160]   Think of that person, just be like, I will get you your career back.
[00:44:45.160 --> 00:44:46.160]   Don't worry.
[00:44:46.160 --> 00:44:47.160]   Right.
[00:44:47.160 --> 00:44:48.160]   That's the goal.
[00:44:48.160 --> 00:44:49.160]   All right.
[00:44:49.160 --> 00:44:50.160]   If you're listening, we're, we're rooting for you.
[00:44:50.160 --> 00:44:51.160]   We'll make it work for you.
[00:44:51.160 --> 00:44:52.160]   All right.
[00:44:52.160 --> 00:44:53.160]   Thanks Will.
[00:44:53.160 --> 00:44:54.160]   Real pleasure.
[00:44:54.160 --> 00:44:55.160]   Yeah.
[00:44:55.160 --> 00:44:56.160]   Thanks for having me.
[00:44:56.160 --> 00:44:57.160]   This is super fun.
[00:44:57.160 --> 00:44:58.840]   And by the way, I'm a big fan of everything you guys are doing.
[00:44:58.840 --> 00:45:02.600]   So I appreciate everything you've done for, for the ML community as well.
[00:45:02.600 --> 00:45:03.600]   Awesome.
[00:45:03.600 --> 00:45:04.600]   Likewise.
[00:45:04.600 --> 00:45:08.640]   If you're enjoying these interviews and you want to learn more, please click on the link
[00:45:08.640 --> 00:45:13.360]   to the show notes in the description where you can find links to all the papers that
[00:45:13.360 --> 00:45:17.760]   are mentioned, supplemental material, and a transcription that we work really hard to
[00:45:17.760 --> 00:45:18.760]   produce.
[00:45:18.760 --> 00:45:18.760]   So check it out.
[00:45:18.760 --> 00:45:19.040]   out.
[00:45:19.040 --> 00:45:20.900]   (upbeat music)

