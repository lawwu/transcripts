
[00:00:00.480 --> 00:00:07.440]   So, Byung-Chul Han is the most popular philosopher that you probably have never heard of, but
[00:00:07.440 --> 00:00:10.020]   I hope to change that in our conversation today.
[00:00:10.020 --> 00:00:15.220]   Han, who is 66, was born in South Korea, but was trained in Germany and eventually became
[00:00:15.220 --> 00:00:16.660]   a philosophy professor in Germany.
[00:00:16.660 --> 00:00:19.880]   He's currently holding a post at the Berlin University of the Arts.
[00:00:19.880 --> 00:00:27.800]   In a New Yorker profile that came out earlier this year, he was named the Internet's New
[00:00:27.800 --> 00:00:29.560]   Favorite Philosopher.
[00:00:29.560 --> 00:00:31.460]   Now, why is this?
[00:00:31.460 --> 00:00:34.120]   He's been writing a series of these thin monographs.
[00:00:34.120 --> 00:00:37.760]   I have one right here for those who are watching instead of just listening.
[00:00:37.760 --> 00:00:42.620]   They have names like The Burnout Society, The Agony of Eros, and most recently The Crisis
[00:00:42.620 --> 00:00:43.340]   of Narration.
[00:00:43.340 --> 00:00:45.680]   In some ways, these books are like Standard Philosophy.
[00:00:45.680 --> 00:00:48.680]   He cites, in particular, Continental Philosophers.
[00:00:48.680 --> 00:00:52.840]   He's a specialist in Heidegger, so he does cite a lot of Heidegger, but also literary sources.
[00:00:53.640 --> 00:00:59.080]   But his books are popular, unlike other philosophy books, for two major reasons.
[00:00:59.080 --> 00:01:02.080]   One, he has a penchant for aphorisms.
[00:01:02.080 --> 00:01:07.120]   So he wraps his philosophical insights into provocative or poignant claims and descriptions
[00:01:07.120 --> 00:01:11.920]   that sort of hit home and are poetic and seem to hold in them a lot of truth, so that makes
[00:01:11.920 --> 00:01:12.500]   it more accessible.
[00:01:12.500 --> 00:01:17.500]   And second, the issues that he writes about are very relevant to our current techno moment.
[00:01:17.500 --> 00:01:23.920]   His work is like a guide, a philosophical guide to the modern technological environment.
[00:01:23.920 --> 00:01:29.140]   So he has relevance, and he has an accessibility, even though it's still a pretty smart academic
[00:01:29.140 --> 00:01:29.900]   philosophy.
[00:01:29.900 --> 00:01:30.720]   All right.
[00:01:30.720 --> 00:01:33.520]   So I hadn't read any Han before, but I thought I should.
[00:01:33.520 --> 00:01:36.000]   And if I was going to, I might as well bring you into this as well.
[00:01:36.000 --> 00:01:38.640]   I picked up his 2017 book.
[00:01:38.640 --> 00:01:39.500]   I'm holding it up here.
[00:01:39.500 --> 00:01:41.960]   In the Swarm, Digital Prospects.
[00:01:41.960 --> 00:01:43.640]   This was an MIT Press book.
[00:01:43.680 --> 00:01:49.040]   I read it a few days ago, and what I wanted to do today was actually present five passages
[00:01:49.040 --> 00:01:51.920]   from the book that caught my attention.
[00:01:51.920 --> 00:01:53.500]   I'll read them.
[00:01:53.500 --> 00:01:55.000]   I'll explain to you my thoughts on them.
[00:01:55.000 --> 00:01:57.060]   In a lot of cases, it's things I really like.
[00:01:57.060 --> 00:02:01.460]   In some cases, I have a disagreement with Han, or I'm going to point out ways where the world
[00:02:01.460 --> 00:02:05.020]   he's writing about has changed since he wrote this book eight years ago.
[00:02:05.020 --> 00:02:10.720]   And hopefully, you'll come away as familiar with Han's type of thinking as I'm becoming now
[00:02:10.720 --> 00:02:14.160]   that you'll have your own thoughts on, is this the internet's new favorite philosopher?
[00:02:14.160 --> 00:02:16.780]   At the very least, get some interesting philosophy.
[00:02:16.780 --> 00:02:18.340]   So I'm putting on my lecturing hat, Jesse.
[00:02:18.340 --> 00:02:19.080]   Wish me luck.
[00:02:19.080 --> 00:02:20.320]   Good luck.
[00:02:20.320 --> 00:02:23.780]   We are going to get into some techno philosophy.
[00:02:23.780 --> 00:02:25.420]   All right.
[00:02:25.420 --> 00:02:26.700]   Passage number one.
[00:02:26.700 --> 00:02:28.440]   This comes from pages one to two.
[00:02:28.440 --> 00:02:32.480]   This is Han on respect and civility.
[00:02:32.960 --> 00:02:34.180]   I'm going to read the quote.
[00:02:34.180 --> 00:02:36.100]   I have two quotes here, and then we'll get into it.
[00:02:36.100 --> 00:02:36.860]   Quote number one.
[00:02:36.860 --> 00:02:43.080]   I got to put on my, Jesse, I got to put on my sort of philosophy professor tone here, right?
[00:02:43.080 --> 00:02:44.060]   Because you're doing philosophy.
[00:02:44.060 --> 00:02:46.880]   You have to have a certain gravitas.
[00:02:46.880 --> 00:02:48.380]   So I'll put that on as I read this here.
[00:02:48.380 --> 00:02:49.040]   Good.
[00:02:49.040 --> 00:02:52.560]   Across the board.
[00:02:52.560 --> 00:02:54.060]   I just did a joke with you.
[00:02:54.060 --> 00:02:57.080]   I insisted on doing a high-pitched voice.
[00:02:57.080 --> 00:02:59.860]   It was just me burning philosophers.
[00:02:59.860 --> 00:03:01.380]   Across the board.
[00:03:01.380 --> 00:03:02.000]   I don't know.
[00:03:02.000 --> 00:03:04.000]   Take that, philosophers.
[00:03:04.000 --> 00:03:04.540]   Your move.
[00:03:04.540 --> 00:03:04.940]   No, okay.
[00:03:04.940 --> 00:03:05.580]   I'll read the series.
[00:03:05.580 --> 00:03:05.980]   Here we go.
[00:03:05.980 --> 00:03:11.620]   Across the board, digital communication is abolishing distance and distances.
[00:03:11.620 --> 00:03:16.220]   The corollary of dwindling spatial distance is the erosion of mental distance.
[00:03:16.220 --> 00:03:19.260]   Digital mediation works to the detriment of respect.
[00:03:19.260 --> 00:03:25.520]   In contrast, isolating and setting apart, as in the iton of ancient Greek temples generates
[00:03:25.520 --> 00:03:27.860]   admiration and reverence.
[00:03:27.860 --> 00:03:29.660]   Second quote.
[00:03:29.660 --> 00:03:31.940]   Respect is tied to names.
[00:03:31.940 --> 00:03:34.520]   Anonymity and respect rule each other out.
[00:03:34.520 --> 00:03:40.160]   The anonymous communication promoted by digital media is dismantling respect on a massive scale.
[00:03:40.160 --> 00:03:44.860]   It is also responsible for the expanding culture of indiscretion and disrespect.
[00:03:44.860 --> 00:03:46.080]   So you see what I mean, Jesse?
[00:03:46.080 --> 00:03:47.360]   It's very like aphorisms.
[00:03:47.360 --> 00:03:50.680]   It's like it's cones of wisdom.
[00:03:50.680 --> 00:03:51.900]   All right.
[00:03:51.900 --> 00:03:52.840]   So think about for a second.
[00:03:52.840 --> 00:03:55.360]   You can think for a second about what these things mean to you.
[00:03:55.380 --> 00:03:56.460]   Let me tell you what I picked up here.
[00:03:56.460 --> 00:03:57.080]   All right.
[00:03:57.080 --> 00:03:59.340]   First of all, the topic here is respect and civility.
[00:03:59.340 --> 00:04:01.840]   There's two factors that he's emphasizing.
[00:04:01.840 --> 00:04:06.460]   Factor number one, and he's saying this formally, but I think it's a common sense point.
[00:04:06.460 --> 00:04:14.040]   He's basically saying, when I see too much of you, I see your thoughts in posts and in videos
[00:04:14.040 --> 00:04:15.120]   and in your reactions.
[00:04:15.120 --> 00:04:19.120]   I'm just seeing you and your inner thoughts and your face and your words so much.
[00:04:19.120 --> 00:04:29.460]   You slip in your mind from someone that is worthy of a sort of distant respect into someone who maybe is more easily dismissed.
[00:04:29.600 --> 00:04:35.000]   Now, here's my sort of evolutionary argument or psych neuropsychological argument for what Han is picking up here.
[00:04:35.000 --> 00:04:39.120]   We have a particular category in our brain for how we categorize people.
[00:04:39.120 --> 00:04:46.500]   And if it's someone we know, it's an acquaintance, so it's like a close friend or a family member, we have a certain way that we categorize them as kith and kin.
[00:04:46.560 --> 00:04:53.000]   This is someone who is like really close to us, which is useful for having really close social interactions.
[00:04:53.000 --> 00:05:01.060]   But that also, think about it when we're thinking about close family members or close friends, we don't hold them with an esteem.
[00:05:01.060 --> 00:05:03.880]   We're more quickly to see like sort of flaws.
[00:05:03.880 --> 00:05:05.920]   It's more of an informal colloquial relationship.
[00:05:05.920 --> 00:05:21.120]   And I think what he's arguing is you don't want to take strangers and thinkers and writers and other people that you don't know well and shift them into that category that you would hold for your family, that you would hold for close friends, because that demolishing of distance ruins respect.
[00:05:21.120 --> 00:05:27.860]   And actually, civil society works much better when there's the people I know well and we have our own special sort of close relationship.
[00:05:27.860 --> 00:05:35.560]   And then there's other people with which I have some distance and a certain type of deference and respect, and so that it's sort of artificial what the digital does.
[00:05:35.640 --> 00:05:36.460]   That's my take there.
[00:05:36.460 --> 00:05:39.020]   The other factor he's talking about here is anonymity.
[00:05:39.020 --> 00:05:40.540]   This is sort of well-trod territory.
[00:05:40.540 --> 00:05:45.840]   He's basically arguing, look, you get bold when you're not right in front of someone.
[00:05:45.840 --> 00:06:03.800]   You get indecorous when there isn't someone standing in front of you who can give you a quick punch to the jaw if you say something particularly mean or off-putting to them, that the anonymity of the internet breeds incivility, which I think is well-trod territory, but it's worth saying.
[00:06:03.800 --> 00:06:05.340]   So I'm with him on it.
[00:06:05.360 --> 00:06:10.240]   I think he said it smarter than I just did, but smart thoughts beyond Joel Han.
[00:06:10.240 --> 00:06:18.160]   All right, topic number two, it's from page seven on outrage and crowds.
[00:06:18.160 --> 00:06:20.580]   So the first quote I want to read here is the following.
[00:06:22.160 --> 00:06:25.540]   Waves of outrage mobilize and bundle attention very efficiently.
[00:06:25.540 --> 00:06:32.080]   However, their fluidity and volatility make them unsuited to shaping public discourse or public space.
[00:06:32.080 --> 00:06:39.700]   They are too uncontrollable and calculable, inconstant, ephemeral, and amorphous for that.
[00:06:39.700 --> 00:06:42.160]   Jesse, this is just Han trying to get me to mispronounce words.
[00:06:42.160 --> 00:06:44.480]   Nice try Han, but I think I got those.
[00:06:45.040 --> 00:06:46.800]   Page eight, he has a related quote.
[00:06:46.800 --> 00:06:50.460]   Rage in the strong sense is more than an effective state.
[00:06:50.460 --> 00:06:55.800]   It means the capacity, our power to interrupt existing conditions and bring new ones.
[00:06:55.800 --> 00:06:57.300]   In this way, it produces the future.
[00:06:57.300 --> 00:07:00.720]   Today's fits of outrage are extremely fleeting and scattered.
[00:07:00.720 --> 00:07:04.940]   Outrage lacks the mass, the gravitation that is necessary for action.
[00:07:05.060 --> 00:07:06.240]   It generates no future.
[00:07:06.240 --> 00:07:10.540]   Related on page 10, he says, the new mass is the digital swarm.
[00:07:10.540 --> 00:07:15.380]   Its features distinguish it radically from the crowd, the classic form that many assumed.
[00:07:15.380 --> 00:07:18.400]   For a crowd to emerge, a chance gathering of human beings is not enough.
[00:07:18.400 --> 00:07:21.140]   It takes a soul, a common spirit, to fuse people into a crowd.
[00:07:21.140 --> 00:07:24.320]   The digital swarm lacks the soul or spirit of the masses.
[00:07:24.320 --> 00:07:27.280]   Individuals who come together as a swarm do not develop into a we.
[00:07:27.280 --> 00:07:32.460]   And then he adds on page 12, only when a crowd is resolute about shared action does power arise.
[00:07:32.960 --> 00:07:36.640]   The masses power, in contrast, digital swarms lack such resolve.
[00:07:36.640 --> 00:07:38.920]   They do not march because of their fleeting nature.
[00:07:38.920 --> 00:07:41.180]   No political energy wells up.
[00:07:41.180 --> 00:07:45.120]   All right, this is an interesting argument, and it's a place where I'm going to break with Han.
[00:07:45.120 --> 00:07:49.240]   Not that he was wrong, but that I think the dynamics of the internet changed since when he wrote this book.
[00:07:49.240 --> 00:07:53.660]   So he has an interesting analysis here of digital outrage.
[00:07:53.660 --> 00:07:59.080]   He's thinking about online mobs, like you would get on Tumblr back then, you would get on Twitter.
[00:07:59.800 --> 00:08:03.040]   And he's saying this is different than crowds marching in the street.
[00:08:03.040 --> 00:08:12.340]   That when a crowd gets together, they're connected and animated by a cause that they're trying to advance, whereas online outrage mobs aren't.
[00:08:12.340 --> 00:08:16.940]   There's just a fleeting addictiveness to the energy itself.
[00:08:17.040 --> 00:08:20.440]   It's a sort of faux rage, and it whips together, but doesn't really change anything.
[00:08:20.440 --> 00:08:26.100]   So he clearly has this antagonism throughout this whole book about online mobs.
[00:08:26.460 --> 00:08:35.980]   But where he's wrong, at least where he became wrong, is this idea that that makes them unsuited to having an impact on public discourse or the public space.
[00:08:35.980 --> 00:08:40.020]   Because, of course, this is exactly what went on to happen in the aftermath of this book.
[00:08:40.620 --> 00:08:47.760]   Like right around that 2016, 2017 period where this book came out, all the way up to basically Elon Musk buying Twitter, for example.
[00:08:47.760 --> 00:08:53.400]   The online world, and especially Twitter, had a massive impact on politics.
[00:08:53.400 --> 00:09:00.860]   It had a massive impact on the public space in elite circles such as journalism, academia, fiction writers.
[00:09:01.860 --> 00:09:06.800]   What was mobbed or not mobbed, the fear of the mob, had massive impact.
[00:09:06.800 --> 00:09:10.680]   We had politicians who were shaping policy based on how it played on Twitter.
[00:09:10.680 --> 00:09:15.320]   We had writers writing in fear of Twitter mobs that entirely affected what they would go after.
[00:09:15.320 --> 00:09:23.600]   Journalists were basically taking their lead from what would and would not generate outrage on the Internet and what would generate approval.
[00:09:24.100 --> 00:09:38.620]   After getting fired from the New York Times and her now sort of classic resignation letter, Barry Weiss talked about how Twitter had become the de facto editor, managing editor of the New York Times because it was who the writers were listening to.
[00:09:38.620 --> 00:09:51.660]   So actually, contrary to Han's argument that the ephemeral nature of online outrage means it can't actually advance the cost, it didn't stop it from having a massive impact on the public space.
[00:09:51.960 --> 00:09:54.980]   Then Elon Musk bought Twitter and basically blew it up.
[00:09:54.980 --> 00:10:02.060]   I mean, I know he had visions, but he just couldn't bring himself together, get off ketamine long enough or whatever's going on to actually enact those visions.
[00:10:02.060 --> 00:10:07.420]   So he kind of just blew it up and it got weird and crazy and super racist and anti-Semitic.
[00:10:07.420 --> 00:10:12.960]   It got like it became weird, but it also lost its influence, which was actually probably a good thing.
[00:10:12.960 --> 00:10:16.960]   Online mobs should not have such an influence on the public sphere.
[00:10:16.960 --> 00:10:18.960]   So he didn't really foresee that coming.
[00:10:18.960 --> 00:10:29.260]   The impact that something as fleeting as people mobbing together digitally without like a real man, the barricades type of passion on a particular cause, they still could have a massive impact.
[00:10:29.260 --> 00:10:30.680]   I think that's why Twitter was so powerful.
[00:10:30.680 --> 00:10:33.580]   But that that period is dying, I think, for the better.
[00:10:34.040 --> 00:10:34.900]   Hey, it's Cal.
[00:10:34.900 --> 00:10:46.500]   I wanted to interrupt briefly to say that if you're enjoying this video, then you need to check out my new book, Slow Productivity, The Lost Art of Accomplishment Without Burnout.
[00:10:46.500 --> 00:10:52.080]   This is like the Bible for most of the ideas we talk about here in these videos.
[00:10:52.320 --> 00:10:57.340]   You can get a free excerpt at calnewport.com slash slow.
[00:10:57.340 --> 00:10:59.160]   I know you're going to like it.
[00:10:59.160 --> 00:11:00.160]   Check it out.
[00:11:00.160 --> 00:11:01.520]   Now let's get back to the video.
[00:11:01.520 --> 00:11:03.620]   Okay, let's go here.
[00:11:03.620 --> 00:11:04.740]   Next passage.
[00:11:04.740 --> 00:11:06.820]   Are you feeling philosophical, Jesse?
[00:11:06.820 --> 00:11:08.000]   Are we getting, do you feel smarter?
[00:11:08.000 --> 00:11:11.040]   Like the IQ is raising in the HQ in here in Anaheim?
[00:11:11.040 --> 00:11:12.080]   It is.
[00:11:13.580 --> 00:11:14.980]   All right, well, here, let's keep it rolling then.
[00:11:14.980 --> 00:11:17.380]   On work, leisure, and optimization.
[00:11:17.380 --> 00:11:18.320]   What does he say?
[00:11:18.320 --> 00:11:19.400]   All right, page 33.
[00:11:19.400 --> 00:11:23.760]   Leisure begins where work ceases entirely.
[00:11:23.760 --> 00:11:26.700]   The time of leisure is a separate time.
[00:11:26.700 --> 00:11:31.800]   The neoliberal imperative to perform transforms time into working hours.
[00:11:31.800 --> 00:11:34.120]   It totalizes a belabored temporality.
[00:11:34.120 --> 00:11:37.440]   Breaks represent only a phase of the working day.
[00:11:37.440 --> 00:11:40.200]   Today we know time only as time for working.
[00:11:40.900 --> 00:11:45.920]   And so this temporality follows us on vacation, not only on vacation, but even when we sleep.
[00:11:45.920 --> 00:11:48.380]   This is why we are sleeping so fitfully.
[00:11:48.380 --> 00:11:54.020]   Exhausted achievement subjects can rest only in the same way that a leg falls asleep.
[00:11:54.020 --> 00:11:59.140]   He also says on page 34, even though we are now free from the machines that enslave and
[00:11:59.140 --> 00:12:03.980]   exploited people during the industrial age, digital apparatuses are installing new constraints,
[00:12:03.980 --> 00:12:04.660]   new slavery.
[00:12:04.660 --> 00:12:10.060]   Because of their mobility, they make possible exploration that proves even exploitation that
[00:12:10.060 --> 00:12:15.120]   proves even more efficient by transforming every space into a workspace and all time into working
[00:12:15.120 --> 00:12:15.580]   hours.
[00:12:15.580 --> 00:12:20.680]   This is really the topic space where Han really first came to people's attention is his critiques
[00:12:20.680 --> 00:12:23.060]   of work in the modern sort of digital age.
[00:12:23.060 --> 00:12:28.940]   He definitely comes at things from a sort of classical critique of capitalism left type perspective,
[00:12:28.940 --> 00:12:32.860]   much more so than like a newer academic left identity perspective.
[00:12:33.340 --> 00:12:38.900]   I have written about these exact same impacts of digital work, much less eloquently, I must
[00:12:38.900 --> 00:12:43.820]   add, but I've written about these same topics and how it helps amplify the sort of totalizing
[00:12:43.820 --> 00:12:45.060]   impulse to perform work.
[00:12:45.060 --> 00:12:46.580]   Slow productivity gets into this.
[00:12:46.580 --> 00:12:51.100]   Slow productivity gets into this idea of the portability of digital devices, brings work,
[00:12:51.100 --> 00:12:53.780]   invades work into all sorts of different spaces and times.
[00:12:54.440 --> 00:12:56.860]   This push to always need to be working.
[00:12:56.860 --> 00:12:58.560]   These are real problems.
[00:12:58.560 --> 00:13:01.600]   I have identified them as have many other writers.
[00:13:01.600 --> 00:13:05.460]   This is also, however, a place where I have some differences with not just Han, but other
[00:13:05.460 --> 00:13:07.560]   writers who have followed in his footsteps here.
[00:13:07.560 --> 00:13:14.160]   So he's applying this very standard critique that says, why do we feel this impulse to work
[00:13:14.160 --> 00:13:14.820]   all the time?
[00:13:15.820 --> 00:13:19.500]   And he uses terms like neo, it's a liberal, neoliberal impulse.
[00:13:19.500 --> 00:13:24.720]   We'll, we'll see other people talk about like a late capitalism impulse that that's a sort
[00:13:24.720 --> 00:13:30.660]   of a standard neo-Marxist type argument that the, the, the culture, the superstructure around
[00:13:30.660 --> 00:13:36.460]   capital of imperative sort of tricks and induces us into saying, I should always be working on
[00:13:36.460 --> 00:13:38.520]   to use his terminology in achievement subject.
[00:13:38.900 --> 00:13:45.480]   And some of that might be true, but my take on our current state of affairs is I look at
[00:13:45.480 --> 00:13:48.880]   a different source because I say, well, that might be the case, but things are worse now.
[00:13:48.880 --> 00:13:52.840]   The last 15 years, things are worse than they were before that.
[00:13:52.840 --> 00:13:59.720]   The 2010s knowledge workers are more exhausted than they were in the 1990s.
[00:13:59.720 --> 00:14:03.220]   And I don't think it's because of changes to neoliberalism or capitalism.
[00:14:03.220 --> 00:14:06.980]   Knowledge work has been around since the mid-century.
[00:14:07.520 --> 00:14:11.440]   So where I argue is I have a much more functionalist sort of pragmatic argument.
[00:14:11.440 --> 00:14:14.580]   I say partially is just how we think about work and productivity.
[00:14:14.580 --> 00:14:17.500]   And this plays poorly with digital technology.
[00:14:17.500 --> 00:14:19.520]   I talked about this in last week's deep dive, right?
[00:14:19.520 --> 00:14:23.700]   So you've heard this argument from me before is if you want to understand why we feel so
[00:14:23.700 --> 00:14:27.640]   exhausted from work now in a way more so than we did 20 years ago, what you have to understand
[00:14:27.640 --> 00:14:28.540]   is pseudo productivity.
[00:14:28.540 --> 00:14:32.820]   You have to understand this idea that visible activity is a proxy for useful effort.
[00:14:32.820 --> 00:14:33.700]   And why is that?
[00:14:33.700 --> 00:14:35.500]   Because we didn't know how else to manage knowledge workers.
[00:14:35.500 --> 00:14:36.840]   They weren't on an assembly line.
[00:14:36.900 --> 00:14:37.580]   We didn't know what to do.
[00:14:37.580 --> 00:14:41.700]   We've been doing pseudo productivity since the fifties, but then we got computers and email
[00:14:41.700 --> 00:14:45.440]   and then we got portable computers and smartphones and pseudo productivity spun off the rails.
[00:14:45.440 --> 00:14:50.960]   When we can demonstrate effort at such a small granularity and we can bring those effort
[00:14:50.960 --> 00:14:52.160]   demonstrations wherever we go.
[00:14:52.160 --> 00:14:57.560]   It's not that we've been seduced by some sort of exploitative trapped from capitalist.
[00:14:58.060 --> 00:15:05.400]   It's this management hack of pseudo productivity, which was worked okay for decades, doesn't work well in the age of the digital.
[00:15:05.400 --> 00:15:09.960]   And why I don't think it's a trap of the capitalist is because it also doesn't make us great workers.
[00:15:09.960 --> 00:15:19.280]   Answering emails all the time and demonstrating sort of fine granularity effort is a really bad way to produce stuff that's valuable and brings money to the organization.
[00:15:19.740 --> 00:15:30.780]   So either the capitalists are bad or what we're really dealing here is with a combination of like techno cultural economic elements that are slamming together and creating unintentional impacts.
[00:15:30.900 --> 00:15:35.540]   That's the way I see that same issue, but, uh, he's very influential.
[00:15:35.540 --> 00:15:37.280]   Excuse me.
[00:15:37.280 --> 00:15:38.500]   I give a talk this morning.
[00:15:38.500 --> 00:15:39.300]   So I've been talking a lot.
[00:15:39.300 --> 00:15:41.580]   Um, he's very influential on this.
[00:15:41.580 --> 00:15:54.920]   I didn't put more quotes here on work, but he does some critiques in this book that sounds straight out of Jenny O'Dell, uh, Jenny O'Dell type of philosophizing on, you know, do nothing, how to do nothing.
[00:15:54.920 --> 00:15:57.100]   And this came first.
[00:15:57.100 --> 00:15:59.640]   So I think his thinking must've been a real influence.
[00:15:59.640 --> 00:16:01.680]   He talks about the performance and the achievement subjects.
[00:16:01.680 --> 00:16:10.400]   There's a lot of sort of my generation of work critics use a lot of young tool Han type of terminology.
[00:16:10.400 --> 00:16:11.020]   All right.
[00:16:11.020 --> 00:16:13.760]   Next topic, virality.
[00:16:13.760 --> 00:16:19.240]   You can see this guy covers a lot of interesting topics all in like one book.
[00:16:19.240 --> 00:16:20.460]   All right.
[00:16:20.460 --> 00:16:21.680]   Here's what he has to say on virality.
[00:16:21.680 --> 00:16:23.000]   This comes from page 57.
[00:16:24.180 --> 00:16:28.080]   Digital communication is not just assuming spectral form.
[00:16:28.080 --> 00:16:30.160]   It's also becoming viral.
[00:16:30.160 --> 00:16:37.400]   Digital communication is contagious insofar as it occurs on an emotive or effective register without mediation.
[00:16:37.400 --> 00:16:44.740]   Contagion represents a form of post-hermetic communication that in fact offers nothing to think about.
[00:16:45.260 --> 00:16:46.960]   It does not presuppose any kind of reading.
[00:16:46.960 --> 00:16:52.760]   Digital content, even if it holds very little significance, spreads like an epidemic, a pandemic racing through the net.
[00:16:52.760 --> 00:16:55.080]   It is burdened by the weight of meaning.
[00:16:55.080 --> 00:16:57.680]   No, it is unburdened by the weight of meaning.
[00:16:57.680 --> 00:17:00.780]   Rather, no other medium can affect such viral infection.
[00:17:00.780 --> 00:17:03.400]   Writing is far too sluggish.
[00:17:04.060 --> 00:17:05.380]   So this is really interesting.
[00:17:05.380 --> 00:17:08.880]   He's trying to give an information theory of virality.
[00:17:08.880 --> 00:17:14.800]   He uses similar terminology throughout the book that information creates.
[00:17:14.800 --> 00:17:17.000]   Sometimes he thinks of it as like an immune response.
[00:17:17.000 --> 00:17:26.500]   He uses this terminology that when something is like richer in information, it's more likely to spur in us some sort of like consideration or resistance or pushback.
[00:17:26.500 --> 00:17:31.720]   And it's like an immune response that slows down that information's ability to take hold or the spread.
[00:17:31.720 --> 00:17:36.260]   And the digital viral communication is weightless.
[00:17:36.260 --> 00:17:40.140]   It doesn't have information content and therefore there's no immune response.
[00:17:40.140 --> 00:17:42.160]   It's like it's slipping through our immune defenses.
[00:17:42.160 --> 00:17:44.820]   It can just bounce from us to other people and it bounces all around.
[00:17:44.820 --> 00:17:47.680]   There's something really interesting here.
[00:17:47.680 --> 00:17:55.720]   We could think of this as like a critique of Richard Dawkins' memetics where memetics is all about the nature of the content, that certain content is sticky and spreadable.
[00:17:55.720 --> 00:18:00.660]   So because of what it's saying, it spreads better.
[00:18:00.660 --> 00:18:06.620]   Whereas Han is arguing it's what content's not saying that makes it more spreadable.
[00:18:06.620 --> 00:18:07.560]   There's like a lightweight in it.
[00:18:07.560 --> 00:18:11.940]   So I mean, look, this is a thread he touches on briefly, but you could probably pull to be more stronger.
[00:18:11.940 --> 00:18:20.500]   My critique here is I don't see how you can understand or really give a full treatment of virality in the digital age without dealing with algorithms and networks.
[00:18:20.500 --> 00:18:24.940]   So when I've dealt and written about virality before, especially like in my New Yorker work on this,
[00:18:24.940 --> 00:18:27.300]   network theory has to be there.
[00:18:27.300 --> 00:18:29.680]   Algorithmic curation has to be there.
[00:18:29.680 --> 00:18:32.540]   That is a key engine of virality.
[00:18:32.540 --> 00:18:34.220]   It's not just the nature of the information.
[00:18:34.220 --> 00:18:36.460]   It's the mediums in which it can spread.
[00:18:36.460 --> 00:18:37.900]   Anyways, interesting stuff.
[00:18:37.900 --> 00:18:40.720]   All right.
[00:18:40.720 --> 00:18:41.800]   One final topic.
[00:18:44.380 --> 00:18:53.040]   His final chapter is a list of reasons why we all should be lucky to be graced by Cal Network's presence.
[00:18:53.040 --> 00:18:54.400]   That's interesting to see that in his book.
[00:18:54.400 --> 00:18:59.880]   It's just like a whole long, a whole long list of reasons why Cal Network is awesome.
[00:18:59.880 --> 00:19:02.920]   Now, that would be, uh, I wish.
[00:19:02.920 --> 00:19:04.160]   No, instead he has.
[00:19:04.160 --> 00:19:07.240]   The last thing I want to read here is about information overload and thinking.
[00:19:08.200 --> 00:19:08.640]   Right.
[00:19:08.640 --> 00:19:09.400]   Here's page 60.
[00:19:09.400 --> 00:19:17.180]   The tide of information to which we are exposed today is clearly interfering with our ability to build matters down to their essence.
[00:19:17.180 --> 00:19:22.160]   Thinking necessarily involves negativity, discernment, discrimination, and election.
[00:19:22.160 --> 00:19:26.340]   In other words, thoughts always process exclusively.
[00:19:27.760 --> 00:19:29.340]   Now, this is interesting as well.
[00:19:29.340 --> 00:19:38.600]   Um, I, I think what he's saying here is real thoughts involve you making decisions and selecting like, this is good.
[00:19:38.600 --> 00:19:39.240]   This is bad.
[00:19:39.240 --> 00:19:39.980]   I agree with this.
[00:19:39.980 --> 00:19:41.000]   I don't agree with that.
[00:19:41.000 --> 00:19:48.080]   And in that affirmation and rejection, you build up a complicated understanding of something.
[00:19:48.080 --> 00:19:55.980]   And what he's trying to argue here is the information in the digital realm lands on us so fast.
[00:19:55.980 --> 00:19:57.280]   We don't have time for curation.
[00:19:57.280 --> 00:19:59.060]   It just sort of flows over us.
[00:19:59.060 --> 00:20:09.440]   And maybe some things stick out as interesting to us or we kind of, they, they're, or they're self-justifying and we hold on to them, but there's no time or space or pace for curation.
[00:20:09.440 --> 00:20:11.900]   And without that, we're not really thinking.
[00:20:11.900 --> 00:20:13.760]   This is an important thought.
[00:20:13.860 --> 00:20:22.380]   I have been ironically to use this verb thinking about this a lot recently because I have an idea for a book about thinking and revitalizing thinking as a movement and taking it seriously.
[00:20:22.380 --> 00:20:25.080]   Just like we, we, we should take deep work seriously in the world of work.
[00:20:25.080 --> 00:20:35.560]   So these types of ideas are ones I'm thinking about that, that the art of thinking requires, you know, certain circumstances and the digital is making that worse.
[00:20:35.560 --> 00:20:36.460]   We're getting worse at it.
[00:20:36.460 --> 00:20:37.760]   All right.
[00:20:37.760 --> 00:20:38.140]   So there we go.
[00:20:38.140 --> 00:20:51.760]   Anyways, you should see why people like Byung Chul Han, this one book, those were just five, I believe out of probably 10 different interesting ideas that I really isolated.
[00:20:51.760 --> 00:20:58.000]   When I was reading this book, I marked it up for those who can see, I use my online note taking method.
[00:20:58.000 --> 00:21:03.440]   So a mark in the corner means that I have notes on that page and then I have a lot of bracketing going on.
[00:21:04.400 --> 00:21:06.780]   So a lot of ideas packed in a thin book.
[00:21:06.780 --> 00:21:10.700]   He writes a lot of these thin books so we can sort of see why he is popular.
[00:21:10.700 --> 00:21:11.320]   So there we go.
[00:21:11.320 --> 00:21:17.160]   And that was our sort of temporary lecture here on Byung Chul Han.
[00:21:17.160 --> 00:21:19.020]   I like how easy these books are to read, Jesse.
[00:21:19.020 --> 00:21:21.900]   I could, I mean, they're not easy, but they're short.
[00:21:21.900 --> 00:21:22.700]   Yeah.
[00:21:22.700 --> 00:21:25.980]   And so you think I'm going to be done with this thing in 20 minutes.
[00:21:25.980 --> 00:21:31.260]   The problem is you've got to read really slow, but he makes it short so that even if you read slow, it doesn't take too long.
[00:21:31.760 --> 00:21:32.900]   It was an enjoyable experience.
[00:21:32.900 --> 00:21:34.640]   I like that.
[00:21:34.640 --> 00:21:35.660]   I like that format.
[00:21:35.660 --> 00:21:37.720]   Aphorisms.
[00:21:37.720 --> 00:21:41.460]   Maybe I should do more aphorisms, just sort of state things sort of quizzically.
[00:21:41.460 --> 00:21:44.560]   I like it.
[00:21:44.560 --> 00:21:47.780]   Cal Network just has declarative sentences.
[00:21:47.780 --> 00:21:49.540]   Each chapter is just a declarative sentence.
[00:21:49.540 --> 00:21:51.500]   That's the way with an exclamation point.
[00:21:51.500 --> 00:21:53.980]   Hey, stop doing that.
[00:21:53.980 --> 00:21:54.520]   Boom.
[00:21:54.520 --> 00:21:56.140]   He also signs weird.
[00:21:56.140 --> 00:21:59.800]   Every page has a quote with exclamation point and he signs at Cal Network.
[00:22:00.200 --> 00:22:02.140]   So a weird style of writing.
[00:22:02.140 --> 00:22:03.040]   All right, there we go.
[00:22:03.040 --> 00:22:04.540]   That's our deep dive for today.
[00:22:04.540 --> 00:22:16.020]   We got some questions to get to, but first let's hear from some of the sponsors that makes this show possible.
[00:22:18.940 --> 00:22:22.500]   This is an ad for better help.
[00:22:22.500 --> 00:22:28.860]   Men today in particular face immense pressure to perform, to provide, to keep it all together.
[00:22:28.860 --> 00:22:34.620]   We hear this often as subtext and a lot of the questions from men that we answer on this show.
[00:22:35.420 --> 00:22:41.120]   So it's no wonder that 6 million men in the U.S. suffer from depression every year and it's often undiagnosed.
[00:22:41.120 --> 00:22:42.740]   Struggle is good.
[00:22:42.740 --> 00:22:43.980]   Life has struggle.
[00:22:43.980 --> 00:22:48.980]   But real strength comes from opening up about what you're carrying and doing something about it.
[00:22:48.980 --> 00:22:53.200]   And so if that mental struggle is becoming too much, you should consider therapy.
[00:22:54.260 --> 00:22:58.560]   And when you're thinking about therapy, think about better help.
[00:22:58.560 --> 00:23:03.760]   With over 35,000 therapists, better help is the world's largest online therapy platform.
[00:23:04.000 --> 00:23:11.460]   It has served over 5 million people globally, and it works with an app store rating of 4.9 out of 5, right?
[00:23:11.460 --> 00:23:14.200]   4.9 out of 5 based on 1.7 million client reviews.
[00:23:14.200 --> 00:23:14.880]   So we know it works.
[00:23:14.880 --> 00:23:15.580]   It's also convenient.
[00:23:15.580 --> 00:23:17.880]   You can join a session with a therapist at the click of a button.
[00:23:17.880 --> 00:23:21.400]   It's virtual, helping you fit therapy into your busy life.
[00:23:21.400 --> 00:23:26.220]   Plus, you can switch therapists at any time.
[00:23:26.220 --> 00:23:32.240]   So if you don't quite find a good fit with the current therapist, you can switch.
[00:23:32.240 --> 00:23:33.840]   I think it's all great.
[00:23:34.500 --> 00:23:40.320]   So as the largest online therapy provider in the world, better help can provide access to mental health professionals with a diverse array of expertise.
[00:23:40.320 --> 00:23:43.300]   So talk it out with better help.
[00:23:43.300 --> 00:23:49.940]   Our listeners get 10% off their first month at betterhelp.com slash deep questions.
[00:23:49.940 --> 00:23:56.460]   That's betterhelp.com slash deep questions.
[00:23:56.460 --> 00:24:01.820]   I also want to talk about our friends at ExpressVPN.
[00:24:02.960 --> 00:24:06.240]   The problem with these huge tech companies is they don't just want your money.
[00:24:06.240 --> 00:24:09.000]   They want to know everything about you.
[00:24:09.440 --> 00:24:16.940]   Shadowy data brokers make a living compiling detailed profiles of your online activity and selling them to marketers and other corporate interests that you want to control.
[00:24:16.940 --> 00:24:18.540]   They want to control you with targeted ads.
[00:24:19.180 --> 00:24:19.540]   They're not selling a product.
[00:24:19.540 --> 00:24:20.440]   They're not selling a product.
[00:24:20.440 --> 00:24:22.020]   They are selling you.
[00:24:22.020 --> 00:24:23.640]   But you don't have to let them.
[00:24:23.640 --> 00:24:25.820]   There is a way to keep your browsing history truly private.
[00:24:25.820 --> 00:24:29.920]   It is what I use for privacy, which is a VPN.
[00:24:29.920 --> 00:24:33.460]   And if you're going to use a VPN, you should use the one I recommend, which is ExpressVPN.
[00:24:33.760 --> 00:24:45.720]   The way this works is that when you're using a network, like I'm at a hotel right now, if I'm just logged on to the network using my web browser, the hotel ISP knows every website and service I'm using.
[00:24:46.240 --> 00:24:53.780]   They can't see the actual messages because those are encrypted if I'm using SSL, but they can see who I'm talking to.
[00:24:53.780 --> 00:25:03.100]   If I use ExpressVPN instead, what happens is my messages get wrapped up in an encrypted, protected message and sent to a VPN server.
[00:25:03.100 --> 00:25:08.800]   ExpressVPN then decrypts that message and talks to the site and server on your behalf, encrypts the response and sends it back.
[00:25:09.020 --> 00:25:14.600]   So all my hotel ISP would learn is that I'm talking to a VPN server and not what site and service I'm using.
[00:25:14.600 --> 00:25:17.220]   So VPNs really does give you privacy.
[00:25:17.220 --> 00:25:27.940]   There are reports that there's these big consumer ISPs to people you might be connected to to give you internet access in your house that keep track of who you're talking to and sell it to data brokers.
[00:25:27.940 --> 00:25:30.980]   So a VPN keeps that all private.
[00:25:30.980 --> 00:25:32.860]   And if you're going to use a VPN, use ExpressVPN.
[00:25:32.860 --> 00:25:34.740]   It's easy to use.
[00:25:34.740 --> 00:25:37.420]   It works on all your devices, phone, laptop, tablet, you name it.
[00:25:37.460 --> 00:25:39.000]   And you just tap one button, you turn it on.
[00:25:39.000 --> 00:25:41.380]   Boom, you use all your apps and websites like normal.
[00:25:41.380 --> 00:25:44.300]   This happens seamlessly in the background.
[00:25:44.300 --> 00:25:49.080]   So protect your online privacy today by visiting expressvpn.com slash deep.
[00:25:49.080 --> 00:25:54.060]   That's E-X-P-R-E-S-S-V-P-N dot com slash deep.
[00:25:54.060 --> 00:26:00.060]   And you can get an extra four months free when you go to expressvpn.com slash deep.
[00:26:00.060 --> 00:26:02.740]   All right, Jesse, let's do some questions.
[00:26:02.740 --> 00:26:06.000]   Hi, first questions from Frank.
[00:26:06.400 --> 00:26:09.380]   When you're traveling, how do you structure your reading in writing?
[00:26:09.380 --> 00:26:11.780]   That's a timely question, Frank.
[00:26:11.780 --> 00:26:17.100]   It's almost like Jesse knew I'd be traveling when selecting the questions for this week.
[00:26:17.100 --> 00:26:19.760]   It depends on the type of traveling.
[00:26:19.760 --> 00:26:25.100]   And for me, the big differentiating factor is family vacation or am I doing business traveling?
[00:26:25.100 --> 00:26:27.620]   This is a good example because this trip is both.
[00:26:27.620 --> 00:26:29.040]   It's a business trip right now.
[00:26:29.040 --> 00:26:33.620]   I'm here in Anaheim by myself, but then my family is coming to meet me and I'll turn into a family trip.
[00:26:34.040 --> 00:26:39.900]   So if it's a family trip and it's not like when we go away for the whole summer, I'm not going to write that much.
[00:26:39.900 --> 00:26:42.320]   It's about being with my family, being able to spend extra time.
[00:26:42.320 --> 00:26:47.000]   When it is a business trip, I actually just make a rough time block plan for the day.
[00:26:47.160 --> 00:26:50.640]   Like I've already spent a good amount of time today doing book editing.
[00:26:50.640 --> 00:26:52.860]   Yesterday, I spent a good amount of time.
[00:26:52.860 --> 00:26:56.340]   This was on the plane working on this podcast episode.
[00:26:56.340 --> 00:27:02.660]   I know what writing and when I'm going to do it tomorrow morning before my family arrives.
[00:27:02.800 --> 00:27:05.740]   So when it's a business trip, I get a lot of writing done.
[00:27:05.740 --> 00:27:12.100]   I take pride in finding interesting and unusual places to write when I'm traveling, just like interesting places.
[00:27:12.100 --> 00:27:13.800]   I write about this a little bit in my book, Deep Work.
[00:27:13.800 --> 00:27:18.100]   Like here in Anaheim, for example, the convention center has these cool fountains.
[00:27:18.100 --> 00:27:20.720]   There's a lot of benches out there.
[00:27:20.720 --> 00:27:22.160]   The water is going.
[00:27:22.160 --> 00:27:23.180]   It's beautiful weather here.
[00:27:23.180 --> 00:27:24.280]   Good place to write.
[00:27:24.280 --> 00:27:26.000]   So I'm always looking for good places to write.
[00:27:26.000 --> 00:27:27.620]   With family vacation, not so much.
[00:27:28.080 --> 00:27:33.340]   The exception is if I'm on a long trip, like we typically go away for a month or so in the summer, we go up north.
[00:27:33.340 --> 00:27:35.800]   And there we actually, I work with my wife to build a schedule.
[00:27:35.800 --> 00:27:42.700]   It's usually me writing first thing in the morning before the kids are really up and going so that we can then hit the adventures or wherever we want to do that day.
[00:27:42.700 --> 00:27:45.180]   I'm already done with my writing.
[00:27:45.180 --> 00:27:48.480]   And then sometimes I'll throw in like a happy hour writing session as well.
[00:27:48.480 --> 00:27:49.720]   So there you go.
[00:27:49.720 --> 00:27:51.160]   That's how I write on vacation.
[00:27:51.160 --> 00:27:57.020]   Maybe I should write on Pirates of the Caribbean or the Haunted Mansion ride.
[00:27:57.580 --> 00:27:59.400]   Yeah, this would be the ultimate.
[00:27:59.400 --> 00:28:01.060]   That solves all your dilemmas.
[00:28:01.060 --> 00:28:03.680]   I talk about setting being important for writing.
[00:28:03.680 --> 00:28:05.580]   I'm going to literally work on my book.
[00:28:05.580 --> 00:28:07.280]   I wonder if this will work out okay.
[00:28:07.280 --> 00:28:09.220]   While on a darkroom ride at Disney.
[00:28:09.220 --> 00:28:13.020]   I wonder if you're allowed to bring laptops and write while you're on the ride.
[00:28:13.020 --> 00:28:14.660]   I'll bring it.
[00:28:14.660 --> 00:28:15.040]   We'll see.
[00:28:15.040 --> 00:28:16.000]   I'm thinking now.
[00:28:16.000 --> 00:28:17.420]   Splash Mountain.
[00:28:17.420 --> 00:28:19.580]   I'm going to work on a Splash Mountain.
[00:28:19.580 --> 00:28:20.740]   All right.
[00:28:20.740 --> 00:28:21.300]   What do we got next?
[00:28:21.300 --> 00:28:23.020]   Next up is Mary.
[00:28:23.020 --> 00:28:26.300]   I just made partner in a professional services firm.
[00:28:26.560 --> 00:28:28.740]   Part of my new job is bringing in new business.
[00:28:28.740 --> 00:28:33.240]   Like many, I strove to be so good they couldn't ignore me at executing projects.
[00:28:33.240 --> 00:28:38.680]   But now I also need to bring in substantial new business and ideally feed other colleagues with this business too.
[00:28:38.680 --> 00:28:39.880]   Any suggestions?
[00:28:40.440 --> 00:28:44.880]   So, Mary, it's common as you move to the partner level that new business is partially what you're responsible for.
[00:28:44.880 --> 00:28:53.960]   If you want to succeed and stick in this position and keep a lot of autonomy, keep that career capital high, you have to become so good they can't ignore you at this new part as well.
[00:28:54.620 --> 00:29:15.560]   For some reason, for a very well reason, not for some reason, for a very understandable reason, people on partnership tracks often had a hard time with the switch when they make partner because typically what they're doing up the partner is very much about a technical expertise on like I do this particular type of law or this particular type of consulting or I'm a CPA that works on like a very particular type of accounting.
[00:29:15.560 --> 00:29:18.680]   You get very good at it and that gives you a lot of career capital.
[00:29:18.680 --> 00:29:24.860]   And so it feels really different when you get the partner and they give you this interpersonal thing like the golf club.
[00:29:24.860 --> 00:29:25.380]   Like, what is this?
[00:29:25.380 --> 00:29:26.060]   This isn't work.
[00:29:26.060 --> 00:29:30.860]   This is like some requirement that's getting in the way of me doing my work well.
[00:29:30.860 --> 00:29:32.440]   You got to see it as part of your work.
[00:29:32.440 --> 00:29:35.520]   You got to see it as part of what you're trying to master as well.
[00:29:35.520 --> 00:29:36.900]   It'll make it more fun.
[00:29:36.900 --> 00:29:38.560]   It'll make you more successful at it.
[00:29:38.600 --> 00:29:43.020]   And if you get more successful at it, again, it's going to give you more autonomy in your job.
[00:29:43.020 --> 00:29:45.220]   So I hear about this a lot from people that make partner track.
[00:29:45.220 --> 00:29:47.400]   You can get just as good at new business as anything else.
[00:29:47.400 --> 00:29:48.040]   Break it down.
[00:29:48.040 --> 00:29:49.240]   Talk to people who are good at it.
[00:29:49.240 --> 00:29:51.020]   Figure out what matters and what doesn't.
[00:29:51.020 --> 00:29:52.800]   Put in the time and the stuff that matters.
[00:29:52.800 --> 00:29:54.260]   Don't waste time on the stuff that doesn't.
[00:29:54.260 --> 00:29:57.100]   Those same depth principle concepts apply right here as well.
[00:29:57.100 --> 00:29:59.220]   All right, let's roll.
[00:29:59.220 --> 00:30:01.100]   Next up is Peter.
[00:30:01.100 --> 00:30:03.740]   Do you find value in memory training?
[00:30:03.740 --> 00:30:06.600]   I write about this, Peter, in deep work.
[00:30:06.740 --> 00:30:11.780]   In fact, I used to have a part of my deep work keynote, which I just gave a few hours ago
[00:30:11.780 --> 00:30:12.880]   this morning here in Anaheim.
[00:30:12.880 --> 00:30:15.700]   I had a longer version of the keynote.
[00:30:15.700 --> 00:30:17.680]   It's a good talk, by the way.
[00:30:17.680 --> 00:30:21.340]   But because it's my paid keynote, it doesn't really exist anywhere on the internet because
[00:30:21.340 --> 00:30:23.060]   that kind of reduces its value.
[00:30:23.060 --> 00:30:24.600]   It's a good talk that I keep updating.
[00:30:24.600 --> 00:30:30.000]   But there was an older version of it where I used to tell the memory training story that
[00:30:30.000 --> 00:30:30.820]   I had in deep work.
[00:30:30.820 --> 00:30:36.260]   I learned over time that I cut out a lot of these stories so I could put more advice in the
[00:30:36.260 --> 00:30:36.420]   talk.
[00:30:36.420 --> 00:30:41.820]   Actually, what people want is the concepts and then give me different ideas for how I can
[00:30:41.820 --> 00:30:43.520]   put these concepts into action.
[00:30:43.520 --> 00:30:44.660]   So that story got cut.
[00:30:44.660 --> 00:30:46.000]   I used to tell the story all the time.
[00:30:46.000 --> 00:30:53.300]   I won't tell the whole story, but the reason why I had it in there is the person that I talk
[00:30:53.300 --> 00:30:57.320]   about in the book had this great setup where they were a student.
[00:30:57.520 --> 00:30:58.440]   I think his name was Daniel.
[00:30:58.440 --> 00:30:59.460]   I have to remember.
[00:30:59.460 --> 00:31:00.140]   I think it was Daniel.
[00:31:00.140 --> 00:31:01.060]   It's in the book.
[00:31:01.060 --> 00:31:04.580]   He was a student who was struggling academically.
[00:31:04.580 --> 00:31:10.060]   Then for unrelated reasons, got interested in memory competitions.
[00:31:10.060 --> 00:31:16.700]   He like saw someone or met someone who did these memory competitions where an example event would
[00:31:16.700 --> 00:31:18.840]   be, we're going to shuffle a deck of cards.
[00:31:18.840 --> 00:31:23.860]   And then you have like a minute to kind of just go through, like flip the cards over.
[00:31:24.400 --> 00:31:28.500]   And then you have to try to recreate what the order of the cards was from memory.
[00:31:28.500 --> 00:31:30.500]   It's like these type of things, like pretty crazy things.
[00:31:30.500 --> 00:31:34.540]   And so he got into these type of memory competitions and he got pretty good at them.
[00:31:34.540 --> 00:31:35.540]   He trained, he's Australian.
[00:31:35.540 --> 00:31:38.620]   He trained with like the runner up for the national championship in Australia.
[00:31:39.620 --> 00:31:41.460]   Why it's interesting is his grades went up.
[00:31:41.460 --> 00:31:43.720]   He became a better student.
[00:31:43.720 --> 00:31:53.300]   And I was arguing is the memory training got him more comfortable with what it feels like
[00:31:53.300 --> 00:31:56.600]   the focus, the control your mind's eye.
[00:31:56.600 --> 00:32:00.720]   Some of the resistance or discomfort you feel when you want to just like release that steam
[00:32:00.720 --> 00:32:01.820]   and just let your mind wander.
[00:32:01.820 --> 00:32:07.080]   He got stronger at his ability to focus, which then carried over directly to his academic work.
[00:32:07.120 --> 00:32:12.440]   And he had an easier time with the strain of focusing on math or English paper, whatever
[00:32:12.440 --> 00:32:13.180]   it is he was doing.
[00:32:13.180 --> 00:32:16.760]   And so I use it as a key example of focusing can be trained.
[00:32:16.760 --> 00:32:22.580]   So yes, there could be some value in memory training or any other activity that requires
[00:32:22.580 --> 00:32:26.860]   you to maintain your mind's eye on a target of focus.
[00:32:26.860 --> 00:32:30.300]   And it's because it's not a direct transference.
[00:32:30.300 --> 00:32:34.380]   Like you're using the techniques from memory training exactly when you're studying a math equation.
[00:32:34.380 --> 00:32:39.460]   I think it is that subjective comfort with what it feels like to be focusing and the discomfort
[00:32:39.460 --> 00:32:40.960]   of trying to maintain your attention.
[00:32:40.960 --> 00:32:44.680]   As you get more used to that in one arena, you can carry it over to another.
[00:32:44.680 --> 00:32:49.200]   So, so, I mean, anything that requires you to focus, I think it's useful to do.
[00:32:49.200 --> 00:32:50.700]   It will help in other areas.
[00:32:50.700 --> 00:32:52.740]   Right.
[00:32:52.780 --> 00:32:55.620]   What we got next up is Alexander.
[00:32:55.620 --> 00:33:00.360]   I'm interested in understanding the relationship between creativity and productivity.
[00:33:00.360 --> 00:33:06.440]   Could you clarify whether creativity and productivity are distinct concepts, overlapping or mutually
[00:33:06.440 --> 00:33:07.320]   influential?
[00:33:08.760 --> 00:33:13.620]   First thing I have to emphasize something that if you're not watching, you won't see it.
[00:33:13.620 --> 00:33:15.540]   These headphones I'm wearing right now.
[00:33:15.540 --> 00:33:18.960]   These are the worst headphones I've ever worn.
[00:33:18.960 --> 00:33:22.740]   I feel like, I feel like I have to say this.
[00:33:22.740 --> 00:33:26.260]   I, I grabbed, this is a pair I got for free on a plane.
[00:33:26.840 --> 00:33:33.220]   And based on their quality, roughly in the year 1923, they are, they are terrible.
[00:33:33.220 --> 00:33:39.060]   I think I would literally be better off with a really long piece of yarn connected to tin
[00:33:39.060 --> 00:33:41.060]   cans and holding up to my ear.
[00:33:42.240 --> 00:33:46.620]   I just felt like I needed to say that Jesse, it basically, what it sounds like to me is
[00:33:46.620 --> 00:33:47.460]   that you're in a submarine.
[00:33:47.460 --> 00:33:50.500]   This is what it sounds like in my, we have a very expensive studio setup.
[00:33:50.500 --> 00:33:53.260]   It sounds like to me, you're talking to a $600 microphone or whatever.
[00:33:53.260 --> 00:33:59.400]   It sounds like to me that you're in a submarine and you're like trying to talk through a tube
[00:33:59.400 --> 00:34:03.540]   in the water and I'm on the surface trying to make out what's going on.
[00:34:03.540 --> 00:34:06.860]   So I just want to say yet again, I missed the studio.
[00:34:06.860 --> 00:34:08.740]   This equipment's no good.
[00:34:08.740 --> 00:34:11.380]   I have a nice pair of earphones that are the same color.
[00:34:11.380 --> 00:34:13.960]   I grabbed the, uh, the free ones from the, by accident.
[00:34:13.960 --> 00:34:17.440]   So, ah, see, I think that was going to be the follow-up question.
[00:34:17.440 --> 00:34:18.300]   Yeah.
[00:34:18.300 --> 00:34:19.320]   They look the same.
[00:34:19.320 --> 00:34:20.400]   They look the same.
[00:34:20.400 --> 00:34:20.660]   All right.
[00:34:20.660 --> 00:34:23.760]   Anyways, Alexander's question, creativity versus productivity.
[00:34:23.760 --> 00:34:29.640]   I mean, look, the question, this question should be like self-evident and or absurd, right?
[00:34:29.640 --> 00:34:33.360]   Creativity is creating, um, valuable new things from scratch.
[00:34:33.360 --> 00:34:35.220]   Productivity is production of valuable things.
[00:34:35.220 --> 00:34:36.960]   Like these are like very closely linked ideas.
[00:34:36.960 --> 00:34:38.580]   There really should be no tension between them.
[00:34:38.580 --> 00:34:41.360]   Uh, productivity is just a broader topic.
[00:34:41.360 --> 00:34:45.900]   I suppose creativity is creative output, whereas you can be productive on things that aren't
[00:34:45.900 --> 00:34:49.200]   necessarily creative, but as implied by this question.
[00:34:49.200 --> 00:34:52.820]   So what's important to me is what's implied by the question itself is that we often today
[00:34:52.820 --> 00:34:53.960]   see them as very different.
[00:34:55.000 --> 00:34:59.260]   And the reason why we see these as very different is when we think about productivity, what we're
[00:34:59.260 --> 00:35:01.660]   often really meaning is pseudo productivity.
[00:35:01.660 --> 00:35:06.320]   When we say the word productivity, we often mean this heuristic that says visible activity
[00:35:06.320 --> 00:35:07.980]   is going to be my proxy for useful effort.
[00:35:07.980 --> 00:35:14.920]   Pseudo productivity can stand in contrast to creativity.
[00:35:14.920 --> 00:35:16.900]   Pseudo productivity can get in the way of creativity.
[00:35:16.900 --> 00:35:20.540]   If you're trying to demonstrate effort all the time, you don't have the time and space required
[00:35:20.540 --> 00:35:24.220]   to actually sit there and come up with and polish an idea and then do the hard work of taking
[00:35:24.220 --> 00:35:26.340]   that idea and realizing it concretely in the world.
[00:35:26.340 --> 00:35:30.760]   So yeah, pseudo productivity does not play nicely with creativity.
[00:35:30.760 --> 00:35:35.780]   But if we think about productivity in this actual native sense of just producing stuff that's
[00:35:35.780 --> 00:35:40.600]   valuable in an efficient matter with the resources you have, these are just very closely linked
[00:35:40.600 --> 00:35:40.960]   things.
[00:35:40.960 --> 00:35:45.760]   I want to be a productive creative means I want to produce like really good creative
[00:35:45.760 --> 00:35:48.380]   work in like a reasonably efficient manner.
[00:35:48.380 --> 00:35:50.740]   So they shouldn't be different.
[00:35:50.740 --> 00:35:55.900]   The fact that they're being presented as intention, I think is more an indictment about the way we
[00:35:55.900 --> 00:35:59.200]   think about productivity, which itself is an indictment of our current world of work.
[00:35:59.200 --> 00:36:04.340]   But when it comes to like the reality of things, create a production is like one of the key things
[00:36:04.340 --> 00:36:05.520]   you might want to be productive about.
[00:36:05.520 --> 00:36:07.460]   So I don't see them in reality.
[00:36:07.460 --> 00:36:08.800]   I don't see them being contrary at all.
[00:36:10.420 --> 00:36:16.000]   All right, who we got next up is Sydney between your teaching, researching, writing, blogging
[00:36:16.000 --> 00:36:16.900]   and podcasting.
[00:36:16.900 --> 00:36:21.320]   It'd be fascinating to hear your insights into how each contribute to your personal lifestyle
[00:36:21.320 --> 00:36:22.620]   centric career planning.
[00:36:22.620 --> 00:36:25.500]   So there's a couple of keys in my lifestyle vision.
[00:36:25.500 --> 00:36:26.940]   One is autonomy.
[00:36:26.940 --> 00:36:28.360]   All right.
[00:36:28.360 --> 00:36:32.460]   So I really like to have control over my time to make my own decisions about what I'm going
[00:36:32.460 --> 00:36:35.700]   to do when because of that.
[00:36:35.700 --> 00:36:39.120]   Another big part of my vision is I do not like crowded calendar days.
[00:36:39.940 --> 00:36:46.300]   OK, they're OK occasionally, but I do not want to feel like my day is full of stuff on a
[00:36:46.300 --> 00:36:47.900]   calendar and I have to go from thing to thing.
[00:36:47.900 --> 00:36:49.020]   I want autonomy.
[00:36:49.020 --> 00:36:51.840]   I want some days that are heavier than others.
[00:36:51.840 --> 00:36:53.740]   I don't want most of my days to be full of things.
[00:36:53.740 --> 00:36:56.060]   And I really wanted huge seasonality.
[00:36:56.060 --> 00:36:59.320]   So this is just like the profession, some of the professional aspects of my lifestyle plan.
[00:36:59.320 --> 00:37:00.180]   It's more broad than that.
[00:37:01.220 --> 00:37:06.280]   Busy periods, non-busy periods, periods where I'm monk mode writing, where other periods
[00:37:06.280 --> 00:37:07.880]   where I'm like interacting with other people.
[00:37:07.880 --> 00:37:09.200]   I like that variation as well.
[00:37:09.200 --> 00:37:14.300]   So by creating a life as a writer and professor, I'm really hitting that vision.
[00:37:14.300 --> 00:37:16.380]   There's a lot of autonomy in being a professor.
[00:37:16.380 --> 00:37:21.500]   Writing allows me to amplify my impact more than it would be as a professor.
[00:37:21.500 --> 00:37:27.580]   And it allows me to, it gives me more flexibility financially and otherwise.
[00:37:27.580 --> 00:37:32.980]   Some ways, some changes I've made working backwards from that lifestyle vision, because I have that
[00:37:32.980 --> 00:37:33.580]   vision in mind.
[00:37:33.580 --> 00:37:35.300]   There's some key changes I've made.
[00:37:35.300 --> 00:37:41.020]   Like, for example, more recently, I've really moved, at least for now, my academic profile
[00:37:41.020 --> 00:37:47.400]   away from pure computer science and more towards technocriticism, the impact of technology on society,
[00:37:47.400 --> 00:37:50.920]   became a founding member of the Center for Digital Ethics, you know, here at Georgetown.
[00:37:50.920 --> 00:37:54.120]   That bought out one of my courses, so it reduced my course load even further.
[00:37:54.120 --> 00:37:57.980]   And I sort of fused together my academic work and my writing work.
[00:37:57.980 --> 00:38:01.900]   So like my New Yorker articles, and so the academic articles I'm working on about technology,
[00:38:01.900 --> 00:38:03.140]   these are sort of interchangeable.
[00:38:03.140 --> 00:38:05.080]   So I don't have such split efforts.
[00:38:05.080 --> 00:38:09.700]   By temporarily, at least for now, moving my academic portfolio more towards digital ethics,
[00:38:09.700 --> 00:38:14.920]   it also took off on my plate, all of the time overhead of trying to acquire and manage grants,
[00:38:14.920 --> 00:38:21.440]   supervision of students, working on like unrelated computer science papers, traveling for like
[00:38:21.440 --> 00:38:25.280]   conferences, collaboration, like there's a huge amount of time that I would, I have now to try to
[00:38:25.280 --> 00:38:30.600]   see closer to my lifestyle vision said, no, I'm going to go all in on technology and its impact.
[00:38:30.600 --> 00:38:31.440]   Let's see how that goes.
[00:38:31.440 --> 00:38:32.700]   We'll try that for a year or two.
[00:38:32.700 --> 00:38:35.460]   That's a decision you make when you have lifestyle-centric career planning.
[00:38:35.460 --> 00:38:38.520]   It's not a decision you make when you just think, how do I do things even better?
[00:38:38.520 --> 00:38:42.360]   You don't give up things that you're doing well at when you're just in an achievement
[00:38:42.360 --> 00:38:43.260]   or a focused way.
[00:38:43.260 --> 00:38:46.920]   But for me, I said, look, these things have to be more consilient because otherwise they're
[00:38:46.920 --> 00:38:48.280]   starting to make my calendar too crowded.
[00:38:48.280 --> 00:38:49.820]   That goes against my lifestyle vision.
[00:38:49.820 --> 00:38:51.840]   It's reducing my impact.
[00:38:51.840 --> 00:38:53.240]   That goes against my lifestyle vision.
[00:38:53.240 --> 00:38:58.340]   I want to be spending a good amount of my time thinking hard about things to make an impact.
[00:38:58.340 --> 00:38:59.880]   Am I bringing these two worlds closer together?
[00:38:59.880 --> 00:39:00.540]   I can do that.
[00:39:01.280 --> 00:39:04.620]   So, you know, this is an example of lifestyle-centric planning.
[00:39:04.620 --> 00:39:07.980]   These various parts of my vision is making me lead to various changes.
[00:39:07.980 --> 00:39:11.420]   It's helping me navigate these various careers in a lot of other ways.
[00:39:11.420 --> 00:39:14.080]   I'm not talking about publicly yet either, but I think about it all the time.
[00:39:14.080 --> 00:39:16.240]   And it gives me a big foundation to make these decisions.
[00:39:16.240 --> 00:39:20.640]   If I'm just chasing what's like the best I can do here, what's the best I can do there,
[00:39:20.640 --> 00:39:24.360]   then it's just all this stuff's going to collide into each other and I'm going to burn out.
[00:39:25.360 --> 00:39:30.720]   So, I think about this a lot and my lifestyle-centric plan, which I update every year,
[00:39:30.720 --> 00:39:34.440]   plays a big role in how I try to make decisions about what to do or what not to do.
[00:39:34.440 --> 00:39:38.140]   But anyways, I think that's a big decision, reducing computer science at least for now.
[00:39:38.140 --> 00:39:39.580]   That's a huge decision.
[00:39:39.580 --> 00:39:43.420]   That's a lifestyle-centric career planning influence decision for sure.
[00:39:43.420 --> 00:39:47.180]   All right, we have a case study here.
[00:39:47.180 --> 00:39:52.240]   This is where people send in their accounts of using the type of advice we talk about on
[00:39:52.240 --> 00:39:53.280]   the show in their own life.
[00:39:53.280 --> 00:39:55.220]   We need some more, by the way.
[00:39:55.900 --> 00:39:57.380]   Oh, all right.
[00:39:57.380 --> 00:39:57.940]   So, we need more.
[00:39:57.940 --> 00:40:01.180]   Send them to jesse at calnewport.com, right?
[00:40:01.180 --> 00:40:01.820]   Yep.
[00:40:01.820 --> 00:40:04.180]   You can send us directly to jesse.
[00:40:04.180 --> 00:40:10.920]   We love hearing specifics about what advice you applied and what results you had.
[00:40:10.920 --> 00:40:12.600]   All right.
[00:40:12.600 --> 00:40:13.040]   Let's do one second.
[00:40:13.040 --> 00:40:16.980]   You got me excited, jesse, and I swallowed water down the wrong tube.
[00:40:16.980 --> 00:40:18.320]   So, there you go.
[00:40:18.320 --> 00:40:19.960]   I'm better now.
[00:40:19.960 --> 00:40:20.660]   All right.
[00:40:20.660 --> 00:40:23.580]   Today's case study is from retiree who says,
[00:40:23.700 --> 00:40:27.640]   I love adapting Cal's practices to the range of activities I undertake in my personal
[00:40:27.640 --> 00:40:31.740]   life, volunteer work, life management, deepening hobbies, and interest.
[00:40:31.740 --> 00:40:36.420]   Today, I had some fun thinking how I had used a range of Cal-isms.
[00:40:37.420 --> 00:40:42.240]   In my new time block planner, I've decided to have themes for a morning's task to avoid
[00:40:42.240 --> 00:40:43.140]   context switching.
[00:40:43.140 --> 00:40:45.040]   And today, my theme was health.
[00:40:45.040 --> 00:40:49.700]   And specifically, dealing with planning my next steps in recovering from a long-term mobility
[00:40:49.700 --> 00:40:50.080]   issue.
[00:40:51.080 --> 00:40:55.600]   So, one, a concentrated period of making a query about my medical insurance and its coverage.
[00:40:55.600 --> 00:40:58.820]   I hesitate to call this deep work, but it requires sustained concentration.
[00:40:58.820 --> 00:41:02.600]   I wonder whether others use self-talk during tasks which need persistence over a long period
[00:41:02.600 --> 00:41:03.020]   of focusing.
[00:41:03.020 --> 00:41:06.760]   For fun, I noted these down today when I was tempted to divert my attention.
[00:41:07.620 --> 00:41:08.480]   That's not for now.
[00:41:08.480 --> 00:41:09.900]   Worry about that later.
[00:41:09.900 --> 00:41:10.640]   That's not urgent.
[00:41:10.640 --> 00:41:11.380]   Stay on task.
[00:41:11.380 --> 00:41:12.000]   You're nearly there.
[00:41:12.000 --> 00:41:13.140]   All right.
[00:41:13.140 --> 00:41:14.480]   Number two, then he...
[00:41:14.480 --> 00:41:18.800]   So, I think he's talking about here, by the way, what he did during his health-themed
[00:41:18.800 --> 00:41:19.320]   morning.
[00:41:19.320 --> 00:41:19.680]   All right.
[00:41:19.680 --> 00:41:24.840]   The second thing he did, he tackled a related subject because my brain was in the zone.
[00:41:25.080 --> 00:41:27.840]   It was investigating ordering some orthotic shoes online.
[00:41:27.840 --> 00:41:32.120]   And then three, and he says, this is one I'm very proud of, is I searched for and found
[00:41:32.120 --> 00:41:36.980]   an appropriate YouTube videos of chair-based yoga and did a 20-minute session.
[00:41:36.980 --> 00:41:40.840]   Much of this got done as a result of deciding an overall context.
[00:41:40.840 --> 00:41:45.500]   Apologies for the detail, but it amused me to see how, over the years of listening to Cal,
[00:41:45.500 --> 00:41:48.860]   various elements or practices have become a way of life.
[00:41:48.860 --> 00:41:52.540]   And having written this email, I have included another element, reflection for future learning,
[00:41:52.540 --> 00:41:55.060]   from the episode with David Epstein.
[00:41:55.060 --> 00:41:55.620]   All right.
[00:41:55.620 --> 00:41:56.400]   I like this.
[00:41:56.400 --> 00:41:57.020]   Themes.
[00:41:57.020 --> 00:42:00.980]   I'm a big believer in cognitive context shifting is a real issue.
[00:42:00.980 --> 00:42:03.160]   It is expensive and you can't do too much of it.
[00:42:03.160 --> 00:42:10.680]   If you connect multiple tasks in a row that are on the same cognitive context, they exist
[00:42:10.680 --> 00:42:14.340]   in the same kind of context, it is easier than if you switch between things that are completely
[00:42:14.340 --> 00:42:14.960]   unrelated.
[00:42:14.960 --> 00:42:18.240]   So, retiree here shows that, right?
[00:42:18.240 --> 00:42:22.420]   These three things were related to the same theme and he was able to stick with them more
[00:42:22.420 --> 00:42:23.160]   and get through them better.
[00:42:23.480 --> 00:42:28.780]   This is why checking your email inbox is such a calamity because nothing induces more cognitive
[00:42:28.780 --> 00:42:32.860]   context shifts than going from one message to another that are essentially arbitrarily ordered.
[00:42:32.860 --> 00:42:36.040]   It is a brain scrambler.
[00:42:36.160 --> 00:42:40.740]   I'm a huge believer in theming things, stick on one theme for a while, take a break, stick
[00:42:40.740 --> 00:42:41.260]   on another.
[00:42:41.260 --> 00:42:44.400]   So, this is a great example of that in practice.
[00:42:44.400 --> 00:42:48.160]   I also, I don't know how I feel about the word cowlism, but maybe.
[00:42:48.160 --> 00:42:49.520]   Cowlisms.
[00:42:49.520 --> 00:42:50.200]   Yeah.
[00:42:50.420 --> 00:42:51.140]   I'll think about it.
[00:42:51.140 --> 00:42:52.580]   Do we have a call this week?
[00:42:52.580 --> 00:42:53.300]   We do.
[00:42:53.300 --> 00:42:53.820]   All right.
[00:42:53.820 --> 00:42:54.380]   Let's hear this.
[00:42:54.380 --> 00:42:56.180]   Hi, Cal.
[00:42:56.180 --> 00:43:01.720]   My name's Juan and I wanted to ask you some advice on some extended adventure working.
[00:43:02.440 --> 00:43:05.820]   I'm currently hiking the Continental Divide Trail.
[00:43:05.820 --> 00:43:12.360]   I'm taking a pit stop in Santa Fe, New Mexico, before continuing on through the snowy mountains
[00:43:12.360 --> 00:43:13.360]   of Southern Colorado.
[00:43:13.360 --> 00:43:18.800]   And yeah, for the next five months, my only real priority is to make it through this next
[00:43:18.800 --> 00:43:19.180]   adventure.
[00:43:19.680 --> 00:43:23.720]   However, I don't completely want to pause my creative life.
[00:43:23.720 --> 00:43:29.240]   I draw graphic novels for fun, and I'd love for my next project to be about this hike I'm
[00:43:29.240 --> 00:43:30.020]   doing right now.
[00:43:30.020 --> 00:43:36.760]   So, this brought to mind your idea of adventure work, where you make progress on work by engaging
[00:43:36.760 --> 00:43:40.040]   with ideas while immersed in a totally unrelated environment.
[00:43:40.040 --> 00:43:46.120]   How would you recommend that I use my time on this hike towards that goal?
[00:43:46.760 --> 00:43:50.780]   I have some pocket notebooks that I could use as sketchbooks or single-purpose notebooks,
[00:43:50.780 --> 00:43:52.560]   and I also have a journal.
[00:43:52.560 --> 00:43:58.060]   However, the vast majority of my time needs to be spent on the trail so that I can cover
[00:43:58.060 --> 00:44:00.880]   the 20 or 25 miles that I need to do each day.
[00:44:00.880 --> 00:44:10.500]   And it's also a little unpredictable if I have the energy and time or even the physical environment
[00:44:10.500 --> 00:44:12.940]   during my breaks to really make progress.
[00:44:12.940 --> 00:44:15.740]   So, yeah, thank you for your thoughts.
[00:44:15.740 --> 00:44:21.100]   I love the show, and though I'm giving myself plenty of space away from the inputs of other
[00:44:21.100 --> 00:44:24.320]   minds on the trail, I'm still keeping up with all your new episodes.
[00:44:25.940 --> 00:44:27.500]   Oh, I love the idea of adventure work.
[00:44:27.500 --> 00:44:28.660]   It's good to bring that back.
[00:44:28.660 --> 00:44:33.800]   This is this notion, as talked about there by the caller, of when you go to cool places
[00:44:33.800 --> 00:44:36.560]   or interesting places to do your work, it's more interesting.
[00:44:36.560 --> 00:44:40.320]   You have deeper insights, and it makes worse, less draining.
[00:44:40.320 --> 00:44:43.820]   I mean, this look I already talked about earlier in the show that I worked by the fountains at the
[00:44:43.820 --> 00:44:44.780]   Anaheim Convention Center.
[00:44:45.180 --> 00:44:47.960]   I'm going to write on Splash Mountain tomorrow.
[00:44:47.960 --> 00:44:49.940]   It's going to be brilliant.
[00:44:49.940 --> 00:44:54.600]   Like, as I said, when I contemplated the, ah, shit, it's wet.
[00:44:54.600 --> 00:44:55.700]   And then that's the end of it.
[00:44:55.700 --> 00:44:58.040]   Adventure work's a cool idea.
[00:44:58.400 --> 00:45:01.420]   Okay, so first of all, you're doing this thing that's using a lot of focus.
[00:45:01.420 --> 00:45:02.800]   You're hiking the Continental Divide Trail.
[00:45:02.800 --> 00:45:07.020]   So you keep your standards, your expectations very reasonable, real slow productivity idea.
[00:45:07.020 --> 00:45:10.880]   So look, I think I can get some cool insights doing this and some cool ideas that can lead
[00:45:10.880 --> 00:45:11.420]   to a book.
[00:45:12.260 --> 00:45:17.640]   Do not turn that into, okay, I need to optimize, like, every day, if I could, this is a pseudo
[00:45:17.640 --> 00:45:18.360]   productivity mindset.
[00:45:18.360 --> 00:45:21.540]   Well, if I could produce five pages a day, I could have a book done by the time I'm done
[00:45:21.540 --> 00:45:24.380]   hiking the trail, and then you're up late at night with your headlamp on, trying to, like,
[00:45:24.380 --> 00:45:25.600]   draw pages of a graphic novel.
[00:45:25.600 --> 00:45:26.540]   You don't want to do that.
[00:45:26.540 --> 00:45:33.260]   What you do want to do is maybe say, what's an idea I want to work out that might be relevant
[00:45:33.260 --> 00:45:34.420]   to the book I want to do?
[00:45:34.420 --> 00:45:36.120]   Like, what's something I could do that's different?
[00:45:36.120 --> 00:45:40.900]   Like, let me just play with this on the trail and take notes in my single, special, single
[00:45:40.900 --> 00:45:43.680]   topic notebook, like a feels note notebook at the end of the day.
[00:45:43.680 --> 00:45:47.140]   And then maybe I have some breakthroughs and take your time, go slow.
[00:45:47.140 --> 00:45:50.840]   Or I have this interesting idea about what would be new about a graphic novel.
[00:45:50.840 --> 00:45:52.980]   Let me kind of work through the plotting a little bit.
[00:45:52.980 --> 00:45:56.100]   As I have, you know, some parts of the walk, I'm thinking, I want to take a water break,
[00:45:56.100 --> 00:45:56.580]   I'll jot it down.
[00:45:56.580 --> 00:45:58.780]   Other parts of the walk, I'm not thinking about it at all.
[00:45:58.780 --> 00:46:02.440]   But over the days, maybe this interesting outline comes up.
[00:46:02.440 --> 00:46:06.340]   And when you take your time, some really interesting stuff happens.
[00:46:06.340 --> 00:46:10.600]   You edit yourself, you come back, you let things marinate, you improve it.
[00:46:11.260 --> 00:46:15.900]   And what you end up with might not be like a lot of pages of material, but it could be
[00:46:15.900 --> 00:46:16.960]   really good in original.
[00:46:16.960 --> 00:46:21.360]   Yeah, I spent four days just like bouncing around, like what would be good in a novel?
[00:46:21.360 --> 00:46:22.800]   What am I missing in a graphic novel?
[00:46:22.800 --> 00:46:23.500]   What would be different?
[00:46:23.500 --> 00:46:25.660]   And then I worked on this plot off and on.
[00:46:25.660 --> 00:46:26.340]   And yeah, it's an outline.
[00:46:26.340 --> 00:46:27.540]   It's just a few pages long.
[00:46:27.540 --> 00:46:30.100]   But I came back to it and this isn't right.
[00:46:30.100 --> 00:46:30.980]   And what if I did this?
[00:46:30.980 --> 00:46:32.220]   And you know, and I like this.
[00:46:32.220 --> 00:46:34.980]   I just let it sit and marinate and see what resonated, what didn't.
[00:46:34.980 --> 00:46:37.220]   In the end, I produced something that's really cool and original.
[00:46:37.560 --> 00:46:40.780]   Now when I'm done hiking, I'll sit down and do, you know, three hours a day and do my
[00:46:40.780 --> 00:46:45.060]   deep work and turn this into an actual graphic novel and do that sort of more harding, hard
[00:46:45.060 --> 00:46:46.740]   sort of grinding aspect of the work.
[00:46:46.740 --> 00:46:52.480]   So use the adventure work and just like take your time producing some original thoughts and
[00:46:52.480 --> 00:46:54.180]   really getting them to a place you're happy with.
[00:46:54.180 --> 00:46:55.340]   Don't worry about volume.
[00:46:55.340 --> 00:46:56.660]   Worry about quality.
[00:46:56.660 --> 00:46:58.380]   Don't worry about speed.
[00:46:58.380 --> 00:47:00.080]   Worry about originality.
[00:47:00.080 --> 00:47:02.200]   And some days you might not do anything.
[00:47:02.200 --> 00:47:04.700]   You guys have some single purpose notebooks to capture this.
[00:47:04.780 --> 00:47:08.000]   And you might only end up with one single purpose notebook full of notes, but those might
[00:47:08.000 --> 00:47:09.640]   be some of the best notes you produce.
[00:47:09.640 --> 00:47:11.940]   I'm a big believer in adventure work for creative work.
[00:47:11.940 --> 00:47:14.160]   So give that a try and keep hiking.
[00:47:14.160 --> 00:47:15.740]   All right.
[00:47:15.740 --> 00:47:17.200]   We got a final segment coming up here.
[00:47:17.200 --> 00:47:19.520]   We call it what to read.
[00:47:19.520 --> 00:47:24.540]   Talk about reading recommendations, be it books or articles, get into some content as well.
[00:47:24.540 --> 00:47:26.420]   So I'm excited to get into that.
[00:47:26.420 --> 00:47:30.320]   But first, let's hear from another sponsor.
[00:47:30.320 --> 00:47:34.780]   Let's talk about our friends at Shopify.
[00:47:34.780 --> 00:47:40.800]   Look, there's nothing small about starting your own small business.
[00:47:40.800 --> 00:47:45.020]   In fact, there's nothing bigger than the heart and soul poured into your business, whether
[00:47:45.020 --> 00:47:50.780]   that is selling a product or in my case, hosting and running a podcast.
[00:47:51.200 --> 00:47:55.880]   What small decisions, what can seem like a small decision on the outside could be like
[00:47:55.880 --> 00:48:00.380]   a really big decision to you who's running this thing that's so important to you.
[00:48:00.380 --> 00:48:06.040]   This is where Shopify enters the scene, because when it comes to decisions about how you're
[00:48:06.040 --> 00:48:09.420]   going to sell things, Shopify will make that all easy.
[00:48:09.420 --> 00:48:13.200]   We'll clear up your brain to think about the other stuff that matters more.
[00:48:13.200 --> 00:48:17.720]   If you're going to be selling things, you should be using Shopify.
[00:48:17.940 --> 00:48:21.380]   Shopify is a commerce platform behind millions of businesses around the world.
[00:48:21.380 --> 00:48:24.980]   10% of all e-commerce in the U.S. goes through this.
[00:48:24.980 --> 00:48:29.140]   Whether we're talking about Mattel and Gymshark or new brands are just getting started, they
[00:48:29.140 --> 00:48:30.540]   rely on Shopify.
[00:48:30.540 --> 00:48:34.740]   It takes all your important tasks related to selling things and puts them in one place from
[00:48:34.740 --> 00:48:37.280]   inventory to payments to analytics.
[00:48:37.280 --> 00:48:38.940]   It helps you with marketing.
[00:48:38.940 --> 00:48:41.240]   It helps you with international sales.
[00:48:41.240 --> 00:48:44.480]   It can work in over 150 different countries.
[00:48:44.480 --> 00:48:48.640]   If you're selling stuff in person, they have point-to-sale tools that are award-winning
[00:48:48.640 --> 00:48:52.020]   that connect into the same system so you can connect them to your online sales.
[00:48:52.020 --> 00:48:58.100]   And it has 99.99% uptime and the best converting checkout on the planet.
[00:48:58.100 --> 00:48:59.180]   Look, this is a no-brainer.
[00:48:59.180 --> 00:49:03.920]   If you're running a small business and you need to sell some things, you need to use Shopify.
[00:49:03.920 --> 00:49:08.220]   Get all the big stuff for your small business right with Shopify.
[00:49:08.840 --> 00:49:14.060]   Sign up for your $1 per month trial and start selling today at shopify.com slash deep.
[00:49:14.060 --> 00:49:19.180]   Go to shopify.com slash deep, shopify.com slash deep.
[00:49:19.180 --> 00:49:22.400]   I also want to talk about my friends at My Body Tutor.
[00:49:22.400 --> 00:49:27.180]   If you want to get healthier, what's getting in your way?
[00:49:27.180 --> 00:49:28.080]   Is it lack of information?
[00:49:28.080 --> 00:49:28.740]   Not really.
[00:49:28.740 --> 00:49:33.820]   You know enough to get started if you really wanted to about eating and exercise.
[00:49:34.300 --> 00:49:35.200]   It's consistency.
[00:49:35.200 --> 00:49:38.340]   It's just easy to say maybe tomorrow.
[00:49:38.340 --> 00:49:40.840]   This is where My Body Tutor enters the scene.
[00:49:40.840 --> 00:49:42.240]   The premise is really simple.
[00:49:42.240 --> 00:49:46.480]   They connect you to one of their coaches online.
[00:49:46.480 --> 00:49:50.580]   The coach helps you design a plan for nutrition and fitness.
[00:49:50.580 --> 00:49:53.360]   And then using this easy-to-use app, and I've tried this.
[00:49:53.360 --> 00:49:54.400]   It is easy to use.
[00:49:54.400 --> 00:49:56.720]   You check in with that coach every day.
[00:49:56.720 --> 00:49:58.020]   It doesn't take long.
[00:49:58.480 --> 00:50:04.100]   But there's accountability in having to check in with the coach on how it went, what you ate, what type of exercise you did.
[00:50:04.100 --> 00:50:07.620]   That little bit of accountability makes all of the difference.
[00:50:07.620 --> 00:50:10.860]   And it gets you over that little hump of, eh, maybe tomorrow?
[00:50:10.860 --> 00:50:13.560]   And you're like, no, I don't want to have to tell my coach I didn't do it today.
[00:50:13.560 --> 00:50:16.580]   And it gets you actually doing the stuff you know you need to do.
[00:50:16.580 --> 00:50:18.080]   Also, you get the expert coaching, right?
[00:50:18.080 --> 00:50:19.120]   I mean, some of the stuff is hard.
[00:50:19.120 --> 00:50:20.340]   Like, what is going on with my diet?
[00:50:20.800 --> 00:50:23.300]   I'm trying to exercise, but my elbow is hurting.
[00:50:23.300 --> 00:50:24.760]   Or what type of exercise should I be doing?
[00:50:24.760 --> 00:50:26.280]   And so that takes care of all that as well.
[00:50:26.280 --> 00:50:28.160]   Or you're traveling like I am right now.
[00:50:28.160 --> 00:50:32.900]   Your coach can be like, yeah, let me help you come up with an alternative routine to use during the travel.
[00:50:32.900 --> 00:50:34.280]   Or you have the holidays coming up.
[00:50:34.280 --> 00:50:38.040]   I'm going to give you some strategies to get through those without going crazy on the food.
[00:50:38.040 --> 00:50:40.160]   So having a coach makes a huge difference.
[00:50:40.160 --> 00:50:43.080]   And My Body Tutor makes this affordable by offering it online.
[00:50:43.080 --> 00:50:44.360]   You connect to them online.
[00:50:44.360 --> 00:50:48.420]   If you want to get healthy, use My Body Tutor.
[00:50:49.500 --> 00:50:53.540]   Good news, if you mention deep questions when you sign up, you will get $50 off your first month.
[00:50:53.540 --> 00:50:56.540]   Just mention it, and they will give you $50 off.
[00:50:56.540 --> 00:51:01.040]   So find out more at MyBodyTutor.com, T-U-T-O-R, MyBodyTutor.com.
[00:51:01.040 --> 00:51:04.140]   Mention deep questions to get $50 off your first month.
[00:51:04.140 --> 00:51:07.280]   All right, Jesse, let's move on to our final segment.
[00:51:07.280 --> 00:51:15.220]   So I'll start by mentioning a book that is coming out the day after this podcast airs.
[00:51:15.220 --> 00:51:16.160]   It's a book I blurbed.
[00:51:16.740 --> 00:51:21.100]   It's called Unplugged, How to Break Up with Your Phone and Reclaim Your Life.
[00:51:21.100 --> 00:51:23.020]   It's by Richard Simon, who I know from Georgetown.
[00:51:23.020 --> 00:51:29.120]   What I liked about this book, why I'm recommending it, yes, we've heard about this topic before.
[00:51:29.120 --> 00:51:33.200]   Like, hey, strategies for, you know, disconnecting.
[00:51:33.400 --> 00:51:38.020]   What made this book cool is it is lots of real stories.
[00:51:38.020 --> 00:51:47.240]   So Richard's approach is, let me get people who have done radical or interesting things to get the phone out of their life and talk to them and tell you their stories.
[00:51:47.240 --> 00:51:53.040]   There's 25 different stories in there, plus the bonus 26th story, which is Richard's own cool story of disconnection.
[00:51:53.920 --> 00:52:03.680]   Some people, including some people who are pretty well-known, Jesse, you'll be happy to hear the Phillies player, Nick Castellanos, professional baseball player.
[00:52:03.680 --> 00:52:05.640]   He's in the book, talks about it.
[00:52:05.640 --> 00:52:08.600]   Steve Hilton, a cable news host, is in there.
[00:52:08.600 --> 00:52:09.740]   Regular people as well.
[00:52:09.740 --> 00:52:11.860]   Principals, pastors, a couple who did it together.
[00:52:12.660 --> 00:52:14.520]   Anyways, that's what I like about this book.
[00:52:14.520 --> 00:52:20.760]   If you want to hear how real people, like real things they did and what happened to get rid of their phone, you're looking for something more radical, check it out.
[00:52:20.760 --> 00:52:21.380]   I blurbed it.
[00:52:21.380 --> 00:52:22.040]   Here's my blurb.
[00:52:22.040 --> 00:52:22.820]   I'll read it to you now.
[00:52:22.820 --> 00:52:35.300]   Diving deep into the growing community of people who radically reinvented their relationships with their phones, Richard Simon identifies a roadmap for the rest of us to achieve a less distracted and more meaningful life.
[00:52:35.300 --> 00:52:38.160]   The quote right after mine was from Cal Network.
[00:52:38.160 --> 00:52:42.120]   And it says, I'm not distracted by my phone.
[00:52:42.400 --> 00:52:46.120]   My phone is distracted by me, Cal Network.
[00:52:46.120 --> 00:52:48.380]   Go get it.
[00:52:48.380 --> 00:52:49.120]   So there you go.
[00:52:49.120 --> 00:52:50.800]   Both me and Cal Network blurbed this book.
[00:52:50.800 --> 00:52:51.440]   All right.
[00:52:51.440 --> 00:52:52.940]   I also want to talk about two articles.
[00:52:52.940 --> 00:52:54.580]   I like books.
[00:52:54.580 --> 00:52:55.460]   I like articles.
[00:52:55.460 --> 00:52:58.620]   The ones I want to talk about today, here's what caught my attention.
[00:52:58.620 --> 00:53:01.180]   They're both on the same topic.
[00:53:01.180 --> 00:53:06.360]   AI, in particular, large language models and their ability to reason.
[00:53:06.360 --> 00:53:07.980]   They're both recent.
[00:53:07.980 --> 00:53:11.700]   These articles both come from the last month or so.
[00:53:12.140 --> 00:53:14.960]   And they have two very different takes.
[00:53:14.960 --> 00:53:19.120]   So I want to dive into this a little bit and try to understand what's going on here.
[00:53:19.120 --> 00:53:22.020]   Links to these articles are in the show notes if you want to dive deeper yourself.
[00:53:22.220 --> 00:53:28.840]   I'm also going to argue this as there's a general strategy for reading that these two articles are going to provide an example of.
[00:53:28.840 --> 00:53:30.640]   So let me bring up the first article here.
[00:53:30.640 --> 00:53:32.200]   Jesse, let's see if we can bring this up on the screen.
[00:53:32.200 --> 00:53:33.720]   The Scientific American article.
[00:53:33.720 --> 00:53:34.860]   Okay.
[00:53:35.560 --> 00:53:37.480]   The headline of this article.
[00:53:37.480 --> 00:53:38.580]   So you can see it on the screen there.
[00:53:38.580 --> 00:53:40.360]   The headline of this article is,
[00:53:40.360 --> 00:53:46.460]   At Secret Math Meeting, Researchers Struggle to Outsmart AI.
[00:53:47.540 --> 00:53:49.840]   I'm going to read a quote from the beginning of this article here.
[00:53:49.840 --> 00:53:55.780]   On a weekend in mid-May, a clandestine mathematical conclave convened.
[00:53:55.780 --> 00:53:57.180]   It's a lot of alliteration.
[00:53:57.180 --> 00:54:04.100]   30 of the world's most renowned mathematicians traveled to Berkeley, California, with some coming as far away as the UK.
[00:54:04.520 --> 00:54:12.340]   The group's member faced off in a showdown with a reasoning chatbot that was tasked with solving problems they had devised to test its mathematical mettle.
[00:54:12.340 --> 00:54:21.020]   After throwing professor-level questions at the bot for two days, the researchers were stunned to discover it was capable of answering some of the world's hardest solvable problems.
[00:54:21.020 --> 00:54:29.600]   I have colleagues who literally said these models are approaching mathematical genius, said Ken Ono, a mathematician at the University of Virginia and a leader and judge at the meeting.
[00:54:29.600 --> 00:54:31.880]   All right, so we can bring that down, Jesse.
[00:54:33.160 --> 00:54:41.480]   You read that article, you're like, oh my God, these AIs are so powerful now that they become math geniuses and are solving like the hardest problems.
[00:54:41.480 --> 00:54:46.020]   And I mean, what else are they, what else can't they do?
[00:54:46.020 --> 00:54:50.440]   I mean, this is pretty optimistic, pretty impressive, pretty scary.
[00:54:50.440 --> 00:54:54.100]   But then we get article number two, came out right around the same time.
[00:54:54.100 --> 00:54:56.520]   Let's bring this up on the screen here, Jesse.
[00:54:56.520 --> 00:55:01.480]   This article is coming from The Guardian and this came out last week.
[00:55:01.480 --> 00:55:03.580]   All right, here's the headline here.
[00:55:03.580 --> 00:55:10.540]   When billion-dollar AIs break down over puzzles a child can do, it's time to rethink the hype.
[00:55:10.540 --> 00:55:13.420]   And this is by the AI centrist, Gary Marcus.
[00:55:13.420 --> 00:55:15.380]   Gary sometimes rub people's the wrong way.
[00:55:15.380 --> 00:55:16.860]   I've been reading a lot of Gary Marcus recently.
[00:55:16.860 --> 00:55:20.740]   The content of what he's saying, I think, is often very, very solid.
[00:55:20.740 --> 00:55:22.280]   Do not sleep on Gary Marcus.
[00:55:22.280 --> 00:55:25.500]   All right, let me read a quote from this article.
[00:55:25.560 --> 00:55:38.040]   The Towers of Hanoi is a classic game with three pegs and multiple disks in which you need to move all the disks on the left peg to the right peg, never stacking a larger disk on top of a smaller one.
[00:55:38.040 --> 00:55:41.760]   With practice, though, a bright and patient seven-year-old can do it.
[00:55:42.140 --> 00:55:50.260]   What Apple found, he's citing here a paper from Apple AI researchers that's really been stirring people up in the last couple of weeks.
[00:55:50.260 --> 00:56:00.260]   What Apple found was that leading generative models could barely do seven disks, getting less than 80% accuracy, and pretty much can't get scenarios with eight disks correct at all.
[00:56:01.060 --> 00:56:04.660]   It is truly embarrassing that LLMs cannot reliably solve Hanoi.
[00:56:04.660 --> 00:56:12.080]   And as the paper's co-lead author, Ayman Mazzotti, told me via DM, it's not just about solving the puzzle.
[00:56:12.080 --> 00:56:16.420]   We have an experiment where we give the solution algorithm to the model, and the model still failed.
[00:56:16.420 --> 00:56:20.560]   Based on what we observe from their thoughts, their process is not logical and intelligent.
[00:56:20.560 --> 00:56:22.760]   All right, we can take that off the screen, Jesse.
[00:56:23.600 --> 00:56:31.860]   So we got one article saying, oh, my God, these reasoning models are solving, like, the world's hardest math problems, and these math professors can't keep up.
[00:56:31.860 --> 00:56:38.380]   Same article, really simple kids' problems that aren't too hard to do are failing.
[00:56:38.380 --> 00:56:41.360]   And even if we tell the bot, here's how you do it.
[00:56:41.360 --> 00:56:43.380]   So Towers of Hanoi comes up in computer science.
[00:56:43.380 --> 00:56:48.140]   There's, like, a classic simple solution to it that you use when you're learning recursion.
[00:56:48.140 --> 00:56:49.340]   It's like a freshman in computer science.
[00:56:49.340 --> 00:56:50.100]   They, like, told it.
[00:56:50.100 --> 00:56:51.460]   Here's, like, the algorithm to solve it.
[00:56:51.460 --> 00:56:57.180]   These generative models have no notion of, like, how to take what you've told them and execute it.
[00:56:57.180 --> 00:57:01.620]   And so they're arguing, how can we think of these as being generally reasoning machines?
[00:57:01.620 --> 00:57:06.680]   We have these, like, two conflicting takes on exactly the same thing, reasoning LLM models.
[00:57:06.680 --> 00:57:11.600]   All right, this is a great opportunity to try out something I've written about before.
[00:57:11.600 --> 00:57:13.740]   I actually just wrote something about this for my new book.
[00:57:13.740 --> 00:57:21.100]   And that is dialectical reading, where you take two different takes on the same topic.
[00:57:21.100 --> 00:57:22.180]   You read them both.
[00:57:22.180 --> 00:57:24.080]   One here is super optimistic.
[00:57:24.080 --> 00:57:25.140]   One here is super skeptical.
[00:57:25.140 --> 00:57:26.660]   Read them both.
[00:57:26.660 --> 00:57:34.880]   And in their collision, you get deeper truth than just sticking with one narrative or the other.
[00:57:34.880 --> 00:57:36.520]   Now, this idea, of course, goes back to Socrates.
[00:57:36.520 --> 00:57:39.060]   Socrates thought this was at the key of philosophical reasoning.
[00:57:39.060 --> 00:57:46.200]   Through the constant question and collision of ideas with other ideas, by pushing back on things and trying to pick them apart, a deeper truth comes out.
[00:57:46.780 --> 00:57:48.060]   And that's exactly what we get here.
[00:57:48.060 --> 00:57:50.020]   So what is this deeper truth?
[00:57:50.020 --> 00:57:53.280]   Well, first, I want to point out, I am going to help this all make sense to you.
[00:57:53.280 --> 00:57:57.240]   But first, I want to point out, notice how the tone of articles matters.
[00:57:57.240 --> 00:58:07.040]   That Scientific American article was clearly written as an article that wanted you to feel odd and amazed, overwhelmed and scared about AI.
[00:58:07.880 --> 00:58:10.900]   Just the terminology, what they focused on, the tone of it.
[00:58:10.900 --> 00:58:14.380]   You read enough articles like that, and you're out back digging your bunker.
[00:58:14.380 --> 00:58:19.500]   Meanwhile, the Gary Marcus article in The Guardian is dismissive.
[00:58:19.500 --> 00:58:24.040]   It's made to be like, look, we all recognize there's nothing really going on here.
[00:58:24.100 --> 00:58:25.960]   And this is the final nail in the coffin.
[00:58:25.960 --> 00:58:31.380]   This study here about Towers of Hanoi clearly means this stuff just isn't working.
[00:58:31.380 --> 00:58:35.900]   If you were just reading Gary Marcus, you'd be like, what is going on here?
[00:58:35.900 --> 00:58:37.740]   Like, these models are clearly terrible.
[00:58:37.740 --> 00:58:40.160]   So the tone of articles, they're on the same topic.
[00:58:40.160 --> 00:58:42.740]   The tone of articles makes a big difference.
[00:58:42.740 --> 00:58:44.020]   All right.
[00:58:44.020 --> 00:58:45.920]   But what is actually going on here?
[00:58:45.920 --> 00:58:48.340]   How could they find two very different findings?
[00:58:48.340 --> 00:59:01.360]   Well, when I look closer at this, and I spent some time today trying to look closer in this, there is a lot of work and I think probably a lot of details being alighted in the Scientific American article.
[00:59:01.360 --> 00:59:11.360]   So when they talk about genius level math, they give this idea that we're just like throwing like whatever math we can at these models.
[00:59:11.640 --> 00:59:17.960]   And by the way, I don't mean to pause here for a second, but there's literally a car alarm going off.
[00:59:17.960 --> 00:59:18.740]   Can you hear this?
[00:59:18.740 --> 00:59:23.820]   It's like the worst case scenario for podcasting is I'm across from a parking garage.
[00:59:23.820 --> 00:59:24.440]   Okay, it stopped.
[00:59:24.440 --> 00:59:30.640]   So if you go back and look at it, I think there's a lot that's actually being alighted by this sort of genius level math.
[00:59:30.640 --> 00:59:34.260]   The type of problems you give these LLMs matter.
[00:59:34.260 --> 00:59:38.620]   And the reason why it matters is that you can, there's a couple of things going on.
[00:59:38.620 --> 00:59:45.380]   One, you can tune these models to work on specific types of math problems, right?
[00:59:45.380 --> 00:59:48.440]   By giving them a lot of examples of those types of math problems.
[00:59:48.440 --> 00:59:49.880]   So that's part of what's going on.
[00:59:49.880 --> 00:59:56.520]   So it could be these genius level math problems were also math problems that were similar to what they tuned on.
[00:59:56.940 --> 01:00:06.460]   And then partially there is this idea that when you do that, what the models are learning is they've seen, I've seen a lot of problems like this.
[01:00:06.460 --> 01:00:17.540]   And I come up with heuristics or shortcuts that I know how to get from, if it's this type of problem and here's the inputs, I can kind of run that through a heuristic that says here would be the output on the other side.
[01:00:17.540 --> 01:00:22.380]   Now, partially we know about this because of some other academic papers that came out at the same time.
[01:00:22.380 --> 01:00:25.120]   So to try to understand this dialectic, I dug deeper.
[01:00:25.120 --> 01:00:33.460]   And interestingly, in April and May, there was two different papers that took these exact same LLMs that according to Scientific America were doing genius level math.
[01:00:33.460 --> 01:00:36.840]   They took those exact same LLMs and they did a very simple study.
[01:00:36.840 --> 01:00:44.780]   It was right after the first paper took the 2025 math Olympiad where you it's these incredibly hard math problems that students compete to try to solve.
[01:00:44.780 --> 01:00:51.100]   And like as soon as the Olympiad was over, they gave those same problems to a bunch of the cutting edge LLMs.
[01:00:51.100 --> 01:00:52.680]   So it was like right after the competition.
[01:00:52.680 --> 01:00:55.920]   So there's no way those LLMs could have been tuned on those specific problems.
[01:00:55.920 --> 01:00:57.380]   They hadn't seen those specific problems.
[01:00:57.380 --> 01:00:59.000]   This was a team.
[01:00:59.000 --> 01:01:01.660]   This first paper was a team that was largely out of Penn State.
[01:01:01.660 --> 01:01:02.540]   All right.
[01:01:02.540 --> 01:01:03.720]   Here's what they found.
[01:01:03.720 --> 01:01:06.480]   Let me read the abstract here to explore this.
[01:01:06.480 --> 01:01:14.260]   We conducted both qualitative and quantitative human evaluations for proofs generated by LLMs and developed a schema for automatically assessing their reasoning capabilities.
[01:01:14.260 --> 01:01:25.280]   Our study reveals that current LLMs fall significantly short of solving challenging Olympiad-level problems and frequently fail to distinguish correct mathematical reasoning from clearly flawed solutions.
[01:01:25.280 --> 01:01:35.380]   Our analysis demonstrates that the occasional correct final answers provided by the LLMs often result from pattern recognition or heuristic shortcuts rather than genuine mathematical reading.
[01:01:35.620 --> 01:01:39.080]   Here's another paper that came out last month.
[01:01:39.080 --> 01:01:47.300]   These benchmarks evaluate models solely based on final numerical answers, neglecting rigorous reasoning and proof generation, which are essential for real-world mathematical tasks.
[01:01:47.300 --> 01:01:53.140]   To address this, we introduce a comprehensive evaluation of full solution reasoning for challenging mathematical problems.
[01:01:53.400 --> 01:02:00.700]   Using expert human annotators, we evaluated several state-of-the-art reasoning models on six problems from the 2025 USAMO.
[01:02:00.700 --> 01:02:02.040]   That's a math competition.
[01:02:02.040 --> 01:02:06.680]   Within hours of their release, our results revealed that all tested models struggled significantly.
[01:02:06.680 --> 01:02:12.860]   Only Gemini 2.5 Pro achieves a non-trivial score of 25%, while all other models achieve less than 5%.
[01:02:12.860 --> 01:02:22.840]   Through detailed analysis of reasoning traces, we identified the most common failure modes and find several unwanted artifacts arising from the optimization strategies employed during model training.
[01:02:22.840 --> 01:02:27.940]   Overall, our results suggest that current LLMs are inadequate for rigorous mathematical reasoning tasks.
[01:02:28.320 --> 01:02:37.860]   So we look at these research papers that are coming out around the same time and we see, oh, the real story around math and reasoning LLMs is much more complicated.
[01:02:37.860 --> 01:02:43.520]   When people are just giving them new math problems from like math competitions, they're finding they struggle significantly.
[01:02:43.520 --> 01:02:45.420]   They're not actually doing reasoning.
[01:02:45.720 --> 01:02:50.040]   When they do get the answer right, it's because they have heuristic shortcuts, this type of problem.
[01:02:50.040 --> 01:02:53.900]   Here's the rule, apply, put the inputs in this rule and get the right answer out.
[01:02:53.900 --> 01:02:56.800]   They had learned that from training on previous similar style problems.
[01:02:56.800 --> 01:02:58.360]   This makes sense.
[01:02:58.360 --> 01:03:07.420]   If you look closely at how you fine tune these reasoning models, the pressure from the reward function, not to get too technical, is not on the actual reasoning itself, but on the final answer.
[01:03:08.340 --> 01:03:17.560]   So it learns to like produce stuff that seems like reasoning, but it's not really being tuned to make that reasoning necessarily make more sense.
[01:03:17.560 --> 01:03:26.900]   So this going back to the original Scientific American article, the only reasonable understanding here is like, well, we don't know what problems they were giving it or what was going on here.
[01:03:27.400 --> 01:03:38.280]   And they're kind of just reporting this subjectively and it's kind of hyperbolic, but when we try to replicate these results systematically, we're like, look, these models can't do general math reasoning.
[01:03:38.280 --> 01:03:44.900]   That sort of matches what Gary Marcus is saying, which he's like, look, this is simpler than a hard math problem that just towers of Hanoi.
[01:03:45.700 --> 01:03:50.000]   It can't figure that out once it's beyond the cases where it could kind of just have the answer memorized.
[01:03:50.000 --> 01:04:01.280]   Even if we tell it what to do, an LLM is not able to take a description of an algorithm and it can run code, but it can't let that impact its reasoning.
[01:04:01.280 --> 01:04:03.300]   That's not really what these things are doing.
[01:04:03.300 --> 01:04:05.540]   So it's an interesting case.
[01:04:05.540 --> 01:04:07.300]   Now, I want to mention something else, though.
[01:04:08.300 --> 01:04:18.680]   There is a model called alpha geometry at a deep mind that did do very well on the same math Olympiad problems that the LLMs did poorly on.
[01:04:18.680 --> 01:04:20.700]   But here's the thing.
[01:04:20.700 --> 01:04:25.100]   Alpha geometry is not a large language model.
[01:04:25.100 --> 01:04:28.320]   It's a neural network that there is neural networks.
[01:04:28.320 --> 01:04:32.140]   There's also what's called symbolic strategies as well.
[01:04:32.140 --> 01:04:37.900]   So it's a custom built AI system for solving these type of math problems.
[01:04:37.900 --> 01:04:40.140]   And they trained it using formal proof methods.
[01:04:40.140 --> 01:04:45.400]   So they could actually put training on the steps of the proof and teaching it how to get proof steps correctly.
[01:04:45.400 --> 01:04:49.500]   So there's a way you can specify proofs in a very formal way a computer can understand and check.
[01:04:49.500 --> 01:04:55.380]   And so they could try to train things not just to get the right answer, but to actually generate proofs for the steps to make sense.
[01:04:55.380 --> 01:05:01.720]   And they built something that was custom made an AI, but not just a language model you trained up and can do stuff.
[01:05:01.720 --> 01:05:06.220]   And when they built a custom symbolic neural AI, it could do really well on those things.
[01:05:06.220 --> 01:05:08.240]   And this is a Gary Marcus point.
[01:05:08.240 --> 01:05:14.500]   That is probably more the future of powerful AI systems is that we figure out certain problems that can be tackled by AI.
[01:05:14.500 --> 01:05:16.420]   We have to build custom systems for it.
[01:05:16.680 --> 01:05:23.980]   That is different than what is being argued in like that Scientific American paper, which is this hope that if we just make language models big enough, they'll be smart at everything.
[01:05:23.980 --> 01:05:28.320]   That if we just scale them up and then test them, we'll realize, oh my God, look, they can do math.
[01:05:28.320 --> 01:05:28.980]   They can do that.
[01:05:28.980 --> 01:05:31.000]   That hope is rapidly diminishing.
[01:05:31.000 --> 01:05:39.020]   If you want to do really hard things, you have to build systems of neural networks and other types of symbolic approaches that are customized to that challenge.
[01:05:39.020 --> 01:05:48.800]   And a lot of challenges aren't going to be well suited to that because we don't have the data math is because we can actually break down proof steps and check them mechanically and use that in training.
[01:05:48.800 --> 01:05:50.060]   So it's a great example for it.
[01:05:50.220 --> 01:06:05.220]   And the reason why we know that the LLMs don't just naturally have within them these sort of genius-level math capabilities is that if they had enough reasoning capabilities to be like genius-level mathematicians, then why would we not be using them on things that were profitable?
[01:06:05.220 --> 01:06:12.800]   Why would we not find things that are much easier than genius-level math and use LLM agents to make a ton of money for this company or that company or this company?
[01:06:12.800 --> 01:06:15.860]   Why are our examples continuing to be these relatively abstract benchmarks?
[01:06:15.860 --> 01:06:20.760]   We created this benchmark on these specific types of math problems, and we made it ourselves.
[01:06:20.760 --> 01:06:27.840]   OpenAI actually commissioned the paid-for the Frontier Math bookmark for which they tested their own O3 model on.
[01:06:27.840 --> 01:06:29.060]   And look, it did really well on it.
[01:06:29.060 --> 01:06:32.100]   At some point, we have to say we don't care about abstract benchmarks.
[01:06:32.100 --> 01:06:37.560]   If they're so good at this reasoning and so smart, have someone make a lot of money off it.
[01:06:37.560 --> 01:06:39.200]   Forget the benchmarks.
[01:06:39.200 --> 01:06:44.360]   Let it reason to figure out X, Y, and Z in an automated way that makes it really good at whatever infrastructure.
[01:06:44.360 --> 01:06:49.020]   Back in logistics and stock trading.
[01:06:49.020 --> 01:07:01.440]   You know, at some point, the vaunted reasoning and intelligence ability of the language models has to actually produce things other than does well on tests that the AI companies themselves create and then say it did well on this test.
[01:07:02.320 --> 01:07:04.780]   So I'm kind of putting on a bit of a skeptic hat there.
[01:07:04.780 --> 01:07:09.060]   I don't mean to do it because, again, these models, the things they do well, they do fantastically well.
[01:07:09.060 --> 01:07:13.800]   But I think this is an example of it's easy when you're filled with hype.
[01:07:13.800 --> 01:07:23.280]   It's easy to take something that a closer look reveals is way more complicated and less exciting than it might seem and make it seem like we're about to no longer need mathematicians.
[01:07:23.460 --> 01:07:23.960]   So there we go.
[01:07:23.960 --> 01:07:25.160]   These were interesting articles.
[01:07:25.160 --> 01:07:25.940]   Read them both.
[01:07:25.940 --> 01:07:28.960]   If you want to keep up with what's going on in AI, recommend those.
[01:07:28.960 --> 01:07:30.080]   Check out the Richard Simon book.
[01:07:30.080 --> 01:07:32.480]   That is what to read this week.
[01:07:32.480 --> 01:07:36.920]   I've been AI ranting a lot, Jesse, but it's sort of on my mind.
[01:07:36.920 --> 01:07:38.080]   I'm doing a lot of writing about it.
[01:07:38.080 --> 01:07:38.920]   I like it.
[01:07:38.920 --> 01:07:40.760]   All right.
[01:07:40.760 --> 01:07:42.680]   Well, I think that's all the time we have.
[01:07:42.680 --> 01:07:45.580]   At the very least, it's all the battery power probably my laptop has here.
[01:07:45.580 --> 01:07:47.980]   So that's our episode for this week.
[01:07:47.980 --> 01:07:48.960]   I'll be back in the studio.
[01:07:49.100 --> 01:07:53.340]   I believe Jesse Wright next, next episode will be recording back in the old, the actual studio.
[01:07:53.340 --> 01:07:54.240]   So that should be exciting.
[01:07:54.240 --> 01:07:55.220]   Yep.
[01:07:55.220 --> 01:07:59.180]   I'm going to insist on wearing these 17 cent headphones regardless.
[01:07:59.180 --> 01:07:59.740]   I don't care.
[01:07:59.740 --> 01:08:02.520]   This is going to be my thing is like barely being able to hear things.
[01:08:02.520 --> 01:08:05.220]   And maybe I'll set off a car alarm just to keep things interesting.
[01:08:05.220 --> 01:08:05.480]   All right.
[01:08:05.480 --> 01:08:07.220]   So thanks for putting up with the vacation episode.
[01:08:07.220 --> 01:08:11.040]   Wish me luck as I venture into Disneyland tomorrow.
[01:08:11.040 --> 01:08:14.220]   And otherwise I'll be back next week with a new episode.
[01:08:14.220 --> 01:08:16.260]   And until then, as always stay deep.
[01:08:17.620 --> 01:08:21.840]   Hey, if you like today's discussion about Byung Chul Han's thoughts on the internet,
[01:08:21.840 --> 01:08:25.160]   you might like to follow it up with some practical advice.
[01:08:25.160 --> 01:08:29.840]   Look at episode 355 called quit social media for real this time.
[01:08:29.840 --> 01:08:35.620]   It'll allow you to take action on the discomfort that Han's thoughts probably have implanted about
[01:08:35.620 --> 01:08:36.000]   the internet.
[01:08:36.000 --> 01:08:36.580]   Check it out.
[01:08:36.580 --> 01:08:37.580]   I think you'll like it.
[01:08:37.960 --> 01:08:43.720]   Most phone users, especially of a certain age, aren't particularly happy about how much
[01:08:43.720 --> 01:08:48.880]   time they are spending on their phone using social apps like TikTok or Instagram and

