
[00:00:00.000 --> 00:00:04.720]   "Superintelligence just got valued at $5 billion."
[00:00:04.720 --> 00:00:06.840]   Or should I say, "Safe superintelligence
[00:00:06.840 --> 00:00:11.000]   "led by none other than the reclusive Ilya Sutskova
[00:00:11.000 --> 00:00:13.200]   "just got valued at $5 billion,"
[00:00:13.200 --> 00:00:17.560]   with this detail-free tweet in just the last few hours.
[00:00:17.560 --> 00:00:22.120]   And today, we also got more news of Gemini 2, Grok 3,
[00:00:22.120 --> 00:00:27.120]   and not just one, but two new $125 billion data centers.
[00:00:29.440 --> 00:00:32.480]   All this news seems so disparate, right?
[00:00:32.480 --> 00:00:35.000]   But there is one theme through it all,
[00:00:35.000 --> 00:00:37.140]   which is computing power.
[00:00:37.140 --> 00:00:40.280]   Even to the point of making data centers in space,
[00:00:40.280 --> 00:00:43.980]   we as a species are making a giant bet
[00:00:43.980 --> 00:00:46.240]   that scaling up language models
[00:00:46.240 --> 00:00:49.900]   will unlock true artificial intelligence.
[00:00:49.900 --> 00:00:53.380]   If the scaling hypothesis believers are right,
[00:00:53.380 --> 00:00:54.740]   it's coming soon.
[00:00:54.740 --> 00:00:57.640]   If they're wrong, this could all be viewed
[00:00:57.640 --> 00:01:01.520]   as the biggest waste of resources in human history.
[00:01:01.520 --> 00:01:03.160]   But let's start with the news
[00:01:03.160 --> 00:01:05.160]   from just a couple of hours ago
[00:01:05.160 --> 00:01:09.160]   that Ilya Sutskova has raised $1 billion
[00:01:09.160 --> 00:01:11.800]   at a $5 billion valuation
[00:01:11.800 --> 00:01:14.620]   for his startup, Safe Superintelligence.
[00:01:14.620 --> 00:01:16.520]   There he is, by the way, in the middle.
[00:01:16.520 --> 00:01:19.960]   He's definitely still alive and working on AI.
[00:01:19.960 --> 00:01:22.560]   If you haven't heard of Safe Superintelligence,
[00:01:22.560 --> 00:01:25.720]   don't worry, it's actually only three months old,
[00:01:25.720 --> 00:01:30.520]   but as mentioned earlier, valued at $5 billion.
[00:01:30.520 --> 00:01:32.600]   If only my three-month-old side hustles
[00:01:32.600 --> 00:01:34.400]   got valued at $5 billion,
[00:01:34.400 --> 00:01:36.320]   the world would be a happy place.
[00:01:36.320 --> 00:01:37.400]   But no, more seriously,
[00:01:37.400 --> 00:01:40.960]   what will those $1 billion in funds be used for?
[00:01:40.960 --> 00:01:44.080]   Well, it's that key theme you'll see throughout this video
[00:01:44.080 --> 00:01:46.060]   and probably throughout the next five years.
[00:01:46.060 --> 00:01:49.760]   The funds will be used to acquire computing power.
[00:01:49.760 --> 00:01:50.840]   Ilya Sutskova, by the way,
[00:01:50.840 --> 00:01:52.920]   sent a link to this Reuters article,
[00:01:52.920 --> 00:01:56.320]   so we can pretty much trust it's spot on with its details.
[00:01:56.320 --> 00:01:57.400]   The salient thing, though,
[00:01:57.400 --> 00:01:59.520]   about the company, Safe Superintelligence,
[00:01:59.520 --> 00:02:01.980]   is just how little detail they're giving out
[00:02:01.980 --> 00:02:03.160]   about what they're working on.
[00:02:03.160 --> 00:02:05.960]   Essentially, though, the key pitch is this.
[00:02:05.960 --> 00:02:07.880]   Give us a couple of years,
[00:02:07.880 --> 00:02:10.780]   and then we're going to attempt in one shot
[00:02:10.780 --> 00:02:12.840]   to bring you superintelligence.
[00:02:12.840 --> 00:02:15.040]   By the way, they're gonna do that with a team
[00:02:15.040 --> 00:02:18.160]   that's currently just 10 employees strong.
[00:02:18.160 --> 00:02:19.920]   But before you dismiss them immediately,
[00:02:19.920 --> 00:02:22.480]   they are backed by some heavy hitters
[00:02:22.480 --> 00:02:26.560]   like Sequoia Capital and Daniel Gross, who is a co-founder.
[00:02:26.560 --> 00:02:28.560]   Up to this point, though, Ilya Sutskova,
[00:02:28.560 --> 00:02:31.320]   who is clearly the key person in this venture,
[00:02:31.320 --> 00:02:34.600]   hasn't given any real detail about his approach,
[00:02:34.600 --> 00:02:37.920]   but he did sprinkle some hints into this article.
[00:02:37.920 --> 00:02:39.800]   Sutskova said that he will approach scaling
[00:02:39.800 --> 00:02:42.160]   in a different way to his former employer,
[00:02:42.160 --> 00:02:43.520]   which would be OpenAI.
[00:02:43.520 --> 00:02:46.500]   And he said, "Everyone just says scaling hypothesis.
[00:02:46.500 --> 00:02:49.740]   Everyone neglects to ask, 'What are we scaling?'"
[00:02:49.740 --> 00:02:52.720]   But he went on, "Some people can work really long hours,
[00:02:52.720 --> 00:02:54.920]   and they'll just go down the same path faster.
[00:02:54.920 --> 00:02:56.680]   It's not so much our style,
[00:02:56.680 --> 00:02:58.600]   but if you do something different,
[00:02:58.600 --> 00:03:01.440]   then it becomes possible for you to do something special."
[00:03:01.440 --> 00:03:03.560]   Before people get completely carried away, though,
[00:03:03.560 --> 00:03:05.800]   I do want to add a little bit of context
[00:03:05.800 --> 00:03:09.000]   to some of the claims that Sutskova has made before.
[00:03:09.000 --> 00:03:13.120]   He co-led the superalignment team at OpenAI,
[00:03:13.120 --> 00:03:16.760]   which just over a year ago set themselves the deadline
[00:03:16.760 --> 00:03:19.740]   of aligning or making safe superintelligence
[00:03:19.740 --> 00:03:21.100]   within four years.
[00:03:21.100 --> 00:03:23.060]   Now, I'm not against crazy ambition,
[00:03:23.060 --> 00:03:24.740]   and alignment is important,
[00:03:24.740 --> 00:03:26.940]   but what actual progress has been made
[00:03:26.940 --> 00:03:28.300]   in that year and a bit?
[00:03:28.300 --> 00:03:30.060]   Yes, I have read those blog posts put out
[00:03:30.060 --> 00:03:32.540]   by the former members of the team,
[00:03:32.540 --> 00:03:36.220]   but it doesn't strike me as being a quarter of the way
[00:03:36.220 --> 00:03:38.940]   to aligning a superintelligence.
[00:03:38.940 --> 00:03:41.580]   On the grounded to fanciful scale,
[00:03:41.580 --> 00:03:44.300]   it is definitely leaning toward the latter.
[00:03:44.300 --> 00:03:48.040]   Now, naturally, those weren't the only grandiose visions
[00:03:48.040 --> 00:03:50.680]   announced in the last 48 hours.
[00:03:50.680 --> 00:03:52.520]   Here is Musk two days ago,
[00:03:52.520 --> 00:03:55.480]   claiming to have the most powerful AI training system
[00:03:55.480 --> 00:03:56.320]   in the world.
[00:03:56.320 --> 00:04:01.320]   He mentions it soon having around 200,000 H100 equivalents,
[00:04:01.320 --> 00:04:04.600]   which are the GPUs that go into training
[00:04:04.600 --> 00:04:05.840]   larger language models.
[00:04:05.840 --> 00:04:07.440]   Now, your first thoughts might be
[00:04:07.440 --> 00:04:09.640]   that that's either an idle boast
[00:04:09.640 --> 00:04:12.860]   or that it's not really the computing power that matters,
[00:04:12.860 --> 00:04:13.960]   it's how you use it.
[00:04:13.960 --> 00:04:15.860]   But I do give comments like that,
[00:04:15.860 --> 00:04:17.400]   and this one from July,
[00:04:17.400 --> 00:04:20.920]   more credence because of the capabilities of Grok2.
[00:04:20.920 --> 00:04:24.920]   Grok2, the frontier model produced by Musk's ex-AI team,
[00:04:24.920 --> 00:04:27.940]   is genuinely a GPT-4 level competitor.
[00:04:27.940 --> 00:04:29.920]   So it's worth paying attention at least
[00:04:29.920 --> 00:04:32.560]   to when he says that they are gonna train
[00:04:32.560 --> 00:04:35.240]   the most powerful AI by every metric
[00:04:35.240 --> 00:04:36.920]   by December of this year.
[00:04:36.920 --> 00:04:38.780]   And I will give one further hint
[00:04:38.780 --> 00:04:41.640]   that that claim shouldn't be immediately dismissed.
[00:04:41.640 --> 00:04:45.680]   And that's from this report yesterday in the information.
[00:04:45.680 --> 00:04:49.400]   Now, first, it did caveat that that 100,000 chip cluster,
[00:04:49.400 --> 00:04:52.160]   known as Colossus, isn't fully operational.
[00:04:52.160 --> 00:04:54.440]   Apparently, fewer than half of those chips
[00:04:54.440 --> 00:04:56.040]   are currently in operation,
[00:04:56.040 --> 00:04:57.240]   largely because of constraints
[00:04:57.240 --> 00:04:59.160]   involving power or networking gear,
[00:04:59.160 --> 00:05:01.240]   and more about power constraints in a moment.
[00:05:01.240 --> 00:05:02.920]   But according to the information,
[00:05:02.920 --> 00:05:06.760]   OpenAI CEO Sam Altman has told some Microsoft executives
[00:05:06.760 --> 00:05:09.640]   that he is concerned that Musk's ex-AI
[00:05:09.640 --> 00:05:12.420]   could soon have more access to computing power
[00:05:12.420 --> 00:05:13.840]   than OpenAI does.
[00:05:13.840 --> 00:05:15.980]   And remember, OpenAI has access
[00:05:15.980 --> 00:05:18.900]   to the behemoth, Microsoft's compute power.
[00:05:18.900 --> 00:05:19.940]   It's at this point, though,
[00:05:19.940 --> 00:05:22.540]   that you might be starting to wonder something.
[00:05:22.540 --> 00:05:24.740]   Is it all just about computing power?
[00:05:24.740 --> 00:05:26.740]   Isn't there supposed to be some secret source
[00:05:26.740 --> 00:05:28.660]   at OpenAI or Google?
[00:05:28.660 --> 00:05:31.320]   Is it really just about raw computing power?
[00:05:31.320 --> 00:05:34.620]   Can we buy our way to super intelligence?
[00:05:34.620 --> 00:05:36.240]   Well, it's not for want of trying.
[00:05:36.240 --> 00:05:37.820]   There have been plenty of teams
[00:05:37.820 --> 00:05:40.260]   that have tried to build their own foundation models,
[00:05:40.260 --> 00:05:43.140]   only to realize that the key ingredient
[00:05:43.140 --> 00:05:44.940]   is scale, computing power.
[00:05:44.940 --> 00:05:48.140]   Character AI even built up a loyal fan base
[00:05:48.140 --> 00:05:50.700]   and had some stars of the industry,
[00:05:50.700 --> 00:05:53.140]   but couldn't make their own foundation models work.
[00:05:53.140 --> 00:05:56.920]   You may also recall efforts by AdeptAI and Inflection,
[00:05:56.920 --> 00:05:59.060]   which produced the Pi chatbot.
[00:05:59.060 --> 00:06:01.100]   The key personnel from those teams
[00:06:01.100 --> 00:06:04.660]   were snapped up by the likes of Google and Microsoft.
[00:06:04.660 --> 00:06:07.860]   In short, people are trying things as alternatives
[00:06:07.860 --> 00:06:09.660]   to brute force scaling,
[00:06:09.660 --> 00:06:12.300]   but not that much is working currently.
[00:06:12.300 --> 00:06:14.420]   Sure, you can eke out compute efficiencies
[00:06:14.420 --> 00:06:16.900]   and optimizations like GPT-4.0,
[00:06:16.900 --> 00:06:19.660]   the Orca series of models and the Phi family of models,
[00:06:19.660 --> 00:06:21.380]   but nothing beats scaling.
[00:06:21.380 --> 00:06:25.740]   And that might be why companies are betting everything
[00:06:25.740 --> 00:06:28.420]   on colossal new data centers.
[00:06:28.420 --> 00:06:30.140]   We're talking levels of investment
[00:06:30.140 --> 00:06:32.780]   at the scale that could fund the research
[00:06:32.780 --> 00:06:34.660]   to cure entire diseases,
[00:06:34.660 --> 00:06:37.060]   or perhaps fund the national budgets
[00:06:37.060 --> 00:06:38.660]   of medium-sized countries.
[00:06:38.660 --> 00:06:41.020]   And you might've thought from the title of this video
[00:06:41.020 --> 00:06:44.620]   that there's a singular 125 billion supercomputer,
[00:06:44.620 --> 00:06:46.460]   but there's actually two being planned.
[00:06:46.460 --> 00:06:48.100]   I should, of course, add the caveat
[00:06:48.100 --> 00:06:50.140]   that it's according to the information
[00:06:50.140 --> 00:06:53.620]   via officials that would know about such investments.
[00:06:53.620 --> 00:06:56.700]   Namely, the source is the Commissioner of Commerce,
[00:06:56.700 --> 00:07:00.220]   Josh Teigen, who said that two separate companies
[00:07:00.220 --> 00:07:02.580]   approached him and the governor of North Dakota
[00:07:02.580 --> 00:07:05.340]   about building mega AI data centers.
[00:07:05.340 --> 00:07:09.140]   These would initially consume around 500 megawatts
[00:07:09.140 --> 00:07:11.380]   to one gigawatt of power,
[00:07:11.380 --> 00:07:15.300]   with plans to scale up to five or 10 gigawatts of power
[00:07:15.300 --> 00:07:16.420]   over several years.
[00:07:16.420 --> 00:07:18.500]   Those numbers, of course, to most of you,
[00:07:18.500 --> 00:07:20.380]   will be complete gobbledygook.
[00:07:20.380 --> 00:07:24.620]   So for context, here is an excellent diagram from Epoch AI.
[00:07:24.620 --> 00:07:28.100]   Five gigawatts of power allocated to a single training run
[00:07:28.100 --> 00:07:31.460]   would put the power constraint just above this line here.
[00:07:31.460 --> 00:07:34.740]   Now, given that it's expected that these other constraints
[00:07:34.740 --> 00:07:36.580]   would kick in at higher levels,
[00:07:36.580 --> 00:07:40.540]   that would give us just over 10,000 times more compute
[00:07:40.540 --> 00:07:42.820]   available compared to that which was used
[00:07:42.820 --> 00:07:44.500]   for training GPT-4.
[00:07:44.500 --> 00:07:47.460]   Now, given the broad approximate deltas
[00:07:47.460 --> 00:07:49.740]   between generations of GPTs,
[00:07:49.740 --> 00:07:53.540]   that will be the equivalent of a GPT-6 training run.
[00:07:53.540 --> 00:07:57.060]   Now, yes, I know that there are quote leaks like this one
[00:07:57.060 --> 00:07:59.420]   showing that GPT-5 might have
[00:07:59.420 --> 00:08:02.220]   between three and five trillion parameters,
[00:08:02.220 --> 00:08:06.300]   but my adage for such leaks is don't trust and verify.
[00:08:06.300 --> 00:08:10.020]   And also the number of parameters that goes into a model
[00:08:10.020 --> 00:08:12.700]   or the number of tweakable knobs, if you like,
[00:08:12.700 --> 00:08:14.540]   doesn't tell you automatically
[00:08:14.540 --> 00:08:16.820]   how much compute is used to train the model.
[00:08:16.820 --> 00:08:19.580]   Data is also a massive factor there.
[00:08:19.580 --> 00:08:22.860]   Chinchilla scaling laws have long since been left behind
[00:08:22.860 --> 00:08:26.420]   and we are massively ramping up the amount of data
[00:08:26.420 --> 00:08:28.300]   for a given number of parameters.
[00:08:28.300 --> 00:08:30.660]   But before we all get too lost in the numbers,
[00:08:30.660 --> 00:08:32.100]   what am I actually saying here?
[00:08:32.100 --> 00:08:35.220]   I'm saying that with the amount of money that's being spent
[00:08:35.220 --> 00:08:37.740]   and the amount of power that's being provisioned,
[00:08:37.740 --> 00:08:41.420]   people are factoring in models up to the scale
[00:08:41.420 --> 00:08:43.340]   of something like GPT-6.
[00:08:43.340 --> 00:08:44.980]   By the way, if you're skeptical
[00:08:44.980 --> 00:08:46.900]   that any progress has been made,
[00:08:46.900 --> 00:08:49.860]   compare the performance of the original chat GPT
[00:08:49.860 --> 00:08:53.820]   in November of 2022 with Claude 3.5 Sonnet.
[00:08:53.820 --> 00:08:55.180]   It's pretty night and day.
[00:08:55.180 --> 00:09:00.180]   Claude 5.5 Sonnet would be quite interesting to behold.
[00:09:00.180 --> 00:09:04.140]   Now, just to emphasize how much this scaling is a bet
[00:09:04.140 --> 00:09:05.780]   rather than a certainty
[00:09:05.780 --> 00:09:08.060]   in terms of the outcome it will produce,
[00:09:08.060 --> 00:09:09.860]   here again is Mark Zuckerberg.
[00:09:09.860 --> 00:09:11.940]   - It's one of the trickiest things in the world
[00:09:11.940 --> 00:09:14.500]   to plan around is when you have an exponential curve,
[00:09:14.500 --> 00:09:16.620]   how long does it keep going for?
[00:09:16.620 --> 00:09:21.300]   And I think it's likely enough that it will keep going,
[00:09:21.300 --> 00:09:26.300]   that it is worth investing the tens or 100 billion plus
[00:09:26.300 --> 00:09:28.500]   in building the infrastructure
[00:09:28.500 --> 00:09:30.740]   to assume that if that kind of keeps going,
[00:09:30.740 --> 00:09:33.020]   you're going to get some really amazing things
[00:09:33.020 --> 00:09:35.260]   that are just going to make amazing products.
[00:09:35.260 --> 00:09:38.980]   But I don't think anyone in the industry can really tell you
[00:09:38.980 --> 00:09:42.020]   that it will continue scaling at that rate for sure.
[00:09:42.020 --> 00:09:43.900]   - And you may have noticed that I've barely mentioned
[00:09:43.900 --> 00:09:48.260]   OpenAI successor language models and new verifier approaches.
[00:09:48.260 --> 00:09:51.900]   Those approaches previously labeled Q* or Strawberry
[00:09:51.900 --> 00:09:55.060]   throw in a bit of an X factor over the coming months.
[00:09:55.060 --> 00:09:58.300]   According to this article from again, the information,
[00:09:58.300 --> 00:10:00.380]   OpenAI want to launch Strawberry,
[00:10:00.380 --> 00:10:02.140]   which was previously called Q*
[00:10:02.140 --> 00:10:03.420]   and check out my video on that
[00:10:03.420 --> 00:10:05.340]   for what I think that might be.
[00:10:05.340 --> 00:10:07.380]   They want to launch that within ChatGPT
[00:10:07.380 --> 00:10:09.060]   as soon as this fall.
[00:10:09.060 --> 00:10:12.660]   Interestingly, the only hint they gave of its capabilities
[00:10:12.660 --> 00:10:13.860]   was that it could solve
[00:10:13.860 --> 00:10:16.420]   a New York Times connections word puzzle.
[00:10:16.420 --> 00:10:17.980]   Now, since I read this article,
[00:10:17.980 --> 00:10:19.620]   I have been trying plenty
[00:10:19.620 --> 00:10:21.980]   of those New York Times connections puzzles.
[00:10:21.980 --> 00:10:25.140]   You've got to create four groups of four words
[00:10:25.140 --> 00:10:27.220]   that form a kind of logical set.
[00:10:27.220 --> 00:10:28.660]   Here though is the interesting part.
[00:10:28.660 --> 00:10:32.060]   If you feed in these puzzles to GPC 4.0 as text
[00:10:32.060 --> 00:10:33.300]   or as an image,
[00:10:33.300 --> 00:10:37.980]   it usually can get one or two sets of four words.
[00:10:37.980 --> 00:10:40.620]   But then what will happen is it will get stuck.
[00:10:40.620 --> 00:10:43.860]   And even if you prompt it to try different arrangements
[00:10:43.860 --> 00:10:45.500]   of the remaining words,
[00:10:45.500 --> 00:10:48.300]   it'll still predict the same things again and again.
[00:10:48.300 --> 00:10:49.700]   So at the very least,
[00:10:49.700 --> 00:10:52.140]   OpenAI must have pioneered a method
[00:10:52.140 --> 00:10:55.060]   to get language models out of their local minima
[00:10:55.060 --> 00:10:57.220]   to get them to try different things
[00:10:57.220 --> 00:10:58.660]   instead of getting stuck in a rut.
[00:10:58.660 --> 00:10:59.700]   How that plays out though,
[00:10:59.700 --> 00:11:01.780]   in terms of true reasoning capability,
[00:11:01.780 --> 00:11:04.900]   I'm gonna wait to test it on SimpleBench to find out.
[00:11:04.900 --> 00:11:06.300]   Speaking of experiments though,
[00:11:06.300 --> 00:11:08.900]   let me quickly introduce you to Weave
[00:11:08.900 --> 00:11:11.620]   from the legendary Weights & Biases,
[00:11:11.620 --> 00:11:13.700]   the sponsors of this video.
[00:11:13.700 --> 00:11:17.660]   Proper evaluations of language models are absolutely crucial
[00:11:17.660 --> 00:11:20.980]   as is clearly visualizing the differences between them.
[00:11:20.980 --> 00:11:23.740]   You'd also ideally want your toolkit to be lightweight
[00:11:23.740 --> 00:11:26.700]   so you could confidently and quickly iterate
[00:11:26.700 --> 00:11:28.460]   on your LLM applications.
[00:11:28.460 --> 00:11:31.580]   So in addition to their free courses and guides,
[00:11:31.580 --> 00:11:34.860]   do check out Weave using the link you can see on screen,
[00:11:34.860 --> 00:11:37.340]   which will also of course be in the description.
[00:11:37.340 --> 00:11:39.660]   Now though, for what some of you have been waiting for,
[00:11:39.660 --> 00:11:41.300]   the news we got yesterday
[00:11:41.300 --> 00:11:44.540]   that one startup is attempting to build data centers
[00:11:44.540 --> 00:11:45.460]   in space.
[00:11:45.460 --> 00:11:48.180]   Such is the need for reliable energy
[00:11:48.180 --> 00:11:50.020]   to power these data centers.
[00:11:50.020 --> 00:11:53.980]   We are resorting to putting the data centers into space.
[00:11:53.980 --> 00:11:57.740]   This company, Lumen Orbit, is a Y Combinator startup
[00:11:57.740 --> 00:12:00.860]   and they are aiming for gigawatt scale.
[00:12:00.860 --> 00:12:02.460]   Their promo video even mentions
[00:12:02.460 --> 00:12:04.980]   a possible five gigawatt data center,
[00:12:04.980 --> 00:12:07.620]   which again, if dedicated to pre-training,
[00:12:07.620 --> 00:12:10.460]   would allow a GPT-6 style model.
[00:12:10.460 --> 00:12:12.620]   But I must add in a quick caveat
[00:12:12.620 --> 00:12:16.220]   before we all go wild about data centers in space.
[00:12:16.220 --> 00:12:18.700]   Things like this have been tried before.
[00:12:18.700 --> 00:12:22.580]   Microsoft tried to build data centers underwater.
[00:12:22.580 --> 00:12:27.580]   The idea was that the sea could help cool the data center
[00:12:27.580 --> 00:12:29.340]   and save on costs.
[00:12:29.340 --> 00:12:33.060]   And even though it was described as largely a success,
[00:12:33.060 --> 00:12:34.620]   apparently it didn't make sense
[00:12:34.620 --> 00:12:37.020]   from an operational or practical perspective.
[00:12:37.020 --> 00:12:39.500]   The cost of maintenance, among other things,
[00:12:39.500 --> 00:12:41.340]   was simply prohibitive.
[00:12:41.340 --> 00:12:42.180]   Now, I don't know about you,
[00:12:42.180 --> 00:12:44.300]   but it strikes me that the cost of maintaining things
[00:12:44.300 --> 00:12:46.500]   in space might be even more.
[00:12:46.500 --> 00:12:48.380]   But as you may have already deduced,
[00:12:48.380 --> 00:12:52.880]   that's not exactly gonna stop us reaching GPT-6 scale models.
[00:12:52.880 --> 00:12:53.720]   Why not?
[00:12:53.720 --> 00:12:57.700]   Well, we do have the option of geographically distributing
[00:12:57.700 --> 00:13:00.540]   the computers used to train the models.
[00:13:00.540 --> 00:13:02.260]   In fact, according to some sources,
[00:13:02.260 --> 00:13:05.060]   Microsoft found they more or less had to do that.
[00:13:05.060 --> 00:13:06.820]   Apparently one Microsoft engineer
[00:13:06.820 --> 00:13:10.740]   on a GPT-6 training cluster project was asked,
[00:13:10.740 --> 00:13:13.900]   "Why not just co-locate the cluster in one region?"
[00:13:13.900 --> 00:13:15.620]   Well, they tried that, he said,
[00:13:15.620 --> 00:13:19.260]   "But we can't put more than 100,000 H100s,"
[00:13:19.260 --> 00:13:21.420]   that's roughly the size of that Colossus project
[00:13:21.420 --> 00:13:23.020]   that we heard earlier from Elon Musk,
[00:13:23.020 --> 00:13:26.420]   "in a single state without bringing down the power grid."
[00:13:26.420 --> 00:13:29.140]   As we saw from that Epoch analysis,
[00:13:29.140 --> 00:13:32.100]   it's the power that's the constraining factor.
[00:13:32.100 --> 00:13:35.620]   And also possibly water, but more on that in a future video.
[00:13:35.620 --> 00:13:37.420]   But if we distribute the training,
[00:13:37.420 --> 00:13:40.140]   then the clusters don't all have to be in the same place,
[00:13:40.140 --> 00:13:42.980]   so it reduces that local power drain.
[00:13:42.980 --> 00:13:45.900]   And that approach of distributed training
[00:13:45.900 --> 00:13:49.820]   to cut a long story short is where we seem to be heading.
[00:13:49.820 --> 00:13:53.540]   According to a report out just today from Semianalysis,
[00:13:53.540 --> 00:13:57.860]   Google, OpenAI, and Anthropic are already executing plans
[00:13:57.860 --> 00:13:59.980]   to expand their large model training
[00:13:59.980 --> 00:14:03.260]   from one site to multiple data center campuses.
[00:14:03.260 --> 00:14:04.740]   And we already know, by the way,
[00:14:04.740 --> 00:14:07.980]   that Gemini Ultra 1.0 was trained
[00:14:07.980 --> 00:14:10.580]   across multiple data centers, so it can be done.
[00:14:10.580 --> 00:14:12.460]   And before we get to more details on that,
[00:14:12.460 --> 00:14:15.380]   there was this hidden gem in the third paragraph.
[00:14:15.380 --> 00:14:17.860]   Again, this article was from today, and it said,
[00:14:17.860 --> 00:14:21.380]   "Google's existing models lag behind OpenAI and Anthropic
[00:14:21.380 --> 00:14:22.780]   "because they are still catching up
[00:14:22.780 --> 00:14:25.340]   "in terms of synthetic data, reinforcement learning,
[00:14:25.340 --> 00:14:26.420]   "and model architecture.
[00:14:26.420 --> 00:14:30.020]   "But the impending release of Gemini 2 will change this."
[00:14:30.020 --> 00:14:32.580]   Semianalysis is a pretty reliable source,
[00:14:32.580 --> 00:14:34.060]   so that's an interesting comment.
[00:14:34.060 --> 00:14:37.580]   It seems like we will get Gemini 2 and Grok 3
[00:14:37.580 --> 00:14:38.780]   within a few months.
[00:14:38.780 --> 00:14:41.540]   And as we heard earlier, the Strawberry system
[00:14:41.540 --> 00:14:44.260]   from OpenAI in roughly the same timeframe.
[00:14:44.260 --> 00:14:47.060]   We will probably have to wait till next year
[00:14:47.060 --> 00:14:49.500]   for OpenAI's next flagship, though,
[00:14:49.500 --> 00:14:51.220]   which is codenamed Orion.
[00:14:51.220 --> 00:14:52.060]   But just for a moment,
[00:14:52.060 --> 00:14:55.180]   I want you to forget all the names and the fruit
[00:14:55.180 --> 00:14:57.380]   and focus on one key detail.
[00:14:57.380 --> 00:14:59.180]   If the key ingredient
[00:14:59.180 --> 00:15:02.580]   to the performance of language models is their scale,
[00:15:02.580 --> 00:15:06.300]   we should find out that fact by the end of this year.
[00:15:06.300 --> 00:15:07.580]   Or to put it another way,
[00:15:07.580 --> 00:15:09.980]   if scaling doesn't work up to the levels
[00:15:09.980 --> 00:15:13.820]   of Grok 3 and Gemini 2, then what else will?
[00:15:13.820 --> 00:15:17.100]   If the data centers are getting to the kind of scale
[00:15:17.100 --> 00:15:20.620]   where we need satellite pictures to assess how big they are
[00:15:20.620 --> 00:15:23.940]   and that doesn't produce true artificial intelligence,
[00:15:23.940 --> 00:15:27.300]   then, well, do we have to rely on Ilya Satskova?
[00:15:27.300 --> 00:15:28.300]   Obviously, I'm being cheeky,
[00:15:28.300 --> 00:15:30.380]   but it's priced into the value, I think,
[00:15:30.380 --> 00:15:31.660]   of many of these companies.
[00:15:31.660 --> 00:15:33.580]   Just the possibility, at least,
[00:15:33.580 --> 00:15:36.380]   that scaling will yield super intelligence.
[00:15:36.380 --> 00:15:40.220]   So if it doesn't, you could expect a reflection of that
[00:15:40.220 --> 00:15:42.620]   in the form of a bubble bursting.
[00:15:42.620 --> 00:15:44.220]   Just quickly, I can't resist pointing out
[00:15:44.220 --> 00:15:46.140]   that if you're in America,
[00:15:46.140 --> 00:15:49.700]   then the fact that models will be increasingly interconnected
[00:15:49.700 --> 00:15:51.540]   across that continent will lead
[00:15:51.540 --> 00:15:54.180]   to a kind of interesting philosophical moment.
[00:15:54.180 --> 00:15:55.980]   Microsoft will quite literally be,
[00:15:55.980 --> 00:15:57.780]   in the famous words of their CEO,
[00:15:57.780 --> 00:16:00.260]   above you, around you, beneath you.
[00:16:00.260 --> 00:16:02.980]   Now, of course, it almost goes without saying
[00:16:02.980 --> 00:16:06.100]   that there will be immense hardware issues
[00:16:06.100 --> 00:16:08.940]   in getting this all set up and running smoothly.
[00:16:08.940 --> 00:16:13.300]   Billions of man hours worth of problems to be solved, for sure.
[00:16:13.300 --> 00:16:16.380]   And that's why companies, it seems, are clamping up
[00:16:16.380 --> 00:16:19.620]   about how they're solving these hardware issues.
[00:16:19.620 --> 00:16:22.060]   The publishing of methods has effectively stopped.
[00:16:22.060 --> 00:16:24.420]   When OpenAI and others tell the hardware industry
[00:16:24.420 --> 00:16:27.180]   about these issues, they are very vague and high level
[00:16:27.180 --> 00:16:30.620]   so as not to reveal any of their distributed systems tricks.
[00:16:30.620 --> 00:16:32.900]   To be clear, Semi-Analysis says these techniques
[00:16:32.900 --> 00:16:35.780]   are more important than model architecture,
[00:16:35.780 --> 00:16:38.580]   as both can be thought of as compute efficiency.
[00:16:38.580 --> 00:16:42.500]   Here, then, is the central claim from Semi-Analysis.
[00:16:42.500 --> 00:16:46.540]   There is a camp that feels AI capabilities have stagnated
[00:16:46.540 --> 00:16:48.300]   ever since GPT-4's release.
[00:16:48.300 --> 00:16:50.300]   I know many of you watching will feel that.
[00:16:50.300 --> 00:16:52.020]   This is generally true,
[00:16:52.020 --> 00:16:53.980]   but only because no one has been able
[00:16:53.980 --> 00:16:56.380]   to massively increase the amount of compute
[00:16:56.380 --> 00:16:57.900]   dedicated to a single model.
[00:16:57.900 --> 00:17:00.780]   The word only there is, of course, an opinion
[00:17:00.780 --> 00:17:02.980]   rather than an established fact.
[00:17:02.980 --> 00:17:05.460]   Some, of course, believe that no amount of scaling
[00:17:05.460 --> 00:17:08.420]   will yield true reasoning or intelligence.
[00:17:08.420 --> 00:17:11.940]   I have my thoughts, but honestly, I'm somewhat agnostic.
[00:17:11.940 --> 00:17:14.540]   I genuinely want to know how these future models
[00:17:14.540 --> 00:17:16.460]   perform on my simple bench.
[00:17:16.460 --> 00:17:19.500]   I go into a ton of detail about what I'm creating
[00:17:19.500 --> 00:17:22.140]   on my Patreon, which is called AI Insiders.
[00:17:22.140 --> 00:17:24.540]   Oh, and also just a couple of days ago,
[00:17:24.540 --> 00:17:28.340]   I released this video on that Epoch AI research.
[00:17:28.340 --> 00:17:29.180]   That reminds me, actually,
[00:17:29.180 --> 00:17:31.260]   there was one more thing from that research
[00:17:31.260 --> 00:17:33.340]   that I wanted to touch on in this video.
[00:17:33.340 --> 00:17:37.380]   It came about halfway through the 20,000 word report,
[00:17:37.380 --> 00:17:38.780]   and it's right here.
[00:17:38.780 --> 00:17:39.980]   I don't know why I picked it out.
[00:17:39.980 --> 00:17:42.740]   I just find it really quite poignant and interesting
[00:17:42.740 --> 00:17:45.500]   to see what these behemoth companies will do,
[00:17:45.500 --> 00:17:47.860]   because basically what they pledged,
[00:17:47.860 --> 00:17:49.980]   this is Google, Microsoft, and Amazon,
[00:17:49.980 --> 00:17:52.580]   to become carbon neutral by 2030.
[00:17:52.580 --> 00:17:54.860]   Now, what do you predict will happen
[00:17:54.860 --> 00:17:58.060]   if it turns out that the scaling hypothesis is true
[00:17:58.060 --> 00:18:00.540]   and that AI is immensely profitable,
[00:18:00.540 --> 00:18:02.820]   and yet it requires this immense power
[00:18:02.820 --> 00:18:04.820]   and that will break these targets?
[00:18:04.820 --> 00:18:07.380]   Will they stick to their honorable pledges?
[00:18:07.380 --> 00:18:09.060]   Well, we know what Sam Altman wants to do,
[00:18:09.060 --> 00:18:11.660]   which is spend in the order of trillions
[00:18:11.660 --> 00:18:14.380]   and finance dozens of new chip factories.
[00:18:14.380 --> 00:18:16.780]   This was from a separate information report,
[00:18:16.780 --> 00:18:18.820]   but there was one quote that I found interesting
[00:18:18.820 --> 00:18:19.740]   in relation to it.
[00:18:19.740 --> 00:18:23.380]   Sam Altman, according to the CEO of TSMC,
[00:18:23.380 --> 00:18:24.980]   which makes most of these chips,
[00:18:24.980 --> 00:18:27.140]   the power, NVIDIA, and everyone else,
[00:18:27.140 --> 00:18:29.580]   he said Sam Altman was, quote,
[00:18:29.580 --> 00:18:31.580]   "Too aggressive for me to believe."
[00:18:31.580 --> 00:18:32.420]   Remember, by the way,
[00:18:32.420 --> 00:18:34.580]   that pretty much all of this comes down
[00:18:34.580 --> 00:18:36.660]   to that Taiwanese company,
[00:18:36.660 --> 00:18:37.860]   which is why, by the way,
[00:18:37.860 --> 00:18:39.500]   the whole tech industry is so nervous
[00:18:39.500 --> 00:18:41.020]   about China invading Taiwan.
[00:18:41.020 --> 00:18:43.940]   Anyway, Sam Altman is, according to the TSMC CEO,
[00:18:43.940 --> 00:18:46.380]   "Too aggressive for him to believe."
[00:18:46.380 --> 00:18:49.420]   And maybe even these 125 billion data centers
[00:18:49.420 --> 00:18:50.940]   are also too aggressive.
[00:18:50.940 --> 00:18:52.300]   Only time will tell.
[00:18:52.300 --> 00:18:57.100]   It's indubitable that a mountain has been identified
[00:18:57.100 --> 00:19:01.020]   and that the AI industry is trying to climb it.
[00:19:01.020 --> 00:19:02.820]   Whether they will, or indeed,
[00:19:02.820 --> 00:19:05.660]   whether they're even heading in the right direction,
[00:19:05.660 --> 00:19:07.460]   only time will tell.
[00:19:07.460 --> 00:19:09.580]   Thank you as ever so much
[00:19:09.580 --> 00:19:11.340]   for watching all the way to the end.
[00:19:11.340 --> 00:19:14.740]   I'm super grateful and have a wonderful day.

