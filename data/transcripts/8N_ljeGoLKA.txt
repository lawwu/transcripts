
[00:00:00.000 --> 00:00:11.800]   So yeah, so intelligence explosion, I'm sure your family has the idea, but it's the idea
[00:00:11.800 --> 00:00:21.200]   that if you were to build general AI problem solving algorithms, well, the problem of building
[00:00:21.200 --> 00:00:26.840]   such an AI, that itself is a problem that could be solved by your AI.
[00:00:26.840 --> 00:00:29.920]   And maybe it could be solved better than what humans can do.
[00:00:29.920 --> 00:00:36.080]   So your AI could start tweaking its own algorithm, could start being a better version of itself.
[00:00:36.080 --> 00:00:39.540]   And so on iteratively in a recursive fashion.
[00:00:39.540 --> 00:00:47.360]   And so you would end up with an AI with exponentially increasing intelligence.
[00:00:47.360 --> 00:00:54.640]   And I was basically questioning this idea, first of all, because the notion of intelligence
[00:00:54.640 --> 00:01:01.640]   explosion uses an implicit definition of intelligence that doesn't sound quite right to me.
[00:01:01.640 --> 00:01:10.000]   It considers intelligence as a property of a brain that you can consider in isolation,
[00:01:10.000 --> 00:01:12.960]   like the height of a building, for instance.
[00:01:12.960 --> 00:01:15.840]   But that's not really what intelligence is.
[00:01:15.840 --> 00:01:23.040]   Intelligence emerges from the interaction between a brain, a body, like embodied intelligence,
[00:01:23.040 --> 00:01:24.640]   and an environment.
[00:01:24.640 --> 00:01:30.100]   And if you're missing one of these pieces, then you cannot redefine intelligence anymore.
[00:01:30.100 --> 00:01:34.280]   So just tweaking a brain to make it smarter and smarter doesn't actually make any sense
[00:01:34.280 --> 00:01:35.280]   to me.
[00:01:35.280 --> 00:01:39.280]   So, first of all, you're crushing the dreams of many people, right?
[00:01:39.280 --> 00:01:45.160]   So there's a, let's look at like Sam Harris, actually a lot of physicists, Max Tegmark,
[00:01:45.160 --> 00:01:50.920]   people who think, you know, the universe is a information processing system.
[00:01:50.920 --> 00:01:53.920]   Our brain is kind of an information processing system.
[00:01:53.920 --> 00:01:55.720]   So what's the theoretical limit?
[00:01:55.720 --> 00:02:02.840]   Like, it doesn't make sense that there should be some, it seems naive to think that our
[00:02:02.840 --> 00:02:07.720]   own brain is somehow the limit of the capabilities of this information.
[00:02:07.720 --> 00:02:09.880]   I'm playing devil's advocate here.
[00:02:09.880 --> 00:02:11.920]   This information processing system.
[00:02:11.920 --> 00:02:16.240]   And then if you just scale it, if you're able to build something that's on par with the
[00:02:16.240 --> 00:02:22.640]   brain, you just, the process that builds it just continues and it'll improve exponentially.
[00:02:22.640 --> 00:02:31.480]   So that's the logic that's used actually by almost everybody that is worried about super
[00:02:31.480 --> 00:02:32.480]   human intelligence.
[00:02:32.480 --> 00:02:33.480]   - Yeah.
[00:02:33.480 --> 00:02:38.560]   - So you're trying to make, so most people who are skeptical of that are kind of like,
[00:02:38.560 --> 00:02:42.160]   this doesn't, their thought process, this doesn't feel right.
[00:02:42.160 --> 00:02:43.880]   Like that's for me as well.
[00:02:43.880 --> 00:02:50.520]   So I'm more like, it doesn't, the whole thing is shrouded in mystery where you can't really
[00:02:50.520 --> 00:02:54.200]   say anything concrete, but you could say this doesn't feel right.
[00:02:54.200 --> 00:02:56.880]   This doesn't feel like that's how the brain works.
[00:02:56.880 --> 00:03:01.880]   And you're trying to, with your blog posts and now making it a little more explicit.
[00:03:01.880 --> 00:03:07.520]   So one idea is that the brain doesn't exist alone.
[00:03:07.520 --> 00:03:10.120]   It exists within the environment.
[00:03:10.120 --> 00:03:15.480]   So you can't exponentially, you would have to somehow exponentially improve the environment
[00:03:15.480 --> 00:03:22.800]   and the brain together almost yet in order to create something that's much smarter in
[00:03:22.800 --> 00:03:26.840]   some kind of, of course we don't have a definition of intelligence.
[00:03:26.840 --> 00:03:27.840]   - That's correct.
[00:03:27.840 --> 00:03:28.840]   That's correct.
[00:03:28.840 --> 00:03:32.760]   I don't think, if you look at very smart people today, even humans, not even talking about
[00:03:32.760 --> 00:03:40.080]   AIs, I don't think their brain and the performance of their brain is the bottleneck to the expressed
[00:03:40.080 --> 00:03:43.320]   intelligence, to their achievements.
[00:03:43.320 --> 00:03:49.440]   You cannot just tweak one part of the system, like of this brain body environment system
[00:03:49.440 --> 00:03:55.760]   and expect capabilities like what emerges out of this system to just, you know, explode
[00:03:55.760 --> 00:03:57.240]   exponentially.
[00:03:57.240 --> 00:04:03.520]   Because anytime you improve one part of a system with many interdependencies like this,
[00:04:03.520 --> 00:04:05.680]   there's a new bottleneck that arises, right?
[00:04:05.680 --> 00:04:10.920]   And I don't think even today for very smart people, their brain is not the bottleneck
[00:04:10.920 --> 00:04:12.960]   to the sort of problems they can solve.
[00:04:12.960 --> 00:04:13.960]   Right?
[00:04:13.960 --> 00:04:18.880]   In fact, many very smart people today, you know, they're not actually solving any big
[00:04:18.880 --> 00:04:19.880]   scientific problems.
[00:04:19.880 --> 00:04:20.880]   They're not Einstein.
[00:04:20.880 --> 00:04:28.000]   They're like Einstein, but you know, the patent clerk days, like Einstein became Einstein
[00:04:28.000 --> 00:04:34.840]   because this was a meeting of a genius with a big problem at the right time.
[00:04:34.840 --> 00:04:35.840]   Right?
[00:04:35.840 --> 00:04:38.680]   But maybe this meeting could have never happened.
[00:04:38.680 --> 00:04:40.640]   And then Einstein would have just been a patent clerk.
[00:04:40.640 --> 00:04:41.640]   Right?
[00:04:41.640 --> 00:04:47.840]   And in fact, many people today are probably like genius level smart, but you wouldn't
[00:04:47.840 --> 00:04:50.280]   know because they're not really expressing any of that.
[00:04:50.280 --> 00:04:51.280]   Wow.
[00:04:51.280 --> 00:04:52.280]   That's brilliant.
[00:04:52.280 --> 00:04:58.880]   We can think of the world, earth, but also the universe as just as a space of problems.
[00:04:58.880 --> 00:05:03.420]   So all of these problems and tasks are roaming it of various difficulty.
[00:05:03.420 --> 00:05:08.600]   And there's agents, creatures like ourselves and animals and so on that are also roaming
[00:05:08.600 --> 00:05:09.600]   it.
[00:05:09.600 --> 00:05:13.920]   And then you get coupled with a problem and then you solve it.
[00:05:13.920 --> 00:05:18.760]   But without that coupling, you can't demonstrate your quote unquote intelligence.
[00:05:18.760 --> 00:05:19.760]   Exactly.
[00:05:19.760 --> 00:05:25.000]   So intelligence is the meeting of great problem solving capabilities with a great problem.
[00:05:25.000 --> 00:05:28.440]   And if you don't have the problem, you don't really express an intelligence.
[00:05:28.440 --> 00:05:32.680]   All you're left with is potential intelligence, like the performance of your brain or, you
[00:05:32.680 --> 00:05:37.320]   know, how high your IQ is, which in itself is just a number.
[00:05:37.320 --> 00:05:38.320]   Right.
[00:05:38.320 --> 00:05:38.320]   Yeah.
[00:05:38.320 --> 00:05:43.320]   Thank you.
[00:05:43.320 --> 00:05:48.320]   Thank you.
[00:05:48.320 --> 00:05:53.320]   Thank you.
[00:05:53.320 --> 00:06:03.320]   [BLANK_AUDIO]

