
[00:00:00.000 --> 00:00:07.600]   I wanted to first introduce Numeri and then share my screen and show you a few things.
[00:00:07.600 --> 00:00:13.440]   So the first thing about Numeri is that we're kind of an open hedge fund.
[00:00:13.440 --> 00:00:18.280]   We give away all of our data for free and allow anyone in the world to model the data
[00:00:18.280 --> 00:00:19.600]   that we give.
[00:00:19.600 --> 00:00:24.000]   So usually it's the last thing a hedge fund would ever do, but Numeri does it because
[00:00:24.000 --> 00:00:27.640]   we want to get the best possible talent looking at our data.
[00:00:27.640 --> 00:00:32.760]   So it's almost a little bit like a Kaggle competition if you're familiar with that,
[00:00:32.760 --> 00:00:35.240]   except all the data is obfuscated.
[00:00:35.240 --> 00:00:40.400]   So you have no idea really what you're modeling, but for any good data scientist, you can still
[00:00:40.400 --> 00:00:44.700]   find the structure of the data without knowing what the features are.
[00:00:44.700 --> 00:00:52.680]   But I did want to share a little bit about what is unique about the stock market and
[00:00:52.680 --> 00:01:00.800]   the most common problems that people have with overfitting in machine learning are kind
[00:01:00.800 --> 00:01:04.080]   of somehow way worse in finance.
[00:01:04.080 --> 00:01:08.520]   And this isn't very well understood by most people.
[00:01:08.520 --> 00:01:13.040]   And so I'll try to share some of the...
[00:01:13.040 --> 00:01:19.440]   So this is your classic back test.
[00:01:19.440 --> 00:01:27.120]   It has a kind of very good historical portion where you trained your model and then it just
[00:01:27.120 --> 00:01:30.520]   stops working whenever you trade it live.
[00:01:30.520 --> 00:01:32.920]   Your performance gets much worse.
[00:01:32.920 --> 00:01:36.360]   And this is the common pattern you see.
[00:01:36.360 --> 00:01:41.960]   And on the one hand, yeah, all machine learning problems have this.
[00:01:41.960 --> 00:01:49.260]   You can easily overfit a face detection algorithm and have your in-sample performance or even
[00:01:49.260 --> 00:01:54.000]   your holdout performance be worse than some other new set that you're shown later.
[00:01:54.000 --> 00:02:00.160]   But there is something special about finance where this is very common and perplexes a
[00:02:00.160 --> 00:02:02.480]   lot of people.
[00:02:02.480 --> 00:02:09.360]   So first just to show you a little bit about numerized data to describe this problem.
[00:02:09.360 --> 00:02:11.760]   This is what it looks like.
[00:02:11.760 --> 00:02:12.840]   You can get this on GitHub.
[00:02:12.840 --> 00:02:17.640]   It's just called our analysis and tips notebook.
[00:02:17.640 --> 00:02:20.720]   And it shows all the data that we have.
[00:02:20.720 --> 00:02:22.120]   This is what it looks like.
[00:02:22.120 --> 00:02:29.960]   You have all these features and we call them off the Dungeons and Dragons names.
[00:02:29.960 --> 00:02:32.560]   And you also have a target.
[00:02:32.560 --> 00:02:37.720]   And the target variable and the features are obfuscated to you, but you're trying to basically
[00:02:37.720 --> 00:02:40.000]   use these features to model this target.
[00:02:40.000 --> 00:02:43.360]   So it seems like a very simple supervised learning problem.
[00:02:43.360 --> 00:02:47.200]   And if you treat it that way, you will do quite badly.
[00:02:47.200 --> 00:02:56.560]   Because there's a few things that you're missing.
[00:02:56.560 --> 00:03:00.280]   So the first thing to notice is this column called era.
[00:03:00.280 --> 00:03:03.720]   Now the big problem with stock market data is time.
[00:03:03.720 --> 00:03:09.360]   And there's a lot of problems with the data modeling because all the data is in different
[00:03:09.360 --> 00:03:11.200]   time periods.
[00:03:11.200 --> 00:03:13.920]   And we call these eras on Numerai.
[00:03:13.920 --> 00:03:17.080]   And what happens is people ignore the eras.
[00:03:17.080 --> 00:03:20.440]   They think their model is a lot better than it really is.
[00:03:20.440 --> 00:03:25.880]   And they end up making a model that doesn't generalize very well.
[00:03:25.880 --> 00:03:30.600]   And so you have to kind of take care that there is this time component.
[00:03:30.600 --> 00:03:32.680]   And there aren't that many eras.
[00:03:32.680 --> 00:03:37.360]   There are only about 100 or something eras.
[00:03:37.360 --> 00:03:43.320]   And so when you think about modeling this data, even though there's half a million rows,
[00:03:43.320 --> 00:03:46.800]   if there are very few eras, eras are the important thing.
[00:03:46.800 --> 00:03:48.400]   Eras are what's unique.
[00:03:48.400 --> 00:03:54.360]   Because in that time section, everything inside that time section, that era, is happening
[00:03:54.360 --> 00:03:55.800]   at the same time.
[00:03:55.800 --> 00:04:00.000]   So the data isn't independent by row.
[00:04:00.000 --> 00:04:02.280]   It's only independent by era.
[00:04:02.280 --> 00:04:04.880]   So this is over a decade of data.
[00:04:04.880 --> 00:04:13.200]   But you actually have very little number of independent observations.
[00:04:13.200 --> 00:04:14.640]   So that's one key thing.
[00:04:14.640 --> 00:04:18.360]   And then the other key thing is how the features interact with each other.
[00:04:18.360 --> 00:04:25.200]   So what happens with most models, going back to this, is during the learning phase, when
[00:04:25.200 --> 00:04:31.800]   you train on historical data, what happens is your model will pick up on the best risk
[00:04:31.800 --> 00:04:32.840]   for that period.
[00:04:32.840 --> 00:04:34.960]   Not the best alpha for that period.
[00:04:34.960 --> 00:04:36.680]   The best risk for that period.
[00:04:36.680 --> 00:04:43.620]   So if it was a period where momentum of common stock factor did well, or a period where value
[00:04:43.620 --> 00:04:49.560]   did well, these things will come out extremely strong in, say, the coefficient of a linear
[00:04:49.560 --> 00:04:51.560]   model that you made.
[00:04:51.560 --> 00:04:55.280]   And the trick in some ways with finance is kind of very strange.
[00:04:55.280 --> 00:05:00.640]   You have to model-- you have to create a model that sort of has some kind of coefficients
[00:05:00.640 --> 00:05:03.400]   on the features to predict something.
[00:05:03.400 --> 00:05:09.640]   But at the same time, you want the coefficients on the features to be as low as possible.
[00:05:09.640 --> 00:05:13.600]   So it's like a strange problem.
[00:05:13.600 --> 00:05:20.160]   Because in some ways, you don't want to have risk exposures to the features.
[00:05:20.160 --> 00:05:22.080]   Because they're really just adding risk.
[00:05:22.080 --> 00:05:24.760]   And they're not adding alpha.
[00:05:24.760 --> 00:05:34.400]   So what happens on Numeri, a lot of our users do something called feature neutralization.
[00:05:34.400 --> 00:05:40.080]   And feature neutralization is-- we have it in this example script that we give out.
[00:05:40.080 --> 00:05:46.280]   If you go to our website, you can download all this data for free and these example scripts.
[00:05:46.280 --> 00:05:53.380]   We actually include a little bit of code that does a linear projection.
[00:05:53.380 --> 00:05:58.080]   So what this is doing is saying, well, you've built a nonlinear model with a neural net.
[00:05:58.080 --> 00:06:04.220]   But I don't want to take on all these linear exposures to what are really just risks.
[00:06:04.220 --> 00:06:12.160]   And this does this linear projection, projects out these risks, and leaves what's left, the
[00:06:12.160 --> 00:06:18.680]   really high quality alpha, the alpha that isn't just something that's in the features
[00:06:18.680 --> 00:06:20.280]   in a linear way.
[00:06:20.280 --> 00:06:26.120]   And what tends to happen if you can take off those features, then suddenly your estimates
[00:06:26.120 --> 00:06:27.120]   go down.
[00:06:27.120 --> 00:06:31.680]   You're like, well, jeez, I actually don't have as good a model as I think in sample.
[00:06:31.680 --> 00:06:38.480]   But it's actually a model that generalizes very well out of sample.
[00:06:38.480 --> 00:06:43.560]   And in most machine learning, typically the feature that you like the most is the feature
[00:06:43.560 --> 00:06:45.800]   you really want to keep.
[00:06:45.800 --> 00:06:51.160]   But in finance, the feature you like the most is the most dangerous risk that you're exposed
[00:06:51.160 --> 00:06:52.320]   to.
[00:06:52.320 --> 00:06:55.560]   And you have to reduce that risk.
[00:06:55.560 --> 00:07:01.000]   Otherwise, your model won't generalize and you will do extremely badly in live data.
[00:07:01.000 --> 00:07:07.240]   So that's kind of like a little bit of a secret about how to make your models generalize in
[00:07:07.240 --> 00:07:08.240]   finance.
[00:07:08.240 --> 00:07:09.560]   There's so much more to it.
[00:07:09.560 --> 00:07:15.960]   And I hope you get to take a look at the data and see some of this for yourself.
[00:07:15.960 --> 00:07:17.360]   Thank you.
[00:07:17.360 --> 00:07:21.860]   The first question that I have is actually-- so there's something very unintuitive to me
[00:07:21.860 --> 00:07:28.640]   as somebody who comes from science into machine learning about the idea that you'd want to--
[00:07:28.640 --> 00:07:31.460]   that you'd want an unsparse model.
[00:07:31.460 --> 00:07:36.600]   It seems like this neutralizing feature exposure idea, you try and have as many small parameters
[00:07:36.600 --> 00:07:39.760]   across as many pieces as possible.
[00:07:39.760 --> 00:07:44.800]   And in science, you're often trying to find a sparse linear model rather than a diffuse
[00:07:44.800 --> 00:07:45.800]   nonlinear model.
[00:07:45.800 --> 00:07:50.680]   So can you comment on why you think there's that big gap between what works and is useful
[00:07:50.680 --> 00:07:53.600]   in science and what works and is useful in finance?
[00:07:53.600 --> 00:07:56.240]   Yeah, it's a really good question.
[00:07:56.240 --> 00:08:01.800]   I mean, the way to think about it is kind of like that the risks and the alphas are
[00:08:01.800 --> 00:08:04.040]   kind of dual.
[00:08:04.040 --> 00:08:12.080]   On the one hand, anything you find, any exposure you find that you think is an alpha, meaning
[00:08:12.080 --> 00:08:18.440]   something that has correlation, subsequent correlation with returns, it could just as
[00:08:18.440 --> 00:08:21.840]   easily kind of turn around.
[00:08:21.840 --> 00:08:26.480]   And so if you want to operate-- it's almost like you have the assumption of, well, the
[00:08:26.480 --> 00:08:30.360]   market's actually efficient to every single feature that I have.
[00:08:30.360 --> 00:08:31.640]   Of course it is.
[00:08:31.640 --> 00:08:33.860]   Everybody's going to have learned from the past data.
[00:08:33.860 --> 00:08:42.040]   So what I actually will generalize is when I de-correlate myself from those basic factors
[00:08:42.040 --> 00:08:48.120]   and make a hedge fund that's quite differentiated from all the exposures that everyone else
[00:08:48.120 --> 00:08:49.120]   is taking on.
[00:08:49.120 --> 00:08:50.120]   I see.
[00:08:50.120 --> 00:08:55.880]   Yeah, because I think the motivation in science is to find a causal model of what's going
[00:08:55.880 --> 00:08:56.880]   on.
[00:08:56.880 --> 00:09:00.960]   That is, if I find something that's sparse, if I apply sort of like Occam's razor, then
[00:09:00.960 --> 00:09:07.600]   I'm finding something that's the real underlying model that causes the phenomena that I'm observing.
[00:09:07.600 --> 00:09:11.880]   But in finance, you don't necessarily want a causal model.
[00:09:11.880 --> 00:09:14.080]   You want a really good predictive model.
[00:09:14.080 --> 00:09:15.080]   Exactly.
[00:09:15.080 --> 00:09:21.320]   And what we see in our data is if you, in some ways, the less you know about how your
[00:09:21.320 --> 00:09:22.660]   model works, the better.
[00:09:22.660 --> 00:09:27.080]   It's like it's somehow especially good for machine learning.
[00:09:27.080 --> 00:09:31.680]   A linear model, like I said, would only have just positive or negative coefficients on
[00:09:31.680 --> 00:09:33.360]   the features.
[00:09:33.360 --> 00:09:36.080]   And if you took those down to zero, you'd have nothing left.
[00:09:36.080 --> 00:09:41.360]   But a nonlinear model, there's actually something left, and that's often the gold.
[00:09:41.360 --> 00:09:45.200]   And that's what we want people to focus on learning, because that tends to generalize
[00:09:45.200 --> 00:09:47.200]   better.
[00:09:47.200 --> 00:09:50.360]   Interesting.
[00:09:50.360 --> 00:09:55.500]   And so then how do you see-- so there's this idea of neutralizing feature exposure.
[00:09:55.500 --> 00:10:00.200]   How does that play into this new Numerai Signals tool that you're putting out, or this new
[00:10:00.200 --> 00:10:01.800]   sort of kind of contest?
[00:10:01.800 --> 00:10:02.800]   Yeah.
[00:10:02.800 --> 00:10:08.200]   So Numerai Signals is a brand new thing we launched just about two weeks ago.
[00:10:08.200 --> 00:10:12.400]   And like I said, with Numerai, we give out all of our data.
[00:10:12.400 --> 00:10:13.720]   And our data is kind of expensive.
[00:10:13.720 --> 00:10:18.560]   It's this high-quality data you probably couldn't find, but it's all in this obfuscated way.
[00:10:18.560 --> 00:10:23.800]   But there are people out there who maybe have some of their own data already, and they have
[00:10:23.800 --> 00:10:28.880]   cobbled together some Yahoo Finance data and combined it with some Bloomberg data, and
[00:10:28.880 --> 00:10:32.920]   they've built their own signal out of that.
[00:10:32.920 --> 00:10:37.240]   And we want to say, well, if you have a signal like that, you should come to us, too.
[00:10:37.240 --> 00:10:40.720]   We also want signals made on data that isn't ours.
[00:10:40.720 --> 00:10:42.000]   And that's what Numerai Signals is.
[00:10:42.000 --> 00:10:46.600]   You can come and submit your signal to us and get rewarded for it.
[00:10:46.600 --> 00:10:54.040]   But the twist is we are not really looking for a signal that is really correlated with
[00:10:54.040 --> 00:10:56.980]   return, really predictive of return.
[00:10:56.980 --> 00:11:02.900]   In some sense, because we already have a lot of signals that are predictive with return.
[00:11:02.900 --> 00:11:09.920]   So if you bring a model that we already have, we kind of think we should pay you zero.
[00:11:09.920 --> 00:11:16.400]   But if you bring a model that is uncorrelated from everything we have, i.e. neutral to everything
[00:11:16.400 --> 00:11:23.200]   we have, like a projection of everything we have, and also still has alpha even after
[00:11:23.200 --> 00:11:28.720]   we do that neutralization to your signal, then you really have something.
[00:11:28.720 --> 00:11:32.640]   And that's much more valuable, and we pay a lot for that.
[00:11:32.640 --> 00:11:34.520]   I see.
[00:11:34.520 --> 00:11:42.320]   So then, so how do you generate, I guess, so if I'm sitting here at home making my signal
[00:11:42.320 --> 00:11:49.280]   that I want to send to Numerai, what kinds of things can I do to ensure that what I think
[00:11:49.280 --> 00:11:51.880]   is valuable is also what you guys are going to think is valuable?
[00:11:51.880 --> 00:11:54.880]   How do I seek alpha, so to speak?
[00:11:54.880 --> 00:11:57.800]   Yeah, no, it is something of a black box.
[00:11:57.800 --> 00:12:01.720]   What we do say is anything basic probably won't work.
[00:12:01.720 --> 00:12:07.400]   So we have, no surprise, we have the PE ratio of every single stock in the world, and we
[00:12:07.400 --> 00:12:11.200]   have it for 15, 18 years or so.
[00:12:11.200 --> 00:12:16.080]   So if you come with, and you just start submitting the PE ratios of stocks, we will neutralize
[00:12:16.080 --> 00:12:21.240]   that by our PE, you'll have nothing left, and you won't do well.
[00:12:21.240 --> 00:12:28.200]   But if you create a complicated model, and it's on unusual data, then you're very likely
[00:12:28.200 --> 00:12:35.040]   to have a good portion of that be orthogonal to the models produced on Numerai and the
[00:12:35.040 --> 00:12:36.840]   data that we have.
[00:12:36.840 --> 00:12:42.200]   So basically, it's like, don't give us something you know kind of everyone has, and then you'll
[00:12:42.200 --> 00:12:45.680]   be good.
[00:12:45.680 --> 00:12:50.200]   So I mean, perhaps some of this stuff is proprietary information.
[00:12:50.200 --> 00:12:56.800]   But do you have any examples of signals that have been useful in this tool so far, or like
[00:12:56.800 --> 00:12:59.160]   a prototypical example to share?
[00:12:59.160 --> 00:13:02.920]   Well, we have been surprised by some of them.
[00:13:02.920 --> 00:13:07.920]   We thought it was kind of, so Numerai, we say is the hardest data science term in the
[00:13:07.920 --> 00:13:10.320]   world, because you have to deal with all these problems.
[00:13:10.320 --> 00:13:14.960]   It's not just like downloading a Kaggle data set and building an XGBoost.
[00:13:14.960 --> 00:13:19.240]   There's a lot more to think about, and it goes deep.
[00:13:19.240 --> 00:13:23.160]   That's why we have users who've been there for many years.
[00:13:23.160 --> 00:13:28.880]   But signals, we were very surprised to see that in the first few days of it, there were
[00:13:28.880 --> 00:13:37.800]   people uploading signals that were very orthogonal and had a lot more orthogonal than we could
[00:13:37.800 --> 00:13:42.960]   even make ourselves if we really tried.
[00:13:42.960 --> 00:13:49.560]   So it does seem like, and there's some people in Japan that are really strong.
[00:13:49.560 --> 00:13:56.080]   There are also some people from Numerai itself who've started building signals.
[00:13:56.080 --> 00:14:02.640]   So I think we're pretty surprised, and who knows what data sets they're using to create
[00:14:02.640 --> 00:14:03.640]   these.
[00:14:03.640 --> 00:14:04.640]   We don't know.
[00:14:04.640 --> 00:14:07.480]   They never give us their model or their data.
[00:14:07.480 --> 00:14:10.200]   They're only giving us the output of their signal.
[00:14:10.200 --> 00:14:14.200]   So it's kind of cool in a way, like we don't really know what they're doing to generate
[00:14:14.200 --> 00:14:15.200]   these things.
[00:14:15.200 --> 00:14:16.200]   I see.
[00:14:16.200 --> 00:14:17.200]   Interesting.
[00:14:17.200 --> 00:14:23.200]   Maybe, so I guess one of the famous examples of the application of machine learning in
[00:14:23.200 --> 00:14:29.280]   finance was predicting crop yields months ahead of time using satellite data.
[00:14:29.280 --> 00:14:31.240]   I forget who the people were who did that.
[00:14:31.240 --> 00:14:34.520]   I don't know if you recall.
[00:14:34.520 --> 00:14:39.720]   So is that the kind of thing that generates the signals that you would be interested in,
[00:14:39.720 --> 00:14:42.240]   or is it maybe a little bit more financial data?
[00:14:42.240 --> 00:14:48.240]   Yeah, I think that is always the kind of like, that's a bigger story than it's real.
[00:14:48.240 --> 00:14:55.080]   The main alternative data that you want is going to apply to lots of stocks.
[00:14:55.080 --> 00:14:59.480]   And so if someone told me something about one stock, that's not a quant model.
[00:14:59.480 --> 00:15:00.680]   That's not a signal.
[00:15:00.680 --> 00:15:03.000]   That's just someone's stock tip.
[00:15:03.000 --> 00:15:05.320]   And Numerai Signals isn't for that.
[00:15:05.320 --> 00:15:08.200]   It's for like broad cross-sectional.
[00:15:08.200 --> 00:15:12.020]   You have some data that applies to 5,000 stocks.
[00:15:12.020 --> 00:15:17.840]   And it could be some NLP signal based off Twitter, or it could be anything, but usually
[00:15:17.840 --> 00:15:22.280]   it's got to be really broad for it to be valuable.
[00:15:22.280 --> 00:15:24.440]   Because we never put the fund in one stock, right?
[00:15:24.440 --> 00:15:25.920]   So we need broad people.
[00:15:25.920 --> 00:15:26.920]   Right, right.
[00:15:26.920 --> 00:15:27.920]   Certainly.
[00:15:27.920 --> 00:15:32.320]   That seems, I don't know that much about finance, but that sounds like a bad idea.
[00:15:32.320 --> 00:15:33.520]   Yeah.
[00:15:33.520 --> 00:15:38.040]   So we got a question in the Q&A, and I actually encourage folks watching on YouTube and folks
[00:15:38.040 --> 00:15:44.600]   in Zoom to post in the Q&A or in the live chat to ask questions, and I'll forward them
[00:15:44.600 --> 00:15:45.760]   to Richard.
[00:15:45.760 --> 00:15:52.280]   So the question is, how is this orthogonality assessed?
[00:15:52.280 --> 00:15:56.240]   You've given a couple of examples of ways to think about what this orthogonality means,
[00:15:56.240 --> 00:15:58.240]   this sort of uniqueness or originality.
[00:15:58.240 --> 00:16:00.920]   What more can you say about that?
[00:16:00.920 --> 00:16:06.200]   Well that code I shared earlier was super high level, but the code is exactly what we
[00:16:06.200 --> 00:16:07.200]   use.
[00:16:07.200 --> 00:16:10.600]   But we do it with every single feature that we have.
[00:16:10.600 --> 00:16:15.640]   So there are about 310 features that we have, and there are also what we call like nine
[00:16:15.640 --> 00:16:20.880]   risk factors, like country risk or sector risk.
[00:16:20.880 --> 00:16:25.040]   Because if someone posts a model that it really only did well just because it had exposure
[00:16:25.040 --> 00:16:28.720]   to the tech industry and the tech industry happened to do well, that's again not what
[00:16:28.720 --> 00:16:30.960]   we're looking for.
[00:16:30.960 --> 00:16:39.240]   So it is, and mathematically it's making this linear projection, it's regressing out all
[00:16:39.240 --> 00:16:46.000]   the linear exposures that you have to the things we have, and what's remaining is what's
[00:16:46.000 --> 00:16:51.960]   valuable to us.
[00:16:51.960 --> 00:17:01.040]   So you mentioned NLP signals maybe of behavior of users on social media, those sound like
[00:17:01.040 --> 00:17:02.040]   useful features.
[00:17:02.040 --> 00:17:06.720]   Any other thoughts about what things might be orthogonal?
[00:17:06.720 --> 00:17:08.800]   Yeah I think NLP is quite a big one.
[00:17:08.800 --> 00:17:12.240]   It's one I'm quite excited about.
[00:17:12.240 --> 00:17:17.760]   We actually did buy some news sentiment data, but they kind of mess it up.
[00:17:17.760 --> 00:17:23.200]   And if you look at it, whenever we go talk to a new data vendor, they say, "Oh we have
[00:17:23.200 --> 00:17:24.400]   all this data.
[00:17:24.400 --> 00:17:30.400]   We test it, it's got no original compared to what we already have."
[00:17:30.400 --> 00:17:36.160]   So I like that we're putting it out to the world and saying, "Anyone can kind of be a
[00:17:36.160 --> 00:17:38.480]   data vendor to us and provide anything."
[00:17:38.480 --> 00:17:43.360]   But NLP is the one I'm kind of the most excited about, and we have a user who's really experienced
[00:17:43.360 --> 00:17:51.520]   with NLP and has even written some numerite jokes with GPT-3 before to show us.
[00:17:51.520 --> 00:17:56.480]   And I think it's not really, I kind of, yeah, like I said, I'm quite skeptical of the alternative
[00:17:56.480 --> 00:17:57.480]   data craze.
[00:17:57.480 --> 00:18:02.400]   There's a lot you can do with very good modeling on normal data.
[00:18:02.400 --> 00:18:08.600]   And there's a lot of text out there that companies have to produce about their funds or have
[00:18:08.600 --> 00:18:12.320]   to make statements about their companies.
[00:18:12.320 --> 00:18:18.280]   So mining that data, because it's already quite structured, I think there's quite a
[00:18:18.280 --> 00:18:22.480]   lot even there that we wouldn't have and that would do well.
[00:18:22.480 --> 00:18:31.360]   Yeah, I guess what I'm kind of aiming at is in your Numerise Signals blog post on Medium,
[00:18:31.360 --> 00:18:33.800]   you asked sort of, "Where is the next Ken Griffin?"
[00:18:33.800 --> 00:18:39.680]   And it seemed like one of the motivations you had was this idea that the power of crowds
[00:18:39.680 --> 00:18:45.320]   of people in garages with internet connections to find signals.
[00:18:45.320 --> 00:18:52.840]   So I guess, yeah, what do you think those next Ken Griffins, it seems like alternative
[00:18:52.840 --> 00:18:57.280]   data sources aren't the right thing, but what do you think those next Ken Griffins are and
[00:18:57.280 --> 00:18:59.760]   should be working on?
[00:18:59.760 --> 00:19:09.760]   Well, the other side of it is that Numerise Signals is just one week long predictions,
[00:19:09.760 --> 00:19:12.600]   whereas Numerise is one month long.
[00:19:12.600 --> 00:19:15.840]   And so there's actually a lot of things that work on a one week time horizon that would
[00:19:15.840 --> 00:19:17.360]   not work on a one month horizon.
[00:19:17.360 --> 00:19:23.440]   And a lot of that is actually technical data, which is data that's kind of built from the
[00:19:23.440 --> 00:19:25.160]   price series.
[00:19:25.160 --> 00:19:29.720]   And oftentimes you can have a very good technical model, but because it trades so often, it's
[00:19:29.720 --> 00:19:30.720]   hard.
[00:19:30.720 --> 00:19:32.880]   You don't really make money off the costs.
[00:19:32.880 --> 00:19:36.640]   But technical features would be great.
[00:19:36.640 --> 00:19:40.500]   And we don't have lots of technical features at Numerise.
[00:19:40.500 --> 00:19:45.280]   And so I would say what's quite nice about that is anyone can make those, you just need
[00:19:45.280 --> 00:19:46.680]   the price.
[00:19:46.680 --> 00:19:49.680]   And there's very easy access to get the price data.
[00:19:49.680 --> 00:19:51.760]   And then you can make your own technical features.
[00:19:51.760 --> 00:19:54.640]   So I think a lot of models will be like that.
[00:19:54.640 --> 00:19:57.840]   Interesting.
[00:19:57.840 --> 00:20:03.160]   What do you think the next sort of, you know, short term, shorter term than the master plan
[00:20:03.160 --> 00:20:06.520]   of building the last hedge fund?
[00:20:06.520 --> 00:20:11.000]   What are sort of the shorter term ways you want to extend either the core data science
[00:20:11.000 --> 00:20:13.320]   tournament or the signals product?
[00:20:13.320 --> 00:20:15.880]   Well, it's yeah, it's just two weeks old.
[00:20:15.880 --> 00:20:18.400]   It's doubling every week so far.
[00:20:18.400 --> 00:20:20.400]   But it's just two weeks.
[00:20:20.400 --> 00:20:23.280]   We think there will be a lot of staking there.
[00:20:23.280 --> 00:20:25.560]   The way Numerise works is you stake your models.
[00:20:25.560 --> 00:20:30.440]   Numerise has $5 million or so, maybe four and a half million dollars staked.
[00:20:30.440 --> 00:20:34.080]   Signals just started but has $24,000 staked.
[00:20:34.080 --> 00:20:39.340]   A year ago, all of Numerise put together was $20,000 staked.
[00:20:39.340 --> 00:20:41.040]   So it's really grown a lot.
[00:20:41.040 --> 00:20:47.080]   And the main focus is on those two things for now in the medium term.
[00:20:47.080 --> 00:20:53.200]   And you know, the one thing we've also been building for a while, and we haven't taken
[00:20:53.200 --> 00:20:55.600]   on capital to our fund.
[00:20:55.600 --> 00:20:59.760]   So at some point next year, we'll probably do that.
[00:20:59.760 --> 00:21:04.240]   But ultimately, the fund is really just for institutional investors, and it's not really
[00:21:04.240 --> 00:21:07.560]   open to the public or our users.
[00:21:07.560 --> 00:21:13.600]   But I think the exciting thing is, you know, is the master plan to monopolise intelligence,
[00:21:13.600 --> 00:21:17.900]   number one, monopolise data, number two, which is what signals is about getting external
[00:21:17.900 --> 00:21:19.080]   data in.
[00:21:19.080 --> 00:21:22.560]   And the third thing is monopolise money.
[00:21:22.560 --> 00:21:28.160]   And so we're kind of going step by step.
[00:21:28.160 --> 00:21:33.840]   So there's this investor who you may have heard of, he lives in Nebraska, so you might
[00:21:33.840 --> 00:21:38.300]   not have heard of him, but Warren Buffett, who says that you should only invest in companies
[00:21:38.300 --> 00:21:39.600]   that have moats.
[00:21:39.600 --> 00:21:44.320]   So what do you think are like, as you mentioned, you know, monopolise shows up in the master
[00:21:44.320 --> 00:21:46.060]   plan of Numerise a couple times.
[00:21:46.060 --> 00:21:51.840]   So what do you think allows you to sort of build those moats to protect your monopolies
[00:21:51.840 --> 00:21:55.960]   in data and in intelligence?
[00:21:55.960 --> 00:22:01.840]   Well, I think you can make, you know, monopoly, it's something like it has negative connotations,
[00:22:01.840 --> 00:22:06.880]   but it's a kind of good word, I think, for what we're trying to say.
[00:22:06.880 --> 00:22:12.760]   We don't, we want to be the best data science community and the most high paying and rewarding
[00:22:12.760 --> 00:22:14.720]   community.
[00:22:14.720 --> 00:22:18.640]   And we've already paid out over $40 million to our data scientists.
[00:22:18.640 --> 00:22:23.760]   There are a number of millionaires from Numerise, and not many people know that.
[00:22:23.760 --> 00:22:26.760]   And I think the community is the whole thing.
[00:22:26.760 --> 00:22:29.480]   We don't trade our own model.
[00:22:29.480 --> 00:22:33.120]   If you decide to rip your data out of signals, we don't have it anymore.
[00:22:33.120 --> 00:22:36.500]   If you decide to pull your model out of Numerise, we don't have it anymore.
[00:22:36.500 --> 00:22:41.880]   So we're really relying on the fact that we can make these incentives that bring a community
[00:22:41.880 --> 00:22:47.360]   together and because they're staking and engaged and making a lot more than they could in other
[00:22:47.360 --> 00:22:55.400]   ways, it's going to get really big and there won't be a reason to quit.
[00:22:55.400 --> 00:22:59.080]   And I do like it, it's kind of like to a Bitcoin, like you can think of our users almost as
[00:22:59.080 --> 00:23:02.280]   being the miners of Bitcoin or something.
[00:23:02.280 --> 00:23:07.240]   And they're doing data mining on our data, and then they're earning our cryptocurrency.
[00:23:07.240 --> 00:23:12.000]   And it's very sticky once you get a lot of miners, it's suddenly, well, this is the best
[00:23:12.000 --> 00:23:13.880]   place to be, why would I move?
[00:23:13.880 --> 00:23:18.320]   And I think that's happening with us and I think a lot of our users like it for that
[00:23:18.320 --> 00:23:19.320]   reason.
[00:23:19.320 --> 00:23:20.320]   I see.
[00:23:20.320 --> 00:23:26.000]   And in some ways, an even better analogy than to the Bitcoin miners would be to the Bitcoin
[00:23:26.000 --> 00:23:27.080]   traders, right?
[00:23:27.080 --> 00:23:32.160]   To the people who have been trading various forms of various coins and tokens.
[00:23:32.160 --> 00:23:37.400]   So do you see that as one of your competitors for mindshare and users?
[00:23:37.400 --> 00:23:43.880]   Or what would you say are some of your competitors, if there are any?
[00:23:43.880 --> 00:23:50.720]   Yeah, I do have a kind of a pet hatred of crypto traders, actually.
[00:23:50.720 --> 00:23:53.120]   They even call themselves DGens.
[00:23:53.120 --> 00:24:00.440]   They're not very likable, it's not something they aim for, it seems.
[00:24:00.440 --> 00:24:01.440]   Yeah, yeah.
[00:24:01.440 --> 00:24:05.360]   And they're not super focused on the long term or the consequences of their actions.
[00:24:05.360 --> 00:24:07.760]   But that's fine.
[00:24:07.760 --> 00:24:16.280]   I think, you know, ultimately the equity markets are a lot sort of better for the world than
[00:24:16.280 --> 00:24:17.620]   the crypto markets.
[00:24:17.620 --> 00:24:24.120]   And if you were an expert trader at Ponzi schemes, I don't think you should be proud of yourself.
[00:24:24.120 --> 00:24:30.200]   You know, no matter how good you are, you're doing the wrong thing.
[00:24:30.200 --> 00:24:33.520]   So yeah, but yeah, I think some of our users are very interested in crypto.
[00:24:33.520 --> 00:24:37.640]   Obviously, we have a cryptocurrency, so I don't hate crypto all through and through.
[00:24:37.640 --> 00:24:42.880]   I love the applications of crypto, the fact that you can use it to build communities and
[00:24:42.880 --> 00:24:44.680]   do things like staking.
[00:24:44.680 --> 00:24:50.120]   But yeah, we need to compete with the mindshare of the DeFi DGens.
[00:24:50.120 --> 00:24:54.280]   And some of the people, there's been some crypto projects that sort of say, you can
[00:24:54.280 --> 00:24:59.280]   just stake your cryptocurrency here and do nothing and earn 300% a year.
[00:24:59.280 --> 00:25:04.040]   And it's like, okay, well, how does that work long term?
[00:25:04.040 --> 00:25:06.680]   And everyone's like, we don't really care about the long term.
[00:25:06.680 --> 00:25:11.720]   So I think for Numeri, whenever people are using Numeri and staking on Numeri, it's much
[00:25:11.720 --> 00:25:13.600]   more about the long term.
[00:25:13.600 --> 00:25:18.580]   And it's much more about doing something like real.
[00:25:18.580 --> 00:25:23.760]   One last question from Michael in the Zoom Q&A.
[00:25:23.760 --> 00:25:30.080]   Do you see the quality of the meta model that is sort of generated by the data science tournament
[00:25:30.080 --> 00:25:31.760]   improve over time?
[00:25:31.760 --> 00:25:33.280]   Do you think there's a limit?
[00:25:33.280 --> 00:25:38.280]   And do you expect the same thing to happen with the output of the signals project?
[00:25:38.280 --> 00:25:41.920]   There is a very strange thing happening with the meta model.
[00:25:41.920 --> 00:25:45.360]   So meta model combines all the Numeri models together.
[00:25:45.360 --> 00:25:50.180]   And if you look at it over the last year, it's climbing.
[00:25:50.180 --> 00:25:53.580]   Not every week, some weeks it'll drop down, someone pulls their model out or something.
[00:25:53.580 --> 00:25:57.120]   But it's climbing kind of linearly.
[00:25:57.120 --> 00:26:00.440]   And you really should think there's like an asymptote to this, right?
[00:26:00.440 --> 00:26:01.840]   And we haven't been changing the data.
[00:26:01.840 --> 00:26:04.320]   So it's not like it's going up because of the data.
[00:26:04.320 --> 00:26:08.800]   We've given out some tips and validation data and other things.
[00:26:08.800 --> 00:26:13.340]   But it's quite impressive to me how it's still going up.
[00:26:13.340 --> 00:26:19.440]   And so I really like that idea of, you know, even if we did nothing, the community would
[00:26:19.440 --> 00:26:24.080]   make everything better without us releasing features.
[00:26:24.080 --> 00:26:25.600]   And that's the problem with most hedge funds.
[00:26:25.600 --> 00:26:30.120]   They find it hard to scale because they always have to be running out, buying new data, trying
[00:26:30.120 --> 00:26:31.120]   new things.
[00:26:31.120 --> 00:26:32.440]   And it's very chaotic.
[00:26:32.440 --> 00:26:38.040]   But Numeri, it's kind of even more chaotic, but the incentives keep it all aligned.
[00:26:38.040 --> 00:26:39.040]   Great.
[00:26:39.040 --> 00:26:42.520]   Well, that's good to hear.
[00:26:42.520 --> 00:26:47.800]   I'm excited to, you know, I think collaboration is a really important thing that both the
[00:26:47.800 --> 00:26:51.040]   machine learning community and the finance community could do better on.
[00:26:51.040 --> 00:27:02.840]   So I'm glad to hear from somebody who's putting so much into making that work well.
[00:27:02.840 --> 00:27:14.560]   Yeah, you're welcome.
[00:27:14.560 --> 00:27:20.320]   Thanks.

