
[00:00:00.000 --> 00:00:04.240]   With the introduction of OpenAI's new ChatGPT endpoint,
[00:00:04.240 --> 00:00:08.080]   the LangChain library have very quickly, unsurprisingly,
[00:00:08.080 --> 00:00:11.320]   added a ton of new support for chat.
[00:00:11.320 --> 00:00:13.000]   The reason for this is that,
[00:00:13.000 --> 00:00:16.080]   unlike previous large language model endpoints,
[00:00:16.080 --> 00:00:20.600]   the new ChatGPT endpoint is slightly different.
[00:00:20.600 --> 00:00:24.960]   It takes multiple inputs, and therefore, with LangChain,
[00:00:24.960 --> 00:00:29.660]   this new sort of approach to calling large language models
[00:00:29.660 --> 00:00:34.660]   has been supported with its own set of objects and functions.
[00:00:34.660 --> 00:00:38.060]   So the new ChatCompletion endpoint from OpenAI,
[00:00:38.060 --> 00:00:41.720]   it differs in the typical large language model endpoints
[00:00:41.720 --> 00:00:46.360]   in that you can essentially pass in three types of inputs
[00:00:46.360 --> 00:00:49.060]   that are defined or distinguished
[00:00:49.060 --> 00:00:50.960]   by these three different role types.
[00:00:50.960 --> 00:00:52.640]   These three different role types
[00:00:52.640 --> 00:00:55.880]   are system, user, and assistant.
[00:00:55.880 --> 00:01:00.880]   The system or system message acts as the initial prompt
[00:01:00.880 --> 00:01:04.700]   to the model in order to set up its behavior
[00:01:04.700 --> 00:01:06.220]   for the rest of the interaction.
[00:01:06.220 --> 00:01:10.360]   So for example, with ChatGPT, what you would find,
[00:01:10.360 --> 00:01:13.220]   before we even write anything,
[00:01:13.220 --> 00:01:18.220]   OpenAI have already passed in a system message to ChatGPT,
[00:01:18.220 --> 00:01:20.500]   kind of telling it how to behave.
[00:01:20.500 --> 00:01:24.060]   Then after that, we have the user messages.
[00:01:24.060 --> 00:01:27.200]   So user messages is like what we write, okay?
[00:01:27.200 --> 00:01:30.460]   So in ChatGPT, we write something that's a user message.
[00:01:30.460 --> 00:01:32.600]   And then the other one is the assistant message.
[00:01:32.600 --> 00:01:35.960]   Those are the responses that we get from ChatGPT, okay?
[00:01:35.960 --> 00:01:39.540]   So the assistant is what ChatGPT is producing.
[00:01:39.540 --> 00:01:42.040]   Now, when we use the endpoint,
[00:01:42.040 --> 00:01:43.320]   for every new interaction,
[00:01:43.320 --> 00:01:46.200]   we're feeding in a history of previous interactions as well.
[00:01:46.200 --> 00:01:49.360]   So we're always gonna have that system message at the top.
[00:01:49.360 --> 00:01:51.760]   We're going to have a user message
[00:01:51.760 --> 00:01:54.240]   followed by an assistant message, followed by user message,
[00:01:54.240 --> 00:01:55.280]   and so on and so on.
[00:01:55.280 --> 00:01:59.160]   So there is some difference with this new endpoint.
[00:01:59.160 --> 00:02:04.160]   And therefore, how we interact with ChatGPT via LangChain
[00:02:04.160 --> 00:02:06.200]   is also different.
[00:02:06.200 --> 00:02:09.460]   So let's just jump straight into it.
[00:02:09.460 --> 00:02:12.260]   Okay, so we get started with a pip install.
[00:02:12.260 --> 00:02:14.440]   Here we're doing LangChain and OpenAI.
[00:02:14.440 --> 00:02:16.420]   There's only two libraries we use for this.
[00:02:16.420 --> 00:02:19.040]   Once those have been installed or updated,
[00:02:19.040 --> 00:02:22.240]   okay, so this is the latest version of OpenAI and LangChain.
[00:02:22.240 --> 00:02:24.380]   So you do need to update
[00:02:24.380 --> 00:02:27.380]   if you haven't updated them very recently.
[00:02:27.380 --> 00:02:30.280]   Now, what we'll do is start by initializing
[00:02:30.280 --> 00:02:32.440]   the chat OpenAI object.
[00:02:32.440 --> 00:02:35.520]   For that, we do need an OpenAI API key.
[00:02:35.520 --> 00:02:37.080]   So you can click this link.
[00:02:37.080 --> 00:02:39.320]   There will be a link to this notebook,
[00:02:39.320 --> 00:02:41.320]   so you can follow along at the top of the video
[00:02:41.320 --> 00:02:42.500]   somewhere right now.
[00:02:42.500 --> 00:02:46.800]   But this will take us across to this page here.
[00:02:46.800 --> 00:02:50.360]   So this is platform.openai.com.
[00:02:50.360 --> 00:02:52.900]   And what we do is we go to view API keys.
[00:02:52.900 --> 00:02:55.560]   We go to here, create a new secret key,
[00:02:55.560 --> 00:02:57.540]   and then you copy that secret key.
[00:02:57.540 --> 00:03:00.320]   And what you do is run this cell.
[00:03:00.320 --> 00:03:01.760]   And you can see at the top here,
[00:03:01.760 --> 00:03:03.920]   it says, tells me OpenAI API key.
[00:03:03.920 --> 00:03:06.720]   If you're on Colab, it will appear just below the cell.
[00:03:06.720 --> 00:03:09.440]   And you just paste your API key into there.
[00:03:09.440 --> 00:03:11.960]   Okay, that stores the API key into here.
[00:03:11.960 --> 00:03:14.580]   And then we come down here.
[00:03:14.580 --> 00:03:16.580]   And what we're going to do is initialize
[00:03:16.580 --> 00:03:18.900]   the chat OpenAI object.
[00:03:18.900 --> 00:03:23.900]   So for this, we're going to be using the chat GPT model.
[00:03:23.900 --> 00:03:27.420]   Now, by using this, we're essentially going to default
[00:03:27.420 --> 00:03:31.780]   to the latest version of chat GPT.
[00:03:31.780 --> 00:03:36.780]   So right now, the latest version is actually this here.
[00:03:36.780 --> 00:03:40.580]   Okay, so if you want to follow this video
[00:03:40.580 --> 00:03:43.620]   and the exact same responses in the future,
[00:03:43.620 --> 00:03:44.660]   you need to write this.
[00:03:44.660 --> 00:03:47.260]   But I will leave it like this.
[00:03:47.260 --> 00:03:51.900]   Basically, as they release new versions of this model,
[00:03:51.900 --> 00:03:53.900]   this will just default to the latest one.
[00:03:53.900 --> 00:03:58.180]   Now, when setting temperature to zero,
[00:03:58.180 --> 00:04:01.580]   that would make the completions fully deterministic
[00:04:01.580 --> 00:04:03.140]   as far as I could tell.
[00:04:03.140 --> 00:04:05.540]   So like running the same prompt twice,
[00:04:05.540 --> 00:04:07.060]   you'll get the same output.
[00:04:07.060 --> 00:04:08.540]   Now, we've seen this.
[00:04:08.540 --> 00:04:13.340]   So the chats with chat GPT are kind of structured like this.
[00:04:13.340 --> 00:04:17.300]   So we have system, user, assistant, user, assistant.
[00:04:17.300 --> 00:04:20.580]   That final empty assistant prompt there
[00:04:20.580 --> 00:04:24.420]   is kind of telling the model,
[00:04:24.420 --> 00:04:27.820]   like now it's your time to respond, right?
[00:04:27.820 --> 00:04:30.300]   So the model is just completing
[00:04:30.300 --> 00:04:32.780]   the end of this conversation.
[00:04:32.780 --> 00:04:36.820]   And the way that we format that is like this, okay?
[00:04:36.820 --> 00:04:40.500]   In LineChain, they kind of mirror this format.
[00:04:40.500 --> 00:04:42.420]   It's very similar, but slightly different.
[00:04:42.420 --> 00:04:44.860]   So we have these system message objects,
[00:04:44.860 --> 00:04:49.100]   a human message object, and an AI message object.
[00:04:49.100 --> 00:04:53.500]   So to create this up here, we would write this, okay?
[00:04:53.500 --> 00:04:54.900]   So we have these messages,
[00:04:54.900 --> 00:04:56.900]   and it's just a list of these, okay?
[00:04:56.900 --> 00:05:01.300]   In the order that they have been passed in the conversation.
[00:05:01.300 --> 00:05:02.900]   Okay, so we're just passing,
[00:05:02.900 --> 00:05:05.180]   we are stopping user for human message
[00:05:05.180 --> 00:05:07.180]   and assistant for AI message.
[00:05:07.180 --> 00:05:09.860]   Assistant message is still system message.
[00:05:09.860 --> 00:05:12.020]   And let's run this, okay?
[00:05:12.020 --> 00:05:13.900]   And let's run this.
[00:05:13.900 --> 00:05:16.380]   So this is going to generate a response
[00:05:16.380 --> 00:05:19.060]   from the chat GPT model, right?
[00:05:19.060 --> 00:05:20.140]   And I get this.
[00:05:20.140 --> 00:05:23.420]   So we have AI message, it's pretty long.
[00:05:23.420 --> 00:05:25.780]   So what we can do is just print it out,
[00:05:25.780 --> 00:05:28.500]   and we get this, it's still pretty long,
[00:05:28.500 --> 00:05:31.580]   but we can go along like so.
[00:05:31.580 --> 00:05:32.780]   All right, cool.
[00:05:32.780 --> 00:05:37.740]   Now, if we take a look up here at the initial response
[00:05:37.740 --> 00:05:40.300]   before printing out the response content,
[00:05:40.300 --> 00:05:43.380]   come to the start and we can see that it's an AI message.
[00:05:43.380 --> 00:05:46.820]   So it's the same type of object as this here.
[00:05:46.820 --> 00:05:49.860]   So that means that we can actually just append
[00:05:49.860 --> 00:05:54.620]   this AI message, our response, directly to messages here,
[00:05:54.620 --> 00:05:58.660]   and that will create the full conversation,
[00:05:58.660 --> 00:06:00.660]   including the latest response, all right?
[00:06:00.660 --> 00:06:02.060]   So that's what we're doing here.
[00:06:02.060 --> 00:06:04.660]   And then from there, we can just continue the conversation.
[00:06:04.660 --> 00:06:08.140]   So we will create a new human message prompt,
[00:06:08.140 --> 00:06:09.860]   we'll add that to our messages,
[00:06:09.860 --> 00:06:12.660]   and then we'll send all of those to chat GPT.
[00:06:12.660 --> 00:06:16.420]   Okay, so now what was the next question I asked?
[00:06:16.420 --> 00:06:20.940]   Why do physicists believe it can produce a unified theory?
[00:06:20.940 --> 00:06:23.540]   This is talking about string theory up here.
[00:06:23.540 --> 00:06:25.580]   And then it goes in and starts explaining
[00:06:25.580 --> 00:06:28.060]   that they believe that string theory has potential
[00:06:28.060 --> 00:06:31.100]   to produce a unified theory, because so on and so on.
[00:06:31.100 --> 00:06:32.100]   Okay, cool.
[00:06:32.100 --> 00:06:35.300]   Now, that is, I suppose, a core functionality
[00:06:35.300 --> 00:06:38.780]   of Lionchain's new chat features,
[00:06:38.780 --> 00:06:40.620]   but there are a few other things
[00:06:40.620 --> 00:06:43.100]   that they've introduced alongside these.
[00:06:43.100 --> 00:06:46.500]   So we have a few new prompt templates.
[00:06:46.500 --> 00:06:51.020]   So these new prompt templates, we have like a AI message,
[00:06:51.020 --> 00:06:54.860]   human message, and system message prompt template.
[00:06:54.860 --> 00:06:57.340]   And these are kind of just an extension
[00:06:57.340 --> 00:07:00.780]   of the original prompt templates in Lionchain.
[00:07:00.780 --> 00:07:03.940]   But when you use them, you have a couple of functions
[00:07:03.940 --> 00:07:07.540]   that will allow you to create your prompt template
[00:07:07.540 --> 00:07:10.740]   and output it as a system message, AI message,
[00:07:10.740 --> 00:07:12.180]   or user message.
[00:07:12.180 --> 00:07:14.980]   And you can also kind of like link them all together
[00:07:14.980 --> 00:07:17.940]   to create a list of messages that you then just pass
[00:07:17.940 --> 00:07:20.380]   straight into your chat endpoint.
[00:07:20.380 --> 00:07:25.380]   Now, I'm not super aware of like a huge number of reasons
[00:07:25.380 --> 00:07:30.620]   to use these right now, but these are part
[00:07:30.620 --> 00:07:32.980]   of the new features in Lionchain for chat.
[00:07:32.980 --> 00:07:36.060]   So I figure it is important to share these.
[00:07:36.060 --> 00:07:41.060]   And if it seems like something that would actually help you
[00:07:41.060 --> 00:07:43.980]   with whatever it is you're building, then that's great.
[00:07:43.980 --> 00:07:47.140]   You now know how, or you will know how to use them.
[00:07:47.140 --> 00:07:49.140]   So we'll come down to here.
[00:07:49.140 --> 00:07:51.100]   What I'm doing is I'm making sure
[00:07:51.100 --> 00:07:53.580]   I'm using the March model here.
[00:07:53.580 --> 00:07:57.260]   So we're going to set up our first system message,
[00:07:57.260 --> 00:08:00.100]   and we're going to create a human message,
[00:08:00.100 --> 00:08:01.820]   all right, our first input.
[00:08:01.820 --> 00:08:05.020]   Now, within this system message,
[00:08:05.020 --> 00:08:07.780]   I'm saying I want the responses to be no more
[00:08:07.780 --> 00:08:10.980]   than 100 characters long, including white space.
[00:08:10.980 --> 00:08:12.860]   And I want it to sign off every message
[00:08:12.860 --> 00:08:17.220]   with a random name like robot or Barbara, okay?
[00:08:17.220 --> 00:08:18.940]   We're just giving it tasks to do
[00:08:18.940 --> 00:08:21.220]   to see how well it follows these instructions.
[00:08:21.220 --> 00:08:26.220]   So run this, and now we make our first completion from this,
[00:08:26.220 --> 00:08:29.220]   and let's see how it does with those instructions.
[00:08:29.220 --> 00:08:32.020]   Okay, so the length is way out.
[00:08:32.020 --> 00:08:35.540]   Like we asked for 100 at maximum, it's 154.
[00:08:35.540 --> 00:08:40.420]   And it also didn't give us a sign off there as well.
[00:08:40.420 --> 00:08:43.860]   Now, this is kind of just an issue
[00:08:43.860 --> 00:08:48.100]   with the current version of ChatGPT.
[00:08:48.100 --> 00:08:49.780]   Okay, so with this version here.
[00:08:49.780 --> 00:08:52.780]   It's not very good at following system messages, apparently.
[00:08:52.780 --> 00:08:55.220]   It's kind of better to pass these instructions
[00:08:55.220 --> 00:08:56.540]   into your human message.
[00:08:56.540 --> 00:09:01.540]   But we might not want a user to have to specify these things.
[00:09:01.620 --> 00:09:03.820]   So maybe this is where we can use
[00:09:03.820 --> 00:09:05.860]   one of these prompt templates.
[00:09:05.860 --> 00:09:06.740]   So let's try.
[00:09:06.740 --> 00:09:11.180]   What we're gonna do is for every human message,
[00:09:11.180 --> 00:09:12.940]   we're gonna pass it into here, right?
[00:09:12.940 --> 00:09:14.780]   So we had that question before.
[00:09:14.780 --> 00:09:16.220]   Hi AI, how are you?
[00:09:16.220 --> 00:09:17.460]   What is quantum physics?
[00:09:17.460 --> 00:09:19.180]   We'd pass that into input here.
[00:09:19.180 --> 00:09:21.900]   And what I'm going to do is after the question,
[00:09:21.900 --> 00:09:25.740]   I'm gonna say, can you keep the response to no more
[00:09:25.740 --> 00:09:29.380]   than 100 characters, including white space,
[00:09:29.380 --> 00:09:31.220]   and sign off with a random name?
[00:09:31.220 --> 00:09:34.180]   So we create our prompt like this.
[00:09:34.180 --> 00:09:36.420]   So we have this LangChain prompts chat,
[00:09:36.420 --> 00:09:38.380]   and we have human message prompt template.
[00:09:38.380 --> 00:09:40.900]   And we also need to use this chat prompt template.
[00:09:40.900 --> 00:09:45.900]   I feel like this is a little bit convoluted at the moment,
[00:09:45.900 --> 00:09:47.740]   but this is just how it is.
[00:09:47.740 --> 00:09:50.980]   So we're gonna go through it anyway.
[00:09:50.980 --> 00:09:53.060]   So we have human message from template,
[00:09:53.060 --> 00:09:55.700]   and we're gonna have this, okay?
[00:09:55.700 --> 00:09:59.300]   This is just like a typical prompt template in LangChain.
[00:09:59.300 --> 00:10:01.020]   Then once we have that human template,
[00:10:01.020 --> 00:10:05.060]   we need to pass it to this chat prompt template
[00:10:05.060 --> 00:10:07.180]   and from messages, right?
[00:10:07.180 --> 00:10:10.820]   And then in there, we pass in like a list
[00:10:10.820 --> 00:10:13.020]   of whatever messages we want, right?
[00:10:13.020 --> 00:10:15.540]   So I will give you another example soon,
[00:10:15.540 --> 00:10:18.900]   but we can also pass multiple messages here,
[00:10:18.900 --> 00:10:22.220]   like system message, human message, AI message, and so on,
[00:10:22.220 --> 00:10:27.140]   which I found some way of kind of using that.
[00:10:27.140 --> 00:10:30.300]   So, I mean, I think that's kind of interesting at least.
[00:10:30.300 --> 00:10:31.940]   So we format that with some input.
[00:10:31.940 --> 00:10:34.700]   So we pass in this input here,
[00:10:34.700 --> 00:10:36.980]   how AI, how you, what is quantum physics,
[00:10:36.980 --> 00:10:39.100]   and let's see what we get from that.
[00:10:39.100 --> 00:10:42.460]   So we get this chat prompt value object,
[00:10:42.460 --> 00:10:46.180]   and it has messages, a list of messages in there.
[00:10:46.180 --> 00:10:48.860]   First message, and the only message is,
[00:10:48.860 --> 00:10:51.540]   hi AI, how are you, what is quantum physics, right?
[00:10:51.540 --> 00:10:52.780]   So that's our input.
[00:10:52.780 --> 00:10:54.380]   And then we have, can you keep the response
[00:10:54.380 --> 00:10:56.900]   to no more than 100 characters, including white space,
[00:10:56.900 --> 00:10:58.740]   sign off, so on and so on, right?
[00:10:58.740 --> 00:11:03.220]   So that is our template that is being applied based on this.
[00:11:03.220 --> 00:11:04.500]   All right, cool.
[00:11:04.500 --> 00:11:07.260]   Now, we come down to here,
[00:11:07.260 --> 00:11:11.460]   and to use our human message prompt template
[00:11:11.460 --> 00:11:16.140]   as a typical message or human message,
[00:11:16.140 --> 00:11:19.940]   we actually need to use this here, right?
[00:11:19.940 --> 00:11:22.460]   So we take our chat prompt value,
[00:11:22.460 --> 00:11:25.180]   which we created here and we can see here,
[00:11:25.180 --> 00:11:30.060]   and we can either pass it as two messages,
[00:11:30.060 --> 00:11:32.700]   that will give us the format that we need
[00:11:32.700 --> 00:11:35.100]   in order to pass it to chat GPT,
[00:11:35.100 --> 00:11:38.260]   or we can just create a string out of it, okay?
[00:11:38.260 --> 00:11:41.820]   So this would, I suppose, be pretty much the same
[00:11:41.820 --> 00:11:44.460]   as using an F string.
[00:11:44.460 --> 00:11:45.900]   The only thing that's added onto there
[00:11:45.900 --> 00:11:48.900]   is we have this human, right?
[00:11:48.900 --> 00:11:52.820]   Otherwise, it's literally just taking this
[00:11:52.820 --> 00:11:54.340]   and converting it into a string.
[00:11:54.340 --> 00:11:57.100]   Okay, so let's see if this approach works.
[00:11:57.100 --> 00:11:59.740]   Here, I'm just kind of throwing it all together.
[00:11:59.740 --> 00:12:02.980]   So we have the chat prompt, the input,
[00:12:02.980 --> 00:12:04.260]   hi, hi, how are you doing?
[00:12:04.260 --> 00:12:07.580]   That's going to create this,
[00:12:07.580 --> 00:12:09.700]   and then I'm going to convert two messages
[00:12:09.700 --> 00:12:11.060]   and take the first message,
[00:12:11.060 --> 00:12:12.740]   which is the only message in there,
[00:12:12.740 --> 00:12:16.460]   which is essentially going to give us this human message.
[00:12:16.460 --> 00:12:20.420]   Okay, and did I, can you keep the response
[00:12:20.420 --> 00:12:23.220]   to no more than 100 characters?
[00:12:23.220 --> 00:12:24.860]   And then here, I put 60 characters.
[00:12:24.860 --> 00:12:28.980]   So maybe I just put 100 here,
[00:12:28.980 --> 00:12:30.980]   and we'll try 60 later as well.
[00:12:30.980 --> 00:12:32.460]   So let's run that.
[00:12:32.460 --> 00:12:35.060]   All right, so you can see now it's listening.
[00:12:35.060 --> 00:12:37.860]   So we said 100 characters here, didn't really work,
[00:12:37.860 --> 00:12:39.580]   but then we did, we've also added it
[00:12:39.580 --> 00:12:43.220]   into this user or human message here,
[00:12:43.220 --> 00:12:45.500]   and now it's sticking to that, right?
[00:12:45.500 --> 00:12:47.260]   So length is good, let's keep going,
[00:12:47.260 --> 00:12:50.060]   and we also have this signed off with bot route.
[00:12:50.060 --> 00:12:53.380]   So that is working by adding those instructions
[00:12:53.380 --> 00:12:56.220]   into the user message, we're getting better results.
[00:12:56.220 --> 00:12:57.540]   Okay, cool.
[00:12:57.540 --> 00:12:59.820]   In my last attempt, I actually got slightly
[00:12:59.820 --> 00:13:01.980]   over the character limit, apparently.
[00:13:01.980 --> 00:13:03.820]   So I mean, we can run this again,
[00:13:03.820 --> 00:13:07.020]   and okay, so we've set temperature to zero here,
[00:13:07.020 --> 00:13:09.740]   and because of that, we would expect the output
[00:13:09.740 --> 00:13:11.700]   to be the same every single time.
[00:13:11.700 --> 00:13:13.140]   So it's deterministic.
[00:13:13.140 --> 00:13:15.540]   So quantum physics is very small scale.
[00:13:15.540 --> 00:13:17.940]   I think it's every time it's outputting the same.
[00:13:17.940 --> 00:13:21.980]   Okay, cool, and then let's continue with this.
[00:13:21.980 --> 00:13:23.460]   So I want to show you,
[00:13:23.460 --> 00:13:25.980]   we can use this prompt templating method
[00:13:25.980 --> 00:13:28.620]   in order to build a initial set of messages
[00:13:28.620 --> 00:13:32.060]   that we can basically use as like examples,
[00:13:32.060 --> 00:13:36.020]   like few shot training for our chat model.
[00:13:36.020 --> 00:13:38.540]   So what we can do like here,
[00:13:38.540 --> 00:13:42.060]   we've done 100 characters, right?
[00:13:42.060 --> 00:13:44.100]   Maybe we can go even lower,
[00:13:44.100 --> 00:13:47.860]   but maybe in that case, we might need to give some examples
[00:13:47.860 --> 00:13:49.380]   to the system, right?
[00:13:49.380 --> 00:13:51.260]   So let's do that.
[00:13:51.260 --> 00:13:53.900]   We're going to have this character limit,
[00:13:53.900 --> 00:13:57.340]   and we're going to have this sign off inputs or variables.
[00:13:57.340 --> 00:13:58.540]   For the human message,
[00:13:58.540 --> 00:14:03.540]   we're just going to pass in the input there, right?
[00:14:03.540 --> 00:14:04.820]   So for this first one,
[00:14:04.820 --> 00:14:06.900]   we're not going to pass in those instructions,
[00:14:06.900 --> 00:14:09.380]   because we're actually going to create this human message,
[00:14:09.380 --> 00:14:11.580]   and we're also going to create the following AI message
[00:14:11.580 --> 00:14:16.580]   as an example to the chatbot as to how it should respond.
[00:14:17.340 --> 00:14:19.980]   Okay, and we put all of these together.
[00:14:19.980 --> 00:14:22.260]   So we have the system template,
[00:14:22.260 --> 00:14:24.500]   the human template, and the AI template,
[00:14:24.500 --> 00:14:27.020]   like know that we're using AI message prompt template,
[00:14:27.020 --> 00:14:28.300]   human message prompt template,
[00:14:28.300 --> 00:14:30.980]   and system message prompt template for each of those.
[00:14:30.980 --> 00:14:34.820]   And what we do is create a list of messages.
[00:14:34.820 --> 00:14:36.780]   So it goes obviously the system message first,
[00:14:36.780 --> 00:14:40.820]   the human message second, and the AI message third.
[00:14:40.820 --> 00:14:43.220]   And these are the templates, right?
[00:14:43.220 --> 00:14:46.260]   So what we then do is we take our chat prompt,
[00:14:46.260 --> 00:14:47.940]   which is a list of these,
[00:14:47.940 --> 00:14:50.740]   and we format that prompt with our input.
[00:14:50.740 --> 00:14:52.100]   So we have the character limit,
[00:14:52.100 --> 00:14:53.420]   which we're going to set to 50,
[00:14:53.420 --> 00:14:56.420]   so half of what we had before, making it harder.
[00:14:56.420 --> 00:15:00.140]   I'm going to say the sign off has to be this robot,
[00:15:00.140 --> 00:15:04.180]   and the input is going to be the same as before.
[00:15:04.180 --> 00:15:07.180]   And then we're giving an example response, right?
[00:15:07.180 --> 00:15:09.780]   So good is the physics of small things.
[00:15:09.780 --> 00:15:13.100]   That example response is going to automatically
[00:15:13.100 --> 00:15:14.620]   have the sign off added to it.
[00:15:14.620 --> 00:15:16.860]   All right, so let's run this,
[00:15:16.860 --> 00:15:17.820]   and let's see what we get.
[00:15:17.820 --> 00:15:21.060]   So system message, you are a helpful assistant.
[00:15:21.060 --> 00:15:24.100]   You keep responses, no more than 50 characters long.
[00:15:24.100 --> 00:15:26.740]   You sign off every message with robot McRobot,
[00:15:26.740 --> 00:15:30.220]   so we can see where those are being added there.
[00:15:30.220 --> 00:15:34.340]   Human message, hi AI, what is quantum physics?
[00:15:34.340 --> 00:15:35.500]   So it's, you know,
[00:15:35.500 --> 00:15:37.780]   because we're just passing the input in there.
[00:15:37.780 --> 00:15:39.340]   And then we have the AI message.
[00:15:39.340 --> 00:15:44.340]   Good, it's physics of small things, robot McRobot, okay?
[00:15:44.940 --> 00:15:45.900]   Very short answer.
[00:15:45.900 --> 00:15:50.340]   And let's just see if that helps the system
[00:15:50.340 --> 00:15:52.540]   produce just very short answers.
[00:15:52.540 --> 00:15:57.540]   So we run this, and we get atoms, electrons, photons,
[00:15:57.540 --> 00:15:58.820]   and then it does the sign off.
[00:15:58.820 --> 00:16:01.220]   So I think that's a pretty good response.
[00:16:01.220 --> 00:16:03.020]   Let's try again.
[00:16:03.020 --> 00:16:05.860]   Right, so here we go slightly over.
[00:16:05.860 --> 00:16:09.380]   So we get like four characters over there.
[00:16:09.380 --> 00:16:11.740]   So maybe we can be more strict again.
[00:16:11.740 --> 00:16:16.300]   So what we can do is we add in that template
[00:16:16.300 --> 00:16:18.860]   that we used before where we add in the answer
[00:16:18.860 --> 00:16:23.060]   in less than the character limit, including white space.
[00:16:23.060 --> 00:16:26.980]   Okay, we're going to add that to our human message.
[00:16:26.980 --> 00:16:29.980]   So we're going to create the human message like this.
[00:16:29.980 --> 00:16:33.540]   So the chat prompt template and so on and so on.
[00:16:33.540 --> 00:16:34.380]   Okay, cool.
[00:16:34.380 --> 00:16:36.260]   So is it like particle physics?
[00:16:36.260 --> 00:16:37.780]   That's why I asked before, yeah.
[00:16:37.780 --> 00:16:38.940]   So asking the same question,
[00:16:38.940 --> 00:16:41.020]   but we're adding that onto the end.
[00:16:41.020 --> 00:16:42.540]   So it's like particle physics,
[00:16:42.540 --> 00:16:45.220]   answering less than 50 characters, including white space.
[00:16:45.220 --> 00:16:46.980]   Then what I'm going to do is,
[00:16:46.980 --> 00:16:49.900]   so within the messages right now,
[00:16:49.900 --> 00:16:52.780]   we have this query that we created before,
[00:16:52.780 --> 00:16:54.460]   where we need to replace that query
[00:16:54.460 --> 00:16:56.540]   with our new modified query.
[00:16:56.540 --> 00:17:00.660]   So I'm going to remove the most recent message in messages,
[00:17:00.660 --> 00:17:04.940]   and I'm going to send it with this new human prompt value,
[00:17:04.940 --> 00:17:08.620]   which is this kind of new version
[00:17:08.620 --> 00:17:10.620]   with those instructions added to the end.
[00:17:10.620 --> 00:17:13.260]   So let's have a look, make sure we have the right format.
[00:17:13.260 --> 00:17:16.700]   So system, human, AI, human, AI.
[00:17:16.700 --> 00:17:19.340]   That's the last correct response we got from the AI.
[00:17:19.340 --> 00:17:22.260]   And now we have the new modified human message.
[00:17:22.260 --> 00:17:23.100]   Okay, cool.
[00:17:23.100 --> 00:17:26.260]   So it's like this, answering less than 50 characters.
[00:17:26.260 --> 00:17:30.300]   And now we pass that through our chat system again,
[00:17:30.300 --> 00:17:32.980]   and we get way shorter.
[00:17:32.980 --> 00:17:35.180]   So 28, it's like, yes, similar.
[00:17:35.180 --> 00:17:37.260]   Because we're saying,
[00:17:37.260 --> 00:17:40.500]   we're telling it in the most recent query again,
[00:17:40.500 --> 00:17:42.820]   but you need to answer in less than 50 characters.
[00:17:42.820 --> 00:17:45.300]   All right, so what I mentioned before
[00:17:45.300 --> 00:17:47.420]   is that maybe this is a little bit convoluted,
[00:17:47.420 --> 00:17:51.180]   and that's not to say that there aren't use cases for this.
[00:17:51.180 --> 00:17:54.660]   It's just that it would be unfair of me
[00:17:54.660 --> 00:17:56.540]   to tell you all of this and be like,
[00:17:56.540 --> 00:17:57.660]   this is how you use it.
[00:17:57.660 --> 00:17:59.980]   And then like, just miss something
[00:17:59.980 --> 00:18:02.020]   that could make things much easier
[00:18:02.020 --> 00:18:04.460]   in most, at least most use cases,
[00:18:04.460 --> 00:18:07.620]   or simpler use cases, or something along those lines.
[00:18:07.620 --> 00:18:09.340]   All right, so I would say it's arguable
[00:18:09.340 --> 00:18:11.940]   as to whether all of the above that we just did
[00:18:11.940 --> 00:18:14.660]   would be any simpler than using an F-string.
[00:18:14.660 --> 00:18:16.740]   So we have this input.
[00:18:16.740 --> 00:18:18.620]   Okay, cool, is it like particle physics?
[00:18:18.620 --> 00:18:21.540]   That's our most recent question, right?
[00:18:21.540 --> 00:18:23.100]   And we can just use an F-string, right?
[00:18:23.100 --> 00:18:24.940]   So we have the F-string here,
[00:18:24.940 --> 00:18:28.260]   and we have the human message, the content,
[00:18:28.260 --> 00:18:29.660]   and then we just say,
[00:18:29.660 --> 00:18:31.660]   answering less than the character limit,
[00:18:31.660 --> 00:18:35.940]   which is set here, characters, including whitespace, right?
[00:18:35.940 --> 00:18:39.420]   And the result of that is basically the same.
[00:18:39.420 --> 00:18:41.460]   Look, we have this, right?
[00:18:41.460 --> 00:18:45.540]   That's the same as all of this code here.
[00:18:45.540 --> 00:18:49.660]   So now all of this code, is that right?
[00:18:49.660 --> 00:18:52.100]   Yeah, plus this.
[00:18:52.100 --> 00:18:54.820]   So it depends, I don't know,
[00:18:54.820 --> 00:18:55.980]   it depends on your use case,
[00:18:55.980 --> 00:18:58.380]   like what you're doing, how you prefer to write this,
[00:18:58.380 --> 00:19:01.220]   but just be aware that you can also do this
[00:19:01.220 --> 00:19:02.940]   and you get the same result.
[00:19:02.940 --> 00:19:05.180]   So now we can see again,
[00:19:05.180 --> 00:19:07.900]   popping the last message to remove the one
[00:19:07.900 --> 00:19:10.860]   that we created using the prompt template,
[00:19:10.860 --> 00:19:12.340]   and then I'm adding the one that we created
[00:19:12.340 --> 00:19:14.220]   using the F-string approach,
[00:19:14.220 --> 00:19:16.500]   and we get this, right, it's the same thing.
[00:19:16.500 --> 00:19:17.980]   There's no difference there,
[00:19:17.980 --> 00:19:20.580]   we can process it through chat GPT again,
[00:19:20.580 --> 00:19:22.780]   and we'll get the same response.
[00:19:22.780 --> 00:19:25.660]   Okay, so just wanted to make you aware of that.
[00:19:25.660 --> 00:19:28.260]   But yeah, that's it for this video.
[00:19:28.260 --> 00:19:30.660]   We've covered, I think the vast majority
[00:19:30.660 --> 00:19:34.780]   of the new chat features within the Limechain,
[00:19:34.780 --> 00:19:37.380]   and naturally, like we saw at the end there,
[00:19:37.380 --> 00:19:38.980]   we don't need to use all of them.
[00:19:38.980 --> 00:19:41.660]   Like the prompt templates, you can use of course,
[00:19:41.660 --> 00:19:44.300]   if you have a reason to, but it isn't needed
[00:19:44.300 --> 00:19:47.500]   if you have a simpler approach to doing these things.
[00:19:47.500 --> 00:19:51.980]   But yeah, it's cool to see this being implemented
[00:19:51.980 --> 00:19:54.860]   in Limechain, and although I haven't been through it yet,
[00:19:54.860 --> 00:19:58.900]   I'm hoping that there will be good integrations
[00:19:58.900 --> 00:20:01.780]   of these new chat features with like
[00:20:01.780 --> 00:20:04.460]   their conversation memory, their retrieval augmentation,
[00:20:04.460 --> 00:20:06.220]   and everything else within Limechain,
[00:20:06.220 --> 00:20:08.580]   which is, that's where the value
[00:20:08.580 --> 00:20:09.780]   of this sort of thing will come in.
[00:20:09.780 --> 00:20:11.780]   Right now, it's kind of like a simple wrapper
[00:20:11.780 --> 00:20:15.260]   on top of OpenAI's chat completion endpoint,
[00:20:15.260 --> 00:20:19.260]   but hopefully with all of the agents,
[00:20:19.260 --> 00:20:22.140]   conversation memory, and retrieval augmentation components
[00:20:22.140 --> 00:20:24.820]   that Limechain offers, we'll get a tight integration
[00:20:24.820 --> 00:20:27.900]   between those, and that's where this will be useful.
[00:20:27.900 --> 00:20:31.460]   So, that's it for this video.
[00:20:31.460 --> 00:20:33.900]   I hope all of this has been useful and interesting.
[00:20:33.900 --> 00:20:36.300]   But for now, thank you very much for watching,
[00:20:36.300 --> 00:20:38.860]   and I will see you again in the next one.
[00:20:38.860 --> 00:20:39.700]   Bye.
[00:20:39.700 --> 00:20:42.280]   (gentle music)
[00:20:42.280 --> 00:20:44.860]   (gentle music)
[00:20:44.860 --> 00:20:47.440]   (gentle music)
[00:20:47.440 --> 00:20:50.020]   (gentle music)
[00:20:50.020 --> 00:20:52.080]   you
[00:20:52.080 --> 00:20:54.140]   you

