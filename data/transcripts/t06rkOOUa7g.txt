
[00:00:00.000 --> 00:00:05.120]   The following is a conversation with Manolis Kellis, his second time on the podcast.
[00:00:05.120 --> 00:00:09.920]   He's a professor at MIT and head of the MIT Computational Biology Group.
[00:00:09.920 --> 00:00:14.720]   He's one of the most brilliant, productive, and kind people I've had the fortune of talking to.
[00:00:14.720 --> 00:00:19.520]   A lot of my colleagues at MIT and former MIT faculty and students
[00:00:19.520 --> 00:00:23.200]   wrote to me after our first conversation with some version of,
[00:00:23.200 --> 00:00:27.120]   "Manolis is awesome, isn't he? I'm glad you guys are now friends."
[00:00:28.320 --> 00:00:35.120]   I am too, and I'm happy that he makes time in his insanely busy schedule to sit down and have a chat with me.
[00:00:35.120 --> 00:00:37.840]   Quick summary of the sponsors.
[00:00:37.840 --> 00:00:41.520]   Public Goods, Magic Spoon, and ExpressVPN.
[00:00:41.520 --> 00:00:46.880]   Please check out these sponsors in the description to get a discount and to support this podcast.
[00:00:46.880 --> 00:00:52.320]   As a side note, let me say that I just got back from talking to Joe Rogan on his podcast,
[00:00:52.320 --> 00:00:54.000]   my fifth time on there.
[00:00:54.000 --> 00:00:58.240]   I also got a chance to record a separate conversation with Joe on this podcast.
[00:00:58.960 --> 00:01:03.440]   We talked on both quite a bit about his journey and his advice for mine.
[00:01:03.440 --> 00:01:08.800]   One of the things that I think made his show special is that he just had fun
[00:01:08.800 --> 00:01:12.720]   and made choices that didn't get in the way of him having fun and loving life.
[00:01:12.720 --> 00:01:15.360]   I'm learning to do just that.
[00:01:15.360 --> 00:01:19.680]   It's tough since I'm naturally full of self-doubt and anxiety,
[00:01:19.680 --> 00:01:21.680]   but I'm learning to let go and have fun,
[00:01:21.680 --> 00:01:27.200]   even if my monotone robotic voice sometimes sounds otherwise.
[00:01:28.000 --> 00:01:31.840]   For Joe, that involved talking to his friends, comedians,
[00:01:31.840 --> 00:01:33.840]   especially ones that brought out the best in him.
[00:01:33.840 --> 00:01:40.000]   Duncan Trussell and the five-hour first episode on Spotify comes to mind as an example of that.
[00:01:40.000 --> 00:01:45.600]   Duncan has been a guest probably close to, if not more than 50 times on Joe's podcast.
[00:01:45.600 --> 00:01:50.880]   My hope with amazing people like Manolis is to find my Duncan Trussell,
[00:01:50.880 --> 00:01:54.720]   my Joey Diaz, and yes, even my Eddie Bravo.
[00:01:55.440 --> 00:02:00.080]   Obviously, Joe and I are very different people, but ultimately both love life,
[00:02:00.080 --> 00:02:06.800]   where we can interact often with people we love and who inspire us, make us smile, make us think,
[00:02:06.800 --> 00:02:12.000]   and make us have fun when we get behind the mic of a podcast, whether anyone is listening or not.
[00:02:12.000 --> 00:02:17.360]   If you enjoy this thing, subscribe on YouTube, review it with 5 Stars on Apple Podcasts,
[00:02:17.360 --> 00:02:22.800]   follow on Spotify, support on Patreon, or connect with me on Twitter @LexFriedman.
[00:02:22.800 --> 00:02:27.440]   I also this time put a link in the description to a survey for this podcast
[00:02:27.440 --> 00:02:32.560]   on how I can improve and also an option if you like, I don't know why you would like to,
[00:02:32.560 --> 00:02:38.160]   but if you like, to join an inner circle of people that help guide the direction of this podcast
[00:02:38.160 --> 00:02:40.560]   via email or occasional video chats.
[00:02:40.560 --> 00:02:43.360]   If you have a few minutes, please fill it out.
[00:02:43.360 --> 00:02:47.520]   As usual, I'll do a few minutes of ads now and no ads in the middle.
[00:02:47.520 --> 00:02:50.880]   I try to make these interesting, but I give you timestamps
[00:02:50.880 --> 00:02:56.320]   so you can skip, but still, please do check out the sponsors by clicking the links in the description.
[00:02:56.320 --> 00:02:59.200]   It's the best way, honestly, to support this podcast.
[00:02:59.200 --> 00:03:05.600]   This show is sponsored by Public Goods, an online store for basic health and household stuff.
[00:03:05.600 --> 00:03:10.480]   Their products have a minimalist black and white design that I find to be just clean,
[00:03:10.480 --> 00:03:11.760]   elegant, and beautiful.
[00:03:11.760 --> 00:03:16.800]   It goes nicely, at least I think so, with the design of Crew Dragon and the
[00:03:16.800 --> 00:03:20.640]   recent SpaceX/NASA mission that sent two humans into space.
[00:03:21.440 --> 00:03:26.800]   To me, very few things are as inspiring as us humans reaching out into the unknown,
[00:03:26.800 --> 00:03:28.480]   the harsh challenges of space.
[00:03:28.480 --> 00:03:34.000]   Colonizing Mars may not have obvious near-term benefits, but I believe it will challenge our
[00:03:34.000 --> 00:03:40.080]   scientists and our engineers to create technologies whose impact will be immeasurable for us humans
[00:03:40.080 --> 00:03:43.840]   here on Earth, or those of us who choose to stay here on Earth.
[00:03:43.840 --> 00:03:49.680]   Personally, I'm kind of a long-time big fan of this planet.
[00:03:50.480 --> 00:03:58.400]   Anyway, visit publicgoods.com/lex and use code LEX at checkout to get $15 off your first order.
[00:03:58.400 --> 00:04:05.360]   This episode is also supported by Magic Spoon, low-carb, keto-friendly cereal.
[00:04:05.360 --> 00:04:11.360]   You might have heard on other videos that I eat keto mostly these days, so Magic Spoon is
[00:04:11.360 --> 00:04:16.480]   a delicious, healthy treat on a hard workout day that fits into that crazy diet.
[00:04:17.440 --> 00:04:23.360]   Also, they're a sponsor of episode 100 with my dad, and got my dad to buy this cereal,
[00:04:23.360 --> 00:04:26.560]   and he now loves it. Honestly, just loves it.
[00:04:26.560 --> 00:04:31.120]   It's kind of funny, actually. The deep heartfelt nature of that conversation,
[00:04:31.120 --> 00:04:34.960]   and the silliness of the cereal, captures my dad perfectly.
[00:04:34.960 --> 00:04:40.480]   Much of the hardship in his life he dealt with using wit and humor.
[00:04:40.480 --> 00:04:43.520]   His favorite flavor happens to be cocoa. Mine is, too.
[00:04:44.800 --> 00:04:49.120]   He hasn't bought the 8-sleep mattress yet, though my mom wants to,
[00:04:49.120 --> 00:04:53.360]   but he's all about this Magic Spoon cereal. I think it's his actually favorite sponsor of
[00:04:53.360 --> 00:04:58.240]   this podcast. Probably because they chose to sponsor the episode he's on.
[00:04:58.240 --> 00:05:04.320]   Anyway, click the magicspoon.com/lex link in the description and use code LEX at checkout
[00:05:04.320 --> 00:05:09.920]   for free shipping to let them know I sent you, and also indirectly to make my dad happy.
[00:05:11.040 --> 00:05:16.960]   This show is also sponsored by ExpressVPN. Get it at expressvpn.com/lexpod.
[00:05:16.960 --> 00:05:23.680]   They gave me a suggested opening line of "using the internet without ExpressVPN is like going to
[00:05:23.680 --> 00:05:29.360]   the bathroom and not closing the door." This is like GPT-3 suggesting to me how to be more
[00:05:29.360 --> 00:05:33.360]   human-like, and I'll honestly take all the help I can get.
[00:05:33.360 --> 00:05:39.760]   By way of life advice, let me tell you that you need a VPN to protect you from Russians like me.
[00:05:40.640 --> 00:05:46.480]   In fact, this podcast is a kind of hack of your biological network where I use my monotone,
[00:05:46.480 --> 00:05:51.440]   low-energy voice to convince you to buy a kind of expensive cereal as a way
[00:05:51.440 --> 00:05:58.000]   to influence the stability of the US economy. I use ExpressVPN on both Windows and Linux
[00:05:58.000 --> 00:06:04.080]   to protect myself if I ever do shady things on the internet, which of course I never do
[00:06:04.080 --> 00:06:11.200]   and never will. So secure your online activity by going to expressvpn.com/lexpod
[00:06:11.200 --> 00:06:14.800]   to get an extra three months free and to support this podcast.
[00:06:14.800 --> 00:06:19.440]   And now, here's my conversation with Manolis Kelis.
[00:06:19.440 --> 00:06:23.600]   What is beautiful about the human epigenome?
[00:06:23.600 --> 00:06:30.560]   Don't get me started. So first of all, as an engineering feat, the human epigenome
[00:06:30.560 --> 00:06:36.080]   manages the most compact, the most incredible compaction you could imagine.
[00:06:36.080 --> 00:06:41.680]   So every single one of your cells contains two meters worth of DNA,
[00:06:41.680 --> 00:06:47.200]   and this is compacted in a radius which is one thousandth of a millimeter.
[00:06:47.200 --> 00:06:51.680]   That's six orders of magnitude. To give you a sense of scale,
[00:06:51.680 --> 00:06:58.880]   it's as if a string as tall as the Burj al-Khalifa, which is about a kilometer tall,
[00:06:59.600 --> 00:07:02.640]   was compacted into a tiny little ball the size of a millimeter.
[00:07:02.640 --> 00:07:10.560]   And if you put it all together, if you stretch the trillions of cells that we have,
[00:07:10.560 --> 00:07:15.840]   we have about 30 trillion cells in your body. If you stretch the DNA, the two meters worth of DNA
[00:07:15.840 --> 00:07:21.680]   in every one of your trillion cells, you would basically reach all the way to Jupiter
[00:07:21.680 --> 00:07:25.440]   a hundred times.
[00:07:26.480 --> 00:07:30.320]   Yeah, it's all curled up in there. It's 30 trillion cells.
[00:07:30.320 --> 00:07:31.760]   30 trillion cells.
[00:07:31.760 --> 00:07:32.480]   In the human body.
[00:07:32.480 --> 00:07:38.400]   Every one of them, two meters worth of DNA. So all of that is compacted through the epigenome.
[00:07:38.400 --> 00:07:44.160]   The epigenome basically has the ability to compact this massive amount of DNA
[00:07:44.160 --> 00:07:49.520]   from here to Jupiter 10 times into one human body, into just the nuclei of one human body,
[00:07:49.520 --> 00:07:52.320]   and the vast majority of the human body is not even these nuclei.
[00:07:52.320 --> 00:07:55.440]   And that's sort of the structural part.
[00:07:55.440 --> 00:07:57.600]   So that's the boring part. That's the structural part.
[00:07:57.600 --> 00:08:00.240]   The functional part is way more interesting.
[00:08:00.240 --> 00:08:03.520]   So functionally, what the human epigenome allows you to do
[00:08:03.520 --> 00:08:11.120]   is basically control the activity patterns of thousands of genes.
[00:08:11.120 --> 00:08:16.080]   So 20,000 genes in your human body, every one of your cells only needs a few thousand of those,
[00:08:16.080 --> 00:08:18.080]   but a different few thousand of those.
[00:08:18.080 --> 00:08:22.400]   And the way that your cells remember what their identity is,
[00:08:22.400 --> 00:08:25.040]   is basically driven by the epigenome.
[00:08:25.040 --> 00:08:30.000]   So the epigenome is both structural, in sort of making this dramatic compaction,
[00:08:30.000 --> 00:08:33.760]   and it's also functional in being able to actually control
[00:08:33.760 --> 00:08:35.920]   the activity patterns of all your cells.
[00:08:35.920 --> 00:08:40.240]   - Now, can we draw a definition,
[00:08:40.240 --> 00:08:42.960]   distinction between the genome and the epigenome?
[00:08:42.960 --> 00:08:46.240]   - Again, being Greek, epi means on top of.
[00:08:46.960 --> 00:08:53.360]   So the genome is the DNA, and the epigenome is anything on top of the DNA.
[00:08:53.360 --> 00:08:57.440]   And there's three types of things on top of the DNA.
[00:08:57.440 --> 00:09:00.160]   The first is chemical modifications on the DNA itself.
[00:09:00.160 --> 00:09:03.920]   So we like to think of four bases of the DNA, A, C, G, T.
[00:09:03.920 --> 00:09:09.280]   C has a methyl form, which is sometimes referred to as the fifth base.
[00:09:09.280 --> 00:09:11.760]   So methyl C takes a different meaning.
[00:09:12.640 --> 00:09:18.160]   So in the same way that you have annotations in a orchestra score,
[00:09:18.160 --> 00:09:21.440]   that basically say whether you should play something softly or loudly,
[00:09:21.440 --> 00:09:26.000]   or space it out, or, you know, interpret basically the score,
[00:09:26.000 --> 00:09:30.960]   the human epigenome allows you to modify that primary score.
[00:09:30.960 --> 00:09:34.640]   So a modified C basically says, play this one softly.
[00:09:34.640 --> 00:09:39.040]   It's basically a sign of repression in a gene regulatory region.
[00:09:39.040 --> 00:09:44.640]   - I love how you're talking about the function that emerges
[00:09:44.640 --> 00:09:47.520]   from the epigenome as a musical score.
[00:09:47.520 --> 00:09:49.680]   - It is in many ways.
[00:09:49.680 --> 00:09:53.440]   And every single cell plays a different part of that score.
[00:09:53.440 --> 00:09:56.640]   It's like having all of human knowledge in 23 volumes,
[00:09:56.640 --> 00:09:59.360]   like 23 giant books, which are your chromosomes.
[00:09:59.360 --> 00:10:03.440]   And every single cell has a different profession, a different role.
[00:10:03.440 --> 00:10:07.280]   Some cells play the piano, and they're looking at chapter seven
[00:10:07.280 --> 00:10:10.000]   from chromosome 23, and chapter four from chromosome two,
[00:10:10.000 --> 00:10:11.200]   and so on and so forth.
[00:10:11.200 --> 00:10:17.120]   And each of those pieces are all encoding in the same DNA.
[00:10:17.120 --> 00:10:18.960]   But what the epigenome allows you to do
[00:10:18.960 --> 00:10:23.440]   is effectively conduct the orchestra
[00:10:23.440 --> 00:10:25.360]   and sort of coordinate the pieces
[00:10:25.360 --> 00:10:27.440]   so that every instrument plays only the things
[00:10:27.440 --> 00:10:28.240]   that it needs to play.
[00:10:28.240 --> 00:10:30.720]   - One thing that kind of blows my mind,
[00:10:30.720 --> 00:10:33.360]   maybe you can tell me your thoughts about it,
[00:10:33.360 --> 00:10:36.800]   is the way evolution works with natural selection,
[00:10:37.520 --> 00:10:40.640]   is based on the final sort of,
[00:10:40.640 --> 00:10:46.160]   the entirety of the orchestra musical performance, right?
[00:10:46.160 --> 00:10:52.160]   And then, but there's these incredibly rich structural things,
[00:10:52.160 --> 00:10:54.240]   like each one of them doing their own little job
[00:10:54.240 --> 00:10:56.400]   that somehow work to get, like,
[00:10:56.400 --> 00:10:59.440]   the evolution selects based on the final result,
[00:10:59.440 --> 00:11:02.000]   and yet all the individual pieces are doing
[00:11:02.000 --> 00:11:05.280]   like infinitely minuscule specific things.
[00:11:05.280 --> 00:11:06.800]   How the heck does that work?
[00:11:06.800 --> 00:11:08.640]   - It's a very good insight.
[00:11:08.640 --> 00:11:10.640]   And you can even go beyond that
[00:11:10.640 --> 00:11:12.800]   and basically say evolution doesn't select
[00:11:12.800 --> 00:11:14.800]   at the level of an organism,
[00:11:14.800 --> 00:11:16.800]   it actually selects at the level of whole environments,
[00:11:16.800 --> 00:11:17.680]   whole ecosystems.
[00:11:17.680 --> 00:11:20.320]   So let me break this down.
[00:11:20.320 --> 00:11:23.440]   So you basically have at the very bottom
[00:11:23.440 --> 00:11:26.640]   every single nucleotide being selected.
[00:11:26.640 --> 00:11:29.760]   But then that nucleotide's function is selected
[00:11:29.760 --> 00:11:33.120]   at the level of, you know, each gene,
[00:11:33.120 --> 00:11:35.680]   and every, not even each gene,
[00:11:35.680 --> 00:11:38.320]   each gene regulatory control element.
[00:11:38.320 --> 00:11:41.200]   And then those control elements are basically converging
[00:11:41.200 --> 00:11:42.800]   onto the function of the gene.
[00:11:42.800 --> 00:11:45.840]   And many genes are converging onto the function of one cell,
[00:11:45.840 --> 00:11:47.120]   and many cells are converging
[00:11:47.120 --> 00:11:49.600]   onto the function of one tissue or organ.
[00:11:49.600 --> 00:11:52.400]   And all of these organs are converging
[00:11:52.400 --> 00:11:55.120]   onto the level of an organism.
[00:11:55.120 --> 00:11:57.360]   But now that organism is not in isolation.
[00:11:57.360 --> 00:12:01.120]   So if you basically think about why is altruism,
[00:12:01.120 --> 00:12:02.800]   for example, a thing?
[00:12:02.800 --> 00:12:04.240]   Why are people being nice to each other?
[00:12:04.240 --> 00:12:06.720]   It was probably selected.
[00:12:06.720 --> 00:12:10.960]   And it was probably selected because those species
[00:12:10.960 --> 00:12:12.560]   that were just nasty to each other
[00:12:12.560 --> 00:12:14.720]   didn't survive as a species.
[00:12:14.720 --> 00:12:22.080]   And now if you think about symbiosis of, you know,
[00:12:22.080 --> 00:12:25.120]   there's plants, for example, that love CO2,
[00:12:25.120 --> 00:12:27.120]   and there's humans that love O2.
[00:12:27.120 --> 00:12:28.880]   And we're sort of, you know,
[00:12:28.880 --> 00:12:33.600]   trading different types of gases to each other.
[00:12:33.600 --> 00:12:38.560]   If you look at ecosystems
[00:12:38.560 --> 00:12:40.880]   where one organism was just really nasty,
[00:12:40.880 --> 00:12:43.760]   that organism actually died
[00:12:43.760 --> 00:12:46.160]   because everyone they were being nasty to was killed off.
[00:12:46.160 --> 00:12:53.280]   And then that kind of, you know, universe of life is gone.
[00:12:53.280 --> 00:12:55.760]   So basically what emerges is selection
[00:12:56.720 --> 00:13:00.400]   at so many different layers of benefit,
[00:13:00.400 --> 00:13:04.000]   including, you know, all of these nucleotides
[00:13:04.000 --> 00:13:08.000]   within a body interacting for the emergent functions
[00:13:08.000 --> 00:13:09.680]   at the body level.
[00:13:09.680 --> 00:13:11.840]   - Yeah, I wonder if it's possible
[00:13:11.840 --> 00:13:13.280]   to break it down into levels.
[00:13:13.280 --> 00:13:16.320]   That's selection even beyond humans.
[00:13:16.320 --> 00:13:17.680]   Like you said environment,
[00:13:17.680 --> 00:13:18.720]   but there's environments
[00:13:18.720 --> 00:13:20.160]   that are all different levels too, right?
[00:13:20.160 --> 00:13:22.960]   At the minuscule, at the organ level,
[00:13:22.960 --> 00:13:24.640]   at the tissue level, like you said,
[00:13:24.640 --> 00:13:26.080]   maybe at the microscopic level.
[00:13:26.080 --> 00:13:27.920]   It'd be fascinating if like,
[00:13:27.920 --> 00:13:30.560]   there's a kind of selection going on
[00:13:30.560 --> 00:13:32.720]   at like both the quantum level
[00:13:32.720 --> 00:13:35.440]   and like the galaxy level.
[00:13:35.440 --> 00:13:36.480]   - Yeah, yeah, yeah.
[00:13:36.480 --> 00:13:38.880]   So, so, yeah, let's again,
[00:13:38.880 --> 00:13:40.320]   sort of break down these different layers.
[00:13:40.320 --> 00:13:42.400]   So basically if you think about the environment
[00:13:42.400 --> 00:13:44.240]   in which a gene operates,
[00:13:44.240 --> 00:13:45.200]   that gene, of course,
[00:13:45.200 --> 00:13:47.920]   the first definition of environment that we think of
[00:13:47.920 --> 00:13:52.160]   is pollution or sunlight or heat or cold
[00:13:52.160 --> 00:13:53.040]   and so on and so forth.
[00:13:53.040 --> 00:13:54.240]   That's the external environment.
[00:13:54.880 --> 00:13:56.160]   But every gene also operates
[00:13:56.160 --> 00:13:58.160]   at the level of the internal cellular environment
[00:13:58.160 --> 00:13:58.660]   that it's in.
[00:13:58.660 --> 00:14:02.240]   If I take a gene from say an African individual
[00:14:02.240 --> 00:14:04.160]   and I put it in a European context,
[00:14:04.160 --> 00:14:07.280]   will it perform the same way?
[00:14:07.280 --> 00:14:10.400]   Probably not because there's a cellular context
[00:14:10.400 --> 00:14:12.640]   of thousands of other genes
[00:14:12.640 --> 00:14:14.160]   that that gene has co-evolved with,
[00:14:14.160 --> 00:14:17.360]   you know, in the out of Africa event
[00:14:17.360 --> 00:14:21.280]   and you know, all of this sort of human history
[00:14:21.280 --> 00:14:22.240]   of evolution.
[00:14:22.240 --> 00:14:25.200]   So basically if you look at Neanderthal genes,
[00:14:25.200 --> 00:14:26.320]   for example,
[00:14:26.320 --> 00:14:29.760]   which again happened long after that out of Africa event,
[00:14:29.760 --> 00:14:33.600]   there's incompatibilities between Neanderthal genes
[00:14:33.600 --> 00:14:37.840]   and modern human genes that can lead to diseases.
[00:14:37.840 --> 00:14:39.680]   So in the context of the Neanderthal genome,
[00:14:39.680 --> 00:14:42.320]   that gene version, that allele was fine.
[00:14:42.320 --> 00:14:44.800]   But in the context of the modern human genome,
[00:14:44.800 --> 00:14:47.280]   that Neanderthal gene version is actually detrimental.
[00:14:47.280 --> 00:14:50.560]   So it's, you know, that cellular environment
[00:14:51.440 --> 00:14:53.840]   constitutes the genetics of that gene,
[00:14:53.840 --> 00:14:56.880]   but also of course, all of the epigenomics of that gene.
[00:14:56.880 --> 00:15:00.560]   - Yeah, it's fascinating that the gene has a history.
[00:15:00.560 --> 00:15:02.480]   I mean, we talked about this a little bit last time,
[00:15:02.480 --> 00:15:06.240]   and then some of your research goes into that,
[00:15:06.240 --> 00:15:10.480]   but the genes as they are today have a story
[00:15:10.480 --> 00:15:13.440]   from the beginning of time.
[00:15:13.440 --> 00:15:17.600]   And then sometimes their story was like,
[00:15:17.600 --> 00:15:20.080]   their path was useful for survival
[00:15:20.080 --> 00:15:22.320]   for the particular organisms and sometimes not.
[00:15:22.320 --> 00:15:24.240]   That's fascinating.
[00:15:24.240 --> 00:15:26.640]   Let me ask a tangent.
[00:15:26.640 --> 00:15:29.200]   We kind of started talking offline about Neanderthals.
[00:15:29.200 --> 00:15:33.600]   Do you have something interesting genetically, biologically,
[00:15:33.600 --> 00:15:36.800]   in terms of difference between Neanderthal
[00:15:36.800 --> 00:15:39.120]   and like the different branches of human evolution
[00:15:39.120 --> 00:15:42.480]   that you find fascinating?
[00:15:42.480 --> 00:15:46.000]   - Neanderthals are only one of about five branches
[00:15:46.000 --> 00:15:47.600]   that we are pretty confident about.
[00:15:47.600 --> 00:15:49.760]   - Branches of?
[00:15:49.760 --> 00:15:51.440]   - Of out of Africa events.
[00:15:51.440 --> 00:15:55.200]   So basically there's Neanderthals, there's Denisovans.
[00:15:55.200 --> 00:15:57.200]   What is the evidence for Denisovans?
[00:15:57.200 --> 00:16:01.680]   One tiny little fragment of one pinky
[00:16:01.680 --> 00:16:05.120]   from one cave in Siberia.
[00:16:05.120 --> 00:16:07.920]   - Relatively recently discovered, right?
[00:16:07.920 --> 00:16:08.960]   - Less than 10 years ago.
[00:16:08.960 --> 00:16:11.200]   - Yeah, and those are like little folks, right?
[00:16:11.200 --> 00:16:13.520]   - No, no, no, no, no, that's yet another one though.
[00:16:13.520 --> 00:16:17.520]   Homo florensis, it had the little folks in sort of Indonesia.
[00:16:17.520 --> 00:16:21.120]   But then Denisovans are basically another branch
[00:16:21.120 --> 00:16:24.240]   that we only know about genetically from that one bone.
[00:16:24.240 --> 00:16:26.880]   And eventually we realized that it's one of the three
[00:16:26.880 --> 00:16:28.640]   major branches along with Neanderthal,
[00:16:28.640 --> 00:16:30.400]   modern human and Denisovan.
[00:16:30.400 --> 00:16:33.440]   And then that one branch has now resurfaced
[00:16:33.440 --> 00:16:34.560]   in many different areas.
[00:16:34.560 --> 00:16:36.640]   And we kind of know about the gene flow
[00:16:36.640 --> 00:16:38.400]   that happened in between them.
[00:16:38.400 --> 00:16:40.960]   So when I was reading my Greek mythology,
[00:16:40.960 --> 00:16:43.440]   it was talking about the age of the heroes.
[00:16:43.440 --> 00:16:47.680]   These eras of human-like precursors
[00:16:47.680 --> 00:16:50.480]   that were wiped out by Zeus or by all kinds of wars
[00:16:50.480 --> 00:16:52.320]   and so on and so forth, like the Titans.
[00:16:52.320 --> 00:16:57.520]   It's ridiculous to sort of read these stories as a kid
[00:16:57.520 --> 00:16:59.280]   because you're like, oh yeah, whatever.
[00:16:59.280 --> 00:17:01.200]   And then you're growing up and you're like,
[00:17:01.200 --> 00:17:04.800]   whoa, layers and layers of human-like ancestors.
[00:17:04.800 --> 00:17:07.920]   And who knows if those stories were inspired by bones
[00:17:07.920 --> 00:17:10.480]   that they found that kind of looked human-like,
[00:17:10.480 --> 00:17:12.240]   but were not quite human-like.
[00:17:12.240 --> 00:17:14.400]   Who knows if stories of dragons were inspired
[00:17:14.400 --> 00:17:16.000]   by bones of dinosaurs.
[00:17:16.000 --> 00:17:18.960]   Basically this archeological evidence has been there
[00:17:18.960 --> 00:17:22.880]   and has probably entered the folk imagination,
[00:17:22.880 --> 00:17:25.360]   migrated into those stories.
[00:17:25.360 --> 00:17:28.640]   But it's not that far removed from what actually happened
[00:17:28.640 --> 00:17:32.480]   of massive wars of wiping out Neanderthals
[00:17:32.480 --> 00:17:36.720]   as modern humans are populating Europe.
[00:17:36.720 --> 00:17:39.680]   - Do you think what killed the Neanderthals
[00:17:39.680 --> 00:17:42.640]   and all those other branches is human conflict
[00:17:42.640 --> 00:17:44.080]   or is it genetic conflict?
[00:17:44.080 --> 00:17:49.360]   So is it us humans being the opposite of altruistic
[00:17:49.360 --> 00:17:50.160]   towards each other,
[00:17:50.160 --> 00:17:56.240]   or is it competition at some other level,
[00:17:56.240 --> 00:17:57.760]   like as we're discussing?
[00:17:57.760 --> 00:18:01.120]   - Yeah, so if you look at a lot of human traits today,
[00:18:01.120 --> 00:18:02.720]   they're probably not that far removed
[00:18:02.720 --> 00:18:04.880]   from the human traits that got us where we are now.
[00:18:04.880 --> 00:18:07.920]   So this whole tribalism,
[00:18:08.880 --> 00:18:11.040]   you're my sports team,
[00:18:11.040 --> 00:18:13.600]   or you're my political party,
[00:18:13.600 --> 00:18:16.320]   or you're my tiny little village.
[00:18:16.320 --> 00:18:19.600]   And therefore, if you're from that other village,
[00:18:19.600 --> 00:18:20.320]   I hate you.
[00:18:20.320 --> 00:18:23.280]   But as soon as we're both in the major city,
[00:18:23.280 --> 00:18:25.440]   I can't believe we're from the same region,
[00:18:25.440 --> 00:18:27.200]   my friend, come here, my family.
[00:18:27.200 --> 00:18:29.600]   And like two neighboring countries fighting.
[00:18:29.600 --> 00:18:30.880]   And as soon as they're off in another country,
[00:18:30.880 --> 00:18:32.480]   we're like, oh, I can't believe that.
[00:18:32.480 --> 00:18:34.160]   So it's kind of funny.
[00:18:34.160 --> 00:18:37.280]   Like this tribalism is nonsensical in many ways.
[00:18:37.280 --> 00:18:39.200]   It's like cognitive incongruent,
[00:18:39.200 --> 00:18:41.280]   that basically we like kin.
[00:18:41.280 --> 00:18:46.480]   And selection for sort of liking kin
[00:18:46.480 --> 00:18:48.640]   is hugely advantageous genetically.
[00:18:48.640 --> 00:18:51.040]   - Probably across all kinds of organs,
[00:18:51.040 --> 00:18:52.160]   across all kinds of life.
[00:18:52.160 --> 00:18:52.660]   - Of course, yeah.
[00:18:52.660 --> 00:18:55.760]   So basically, if you now transport that
[00:18:55.760 --> 00:19:00.480]   to the sort of humans arriving in Europe
[00:19:00.480 --> 00:19:01.840]   and Neanderthals are everywhere,
[00:19:01.840 --> 00:19:03.360]   what are you gonna do?
[00:19:03.360 --> 00:19:04.240]   You're gonna kill them off.
[00:19:05.600 --> 00:19:07.600]   There's this battle for territory
[00:19:07.600 --> 00:19:09.520]   and this battle for they're not like us,
[00:19:09.520 --> 00:19:11.040]   we have to get rid of them.
[00:19:11.040 --> 00:19:14.080]   So basically there's a very interesting mix there.
[00:19:14.080 --> 00:19:17.200]   But and yet, when you look at the genetics,
[00:19:17.200 --> 00:19:19.680]   there's tons of gene flow between them.
[00:19:19.680 --> 00:19:24.400]   So basically, love, romance between near species.
[00:19:24.400 --> 00:19:27.840]   - We have tribes, but love spans
[00:19:27.840 --> 00:19:30.080]   the gap between the different tribes.
[00:19:30.080 --> 00:19:32.720]   - It's Romeo and Juliet across species boundaries.
[00:19:32.720 --> 00:19:35.280]   - Sneaks away from the village to hang out.
[00:19:35.280 --> 00:19:37.840]   - Even before the out of Africa,
[00:19:37.840 --> 00:19:41.040]   there's within Africa selection,
[00:19:41.040 --> 00:19:43.520]   which was probably massive battles
[00:19:43.520 --> 00:19:45.200]   of larger and larger tribes
[00:19:45.200 --> 00:19:51.280]   selecting for our social networking and savviness
[00:19:51.280 --> 00:19:54.880]   and probably all our conspiracy theory genes
[00:19:54.880 --> 00:19:56.560]   are dating back from then.
[00:19:56.560 --> 00:20:01.280]   And so there's a lot of this mischievousness
[00:20:01.280 --> 00:20:03.520]   in the history of human evolution
[00:20:04.160 --> 00:20:08.400]   that unfortunately still present in many ugly forms today,
[00:20:08.400 --> 00:20:12.480]   but probably contributed to our success as a species
[00:20:12.480 --> 00:20:14.640]   in wiping out other species.
[00:20:14.640 --> 00:20:18.880]   - It just sucks that we don't have neighboring species
[00:20:18.880 --> 00:20:21.600]   that are intelligent like us,
[00:20:21.600 --> 00:20:26.320]   but yet very different than us.
[00:20:26.320 --> 00:20:30.960]   So we have like, dogs or wolves, I guess, co-evolved.
[00:20:30.960 --> 00:20:35.920]   They figured out how to neighbor up with humans
[00:20:35.920 --> 00:20:40.000]   in a friendly way and collaborate and develop in time.
[00:20:40.000 --> 00:20:42.240]   - You're describing this as if the wolves made a choice.
[00:20:42.240 --> 00:20:46.160]   It's possible that the wolves never had a say,
[00:20:46.160 --> 00:20:49.360]   that basically humans were just so overpowering
[00:20:49.360 --> 00:20:51.440]   that they had captive wolves
[00:20:51.440 --> 00:20:54.960]   and then at every generation killed off eight of the nine pups
[00:20:54.960 --> 00:20:56.480]   and only kept the one that was milder.
[00:20:56.480 --> 00:20:57.120]   - Ah, humans.
[00:20:57.120 --> 00:20:58.880]   - And it only takes a few generations
[00:20:58.880 --> 00:21:01.040]   to then sort of have pups that are really mild.
[00:21:01.040 --> 00:21:04.960]   - And so the Neanderthals weren't useful
[00:21:04.960 --> 00:21:07.520]   in the same way that wolves were.
[00:21:07.520 --> 00:21:09.360]   - I don't know if it's a question of useful.
[00:21:09.360 --> 00:21:10.720]   They were probably super useful.
[00:21:10.720 --> 00:21:15.280]   My thinking is that they were scary,
[00:21:15.280 --> 00:21:17.600]   that basically something that almost resembles you
[00:21:17.600 --> 00:21:20.800]   is something that you try to eliminate first.
[00:21:20.800 --> 00:21:21.680]   - It's too close.
[00:21:21.680 --> 00:21:26.800]   - Yeah, and speaking of species that are intelligent
[00:21:26.800 --> 00:21:28.800]   and sort of what's left of evolution,
[00:21:28.800 --> 00:21:32.000]   it is a shame, exactly like you say,
[00:21:32.000 --> 00:21:35.360]   that so many different amazing life forms were extinct
[00:21:35.360 --> 00:21:38.640]   and the kind of boring ones remained.
[00:21:38.640 --> 00:21:40.240]   (laughs)
[00:21:40.240 --> 00:21:42.800]   So if you look at dinosaurs, I mean,
[00:21:42.800 --> 00:21:45.360]   the diversity that they had, if you look at sub,
[00:21:45.360 --> 00:21:51.280]   like there's just so many different lineages of life
[00:21:51.280 --> 00:21:53.440]   that were just abruptly killed
[00:21:54.160 --> 00:21:57.440]   and yet out of that death emerged
[00:21:57.440 --> 00:22:00.080]   many new kinds of really awesome lineages.
[00:22:00.080 --> 00:22:03.680]   - Do you think there was in the history of life on Earth,
[00:22:03.680 --> 00:22:06.480]   species that may be still alive today
[00:22:06.480 --> 00:22:08.400]   that are more intelligent than humans?
[00:22:08.400 --> 00:22:09.360]   And we just don't know, like dolphins?
[00:22:09.360 --> 00:22:11.200]   - So there's a reason we made for dolphins.
[00:22:11.200 --> 00:22:12.560]   Like if you look at their brains,
[00:22:12.560 --> 00:22:14.560]   if you look at the way that they play,
[00:22:14.560 --> 00:22:15.920]   if you look at the way that they learn,
[00:22:15.920 --> 00:22:19.920]   I mean, they don't have opposable thumbs and we do.
[00:22:19.920 --> 00:22:21.840]   So that probably made a big difference.
[00:22:21.840 --> 00:22:24.240]   - It's terrifying to think that like, not terrifying,
[00:22:24.240 --> 00:22:25.840]   I don't know how to feel about it,
[00:22:25.840 --> 00:22:27.680]   that they're more intelligent than us.
[00:22:27.680 --> 00:22:29.360]   It's like the hitchhiker's guide.
[00:22:29.360 --> 00:22:32.480]   - I know, but how do you define intelligence?
[00:22:32.480 --> 00:22:34.240]   Basically, like I was saying last time,
[00:22:34.240 --> 00:22:37.920]   stupid is as stupid does and smart is as smart does.
[00:22:37.920 --> 00:22:41.840]   So if the dolphins are basically super smart,
[00:22:41.840 --> 00:22:43.040]   figured out the meaning of life
[00:22:43.040 --> 00:22:45.200]   and just go around playing with water all day,
[00:22:45.200 --> 00:22:46.400]   which is probably the meaning of life,
[00:22:46.400 --> 00:22:50.160]   then we wouldn't know
[00:22:50.160 --> 00:22:51.680]   because all they're doing is kicking water,
[00:22:51.680 --> 00:22:52.640]   just like sharks are,
[00:22:52.640 --> 00:22:54.400]   and sharks are probably pretty stupid.
[00:22:54.400 --> 00:22:57.120]   So basically it's very difficult
[00:22:57.120 --> 00:22:59.280]   to sort of judge a species intelligence
[00:22:59.280 --> 00:23:01.600]   unless they kind of go out of their way to demonstrate it.
[00:23:01.600 --> 00:23:06.240]   - Yeah, and that's instructive for our understanding
[00:23:06.240 --> 00:23:07.760]   of any kind of life form.
[00:23:07.760 --> 00:23:10.960]   You know, I recently talked to Sarah Seager
[00:23:10.960 --> 00:23:13.840]   looking for life out there on other planets.
[00:23:13.840 --> 00:23:16.320]   It'd be fascinating to think
[00:23:16.320 --> 00:23:21.120]   if we discover a habitable planet outside of Earth
[00:23:21.120 --> 00:23:23.200]   in one day, maybe many centuries away,
[00:23:23.200 --> 00:23:26.080]   or be able to travel with like a robot there,
[00:23:26.080 --> 00:23:30.560]   how would we actually know that this species
[00:23:30.560 --> 00:23:33.520]   would probably be able to detect that it's a living being,
[00:23:33.520 --> 00:23:37.120]   but how would we know if it's an intelligent being?
[00:23:37.120 --> 00:23:41.840]   I mean, it's both exciting and terrifying
[00:23:41.840 --> 00:23:46.160]   to sort of come face to face with a life form
[00:23:46.160 --> 00:23:47.440]   that's of another world,
[00:23:48.320 --> 00:23:51.200]   like something that clearly is moving in a,
[00:23:51.200 --> 00:23:54.960]   how would you say, like a deliberate way,
[00:23:54.960 --> 00:23:57.840]   and to then like ask,
[00:23:57.840 --> 00:24:01.920]   "Well, how do I ask that thing whether it's intelligent?"
[00:24:01.920 --> 00:24:03.840]   - No, but the question that you're asking
[00:24:03.840 --> 00:24:07.600]   is applicable to every species on the Earth now.
[00:24:07.600 --> 00:24:08.320]   - On Earth now, yeah.
[00:24:08.320 --> 00:24:11.280]   - Yeah, so basically, you know, dolphins are a great example.
[00:24:11.280 --> 00:24:15.520]   We know that they're clearly capable hardware-wise
[00:24:15.520 --> 00:24:17.840]   and behavior-wise of intelligence.
[00:24:17.840 --> 00:24:20.000]   You know, how do we communicate?
[00:24:20.000 --> 00:24:21.760]   So basically, if your question is about
[00:24:21.760 --> 00:24:23.680]   crossing species boundaries of communication,
[00:24:23.680 --> 00:24:28.240]   the way that I wanna put it is that
[00:24:28.240 --> 00:24:32.880]   humans have achieved a level of sophistication
[00:24:32.880 --> 00:24:35.760]   in our behaviors, in our communication, in our language,
[00:24:35.760 --> 00:24:38.240]   in our ways of expressing ourselves,
[00:24:38.240 --> 00:24:43.200]   that I have no doubt that if we encountered
[00:24:43.200 --> 00:24:44.720]   a human-like form of intelligence,
[00:24:45.360 --> 00:24:47.440]   we'd figure out their language in a few weeks.
[00:24:47.440 --> 00:24:50.400]   Like, it'd be just fine, as long as, you know,
[00:24:50.400 --> 00:24:52.720]   of course, they're both trusting each other
[00:24:52.720 --> 00:24:53.920]   and not annihilating each other
[00:24:53.920 --> 00:24:56.960]   and not sort of fearing each other and attacking each other.
[00:24:56.960 --> 00:25:00.480]   - What about, let me ask, just out of curiosity
[00:25:00.480 --> 00:25:02.000]   into science fiction land a little bit,
[00:25:02.000 --> 00:25:05.920]   if, so clearly, you're one of the top scientists
[00:25:05.920 --> 00:25:10.720]   in the world, so if we were to discover an alien life form,
[00:25:10.720 --> 00:25:14.720]   you would be brought in to study his genetics,
[00:25:15.600 --> 00:25:18.160]   do you think the epigenome that we talked about,
[00:25:18.160 --> 00:25:22.240]   the genome, the code, the digital code that underlies
[00:25:22.240 --> 00:25:24.480]   that alien life form would be similar to ours?
[00:25:24.480 --> 00:25:29.840]   Like, in fundamental ways, maybe not exactly,
[00:25:29.840 --> 00:25:32.320]   but in fundamental ways of how it's structured?
[00:25:32.320 --> 00:25:35.440]   - Yeah, so you're getting to the very definition of life.
[00:25:35.440 --> 00:25:37.280]   You're getting to the very definition of
[00:25:37.280 --> 00:25:41.200]   what makes life life and how do we decode that life?
[00:25:41.920 --> 00:25:45.600]   And it's so easy to think that every life form
[00:25:45.600 --> 00:25:48.080]   would basically have to, you know, like oxygen,
[00:25:48.080 --> 00:25:53.040]   have to like heat from the sun and rely on sort of being
[00:25:53.040 --> 00:25:56.960]   in the habitable zone of, you know, its solar system
[00:25:56.960 --> 00:25:58.080]   and so on and so forth.
[00:25:58.080 --> 00:26:02.320]   But I think we have to sort of go beyond this sort of,
[00:26:02.320 --> 00:26:05.200]   oh, life on another planet must be exactly
[00:26:05.200 --> 00:26:08.000]   like life is on Earth, because of course, life on Earth
[00:26:08.000 --> 00:26:11.280]   happens to rely on the proximity to the sun
[00:26:11.280 --> 00:26:13.360]   and benefit from that amount of energy.
[00:26:13.360 --> 00:26:18.800]   But we're talking at timescales of human life
[00:26:18.800 --> 00:26:21.920]   where we kind of live, I don't know, between,
[00:26:21.920 --> 00:26:23.760]   and I'm gonna be super wide here,
[00:26:23.760 --> 00:26:26.720]   we're gonna live between six Earth months
[00:26:26.720 --> 00:26:31.200]   and, you know, 200 Earth months or 200 Earth years.
[00:26:31.200 --> 00:26:34.320]   So basically, if you look at the timescale
[00:26:34.320 --> 00:26:37.600]   that we inhabit on Earth, it is very much dictated
[00:26:37.600 --> 00:26:39.520]   by the amount of energy that we receive from the sun.
[00:26:40.480 --> 00:26:43.600]   If you look at, I don't know, Europa, you know,
[00:26:43.600 --> 00:26:47.120]   the smallest, the fourth smallest moon of Jupiter,
[00:26:47.120 --> 00:26:48.720]   the smallest of the Galilean moons,
[00:26:48.720 --> 00:26:52.000]   and also the smallest in its distance from Jupiter,
[00:26:52.000 --> 00:26:58.640]   it has an iron core, it has a rock exterior,
[00:26:58.640 --> 00:27:02.000]   it has ice all around it,
[00:27:02.000 --> 00:27:06.320]   and it has probably massive liquid oceans underneath.
[00:27:07.200 --> 00:27:10.960]   And the gravitational pull of Jupiter
[00:27:10.960 --> 00:27:14.240]   is probably creating all kinds of movement under that ice.
[00:27:14.240 --> 00:27:17.600]   How did life evolve on Earth?
[00:27:17.600 --> 00:27:22.080]   Yes, sure, life now, most of life that we,
[00:27:22.080 --> 00:27:25.760]   above the surface, look at has to do with
[00:27:25.760 --> 00:27:30.720]   exploiting the solar energy for, you know,
[00:27:30.720 --> 00:27:32.000]   our daily behavior.
[00:27:32.000 --> 00:27:33.680]   But that's not the case everywhere on the planet.
[00:27:33.680 --> 00:27:36.240]   If you look at the bottom of the ocean,
[00:27:37.120 --> 00:27:38.960]   there are hydrothermal vents.
[00:27:38.960 --> 00:27:41.280]   There's both black smokers and white smokers,
[00:27:41.280 --> 00:27:45.680]   and they are near these volcanic, you know,
[00:27:45.680 --> 00:27:50.240]   ducts that basically emanate a massive amount of energy
[00:27:50.240 --> 00:27:52.640]   from the core of our planet.
[00:27:52.640 --> 00:27:53.600]   What does life need?
[00:27:53.600 --> 00:27:54.480]   It needs energy.
[00:27:54.480 --> 00:27:57.280]   Does it need energy from the sun?
[00:27:57.280 --> 00:27:58.160]   It couldn't care less.
[00:27:58.160 --> 00:28:01.600]   Does it need energy from, you know, the Earth itself?
[00:28:01.600 --> 00:28:04.720]   Yeah, possibly, it could use that.
[00:28:04.720 --> 00:28:07.840]   And if you look at how did life evolve on,
[00:28:07.840 --> 00:28:10.560]   you know, on Earth, there are many theories.
[00:28:10.560 --> 00:28:14.000]   I mean, a kind of silly theory is that it came from outer space,
[00:28:14.000 --> 00:28:15.760]   that basically there's a meteorite out there
[00:28:15.760 --> 00:28:19.280]   that sort of landed on Earth and brought with it DNA material.
[00:28:19.280 --> 00:28:20.160]   I think it's a little silly
[00:28:20.160 --> 00:28:22.160]   because it kind of pushes the buck down the road.
[00:28:22.160 --> 00:28:24.720]   Basically, the next question is how did it evolve over there?
[00:28:24.720 --> 00:28:25.280]   - Yeah, exactly.
[00:28:25.280 --> 00:28:28.320]   - Whereas our planet has basically all of the right ingredients.
[00:28:28.320 --> 00:28:29.440]   Why wouldn't it evolve here?
[00:28:29.440 --> 00:28:31.040]   So basically, let's kind of ignore that one.
[00:28:31.040 --> 00:28:32.800]   And now the two other competing hypotheses
[00:28:32.800 --> 00:28:35.760]   are from the outside in or from the inside out.
[00:28:35.760 --> 00:28:36.640]   - What's that mean?
[00:28:36.640 --> 00:28:38.640]   - From the outside in means from the surface
[00:28:38.640 --> 00:28:39.600]   to the bottom of the ocean.
[00:28:39.600 --> 00:28:40.400]   - Ah.
[00:28:40.400 --> 00:28:42.080]   - From the inside out means
[00:28:42.080 --> 00:28:43.840]   from the bottom of the ocean to the surface.
[00:28:43.840 --> 00:28:49.360]   So life on the surface is pretty brutal.
[00:28:49.360 --> 00:28:54.880]   Life obviously evolved in the water
[00:28:54.880 --> 00:28:56.960]   and then there was an out of water event.
[00:28:56.960 --> 00:29:00.240]   But basically, before it exited,
[00:29:01.280 --> 00:29:02.640]   it was clearly in the water,
[00:29:02.640 --> 00:29:04.720]   which is a much nicer and shielded environment.
[00:29:04.720 --> 00:29:07.200]   - So just to be clear, on the surface,
[00:29:07.200 --> 00:29:09.200]   are you referring to the--
[00:29:09.200 --> 00:29:12.080]   - The surface of the sea or the bottom of the sea.
[00:29:12.080 --> 00:29:15.440]   - Versus the bottom of the sea.
[00:29:15.440 --> 00:29:19.200]   And you're saying life on the surface is harsh.
[00:29:19.200 --> 00:29:23.440]   - Life outside the water is horrible.
[00:29:23.440 --> 00:29:27.600]   It takes huge amounts of evolutionary innovations
[00:29:27.600 --> 00:29:29.440]   to sustain living outside the water.
[00:29:29.440 --> 00:29:32.240]   - That's so interesting.
[00:29:32.240 --> 00:29:33.120]   Why is that?
[00:29:33.120 --> 00:29:36.480]   So it's easier to, life is easier in the water.
[00:29:36.480 --> 00:29:38.080]   Maybe, see, I'm telling dolphins--
[00:29:38.080 --> 00:29:39.760]   - We are 70% water.
[00:29:39.760 --> 00:29:41.440]   No, dolphins went back into the water.
[00:29:41.440 --> 00:29:42.320]   - Really?
[00:29:42.320 --> 00:29:42.560]   - Of course.
[00:29:42.560 --> 00:29:43.920]   - 'Cause dolphins are mammals.
[00:29:43.920 --> 00:29:44.960]   - Of course, yeah.
[00:29:44.960 --> 00:29:45.760]   - Interesting.
[00:29:45.760 --> 00:29:47.280]   Well, again, they might be smarter.
[00:29:47.280 --> 00:29:47.920]   They went back.
[00:29:47.920 --> 00:29:49.200]   They're like, "Screw this."
[00:29:49.200 --> 00:29:53.840]   - So if you basically think about the fact
[00:29:53.840 --> 00:29:55.280]   that we are 70% water,
[00:29:55.280 --> 00:29:58.320]   we're basically transporting the sea with us
[00:29:59.040 --> 00:30:00.160]   outside the sea.
[00:30:00.160 --> 00:30:01.440]   (Lex laughs)
[00:30:01.440 --> 00:30:05.680]   You know, if we don't have water for about 24 hours,
[00:30:05.680 --> 00:30:06.240]   we're dry.
[00:30:06.240 --> 00:30:06.800]   - Yeah.
[00:30:06.800 --> 00:30:09.600]   - And if you look at life under the sea,
[00:30:09.600 --> 00:30:10.880]   I mean, I don't know if you're a diver,
[00:30:10.880 --> 00:30:13.920]   but when you go diving, your brain explodes.
[00:30:13.920 --> 00:30:17.120]   Again, when I say the boring life forms
[00:30:17.120 --> 00:30:19.840]   is what we see all the time, like tetrapods.
[00:30:19.840 --> 00:30:22.720]   I mean, what a stupid, boring body plan.
[00:30:22.720 --> 00:30:23.360]   Seriously.
[00:30:23.360 --> 00:30:26.160]   Like, just go diving and you'll see
[00:30:26.160 --> 00:30:29.360]   that a tiny little minority of the stuff under the sea,
[00:30:29.360 --> 00:30:31.600]   under the surface of the sea, is actually tetrapods.
[00:30:31.600 --> 00:30:36.320]   It's like snails with all kinds of crazy appendages
[00:30:36.320 --> 00:30:40.320]   and colors and round things and five-way symmetric things
[00:30:40.320 --> 00:30:42.640]   and eight-way symmetric things,
[00:30:42.640 --> 00:30:44.240]   all kinds of crazy body plans.
[00:30:44.240 --> 00:30:48.640]   And only the tetrapod fish managed to get out.
[00:30:48.640 --> 00:30:50.560]   And then they gave rise to all the boring plans
[00:30:50.560 --> 00:30:56.080]   we kind of see today of basically humans with four limbs,
[00:30:56.160 --> 00:30:58.480]   birds with four limbs, lizards with four limbs,
[00:30:58.480 --> 00:31:00.960]   and you know, right?
[00:31:00.960 --> 00:31:01.920]   It's kind of boring.
[00:31:01.920 --> 00:31:03.760]   If you look at, by comparison,
[00:31:03.760 --> 00:31:06.160]   life underwater is teeming with diversity.
[00:31:06.160 --> 00:31:08.560]   So now let's roll back the clock
[00:31:08.560 --> 00:31:12.160]   and basically say where did life in the ocean come from?
[00:31:12.160 --> 00:31:12.640]   - The three--
[00:31:12.640 --> 00:31:14.400]   - From the surface or from the bottom?
[00:31:14.400 --> 00:31:16.080]   - Exactly, those two options you were mentioning.
[00:31:16.080 --> 00:31:16.800]   - Exactly.
[00:31:16.800 --> 00:31:20.320]   So basically, life on the surface is one option.
[00:31:20.320 --> 00:31:23.440]   And then the idea there is that there's tides
[00:31:23.440 --> 00:31:25.760]   with the moon and the sun sort of causing
[00:31:25.760 --> 00:31:28.240]   all this movement and this movement is basically
[00:31:28.240 --> 00:31:31.120]   causing nutrients to sort of coalesce
[00:31:31.120 --> 00:31:32.880]   and bounce around, et cetera.
[00:31:32.880 --> 00:31:33.840]   That's one option.
[00:31:33.840 --> 00:31:36.720]   The second option, massive amount of energy
[00:31:36.720 --> 00:31:40.560]   under, from the core of our planet,
[00:31:40.560 --> 00:31:43.200]   basically exploited,
[00:31:43.200 --> 00:31:47.920]   leading to these basic ingredients of life forms.
[00:31:47.920 --> 00:31:49.200]   And what are these basic ingredients?
[00:31:49.200 --> 00:31:52.400]   Metabolism, being able to take energy
[00:31:52.400 --> 00:31:55.120]   from the environment and put it as part of yourself.
[00:31:56.080 --> 00:31:58.800]   Metabolism, it basically means transformation,
[00:31:58.800 --> 00:31:59.680]   again, in the Greek.
[00:31:59.680 --> 00:32:01.480]   (laughs)
[00:32:01.480 --> 00:32:05.200]   - It basically means taking stuff from,
[00:32:05.200 --> 00:32:08.000]   you know, like nutrients or energy source
[00:32:08.000 --> 00:32:09.920]   or anything and then making it your own.
[00:32:09.920 --> 00:32:11.840]   The second one is compartmentalization.
[00:32:11.840 --> 00:32:16.320]   If there's no notion of self, there can't be evolution.
[00:32:16.320 --> 00:32:18.480]   You have to know where your own boundaries end
[00:32:18.480 --> 00:32:20.640]   and where the non-self boundaries begin.
[00:32:20.640 --> 00:32:24.720]   And that's basically the lipid bilayer nowadays,
[00:32:24.720 --> 00:32:27.040]   which is extremely simple to form.
[00:32:27.040 --> 00:32:28.560]   It's basically just a bunch of lipids
[00:32:28.560 --> 00:32:30.480]   and then they eventually just self-organize
[00:32:30.480 --> 00:32:31.120]   into a membrane.
[00:32:31.120 --> 00:32:34.480]   So that's a very natural way of forming a self.
[00:32:34.480 --> 00:32:39.040]   And then the third component is replication.
[00:32:39.040 --> 00:32:42.800]   Replication doesn't need to be self-replication.
[00:32:42.800 --> 00:32:45.760]   It could be A helps make more of B,
[00:32:45.760 --> 00:32:47.440]   B helps make more of C,
[00:32:47.440 --> 00:32:49.280]   and C helps make more of A.
[00:32:49.280 --> 00:32:52.720]   Any kind of self-reinforcement
[00:32:52.720 --> 00:32:55.360]   is what you need to ignite the process of evolution.
[00:32:55.360 --> 00:32:57.520]   After you've ignited that process,
[00:32:57.520 --> 00:33:00.560]   you know, I don't wanna say all hell breaks loose,
[00:33:00.560 --> 00:33:01.760]   but all paradise breaks loose.
[00:33:01.760 --> 00:33:02.320]   (laughs)
[00:33:02.320 --> 00:33:06.880]   So basically you then, boom, you know, have life going.
[00:33:06.880 --> 00:33:08.720]   And the moment you have A, B, C,
[00:33:08.720 --> 00:33:10.880]   some kind of thing looping back onto A,
[00:33:10.880 --> 00:33:14.800]   you can make modifications and you can improve
[00:33:14.800 --> 00:33:16.480]   and then you let natural selection work.
[00:33:16.480 --> 00:33:19.120]   - Is there some element of that that's like,
[00:33:21.200 --> 00:33:24.880]   like some state representation that stores information?
[00:33:24.880 --> 00:33:26.640]   Like maybe I should say information.
[00:33:26.640 --> 00:33:27.280]   - Yeah, absolutely.
[00:33:27.280 --> 00:33:28.560]   - Is that a fundamental part of life?
[00:33:28.560 --> 00:33:31.200]   - So we like to think of life
[00:33:31.200 --> 00:33:34.800]   as the information propagation, which is DNA,
[00:33:34.800 --> 00:33:37.200]   the messenger, which is RNA,
[00:33:37.200 --> 00:33:39.920]   and then the action, which is protein.
[00:33:39.920 --> 00:33:45.040]   So basically DNA, we think is an essential part of life.
[00:33:45.040 --> 00:33:48.240]   That's where the storage is.
[00:33:48.240 --> 00:33:49.760]   And therefore that early life forms
[00:33:49.760 --> 00:33:52.320]   must have had some kind of storage medium, DNA.
[00:33:52.320 --> 00:33:55.600]   If you look at how life actually evolved,
[00:33:55.600 --> 00:33:58.080]   DNA was invented much later.
[00:33:58.080 --> 00:34:01.920]   Proteins were invented later.
[00:34:01.920 --> 00:34:06.480]   And RNA was found by itself, thank you very much,
[00:34:06.480 --> 00:34:08.080]   in an RNA world.
[00:34:08.080 --> 00:34:12.400]   So the early version of life as we know it today
[00:34:12.400 --> 00:34:17.120]   was in fact RNA molecules performing all of the functions.
[00:34:17.760 --> 00:34:22.240]   The RNA molecule itself was the protein actuator
[00:34:22.240 --> 00:34:25.600]   by creating three-dimensional folds
[00:34:25.600 --> 00:34:26.800]   through self hybridization.
[00:34:26.800 --> 00:34:28.160]   - Self what?
[00:34:28.160 --> 00:34:29.360]   - Self hybridization.
[00:34:29.360 --> 00:34:31.280]   So basically the same way that DNA molecules
[00:34:31.280 --> 00:34:32.400]   can hybridize with themselves
[00:34:32.400 --> 00:34:34.400]   and basically form this double helix.
[00:34:34.400 --> 00:34:37.280]   The single-stranded RNA molecule
[00:34:37.280 --> 00:34:41.760]   can form partial double helices in various places,
[00:34:41.760 --> 00:34:45.120]   creating structure as if you had a long string
[00:34:45.120 --> 00:34:46.400]   with complementary parts
[00:34:46.400 --> 00:34:48.000]   and you could then sort of design
[00:34:48.000 --> 00:34:50.240]   kind of like origami-like structures
[00:34:50.240 --> 00:34:51.520]   that will fold onto themselves.
[00:34:51.520 --> 00:34:53.920]   And then you can make any shape from that.
[00:34:53.920 --> 00:35:00.320]   That early RNA world eventually got to replication
[00:35:00.320 --> 00:35:07.280]   where enzymes encoded in RNA would replicate RNA itself.
[00:35:07.280 --> 00:35:12.240]   And then that process basically kicked off evolution.
[00:35:12.240 --> 00:35:15.360]   And that process of evolution then
[00:35:15.360 --> 00:35:16.880]   led to major innovations.
[00:35:16.880 --> 00:35:20.080]   The first innovation was translation.
[00:35:20.080 --> 00:35:23.120]   So you start with an RNA molecule
[00:35:23.120 --> 00:35:25.680]   and you translate it into another kind of form.
[00:35:25.680 --> 00:35:27.040]   And that's the first kind of encoding.
[00:35:27.040 --> 00:35:29.120]   You're like, well, do you need some kind of code?
[00:35:29.120 --> 00:35:33.280]   Yeah, but the code was in fact one thing.
[00:35:33.280 --> 00:35:35.920]   It was conflated with the actuators.
[00:35:35.920 --> 00:35:39.760]   The actuators were separated from the code only later on.
[00:35:39.760 --> 00:35:42.480]   So you first had the self-replicating code
[00:35:42.480 --> 00:35:44.320]   which was also the actuator.
[00:35:44.320 --> 00:35:46.960]   And then you kind of have a functionalization,
[00:35:46.960 --> 00:35:49.360]   partitioning of the functionalization,
[00:35:49.360 --> 00:35:52.160]   a sub-functionalization of the proteins
[00:35:52.160 --> 00:35:54.160]   that are now gonna be the workhorse of life
[00:35:54.160 --> 00:35:56.400]   but they're not self-replicating.
[00:35:56.400 --> 00:35:58.080]   The code remains the RNA.
[00:35:58.080 --> 00:36:02.960]   So the most beautiful and most complex RNA machine
[00:36:02.960 --> 00:36:04.640]   known to man is the ribosome.
[00:36:04.640 --> 00:36:08.560]   And the ribosome is this massive factory
[00:36:08.560 --> 00:36:11.520]   that is able to translate RNA into protein.
[00:36:13.200 --> 00:36:15.200]   The ribosome, I mean, if you want, I don't know,
[00:36:15.200 --> 00:36:17.360]   divine intervention in the history of life,
[00:36:17.360 --> 00:36:18.320]   the ribosome is it.
[00:36:18.320 --> 00:36:18.880]   (laughs)
[00:36:18.880 --> 00:36:20.400]   - That's one of the great invention
[00:36:20.400 --> 00:36:21.280]   in the history of life.
[00:36:21.280 --> 00:36:22.640]   - It's, yeah.
[00:36:22.640 --> 00:36:24.480]   But again, you can't think of great inventions
[00:36:24.480 --> 00:36:25.840]   as one-time steps.
[00:36:25.840 --> 00:36:29.360]   They're basically the culmination
[00:36:29.360 --> 00:36:32.800]   of probably many competing software infrastructures
[00:36:32.800 --> 00:36:36.240]   for life preservation that won out.
[00:36:36.240 --> 00:36:38.560]   And then when the ribosome was so efficient
[00:36:38.560 --> 00:36:39.520]   at making proteins,
[00:36:39.520 --> 00:36:41.680]   all the other ones basically died out.
[00:36:42.400 --> 00:36:44.800]   And then the life forms that were using
[00:36:44.800 --> 00:36:45.840]   the modern ribosome
[00:36:45.840 --> 00:36:48.640]   were basically the more successful ones
[00:36:48.640 --> 00:36:49.760]   because it could make proteins.
[00:36:49.760 --> 00:36:54.400]   And now those proteins are much more versatile
[00:36:54.400 --> 00:36:56.000]   because RNA only has four bases.
[00:36:56.000 --> 00:36:59.840]   Proteins eventually have 20 amino acids,
[00:36:59.840 --> 00:37:01.200]   not initially, but eventually.
[00:37:01.200 --> 00:37:05.120]   And then they can form in much more complex shapes
[00:37:05.120 --> 00:37:06.960]   and they can create all kinds of additional machines,
[00:37:06.960 --> 00:37:10.960]   one of which is reverse transcriptase.
[00:37:11.920 --> 00:37:13.440]   So you basically now have RNA.
[00:37:13.440 --> 00:37:16.960]   Again, we like to think of transcription as the normal,
[00:37:16.960 --> 00:37:18.400]   reverse transcription as the oddball.
[00:37:18.400 --> 00:37:21.440]   Well, RNA preceded DNA.
[00:37:21.440 --> 00:37:24.320]   So reverse transcription actually was the first invention
[00:37:24.320 --> 00:37:25.600]   before transcription itself.
[00:37:25.600 --> 00:37:29.200]   So basically RNA invents proteins,
[00:37:29.200 --> 00:37:32.080]   RNA and proteins together invent DNA.
[00:37:32.080 --> 00:37:35.600]   So you now have a more stable medium,
[00:37:35.600 --> 00:37:37.840]   a more stable backbone
[00:37:37.840 --> 00:37:41.280]   with two helices instead of one.
[00:37:41.600 --> 00:37:43.920]   Two strands instead of one, the double helix.
[00:37:43.920 --> 00:37:47.120]   And RNA basically says, "Listen, I'm tired.
[00:37:47.120 --> 00:37:50.720]   "I'm gonna delegate all information storage to DNA
[00:37:50.720 --> 00:37:55.280]   "and I'm gonna delegate most actuation to proteins."
[00:37:55.280 --> 00:37:55.920]   - Proteins.
[00:37:55.920 --> 00:37:58.160]   But that's, to you, is not like a,
[00:37:58.160 --> 00:38:01.280]   that's just an efficiency thing.
[00:38:01.280 --> 00:38:04.320]   It's not a fundamentally new invention.
[00:38:04.320 --> 00:38:04.640]   - Correct.
[00:38:04.640 --> 00:38:05.680]   That's why when you're asking,
[00:38:05.680 --> 00:38:08.240]   "Is a separate information storage medium
[00:38:08.240 --> 00:38:09.600]   "a definition of life?"
[00:38:09.600 --> 00:38:13.120]   I'm like, "No, any kind of self-preservation,
[00:38:13.120 --> 00:38:15.040]   "self-reinforcement."
[00:38:15.040 --> 00:38:18.400]   And it didn't need to be RNA-based initially.
[00:38:18.400 --> 00:38:21.200]   It didn't need to be self-replication initially.
[00:38:21.200 --> 00:38:23.360]   You just need to have enough RNA molecules
[00:38:23.360 --> 00:38:26.560]   randomly arising that reinforce each other
[00:38:26.560 --> 00:38:32.480]   that ultimately lead to the closing of that loop
[00:38:32.480 --> 00:38:34.080]   and the ignition of the evolutionary process.
[00:38:34.080 --> 00:38:36.640]   - Can we just rewind a little bit?
[00:38:36.640 --> 00:38:38.320]   Like if you were to bet all your money
[00:38:38.320 --> 00:38:41.120]   on the two options in terms of where life started--
[00:38:41.120 --> 00:38:42.320]   - Probably the bottom.
[00:38:42.320 --> 00:38:45.520]   - At the bottom, I don't know if this is answerable,
[00:38:45.520 --> 00:38:49.360]   but how hard is the first step?
[00:38:49.360 --> 00:38:52.080]   Or if there's something interesting you can say
[00:38:52.080 --> 00:38:53.360]   about that first leap--
[00:38:53.360 --> 00:38:54.320]   - Yeah, yeah, yeah.
[00:38:54.320 --> 00:38:56.880]   - About from not life to life.
[00:38:56.880 --> 00:38:59.280]   - Yeah, I think it's inevitable.
[00:38:59.280 --> 00:39:01.600]   - On Earth or just--
[00:39:01.600 --> 00:39:02.640]   - In the universe.
[00:39:02.640 --> 00:39:03.440]   (Lex laughing)
[00:39:03.440 --> 00:39:04.400]   I think it's inevitable.
[00:39:04.400 --> 00:39:08.080]   If you look at Europa, you know, going back--
[00:39:08.080 --> 00:39:10.240]   - The moon of Jupiter?
[00:39:10.240 --> 00:39:12.000]   - It's also a really nice song by Santana.
[00:39:12.000 --> 00:39:13.680]   (Lex laughing)
[00:39:13.680 --> 00:39:16.960]   - Europa basically has all the ingredients.
[00:39:16.960 --> 00:39:20.800]   It has, you know, the core that can emit energy.
[00:39:20.800 --> 00:39:24.400]   It has the shielding through the ice sheet,
[00:39:24.400 --> 00:39:27.920]   protecting it just like an atmosphere would.
[00:39:27.920 --> 00:39:29.280]   It even has a layer of oxygen,
[00:39:29.280 --> 00:39:32.320]   probably sufficiently dense to sustain life.
[00:39:32.320 --> 00:39:36.960]   So my guess is that there's probably
[00:39:37.920 --> 00:39:43.920]   a independently arisen life form already teeming in Europa
[00:39:43.920 --> 00:39:44.960]   because as soon as it--
[00:39:44.960 --> 00:39:45.460]   - Today?
[00:39:45.460 --> 00:39:45.960]   - Today.
[00:39:45.960 --> 00:39:48.640]   - Is that exciting or terrifying to you?
[00:39:48.640 --> 00:39:50.640]   (Lex laughing)
[00:39:50.640 --> 00:39:53.600]   - It's, I mean, as a scientist,
[00:39:53.600 --> 00:39:57.520]   I can't wait to see non-DNA-based life forms.
[00:39:57.520 --> 00:40:01.040]   I can't wait because we are so born,
[00:40:01.040 --> 00:40:06.480]   you know, sort of born,
[00:40:06.800 --> 00:40:07.920]   as I would say in French,
[00:40:07.920 --> 00:40:10.000]   but basically we're sort of, you know,
[00:40:10.000 --> 00:40:13.440]   we are so narrow-minded in our thinking
[00:40:13.440 --> 00:40:15.840]   of what life should look like
[00:40:15.840 --> 00:40:18.800]   that I can't wait for all that to just be blown away
[00:40:18.800 --> 00:40:21.040]   by the discovery of life elsewhere.
[00:40:21.040 --> 00:40:24.720]   - Let me bring you into another science fiction scenario.
[00:40:24.720 --> 00:40:29.280]   So on that point, if we discover life on Europa
[00:40:29.280 --> 00:40:31.680]   and you were brought in,
[00:40:31.680 --> 00:40:34.880]   you seem very excited,
[00:40:34.880 --> 00:40:39.200]   but how would you start looking at that life
[00:40:39.200 --> 00:40:44.000]   in a way that's useful to you as a scientist,
[00:40:44.000 --> 00:40:46.400]   but also not going to kill all of us?
[00:40:46.400 --> 00:40:47.520]   (Lex laughing)
[00:40:47.520 --> 00:40:49.920]   So like, to me, it's a little bit scary
[00:40:49.920 --> 00:40:54.000]   because not because it's a malevolent life,
[00:40:54.000 --> 00:40:58.240]   like it's a dictator petting like a cat, it's evil,
[00:40:58.240 --> 00:41:00.080]   but just the way life is,
[00:41:00.080 --> 00:41:04.080]   it seems to be very good at conquering other life.
[00:41:04.080 --> 00:41:06.240]   - So there's a lot of science fiction movies
[00:41:06.240 --> 00:41:07.200]   based on that principle.
[00:41:07.200 --> 00:41:07.760]   - Yeah.
[00:41:07.760 --> 00:41:11.360]   - And that's sort of what causes the public to be so scared.
[00:41:11.360 --> 00:41:12.560]   But if you think about sort of,
[00:41:12.560 --> 00:41:16.240]   would Europa life be scared of humans
[00:41:16.240 --> 00:41:17.360]   coming over and taking over?
[00:41:17.360 --> 00:41:20.480]   Chances are no, not even like Earth bacteria,
[00:41:20.480 --> 00:41:22.480]   because Earth bacteria would be wiped out
[00:41:22.480 --> 00:41:24.720]   in an instant in this foreign world
[00:41:24.720 --> 00:41:28.240]   because they don't know how to metabolize energy
[00:41:28.240 --> 00:41:30.960]   that doesn't come from the types of energy sources
[00:41:30.960 --> 00:41:31.520]   that are here.
[00:41:32.320 --> 00:41:35.680]   The levels of acidity may just kill us all off.
[00:41:35.680 --> 00:41:38.800]   And at the same way, in the converse way,
[00:41:38.800 --> 00:41:40.640]   if you bring life from Europa on Earth,
[00:41:40.640 --> 00:41:42.480]   it'll die instantly because it's too hot.
[00:41:42.480 --> 00:41:46.320]   Or because it doesn't need to know how to cope with,
[00:41:46.320 --> 00:41:47.920]   I don't know, the sun's radiation
[00:41:47.920 --> 00:41:50.960]   so close to this completely inhabitable zone
[00:41:50.960 --> 00:41:51.840]   by their standards.
[00:41:51.840 --> 00:41:53.040]   (Lex laughing)
[00:41:53.040 --> 00:41:53.360]   - So--
[00:41:53.360 --> 00:41:55.120]   - So what we call the habitable zone
[00:41:55.120 --> 00:41:56.400]   might actually be the inhabitable zone.
[00:41:56.400 --> 00:41:57.360]   - Inhabitable for them.
[00:41:57.360 --> 00:41:59.120]   So the difference,
[00:41:59.120 --> 00:42:01.440]   if the environments are sufficiently different,
[00:42:01.440 --> 00:42:05.200]   you think we'll just not be able to even attack each other
[00:42:05.200 --> 00:42:05.840]   and the basic--
[00:42:05.840 --> 00:42:08.800]   - It'll take massive amounts of engineering
[00:42:08.800 --> 00:42:12.320]   to create machines that will go there
[00:42:12.320 --> 00:42:15.920]   and sample the oceans,
[00:42:15.920 --> 00:42:19.360]   basically drill through the layers of ice
[00:42:19.360 --> 00:42:23.520]   to basically sample and see what life is like there.
[00:42:23.520 --> 00:42:27.120]   And detecting it will probably be trivial.
[00:42:27.120 --> 00:42:28.720]   It definitely won't be DNA-based.
[00:42:28.720 --> 00:42:30.160]   It's not like we're gonna send a sequencer.
[00:42:30.880 --> 00:42:34.960]   But it'll be some other kind of combination of chemicals
[00:42:34.960 --> 00:42:36.240]   that will look non-random.
[00:42:36.240 --> 00:42:37.120]   - So if you had to bet,
[00:42:37.120 --> 00:42:41.200]   if I took that life form we find in Europa
[00:42:41.200 --> 00:42:43.840]   and put it on a sandwich that you're eating
[00:42:43.840 --> 00:42:45.520]   and eat that sandwich--
[00:42:45.520 --> 00:42:46.800]   - It'll taste just fine.
[00:42:46.800 --> 00:42:49.600]   - And you'll be, well, I know about that.
[00:42:49.600 --> 00:42:50.240]   (Lex laughing)
[00:42:50.240 --> 00:42:52.000]   I don't know, actually, will it taste fine?
[00:42:52.000 --> 00:42:52.720]   That's interesting.
[00:42:52.720 --> 00:42:53.760]   - So the other question is,
[00:42:53.760 --> 00:42:56.400]   do we have taste receptors for this?
[00:42:56.400 --> 00:42:56.800]   - Do you understand?
[00:42:56.800 --> 00:42:58.400]   - So where does our taste come from?
[00:42:58.400 --> 00:42:58.880]   - Oh, well, the chemistry.
[00:42:58.880 --> 00:43:01.680]   - Basically adaptations to chemical molecules
[00:43:01.680 --> 00:43:03.040]   that we are used to seeing.
[00:43:03.040 --> 00:43:03.520]   - So you think even the chemistry--
[00:43:03.520 --> 00:43:04.880]   - We don't have taste buds for things
[00:43:04.880 --> 00:43:05.920]   we don't even know about.
[00:43:05.920 --> 00:43:06.240]   - Wow.
[00:43:06.240 --> 00:43:07.840]   - So we won't, yeah, we won't be able to know
[00:43:07.840 --> 00:43:09.200]   that this chemical tastes funny.
[00:43:09.200 --> 00:43:10.240]   - But you think it won't be,
[00:43:10.240 --> 00:43:13.120]   it's likely not to be dangerous.
[00:43:13.120 --> 00:43:16.160]   Like it won't know how to even interact.
[00:43:16.160 --> 00:43:19.280]   Do you think our immune system will even detect
[00:43:19.280 --> 00:43:20.480]   that something weird is going on?
[00:43:20.480 --> 00:43:21.120]   - Probably.
[00:43:21.120 --> 00:43:22.080]   (Lex laughing)
[00:43:22.080 --> 00:43:23.360]   And it'll be very easy to detect
[00:43:23.360 --> 00:43:24.960]   because it'll be very different from us.
[00:43:24.960 --> 00:43:25.440]   - Very weird.
[00:43:25.440 --> 00:43:27.280]   - But it won't be able to sort of attack.
[00:43:27.280 --> 00:43:30.000]   I mean, the scene from, I don't know, Independence Day,
[00:43:30.000 --> 00:43:32.080]   where like they're communicating with the alien computer
[00:43:32.080 --> 00:43:32.880]   and they're like, "Ooh, I'm in."
[00:43:32.880 --> 00:43:34.080]   (Lex laughing)
[00:43:34.080 --> 00:43:34.960]   I mean, it's hilarious
[00:43:34.960 --> 00:43:37.520]   'cause like Macs and PCs have trouble communicating.
[00:43:37.520 --> 00:43:39.840]   (both laughing)
[00:43:39.840 --> 00:43:43.120]   I mean, let alone an alien technology or even alien DNA.
[00:43:43.120 --> 00:43:45.760]   - So, okay, now I was talking about you
[00:43:45.760 --> 00:43:46.880]   being a scientist on Earth,
[00:43:46.880 --> 00:43:49.040]   but say you were a scientist
[00:43:49.040 --> 00:43:50.640]   that was shipped over to Europa
[00:43:50.640 --> 00:43:52.960]   to investigate if there's life,
[00:43:52.960 --> 00:43:55.760]   what would you look for in terms of signs of life?
[00:43:55.760 --> 00:44:00.720]   - Life is unmistakable, I would say.
[00:44:00.720 --> 00:44:04.080]   The way that life transforms a planet surrounding it
[00:44:04.080 --> 00:44:07.200]   is not the kind of thing that you would expect
[00:44:07.200 --> 00:44:08.640]   from the physical laws alone.
[00:44:08.640 --> 00:44:15.200]   So, I would say that as soon as life arises,
[00:44:15.200 --> 00:44:18.080]   it creates this compartmentalization,
[00:44:18.080 --> 00:44:20.160]   it starts pushing things away,
[00:44:20.160 --> 00:44:22.880]   it starts sort of keeping things inside that are self,
[00:44:23.520 --> 00:44:27.760]   and there's a whole signature that you can see from that.
[00:44:27.760 --> 00:44:31.040]   So, when I was organizing my Meaning of Life Symposium,
[00:44:31.040 --> 00:44:33.520]   my friend who's an astrophysicist,
[00:44:33.520 --> 00:44:37.840]   basically we were deciding on what would be the themes
[00:44:37.840 --> 00:44:39.280]   for the symposium.
[00:44:39.280 --> 00:44:41.760]   And then I said, "Well, we're gonna have biology,
[00:44:41.760 --> 00:44:42.400]   we're gonna have physics."
[00:44:42.400 --> 00:44:44.080]   And she's like, "Oh, come on,
[00:44:44.080 --> 00:44:46.160]   biology is just a small part of physics."
[00:44:46.160 --> 00:44:48.640]   (both laughing)
[00:44:48.640 --> 00:44:50.240]   - Everything's a small part of physics, right?
[00:44:50.240 --> 00:44:53.280]   - And I mean, in many ways it is,
[00:44:53.280 --> 00:44:55.600]   but my immediate answer was, "No, no, no, no, wait.
[00:44:55.600 --> 00:45:00.160]   Life challenges physics, it supersedes physics,
[00:45:00.160 --> 00:45:02.560]   it sort of fights against physics."
[00:45:02.560 --> 00:45:05.040]   And that's what I would look for in Europa,
[00:45:05.040 --> 00:45:08.400]   I would basically look for this fight against physics
[00:45:08.400 --> 00:45:11.040]   for anything that sort of signatures of,
[00:45:11.040 --> 00:45:13.760]   not just entropy at work, not just things diffusing away,
[00:45:13.760 --> 00:45:18.560]   not just gravitational pools, but clear signatures of...
[00:45:18.560 --> 00:45:20.560]   You remember when I was talking earlier
[00:45:20.560 --> 00:45:22.400]   about this whole selection for environments,
[00:45:22.400 --> 00:45:25.120]   selection for biospheres, for ecosystems,
[00:45:25.120 --> 00:45:29.360]   for these multi-organism form of life?
[00:45:29.360 --> 00:45:31.440]   And I think that's sort of the first thing
[00:45:31.440 --> 00:45:34.720]   that you can look for, chemical signatures
[00:45:34.720 --> 00:45:36.720]   that are not simply predicted
[00:45:36.720 --> 00:45:38.480]   from the reactions you would get randomly.
[00:45:38.480 --> 00:45:40.880]   - It's such a beautiful way to look at life.
[00:45:40.880 --> 00:45:43.680]   So you're basically leveraging some energy source
[00:45:43.680 --> 00:45:47.840]   to enable you to resist the physics of the universe.
[00:45:47.840 --> 00:45:49.200]   - Fighting against physics.
[00:45:49.200 --> 00:45:49.760]   (Lex laughing)
[00:45:49.760 --> 00:45:51.440]   But that's the first transformation.
[00:45:51.440 --> 00:45:53.760]   If you look at humans, we're way past that.
[00:45:53.760 --> 00:45:55.200]   - What do you mean by transformation?
[00:45:55.200 --> 00:45:57.760]   - So basically there's layers.
[00:45:57.760 --> 00:46:00.400]   I sort of see life, you know,
[00:46:00.400 --> 00:46:04.160]   when we talk about the meaning of life,
[00:46:04.160 --> 00:46:06.880]   life can be construed at many levels.
[00:46:06.880 --> 00:46:09.040]   We talked about life in the simplest form
[00:46:09.040 --> 00:46:11.920]   of sort of the ignition of evolution.
[00:46:11.920 --> 00:46:13.520]   And that's sort of the basic definition
[00:46:13.520 --> 00:46:15.360]   that you can check off, yes, it's alive.
[00:46:15.360 --> 00:46:18.560]   But when Alexander the Great was asked,
[00:46:19.680 --> 00:46:23.440]   "To whom do you owe your life?
[00:46:23.440 --> 00:46:27.200]   To your teachers or to your parents?"
[00:46:27.200 --> 00:46:30.240]   And Alexander the Great answered,
[00:46:30.240 --> 00:46:35.120]   "I owe to my parents the zine, the life itself.
[00:46:35.120 --> 00:46:38.640]   And I owe to my teachers the F-zine."
[00:46:38.640 --> 00:46:42.480]   Like euphony, F means good, the opposite of cacophony,
[00:46:42.480 --> 00:46:44.160]   which means, you know, bad.
[00:46:44.160 --> 00:46:49.040]   So F-zine in his words
[00:46:49.040 --> 00:46:53.680]   was basically living a human life, a proper life.
[00:46:53.680 --> 00:46:56.880]   So basically we can go from the zine to the F-zine.
[00:46:56.880 --> 00:47:02.320]   And that transformation has taken several additional leaps.
[00:47:02.320 --> 00:47:05.360]   So basically, you know, life on Europa,
[00:47:05.360 --> 00:47:07.520]   I'm pretty sure has gotten to the stage of
[00:47:07.520 --> 00:47:10.320]   A makes B makes C makes A again.
[00:47:10.320 --> 00:47:15.920]   But getting to the F-zine is a whole other level.
[00:47:16.560 --> 00:47:20.080]   And that level requires cooperation.
[00:47:20.080 --> 00:47:23.360]   That level requires altruism.
[00:47:23.360 --> 00:47:26.880]   That level requires specialization.
[00:47:26.880 --> 00:47:29.760]   Remember how we were talking about the RNA specializing
[00:47:29.760 --> 00:47:34.640]   into DNA for storage, proteins, and then compartmentalizations?
[00:47:34.640 --> 00:47:38.080]   And if you look at prokaryotic life, there's no nucleus.
[00:47:38.080 --> 00:47:41.360]   It's all one soup of things intermingling.
[00:47:41.360 --> 00:47:44.800]   If you look at eukaryotic life, again,
[00:47:44.800 --> 00:47:47.920]   "euk" for true, good, you know?
[00:47:47.920 --> 00:47:51.040]   So a eukaryote basically has a nucleus,
[00:47:51.040 --> 00:47:52.960]   and that's where you compartmentalize further
[00:47:52.960 --> 00:47:57.360]   the organization of the information storage
[00:47:57.360 --> 00:47:59.440]   from all of the daily activities.
[00:47:59.440 --> 00:48:02.560]   If you look at a human body plan or any animal,
[00:48:02.560 --> 00:48:04.560]   you have a compartmentalization of the germline.
[00:48:04.560 --> 00:48:08.320]   You basically have one lineage that will basically be saved
[00:48:08.320 --> 00:48:09.760]   for the future generations.
[00:48:09.760 --> 00:48:12.640]   And everything outside that lineage is almost superfluous.
[00:48:14.160 --> 00:48:16.080]   If you think about it, the rest of your body,
[00:48:16.080 --> 00:48:19.840]   all it does is ensure that that lineage
[00:48:19.840 --> 00:48:21.360]   will make it to the next generation,
[00:48:21.360 --> 00:48:23.840]   that these germlines will make it to the next generation.
[00:48:23.840 --> 00:48:24.720]   The rest is packaging.
[00:48:24.720 --> 00:48:26.720]   I'm sorry to be so blunt.
[00:48:26.720 --> 00:48:30.880]   And if you look at nutrition, we're deuterostomes.
[00:48:30.880 --> 00:48:32.240]   What does deuterostome mean?
[00:48:32.240 --> 00:48:36.480]   Deutero means second, where this is the second mouth.
[00:48:36.480 --> 00:48:38.880]   The first mouth is actually down here, it's the esophagus.
[00:48:38.880 --> 00:48:42.800]   So deuterostomes have evolved a second layer of eating,
[00:48:42.800 --> 00:48:44.480]   kind of like alien with the two mouths.
[00:48:44.480 --> 00:48:46.320]   (laughing)
[00:48:46.320 --> 00:48:47.440]   So you can think of us as alien,
[00:48:47.440 --> 00:48:49.120]   where the first mouth is up here,
[00:48:49.120 --> 00:48:50.640]   and then the second mouth is down there.
[00:48:50.640 --> 00:48:55.040]   - Is the first mouth just the physical manipulation
[00:48:55.040 --> 00:48:56.720]   of the food to make it more consumable?
[00:48:56.720 --> 00:48:57.360]   - Correct, correct.
[00:48:57.360 --> 00:49:01.040]   And basically, again, if you look at a worm,
[00:49:01.040 --> 00:49:02.720]   it's an extremely simple life form.
[00:49:02.720 --> 00:49:05.040]   It basically has a mouth, it has an anus,
[00:49:05.040 --> 00:49:07.120]   and it has just some organs in between
[00:49:07.120 --> 00:49:09.120]   that consume the food and just spit out poo.
[00:49:10.720 --> 00:49:13.440]   Humans are basically a fancy form of that.
[00:49:13.440 --> 00:49:15.680]   So you basically have the mouth,
[00:49:15.680 --> 00:49:17.520]   you have the digestive tract,
[00:49:17.520 --> 00:49:19.760]   and then you have limbs to get better at getting food.
[00:49:19.760 --> 00:49:22.960]   You have eyesight, hearing, et cetera,
[00:49:22.960 --> 00:49:24.400]   to get better at getting food.
[00:49:24.400 --> 00:49:24.880]   - Yeah.
[00:49:24.880 --> 00:49:26.720]   - And then you have, of course, the germline.
[00:49:26.720 --> 00:49:28.400]   And all of this food part,
[00:49:28.400 --> 00:49:30.560]   it's just auxiliary to the germline.
[00:49:30.560 --> 00:49:32.960]   So you basically have layers of addition,
[00:49:32.960 --> 00:49:35.600]   of compartmentalization, of specialization,
[00:49:35.600 --> 00:49:39.360]   on top of this zine to get all the way to the earth zine.
[00:49:39.360 --> 00:49:42.480]   - Yeah, so the worm is like Windows 95,
[00:49:42.480 --> 00:49:44.320]   very few features, very basic.
[00:49:44.320 --> 00:49:47.520]   And then us humans are like Windows Vista,
[00:49:47.520 --> 00:49:48.800]   Windows 10, whatever it is.
[00:49:48.800 --> 00:49:51.520]   - Well, a few innovations beyond that.
[00:49:51.520 --> 00:49:52.480]   - Beyond that, all right.
[00:49:52.480 --> 00:49:53.840]   - Where, I don't know, Linux.
[00:49:53.840 --> 00:49:55.680]   - We're Windows 2000, at least put it that way.
[00:49:55.680 --> 00:49:56.160]   (laughing)
[00:49:56.160 --> 00:49:58.800]   - So, okay, that's such a fascinating way
[00:49:58.800 --> 00:50:01.200]   to look at life as a set of transformations.
[00:50:01.200 --> 00:50:01.920]   - Exactly.
[00:50:01.920 --> 00:50:04.800]   - So is there some interesting transformations
[00:50:04.800 --> 00:50:08.240]   to our history here on earth that appeal to you?
[00:50:08.240 --> 00:50:08.960]   - Of course.
[00:50:08.960 --> 00:50:11.360]   - And what are the most brilliant innovations
[00:50:11.360 --> 00:50:12.240]   and transformations, you could say?
[00:50:12.240 --> 00:50:13.200]   - Yeah, yeah, yeah.
[00:50:13.200 --> 00:50:15.280]   I mean, this is such a fascinating question.
[00:50:15.280 --> 00:50:16.320]   Of course, like, you know,
[00:50:16.320 --> 00:50:18.160]   we're talking about basic, basic life forms,
[00:50:18.160 --> 00:50:20.480]   and we're talking about eukaryotic life forms.
[00:50:20.480 --> 00:50:22.320]   And then the next big transformation
[00:50:22.320 --> 00:50:24.720]   is multicellular life forms,
[00:50:24.720 --> 00:50:28.240]   where the specialization separates the germline
[00:50:28.240 --> 00:50:30.400]   from everything else that accompanies it
[00:50:30.400 --> 00:50:31.920]   and sort of carries it.
[00:50:31.920 --> 00:50:34.640]   And then that specialization then sort of has
[00:50:34.640 --> 00:50:38.720]   this massive new innovation, like above the second mouth,
[00:50:38.720 --> 00:50:40.640]   which is this massive brain.
[00:50:40.640 --> 00:50:43.760]   And this massive brain is basically something
[00:50:43.760 --> 00:50:46.640]   that arises much, much later on.
[00:50:46.640 --> 00:50:48.160]   Basically, you know, notochords,
[00:50:48.160 --> 00:50:50.000]   like having the first spinal cord,
[00:50:50.000 --> 00:50:51.520]   this whole concept that,
[00:50:51.520 --> 00:50:54.240]   along with these very simple layers,
[00:50:54.240 --> 00:50:56.800]   you basically now have a coordinating agent.
[00:50:56.800 --> 00:51:00.160]   And this coordinating agent is starting to make decisions.
[00:51:00.160 --> 00:51:03.600]   And remember when we were talking about free will?
[00:51:03.600 --> 00:51:04.160]   - Mm-hmm.
[00:51:04.160 --> 00:51:07.360]   - I mean, you know, as a worm is hunting for food,
[00:51:07.360 --> 00:51:09.280]   oh, it has plenty of free will.
[00:51:09.280 --> 00:51:12.000]   It can choose to, you know, follow chemotaxis to the left
[00:51:12.000 --> 00:51:13.120]   or chemotaxis to the right.
[00:51:13.120 --> 00:51:13.440]   - Yeah.
[00:51:13.440 --> 00:51:14.640]   - And maybe that's free will,
[00:51:14.640 --> 00:51:17.520]   because it's unpredictable beyond a certain level.
[00:51:17.520 --> 00:51:23.600]   So you basically now have more and more decision-making
[00:51:23.600 --> 00:51:27.120]   and coordination of all of these different body parts
[00:51:27.120 --> 00:51:29.760]   and organs by a central operating system,
[00:51:29.760 --> 00:51:32.640]   a central machine that basically will control
[00:51:32.640 --> 00:51:34.000]   the rest of the body.
[00:51:34.000 --> 00:51:36.720]   And the other thing that I love talking about
[00:51:36.720 --> 00:51:39.040]   is the different timescales at which things happen.
[00:51:39.040 --> 00:51:40.960]   You know, we were talking about the human epigenome before.
[00:51:40.960 --> 00:51:44.080]   The human epigenome is basically able to find
[00:51:44.080 --> 00:51:47.680]   what genes should be expressed
[00:51:47.680 --> 00:51:49.760]   in response to environmental stimuli
[00:51:49.760 --> 00:51:52.400]   in the order of minutes,
[00:51:52.400 --> 00:51:54.560]   and basically receive a stimulus,
[00:51:54.560 --> 00:51:55.920]   transfer all that data
[00:51:55.920 --> 00:51:59.360]   through this humongously long string of searching,
[00:51:59.360 --> 00:52:02.800]   and then sort of find what genes to turn on,
[00:52:02.800 --> 00:52:04.320]   and then create all that.
[00:52:04.320 --> 00:52:07.040]   All of that is happening in the timescale of minutes,
[00:52:07.040 --> 00:52:09.440]   basically, you know, three minutes to half an hour.
[00:52:09.440 --> 00:52:12.320]   That's the expression response.
[00:52:12.320 --> 00:52:13.920]   But our daily life doesn't happen
[00:52:13.920 --> 00:52:15.760]   on the order of three minutes to half an hour.
[00:52:15.760 --> 00:52:17.680]   It happens on the order of milliseconds.
[00:52:17.680 --> 00:52:19.600]   Like I throw a ball at you, you catch it right away.
[00:52:19.600 --> 00:52:21.840]   No gene expression changes there.
[00:52:21.840 --> 00:52:23.120]   You just don't have time to do that.
[00:52:23.120 --> 00:52:26.800]   So you basically have a layer of control
[00:52:26.800 --> 00:52:30.800]   built on a hardware that supports it,
[00:52:30.800 --> 00:52:34.000]   but that hardware itself lives in a different timescale
[00:52:34.880 --> 00:52:36.800]   than the controlling machine on top of that.
[00:52:36.800 --> 00:52:38.320]   - Is that an accident, by the way?
[00:52:38.320 --> 00:52:39.200]   Is that like a feature?
[00:52:39.200 --> 00:52:42.000]   Was it possible for life to have evolved
[00:52:42.000 --> 00:52:46.000]   where the daily life of the organism
[00:52:46.000 --> 00:52:48.000]   as it interacts with its environment
[00:52:48.000 --> 00:52:53.280]   was on a timescale similar to the way our internals work?
[00:52:53.280 --> 00:52:55.360]   - If you look at trees,
[00:52:55.360 --> 00:52:57.760]   they look kind of boring and stupid.
[00:52:57.760 --> 00:52:59.840]   You're like looking at a tree, like stupid.
[00:52:59.840 --> 00:53:02.000]   If you speed up the movie of a tree
[00:53:02.000 --> 00:53:04.080]   from spring until October,
[00:53:04.080 --> 00:53:05.600]   you'll be like, "Oh my God, it's intelligent."
[00:53:05.600 --> 00:53:09.840]   And the reason for that is that at that timescale,
[00:53:09.840 --> 00:53:11.120]   the tree is basically saying,
[00:53:11.120 --> 00:53:14.320]   "Oh, I'm looking for a thing to catch onto.
[00:53:14.320 --> 00:53:15.440]   "Ooh, I just caught onto that.
[00:53:15.440 --> 00:53:16.400]   "I'm gonna grow more here.
[00:53:16.400 --> 00:53:18.080]   "I'm gonna spawn there," et cetera.
[00:53:18.080 --> 00:53:20.800]   Like I can see the trees in my garden just growing
[00:53:20.800 --> 00:53:22.480]   and sort of looping around.
[00:53:22.480 --> 00:53:26.400]   It's all a matter of timescale.
[00:53:26.400 --> 00:53:28.640]   And if you look at the human timescale,
[00:53:28.640 --> 00:53:30.960]   remember we were talking about neoteny
[00:53:30.960 --> 00:53:32.000]   the last time around,
[00:53:32.000 --> 00:53:35.200]   the whole fact that our young are pretty useless
[00:53:35.200 --> 00:53:38.720]   until maybe a few months of age,
[00:53:38.720 --> 00:53:39.920]   if not a few years of age,
[00:53:39.920 --> 00:53:41.520]   if not, I don't know, getting out of college.
[00:53:41.520 --> 00:53:45.840]   And then we basically hold them,
[00:53:45.840 --> 00:53:50.000]   enabling their brain to continue being malleable
[00:53:50.000 --> 00:53:53.760]   and infusing it with knowledge and thoughts
[00:53:53.760 --> 00:53:57.360]   as that period of neoteny increases and expands.
[00:53:57.360 --> 00:54:00.480]   If you fast forward, I don't know,
[00:54:00.480 --> 00:54:01.440]   another million years.
[00:54:01.440 --> 00:54:04.720]   So humans have only been around,
[00:54:04.720 --> 00:54:06.640]   different from apes for about that long.
[00:54:06.640 --> 00:54:10.240]   Jump another unit of that,
[00:54:10.240 --> 00:54:11.680]   another human-gem divergence.
[00:54:11.680 --> 00:54:13.360]   What could happen?
[00:54:13.360 --> 00:54:17.040]   From an evolutionary timescale, a lot.
[00:54:17.040 --> 00:54:19.920]   One of the things that's happening already
[00:54:19.920 --> 00:54:21.600]   is expansion of human lifespan.
[00:54:21.600 --> 00:54:25.520]   We have longer and longer periods before we mature
[00:54:25.520 --> 00:54:27.920]   and we have longer and longer periods
[00:54:27.920 --> 00:54:29.440]   before we have babies.
[00:54:29.440 --> 00:54:32.880]   So intergenerational distance is grown from,
[00:54:32.880 --> 00:54:35.200]   I don't know, 16 years to 40 years.
[00:54:35.200 --> 00:54:38.000]   - You're saying that's in the genetics.
[00:54:38.000 --> 00:54:40.400]   - No, no, not necessarily.
[00:54:40.400 --> 00:54:43.600]   But it's sort of an environmental tendency that's happening.
[00:54:43.600 --> 00:54:49.040]   But as we medically expand human lifespan,
[00:54:49.040 --> 00:54:54.240]   the generations might actually be pushed
[00:54:54.240 --> 00:54:56.880]   instead of 40 years to 60 years, to 100 years.
[00:54:56.880 --> 00:55:00.160]   - Like if we look at the long arc of the evolutionary history.
[00:55:00.160 --> 00:55:00.880]   - Exactly.
[00:55:00.880 --> 00:55:04.400]   So as we start thinking about intergalactic travel now.
[00:55:04.400 --> 00:55:06.720]   (Lex laughing)
[00:55:06.720 --> 00:55:10.080]   - Sorry, that's a heck of a transition.
[00:55:10.080 --> 00:55:12.240]   Yeah, so let's talk about intergalactic travel.
[00:55:12.240 --> 00:55:12.960]   - No, no, no, no, no.
[00:55:12.960 --> 00:55:15.760]   As we as a species start thinking about,
[00:55:15.760 --> 00:55:18.160]   I'm talking about these transitions that are happening.
[00:55:18.160 --> 00:55:19.760]   - Oh, that's awesome.
[00:55:19.760 --> 00:55:21.360]   - Continuing along these transitions,
[00:55:21.360 --> 00:55:23.600]   what does the future hold in the next million years?
[00:55:23.600 --> 00:55:26.400]   So the concept of us going to another planet,
[00:55:26.800 --> 00:55:29.600]   and that taking three human lifetimes,
[00:55:29.600 --> 00:55:31.760]   might be a joke if the human lifetime
[00:55:31.760 --> 00:55:35.440]   starts being 400 years or 800 years.
[00:55:35.440 --> 00:55:37.280]   So imagine--
[00:55:37.280 --> 00:55:38.160]   - It's all timescale.
[00:55:38.160 --> 00:55:40.160]   - It's all timescale, just different timescales.
[00:55:40.160 --> 00:55:43.520]   You asked me offline whether I would like to live forever.
[00:55:43.520 --> 00:55:46.800]   I mean, my answer is absolutely.
[00:55:46.800 --> 00:55:49.760]   And there's many different types of forevers.
[00:55:49.760 --> 00:55:55.360]   One forever is, do I want to live today forever?
[00:55:55.360 --> 00:55:56.800]   Kind of like Groundhog Day.
[00:55:56.800 --> 00:55:58.800]   And the answer is absolutely.
[00:55:58.800 --> 00:56:00.160]   The stuff that I want to learn today
[00:56:00.160 --> 00:56:03.440]   will probably take a lifetime just to learn,
[00:56:03.440 --> 00:56:05.600]   you know, basically to clear my to-do list for the day.
[00:56:05.600 --> 00:56:07.040]   - You mean like relive the day?
[00:56:07.040 --> 00:56:07.760]   - Relive the day.
[00:56:07.760 --> 00:56:09.760]   - And then pick up different things
[00:56:09.760 --> 00:56:11.440]   from the richness of the experiences
[00:56:11.440 --> 00:56:12.320]   that are all in today.
[00:56:12.320 --> 00:56:12.720]   - Exactly.
[00:56:12.720 --> 00:56:15.360]   There's just so much happening in the world every single day.
[00:56:15.360 --> 00:56:17.360]   So much knowledge that has happened already,
[00:56:17.360 --> 00:56:18.800]   that just to catch up on that
[00:56:18.800 --> 00:56:20.160]   will probably take me around forever.
[00:56:20.160 --> 00:56:23.920]   - On that point, I would just love to see you
[00:56:23.920 --> 00:56:25.760]   in the Groundhog movie, just...
[00:56:25.760 --> 00:56:29.760]   Because you're so naturally as a scientist,
[00:56:29.760 --> 00:56:32.480]   but just the way your mind works beautifully,
[00:56:32.480 --> 00:56:34.400]   just all the richness of the experiences
[00:56:34.400 --> 00:56:35.600]   that you will pick up from that.
[00:56:35.600 --> 00:56:37.920]   It's a beautiful visual.
[00:56:37.920 --> 00:56:41.040]   - I try to live each day as if it was Groundhog Day.
[00:56:41.040 --> 00:56:43.280]   I'm basically every single day waking up and saying,
[00:56:43.280 --> 00:56:45.600]   all right, how would Bill Murray get out of that one?
[00:56:45.600 --> 00:56:46.400]   - Well, you know what?
[00:56:46.400 --> 00:56:53.040]   On a funny tangent, I got a chance to go to
[00:56:53.760 --> 00:56:55.920]   Neuralink demonstration event.
[00:56:55.920 --> 00:56:57.600]   I'm not sure if you're familiar with Neuralink.
[00:56:57.600 --> 00:57:00.800]   I talked to Elon for a while,
[00:57:00.800 --> 00:57:03.920]   and one of the funny things he said
[00:57:03.920 --> 00:57:06.480]   on this Groundhog Day thing is,
[00:57:06.480 --> 00:57:10.000]   it's a beautiful dream to eventually
[00:57:10.000 --> 00:57:11.840]   be able to replay our memories.
[00:57:11.840 --> 00:57:14.320]   So we're kind of these recording machines.
[00:57:14.320 --> 00:57:17.520]   Our brain is kind of maybe a noisy
[00:57:17.520 --> 00:57:18.960]   recording machine of memories.
[00:57:18.960 --> 00:57:21.760]   And it would be beautiful if we can,
[00:57:22.800 --> 00:57:26.080]   someday in the future, maybe far into the future,
[00:57:26.080 --> 00:57:29.680]   be able to, like in the Groundhog Day situation, replay that.
[00:57:29.680 --> 00:57:31.440]   And the funny comment that stuck with me
[00:57:31.440 --> 00:57:36.240]   is he said that maybe this, our conversation now,
[00:57:36.240 --> 00:57:39.280]   is a replay of a previous memory.
[00:57:39.280 --> 00:57:41.440]   And that stuck with me because
[00:57:41.440 --> 00:57:43.840]   it would probably be my replay.
[00:57:43.840 --> 00:57:45.280]   Who the hell am I?
[00:57:45.280 --> 00:57:46.880]   I'm just some idiot guy.
[00:57:46.880 --> 00:57:52.080]   But Elon Musk is, probably because of SpaceX and so on,
[00:57:52.080 --> 00:57:54.960]   is probably going to be remembered as a special person,
[00:57:54.960 --> 00:57:58.000]   one of our special apes in history.
[00:57:58.000 --> 00:58:00.240]   So if I wanted to replay a memory,
[00:58:00.240 --> 00:58:02.560]   probably be that one, talking to Elon for a while.
[00:58:02.560 --> 00:58:03.200]   - Yeah, that's awesome.
[00:58:03.200 --> 00:58:06.960]   - And that's an interesting possibility from,
[00:58:06.960 --> 00:58:09.920]   if we think about time scales,
[00:58:09.920 --> 00:58:13.600]   if we think about the richness of the experience
[00:58:13.600 --> 00:58:17.040]   through time that we humans take,
[00:58:17.040 --> 00:58:20.560]   and be able to replay some aspects of that,
[00:58:20.560 --> 00:58:21.440]   of that biology.
[00:58:21.440 --> 00:58:22.880]   That's super interesting.
[00:58:22.880 --> 00:58:25.200]   But anyway, sorry for the tangent.
[00:58:25.200 --> 00:58:27.520]   Let's, yeah, you were talking about time scales
[00:58:27.520 --> 00:58:32.240]   and the expansion of the human lifetime
[00:58:32.240 --> 00:58:35.360]   and the idea of intergalactic travel.
[00:58:35.360 --> 00:58:37.600]   - Yeah, no, but you're laughing about it.
[00:58:37.600 --> 00:58:38.240]   It's like, I can't believe you're laughing about it.
[00:58:38.240 --> 00:58:39.040]   - Yeah, no, for sure, that is the future.
[00:58:39.040 --> 00:58:40.000]   - You're talking about this.
[00:58:40.000 --> 00:58:42.160]   You're talking about exploring alien worlds
[00:58:42.160 --> 00:58:43.280]   and going to other planets.
[00:58:43.280 --> 00:58:45.040]   I mean, you know, when Sarah was here,
[00:58:45.040 --> 00:58:47.040]   she was talking about sort of going to other planets
[00:58:47.040 --> 00:58:48.640]   when we find these life.
[00:58:48.640 --> 00:58:50.800]   I mean, I'm just very naturally,
[00:58:50.800 --> 00:58:53.520]   given the topics that we've approached,
[00:58:53.520 --> 00:58:56.480]   talking about the time scale at which this will happen.
[00:58:56.480 --> 00:58:59.920]   - So you think eventually we will, human or life,
[00:58:59.920 --> 00:59:02.880]   life will expand out into the universe.
[00:59:02.880 --> 00:59:04.960]   - The point that I'm trying to make
[00:59:04.960 --> 00:59:07.200]   is that an intergalactic species
[00:59:07.200 --> 00:59:10.960]   will probably find ways to engineer its biology
[00:59:10.960 --> 00:59:16.160]   in order to expand the way that we experience time,
[00:59:16.960 --> 00:59:19.280]   expand the time scale that we experience.
[00:59:19.280 --> 00:59:21.120]   And going back to this whole concept of,
[00:59:21.120 --> 00:59:23.120]   would I like to live forever?
[00:59:23.120 --> 00:59:25.200]   Yes, I'd like to live forever,
[00:59:25.200 --> 00:59:27.600]   even if it was stuck on the same day,
[00:59:27.600 --> 00:59:28.880]   I'd love to live forever
[00:59:28.880 --> 00:59:30.800]   because I would finally have time to do all these things
[00:59:30.800 --> 00:59:31.360]   that I wanna do.
[00:59:31.360 --> 00:59:35.680]   But if living forever actually comes with a perk
[00:59:35.680 --> 00:59:38.640]   of watching the whole world evolve forever,
[00:59:38.640 --> 00:59:41.040]   I mean, that's a huge perk.
[00:59:41.040 --> 00:59:43.440]   And I would, you know, just, it'll never get boring,
[00:59:43.440 --> 00:59:45.200]   just an ever-changing world.
[00:59:45.200 --> 00:59:47.600]   And then the mind, you know,
[00:59:47.600 --> 00:59:50.720]   sort of experiment that I want you to do
[00:59:50.720 --> 00:59:53.600]   is to also ask, what if I wanted to live forever
[00:59:53.600 --> 00:59:57.360]   one day at a time every year,
[00:59:57.360 --> 00:59:58.960]   or one day at a time every decade?
[00:59:58.960 --> 01:00:00.560]   Would you choose that?
[01:00:00.560 --> 01:00:02.400]   Where you would wake up
[01:00:02.400 --> 01:00:04.240]   and the world would be 10 years later
[01:00:04.240 --> 01:00:05.680]   every single day you wake up.
[01:00:05.680 --> 01:00:07.120]   It's the opposite of Groundhog Day,
[01:00:07.120 --> 01:00:09.280]   where basically you always wake up
[01:00:09.280 --> 01:00:10.640]   and it's always 10 years later.
[01:00:10.640 --> 01:00:14.720]   - So you're saying that's such a powerful,
[01:00:14.720 --> 01:00:18.800]   interesting concept that life is more interesting
[01:00:18.800 --> 01:00:22.480]   if you're of all the life forms on earth,
[01:00:22.480 --> 01:00:23.920]   that you're the slowest one.
[01:00:23.920 --> 01:00:25.200]   - Exactly, exactly.
[01:00:25.200 --> 01:00:26.640]   - Like trees have it right.
[01:00:26.640 --> 01:00:27.760]   - Like trees have it right.
[01:00:27.760 --> 01:00:29.440]   All of trees, like, you know,
[01:00:29.440 --> 01:00:31.360]   they've been there since the Minoan civilization.
[01:00:31.360 --> 01:00:31.920]   - Yeah.
[01:00:31.920 --> 01:00:33.200]   - And, you know, that takes us back
[01:00:33.200 --> 01:00:34.480]   to the question you asked
[01:00:34.480 --> 01:00:36.080]   about sort of the transformations
[01:00:36.080 --> 01:00:37.520]   that have happened in humanity.
[01:00:37.520 --> 01:00:39.440]   The Minoan civilization is one of them.
[01:00:39.440 --> 01:00:41.760]   You know, there's this paper that was published
[01:00:41.760 --> 01:00:43.440]   just a couple of years ago by one of my friends
[01:00:44.240 --> 01:00:49.600]   that basically looked at the genetic makeup
[01:00:49.600 --> 01:00:54.320]   of the Minoans and the Mycenaeans in ancient Greece
[01:00:54.320 --> 01:00:56.800]   and how they relate to modern Greeks.
[01:00:56.800 --> 01:00:57.760]   And they found that indeed
[01:00:57.760 --> 01:01:02.320]   there was very little gene flow from, you know, the outside.
[01:01:02.320 --> 01:01:06.960]   And, you know, it's fantastic to sort of think
[01:01:06.960 --> 01:01:08.960]   about these amazing civilizations
[01:01:08.960 --> 01:01:13.280]   that transform the way that human thought happens.
[01:01:13.280 --> 01:01:16.640]   That basically looked for rules in nature,
[01:01:16.640 --> 01:01:18.320]   that looked for principles,
[01:01:18.320 --> 01:01:21.440]   that looked for the standard of beauty,
[01:01:21.440 --> 01:01:24.800]   not human beauty, but beauty in the natural world.
[01:01:24.800 --> 01:01:28.560]   This whole concept that the world must be elegant
[01:01:28.560 --> 01:01:31.760]   and there must be deeper ways of understanding that world.
[01:01:31.760 --> 01:01:35.520]   To me, that's a massive transformation of our species,
[01:01:35.520 --> 01:01:38.880]   similar to, you know, the earlier transformation
[01:01:38.880 --> 01:01:40.800]   that we were talking about of even evolving a brain,
[01:01:42.080 --> 01:01:46.080]   of, you know, learning how to communicate language
[01:01:46.080 --> 01:01:47.760]   or the evolution of eyesight.
[01:01:47.760 --> 01:01:50.480]   If you look at sort of, you know,
[01:01:50.480 --> 01:01:52.480]   we're talking about these worms crawling around
[01:01:52.480 --> 01:01:54.080]   and then sensing which direction
[01:01:54.080 --> 01:01:56.800]   are the chemicals more abundant, you know, chemotaxis.
[01:01:56.800 --> 01:02:00.240]   So eventually they grow a nose,
[01:02:00.240 --> 01:02:02.560]   eventually they grow a, yeah, I mean, when I say nose,
[01:02:02.560 --> 01:02:04.400]   I mean ways of sensing chemicals.
[01:02:04.400 --> 01:02:06.000]   That's probably one of the earliest senses.
[01:02:06.000 --> 01:02:08.320]   You know, we always talk about how deep-rooted
[01:02:08.320 --> 01:02:09.440]   it is in your brain.
[01:02:09.440 --> 01:02:10.880]   That's one of the earliest senses.
[01:02:10.880 --> 01:02:13.120]   If you look at hearing, that's a much later sense.
[01:02:13.120 --> 01:02:15.680]   If you look at eyesight, that's an intermediate sense
[01:02:15.680 --> 01:02:17.040]   where you're basically sensing
[01:02:17.040 --> 01:02:18.880]   where the light direction comes from.
[01:02:18.880 --> 01:02:20.640]   That's probably something that life didn't need
[01:02:20.640 --> 01:02:22.880]   until he got, you know, into the surface
[01:02:22.880 --> 01:02:23.920]   and so on and so forth.
[01:02:23.920 --> 01:02:28.240]   So there's a lot of, you know, milestones.
[01:02:28.240 --> 01:02:29.760]   And I was talking about the latest milestone,
[01:02:29.760 --> 01:02:31.680]   which is LIGO last time,
[01:02:31.680 --> 01:02:34.320]   of being able to detect gravitational waves
[01:02:34.320 --> 01:02:37.280]   and sort of being able to sort of have a sense
[01:02:37.280 --> 01:02:38.880]   that humans haven't had before.
[01:02:38.880 --> 01:02:41.760]   - So you see that as a yet another transformation
[01:02:41.760 --> 01:02:43.360]   that gives us an extra little sense.
[01:02:43.360 --> 01:02:44.000]   - Of course.
[01:02:44.000 --> 01:02:46.880]   And now if you go back to this history of ancient Greece,
[01:02:46.880 --> 01:02:49.440]   I mean, this transformation that happened,
[01:02:49.440 --> 01:02:52.640]   I mean, of course, the Egyptians had this incredible,
[01:02:52.640 --> 01:02:55.360]   you know, civilization for thousands of years.
[01:02:55.360 --> 01:02:58.240]   But what happened in Greece was this whole concept of,
[01:02:58.240 --> 01:03:01.200]   let's break things down and understand the natural world.
[01:03:01.200 --> 01:03:03.200]   Let's break things down and understand physics.
[01:03:03.200 --> 01:03:05.520]   Let's basically build rules around architecture,
[01:03:06.400 --> 01:03:11.840]   around elegance, around, you know, statues and tragedy.
[01:03:11.840 --> 01:03:14.960]   I mean, another question that you asked me in passing
[01:03:14.960 --> 01:03:18.400]   was this whole concept of embracing the good and the bad,
[01:03:18.400 --> 01:03:20.720]   embracing the full range of human emotions.
[01:03:20.720 --> 01:03:23.600]   And if you look at Greek tragedy,
[01:03:23.600 --> 01:03:25.680]   it's the definition of that.
[01:03:25.680 --> 01:03:28.400]   It's, I mean, drama.
[01:03:28.400 --> 01:03:29.680]   I mean, again, it's a Greek word,
[01:03:29.680 --> 01:03:34.560]   but the whole concept of some problems
[01:03:34.560 --> 01:03:36.960]   that are just so vast and large
[01:03:36.960 --> 01:03:39.840]   that dying is the easy way out.
[01:03:39.840 --> 01:03:41.840]   (both laughing)
[01:03:41.840 --> 01:03:43.520]   That death, oh, that's the easy solution.
[01:03:43.520 --> 01:03:47.280]   You know, so I wanna touch a little bit on that point
[01:03:47.280 --> 01:03:52.000]   and sort of talk about this concept
[01:03:52.000 --> 01:03:55.600]   that life supersedes physics
[01:03:55.600 --> 01:04:00.320]   and that the brain supersedes life.
[01:04:01.520 --> 01:04:04.480]   That basically we have a brain that can decide
[01:04:04.480 --> 01:04:06.640]   to not follow evolution's path.
[01:04:06.640 --> 01:04:08.960]   We can decide to not have children.
[01:04:08.960 --> 01:04:11.200]   We can decide to not eat.
[01:04:11.200 --> 01:04:13.360]   We can decide to suicide.
[01:04:13.360 --> 01:04:17.600]   We can decide to sort of abolish communication
[01:04:17.600 --> 01:04:18.880]   with the outside world.
[01:04:18.880 --> 01:04:20.720]   I mean, all the things that make us human,
[01:04:20.720 --> 01:04:23.920]   we can basically decide not to do that.
[01:04:23.920 --> 01:04:28.640]   And that is basically when the brain itself
[01:04:28.640 --> 01:04:32.640]   is basically superseding what evolution problem is for.
[01:04:32.640 --> 01:04:33.840]   - Poof!
[01:04:33.840 --> 01:04:38.320]   So, okay, so one of the, it's, okay.
[01:04:38.320 --> 01:04:41.920]   My mind was already blown at the beautiful formulation
[01:04:41.920 --> 01:04:49.280]   of the idea that life is a system that resists physics.
[01:04:49.280 --> 01:04:50.000]   - Yeah.
[01:04:50.000 --> 01:04:53.200]   - And our brain, or perhaps the content of it,
[01:04:53.200 --> 01:04:56.000]   however it may be functionally,
[01:04:56.000 --> 01:04:59.520]   our brain is a thing that resists life.
[01:04:59.520 --> 01:05:00.800]   - Yes, yes.
[01:05:00.800 --> 01:05:05.920]   - You're so, you're so brilliant.
[01:05:05.920 --> 01:05:06.960]   (laughing)
[01:05:06.960 --> 01:05:11.280]   - But I want you to see all of that as continuum.
[01:05:11.280 --> 01:05:12.560]   Basically, you're sort of talking about
[01:05:12.560 --> 01:05:14.400]   the sort of individual transformations,
[01:05:14.400 --> 01:05:17.760]   but it's a path that humanity has been taking.
[01:05:17.760 --> 01:05:18.240]   - It's a transformation.
[01:05:18.240 --> 01:05:19.680]   - It's a path of transformation.
[01:05:19.680 --> 01:05:22.240]   And then I want us to think about
[01:05:22.240 --> 01:05:24.880]   what it truly means to become human.
[01:05:24.880 --> 01:05:26.240]   Like the F-zine.
[01:05:26.240 --> 01:05:28.640]   And you asked me about what motivated
[01:05:28.640 --> 01:05:29.920]   my Meaning of Life Symposium.
[01:05:29.920 --> 01:05:32.240]   What motivated it, in part,
[01:05:32.240 --> 01:05:35.520]   I mean, of course, it was an inside joke of turning 42,
[01:05:35.520 --> 01:05:38.960]   but what motivated it in part
[01:05:38.960 --> 01:05:40.720]   was actually a midlife crisis.
[01:05:40.720 --> 01:05:43.840]   So the joke that I always like to say
[01:05:43.840 --> 01:05:46.960]   is Christos Papadimitriou, a famous Greek professor
[01:05:46.960 --> 01:05:48.560]   who was previously at MIT, at Harvard,
[01:05:48.560 --> 01:05:49.760]   at Stanford, at Berkeley, everywhere.
[01:05:49.760 --> 01:05:53.680]   Brilliant, brilliant person, actually Costis' advisor.
[01:05:53.680 --> 01:05:54.640]   - Advisor, yeah.
[01:05:54.640 --> 01:05:57.040]   - So Christos Papadimitriou likes to say
[01:05:57.040 --> 01:05:59.040]   that when you're an undergrad,
[01:05:59.040 --> 01:06:01.520]   you work like a rat to get into grad school.
[01:06:01.520 --> 01:06:02.400]   And where you're grad student,
[01:06:02.400 --> 01:06:04.640]   you work like a rat to get your PhD.
[01:06:04.640 --> 01:06:06.880]   And where you're a postdoc, you work like a rat
[01:06:06.880 --> 01:06:08.880]   to get your assistant professor's degree.
[01:06:08.880 --> 01:06:09.840]   And where you're an assistant professor,
[01:06:09.840 --> 01:06:12.000]   you work like a rat to become a full professor.
[01:06:12.000 --> 01:06:14.320]   And then when you're a full professor,
[01:06:14.320 --> 01:06:16.880]   well, by then you're basically a rat.
[01:06:16.880 --> 01:06:19.120]   (both laughing)
[01:06:19.120 --> 01:06:19.920]   - Oh, that's brilliant.
[01:06:19.920 --> 01:06:21.680]   - So basically what happened to me
[01:06:21.680 --> 01:06:24.160]   is that I arrived at the end of the rat race.
[01:06:24.720 --> 01:06:25.360]   - Yeah.
[01:06:25.360 --> 01:06:27.120]   - You know, life is a rat race.
[01:06:27.120 --> 01:06:28.880]   You constantly have hurdles to jump over.
[01:06:28.880 --> 01:06:31.520]   You constantly have tunnels and secret pathways.
[01:06:31.520 --> 01:06:32.560]   And I figured it all out.
[01:06:32.560 --> 01:06:35.200]   And eventually, as I was turning 42,
[01:06:35.200 --> 01:06:36.480]   I looked back and I was like,
[01:06:36.480 --> 01:06:39.040]   "Wow, that was an awesome rat race,
[01:06:39.040 --> 01:06:42.240]   "but I'm not a rat."
[01:06:42.240 --> 01:06:44.400]   I basically got out of the labyrinth
[01:06:44.400 --> 01:06:46.800]   and I was like, "I'm not a rat," turns out.
[01:06:46.800 --> 01:06:47.360]   (laughs)
[01:06:47.360 --> 01:06:48.880]   - Is that the first moment where you saw
[01:06:48.880 --> 01:06:52.320]   that you were in a rat race?
[01:06:52.320 --> 01:06:54.000]   - No, no, no.
[01:06:54.000 --> 01:06:55.680]   I've known that I'm in a rat race for a long time.
[01:06:55.680 --> 01:06:57.120]   It's so easy to be in a rat race.
[01:06:57.120 --> 01:06:58.480]   It's so easy to be an undergraduate.
[01:06:58.480 --> 01:06:59.440]   You have problem sets.
[01:06:59.440 --> 01:07:00.960]   - You have problem sets.
[01:07:00.960 --> 01:07:02.320]   - We're all smart people.
[01:07:02.320 --> 01:07:03.920]   You know, problem set, it has a solution.
[01:07:03.920 --> 01:07:04.960]   Somebody made it for you.
[01:07:04.960 --> 01:07:05.840]   You can just solve it.
[01:07:05.840 --> 01:07:06.320]   - Yeah.
[01:07:06.320 --> 01:07:08.880]   - Everything was made as a test.
[01:07:08.880 --> 01:07:11.600]   And you keep passing those tests and tests and tests and tests.
[01:07:11.600 --> 01:07:13.440]   And you have tasks that are well-defined.
[01:07:13.440 --> 01:07:15.600]   The PhD is a little different
[01:07:15.600 --> 01:07:17.760]   because it's more open-ended.
[01:07:17.760 --> 01:07:19.520]   But yet you have an advisor who's guiding you.
[01:07:19.520 --> 01:07:21.440]   And then you become a professor
[01:07:22.400 --> 01:07:26.320]   and tenure is a well-set, defined set of tasks.
[01:07:26.320 --> 01:07:27.120]   And you do all that.
[01:07:27.120 --> 01:07:30.560]   And at 42, I basically had bought a house,
[01:07:30.560 --> 01:07:34.480]   three kids, beautiful wife, tenure,
[01:07:34.480 --> 01:07:38.160]   awesome students, tons of grants.
[01:07:38.160 --> 01:07:40.480]   Life was basically laid out for me.
[01:07:40.480 --> 01:07:41.040]   - Yeah.
[01:07:41.040 --> 01:07:43.520]   - And that's when I had my limited mean life crisis.
[01:07:43.520 --> 01:07:45.600]   That's when people usually buy a Harley Davidson.
[01:07:45.600 --> 01:07:47.520]   (laughs)
[01:07:47.520 --> 01:07:49.360]   And they basically say, "Oh, I need something new.
[01:07:49.360 --> 01:07:51.760]   "I need something different and to be young myself," et cetera.
[01:07:51.760 --> 01:07:53.360]   But basically that was my realization
[01:07:53.360 --> 01:07:56.640]   that it's not a rat race, that there's no rat race.
[01:07:56.640 --> 01:07:57.200]   It's over.
[01:07:57.200 --> 01:08:01.360]   That I have to basically think,
[01:08:01.360 --> 01:08:03.760]   how do I fully instantiate myself?
[01:08:03.760 --> 01:08:06.000]   How do I complete my transformation
[01:08:06.000 --> 01:08:07.200]   into an actual human being?
[01:08:07.200 --> 01:08:10.640]   Because it's very easy to sort of forget
[01:08:10.640 --> 01:08:12.000]   all the intangibles of life.
[01:08:12.000 --> 01:08:15.440]   It's very hard to just sort of think about the next task
[01:08:15.440 --> 01:08:16.880]   and the next task and it's all metrics.
[01:08:16.880 --> 01:08:18.480]   And what is the number of viewers I have?
[01:08:18.480 --> 01:08:20.240]   What is the number of publications I have?
[01:08:20.240 --> 01:08:21.440]   What is the number of citations,
[01:08:21.440 --> 01:08:23.120]   the number of talks, the number of grants?
[01:08:23.120 --> 01:08:24.560]   It's very easy to quantify everything.
[01:08:24.560 --> 01:08:26.400]   And then at some point you're like,
[01:08:26.400 --> 01:08:28.720]   "This is real life.
[01:08:28.720 --> 01:08:30.160]   "It's not a test anymore."
[01:08:30.160 --> 01:08:32.320]   And that's something that I told my wife early on.
[01:08:32.320 --> 01:08:35.200]   I was like, "No, no, no.
[01:08:35.200 --> 01:08:36.160]   "Our life is not gonna be,
[01:08:36.160 --> 01:08:37.440]   "'Let's put the kids through college.'"
[01:08:37.440 --> 01:08:40.480]   And maybe that's when I escaped the rat race.
[01:08:40.480 --> 01:08:42.160]   Maybe it continued being a rat race.
[01:08:42.160 --> 01:08:43.520]   Maybe the next step would have been,
[01:08:43.520 --> 01:08:44.560]   "All right, how do I make sure
[01:08:44.560 --> 01:08:45.920]   "that my kid is first in class?
[01:08:45.920 --> 01:08:47.360]   "How do I make sure that they're
[01:08:47.360 --> 01:08:48.800]   "into the greatest college?"
[01:08:48.800 --> 01:08:50.400]   And then they're into college
[01:08:50.400 --> 01:08:53.360]   and then you're like 60.
[01:08:53.360 --> 01:08:54.720]   (laughs)
[01:08:54.720 --> 01:08:57.120]   - So how do you escape?
[01:08:57.120 --> 01:09:01.920]   Is there a light at the end of the tunnel
[01:09:01.920 --> 01:09:03.040]   of a midlife crisis?
[01:09:03.040 --> 01:09:06.480]   - So you should watch that symposium
[01:09:06.480 --> 01:09:10.640]   because the videos were transformative to me
[01:09:10.640 --> 01:09:11.520]   and to many others.
[01:09:11.520 --> 01:09:15.120]   So basically the advice that I received
[01:09:15.120 --> 01:09:17.760]   from all of my friends was so meaningful.
[01:09:17.760 --> 01:09:21.200]   There's some advice that basically says
[01:09:21.200 --> 01:09:26.640]   you have to constantly maintain unachievable goals.
[01:09:26.640 --> 01:09:30.160]   Goals that you can make progress towards
[01:09:30.160 --> 01:09:31.840]   but you can never be fully done with.
[01:09:31.840 --> 01:09:33.920]   And I think that's almost playing
[01:09:33.920 --> 01:09:35.520]   into the sort of rat race thing.
[01:09:35.520 --> 01:09:37.200]   Like basically make sure that there's more obstacles
[01:09:37.200 --> 01:09:40.480]   for your little rat persona to jump through.
[01:09:40.480 --> 01:09:42.640]   So that's one possibility.
[01:09:42.640 --> 01:09:45.040]   - So first of all, watch.
[01:09:45.040 --> 01:09:46.240]   Is it available somewhere?
[01:09:46.240 --> 01:09:46.800]   - It's on YouTube.
[01:09:46.800 --> 01:09:48.080]   Just Google-- - What?
[01:09:48.080 --> 01:09:49.360]   - Google Meaning of Life Symposium.
[01:09:49.360 --> 01:09:50.160]   - I should have known this.
[01:09:50.160 --> 01:09:51.600]   I mean you should have told me this.
[01:09:51.600 --> 01:09:52.480]   This is awesome.
[01:09:52.480 --> 01:09:53.680]   Okay, this is great.
[01:09:53.680 --> 01:09:58.080]   And also like seeing rat race is,
[01:09:58.080 --> 01:10:01.440]   if we look at Ratatouille,
[01:10:01.440 --> 01:10:06.640]   I mean that's a beautiful thing
[01:10:06.640 --> 01:10:09.360]   of challenges and overcoming challenges.
[01:10:09.360 --> 01:10:13.440]   That could be fundamentally the meaning of life
[01:10:13.440 --> 01:10:18.400]   is to see life as a set of challenges
[01:10:18.400 --> 01:10:23.280]   and to fully engage in the overcoming of those challenges.
[01:10:23.280 --> 01:10:26.320]   - I would say that that's embracing the rat race view of life.
[01:10:26.320 --> 01:10:29.680]   So a joke that we like to have with my wife all the time
[01:10:29.680 --> 01:10:31.680]   is we basically say,
[01:10:31.680 --> 01:10:34.960]   we pretend that we're in this all-inclusive resort
[01:10:34.960 --> 01:10:37.600]   that we've basically hired all these people
[01:10:37.600 --> 01:10:39.520]   to go on the Esplanade and play games
[01:10:39.520 --> 01:10:41.920]   'cause we enjoy watching people playing on the Esplanade
[01:10:41.920 --> 01:10:44.480]   and we enjoy sort of laying and looking at life
[01:10:44.480 --> 01:10:46.640]   and all the people biking and rollerblading and all of that.
[01:10:46.640 --> 01:10:49.120]   And then we've paid all these people
[01:10:49.120 --> 01:10:51.760]   in this all-inclusive resort that we live in.
[01:10:51.760 --> 01:10:53.760]   And then what are we gonna do today?
[01:10:53.760 --> 01:10:56.320]   I'm like, oh, I've signed up for professor activities.
[01:10:56.320 --> 01:10:57.520]   It's gonna be awesome.
[01:10:57.520 --> 01:10:59.920]   They lined up a bunch of super smart MIT students
[01:10:59.920 --> 01:11:00.960]   for me to meet with.
[01:11:00.960 --> 01:11:03.040]   I'm gonna have a grant writing meeting afterwards.
[01:11:03.040 --> 01:11:04.320]   It's gonna be awesome.
[01:11:04.320 --> 01:11:06.640]   And then she signed up for a bunch of consulting activities.
[01:11:06.640 --> 01:11:07.520]   It's gonna be great.
[01:11:07.520 --> 01:11:09.360]   And then in the evening, we just get back together and say,
[01:11:09.360 --> 01:11:11.520]   hey, how was your consulting today?
[01:11:11.520 --> 01:11:16.080]   So in a way, that's another view of life of basically,
[01:11:16.080 --> 01:11:18.560]   wait a minute, if I was a gazillionaire,
[01:11:18.560 --> 01:11:19.600]   what would I choose to do?
[01:11:19.600 --> 01:11:22.640]   I would probably pay an awesome university
[01:11:22.640 --> 01:11:23.920]   to give me an office there
[01:11:23.920 --> 01:11:27.360]   and just pay a bunch of super smart people to work with me
[01:11:27.360 --> 01:11:31.840]   even though they don't really want to, et cetera, et cetera.
[01:11:31.840 --> 01:11:34.560]   In fact, I would have exactly the life that I have now
[01:11:34.560 --> 01:11:36.960]   working my butt off every single day
[01:11:36.960 --> 01:11:40.720]   because it's so freaking fulfilling.
[01:11:40.720 --> 01:11:44.000]   - Well, that's, so let's clarify.
[01:11:44.000 --> 01:11:44.800]   It's just a beautiful way.
[01:11:44.800 --> 01:11:46.960]   It's almost like a video game view of life
[01:11:46.960 --> 01:11:49.440]   that is a set of, I mean, again,
[01:11:49.440 --> 01:11:51.520]   game is not perhaps a positive term,
[01:11:51.520 --> 01:11:53.600]   but it is a beautiful term.
[01:11:53.600 --> 01:11:59.840]   So do you or do you not like the rat race view of life?
[01:11:59.840 --> 01:12:01.120]   - No.
[01:12:01.120 --> 01:12:03.360]   - Because it is fulfilling in some--
[01:12:03.360 --> 01:12:05.280]   - The rat race is about the goal.
[01:12:05.280 --> 01:12:07.520]   My view of life is about the path.
[01:12:07.520 --> 01:12:10.320]   So again, quoting Greece.
[01:12:10.320 --> 01:12:12.240]   (laughing)
[01:12:12.240 --> 01:12:14.000]   - Those folks have come up with some good stuff.
[01:12:14.000 --> 01:12:19.440]   - So this Odysseus Elitis basically wrote this beautiful poem
[01:12:19.440 --> 01:12:23.040]   about sort of going through life saying,
[01:12:23.040 --> 01:12:25.440]   as you go through your journey,
[01:12:25.440 --> 01:12:28.800]   impersonating Ulysses of his voyage,
[01:12:29.600 --> 01:12:33.440]   he says, "Wish that the path is long and arduous."
[01:12:33.440 --> 01:12:37.280]   Because when you get to Ithaca,
[01:12:37.280 --> 01:12:42.080]   you might realize that it was all about the path,
[01:12:42.080 --> 01:12:42.960]   not the destination.
[01:12:42.960 --> 01:12:48.400]   So the rat race view of life
[01:12:48.400 --> 01:12:49.680]   makes it all about the destination.
[01:12:49.680 --> 01:12:52.240]   It's like, how do I get through the maze to get there?
[01:12:52.240 --> 01:12:56.720]   But the all-inclusive resort view of life
[01:12:56.720 --> 01:12:58.400]   is about the path.
[01:12:59.120 --> 01:13:02.960]   It's about, wow, today I couldn't wish
[01:13:02.960 --> 01:13:05.760]   for a better set of activities all programmed for me
[01:13:05.760 --> 01:13:09.600]   to enjoy having my brain, having my body,
[01:13:09.600 --> 01:13:14.160]   having my senses and the life that I have.
[01:13:14.160 --> 01:13:15.600]   So it's a very different kind of view.
[01:13:15.600 --> 01:13:18.160]   It's focused on the journey, not on the destination.
[01:13:18.160 --> 01:13:22.320]   - So you mentioned kind of the ups and downs of life
[01:13:22.320 --> 01:13:24.480]   and the midlife crisis.
[01:13:24.480 --> 01:13:28.560]   And right now you said focusing kind of on the journey.
[01:13:29.440 --> 01:13:32.800]   But what the journey involves is ups and downs.
[01:13:32.800 --> 01:13:39.280]   Is there advice or any kind of thoughts
[01:13:39.280 --> 01:13:43.760]   that you can elucidate about the downs in your life?
[01:13:43.760 --> 01:13:48.560]   The hard parts of your life and how you got out
[01:13:48.560 --> 01:13:51.120]   or maybe not, or is there,
[01:13:51.120 --> 01:13:54.720]   how do you see the dark parts of life?
[01:13:54.720 --> 01:13:57.040]   - Yeah, so I'm so glad you're asking this question
[01:13:57.040 --> 01:13:59.520]   because it's something that our society
[01:13:59.520 --> 01:14:01.920]   does a terrible job at preparing us for.
[01:14:01.920 --> 01:14:05.600]   Every Hollywood movie has to have a happy ending.
[01:14:05.600 --> 01:14:07.280]   It is ridiculous.
[01:14:07.280 --> 01:14:09.040]   You can count on your 10 fingers
[01:14:09.040 --> 01:14:12.160]   the number of bad ending movies that you've ever watched.
[01:14:12.160 --> 01:14:14.720]   And you probably wouldn't need all 10 fingers.
[01:14:14.720 --> 01:14:20.640]   We strive to tell everyone, yes, you can succeed.
[01:14:20.640 --> 01:14:25.360]   Yes, you're a millionaire, just temporarily disabled.
[01:14:26.240 --> 01:14:32.720]   And yes, the prince will eventually figure out his princess
[01:14:32.720 --> 01:14:36.320]   and they will have a happily ever after ending.
[01:14:36.320 --> 01:14:39.280]   And yes, the hero will be beaten and beaten and beaten.
[01:14:39.280 --> 01:14:40.960]   But you know that at the end of the movie,
[01:14:40.960 --> 01:14:41.840]   the good guys will win.
[01:14:41.840 --> 01:14:44.560]   We need more movies where the bad guys win.
[01:14:44.560 --> 01:14:46.400]   We need more movies where just everybody dies.
[01:14:46.400 --> 01:14:47.920]   (laughs)
[01:14:47.920 --> 01:14:50.240]   Where just, MacGyver doesn't figure out
[01:14:50.240 --> 01:14:52.080]   how to disable the bomb and just explodes.
[01:14:52.080 --> 01:14:55.920]   You just need more movies that are more realistic
[01:14:55.920 --> 01:14:58.480]   about the fact that life kind of sucks sometimes
[01:14:58.480 --> 01:14:59.120]   and it's okay.
[01:14:59.120 --> 01:15:02.000]   So again, growing up in Greece,
[01:15:02.000 --> 01:15:08.640]   I have been exposed to songs that are not just sad,
[01:15:08.640 --> 01:15:10.480]   but they're miserable.
[01:15:10.480 --> 01:15:11.600]   (laughs)
[01:15:11.600 --> 01:15:12.320]   Miserable.
[01:15:12.320 --> 01:15:13.280]   (laughs)
[01:15:13.280 --> 01:15:15.600]   So one of them comes to mind.
[01:15:15.600 --> 01:15:17.280]   (laughs)
[01:15:17.280 --> 01:15:20.800]   And it's basically talking about this woman
[01:15:20.800 --> 01:15:24.800]   who's lamenting in the early morning
[01:15:24.800 --> 01:15:28.960]   about losing the joyful kid, the joyful young man,
[01:15:28.960 --> 01:15:32.560]   who basically died in the civil war
[01:15:32.560 --> 01:15:37.360]   in the arms of our own fellow citizens.
[01:15:37.360 --> 01:15:41.760]   And she's like, if only he had died
[01:15:41.760 --> 01:15:43.520]   fighting the foreign forces,
[01:15:43.520 --> 01:15:49.280]   if only he had died at the sides of the general,
[01:15:49.280 --> 01:15:51.920]   if only he had died with honor,
[01:15:52.480 --> 01:15:56.400]   I would be proud to have lost the joyful kid.
[01:15:56.400 --> 01:15:58.480]   I mean, it's devastating, right?
[01:15:58.480 --> 01:16:00.640]   It's like, he didn't just die,
[01:16:00.640 --> 01:16:03.200]   he died without honor.
[01:16:03.200 --> 01:16:07.600]   And my friend who was with me was listening to the song
[01:16:07.600 --> 01:16:08.880]   and she's like, this is depressing.
[01:16:08.880 --> 01:16:09.760]   I'm like, whoa, whoa, whoa,
[01:16:09.760 --> 01:16:10.960]   you have to listen to another one.
[01:16:10.960 --> 01:16:12.080]   It's not as sad.
[01:16:12.080 --> 01:16:13.920]   And she's like, what, this one died with honor?
[01:16:13.920 --> 01:16:15.520]   (laughs)
[01:16:15.520 --> 01:16:17.360]   So that's one example.
[01:16:17.360 --> 01:16:20.560]   - It's a kind of a celebration of misery.
[01:16:20.560 --> 01:16:22.240]   - No, no, no, no, no, no, no.
[01:16:22.240 --> 01:16:23.840]   So let me give you a couple more examples
[01:16:23.840 --> 01:16:25.200]   and then I'll answer that question.
[01:16:25.200 --> 01:16:28.240]   So another example is I picked up this book
[01:16:28.240 --> 01:16:29.520]   that I had from my childhood
[01:16:29.520 --> 01:16:32.000]   and I started reading stories to my kids.
[01:16:32.000 --> 01:16:35.200]   And the first story is about these two children.
[01:16:35.200 --> 01:16:37.040]   One is really poor living on the street
[01:16:37.040 --> 01:16:38.560]   and the other one is really rich,
[01:16:38.560 --> 01:16:40.640]   living in the house in the bright light above.
[01:16:40.640 --> 01:16:42.000]   And the poor one is wishing,
[01:16:42.000 --> 01:16:43.520]   looking at that window and wishing
[01:16:43.520 --> 01:16:44.960]   that he could have that house.
[01:16:44.960 --> 01:16:47.280]   And the other one is at the window,
[01:16:47.280 --> 01:16:48.240]   wishing that he was free,
[01:16:48.240 --> 01:16:49.360]   that he wasn't sick all the time,
[01:16:49.360 --> 01:16:50.640]   that he could escape outside.
[01:16:51.520 --> 01:16:52.800]   It's only four pages long.
[01:16:52.800 --> 01:16:54.640]   And at the end, both children die.
[01:16:54.640 --> 01:16:57.040]   One of them dies from cold,
[01:16:57.040 --> 01:16:58.320]   the other one dies from illness.
[01:16:58.320 --> 01:17:01.920]   And you're like, how is that even a children's story?
[01:17:01.920 --> 01:17:04.560]   The next story, I'm like, okay, that's fine.
[01:17:04.560 --> 01:17:05.760]   Let's skip this one.
[01:17:05.760 --> 01:17:08.240]   So I read this to my kids and then I read the next one.
[01:17:08.240 --> 01:17:10.880]   And the next one is about this woman
[01:17:10.880 --> 01:17:14.560]   whose brother is at war against the Turks
[01:17:14.560 --> 01:17:18.880]   and he is gonna die.
[01:17:19.760 --> 01:17:21.760]   And she prays to the Virgin,
[01:17:21.760 --> 01:17:23.120]   please don't let him die.
[01:17:23.120 --> 01:17:24.320]   And the Virgin appears and she's like,
[01:17:24.320 --> 01:17:27.280]   no problem, tell me who to kill instead.
[01:17:27.280 --> 01:17:31.360]   And she's like, anyone, anyone.
[01:17:31.360 --> 01:17:33.040]   No, no, no, no, choose one.
[01:17:33.040 --> 01:17:33.920]   How about this Turk?
[01:17:33.920 --> 01:17:36.480]   This one has two kids,
[01:17:36.480 --> 01:17:38.320]   a beautiful family waiting for him at home.
[01:17:38.320 --> 01:17:40.560]   She's like, no, not this one, choose another one.
[01:17:40.560 --> 01:17:43.920]   And then she goes through all the life stories of the others.
[01:17:43.920 --> 01:17:46.480]   And she's like, no, no, just don't take anyone.
[01:17:46.480 --> 01:17:47.920]   She's like, I can't do that.
[01:17:47.920 --> 01:17:50.560]   I can't, you can choose to bring your brother back
[01:17:50.560 --> 01:17:52.640]   and he will be depressed for the rest of his life
[01:17:52.640 --> 01:17:54.560]   because he didn't fight at war,
[01:17:54.560 --> 01:17:56.240]   because he didn't go to that battle
[01:17:56.240 --> 01:17:58.000]   and he will live without honor.
[01:17:58.000 --> 01:17:59.520]   She's like, and in the end,
[01:17:59.520 --> 01:18:02.480]   the woman decides to have her brother killed instead
[01:18:02.480 --> 01:18:05.760]   'cause he dies without, I mean, this is insane.
[01:18:05.760 --> 01:18:07.680]   So why am I giving you these examples?
[01:18:07.680 --> 01:18:09.360]   It's not a glorification of misery.
[01:18:09.360 --> 01:18:13.680]   It's expanding your emotional range.
[01:18:13.680 --> 01:18:16.720]   It's teaching you that,
[01:18:17.280 --> 01:18:20.160]   and when I read these stories, I'm not a jerk.
[01:18:20.160 --> 01:18:21.440]   I'm crying out loud.
[01:18:21.440 --> 01:18:25.280]   I have tears and like my face becomes red
[01:18:25.280 --> 01:18:30.480]   from the pain that I'm experiencing through these stories.
[01:18:30.480 --> 01:18:37.920]   It's just so deeply touching to embrace the suffering
[01:18:37.920 --> 01:18:43.040]   not because of an accident, but because of a choice.
[01:18:44.240 --> 01:18:48.000]   The sacrifice to embrace the fact that
[01:18:48.000 --> 01:18:50.640]   not everything is cute and rosy and always ending well.
[01:18:50.640 --> 01:18:53.760]   And I think that we don't do a good enough job
[01:18:53.760 --> 01:18:56.640]   of teaching our kids that just life sucks
[01:18:56.640 --> 01:19:00.400]   and life is unfair sometimes and that's okay.
[01:19:00.400 --> 01:19:02.400]   And sometimes I read a story to my kids.
[01:19:02.400 --> 01:19:03.600]   I read a story every night
[01:19:03.600 --> 01:19:06.960]   and sometimes the story is horrible
[01:19:06.960 --> 01:19:09.440]   and sometimes the story is good
[01:19:09.440 --> 01:19:11.280]   and sort of friendly and happy.
[01:19:11.280 --> 01:19:14.720]   And my kids always ask, what's the moral of the story?
[01:19:14.720 --> 01:19:16.480]   And sometimes there's a moral and it's like,
[01:19:16.480 --> 01:19:18.240]   oh, you should be good or you should be nice.
[01:19:18.240 --> 01:19:20.000]   You should be helping each other, et cetera.
[01:19:20.000 --> 01:19:21.360]   And sometimes there's just no moral.
[01:19:21.360 --> 01:19:24.800]   And I tell my kids, you know what?
[01:19:24.800 --> 01:19:27.120]   Sometimes just life doesn't make sense and it's okay.
[01:19:27.120 --> 01:19:29.120]   And you can't comprehend everything.
[01:19:29.120 --> 01:19:33.600]   And I think this concept of how do you deal with bad days
[01:19:33.600 --> 01:19:35.440]   comes from the fact that we're taught,
[01:19:35.440 --> 01:19:36.880]   we're brainwashed into thinking
[01:19:36.880 --> 01:19:38.240]   that every day should be a happy day.
[01:19:39.440 --> 01:19:42.160]   And we're not ready to cope with misery.
[01:19:42.160 --> 01:19:46.960]   And the other thing that crying through these stories
[01:19:46.960 --> 01:19:50.720]   teaches you is that you don't have it
[01:19:50.720 --> 01:19:52.240]   nearly half as bad as you think.
[01:19:52.240 --> 01:19:55.920]   Do you see what I mean?
[01:19:55.920 --> 01:19:58.800]   Basically, it tells you that, I mean,
[01:19:58.800 --> 01:20:00.640]   my mom would always tell me about
[01:20:00.640 --> 01:20:02.560]   how she was transformed as a teenager
[01:20:02.560 --> 01:20:05.200]   when she volunteered in the hospital
[01:20:05.200 --> 01:20:08.560]   and she saw all these people at the brink of death
[01:20:08.560 --> 01:20:12.080]   clinging for life and helping them out to best she could
[01:20:12.080 --> 01:20:16.320]   and crying her heart out when they were dying.
[01:20:16.320 --> 01:20:19.200]   And just sort of how that taught her
[01:20:19.200 --> 01:20:21.840]   the appreciation for what we have every day.
[01:20:21.840 --> 01:20:24.640]   Waking up every morning and saying,
[01:20:24.640 --> 01:20:27.280]   my life doesn't suck.
[01:20:27.280 --> 01:20:32.480]   My life is not nearly half as bad as it could be.
[01:20:32.480 --> 01:20:38.080]   And sort of embracing the joy that we have
[01:20:38.880 --> 01:20:41.600]   of living where we live in the moment we live.
[01:20:41.600 --> 01:20:42.640]   And I'm going to go further.
[01:20:42.640 --> 01:20:48.560]   If you look at the arc of human life,
[01:20:48.560 --> 01:20:52.000]   you know, human existence through the centuries,
[01:20:52.000 --> 01:20:53.840]   there's no better way to be alive than now.
[01:20:53.840 --> 01:20:57.760]   I mean, we're complaining about every single little thing,
[01:20:57.760 --> 01:21:00.240]   but life expectancy is at an all-time high.
[01:21:00.240 --> 01:21:02.480]   Sickness, all-time low.
[01:21:02.480 --> 01:21:05.680]   Poorness, misery, all-time low.
[01:21:06.640 --> 01:21:09.600]   There's no better time to be alive globally
[01:21:09.600 --> 01:21:12.560]   across all of human existence, number one.
[01:21:12.560 --> 01:21:14.720]   Number two, here in Boston,
[01:21:14.720 --> 01:21:16.240]   there's no better place to be alive.
[01:21:16.240 --> 01:21:21.280]   If you think about the amalgamation of science,
[01:21:21.280 --> 01:21:23.200]   engineering, technology,
[01:21:23.200 --> 01:21:25.280]   the ridiculously awesome people you're bringing
[01:21:25.280 --> 01:21:26.800]   every week to your podcast,
[01:21:26.800 --> 01:21:30.400]   I mean, this is the ancient Greece of modern society.
[01:21:30.400 --> 01:21:32.240]   - But the weather still sucks.
[01:21:32.240 --> 01:21:32.800]   (Lex laughing)
[01:21:32.800 --> 01:21:35.360]   - No, let me put it this way.
[01:21:35.360 --> 01:21:38.160]   The weather gives us a range of emotion.
[01:21:38.160 --> 01:21:39.360]   (Lex laughing)
[01:21:39.360 --> 01:21:42.000]   The full range of human weather patterns.
[01:21:42.000 --> 01:21:42.160]   - The full scenic range.
[01:21:42.160 --> 01:21:44.720]   There's such a fascinating thing about human psychology.
[01:21:44.720 --> 01:21:46.240]   I often reread this book.
[01:21:46.240 --> 01:21:47.760]   I'm not sure if you're familiar with it.
[01:21:47.760 --> 01:21:50.480]   It's "Man's Search for Meaning" by Viktor Frankl.
[01:21:50.480 --> 01:21:56.240]   And he talks about, you know,
[01:21:56.240 --> 01:22:00.000]   his living through the Holocaust
[01:22:00.000 --> 01:22:01.520]   and the concentration camps.
[01:22:02.160 --> 01:22:05.920]   And even there, where there's like human misery
[01:22:05.920 --> 01:22:08.160]   is at its highest,
[01:22:08.160 --> 01:22:14.240]   even there he discovers these moments
[01:22:14.240 --> 01:22:15.920]   by observing the suffering,
[01:22:15.920 --> 01:22:17.600]   by accepting the suffering.
[01:22:17.600 --> 01:22:22.720]   He observes moments of true joy
[01:22:22.720 --> 01:22:25.440]   of how great his life is
[01:22:25.440 --> 01:22:31.280]   relative to others at the camp who have it worse.
[01:22:31.280 --> 01:22:31.760]   - Yeah.
[01:22:31.760 --> 01:22:32.080]   - Yeah.
[01:22:32.080 --> 01:22:35.760]   So it's a dangerous slippery slope to think that way
[01:22:35.760 --> 01:22:38.400]   because it's basically being better than the Joneses.
[01:22:38.400 --> 01:22:41.920]   And if, you know, if the house next door has a giant car,
[01:22:41.920 --> 01:22:44.000]   then you want to get a bigger car or something like that.
[01:22:44.000 --> 01:22:46.000]   It's not comparative misery.
[01:22:46.000 --> 01:22:49.200]   I think the way that I see it is slightly different.
[01:22:49.200 --> 01:22:53.200]   It's, and it's not even thinking
[01:22:53.200 --> 01:22:55.360]   about all the worst possible outcomes
[01:22:55.360 --> 01:22:57.040]   that could have happened, but didn't.
[01:22:57.040 --> 01:23:00.480]   The example, as you were talking
[01:23:00.480 --> 01:23:02.880]   about the concentration camps, the most horrible,
[01:23:02.880 --> 01:23:04.880]   I mean, one of the most horrible moments of human existence,
[01:23:04.880 --> 01:23:07.680]   I was thinking about pictures that I was seeing
[01:23:07.680 --> 01:23:10.880]   of kids in Syria, in war-torn zones.
[01:23:10.880 --> 01:23:12.800]   And you're looking at these kids.
[01:23:12.800 --> 01:23:15.760]   And again, I cried out loud,
[01:23:15.760 --> 01:23:20.320]   imagining my own son in the van
[01:23:20.320 --> 01:23:23.680]   after a bomb explosion,
[01:23:23.680 --> 01:23:26.320]   watching his, you know, father die
[01:23:26.320 --> 01:23:29.280]   or his siblings die or losing his friends.
[01:23:29.920 --> 01:23:33.600]   It's something that we are not capable of fathoming.
[01:23:33.600 --> 01:23:36.720]   But if you actually put a seven-year-old
[01:23:36.720 --> 01:23:39.600]   in that situation, the look that I saw
[01:23:39.600 --> 01:23:43.360]   in these kids' eyes basically said, it is what it is.
[01:23:43.360 --> 01:23:48.320]   It was, and I've experienced that with my own kid.
[01:23:48.320 --> 01:23:52.080]   When he gets, like, my three-year-old last,
[01:23:52.080 --> 01:23:54.400]   like two years ago, who's now my five-year-old,
[01:23:54.400 --> 01:23:57.360]   she was burned really badly
[01:23:57.360 --> 01:23:59.120]   with like hot chocolate and coffee
[01:23:59.120 --> 01:24:01.120]   that just peeled off her skin.
[01:24:01.120 --> 01:24:03.200]   So you could actually see just her fragile skin
[01:24:03.200 --> 01:24:04.160]   had just peeled off.
[01:24:04.160 --> 01:24:08.320]   And she was the happiest little kid.
[01:24:08.320 --> 01:24:11.520]   She was just going along with the punches.
[01:24:11.520 --> 01:24:12.240]   - It is what it is.
[01:24:12.240 --> 01:24:13.040]   - It is what it is.
[01:24:13.040 --> 01:24:13.920]   - She accepted it.
[01:24:13.920 --> 01:24:18.480]   - So it's quite dramatic to sort of realize
[01:24:18.480 --> 01:24:24.320]   that children don't say, "Oh, I could have it better."
[01:24:25.280 --> 01:24:30.240]   They sort of embrace the moment, not embrace,
[01:24:30.240 --> 01:24:31.680]   but sort of accept the moment.
[01:24:31.680 --> 01:24:35.920]   And then they can have moments of pure joy
[01:24:35.920 --> 01:24:39.600]   in a horrendous war-torn country.
[01:24:39.600 --> 01:24:42.240]   And, you know, like so many people
[01:24:42.240 --> 01:24:45.680]   from these war-torn countries basically say,
[01:24:45.680 --> 01:24:48.640]   "Oh, you think you Americans are gonna just come
[01:24:48.640 --> 01:24:51.440]   and just send us a bunch of aid and food, et cetera?
[01:24:51.440 --> 01:24:53.840]   Yeah, sure, that's helpful.
[01:24:54.400 --> 01:24:56.000]   But what do we dream of?
[01:24:56.000 --> 01:24:57.280]   What do we struggle for?
[01:24:57.280 --> 01:24:58.720]   We struggle for love.
[01:24:58.720 --> 01:25:00.320]   We struggle for meaning.
[01:25:00.320 --> 01:25:04.400]   We struggle for, you know, emotions and friendships.
[01:25:04.400 --> 01:25:06.400]   We struggle for the same things you guys struggle for.
[01:25:06.400 --> 01:25:08.960]   We're not just like every day waking up and saying,
[01:25:08.960 --> 01:25:10.320]   "Oh, I wish I had more food."
[01:25:10.320 --> 01:25:11.840]   No, that's just the given.
[01:25:11.840 --> 01:25:13.040]   I just don't have enough food.
[01:25:13.040 --> 01:25:16.800]   But what we struggle with are basically everything else.
[01:25:16.800 --> 01:25:20.160]   And that sort of gives you some perspective on life.
[01:25:20.160 --> 01:25:21.920]   It basically says, you know,
[01:25:21.920 --> 01:25:24.560]   and another story that my mom told me when I was a kid
[01:25:24.560 --> 01:25:27.520]   is this story about sort of this man who's basically,
[01:25:27.520 --> 01:25:31.360]   you know, he sees the Christ appear in front of him.
[01:25:31.360 --> 01:25:35.600]   And he says, "Oh, Christ, I'm carrying all these problems.
[01:25:35.600 --> 01:25:36.800]   I'm carrying this big bag.
[01:25:36.800 --> 01:25:38.800]   Can you please take it from me?"
[01:25:38.800 --> 01:25:39.520]   And he's like, "Sure.
[01:25:39.520 --> 01:25:41.600]   Let me just give you any other bag."
[01:25:41.600 --> 01:25:43.680]   (Lex laughing)
[01:25:43.680 --> 01:25:47.760]   And basically, and of course the person in the end
[01:25:47.760 --> 01:25:48.640]   accepts his own bag.
[01:25:48.640 --> 01:25:50.800]   - So acceptance ultimately.
[01:25:50.800 --> 01:25:52.720]   - Basically every single-- - The path you recommend
[01:25:52.720 --> 01:25:53.440]   is acceptance.
[01:25:53.440 --> 01:25:56.240]   - Every single other bag is probably worse.
[01:25:56.240 --> 01:25:59.120]   It's the evil you don't know versus the evil you know.
[01:25:59.120 --> 01:26:00.880]   Like we all struggle with our own problems.
[01:26:00.880 --> 01:26:03.440]   But if you look at the bigger picture,
[01:26:03.440 --> 01:26:06.400]   it's just your path through life.
[01:26:06.400 --> 01:26:09.040]   And if you embrace it, the good and the bad,
[01:26:09.040 --> 01:26:15.280]   every single day, it's just joy, elation,
[01:26:15.280 --> 01:26:19.120]   sadness, misery.
[01:26:19.920 --> 01:26:23.120]   If you don't have both, you're not a complete human being.
[01:26:23.120 --> 01:26:25.120]   You know, you can't, I mean,
[01:26:25.120 --> 01:26:27.920]   the last example I'm gonna give is the movie
[01:26:27.920 --> 01:26:30.560]   "Inside Out" by Pixar.
[01:26:30.560 --> 01:26:32.400]   Beautiful movie.
[01:26:32.400 --> 01:26:33.120]   - Which one is that?
[01:26:33.120 --> 01:26:35.120]   - The one with the little characters controlling--
[01:26:35.120 --> 01:26:36.320]   - Oh, the emotions. - Highly framed.
[01:26:36.320 --> 01:26:37.360]   - Oh, it's a great movie. - Yeah.
[01:26:37.360 --> 01:26:40.320]   So you basically have joy and sadness and fear
[01:26:40.320 --> 01:26:42.080]   and disgust, et cetera.
[01:26:42.080 --> 01:26:45.280]   And the moral of the story, if you remember the movie,
[01:26:45.280 --> 01:26:47.440]   the moral of the story is that in the end,
[01:26:48.400 --> 01:26:50.080]   joy is basically trying to fix everything,
[01:26:50.080 --> 01:26:51.440]   to make everything happy.
[01:26:51.440 --> 01:26:53.760]   And she's failing miserably and everything else
[01:26:53.760 --> 01:26:55.840]   is like crumbling and falling apart.
[01:26:55.840 --> 01:26:58.240]   And the little girl basically becomes emotionless
[01:26:58.240 --> 01:27:00.640]   because all she knows how to do is fake happiness.
[01:27:00.640 --> 01:27:02.960]   And I think it's a very good analogy
[01:27:02.960 --> 01:27:04.880]   for our everyday society,
[01:27:04.880 --> 01:27:06.640]   where we're always saying, "Are you happy?
[01:27:06.640 --> 01:27:07.440]   "Are you happy?"
[01:27:07.440 --> 01:27:08.800]   My mama calls me and she's like,
[01:27:08.800 --> 01:27:09.600]   "Manolis, are you happy?"
[01:27:09.600 --> 01:27:12.480]   I'm like, "Mom, stop asking this stupid question.
[01:27:12.480 --> 01:27:14.000]   "No, I'm not happy.
[01:27:14.000 --> 01:27:15.920]   "What you should be asking is if I'm fulfilled."
[01:27:15.920 --> 01:27:16.560]   - Yeah.
[01:27:16.560 --> 01:27:17.840]   - And that's a very different thing.
[01:27:17.840 --> 01:27:19.120]   I don't go around being happy.
[01:27:19.120 --> 01:27:23.600]   - I would love it if your mom called and said,
[01:27:23.600 --> 01:27:25.600]   "Manolis, are you suffering beautifully?"
[01:27:25.600 --> 01:27:26.160]   or something like that.
[01:27:26.160 --> 01:27:27.120]   - That's exactly right.
[01:27:27.120 --> 01:27:28.240]   That's what she should be asking.
[01:27:28.240 --> 01:27:29.840]   (laughing)
[01:27:29.840 --> 01:27:33.040]   Are you struggling to achieve something great?
[01:27:33.040 --> 01:27:33.600]   - Yeah.
[01:27:33.600 --> 01:27:35.120]   - That's the question that mom should be asking.
[01:27:35.120 --> 01:27:36.160]   - Hear that mom?
[01:27:36.160 --> 01:27:37.360]   Call me about the suffering,
[01:27:37.360 --> 01:27:39.920]   not about how good are you doing?
[01:27:39.920 --> 01:27:41.920]   - So what I tell her is that life
[01:27:41.920 --> 01:27:43.920]   is not about maximizing happiness.
[01:27:43.920 --> 01:27:46.640]   Life is about accomplishing something meaningful
[01:27:47.280 --> 01:27:48.880]   and accomplishing that meaningful thing
[01:27:48.880 --> 01:27:52.000]   cannot come from a series of joyful moments.
[01:27:52.000 --> 01:27:54.400]   It comes from a series of struggles,
[01:27:54.400 --> 01:27:58.240]   of successes and failures,
[01:27:58.240 --> 01:28:00.160]   of people being nasty to you
[01:28:00.160 --> 01:28:01.760]   and people being nice to you
[01:28:01.760 --> 01:28:03.440]   and embracing the full thing.
[01:28:03.440 --> 01:28:07.440]   And if you supersede that constant need for gratification,
[01:28:07.440 --> 01:28:11.120]   if you supersede that constant need for kindness,
[01:28:11.120 --> 01:28:15.040]   you suddenly know who you are.
[01:28:16.240 --> 01:28:17.520]   And what I like to say to my kid,
[01:28:17.520 --> 01:28:19.040]   and my son the other day was telling me,
[01:28:19.040 --> 01:28:20.480]   "Oh, so-and-so called me such and such."
[01:28:20.480 --> 01:28:22.240]   And I'm like, "Are you such and such?"
[01:28:22.240 --> 01:28:23.040]   He's like, "No."
[01:28:23.040 --> 01:28:24.800]   I'm like, "Ha-ha, see, they were wrong."
[01:28:24.800 --> 01:28:25.840]   (laughing)
[01:28:25.840 --> 01:28:28.400]   And what I tell him is if you know who you are,
[01:28:28.400 --> 01:28:30.880]   what other people say about you
[01:28:30.880 --> 01:28:32.880]   only teaches you about them.
[01:28:32.880 --> 01:28:35.440]   - Yeah.
[01:28:35.440 --> 01:28:40.240]   - So it has no influence on your self-esteem.
[01:28:40.240 --> 01:28:42.480]   If you know where you stand,
[01:28:42.480 --> 01:28:44.640]   you embrace the good, but you also embrace the bad.
[01:28:45.200 --> 01:28:47.920]   I have plenty of bad and I'm embracing it.
[01:28:47.920 --> 01:28:49.600]   I'm a procrastinator.
[01:28:49.600 --> 01:28:52.160]   How do I deal with that?
[01:28:52.160 --> 01:28:54.880]   I trick myself into procrastinating
[01:28:54.880 --> 01:28:57.760]   about mindless, stupid little day-to-day things.
[01:28:57.760 --> 01:29:00.000]   And in that procrastination time,
[01:29:00.000 --> 01:29:01.280]   doing important things for the future.
[01:29:01.280 --> 01:29:03.000]   (laughing)
[01:29:03.000 --> 01:29:04.400]   - So accepting who you are.
[01:29:04.400 --> 01:29:05.600]   - Accepting your flaws.
[01:29:05.600 --> 01:29:06.880]   - Accepting the whole of it.
[01:29:06.880 --> 01:29:08.880]   - Accepting the struggle,
[01:29:08.880 --> 01:29:10.720]   accepting the sleeplessness,
[01:29:10.720 --> 01:29:14.720]   accepting the fact that the journey is what matters.
[01:29:15.440 --> 01:29:19.280]   Hoping that your path to Ithaca is full of troubles
[01:29:19.280 --> 01:29:21.840]   because those troubles are the life you will lead.
[01:29:21.840 --> 01:29:25.440]   Accepting that life will not start
[01:29:25.440 --> 01:29:28.080]   after the next milestone,
[01:29:28.080 --> 01:29:30.160]   that life has already started a long time ago.
[01:29:30.160 --> 01:29:34.000]   And what you're experiencing now is the life.
[01:29:34.000 --> 01:29:35.600]   This is it.
[01:29:35.600 --> 01:29:36.800]   It's not some kind of future thing
[01:29:36.800 --> 01:29:38.560]   that you work yourself hard to get to.
[01:29:38.560 --> 01:29:41.920]   And then after that, you live happily ever after.
[01:29:41.920 --> 01:29:44.160]   To me, the happily ever after,
[01:29:44.160 --> 01:29:45.120]   that's the end of the story.
[01:29:45.120 --> 01:29:46.240]   Nothing happens after that.
[01:29:46.240 --> 01:29:49.360]   The struggle and the struggle and the struggle
[01:29:49.360 --> 01:29:50.880]   is much more interesting story
[01:29:50.880 --> 01:29:54.080]   than the lived happily ever after.
[01:29:54.080 --> 01:29:57.120]   So I think we have to embrace that as a society
[01:29:57.120 --> 01:29:59.840]   that it's not just about the happy ending,
[01:29:59.840 --> 01:30:03.520]   that our kids are brainwashed into expecting
[01:30:03.520 --> 01:30:05.120]   that things will be happy and rosy
[01:30:05.120 --> 01:30:07.440]   and it's okay if they're not.
[01:30:07.440 --> 01:30:08.640]   And they should keep struggling
[01:30:08.640 --> 01:30:11.040]   because the struggle is the journey
[01:30:11.040 --> 01:30:13.200]   and the journey is the meaning of life.
[01:30:14.160 --> 01:30:15.920]   It's not the end, it's the journey.
[01:30:15.920 --> 01:30:20.160]   - What about accepting one of the harder things?
[01:30:20.160 --> 01:30:22.080]   We talked a little bit about immortality.
[01:30:22.080 --> 01:30:26.080]   What about accepting that life ends?
[01:30:26.080 --> 01:30:31.200]   So do you, Manolis, think about your own mortality?
[01:30:31.200 --> 01:30:34.800]   How, we talked about accepting
[01:30:34.800 --> 01:30:37.120]   that there's ups and downs to life.
[01:30:37.120 --> 01:30:38.480]   What about the ultimate down,
[01:30:38.480 --> 01:30:40.160]   which is the finality of it?
[01:30:40.160 --> 01:30:41.440]   Do you think about that?
[01:30:41.440 --> 01:30:42.240]   Do you fear it?
[01:30:42.240 --> 01:30:47.440]   - You also asked me if I'm afraid of getting older.
[01:30:47.440 --> 01:30:48.400]   - Yes.
[01:30:48.400 --> 01:30:51.040]   - And that's on the path to mortality.
[01:30:51.040 --> 01:30:52.960]   So let me talk about that first step
[01:30:52.960 --> 01:30:53.840]   and then the last step.
[01:30:53.840 --> 01:30:55.200]   - The last step.
[01:30:55.200 --> 01:30:56.320]   - Literally the last step.
[01:30:56.320 --> 01:31:00.080]   So getting older, what does that mean?
[01:31:00.080 --> 01:31:03.200]   When I was 18, when I was 20,
[01:31:03.200 --> 01:31:06.400]   my brain, I felt was at my maximum.
[01:31:06.400 --> 01:31:08.720]   I was like, nothing is impossible.
[01:31:08.720 --> 01:31:10.640]   I can solve anything.
[01:31:10.640 --> 01:31:13.440]   I could take any math puzzle, any logic puzzle,
[01:31:13.440 --> 01:31:16.240]   any programming puzzle and just solve it in milliseconds.
[01:31:16.240 --> 01:31:18.160]   I just saw the answer through problems.
[01:31:18.160 --> 01:31:19.920]   I was like feeling invincible.
[01:31:19.920 --> 01:31:22.880]   I would show up at lecture with my newspaper,
[01:31:22.880 --> 01:31:24.080]   lift up my head every now and then,
[01:31:24.080 --> 01:31:27.680]   point to errors, just brat, complete brat.
[01:31:27.680 --> 01:31:29.360]   I would raise my hand and correct my professors
[01:31:29.360 --> 01:31:31.520]   from the whole classroom, total brat.
[01:31:31.520 --> 01:31:33.440]   I have some of those in my class now and it's awesome.
[01:31:33.440 --> 01:31:34.160]   It's like very--
[01:31:34.160 --> 01:31:35.440]   - I used to be you.
[01:31:35.440 --> 01:31:36.720]   - It teaches you humility.
[01:31:36.720 --> 01:31:37.040]   - Yeah.
[01:31:37.920 --> 01:31:42.880]   - So I felt invincible and I was like, this is it.
[01:31:42.880 --> 01:31:43.520]   This is awesome.
[01:31:43.520 --> 01:31:44.240]   I'm living the life.
[01:31:44.240 --> 01:31:48.240]   10 years later, my brain didn't work the same way.
[01:31:48.240 --> 01:31:51.760]   I wasn't as good at the tiny little puzzles
[01:31:51.760 --> 01:31:54.800]   but it worked in different ways.
[01:31:54.800 --> 01:31:57.280]   And right now, 20 years later,
[01:31:57.280 --> 01:31:59.040]   it works in yet different ways.
[01:31:59.040 --> 01:32:02.640]   And oh gosh, I love the journey.
[01:32:02.640 --> 01:32:05.200]   - Can you maybe give some hints
[01:32:06.000 --> 01:32:08.000]   of the interesting different ways
[01:32:08.000 --> 01:32:10.240]   that your brain works as it aged?
[01:32:10.240 --> 01:32:14.400]   - Yeah, I went from the phase of sheer speed
[01:32:14.400 --> 01:32:17.840]   and hardcore quantitative thinking
[01:32:17.840 --> 01:32:20.400]   to sort of stepping back,
[01:32:20.400 --> 01:32:22.240]   being able to sort of make more connections,
[01:32:22.240 --> 01:32:24.480]   being able to sort of say, yeah,
[01:32:24.480 --> 01:32:25.520]   but let's use that thing.
[01:32:25.520 --> 01:32:29.600]   Sort of a huge new creativity being unleashed.
[01:32:29.600 --> 01:32:30.560]   Basically when you're young,
[01:32:30.560 --> 01:32:32.640]   you're sort of thinking about that one problem.
[01:32:32.640 --> 01:32:34.320]   You can sort of reconfigure all the variables
[01:32:34.320 --> 01:32:35.600]   combinatorially in your head
[01:32:35.600 --> 01:32:37.680]   and just wipe it all out.
[01:32:37.680 --> 01:32:40.000]   When you're just a little older,
[01:32:40.000 --> 01:32:41.280]   you start getting more creative.
[01:32:41.280 --> 01:32:43.680]   You start bringing in things from different fields
[01:32:43.680 --> 01:32:45.360]   and different contexts
[01:32:45.360 --> 01:32:47.360]   and sort of stepping outside the box.
[01:32:47.360 --> 01:32:48.880]   Basically it's like being in the rat race
[01:32:48.880 --> 01:32:50.640]   and saying, there's a ceiling.
[01:32:50.640 --> 01:32:52.320]   Why are we trying to get through that?
[01:32:52.320 --> 01:32:54.800]   So it's sort of thinking outside the box.
[01:32:54.800 --> 01:32:58.960]   And then at 40, what I'm going through now
[01:32:58.960 --> 01:33:01.680]   is this whole sort of embracing the path of life.
[01:33:01.680 --> 01:33:04.960]   And when I say life has started already,
[01:33:04.960 --> 01:33:06.160]   it's not a test anymore,
[01:33:06.160 --> 01:33:09.600]   this is basically embracing the finality.
[01:33:09.600 --> 01:33:14.400]   Embracing that the journey is what it's at.
[01:33:14.400 --> 01:33:18.480]   So what I like to say is live every day
[01:33:18.480 --> 01:33:20.160]   as if it's your last one
[01:33:20.160 --> 01:33:23.200]   and make plans as if you'll never die.
[01:33:23.200 --> 01:33:26.560]   I always have the long-term
[01:33:26.560 --> 01:33:29.920]   that I'm sort of planning out for
[01:33:29.920 --> 01:33:31.840]   that will eventually become the short-term.
[01:33:31.840 --> 01:33:33.520]   And I always have the sort of short-term
[01:33:34.880 --> 01:33:37.440]   and I think this ability to sort of look at life
[01:33:37.440 --> 01:33:41.600]   in the past and look at life in the future jointly
[01:33:41.600 --> 01:33:44.000]   and sort of embrace the continuity
[01:33:44.000 --> 01:33:47.120]   both of life in the universe and on our planet
[01:33:47.120 --> 01:33:49.120]   as well as life as a human being
[01:33:49.120 --> 01:33:50.400]   from the beginning to the end,
[01:33:50.400 --> 01:33:52.160]   just as a path, as a journey
[01:33:52.160 --> 01:33:55.200]   and just embracing every aspect of that.
[01:33:55.200 --> 01:33:57.120]   I mean, I was talking about parenthood the other day
[01:33:57.120 --> 01:33:59.440]   and how amazingly fulfilling it is
[01:33:59.440 --> 01:34:04.480]   to sort of relive childhood through the eyes of my kids
[01:34:04.480 --> 01:34:06.800]   but with the perspective of a parent.
[01:34:06.800 --> 01:34:12.000]   So the sheer, you know,
[01:34:12.000 --> 01:34:16.000]   arrogance of youth.
[01:34:16.000 --> 01:34:19.360]   Watching this in my kid,
[01:34:19.360 --> 01:34:22.400]   I can see myself when I was 18 correcting my professor.
[01:34:22.400 --> 01:34:23.120]   I felt so proud.
[01:34:23.120 --> 01:34:26.480]   Little did I know that my professor was working
[01:34:26.480 --> 01:34:27.920]   on so much more interesting things
[01:34:27.920 --> 01:34:28.960]   than the three little things
[01:34:28.960 --> 01:34:30.640]   he was putting on the board that day.
[01:34:30.640 --> 01:34:32.320]   And I was like, "Ah, I'm invincible."
[01:34:32.880 --> 01:34:34.480]   But in fact, no, just a little brat.
[01:34:34.480 --> 01:34:36.720]   And basically right now,
[01:34:36.720 --> 01:34:41.920]   I sort of can see the sort of journey
[01:34:41.920 --> 01:34:43.120]   with a little more humility.
[01:34:43.120 --> 01:34:46.560]   I can sort of look at my own students
[01:34:46.560 --> 01:34:48.960]   with their unbelievable abilities,
[01:34:48.960 --> 01:34:51.840]   being able to do things that I'm no longer able to do,
[01:34:51.840 --> 01:34:54.560]   better than I probably was ever able to do,
[01:34:54.560 --> 01:34:57.280]   but yet being able to guide them
[01:34:57.280 --> 01:35:00.240]   and shape their thinking and blow their minds
[01:35:00.240 --> 01:35:02.080]   with new ideas and new directions.
[01:35:02.880 --> 01:35:03.920]   Through my perspective.
[01:35:03.920 --> 01:35:07.040]   And I know when something is solvable
[01:35:07.040 --> 01:35:08.320]   because I've been there,
[01:35:08.320 --> 01:35:09.920]   but I'm not gonna even bother.
[01:35:09.920 --> 01:35:11.280]   It's not that I can't do it.
[01:35:11.280 --> 01:35:12.800]   I'm sure I could if I tried,
[01:35:12.800 --> 01:35:14.880]   I just, I'm not interested in that anymore.
[01:35:14.880 --> 01:35:18.080]   So what I'm embracing this journey of aging
[01:35:18.080 --> 01:35:19.920]   is how my brain is changing
[01:35:19.920 --> 01:35:23.920]   and how I'm constantly trying to figure out the niches,
[01:35:23.920 --> 01:35:26.240]   the evolutionary niches that I'm best adapted for.
[01:35:26.240 --> 01:35:27.840]   - Yeah.
[01:35:27.840 --> 01:35:30.320]   - For the tasks that I'm best at,
[01:35:30.880 --> 01:35:33.440]   while hiring and recruiting
[01:35:33.440 --> 01:35:36.880]   both assistants and research scientists
[01:35:36.880 --> 01:35:38.640]   and students and postdocs,
[01:35:38.640 --> 01:35:41.920]   and that will be the best at those tasks.
[01:35:41.920 --> 01:35:44.880]   But someone still has to see the big picture.
[01:35:44.880 --> 01:35:46.960]   And I love being in that role.
[01:35:46.960 --> 01:35:51.280]   - So you're at the timescale of a human lifespan,
[01:35:51.280 --> 01:35:53.120]   you're doing the same thing that the worm
[01:35:53.120 --> 01:35:57.280]   did at the evolutionary timescale of growing arms,
[01:35:57.280 --> 01:35:58.640]   of the specialization,
[01:35:58.640 --> 01:36:02.400]   the compartmentalization he talks about.
[01:36:02.400 --> 01:36:03.600]   I mean, it's fascinating to think
[01:36:03.600 --> 01:36:07.280]   of what 80 year old Manolis would look back
[01:36:07.280 --> 01:36:10.240]   at the man that's sitting here today
[01:36:10.240 --> 01:36:14.160]   and laugh at the silliness, at the arrogance.
[01:36:14.160 --> 01:36:15.520]   - I think he finally figured out something.
[01:36:15.520 --> 01:36:16.880]   (laughing)
[01:36:16.880 --> 01:36:18.480]   I was like, no little thing,
[01:36:18.480 --> 01:36:20.720]   you didn't figure out anything.
[01:36:20.720 --> 01:36:22.400]   - I mean, ultimately it seems
[01:36:22.400 --> 01:36:24.480]   that if you're introspective about life,
[01:36:24.480 --> 01:36:27.760]   it all, it leads to a kind of acceptance
[01:36:27.760 --> 01:36:33.120]   a deeper and deeper acceptance of the whole of it.
[01:36:33.120 --> 01:36:36.400]   - Again, I wanna be cautious about acceptance
[01:36:36.400 --> 01:36:38.560]   because it almost says that you can't change it.
[01:36:38.560 --> 01:36:39.440]   - Ah, yeah.
[01:36:39.440 --> 01:36:42.480]   - It's sort of embracing the struggle
[01:36:42.480 --> 01:36:43.920]   and embracing the journey,
[01:36:43.920 --> 01:36:45.040]   is the way that I would put it.
[01:36:45.040 --> 01:36:46.960]   - So you ultimately feel the journey
[01:36:46.960 --> 01:36:48.640]   isn't just something that happens to you.
[01:36:48.640 --> 01:36:51.520]   - Of course, you shape it, you shape it.
[01:36:51.520 --> 01:36:53.680]   Remember how I was saying that Boston is the best place
[01:36:53.680 --> 01:36:55.280]   and the best time to live in right now,
[01:36:55.280 --> 01:36:56.720]   you know, in the history of humanity.
[01:36:56.720 --> 01:36:57.200]   (laughing)
[01:36:57.200 --> 01:36:59.040]   I'm exaggerating a little bit,
[01:36:59.040 --> 01:37:01.760]   but the way that I think about this is that,
[01:37:01.760 --> 01:37:05.280]   if you look at the whole of cosmos,
[01:37:05.280 --> 01:37:07.200]   where would you rather be?
[01:37:07.200 --> 01:37:08.960]   If you're just a bunch of molecules,
[01:37:08.960 --> 01:37:11.200]   roughly your, you know, biomass,
[01:37:11.200 --> 01:37:12.000]   where would you rather be?
[01:37:12.000 --> 01:37:13.600]   Would you rather be a rock on Mars?
[01:37:13.600 --> 01:37:14.800]   Eh, probably not.
[01:37:14.800 --> 01:37:16.480]   Would you rather be in a black hole?
[01:37:16.480 --> 01:37:17.120]   Probably not.
[01:37:17.120 --> 01:37:19.440]   Would you rather be in a exploding supernova?
[01:37:19.440 --> 01:37:20.640]   Maybe, that might be interesting.
[01:37:20.640 --> 01:37:24.960]   But being on earth is an awesome solar system,
[01:37:25.520 --> 01:37:26.800]   an awesome planetary system,
[01:37:26.800 --> 01:37:29.680]   an awesome, you know, place to be in.
[01:37:29.680 --> 01:37:31.200]   Across all of space time,
[01:37:31.200 --> 01:37:34.080]   it's a pretty good place to be in as a bunch of molecules.
[01:37:34.080 --> 01:37:36.800]   If you are a bunch of molecules on earth today,
[01:37:36.800 --> 01:37:40.640]   being an animal with, you know,
[01:37:40.640 --> 01:37:44.560]   some kind of awareness of the stuff around you is wonderful.
[01:37:44.560 --> 01:37:48.160]   Being a human among all animals is amazing
[01:37:48.160 --> 01:37:49.680]   because you have all this introspection.
[01:37:49.680 --> 01:37:54.640]   And being a human who's young, fit, athletic,
[01:37:54.640 --> 01:37:56.960]   smart, et cetera, I mean, you know,
[01:37:56.960 --> 01:37:58.800]   you have so much to be happy for.
[01:37:58.800 --> 01:38:04.240]   Beyond that, being surrounded by a bunch of awesome people
[01:38:04.240 --> 01:38:05.920]   that you interact with all the time.
[01:38:05.920 --> 01:38:08.480]   I mean, I feel blessed to interact with the people I know,
[01:38:08.480 --> 01:38:10.400]   with the friends I have, the dinners that I have,
[01:38:10.400 --> 01:38:12.640]   all of this, the students that I interact with.
[01:38:12.640 --> 01:38:13.440]   I'm so blessed.
[01:38:13.440 --> 01:38:18.880]   And the last little blip in this awesomeness of local maximum,
[01:38:18.880 --> 01:38:21.520]   the last little blip comes from being kind,
[01:38:22.800 --> 01:38:24.800]   being grateful and being kind.
[01:38:24.800 --> 01:38:26.800]   I don't know if you remember that little prayer
[01:38:26.800 --> 01:38:29.200]   that I described last time of,
[01:38:29.200 --> 01:38:32.000]   "Thank you for all the good you've given me
[01:38:32.000 --> 01:38:35.040]   and give me strength to give unto others
[01:38:35.040 --> 01:38:37.920]   with the same love that you've given to me."
[01:38:37.920 --> 01:38:42.480]   And the whole point of that is being grateful and being kind.
[01:38:42.480 --> 01:38:43.200]   What does that do?
[01:38:43.200 --> 01:38:46.720]   From a purely egoistic perspective,
[01:38:46.720 --> 01:38:48.960]   it makes the people around you happier
[01:38:48.960 --> 01:38:52.640]   and it takes that little maximum a little bit further.
[01:38:53.440 --> 01:38:57.120]   Because you'll be surrounded by happy people by being kind.
[01:38:57.120 --> 01:38:58.720]   That's the purely egoistic view.
[01:38:58.720 --> 01:39:00.960]   And the purely altruistic view,
[01:39:00.960 --> 01:39:03.040]   or maybe it's egoistic as well,
[01:39:03.040 --> 01:39:05.440]   is that it's just good to give.
[01:39:05.440 --> 01:39:06.800]   It feels good to give.
[01:39:06.800 --> 01:39:11.120]   Like basically watching somebody who's touched by what you said,
[01:39:11.120 --> 01:39:15.360]   watching somebody who's like appreciating a rapid response
[01:39:15.360 --> 01:39:19.280]   or a generous offer or just random acts of kindness
[01:39:19.280 --> 01:39:20.720]   is so fulfilling.
[01:39:21.360 --> 01:39:24.960]   So evolutionarily, we were selected for that.
[01:39:24.960 --> 01:39:27.200]   There's just such a good feeling that comes from that.
[01:39:27.200 --> 01:39:29.600]   - You know, it's fascinating to think
[01:39:29.600 --> 01:39:31.440]   you said Boston is the best place
[01:39:31.440 --> 01:39:33.760]   and talking about kindness,
[01:39:33.760 --> 01:39:38.000]   that the very thought that Boston is the best place
[01:39:38.000 --> 01:39:40.560]   in the universe is almost,
[01:39:40.560 --> 01:39:44.320]   it's a kind of a gravitational field.
[01:39:44.320 --> 01:39:50.480]   Your thought and your very life in itself
[01:39:50.480 --> 01:39:52.480]   is a kind of field that makes that real.
[01:39:52.480 --> 01:39:55.280]   - Yeah, it's a self-fulfilling prophecy.
[01:39:55.280 --> 01:39:59.280]   By claiming it's the best and thinking it's the best,
[01:39:59.280 --> 01:40:00.160]   it becomes the best.
[01:40:00.160 --> 01:40:01.200]   - And you make others,
[01:40:01.200 --> 01:40:06.480]   it's not a force that just applies to your own cognition.
[01:40:06.480 --> 01:40:07.040]   - Exactly.
[01:40:07.040 --> 01:40:09.120]   - It applies to the others around you.
[01:40:09.120 --> 01:40:11.040]   - And then suddenly you live in an even better place.
[01:40:11.040 --> 01:40:13.440]   - Yeah, and it creates the reality,
[01:40:13.440 --> 01:40:16.640]   the actual reality, the social reality.
[01:40:16.640 --> 01:40:16.960]   - Exactly.
[01:40:16.960 --> 01:40:18.800]   - Then it molds the environment.
[01:40:18.800 --> 01:40:19.360]   - Exactly.
[01:40:20.000 --> 01:40:22.000]   By the way, one of the coolest things about you,
[01:40:22.000 --> 01:40:30.960]   I think, is you represent the best of MIT,
[01:40:30.960 --> 01:40:32.400]   like the spirit of MIT.
[01:40:32.400 --> 01:40:38.000]   So I'm so glad that I'm fortunate enough
[01:40:38.000 --> 01:40:39.040]   to be able to talk to you
[01:40:39.040 --> 01:40:46.960]   because there's a kind of cynicism about academia in parts
[01:40:48.160 --> 01:40:50.480]   that I think is undeserved
[01:40:50.480 --> 01:40:54.160]   and that there's this, you know, MIT, of course,
[01:40:54.160 --> 01:40:59.440]   but academic institutions is a sacred place
[01:40:59.440 --> 01:41:01.440]   where ideas can flourish
[01:41:01.440 --> 01:41:03.920]   just in the same very way that you're talking about,
[01:41:03.920 --> 01:41:09.040]   is both kindness and curiosity
[01:41:09.040 --> 01:41:11.440]   and that weird thing that happens
[01:41:11.440 --> 01:41:15.360]   when a bunch of curious descendants of apes get together
[01:41:15.360 --> 01:41:21.040]   and just like get excited in this ripple effect that happens.
[01:41:21.040 --> 01:41:23.760]   I mean, that's the most beautiful aspect of MIT.
[01:41:23.760 --> 01:41:27.680]   People might think like competition and grants
[01:41:27.680 --> 01:41:32.400]   and like position, like you said, the rat race,
[01:41:32.400 --> 01:41:36.960]   but like underneath it all is these curious human beings,
[01:41:36.960 --> 01:41:39.280]   inspiring younger human beings,
[01:41:39.280 --> 01:41:42.240]   and there's this ripple effect that happens.
[01:41:42.240 --> 01:41:47.280]   I'm so glad that, I mean, I'm glad that I get a chance
[01:41:47.280 --> 01:41:50.960]   to record this because it inspires so many other students
[01:41:50.960 --> 01:41:53.920]   and so many other people to do the same,
[01:41:53.920 --> 01:41:56.720]   to embrace the inner curious creature
[01:41:56.720 --> 01:41:58.080]   that's not about the race.
[01:41:58.080 --> 01:41:59.520]   - So let's talk about the negative.
[01:41:59.520 --> 01:42:01.600]   Let's talk about, no, no, no, I'm serious, I'm serious.
[01:42:01.600 --> 01:42:03.760]   You know, you have to embrace the good and the bad.
[01:42:03.760 --> 01:42:04.880]   So let's talk about the negative.
[01:42:04.880 --> 01:42:05.840]   - As the Greek comes out.
[01:42:05.840 --> 01:42:06.960]   - Let's address it.
[01:42:06.960 --> 01:42:10.640]   So why do people want positions of power?
[01:42:11.360 --> 01:42:14.720]   Why do people want more money, more power,
[01:42:14.720 --> 01:42:15.440]   more this, more that?
[01:42:15.440 --> 01:42:17.600]   Remember the part where I was saying,
[01:42:17.600 --> 01:42:20.560]   if you know who you are, what other people think about you,
[01:42:20.560 --> 01:42:22.800]   it makes no difference to you.
[01:42:22.800 --> 01:42:24.080]   It only teaches you about them.
[01:42:24.080 --> 01:42:31.280]   Many people feel defined themselves.
[01:42:31.280 --> 01:42:34.480]   They feel instantiated through the eyes of others.
[01:42:34.480 --> 01:42:38.400]   So being in a position of power
[01:42:38.400 --> 01:42:40.160]   makes them feel better about themselves.
[01:42:41.120 --> 01:42:43.520]   Who knows what other kind of struggles they might have
[01:42:43.520 --> 01:42:47.520]   that creates that need to feel better about themselves.
[01:42:47.520 --> 01:42:48.800]   But they have a bunch of struggles
[01:42:48.800 --> 01:42:50.080]   and everybody has a bunch of struggles.
[01:42:50.080 --> 01:42:53.360]   And every time I see somebody behaving poorly,
[01:42:53.360 --> 01:42:55.520]   I'm basically thinking,
[01:42:55.520 --> 01:42:59.840]   well, they're in a tough spot right now and it's okay.
[01:42:59.840 --> 01:43:03.440]   I can kind of see how I would behave badly
[01:43:03.440 --> 01:43:04.720]   in other circumstances as well.
[01:43:04.720 --> 01:43:10.400]   So I think if you take away that sort of,
[01:43:11.040 --> 01:43:13.920]   having to prove yourself in the eyes of others,
[01:43:13.920 --> 01:43:16.800]   life becomes so much easier.
[01:43:16.800 --> 01:43:19.760]   So when I first became a professor at MIT,
[01:43:19.760 --> 01:43:22.800]   I started wearing adult clothes.
[01:43:22.800 --> 01:43:23.360]   (laughing)
[01:43:23.360 --> 01:43:25.840]   I had my like, I mean, before-
[01:43:25.840 --> 01:43:27.440]   - You became a serious person, Cor.
[01:43:27.440 --> 01:43:30.400]   - I basically had, I would always go around
[01:43:30.400 --> 01:43:32.160]   in my roller blades and my shorts and a t-shirt.
[01:43:32.160 --> 01:43:33.520]   And eventually I was a professional, like,
[01:43:33.520 --> 01:43:36.400]   oh, I bought all these khaki pants
[01:43:36.400 --> 01:43:40.480]   and these nice shirts with like,
[01:43:40.480 --> 01:43:42.720]   whatever they call it, the patterns.
[01:43:42.720 --> 01:43:45.200]   And I was like, dressing with my nice belt every day,
[01:43:45.200 --> 01:43:45.760]   showing up.
[01:43:45.760 --> 01:43:48.880]   And then a few months later, I was like,
[01:43:48.880 --> 01:43:51.040]   I can't stand it.
[01:43:51.040 --> 01:43:52.880]   And I just went back to my roller blades
[01:43:52.880 --> 01:43:55.840]   and my t-shirts and my shorts.
[01:43:55.840 --> 01:43:58.640]   And it was this struggle of sort of
[01:43:58.640 --> 01:44:00.240]   not feeling that I fit in.
[01:44:00.240 --> 01:44:03.280]   I was so intimidated by all of my colleagues,
[01:44:03.280 --> 01:44:05.520]   like just watching their incredible achievements,
[01:44:05.520 --> 01:44:07.680]   like persons next to me and the person,
[01:44:07.680 --> 01:44:09.120]   you know, the floor below me.
[01:44:09.120 --> 01:44:10.960]   I was like, oh my God, like,
[01:44:10.960 --> 01:44:13.600]   they clearly made a mistake.
[01:44:13.600 --> 01:44:15.200]   What the heck am I doing here?
[01:44:15.200 --> 01:44:19.760]   How will I ever live up to these people's standards?
[01:44:19.760 --> 01:44:26.080]   And eventually you grow up to realize that
[01:44:26.080 --> 01:44:29.600]   the way that, I grew up to realize that
[01:44:29.600 --> 01:44:31.600]   the way that other people perceived my work
[01:44:31.600 --> 01:44:33.520]   was very similar to the way that
[01:44:33.520 --> 01:44:35.120]   I perceived other people's work.
[01:44:35.120 --> 01:44:35.840]   As flawless.
[01:44:35.840 --> 01:44:39.440]   I knew all of the flaws in my work.
[01:44:39.440 --> 01:44:41.440]   I knew the limitations.
[01:44:41.440 --> 01:44:44.320]   I knew what I hadn't managed to achieve.
[01:44:44.320 --> 01:44:47.200]   And what I saw was maybe a third of the way
[01:44:47.200 --> 01:44:48.640]   of what I was trying to achieve.
[01:44:48.640 --> 01:44:50.960]   And I saw everything as flawed.
[01:44:50.960 --> 01:44:54.080]   What they saw, what I had achieved,
[01:44:54.080 --> 01:44:55.600]   they didn't see what I hadn't achieved.
[01:44:55.600 --> 01:44:57.760]   They only saw the one third down,
[01:44:57.760 --> 01:44:59.600]   which was pretty good in their eyes.
[01:44:59.600 --> 01:45:00.800]   So they all respected me.
[01:45:00.800 --> 01:45:04.240]   And I was feeling miserable about myself.
[01:45:04.240 --> 01:45:05.680]   I was like, I'm not worthy.
[01:45:05.680 --> 01:45:11.520]   And I think that this is a cognitive problem that we have.
[01:45:11.520 --> 01:45:14.880]   We kind of, it's kind of like when we're talking about
[01:45:14.880 --> 01:45:17.120]   artificial general intelligence, HEI,
[01:45:17.120 --> 01:45:19.280]   of sort of, we kind of have this definition
[01:45:19.280 --> 01:45:22.080]   that anything that machines can do is not intelligent
[01:45:22.080 --> 01:45:24.080]   and anything that they can't do is intelligent.
[01:45:24.080 --> 01:45:26.160]   Therefore, we narrow, narrow, narrow, narrow
[01:45:26.160 --> 01:45:27.920]   the field of what intelligence truly means.
[01:45:27.920 --> 01:45:29.520]   And as soon as machines achieve something,
[01:45:29.520 --> 01:45:30.880]   it's not intelligent anymore.
[01:45:30.880 --> 01:45:33.040]   I feel like I was doing the same thing with myself.
[01:45:33.040 --> 01:45:34.720]   As soon as I could solve something,
[01:45:34.720 --> 01:45:37.280]   it was the kind of thing that a kid like me could solve.
[01:45:37.280 --> 01:45:38.560]   And therefore it was kind of easy.
[01:45:38.560 --> 01:45:41.280]   But to the others, it seemed hard.
[01:45:41.280 --> 01:45:42.340]   - Yeah.
[01:45:42.340 --> 01:45:44.240]   - But to me, it seemed easy.
[01:45:44.240 --> 01:45:46.000]   So it was this kind of thing that everything
[01:45:46.000 --> 01:45:48.720]   that my colleagues were doing seemed impossible to me.
[01:45:48.720 --> 01:45:51.600]   But everything that I was doing seemed impossible to them.
[01:45:51.600 --> 01:45:55.360]   So it was that realization that sort of made me mature
[01:45:55.360 --> 01:45:57.920]   into sort of a, not more confident,
[01:45:57.920 --> 01:45:59.840]   but more comfortable human being.
[01:45:59.840 --> 01:46:02.160]   - Can you actually linger on that a little bit?
[01:46:02.160 --> 01:46:04.320]   I mean, you mentioned Minsky.
[01:46:04.320 --> 01:46:07.280]   I remember he said something in an interview
[01:46:07.280 --> 01:46:10.320]   where he said the secret to his,
[01:46:10.320 --> 01:46:13.200]   like the way he approached life
[01:46:13.200 --> 01:46:16.640]   was to never be happy with anything he did.
[01:46:16.640 --> 01:46:21.520]   So there's something powerful as a motivator
[01:46:21.520 --> 01:46:24.800]   to doing exactly what you're saying,
[01:46:24.800 --> 01:46:26.240]   which is everything you've achieved,
[01:46:26.240 --> 01:46:28.240]   to see that as easy and unimpressive.
[01:46:28.240 --> 01:46:31.520]   What do you do with that?
[01:46:31.520 --> 01:46:34.480]   Because clearly that's a useful thing.
[01:46:34.480 --> 01:46:36.880]   - I think I've kind of matured past that.
[01:46:36.880 --> 01:46:38.640]   And I think the maturity past that
[01:46:38.640 --> 01:46:41.520]   is to sort of accept what it is
[01:46:41.520 --> 01:46:47.280]   and accept that it has helped others build onto it
[01:46:47.280 --> 01:46:50.000]   and therefore advance human knowledge.
[01:46:50.000 --> 01:46:53.760]   So it's very easy to sort of fall into the trap of,
[01:46:53.760 --> 01:46:55.040]   oh, everything I've done is crap.
[01:46:55.040 --> 01:46:58.960]   What I told you last time is that I always tell my students
[01:46:58.960 --> 01:47:00.560]   that our best work is ahead of us.
[01:47:01.520 --> 01:47:04.480]   And I think that's more of my mindset.
[01:47:04.480 --> 01:47:05.760]   - That's a beautiful way to put it.
[01:47:05.760 --> 01:47:06.320]   - Exactly.
[01:47:06.320 --> 01:47:08.480]   - What we've done is strong.
[01:47:08.480 --> 01:47:09.200]   - It's great.
[01:47:09.200 --> 01:47:10.560]   It's great for the time
[01:47:10.560 --> 01:47:12.320]   and it'll become obsolete in 30 years.
[01:47:12.320 --> 01:47:15.040]   Not we can't, we are doing even better.
[01:47:15.040 --> 01:47:15.920]   - We're doing even better.
[01:47:15.920 --> 01:47:16.560]   - Exactly.
[01:47:16.560 --> 01:47:20.080]   So basically our next work, we'll just strive.
[01:47:20.080 --> 01:47:22.640]   And again, you can't let the perfect
[01:47:22.640 --> 01:47:23.520]   be the enemy of the good.
[01:47:23.520 --> 01:47:25.600]   At some point you have to wrap.
[01:47:25.600 --> 01:47:28.240]   I was having a meeting with my student yesterday
[01:47:28.400 --> 01:47:31.760]   and he was like, listen, we know this is not perfect
[01:47:31.760 --> 01:47:34.000]   but it's way better than anything
[01:47:34.000 --> 01:47:35.120]   that's ever been done before.
[01:47:35.120 --> 01:47:37.360]   You know how to improve it
[01:47:37.360 --> 01:47:41.040]   but if you try to, your paper is never gonna get published.
[01:47:41.040 --> 01:47:45.840]   So there's this balance of
[01:47:45.840 --> 01:47:50.080]   we're already at the top of the field, get it out.
[01:47:50.080 --> 01:47:52.560]   And then you work on the next improvement.
[01:47:52.560 --> 01:47:55.280]   And in my experience, this has never happened.
[01:47:55.280 --> 01:47:57.120]   We've never actually worked on the next improvement
[01:47:57.120 --> 01:47:57.760]   and that's okay.
[01:47:57.760 --> 01:47:58.760]   - Yeah, but it's a good way to think of it.
[01:47:58.760 --> 01:48:00.240]   - It didn't make a difference
[01:48:00.240 --> 01:48:03.120]   because you're basically putting a new stepping stone
[01:48:03.120 --> 01:48:06.160]   that others will be able to step on and surpass you.
[01:48:06.160 --> 01:48:10.400]   My advisor in grad school would basically tell me,
[01:48:10.400 --> 01:48:13.920]   Manolis, let others write the second paper in that field.
[01:48:13.920 --> 01:48:16.080]   Just write the first one, move on.
[01:48:16.080 --> 01:48:17.760]   Move on to the next field.
[01:48:17.760 --> 01:48:20.720]   You don't wanna be writing the second and the third
[01:48:20.720 --> 01:48:22.720]   and the fourth and the fifth paper in the same field.
[01:48:22.720 --> 01:48:29.040]   Just, and it's very shocking to a student to hear that
[01:48:29.040 --> 01:48:31.440]   'cause I was like, I was at the top of my game.
[01:48:31.440 --> 01:48:34.080]   I was owning that field and I published the first paper.
[01:48:34.080 --> 01:48:35.840]   I'm like, I'm ready for two and three and four.
[01:48:35.840 --> 01:48:38.000]   He's like, move on, just let it be.
[01:48:38.000 --> 01:48:40.640]   And I was like, whoa.
[01:48:40.640 --> 01:48:43.280]   And it's so liberating to sort of not have to
[01:48:43.280 --> 01:48:48.240]   surpass everyone but just put your little stepping stone
[01:48:48.240 --> 01:48:50.560]   out there and others will step on it
[01:48:50.560 --> 01:48:51.920]   and put their own stones further
[01:48:51.920 --> 01:48:53.520]   and eventually cross a bigger river
[01:48:53.520 --> 01:48:57.120]   than if you tried to sort of make a giant leap all at once.
[01:48:57.120 --> 01:48:58.960]   So you need both.
[01:48:58.960 --> 01:49:00.720]   - Beautifully put.
[01:49:00.720 --> 01:49:05.360]   So the funny thing is, I've, I believe I closed
[01:49:05.360 --> 01:49:07.600]   the previous episode with a Darwin quote about
[01:49:07.600 --> 01:49:11.920]   the power of poetry and music in life.
[01:49:11.920 --> 01:49:14.160]   I think your quote, and again, I only heard once,
[01:49:14.160 --> 01:49:16.640]   was Darwin basically saying,
[01:49:16.640 --> 01:49:18.400]   if I were to live life again,
[01:49:18.400 --> 01:49:21.600]   next time I would read more poetry
[01:49:21.600 --> 01:49:24.480]   and something about art every week or something like that.
[01:49:24.480 --> 01:49:25.680]   - Yeah, yeah.
[01:49:25.680 --> 01:49:30.080]   It's so interesting for somebody who studied life
[01:49:30.080 --> 01:49:33.280]   at a very cold, I would say, genetic level to say that,
[01:49:33.280 --> 01:49:38.800]   yeah, the highest form of living is the art.
[01:49:38.800 --> 01:49:42.080]   But like on that, which made me realize
[01:49:42.080 --> 01:49:46.480]   that you write poetry and I forced you
[01:49:46.480 --> 01:49:50.720]   or maybe convinced you somehow to maybe share
[01:49:50.720 --> 01:49:52.560]   if it's possible, if it's okay,
[01:49:52.560 --> 01:49:57.360]   some of the poetry you've written yourself in your life.
[01:49:57.360 --> 01:50:00.400]   - So again, being Greek, a lot of my poems
[01:50:00.400 --> 01:50:01.520]   have been pretty miserable.
[01:50:01.520 --> 01:50:03.440]   (both laughing)
[01:50:03.440 --> 01:50:06.320]   And I always like to say that it's very hard for me
[01:50:06.320 --> 01:50:07.920]   to write a poem when I'm happy.
[01:50:07.920 --> 01:50:12.480]   And I just have to be in a state of deep despair
[01:50:12.480 --> 01:50:13.440]   in order to write poems.
[01:50:13.440 --> 01:50:19.040]   But the first poem I ever wrote was in English class.
[01:50:19.040 --> 01:50:20.880]   I'm Greek, I grew up in Greece,
[01:50:20.880 --> 01:50:22.080]   but I was in a French high school
[01:50:22.080 --> 01:50:24.480]   and I was taking English as a foreign language.
[01:50:24.480 --> 01:50:27.040]   So the English teacher basically asked us
[01:50:27.040 --> 01:50:29.280]   to write a poem in English.
[01:50:29.280 --> 01:50:33.120]   So this is basically what I'm gonna embarrass myself
[01:50:33.120 --> 01:50:36.720]   and read from my 16-year-old self many, many years ago.
[01:50:36.720 --> 01:50:38.320]   - Can you give a little bit more context
[01:50:38.320 --> 01:50:39.840]   about who you were in this moment?
[01:50:39.840 --> 01:50:40.960]   So like just--
[01:50:40.960 --> 01:50:43.440]   - So here's what's really interesting.
[01:50:43.440 --> 01:50:46.080]   In terms of growing up, how do we grow up?
[01:50:48.480 --> 01:50:49.840]   It's very difficult to grow up
[01:50:49.840 --> 01:50:52.080]   if you're in the same school
[01:50:52.080 --> 01:50:53.600]   going from one class to the other
[01:50:53.600 --> 01:50:55.840]   and all your friends know you inside out.
[01:50:55.840 --> 01:50:57.120]   It's very difficult to change.
[01:50:57.120 --> 01:50:58.480]   It's very difficult to grow up
[01:50:58.480 --> 01:51:00.480]   because they have a certain set of expectations
[01:51:00.480 --> 01:51:03.360]   for who you are and for how you're gonna behave.
[01:51:03.360 --> 01:51:07.520]   So in many ways, we kind of tend to get set in our ways
[01:51:07.520 --> 01:51:09.040]   and not change very much.
[01:51:09.040 --> 01:51:11.920]   I think something that helped me grow up
[01:51:11.920 --> 01:51:14.240]   is that when I was 11 years old,
[01:51:14.240 --> 01:51:18.000]   I was a kid in Greece in primary school.
[01:51:18.000 --> 01:51:20.640]   When I was 12 years old, I was a kid in Greece
[01:51:20.640 --> 01:51:23.200]   in first year of high school.
[01:51:23.200 --> 01:51:28.000]   When I was 13, I was in France.
[01:51:28.000 --> 01:51:31.600]   So basically moved countries and schools.
[01:51:31.600 --> 01:51:33.520]   The next year, I moved schools again
[01:51:33.520 --> 01:51:34.560]   because it was a transition
[01:51:34.560 --> 01:51:35.760]   in the French educational system
[01:51:35.760 --> 01:51:36.720]   from one school to the next.
[01:51:36.720 --> 01:51:39.840]   The next year after that, my family moved to New York
[01:51:39.840 --> 01:51:41.200]   in a French high school there.
[01:51:41.200 --> 01:51:43.280]   And the next year after that, I'm moving to MIT.
[01:51:43.280 --> 01:51:46.800]   So basically between 11 and 19,
[01:51:46.800 --> 01:51:50.160]   every single year, I actually had the opportunity to grow.
[01:51:50.160 --> 01:51:53.920]   I was not held by people who knew me
[01:51:53.920 --> 01:51:58.160]   and I could reinvent myself or reshape myself
[01:51:58.160 --> 01:52:01.600]   or reshape my sort of personality, my emotions,
[01:52:01.600 --> 01:52:03.280]   as I was growing up,
[01:52:03.280 --> 01:52:06.560]   especially in such a transformative time of a kid's life
[01:52:06.560 --> 01:52:08.960]   from 11 to 17.
[01:52:08.960 --> 01:52:10.240]   - Okay, first of all, it's so powerful
[01:52:10.240 --> 01:52:11.120]   that you think of it that way.
[01:52:11.120 --> 01:52:12.960]   Did you think of it that way at the moment?
[01:52:12.960 --> 01:52:14.720]   'Cause it's kind of a source,
[01:52:15.440 --> 01:52:17.440]   you said an opportunity to grow,
[01:52:17.440 --> 01:52:18.480]   but it's kind of suffering.
[01:52:18.480 --> 01:52:21.280]   I mean, you're being torn away from the thing you know
[01:52:21.280 --> 01:52:22.400]   into a thing you don't know.
[01:52:22.400 --> 01:52:26.480]   - So when we moved from South France to New York,
[01:52:26.480 --> 01:52:27.280]   I was pissed.
[01:52:27.280 --> 01:52:28.240]   (Lex laughing)
[01:52:28.240 --> 01:52:29.040]   I was pissed.
[01:52:29.040 --> 01:52:33.600]   I was taking these long bike rides in the countryside,
[01:52:33.600 --> 01:52:35.600]   jumping in French swimming pools.
[01:52:35.600 --> 01:52:38.400]   And I had all these wonderful friendships
[01:52:38.400 --> 01:52:41.600]   going downtown and just staying by the fountains
[01:52:41.600 --> 01:52:44.640]   in the dim lit streets of Aix-en-Provence
[01:52:44.640 --> 01:52:45.440]   in the South of France.
[01:52:45.440 --> 01:52:47.360]   It was magical.
[01:52:47.360 --> 01:52:49.360]   And suddenly I moved to New York City,
[01:52:49.360 --> 01:52:53.440]   a city of cement, of ugliness,
[01:52:53.440 --> 01:52:55.760]   like trash in the streets at every corner.
[01:52:55.760 --> 01:52:56.800]   It's just horrible.
[01:52:56.800 --> 01:52:58.800]   Snow everywhere.
[01:52:58.800 --> 01:53:02.000]   Having never seen snow or like real snow in my life.
[01:53:02.000 --> 01:53:04.560]   I moved from Athens to South France to suddenly New York.
[01:53:04.560 --> 01:53:05.840]   So I was pissed.
[01:53:05.840 --> 01:53:09.840]   But whether I saw it as an opportunity for growth,
[01:53:09.840 --> 01:53:10.640]   I don't think so.
[01:53:10.640 --> 01:53:13.360]   I don't think that I was that self-reflective.
[01:53:13.360 --> 01:53:14.880]   It was just how it happened.
[01:53:14.880 --> 01:53:15.680]   - Only now do you see it this way.
[01:53:15.680 --> 01:53:18.960]   - I saw it like that probably pretty early on,
[01:53:18.960 --> 01:53:21.200]   but not during those transitions.
[01:53:21.200 --> 01:53:22.640]   So basically during those transitions,
[01:53:22.640 --> 01:53:25.280]   I was just a kid being a kid, you know?
[01:53:25.280 --> 01:53:30.160]   And maybe the time that I started seeing it that way
[01:53:30.160 --> 01:53:35.120]   was maybe when I decided to stay at MIT as a professor
[01:53:35.120 --> 01:53:37.120]   after having been there as a student.
[01:53:37.120 --> 01:53:42.320]   And I kind of saw the struggle of getting professors
[01:53:42.320 --> 01:53:45.920]   to not see you as a kid when they're your peers.
[01:53:45.920 --> 01:53:50.080]   And I was very flattered when one of my friends
[01:53:50.080 --> 01:53:52.560]   basically told me, "Oh, I remember you in recitation
[01:53:52.560 --> 01:53:53.920]   when you first asked me a question."
[01:53:53.920 --> 01:53:58.160]   I said, "Wow, this kid, I'll pay attention."
[01:53:58.160 --> 01:53:59.200]   (laughs)
[01:53:59.200 --> 01:54:00.320]   - One day you'll be a peer.
[01:54:00.320 --> 01:54:03.840]   - So it's, you know, certainly my perception
[01:54:03.840 --> 01:54:05.440]   was that many of them could not see me
[01:54:05.440 --> 01:54:06.480]   as anything but a kid,
[01:54:06.480 --> 01:54:09.200]   but it turns out that some of them saw me
[01:54:09.200 --> 01:54:11.600]   as something different than a kid even before
[01:54:11.600 --> 01:54:13.280]   I was actually their colleague.
[01:54:13.280 --> 01:54:14.960]   So it's kind of an interesting place
[01:54:14.960 --> 01:54:16.880]   because what I like to say about MIT
[01:54:16.880 --> 01:54:20.000]   is that people treat you as equal no matter what stage.
[01:54:20.000 --> 01:54:23.440]   And they respect you for what you say,
[01:54:23.440 --> 01:54:25.840]   not for who you are when you're saying it.
[01:54:25.840 --> 01:54:29.120]   And if I'm wrong, my students will tell me.
[01:54:29.120 --> 01:54:32.960]   They will have no reservation to just be bluntly,
[01:54:32.960 --> 01:54:35.440]   you know, sorry, I don't agree with that.
[01:54:35.440 --> 01:54:40.080]   - Yeah, I mean, the beautiful thing about you is,
[01:54:40.080 --> 01:54:42.720]   sorry to put it this way,
[01:54:42.720 --> 01:54:46.320]   is, you know, maybe people who weren't familiar
[01:54:46.320 --> 01:54:48.240]   with your work beforehand might think,
[01:54:48.240 --> 01:54:53.520]   like, might not realize that you're a world-class scientist
[01:54:53.520 --> 01:54:55.520]   who leads a large group and so on.
[01:54:55.520 --> 01:54:58.560]   'Cause there's a youthful nature to you that it's,
[01:54:58.560 --> 01:55:02.080]   I mean, you talk like an undergrad,
[01:55:02.080 --> 01:55:05.280]   you know, with the excitement and the fresh eyes
[01:55:05.280 --> 01:55:07.520]   and the sort of excitement about the world.
[01:55:07.520 --> 01:55:09.920]   And that's, first of all, super contagious.
[01:55:09.920 --> 01:55:13.040]   And beautiful, you know, it's easy to sort of fall
[01:55:13.040 --> 01:55:18.640]   into behaving seriously because then people kind of
[01:55:18.640 --> 01:55:22.560]   start putting you on a pedestal more
[01:55:22.560 --> 01:55:24.560]   into a position of power.
[01:55:24.560 --> 01:55:28.320]   You wanna sort of act like you're in a position of power
[01:55:28.320 --> 01:55:30.480]   as opposed to allowing yourself to be lost
[01:55:30.480 --> 01:55:35.120]   in just the curiosity, the childish view of the world,
[01:55:35.120 --> 01:55:38.880]   which is just this open-eyed love of knowledge.
[01:55:38.880 --> 01:55:40.720]   - And that was the transition that I was describing
[01:55:40.720 --> 01:55:43.120]   when I decided to go back to my rollerblades and T-shirt
[01:55:43.120 --> 01:55:45.840]   and baseball cap, basically.
[01:55:45.840 --> 01:55:48.800]   You know, when I met my first postdoc,
[01:55:48.800 --> 01:55:52.000]   it was basically, you know,
[01:55:52.000 --> 01:55:54.160]   he was interviewing for postdocs at MIT.
[01:55:54.160 --> 01:55:56.560]   He already had several first author papers to his name
[01:55:56.560 --> 01:55:57.920]   in top journals.
[01:55:57.920 --> 01:56:03.040]   And my friend, Yulia, basically introduced me to Alex Stark,
[01:56:03.040 --> 01:56:05.440]   who basically was interviewing at the time with Rick Young
[01:56:05.440 --> 01:56:06.480]   and with Eric Lander,
[01:56:06.480 --> 01:56:08.960]   just like these massive names in the field.
[01:56:08.960 --> 01:56:11.200]   And I was just a first year faculty person
[01:56:11.200 --> 01:56:14.400]   with, you know, zero credibility.
[01:56:14.400 --> 01:56:16.560]   And she basically says,
[01:56:16.560 --> 01:56:18.560]   "Oh, there's this friend of mine, Alex, who's visiting.
[01:56:18.560 --> 01:56:19.520]   "He's also German.
[01:56:19.520 --> 01:56:20.480]   "You know, he wanted to meet you."
[01:56:20.480 --> 01:56:21.520]   I'm like, "Oh, sounds great.
[01:56:21.520 --> 01:56:22.960]   "I'd love to talk science."
[01:56:22.960 --> 01:56:25.600]   I show up, we sit at the amphitheater in Stata.
[01:56:25.600 --> 01:56:29.520]   You know, I basically arrive in my rollerblades,
[01:56:29.520 --> 01:56:33.680]   you know, jump a few steps, sit down, wearing my blades.
[01:56:33.680 --> 01:56:35.840]   We're having this awesome conversation
[01:56:35.840 --> 01:56:37.520]   about science and about gene regulation
[01:56:37.520 --> 01:56:39.360]   and how the whole thing works and sort of,
[01:56:39.360 --> 01:56:41.200]   you know, my perspective and his perspective.
[01:56:41.200 --> 01:56:42.960]   And we're just bouncing ideas for 30 minutes.
[01:56:42.960 --> 01:56:45.840]   And then I just dash off to my next meeting.
[01:56:45.840 --> 01:56:48.000]   And he basically emails me afterwards.
[01:56:48.000 --> 01:56:49.440]   And I was giving him advice
[01:56:49.440 --> 01:56:50.880]   about how to interview with Eric Lander,
[01:56:50.880 --> 01:56:51.920]   how to interview with Rick Young,
[01:56:51.920 --> 01:56:54.160]   and how to sort of get a position with them.
[01:56:54.160 --> 01:56:57.280]   And then after a while, he emails me saying,
[01:56:57.280 --> 01:56:59.360]   "I would love to become a postdoc in your group."
[01:56:59.360 --> 01:57:01.520]   I'm like, "What? Are you kidding me?"
[01:57:04.080 --> 01:57:09.040]   So he basically didn't care
[01:57:09.040 --> 01:57:11.120]   that I wear rollerblades and T-shirt.
[01:57:11.120 --> 01:57:12.640]   All he cared about was my ideas
[01:57:12.640 --> 01:57:15.200]   and sort of embracing the me
[01:57:15.200 --> 01:57:19.520]   with the childhood excitement about science
[01:57:19.520 --> 01:57:21.360]   was basically what attracted him.
[01:57:21.360 --> 01:57:23.840]   It wasn't the, "Wow, this guy runs a big lab,"
[01:57:23.840 --> 01:57:24.800]   or this and that.
[01:57:24.800 --> 01:57:26.880]   It was just like, "I like his ideas.
[01:57:26.880 --> 01:57:27.680]   "I wanna work with him."
[01:57:27.680 --> 01:57:28.240]   (laughs)
[01:57:28.240 --> 01:57:31.120]   - That, by the way, folks, is the best of MIT.
[01:57:31.120 --> 01:57:32.320]   That's what MIT stands for.
[01:57:32.320 --> 01:57:34.000]   So that's a beautiful story.
[01:57:34.000 --> 01:57:35.520]   But take me back to the poem.
[01:57:35.520 --> 01:57:36.400]   (laughs)
[01:57:36.400 --> 01:57:38.000]   And where did this poem come from?
[01:57:38.000 --> 01:57:38.480]   - So now--
[01:57:38.480 --> 01:57:39.920]   - Where's your mindset?
[01:57:39.920 --> 01:57:42.960]   So who is the 17, 16-year-old kid, Manolis?
[01:57:42.960 --> 01:57:47.520]   - So again, I've just seen "Snow" for the first time.
[01:57:47.520 --> 01:57:49.280]   And I'm in New York. - Is this in New York?
[01:57:49.280 --> 01:57:50.400]   - This is in New York.
[01:57:50.400 --> 01:57:54.400]   So maybe that's where the sadness in the poem comes from.
[01:57:54.400 --> 01:57:56.880]   But anyway, we're asked in class to write an assignment.
[01:57:56.880 --> 01:57:58.080]   This is my third language.
[01:57:58.080 --> 01:57:59.600]   I'm not very good at it.
[01:57:59.600 --> 01:58:02.160]   So pardon me, but here's what I wrote.
[01:58:02.160 --> 01:58:05.760]   "Children dance now all in row,
[01:58:05.760 --> 01:58:07.920]   "Children laughing at the snow.
[01:58:07.920 --> 01:58:10.080]   "But in time's endless flow,
[01:58:10.080 --> 01:58:12.240]   "Children sooner or later grow.
[01:58:12.240 --> 01:58:15.440]   "Men are mortal, we go by.
[01:58:15.440 --> 01:58:17.040]   "If we know it, we may cry.
[01:58:17.040 --> 01:58:19.360]   "But I thought a love so sweet
[01:58:19.360 --> 01:58:21.120]   "Was immortal, was so deep.
[01:58:21.120 --> 01:58:23.680]   "There I told you, darling, sweet
[01:58:23.680 --> 01:58:25.200]   "That forever love would keep.
[01:58:25.200 --> 01:58:28.320]   "Blossomed spring and summer shined,
[01:58:28.320 --> 01:58:30.960]   "Then blue autumn, winter died.
[01:58:31.760 --> 01:58:33.760]   "One year passed, but the clouds
[01:58:33.760 --> 01:58:36.240]   "Still remember all our vows.
[01:58:36.240 --> 01:58:38.960]   "Never faked and never lied.
[01:58:38.960 --> 01:58:41.200]   "All we did was stare and smile.
[01:58:41.200 --> 01:58:44.000]   "All alone, sitting down
[01:58:44.000 --> 01:58:45.760]   "To the snow we made our vow.
[01:58:45.760 --> 01:58:48.320]   "But you told me you were right.
[01:58:48.320 --> 01:58:51.280]   "Birds who love are birds who cry.
[01:58:51.280 --> 01:58:55.280]   "Now with laughter children play,
[01:58:55.280 --> 01:58:58.080]   "Yet the sky is so gray.
[01:58:58.080 --> 01:59:01.200]   "Even if the snow seems bright,
[01:59:01.200 --> 01:59:03.040]   "Without you have lost their light.
[01:59:03.040 --> 01:59:06.240]   "Sun that sang and moon that smiled,
[01:59:06.240 --> 01:59:08.240]   "All the stars have ceased to shine.
[01:59:08.240 --> 01:59:11.040]   "All of nature drew its grace,
[01:59:11.040 --> 01:59:12.800]   "Found its light within your face.
[01:59:12.800 --> 01:59:15.440]   "Now you're gone and won't return.
[01:59:15.440 --> 01:59:18.240]   "Let the snow and my heart burn."
[01:59:18.240 --> 01:59:19.520]   (Lex laughing)
[01:59:19.520 --> 01:59:21.200]   - There's a Greek in there, that's beautiful.
[01:59:21.200 --> 01:59:22.480]   That's beautiful, by the way.
[01:59:22.480 --> 01:59:24.560]   And the rhyming, the musicality,
[01:59:24.560 --> 01:59:27.120]   there's both a simplicity--
[01:59:27.120 --> 01:59:28.640]   - I'm 16.
[01:59:28.640 --> 01:59:29.440]   - And a musicality to it.
[01:59:29.440 --> 01:59:30.160]   - I hate my third language.
[01:59:31.120 --> 01:59:31.760]   - No, no, no.
[01:59:31.760 --> 01:59:34.560]   But like, so I really enjoy like Robert Frost poems.
[01:59:34.560 --> 01:59:36.320]   I don't mean simplicity in a bad way,
[01:59:36.320 --> 01:59:37.440]   in a negative way at all.
[01:59:37.440 --> 01:59:39.360]   - Again, it's very weird to analyze your own poem,
[01:59:39.360 --> 01:59:42.240]   but I think it captures the simplicity of youth
[01:59:42.240 --> 01:59:43.680]   and the way that it kind of starts
[01:59:43.680 --> 01:59:45.040]   with "Children Dance La-On-La-Lo".
[01:59:45.040 --> 01:59:47.200]   It basically, and it kind of shows that
[01:59:47.200 --> 01:59:49.840]   snow can be interpreted first in the first verse
[01:59:49.840 --> 01:59:52.720]   as a happy thing, ta-da-da-da-da snow.
[01:59:52.720 --> 01:59:54.480]   And then in the end, you know,
[01:59:54.480 --> 01:59:57.280]   "Now with laughter children play."
[01:59:57.280 --> 01:59:59.440]   I'm like, now I've grown basically.
[02:00:00.000 --> 02:00:02.240]   It's this transformation that we're actually talking about.
[02:00:02.240 --> 02:00:03.760]   This whole men are mortal, we go by.
[02:00:03.760 --> 02:00:05.680]   I'm sort of, you know, you're saying,
[02:00:05.680 --> 02:00:07.040]   are you comfortable with growing old?
[02:00:07.040 --> 02:00:09.840]   I'm like, duh, I was since I was 16.
[02:00:09.840 --> 02:00:10.240]   - Yeah.
[02:00:10.240 --> 02:00:12.640]   - And what's really interesting is that, you know,
[02:00:12.640 --> 02:00:14.640]   again, when I was 12 years old
[02:00:14.640 --> 02:00:16.160]   in our summer house in Greece,
[02:00:16.160 --> 02:00:18.320]   I remember sort of telling my sister
[02:00:18.320 --> 02:00:20.960]   my outlook that I would have as a father
[02:00:20.960 --> 02:00:22.800]   for how to bring up my own kids.
[02:00:22.800 --> 02:00:25.040]   So it's very weird that I've always sort of seen
[02:00:25.040 --> 02:00:28.560]   the full path from, you know, a kid.
[02:00:28.560 --> 02:00:30.240]   - From when you were young.
[02:00:30.240 --> 02:00:33.440]   - Yeah, I don't know if you like this Jonny Mitchell song.
[02:00:33.440 --> 02:00:35.520]   "I've looked at clouds from both sides now,
[02:00:35.520 --> 02:00:37.600]   "from up and down and still somehow,
[02:00:37.600 --> 02:00:39.920]   "it's snow's illusions I recall."
[02:00:39.920 --> 02:00:42.400]   Or it's clouds illusions I recall,
[02:00:42.400 --> 02:00:43.840]   I really don't know clouds at all.
[02:00:43.840 --> 02:00:45.760]   So it's really beautiful.
[02:00:45.760 --> 02:00:47.120]   So I think the Jonny Mitchell song,
[02:00:47.120 --> 02:00:48.560]   which again, I heard for the first time
[02:00:48.560 --> 02:00:49.520]   much, much after this,
[02:00:49.520 --> 02:00:52.160]   and I wouldn't even compare this to that.
[02:00:52.160 --> 02:00:54.240]   But what Jonny Mitchell is saying that song
[02:00:54.240 --> 02:00:57.360]   is that you can see life from two perspectives.
[02:00:58.320 --> 02:01:00.800]   You can see the good or the bad
[02:01:00.800 --> 02:01:03.120]   in both, you know, in everything you see.
[02:01:03.120 --> 02:01:05.360]   And I think that's the allegory of snow right now.
[02:01:05.360 --> 02:01:09.600]   You can see snow as this bright, white, wonderful thing,
[02:01:09.600 --> 02:01:11.840]   or you can see snow as this miserable,
[02:01:11.840 --> 02:01:14.160]   you know, gray thing.
[02:01:14.160 --> 02:01:15.200]   So that's sort of,
[02:01:15.200 --> 02:01:16.960]   and what I like about the last verse now
[02:01:16.960 --> 02:01:18.240]   with Laughter Children Play
[02:01:18.240 --> 02:01:20.160]   is that it's a recall to the first one
[02:01:20.160 --> 02:01:25.120]   where I was the kid enjoying careless life
[02:01:25.120 --> 02:01:27.280]   and eventually was making promises
[02:01:27.280 --> 02:01:28.800]   that something would be forever.
[02:01:28.800 --> 02:01:30.560]   And I think part of that is also the loss
[02:01:30.560 --> 02:01:32.320]   of my friendships in France,
[02:01:32.320 --> 02:01:34.720]   of being in New York now and sort of everything's gray.
[02:01:34.720 --> 02:01:38.640]   And, you know, even though the snow seems bright
[02:01:38.640 --> 02:01:40.480]   without you have lost their light,
[02:01:40.480 --> 02:01:41.840]   sun that sang and moon that smiled.
[02:01:41.840 --> 02:01:46.800]   So it's this concept that if you lose your love,
[02:01:46.800 --> 02:01:51.840]   the same thing can be perceived in a very different way.
[02:01:51.840 --> 02:01:53.920]   - Let me ask you this,
[02:01:53.920 --> 02:01:55.760]   because somebody wrote me this long email,
[02:01:55.760 --> 02:01:59.360]   and I think you're the perfect person to ask this.
[02:01:59.360 --> 02:01:59.860]   - Uh-oh.
[02:01:59.860 --> 02:02:03.840]   - You mentioned love.
[02:02:03.840 --> 02:02:08.240]   From a genetic perspective,
[02:02:08.240 --> 02:02:11.700]   what is it?
[02:02:11.700 --> 02:02:14.000]   What do you make of love?
[02:02:14.000 --> 02:02:16.880]   Why do we humans fall in love?
[02:02:16.880 --> 02:02:19.680]   In your own life, why did you fall in love?
[02:02:19.680 --> 02:02:23.600]   You know, the email that was written to me
[02:02:23.600 --> 02:02:27.040]   was you always talk about mortality
[02:02:27.040 --> 02:02:28.400]   and fear of mortality,
[02:02:28.400 --> 02:02:32.000]   but you don't ask about love.
[02:02:32.000 --> 02:02:35.760]   So I don't know if there's some thoughts
[02:02:35.760 --> 02:02:40.000]   you could give about the role of love in your own life
[02:02:40.000 --> 02:02:47.520]   or the role of love in human life in general.
[02:02:47.520 --> 02:02:51.120]   - I think love in many ways defines my life.
[02:02:51.120 --> 02:02:54.640]   It's basically, I like to say that I'm a human first
[02:02:54.640 --> 02:02:56.560]   and a professor second.
[02:02:56.560 --> 02:03:00.880]   And I think this passion for life,
[02:03:00.880 --> 02:03:03.920]   this passion for everything around us,
[02:03:03.920 --> 02:03:06.160]   I mean, the only way to describe that is love.
[02:03:06.160 --> 02:03:13.040]   It's basically embracing your emotional self,
[02:03:13.040 --> 02:03:22.560]   embracing the non-brainiac in you,
[02:03:22.560 --> 02:03:26.240]   embracing the sort of intangible,
[02:03:26.240 --> 02:03:30.480]   not very well-defined.
[02:03:30.480 --> 02:03:32.400]   And even in my own research,
[02:03:32.400 --> 02:03:34.880]   I'm just very passionate about everything I do.
[02:03:34.880 --> 02:03:37.200]   There's a certain passion that comes through.
[02:03:37.200 --> 02:03:40.080]   And what, I'm sorry, again, being Greek,
[02:03:40.080 --> 02:03:41.920]   the etymology of the word passion.
[02:03:41.920 --> 02:03:42.880]   What was passion?
[02:03:42.880 --> 02:03:44.640]   Passion is suffering.
[02:03:44.640 --> 02:03:47.600]   The etymology, I mean,
[02:03:47.600 --> 02:03:48.960]   when we talk about the passion of the Christ,
[02:03:48.960 --> 02:03:49.840]   it's the suffering.
[02:03:49.840 --> 02:03:53.200]   And in the Greek version of that word, pathos,
[02:03:53.200 --> 02:03:59.440]   like pathology, pathos is deep suffering.
[02:03:59.440 --> 02:04:02.160]   It's the concept of someone who's sympathetic.
[02:04:02.160 --> 02:04:04.880]   Sympathetic means suffering together,
[02:04:04.880 --> 02:04:07.840]   experiencing emotions together.
[02:04:07.840 --> 02:04:09.600]   So it's funny that you're asking about love
[02:04:09.600 --> 02:04:11.120]   and I respond with passion,
[02:04:11.120 --> 02:04:13.200]   passion for life, passion for research,
[02:04:13.200 --> 02:04:16.320]   passion for my family, for my children, for, you know.
[02:04:16.320 --> 02:04:23.360]   So there's a certain passion that defines me
[02:04:23.360 --> 02:04:25.840]   and everything else follows
[02:04:25.840 --> 02:04:27.040]   rather than the other way around.
[02:04:27.040 --> 02:04:29.360]   I'm not first thinking with my brain,
[02:04:29.360 --> 02:04:32.320]   what is the most impactful paper we could write?
[02:04:32.320 --> 02:04:33.760]   And then going after that,
[02:04:33.760 --> 02:04:35.520]   I'm thinking with my heart, what am I passionate about?
[02:04:35.520 --> 02:04:38.720]   What drives me, what's just like, you know, makes me tick.
[02:04:39.440 --> 02:04:41.040]   - And that's a beautiful way to live,
[02:04:41.040 --> 02:04:43.440]   but I love it how the Greek part of you
[02:04:43.440 --> 02:04:45.200]   just kind of connects it to the suffering.
[02:04:45.200 --> 02:04:47.440]   So if you could remove the suffering.
[02:04:47.440 --> 02:04:48.640]   - No, no, no, no, no, no.
[02:04:48.640 --> 02:04:50.080]   When I say suffering,
[02:04:50.080 --> 02:04:53.200]   I don't mean suffering as in being miserable.
[02:04:53.200 --> 02:04:57.360]   I mean, suffering as in being emotionally invested
[02:04:57.360 --> 02:04:58.320]   in something.
[02:04:58.320 --> 02:05:00.880]   Remember, I mean, again, if you look at this poem,
[02:05:00.880 --> 02:05:01.680]   what is it saying?
[02:05:01.680 --> 02:05:07.280]   It's saying birds who love are birds who cry, right?
[02:05:07.280 --> 02:05:08.240]   - Yeah.
[02:05:08.240 --> 02:05:10.560]   - That's the very definition of love.
[02:05:10.560 --> 02:05:12.960]   Exposing your fragility.
[02:05:12.960 --> 02:05:15.600]   If you're not afraid of suffering,
[02:05:15.600 --> 02:05:17.200]   you don't fall in love.
[02:05:17.200 --> 02:05:20.160]   As soon as you hold back,
[02:05:20.160 --> 02:05:21.680]   you protect, you shield your heart,
[02:05:21.680 --> 02:05:24.080]   no love can enter.
[02:05:24.080 --> 02:05:27.680]   So there's this Simon and Garfunkel song.
[02:05:27.680 --> 02:05:29.120]   I am a rock.
[02:05:29.120 --> 02:05:33.600]   I am an island and a rock feels no pain
[02:05:33.600 --> 02:05:36.800]   and an island never cries.
[02:05:37.520 --> 02:05:40.480]   So again, there's some aspect of that into this poem.
[02:05:40.480 --> 02:05:42.320]   The fact that,
[02:05:42.320 --> 02:05:46.400]   but you told me,
[02:05:46.400 --> 02:05:47.520]   there I told you darling sweet
[02:05:47.520 --> 02:05:49.680]   that forever love would keep is this intermediate thing.
[02:05:49.680 --> 02:05:50.720]   And then there's a recall,
[02:05:50.720 --> 02:05:52.080]   but you told me you were right,
[02:05:52.080 --> 02:05:53.440]   birds who love are birds who cry.
[02:05:53.440 --> 02:05:57.680]   So it basically says that love is the fragility
[02:05:57.680 --> 02:06:00.160]   that you're willing to give to another person.
[02:06:00.160 --> 02:06:05.520]   It's opening up your vulnerable spots.
[02:06:05.520 --> 02:06:10.640]   It's sort of accepting that there's no safety net.
[02:06:10.640 --> 02:06:12.720]   You're just giving yourself fully
[02:06:12.720 --> 02:06:14.400]   and you're ready to be hurt.
[02:06:14.400 --> 02:06:18.320]   - So you've already been way too kind with your time,
[02:06:18.320 --> 02:06:20.000]   but I'm gonna force you to stay here
[02:06:20.000 --> 02:06:21.280]   just a few minutes longer.
[02:06:21.280 --> 02:06:24.160]   As we're talking about goodbyes,
[02:06:24.160 --> 02:06:28.080]   you have a really nice other poem here about goodbyes.
[02:06:28.080 --> 02:06:30.320]   Can I force you to read it as well?
[02:06:30.320 --> 02:06:31.760]   (laughing)
[02:06:31.760 --> 02:06:33.280]   - Oh, twist my arm, twist my arm.
[02:06:34.080 --> 02:06:37.200]   So the next poem was written
[02:06:37.200 --> 02:06:39.520]   specifically for our high school yearbook.
[02:06:39.520 --> 02:06:42.480]   So another poem written on demand.
[02:06:42.480 --> 02:06:44.000]   The rest of them are just so miserable
[02:06:44.000 --> 02:06:48.640]   written by pure sadness and melancholy.
[02:06:48.640 --> 02:06:50.720]   But this one was also written on demand.
[02:06:50.720 --> 02:06:54.320]   And it was basically saying goodbye,
[02:06:54.320 --> 02:06:56.000]   as is appropriate right now,
[02:06:56.000 --> 02:06:58.720]   to my friends and sort of, again,
[02:06:58.720 --> 02:06:59.920]   reflecting this whole journey
[02:06:59.920 --> 02:07:00.960]   and transformation through life.
[02:07:01.520 --> 02:07:04.560]   And also, I think showing a little bit of introspection
[02:07:04.560 --> 02:07:07.840]   about how we kind of had it easy in high school
[02:07:07.840 --> 02:07:09.760]   and we're about to go into rougher waters.
[02:07:09.760 --> 02:07:12.320]   So the title is actually "The Tidewaters"
[02:07:12.320 --> 02:07:14.960]   and it's an analogy on that.
[02:07:14.960 --> 02:07:16.400]   So here it goes.
[02:07:16.400 --> 02:07:20.320]   All this was another lake
[02:07:20.320 --> 02:07:23.040]   where some rest we sailors take.
[02:07:23.040 --> 02:07:25.200]   Water's calm and full of fish.
[02:07:25.200 --> 02:07:26.880]   We'll find there what we wish.
[02:07:26.880 --> 02:07:29.280]   Some seek fruit and others feast.
[02:07:29.840 --> 02:07:32.000]   Some of us just look for peace.
[02:07:32.000 --> 02:07:34.560]   Some find friendships, other love.
[02:07:34.560 --> 02:07:36.400]   Some seek both and neither have.
[02:07:36.400 --> 02:07:38.800]   We were different when we came.
[02:07:38.800 --> 02:07:41.200]   Each his own story and fame.
[02:07:41.200 --> 02:07:43.360]   Different people had we been.
[02:07:43.360 --> 02:07:44.720]   Different cultures had we seen.
[02:07:44.720 --> 02:07:47.120]   Different nature, different face.
[02:07:47.120 --> 02:07:49.760]   Each unlike all in this place.
[02:07:49.760 --> 02:07:52.400]   We had faced success, defeat,
[02:07:52.400 --> 02:07:54.880]   then in one lake came to meet.
[02:07:54.880 --> 02:07:58.560]   There, the orders that we followed
[02:07:58.560 --> 02:08:00.240]   and the pride that we swallowed
[02:08:00.240 --> 02:08:02.640]   made us one but not the same.
[02:08:02.640 --> 02:08:05.920]   Joined us strangers who there came.
[02:08:05.920 --> 02:08:09.040]   Sooner, later, groups were made.
[02:08:09.040 --> 02:08:11.760]   Tribes where differences will fade.
[02:08:11.760 --> 02:08:14.560]   Some attached, more or less.
[02:08:14.560 --> 02:08:16.160]   Others fought and made a mess.
[02:08:16.160 --> 02:08:18.720]   But again we have to go.
[02:08:18.720 --> 02:08:21.360]   What for? Where to? We don't know.
[02:08:21.360 --> 02:08:22.880]   Still we know it. We will try.
[02:08:22.880 --> 02:08:25.600]   There to rush, to flee, to fly.
[02:08:25.600 --> 02:08:28.400]   There'll be some who wish to stay
[02:08:28.400 --> 02:08:29.680]   but they'll carry on away.
[02:08:29.680 --> 02:08:32.080]   We will continue on our journey
[02:08:32.080 --> 02:08:34.800]   as we came here, strong yet lonely.
[02:08:34.800 --> 02:08:37.360]   From the lake a river flows,
[02:08:37.360 --> 02:08:39.040]   from the river many goals.
[02:08:39.040 --> 02:08:40.560]   On that river we will race.
[02:08:40.560 --> 02:08:42.800]   Each will try to find his pace.
[02:08:42.800 --> 02:08:45.600]   In that scene, the sailors face,
[02:08:45.600 --> 02:08:49.280]   their first fear, defeat, disgrace.
[02:08:49.280 --> 02:08:51.760]   Here and there comes out a face
[02:08:51.760 --> 02:08:54.480]   that the waters soon embrace.
[02:08:54.480 --> 02:08:57.280]   Some get lucky, find their way.
[02:08:57.840 --> 02:09:00.000]   Others sink beneath the waves.
[02:09:00.000 --> 02:09:02.480]   In this race we will part.
[02:09:02.480 --> 02:09:05.360]   Some will settle near the start.
[02:09:05.360 --> 02:09:07.120]   Some set goals beyond the stars
[02:09:07.120 --> 02:09:09.360]   'cause the river carries far.
[02:09:09.360 --> 02:09:12.000]   You should know in what we've done,
[02:09:12.000 --> 02:09:14.720]   the hard part is still to come.
[02:09:14.720 --> 02:09:17.120]   So I'll have to say goodbye.
[02:09:17.120 --> 02:09:19.680]   Don't you worry, I won't cry.
[02:09:19.680 --> 02:09:22.240]   Neither will they those who try
[02:09:22.240 --> 02:09:25.120]   till the end to keep their pride.
[02:09:26.240 --> 02:09:28.560]   But please know, dearest friends,
[02:09:28.560 --> 02:09:30.160]   who are always there to mend,
[02:09:30.160 --> 02:09:32.800]   I will always need your hand.
[02:09:32.800 --> 02:09:34.720]   I will miss you till the end.
[02:09:34.720 --> 02:09:37.600]   - I don't think there's a better way to end it.
[02:09:37.600 --> 02:09:41.040]   Manolis, like I said last time,
[02:09:41.040 --> 02:09:43.760]   you're one of the most special people at MIT,
[02:09:43.760 --> 02:09:47.280]   one of the most special people in Boston
[02:09:47.280 --> 02:09:49.360]   and whatever mental force field
[02:09:49.360 --> 02:09:51.920]   that you're applying in saying
[02:09:51.920 --> 02:09:54.000]   that Boston is the best city in the world,
[02:09:54.000 --> 02:09:56.000]   MIT the best university in the world,
[02:09:56.000 --> 02:09:57.440]   you're actually making it happen.
[02:09:57.440 --> 02:09:58.800]   So thank you so much for talking to me.
[02:09:58.800 --> 02:09:59.520]   It's a huge honor.
[02:09:59.520 --> 02:10:00.480]   - Thank you so much.
[02:10:00.480 --> 02:10:01.200]   It's been a pleasure.
[02:10:01.200 --> 02:10:03.680]   - Thanks for listening to this conversation
[02:10:03.680 --> 02:10:06.640]   with Manolis Kellis and thank you to our sponsors,
[02:10:06.640 --> 02:10:09.840]   Public Goods, Magic Spoon and ExpressVPN.
[02:10:09.840 --> 02:10:12.720]   Please check out these sponsors in the description
[02:10:12.720 --> 02:10:15.440]   to get a discount and to support this podcast.
[02:10:15.440 --> 02:10:18.480]   If you enjoy this thing, subscribe on YouTube,
[02:10:18.480 --> 02:10:20.640]   review the Five Stars on Apple Podcast,
[02:10:20.640 --> 02:10:22.960]   follow on Spotify, support on Patreon
[02:10:22.960 --> 02:10:25.680]   or connect with me on Twitter @LexFriedman.
[02:10:26.560 --> 02:10:29.040]   And now let me leave you with some words
[02:10:29.040 --> 02:10:31.040]   from another well-known Greek,
[02:10:31.040 --> 02:10:33.280]   Alexander III of Macedonia,
[02:10:33.280 --> 02:10:35.120]   commonly known as Alexander the Great.
[02:10:35.120 --> 02:10:39.040]   "There is nothing impossible to him who will try."
[02:10:39.040 --> 02:10:43.360]   Thank you for listening and hope to see you next time.
[02:10:43.520 --> 02:10:44.100]   (upbeat music)
[02:10:45.060 --> 02:10:45.560]   (upbeat music)
[02:10:45.560 --> 02:10:46.060]   (upbeat music)
[02:10:46.060 --> 02:10:46.560]   (upbeat music)
[02:10:46.560 --> 02:10:47.060]   (upbeat music)
[02:10:47.060 --> 02:10:47.560]   (upbeat music)
[02:10:47.560 --> 02:10:57.560]   [BLANK_AUDIO]

