
[00:00:00.000 --> 00:00:06.900]   I really wanted to demonstrate the full power of combining PyTorch
[00:00:06.900 --> 00:00:08.960]   Lightning with Weights and Biases.
[00:00:08.960 --> 00:00:11.360]   This is sort of a Reese's situation.
[00:00:11.360 --> 00:00:14.480]   It's two great tastes that taste great together.
[00:00:14.480 --> 00:00:19.660]   So I'm going to show you how to do a PyTorch Lightning callback that gives
[00:00:19.660 --> 00:00:24.500]   you the ability to do fully flexible media logging with Weights and Biases.
[00:00:24.500 --> 00:00:29.280]   If you just use PyTorch Lightning, then you would be able to log metrics pretty
[00:00:29.280 --> 00:00:34.020]   easily, but if you wanted to log things like the input and output of your model,
[00:00:34.020 --> 00:00:37.140]   you're going to have a little bit more trouble with just base PyTorch Lightning.
[00:00:37.140 --> 00:00:40.240]   This is a problem because DNNs often fail in these very
[00:00:40.240 --> 00:00:42.440]   pernicious kind of silent ways.
[00:00:42.440 --> 00:00:45.660]   You know, the loss is going down, but it's actually getting every
[00:00:45.660 --> 00:00:47.960]   single example from one class wrong.
[00:00:47.960 --> 00:00:50.940]   Maybe you have a bug in your code and the way you're calculating
[00:00:50.940 --> 00:00:52.140]   your accuracy is incorrect.
[00:00:52.140 --> 00:00:56.500]   These can be very difficult bugs to track down unless you actually look at how
[00:00:56.720 --> 00:01:00.440]   things go into your model and what comes out directly, neural networks are designed
[00:01:00.440 --> 00:01:04.660]   to take a human interpretable data, like images, sounds, videos, and produce
[00:01:04.660 --> 00:01:08.280]   something that humans would be able to produce themselves out of it, like a label.
[00:01:08.280 --> 00:01:12.080]   And so sometimes the only way to debug them is to compare them to what a human thinks.
[00:01:12.080 --> 00:01:17.260]   Logging media is a really great way to find these silent, super scary bugs
[00:01:17.260 --> 00:01:19.640]   in your machine learning model.
[00:01:19.640 --> 00:01:22.180]   In order to be able to take advantage of that with PyTorch Lightning and
[00:01:22.180 --> 00:01:24.660]   Weights and Biases, we're going to need this callback here.
[00:01:24.860 --> 00:01:27.440]   There's maybe a couple of other ways to do it, but they all are going to
[00:01:27.440 --> 00:01:29.600]   require a little bit of extra code.
[00:01:29.600 --> 00:01:33.560]   So here I'm inheriting from PyTorch Lightning's callbacks.
[00:01:33.560 --> 00:01:36.020]   Basically I define a whole bunch of methods for it.
[00:01:36.020 --> 00:01:39.980]   Like this is what I want this callback to do when the validation epoch starts.
[00:01:39.980 --> 00:01:42.980]   What I want it to do when it ends, what I want it to do when a training
[00:01:42.980 --> 00:01:44.880]   epoch starts and a training epoch ends.
[00:01:44.880 --> 00:01:49.080]   This keeps all the code organized, make sure things run at the right time.
[00:01:49.080 --> 00:01:50.560]   It's a really nice interface.
[00:01:50.560 --> 00:01:53.940]   So we're going to inherit from that to make our image prediction logger.
[00:01:54.160 --> 00:01:57.280]   It's going to take some particular samples from the validation
[00:01:57.280 --> 00:01:58.800]   set and they're labeled.
[00:01:58.800 --> 00:02:03.380]   And then at the end of every validation epoch, it's going to compute the
[00:02:03.380 --> 00:02:07.480]   outputs of our model on those images, get those predictions and then log them
[00:02:07.480 --> 00:02:09.760]   to Weights and Biases with WB.image.
[00:02:09.760 --> 00:02:12.880]   And a caption that says, okay, this is what the model predicted.
[00:02:12.880 --> 00:02:14.680]   And this is what the true label was.
[00:02:14.680 --> 00:02:18.360]   That way you can actually find, Oh, Hey, there's an error in my labeling.
[00:02:18.360 --> 00:02:22.000]   What should be a four is actually labeled a five or something like that.
[00:02:22.120 --> 00:02:27.120]   So we add this by defining this onValidationEpoch end method of the
[00:02:27.120 --> 00:02:32.260]   callback and since we're in the callback interface has access to both the thing
[00:02:32.260 --> 00:02:36.840]   that's training the model and the model itself, lastly, we can set up this
[00:02:36.840 --> 00:02:38.760]   trainer, customize some of the options.
[00:02:38.760 --> 00:02:41.940]   Passing in that logger is something that we want to do.
[00:02:41.940 --> 00:02:46.920]   The trainer is what we use to configure a lot of the computation, the ML
[00:02:46.920 --> 00:02:48.260]   engineering kind of side of things.
[00:02:48.280 --> 00:02:52.640]   Asking for GPUs, asking for TPUs, saying that we're running in distributed
[00:02:52.640 --> 00:02:54.880]   setting, this is done in the trainer section.
[00:02:54.880 --> 00:02:59.080]   This is also where we're going to use that custom callback that we wrote.
[00:02:59.080 --> 00:03:01.080]   You provide a list of callbacks.
[00:03:01.080 --> 00:03:05.040]   And so we're going to provide our image prediction logger callback here.
[00:03:05.040 --> 00:03:07.920]   Here's where all of our hard work finally pays off.
[00:03:07.920 --> 00:03:12.800]   All of that logging stuff that we did is what is resulting in
[00:03:12.800 --> 00:03:14.600]   this dashboard that we have here.
[00:03:15.040 --> 00:03:19.960]   Here's those media examples, those particular inputs that we logged
[00:03:19.960 --> 00:03:21.320]   with that custom callback here.
[00:03:21.320 --> 00:03:24.360]   We can make that a little bigger if we want to look at more of them.
[00:03:24.360 --> 00:03:27.840]   We can see by the time that these images got logged, we're doing pretty well.
[00:03:27.840 --> 00:03:31.620]   It looks like we've made a mistake on this one here, predicted a three, but
[00:03:31.620 --> 00:03:35.920]   the label is actually a five, so we're not perfect yet, but it doesn't look
[00:03:35.920 --> 00:03:37.720]   like there's any gross errors happening.
[00:03:37.720 --> 00:03:39.560]   I didn't shuffle the labels on accident.
[00:03:39.560 --> 00:03:43.080]   I'm not miscalculating my accuracy or anything like that.
[00:03:43.080 --> 00:03:45.660]   (upbeat music)
[00:03:45.660 --> 00:03:48.240]   (upbeat music)
[00:03:48.240 --> 00:03:50.820]   (upbeat music)
[00:03:50.820 --> 00:03:53.400]   (upbeat music)
[00:03:53.400 --> 00:03:55.980]   (upbeat music)
[00:03:55.980 --> 00:03:58.560]   (upbeat music)
[00:03:59.400 --> 00:04:01.980]   (upbeat music)
[00:04:01.980 --> 00:04:03.960]   (smooth music)

