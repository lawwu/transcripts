
[00:00:00.000 --> 00:00:03.380]   The following is a conversation with Paola Arlotta.
[00:00:03.380 --> 00:00:06.400]   She's a professor of stem cell and regenerative biology
[00:00:06.400 --> 00:00:09.780]   at Harvard University and is interested in understanding
[00:00:09.780 --> 00:00:13.180]   the molecular laws that govern the birth, differentiation,
[00:00:13.180 --> 00:00:16.620]   and assembly of the human brain's cerebral cortex.
[00:00:16.620 --> 00:00:18.420]   She explores the complexity of the brain
[00:00:18.420 --> 00:00:21.020]   by studying and engineering elements
[00:00:21.020 --> 00:00:22.900]   of how the brain develops.
[00:00:22.900 --> 00:00:25.660]   This was a fascinating conversation to me.
[00:00:25.660 --> 00:00:28.580]   It's part of the Artificial Intelligence Podcast.
[00:00:28.580 --> 00:00:30.620]   If you enjoy it, subscribe on YouTube,
[00:00:30.620 --> 00:00:33.820]   give it five stars on iTunes, support it on Patreon,
[00:00:33.820 --> 00:00:35.820]   or simply connect with me on Twitter
[00:00:35.820 --> 00:00:39.980]   at Lex Friedman, spelled F-R-I-D-M-A-N.
[00:00:39.980 --> 00:00:43.140]   And I'd like to give a special thank you to Amy Jeffress
[00:00:43.140 --> 00:00:45.580]   for her support of the podcast on Patreon.
[00:00:45.580 --> 00:00:47.660]   She's an artist, and you should definitely check out
[00:00:47.660 --> 00:00:52.660]   her Instagram at lovetruthgood, three beautiful words.
[00:00:52.660 --> 00:00:55.640]   Your support means a lot and inspires me
[00:00:55.640 --> 00:00:57.740]   to keep the series going.
[00:00:57.740 --> 00:01:01.780]   And now, here's my conversation with Paola Arlotta.
[00:01:01.780 --> 00:01:05.340]   You studied the development of the human brain
[00:01:05.340 --> 00:01:08.620]   for many years, so let me ask you
[00:01:08.620 --> 00:01:10.540]   an out-of-the-box question first.
[00:01:10.540 --> 00:01:14.620]   How likely is it that there's intelligent life out there
[00:01:14.620 --> 00:01:17.180]   in the universe, outside of Earth,
[00:01:17.180 --> 00:01:19.340]   with something like the human brain?
[00:01:19.340 --> 00:01:20.780]   So I could put it another way.
[00:01:20.780 --> 00:01:24.340]   How unlikely is the human brain?
[00:01:24.340 --> 00:01:28.380]   How difficult is it to build a thing
[00:01:28.380 --> 00:01:30.420]   through the evolutionary process?
[00:01:30.420 --> 00:01:33.380]   - Well, it has happened here, right, on this planet?
[00:01:33.380 --> 00:01:34.660]   - Once, yes. - Once.
[00:01:34.660 --> 00:01:36.340]   (Paola laughs)
[00:01:36.340 --> 00:01:39.980]   So that simply tells you that it could, of course,
[00:01:39.980 --> 00:01:42.140]   happen again other places.
[00:01:42.140 --> 00:01:44.140]   It's only a matter of probability,
[00:01:44.140 --> 00:01:46.620]   what the probability that you would get a brain
[00:01:46.620 --> 00:01:51.220]   like the ones that we have, like the human brain.
[00:01:51.220 --> 00:01:53.980]   So how difficult is it to make the human brain?
[00:01:53.980 --> 00:01:57.900]   It's pretty difficult, but most importantly,
[00:01:57.900 --> 00:02:00.940]   I guess we know very little
[00:02:00.940 --> 00:02:04.420]   about how this process really happens,
[00:02:04.420 --> 00:02:06.300]   and there is a reason for that,
[00:02:06.300 --> 00:02:09.140]   actually multiple reasons for that.
[00:02:09.140 --> 00:02:13.380]   Most of what we know about how the mammalian brains,
[00:02:13.380 --> 00:02:17.060]   or the brain of mammals, develop comes from studying,
[00:02:17.060 --> 00:02:20.460]   in labs, other brains, not our own brain,
[00:02:20.460 --> 00:02:22.580]   the brain of mice, for example.
[00:02:22.580 --> 00:02:25.420]   But if I showed you a picture of a mouse brain,
[00:02:25.420 --> 00:02:28.380]   and then you put it next to a picture of a human brain,
[00:02:28.380 --> 00:02:31.140]   they don't look at all like each other.
[00:02:31.140 --> 00:02:33.020]   So they're very different,
[00:02:33.020 --> 00:02:35.300]   and therefore there is a limit
[00:02:35.300 --> 00:02:37.940]   to what you can learn about how the human brain is made
[00:02:37.940 --> 00:02:39.780]   by studying the mouse brain.
[00:02:39.780 --> 00:02:43.300]   There is a huge value in studying the mouse brain.
[00:02:43.300 --> 00:02:45.060]   There are many things that we have learned,
[00:02:45.060 --> 00:02:46.580]   but it's not the same thing.
[00:02:46.580 --> 00:02:49.220]   - So in having studied the human brain,
[00:02:49.220 --> 00:02:51.420]   or through the mouse and through other methodologies
[00:02:51.420 --> 00:02:54.700]   that we'll talk about, do you have a sense,
[00:02:54.700 --> 00:02:57.500]   I mean, you're one of the experts in the world,
[00:02:57.500 --> 00:03:01.100]   how much do you feel you know about the brain?
[00:03:01.100 --> 00:03:05.340]   And how often do you find yourself
[00:03:05.340 --> 00:03:07.780]   in awe of this mysterious thing?
[00:03:07.780 --> 00:03:12.180]   - Yeah, you pretty much find yourself in awe all the time.
[00:03:12.180 --> 00:03:15.300]   It's an amazing process.
[00:03:15.300 --> 00:03:17.940]   It's a process by which,
[00:03:17.940 --> 00:03:20.700]   by means that we don't fully understand,
[00:03:20.700 --> 00:03:23.620]   at the very beginning of embryogenesis,
[00:03:23.620 --> 00:03:26.260]   the structure called the neural tube
[00:03:26.260 --> 00:03:28.780]   literally self-assembles.
[00:03:28.780 --> 00:03:30.420]   And it happens in an embryo,
[00:03:30.420 --> 00:03:33.740]   and it can happen also from stem cells in a dish.
[00:03:33.740 --> 00:03:34.900]   Okay.
[00:03:34.900 --> 00:03:36.860]   And then from there,
[00:03:36.860 --> 00:03:39.860]   these stem cells that are present within the neural tube
[00:03:39.860 --> 00:03:42.220]   give rise to all of the thousands and thousands
[00:03:42.220 --> 00:03:45.060]   of different cell types that are present in the brain
[00:03:45.060 --> 00:03:46.540]   through time, right?
[00:03:47.540 --> 00:03:49.980]   With the interesting, very intriguing,
[00:03:49.980 --> 00:03:54.900]   interesting observation is that the time that it takes
[00:03:54.900 --> 00:03:58.780]   for the human brain to be made, it's human time.
[00:03:58.780 --> 00:04:02.180]   Meaning that for me and you,
[00:04:02.180 --> 00:04:05.300]   it took almost nine months of gestation to build a brain,
[00:04:05.300 --> 00:04:08.700]   and then another 20 years of learning postnatally
[00:04:08.700 --> 00:04:09.980]   to get the brain that we have today
[00:04:09.980 --> 00:04:12.140]   that allows us to this conversation.
[00:04:12.140 --> 00:04:16.780]   A mouse takes 20 days or so to--
[00:04:16.780 --> 00:04:19.220]   - So it's mouse time. - For an embryo to be born.
[00:04:19.220 --> 00:04:23.820]   And so the brain is built in a much shorter period of time.
[00:04:23.820 --> 00:04:27.220]   And the beauty of it is that if you take mouse stem cells
[00:04:27.220 --> 00:04:28.980]   and you put them in a culture dish,
[00:04:28.980 --> 00:04:33.340]   the brain organoid that you get from a mouse
[00:04:33.340 --> 00:04:37.660]   is formed faster than if you took human stem cells
[00:04:37.660 --> 00:04:39.140]   and put them in the dish
[00:04:39.140 --> 00:04:42.020]   and let them make a human brain organoid.
[00:04:42.020 --> 00:04:45.580]   - So the very developmental process is--
[00:04:45.580 --> 00:04:49.020]   - Controlled by the speed of the species.
[00:04:49.020 --> 00:04:54.020]   - Which means it's on purpose, it's not accidental.
[00:04:54.020 --> 00:04:58.380]   Or there is something in that temporal--
[00:04:58.380 --> 00:05:01.500]   - It's very, exactly, that is very important
[00:05:01.500 --> 00:05:04.060]   for us to get the brain we have.
[00:05:04.060 --> 00:05:07.340]   And we can speculate for why that is.
[00:05:07.340 --> 00:05:13.060]   It takes us a long time as human beings after we're born
[00:05:13.060 --> 00:05:16.100]   to learn all the things that we have to learn
[00:05:16.100 --> 00:05:18.020]   to have the adult brain.
[00:05:18.020 --> 00:05:20.220]   It's actually 20 years, think about it.
[00:05:20.220 --> 00:05:23.500]   From when a baby is born to when a teenager
[00:05:23.500 --> 00:05:27.260]   goes through puberty to adults, it's a long time.
[00:05:27.260 --> 00:05:30.340]   - Do you think you can maybe talk through
[00:05:30.340 --> 00:05:35.140]   the first few months and then on through the first 20 years
[00:05:35.140 --> 00:05:37.660]   and then for the rest of their lives,
[00:05:37.660 --> 00:05:41.180]   what is the development of the human brain look like?
[00:05:41.180 --> 00:05:42.620]   What are the different stages?
[00:05:42.620 --> 00:05:46.780]   - Yeah, at the beginning you have to build a brain, right?
[00:05:46.780 --> 00:05:48.900]   And the brain is made of cells.
[00:05:48.900 --> 00:05:49.780]   - What's the very beginning,
[00:05:49.780 --> 00:05:52.020]   which beginning are we talking about?
[00:05:52.020 --> 00:05:53.100]   - In the embryo.
[00:05:53.100 --> 00:05:53.940]   - In the embryo.
[00:05:53.940 --> 00:05:56.060]   - As the embryo is developing in the womb,
[00:05:56.060 --> 00:05:58.580]   in addition to making all of the other tissues
[00:05:58.580 --> 00:06:02.100]   of the embryo, the muscle, the heart, the blood,
[00:06:02.100 --> 00:06:05.020]   the embryo is also building the brain.
[00:06:05.020 --> 00:06:08.500]   And it builds from a very simple structure
[00:06:08.500 --> 00:06:10.860]   called the neural tube, which is basically
[00:06:10.860 --> 00:06:13.980]   nothing but a tube of cells that spans
[00:06:13.980 --> 00:06:16.980]   sort of the length of the embryo from the head
[00:06:16.980 --> 00:06:19.940]   all the way to the tail, let's say, of the embryo.
[00:06:19.940 --> 00:06:25.540]   And then in human beings, over many months of gestation,
[00:06:25.540 --> 00:06:30.540]   from that neural tube, which contains stem cell-like cells
[00:06:30.540 --> 00:06:35.540]   of the brain, you will make many, many other
[00:06:35.540 --> 00:06:37.020]   building blocks of the brain.
[00:06:37.020 --> 00:06:39.620]   So all of the other cell types,
[00:06:39.620 --> 00:06:41.900]   'cause there are many, many different types of cells
[00:06:41.900 --> 00:06:45.940]   in the brain, that will form specific structures
[00:06:45.940 --> 00:06:46.780]   of the brain.
[00:06:46.780 --> 00:06:49.260]   So you can think about embryonic development
[00:06:49.260 --> 00:06:51.620]   of the brain as just the time in which you are making
[00:06:51.620 --> 00:06:54.460]   the building blocks, the cells.
[00:06:54.460 --> 00:06:56.860]   - Are the stem cells relatively homogeneous,
[00:06:56.860 --> 00:06:59.300]   like uniform, or are they all different type?
[00:06:59.300 --> 00:07:00.180]   - That's a very good question.
[00:07:00.180 --> 00:07:01.260]   It's exactly how it works.
[00:07:01.260 --> 00:07:04.220]   You start with a more homogeneous,
[00:07:04.220 --> 00:07:09.140]   perhaps more multipotent type of stem cell.
[00:07:09.140 --> 00:07:09.980]   - What's multipotent?
[00:07:09.980 --> 00:07:13.540]   - Multipotent means that it has the potential
[00:07:13.540 --> 00:07:17.380]   to make many, many different types of other cells.
[00:07:17.380 --> 00:07:19.820]   And then with time, these progenitors
[00:07:19.820 --> 00:07:22.860]   become more heterogeneous, which means more diverse.
[00:07:22.860 --> 00:07:26.020]   There are gonna be many different types of the stem cells.
[00:07:26.020 --> 00:07:28.780]   And also, they will give rise to progeny,
[00:07:28.780 --> 00:07:31.780]   to other cells that are not stem cells,
[00:07:31.780 --> 00:07:33.340]   that are specific cells of the brain,
[00:07:33.340 --> 00:07:36.100]   that are very different from the mother stem cell.
[00:07:36.100 --> 00:07:38.860]   And now you think about this process of making cells
[00:07:38.860 --> 00:07:41.580]   from the stem cells over many, many months
[00:07:41.580 --> 00:07:43.860]   of development for humans.
[00:07:43.860 --> 00:07:46.220]   And what you're doing, you're building the cells
[00:07:46.220 --> 00:07:48.260]   that physically make the brain,
[00:07:48.260 --> 00:07:52.460]   and then you arrange them in specific structures
[00:07:52.460 --> 00:07:55.460]   that are present in the final brain.
[00:07:55.460 --> 00:07:58.740]   So you can think about the embryonic development
[00:07:58.740 --> 00:08:02.180]   of the brain as the time where you're building the bricks.
[00:08:02.180 --> 00:08:05.580]   You're putting the bricks together to form buildings,
[00:08:05.580 --> 00:08:08.180]   structures, regions of the brain,
[00:08:08.180 --> 00:08:10.380]   and where you make the connections
[00:08:10.380 --> 00:08:13.100]   between these many different type of cells,
[00:08:13.100 --> 00:08:15.300]   especially nerve cells, neurons, right,
[00:08:15.300 --> 00:08:19.300]   that transmit action potentials and electricity.
[00:08:19.300 --> 00:08:21.380]   - I've heard you also say somewhere, I think,
[00:08:21.380 --> 00:08:22.300]   correct me if I'm wrong,
[00:08:22.300 --> 00:08:25.180]   that the order of the way this builds matters.
[00:08:25.180 --> 00:08:26.100]   - Oh, yes.
[00:08:26.100 --> 00:08:29.900]   If you are an engineer and you think about development,
[00:08:29.900 --> 00:08:34.900]   you can think of it as, well, I could also take all the cells
[00:08:34.900 --> 00:08:38.020]   and bring them all together into a brain in the end.
[00:08:38.020 --> 00:08:40.380]   But development is much more than that.
[00:08:40.380 --> 00:08:43.900]   So the cells are made in a very specific order
[00:08:43.900 --> 00:08:47.420]   that subserve the final product that you need to get.
[00:08:47.420 --> 00:08:49.940]   And so, for example, all of the nerve cells,
[00:08:49.940 --> 00:08:52.260]   the neurons, are made first,
[00:08:52.260 --> 00:08:54.420]   and all of the supportive cells of the neurons,
[00:08:54.420 --> 00:08:56.820]   like the glia, is made later.
[00:08:56.820 --> 00:08:58.420]   And there is a reason for that,
[00:08:58.420 --> 00:09:02.140]   because they have to assemble together in specific ways.
[00:09:02.140 --> 00:09:03.380]   But you also may say, well,
[00:09:03.380 --> 00:09:05.740]   why don't we just put them all together in the end?
[00:09:05.740 --> 00:09:08.980]   It's because as they develop next to each other,
[00:09:08.980 --> 00:09:11.300]   they influence their own development.
[00:09:11.300 --> 00:09:13.220]   So it's a different thing for a glia
[00:09:13.220 --> 00:09:15.420]   to be made alone in a dish,
[00:09:15.420 --> 00:09:19.380]   than a glia cell be made in a developing embryo
[00:09:19.380 --> 00:09:21.340]   with all these other cells around it
[00:09:21.340 --> 00:09:23.700]   that produce all these other signals.
[00:09:23.700 --> 00:09:25.900]   - First of all, that's mind-blowing,
[00:09:25.900 --> 00:09:27.820]   this development process.
[00:09:27.820 --> 00:09:29.780]   From my perspective in artificial intelligence,
[00:09:29.780 --> 00:09:33.500]   you often think of how incredible the final product is,
[00:09:33.500 --> 00:09:35.220]   the final product, the brain.
[00:09:35.220 --> 00:09:38.460]   But you're making me realize that the final product
[00:09:38.460 --> 00:09:42.060]   is just, the beautiful thing
[00:09:42.060 --> 00:09:44.460]   is the actual development process.
[00:09:44.460 --> 00:09:49.460]   Do we know the code that drives that development?
[00:09:49.460 --> 00:09:51.980]   - Yeah.
[00:09:51.980 --> 00:09:53.860]   - Do we have any sense?
[00:09:53.860 --> 00:09:55.820]   - First of all, thank you for saying
[00:09:55.820 --> 00:09:59.300]   that it's really the formation of the brain.
[00:09:59.300 --> 00:10:00.700]   It's really its development,
[00:10:00.700 --> 00:10:05.140]   it's this incredibly choreographed dance
[00:10:05.140 --> 00:10:07.500]   that happens the same way every time
[00:10:07.500 --> 00:10:10.580]   each one of us builds the brain, right?
[00:10:10.580 --> 00:10:12.660]   And that builds an organ that allows us
[00:10:12.660 --> 00:10:14.900]   to do what we're doing today, right?
[00:10:14.900 --> 00:10:16.380]   That is mind-blowing,
[00:10:16.380 --> 00:10:18.900]   and this is why developmental neurobiologists
[00:10:18.900 --> 00:10:21.900]   never get tired of studying that.
[00:10:21.900 --> 00:10:23.820]   Now you're asking about the code.
[00:10:23.820 --> 00:10:24.900]   What drives this?
[00:10:24.900 --> 00:10:26.500]   How is this done?
[00:10:26.500 --> 00:10:29.740]   Well, it's millions of years of evolution,
[00:10:29.740 --> 00:10:33.180]   of really fine tuning gene expression programs
[00:10:33.180 --> 00:10:37.460]   that allow certain cells to be made at a certain time
[00:10:37.460 --> 00:10:41.700]   and to become a certain cell type,
[00:10:41.700 --> 00:10:46.700]   but also mechanical forces of pressure, bending.
[00:10:46.700 --> 00:10:50.340]   This embryo is not just, it will not stay a tube,
[00:10:50.340 --> 00:10:52.020]   this brain for very long.
[00:10:52.020 --> 00:10:54.900]   At some point, this tube in the front of the embryo
[00:10:54.900 --> 00:10:58.180]   will expand to make the primordium of the brain, right?
[00:10:58.180 --> 00:11:02.860]   Now the forces that control, that the cells feel,
[00:11:02.860 --> 00:11:04.940]   and this is another beautiful thing,
[00:11:04.940 --> 00:11:06.820]   the very force that they feel,
[00:11:06.820 --> 00:11:10.260]   which is different from a week before or a week ago,
[00:11:10.260 --> 00:11:11.100]   will tell the cell,
[00:11:11.100 --> 00:11:13.620]   "Oh, you're being squished in a certain way.
[00:11:13.620 --> 00:11:16.540]   "Begin to produce these new genes
[00:11:16.540 --> 00:11:18.380]   "because now you are at the corner,
[00:11:18.380 --> 00:11:23.180]   "or you are in a stretch of cells," or whatever it is.
[00:11:23.180 --> 00:11:26.020]   And so that mechanical physical force
[00:11:26.020 --> 00:11:29.500]   shapes the fate of the cell as well.
[00:11:29.500 --> 00:11:30.340]   So-
[00:11:30.340 --> 00:11:31.940]   It's not only chemical, it's also mechanical.
[00:11:31.940 --> 00:11:33.020]   - It's mechanical.
[00:11:33.020 --> 00:11:34.520]   So from my perspective,
[00:11:34.520 --> 00:11:39.520]   biology is this incredibly complex mess, gooey mess.
[00:11:39.520 --> 00:11:43.460]   So you're saying mechanical forces.
[00:11:43.460 --> 00:11:44.300]   - Yes.
[00:11:44.300 --> 00:11:47.860]   - How different is a computer
[00:11:47.860 --> 00:11:52.180]   or any kind of mechanical machine that we humans build
[00:11:52.180 --> 00:11:53.900]   and the biological systems?
[00:11:53.900 --> 00:11:54.740]   - Yeah.
[00:11:54.740 --> 00:11:56.740]   - 'Cause you've worked a lot with biological systems.
[00:11:56.740 --> 00:11:57.580]   - Yes.
[00:11:57.580 --> 00:11:59.980]   - Are they as much of a mess as it seems
[00:12:00.740 --> 00:12:03.580]   from a perspective of a mechanical engineer?
[00:12:03.580 --> 00:12:04.460]   - Yeah.
[00:12:04.460 --> 00:12:08.420]   They are much more prone
[00:12:08.420 --> 00:12:11.740]   to taking alternative routes, right?
[00:12:11.740 --> 00:12:13.080]   So if you,
[00:12:13.080 --> 00:12:18.260]   we go back to printing a brain versus developing a brain.
[00:12:18.260 --> 00:12:20.500]   Of course, if you print a brain,
[00:12:20.500 --> 00:12:23.100]   given that you start with the same building blocks,
[00:12:23.100 --> 00:12:24.020]   the same cells,
[00:12:24.020 --> 00:12:28.660]   you could potentially print it the same way every time.
[00:12:28.660 --> 00:12:32.540]   But that final brain may not work the same way
[00:12:32.540 --> 00:12:34.480]   as a brain built during development does
[00:12:34.480 --> 00:12:38.740]   because the very same building blocks that you're using
[00:12:38.740 --> 00:12:41.500]   developed in a completely different environment, right?
[00:12:41.500 --> 00:12:43.060]   It was not the environment of the brain.
[00:12:43.060 --> 00:12:45.900]   Therefore, they're gonna be different just by definition.
[00:12:45.900 --> 00:12:50.500]   So if you instead use development to build,
[00:12:50.500 --> 00:12:52.740]   let's say a brain organoid,
[00:12:52.740 --> 00:12:54.860]   which maybe we will be talking about in a few minutes.
[00:12:54.860 --> 00:12:55.860]   - For sure.
[00:12:55.860 --> 00:12:57.020]   Those things are fascinating.
[00:12:57.020 --> 00:12:57.860]   - Yes.
[00:12:57.860 --> 00:13:02.020]   So if you use processes of development,
[00:13:02.020 --> 00:13:03.380]   then when you watch it,
[00:13:03.380 --> 00:13:06.460]   you can see that sometimes things can go wrong
[00:13:06.460 --> 00:13:07.540]   in some organoids.
[00:13:07.540 --> 00:13:10.860]   And by wrong, I mean different one organoid from the next.
[00:13:10.860 --> 00:13:13.100]   While if you think about that embryo,
[00:13:13.100 --> 00:13:14.820]   it always goes right.
[00:13:14.820 --> 00:13:18.940]   So this development, for as complex as it is,
[00:13:18.940 --> 00:13:21.420]   every time a baby is born has,
[00:13:21.420 --> 00:13:23.700]   with very few exceptions,
[00:13:23.700 --> 00:13:26.180]   the brain is like the next baby.
[00:13:26.180 --> 00:13:31.180]   But it's not the same if you develop it in a dish.
[00:13:31.180 --> 00:13:33.820]   And first of all, we don't even develop a brain,
[00:13:33.820 --> 00:13:36.100]   you develop something much simpler in the dish.
[00:13:36.100 --> 00:13:39.660]   But there are more options for building things differently,
[00:13:39.660 --> 00:13:42.940]   which really tells you that evolution
[00:13:42.940 --> 00:13:47.940]   has played a really tight game here
[00:13:47.940 --> 00:13:53.060]   for how in the end the brain is built in vivo.
[00:13:53.060 --> 00:13:55.380]   - So just a quick, maybe dumb question,
[00:13:55.380 --> 00:13:58.340]   but it seems like this is not,
[00:13:58.340 --> 00:14:01.100]   the building process is not a dictatorship.
[00:14:01.100 --> 00:14:03.340]   It seems like there's not a centralized,
[00:14:03.340 --> 00:14:07.420]   like high level mechanism that says,
[00:14:07.420 --> 00:14:10.300]   okay, this cell built itself the wrong way,
[00:14:10.300 --> 00:14:11.540]   I'm gonna kill it.
[00:14:11.540 --> 00:14:15.460]   It seems like there's a really strong distributed mechanism.
[00:14:15.460 --> 00:14:17.500]   Is that in your sense?
[00:14:17.500 --> 00:14:20.940]   - There are a lot of possibilities, right?
[00:14:20.940 --> 00:14:25.100]   And if you think about, for example, different species,
[00:14:25.100 --> 00:14:26.780]   building their brain,
[00:14:26.780 --> 00:14:28.900]   each brain is a little bit different.
[00:14:28.900 --> 00:14:31.060]   So the brain of a lizard is very different
[00:14:31.060 --> 00:14:35.540]   from that of a chicken, from that of one of us,
[00:14:35.540 --> 00:14:38.060]   and so on and so forth, and still is a brain,
[00:14:38.060 --> 00:14:40.980]   but it was built differently,
[00:14:40.980 --> 00:14:43.300]   starting from stem cells
[00:14:43.300 --> 00:14:46.020]   that pretty much had the same potential.
[00:14:46.020 --> 00:14:49.420]   But in the end, evolution builds different brains
[00:14:49.420 --> 00:14:50.900]   in different species,
[00:14:50.900 --> 00:14:54.020]   because that serves in a way the purpose of that species
[00:14:54.020 --> 00:14:55.980]   and the wellbeing of that organism.
[00:14:55.980 --> 00:14:56.820]   - Right.
[00:14:56.820 --> 00:15:00.740]   - And so there are many possibilities,
[00:15:00.740 --> 00:15:02.900]   but then there is a way,
[00:15:02.900 --> 00:15:04.860]   and you were talking about a code.
[00:15:04.860 --> 00:15:07.500]   Nobody knows what the entire code of development is.
[00:15:07.500 --> 00:15:08.660]   Of course we don't.
[00:15:08.660 --> 00:15:13.380]   We know bits and pieces of very specific aspects
[00:15:13.380 --> 00:15:14.500]   of development of the brain,
[00:15:14.500 --> 00:15:17.060]   what genes are involved to make a certain cell types,
[00:15:17.060 --> 00:15:18.540]   how those two cells interact
[00:15:18.540 --> 00:15:20.380]   to make the next level structure.
[00:15:20.380 --> 00:15:22.820]   That we might know, but the entirety of it,
[00:15:22.820 --> 00:15:26.180]   how it's so well controlled, it's really mind blowing.
[00:15:26.180 --> 00:15:29.140]   - So in the first two months in the embryo,
[00:15:29.140 --> 00:15:32.740]   or whatever, the first few weeks, months, months.
[00:15:32.740 --> 00:15:37.140]   So yeah, the building blocks are constructed,
[00:15:37.140 --> 00:15:40.420]   the actual, the different regions of the brain, I guess,
[00:15:40.420 --> 00:15:42.740]   and the nervous system.
[00:15:42.740 --> 00:15:44.340]   - Well, this continues way longer
[00:15:44.340 --> 00:15:46.500]   than just the first few months.
[00:15:46.500 --> 00:15:50.460]   So over the very first few months,
[00:15:50.460 --> 00:15:52.060]   you build a lot of these cells,
[00:15:52.060 --> 00:15:56.420]   but then there is continuous building of new cell types
[00:15:56.420 --> 00:15:58.420]   all the way through birth.
[00:15:58.420 --> 00:16:00.420]   And then even postnatally,
[00:16:00.420 --> 00:16:03.980]   I don't know if you've ever heard of myelin.
[00:16:03.980 --> 00:16:06.660]   Myelin is this sort of insulation
[00:16:06.660 --> 00:16:09.780]   that is built around the cables of the neurons
[00:16:09.780 --> 00:16:12.180]   so that the electricity can go really fast from-
[00:16:12.180 --> 00:16:13.380]   - The axons, I guess they're called.
[00:16:13.380 --> 00:16:15.980]   - The axons, they're called axons, exactly.
[00:16:15.980 --> 00:16:20.980]   And so as human beings, we myelinate our cells
[00:16:21.980 --> 00:16:24.300]   postnatally.
[00:16:24.300 --> 00:16:28.700]   A kid, a six-year-old kid has barely started
[00:16:28.700 --> 00:16:31.860]   the process of making the mature oligodendrocytes,
[00:16:31.860 --> 00:16:33.620]   which are the cells that then eventually
[00:16:33.620 --> 00:16:36.580]   will wrap the axons into myelin.
[00:16:36.580 --> 00:16:38.940]   And this will continue, believe it or not,
[00:16:38.940 --> 00:16:42.420]   until we are about 25, 30 years old.
[00:16:42.420 --> 00:16:45.300]   So there is a continuous process of maturation
[00:16:45.300 --> 00:16:46.580]   and tweaking and additions,
[00:16:46.580 --> 00:16:50.620]   and also in response to what we do.
[00:16:50.620 --> 00:16:53.940]   - I remember taking AP Biology in high school,
[00:16:53.940 --> 00:16:57.060]   and in the textbook, it said that,
[00:16:57.060 --> 00:16:58.580]   I'm going by memory here,
[00:16:58.580 --> 00:17:01.980]   that scientists disagree on the purpose of myelin
[00:17:01.980 --> 00:17:04.740]   in the brain.
[00:17:04.740 --> 00:17:06.340]   Is that totally wrong?
[00:17:06.340 --> 00:17:07.300]   (both laughing)
[00:17:07.300 --> 00:17:10.540]   So I guess it speeds up the,
[00:17:10.540 --> 00:17:13.220]   okay, I might be wrong here,
[00:17:13.220 --> 00:17:14.780]   but I guess it speeds up the electricity
[00:17:14.780 --> 00:17:17.140]   traveling down the axon or something?
[00:17:17.140 --> 00:17:17.980]   - Yeah.
[00:17:18.300 --> 00:17:20.140]   That's the most sort of canonical,
[00:17:20.140 --> 00:17:21.780]   and definitely that's the case.
[00:17:21.780 --> 00:17:24.860]   So you have to imagine an axon,
[00:17:24.860 --> 00:17:27.660]   and you can think about it as a cable of some type
[00:17:27.660 --> 00:17:29.380]   with electricity going through.
[00:17:29.380 --> 00:17:34.380]   And what myelin does, by insulating the outside,
[00:17:34.380 --> 00:17:36.340]   I should say there are tracts of myelin
[00:17:36.340 --> 00:17:39.620]   and pieces of axons that are naked without myelin.
[00:17:39.620 --> 00:17:41.740]   And so by having the insulation,
[00:17:41.740 --> 00:17:43.980]   the electricity, instead of going straight through the cable,
[00:17:43.980 --> 00:17:47.220]   it will jump over a piece of myelin, right,
[00:17:47.220 --> 00:17:49.940]   to the next naked little piece and jump again.
[00:17:49.940 --> 00:17:52.700]   And therefore, that's the idea that you go faster.
[00:17:52.700 --> 00:17:58.700]   And it was always thought that in order to build
[00:17:58.700 --> 00:18:01.820]   a big brain, a big nervous system,
[00:18:01.820 --> 00:18:04.140]   in order to have a nervous system
[00:18:04.140 --> 00:18:06.420]   that can do very complex type of things,
[00:18:06.420 --> 00:18:07.820]   then you need a lot of myelin
[00:18:07.820 --> 00:18:10.820]   because you wanna go fast with this information
[00:18:10.820 --> 00:18:13.180]   from point A to point B.
[00:18:13.180 --> 00:18:17.100]   Well, a few years ago, maybe five years ago
[00:18:17.100 --> 00:18:20.660]   or so, we discovered that some of the most evolved,
[00:18:20.660 --> 00:18:23.140]   which means the newest type of neurons
[00:18:23.140 --> 00:18:26.500]   that we have as non-human primates, as human beings
[00:18:26.500 --> 00:18:29.060]   in the top of our cerebral cortex,
[00:18:29.060 --> 00:18:30.860]   which should be the neurons that do some
[00:18:30.860 --> 00:18:33.180]   of the most complex things that we do,
[00:18:33.180 --> 00:18:37.020]   well, those have axons that have very little myelin.
[00:18:37.020 --> 00:18:38.460]   - Wow.
[00:18:38.460 --> 00:18:42.020]   - And they have very interesting ways
[00:18:42.020 --> 00:18:44.380]   in which they put this myelin on their axons,
[00:18:44.380 --> 00:18:45.500]   you know, a little piece here,
[00:18:45.500 --> 00:18:48.580]   then a long track with no myelin, another chunk there,
[00:18:48.580 --> 00:18:50.500]   and some don't have myelin at all.
[00:18:50.500 --> 00:18:53.020]   So now you have to explain
[00:18:53.020 --> 00:18:57.860]   where we're going with evolution.
[00:18:57.860 --> 00:18:59.380]   And if you think about it,
[00:18:59.380 --> 00:19:01.260]   perhaps as an electrical engineer,
[00:19:01.260 --> 00:19:05.900]   when I looked at it, I initially thought,
[00:19:05.900 --> 00:19:07.580]   and I'm a developmental neurobiologist,
[00:19:07.580 --> 00:19:10.780]   I thought maybe this is what we see now,
[00:19:10.780 --> 00:19:14.100]   but if we give evolution another few million years,
[00:19:14.140 --> 00:19:16.500]   we'll see a lot of myelin on these neurons too.
[00:19:16.500 --> 00:19:18.860]   But I actually think now that that's instead
[00:19:18.860 --> 00:19:21.060]   the future of the brain. - Less myelin.
[00:19:21.060 --> 00:19:24.700]   - Less myelin might allow for more flexibility
[00:19:24.700 --> 00:19:26.780]   on what you do with your axons,
[00:19:26.780 --> 00:19:28.540]   and therefore more complicated
[00:19:28.540 --> 00:19:32.180]   and unpredictable type of functions,
[00:19:32.180 --> 00:19:34.300]   which is also a bit mind-blowing.
[00:19:34.300 --> 00:19:36.580]   - Well, so it seems like it's controlling
[00:19:36.580 --> 00:19:38.500]   the timing of the signal,
[00:19:38.500 --> 00:19:42.940]   so in the timing, you can encode a lot of information.
[00:19:42.940 --> 00:19:43.780]   - Yeah.
[00:19:43.780 --> 00:19:44.700]   - So the brain-
[00:19:44.700 --> 00:19:48.620]   - The timing, the chemistry of that little piece of axon,
[00:19:48.620 --> 00:19:52.180]   perhaps it's a dynamic process where the myelin can move.
[00:19:52.180 --> 00:19:57.180]   Now you see how many layers of variability you can add,
[00:19:57.180 --> 00:19:58.980]   and that's actually really good
[00:19:58.980 --> 00:20:02.340]   if you're trying to come up with a new function
[00:20:02.340 --> 00:20:06.620]   or a new capability or something unpredictable in a way.
[00:20:06.620 --> 00:20:08.260]   - So we're gonna jump around a little bit,
[00:20:08.260 --> 00:20:12.900]   but the old question of how much is nature
[00:20:12.900 --> 00:20:14.580]   and how much is nurture,
[00:20:14.580 --> 00:20:17.380]   in terms of this incredible thing
[00:20:17.380 --> 00:20:19.060]   after the development is over,
[00:20:19.060 --> 00:20:25.300]   we seem to be kind of somewhat smart, intelligent,
[00:20:25.300 --> 00:20:28.340]   cognition, consciousness, all of these things
[00:20:28.340 --> 00:20:32.100]   are just incredible ability to reason and so on, emerge.
[00:20:32.100 --> 00:20:36.020]   In your sense, how much is in the hardware, in the nature,
[00:20:36.020 --> 00:20:39.140]   and how much is in the nurture,
[00:20:39.140 --> 00:20:41.100]   is learned through with our parents,
[00:20:41.100 --> 00:20:42.540]   through interacting with the environment and so on?
[00:20:42.540 --> 00:20:43.820]   - It's really both, right?
[00:20:43.820 --> 00:20:45.060]   If you think about it,
[00:20:45.060 --> 00:20:48.060]   so we are born with a brain as babies
[00:20:48.060 --> 00:20:53.060]   that has most of his cells and most of his structures,
[00:20:53.060 --> 00:20:57.940]   and that will take a few years to grow,
[00:20:57.940 --> 00:21:00.660]   to add more, to be better,
[00:21:00.660 --> 00:21:04.140]   but really then we have this 20 years
[00:21:04.140 --> 00:21:07.060]   of interacting with the environment around us.
[00:21:07.060 --> 00:21:10.820]   And so what that brain that was so perfectly built
[00:21:10.820 --> 00:21:15.820]   or imperfectly built due to our genetic cues
[00:21:15.820 --> 00:21:20.180]   will then be used to incorporate the environment
[00:21:20.180 --> 00:21:22.740]   in its farther maturation and development.
[00:21:22.740 --> 00:21:26.980]   And so your experiences do shape your brain.
[00:21:26.980 --> 00:21:27.900]   I mean, we know that,
[00:21:27.900 --> 00:21:31.940]   like if you and I may have had a different childhood
[00:21:31.940 --> 00:21:35.060]   or a different, we have been going to different schools,
[00:21:35.060 --> 00:21:36.460]   we have been learning different things,
[00:21:36.460 --> 00:21:38.780]   and our brain is a little bit different because of that,
[00:21:38.780 --> 00:21:41.140]   we behave differently because of that.
[00:21:41.140 --> 00:21:44.020]   And so, especially postnatally,
[00:21:44.020 --> 00:21:46.020]   experience is extremely important.
[00:21:46.020 --> 00:21:48.780]   We are born with a plastic brain.
[00:21:48.780 --> 00:21:51.460]   What that means is a brain that is able to change
[00:21:51.460 --> 00:21:54.260]   in response to stimuli.
[00:21:54.260 --> 00:21:56.340]   They can be sensory.
[00:21:56.340 --> 00:22:01.020]   So perhaps some of the most illuminating studies
[00:22:01.020 --> 00:22:02.500]   that were done were studies
[00:22:02.500 --> 00:22:06.740]   in which the sensory organs were not working, right?
[00:22:06.740 --> 00:22:09.540]   Like if you are born with eyes that don't work,
[00:22:09.540 --> 00:22:12.540]   then your very brain, the piece of the brain
[00:22:12.540 --> 00:22:14.620]   that normally would process vision,
[00:22:14.620 --> 00:22:19.620]   the visual cortex, develops postnatally differently,
[00:22:19.620 --> 00:22:23.500]   and it might be used to do something different, right?
[00:22:23.500 --> 00:22:25.580]   So that's the most extreme.
[00:22:25.580 --> 00:22:27.420]   - The plasticity of the brain, I guess,
[00:22:27.420 --> 00:22:29.420]   is the magic hardware that it,
[00:22:29.420 --> 00:22:32.900]   and then its flexibility in all forms
[00:22:32.900 --> 00:22:36.260]   is what enables the learning postnatally.
[00:22:36.260 --> 00:22:39.220]   Can you talk about organoids?
[00:22:39.220 --> 00:22:40.860]   What are they? - Yes.
[00:22:40.860 --> 00:22:44.300]   - And how can you use them to help us understand the brain
[00:22:44.300 --> 00:22:45.700]   and the development of the brain?
[00:22:45.700 --> 00:22:47.300]   - This is very, very important.
[00:22:47.300 --> 00:22:49.860]   So the first thing I'd like to say,
[00:22:49.860 --> 00:22:51.500]   and please skip this in the video.
[00:22:51.500 --> 00:22:52.660]   (laughing)
[00:22:52.660 --> 00:22:56.020]   The first thing I'd like to say is that an organoid,
[00:22:56.020 --> 00:23:00.020]   a brain organoid, is not the same as a brain, okay?
[00:23:00.020 --> 00:23:03.620]   It's a fundamental distinction.
[00:23:03.620 --> 00:23:08.540]   It's a system, a cellular system,
[00:23:08.540 --> 00:23:12.140]   that one can develop in the culture dish,
[00:23:12.140 --> 00:23:14.100]   starting from stem cells,
[00:23:14.100 --> 00:23:17.140]   that will mimic some aspects
[00:23:17.140 --> 00:23:21.340]   of the development of the brain, but not all of it.
[00:23:21.340 --> 00:23:23.100]   They are very small.
[00:23:23.100 --> 00:23:26.420]   Maximum, they become about four to five millimeters
[00:23:26.420 --> 00:23:27.860]   in diameters.
[00:23:27.860 --> 00:23:32.860]   They are much simpler than our brain, of course,
[00:23:33.380 --> 00:23:36.460]   but yet they are the only system
[00:23:36.460 --> 00:23:39.500]   where we can literally watch a process
[00:23:39.500 --> 00:23:42.380]   of human brain development unfold.
[00:23:42.380 --> 00:23:45.060]   And by watch, I mean study it.
[00:23:45.060 --> 00:23:47.980]   Remember when I told you that we can't understand
[00:23:47.980 --> 00:23:49.980]   everything about development in our own brain
[00:23:49.980 --> 00:23:51.460]   by studying a mouse?
[00:23:51.460 --> 00:23:54.100]   Well, we can study the actual process of development
[00:23:54.100 --> 00:23:56.220]   of the human brain because it all happens in utero,
[00:23:56.220 --> 00:23:59.260]   so we will never have access to that process, ever.
[00:24:00.300 --> 00:24:04.220]   And therefore, this is our next best thing,
[00:24:04.220 --> 00:24:08.300]   like a bunch of stem cells that can be coaxed
[00:24:08.300 --> 00:24:11.620]   into starting a process of neural tube formation.
[00:24:11.620 --> 00:24:14.580]   Remember that tube that is made by the embryo, Leon?
[00:24:14.580 --> 00:24:17.060]   And from there, a lot of the cell types
[00:24:17.060 --> 00:24:20.620]   that are present within the brain,
[00:24:20.620 --> 00:24:24.900]   and you can simply watch it and study it,
[00:24:24.900 --> 00:24:28.580]   but you can also think about diseases
[00:24:28.580 --> 00:24:30.780]   where development of the brain
[00:24:30.780 --> 00:24:34.100]   does not proceed normally, right, properly.
[00:24:34.100 --> 00:24:35.820]   Think about neurodevelopmental diseases
[00:24:35.820 --> 00:24:38.220]   that are many, many different types.
[00:24:38.220 --> 00:24:40.100]   Think about autism spectrum disorders
[00:24:40.100 --> 00:24:42.540]   that are also many different types of autism.
[00:24:42.540 --> 00:24:45.220]   So there, you could take a stem cell,
[00:24:45.220 --> 00:24:47.460]   which really means either a sample of blood
[00:24:47.460 --> 00:24:50.860]   or a sample of skin from the patient,
[00:24:50.860 --> 00:24:54.300]   make a stem cell, and then with that stem cell,
[00:24:54.300 --> 00:24:57.380]   watch a process of formation of a brain organoid
[00:24:57.380 --> 00:25:00.540]   of that person, with that genetics,
[00:25:00.540 --> 00:25:02.180]   with that genetic code in it,
[00:25:02.180 --> 00:25:05.780]   and you can ask, what is this genetic code doing
[00:25:05.780 --> 00:25:08.740]   to some aspects of development of the brain?
[00:25:08.740 --> 00:25:11.980]   And for the first time, you may come to solutions
[00:25:11.980 --> 00:25:15.980]   like what cells are involved in autism, right?
[00:25:15.980 --> 00:25:17.300]   - So many questions around this.
[00:25:17.300 --> 00:25:20.460]   So if you take this human stem cell
[00:25:20.460 --> 00:25:23.020]   for that particular person with that genetic code,
[00:25:23.020 --> 00:25:26.500]   and you try to build an organoid,
[00:25:26.500 --> 00:25:28.820]   how often will it look similar?
[00:25:28.820 --> 00:25:31.100]   What's the-- - Yeah.
[00:25:31.100 --> 00:25:33.260]   - Yeah, so-- - Reproducibility.
[00:25:33.260 --> 00:25:36.620]   - Yes, or how much variability is the flip side of that.
[00:25:36.620 --> 00:25:40.260]   - Yeah, so there is much more variability
[00:25:40.260 --> 00:25:44.500]   in building organoids than there is in building brain.
[00:25:44.500 --> 00:25:47.260]   It's really true that the majority of us,
[00:25:47.260 --> 00:25:49.540]   when we are born as babies,
[00:25:49.540 --> 00:25:52.420]   our brains look a lot like each other.
[00:25:52.420 --> 00:25:54.860]   This is the magic that the embryo does,
[00:25:54.860 --> 00:25:57.620]   where it builds a brain in the context of a body,
[00:25:57.620 --> 00:26:01.220]   and there is very little variability there.
[00:26:01.220 --> 00:26:02.260]   There is disease, of course,
[00:26:02.260 --> 00:26:03.940]   but in general, a little variability.
[00:26:03.940 --> 00:26:05.540]   When you build an organoid,
[00:26:05.540 --> 00:26:09.460]   we don't have the full code for how this is done.
[00:26:09.460 --> 00:26:13.380]   And so in part, the organoid somewhat builds itself,
[00:26:13.380 --> 00:26:15.500]   because there are some structures of the brain
[00:26:15.500 --> 00:26:17.180]   that the cells know how to make.
[00:26:17.180 --> 00:26:21.780]   And another part comes from the investigator,
[00:26:21.780 --> 00:26:26.100]   the scientist, adding to the media factors
[00:26:26.100 --> 00:26:27.940]   that we know in the mouse, for example,
[00:26:27.940 --> 00:26:30.660]   would foster a certain step of development.
[00:26:30.660 --> 00:26:33.140]   But it's very limited.
[00:26:33.140 --> 00:26:36.060]   And so as a result,
[00:26:36.060 --> 00:26:38.100]   the kind of product you get in the end
[00:26:38.100 --> 00:26:39.620]   is much more reductionist,
[00:26:39.620 --> 00:26:42.580]   is much more simple than what you get in vivo.
[00:26:42.580 --> 00:26:46.100]   It mimics early events of development as of today,
[00:26:46.100 --> 00:26:49.020]   and it doesn't build very complex type of anatomy
[00:26:49.020 --> 00:26:51.700]   and structure, does not as of today.
[00:26:51.700 --> 00:26:54.860]   Which happens instead in vivo.
[00:26:54.860 --> 00:26:59.060]   And also the variability that you see
[00:26:59.060 --> 00:27:01.380]   one organoid to the next
[00:27:01.380 --> 00:27:03.580]   tends to be higher than when you compare
[00:27:03.580 --> 00:27:05.500]   an embryo to the next.
[00:27:05.500 --> 00:27:07.340]   - So, okay, then the next question is,
[00:27:07.340 --> 00:27:10.380]   how hard and maybe another flip side of that,
[00:27:10.380 --> 00:27:14.900]   expensive is it to go from one stem cell to an organoid?
[00:27:14.900 --> 00:27:16.700]   How many can you build in a life,
[00:27:16.700 --> 00:27:18.420]   'cause it sounds very complicated.
[00:27:18.420 --> 00:27:23.420]   - It's work, definitely, and it's money, definitely.
[00:27:23.420 --> 00:27:26.740]   But you can really grow
[00:27:26.740 --> 00:27:29.820]   a very high number of these organoids.
[00:27:29.820 --> 00:27:31.580]   You know, can go, perhaps,
[00:27:31.580 --> 00:27:33.100]   I told you the maximum they become
[00:27:33.100 --> 00:27:34.580]   about five millimeters in diameter.
[00:27:34.580 --> 00:27:35.420]   - Yeah, which is how many cells, sorry to ask.
[00:27:35.420 --> 00:27:39.180]   - So this is about the size of a tiny, tiny, you know,
[00:27:39.180 --> 00:27:40.740]   raisin. - Yeah.
[00:27:40.740 --> 00:27:43.180]   - Or perhaps the seed of an apple.
[00:27:43.180 --> 00:27:47.500]   And so you can grow 50 to 100 of those
[00:27:47.500 --> 00:27:50.300]   inside one big bioreactors,
[00:27:50.300 --> 00:27:52.260]   which are these flasks where the media
[00:27:52.260 --> 00:27:55.500]   provides nutrients for the organoids.
[00:27:55.500 --> 00:28:00.500]   So the problem is not to grow more or less of them.
[00:28:00.500 --> 00:28:06.500]   It's really to figure out how to grow them in a way
[00:28:06.500 --> 00:28:08.420]   that they are more and more reproducible,
[00:28:08.420 --> 00:28:09.980]   for example, organoid to organoid,
[00:28:09.980 --> 00:28:13.220]   so they can be used to study a biological process.
[00:28:13.220 --> 00:28:15.620]   Because if you have too much variability,
[00:28:15.620 --> 00:28:17.140]   then you never know if what you see
[00:28:17.140 --> 00:28:19.580]   is just an exception or really the rule.
[00:28:19.580 --> 00:28:22.060]   - So what does an organoid look like?
[00:28:22.060 --> 00:28:25.140]   Are there different neurons already emerging?
[00:28:25.140 --> 00:28:27.580]   Is there, you know, well, first,
[00:28:27.580 --> 00:28:29.980]   can you tell me what kind of neurons are there?
[00:28:29.980 --> 00:28:30.940]   - Yes.
[00:28:30.940 --> 00:28:35.620]   - Are they sort of all the same?
[00:28:35.620 --> 00:28:37.500]   Are they not all the same?
[00:28:37.500 --> 00:28:39.580]   Is, how much do we understand?
[00:28:39.580 --> 00:28:43.500]   And how much of that variance, if any,
[00:28:43.500 --> 00:28:45.860]   can exist in organoids?
[00:28:45.860 --> 00:28:47.020]   - Yes.
[00:28:47.020 --> 00:28:49.420]   So you could grow,
[00:28:49.420 --> 00:28:52.500]   I told you that the brain has different parts.
[00:28:52.500 --> 00:28:54.700]   So the cerebral cortex is on top,
[00:28:54.700 --> 00:28:56.020]   the top part of the brain,
[00:28:56.020 --> 00:28:57.980]   but there is another region called the striatum
[00:28:57.980 --> 00:28:59.980]   that is below the cortex and so on and so forth.
[00:28:59.980 --> 00:29:03.780]   All of these regions have different types of cells
[00:29:03.780 --> 00:29:05.660]   in the actual brain, okay?
[00:29:05.660 --> 00:29:08.940]   And so scientists have been able to grow organoids
[00:29:08.940 --> 00:29:11.460]   that may mimic some aspects of development
[00:29:11.460 --> 00:29:13.940]   of these different regions of the brain.
[00:29:13.940 --> 00:29:16.460]   And so we are very interested in the cerebral cortex.
[00:29:16.460 --> 00:29:17.780]   - That's the coolest part, right?
[00:29:17.780 --> 00:29:18.620]   - Very cool.
[00:29:18.620 --> 00:29:19.460]   (laughing)
[00:29:19.460 --> 00:29:20.300]   I agree with you.
[00:29:20.300 --> 00:29:21.140]   (laughing)
[00:29:21.140 --> 00:29:21.980]   - Sorry.
[00:29:21.980 --> 00:29:22.820]   - We wouldn't be here talking
[00:29:22.820 --> 00:29:23.940]   if we didn't have a cerebral cortex.
[00:29:23.940 --> 00:29:25.300]   It's also, I like to think,
[00:29:25.300 --> 00:29:27.700]   the part of the brain that really truly makes us human,
[00:29:27.700 --> 00:29:30.300]   the most evolved in recent evolution.
[00:29:30.300 --> 00:29:33.700]   And so in the attempt to make the cerebral cortex,
[00:29:33.700 --> 00:29:37.300]   and by figuring out a way to have these organoids
[00:29:37.300 --> 00:29:40.340]   continue to grow and develop for extended periods of times,
[00:29:40.340 --> 00:29:42.500]   much like it happens in the real embryo,
[00:29:42.500 --> 00:29:44.340]   months and months in culture,
[00:29:44.340 --> 00:29:48.020]   then you can see that many different types
[00:29:48.020 --> 00:29:50.220]   of neurons of the cortex appear.
[00:29:50.220 --> 00:29:52.220]   And at some point, also the astrocytes,
[00:29:52.220 --> 00:29:57.220]   so the glia cells of the cerebral cortex also appear.
[00:29:57.220 --> 00:29:59.020]   - What are these?
[00:29:59.020 --> 00:29:59.860]   - Astrocytes.
[00:29:59.860 --> 00:30:00.700]   - Astrocytes.
[00:30:00.700 --> 00:30:02.140]   - The astrocytes are not neurons,
[00:30:02.140 --> 00:30:03.460]   so they're not nerve cells,
[00:30:03.460 --> 00:30:06.220]   but they play very important roles.
[00:30:06.220 --> 00:30:09.060]   One important role is to support the neuron,
[00:30:09.060 --> 00:30:11.900]   but of course they have much more active type of roles
[00:30:11.900 --> 00:30:13.340]   that are very important, for example,
[00:30:13.340 --> 00:30:14.580]   to make the synapses,
[00:30:14.580 --> 00:30:17.700]   which are the point of contact and communication
[00:30:17.700 --> 00:30:18.860]   between two neurons.
[00:30:18.860 --> 00:30:25.740]   - So all that chemistry fun happens in the synapses
[00:30:25.740 --> 00:30:28.220]   happens because of these cells?
[00:30:28.220 --> 00:30:29.740]   Are they the medium in which--
[00:30:29.740 --> 00:30:32.100]   - Happens because of the interactions.
[00:30:32.100 --> 00:30:34.860]   Happens because you are making the cells,
[00:30:34.860 --> 00:30:36.380]   and they have certain properties,
[00:30:36.380 --> 00:30:40.420]   including the ability to make neurotransmitters,
[00:30:40.420 --> 00:30:43.380]   which are the chemicals that are secreted to the synapses,
[00:30:43.380 --> 00:30:46.540]   including the ability of making these axons grow
[00:30:46.540 --> 00:30:49.260]   with their growth cones and so on and so forth.
[00:30:49.260 --> 00:30:51.460]   And then you have other cells around it
[00:30:51.460 --> 00:30:55.260]   that release chemicals or touch the neurons
[00:30:55.260 --> 00:30:57.260]   or interact with them in different ways
[00:30:57.260 --> 00:30:59.940]   to really foster this perfect process
[00:30:59.940 --> 00:31:02.540]   in this case of synaptogenesis.
[00:31:02.540 --> 00:31:05.700]   And this does happen within organoids.
[00:31:05.700 --> 00:31:06.540]   - Oh, with organoids.
[00:31:06.540 --> 00:31:09.820]   So the mechanical and the chemical stuff happens.
[00:31:09.820 --> 00:31:11.660]   - The connectivity between neurons.
[00:31:11.660 --> 00:31:13.380]   This, in a way, is not surprising
[00:31:13.380 --> 00:31:18.220]   because scientists have been culturing neurons forever.
[00:31:18.220 --> 00:31:20.820]   And when you take a neuron, even a very young one,
[00:31:20.820 --> 00:31:21.740]   and you culture it,
[00:31:21.740 --> 00:31:25.140]   eventually finds another cell or another neuron to talk to,
[00:31:25.140 --> 00:31:27.020]   it will form a synapse.
[00:31:27.020 --> 00:31:28.580]   - Are we talking about mice neurons?
[00:31:28.580 --> 00:31:29.700]   Are we talking about human neurons?
[00:31:29.700 --> 00:31:30.660]   - It doesn't matter, both.
[00:31:30.660 --> 00:31:33.300]   - So you can culture a neuron, like a single neuron,
[00:31:33.300 --> 00:31:37.980]   and give it a little friend, and it starts interacting?
[00:31:37.980 --> 00:31:38.820]   - Yes.
[00:31:38.820 --> 00:31:40.300]   So neurons are able to,
[00:31:40.300 --> 00:31:43.580]   it sounds, it's more simple than what it may sound to you.
[00:31:43.580 --> 00:31:48.380]   Neurons have molecular properties and structural properties
[00:31:48.380 --> 00:31:51.020]   that allow them to really communicate with other cells.
[00:31:51.020 --> 00:31:53.260]   And so if you put not one neuron,
[00:31:53.260 --> 00:31:55.220]   but if you put several neurons together,
[00:31:55.220 --> 00:31:59.460]   chances are that they will form synapses with each other.
[00:31:59.460 --> 00:32:01.180]   - Okay, great.
[00:32:01.180 --> 00:32:03.460]   So an organoid is not a brain.
[00:32:03.460 --> 00:32:04.300]   - No.
[00:32:04.300 --> 00:32:06.060]   (both laughing)
[00:32:06.060 --> 00:32:09.260]   - But there's some, it's able to,
[00:32:09.260 --> 00:32:10.500]   especially what you're talking about,
[00:32:10.500 --> 00:32:15.140]   mimic some properties of the cerebral cortex, for example.
[00:32:15.140 --> 00:32:18.020]   So what can you understand about the brain
[00:32:18.020 --> 00:32:21.100]   by studying an organoid of a cerebral cortex?
[00:32:21.100 --> 00:32:23.100]   - I can literally study
[00:32:23.100 --> 00:32:26.460]   how all this incredible diversity of cell type,
[00:32:26.460 --> 00:32:29.100]   all these many, many different classes of cells,
[00:32:29.100 --> 00:32:30.820]   how are they made?
[00:32:30.820 --> 00:32:32.540]   How do they look like?
[00:32:32.540 --> 00:32:34.940]   What do they need to be made properly?
[00:32:34.940 --> 00:32:39.700]   And what goes wrong if now the genetics of that stem cell
[00:32:39.700 --> 00:32:41.140]   that I used to make the organoid
[00:32:41.140 --> 00:32:44.300]   came from a patient with a neurodevelopmental disease?
[00:32:44.300 --> 00:32:47.580]   Can I actually watch for the very first time
[00:32:47.580 --> 00:32:51.380]   what may have gone wrong years before in this kid
[00:32:51.380 --> 00:32:53.460]   when its own brain was being made?
[00:32:53.460 --> 00:32:54.700]   Think about that loop.
[00:32:54.700 --> 00:32:59.580]   In a way, it's a little tiny rudimentary window
[00:32:59.580 --> 00:33:04.580]   into the past, into the time when that brain in a kid
[00:33:05.060 --> 00:33:08.860]   that had this neurodevelopmental disease was being made.
[00:33:08.860 --> 00:33:12.820]   And I think that's unbelievably powerful
[00:33:12.820 --> 00:33:16.740]   because today we have no idea of what cell types,
[00:33:16.740 --> 00:33:18.700]   we barely know what brain regions
[00:33:18.700 --> 00:33:20.820]   are affected in these diseases.
[00:33:20.820 --> 00:33:23.660]   Now we have an experimental system
[00:33:23.660 --> 00:33:25.380]   that we can study in the lab,
[00:33:25.380 --> 00:33:28.380]   and we can ask, what are the cells affected?
[00:33:28.380 --> 00:33:31.780]   When during development things went wrong?
[00:33:31.780 --> 00:33:33.100]   What are the molecules
[00:33:33.100 --> 00:33:35.140]   among the many, many different molecules
[00:33:35.140 --> 00:33:36.540]   that control brain development?
[00:33:36.540 --> 00:33:39.660]   Which ones are the ones that really messed up here
[00:33:39.660 --> 00:33:42.100]   and we want perhaps to fix?
[00:33:42.100 --> 00:33:44.460]   And what is really the final product?
[00:33:44.460 --> 00:33:48.500]   Is it a less strong kind of circuit and brain?
[00:33:48.500 --> 00:33:50.460]   Is it a brain that lacks a cell type?
[00:33:50.460 --> 00:33:51.980]   Is it a, what is it?
[00:33:51.980 --> 00:33:54.900]   Because then we can think about treatment
[00:33:54.900 --> 00:33:59.300]   and care for these patients that is informed
[00:33:59.300 --> 00:34:02.020]   rather than just based on current diagnostics.
[00:34:02.020 --> 00:34:04.580]   - So how hard is it to detect
[00:34:04.580 --> 00:34:06.340]   through the developmental process?
[00:34:06.340 --> 00:34:09.420]   It's a super exciting tool
[00:34:09.420 --> 00:34:14.020]   to see how different conditions develop.
[00:34:14.020 --> 00:34:17.660]   How hard is it to detect that, wait a minute,
[00:34:17.660 --> 00:34:20.820]   this is abnormal development?
[00:34:20.820 --> 00:34:21.660]   - Yeah.
[00:34:21.660 --> 00:34:24.860]   - How much signal is there?
[00:34:24.860 --> 00:34:26.580]   How much of it is it a mess?
[00:34:26.580 --> 00:34:29.540]   - 'Cause things can go wrong at multiple levels, right?
[00:34:29.540 --> 00:34:34.380]   You could have a cell that is born and built
[00:34:34.380 --> 00:34:36.300]   but then doesn't work properly
[00:34:36.300 --> 00:34:38.380]   or a cell that is not even born
[00:34:38.380 --> 00:34:39.660]   or a cell that doesn't interact
[00:34:39.660 --> 00:34:42.180]   with other cells differently and so on and so forth.
[00:34:42.180 --> 00:34:44.460]   So today we have technology
[00:34:44.460 --> 00:34:47.820]   that we did not have even five years ago
[00:34:47.820 --> 00:34:49.860]   that allows us to look, for example,
[00:34:49.860 --> 00:34:52.180]   at the molecular picture of a cell,
[00:34:52.180 --> 00:34:56.700]   of a single cell in a sea of cells with high precision.
[00:34:56.700 --> 00:34:58.900]   And so that molecular information
[00:34:58.900 --> 00:35:01.820]   where you compare many, many single cells
[00:35:01.820 --> 00:35:03.700]   for the genes that they produce
[00:35:03.700 --> 00:35:06.220]   between a control individual
[00:35:06.220 --> 00:35:10.180]   and an individual with a neurodevelopmental disease,
[00:35:10.180 --> 00:35:13.820]   that may tell you what is different molecularly.
[00:35:13.820 --> 00:35:18.620]   Or you could see that some cells are not even made,
[00:35:18.620 --> 00:35:20.820]   for example, or that the process of maturation
[00:35:20.820 --> 00:35:22.660]   of the cells may be wrong.
[00:35:22.660 --> 00:35:25.060]   There are many different levels here
[00:35:26.660 --> 00:35:29.620]   and we can study the cells at the molecular level,
[00:35:29.620 --> 00:35:33.420]   but also we can use the organoids to ask questions
[00:35:33.420 --> 00:35:35.380]   about the properties of the neurons,
[00:35:35.380 --> 00:35:37.420]   the functional properties,
[00:35:37.420 --> 00:35:38.980]   how they communicate with each other,
[00:35:38.980 --> 00:35:41.420]   how they respond to a stimulus and so on and so forth.
[00:35:41.420 --> 00:35:46.420]   And we may get at abnormalities there, right?
[00:35:46.420 --> 00:35:47.540]   - Detect those.
[00:35:47.540 --> 00:35:50.660]   So how early is this work in a,
[00:35:50.660 --> 00:35:54.340]   maybe in the history of science?
[00:35:54.340 --> 00:35:55.180]   (laughing)
[00:35:55.180 --> 00:35:57.180]   - That's an easy question.
[00:35:57.180 --> 00:35:59.820]   - I mean, like, so if you were to,
[00:35:59.820 --> 00:36:04.820]   if you and I time travel a thousand years into the future,
[00:36:04.820 --> 00:36:06.980]   organoids seem to be,
[00:36:06.980 --> 00:36:09.980]   maybe I'm romanticizing the notion,
[00:36:09.980 --> 00:36:12.820]   but you're building not a brain,
[00:36:12.820 --> 00:36:15.740]   but something that has properties of a brain.
[00:36:15.740 --> 00:36:19.060]   So it feels like you might be getting close to,
[00:36:19.060 --> 00:36:23.300]   in the building process, to build this, to understand.
[00:36:23.300 --> 00:36:28.300]   So how far are we in this understanding
[00:36:28.300 --> 00:36:30.300]   process of development?
[00:36:30.300 --> 00:36:34.300]   - A thousand years from now, it's a long time from now.
[00:36:34.300 --> 00:36:36.500]   So if this planet is still gonna be here
[00:36:36.500 --> 00:36:38.220]   a thousand years from now.
[00:36:38.220 --> 00:36:42.060]   - So I mean, if, you know, like they write a book,
[00:36:42.060 --> 00:36:44.020]   obviously there'll be a chapter about you.
[00:36:44.020 --> 00:36:47.340]   - Let's write the science fiction book today.
[00:36:47.340 --> 00:36:48.180]   - Yeah, today.
[00:36:48.180 --> 00:36:50.820]   I mean, I guess where we really understood
[00:36:50.820 --> 00:36:53.100]   very little about the brain a century ago.
[00:36:53.100 --> 00:36:57.260]   I was a big fan in high school of reading Freud and so on.
[00:36:57.260 --> 00:36:58.740]   Still am of psychiatry.
[00:36:58.740 --> 00:37:01.460]   I would say we still understand very little
[00:37:01.460 --> 00:37:03.700]   about the functional aspect of just,
[00:37:03.700 --> 00:37:07.780]   but how in the history of understanding
[00:37:07.780 --> 00:37:09.660]   the biology of the brain, the development,
[00:37:09.660 --> 00:37:11.260]   how far are we along?
[00:37:11.260 --> 00:37:12.980]   - It's a very good question.
[00:37:12.980 --> 00:37:15.540]   And so this is just, of course, my opinion.
[00:37:15.540 --> 00:37:19.740]   I think that we did not have technology,
[00:37:19.740 --> 00:37:23.180]   even 10 years ago or 20, certainly not 20 years ago,
[00:37:23.180 --> 00:37:27.780]   to even think about experimentally investigating
[00:37:27.780 --> 00:37:30.180]   the development of the human brain.
[00:37:30.180 --> 00:37:32.220]   So we've done a lot of work in science
[00:37:32.220 --> 00:37:35.500]   to study the brain or many other organisms.
[00:37:35.500 --> 00:37:39.620]   Now we have some technologies which I'll spell out
[00:37:39.620 --> 00:37:43.140]   that allow us to actually look at the real thing
[00:37:43.140 --> 00:37:45.060]   and look at the brain, at the human brain.
[00:37:45.060 --> 00:37:46.900]   So what are these technologies?
[00:37:46.900 --> 00:37:50.500]   There has been huge progress in stem cell biology.
[00:37:50.500 --> 00:37:54.140]   The moment someone figured out how to turn a skin cell
[00:37:54.140 --> 00:37:57.820]   into an embryonic stem cell, basically,
[00:37:57.820 --> 00:38:00.220]   and that how that embryonic stem cell
[00:38:00.220 --> 00:38:02.540]   could begin a process of development again
[00:38:02.540 --> 00:38:04.060]   to, for example, make a brain,
[00:38:04.060 --> 00:38:06.100]   there was a huge advance.
[00:38:06.100 --> 00:38:08.220]   And in fact, there was a Nobel Prize for that.
[00:38:08.220 --> 00:38:12.380]   That started the field really of using stem cells
[00:38:12.380 --> 00:38:14.260]   to build organs.
[00:38:14.260 --> 00:38:17.060]   Now we can build on all the knowledge of development
[00:38:17.060 --> 00:38:18.580]   that we build over the many, many, many years
[00:38:18.580 --> 00:38:20.740]   to say, how do we make the stem cells
[00:38:20.740 --> 00:38:23.340]   now make more and more complex aspects of development
[00:38:23.340 --> 00:38:24.420]   of the human brain?
[00:38:24.420 --> 00:38:28.500]   So this field is young, the field of brain organoids,
[00:38:28.500 --> 00:38:30.140]   but it's moving faster.
[00:38:30.140 --> 00:38:32.580]   And it's moving fast in a very serious way
[00:38:32.580 --> 00:38:35.980]   that is rooted in labs with the right ethical framework
[00:38:35.980 --> 00:38:40.740]   and really building on solid science
[00:38:40.740 --> 00:38:43.540]   for what reality is and what is not.
[00:38:43.540 --> 00:38:46.100]   And, but it will go faster
[00:38:46.100 --> 00:38:49.100]   and it will be more and more powerful.
[00:38:49.100 --> 00:38:51.460]   We also have technology that allows us
[00:38:51.460 --> 00:38:54.620]   to basically study the properties of single cells
[00:38:54.620 --> 00:38:59.180]   across many, many millions of single cells,
[00:38:59.180 --> 00:39:02.140]   which we didn't have perhaps five years ago.
[00:39:02.140 --> 00:39:04.780]   So now with that, even an organoid
[00:39:04.780 --> 00:39:08.420]   that has millions of cells can be profiled in a way,
[00:39:08.420 --> 00:39:11.260]   looked at with very, very high resolution,
[00:39:11.260 --> 00:39:14.900]   the single cell level to really understand what is going on.
[00:39:14.900 --> 00:39:17.460]   And you could do it in multiple stages of development
[00:39:17.460 --> 00:39:20.060]   and you can build your hypothesis and so on and so forth.
[00:39:20.060 --> 00:39:22.540]   So it's not gonna be a thousand years.
[00:39:22.540 --> 00:39:25.180]   It's gonna be a shorter amount of time.
[00:39:25.180 --> 00:39:29.420]   And I see these as sort of an exponential growth
[00:39:29.420 --> 00:39:33.500]   of this field enabled by these technologies
[00:39:33.500 --> 00:39:34.980]   that we didn't have before.
[00:39:34.980 --> 00:39:36.940]   And so we're gonna see something transformative
[00:39:36.940 --> 00:39:41.860]   that we didn't see at all in the prior thousand years.
[00:39:41.860 --> 00:39:44.620]   - So I apologize for the crazy sci-fi questions,
[00:39:44.620 --> 00:39:47.420]   but the developmental process
[00:39:47.420 --> 00:39:50.180]   is fascinating to watch and study,
[00:39:50.180 --> 00:39:53.340]   but how far are we away from
[00:39:53.340 --> 00:39:57.220]   and maybe how difficult is it to build,
[00:39:57.220 --> 00:39:59.660]   not just an organoid, but a human brain?
[00:39:59.660 --> 00:40:02.260]   - Okay. - From a stem cell.
[00:40:02.260 --> 00:40:03.100]   - Yeah.
[00:40:03.100 --> 00:40:05.620]   First of all, that's not the goal
[00:40:05.620 --> 00:40:07.660]   for the majority of the serious scientists
[00:40:07.660 --> 00:40:09.380]   that work on this,
[00:40:09.380 --> 00:40:14.140]   because you don't have to build the whole human brain
[00:40:14.140 --> 00:40:16.060]   to make this model useful
[00:40:16.060 --> 00:40:17.980]   for understanding how the brain develops
[00:40:17.980 --> 00:40:20.420]   or understanding disease.
[00:40:20.420 --> 00:40:22.380]   You don't have to build the whole thing.
[00:40:22.380 --> 00:40:24.140]   - So let me just comment on that.
[00:40:24.140 --> 00:40:25.140]   It's fascinating.
[00:40:25.140 --> 00:40:29.140]   It shows to me the difference between you and I
[00:40:29.140 --> 00:40:31.780]   is you're actually trying to understand
[00:40:31.780 --> 00:40:33.380]   the beauty of the human brain
[00:40:33.380 --> 00:40:35.500]   and to use it to really help
[00:40:35.500 --> 00:40:37.820]   thousands or millions of people with disease and so on.
[00:40:37.820 --> 00:40:38.820]   Right.
[00:40:38.820 --> 00:40:41.460]   From an artificial intelligence perspective,
[00:40:41.460 --> 00:40:45.580]   we're trying to build systems that we can put in robots
[00:40:45.580 --> 00:40:49.100]   and try to create systems that have echoes
[00:40:49.100 --> 00:40:52.380]   of the intelligence about reasoning about the world,
[00:40:52.380 --> 00:40:53.580]   navigating the world.
[00:40:53.580 --> 00:40:55.980]   It's different objectives, I think.
[00:40:55.980 --> 00:40:57.540]   - Yeah, that's very much science fiction.
[00:40:57.540 --> 00:40:58.700]   - Science fiction.
[00:40:58.700 --> 00:41:00.500]   But we operate in science fiction a little bit.
[00:41:00.500 --> 00:41:03.460]   So on that point of building a brain,
[00:41:03.460 --> 00:41:05.820]   even though that is not the focus or interest
[00:41:05.820 --> 00:41:08.540]   perhaps of the community, how difficult is it?
[00:41:08.540 --> 00:41:11.220]   Is it truly science fiction at this point?
[00:41:11.220 --> 00:41:13.980]   - I think the field will progress, like I said,
[00:41:13.980 --> 00:41:18.740]   and that the system will be more and more complex in a way.
[00:41:18.740 --> 00:41:23.740]   But there are properties that emerge from the human brain
[00:41:23.740 --> 00:41:25.420]   that have to do with the mind,
[00:41:25.420 --> 00:41:26.820]   that may have to do with consciousness,
[00:41:26.820 --> 00:41:29.860]   may have to do with intelligence or whatever,
[00:41:29.860 --> 00:41:31.980]   that we really don't understand
[00:41:31.980 --> 00:41:35.580]   even how they can emerge from an actual real brain.
[00:41:35.580 --> 00:41:39.140]   And therefore we can now measure or study in an organoid.
[00:41:39.140 --> 00:41:43.020]   So I think that this field, many, many years from now,
[00:41:43.020 --> 00:41:47.020]   may lead to the building of better neural circuits
[00:41:47.020 --> 00:41:50.300]   that really are built out of understanding
[00:41:50.300 --> 00:41:52.260]   of how this process really works.
[00:41:52.260 --> 00:41:57.020]   And it's hard to predict how complex this really will be.
[00:41:57.020 --> 00:42:00.220]   I really don't think we're so far from,
[00:42:00.220 --> 00:42:02.620]   it makes me laugh really, it's really that far
[00:42:02.620 --> 00:42:05.180]   from building the human brain,
[00:42:05.180 --> 00:42:07.820]   but you're gonna be building something
[00:42:07.820 --> 00:42:11.660]   that is always a bad version of it,
[00:42:11.660 --> 00:42:14.860]   but that may have really powerful properties
[00:42:14.860 --> 00:42:18.580]   and might be able to respond to stimuli
[00:42:18.580 --> 00:42:21.740]   or be used in certain context.
[00:42:21.740 --> 00:42:23.740]   And this is why I really think
[00:42:23.740 --> 00:42:25.820]   that there is no other way to do this science,
[00:42:25.820 --> 00:42:28.260]   but within the right ethical framework,
[00:42:28.260 --> 00:42:30.660]   because where you're going with this is also,
[00:42:30.660 --> 00:42:34.100]   we can talk about science fiction and write that book
[00:42:34.100 --> 00:42:36.620]   and we could today,
[00:42:36.620 --> 00:42:41.580]   but this work happens in a specific ethical framework
[00:42:41.580 --> 00:42:43.220]   that we don't decide just as scientists,
[00:42:43.220 --> 00:42:44.940]   but also as a society.
[00:42:44.940 --> 00:42:48.580]   - So the ethical framework here is a fascinating one,
[00:42:48.580 --> 00:42:49.780]   is a complicated one.
[00:42:49.780 --> 00:42:51.180]   - Yes.
[00:42:51.180 --> 00:42:53.340]   - Do you have a sense, a grasp
[00:42:53.340 --> 00:42:58.340]   of how we think about ethically of building organoids
[00:42:58.340 --> 00:43:04.180]   from human stem cells to understand the brain?
[00:43:04.180 --> 00:43:07.540]   It seems like a tool for helping
[00:43:07.540 --> 00:43:11.100]   potentially millions of people cure diseases
[00:43:11.100 --> 00:43:14.980]   or at least start the cure by understanding it,
[00:43:14.980 --> 00:43:17.860]   but is there more, is there gray areas
[00:43:17.860 --> 00:43:22.420]   that we have to think about ethically?
[00:43:22.420 --> 00:43:25.620]   - Absolutely, we must think about that.
[00:43:25.620 --> 00:43:29.620]   Every discussion about the ethics of this
[00:43:29.620 --> 00:43:32.700]   needs to be based on actual data
[00:43:32.700 --> 00:43:34.500]   from the models that we have today
[00:43:34.500 --> 00:43:36.340]   and from the ones that we will have tomorrow.
[00:43:36.340 --> 00:43:37.860]   So it's a continuous conversation,
[00:43:37.860 --> 00:43:39.900]   it's not something that you decide now.
[00:43:39.900 --> 00:43:42.060]   Today, there is no issue really,
[00:43:42.060 --> 00:43:47.060]   very simple models that clearly can help you in many ways
[00:43:47.060 --> 00:43:49.940]   without much think about,
[00:43:49.940 --> 00:43:52.220]   but tomorrow we need to have another conversation
[00:43:52.220 --> 00:43:53.060]   and so on and so forth.
[00:43:53.060 --> 00:43:55.980]   And so the way we do this is to actually
[00:43:55.980 --> 00:43:58.940]   really bring together constantly a group of people
[00:43:58.940 --> 00:44:01.860]   that are not only scientists, but also bioethicists,
[00:44:01.860 --> 00:44:04.140]   the lawyers, philosophers, psychologists,
[00:44:04.140 --> 00:44:06.700]   and so on and so forth,
[00:44:06.700 --> 00:44:10.780]   to decide as a society really,
[00:44:10.780 --> 00:44:15.260]   what we should and what we should not do.
[00:44:15.260 --> 00:44:17.580]   So that's the way to think about the ethics.
[00:44:17.580 --> 00:44:21.220]   Now, I also think though, that as a scientist,
[00:44:21.220 --> 00:44:23.740]   I have a moral responsibility.
[00:44:23.740 --> 00:44:28.740]   So if you think about how transformative it could be
[00:44:28.740 --> 00:44:34.100]   for understanding and curing a neuropsychiatric disease,
[00:44:34.100 --> 00:44:37.300]   to be able to actually watch and study
[00:44:37.300 --> 00:44:40.620]   and treat with drugs the very brain
[00:44:40.620 --> 00:44:43.220]   of the patient that you are trying to study.
[00:44:43.220 --> 00:44:47.220]   How transformative at this moment in time, this could be.
[00:44:47.220 --> 00:44:49.980]   We couldn't do it five years ago, we could do it now.
[00:44:49.980 --> 00:44:50.820]   Right?
[00:44:50.820 --> 00:44:52.940]   - Taking a stem cell of a particular patient.
[00:44:52.940 --> 00:44:56.100]   - Patient and make an organoid for a simple
[00:44:56.100 --> 00:44:58.860]   and different from the human brain,
[00:44:58.860 --> 00:45:02.140]   it still is his process of brain development
[00:45:02.140 --> 00:45:04.700]   with his or her genetics.
[00:45:04.700 --> 00:45:08.260]   And we could understand perhaps what is going wrong.
[00:45:08.260 --> 00:45:10.980]   Perhaps we could use as a platform, as a cellular platform
[00:45:10.980 --> 00:45:13.580]   to screen for drugs, to fix a process
[00:45:13.580 --> 00:45:15.220]   and so on and so forth, right?
[00:45:15.220 --> 00:45:18.780]   So we could do it now, we couldn't do it five years ago.
[00:45:18.780 --> 00:45:20.460]   Should we not do it?
[00:45:20.460 --> 00:45:24.740]   - What is the downside of doing it?
[00:45:24.740 --> 00:45:27.300]   - I don't see a downside at this very moment.
[00:45:27.300 --> 00:45:30.020]   - If we invited a lot of people,
[00:45:30.020 --> 00:45:33.420]   I'm sure there would be somebody who would argue against it.
[00:45:33.420 --> 00:45:37.580]   What would be the devil's advocate argument?
[00:45:37.580 --> 00:45:42.980]   - So it's exactly perhaps what you alluded at
[00:45:42.980 --> 00:45:47.140]   with your question, that you are making it,
[00:45:47.140 --> 00:45:51.660]   enabling some process of formation of the brain
[00:45:51.660 --> 00:45:54.420]   that could be misused at some point,
[00:45:54.420 --> 00:45:59.060]   or that could be showing properties
[00:45:59.060 --> 00:46:03.980]   that ethically we don't wanna see in a tissue.
[00:46:03.980 --> 00:46:07.740]   So today, I repeat, today, this is not an issue.
[00:46:07.740 --> 00:46:11.260]   And so you just gain dramatically from the science
[00:46:11.260 --> 00:46:13.740]   without because the system is so simple
[00:46:14.340 --> 00:46:17.820]   and so different in a way from the actual brain.
[00:46:17.820 --> 00:46:19.980]   But because it is the brain,
[00:46:19.980 --> 00:46:23.980]   we have an obligation to really consider all of this, right?
[00:46:23.980 --> 00:46:27.180]   And again, it's a balanced conversation
[00:46:27.180 --> 00:46:30.380]   where we should put disease and betterment of humanity
[00:46:30.380 --> 00:46:32.460]   also on that plate.
[00:46:32.460 --> 00:46:35.420]   - What do you think, at least historically,
[00:46:35.420 --> 00:46:40.420]   there was some politicization of embryonic stem cells
[00:46:40.420 --> 00:46:45.420]   or stem cell research.
[00:46:45.420 --> 00:46:49.140]   Do you still see that out there?
[00:46:49.140 --> 00:46:53.540]   Is that still a force that we have to think about,
[00:46:53.540 --> 00:46:55.580]   especially in this larger discourse
[00:46:55.580 --> 00:46:57.540]   that we're having about the role of science
[00:46:57.540 --> 00:47:00.580]   in at least American society?
[00:47:00.580 --> 00:47:03.460]   - Yeah, this is a very good question.
[00:47:03.460 --> 00:47:04.980]   It's very, very important.
[00:47:04.980 --> 00:47:08.460]   I see a very central role for scientists
[00:47:08.460 --> 00:47:12.020]   to inform decisions about what we should
[00:47:12.020 --> 00:47:14.420]   or should not do in society.
[00:47:14.420 --> 00:47:16.380]   And this is because the scientists
[00:47:16.380 --> 00:47:20.420]   have the firsthand look and understanding
[00:47:20.420 --> 00:47:23.500]   of really the work that they are doing.
[00:47:23.500 --> 00:47:25.220]   And again, this varies
[00:47:25.220 --> 00:47:27.460]   depending on what we're talking about here.
[00:47:27.460 --> 00:47:30.780]   So now we're talking about brain organoids.
[00:47:30.780 --> 00:47:33.780]   I think that the scientists need to be part
[00:47:33.780 --> 00:47:36.500]   of that conversation about what is,
[00:47:36.500 --> 00:47:37.980]   will be allowed in the future
[00:47:37.980 --> 00:47:40.780]   or not allowed in the future to do with the system.
[00:47:40.780 --> 00:47:43.340]   And I think that is very, very important
[00:47:43.340 --> 00:47:47.840]   because they bring reality of data to the conversation.
[00:47:47.840 --> 00:47:51.660]   And so they should have a voice.
[00:47:51.660 --> 00:47:53.340]   - So data should have a voice.
[00:47:53.340 --> 00:47:57.300]   - Data needs to have a voice because not only data,
[00:47:57.300 --> 00:48:01.140]   we should also be good at communicating
[00:48:01.140 --> 00:48:04.220]   with non-scientists the data.
[00:48:04.220 --> 00:48:06.780]   So there has been often time,
[00:48:06.780 --> 00:48:11.780]   there is a lot of discussion and excitement
[00:48:11.780 --> 00:48:16.280]   and fights about certain topics
[00:48:16.280 --> 00:48:19.260]   just because of the way they are described.
[00:48:19.260 --> 00:48:20.980]   I'll give you an example.
[00:48:20.980 --> 00:48:23.340]   If I called the same cellular system
[00:48:23.340 --> 00:48:27.060]   we just talked about a brain organoid,
[00:48:27.060 --> 00:48:30.300]   or if I called it a human mini brain,
[00:48:30.300 --> 00:48:34.580]   your reaction is gonna be very different to this.
[00:48:34.580 --> 00:48:37.740]   And so the way the systems are described,
[00:48:37.740 --> 00:48:42.500]   I mean, we and journalists alike need to be a bit careful
[00:48:42.500 --> 00:48:46.020]   that this debate is a real debate and informed by real data.
[00:48:46.020 --> 00:48:47.940]   That's all I'm asking.
[00:48:47.940 --> 00:48:49.580]   - And yeah, the language matters here.
[00:48:49.580 --> 00:48:51.260]   So I work on autonomous vehicles
[00:48:51.260 --> 00:48:53.020]   and there the use of language
[00:48:53.020 --> 00:48:56.420]   could drastically change the interpretation
[00:48:56.420 --> 00:48:58.460]   and the way people feel about
[00:48:58.460 --> 00:49:01.480]   what is the right way to proceed forward.
[00:49:01.480 --> 00:49:06.220]   You are, as I've seen from a presentation, you're a parent.
[00:49:06.220 --> 00:49:09.820]   I saw you show a couple of pictures of your son.
[00:49:09.820 --> 00:49:11.380]   Is it just the one?
[00:49:11.380 --> 00:49:12.220]   - Two.
[00:49:12.220 --> 00:49:13.260]   - Two. - Son and a daughter.
[00:49:13.260 --> 00:49:14.140]   - Son and a daughter.
[00:49:14.140 --> 00:49:17.300]   So what have you learned from the human brain
[00:49:17.300 --> 00:49:20.060]   by raising two of them?
[00:49:20.060 --> 00:49:22.660]   - More than I could ever learn in a lab.
[00:49:22.660 --> 00:49:24.460]   (laughs)
[00:49:24.460 --> 00:49:25.580]   What have I learned?
[00:49:26.820 --> 00:49:28.620]   I've learned that children really have
[00:49:28.620 --> 00:49:31.540]   these amazing plastic minds, right?
[00:49:31.540 --> 00:49:36.540]   That we have a responsibility to foster their growth
[00:49:36.540 --> 00:49:40.780]   in good, healthy ways that keep them curious,
[00:49:40.780 --> 00:49:42.380]   that keep some adventures,
[00:49:42.380 --> 00:49:45.760]   that doesn't raise them in fear of things.
[00:49:45.760 --> 00:49:48.940]   But also respecting who they are,
[00:49:48.940 --> 00:49:52.340]   which is in part coming from the genetics we talked about.
[00:49:52.340 --> 00:49:54.500]   My children are very different from each other
[00:49:54.500 --> 00:49:56.020]   despite the fact that they're the product
[00:49:56.020 --> 00:49:57.800]   of the same two parents.
[00:49:57.800 --> 00:50:04.300]   I also learned that what you do for them comes back to you.
[00:50:04.300 --> 00:50:07.620]   If you're a good parent, you're gonna,
[00:50:07.620 --> 00:50:12.180]   most of the time, have perhaps a decent kids at the end.
[00:50:12.180 --> 00:50:13.740]   - So what do you think, just a quick comment,
[00:50:13.740 --> 00:50:17.760]   what do you think is the source of that difference?
[00:50:17.760 --> 00:50:20.460]   That's often the surprising thing for parents.
[00:50:20.460 --> 00:50:21.300]   - Yeah.
[00:50:21.300 --> 00:50:24.020]   - Is that they can't believe that our kids,
[00:50:25.580 --> 00:50:28.020]   they're so different, yet they came from the same parents.
[00:50:28.020 --> 00:50:29.620]   - Well, they are genetically different.
[00:50:29.620 --> 00:50:31.900]   Even they came from the same two parents
[00:50:31.900 --> 00:50:33.660]   because the mixing of gametes,
[00:50:33.660 --> 00:50:35.700]   and we know this genetics,
[00:50:35.700 --> 00:50:39.780]   creates every time a genetically different individual
[00:50:39.780 --> 00:50:43.740]   which will have a specific mix of genes
[00:50:43.740 --> 00:50:46.540]   that is a different mix every time from the two parents.
[00:50:46.540 --> 00:50:51.540]   And so they're not twins, they are genetically different.
[00:50:51.540 --> 00:50:55.340]   - Even just that little bit of variation.
[00:50:55.340 --> 00:50:58.340]   'Cause you said really from a biological perspective,
[00:50:58.340 --> 00:51:00.580]   the brains look pretty similar.
[00:51:00.580 --> 00:51:02.420]   - Well, so let me clarify that.
[00:51:02.420 --> 00:51:05.420]   So the genetics you have, the genes that you have
[00:51:05.420 --> 00:51:08.700]   that play that beautiful orchestrated symphony
[00:51:08.700 --> 00:51:12.040]   of development, different genes
[00:51:12.040 --> 00:51:13.900]   will play it slightly differently.
[00:51:13.900 --> 00:51:16.100]   It's like playing the same piece of music,
[00:51:16.100 --> 00:51:17.980]   but with a different orchestra
[00:51:17.980 --> 00:51:19.980]   and a different director, right?
[00:51:19.980 --> 00:51:21.460]   The music will not come out,
[00:51:21.460 --> 00:51:25.420]   it will be still a piece by the same author,
[00:51:25.420 --> 00:51:27.060]   but it will come out differently
[00:51:27.060 --> 00:51:28.940]   if it's played by the high school orchestra
[00:51:28.940 --> 00:51:29.780]   instead of the-
[00:51:29.780 --> 00:51:31.860]   (laughing)
[00:51:31.860 --> 00:51:33.480]   Instead of La Scala in Milan.
[00:51:33.480 --> 00:51:39.220]   And so you are born superficially with the same brain.
[00:51:39.220 --> 00:51:41.220]   It has the same cell types,
[00:51:41.220 --> 00:51:43.460]   similar patterns of connectivity,
[00:51:43.460 --> 00:51:45.220]   but the properties of the cells
[00:51:45.220 --> 00:51:47.620]   and how the cells will then react to the environment
[00:51:47.620 --> 00:51:49.580]   as you experience your world
[00:51:49.580 --> 00:51:53.740]   will be also shaped by who genetically you are.
[00:51:53.740 --> 00:51:55.160]   Speaking just as a parent,
[00:51:55.160 --> 00:51:56.940]   this is not something that comes from my work.
[00:51:56.940 --> 00:51:58.860]   I think you can tell at birth
[00:51:58.860 --> 00:52:01.180]   that these kids are different,
[00:52:01.180 --> 00:52:04.600]   that they have a different personality in a way, right?
[00:52:04.600 --> 00:52:08.780]   So both is needed, the genetics
[00:52:08.780 --> 00:52:10.700]   as well as the nurturing afterwards.
[00:52:10.700 --> 00:52:15.500]   - So you are one human with a brain,
[00:52:15.500 --> 00:52:17.700]   sort of living through the whole mess of it,
[00:52:17.700 --> 00:52:19.900]   the human condition full of love,
[00:52:19.900 --> 00:52:23.420]   maybe fear, ultimately mortal.
[00:52:23.420 --> 00:52:27.700]   How has studying the brain changed the way you see yourself
[00:52:27.700 --> 00:52:28.620]   when you look in the mirror,
[00:52:28.620 --> 00:52:30.500]   when you think about your life,
[00:52:30.500 --> 00:52:32.420]   the fears, the love,
[00:52:32.420 --> 00:52:34.660]   when you see your own life, your own mortality?
[00:52:34.660 --> 00:52:37.380]   - Yeah, that's a very good question.
[00:52:37.380 --> 00:52:43.540]   It's almost impossible to dissociate sometime for me.
[00:52:43.540 --> 00:52:45.340]   Some of the things we do
[00:52:45.340 --> 00:52:48.780]   or some of the things that other people do from,
[00:52:48.780 --> 00:52:51.660]   oh, that's because that part of the brain
[00:52:51.660 --> 00:52:54.660]   is working in a certain way.
[00:52:54.660 --> 00:52:58.380]   Or thinking about a teenager,
[00:52:58.380 --> 00:53:01.140]   going through teenage years
[00:53:01.140 --> 00:53:04.060]   and being at times funny in the way they think.
[00:53:04.060 --> 00:53:06.340]   And impossible for me not to think
[00:53:06.340 --> 00:53:09.920]   it's because they're going through this period of time
[00:53:09.920 --> 00:53:13.300]   called critical period of plasticity
[00:53:13.300 --> 00:53:16.420]   where their synapses are being eliminated here and there
[00:53:16.420 --> 00:53:17.780]   and they're just confused.
[00:53:17.780 --> 00:53:22.300]   And so from that comes perhaps a different take
[00:53:22.300 --> 00:53:27.300]   on that behavior or maybe I can justify it scientifically
[00:53:27.300 --> 00:53:30.100]   in some sort of way.
[00:53:30.100 --> 00:53:32.260]   I also look at humanity in general
[00:53:32.260 --> 00:53:37.060]   and I am amazed by what we can do
[00:53:37.060 --> 00:53:39.940]   and the kind of ideas that we can come up with.
[00:53:39.940 --> 00:53:42.820]   And I cannot stop thinking about
[00:53:42.820 --> 00:53:46.420]   how the brain is continuing to evolve.
[00:53:46.420 --> 00:53:47.320]   I don't know if you do this,
[00:53:47.320 --> 00:53:49.680]   but I think about the next brain sometimes.
[00:53:49.680 --> 00:53:51.060]   Where are we going with this?
[00:53:51.060 --> 00:53:53.860]   Like what are the features of this brain
[00:53:53.860 --> 00:53:57.860]   that evolution is really playing with
[00:53:57.860 --> 00:54:02.500]   to get us in the future the new brain?
[00:54:02.500 --> 00:54:04.220]   It's not over, right?
[00:54:04.220 --> 00:54:07.140]   It's a work in progress.
[00:54:07.140 --> 00:54:09.220]   - So let me just a quick comment on that.
[00:54:09.220 --> 00:54:14.220]   Do you think there's a lot of fascination
[00:54:14.220 --> 00:54:16.220]   and hope for artificial intelligence
[00:54:16.220 --> 00:54:17.940]   of creating artificial brains?
[00:54:17.940 --> 00:54:20.300]   You said the next brain.
[00:54:20.300 --> 00:54:23.560]   When you imagine over a period of a thousand years,
[00:54:23.560 --> 00:54:25.700]   the evolution of the human brain,
[00:54:25.700 --> 00:54:28.900]   do you sometimes envisioning that future
[00:54:28.900 --> 00:54:31.420]   see an artificial one?
[00:54:31.420 --> 00:54:34.260]   Artificial intelligence as it is hoped by many,
[00:54:34.260 --> 00:54:36.780]   not hoped, thought by many people
[00:54:36.780 --> 00:54:39.080]   would be actually the next evolutionary step
[00:54:39.080 --> 00:54:40.620]   in the development of humans.
[00:54:40.620 --> 00:54:45.420]   - Yeah, I think in a way that will happen, right?
[00:54:45.420 --> 00:54:48.700]   It's almost like a part of the way we evolve.
[00:54:48.700 --> 00:54:51.340]   We evolve in the world that we created,
[00:54:51.340 --> 00:54:53.220]   that we interact with,
[00:54:53.220 --> 00:54:56.660]   that shape us as we grow up and so on and so forth.
[00:54:56.660 --> 00:55:01.080]   Sometime I think about something that may sound silly,
[00:55:01.080 --> 00:55:04.660]   but think about the use of cell phones.
[00:55:04.660 --> 00:55:07.220]   Part of me thinks that somehow in their brain
[00:55:07.220 --> 00:55:09.140]   there will be a region of the cortex
[00:55:09.140 --> 00:55:13.720]   that is attuned to that tool.
[00:55:13.720 --> 00:55:18.720]   And this comes from a lot of studies in modern organisms
[00:55:18.720 --> 00:55:22.800]   where really the cortex especially adapts
[00:55:22.800 --> 00:55:24.260]   to the kind of things you have to do.
[00:55:24.260 --> 00:55:28.620]   So if we need to move our fingers in a very specific way,
[00:55:28.620 --> 00:55:30.760]   we have a part of our cortex that allows us
[00:55:30.760 --> 00:55:33.060]   to do this kind of very precise movement.
[00:55:33.060 --> 00:55:37.000]   An owl that has to see very, very far away
[00:55:37.000 --> 00:55:39.960]   with big eyes, the visual cortex, very big.
[00:55:39.960 --> 00:55:43.280]   The brain attunes to your environment.
[00:55:43.280 --> 00:55:47.600]   So the brain will attune to the technologies
[00:55:47.600 --> 00:55:51.200]   that we will have and will be shaped by it.
[00:55:51.200 --> 00:55:52.920]   - So the cortex very well may be-
[00:55:52.920 --> 00:55:54.640]   - Will be shaped by it.
[00:55:54.640 --> 00:55:57.360]   - In artificial intelligence, it may merge with it,
[00:55:57.360 --> 00:56:01.240]   it may get an envelope it and adjust to it.
[00:56:01.240 --> 00:56:04.200]   - Even if it's not a merge of the kind of,
[00:56:04.200 --> 00:56:06.960]   oh, let's have a synthetic element together
[00:56:06.960 --> 00:56:08.780]   with a biological one.
[00:56:08.780 --> 00:56:11.820]   The very space around us, the fact, for example,
[00:56:11.820 --> 00:56:15.240]   think about we put on some goggles of virtual reality
[00:56:15.240 --> 00:56:18.820]   and we physically are surfing the ocean, right?
[00:56:18.820 --> 00:56:21.760]   Like I've done it and you have all these emotions
[00:56:21.760 --> 00:56:22.760]   that come to you.
[00:56:22.760 --> 00:56:27.160]   Your brain placed you in that reality
[00:56:27.160 --> 00:56:29.680]   and it was able to do it like that
[00:56:29.680 --> 00:56:31.160]   just by putting the goggles on.
[00:56:31.160 --> 00:56:36.040]   It didn't take thousands of years of adapting to this.
[00:56:36.040 --> 00:56:39.320]   The brain is plastic, so adapts to new technology.
[00:56:39.320 --> 00:56:41.800]   So you could do it from the outside
[00:56:41.800 --> 00:56:46.800]   by simply hijacking some sensory capacities that we have.
[00:56:46.800 --> 00:56:51.600]   So clearly over recent evolution,
[00:56:51.600 --> 00:56:54.000]   the cerebral cortex has been a part of the brain
[00:56:54.000 --> 00:56:56.000]   that has known the most evolution.
[00:56:56.000 --> 00:57:01.000]   So we have put a lot of chips on evolving this specific brain
[00:57:01.000 --> 00:57:06.000]   and the evolution of cortex is plasticity.
[00:57:06.000 --> 00:57:10.320]   It's this ability to change in response to things.
[00:57:10.320 --> 00:57:13.820]   So yes, they will integrate, that we want it or not.
[00:57:13.820 --> 00:57:17.840]   - Wow, there's no better way to end it.
[00:57:17.840 --> 00:57:19.520]   Paola, thank you so much for talking to me.
[00:57:19.520 --> 00:57:20.360]   - You're very welcome.
[00:57:20.360 --> 00:57:22.400]   - That was great. - This is very exciting.
[00:57:22.400 --> 00:57:24.980]   (upbeat music)
[00:57:24.980 --> 00:57:27.560]   (upbeat music)
[00:57:27.560 --> 00:57:30.140]   (upbeat music)
[00:57:30.140 --> 00:57:32.720]   (upbeat music)
[00:57:32.720 --> 00:57:35.300]   (upbeat music)
[00:57:35.300 --> 00:57:37.880]   (upbeat music)
[00:57:37.880 --> 00:57:47.880]   [BLANK_AUDIO]

